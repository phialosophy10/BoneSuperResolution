
wandb: WARNING Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 0.4892932176589966, disc_loss = 0.5894583463668823
Trained batch 1 in epoch 0, gen_loss = 0.4966427981853485, disc_loss = 0.5687395334243774
Trained batch 2 in epoch 0, gen_loss = 0.4783187210559845, disc_loss = 0.5412423113981882
Trained batch 3 in epoch 0, gen_loss = 0.47487594932317734, disc_loss = 0.5716851279139519
Trained batch 4 in epoch 0, gen_loss = 0.48064244389533994, disc_loss = 0.5153175115585327
Trained batch 5 in epoch 0, gen_loss = 0.47728897134462994, disc_loss = 0.4679744939009349
Trained batch 6 in epoch 0, gen_loss = 0.4783078602382115, disc_loss = 0.4265021937234061
Trained batch 7 in epoch 0, gen_loss = 0.4723774418234825, disc_loss = 0.3927569966763258
Trained batch 8 in epoch 0, gen_loss = 0.4675438172287411, disc_loss = 0.3612167619996601
Trained batch 9 in epoch 0, gen_loss = 0.4692127227783203, disc_loss = 0.33502810075879097
Trained batch 10 in epoch 0, gen_loss = 0.4695886861194264, disc_loss = 0.31342632391236047
Trained batch 11 in epoch 0, gen_loss = 0.47309034566084546, disc_loss = 0.2951133114596208
Trained batch 12 in epoch 0, gen_loss = 0.4660798769730788, disc_loss = 0.27943551540374756
Trained batch 13 in epoch 0, gen_loss = 0.45976113634450094, disc_loss = 0.26703485899737905
Trained batch 14 in epoch 0, gen_loss = 0.46323647697766623, disc_loss = 0.25627322296301525
Trained batch 15 in epoch 0, gen_loss = 0.4646027609705925, disc_loss = 0.24777583312243223
Trained batch 16 in epoch 0, gen_loss = 0.4657791467273937, disc_loss = 0.24070642012007096
Trained batch 17 in epoch 0, gen_loss = 0.4636089007059733, disc_loss = 0.24407351430919436
Trained batch 18 in epoch 0, gen_loss = 0.46717053338101033, disc_loss = 0.25498347298095103
Trained batch 19 in epoch 0, gen_loss = 0.4669386953115463, disc_loss = 0.25772756412625314
Trained batch 20 in epoch 0, gen_loss = 0.46861774296987624, disc_loss = 0.26261649032433826
Trained batch 21 in epoch 0, gen_loss = 0.4639153548262336, disc_loss = 0.2631668265570294
Trained batch 22 in epoch 0, gen_loss = 0.46439317775809247, disc_loss = 0.2648064863422643
Trained batch 23 in epoch 0, gen_loss = 0.46502578631043434, disc_loss = 0.2656435215224822
Trained batch 24 in epoch 0, gen_loss = 0.4650102746486664, disc_loss = 0.26692336857318877
Trained batch 25 in epoch 0, gen_loss = 0.4624587721549548, disc_loss = 0.2639790314894456
Trained batch 26 in epoch 0, gen_loss = 0.4632414623543068, disc_loss = 0.26045488428186486
Trained batch 27 in epoch 0, gen_loss = 0.46554240584373474, disc_loss = 0.25637073442339897
Trained batch 28 in epoch 0, gen_loss = 0.46645121944361717, disc_loss = 0.2518760212536516
Trained batch 29 in epoch 0, gen_loss = 0.46696255207061765, disc_loss = 0.24786626895268757
Trained batch 30 in epoch 0, gen_loss = 0.46628361748110864, disc_loss = 0.2445441811315475
Trained batch 31 in epoch 0, gen_loss = 0.4626634595915675, disc_loss = 0.24439073912799358
Trained batch 32 in epoch 0, gen_loss = 0.4602599225260995, disc_loss = 0.2411290772936561
Trained batch 33 in epoch 0, gen_loss = 0.46065646147026734, disc_loss = 0.23821254907285466
Trained batch 34 in epoch 0, gen_loss = 0.4596058351652963, disc_loss = 0.23703788944653104
Trained batch 35 in epoch 0, gen_loss = 0.45950816654496723, disc_loss = 0.23270912137296465
Trained batch 36 in epoch 0, gen_loss = 0.45871727369927073, disc_loss = 0.22919958990973396
Trained batch 37 in epoch 0, gen_loss = 0.45964279378715317, disc_loss = 0.22502123446840988
Trained batch 38 in epoch 0, gen_loss = 0.45877337608581936, disc_loss = 0.2217011822339816
Trained batch 39 in epoch 0, gen_loss = 0.45751055255532264, disc_loss = 0.2185239152982831
Trained batch 40 in epoch 0, gen_loss = 0.4583783607657363, disc_loss = 0.21563350463785777
Trained batch 41 in epoch 0, gen_loss = 0.46106142018522533, disc_loss = 0.21445420277970179
Trained batch 42 in epoch 0, gen_loss = 0.45936426728270774, disc_loss = 0.21390232305194057
Trained batch 43 in epoch 0, gen_loss = 0.456361784176393, disc_loss = 0.21622193401510065
Trained batch 44 in epoch 0, gen_loss = 0.45848815706041124, disc_loss = 0.21339126129945118
Trained batch 45 in epoch 0, gen_loss = 0.461061197778453, disc_loss = 0.211071136529031
Trained batch 46 in epoch 0, gen_loss = 0.46003653901688596, disc_loss = 0.2089537908422186
Trained batch 47 in epoch 0, gen_loss = 0.45997056489189464, disc_loss = 0.21326425423224768
Trained batch 48 in epoch 0, gen_loss = 0.46230293415030654, disc_loss = 0.212864345737866
Trained batch 49 in epoch 0, gen_loss = 0.4631538259983063, disc_loss = 0.21163009405136107
Trained batch 50 in epoch 0, gen_loss = 0.4629772837255515, disc_loss = 0.21036859382601344
Trained batch 51 in epoch 0, gen_loss = 0.46236243213598543, disc_loss = 0.20850104924577934
Trained batch 52 in epoch 0, gen_loss = 0.46183506329104584, disc_loss = 0.2059733673649014
Trained batch 53 in epoch 0, gen_loss = 0.46049464742342633, disc_loss = 0.205952452564681
Trained batch 54 in epoch 0, gen_loss = 0.45973887226798316, disc_loss = 0.20778925716876984
Trained batch 55 in epoch 0, gen_loss = 0.460708563881261, disc_loss = 0.2073078520063843
Trained batch 56 in epoch 0, gen_loss = 0.4612558301080737, disc_loss = 0.20532750207604022
Trained batch 57 in epoch 0, gen_loss = 0.46214285030447205, disc_loss = 0.2031434308095225
Trained batch 58 in epoch 0, gen_loss = 0.4619692351858495, disc_loss = 0.20152492215067652
Trained batch 59 in epoch 0, gen_loss = 0.46043888926506044, disc_loss = 0.20166428113977114
Trained batch 60 in epoch 0, gen_loss = 0.45945076424567427, disc_loss = 0.20562202837623533
Trained batch 61 in epoch 0, gen_loss = 0.4604499940910647, disc_loss = 0.20354388870539203
Trained batch 62 in epoch 0, gen_loss = 0.4615715945523883, disc_loss = 0.20231509397900294
Trained batch 63 in epoch 0, gen_loss = 0.4612136431969702, disc_loss = 0.20220568822696805
Trained batch 64 in epoch 0, gen_loss = 0.460418949677394, disc_loss = 0.20292469217227055
Trained batch 65 in epoch 0, gen_loss = 0.4618252055211501, disc_loss = 0.20179959454319693
Trained batch 66 in epoch 0, gen_loss = 0.4617724062791511, disc_loss = 0.2017386088620371
Trained batch 67 in epoch 0, gen_loss = 0.4621858022668782, disc_loss = 0.20204694985466845
Trained batch 68 in epoch 0, gen_loss = 0.4624563481496728, disc_loss = 0.20138152980286142
Trained batch 69 in epoch 0, gen_loss = 0.46266579415116993, disc_loss = 0.20069459101983478
Trained batch 70 in epoch 0, gen_loss = 0.46360333494737116, disc_loss = 0.20152408031510635
Trained batch 71 in epoch 0, gen_loss = 0.46443143859505653, disc_loss = 0.2027315114521318
Trained batch 72 in epoch 0, gen_loss = 0.4649448464178059, disc_loss = 0.20294665800382014
Trained batch 73 in epoch 0, gen_loss = 0.46602142139061076, disc_loss = 0.20217155342971957
Trained batch 74 in epoch 0, gen_loss = 0.46600674152374266, disc_loss = 0.20168246030807496
Trained batch 75 in epoch 0, gen_loss = 0.4659341797232628, disc_loss = 0.20104231254050606
Trained batch 76 in epoch 0, gen_loss = 0.4662045170734455, disc_loss = 0.2007932910671482
Trained batch 77 in epoch 0, gen_loss = 0.4667882407322908, disc_loss = 0.20063236565926137
Trained batch 78 in epoch 0, gen_loss = 0.4664746824699112, disc_loss = 0.20086658510226238
Trained batch 79 in epoch 0, gen_loss = 0.4650509297847748, disc_loss = 0.20281370189040898
Trained batch 80 in epoch 0, gen_loss = 0.46468238477353696, disc_loss = 0.20331751030904274
Trained batch 81 in epoch 0, gen_loss = 0.4653778803057787, disc_loss = 0.20374796485028615
Trained batch 82 in epoch 0, gen_loss = 0.46606538166482764, disc_loss = 0.20433589564748558
Trained batch 83 in epoch 0, gen_loss = 0.4665323020446868, disc_loss = 0.20497038995935804
Trained batch 84 in epoch 0, gen_loss = 0.46664855620440315, disc_loss = 0.20539016197709475
Trained batch 85 in epoch 0, gen_loss = 0.4677127960116364, disc_loss = 0.20526929182368656
Trained batch 86 in epoch 0, gen_loss = 0.4670547503849556, disc_loss = 0.20584588506441007
Trained batch 87 in epoch 0, gen_loss = 0.4671478478068655, disc_loss = 0.20676008086990227
Trained batch 88 in epoch 0, gen_loss = 0.46788512354486445, disc_loss = 0.20686732634399715
Trained batch 89 in epoch 0, gen_loss = 0.4682822455962499, disc_loss = 0.2071010892589887
Trained batch 90 in epoch 0, gen_loss = 0.4677281608948341, disc_loss = 0.20736524217076355
Trained batch 91 in epoch 0, gen_loss = 0.4680119046698446, disc_loss = 0.20783698931336403
Trained batch 92 in epoch 0, gen_loss = 0.46669864974996095, disc_loss = 0.20788427049754768
Trained batch 93 in epoch 0, gen_loss = 0.4664045686417438, disc_loss = 0.2083885040371976
Trained batch 94 in epoch 0, gen_loss = 0.4666686453317341, disc_loss = 0.20860074413450141
Trained batch 95 in epoch 0, gen_loss = 0.4670250912507375, disc_loss = 0.20882065780460835
Trained batch 96 in epoch 0, gen_loss = 0.466932270944733, disc_loss = 0.20898563960163863
Trained batch 97 in epoch 0, gen_loss = 0.4664757531516406, disc_loss = 0.2099323601138835
Trained batch 98 in epoch 0, gen_loss = 0.46698481265944664, disc_loss = 0.20983902432701804
Trained batch 99 in epoch 0, gen_loss = 0.4676801282167435, disc_loss = 0.20938262462615967
Trained batch 100 in epoch 0, gen_loss = 0.46778313918869097, disc_loss = 0.2094097501865708
Trained batch 101 in epoch 0, gen_loss = 0.4677397334108166, disc_loss = 0.209150534342317
Trained batch 102 in epoch 0, gen_loss = 0.4675694000952452, disc_loss = 0.209060008664733
Trained batch 103 in epoch 0, gen_loss = 0.46672374411271167, disc_loss = 0.20981798292352602
Trained batch 104 in epoch 0, gen_loss = 0.4671243480273655, disc_loss = 0.20993662604263852
Trained batch 105 in epoch 0, gen_loss = 0.46685927712692404, disc_loss = 0.2102116252172668
Trained batch 106 in epoch 0, gen_loss = 0.4665564883535153, disc_loss = 0.21015026789402294
Trained batch 107 in epoch 0, gen_loss = 0.46628919354191534, disc_loss = 0.210346473035989
Trained batch 108 in epoch 0, gen_loss = 0.46652858629139193, disc_loss = 0.2107419612210825
Trained batch 109 in epoch 0, gen_loss = 0.4659984385425394, disc_loss = 0.21131824011152442
Trained batch 110 in epoch 0, gen_loss = 0.4658704716880042, disc_loss = 0.21126172134468146
Trained batch 111 in epoch 0, gen_loss = 0.46657876723579, disc_loss = 0.2113828749528953
Trained batch 112 in epoch 0, gen_loss = 0.4671023234856867, disc_loss = 0.21113798075017676
Trained batch 113 in epoch 0, gen_loss = 0.46738757271515696, disc_loss = 0.21089824262941093
Trained batch 114 in epoch 0, gen_loss = 0.4676644597364509, disc_loss = 0.21026223172312197
Trained batch 115 in epoch 0, gen_loss = 0.4670719000799903, disc_loss = 0.21022201663461224
Trained batch 116 in epoch 0, gen_loss = 0.4669178563814897, disc_loss = 0.21120154577442724
Trained batch 117 in epoch 0, gen_loss = 0.46674473735235505, disc_loss = 0.2123406516798472
Trained batch 118 in epoch 0, gen_loss = 0.46609209590599315, disc_loss = 0.21254824177056802
Trained batch 119 in epoch 0, gen_loss = 0.46619382724165914, disc_loss = 0.21258154089252154
Trained batch 120 in epoch 0, gen_loss = 0.4658663799940062, disc_loss = 0.2128122325771111
Trained batch 121 in epoch 0, gen_loss = 0.46540504938266314, disc_loss = 0.21270833225523839
Trained batch 122 in epoch 0, gen_loss = 0.46511260135387017, disc_loss = 0.212869097304538
Trained batch 123 in epoch 0, gen_loss = 0.46493806665943516, disc_loss = 0.21269330718824941
Trained batch 124 in epoch 0, gen_loss = 0.46398590087890623, disc_loss = 0.21250007629394532
Trained batch 125 in epoch 0, gen_loss = 0.46345301114377524, disc_loss = 0.21264411012331644
Trained batch 126 in epoch 0, gen_loss = 0.4632789250903242, disc_loss = 0.21222815422091898
Trained batch 127 in epoch 0, gen_loss = 0.46321428893134, disc_loss = 0.21206296037416905
Trained batch 128 in epoch 0, gen_loss = 0.4629260562649069, disc_loss = 0.21175788770350376
Trained batch 129 in epoch 0, gen_loss = 0.46272871929865617, disc_loss = 0.21143777760175558
Trained batch 130 in epoch 0, gen_loss = 0.4629033915414155, disc_loss = 0.2112929170368282
Trained batch 131 in epoch 0, gen_loss = 0.46256520102421445, disc_loss = 0.21113782872756323
Trained batch 132 in epoch 0, gen_loss = 0.46233764514887243, disc_loss = 0.21086482053860686
Trained batch 133 in epoch 0, gen_loss = 0.4621746146412038, disc_loss = 0.2109807664111479
Trained batch 134 in epoch 0, gen_loss = 0.4621935371999387, disc_loss = 0.21167708800898657
Trained batch 135 in epoch 0, gen_loss = 0.4625508675680441, disc_loss = 0.21230119433911407
Trained batch 136 in epoch 0, gen_loss = 0.4623738462037414, disc_loss = 0.21295661615194195
Trained batch 137 in epoch 0, gen_loss = 0.46241479874521063, disc_loss = 0.21306639423836832
Trained batch 138 in epoch 0, gen_loss = 0.46248109070517174, disc_loss = 0.21357105865324144
Trained batch 139 in epoch 0, gen_loss = 0.4616637715271541, disc_loss = 0.21410067070807728
Trained batch 140 in epoch 0, gen_loss = 0.4608325300909949, disc_loss = 0.214025061709661
Trained batch 141 in epoch 0, gen_loss = 0.4600538502276783, disc_loss = 0.21394540012722285
Trained batch 142 in epoch 0, gen_loss = 0.4594546214683906, disc_loss = 0.2137643709466174
Trained batch 143 in epoch 0, gen_loss = 0.4588425149106317, disc_loss = 0.21364265328480136
Trained batch 144 in epoch 0, gen_loss = 0.45870476858369236, disc_loss = 0.21350964842171505
Trained batch 145 in epoch 0, gen_loss = 0.45819648426689513, disc_loss = 0.21326314300706942
Trained batch 146 in epoch 0, gen_loss = 0.45775826974790923, disc_loss = 0.21315751371740485
Trained batch 147 in epoch 0, gen_loss = 0.4572839136864688, disc_loss = 0.21315088545953906
Trained batch 148 in epoch 0, gen_loss = 0.4575363067572549, disc_loss = 0.21354288062793297
Trained batch 149 in epoch 0, gen_loss = 0.45734239399433135, disc_loss = 0.2136542910337448
Trained batch 150 in epoch 0, gen_loss = 0.45721489881837607, disc_loss = 0.2134755958389762
Trained batch 151 in epoch 0, gen_loss = 0.45688132333912346, disc_loss = 0.213410733071597
Trained batch 152 in epoch 0, gen_loss = 0.45653607214198394, disc_loss = 0.21323717663101122
Trained batch 153 in epoch 0, gen_loss = 0.45660087930691706, disc_loss = 0.21301894151158146
Trained batch 154 in epoch 0, gen_loss = 0.4572304194973361, disc_loss = 0.2127698803140271
Trained batch 155 in epoch 0, gen_loss = 0.4572892317023033, disc_loss = 0.21245214581871644
Trained batch 156 in epoch 0, gen_loss = 0.457093757239117, disc_loss = 0.2117236753937545
Trained batch 157 in epoch 0, gen_loss = 0.45661991759191584, disc_loss = 0.21151037353880797
Trained batch 158 in epoch 0, gen_loss = 0.45668958343050015, disc_loss = 0.2120741865357513
Trained batch 159 in epoch 0, gen_loss = 0.4564626272767782, disc_loss = 0.21343070389702917
Trained batch 160 in epoch 0, gen_loss = 0.45630526764792684, disc_loss = 0.21389903535383828
Trained batch 161 in epoch 0, gen_loss = 0.4559358534989534, disc_loss = 0.21388311996872042
Trained batch 162 in epoch 0, gen_loss = 0.4556114797943209, disc_loss = 0.21389407239442954
Trained batch 163 in epoch 0, gen_loss = 0.4554252277423696, disc_loss = 0.21387440702173768
Trained batch 164 in epoch 0, gen_loss = 0.4550159376679045, disc_loss = 0.2140043351686362
Trained batch 165 in epoch 0, gen_loss = 0.45490400026361627, disc_loss = 0.21420464539025202
Trained batch 166 in epoch 0, gen_loss = 0.45503779746101286, disc_loss = 0.21444127490063628
Trained batch 167 in epoch 0, gen_loss = 0.4549441561102867, disc_loss = 0.21459990411642052
Trained batch 168 in epoch 0, gen_loss = 0.4545698317550343, disc_loss = 0.2150134332257615
Trained batch 169 in epoch 0, gen_loss = 0.45405520148137035, disc_loss = 0.21490566511364545
Trained batch 170 in epoch 0, gen_loss = 0.45410275668428657, disc_loss = 0.2145885185540071
Trained batch 171 in epoch 0, gen_loss = 0.45416802254527117, disc_loss = 0.21447256831235664
Trained batch 172 in epoch 0, gen_loss = 0.45382978909277505, disc_loss = 0.21425851757471273
Trained batch 173 in epoch 0, gen_loss = 0.4536234049618929, disc_loss = 0.21401114650498862
Trained batch 174 in epoch 0, gen_loss = 0.45324694854872566, disc_loss = 0.21382861018180846
Trained batch 175 in epoch 0, gen_loss = 0.4530417434871197, disc_loss = 0.21357074261388995
Trained batch 176 in epoch 0, gen_loss = 0.4524170099678686, disc_loss = 0.21346385322384914
Trained batch 177 in epoch 0, gen_loss = 0.4527027904987335, disc_loss = 0.21331402701273394
Trained batch 178 in epoch 0, gen_loss = 0.45239965309643876, disc_loss = 0.21296957459862673
Trained batch 179 in epoch 0, gen_loss = 0.45210232469770645, disc_loss = 0.21270299744274881
Trained batch 180 in epoch 0, gen_loss = 0.45228497412323293, disc_loss = 0.21280261717777885
Trained batch 181 in epoch 0, gen_loss = 0.4521034382856809, disc_loss = 0.21281243140225883
Trained batch 182 in epoch 0, gen_loss = 0.4519008396427488, disc_loss = 0.2124475623414816
Trained batch 183 in epoch 0, gen_loss = 0.45185377626963286, disc_loss = 0.21212886055202587
Trained batch 184 in epoch 0, gen_loss = 0.45169570446014407, disc_loss = 0.21179957115972364
Trained batch 185 in epoch 0, gen_loss = 0.4518311241621612, disc_loss = 0.21136921516028784
Trained batch 186 in epoch 0, gen_loss = 0.4516970418035028, disc_loss = 0.21095839047176954
Trained batch 187 in epoch 0, gen_loss = 0.4514641059522933, disc_loss = 0.2105713152980551
Trained batch 188 in epoch 0, gen_loss = 0.4515332256360029, disc_loss = 0.21011210465557362
Trained batch 189 in epoch 0, gen_loss = 0.45150398753191295, disc_loss = 0.2101154797955563
Trained batch 190 in epoch 0, gen_loss = 0.4515914124344032, disc_loss = 0.2110333837451735
Trained batch 191 in epoch 0, gen_loss = 0.4517602229801317, disc_loss = 0.21159709601973495
Trained batch 192 in epoch 0, gen_loss = 0.451689510765471, disc_loss = 0.2114536471163053
Trained batch 193 in epoch 0, gen_loss = 0.4514233230315533, disc_loss = 0.21148303266345841
Trained batch 194 in epoch 0, gen_loss = 0.4513941214634822, disc_loss = 0.2113525233207605
Trained batch 195 in epoch 0, gen_loss = 0.45177494019878156, disc_loss = 0.2116216641603684
Trained batch 196 in epoch 0, gen_loss = 0.4512834087543681, disc_loss = 0.21144774072061334
Trained batch 197 in epoch 0, gen_loss = 0.45123091686253597, disc_loss = 0.21108231174223352
Trained batch 198 in epoch 0, gen_loss = 0.4509701740801634, disc_loss = 0.21130745389952732
Trained batch 199 in epoch 0, gen_loss = 0.45067988395690917, disc_loss = 0.21156357511878013
Trained batch 200 in epoch 0, gen_loss = 0.4502186589869694, disc_loss = 0.21171263008568417
Trained batch 201 in epoch 0, gen_loss = 0.4499324207553769, disc_loss = 0.21168612187156582
Trained batch 202 in epoch 0, gen_loss = 0.45010357390483613, disc_loss = 0.2116426318296658
Trained batch 203 in epoch 0, gen_loss = 0.4498479392598657, disc_loss = 0.2111663779645574
Trained batch 204 in epoch 0, gen_loss = 0.4498797924053378, disc_loss = 0.2106659817622929
Trained batch 205 in epoch 0, gen_loss = 0.449686765236762, disc_loss = 0.21035692178942625
Trained batch 206 in epoch 0, gen_loss = 0.44969496879600673, disc_loss = 0.20997595625079196
Trained batch 207 in epoch 0, gen_loss = 0.4492952171713114, disc_loss = 0.2097412934885002
Trained batch 208 in epoch 0, gen_loss = 0.4493235659085963, disc_loss = 0.21019865076935462
Trained batch 209 in epoch 0, gen_loss = 0.4491812166713533, disc_loss = 0.21081865454713503
Trained batch 210 in epoch 0, gen_loss = 0.4487216280534934, disc_loss = 0.21068716871936174
Trained batch 211 in epoch 0, gen_loss = 0.4486172930249628, disc_loss = 0.21067828351174886
Trained batch 212 in epoch 0, gen_loss = 0.44857525125915454, disc_loss = 0.21034175482854037
Trained batch 213 in epoch 0, gen_loss = 0.448340025739135, disc_loss = 0.2101016121559611
Trained batch 214 in epoch 0, gen_loss = 0.4486256477444671, disc_loss = 0.20968331112418065
Trained batch 215 in epoch 0, gen_loss = 0.44866777101048716, disc_loss = 0.2096724301852562
Trained batch 216 in epoch 0, gen_loss = 0.448592631635578, disc_loss = 0.20934804298910678
Trained batch 217 in epoch 0, gen_loss = 0.4483306459877469, disc_loss = 0.20901039769069865
Trained batch 218 in epoch 0, gen_loss = 0.4481976799768944, disc_loss = 0.20854863939492124
Trained batch 219 in epoch 0, gen_loss = 0.4482052039016377, disc_loss = 0.20807897309688003
Trained batch 220 in epoch 0, gen_loss = 0.44802112897596746, disc_loss = 0.20791264940306073
Trained batch 221 in epoch 0, gen_loss = 0.4482591530761203, disc_loss = 0.20797236569158667
Trained batch 222 in epoch 0, gen_loss = 0.44791454571244965, disc_loss = 0.20795498210352098
Trained batch 223 in epoch 0, gen_loss = 0.4478363406711391, disc_loss = 0.2077682081144303
Trained batch 224 in epoch 0, gen_loss = 0.447615274588267, disc_loss = 0.20768284032742182
Trained batch 225 in epoch 0, gen_loss = 0.4477184199917633, disc_loss = 0.20733477415896095
Trained batch 226 in epoch 0, gen_loss = 0.4478699912846351, disc_loss = 0.2066582867686969
Trained batch 227 in epoch 0, gen_loss = 0.4478916264416879, disc_loss = 0.2063863134632508
Trained batch 228 in epoch 0, gen_loss = 0.44784267487484297, disc_loss = 0.20653188570227685
Trained batch 229 in epoch 0, gen_loss = 0.4477373374545056, disc_loss = 0.20607407404028852
Trained batch 230 in epoch 0, gen_loss = 0.4475431509348221, disc_loss = 0.20640123264614121
Trained batch 231 in epoch 0, gen_loss = 0.4480183854185302, disc_loss = 0.20688612386584282
Trained batch 232 in epoch 0, gen_loss = 0.4479946341893192, disc_loss = 0.20674978190225593
Trained batch 233 in epoch 0, gen_loss = 0.44793468280735177, disc_loss = 0.206652390714894
Trained batch 234 in epoch 0, gen_loss = 0.44789414012685735, disc_loss = 0.2066079740194564
Trained batch 235 in epoch 0, gen_loss = 0.4478777053497605, disc_loss = 0.20642374127598132
Trained batch 236 in epoch 0, gen_loss = 0.4481760623082833, disc_loss = 0.20615930364856236
Trained batch 237 in epoch 0, gen_loss = 0.44813685795339214, disc_loss = 0.20585122911118658
Trained batch 238 in epoch 0, gen_loss = 0.44844370843476333, disc_loss = 0.20582719271901262
Trained batch 239 in epoch 0, gen_loss = 0.44839100167155266, disc_loss = 0.20575152517606815
Trained batch 240 in epoch 0, gen_loss = 0.44843928744684114, disc_loss = 0.20558616655001502
Trained batch 241 in epoch 0, gen_loss = 0.44850004532120447, disc_loss = 0.2054251565420923
Trained batch 242 in epoch 0, gen_loss = 0.4483593211743076, disc_loss = 0.20521468899132292
Trained batch 243 in epoch 0, gen_loss = 0.44839275274120394, disc_loss = 0.20533074572926663
Trained batch 244 in epoch 0, gen_loss = 0.4479813952835239, disc_loss = 0.2061220242052662
Trained batch 245 in epoch 0, gen_loss = 0.44806155719892765, disc_loss = 0.20698705036950305
Trained batch 246 in epoch 0, gen_loss = 0.4480807670214881, disc_loss = 0.20700735601818995
Trained batch 247 in epoch 0, gen_loss = 0.448002107561596, disc_loss = 0.20711323877255763
Trained batch 248 in epoch 0, gen_loss = 0.4480255043889624, disc_loss = 0.2070199005216001
Trained batch 249 in epoch 0, gen_loss = 0.4479361318349838, disc_loss = 0.20664698827266692
Trained batch 250 in epoch 0, gen_loss = 0.44814771378182794, disc_loss = 0.20646735723037643
Trained batch 251 in epoch 0, gen_loss = 0.44841080797570093, disc_loss = 0.20624475163363276
Trained batch 252 in epoch 0, gen_loss = 0.44878704592644464, disc_loss = 0.20616014843637293
Trained batch 253 in epoch 0, gen_loss = 0.4487289224318632, disc_loss = 0.20571358774708012
Trained batch 254 in epoch 0, gen_loss = 0.44843402259490067, disc_loss = 0.20558172268610375
Trained batch 255 in epoch 0, gen_loss = 0.448619537637569, disc_loss = 0.20543013160931878
Trained batch 256 in epoch 0, gen_loss = 0.44875461582079934, disc_loss = 0.20504381200334906
Trained batch 257 in epoch 0, gen_loss = 0.4486879006374714, disc_loss = 0.2057172943975112
Trained batch 258 in epoch 0, gen_loss = 0.44893862082691266, disc_loss = 0.20553647076646334
Trained batch 259 in epoch 0, gen_loss = 0.44893520795381986, disc_loss = 0.20520322772745903
Trained batch 260 in epoch 0, gen_loss = 0.44911017203239645, disc_loss = 0.20511086407863316
Trained batch 261 in epoch 0, gen_loss = 0.4491727529591276, disc_loss = 0.2047747252722278
Trained batch 262 in epoch 0, gen_loss = 0.4492463162416741, disc_loss = 0.20455703646397863
Trained batch 263 in epoch 0, gen_loss = 0.4494800033668677, disc_loss = 0.2040833060375669
Trained batch 264 in epoch 0, gen_loss = 0.44934172832740926, disc_loss = 0.20362749645170175
Trained batch 265 in epoch 0, gen_loss = 0.44951311269200833, disc_loss = 0.2032932429609442
Trained batch 266 in epoch 0, gen_loss = 0.449544111329518, disc_loss = 0.20301182919673705
Trained batch 267 in epoch 0, gen_loss = 0.44920877345017535, disc_loss = 0.2027004154593642
Trained batch 268 in epoch 0, gen_loss = 0.4493138979580323, disc_loss = 0.20246615953272604
Trained batch 269 in epoch 0, gen_loss = 0.449439705853109, disc_loss = 0.20182191054164259
Trained batch 270 in epoch 0, gen_loss = 0.4493136066132366, disc_loss = 0.2013019238052223
Trained batch 271 in epoch 0, gen_loss = 0.449426855891943, disc_loss = 0.2008485920549206
Trained batch 272 in epoch 0, gen_loss = 0.4491828723704859, disc_loss = 0.20046790557548458
Trained batch 273 in epoch 0, gen_loss = 0.44941550602007957, disc_loss = 0.2005753439042146
Trained batch 274 in epoch 0, gen_loss = 0.44935409372503105, disc_loss = 0.2002394783158194
Trained batch 275 in epoch 0, gen_loss = 0.44955557584762573, disc_loss = 0.19975758367555513
Trained batch 276 in epoch 0, gen_loss = 0.4496119003003255, disc_loss = 0.19916421992011665
Trained batch 277 in epoch 0, gen_loss = 0.4494461731301795, disc_loss = 0.19874263211093146
Trained batch 278 in epoch 0, gen_loss = 0.44924641648928326, disc_loss = 0.19840353016330992
Trained batch 279 in epoch 0, gen_loss = 0.44931623509952, disc_loss = 0.1987884187738278
Trained batch 280 in epoch 0, gen_loss = 0.4491957898029653, disc_loss = 0.19982474230335912
Trained batch 281 in epoch 0, gen_loss = 0.4493079655770714, disc_loss = 0.19984025201027064
Trained batch 282 in epoch 0, gen_loss = 0.44925863403734806, disc_loss = 0.19984297643254376
Trained batch 283 in epoch 0, gen_loss = 0.44921335021794684, disc_loss = 0.19952000598226424
Trained batch 284 in epoch 0, gen_loss = 0.44923903743426, disc_loss = 0.19923235613918094
Trained batch 285 in epoch 0, gen_loss = 0.44908448407700013, disc_loss = 0.19918406756685955
Trained batch 286 in epoch 0, gen_loss = 0.44918177902490836, disc_loss = 0.19893849131615526
Trained batch 287 in epoch 0, gen_loss = 0.4490277600578136, disc_loss = 0.1990481105620145
Trained batch 288 in epoch 0, gen_loss = 0.44871054656777826, disc_loss = 0.19936556909813394
Trained batch 289 in epoch 0, gen_loss = 0.4487395655492256, disc_loss = 0.1992460234604519
Trained batch 290 in epoch 0, gen_loss = 0.44830678306084726, disc_loss = 0.19893125139330467
Trained batch 291 in epoch 0, gen_loss = 0.44837011652041786, disc_loss = 0.19849831737858586
Trained batch 292 in epoch 0, gen_loss = 0.448219979277243, disc_loss = 0.19805767958659565
Trained batch 293 in epoch 0, gen_loss = 0.44790302784669966, disc_loss = 0.19791561972704672
Trained batch 294 in epoch 0, gen_loss = 0.4479641509258141, disc_loss = 0.19849582202732563
Trained batch 295 in epoch 0, gen_loss = 0.44782902129195834, disc_loss = 0.19823493546101492
Trained batch 296 in epoch 0, gen_loss = 0.4478062559859921, disc_loss = 0.19818021120622703
Trained batch 297 in epoch 0, gen_loss = 0.44768907439788713, disc_loss = 0.19766213237964267
Trained batch 298 in epoch 0, gen_loss = 0.4475511490899982, disc_loss = 0.19779316545853448
Trained batch 299 in epoch 0, gen_loss = 0.4475610501567523, disc_loss = 0.19753094750766953
Trained batch 300 in epoch 0, gen_loss = 0.4474190871580891, disc_loss = 0.19723768480914178
Trained batch 301 in epoch 0, gen_loss = 0.44726980117377857, disc_loss = 0.19693408682572328
Trained batch 302 in epoch 0, gen_loss = 0.4472373211541192, disc_loss = 0.1966353998436491
Trained batch 303 in epoch 0, gen_loss = 0.44753841124475, disc_loss = 0.1963892746532924
Trained batch 304 in epoch 0, gen_loss = 0.4474702421758996, disc_loss = 0.19644044332939092
Trained batch 305 in epoch 0, gen_loss = 0.44748373310160794, disc_loss = 0.196652048340469
Trained batch 306 in epoch 0, gen_loss = 0.4477028639968909, disc_loss = 0.1963589297552936
Trained batch 307 in epoch 0, gen_loss = 0.4476482414386489, disc_loss = 0.19587663019850077
Trained batch 308 in epoch 0, gen_loss = 0.4478367313405071, disc_loss = 0.19535139418270403
Trained batch 309 in epoch 0, gen_loss = 0.4476967720254775, disc_loss = 0.19519850792543542
Trained batch 310 in epoch 0, gen_loss = 0.44786548336602483, disc_loss = 0.19566054041482436
Trained batch 311 in epoch 0, gen_loss = 0.44798405907857114, disc_loss = 0.19584659217761305
Trained batch 312 in epoch 0, gen_loss = 0.4479517357798811, disc_loss = 0.1957056534568818
Trained batch 313 in epoch 0, gen_loss = 0.44791457056999207, disc_loss = 0.19555104493644018
Trained batch 314 in epoch 0, gen_loss = 0.4477505644162496, disc_loss = 0.19538419684838682
Trained batch 315 in epoch 0, gen_loss = 0.4474994110155709, disc_loss = 0.19520883934713806
Trained batch 316 in epoch 0, gen_loss = 0.4475244105990377, disc_loss = 0.19493265302516874
Trained batch 317 in epoch 0, gen_loss = 0.44732808279541303, disc_loss = 0.1956178654488996
Trained batch 318 in epoch 0, gen_loss = 0.4471024626101072, disc_loss = 0.19541404443591553
Trained batch 319 in epoch 0, gen_loss = 0.4473563198000193, disc_loss = 0.19497225210652686
Trained batch 320 in epoch 0, gen_loss = 0.4473188400639923, disc_loss = 0.19481038258663405
Trained batch 321 in epoch 0, gen_loss = 0.4472440663516892, disc_loss = 0.19452352655808564
Trained batch 322 in epoch 0, gen_loss = 0.4473044885201351, disc_loss = 0.19412623111147076
Trained batch 323 in epoch 0, gen_loss = 0.44708139338979014, disc_loss = 0.1943111272563261
Trained batch 324 in epoch 0, gen_loss = 0.44719692807931166, disc_loss = 0.19447082886902187
Trained batch 325 in epoch 0, gen_loss = 0.44718485293578514, disc_loss = 0.1941181355287418
Trained batch 326 in epoch 0, gen_loss = 0.446970356987157, disc_loss = 0.19453346180738113
Trained batch 327 in epoch 0, gen_loss = 0.44700821879796865, disc_loss = 0.19433585448167856
Trained batch 328 in epoch 0, gen_loss = 0.447247863631118, disc_loss = 0.19405774319810526
Trained batch 329 in epoch 0, gen_loss = 0.447341704007351, disc_loss = 0.19393049551343375
Trained batch 330 in epoch 0, gen_loss = 0.4472892474371861, disc_loss = 0.19382963026240693
Trained batch 331 in epoch 0, gen_loss = 0.4471461501825287, disc_loss = 0.19386460058144236
Trained batch 332 in epoch 0, gen_loss = 0.4471556439593032, disc_loss = 0.19340081979987678
Trained batch 333 in epoch 0, gen_loss = 0.4469636353903902, disc_loss = 0.19327924263936852
Trained batch 334 in epoch 0, gen_loss = 0.4472296860680651, disc_loss = 0.1929841882868934
Trained batch 335 in epoch 0, gen_loss = 0.44733925970892113, disc_loss = 0.19253988822899937
Trained batch 336 in epoch 0, gen_loss = 0.44698987932162754, disc_loss = 0.19281928406514293
Trained batch 337 in epoch 0, gen_loss = 0.44683968421270154, disc_loss = 0.19280381264308324
Trained batch 338 in epoch 0, gen_loss = 0.4469366555368654, disc_loss = 0.19263639757656945
Trained batch 339 in epoch 0, gen_loss = 0.4469797862803235, disc_loss = 0.19231141496121007
Trained batch 340 in epoch 0, gen_loss = 0.44684524375322626, disc_loss = 0.1920951702017501
Trained batch 341 in epoch 0, gen_loss = 0.44676906820277723, disc_loss = 0.19171562500581232
Trained batch 342 in epoch 0, gen_loss = 0.44692111554020697, disc_loss = 0.19154898858691619
Trained batch 343 in epoch 0, gen_loss = 0.44666393854936887, disc_loss = 0.19120034787175788
Trained batch 344 in epoch 0, gen_loss = 0.4465864995251531, disc_loss = 0.19070332970848117
Trained batch 345 in epoch 0, gen_loss = 0.446608150280969, disc_loss = 0.19056035703683347
Trained batch 346 in epoch 0, gen_loss = 0.44654521921526114, disc_loss = 0.19080063636798508
Trained batch 347 in epoch 0, gen_loss = 0.4467273070209328, disc_loss = 0.19060873249331597
Trained batch 348 in epoch 0, gen_loss = 0.4466979331990709, disc_loss = 0.19089789522603623
Trained batch 349 in epoch 0, gen_loss = 0.44671512757028853, disc_loss = 0.1907133344720517
Trained batch 350 in epoch 0, gen_loss = 0.4467514754190744, disc_loss = 0.19051865864534492
Trained batch 351 in epoch 0, gen_loss = 0.4465934540229765, disc_loss = 0.190465323547621
Trained batch 352 in epoch 0, gen_loss = 0.44643414307586193, disc_loss = 0.19028096813339182
Trained batch 353 in epoch 0, gen_loss = 0.4464992769693924, disc_loss = 0.18995750171926903
Trained batch 354 in epoch 0, gen_loss = 0.44649820117883277, disc_loss = 0.1896868183002086
Trained batch 355 in epoch 0, gen_loss = 0.4462849260883385, disc_loss = 0.1897199147046031
Trained batch 356 in epoch 0, gen_loss = 0.44608451872646643, disc_loss = 0.1896336480860366
Trained batch 357 in epoch 0, gen_loss = 0.4458671476088423, disc_loss = 0.1895077107266091
Trained batch 358 in epoch 0, gen_loss = 0.4458172933138845, disc_loss = 0.18933886408411527
Trained batch 359 in epoch 0, gen_loss = 0.44577256184485226, disc_loss = 0.18943466973077092
Trained batch 360 in epoch 0, gen_loss = 0.4457953294063209, disc_loss = 0.1900416283076242
Trained batch 361 in epoch 0, gen_loss = 0.4459041968728956, disc_loss = 0.18993926614790496
Trained batch 362 in epoch 0, gen_loss = 0.4458921641193474, disc_loss = 0.18995076724258828
Trained batch 363 in epoch 0, gen_loss = 0.44584175101020834, disc_loss = 0.18999164861084505
Trained batch 364 in epoch 0, gen_loss = 0.4461485456930448, disc_loss = 0.19041232399846594
Trained batch 365 in epoch 0, gen_loss = 0.44596933553127643, disc_loss = 0.19084604718096432
Trained batch 366 in epoch 0, gen_loss = 0.4460157514105701, disc_loss = 0.19048143491372263
Trained batch 367 in epoch 0, gen_loss = 0.44582126249113807, disc_loss = 0.1900737235656656
Trained batch 368 in epoch 0, gen_loss = 0.445728808076078, disc_loss = 0.19021457448339235
Trained batch 369 in epoch 0, gen_loss = 0.4456757530167296, disc_loss = 0.1900356903923927
Trained batch 370 in epoch 0, gen_loss = 0.44567931252669774, disc_loss = 0.18986728083031035
Trained batch 371 in epoch 0, gen_loss = 0.4457102187218205, disc_loss = 0.18981228498942268
Trained batch 372 in epoch 0, gen_loss = 0.44571366642499416, disc_loss = 0.1899740208819229
Trained batch 373 in epoch 0, gen_loss = 0.44556083829007687, disc_loss = 0.19002994598651474
Trained batch 374 in epoch 0, gen_loss = 0.445724063873291, disc_loss = 0.1899032204002142
Trained batch 375 in epoch 0, gen_loss = 0.4455274866616472, disc_loss = 0.18968443467995114
Trained batch 376 in epoch 0, gen_loss = 0.44529593228029, disc_loss = 0.18948814223967592
Trained batch 377 in epoch 0, gen_loss = 0.44500674520220074, disc_loss = 0.18952433534814095
Trained batch 378 in epoch 0, gen_loss = 0.4449593151936745, disc_loss = 0.18979355691389074
Trained batch 379 in epoch 0, gen_loss = 0.44478159060603695, disc_loss = 0.18981654869980719
Trained batch 380 in epoch 0, gen_loss = 0.44483452245319294, disc_loss = 0.18963744499649746
Trained batch 381 in epoch 0, gen_loss = 0.4445237280186558, disc_loss = 0.18955354231131794
Trained batch 382 in epoch 0, gen_loss = 0.44453203872663233, disc_loss = 0.18942711728457215
Trained batch 383 in epoch 0, gen_loss = 0.4445470836944878, disc_loss = 0.1892100259089299
Trained batch 384 in epoch 0, gen_loss = 0.4443785970087175, disc_loss = 0.18895487302019223
Trained batch 385 in epoch 0, gen_loss = 0.444390729224126, disc_loss = 0.18888696924411724
Trained batch 386 in epoch 0, gen_loss = 0.44412669231417257, disc_loss = 0.1889637805357845
Trained batch 387 in epoch 0, gen_loss = 0.4438412055065951, disc_loss = 0.18903245036154218
Trained batch 388 in epoch 0, gen_loss = 0.443870366155948, disc_loss = 0.18906725058691207
Trained batch 389 in epoch 0, gen_loss = 0.44366639585067064, disc_loss = 0.1889340496263825
Trained batch 390 in epoch 0, gen_loss = 0.4435763424619689, disc_loss = 0.1886784115191692
Trained batch 391 in epoch 0, gen_loss = 0.44356020083841013, disc_loss = 0.18869401121569074
Trained batch 392 in epoch 0, gen_loss = 0.4436586048766857, disc_loss = 0.18845742344192726
Trained batch 393 in epoch 0, gen_loss = 0.4437370905416266, disc_loss = 0.18851372443120643
Trained batch 394 in epoch 0, gen_loss = 0.4435425999798352, disc_loss = 0.18836746361531034
Trained batch 395 in epoch 0, gen_loss = 0.443424103311216, disc_loss = 0.1881392798950952
Trained batch 396 in epoch 0, gen_loss = 0.4431840696322828, disc_loss = 0.18814538282715254
Trained batch 397 in epoch 0, gen_loss = 0.4428977395721416, disc_loss = 0.1880434239189604
Trained batch 398 in epoch 0, gen_loss = 0.44283802840942726, disc_loss = 0.18783840703728952
Trained batch 399 in epoch 0, gen_loss = 0.44273387171328066, disc_loss = 0.1878801299119368
Trained batch 400 in epoch 0, gen_loss = 0.442498979202827, disc_loss = 0.18772452012949306
Trained batch 401 in epoch 0, gen_loss = 0.4425434344146975, disc_loss = 0.18771001109529045
Trained batch 402 in epoch 0, gen_loss = 0.4425458139728376, disc_loss = 0.187868313281508
Trained batch 403 in epoch 0, gen_loss = 0.4425958336727454, disc_loss = 0.18784922994396622
Trained batch 404 in epoch 0, gen_loss = 0.4422819275179027, disc_loss = 0.18778686316017015
Trained batch 405 in epoch 0, gen_loss = 0.4421061232612638, disc_loss = 0.18806228040272527
Trained batch 406 in epoch 0, gen_loss = 0.4420143541598496, disc_loss = 0.1882425452049373
Trained batch 407 in epoch 0, gen_loss = 0.4420557530487285, disc_loss = 0.1880627007944984
Trained batch 408 in epoch 0, gen_loss = 0.4420860237043469, disc_loss = 0.1880086193357601
Trained batch 409 in epoch 0, gen_loss = 0.44195261067006647, disc_loss = 0.1880631696932563
Trained batch 410 in epoch 0, gen_loss = 0.4418829340859341, disc_loss = 0.18801011341349777
Trained batch 411 in epoch 0, gen_loss = 0.4417484069912179, disc_loss = 0.18801320579752906
Trained batch 412 in epoch 0, gen_loss = 0.44172367063907964, disc_loss = 0.1879773891551226
Trained batch 413 in epoch 0, gen_loss = 0.4416303158094342, disc_loss = 0.187834481726702
Trained batch 414 in epoch 0, gen_loss = 0.44141046555645497, disc_loss = 0.18761852617454097
Trained batch 415 in epoch 0, gen_loss = 0.4414168225171474, disc_loss = 0.18736601517482016
Trained batch 416 in epoch 0, gen_loss = 0.44139641523361206, disc_loss = 0.18719394362533837
Trained batch 417 in epoch 0, gen_loss = 0.4415160074616163, disc_loss = 0.18713958408576592
Trained batch 418 in epoch 0, gen_loss = 0.4412047594856818, disc_loss = 0.18695172162944348
Trained batch 419 in epoch 0, gen_loss = 0.44089527868089223, disc_loss = 0.18694284441659137
Trained batch 420 in epoch 0, gen_loss = 0.4410593409153175, disc_loss = 0.18708535052411204
Trained batch 421 in epoch 0, gen_loss = 0.44090439852380076, disc_loss = 0.18715937280700812
Trained batch 422 in epoch 0, gen_loss = 0.44091258094102215, disc_loss = 0.18700795751461324
Trained batch 423 in epoch 0, gen_loss = 0.4407881908118725, disc_loss = 0.18677335793486322
Trained batch 424 in epoch 0, gen_loss = 0.440628587919123, disc_loss = 0.1865254198146217
Trained batch 425 in epoch 0, gen_loss = 0.44049920323589037, disc_loss = 0.1865694120290204
Trained batch 426 in epoch 0, gen_loss = 0.44056379027333137, disc_loss = 0.18668450091025449
Trained batch 427 in epoch 0, gen_loss = 0.4403728411019405, disc_loss = 0.18667511997535546
Trained batch 428 in epoch 0, gen_loss = 0.44049981486547246, disc_loss = 0.18649137145589975
Trained batch 429 in epoch 0, gen_loss = 0.4406182037536488, disc_loss = 0.1863686819799071
Trained batch 430 in epoch 0, gen_loss = 0.44077046668446535, disc_loss = 0.18632914458256725
Trained batch 431 in epoch 0, gen_loss = 0.44079352922185705, disc_loss = 0.18624667465014177
Trained batch 432 in epoch 0, gen_loss = 0.4407347085569527, disc_loss = 0.18614669416452528
Trained batch 433 in epoch 0, gen_loss = 0.4408118171351297, disc_loss = 0.18605368505854347
Trained batch 434 in epoch 0, gen_loss = 0.4407944712145575, disc_loss = 0.18598023828161858
Trained batch 435 in epoch 0, gen_loss = 0.4409735447496449, disc_loss = 0.1860422999598086
Trained batch 436 in epoch 0, gen_loss = 0.4410348412510459, disc_loss = 0.18608546475677387
Trained batch 437 in epoch 0, gen_loss = 0.4409985840320587, disc_loss = 0.18611934305206962
Trained batch 438 in epoch 0, gen_loss = 0.4408872094947276, disc_loss = 0.18595365326690375
Trained batch 439 in epoch 0, gen_loss = 0.4408061012625694, disc_loss = 0.1857591029298915
Trained batch 440 in epoch 0, gen_loss = 0.44081264315278623, disc_loss = 0.1854708377069154
Trained batch 441 in epoch 0, gen_loss = 0.4406406588144432, disc_loss = 0.18546414987618162
Trained batch 442 in epoch 0, gen_loss = 0.4406512786653187, disc_loss = 0.18583636768330436
Trained batch 443 in epoch 0, gen_loss = 0.44054558101269575, disc_loss = 0.18575426367707215
Trained batch 444 in epoch 0, gen_loss = 0.4405236523472861, disc_loss = 0.18569648545863254
Trained batch 445 in epoch 0, gen_loss = 0.4405325808867211, disc_loss = 0.18570427632067904
Trained batch 446 in epoch 0, gen_loss = 0.44046758351976706, disc_loss = 0.18564769341058246
Trained batch 447 in epoch 0, gen_loss = 0.44035002855317934, disc_loss = 0.18558027853474154
Trained batch 448 in epoch 0, gen_loss = 0.4405303239025889, disc_loss = 0.1854626235898526
Trained batch 449 in epoch 0, gen_loss = 0.44045171909862096, disc_loss = 0.18543981686648395
Trained batch 450 in epoch 0, gen_loss = 0.4405486152864613, disc_loss = 0.18527451962513433
Trained batch 451 in epoch 0, gen_loss = 0.44073391936521616, disc_loss = 0.18496929201816695
Trained batch 452 in epoch 0, gen_loss = 0.44089171389080833, disc_loss = 0.1848005253788717
Trained batch 453 in epoch 0, gen_loss = 0.44079469643237834, disc_loss = 0.1846545233969712
Trained batch 454 in epoch 0, gen_loss = 0.4408163492496197, disc_loss = 0.18435340604366182
Trained batch 455 in epoch 0, gen_loss = 0.44069802342799674, disc_loss = 0.18443561255882837
Trained batch 456 in epoch 0, gen_loss = 0.44076351987715623, disc_loss = 0.1848826732046299
Trained batch 457 in epoch 0, gen_loss = 0.4407519182784068, disc_loss = 0.1846450154576044
Trained batch 458 in epoch 0, gen_loss = 0.44062256403997835, disc_loss = 0.18541381586432326
Trained batch 459 in epoch 0, gen_loss = 0.44066065776607266, disc_loss = 0.18546249955973548
Trained batch 460 in epoch 0, gen_loss = 0.44071999250420263, disc_loss = 0.1857444593428337
Trained batch 461 in epoch 0, gen_loss = 0.4405730077069559, disc_loss = 0.18606366970661012
Trained batch 462 in epoch 0, gen_loss = 0.44046507676013347, disc_loss = 0.18617200084255917
Trained batch 463 in epoch 0, gen_loss = 0.44059845079378834, disc_loss = 0.18622382966689124
Trained batch 464 in epoch 0, gen_loss = 0.4405805075681338, disc_loss = 0.18613762283918037
Trained batch 465 in epoch 0, gen_loss = 0.44052389001897474, disc_loss = 0.18600729224971563
Trained batch 466 in epoch 0, gen_loss = 0.4405122823071939, disc_loss = 0.18588760079181807
Trained batch 467 in epoch 0, gen_loss = 0.4405819695347395, disc_loss = 0.1857921664093613
Trained batch 468 in epoch 0, gen_loss = 0.4404554954215662, disc_loss = 0.18571977106445253
Trained batch 469 in epoch 0, gen_loss = 0.4403896130145864, disc_loss = 0.18557619131071137
Trained batch 470 in epoch 0, gen_loss = 0.440332276742676, disc_loss = 0.1854319661863607
Trained batch 471 in epoch 0, gen_loss = 0.44013562413342927, disc_loss = 0.1853632421067016
Trained batch 472 in epoch 0, gen_loss = 0.4401336599606036, disc_loss = 0.18525481449703965
Trained batch 473 in epoch 0, gen_loss = 0.4401563131859534, disc_loss = 0.1852531990680828
Trained batch 474 in epoch 0, gen_loss = 0.4401081915905601, disc_loss = 0.18513099123380686
Trained batch 475 in epoch 0, gen_loss = 0.4400228140484385, disc_loss = 0.18497660661022328
Trained batch 476 in epoch 0, gen_loss = 0.43993433866360904, disc_loss = 0.18489049770625257
Trained batch 477 in epoch 0, gen_loss = 0.4401220479769687, disc_loss = 0.18483729584524447
Trained batch 478 in epoch 0, gen_loss = 0.4399692424279414, disc_loss = 0.18461255410721134
Trained batch 479 in epoch 0, gen_loss = 0.4399725436543425, disc_loss = 0.18448300470675652
Trained batch 480 in epoch 0, gen_loss = 0.43995001918312915, disc_loss = 0.1843169088709689
Trained batch 481 in epoch 0, gen_loss = 0.4397182849185595, disc_loss = 0.18447932125266286
Trained batch 482 in epoch 0, gen_loss = 0.439572867276012, disc_loss = 0.18504446344238012
Trained batch 483 in epoch 0, gen_loss = 0.43972599986663535, disc_loss = 0.18520760339538545
Trained batch 484 in epoch 0, gen_loss = 0.43972001530460475, disc_loss = 0.18522734888205208
Trained batch 485 in epoch 0, gen_loss = 0.43963701648967257, disc_loss = 0.18518215304800145
Trained batch 486 in epoch 0, gen_loss = 0.43958170476390596, disc_loss = 0.18509326064748807
Trained batch 487 in epoch 0, gen_loss = 0.4397674772705211, disc_loss = 0.18501765522571495
Trained batch 488 in epoch 0, gen_loss = 0.43953980989982744, disc_loss = 0.1848746078824034
Trained batch 489 in epoch 0, gen_loss = 0.4394745846183933, disc_loss = 0.18493295727411704
Trained batch 490 in epoch 0, gen_loss = 0.439315347710355, disc_loss = 0.1848844966743058
Trained batch 491 in epoch 0, gen_loss = 0.439448738485817, disc_loss = 0.18494853533698413
Trained batch 492 in epoch 0, gen_loss = 0.43943135122982047, disc_loss = 0.18485933810124897
Trained batch 493 in epoch 0, gen_loss = 0.4393872359262304, disc_loss = 0.18481382234813834
Trained batch 494 in epoch 0, gen_loss = 0.4393459420011501, disc_loss = 0.18469514809548854
Trained batch 495 in epoch 0, gen_loss = 0.43916883710170945, disc_loss = 0.1846100711000843
Trained batch 496 in epoch 0, gen_loss = 0.4391320901857296, disc_loss = 0.18441460280486155
Trained batch 497 in epoch 0, gen_loss = 0.43916568351557933, disc_loss = 0.18416632704780883
Trained batch 498 in epoch 0, gen_loss = 0.43914789905051194, disc_loss = 0.18411308143638777
Trained batch 499 in epoch 0, gen_loss = 0.4392065367102623, disc_loss = 0.18422241436317563
Trained batch 500 in epoch 0, gen_loss = 0.43923307250359817, disc_loss = 0.18437740253191628
Trained batch 501 in epoch 0, gen_loss = 0.43904977288854075, disc_loss = 0.1843296242729423
Trained batch 502 in epoch 0, gen_loss = 0.43907147906646576, disc_loss = 0.1840615663010901
Trained batch 503 in epoch 0, gen_loss = 0.4389309118546191, disc_loss = 0.18395143457954483
Trained batch 504 in epoch 0, gen_loss = 0.43881274963369465, disc_loss = 0.1839708180747705
Trained batch 505 in epoch 0, gen_loss = 0.43895103579217737, disc_loss = 0.18388152376126513
Trained batch 506 in epoch 0, gen_loss = 0.4390263174177392, disc_loss = 0.18368032613229116
Trained batch 507 in epoch 0, gen_loss = 0.43893160770727896, disc_loss = 0.1836200249748026
Trained batch 508 in epoch 0, gen_loss = 0.43908000308544554, disc_loss = 0.18346416694432321
Trained batch 509 in epoch 0, gen_loss = 0.43916879138525794, disc_loss = 0.1833057236035957
Trained batch 510 in epoch 0, gen_loss = 0.43919251558831995, disc_loss = 0.18310374118125253
Trained batch 511 in epoch 0, gen_loss = 0.439239026629366, disc_loss = 0.18289040628951625
Trained batch 512 in epoch 0, gen_loss = 0.43910277877402354, disc_loss = 0.18287341114039193
Trained batch 513 in epoch 0, gen_loss = 0.43897321547747586, disc_loss = 0.1828801804747621
Trained batch 514 in epoch 0, gen_loss = 0.4390602899407878, disc_loss = 0.1827879970839012
Trained batch 515 in epoch 0, gen_loss = 0.4390186304154322, disc_loss = 0.18272470154748985
Trained batch 516 in epoch 0, gen_loss = 0.43889425853465464, disc_loss = 0.18256227436116979
Trained batch 517 in epoch 0, gen_loss = 0.43878069773143785, disc_loss = 0.18249090433365245
Trained batch 518 in epoch 0, gen_loss = 0.4388411228252514, disc_loss = 0.1823050744996652
Trained batch 519 in epoch 0, gen_loss = 0.43872339931818155, disc_loss = 0.18216807051705053
Trained batch 520 in epoch 0, gen_loss = 0.4386568773044506, disc_loss = 0.18200465911309344
Trained batch 521 in epoch 0, gen_loss = 0.4387251146680094, disc_loss = 0.18183494062730293
Trained batch 522 in epoch 0, gen_loss = 0.4388252836340472, disc_loss = 0.18164729948438718
Trained batch 523 in epoch 0, gen_loss = 0.4386761678197912, disc_loss = 0.18141804564075956
Trained batch 524 in epoch 0, gen_loss = 0.4387208694503421, disc_loss = 0.1811812973128898
Trained batch 525 in epoch 0, gen_loss = 0.4387240983234159, disc_loss = 0.18105415737490124
Trained batch 526 in epoch 0, gen_loss = 0.4387066649870357, disc_loss = 0.18084644716749043
Trained batch 527 in epoch 0, gen_loss = 0.43865224956111476, disc_loss = 0.18069335878615014
Trained batch 528 in epoch 0, gen_loss = 0.4386895397547738, disc_loss = 0.18048486728678917
Trained batch 529 in epoch 0, gen_loss = 0.43878730271222455, disc_loss = 0.1801860851956145
Trained batch 530 in epoch 0, gen_loss = 0.4387858215361665, disc_loss = 0.179907442482711
Trained batch 531 in epoch 0, gen_loss = 0.438788766139432, disc_loss = 0.17960906895647819
Trained batch 532 in epoch 0, gen_loss = 0.43864484564672046, disc_loss = 0.1794201675068594
Trained batch 533 in epoch 0, gen_loss = 0.4388245497080271, disc_loss = 0.17938668022720555
Trained batch 534 in epoch 0, gen_loss = 0.43904015371732624, disc_loss = 0.17909076638241236
Trained batch 535 in epoch 0, gen_loss = 0.4390725023599703, disc_loss = 0.17885273352001252
Trained batch 536 in epoch 0, gen_loss = 0.4392010584556857, disc_loss = 0.1785731610410207
Trained batch 537 in epoch 0, gen_loss = 0.4391925524934074, disc_loss = 0.17827081343775344
Trained batch 538 in epoch 0, gen_loss = 0.43926534311006155, disc_loss = 0.17798980121226057
Trained batch 539 in epoch 0, gen_loss = 0.43949559645520314, disc_loss = 0.17770235820983846
Trained batch 540 in epoch 0, gen_loss = 0.4396788570995472, disc_loss = 0.17742173828170832
Trained batch 541 in epoch 0, gen_loss = 0.4398404245996827, disc_loss = 0.17718697532434086
Trained batch 542 in epoch 0, gen_loss = 0.4398454481505996, disc_loss = 0.17697490663241944
Trained batch 543 in epoch 0, gen_loss = 0.43979935956132765, disc_loss = 0.17678349505534724
Trained batch 544 in epoch 0, gen_loss = 0.43982197024406644, disc_loss = 0.17655323432126177
Trained batch 545 in epoch 0, gen_loss = 0.4398301554905189, disc_loss = 0.1762622236461812
Trained batch 546 in epoch 0, gen_loss = 0.43981418618336454, disc_loss = 0.17600936681999257
Trained batch 547 in epoch 0, gen_loss = 0.4398737641690421, disc_loss = 0.17573921702951736
Trained batch 548 in epoch 0, gen_loss = 0.44014832952852023, disc_loss = 0.17559953746072038
Trained batch 549 in epoch 0, gen_loss = 0.4400678901238875, disc_loss = 0.1756104220145128
Trained batch 550 in epoch 0, gen_loss = 0.43998318023560484, disc_loss = 0.1761768093119678
Trained batch 551 in epoch 0, gen_loss = 0.44002931543450424, disc_loss = 0.17598421334127046
Trained batch 552 in epoch 0, gen_loss = 0.4399781776811072, disc_loss = 0.17597984143652384
Trained batch 553 in epoch 0, gen_loss = 0.44014879770657644, disc_loss = 0.17577474907591992
Trained batch 554 in epoch 0, gen_loss = 0.44014617279843166, disc_loss = 0.17599268589537959
Trained batch 555 in epoch 0, gen_loss = 0.43999266747733673, disc_loss = 0.17608632931566173
Trained batch 556 in epoch 0, gen_loss = 0.44001216991157466, disc_loss = 0.17605934832813602
Trained batch 557 in epoch 0, gen_loss = 0.43994899062059256, disc_loss = 0.17608358710002836
Trained batch 558 in epoch 0, gen_loss = 0.4399161659221103, disc_loss = 0.17595623003415536
Trained batch 559 in epoch 0, gen_loss = 0.4398326369800738, disc_loss = 0.17599609506516053
Trained batch 560 in epoch 0, gen_loss = 0.4396898346470002, disc_loss = 0.1758687229538187
Trained batch 561 in epoch 0, gen_loss = 0.439636523772389, disc_loss = 0.17583140797475585
Trained batch 562 in epoch 0, gen_loss = 0.4395991092676803, disc_loss = 0.17569737280942302
Trained batch 563 in epoch 0, gen_loss = 0.4395476276887224, disc_loss = 0.1755411624413063
Trained batch 564 in epoch 0, gen_loss = 0.43955293656450456, disc_loss = 0.17530554402125093
Trained batch 565 in epoch 0, gen_loss = 0.4395308796803437, disc_loss = 0.17514640407129964
Trained batch 566 in epoch 0, gen_loss = 0.43938838689205295, disc_loss = 0.17506217639531935
Trained batch 567 in epoch 0, gen_loss = 0.43960089876618186, disc_loss = 0.17519038913994503
Trained batch 568 in epoch 0, gen_loss = 0.4394692788015141, disc_loss = 0.1751686293068743
Trained batch 569 in epoch 0, gen_loss = 0.4393923049956037, disc_loss = 0.17515120096831469
Trained batch 570 in epoch 0, gen_loss = 0.43930997108411035, disc_loss = 0.1752829915842273
Trained batch 571 in epoch 0, gen_loss = 0.4393034857678247, disc_loss = 0.17522744658253306
Trained batch 572 in epoch 0, gen_loss = 0.43938440640975457, disc_loss = 0.1752576632018853
Trained batch 573 in epoch 0, gen_loss = 0.43923303152625987, disc_loss = 0.17524982366762823
Trained batch 574 in epoch 0, gen_loss = 0.4391964176426763, disc_loss = 0.17526700134834516
Trained batch 575 in epoch 0, gen_loss = 0.4390203882422712, disc_loss = 0.1751806888205465
Trained batch 576 in epoch 0, gen_loss = 0.43907646579180476, disc_loss = 0.1750078513876146
Trained batch 577 in epoch 0, gen_loss = 0.4389957351461826, disc_loss = 0.17506994328632383
Trained batch 578 in epoch 0, gen_loss = 0.4390906407940161, disc_loss = 0.1750952281373101
Trained batch 579 in epoch 0, gen_loss = 0.43920239749653583, disc_loss = 0.17492596486197978
Trained batch 580 in epoch 0, gen_loss = 0.4391715414757983, disc_loss = 0.17500207592090417
Trained batch 581 in epoch 0, gen_loss = 0.4392293908751707, disc_loss = 0.17485020066134607
Trained batch 582 in epoch 0, gen_loss = 0.43926140292839977, disc_loss = 0.17486849015396516
Trained batch 583 in epoch 0, gen_loss = 0.4392757900569537, disc_loss = 0.1747351562291741
Trained batch 584 in epoch 0, gen_loss = 0.4392654741931165, disc_loss = 0.17462303589742917
Trained batch 585 in epoch 0, gen_loss = 0.4391353538215364, disc_loss = 0.1745340219657525
Trained batch 586 in epoch 0, gen_loss = 0.43919907832673705, disc_loss = 0.17448063034507139
Trained batch 587 in epoch 0, gen_loss = 0.4390835345399623, disc_loss = 0.1742952650469937
Trained batch 588 in epoch 0, gen_loss = 0.4391167043931213, disc_loss = 0.1742056049311657
Trained batch 589 in epoch 0, gen_loss = 0.4390716787111961, disc_loss = 0.174117296097516
Trained batch 590 in epoch 0, gen_loss = 0.4391206196318625, disc_loss = 0.17415842789267827
Trained batch 591 in epoch 0, gen_loss = 0.4389809428437336, disc_loss = 0.1741688729710625
Trained batch 592 in epoch 0, gen_loss = 0.43896311561735646, disc_loss = 0.17422259278268779
Trained batch 593 in epoch 0, gen_loss = 0.43877814022780265, disc_loss = 0.1742604706241978
Trained batch 594 in epoch 0, gen_loss = 0.43880862819046534, disc_loss = 0.17416655623800115
Trained batch 595 in epoch 0, gen_loss = 0.438790039678148, disc_loss = 0.17415140681406296
Trained batch 596 in epoch 0, gen_loss = 0.4387309295647907, disc_loss = 0.1740190381748942
Trained batch 597 in epoch 0, gen_loss = 0.43878013329163046, disc_loss = 0.17395621934052197
Trained batch 598 in epoch 0, gen_loss = 0.4387139506849502, disc_loss = 0.17420724912146993
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.38529977202415466, disc_loss = 0.09439084678888321
Trained batch 1 in epoch 1, gen_loss = 0.43731535971164703, disc_loss = 0.10647067800164223
Trained batch 2 in epoch 1, gen_loss = 0.4222654600938161, disc_loss = 0.13634975999593735
Trained batch 3 in epoch 1, gen_loss = 0.41545524448156357, disc_loss = 0.1393160205334425
Trained batch 4 in epoch 1, gen_loss = 0.41961886286735534, disc_loss = 0.12930669635534286
Trained batch 5 in epoch 1, gen_loss = 0.4279578278462092, disc_loss = 0.12471177304784457
Trained batch 6 in epoch 1, gen_loss = 0.4237723435674395, disc_loss = 0.1145264623420579
Trained batch 7 in epoch 1, gen_loss = 0.42539825662970543, disc_loss = 0.10757729969918728
Trained batch 8 in epoch 1, gen_loss = 0.4310539662837982, disc_loss = 0.1038407873776224
Trained batch 9 in epoch 1, gen_loss = 0.43368848860263826, disc_loss = 0.1067351184785366
Trained batch 10 in epoch 1, gen_loss = 0.44363321228460834, disc_loss = 0.11093117770823566
Trained batch 11 in epoch 1, gen_loss = 0.4402964984377225, disc_loss = 0.1138228780279557
Trained batch 12 in epoch 1, gen_loss = 0.4442008321101849, disc_loss = 0.11631918927797905
Trained batch 13 in epoch 1, gen_loss = 0.44707617802279337, disc_loss = 0.12329805376274246
Trained batch 14 in epoch 1, gen_loss = 0.4415999988714854, disc_loss = 0.12605153967936833
Trained batch 15 in epoch 1, gen_loss = 0.4385831020772457, disc_loss = 0.12863949267193675
Trained batch 16 in epoch 1, gen_loss = 0.43650410105200377, disc_loss = 0.12922036603969686
Trained batch 17 in epoch 1, gen_loss = 0.43430464300844407, disc_loss = 0.12652904581692484
Trained batch 18 in epoch 1, gen_loss = 0.43571273119826065, disc_loss = 0.12544236959595428
Trained batch 19 in epoch 1, gen_loss = 0.43380325436592104, disc_loss = 0.12379227094352245
Trained batch 20 in epoch 1, gen_loss = 0.4391857981681824, disc_loss = 0.12382973907958894
Trained batch 21 in epoch 1, gen_loss = 0.4361494075168263, disc_loss = 0.13080031187696892
Trained batch 22 in epoch 1, gen_loss = 0.4373999134353969, disc_loss = 0.12710250962687575
Trained batch 23 in epoch 1, gen_loss = 0.438622551659743, disc_loss = 0.12894020462408662
Trained batch 24 in epoch 1, gen_loss = 0.43459652304649354, disc_loss = 0.12783039823174477
Trained batch 25 in epoch 1, gen_loss = 0.43428899347782135, disc_loss = 0.12835721800533625
Trained batch 26 in epoch 1, gen_loss = 0.4324571865576285, disc_loss = 0.12654714134556275
Trained batch 27 in epoch 1, gen_loss = 0.43209831203733173, disc_loss = 0.12476902388568435
Trained batch 28 in epoch 1, gen_loss = 0.4312419017841076, disc_loss = 0.12266385825029735
Trained batch 29 in epoch 1, gen_loss = 0.4289129277070363, disc_loss = 0.12221756043533484
Trained batch 30 in epoch 1, gen_loss = 0.43229745664904196, disc_loss = 0.1219433431904162
Trained batch 31 in epoch 1, gen_loss = 0.4315794864669442, disc_loss = 0.12078074447344989
Trained batch 32 in epoch 1, gen_loss = 0.43248094753785565, disc_loss = 0.12006120056365475
Trained batch 33 in epoch 1, gen_loss = 0.4339100920102176, disc_loss = 0.11985624241916572
Trained batch 34 in epoch 1, gen_loss = 0.43447489993912836, disc_loss = 0.11938905769160815
Trained batch 35 in epoch 1, gen_loss = 0.4343380464447869, disc_loss = 0.11924497772836024
Trained batch 36 in epoch 1, gen_loss = 0.4344986902700888, disc_loss = 0.11852700434423782
Trained batch 37 in epoch 1, gen_loss = 0.43368149352701085, disc_loss = 0.11673080842745931
Trained batch 38 in epoch 1, gen_loss = 0.4350065520176521, disc_loss = 0.11478143787154785
Trained batch 39 in epoch 1, gen_loss = 0.4359087385237217, disc_loss = 0.11425392860546708
Trained batch 40 in epoch 1, gen_loss = 0.4350536727323765, disc_loss = 0.11322110482468838
Trained batch 41 in epoch 1, gen_loss = 0.43666193456876845, disc_loss = 0.11299263978643077
Trained batch 42 in epoch 1, gen_loss = 0.4379183622293694, disc_loss = 0.11084981362313726
Trained batch 43 in epoch 1, gen_loss = 0.43609851463274524, disc_loss = 0.11216603316874667
Trained batch 44 in epoch 1, gen_loss = 0.4382742140028212, disc_loss = 0.11676112309926086
Trained batch 45 in epoch 1, gen_loss = 0.4350112709014312, disc_loss = 0.11874610408330741
Trained batch 46 in epoch 1, gen_loss = 0.4344352458385711, disc_loss = 0.1186883208203189
Trained batch 47 in epoch 1, gen_loss = 0.4345586374402046, disc_loss = 0.11924241168890148
Trained batch 48 in epoch 1, gen_loss = 0.435039396188697, disc_loss = 0.11954993005765945
Trained batch 49 in epoch 1, gen_loss = 0.43604631364345553, disc_loss = 0.11970859613269567
Trained batch 50 in epoch 1, gen_loss = 0.43536577797403525, disc_loss = 0.12075463255100391
Trained batch 51 in epoch 1, gen_loss = 0.4353575866955977, disc_loss = 0.12192710428140484
Trained batch 52 in epoch 1, gen_loss = 0.4337934266846135, disc_loss = 0.12420849920303192
Trained batch 53 in epoch 1, gen_loss = 0.4334414297783816, disc_loss = 0.12390869521294479
Trained batch 54 in epoch 1, gen_loss = 0.4329901911995628, disc_loss = 0.12697971730747007
Trained batch 55 in epoch 1, gen_loss = 0.43126762019736425, disc_loss = 0.12823105147773667
Trained batch 56 in epoch 1, gen_loss = 0.4301938095636535, disc_loss = 0.12892075480991289
Trained batch 57 in epoch 1, gen_loss = 0.43122987140869273, disc_loss = 0.13351945010624056
Trained batch 58 in epoch 1, gen_loss = 0.43210747736995503, disc_loss = 0.1347887586423401
Trained batch 59 in epoch 1, gen_loss = 0.4320266534884771, disc_loss = 0.13366009887928765
Trained batch 60 in epoch 1, gen_loss = 0.43174673055039076, disc_loss = 0.1348833265546404
Trained batch 61 in epoch 1, gen_loss = 0.4310866546246313, disc_loss = 0.13602432797873212
Trained batch 62 in epoch 1, gen_loss = 0.43015873101022506, disc_loss = 0.13513759201362965
Trained batch 63 in epoch 1, gen_loss = 0.4294301983900368, disc_loss = 0.1347388234862592
Trained batch 64 in epoch 1, gen_loss = 0.4300354838371277, disc_loss = 0.13511668681525268
Trained batch 65 in epoch 1, gen_loss = 0.4304416978901083, disc_loss = 0.1344595651678515
Trained batch 66 in epoch 1, gen_loss = 0.4310368766535574, disc_loss = 0.13445423952123123
Trained batch 67 in epoch 1, gen_loss = 0.43111896383411746, disc_loss = 0.13420602490248926
Trained batch 68 in epoch 1, gen_loss = 0.4310779640640038, disc_loss = 0.13506197548754836
Trained batch 69 in epoch 1, gen_loss = 0.4309535473585129, disc_loss = 0.13416856854621853
Trained batch 70 in epoch 1, gen_loss = 0.43166362735587105, disc_loss = 0.13448702079624358
Trained batch 71 in epoch 1, gen_loss = 0.4307629954483774, disc_loss = 0.13525247312564817
Trained batch 72 in epoch 1, gen_loss = 0.4305131557869585, disc_loss = 0.13542963898651403
Trained batch 73 in epoch 1, gen_loss = 0.4316661760613725, disc_loss = 0.1343523183636166
Trained batch 74 in epoch 1, gen_loss = 0.4305349159240723, disc_loss = 0.13409901035328706
Trained batch 75 in epoch 1, gen_loss = 0.43024854754146774, disc_loss = 0.13380073346687774
Trained batch 76 in epoch 1, gen_loss = 0.43044473675938394, disc_loss = 0.13541965846988288
Trained batch 77 in epoch 1, gen_loss = 0.42878933785817563, disc_loss = 0.13648260635538742
Trained batch 78 in epoch 1, gen_loss = 0.4299448211736317, disc_loss = 0.1360341070243452
Trained batch 79 in epoch 1, gen_loss = 0.43028913959860804, disc_loss = 0.13481630117166787
Trained batch 80 in epoch 1, gen_loss = 0.42985331975383523, disc_loss = 0.13506709970533848
Trained batch 81 in epoch 1, gen_loss = 0.43047897081549574, disc_loss = 0.134583657584721
Trained batch 82 in epoch 1, gen_loss = 0.4302672646849988, disc_loss = 0.13368525874453135
Trained batch 83 in epoch 1, gen_loss = 0.430390603130772, disc_loss = 0.13398867515137508
Trained batch 84 in epoch 1, gen_loss = 0.4307798091103049, disc_loss = 0.1333397359313334
Trained batch 85 in epoch 1, gen_loss = 0.4319209033666655, disc_loss = 0.1334042884192841
Trained batch 86 in epoch 1, gen_loss = 0.43146592652660676, disc_loss = 0.13244161949674974
Trained batch 87 in epoch 1, gen_loss = 0.43063292652368546, disc_loss = 0.1315770763692192
Trained batch 88 in epoch 1, gen_loss = 0.43144075321347525, disc_loss = 0.1305878698365407
Trained batch 89 in epoch 1, gen_loss = 0.43120747407277427, disc_loss = 0.13088754798389143
Trained batch 90 in epoch 1, gen_loss = 0.4322144415352371, disc_loss = 0.13243941604517973
Trained batch 91 in epoch 1, gen_loss = 0.43219838259012805, disc_loss = 0.1320105855272192
Trained batch 92 in epoch 1, gen_loss = 0.4317353601737689, disc_loss = 0.13214769040144259
Trained batch 93 in epoch 1, gen_loss = 0.43172114231485004, disc_loss = 0.1319960812503036
Trained batch 94 in epoch 1, gen_loss = 0.4322812281156841, disc_loss = 0.13166408399610144
Trained batch 95 in epoch 1, gen_loss = 0.4314993619918823, disc_loss = 0.13264003491106754
Trained batch 96 in epoch 1, gen_loss = 0.4317810560010143, disc_loss = 0.13186678572644278
Trained batch 97 in epoch 1, gen_loss = 0.4329548599768658, disc_loss = 0.1324081679958166
Trained batch 98 in epoch 1, gen_loss = 0.4329802225334476, disc_loss = 0.131958890273565
Trained batch 99 in epoch 1, gen_loss = 0.4325415202975273, disc_loss = 0.13171201614663006
Trained batch 100 in epoch 1, gen_loss = 0.4330913946770205, disc_loss = 0.1322047648269056
Trained batch 101 in epoch 1, gen_loss = 0.43302900680139955, disc_loss = 0.1318370737683247
Trained batch 102 in epoch 1, gen_loss = 0.4327093212349901, disc_loss = 0.13115228092279826
Trained batch 103 in epoch 1, gen_loss = 0.4330043342824166, disc_loss = 0.13092868698116106
Trained batch 104 in epoch 1, gen_loss = 0.4329352486701239, disc_loss = 0.13077339255029247
Trained batch 105 in epoch 1, gen_loss = 0.433403232749903, disc_loss = 0.13086588816049527
Trained batch 106 in epoch 1, gen_loss = 0.4327224052955057, disc_loss = 0.1303399065422399
Trained batch 107 in epoch 1, gen_loss = 0.4325877309397415, disc_loss = 0.13063447682738857
Trained batch 108 in epoch 1, gen_loss = 0.4324381786202072, disc_loss = 0.1311064798111489
Trained batch 109 in epoch 1, gen_loss = 0.4325237959623337, disc_loss = 0.1304873813451691
Trained batch 110 in epoch 1, gen_loss = 0.43166006255794215, disc_loss = 0.13081640302128084
Trained batch 111 in epoch 1, gen_loss = 0.4319186351661171, disc_loss = 0.1303044191860993
Trained batch 112 in epoch 1, gen_loss = 0.4327408753137673, disc_loss = 0.12956156593178753
Trained batch 113 in epoch 1, gen_loss = 0.43249272803465527, disc_loss = 0.12872788269203483
Trained batch 114 in epoch 1, gen_loss = 0.4316012872302014, disc_loss = 0.12824996105678704
Trained batch 115 in epoch 1, gen_loss = 0.43099234741309594, disc_loss = 0.12764112386402898
Trained batch 116 in epoch 1, gen_loss = 0.4308538890292502, disc_loss = 0.12892640800748625
Trained batch 117 in epoch 1, gen_loss = 0.4309045970439911, disc_loss = 0.12919484828677724
Trained batch 118 in epoch 1, gen_loss = 0.4310780322852255, disc_loss = 0.12945361790724663
Trained batch 119 in epoch 1, gen_loss = 0.43072743266820906, disc_loss = 0.1290775575209409
Trained batch 120 in epoch 1, gen_loss = 0.4307633007853484, disc_loss = 0.12867055456192533
Trained batch 121 in epoch 1, gen_loss = 0.43106378517189964, disc_loss = 0.12823652034839156
Trained batch 122 in epoch 1, gen_loss = 0.4310289337867644, disc_loss = 0.12816960520557757
Trained batch 123 in epoch 1, gen_loss = 0.43171705281542194, disc_loss = 0.12777559289468393
Trained batch 124 in epoch 1, gen_loss = 0.432226380109787, disc_loss = 0.12702567480504512
Trained batch 125 in epoch 1, gen_loss = 0.43275773004880025, disc_loss = 0.12772928555274293
Trained batch 126 in epoch 1, gen_loss = 0.4334043912061556, disc_loss = 0.127006872065776
Trained batch 127 in epoch 1, gen_loss = 0.4336669221520424, disc_loss = 0.12627251805679407
Trained batch 128 in epoch 1, gen_loss = 0.43366464187008463, disc_loss = 0.12571699052413768
Trained batch 129 in epoch 1, gen_loss = 0.4337474596041899, disc_loss = 0.12517915421093886
Trained batch 130 in epoch 1, gen_loss = 0.43404516850719016, disc_loss = 0.12473673431757297
Trained batch 131 in epoch 1, gen_loss = 0.43424663805600366, disc_loss = 0.12458663435201302
Trained batch 132 in epoch 1, gen_loss = 0.43472314015366975, disc_loss = 0.12434231911442782
Trained batch 133 in epoch 1, gen_loss = 0.43487210238157814, disc_loss = 0.12372577720002007
Trained batch 134 in epoch 1, gen_loss = 0.43501435584492154, disc_loss = 0.12346775560743278
Trained batch 135 in epoch 1, gen_loss = 0.4347979524994598, disc_loss = 0.1231635346159558
Trained batch 136 in epoch 1, gen_loss = 0.43543370992597874, disc_loss = 0.12367220936737357
Trained batch 137 in epoch 1, gen_loss = 0.435221771615139, disc_loss = 0.12496365095232276
Trained batch 138 in epoch 1, gen_loss = 0.4350641965866089, disc_loss = 0.12620735989896942
Trained batch 139 in epoch 1, gen_loss = 0.43511020094156266, disc_loss = 0.12592659961166128
Trained batch 140 in epoch 1, gen_loss = 0.4357431934657672, disc_loss = 0.12514352556714353
Trained batch 141 in epoch 1, gen_loss = 0.43568386095510403, disc_loss = 0.12438499068342884
Trained batch 142 in epoch 1, gen_loss = 0.4355587386167966, disc_loss = 0.12363796148423131
Trained batch 143 in epoch 1, gen_loss = 0.4353172919816441, disc_loss = 0.12346493813674897
Trained batch 144 in epoch 1, gen_loss = 0.4355156318894748, disc_loss = 0.12358818957260971
Trained batch 145 in epoch 1, gen_loss = 0.4354885722676369, disc_loss = 0.12305715780909339
Trained batch 146 in epoch 1, gen_loss = 0.4353485322322975, disc_loss = 0.12247214951634812
Trained batch 147 in epoch 1, gen_loss = 0.43542537133435943, disc_loss = 0.12187760432779386
Trained batch 148 in epoch 1, gen_loss = 0.43524224486126994, disc_loss = 0.12121385109654609
Trained batch 149 in epoch 1, gen_loss = 0.434944796760877, disc_loss = 0.12083641065905491
Trained batch 150 in epoch 1, gen_loss = 0.4347375108311508, disc_loss = 0.12063592429340675
Trained batch 151 in epoch 1, gen_loss = 0.43444828591064405, disc_loss = 0.12042472490697707
Trained batch 152 in epoch 1, gen_loss = 0.43445574049077, disc_loss = 0.12101726476224808
Trained batch 153 in epoch 1, gen_loss = 0.4345662998301642, disc_loss = 0.12055933817785669
Trained batch 154 in epoch 1, gen_loss = 0.43494660777430383, disc_loss = 0.12009918626037336
Trained batch 155 in epoch 1, gen_loss = 0.43488324739229983, disc_loss = 0.1196593250004718
Trained batch 156 in epoch 1, gen_loss = 0.435241294134954, disc_loss = 0.11935403832726797
Trained batch 157 in epoch 1, gen_loss = 0.43537365635739095, disc_loss = 0.11941840672936244
Trained batch 158 in epoch 1, gen_loss = 0.43582015704808746, disc_loss = 0.11883960932540069
Trained batch 159 in epoch 1, gen_loss = 0.43625630997121334, disc_loss = 0.11833990853046998
Trained batch 160 in epoch 1, gen_loss = 0.4362001789282568, disc_loss = 0.11889146086730942
Trained batch 161 in epoch 1, gen_loss = 0.4363119282104351, disc_loss = 0.11931168926120908
Trained batch 162 in epoch 1, gen_loss = 0.43653576249725246, disc_loss = 0.11920839853219094
Trained batch 163 in epoch 1, gen_loss = 0.4361382279454208, disc_loss = 0.12009883230188634
Trained batch 164 in epoch 1, gen_loss = 0.43603974327896583, disc_loss = 0.1197330039446101
Trained batch 165 in epoch 1, gen_loss = 0.4357770273843444, disc_loss = 0.11936003314218967
Trained batch 166 in epoch 1, gen_loss = 0.43567692644581824, disc_loss = 0.11889843920435378
Trained batch 167 in epoch 1, gen_loss = 0.43559395113871213, disc_loss = 0.11909836585012575
Trained batch 168 in epoch 1, gen_loss = 0.4359912073471137, disc_loss = 0.1192398945189263
Trained batch 169 in epoch 1, gen_loss = 0.4360103922731736, disc_loss = 0.11900032908820055
Trained batch 170 in epoch 1, gen_loss = 0.4359475975496727, disc_loss = 0.11849519689921399
Trained batch 171 in epoch 1, gen_loss = 0.43545066946467686, disc_loss = 0.11864932558261031
Trained batch 172 in epoch 1, gen_loss = 0.4354850446557723, disc_loss = 0.11839897328761616
Trained batch 173 in epoch 1, gen_loss = 0.43515413245935547, disc_loss = 0.11813655779322331
Trained batch 174 in epoch 1, gen_loss = 0.43501452956880843, disc_loss = 0.11772481289293085
Trained batch 175 in epoch 1, gen_loss = 0.4346979224885052, disc_loss = 0.11744989070575684
Trained batch 176 in epoch 1, gen_loss = 0.43466817120374257, disc_loss = 0.11714772615939548
Trained batch 177 in epoch 1, gen_loss = 0.4349398181009828, disc_loss = 0.11674995055903545
Trained batch 178 in epoch 1, gen_loss = 0.43511597321020157, disc_loss = 0.11623682130606813
Trained batch 179 in epoch 1, gen_loss = 0.4350810107257631, disc_loss = 0.11589967414943708
Trained batch 180 in epoch 1, gen_loss = 0.43508960018500437, disc_loss = 0.11554379706677481
Trained batch 181 in epoch 1, gen_loss = 0.435613072016737, disc_loss = 0.11516727833589027
Trained batch 182 in epoch 1, gen_loss = 0.43597078828212343, disc_loss = 0.11504234918113289
Trained batch 183 in epoch 1, gen_loss = 0.4356962214021579, disc_loss = 0.11580196831820776
Trained batch 184 in epoch 1, gen_loss = 0.435881609207875, disc_loss = 0.11568407814043599
Trained batch 185 in epoch 1, gen_loss = 0.4363108479207562, disc_loss = 0.11547230583645644
Trained batch 186 in epoch 1, gen_loss = 0.4359524301029144, disc_loss = 0.11599471526628828
Trained batch 187 in epoch 1, gen_loss = 0.4362383392897058, disc_loss = 0.115649196289559
Trained batch 188 in epoch 1, gen_loss = 0.4363878802963035, disc_loss = 0.11580994132925909
Trained batch 189 in epoch 1, gen_loss = 0.4365656918600986, disc_loss = 0.11532523096784165
Trained batch 190 in epoch 1, gen_loss = 0.43688101746649016, disc_loss = 0.11539186582125294
Trained batch 191 in epoch 1, gen_loss = 0.43709616906320053, disc_loss = 0.11552217561984435
Trained batch 192 in epoch 1, gen_loss = 0.4371100430970365, disc_loss = 0.11518582981562367
Trained batch 193 in epoch 1, gen_loss = 0.43677695049453025, disc_loss = 0.1150561810960782
Trained batch 194 in epoch 1, gen_loss = 0.436814371133462, disc_loss = 0.11479819289002663
Trained batch 195 in epoch 1, gen_loss = 0.43679055024166497, disc_loss = 0.11452914852344868
Trained batch 196 in epoch 1, gen_loss = 0.43652710984200993, disc_loss = 0.11410400368802741
Trained batch 197 in epoch 1, gen_loss = 0.43633887879174166, disc_loss = 0.11371744528525707
Trained batch 198 in epoch 1, gen_loss = 0.4362570992366752, disc_loss = 0.11363693108623052
Trained batch 199 in epoch 1, gen_loss = 0.4360565158724785, disc_loss = 0.1136900722142309
Trained batch 200 in epoch 1, gen_loss = 0.43631526560925726, disc_loss = 0.11410507225241531
Trained batch 201 in epoch 1, gen_loss = 0.43591473922871127, disc_loss = 0.1155479785589741
Trained batch 202 in epoch 1, gen_loss = 0.4362881433200366, disc_loss = 0.1153698303631227
Trained batch 203 in epoch 1, gen_loss = 0.43661051082844826, disc_loss = 0.11545577527516905
Trained batch 204 in epoch 1, gen_loss = 0.4368956952560239, disc_loss = 0.11548087559640408
Trained batch 205 in epoch 1, gen_loss = 0.43732762828613947, disc_loss = 0.11532729371333296
Trained batch 206 in epoch 1, gen_loss = 0.4372194115666376, disc_loss = 0.11498217865068844
Trained batch 207 in epoch 1, gen_loss = 0.43718689106977904, disc_loss = 0.11478705343324691
Trained batch 208 in epoch 1, gen_loss = 0.4372735244520543, disc_loss = 0.11472587976337335
Trained batch 209 in epoch 1, gen_loss = 0.43720244069894154, disc_loss = 0.11440665644726583
Trained batch 210 in epoch 1, gen_loss = 0.4373320512014543, disc_loss = 0.11410006065963287
Trained batch 211 in epoch 1, gen_loss = 0.43712588090379284, disc_loss = 0.11381288768091011
Trained batch 212 in epoch 1, gen_loss = 0.43710839496531956, disc_loss = 0.11375584410494761
Trained batch 213 in epoch 1, gen_loss = 0.4371981021956863, disc_loss = 0.11351445556626977
Trained batch 214 in epoch 1, gen_loss = 0.437153274098108, disc_loss = 0.11319094211036383
Trained batch 215 in epoch 1, gen_loss = 0.43757777812856213, disc_loss = 0.11330293885570157
Trained batch 216 in epoch 1, gen_loss = 0.4368463311052542, disc_loss = 0.1142188555857141
Trained batch 217 in epoch 1, gen_loss = 0.4365907621766449, disc_loss = 0.114043974693557
Trained batch 218 in epoch 1, gen_loss = 0.43630220315772106, disc_loss = 0.11428121951106748
Trained batch 219 in epoch 1, gen_loss = 0.4360061996362426, disc_loss = 0.11426742714406414
Trained batch 220 in epoch 1, gen_loss = 0.43618287570875697, disc_loss = 0.11416755502883395
Trained batch 221 in epoch 1, gen_loss = 0.4360794484078347, disc_loss = 0.11403202836880007
Trained batch 222 in epoch 1, gen_loss = 0.43557636860774773, disc_loss = 0.11364226409906496
Trained batch 223 in epoch 1, gen_loss = 0.43563006312719416, disc_loss = 0.11382344982952677
Trained batch 224 in epoch 1, gen_loss = 0.4359131889873081, disc_loss = 0.11397910905381044
Trained batch 225 in epoch 1, gen_loss = 0.4353813783521146, disc_loss = 0.11371308687942482
Trained batch 226 in epoch 1, gen_loss = 0.4354167563537144, disc_loss = 0.11398805209357571
Trained batch 227 in epoch 1, gen_loss = 0.4354248601093627, disc_loss = 0.11366771391119089
Trained batch 228 in epoch 1, gen_loss = 0.435866256728443, disc_loss = 0.11348952080517617
Trained batch 229 in epoch 1, gen_loss = 0.4358048739640609, disc_loss = 0.11361935916964126
Trained batch 230 in epoch 1, gen_loss = 0.43607418645511975, disc_loss = 0.11327085370657505
Trained batch 231 in epoch 1, gen_loss = 0.4362895366703642, disc_loss = 0.11310073107898493
Trained batch 232 in epoch 1, gen_loss = 0.43648531380641103, disc_loss = 0.11288509998358626
Trained batch 233 in epoch 1, gen_loss = 0.43646733819419503, disc_loss = 0.11261143187522633
Trained batch 234 in epoch 1, gen_loss = 0.4369289257424943, disc_loss = 0.1129083487819484
Trained batch 235 in epoch 1, gen_loss = 0.43701870840484813, disc_loss = 0.11319829727980797
Trained batch 236 in epoch 1, gen_loss = 0.43698618130341865, disc_loss = 0.11286606167281982
Trained batch 237 in epoch 1, gen_loss = 0.4370812897672172, disc_loss = 0.11270203177637163
Trained batch 238 in epoch 1, gen_loss = 0.4372540611352881, disc_loss = 0.1124369913018523
Trained batch 239 in epoch 1, gen_loss = 0.43707054915527505, disc_loss = 0.1121988794223095
Trained batch 240 in epoch 1, gen_loss = 0.4370228148594931, disc_loss = 0.11205161845937557
Trained batch 241 in epoch 1, gen_loss = 0.4371253867779881, disc_loss = 0.11192445011332261
Trained batch 242 in epoch 1, gen_loss = 0.43726743175169075, disc_loss = 0.11168141700634004
Trained batch 243 in epoch 1, gen_loss = 0.43750561260786214, disc_loss = 0.11165823018727977
Trained batch 244 in epoch 1, gen_loss = 0.4375624668841459, disc_loss = 0.11139016319446418
Trained batch 245 in epoch 1, gen_loss = 0.4378327528635661, disc_loss = 0.11113492313893587
Trained batch 246 in epoch 1, gen_loss = 0.43802043023379705, disc_loss = 0.11087885288604599
Trained batch 247 in epoch 1, gen_loss = 0.4384057527828601, disc_loss = 0.11079473662069969
Trained batch 248 in epoch 1, gen_loss = 0.438550505413109, disc_loss = 0.1108073600638942
Trained batch 249 in epoch 1, gen_loss = 0.43834646785259246, disc_loss = 0.11055388820916415
Trained batch 250 in epoch 1, gen_loss = 0.43840701753399763, disc_loss = 0.11028447281940287
Trained batch 251 in epoch 1, gen_loss = 0.43848644303424017, disc_loss = 0.10997778148434702
Trained batch 252 in epoch 1, gen_loss = 0.4385822787586408, disc_loss = 0.10976788010669085
Trained batch 253 in epoch 1, gen_loss = 0.4386237440850791, disc_loss = 0.10952690232721135
Trained batch 254 in epoch 1, gen_loss = 0.43867224957428724, disc_loss = 0.1092096284835362
Trained batch 255 in epoch 1, gen_loss = 0.4389572461368516, disc_loss = 0.10951311268581776
Trained batch 256 in epoch 1, gen_loss = 0.43905857402526915, disc_loss = 0.10975608611588117
Trained batch 257 in epoch 1, gen_loss = 0.4392436984204507, disc_loss = 0.1097592915834267
Trained batch 258 in epoch 1, gen_loss = 0.4393193101560747, disc_loss = 0.10949312335304542
Trained batch 259 in epoch 1, gen_loss = 0.4393801912665367, disc_loss = 0.10936322935068836
Trained batch 260 in epoch 1, gen_loss = 0.43963653796934077, disc_loss = 0.10940347458467858
Trained batch 261 in epoch 1, gen_loss = 0.439770974616968, disc_loss = 0.10925212127817724
Trained batch 262 in epoch 1, gen_loss = 0.4403194910899768, disc_loss = 0.1090091993047824
Trained batch 263 in epoch 1, gen_loss = 0.4404457068127213, disc_loss = 0.10885754931069007
Trained batch 264 in epoch 1, gen_loss = 0.4407569373553654, disc_loss = 0.10870442964698908
Trained batch 265 in epoch 1, gen_loss = 0.44075056641621696, disc_loss = 0.10870507785952405
Trained batch 266 in epoch 1, gen_loss = 0.4405752865785963, disc_loss = 0.10859952426832936
Trained batch 267 in epoch 1, gen_loss = 0.4406648886515133, disc_loss = 0.10903386438765855
Trained batch 268 in epoch 1, gen_loss = 0.4405291617802971, disc_loss = 0.10921456961854462
Trained batch 269 in epoch 1, gen_loss = 0.4403979479162781, disc_loss = 0.10921837340488479
Trained batch 270 in epoch 1, gen_loss = 0.4405904291300756, disc_loss = 0.10924093041060376
Trained batch 271 in epoch 1, gen_loss = 0.44038691546987085, disc_loss = 0.10903826321009547
Trained batch 272 in epoch 1, gen_loss = 0.4402840800119407, disc_loss = 0.10905189411680559
Trained batch 273 in epoch 1, gen_loss = 0.4400840614833971, disc_loss = 0.10881079511077953
Trained batch 274 in epoch 1, gen_loss = 0.44005148020657625, disc_loss = 0.10880011846396057
Trained batch 275 in epoch 1, gen_loss = 0.43994425474733545, disc_loss = 0.10899363982531687
Trained batch 276 in epoch 1, gen_loss = 0.4401036563332761, disc_loss = 0.10902776378828911
Trained batch 277 in epoch 1, gen_loss = 0.44009797371548715, disc_loss = 0.10898184441968048
Trained batch 278 in epoch 1, gen_loss = 0.4400594727967375, disc_loss = 0.1087617425975727
Trained batch 279 in epoch 1, gen_loss = 0.4401666305959225, disc_loss = 0.10875447716430894
Trained batch 280 in epoch 1, gen_loss = 0.44010208690293745, disc_loss = 0.10845265689958881
Trained batch 281 in epoch 1, gen_loss = 0.4402455632568251, disc_loss = 0.10846900072028028
Trained batch 282 in epoch 1, gen_loss = 0.4403141971822341, disc_loss = 0.10815229320852579
Trained batch 283 in epoch 1, gen_loss = 0.44035899114440863, disc_loss = 0.107828057554721
Trained batch 284 in epoch 1, gen_loss = 0.440879670151493, disc_loss = 0.10782129611623914
Trained batch 285 in epoch 1, gen_loss = 0.44087114211145817, disc_loss = 0.10773007940318617
Trained batch 286 in epoch 1, gen_loss = 0.44091386225996115, disc_loss = 0.1081692184279397
Trained batch 287 in epoch 1, gen_loss = 0.4409329110963477, disc_loss = 0.10816667858873391
Trained batch 288 in epoch 1, gen_loss = 0.44099890278284937, disc_loss = 0.10849029556638642
Trained batch 289 in epoch 1, gen_loss = 0.4409510187033949, disc_loss = 0.10815619362903567
Trained batch 290 in epoch 1, gen_loss = 0.44074222547901454, disc_loss = 0.10800738531865717
Trained batch 291 in epoch 1, gen_loss = 0.44054054091237993, disc_loss = 0.10823399447580825
Trained batch 292 in epoch 1, gen_loss = 0.44093867109090396, disc_loss = 0.10870362580801542
Trained batch 293 in epoch 1, gen_loss = 0.4408845056076439, disc_loss = 0.10878253268508785
Trained batch 294 in epoch 1, gen_loss = 0.4406024717678458, disc_loss = 0.10873614190051616
Trained batch 295 in epoch 1, gen_loss = 0.44053254810136716, disc_loss = 0.10850253162867818
Trained batch 296 in epoch 1, gen_loss = 0.4406346846309174, disc_loss = 0.1081702912552439
Trained batch 297 in epoch 1, gen_loss = 0.4406045546267657, disc_loss = 0.10816284520676572
Trained batch 298 in epoch 1, gen_loss = 0.44052984214147994, disc_loss = 0.10798866299594624
Trained batch 299 in epoch 1, gen_loss = 0.44039361774921415, disc_loss = 0.1077874339154611
Trained batch 300 in epoch 1, gen_loss = 0.4404210128459424, disc_loss = 0.10761684730364338
Trained batch 301 in epoch 1, gen_loss = 0.4404248066295851, disc_loss = 0.10734495684344149
Trained batch 302 in epoch 1, gen_loss = 0.440283456848006, disc_loss = 0.10729248380048735
Trained batch 303 in epoch 1, gen_loss = 0.44008820582377284, disc_loss = 0.10702287665825631
Trained batch 304 in epoch 1, gen_loss = 0.44013175407394034, disc_loss = 0.1074655064824419
Trained batch 305 in epoch 1, gen_loss = 0.4399266482568255, disc_loss = 0.10753977552263273
Trained batch 306 in epoch 1, gen_loss = 0.44028534931934615, disc_loss = 0.10756312466320561
Trained batch 307 in epoch 1, gen_loss = 0.4400451776462716, disc_loss = 0.10764217807596864
Trained batch 308 in epoch 1, gen_loss = 0.43996478120485943, disc_loss = 0.10745314549968177
Trained batch 309 in epoch 1, gen_loss = 0.43974693225276085, disc_loss = 0.10733429056802585
Trained batch 310 in epoch 1, gen_loss = 0.43977305705141023, disc_loss = 0.10734288200700111
Trained batch 311 in epoch 1, gen_loss = 0.4396547977931989, disc_loss = 0.10713603844543776
Trained batch 312 in epoch 1, gen_loss = 0.43948004744685115, disc_loss = 0.10689063169383489
Trained batch 313 in epoch 1, gen_loss = 0.43952965328268184, disc_loss = 0.10663368143912429
Trained batch 314 in epoch 1, gen_loss = 0.4397580437243931, disc_loss = 0.10646405555012207
Trained batch 315 in epoch 1, gen_loss = 0.43985859597031074, disc_loss = 0.10651401497859837
Trained batch 316 in epoch 1, gen_loss = 0.4399849511095402, disc_loss = 0.10653831287102086
Trained batch 317 in epoch 1, gen_loss = 0.4400896591210515, disc_loss = 0.10633450945979862
Trained batch 318 in epoch 1, gen_loss = 0.44005764493000543, disc_loss = 0.10612690157102286
Trained batch 319 in epoch 1, gen_loss = 0.4404237980954349, disc_loss = 0.10616607591800857
Trained batch 320 in epoch 1, gen_loss = 0.4405477245648702, disc_loss = 0.10619557363697765
Trained batch 321 in epoch 1, gen_loss = 0.4405795465344968, disc_loss = 0.10592704713171036
Trained batch 322 in epoch 1, gen_loss = 0.44052824931617124, disc_loss = 0.10567638371139765
Trained batch 323 in epoch 1, gen_loss = 0.4405788230123343, disc_loss = 0.1057448411607586
Trained batch 324 in epoch 1, gen_loss = 0.44040423970956066, disc_loss = 0.1062034156316748
Trained batch 325 in epoch 1, gen_loss = 0.4407484223323366, disc_loss = 0.10623465584408194
Trained batch 326 in epoch 1, gen_loss = 0.440420898913608, disc_loss = 0.10614272128129862
Trained batch 327 in epoch 1, gen_loss = 0.44067193740388244, disc_loss = 0.10596146985104807
Trained batch 328 in epoch 1, gen_loss = 0.44060895426657426, disc_loss = 0.10609671872924435
Trained batch 329 in epoch 1, gen_loss = 0.44064685837789014, disc_loss = 0.10600606461309574
Trained batch 330 in epoch 1, gen_loss = 0.44084838302834156, disc_loss = 0.10579491929739174
Trained batch 331 in epoch 1, gen_loss = 0.4406555236642619, disc_loss = 0.1058258244021605
Trained batch 332 in epoch 1, gen_loss = 0.4406703450121321, disc_loss = 0.10578074703110499
Trained batch 333 in epoch 1, gen_loss = 0.44080911915816234, disc_loss = 0.10638631898965575
Trained batch 334 in epoch 1, gen_loss = 0.44046643064982854, disc_loss = 0.10671589651158941
Trained batch 335 in epoch 1, gen_loss = 0.44047153279894874, disc_loss = 0.10668541780129696
Trained batch 336 in epoch 1, gen_loss = 0.4406964711690161, disc_loss = 0.10688754267028867
Trained batch 337 in epoch 1, gen_loss = 0.44053589812749944, disc_loss = 0.10679007531832573
Trained batch 338 in epoch 1, gen_loss = 0.4401803653148775, disc_loss = 0.10679890317320384
Trained batch 339 in epoch 1, gen_loss = 0.4400421835043851, disc_loss = 0.10659413525889463
Trained batch 340 in epoch 1, gen_loss = 0.44017032129673667, disc_loss = 0.10643326307310999
Trained batch 341 in epoch 1, gen_loss = 0.4399763493858583, disc_loss = 0.10652843067335369
Trained batch 342 in epoch 1, gen_loss = 0.4399421753758244, disc_loss = 0.10663012827613524
Trained batch 343 in epoch 1, gen_loss = 0.43978482510807904, disc_loss = 0.1065850809059474
Trained batch 344 in epoch 1, gen_loss = 0.4399548400139463, disc_loss = 0.10643826809212349
Trained batch 345 in epoch 1, gen_loss = 0.4400992162654855, disc_loss = 0.10650471438293081
Trained batch 346 in epoch 1, gen_loss = 0.4401449400512904, disc_loss = 0.10648783302519696
Trained batch 347 in epoch 1, gen_loss = 0.44015518190531894, disc_loss = 0.10640797262807944
Trained batch 348 in epoch 1, gen_loss = 0.440218031662583, disc_loss = 0.10650964507987899
Trained batch 349 in epoch 1, gen_loss = 0.440333440048354, disc_loss = 0.10644596684990185
Trained batch 350 in epoch 1, gen_loss = 0.4402341447834276, disc_loss = 0.10633922113302002
Trained batch 351 in epoch 1, gen_loss = 0.4401059507985007, disc_loss = 0.10652628691009754
Trained batch 352 in epoch 1, gen_loss = 0.44010414052279745, disc_loss = 0.10640246287864176
Trained batch 353 in epoch 1, gen_loss = 0.44007985411727496, disc_loss = 0.10617526219421103
Trained batch 354 in epoch 1, gen_loss = 0.4399291439795158, disc_loss = 0.10608239879857906
Trained batch 355 in epoch 1, gen_loss = 0.43975039964981294, disc_loss = 0.10604062539085829
Trained batch 356 in epoch 1, gen_loss = 0.4397213713628571, disc_loss = 0.10628699418157339
Trained batch 357 in epoch 1, gen_loss = 0.43988124310304333, disc_loss = 0.1068860302918575
Trained batch 358 in epoch 1, gen_loss = 0.4399733040326153, disc_loss = 0.10690183946629338
Trained batch 359 in epoch 1, gen_loss = 0.43993643787172104, disc_loss = 0.10688026993173277
Trained batch 360 in epoch 1, gen_loss = 0.4397009015908862, disc_loss = 0.10669772257548538
Trained batch 361 in epoch 1, gen_loss = 0.43979038742695065, disc_loss = 0.10662989944826749
Trained batch 362 in epoch 1, gen_loss = 0.4397019880205475, disc_loss = 0.10658199698010012
Trained batch 363 in epoch 1, gen_loss = 0.43986759302052825, disc_loss = 0.10643525685408858
Trained batch 364 in epoch 1, gen_loss = 0.43995720980918573, disc_loss = 0.10620556293336088
Trained batch 365 in epoch 1, gen_loss = 0.44002786864999865, disc_loss = 0.10614722630497618
Trained batch 366 in epoch 1, gen_loss = 0.439981139648188, disc_loss = 0.10606217773362223
Trained batch 367 in epoch 1, gen_loss = 0.43988420514632826, disc_loss = 0.10602911751282038
Trained batch 368 in epoch 1, gen_loss = 0.4397559009270293, disc_loss = 0.10596489778348828
Trained batch 369 in epoch 1, gen_loss = 0.4396645850426442, disc_loss = 0.10574968865241956
Trained batch 370 in epoch 1, gen_loss = 0.43958239381846714, disc_loss = 0.10558014302050088
Trained batch 371 in epoch 1, gen_loss = 0.43974121363573176, disc_loss = 0.10536268801348264
Trained batch 372 in epoch 1, gen_loss = 0.43983409943273816, disc_loss = 0.10537698844213028
Trained batch 373 in epoch 1, gen_loss = 0.43966309479213656, disc_loss = 0.10551361798652432
Trained batch 374 in epoch 1, gen_loss = 0.4395955380598704, disc_loss = 0.10536357857038578
Trained batch 375 in epoch 1, gen_loss = 0.43941292745318816, disc_loss = 0.10523140615971878
Trained batch 376 in epoch 1, gen_loss = 0.4394157034806927, disc_loss = 0.10513909385645817
Trained batch 377 in epoch 1, gen_loss = 0.43947315365864487, disc_loss = 0.10495881772989397
Trained batch 378 in epoch 1, gen_loss = 0.43941848416441665, disc_loss = 0.10489147804471072
Trained batch 379 in epoch 1, gen_loss = 0.43959745388281973, disc_loss = 0.10477988674109312
Trained batch 380 in epoch 1, gen_loss = 0.439759208930759, disc_loss = 0.10461737731046329
Trained batch 381 in epoch 1, gen_loss = 0.4398124047130814, disc_loss = 0.10448609677957693
Trained batch 382 in epoch 1, gen_loss = 0.4397057815413562, disc_loss = 0.10450485242924631
Trained batch 383 in epoch 1, gen_loss = 0.43981545860879123, disc_loss = 0.1045934337040914
Trained batch 384 in epoch 1, gen_loss = 0.4397244813380303, disc_loss = 0.10451221716916793
Trained batch 385 in epoch 1, gen_loss = 0.43967243913232973, disc_loss = 0.10428845956004731
Trained batch 386 in epoch 1, gen_loss = 0.43966431118721183, disc_loss = 0.1041418708576905
Trained batch 387 in epoch 1, gen_loss = 0.439575170733265, disc_loss = 0.1039289856334361
Trained batch 388 in epoch 1, gen_loss = 0.4394962928595457, disc_loss = 0.10373374524078594
Trained batch 389 in epoch 1, gen_loss = 0.4394764609061755, disc_loss = 0.10359214299047986
Trained batch 390 in epoch 1, gen_loss = 0.43938400419166934, disc_loss = 0.10360681398264358
Trained batch 391 in epoch 1, gen_loss = 0.43932268274377806, disc_loss = 0.10356317376195244
Trained batch 392 in epoch 1, gen_loss = 0.4394386287105599, disc_loss = 0.10347798970260162
Trained batch 393 in epoch 1, gen_loss = 0.43962749922033495, disc_loss = 0.1033418765457035
Trained batch 394 in epoch 1, gen_loss = 0.43973409382602835, disc_loss = 0.10320936612360462
Trained batch 395 in epoch 1, gen_loss = 0.4396646104075692, disc_loss = 0.10316007062463523
Trained batch 396 in epoch 1, gen_loss = 0.44000708636468844, disc_loss = 0.10301217963445172
Trained batch 397 in epoch 1, gen_loss = 0.44006797266964937, disc_loss = 0.10287263876426235
Trained batch 398 in epoch 1, gen_loss = 0.440124906095347, disc_loss = 0.10264421697416551
Trained batch 399 in epoch 1, gen_loss = 0.44004071623086927, disc_loss = 0.10246032308321446
Trained batch 400 in epoch 1, gen_loss = 0.4400924441225808, disc_loss = 0.10224769625376139
Trained batch 401 in epoch 1, gen_loss = 0.44018698227939324, disc_loss = 0.10202185774166415
Trained batch 402 in epoch 1, gen_loss = 0.44021145884807295, disc_loss = 0.10183398531190589
Trained batch 403 in epoch 1, gen_loss = 0.4403348195523319, disc_loss = 0.10161756022169374
Trained batch 404 in epoch 1, gen_loss = 0.4406297101650709, disc_loss = 0.10150440116125492
Trained batch 405 in epoch 1, gen_loss = 0.4407685270597195, disc_loss = 0.10135004911434108
Trained batch 406 in epoch 1, gen_loss = 0.44085438414053485, disc_loss = 0.10116159990750236
Trained batch 407 in epoch 1, gen_loss = 0.44088853391654353, disc_loss = 0.10094643785736944
Trained batch 408 in epoch 1, gen_loss = 0.4410686034590807, disc_loss = 0.10073981673882541
Trained batch 409 in epoch 1, gen_loss = 0.44121365379996413, disc_loss = 0.10060511130794156
Trained batch 410 in epoch 1, gen_loss = 0.44121183705155864, disc_loss = 0.10085258447313614
Trained batch 411 in epoch 1, gen_loss = 0.4411034896535781, disc_loss = 0.10079943118571728
Trained batch 412 in epoch 1, gen_loss = 0.4410839062048794, disc_loss = 0.10060098831548601
Trained batch 413 in epoch 1, gen_loss = 0.44117401158752073, disc_loss = 0.10048440292450612
Trained batch 414 in epoch 1, gen_loss = 0.44123664419335057, disc_loss = 0.10031317150871079
Trained batch 415 in epoch 1, gen_loss = 0.4414347213907884, disc_loss = 0.10017917886188325
Trained batch 416 in epoch 1, gen_loss = 0.441608353341512, disc_loss = 0.10000026244580817
Trained batch 417 in epoch 1, gen_loss = 0.4416878805206153, disc_loss = 0.09980440250058707
Trained batch 418 in epoch 1, gen_loss = 0.44154815365135813, disc_loss = 0.0996676123187586
Trained batch 419 in epoch 1, gen_loss = 0.4417276009917259, disc_loss = 0.09960209351875597
Trained batch 420 in epoch 1, gen_loss = 0.4417896854056315, disc_loss = 0.09939644431292728
Trained batch 421 in epoch 1, gen_loss = 0.44177569441885745, disc_loss = 0.09920607456469564
Trained batch 422 in epoch 1, gen_loss = 0.4417170270678563, disc_loss = 0.09911553734741735
Trained batch 423 in epoch 1, gen_loss = 0.4419690248257709, disc_loss = 0.09956535128085821
Trained batch 424 in epoch 1, gen_loss = 0.4417552216613994, disc_loss = 0.09959418905570226
Trained batch 425 in epoch 1, gen_loss = 0.4419148625202582, disc_loss = 0.09943270276654774
Trained batch 426 in epoch 1, gen_loss = 0.442112246427938, disc_loss = 0.09930922420787029
Trained batch 427 in epoch 1, gen_loss = 0.44220317538096526, disc_loss = 0.09956629112989546
Trained batch 428 in epoch 1, gen_loss = 0.4421157898047032, disc_loss = 0.09969287626184783
Trained batch 429 in epoch 1, gen_loss = 0.4421377687953239, disc_loss = 0.09984451700435128
Trained batch 430 in epoch 1, gen_loss = 0.4420065156544997, disc_loss = 0.09983939243579962
Trained batch 431 in epoch 1, gen_loss = 0.44197886361292116, disc_loss = 0.10020753527405085
Trained batch 432 in epoch 1, gen_loss = 0.44209927231004553, disc_loss = 0.10066310369665574
Trained batch 433 in epoch 1, gen_loss = 0.4421281128572429, disc_loss = 0.10071138374953775
Trained batch 434 in epoch 1, gen_loss = 0.44197159923356155, disc_loss = 0.10089448296475685
Trained batch 435 in epoch 1, gen_loss = 0.4417866564125096, disc_loss = 0.10088702236567068
Trained batch 436 in epoch 1, gen_loss = 0.44178002042955883, disc_loss = 0.101120264361052
Trained batch 437 in epoch 1, gen_loss = 0.4417794307345125, disc_loss = 0.10113329487984583
Trained batch 438 in epoch 1, gen_loss = 0.44154394419698345, disc_loss = 0.10118738354813808
Trained batch 439 in epoch 1, gen_loss = 0.44153757291761314, disc_loss = 0.10114102710715749
Trained batch 440 in epoch 1, gen_loss = 0.44142297687444015, disc_loss = 0.10101643445439079
Trained batch 441 in epoch 1, gen_loss = 0.4414263447889915, disc_loss = 0.10090919200550108
Trained batch 442 in epoch 1, gen_loss = 0.44141233734298774, disc_loss = 0.1008341344783995
Trained batch 443 in epoch 1, gen_loss = 0.4414545385552956, disc_loss = 0.10068217902402352
Trained batch 444 in epoch 1, gen_loss = 0.4414184100842208, disc_loss = 0.10061570138911183
Trained batch 445 in epoch 1, gen_loss = 0.4415979357979223, disc_loss = 0.10055766442598515
Trained batch 446 in epoch 1, gen_loss = 0.44155953014456983, disc_loss = 0.10065862110563839
Trained batch 447 in epoch 1, gen_loss = 0.4415900203000222, disc_loss = 0.10080766582229574
Trained batch 448 in epoch 1, gen_loss = 0.4417962421287673, disc_loss = 0.1007758102946
Trained batch 449 in epoch 1, gen_loss = 0.44162049876319037, disc_loss = 0.10102521122329765
Trained batch 450 in epoch 1, gen_loss = 0.4415072246956455, disc_loss = 0.10098970786331762
Trained batch 451 in epoch 1, gen_loss = 0.4416160639540284, disc_loss = 0.10109457315102352
Trained batch 452 in epoch 1, gen_loss = 0.4417322716834003, disc_loss = 0.10094036596516769
Trained batch 453 in epoch 1, gen_loss = 0.4416064793317854, disc_loss = 0.10080053980179164
Trained batch 454 in epoch 1, gen_loss = 0.4418812825129582, disc_loss = 0.100635798062597
Trained batch 455 in epoch 1, gen_loss = 0.44188404494994565, disc_loss = 0.10062144028447699
Trained batch 456 in epoch 1, gen_loss = 0.4420582871859653, disc_loss = 0.1004856693470765
Trained batch 457 in epoch 1, gen_loss = 0.4420520542230148, disc_loss = 0.10034148535776607
Trained batch 458 in epoch 1, gen_loss = 0.4420238500846497, disc_loss = 0.10022521003561342
Trained batch 459 in epoch 1, gen_loss = 0.4420783160173375, disc_loss = 0.10007043339959953
Trained batch 460 in epoch 1, gen_loss = 0.4421792293448252, disc_loss = 0.1000857750951856
Trained batch 461 in epoch 1, gen_loss = 0.44223111235734186, disc_loss = 0.0999493541849124
Trained batch 462 in epoch 1, gen_loss = 0.4422337614305591, disc_loss = 0.09984564083602207
Trained batch 463 in epoch 1, gen_loss = 0.44235499659232025, disc_loss = 0.09975890933279076
Trained batch 464 in epoch 1, gen_loss = 0.44228258716162816, disc_loss = 0.09972917156354073
Trained batch 465 in epoch 1, gen_loss = 0.4423507725092474, disc_loss = 0.09976161681435394
Trained batch 466 in epoch 1, gen_loss = 0.44213029499738066, disc_loss = 0.10005900497514379
Trained batch 467 in epoch 1, gen_loss = 0.4423713366317953, disc_loss = 0.10023232738081461
Trained batch 468 in epoch 1, gen_loss = 0.4424484319397127, disc_loss = 0.10007917811907431
Trained batch 469 in epoch 1, gen_loss = 0.44236202962855076, disc_loss = 0.10006309997369635
Trained batch 470 in epoch 1, gen_loss = 0.44222011118178156, disc_loss = 0.10002607153827471
Trained batch 471 in epoch 1, gen_loss = 0.4421589475567058, disc_loss = 0.0999862099839848
Trained batch 472 in epoch 1, gen_loss = 0.44212504729912094, disc_loss = 0.09988832126428662
Trained batch 473 in epoch 1, gen_loss = 0.44199127807647365, disc_loss = 0.10012120598699221
Trained batch 474 in epoch 1, gen_loss = 0.4421935525065974, disc_loss = 0.10017416648958859
Trained batch 475 in epoch 1, gen_loss = 0.4422743636645189, disc_loss = 0.1001801473174651
Trained batch 476 in epoch 1, gen_loss = 0.4422182312676492, disc_loss = 0.10018543214136949
Trained batch 477 in epoch 1, gen_loss = 0.44210323922055533, disc_loss = 0.1001002346107027
Trained batch 478 in epoch 1, gen_loss = 0.4421674904096599, disc_loss = 0.09994648074991767
Trained batch 479 in epoch 1, gen_loss = 0.44222876330216726, disc_loss = 0.0999155553833892
Trained batch 480 in epoch 1, gen_loss = 0.4420527871581968, disc_loss = 0.09995931136013317
Trained batch 481 in epoch 1, gen_loss = 0.44198373974111566, disc_loss = 0.10021933560796793
Trained batch 482 in epoch 1, gen_loss = 0.44201306989474326, disc_loss = 0.10016722306146385
Trained batch 483 in epoch 1, gen_loss = 0.4420450722629374, disc_loss = 0.10019190058358445
Trained batch 484 in epoch 1, gen_loss = 0.44196034399504514, disc_loss = 0.10011653216536512
Trained batch 485 in epoch 1, gen_loss = 0.4420262868880244, disc_loss = 0.09997442855265896
Trained batch 486 in epoch 1, gen_loss = 0.4419703759574303, disc_loss = 0.09984350563227763
Trained batch 487 in epoch 1, gen_loss = 0.4419521381009798, disc_loss = 0.09988325338841217
Trained batch 488 in epoch 1, gen_loss = 0.4418424116199977, disc_loss = 0.10000922498131334
Trained batch 489 in epoch 1, gen_loss = 0.4418191521143427, disc_loss = 0.09990609304941431
Trained batch 490 in epoch 1, gen_loss = 0.4417902767779628, disc_loss = 0.0998028338623144
Trained batch 491 in epoch 1, gen_loss = 0.4419182030166068, disc_loss = 0.09964916749849795
Trained batch 492 in epoch 1, gen_loss = 0.4419542710631179, disc_loss = 0.09948932208710219
Trained batch 493 in epoch 1, gen_loss = 0.4419284081048811, disc_loss = 0.09940702564682555
Trained batch 494 in epoch 1, gen_loss = 0.44185908581271316, disc_loss = 0.09925679944530882
Trained batch 495 in epoch 1, gen_loss = 0.44182915673140555, disc_loss = 0.09910921613129997
Trained batch 496 in epoch 1, gen_loss = 0.4417263310200252, disc_loss = 0.09909886441435253
Trained batch 497 in epoch 1, gen_loss = 0.44165357301034125, disc_loss = 0.09900747212285857
Trained batch 498 in epoch 1, gen_loss = 0.4419063965161004, disc_loss = 0.09922482108768217
Trained batch 499 in epoch 1, gen_loss = 0.4417211263179779, disc_loss = 0.09954490586742759
Trained batch 500 in epoch 1, gen_loss = 0.441757848698222, disc_loss = 0.09938888306062141
Trained batch 501 in epoch 1, gen_loss = 0.44188475139824995, disc_loss = 0.0993344783857168
Trained batch 502 in epoch 1, gen_loss = 0.441768561099206, disc_loss = 0.0994602897191498
Trained batch 503 in epoch 1, gen_loss = 0.44195116577403887, disc_loss = 0.09940916445431491
Trained batch 504 in epoch 1, gen_loss = 0.442045124627576, disc_loss = 0.0994153068723655
Trained batch 505 in epoch 1, gen_loss = 0.4419829129819342, disc_loss = 0.09925901291251418
Trained batch 506 in epoch 1, gen_loss = 0.4418218936440507, disc_loss = 0.09923023022931708
Trained batch 507 in epoch 1, gen_loss = 0.4417382543246577, disc_loss = 0.0991477378402052
Trained batch 508 in epoch 1, gen_loss = 0.44182724474923785, disc_loss = 0.09906908090286733
Trained batch 509 in epoch 1, gen_loss = 0.441845580292683, disc_loss = 0.09895158251564877
Trained batch 510 in epoch 1, gen_loss = 0.4417941413980174, disc_loss = 0.09877712935311338
Trained batch 511 in epoch 1, gen_loss = 0.4417479130788706, disc_loss = 0.09861606898266473
Trained batch 512 in epoch 1, gen_loss = 0.44178391746145473, disc_loss = 0.09856328202981582
Trained batch 513 in epoch 1, gen_loss = 0.4417030570108139, disc_loss = 0.09842311261866807
Trained batch 514 in epoch 1, gen_loss = 0.44178493086574144, disc_loss = 0.09828661595950428
Trained batch 515 in epoch 1, gen_loss = 0.4418551922422047, disc_loss = 0.09819394469535513
Trained batch 516 in epoch 1, gen_loss = 0.44193273846139297, disc_loss = 0.0981117570070222
Trained batch 517 in epoch 1, gen_loss = 0.44192845848996665, disc_loss = 0.09796035508031896
Trained batch 518 in epoch 1, gen_loss = 0.4419679484959972, disc_loss = 0.09784458471042227
Trained batch 519 in epoch 1, gen_loss = 0.4417984505685476, disc_loss = 0.09785540719659856
Trained batch 520 in epoch 1, gen_loss = 0.4416913756825416, disc_loss = 0.0977760957957973
Trained batch 521 in epoch 1, gen_loss = 0.44155596887471577, disc_loss = 0.0977169528667783
Trained batch 522 in epoch 1, gen_loss = 0.44150579289086234, disc_loss = 0.09759460863644831
Trained batch 523 in epoch 1, gen_loss = 0.44133780663477556, disc_loss = 0.09765723070044441
Trained batch 524 in epoch 1, gen_loss = 0.44123583509808495, disc_loss = 0.09792791466982592
Trained batch 525 in epoch 1, gen_loss = 0.44110711383502293, disc_loss = 0.09779048630323246
Trained batch 526 in epoch 1, gen_loss = 0.4411627293424769, disc_loss = 0.0979988344112655
Trained batch 527 in epoch 1, gen_loss = 0.44120137410407717, disc_loss = 0.0979768109197418
Trained batch 528 in epoch 1, gen_loss = 0.44127494384075155, disc_loss = 0.09797419803410712
Trained batch 529 in epoch 1, gen_loss = 0.4413327763103089, disc_loss = 0.09791274041218578
Trained batch 530 in epoch 1, gen_loss = 0.4413353772149921, disc_loss = 0.09790071895567037
Trained batch 531 in epoch 1, gen_loss = 0.4413411434655799, disc_loss = 0.0978144109249115
Trained batch 532 in epoch 1, gen_loss = 0.44142405367255433, disc_loss = 0.0979613644432619
Trained batch 533 in epoch 1, gen_loss = 0.44143895542576966, disc_loss = 0.09796192374233896
Trained batch 534 in epoch 1, gen_loss = 0.44146072396608155, disc_loss = 0.09787608683109283
Trained batch 535 in epoch 1, gen_loss = 0.44146920951889523, disc_loss = 0.09779803093467186
Trained batch 536 in epoch 1, gen_loss = 0.44163033105363614, disc_loss = 0.09772068917668066
Trained batch 537 in epoch 1, gen_loss = 0.4417481005856539, disc_loss = 0.09773388411503521
Trained batch 538 in epoch 1, gen_loss = 0.44167516923791184, disc_loss = 0.0977927767680284
Trained batch 539 in epoch 1, gen_loss = 0.44171650183421596, disc_loss = 0.09767307232099551
Trained batch 540 in epoch 1, gen_loss = 0.441825910603934, disc_loss = 0.09752869429738156
Trained batch 541 in epoch 1, gen_loss = 0.44189115341519075, disc_loss = 0.0973735911861007
Trained batch 542 in epoch 1, gen_loss = 0.4418637928163588, disc_loss = 0.0972644684434925
Trained batch 543 in epoch 1, gen_loss = 0.4418585470274967, disc_loss = 0.0972999459995395
Trained batch 544 in epoch 1, gen_loss = 0.44185376954734873, disc_loss = 0.09715247217121474
Trained batch 545 in epoch 1, gen_loss = 0.4418506837371505, disc_loss = 0.09703872658503361
Trained batch 546 in epoch 1, gen_loss = 0.4418731613503514, disc_loss = 0.09693060324985323
Trained batch 547 in epoch 1, gen_loss = 0.4419269383388714, disc_loss = 0.09680180020807107
Trained batch 548 in epoch 1, gen_loss = 0.4419987228833044, disc_loss = 0.09664433253403136
Trained batch 549 in epoch 1, gen_loss = 0.4419994074648077, disc_loss = 0.09650262804871255
Trained batch 550 in epoch 1, gen_loss = 0.44205101794426327, disc_loss = 0.0964663211195417
Trained batch 551 in epoch 1, gen_loss = 0.4421076700091362, disc_loss = 0.09636113627314352
Trained batch 552 in epoch 1, gen_loss = 0.44218237706161967, disc_loss = 0.0962250839049842
Trained batch 553 in epoch 1, gen_loss = 0.4421367750701491, disc_loss = 0.09608835673854024
Trained batch 554 in epoch 1, gen_loss = 0.4420894678111549, disc_loss = 0.09598408389735866
Trained batch 555 in epoch 1, gen_loss = 0.44196428717683545, disc_loss = 0.09587795832093886
Trained batch 556 in epoch 1, gen_loss = 0.4419513594098322, disc_loss = 0.09579015363348879
Trained batch 557 in epoch 1, gen_loss = 0.44198593791026797, disc_loss = 0.0957092741657863
Trained batch 558 in epoch 1, gen_loss = 0.4418237953045287, disc_loss = 0.09576912078346678
Trained batch 559 in epoch 1, gen_loss = 0.44188027887472087, disc_loss = 0.09562862527423671
Trained batch 560 in epoch 1, gen_loss = 0.4418301251376589, disc_loss = 0.09552599819055003
Trained batch 561 in epoch 1, gen_loss = 0.44182213138643106, disc_loss = 0.09551445132260646
Trained batch 562 in epoch 1, gen_loss = 0.441826050224355, disc_loss = 0.09536997944970167
Trained batch 563 in epoch 1, gen_loss = 0.44186372066854585, disc_loss = 0.09537308326433577
Trained batch 564 in epoch 1, gen_loss = 0.4417990129078384, disc_loss = 0.09536505292903269
Trained batch 565 in epoch 1, gen_loss = 0.44200092169716165, disc_loss = 0.09552696962139895
Trained batch 566 in epoch 1, gen_loss = 0.4419305987353888, disc_loss = 0.095657454821654
Trained batch 567 in epoch 1, gen_loss = 0.4420197645438389, disc_loss = 0.0955578625730147
Trained batch 568 in epoch 1, gen_loss = 0.4419513021600686, disc_loss = 0.09548928236559374
Trained batch 569 in epoch 1, gen_loss = 0.4419167644622033, disc_loss = 0.09535232098903834
Trained batch 570 in epoch 1, gen_loss = 0.4418055355653245, disc_loss = 0.09537068134803331
Trained batch 571 in epoch 1, gen_loss = 0.44188774851235474, disc_loss = 0.09533172425279927
Trained batch 572 in epoch 1, gen_loss = 0.4418551944209227, disc_loss = 0.09523926302303039
Trained batch 573 in epoch 1, gen_loss = 0.44183762174242464, disc_loss = 0.09510120269371918
Trained batch 574 in epoch 1, gen_loss = 0.44196745411209437, disc_loss = 0.095005230937639
Trained batch 575 in epoch 1, gen_loss = 0.442098558621688, disc_loss = 0.09487862041472302
Trained batch 576 in epoch 1, gen_loss = 0.4422020431304515, disc_loss = 0.09475364305395342
Trained batch 577 in epoch 1, gen_loss = 0.44217996985029595, disc_loss = 0.09475278464278084
Trained batch 578 in epoch 1, gen_loss = 0.442127055197388, disc_loss = 0.09464062732485137
Trained batch 579 in epoch 1, gen_loss = 0.442087936041684, disc_loss = 0.09474033569628051
Trained batch 580 in epoch 1, gen_loss = 0.4422390718981239, disc_loss = 0.09498147233172918
Trained batch 581 in epoch 1, gen_loss = 0.4422479609853214, disc_loss = 0.09497848643578871
Trained batch 582 in epoch 1, gen_loss = 0.4421876266624261, disc_loss = 0.09486304092385502
Trained batch 583 in epoch 1, gen_loss = 0.4422762521019537, disc_loss = 0.09475655329879373
Trained batch 584 in epoch 1, gen_loss = 0.4422370034405309, disc_loss = 0.09470359822337189
Trained batch 585 in epoch 1, gen_loss = 0.44215137620834766, disc_loss = 0.09461172562531187
Trained batch 586 in epoch 1, gen_loss = 0.4421102233497613, disc_loss = 0.09449341984741783
Trained batch 587 in epoch 1, gen_loss = 0.44200872766728305, disc_loss = 0.09453186661568883
Trained batch 588 in epoch 1, gen_loss = 0.4420099028707158, disc_loss = 0.09458975279023824
Trained batch 589 in epoch 1, gen_loss = 0.4421005270743774, disc_loss = 0.09451544858294271
Trained batch 590 in epoch 1, gen_loss = 0.44210046590282226, disc_loss = 0.09451648933488352
Trained batch 591 in epoch 1, gen_loss = 0.44192970589407393, disc_loss = 0.09452953014831134
Trained batch 592 in epoch 1, gen_loss = 0.441953662173543, disc_loss = 0.09444712252084411
Trained batch 593 in epoch 1, gen_loss = 0.4419962167739868, disc_loss = 0.09441659345075187
Trained batch 594 in epoch 1, gen_loss = 0.44187961811778925, disc_loss = 0.0943879224062592
Trained batch 595 in epoch 1, gen_loss = 0.44185367851649354, disc_loss = 0.09443851711772282
Trained batch 596 in epoch 1, gen_loss = 0.44175932744839286, disc_loss = 0.09433877110712142
Trained batch 597 in epoch 1, gen_loss = 0.44155290254382384, disc_loss = 0.09450163711703392
Trained batch 598 in epoch 1, gen_loss = 0.44152428033156865, disc_loss = 0.09541777111683196
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.38676944375038147, disc_loss = 0.1361839771270752
Trained batch 1 in epoch 2, gen_loss = 0.4114777147769928, disc_loss = 0.10215992853045464
Trained batch 2 in epoch 2, gen_loss = 0.41534727811813354, disc_loss = 0.09363353500763576
Trained batch 3 in epoch 2, gen_loss = 0.41824421286582947, disc_loss = 0.09660576470196247
Trained batch 4 in epoch 2, gen_loss = 0.41931797862052916, disc_loss = 0.09215062111616135
Trained batch 5 in epoch 2, gen_loss = 0.40707624951998395, disc_loss = 0.08798065781593323
Trained batch 6 in epoch 2, gen_loss = 0.40370810883385794, disc_loss = 0.08206259139946528
Trained batch 7 in epoch 2, gen_loss = 0.4169827848672867, disc_loss = 0.08393317181617022
Trained batch 8 in epoch 2, gen_loss = 0.41515445709228516, disc_loss = 0.08750419235891765
Trained batch 9 in epoch 2, gen_loss = 0.4134954571723938, disc_loss = 0.08340642713010311
Trained batch 10 in epoch 2, gen_loss = 0.41978195580569183, disc_loss = 0.07973429933190346
Trained batch 11 in epoch 2, gen_loss = 0.42217690745989483, disc_loss = 0.08022124040871859
Trained batch 12 in epoch 2, gen_loss = 0.41463953715104324, disc_loss = 0.07622652400571567
Trained batch 13 in epoch 2, gen_loss = 0.41006696224212646, disc_loss = 0.07642750934298549
Trained batch 14 in epoch 2, gen_loss = 0.41247302293777466, disc_loss = 0.07607393525540829
Trained batch 15 in epoch 2, gen_loss = 0.4191443510353565, disc_loss = 0.07493122026789933
Trained batch 16 in epoch 2, gen_loss = 0.41877565138480244, disc_loss = 0.07663626410067081
Trained batch 17 in epoch 2, gen_loss = 0.4185471269819472, disc_loss = 0.07596963281846708
Trained batch 18 in epoch 2, gen_loss = 0.41922131494471904, disc_loss = 0.07506843587677729
Trained batch 19 in epoch 2, gen_loss = 0.4200979366898537, disc_loss = 0.07462168605998158
Trained batch 20 in epoch 2, gen_loss = 0.42184531972521827, disc_loss = 0.07394156613875003
Trained batch 21 in epoch 2, gen_loss = 0.41914986073970795, disc_loss = 0.07346946652978659
Trained batch 22 in epoch 2, gen_loss = 0.4210571335709613, disc_loss = 0.07159659266471863
Trained batch 23 in epoch 2, gen_loss = 0.4230423979461193, disc_loss = 0.06993565832575162
Trained batch 24 in epoch 2, gen_loss = 0.4226571154594421, disc_loss = 0.06860621452331543
Trained batch 25 in epoch 2, gen_loss = 0.42251376234568083, disc_loss = 0.06689799347749123
Trained batch 26 in epoch 2, gen_loss = 0.42153252054143836, disc_loss = 0.06521677301713714
Trained batch 27 in epoch 2, gen_loss = 0.42188932320901323, disc_loss = 0.06513184036261269
Trained batch 28 in epoch 2, gen_loss = 0.422027836585867, disc_loss = 0.06353182660351539
Trained batch 29 in epoch 2, gen_loss = 0.42805867989857993, disc_loss = 0.06933217576394478
Trained batch 30 in epoch 2, gen_loss = 0.4268955386454059, disc_loss = 0.0721538747630773
Trained batch 31 in epoch 2, gen_loss = 0.42840834707021713, disc_loss = 0.07239037012914196
Trained batch 32 in epoch 2, gen_loss = 0.4283754121173512, disc_loss = 0.07176081966044325
Trained batch 33 in epoch 2, gen_loss = 0.4291955732247409, disc_loss = 0.07015292708049803
Trained batch 34 in epoch 2, gen_loss = 0.42938071148736134, disc_loss = 0.06871820720178741
Trained batch 35 in epoch 2, gen_loss = 0.4297643303871155, disc_loss = 0.06775905771387948
Trained batch 36 in epoch 2, gen_loss = 0.43002242333180196, disc_loss = 0.06734998584599108
Trained batch 37 in epoch 2, gen_loss = 0.4303754544571826, disc_loss = 0.0660203886463454
Trained batch 38 in epoch 2, gen_loss = 0.4342645246248979, disc_loss = 0.0664222697990063
Trained batch 39 in epoch 2, gen_loss = 0.43388830944895745, disc_loss = 0.06589425234124065
Trained batch 40 in epoch 2, gen_loss = 0.4337692297086483, disc_loss = 0.06550884464891946
Trained batch 41 in epoch 2, gen_loss = 0.43589638315495993, disc_loss = 0.06441989164089873
Trained batch 42 in epoch 2, gen_loss = 0.43488508254982705, disc_loss = 0.06329172498784787
Trained batch 43 in epoch 2, gen_loss = 0.4350793876431205, disc_loss = 0.06259810056706722
Trained batch 44 in epoch 2, gen_loss = 0.4347973214255439, disc_loss = 0.06307643863062064
Trained batch 45 in epoch 2, gen_loss = 0.43372782870479254, disc_loss = 0.06327879376223554
Trained batch 46 in epoch 2, gen_loss = 0.4353993554064568, disc_loss = 0.062148820628669665
Trained batch 47 in epoch 2, gen_loss = 0.4364386163651943, disc_loss = 0.06232678061739231
Trained batch 48 in epoch 2, gen_loss = 0.4362644553184509, disc_loss = 0.06355903444013425
Trained batch 49 in epoch 2, gen_loss = 0.4370068830251694, disc_loss = 0.0626937180198729
Trained batch 50 in epoch 2, gen_loss = 0.4377416389829972, disc_loss = 0.06170192439401267
Trained batch 51 in epoch 2, gen_loss = 0.4395898781143702, disc_loss = 0.06078989325592724
Trained batch 52 in epoch 2, gen_loss = 0.4403495929151211, disc_loss = 0.05986499833821688
Trained batch 53 in epoch 2, gen_loss = 0.4408836618617729, disc_loss = 0.05897732373947898
Trained batch 54 in epoch 2, gen_loss = 0.44078307531096717, disc_loss = 0.058018666929142045
Trained batch 55 in epoch 2, gen_loss = 0.4418304865913732, disc_loss = 0.05718268229559596
Trained batch 56 in epoch 2, gen_loss = 0.44099670700859606, disc_loss = 0.056633581538080124
Trained batch 57 in epoch 2, gen_loss = 0.4411399605973014, disc_loss = 0.05605507923033217
Trained batch 58 in epoch 2, gen_loss = 0.440865084276361, disc_loss = 0.05532395460848081
Trained batch 59 in epoch 2, gen_loss = 0.44044402142365774, disc_loss = 0.05482895017291109
Trained batch 60 in epoch 2, gen_loss = 0.44128166945254216, disc_loss = 0.05404720456934855
Trained batch 61 in epoch 2, gen_loss = 0.4413752507778906, disc_loss = 0.054042457167299524
Trained batch 62 in epoch 2, gen_loss = 0.4431795913075644, disc_loss = 0.053307016069690384
Trained batch 63 in epoch 2, gen_loss = 0.44395802496001124, disc_loss = 0.05317756117437966
Trained batch 64 in epoch 2, gen_loss = 0.4451758114191202, disc_loss = 0.05251086405836619
Trained batch 65 in epoch 2, gen_loss = 0.44530598548325623, disc_loss = 0.05201787114933585
Trained batch 66 in epoch 2, gen_loss = 0.4448753003753833, disc_loss = 0.051426350750696306
Trained batch 67 in epoch 2, gen_loss = 0.4462783937068546, disc_loss = 0.05109388615442988
Trained batch 68 in epoch 2, gen_loss = 0.4461995440980662, disc_loss = 0.0504532085556159
Trained batch 69 in epoch 2, gen_loss = 0.44697932771274024, disc_loss = 0.04986755984303142
Trained batch 70 in epoch 2, gen_loss = 0.447373757479896, disc_loss = 0.04930621868943874
Trained batch 71 in epoch 2, gen_loss = 0.44700698802868527, disc_loss = 0.04873490926628518
Trained batch 72 in epoch 2, gen_loss = 0.4477506998467119, disc_loss = 0.04821808835848758
Trained batch 73 in epoch 2, gen_loss = 0.4478960343309351, disc_loss = 0.04778055610714128
Trained batch 74 in epoch 2, gen_loss = 0.44822046597798665, disc_loss = 0.04723711276426911
Trained batch 75 in epoch 2, gen_loss = 0.4485208474491772, disc_loss = 0.04671112569294086
Trained batch 76 in epoch 2, gen_loss = 0.44845890844023073, disc_loss = 0.04622486833628122
Trained batch 77 in epoch 2, gen_loss = 0.44926181741249865, disc_loss = 0.04583816108508752
Trained batch 78 in epoch 2, gen_loss = 0.4495371625393252, disc_loss = 0.04532501343166149
Trained batch 79 in epoch 2, gen_loss = 0.44964047707617283, disc_loss = 0.04482213111477904
Trained batch 80 in epoch 2, gen_loss = 0.4493499817671599, disc_loss = 0.04440410608241772
Trained batch 81 in epoch 2, gen_loss = 0.449463525923287, disc_loss = 0.04405295563202987
Trained batch 82 in epoch 2, gen_loss = 0.4492465236100806, disc_loss = 0.04359542171706457
Trained batch 83 in epoch 2, gen_loss = 0.4492880396899723, disc_loss = 0.043154803880800806
Trained batch 84 in epoch 2, gen_loss = 0.4491475350716535, disc_loss = 0.04314036183059215
Trained batch 85 in epoch 2, gen_loss = 0.4485748884982841, disc_loss = 0.042989661635527775
Trained batch 86 in epoch 2, gen_loss = 0.44894072002378005, disc_loss = 0.04266977977093266
Trained batch 87 in epoch 2, gen_loss = 0.448581492358988, disc_loss = 0.04235594134396789
Trained batch 88 in epoch 2, gen_loss = 0.4488233920563473, disc_loss = 0.041961867974422286
Trained batch 89 in epoch 2, gen_loss = 0.44833212130599553, disc_loss = 0.04156128850558566
Trained batch 90 in epoch 2, gen_loss = 0.4475716070814447, disc_loss = 0.041772188347569864
Trained batch 91 in epoch 2, gen_loss = 0.44856833958107495, disc_loss = 0.0421718447621021
Trained batch 92 in epoch 2, gen_loss = 0.44826885448989046, disc_loss = 0.04206534510638605
Trained batch 93 in epoch 2, gen_loss = 0.4485663571890364, disc_loss = 0.04179435002894953
Trained batch 94 in epoch 2, gen_loss = 0.4484514628586016, disc_loss = 0.04167248037594714
Trained batch 95 in epoch 2, gen_loss = 0.44793339477231103, disc_loss = 0.04130121822527144
Trained batch 96 in epoch 2, gen_loss = 0.44740374678188993, disc_loss = 0.04166117392614791
Trained batch 97 in epoch 2, gen_loss = 0.44677629762766313, disc_loss = 0.04149475769253866
Trained batch 98 in epoch 2, gen_loss = 0.447678009668986, disc_loss = 0.04141663846023606
Trained batch 99 in epoch 2, gen_loss = 0.4470938366651535, disc_loss = 0.04116271882783622
Trained batch 100 in epoch 2, gen_loss = 0.4465511494343824, disc_loss = 0.04113736715038667
Trained batch 101 in epoch 2, gen_loss = 0.4465584345892364, disc_loss = 0.040814897944858555
Trained batch 102 in epoch 2, gen_loss = 0.44691372293870424, disc_loss = 0.040858899636501536
Trained batch 103 in epoch 2, gen_loss = 0.4469844965407482, disc_loss = 0.04055826312665326
Trained batch 104 in epoch 2, gen_loss = 0.4475140886647361, disc_loss = 0.040346767811015954
Trained batch 105 in epoch 2, gen_loss = 0.447098452527568, disc_loss = 0.04026505578186293
Trained batch 106 in epoch 2, gen_loss = 0.447959617476597, disc_loss = 0.04009300200964942
Trained batch 107 in epoch 2, gen_loss = 0.44784062383351503, disc_loss = 0.0398815240305676
Trained batch 108 in epoch 2, gen_loss = 0.44695799449168216, disc_loss = 0.0397445493582807
Trained batch 109 in epoch 2, gen_loss = 0.4466689388860356, disc_loss = 0.04012819464657117
Trained batch 110 in epoch 2, gen_loss = 0.4476619419213888, disc_loss = 0.04200550474578867
Trained batch 111 in epoch 2, gen_loss = 0.44724913792950766, disc_loss = 0.04200167335719535
Trained batch 112 in epoch 2, gen_loss = 0.4472582305954621, disc_loss = 0.04202632975673913
Trained batch 113 in epoch 2, gen_loss = 0.4471781868160817, disc_loss = 0.04237327176113531
Trained batch 114 in epoch 2, gen_loss = 0.4467993591142737, disc_loss = 0.042322632220938156
Trained batch 115 in epoch 2, gen_loss = 0.4466766005960004, disc_loss = 0.04238062891868297
Trained batch 116 in epoch 2, gen_loss = 0.4468060449147836, disc_loss = 0.04242661646686685
Trained batch 117 in epoch 2, gen_loss = 0.44708013761851745, disc_loss = 0.04258952577503682
Trained batch 118 in epoch 2, gen_loss = 0.44698700759591176, disc_loss = 0.042681897642137874
Trained batch 119 in epoch 2, gen_loss = 0.4473050927122434, disc_loss = 0.04264824837834264
Trained batch 120 in epoch 2, gen_loss = 0.44724774163616593, disc_loss = 0.04241953645101633
Trained batch 121 in epoch 2, gen_loss = 0.4478223978495989, disc_loss = 0.04225799964633999
Trained batch 122 in epoch 2, gen_loss = 0.4478730738647585, disc_loss = 0.04206584225507165
Trained batch 123 in epoch 2, gen_loss = 0.44788946259406304, disc_loss = 0.041770915662299
Trained batch 124 in epoch 2, gen_loss = 0.44771594715118407, disc_loss = 0.041611914288252595
Trained batch 125 in epoch 2, gen_loss = 0.4480575273434321, disc_loss = 0.04175324023642119
Trained batch 126 in epoch 2, gen_loss = 0.44802788979425207, disc_loss = 0.04154112851100526
Trained batch 127 in epoch 2, gen_loss = 0.4485909140203148, disc_loss = 0.041375732584128855
Trained batch 128 in epoch 2, gen_loss = 0.44845321936200755, disc_loss = 0.04172883310911152
Trained batch 129 in epoch 2, gen_loss = 0.44854530462851894, disc_loss = 0.04157736233722132
Trained batch 130 in epoch 2, gen_loss = 0.4485993239715809, disc_loss = 0.04182510050582408
Trained batch 131 in epoch 2, gen_loss = 0.44832546625173453, disc_loss = 0.04230641049798578
Trained batch 132 in epoch 2, gen_loss = 0.4483542065871389, disc_loss = 0.04211482751232229
Trained batch 133 in epoch 2, gen_loss = 0.44825848892553527, disc_loss = 0.04207372391221127
Trained batch 134 in epoch 2, gen_loss = 0.4489104288595694, disc_loss = 0.04329209684704741
Trained batch 135 in epoch 2, gen_loss = 0.4490565074717297, disc_loss = 0.04445790941484601
Trained batch 136 in epoch 2, gen_loss = 0.4484108729954184, disc_loss = 0.04488589330134492
Trained batch 137 in epoch 2, gen_loss = 0.44839680000491766, disc_loss = 0.04613556824557051
Trained batch 138 in epoch 2, gen_loss = 0.4483034625756655, disc_loss = 0.046655610186992574
Trained batch 139 in epoch 2, gen_loss = 0.44763643613883425, disc_loss = 0.046902065122100926
Trained batch 140 in epoch 2, gen_loss = 0.4475742610211068, disc_loss = 0.046879663095802916
Trained batch 141 in epoch 2, gen_loss = 0.44762710429413216, disc_loss = 0.04675809974441121
Trained batch 142 in epoch 2, gen_loss = 0.4472939853484814, disc_loss = 0.04669615077636354
Trained batch 143 in epoch 2, gen_loss = 0.4474616532938348, disc_loss = 0.04812727965246369
Trained batch 144 in epoch 2, gen_loss = 0.4471548183210965, disc_loss = 0.04855547042178183
Trained batch 145 in epoch 2, gen_loss = 0.4468982660607116, disc_loss = 0.048449451496110185
Trained batch 146 in epoch 2, gen_loss = 0.44708218217707, disc_loss = 0.048647216853818724
Trained batch 147 in epoch 2, gen_loss = 0.44780079053865895, disc_loss = 0.04894861735944712
Trained batch 148 in epoch 2, gen_loss = 0.4480882085009709, disc_loss = 0.04905117449081884
Trained batch 149 in epoch 2, gen_loss = 0.44783368209997815, disc_loss = 0.049282895335927605
Trained batch 150 in epoch 2, gen_loss = 0.4477343955971547, disc_loss = 0.04927245200309434
Trained batch 151 in epoch 2, gen_loss = 0.44766783969182716, disc_loss = 0.050247729642586295
Trained batch 152 in epoch 2, gen_loss = 0.4479545181483225, disc_loss = 0.05019019362425395
Trained batch 153 in epoch 2, gen_loss = 0.44803390468095805, disc_loss = 0.050248356956335435
Trained batch 154 in epoch 2, gen_loss = 0.4480644114555851, disc_loss = 0.050334371395048594
Trained batch 155 in epoch 2, gen_loss = 0.44809920378984547, disc_loss = 0.05011636782616664
Trained batch 156 in epoch 2, gen_loss = 0.44851197995198, disc_loss = 0.049898890182257266
Trained batch 157 in epoch 2, gen_loss = 0.4483070058535926, disc_loss = 0.04974982205813727
Trained batch 158 in epoch 2, gen_loss = 0.4480393890689754, disc_loss = 0.04952519425372564
Trained batch 159 in epoch 2, gen_loss = 0.44779024217277763, disc_loss = 0.04933746599999722
Trained batch 160 in epoch 2, gen_loss = 0.4477046472685678, disc_loss = 0.04909081251782753
Trained batch 161 in epoch 2, gen_loss = 0.44777835427243035, disc_loss = 0.04888092391020446
Trained batch 162 in epoch 2, gen_loss = 0.4482094358447139, disc_loss = 0.048671522329167174
Trained batch 163 in epoch 2, gen_loss = 0.4476166600134315, disc_loss = 0.0486524470644526
Trained batch 164 in epoch 2, gen_loss = 0.44772279912775215, disc_loss = 0.04844719653271816
Trained batch 165 in epoch 2, gen_loss = 0.44743683772632875, disc_loss = 0.04818164084263774
Trained batch 166 in epoch 2, gen_loss = 0.44723599935006236, disc_loss = 0.04792516950718657
Trained batch 167 in epoch 2, gen_loss = 0.4474009158355849, disc_loss = 0.04768082129192494
Trained batch 168 in epoch 2, gen_loss = 0.447183401450603, disc_loss = 0.04745595428828128
Trained batch 169 in epoch 2, gen_loss = 0.44709154016831343, disc_loss = 0.04720130091094795
Trained batch 170 in epoch 2, gen_loss = 0.44707668071601825, disc_loss = 0.04697711064823364
Trained batch 171 in epoch 2, gen_loss = 0.44708210888297056, disc_loss = 0.04674744010134058
Trained batch 172 in epoch 2, gen_loss = 0.44706136022689025, disc_loss = 0.0466407844931361
Trained batch 173 in epoch 2, gen_loss = 0.44725838115160493, disc_loss = 0.04680586156392491
Trained batch 174 in epoch 2, gen_loss = 0.447599766765322, disc_loss = 0.04673589452835066
Trained batch 175 in epoch 2, gen_loss = 0.4471961608664556, disc_loss = 0.04652896479819901
Trained batch 176 in epoch 2, gen_loss = 0.4470266127316965, disc_loss = 0.046419697637422444
Trained batch 177 in epoch 2, gen_loss = 0.4470834820792916, disc_loss = 0.04628005714595234
Trained batch 178 in epoch 2, gen_loss = 0.44692459286258207, disc_loss = 0.046192258635442185
Trained batch 179 in epoch 2, gen_loss = 0.44726058542728425, disc_loss = 0.04628175678921657
Trained batch 180 in epoch 2, gen_loss = 0.4472121718180114, disc_loss = 0.04620280067143108
Trained batch 181 in epoch 2, gen_loss = 0.44724431273701426, disc_loss = 0.04602056165266741
Trained batch 182 in epoch 2, gen_loss = 0.44736297632175714, disc_loss = 0.045805770794408084
Trained batch 183 in epoch 2, gen_loss = 0.44735730147880054, disc_loss = 0.04559468555405898
Trained batch 184 in epoch 2, gen_loss = 0.44744362444491, disc_loss = 0.04544829769009674
Trained batch 185 in epoch 2, gen_loss = 0.4473418490861052, disc_loss = 0.0454005299246199
Trained batch 186 in epoch 2, gen_loss = 0.4473309131229625, disc_loss = 0.04519230685381089
Trained batch 187 in epoch 2, gen_loss = 0.44741378122187675, disc_loss = 0.04526973682445811
Trained batch 188 in epoch 2, gen_loss = 0.4476167833994305, disc_loss = 0.045199283455355614
Trained batch 189 in epoch 2, gen_loss = 0.44727866273177297, disc_loss = 0.045059785033625205
Trained batch 190 in epoch 2, gen_loss = 0.44770681982889227, disc_loss = 0.044896825292289104
Trained batch 191 in epoch 2, gen_loss = 0.44790444476529956, disc_loss = 0.04469791695252449
Trained batch 192 in epoch 2, gen_loss = 0.4478038798033265, disc_loss = 0.044510628446608476
Trained batch 193 in epoch 2, gen_loss = 0.4477183404042549, disc_loss = 0.0443174232171906
Trained batch 194 in epoch 2, gen_loss = 0.4475409929568951, disc_loss = 0.04414171119913077
Trained batch 195 in epoch 2, gen_loss = 0.44716558939948375, disc_loss = 0.043942826752531895
Trained batch 196 in epoch 2, gen_loss = 0.44702991298612604, disc_loss = 0.04376197226704831
Trained batch 197 in epoch 2, gen_loss = 0.4473118461442716, disc_loss = 0.043566793038726154
Trained batch 198 in epoch 2, gen_loss = 0.44734898239523924, disc_loss = 0.04355176823241776
Trained batch 199 in epoch 2, gen_loss = 0.4473421357572079, disc_loss = 0.0434088819520548
Trained batch 200 in epoch 2, gen_loss = 0.4472330905015196, disc_loss = 0.043347925730790965
Trained batch 201 in epoch 2, gen_loss = 0.4475691432114875, disc_loss = 0.04320194924914158
Trained batch 202 in epoch 2, gen_loss = 0.4479231401323685, disc_loss = 0.043074921145117635
Trained batch 203 in epoch 2, gen_loss = 0.4481827886957748, disc_loss = 0.04301516527730022
Trained batch 204 in epoch 2, gen_loss = 0.44823366810635823, disc_loss = 0.04285511851038148
Trained batch 205 in epoch 2, gen_loss = 0.4482934165348127, disc_loss = 0.04279170856693561
Trained batch 206 in epoch 2, gen_loss = 0.44842332313602096, disc_loss = 0.042662453315792166
Trained batch 207 in epoch 2, gen_loss = 0.44837459463339585, disc_loss = 0.042494020268070296
Trained batch 208 in epoch 2, gen_loss = 0.4485907794185803, disc_loss = 0.042322929070718836
Trained batch 209 in epoch 2, gen_loss = 0.44829022274130864, disc_loss = 0.04227642822744591
Trained batch 210 in epoch 2, gen_loss = 0.44828948152573755, disc_loss = 0.04219854802723038
Trained batch 211 in epoch 2, gen_loss = 0.4482124814728521, disc_loss = 0.04203504364814539
Trained batch 212 in epoch 2, gen_loss = 0.4483337119711397, disc_loss = 0.041885121253279735
Trained batch 213 in epoch 2, gen_loss = 0.4485047792441377, disc_loss = 0.04177525395388219
Trained batch 214 in epoch 2, gen_loss = 0.448327430458956, disc_loss = 0.04162496127361475
Trained batch 215 in epoch 2, gen_loss = 0.44823700672498457, disc_loss = 0.04152661989684458
Trained batch 216 in epoch 2, gen_loss = 0.44875636312269396, disc_loss = 0.041415940935847946
Trained batch 217 in epoch 2, gen_loss = 0.44924080768309604, disc_loss = 0.04132538685284623
Trained batch 218 in epoch 2, gen_loss = 0.4493875224568528, disc_loss = 0.041169634590682375
Trained batch 219 in epoch 2, gen_loss = 0.4495946928858757, disc_loss = 0.04121528079902584
Trained batch 220 in epoch 2, gen_loss = 0.44993312339976904, disc_loss = 0.04105957918189365
Trained batch 221 in epoch 2, gen_loss = 0.44979296785754125, disc_loss = 0.04097167629463313
Trained batch 222 in epoch 2, gen_loss = 0.44975947037406033, disc_loss = 0.04081497994155493
Trained batch 223 in epoch 2, gen_loss = 0.45006795107786146, disc_loss = 0.04084405962826817
Trained batch 224 in epoch 2, gen_loss = 0.45050495717260575, disc_loss = 0.04072229366749525
Trained batch 225 in epoch 2, gen_loss = 0.45082531500179157, disc_loss = 0.04065761788937766
Trained batch 226 in epoch 2, gen_loss = 0.45111654915473537, disc_loss = 0.0405338340508649
Trained batch 227 in epoch 2, gen_loss = 0.451433326983661, disc_loss = 0.04054907610509218
Trained batch 228 in epoch 2, gen_loss = 0.4513714796330731, disc_loss = 0.04042509100582922
Trained batch 229 in epoch 2, gen_loss = 0.4513210183900336, disc_loss = 0.04034243350767571
Trained batch 230 in epoch 2, gen_loss = 0.4516212611229389, disc_loss = 0.04019370304976965
Trained batch 231 in epoch 2, gen_loss = 0.45153733150198544, disc_loss = 0.04004208519171666
Trained batch 232 in epoch 2, gen_loss = 0.45154521930882857, disc_loss = 0.039889392764767224
Trained batch 233 in epoch 2, gen_loss = 0.45173935770479023, disc_loss = 0.03974619470178508
Trained batch 234 in epoch 2, gen_loss = 0.45199092943617636, disc_loss = 0.03971207643403335
Trained batch 235 in epoch 2, gen_loss = 0.45156915410090304, disc_loss = 0.03956128232441527
Trained batch 236 in epoch 2, gen_loss = 0.45151275647843436, disc_loss = 0.03949750656702159
Trained batch 237 in epoch 2, gen_loss = 0.4513999669491744, disc_loss = 0.03935041287992181
Trained batch 238 in epoch 2, gen_loss = 0.45129162073135376, disc_loss = 0.03926301395294556
Trained batch 239 in epoch 2, gen_loss = 0.4512034857024749, disc_loss = 0.03912300799856894
Trained batch 240 in epoch 2, gen_loss = 0.45125043206689763, disc_loss = 0.03901190011031709
Trained batch 241 in epoch 2, gen_loss = 0.45121423666142235, disc_loss = 0.03888952384764437
Trained batch 242 in epoch 2, gen_loss = 0.45116893474947767, disc_loss = 0.038747454759638006
Trained batch 243 in epoch 2, gen_loss = 0.451036090000731, disc_loss = 0.03865040691004547
Trained batch 244 in epoch 2, gen_loss = 0.45103234040493867, disc_loss = 0.038513778796305465
Trained batch 245 in epoch 2, gen_loss = 0.4511991260739846, disc_loss = 0.0384088017924772
Trained batch 246 in epoch 2, gen_loss = 0.4511962814128351, disc_loss = 0.03830448999955707
Trained batch 247 in epoch 2, gen_loss = 0.4512521739928953, disc_loss = 0.0381689103275177
Trained batch 248 in epoch 2, gen_loss = 0.45140119250040933, disc_loss = 0.03806239722603296
Trained batch 249 in epoch 2, gen_loss = 0.45116701602935794, disc_loss = 0.037956958204507826
Trained batch 250 in epoch 2, gen_loss = 0.4511234913451738, disc_loss = 0.03789192059659863
Trained batch 251 in epoch 2, gen_loss = 0.45101938988008194, disc_loss = 0.03779179959129247
Trained batch 252 in epoch 2, gen_loss = 0.4512349050271181, disc_loss = 0.03775864439048315
Trained batch 253 in epoch 2, gen_loss = 0.4512379117838041, disc_loss = 0.03764590413463632
Trained batch 254 in epoch 2, gen_loss = 0.4512904404425154, disc_loss = 0.03759131871309935
Trained batch 255 in epoch 2, gen_loss = 0.4515371647430584, disc_loss = 0.03747582570576924
Trained batch 256 in epoch 2, gen_loss = 0.45125735455449917, disc_loss = 0.03737450530208966
Trained batch 257 in epoch 2, gen_loss = 0.4515454618967781, disc_loss = 0.03729279636759167
Trained batch 258 in epoch 2, gen_loss = 0.4514939393776264, disc_loss = 0.03718280429775651
Trained batch 259 in epoch 2, gen_loss = 0.4515390172600746, disc_loss = 0.037120122441019004
Trained batch 260 in epoch 2, gen_loss = 0.45163201897537114, disc_loss = 0.037012074267584474
Trained batch 261 in epoch 2, gen_loss = 0.4515057567876714, disc_loss = 0.036893450024089856
Trained batch 262 in epoch 2, gen_loss = 0.4513879952095307, disc_loss = 0.03689577053885326
Trained batch 263 in epoch 2, gen_loss = 0.45164276806242537, disc_loss = 0.03689094624573817
Trained batch 264 in epoch 2, gen_loss = 0.45166543665921915, disc_loss = 0.036804984118086546
Trained batch 265 in epoch 2, gen_loss = 0.4518189056027204, disc_loss = 0.03676403587144848
Trained batch 266 in epoch 2, gen_loss = 0.4516154999813337, disc_loss = 0.03675011609775129
Trained batch 267 in epoch 2, gen_loss = 0.45174275472092984, disc_loss = 0.036676362950924725
Trained batch 268 in epoch 2, gen_loss = 0.4514830012746903, disc_loss = 0.036575336492236106
Trained batch 269 in epoch 2, gen_loss = 0.4512924517746325, disc_loss = 0.03649460043654674
Trained batch 270 in epoch 2, gen_loss = 0.4513126657897696, disc_loss = 0.03644821999896991
Trained batch 271 in epoch 2, gen_loss = 0.45138586422099786, disc_loss = 0.03644739918116316
Trained batch 272 in epoch 2, gen_loss = 0.45110244497711405, disc_loss = 0.03639767405102814
Trained batch 273 in epoch 2, gen_loss = 0.4511478831515695, disc_loss = 0.0362918042615192
Trained batch 274 in epoch 2, gen_loss = 0.45137556412003255, disc_loss = 0.03628851782361215
Trained batch 275 in epoch 2, gen_loss = 0.4514716493262761, disc_loss = 0.03657247901023568
Trained batch 276 in epoch 2, gen_loss = 0.4512861729313751, disc_loss = 0.03695287932187911
Trained batch 277 in epoch 2, gen_loss = 0.45138251717142064, disc_loss = 0.036885015286250614
Trained batch 278 in epoch 2, gen_loss = 0.4515092461553526, disc_loss = 0.03681714015789196
Trained batch 279 in epoch 2, gen_loss = 0.4514166952243873, disc_loss = 0.03686013229889795
Trained batch 280 in epoch 2, gen_loss = 0.4515197059650014, disc_loss = 0.03676175163873203
Trained batch 281 in epoch 2, gen_loss = 0.45128265213459096, disc_loss = 0.03666902979314063
Trained batch 282 in epoch 2, gen_loss = 0.45133960162792947, disc_loss = 0.03661921276635237
Trained batch 283 in epoch 2, gen_loss = 0.4513511119384161, disc_loss = 0.03653066630744126
Trained batch 284 in epoch 2, gen_loss = 0.45150302387120433, disc_loss = 0.03644965618946835
Trained batch 285 in epoch 2, gen_loss = 0.45142972979929064, disc_loss = 0.036356960050436066
Trained batch 286 in epoch 2, gen_loss = 0.45137536151899277, disc_loss = 0.03629515928667337
Trained batch 287 in epoch 2, gen_loss = 0.4515056624594662, disc_loss = 0.03627447472050941
Trained batch 288 in epoch 2, gen_loss = 0.4516758159782647, disc_loss = 0.0361796028728381
Trained batch 289 in epoch 2, gen_loss = 0.4514900200325867, disc_loss = 0.0361049333763919
Trained batch 290 in epoch 2, gen_loss = 0.4514879839322002, disc_loss = 0.03608262990649367
Trained batch 291 in epoch 2, gen_loss = 0.45148026565574617, disc_loss = 0.035994095815511495
Trained batch 292 in epoch 2, gen_loss = 0.45125039364290725, disc_loss = 0.03615851559018265
Trained batch 293 in epoch 2, gen_loss = 0.4514236474523739, disc_loss = 0.03611001638271117
Trained batch 294 in epoch 2, gen_loss = 0.4516406909894135, disc_loss = 0.03601781557140461
Trained batch 295 in epoch 2, gen_loss = 0.45184207224362605, disc_loss = 0.0359629548038356
Trained batch 296 in epoch 2, gen_loss = 0.45208773869858043, disc_loss = 0.035985101188410716
Trained batch 297 in epoch 2, gen_loss = 0.4519080555679014, disc_loss = 0.03595091974919024
Trained batch 298 in epoch 2, gen_loss = 0.4518027633528247, disc_loss = 0.03586828040058746
Trained batch 299 in epoch 2, gen_loss = 0.45163953681786856, disc_loss = 0.03584484878151367
Trained batch 300 in epoch 2, gen_loss = 0.45164363200086294, disc_loss = 0.03580748582370208
Trained batch 301 in epoch 2, gen_loss = 0.45147923108757726, disc_loss = 0.03585144259892897
Trained batch 302 in epoch 2, gen_loss = 0.45146774458806505, disc_loss = 0.035815449491475186
Trained batch 303 in epoch 2, gen_loss = 0.45166233319200966, disc_loss = 0.03597726967449202
Trained batch 304 in epoch 2, gen_loss = 0.45129635128818574, disc_loss = 0.03636323927336785
Trained batch 305 in epoch 2, gen_loss = 0.4511750346305324, disc_loss = 0.03647796673779345
Trained batch 306 in epoch 2, gen_loss = 0.45139960182606204, disc_loss = 0.037049866756211955
Trained batch 307 in epoch 2, gen_loss = 0.4512678136105661, disc_loss = 0.03730783880500776
Trained batch 308 in epoch 2, gen_loss = 0.45083159893076014, disc_loss = 0.03743414188249935
Trained batch 309 in epoch 2, gen_loss = 0.4506473579714375, disc_loss = 0.03739659321614571
Trained batch 310 in epoch 2, gen_loss = 0.45083398642647304, disc_loss = 0.03733008469745421
Trained batch 311 in epoch 2, gen_loss = 0.45086285892205363, disc_loss = 0.03726599883520976
Trained batch 312 in epoch 2, gen_loss = 0.4508845426213627, disc_loss = 0.03721017120167994
Trained batch 313 in epoch 2, gen_loss = 0.45095240794549324, disc_loss = 0.037186266485138966
Trained batch 314 in epoch 2, gen_loss = 0.4513247927976033, disc_loss = 0.03726324959258948
Trained batch 315 in epoch 2, gen_loss = 0.4512707968301411, disc_loss = 0.03719270164058603
Trained batch 316 in epoch 2, gen_loss = 0.45101426903757763, disc_loss = 0.03722088919858498
Trained batch 317 in epoch 2, gen_loss = 0.450916570125136, disc_loss = 0.03730214201646078
Trained batch 318 in epoch 2, gen_loss = 0.4508868710934929, disc_loss = 0.03745838592914999
Trained batch 319 in epoch 2, gen_loss = 0.45094211073592305, disc_loss = 0.037662152615666855
Trained batch 320 in epoch 2, gen_loss = 0.4509228506934977, disc_loss = 0.037679267178269284
Trained batch 321 in epoch 2, gen_loss = 0.451003750103601, disc_loss = 0.0376305728876003
Trained batch 322 in epoch 2, gen_loss = 0.4508116242501758, disc_loss = 0.037567675224687014
Trained batch 323 in epoch 2, gen_loss = 0.45098071379794014, disc_loss = 0.037493111429172624
Trained batch 324 in epoch 2, gen_loss = 0.450853319809987, disc_loss = 0.03780582691757725
Trained batch 325 in epoch 2, gen_loss = 0.45105093818135056, disc_loss = 0.03816649822969607
Trained batch 326 in epoch 2, gen_loss = 0.451000008470057, disc_loss = 0.038092097550892594
Trained batch 327 in epoch 2, gen_loss = 0.4506027660355335, disc_loss = 0.038539464237656806
Trained batch 328 in epoch 2, gen_loss = 0.4506917843159209, disc_loss = 0.038574481347581444
Trained batch 329 in epoch 2, gen_loss = 0.450981189716946, disc_loss = 0.03863993211875134
Trained batch 330 in epoch 2, gen_loss = 0.45104710996331043, disc_loss = 0.038654340215848924
Trained batch 331 in epoch 2, gen_loss = 0.4508805590939809, disc_loss = 0.038708426668420885
Trained batch 332 in epoch 2, gen_loss = 0.45073569715918005, disc_loss = 0.03909436618215642
Trained batch 333 in epoch 2, gen_loss = 0.4504418793374193, disc_loss = 0.03921329768090146
Trained batch 334 in epoch 2, gen_loss = 0.4500927986493751, disc_loss = 0.03937035961799435
Trained batch 335 in epoch 2, gen_loss = 0.4500281045302039, disc_loss = 0.03933172917874929
Trained batch 336 in epoch 2, gen_loss = 0.45007592899509286, disc_loss = 0.03931957374821563
Trained batch 337 in epoch 2, gen_loss = 0.45008272029591734, disc_loss = 0.039294441096958586
Trained batch 338 in epoch 2, gen_loss = 0.4502058396648868, disc_loss = 0.03931655404418927
Trained batch 339 in epoch 2, gen_loss = 0.4498992457109339, disc_loss = 0.03939482266603805
Trained batch 340 in epoch 2, gen_loss = 0.44960589676308843, disc_loss = 0.039421086364816275
Trained batch 341 in epoch 2, gen_loss = 0.44985346618103006, disc_loss = 0.039720682474942495
Trained batch 342 in epoch 2, gen_loss = 0.4499666282456401, disc_loss = 0.03965406549236474
Trained batch 343 in epoch 2, gen_loss = 0.4501713034371997, disc_loss = 0.03960069503261556
Trained batch 344 in epoch 2, gen_loss = 0.45016646972600965, disc_loss = 0.03952665795855548
Trained batch 345 in epoch 2, gen_loss = 0.4500306426961987, disc_loss = 0.03945687762461603
Trained batch 346 in epoch 2, gen_loss = 0.4500959092155314, disc_loss = 0.03959704203778067
Trained batch 347 in epoch 2, gen_loss = 0.450213681435448, disc_loss = 0.03965469062644132
Trained batch 348 in epoch 2, gen_loss = 0.450184828657817, disc_loss = 0.03959316188565597
Trained batch 349 in epoch 2, gen_loss = 0.4500030346427645, disc_loss = 0.03961818312294781
Trained batch 350 in epoch 2, gen_loss = 0.4502337879774577, disc_loss = 0.040082962386193355
Trained batch 351 in epoch 2, gen_loss = 0.4500086627561938, disc_loss = 0.040167631225565194
Trained batch 352 in epoch 2, gen_loss = 0.44991973709452254, disc_loss = 0.04034156943658214
Trained batch 353 in epoch 2, gen_loss = 0.45004937919856464, disc_loss = 0.04036547315549
Trained batch 354 in epoch 2, gen_loss = 0.45000733103550655, disc_loss = 0.04036194648934712
Trained batch 355 in epoch 2, gen_loss = 0.4497535956207286, disc_loss = 0.04043282878590392
Trained batch 356 in epoch 2, gen_loss = 0.4496934792073835, disc_loss = 0.0405047928499637
Trained batch 357 in epoch 2, gen_loss = 0.44953406056878287, disc_loss = 0.04059682316510995
Trained batch 358 in epoch 2, gen_loss = 0.44953751929291114, disc_loss = 0.040708170133619506
Trained batch 359 in epoch 2, gen_loss = 0.44948023160298667, disc_loss = 0.04089635555089141
Trained batch 360 in epoch 2, gen_loss = 0.44929191552701087, disc_loss = 0.0409850579959926
Trained batch 361 in epoch 2, gen_loss = 0.44926624395241394, disc_loss = 0.04098108799186489
Trained batch 362 in epoch 2, gen_loss = 0.44944790547544305, disc_loss = 0.04104392203186785
Trained batch 363 in epoch 2, gen_loss = 0.4493269810637275, disc_loss = 0.041112234113625364
Trained batch 364 in epoch 2, gen_loss = 0.44940852792295694, disc_loss = 0.0417343423523213
Trained batch 365 in epoch 2, gen_loss = 0.4493316153033835, disc_loss = 0.042023578438592335
Trained batch 366 in epoch 2, gen_loss = 0.44917334595882924, disc_loss = 0.042013106490827956
Trained batch 367 in epoch 2, gen_loss = 0.4491045373775389, disc_loss = 0.04212827412993647
Trained batch 368 in epoch 2, gen_loss = 0.4490545885511207, disc_loss = 0.04249198148582323
Trained batch 369 in epoch 2, gen_loss = 0.44904523773773297, disc_loss = 0.04285384174310476
Trained batch 370 in epoch 2, gen_loss = 0.4489733835436263, disc_loss = 0.04321063881629521
Trained batch 371 in epoch 2, gen_loss = 0.4486541492483949, disc_loss = 0.04341388372979778
Trained batch 372 in epoch 2, gen_loss = 0.44881661767614434, disc_loss = 0.04354569798675004
Trained batch 373 in epoch 2, gen_loss = 0.4487073980072603, disc_loss = 0.04360165723280752
Trained batch 374 in epoch 2, gen_loss = 0.4488089222113291, disc_loss = 0.043651788745075464
Trained batch 375 in epoch 2, gen_loss = 0.44876791275245076, disc_loss = 0.043677887248935454
Trained batch 376 in epoch 2, gen_loss = 0.4487089283902702, disc_loss = 0.043651421476570536
Trained batch 377 in epoch 2, gen_loss = 0.44871931101279283, disc_loss = 0.04361368854599142
Trained batch 378 in epoch 2, gen_loss = 0.4486799001850994, disc_loss = 0.04356707029393567
Trained batch 379 in epoch 2, gen_loss = 0.44862239847057744, disc_loss = 0.043624288219909525
Trained batch 380 in epoch 2, gen_loss = 0.4487667302759926, disc_loss = 0.04369071484213387
Trained batch 381 in epoch 2, gen_loss = 0.4487365220541729, disc_loss = 0.04367980527135675
Trained batch 382 in epoch 2, gen_loss = 0.4486486393540086, disc_loss = 0.04373947190918398
Trained batch 383 in epoch 2, gen_loss = 0.4488912519688408, disc_loss = 0.04389735261186919
Trained batch 384 in epoch 2, gen_loss = 0.4488241148459447, disc_loss = 0.04401190931509648
Trained batch 385 in epoch 2, gen_loss = 0.44890343170091895, disc_loss = 0.044234168618058525
Trained batch 386 in epoch 2, gen_loss = 0.44868761639878424, disc_loss = 0.04417858919061393
Trained batch 387 in epoch 2, gen_loss = 0.44873521261915716, disc_loss = 0.04460181658199422
Trained batch 388 in epoch 2, gen_loss = 0.4489241382609909, disc_loss = 0.04488782333162228
Trained batch 389 in epoch 2, gen_loss = 0.4489195155791747, disc_loss = 0.04485789055410677
Trained batch 390 in epoch 2, gen_loss = 0.44868715210338994, disc_loss = 0.04497358566292983
Trained batch 391 in epoch 2, gen_loss = 0.44873777830174993, disc_loss = 0.04490378753125326
Trained batch 392 in epoch 2, gen_loss = 0.44876841954299207, disc_loss = 0.0449577024474304
Trained batch 393 in epoch 2, gen_loss = 0.44847687995675856, disc_loss = 0.04500697416414124
Trained batch 394 in epoch 2, gen_loss = 0.44840260630921475, disc_loss = 0.044995004668407425
Trained batch 395 in epoch 2, gen_loss = 0.44830596251319155, disc_loss = 0.04506206658617076
Trained batch 396 in epoch 2, gen_loss = 0.44835749148421683, disc_loss = 0.04498001598455106
Trained batch 397 in epoch 2, gen_loss = 0.44844773861032033, disc_loss = 0.04494817732206204
Trained batch 398 in epoch 2, gen_loss = 0.4483958714289175, disc_loss = 0.044917544255495295
Trained batch 399 in epoch 2, gen_loss = 0.4483767196536064, disc_loss = 0.04486310573644005
Trained batch 400 in epoch 2, gen_loss = 0.448463286396274, disc_loss = 0.04478888769989411
Trained batch 401 in epoch 2, gen_loss = 0.4484372580822428, disc_loss = 0.044747574471483996
Trained batch 402 in epoch 2, gen_loss = 0.4485174777637936, disc_loss = 0.04472910293329405
Trained batch 403 in epoch 2, gen_loss = 0.4487750411476239, disc_loss = 0.04481849517318245
Trained batch 404 in epoch 2, gen_loss = 0.44868706479484655, disc_loss = 0.045064312958928904
Trained batch 405 in epoch 2, gen_loss = 0.44869630280973877, disc_loss = 0.045185013746457364
Trained batch 406 in epoch 2, gen_loss = 0.4484757157889279, disc_loss = 0.04532169620563672
Trained batch 407 in epoch 2, gen_loss = 0.4485447037892014, disc_loss = 0.04534336989722671
Trained batch 408 in epoch 2, gen_loss = 0.44860610256568145, disc_loss = 0.045351432052311146
Trained batch 409 in epoch 2, gen_loss = 0.44871749267345523, disc_loss = 0.04559420078606685
Trained batch 410 in epoch 2, gen_loss = 0.4486812712067235, disc_loss = 0.046154693098752385
Trained batch 411 in epoch 2, gen_loss = 0.4488672111364244, disc_loss = 0.04654805619355508
Trained batch 412 in epoch 2, gen_loss = 0.448825231548083, disc_loss = 0.04662395072379319
Trained batch 413 in epoch 2, gen_loss = 0.44869640887071544, disc_loss = 0.04664287694891834
Trained batch 414 in epoch 2, gen_loss = 0.4488303806408342, disc_loss = 0.046627208234809606
Trained batch 415 in epoch 2, gen_loss = 0.4488308817291489, disc_loss = 0.046616191916445344
Trained batch 416 in epoch 2, gen_loss = 0.44881096761003675, disc_loss = 0.046584273837015425
Trained batch 417 in epoch 2, gen_loss = 0.44875564215856306, disc_loss = 0.046493755376109024
Trained batch 418 in epoch 2, gen_loss = 0.44891916297216117, disc_loss = 0.04641593128180482
Trained batch 419 in epoch 2, gen_loss = 0.44892589620181494, disc_loss = 0.04632059207319149
Trained batch 420 in epoch 2, gen_loss = 0.4489923855046478, disc_loss = 0.04624130277100269
Trained batch 421 in epoch 2, gen_loss = 0.4490171037437792, disc_loss = 0.04618942610239742
Trained batch 422 in epoch 2, gen_loss = 0.449109569861252, disc_loss = 0.04615187703744105
Trained batch 423 in epoch 2, gen_loss = 0.44913819137046923, disc_loss = 0.04609314773785267
Trained batch 424 in epoch 2, gen_loss = 0.44907433040001815, disc_loss = 0.04605697952430038
Trained batch 425 in epoch 2, gen_loss = 0.44893420267273004, disc_loss = 0.045983297330602795
Trained batch 426 in epoch 2, gen_loss = 0.44879040903732426, disc_loss = 0.0459389007918589
Trained batch 427 in epoch 2, gen_loss = 0.44895414639020637, disc_loss = 0.04584641393630931
Trained batch 428 in epoch 2, gen_loss = 0.4489378112874109, disc_loss = 0.04576919033975799
Trained batch 429 in epoch 2, gen_loss = 0.4488804907992829, disc_loss = 0.04569917825635436
Trained batch 430 in epoch 2, gen_loss = 0.4489385039651477, disc_loss = 0.045616128486246216
Trained batch 431 in epoch 2, gen_loss = 0.4489402137696743, disc_loss = 0.045547503850819474
Trained batch 432 in epoch 2, gen_loss = 0.44907063906517647, disc_loss = 0.04547007092625316
Trained batch 433 in epoch 2, gen_loss = 0.4490101024989159, disc_loss = 0.04541221997284326
Trained batch 434 in epoch 2, gen_loss = 0.44893218683100294, disc_loss = 0.04540905691897389
Trained batch 435 in epoch 2, gen_loss = 0.4492111709823302, disc_loss = 0.04546850793055096
Trained batch 436 in epoch 2, gen_loss = 0.4492808182806936, disc_loss = 0.045442172194014835
Trained batch 437 in epoch 2, gen_loss = 0.4490916308474867, disc_loss = 0.045527629109873485
Trained batch 438 in epoch 2, gen_loss = 0.4490297239842339, disc_loss = 0.04553223808416948
Trained batch 439 in epoch 2, gen_loss = 0.4489195821637457, disc_loss = 0.04567960381973535
Trained batch 440 in epoch 2, gen_loss = 0.4490769491309211, disc_loss = 0.04564401274863757
Trained batch 441 in epoch 2, gen_loss = 0.44918296590649703, disc_loss = 0.04559860508931101
Trained batch 442 in epoch 2, gen_loss = 0.44920573439070655, disc_loss = 0.04556935953930794
Trained batch 443 in epoch 2, gen_loss = 0.4492470392504254, disc_loss = 0.0455272377338596
Trained batch 444 in epoch 2, gen_loss = 0.4493256084704667, disc_loss = 0.04545227445117878
Trained batch 445 in epoch 2, gen_loss = 0.44947594050067424, disc_loss = 0.04538846723192409
Trained batch 446 in epoch 2, gen_loss = 0.4495796032533283, disc_loss = 0.04530549175428931
Trained batch 447 in epoch 2, gen_loss = 0.4496820511828576, disc_loss = 0.045241586458619816
Trained batch 448 in epoch 2, gen_loss = 0.4498258973814066, disc_loss = 0.04515820839971237
Trained batch 449 in epoch 2, gen_loss = 0.45001332998275756, disc_loss = 0.04507195511211952
Trained batch 450 in epoch 2, gen_loss = 0.4499542632547027, disc_loss = 0.044984304949129104
Trained batch 451 in epoch 2, gen_loss = 0.44999803075220735, disc_loss = 0.04490444860915629
Trained batch 452 in epoch 2, gen_loss = 0.4503479768372003, disc_loss = 0.04488871638636387
Trained batch 453 in epoch 2, gen_loss = 0.45050017279675353, disc_loss = 0.04480592348091797
Trained batch 454 in epoch 2, gen_loss = 0.4505970090300172, disc_loss = 0.04482602492220454
Trained batch 455 in epoch 2, gen_loss = 0.4504978088825418, disc_loss = 0.04490205768512137
Trained batch 456 in epoch 2, gen_loss = 0.4505572368592611, disc_loss = 0.04482975713011994
Trained batch 457 in epoch 2, gen_loss = 0.45073882877566407, disc_loss = 0.04484948245035769
Trained batch 458 in epoch 2, gen_loss = 0.45061467130199756, disc_loss = 0.044803320026443154
Trained batch 459 in epoch 2, gen_loss = 0.45070434905912565, disc_loss = 0.04477789327097328
Trained batch 460 in epoch 2, gen_loss = 0.45070206272110763, disc_loss = 0.04475688404623831
Trained batch 461 in epoch 2, gen_loss = 0.450698071808526, disc_loss = 0.04470299349218865
Trained batch 462 in epoch 2, gen_loss = 0.45066120853691843, disc_loss = 0.04468782669733848
Trained batch 463 in epoch 2, gen_loss = 0.45080965641757537, disc_loss = 0.044698257573302196
Trained batch 464 in epoch 2, gen_loss = 0.45085632108872936, disc_loss = 0.04465534911360792
Trained batch 465 in epoch 2, gen_loss = 0.45092011259093306, disc_loss = 0.044581580251583215
Trained batch 466 in epoch 2, gen_loss = 0.4506933317705191, disc_loss = 0.04473523762101024
Trained batch 467 in epoch 2, gen_loss = 0.45055586717322343, disc_loss = 0.04480100413545584
Trained batch 468 in epoch 2, gen_loss = 0.45069526501301765, disc_loss = 0.04505021870136261
Trained batch 469 in epoch 2, gen_loss = 0.45057656111869404, disc_loss = 0.04502418494605003
Trained batch 470 in epoch 2, gen_loss = 0.45047828118512584, disc_loss = 0.04499378407298886
Trained batch 471 in epoch 2, gen_loss = 0.45051388625623817, disc_loss = 0.044917580188188894
Trained batch 472 in epoch 2, gen_loss = 0.4505136437698348, disc_loss = 0.04488583102263116
Trained batch 473 in epoch 2, gen_loss = 0.450457488308476, disc_loss = 0.044864057356939664
Trained batch 474 in epoch 2, gen_loss = 0.45038675766242176, disc_loss = 0.04493428700260426
Trained batch 475 in epoch 2, gen_loss = 0.4504582561364695, disc_loss = 0.0448753706692178
Trained batch 476 in epoch 2, gen_loss = 0.4505586321123991, disc_loss = 0.044868868064970965
Trained batch 477 in epoch 2, gen_loss = 0.45058980634022955, disc_loss = 0.0448057031917491
Trained batch 478 in epoch 2, gen_loss = 0.4506325416251364, disc_loss = 0.04484351360217701
Trained batch 479 in epoch 2, gen_loss = 0.4508170267567039, disc_loss = 0.04501469201835183
Trained batch 480 in epoch 2, gen_loss = 0.4509013617980505, disc_loss = 0.045247886335697964
Trained batch 481 in epoch 2, gen_loss = 0.4508118854518748, disc_loss = 0.0452802178905929
Trained batch 482 in epoch 2, gen_loss = 0.4508408759074675, disc_loss = 0.045240641775970994
Trained batch 483 in epoch 2, gen_loss = 0.45079369128735597, disc_loss = 0.04570616944308185
Trained batch 484 in epoch 2, gen_loss = 0.450578350443201, disc_loss = 0.04600083830468741
Trained batch 485 in epoch 2, gen_loss = 0.4507040568462615, disc_loss = 0.04597186006858577
Trained batch 486 in epoch 2, gen_loss = 0.45049907570012543, disc_loss = 0.046238873630104246
Trained batch 487 in epoch 2, gen_loss = 0.45049278267094345, disc_loss = 0.04637390853966907
Trained batch 488 in epoch 2, gen_loss = 0.4504660809820171, disc_loss = 0.04646783021368193
Trained batch 489 in epoch 2, gen_loss = 0.45043106723804865, disc_loss = 0.04639989564347328
Trained batch 490 in epoch 2, gen_loss = 0.45044262874150715, disc_loss = 0.046421510831295476
Trained batch 491 in epoch 2, gen_loss = 0.4504082858320174, disc_loss = 0.046441300365150096
Trained batch 492 in epoch 2, gen_loss = 0.4503430557903847, disc_loss = 0.04638458092642181
Trained batch 493 in epoch 2, gen_loss = 0.45037667887654864, disc_loss = 0.046329306233071
Trained batch 494 in epoch 2, gen_loss = 0.45037276473912324, disc_loss = 0.046286353557323565
Trained batch 495 in epoch 2, gen_loss = 0.45034817696338697, disc_loss = 0.04624348665369795
Trained batch 496 in epoch 2, gen_loss = 0.4502896417674404, disc_loss = 0.04654563414551303
Trained batch 497 in epoch 2, gen_loss = 0.4504283584624409, disc_loss = 0.04656194162977687
Trained batch 498 in epoch 2, gen_loss = 0.45044464476122886, disc_loss = 0.046573608805740886
Trained batch 499 in epoch 2, gen_loss = 0.45038418024778365, disc_loss = 0.04691786899231374
Trained batch 500 in epoch 2, gen_loss = 0.4503045632929621, disc_loss = 0.046844174871648735
Trained batch 501 in epoch 2, gen_loss = 0.45046489872780454, disc_loss = 0.04685761754872255
Trained batch 502 in epoch 2, gen_loss = 0.45044702457386265, disc_loss = 0.04683553193979128
Trained batch 503 in epoch 2, gen_loss = 0.45033580248081495, disc_loss = 0.04684968120307617
Trained batch 504 in epoch 2, gen_loss = 0.4502167240817948, disc_loss = 0.04684206776800427
Trained batch 505 in epoch 2, gen_loss = 0.45028504941303266, disc_loss = 0.0468780555902233
Trained batch 506 in epoch 2, gen_loss = 0.45032936569736787, disc_loss = 0.04687331813613515
Trained batch 507 in epoch 2, gen_loss = 0.450306528841886, disc_loss = 0.04679294889352805
Trained batch 508 in epoch 2, gen_loss = 0.4502942794549676, disc_loss = 0.046724097140879904
Trained batch 509 in epoch 2, gen_loss = 0.4501549426247092, disc_loss = 0.04669008164429197
Trained batch 510 in epoch 2, gen_loss = 0.45009826581538775, disc_loss = 0.046669752820014024
Trained batch 511 in epoch 2, gen_loss = 0.45016812288668007, disc_loss = 0.04716463103250135
Trained batch 512 in epoch 2, gen_loss = 0.4500574029212342, disc_loss = 0.047127071528406866
Trained batch 513 in epoch 2, gen_loss = 0.4498344170444207, disc_loss = 0.04728165645775628
Trained batch 514 in epoch 2, gen_loss = 0.4498859022427531, disc_loss = 0.047261209062580925
Trained batch 515 in epoch 2, gen_loss = 0.44967525440824124, disc_loss = 0.04727532150036143
Trained batch 516 in epoch 2, gen_loss = 0.449644530764862, disc_loss = 0.047231164161022215
Trained batch 517 in epoch 2, gen_loss = 0.4496217450580081, disc_loss = 0.047281501210621885
Trained batch 518 in epoch 2, gen_loss = 0.4497006733638014, disc_loss = 0.04721438880787305
Trained batch 519 in epoch 2, gen_loss = 0.44974285215139387, disc_loss = 0.04720232569469282
Trained batch 520 in epoch 2, gen_loss = 0.4498931666024587, disc_loss = 0.047192172899899465
Trained batch 521 in epoch 2, gen_loss = 0.449935476270672, disc_loss = 0.04712134660703355
Trained batch 522 in epoch 2, gen_loss = 0.4500027815766818, disc_loss = 0.047052491352987794
Trained batch 523 in epoch 2, gen_loss = 0.45011752212548073, disc_loss = 0.04698904943545811
Trained batch 524 in epoch 2, gen_loss = 0.4501113807019733, disc_loss = 0.04692993166546027
Trained batch 525 in epoch 2, gen_loss = 0.45012892074458044, disc_loss = 0.04686511478638241
Trained batch 526 in epoch 2, gen_loss = 0.45000818417013483, disc_loss = 0.0468768457576378
Trained batch 527 in epoch 2, gen_loss = 0.4499646303893039, disc_loss = 0.046852527567270125
Trained batch 528 in epoch 2, gen_loss = 0.4498507937659388, disc_loss = 0.04685218427999258
Trained batch 529 in epoch 2, gen_loss = 0.4499583081816727, disc_loss = 0.04704059656217413
Trained batch 530 in epoch 2, gen_loss = 0.45000966844585655, disc_loss = 0.04702912315922717
Trained batch 531 in epoch 2, gen_loss = 0.45001264297424404, disc_loss = 0.046958749333074444
Trained batch 532 in epoch 2, gen_loss = 0.4499689240504832, disc_loss = 0.047034443686340584
Trained batch 533 in epoch 2, gen_loss = 0.4497674185126908, disc_loss = 0.04731561704312036
Trained batch 534 in epoch 2, gen_loss = 0.44975211358516015, disc_loss = 0.047462216719427956
Trained batch 535 in epoch 2, gen_loss = 0.4496876575719954, disc_loss = 0.047465874664068444
Trained batch 536 in epoch 2, gen_loss = 0.4495463634891439, disc_loss = 0.04753776357007981
Trained batch 537 in epoch 2, gen_loss = 0.4495663052930265, disc_loss = 0.04749400220936005
Trained batch 538 in epoch 2, gen_loss = 0.44968455958012526, disc_loss = 0.04748097506864947
Trained batch 539 in epoch 2, gen_loss = 0.44970339089632033, disc_loss = 0.04747577604527275
Trained batch 540 in epoch 2, gen_loss = 0.449675910243706, disc_loss = 0.047447159772742255
Trained batch 542 in epoch 2, gen_loss = 0.4496011050695872, disc_loss = 0.047369173935461875
Trained batch 543 in epoch 2, gen_loss = 0.44958018078742656, disc_loss = 0.04730877579833545
Trained batch 544 in epoch 2, gen_loss = 0.44971376783257233, disc_loss = 0.04731931609503173
Trained batch 545 in epoch 2, gen_loss = 0.449562050756954, disc_loss = 0.04728001568657465
Trained batch 546 in epoch 2, gen_loss = 0.44960305628654507, disc_loss = 0.04722265554234467
Trained batch 547 in epoch 2, gen_loss = 0.44948149907545454, disc_loss = 0.04718095070961183
Trained batch 548 in epoch 2, gen_loss = 0.44947983001533537, disc_loss = 0.0471304364651713
Trained batch 549 in epoch 2, gen_loss = 0.4495224638960578, disc_loss = 0.047056920057670634
Trained batch 550 in epoch 2, gen_loss = 0.44948760264581866, disc_loss = 0.04700784267225521
Trained batch 551 in epoch 2, gen_loss = 0.44937897214423056, disc_loss = 0.04698688670169508
Trained batch 552 in epoch 2, gen_loss = 0.44928060356143584, disc_loss = 0.04694108540700853
Trained batch 553 in epoch 2, gen_loss = 0.449310379445768, disc_loss = 0.04687625475375769
Trained batch 554 in epoch 2, gen_loss = 0.4492619302358713, disc_loss = 0.04685233029629196
Trained batch 555 in epoch 2, gen_loss = 0.44931574176541333, disc_loss = 0.046798422758420596
Trained batch 556 in epoch 2, gen_loss = 0.44932748909698567, disc_loss = 0.04679485390387489
Trained batch 557 in epoch 2, gen_loss = 0.449333415129706, disc_loss = 0.04675633798763957
Trained batch 558 in epoch 2, gen_loss = 0.4493552579649446, disc_loss = 0.04671797475216107
Trained batch 559 in epoch 2, gen_loss = 0.44941643481808047, disc_loss = 0.04665080225594076
Trained batch 560 in epoch 2, gen_loss = 0.4493829305159217, disc_loss = 0.04661606902791164
Trained batch 561 in epoch 2, gen_loss = 0.449392849175107, disc_loss = 0.04658791029931865
Trained batch 562 in epoch 2, gen_loss = 0.4494648284641083, disc_loss = 0.04671498249925104
Trained batch 563 in epoch 2, gen_loss = 0.4496000478876398, disc_loss = 0.04700581241458496
Trained batch 564 in epoch 2, gen_loss = 0.44947504111095865, disc_loss = 0.047163535728720965
Trained batch 565 in epoch 2, gen_loss = 0.4493752754829798, disc_loss = 0.04712156280908115
Trained batch 566 in epoch 2, gen_loss = 0.44947706822575295, disc_loss = 0.0470804814692764
Trained batch 567 in epoch 2, gen_loss = 0.44949251245444927, disc_loss = 0.0470245616333428
Trained batch 568 in epoch 2, gen_loss = 0.4494526897981003, disc_loss = 0.04695830682721414
Trained batch 569 in epoch 2, gen_loss = 0.44949032083937995, disc_loss = 0.04689874993310424
Trained batch 570 in epoch 2, gen_loss = 0.4495290882115606, disc_loss = 0.0468380566565695
Trained batch 571 in epoch 2, gen_loss = 0.4495816446476049, disc_loss = 0.0467746321623168
Trained batch 572 in epoch 2, gen_loss = 0.44947279654248223, disc_loss = 0.04672968321127157
Trained batch 573 in epoch 2, gen_loss = 0.44939240641917916, disc_loss = 0.046666491846472855
Trained batch 574 in epoch 2, gen_loss = 0.4495492222516433, disc_loss = 0.04660595770277407
Trained batch 575 in epoch 2, gen_loss = 0.44960320042446256, disc_loss = 0.04656948484706744
Trained batch 576 in epoch 2, gen_loss = 0.44958985574943766, disc_loss = 0.046574422529538646
Trained batch 577 in epoch 2, gen_loss = 0.4497216492375701, disc_loss = 0.046534934633807847
Trained batch 578 in epoch 2, gen_loss = 0.44993225270190595, disc_loss = 0.04647512770449302
Trained batch 579 in epoch 2, gen_loss = 0.45006180703639986, disc_loss = 0.04640810088061824
Trained batch 580 in epoch 2, gen_loss = 0.4501586295856666, disc_loss = 0.04635148935770157
Trained batch 581 in epoch 2, gen_loss = 0.45017349049192934, disc_loss = 0.04629703620576726
Trained batch 582 in epoch 2, gen_loss = 0.4502545529736867, disc_loss = 0.04623530480186383
Trained batch 583 in epoch 2, gen_loss = 0.45025972797446057, disc_loss = 0.04618131324699889
Trained batch 584 in epoch 2, gen_loss = 0.45035008874713867, disc_loss = 0.04612329381589706
Trained batch 585 in epoch 2, gen_loss = 0.45028998567992917, disc_loss = 0.046086096872318114
Trained batch 586 in epoch 2, gen_loss = 0.4503521698398525, disc_loss = 0.04605972110349336
Trained batch 587 in epoch 2, gen_loss = 0.4504496172881451, disc_loss = 0.046053031380256626
Trained batch 588 in epoch 2, gen_loss = 0.4503962374806202, disc_loss = 0.046002586829161404
Trained batch 589 in epoch 2, gen_loss = 0.45034371599302453, disc_loss = 0.045956135803233766
Trained batch 590 in epoch 2, gen_loss = 0.45020933325722334, disc_loss = 0.0458888074110519
Trained batch 591 in epoch 2, gen_loss = 0.4501286928818838, disc_loss = 0.04590511334685583
Trained batch 592 in epoch 2, gen_loss = 0.4501798563522191, disc_loss = 0.04589075973401911
Trained batch 593 in epoch 2, gen_loss = 0.450217696903932, disc_loss = 0.04583448397469164
Trained batch 594 in epoch 2, gen_loss = 0.4501895115656011, disc_loss = 0.04577198391154158
Trained batch 595 in epoch 2, gen_loss = 0.4502283194221106, disc_loss = 0.04571043378470353
Trained batch 596 in epoch 2, gen_loss = 0.4503682075533236, disc_loss = 0.045661011586742635
Trained batch 597 in epoch 2, gen_loss = 0.45046614828117715, disc_loss = 0.04559590653936849
Trained batch 598 in epoch 2, gen_loss = 0.450540491406229, disc_loss = 0.04558606333999532
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.3968845009803772, disc_loss = 0.014240730553865433
Trained batch 1 in epoch 3, gen_loss = 0.4279702752828598, disc_loss = 0.030773838981986046
Trained batch 2 in epoch 3, gen_loss = 0.45503174265225727, disc_loss = 0.1143150565524896
Trained batch 3 in epoch 3, gen_loss = 0.4444301500916481, disc_loss = 0.09253032272681594
Trained batch 4 in epoch 3, gen_loss = 0.43216941952705384, disc_loss = 0.08929948173463345
Trained batch 5 in epoch 3, gen_loss = 0.42922524114449817, disc_loss = 0.08167343866080046
Trained batch 6 in epoch 3, gen_loss = 0.4422747790813446, disc_loss = 0.07127268346292633
Trained batch 7 in epoch 3, gen_loss = 0.4468335844576359, disc_loss = 0.06383855291642249
Trained batch 8 in epoch 3, gen_loss = 0.45057521926032174, disc_loss = 0.05749574965900845
Trained batch 9 in epoch 3, gen_loss = 0.4484366148710251, disc_loss = 0.05269496738910675
Trained batch 10 in epoch 3, gen_loss = 0.45424553751945496, disc_loss = 0.05104865641756491
Trained batch 11 in epoch 3, gen_loss = 0.4604447012146314, disc_loss = 0.04800873203203082
Trained batch 12 in epoch 3, gen_loss = 0.462101739186507, disc_loss = 0.04846045503822657
Trained batch 13 in epoch 3, gen_loss = 0.46043139696121216, disc_loss = 0.0464124313688704
Trained batch 14 in epoch 3, gen_loss = 0.4596369246641795, disc_loss = 0.043734948212901754
Trained batch 15 in epoch 3, gen_loss = 0.45967505499720573, disc_loss = 0.0413393770577386
Trained batch 16 in epoch 3, gen_loss = 0.4602949549170101, disc_loss = 0.03925355707350023
Trained batch 17 in epoch 3, gen_loss = 0.4610287977589501, disc_loss = 0.037461251874143876
Trained batch 18 in epoch 3, gen_loss = 0.4607056708712327, disc_loss = 0.03624432933467783
Trained batch 19 in epoch 3, gen_loss = 0.4600634500384331, disc_loss = 0.035320997587405145
Trained batch 20 in epoch 3, gen_loss = 0.4591961460454123, disc_loss = 0.03389233694456163
Trained batch 21 in epoch 3, gen_loss = 0.4600147848779505, disc_loss = 0.0327095787929879
Trained batch 22 in epoch 3, gen_loss = 0.458684970503268, disc_loss = 0.03298172279787452
Trained batch 23 in epoch 3, gen_loss = 0.4597161337733269, disc_loss = 0.033501353328271456
Trained batch 24 in epoch 3, gen_loss = 0.460573273897171, disc_loss = 0.03276916829869151
Trained batch 25 in epoch 3, gen_loss = 0.4653264960417381, disc_loss = 0.034401196968526795
Trained batch 26 in epoch 3, gen_loss = 0.46360713795379355, disc_loss = 0.03362229388828079
Trained batch 27 in epoch 3, gen_loss = 0.46209463477134705, disc_loss = 0.037362920170250745
Trained batch 28 in epoch 3, gen_loss = 0.4638365815425741, disc_loss = 0.03739494257124847
Trained batch 29 in epoch 3, gen_loss = 0.4647998481988907, disc_loss = 0.03700773472276827
Trained batch 30 in epoch 3, gen_loss = 0.4661457509763779, disc_loss = 0.03615995479987994
Trained batch 31 in epoch 3, gen_loss = 0.4639817727729678, disc_loss = 0.035676460902323015
Trained batch 32 in epoch 3, gen_loss = 0.46356340249379474, disc_loss = 0.034835900222374636
Trained batch 33 in epoch 3, gen_loss = 0.4601317205849816, disc_loss = 0.03424408644273439
Trained batch 34 in epoch 3, gen_loss = 0.4595667583601815, disc_loss = 0.033509538096508806
Trained batch 35 in epoch 3, gen_loss = 0.4601388904783461, disc_loss = 0.03311179582184801
Trained batch 36 in epoch 3, gen_loss = 0.4614164056004705, disc_loss = 0.032750337699277175
Trained batch 37 in epoch 3, gen_loss = 0.4617595703978288, disc_loss = 0.032813770782300515
Trained batch 38 in epoch 3, gen_loss = 0.46297484789139187, disc_loss = 0.03227260523738387
Trained batch 39 in epoch 3, gen_loss = 0.461474034935236, disc_loss = 0.03177350087789819
Trained batch 40 in epoch 3, gen_loss = 0.4614954997853535, disc_loss = 0.03124322609339909
Trained batch 41 in epoch 3, gen_loss = 0.4619334347191311, disc_loss = 0.0307605397954051
Trained batch 42 in epoch 3, gen_loss = 0.46225029853887334, disc_loss = 0.03146629469729094
Trained batch 43 in epoch 3, gen_loss = 0.4604229039766572, disc_loss = 0.033037220731123605
Trained batch 44 in epoch 3, gen_loss = 0.4595968743165334, disc_loss = 0.03268940275948909
Trained batch 45 in epoch 3, gen_loss = 0.45979548666788184, disc_loss = 0.033032886937017676
Trained batch 46 in epoch 3, gen_loss = 0.4597127038113614, disc_loss = 0.032545468878952113
Trained batch 47 in epoch 3, gen_loss = 0.45779085469742614, disc_loss = 0.03357695179875009
Trained batch 48 in epoch 3, gen_loss = 0.45827167922136736, disc_loss = 0.03351808420135355
Trained batch 49 in epoch 3, gen_loss = 0.45959059298038485, disc_loss = 0.03438818295486271
Trained batch 50 in epoch 3, gen_loss = 0.46053509209670274, disc_loss = 0.03385855680258543
Trained batch 51 in epoch 3, gen_loss = 0.4593896481853265, disc_loss = 0.03454317380853284
Trained batch 52 in epoch 3, gen_loss = 0.46091371943365855, disc_loss = 0.0340615112492639
Trained batch 53 in epoch 3, gen_loss = 0.4613069952638061, disc_loss = 0.0340160399209708
Trained batch 54 in epoch 3, gen_loss = 0.4620041245763952, disc_loss = 0.03366488976065408
Trained batch 55 in epoch 3, gen_loss = 0.46041203449879375, disc_loss = 0.03523934325702222
Trained batch 56 in epoch 3, gen_loss = 0.4608185855965865, disc_loss = 0.03504785901066242
Trained batch 57 in epoch 3, gen_loss = 0.4605251499291124, disc_loss = 0.03531128674713445
Trained batch 58 in epoch 3, gen_loss = 0.45866979885909515, disc_loss = 0.03489095410647786
Trained batch 59 in epoch 3, gen_loss = 0.4585096483429273, disc_loss = 0.03537709597342958
Trained batch 60 in epoch 3, gen_loss = 0.4590381862687283, disc_loss = 0.03520227922126651
Trained batch 61 in epoch 3, gen_loss = 0.4587460962995406, disc_loss = 0.034837128136367086
Trained batch 62 in epoch 3, gen_loss = 0.4584649143710969, disc_loss = 0.034523573415797384
Trained batch 63 in epoch 3, gen_loss = 0.4588553528301418, disc_loss = 0.03457777265430195
Trained batch 64 in epoch 3, gen_loss = 0.4588971206775078, disc_loss = 0.03498688190459059
Trained batch 65 in epoch 3, gen_loss = 0.4588101817802949, disc_loss = 0.03473167843185365
Trained batch 66 in epoch 3, gen_loss = 0.4577140354398471, disc_loss = 0.03518524709671958
Trained batch 67 in epoch 3, gen_loss = 0.4582917322130764, disc_loss = 0.035101751954404306
Trained batch 68 in epoch 3, gen_loss = 0.45770527659982874, disc_loss = 0.036263146579427565
Trained batch 69 in epoch 3, gen_loss = 0.45855723789760044, disc_loss = 0.036804374939362915
Trained batch 70 in epoch 3, gen_loss = 0.45857056807464275, disc_loss = 0.036567881250832705
Trained batch 71 in epoch 3, gen_loss = 0.4592901472416189, disc_loss = 0.03627148427767679
Trained batch 72 in epoch 3, gen_loss = 0.4588071899871304, disc_loss = 0.03713204550288924
Trained batch 73 in epoch 3, gen_loss = 0.4579850427202276, disc_loss = 0.036942407457359334
Trained batch 74 in epoch 3, gen_loss = 0.4578772735595703, disc_loss = 0.03677663556610544
Trained batch 75 in epoch 3, gen_loss = 0.4576701157187161, disc_loss = 0.036636489903015136
Trained batch 76 in epoch 3, gen_loss = 0.4582127321076083, disc_loss = 0.036651598815745735
Trained batch 77 in epoch 3, gen_loss = 0.4575326522955528, disc_loss = 0.0363142676352977
Trained batch 78 in epoch 3, gen_loss = 0.4581204686738268, disc_loss = 0.03610203398061516
Trained batch 79 in epoch 3, gen_loss = 0.458380239456892, disc_loss = 0.035968640603823585
Trained batch 80 in epoch 3, gen_loss = 0.4586507729542108, disc_loss = 0.03626951737973241
Trained batch 81 in epoch 3, gen_loss = 0.45956841765380485, disc_loss = 0.0362838374666597
Trained batch 82 in epoch 3, gen_loss = 0.4590841538934822, disc_loss = 0.03598829168624368
Trained batch 83 in epoch 3, gen_loss = 0.4587146423402287, disc_loss = 0.03567436138456244
Trained batch 84 in epoch 3, gen_loss = 0.4593301475048065, disc_loss = 0.035989834768149785
Trained batch 85 in epoch 3, gen_loss = 0.45848495045373605, disc_loss = 0.03678500561888308
Trained batch 86 in epoch 3, gen_loss = 0.4573304475038901, disc_loss = 0.036849353938823805
Trained batch 87 in epoch 3, gen_loss = 0.4577741927721284, disc_loss = 0.036766225477384236
Trained batch 88 in epoch 3, gen_loss = 0.4577852671735742, disc_loss = 0.036642970941081814
Trained batch 89 in epoch 3, gen_loss = 0.45682382749186623, disc_loss = 0.03686507835259868
Trained batch 90 in epoch 3, gen_loss = 0.4570068582728669, disc_loss = 0.03661606375353186
Trained batch 91 in epoch 3, gen_loss = 0.4566064000777576, disc_loss = 0.03691586297835507
Trained batch 92 in epoch 3, gen_loss = 0.4555884875277037, disc_loss = 0.038017163318531805
Trained batch 93 in epoch 3, gen_loss = 0.45526902979992806, disc_loss = 0.03771835850413017
Trained batch 94 in epoch 3, gen_loss = 0.45539160715906246, disc_loss = 0.03743361045949553
Trained batch 95 in epoch 3, gen_loss = 0.4551221951842308, disc_loss = 0.03713286828618342
Trained batch 96 in epoch 3, gen_loss = 0.45514082939354417, disc_loss = 0.03690017980148958
Trained batch 97 in epoch 3, gen_loss = 0.4560307534981747, disc_loss = 0.036625284506768295
Trained batch 98 in epoch 3, gen_loss = 0.4557357475613103, disc_loss = 0.03634292573545768
Trained batch 99 in epoch 3, gen_loss = 0.45533044427633285, disc_loss = 0.03626403985079378
Trained batch 100 in epoch 3, gen_loss = 0.4552104930476387, disc_loss = 0.03612392076226597
Trained batch 101 in epoch 3, gen_loss = 0.45535100821186514, disc_loss = 0.03589930282631779
Trained batch 102 in epoch 3, gen_loss = 0.4552060689740968, disc_loss = 0.035608740550583426
Trained batch 103 in epoch 3, gen_loss = 0.4553370398397629, disc_loss = 0.03534151094320875
Trained batch 104 in epoch 3, gen_loss = 0.45554964797837394, disc_loss = 0.03509790553223519
Trained batch 105 in epoch 3, gen_loss = 0.45536804789642116, disc_loss = 0.03493137801733782
Trained batch 106 in epoch 3, gen_loss = 0.45466308643884745, disc_loss = 0.03474818787180653
Trained batch 107 in epoch 3, gen_loss = 0.45420206034625016, disc_loss = 0.035130745670930656
Trained batch 108 in epoch 3, gen_loss = 0.45298564953541537, disc_loss = 0.0349065956377655
Trained batch 109 in epoch 3, gen_loss = 0.4526877378875559, disc_loss = 0.03478875820609656
Trained batch 110 in epoch 3, gen_loss = 0.4524366468996615, disc_loss = 0.034595389934340574
Trained batch 111 in epoch 3, gen_loss = 0.452852656266519, disc_loss = 0.03448554438572111
Trained batch 112 in epoch 3, gen_loss = 0.45316497414512974, disc_loss = 0.034254999666483
Trained batch 113 in epoch 3, gen_loss = 0.45333329914954673, disc_loss = 0.034012455534059224
Trained batch 114 in epoch 3, gen_loss = 0.4530955838120502, disc_loss = 0.033752842607867456
Trained batch 115 in epoch 3, gen_loss = 0.45328318738731843, disc_loss = 0.033516587075327745
Trained batch 116 in epoch 3, gen_loss = 0.4537423077302101, disc_loss = 0.03332590656832625
Trained batch 117 in epoch 3, gen_loss = 0.4535936210620201, disc_loss = 0.03311134873636824
Trained batch 118 in epoch 3, gen_loss = 0.45355895261804596, disc_loss = 0.03287646039036893
Trained batch 119 in epoch 3, gen_loss = 0.45369159380594887, disc_loss = 0.03263901579193771
Trained batch 120 in epoch 3, gen_loss = 0.45381480258358414, disc_loss = 0.03243530572445925
Trained batch 121 in epoch 3, gen_loss = 0.4535387568786496, disc_loss = 0.03220730813098003
Trained batch 122 in epoch 3, gen_loss = 0.45363046192541356, disc_loss = 0.032015549223415735
Trained batch 123 in epoch 3, gen_loss = 0.4540782210326964, disc_loss = 0.03183526087612394
Trained batch 124 in epoch 3, gen_loss = 0.45418830108642577, disc_loss = 0.03170304688811302
Trained batch 125 in epoch 3, gen_loss = 0.4538125277511657, disc_loss = 0.03148407890417036
Trained batch 126 in epoch 3, gen_loss = 0.4536159911493617, disc_loss = 0.03126589522337702
Trained batch 127 in epoch 3, gen_loss = 0.45341273583471775, disc_loss = 0.03104916365191457
Trained batch 128 in epoch 3, gen_loss = 0.4532422612803851, disc_loss = 0.03083481569954938
Trained batch 129 in epoch 3, gen_loss = 0.4531795561313629, disc_loss = 0.03063269152592581
Trained batch 130 in epoch 3, gen_loss = 0.45263969079228755, disc_loss = 0.030423630988722992
Trained batch 131 in epoch 3, gen_loss = 0.4525692607417251, disc_loss = 0.030229491195782568
Trained batch 132 in epoch 3, gen_loss = 0.45252558208049687, disc_loss = 0.03002589292075009
Trained batch 133 in epoch 3, gen_loss = 0.4516295058958566, disc_loss = 0.02988966931971207
Trained batch 134 in epoch 3, gen_loss = 0.4515507464055662, disc_loss = 0.029727755205843736
Trained batch 135 in epoch 3, gen_loss = 0.45133524585296125, disc_loss = 0.029814251008621583
Trained batch 136 in epoch 3, gen_loss = 0.4509389433112458, disc_loss = 0.029718745481154888
Trained batch 137 in epoch 3, gen_loss = 0.4505699309317962, disc_loss = 0.02958968207678771
Trained batch 138 in epoch 3, gen_loss = 0.4504738797386773, disc_loss = 0.029399773270132944
Trained batch 139 in epoch 3, gen_loss = 0.4507846568311964, disc_loss = 0.02922158987327878
Trained batch 140 in epoch 3, gen_loss = 0.45081918226911666, disc_loss = 0.029105455604718722
Trained batch 141 in epoch 3, gen_loss = 0.4506429142095673, disc_loss = 0.028943783783970375
Trained batch 142 in epoch 3, gen_loss = 0.45044354083654764, disc_loss = 0.028856026552539396
Trained batch 143 in epoch 3, gen_loss = 0.45016356247166794, disc_loss = 0.028699065406625677
Trained batch 144 in epoch 3, gen_loss = 0.45059129390223274, disc_loss = 0.028555212089599206
Trained batch 145 in epoch 3, gen_loss = 0.45063400901343725, disc_loss = 0.02839479204713788
Trained batch 146 in epoch 3, gen_loss = 0.4507365761970987, disc_loss = 0.02826473790024515
Trained batch 147 in epoch 3, gen_loss = 0.4506866654028764, disc_loss = 0.02814206851306497
Trained batch 148 in epoch 3, gen_loss = 0.4507504529600975, disc_loss = 0.027993720899892334
Trained batch 149 in epoch 3, gen_loss = 0.4510080204407374, disc_loss = 0.027839100090786814
Trained batch 150 in epoch 3, gen_loss = 0.4512227110515367, disc_loss = 0.02767928745227539
Trained batch 151 in epoch 3, gen_loss = 0.4513375927743159, disc_loss = 0.027531820300378297
Trained batch 152 in epoch 3, gen_loss = 0.4514142214472777, disc_loss = 0.0273911517259537
Trained batch 153 in epoch 3, gen_loss = 0.4511857166305765, disc_loss = 0.027271106216282426
Trained batch 154 in epoch 3, gen_loss = 0.45083002909537284, disc_loss = 0.027126790850513404
Trained batch 155 in epoch 3, gen_loss = 0.4505694479896472, disc_loss = 0.026985629410960544
Trained batch 156 in epoch 3, gen_loss = 0.45045428917666147, disc_loss = 0.026909123231200087
Trained batch 157 in epoch 3, gen_loss = 0.450524952592729, disc_loss = 0.02679319493177854
Trained batch 158 in epoch 3, gen_loss = 0.4504343454942763, disc_loss = 0.026684042508567467
Trained batch 159 in epoch 3, gen_loss = 0.4505101269111037, disc_loss = 0.026553938814322463
Trained batch 160 in epoch 3, gen_loss = 0.45065490799661007, disc_loss = 0.026416568973489245
Trained batch 161 in epoch 3, gen_loss = 0.4508369024153109, disc_loss = 0.026289848731485783
Trained batch 162 in epoch 3, gen_loss = 0.4507109010877785, disc_loss = 0.026165196437822894
Trained batch 163 in epoch 3, gen_loss = 0.45083379018597486, disc_loss = 0.0260357130432456
Trained batch 164 in epoch 3, gen_loss = 0.4504403634504838, disc_loss = 0.025962086117854624
Trained batch 165 in epoch 3, gen_loss = 0.4504061843975481, disc_loss = 0.025845299859205823
Trained batch 166 in epoch 3, gen_loss = 0.4502710514439794, disc_loss = 0.025730171182309976
Trained batch 167 in epoch 3, gen_loss = 0.4500342784892945, disc_loss = 0.02560682071461564
Trained batch 168 in epoch 3, gen_loss = 0.45027181876481637, disc_loss = 0.025494989357646224
Trained batch 169 in epoch 3, gen_loss = 0.45046563814668095, disc_loss = 0.02537379715427318
Trained batch 170 in epoch 3, gen_loss = 0.45047631737781546, disc_loss = 0.025256751317596228
Trained batch 171 in epoch 3, gen_loss = 0.45061692387558694, disc_loss = 0.025146477233055374
Trained batch 172 in epoch 3, gen_loss = 0.4505071956987326, disc_loss = 0.025022485651441908
Trained batch 173 in epoch 3, gen_loss = 0.4506056712961745, disc_loss = 0.02491466064626972
Trained batch 174 in epoch 3, gen_loss = 0.45104540245873587, disc_loss = 0.0247954030148685
Trained batch 175 in epoch 3, gen_loss = 0.4508279313079335, disc_loss = 0.02473727313388901
Trained batch 176 in epoch 3, gen_loss = 0.451131990568786, disc_loss = 0.024632805640056814
Trained batch 177 in epoch 3, gen_loss = 0.45096715430865125, disc_loss = 0.024539068678728817
Trained batch 178 in epoch 3, gen_loss = 0.4509553791091429, disc_loss = 0.02446760875355015
Trained batch 179 in epoch 3, gen_loss = 0.45087294462654326, disc_loss = 0.02436417100381934
Trained batch 180 in epoch 3, gen_loss = 0.45104598093428006, disc_loss = 0.02433847279148948
Trained batch 181 in epoch 3, gen_loss = 0.4512363806530669, disc_loss = 0.02431624120991718
Trained batch 182 in epoch 3, gen_loss = 0.4511677609766767, disc_loss = 0.024219170449393205
Trained batch 183 in epoch 3, gen_loss = 0.45144627599612525, disc_loss = 0.024144800514003018
Trained batch 184 in epoch 3, gen_loss = 0.4517962455749512, disc_loss = 0.0240422550211283
Trained batch 185 in epoch 3, gen_loss = 0.45179952552882574, disc_loss = 0.02393385829023456
Trained batch 186 in epoch 3, gen_loss = 0.4515708614798153, disc_loss = 0.02387703909354414
Trained batch 187 in epoch 3, gen_loss = 0.4516665276060713, disc_loss = 0.02379781961381594
Trained batch 188 in epoch 3, gen_loss = 0.45159378080140977, disc_loss = 0.023693224878380537
Trained batch 189 in epoch 3, gen_loss = 0.45136180708282875, disc_loss = 0.023598890357013597
Trained batch 190 in epoch 3, gen_loss = 0.45158312192762085, disc_loss = 0.023507228084591204
Trained batch 191 in epoch 3, gen_loss = 0.4517041655878226, disc_loss = 0.023592834295413923
Trained batch 192 in epoch 3, gen_loss = 0.45173685955260084, disc_loss = 0.02366721418980567
Trained batch 193 in epoch 3, gen_loss = 0.45164508149795923, disc_loss = 0.02357838965097884
Trained batch 194 in epoch 3, gen_loss = 0.4517818374511523, disc_loss = 0.023515440100947253
Trained batch 195 in epoch 3, gen_loss = 0.45190904806463084, disc_loss = 0.02348166129941463
Trained batch 196 in epoch 3, gen_loss = 0.4517712930434851, disc_loss = 0.02339612938662244
Trained batch 197 in epoch 3, gen_loss = 0.45142826829293764, disc_loss = 0.0235419006797137
Trained batch 198 in epoch 3, gen_loss = 0.4517465197860296, disc_loss = 0.023549025861930157
Trained batch 199 in epoch 3, gen_loss = 0.4516337242722511, disc_loss = 0.02349399506347254
Trained batch 200 in epoch 3, gen_loss = 0.4513477786856504, disc_loss = 0.023443521535607862
Trained batch 201 in epoch 3, gen_loss = 0.45124513353451645, disc_loss = 0.023380498404125913
Trained batch 202 in epoch 3, gen_loss = 0.45114352256793694, disc_loss = 0.0233126941155367
Trained batch 203 in epoch 3, gen_loss = 0.4508783398013489, disc_loss = 0.023233402819445758
Trained batch 204 in epoch 3, gen_loss = 0.4509139408425587, disc_loss = 0.02337552331524288
Trained batch 205 in epoch 3, gen_loss = 0.45084629055944464, disc_loss = 0.023423126100752395
Trained batch 206 in epoch 3, gen_loss = 0.45073458984278253, disc_loss = 0.023359872389512794
Trained batch 207 in epoch 3, gen_loss = 0.45070149505940765, disc_loss = 0.023304034523719635
Trained batch 208 in epoch 3, gen_loss = 0.45027554163522127, disc_loss = 0.023281417731373932
Trained batch 209 in epoch 3, gen_loss = 0.4503112297682535, disc_loss = 0.02320096547981458
Trained batch 210 in epoch 3, gen_loss = 0.45037763449253065, disc_loss = 0.023188798615523566
Trained batch 211 in epoch 3, gen_loss = 0.4505956544066375, disc_loss = 0.023106692940928042
Trained batch 212 in epoch 3, gen_loss = 0.45075301441228444, disc_loss = 0.023030959684051958
Trained batch 213 in epoch 3, gen_loss = 0.45089433627707937, disc_loss = 0.02302224631421268
Trained batch 214 in epoch 3, gen_loss = 0.45057908019354176, disc_loss = 0.022967861525627763
Trained batch 215 in epoch 3, gen_loss = 0.4505400970854141, disc_loss = 0.022919872782141384
Trained batch 216 in epoch 3, gen_loss = 0.4506070697637198, disc_loss = 0.022877880039491823
Trained batch 217 in epoch 3, gen_loss = 0.4507087366570027, disc_loss = 0.022805388194483217
Trained batch 218 in epoch 3, gen_loss = 0.45073607182938213, disc_loss = 0.022776034569206165
Trained batch 219 in epoch 3, gen_loss = 0.45059147531336, disc_loss = 0.022704729905605993
Trained batch 220 in epoch 3, gen_loss = 0.450154825707906, disc_loss = 0.0226599319660994
Trained batch 221 in epoch 3, gen_loss = 0.45024906837188444, disc_loss = 0.02277202093092775
Trained batch 222 in epoch 3, gen_loss = 0.4499089585558716, disc_loss = 0.022723759647726077
Trained batch 223 in epoch 3, gen_loss = 0.4501026399167521, disc_loss = 0.02268577795101529
Trained batch 224 in epoch 3, gen_loss = 0.45024651567141216, disc_loss = 0.02269654250600272
Trained batch 225 in epoch 3, gen_loss = 0.45065259814789865, disc_loss = 0.02281188704197056
Trained batch 226 in epoch 3, gen_loss = 0.45040718653128536, disc_loss = 0.022992130613061167
Trained batch 227 in epoch 3, gen_loss = 0.4505708954836193, disc_loss = 0.022933397231737904
Trained batch 228 in epoch 3, gen_loss = 0.450828189152297, disc_loss = 0.02292744919665841
Trained batch 229 in epoch 3, gen_loss = 0.4506157741598461, disc_loss = 0.023013493161567526
Trained batch 230 in epoch 3, gen_loss = 0.4506293985492739, disc_loss = 0.02313549378161113
Trained batch 231 in epoch 3, gen_loss = 0.4512467097876401, disc_loss = 0.023780213157116467
Trained batch 232 in epoch 3, gen_loss = 0.45084122360520096, disc_loss = 0.024237190387231725
Trained batch 233 in epoch 3, gen_loss = 0.4510851903603627, disc_loss = 0.024225495192500897
Trained batch 234 in epoch 3, gen_loss = 0.4509609673885589, disc_loss = 0.02426369769815752
Trained batch 235 in epoch 3, gen_loss = 0.450851069542311, disc_loss = 0.02428929622371886
Trained batch 236 in epoch 3, gen_loss = 0.4510813613229663, disc_loss = 0.024635017556747428
Trained batch 237 in epoch 3, gen_loss = 0.45059855344916594, disc_loss = 0.024748422997854964
Trained batch 238 in epoch 3, gen_loss = 0.4506455422944105, disc_loss = 0.024821562148926772
Trained batch 239 in epoch 3, gen_loss = 0.4508678925534089, disc_loss = 0.025144891031474496
Trained batch 240 in epoch 3, gen_loss = 0.45080657260051904, disc_loss = 0.025135804843002953
Trained batch 241 in epoch 3, gen_loss = 0.45077050791299045, disc_loss = 0.025129174715492968
Trained batch 242 in epoch 3, gen_loss = 0.4509270449969994, disc_loss = 0.025056944602387554
Trained batch 243 in epoch 3, gen_loss = 0.4506188588308506, disc_loss = 0.025008677140443174
Trained batch 244 in epoch 3, gen_loss = 0.4504939525711293, disc_loss = 0.02507718219326771
Trained batch 245 in epoch 3, gen_loss = 0.4506352213097782, disc_loss = 0.025003941381365302
Trained batch 246 in epoch 3, gen_loss = 0.4507302244906483, disc_loss = 0.025194057387861644
Trained batch 247 in epoch 3, gen_loss = 0.45063635142099473, disc_loss = 0.025263696923972137
Trained batch 248 in epoch 3, gen_loss = 0.4504567184840819, disc_loss = 0.025191021178022445
Trained batch 249 in epoch 3, gen_loss = 0.45046928656101226, disc_loss = 0.025246189311146736
Trained batch 250 in epoch 3, gen_loss = 0.4507381679764782, disc_loss = 0.025448258966207504
Trained batch 251 in epoch 3, gen_loss = 0.45083556194154045, disc_loss = 0.025379299847704786
Trained batch 252 in epoch 3, gen_loss = 0.45071522791395074, disc_loss = 0.025315695125683258
Trained batch 253 in epoch 3, gen_loss = 0.4506367096516091, disc_loss = 0.02532745365009416
Trained batch 254 in epoch 3, gen_loss = 0.45075324329675415, disc_loss = 0.025266567004077575
Trained batch 255 in epoch 3, gen_loss = 0.450743235880509, disc_loss = 0.025184788875776576
Trained batch 256 in epoch 3, gen_loss = 0.45095990673577274, disc_loss = 0.02511211806103761
Trained batch 257 in epoch 3, gen_loss = 0.45109276230945144, disc_loss = 0.025032887724408693
Trained batch 258 in epoch 3, gen_loss = 0.45134114643781803, disc_loss = 0.024968894326189196
Trained batch 259 in epoch 3, gen_loss = 0.45162894152677974, disc_loss = 0.024901745334052695
Trained batch 260 in epoch 3, gen_loss = 0.4517052446516994, disc_loss = 0.024824794661967346
Trained batch 261 in epoch 3, gen_loss = 0.4515797641441112, disc_loss = 0.024745318905329546
Trained batch 262 in epoch 3, gen_loss = 0.45160227776026995, disc_loss = 0.024667940564637742
Trained batch 263 in epoch 3, gen_loss = 0.4514791189946912, disc_loss = 0.024594182764165893
Trained batch 264 in epoch 3, gen_loss = 0.4520454862207737, disc_loss = 0.024779774130866777
Trained batch 265 in epoch 3, gen_loss = 0.4519293142440624, disc_loss = 0.02492348717602628
Trained batch 266 in epoch 3, gen_loss = 0.4518298046865713, disc_loss = 0.02488882274084379
Trained batch 267 in epoch 3, gen_loss = 0.4519800047821073, disc_loss = 0.024831380682941804
Trained batch 268 in epoch 3, gen_loss = 0.45200479806134247, disc_loss = 0.02477175663623502
Trained batch 269 in epoch 3, gen_loss = 0.4519829609879741, disc_loss = 0.024743631573531915
Trained batch 270 in epoch 3, gen_loss = 0.45163631395220316, disc_loss = 0.024679808834450822
Trained batch 271 in epoch 3, gen_loss = 0.4518252852208474, disc_loss = 0.024668261424213758
Trained batch 272 in epoch 3, gen_loss = 0.45164909904256406, disc_loss = 0.024648777432671506
Trained batch 273 in epoch 3, gen_loss = 0.4513986808975248, disc_loss = 0.02469408854903368
Trained batch 274 in epoch 3, gen_loss = 0.45132452975619924, disc_loss = 0.02470145724205808
Trained batch 275 in epoch 3, gen_loss = 0.45132774827273, disc_loss = 0.02464427583196295
Trained batch 276 in epoch 3, gen_loss = 0.45122368951136455, disc_loss = 0.02460542706678544
Trained batch 277 in epoch 3, gen_loss = 0.4513520667021223, disc_loss = 0.02454369716687972
Trained batch 278 in epoch 3, gen_loss = 0.45136154905014997, disc_loss = 0.024485611485310674
Trained batch 279 in epoch 3, gen_loss = 0.45149776552404675, disc_loss = 0.024426346892557505
Trained batch 280 in epoch 3, gen_loss = 0.4513996113025421, disc_loss = 0.0243583790845241
Trained batch 281 in epoch 3, gen_loss = 0.45133742193380993, disc_loss = 0.02429514695850617
Trained batch 282 in epoch 3, gen_loss = 0.45139768593302887, disc_loss = 0.02425070237467072
Trained batch 283 in epoch 3, gen_loss = 0.4515017888075869, disc_loss = 0.024206749926006396
Trained batch 284 in epoch 3, gen_loss = 0.4517977369459052, disc_loss = 0.024440287068290146
Trained batch 285 in epoch 3, gen_loss = 0.4515717868413125, disc_loss = 0.02455689699610474
Trained batch 286 in epoch 3, gen_loss = 0.4511910067410419, disc_loss = 0.024654203722454634
Trained batch 287 in epoch 3, gen_loss = 0.451200724268953, disc_loss = 0.024979665540740825
Trained batch 288 in epoch 3, gen_loss = 0.4511135034907648, disc_loss = 0.025121235158165535
Trained batch 289 in epoch 3, gen_loss = 0.45105290382072843, disc_loss = 0.02510876573525883
Trained batch 290 in epoch 3, gen_loss = 0.45115409264040157, disc_loss = 0.025511789518085234
Trained batch 291 in epoch 3, gen_loss = 0.4510311286335122, disc_loss = 0.02629297987194349
Trained batch 292 in epoch 3, gen_loss = 0.4508912162569196, disc_loss = 0.02642794716435742
Trained batch 293 in epoch 3, gen_loss = 0.45084918518455663, disc_loss = 0.02685601538091543
Trained batch 294 in epoch 3, gen_loss = 0.4504683060161138, disc_loss = 0.027412514162833912
Trained batch 295 in epoch 3, gen_loss = 0.4501933080924524, disc_loss = 0.027577655290794634
Trained batch 296 in epoch 3, gen_loss = 0.4501390784276455, disc_loss = 0.027794186566777603
Trained batch 297 in epoch 3, gen_loss = 0.4500017189139488, disc_loss = 0.02788310815680197
Trained batch 298 in epoch 3, gen_loss = 0.4496369433642231, disc_loss = 0.028001519525890865
Trained batch 299 in epoch 3, gen_loss = 0.44937954167524974, disc_loss = 0.028629585928283633
Trained batch 300 in epoch 3, gen_loss = 0.4492392021160189, disc_loss = 0.028566310579804983
Trained batch 301 in epoch 3, gen_loss = 0.4493906462429375, disc_loss = 0.028539252832889654
Trained batch 302 in epoch 3, gen_loss = 0.449213704456984, disc_loss = 0.028497402825186847
Trained batch 303 in epoch 3, gen_loss = 0.44917498685811696, disc_loss = 0.028446648283677763
Trained batch 304 in epoch 3, gen_loss = 0.44903055536942404, disc_loss = 0.028386308468084355
Trained batch 305 in epoch 3, gen_loss = 0.4488541293962329, disc_loss = 0.028326436032668923
Trained batch 306 in epoch 3, gen_loss = 0.4488042091119561, disc_loss = 0.028324001169906087
Trained batch 307 in epoch 3, gen_loss = 0.4488732194552174, disc_loss = 0.028382281580782653
Trained batch 308 in epoch 3, gen_loss = 0.44911458413191985, disc_loss = 0.028327256644560584
Trained batch 309 in epoch 3, gen_loss = 0.4492143076273703, disc_loss = 0.028380231425586728
Trained batch 310 in epoch 3, gen_loss = 0.4491639630779193, disc_loss = 0.028379211901504414
Trained batch 311 in epoch 3, gen_loss = 0.448992858425929, disc_loss = 0.028336599509482488
Trained batch 312 in epoch 3, gen_loss = 0.4487532528635031, disc_loss = 0.028471840853496386
Trained batch 313 in epoch 3, gen_loss = 0.4486515721318069, disc_loss = 0.028481000860868272
Trained batch 314 in epoch 3, gen_loss = 0.44903514971808783, disc_loss = 0.028604193367359657
Trained batch 315 in epoch 3, gen_loss = 0.4488664413743381, disc_loss = 0.02871968642413569
Trained batch 316 in epoch 3, gen_loss = 0.4487751903782132, disc_loss = 0.028681017351204572
Trained batch 317 in epoch 3, gen_loss = 0.44863819935411775, disc_loss = 0.028745735285264796
Trained batch 318 in epoch 3, gen_loss = 0.44877398350395753, disc_loss = 0.02884309348682391
Trained batch 319 in epoch 3, gen_loss = 0.4487787251360714, disc_loss = 0.028783876948000397
Trained batch 320 in epoch 3, gen_loss = 0.44894758126817386, disc_loss = 0.028783924580258653
Trained batch 321 in epoch 3, gen_loss = 0.44895103120285534, disc_loss = 0.02871258784611912
Trained batch 322 in epoch 3, gen_loss = 0.4489890568581159, disc_loss = 0.028763711773977838
Trained batch 323 in epoch 3, gen_loss = 0.4491319302239536, disc_loss = 0.028808810597251135
Trained batch 324 in epoch 3, gen_loss = 0.44925052899580736, disc_loss = 0.02876941692800476
Trained batch 325 in epoch 3, gen_loss = 0.44926794970328093, disc_loss = 0.02877895515040706
Trained batch 326 in epoch 3, gen_loss = 0.44925741728292695, disc_loss = 0.028746171354598136
Trained batch 327 in epoch 3, gen_loss = 0.4491289059926824, disc_loss = 0.02895747609408118
Trained batch 328 in epoch 3, gen_loss = 0.44913998454537435, disc_loss = 0.02888935422071887
Trained batch 329 in epoch 3, gen_loss = 0.44956963911201014, disc_loss = 0.029182133782711443
Trained batch 330 in epoch 3, gen_loss = 0.44977429644218747, disc_loss = 0.02912489293998507
Trained batch 331 in epoch 3, gen_loss = 0.44962537019367677, disc_loss = 0.02936545937428677
Trained batch 332 in epoch 3, gen_loss = 0.449516149344029, disc_loss = 0.029303367393701017
Trained batch 333 in epoch 3, gen_loss = 0.4497523922584728, disc_loss = 0.029324454881395855
Trained batch 334 in epoch 3, gen_loss = 0.4498405663824793, disc_loss = 0.02925850085135716
Trained batch 335 in epoch 3, gen_loss = 0.449512029776261, disc_loss = 0.029239736203592093
Trained batch 336 in epoch 3, gen_loss = 0.4493614130097964, disc_loss = 0.02918949528412136
Trained batch 337 in epoch 3, gen_loss = 0.44944630360462257, disc_loss = 0.029225872992124608
Trained batch 338 in epoch 3, gen_loss = 0.4494128088332207, disc_loss = 0.02916225620784459
Trained batch 339 in epoch 3, gen_loss = 0.4491402717197643, disc_loss = 0.02917590636677821
Trained batch 340 in epoch 3, gen_loss = 0.44896316073856746, disc_loss = 0.02916947996538799
Trained batch 341 in epoch 3, gen_loss = 0.44918318938093577, disc_loss = 0.02913875256567017
Trained batch 342 in epoch 3, gen_loss = 0.44940242614412446, disc_loss = 0.02910954347857798
Trained batch 343 in epoch 3, gen_loss = 0.44953400182516073, disc_loss = 0.02908928460728507
Trained batch 344 in epoch 3, gen_loss = 0.4497384790925012, disc_loss = 0.02904867929527941
Trained batch 345 in epoch 3, gen_loss = 0.4498445951525187, disc_loss = 0.028999934114268145
Trained batch 346 in epoch 3, gen_loss = 0.4501673057031219, disc_loss = 0.02898638940386753
Trained batch 347 in epoch 3, gen_loss = 0.45027574477182036, disc_loss = 0.0289427348045932
Trained batch 348 in epoch 3, gen_loss = 0.45027253902744085, disc_loss = 0.02888807217673236
Trained batch 349 in epoch 3, gen_loss = 0.4501751674073083, disc_loss = 0.02883613858505019
Trained batch 350 in epoch 3, gen_loss = 0.4501643718307854, disc_loss = 0.028841206571750575
Trained batch 351 in epoch 3, gen_loss = 0.45020506776530633, disc_loss = 0.028824567462751558
Trained batch 352 in epoch 3, gen_loss = 0.4501401219759717, disc_loss = 0.028761204227900117
Trained batch 353 in epoch 3, gen_loss = 0.4501247803370158, disc_loss = 0.028711250429383696
Trained batch 354 in epoch 3, gen_loss = 0.4502026447108094, disc_loss = 0.028652070887701612
Trained batch 355 in epoch 3, gen_loss = 0.4502780160374856, disc_loss = 0.0285827459458764
Trained batch 356 in epoch 3, gen_loss = 0.450221645648406, disc_loss = 0.02851455447757069
Trained batch 357 in epoch 3, gen_loss = 0.4501199760583526, disc_loss = 0.02855718668482615
Trained batch 358 in epoch 3, gen_loss = 0.4501314027893842, disc_loss = 0.028607309568922417
Trained batch 359 in epoch 3, gen_loss = 0.4503645561635494, disc_loss = 0.0285516919917427
Trained batch 360 in epoch 3, gen_loss = 0.4501801928159603, disc_loss = 0.028542859844832458
Trained batch 361 in epoch 3, gen_loss = 0.45034610377161544, disc_loss = 0.028494510628560878
Trained batch 362 in epoch 3, gen_loss = 0.45045704519781526, disc_loss = 0.02847127509034
Trained batch 363 in epoch 3, gen_loss = 0.45053571208820237, disc_loss = 0.028438791656958777
Trained batch 364 in epoch 3, gen_loss = 0.45058977603912354, disc_loss = 0.02838610963232509
Trained batch 365 in epoch 3, gen_loss = 0.45044727656033523, disc_loss = 0.028350096685771164
Trained batch 366 in epoch 3, gen_loss = 0.4503270441244993, disc_loss = 0.028318645088738006
Trained batch 367 in epoch 3, gen_loss = 0.45036073612130206, disc_loss = 0.028291553634714903
Trained batch 368 in epoch 3, gen_loss = 0.4504962230762492, disc_loss = 0.02824317841969814
Trained batch 369 in epoch 3, gen_loss = 0.4506479272971282, disc_loss = 0.02818639841862023
Trained batch 370 in epoch 3, gen_loss = 0.4505393960565891, disc_loss = 0.028152349659786472
Trained batch 371 in epoch 3, gen_loss = 0.4503696883718173, disc_loss = 0.028101323897229327
Trained batch 372 in epoch 3, gen_loss = 0.45032621780285564, disc_loss = 0.02805897101495245
Trained batch 373 in epoch 3, gen_loss = 0.4502650406112008, disc_loss = 0.028040492512474962
Trained batch 374 in epoch 3, gen_loss = 0.45027710644404095, disc_loss = 0.027984567203869423
Trained batch 375 in epoch 3, gen_loss = 0.45022109967279944, disc_loss = 0.027976989893470593
Trained batch 376 in epoch 3, gen_loss = 0.45036194550579994, disc_loss = 0.027926694874748074
Trained batch 377 in epoch 3, gen_loss = 0.45017214174623843, disc_loss = 0.027889442904827692
Trained batch 378 in epoch 3, gen_loss = 0.4501485648444586, disc_loss = 0.027831744545171316
Trained batch 379 in epoch 3, gen_loss = 0.45014076821113885, disc_loss = 0.02779831968640026
Trained batch 380 in epoch 3, gen_loss = 0.4500335526904409, disc_loss = 0.02773676560873904
Trained batch 381 in epoch 3, gen_loss = 0.45007734819856615, disc_loss = 0.02769573002624574
Trained batch 382 in epoch 3, gen_loss = 0.4503349856359218, disc_loss = 0.027917333501670753
Trained batch 383 in epoch 3, gen_loss = 0.45007794280536473, disc_loss = 0.028102753557808075
Trained batch 384 in epoch 3, gen_loss = 0.449986687496111, disc_loss = 0.028196546232158486
Trained batch 385 in epoch 3, gen_loss = 0.4499989577371222, disc_loss = 0.0282001838454774
Trained batch 386 in epoch 3, gen_loss = 0.45016150704033925, disc_loss = 0.02829143937282476
Trained batch 387 in epoch 3, gen_loss = 0.45014419160860103, disc_loss = 0.028321615919547596
Trained batch 388 in epoch 3, gen_loss = 0.4501528000617089, disc_loss = 0.02826589122677945
Trained batch 389 in epoch 3, gen_loss = 0.45026908555091955, disc_loss = 0.028247978809313515
Trained batch 390 in epoch 3, gen_loss = 0.4502787108311568, disc_loss = 0.028192815686459354
Trained batch 391 in epoch 3, gen_loss = 0.4502016171356853, disc_loss = 0.028137136023843243
Trained batch 392 in epoch 3, gen_loss = 0.45015833866201893, disc_loss = 0.028156576503978202
Trained batch 393 in epoch 3, gen_loss = 0.45009526209480266, disc_loss = 0.028102858508535222
Trained batch 394 in epoch 3, gen_loss = 0.4502004397820823, disc_loss = 0.028104908058207624
Trained batch 395 in epoch 3, gen_loss = 0.4502070297044937, disc_loss = 0.028084016909512382
Trained batch 396 in epoch 3, gen_loss = 0.4502089783286568, disc_loss = 0.02804799040695019
Trained batch 397 in epoch 3, gen_loss = 0.4501714412890487, disc_loss = 0.027998700306221994
Trained batch 398 in epoch 3, gen_loss = 0.4500643829056494, disc_loss = 0.027941118578022735
Trained batch 399 in epoch 3, gen_loss = 0.4501090758293867, disc_loss = 0.02788774112588726
Trained batch 400 in epoch 3, gen_loss = 0.45011570232170184, disc_loss = 0.02789963263799982
Trained batch 401 in epoch 3, gen_loss = 0.450159334795392, disc_loss = 0.027856446706472124
Trained batch 402 in epoch 3, gen_loss = 0.4501979725976144, disc_loss = 0.027862828323113785
Trained batch 403 in epoch 3, gen_loss = 0.4499776319111928, disc_loss = 0.027844666209449937
Trained batch 404 in epoch 3, gen_loss = 0.44996994461542295, disc_loss = 0.02782190205345367
Trained batch 405 in epoch 3, gen_loss = 0.4499466323059768, disc_loss = 0.027772472096662143
Trained batch 406 in epoch 3, gen_loss = 0.45010190814074486, disc_loss = 0.027730674236893873
Trained batch 407 in epoch 3, gen_loss = 0.4501753846804301, disc_loss = 0.027676047498186796
Trained batch 408 in epoch 3, gen_loss = 0.4502069259331104, disc_loss = 0.027630046773975153
Trained batch 409 in epoch 3, gen_loss = 0.4501206339132495, disc_loss = 0.027575074780232658
Trained batch 410 in epoch 3, gen_loss = 0.4500756903286398, disc_loss = 0.027537283010626724
Trained batch 411 in epoch 3, gen_loss = 0.45007253257394997, disc_loss = 0.027488290536832244
Trained batch 412 in epoch 3, gen_loss = 0.45013532655868344, disc_loss = 0.027435104546450602
Trained batch 413 in epoch 3, gen_loss = 0.4503331737241883, disc_loss = 0.027471080207567358
Trained batch 414 in epoch 3, gen_loss = 0.4502382673412921, disc_loss = 0.027438775123467287
Trained batch 415 in epoch 3, gen_loss = 0.45004744877895486, disc_loss = 0.027436954028626833
Trained batch 416 in epoch 3, gen_loss = 0.44997105967226647, disc_loss = 0.027542686207126157
Trained batch 417 in epoch 3, gen_loss = 0.44999787425310417, disc_loss = 0.027491864132244834
Trained batch 418 in epoch 3, gen_loss = 0.44989258200285825, disc_loss = 0.02747180085153561
Trained batch 419 in epoch 3, gen_loss = 0.4500294711618196, disc_loss = 0.027425275360500174
Trained batch 420 in epoch 3, gen_loss = 0.45022757411569425, disc_loss = 0.027388935805809398
Trained batch 421 in epoch 3, gen_loss = 0.45003495248855574, disc_loss = 0.027491870207129426
Trained batch 422 in epoch 3, gen_loss = 0.4497322341510872, disc_loss = 0.027799789134377778
Trained batch 423 in epoch 3, gen_loss = 0.4498320985234009, disc_loss = 0.027882996664321015
Trained batch 424 in epoch 3, gen_loss = 0.449862237257116, disc_loss = 0.0278583058616256
Trained batch 425 in epoch 3, gen_loss = 0.44992509708158285, disc_loss = 0.027850297221721547
Trained batch 426 in epoch 3, gen_loss = 0.4498679730735841, disc_loss = 0.027803410456430786
Trained batch 427 in epoch 3, gen_loss = 0.449792755611032, disc_loss = 0.027872459903124407
Trained batch 428 in epoch 3, gen_loss = 0.4497368872721434, disc_loss = 0.02795506762948521
Trained batch 429 in epoch 3, gen_loss = 0.44976697363132656, disc_loss = 0.027903682137514617
Trained batch 430 in epoch 3, gen_loss = 0.4497564754463957, disc_loss = 0.027876185103084053
Trained batch 431 in epoch 3, gen_loss = 0.4498617684951535, disc_loss = 0.02785130487690266
Trained batch 432 in epoch 3, gen_loss = 0.45006550611029045, disc_loss = 0.027814940645146523
Trained batch 433 in epoch 3, gen_loss = 0.4500951016416198, disc_loss = 0.027803393783614315
Trained batch 434 in epoch 3, gen_loss = 0.450095937649409, disc_loss = 0.02776793349084669
Trained batch 435 in epoch 3, gen_loss = 0.45005413773683234, disc_loss = 0.02773941289996643
Trained batch 436 in epoch 3, gen_loss = 0.4499924890100274, disc_loss = 0.027781361024571023
Trained batch 437 in epoch 3, gen_loss = 0.4500292659350182, disc_loss = 0.027742520605158656
Trained batch 438 in epoch 3, gen_loss = 0.45008669396467793, disc_loss = 0.027728852051138404
Trained batch 439 in epoch 3, gen_loss = 0.45011165738105774, disc_loss = 0.028050547538706186
Trained batch 440 in epoch 3, gen_loss = 0.4499223840479948, disc_loss = 0.028645850875353665
Trained batch 441 in epoch 3, gen_loss = 0.4498522250630737, disc_loss = 0.02885354420368252
Trained batch 442 in epoch 3, gen_loss = 0.44975975404743684, disc_loss = 0.028995775532515606
Trained batch 443 in epoch 3, gen_loss = 0.44963576335896244, disc_loss = 0.02912733159007018
Trained batch 444 in epoch 3, gen_loss = 0.44969512605935, disc_loss = 0.029243471001515562
Trained batch 445 in epoch 3, gen_loss = 0.44938727070665146, disc_loss = 0.029456148956664274
Trained batch 446 in epoch 3, gen_loss = 0.4492786491343906, disc_loss = 0.029545836855909502
Trained batch 447 in epoch 3, gen_loss = 0.4491932300983795, disc_loss = 0.029626311589839003
Trained batch 448 in epoch 3, gen_loss = 0.4489838305719711, disc_loss = 0.029622297208208616
Trained batch 449 in epoch 3, gen_loss = 0.44891380978955164, disc_loss = 0.029722717980750733
Trained batch 450 in epoch 3, gen_loss = 0.448931865707998, disc_loss = 0.029788439879668855
Trained batch 451 in epoch 3, gen_loss = 0.44899192076604977, disc_loss = 0.02979580336559432
Trained batch 452 in epoch 3, gen_loss = 0.4489003587637516, disc_loss = 0.029768665373596726
Trained batch 453 in epoch 3, gen_loss = 0.4489231507421065, disc_loss = 0.02978942419057671
Trained batch 454 in epoch 3, gen_loss = 0.44893688618481814, disc_loss = 0.029792024495059646
Trained batch 455 in epoch 3, gen_loss = 0.4490036981409056, disc_loss = 0.02978203392264907
Trained batch 456 in epoch 3, gen_loss = 0.44932355479025476, disc_loss = 0.029966023745508438
Trained batch 457 in epoch 3, gen_loss = 0.44912626265698646, disc_loss = 0.030017141209036827
Trained batch 458 in epoch 3, gen_loss = 0.44921113482487746, disc_loss = 0.029999259036553778
Trained batch 459 in epoch 3, gen_loss = 0.4493084982037544, disc_loss = 0.029956132340568885
Trained batch 460 in epoch 3, gen_loss = 0.44940198392257774, disc_loss = 0.029923187210194265
Trained batch 461 in epoch 3, gen_loss = 0.4494758318642001, disc_loss = 0.02992757555052993
Trained batch 462 in epoch 3, gen_loss = 0.4494676237229909, disc_loss = 0.029902854416374577
Trained batch 463 in epoch 3, gen_loss = 0.4494900266672003, disc_loss = 0.02987577314267802
Trained batch 464 in epoch 3, gen_loss = 0.4495243303237423, disc_loss = 0.02986403346482304
Trained batch 465 in epoch 3, gen_loss = 0.4494792971871953, disc_loss = 0.029855085877589723
Trained batch 466 in epoch 3, gen_loss = 0.4497228104629149, disc_loss = 0.029916806394788706
Trained batch 467 in epoch 3, gen_loss = 0.44969150678724307, disc_loss = 0.029989972341463417
Trained batch 468 in epoch 3, gen_loss = 0.4496042617856821, disc_loss = 0.02995074945571485
Trained batch 469 in epoch 3, gen_loss = 0.4497153978398506, disc_loss = 0.029922181238083448
Trained batch 470 in epoch 3, gen_loss = 0.4498373972382515, disc_loss = 0.029870820877334052
Trained batch 471 in epoch 3, gen_loss = 0.4497870621034655, disc_loss = 0.02986494557817577
Trained batch 472 in epoch 3, gen_loss = 0.4498911725542258, disc_loss = 0.02982483674372383
Trained batch 473 in epoch 3, gen_loss = 0.44992683482069507, disc_loss = 0.029826344243341168
Trained batch 474 in epoch 3, gen_loss = 0.45002720694792897, disc_loss = 0.029787635155218213
Trained batch 475 in epoch 3, gen_loss = 0.4499314088656121, disc_loss = 0.02983555486797504
Trained batch 476 in epoch 3, gen_loss = 0.4499683458850069, disc_loss = 0.02979634987166936
Trained batch 477 in epoch 3, gen_loss = 0.4500117041326467, disc_loss = 0.02977161349000012
Trained batch 478 in epoch 3, gen_loss = 0.449991189114485, disc_loss = 0.02979666210364916
Trained batch 479 in epoch 3, gen_loss = 0.45007140636444093, disc_loss = 0.029767239686528533
Trained batch 480 in epoch 3, gen_loss = 0.450120511520925, disc_loss = 0.029731301938352057
Trained batch 481 in epoch 3, gen_loss = 0.4500721510020529, disc_loss = 0.029681833931418808
Trained batch 482 in epoch 3, gen_loss = 0.4500026825668896, disc_loss = 0.029630457977600413
Trained batch 483 in epoch 3, gen_loss = 0.4500491670217396, disc_loss = 0.029612392240034587
Trained batch 484 in epoch 3, gen_loss = 0.4500676481379676, disc_loss = 0.029560283494671595
Trained batch 485 in epoch 3, gen_loss = 0.4500314717798076, disc_loss = 0.029646998118041966
Trained batch 486 in epoch 3, gen_loss = 0.4502133044741237, disc_loss = 0.029693229387856606
Trained batch 487 in epoch 3, gen_loss = 0.4501722380518913, disc_loss = 0.029646990062157454
Trained batch 488 in epoch 3, gen_loss = 0.45024509468936724, disc_loss = 0.029607710359020042
Trained batch 489 in epoch 3, gen_loss = 0.45023540702401377, disc_loss = 0.029560650204669456
Trained batch 490 in epoch 3, gen_loss = 0.4502239343833535, disc_loss = 0.029550567686618467
Trained batch 491 in epoch 3, gen_loss = 0.4501727830951776, disc_loss = 0.029508516427159796
Trained batch 492 in epoch 3, gen_loss = 0.4502110799234247, disc_loss = 0.029456763914606814
Trained batch 493 in epoch 3, gen_loss = 0.4501392402146992, disc_loss = 0.029413721153723746
Trained batch 494 in epoch 3, gen_loss = 0.4501024441285567, disc_loss = 0.02936554682638609
Trained batch 495 in epoch 3, gen_loss = 0.4502165459336773, disc_loss = 0.029333160104860943
Trained batch 496 in epoch 3, gen_loss = 0.4501469676163595, disc_loss = 0.029311587336947262
Trained batch 497 in epoch 3, gen_loss = 0.4500230306003946, disc_loss = 0.02926340150688008
Trained batch 498 in epoch 3, gen_loss = 0.4500562037996395, disc_loss = 0.02921392518900081
Trained batch 499 in epoch 3, gen_loss = 0.4502403820157051, disc_loss = 0.029231616225093602
Trained batch 500 in epoch 3, gen_loss = 0.45036837577581884, disc_loss = 0.029198490306288898
Trained batch 501 in epoch 3, gen_loss = 0.45034774449242065, disc_loss = 0.029151896808845588
Trained batch 502 in epoch 3, gen_loss = 0.4503431670945397, disc_loss = 0.029104434048190388
Trained batch 503 in epoch 3, gen_loss = 0.4503215418921577, disc_loss = 0.029131126787794368
Trained batch 504 in epoch 3, gen_loss = 0.4505375718126203, disc_loss = 0.02922647982503813
Trained batch 505 in epoch 3, gen_loss = 0.4505835641985354, disc_loss = 0.029217979924112795
Trained batch 506 in epoch 3, gen_loss = 0.4505351691321273, disc_loss = 0.029284244610815947
Trained batch 507 in epoch 3, gen_loss = 0.4505332488947966, disc_loss = 0.029282052907726074
Trained batch 508 in epoch 3, gen_loss = 0.45050839772393053, disc_loss = 0.02923644726733679
Trained batch 509 in epoch 3, gen_loss = 0.4503210971168443, disc_loss = 0.029204116060453304
Trained batch 510 in epoch 3, gen_loss = 0.45039914924571195, disc_loss = 0.02916293791012288
Trained batch 511 in epoch 3, gen_loss = 0.4504871785757132, disc_loss = 0.029147335786547046
Trained batch 512 in epoch 3, gen_loss = 0.45046327029287697, disc_loss = 0.029111781840159997
Trained batch 513 in epoch 3, gen_loss = 0.4503672470842354, disc_loss = 0.029070869894473585
Trained batch 514 in epoch 3, gen_loss = 0.45029606934890004, disc_loss = 0.02902477771966058
Trained batch 515 in epoch 3, gen_loss = 0.45021764541319176, disc_loss = 0.029013407199152623
Trained batch 516 in epoch 3, gen_loss = 0.4502844924045946, disc_loss = 0.028964482406352427
Trained batch 517 in epoch 3, gen_loss = 0.45025576645343, disc_loss = 0.028948705157977043
Trained batch 518 in epoch 3, gen_loss = 0.45032048713494816, disc_loss = 0.028922893813953004
Trained batch 519 in epoch 3, gen_loss = 0.4503289614159327, disc_loss = 0.02889384410988826
Trained batch 520 in epoch 3, gen_loss = 0.4503198028068396, disc_loss = 0.02890061362576805
Trained batch 521 in epoch 3, gen_loss = 0.45029789574758305, disc_loss = 0.02886453435231728
Trained batch 522 in epoch 3, gen_loss = 0.45018896905003725, disc_loss = 0.028821087187693863
Trained batch 523 in epoch 3, gen_loss = 0.4502522375519949, disc_loss = 0.028781006425505375
Trained batch 524 in epoch 3, gen_loss = 0.45024533578327725, disc_loss = 0.02873448331618593
Trained batch 525 in epoch 3, gen_loss = 0.4503045568221422, disc_loss = 0.028701915267585802
Trained batch 526 in epoch 3, gen_loss = 0.4502218166610095, disc_loss = 0.028664209188953522
Trained batch 527 in epoch 3, gen_loss = 0.45022937282919884, disc_loss = 0.028652452620338987
Trained batch 528 in epoch 3, gen_loss = 0.4502563164455003, disc_loss = 0.028615008405848127
Trained batch 529 in epoch 3, gen_loss = 0.45027987788308343, disc_loss = 0.028573609704046318
Trained batch 530 in epoch 3, gen_loss = 0.45040217676180677, disc_loss = 0.028531770948881877
Trained batch 531 in epoch 3, gen_loss = 0.45043782088765527, disc_loss = 0.028491966639946503
Trained batch 532 in epoch 3, gen_loss = 0.45043352727147473, disc_loss = 0.02845452763978916
Trained batch 533 in epoch 3, gen_loss = 0.45050356389208235, disc_loss = 0.028415553249969857
Trained batch 534 in epoch 3, gen_loss = 0.45051385186542975, disc_loss = 0.02837288286536932
Trained batch 535 in epoch 3, gen_loss = 0.4503895416855812, disc_loss = 0.02832888281528852
Trained batch 536 in epoch 3, gen_loss = 0.45039332834257984, disc_loss = 0.028289370356713816
Trained batch 537 in epoch 3, gen_loss = 0.45045452645277, disc_loss = 0.028253880024759523
Trained batch 538 in epoch 3, gen_loss = 0.45041533281719087, disc_loss = 0.028245825683335207
Trained batch 539 in epoch 3, gen_loss = 0.4505031196055589, disc_loss = 0.028201660001650454
Trained batch 540 in epoch 3, gen_loss = 0.4505545297523964, disc_loss = 0.02819549774857799
Trained batch 541 in epoch 3, gen_loss = 0.45062939195835283, disc_loss = 0.028393793718827498
Trained batch 542 in epoch 3, gen_loss = 0.4505228997923393, disc_loss = 0.028773749557634194
Trained batch 543 in epoch 3, gen_loss = 0.4503783993422985, disc_loss = 0.028907005872015896
Trained batch 544 in epoch 3, gen_loss = 0.450391067332084, disc_loss = 0.02905349551503538
Trained batch 545 in epoch 3, gen_loss = 0.45024978197537935, disc_loss = 0.02920234708743163
Trained batch 546 in epoch 3, gen_loss = 0.45022893998043195, disc_loss = 0.029276028825429828
Trained batch 547 in epoch 3, gen_loss = 0.4502066273758881, disc_loss = 0.029293705795952765
Trained batch 548 in epoch 3, gen_loss = 0.45003336288021345, disc_loss = 0.029297489929055363
Trained batch 549 in epoch 3, gen_loss = 0.4500049531459808, disc_loss = 0.029285772684961558
Trained batch 550 in epoch 3, gen_loss = 0.449947256466438, disc_loss = 0.029279706690345506
Trained batch 551 in epoch 3, gen_loss = 0.44997699051231577, disc_loss = 0.029257842668575115
Trained batch 552 in epoch 3, gen_loss = 0.4499900843308157, disc_loss = 0.02939280846525004
Trained batch 553 in epoch 3, gen_loss = 0.4498322382300339, disc_loss = 0.029579817446869956
Trained batch 554 in epoch 3, gen_loss = 0.44975515673826405, disc_loss = 0.02959831117207671
Trained batch 555 in epoch 3, gen_loss = 0.44978013157630137, disc_loss = 0.029725319744429463
Trained batch 556 in epoch 3, gen_loss = 0.4497649593134971, disc_loss = 0.029825491009738223
Trained batch 557 in epoch 3, gen_loss = 0.44988899125206855, disc_loss = 0.029838875595373387
Trained batch 558 in epoch 3, gen_loss = 0.44992828816975167, disc_loss = 0.02979930483091336
Trained batch 559 in epoch 3, gen_loss = 0.4498665820275034, disc_loss = 0.02977738955024896
Trained batch 560 in epoch 3, gen_loss = 0.4499346110803771, disc_loss = 0.029772251082414932
Trained batch 561 in epoch 3, gen_loss = 0.4500365408395957, disc_loss = 0.0297784379557491
Trained batch 562 in epoch 3, gen_loss = 0.45024190125838054, disc_loss = 0.029749094849356433
Trained batch 563 in epoch 3, gen_loss = 0.4501158023345555, disc_loss = 0.02974315981565585
Trained batch 564 in epoch 3, gen_loss = 0.45008936366148755, disc_loss = 0.029744162230826585
Trained batch 565 in epoch 3, gen_loss = 0.45017004081512085, disc_loss = 0.029709482099860907
Trained batch 566 in epoch 3, gen_loss = 0.45026913474476526, disc_loss = 0.029674368956482705
Trained batch 567 in epoch 3, gen_loss = 0.4503599815070629, disc_loss = 0.02964356868088403
Trained batch 568 in epoch 3, gen_loss = 0.45038800520301914, disc_loss = 0.02971230910662136
Trained batch 569 in epoch 3, gen_loss = 0.4502661612995884, disc_loss = 0.02986810941804658
Trained batch 570 in epoch 3, gen_loss = 0.45027487431432656, disc_loss = 0.02995055040830645
Trained batch 571 in epoch 3, gen_loss = 0.45040636686803576, disc_loss = 0.030325714458053658
Trained batch 572 in epoch 3, gen_loss = 0.45035812669607567, disc_loss = 0.030429000992256414
Trained batch 573 in epoch 3, gen_loss = 0.4502413591649059, disc_loss = 0.03040419658321485
Trained batch 574 in epoch 3, gen_loss = 0.45019114763840384, disc_loss = 0.030391257623939412
Trained batch 575 in epoch 3, gen_loss = 0.4502565159669353, disc_loss = 0.030354953805928946
Trained batch 576 in epoch 3, gen_loss = 0.4503034915213362, disc_loss = 0.03032210037964469
Trained batch 577 in epoch 3, gen_loss = 0.4503571108550761, disc_loss = 0.030293269094182854
Trained batch 578 in epoch 3, gen_loss = 0.4503517213160098, disc_loss = 0.030263493632148173
Trained batch 579 in epoch 3, gen_loss = 0.4503846838042654, disc_loss = 0.030377994792471674
Trained batch 580 in epoch 3, gen_loss = 0.4502941502351154, disc_loss = 0.030548864824892937
Trained batch 581 in epoch 3, gen_loss = 0.4503424665362565, disc_loss = 0.030564729258725325
Trained batch 582 in epoch 3, gen_loss = 0.45043176238778115, disc_loss = 0.030548329508222807
Trained batch 583 in epoch 3, gen_loss = 0.45036488893913895, disc_loss = 0.030616523493846803
Trained batch 584 in epoch 3, gen_loss = 0.45043459743516057, disc_loss = 0.030693418730018487
Trained batch 585 in epoch 3, gen_loss = 0.4506038931856383, disc_loss = 0.030657166993378983
Trained batch 586 in epoch 3, gen_loss = 0.45052856242433315, disc_loss = 0.03062514810992668
Trained batch 587 in epoch 3, gen_loss = 0.45046678824084146, disc_loss = 0.030757331206989126
Trained batch 588 in epoch 3, gen_loss = 0.4506301824224825, disc_loss = 0.030848291346800144
Trained batch 589 in epoch 3, gen_loss = 0.45068064028933896, disc_loss = 0.030827679608206628
Trained batch 590 in epoch 3, gen_loss = 0.4506286039771969, disc_loss = 0.030847959778257432
Trained batch 591 in epoch 3, gen_loss = 0.4506262267964917, disc_loss = 0.03080882363074862
Trained batch 592 in epoch 3, gen_loss = 0.4505786190648103, disc_loss = 0.03078112672169459
Trained batch 593 in epoch 3, gen_loss = 0.45067246137845396, disc_loss = 0.030738608576890446
Trained batch 594 in epoch 3, gen_loss = 0.45068389062120134, disc_loss = 0.030706521543916784
Trained batch 595 in epoch 3, gen_loss = 0.4505857439249154, disc_loss = 0.030663828369411297
Trained batch 596 in epoch 3, gen_loss = 0.4505578498145444, disc_loss = 0.030620289001601374
Trained batch 597 in epoch 3, gen_loss = 0.4505853462578062, disc_loss = 0.03057927923996537
Trained batch 598 in epoch 3, gen_loss = 0.4504628779494106, disc_loss = 0.030559037046317315
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.48919373750686646, disc_loss = 0.034062162041664124
Trained batch 1 in epoch 4, gen_loss = 0.46436724066734314, disc_loss = 0.022637948393821716
Trained batch 2 in epoch 4, gen_loss = 0.4286192258199056, disc_loss = 0.0390183354417483
Trained batch 3 in epoch 4, gen_loss = 0.43040820956230164, disc_loss = 0.034200025256723166
Trained batch 4 in epoch 4, gen_loss = 0.4398216426372528, disc_loss = 0.042138860747218135
Trained batch 5 in epoch 4, gen_loss = 0.4471223254998525, disc_loss = 0.037342728270838656
Trained batch 6 in epoch 4, gen_loss = 0.4433579572609493, disc_loss = 0.042794148703770976
Trained batch 7 in epoch 4, gen_loss = 0.44648055732250214, disc_loss = 0.03936502046417445
Trained batch 8 in epoch 4, gen_loss = 0.45329723093244767, disc_loss = 0.03644848697715335
Trained batch 9 in epoch 4, gen_loss = 0.45579640865325927, disc_loss = 0.03478358257561922
Trained batch 10 in epoch 4, gen_loss = 0.45156184380704706, disc_loss = 0.03243747108023275
Trained batch 11 in epoch 4, gen_loss = 0.4518641879161199, disc_loss = 0.031509624095633626
Trained batch 12 in epoch 4, gen_loss = 0.447741490143996, disc_loss = 0.032452510454906866
Trained batch 13 in epoch 4, gen_loss = 0.4559363126754761, disc_loss = 0.0385806990920433
Trained batch 14 in epoch 4, gen_loss = 0.460757037003835, disc_loss = 0.03686786536127329
Trained batch 15 in epoch 4, gen_loss = 0.4585229065269232, disc_loss = 0.048296811466570944
Trained batch 16 in epoch 4, gen_loss = 0.460296969203388, disc_loss = 0.04701006253633429
Trained batch 17 in epoch 4, gen_loss = 0.4689084374242359, disc_loss = 0.051889087746126786
Trained batch 18 in epoch 4, gen_loss = 0.4655783176422119, disc_loss = 0.05223642912154135
Trained batch 19 in epoch 4, gen_loss = 0.4641789734363556, disc_loss = 0.051075828401371835
Trained batch 20 in epoch 4, gen_loss = 0.46307196219762164, disc_loss = 0.0493637134897567
Trained batch 21 in epoch 4, gen_loss = 0.46580261262980377, disc_loss = 0.047498445195907894
Trained batch 22 in epoch 4, gen_loss = 0.4633704553479734, disc_loss = 0.045983940524899444
Trained batch 23 in epoch 4, gen_loss = 0.4594772458076477, disc_loss = 0.04442895413376391
Trained batch 24 in epoch 4, gen_loss = 0.45939833998680113, disc_loss = 0.04328351557254791
Trained batch 25 in epoch 4, gen_loss = 0.45778634685736436, disc_loss = 0.041770355561031744
Trained batch 26 in epoch 4, gen_loss = 0.4590982772685863, disc_loss = 0.04034398294364413
Trained batch 27 in epoch 4, gen_loss = 0.45982868543692995, disc_loss = 0.0397119674266183
Trained batch 28 in epoch 4, gen_loss = 0.4569853462021926, disc_loss = 0.03863914296480602
Trained batch 29 in epoch 4, gen_loss = 0.4557182083527247, disc_loss = 0.037735182776426276
Trained batch 30 in epoch 4, gen_loss = 0.4570572914615754, disc_loss = 0.03666343588021494
Trained batch 31 in epoch 4, gen_loss = 0.4577704044058919, disc_loss = 0.03576018358580768
Trained batch 32 in epoch 4, gen_loss = 0.45678232384450507, disc_loss = 0.03478126876959295
Trained batch 33 in epoch 4, gen_loss = 0.4561721516006133, disc_loss = 0.03396725725820836
Trained batch 34 in epoch 4, gen_loss = 0.4561734974384308, disc_loss = 0.03323797868298633
Trained batch 35 in epoch 4, gen_loss = 0.45856976757446927, disc_loss = 0.033452563272375196
Trained batch 36 in epoch 4, gen_loss = 0.4585999943114616, disc_loss = 0.033015296190372995
Trained batch 37 in epoch 4, gen_loss = 0.4575927430077603, disc_loss = 0.0325252973768664
Trained batch 38 in epoch 4, gen_loss = 0.45776817278984266, disc_loss = 0.0318865372488896
Trained batch 39 in epoch 4, gen_loss = 0.4574430175125599, disc_loss = 0.031214670557528735
Trained batch 40 in epoch 4, gen_loss = 0.45813926981716624, disc_loss = 0.030549671671285136
Trained batch 41 in epoch 4, gen_loss = 0.4592144290606181, disc_loss = 0.030545548081309312
Trained batch 42 in epoch 4, gen_loss = 0.46028397804082827, disc_loss = 0.03011172978467373
Trained batch 43 in epoch 4, gen_loss = 0.4600709229707718, disc_loss = 0.02968661579176445
Trained batch 44 in epoch 4, gen_loss = 0.4604419489701589, disc_loss = 0.029165413892931407
Trained batch 45 in epoch 4, gen_loss = 0.4595813485591308, disc_loss = 0.02877963508438805
Trained batch 46 in epoch 4, gen_loss = 0.45993250608444214, disc_loss = 0.028360620378813844
Trained batch 47 in epoch 4, gen_loss = 0.46062250311175984, disc_loss = 0.027905236017735053
Trained batch 48 in epoch 4, gen_loss = 0.45872868688739077, disc_loss = 0.027911461414579227
Trained batch 49 in epoch 4, gen_loss = 0.4577057123184204, disc_loss = 0.02743748504668474
Trained batch 50 in epoch 4, gen_loss = 0.45582011049869015, disc_loss = 0.027366778575906567
Trained batch 51 in epoch 4, gen_loss = 0.45529863009086025, disc_loss = 0.02707412584613149
Trained batch 52 in epoch 4, gen_loss = 0.45538072372382543, disc_loss = 0.026700477792336693
Trained batch 53 in epoch 4, gen_loss = 0.4562783964254238, disc_loss = 0.02649914213732161
Trained batch 54 in epoch 4, gen_loss = 0.4571191142905842, disc_loss = 0.026188727527518163
Trained batch 55 in epoch 4, gen_loss = 0.4576171955892018, disc_loss = 0.025810166336928626
Trained batch 56 in epoch 4, gen_loss = 0.4570344566253194, disc_loss = 0.02543402058807643
Trained batch 57 in epoch 4, gen_loss = 0.45652166779699, disc_loss = 0.02513666745628519
Trained batch 58 in epoch 4, gen_loss = 0.45558118517115964, disc_loss = 0.024953749985828742
Trained batch 59 in epoch 4, gen_loss = 0.4551835964123408, disc_loss = 0.02467292796354741
Trained batch 60 in epoch 4, gen_loss = 0.4552844943570309, disc_loss = 0.024434437005795905
Trained batch 61 in epoch 4, gen_loss = 0.454314447218372, disc_loss = 0.024194246841474407
Trained batch 62 in epoch 4, gen_loss = 0.4533305319528731, disc_loss = 0.024070314612121335
Trained batch 63 in epoch 4, gen_loss = 0.4531484665349126, disc_loss = 0.023786389298038557
Trained batch 64 in epoch 4, gen_loss = 0.45318212692554183, disc_loss = 0.023648989544464993
Trained batch 65 in epoch 4, gen_loss = 0.45144807208668103, disc_loss = 0.023443833572056257
Trained batch 66 in epoch 4, gen_loss = 0.4515508466692113, disc_loss = 0.023497170991083578
Trained batch 67 in epoch 4, gen_loss = 0.4516403604956234, disc_loss = 0.023567893254735014
Trained batch 68 in epoch 4, gen_loss = 0.45161568254664325, disc_loss = 0.023409281830316868
Trained batch 69 in epoch 4, gen_loss = 0.45096645355224607, disc_loss = 0.02325186493939587
Trained batch 70 in epoch 4, gen_loss = 0.451499944001856, disc_loss = 0.023066369659254248
Trained batch 71 in epoch 4, gen_loss = 0.4511535316705704, disc_loss = 0.022966469198258385
Trained batch 72 in epoch 4, gen_loss = 0.4515802264213562, disc_loss = 0.022814473685846753
Trained batch 73 in epoch 4, gen_loss = 0.44970325521520665, disc_loss = 0.023275311444760173
Trained batch 74 in epoch 4, gen_loss = 0.45051967064539594, disc_loss = 0.026277339172859987
Trained batch 75 in epoch 4, gen_loss = 0.45025874909601715, disc_loss = 0.02644086762723562
Trained batch 76 in epoch 4, gen_loss = 0.45020823316140607, disc_loss = 0.026409464622182504
Trained batch 77 in epoch 4, gen_loss = 0.45012562358990693, disc_loss = 0.027649598637930095
Trained batch 78 in epoch 4, gen_loss = 0.45072610167008414, disc_loss = 0.029499415367181543
Trained batch 79 in epoch 4, gen_loss = 0.45080905184149744, disc_loss = 0.02945667119929567
Trained batch 80 in epoch 4, gen_loss = 0.45099579809624474, disc_loss = 0.029490774393909507
Trained batch 81 in epoch 4, gen_loss = 0.4521519065630145, disc_loss = 0.02923115674497151
Trained batch 82 in epoch 4, gen_loss = 0.45250963482512047, disc_loss = 0.028985714517444014
Trained batch 83 in epoch 4, gen_loss = 0.45191485434770584, disc_loss = 0.02869861642830074
Trained batch 84 in epoch 4, gen_loss = 0.4519278438652263, disc_loss = 0.029381053314051206
Trained batch 85 in epoch 4, gen_loss = 0.4522585383681364, disc_loss = 0.029895622272390957
Trained batch 86 in epoch 4, gen_loss = 0.45168204348662805, disc_loss = 0.029824222823412253
Trained batch 87 in epoch 4, gen_loss = 0.4504714455794204, disc_loss = 0.029824080104431647
Trained batch 88 in epoch 4, gen_loss = 0.45069677608736447, disc_loss = 0.03055940374857589
Trained batch 89 in epoch 4, gen_loss = 0.451140484213829, disc_loss = 0.03182192899079787
Trained batch 90 in epoch 4, gen_loss = 0.45153374102089433, disc_loss = 0.031659399977997764
Trained batch 91 in epoch 4, gen_loss = 0.4508993554374446, disc_loss = 0.03158741293515524
Trained batch 92 in epoch 4, gen_loss = 0.4503382633450211, disc_loss = 0.031408667624477415
Trained batch 93 in epoch 4, gen_loss = 0.4500365482365831, disc_loss = 0.031195016161717
Trained batch 94 in epoch 4, gen_loss = 0.4501527789391969, disc_loss = 0.031003386125360664
Trained batch 95 in epoch 4, gen_loss = 0.45001440898825723, disc_loss = 0.030748814441418897
Trained batch 96 in epoch 4, gen_loss = 0.4496619501679214, disc_loss = 0.03057318153915946
Trained batch 97 in epoch 4, gen_loss = 0.4494547950369971, disc_loss = 0.030319869736855735
Trained batch 98 in epoch 4, gen_loss = 0.44920849559283016, disc_loss = 0.030130547057423327
Trained batch 99 in epoch 4, gen_loss = 0.44894479095935824, disc_loss = 0.029970821114256977
Trained batch 100 in epoch 4, gen_loss = 0.4495760320436836, disc_loss = 0.029806945030346955
Trained batch 101 in epoch 4, gen_loss = 0.45007676412077513, disc_loss = 0.02956009845651102
Trained batch 102 in epoch 4, gen_loss = 0.44951805732782607, disc_loss = 0.029383466384617737
Trained batch 103 in epoch 4, gen_loss = 0.448884303180071, disc_loss = 0.029194352302091338
Trained batch 104 in epoch 4, gen_loss = 0.44969854184559416, disc_loss = 0.029047999907994553
Trained batch 105 in epoch 4, gen_loss = 0.44957649482871004, disc_loss = 0.028896808997675213
Trained batch 106 in epoch 4, gen_loss = 0.44929934188584303, disc_loss = 0.02871018258645852
Trained batch 107 in epoch 4, gen_loss = 0.4490123330442994, disc_loss = 0.028503732294430612
Trained batch 108 in epoch 4, gen_loss = 0.44921430972738, disc_loss = 0.028375045144332384
Trained batch 109 in epoch 4, gen_loss = 0.44815664020451634, disc_loss = 0.028203160396184434
Trained batch 110 in epoch 4, gen_loss = 0.44826919699574375, disc_loss = 0.028213753889373562
Trained batch 111 in epoch 4, gen_loss = 0.44897409847804476, disc_loss = 0.02810292151739954
Trained batch 112 in epoch 4, gen_loss = 0.4497783511085848, disc_loss = 0.028016519324804565
Trained batch 113 in epoch 4, gen_loss = 0.4498373500087805, disc_loss = 0.028014540733573467
Trained batch 114 in epoch 4, gen_loss = 0.44964679894240006, disc_loss = 0.028138531481280274
Trained batch 115 in epoch 4, gen_loss = 0.44870128379813556, disc_loss = 0.028895759694117666
Trained batch 116 in epoch 4, gen_loss = 0.44898779320920634, disc_loss = 0.02944149254845121
Trained batch 117 in epoch 4, gen_loss = 0.44926356966212644, disc_loss = 0.029308039549012052
Trained batch 118 in epoch 4, gen_loss = 0.44890630345384613, disc_loss = 0.029286567618710405
Trained batch 119 in epoch 4, gen_loss = 0.4489091249803702, disc_loss = 0.029689558250053476
Trained batch 120 in epoch 4, gen_loss = 0.448371414310676, disc_loss = 0.02954913933245727
Trained batch 121 in epoch 4, gen_loss = 0.4479218999870488, disc_loss = 0.029388239771341446
Trained batch 122 in epoch 4, gen_loss = 0.44763198058779646, disc_loss = 0.029611875443166593
Trained batch 123 in epoch 4, gen_loss = 0.4481194603347009, disc_loss = 0.029461586265824735
Trained batch 124 in epoch 4, gen_loss = 0.4478771903514862, disc_loss = 0.029314437825232745
Trained batch 125 in epoch 4, gen_loss = 0.44825915353638784, disc_loss = 0.029276875620116553
Trained batch 126 in epoch 4, gen_loss = 0.44800193431809193, disc_loss = 0.029316275068888748
Trained batch 127 in epoch 4, gen_loss = 0.44796124822460115, disc_loss = 0.0301282295731653
Trained batch 128 in epoch 4, gen_loss = 0.4473320259604343, disc_loss = 0.029945996066540942
Trained batch 129 in epoch 4, gen_loss = 0.4472043697650616, disc_loss = 0.030122682685032487
Trained batch 130 in epoch 4, gen_loss = 0.4479083505295615, disc_loss = 0.030010931773239193
Trained batch 131 in epoch 4, gen_loss = 0.44763492025209195, disc_loss = 0.03061279898269497
Trained batch 132 in epoch 4, gen_loss = 0.44816938849320087, disc_loss = 0.030710760486501277
Trained batch 133 in epoch 4, gen_loss = 0.44838468241157814, disc_loss = 0.030608392595104984
Trained batch 134 in epoch 4, gen_loss = 0.44867377126658403, disc_loss = 0.030421177046028553
Trained batch 135 in epoch 4, gen_loss = 0.44787673893220287, disc_loss = 0.030638361620196307
Trained batch 136 in epoch 4, gen_loss = 0.4485705718941932, disc_loss = 0.03091440463683357
Trained batch 137 in epoch 4, gen_loss = 0.44784050877543463, disc_loss = 0.031016918786706916
Trained batch 138 in epoch 4, gen_loss = 0.44740370880785607, disc_loss = 0.03084928963480772
Trained batch 139 in epoch 4, gen_loss = 0.4472298102719443, disc_loss = 0.030905046716465483
Trained batch 140 in epoch 4, gen_loss = 0.44695458323397536, disc_loss = 0.030823593764361126
Trained batch 141 in epoch 4, gen_loss = 0.4471947731266559, disc_loss = 0.03101986224605689
Trained batch 142 in epoch 4, gen_loss = 0.4474068050617938, disc_loss = 0.031089997404235434
Trained batch 143 in epoch 4, gen_loss = 0.4472117964178324, disc_loss = 0.03101834214046701
Trained batch 144 in epoch 4, gen_loss = 0.44722021242667886, disc_loss = 0.030846690726948196
Trained batch 145 in epoch 4, gen_loss = 0.44684047405033894, disc_loss = 0.030774022063419018
Trained batch 146 in epoch 4, gen_loss = 0.4469175616494652, disc_loss = 0.030597874349882814
Trained batch 147 in epoch 4, gen_loss = 0.4467177026577898, disc_loss = 0.030528708738652436
Trained batch 148 in epoch 4, gen_loss = 0.4470824173232853, disc_loss = 0.030388328659304437
Trained batch 149 in epoch 4, gen_loss = 0.44709579209486644, disc_loss = 0.03022535942494869
Trained batch 150 in epoch 4, gen_loss = 0.4466635166414526, disc_loss = 0.030058401605940813
Trained batch 151 in epoch 4, gen_loss = 0.4465787544062263, disc_loss = 0.029985716676731642
Trained batch 152 in epoch 4, gen_loss = 0.4466660145451041, disc_loss = 0.029839949024950758
Trained batch 153 in epoch 4, gen_loss = 0.44652719369956423, disc_loss = 0.02973248152812193
Trained batch 154 in epoch 4, gen_loss = 0.4463482993264352, disc_loss = 0.029602590395558265
Trained batch 155 in epoch 4, gen_loss = 0.44597947482879347, disc_loss = 0.029446428367056143
Trained batch 156 in epoch 4, gen_loss = 0.44583202889011164, disc_loss = 0.029282903838546794
Trained batch 157 in epoch 4, gen_loss = 0.4454530964169321, disc_loss = 0.029292795600817552
Trained batch 158 in epoch 4, gen_loss = 0.44536112351987345, disc_loss = 0.029171896981274557
Trained batch 159 in epoch 4, gen_loss = 0.4457531746476889, disc_loss = 0.029095709568355232
Trained batch 160 in epoch 4, gen_loss = 0.4458269917446634, disc_loss = 0.028962340067077128
Trained batch 161 in epoch 4, gen_loss = 0.4457221555489081, disc_loss = 0.028818229908974452
Trained batch 162 in epoch 4, gen_loss = 0.44555016986431517, disc_loss = 0.028689847739150554
Trained batch 163 in epoch 4, gen_loss = 0.4455948902702913, disc_loss = 0.02856022053648059
Trained batch 164 in epoch 4, gen_loss = 0.4455435010519895, disc_loss = 0.02844085115374941
Trained batch 165 in epoch 4, gen_loss = 0.44616492200328645, disc_loss = 0.02836271801806358
Trained batch 166 in epoch 4, gen_loss = 0.4461439044889576, disc_loss = 0.028346815442075273
Trained batch 167 in epoch 4, gen_loss = 0.4459534897690728, disc_loss = 0.02831036383507862
Trained batch 168 in epoch 4, gen_loss = 0.4457769129403244, disc_loss = 0.028195773570980194
Trained batch 169 in epoch 4, gen_loss = 0.44548616759917314, disc_loss = 0.028180957360960105
Trained batch 170 in epoch 4, gen_loss = 0.44552888159166304, disc_loss = 0.02804832090215202
Trained batch 171 in epoch 4, gen_loss = 0.4456138610839844, disc_loss = 0.027932600215683844
Trained batch 172 in epoch 4, gen_loss = 0.44554009378989995, disc_loss = 0.027793685334998403
Trained batch 173 in epoch 4, gen_loss = 0.4461544192042844, disc_loss = 0.027681335367947476
Trained batch 174 in epoch 4, gen_loss = 0.4466002561364855, disc_loss = 0.027565445931894438
Trained batch 175 in epoch 4, gen_loss = 0.4464489785446362, disc_loss = 0.027451503206975758
Trained batch 176 in epoch 4, gen_loss = 0.4464148254381061, disc_loss = 0.02733100572401016
Trained batch 177 in epoch 4, gen_loss = 0.4462305828091804, disc_loss = 0.027196896388038492
Trained batch 178 in epoch 4, gen_loss = 0.4462047865270902, disc_loss = 0.027092655829294435
Trained batch 179 in epoch 4, gen_loss = 0.44605076544814637, disc_loss = 0.026975451544341115
Trained batch 180 in epoch 4, gen_loss = 0.446042992133462, disc_loss = 0.026911608164728675
Trained batch 181 in epoch 4, gen_loss = 0.44569597843584124, disc_loss = 0.026813501261870612
Trained batch 182 in epoch 4, gen_loss = 0.4453853336188311, disc_loss = 0.026681636024999324
Trained batch 183 in epoch 4, gen_loss = 0.4452572513533675, disc_loss = 0.02657828684238231
Trained batch 184 in epoch 4, gen_loss = 0.4453021639102214, disc_loss = 0.027361638740812603
Trained batch 185 in epoch 4, gen_loss = 0.444843475376406, disc_loss = 0.028731713629758324
Trained batch 186 in epoch 4, gen_loss = 0.444756390098582, disc_loss = 0.029284174845399545
Trained batch 187 in epoch 4, gen_loss = 0.4446466368563632, disc_loss = 0.030073109397446698
Trained batch 188 in epoch 4, gen_loss = 0.4446938167173396, disc_loss = 0.03027310740527889
Trained batch 189 in epoch 4, gen_loss = 0.44462830722332003, disc_loss = 0.030730314491512745
Trained batch 190 in epoch 4, gen_loss = 0.4449297222479476, disc_loss = 0.030972290664657717
Trained batch 191 in epoch 4, gen_loss = 0.44488518747190636, disc_loss = 0.031085038419405464
Trained batch 192 in epoch 4, gen_loss = 0.4450364054175856, disc_loss = 0.031139485149552632
Trained batch 193 in epoch 4, gen_loss = 0.44464432425105693, disc_loss = 0.03117232001386583
Trained batch 194 in epoch 4, gen_loss = 0.44439810315767925, disc_loss = 0.031243848416190118
Trained batch 195 in epoch 4, gen_loss = 0.44440747234894307, disc_loss = 0.031181442463409384
Trained batch 196 in epoch 4, gen_loss = 0.44451660613723215, disc_loss = 0.031214053451844734
Trained batch 197 in epoch 4, gen_loss = 0.44437486144027327, disc_loss = 0.03111614709992827
Trained batch 198 in epoch 4, gen_loss = 0.4446388171545824, disc_loss = 0.031032583107657018
Trained batch 199 in epoch 4, gen_loss = 0.4445684437453747, disc_loss = 0.030936119582038374
Trained batch 200 in epoch 4, gen_loss = 0.44475638406786755, disc_loss = 0.030898292199129342
Trained batch 201 in epoch 4, gen_loss = 0.44503244447826157, disc_loss = 0.030783159895753948
Trained batch 202 in epoch 4, gen_loss = 0.4449945724950048, disc_loss = 0.030733401540740224
Trained batch 203 in epoch 4, gen_loss = 0.44512243086800857, disc_loss = 0.030664033710719178
Trained batch 204 in epoch 4, gen_loss = 0.44500112053824636, disc_loss = 0.03061013385062901
Trained batch 205 in epoch 4, gen_loss = 0.4450614116724255, disc_loss = 0.030544223939746762
Trained batch 206 in epoch 4, gen_loss = 0.44554641684472274, disc_loss = 0.030494258957262634
Trained batch 207 in epoch 4, gen_loss = 0.44557294994592667, disc_loss = 0.030376857278707366
Trained batch 208 in epoch 4, gen_loss = 0.4457124236382936, disc_loss = 0.030302817195778684
Trained batch 209 in epoch 4, gen_loss = 0.445936110048067, disc_loss = 0.030221924715719762
Trained batch 210 in epoch 4, gen_loss = 0.4459205751452966, disc_loss = 0.030124105078331527
Trained batch 211 in epoch 4, gen_loss = 0.44577417578899636, disc_loss = 0.030004629316159857
Trained batch 212 in epoch 4, gen_loss = 0.4457426111742924, disc_loss = 0.02992317565834858
Trained batch 213 in epoch 4, gen_loss = 0.4457544216485781, disc_loss = 0.029834839489276163
Trained batch 214 in epoch 4, gen_loss = 0.44577480596165325, disc_loss = 0.029777370653180188
Trained batch 215 in epoch 4, gen_loss = 0.4458109663316497, disc_loss = 0.029663283589158068
Trained batch 216 in epoch 4, gen_loss = 0.4458262445190535, disc_loss = 0.029560364076807615
Trained batch 217 in epoch 4, gen_loss = 0.44626085227782575, disc_loss = 0.029458698107425227
Trained batch 218 in epoch 4, gen_loss = 0.44625118225132493, disc_loss = 0.029379362291465067
Trained batch 219 in epoch 4, gen_loss = 0.4464871890165589, disc_loss = 0.02933448198336092
Trained batch 220 in epoch 4, gen_loss = 0.4464031920443833, disc_loss = 0.029238107331872525
Trained batch 221 in epoch 4, gen_loss = 0.44636937693969625, disc_loss = 0.029211730285136548
Trained batch 222 in epoch 4, gen_loss = 0.4461147707674001, disc_loss = 0.029100564249995846
Trained batch 223 in epoch 4, gen_loss = 0.44615497200616766, disc_loss = 0.02899229046722342
Trained batch 224 in epoch 4, gen_loss = 0.4460696907838186, disc_loss = 0.028886346220970152
Trained batch 225 in epoch 4, gen_loss = 0.44603758641576347, disc_loss = 0.028844369657799206
Trained batch 226 in epoch 4, gen_loss = 0.446391174840507, disc_loss = 0.028739151077156286
Trained batch 227 in epoch 4, gen_loss = 0.44618938641067135, disc_loss = 0.028628682871880175
Trained batch 228 in epoch 4, gen_loss = 0.4461618388584087, disc_loss = 0.028553882018992408
Trained batch 229 in epoch 4, gen_loss = 0.44609801004762234, disc_loss = 0.028485766708162493
Trained batch 230 in epoch 4, gen_loss = 0.4457404302570211, disc_loss = 0.028406578320727655
Trained batch 231 in epoch 4, gen_loss = 0.4460729392695016, disc_loss = 0.028605256068062614
Trained batch 232 in epoch 4, gen_loss = 0.44585157886083543, disc_loss = 0.028630998815997413
Trained batch 233 in epoch 4, gen_loss = 0.44578656477805895, disc_loss = 0.02859062566043825
Trained batch 234 in epoch 4, gen_loss = 0.44576129799193526, disc_loss = 0.028546446798607072
Trained batch 235 in epoch 4, gen_loss = 0.4458809292922586, disc_loss = 0.0285393515655029
Trained batch 236 in epoch 4, gen_loss = 0.445975797463067, disc_loss = 0.02851256416847277
Trained batch 237 in epoch 4, gen_loss = 0.44595149597700906, disc_loss = 0.028453588797789097
Trained batch 238 in epoch 4, gen_loss = 0.4458858500464691, disc_loss = 0.02836894272304448
Trained batch 239 in epoch 4, gen_loss = 0.44603196655710536, disc_loss = 0.028291482640391528
Trained batch 240 in epoch 4, gen_loss = 0.44589446070777927, disc_loss = 0.02819078854725723
Trained batch 241 in epoch 4, gen_loss = 0.44623590008286407, disc_loss = 0.0281213329160155
Trained batch 242 in epoch 4, gen_loss = 0.4465331800680592, disc_loss = 0.028044335046829082
Trained batch 243 in epoch 4, gen_loss = 0.4463987277179468, disc_loss = 0.02803229722366134
Trained batch 244 in epoch 4, gen_loss = 0.44659821184314025, disc_loss = 0.028003593002997186
Trained batch 245 in epoch 4, gen_loss = 0.4466045905904072, disc_loss = 0.027997987694106996
Trained batch 246 in epoch 4, gen_loss = 0.4462697844997591, disc_loss = 0.027922951726635035
Trained batch 247 in epoch 4, gen_loss = 0.44632339525607323, disc_loss = 0.027864867326570675
Trained batch 248 in epoch 4, gen_loss = 0.44613689758691444, disc_loss = 0.027944447511029112
Trained batch 249 in epoch 4, gen_loss = 0.44587511372566224, disc_loss = 0.027907486365176738
Trained batch 250 in epoch 4, gen_loss = 0.44609751359400046, disc_loss = 0.02789512604745884
Trained batch 251 in epoch 4, gen_loss = 0.446555884584548, disc_loss = 0.027819873074934418
Trained batch 252 in epoch 4, gen_loss = 0.4467003757774594, disc_loss = 0.027753198310445714
Trained batch 253 in epoch 4, gen_loss = 0.44677802685677537, disc_loss = 0.027659199398568295
Trained batch 254 in epoch 4, gen_loss = 0.4469861960878559, disc_loss = 0.0275639147935983
Trained batch 255 in epoch 4, gen_loss = 0.44662425841670483, disc_loss = 0.02747054215433309
Trained batch 256 in epoch 4, gen_loss = 0.44653017302895337, disc_loss = 0.027402520893641716
Trained batch 257 in epoch 4, gen_loss = 0.44633203952811484, disc_loss = 0.027316879564102076
Trained batch 258 in epoch 4, gen_loss = 0.446514535479564, disc_loss = 0.027227804187009232
Trained batch 259 in epoch 4, gen_loss = 0.44647691685419816, disc_loss = 0.027135073074784417
Trained batch 260 in epoch 4, gen_loss = 0.4464332747961826, disc_loss = 0.02706240065096096
Trained batch 261 in epoch 4, gen_loss = 0.44656012133332607, disc_loss = 0.026990849720243053
Trained batch 262 in epoch 4, gen_loss = 0.4466732467308697, disc_loss = 0.026943490656354808
Trained batch 263 in epoch 4, gen_loss = 0.4463261956292571, disc_loss = 0.026857020282257123
Trained batch 264 in epoch 4, gen_loss = 0.4462322392553653, disc_loss = 0.02680761951707163
Trained batch 265 in epoch 4, gen_loss = 0.44628828629515227, disc_loss = 0.026740407979087832
Trained batch 266 in epoch 4, gen_loss = 0.4464214104838139, disc_loss = 0.026655330129093335
Trained batch 267 in epoch 4, gen_loss = 0.4466844121022011, disc_loss = 0.026572586143208638
Trained batch 268 in epoch 4, gen_loss = 0.446680360234803, disc_loss = 0.026482171086476748
Trained batch 269 in epoch 4, gen_loss = 0.44693636220914346, disc_loss = 0.0264116278556348
Trained batch 270 in epoch 4, gen_loss = 0.4468150946047033, disc_loss = 0.026329589787719435
Trained batch 271 in epoch 4, gen_loss = 0.4466095320223009, disc_loss = 0.026246190728510126
Trained batch 272 in epoch 4, gen_loss = 0.4468395010237292, disc_loss = 0.02616610247539459
Trained batch 273 in epoch 4, gen_loss = 0.44678167335308383, disc_loss = 0.02607962428966034
Trained batch 274 in epoch 4, gen_loss = 0.4468420154398138, disc_loss = 0.02599859878928824
Trained batch 275 in epoch 4, gen_loss = 0.44709183340487274, disc_loss = 0.025919093892140234
Trained batch 276 in epoch 4, gen_loss = 0.44698275975371954, disc_loss = 0.025839278300457538
Trained batch 277 in epoch 4, gen_loss = 0.4468657936123635, disc_loss = 0.025754789199525986
Trained batch 278 in epoch 4, gen_loss = 0.4468991235165613, disc_loss = 0.025673169664384324
Trained batch 279 in epoch 4, gen_loss = 0.4468536898493767, disc_loss = 0.02559358130009579
Trained batch 280 in epoch 4, gen_loss = 0.4467858426087267, disc_loss = 0.02551406747462672
Trained batch 281 in epoch 4, gen_loss = 0.44697307346137705, disc_loss = 0.025434341512831814
Trained batch 282 in epoch 4, gen_loss = 0.44688702482638004, disc_loss = 0.025355204312927204
Trained batch 283 in epoch 4, gen_loss = 0.44691885178777535, disc_loss = 0.025279147330750252
Trained batch 284 in epoch 4, gen_loss = 0.44708682330031146, disc_loss = 0.02521400435321164
Trained batch 285 in epoch 4, gen_loss = 0.447008675315997, disc_loss = 0.025145939017248736
Trained batch 286 in epoch 4, gen_loss = 0.4471057927566954, disc_loss = 0.025074760802739172
Trained batch 287 in epoch 4, gen_loss = 0.4468365107766456, disc_loss = 0.02500646232834293
Trained batch 288 in epoch 4, gen_loss = 0.4468761190617373, disc_loss = 0.024942836733889414
Trained batch 289 in epoch 4, gen_loss = 0.4468814492225647, disc_loss = 0.02489433923479298
Trained batch 290 in epoch 4, gen_loss = 0.4470406959146978, disc_loss = 0.024823531276415203
Trained batch 291 in epoch 4, gen_loss = 0.44705115126012124, disc_loss = 0.02475035693879201
Trained batch 292 in epoch 4, gen_loss = 0.4471306316681689, disc_loss = 0.02467686092916482
Trained batch 293 in epoch 4, gen_loss = 0.44720151898812277, disc_loss = 0.024602636664022445
Trained batch 294 in epoch 4, gen_loss = 0.44732802429441676, disc_loss = 0.02453050170867246
Trained batch 295 in epoch 4, gen_loss = 0.447191117885145, disc_loss = 0.02447940077635812
Trained batch 296 in epoch 4, gen_loss = 0.4473167374880627, disc_loss = 0.024408972932665488
Trained batch 297 in epoch 4, gen_loss = 0.4474188081370104, disc_loss = 0.024336537166542355
Trained batch 298 in epoch 4, gen_loss = 0.4474135175795858, disc_loss = 0.02426281734759044
Trained batch 299 in epoch 4, gen_loss = 0.44736846546332043, disc_loss = 0.024189949398860336
Trained batch 300 in epoch 4, gen_loss = 0.4474252718825673, disc_loss = 0.024121592981598505
Trained batch 301 in epoch 4, gen_loss = 0.4473436854730379, disc_loss = 0.024052164369318264
Trained batch 302 in epoch 4, gen_loss = 0.44722712659599756, disc_loss = 0.023981239867977577
Trained batch 303 in epoch 4, gen_loss = 0.44727218337357044, disc_loss = 0.023912665378271702
Trained batch 304 in epoch 4, gen_loss = 0.4473267352971874, disc_loss = 0.023843735799987296
Trained batch 305 in epoch 4, gen_loss = 0.4475900938892676, disc_loss = 0.02377314581018355
Trained batch 306 in epoch 4, gen_loss = 0.4475944951807637, disc_loss = 0.0237026273906959
Trained batch 307 in epoch 4, gen_loss = 0.4475117649931412, disc_loss = 0.023639595278163814
Trained batch 308 in epoch 4, gen_loss = 0.4475723870556717, disc_loss = 0.02357372485137391
Trained batch 309 in epoch 4, gen_loss = 0.4476706217373571, disc_loss = 0.023506031420472407
Trained batch 310 in epoch 4, gen_loss = 0.4476667288031992, disc_loss = 0.02344114626937477
Trained batch 311 in epoch 4, gen_loss = 0.44773941267377293, disc_loss = 0.023377796253696896
Trained batch 312 in epoch 4, gen_loss = 0.44779485587875684, disc_loss = 0.02331191150117487
Trained batch 313 in epoch 4, gen_loss = 0.4477023139690897, disc_loss = 0.02324458534508991
Trained batch 314 in epoch 4, gen_loss = 0.4476012944229065, disc_loss = 0.023177668142561166
Trained batch 315 in epoch 4, gen_loss = 0.4475127135085154, disc_loss = 0.02310990458398562
Trained batch 316 in epoch 4, gen_loss = 0.4474410081887471, disc_loss = 0.023063359481696778
Trained batch 317 in epoch 4, gen_loss = 0.4474607171877375, disc_loss = 0.023010683532236086
Trained batch 318 in epoch 4, gen_loss = 0.44757212553652104, disc_loss = 0.022950012455066685
Trained batch 319 in epoch 4, gen_loss = 0.44760387260466816, disc_loss = 0.022886633454618277
Trained batch 320 in epoch 4, gen_loss = 0.4474856614880844, disc_loss = 0.022827435246410538
Trained batch 321 in epoch 4, gen_loss = 0.4474231146322274, disc_loss = 0.022770370071123338
Trained batch 322 in epoch 4, gen_loss = 0.4473617085177832, disc_loss = 0.02270946721546352
Trained batch 323 in epoch 4, gen_loss = 0.44720568627486995, disc_loss = 0.022647901121268257
Trained batch 324 in epoch 4, gen_loss = 0.44728895535835855, disc_loss = 0.02258984064181837
Trained batch 325 in epoch 4, gen_loss = 0.44742478585682033, disc_loss = 0.022528400118291332
Trained batch 326 in epoch 4, gen_loss = 0.44744669388558156, disc_loss = 0.0224665687554758
Trained batch 327 in epoch 4, gen_loss = 0.4473186076232573, disc_loss = 0.02241429306563876
Trained batch 328 in epoch 4, gen_loss = 0.447531890995959, disc_loss = 0.022362886533837504
Trained batch 329 in epoch 4, gen_loss = 0.44747169902830414, disc_loss = 0.022305304019457916
Trained batch 330 in epoch 4, gen_loss = 0.4473943346576748, disc_loss = 0.02224937089285574
Trained batch 331 in epoch 4, gen_loss = 0.4475125111190669, disc_loss = 0.022190815901681107
Trained batch 332 in epoch 4, gen_loss = 0.4474283933818519, disc_loss = 0.022132319376549428
Trained batch 333 in epoch 4, gen_loss = 0.44749043756973245, disc_loss = 0.02207217268955275
Trained batch 334 in epoch 4, gen_loss = 0.4474248748217056, disc_loss = 0.022017468003305927
Trained batch 335 in epoch 4, gen_loss = 0.4474408769359191, disc_loss = 0.021959228899850997
Trained batch 336 in epoch 4, gen_loss = 0.4475487837628724, disc_loss = 0.021920537591278995
Trained batch 337 in epoch 4, gen_loss = 0.4476085846593394, disc_loss = 0.02186440541023201
Trained batch 338 in epoch 4, gen_loss = 0.4475474929035941, disc_loss = 0.02181741212711705
Trained batch 339 in epoch 4, gen_loss = 0.4474421987638754, disc_loss = 0.02176058829132029
Trained batch 340 in epoch 4, gen_loss = 0.4474466490256122, disc_loss = 0.021705490888623506
Trained batch 341 in epoch 4, gen_loss = 0.4474174799452051, disc_loss = 0.0216586200080605
Trained batch 342 in epoch 4, gen_loss = 0.44743977196015006, disc_loss = 0.021604115751628974
Trained batch 343 in epoch 4, gen_loss = 0.4471988095793613, disc_loss = 0.021549704149609085
Trained batch 344 in epoch 4, gen_loss = 0.4471920937731646, disc_loss = 0.0215022851895217
Trained batch 345 in epoch 4, gen_loss = 0.44733100500754536, disc_loss = 0.021447313575994633
Trained batch 346 in epoch 4, gen_loss = 0.44733697390693755, disc_loss = 0.021398565888281387
Trained batch 347 in epoch 4, gen_loss = 0.4472200709512864, disc_loss = 0.02135355866597109
Trained batch 348 in epoch 4, gen_loss = 0.44716301893436466, disc_loss = 0.021298155933751974
Trained batch 349 in epoch 4, gen_loss = 0.4470581547703062, disc_loss = 0.021245572477179977
Trained batch 350 in epoch 4, gen_loss = 0.4471539865192185, disc_loss = 0.021195557526978756
Trained batch 351 in epoch 4, gen_loss = 0.44709695562381635, disc_loss = 0.021144759705004453
Trained batch 352 in epoch 4, gen_loss = 0.4471272943546684, disc_loss = 0.02109028420031134
Trained batch 353 in epoch 4, gen_loss = 0.4472159700373472, disc_loss = 0.021036362920040633
Trained batch 354 in epoch 4, gen_loss = 0.44715246633744576, disc_loss = 0.020984665903879304
Trained batch 355 in epoch 4, gen_loss = 0.44718659342674727, disc_loss = 0.020935816413675843
Trained batch 356 in epoch 4, gen_loss = 0.4473583190714946, disc_loss = 0.020884014722820716
Trained batch 357 in epoch 4, gen_loss = 0.4474571077517291, disc_loss = 0.020831136278126536
Trained batch 358 in epoch 4, gen_loss = 0.4474747231577764, disc_loss = 0.020785630402391293
Trained batch 359 in epoch 4, gen_loss = 0.4475111202233367, disc_loss = 0.02073368540344139
Trained batch 360 in epoch 4, gen_loss = 0.4475143901033745, disc_loss = 0.020681429761100736
Trained batch 361 in epoch 4, gen_loss = 0.4474164799926031, disc_loss = 0.020630422530333044
Trained batch 362 in epoch 4, gen_loss = 0.447357951199056, disc_loss = 0.020579985998116803
Trained batch 363 in epoch 4, gen_loss = 0.4474772022484423, disc_loss = 0.020531825261679224
Trained batch 364 in epoch 4, gen_loss = 0.44730472540202204, disc_loss = 0.020482555268115477
Trained batch 365 in epoch 4, gen_loss = 0.44724857823444847, disc_loss = 0.02043264781543476
Trained batch 366 in epoch 4, gen_loss = 0.44732469352779336, disc_loss = 0.02038318655492956
Trained batch 367 in epoch 4, gen_loss = 0.4472518311408551, disc_loss = 0.02033394816079754
Trained batch 368 in epoch 4, gen_loss = 0.4473067938796873, disc_loss = 0.02028388060821185
Trained batch 369 in epoch 4, gen_loss = 0.44739687869677675, disc_loss = 0.020236103005103163
Trained batch 370 in epoch 4, gen_loss = 0.4472839167979207, disc_loss = 0.020190938468771482
Trained batch 371 in epoch 4, gen_loss = 0.44737339628640044, disc_loss = 0.020142528264763294
Trained batch 372 in epoch 4, gen_loss = 0.447415834936955, disc_loss = 0.02009502090214085
Trained batch 373 in epoch 4, gen_loss = 0.4474909045798256, disc_loss = 0.02007055172029345
Trained batch 374 in epoch 4, gen_loss = 0.4477325277328491, disc_loss = 0.02002919355283181
Trained batch 375 in epoch 4, gen_loss = 0.44770396794093414, disc_loss = 0.020001388533892942
Trained batch 376 in epoch 4, gen_loss = 0.44761551367193064, disc_loss = 0.019963303269615856
Trained batch 377 in epoch 4, gen_loss = 0.447569396366518, disc_loss = 0.01992149282586835
Trained batch 378 in epoch 4, gen_loss = 0.44771981168548164, disc_loss = 0.019876993935810782
Trained batch 379 in epoch 4, gen_loss = 0.44768517997704055, disc_loss = 0.019828761496434085
Trained batch 380 in epoch 4, gen_loss = 0.44758651763435425, disc_loss = 0.01978124905129518
Trained batch 381 in epoch 4, gen_loss = 0.44748993810870885, disc_loss = 0.019735299032218073
Trained batch 382 in epoch 4, gen_loss = 0.44755125535997337, disc_loss = 0.019687695337238166
Trained batch 383 in epoch 4, gen_loss = 0.4476522367137174, disc_loss = 0.019645063902316906
Trained batch 384 in epoch 4, gen_loss = 0.44766365668990393, disc_loss = 0.019599558959424786
Trained batch 385 in epoch 4, gen_loss = 0.44755886958361907, disc_loss = 0.01955532637597279
Trained batch 386 in epoch 4, gen_loss = 0.4476104917760351, disc_loss = 0.019510636918634194
Trained batch 387 in epoch 4, gen_loss = 0.44778793573993997, disc_loss = 0.019466571990801405
Trained batch 388 in epoch 4, gen_loss = 0.44757160429476467, disc_loss = 0.019426207579756133
Trained batch 389 in epoch 4, gen_loss = 0.44748000961083634, disc_loss = 0.01938378952163009
Trained batch 390 in epoch 4, gen_loss = 0.44743189894024976, disc_loss = 0.01933868170586055
Trained batch 391 in epoch 4, gen_loss = 0.4473909019511573, disc_loss = 0.019293962271316262
Trained batch 392 in epoch 4, gen_loss = 0.44741619004851385, disc_loss = 0.019251598931822936
Trained batch 393 in epoch 4, gen_loss = 0.44735490958097623, disc_loss = 0.019208162063011795
Trained batch 394 in epoch 4, gen_loss = 0.4474598431889015, disc_loss = 0.019169574263623528
Trained batch 395 in epoch 4, gen_loss = 0.4474575776192877, disc_loss = 0.01912883328211569
Trained batch 396 in epoch 4, gen_loss = 0.44752392045196415, disc_loss = 0.019088276707384295
Trained batch 397 in epoch 4, gen_loss = 0.44759609838526454, disc_loss = 0.01905367514393503
Trained batch 398 in epoch 4, gen_loss = 0.4475475132913518, disc_loss = 0.019015180154465475
Trained batch 399 in epoch 4, gen_loss = 0.4473776192963123, disc_loss = 0.018972086051653604
Trained batch 400 in epoch 4, gen_loss = 0.4474724884193734, disc_loss = 0.018930106919939325
Trained batch 401 in epoch 4, gen_loss = 0.44753019608075345, disc_loss = 0.018892510935712828
Trained batch 402 in epoch 4, gen_loss = 0.44747543253614647, disc_loss = 0.018852957885160063
Trained batch 403 in epoch 4, gen_loss = 0.44747986991216643, disc_loss = 0.01881686285614165
Trained batch 404 in epoch 4, gen_loss = 0.4474025866131724, disc_loss = 0.018774815792516792
Trained batch 405 in epoch 4, gen_loss = 0.4474987401604065, disc_loss = 0.018735058087249987
Trained batch 406 in epoch 4, gen_loss = 0.44743782933572585, disc_loss = 0.018697514506491673
Trained batch 407 in epoch 4, gen_loss = 0.44747403439353495, disc_loss = 0.018662397877550592
Trained batch 408 in epoch 4, gen_loss = 0.44751937246555806, disc_loss = 0.01862399286503988
Trained batch 409 in epoch 4, gen_loss = 0.44733009585520117, disc_loss = 0.018583662018020888
Trained batch 410 in epoch 4, gen_loss = 0.44726738282943873, disc_loss = 0.01855056408346334
Trained batch 411 in epoch 4, gen_loss = 0.4474881230627449, disc_loss = 0.018516016333449847
Trained batch 412 in epoch 4, gen_loss = 0.44748424098220346, disc_loss = 0.018480812628431015
Trained batch 413 in epoch 4, gen_loss = 0.4474934059496663, disc_loss = 0.018445208869483053
Trained batch 414 in epoch 4, gen_loss = 0.44748068236442934, disc_loss = 0.018406556469264878
Trained batch 415 in epoch 4, gen_loss = 0.4475344942452816, disc_loss = 0.018368974494828414
Trained batch 416 in epoch 4, gen_loss = 0.44772868347968414, disc_loss = 0.018337341718938496
Trained batch 417 in epoch 4, gen_loss = 0.44785669403213063, disc_loss = 0.018297871918992348
Trained batch 418 in epoch 4, gen_loss = 0.44778092394011687, disc_loss = 0.018262035101163147
Trained batch 419 in epoch 4, gen_loss = 0.44775743725753964, disc_loss = 0.018226109590337033
Trained batch 420 in epoch 4, gen_loss = 0.4476253136178377, disc_loss = 0.01819036500871341
Trained batch 421 in epoch 4, gen_loss = 0.4474350812169613, disc_loss = 0.018161002227096372
Trained batch 422 in epoch 4, gen_loss = 0.44750831094757604, disc_loss = 0.018124372538742797
Trained batch 423 in epoch 4, gen_loss = 0.4474349904032248, disc_loss = 0.018088193161123135
Trained batch 424 in epoch 4, gen_loss = 0.44751437628970425, disc_loss = 0.018054314189426164
Trained batch 425 in epoch 4, gen_loss = 0.4477433323720251, disc_loss = 0.018022278990015003
Trained batch 426 in epoch 4, gen_loss = 0.4477786637441336, disc_loss = 0.017984964916988578
Trained batch 427 in epoch 4, gen_loss = 0.4476462319911083, disc_loss = 0.017948013294605696
Trained batch 428 in epoch 4, gen_loss = 0.44745415949321293, disc_loss = 0.017921117499648725
Trained batch 429 in epoch 4, gen_loss = 0.44737474883711614, disc_loss = 0.01788530046022822
Trained batch 430 in epoch 4, gen_loss = 0.4474544772692457, disc_loss = 0.01785151526092048
Trained batch 431 in epoch 4, gen_loss = 0.4474279602506646, disc_loss = 0.01782249658275827
Trained batch 432 in epoch 4, gen_loss = 0.4473715261416402, disc_loss = 0.01778600426330543
Trained batch 433 in epoch 4, gen_loss = 0.44749863802837336, disc_loss = 0.017754087146277183
Trained batch 434 in epoch 4, gen_loss = 0.4474906241071635, disc_loss = 0.017717588698523568
Trained batch 435 in epoch 4, gen_loss = 0.4475768430654062, disc_loss = 0.017682216873813265
Trained batch 436 in epoch 4, gen_loss = 0.4475764687465039, disc_loss = 0.017653979053369188
Trained batch 437 in epoch 4, gen_loss = 0.4475114321055478, disc_loss = 0.017619525096496166
Trained batch 438 in epoch 4, gen_loss = 0.44741152644428955, disc_loss = 0.017593051012285088
Trained batch 439 in epoch 4, gen_loss = 0.44740046404979444, disc_loss = 0.01755746765252711
Trained batch 440 in epoch 4, gen_loss = 0.4473450873173824, disc_loss = 0.01752562174581988
Trained batch 441 in epoch 4, gen_loss = 0.44749857114450964, disc_loss = 0.017498090029883777
Trained batch 442 in epoch 4, gen_loss = 0.4475728093770503, disc_loss = 0.01747220142746584
Trained batch 443 in epoch 4, gen_loss = 0.44754756476965035, disc_loss = 0.017442621045267663
Trained batch 444 in epoch 4, gen_loss = 0.4475800011934859, disc_loss = 0.017408474042404736
Trained batch 445 in epoch 4, gen_loss = 0.4475843552917643, disc_loss = 0.017373880970233326
Trained batch 446 in epoch 4, gen_loss = 0.4476583435364751, disc_loss = 0.017343990581310136
Trained batch 447 in epoch 4, gen_loss = 0.44756654230877757, disc_loss = 0.017311889539476915
Trained batch 448 in epoch 4, gen_loss = 0.4476186384204236, disc_loss = 0.01727800167534907
Trained batch 449 in epoch 4, gen_loss = 0.4476421329047945, disc_loss = 0.017243442012307545
Trained batch 450 in epoch 4, gen_loss = 0.44778067567396057, disc_loss = 0.017211307214465645
Trained batch 451 in epoch 4, gen_loss = 0.4477227433724741, disc_loss = 0.017179746300278777
Trained batch 452 in epoch 4, gen_loss = 0.44788532166291545, disc_loss = 0.017147917481381898
Trained batch 453 in epoch 4, gen_loss = 0.44785828389522786, disc_loss = 0.01712546775236496
Trained batch 454 in epoch 4, gen_loss = 0.44779049511794206, disc_loss = 0.017126632222885286
Trained batch 455 in epoch 4, gen_loss = 0.447805803007724, disc_loss = 0.017095672925055976
Trained batch 456 in epoch 4, gen_loss = 0.44777603620251627, disc_loss = 0.017070485188786746
Trained batch 457 in epoch 4, gen_loss = 0.4478042593559323, disc_loss = 0.017040289681726117
Trained batch 458 in epoch 4, gen_loss = 0.4476157532668062, disc_loss = 0.017009664982788605
Trained batch 459 in epoch 4, gen_loss = 0.44761743383563085, disc_loss = 0.016998253605308253
Trained batch 460 in epoch 4, gen_loss = 0.4477577038157788, disc_loss = 0.016980328444096537
Trained batch 461 in epoch 4, gen_loss = 0.44773894116217955, disc_loss = 0.016950447902030985
Trained batch 462 in epoch 4, gen_loss = 0.44773559069530494, disc_loss = 0.016917950392260215
Trained batch 463 in epoch 4, gen_loss = 0.4477458542919365, disc_loss = 0.016895823048202897
Trained batch 464 in epoch 4, gen_loss = 0.4477677580489907, disc_loss = 0.016869307470618076
Trained batch 465 in epoch 4, gen_loss = 0.44776644266726123, disc_loss = 0.016870568703276467
Trained batch 466 in epoch 4, gen_loss = 0.4476429294212472, disc_loss = 0.01684144168505864
Trained batch 467 in epoch 4, gen_loss = 0.4476965370341244, disc_loss = 0.016826685359820914
Trained batch 468 in epoch 4, gen_loss = 0.4477292564886211, disc_loss = 0.016800025153333252
Trained batch 469 in epoch 4, gen_loss = 0.44768171297742965, disc_loss = 0.016772894695044515
Trained batch 470 in epoch 4, gen_loss = 0.4477911361210412, disc_loss = 0.016755176920665235
Trained batch 471 in epoch 4, gen_loss = 0.44787530405289033, disc_loss = 0.016762656525716627
Trained batch 472 in epoch 4, gen_loss = 0.4478863068791323, disc_loss = 0.016779835970902986
Trained batch 473 in epoch 4, gen_loss = 0.4480156431343988, disc_loss = 0.016766715998160122
Trained batch 474 in epoch 4, gen_loss = 0.4479543607485922, disc_loss = 0.01674145821481943
Trained batch 475 in epoch 4, gen_loss = 0.4478656612649685, disc_loss = 0.0167178212960462
Trained batch 476 in epoch 4, gen_loss = 0.4479419829585517, disc_loss = 0.016693569985325733
Trained batch 477 in epoch 4, gen_loss = 0.44806622317894734, disc_loss = 0.016683548684991802
Trained batch 478 in epoch 4, gen_loss = 0.44790117470605884, disc_loss = 0.016706318293147893
Trained batch 479 in epoch 4, gen_loss = 0.44790152392039695, disc_loss = 0.016723008764286836
Trained batch 480 in epoch 4, gen_loss = 0.44793067373753587, disc_loss = 0.01690759209300277
Trained batch 481 in epoch 4, gen_loss = 0.4478431467693376, disc_loss = 0.016894526675312597
Trained batch 482 in epoch 4, gen_loss = 0.44765758026954305, disc_loss = 0.017300378758745658
Trained batch 483 in epoch 4, gen_loss = 0.4478140578659113, disc_loss = 0.017510780668240196
Trained batch 484 in epoch 4, gen_loss = 0.44794626918035685, disc_loss = 0.01767878684877735
Trained batch 485 in epoch 4, gen_loss = 0.44795894346855303, disc_loss = 0.017704864553800582
Trained batch 486 in epoch 4, gen_loss = 0.4478733185258, disc_loss = 0.017935605842077023
Trained batch 487 in epoch 4, gen_loss = 0.447911339766178, disc_loss = 0.0182621854884153
Trained batch 488 in epoch 4, gen_loss = 0.44781331330964413, disc_loss = 0.01825757402781938
Trained batch 489 in epoch 4, gen_loss = 0.44759389581728953, disc_loss = 0.018346245986010347
Trained batch 490 in epoch 4, gen_loss = 0.4476018015090414, disc_loss = 0.01834669509284244
Trained batch 491 in epoch 4, gen_loss = 0.4476101233707211, disc_loss = 0.018582787701663207
Trained batch 492 in epoch 4, gen_loss = 0.44738168890529423, disc_loss = 0.018932619519365486
Trained batch 493 in epoch 4, gen_loss = 0.4473008716154678, disc_loss = 0.018947627474572737
Trained batch 494 in epoch 4, gen_loss = 0.44724426588626826, disc_loss = 0.018996038359373506
Trained batch 495 in epoch 4, gen_loss = 0.4472382843734757, disc_loss = 0.01902516333070854
Trained batch 496 in epoch 4, gen_loss = 0.44700172231710655, disc_loss = 0.01909132062324456
Trained batch 497 in epoch 4, gen_loss = 0.44698954478325137, disc_loss = 0.019143929252453357
Trained batch 498 in epoch 4, gen_loss = 0.44699605576738805, disc_loss = 0.01921267757838021
Trained batch 499 in epoch 4, gen_loss = 0.4469960895776749, disc_loss = 0.019224957235157488
Trained batch 500 in epoch 4, gen_loss = 0.44693849971908295, disc_loss = 0.019236297943367217
Trained batch 501 in epoch 4, gen_loss = 0.4469119087752118, disc_loss = 0.01921726191839374
Trained batch 502 in epoch 4, gen_loss = 0.44696968444299034, disc_loss = 0.019372462737512874
Trained batch 503 in epoch 4, gen_loss = 0.44687385650144684, disc_loss = 0.019656075889037714
Trained batch 504 in epoch 4, gen_loss = 0.44688577976557287, disc_loss = 0.019665121803484342
Trained batch 505 in epoch 4, gen_loss = 0.4469833431154372, disc_loss = 0.019702179939025947
Trained batch 506 in epoch 4, gen_loss = 0.4469278470063821, disc_loss = 0.01970323392684173
Trained batch 507 in epoch 4, gen_loss = 0.4468884724448985, disc_loss = 0.019701652698160158
Trained batch 508 in epoch 4, gen_loss = 0.4467939766661826, disc_loss = 0.019696549064166888
Trained batch 509 in epoch 4, gen_loss = 0.44686435770754723, disc_loss = 0.01970380366067676
Trained batch 510 in epoch 4, gen_loss = 0.44673573253439364, disc_loss = 0.01974808258859262
Trained batch 511 in epoch 4, gen_loss = 0.44652918924111873, disc_loss = 0.01978701512052794
Trained batch 512 in epoch 4, gen_loss = 0.44645104259543017, disc_loss = 0.01981228715277206
Trained batch 513 in epoch 4, gen_loss = 0.4462107643774975, disc_loss = 0.019802312114808693
Trained batch 514 in epoch 4, gen_loss = 0.44620301399416135, disc_loss = 0.019779883930911717
Trained batch 515 in epoch 4, gen_loss = 0.4461944574533507, disc_loss = 0.019870258346127795
Trained batch 516 in epoch 4, gen_loss = 0.44625812734349324, disc_loss = 0.020017786342398456
Trained batch 517 in epoch 4, gen_loss = 0.4461901057295818, disc_loss = 0.02013272308640211
Trained batch 518 in epoch 4, gen_loss = 0.4462951668080567, disc_loss = 0.020245405432619226
Trained batch 519 in epoch 4, gen_loss = 0.44618869475447215, disc_loss = 0.02022545424540742
Trained batch 520 in epoch 4, gen_loss = 0.4461326517894035, disc_loss = 0.020212281522146228
Trained batch 521 in epoch 4, gen_loss = 0.44619342753256874, disc_loss = 0.020182596282298425
Trained batch 522 in epoch 4, gen_loss = 0.446204326006924, disc_loss = 0.020158649147105318
Trained batch 523 in epoch 4, gen_loss = 0.446214895098264, disc_loss = 0.02013771960828169
Trained batch 524 in epoch 4, gen_loss = 0.44621339724177406, disc_loss = 0.020119119390313113
Trained batch 525 in epoch 4, gen_loss = 0.4461817149880268, disc_loss = 0.020105401100944942
Trained batch 526 in epoch 4, gen_loss = 0.4462998813650866, disc_loss = 0.0201116749209191
Trained batch 527 in epoch 4, gen_loss = 0.44626071947542106, disc_loss = 0.02009544781652618
Trained batch 528 in epoch 4, gen_loss = 0.44638184203092, disc_loss = 0.02007017922825365
Trained batch 529 in epoch 4, gen_loss = 0.4464148425830985, disc_loss = 0.020054520311642367
Trained batch 530 in epoch 4, gen_loss = 0.4464375411498794, disc_loss = 0.020028027269126333
Trained batch 531 in epoch 4, gen_loss = 0.44659506176647384, disc_loss = 0.020000981131946684
Trained batch 532 in epoch 4, gen_loss = 0.4465986954338331, disc_loss = 0.019972489425112226
Trained batch 533 in epoch 4, gen_loss = 0.446516029006533, disc_loss = 0.01994381643210848
Trained batch 534 in epoch 4, gen_loss = 0.4466442673562843, disc_loss = 0.019920396540209512
Trained batch 535 in epoch 4, gen_loss = 0.4467224792869233, disc_loss = 0.01989959269664737
Trained batch 536 in epoch 4, gen_loss = 0.4467106880533407, disc_loss = 0.01987159524452864
Trained batch 537 in epoch 4, gen_loss = 0.4466363708436711, disc_loss = 0.019839058270103203
Trained batch 538 in epoch 4, gen_loss = 0.44659524193942435, disc_loss = 0.01980830374750929
Trained batch 539 in epoch 4, gen_loss = 0.4466131213638518, disc_loss = 0.019782560246703388
Trained batch 540 in epoch 4, gen_loss = 0.44656954664399573, disc_loss = 0.019756647514165577
Trained batch 541 in epoch 4, gen_loss = 0.44658753000942103, disc_loss = 0.01972606442860118
Trained batch 542 in epoch 4, gen_loss = 0.4465490756882269, disc_loss = 0.01971552483728893
Trained batch 543 in epoch 4, gen_loss = 0.446644504335435, disc_loss = 0.019716722737939563
Trained batch 544 in epoch 4, gen_loss = 0.44663172298615134, disc_loss = 0.01970476395826479
Trained batch 545 in epoch 4, gen_loss = 0.44662650666394077, disc_loss = 0.019686805936780797
Trained batch 546 in epoch 4, gen_loss = 0.44670170452956526, disc_loss = 0.019660207098588293
Trained batch 547 in epoch 4, gen_loss = 0.44659488180475515, disc_loss = 0.019641883057341606
Trained batch 548 in epoch 4, gen_loss = 0.4465109834036975, disc_loss = 0.019610633954443107
Trained batch 549 in epoch 4, gen_loss = 0.44643883846022864, disc_loss = 0.01958062150007622
Trained batch 550 in epoch 4, gen_loss = 0.4463834155709255, disc_loss = 0.019549430395305805
Trained batch 551 in epoch 4, gen_loss = 0.4464961848613145, disc_loss = 0.019525393730609852
Trained batch 552 in epoch 4, gen_loss = 0.4465034676826884, disc_loss = 0.019494354322798564
Trained batch 553 in epoch 4, gen_loss = 0.4466893671329271, disc_loss = 0.019466080453620034
Trained batch 554 in epoch 4, gen_loss = 0.4467622437455633, disc_loss = 0.019436449547054934
Trained batch 555 in epoch 4, gen_loss = 0.4468332653423007, disc_loss = 0.01940967845135844
Trained batch 556 in epoch 4, gen_loss = 0.44692141919846595, disc_loss = 0.019383545152766087
Trained batch 557 in epoch 4, gen_loss = 0.4469966057380895, disc_loss = 0.01935262680654564
Trained batch 558 in epoch 4, gen_loss = 0.4470985256708585, disc_loss = 0.01932713961518621
Trained batch 559 in epoch 4, gen_loss = 0.4469675506332091, disc_loss = 0.01929745245558609
Trained batch 560 in epoch 4, gen_loss = 0.44689100970133955, disc_loss = 0.019272129496297204
Trained batch 561 in epoch 4, gen_loss = 0.4468593102120844, disc_loss = 0.019241129502229844
Trained batch 562 in epoch 4, gen_loss = 0.4469401640006958, disc_loss = 0.019211608814786903
Trained batch 563 in epoch 4, gen_loss = 0.4469334883153016, disc_loss = 0.019183113302041425
Trained batch 564 in epoch 4, gen_loss = 0.44701140153724533, disc_loss = 0.01915250157719
Trained batch 565 in epoch 4, gen_loss = 0.44702741351018105, disc_loss = 0.019121628676297624
Trained batch 566 in epoch 4, gen_loss = 0.4469928276286554, disc_loss = 0.019092918652055597
Trained batch 567 in epoch 4, gen_loss = 0.44689367150127046, disc_loss = 0.01906321102812309
Trained batch 568 in epoch 4, gen_loss = 0.44689358998685813, disc_loss = 0.019032610067197486
Trained batch 569 in epoch 4, gen_loss = 0.44702384315038984, disc_loss = 0.019006255392409993
Trained batch 570 in epoch 4, gen_loss = 0.4469775157718024, disc_loss = 0.018978365506135228
Trained batch 571 in epoch 4, gen_loss = 0.4470926519040461, disc_loss = 0.018949564918794286
Trained batch 572 in epoch 4, gen_loss = 0.4471095395753937, disc_loss = 0.018920113099738955
Trained batch 573 in epoch 4, gen_loss = 0.44715194087410637, disc_loss = 0.018890431195210326
Trained batch 574 in epoch 4, gen_loss = 0.4470340371131897, disc_loss = 0.018862357762156296
Trained batch 575 in epoch 4, gen_loss = 0.4469429911631677, disc_loss = 0.018832854338446243
Trained batch 576 in epoch 4, gen_loss = 0.44694657331942683, disc_loss = 0.018804761780864935
Trained batch 577 in epoch 4, gen_loss = 0.4469657321702238, disc_loss = 0.018775106764802946
Trained batch 578 in epoch 4, gen_loss = 0.4468234515457779, disc_loss = 0.01874599156403409
Trained batch 579 in epoch 4, gen_loss = 0.4468167227917704, disc_loss = 0.01871742008290061
Trained batch 580 in epoch 4, gen_loss = 0.44674401511013406, disc_loss = 0.018688022927461245
Trained batch 581 in epoch 4, gen_loss = 0.44678374838173596, disc_loss = 0.01865939653252133
Trained batch 582 in epoch 4, gen_loss = 0.4467941568605282, disc_loss = 0.01863127247263449
Trained batch 583 in epoch 4, gen_loss = 0.4467388777291938, disc_loss = 0.01860169432311772
Trained batch 584 in epoch 4, gen_loss = 0.4467088517979679, disc_loss = 0.018586205926914817
Trained batch 585 in epoch 4, gen_loss = 0.44672181688681395, disc_loss = 0.018569074064348556
Trained batch 586 in epoch 4, gen_loss = 0.44663287640836413, disc_loss = 0.018542537448437507
Trained batch 587 in epoch 4, gen_loss = 0.44663158337883396, disc_loss = 0.01851477443108329
Trained batch 588 in epoch 4, gen_loss = 0.4466900779456153, disc_loss = 0.018489286302927257
Trained batch 589 in epoch 4, gen_loss = 0.4467302383002588, disc_loss = 0.018461713775147888
Trained batch 590 in epoch 4, gen_loss = 0.4467266235759012, disc_loss = 0.01843444955895313
Trained batch 591 in epoch 4, gen_loss = 0.4466744557123732, disc_loss = 0.018405779545089998
Trained batch 592 in epoch 4, gen_loss = 0.446686019985913, disc_loss = 0.0183783584145961
Trained batch 593 in epoch 4, gen_loss = 0.44673465362903647, disc_loss = 0.018350709240486915
Trained batch 594 in epoch 4, gen_loss = 0.4467814377876891, disc_loss = 0.018324293603361467
Trained batch 595 in epoch 4, gen_loss = 0.44680634425990534, disc_loss = 0.01829670634430883
Trained batch 596 in epoch 4, gen_loss = 0.44672353298620165, disc_loss = 0.018270062588637313
Trained batch 597 in epoch 4, gen_loss = 0.4467681393675182, disc_loss = 0.01824258239223407
Trained batch 598 in epoch 4, gen_loss = 0.4468800537474764, disc_loss = 0.018216842493176063
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.4500047266483307, disc_loss = 0.0042663938365876675
Trained batch 1 in epoch 5, gen_loss = 0.49672384560108185, disc_loss = 0.0038626225432381034
Trained batch 2 in epoch 5, gen_loss = 0.4893780251344045, disc_loss = 0.0032845030849178634
Trained batch 3 in epoch 5, gen_loss = 0.47489260882139206, disc_loss = 0.0035391622222959995
Trained batch 4 in epoch 5, gen_loss = 0.4745550394058228, disc_loss = 0.003914413973689079
Trained batch 5 in epoch 5, gen_loss = 0.46943023800849915, disc_loss = 0.0036703512305393815
Trained batch 6 in epoch 5, gen_loss = 0.46431629572595867, disc_loss = 0.003467585924746735
Trained batch 7 in epoch 5, gen_loss = 0.4595729075372219, disc_loss = 0.003282233636127785
Trained batch 8 in epoch 5, gen_loss = 0.45594271686342025, disc_loss = 0.0031238289989738
Trained batch 9 in epoch 5, gen_loss = 0.4564620316028595, disc_loss = 0.003104516037274152
Trained batch 10 in epoch 5, gen_loss = 0.4560618996620178, disc_loss = 0.003041868362660435
Trained batch 11 in epoch 5, gen_loss = 0.45605649302403134, disc_loss = 0.0030677997953413674
Trained batch 12 in epoch 5, gen_loss = 0.45687954930158764, disc_loss = 0.004602469315824027
Trained batch 13 in epoch 5, gen_loss = 0.45625520391123636, disc_loss = 0.005044359406123736
Trained batch 14 in epoch 5, gen_loss = 0.4549595952033997, disc_loss = 0.0049455651625369985
Trained batch 15 in epoch 5, gen_loss = 0.4535181298851967, disc_loss = 0.0047875852542347275
Trained batch 16 in epoch 5, gen_loss = 0.4500309071120094, disc_loss = 0.004685486838057199
Trained batch 17 in epoch 5, gen_loss = 0.4479059742556678, disc_loss = 0.004747312807012349
Trained batch 18 in epoch 5, gen_loss = 0.4491711007921319, disc_loss = 0.004712638720919035
Trained batch 19 in epoch 5, gen_loss = 0.45027778297662735, disc_loss = 0.004609373566927389
Trained batch 20 in epoch 5, gen_loss = 0.44854104093142916, disc_loss = 0.004542817544591214
Trained batch 21 in epoch 5, gen_loss = 0.45037326216697693, disc_loss = 0.004687016750474207
Trained batch 22 in epoch 5, gen_loss = 0.4466734010240306, disc_loss = 0.004745689549726312
Trained batch 23 in epoch 5, gen_loss = 0.44241988286376, disc_loss = 0.004797322311787866
Trained batch 24 in epoch 5, gen_loss = 0.44045629143714904, disc_loss = 0.004940995895303786
Trained batch 25 in epoch 5, gen_loss = 0.43793178636294144, disc_loss = 0.004864918735200683
Trained batch 26 in epoch 5, gen_loss = 0.43880599295651473, disc_loss = 0.004763917950050974
Trained batch 27 in epoch 5, gen_loss = 0.43888218488012043, disc_loss = 0.004662454789338101
Trained batch 28 in epoch 5, gen_loss = 0.43856736606565017, disc_loss = 0.004565973617618197
Trained batch 29 in epoch 5, gen_loss = 0.4399364550908407, disc_loss = 0.00448361731832847
Trained batch 30 in epoch 5, gen_loss = 0.44025059765385044, disc_loss = 0.004419396109428377
Trained batch 31 in epoch 5, gen_loss = 0.4401805568486452, disc_loss = 0.004361273593531223
Trained batch 32 in epoch 5, gen_loss = 0.44040299906875147, disc_loss = 0.004316117787366789
Trained batch 33 in epoch 5, gen_loss = 0.440730729523827, disc_loss = 0.004252293540904408
Trained batch 34 in epoch 5, gen_loss = 0.4411868751049042, disc_loss = 0.004179940642123776
Trained batch 35 in epoch 5, gen_loss = 0.44156542585955727, disc_loss = 0.0041539906362433815
Trained batch 36 in epoch 5, gen_loss = 0.44004598582113114, disc_loss = 0.004092860101671839
Trained batch 37 in epoch 5, gen_loss = 0.4393215657849061, disc_loss = 0.00402982419319941
Trained batch 38 in epoch 5, gen_loss = 0.43641153360024476, disc_loss = 0.003969326364592864
Trained batch 39 in epoch 5, gen_loss = 0.43503016605973244, disc_loss = 0.003951127361506224
Trained batch 40 in epoch 5, gen_loss = 0.4374144317173376, disc_loss = 0.003913044725067732
Trained batch 41 in epoch 5, gen_loss = 0.43802816172440845, disc_loss = 0.003920463412734014
Trained batch 42 in epoch 5, gen_loss = 0.43652668248775395, disc_loss = 0.0038938617312111136
Trained batch 43 in epoch 5, gen_loss = 0.4380165948109193, disc_loss = 0.0038654000381939113
Trained batch 44 in epoch 5, gen_loss = 0.43909744421641034, disc_loss = 0.0038426576647907495
Trained batch 45 in epoch 5, gen_loss = 0.43959607637446857, disc_loss = 0.0038249171794513645
Trained batch 46 in epoch 5, gen_loss = 0.4396017111362295, disc_loss = 0.0038228831204407394
Trained batch 47 in epoch 5, gen_loss = 0.43876796836654347, disc_loss = 0.003807086953505253
Trained batch 48 in epoch 5, gen_loss = 0.43934417135861453, disc_loss = 0.0037645257876387666
Trained batch 49 in epoch 5, gen_loss = 0.4397551089525223, disc_loss = 0.0037310837954282763
Trained batch 50 in epoch 5, gen_loss = 0.43851977411438436, disc_loss = 0.003715594500011089
Trained batch 51 in epoch 5, gen_loss = 0.43864056582634264, disc_loss = 0.0036811491143173324
Trained batch 52 in epoch 5, gen_loss = 0.43852455211135577, disc_loss = 0.003640172583543045
Trained batch 53 in epoch 5, gen_loss = 0.440243590761114, disc_loss = 0.0036333780153654516
Trained batch 54 in epoch 5, gen_loss = 0.44075774225321684, disc_loss = 0.003618799067441035
Trained batch 55 in epoch 5, gen_loss = 0.4409265959901469, disc_loss = 0.0036006060025621472
Trained batch 56 in epoch 5, gen_loss = 0.44201158692962245, disc_loss = 0.003595511802766276
Trained batch 57 in epoch 5, gen_loss = 0.4429997894270667, disc_loss = 0.0036083745974886776
Trained batch 58 in epoch 5, gen_loss = 0.4455551141399448, disc_loss = 0.003648033955576435
Trained batch 59 in epoch 5, gen_loss = 0.4446449980139732, disc_loss = 0.003682305491141354
Trained batch 60 in epoch 5, gen_loss = 0.4448852744258818, disc_loss = 0.0036592085742712267
Trained batch 61 in epoch 5, gen_loss = 0.44552141427993774, disc_loss = 0.0036433146338939906
Trained batch 62 in epoch 5, gen_loss = 0.4455666854268029, disc_loss = 0.0036133761307047237
Trained batch 63 in epoch 5, gen_loss = 0.4454738702625036, disc_loss = 0.0035970800872746622
Trained batch 64 in epoch 5, gen_loss = 0.44592119180239165, disc_loss = 0.0035714355995878576
Trained batch 65 in epoch 5, gen_loss = 0.44565996437361743, disc_loss = 0.0035629784035722187
Trained batch 66 in epoch 5, gen_loss = 0.44541092061284765, disc_loss = 0.0035407581043415772
Trained batch 67 in epoch 5, gen_loss = 0.44512343757292805, disc_loss = 0.0035357912814052883
Trained batch 68 in epoch 5, gen_loss = 0.4451878947624262, disc_loss = 0.0035428698461475797
Trained batch 69 in epoch 5, gen_loss = 0.44521198528153555, disc_loss = 0.003533156294309135
Trained batch 70 in epoch 5, gen_loss = 0.4455700676206132, disc_loss = 0.0035308869112886383
Trained batch 71 in epoch 5, gen_loss = 0.4455090786019961, disc_loss = 0.003515832713067842
Trained batch 72 in epoch 5, gen_loss = 0.44537861420683666, disc_loss = 0.0035758658857658913
Trained batch 73 in epoch 5, gen_loss = 0.4460424055924287, disc_loss = 0.003639241974687556
Trained batch 74 in epoch 5, gen_loss = 0.4465826431910197, disc_loss = 0.003655201884297033
Trained batch 75 in epoch 5, gen_loss = 0.44655165938954605, disc_loss = 0.003878808474646097
Trained batch 76 in epoch 5, gen_loss = 0.4472814008787081, disc_loss = 0.00390615308651241
Trained batch 77 in epoch 5, gen_loss = 0.4471883170115642, disc_loss = 0.003939295598031141
Trained batch 78 in epoch 5, gen_loss = 0.44737795825246013, disc_loss = 0.00403109136703601
Trained batch 79 in epoch 5, gen_loss = 0.4466826770454645, disc_loss = 0.004019618527672719
Trained batch 80 in epoch 5, gen_loss = 0.44681814680864784, disc_loss = 0.004129642923937443
Trained batch 81 in epoch 5, gen_loss = 0.4469101378103582, disc_loss = 0.004111566744097395
Trained batch 82 in epoch 5, gen_loss = 0.4467144472053252, disc_loss = 0.00440031059327569
Trained batch 83 in epoch 5, gen_loss = 0.44667109350363415, disc_loss = 0.0044392072470925215
Trained batch 84 in epoch 5, gen_loss = 0.44635431696386896, disc_loss = 0.004491846514044001
Trained batch 85 in epoch 5, gen_loss = 0.4467530770357265, disc_loss = 0.004476676328205179
Trained batch 86 in epoch 5, gen_loss = 0.44571196210795433, disc_loss = 0.004508994724440934
Trained batch 87 in epoch 5, gen_loss = 0.44637454504316504, disc_loss = 0.004549435870351524
Trained batch 88 in epoch 5, gen_loss = 0.4454213960117169, disc_loss = 0.004583213102920086
Trained batch 89 in epoch 5, gen_loss = 0.44528829289807215, disc_loss = 0.004608853804206269
Trained batch 90 in epoch 5, gen_loss = 0.44576457142829895, disc_loss = 0.00463846777847221
Trained batch 91 in epoch 5, gen_loss = 0.44553502519493515, disc_loss = 0.004668655396570735
Trained batch 92 in epoch 5, gen_loss = 0.4454328404959812, disc_loss = 0.0046513290632696404
Trained batch 93 in epoch 5, gen_loss = 0.44586383155051695, disc_loss = 0.004650410313030428
Trained batch 94 in epoch 5, gen_loss = 0.4456163801644978, disc_loss = 0.004630063727841173
Trained batch 95 in epoch 5, gen_loss = 0.4454696864510576, disc_loss = 0.004608890130233097
Trained batch 96 in epoch 5, gen_loss = 0.4450265104623185, disc_loss = 0.004589604147825122
Trained batch 97 in epoch 5, gen_loss = 0.4452402768086414, disc_loss = 0.004589715593599011
Trained batch 98 in epoch 5, gen_loss = 0.4459290889778523, disc_loss = 0.004590698486109349
Trained batch 99 in epoch 5, gen_loss = 0.4459826773405075, disc_loss = 0.004587641410762444
Trained batch 100 in epoch 5, gen_loss = 0.4466291370958385, disc_loss = 0.004620683975379435
Trained batch 101 in epoch 5, gen_loss = 0.44771920465955545, disc_loss = 0.004608865303453058
Trained batch 102 in epoch 5, gen_loss = 0.44814904598356453, disc_loss = 0.0046907753459837975
Trained batch 103 in epoch 5, gen_loss = 0.44828076689289165, disc_loss = 0.004697672822378361
Trained batch 104 in epoch 5, gen_loss = 0.44849943291573297, disc_loss = 0.004965241906410527
Trained batch 105 in epoch 5, gen_loss = 0.44845564297910007, disc_loss = 0.005467993063404101
Trained batch 106 in epoch 5, gen_loss = 0.44897181185606483, disc_loss = 0.005783748975084555
Trained batch 107 in epoch 5, gen_loss = 0.4489178017333702, disc_loss = 0.005872012681922772
Trained batch 108 in epoch 5, gen_loss = 0.4487944559766612, disc_loss = 0.005930256437074496
Trained batch 109 in epoch 5, gen_loss = 0.44859684082594786, disc_loss = 0.0059219488588331095
Trained batch 110 in epoch 5, gen_loss = 0.44891754463986233, disc_loss = 0.006001984470876286
Trained batch 111 in epoch 5, gen_loss = 0.4492516102535384, disc_loss = 0.0060401124615704505
Trained batch 112 in epoch 5, gen_loss = 0.4490165404513874, disc_loss = 0.006104986542893524
Trained batch 113 in epoch 5, gen_loss = 0.44954292972882587, disc_loss = 0.0063573335626227944
Trained batch 114 in epoch 5, gen_loss = 0.44833927750587466, disc_loss = 0.006597209516305314
Trained batch 115 in epoch 5, gen_loss = 0.4492522347076186, disc_loss = 0.006814866347824512
Trained batch 116 in epoch 5, gen_loss = 0.44904407043742317, disc_loss = 0.006795192755257281
Trained batch 117 in epoch 5, gen_loss = 0.4494246044906519, disc_loss = 0.006774166453890187
Trained batch 118 in epoch 5, gen_loss = 0.4495307287248243, disc_loss = 0.00674545151443698
Trained batch 119 in epoch 5, gen_loss = 0.44984407822291056, disc_loss = 0.006743887626604798
Trained batch 120 in epoch 5, gen_loss = 0.44962220694407945, disc_loss = 0.006868059786367576
Trained batch 121 in epoch 5, gen_loss = 0.44973000932912355, disc_loss = 0.006885878727427821
Trained batch 122 in epoch 5, gen_loss = 0.4505148481547348, disc_loss = 0.006888531785405324
Trained batch 123 in epoch 5, gen_loss = 0.4499316770703562, disc_loss = 0.006938766268449986
Trained batch 124 in epoch 5, gen_loss = 0.45030345582962034, disc_loss = 0.006912043293006718
Trained batch 125 in epoch 5, gen_loss = 0.45014574603428914, disc_loss = 0.006925628155595549
Trained batch 126 in epoch 5, gen_loss = 0.45029411822792115, disc_loss = 0.006911810323427336
Trained batch 127 in epoch 5, gen_loss = 0.45001568738371134, disc_loss = 0.006900357316226291
Trained batch 128 in epoch 5, gen_loss = 0.45000179146611413, disc_loss = 0.006877133961182174
Trained batch 129 in epoch 5, gen_loss = 0.4500099938649398, disc_loss = 0.006924042957297598
Trained batch 130 in epoch 5, gen_loss = 0.450442127599061, disc_loss = 0.006973044185202484
Trained batch 131 in epoch 5, gen_loss = 0.4511134127775828, disc_loss = 0.007109684466603071
Trained batch 132 in epoch 5, gen_loss = 0.45116589190368367, disc_loss = 0.007133800857630383
Trained batch 133 in epoch 5, gen_loss = 0.4517852096860088, disc_loss = 0.007295898536268844
Trained batch 134 in epoch 5, gen_loss = 0.45182329526653997, disc_loss = 0.007326429115642828
Trained batch 135 in epoch 5, gen_loss = 0.45140501133659305, disc_loss = 0.0073209844164974875
Trained batch 136 in epoch 5, gen_loss = 0.45107114271525917, disc_loss = 0.0073244432862644105
Trained batch 137 in epoch 5, gen_loss = 0.45091043153534766, disc_loss = 0.007294332283798713
Trained batch 138 in epoch 5, gen_loss = 0.4506557459453885, disc_loss = 0.007686959940558232
Trained batch 139 in epoch 5, gen_loss = 0.45108545294829777, disc_loss = 0.008895020904518398
Trained batch 140 in epoch 5, gen_loss = 0.4507608339718893, disc_loss = 0.010071214710375465
Trained batch 141 in epoch 5, gen_loss = 0.45127870016534566, disc_loss = 0.01040925875119209
Trained batch 142 in epoch 5, gen_loss = 0.4509045427495783, disc_loss = 0.010693740463568146
Trained batch 143 in epoch 5, gen_loss = 0.450655952302946, disc_loss = 0.011353478688559134
Trained batch 144 in epoch 5, gen_loss = 0.4511263615098493, disc_loss = 0.011888400772747039
Trained batch 145 in epoch 5, gen_loss = 0.4511575704976304, disc_loss = 0.011908220330553053
Trained batch 146 in epoch 5, gen_loss = 0.451112203249315, disc_loss = 0.012145194116517344
Trained batch 147 in epoch 5, gen_loss = 0.45075123374526566, disc_loss = 0.012112165882245864
Trained batch 148 in epoch 5, gen_loss = 0.4508024634130849, disc_loss = 0.01215722619934045
Trained batch 149 in epoch 5, gen_loss = 0.4507628007729848, disc_loss = 0.012105660111798594
Trained batch 150 in epoch 5, gen_loss = 0.4500982062706095, disc_loss = 0.012111388506916728
Trained batch 151 in epoch 5, gen_loss = 0.44963554116456134, disc_loss = 0.01214396815339569
Trained batch 152 in epoch 5, gen_loss = 0.449919870671104, disc_loss = 0.012201600862526961
Trained batch 153 in epoch 5, gen_loss = 0.4499692655615992, disc_loss = 0.012167173633563587
Trained batch 154 in epoch 5, gen_loss = 0.4500418730320469, disc_loss = 0.012111442364121396
Trained batch 155 in epoch 5, gen_loss = 0.45045200544290054, disc_loss = 0.012095405238841731
Trained batch 156 in epoch 5, gen_loss = 0.4508958149487805, disc_loss = 0.012051601368477154
Trained batch 157 in epoch 5, gen_loss = 0.4512176885257793, disc_loss = 0.011992641314245241
Trained batch 158 in epoch 5, gen_loss = 0.45132726037277365, disc_loss = 0.011948866824584329
Trained batch 159 in epoch 5, gen_loss = 0.4512846577912569, disc_loss = 0.011923147181369132
Trained batch 160 in epoch 5, gen_loss = 0.45122571576456105, disc_loss = 0.01188119453947806
Trained batch 161 in epoch 5, gen_loss = 0.4512334245222586, disc_loss = 0.011854427684828594
Trained batch 162 in epoch 5, gen_loss = 0.451587270373947, disc_loss = 0.012091147972619377
Trained batch 163 in epoch 5, gen_loss = 0.45096991647307466, disc_loss = 0.012106701500980728
Trained batch 164 in epoch 5, gen_loss = 0.4507773547461539, disc_loss = 0.013125499221496284
Trained batch 165 in epoch 5, gen_loss = 0.4513556673584214, disc_loss = 0.014744009370270398
Trained batch 166 in epoch 5, gen_loss = 0.45129994004072543, disc_loss = 0.014872889270766186
Trained batch 167 in epoch 5, gen_loss = 0.4512535156238647, disc_loss = 0.015269712718907699
Trained batch 168 in epoch 5, gen_loss = 0.450689375047853, disc_loss = 0.01547689321134019
Trained batch 169 in epoch 5, gen_loss = 0.4507166382144479, disc_loss = 0.01612585361923694
Trained batch 170 in epoch 5, gen_loss = 0.45008132035969295, disc_loss = 0.017241013499810116
Trained batch 171 in epoch 5, gen_loss = 0.4503397135887035, disc_loss = 0.019634887572719043
Trained batch 172 in epoch 5, gen_loss = 0.44943406213225656, disc_loss = 0.022233560419576835
Trained batch 173 in epoch 5, gen_loss = 0.44942628275388957, disc_loss = 0.02707965671681617
Trained batch 174 in epoch 5, gen_loss = 0.44926989998136246, disc_loss = 0.03153700402472168
Trained batch 175 in epoch 5, gen_loss = 0.4494067823345011, disc_loss = 0.03296712802561656
Trained batch 176 in epoch 5, gen_loss = 0.4493109141029207, disc_loss = 0.034313217728230365
Trained batch 177 in epoch 5, gen_loss = 0.4488690420148078, disc_loss = 0.0351856920961029
Trained batch 178 in epoch 5, gen_loss = 0.4479635356191816, disc_loss = 0.036128369619804514
Trained batch 179 in epoch 5, gen_loss = 0.44719215085109076, disc_loss = 0.036877752506148276
Trained batch 180 in epoch 5, gen_loss = 0.44656454775873466, disc_loss = 0.037494886395758154
Trained batch 181 in epoch 5, gen_loss = 0.44601685987724055, disc_loss = 0.038164544478954315
Trained batch 182 in epoch 5, gen_loss = 0.4454859811100152, disc_loss = 0.03843905222716695
Trained batch 183 in epoch 5, gen_loss = 0.44514111008333124, disc_loss = 0.03880499728193567
Trained batch 184 in epoch 5, gen_loss = 0.44462787831151807, disc_loss = 0.038891013587724316
Trained batch 185 in epoch 5, gen_loss = 0.4440041599414682, disc_loss = 0.03913645828530813
Trained batch 186 in epoch 5, gen_loss = 0.44352976619241075, disc_loss = 0.039274072321256334
Trained batch 187 in epoch 5, gen_loss = 0.4431852806121745, disc_loss = 0.03961047131575624
Trained batch 188 in epoch 5, gen_loss = 0.44333638511006795, disc_loss = 0.03982583998773917
Trained batch 189 in epoch 5, gen_loss = 0.4427563954340784, disc_loss = 0.039984175461761064
Trained batch 190 in epoch 5, gen_loss = 0.44285817764192353, disc_loss = 0.03999527662453676
Trained batch 191 in epoch 5, gen_loss = 0.4426629253042241, disc_loss = 0.04018510227797378
Trained batch 192 in epoch 5, gen_loss = 0.442671401358639, disc_loss = 0.04100400566212698
Trained batch 193 in epoch 5, gen_loss = 0.44251789167984246, disc_loss = 0.041101032346559055
Trained batch 194 in epoch 5, gen_loss = 0.44223585862379805, disc_loss = 0.04120359363165708
Trained batch 195 in epoch 5, gen_loss = 0.4420921367650129, disc_loss = 0.04131212778928766
Trained batch 196 in epoch 5, gen_loss = 0.44182573326953173, disc_loss = 0.041786988012298826
Trained batch 197 in epoch 5, gen_loss = 0.4413986120260123, disc_loss = 0.04211816625996502
Trained batch 198 in epoch 5, gen_loss = 0.4411568397553123, disc_loss = 0.041990957205913886
Trained batch 199 in epoch 5, gen_loss = 0.44125904455780984, disc_loss = 0.04266595936089288
Trained batch 200 in epoch 5, gen_loss = 0.4408858194576567, disc_loss = 0.04256602403283842
Trained batch 201 in epoch 5, gen_loss = 0.44044657051563263, disc_loss = 0.043230940216096435
Trained batch 202 in epoch 5, gen_loss = 0.44025457360474346, disc_loss = 0.04329091757065685
Trained batch 203 in epoch 5, gen_loss = 0.4396800721685092, disc_loss = 0.043432158022530046
Trained batch 204 in epoch 5, gen_loss = 0.4393546703385144, disc_loss = 0.04367281549848707
Trained batch 205 in epoch 5, gen_loss = 0.43929005595086845, disc_loss = 0.0439934845786605
Trained batch 206 in epoch 5, gen_loss = 0.4388966843989736, disc_loss = 0.044411666319561574
Trained batch 207 in epoch 5, gen_loss = 0.4385955167504457, disc_loss = 0.04459239555636976
Trained batch 208 in epoch 5, gen_loss = 0.4386433040696468, disc_loss = 0.044933103583641706
Trained batch 209 in epoch 5, gen_loss = 0.43867030030205134, disc_loss = 0.044859302245147
Trained batch 210 in epoch 5, gen_loss = 0.438455398190078, disc_loss = 0.04496668595809631
Trained batch 211 in epoch 5, gen_loss = 0.43854421475585903, disc_loss = 0.04494376588373375
Trained batch 212 in epoch 5, gen_loss = 0.4388963103014539, disc_loss = 0.04481040045975362
Trained batch 213 in epoch 5, gen_loss = 0.43881127210420984, disc_loss = 0.04465394188317026
Trained batch 214 in epoch 5, gen_loss = 0.4384963906088541, disc_loss = 0.045257592614371935
Trained batch 215 in epoch 5, gen_loss = 0.4380291658971045, disc_loss = 0.04655826891744423
Trained batch 216 in epoch 5, gen_loss = 0.437882630231743, disc_loss = 0.04650782973748044
Trained batch 217 in epoch 5, gen_loss = 0.43776671684116397, disc_loss = 0.046449912111210814
Trained batch 218 in epoch 5, gen_loss = 0.43752936508557566, disc_loss = 0.046455172963810396
Trained batch 219 in epoch 5, gen_loss = 0.43760035200552505, disc_loss = 0.046403694793645464
Trained batch 220 in epoch 5, gen_loss = 0.4376137511492854, disc_loss = 0.046283162217397596
Trained batch 221 in epoch 5, gen_loss = 0.4374851921388695, disc_loss = 0.046266573721958276
Trained batch 222 in epoch 5, gen_loss = 0.43775320240200366, disc_loss = 0.046779720652994655
Trained batch 223 in epoch 5, gen_loss = 0.4374234444860901, disc_loss = 0.04823731672357618
Trained batch 224 in epoch 5, gen_loss = 0.43748566057946947, disc_loss = 0.04857848930431323
Trained batch 225 in epoch 5, gen_loss = 0.4373715368256105, disc_loss = 0.04893825376000404
Trained batch 226 in epoch 5, gen_loss = 0.4373038419017708, disc_loss = 0.04903371410294629
Trained batch 227 in epoch 5, gen_loss = 0.4369817255881795, disc_loss = 0.04908894392684216
Trained batch 228 in epoch 5, gen_loss = 0.4371361433158275, disc_loss = 0.04902341507739229
Trained batch 229 in epoch 5, gen_loss = 0.43709688743819364, disc_loss = 0.04886379850694262
Trained batch 230 in epoch 5, gen_loss = 0.4371206501087585, disc_loss = 0.048708581314744724
Trained batch 231 in epoch 5, gen_loss = 0.43743792086325844, disc_loss = 0.04861586538679368
Trained batch 232 in epoch 5, gen_loss = 0.43738824679104554, disc_loss = 0.04871954382926849
Trained batch 233 in epoch 5, gen_loss = 0.4374004910644303, disc_loss = 0.04875689440229748
Trained batch 234 in epoch 5, gen_loss = 0.4375813070763933, disc_loss = 0.04908944521485729
Trained batch 235 in epoch 5, gen_loss = 0.43738937706260356, disc_loss = 0.04912255067620979
Trained batch 236 in epoch 5, gen_loss = 0.4374937074345375, disc_loss = 0.04926249156322896
Trained batch 237 in epoch 5, gen_loss = 0.4377254491844097, disc_loss = 0.04924934923388612
Trained batch 238 in epoch 5, gen_loss = 0.4378673289610252, disc_loss = 0.04925992841117287
Trained batch 239 in epoch 5, gen_loss = 0.4376042994360129, disc_loss = 0.04961309196417763
Trained batch 240 in epoch 5, gen_loss = 0.4370921290019736, disc_loss = 0.04983649838134198
Trained batch 241 in epoch 5, gen_loss = 0.4367043241735332, disc_loss = 0.04975792403238602
Trained batch 242 in epoch 5, gen_loss = 0.4371684275782157, disc_loss = 0.04964711171538481
Trained batch 243 in epoch 5, gen_loss = 0.43710482450293714, disc_loss = 0.04966496565659744
Trained batch 244 in epoch 5, gen_loss = 0.437118009888396, disc_loss = 0.04957350805088193
Trained batch 245 in epoch 5, gen_loss = 0.4371416951582684, disc_loss = 0.049637251807569824
Trained batch 246 in epoch 5, gen_loss = 0.4370083545866283, disc_loss = 0.04960176283220274
Trained batch 247 in epoch 5, gen_loss = 0.43718554656351766, disc_loss = 0.049498122900390185
Trained batch 248 in epoch 5, gen_loss = 0.43729966112887525, disc_loss = 0.04934702716519061
Trained batch 249 in epoch 5, gen_loss = 0.43716687214374544, disc_loss = 0.04921657030424103
Trained batch 250 in epoch 5, gen_loss = 0.4373902398276614, disc_loss = 0.04910427663035587
Trained batch 251 in epoch 5, gen_loss = 0.4370197640761497, disc_loss = 0.04901834859813948
Trained batch 252 in epoch 5, gen_loss = 0.4372962495319457, disc_loss = 0.04888731652913107
Trained batch 253 in epoch 5, gen_loss = 0.4372298909923223, disc_loss = 0.04875658688045613
Trained batch 254 in epoch 5, gen_loss = 0.43750631505367804, disc_loss = 0.04858401323823879
Trained batch 255 in epoch 5, gen_loss = 0.43773933651391417, disc_loss = 0.04840992598428784
Trained batch 256 in epoch 5, gen_loss = 0.437736167402119, disc_loss = 0.048234708781593305
Trained batch 257 in epoch 5, gen_loss = 0.4378332864175471, disc_loss = 0.048066353274224136
Trained batch 258 in epoch 5, gen_loss = 0.4378308079647742, disc_loss = 0.04791335733544484
Trained batch 259 in epoch 5, gen_loss = 0.43797371696967347, disc_loss = 0.04776332386670849
Trained batch 260 in epoch 5, gen_loss = 0.43807185849467456, disc_loss = 0.047600133259338234
Trained batch 261 in epoch 5, gen_loss = 0.4380286535006443, disc_loss = 0.04743378531438377
Trained batch 262 in epoch 5, gen_loss = 0.4381024468081079, disc_loss = 0.047276121515076
Trained batch 263 in epoch 5, gen_loss = 0.4381112718220913, disc_loss = 0.04711559398680093
Trained batch 264 in epoch 5, gen_loss = 0.43812869832200824, disc_loss = 0.0469645391468767
Trained batch 265 in epoch 5, gen_loss = 0.43802160181497274, disc_loss = 0.046802965842302945
Trained batch 266 in epoch 5, gen_loss = 0.43768868531180677, disc_loss = 0.04665605892551093
Trained batch 267 in epoch 5, gen_loss = 0.4377458344644575, disc_loss = 0.04649305681449556
Trained batch 268 in epoch 5, gen_loss = 0.43792723988954907, disc_loss = 0.04634809642761849
Trained batch 269 in epoch 5, gen_loss = 0.4379490512388724, disc_loss = 0.0462013834263888
Trained batch 270 in epoch 5, gen_loss = 0.43796156286313526, disc_loss = 0.046098911592211037
Trained batch 271 in epoch 5, gen_loss = 0.43829049969858985, disc_loss = 0.045979022117321355
Trained batch 272 in epoch 5, gen_loss = 0.43829848849293074, disc_loss = 0.045838176017378086
Trained batch 273 in epoch 5, gen_loss = 0.4384540684901885, disc_loss = 0.04568953550952643
Trained batch 274 in epoch 5, gen_loss = 0.43848264293237166, disc_loss = 0.04558459724087945
Trained batch 275 in epoch 5, gen_loss = 0.43879055534152017, disc_loss = 0.045507552445127185
Trained batch 276 in epoch 5, gen_loss = 0.43856520170769536, disc_loss = 0.04536496819331502
Trained batch 277 in epoch 5, gen_loss = 0.43868449244567814, disc_loss = 0.04521532189946876
Trained batch 278 in epoch 5, gen_loss = 0.4390041623064267, disc_loss = 0.045075484922432796
Trained batch 279 in epoch 5, gen_loss = 0.4388271522309099, disc_loss = 0.04492911381821614
Trained batch 280 in epoch 5, gen_loss = 0.4387460643710615, disc_loss = 0.04481432760951318
Trained batch 281 in epoch 5, gen_loss = 0.43885227974424973, disc_loss = 0.04468356313040242
Trained batch 282 in epoch 5, gen_loss = 0.4391102133707107, disc_loss = 0.04455671869851846
Trained batch 283 in epoch 5, gen_loss = 0.43909755454096994, disc_loss = 0.04441136608111777
Trained batch 284 in epoch 5, gen_loss = 0.4389180580774943, disc_loss = 0.044271906181401983
Trained batch 285 in epoch 5, gen_loss = 0.43880902741338823, disc_loss = 0.044129011448769066
Trained batch 286 in epoch 5, gen_loss = 0.4386457438460626, disc_loss = 0.043992541285429655
Trained batch 287 in epoch 5, gen_loss = 0.43873733147564864, disc_loss = 0.043848801057821324
Trained batch 288 in epoch 5, gen_loss = 0.4388281950488635, disc_loss = 0.043708974957566024
Trained batch 289 in epoch 5, gen_loss = 0.438745768830694, disc_loss = 0.04363672279006127
Trained batch 290 in epoch 5, gen_loss = 0.4386497152220343, disc_loss = 0.04355974632829005
Trained batch 291 in epoch 5, gen_loss = 0.43858076795323253, disc_loss = 0.043439494412031966
Trained batch 292 in epoch 5, gen_loss = 0.4385832923467656, disc_loss = 0.04343900396432982
Trained batch 293 in epoch 5, gen_loss = 0.4384402947969177, disc_loss = 0.04336406363191742
Trained batch 294 in epoch 5, gen_loss = 0.4384056154954231, disc_loss = 0.04325349017212136
Trained batch 295 in epoch 5, gen_loss = 0.43836298474186175, disc_loss = 0.043152586910543286
Trained batch 296 in epoch 5, gen_loss = 0.4385947517875068, disc_loss = 0.04302538476330902
Trained batch 297 in epoch 5, gen_loss = 0.4384865943817484, disc_loss = 0.042920642966426434
Trained batch 298 in epoch 5, gen_loss = 0.4382460061523029, disc_loss = 0.0427939189815221
Trained batch 299 in epoch 5, gen_loss = 0.43817829648653667, disc_loss = 0.042674064986640586
Trained batch 300 in epoch 5, gen_loss = 0.4381096938321757, disc_loss = 0.04254823346178285
Trained batch 301 in epoch 5, gen_loss = 0.43809577763475327, disc_loss = 0.042566054184159374
Trained batch 302 in epoch 5, gen_loss = 0.43780046248986776, disc_loss = 0.04311630373056855
Trained batch 303 in epoch 5, gen_loss = 0.43781958089063044, disc_loss = 0.04310989293911629
Trained batch 304 in epoch 5, gen_loss = 0.43781751589696916, disc_loss = 0.04311601155414628
Trained batch 305 in epoch 5, gen_loss = 0.4376004930415185, disc_loss = 0.043624695680740296
Trained batch 306 in epoch 5, gen_loss = 0.43769287732991025, disc_loss = 0.04365161148465697
Trained batch 307 in epoch 5, gen_loss = 0.4378114112398841, disc_loss = 0.04367100378285259
Trained batch 308 in epoch 5, gen_loss = 0.4379353335181486, disc_loss = 0.04357590490588949
Trained batch 309 in epoch 5, gen_loss = 0.43769054807001545, disc_loss = 0.04349016054916466
Trained batch 310 in epoch 5, gen_loss = 0.43783303136994217, disc_loss = 0.04336874771652102
Trained batch 311 in epoch 5, gen_loss = 0.4380530822926607, disc_loss = 0.043271404489179335
Trained batch 312 in epoch 5, gen_loss = 0.43805017381811295, disc_loss = 0.04315496926953177
Trained batch 313 in epoch 5, gen_loss = 0.4380509240232455, disc_loss = 0.04303443894809064
Trained batch 314 in epoch 5, gen_loss = 0.4379921379543486, disc_loss = 0.04291072227171667
Trained batch 315 in epoch 5, gen_loss = 0.43804705444770525, disc_loss = 0.04278281943826889
Trained batch 316 in epoch 5, gen_loss = 0.43785136919292367, disc_loss = 0.04272912292592874
Trained batch 317 in epoch 5, gen_loss = 0.4377173921971951, disc_loss = 0.042654385863812115
Trained batch 318 in epoch 5, gen_loss = 0.4376020871546575, disc_loss = 0.04255622087614348
Trained batch 319 in epoch 5, gen_loss = 0.4377549711614847, disc_loss = 0.042435080166251284
Trained batch 320 in epoch 5, gen_loss = 0.4377878169961436, disc_loss = 0.042337440503717655
Trained batch 321 in epoch 5, gen_loss = 0.43772657011976895, disc_loss = 0.04223261153005839
Trained batch 322 in epoch 5, gen_loss = 0.4376919637708103, disc_loss = 0.04211075910930767
Trained batch 323 in epoch 5, gen_loss = 0.4376649735150514, disc_loss = 0.04199381848620423
Trained batch 324 in epoch 5, gen_loss = 0.4377545909698193, disc_loss = 0.04187456802572482
Trained batch 325 in epoch 5, gen_loss = 0.4379844066738351, disc_loss = 0.04178960058742426
Trained batch 326 in epoch 5, gen_loss = 0.43784569135499657, disc_loss = 0.04166928995635634
Trained batch 327 in epoch 5, gen_loss = 0.43779638018913386, disc_loss = 0.04158322307140646
Trained batch 328 in epoch 5, gen_loss = 0.4377292176329256, disc_loss = 0.04147657707912457
Trained batch 329 in epoch 5, gen_loss = 0.4377986610838861, disc_loss = 0.04136015616082163
Trained batch 330 in epoch 5, gen_loss = 0.43786689386987254, disc_loss = 0.04124786537822921
Trained batch 331 in epoch 5, gen_loss = 0.437941376074969, disc_loss = 0.04113486891995319
Trained batch 332 in epoch 5, gen_loss = 0.4381527357452267, disc_loss = 0.04102130513813056
Trained batch 333 in epoch 5, gen_loss = 0.43823017019354654, disc_loss = 0.04090819300415864
Trained batch 334 in epoch 5, gen_loss = 0.4383780287272895, disc_loss = 0.04080574475402541
Trained batch 335 in epoch 5, gen_loss = 0.43838245962702094, disc_loss = 0.040695832315014696
Trained batch 336 in epoch 5, gen_loss = 0.4382889505133077, disc_loss = 0.040582796014660215
Trained batch 337 in epoch 5, gen_loss = 0.43841504662699954, disc_loss = 0.040469678383687036
Trained batch 338 in epoch 5, gen_loss = 0.43841936507407897, disc_loss = 0.04035676725155188
Trained batch 339 in epoch 5, gen_loss = 0.438588043784394, disc_loss = 0.04024507180575336
Trained batch 340 in epoch 5, gen_loss = 0.4386152620714081, disc_loss = 0.04013914005357029
Trained batch 341 in epoch 5, gen_loss = 0.43863338415037123, disc_loss = 0.04003586473620132
Trained batch 342 in epoch 5, gen_loss = 0.4385345423534382, disc_loss = 0.03993344599138077
Trained batch 343 in epoch 5, gen_loss = 0.4387600021653397, disc_loss = 0.039825993837439455
Trained batch 344 in epoch 5, gen_loss = 0.43870191850524015, disc_loss = 0.03973632894179689
Trained batch 345 in epoch 5, gen_loss = 0.4387166484587454, disc_loss = 0.03963392447899607
Trained batch 346 in epoch 5, gen_loss = 0.4389231936732355, disc_loss = 0.039531029386094284
Trained batch 347 in epoch 5, gen_loss = 0.4389137389331028, disc_loss = 0.039424538280180624
Trained batch 348 in epoch 5, gen_loss = 0.4389841659021241, disc_loss = 0.0393187138328681
Trained batch 349 in epoch 5, gen_loss = 0.438965573821749, disc_loss = 0.039211698168156936
Trained batch 350 in epoch 5, gen_loss = 0.4388600821338827, disc_loss = 0.03910854019448851
Trained batch 351 in epoch 5, gen_loss = 0.43882702672007406, disc_loss = 0.03900438817436225
Trained batch 352 in epoch 5, gen_loss = 0.4388885639038032, disc_loss = 0.038902233284502354
Trained batch 353 in epoch 5, gen_loss = 0.43896373609701794, disc_loss = 0.03880092244572927
Trained batch 354 in epoch 5, gen_loss = 0.4388710963893944, disc_loss = 0.03869990471743939
Trained batch 355 in epoch 5, gen_loss = 0.43905044573076657, disc_loss = 0.0385999324600071
Trained batch 356 in epoch 5, gen_loss = 0.43912313456962754, disc_loss = 0.038500555626283656
Trained batch 357 in epoch 5, gen_loss = 0.4391368465217132, disc_loss = 0.03840307625792348
Trained batch 358 in epoch 5, gen_loss = 0.43923631094624405, disc_loss = 0.03832077932859249
Trained batch 359 in epoch 5, gen_loss = 0.43928444733222327, disc_loss = 0.038221174119260265
Trained batch 360 in epoch 5, gen_loss = 0.43905332321275303, disc_loss = 0.038126136050198406
Trained batch 361 in epoch 5, gen_loss = 0.439087002975506, disc_loss = 0.038026872860558475
Trained batch 362 in epoch 5, gen_loss = 0.43924602431042464, disc_loss = 0.03792912208060824
Trained batch 363 in epoch 5, gen_loss = 0.43913030542515136, disc_loss = 0.03783220027804958
Trained batch 364 in epoch 5, gen_loss = 0.4390863358157955, disc_loss = 0.03774189669670767
Trained batch 365 in epoch 5, gen_loss = 0.4389622252169854, disc_loss = 0.037646607942739246
Trained batch 366 in epoch 5, gen_loss = 0.43914813258017765, disc_loss = 0.03755830082825413
Trained batch 367 in epoch 5, gen_loss = 0.43920638055905054, disc_loss = 0.0374616873592933
Trained batch 368 in epoch 5, gen_loss = 0.4393645468443067, disc_loss = 0.037370040395983614
Trained batch 369 in epoch 5, gen_loss = 0.43934883346428744, disc_loss = 0.03727556798839941
Trained batch 370 in epoch 5, gen_loss = 0.4394351452026727, disc_loss = 0.03718038581875266
Trained batch 371 in epoch 5, gen_loss = 0.43945487460461996, disc_loss = 0.037088346780560694
Trained batch 372 in epoch 5, gen_loss = 0.43957122329412773, disc_loss = 0.03699430641087756
Trained batch 373 in epoch 5, gen_loss = 0.43964448021376196, disc_loss = 0.03690696125358273
Trained batch 374 in epoch 5, gen_loss = 0.43955214230219525, disc_loss = 0.03681739328894764
Trained batch 375 in epoch 5, gen_loss = 0.43956649937528247, disc_loss = 0.03673174816890907
Trained batch 376 in epoch 5, gen_loss = 0.43962304788179674, disc_loss = 0.03664146612592249
Trained batch 377 in epoch 5, gen_loss = 0.4396427877680965, disc_loss = 0.0365533988190465
Trained batch 378 in epoch 5, gen_loss = 0.4396494694624224, disc_loss = 0.03646485879740832
Trained batch 379 in epoch 5, gen_loss = 0.43958257570078496, disc_loss = 0.036379970739730386
Trained batch 380 in epoch 5, gen_loss = 0.43972378061825207, disc_loss = 0.03629791868448482
Trained batch 381 in epoch 5, gen_loss = 0.43962596068207505, disc_loss = 0.0362215277782144
Trained batch 382 in epoch 5, gen_loss = 0.43969003930104306, disc_loss = 0.03614209056254379
Trained batch 383 in epoch 5, gen_loss = 0.4395778530742973, disc_loss = 0.03607180117342068
Trained batch 384 in epoch 5, gen_loss = 0.43973701456924535, disc_loss = 0.035994956099017004
Trained batch 385 in epoch 5, gen_loss = 0.43974477647190885, disc_loss = 0.035920069722755486
Trained batch 386 in epoch 5, gen_loss = 0.43970636195606655, disc_loss = 0.035845580005125464
Trained batch 387 in epoch 5, gen_loss = 0.439678512820878, disc_loss = 0.03576132519735916
Trained batch 388 in epoch 5, gen_loss = 0.4398153529222336, disc_loss = 0.035682463644678135
Trained batch 389 in epoch 5, gen_loss = 0.4398626086803583, disc_loss = 0.035597692294798505
Trained batch 390 in epoch 5, gen_loss = 0.43986083235582124, disc_loss = 0.035518661342368314
Trained batch 391 in epoch 5, gen_loss = 0.4398680660037362, disc_loss = 0.03545042715238512
Trained batch 392 in epoch 5, gen_loss = 0.44001938527776996, disc_loss = 0.035374348497067984
Trained batch 393 in epoch 5, gen_loss = 0.4400882474359522, disc_loss = 0.035293044591840204
Trained batch 394 in epoch 5, gen_loss = 0.44004691914667055, disc_loss = 0.03521180963350012
Trained batch 395 in epoch 5, gen_loss = 0.44018417732282117, disc_loss = 0.03513602705671207
Trained batch 396 in epoch 5, gen_loss = 0.4401809155790872, disc_loss = 0.03505901098034347
Trained batch 397 in epoch 5, gen_loss = 0.4402409695350944, disc_loss = 0.034976986034167226
Trained batch 398 in epoch 5, gen_loss = 0.44016448701533456, disc_loss = 0.03489537109453978
Trained batch 399 in epoch 5, gen_loss = 0.44013556860387326, disc_loss = 0.034814802317123396
Trained batch 400 in epoch 5, gen_loss = 0.4398878304441076, disc_loss = 0.034737492759103546
Trained batch 401 in epoch 5, gen_loss = 0.4401029775391764, disc_loss = 0.03465806858918736
Trained batch 402 in epoch 5, gen_loss = 0.44016023087442363, disc_loss = 0.034581340772270805
Trained batch 403 in epoch 5, gen_loss = 0.44008107822720366, disc_loss = 0.03454195693887927
Trained batch 404 in epoch 5, gen_loss = 0.4401200007509302, disc_loss = 0.034533215163815995
Trained batch 405 in epoch 5, gen_loss = 0.44025092861922505, disc_loss = 0.034465023336227835
Trained batch 406 in epoch 5, gen_loss = 0.4403258439803299, disc_loss = 0.03439303684015175
Trained batch 407 in epoch 5, gen_loss = 0.44039062410593033, disc_loss = 0.0343196284857364
Trained batch 408 in epoch 5, gen_loss = 0.44033498147589073, disc_loss = 0.03424830389781775
Trained batch 409 in epoch 5, gen_loss = 0.4401512340074632, disc_loss = 0.03416932259782831
Trained batch 410 in epoch 5, gen_loss = 0.44016706537446254, disc_loss = 0.03413322561170108
Trained batch 411 in epoch 5, gen_loss = 0.44018023417702, disc_loss = 0.034088579779863806
Trained batch 412 in epoch 5, gen_loss = 0.4402681642525421, disc_loss = 0.03403374209992146
Trained batch 413 in epoch 5, gen_loss = 0.44021095047538406, disc_loss = 0.03398377310674736
Trained batch 414 in epoch 5, gen_loss = 0.4403402580554227, disc_loss = 0.03393331534111401
Trained batch 415 in epoch 5, gen_loss = 0.44051015914346164, disc_loss = 0.03386900329748572
Trained batch 416 in epoch 5, gen_loss = 0.44051094449681344, disc_loss = 0.03379771327158789
Trained batch 417 in epoch 5, gen_loss = 0.44065312577776933, disc_loss = 0.03385479580059549
Trained batch 418 in epoch 5, gen_loss = 0.4407304982012382, disc_loss = 0.033862675193681656
Trained batch 419 in epoch 5, gen_loss = 0.4407809833685557, disc_loss = 0.03384039311786182
Trained batch 420 in epoch 5, gen_loss = 0.440882593039379, disc_loss = 0.03388354301949268
Trained batch 421 in epoch 5, gen_loss = 0.44084168462109224, disc_loss = 0.03431814721199547
Trained batch 422 in epoch 5, gen_loss = 0.4410009921724351, disc_loss = 0.0348222810473958
Trained batch 423 in epoch 5, gen_loss = 0.44099477790998964, disc_loss = 0.03478300459227165
Trained batch 424 in epoch 5, gen_loss = 0.44078761549556955, disc_loss = 0.03494676300954512
Trained batch 425 in epoch 5, gen_loss = 0.44058190691918836, disc_loss = 0.03500016119594559
Trained batch 426 in epoch 5, gen_loss = 0.44071163973428606, disc_loss = 0.03498360488276964
Trained batch 427 in epoch 5, gen_loss = 0.44081576259058214, disc_loss = 0.03493287883917627
Trained batch 428 in epoch 5, gen_loss = 0.4408624929425878, disc_loss = 0.034963250077993877
Trained batch 429 in epoch 5, gen_loss = 0.4408649871515673, disc_loss = 0.03489867530595295
Trained batch 430 in epoch 5, gen_loss = 0.440938853954771, disc_loss = 0.03482919430447712
Trained batch 431 in epoch 5, gen_loss = 0.441058325615746, disc_loss = 0.03496383737985053
Trained batch 432 in epoch 5, gen_loss = 0.4408615022966548, disc_loss = 0.035357894512768794
Trained batch 433 in epoch 5, gen_loss = 0.4408566374932566, disc_loss = 0.03539228615643937
Trained batch 434 in epoch 5, gen_loss = 0.4409026801586151, disc_loss = 0.03541741857075015
Trained batch 435 in epoch 5, gen_loss = 0.440920121284253, disc_loss = 0.03538056195061013
Trained batch 436 in epoch 5, gen_loss = 0.44080621406470066, disc_loss = 0.03538581262128449
Trained batch 437 in epoch 5, gen_loss = 0.44084059144263943, disc_loss = 0.03533531173124918
Trained batch 438 in epoch 5, gen_loss = 0.44091503121858305, disc_loss = 0.03531299131060049
Trained batch 439 in epoch 5, gen_loss = 0.44087152345614, disc_loss = 0.035257942031867884
Trained batch 440 in epoch 5, gen_loss = 0.44085836545680385, disc_loss = 0.03525765348028375
Trained batch 441 in epoch 5, gen_loss = 0.44083973300133356, disc_loss = 0.03519567572411647
Trained batch 442 in epoch 5, gen_loss = 0.4409895701413768, disc_loss = 0.0355138018652145
Trained batch 443 in epoch 5, gen_loss = 0.4407480561786944, disc_loss = 0.03609124948569523
Trained batch 444 in epoch 5, gen_loss = 0.4409652096501897, disc_loss = 0.03610083305020555
Trained batch 445 in epoch 5, gen_loss = 0.44086783048550643, disc_loss = 0.03617414061920801
Trained batch 446 in epoch 5, gen_loss = 0.44089852296799353, disc_loss = 0.03622240062216526
Trained batch 447 in epoch 5, gen_loss = 0.44069288917151944, disc_loss = 0.03619726915167121
Trained batch 448 in epoch 5, gen_loss = 0.4405667781829834, disc_loss = 0.03621615316715705
Trained batch 449 in epoch 5, gen_loss = 0.44067035893599193, disc_loss = 0.036361699898261574
Trained batch 450 in epoch 5, gen_loss = 0.44058689745989715, disc_loss = 0.036397696135332294
Trained batch 451 in epoch 5, gen_loss = 0.44053421110178514, disc_loss = 0.036367292935492276
Trained batch 452 in epoch 5, gen_loss = 0.4404744277595158, disc_loss = 0.036450380355861886
Trained batch 453 in epoch 5, gen_loss = 0.4404382529762873, disc_loss = 0.03653329346531034
Trained batch 454 in epoch 5, gen_loss = 0.44015606910317806, disc_loss = 0.03683721372310154
Trained batch 455 in epoch 5, gen_loss = 0.44020985661630047, disc_loss = 0.03692431559938358
Trained batch 456 in epoch 5, gen_loss = 0.4401691164699112, disc_loss = 0.03690409723030407
Trained batch 457 in epoch 5, gen_loss = 0.4401307803574608, disc_loss = 0.036843141773969794
Trained batch 458 in epoch 5, gen_loss = 0.44004923325997813, disc_loss = 0.03681340435553294
Trained batch 459 in epoch 5, gen_loss = 0.4398959343848021, disc_loss = 0.0368314229126554
Trained batch 460 in epoch 5, gen_loss = 0.4400158823829411, disc_loss = 0.03677382412212022
Trained batch 461 in epoch 5, gen_loss = 0.4401464896413671, disc_loss = 0.036798416664350166
Trained batch 462 in epoch 5, gen_loss = 0.4400731847816616, disc_loss = 0.036792912505633456
Trained batch 463 in epoch 5, gen_loss = 0.43997992877045583, disc_loss = 0.036759861166125306
Trained batch 464 in epoch 5, gen_loss = 0.440090202003397, disc_loss = 0.036722194875330134
Trained batch 465 in epoch 5, gen_loss = 0.4402508391587008, disc_loss = 0.03677934000409476
Trained batch 466 in epoch 5, gen_loss = 0.4403196231838978, disc_loss = 0.03671255885853733
Trained batch 467 in epoch 5, gen_loss = 0.4402415186930925, disc_loss = 0.03668303826936266
Trained batch 468 in epoch 5, gen_loss = 0.44020489353869263, disc_loss = 0.03664816826853012
Trained batch 469 in epoch 5, gen_loss = 0.440185942358159, disc_loss = 0.036583397804234336
Trained batch 470 in epoch 5, gen_loss = 0.44011446934849846, disc_loss = 0.036578148608629825
Trained batch 471 in epoch 5, gen_loss = 0.44024537295355637, disc_loss = 0.03656556834274374
Trained batch 472 in epoch 5, gen_loss = 0.44018292578279844, disc_loss = 0.036686297905056425
Trained batch 473 in epoch 5, gen_loss = 0.4404027635538125, disc_loss = 0.036753750124500224
Trained batch 474 in epoch 5, gen_loss = 0.4404831787159568, disc_loss = 0.03678971959302496
Trained batch 475 in epoch 5, gen_loss = 0.440321829702173, disc_loss = 0.036965947305957765
Trained batch 476 in epoch 5, gen_loss = 0.44028489188578146, disc_loss = 0.03692177390758792
Trained batch 477 in epoch 5, gen_loss = 0.4401328710207879, disc_loss = 0.03700509481643478
Trained batch 478 in epoch 5, gen_loss = 0.4400003338407624, disc_loss = 0.0369878474572899
Trained batch 479 in epoch 5, gen_loss = 0.43997871577739717, disc_loss = 0.03692739603308534
Trained batch 480 in epoch 5, gen_loss = 0.4399082726971275, disc_loss = 0.03690532950143254
Trained batch 481 in epoch 5, gen_loss = 0.4400718842180933, disc_loss = 0.036924024647018674
Trained batch 482 in epoch 5, gen_loss = 0.44003062335847576, disc_loss = 0.03689760024207172
Trained batch 483 in epoch 5, gen_loss = 0.43994119566334183, disc_loss = 0.036848438254505594
Trained batch 484 in epoch 5, gen_loss = 0.439974544957741, disc_loss = 0.03684269837847882
Trained batch 485 in epoch 5, gen_loss = 0.4398454680364318, disc_loss = 0.036818155717275224
Trained batch 486 in epoch 5, gen_loss = 0.4397843663085413, disc_loss = 0.03678610618871654
Trained batch 487 in epoch 5, gen_loss = 0.44002059657798437, disc_loss = 0.03680015925712097
Trained batch 488 in epoch 5, gen_loss = 0.4402003255967957, disc_loss = 0.03674794139044363
Trained batch 489 in epoch 5, gen_loss = 0.44018844268759905, disc_loss = 0.036709399001758396
Trained batch 490 in epoch 5, gen_loss = 0.4402119485156842, disc_loss = 0.036665943177377085
Trained batch 491 in epoch 5, gen_loss = 0.440382406781844, disc_loss = 0.0366560027991872
Trained batch 492 in epoch 5, gen_loss = 0.4404038868496916, disc_loss = 0.03660436035544776
Trained batch 493 in epoch 5, gen_loss = 0.44035751357493613, disc_loss = 0.03654244843694129
Trained batch 494 in epoch 5, gen_loss = 0.44018906385007533, disc_loss = 0.03648222798241697
Trained batch 495 in epoch 5, gen_loss = 0.44023609185411083, disc_loss = 0.03645696974807276
Trained batch 496 in epoch 5, gen_loss = 0.4402688892794327, disc_loss = 0.03644272179218193
Trained batch 497 in epoch 5, gen_loss = 0.4401684898927987, disc_loss = 0.03664784427534931
Trained batch 498 in epoch 5, gen_loss = 0.4399033309462553, disc_loss = 0.0370781124321714
Trained batch 499 in epoch 5, gen_loss = 0.4398511246442795, disc_loss = 0.037050664623500776
Trained batch 500 in epoch 5, gen_loss = 0.43969539307548616, disc_loss = 0.03715315138936943
Trained batch 501 in epoch 5, gen_loss = 0.43962909880862294, disc_loss = 0.03716795238971421
Trained batch 502 in epoch 5, gen_loss = 0.4396578151117973, disc_loss = 0.0371930310643828
Trained batch 503 in epoch 5, gen_loss = 0.4397978971283587, disc_loss = 0.03715468642032994
Trained batch 504 in epoch 5, gen_loss = 0.43998310843316635, disc_loss = 0.03714577626220255
Trained batch 505 in epoch 5, gen_loss = 0.43995528141029266, disc_loss = 0.03711144291642104
Trained batch 506 in epoch 5, gen_loss = 0.4400088673042358, disc_loss = 0.03705363021084315
Trained batch 507 in epoch 5, gen_loss = 0.4400300049758333, disc_loss = 0.037000814646410966
Trained batch 508 in epoch 5, gen_loss = 0.43997561223146253, disc_loss = 0.03695115358051835
Trained batch 509 in epoch 5, gen_loss = 0.4400710511441324, disc_loss = 0.03697756453184411
Trained batch 510 in epoch 5, gen_loss = 0.4400553465356099, disc_loss = 0.03740496884183065
Trained batch 511 in epoch 5, gen_loss = 0.44002901623025537, disc_loss = 0.03774264146636597
Trained batch 512 in epoch 5, gen_loss = 0.4400308750293873, disc_loss = 0.03790855259869654
Trained batch 513 in epoch 5, gen_loss = 0.4400136456299385, disc_loss = 0.037895401888336726
Trained batch 514 in epoch 5, gen_loss = 0.44001844913056753, disc_loss = 0.037865726439309425
Trained batch 515 in epoch 5, gen_loss = 0.4400889012356137, disc_loss = 0.037809675746433104
Trained batch 516 in epoch 5, gen_loss = 0.4400062194991158, disc_loss = 0.03776936279452177
Trained batch 517 in epoch 5, gen_loss = 0.4399609569762204, disc_loss = 0.03771111324117573
Trained batch 518 in epoch 5, gen_loss = 0.439895705910317, disc_loss = 0.037703533245291854
Trained batch 519 in epoch 5, gen_loss = 0.4399106295636067, disc_loss = 0.03767731836571609
Trained batch 520 in epoch 5, gen_loss = 0.4397773211267768, disc_loss = 0.03768757406748195
Trained batch 521 in epoch 5, gen_loss = 0.43991282165507245, disc_loss = 0.03788336486956176
Trained batch 522 in epoch 5, gen_loss = 0.43992769929008774, disc_loss = 0.03810681047182473
Trained batch 523 in epoch 5, gen_loss = 0.4400527797468746, disc_loss = 0.03810565113840902
Trained batch 524 in epoch 5, gen_loss = 0.4401297757171449, disc_loss = 0.03805486904834175
Trained batch 525 in epoch 5, gen_loss = 0.44007530156877106, disc_loss = 0.03800441253644382
Trained batch 526 in epoch 5, gen_loss = 0.4401824766702851, disc_loss = 0.03794871412851164
Trained batch 527 in epoch 5, gen_loss = 0.4401477092143261, disc_loss = 0.038030062725628144
Trained batch 528 in epoch 5, gen_loss = 0.4401762096214835, disc_loss = 0.03808619220814155
Trained batch 529 in epoch 5, gen_loss = 0.44018022069391216, disc_loss = 0.03803110805994673
Trained batch 530 in epoch 5, gen_loss = 0.44026883611571316, disc_loss = 0.03797696639144383
Trained batch 531 in epoch 5, gen_loss = 0.4402886587650256, disc_loss = 0.03797112832732562
Trained batch 532 in epoch 5, gen_loss = 0.4402891543971665, disc_loss = 0.037973727502573565
Trained batch 533 in epoch 5, gen_loss = 0.44029248486297407, disc_loss = 0.03794430365043863
Trained batch 534 in epoch 5, gen_loss = 0.4404402456550955, disc_loss = 0.03788897063274146
Trained batch 535 in epoch 5, gen_loss = 0.44037944462094736, disc_loss = 0.037834436272370014
Trained batch 536 in epoch 5, gen_loss = 0.440310194949642, disc_loss = 0.03777707242159766
Trained batch 537 in epoch 5, gen_loss = 0.4404334236476501, disc_loss = 0.03771935713232485
Trained batch 538 in epoch 5, gen_loss = 0.44046707172119554, disc_loss = 0.03772238958890486
Trained batch 539 in epoch 5, gen_loss = 0.44062934711023616, disc_loss = 0.037819615465425026
Trained batch 540 in epoch 5, gen_loss = 0.4407425293089502, disc_loss = 0.03776937895501807
Trained batch 541 in epoch 5, gen_loss = 0.4407810004104987, disc_loss = 0.037724469742193005
Trained batch 542 in epoch 5, gen_loss = 0.4408768823792263, disc_loss = 0.03766717754658586
Trained batch 543 in epoch 5, gen_loss = 0.44096125717110496, disc_loss = 0.03760544956779032
Trained batch 544 in epoch 5, gen_loss = 0.44100284412366536, disc_loss = 0.03754338527700667
Trained batch 545 in epoch 5, gen_loss = 0.4408928427722428, disc_loss = 0.03748497144244918
Trained batch 546 in epoch 5, gen_loss = 0.44088584506097617, disc_loss = 0.03747587248285419
Trained batch 547 in epoch 5, gen_loss = 0.44097762408047697, disc_loss = 0.03755598487166763
Trained batch 548 in epoch 5, gen_loss = 0.4410784898125626, disc_loss = 0.03749793247325695
Trained batch 549 in epoch 5, gen_loss = 0.44107183196327904, disc_loss = 0.037482617346950894
Trained batch 550 in epoch 5, gen_loss = 0.44112490964022394, disc_loss = 0.03742546290890254
Trained batch 551 in epoch 5, gen_loss = 0.44116648437752237, disc_loss = 0.037371500292531404
Trained batch 552 in epoch 5, gen_loss = 0.44128300516342384, disc_loss = 0.03732741360908802
Trained batch 553 in epoch 5, gen_loss = 0.441226775519254, disc_loss = 0.037267344928344895
Trained batch 554 in epoch 5, gen_loss = 0.4412239016176344, disc_loss = 0.037214121715216014
Trained batch 555 in epoch 5, gen_loss = 0.44128060437363686, disc_loss = 0.03715426977426517
Trained batch 556 in epoch 5, gen_loss = 0.4412915388279372, disc_loss = 0.037093764076325406
Trained batch 557 in epoch 5, gen_loss = 0.4413522048769886, disc_loss = 0.03703932646277284
Trained batch 558 in epoch 5, gen_loss = 0.44139747718792266, disc_loss = 0.0369831563091432
Trained batch 559 in epoch 5, gen_loss = 0.4414686188633953, disc_loss = 0.03692185240569026
Trained batch 560 in epoch 5, gen_loss = 0.44134790390570533, disc_loss = 0.036883238235898584
Trained batch 561 in epoch 5, gen_loss = 0.44148624309229256, disc_loss = 0.03684750541790266
Trained batch 562 in epoch 5, gen_loss = 0.44145522273243215, disc_loss = 0.036787533249456245
Trained batch 563 in epoch 5, gen_loss = 0.4414530543887869, disc_loss = 0.036729798210720394
Trained batch 564 in epoch 5, gen_loss = 0.4413851312303965, disc_loss = 0.03668550861921095
Trained batch 565 in epoch 5, gen_loss = 0.4414094208933861, disc_loss = 0.03662502991595855
Trained batch 566 in epoch 5, gen_loss = 0.44141193793354, disc_loss = 0.03656721628386843
Trained batch 567 in epoch 5, gen_loss = 0.44134401650705807, disc_loss = 0.036514356419809726
Trained batch 568 in epoch 5, gen_loss = 0.4412367733061209, disc_loss = 0.03647833964595103
Trained batch 569 in epoch 5, gen_loss = 0.44116912745592884, disc_loss = 0.036419992104556674
Trained batch 570 in epoch 5, gen_loss = 0.44127134657782974, disc_loss = 0.03636947554889283
Trained batch 571 in epoch 5, gen_loss = 0.44115755738286705, disc_loss = 0.03631084157667657
Trained batch 572 in epoch 5, gen_loss = 0.44116746344283403, disc_loss = 0.03625513067412926
Trained batch 573 in epoch 5, gen_loss = 0.44111120384121605, disc_loss = 0.036203591362127016
Trained batch 574 in epoch 5, gen_loss = 0.4412509474028712, disc_loss = 0.03615314453334102
Trained batch 575 in epoch 5, gen_loss = 0.4411476226006117, disc_loss = 0.036096256260053555
Trained batch 576 in epoch 5, gen_loss = 0.4411468824026283, disc_loss = 0.03604288494187783
Trained batch 577 in epoch 5, gen_loss = 0.4411338617748043, disc_loss = 0.03598771636937439
Trained batch 578 in epoch 5, gen_loss = 0.4412042672049402, disc_loss = 0.03593811885206855
Trained batch 579 in epoch 5, gen_loss = 0.4411253450759526, disc_loss = 0.035881157269789674
Trained batch 580 in epoch 5, gen_loss = 0.44115225978439315, disc_loss = 0.03583148477271218
Trained batch 581 in epoch 5, gen_loss = 0.4410209829864633, disc_loss = 0.03577603176784225
Trained batch 582 in epoch 5, gen_loss = 0.44104641926431737, disc_loss = 0.03572457474253043
Trained batch 583 in epoch 5, gen_loss = 0.44100252620569647, disc_loss = 0.03566676303716408
Trained batch 584 in epoch 5, gen_loss = 0.4409847247294891, disc_loss = 0.03561601980696791
Trained batch 585 in epoch 5, gen_loss = 0.4410303819403307, disc_loss = 0.03555931319715455
Trained batch 586 in epoch 5, gen_loss = 0.4410410937194727, disc_loss = 0.03550277534397113
Trained batch 587 in epoch 5, gen_loss = 0.440941376294814, disc_loss = 0.03544630863063107
Trained batch 588 in epoch 5, gen_loss = 0.4408486294220178, disc_loss = 0.03539621356004258
Trained batch 589 in epoch 5, gen_loss = 0.4408315923254369, disc_loss = 0.035340135557363914
Trained batch 590 in epoch 5, gen_loss = 0.4408672605775133, disc_loss = 0.03530042020973549
Trained batch 591 in epoch 5, gen_loss = 0.44084574448297154, disc_loss = 0.0352461581825156
Trained batch 592 in epoch 5, gen_loss = 0.44084278070705535, disc_loss = 0.03519262318498601
Trained batch 593 in epoch 5, gen_loss = 0.44085659673719696, disc_loss = 0.03513858517532328
Trained batch 594 in epoch 5, gen_loss = 0.4409047806964201, disc_loss = 0.035084862160073796
Trained batch 595 in epoch 5, gen_loss = 0.44092759735032216, disc_loss = 0.03503097830267604
Trained batch 596 in epoch 5, gen_loss = 0.44098171047629225, disc_loss = 0.034996216497976816
Trained batch 597 in epoch 5, gen_loss = 0.4409877338935699, disc_loss = 0.03496458465416439
Trained batch 598 in epoch 5, gen_loss = 0.44099944635902305, disc_loss = 0.03492073951275842
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.40931975841522217, disc_loss = 0.005030691623687744
Trained batch 1 in epoch 6, gen_loss = 0.4065994918346405, disc_loss = 0.005544926505535841
Trained batch 2 in epoch 6, gen_loss = 0.4071412781874339, disc_loss = 0.008018914299706617
Trained batch 3 in epoch 6, gen_loss = 0.3891766518354416, disc_loss = 0.006697376549709588
Trained batch 4 in epoch 6, gen_loss = 0.3791136980056763, disc_loss = 0.007742011407390237
Trained batch 5 in epoch 6, gen_loss = 0.4035438299179077, disc_loss = 0.008052404853515327
Trained batch 6 in epoch 6, gen_loss = 0.41090467146464754, disc_loss = 0.008218577297936593
Trained batch 7 in epoch 6, gen_loss = 0.43023645132780075, disc_loss = 0.010390267620095983
Trained batch 8 in epoch 6, gen_loss = 0.42522809240553117, disc_loss = 0.011646809599672755
Trained batch 9 in epoch 6, gen_loss = 0.4261558145284653, disc_loss = 0.013272562739439308
Trained batch 10 in epoch 6, gen_loss = 0.4263245409185236, disc_loss = 0.01480146372606131
Trained batch 11 in epoch 6, gen_loss = 0.43070291727781296, disc_loss = 0.014326714852359146
Trained batch 12 in epoch 6, gen_loss = 0.4383089244365692, disc_loss = 0.013759802614983458
Trained batch 13 in epoch 6, gen_loss = 0.43150587379932404, disc_loss = 0.013297339152943875
Trained batch 14 in epoch 6, gen_loss = 0.43249973058700564, disc_loss = 0.01287669053611656
Trained batch 15 in epoch 6, gen_loss = 0.43480051308870316, disc_loss = 0.012929896111018024
Trained batch 16 in epoch 6, gen_loss = 0.43479233278947715, disc_loss = 0.012401747969253099
Trained batch 17 in epoch 6, gen_loss = 0.4390653901629978, disc_loss = 0.012008282317159077
Trained batch 18 in epoch 6, gen_loss = 0.4339759051799774, disc_loss = 0.011534220257185791
Trained batch 19 in epoch 6, gen_loss = 0.43022983968257905, disc_loss = 0.011154801084194333
Trained batch 20 in epoch 6, gen_loss = 0.42641528731300715, disc_loss = 0.010970179845268527
Trained batch 21 in epoch 6, gen_loss = 0.42818414487622003, disc_loss = 0.010650796254842797
Trained batch 22 in epoch 6, gen_loss = 0.4304980959581292, disc_loss = 0.011108603925727632
Trained batch 23 in epoch 6, gen_loss = 0.4291510892411073, disc_loss = 0.010867297426254178
Trained batch 24 in epoch 6, gen_loss = 0.42937971591949464, disc_loss = 0.01079248716123402
Trained batch 25 in epoch 6, gen_loss = 0.4290404480237227, disc_loss = 0.0105797294795943
Trained batch 26 in epoch 6, gen_loss = 0.42960643657931574, disc_loss = 0.010474786671154477
Trained batch 27 in epoch 6, gen_loss = 0.4288615509867668, disc_loss = 0.010613682372162916
Trained batch 28 in epoch 6, gen_loss = 0.4268624936712199, disc_loss = 0.010725766572908595
Trained batch 29 in epoch 6, gen_loss = 0.42921818296114606, disc_loss = 0.010662391991354525
Trained batch 30 in epoch 6, gen_loss = 0.4276708326032085, disc_loss = 0.010957502572226429
Trained batch 31 in epoch 6, gen_loss = 0.42701566871255636, disc_loss = 0.011000940830854233
Trained batch 32 in epoch 6, gen_loss = 0.42712050676345825, disc_loss = 0.011109462593484557
Trained batch 33 in epoch 6, gen_loss = 0.4293641728513381, disc_loss = 0.011151087983949658
Trained batch 34 in epoch 6, gen_loss = 0.4317792773246765, disc_loss = 0.010989173641428351
Trained batch 35 in epoch 6, gen_loss = 0.4316081388129128, disc_loss = 0.010846518064176457
Trained batch 36 in epoch 6, gen_loss = 0.4312728925331219, disc_loss = 0.010753527692695325
Trained batch 37 in epoch 6, gen_loss = 0.43160907061476456, disc_loss = 0.010669811487835097
Trained batch 38 in epoch 6, gen_loss = 0.43134618798891705, disc_loss = 0.010473184794999467
Trained batch 39 in epoch 6, gen_loss = 0.4319415926933289, disc_loss = 0.01204490804229863
Trained batch 40 in epoch 6, gen_loss = 0.4307645682881518, disc_loss = 0.019737199249836367
Trained batch 41 in epoch 6, gen_loss = 0.42916194668837954, disc_loss = 0.022445148239577457
Trained batch 42 in epoch 6, gen_loss = 0.429535121418709, disc_loss = 0.026607171334542854
Trained batch 43 in epoch 6, gen_loss = 0.4306797005913474, disc_loss = 0.02966915877980434
Trained batch 44 in epoch 6, gen_loss = 0.4302201959821913, disc_loss = 0.032540095457807186
Trained batch 45 in epoch 6, gen_loss = 0.42883903954340064, disc_loss = 0.033803761921539575
Trained batch 46 in epoch 6, gen_loss = 0.4300845221002051, disc_loss = 0.03481917109518768
Trained batch 47 in epoch 6, gen_loss = 0.4319473796834548, disc_loss = 0.03548618431765741
Trained batch 48 in epoch 6, gen_loss = 0.43126077858769163, disc_loss = 0.03689160192746441
Trained batch 49 in epoch 6, gen_loss = 0.4299334567785263, disc_loss = 0.03665130170527846
Trained batch 50 in epoch 6, gen_loss = 0.4300528197896247, disc_loss = 0.037052573111163924
Trained batch 51 in epoch 6, gen_loss = 0.42923731872668636, disc_loss = 0.03714103153638112
Trained batch 52 in epoch 6, gen_loss = 0.42940043053537047, disc_loss = 0.036874267452765466
Trained batch 53 in epoch 6, gen_loss = 0.4284507190739667, disc_loss = 0.038170356462985555
Trained batch 54 in epoch 6, gen_loss = 0.4298540928147056, disc_loss = 0.03788663452406499
Trained batch 55 in epoch 6, gen_loss = 0.42976064926811625, disc_loss = 0.03735608415029544
Trained batch 56 in epoch 6, gen_loss = 0.42936260292404577, disc_loss = 0.03717765081755556
Trained batch 57 in epoch 6, gen_loss = 0.4301087172894642, disc_loss = 0.03706855908566122
Trained batch 58 in epoch 6, gen_loss = 0.43077987735554324, disc_loss = 0.0367495553070774
Trained batch 59 in epoch 6, gen_loss = 0.43107533901929856, disc_loss = 0.03626199733698741
Trained batch 60 in epoch 6, gen_loss = 0.4325567156564994, disc_loss = 0.03594133034577501
Trained batch 61 in epoch 6, gen_loss = 0.43296071983152823, disc_loss = 0.03572563168727943
Trained batch 62 in epoch 6, gen_loss = 0.43436966623578754, disc_loss = 0.035728248542115565
Trained batch 63 in epoch 6, gen_loss = 0.4345046216621995, disc_loss = 0.03546688964343048
Trained batch 64 in epoch 6, gen_loss = 0.4340823077238523, disc_loss = 0.036003346307776296
Trained batch 65 in epoch 6, gen_loss = 0.43553421849554236, disc_loss = 0.03751169068555376
Trained batch 66 in epoch 6, gen_loss = 0.4355335756024318, disc_loss = 0.037394606240733125
Trained batch 67 in epoch 6, gen_loss = 0.4346599412315032, disc_loss = 0.03693499777342796
Trained batch 68 in epoch 6, gen_loss = 0.4352089775645215, disc_loss = 0.036945988515229976
Trained batch 69 in epoch 6, gen_loss = 0.43664669096469877, disc_loss = 0.0376210959861055
Trained batch 70 in epoch 6, gen_loss = 0.4351328972359778, disc_loss = 0.037216756515808296
Trained batch 71 in epoch 6, gen_loss = 0.4350282723704974, disc_loss = 0.03707568494590103
Trained batch 72 in epoch 6, gen_loss = 0.4353480273730134, disc_loss = 0.03663547921045492
Trained batch 73 in epoch 6, gen_loss = 0.43538367426073227, disc_loss = 0.036305360404799716
Trained batch 74 in epoch 6, gen_loss = 0.43612228830655414, disc_loss = 0.03588087505660951
Trained batch 75 in epoch 6, gen_loss = 0.4364637234493306, disc_loss = 0.035502004023567825
Trained batch 76 in epoch 6, gen_loss = 0.4366150912526366, disc_loss = 0.035165107267751516
Trained batch 77 in epoch 6, gen_loss = 0.4369724110150949, disc_loss = 0.03545671307708686
Trained batch 78 in epoch 6, gen_loss = 0.4378761143624028, disc_loss = 0.03530891400266769
Trained batch 79 in epoch 6, gen_loss = 0.43825213722884654, disc_loss = 0.035411169988219623
Trained batch 80 in epoch 6, gen_loss = 0.43879476263199324, disc_loss = 0.0359070388008093
Trained batch 81 in epoch 6, gen_loss = 0.4392858645538004, disc_loss = 0.03563417733090407
Trained batch 82 in epoch 6, gen_loss = 0.4388503895466586, disc_loss = 0.03526675523011889
Trained batch 83 in epoch 6, gen_loss = 0.43828463306029636, disc_loss = 0.036691930336278995
Trained batch 84 in epoch 6, gen_loss = 0.4397792174535639, disc_loss = 0.03704739161767066
Trained batch 85 in epoch 6, gen_loss = 0.4400327888339065, disc_loss = 0.03691745004995704
Trained batch 86 in epoch 6, gen_loss = 0.4403433854552521, disc_loss = 0.03669255116858102
Trained batch 87 in epoch 6, gen_loss = 0.44046612828969955, disc_loss = 0.03637450587649999
Trained batch 88 in epoch 6, gen_loss = 0.4390237301253201, disc_loss = 0.03616075708761058
Trained batch 89 in epoch 6, gen_loss = 0.4388959907823139, disc_loss = 0.03592386958965411
Trained batch 90 in epoch 6, gen_loss = 0.4375683747150086, disc_loss = 0.03590224459409141
Trained batch 91 in epoch 6, gen_loss = 0.43792591114407, disc_loss = 0.03586667036364341
Trained batch 92 in epoch 6, gen_loss = 0.43866679521017177, disc_loss = 0.03555075559134205
Trained batch 93 in epoch 6, gen_loss = 0.43831270742923656, disc_loss = 0.0354288755346367
Trained batch 94 in epoch 6, gen_loss = 0.43813024727921734, disc_loss = 0.03510642423980722
Trained batch 95 in epoch 6, gen_loss = 0.43845235866804916, disc_loss = 0.03483095352567034
Trained batch 96 in epoch 6, gen_loss = 0.43849743795149104, disc_loss = 0.03528786242037013
Trained batch 97 in epoch 6, gen_loss = 0.4399628922039149, disc_loss = 0.03940963576671344
Trained batch 98 in epoch 6, gen_loss = 0.4396717409894924, disc_loss = 0.03956579073388694
Trained batch 99 in epoch 6, gen_loss = 0.439253888130188, disc_loss = 0.041075792859774085
Trained batch 100 in epoch 6, gen_loss = 0.4395286803788478, disc_loss = 0.04101528285191127
Trained batch 101 in epoch 6, gen_loss = 0.4400431487490149, disc_loss = 0.04092373493282745
Trained batch 102 in epoch 6, gen_loss = 0.4400791893306288, disc_loss = 0.04075456206976138
Trained batch 103 in epoch 6, gen_loss = 0.44017146785671896, disc_loss = 0.040457683675832905
Trained batch 104 in epoch 6, gen_loss = 0.440612499770664, disc_loss = 0.040396098852423686
Trained batch 105 in epoch 6, gen_loss = 0.44048548475751337, disc_loss = 0.04006041605508763
Trained batch 106 in epoch 6, gen_loss = 0.43969353894206964, disc_loss = 0.040011396142001325
Trained batch 107 in epoch 6, gen_loss = 0.4392974553284822, disc_loss = 0.039734105586022556
Trained batch 108 in epoch 6, gen_loss = 0.43894700336893766, disc_loss = 0.03960338700349109
Trained batch 109 in epoch 6, gen_loss = 0.43913064111362804, disc_loss = 0.039328551993028
Trained batch 110 in epoch 6, gen_loss = 0.43888338460578574, disc_loss = 0.03900897965414097
Trained batch 111 in epoch 6, gen_loss = 0.43921551161578726, disc_loss = 0.03922215595749939
Trained batch 112 in epoch 6, gen_loss = 0.43784937104292676, disc_loss = 0.039786542273349074
Trained batch 113 in epoch 6, gen_loss = 0.4377301779755375, disc_loss = 0.03988394660164455
Trained batch 114 in epoch 6, gen_loss = 0.43752368766328564, disc_loss = 0.03958179320856605
Trained batch 115 in epoch 6, gen_loss = 0.4368915018336526, disc_loss = 0.03929919721598833
Trained batch 116 in epoch 6, gen_loss = 0.4361652008488647, disc_loss = 0.03902714794430022
Trained batch 117 in epoch 6, gen_loss = 0.4358351498337115, disc_loss = 0.03878853465548827
Trained batch 118 in epoch 6, gen_loss = 0.4363277865057232, disc_loss = 0.0385686072595261
Trained batch 119 in epoch 6, gen_loss = 0.4362024962902069, disc_loss = 0.03870668055994126
Trained batch 120 in epoch 6, gen_loss = 0.4364345492410266, disc_loss = 0.040980230356866786
Trained batch 121 in epoch 6, gen_loss = 0.4362769165977103, disc_loss = 0.04345050055846633
Trained batch 122 in epoch 6, gen_loss = 0.43614007132809335, disc_loss = 0.045265586564044766
Trained batch 123 in epoch 6, gen_loss = 0.43527013231669703, disc_loss = 0.04558714634115477
Trained batch 124 in epoch 6, gen_loss = 0.43512174892425537, disc_loss = 0.04638560925610363
Trained batch 125 in epoch 6, gen_loss = 0.4348332687975868, disc_loss = 0.04671106095950577
Trained batch 126 in epoch 6, gen_loss = 0.4348464504940303, disc_loss = 0.04782128473560465
Trained batch 127 in epoch 6, gen_loss = 0.43471477506682277, disc_loss = 0.04803800145054993
Trained batch 128 in epoch 6, gen_loss = 0.43443820758383406, disc_loss = 0.04824931207907119
Trained batch 129 in epoch 6, gen_loss = 0.43469507969342747, disc_loss = 0.04827991057939541
Trained batch 130 in epoch 6, gen_loss = 0.4345176879686254, disc_loss = 0.04800428217810131
Trained batch 131 in epoch 6, gen_loss = 0.4341611516746608, disc_loss = 0.04816497688245198
Trained batch 132 in epoch 6, gen_loss = 0.4344600826725924, disc_loss = 0.04912746653724041
Trained batch 133 in epoch 6, gen_loss = 0.43405733580019934, disc_loss = 0.04955856130395863
Trained batch 134 in epoch 6, gen_loss = 0.43376179933547976, disc_loss = 0.04958556590567308
Trained batch 135 in epoch 6, gen_loss = 0.43360311275019364, disc_loss = 0.04940328990307856
Trained batch 136 in epoch 6, gen_loss = 0.43310364493488396, disc_loss = 0.04921208952390419
Trained batch 137 in epoch 6, gen_loss = 0.43272752131240955, disc_loss = 0.04903389784284746
Trained batch 138 in epoch 6, gen_loss = 0.43281822238894674, disc_loss = 0.049284643522068426
Trained batch 139 in epoch 6, gen_loss = 0.43214756420680456, disc_loss = 0.04968552042098184
Trained batch 140 in epoch 6, gen_loss = 0.4325270781703029, disc_loss = 0.04956526146270335
Trained batch 141 in epoch 6, gen_loss = 0.4329711305843273, disc_loss = 0.0493116105634483
Trained batch 142 in epoch 6, gen_loss = 0.4329937481796825, disc_loss = 0.049191360259298364
Trained batch 143 in epoch 6, gen_loss = 0.4331937421941095, disc_loss = 0.04900628436492601
Trained batch 144 in epoch 6, gen_loss = 0.43298151431412535, disc_loss = 0.048731415598364226
Trained batch 145 in epoch 6, gen_loss = 0.4330652474540554, disc_loss = 0.04848006008071697
Trained batch 146 in epoch 6, gen_loss = 0.43342913494629115, disc_loss = 0.048174486750559437
Trained batch 147 in epoch 6, gen_loss = 0.4334277162278021, disc_loss = 0.04787787919190738
Trained batch 148 in epoch 6, gen_loss = 0.433550643440861, disc_loss = 0.04759164696603063
Trained batch 149 in epoch 6, gen_loss = 0.4336479024092356, disc_loss = 0.04729150111010919
Trained batch 150 in epoch 6, gen_loss = 0.4341793885294175, disc_loss = 0.047021352607349784
Trained batch 151 in epoch 6, gen_loss = 0.43437674347507327, disc_loss = 0.04673471446547314
Trained batch 152 in epoch 6, gen_loss = 0.4342286354965634, disc_loss = 0.046451513116777525
Trained batch 153 in epoch 6, gen_loss = 0.4343111516980382, disc_loss = 0.04618496182918936
Trained batch 154 in epoch 6, gen_loss = 0.4345599684023088, disc_loss = 0.045942173351443585
Trained batch 155 in epoch 6, gen_loss = 0.4348500464589168, disc_loss = 0.04567921356871151
Trained batch 156 in epoch 6, gen_loss = 0.43508006072348093, disc_loss = 0.04540831280818838
Trained batch 157 in epoch 6, gen_loss = 0.43541232977486866, disc_loss = 0.0451655301126899
Trained batch 158 in epoch 6, gen_loss = 0.43504847051962364, disc_loss = 0.044916893321868476
Trained batch 159 in epoch 6, gen_loss = 0.43507750760763886, disc_loss = 0.044676929859269875
Trained batch 160 in epoch 6, gen_loss = 0.435010361190168, disc_loss = 0.04441738158597478
Trained batch 161 in epoch 6, gen_loss = 0.4348175005044466, disc_loss = 0.044161962349554176
Trained batch 162 in epoch 6, gen_loss = 0.4352123890917725, disc_loss = 0.04397627097508796
Trained batch 163 in epoch 6, gen_loss = 0.4355048929772726, disc_loss = 0.043749844673850645
Trained batch 164 in epoch 6, gen_loss = 0.4359903769059615, disc_loss = 0.04362387514503842
Trained batch 165 in epoch 6, gen_loss = 0.43608896739511605, disc_loss = 0.0433910483093259
Trained batch 166 in epoch 6, gen_loss = 0.43616544557902626, disc_loss = 0.04316771877399774
Trained batch 167 in epoch 6, gen_loss = 0.4362074330094315, disc_loss = 0.04292509897606492
Trained batch 168 in epoch 6, gen_loss = 0.4364263235464604, disc_loss = 0.04268657486505542
Trained batch 169 in epoch 6, gen_loss = 0.43628424230743856, disc_loss = 0.04245870207463775
Trained batch 170 in epoch 6, gen_loss = 0.4366938370710228, disc_loss = 0.04225916387540512
Trained batch 171 in epoch 6, gen_loss = 0.4370074765973313, disc_loss = 0.04203819990466717
Trained batch 172 in epoch 6, gen_loss = 0.4364918454878592, disc_loss = 0.0418726082344814
Trained batch 173 in epoch 6, gen_loss = 0.43643494858138865, disc_loss = 0.04167976541492831
Trained batch 174 in epoch 6, gen_loss = 0.4363854966844831, disc_loss = 0.041470707217231395
Trained batch 175 in epoch 6, gen_loss = 0.43658791516314854, disc_loss = 0.041264516204881314
Trained batch 176 in epoch 6, gen_loss = 0.4365522762139638, disc_loss = 0.04105383252046245
Trained batch 177 in epoch 6, gen_loss = 0.436422561661581, disc_loss = 0.04083545439029008
Trained batch 178 in epoch 6, gen_loss = 0.4365822359836301, disc_loss = 0.04062487371005742
Trained batch 179 in epoch 6, gen_loss = 0.4362955030467775, disc_loss = 0.04042975560296327
Trained batch 180 in epoch 6, gen_loss = 0.4363645805838358, disc_loss = 0.04027201242240671
Trained batch 181 in epoch 6, gen_loss = 0.4366932655428792, disc_loss = 0.0400957844225219
Trained batch 182 in epoch 6, gen_loss = 0.43662575489836314, disc_loss = 0.039892534135021473
Trained batch 183 in epoch 6, gen_loss = 0.4369848710687264, disc_loss = 0.0396978296567281
Trained batch 184 in epoch 6, gen_loss = 0.4369022264673903, disc_loss = 0.039508167883330905
Trained batch 185 in epoch 6, gen_loss = 0.4367864146347969, disc_loss = 0.03933336073282345
Trained batch 186 in epoch 6, gen_loss = 0.436933908551772, disc_loss = 0.039149915829380565
Trained batch 187 in epoch 6, gen_loss = 0.43710069596133333, disc_loss = 0.039021383797591354
Trained batch 188 in epoch 6, gen_loss = 0.4371213707974348, disc_loss = 0.03886739017747382
Trained batch 189 in epoch 6, gen_loss = 0.43703620998482956, disc_loss = 0.038682341765563344
Trained batch 190 in epoch 6, gen_loss = 0.43708931619584246, disc_loss = 0.038559027668332475
Trained batch 191 in epoch 6, gen_loss = 0.43703733043124277, disc_loss = 0.03841399560405989
Trained batch 192 in epoch 6, gen_loss = 0.4372238916745458, disc_loss = 0.03823871805255393
Trained batch 193 in epoch 6, gen_loss = 0.43711038148894754, disc_loss = 0.03806230011900177
Trained batch 194 in epoch 6, gen_loss = 0.43710235464267244, disc_loss = 0.03826613102275401
Trained batch 195 in epoch 6, gen_loss = 0.43682938570878943, disc_loss = 0.03936082030508705
Trained batch 196 in epoch 6, gen_loss = 0.4371228313385533, disc_loss = 0.039722392788194685
Trained batch 197 in epoch 6, gen_loss = 0.4371284359332287, disc_loss = 0.03976657061785874
Trained batch 198 in epoch 6, gen_loss = 0.43734269585441704, disc_loss = 0.03966751934178922
Trained batch 199 in epoch 6, gen_loss = 0.4374153690040112, disc_loss = 0.039662935360101986
Trained batch 200 in epoch 6, gen_loss = 0.4373810519626485, disc_loss = 0.03955413788367081
Trained batch 201 in epoch 6, gen_loss = 0.4377646773758501, disc_loss = 0.03948521248807227
Trained batch 202 in epoch 6, gen_loss = 0.43753360865151353, disc_loss = 0.03932841690693032
Trained batch 203 in epoch 6, gen_loss = 0.43755339626588075, disc_loss = 0.03940312392375085
Trained batch 204 in epoch 6, gen_loss = 0.43808259978526976, disc_loss = 0.03946300295817597
Trained batch 205 in epoch 6, gen_loss = 0.43829503206952103, disc_loss = 0.03936453889354666
Trained batch 206 in epoch 6, gen_loss = 0.43767325544126945, disc_loss = 0.03928882105541438
Trained batch 207 in epoch 6, gen_loss = 0.4380280361152612, disc_loss = 0.03919039112896336
Trained batch 208 in epoch 6, gen_loss = 0.43780063983926365, disc_loss = 0.03913114213331215
Trained batch 209 in epoch 6, gen_loss = 0.4376365166334879, disc_loss = 0.03965716820232393
Trained batch 210 in epoch 6, gen_loss = 0.43788233371142526, disc_loss = 0.04050014585243335
Trained batch 211 in epoch 6, gen_loss = 0.4376668192024501, disc_loss = 0.040452079624508704
Trained batch 212 in epoch 6, gen_loss = 0.4377153934167584, disc_loss = 0.04040531021490378
Trained batch 213 in epoch 6, gen_loss = 0.43766342479491904, disc_loss = 0.0402598793968715
Trained batch 214 in epoch 6, gen_loss = 0.4375959601513175, disc_loss = 0.04011097683917818
Trained batch 215 in epoch 6, gen_loss = 0.4376759496000078, disc_loss = 0.03995725469064416
Trained batch 216 in epoch 6, gen_loss = 0.4379540437377543, disc_loss = 0.03981059618950886
Trained batch 217 in epoch 6, gen_loss = 0.43810336032044994, disc_loss = 0.039660966439266615
Trained batch 218 in epoch 6, gen_loss = 0.43802394265453565, disc_loss = 0.039562791650774615
Trained batch 219 in epoch 6, gen_loss = 0.43831194110892036, disc_loss = 0.03941052402687174
Trained batch 220 in epoch 6, gen_loss = 0.43831331630098336, disc_loss = 0.03931983284614306
Trained batch 221 in epoch 6, gen_loss = 0.43843925536215844, disc_loss = 0.039368763472675136
Trained batch 222 in epoch 6, gen_loss = 0.43815103801376615, disc_loss = 0.0392630310142371
Trained batch 223 in epoch 6, gen_loss = 0.43793280821825775, disc_loss = 0.039897783201013226
Trained batch 224 in epoch 6, gen_loss = 0.43739643785688614, disc_loss = 0.041309273316421445
Trained batch 225 in epoch 6, gen_loss = 0.4372127228869801, disc_loss = 0.04135025540609902
Trained batch 226 in epoch 6, gen_loss = 0.43695188527065226, disc_loss = 0.041427398329223236
Trained batch 227 in epoch 6, gen_loss = 0.43670873134805444, disc_loss = 0.04154684233556812
Trained batch 228 in epoch 6, gen_loss = 0.4367377266092592, disc_loss = 0.04185334100859752
Trained batch 229 in epoch 6, gen_loss = 0.43640761686408003, disc_loss = 0.04222339967407448
Trained batch 230 in epoch 6, gen_loss = 0.43638369853878434, disc_loss = 0.04233619982671009
Trained batch 231 in epoch 6, gen_loss = 0.4365762872942563, disc_loss = 0.04227028765358384
Trained batch 232 in epoch 6, gen_loss = 0.43658138997053386, disc_loss = 0.042512505901817536
Trained batch 233 in epoch 6, gen_loss = 0.43655889003704756, disc_loss = 0.04287551372793591
Trained batch 234 in epoch 6, gen_loss = 0.4363929328766275, disc_loss = 0.04277175993737864
Trained batch 235 in epoch 6, gen_loss = 0.43614024820469194, disc_loss = 0.04333212383592627
Trained batch 236 in epoch 6, gen_loss = 0.4362388792671735, disc_loss = 0.04344212608745927
Trained batch 237 in epoch 6, gen_loss = 0.4365458174162552, disc_loss = 0.043472703036601744
Trained batch 238 in epoch 6, gen_loss = 0.43637575788976757, disc_loss = 0.043714862541883996
Trained batch 239 in epoch 6, gen_loss = 0.4361689341564973, disc_loss = 0.04370918164398366
Trained batch 240 in epoch 6, gen_loss = 0.43639650001070807, disc_loss = 0.04367049861432699
Trained batch 241 in epoch 6, gen_loss = 0.43625762184296757, disc_loss = 0.04361797466562399
Trained batch 242 in epoch 6, gen_loss = 0.4361963529645661, disc_loss = 0.04377685319306521
Trained batch 243 in epoch 6, gen_loss = 0.43631827635843246, disc_loss = 0.04369997491842502
Trained batch 244 in epoch 6, gen_loss = 0.43643393930123775, disc_loss = 0.04379183354179318
Trained batch 245 in epoch 6, gen_loss = 0.43637185489259117, disc_loss = 0.04435033783433974
Trained batch 246 in epoch 6, gen_loss = 0.4364364866303046, disc_loss = 0.04447945658973444
Trained batch 247 in epoch 6, gen_loss = 0.43658557317910657, disc_loss = 0.04436645878294873
Trained batch 248 in epoch 6, gen_loss = 0.4366341239237881, disc_loss = 0.04436722736577522
Trained batch 249 in epoch 6, gen_loss = 0.4365805352926254, disc_loss = 0.04427114004548639
Trained batch 250 in epoch 6, gen_loss = 0.4369346569496322, disc_loss = 0.04467700066256422
Trained batch 251 in epoch 6, gen_loss = 0.43675734303773395, disc_loss = 0.044754534729734244
Trained batch 252 in epoch 6, gen_loss = 0.4368785731641671, disc_loss = 0.04465051552578954
Trained batch 253 in epoch 6, gen_loss = 0.43683035941574516, disc_loss = 0.044538881797453495
Trained batch 254 in epoch 6, gen_loss = 0.43685877299776266, disc_loss = 0.044456547753447116
Trained batch 255 in epoch 6, gen_loss = 0.4369638360803947, disc_loss = 0.04432408244883845
Trained batch 256 in epoch 6, gen_loss = 0.43694005970361166, disc_loss = 0.044256393586607934
Trained batch 257 in epoch 6, gen_loss = 0.437295695030412, disc_loss = 0.04431240639898406
Trained batch 258 in epoch 6, gen_loss = 0.4373022518102727, disc_loss = 0.044189728072819276
Trained batch 259 in epoch 6, gen_loss = 0.4374445113998193, disc_loss = 0.04410823916998477
Trained batch 260 in epoch 6, gen_loss = 0.43749204951684595, disc_loss = 0.043973355667337316
Trained batch 262 in epoch 6, gen_loss = 0.4371414415736615, disc_loss = 0.044312908207048654
Trained batch 263 in epoch 6, gen_loss = 0.4369378490655711, disc_loss = 0.04446032889818801
Trained batch 264 in epoch 6, gen_loss = 0.43690887914513643, disc_loss = 0.044386909166702404
Trained batch 265 in epoch 6, gen_loss = 0.43696999437826917, disc_loss = 0.04440290585450856
Trained batch 266 in epoch 6, gen_loss = 0.43683500214015947, disc_loss = 0.04440978262486278
Trained batch 267 in epoch 6, gen_loss = 0.43700934301561384, disc_loss = 0.04435060844919992
Trained batch 268 in epoch 6, gen_loss = 0.43710248155664777, disc_loss = 0.04424985634166484
Trained batch 269 in epoch 6, gen_loss = 0.43704548820301337, disc_loss = 0.04425998102718343
Trained batch 270 in epoch 6, gen_loss = 0.4369513093325485, disc_loss = 0.04414820560336635
Trained batch 271 in epoch 6, gen_loss = 0.43688339115503955, disc_loss = 0.04402778355784796
Trained batch 272 in epoch 6, gen_loss = 0.43688578057638455, disc_loss = 0.043888860210714926
Trained batch 273 in epoch 6, gen_loss = 0.4370211003905665, disc_loss = 0.04376596299656089
Trained batch 274 in epoch 6, gen_loss = 0.4370252013206482, disc_loss = 0.0436326144288548
Trained batch 275 in epoch 6, gen_loss = 0.4371125121479449, disc_loss = 0.04355717414527781
Trained batch 276 in epoch 6, gen_loss = 0.43735097848981724, disc_loss = 0.043432401374675036
Trained batch 277 in epoch 6, gen_loss = 0.43755087599479897, disc_loss = 0.04330590768238168
Trained batch 278 in epoch 6, gen_loss = 0.4376912912801175, disc_loss = 0.04318940142373217
Trained batch 279 in epoch 6, gen_loss = 0.4377959358905043, disc_loss = 0.043070639881937364
Trained batch 280 in epoch 6, gen_loss = 0.43782338446993846, disc_loss = 0.04293421264389841
Trained batch 281 in epoch 6, gen_loss = 0.4378774049856984, disc_loss = 0.04280314045869052
Trained batch 282 in epoch 6, gen_loss = 0.43774114206907183, disc_loss = 0.04269566867984305
Trained batch 283 in epoch 6, gen_loss = 0.4379235787290922, disc_loss = 0.042563076349939416
Trained batch 284 in epoch 6, gen_loss = 0.4380815123256884, disc_loss = 0.042434459711474026
Trained batch 285 in epoch 6, gen_loss = 0.43812144063152636, disc_loss = 0.04230435799491442
Trained batch 286 in epoch 6, gen_loss = 0.43796953818523926, disc_loss = 0.04216671156297837
Trained batch 287 in epoch 6, gen_loss = 0.4377504676166508, disc_loss = 0.042044750202977516
Trained batch 288 in epoch 6, gen_loss = 0.4379316383785855, disc_loss = 0.041919117198876754
Trained batch 289 in epoch 6, gen_loss = 0.4379190611428228, disc_loss = 0.04179260756435065
Trained batch 290 in epoch 6, gen_loss = 0.4380336441739728, disc_loss = 0.04166535280894527
Trained batch 291 in epoch 6, gen_loss = 0.43823090369162493, disc_loss = 0.041549057863997166
Trained batch 292 in epoch 6, gen_loss = 0.438096989645486, disc_loss = 0.041419934513168125
Trained batch 293 in epoch 6, gen_loss = 0.43820183425128056, disc_loss = 0.041288028091040194
Trained batch 294 in epoch 6, gen_loss = 0.4383302774469731, disc_loss = 0.04115602280392106
Trained batch 295 in epoch 6, gen_loss = 0.4384299449219897, disc_loss = 0.041028522745536235
Trained batch 296 in epoch 6, gen_loss = 0.4384850430167484, disc_loss = 0.040899633621226256
Trained batch 297 in epoch 6, gen_loss = 0.43847916110249974, disc_loss = 0.04077999566012881
Trained batch 298 in epoch 6, gen_loss = 0.43852553259967564, disc_loss = 0.040670844850856126
Trained batch 299 in epoch 6, gen_loss = 0.43841565122207005, disc_loss = 0.04054972648775826
Trained batch 300 in epoch 6, gen_loss = 0.4382472511541804, disc_loss = 0.040436774871290423
Trained batch 301 in epoch 6, gen_loss = 0.43846488275275325, disc_loss = 0.04032416471021114
Trained batch 302 in epoch 6, gen_loss = 0.4386728880035602, disc_loss = 0.040205360865128215
Trained batch 303 in epoch 6, gen_loss = 0.438851200240223, disc_loss = 0.0400931820178429
Trained batch 304 in epoch 6, gen_loss = 0.4387122672112262, disc_loss = 0.039975395824638056
Trained batch 305 in epoch 6, gen_loss = 0.4388221857789295, disc_loss = 0.039853777425223655
Trained batch 306 in epoch 6, gen_loss = 0.43887243393189745, disc_loss = 0.039731219128010864
Trained batch 307 in epoch 6, gen_loss = 0.4389691546365812, disc_loss = 0.03960954680866501
Trained batch 308 in epoch 6, gen_loss = 0.4391091621230721, disc_loss = 0.03949479832808249
Trained batch 309 in epoch 6, gen_loss = 0.4392235181985363, disc_loss = 0.03937322098551498
Trained batch 310 in epoch 6, gen_loss = 0.4391628607293034, disc_loss = 0.03925262699525061
Trained batch 311 in epoch 6, gen_loss = 0.439155251169816, disc_loss = 0.03913330953704038
Trained batch 312 in epoch 6, gen_loss = 0.4391157626153562, disc_loss = 0.03902024995147313
Trained batch 313 in epoch 6, gen_loss = 0.43912542122564496, disc_loss = 0.038903119088117936
Trained batch 314 in epoch 6, gen_loss = 0.43900557832112386, disc_loss = 0.03878803224605878
Trained batch 315 in epoch 6, gen_loss = 0.43894003991839253, disc_loss = 0.03869060950782563
Trained batch 316 in epoch 6, gen_loss = 0.4386508359517961, disc_loss = 0.03857718438698913
Trained batch 317 in epoch 6, gen_loss = 0.43866542862646235, disc_loss = 0.03846290444189378
Trained batch 318 in epoch 6, gen_loss = 0.4385826082252036, disc_loss = 0.03834723503158069
Trained batch 319 in epoch 6, gen_loss = 0.4385968322865665, disc_loss = 0.038232655527463064
Trained batch 320 in epoch 6, gen_loss = 0.438512736856009, disc_loss = 0.03811830335196595
Trained batch 321 in epoch 6, gen_loss = 0.43839013132249344, disc_loss = 0.03800425421546346
Trained batch 322 in epoch 6, gen_loss = 0.4384377445598874, disc_loss = 0.037949209091766814
Trained batch 323 in epoch 6, gen_loss = 0.43848688311782885, disc_loss = 0.03796672834734501
Trained batch 324 in epoch 6, gen_loss = 0.4382376433335818, disc_loss = 0.03795521121651221
Trained batch 325 in epoch 6, gen_loss = 0.4381605733208861, disc_loss = 0.037912221338694194
Trained batch 326 in epoch 6, gen_loss = 0.43821286918191005, disc_loss = 0.0378114077214875
Trained batch 327 in epoch 6, gen_loss = 0.4384755339564347, disc_loss = 0.03771100218142326
Trained batch 328 in epoch 6, gen_loss = 0.438546340516273, disc_loss = 0.03764101823453585
Trained batch 329 in epoch 6, gen_loss = 0.43846525667291697, disc_loss = 0.037790953268113575
Trained batch 330 in epoch 6, gen_loss = 0.4388403124499537, disc_loss = 0.037785356579098026
Trained batch 331 in epoch 6, gen_loss = 0.43903486816638926, disc_loss = 0.03768836298616637
Trained batch 332 in epoch 6, gen_loss = 0.43903023013481507, disc_loss = 0.037611380752592766
Trained batch 333 in epoch 6, gen_loss = 0.4391794519688555, disc_loss = 0.03751223489208549
Trained batch 334 in epoch 6, gen_loss = 0.43906657268751914, disc_loss = 0.03740943008860045
Trained batch 335 in epoch 6, gen_loss = 0.43894998551834197, disc_loss = 0.03733603655702956
Trained batch 336 in epoch 6, gen_loss = 0.43875515514028535, disc_loss = 0.03726377764278719
Trained batch 337 in epoch 6, gen_loss = 0.43872043155354157, disc_loss = 0.037162116663626905
Trained batch 338 in epoch 6, gen_loss = 0.43848710337922986, disc_loss = 0.0370611534477967
Trained batch 339 in epoch 6, gen_loss = 0.43857054342241847, disc_loss = 0.03696203328812878
Trained batch 340 in epoch 6, gen_loss = 0.4384894989802341, disc_loss = 0.03687307124997044
Trained batch 341 in epoch 6, gen_loss = 0.43844939027613367, disc_loss = 0.03678274125286939
Trained batch 342 in epoch 6, gen_loss = 0.4385003881099968, disc_loss = 0.03669498609575788
Trained batch 343 in epoch 6, gen_loss = 0.43842714418505513, disc_loss = 0.03659447065661499
Trained batch 344 in epoch 6, gen_loss = 0.4385078424128933, disc_loss = 0.03649592100257945
Trained batch 345 in epoch 6, gen_loss = 0.4385246610365851, disc_loss = 0.03644824105300106
Trained batch 346 in epoch 6, gen_loss = 0.4384901338935929, disc_loss = 0.03636088602074425
Trained batch 347 in epoch 6, gen_loss = 0.4386248712738355, disc_loss = 0.03628584590035319
Trained batch 348 in epoch 6, gen_loss = 0.4387131276991442, disc_loss = 0.03619389946106821
Trained batch 349 in epoch 6, gen_loss = 0.43869211103234973, disc_loss = 0.036156915626156014
Trained batch 350 in epoch 6, gen_loss = 0.43875613163339444, disc_loss = 0.03607257631271706
Trained batch 351 in epoch 6, gen_loss = 0.43875218893993984, disc_loss = 0.03598639573829132
Trained batch 352 in epoch 6, gen_loss = 0.438918654456017, disc_loss = 0.03589562230932107
Trained batch 353 in epoch 6, gen_loss = 0.439073080481109, disc_loss = 0.0358083864472054
Trained batch 354 in epoch 6, gen_loss = 0.43894843887275375, disc_loss = 0.0357245942161248
Trained batch 355 in epoch 6, gen_loss = 0.4390429024783413, disc_loss = 0.03563888790903435
Trained batch 356 in epoch 6, gen_loss = 0.4392969570740932, disc_loss = 0.0355476216124162
Trained batch 357 in epoch 6, gen_loss = 0.43943153196872947, disc_loss = 0.03546548306365763
Trained batch 358 in epoch 6, gen_loss = 0.43944653428696656, disc_loss = 0.03539331998931591
Trained batch 359 in epoch 6, gen_loss = 0.43921377228366004, disc_loss = 0.03531932337888672
Trained batch 360 in epoch 6, gen_loss = 0.439172375152646, disc_loss = 0.03525088274099418
Trained batch 361 in epoch 6, gen_loss = 0.4392020115371567, disc_loss = 0.03516958721106851
Trained batch 362 in epoch 6, gen_loss = 0.43920910974179417, disc_loss = 0.03510162054487958
Trained batch 363 in epoch 6, gen_loss = 0.4392859744992885, disc_loss = 0.03501185673195613
Trained batch 364 in epoch 6, gen_loss = 0.43920381771375056, disc_loss = 0.03492650720577891
Trained batch 365 in epoch 6, gen_loss = 0.4390652397128402, disc_loss = 0.03484382146499959
Trained batch 366 in epoch 6, gen_loss = 0.43911971423866314, disc_loss = 0.03476121723087256
Trained batch 367 in epoch 6, gen_loss = 0.439097479066771, disc_loss = 0.03468155200971523
Trained batch 368 in epoch 6, gen_loss = 0.4389200045002831, disc_loss = 0.0345991269826036
Trained batch 369 in epoch 6, gen_loss = 0.43897214765484266, disc_loss = 0.03452441005029942
Trained batch 370 in epoch 6, gen_loss = 0.4389027601303759, disc_loss = 0.0344414944993332
Trained batch 371 in epoch 6, gen_loss = 0.43911781987195375, disc_loss = 0.034357882863078365
Trained batch 372 in epoch 6, gen_loss = 0.43907682745450305, disc_loss = 0.034273578466700226
Trained batch 373 in epoch 6, gen_loss = 0.43910196431499116, disc_loss = 0.03418974585197418
Trained batch 374 in epoch 6, gen_loss = 0.43933141175905865, disc_loss = 0.03410774315676342
Trained batch 375 in epoch 6, gen_loss = 0.43923888926176313, disc_loss = 0.03402848509815274
Trained batch 376 in epoch 6, gen_loss = 0.43935822349644466, disc_loss = 0.033949492509422495
Trained batch 377 in epoch 6, gen_loss = 0.43930584933391953, disc_loss = 0.03393721940746117
Trained batch 378 in epoch 6, gen_loss = 0.43940035939845684, disc_loss = 0.03401774782865581
Trained batch 379 in epoch 6, gen_loss = 0.4395090580770844, disc_loss = 0.03395756187291179
Trained batch 380 in epoch 6, gen_loss = 0.4394188469319832, disc_loss = 0.03387972329262879
Trained batch 381 in epoch 6, gen_loss = 0.4394270132505457, disc_loss = 0.03385811453686383
Trained batch 382 in epoch 6, gen_loss = 0.4395646113639712, disc_loss = 0.03384839447717335
Trained batch 383 in epoch 6, gen_loss = 0.4395567396034797, disc_loss = 0.03378138084644888
Trained batch 384 in epoch 6, gen_loss = 0.43955454083232137, disc_loss = 0.03374087676774807
Trained batch 385 in epoch 6, gen_loss = 0.43957891017970646, disc_loss = 0.033673627018853736
Trained batch 386 in epoch 6, gen_loss = 0.4394892657450003, disc_loss = 0.033695269873286346
Trained batch 387 in epoch 6, gen_loss = 0.43976222885023686, disc_loss = 0.03371870159273535
Trained batch 388 in epoch 6, gen_loss = 0.43983440878765134, disc_loss = 0.03367112140897853
Trained batch 389 in epoch 6, gen_loss = 0.4397901436457267, disc_loss = 0.03367614513651158
Trained batch 390 in epoch 6, gen_loss = 0.4399660078003583, disc_loss = 0.033623816699439854
Trained batch 391 in epoch 6, gen_loss = 0.4399858709348708, disc_loss = 0.03355439572520221
Trained batch 392 in epoch 6, gen_loss = 0.4399138005786876, disc_loss = 0.03356314415222333
Trained batch 393 in epoch 6, gen_loss = 0.4399764624041349, disc_loss = 0.03410924941586179
Trained batch 394 in epoch 6, gen_loss = 0.4400256107125101, disc_loss = 0.034111489117723194
Trained batch 395 in epoch 6, gen_loss = 0.4399912641807036, disc_loss = 0.034230210609331894
Trained batch 396 in epoch 6, gen_loss = 0.4400967042001729, disc_loss = 0.03425795484307253
Trained batch 397 in epoch 6, gen_loss = 0.440178636704857, disc_loss = 0.03419578813242225
Trained batch 398 in epoch 6, gen_loss = 0.43994076195217313, disc_loss = 0.034193860747697376
Trained batch 399 in epoch 6, gen_loss = 0.4397576865553856, disc_loss = 0.03428777328022989
Trained batch 400 in epoch 6, gen_loss = 0.44006799402974195, disc_loss = 0.03509119456138072
Trained batch 401 in epoch 6, gen_loss = 0.44001047772851154, disc_loss = 0.0351557599879287
Trained batch 402 in epoch 6, gen_loss = 0.43998592071438547, disc_loss = 0.03517461943679325
Trained batch 403 in epoch 6, gen_loss = 0.43989158731580963, disc_loss = 0.03520329897136354
Trained batch 404 in epoch 6, gen_loss = 0.4399531101738965, disc_loss = 0.03527640821096016
Trained batch 405 in epoch 6, gen_loss = 0.4400870801486405, disc_loss = 0.035274782381192527
Trained batch 406 in epoch 6, gen_loss = 0.4399632036832392, disc_loss = 0.03525671570908498
Trained batch 407 in epoch 6, gen_loss = 0.43997974584207816, disc_loss = 0.0351969158489773
Trained batch 408 in epoch 6, gen_loss = 0.43997715708678975, disc_loss = 0.03514505284787144
Trained batch 409 in epoch 6, gen_loss = 0.44000966301778466, disc_loss = 0.03512565419560571
Trained batch 410 in epoch 6, gen_loss = 0.4401450600212218, disc_loss = 0.035117511807741496
Trained batch 411 in epoch 6, gen_loss = 0.44018037978885244, disc_loss = 0.0351426339512171
Trained batch 412 in epoch 6, gen_loss = 0.44024904617097127, disc_loss = 0.0350973074965418
Trained batch 413 in epoch 6, gen_loss = 0.4403184197375164, disc_loss = 0.03502768843692327
Trained batch 414 in epoch 6, gen_loss = 0.4402423526867327, disc_loss = 0.03505225918137928
Trained batch 415 in epoch 6, gen_loss = 0.4398338891422519, disc_loss = 0.03545168010420569
Trained batch 416 in epoch 6, gen_loss = 0.43980817893426194, disc_loss = 0.03544414750544904
Trained batch 417 in epoch 6, gen_loss = 0.43978473216152647, disc_loss = 0.035624304612815544
Trained batch 418 in epoch 6, gen_loss = 0.4396417574836986, disc_loss = 0.03586497278311701
Trained batch 419 in epoch 6, gen_loss = 0.43956419378519057, disc_loss = 0.035926196790976625
Trained batch 420 in epoch 6, gen_loss = 0.43968091547630744, disc_loss = 0.03601060853303231
Trained batch 421 in epoch 6, gen_loss = 0.4397366116820918, disc_loss = 0.03619864052939516
Trained batch 422 in epoch 6, gen_loss = 0.4396707378944325, disc_loss = 0.036360361100610424
Trained batch 423 in epoch 6, gen_loss = 0.43965509119180013, disc_loss = 0.03632904877825772
Trained batch 424 in epoch 6, gen_loss = 0.43972453460973854, disc_loss = 0.03631168895373669
Trained batch 425 in epoch 6, gen_loss = 0.43961207071940106, disc_loss = 0.03639574958030091
Trained batch 426 in epoch 6, gen_loss = 0.43969140105839355, disc_loss = 0.03642684954575173
Trained batch 427 in epoch 6, gen_loss = 0.4397026012851813, disc_loss = 0.03648421301960153
Trained batch 428 in epoch 6, gen_loss = 0.4398555169989179, disc_loss = 0.03709707554621895
Trained batch 429 in epoch 6, gen_loss = 0.4397879536068717, disc_loss = 0.03735377640858682
Trained batch 430 in epoch 6, gen_loss = 0.43971033639808266, disc_loss = 0.037357583491017136
Trained batch 431 in epoch 6, gen_loss = 0.43976837914023137, disc_loss = 0.037683577953969316
Trained batch 432 in epoch 6, gen_loss = 0.43978026289036865, disc_loss = 0.03762785883488103
Trained batch 433 in epoch 6, gen_loss = 0.439651599746146, disc_loss = 0.037596274128941225
Trained batch 434 in epoch 6, gen_loss = 0.4395417126430862, disc_loss = 0.037553924827665175
Trained batch 435 in epoch 6, gen_loss = 0.43937976405434653, disc_loss = 0.03752858371184412
Trained batch 436 in epoch 6, gen_loss = 0.43934256063446026, disc_loss = 0.03748504033240807
Trained batch 437 in epoch 6, gen_loss = 0.4393692379944945, disc_loss = 0.03743163617269336
Trained batch 438 in epoch 6, gen_loss = 0.43929754723720504, disc_loss = 0.03737090467151832
Trained batch 439 in epoch 6, gen_loss = 0.43933906108140947, disc_loss = 0.037336064322946845
Trained batch 440 in epoch 6, gen_loss = 0.43937666318854507, disc_loss = 0.037311570412931275
Trained batch 441 in epoch 6, gen_loss = 0.43935480181178355, disc_loss = 0.03727756543279882
Trained batch 442 in epoch 6, gen_loss = 0.4392556622792582, disc_loss = 0.03727749412859376
Trained batch 443 in epoch 6, gen_loss = 0.439296013130261, disc_loss = 0.03740235472434653
Trained batch 444 in epoch 6, gen_loss = 0.4395258555921276, disc_loss = 0.03735215599266708
Trained batch 445 in epoch 6, gen_loss = 0.4393430733092697, disc_loss = 0.03741604041944011
Trained batch 446 in epoch 6, gen_loss = 0.43936659018998714, disc_loss = 0.037364682605879704
Trained batch 447 in epoch 6, gen_loss = 0.43935610819607973, disc_loss = 0.03731085828024204
Trained batch 448 in epoch 6, gen_loss = 0.4393817660936003, disc_loss = 0.037250977250403064
Trained batch 449 in epoch 6, gen_loss = 0.43944011880291833, disc_loss = 0.03719731262600463
Trained batch 450 in epoch 6, gen_loss = 0.43935943561752727, disc_loss = 0.03712602944021421
Trained batch 451 in epoch 6, gen_loss = 0.439355629471551, disc_loss = 0.03712089403982653
Trained batch 452 in epoch 6, gen_loss = 0.43934535427598764, disc_loss = 0.037055837113058675
Trained batch 453 in epoch 6, gen_loss = 0.4393552719627708, disc_loss = 0.037113486123753356
Trained batch 454 in epoch 6, gen_loss = 0.43932189456709136, disc_loss = 0.037060631012574737
Trained batch 455 in epoch 6, gen_loss = 0.4391389644721098, disc_loss = 0.03701747136048589
Trained batch 456 in epoch 6, gen_loss = 0.4391987873506233, disc_loss = 0.037161701706572306
Trained batch 457 in epoch 6, gen_loss = 0.4393116634615644, disc_loss = 0.03712676141708967
Trained batch 458 in epoch 6, gen_loss = 0.4393060269698598, disc_loss = 0.03780009714335666
Trained batch 459 in epoch 6, gen_loss = 0.4390215295812358, disc_loss = 0.037845554542171
Trained batch 460 in epoch 6, gen_loss = 0.43893677623308147, disc_loss = 0.03790977791102235
Trained batch 461 in epoch 6, gen_loss = 0.43877994762612627, disc_loss = 0.03790693232528583
Trained batch 462 in epoch 6, gen_loss = 0.4388492688633196, disc_loss = 0.03795519220863004
Trained batch 463 in epoch 6, gen_loss = 0.43873313538216313, disc_loss = 0.037965829475383385
Trained batch 464 in epoch 6, gen_loss = 0.4387123466178935, disc_loss = 0.03801809433091592
Trained batch 465 in epoch 6, gen_loss = 0.4387065851381408, disc_loss = 0.03802399784091724
Trained batch 466 in epoch 6, gen_loss = 0.4389117243968955, disc_loss = 0.03802421736023419
Trained batch 467 in epoch 6, gen_loss = 0.438922873355894, disc_loss = 0.0379682638491882
Trained batch 468 in epoch 6, gen_loss = 0.43894014652095625, disc_loss = 0.03790471023211736
Trained batch 469 in epoch 6, gen_loss = 0.4388984113931656, disc_loss = 0.03784825816042127
Trained batch 470 in epoch 6, gen_loss = 0.438963864576032, disc_loss = 0.03777566476257403
Trained batch 471 in epoch 6, gen_loss = 0.43902902324068344, disc_loss = 0.03770472404721659
Trained batch 472 in epoch 6, gen_loss = 0.43892281207927436, disc_loss = 0.03764078614619968
Trained batch 473 in epoch 6, gen_loss = 0.4389257352437651, disc_loss = 0.03760409720349106
Trained batch 474 in epoch 6, gen_loss = 0.43895086595886634, disc_loss = 0.03756927978173879
Trained batch 475 in epoch 6, gen_loss = 0.43889178291839714, disc_loss = 0.03782996014195901
Trained batch 476 in epoch 6, gen_loss = 0.4386929693461964, disc_loss = 0.03841163844492021
Trained batch 477 in epoch 6, gen_loss = 0.4384910172498376, disc_loss = 0.03860762208884301
Trained batch 478 in epoch 6, gen_loss = 0.4384359502095519, disc_loss = 0.038827183274581394
Trained batch 479 in epoch 6, gen_loss = 0.4384023822223147, disc_loss = 0.03897707297898402
Trained batch 480 in epoch 6, gen_loss = 0.43825884779872615, disc_loss = 0.03901147653553015
Trained batch 481 in epoch 6, gen_loss = 0.43818244702835796, disc_loss = 0.03909863661554414
Trained batch 482 in epoch 6, gen_loss = 0.43812902311854235, disc_loss = 0.03915475561996
Trained batch 483 in epoch 6, gen_loss = 0.43809180811417003, disc_loss = 0.03927375011512633
Trained batch 484 in epoch 6, gen_loss = 0.43811843057268673, disc_loss = 0.03937974303466335
Trained batch 485 in epoch 6, gen_loss = 0.43785712043199027, disc_loss = 0.03945660068478182
Trained batch 486 in epoch 6, gen_loss = 0.4376786113152514, disc_loss = 0.03955497069583605
Trained batch 487 in epoch 6, gen_loss = 0.43741797576429414, disc_loss = 0.03963331463026287
Trained batch 488 in epoch 6, gen_loss = 0.43738852718612653, disc_loss = 0.03962192682245583
Trained batch 489 in epoch 6, gen_loss = 0.4373686086766574, disc_loss = 0.03963628666100035
Trained batch 490 in epoch 6, gen_loss = 0.43738866404700427, disc_loss = 0.03967697101397641
Trained batch 491 in epoch 6, gen_loss = 0.43746330031776814, disc_loss = 0.039685558634895333
Trained batch 492 in epoch 6, gen_loss = 0.43755818471221847, disc_loss = 0.03973754973062947
Trained batch 493 in epoch 6, gen_loss = 0.43751683547670545, disc_loss = 0.03991440139255611
Trained batch 494 in epoch 6, gen_loss = 0.43760665022965634, disc_loss = 0.03994431763703963
Trained batch 495 in epoch 6, gen_loss = 0.4378461391334572, disc_loss = 0.039985317745548296
Trained batch 496 in epoch 6, gen_loss = 0.43786413203062907, disc_loss = 0.03995534989133035
Trained batch 497 in epoch 6, gen_loss = 0.43779288723047477, disc_loss = 0.040057843649455055
Trained batch 498 in epoch 6, gen_loss = 0.4378019101872951, disc_loss = 0.040028782185579544
Trained batch 499 in epoch 6, gen_loss = 0.4377099583745003, disc_loss = 0.04025849291053601
Trained batch 500 in epoch 6, gen_loss = 0.4377187480945549, disc_loss = 0.0402675889176363
Trained batch 501 in epoch 6, gen_loss = 0.4376513047284814, disc_loss = 0.04035481369142343
Trained batch 502 in epoch 6, gen_loss = 0.43779416977766733, disc_loss = 0.04068282677002333
Trained batch 503 in epoch 6, gen_loss = 0.437688233892596, disc_loss = 0.04092211584631716
Trained batch 504 in epoch 6, gen_loss = 0.4378193576147061, disc_loss = 0.04100794551068788
Trained batch 505 in epoch 6, gen_loss = 0.43773863114151557, disc_loss = 0.04094836916963169
Trained batch 506 in epoch 6, gen_loss = 0.4378469176076103, disc_loss = 0.04095502763631142
Trained batch 507 in epoch 6, gen_loss = 0.4376978704075175, disc_loss = 0.04107256673801668
Trained batch 508 in epoch 6, gen_loss = 0.43763801590164425, disc_loss = 0.04119112278304606
Trained batch 509 in epoch 6, gen_loss = 0.43762790367883797, disc_loss = 0.04114049949669553
Trained batch 510 in epoch 6, gen_loss = 0.4374992852691568, disc_loss = 0.04129298819149726
Trained batch 511 in epoch 6, gen_loss = 0.43758047494338825, disc_loss = 0.04126607892726497
Trained batch 512 in epoch 6, gen_loss = 0.43759493945170097, disc_loss = 0.04120033465032638
Trained batch 513 in epoch 6, gen_loss = 0.43753587892315265, disc_loss = 0.04113344180036213
Trained batch 514 in epoch 6, gen_loss = 0.4376972988392543, disc_loss = 0.04106780201020352
Trained batch 515 in epoch 6, gen_loss = 0.43759230143109035, disc_loss = 0.04100539302746693
Trained batch 516 in epoch 6, gen_loss = 0.43764456974007404, disc_loss = 0.040937887498617126
Trained batch 517 in epoch 6, gen_loss = 0.4375228311104204, disc_loss = 0.04088233216889526
Trained batch 518 in epoch 6, gen_loss = 0.4374747800000141, disc_loss = 0.04083409095887339
Trained batch 519 in epoch 6, gen_loss = 0.43747508313793404, disc_loss = 0.040764912244944405
Trained batch 520 in epoch 6, gen_loss = 0.43737210427730877, disc_loss = 0.04069118438518272
Trained batch 521 in epoch 6, gen_loss = 0.43740359222751923, disc_loss = 0.04062032955096521
Trained batch 522 in epoch 6, gen_loss = 0.4374235195479931, disc_loss = 0.040550741889018985
Trained batch 523 in epoch 6, gen_loss = 0.4374597716991228, disc_loss = 0.04047845180954194
Trained batch 524 in epoch 6, gen_loss = 0.437681816475732, disc_loss = 0.04041729325982964
Trained batch 525 in epoch 6, gen_loss = 0.43772436956035776, disc_loss = 0.04035474994673992
Trained batch 526 in epoch 6, gen_loss = 0.43769403839699456, disc_loss = 0.040290088077567066
Trained batch 527 in epoch 6, gen_loss = 0.4376301582564007, disc_loss = 0.04025839835120485
Trained batch 528 in epoch 6, gen_loss = 0.4376029067994967, disc_loss = 0.0401944637473317
Trained batch 529 in epoch 6, gen_loss = 0.4375226438045502, disc_loss = 0.04012817392094974
Trained batch 530 in epoch 6, gen_loss = 0.4374925741143595, disc_loss = 0.04006359475667425
Trained batch 531 in epoch 6, gen_loss = 0.4374482376795066, disc_loss = 0.04000725542458607
Trained batch 532 in epoch 6, gen_loss = 0.43739987800760965, disc_loss = 0.03993840263322115
Trained batch 533 in epoch 6, gen_loss = 0.43733335183131117, disc_loss = 0.03986797379857376
Trained batch 534 in epoch 6, gen_loss = 0.43733520101163986, disc_loss = 0.039810583527443634
Trained batch 535 in epoch 6, gen_loss = 0.43739865981598397, disc_loss = 0.03974237804168161
Trained batch 536 in epoch 6, gen_loss = 0.4372943371700841, disc_loss = 0.03967386716608222
Trained batch 537 in epoch 6, gen_loss = 0.43719230481461524, disc_loss = 0.03960806682085286
Trained batch 538 in epoch 6, gen_loss = 0.4371706909726414, disc_loss = 0.039541692106901616
Trained batch 539 in epoch 6, gen_loss = 0.4373067554500368, disc_loss = 0.03947418750311179
Trained batch 540 in epoch 6, gen_loss = 0.43720258295866565, disc_loss = 0.039413729212384556
Trained batch 541 in epoch 6, gen_loss = 0.4372863931189604, disc_loss = 0.03934877574494507
Trained batch 542 in epoch 6, gen_loss = 0.4372520242606737, disc_loss = 0.03931596277356251
Trained batch 543 in epoch 6, gen_loss = 0.43712616991251707, disc_loss = 0.03931716321141507
Trained batch 544 in epoch 6, gen_loss = 0.43718295469196566, disc_loss = 0.03926528887801863
Trained batch 545 in epoch 6, gen_loss = 0.43714668724563094, disc_loss = 0.03920024197063351
Trained batch 546 in epoch 6, gen_loss = 0.43719543497566765, disc_loss = 0.0391374853398341
Trained batch 547 in epoch 6, gen_loss = 0.4371328713902592, disc_loss = 0.039074605811569144
Trained batch 548 in epoch 6, gen_loss = 0.43715111175738613, disc_loss = 0.0390114868837977
Trained batch 549 in epoch 6, gen_loss = 0.43703004598617556, disc_loss = 0.03894840326139026
Trained batch 550 in epoch 6, gen_loss = 0.4370699985706655, disc_loss = 0.03890684812888334
Trained batch 551 in epoch 6, gen_loss = 0.4370825497460538, disc_loss = 0.03886144825209276
Trained batch 552 in epoch 6, gen_loss = 0.43709887146518633, disc_loss = 0.038838792969321134
Trained batch 553 in epoch 6, gen_loss = 0.43707568550798437, disc_loss = 0.03877750643262545
Trained batch 554 in epoch 6, gen_loss = 0.43698802493713995, disc_loss = 0.03875308566042935
Trained batch 555 in epoch 6, gen_loss = 0.4370556656512425, disc_loss = 0.038721016939627276
Trained batch 556 in epoch 6, gen_loss = 0.4370427769433232, disc_loss = 0.03865912555624134
Trained batch 557 in epoch 6, gen_loss = 0.4369746760121383, disc_loss = 0.038610340693363034
Trained batch 558 in epoch 6, gen_loss = 0.43720505750456523, disc_loss = 0.03855329122180236
Trained batch 559 in epoch 6, gen_loss = 0.43711145695831094, disc_loss = 0.03854837550627833
Trained batch 560 in epoch 6, gen_loss = 0.4373026731923727, disc_loss = 0.03897110419244125
Trained batch 561 in epoch 6, gen_loss = 0.4372318387031555, disc_loss = 0.03898445359042604
Trained batch 562 in epoch 6, gen_loss = 0.43728998149902315, disc_loss = 0.03896937078277731
Trained batch 563 in epoch 6, gen_loss = 0.43744231136978096, disc_loss = 0.03898504702353698
Trained batch 564 in epoch 6, gen_loss = 0.43753559826749616, disc_loss = 0.03896097509845663
Trained batch 565 in epoch 6, gen_loss = 0.4376240187314711, disc_loss = 0.038917357388138445
Trained batch 566 in epoch 6, gen_loss = 0.4374907136594177, disc_loss = 0.0388942224840425
Trained batch 567 in epoch 6, gen_loss = 0.4375543956395606, disc_loss = 0.038838423685044456
Trained batch 568 in epoch 6, gen_loss = 0.4376446364843573, disc_loss = 0.03879152810890948
Trained batch 569 in epoch 6, gen_loss = 0.43771582747760573, disc_loss = 0.03873289023881386
Trained batch 570 in epoch 6, gen_loss = 0.4378099427958086, disc_loss = 0.038676153528977075
Trained batch 571 in epoch 6, gen_loss = 0.43791659900566915, disc_loss = 0.038619431303740785
Trained batch 572 in epoch 6, gen_loss = 0.43784627812487087, disc_loss = 0.038564984043645646
Trained batch 573 in epoch 6, gen_loss = 0.4379023190990142, disc_loss = 0.03852723915521737
Trained batch 574 in epoch 6, gen_loss = 0.43777511264966884, disc_loss = 0.03847537718774022
Trained batch 575 in epoch 6, gen_loss = 0.4377559952230917, disc_loss = 0.03841367819546172
Trained batch 576 in epoch 6, gen_loss = 0.4377056779646584, disc_loss = 0.038353336311390936
Trained batch 577 in epoch 6, gen_loss = 0.4376752887011399, disc_loss = 0.03829202750455234
Trained batch 578 in epoch 6, gen_loss = 0.43761630173585986, disc_loss = 0.03823426945938444
Trained batch 579 in epoch 6, gen_loss = 0.43756332217619337, disc_loss = 0.038187346450687415
Trained batch 580 in epoch 6, gen_loss = 0.4375794205218297, disc_loss = 0.038137457968880344
Trained batch 581 in epoch 6, gen_loss = 0.4376021546801341, disc_loss = 0.038099592701008676
Trained batch 582 in epoch 6, gen_loss = 0.4376420292805235, disc_loss = 0.03809102931587859
Trained batch 583 in epoch 6, gen_loss = 0.4376428979512763, disc_loss = 0.03804036170744165
Trained batch 584 in epoch 6, gen_loss = 0.4375878932129624, disc_loss = 0.03799615673080055
Trained batch 585 in epoch 6, gen_loss = 0.4375239674243504, disc_loss = 0.03795231861970626
Trained batch 586 in epoch 6, gen_loss = 0.43753170241082956, disc_loss = 0.037902558987739685
Trained batch 587 in epoch 6, gen_loss = 0.43765123071921924, disc_loss = 0.037851204400918555
Trained batch 588 in epoch 6, gen_loss = 0.43774715855287577, disc_loss = 0.037820163452309985
Trained batch 589 in epoch 6, gen_loss = 0.4377690431930251, disc_loss = 0.037910326130459304
Trained batch 590 in epoch 6, gen_loss = 0.43783580258413013, disc_loss = 0.03794291215438975
Trained batch 591 in epoch 6, gen_loss = 0.4378765013471648, disc_loss = 0.03790648443828104
Trained batch 592 in epoch 6, gen_loss = 0.4380246968233163, disc_loss = 0.037850848506487476
Trained batch 593 in epoch 6, gen_loss = 0.4379855692386627, disc_loss = 0.03784178895934607
Trained batch 594 in epoch 6, gen_loss = 0.43792422924722946, disc_loss = 0.037913332014548114
Trained batch 595 in epoch 6, gen_loss = 0.43803106543401743, disc_loss = 0.037888971168896335
Trained batch 596 in epoch 6, gen_loss = 0.4381838889677121, disc_loss = 0.03791998509513417
Trained batch 597 in epoch 6, gen_loss = 0.4382680485579481, disc_loss = 0.03792131835977114
Trained batch 598 in epoch 6, gen_loss = 0.4383208120307063, disc_loss = 0.037891309800672845
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.44030219316482544, disc_loss = 0.01406451128423214
Trained batch 1 in epoch 7, gen_loss = 0.43733498454093933, disc_loss = 0.009350602282211185
Trained batch 2 in epoch 7, gen_loss = 0.4509214162826538, disc_loss = 0.007772152777761221
Trained batch 3 in epoch 7, gen_loss = 0.4536553844809532, disc_loss = 0.007292686379514635
Trained batch 4 in epoch 7, gen_loss = 0.46185638308525084, disc_loss = 0.008841763157397509
Trained batch 5 in epoch 7, gen_loss = 0.44822073479493457, disc_loss = 0.007959216755504409
Trained batch 6 in epoch 7, gen_loss = 0.44138684017317636, disc_loss = 0.010590963797377688
Trained batch 7 in epoch 7, gen_loss = 0.4401295632123947, disc_loss = 0.010591597005259246
Trained batch 8 in epoch 7, gen_loss = 0.44140083922280204, disc_loss = 0.009988510308580266
Trained batch 9 in epoch 7, gen_loss = 0.44430020451545715, disc_loss = 0.010829267790541053
Trained batch 10 in epoch 7, gen_loss = 0.45551539009267633, disc_loss = 0.01190572041510181
Trained batch 11 in epoch 7, gen_loss = 0.44777459651231766, disc_loss = 0.011390275787562132
Trained batch 12 in epoch 7, gen_loss = 0.4427690895704123, disc_loss = 0.01203904659129106
Trained batch 13 in epoch 7, gen_loss = 0.4420416844742639, disc_loss = 0.012276091546352421
Trained batch 14 in epoch 7, gen_loss = 0.4423859814802806, disc_loss = 0.012152585200965405
Trained batch 15 in epoch 7, gen_loss = 0.43838626705110073, disc_loss = 0.01227609597845003
Trained batch 16 in epoch 7, gen_loss = 0.4410564987098469, disc_loss = 0.012760850053061457
Trained batch 17 in epoch 7, gen_loss = 0.44449082182513344, disc_loss = 0.012394991677461399
Trained batch 18 in epoch 7, gen_loss = 0.44230894665969045, disc_loss = 0.014537767629678311
Trained batch 19 in epoch 7, gen_loss = 0.44349589496850966, disc_loss = 0.021877262997440992
Trained batch 20 in epoch 7, gen_loss = 0.44376201430956524, disc_loss = 0.026936358883089963
Trained batch 21 in epoch 7, gen_loss = 0.446545502001589, disc_loss = 0.028859625041315503
Trained batch 22 in epoch 7, gen_loss = 0.4460850396881933, disc_loss = 0.028867498748814283
Trained batch 23 in epoch 7, gen_loss = 0.4478534745673339, disc_loss = 0.03765639296034351
Trained batch 24 in epoch 7, gen_loss = 0.44217199325561524, disc_loss = 0.04995665198192
Trained batch 25 in epoch 7, gen_loss = 0.43621506140782285, disc_loss = 0.05375937320506917
Trained batch 26 in epoch 7, gen_loss = 0.43390810600033514, disc_loss = 0.05569228811051558
Trained batch 27 in epoch 7, gen_loss = 0.43412799494607107, disc_loss = 0.057105347564044805
Trained batch 28 in epoch 7, gen_loss = 0.432848675497647, disc_loss = 0.05744150516994555
Trained batch 29 in epoch 7, gen_loss = 0.43179271221160886, disc_loss = 0.05663210269995034
Trained batch 30 in epoch 7, gen_loss = 0.4325268797336086, disc_loss = 0.056765529462286544
Trained batch 31 in epoch 7, gen_loss = 0.4337934674695134, disc_loss = 0.05596879105723929
Trained batch 32 in epoch 7, gen_loss = 0.4352369452967788, disc_loss = 0.05544956597132665
Trained batch 33 in epoch 7, gen_loss = 0.4364064169280669, disc_loss = 0.05607261293677285
Trained batch 34 in epoch 7, gen_loss = 0.4357649769101824, disc_loss = 0.06005451257473656
Trained batch 35 in epoch 7, gen_loss = 0.43689023620552486, disc_loss = 0.06081827299203724
Trained batch 36 in epoch 7, gen_loss = 0.4370363072769062, disc_loss = 0.059840851677329956
Trained batch 37 in epoch 7, gen_loss = 0.43628641178733424, disc_loss = 0.059768919624682317
Trained batch 38 in epoch 7, gen_loss = 0.4366598855226468, disc_loss = 0.05920636561961892
Trained batch 39 in epoch 7, gen_loss = 0.4388925261795521, disc_loss = 0.05941223971312866
Trained batch 40 in epoch 7, gen_loss = 0.43950630615397196, disc_loss = 0.05911698422917142
Trained batch 41 in epoch 7, gen_loss = 0.43989346566654386, disc_loss = 0.061251276959886865
Trained batch 42 in epoch 7, gen_loss = 0.44149855264397553, disc_loss = 0.06084195969539673
Trained batch 43 in epoch 7, gen_loss = 0.44456780498678033, disc_loss = 0.06027463742066175
Trained batch 44 in epoch 7, gen_loss = 0.44578024612532724, disc_loss = 0.05962257487699389
Trained batch 45 in epoch 7, gen_loss = 0.4465436728104301, disc_loss = 0.05888484903287305
Trained batch 46 in epoch 7, gen_loss = 0.4495165766553676, disc_loss = 0.057837939652753
Trained batch 47 in epoch 7, gen_loss = 0.4483513751377662, disc_loss = 0.05694247820065357
Trained batch 48 in epoch 7, gen_loss = 0.44837789936941497, disc_loss = 0.056554784646675904
Trained batch 49 in epoch 7, gen_loss = 0.4474383932352066, disc_loss = 0.055627002036198976
Trained batch 50 in epoch 7, gen_loss = 0.4472237317001118, disc_loss = 0.054763910114107764
Trained batch 51 in epoch 7, gen_loss = 0.445773530464906, disc_loss = 0.05391089581490423
Trained batch 52 in epoch 7, gen_loss = 0.4457037150859833, disc_loss = 0.05320841660020205
Trained batch 53 in epoch 7, gen_loss = 0.44489100244310165, disc_loss = 0.05234093883902662
Trained batch 54 in epoch 7, gen_loss = 0.4443835589018735, disc_loss = 0.05256121079860763
Trained batch 55 in epoch 7, gen_loss = 0.443199522793293, disc_loss = 0.05279346863972023
Trained batch 56 in epoch 7, gen_loss = 0.4426155780491076, disc_loss = 0.05230775948515848
Trained batch 57 in epoch 7, gen_loss = 0.4433603918757932, disc_loss = 0.052971793426971496
Trained batch 58 in epoch 7, gen_loss = 0.44350021067312206, disc_loss = 0.05366059369802222
Trained batch 59 in epoch 7, gen_loss = 0.4417720566193263, disc_loss = 0.05388696196023375
Trained batch 60 in epoch 7, gen_loss = 0.4421714036191096, disc_loss = 0.05332769840558777
Trained batch 61 in epoch 7, gen_loss = 0.44213912515870984, disc_loss = 0.052578652825867454
Trained batch 62 in epoch 7, gen_loss = 0.4421742284108722, disc_loss = 0.052282355200972346
Trained batch 63 in epoch 7, gen_loss = 0.442678636405617, disc_loss = 0.052372078360349406
Trained batch 64 in epoch 7, gen_loss = 0.4430662709933061, disc_loss = 0.05171667603202737
Trained batch 65 in epoch 7, gen_loss = 0.44268983602523804, disc_loss = 0.05152948135086759
Trained batch 66 in epoch 7, gen_loss = 0.44172649419129784, disc_loss = 0.05178012122719813
Trained batch 67 in epoch 7, gen_loss = 0.4431780655594433, disc_loss = 0.05121225657571545
Trained batch 68 in epoch 7, gen_loss = 0.4426729134891344, disc_loss = 0.05060717279253447
Trained batch 69 in epoch 7, gen_loss = 0.4423867894070489, disc_loss = 0.05025777619199029
Trained batch 70 in epoch 7, gen_loss = 0.4418405126517927, disc_loss = 0.049938585655107885
Trained batch 71 in epoch 7, gen_loss = 0.44155813794997, disc_loss = 0.04948336319972037
Trained batch 72 in epoch 7, gen_loss = 0.4401016941625778, disc_loss = 0.04916412734796535
Trained batch 73 in epoch 7, gen_loss = 0.4391315865355569, disc_loss = 0.04920228640548885
Trained batch 74 in epoch 7, gen_loss = 0.4395136408011119, disc_loss = 0.048611383307725194
Trained batch 75 in epoch 7, gen_loss = 0.439792347581763, disc_loss = 0.050301218570798244
Trained batch 76 in epoch 7, gen_loss = 0.438702702909321, disc_loss = 0.05446039127524604
Trained batch 77 in epoch 7, gen_loss = 0.4378387717864452, disc_loss = 0.05583411289784962
Trained batch 78 in epoch 7, gen_loss = 0.4384717756434332, disc_loss = 0.057939067547787215
Trained batch 79 in epoch 7, gen_loss = 0.43753009326756, disc_loss = 0.05778101251344196
Trained batch 80 in epoch 7, gen_loss = 0.4371785138860161, disc_loss = 0.0577101350279042
Trained batch 81 in epoch 7, gen_loss = 0.43612050864754653, disc_loss = 0.057268210885501124
Trained batch 82 in epoch 7, gen_loss = 0.4355917673513114, disc_loss = 0.05680681035169456
Trained batch 83 in epoch 7, gen_loss = 0.4357152066770054, disc_loss = 0.0571435861721901
Trained batch 84 in epoch 7, gen_loss = 0.4354682855746325, disc_loss = 0.057405985601465495
Trained batch 85 in epoch 7, gen_loss = 0.43558092553948247, disc_loss = 0.05686582617873196
Trained batch 86 in epoch 7, gen_loss = 0.4359069387803132, disc_loss = 0.05676873535153338
Trained batch 87 in epoch 7, gen_loss = 0.4361846192993901, disc_loss = 0.05647238967834379
Trained batch 88 in epoch 7, gen_loss = 0.4364152145519685, disc_loss = 0.05599826295452004
Trained batch 89 in epoch 7, gen_loss = 0.43590867287582824, disc_loss = 0.05548176752506859
Trained batch 90 in epoch 7, gen_loss = 0.43617201735685157, disc_loss = 0.054916009736748844
Trained batch 91 in epoch 7, gen_loss = 0.43718083300020383, disc_loss = 0.05490302584012565
Trained batch 92 in epoch 7, gen_loss = 0.4362459471148829, disc_loss = 0.05449050378495006
Trained batch 93 in epoch 7, gen_loss = 0.43631206611369516, disc_loss = 0.054453666242671776
Trained batch 94 in epoch 7, gen_loss = 0.4362287308040418, disc_loss = 0.053977454336065996
Trained batch 95 in epoch 7, gen_loss = 0.436959362278382, disc_loss = 0.053824988775886595
Trained batch 96 in epoch 7, gen_loss = 0.4368524035227667, disc_loss = 0.053321386591444926
Trained batch 97 in epoch 7, gen_loss = 0.43675221898117844, disc_loss = 0.05283307884724773
Trained batch 98 in epoch 7, gen_loss = 0.4375631128898775, disc_loss = 0.052343142157740365
Trained batch 99 in epoch 7, gen_loss = 0.43771496385335923, disc_loss = 0.05190618113148957
Trained batch 100 in epoch 7, gen_loss = 0.4378552785014162, disc_loss = 0.05143661514422534
Trained batch 101 in epoch 7, gen_loss = 0.4376400387754627, disc_loss = 0.05099770326769965
Trained batch 102 in epoch 7, gen_loss = 0.43736779602985937, disc_loss = 0.05062381616223929
Trained batch 103 in epoch 7, gen_loss = 0.4370129933724037, disc_loss = 0.05016021485565803
Trained batch 104 in epoch 7, gen_loss = 0.43719531496365865, disc_loss = 0.04971560010952609
Trained batch 105 in epoch 7, gen_loss = 0.4369786665687021, disc_loss = 0.04927271623208346
Trained batch 106 in epoch 7, gen_loss = 0.4367858650528382, disc_loss = 0.048871282020270405
Trained batch 107 in epoch 7, gen_loss = 0.4373571952735936, disc_loss = 0.048461137134668035
Trained batch 108 in epoch 7, gen_loss = 0.4373035009847869, disc_loss = 0.04806595600483546
Trained batch 109 in epoch 7, gen_loss = 0.43704586760564285, disc_loss = 0.047653318018737165
Trained batch 110 in epoch 7, gen_loss = 0.4375459618933566, disc_loss = 0.04729185175352
Trained batch 111 in epoch 7, gen_loss = 0.43778109923005104, disc_loss = 0.0469401771718237
Trained batch 112 in epoch 7, gen_loss = 0.4372489220273178, disc_loss = 0.04655446851650764
Trained batch 113 in epoch 7, gen_loss = 0.43699628689832853, disc_loss = 0.04617712038503796
Trained batch 114 in epoch 7, gen_loss = 0.43731063500694606, disc_loss = 0.045799118750121284
Trained batch 115 in epoch 7, gen_loss = 0.437038443468768, disc_loss = 0.04543193077251058
Trained batch 116 in epoch 7, gen_loss = 0.43747801734850955, disc_loss = 0.04508102870283601
Trained batch 117 in epoch 7, gen_loss = 0.4375230139594967, disc_loss = 0.044853124787273296
Trained batch 118 in epoch 7, gen_loss = 0.4374514277241811, disc_loss = 0.04455521858117285
Trained batch 119 in epoch 7, gen_loss = 0.43714167748888333, disc_loss = 0.04424404106102884
Trained batch 120 in epoch 7, gen_loss = 0.4370341882232792, disc_loss = 0.04391522655910081
Trained batch 121 in epoch 7, gen_loss = 0.43735201046115063, disc_loss = 0.04362065373675623
Trained batch 122 in epoch 7, gen_loss = 0.43778762754386036, disc_loss = 0.04330619598731277
Trained batch 123 in epoch 7, gen_loss = 0.43782529355056826, disc_loss = 0.04299922517290519
Trained batch 124 in epoch 7, gen_loss = 0.4377877027988434, disc_loss = 0.04292664302885532
Trained batch 125 in epoch 7, gen_loss = 0.4378922621882151, disc_loss = 0.04269233245461706
Trained batch 126 in epoch 7, gen_loss = 0.43801456384771453, disc_loss = 0.042381420322715885
Trained batch 127 in epoch 7, gen_loss = 0.4380664413329214, disc_loss = 0.042126104768613004
Trained batch 128 in epoch 7, gen_loss = 0.43866629863894263, disc_loss = 0.041863065416917436
Trained batch 129 in epoch 7, gen_loss = 0.4383559573155183, disc_loss = 0.04163239598453331
Trained batch 130 in epoch 7, gen_loss = 0.43874445170846604, disc_loss = 0.04133799846305419
Trained batch 131 in epoch 7, gen_loss = 0.4389606520082011, disc_loss = 0.0410407819982731
Trained batch 132 in epoch 7, gen_loss = 0.4389825656001729, disc_loss = 0.040761080574020184
Trained batch 133 in epoch 7, gen_loss = 0.43923009731876317, disc_loss = 0.0404817158523113
Trained batch 134 in epoch 7, gen_loss = 0.4396102220923812, disc_loss = 0.040242085074660955
Trained batch 135 in epoch 7, gen_loss = 0.43967263488208547, disc_loss = 0.03997072628836202
Trained batch 136 in epoch 7, gen_loss = 0.4395288940328751, disc_loss = 0.039700655936243105
Trained batch 137 in epoch 7, gen_loss = 0.4392301982295686, disc_loss = 0.03944188515669194
Trained batch 138 in epoch 7, gen_loss = 0.43915051093204416, disc_loss = 0.03918736678608459
Trained batch 139 in epoch 7, gen_loss = 0.4396870234182903, disc_loss = 0.03893880816841764
Trained batch 140 in epoch 7, gen_loss = 0.43990857487029217, disc_loss = 0.03868093956856335
Trained batch 141 in epoch 7, gen_loss = 0.4398739579277979, disc_loss = 0.03842232233523325
Trained batch 142 in epoch 7, gen_loss = 0.43935468376099646, disc_loss = 0.038295046994592866
Trained batch 143 in epoch 7, gen_loss = 0.43898482786284554, disc_loss = 0.03810958659515665
Trained batch 144 in epoch 7, gen_loss = 0.4389574461969836, disc_loss = 0.03788268876518926
Trained batch 145 in epoch 7, gen_loss = 0.4387774704253837, disc_loss = 0.037643000424507855
Trained batch 146 in epoch 7, gen_loss = 0.43890159511241783, disc_loss = 0.03740336592499243
Trained batch 147 in epoch 7, gen_loss = 0.43900366208037817, disc_loss = 0.03717211040674482
Trained batch 148 in epoch 7, gen_loss = 0.43906830481234815, disc_loss = 0.03695949319681315
Trained batch 149 in epoch 7, gen_loss = 0.43962513546148935, disc_loss = 0.036759196931185824
Trained batch 150 in epoch 7, gen_loss = 0.4401610464055017, disc_loss = 0.03655256740039597
Trained batch 151 in epoch 7, gen_loss = 0.4401424568342535, disc_loss = 0.03634111587981399
Trained batch 152 in epoch 7, gen_loss = 0.43976333211450014, disc_loss = 0.03613660264048068
Trained batch 153 in epoch 7, gen_loss = 0.4396872032772411, disc_loss = 0.03592109561795006
Trained batch 154 in epoch 7, gen_loss = 0.44032971589796005, disc_loss = 0.0357368903369793
Trained batch 155 in epoch 7, gen_loss = 0.4406394769365971, disc_loss = 0.03556722471377072
Trained batch 156 in epoch 7, gen_loss = 0.4404233329615016, disc_loss = 0.035417647114332027
Trained batch 157 in epoch 7, gen_loss = 0.44031022621106497, disc_loss = 0.03530216068058876
Trained batch 158 in epoch 7, gen_loss = 0.44008572334013646, disc_loss = 0.03513626068531764
Trained batch 159 in epoch 7, gen_loss = 0.44021566342562435, disc_loss = 0.03496075731964084
Trained batch 160 in epoch 7, gen_loss = 0.4402332850124525, disc_loss = 0.03477037183344595
Trained batch 161 in epoch 7, gen_loss = 0.44010138143727806, disc_loss = 0.03460881994307087
Trained batch 162 in epoch 7, gen_loss = 0.44059443583517716, disc_loss = 0.03447801395365111
Trained batch 163 in epoch 7, gen_loss = 0.44055799849149657, disc_loss = 0.03441231168108061
Trained batch 164 in epoch 7, gen_loss = 0.4405853555057988, disc_loss = 0.03450968012241929
Trained batch 165 in epoch 7, gen_loss = 0.44024655384471617, disc_loss = 0.034332097083027195
Trained batch 166 in epoch 7, gen_loss = 0.44040703487967303, disc_loss = 0.03416399529042046
Trained batch 167 in epoch 7, gen_loss = 0.44047374171870096, disc_loss = 0.03397656806157015
Trained batch 168 in epoch 7, gen_loss = 0.4407232463712523, disc_loss = 0.03381871777041071
Trained batch 169 in epoch 7, gen_loss = 0.44059231000788074, disc_loss = 0.03368181599413647
Trained batch 170 in epoch 7, gen_loss = 0.4404232578667981, disc_loss = 0.03350983990073117
Trained batch 171 in epoch 7, gen_loss = 0.440022170197132, disc_loss = 0.03333465697048882
Trained batch 172 in epoch 7, gen_loss = 0.44024063724313856, disc_loss = 0.03315823804048789
Trained batch 173 in epoch 7, gen_loss = 0.44027743959563903, disc_loss = 0.03299565114423461
Trained batch 174 in epoch 7, gen_loss = 0.440120918239866, disc_loss = 0.03284159205853939
Trained batch 175 in epoch 7, gen_loss = 0.43972711519084196, disc_loss = 0.03270300032719123
Trained batch 176 in epoch 7, gen_loss = 0.4398387486988542, disc_loss = 0.03254405225990182
Trained batch 177 in epoch 7, gen_loss = 0.4401554096950574, disc_loss = 0.032377233786320084
Trained batch 178 in epoch 7, gen_loss = 0.43992338999689623, disc_loss = 0.03226984383840135
Trained batch 179 in epoch 7, gen_loss = 0.44004719091786276, disc_loss = 0.032110949953655814
Trained batch 180 in epoch 7, gen_loss = 0.4397526811499622, disc_loss = 0.03205326980221708
Trained batch 181 in epoch 7, gen_loss = 0.43959012578476914, disc_loss = 0.03191019797436688
Trained batch 182 in epoch 7, gen_loss = 0.44000075635362845, disc_loss = 0.031761068574666894
Trained batch 183 in epoch 7, gen_loss = 0.43974755380464636, disc_loss = 0.03165058438721842
Trained batch 184 in epoch 7, gen_loss = 0.4395480244546323, disc_loss = 0.031522248125307864
Trained batch 185 in epoch 7, gen_loss = 0.43944417484985887, disc_loss = 0.03137743257371689
Trained batch 186 in epoch 7, gen_loss = 0.4394942063061311, disc_loss = 0.03124354495965741
Trained batch 187 in epoch 7, gen_loss = 0.4394357277357832, disc_loss = 0.031111966552302004
Trained batch 188 in epoch 7, gen_loss = 0.4397232548269645, disc_loss = 0.03097978552000193
Trained batch 189 in epoch 7, gen_loss = 0.43973093534770763, disc_loss = 0.030838427823772163
Trained batch 190 in epoch 7, gen_loss = 0.439562764155303, disc_loss = 0.030720858653051613
Trained batch 191 in epoch 7, gen_loss = 0.4391416944563389, disc_loss = 0.03058433507370258
Trained batch 192 in epoch 7, gen_loss = 0.4393705500222241, disc_loss = 0.030448188304351014
Trained batch 193 in epoch 7, gen_loss = 0.4392673539132187, disc_loss = 0.03033186922920388
Trained batch 194 in epoch 7, gen_loss = 0.43970386920831145, disc_loss = 0.030268445815174627
Trained batch 195 in epoch 7, gen_loss = 0.43982613101905704, disc_loss = 0.03023545151666681
Trained batch 196 in epoch 7, gen_loss = 0.43963832101846106, disc_loss = 0.030500943100004254
Trained batch 197 in epoch 7, gen_loss = 0.4396371117444954, disc_loss = 0.03081212452768038
Trained batch 198 in epoch 7, gen_loss = 0.4395400583744049, disc_loss = 0.030997791822447475
Trained batch 199 in epoch 7, gen_loss = 0.43976652875542643, disc_loss = 0.03089418923831545
Trained batch 200 in epoch 7, gen_loss = 0.4400982312598632, disc_loss = 0.030830157016037932
Trained batch 201 in epoch 7, gen_loss = 0.4401364392868363, disc_loss = 0.030709596229763242
Trained batch 202 in epoch 7, gen_loss = 0.44035058347462436, disc_loss = 0.03073038958045172
Trained batch 203 in epoch 7, gen_loss = 0.4405311221877734, disc_loss = 0.030664222669906403
Trained batch 204 in epoch 7, gen_loss = 0.44071910017874183, disc_loss = 0.030675270870645963
Trained batch 205 in epoch 7, gen_loss = 0.44078300965642464, disc_loss = 0.030606014526322556
Trained batch 206 in epoch 7, gen_loss = 0.44069638099647374, disc_loss = 0.030524969671218507
Trained batch 207 in epoch 7, gen_loss = 0.4406435195929729, disc_loss = 0.03040621009131428
Trained batch 208 in epoch 7, gen_loss = 0.4406321589171031, disc_loss = 0.03031634833801841
Trained batch 209 in epoch 7, gen_loss = 0.44071754600320545, disc_loss = 0.030305042600126137
Trained batch 210 in epoch 7, gen_loss = 0.44058630195274173, disc_loss = 0.030293840582822383
Trained batch 211 in epoch 7, gen_loss = 0.4406300038099289, disc_loss = 0.0303082392355515
Trained batch 212 in epoch 7, gen_loss = 0.4404287508955584, disc_loss = 0.030182548410569627
Trained batch 213 in epoch 7, gen_loss = 0.44053348397540154, disc_loss = 0.030078426587708713
Trained batch 214 in epoch 7, gen_loss = 0.4405808218689852, disc_loss = 0.029989267735157248
Trained batch 215 in epoch 7, gen_loss = 0.44045741386987547, disc_loss = 0.02994784828021053
Trained batch 216 in epoch 7, gen_loss = 0.44026737114251485, disc_loss = 0.029837358053044036
Trained batch 217 in epoch 7, gen_loss = 0.44047424949090414, disc_loss = 0.029731149427430412
Trained batch 218 in epoch 7, gen_loss = 0.4403386676692527, disc_loss = 0.02960812763872314
Trained batch 219 in epoch 7, gen_loss = 0.4402332276105881, disc_loss = 0.02952879875030538
Trained batch 220 in epoch 7, gen_loss = 0.4403739167014938, disc_loss = 0.029406586136222223
Trained batch 221 in epoch 7, gen_loss = 0.4402429050690419, disc_loss = 0.029288816564666056
Trained batch 222 in epoch 7, gen_loss = 0.44045692602080616, disc_loss = 0.029172146280459024
Trained batch 223 in epoch 7, gen_loss = 0.44028948580047916, disc_loss = 0.029069714627569607
Trained batch 224 in epoch 7, gen_loss = 0.4403434921635522, disc_loss = 0.02895039283670485
Trained batch 225 in epoch 7, gen_loss = 0.44037150215786114, disc_loss = 0.028836512800091797
Trained batch 226 in epoch 7, gen_loss = 0.44056132777146834, disc_loss = 0.028726510262518858
Trained batch 227 in epoch 7, gen_loss = 0.4404932816039052, disc_loss = 0.0286114951044223
Trained batch 228 in epoch 7, gen_loss = 0.44045854278526975, disc_loss = 0.028510869999200626
Trained batch 229 in epoch 7, gen_loss = 0.4402136534452438, disc_loss = 0.028416352227087254
Trained batch 230 in epoch 7, gen_loss = 0.4404238928190041, disc_loss = 0.02839521129385798
Trained batch 231 in epoch 7, gen_loss = 0.4403813858998233, disc_loss = 0.028385791118690294
Trained batch 232 in epoch 7, gen_loss = 0.44026493770370156, disc_loss = 0.02829236672519678
Trained batch 233 in epoch 7, gen_loss = 0.4401620846782994, disc_loss = 0.02821769675391161
Trained batch 234 in epoch 7, gen_loss = 0.44010657490567956, disc_loss = 0.028113532531015735
Trained batch 235 in epoch 7, gen_loss = 0.44000122923467117, disc_loss = 0.02803112167600637
Trained batch 236 in epoch 7, gen_loss = 0.44029679592651655, disc_loss = 0.027939502433736177
Trained batch 237 in epoch 7, gen_loss = 0.440295246969752, disc_loss = 0.027861516297591395
Trained batch 238 in epoch 7, gen_loss = 0.43994423759532275, disc_loss = 0.027761351655210098
Trained batch 239 in epoch 7, gen_loss = 0.4401083715260029, disc_loss = 0.027688972685912933
Trained batch 240 in epoch 7, gen_loss = 0.44005504868831874, disc_loss = 0.027584407398384452
Trained batch 241 in epoch 7, gen_loss = 0.43989692751533727, disc_loss = 0.027512350151399998
Trained batch 242 in epoch 7, gen_loss = 0.43986924685568474, disc_loss = 0.027411849633694738
Trained batch 243 in epoch 7, gen_loss = 0.43980299009651436, disc_loss = 0.027343199280144066
Trained batch 244 in epoch 7, gen_loss = 0.43989865195994476, disc_loss = 0.027255990691673088
Trained batch 245 in epoch 7, gen_loss = 0.4401043445114198, disc_loss = 0.027185963221628796
Trained batch 246 in epoch 7, gen_loss = 0.4399644497193788, disc_loss = 0.027084521695722633
Trained batch 247 in epoch 7, gen_loss = 0.43993814686133015, disc_loss = 0.02698811966899572
Trained batch 248 in epoch 7, gen_loss = 0.43993669113959655, disc_loss = 0.026887284915793282
Trained batch 249 in epoch 7, gen_loss = 0.4398539264202118, disc_loss = 0.026792425299528987
Trained batch 250 in epoch 7, gen_loss = 0.4398986357616713, disc_loss = 0.02669446952538973
Trained batch 251 in epoch 7, gen_loss = 0.4393929068058256, disc_loss = 0.02665885723434344
Trained batch 252 in epoch 7, gen_loss = 0.43966530834733264, disc_loss = 0.026571764857802733
Trained batch 253 in epoch 7, gen_loss = 0.4398041299478276, disc_loss = 0.02649656054426322
Trained batch 254 in epoch 7, gen_loss = 0.43973052314683503, disc_loss = 0.026407637504185094
Trained batch 255 in epoch 7, gen_loss = 0.4393714645411819, disc_loss = 0.02631675067505057
Trained batch 256 in epoch 7, gen_loss = 0.4393874258382775, disc_loss = 0.026308408329998964
Trained batch 257 in epoch 7, gen_loss = 0.439421457260154, disc_loss = 0.026222829671320325
Trained batch 258 in epoch 7, gen_loss = 0.4393953789154995, disc_loss = 0.026147067658765004
Trained batch 259 in epoch 7, gen_loss = 0.43959256548147935, disc_loss = 0.026057456557800132
Trained batch 260 in epoch 7, gen_loss = 0.43942426013763836, disc_loss = 0.025965263711563328
Trained batch 261 in epoch 7, gen_loss = 0.43929370748632735, disc_loss = 0.02588394387822442
Trained batch 262 in epoch 7, gen_loss = 0.43916834137285615, disc_loss = 0.025798792386438146
Trained batch 263 in epoch 7, gen_loss = 0.4390725227016391, disc_loss = 0.025737931834142233
Trained batch 264 in epoch 7, gen_loss = 0.43919424223449993, disc_loss = 0.025667371910575006
Trained batch 265 in epoch 7, gen_loss = 0.4390762762019509, disc_loss = 0.025846529290293643
Trained batch 266 in epoch 7, gen_loss = 0.43932373135277397, disc_loss = 0.02641570346285188
Trained batch 267 in epoch 7, gen_loss = 0.4392939048694141, disc_loss = 0.026342961001088287
Trained batch 268 in epoch 7, gen_loss = 0.4394809468528152, disc_loss = 0.026535334926337476
Trained batch 269 in epoch 7, gen_loss = 0.43940266613607054, disc_loss = 0.026497599243238155
Trained batch 270 in epoch 7, gen_loss = 0.4396281939590989, disc_loss = 0.026481833400435032
Trained batch 271 in epoch 7, gen_loss = 0.43944013315965147, disc_loss = 0.026436285337053157
Trained batch 272 in epoch 7, gen_loss = 0.439030674132672, disc_loss = 0.026381190100790517
Trained batch 273 in epoch 7, gen_loss = 0.4389218722816801, disc_loss = 0.02630191363681475
Trained batch 274 in epoch 7, gen_loss = 0.43886331135576423, disc_loss = 0.026233178252269597
Trained batch 275 in epoch 7, gen_loss = 0.43890359684608987, disc_loss = 0.026152885289933613
Trained batch 276 in epoch 7, gen_loss = 0.43923933443609986, disc_loss = 0.026107795355380898
Trained batch 277 in epoch 7, gen_loss = 0.4393341426583503, disc_loss = 0.026046378257024442
Trained batch 278 in epoch 7, gen_loss = 0.4393436198379831, disc_loss = 0.02596844074868774
Trained batch 279 in epoch 7, gen_loss = 0.4395198929522719, disc_loss = 0.02588491259916087
Trained batch 280 in epoch 7, gen_loss = 0.4395189092252602, disc_loss = 0.025803156732747273
Trained batch 281 in epoch 7, gen_loss = 0.4393415753300308, disc_loss = 0.0257235943130878
Trained batch 282 in epoch 7, gen_loss = 0.43940474730077145, disc_loss = 0.025648950539486542
Trained batch 283 in epoch 7, gen_loss = 0.4392674243156339, disc_loss = 0.025579778039352442
Trained batch 284 in epoch 7, gen_loss = 0.43930717842620715, disc_loss = 0.02550649909065677
Trained batch 285 in epoch 7, gen_loss = 0.43900914375598615, disc_loss = 0.025436515365873782
Trained batch 286 in epoch 7, gen_loss = 0.4390340331124096, disc_loss = 0.025357421934977822
Trained batch 287 in epoch 7, gen_loss = 0.43878723453316426, disc_loss = 0.025275604410934547
Trained batch 288 in epoch 7, gen_loss = 0.43885883266125586, disc_loss = 0.025196776140052633
Trained batch 289 in epoch 7, gen_loss = 0.4388802145061822, disc_loss = 0.025119930979041062
Trained batch 290 in epoch 7, gen_loss = 0.4389109163964327, disc_loss = 0.02504197166491735
Trained batch 291 in epoch 7, gen_loss = 0.4388978239404012, disc_loss = 0.02496247092494741
Trained batch 292 in epoch 7, gen_loss = 0.4390556255908549, disc_loss = 0.02489071241548164
Trained batch 293 in epoch 7, gen_loss = 0.4391254990482006, disc_loss = 0.024893487234232427
Trained batch 294 in epoch 7, gen_loss = 0.43903738765393274, disc_loss = 0.02484113999042597
Trained batch 295 in epoch 7, gen_loss = 0.4389076385949109, disc_loss = 0.024792535331987497
Trained batch 296 in epoch 7, gen_loss = 0.4388486699825184, disc_loss = 0.02472300423694906
Trained batch 297 in epoch 7, gen_loss = 0.4385657701516311, disc_loss = 0.02465328525504935
Trained batch 298 in epoch 7, gen_loss = 0.4384949232224238, disc_loss = 0.02458073589623747
Trained batch 299 in epoch 7, gen_loss = 0.43834243605534234, disc_loss = 0.024511408340961983
Trained batch 300 in epoch 7, gen_loss = 0.43823133750611365, disc_loss = 0.024436589984835878
Trained batch 301 in epoch 7, gen_loss = 0.43836788635774954, disc_loss = 0.02438110584818715
Trained batch 302 in epoch 7, gen_loss = 0.4382209106050309, disc_loss = 0.024311817812090956
Trained batch 303 in epoch 7, gen_loss = 0.43841153226400675, disc_loss = 0.02424532697707611
Trained batch 304 in epoch 7, gen_loss = 0.43826131498227355, disc_loss = 0.024175148590116716
Trained batch 305 in epoch 7, gen_loss = 0.43808653492943134, disc_loss = 0.024105030762524727
Trained batch 306 in epoch 7, gen_loss = 0.43814151207476565, disc_loss = 0.024032994008893055
Trained batch 307 in epoch 7, gen_loss = 0.4382723839832591, disc_loss = 0.0239615049213171
Trained batch 308 in epoch 7, gen_loss = 0.43827084160159707, disc_loss = 0.023895337406099806
Trained batch 309 in epoch 7, gen_loss = 0.4383654832839966, disc_loss = 0.023827204572397374
Trained batch 310 in epoch 7, gen_loss = 0.4383856652250627, disc_loss = 0.02376126599650818
Trained batch 311 in epoch 7, gen_loss = 0.4386319426389841, disc_loss = 0.023697250083876915
Trained batch 312 in epoch 7, gen_loss = 0.4387485069779161, disc_loss = 0.02364659794091512
Trained batch 313 in epoch 7, gen_loss = 0.43885226490770934, disc_loss = 0.023585696145595542
Trained batch 314 in epoch 7, gen_loss = 0.43872312799332636, disc_loss = 0.023538899296037263
Trained batch 315 in epoch 7, gen_loss = 0.4386338340707972, disc_loss = 0.02347550089205792
Trained batch 316 in epoch 7, gen_loss = 0.43862333884374577, disc_loss = 0.023412325998257013
Trained batch 317 in epoch 7, gen_loss = 0.43835874454780194, disc_loss = 0.023350799921900034
Trained batch 318 in epoch 7, gen_loss = 0.4383732042155669, disc_loss = 0.023300047470461053
Trained batch 319 in epoch 7, gen_loss = 0.4382026988081634, disc_loss = 0.023264985921559855
Trained batch 320 in epoch 7, gen_loss = 0.4381271982304404, disc_loss = 0.023204141521298346
Trained batch 321 in epoch 7, gen_loss = 0.4383663650810348, disc_loss = 0.023172865041838207
Trained batch 322 in epoch 7, gen_loss = 0.43881655948080883, disc_loss = 0.023164477884112036
Trained batch 323 in epoch 7, gen_loss = 0.438835117827963, disc_loss = 0.023114065030290756
Trained batch 324 in epoch 7, gen_loss = 0.4387951646401332, disc_loss = 0.0230519868977941
Trained batch 325 in epoch 7, gen_loss = 0.43862938560956827, disc_loss = 0.022986244002465683
Trained batch 326 in epoch 7, gen_loss = 0.43855278681542165, disc_loss = 0.022921709783463553
Trained batch 327 in epoch 7, gen_loss = 0.43851763809599525, disc_loss = 0.02287139486991403
Trained batch 328 in epoch 7, gen_loss = 0.4384238908356084, disc_loss = 0.022812597565055687
Trained batch 329 in epoch 7, gen_loss = 0.4383645975228512, disc_loss = 0.022750860176430167
Trained batch 330 in epoch 7, gen_loss = 0.43848259409388746, disc_loss = 0.02268982971941045
Trained batch 331 in epoch 7, gen_loss = 0.438456275735993, disc_loss = 0.02262661650325228
Trained batch 332 in epoch 7, gen_loss = 0.4385147779374509, disc_loss = 0.022565760358178
Trained batch 333 in epoch 7, gen_loss = 0.43831760074920995, disc_loss = 0.022511828790452264
Trained batch 334 in epoch 7, gen_loss = 0.43820533939261935, disc_loss = 0.022450205547484888
Trained batch 335 in epoch 7, gen_loss = 0.43818556357707295, disc_loss = 0.022388529979729184
Trained batch 336 in epoch 7, gen_loss = 0.43818611269181135, disc_loss = 0.02232676163455333
Trained batch 337 in epoch 7, gen_loss = 0.438090117108187, disc_loss = 0.022271000629651896
Trained batch 338 in epoch 7, gen_loss = 0.4382680629031145, disc_loss = 0.022210817209549337
Trained batch 339 in epoch 7, gen_loss = 0.4382100547061247, disc_loss = 0.022149427993538078
Trained batch 340 in epoch 7, gen_loss = 0.4381442936983975, disc_loss = 0.022088267337913213
Trained batch 341 in epoch 7, gen_loss = 0.4381577954654805, disc_loss = 0.0220280833806494
Trained batch 342 in epoch 7, gen_loss = 0.43834148742714707, disc_loss = 0.021968180731851226
Trained batch 343 in epoch 7, gen_loss = 0.4382998528348845, disc_loss = 0.021909242983214384
Trained batch 344 in epoch 7, gen_loss = 0.43825401586035023, disc_loss = 0.021848700292057533
Trained batch 345 in epoch 7, gen_loss = 0.4379367129823376, disc_loss = 0.021789276791733793
Trained batch 346 in epoch 7, gen_loss = 0.4379765265956736, disc_loss = 0.0217321771636514
Trained batch 347 in epoch 7, gen_loss = 0.4380189761005599, disc_loss = 0.021673674159950907
Trained batch 348 in epoch 7, gen_loss = 0.43798848277859836, disc_loss = 0.02161693054766402
Trained batch 349 in epoch 7, gen_loss = 0.43791025034018927, disc_loss = 0.021567689324063916
Trained batch 350 in epoch 7, gen_loss = 0.4380458994129105, disc_loss = 0.02151023683587933
Trained batch 351 in epoch 7, gen_loss = 0.43786791170185263, disc_loss = 0.02145391103410723
Trained batch 352 in epoch 7, gen_loss = 0.4378664706313914, disc_loss = 0.021400654078698678
Trained batch 353 in epoch 7, gen_loss = 0.43805025543196724, disc_loss = 0.02134386888714402
Trained batch 354 in epoch 7, gen_loss = 0.4381953084972543, disc_loss = 0.02129079627338797
Trained batch 355 in epoch 7, gen_loss = 0.4383362848102377, disc_loss = 0.02123515009605378
Trained batch 356 in epoch 7, gen_loss = 0.4385450074986583, disc_loss = 0.021180991555566714
Trained batch 357 in epoch 7, gen_loss = 0.4384637711434391, disc_loss = 0.021127592250652735
Trained batch 358 in epoch 7, gen_loss = 0.43825199926131947, disc_loss = 0.02107211466311817
Trained batch 359 in epoch 7, gen_loss = 0.4382199178139369, disc_loss = 0.02101798188232351
Trained batch 360 in epoch 7, gen_loss = 0.4380779086387719, disc_loss = 0.02096649795516531
Trained batch 361 in epoch 7, gen_loss = 0.438009452589309, disc_loss = 0.02091130791894464
Trained batch 362 in epoch 7, gen_loss = 0.43812021908681253, disc_loss = 0.020859383077093865
Trained batch 363 in epoch 7, gen_loss = 0.43801463821104597, disc_loss = 0.020806441267448284
Trained batch 364 in epoch 7, gen_loss = 0.43785170316696165, disc_loss = 0.020754238008521497
Trained batch 365 in epoch 7, gen_loss = 0.43775619688581247, disc_loss = 0.02070423811540527
Trained batch 366 in epoch 7, gen_loss = 0.4377683506674598, disc_loss = 0.0206532580070629
Trained batch 367 in epoch 7, gen_loss = 0.43778069050091767, disc_loss = 0.02059969934982845
Trained batch 368 in epoch 7, gen_loss = 0.43764934686787405, disc_loss = 0.02055037680724358
Trained batch 369 in epoch 7, gen_loss = 0.437510353085157, disc_loss = 0.02049777752191231
Trained batch 370 in epoch 7, gen_loss = 0.4375402356254444, disc_loss = 0.020447177236656233
Trained batch 371 in epoch 7, gen_loss = 0.43770488712095446, disc_loss = 0.02039687163090103
Trained batch 372 in epoch 7, gen_loss = 0.4375001180907037, disc_loss = 0.020345262795794086
Trained batch 373 in epoch 7, gen_loss = 0.43755501309499384, disc_loss = 0.02029668920228935
Trained batch 374 in epoch 7, gen_loss = 0.43751392483711243, disc_loss = 0.02024776812301328
Trained batch 375 in epoch 7, gen_loss = 0.437385489648961, disc_loss = 0.020197496914485608
Trained batch 376 in epoch 7, gen_loss = 0.437332114110891, disc_loss = 0.020156043707961292
Trained batch 377 in epoch 7, gen_loss = 0.43743176308889237, disc_loss = 0.02010738809202507
Trained batch 378 in epoch 7, gen_loss = 0.43739825817400046, disc_loss = 0.020062293748906997
Trained batch 379 in epoch 7, gen_loss = 0.43729124728002045, disc_loss = 0.020014210619755383
Trained batch 380 in epoch 7, gen_loss = 0.43721669075370145, disc_loss = 0.01996527482624706
Trained batch 381 in epoch 7, gen_loss = 0.4372732480939146, disc_loss = 0.01991785550215745
Trained batch 382 in epoch 7, gen_loss = 0.437407139075954, disc_loss = 0.019869414171235583
Trained batch 383 in epoch 7, gen_loss = 0.43726211902685463, disc_loss = 0.019821157687147206
Trained batch 384 in epoch 7, gen_loss = 0.437345765395598, disc_loss = 0.019772204082435022
Trained batch 385 in epoch 7, gen_loss = 0.4372403039524592, disc_loss = 0.019723860473055972
Trained batch 386 in epoch 7, gen_loss = 0.43731397713801656, disc_loss = 0.01967691708096238
Trained batch 387 in epoch 7, gen_loss = 0.4373968862688419, disc_loss = 0.01962865922181776
Trained batch 388 in epoch 7, gen_loss = 0.43733344799755164, disc_loss = 0.01958103805907899
Trained batch 389 in epoch 7, gen_loss = 0.4372820083911602, disc_loss = 0.01953335861236645
Trained batch 390 in epoch 7, gen_loss = 0.43709491014175705, disc_loss = 0.019486242661263337
Trained batch 391 in epoch 7, gen_loss = 0.43705935685002073, disc_loss = 0.01943886348735945
Trained batch 392 in epoch 7, gen_loss = 0.4369752579972944, disc_loss = 0.019392320340168696
Trained batch 393 in epoch 7, gen_loss = 0.43686394166522824, disc_loss = 0.019347609380504758
Trained batch 394 in epoch 7, gen_loss = 0.4366340714164927, disc_loss = 0.01930140302637356
Trained batch 395 in epoch 7, gen_loss = 0.43661220620075863, disc_loss = 0.019256979612030344
Trained batch 396 in epoch 7, gen_loss = 0.4366291143581909, disc_loss = 0.019213273892119312
Trained batch 397 in epoch 7, gen_loss = 0.4364714306503085, disc_loss = 0.01917166623357688
Trained batch 398 in epoch 7, gen_loss = 0.4365997699866618, disc_loss = 0.019130277522824434
Trained batch 399 in epoch 7, gen_loss = 0.4364565446972847, disc_loss = 0.01908988059396506
Trained batch 400 in epoch 7, gen_loss = 0.4363274816563005, disc_loss = 0.01904835985021833
Trained batch 401 in epoch 7, gen_loss = 0.436292610951324, disc_loss = 0.019004709455526354
Trained batch 402 in epoch 7, gen_loss = 0.43630729604595647, disc_loss = 0.018960746566022032
Trained batch 403 in epoch 7, gen_loss = 0.4362692205917717, disc_loss = 0.01891748710995941
Trained batch 404 in epoch 7, gen_loss = 0.4363410461831976, disc_loss = 0.01887543955401023
Trained batch 405 in epoch 7, gen_loss = 0.4361639298828952, disc_loss = 0.018832342619887265
Trained batch 406 in epoch 7, gen_loss = 0.43603562766855414, disc_loss = 0.01878851743747368
Trained batch 407 in epoch 7, gen_loss = 0.43599606414928155, disc_loss = 0.018784977765736746
Trained batch 408 in epoch 7, gen_loss = 0.43578205948062515, disc_loss = 0.0187459578323474
Trained batch 409 in epoch 7, gen_loss = 0.4356889297322529, disc_loss = 0.018706798544522694
Trained batch 410 in epoch 7, gen_loss = 0.4355510973582303, disc_loss = 0.018666946806309297
Trained batch 411 in epoch 7, gen_loss = 0.43548136226181844, disc_loss = 0.0186268839719807
Trained batch 412 in epoch 7, gen_loss = 0.4355361314431807, disc_loss = 0.018585114235415846
Trained batch 413 in epoch 7, gen_loss = 0.4355424014842453, disc_loss = 0.01854385772131154
Trained batch 414 in epoch 7, gen_loss = 0.4353783745363534, disc_loss = 0.018502240609069052
Trained batch 415 in epoch 7, gen_loss = 0.43534445339957106, disc_loss = 0.01846062089498446
Trained batch 416 in epoch 7, gen_loss = 0.43516135780359627, disc_loss = 0.018419019127073666
Trained batch 417 in epoch 7, gen_loss = 0.4353219404032356, disc_loss = 0.01838011232232029
Trained batch 418 in epoch 7, gen_loss = 0.4351528937037065, disc_loss = 0.01834070784896101
Trained batch 419 in epoch 7, gen_loss = 0.43521844233785356, disc_loss = 0.018302207719673225
Trained batch 420 in epoch 7, gen_loss = 0.43527710501485084, disc_loss = 0.018263435818729457
Trained batch 421 in epoch 7, gen_loss = 0.4352999667844501, disc_loss = 0.01822373535033311
Trained batch 422 in epoch 7, gen_loss = 0.4351732140455404, disc_loss = 0.018184846595571492
Trained batch 423 in epoch 7, gen_loss = 0.4350713653103361, disc_loss = 0.018144702328394283
Trained batch 424 in epoch 7, gen_loss = 0.4350747669444365, disc_loss = 0.018104616115828427
Trained batch 425 in epoch 7, gen_loss = 0.4348734398263161, disc_loss = 0.018064581481778138
Trained batch 426 in epoch 7, gen_loss = 0.43487807710500176, disc_loss = 0.018028670429951127
Trained batch 427 in epoch 7, gen_loss = 0.4348645655908317, disc_loss = 0.017989342409228497
Trained batch 428 in epoch 7, gen_loss = 0.43495055651053405, disc_loss = 0.017951247629536954
Trained batch 429 in epoch 7, gen_loss = 0.4350369587887165, disc_loss = 0.01791403238528928
Trained batch 430 in epoch 7, gen_loss = 0.43495945518365314, disc_loss = 0.0178785580198233
Trained batch 431 in epoch 7, gen_loss = 0.43501047293345135, disc_loss = 0.01784330768296732
Trained batch 432 in epoch 7, gen_loss = 0.43492479536329626, disc_loss = 0.017804395446557052
Trained batch 433 in epoch 7, gen_loss = 0.4348712961794594, disc_loss = 0.017770576839467235
Trained batch 434 in epoch 7, gen_loss = 0.43490151694451257, disc_loss = 0.017733108778029208
Trained batch 435 in epoch 7, gen_loss = 0.43502200511070566, disc_loss = 0.01769473163158432
Trained batch 436 in epoch 7, gen_loss = 0.43505241969084574, disc_loss = 0.017656527990150293
Trained batch 437 in epoch 7, gen_loss = 0.4350389597350604, disc_loss = 0.0176184264457674
Trained batch 438 in epoch 7, gen_loss = 0.43500459465730706, disc_loss = 0.01758233978225296
Trained batch 439 in epoch 7, gen_loss = 0.4350565692917867, disc_loss = 0.017544322288780344
Trained batch 440 in epoch 7, gen_loss = 0.4349341798666653, disc_loss = 0.017508469305931466
Trained batch 441 in epoch 7, gen_loss = 0.43498606892193065, disc_loss = 0.01747181846792346
Trained batch 442 in epoch 7, gen_loss = 0.43500675002016276, disc_loss = 0.017436018256070072
Trained batch 443 in epoch 7, gen_loss = 0.4349749766894289, disc_loss = 0.017400190325822
Trained batch 444 in epoch 7, gen_loss = 0.4348694710249311, disc_loss = 0.01736409080965612
Trained batch 445 in epoch 7, gen_loss = 0.4349064508227489, disc_loss = 0.017327618971440917
Trained batch 446 in epoch 7, gen_loss = 0.4348940575282846, disc_loss = 0.017291120601056448
Trained batch 447 in epoch 7, gen_loss = 0.4348794012995703, disc_loss = 0.017254724792889777
Trained batch 448 in epoch 7, gen_loss = 0.4348002999423607, disc_loss = 0.01721880238211272
Trained batch 449 in epoch 7, gen_loss = 0.43467372092935774, disc_loss = 0.017182132989659697
Trained batch 450 in epoch 7, gen_loss = 0.43466827749148707, disc_loss = 0.017146364543220428
Trained batch 451 in epoch 7, gen_loss = 0.4346886490826058, disc_loss = 0.017110503362249625
Trained batch 452 in epoch 7, gen_loss = 0.4346614605017319, disc_loss = 0.017075224769138267
Trained batch 453 in epoch 7, gen_loss = 0.43469714087799255, disc_loss = 0.01704006686502563
Trained batch 454 in epoch 7, gen_loss = 0.434663674399093, disc_loss = 0.01700475826734104
Trained batch 455 in epoch 7, gen_loss = 0.4345254835983117, disc_loss = 0.016969733362840776
Trained batch 456 in epoch 7, gen_loss = 0.434471647183796, disc_loss = 0.016934541028596185
Trained batch 457 in epoch 7, gen_loss = 0.43457375544908267, disc_loss = 0.016899917781552275
Trained batch 458 in epoch 7, gen_loss = 0.4345057045062902, disc_loss = 0.016867228001731495
Trained batch 459 in epoch 7, gen_loss = 0.434401656816835, disc_loss = 0.016833095467376078
Trained batch 460 in epoch 7, gen_loss = 0.4343761003974203, disc_loss = 0.016798585853054555
Trained batch 461 in epoch 7, gen_loss = 0.4343179001823648, disc_loss = 0.01676592306819547
Trained batch 462 in epoch 7, gen_loss = 0.43425841574792473, disc_loss = 0.01673175071941419
Trained batch 463 in epoch 7, gen_loss = 0.43426026808547563, disc_loss = 0.016698882511389394
Trained batch 464 in epoch 7, gen_loss = 0.4342420151797674, disc_loss = 0.016665333692455084
Trained batch 465 in epoch 7, gen_loss = 0.4341013540909526, disc_loss = 0.016633384847062213
Trained batch 466 in epoch 7, gen_loss = 0.43411742230554207, disc_loss = 0.016599929261338405
Trained batch 467 in epoch 7, gen_loss = 0.4341579995985724, disc_loss = 0.016567484849295776
Trained batch 468 in epoch 7, gen_loss = 0.4341712269320417, disc_loss = 0.01653493782440856
Trained batch 469 in epoch 7, gen_loss = 0.4342780625566523, disc_loss = 0.016502999655773586
Trained batch 470 in epoch 7, gen_loss = 0.43427418915835664, disc_loss = 0.016469839931665394
Trained batch 471 in epoch 7, gen_loss = 0.4342891711552264, disc_loss = 0.01643662499567253
Trained batch 472 in epoch 7, gen_loss = 0.4341932378914089, disc_loss = 0.016403695782444716
Trained batch 473 in epoch 7, gen_loss = 0.4341338229078784, disc_loss = 0.01637088544290996
Trained batch 474 in epoch 7, gen_loss = 0.43410978298438224, disc_loss = 0.01633852987145809
Trained batch 475 in epoch 7, gen_loss = 0.434178107551166, disc_loss = 0.016307687002284053
Trained batch 476 in epoch 7, gen_loss = 0.43412864226965037, disc_loss = 0.016275708812686265
Trained batch 477 in epoch 7, gen_loss = 0.4341698284553185, disc_loss = 0.016244124014599827
Trained batch 478 in epoch 7, gen_loss = 0.434024708069441, disc_loss = 0.01621264289266922
Trained batch 479 in epoch 7, gen_loss = 0.433906011407574, disc_loss = 0.016181098178518975
Trained batch 480 in epoch 7, gen_loss = 0.43384392940576755, disc_loss = 0.01614994670711206
Trained batch 481 in epoch 7, gen_loss = 0.43388514721541976, disc_loss = 0.016118461662503462
Trained batch 482 in epoch 7, gen_loss = 0.433792628795217, disc_loss = 0.016086906345086808
Trained batch 483 in epoch 7, gen_loss = 0.43378467999460285, disc_loss = 0.016055642625014875
Trained batch 484 in epoch 7, gen_loss = 0.4337514478521249, disc_loss = 0.01602434817456746
Trained batch 485 in epoch 7, gen_loss = 0.4338277134998345, disc_loss = 0.015993981883016036
Trained batch 486 in epoch 7, gen_loss = 0.4338450705980618, disc_loss = 0.01596356866029292
Trained batch 487 in epoch 7, gen_loss = 0.4338731415814064, disc_loss = 0.015932758322289044
Trained batch 488 in epoch 7, gen_loss = 0.4339297284012192, disc_loss = 0.015904422018320846
Trained batch 489 in epoch 7, gen_loss = 0.43395274232844916, disc_loss = 0.015875283015264693
Trained batch 490 in epoch 7, gen_loss = 0.4338321300363832, disc_loss = 0.01584669643569199
Trained batch 491 in epoch 7, gen_loss = 0.4337492874725078, disc_loss = 0.015817180824630735
Trained batch 492 in epoch 7, gen_loss = 0.4338627715139795, disc_loss = 0.01578804344514056
Trained batch 493 in epoch 7, gen_loss = 0.4338388294584838, disc_loss = 0.01575857226978158
Trained batch 494 in epoch 7, gen_loss = 0.4339201831456387, disc_loss = 0.015729002356105908
Trained batch 495 in epoch 7, gen_loss = 0.43381488617629776, disc_loss = 0.01569926660322967
Trained batch 496 in epoch 7, gen_loss = 0.43382406912339283, disc_loss = 0.015669216150656844
Trained batch 497 in epoch 7, gen_loss = 0.43382667070890524, disc_loss = 0.01564014600844676
Trained batch 498 in epoch 7, gen_loss = 0.4337841079445306, disc_loss = 0.015612944020056361
Trained batch 499 in epoch 7, gen_loss = 0.43385499697923663, disc_loss = 0.015585150085040368
Trained batch 500 in epoch 7, gen_loss = 0.43375460021272155, disc_loss = 0.015557067358737138
Trained batch 501 in epoch 7, gen_loss = 0.4337632656097412, disc_loss = 0.015532768543543428
Trained batch 502 in epoch 7, gen_loss = 0.433861050110451, disc_loss = 0.015504341486542417
Trained batch 503 in epoch 7, gen_loss = 0.43377031338593314, disc_loss = 0.015476079750875388
Trained batch 504 in epoch 7, gen_loss = 0.433803121878369, disc_loss = 0.015447250046619758
Trained batch 505 in epoch 7, gen_loss = 0.43381053497904376, disc_loss = 0.015419200663924174
Trained batch 506 in epoch 7, gen_loss = 0.4339218056178422, disc_loss = 0.01539067352462479
Trained batch 507 in epoch 7, gen_loss = 0.4339044287683457, disc_loss = 0.015363744414671816
Trained batch 508 in epoch 7, gen_loss = 0.4337455352186454, disc_loss = 0.015335129629061256
Trained batch 509 in epoch 7, gen_loss = 0.43374563432207297, disc_loss = 0.01530663300061361
Trained batch 510 in epoch 7, gen_loss = 0.43376942454252226, disc_loss = 0.015278861407439339
Trained batch 511 in epoch 7, gen_loss = 0.43369901552796364, disc_loss = 0.01525068230080251
Trained batch 512 in epoch 7, gen_loss = 0.43375531960184344, disc_loss = 0.015223879482847645
Trained batch 513 in epoch 7, gen_loss = 0.4337345700319639, disc_loss = 0.015196914138890266
Trained batch 514 in epoch 7, gen_loss = 0.4337145563468192, disc_loss = 0.0151698990408512
Trained batch 515 in epoch 7, gen_loss = 0.4336448425008345, disc_loss = 0.01514267254879792
Trained batch 516 in epoch 7, gen_loss = 0.43346624488526203, disc_loss = 0.015115738797273551
Trained batch 517 in epoch 7, gen_loss = 0.43360346089688967, disc_loss = 0.015089220038802151
Trained batch 518 in epoch 7, gen_loss = 0.433544419289554, disc_loss = 0.015062462265723473
Trained batch 519 in epoch 7, gen_loss = 0.433557867201475, disc_loss = 0.015035486350265833
Trained batch 520 in epoch 7, gen_loss = 0.43362906272031526, disc_loss = 0.01500914283114666
Trained batch 521 in epoch 7, gen_loss = 0.43364760867708946, disc_loss = 0.01498209709864488
Trained batch 522 in epoch 7, gen_loss = 0.43366285087273637, disc_loss = 0.01495517052449179
Trained batch 523 in epoch 7, gen_loss = 0.4337126223640588, disc_loss = 0.014930462723958683
Trained batch 524 in epoch 7, gen_loss = 0.4336498639129457, disc_loss = 0.014904296140053442
Trained batch 525 in epoch 7, gen_loss = 0.43370550394964763, disc_loss = 0.014879380233945262
Trained batch 526 in epoch 7, gen_loss = 0.43373895929931916, disc_loss = 0.014852923615234754
Trained batch 527 in epoch 7, gen_loss = 0.4337832039278565, disc_loss = 0.014827014220028297
Trained batch 528 in epoch 7, gen_loss = 0.4338142936080976, disc_loss = 0.014800560135140818
Trained batch 529 in epoch 7, gen_loss = 0.43396874160136817, disc_loss = 0.014775393491189153
Trained batch 530 in epoch 7, gen_loss = 0.4340629211702365, disc_loss = 0.014750656076810427
Trained batch 531 in epoch 7, gen_loss = 0.4341655012248154, disc_loss = 0.014726296583010248
Trained batch 532 in epoch 7, gen_loss = 0.4340673241673446, disc_loss = 0.014701331604148068
Trained batch 533 in epoch 7, gen_loss = 0.43396982918964344, disc_loss = 0.01467632362008625
Trained batch 534 in epoch 7, gen_loss = 0.433877926730664, disc_loss = 0.01465088507230176
Trained batch 535 in epoch 7, gen_loss = 0.43390188327253754, disc_loss = 0.014625478018971799
Trained batch 536 in epoch 7, gen_loss = 0.4339081280391309, disc_loss = 0.014601383786397037
Trained batch 537 in epoch 7, gen_loss = 0.4338865887830692, disc_loss = 0.014575786798583087
Trained batch 538 in epoch 7, gen_loss = 0.43389148692253127, disc_loss = 0.01455035439015544
Trained batch 539 in epoch 7, gen_loss = 0.4338818872416461, disc_loss = 0.014525503213021524
Trained batch 540 in epoch 7, gen_loss = 0.4338754077825881, disc_loss = 0.014500073717593761
Trained batch 541 in epoch 7, gen_loss = 0.4337757316132753, disc_loss = 0.014475031040726586
Trained batch 542 in epoch 7, gen_loss = 0.4338923778872025, disc_loss = 0.014452605826105292
Trained batch 543 in epoch 7, gen_loss = 0.4340144980370122, disc_loss = 0.01443197829180195
Trained batch 544 in epoch 7, gen_loss = 0.43398228610327483, disc_loss = 0.01441132268033187
Trained batch 545 in epoch 7, gen_loss = 0.43390368700245796, disc_loss = 0.014389338603029165
Trained batch 546 in epoch 7, gen_loss = 0.4338928702980334, disc_loss = 0.014364983632473592
Trained batch 547 in epoch 7, gen_loss = 0.4339081414968428, disc_loss = 0.014340470199890428
Trained batch 548 in epoch 7, gen_loss = 0.43392738580486595, disc_loss = 0.01431665088053036
Trained batch 549 in epoch 7, gen_loss = 0.43373265418139373, disc_loss = 0.014295365294251083
Trained batch 550 in epoch 7, gen_loss = 0.43372567271147794, disc_loss = 0.014272608308222131
Trained batch 551 in epoch 7, gen_loss = 0.433641769963762, disc_loss = 0.014248100272105648
Trained batch 552 in epoch 7, gen_loss = 0.4336801761421114, disc_loss = 0.014223861260294146
Trained batch 553 in epoch 7, gen_loss = 0.4336525844645414, disc_loss = 0.014199583740133309
Trained batch 554 in epoch 7, gen_loss = 0.43349981420748945, disc_loss = 0.014176202777286505
Trained batch 555 in epoch 7, gen_loss = 0.4335605273251053, disc_loss = 0.014152852536544283
Trained batch 556 in epoch 7, gen_loss = 0.43350738645455994, disc_loss = 0.014128982991521887
Trained batch 557 in epoch 7, gen_loss = 0.4333630303007727, disc_loss = 0.014105080184505878
Trained batch 558 in epoch 7, gen_loss = 0.4333385279758672, disc_loss = 0.014081349051582473
Trained batch 559 in epoch 7, gen_loss = 0.43336038781063896, disc_loss = 0.014057516399147322
Trained batch 560 in epoch 7, gen_loss = 0.4334122381320824, disc_loss = 0.01403413830555763
Trained batch 561 in epoch 7, gen_loss = 0.4333449329557792, disc_loss = 0.01401075842836706
Trained batch 562 in epoch 7, gen_loss = 0.4333100360197877, disc_loss = 0.013988364227347698
Trained batch 563 in epoch 7, gen_loss = 0.43337063285264565, disc_loss = 0.013964769468438012
Trained batch 564 in epoch 7, gen_loss = 0.4334030464159704, disc_loss = 0.013941537993506784
Trained batch 565 in epoch 7, gen_loss = 0.43328750781162045, disc_loss = 0.013918849586734594
Trained batch 566 in epoch 7, gen_loss = 0.4331987507549333, disc_loss = 0.013895968748486521
Trained batch 567 in epoch 7, gen_loss = 0.43325228396225984, disc_loss = 0.013873427188102628
Trained batch 568 in epoch 7, gen_loss = 0.4332588801589289, disc_loss = 0.013850890802381551
Trained batch 569 in epoch 7, gen_loss = 0.4333164247504452, disc_loss = 0.013828156892569703
Trained batch 570 in epoch 7, gen_loss = 0.4333645536999778, disc_loss = 0.013806005666642442
Trained batch 571 in epoch 7, gen_loss = 0.43345515028788495, disc_loss = 0.01378418601885718
Trained batch 572 in epoch 7, gen_loss = 0.43341571992396477, disc_loss = 0.013762015546225076
Trained batch 573 in epoch 7, gen_loss = 0.43341886254760864, disc_loss = 0.013739501774710203
Trained batch 574 in epoch 7, gen_loss = 0.4333527273198833, disc_loss = 0.013716982222648095
Trained batch 575 in epoch 7, gen_loss = 0.4333106507029798, disc_loss = 0.013694430761259153
Trained batch 576 in epoch 7, gen_loss = 0.43325705152243843, disc_loss = 0.013671917549194848
Trained batch 577 in epoch 7, gen_loss = 0.43339624402844784, disc_loss = 0.01365140569547375
Trained batch 578 in epoch 7, gen_loss = 0.4334695220817144, disc_loss = 0.01362985198051043
Trained batch 579 in epoch 7, gen_loss = 0.4334117478337781, disc_loss = 0.013608437349742824
Trained batch 580 in epoch 7, gen_loss = 0.43336607785110015, disc_loss = 0.013586380415281086
Trained batch 581 in epoch 7, gen_loss = 0.43339863757497255, disc_loss = 0.013564748678430818
Trained batch 582 in epoch 7, gen_loss = 0.433418528906886, disc_loss = 0.013542531592045362
Trained batch 583 in epoch 7, gen_loss = 0.43342997776727155, disc_loss = 0.01352118401162642
Trained batch 584 in epoch 7, gen_loss = 0.4335096321044824, disc_loss = 0.013502421768473731
Trained batch 585 in epoch 7, gen_loss = 0.4335934564522102, disc_loss = 0.013481779308984082
Trained batch 586 in epoch 7, gen_loss = 0.43358879672201567, disc_loss = 0.01346013461903223
Trained batch 587 in epoch 7, gen_loss = 0.4336517192676765, disc_loss = 0.013440852926677365
Trained batch 588 in epoch 7, gen_loss = 0.4336279102416111, disc_loss = 0.013419992522576094
Trained batch 589 in epoch 7, gen_loss = 0.43368722649954133, disc_loss = 0.013399945684191691
Trained batch 590 in epoch 7, gen_loss = 0.4336244539056736, disc_loss = 0.013379184624425241
Trained batch 591 in epoch 7, gen_loss = 0.4337006513834805, disc_loss = 0.013358315368866504
Trained batch 592 in epoch 7, gen_loss = 0.43360353159462217, disc_loss = 0.013336890972039583
Trained batch 593 in epoch 7, gen_loss = 0.43357406927881015, disc_loss = 0.013315749899989859
Trained batch 594 in epoch 7, gen_loss = 0.4335221327152573, disc_loss = 0.013295179980067427
Trained batch 595 in epoch 7, gen_loss = 0.43360992156019146, disc_loss = 0.013275090017181745
Trained batch 596 in epoch 7, gen_loss = 0.4337698420887217, disc_loss = 0.013256474623204657
Trained batch 597 in epoch 7, gen_loss = 0.43376887417756593, disc_loss = 0.013236735402049659
Trained batch 598 in epoch 7, gen_loss = 0.43372210422421936, disc_loss = 0.013218258367715332
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.3975670635700226, disc_loss = 0.00268352497369051
Trained batch 1 in epoch 8, gen_loss = 0.4162634462118149, disc_loss = 0.0017889334703795612
Trained batch 2 in epoch 8, gen_loss = 0.3958933651447296, disc_loss = 0.0015513092512264848
Trained batch 3 in epoch 8, gen_loss = 0.39431295543909073, disc_loss = 0.0013621386751765385
Trained batch 4 in epoch 8, gen_loss = 0.41676111817359923, disc_loss = 0.0013102423516102135
Trained batch 5 in epoch 8, gen_loss = 0.4085599134365718, disc_loss = 0.0012603572007113446
Trained batch 6 in epoch 8, gen_loss = 0.40574709858213154, disc_loss = 0.0011831001029349864
Trained batch 7 in epoch 8, gen_loss = 0.4080892503261566, disc_loss = 0.0011547856047400273
Trained batch 8 in epoch 8, gen_loss = 0.4105124208662245, disc_loss = 0.0010968083580438462
Trained batch 9 in epoch 8, gen_loss = 0.41120203137397765, disc_loss = 0.0010476584604475648
Trained batch 10 in epoch 8, gen_loss = 0.41392388939857483, disc_loss = 0.001024897300257263
Trained batch 11 in epoch 8, gen_loss = 0.40760904798905057, disc_loss = 0.0010154524449414264
Trained batch 12 in epoch 8, gen_loss = 0.4137508410673875, disc_loss = 0.0010376246019194906
Trained batch 13 in epoch 8, gen_loss = 0.41230501021657673, disc_loss = 0.0010167408867606095
Trained batch 14 in epoch 8, gen_loss = 0.4168819606304169, disc_loss = 0.0010077448522982499
Trained batch 15 in epoch 8, gen_loss = 0.4208694938570261, disc_loss = 0.0010347869210818317
Trained batch 16 in epoch 8, gen_loss = 0.4252540048430948, disc_loss = 0.0010190063313690618
Trained batch 17 in epoch 8, gen_loss = 0.42840492228666943, disc_loss = 0.001006407692329958
Trained batch 18 in epoch 8, gen_loss = 0.42963103087324844, disc_loss = 0.0010014061331994047
Trained batch 19 in epoch 8, gen_loss = 0.42880978137254716, disc_loss = 0.0009881284990115092
Trained batch 20 in epoch 8, gen_loss = 0.43035621302468435, disc_loss = 0.0009848813531875965
Trained batch 21 in epoch 8, gen_loss = 0.4321414530277252, disc_loss = 0.0009837146948980676
Trained batch 22 in epoch 8, gen_loss = 0.43173993540846783, disc_loss = 0.0009916020916653392
Trained batch 23 in epoch 8, gen_loss = 0.43324099108576775, disc_loss = 0.0009959266099031083
Trained batch 24 in epoch 8, gen_loss = 0.4342804753780365, disc_loss = 0.0009896167810074985
Trained batch 25 in epoch 8, gen_loss = 0.43168079967682177, disc_loss = 0.0009968267740287746
Trained batch 26 in epoch 8, gen_loss = 0.4306753498536569, disc_loss = 0.001007415106330343
Trained batch 27 in epoch 8, gen_loss = 0.43385760486125946, disc_loss = 0.001040807702728281
Trained batch 28 in epoch 8, gen_loss = 0.4348096611170933, disc_loss = 0.001039713041070078
Trained batch 29 in epoch 8, gen_loss = 0.4345302830139796, disc_loss = 0.0010288858068330834
Trained batch 30 in epoch 8, gen_loss = 0.4360865152651264, disc_loss = 0.0010272631996251162
Trained batch 31 in epoch 8, gen_loss = 0.4352218145504594, disc_loss = 0.0010159298981307074
Trained batch 32 in epoch 8, gen_loss = 0.4346657702417085, disc_loss = 0.001009064765336613
Trained batch 33 in epoch 8, gen_loss = 0.4336940304321401, disc_loss = 0.0010028627053971456
Trained batch 34 in epoch 8, gen_loss = 0.43244380695479256, disc_loss = 0.0009933036868460476
Trained batch 35 in epoch 8, gen_loss = 0.433223645720217, disc_loss = 0.0009975675315622033
Trained batch 36 in epoch 8, gen_loss = 0.43159956948177236, disc_loss = 0.0010004755427330933
Trained batch 37 in epoch 8, gen_loss = 0.4333519394460477, disc_loss = 0.0010063390195443247
Trained batch 38 in epoch 8, gen_loss = 0.43402481919679886, disc_loss = 0.0010032883669154192
Trained batch 39 in epoch 8, gen_loss = 0.4336858317255974, disc_loss = 0.0009993507017497904
Trained batch 40 in epoch 8, gen_loss = 0.43300819396972656, disc_loss = 0.0009919659464574624
Trained batch 41 in epoch 8, gen_loss = 0.4332958303746723, disc_loss = 0.0010040697511396416
Trained batch 42 in epoch 8, gen_loss = 0.4349188125410745, disc_loss = 0.0010122021370524063
Trained batch 43 in epoch 8, gen_loss = 0.43477190827781503, disc_loss = 0.0010102344901745462
Trained batch 44 in epoch 8, gen_loss = 0.43456759320365057, disc_loss = 0.0010036943312216964
Trained batch 45 in epoch 8, gen_loss = 0.4332948346500811, disc_loss = 0.0010081818643653685
Trained batch 46 in epoch 8, gen_loss = 0.4332980684777524, disc_loss = 0.0010182361348849186
Trained batch 47 in epoch 8, gen_loss = 0.4327730716516574, disc_loss = 0.0010246807081178606
Trained batch 48 in epoch 8, gen_loss = 0.4333553563575355, disc_loss = 0.00102406499161366
Trained batch 49 in epoch 8, gen_loss = 0.43227382242679596, disc_loss = 0.0010181799333076923
Trained batch 50 in epoch 8, gen_loss = 0.43271970807337296, disc_loss = 0.0010156230784167408
Trained batch 51 in epoch 8, gen_loss = 0.4321690740493628, disc_loss = 0.0010125755428676852
Trained batch 52 in epoch 8, gen_loss = 0.4322276289732951, disc_loss = 0.001006925945337159
Trained batch 53 in epoch 8, gen_loss = 0.4326031450872068, disc_loss = 0.0010100413939518923
Trained batch 54 in epoch 8, gen_loss = 0.4322614388032393, disc_loss = 0.0010055340741845695
Trained batch 55 in epoch 8, gen_loss = 0.4321094692817756, disc_loss = 0.0010062602689556246
Trained batch 56 in epoch 8, gen_loss = 0.43055858894398336, disc_loss = 0.0010041948979753151
Trained batch 57 in epoch 8, gen_loss = 0.4295542085992879, disc_loss = 0.0010079984083482675
Trained batch 58 in epoch 8, gen_loss = 0.42979688513076914, disc_loss = 0.00101498838995536
Trained batch 59 in epoch 8, gen_loss = 0.430270616710186, disc_loss = 0.0010143836261704564
Trained batch 60 in epoch 8, gen_loss = 0.430055315865845, disc_loss = 0.0010142379657930283
Trained batch 61 in epoch 8, gen_loss = 0.42851685516295895, disc_loss = 0.0010120087676876856
Trained batch 62 in epoch 8, gen_loss = 0.42953906456629437, disc_loss = 0.0010122887167473517
Trained batch 63 in epoch 8, gen_loss = 0.42853462463244796, disc_loss = 0.0010150877706109895
Trained batch 64 in epoch 8, gen_loss = 0.42891433926729056, disc_loss = 0.001012227244567699
Trained batch 65 in epoch 8, gen_loss = 0.4297329368013324, disc_loss = 0.001013571672515492
Trained batch 66 in epoch 8, gen_loss = 0.4288134388069608, disc_loss = 0.001008057696640547
Trained batch 67 in epoch 8, gen_loss = 0.4285118334433612, disc_loss = 0.0010045458492480546
Trained batch 68 in epoch 8, gen_loss = 0.42805246598478675, disc_loss = 0.0009977628816040638
Trained batch 69 in epoch 8, gen_loss = 0.42760813576834544, disc_loss = 0.0009938807384709694
Trained batch 70 in epoch 8, gen_loss = 0.4281642944879935, disc_loss = 0.0009962643167122044
Trained batch 71 in epoch 8, gen_loss = 0.42834992085893947, disc_loss = 0.0009957842072860028
Trained batch 72 in epoch 8, gen_loss = 0.4276277716845682, disc_loss = 0.000992872013889049
Trained batch 73 in epoch 8, gen_loss = 0.42763296736253276, disc_loss = 0.0009964950291465062
Trained batch 74 in epoch 8, gen_loss = 0.42741008281707765, disc_loss = 0.000990467903514703
Trained batch 75 in epoch 8, gen_loss = 0.4273828997423774, disc_loss = 0.0009891311247453192
Trained batch 76 in epoch 8, gen_loss = 0.42752700618335177, disc_loss = 0.0009841770047092108
Trained batch 77 in epoch 8, gen_loss = 0.42737182363485676, disc_loss = 0.0009827682567843928
Trained batch 78 in epoch 8, gen_loss = 0.42729854810086987, disc_loss = 0.0009787777693694621
Trained batch 79 in epoch 8, gen_loss = 0.42742447964847086, disc_loss = 0.0009764904469193425
Trained batch 80 in epoch 8, gen_loss = 0.42718434738524164, disc_loss = 0.0009759074647588955
Trained batch 81 in epoch 8, gen_loss = 0.42696633753253194, disc_loss = 0.0009711331655214564
Trained batch 82 in epoch 8, gen_loss = 0.42688183863478973, disc_loss = 0.0009678229949078018
Trained batch 83 in epoch 8, gen_loss = 0.4271001872562227, disc_loss = 0.0009652125514722208
Trained batch 84 in epoch 8, gen_loss = 0.42682230647872477, disc_loss = 0.0009617075556889176
Trained batch 85 in epoch 8, gen_loss = 0.4261857295452162, disc_loss = 0.000958767655944495
Trained batch 86 in epoch 8, gen_loss = 0.4263295980020501, disc_loss = 0.0009608292435670549
Trained batch 87 in epoch 8, gen_loss = 0.4259948158128695, disc_loss = 0.0009589102344100618
Trained batch 88 in epoch 8, gen_loss = 0.42642556683401045, disc_loss = 0.0009621010486329539
Trained batch 89 in epoch 8, gen_loss = 0.42586089935567645, disc_loss = 0.0009651566312337915
Trained batch 90 in epoch 8, gen_loss = 0.425790256523824, disc_loss = 0.0009600841376295947
Trained batch 91 in epoch 8, gen_loss = 0.42564719656239386, disc_loss = 0.0009619735748223636
Trained batch 92 in epoch 8, gen_loss = 0.4257283691437014, disc_loss = 0.0009590706747946559
Trained batch 93 in epoch 8, gen_loss = 0.42562352406217696, disc_loss = 0.0009546331284775775
Trained batch 94 in epoch 8, gen_loss = 0.4257803565577457, disc_loss = 0.0009514808654785157
Trained batch 95 in epoch 8, gen_loss = 0.4261160617073377, disc_loss = 0.0009501422428002115
Trained batch 96 in epoch 8, gen_loss = 0.42637984193477435, disc_loss = 0.0009476562533479606
Trained batch 97 in epoch 8, gen_loss = 0.4264814595178682, disc_loss = 0.000947103953245571
Trained batch 98 in epoch 8, gen_loss = 0.42659379466615543, disc_loss = 0.0009462212499306359
Trained batch 99 in epoch 8, gen_loss = 0.42672065645456314, disc_loss = 0.0009552282514050603
Trained batch 100 in epoch 8, gen_loss = 0.4262221334594311, disc_loss = 0.0009535518463350611
Trained batch 101 in epoch 8, gen_loss = 0.4261932726584229, disc_loss = 0.0009532711187870625
Trained batch 102 in epoch 8, gen_loss = 0.42606106545161276, disc_loss = 0.0009529155439434989
Trained batch 103 in epoch 8, gen_loss = 0.4255078781682711, disc_loss = 0.0009529221883545128
Trained batch 104 in epoch 8, gen_loss = 0.42612830400466917, disc_loss = 0.0009518738880398728
Trained batch 105 in epoch 8, gen_loss = 0.4264938713244672, disc_loss = 0.0009532114545779548
Trained batch 106 in epoch 8, gen_loss = 0.42633423376306195, disc_loss = 0.0009517345629702105
Trained batch 107 in epoch 8, gen_loss = 0.4263579820593198, disc_loss = 0.0009515577737517931
Trained batch 108 in epoch 8, gen_loss = 0.42695082190933575, disc_loss = 0.0009511675046961925
Trained batch 109 in epoch 8, gen_loss = 0.4265744856812737, disc_loss = 0.0009491559932939709
Trained batch 110 in epoch 8, gen_loss = 0.4267057073008907, disc_loss = 0.0009596744344594914
Trained batch 111 in epoch 8, gen_loss = 0.4264483486435243, disc_loss = 0.0009582106525028523
Trained batch 112 in epoch 8, gen_loss = 0.4267013460661458, disc_loss = 0.0009611696746628897
Trained batch 113 in epoch 8, gen_loss = 0.4264730541852483, disc_loss = 0.0009590808247019978
Trained batch 114 in epoch 8, gen_loss = 0.4264359647813051, disc_loss = 0.000958899597880309
Trained batch 115 in epoch 8, gen_loss = 0.42694171158404187, disc_loss = 0.0009606482625682035
Trained batch 116 in epoch 8, gen_loss = 0.42686564978371316, disc_loss = 0.0009585482836501976
Trained batch 117 in epoch 8, gen_loss = 0.4267717029078532, disc_loss = 0.0009569584015141226
Trained batch 118 in epoch 8, gen_loss = 0.42712488820572864, disc_loss = 0.0009544579881564283
Trained batch 119 in epoch 8, gen_loss = 0.42744188209374745, disc_loss = 0.0009536594778182916
Trained batch 120 in epoch 8, gen_loss = 0.4274296942821219, disc_loss = 0.0009508589604938757
Trained batch 121 in epoch 8, gen_loss = 0.4273659098343771, disc_loss = 0.000949594506146539
Trained batch 122 in epoch 8, gen_loss = 0.4268636163172683, disc_loss = 0.0009487312659999825
Trained batch 123 in epoch 8, gen_loss = 0.4263842800451863, disc_loss = 0.0009468194170509496
Trained batch 124 in epoch 8, gen_loss = 0.42617081236839294, disc_loss = 0.0009437084784731269
Trained batch 125 in epoch 8, gen_loss = 0.4260206302953145, disc_loss = 0.0009404421776592259
Trained batch 126 in epoch 8, gen_loss = 0.4257847127013319, disc_loss = 0.0009378879230220135
Trained batch 127 in epoch 8, gen_loss = 0.4256030030082911, disc_loss = 0.0009345131456939271
Trained batch 128 in epoch 8, gen_loss = 0.425436292276826, disc_loss = 0.0009376988313052544
Trained batch 129 in epoch 8, gen_loss = 0.4260258672329096, disc_loss = 0.0009400462839179314
Trained batch 130 in epoch 8, gen_loss = 0.4254933488732986, disc_loss = 0.0009385426182171885
Trained batch 131 in epoch 8, gen_loss = 0.4253006243344509, disc_loss = 0.0009393791075457226
Trained batch 132 in epoch 8, gen_loss = 0.4254901261257946, disc_loss = 0.0009392938826975406
Trained batch 133 in epoch 8, gen_loss = 0.4253121111819993, disc_loss = 0.0009367629032540343
Trained batch 134 in epoch 8, gen_loss = 0.42524546208205044, disc_loss = 0.0009372073010093084
Trained batch 135 in epoch 8, gen_loss = 0.425344078856356, disc_loss = 0.0009358365239356371
Trained batch 136 in epoch 8, gen_loss = 0.4259350987246437, disc_loss = 0.0009367827778124679
Trained batch 137 in epoch 8, gen_loss = 0.4260344272074492, disc_loss = 0.0009385184283651736
Trained batch 138 in epoch 8, gen_loss = 0.4264111128642405, disc_loss = 0.0009449682191764708
Trained batch 139 in epoch 8, gen_loss = 0.42641712469714027, disc_loss = 0.0009421495072144483
Trained batch 140 in epoch 8, gen_loss = 0.4265516869565274, disc_loss = 0.000942632284325858
Trained batch 141 in epoch 8, gen_loss = 0.42718471691642007, disc_loss = 0.0009434321873926256
Trained batch 142 in epoch 8, gen_loss = 0.42675364871958754, disc_loss = 0.0009430779992452972
Trained batch 143 in epoch 8, gen_loss = 0.42641460129784214, disc_loss = 0.0009422712690947163
Trained batch 144 in epoch 8, gen_loss = 0.4265170216560364, disc_loss = 0.0009409302636852552
Trained batch 145 in epoch 8, gen_loss = 0.42644323224890723, disc_loss = 0.0009411167762440004
Trained batch 146 in epoch 8, gen_loss = 0.4262118453071231, disc_loss = 0.0009412653094829143
Trained batch 147 in epoch 8, gen_loss = 0.4260348790400737, disc_loss = 0.0009407698856414976
Trained batch 148 in epoch 8, gen_loss = 0.4263782867249226, disc_loss = 0.0009400596312440982
Trained batch 149 in epoch 8, gen_loss = 0.42632765968640646, disc_loss = 0.0009384032575568805
Trained batch 150 in epoch 8, gen_loss = 0.42625064664329126, disc_loss = 0.0009365211925561855
Trained batch 151 in epoch 8, gen_loss = 0.42631866233913523, disc_loss = 0.000934787481367637
Trained batch 152 in epoch 8, gen_loss = 0.4263255159839306, disc_loss = 0.0009329545256846092
Trained batch 153 in epoch 8, gen_loss = 0.4257538535378196, disc_loss = 0.0009327909433700192
Trained batch 154 in epoch 8, gen_loss = 0.4261605860725526, disc_loss = 0.0009333673064717122
Trained batch 155 in epoch 8, gen_loss = 0.4259929458300273, disc_loss = 0.0009319696408242751
Trained batch 156 in epoch 8, gen_loss = 0.4261499147885924, disc_loss = 0.0009315464572215773
Trained batch 157 in epoch 8, gen_loss = 0.426458971409858, disc_loss = 0.0009307922788783672
Trained batch 158 in epoch 8, gen_loss = 0.4265950993172028, disc_loss = 0.0009300334861578198
Trained batch 159 in epoch 8, gen_loss = 0.42652765549719335, disc_loss = 0.0009277702720282832
Trained batch 160 in epoch 8, gen_loss = 0.4259725424073498, disc_loss = 0.0009272654550959883
Trained batch 161 in epoch 8, gen_loss = 0.4258757787354199, disc_loss = 0.0009249444313657781
Trained batch 162 in epoch 8, gen_loss = 0.4258972468551683, disc_loss = 0.0009256768478880539
Trained batch 163 in epoch 8, gen_loss = 0.426273854403961, disc_loss = 0.0009266559777088555
Trained batch 164 in epoch 8, gen_loss = 0.42668551622015055, disc_loss = 0.0009255094065641363
Trained batch 165 in epoch 8, gen_loss = 0.42636488808924894, disc_loss = 0.0009227350115052324
Trained batch 166 in epoch 8, gen_loss = 0.42672320575771217, disc_loss = 0.0009220763058039154
Trained batch 167 in epoch 8, gen_loss = 0.4264691087106864, disc_loss = 0.0009203384186202172
Trained batch 168 in epoch 8, gen_loss = 0.4264949554875052, disc_loss = 0.0009176981457668913
Trained batch 169 in epoch 8, gen_loss = 0.42645055143272176, disc_loss = 0.0009158038784174578
Trained batch 170 in epoch 8, gen_loss = 0.4265530952933239, disc_loss = 0.0009150370476870901
Trained batch 171 in epoch 8, gen_loss = 0.42609524397655973, disc_loss = 0.0009158256759482631
Trained batch 172 in epoch 8, gen_loss = 0.4262861893700726, disc_loss = 0.0009159676127022703
Trained batch 173 in epoch 8, gen_loss = 0.42616822424976303, disc_loss = 0.0009161354923733221
Trained batch 174 in epoch 8, gen_loss = 0.42624856420925683, disc_loss = 0.0009161407693422266
Trained batch 175 in epoch 8, gen_loss = 0.42633265324614267, disc_loss = 0.0009140971295974767
Trained batch 176 in epoch 8, gen_loss = 0.42592840814321054, disc_loss = 0.000915489737325911
Trained batch 177 in epoch 8, gen_loss = 0.425857205739182, disc_loss = 0.0009162497240395986
Trained batch 178 in epoch 8, gen_loss = 0.4259878748289034, disc_loss = 0.0009173404554805234
Trained batch 179 in epoch 8, gen_loss = 0.42634005662467744, disc_loss = 0.0009206582142117744
Trained batch 180 in epoch 8, gen_loss = 0.4264925752884775, disc_loss = 0.0009216151681975641
Trained batch 181 in epoch 8, gen_loss = 0.42643135949805544, disc_loss = 0.0009198186923570645
Trained batch 182 in epoch 8, gen_loss = 0.4263463124551408, disc_loss = 0.0009184485613724695
Trained batch 183 in epoch 8, gen_loss = 0.42637260517348413, disc_loss = 0.0009169123969395118
Trained batch 184 in epoch 8, gen_loss = 0.42669136234231897, disc_loss = 0.0009177072181341214
Trained batch 185 in epoch 8, gen_loss = 0.42657436382385994, disc_loss = 0.0009153271583722584
Trained batch 186 in epoch 8, gen_loss = 0.4267459011332874, disc_loss = 0.0009151429143662061
Trained batch 187 in epoch 8, gen_loss = 0.4267548937746819, disc_loss = 0.0009141173890229572
Trained batch 188 in epoch 8, gen_loss = 0.4265241906756446, disc_loss = 0.0009132894191819504
Trained batch 189 in epoch 8, gen_loss = 0.4263426339940021, disc_loss = 0.0009123073978116736
Trained batch 190 in epoch 8, gen_loss = 0.42621162284107106, disc_loss = 0.0009108869347011875
Trained batch 191 in epoch 8, gen_loss = 0.42630638896177214, disc_loss = 0.0009109674003108618
Trained batch 192 in epoch 8, gen_loss = 0.42616305959657064, disc_loss = 0.0009121465943982931
Trained batch 193 in epoch 8, gen_loss = 0.42610205233711557, disc_loss = 0.0009103603800578695
Trained batch 194 in epoch 8, gen_loss = 0.426043412165764, disc_loss = 0.0009123485214494837
Trained batch 195 in epoch 8, gen_loss = 0.42549717973689644, disc_loss = 0.0009172004643098299
Trained batch 196 in epoch 8, gen_loss = 0.4254427549197589, disc_loss = 0.0009163726308219948
Trained batch 197 in epoch 8, gen_loss = 0.42513604191216553, disc_loss = 0.0009231800314878593
Trained batch 198 in epoch 8, gen_loss = 0.4250244075928501, disc_loss = 0.0009229401047236225
Trained batch 199 in epoch 8, gen_loss = 0.4248472860455513, disc_loss = 0.0009217862012155819
Trained batch 200 in epoch 8, gen_loss = 0.42478386027302906, disc_loss = 0.0009206714997918284
Trained batch 201 in epoch 8, gen_loss = 0.42488356126417026, disc_loss = 0.0009200647552578369
Trained batch 202 in epoch 8, gen_loss = 0.4250944303761562, disc_loss = 0.0009188984629406772
Trained batch 203 in epoch 8, gen_loss = 0.424831085637504, disc_loss = 0.0009167624937653469
Trained batch 204 in epoch 8, gen_loss = 0.42453111904423413, disc_loss = 0.0009151549706031091
Trained batch 205 in epoch 8, gen_loss = 0.42463627544421595, disc_loss = 0.000914917884392266
Trained batch 206 in epoch 8, gen_loss = 0.424548413010611, disc_loss = 0.0009150498522477054
Trained batch 207 in epoch 8, gen_loss = 0.4247057674309382, disc_loss = 0.0009153382967409785
Trained batch 208 in epoch 8, gen_loss = 0.4246100943054309, disc_loss = 0.0009146686802110212
Trained batch 209 in epoch 8, gen_loss = 0.4244186760414214, disc_loss = 0.0009133390857771571
Trained batch 210 in epoch 8, gen_loss = 0.4244200032186734, disc_loss = 0.000912572622191055
Trained batch 211 in epoch 8, gen_loss = 0.42423526422595076, disc_loss = 0.0009128993686249058
Trained batch 212 in epoch 8, gen_loss = 0.42427083947848826, disc_loss = 0.0009118530365306132
Trained batch 213 in epoch 8, gen_loss = 0.4243402726182314, disc_loss = 0.0009108699654733814
Trained batch 214 in epoch 8, gen_loss = 0.42458890343821326, disc_loss = 0.0009104431604121834
Trained batch 215 in epoch 8, gen_loss = 0.4247896663016743, disc_loss = 0.0009092553510628124
Trained batch 216 in epoch 8, gen_loss = 0.42473281885621733, disc_loss = 0.0009079439228095869
Trained batch 217 in epoch 8, gen_loss = 0.42481696578340794, disc_loss = 0.000906450759113228
Trained batch 218 in epoch 8, gen_loss = 0.4249212099536913, disc_loss = 0.0009056135361427313
Trained batch 219 in epoch 8, gen_loss = 0.42499955784190785, disc_loss = 0.000904024736056189
Trained batch 220 in epoch 8, gen_loss = 0.42495601668077354, disc_loss = 0.000903100415335218
Trained batch 221 in epoch 8, gen_loss = 0.42508056357100205, disc_loss = 0.0009016262373660464
Trained batch 222 in epoch 8, gen_loss = 0.42512086528299103, disc_loss = 0.0008995864386858227
Trained batch 223 in epoch 8, gen_loss = 0.4252229936953102, disc_loss = 0.0008981843717005436
Trained batch 224 in epoch 8, gen_loss = 0.4254381341404385, disc_loss = 0.000898974321058227
Trained batch 225 in epoch 8, gen_loss = 0.42533241977206376, disc_loss = 0.0008975742294646767
Trained batch 226 in epoch 8, gen_loss = 0.42515057587938687, disc_loss = 0.000896225195421144
Trained batch 227 in epoch 8, gen_loss = 0.42510726642713215, disc_loss = 0.0008949869771369553
Trained batch 228 in epoch 8, gen_loss = 0.4249203918282122, disc_loss = 0.0008944937286748018
Trained batch 229 in epoch 8, gen_loss = 0.4246580868959427, disc_loss = 0.0008926915971602759
Trained batch 230 in epoch 8, gen_loss = 0.4249361040014209, disc_loss = 0.000891736530682709
Trained batch 231 in epoch 8, gen_loss = 0.4249425936361839, disc_loss = 0.0008904758518650036
Trained batch 232 in epoch 8, gen_loss = 0.4251954427604512, disc_loss = 0.0008901606789538277
Trained batch 233 in epoch 8, gen_loss = 0.42506860858864254, disc_loss = 0.0008886338616562132
Trained batch 234 in epoch 8, gen_loss = 0.42496190870061834, disc_loss = 0.0008882563016278312
Trained batch 235 in epoch 8, gen_loss = 0.42490520164117973, disc_loss = 0.0008868788952556423
Trained batch 236 in epoch 8, gen_loss = 0.4251201230765395, disc_loss = 0.0008882192355965732
Trained batch 237 in epoch 8, gen_loss = 0.42528212095509055, disc_loss = 0.0008869395696972849
Trained batch 238 in epoch 8, gen_loss = 0.4253115288632684, disc_loss = 0.0008858730466101147
Trained batch 239 in epoch 8, gen_loss = 0.42532856451968354, disc_loss = 0.0008868888588040135
Trained batch 240 in epoch 8, gen_loss = 0.4254972573632521, disc_loss = 0.0008889563488909256
Trained batch 241 in epoch 8, gen_loss = 0.42539711690638676, disc_loss = 0.0008874430902271477
Trained batch 242 in epoch 8, gen_loss = 0.42525750570336485, disc_loss = 0.0008880223594069358
Trained batch 243 in epoch 8, gen_loss = 0.42554421649604546, disc_loss = 0.0008895445856471836
Trained batch 244 in epoch 8, gen_loss = 0.4253634603656068, disc_loss = 0.0008891266528326942
Trained batch 245 in epoch 8, gen_loss = 0.42537316994938423, disc_loss = 0.0008909445690422705
Trained batch 246 in epoch 8, gen_loss = 0.4250931270450716, disc_loss = 0.0008915449155170304
Trained batch 247 in epoch 8, gen_loss = 0.42527358089723893, disc_loss = 0.0008931448185561044
Trained batch 248 in epoch 8, gen_loss = 0.42520891315487014, disc_loss = 0.0008931395847417684
Trained batch 249 in epoch 8, gen_loss = 0.42536634027957915, disc_loss = 0.0008924842157866805
Trained batch 250 in epoch 8, gen_loss = 0.4253788173673637, disc_loss = 0.0008920241665351112
Trained batch 251 in epoch 8, gen_loss = 0.4255160888036092, disc_loss = 0.0008926991087343869
Trained batch 252 in epoch 8, gen_loss = 0.4254772492312631, disc_loss = 0.0008949082813652697
Trained batch 253 in epoch 8, gen_loss = 0.4254990867742403, disc_loss = 0.000893709294481467
Trained batch 254 in epoch 8, gen_loss = 0.42539908067852844, disc_loss = 0.000892799231908558
Trained batch 255 in epoch 8, gen_loss = 0.4253354499815032, disc_loss = 0.0008913247968393989
Trained batch 256 in epoch 8, gen_loss = 0.42551741583801894, disc_loss = 0.0008905325929728493
Trained batch 257 in epoch 8, gen_loss = 0.42586538045443306, disc_loss = 0.0008910907499669047
Trained batch 258 in epoch 8, gen_loss = 0.4258873739988187, disc_loss = 0.0008903346246946244
Trained batch 259 in epoch 8, gen_loss = 0.4260943109026322, disc_loss = 0.000889643423859245
Trained batch 260 in epoch 8, gen_loss = 0.42613333692039107, disc_loss = 0.0008891446873192387
Trained batch 261 in epoch 8, gen_loss = 0.42589784737761693, disc_loss = 0.000887688320665087
Trained batch 262 in epoch 8, gen_loss = 0.4259675938366937, disc_loss = 0.0008877161682225735
Trained batch 263 in epoch 8, gen_loss = 0.4260314969402371, disc_loss = 0.0008869786644495572
Trained batch 264 in epoch 8, gen_loss = 0.4261308820742481, disc_loss = 0.0008880177231610945
Trained batch 265 in epoch 8, gen_loss = 0.426012660103633, disc_loss = 0.0008865034013384379
Trained batch 266 in epoch 8, gen_loss = 0.42629889423927564, disc_loss = 0.0008864761133981722
Trained batch 267 in epoch 8, gen_loss = 0.4263804837394117, disc_loss = 0.0008859932188069753
Trained batch 268 in epoch 8, gen_loss = 0.42642935456839637, disc_loss = 0.0008850815923638697
Trained batch 269 in epoch 8, gen_loss = 0.4266626548987848, disc_loss = 0.0008871194132586459
Trained batch 270 in epoch 8, gen_loss = 0.42660144367341185, disc_loss = 0.0008889980748642882
Trained batch 271 in epoch 8, gen_loss = 0.42653000212329273, disc_loss = 0.0008897437842011534
Trained batch 272 in epoch 8, gen_loss = 0.4268409597786355, disc_loss = 0.0008892818047467196
Trained batch 273 in epoch 8, gen_loss = 0.4268907582672843, disc_loss = 0.0008883839120483366
Trained batch 274 in epoch 8, gen_loss = 0.42699245669625024, disc_loss = 0.0008873406615616245
Trained batch 275 in epoch 8, gen_loss = 0.4270354042882505, disc_loss = 0.0008866109765485685
Trained batch 276 in epoch 8, gen_loss = 0.42736684372278755, disc_loss = 0.0008928594171046027
Trained batch 277 in epoch 8, gen_loss = 0.42746181443012016, disc_loss = 0.0008923832939354796
Trained batch 278 in epoch 8, gen_loss = 0.42720599659454866, disc_loss = 0.0008952478506004831
Trained batch 279 in epoch 8, gen_loss = 0.4273983055991786, disc_loss = 0.0008987974479428626
Trained batch 280 in epoch 8, gen_loss = 0.42725430222168514, disc_loss = 0.0008987266101354064
Trained batch 281 in epoch 8, gen_loss = 0.4273474139313326, disc_loss = 0.000897543779153258
Trained batch 282 in epoch 8, gen_loss = 0.42741663348548403, disc_loss = 0.0008976979945480245
Trained batch 283 in epoch 8, gen_loss = 0.42745102039525207, disc_loss = 0.0008968248591154919
Trained batch 284 in epoch 8, gen_loss = 0.4272464551423725, disc_loss = 0.000896142673956459
Trained batch 285 in epoch 8, gen_loss = 0.42724251007283487, disc_loss = 0.000895406651942359
Trained batch 286 in epoch 8, gen_loss = 0.42730408886168475, disc_loss = 0.0008943092957372658
Trained batch 287 in epoch 8, gen_loss = 0.42731883138832116, disc_loss = 0.0008933656115712236
Trained batch 288 in epoch 8, gen_loss = 0.4272619649819437, disc_loss = 0.0008921296123067194
Trained batch 289 in epoch 8, gen_loss = 0.42687666930001356, disc_loss = 0.0008922284942698376
Trained batch 290 in epoch 8, gen_loss = 0.4267715410268593, disc_loss = 0.0008914489397071814
Trained batch 291 in epoch 8, gen_loss = 0.427110321921845, disc_loss = 0.0008926594353596718
Trained batch 292 in epoch 8, gen_loss = 0.42714512104060465, disc_loss = 0.0008928893015198664
Trained batch 293 in epoch 8, gen_loss = 0.4268831404901686, disc_loss = 0.0008914765375618804
Trained batch 294 in epoch 8, gen_loss = 0.42710641390186244, disc_loss = 0.0008914062289631594
Trained batch 295 in epoch 8, gen_loss = 0.42713350601292943, disc_loss = 0.0008916867278654732
Trained batch 296 in epoch 8, gen_loss = 0.4271571666303307, disc_loss = 0.0008913263804373341
Trained batch 297 in epoch 8, gen_loss = 0.4272840782099922, disc_loss = 0.0008920145640227843
Trained batch 298 in epoch 8, gen_loss = 0.427391440673018, disc_loss = 0.0008925080848748742
Trained batch 299 in epoch 8, gen_loss = 0.4275412791967392, disc_loss = 0.0008928755544669305
Trained batch 300 in epoch 8, gen_loss = 0.4274259949245326, disc_loss = 0.0008919785807506364
Trained batch 301 in epoch 8, gen_loss = 0.4273812064271889, disc_loss = 0.0008907490820448155
Trained batch 302 in epoch 8, gen_loss = 0.427355158250324, disc_loss = 0.000889707154405331
Trained batch 303 in epoch 8, gen_loss = 0.4272148863069321, disc_loss = 0.000888165364143022
Trained batch 304 in epoch 8, gen_loss = 0.42730088351202794, disc_loss = 0.0008876840244276357
Trained batch 305 in epoch 8, gen_loss = 0.4273373688163321, disc_loss = 0.0008870234027781883
Trained batch 306 in epoch 8, gen_loss = 0.4270803238165107, disc_loss = 0.000886786885897808
Trained batch 307 in epoch 8, gen_loss = 0.4267660676465406, disc_loss = 0.000887633258039918
Trained batch 308 in epoch 8, gen_loss = 0.4267167118182074, disc_loss = 0.0008927917785710478
Trained batch 309 in epoch 8, gen_loss = 0.4267100064023848, disc_loss = 0.0008990237111931727
Trained batch 310 in epoch 8, gen_loss = 0.4268578941607399, disc_loss = 0.000898795057884702
Trained batch 311 in epoch 8, gen_loss = 0.4268604387075473, disc_loss = 0.0008988260505691123
Trained batch 312 in epoch 8, gen_loss = 0.4269050666318534, disc_loss = 0.0008989673426981789
Trained batch 313 in epoch 8, gen_loss = 0.4269564556088417, disc_loss = 0.0009008393868370942
Trained batch 314 in epoch 8, gen_loss = 0.4269906321215251, disc_loss = 0.0009011538614267632
Trained batch 315 in epoch 8, gen_loss = 0.4271818272109273, disc_loss = 0.0009012530882742633
Trained batch 316 in epoch 8, gen_loss = 0.4270316609636842, disc_loss = 0.0009018280223887472
Trained batch 317 in epoch 8, gen_loss = 0.42693603348057224, disc_loss = 0.0009016167746238856
Trained batch 318 in epoch 8, gen_loss = 0.4268193159918053, disc_loss = 0.0009012769053392346
Trained batch 319 in epoch 8, gen_loss = 0.4267883849330246, disc_loss = 0.0009003280334582087
Trained batch 320 in epoch 8, gen_loss = 0.42682933705246706, disc_loss = 0.0008990078444797197
Trained batch 321 in epoch 8, gen_loss = 0.4269386192101129, disc_loss = 0.0008982830594679896
Trained batch 322 in epoch 8, gen_loss = 0.4269888115925686, disc_loss = 0.0008977262627429995
Trained batch 323 in epoch 8, gen_loss = 0.42713266408737793, disc_loss = 0.0008985615182879243
Trained batch 324 in epoch 8, gen_loss = 0.42723757872214685, disc_loss = 0.0009001164402490338
Trained batch 325 in epoch 8, gen_loss = 0.4272103880080709, disc_loss = 0.0009000636241720144
Trained batch 326 in epoch 8, gen_loss = 0.4272112840906196, disc_loss = 0.0008993340697636492
Trained batch 327 in epoch 8, gen_loss = 0.42736043844644617, disc_loss = 0.0008991164599492772
Trained batch 328 in epoch 8, gen_loss = 0.42747407345423943, disc_loss = 0.0008983826099316049
Trained batch 329 in epoch 8, gen_loss = 0.427226752855561, disc_loss = 0.0008974254380904533
Trained batch 330 in epoch 8, gen_loss = 0.4272383580215028, disc_loss = 0.000897009014042961
Trained batch 331 in epoch 8, gen_loss = 0.4275001620492303, disc_loss = 0.0008974353564904543
Trained batch 332 in epoch 8, gen_loss = 0.42745041542941026, disc_loss = 0.0008966029334467956
Trained batch 333 in epoch 8, gen_loss = 0.42742416744460604, disc_loss = 0.00089545507626371
Trained batch 334 in epoch 8, gen_loss = 0.42738437643691674, disc_loss = 0.0008947012392602472
Trained batch 335 in epoch 8, gen_loss = 0.42744616969000726, disc_loss = 0.000893964256430904
Trained batch 336 in epoch 8, gen_loss = 0.42746535465342356, disc_loss = 0.0008937230665141369
Trained batch 337 in epoch 8, gen_loss = 0.42738191607083087, disc_loss = 0.0008926323313471316
Trained batch 338 in epoch 8, gen_loss = 0.4273266183064047, disc_loss = 0.0008917519309150006
Trained batch 339 in epoch 8, gen_loss = 0.42727762311697004, disc_loss = 0.0008914266097503166
Trained batch 340 in epoch 8, gen_loss = 0.42732048060887023, disc_loss = 0.0008930496683192666
Trained batch 341 in epoch 8, gen_loss = 0.4274412356970603, disc_loss = 0.0008928076239344963
Trained batch 342 in epoch 8, gen_loss = 0.4275098100695596, disc_loss = 0.0008925235297893372
Trained batch 343 in epoch 8, gen_loss = 0.4275548605378284, disc_loss = 0.0008928951597332597
Trained batch 344 in epoch 8, gen_loss = 0.4276548607625823, disc_loss = 0.0008919824762573547
Trained batch 345 in epoch 8, gen_loss = 0.42780455076970114, disc_loss = 0.0008912480003409077
Trained batch 346 in epoch 8, gen_loss = 0.42791186792706204, disc_loss = 0.0008913376656265645
Trained batch 347 in epoch 8, gen_loss = 0.42785300083201505, disc_loss = 0.0008917686380760413
Trained batch 348 in epoch 8, gen_loss = 0.4277349913700945, disc_loss = 0.0008934740727483149
Trained batch 349 in epoch 8, gen_loss = 0.42785992409501755, disc_loss = 0.0008943571295822039
Trained batch 350 in epoch 8, gen_loss = 0.42771506368944107, disc_loss = 0.000894338321461451
Trained batch 351 in epoch 8, gen_loss = 0.42787192135371943, disc_loss = 0.000893795575972366
Trained batch 352 in epoch 8, gen_loss = 0.42784818778970085, disc_loss = 0.0008925916453086041
Trained batch 353 in epoch 8, gen_loss = 0.4278961529502761, disc_loss = 0.000891901673614258
Trained batch 354 in epoch 8, gen_loss = 0.4278672174668648, disc_loss = 0.0008919824964963687
Trained batch 355 in epoch 8, gen_loss = 0.42797248090585965, disc_loss = 0.0008913130438762319
Trained batch 356 in epoch 8, gen_loss = 0.42802468576685054, disc_loss = 0.0008900669192717899
Trained batch 357 in epoch 8, gen_loss = 0.42805852778464054, disc_loss = 0.0008893517816995983
Trained batch 358 in epoch 8, gen_loss = 0.42808230457863766, disc_loss = 0.0008884746089064021
Trained batch 359 in epoch 8, gen_loss = 0.42809188548061583, disc_loss = 0.0008873753537449779
Trained batch 360 in epoch 8, gen_loss = 0.42829942174895647, disc_loss = 0.0008870463765424953
Trained batch 361 in epoch 8, gen_loss = 0.4284792416497489, disc_loss = 0.000895045995480736
Trained batch 362 in epoch 8, gen_loss = 0.42856025942100967, disc_loss = 0.0008982841840101093
Trained batch 363 in epoch 8, gen_loss = 0.428548521392948, disc_loss = 0.0008996259360343914
Trained batch 364 in epoch 8, gen_loss = 0.4285564672457029, disc_loss = 0.0008996837568303493
Trained batch 365 in epoch 8, gen_loss = 0.4286903150257517, disc_loss = 0.0008988481889990326
Trained batch 366 in epoch 8, gen_loss = 0.4289433331677959, disc_loss = 0.0008990303987550882
Trained batch 367 in epoch 8, gen_loss = 0.42893212442488776, disc_loss = 0.0008988952591291467
Trained batch 368 in epoch 8, gen_loss = 0.4289383385078048, disc_loss = 0.0008978373623455604
Trained batch 369 in epoch 8, gen_loss = 0.428885818413786, disc_loss = 0.0008971407940309193
Trained batch 370 in epoch 8, gen_loss = 0.4286208377694184, disc_loss = 0.0008970232435057788
Trained batch 371 in epoch 8, gen_loss = 0.4285898525067555, disc_loss = 0.0008962758942269369
Trained batch 372 in epoch 8, gen_loss = 0.4285934851092883, disc_loss = 0.000895939687773805
Trained batch 373 in epoch 8, gen_loss = 0.42840653227612296, disc_loss = 0.0008947128817696811
Trained batch 374 in epoch 8, gen_loss = 0.42832444604237874, disc_loss = 0.0008937809126606832
Trained batch 375 in epoch 8, gen_loss = 0.4284627749881846, disc_loss = 0.0008941944138217529
Trained batch 376 in epoch 8, gen_loss = 0.4283549626720995, disc_loss = 0.00089472439518354
Trained batch 377 in epoch 8, gen_loss = 0.4283760547953308, disc_loss = 0.0008942649420874351
Trained batch 378 in epoch 8, gen_loss = 0.4283437603067282, disc_loss = 0.0008935554010337734
Trained batch 379 in epoch 8, gen_loss = 0.42831431760599736, disc_loss = 0.000893005576539221
Trained batch 380 in epoch 8, gen_loss = 0.4284048890034983, disc_loss = 0.0008926245392626519
Trained batch 381 in epoch 8, gen_loss = 0.4282412087418022, disc_loss = 0.0008914496628348155
Trained batch 382 in epoch 8, gen_loss = 0.42819425985022563, disc_loss = 0.0008908149430056542
Trained batch 383 in epoch 8, gen_loss = 0.4283095099187146, disc_loss = 0.0008900564028711718
Trained batch 384 in epoch 8, gen_loss = 0.42840694134885615, disc_loss = 0.0008893678518157308
Trained batch 385 in epoch 8, gen_loss = 0.4282806853093014, disc_loss = 0.0008885226671769733
Trained batch 386 in epoch 8, gen_loss = 0.42826160565211174, disc_loss = 0.0008879810999128342
Trained batch 387 in epoch 8, gen_loss = 0.4281719405319273, disc_loss = 0.0008873056088389407
Trained batch 388 in epoch 8, gen_loss = 0.4282872750397513, disc_loss = 0.0008872959989956209
Trained batch 389 in epoch 8, gen_loss = 0.42820994074528035, disc_loss = 0.0008861930589400566
Trained batch 390 in epoch 8, gen_loss = 0.42819767542507337, disc_loss = 0.0008857329282998953
Trained batch 391 in epoch 8, gen_loss = 0.42791290246710484, disc_loss = 0.0008865584893602336
Trained batch 392 in epoch 8, gen_loss = 0.4280031643447682, disc_loss = 0.0008875185243267585
Trained batch 393 in epoch 8, gen_loss = 0.4278931956605863, disc_loss = 0.0008872867050565315
Trained batch 394 in epoch 8, gen_loss = 0.4278857867174511, disc_loss = 0.000887356219368197
Trained batch 395 in epoch 8, gen_loss = 0.42779137743542894, disc_loss = 0.0008873251938370452
Trained batch 396 in epoch 8, gen_loss = 0.42774905973777966, disc_loss = 0.0008864107924268372
Trained batch 397 in epoch 8, gen_loss = 0.42774497526674415, disc_loss = 0.0008867191600211984
Trained batch 398 in epoch 8, gen_loss = 0.42759659744444345, disc_loss = 0.0008861314503733947
Trained batch 399 in epoch 8, gen_loss = 0.4275311888754368, disc_loss = 0.0008853301991621265
Trained batch 400 in epoch 8, gen_loss = 0.4274872251579589, disc_loss = 0.0008845089945943325
Trained batch 401 in epoch 8, gen_loss = 0.4274471818066355, disc_loss = 0.0008832343266286484
Trained batch 402 in epoch 8, gen_loss = 0.42742192915296434, disc_loss = 0.0008821068455091915
Trained batch 403 in epoch 8, gen_loss = 0.4273579682011415, disc_loss = 0.0008809631424558367
Trained batch 404 in epoch 8, gen_loss = 0.4274246966397321, disc_loss = 0.0008800873704639803
Trained batch 405 in epoch 8, gen_loss = 0.42762822793622324, disc_loss = 0.0008796755690557717
Trained batch 406 in epoch 8, gen_loss = 0.4277524388685859, disc_loss = 0.0008882344957110437
Trained batch 407 in epoch 8, gen_loss = 0.42773450144073544, disc_loss = 0.0008912058746158008
Trained batch 408 in epoch 8, gen_loss = 0.4276865172794221, disc_loss = 0.0008949145741167553
Trained batch 409 in epoch 8, gen_loss = 0.4276842211804739, disc_loss = 0.0008967505117009462
Trained batch 410 in epoch 8, gen_loss = 0.4276088869919742, disc_loss = 0.00089598266449485
Trained batch 411 in epoch 8, gen_loss = 0.42772162278879033, disc_loss = 0.0008957064996650939
Trained batch 412 in epoch 8, gen_loss = 0.4276415758358076, disc_loss = 0.0008955813784938143
Trained batch 413 in epoch 8, gen_loss = 0.42766637797804846, disc_loss = 0.0008955330257939517
Trained batch 414 in epoch 8, gen_loss = 0.42775188835270433, disc_loss = 0.0008955789013928453
Trained batch 415 in epoch 8, gen_loss = 0.4277995521775805, disc_loss = 0.0008947821978346418
Trained batch 416 in epoch 8, gen_loss = 0.4277487452224576, disc_loss = 0.0008936806340289818
Trained batch 417 in epoch 8, gen_loss = 0.42772421604423433, disc_loss = 0.000892724366076001
Trained batch 418 in epoch 8, gen_loss = 0.42779597952997483, disc_loss = 0.0008916291215141395
Trained batch 419 in epoch 8, gen_loss = 0.4277208094085966, disc_loss = 0.0008904589090629347
Trained batch 420 in epoch 8, gen_loss = 0.42775596490665174, disc_loss = 0.0008894894045341822
Trained batch 421 in epoch 8, gen_loss = 0.427726866156569, disc_loss = 0.0008882319737999299
Trained batch 422 in epoch 8, gen_loss = 0.42783779716097153, disc_loss = 0.0008875579631972142
Trained batch 423 in epoch 8, gen_loss = 0.4277809960240463, disc_loss = 0.0008865533236530609
Trained batch 424 in epoch 8, gen_loss = 0.4277135384082794, disc_loss = 0.0008856615469352726
Trained batch 425 in epoch 8, gen_loss = 0.42745271416057445, disc_loss = 0.0008860666370686109
Trained batch 426 in epoch 8, gen_loss = 0.4273568286409981, disc_loss = 0.0008873688783638388
Trained batch 427 in epoch 8, gen_loss = 0.4272684621337418, disc_loss = 0.0008879446727278094
Trained batch 428 in epoch 8, gen_loss = 0.42717569086935137, disc_loss = 0.0008877673843606334
Trained batch 429 in epoch 8, gen_loss = 0.42713578710722366, disc_loss = 0.0008872424179233264
Trained batch 430 in epoch 8, gen_loss = 0.4271612410755556, disc_loss = 0.0008866471853463752
Trained batch 431 in epoch 8, gen_loss = 0.4271805709986775, disc_loss = 0.0008861942959710076
Trained batch 432 in epoch 8, gen_loss = 0.42720119816877, disc_loss = 0.0008854158522451499
Trained batch 433 in epoch 8, gen_loss = 0.42719136906384325, disc_loss = 0.0008842716747809047
Trained batch 434 in epoch 8, gen_loss = 0.4269765037914802, disc_loss = 0.0008836444234475493
Trained batch 435 in epoch 8, gen_loss = 0.4269319895073908, disc_loss = 0.0008826706372361648
Trained batch 436 in epoch 8, gen_loss = 0.4269222402327121, disc_loss = 0.0008817943074373907
Trained batch 437 in epoch 8, gen_loss = 0.4269774401705015, disc_loss = 0.000881075185296215
Trained batch 438 in epoch 8, gen_loss = 0.4268995031273175, disc_loss = 0.0008799606157999256
Trained batch 439 in epoch 8, gen_loss = 0.4268380091948943, disc_loss = 0.0008794233878936873
Trained batch 440 in epoch 8, gen_loss = 0.426871976682118, disc_loss = 0.0008785660802851307
Trained batch 441 in epoch 8, gen_loss = 0.42698734297471885, disc_loss = 0.0008778112515916719
Trained batch 442 in epoch 8, gen_loss = 0.4270749916879641, disc_loss = 0.0008771814190168733
Trained batch 443 in epoch 8, gen_loss = 0.4269628167689384, disc_loss = 0.0008766403873262272
Trained batch 444 in epoch 8, gen_loss = 0.4268553583809499, disc_loss = 0.0008763253178677699
Trained batch 445 in epoch 8, gen_loss = 0.4267283531047838, disc_loss = 0.0008756797871658904
Trained batch 446 in epoch 8, gen_loss = 0.42665751275066827, disc_loss = 0.0008748125990564149
Trained batch 447 in epoch 8, gen_loss = 0.42669499811849426, disc_loss = 0.0008738715631417497
Trained batch 448 in epoch 8, gen_loss = 0.4267947663841375, disc_loss = 0.0008732191415841719
Trained batch 449 in epoch 8, gen_loss = 0.4267604230509864, disc_loss = 0.0008732128132962518
Trained batch 450 in epoch 8, gen_loss = 0.42678099236308603, disc_loss = 0.0008727424245528018
Trained batch 451 in epoch 8, gen_loss = 0.42666657058011115, disc_loss = 0.0008719564120355268
Trained batch 452 in epoch 8, gen_loss = 0.42680332268573856, disc_loss = 0.0008724858831700604
Trained batch 453 in epoch 8, gen_loss = 0.4267566048495045, disc_loss = 0.0008722612642506671
Trained batch 454 in epoch 8, gen_loss = 0.42680047567074114, disc_loss = 0.0008722007202987488
Trained batch 455 in epoch 8, gen_loss = 0.4268329195808946, disc_loss = 0.0008714056477816612
Trained batch 456 in epoch 8, gen_loss = 0.4270533865859785, disc_loss = 0.0008713489324995673
Trained batch 457 in epoch 8, gen_loss = 0.4270730287357189, disc_loss = 0.0008710227346486986
Trained batch 458 in epoch 8, gen_loss = 0.4270727329264539, disc_loss = 0.0008702621654980696
Trained batch 459 in epoch 8, gen_loss = 0.42708847859631416, disc_loss = 0.0008693184652973128
Trained batch 460 in epoch 8, gen_loss = 0.42706009603374173, disc_loss = 0.0008690258583514557
Trained batch 461 in epoch 8, gen_loss = 0.42715111671588124, disc_loss = 0.0008685748805685042
Trained batch 462 in epoch 8, gen_loss = 0.42725580924273054, disc_loss = 0.0008678104871527953
Trained batch 463 in epoch 8, gen_loss = 0.4272104103503556, disc_loss = 0.0008670279993535148
Trained batch 464 in epoch 8, gen_loss = 0.4272274213452493, disc_loss = 0.0008662362575470921
Trained batch 465 in epoch 8, gen_loss = 0.4272093724923072, disc_loss = 0.0008655592017005649
Trained batch 466 in epoch 8, gen_loss = 0.4271322808505636, disc_loss = 0.0008645238959563525
Trained batch 467 in epoch 8, gen_loss = 0.4271238384465886, disc_loss = 0.0008634839537274889
Trained batch 468 in epoch 8, gen_loss = 0.4270399208389111, disc_loss = 0.0008627205142882397
Trained batch 469 in epoch 8, gen_loss = 0.42714849723146314, disc_loss = 0.0008622820059362641
Trained batch 470 in epoch 8, gen_loss = 0.4270831800823252, disc_loss = 0.0008613602644462344
Trained batch 471 in epoch 8, gen_loss = 0.4271392224956367, disc_loss = 0.0008607232317074904
Trained batch 472 in epoch 8, gen_loss = 0.42696645150224954, disc_loss = 0.000859967158060328
Trained batch 473 in epoch 8, gen_loss = 0.4268358579290567, disc_loss = 0.0008591906231300481
Trained batch 474 in epoch 8, gen_loss = 0.4268634732146012, disc_loss = 0.000858718419239219
Trained batch 475 in epoch 8, gen_loss = 0.426758217398359, disc_loss = 0.0008577420845815615
Trained batch 476 in epoch 8, gen_loss = 0.42675328460879297, disc_loss = 0.0008570151386462323
Trained batch 477 in epoch 8, gen_loss = 0.4267356097074732, disc_loss = 0.0008562099832503679
Trained batch 478 in epoch 8, gen_loss = 0.42677229008246564, disc_loss = 0.000855495274530642
Trained batch 479 in epoch 8, gen_loss = 0.4266108530263106, disc_loss = 0.0008545493793159646
Trained batch 480 in epoch 8, gen_loss = 0.4265644235571308, disc_loss = 0.0008540256604796233
Trained batch 481 in epoch 8, gen_loss = 0.4264039710720545, disc_loss = 0.0008531747512298122
Trained batch 482 in epoch 8, gen_loss = 0.4263343982568192, disc_loss = 0.0008522920452340798
Trained batch 483 in epoch 8, gen_loss = 0.4264618861527482, disc_loss = 0.0008514847077620754
Trained batch 484 in epoch 8, gen_loss = 0.42632334650177317, disc_loss = 0.0008506781167168286
Trained batch 485 in epoch 8, gen_loss = 0.4262242669185984, disc_loss = 0.0008499775916182747
Trained batch 486 in epoch 8, gen_loss = 0.426136550778481, disc_loss = 0.0008497489916277358
Trained batch 487 in epoch 8, gen_loss = 0.42609305343911297, disc_loss = 0.0008488747191192682
Trained batch 488 in epoch 8, gen_loss = 0.42602158817776875, disc_loss = 0.0008480955179659783
Trained batch 489 in epoch 8, gen_loss = 0.42607489459368647, disc_loss = 0.0008471697109171702
Trained batch 490 in epoch 8, gen_loss = 0.42597549243274385, disc_loss = 0.000846495527168072
Trained batch 491 in epoch 8, gen_loss = 0.4259917579167257, disc_loss = 0.0008458737128961271
Trained batch 492 in epoch 8, gen_loss = 0.4259650865626384, disc_loss = 0.0008450757945192559
Trained batch 493 in epoch 8, gen_loss = 0.426021083163829, disc_loss = 0.0008442256561252345
Trained batch 494 in epoch 8, gen_loss = 0.42600721012462267, disc_loss = 0.0008436668512524303
Trained batch 495 in epoch 8, gen_loss = 0.42606492863307077, disc_loss = 0.0008431729930312178
Trained batch 496 in epoch 8, gen_loss = 0.4259444363040464, disc_loss = 0.000843353003827514
Trained batch 497 in epoch 8, gen_loss = 0.426015945802252, disc_loss = 0.000842859523102499
Trained batch 498 in epoch 8, gen_loss = 0.42616140281031273, disc_loss = 0.0008423809290589216
Trained batch 499 in epoch 8, gen_loss = 0.42616445368528366, disc_loss = 0.000841917690820992
Trained batch 500 in epoch 8, gen_loss = 0.4260614750509015, disc_loss = 0.0008412606679804683
Trained batch 501 in epoch 8, gen_loss = 0.426098077954999, disc_loss = 0.0008408760032069264
Trained batch 502 in epoch 8, gen_loss = 0.4261811231050055, disc_loss = 0.0008405590310478009
Trained batch 503 in epoch 8, gen_loss = 0.42604707169627387, disc_loss = 0.0008397461742066615
Trained batch 504 in epoch 8, gen_loss = 0.4260498564432163, disc_loss = 0.0008392549418420116
Trained batch 505 in epoch 8, gen_loss = 0.4260234634277849, disc_loss = 0.0008383548579025984
Trained batch 506 in epoch 8, gen_loss = 0.42615317046289614, disc_loss = 0.000838544971495132
Trained batch 507 in epoch 8, gen_loss = 0.42603808764632295, disc_loss = 0.0008381158860554318
Trained batch 508 in epoch 8, gen_loss = 0.4259958205733646, disc_loss = 0.0008374282809258905
Trained batch 509 in epoch 8, gen_loss = 0.42583483124480526, disc_loss = 0.0008368643235264565
Trained batch 510 in epoch 8, gen_loss = 0.4260031410042787, disc_loss = 0.0008367878830159691
Trained batch 511 in epoch 8, gen_loss = 0.42601851181825623, disc_loss = 0.0008363642887729839
Trained batch 512 in epoch 8, gen_loss = 0.42595647435206885, disc_loss = 0.0008365143689923315
Trained batch 513 in epoch 8, gen_loss = 0.42599692621815527, disc_loss = 0.000836831206491612
Trained batch 514 in epoch 8, gen_loss = 0.4260023485109644, disc_loss = 0.000836113626216493
Trained batch 515 in epoch 8, gen_loss = 0.4259560905223669, disc_loss = 0.0008353690585539345
Trained batch 516 in epoch 8, gen_loss = 0.42596330719944125, disc_loss = 0.0008347733121349997
Trained batch 517 in epoch 8, gen_loss = 0.4259235027559015, disc_loss = 0.0008341531350945291
Trained batch 518 in epoch 8, gen_loss = 0.42579774079065563, disc_loss = 0.0008334709168882836
Trained batch 519 in epoch 8, gen_loss = 0.42583294270130306, disc_loss = 0.0008331321662878438
Trained batch 520 in epoch 8, gen_loss = 0.4258080850750379, disc_loss = 0.0008324862736784058
Trained batch 521 in epoch 8, gen_loss = 0.42570042010696457, disc_loss = 0.000831923558333464
Trained batch 522 in epoch 8, gen_loss = 0.42557325275404734, disc_loss = 0.0008314163770760814
Trained batch 523 in epoch 8, gen_loss = 0.4255233056672657, disc_loss = 0.0008305733722304918
Trained batch 524 in epoch 8, gen_loss = 0.4256122013500759, disc_loss = 0.000829997357102998
Trained batch 525 in epoch 8, gen_loss = 0.42562182343957994, disc_loss = 0.0008297666017928413
Trained batch 526 in epoch 8, gen_loss = 0.4257326297447849, disc_loss = 0.0008292747589125982
Trained batch 527 in epoch 8, gen_loss = 0.425615226737026, disc_loss = 0.0008287667727320999
Trained batch 528 in epoch 8, gen_loss = 0.42564416297892765, disc_loss = 0.0008292637181900519
Trained batch 529 in epoch 8, gen_loss = 0.425607748863832, disc_loss = 0.0008289130207454294
Trained batch 530 in epoch 8, gen_loss = 0.4256136904553056, disc_loss = 0.0008287890604324464
Trained batch 531 in epoch 8, gen_loss = 0.42554415129405215, disc_loss = 0.0008279060728496109
Trained batch 532 in epoch 8, gen_loss = 0.4255809614515215, disc_loss = 0.000827533306071699
Trained batch 533 in epoch 8, gen_loss = 0.4257007809390736, disc_loss = 0.0008280356299072811
Trained batch 534 in epoch 8, gen_loss = 0.4256704764945485, disc_loss = 0.0008276348350412934
Trained batch 535 in epoch 8, gen_loss = 0.4256772330002998, disc_loss = 0.0008268574875090514
Trained batch 536 in epoch 8, gen_loss = 0.42574888395641547, disc_loss = 0.0008264906717758292
Trained batch 537 in epoch 8, gen_loss = 0.42561251096787506, disc_loss = 0.0008259840936812859
Trained batch 538 in epoch 8, gen_loss = 0.42569171646972753, disc_loss = 0.000825758572723561
Trained batch 539 in epoch 8, gen_loss = 0.4257959254361965, disc_loss = 0.0008260814245052946
Trained batch 540 in epoch 8, gen_loss = 0.42576722324225025, disc_loss = 0.0008254516915510307
Trained batch 541 in epoch 8, gen_loss = 0.4257391665364543, disc_loss = 0.0008250031692969932
Trained batch 542 in epoch 8, gen_loss = 0.4258197843479627, disc_loss = 0.0008244500071531535
Trained batch 543 in epoch 8, gen_loss = 0.42580219013068604, disc_loss = 0.0008240099654465346
Trained batch 544 in epoch 8, gen_loss = 0.4257665195049496, disc_loss = 0.0008233330356183573
Trained batch 545 in epoch 8, gen_loss = 0.42570638689366014, disc_loss = 0.000822558272798416
Trained batch 546 in epoch 8, gen_loss = 0.4256817982336285, disc_loss = 0.0008217166282744802
Trained batch 547 in epoch 8, gen_loss = 0.42567141500920275, disc_loss = 0.0008216678472613936
Trained batch 548 in epoch 8, gen_loss = 0.4256785047835991, disc_loss = 0.0008210640267374839
Trained batch 549 in epoch 8, gen_loss = 0.42560890907591037, disc_loss = 0.0008202557491710071
Trained batch 550 in epoch 8, gen_loss = 0.4254892191523433, disc_loss = 0.0008194673649130893
Trained batch 551 in epoch 8, gen_loss = 0.42553346841663553, disc_loss = 0.0008193686424920747
Trained batch 552 in epoch 8, gen_loss = 0.42544673558385204, disc_loss = 0.0008188056579860901
Trained batch 553 in epoch 8, gen_loss = 0.4254319311694548, disc_loss = 0.0008181973831393564
Trained batch 554 in epoch 8, gen_loss = 0.4253139789040024, disc_loss = 0.0008176308667480208
Trained batch 555 in epoch 8, gen_loss = 0.42534012004411476, disc_loss = 0.0008170917660974489
Trained batch 556 in epoch 8, gen_loss = 0.4252143765480343, disc_loss = 0.0008163001136252359
Trained batch 557 in epoch 8, gen_loss = 0.4252692553945767, disc_loss = 0.0008157534188070204
Trained batch 558 in epoch 8, gen_loss = 0.4252837658035094, disc_loss = 0.0008151807468459477
Trained batch 559 in epoch 8, gen_loss = 0.4253851430756705, disc_loss = 0.0008154572906538046
Trained batch 560 in epoch 8, gen_loss = 0.42534596636333566, disc_loss = 0.0008149417074697687
Trained batch 561 in epoch 8, gen_loss = 0.42529384669884246, disc_loss = 0.0008144026817513623
Trained batch 562 in epoch 8, gen_loss = 0.42535213239451286, disc_loss = 0.000813783663589686
Trained batch 563 in epoch 8, gen_loss = 0.4252740469701747, disc_loss = 0.0008132175287704069
Trained batch 564 in epoch 8, gen_loss = 0.4253284314564899, disc_loss = 0.0008125701229978122
Trained batch 565 in epoch 8, gen_loss = 0.42517901899115357, disc_loss = 0.0008120748307802731
Trained batch 566 in epoch 8, gen_loss = 0.4252590942845353, disc_loss = 0.0008117645098934545
Trained batch 567 in epoch 8, gen_loss = 0.425228637079118, disc_loss = 0.0008114252418187827
Trained batch 568 in epoch 8, gen_loss = 0.4252866692513699, disc_loss = 0.0008113230902886572
Trained batch 569 in epoch 8, gen_loss = 0.42518777899574817, disc_loss = 0.0008107728720029914
Trained batch 570 in epoch 8, gen_loss = 0.42524066463034543, disc_loss = 0.0008101979706472279
Trained batch 571 in epoch 8, gen_loss = 0.4251722882573421, disc_loss = 0.0008096003724210016
Trained batch 572 in epoch 8, gen_loss = 0.42517945305631216, disc_loss = 0.0008093070424321135
Trained batch 573 in epoch 8, gen_loss = 0.42516936948490475, disc_loss = 0.0008089063170516883
Trained batch 574 in epoch 8, gen_loss = 0.4251908668746119, disc_loss = 0.0008081268021108015
Trained batch 575 in epoch 8, gen_loss = 0.425253229888363, disc_loss = 0.0008076980302575976
Trained batch 576 in epoch 8, gen_loss = 0.42528784249229695, disc_loss = 0.0008070340771587207
Trained batch 577 in epoch 8, gen_loss = 0.4252450720352285, disc_loss = 0.00080617225998215
Trained batch 578 in epoch 8, gen_loss = 0.42526177946149996, disc_loss = 0.000805397510539824
Trained batch 579 in epoch 8, gen_loss = 0.42519236828746465, disc_loss = 0.0008048330389509171
Trained batch 580 in epoch 8, gen_loss = 0.42507843311600346, disc_loss = 0.00080442957286747
Trained batch 581 in epoch 8, gen_loss = 0.42505142886409236, disc_loss = 0.0008041143932026136
Trained batch 582 in epoch 8, gen_loss = 0.4250892132878508, disc_loss = 0.0008033942999310255
Trained batch 583 in epoch 8, gen_loss = 0.42510198842581004, disc_loss = 0.0008027492274852368
Trained batch 584 in epoch 8, gen_loss = 0.425102511787007, disc_loss = 0.0008022283184994808
Trained batch 585 in epoch 8, gen_loss = 0.4250155909069569, disc_loss = 0.0008016478667316208
Trained batch 586 in epoch 8, gen_loss = 0.4250650277941962, disc_loss = 0.0008010848634459833
Trained batch 587 in epoch 8, gen_loss = 0.42497469241521796, disc_loss = 0.0008007405828355913
Trained batch 588 in epoch 8, gen_loss = 0.4249078466451026, disc_loss = 0.0008003878641295672
Trained batch 589 in epoch 8, gen_loss = 0.42495048632056026, disc_loss = 0.0007999019344609578
Trained batch 590 in epoch 8, gen_loss = 0.42495762091602773, disc_loss = 0.0007991667251577742
Trained batch 591 in epoch 8, gen_loss = 0.42497813218348734, disc_loss = 0.000798624480110546
Trained batch 592 in epoch 8, gen_loss = 0.4249174182270269, disc_loss = 0.0007978942995466148
Trained batch 593 in epoch 8, gen_loss = 0.4249192666425448, disc_loss = 0.0007973596224755751
Trained batch 594 in epoch 8, gen_loss = 0.42484588367598397, disc_loss = 0.0007968770665852274
Trained batch 595 in epoch 8, gen_loss = 0.4248340346369167, disc_loss = 0.0007963410248368941
Trained batch 596 in epoch 8, gen_loss = 0.4247986006876532, disc_loss = 0.0007956614229364798
Trained batch 597 in epoch 8, gen_loss = 0.4247087009973749, disc_loss = 0.0007950582087057858
Trained batch 598 in epoch 8, gen_loss = 0.4248308660291471, disc_loss = 0.0007965621012842162
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.37070363759994507, disc_loss = 0.001632601022720337
Trained batch 1 in epoch 9, gen_loss = 0.3910932242870331, disc_loss = 0.0013180298265069723
Trained batch 2 in epoch 9, gen_loss = 0.41667426625887555, disc_loss = 0.0010896166398500402
Trained batch 3 in epoch 9, gen_loss = 0.4177786484360695, disc_loss = 0.0009798997489269823
Trained batch 4 in epoch 9, gen_loss = 0.414773041009903, disc_loss = 0.000868604303104803
Trained batch 5 in epoch 9, gen_loss = 0.4076097110907237, disc_loss = 0.0007967205407718817
Trained batch 6 in epoch 9, gen_loss = 0.4137442708015442, disc_loss = 0.0007756203579317246
Trained batch 7 in epoch 9, gen_loss = 0.42071159183979034, disc_loss = 0.0007443263384629972
Trained batch 8 in epoch 9, gen_loss = 0.4140123989846971, disc_loss = 0.0007009407401912742
Trained batch 9 in epoch 9, gen_loss = 0.4076171964406967, disc_loss = 0.0006656608136836439
Trained batch 10 in epoch 9, gen_loss = 0.40637074275450275, disc_loss = 0.0006672294799831103
Trained batch 11 in epoch 9, gen_loss = 0.40592636664708454, disc_loss = 0.0006847918702987954
Trained batch 12 in epoch 9, gen_loss = 0.4055043321389418, disc_loss = 0.0007008999460735
Trained batch 13 in epoch 9, gen_loss = 0.40648494235106875, disc_loss = 0.0007343739437471543
Trained batch 14 in epoch 9, gen_loss = 0.410174822807312, disc_loss = 0.0007403696149898072
Trained batch 15 in epoch 9, gen_loss = 0.4118845444172621, disc_loss = 0.0007371309948212001
Trained batch 16 in epoch 9, gen_loss = 0.41458582176881675, disc_loss = 0.0007371577632832615
Trained batch 17 in epoch 9, gen_loss = 0.41524431109428406, disc_loss = 0.0007231208518432039
Trained batch 18 in epoch 9, gen_loss = 0.4152349766932036, disc_loss = 0.0007115991243872008
Trained batch 19 in epoch 9, gen_loss = 0.41791370064020156, disc_loss = 0.0007061919706757181
Trained batch 20 in epoch 9, gen_loss = 0.4161178654148465, disc_loss = 0.000705552660205978
Trained batch 21 in epoch 9, gen_loss = 0.41384475204077636, disc_loss = 0.0006924974930536172
Trained batch 22 in epoch 9, gen_loss = 0.41424944478532544, disc_loss = 0.0006943303299561629
Trained batch 23 in epoch 9, gen_loss = 0.41729866713285446, disc_loss = 0.0006865461073175538
Trained batch 24 in epoch 9, gen_loss = 0.4181560134887695, disc_loss = 0.0006753933278378099
Trained batch 25 in epoch 9, gen_loss = 0.4186795262190012, disc_loss = 0.0006624943231984687
Trained batch 26 in epoch 9, gen_loss = 0.41920297123767714, disc_loss = 0.0006496305426548201
Trained batch 27 in epoch 9, gen_loss = 0.4182277364390237, disc_loss = 0.0006492953024072838
Trained batch 28 in epoch 9, gen_loss = 0.4179144316706164, disc_loss = 0.000648770356904073
Trained batch 29 in epoch 9, gen_loss = 0.4203658749659856, disc_loss = 0.0006776972169366976
Trained batch 30 in epoch 9, gen_loss = 0.42283529620016774, disc_loss = 0.000715521644921072
Trained batch 31 in epoch 9, gen_loss = 0.42383337300270796, disc_loss = 0.0007236557903524954
Trained batch 32 in epoch 9, gen_loss = 0.4239629145824548, disc_loss = 0.0007250317033718933
Trained batch 33 in epoch 9, gen_loss = 0.42403752488248486, disc_loss = 0.000722893191884984
Trained batch 34 in epoch 9, gen_loss = 0.4225941640990121, disc_loss = 0.0007202038607959237
Trained batch 35 in epoch 9, gen_loss = 0.42458002600404954, disc_loss = 0.0007234870863612741
Trained batch 36 in epoch 9, gen_loss = 0.4228521424370843, disc_loss = 0.0007302220627615178
Trained batch 37 in epoch 9, gen_loss = 0.42178807525258316, disc_loss = 0.0007302965968847275
Trained batch 38 in epoch 9, gen_loss = 0.4209357545926021, disc_loss = 0.0007251776256359732
Trained batch 39 in epoch 9, gen_loss = 0.4212654814124107, disc_loss = 0.0007320155200432055
Trained batch 40 in epoch 9, gen_loss = 0.42164448339764665, disc_loss = 0.000726003833001525
Trained batch 41 in epoch 9, gen_loss = 0.42320511241753894, disc_loss = 0.0007243084837682545
Trained batch 42 in epoch 9, gen_loss = 0.4224509021570516, disc_loss = 0.0007247010863191167
Trained batch 43 in epoch 9, gen_loss = 0.42231515862725, disc_loss = 0.000719363610683517
Trained batch 44 in epoch 9, gen_loss = 0.4230914466910892, disc_loss = 0.0007171341968286369
Trained batch 45 in epoch 9, gen_loss = 0.42233584562073584, disc_loss = 0.0007203501337916468
Trained batch 46 in epoch 9, gen_loss = 0.4224936619718024, disc_loss = 0.0007225222206932116
Trained batch 47 in epoch 9, gen_loss = 0.4222282040864229, disc_loss = 0.0007266141486373575
Trained batch 48 in epoch 9, gen_loss = 0.42194758264385923, disc_loss = 0.0007204982589892283
Trained batch 49 in epoch 9, gen_loss = 0.42244161903858185, disc_loss = 0.0007151866191998124
Trained batch 50 in epoch 9, gen_loss = 0.42114552913927567, disc_loss = 0.0007095712787179532
Trained batch 51 in epoch 9, gen_loss = 0.4202920519388639, disc_loss = 0.0007061503487280929
Trained batch 52 in epoch 9, gen_loss = 0.42064166968723515, disc_loss = 0.0007044508271270766
Trained batch 53 in epoch 9, gen_loss = 0.4196116195784675, disc_loss = 0.0007006810499458677
Trained batch 54 in epoch 9, gen_loss = 0.41944024617021736, disc_loss = 0.0006971707165410573
Trained batch 55 in epoch 9, gen_loss = 0.41873982548713684, disc_loss = 0.0006907108794881164
Trained batch 56 in epoch 9, gen_loss = 0.4205410919691387, disc_loss = 0.000691880484258658
Trained batch 57 in epoch 9, gen_loss = 0.4198188216521822, disc_loss = 0.000699752712911316
Trained batch 58 in epoch 9, gen_loss = 0.4199064525507264, disc_loss = 0.0007083686147579702
Trained batch 59 in epoch 9, gen_loss = 0.41969535251458484, disc_loss = 0.0007067387137794867
Trained batch 60 in epoch 9, gen_loss = 0.4189542531967163, disc_loss = 0.0007009164928305956
Trained batch 61 in epoch 9, gen_loss = 0.4193571493510277, disc_loss = 0.0006990841995444029
Trained batch 62 in epoch 9, gen_loss = 0.41953297787242466, disc_loss = 0.0006977698048724542
Trained batch 63 in epoch 9, gen_loss = 0.4186976309865713, disc_loss = 0.0006910915162734454
Trained batch 64 in epoch 9, gen_loss = 0.41951583578036383, disc_loss = 0.0006878678669006779
Trained batch 65 in epoch 9, gen_loss = 0.4207684790546244, disc_loss = 0.000687427013569201
Trained batch 66 in epoch 9, gen_loss = 0.42006773601717023, disc_loss = 0.0006850572179572017
Trained batch 67 in epoch 9, gen_loss = 0.42022420904215646, disc_loss = 0.0006817670073360205
Trained batch 68 in epoch 9, gen_loss = 0.41997214849444403, disc_loss = 0.0006777608144582938
Trained batch 69 in epoch 9, gen_loss = 0.4201498883111136, disc_loss = 0.0006732229426104043
Trained batch 70 in epoch 9, gen_loss = 0.4197310448532373, disc_loss = 0.0006677250895964008
Trained batch 71 in epoch 9, gen_loss = 0.41956016586886513, disc_loss = 0.000667638199552635
Trained batch 72 in epoch 9, gen_loss = 0.4197425017618153, disc_loss = 0.0006650431685258112
Trained batch 73 in epoch 9, gen_loss = 0.41915266578261917, disc_loss = 0.0006635109638335888
Trained batch 74 in epoch 9, gen_loss = 0.42017900824546817, disc_loss = 0.0006633974375048031
Trained batch 75 in epoch 9, gen_loss = 0.4199419696080057, disc_loss = 0.0006597702553048485
Trained batch 76 in epoch 9, gen_loss = 0.41946772824634204, disc_loss = 0.0006562342217899617
Trained batch 77 in epoch 9, gen_loss = 0.4191481306766852, disc_loss = 0.0006552694887012386
Trained batch 78 in epoch 9, gen_loss = 0.41954778380031826, disc_loss = 0.0006561023606830336
Trained batch 79 in epoch 9, gen_loss = 0.4196211535483599, disc_loss = 0.0006558003162353998
Trained batch 80 in epoch 9, gen_loss = 0.419789923194014, disc_loss = 0.0006559007103342195
Trained batch 81 in epoch 9, gen_loss = 0.41955447051583267, disc_loss = 0.0006553405557230978
Trained batch 82 in epoch 9, gen_loss = 0.4194652089871556, disc_loss = 0.0006544869607005896
Trained batch 83 in epoch 9, gen_loss = 0.41868852894930614, disc_loss = 0.0006514076220420455
Trained batch 84 in epoch 9, gen_loss = 0.41836924938594594, disc_loss = 0.0006482523218865561
Trained batch 85 in epoch 9, gen_loss = 0.4182410808496697, disc_loss = 0.0006461438021032399
Trained batch 86 in epoch 9, gen_loss = 0.4184521258562461, disc_loss = 0.0006486948726072522
Trained batch 87 in epoch 9, gen_loss = 0.41811455752361903, disc_loss = 0.0006453169404597826
Trained batch 88 in epoch 9, gen_loss = 0.41827795478735075, disc_loss = 0.0006425574600429724
Trained batch 89 in epoch 9, gen_loss = 0.41772060261832344, disc_loss = 0.0006425073308896067
Trained batch 90 in epoch 9, gen_loss = 0.41725774060238846, disc_loss = 0.000639883322886877
Trained batch 91 in epoch 9, gen_loss = 0.41775635403135547, disc_loss = 0.0006373926975673227
Trained batch 92 in epoch 9, gen_loss = 0.41792495372474836, disc_loss = 0.0006349039685246484
Trained batch 93 in epoch 9, gen_loss = 0.4183282712672619, disc_loss = 0.0006334417820982437
Trained batch 94 in epoch 9, gen_loss = 0.4181815693252965, disc_loss = 0.000631168756732031
Trained batch 95 in epoch 9, gen_loss = 0.4187531815841794, disc_loss = 0.0006285998188104713
Trained batch 96 in epoch 9, gen_loss = 0.41896655848345804, disc_loss = 0.0006254979393675385
Trained batch 97 in epoch 9, gen_loss = 0.41875799000263214, disc_loss = 0.0006231937550925364
Trained batch 98 in epoch 9, gen_loss = 0.41918250105597754, disc_loss = 0.0006220747156402642
Trained batch 99 in epoch 9, gen_loss = 0.41933560132980346, disc_loss = 0.0006214094240567647
Trained batch 100 in epoch 9, gen_loss = 0.41959195650450076, disc_loss = 0.0006215542633810293
Trained batch 101 in epoch 9, gen_loss = 0.4194205301065071, disc_loss = 0.0006195758674841593
Trained batch 102 in epoch 9, gen_loss = 0.41999431055726355, disc_loss = 0.0006173145242410631
Trained batch 103 in epoch 9, gen_loss = 0.4203258824463074, disc_loss = 0.0006157678933679842
Trained batch 104 in epoch 9, gen_loss = 0.4203903558708373, disc_loss = 0.0006148668072585549
Trained batch 105 in epoch 9, gen_loss = 0.4202387037704576, disc_loss = 0.0006149218006955705
Trained batch 106 in epoch 9, gen_loss = 0.4199141074563855, disc_loss = 0.0006128960842849843
Trained batch 107 in epoch 9, gen_loss = 0.41974106789739046, disc_loss = 0.0006114021671237424
Trained batch 108 in epoch 9, gen_loss = 0.4198799874257604, disc_loss = 0.000612392964977942
Trained batch 109 in epoch 9, gen_loss = 0.4201618511568416, disc_loss = 0.0006148269177753139
Trained batch 110 in epoch 9, gen_loss = 0.42001861280149166, disc_loss = 0.000617050594620843
Trained batch 111 in epoch 9, gen_loss = 0.42051045703036444, disc_loss = 0.0006206642465258483
Trained batch 112 in epoch 9, gen_loss = 0.4207398793866149, disc_loss = 0.000620742484543934
Trained batch 113 in epoch 9, gen_loss = 0.4208003729581833, disc_loss = 0.0006195608316614342
Trained batch 114 in epoch 9, gen_loss = 0.42078343863072604, disc_loss = 0.0006186208138546056
Trained batch 115 in epoch 9, gen_loss = 0.42021470105853576, disc_loss = 0.000619562601435785
Trained batch 116 in epoch 9, gen_loss = 0.4203698021224421, disc_loss = 0.0006204567987443958
Trained batch 117 in epoch 9, gen_loss = 0.42056825024596717, disc_loss = 0.000618527675692734
Trained batch 118 in epoch 9, gen_loss = 0.4202084388552594, disc_loss = 0.0006167148105397101
Trained batch 119 in epoch 9, gen_loss = 0.42004885772864026, disc_loss = 0.0006143542370409705
Trained batch 120 in epoch 9, gen_loss = 0.4203715166769737, disc_loss = 0.0006127852291322875
Trained batch 121 in epoch 9, gen_loss = 0.4206919198642012, disc_loss = 0.0006114877345322891
Trained batch 122 in epoch 9, gen_loss = 0.4208785515975177, disc_loss = 0.0006147403325847676
Trained batch 123 in epoch 9, gen_loss = 0.42094419560124796, disc_loss = 0.0006145640293271431
Trained batch 124 in epoch 9, gen_loss = 0.42125437450408937, disc_loss = 0.0006161097548902035
Trained batch 125 in epoch 9, gen_loss = 0.4212757024973158, disc_loss = 0.0006150872652633263
Trained batch 126 in epoch 9, gen_loss = 0.4207742981554016, disc_loss = 0.0006142263355716241
Trained batch 127 in epoch 9, gen_loss = 0.42037737811915576, disc_loss = 0.0006130988294898998
Trained batch 128 in epoch 9, gen_loss = 0.4207441735175229, disc_loss = 0.0006124811362504035
Trained batch 129 in epoch 9, gen_loss = 0.42071387469768523, disc_loss = 0.0006115127804850299
Trained batch 130 in epoch 9, gen_loss = 0.42061108146005005, disc_loss = 0.00061063404050158
Trained batch 131 in epoch 9, gen_loss = 0.42069993077805545, disc_loss = 0.0006103638013221578
Trained batch 132 in epoch 9, gen_loss = 0.42018266212671324, disc_loss = 0.0006089267844799906
Trained batch 133 in epoch 9, gen_loss = 0.4200388782504779, disc_loss = 0.0006076811435771411
Trained batch 134 in epoch 9, gen_loss = 0.42016403653003553, disc_loss = 0.0006063317698943946
Trained batch 135 in epoch 9, gen_loss = 0.42019777723095, disc_loss = 0.0006046854582296766
Trained batch 136 in epoch 9, gen_loss = 0.4201945638569602, disc_loss = 0.0006027558304787525
Trained batch 137 in epoch 9, gen_loss = 0.4201198868129564, disc_loss = 0.0006011540185747857
Trained batch 138 in epoch 9, gen_loss = 0.42029375588293555, disc_loss = 0.0005999681947705932
Trained batch 139 in epoch 9, gen_loss = 0.42029771038464137, disc_loss = 0.0006008031067072547
Trained batch 140 in epoch 9, gen_loss = 0.41997752819500916, disc_loss = 0.0006003410675965831
Trained batch 141 in epoch 9, gen_loss = 0.41988684069102916, disc_loss = 0.0006052455159796166
Trained batch 142 in epoch 9, gen_loss = 0.4199497059925453, disc_loss = 0.0006071734970754625
Trained batch 143 in epoch 9, gen_loss = 0.4201874246613847, disc_loss = 0.0006101386368552792
Trained batch 144 in epoch 9, gen_loss = 0.4204226904901965, disc_loss = 0.000612046232382799
Trained batch 145 in epoch 9, gen_loss = 0.420886876852545, disc_loss = 0.0006135260440689856
Trained batch 146 in epoch 9, gen_loss = 0.42104627790094235, disc_loss = 0.0006138016667761872
Trained batch 147 in epoch 9, gen_loss = 0.42110586307338765, disc_loss = 0.0006126738841664297
Trained batch 148 in epoch 9, gen_loss = 0.42167699957053933, disc_loss = 0.0006125609799844506
Trained batch 149 in epoch 9, gen_loss = 0.4215709884961446, disc_loss = 0.0006129763764329255
Trained batch 150 in epoch 9, gen_loss = 0.4218226910032184, disc_loss = 0.0006142848831237547
Trained batch 151 in epoch 9, gen_loss = 0.4216635848738645, disc_loss = 0.0006124028222984634
Trained batch 152 in epoch 9, gen_loss = 0.4218648666260289, disc_loss = 0.0006126703719571963
Trained batch 153 in epoch 9, gen_loss = 0.42181453437774213, disc_loss = 0.0006129267132635434
Trained batch 154 in epoch 9, gen_loss = 0.4216802152895158, disc_loss = 0.0006113928100544839
Trained batch 155 in epoch 9, gen_loss = 0.4216367031137149, disc_loss = 0.000611916314646339
Trained batch 156 in epoch 9, gen_loss = 0.4213614655528099, disc_loss = 0.0006148418938818204
Trained batch 157 in epoch 9, gen_loss = 0.4216187681201138, disc_loss = 0.0006170724640170088
Trained batch 158 in epoch 9, gen_loss = 0.4222378687663648, disc_loss = 0.0006233129863416389
Trained batch 159 in epoch 9, gen_loss = 0.4222596034407616, disc_loss = 0.0006265641979553039
Trained batch 160 in epoch 9, gen_loss = 0.4221391409450436, disc_loss = 0.0006268842999753976
Trained batch 161 in epoch 9, gen_loss = 0.422093234864282, disc_loss = 0.0006270055949435006
Trained batch 162 in epoch 9, gen_loss = 0.42220864157003857, disc_loss = 0.0006285898003190116
Trained batch 163 in epoch 9, gen_loss = 0.42233878410444026, disc_loss = 0.0006303696431043535
Trained batch 164 in epoch 9, gen_loss = 0.42217567472746875, disc_loss = 0.0006297060228517336
Trained batch 165 in epoch 9, gen_loss = 0.4221722332828016, disc_loss = 0.0006301667410122926
Trained batch 166 in epoch 9, gen_loss = 0.4219258779180264, disc_loss = 0.0006308322723586849
Trained batch 167 in epoch 9, gen_loss = 0.4219153869364943, disc_loss = 0.0006324682381957592
Trained batch 168 in epoch 9, gen_loss = 0.4216344645742834, disc_loss = 0.0006344640481467607
Trained batch 169 in epoch 9, gen_loss = 0.42131856469547047, disc_loss = 0.00063662795788225
Trained batch 170 in epoch 9, gen_loss = 0.42117685881274486, disc_loss = 0.0006363144834057499
Trained batch 171 in epoch 9, gen_loss = 0.4209455036839774, disc_loss = 0.0006348347747535987
Trained batch 172 in epoch 9, gen_loss = 0.42067532267184615, disc_loss = 0.0006344241017443424
Trained batch 173 in epoch 9, gen_loss = 0.4204535736092206, disc_loss = 0.0006342519324904457
Trained batch 174 in epoch 9, gen_loss = 0.4206258724417005, disc_loss = 0.0006345790301981781
Trained batch 175 in epoch 9, gen_loss = 0.4213208161633123, disc_loss = 0.0006371964009304065
Trained batch 176 in epoch 9, gen_loss = 0.4211703520373436, disc_loss = 0.0006358397626028643
Trained batch 177 in epoch 9, gen_loss = 0.4207957931114047, disc_loss = 0.0006338398811391691
Trained batch 178 in epoch 9, gen_loss = 0.420767532547093, disc_loss = 0.0006332165212370455
Trained batch 179 in epoch 9, gen_loss = 0.42112858908043965, disc_loss = 0.0006328311661491171
Trained batch 180 in epoch 9, gen_loss = 0.42095013679061805, disc_loss = 0.0006321325231837469
Trained batch 181 in epoch 9, gen_loss = 0.4206861938749041, disc_loss = 0.0006323395831674173
Trained batch 182 in epoch 9, gen_loss = 0.42042827573630326, disc_loss = 0.0006328668557311016
Trained batch 183 in epoch 9, gen_loss = 0.41995619836708775, disc_loss = 0.0006323854189679918
Trained batch 184 in epoch 9, gen_loss = 0.4200956157735876, disc_loss = 0.0006330380977660015
Trained batch 185 in epoch 9, gen_loss = 0.42019595814648497, disc_loss = 0.0006318986447157479
Trained batch 186 in epoch 9, gen_loss = 0.41967156784419707, disc_loss = 0.0006311060221091331
Trained batch 187 in epoch 9, gen_loss = 0.4198402832163141, disc_loss = 0.0006309043626273745
Trained batch 188 in epoch 9, gen_loss = 0.4199578806206032, disc_loss = 0.0006305061842169534
Trained batch 189 in epoch 9, gen_loss = 0.4198827549030906, disc_loss = 0.0006291926012827868
Trained batch 190 in epoch 9, gen_loss = 0.4201721602085373, disc_loss = 0.0006300001336610266
Trained batch 191 in epoch 9, gen_loss = 0.42015571147203445, disc_loss = 0.0006287401217074754
Trained batch 192 in epoch 9, gen_loss = 0.4202146275364673, disc_loss = 0.0006278871258218903
Trained batch 193 in epoch 9, gen_loss = 0.4202954314418675, disc_loss = 0.0006268181533255067
Trained batch 194 in epoch 9, gen_loss = 0.42019156385690737, disc_loss = 0.0006255549226457683
Trained batch 195 in epoch 9, gen_loss = 0.4204907628650568, disc_loss = 0.0006246849645359195
Trained batch 196 in epoch 9, gen_loss = 0.4207469937462492, disc_loss = 0.000623535668757522
Trained batch 197 in epoch 9, gen_loss = 0.42078844360028855, disc_loss = 0.0006227612785284756
Trained batch 198 in epoch 9, gen_loss = 0.42067617881837205, disc_loss = 0.0006222736360107422
Trained batch 199 in epoch 9, gen_loss = 0.4207888260483742, disc_loss = 0.000622248609433882
Trained batch 200 in epoch 9, gen_loss = 0.42066561375091327, disc_loss = 0.0006307151651621532
Trained batch 201 in epoch 9, gen_loss = 0.42058251798152924, disc_loss = 0.0006339494605769984
Trained batch 202 in epoch 9, gen_loss = 0.4206567946913207, disc_loss = 0.0006343493899881032
Trained batch 203 in epoch 9, gen_loss = 0.42047522114772423, disc_loss = 0.0006333416518721017
Trained batch 204 in epoch 9, gen_loss = 0.4204411868642016, disc_loss = 0.0006328770721887761
Trained batch 205 in epoch 9, gen_loss = 0.420580206999501, disc_loss = 0.0006332385077681483
Trained batch 206 in epoch 9, gen_loss = 0.42054552314937976, disc_loss = 0.000633775191195984
Trained batch 207 in epoch 9, gen_loss = 0.420681307808711, disc_loss = 0.0006345407325100566
Trained batch 208 in epoch 9, gen_loss = 0.42072821633097085, disc_loss = 0.0006337320638439534
Trained batch 209 in epoch 9, gen_loss = 0.4209021863483247, disc_loss = 0.0006329407512177048
Trained batch 210 in epoch 9, gen_loss = 0.42071427440191334, disc_loss = 0.0006316721023356109
Trained batch 211 in epoch 9, gen_loss = 0.4206070375611197, disc_loss = 0.000630463843611684
Trained batch 212 in epoch 9, gen_loss = 0.4206588944079171, disc_loss = 0.0006293118480448676
Trained batch 213 in epoch 9, gen_loss = 0.42104128964036425, disc_loss = 0.0006288360123235349
Trained batch 214 in epoch 9, gen_loss = 0.421142884742382, disc_loss = 0.0006277386905885366
Trained batch 215 in epoch 9, gen_loss = 0.42105412234862644, disc_loss = 0.0006261543644035959
Trained batch 216 in epoch 9, gen_loss = 0.4209787315487312, disc_loss = 0.0006244379033501934
Trained batch 217 in epoch 9, gen_loss = 0.4208473254234419, disc_loss = 0.0006229948624114104
Trained batch 218 in epoch 9, gen_loss = 0.4208757490872248, disc_loss = 0.0006224537245954757
Trained batch 219 in epoch 9, gen_loss = 0.42086336423050275, disc_loss = 0.0006227594763252207
Trained batch 220 in epoch 9, gen_loss = 0.42090643436660596, disc_loss = 0.0006217903626673935
Trained batch 221 in epoch 9, gen_loss = 0.42110621150549465, disc_loss = 0.0006219780941489614
Trained batch 222 in epoch 9, gen_loss = 0.4209771971531513, disc_loss = 0.0006210389432200802
Trained batch 223 in epoch 9, gen_loss = 0.42109246605208944, disc_loss = 0.0006218690066037068
Trained batch 224 in epoch 9, gen_loss = 0.4208914613723755, disc_loss = 0.0006206538854166866
Trained batch 225 in epoch 9, gen_loss = 0.4210231922632825, disc_loss = 0.0006198518067563315
Trained batch 226 in epoch 9, gen_loss = 0.4208313369803492, disc_loss = 0.0006202435981746894
Trained batch 227 in epoch 9, gen_loss = 0.4206018300171484, disc_loss = 0.0006217635758762379
Trained batch 228 in epoch 9, gen_loss = 0.42052399331305224, disc_loss = 0.0006235981428452796
Trained batch 229 in epoch 9, gen_loss = 0.4205770951250325, disc_loss = 0.0006237893973973216
Trained batch 230 in epoch 9, gen_loss = 0.42041146303668164, disc_loss = 0.0006225453756469427
Trained batch 231 in epoch 9, gen_loss = 0.4201764799654484, disc_loss = 0.0006212620582714565
Trained batch 232 in epoch 9, gen_loss = 0.4201478519409, disc_loss = 0.0006214091935256984
Trained batch 233 in epoch 9, gen_loss = 0.42028863256813115, disc_loss = 0.0006215433033161327
Trained batch 234 in epoch 9, gen_loss = 0.4202588233541935, disc_loss = 0.0006213249451669052
Trained batch 235 in epoch 9, gen_loss = 0.4201800254947048, disc_loss = 0.0006208098909109279
Trained batch 236 in epoch 9, gen_loss = 0.4200341348155138, disc_loss = 0.0006198927823735111
Trained batch 237 in epoch 9, gen_loss = 0.41992434583792165, disc_loss = 0.000618934040099672
Trained batch 238 in epoch 9, gen_loss = 0.4201200259031112, disc_loss = 0.0006204759601014569
Trained batch 239 in epoch 9, gen_loss = 0.4202633876353502, disc_loss = 0.000619593022444557
Trained batch 240 in epoch 9, gen_loss = 0.4202754663233935, disc_loss = 0.000620546354984679
Trained batch 241 in epoch 9, gen_loss = 0.41999687882494335, disc_loss = 0.0006212893634609309
Trained batch 242 in epoch 9, gen_loss = 0.42014068978313557, disc_loss = 0.0006215960502867882
Trained batch 243 in epoch 9, gen_loss = 0.4202168364016736, disc_loss = 0.0006209988553519742
Trained batch 244 in epoch 9, gen_loss = 0.4202778486572966, disc_loss = 0.0006201182435057602
Trained batch 245 in epoch 9, gen_loss = 0.4201674065211924, disc_loss = 0.0006199158097303101
Trained batch 246 in epoch 9, gen_loss = 0.420390688576679, disc_loss = 0.0006204771470874246
Trained batch 247 in epoch 9, gen_loss = 0.42049305465432907, disc_loss = 0.0006202488537735096
Trained batch 248 in epoch 9, gen_loss = 0.4206145660704877, disc_loss = 0.0006199353423631605
Trained batch 249 in epoch 9, gen_loss = 0.4206165933609009, disc_loss = 0.0006203336513135582
Trained batch 250 in epoch 9, gen_loss = 0.4205963812263838, disc_loss = 0.0006211482322834195
Trained batch 251 in epoch 9, gen_loss = 0.42087620875192067, disc_loss = 0.0006221202779598239
Trained batch 252 in epoch 9, gen_loss = 0.42100626913455164, disc_loss = 0.0006220377135005864
Trained batch 253 in epoch 9, gen_loss = 0.4210095134541744, disc_loss = 0.0006217580846892156
Trained batch 254 in epoch 9, gen_loss = 0.42100748478197586, disc_loss = 0.0006215438045853493
Trained batch 255 in epoch 9, gen_loss = 0.4212046052562073, disc_loss = 0.0006213732599462674
Trained batch 256 in epoch 9, gen_loss = 0.42121941744121594, disc_loss = 0.0006209327902731845
Trained batch 257 in epoch 9, gen_loss = 0.42117712248203365, disc_loss = 0.00062034072628779
Trained batch 258 in epoch 9, gen_loss = 0.4212329393418139, disc_loss = 0.0006197497445746581
Trained batch 259 in epoch 9, gen_loss = 0.42097801967309073, disc_loss = 0.0006204521284626725
Trained batch 260 in epoch 9, gen_loss = 0.4211122258869624, disc_loss = 0.0006235426661363978
Trained batch 261 in epoch 9, gen_loss = 0.4210516350869914, disc_loss = 0.0006240274432117034
Trained batch 262 in epoch 9, gen_loss = 0.42097237706184387, disc_loss = 0.0006231027896544354
Trained batch 263 in epoch 9, gen_loss = 0.42096438574971573, disc_loss = 0.0006223847959710948
Trained batch 264 in epoch 9, gen_loss = 0.42084929470746024, disc_loss = 0.0006215157033436281
Trained batch 265 in epoch 9, gen_loss = 0.42088347404523, disc_loss = 0.000620690044855937
Trained batch 266 in epoch 9, gen_loss = 0.42099520619888875, disc_loss = 0.0006204789074064557
Trained batch 267 in epoch 9, gen_loss = 0.42089673854521853, disc_loss = 0.0006199750579926602
Trained batch 268 in epoch 9, gen_loss = 0.42088815625272274, disc_loss = 0.0006192541085304796
Trained batch 269 in epoch 9, gen_loss = 0.42098166788065877, disc_loss = 0.0006188882706704101
Trained batch 270 in epoch 9, gen_loss = 0.4207296861933606, disc_loss = 0.0006181056956190107
Trained batch 271 in epoch 9, gen_loss = 0.4208580356310396, disc_loss = 0.0006173076810013942
Trained batch 272 in epoch 9, gen_loss = 0.4208419864430969, disc_loss = 0.0006162137016585786
Trained batch 273 in epoch 9, gen_loss = 0.4208037137550159, disc_loss = 0.0006153702718481068
Trained batch 274 in epoch 9, gen_loss = 0.42096031362360176, disc_loss = 0.0006147816190919416
Trained batch 275 in epoch 9, gen_loss = 0.4210789615045423, disc_loss = 0.0006140819908899215
Trained batch 276 in epoch 9, gen_loss = 0.4211615962026782, disc_loss = 0.0006134037501245925
Trained batch 277 in epoch 9, gen_loss = 0.42111847544316766, disc_loss = 0.0006136027266934729
Trained batch 278 in epoch 9, gen_loss = 0.42100679158737153, disc_loss = 0.0006153244265658935
Trained batch 279 in epoch 9, gen_loss = 0.42097782056246486, disc_loss = 0.0006168897953882282
Trained batch 280 in epoch 9, gen_loss = 0.42103972309849014, disc_loss = 0.0006170103699714608
Trained batch 281 in epoch 9, gen_loss = 0.42085629469113994, disc_loss = 0.000616639020690919
Trained batch 282 in epoch 9, gen_loss = 0.42100198961820706, disc_loss = 0.0006173118638769845
Trained batch 283 in epoch 9, gen_loss = 0.42089684171156144, disc_loss = 0.0006167461028204523
Trained batch 284 in epoch 9, gen_loss = 0.42106002820165533, disc_loss = 0.0006162442789788831
Trained batch 285 in epoch 9, gen_loss = 0.42101219296455383, disc_loss = 0.0006156357479854845
Trained batch 286 in epoch 9, gen_loss = 0.421042090508996, disc_loss = 0.0006160026092491135
Trained batch 287 in epoch 9, gen_loss = 0.4212232765017284, disc_loss = 0.0006167514010384264
Trained batch 288 in epoch 9, gen_loss = 0.4214140436641073, disc_loss = 0.0006169037195325387
Trained batch 289 in epoch 9, gen_loss = 0.4216406009320555, disc_loss = 0.0006176163137344451
Trained batch 290 in epoch 9, gen_loss = 0.42154078190678995, disc_loss = 0.0006170123217457784
Trained batch 291 in epoch 9, gen_loss = 0.4217476896839599, disc_loss = 0.0006167649328134545
Trained batch 292 in epoch 9, gen_loss = 0.42184143393926654, disc_loss = 0.0006170043763116562
Trained batch 293 in epoch 9, gen_loss = 0.4218327730488615, disc_loss = 0.0006165320016475407
Trained batch 294 in epoch 9, gen_loss = 0.4217656559863333, disc_loss = 0.000616065068348011
Trained batch 295 in epoch 9, gen_loss = 0.42194702023187197, disc_loss = 0.0006164516837727844
Trained batch 296 in epoch 9, gen_loss = 0.4219886102660336, disc_loss = 0.0006158276035188562
Trained batch 297 in epoch 9, gen_loss = 0.421964621783903, disc_loss = 0.0006154180367066268
Trained batch 298 in epoch 9, gen_loss = 0.4219115567845246, disc_loss = 0.0006153099621407825
Trained batch 299 in epoch 9, gen_loss = 0.42186964392662046, disc_loss = 0.0006144777339068242
Trained batch 300 in epoch 9, gen_loss = 0.4219978986388425, disc_loss = 0.0006139262869839627
Trained batch 301 in epoch 9, gen_loss = 0.42204568944624715, disc_loss = 0.0006141414056726368
Trained batch 302 in epoch 9, gen_loss = 0.4219848624747185, disc_loss = 0.0006135854087831458
Trained batch 303 in epoch 9, gen_loss = 0.4221216507844235, disc_loss = 0.0006140236856529219
Trained batch 304 in epoch 9, gen_loss = 0.4222043718470902, disc_loss = 0.0006161215423117774
Trained batch 305 in epoch 9, gen_loss = 0.42199380091981953, disc_loss = 0.0006167813068411002
Trained batch 306 in epoch 9, gen_loss = 0.4220351488465983, disc_loss = 0.0006181179905683408
Trained batch 307 in epoch 9, gen_loss = 0.4220893650085895, disc_loss = 0.0006184471816855616
Trained batch 308 in epoch 9, gen_loss = 0.4220718398063314, disc_loss = 0.0006202867273075513
Trained batch 309 in epoch 9, gen_loss = 0.4219883619777618, disc_loss = 0.0006220580779031039
Trained batch 310 in epoch 9, gen_loss = 0.4219190864509325, disc_loss = 0.000623636697291717
Trained batch 311 in epoch 9, gen_loss = 0.4218233837149082, disc_loss = 0.0006239852136320387
Trained batch 312 in epoch 9, gen_loss = 0.42177189110567015, disc_loss = 0.0006241477970495082
Trained batch 313 in epoch 9, gen_loss = 0.42163791521719307, disc_loss = 0.0006239713602669679
Trained batch 314 in epoch 9, gen_loss = 0.4215894845743028, disc_loss = 0.0006244084783016689
Trained batch 315 in epoch 9, gen_loss = 0.42143733261884014, disc_loss = 0.0006243266512292048
Trained batch 316 in epoch 9, gen_loss = 0.42138252639996143, disc_loss = 0.0006242384392274573
Trained batch 317 in epoch 9, gen_loss = 0.4213954445513539, disc_loss = 0.0006235637033941026
Trained batch 318 in epoch 9, gen_loss = 0.4213001675740305, disc_loss = 0.0006228012321473079
Trained batch 319 in epoch 9, gen_loss = 0.4213964506983757, disc_loss = 0.000622305519573274
Trained batch 320 in epoch 9, gen_loss = 0.4214459139610005, disc_loss = 0.0006214053850770402
Trained batch 321 in epoch 9, gen_loss = 0.42141738450675276, disc_loss = 0.0006206055130753145
Trained batch 322 in epoch 9, gen_loss = 0.42153101264507775, disc_loss = 0.0006207328989140217
Trained batch 323 in epoch 9, gen_loss = 0.4216526845171128, disc_loss = 0.000621041049911313
Trained batch 324 in epoch 9, gen_loss = 0.4215066487055558, disc_loss = 0.0006201142025215981
Trained batch 325 in epoch 9, gen_loss = 0.42172614261050895, disc_loss = 0.0006204239785366983
Trained batch 326 in epoch 9, gen_loss = 0.42170175171773366, disc_loss = 0.0006200366815308604
Trained batch 327 in epoch 9, gen_loss = 0.42175795873854216, disc_loss = 0.0006199082115305894
Trained batch 328 in epoch 9, gen_loss = 0.42173450605485213, disc_loss = 0.0006198971533169828
Trained batch 329 in epoch 9, gen_loss = 0.4217628831213171, disc_loss = 0.0006206665709297258
Trained batch 330 in epoch 9, gen_loss = 0.42188526730523007, disc_loss = 0.0006216380881811028
Trained batch 331 in epoch 9, gen_loss = 0.42158818334700116, disc_loss = 0.000623872349791212
Trained batch 332 in epoch 9, gen_loss = 0.4215901871701261, disc_loss = 0.0006243926416152624
Trained batch 333 in epoch 9, gen_loss = 0.4215719276916481, disc_loss = 0.0006245107613580613
Trained batch 334 in epoch 9, gen_loss = 0.4213975828974994, disc_loss = 0.0006236639760830787
Trained batch 335 in epoch 9, gen_loss = 0.42125635638478254, disc_loss = 0.0006233496118338302
Trained batch 336 in epoch 9, gen_loss = 0.4211911515772166, disc_loss = 0.0006230069882787753
Trained batch 337 in epoch 9, gen_loss = 0.42123228602508117, disc_loss = 0.0006226118909403097
Trained batch 338 in epoch 9, gen_loss = 0.4211752642396629, disc_loss = 0.0006217529873087574
Trained batch 339 in epoch 9, gen_loss = 0.4210549101233482, disc_loss = 0.0006209133691085941
Trained batch 340 in epoch 9, gen_loss = 0.42101350872397775, disc_loss = 0.0006197848909208824
Trained batch 341 in epoch 9, gen_loss = 0.4211830641442572, disc_loss = 0.000619547727661771
Trained batch 342 in epoch 9, gen_loss = 0.421175877571801, disc_loss = 0.0006187058222509307
Trained batch 343 in epoch 9, gen_loss = 0.4211339840535508, disc_loss = 0.0006176407604534476
Trained batch 344 in epoch 9, gen_loss = 0.42105490496193154, disc_loss = 0.0006166953814091107
Trained batch 345 in epoch 9, gen_loss = 0.42084340277434773, disc_loss = 0.0006157320230910582
Trained batch 346 in epoch 9, gen_loss = 0.42075446514300036, disc_loss = 0.0006152168418276083
Trained batch 347 in epoch 9, gen_loss = 0.42074265108368863, disc_loss = 0.0006143057162471346
Trained batch 348 in epoch 9, gen_loss = 0.4207660490086564, disc_loss = 0.0006141806620337939
Trained batch 349 in epoch 9, gen_loss = 0.420721931542669, disc_loss = 0.0006159014142966563
Trained batch 350 in epoch 9, gen_loss = 0.42062535092361975, disc_loss = 0.000615763278109913
Trained batch 351 in epoch 9, gen_loss = 0.420302972112867, disc_loss = 0.000616636758712213
Trained batch 352 in epoch 9, gen_loss = 0.42051145924049466, disc_loss = 0.0006166342482226044
Trained batch 353 in epoch 9, gen_loss = 0.42051330393990555, disc_loss = 0.0006174237258442267
Trained batch 354 in epoch 9, gen_loss = 0.42061450103638875, disc_loss = 0.0006199394080141874
Trained batch 355 in epoch 9, gen_loss = 0.4207613998082247, disc_loss = 0.0006223781909672622
Trained batch 356 in epoch 9, gen_loss = 0.42078510160539667, disc_loss = 0.0006250144410549066
Trained batch 357 in epoch 9, gen_loss = 0.42078309560288263, disc_loss = 0.0006289727736362672
Trained batch 358 in epoch 9, gen_loss = 0.42069567719209827, disc_loss = 0.0006299837187829513
Trained batch 359 in epoch 9, gen_loss = 0.4206918845574061, disc_loss = 0.0006295167974005582
Trained batch 360 in epoch 9, gen_loss = 0.42073161664761993, disc_loss = 0.0006301958266522482
Trained batch 361 in epoch 9, gen_loss = 0.4207255590027867, disc_loss = 0.0006298851069446926
Trained batch 362 in epoch 9, gen_loss = 0.4208080066629678, disc_loss = 0.0006309757748770735
Trained batch 363 in epoch 9, gen_loss = 0.4209001685728084, disc_loss = 0.0006319645520476855
Trained batch 364 in epoch 9, gen_loss = 0.42116237086792513, disc_loss = 0.0006322366908297887
Trained batch 365 in epoch 9, gen_loss = 0.42104105195386815, disc_loss = 0.000633006384623265
Trained batch 366 in epoch 9, gen_loss = 0.4210941720073814, disc_loss = 0.0006345044479312689
Trained batch 367 in epoch 9, gen_loss = 0.4209847154662661, disc_loss = 0.0006343595735850851
Trained batch 368 in epoch 9, gen_loss = 0.4210678232394583, disc_loss = 0.0006342591332706438
Trained batch 369 in epoch 9, gen_loss = 0.42090716088140334, disc_loss = 0.0006339112353728253
Trained batch 370 in epoch 9, gen_loss = 0.4207713350131505, disc_loss = 0.0006329534472812926
Trained batch 371 in epoch 9, gen_loss = 0.42090665533017085, disc_loss = 0.0006322939989331644
Trained batch 372 in epoch 9, gen_loss = 0.4208707714368447, disc_loss = 0.0006320906907801289
Trained batch 373 in epoch 9, gen_loss = 0.420535237234544, disc_loss = 0.0006314116276979302
Trained batch 374 in epoch 9, gen_loss = 0.4203955825169881, disc_loss = 0.0006316240798914805
Trained batch 375 in epoch 9, gen_loss = 0.42045915499329567, disc_loss = 0.000632010764209244
Trained batch 376 in epoch 9, gen_loss = 0.42046148707442954, disc_loss = 0.0006323321887266647
Trained batch 377 in epoch 9, gen_loss = 0.4202568485307946, disc_loss = 0.0006317159265452853
Trained batch 378 in epoch 9, gen_loss = 0.4202452998677156, disc_loss = 0.0006311327507513597
Trained batch 379 in epoch 9, gen_loss = 0.4202672350563501, disc_loss = 0.0006308077557677232
Trained batch 380 in epoch 9, gen_loss = 0.4202241638670443, disc_loss = 0.0006304890791023287
Trained batch 381 in epoch 9, gen_loss = 0.420301582332681, disc_loss = 0.000629873288692041
Trained batch 382 in epoch 9, gen_loss = 0.42040544296991733, disc_loss = 0.0006290669556401363
Trained batch 383 in epoch 9, gen_loss = 0.4202542947605252, disc_loss = 0.0006284236629123067
Trained batch 384 in epoch 9, gen_loss = 0.4202524810642391, disc_loss = 0.0006276173850101141
Trained batch 385 in epoch 9, gen_loss = 0.4201475147138605, disc_loss = 0.0006269982022880529
Trained batch 386 in epoch 9, gen_loss = 0.420096387080752, disc_loss = 0.0006268432271592825
Trained batch 387 in epoch 9, gen_loss = 0.42018287229476514, disc_loss = 0.0006268257155582986
Trained batch 388 in epoch 9, gen_loss = 0.4201893566659913, disc_loss = 0.0006262278253500467
Trained batch 389 in epoch 9, gen_loss = 0.4202899050254088, disc_loss = 0.0006261477411429111
Trained batch 390 in epoch 9, gen_loss = 0.4201073334802447, disc_loss = 0.0006265930423606544
Trained batch 391 in epoch 9, gen_loss = 0.4199621447038894, disc_loss = 0.0006276842592268046
Trained batch 392 in epoch 9, gen_loss = 0.4200599259547605, disc_loss = 0.0006285975875677162
Trained batch 393 in epoch 9, gen_loss = 0.4201734491865042, disc_loss = 0.0006284010268970591
Trained batch 394 in epoch 9, gen_loss = 0.42016147850434993, disc_loss = 0.0006279224547914146
Trained batch 395 in epoch 9, gen_loss = 0.42025452242656186, disc_loss = 0.0006275627564893438
Trained batch 396 in epoch 9, gen_loss = 0.4202693941010636, disc_loss = 0.0006272592972181104
Trained batch 397 in epoch 9, gen_loss = 0.4204299085254046, disc_loss = 0.0006271877245121664
Trained batch 398 in epoch 9, gen_loss = 0.4203773549475467, disc_loss = 0.0006265214750211205
Trained batch 399 in epoch 9, gen_loss = 0.42022630527615545, disc_loss = 0.0006257093729436746
Trained batch 400 in epoch 9, gen_loss = 0.42023072129770406, disc_loss = 0.0006255077791764306
Trained batch 401 in epoch 9, gen_loss = 0.42012498005112603, disc_loss = 0.0006251846942503297
Trained batch 402 in epoch 9, gen_loss = 0.4201325823740095, disc_loss = 0.0006251393917531455
Trained batch 403 in epoch 9, gen_loss = 0.4201634793293358, disc_loss = 0.0006247876260050983
Trained batch 404 in epoch 9, gen_loss = 0.4201173404116689, disc_loss = 0.0006239751316851327
Trained batch 405 in epoch 9, gen_loss = 0.420055064808559, disc_loss = 0.0006230811915991786
Trained batch 406 in epoch 9, gen_loss = 0.4201052708766384, disc_loss = 0.0006222878160519772
Trained batch 407 in epoch 9, gen_loss = 0.4200790987587443, disc_loss = 0.0006214466713715286
Trained batch 408 in epoch 9, gen_loss = 0.4201183262984735, disc_loss = 0.0006208652534028561
Trained batch 409 in epoch 9, gen_loss = 0.4201072947281163, disc_loss = 0.0006207535304938352
Trained batch 410 in epoch 9, gen_loss = 0.42007124141184954, disc_loss = 0.0006213388076109286
Trained batch 411 in epoch 9, gen_loss = 0.41998637851002146, disc_loss = 0.0006220320315460236
Trained batch 412 in epoch 9, gen_loss = 0.41985032106715886, disc_loss = 0.0006224422688614554
Trained batch 413 in epoch 9, gen_loss = 0.419767111107923, disc_loss = 0.0006219436096295755
Trained batch 414 in epoch 9, gen_loss = 0.4197767310113792, disc_loss = 0.0006216613235336403
Trained batch 415 in epoch 9, gen_loss = 0.41987103847070384, disc_loss = 0.0006211118567569848
Trained batch 416 in epoch 9, gen_loss = 0.4199259169667745, disc_loss = 0.0006206374232893434
Trained batch 417 in epoch 9, gen_loss = 0.4199862850197194, disc_loss = 0.0006202743157204663
Trained batch 418 in epoch 9, gen_loss = 0.4200296963171629, disc_loss = 0.0006200165547492196
Trained batch 419 in epoch 9, gen_loss = 0.42001457739444004, disc_loss = 0.0006197400020720947
Trained batch 420 in epoch 9, gen_loss = 0.42021593019684816, disc_loss = 0.0006194169500153047
Trained batch 421 in epoch 9, gen_loss = 0.4201730262329228, disc_loss = 0.0006199604746462419
Trained batch 422 in epoch 9, gen_loss = 0.4201533804971276, disc_loss = 0.0006221745727183606
Trained batch 423 in epoch 9, gen_loss = 0.4200018160045147, disc_loss = 0.0006246832205229197
Trained batch 424 in epoch 9, gen_loss = 0.4198577279904309, disc_loss = 0.0006266315780265037
Trained batch 425 in epoch 9, gen_loss = 0.4197181589866468, disc_loss = 0.0006278548286170174
Trained batch 426 in epoch 9, gen_loss = 0.4198777495558424, disc_loss = 0.0006280982675288741
Trained batch 427 in epoch 9, gen_loss = 0.41983558467336907, disc_loss = 0.0006275636638815527
Trained batch 428 in epoch 9, gen_loss = 0.4197886732769457, disc_loss = 0.0006271342005478088
Trained batch 429 in epoch 9, gen_loss = 0.4199233075907064, disc_loss = 0.0006267468080528319
Trained batch 430 in epoch 9, gen_loss = 0.41988892358859564, disc_loss = 0.0006262506497092005
Trained batch 431 in epoch 9, gen_loss = 0.419912118602682, disc_loss = 0.0006255860112947563
Trained batch 432 in epoch 9, gen_loss = 0.41985666676151284, disc_loss = 0.0006250257418782926
Trained batch 433 in epoch 9, gen_loss = 0.4199736519343293, disc_loss = 0.0006251386822453992
Trained batch 434 in epoch 9, gen_loss = 0.4201232983463112, disc_loss = 0.0006269890718341366
Trained batch 435 in epoch 9, gen_loss = 0.4200409319969492, disc_loss = 0.0006285931972384671
Trained batch 436 in epoch 9, gen_loss = 0.42001308231386497, disc_loss = 0.0006293044992638922
Trained batch 437 in epoch 9, gen_loss = 0.419959458518246, disc_loss = 0.0006291807994826433
Trained batch 438 in epoch 9, gen_loss = 0.4198438422011895, disc_loss = 0.0006295689161225691
Trained batch 439 in epoch 9, gen_loss = 0.4196333278986541, disc_loss = 0.0006310161491207757
Trained batch 440 in epoch 9, gen_loss = 0.41968736282281593, disc_loss = 0.0006316863498985746
Trained batch 441 in epoch 9, gen_loss = 0.4196290468198681, disc_loss = 0.0006311886962774479
Trained batch 442 in epoch 9, gen_loss = 0.4195775477127351, disc_loss = 0.0006318041329410318
Trained batch 443 in epoch 9, gen_loss = 0.4195413361261557, disc_loss = 0.0006322854981893519
Trained batch 444 in epoch 9, gen_loss = 0.41967675739459775, disc_loss = 0.0006335676258908626
Trained batch 445 in epoch 9, gen_loss = 0.41970171722596, disc_loss = 0.0006330302146651298
Trained batch 446 in epoch 9, gen_loss = 0.4197502382916359, disc_loss = 0.0006323507516548533
Trained batch 447 in epoch 9, gen_loss = 0.41980464157781433, disc_loss = 0.0006321118262024226
Trained batch 448 in epoch 9, gen_loss = 0.419689895514656, disc_loss = 0.0006312925052164819
Trained batch 449 in epoch 9, gen_loss = 0.41959568096531763, disc_loss = 0.0006311292087128903
Trained batch 450 in epoch 9, gen_loss = 0.4196260962676579, disc_loss = 0.0006305958116166355
Trained batch 451 in epoch 9, gen_loss = 0.4196073892237866, disc_loss = 0.000630292530444325
Trained batch 452 in epoch 9, gen_loss = 0.41972075169186457, disc_loss = 0.0006300480746873295
Trained batch 453 in epoch 9, gen_loss = 0.41966383920629646, disc_loss = 0.0006292518541447117
Trained batch 454 in epoch 9, gen_loss = 0.4196072697639465, disc_loss = 0.000628715651116211
Trained batch 455 in epoch 9, gen_loss = 0.4196770393142575, disc_loss = 0.0006279519863726403
Trained batch 456 in epoch 9, gen_loss = 0.41964157978867545, disc_loss = 0.0006276845912073578
Trained batch 457 in epoch 9, gen_loss = 0.41951417753790143, disc_loss = 0.0006274607443486088
Trained batch 458 in epoch 9, gen_loss = 0.4194541704680665, disc_loss = 0.00062712153051711
Trained batch 459 in epoch 9, gen_loss = 0.419495181221029, disc_loss = 0.0006271360930796895
Trained batch 460 in epoch 9, gen_loss = 0.4195422082816184, disc_loss = 0.0006268241732452497
Trained batch 461 in epoch 9, gen_loss = 0.4196730014823732, disc_loss = 0.000626580399775815
Trained batch 462 in epoch 9, gen_loss = 0.41970578666382163, disc_loss = 0.0006259224280077847
Trained batch 463 in epoch 9, gen_loss = 0.4195814289409539, disc_loss = 0.0006253475529743371
Trained batch 464 in epoch 9, gen_loss = 0.41940508132339804, disc_loss = 0.0006249048181631733
Trained batch 465 in epoch 9, gen_loss = 0.4194287487621471, disc_loss = 0.0006246892089894053
Trained batch 466 in epoch 9, gen_loss = 0.4193231925464034, disc_loss = 0.0006243462801267287
Trained batch 467 in epoch 9, gen_loss = 0.4193031109041638, disc_loss = 0.000623770706181695
Trained batch 468 in epoch 9, gen_loss = 0.41927557459263914, disc_loss = 0.0006233275803026936
Trained batch 469 in epoch 9, gen_loss = 0.41917274251897285, disc_loss = 0.0006232139840536315
Trained batch 470 in epoch 9, gen_loss = 0.41923928051997145, disc_loss = 0.0006232973632875795
Trained batch 471 in epoch 9, gen_loss = 0.4193228303881015, disc_loss = 0.0006236296881918137
Trained batch 472 in epoch 9, gen_loss = 0.41949477646870037, disc_loss = 0.0006235482639854136
Trained batch 473 in epoch 9, gen_loss = 0.4195025533060484, disc_loss = 0.0006236429627405633
Trained batch 474 in epoch 9, gen_loss = 0.41947949597710055, disc_loss = 0.0006240113393562895
Trained batch 475 in epoch 9, gen_loss = 0.41940265831326234, disc_loss = 0.0006237670712521742
Trained batch 476 in epoch 9, gen_loss = 0.41951449281014735, disc_loss = 0.0006231669279753056
Trained batch 477 in epoch 9, gen_loss = 0.41940718951584405, disc_loss = 0.000622742533447293
Trained batch 478 in epoch 9, gen_loss = 0.41935260895647436, disc_loss = 0.0006225541771920826
Trained batch 479 in epoch 9, gen_loss = 0.4192769496391217, disc_loss = 0.0006223937770907166
Trained batch 480 in epoch 9, gen_loss = 0.4193544487571518, disc_loss = 0.0006218830241471735
Trained batch 481 in epoch 9, gen_loss = 0.41938714274974287, disc_loss = 0.0006217496577156147
Trained batch 482 in epoch 9, gen_loss = 0.41933385055998096, disc_loss = 0.0006211896986576707
Trained batch 483 in epoch 9, gen_loss = 0.4193181010686662, disc_loss = 0.0006210292009230269
Trained batch 484 in epoch 9, gen_loss = 0.4192781657287755, disc_loss = 0.000621810921356226
Trained batch 485 in epoch 9, gen_loss = 0.4192184996580391, disc_loss = 0.0006231245774439911
Trained batch 486 in epoch 9, gen_loss = 0.4190565254042036, disc_loss = 0.0006255539490263316
Trained batch 487 in epoch 9, gen_loss = 0.4190207072457329, disc_loss = 0.0006270699349905224
Trained batch 488 in epoch 9, gen_loss = 0.41896092001889623, disc_loss = 0.0006276993640136175
Trained batch 489 in epoch 9, gen_loss = 0.4187471859309138, disc_loss = 0.0006277860393830841
Trained batch 490 in epoch 9, gen_loss = 0.418720411853732, disc_loss = 0.0006273408293714102
Trained batch 491 in epoch 9, gen_loss = 0.41873802929147474, disc_loss = 0.0006268385992533569
Trained batch 492 in epoch 9, gen_loss = 0.4186872337580211, disc_loss = 0.0006275127137291886
Trained batch 493 in epoch 9, gen_loss = 0.4187530030605764, disc_loss = 0.000629885658332635
Trained batch 494 in epoch 9, gen_loss = 0.418652174268106, disc_loss = 0.0006307418211516125
Trained batch 495 in epoch 9, gen_loss = 0.41866544706206166, disc_loss = 0.0006305200066626346
Trained batch 496 in epoch 9, gen_loss = 0.41879684506527615, disc_loss = 0.0006304268629003928
Trained batch 497 in epoch 9, gen_loss = 0.4188621458878, disc_loss = 0.0006298441140354708
Trained batch 498 in epoch 9, gen_loss = 0.41886590442103233, disc_loss = 0.0006293212542161513
Trained batch 499 in epoch 9, gen_loss = 0.41889842265844346, disc_loss = 0.0006290520084148739
Trained batch 500 in epoch 9, gen_loss = 0.4188691159922206, disc_loss = 0.0006288710204401553
Trained batch 501 in epoch 9, gen_loss = 0.41884300736079655, disc_loss = 0.0006289070107627649
Trained batch 502 in epoch 9, gen_loss = 0.41883631515692527, disc_loss = 0.0006294705688679836
Trained batch 503 in epoch 9, gen_loss = 0.41882331976814874, disc_loss = 0.0006301472339622532
Trained batch 504 in epoch 9, gen_loss = 0.4189098536968231, disc_loss = 0.0006297315229687121
Trained batch 505 in epoch 9, gen_loss = 0.4188747159223783, disc_loss = 0.0006295490046590843
Trained batch 506 in epoch 9, gen_loss = 0.41895797131564727, disc_loss = 0.0006307114245582654
Trained batch 507 in epoch 9, gen_loss = 0.41891515249107764, disc_loss = 0.0006311552844678994
Trained batch 508 in epoch 9, gen_loss = 0.41886566652530305, disc_loss = 0.000630776975986599
Trained batch 509 in epoch 9, gen_loss = 0.4188113618715137, disc_loss = 0.0006300749268905515
Trained batch 510 in epoch 9, gen_loss = 0.4187881201797269, disc_loss = 0.0006293512516804933
Trained batch 511 in epoch 9, gen_loss = 0.4186638270621188, disc_loss = 0.0006286611765347061
Trained batch 512 in epoch 9, gen_loss = 0.4186981986140647, disc_loss = 0.0006281546082791961
Trained batch 513 in epoch 9, gen_loss = 0.4187091620283832, disc_loss = 0.0006275345675354182
Trained batch 514 in epoch 9, gen_loss = 0.41874493192700507, disc_loss = 0.0006268888643266886
Trained batch 515 in epoch 9, gen_loss = 0.4187201221668443, disc_loss = 0.0006262715814814293
Trained batch 516 in epoch 9, gen_loss = 0.4186440099254106, disc_loss = 0.000625623148212766
Trained batch 517 in epoch 9, gen_loss = 0.41866407943278205, disc_loss = 0.0006252640096030673
Trained batch 518 in epoch 9, gen_loss = 0.41857943501545974, disc_loss = 0.0006251072259909188
Trained batch 519 in epoch 9, gen_loss = 0.41854509327274103, disc_loss = 0.0006245214959143105
Trained batch 520 in epoch 9, gen_loss = 0.4184691561618373, disc_loss = 0.0006238987509640749
Trained batch 521 in epoch 9, gen_loss = 0.4184047054513661, disc_loss = 0.0006232013902994911
Trained batch 522 in epoch 9, gen_loss = 0.4185013922632994, disc_loss = 0.000622856761953245
Trained batch 523 in epoch 9, gen_loss = 0.41849153050939547, disc_loss = 0.0006226017707765532
Trained batch 524 in epoch 9, gen_loss = 0.4185194589978173, disc_loss = 0.0006222958203371881
Trained batch 525 in epoch 9, gen_loss = 0.41861747029616353, disc_loss = 0.0006223039378948995
Trained batch 526 in epoch 9, gen_loss = 0.41871740786355177, disc_loss = 0.0006220144508470582
Trained batch 527 in epoch 9, gen_loss = 0.41860487701540644, disc_loss = 0.0006218206765631542
Trained batch 528 in epoch 9, gen_loss = 0.41868696754731394, disc_loss = 0.0006218553197075875
Trained batch 529 in epoch 9, gen_loss = 0.4185673562985546, disc_loss = 0.0006219828932135331
Trained batch 530 in epoch 9, gen_loss = 0.4184921639787275, disc_loss = 0.0006217298474394771
Trained batch 531 in epoch 9, gen_loss = 0.41848834161471604, disc_loss = 0.0006213906381436347
Trained batch 532 in epoch 9, gen_loss = 0.41850126018890965, disc_loss = 0.0006207684812598598
Trained batch 533 in epoch 9, gen_loss = 0.4184667857621939, disc_loss = 0.0006201834158615683
Trained batch 534 in epoch 9, gen_loss = 0.41838149751458215, disc_loss = 0.0006194755353934402
Trained batch 535 in epoch 9, gen_loss = 0.41848701766845003, disc_loss = 0.0006190595398296484
Trained batch 536 in epoch 9, gen_loss = 0.4183988436862299, disc_loss = 0.0006183896563232667
Trained batch 537 in epoch 9, gen_loss = 0.41833169564438577, disc_loss = 0.0006177798113707786
Trained batch 538 in epoch 9, gen_loss = 0.4182223970129229, disc_loss = 0.0006170905266883256
Trained batch 539 in epoch 9, gen_loss = 0.41816357572873436, disc_loss = 0.0006164581801621588
Trained batch 540 in epoch 9, gen_loss = 0.41822555308641657, disc_loss = 0.0006164948900562475
Trained batch 541 in epoch 9, gen_loss = 0.4181416216151741, disc_loss = 0.0006163384280179549
Trained batch 542 in epoch 9, gen_loss = 0.4181960344753652, disc_loss = 0.0006163368435940168
Trained batch 543 in epoch 9, gen_loss = 0.4183526181561105, disc_loss = 0.0006163762984001284
Trained batch 544 in epoch 9, gen_loss = 0.41828498670814235, disc_loss = 0.0006158789557857661
Trained batch 545 in epoch 9, gen_loss = 0.41815869941379563, disc_loss = 0.0006151760161772025
Trained batch 546 in epoch 9, gen_loss = 0.4182083418208023, disc_loss = 0.0006149011586996653
Trained batch 547 in epoch 9, gen_loss = 0.41817262888389783, disc_loss = 0.0006147445315003555
Trained batch 548 in epoch 9, gen_loss = 0.4181957650922904, disc_loss = 0.0006142488079565833
Trained batch 549 in epoch 9, gen_loss = 0.41816302039406517, disc_loss = 0.000613878888305573
Trained batch 550 in epoch 9, gen_loss = 0.418117322798433, disc_loss = 0.0006137542802823146
Trained batch 551 in epoch 9, gen_loss = 0.4181510685686616, disc_loss = 0.0006134887021091898
Trained batch 552 in epoch 9, gen_loss = 0.41808179543634866, disc_loss = 0.0006129137682907408
Trained batch 553 in epoch 9, gen_loss = 0.41801452378503684, disc_loss = 0.000612894756622177
Trained batch 554 in epoch 9, gen_loss = 0.4179992335873681, disc_loss = 0.000613297269861046
Trained batch 555 in epoch 9, gen_loss = 0.4180997486273162, disc_loss = 0.0006135857375156512
Trained batch 556 in epoch 9, gen_loss = 0.41812369163203283, disc_loss = 0.000613497739372051
Trained batch 557 in epoch 9, gen_loss = 0.4181865519947476, disc_loss = 0.0006132666077133098
Trained batch 558 in epoch 9, gen_loss = 0.41821983381972544, disc_loss = 0.0006129298302561981
Trained batch 559 in epoch 9, gen_loss = 0.4182976479509047, disc_loss = 0.0006131634059264408
Trained batch 560 in epoch 9, gen_loss = 0.4182730974254336, disc_loss = 0.0006130001808439071
Trained batch 561 in epoch 9, gen_loss = 0.4183044312157241, disc_loss = 0.000613196537975144
Trained batch 562 in epoch 9, gen_loss = 0.41831220683788956, disc_loss = 0.0006128765363649418
Trained batch 563 in epoch 9, gen_loss = 0.418197807215207, disc_loss = 0.0006128247914344967
Trained batch 564 in epoch 9, gen_loss = 0.41819975687339245, disc_loss = 0.0006126510726022163
Trained batch 565 in epoch 9, gen_loss = 0.41801034825008243, disc_loss = 0.0006122422471073582
Trained batch 566 in epoch 9, gen_loss = 0.4179116981580354, disc_loss = 0.000612080258809439
Trained batch 567 in epoch 9, gen_loss = 0.41789482638869485, disc_loss = 0.0006119338613387581
Trained batch 568 in epoch 9, gen_loss = 0.41788999817492883, disc_loss = 0.0006114219125126602
Trained batch 569 in epoch 9, gen_loss = 0.41796655675821137, disc_loss = 0.0006110181584453881
Trained batch 570 in epoch 9, gen_loss = 0.4180294075905755, disc_loss = 0.0006105730978247257
Trained batch 571 in epoch 9, gen_loss = 0.4180640244296381, disc_loss = 0.0006100630856632382
Trained batch 572 in epoch 9, gen_loss = 0.41813079432875283, disc_loss = 0.000609794390058904
Trained batch 573 in epoch 9, gen_loss = 0.4181431368356798, disc_loss = 0.0006098336592539318
Trained batch 574 in epoch 9, gen_loss = 0.41816436715748, disc_loss = 0.0006101121655513492
Trained batch 575 in epoch 9, gen_loss = 0.41806275697631967, disc_loss = 0.0006100716539094719
Trained batch 576 in epoch 9, gen_loss = 0.41806497829005873, disc_loss = 0.0006100645693000067
Trained batch 577 in epoch 9, gen_loss = 0.4180939357379729, disc_loss = 0.0006098883520019447
Trained batch 578 in epoch 9, gen_loss = 0.4180749758743457, disc_loss = 0.000609692952995565
Trained batch 579 in epoch 9, gen_loss = 0.4180124206789609, disc_loss = 0.0006091799071421927
Trained batch 580 in epoch 9, gen_loss = 0.41799971676734554, disc_loss = 0.0006086147439046146
Trained batch 581 in epoch 9, gen_loss = 0.41799347793933045, disc_loss = 0.0006082466710428867
Trained batch 582 in epoch 9, gen_loss = 0.4180137921974549, disc_loss = 0.0006082633981833835
Trained batch 583 in epoch 9, gen_loss = 0.41803168005322755, disc_loss = 0.0006079133245916574
Trained batch 584 in epoch 9, gen_loss = 0.4180394728978475, disc_loss = 0.0006076679960774799
Trained batch 585 in epoch 9, gen_loss = 0.4181246231135248, disc_loss = 0.0006075973537623001
Trained batch 586 in epoch 9, gen_loss = 0.4181264841475316, disc_loss = 0.0006073374074165434
Trained batch 587 in epoch 9, gen_loss = 0.41815940817805375, disc_loss = 0.0006068651581495497
Trained batch 588 in epoch 9, gen_loss = 0.4180623809530294, disc_loss = 0.0006062004359732327
Trained batch 589 in epoch 9, gen_loss = 0.41812666199975096, disc_loss = 0.000605805925048209
Trained batch 590 in epoch 9, gen_loss = 0.41809793414198204, disc_loss = 0.0006056670470312144
Trained batch 591 in epoch 9, gen_loss = 0.41820188239216805, disc_loss = 0.0006059162293437308
Trained batch 592 in epoch 9, gen_loss = 0.41827661437288705, disc_loss = 0.0006054364102397861
Trained batch 593 in epoch 9, gen_loss = 0.41829621475754364, disc_loss = 0.0006053189303912536
Trained batch 594 in epoch 9, gen_loss = 0.41832350327187223, disc_loss = 0.0006053104557433486
Trained batch 595 in epoch 9, gen_loss = 0.41823334541896845, disc_loss = 0.0006053932293376029
Trained batch 596 in epoch 9, gen_loss = 0.41824108846423214, disc_loss = 0.0006056258476758922
Trained batch 597 in epoch 9, gen_loss = 0.4181856910221553, disc_loss = 0.0006051272538141737
Trained batch 598 in epoch 9, gen_loss = 0.4181945853818438, disc_loss = 0.0006047761727467285
Testing Epoch 9
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 1.1588034629821777, disc_loss = 0.7504897117614746
Trained batch 1 in epoch 0, gen_loss = 1.0329801440238953, disc_loss = 0.6562624573707581
Trained batch 2 in epoch 0, gen_loss = 1.0121410489082336, disc_loss = 0.6349629561106364
Trained batch 3 in epoch 0, gen_loss = 0.9621112644672394, disc_loss = 0.5704038962721825
Trained batch 4 in epoch 0, gen_loss = 0.9203803300857544, disc_loss = 0.5092172265052796
Trained batch 5 in epoch 0, gen_loss = 0.9064383506774902, disc_loss = 0.46753962834676105
Trained batch 6 in epoch 0, gen_loss = 0.9092071567262922, disc_loss = 0.4411958541188921
Trained batch 7 in epoch 0, gen_loss = 0.9114769771695137, disc_loss = 0.4156810436397791
Trained batch 8 in epoch 0, gen_loss = 0.8849369353718228, disc_loss = 0.38319069312678444
Trained batch 9 in epoch 0, gen_loss = 0.8633165836334229, disc_loss = 0.37016172558069227
Trained batch 10 in epoch 0, gen_loss = 0.8633742711760781, disc_loss = 0.3505051759156314
Trained batch 11 in epoch 0, gen_loss = 0.8695066571235657, disc_loss = 0.333456518749396
Trained batch 12 in epoch 0, gen_loss = 0.8713458409676185, disc_loss = 0.3174997843228854
Trained batch 13 in epoch 0, gen_loss = 0.8779557475021907, disc_loss = 0.3021703591304166
Trained batch 14 in epoch 0, gen_loss = 0.8780697027842204, disc_loss = 0.2894755507508914
Trained batch 15 in epoch 0, gen_loss = 0.8763426057994366, disc_loss = 0.2780321668833494
Trained batch 16 in epoch 0, gen_loss = 0.8759923507185543, disc_loss = 0.2681586479439455
Trained batch 17 in epoch 0, gen_loss = 0.8744137850072649, disc_loss = 0.262916828195254
Trained batch 18 in epoch 0, gen_loss = 0.890128427430203, disc_loss = 0.25961611851265554
Trained batch 19 in epoch 0, gen_loss = 0.8930279403924942, disc_loss = 0.2560815267264843
Trained batch 20 in epoch 0, gen_loss = 0.883794245265779, disc_loss = 0.2525996970278876
Trained batch 21 in epoch 0, gen_loss = 0.8902019749988209, disc_loss = 0.24814270369031213
Trained batch 22 in epoch 0, gen_loss = 0.885188517363175, disc_loss = 0.24249720541031464
Trained batch 23 in epoch 0, gen_loss = 0.8869664520025253, disc_loss = 0.23928946411858001
Trained batch 24 in epoch 0, gen_loss = 0.8888040971755982, disc_loss = 0.23724964171648025
Trained batch 25 in epoch 0, gen_loss = 0.8874710912887867, disc_loss = 0.23464920629675573
Trained batch 26 in epoch 0, gen_loss = 0.8893026577101814, disc_loss = 0.23009130137938041
Trained batch 27 in epoch 0, gen_loss = 0.891647783773286, disc_loss = 0.22552619901086604
Trained batch 28 in epoch 0, gen_loss = 0.8926776606461098, disc_loss = 0.22165100661845044
Trained batch 29 in epoch 0, gen_loss = 0.897570788860321, disc_loss = 0.2205184298257033
Trained batch 30 in epoch 0, gen_loss = 0.8904940216772018, disc_loss = 0.22024323022173298
Trained batch 31 in epoch 0, gen_loss = 0.8912671264261007, disc_loss = 0.21616708557121456
Trained batch 32 in epoch 0, gen_loss = 0.8969262639681498, disc_loss = 0.2127063615304051
Trained batch 33 in epoch 0, gen_loss = 0.9039248350788566, disc_loss = 0.2088627431760816
Trained batch 34 in epoch 0, gen_loss = 0.9029506410871233, disc_loss = 0.20535361064331872
Trained batch 35 in epoch 0, gen_loss = 0.9041510737604566, disc_loss = 0.20208696524302164
Trained batch 36 in epoch 0, gen_loss = 0.909169936502302, disc_loss = 0.1982690141209074
Trained batch 37 in epoch 0, gen_loss = 0.9119009485370234, disc_loss = 0.19468933598775612
Trained batch 38 in epoch 0, gen_loss = 0.9139629755264673, disc_loss = 0.1918795821376336
Trained batch 39 in epoch 0, gen_loss = 0.9178405970335006, disc_loss = 0.189108613319695
Trained batch 40 in epoch 0, gen_loss = 0.925851839344676, disc_loss = 0.18606977600876878
Trained batch 41 in epoch 0, gen_loss = 0.9274969455741701, disc_loss = 0.18346336164644786
Trained batch 42 in epoch 0, gen_loss = 0.932099582150925, disc_loss = 0.18075092171513757
Trained batch 43 in epoch 0, gen_loss = 0.9426455944776535, disc_loss = 0.17801910689608616
Trained batch 44 in epoch 0, gen_loss = 0.946404042508867, disc_loss = 0.17567201902468998
Trained batch 45 in epoch 0, gen_loss = 0.9492657638114431, disc_loss = 0.1733645058196524
Trained batch 46 in epoch 0, gen_loss = 0.9495115140651135, disc_loss = 0.17188456464321056
Trained batch 47 in epoch 0, gen_loss = 0.9557692172626654, disc_loss = 0.16952979378402233
Trained batch 48 in epoch 0, gen_loss = 0.958835534903468, disc_loss = 0.16760245056784884
Trained batch 49 in epoch 0, gen_loss = 0.9600718820095062, disc_loss = 0.1665816506743431
Trained batch 50 in epoch 0, gen_loss = 0.959342992773243, disc_loss = 0.1655166809465371
Trained batch 51 in epoch 0, gen_loss = 0.9608742812505136, disc_loss = 0.164846205080931
Trained batch 52 in epoch 0, gen_loss = 0.9676185047851419, disc_loss = 0.16403619635779904
Trained batch 53 in epoch 0, gen_loss = 0.9704956357125882, disc_loss = 0.1629766165106385
Trained batch 54 in epoch 0, gen_loss = 0.9693198756738143, disc_loss = 0.16149400526827032
Trained batch 55 in epoch 0, gen_loss = 0.9726456201502255, disc_loss = 0.15980249882808753
Trained batch 56 in epoch 0, gen_loss = 0.9733873009681702, disc_loss = 0.15822829201556088
Trained batch 57 in epoch 0, gen_loss = 0.9769130338882578, disc_loss = 0.1563538321261776
Trained batch 58 in epoch 0, gen_loss = 0.9777675149804455, disc_loss = 0.15470195321713465
Trained batch 59 in epoch 0, gen_loss = 0.9804919352134068, disc_loss = 0.1532328418145577
Trained batch 60 in epoch 0, gen_loss = 0.9781976948018933, disc_loss = 0.15357895793973422
Trained batch 61 in epoch 0, gen_loss = 0.9851121489078768, disc_loss = 0.15523505439200708
Trained batch 62 in epoch 0, gen_loss = 0.9839937563926454, disc_loss = 0.15491889712829437
Trained batch 63 in epoch 0, gen_loss = 0.9832966243848205, disc_loss = 0.15365065995138139
Trained batch 64 in epoch 0, gen_loss = 0.9831064682740431, disc_loss = 0.15257340589394935
Trained batch 65 in epoch 0, gen_loss = 0.9849525292714437, disc_loss = 0.15189829536459662
Trained batch 66 in epoch 0, gen_loss = 0.9814559470361738, disc_loss = 0.15350107537276708
Trained batch 67 in epoch 0, gen_loss = 0.9825990883743062, disc_loss = 0.1525351481840891
Trained batch 68 in epoch 0, gen_loss = 0.9835689741632213, disc_loss = 0.15185540882141693
Trained batch 69 in epoch 0, gen_loss = 0.9821168737752097, disc_loss = 0.15140835610883577
Trained batch 70 in epoch 0, gen_loss = 0.9840495091089061, disc_loss = 0.1503449712001102
Trained batch 71 in epoch 0, gen_loss = 0.983902805381351, disc_loss = 0.148828215069241
Trained batch 72 in epoch 0, gen_loss = 0.984258524359089, disc_loss = 0.1476916389106071
Trained batch 73 in epoch 0, gen_loss = 0.9846426087456781, disc_loss = 0.14636581954923836
Trained batch 74 in epoch 0, gen_loss = 0.9831883851687113, disc_loss = 0.1452115671833356
Trained batch 75 in epoch 0, gen_loss = 0.9858781232645637, disc_loss = 0.14521484184814126
Trained batch 76 in epoch 0, gen_loss = 0.9826757172485451, disc_loss = 0.146216103105576
Trained batch 77 in epoch 0, gen_loss = 0.984798115797532, disc_loss = 0.14657134629594973
Trained batch 78 in epoch 0, gen_loss = 0.9814510752883139, disc_loss = 0.14762935164985777
Trained batch 79 in epoch 0, gen_loss = 0.9808177396655082, disc_loss = 0.14687617151066662
Trained batch 80 in epoch 0, gen_loss = 0.9829339348239663, disc_loss = 0.14695833246281118
Trained batch 81 in epoch 0, gen_loss = 0.9824613565351905, disc_loss = 0.146447915220406
Trained batch 82 in epoch 0, gen_loss = 0.9813495824135929, disc_loss = 0.14572601496096116
Trained batch 83 in epoch 0, gen_loss = 0.9824906750803902, disc_loss = 0.14665532245167665
Trained batch 84 in epoch 0, gen_loss = 0.979576648684109, disc_loss = 0.14933103173971177
Trained batch 85 in epoch 0, gen_loss = 0.9815275939398034, disc_loss = 0.1492277192341727
Trained batch 86 in epoch 0, gen_loss = 0.9802440726894072, disc_loss = 0.1495982568668223
Trained batch 87 in epoch 0, gen_loss = 0.9795743938196789, disc_loss = 0.14970244374126196
Trained batch 88 in epoch 0, gen_loss = 0.9794080853462219, disc_loss = 0.149541188240721
Trained batch 89 in epoch 0, gen_loss = 0.9798441178268856, disc_loss = 0.15026144426729943
Trained batch 90 in epoch 0, gen_loss = 0.9771499129442068, disc_loss = 0.15168997850064392
Trained batch 91 in epoch 0, gen_loss = 0.9769781873277996, disc_loss = 0.15214371689311837
Trained batch 92 in epoch 0, gen_loss = 0.9783773236377264, disc_loss = 0.15204100975746748
Trained batch 93 in epoch 0, gen_loss = 0.9759989336450049, disc_loss = 0.1528342010334451
Trained batch 94 in epoch 0, gen_loss = 0.9771184789507013, disc_loss = 0.15418821314447803
Trained batch 95 in epoch 0, gen_loss = 0.9734749402850866, disc_loss = 0.15490307309664786
Trained batch 96 in epoch 0, gen_loss = 0.9744507400030943, disc_loss = 0.15459089649399532
Trained batch 97 in epoch 0, gen_loss = 0.97406503679801, disc_loss = 0.15540195370511134
Trained batch 98 in epoch 0, gen_loss = 0.9730699519918422, disc_loss = 0.15623863455322054
Trained batch 99 in epoch 0, gen_loss = 0.973388876914978, disc_loss = 0.15589461252093315
Trained batch 100 in epoch 0, gen_loss = 0.9722520207414532, disc_loss = 0.15602875405018873
Trained batch 101 in epoch 0, gen_loss = 0.970634975269729, disc_loss = 0.1559622968528785
Trained batch 102 in epoch 0, gen_loss = 0.9680537917081592, disc_loss = 0.15665576238076664
Trained batch 103 in epoch 0, gen_loss = 0.971271599141451, disc_loss = 0.1589945345543898
Trained batch 104 in epoch 0, gen_loss = 0.9709499387514023, disc_loss = 0.15852609801860082
Trained batch 105 in epoch 0, gen_loss = 0.9675608732790317, disc_loss = 0.15937120242501204
Trained batch 106 in epoch 0, gen_loss = 0.9682559281866127, disc_loss = 0.15980722302588346
Trained batch 107 in epoch 0, gen_loss = 0.9668634445578964, disc_loss = 0.1601297993350912
Trained batch 108 in epoch 0, gen_loss = 0.9646186992662762, disc_loss = 0.160465473018655
Trained batch 109 in epoch 0, gen_loss = 0.9621061715212735, disc_loss = 0.1604139189828526
Trained batch 110 in epoch 0, gen_loss = 0.9612098073100185, disc_loss = 0.16019384361602165
Trained batch 111 in epoch 0, gen_loss = 0.9607402070292405, disc_loss = 0.15983685817835586
Trained batch 112 in epoch 0, gen_loss = 0.9595182770121414, disc_loss = 0.1601677942460617
Trained batch 113 in epoch 0, gen_loss = 0.9568399279786829, disc_loss = 0.161943022553858
Trained batch 114 in epoch 0, gen_loss = 0.9569751506266386, disc_loss = 0.16350425786298253
Trained batch 115 in epoch 0, gen_loss = 0.9559701192995598, disc_loss = 0.1638507318265479
Trained batch 116 in epoch 0, gen_loss = 0.9548636430349106, disc_loss = 0.16416012775948924
Trained batch 117 in epoch 0, gen_loss = 0.9535243283894103, disc_loss = 0.16440710318038018
Trained batch 118 in epoch 0, gen_loss = 0.9530405542429756, disc_loss = 0.16435553139748693
Trained batch 119 in epoch 0, gen_loss = 0.9516024847825368, disc_loss = 0.16403071079403161
Trained batch 120 in epoch 0, gen_loss = 0.9518942961022874, disc_loss = 0.16365160762278502
Trained batch 121 in epoch 0, gen_loss = 0.9516384904501868, disc_loss = 0.16430383981739888
Trained batch 122 in epoch 0, gen_loss = 0.9495706916824589, disc_loss = 0.16516619302877567
Trained batch 123 in epoch 0, gen_loss = 0.9491298929337533, disc_loss = 0.1650892229330155
Trained batch 124 in epoch 0, gen_loss = 0.9484296922683716, disc_loss = 0.1646004800796509
Trained batch 125 in epoch 0, gen_loss = 0.9465707923684802, disc_loss = 0.16462404588385235
Trained batch 126 in epoch 0, gen_loss = 0.9462577498803927, disc_loss = 0.16547140350022654
Trained batch 127 in epoch 0, gen_loss = 0.9446358480490744, disc_loss = 0.1654980689054355
Trained batch 128 in epoch 0, gen_loss = 0.9429848716240521, disc_loss = 0.16573737746523332
Trained batch 129 in epoch 0, gen_loss = 0.9443983751993913, disc_loss = 0.16690405435287037
Trained batch 130 in epoch 0, gen_loss = 0.9427869729413331, disc_loss = 0.16734447563422544
Trained batch 131 in epoch 0, gen_loss = 0.941597938989148, disc_loss = 0.1674835312772881
Trained batch 132 in epoch 0, gen_loss = 0.9415540542817653, disc_loss = 0.1677378952727282
Trained batch 133 in epoch 0, gen_loss = 0.9397154308077115, disc_loss = 0.16786686842566106
Trained batch 134 in epoch 0, gen_loss = 0.9375590200777407, disc_loss = 0.1680742112574754
Trained batch 135 in epoch 0, gen_loss = 0.9376100915319779, disc_loss = 0.16786829469835057
Trained batch 136 in epoch 0, gen_loss = 0.9374274311274507, disc_loss = 0.16773903369903564
Trained batch 137 in epoch 0, gen_loss = 0.9362770232601442, disc_loss = 0.1674170920058437
Trained batch 138 in epoch 0, gen_loss = 0.9351557587548126, disc_loss = 0.16728578309575431
Trained batch 139 in epoch 0, gen_loss = 0.934707755276135, disc_loss = 0.16773002674537046
Trained batch 140 in epoch 0, gen_loss = 0.9325886254614972, disc_loss = 0.16821968053460967
Trained batch 141 in epoch 0, gen_loss = 0.9332852976422914, disc_loss = 0.16803062177250083
Trained batch 142 in epoch 0, gen_loss = 0.9339901700720087, disc_loss = 0.1679880534122874
Trained batch 143 in epoch 0, gen_loss = 0.9325802359316084, disc_loss = 0.1680925862553219
Trained batch 144 in epoch 0, gen_loss = 0.9322522241493751, disc_loss = 0.16767272759100488
Trained batch 145 in epoch 0, gen_loss = 0.9308161323201166, disc_loss = 0.1679709052080161
Trained batch 146 in epoch 0, gen_loss = 0.9312929292114414, disc_loss = 0.1686409177119229
Trained batch 147 in epoch 0, gen_loss = 0.9300315122346621, disc_loss = 0.1683815111078926
Trained batch 148 in epoch 0, gen_loss = 0.9285772426816441, disc_loss = 0.16881896610428024
Trained batch 149 in epoch 0, gen_loss = 0.930128884712855, disc_loss = 0.17000796958804132
Trained batch 150 in epoch 0, gen_loss = 0.9292662818700272, disc_loss = 0.16985073700448536
Trained batch 151 in epoch 0, gen_loss = 0.9271439819743759, disc_loss = 0.17137450680724883
Trained batch 152 in epoch 0, gen_loss = 0.926324757096035, disc_loss = 0.1712362709290841
Trained batch 153 in epoch 0, gen_loss = 0.9261310607581944, disc_loss = 0.1711982377841101
Trained batch 154 in epoch 0, gen_loss = 0.9253393184754156, disc_loss = 0.17133802728306863
Trained batch 155 in epoch 0, gen_loss = 0.9243296312216001, disc_loss = 0.1714466924373156
Trained batch 156 in epoch 0, gen_loss = 0.9227502623181434, disc_loss = 0.17141124050898157
Trained batch 157 in epoch 0, gen_loss = 0.9224400226073929, disc_loss = 0.17186587968770461
Trained batch 158 in epoch 0, gen_loss = 0.9214618505921753, disc_loss = 0.17193664671302591
Trained batch 159 in epoch 0, gen_loss = 0.9196876347064972, disc_loss = 0.17194372261874377
Trained batch 160 in epoch 0, gen_loss = 0.9193025475703411, disc_loss = 0.1718234414732234
Trained batch 161 in epoch 0, gen_loss = 0.9186526253635501, disc_loss = 0.17176472593420816
Trained batch 162 in epoch 0, gen_loss = 0.9187111375522028, disc_loss = 0.1717099567955257
Trained batch 163 in epoch 0, gen_loss = 0.916780082554352, disc_loss = 0.17193504909008014
Trained batch 164 in epoch 0, gen_loss = 0.9174095966599204, disc_loss = 0.17165793537190466
Trained batch 165 in epoch 0, gen_loss = 0.9169706361121442, disc_loss = 0.17134231683540058
Trained batch 166 in epoch 0, gen_loss = 0.9172780121157983, disc_loss = 0.17090413514190092
Trained batch 167 in epoch 0, gen_loss = 0.9163853036505836, disc_loss = 0.17076838561998947
Trained batch 168 in epoch 0, gen_loss = 0.916563805038407, disc_loss = 0.17178145222938979
Trained batch 169 in epoch 0, gen_loss = 0.9152570889276617, disc_loss = 0.17265869690214886
Trained batch 170 in epoch 0, gen_loss = 0.9147650446110999, disc_loss = 0.1730178106162283
Trained batch 171 in epoch 0, gen_loss = 0.9137692752965662, disc_loss = 0.17304961015145445
Trained batch 172 in epoch 0, gen_loss = 0.9129384659618311, disc_loss = 0.17299348025480446
Trained batch 173 in epoch 0, gen_loss = 0.9123489562122301, disc_loss = 0.1729374227767018
Trained batch 174 in epoch 0, gen_loss = 0.9122387749808175, disc_loss = 0.17281645957912717
Trained batch 175 in epoch 0, gen_loss = 0.9116423008116809, disc_loss = 0.1730923084118827
Trained batch 176 in epoch 0, gen_loss = 0.9099904083262729, disc_loss = 0.17326917103623266
Trained batch 177 in epoch 0, gen_loss = 0.9089469072524081, disc_loss = 0.17319383375932662
Trained batch 178 in epoch 0, gen_loss = 0.9097319488418835, disc_loss = 0.1733552698233274
Trained batch 179 in epoch 0, gen_loss = 0.9087502482864592, disc_loss = 0.17330110573934185
Trained batch 180 in epoch 0, gen_loss = 0.9084622418682878, disc_loss = 0.17381598248830815
Trained batch 181 in epoch 0, gen_loss = 0.9064160284105238, disc_loss = 0.17389152244060904
Trained batch 182 in epoch 0, gen_loss = 0.9056114385036823, disc_loss = 0.17436338810484267
Trained batch 183 in epoch 0, gen_loss = 0.905537727734317, disc_loss = 0.1749339296846934
Trained batch 184 in epoch 0, gen_loss = 0.9058955508309442, disc_loss = 0.1748888900553858
Trained batch 185 in epoch 0, gen_loss = 0.9048412326843508, disc_loss = 0.17510673287574963
Trained batch 186 in epoch 0, gen_loss = 0.9041625121060539, disc_loss = 0.17514399375348166
Trained batch 187 in epoch 0, gen_loss = 0.9038720784035135, disc_loss = 0.17504603578213682
Trained batch 188 in epoch 0, gen_loss = 0.9026600772110873, disc_loss = 0.17510992655205349
Trained batch 189 in epoch 0, gen_loss = 0.9017434785240575, disc_loss = 0.1749805166140983
Trained batch 190 in epoch 0, gen_loss = 0.9013755671016833, disc_loss = 0.17501430607434967
Trained batch 191 in epoch 0, gen_loss = 0.9005148385961851, disc_loss = 0.17488070278583714
Trained batch 192 in epoch 0, gen_loss = 0.8998853332638123, disc_loss = 0.1747346364077509
Trained batch 193 in epoch 0, gen_loss = 0.8994900203242744, disc_loss = 0.17447037249803543
Trained batch 194 in epoch 0, gen_loss = 0.8979848748598344, disc_loss = 0.17450458842974442
Trained batch 195 in epoch 0, gen_loss = 0.8966553104775292, disc_loss = 0.17459593948965169
Trained batch 196 in epoch 0, gen_loss = 0.8980738175701974, disc_loss = 0.17500600816332143
Trained batch 197 in epoch 0, gen_loss = 0.8966019162625978, disc_loss = 0.17554378998701017
Trained batch 198 in epoch 0, gen_loss = 0.8964062764416987, disc_loss = 0.1760278590510239
Trained batch 199 in epoch 0, gen_loss = 0.8948551979660988, disc_loss = 0.1761816480010748
Trained batch 200 in epoch 0, gen_loss = 0.8933388359511076, disc_loss = 0.17646822911589893
Trained batch 201 in epoch 0, gen_loss = 0.8927642050946113, disc_loss = 0.17633847597211894
Trained batch 202 in epoch 0, gen_loss = 0.8930989483307148, disc_loss = 0.1762137162714756
Trained batch 203 in epoch 0, gen_loss = 0.8919596318520752, disc_loss = 0.1761335699143363
Trained batch 204 in epoch 0, gen_loss = 0.8910444250920924, disc_loss = 0.17623765941073255
Trained batch 205 in epoch 0, gen_loss = 0.891366679112888, disc_loss = 0.17621690244639962
Trained batch 206 in epoch 0, gen_loss = 0.8909325251256787, disc_loss = 0.17614153999349344
Trained batch 207 in epoch 0, gen_loss = 0.8904871877569419, disc_loss = 0.17590529708048472
Trained batch 208 in epoch 0, gen_loss = 0.8898480520294043, disc_loss = 0.1756955132102282
Trained batch 209 in epoch 0, gen_loss = 0.8897343680972145, disc_loss = 0.17552642332656043
Trained batch 210 in epoch 0, gen_loss = 0.8897224695761622, disc_loss = 0.1755927294775208
Trained batch 211 in epoch 0, gen_loss = 0.8887370015090367, disc_loss = 0.17592176844207746
Trained batch 212 in epoch 0, gen_loss = 0.8898369818226273, disc_loss = 0.17708893414114563
Trained batch 213 in epoch 0, gen_loss = 0.8892419750445357, disc_loss = 0.17703275278071376
Trained batch 214 in epoch 0, gen_loss = 0.8881185847659444, disc_loss = 0.17713136409604271
Trained batch 215 in epoch 0, gen_loss = 0.8872348197080471, disc_loss = 0.17717697416190747
Trained batch 216 in epoch 0, gen_loss = 0.8867433194740577, disc_loss = 0.1771786829568274
Trained batch 217 in epoch 0, gen_loss = 0.886100200611517, disc_loss = 0.177143520444905
Trained batch 218 in epoch 0, gen_loss = 0.8851740147969495, disc_loss = 0.17721164423853294
Trained batch 219 in epoch 0, gen_loss = 0.8848605892874978, disc_loss = 0.17713397138498047
Trained batch 220 in epoch 0, gen_loss = 0.8843635280207811, disc_loss = 0.1769890913326816
Trained batch 221 in epoch 0, gen_loss = 0.8837270701790715, disc_loss = 0.17694736950032347
Trained batch 222 in epoch 0, gen_loss = 0.8830031426498174, disc_loss = 0.17695274568192093
Trained batch 223 in epoch 0, gen_loss = 0.882218372342842, disc_loss = 0.17674979474395514
Trained batch 224 in epoch 0, gen_loss = 0.8814004074202644, disc_loss = 0.1765708135233985
Trained batch 225 in epoch 0, gen_loss = 0.8811957166258213, disc_loss = 0.17669139156299354
Trained batch 226 in epoch 0, gen_loss = 0.879980353794434, disc_loss = 0.17702162397065352
Trained batch 227 in epoch 0, gen_loss = 0.8807366043329239, disc_loss = 0.17704592991554946
Trained batch 228 in epoch 0, gen_loss = 0.8802572543444072, disc_loss = 0.17695497548996622
Trained batch 229 in epoch 0, gen_loss = 0.8797552007695902, disc_loss = 0.17696981255127037
Trained batch 230 in epoch 0, gen_loss = 0.8806727193134688, disc_loss = 0.17709340077716035
Trained batch 231 in epoch 0, gen_loss = 0.8802177610582319, disc_loss = 0.1770218813727642
Trained batch 232 in epoch 0, gen_loss = 0.8794669913120025, disc_loss = 0.17690282394957646
Trained batch 233 in epoch 0, gen_loss = 0.8791402927321247, disc_loss = 0.17668431309553292
Trained batch 234 in epoch 0, gen_loss = 0.8794872070880646, disc_loss = 0.17647589324636662
Trained batch 235 in epoch 0, gen_loss = 0.8783955311371108, disc_loss = 0.17657818020147792
Trained batch 236 in epoch 0, gen_loss = 0.8787276817776483, disc_loss = 0.1771698677715873
Trained batch 237 in epoch 0, gen_loss = 0.8783781310590375, disc_loss = 0.1768671705880586
Trained batch 238 in epoch 0, gen_loss = 0.8777668144413617, disc_loss = 0.1768099499484485
Trained batch 239 in epoch 0, gen_loss = 0.8778138789037864, disc_loss = 0.17709912555292248
Trained batch 240 in epoch 0, gen_loss = 0.8770506300372207, disc_loss = 0.17692773245058613
Trained batch 241 in epoch 0, gen_loss = 0.87575814054032, disc_loss = 0.17721469654155173
Trained batch 242 in epoch 0, gen_loss = 0.8762403832050999, disc_loss = 0.17707766742740638
Trained batch 243 in epoch 0, gen_loss = 0.8761082421072194, disc_loss = 0.1767959606940629
Trained batch 244 in epoch 0, gen_loss = 0.8762298231222192, disc_loss = 0.1764412813040675
Trained batch 245 in epoch 0, gen_loss = 0.875641787439827, disc_loss = 0.17641029403946265
Trained batch 246 in epoch 0, gen_loss = 0.8765477115808711, disc_loss = 0.17648985776824025
Trained batch 247 in epoch 0, gen_loss = 0.8757371176635066, disc_loss = 0.17631808205717994
Trained batch 248 in epoch 0, gen_loss = 0.8749409612402859, disc_loss = 0.17647877209875956
Trained batch 249 in epoch 0, gen_loss = 0.8751875705718994, disc_loss = 0.17695674985647203
Trained batch 250 in epoch 0, gen_loss = 0.874885784202363, disc_loss = 0.1768110832013932
Trained batch 251 in epoch 0, gen_loss = 0.8741246816657838, disc_loss = 0.1767772678581495
Trained batch 252 in epoch 0, gen_loss = 0.8736354008964871, disc_loss = 0.17675497279807983
Trained batch 253 in epoch 0, gen_loss = 0.8731272898790404, disc_loss = 0.1766358541808729
Trained batch 254 in epoch 0, gen_loss = 0.8729165369389104, disc_loss = 0.17625925143559773
Trained batch 255 in epoch 0, gen_loss = 0.8722248168196529, disc_loss = 0.17611735314130783
Trained batch 256 in epoch 0, gen_loss = 0.8724524214110022, disc_loss = 0.17594662430453392
Trained batch 257 in epoch 0, gen_loss = 0.8723099116207094, disc_loss = 0.1755818532303322
Trained batch 258 in epoch 0, gen_loss = 0.8720771055884343, disc_loss = 0.1754979675916171
Trained batch 259 in epoch 0, gen_loss = 0.871397857941114, disc_loss = 0.1753162406384945
Trained batch 260 in epoch 0, gen_loss = 0.871209963071392, disc_loss = 0.17540982200039756
Trained batch 261 in epoch 0, gen_loss = 0.8701546503842332, disc_loss = 0.17586336046002293
Trained batch 262 in epoch 0, gen_loss = 0.8707792194623911, disc_loss = 0.17626393005648494
Trained batch 263 in epoch 0, gen_loss = 0.8701879641774929, disc_loss = 0.1764660250169761
Trained batch 264 in epoch 0, gen_loss = 0.8691951319856464, disc_loss = 0.17672034895644997
Trained batch 265 in epoch 0, gen_loss = 0.8689059426909999, disc_loss = 0.17697614285730778
Trained batch 266 in epoch 0, gen_loss = 0.8683686033170321, disc_loss = 0.17727309242169956
Trained batch 267 in epoch 0, gen_loss = 0.8676806737237902, disc_loss = 0.17756559532969746
Trained batch 268 in epoch 0, gen_loss = 0.8672794743984605, disc_loss = 0.1777008735889839
Trained batch 269 in epoch 0, gen_loss = 0.8661962257491218, disc_loss = 0.17779945775314612
Trained batch 270 in epoch 0, gen_loss = 0.8656283617019653, disc_loss = 0.17781152545965906
Trained batch 271 in epoch 0, gen_loss = 0.8649588685263606, disc_loss = 0.1778187069165356
Trained batch 272 in epoch 0, gen_loss = 0.8644501776485652, disc_loss = 0.17777328023980388
Trained batch 273 in epoch 0, gen_loss = 0.8641092492281085, disc_loss = 0.17771771778590487
Trained batch 274 in epoch 0, gen_loss = 0.8638140992684797, disc_loss = 0.17762633881785653
Trained batch 275 in epoch 0, gen_loss = 0.8635697656351587, disc_loss = 0.1774883898164051
Trained batch 276 in epoch 0, gen_loss = 0.8635375809583423, disc_loss = 0.17728051623927987
Trained batch 277 in epoch 0, gen_loss = 0.8636048204607243, disc_loss = 0.17715331016899014
Trained batch 278 in epoch 0, gen_loss = 0.8630971799614608, disc_loss = 0.17700679963421223
Trained batch 279 in epoch 0, gen_loss = 0.8622130806956972, disc_loss = 0.17705011213464397
Trained batch 280 in epoch 0, gen_loss = 0.8637378987892667, disc_loss = 0.17785627493018358
Trained batch 281 in epoch 0, gen_loss = 0.8629582029707888, disc_loss = 0.1776885323173611
Trained batch 282 in epoch 0, gen_loss = 0.8618196514385749, disc_loss = 0.17801730376882183
Trained batch 283 in epoch 0, gen_loss = 0.861983769376513, disc_loss = 0.17844667154508578
Trained batch 284 in epoch 0, gen_loss = 0.8614834390188518, disc_loss = 0.17854392596504146
Trained batch 285 in epoch 0, gen_loss = 0.8608647468206766, disc_loss = 0.17849595224732287
Trained batch 286 in epoch 0, gen_loss = 0.8603718363864912, disc_loss = 0.17837886455167046
Trained batch 287 in epoch 0, gen_loss = 0.8598218576775657, disc_loss = 0.17832946642819378
Trained batch 288 in epoch 0, gen_loss = 0.8598595756560461, disc_loss = 0.17819211665528042
Trained batch 289 in epoch 0, gen_loss = 0.8593115724366287, disc_loss = 0.1781789921994867
Trained batch 290 in epoch 0, gen_loss = 0.8586813178668726, disc_loss = 0.1781924853415014
Trained batch 291 in epoch 0, gen_loss = 0.8592307024622616, disc_loss = 0.1783347236477349
Trained batch 292 in epoch 0, gen_loss = 0.8588132117795456, disc_loss = 0.1783763736283006
Trained batch 293 in epoch 0, gen_loss = 0.8579120656260016, disc_loss = 0.1785308727297653
Trained batch 294 in epoch 0, gen_loss = 0.85763439061278, disc_loss = 0.1784345950615608
Trained batch 295 in epoch 0, gen_loss = 0.8573585386211807, disc_loss = 0.1784181834978832
Trained batch 296 in epoch 0, gen_loss = 0.8564765320883857, disc_loss = 0.17841185574178342
Trained batch 297 in epoch 0, gen_loss = 0.8560407415732442, disc_loss = 0.17826241004787036
Trained batch 298 in epoch 0, gen_loss = 0.8556393897254332, disc_loss = 0.17802646427250227
Trained batch 299 in epoch 0, gen_loss = 0.8558589015404383, disc_loss = 0.17793445706367492
Trained batch 300 in epoch 0, gen_loss = 0.8552528493032107, disc_loss = 0.1782775740092775
Trained batch 301 in epoch 0, gen_loss = 0.8556244276612011, disc_loss = 0.17823939568159597
Trained batch 302 in epoch 0, gen_loss = 0.855006471325462, disc_loss = 0.17816559031064755
Trained batch 303 in epoch 0, gen_loss = 0.8545696155021065, disc_loss = 0.17798921127656572
Trained batch 304 in epoch 0, gen_loss = 0.8546950316819988, disc_loss = 0.17827293447783735
Trained batch 305 in epoch 0, gen_loss = 0.8538910721252168, disc_loss = 0.17877786976644416
Trained batch 306 in epoch 0, gen_loss = 0.8537030367587211, disc_loss = 0.17858215059830235
Trained batch 307 in epoch 0, gen_loss = 0.8536053466332423, disc_loss = 0.17850701888273288
Trained batch 308 in epoch 0, gen_loss = 0.8534440276692214, disc_loss = 0.1783399271347762
Trained batch 309 in epoch 0, gen_loss = 0.8525203424115335, disc_loss = 0.1783152717255777
Trained batch 310 in epoch 0, gen_loss = 0.8526676580836918, disc_loss = 0.17843284977785645
Trained batch 311 in epoch 0, gen_loss = 0.8523455115082936, disc_loss = 0.1782014306443624
Trained batch 312 in epoch 0, gen_loss = 0.8516395470966547, disc_loss = 0.17847504883338086
Trained batch 313 in epoch 0, gen_loss = 0.8524719433040376, disc_loss = 0.178481771118322
Trained batch 314 in epoch 0, gen_loss = 0.8526056249936421, disc_loss = 0.1781735514837598
Trained batch 315 in epoch 0, gen_loss = 0.8516962741371952, disc_loss = 0.178493500793282
Trained batch 316 in epoch 0, gen_loss = 0.8519737472293505, disc_loss = 0.1782937719007772
Trained batch 317 in epoch 0, gen_loss = 0.8523045470879512, disc_loss = 0.17806181927803177
Trained batch 318 in epoch 0, gen_loss = 0.851665400786086, disc_loss = 0.17791067589319612
Trained batch 319 in epoch 0, gen_loss = 0.8512391831725836, disc_loss = 0.1777283166302368
Trained batch 320 in epoch 0, gen_loss = 0.8508343496055246, disc_loss = 0.17751386206933642
Trained batch 321 in epoch 0, gen_loss = 0.8513379315411822, disc_loss = 0.17721199408543775
Trained batch 322 in epoch 0, gen_loss = 0.8504865468471043, disc_loss = 0.17707671891701848
Trained batch 323 in epoch 0, gen_loss = 0.8502665986249476, disc_loss = 0.17698410417838598
Trained batch 324 in epoch 0, gen_loss = 0.8493855025218083, disc_loss = 0.1770424278653585
Trained batch 325 in epoch 0, gen_loss = 0.849473759074884, disc_loss = 0.17711374641287547
Trained batch 326 in epoch 0, gen_loss = 0.849175686865407, disc_loss = 0.17689447004678416
Trained batch 327 in epoch 0, gen_loss = 0.8480388324980329, disc_loss = 0.17729523827935137
Trained batch 328 in epoch 0, gen_loss = 0.8482135125750104, disc_loss = 0.1770533562657681
Trained batch 329 in epoch 0, gen_loss = 0.8483211128097592, disc_loss = 0.17701417964064714
Trained batch 330 in epoch 0, gen_loss = 0.8483379727223849, disc_loss = 0.17709076042171693
Trained batch 331 in epoch 0, gen_loss = 0.8486574808337602, disc_loss = 0.17738708528319755
Trained batch 332 in epoch 0, gen_loss = 0.8487886561824752, disc_loss = 0.17740397891393295
Trained batch 333 in epoch 0, gen_loss = 0.8485790490211841, disc_loss = 0.17721091884517384
Trained batch 334 in epoch 0, gen_loss = 0.8477455736096225, disc_loss = 0.17730114330996327
Trained batch 335 in epoch 0, gen_loss = 0.8477612108524356, disc_loss = 0.17713634252903007
Trained batch 336 in epoch 0, gen_loss = 0.8481436765335434, disc_loss = 0.17706155233107265
Trained batch 337 in epoch 0, gen_loss = 0.8472635843873729, disc_loss = 0.17703535826601222
Trained batch 338 in epoch 0, gen_loss = 0.84707460668938, disc_loss = 0.17696199401290016
Trained batch 339 in epoch 0, gen_loss = 0.84636580216534, disc_loss = 0.17685632035136223
Trained batch 340 in epoch 0, gen_loss = 0.8463089991349978, disc_loss = 0.17663522287547764
Trained batch 341 in epoch 0, gen_loss = 0.8471213447594503, disc_loss = 0.17711425489849514
Trained batch 342 in epoch 0, gen_loss = 0.8464667516442846, disc_loss = 0.17725493926174787
Trained batch 343 in epoch 0, gen_loss = 0.8461519515271797, disc_loss = 0.17703054065621177
Trained batch 344 in epoch 0, gen_loss = 0.8462604406087295, disc_loss = 0.1769736946924873
Trained batch 345 in epoch 0, gen_loss = 0.8457557285968968, disc_loss = 0.17678095456320425
Trained batch 346 in epoch 0, gen_loss = 0.8454905871183797, disc_loss = 0.17643610332214868
Trained batch 347 in epoch 0, gen_loss = 0.8454017847262579, disc_loss = 0.17623183129076986
Trained batch 348 in epoch 0, gen_loss = 0.8457373325155253, disc_loss = 0.1759057225269882
Trained batch 349 in epoch 0, gen_loss = 0.8459633104290281, disc_loss = 0.17568291824843202
Trained batch 350 in epoch 0, gen_loss = 0.8456833572299393, disc_loss = 0.17542480867345447
Trained batch 351 in epoch 0, gen_loss = 0.8459148770198226, disc_loss = 0.17507122110956433
Trained batch 352 in epoch 0, gen_loss = 0.8460035814610825, disc_loss = 0.17474986443945098
Trained batch 353 in epoch 0, gen_loss = 0.8453510525704777, disc_loss = 0.17463171957744716
Trained batch 354 in epoch 0, gen_loss = 0.8461526821196919, disc_loss = 0.1749895709920937
Trained batch 355 in epoch 0, gen_loss = 0.8454861812544673, disc_loss = 0.1753293239417371
Trained batch 356 in epoch 0, gen_loss = 0.8456489798568544, disc_loss = 0.17523483689926586
Trained batch 357 in epoch 0, gen_loss = 0.8454474897524498, disc_loss = 0.17494386626022487
Trained batch 358 in epoch 0, gen_loss = 0.8447648573220606, disc_loss = 0.1748384601724513
Trained batch 359 in epoch 0, gen_loss = 0.8449988187187247, disc_loss = 0.17462522441314327
Trained batch 360 in epoch 0, gen_loss = 0.8446980248362734, disc_loss = 0.17436574382960301
Trained batch 361 in epoch 0, gen_loss = 0.8441285473701045, disc_loss = 0.17420851688276337
Trained batch 362 in epoch 0, gen_loss = 0.8447502656909059, disc_loss = 0.17426963259283834
Trained batch 363 in epoch 0, gen_loss = 0.8444132286604944, disc_loss = 0.17397278027383836
Trained batch 364 in epoch 0, gen_loss = 0.8440336260893574, disc_loss = 0.1737757466631393
Trained batch 365 in epoch 0, gen_loss = 0.8443634076033785, disc_loss = 0.17386401784631725
Trained batch 366 in epoch 0, gen_loss = 0.8447455236794839, disc_loss = 0.17346101698315924
Trained batch 367 in epoch 0, gen_loss = 0.8443495999697758, disc_loss = 0.173632693552898
Trained batch 368 in epoch 0, gen_loss = 0.8444983509336383, disc_loss = 0.17381464687446108
Trained batch 369 in epoch 0, gen_loss = 0.8443836976547499, disc_loss = 0.17358645010940932
Trained batch 370 in epoch 0, gen_loss = 0.844450468081991, disc_loss = 0.17332605300144846
Trained batch 371 in epoch 0, gen_loss = 0.8441962315350451, disc_loss = 0.17315678830729217
Trained batch 372 in epoch 0, gen_loss = 0.8436739995236691, disc_loss = 0.17305597722350594
Trained batch 373 in epoch 0, gen_loss = 0.8438577310127371, disc_loss = 0.17297607376912538
Trained batch 374 in epoch 0, gen_loss = 0.844519991795222, disc_loss = 0.17258047320942085
Trained batch 375 in epoch 0, gen_loss = 0.8439567814323496, disc_loss = 0.17262370502477156
Trained batch 376 in epoch 0, gen_loss = 0.8447801462060893, disc_loss = 0.1725233557932968
Trained batch 377 in epoch 0, gen_loss = 0.844873330343968, disc_loss = 0.17216863638410965
Trained batch 378 in epoch 0, gen_loss = 0.8443409722681725, disc_loss = 0.17192501922219128
Trained batch 379 in epoch 0, gen_loss = 0.844262111579117, disc_loss = 0.17164464484606134
Trained batch 380 in epoch 0, gen_loss = 0.8447058955671907, disc_loss = 0.17156057511004094
Trained batch 381 in epoch 0, gen_loss = 0.8444242746574092, disc_loss = 0.17143985724164398
Trained batch 382 in epoch 0, gen_loss = 0.8448481180804828, disc_loss = 0.17143981662085256
Trained batch 383 in epoch 0, gen_loss = 0.8446436571733406, disc_loss = 0.17110837058377606
Trained batch 384 in epoch 0, gen_loss = 0.844006675946248, disc_loss = 0.1712400121880429
Trained batch 385 in epoch 0, gen_loss = 0.8446236905193082, disc_loss = 0.1710144262230072
Trained batch 386 in epoch 0, gen_loss = 0.8447996243179923, disc_loss = 0.17068601553195978
Trained batch 387 in epoch 0, gen_loss = 0.8446534120084084, disc_loss = 0.17047600635836266
Trained batch 388 in epoch 0, gen_loss = 0.8443035718561138, disc_loss = 0.1704370290912439
Trained batch 389 in epoch 0, gen_loss = 0.8445494947525171, disc_loss = 0.17010613994625134
Trained batch 390 in epoch 0, gen_loss = 0.8438851116106029, disc_loss = 0.16986984219830817
Trained batch 391 in epoch 0, gen_loss = 0.8439082443257984, disc_loss = 0.16960546647540617
Trained batch 392 in epoch 0, gen_loss = 0.8437887315683389, disc_loss = 0.16944028303956105
Trained batch 393 in epoch 0, gen_loss = 0.844299452029509, disc_loss = 0.1691140269217682
Trained batch 394 in epoch 0, gen_loss = 0.8443399872206434, disc_loss = 0.168742127527919
Trained batch 395 in epoch 0, gen_loss = 0.8445703193846376, disc_loss = 0.168427390149898
Trained batch 396 in epoch 0, gen_loss = 0.8442260776869296, disc_loss = 0.1682564408262671
Trained batch 397 in epoch 0, gen_loss = 0.8458342880909168, disc_loss = 0.1685615378857857
Trained batch 398 in epoch 0, gen_loss = 0.8452031284496001, disc_loss = 0.16872458335451015
Trained batch 399 in epoch 0, gen_loss = 0.8453038846701384, disc_loss = 0.16849126644432544
Trained batch 400 in epoch 0, gen_loss = 0.845629071877187, disc_loss = 0.16873399909595005
Trained batch 401 in epoch 0, gen_loss = 0.8448785779932838, disc_loss = 0.16887425256902305
Trained batch 402 in epoch 0, gen_loss = 0.8449140869210435, disc_loss = 0.16873054289566375
Trained batch 403 in epoch 0, gen_loss = 0.8453868620909086, disc_loss = 0.16858154572177642
Trained batch 404 in epoch 0, gen_loss = 0.8445795386661717, disc_loss = 0.16888080680811846
Trained batch 405 in epoch 0, gen_loss = 0.8443352281313224, disc_loss = 0.16873831191820465
Trained batch 406 in epoch 0, gen_loss = 0.8444964964061756, disc_loss = 0.16868911456563843
Trained batch 407 in epoch 0, gen_loss = 0.8444097301393163, disc_loss = 0.1685347041370822
Trained batch 408 in epoch 0, gen_loss = 0.8444251628697356, disc_loss = 0.168242054957268
Trained batch 409 in epoch 0, gen_loss = 0.8444710429848694, disc_loss = 0.16806179981951305
Trained batch 410 in epoch 0, gen_loss = 0.8445804454839433, disc_loss = 0.16792829689136968
Trained batch 411 in epoch 0, gen_loss = 0.8442731454100424, disc_loss = 0.167887105154398
Trained batch 412 in epoch 0, gen_loss = 0.8448088233320823, disc_loss = 0.16781960387170747
Trained batch 413 in epoch 0, gen_loss = 0.8440400961660532, disc_loss = 0.16801642384470086
Trained batch 414 in epoch 0, gen_loss = 0.8444625510508755, disc_loss = 0.16804981575493352
Trained batch 415 in epoch 0, gen_loss = 0.8439706031662914, disc_loss = 0.16787841793400451
Trained batch 416 in epoch 0, gen_loss = 0.8439950930843536, disc_loss = 0.1675785698121686
Trained batch 417 in epoch 0, gen_loss = 0.8437735159573942, disc_loss = 0.16744531249030356
Trained batch 418 in epoch 0, gen_loss = 0.8443232277554942, disc_loss = 0.16756213660883162
Trained batch 419 in epoch 0, gen_loss = 0.8437643798334258, disc_loss = 0.1675198035935561
Trained batch 420 in epoch 0, gen_loss = 0.8437156750159139, disc_loss = 0.16721755021966267
Trained batch 421 in epoch 0, gen_loss = 0.8437448805683597, disc_loss = 0.1669831025233201
Trained batch 422 in epoch 0, gen_loss = 0.8438358244180115, disc_loss = 0.1669859224247876
Trained batch 423 in epoch 0, gen_loss = 0.8428972484368198, disc_loss = 0.16753646495910185
Trained batch 424 in epoch 0, gen_loss = 0.8425849266613231, disc_loss = 0.16743453839245964
Trained batch 425 in epoch 0, gen_loss = 0.8427141247221002, disc_loss = 0.16755530227657775
Trained batch 426 in epoch 0, gen_loss = 0.8425294638238411, disc_loss = 0.16751148476673233
Trained batch 427 in epoch 0, gen_loss = 0.8419014538559958, disc_loss = 0.16756882737869414
Trained batch 428 in epoch 0, gen_loss = 0.8414346046381064, disc_loss = 0.1676501701900731
Trained batch 429 in epoch 0, gen_loss = 0.841359037022258, disc_loss = 0.16799796459286712
Trained batch 430 in epoch 0, gen_loss = 0.8408270481014473, disc_loss = 0.1682514658245299
Trained batch 431 in epoch 0, gen_loss = 0.8404561994528329, disc_loss = 0.16829079779347889
Trained batch 432 in epoch 0, gen_loss = 0.8405041515689524, disc_loss = 0.16829920014663327
Trained batch 433 in epoch 0, gen_loss = 0.8401886296162407, disc_loss = 0.1682351482903353
Trained batch 434 in epoch 0, gen_loss = 0.839532298603277, disc_loss = 0.16846520044337743
Trained batch 435 in epoch 0, gen_loss = 0.8395652883096573, disc_loss = 0.1684155646335641
Trained batch 436 in epoch 0, gen_loss = 0.8394783358824881, disc_loss = 0.16843152066662873
Trained batch 437 in epoch 0, gen_loss = 0.8392165357663751, disc_loss = 0.16826901884247722
Trained batch 438 in epoch 0, gen_loss = 0.8388990720475181, disc_loss = 0.16836256440516756
Trained batch 439 in epoch 0, gen_loss = 0.8392704505812038, disc_loss = 0.1683646118776365
Trained batch 440 in epoch 0, gen_loss = 0.8392190925118064, disc_loss = 0.16823571741310647
Trained batch 441 in epoch 0, gen_loss = 0.8384901331021235, disc_loss = 0.16850206926802164
Trained batch 442 in epoch 0, gen_loss = 0.8384747865775907, disc_loss = 0.1685334391236036
Trained batch 443 in epoch 0, gen_loss = 0.8381734589735667, disc_loss = 0.168364811671881
Trained batch 444 in epoch 0, gen_loss = 0.8379593743367142, disc_loss = 0.16829512847608394
Trained batch 445 in epoch 0, gen_loss = 0.837878210127621, disc_loss = 0.16817246001598013
Trained batch 446 in epoch 0, gen_loss = 0.8379242217514072, disc_loss = 0.167945307123181
Trained batch 447 in epoch 0, gen_loss = 0.8375257184462888, disc_loss = 0.1678231980851186
Trained batch 448 in epoch 0, gen_loss = 0.8374830209598244, disc_loss = 0.1676523797628874
Trained batch 449 in epoch 0, gen_loss = 0.8379211978117624, disc_loss = 0.16742349622978103
Trained batch 450 in epoch 0, gen_loss = 0.8376095478656287, disc_loss = 0.16723909856805252
Trained batch 451 in epoch 0, gen_loss = 0.8373981668094618, disc_loss = 0.1671379848622379
Trained batch 452 in epoch 0, gen_loss = 0.8374595772351651, disc_loss = 0.1670408442813829
Trained batch 453 in epoch 0, gen_loss = 0.8369599526936787, disc_loss = 0.16701663188669125
Trained batch 454 in epoch 0, gen_loss = 0.8374700985112034, disc_loss = 0.1669514061494188
Trained batch 455 in epoch 0, gen_loss = 0.8369301415064878, disc_loss = 0.16739097017010576
Trained batch 456 in epoch 0, gen_loss = 0.8377354341993186, disc_loss = 0.1677436933769178
Trained batch 457 in epoch 0, gen_loss = 0.8373028456383917, disc_loss = 0.16773672302672435
Trained batch 458 in epoch 0, gen_loss = 0.8367687926053481, disc_loss = 0.16782040155466346
Trained batch 459 in epoch 0, gen_loss = 0.8369524328604988, disc_loss = 0.16801443480603073
Trained batch 460 in epoch 0, gen_loss = 0.8367225980293208, disc_loss = 0.16795789553842422
Trained batch 461 in epoch 0, gen_loss = 0.8362805354388761, disc_loss = 0.16794406453316862
Trained batch 462 in epoch 0, gen_loss = 0.8359907740650631, disc_loss = 0.1679051067382419
Trained batch 463 in epoch 0, gen_loss = 0.836061914547764, disc_loss = 0.16806169787164907
Trained batch 464 in epoch 0, gen_loss = 0.8356491213203758, disc_loss = 0.1680826938761178
Trained batch 465 in epoch 0, gen_loss = 0.8349850482183465, disc_loss = 0.16811718054659378
Trained batch 466 in epoch 0, gen_loss = 0.8349128237883591, disc_loss = 0.16807460843942407
Trained batch 467 in epoch 0, gen_loss = 0.8347317356074977, disc_loss = 0.16809159569824353
Trained batch 468 in epoch 0, gen_loss = 0.8346249147264688, disc_loss = 0.16800419730481816
Trained batch 469 in epoch 0, gen_loss = 0.8343774794264043, disc_loss = 0.1679769424206399
Trained batch 470 in epoch 0, gen_loss = 0.8338031758674896, disc_loss = 0.16797999270465977
Trained batch 471 in epoch 0, gen_loss = 0.8334750762935412, disc_loss = 0.16803337982461108
Trained batch 472 in epoch 0, gen_loss = 0.8328973159477524, disc_loss = 0.16801519444641552
Trained batch 473 in epoch 0, gen_loss = 0.8322952627381192, disc_loss = 0.1680182575204956
Trained batch 474 in epoch 0, gen_loss = 0.832242783370771, disc_loss = 0.16801407897158674
Trained batch 475 in epoch 0, gen_loss = 0.832207275789325, disc_loss = 0.16796817337828024
Trained batch 476 in epoch 0, gen_loss = 0.8318429667994661, disc_loss = 0.16789279801603132
Trained batch 477 in epoch 0, gen_loss = 0.8315596846107659, disc_loss = 0.1678326496675174
Trained batch 478 in epoch 0, gen_loss = 0.8318716881170651, disc_loss = 0.16797938938242907
Trained batch 479 in epoch 0, gen_loss = 0.8317809027930101, disc_loss = 0.1678276530156533
Trained batch 480 in epoch 0, gen_loss = 0.8315745054312407, disc_loss = 0.1677902158729252
Trained batch 481 in epoch 0, gen_loss = 0.831703129893022, disc_loss = 0.16791751279004877
Trained batch 482 in epoch 0, gen_loss = 0.8315508429801736, disc_loss = 0.16777409418769504
Trained batch 483 in epoch 0, gen_loss = 0.8310971500213481, disc_loss = 0.16776394643936277
Trained batch 484 in epoch 0, gen_loss = 0.8309905318869758, disc_loss = 0.16762701841359287
Trained batch 485 in epoch 0, gen_loss = 0.8311001912311271, disc_loss = 0.16752007160596397
Trained batch 486 in epoch 0, gen_loss = 0.8306229296895757, disc_loss = 0.16750989204131111
Trained batch 487 in epoch 0, gen_loss = 0.8307906666495761, disc_loss = 0.16754395971227376
Trained batch 488 in epoch 0, gen_loss = 0.8302876838389593, disc_loss = 0.16756121178894687
Trained batch 489 in epoch 0, gen_loss = 0.8301207349008444, disc_loss = 0.16770602666905948
Trained batch 490 in epoch 0, gen_loss = 0.8295022859835576, disc_loss = 0.16776545936063447
Trained batch 491 in epoch 0, gen_loss = 0.829174401314278, disc_loss = 0.16773757536903144
Trained batch 492 in epoch 0, gen_loss = 0.8290905760219566, disc_loss = 0.16772090123766092
Trained batch 493 in epoch 0, gen_loss = 0.8286502612264532, disc_loss = 0.16765963541049705
Trained batch 494 in epoch 0, gen_loss = 0.8285987282040144, disc_loss = 0.16766773316294256
Trained batch 495 in epoch 0, gen_loss = 0.8287713045795118, disc_loss = 0.16740766271287877
Trained batch 496 in epoch 0, gen_loss = 0.8284999629861153, disc_loss = 0.16721466856763156
Trained batch 497 in epoch 0, gen_loss = 0.8281898350121984, disc_loss = 0.16713968624013015
Trained batch 498 in epoch 0, gen_loss = 0.8285760709900177, disc_loss = 0.16720237788970102
Trained batch 499 in epoch 0, gen_loss = 0.8286731901168823, disc_loss = 0.16695944675058128
Trained batch 500 in epoch 0, gen_loss = 0.8280617548320108, disc_loss = 0.1674026843539612
Trained batch 501 in epoch 0, gen_loss = 0.8287468448103187, disc_loss = 0.16759596707900445
Trained batch 502 in epoch 0, gen_loss = 0.828685458090386, disc_loss = 0.16751715232049733
Trained batch 503 in epoch 0, gen_loss = 0.8280627848136992, disc_loss = 0.16786661725639115
Trained batch 504 in epoch 0, gen_loss = 0.8277144191288712, disc_loss = 0.16773395466774998
Trained batch 505 in epoch 0, gen_loss = 0.8277436639716031, disc_loss = 0.16769891950069915
Trained batch 506 in epoch 0, gen_loss = 0.8275404054032275, disc_loss = 0.16764874931946544
Trained batch 507 in epoch 0, gen_loss = 0.8273420599032575, disc_loss = 0.16755184967540146
Trained batch 508 in epoch 0, gen_loss = 0.8270558132872367, disc_loss = 0.16750378115560077
Trained batch 509 in epoch 0, gen_loss = 0.8266111357539307, disc_loss = 0.16752889477008698
Trained batch 510 in epoch 0, gen_loss = 0.8261388522771473, disc_loss = 0.16754938346386655
Trained batch 511 in epoch 0, gen_loss = 0.8258772449335083, disc_loss = 0.1674516230050358
Trained batch 512 in epoch 0, gen_loss = 0.8259334651350277, disc_loss = 0.16744314740479108
Trained batch 513 in epoch 0, gen_loss = 0.8258605383713422, disc_loss = 0.16728216530718923
Trained batch 514 in epoch 0, gen_loss = 0.8255197610669923, disc_loss = 0.1671829044891214
Trained batch 515 in epoch 0, gen_loss = 0.8256269956743995, disc_loss = 0.16716506705410028
Trained batch 516 in epoch 0, gen_loss = 0.8258811996338216, disc_loss = 0.16689082684726733
Trained batch 517 in epoch 0, gen_loss = 0.8255659588055261, disc_loss = 0.16665668116745802
Trained batch 518 in epoch 0, gen_loss = 0.8254688330468415, disc_loss = 0.16644936751193853
Trained batch 519 in epoch 0, gen_loss = 0.8257140929882343, disc_loss = 0.16617142665916337
Trained batch 520 in epoch 0, gen_loss = 0.8257522697412121, disc_loss = 0.16596314141923657
Trained batch 521 in epoch 0, gen_loss = 0.8261362076719145, disc_loss = 0.16579318871200655
Trained batch 522 in epoch 0, gen_loss = 0.8265685221433183, disc_loss = 0.16549769394014238
Trained batch 523 in epoch 0, gen_loss = 0.8263483709506406, disc_loss = 0.165406703348236
Trained batch 524 in epoch 0, gen_loss = 0.8272292062214442, disc_loss = 0.16544783807581379
Trained batch 525 in epoch 0, gen_loss = 0.8274929994865968, disc_loss = 0.16518500235512457
Trained batch 526 in epoch 0, gen_loss = 0.8272912315670861, disc_loss = 0.16526626712824632
Trained batch 527 in epoch 0, gen_loss = 0.8272891992872412, disc_loss = 0.16523175108754498
Trained batch 528 in epoch 0, gen_loss = 0.8274370775556293, disc_loss = 0.165331910605523
Trained batch 529 in epoch 0, gen_loss = 0.8272373046515122, disc_loss = 0.16513600781700521
Trained batch 530 in epoch 0, gen_loss = 0.8267108074015816, disc_loss = 0.1651597436299993
Trained batch 531 in epoch 0, gen_loss = 0.826874461837281, disc_loss = 0.165063156830357
Trained batch 532 in epoch 0, gen_loss = 0.8273324076274994, disc_loss = 0.1649257849839011
Trained batch 533 in epoch 0, gen_loss = 0.8268552862303087, disc_loss = 0.16516425183621908
Trained batch 534 in epoch 0, gen_loss = 0.8269162120106064, disc_loss = 0.16527461163769258
Trained batch 535 in epoch 0, gen_loss = 0.8266789310458881, disc_loss = 0.16512471206013613
Trained batch 536 in epoch 0, gen_loss = 0.8264977497983467, disc_loss = 0.16498653133515984
Trained batch 537 in epoch 0, gen_loss = 0.8263356376536274, disc_loss = 0.16502894977017626
Trained batch 538 in epoch 0, gen_loss = 0.8258987578921061, disc_loss = 0.16508812744149692
Trained batch 539 in epoch 0, gen_loss = 0.8256115363703833, disc_loss = 0.1650356929404316
Trained batch 540 in epoch 0, gen_loss = 0.8262411664462134, disc_loss = 0.16560255873142682
Trained batch 541 in epoch 0, gen_loss = 0.8256759995464029, disc_loss = 0.16584714238851492
Trained batch 542 in epoch 0, gen_loss = 0.825271248158829, disc_loss = 0.1658991748744941
Trained batch 543 in epoch 0, gen_loss = 0.8253081508857363, disc_loss = 0.16609139231663636
Trained batch 544 in epoch 0, gen_loss = 0.8251037464229338, disc_loss = 0.16607971131938312
Trained batch 545 in epoch 0, gen_loss = 0.8246950078141558, disc_loss = 0.16613313496358448
Trained batch 546 in epoch 0, gen_loss = 0.8245605741384042, disc_loss = 0.1661660984580761
Trained batch 547 in epoch 0, gen_loss = 0.8244635574791553, disc_loss = 0.1661356920920258
Trained batch 548 in epoch 0, gen_loss = 0.8241378080866593, disc_loss = 0.16615812136420136
Trained batch 549 in epoch 0, gen_loss = 0.8237150242111899, disc_loss = 0.1661498631198298
Trained batch 550 in epoch 0, gen_loss = 0.823635786825862, disc_loss = 0.16613971698224653
Trained batch 551 in epoch 0, gen_loss = 0.8234779285132021, disc_loss = 0.16616832233452494
Trained batch 552 in epoch 0, gen_loss = 0.8232266423284037, disc_loss = 0.1661999092570373
Trained batch 553 in epoch 0, gen_loss = 0.8229099505644843, disc_loss = 0.16611262182923645
Trained batch 554 in epoch 0, gen_loss = 0.8227101779198861, disc_loss = 0.1660530007435932
Trained batch 555 in epoch 0, gen_loss = 0.8225239866929088, disc_loss = 0.1659722548152367
Trained batch 556 in epoch 0, gen_loss = 0.8221247442320818, disc_loss = 0.16590300758153576
Trained batch 557 in epoch 0, gen_loss = 0.8216521838232608, disc_loss = 0.16591310083839414
Trained batch 558 in epoch 0, gen_loss = 0.8216072800760832, disc_loss = 0.16592168284843348
Trained batch 559 in epoch 0, gen_loss = 0.821140020447118, disc_loss = 0.1660193064316575
Trained batch 560 in epoch 0, gen_loss = 0.8210012407013865, disc_loss = 0.16589463524082126
Trained batch 561 in epoch 0, gen_loss = 0.8209492444355717, disc_loss = 0.1657407044555687
Trained batch 562 in epoch 0, gen_loss = 0.8204243831058591, disc_loss = 0.16576728536408283
Trained batch 563 in epoch 0, gen_loss = 0.8207983476050357, disc_loss = 0.16572450314721104
Trained batch 564 in epoch 0, gen_loss = 0.8207675838892439, disc_loss = 0.1655194074772628
Trained batch 565 in epoch 0, gen_loss = 0.8202372103824211, disc_loss = 0.1654882017233452
Trained batch 566 in epoch 0, gen_loss = 0.8202802627174942, disc_loss = 0.16548217323853437
Trained batch 567 in epoch 0, gen_loss = 0.819797132111771, disc_loss = 0.16562931717727597
Trained batch 568 in epoch 0, gen_loss = 0.8198063315951343, disc_loss = 0.1657267832811038
Trained batch 569 in epoch 0, gen_loss = 0.8195815940697988, disc_loss = 0.16560515861370062
Trained batch 570 in epoch 0, gen_loss = 0.819258935501613, disc_loss = 0.1655424218266002
Trained batch 571 in epoch 0, gen_loss = 0.819336375990114, disc_loss = 0.16559869265248933
Trained batch 572 in epoch 0, gen_loss = 0.819114573234871, disc_loss = 0.1654504094253348
Trained batch 573 in epoch 0, gen_loss = 0.8186047931789106, disc_loss = 0.16550060502457908
Trained batch 574 in epoch 0, gen_loss = 0.8186090181184852, disc_loss = 0.16540298658220665
Trained batch 575 in epoch 0, gen_loss = 0.8190146846075853, disc_loss = 0.16533706036473936
Trained batch 576 in epoch 0, gen_loss = 0.8186426142059537, disc_loss = 0.16537117252394273
Trained batch 577 in epoch 0, gen_loss = 0.8182163814978616, disc_loss = 0.16549198161230574
Trained batch 578 in epoch 0, gen_loss = 0.8187032395488034, disc_loss = 0.16584324097463504
Trained batch 579 in epoch 0, gen_loss = 0.8185858667924486, disc_loss = 0.16575396837473944
Trained batch 580 in epoch 0, gen_loss = 0.8181600463985371, disc_loss = 0.16585208768611726
Trained batch 581 in epoch 0, gen_loss = 0.8179296357525173, disc_loss = 0.16578513192480168
Trained batch 582 in epoch 0, gen_loss = 0.818114045247001, disc_loss = 0.16576506420458775
Trained batch 583 in epoch 0, gen_loss = 0.8179712874228007, disc_loss = 0.16562370654221062
Trained batch 584 in epoch 0, gen_loss = 0.8174967408180237, disc_loss = 0.1657362165550391
Trained batch 585 in epoch 0, gen_loss = 0.8173576460153169, disc_loss = 0.16568586689900008
Trained batch 586 in epoch 0, gen_loss = 0.8173122463884305, disc_loss = 0.16573187794530006
Trained batch 587 in epoch 0, gen_loss = 0.8170443422534839, disc_loss = 0.1656825763623224
Trained batch 588 in epoch 0, gen_loss = 0.8167441863762704, disc_loss = 0.16560311377023193
Trained batch 589 in epoch 0, gen_loss = 0.8166913123454078, disc_loss = 0.1654421360500283
Trained batch 590 in epoch 0, gen_loss = 0.8162889655068037, disc_loss = 0.16547123903121844
Trained batch 591 in epoch 0, gen_loss = 0.816016601448929, disc_loss = 0.16556395330415988
Trained batch 592 in epoch 0, gen_loss = 0.8154808667819777, disc_loss = 0.16565119051083949
Trained batch 593 in epoch 0, gen_loss = 0.8155217858075293, disc_loss = 0.16566106061818023
Trained batch 594 in epoch 0, gen_loss = 0.8155235533954717, disc_loss = 0.1655421413856895
Trained batch 595 in epoch 0, gen_loss = 0.8150758516268443, disc_loss = 0.1655490615236379
Trained batch 596 in epoch 0, gen_loss = 0.8149879058601469, disc_loss = 0.16554122025668122
Trained batch 597 in epoch 0, gen_loss = 0.8153319665819506, disc_loss = 0.16545275771323853
Trained batch 598 in epoch 0, gen_loss = 0.8149114336712731, disc_loss = 0.16546786095766672
Trained batch 599 in epoch 0, gen_loss = 0.8147126586238543, disc_loss = 0.16536713732406497
Trained batch 600 in epoch 0, gen_loss = 0.8150910965218123, disc_loss = 0.16527061917495212
Trained batch 601 in epoch 0, gen_loss = 0.8146846012221618, disc_loss = 0.16522083279871663
Trained batch 602 in epoch 0, gen_loss = 0.8141911319436916, disc_loss = 0.1653927942648357
Trained batch 603 in epoch 0, gen_loss = 0.8138867362050821, disc_loss = 0.1653373022286209
Trained batch 604 in epoch 0, gen_loss = 0.8136720168689066, disc_loss = 0.16532896823011153
Trained batch 605 in epoch 0, gen_loss = 0.8137620593061542, disc_loss = 0.1652413530355141
Trained batch 606 in epoch 0, gen_loss = 0.8137988747639161, disc_loss = 0.16503811554593545
Trained batch 607 in epoch 0, gen_loss = 0.8136772222228741, disc_loss = 0.16487340771862746
Trained batch 608 in epoch 0, gen_loss = 0.8135468645636084, disc_loss = 0.1648043805583455
Trained batch 609 in epoch 0, gen_loss = 0.8143276004517664, disc_loss = 0.16459584035223626
Trained batch 610 in epoch 0, gen_loss = 0.8144233227751649, disc_loss = 0.16436196642938494
Trained batch 611 in epoch 0, gen_loss = 0.8142325861586465, disc_loss = 0.16430123231915478
Trained batch 612 in epoch 0, gen_loss = 0.8143722749456496, disc_loss = 0.16412989564276442
Trained batch 613 in epoch 0, gen_loss = 0.8150482464108483, disc_loss = 0.16448062469011798
Trained batch 614 in epoch 0, gen_loss = 0.8145643181917144, disc_loss = 0.16461238747205192
Trained batch 615 in epoch 0, gen_loss = 0.8145285099744797, disc_loss = 0.16444559011898643
Trained batch 616 in epoch 0, gen_loss = 0.8143932634852887, disc_loss = 0.1643511779376908
Trained batch 617 in epoch 0, gen_loss = 0.8145051545502684, disc_loss = 0.16437034293237626
Trained batch 618 in epoch 0, gen_loss = 0.8142649658469661, disc_loss = 0.16443004550619927
Trained batch 619 in epoch 0, gen_loss = 0.813992315530777, disc_loss = 0.16448245638560866
Trained batch 620 in epoch 0, gen_loss = 0.8138802557367826, disc_loss = 0.1644326513828095
Trained batch 621 in epoch 0, gen_loss = 0.8135259822250562, disc_loss = 0.16439472810871347
Trained batch 622 in epoch 0, gen_loss = 0.8134412220163483, disc_loss = 0.16440833644585662
Trained batch 623 in epoch 0, gen_loss = 0.8130130486037487, disc_loss = 0.16449452839935055
Trained batch 624 in epoch 0, gen_loss = 0.8129078102111816, disc_loss = 0.16457160342931748
Trained batch 625 in epoch 0, gen_loss = 0.8124245348068091, disc_loss = 0.1646184877584727
Trained batch 626 in epoch 0, gen_loss = 0.8126309257374996, disc_loss = 0.16455746720139489
Trained batch 627 in epoch 0, gen_loss = 0.8123050925268489, disc_loss = 0.16455692345881537
Trained batch 628 in epoch 0, gen_loss = 0.812402148220232, disc_loss = 0.16452584505697124
Trained batch 629 in epoch 0, gen_loss = 0.812139811496886, disc_loss = 0.16454517298511095
Trained batch 630 in epoch 0, gen_loss = 0.8119750642549783, disc_loss = 0.16459415273271535
Trained batch 631 in epoch 0, gen_loss = 0.8116968394834784, disc_loss = 0.16458463280968652
Trained batch 632 in epoch 0, gen_loss = 0.8114898420434804, disc_loss = 0.16456949966260795
Trained batch 633 in epoch 0, gen_loss = 0.8112503967074566, disc_loss = 0.16459564217116554
Trained batch 634 in epoch 0, gen_loss = 0.810933610773462, disc_loss = 0.1646035962804096
Trained batch 635 in epoch 0, gen_loss = 0.8108230461864352, disc_loss = 0.16464944808222587
Trained batch 636 in epoch 0, gen_loss = 0.8105329990948388, disc_loss = 0.16464373573450317
Trained batch 637 in epoch 0, gen_loss = 0.8102795392928827, disc_loss = 0.16468619610121632
Trained batch 638 in epoch 0, gen_loss = 0.8100469658072565, disc_loss = 0.16481843892723927
Trained batch 639 in epoch 0, gen_loss = 0.809554435359314, disc_loss = 0.1648641800857149
Trained batch 640 in epoch 0, gen_loss = 0.8094750648820642, disc_loss = 0.1648531088753721
Trained batch 641 in epoch 0, gen_loss = 0.8093746177782523, disc_loss = 0.16496037038455127
Trained batch 642 in epoch 0, gen_loss = 0.8088409263368342, disc_loss = 0.1650699981101564
Trained batch 643 in epoch 0, gen_loss = 0.8087320668819529, disc_loss = 0.1650554723921955
Trained batch 644 in epoch 0, gen_loss = 0.8085500185341798, disc_loss = 0.16499894886284835
Trained batch 645 in epoch 0, gen_loss = 0.808314026647677, disc_loss = 0.16499279588230253
Trained batch 646 in epoch 0, gen_loss = 0.8081690279833131, disc_loss = 0.16502821423585484
Trained batch 647 in epoch 0, gen_loss = 0.807903013985466, disc_loss = 0.1650162150071543
Trained batch 648 in epoch 0, gen_loss = 0.8075404214473277, disc_loss = 0.16504149406413635
Trained batch 649 in epoch 0, gen_loss = 0.8076733412650915, disc_loss = 0.16506395733127227
Trained batch 650 in epoch 0, gen_loss = 0.8077221366758537, disc_loss = 0.16493368230061964
Trained batch 651 in epoch 0, gen_loss = 0.8074757644643813, disc_loss = 0.16511605843398836
Trained batch 652 in epoch 0, gen_loss = 0.8079472107963942, disc_loss = 0.16516001765569172
Trained batch 653 in epoch 0, gen_loss = 0.8079774483172536, disc_loss = 0.16499648100784794
Trained batch 654 in epoch 0, gen_loss = 0.807613461299707, disc_loss = 0.16506664515224123
Trained batch 655 in epoch 0, gen_loss = 0.8078760590585994, disc_loss = 0.1650877454908701
Trained batch 656 in epoch 0, gen_loss = 0.807802693348497, disc_loss = 0.16495694441202025
Trained batch 657 in epoch 0, gen_loss = 0.8073518989568061, disc_loss = 0.1650447991413367
Trained batch 658 in epoch 0, gen_loss = 0.8077493386402478, disc_loss = 0.16531898934897232
Trained batch 659 in epoch 0, gen_loss = 0.8072299220796787, disc_loss = 0.16529817092373517
Trained batch 660 in epoch 0, gen_loss = 0.8067721796198078, disc_loss = 0.1655706883987212
Trained batch 661 in epoch 0, gen_loss = 0.8069246683686161, disc_loss = 0.1658072805994407
Trained batch 662 in epoch 0, gen_loss = 0.8069972177885956, disc_loss = 0.16581408907610187
Trained batch 663 in epoch 0, gen_loss = 0.8066899717661989, disc_loss = 0.1659004056871117
Trained batch 664 in epoch 0, gen_loss = 0.8066083105435049, disc_loss = 0.1658266913958062
Trained batch 665 in epoch 0, gen_loss = 0.8066466798384985, disc_loss = 0.16590092354663857
Trained batch 666 in epoch 0, gen_loss = 0.8063417631557499, disc_loss = 0.16587514903904615
Trained batch 667 in epoch 0, gen_loss = 0.805890787459776, disc_loss = 0.16594609293618245
Trained batch 668 in epoch 0, gen_loss = 0.8055385929853927, disc_loss = 0.16595160792984057
Trained batch 669 in epoch 0, gen_loss = 0.8054058981030735, disc_loss = 0.16591319380633868
Trained batch 670 in epoch 0, gen_loss = 0.8051940035269264, disc_loss = 0.16588180694290494
Trained batch 671 in epoch 0, gen_loss = 0.805077158136382, disc_loss = 0.1658264223286616
Trained batch 672 in epoch 0, gen_loss = 0.8048296642073196, disc_loss = 0.16585794063547923
Trained batch 673 in epoch 0, gen_loss = 0.8046585733971893, disc_loss = 0.16581070674058238
Trained batch 674 in epoch 0, gen_loss = 0.8044882307670734, disc_loss = 0.16573625748908077
Trained batch 675 in epoch 0, gen_loss = 0.8042633236777148, disc_loss = 0.16568933009616368
Trained batch 676 in epoch 0, gen_loss = 0.8040453318390923, disc_loss = 0.1656214507789168
Trained batch 677 in epoch 0, gen_loss = 0.804075769398768, disc_loss = 0.16556041040471522
Trained batch 678 in epoch 0, gen_loss = 0.8039746772997158, disc_loss = 0.16540368211857526
Trained batch 679 in epoch 0, gen_loss = 0.8037730845020098, disc_loss = 0.16525894722298665
Trained batch 680 in epoch 0, gen_loss = 0.8039144404046511, disc_loss = 0.16522424845312136
Trained batch 681 in epoch 0, gen_loss = 0.8037329653928007, disc_loss = 0.1651019027942786
Trained batch 682 in epoch 0, gen_loss = 0.8032753825798565, disc_loss = 0.16512279864809698
Trained batch 683 in epoch 0, gen_loss = 0.8033911356190492, disc_loss = 0.16510553420548552
Trained batch 684 in epoch 0, gen_loss = 0.8033941871493402, disc_loss = 0.16507577112991445
Trained batch 685 in epoch 0, gen_loss = 0.8031575828790665, disc_loss = 0.16503695255205167
Trained batch 686 in epoch 0, gen_loss = 0.8030524435609016, disc_loss = 0.16500224016899626
Trained batch 687 in epoch 0, gen_loss = 0.8031149846609942, disc_loss = 0.16488721911513873
Trained batch 688 in epoch 0, gen_loss = 0.8030360353615875, disc_loss = 0.16474468631910483
Trained batch 689 in epoch 0, gen_loss = 0.802806765920874, disc_loss = 0.16468793447466865
Trained batch 690 in epoch 0, gen_loss = 0.802944555770816, disc_loss = 0.1649668179614154
Trained batch 691 in epoch 0, gen_loss = 0.8025966028688271, disc_loss = 0.1650904310231953
Trained batch 692 in epoch 0, gen_loss = 0.8024836885722685, disc_loss = 0.165063031652101
Trained batch 693 in epoch 0, gen_loss = 0.8025838148267537, disc_loss = 0.16508228102060146
Trained batch 694 in epoch 0, gen_loss = 0.8025733628290163, disc_loss = 0.16493783689660135
Trained batch 695 in epoch 0, gen_loss = 0.8024865995621544, disc_loss = 0.16480038245476183
Trained batch 696 in epoch 0, gen_loss = 0.8021245980621924, disc_loss = 0.16473464625039094
Trained batch 697 in epoch 0, gen_loss = 0.8022592279921289, disc_loss = 0.1646360435168176
Trained batch 698 in epoch 0, gen_loss = 0.8018316983409194, disc_loss = 0.16468685225867408
Trained batch 699 in epoch 0, gen_loss = 0.8021314821498735, disc_loss = 0.16466935509017536
Trained batch 700 in epoch 0, gen_loss = 0.802294323473276, disc_loss = 0.1644809866236382
Trained batch 701 in epoch 0, gen_loss = 0.8020003681254183, disc_loss = 0.16443074336461191
Trained batch 702 in epoch 0, gen_loss = 0.8022876240705189, disc_loss = 0.1642912549429055
Trained batch 703 in epoch 0, gen_loss = 0.8023488135077059, disc_loss = 0.16415479946458203
Trained batch 704 in epoch 0, gen_loss = 0.8019881255660497, disc_loss = 0.1642585811885536
Trained batch 705 in epoch 0, gen_loss = 0.8023505197790459, disc_loss = 0.16454724811291896
Trained batch 706 in epoch 0, gen_loss = 0.8020963444989675, disc_loss = 0.16452577261219942
Trained batch 707 in epoch 0, gen_loss = 0.8017305928350842, disc_loss = 0.1646019279283319
Trained batch 708 in epoch 0, gen_loss = 0.8016851819704887, disc_loss = 0.1645559220034918
Trained batch 709 in epoch 0, gen_loss = 0.8015199347700871, disc_loss = 0.16457778952071364
Trained batch 710 in epoch 0, gen_loss = 0.8012244198811875, disc_loss = 0.16456908245378404
Trained batch 711 in epoch 0, gen_loss = 0.8011201158417075, disc_loss = 0.16450683474331423
Trained batch 712 in epoch 0, gen_loss = 0.800999118310372, disc_loss = 0.1644572502454066
Trained batch 713 in epoch 0, gen_loss = 0.8006684030888795, disc_loss = 0.16444000473418155
Trained batch 714 in epoch 0, gen_loss = 0.8005836173787817, disc_loss = 0.16442264450805172
Trained batch 715 in epoch 0, gen_loss = 0.8005702730746909, disc_loss = 0.1643134702371652
Trained batch 716 in epoch 0, gen_loss = 0.8009472613637251, disc_loss = 0.16419450965719076
Trained batch 717 in epoch 0, gen_loss = 0.8007172150615198, disc_loss = 0.16408463934835948
Trained batch 718 in epoch 0, gen_loss = 0.8003276226334843, disc_loss = 0.16409220974451974
Trained batch 719 in epoch 0, gen_loss = 0.8003762834188011, disc_loss = 0.16425783818380701
Trained batch 720 in epoch 0, gen_loss = 0.8000570565007431, disc_loss = 0.16435150678131352
Trained batch 721 in epoch 0, gen_loss = 0.7997756249108803, disc_loss = 0.16438201265899757
Trained batch 722 in epoch 0, gen_loss = 0.7997260151809676, disc_loss = 0.1643616874724173
Trained batch 723 in epoch 0, gen_loss = 0.7995666588620586, disc_loss = 0.16432614153179015
Trained batch 724 in epoch 0, gen_loss = 0.7993303580530758, disc_loss = 0.16435019612312318
Trained batch 725 in epoch 0, gen_loss = 0.7993861107212125, disc_loss = 0.16437165049153582
Trained batch 726 in epoch 0, gen_loss = 0.7997060701394507, disc_loss = 0.16419765356789756
Trained batch 727 in epoch 0, gen_loss = 0.7995167890010955, disc_loss = 0.16411225838013566
Trained batch 728 in epoch 0, gen_loss = 0.799543972572999, disc_loss = 0.1639409886905604
Trained batch 729 in epoch 0, gen_loss = 0.7992631422738506, disc_loss = 0.16389234792185972
Trained batch 730 in epoch 0, gen_loss = 0.7995304786147889, disc_loss = 0.16386479540395507
Trained batch 731 in epoch 0, gen_loss = 0.7994017037130444, disc_loss = 0.16374098893784272
Trained batch 732 in epoch 0, gen_loss = 0.7993803879329973, disc_loss = 0.16359061085572021
Trained batch 733 in epoch 0, gen_loss = 0.7994129137625812, disc_loss = 0.16349861055754672
Trained batch 734 in epoch 0, gen_loss = 0.7989034825847262, disc_loss = 0.16352830350297648
Trained batch 735 in epoch 0, gen_loss = 0.798620737724654, disc_loss = 0.16347702887698845
Trained batch 736 in epoch 0, gen_loss = 0.7992045573253321, disc_loss = 0.16354705892210092
Trained batch 737 in epoch 0, gen_loss = 0.7987711946896421, disc_loss = 0.163585537428738
Trained batch 738 in epoch 0, gen_loss = 0.7984520077140793, disc_loss = 0.16367642068794358
Trained batch 739 in epoch 0, gen_loss = 0.7988425906848263, disc_loss = 0.16392584521122075
Trained batch 740 in epoch 0, gen_loss = 0.7989930503683695, disc_loss = 0.1637787004070565
Trained batch 741 in epoch 0, gen_loss = 0.7990710518832477, disc_loss = 0.1636173040719045
Trained batch 742 in epoch 0, gen_loss = 0.7989377429555916, disc_loss = 0.1635024345217932
Trained batch 743 in epoch 0, gen_loss = 0.7989675358979291, disc_loss = 0.16335236520997137
Trained batch 744 in epoch 0, gen_loss = 0.7989926384199386, disc_loss = 0.16319792103647385
Trained batch 745 in epoch 0, gen_loss = 0.7989034016314525, disc_loss = 0.16306836872134386
Trained batch 746 in epoch 0, gen_loss = 0.798935804301636, disc_loss = 0.16300652269897373
Trained batch 747 in epoch 0, gen_loss = 0.7990000896195677, disc_loss = 0.1628797716177243
Trained batch 748 in epoch 0, gen_loss = 0.7989866398921478, disc_loss = 0.1628523627233919
Trained batch 749 in epoch 0, gen_loss = 0.7989026813904444, disc_loss = 0.16273314985632897
Trained batch 750 in epoch 0, gen_loss = 0.7992487427159727, disc_loss = 0.1626065307446866
Trained batch 751 in epoch 0, gen_loss = 0.7988313141655414, disc_loss = 0.16266265258866738
Trained batch 752 in epoch 0, gen_loss = 0.7991001273531363, disc_loss = 0.16289739016873903
Trained batch 753 in epoch 0, gen_loss = 0.7989242057901479, disc_loss = 0.16280387536639876
Trained batch 754 in epoch 0, gen_loss = 0.7986888280767479, disc_loss = 0.16275261574430971
Trained batch 755 in epoch 0, gen_loss = 0.7988999983463337, disc_loss = 0.16266855551176285
Trained batch 756 in epoch 0, gen_loss = 0.7988297049561454, disc_loss = 0.16261697290871227
Trained batch 757 in epoch 0, gen_loss = 0.7984787207637425, disc_loss = 0.16268416461694524
Trained batch 758 in epoch 0, gen_loss = 0.7985612926747017, disc_loss = 0.16264709016511877
Trained batch 759 in epoch 0, gen_loss = 0.7988996698668128, disc_loss = 0.16275253149827845
Trained batch 760 in epoch 0, gen_loss = 0.7985803021237978, disc_loss = 0.16278909329868335
Trained batch 761 in epoch 0, gen_loss = 0.798486478685394, disc_loss = 0.1627272720255564
Trained batch 762 in epoch 0, gen_loss = 0.7983704265573234, disc_loss = 0.16273651503485434
Trained batch 763 in epoch 0, gen_loss = 0.798279931485965, disc_loss = 0.16279176197438963
Trained batch 764 in epoch 0, gen_loss = 0.7982154906185623, disc_loss = 0.16272128122109994
Trained batch 765 in epoch 0, gen_loss = 0.7979495815602046, disc_loss = 0.16274616136835698
Trained batch 766 in epoch 0, gen_loss = 0.7977690114657913, disc_loss = 0.16275820368233063
Trained batch 767 in epoch 0, gen_loss = 0.7978518067393452, disc_loss = 0.16293625726636188
Trained batch 768 in epoch 0, gen_loss = 0.7977208704415162, disc_loss = 0.16296487196950515
Trained batch 769 in epoch 0, gen_loss = 0.7975435379263642, disc_loss = 0.1628888330192535
Trained batch 770 in epoch 0, gen_loss = 0.7974513403481855, disc_loss = 0.16283972071418504
Trained batch 771 in epoch 0, gen_loss = 0.7976513658626092, disc_loss = 0.16266697035243474
Trained batch 772 in epoch 0, gen_loss = 0.7973389075767794, disc_loss = 0.162755531893819
Trained batch 773 in epoch 0, gen_loss = 0.7974829404237043, disc_loss = 0.16269481673990724
Trained batch 774 in epoch 0, gen_loss = 0.7976274181181384, disc_loss = 0.16263032532507374
Trained batch 775 in epoch 0, gen_loss = 0.7973877566376912, disc_loss = 0.16266750012399608
Trained batch 776 in epoch 0, gen_loss = 0.7972647587611715, disc_loss = 0.1626214070132954
Trained batch 777 in epoch 0, gen_loss = 0.7976046468880612, disc_loss = 0.1626655828676984
Trained batch 778 in epoch 0, gen_loss = 0.7976484126548865, disc_loss = 0.16256286565391334
Trained batch 779 in epoch 0, gen_loss = 0.7973126837076285, disc_loss = 0.16258811476903084
Trained batch 780 in epoch 0, gen_loss = 0.797199416557439, disc_loss = 0.16253079695295586
Trained batch 781 in epoch 0, gen_loss = 0.7973431483711428, disc_loss = 0.16247349484916537
Trained batch 782 in epoch 0, gen_loss = 0.7974738352295692, disc_loss = 0.16231660976872742
Trained batch 783 in epoch 0, gen_loss = 0.7970940713219496, disc_loss = 0.1623925185021089
Trained batch 784 in epoch 0, gen_loss = 0.7973369172424268, disc_loss = 0.16237618676416435
Trained batch 785 in epoch 0, gen_loss = 0.7973081822158726, disc_loss = 0.1622804608527789
Trained batch 786 in epoch 0, gen_loss = 0.7970452194292633, disc_loss = 0.16224535202472606
Trained batch 787 in epoch 0, gen_loss = 0.7967701937038887, disc_loss = 0.16225366342604766
Trained batch 788 in epoch 0, gen_loss = 0.7969721177231677, disc_loss = 0.16226228819487212
Trained batch 789 in epoch 0, gen_loss = 0.7969743352147597, disc_loss = 0.16214787575263012
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.6752521991729736, disc_loss = 0.12050770223140717
Trained batch 1 in epoch 1, gen_loss = 0.7018984854221344, disc_loss = 0.09555337950587273
Trained batch 2 in epoch 1, gen_loss = 0.7998635371526083, disc_loss = 0.10878374924262364
Trained batch 3 in epoch 1, gen_loss = 0.767002671957016, disc_loss = 0.09944085590541363
Trained batch 4 in epoch 1, gen_loss = 0.7564929485321045, disc_loss = 0.09167841970920562
Trained batch 5 in epoch 1, gen_loss = 0.7497708797454834, disc_loss = 0.0889649565021197
Trained batch 6 in epoch 1, gen_loss = 0.7740132978984288, disc_loss = 0.08757023832627706
Trained batch 7 in epoch 1, gen_loss = 0.8087174743413925, disc_loss = 0.08084094151854515
Trained batch 8 in epoch 1, gen_loss = 0.7780610058042738, disc_loss = 0.08682494858900706
Trained batch 9 in epoch 1, gen_loss = 0.8050296068191528, disc_loss = 0.08541324362158775
Trained batch 10 in epoch 1, gen_loss = 0.7818576476790688, disc_loss = 0.10005773942578923
Trained batch 11 in epoch 1, gen_loss = 0.8052014956871668, disc_loss = 0.11166161236663659
Trained batch 12 in epoch 1, gen_loss = 0.8148818566248968, disc_loss = 0.1185798581976157
Trained batch 13 in epoch 1, gen_loss = 0.7904112466744014, disc_loss = 0.13404795793550356
Trained batch 14 in epoch 1, gen_loss = 0.7822953621546428, disc_loss = 0.13118375440438587
Trained batch 15 in epoch 1, gen_loss = 0.7897244468331337, disc_loss = 0.13193580973893404
Trained batch 16 in epoch 1, gen_loss = 0.7841984945185044, disc_loss = 0.13153008415418513
Trained batch 17 in epoch 1, gen_loss = 0.7746066583527459, disc_loss = 0.1305760153465801
Trained batch 18 in epoch 1, gen_loss = 0.7610122969276026, disc_loss = 0.13487353215092107
Trained batch 19 in epoch 1, gen_loss = 0.7581364750862122, disc_loss = 0.13341974839568138
Trained batch 20 in epoch 1, gen_loss = 0.7551307394391015, disc_loss = 0.13370524488744281
Trained batch 21 in epoch 1, gen_loss = 0.7516661286354065, disc_loss = 0.13419820368289948
Trained batch 22 in epoch 1, gen_loss = 0.7514847024627354, disc_loss = 0.13095889434866284
Trained batch 23 in epoch 1, gen_loss = 0.7523576890428861, disc_loss = 0.1280148164369166
Trained batch 24 in epoch 1, gen_loss = 0.7504632139205932, disc_loss = 0.12964849576354026
Trained batch 25 in epoch 1, gen_loss = 0.762980199777163, disc_loss = 0.13016396746612513
Trained batch 26 in epoch 1, gen_loss = 0.7592141716568558, disc_loss = 0.12777632792238836
Trained batch 27 in epoch 1, gen_loss = 0.7528813311031887, disc_loss = 0.13232549160186732
Trained batch 28 in epoch 1, gen_loss = 0.7511929438031953, disc_loss = 0.1319089019349937
Trained batch 29 in epoch 1, gen_loss = 0.7572573781013489, disc_loss = 0.1381660641481479
Trained batch 30 in epoch 1, gen_loss = 0.7525168849575904, disc_loss = 0.13776132091879845
Trained batch 31 in epoch 1, gen_loss = 0.7464678194373846, disc_loss = 0.14005284674931318
Trained batch 32 in epoch 1, gen_loss = 0.7496017922054637, disc_loss = 0.14247673083886955
Trained batch 33 in epoch 1, gen_loss = 0.7447814748567694, disc_loss = 0.14391730868202798
Trained batch 34 in epoch 1, gen_loss = 0.7437597938946315, disc_loss = 0.14460051751562528
Trained batch 35 in epoch 1, gen_loss = 0.748468612631162, disc_loss = 0.14339610944605535
Trained batch 36 in epoch 1, gen_loss = 0.7481562559669083, disc_loss = 0.14405942134357788
Trained batch 37 in epoch 1, gen_loss = 0.74587566287894, disc_loss = 0.14338240429366889
Trained batch 38 in epoch 1, gen_loss = 0.7434159410305512, disc_loss = 0.14214068221358153
Trained batch 39 in epoch 1, gen_loss = 0.741236899793148, disc_loss = 0.14124026848003268
Trained batch 40 in epoch 1, gen_loss = 0.7422330975532532, disc_loss = 0.14112151495930625
Trained batch 41 in epoch 1, gen_loss = 0.7449657207443601, disc_loss = 0.14122701924116837
Trained batch 42 in epoch 1, gen_loss = 0.7479156075521957, disc_loss = 0.13918638619226079
Trained batch 43 in epoch 1, gen_loss = 0.7435984056104313, disc_loss = 0.13971806834028525
Trained batch 44 in epoch 1, gen_loss = 0.7477196786138747, disc_loss = 0.13945513806409307
Trained batch 45 in epoch 1, gen_loss = 0.7545888048151265, disc_loss = 0.13735004150025223
Trained batch 46 in epoch 1, gen_loss = 0.7539814216025332, disc_loss = 0.1354611574652347
Trained batch 47 in epoch 1, gen_loss = 0.7515775772432486, disc_loss = 0.13422998460009694
Trained batch 48 in epoch 1, gen_loss = 0.7559677812517905, disc_loss = 0.13209375492012015
Trained batch 49 in epoch 1, gen_loss = 0.7604178285598755, disc_loss = 0.13089507158845662
Trained batch 50 in epoch 1, gen_loss = 0.7711145550596947, disc_loss = 0.12980262157233322
Trained batch 51 in epoch 1, gen_loss = 0.7748523285755744, disc_loss = 0.1275494277047423
Trained batch 52 in epoch 1, gen_loss = 0.773543822315504, disc_loss = 0.12582205292188897
Trained batch 53 in epoch 1, gen_loss = 0.7716252903143564, disc_loss = 0.12544389455406754
Trained batch 54 in epoch 1, gen_loss = 0.7751578428528526, disc_loss = 0.12569565285335887
Trained batch 55 in epoch 1, gen_loss = 0.7796245355691228, disc_loss = 0.12382100615650415
Trained batch 56 in epoch 1, gen_loss = 0.7761440057503549, disc_loss = 0.12391273402854015
Trained batch 57 in epoch 1, gen_loss = 0.7777964493324017, disc_loss = 0.12275381251398859
Trained batch 58 in epoch 1, gen_loss = 0.7819958157458547, disc_loss = 0.1251884867452969
Trained batch 59 in epoch 1, gen_loss = 0.7788958092530568, disc_loss = 0.1246682083234191
Trained batch 60 in epoch 1, gen_loss = 0.7771259243371057, disc_loss = 0.12533535924358447
Trained batch 61 in epoch 1, gen_loss = 0.7814894885786118, disc_loss = 0.12894691484830073
Trained batch 62 in epoch 1, gen_loss = 0.7791367173194885, disc_loss = 0.1295905468601083
Trained batch 63 in epoch 1, gen_loss = 0.774375740904361, disc_loss = 0.13229524908820167
Trained batch 64 in epoch 1, gen_loss = 0.7739029797223899, disc_loss = 0.13273444089751976
Trained batch 65 in epoch 1, gen_loss = 0.7735015808632879, disc_loss = 0.13327375850216908
Trained batch 66 in epoch 1, gen_loss = 0.7717328325136384, disc_loss = 0.13327922444067783
Trained batch 67 in epoch 1, gen_loss = 0.7726956636590117, disc_loss = 0.1323434368104619
Trained batch 68 in epoch 1, gen_loss = 0.7725759334322335, disc_loss = 0.1322541765436746
Trained batch 69 in epoch 1, gen_loss = 0.7687031486204692, disc_loss = 0.13382572377366678
Trained batch 70 in epoch 1, gen_loss = 0.7690200700726307, disc_loss = 0.13421700448847154
Trained batch 71 in epoch 1, gen_loss = 0.7682906898359457, disc_loss = 0.13407219930862388
Trained batch 72 in epoch 1, gen_loss = 0.7670136465601725, disc_loss = 0.13412051193722307
Trained batch 73 in epoch 1, gen_loss = 0.7655914429877255, disc_loss = 0.13455459581234971
Trained batch 74 in epoch 1, gen_loss = 0.7677857641379039, disc_loss = 0.133463862935702
Trained batch 75 in epoch 1, gen_loss = 0.7645272687077522, disc_loss = 0.13478344678878784
Trained batch 76 in epoch 1, gen_loss = 0.7646800833089011, disc_loss = 0.1343852494444166
Trained batch 77 in epoch 1, gen_loss = 0.7662107451603963, disc_loss = 0.13342771230217737
Trained batch 78 in epoch 1, gen_loss = 0.7657607375066492, disc_loss = 0.13284421740453453
Trained batch 79 in epoch 1, gen_loss = 0.764945612475276, disc_loss = 0.1325703884474933
Trained batch 80 in epoch 1, gen_loss = 0.7634844415717654, disc_loss = 0.13281322381010763
Trained batch 81 in epoch 1, gen_loss = 0.7647008303462005, disc_loss = 0.132489609009609
Trained batch 82 in epoch 1, gen_loss = 0.7669896027409887, disc_loss = 0.1326035886823413
Trained batch 83 in epoch 1, gen_loss = 0.7639796928990454, disc_loss = 0.13515712719942843
Trained batch 84 in epoch 1, gen_loss = 0.7646092895199271, disc_loss = 0.13605593925013262
Trained batch 85 in epoch 1, gen_loss = 0.7672920424577802, disc_loss = 0.13603891371641047
Trained batch 86 in epoch 1, gen_loss = 0.7655317163330385, disc_loss = 0.13630162701867093
Trained batch 87 in epoch 1, gen_loss = 0.7642064043744043, disc_loss = 0.1358779337765141
Trained batch 88 in epoch 1, gen_loss = 0.7662388518285216, disc_loss = 0.13523767469974046
Trained batch 89 in epoch 1, gen_loss = 0.7664007236560185, disc_loss = 0.13488293836514156
Trained batch 90 in epoch 1, gen_loss = 0.7652954449365427, disc_loss = 0.13468570581504277
Trained batch 91 in epoch 1, gen_loss = 0.764146303029164, disc_loss = 0.13461944088339806
Trained batch 92 in epoch 1, gen_loss = 0.7642972978853411, disc_loss = 0.13448070758773434
Trained batch 93 in epoch 1, gen_loss = 0.7637955435412995, disc_loss = 0.13425909529658073
Trained batch 94 in epoch 1, gen_loss = 0.7632477543855968, disc_loss = 0.13391184273519013
Trained batch 95 in epoch 1, gen_loss = 0.7645443823809425, disc_loss = 0.13355409059052667
Trained batch 96 in epoch 1, gen_loss = 0.7670509369717431, disc_loss = 0.1337181338944386
Trained batch 97 in epoch 1, gen_loss = 0.7657278888687795, disc_loss = 0.13408926615909655
Trained batch 98 in epoch 1, gen_loss = 0.7664329490878365, disc_loss = 0.13329658476692258
Trained batch 99 in epoch 1, gen_loss = 0.7667968872189522, disc_loss = 0.1326415590196848
Trained batch 100 in epoch 1, gen_loss = 0.7666920225809116, disc_loss = 0.1326635580989394
Trained batch 101 in epoch 1, gen_loss = 0.7688817466590919, disc_loss = 0.1317215872672843
Trained batch 102 in epoch 1, gen_loss = 0.7662799592735698, disc_loss = 0.13273353191110696
Trained batch 103 in epoch 1, gen_loss = 0.765633519165791, disc_loss = 0.13299146104747286
Trained batch 104 in epoch 1, gen_loss = 0.7654532367274874, disc_loss = 0.13348570717942146
Trained batch 105 in epoch 1, gen_loss = 0.7651981961614681, disc_loss = 0.13302783446632466
Trained batch 106 in epoch 1, gen_loss = 0.7635132957284696, disc_loss = 0.13288615536049148
Trained batch 107 in epoch 1, gen_loss = 0.7643465424577395, disc_loss = 0.1330993624266099
Trained batch 108 in epoch 1, gen_loss = 0.7649994927261947, disc_loss = 0.13303964595318934
Trained batch 109 in epoch 1, gen_loss = 0.765234842354601, disc_loss = 0.13216177641668103
Trained batch 110 in epoch 1, gen_loss = 0.7634096427543743, disc_loss = 0.1321750523203665
Trained batch 111 in epoch 1, gen_loss = 0.7629892461534057, disc_loss = 0.13213073831450725
Trained batch 112 in epoch 1, gen_loss = 0.7642664342327455, disc_loss = 0.13200344636508848
Trained batch 113 in epoch 1, gen_loss = 0.765198134800844, disc_loss = 0.1314122224259272
Trained batch 114 in epoch 1, gen_loss = 0.7641165010307146, disc_loss = 0.13125494099829507
Trained batch 115 in epoch 1, gen_loss = 0.7640322737138847, disc_loss = 0.13096478051538096
Trained batch 116 in epoch 1, gen_loss = 0.7668837596718062, disc_loss = 0.13046265014598513
Trained batch 117 in epoch 1, gen_loss = 0.7689142522670455, disc_loss = 0.12991206887793744
Trained batch 118 in epoch 1, gen_loss = 0.7686098911682097, disc_loss = 0.12948586726013353
Trained batch 119 in epoch 1, gen_loss = 0.7669168420135974, disc_loss = 0.1302097790253659
Trained batch 120 in epoch 1, gen_loss = 0.7672600054051265, disc_loss = 0.12978218252624363
Trained batch 121 in epoch 1, gen_loss = 0.7716090012280667, disc_loss = 0.13005957205886723
Trained batch 122 in epoch 1, gen_loss = 0.7708545533137593, disc_loss = 0.1298934773398124
Trained batch 123 in epoch 1, gen_loss = 0.7709683393759112, disc_loss = 0.12927785939386777
Trained batch 124 in epoch 1, gen_loss = 0.7700296032428742, disc_loss = 0.12894853535294531
Trained batch 125 in epoch 1, gen_loss = 0.7691305878143462, disc_loss = 0.1286003812260571
Trained batch 126 in epoch 1, gen_loss = 0.7711855579079605, disc_loss = 0.1288108600699526
Trained batch 127 in epoch 1, gen_loss = 0.7726438932586461, disc_loss = 0.12794584315270185
Trained batch 128 in epoch 1, gen_loss = 0.7705429660719495, disc_loss = 0.1291075251823248
Trained batch 129 in epoch 1, gen_loss = 0.7700764383261021, disc_loss = 0.1292170904003657
Trained batch 130 in epoch 1, gen_loss = 0.7726319602882589, disc_loss = 0.12887210700348134
Trained batch 131 in epoch 1, gen_loss = 0.773219686340202, disc_loss = 0.12838314276075724
Trained batch 132 in epoch 1, gen_loss = 0.7732417218219069, disc_loss = 0.12800525565792745
Trained batch 133 in epoch 1, gen_loss = 0.7734213291264292, disc_loss = 0.12769424720709002
Trained batch 134 in epoch 1, gen_loss = 0.7763983697802932, disc_loss = 0.12758145426158551
Trained batch 135 in epoch 1, gen_loss = 0.7783339363248909, disc_loss = 0.12696242798119783
Trained batch 136 in epoch 1, gen_loss = 0.7766836505301677, disc_loss = 0.12756046081763983
Trained batch 137 in epoch 1, gen_loss = 0.7759701089150663, disc_loss = 0.12747183404322984
Trained batch 138 in epoch 1, gen_loss = 0.7778439974184517, disc_loss = 0.12840420013065817
Trained batch 139 in epoch 1, gen_loss = 0.7765085639698165, disc_loss = 0.1294027307736022
Trained batch 140 in epoch 1, gen_loss = 0.7748053887634413, disc_loss = 0.12977002386717088
Trained batch 141 in epoch 1, gen_loss = 0.775183199367053, disc_loss = 0.12986878573264873
Trained batch 142 in epoch 1, gen_loss = 0.7748672063950892, disc_loss = 0.13063870625687646
Trained batch 143 in epoch 1, gen_loss = 0.7741128903710179, disc_loss = 0.130494876506014
Trained batch 144 in epoch 1, gen_loss = 0.7729105819915904, disc_loss = 0.1309599597392411
Trained batch 145 in epoch 1, gen_loss = 0.7726231623594075, disc_loss = 0.13094576483924095
Trained batch 146 in epoch 1, gen_loss = 0.7728973069564015, disc_loss = 0.13097458444282312
Trained batch 147 in epoch 1, gen_loss = 0.7723462873616734, disc_loss = 0.1313091934834783
Trained batch 148 in epoch 1, gen_loss = 0.7719432321570864, disc_loss = 0.13114430610365516
Trained batch 149 in epoch 1, gen_loss = 0.7724669172366461, disc_loss = 0.1314024089773496
Trained batch 150 in epoch 1, gen_loss = 0.7718781432173899, disc_loss = 0.13120707484665295
Trained batch 151 in epoch 1, gen_loss = 0.7715924454754904, disc_loss = 0.13102556069038415
Trained batch 152 in epoch 1, gen_loss = 0.7723586791091495, disc_loss = 0.131174098140274
Trained batch 153 in epoch 1, gen_loss = 0.7718192576975017, disc_loss = 0.1307532581222522
Trained batch 154 in epoch 1, gen_loss = 0.7708453507192673, disc_loss = 0.13085781441580865
Trained batch 155 in epoch 1, gen_loss = 0.771156625296825, disc_loss = 0.13101781331575835
Trained batch 156 in epoch 1, gen_loss = 0.7695725584865376, disc_loss = 0.1312945617991648
Trained batch 157 in epoch 1, gen_loss = 0.769629056506519, disc_loss = 0.1313093314065209
Trained batch 158 in epoch 1, gen_loss = 0.7690054866127998, disc_loss = 0.13109507191481082
Trained batch 159 in epoch 1, gen_loss = 0.772302252613008, disc_loss = 0.13147747805342078
Trained batch 160 in epoch 1, gen_loss = 0.7713527066737228, disc_loss = 0.1311282140682943
Trained batch 161 in epoch 1, gen_loss = 0.7705614436187862, disc_loss = 0.13103665692018873
Trained batch 162 in epoch 1, gen_loss = 0.7697611526111884, disc_loss = 0.13115591263295684
Trained batch 163 in epoch 1, gen_loss = 0.7703680888545222, disc_loss = 0.13189902897106437
Trained batch 164 in epoch 1, gen_loss = 0.7689143164591355, disc_loss = 0.13253404918042097
Trained batch 165 in epoch 1, gen_loss = 0.7679940876831491, disc_loss = 0.13268292996000094
Trained batch 166 in epoch 1, gen_loss = 0.7675551413419004, disc_loss = 0.13300602454803662
Trained batch 167 in epoch 1, gen_loss = 0.7669871394478139, disc_loss = 0.13300078934324638
Trained batch 168 in epoch 1, gen_loss = 0.7669447866769937, disc_loss = 0.13314166581313286
Trained batch 169 in epoch 1, gen_loss = 0.7659502543070738, disc_loss = 0.13288481594885096
Trained batch 170 in epoch 1, gen_loss = 0.7655535279310237, disc_loss = 0.13307338569596497
Trained batch 171 in epoch 1, gen_loss = 0.7662299582084944, disc_loss = 0.13354043428634488
Trained batch 172 in epoch 1, gen_loss = 0.7655978686892229, disc_loss = 0.1332664296806203
Trained batch 173 in epoch 1, gen_loss = 0.7642011719531027, disc_loss = 0.13340691125941004
Trained batch 174 in epoch 1, gen_loss = 0.7650015148094722, disc_loss = 0.13327736058405468
Trained batch 175 in epoch 1, gen_loss = 0.7655246201902628, disc_loss = 0.13296929230405527
Trained batch 176 in epoch 1, gen_loss = 0.7638286700693228, disc_loss = 0.13369334947928196
Trained batch 177 in epoch 1, gen_loss = 0.7639757399813513, disc_loss = 0.1335203783649407
Trained batch 178 in epoch 1, gen_loss = 0.7649393386348, disc_loss = 0.13403369498818946
Trained batch 179 in epoch 1, gen_loss = 0.764365841779444, disc_loss = 0.13391150654190118
Trained batch 180 in epoch 1, gen_loss = 0.7632440182056216, disc_loss = 0.1344463548195955
Trained batch 181 in epoch 1, gen_loss = 0.7638990055401247, disc_loss = 0.13456490255155407
Trained batch 182 in epoch 1, gen_loss = 0.7636294474041527, disc_loss = 0.13466775966960876
Trained batch 183 in epoch 1, gen_loss = 0.7632396355595278, disc_loss = 0.13501597483358954
Trained batch 184 in epoch 1, gen_loss = 0.7625661690492888, disc_loss = 0.13482730191301656
Trained batch 185 in epoch 1, gen_loss = 0.7628455125196005, disc_loss = 0.13520748380531547
Trained batch 186 in epoch 1, gen_loss = 0.7635150384456716, disc_loss = 0.13507327891607335
Trained batch 187 in epoch 1, gen_loss = 0.762572095590703, disc_loss = 0.13529687446165592
Trained batch 188 in epoch 1, gen_loss = 0.7622655467696922, disc_loss = 0.13507405885312923
Trained batch 189 in epoch 1, gen_loss = 0.7626857928539578, disc_loss = 0.1349999539946255
Trained batch 190 in epoch 1, gen_loss = 0.761422326895579, disc_loss = 0.1351599260306483
Trained batch 191 in epoch 1, gen_loss = 0.7611597538925707, disc_loss = 0.1356331727001816
Trained batch 192 in epoch 1, gen_loss = 0.7600449844036695, disc_loss = 0.136030738217843
Trained batch 193 in epoch 1, gen_loss = 0.7588735353393653, disc_loss = 0.13624544034606403
Trained batch 194 in epoch 1, gen_loss = 0.7586423572821495, disc_loss = 0.1360961078069149
Trained batch 195 in epoch 1, gen_loss = 0.7590999163839282, disc_loss = 0.1364516329248341
Trained batch 196 in epoch 1, gen_loss = 0.7588846497426783, disc_loss = 0.13636697234992448
Trained batch 197 in epoch 1, gen_loss = 0.7586589610636837, disc_loss = 0.13636964713834754
Trained batch 198 in epoch 1, gen_loss = 0.7594174444675446, disc_loss = 0.1366749139661765
Trained batch 199 in epoch 1, gen_loss = 0.7593764464557171, disc_loss = 0.13662132602185012
Trained batch 200 in epoch 1, gen_loss = 0.759056292807878, disc_loss = 0.1362040260463805
Trained batch 201 in epoch 1, gen_loss = 0.7581092967550354, disc_loss = 0.13621749061316546
Trained batch 202 in epoch 1, gen_loss = 0.7588461818072596, disc_loss = 0.13622168546973779
Trained batch 203 in epoch 1, gen_loss = 0.7580622243238431, disc_loss = 0.13606107549047938
Trained batch 204 in epoch 1, gen_loss = 0.7568959551613506, disc_loss = 0.1362650536909336
Trained batch 205 in epoch 1, gen_loss = 0.7565655093459249, disc_loss = 0.1362697066901957
Trained batch 206 in epoch 1, gen_loss = 0.7579484554592538, disc_loss = 0.1358556147970727
Trained batch 207 in epoch 1, gen_loss = 0.7571559621450993, disc_loss = 0.1356825191849986
Trained batch 208 in epoch 1, gen_loss = 0.7562657804295206, disc_loss = 0.13587938350710002
Trained batch 209 in epoch 1, gen_loss = 0.7554740115290597, disc_loss = 0.13631840108760765
Trained batch 210 in epoch 1, gen_loss = 0.7566301293000226, disc_loss = 0.13680664780086252
Trained batch 211 in epoch 1, gen_loss = 0.7560259538157931, disc_loss = 0.1366775264471488
Trained batch 212 in epoch 1, gen_loss = 0.7552877285390952, disc_loss = 0.13661561628252689
Trained batch 213 in epoch 1, gen_loss = 0.7546590969105748, disc_loss = 0.13669191978036244
Trained batch 214 in epoch 1, gen_loss = 0.7546669556651004, disc_loss = 0.13640174985278483
Trained batch 215 in epoch 1, gen_loss = 0.7548750651379427, disc_loss = 0.13631595517681153
Trained batch 216 in epoch 1, gen_loss = 0.7551154487418689, disc_loss = 0.13591144592737273
Trained batch 217 in epoch 1, gen_loss = 0.7570215486878649, disc_loss = 0.13543813516719078
Trained batch 218 in epoch 1, gen_loss = 0.757619754500585, disc_loss = 0.13489899858322046
Trained batch 219 in epoch 1, gen_loss = 0.7581017446788875, disc_loss = 0.13443590618500656
Trained batch 220 in epoch 1, gen_loss = 0.7584447044862341, disc_loss = 0.13392304876035424
Trained batch 221 in epoch 1, gen_loss = 0.759371728913204, disc_loss = 0.1334014195311177
Trained batch 222 in epoch 1, gen_loss = 0.7604314306659015, disc_loss = 0.1329177027743627
Trained batch 223 in epoch 1, gen_loss = 0.7612168867407101, disc_loss = 0.13248654099879786
Trained batch 224 in epoch 1, gen_loss = 0.761223850912518, disc_loss = 0.13209575263162454
Trained batch 225 in epoch 1, gen_loss = 0.7613385924987034, disc_loss = 0.13183932402789328
Trained batch 226 in epoch 1, gen_loss = 0.7631346799991204, disc_loss = 0.1315628372313299
Trained batch 227 in epoch 1, gen_loss = 0.7631462382381422, disc_loss = 0.13117128051000468
Trained batch 228 in epoch 1, gen_loss = 0.7629908079924022, disc_loss = 0.1309418954752288
Trained batch 229 in epoch 1, gen_loss = 0.7638422503419544, disc_loss = 0.13103139535726413
Trained batch 230 in epoch 1, gen_loss = 0.7642858563821553, disc_loss = 0.13068898988976366
Trained batch 231 in epoch 1, gen_loss = 0.7633423228459112, disc_loss = 0.13219134065579494
Trained batch 232 in epoch 1, gen_loss = 0.7637091226587991, disc_loss = 0.1322464648666172
Trained batch 233 in epoch 1, gen_loss = 0.7633337731290067, disc_loss = 0.13236929781129983
Trained batch 234 in epoch 1, gen_loss = 0.7632526645000944, disc_loss = 0.13248808960172725
Trained batch 235 in epoch 1, gen_loss = 0.76285677453724, disc_loss = 0.1325071117430294
Trained batch 236 in epoch 1, gen_loss = 0.7636301433235281, disc_loss = 0.13262522854854034
Trained batch 237 in epoch 1, gen_loss = 0.7640631052375841, disc_loss = 0.13230276587536605
Trained batch 238 in epoch 1, gen_loss = 0.7634812637103652, disc_loss = 0.13215318728222758
Trained batch 239 in epoch 1, gen_loss = 0.7624381838987271, disc_loss = 0.13219710104943563
Trained batch 240 in epoch 1, gen_loss = 0.7627155547072778, disc_loss = 0.13233689259722273
Trained batch 241 in epoch 1, gen_loss = 0.7629399470800211, disc_loss = 0.1320765003146342
Trained batch 242 in epoch 1, gen_loss = 0.763982437643004, disc_loss = 0.1316025465450905
Trained batch 243 in epoch 1, gen_loss = 0.7642962853195238, disc_loss = 0.1312376817718881
Trained batch 244 in epoch 1, gen_loss = 0.764577466249466, disc_loss = 0.1309015257474111
Trained batch 245 in epoch 1, gen_loss = 0.7651352854521294, disc_loss = 0.13080214986168756
Trained batch 246 in epoch 1, gen_loss = 0.765845808543657, disc_loss = 0.1304233386237853
Trained batch 247 in epoch 1, gen_loss = 0.7648993820673035, disc_loss = 0.1309890179414182
Trained batch 248 in epoch 1, gen_loss = 0.7655172997928528, disc_loss = 0.1306927091625321
Trained batch 249 in epoch 1, gen_loss = 0.7677828320264817, disc_loss = 0.1305882283449173
Trained batch 250 in epoch 1, gen_loss = 0.7673886063326878, disc_loss = 0.13041905925212152
Trained batch 251 in epoch 1, gen_loss = 0.7668279966428166, disc_loss = 0.13033974489995412
Trained batch 252 in epoch 1, gen_loss = 0.7676572972842356, disc_loss = 0.1307995023699146
Trained batch 253 in epoch 1, gen_loss = 0.7678512779511805, disc_loss = 0.13047404452337055
Trained batch 254 in epoch 1, gen_loss = 0.7674873411655426, disc_loss = 0.13035730105989118
Trained batch 255 in epoch 1, gen_loss = 0.7666559038916603, disc_loss = 0.13042363431304693
Trained batch 256 in epoch 1, gen_loss = 0.7679590498195085, disc_loss = 0.1306822435053406
Trained batch 257 in epoch 1, gen_loss = 0.7672197704398355, disc_loss = 0.13079481554585834
Trained batch 258 in epoch 1, gen_loss = 0.7668550593282265, disc_loss = 0.13090095499307491
Trained batch 259 in epoch 1, gen_loss = 0.7677596939297823, disc_loss = 0.13089993647657908
Trained batch 260 in epoch 1, gen_loss = 0.7671154147135344, disc_loss = 0.13076129384424495
Trained batch 261 in epoch 1, gen_loss = 0.7665534657603912, disc_loss = 0.131198380114013
Trained batch 262 in epoch 1, gen_loss = 0.7668041488290286, disc_loss = 0.1310725721739544
Trained batch 263 in epoch 1, gen_loss = 0.7686293625244589, disc_loss = 0.13112108186451774
Trained batch 264 in epoch 1, gen_loss = 0.7688130121186094, disc_loss = 0.13074779143592097
Trained batch 265 in epoch 1, gen_loss = 0.7678775078147874, disc_loss = 0.13124016928661586
Trained batch 266 in epoch 1, gen_loss = 0.7682945501715056, disc_loss = 0.13128312901778613
Trained batch 267 in epoch 1, gen_loss = 0.768589891270915, disc_loss = 0.1309383835977138
Trained batch 268 in epoch 1, gen_loss = 0.7686258307398474, disc_loss = 0.13052560832199112
Trained batch 269 in epoch 1, gen_loss = 0.7675996501136709, disc_loss = 0.13075746789022727
Trained batch 270 in epoch 1, gen_loss = 0.7677942742060911, disc_loss = 0.13050496528729302
Trained batch 271 in epoch 1, gen_loss = 0.7685133182608029, disc_loss = 0.13013608944054475
Trained batch 272 in epoch 1, gen_loss = 0.768066208987009, disc_loss = 0.12997122039342976
Trained batch 273 in epoch 1, gen_loss = 0.7683398652903355, disc_loss = 0.1296732250437902
Trained batch 274 in epoch 1, gen_loss = 0.7686613922769373, disc_loss = 0.1292828189649365
Trained batch 275 in epoch 1, gen_loss = 0.7685300875185193, disc_loss = 0.12920085425772096
Trained batch 276 in epoch 1, gen_loss = 0.768331584194507, disc_loss = 0.12905379165542255
Trained batch 277 in epoch 1, gen_loss = 0.7680136343772462, disc_loss = 0.12897116451008286
Trained batch 278 in epoch 1, gen_loss = 0.7673407298476038, disc_loss = 0.1289783621266965
Trained batch 279 in epoch 1, gen_loss = 0.7673229588993958, disc_loss = 0.12896643867716193
Trained batch 280 in epoch 1, gen_loss = 0.7665422517421832, disc_loss = 0.12888250586135955
Trained batch 281 in epoch 1, gen_loss = 0.7662103576651702, disc_loss = 0.12893427648178651
Trained batch 282 in epoch 1, gen_loss = 0.7664004335765704, disc_loss = 0.129163183758937
Trained batch 283 in epoch 1, gen_loss = 0.7661640531790088, disc_loss = 0.12915215010321895
Trained batch 284 in epoch 1, gen_loss = 0.7658401985963186, disc_loss = 0.12911073626917705
Trained batch 285 in epoch 1, gen_loss = 0.7667021450254466, disc_loss = 0.12909447238943378
Trained batch 286 in epoch 1, gen_loss = 0.7671529122138273, disc_loss = 0.12884446990251125
Trained batch 287 in epoch 1, gen_loss = 0.7664328816657265, disc_loss = 0.1290822206194409
Trained batch 288 in epoch 1, gen_loss = 0.7672258878455442, disc_loss = 0.12913570360999208
Trained batch 289 in epoch 1, gen_loss = 0.7669261512057535, disc_loss = 0.12903135422745654
Trained batch 290 in epoch 1, gen_loss = 0.766672288326873, disc_loss = 0.12873507328203454
Trained batch 291 in epoch 1, gen_loss = 0.7668108714565839, disc_loss = 0.12869196901837848
Trained batch 292 in epoch 1, gen_loss = 0.7667825141660997, disc_loss = 0.12860843314194842
Trained batch 293 in epoch 1, gen_loss = 0.7676360527066146, disc_loss = 0.12848639631403141
Trained batch 294 in epoch 1, gen_loss = 0.7665991615440886, disc_loss = 0.12860588180059093
Trained batch 295 in epoch 1, gen_loss = 0.7668477504237278, disc_loss = 0.1284148024671988
Trained batch 296 in epoch 1, gen_loss = 0.7676397857039866, disc_loss = 0.12868080347124172
Trained batch 297 in epoch 1, gen_loss = 0.7667526220715286, disc_loss = 0.12921542180514575
Trained batch 298 in epoch 1, gen_loss = 0.766683310768676, disc_loss = 0.1292772309163143
Trained batch 299 in epoch 1, gen_loss = 0.7668099592129389, disc_loss = 0.12925029510011277
Trained batch 300 in epoch 1, gen_loss = 0.7667800328660249, disc_loss = 0.12916346256964625
Trained batch 301 in epoch 1, gen_loss = 0.7664117844688971, disc_loss = 0.1290543314365559
Trained batch 302 in epoch 1, gen_loss = 0.7665449768403182, disc_loss = 0.12886613281597398
Trained batch 303 in epoch 1, gen_loss = 0.7657418586313725, disc_loss = 0.12899885825371663
Trained batch 304 in epoch 1, gen_loss = 0.765683328714527, disc_loss = 0.12887983653144758
Trained batch 305 in epoch 1, gen_loss = 0.7651225875795277, disc_loss = 0.1288988514638999
Trained batch 306 in epoch 1, gen_loss = 0.7656060199007537, disc_loss = 0.12922412189821855
Trained batch 307 in epoch 1, gen_loss = 0.7655933988945824, disc_loss = 0.12891420535743237
Trained batch 308 in epoch 1, gen_loss = 0.765126481604036, disc_loss = 0.1291306241382287
Trained batch 309 in epoch 1, gen_loss = 0.7645304178037952, disc_loss = 0.1292729671203321
Trained batch 310 in epoch 1, gen_loss = 0.7648907131320793, disc_loss = 0.12922208696316292
Trained batch 311 in epoch 1, gen_loss = 0.7650836530404214, disc_loss = 0.12897193162009501
Trained batch 312 in epoch 1, gen_loss = 0.7647680055600005, disc_loss = 0.12875588800008306
Trained batch 313 in epoch 1, gen_loss = 0.7641075287654902, disc_loss = 0.1287764895019258
Trained batch 314 in epoch 1, gen_loss = 0.7644403648754907, disc_loss = 0.12873540454440646
Trained batch 315 in epoch 1, gen_loss = 0.7658885243950011, disc_loss = 0.12848179504463944
Trained batch 316 in epoch 1, gen_loss = 0.7654406672772549, disc_loss = 0.1283604693055529
Trained batch 317 in epoch 1, gen_loss = 0.7651527949474143, disc_loss = 0.12816336094958228
Trained batch 318 in epoch 1, gen_loss = 0.7657619051425061, disc_loss = 0.12844966053028464
Trained batch 319 in epoch 1, gen_loss = 0.7654598813503981, disc_loss = 0.12853583008982242
Trained batch 320 in epoch 1, gen_loss = 0.7659905016236588, disc_loss = 0.12840965789426526
Trained batch 321 in epoch 1, gen_loss = 0.7659945317677089, disc_loss = 0.1282339067377659
Trained batch 322 in epoch 1, gen_loss = 0.7655669871498557, disc_loss = 0.1281981573385351
Trained batch 323 in epoch 1, gen_loss = 0.7659885807905669, disc_loss = 0.12828178381846275
Trained batch 324 in epoch 1, gen_loss = 0.766156690120697, disc_loss = 0.12798501731111453
Trained batch 325 in epoch 1, gen_loss = 0.7654138975348209, disc_loss = 0.12832582843678494
Trained batch 326 in epoch 1, gen_loss = 0.7661709132909046, disc_loss = 0.12829654947470087
Trained batch 327 in epoch 1, gen_loss = 0.766356341722535, disc_loss = 0.12803647233309542
Trained batch 328 in epoch 1, gen_loss = 0.7656590541807714, disc_loss = 0.1284034483383854
Trained batch 329 in epoch 1, gen_loss = 0.7657666780731894, disc_loss = 0.12828091969995786
Trained batch 330 in epoch 1, gen_loss = 0.7659706005156941, disc_loss = 0.1282624553472614
Trained batch 331 in epoch 1, gen_loss = 0.7664345817034504, disc_loss = 0.12804056384252854
Trained batch 332 in epoch 1, gen_loss = 0.7659283708165716, disc_loss = 0.12806306259186417
Trained batch 333 in epoch 1, gen_loss = 0.7656610154820059, disc_loss = 0.12797664671377865
Trained batch 334 in epoch 1, gen_loss = 0.7660618828303778, disc_loss = 0.12799300029873847
Trained batch 335 in epoch 1, gen_loss = 0.7659268084736097, disc_loss = 0.1281937821435609
Trained batch 336 in epoch 1, gen_loss = 0.7652306238338572, disc_loss = 0.12829853708162153
Trained batch 337 in epoch 1, gen_loss = 0.7650899932934687, disc_loss = 0.1282240160845617
Trained batch 338 in epoch 1, gen_loss = 0.7656044843977532, disc_loss = 0.1281518969234288
Trained batch 339 in epoch 1, gen_loss = 0.7650669658885283, disc_loss = 0.12829291116007988
Trained batch 340 in epoch 1, gen_loss = 0.7653549208669019, disc_loss = 0.12828857122846712
Trained batch 341 in epoch 1, gen_loss = 0.7649434792716601, disc_loss = 0.1283266748797301
Trained batch 342 in epoch 1, gen_loss = 0.7649709288649934, disc_loss = 0.12827901695325492
Trained batch 343 in epoch 1, gen_loss = 0.7656320097834565, disc_loss = 0.12819953781530954
Trained batch 344 in epoch 1, gen_loss = 0.7652674282806508, disc_loss = 0.12810228193799655
Trained batch 345 in epoch 1, gen_loss = 0.7648015875003241, disc_loss = 0.12816463129842556
Trained batch 346 in epoch 1, gen_loss = 0.7656320520711564, disc_loss = 0.1285056482452996
Trained batch 347 in epoch 1, gen_loss = 0.7654925228535444, disc_loss = 0.12838239945342828
Trained batch 348 in epoch 1, gen_loss = 0.7646086562670404, disc_loss = 0.12868244398417308
Trained batch 349 in epoch 1, gen_loss = 0.7644086464813777, disc_loss = 0.12859643896775586
Trained batch 350 in epoch 1, gen_loss = 0.7649093772950675, disc_loss = 0.12866788783092103
Trained batch 351 in epoch 1, gen_loss = 0.765959182754159, disc_loss = 0.1284982658901506
Trained batch 352 in epoch 1, gen_loss = 0.7657529443249148, disc_loss = 0.12830854668453462
Trained batch 353 in epoch 1, gen_loss = 0.764948459415786, disc_loss = 0.12857882677456417
Trained batch 354 in epoch 1, gen_loss = 0.7652688351315512, disc_loss = 0.12840331539931432
Trained batch 355 in epoch 1, gen_loss = 0.7660350155796898, disc_loss = 0.12828990615109045
Trained batch 356 in epoch 1, gen_loss = 0.7653678995387561, disc_loss = 0.12833849717380286
Trained batch 357 in epoch 1, gen_loss = 0.7646033813001057, disc_loss = 0.12834295321401604
Trained batch 358 in epoch 1, gen_loss = 0.7645442375399608, disc_loss = 0.12831301577285473
Trained batch 359 in epoch 1, gen_loss = 0.765102296984858, disc_loss = 0.12824087475116056
Trained batch 360 in epoch 1, gen_loss = 0.7646859206486276, disc_loss = 0.12828283417464292
Trained batch 361 in epoch 1, gen_loss = 0.7641010767682481, disc_loss = 0.12832145661486116
Trained batch 362 in epoch 1, gen_loss = 0.7640036759133509, disc_loss = 0.1282202695539996
Trained batch 363 in epoch 1, gen_loss = 0.7636765209691865, disc_loss = 0.1282265042722389
Trained batch 364 in epoch 1, gen_loss = 0.7633092593656827, disc_loss = 0.12830023109300495
Trained batch 365 in epoch 1, gen_loss = 0.7630787316730113, disc_loss = 0.12826549498964854
Trained batch 366 in epoch 1, gen_loss = 0.7635513830737132, disc_loss = 0.12811858796740422
Trained batch 367 in epoch 1, gen_loss = 0.7638906388665023, disc_loss = 0.12803107843248415
Trained batch 368 in epoch 1, gen_loss = 0.7634494959661954, disc_loss = 0.12796013141025694
Trained batch 369 in epoch 1, gen_loss = 0.7630093796027674, disc_loss = 0.12795080579817295
Trained batch 370 in epoch 1, gen_loss = 0.7640193362602327, disc_loss = 0.12811568874433998
Trained batch 371 in epoch 1, gen_loss = 0.7640696570918124, disc_loss = 0.12816269476447376
Trained batch 372 in epoch 1, gen_loss = 0.763741090773897, disc_loss = 0.12802138466178253
Trained batch 373 in epoch 1, gen_loss = 0.762947112640595, disc_loss = 0.12831563089182352
Trained batch 374 in epoch 1, gen_loss = 0.7634440522193908, disc_loss = 0.12836332214872043
Trained batch 375 in epoch 1, gen_loss = 0.7636183980614581, disc_loss = 0.1283617903914382
Trained batch 376 in epoch 1, gen_loss = 0.7634690081409181, disc_loss = 0.1282270876913077
Trained batch 377 in epoch 1, gen_loss = 0.7631202243938648, disc_loss = 0.12823150930778374
Trained batch 378 in epoch 1, gen_loss = 0.7636008067621719, disc_loss = 0.12843472576432305
Trained batch 379 in epoch 1, gen_loss = 0.7637430972174595, disc_loss = 0.12829245553400956
Trained batch 380 in epoch 1, gen_loss = 0.7633843426629314, disc_loss = 0.12832202718365848
Trained batch 381 in epoch 1, gen_loss = 0.7629692793204522, disc_loss = 0.1283332643182022
Trained batch 382 in epoch 1, gen_loss = 0.7630949924571084, disc_loss = 0.12853802391388708
Trained batch 383 in epoch 1, gen_loss = 0.7627673537159959, disc_loss = 0.12881185549971028
Trained batch 384 in epoch 1, gen_loss = 0.7631029686370453, disc_loss = 0.12872552179864474
Trained batch 385 in epoch 1, gen_loss = 0.7634018514440467, disc_loss = 0.12847036779544513
Trained batch 386 in epoch 1, gen_loss = 0.7635583224530675, disc_loss = 0.12821175626813594
Trained batch 387 in epoch 1, gen_loss = 0.7631855090868842, disc_loss = 0.12816832843476655
Trained batch 388 in epoch 1, gen_loss = 0.7630772192251406, disc_loss = 0.12804744721110192
Trained batch 389 in epoch 1, gen_loss = 0.7633995834069375, disc_loss = 0.12787705083879142
Trained batch 390 in epoch 1, gen_loss = 0.7640663457038762, disc_loss = 0.12759366531468108
Trained batch 391 in epoch 1, gen_loss = 0.7635197945091189, disc_loss = 0.12817080340785336
Trained batch 392 in epoch 1, gen_loss = 0.7643234148886974, disc_loss = 0.12810147888294918
Trained batch 393 in epoch 1, gen_loss = 0.7651294084067272, disc_loss = 0.12806234799022906
Trained batch 394 in epoch 1, gen_loss = 0.7648224252688733, disc_loss = 0.12818118332873416
Trained batch 395 in epoch 1, gen_loss = 0.7643680462632516, disc_loss = 0.12831470452136162
Trained batch 396 in epoch 1, gen_loss = 0.7645591474900618, disc_loss = 0.12895880890095263
Trained batch 397 in epoch 1, gen_loss = 0.7644242972285304, disc_loss = 0.12900171544047156
Trained batch 398 in epoch 1, gen_loss = 0.7641449561692718, disc_loss = 0.1289134003819529
Trained batch 399 in epoch 1, gen_loss = 0.7643862031400204, disc_loss = 0.12878004423342646
Trained batch 400 in epoch 1, gen_loss = 0.7647911177906312, disc_loss = 0.12880989209635002
Trained batch 401 in epoch 1, gen_loss = 0.7644261453875262, disc_loss = 0.1288277345121055
Trained batch 402 in epoch 1, gen_loss = 0.7642613045926722, disc_loss = 0.12882260729561076
Trained batch 403 in epoch 1, gen_loss = 0.7636560511471021, disc_loss = 0.12903115620818173
Trained batch 404 in epoch 1, gen_loss = 0.7635404433733152, disc_loss = 0.12900677708747946
Trained batch 405 in epoch 1, gen_loss = 0.764320364726588, disc_loss = 0.12906608061653935
Trained batch 406 in epoch 1, gen_loss = 0.7642361499753573, disc_loss = 0.12897965095076866
Trained batch 407 in epoch 1, gen_loss = 0.7639408136407534, disc_loss = 0.128811377584569
Trained batch 408 in epoch 1, gen_loss = 0.7638207006571054, disc_loss = 0.12894290028946032
Trained batch 409 in epoch 1, gen_loss = 0.7640108942985535, disc_loss = 0.1289200606233463
Trained batch 410 in epoch 1, gen_loss = 0.7635801430166202, disc_loss = 0.12900448393828967
Trained batch 411 in epoch 1, gen_loss = 0.7635079549932943, disc_loss = 0.12903287779829167
Trained batch 412 in epoch 1, gen_loss = 0.7633787468616957, disc_loss = 0.12914057351089564
Trained batch 413 in epoch 1, gen_loss = 0.7629250963241005, disc_loss = 0.12914096251813975
Trained batch 414 in epoch 1, gen_loss = 0.7632850681442812, disc_loss = 0.1291139052664659
Trained batch 415 in epoch 1, gen_loss = 0.7633184665957322, disc_loss = 0.1291366034778408
Trained batch 416 in epoch 1, gen_loss = 0.7631181665747572, disc_loss = 0.12898630915964535
Trained batch 417 in epoch 1, gen_loss = 0.7633244496498381, disc_loss = 0.12875297731546123
Trained batch 418 in epoch 1, gen_loss = 0.7630722185592378, disc_loss = 0.12873435445432163
Trained batch 419 in epoch 1, gen_loss = 0.7637918249482201, disc_loss = 0.12894382492772172
Trained batch 420 in epoch 1, gen_loss = 0.7638818788698337, disc_loss = 0.12877998962962994
Trained batch 421 in epoch 1, gen_loss = 0.763282399183201, disc_loss = 0.12897372086889936
Trained batch 422 in epoch 1, gen_loss = 0.7633199669226969, disc_loss = 0.1289482493631665
Trained batch 423 in epoch 1, gen_loss = 0.7638614845444571, disc_loss = 0.1291747842476053
Trained batch 424 in epoch 1, gen_loss = 0.763754046384026, disc_loss = 0.1290543492050732
Trained batch 425 in epoch 1, gen_loss = 0.7636578975708832, disc_loss = 0.12898439354320088
Trained batch 426 in epoch 1, gen_loss = 0.7632878031886992, disc_loss = 0.12893430510016737
Trained batch 427 in epoch 1, gen_loss = 0.7630357364906328, disc_loss = 0.12894974118011576
Trained batch 428 in epoch 1, gen_loss = 0.7632610262968601, disc_loss = 0.12887039698990352
Trained batch 429 in epoch 1, gen_loss = 0.7636855046416438, disc_loss = 0.1287219803347144
Trained batch 430 in epoch 1, gen_loss = 0.7642399652098282, disc_loss = 0.1285405350706417
Trained batch 431 in epoch 1, gen_loss = 0.7640884084006151, disc_loss = 0.12835057576497397
Trained batch 432 in epoch 1, gen_loss = 0.7637541521228763, disc_loss = 0.1283241938842637
Trained batch 433 in epoch 1, gen_loss = 0.7642822920726741, disc_loss = 0.12807432154390944
Trained batch 434 in epoch 1, gen_loss = 0.7645843389390529, disc_loss = 0.1279031167941532
Trained batch 435 in epoch 1, gen_loss = 0.7647551173737289, disc_loss = 0.1278902509788034
Trained batch 436 in epoch 1, gen_loss = 0.7646543372686723, disc_loss = 0.12792604764416235
Trained batch 437 in epoch 1, gen_loss = 0.7647871818716667, disc_loss = 0.1278564310951592
Trained batch 438 in epoch 1, gen_loss = 0.7662171065671569, disc_loss = 0.1279406749340016
Trained batch 439 in epoch 1, gen_loss = 0.7664674401283265, disc_loss = 0.1276874990625815
Trained batch 440 in epoch 1, gen_loss = 0.7663508196806962, disc_loss = 0.12756435198037802
Trained batch 441 in epoch 1, gen_loss = 0.7664788775314573, disc_loss = 0.1273965332404251
Trained batch 442 in epoch 1, gen_loss = 0.7672368772411993, disc_loss = 0.12733294037811912
Trained batch 443 in epoch 1, gen_loss = 0.7674503742574571, disc_loss = 0.12714960543556256
Trained batch 444 in epoch 1, gen_loss = 0.7675934196857924, disc_loss = 0.12694845727822754
Trained batch 445 in epoch 1, gen_loss = 0.7670982060411051, disc_loss = 0.12719961204837524
Trained batch 446 in epoch 1, gen_loss = 0.7672264214596759, disc_loss = 0.12709127835746045
Trained batch 447 in epoch 1, gen_loss = 0.7673044980370572, disc_loss = 0.12706048300190428
Trained batch 448 in epoch 1, gen_loss = 0.7678435434211867, disc_loss = 0.12682632024177995
Trained batch 449 in epoch 1, gen_loss = 0.7678490057256486, disc_loss = 0.12667954679164622
Trained batch 450 in epoch 1, gen_loss = 0.7678993915242789, disc_loss = 0.1264637585547639
Trained batch 451 in epoch 1, gen_loss = 0.768036235750249, disc_loss = 0.12629927117459938
Trained batch 452 in epoch 1, gen_loss = 0.7683342982075335, disc_loss = 0.1261072185087875
Trained batch 453 in epoch 1, gen_loss = 0.7682298113333497, disc_loss = 0.12604862792491256
Trained batch 454 in epoch 1, gen_loss = 0.7689503026532603, disc_loss = 0.12583244784765846
Trained batch 455 in epoch 1, gen_loss = 0.7685008813676081, disc_loss = 0.1260997435821449
Trained batch 456 in epoch 1, gen_loss = 0.768704530838021, disc_loss = 0.12618795736271
Trained batch 457 in epoch 1, gen_loss = 0.7689708308621785, disc_loss = 0.12619098592712238
Trained batch 458 in epoch 1, gen_loss = 0.7694159273488329, disc_loss = 0.126041659484729
Trained batch 459 in epoch 1, gen_loss = 0.7689035996146824, disc_loss = 0.12647580265917857
Trained batch 460 in epoch 1, gen_loss = 0.7689451510632116, disc_loss = 0.1264349012524536
Trained batch 461 in epoch 1, gen_loss = 0.7689108849861921, disc_loss = 0.1264993632696085
Trained batch 462 in epoch 1, gen_loss = 0.7689919854085853, disc_loss = 0.126664487653076
Trained batch 463 in epoch 1, gen_loss = 0.768421550120773, disc_loss = 0.1270141385873009
Trained batch 464 in epoch 1, gen_loss = 0.7679145688651711, disc_loss = 0.12706097740559807
Trained batch 465 in epoch 1, gen_loss = 0.7678873767924411, disc_loss = 0.12710918535282556
Trained batch 466 in epoch 1, gen_loss = 0.7677040485549534, disc_loss = 0.12704886768483886
Trained batch 467 in epoch 1, gen_loss = 0.7680703833317145, disc_loss = 0.12689886935867178
Trained batch 468 in epoch 1, gen_loss = 0.7675665252244295, disc_loss = 0.1269106345096313
Trained batch 469 in epoch 1, gen_loss = 0.7673827915749651, disc_loss = 0.12684135411251732
Trained batch 470 in epoch 1, gen_loss = 0.7667345633046136, disc_loss = 0.12699835353200728
Trained batch 471 in epoch 1, gen_loss = 0.7666670040432679, disc_loss = 0.12706645697718327
Trained batch 472 in epoch 1, gen_loss = 0.7665112567376384, disc_loss = 0.12709663092822276
Trained batch 473 in epoch 1, gen_loss = 0.7662337734855177, disc_loss = 0.12703140118878475
Trained batch 474 in epoch 1, gen_loss = 0.7658925049555929, disc_loss = 0.1270333856148155
Trained batch 475 in epoch 1, gen_loss = 0.7659763472796488, disc_loss = 0.12703899116873615
Trained batch 476 in epoch 1, gen_loss = 0.7660979776637359, disc_loss = 0.12702455127560994
Trained batch 477 in epoch 1, gen_loss = 0.7656114048414151, disc_loss = 0.127118645052749
Trained batch 478 in epoch 1, gen_loss = 0.7660468243731338, disc_loss = 0.12706125320357295
Trained batch 479 in epoch 1, gen_loss = 0.7665994079783559, disc_loss = 0.12687766270634407
Trained batch 480 in epoch 1, gen_loss = 0.7660837440505592, disc_loss = 0.12709909034292688
Trained batch 481 in epoch 1, gen_loss = 0.7659447212313221, disc_loss = 0.1270688642473327
Trained batch 482 in epoch 1, gen_loss = 0.7660362576722605, disc_loss = 0.1270891513567472
Trained batch 483 in epoch 1, gen_loss = 0.7662470799462855, disc_loss = 0.1269030886979327
Trained batch 484 in epoch 1, gen_loss = 0.7658903810781302, disc_loss = 0.1270379787675806
Trained batch 485 in epoch 1, gen_loss = 0.7668173750364241, disc_loss = 0.12711436422196803
Trained batch 486 in epoch 1, gen_loss = 0.7671238876098969, disc_loss = 0.12688726624301816
Trained batch 487 in epoch 1, gen_loss = 0.7665159485501344, disc_loss = 0.12734584354597037
Trained batch 488 in epoch 1, gen_loss = 0.7666323585378612, disc_loss = 0.12721060231663212
Trained batch 489 in epoch 1, gen_loss = 0.7669398164870788, disc_loss = 0.1274549962002404
Trained batch 490 in epoch 1, gen_loss = 0.7667932163794997, disc_loss = 0.127354789805995
Trained batch 491 in epoch 1, gen_loss = 0.766346291131605, disc_loss = 0.12743705411146328
Trained batch 492 in epoch 1, gen_loss = 0.7666039491642803, disc_loss = 0.12744311840248881
Trained batch 493 in epoch 1, gen_loss = 0.7660737239759461, disc_loss = 0.12765645407713377
Trained batch 494 in epoch 1, gen_loss = 0.7661019050111675, disc_loss = 0.1276436126292354
Trained batch 495 in epoch 1, gen_loss = 0.7667068761563108, disc_loss = 0.12777780786517165
Trained batch 496 in epoch 1, gen_loss = 0.7664385788757316, disc_loss = 0.12772555604307226
Trained batch 497 in epoch 1, gen_loss = 0.7658640351520485, disc_loss = 0.12773254367122688
Trained batch 498 in epoch 1, gen_loss = 0.7656507496246117, disc_loss = 0.12768371043379656
Trained batch 499 in epoch 1, gen_loss = 0.7658122846484184, disc_loss = 0.1277580054551363
Trained batch 500 in epoch 1, gen_loss = 0.7654505527305032, disc_loss = 0.12789882842949526
Trained batch 501 in epoch 1, gen_loss = 0.7651462504469541, disc_loss = 0.12797498793537873
Trained batch 502 in epoch 1, gen_loss = 0.7654927597486713, disc_loss = 0.12798897174018514
Trained batch 503 in epoch 1, gen_loss = 0.765642185591989, disc_loss = 0.12801575242349553
Trained batch 504 in epoch 1, gen_loss = 0.7657314271620005, disc_loss = 0.12787905617220566
Trained batch 505 in epoch 1, gen_loss = 0.7656363834858883, disc_loss = 0.1277463075082764
Trained batch 506 in epoch 1, gen_loss = 0.7656426413877476, disc_loss = 0.12766200800736746
Trained batch 507 in epoch 1, gen_loss = 0.7655571709115674, disc_loss = 0.1276777944578899
Trained batch 508 in epoch 1, gen_loss = 0.765250567778623, disc_loss = 0.12769631107570145
Trained batch 509 in epoch 1, gen_loss = 0.7653636730769101, disc_loss = 0.12781869409715427
Trained batch 510 in epoch 1, gen_loss = 0.7655907546820706, disc_loss = 0.12762402472634837
Trained batch 511 in epoch 1, gen_loss = 0.7652821505325846, disc_loss = 0.12760261682706187
Trained batch 512 in epoch 1, gen_loss = 0.7654323224087207, disc_loss = 0.12743772350643812
Trained batch 513 in epoch 1, gen_loss = 0.7656064645209665, disc_loss = 0.1273334289498714
Trained batch 514 in epoch 1, gen_loss = 0.765474878294954, disc_loss = 0.1272334176287489
Trained batch 515 in epoch 1, gen_loss = 0.7658270875266356, disc_loss = 0.12716055926397557
Trained batch 516 in epoch 1, gen_loss = 0.7656145684377829, disc_loss = 0.1271412325824829
Trained batch 517 in epoch 1, gen_loss = 0.7656603048782091, disc_loss = 0.12712319974129493
Trained batch 518 in epoch 1, gen_loss = 0.7660335325896166, disc_loss = 0.1270933962554486
Trained batch 519 in epoch 1, gen_loss = 0.766112405119034, disc_loss = 0.12695566003855605
Trained batch 520 in epoch 1, gen_loss = 0.7659900266812997, disc_loss = 0.12711598737712326
Trained batch 521 in epoch 1, gen_loss = 0.7662154580555657, disc_loss = 0.12711684069671164
Trained batch 522 in epoch 1, gen_loss = 0.766000608014331, disc_loss = 0.1270198098118515
Trained batch 523 in epoch 1, gen_loss = 0.76641898306499, disc_loss = 0.12692519613605646
Trained batch 524 in epoch 1, gen_loss = 0.7668974089054834, disc_loss = 0.12677799454047567
Trained batch 525 in epoch 1, gen_loss = 0.7667025153741184, disc_loss = 0.12675412463116328
Trained batch 526 in epoch 1, gen_loss = 0.7668466594572085, disc_loss = 0.12675569546488477
Trained batch 527 in epoch 1, gen_loss = 0.7671125121979099, disc_loss = 0.1265731374450931
Trained batch 528 in epoch 1, gen_loss = 0.7668300974684537, disc_loss = 0.12643803523709057
Trained batch 529 in epoch 1, gen_loss = 0.767752643070131, disc_loss = 0.12656722954421673
Trained batch 530 in epoch 1, gen_loss = 0.7671941172492931, disc_loss = 0.1268180597805034
Trained batch 531 in epoch 1, gen_loss = 0.7673540538302938, disc_loss = 0.1266453327765142
Trained batch 532 in epoch 1, gen_loss = 0.767462330005406, disc_loss = 0.12650731788147904
Trained batch 533 in epoch 1, gen_loss = 0.7673826893505532, disc_loss = 0.12645149121430707
Trained batch 534 in epoch 1, gen_loss = 0.7673240153031928, disc_loss = 0.12631980634738352
Trained batch 535 in epoch 1, gen_loss = 0.7674713905956319, disc_loss = 0.12627073818011514
Trained batch 536 in epoch 1, gen_loss = 0.7685023472406789, disc_loss = 0.12612223801388642
Trained batch 537 in epoch 1, gen_loss = 0.7689728663202555, disc_loss = 0.12590923398165343
Trained batch 538 in epoch 1, gen_loss = 0.768772611093875, disc_loss = 0.12575893855700357
Trained batch 539 in epoch 1, gen_loss = 0.7684111894832717, disc_loss = 0.12567675634873687
Trained batch 540 in epoch 1, gen_loss = 0.7686318962829611, disc_loss = 0.1255975083694165
Trained batch 541 in epoch 1, gen_loss = 0.7687297977534607, disc_loss = 0.1254935505116063
Trained batch 542 in epoch 1, gen_loss = 0.7680783174095013, disc_loss = 0.12593521067656535
Trained batch 543 in epoch 1, gen_loss = 0.768442000317223, disc_loss = 0.12590929794275915
Trained batch 544 in epoch 1, gen_loss = 0.7688495486154469, disc_loss = 0.12575686592096036
Trained batch 545 in epoch 1, gen_loss = 0.7684749699992575, disc_loss = 0.12594401095772073
Trained batch 546 in epoch 1, gen_loss = 0.7689402224376825, disc_loss = 0.1259130815817026
Trained batch 547 in epoch 1, gen_loss = 0.7691847837536875, disc_loss = 0.1257700593700211
Trained batch 548 in epoch 1, gen_loss = 0.7691525139443861, disc_loss = 0.1256501974134226
Trained batch 549 in epoch 1, gen_loss = 0.76891970038414, disc_loss = 0.12561428877101702
Trained batch 550 in epoch 1, gen_loss = 0.7692317338474433, disc_loss = 0.12549375418485725
Trained batch 551 in epoch 1, gen_loss = 0.7691928380425426, disc_loss = 0.12539091030392202
Trained batch 552 in epoch 1, gen_loss = 0.768775946192888, disc_loss = 0.12539609990825382
Trained batch 553 in epoch 1, gen_loss = 0.7689156381662141, disc_loss = 0.12527802874693908
Trained batch 554 in epoch 1, gen_loss = 0.7695674853281932, disc_loss = 0.12518456095309408
Trained batch 555 in epoch 1, gen_loss = 0.7693513732591122, disc_loss = 0.12520678561489038
Trained batch 556 in epoch 1, gen_loss = 0.7696617823528858, disc_loss = 0.12502853570027775
Trained batch 557 in epoch 1, gen_loss = 0.7694421356083244, disc_loss = 0.1251016519596553
Trained batch 558 in epoch 1, gen_loss = 0.769395178567105, disc_loss = 0.12522504355072014
Trained batch 559 in epoch 1, gen_loss = 0.769395145454577, disc_loss = 0.12528973544083002
Trained batch 560 in epoch 1, gen_loss = 0.7690951767877249, disc_loss = 0.12550509085218006
Trained batch 561 in epoch 1, gen_loss = 0.7694504392528874, disc_loss = 0.12546439033028176
Trained batch 562 in epoch 1, gen_loss = 0.7696407444735404, disc_loss = 0.12533072600237113
Trained batch 563 in epoch 1, gen_loss = 0.7696320603713922, disc_loss = 0.12519478039974544
Trained batch 564 in epoch 1, gen_loss = 0.7691819379814958, disc_loss = 0.12525974227593537
Trained batch 565 in epoch 1, gen_loss = 0.769194002812827, disc_loss = 0.12516489850403248
Trained batch 566 in epoch 1, gen_loss = 0.7692924385768817, disc_loss = 0.12522214245399366
Trained batch 567 in epoch 1, gen_loss = 0.7693324195037425, disc_loss = 0.12516415708462222
Trained batch 568 in epoch 1, gen_loss = 0.7692069205961244, disc_loss = 0.1250732898456822
Trained batch 569 in epoch 1, gen_loss = 0.7688209514868887, disc_loss = 0.1251327388805517
Trained batch 570 in epoch 1, gen_loss = 0.7689249296321969, disc_loss = 0.12517699577410146
Trained batch 571 in epoch 1, gen_loss = 0.7691593807894033, disc_loss = 0.12504179486874623
Trained batch 572 in epoch 1, gen_loss = 0.7692465999571648, disc_loss = 0.12494088916423329
Trained batch 573 in epoch 1, gen_loss = 0.7690168960792262, disc_loss = 0.12482350275167085
Trained batch 574 in epoch 1, gen_loss = 0.7686142927667369, disc_loss = 0.12486409402087979
Trained batch 575 in epoch 1, gen_loss = 0.768573552577032, disc_loss = 0.12481822922968099
Trained batch 576 in epoch 1, gen_loss = 0.7691124020664076, disc_loss = 0.12478986666239217
Trained batch 577 in epoch 1, gen_loss = 0.769076111613673, disc_loss = 0.12467996934332135
Trained batch 578 in epoch 1, gen_loss = 0.7688283213061989, disc_loss = 0.12470051940588445
Trained batch 579 in epoch 1, gen_loss = 0.7687518630562158, disc_loss = 0.12473267772524008
Trained batch 580 in epoch 1, gen_loss = 0.7684987324855824, disc_loss = 0.12472609526408826
Trained batch 581 in epoch 1, gen_loss = 0.7679711059503949, disc_loss = 0.12471145830241982
Trained batch 582 in epoch 1, gen_loss = 0.7681855714239346, disc_loss = 0.12472552683134124
Trained batch 583 in epoch 1, gen_loss = 0.768702155361845, disc_loss = 0.12459006034513961
Trained batch 584 in epoch 1, gen_loss = 0.7682887852191925, disc_loss = 0.12475730197615603
Trained batch 585 in epoch 1, gen_loss = 0.7682454490926078, disc_loss = 0.12468173704825265
Trained batch 586 in epoch 1, gen_loss = 0.768357219901158, disc_loss = 0.12493895785327766
Trained batch 587 in epoch 1, gen_loss = 0.7685066881735308, disc_loss = 0.12487114848391641
Trained batch 588 in epoch 1, gen_loss = 0.7685860924182399, disc_loss = 0.12469454469864458
Trained batch 589 in epoch 1, gen_loss = 0.7681671098632328, disc_loss = 0.1248677868301333
Trained batch 590 in epoch 1, gen_loss = 0.7684720456600189, disc_loss = 0.12481233574349163
Trained batch 591 in epoch 1, gen_loss = 0.7686325446073268, disc_loss = 0.12475808967546737
Trained batch 592 in epoch 1, gen_loss = 0.7686254102202732, disc_loss = 0.12463452701863612
Trained batch 593 in epoch 1, gen_loss = 0.7682668958549146, disc_loss = 0.1246893462452172
Trained batch 594 in epoch 1, gen_loss = 0.768515160053718, disc_loss = 0.12457162339960327
Trained batch 595 in epoch 1, gen_loss = 0.7689689365309357, disc_loss = 0.12442642539402082
Trained batch 596 in epoch 1, gen_loss = 0.7685867658312396, disc_loss = 0.12454877755412803
Trained batch 597 in epoch 1, gen_loss = 0.7687105181125494, disc_loss = 0.12480592721743029
Trained batch 598 in epoch 1, gen_loss = 0.7684975278894969, disc_loss = 0.1247930167171364
Trained batch 599 in epoch 1, gen_loss = 0.7683069931964079, disc_loss = 0.12492291139128307
Trained batch 600 in epoch 1, gen_loss = 0.768190014530934, disc_loss = 0.1251193547463308
Trained batch 601 in epoch 1, gen_loss = 0.7685216845963089, disc_loss = 0.12551587559220898
Trained batch 602 in epoch 1, gen_loss = 0.7684514837379677, disc_loss = 0.1258674695080835
Trained batch 603 in epoch 1, gen_loss = 0.7685845444435315, disc_loss = 0.12609271662285096
Trained batch 604 in epoch 1, gen_loss = 0.7683468199465886, disc_loss = 0.12609921852973374
Trained batch 605 in epoch 1, gen_loss = 0.768133896166342, disc_loss = 0.12611716515123353
Trained batch 606 in epoch 1, gen_loss = 0.7680373639113821, disc_loss = 0.12612594763826598
Trained batch 607 in epoch 1, gen_loss = 0.7680086510648069, disc_loss = 0.12611800519516692
Trained batch 608 in epoch 1, gen_loss = 0.7680907090407091, disc_loss = 0.12607679257019497
Trained batch 609 in epoch 1, gen_loss = 0.7678003082021339, disc_loss = 0.12625225407727916
Trained batch 610 in epoch 1, gen_loss = 0.767636051496, disc_loss = 0.12628817342758275
Trained batch 611 in epoch 1, gen_loss = 0.7671897087027045, disc_loss = 0.1263715764477216
Trained batch 612 in epoch 1, gen_loss = 0.7671967014597446, disc_loss = 0.12645188906514138
Trained batch 613 in epoch 1, gen_loss = 0.7670070622177, disc_loss = 0.12649010217988238
Trained batch 614 in epoch 1, gen_loss = 0.7668244985060964, disc_loss = 0.1265171538917272
Trained batch 615 in epoch 1, gen_loss = 0.7670090972603142, disc_loss = 0.12653637911168883
Trained batch 616 in epoch 1, gen_loss = 0.7668195098300421, disc_loss = 0.12662961406744958
Trained batch 617 in epoch 1, gen_loss = 0.766570199076026, disc_loss = 0.12670499186745834
Trained batch 618 in epoch 1, gen_loss = 0.7666517450851847, disc_loss = 0.12674583390246782
Trained batch 619 in epoch 1, gen_loss = 0.7664200417457089, disc_loss = 0.12679532683724837
Trained batch 620 in epoch 1, gen_loss = 0.7662552314871943, disc_loss = 0.12693028950136928
Trained batch 621 in epoch 1, gen_loss = 0.7657787236849212, disc_loss = 0.1270209074026375
Trained batch 622 in epoch 1, gen_loss = 0.7656359039665608, disc_loss = 0.12713955332305324
Trained batch 623 in epoch 1, gen_loss = 0.7655104786062088, disc_loss = 0.12717498673233563
Trained batch 624 in epoch 1, gen_loss = 0.7655649606227874, disc_loss = 0.12711121217310428
Trained batch 625 in epoch 1, gen_loss = 0.7657296192436553, disc_loss = 0.12698377046686488
Trained batch 626 in epoch 1, gen_loss = 0.7657393579753011, disc_loss = 0.1269072398478002
Trained batch 627 in epoch 1, gen_loss = 0.7654704543150914, disc_loss = 0.127018236611513
Trained batch 628 in epoch 1, gen_loss = 0.7653906765632296, disc_loss = 0.12701877244764462
Trained batch 629 in epoch 1, gen_loss = 0.7655368827165119, disc_loss = 0.1269079737040022
Trained batch 630 in epoch 1, gen_loss = 0.765550456740399, disc_loss = 0.12687733045907576
Trained batch 631 in epoch 1, gen_loss = 0.7655591122994695, disc_loss = 0.1267893726884423
Trained batch 632 in epoch 1, gen_loss = 0.7652295973346132, disc_loss = 0.12692059771015088
Trained batch 633 in epoch 1, gen_loss = 0.7649256749202025, disc_loss = 0.12698843576049296
Trained batch 634 in epoch 1, gen_loss = 0.7650019561681222, disc_loss = 0.1270551764032268
Trained batch 635 in epoch 1, gen_loss = 0.7647532187636543, disc_loss = 0.1271363348149513
Trained batch 636 in epoch 1, gen_loss = 0.7652664903662455, disc_loss = 0.12715064814048155
Trained batch 637 in epoch 1, gen_loss = 0.7656582063735465, disc_loss = 0.12705049194617424
Trained batch 638 in epoch 1, gen_loss = 0.7652075474437601, disc_loss = 0.12732191997433026
Trained batch 639 in epoch 1, gen_loss = 0.7649813570082188, disc_loss = 0.12732628751837183
Trained batch 640 in epoch 1, gen_loss = 0.7649105805874614, disc_loss = 0.12739766602129812
Trained batch 641 in epoch 1, gen_loss = 0.7648819678483351, disc_loss = 0.127351559132825
Trained batch 642 in epoch 1, gen_loss = 0.7647700748213713, disc_loss = 0.12732571246707886
Trained batch 643 in epoch 1, gen_loss = 0.7649304426234701, disc_loss = 0.1272312302448966
Trained batch 644 in epoch 1, gen_loss = 0.7647628835929456, disc_loss = 0.12721973847337933
Trained batch 645 in epoch 1, gen_loss = 0.7646250173956987, disc_loss = 0.12720305506347596
Trained batch 646 in epoch 1, gen_loss = 0.7646537098855103, disc_loss = 0.1271475039946471
Trained batch 647 in epoch 1, gen_loss = 0.7645659269190129, disc_loss = 0.12713499135268783
Trained batch 648 in epoch 1, gen_loss = 0.7646549514886595, disc_loss = 0.12713434780518795
Trained batch 649 in epoch 1, gen_loss = 0.7641749213292048, disc_loss = 0.12727472468350942
Trained batch 650 in epoch 1, gen_loss = 0.7644332124524036, disc_loss = 0.12735627317220294
Trained batch 651 in epoch 1, gen_loss = 0.7640826163664918, disc_loss = 0.12734889570749336
Trained batch 652 in epoch 1, gen_loss = 0.7638236318941686, disc_loss = 0.1273525015438178
Trained batch 653 in epoch 1, gen_loss = 0.7637049932180924, disc_loss = 0.12730922685816473
Trained batch 654 in epoch 1, gen_loss = 0.7635307380261313, disc_loss = 0.1272499909979924
Trained batch 655 in epoch 1, gen_loss = 0.7632389601047446, disc_loss = 0.1272416582427601
Trained batch 656 in epoch 1, gen_loss = 0.7629895029728453, disc_loss = 0.12730681793296447
Trained batch 657 in epoch 1, gen_loss = 0.7628783911557183, disc_loss = 0.12727336097780423
Trained batch 658 in epoch 1, gen_loss = 0.7628113539700081, disc_loss = 0.12726662100231972
Trained batch 659 in epoch 1, gen_loss = 0.7628785099043991, disc_loss = 0.12725929079690215
Trained batch 660 in epoch 1, gen_loss = 0.762973483139015, disc_loss = 0.1273115095055455
Trained batch 661 in epoch 1, gen_loss = 0.7631728867029496, disc_loss = 0.12736858602253062
Trained batch 662 in epoch 1, gen_loss = 0.7638403402014915, disc_loss = 0.12728338781041887
Trained batch 663 in epoch 1, gen_loss = 0.7638611635529852, disc_loss = 0.12717388928531254
Trained batch 664 in epoch 1, gen_loss = 0.7637942660123782, disc_loss = 0.12710477313432927
Trained batch 665 in epoch 1, gen_loss = 0.7643203719242199, disc_loss = 0.12703022900297567
Trained batch 666 in epoch 1, gen_loss = 0.7643532923672689, disc_loss = 0.12693963283910298
Trained batch 667 in epoch 1, gen_loss = 0.7641583247456009, disc_loss = 0.12701476802826375
Trained batch 668 in epoch 1, gen_loss = 0.7644154384888163, disc_loss = 0.12699599239156653
Trained batch 669 in epoch 1, gen_loss = 0.7645656314358782, disc_loss = 0.12690264095844173
Trained batch 670 in epoch 1, gen_loss = 0.7645707559478976, disc_loss = 0.12685749674529592
Trained batch 671 in epoch 1, gen_loss = 0.7643960138694161, disc_loss = 0.12693457292403937
Trained batch 672 in epoch 1, gen_loss = 0.764548762946391, disc_loss = 0.12683499346239518
Trained batch 673 in epoch 1, gen_loss = 0.7645492436093463, disc_loss = 0.12674632049179485
Trained batch 674 in epoch 1, gen_loss = 0.7645952589423568, disc_loss = 0.12663471749259367
Trained batch 675 in epoch 1, gen_loss = 0.7644200006709296, disc_loss = 0.12659823628605382
Trained batch 676 in epoch 1, gen_loss = 0.7648068367994695, disc_loss = 0.12657741772800551
Trained batch 677 in epoch 1, gen_loss = 0.7651278110204545, disc_loss = 0.12645463341336072
Trained batch 678 in epoch 1, gen_loss = 0.7648049918646666, disc_loss = 0.12662445938431374
Trained batch 679 in epoch 1, gen_loss = 0.7649576520218568, disc_loss = 0.12656931878505823
Trained batch 680 in epoch 1, gen_loss = 0.7654031581640593, disc_loss = 0.12645144585831838
Trained batch 681 in epoch 1, gen_loss = 0.7650357563474661, disc_loss = 0.1266261630027918
Trained batch 682 in epoch 1, gen_loss = 0.7652036600894844, disc_loss = 0.12661519590192535
Trained batch 683 in epoch 1, gen_loss = 0.7648794014028638, disc_loss = 0.12675520050344846
Trained batch 684 in epoch 1, gen_loss = 0.7649491351886387, disc_loss = 0.1267796182311582
Trained batch 685 in epoch 1, gen_loss = 0.7650627502547062, disc_loss = 0.12669133916551534
Trained batch 686 in epoch 1, gen_loss = 0.7649432329631789, disc_loss = 0.12658416135223063
Trained batch 687 in epoch 1, gen_loss = 0.7649598221272923, disc_loss = 0.12658266808978433
Trained batch 688 in epoch 1, gen_loss = 0.7653146242541741, disc_loss = 0.12648104925752118
Trained batch 689 in epoch 1, gen_loss = 0.7649878793868465, disc_loss = 0.12653199784943592
Trained batch 690 in epoch 1, gen_loss = 0.7649119798250378, disc_loss = 0.1264870459275851
Trained batch 691 in epoch 1, gen_loss = 0.7647681070028702, disc_loss = 0.12647618157143106
Trained batch 692 in epoch 1, gen_loss = 0.7649940942961072, disc_loss = 0.12644102945547514
Trained batch 693 in epoch 1, gen_loss = 0.7649001492031713, disc_loss = 0.12635579993760465
Trained batch 694 in epoch 1, gen_loss = 0.7650502552231438, disc_loss = 0.12624362550354262
Trained batch 695 in epoch 1, gen_loss = 0.76506458976488, disc_loss = 0.12626591727041223
Trained batch 696 in epoch 1, gen_loss = 0.7658777358371182, disc_loss = 0.12632744685296435
Trained batch 697 in epoch 1, gen_loss = 0.7654731859450354, disc_loss = 0.1264678918460336
Trained batch 698 in epoch 1, gen_loss = 0.7656338325726969, disc_loss = 0.1264009812609619
Trained batch 699 in epoch 1, gen_loss = 0.7656189118112836, disc_loss = 0.12633437340546932
Trained batch 700 in epoch 1, gen_loss = 0.7659058099806564, disc_loss = 0.12635231954171808
Trained batch 701 in epoch 1, gen_loss = 0.7659814678705655, disc_loss = 0.1262568281008265
Trained batch 702 in epoch 1, gen_loss = 0.7659716852867756, disc_loss = 0.12618667409512854
Trained batch 703 in epoch 1, gen_loss = 0.7659528108991005, disc_loss = 0.1261690147723791
Trained batch 704 in epoch 1, gen_loss = 0.7663024482152141, disc_loss = 0.126232202919134
Trained batch 705 in epoch 1, gen_loss = 0.7662105933464958, disc_loss = 0.12618764133981453
Trained batch 706 in epoch 1, gen_loss = 0.7658897398047603, disc_loss = 0.12625295502071754
Trained batch 707 in epoch 1, gen_loss = 0.7659878475686251, disc_loss = 0.1261481509207206
Trained batch 708 in epoch 1, gen_loss = 0.7659106452138871, disc_loss = 0.1261161041849297
Trained batch 709 in epoch 1, gen_loss = 0.76608650810282, disc_loss = 0.12604617283640193
Trained batch 710 in epoch 1, gen_loss = 0.7659998775031496, disc_loss = 0.12600335571259974
Trained batch 711 in epoch 1, gen_loss = 0.7657983691504832, disc_loss = 0.1260585295209096
Trained batch 712 in epoch 1, gen_loss = 0.7660865674179366, disc_loss = 0.12606627610348803
Trained batch 713 in epoch 1, gen_loss = 0.7661440047730251, disc_loss = 0.12597018489953266
Trained batch 714 in epoch 1, gen_loss = 0.7662954988179507, disc_loss = 0.12583103021802186
Trained batch 715 in epoch 1, gen_loss = 0.7660149937734924, disc_loss = 0.1258486267101207
Trained batch 716 in epoch 1, gen_loss = 0.7662059915780689, disc_loss = 0.12579391199726522
Trained batch 717 in epoch 1, gen_loss = 0.7667976090668968, disc_loss = 0.12569045803891002
Trained batch 718 in epoch 1, gen_loss = 0.7666755098129346, disc_loss = 0.1255888561530347
Trained batch 719 in epoch 1, gen_loss = 0.7666600421898895, disc_loss = 0.1254684754000563
Trained batch 720 in epoch 1, gen_loss = 0.7663930079146661, disc_loss = 0.12548582343418208
Trained batch 721 in epoch 1, gen_loss = 0.7665744666577706, disc_loss = 0.12544351406240645
Trained batch 722 in epoch 1, gen_loss = 0.7668317704774532, disc_loss = 0.12533151965593484
Trained batch 723 in epoch 1, gen_loss = 0.7668609648778294, disc_loss = 0.12523151319010895
Trained batch 724 in epoch 1, gen_loss = 0.7667252290659937, disc_loss = 0.12530767393780165
Trained batch 725 in epoch 1, gen_loss = 0.7669204045754162, disc_loss = 0.12531526140694202
Trained batch 726 in epoch 1, gen_loss = 0.7674755880396501, disc_loss = 0.1252253191030624
Trained batch 727 in epoch 1, gen_loss = 0.7676139288878703, disc_loss = 0.12509396374174445
Trained batch 728 in epoch 1, gen_loss = 0.7671794035307173, disc_loss = 0.12520074511945903
Trained batch 729 in epoch 1, gen_loss = 0.7670264831961018, disc_loss = 0.12513228255540948
Trained batch 730 in epoch 1, gen_loss = 0.767911576376731, disc_loss = 0.12542106776604003
Trained batch 731 in epoch 1, gen_loss = 0.7677477218739973, disc_loss = 0.12538680836018887
Trained batch 732 in epoch 1, gen_loss = 0.7674529980181998, disc_loss = 0.1256012752992679
Trained batch 733 in epoch 1, gen_loss = 0.7675395578714418, disc_loss = 0.12568718149029834
Trained batch 734 in epoch 1, gen_loss = 0.7674909478142148, disc_loss = 0.12570779869700371
Trained batch 735 in epoch 1, gen_loss = 0.7672795769960984, disc_loss = 0.12570886407806742
Trained batch 736 in epoch 1, gen_loss = 0.767101863346074, disc_loss = 0.12574495565970117
Trained batch 737 in epoch 1, gen_loss = 0.7671052353976542, disc_loss = 0.1259946297213112
Trained batch 738 in epoch 1, gen_loss = 0.7669340627764494, disc_loss = 0.12591462749458537
Trained batch 739 in epoch 1, gen_loss = 0.7666745200350478, disc_loss = 0.12597888267875926
Trained batch 740 in epoch 1, gen_loss = 0.7668989528367716, disc_loss = 0.1259694245999601
Trained batch 741 in epoch 1, gen_loss = 0.7670060964928804, disc_loss = 0.1260243390945371
Trained batch 742 in epoch 1, gen_loss = 0.7667748738747105, disc_loss = 0.12611828551628948
Trained batch 743 in epoch 1, gen_loss = 0.7667120981921431, disc_loss = 0.12605595960962757
Trained batch 744 in epoch 1, gen_loss = 0.7668104871807483, disc_loss = 0.12602638073965608
Trained batch 745 in epoch 1, gen_loss = 0.766827494705011, disc_loss = 0.12595502151071467
Trained batch 746 in epoch 1, gen_loss = 0.7665045981905068, disc_loss = 0.1259910908304504
Trained batch 747 in epoch 1, gen_loss = 0.7664825819074151, disc_loss = 0.12595789230871887
Trained batch 748 in epoch 1, gen_loss = 0.7666327576134329, disc_loss = 0.12594310524257943
Trained batch 749 in epoch 1, gen_loss = 0.7667131022612254, disc_loss = 0.12591920847445726
Trained batch 750 in epoch 1, gen_loss = 0.7665059906188721, disc_loss = 0.12587134673764877
Trained batch 751 in epoch 1, gen_loss = 0.7663666588511873, disc_loss = 0.12586387637953095
Trained batch 752 in epoch 1, gen_loss = 0.7661150367769746, disc_loss = 0.12582148190780704
Trained batch 753 in epoch 1, gen_loss = 0.7659893295176782, disc_loss = 0.12578429466246846
Trained batch 754 in epoch 1, gen_loss = 0.7658931569547842, disc_loss = 0.12575745126417537
Trained batch 755 in epoch 1, gen_loss = 0.766079500002205, disc_loss = 0.12564850124781804
Trained batch 756 in epoch 1, gen_loss = 0.7656501269797196, disc_loss = 0.12573894587944567
Trained batch 757 in epoch 1, gen_loss = 0.7659367892625778, disc_loss = 0.12569988294108955
Trained batch 758 in epoch 1, gen_loss = 0.7660476149542058, disc_loss = 0.1255774327402883
Trained batch 759 in epoch 1, gen_loss = 0.766233891993761, disc_loss = 0.1254851785856054
Trained batch 760 in epoch 1, gen_loss = 0.7667196161565267, disc_loss = 0.1253648985950729
Trained batch 761 in epoch 1, gen_loss = 0.7664959585181684, disc_loss = 0.12542345006937977
Trained batch 762 in epoch 1, gen_loss = 0.7673162926149556, disc_loss = 0.1255656087241315
Trained batch 763 in epoch 1, gen_loss = 0.7670373159475351, disc_loss = 0.1256631966363346
Trained batch 764 in epoch 1, gen_loss = 0.7668710712903465, disc_loss = 0.12577208319277156
Trained batch 765 in epoch 1, gen_loss = 0.7668226048856118, disc_loss = 0.1261581424064448
Trained batch 766 in epoch 1, gen_loss = 0.7667723992424186, disc_loss = 0.12629963830356258
Trained batch 767 in epoch 1, gen_loss = 0.7667300727916881, disc_loss = 0.12624483883215967
Trained batch 768 in epoch 1, gen_loss = 0.7666576291169239, disc_loss = 0.12627808534345253
Trained batch 769 in epoch 1, gen_loss = 0.7665626830481863, disc_loss = 0.126346318053638
Trained batch 770 in epoch 1, gen_loss = 0.7666225502540475, disc_loss = 0.12633662608762583
Trained batch 771 in epoch 1, gen_loss = 0.766367723866139, disc_loss = 0.1264454429086124
Trained batch 772 in epoch 1, gen_loss = 0.7665104993641916, disc_loss = 0.12650241432675338
Trained batch 773 in epoch 1, gen_loss = 0.7662994608629582, disc_loss = 0.12648673812577196
Trained batch 774 in epoch 1, gen_loss = 0.7662318045477713, disc_loss = 0.12650503937996202
Trained batch 775 in epoch 1, gen_loss = 0.7663563840552089, disc_loss = 0.126726692050369
Trained batch 776 in epoch 1, gen_loss = 0.7661177710446612, disc_loss = 0.12675980298013992
Trained batch 777 in epoch 1, gen_loss = 0.7659761182829776, disc_loss = 0.12675137161624386
Trained batch 778 in epoch 1, gen_loss = 0.7659731453358745, disc_loss = 0.12681001104146664
Trained batch 779 in epoch 1, gen_loss = 0.7658286933333446, disc_loss = 0.12685697364071624
Trained batch 780 in epoch 1, gen_loss = 0.7659630369056355, disc_loss = 0.12682321029220364
Trained batch 781 in epoch 1, gen_loss = 0.766096848013151, disc_loss = 0.12677168064629254
Trained batch 782 in epoch 1, gen_loss = 0.7657813335820024, disc_loss = 0.12680734050523199
Trained batch 783 in epoch 1, gen_loss = 0.7656394348536827, disc_loss = 0.12676307828669264
Trained batch 784 in epoch 1, gen_loss = 0.7659625150975148, disc_loss = 0.12671067065256797
Trained batch 785 in epoch 1, gen_loss = 0.7660359897610493, disc_loss = 0.12669286442536662
Trained batch 786 in epoch 1, gen_loss = 0.7660119333215711, disc_loss = 0.12660755630549436
Trained batch 787 in epoch 1, gen_loss = 0.7658655903287951, disc_loss = 0.12661272490416006
Trained batch 788 in epoch 1, gen_loss = 0.7661397412929245, disc_loss = 0.1266997438679592
Trained batch 789 in epoch 1, gen_loss = 0.7659674995684925, disc_loss = 0.126616156589287
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.6067006587982178, disc_loss = 0.20384424924850464
Trained batch 1 in epoch 2, gen_loss = 0.6565647125244141, disc_loss = 0.15653254464268684
Trained batch 2 in epoch 2, gen_loss = 0.7279485861460367, disc_loss = 0.1344438393910726
Trained batch 3 in epoch 2, gen_loss = 0.7894109785556793, disc_loss = 0.11658700369298458
Trained batch 4 in epoch 2, gen_loss = 0.7313405394554138, disc_loss = 0.11742201298475266
Trained batch 5 in epoch 2, gen_loss = 0.6865715483824412, disc_loss = 0.1345194714764754
Trained batch 6 in epoch 2, gen_loss = 0.7467731663158962, disc_loss = 0.1508666436587061
Trained batch 7 in epoch 2, gen_loss = 0.7595093697309494, disc_loss = 0.1459080334752798
Trained batch 8 in epoch 2, gen_loss = 0.7297062476476034, disc_loss = 0.16005212896400028
Trained batch 9 in epoch 2, gen_loss = 0.7480618119239807, disc_loss = 0.15069996044039727
Trained batch 10 in epoch 2, gen_loss = 0.7433779564770785, disc_loss = 0.14537237245928158
Trained batch 11 in epoch 2, gen_loss = 0.7525462210178375, disc_loss = 0.1511595156043768
Trained batch 12 in epoch 2, gen_loss = 0.7352174520492554, disc_loss = 0.153147942171647
Trained batch 13 in epoch 2, gen_loss = 0.7265404079641614, disc_loss = 0.15308627752321108
Trained batch 14 in epoch 2, gen_loss = 0.7220730185508728, disc_loss = 0.1496137077609698
Trained batch 15 in epoch 2, gen_loss = 0.7304145395755768, disc_loss = 0.1497383895330131
Trained batch 16 in epoch 2, gen_loss = 0.7286378846449011, disc_loss = 0.14956054485896053
Trained batch 17 in epoch 2, gen_loss = 0.7162956396738688, disc_loss = 0.1502100448641512
Trained batch 18 in epoch 2, gen_loss = 0.7140732784020273, disc_loss = 0.15020073283659785
Trained batch 19 in epoch 2, gen_loss = 0.7087253123521805, disc_loss = 0.14944531060755253
Trained batch 20 in epoch 2, gen_loss = 0.7066045318331037, disc_loss = 0.14700752532198316
Trained batch 21 in epoch 2, gen_loss = 0.7116517668420618, disc_loss = 0.1438224898143248
Trained batch 22 in epoch 2, gen_loss = 0.7205860226050668, disc_loss = 0.14046012383440268
Trained batch 23 in epoch 2, gen_loss = 0.7306259746352831, disc_loss = 0.13548704578230777
Trained batch 24 in epoch 2, gen_loss = 0.7308931708335876, disc_loss = 0.1327346608042717
Trained batch 25 in epoch 2, gen_loss = 0.7315727128432348, disc_loss = 0.12980682488817435
Trained batch 26 in epoch 2, gen_loss = 0.7330596336611995, disc_loss = 0.1288780567270738
Trained batch 27 in epoch 2, gen_loss = 0.7356596461364201, disc_loss = 0.127796023817999
Trained batch 28 in epoch 2, gen_loss = 0.7342157672191488, disc_loss = 0.12723869367920118
Trained batch 29 in epoch 2, gen_loss = 0.7376275797684987, disc_loss = 0.12431850309173266
Trained batch 30 in epoch 2, gen_loss = 0.746680119345265, disc_loss = 0.12282637314450356
Trained batch 31 in epoch 2, gen_loss = 0.7707915212959051, disc_loss = 0.12310400954447687
Trained batch 32 in epoch 2, gen_loss = 0.7802897890408834, disc_loss = 0.12031831185926091
Trained batch 33 in epoch 2, gen_loss = 0.782034183249754, disc_loss = 0.11841921135783195
Trained batch 34 in epoch 2, gen_loss = 0.7824858069419861, disc_loss = 0.1163544380239078
Trained batch 35 in epoch 2, gen_loss = 0.7836086534791522, disc_loss = 0.11362063776080807
Trained batch 36 in epoch 2, gen_loss = 0.782398834421828, disc_loss = 0.11186538208779451
Trained batch 37 in epoch 2, gen_loss = 0.7861219268096121, disc_loss = 0.10981109860892359
Trained batch 38 in epoch 2, gen_loss = 0.7923529789997981, disc_loss = 0.10795018387337525
Trained batch 39 in epoch 2, gen_loss = 0.7915225088596344, disc_loss = 0.1065035140607506
Trained batch 40 in epoch 2, gen_loss = 0.791514062299961, disc_loss = 0.10597592069790131
Trained batch 41 in epoch 2, gen_loss = 0.7924671598843166, disc_loss = 0.10636408294418029
Trained batch 42 in epoch 2, gen_loss = 0.7900700680045194, disc_loss = 0.1063724254193001
Trained batch 43 in epoch 2, gen_loss = 0.7965562695806677, disc_loss = 0.10810134530236776
Trained batch 44 in epoch 2, gen_loss = 0.8004251427120632, disc_loss = 0.10606955972810586
Trained batch 45 in epoch 2, gen_loss = 0.7979260125885839, disc_loss = 0.10800341634160798
Trained batch 46 in epoch 2, gen_loss = 0.7934487779089745, disc_loss = 0.1090243536820437
Trained batch 47 in epoch 2, gen_loss = 0.7943902065356573, disc_loss = 0.11054611442765842
Trained batch 48 in epoch 2, gen_loss = 0.7950274628035876, disc_loss = 0.10964416761939623
Trained batch 49 in epoch 2, gen_loss = 0.7924839317798614, disc_loss = 0.10869593475013971
Trained batch 50 in epoch 2, gen_loss = 0.7881360579939449, disc_loss = 0.10867831932709497
Trained batch 51 in epoch 2, gen_loss = 0.7891975732950064, disc_loss = 0.11001298035709904
Trained batch 52 in epoch 2, gen_loss = 0.7926671853605306, disc_loss = 0.10955856645585231
Trained batch 53 in epoch 2, gen_loss = 0.7890007197856903, disc_loss = 0.11043057663159238
Trained batch 54 in epoch 2, gen_loss = 0.7842269810763273, disc_loss = 0.11148149550638416
Trained batch 55 in epoch 2, gen_loss = 0.7889362573623657, disc_loss = 0.11246875450680298
Trained batch 56 in epoch 2, gen_loss = 0.7920192898365489, disc_loss = 0.11266780059719295
Trained batch 57 in epoch 2, gen_loss = 0.787384477154962, disc_loss = 0.11354838982866756
Trained batch 58 in epoch 2, gen_loss = 0.7847883438659926, disc_loss = 0.1143365169291274
Trained batch 59 in epoch 2, gen_loss = 0.7828499674797058, disc_loss = 0.11383561557158828
Trained batch 60 in epoch 2, gen_loss = 0.7855819571213644, disc_loss = 0.11389763204411404
Trained batch 61 in epoch 2, gen_loss = 0.782834138601057, disc_loss = 0.11344016790990868
Trained batch 62 in epoch 2, gen_loss = 0.7812384849502927, disc_loss = 0.11290003598800727
Trained batch 63 in epoch 2, gen_loss = 0.7812687577679753, disc_loss = 0.11279314805869944
Trained batch 64 in epoch 2, gen_loss = 0.7805146758372967, disc_loss = 0.11288176273497251
Trained batch 65 in epoch 2, gen_loss = 0.7789118253823483, disc_loss = 0.11232342133580735
Trained batch 66 in epoch 2, gen_loss = 0.7771559526671225, disc_loss = 0.11150787006229607
Trained batch 67 in epoch 2, gen_loss = 0.7789627041886834, disc_loss = 0.11073982553994831
Trained batch 68 in epoch 2, gen_loss = 0.7775722767995752, disc_loss = 0.11025103119512399
Trained batch 69 in epoch 2, gen_loss = 0.7756129137107304, disc_loss = 0.1099910970511181
Trained batch 70 in epoch 2, gen_loss = 0.7747716106159587, disc_loss = 0.10940827243030071
Trained batch 71 in epoch 2, gen_loss = 0.7786400044957796, disc_loss = 0.10970591777004302
Trained batch 72 in epoch 2, gen_loss = 0.7772687926684341, disc_loss = 0.1092996472008016
Trained batch 73 in epoch 2, gen_loss = 0.7776472439637055, disc_loss = 0.10830425337661763
Trained batch 74 in epoch 2, gen_loss = 0.7762170608838399, disc_loss = 0.10868048993249735
Trained batch 75 in epoch 2, gen_loss = 0.7764922780425925, disc_loss = 0.10878531720587298
Trained batch 76 in epoch 2, gen_loss = 0.776319745299104, disc_loss = 0.10829861420992908
Trained batch 77 in epoch 2, gen_loss = 0.7752282084562839, disc_loss = 0.108410596059492
Trained batch 78 in epoch 2, gen_loss = 0.7819612825973125, disc_loss = 0.1099485841497213
Trained batch 79 in epoch 2, gen_loss = 0.7835058711469174, disc_loss = 0.10901147716213018
Trained batch 80 in epoch 2, gen_loss = 0.7808264324694504, disc_loss = 0.11006142964793576
Trained batch 81 in epoch 2, gen_loss = 0.784971156498281, disc_loss = 0.11176993909132917
Trained batch 82 in epoch 2, gen_loss = 0.7827650416328247, disc_loss = 0.11208683622619474
Trained batch 83 in epoch 2, gen_loss = 0.7833551523231325, disc_loss = 0.11182770534374174
Trained batch 84 in epoch 2, gen_loss = 0.7835938551846673, disc_loss = 0.1112963028909529
Trained batch 85 in epoch 2, gen_loss = 0.7827919735464939, disc_loss = 0.1111311364355822
Trained batch 86 in epoch 2, gen_loss = 0.7835588955331123, disc_loss = 0.11087752983573525
Trained batch 87 in epoch 2, gen_loss = 0.7821728973226114, disc_loss = 0.1111372673926367
Trained batch 88 in epoch 2, gen_loss = 0.7838539534740234, disc_loss = 0.11101909394093444
Trained batch 89 in epoch 2, gen_loss = 0.7829480608304341, disc_loss = 0.11051162839349774
Trained batch 90 in epoch 2, gen_loss = 0.7821158000401088, disc_loss = 0.10986415781899468
Trained batch 91 in epoch 2, gen_loss = 0.7818018638569376, disc_loss = 0.10917903764335357
Trained batch 92 in epoch 2, gen_loss = 0.7827995784821049, disc_loss = 0.10851693083281799
Trained batch 93 in epoch 2, gen_loss = 0.7837154510173392, disc_loss = 0.10822978657373089
Trained batch 94 in epoch 2, gen_loss = 0.782586165478355, disc_loss = 0.1088713861805828
Trained batch 95 in epoch 2, gen_loss = 0.7828407902270555, disc_loss = 0.1080797408358194
Trained batch 96 in epoch 2, gen_loss = 0.7850363869027993, disc_loss = 0.10753442663891413
Trained batch 97 in epoch 2, gen_loss = 0.7865119667685762, disc_loss = 0.10674157120971656
Trained batch 98 in epoch 2, gen_loss = 0.7862955265574985, disc_loss = 0.10630700359064521
Trained batch 99 in epoch 2, gen_loss = 0.7855062574148178, disc_loss = 0.10593869036063552
Trained batch 100 in epoch 2, gen_loss = 0.7868841579644987, disc_loss = 0.10553378632089289
Trained batch 101 in epoch 2, gen_loss = 0.7936516193782582, disc_loss = 0.10606551343830777
Trained batch 102 in epoch 2, gen_loss = 0.790994193947431, disc_loss = 0.10717915647744554
Trained batch 103 in epoch 2, gen_loss = 0.7896271273493767, disc_loss = 0.10679534262117858
Trained batch 104 in epoch 2, gen_loss = 0.7920256949606396, disc_loss = 0.10705683328920887
Trained batch 105 in epoch 2, gen_loss = 0.7919638426798694, disc_loss = 0.10697590993752457
Trained batch 106 in epoch 2, gen_loss = 0.7903331395621612, disc_loss = 0.1074311667618072
Trained batch 107 in epoch 2, gen_loss = 0.7888528699124301, disc_loss = 0.10783307100818665
Trained batch 108 in epoch 2, gen_loss = 0.788536951082562, disc_loss = 0.10769907041632254
Trained batch 109 in epoch 2, gen_loss = 0.78829629258676, disc_loss = 0.10762471229853955
Trained batch 110 in epoch 2, gen_loss = 0.7861991401191231, disc_loss = 0.1091520979429956
Trained batch 111 in epoch 2, gen_loss = 0.7853448199374335, disc_loss = 0.10888376604166947
Trained batch 112 in epoch 2, gen_loss = 0.7882114374532109, disc_loss = 0.10955375101648074
Trained batch 113 in epoch 2, gen_loss = 0.7864710604935362, disc_loss = 0.10952178805478309
Trained batch 114 in epoch 2, gen_loss = 0.7852291672126107, disc_loss = 0.11001171545813913
Trained batch 115 in epoch 2, gen_loss = 0.786021216676153, disc_loss = 0.1093244100920856
Trained batch 116 in epoch 2, gen_loss = 0.7858413580136422, disc_loss = 0.10944310650547855
Trained batch 117 in epoch 2, gen_loss = 0.7866275982331421, disc_loss = 0.10883270979117034
Trained batch 118 in epoch 2, gen_loss = 0.7869997099668038, disc_loss = 0.10861612748385978
Trained batch 119 in epoch 2, gen_loss = 0.7852659285068512, disc_loss = 0.10853903136836986
Trained batch 120 in epoch 2, gen_loss = 0.7850968404249712, disc_loss = 0.1086784776546492
Trained batch 121 in epoch 2, gen_loss = 0.7858156444596462, disc_loss = 0.1084843198387105
Trained batch 122 in epoch 2, gen_loss = 0.7856002018703678, disc_loss = 0.10800523115549146
Trained batch 123 in epoch 2, gen_loss = 0.784865713888599, disc_loss = 0.1078268590443317
Trained batch 124 in epoch 2, gen_loss = 0.7862281475067139, disc_loss = 0.1072041595429182
Trained batch 125 in epoch 2, gen_loss = 0.7892676960854303, disc_loss = 0.1065237908993685
Trained batch 126 in epoch 2, gen_loss = 0.7877039472887836, disc_loss = 0.10631443543990296
Trained batch 127 in epoch 2, gen_loss = 0.7918684124015272, disc_loss = 0.10609762150852475
Trained batch 128 in epoch 2, gen_loss = 0.793457382871199, disc_loss = 0.10537719344648049
Trained batch 129 in epoch 2, gen_loss = 0.7938635738996359, disc_loss = 0.10487653262769947
Trained batch 130 in epoch 2, gen_loss = 0.79420284142021, disc_loss = 0.10470365880071435
Trained batch 131 in epoch 2, gen_loss = 0.7935740220727343, disc_loss = 0.10430357412604446
Trained batch 132 in epoch 2, gen_loss = 0.7940294222724169, disc_loss = 0.10378945231633752
Trained batch 133 in epoch 2, gen_loss = 0.7961587300941125, disc_loss = 0.10324855459464798
Trained batch 134 in epoch 2, gen_loss = 0.795839046548914, disc_loss = 0.1027764403640672
Trained batch 135 in epoch 2, gen_loss = 0.7953834393445183, disc_loss = 0.10240771275643698
Trained batch 136 in epoch 2, gen_loss = 0.7954687336935614, disc_loss = 0.10200647535958211
Trained batch 137 in epoch 2, gen_loss = 0.7985482073348501, disc_loss = 0.10154553755874866
Trained batch 138 in epoch 2, gen_loss = 0.7976199242708494, disc_loss = 0.1013634800843948
Trained batch 139 in epoch 2, gen_loss = 0.7970833033323288, disc_loss = 0.10102003998389202
Trained batch 140 in epoch 2, gen_loss = 0.8000306258810327, disc_loss = 0.10072205008952119
Trained batch 141 in epoch 2, gen_loss = 0.8009521843681873, disc_loss = 0.10019703722939315
Trained batch 142 in epoch 2, gen_loss = 0.7989887282564924, disc_loss = 0.10082582461849585
Trained batch 143 in epoch 2, gen_loss = 0.8013665502270063, disc_loss = 0.10078145873396555
Trained batch 144 in epoch 2, gen_loss = 0.8017945536251726, disc_loss = 0.10032053581471073
Trained batch 145 in epoch 2, gen_loss = 0.8020992156577437, disc_loss = 0.09980545614603652
Trained batch 146 in epoch 2, gen_loss = 0.8023556000521394, disc_loss = 0.09925100552615057
Trained batch 147 in epoch 2, gen_loss = 0.8018827067839133, disc_loss = 0.09910459444556083
Trained batch 148 in epoch 2, gen_loss = 0.8009021230191993, disc_loss = 0.09934192816508096
Trained batch 149 in epoch 2, gen_loss = 0.8007622798283894, disc_loss = 0.09900227477774023
Trained batch 150 in epoch 2, gen_loss = 0.8032339550801461, disc_loss = 0.09853257551567246
Trained batch 151 in epoch 2, gen_loss = 0.8030943745060971, disc_loss = 0.09816455021868215
Trained batch 152 in epoch 2, gen_loss = 0.804272216909072, disc_loss = 0.09770055881585755
Trained batch 153 in epoch 2, gen_loss = 0.8031239049001173, disc_loss = 0.09782054920547775
Trained batch 154 in epoch 2, gen_loss = 0.8033978173809667, disc_loss = 0.0978526879883101
Trained batch 155 in epoch 2, gen_loss = 0.8032078024668571, disc_loss = 0.09800122288437799
Trained batch 156 in epoch 2, gen_loss = 0.8021913231558101, disc_loss = 0.0979694248277955
Trained batch 157 in epoch 2, gen_loss = 0.8016914261292808, disc_loss = 0.09776618536208061
Trained batch 158 in epoch 2, gen_loss = 0.8041330737137945, disc_loss = 0.0981762063097935
Trained batch 159 in epoch 2, gen_loss = 0.8035952143371106, disc_loss = 0.09784453880856744
Trained batch 160 in epoch 2, gen_loss = 0.801872910549922, disc_loss = 0.09848804074854399
Trained batch 161 in epoch 2, gen_loss = 0.8025817543636133, disc_loss = 0.09869106681327577
Trained batch 162 in epoch 2, gen_loss = 0.8026534168998156, disc_loss = 0.09862567120420238
Trained batch 163 in epoch 2, gen_loss = 0.8024693934655771, disc_loss = 0.09841796057866659
Trained batch 164 in epoch 2, gen_loss = 0.8019118388493855, disc_loss = 0.09842403690810457
Trained batch 165 in epoch 2, gen_loss = 0.8020242560340698, disc_loss = 0.09875022482508457
Trained batch 166 in epoch 2, gen_loss = 0.8014370663437301, disc_loss = 0.09886885819744742
Trained batch 167 in epoch 2, gen_loss = 0.8008721573721795, disc_loss = 0.09887358778533303
Trained batch 168 in epoch 2, gen_loss = 0.8000489921259457, disc_loss = 0.09967746909090577
Trained batch 169 in epoch 2, gen_loss = 0.800621981831158, disc_loss = 0.10001202753251966
Trained batch 170 in epoch 2, gen_loss = 0.7990935260092306, disc_loss = 0.10080635967550047
Trained batch 171 in epoch 2, gen_loss = 0.7988142041965972, disc_loss = 0.10084724822081625
Trained batch 172 in epoch 2, gen_loss = 0.799293231068319, disc_loss = 0.10103610473970286
Trained batch 173 in epoch 2, gen_loss = 0.7985037164441471, disc_loss = 0.10126193798543222
Trained batch 174 in epoch 2, gen_loss = 0.797633136681148, disc_loss = 0.1017109794010009
Trained batch 175 in epoch 2, gen_loss = 0.7974845221774145, disc_loss = 0.10209157543828372
Trained batch 176 in epoch 2, gen_loss = 0.7974202174924861, disc_loss = 0.10195299487897737
Trained batch 177 in epoch 2, gen_loss = 0.7973278707332825, disc_loss = 0.10160438265923537
Trained batch 178 in epoch 2, gen_loss = 0.7965785890984136, disc_loss = 0.10150208463111902
Trained batch 179 in epoch 2, gen_loss = 0.7988286660777197, disc_loss = 0.10181168112386432
Trained batch 180 in epoch 2, gen_loss = 0.797844760984347, disc_loss = 0.10166935113809221
Trained batch 181 in epoch 2, gen_loss = 0.7971853813627264, disc_loss = 0.10216447516027224
Trained batch 182 in epoch 2, gen_loss = 0.7980879300930461, disc_loss = 0.10287331779044671
Trained batch 183 in epoch 2, gen_loss = 0.7976606348934381, disc_loss = 0.1029840899054366
Trained batch 184 in epoch 2, gen_loss = 0.7974085798134675, disc_loss = 0.10314462411947348
Trained batch 185 in epoch 2, gen_loss = 0.7969284926050453, disc_loss = 0.10324915011303239
Trained batch 186 in epoch 2, gen_loss = 0.7965531084626754, disc_loss = 0.10317896889711925
Trained batch 187 in epoch 2, gen_loss = 0.7970320097309478, disc_loss = 0.10278355131579682
Trained batch 188 in epoch 2, gen_loss = 0.7961600763457162, disc_loss = 0.10273599281177792
Trained batch 189 in epoch 2, gen_loss = 0.7978164487763455, disc_loss = 0.10273972564916077
Trained batch 190 in epoch 2, gen_loss = 0.7970666910341273, disc_loss = 0.10273753816057093
Trained batch 191 in epoch 2, gen_loss = 0.7973988698795438, disc_loss = 0.10245254418017187
Trained batch 192 in epoch 2, gen_loss = 0.7966500959248123, disc_loss = 0.10241101550449824
Trained batch 193 in epoch 2, gen_loss = 0.7964190816141895, disc_loss = 0.102544249635497
Trained batch 194 in epoch 2, gen_loss = 0.7961558121901292, disc_loss = 0.10251853882024685
Trained batch 195 in epoch 2, gen_loss = 0.7958547637170675, disc_loss = 0.10246092072992148
Trained batch 196 in epoch 2, gen_loss = 0.7948891953163341, disc_loss = 0.10257392527469372
Trained batch 197 in epoch 2, gen_loss = 0.7968485234963774, disc_loss = 0.10265257461184654
Trained batch 198 in epoch 2, gen_loss = 0.7985427774975647, disc_loss = 0.10231379297416864
Trained batch 199 in epoch 2, gen_loss = 0.7973137855529785, disc_loss = 0.10233670601155609
Trained batch 200 in epoch 2, gen_loss = 0.7981609651698401, disc_loss = 0.10193882626365518
Trained batch 201 in epoch 2, gen_loss = 0.7983041830582194, disc_loss = 0.10164496988187184
Trained batch 202 in epoch 2, gen_loss = 0.7981899166342072, disc_loss = 0.1017555098916436
Trained batch 203 in epoch 2, gen_loss = 0.7974625241522696, disc_loss = 0.10169209754916236
Trained batch 204 in epoch 2, gen_loss = 0.7969423067278978, disc_loss = 0.10156385047679267
Trained batch 205 in epoch 2, gen_loss = 0.798467480441899, disc_loss = 0.10174217175927411
Trained batch 206 in epoch 2, gen_loss = 0.8011609937833704, disc_loss = 0.10163657417169948
Trained batch 207 in epoch 2, gen_loss = 0.8005631540257198, disc_loss = 0.10143768029341188
Trained batch 208 in epoch 2, gen_loss = 0.7993249821891054, disc_loss = 0.10202829213144533
Trained batch 209 in epoch 2, gen_loss = 0.7996050641650245, disc_loss = 0.10210034362528296
Trained batch 210 in epoch 2, gen_loss = 0.8009561989544692, disc_loss = 0.10200697809934475
Trained batch 211 in epoch 2, gen_loss = 0.800102986254782, disc_loss = 0.10218042034638238
Trained batch 212 in epoch 2, gen_loss = 0.7997393470974595, disc_loss = 0.10220312678250769
Trained batch 213 in epoch 2, gen_loss = 0.7993569421433957, disc_loss = 0.10223380091086587
Trained batch 214 in epoch 2, gen_loss = 0.7990054352338924, disc_loss = 0.10234357553079378
Trained batch 215 in epoch 2, gen_loss = 0.7996135629989483, disc_loss = 0.10234624866171982
Trained batch 216 in epoch 2, gen_loss = 0.7989126713045182, disc_loss = 0.10220514791953261
Trained batch 217 in epoch 2, gen_loss = 0.7980409994584705, disc_loss = 0.10226973530263939
Trained batch 218 in epoch 2, gen_loss = 0.7984937217137585, disc_loss = 0.10258329800461934
Trained batch 219 in epoch 2, gen_loss = 0.797651894255118, disc_loss = 0.10256509653461927
Trained batch 220 in epoch 2, gen_loss = 0.7969970112472637, disc_loss = 0.10258356783100787
Trained batch 221 in epoch 2, gen_loss = 0.7981907099753887, disc_loss = 0.10269721612116103
Trained batch 222 in epoch 2, gen_loss = 0.7981390255449065, disc_loss = 0.10243221510602621
Trained batch 223 in epoch 2, gen_loss = 0.7974614210958991, disc_loss = 0.10234726268182774
Trained batch 224 in epoch 2, gen_loss = 0.7967664281527201, disc_loss = 0.10232405220054917
Trained batch 225 in epoch 2, gen_loss = 0.7971168152526417, disc_loss = 0.10233243552770104
Trained batch 226 in epoch 2, gen_loss = 0.7976068329180915, disc_loss = 0.10220178772617411
Trained batch 227 in epoch 2, gen_loss = 0.797511829618822, disc_loss = 0.10189668485780426
Trained batch 228 in epoch 2, gen_loss = 0.798178113704165, disc_loss = 0.10152570714189886
Trained batch 229 in epoch 2, gen_loss = 0.7972979105037191, disc_loss = 0.10181978882249931
Trained batch 230 in epoch 2, gen_loss = 0.7982680116380964, disc_loss = 0.10159892715852369
Trained batch 231 in epoch 2, gen_loss = 0.7995426726752314, disc_loss = 0.10187953178658439
Trained batch 232 in epoch 2, gen_loss = 0.7981917074054096, disc_loss = 0.10251318610197357
Trained batch 233 in epoch 2, gen_loss = 0.7987887259477224, disc_loss = 0.10223810458715019
Trained batch 234 in epoch 2, gen_loss = 0.7998256542581192, disc_loss = 0.10199811020667883
Trained batch 235 in epoch 2, gen_loss = 0.8000915003782612, disc_loss = 0.10165711393248353
Trained batch 236 in epoch 2, gen_loss = 0.799081037190393, disc_loss = 0.1019717452591796
Trained batch 237 in epoch 2, gen_loss = 0.7992649698207358, disc_loss = 0.10208741326996383
Trained batch 238 in epoch 2, gen_loss = 0.8003649231529635, disc_loss = 0.10180911194595457
Trained batch 239 in epoch 2, gen_loss = 0.8009969188521305, disc_loss = 0.10146288632337624
Trained batch 240 in epoch 2, gen_loss = 0.8004348249603603, disc_loss = 0.10174780585938346
Trained batch 241 in epoch 2, gen_loss = 0.8014188001224817, disc_loss = 0.10158157357484225
Trained batch 242 in epoch 2, gen_loss = 0.8018747782756271, disc_loss = 0.10136514539933866
Trained batch 243 in epoch 2, gen_loss = 0.8009148348794609, disc_loss = 0.10131186209848059
Trained batch 244 in epoch 2, gen_loss = 0.8012697279453278, disc_loss = 0.10101966497925471
Trained batch 245 in epoch 2, gen_loss = 0.8018506323176671, disc_loss = 0.10091528901073142
Trained batch 246 in epoch 2, gen_loss = 0.8017003274398294, disc_loss = 0.10057740244139665
Trained batch 247 in epoch 2, gen_loss = 0.8017425699339759, disc_loss = 0.10024369542952627
Trained batch 248 in epoch 2, gen_loss = 0.8025733887191757, disc_loss = 0.09993174103234546
Trained batch 249 in epoch 2, gen_loss = 0.8026394993066788, disc_loss = 0.09966417248174549
Trained batch 250 in epoch 2, gen_loss = 0.8033588584438264, disc_loss = 0.09931106328504138
Trained batch 251 in epoch 2, gen_loss = 0.8022951730896556, disc_loss = 0.09936693195800578
Trained batch 252 in epoch 2, gen_loss = 0.8021441883013654, disc_loss = 0.09915900899266655
Trained batch 253 in epoch 2, gen_loss = 0.8021285962166749, disc_loss = 0.09892387490528892
Trained batch 254 in epoch 2, gen_loss = 0.8024485874409769, disc_loss = 0.09889078878377583
Trained batch 255 in epoch 2, gen_loss = 0.8015385331818834, disc_loss = 0.09912628944221069
Trained batch 256 in epoch 2, gen_loss = 0.8011396315079254, disc_loss = 0.09906059499569092
Trained batch 257 in epoch 2, gen_loss = 0.8020670565292817, disc_loss = 0.09919062882387476
Trained batch 258 in epoch 2, gen_loss = 0.8012214881803078, disc_loss = 0.09955338370342627
Trained batch 259 in epoch 2, gen_loss = 0.8021537071237197, disc_loss = 0.09945223648459292
Trained batch 260 in epoch 2, gen_loss = 0.8033856889982333, disc_loss = 0.09916096540717444
Trained batch 261 in epoch 2, gen_loss = 0.8034191624126361, disc_loss = 0.09893031245211267
Trained batch 262 in epoch 2, gen_loss = 0.8029330643637552, disc_loss = 0.09900905047773521
Trained batch 263 in epoch 2, gen_loss = 0.8031886830700167, disc_loss = 0.09885994901273851
Trained batch 264 in epoch 2, gen_loss = 0.8044467144417313, disc_loss = 0.09883567283527468
Trained batch 265 in epoch 2, gen_loss = 0.803141728715789, disc_loss = 0.09934158878456942
Trained batch 266 in epoch 2, gen_loss = 0.8025606932041797, disc_loss = 0.09927871826450142
Trained batch 267 in epoch 2, gen_loss = 0.8033110480477561, disc_loss = 0.09984664644337078
Trained batch 268 in epoch 2, gen_loss = 0.8033807329750415, disc_loss = 0.09969984917627946
Trained batch 269 in epoch 2, gen_loss = 0.8027602199051115, disc_loss = 0.09992412685037211
Trained batch 270 in epoch 2, gen_loss = 0.802006391911489, disc_loss = 0.09998277872044772
Trained batch 271 in epoch 2, gen_loss = 0.8020389473394436, disc_loss = 0.09995403015123241
Trained batch 272 in epoch 2, gen_loss = 0.8019589154056577, disc_loss = 0.10002426170290281
Trained batch 273 in epoch 2, gen_loss = 0.8009735394785874, disc_loss = 0.10033655721680636
Trained batch 274 in epoch 2, gen_loss = 0.8016082036495209, disc_loss = 0.10058334459296682
Trained batch 275 in epoch 2, gen_loss = 0.8009017745869748, disc_loss = 0.10089369545069833
Trained batch 276 in epoch 2, gen_loss = 0.8014286645698203, disc_loss = 0.10076039669436776
Trained batch 277 in epoch 2, gen_loss = 0.800701899386996, disc_loss = 0.10072123039875636
Trained batch 278 in epoch 2, gen_loss = 0.8004252116953601, disc_loss = 0.10082282580261696
Trained batch 279 in epoch 2, gen_loss = 0.8003625772893429, disc_loss = 0.10068776099610009
Trained batch 280 in epoch 2, gen_loss = 0.8002628222691207, disc_loss = 0.10059996798064468
Trained batch 281 in epoch 2, gen_loss = 0.8006879553093132, disc_loss = 0.10065975045811729
Trained batch 282 in epoch 2, gen_loss = 0.8002115282700677, disc_loss = 0.10077023411715937
Trained batch 283 in epoch 2, gen_loss = 0.8000712731564549, disc_loss = 0.10083430911361857
Trained batch 284 in epoch 2, gen_loss = 0.7998835755021949, disc_loss = 0.1009143260258593
Trained batch 285 in epoch 2, gen_loss = 0.7996087896448749, disc_loss = 0.10095445819889436
Trained batch 286 in epoch 2, gen_loss = 0.7997801639269453, disc_loss = 0.10093580142559179
Trained batch 287 in epoch 2, gen_loss = 0.8002927856933739, disc_loss = 0.10098184228991158
Trained batch 288 in epoch 2, gen_loss = 0.8002845297428975, disc_loss = 0.10112265430738872
Trained batch 289 in epoch 2, gen_loss = 0.8001353406700594, disc_loss = 0.10111260928277825
Trained batch 290 in epoch 2, gen_loss = 0.8004282797939589, disc_loss = 0.10103920171568587
Trained batch 291 in epoch 2, gen_loss = 0.79941529658151, disc_loss = 0.10122887946167732
Trained batch 292 in epoch 2, gen_loss = 0.7989736906294123, disc_loss = 0.10122193732066874
Trained batch 293 in epoch 2, gen_loss = 0.8000654761685806, disc_loss = 0.10170328612344301
Trained batch 294 in epoch 2, gen_loss = 0.7988837403766179, disc_loss = 0.10218663902921697
Trained batch 295 in epoch 2, gen_loss = 0.7986107172595488, disc_loss = 0.10276806062855129
Trained batch 296 in epoch 2, gen_loss = 0.7983107958177124, disc_loss = 0.102662346281914
Trained batch 297 in epoch 2, gen_loss = 0.7978056629232112, disc_loss = 0.10262791982745664
Trained batch 298 in epoch 2, gen_loss = 0.7974418605051711, disc_loss = 0.10268589121953002
Trained batch 299 in epoch 2, gen_loss = 0.7969291849931082, disc_loss = 0.10291185637625555
Trained batch 300 in epoch 2, gen_loss = 0.7964840778876777, disc_loss = 0.10291897943955026
Trained batch 301 in epoch 2, gen_loss = 0.7962399519831929, disc_loss = 0.10296396926255119
Trained batch 302 in epoch 2, gen_loss = 0.7965043338611968, disc_loss = 0.10274214873231775
Trained batch 303 in epoch 2, gen_loss = 0.7981605819965664, disc_loss = 0.10279703603775583
Trained batch 304 in epoch 2, gen_loss = 0.7975780494877549, disc_loss = 0.10272367797242325
Trained batch 305 in epoch 2, gen_loss = 0.7970030755778543, disc_loss = 0.10278852518002679
Trained batch 306 in epoch 2, gen_loss = 0.7971754202236958, disc_loss = 0.10268703508661023
Trained batch 307 in epoch 2, gen_loss = 0.7975070383641627, disc_loss = 0.10253640949157636
Trained batch 308 in epoch 2, gen_loss = 0.7972750150655852, disc_loss = 0.10237934994044139
Trained batch 309 in epoch 2, gen_loss = 0.7967447119374429, disc_loss = 0.10234775794669985
Trained batch 310 in epoch 2, gen_loss = 0.797004088328199, disc_loss = 0.1021290671026448
Trained batch 311 in epoch 2, gen_loss = 0.7970199309862577, disc_loss = 0.10203347483184189
Trained batch 312 in epoch 2, gen_loss = 0.7967991775598008, disc_loss = 0.10178892441486684
Trained batch 313 in epoch 2, gen_loss = 0.7973326220633877, disc_loss = 0.10156873884984548
Trained batch 314 in epoch 2, gen_loss = 0.7981884903377957, disc_loss = 0.10139557519070212
Trained batch 315 in epoch 2, gen_loss = 0.7974174084919917, disc_loss = 0.10150823075784064
Trained batch 316 in epoch 2, gen_loss = 0.7969951872193851, disc_loss = 0.1014533254291498
Trained batch 317 in epoch 2, gen_loss = 0.7974092861016592, disc_loss = 0.1017432794671904
Trained batch 318 in epoch 2, gen_loss = 0.7975245275093844, disc_loss = 0.101597788854616
Trained batch 319 in epoch 2, gen_loss = 0.7975730219855904, disc_loss = 0.10158362687507179
Trained batch 320 in epoch 2, gen_loss = 0.7973841382335651, disc_loss = 0.10147741347307636
Trained batch 321 in epoch 2, gen_loss = 0.7977020779381627, disc_loss = 0.10140753582247203
Trained batch 322 in epoch 2, gen_loss = 0.797277034805286, disc_loss = 0.10129885639326398
Trained batch 323 in epoch 2, gen_loss = 0.7972877549904364, disc_loss = 0.10164524229346877
Trained batch 324 in epoch 2, gen_loss = 0.796781122317681, disc_loss = 0.10145609409476702
Trained batch 325 in epoch 2, gen_loss = 0.796256016917024, disc_loss = 0.10157259666515182
Trained batch 326 in epoch 2, gen_loss = 0.7958730490200381, disc_loss = 0.1015574430921528
Trained batch 327 in epoch 2, gen_loss = 0.7973333573559436, disc_loss = 0.10179622908315916
Trained batch 328 in epoch 2, gen_loss = 0.7971800908129266, disc_loss = 0.10182503170098849
Trained batch 329 in epoch 2, gen_loss = 0.7966234669540868, disc_loss = 0.10197052784884969
Trained batch 330 in epoch 2, gen_loss = 0.796649544980951, disc_loss = 0.10195378095665637
Trained batch 331 in epoch 2, gen_loss = 0.7974423127002027, disc_loss = 0.10187758580242923
Trained batch 332 in epoch 2, gen_loss = 0.7966702943807608, disc_loss = 0.10208070035128891
Trained batch 333 in epoch 2, gen_loss = 0.7972239687771141, disc_loss = 0.10228933722706522
Trained batch 334 in epoch 2, gen_loss = 0.7970181249860507, disc_loss = 0.10227459162862888
Trained batch 335 in epoch 2, gen_loss = 0.7966088633097353, disc_loss = 0.10229839254558708
Trained batch 336 in epoch 2, gen_loss = 0.7966592034175771, disc_loss = 0.10239981480484459
Trained batch 337 in epoch 2, gen_loss = 0.7961379428939707, disc_loss = 0.10231701525743808
Trained batch 338 in epoch 2, gen_loss = 0.7959698588095584, disc_loss = 0.10216960142528676
Trained batch 339 in epoch 2, gen_loss = 0.7955629126114003, disc_loss = 0.1021794850636712
Trained batch 340 in epoch 2, gen_loss = 0.7957488307155822, disc_loss = 0.10205394761292728
Trained batch 341 in epoch 2, gen_loss = 0.7952789261675718, disc_loss = 0.10213785311098249
Trained batch 342 in epoch 2, gen_loss = 0.7949649750665048, disc_loss = 0.10203313051774533
Trained batch 343 in epoch 2, gen_loss = 0.7951164398082468, disc_loss = 0.10207947451610465
Trained batch 344 in epoch 2, gen_loss = 0.7948488815971043, disc_loss = 0.10196484724410634
Trained batch 345 in epoch 2, gen_loss = 0.7945144760470859, disc_loss = 0.10188224900653856
Trained batch 346 in epoch 2, gen_loss = 0.7938283128765887, disc_loss = 0.10214031775151876
Trained batch 347 in epoch 2, gen_loss = 0.7950340821140114, disc_loss = 0.1027525865670893
Trained batch 348 in epoch 2, gen_loss = 0.7955615674185548, disc_loss = 0.10254520914093045
Trained batch 349 in epoch 2, gen_loss = 0.7957524926321847, disc_loss = 0.10239790471270681
Trained batch 350 in epoch 2, gen_loss = 0.7954706656627166, disc_loss = 0.10230034786910668
Trained batch 351 in epoch 2, gen_loss = 0.7950295878743584, disc_loss = 0.10221188254813156
Trained batch 352 in epoch 2, gen_loss = 0.7951108897711671, disc_loss = 0.1020605791302097
Trained batch 353 in epoch 2, gen_loss = 0.7959401427352496, disc_loss = 0.10213024713004291
Trained batch 354 in epoch 2, gen_loss = 0.7957059430404448, disc_loss = 0.10220768590995544
Trained batch 355 in epoch 2, gen_loss = 0.7955622368314293, disc_loss = 0.10221984246588742
Trained batch 356 in epoch 2, gen_loss = 0.7958015857958326, disc_loss = 0.10214551925106126
Trained batch 357 in epoch 2, gen_loss = 0.7956412586086955, disc_loss = 0.10204326541178636
Trained batch 358 in epoch 2, gen_loss = 0.7965470733416777, disc_loss = 0.10181545835860012
Trained batch 359 in epoch 2, gen_loss = 0.7983678743243218, disc_loss = 0.101900518212157
Trained batch 360 in epoch 2, gen_loss = 0.7992562050634474, disc_loss = 0.10167588070912127
Trained batch 361 in epoch 2, gen_loss = 0.799176293677388, disc_loss = 0.10151750129488045
Trained batch 362 in epoch 2, gen_loss = 0.7990377855694983, disc_loss = 0.10143805794243395
Trained batch 363 in epoch 2, gen_loss = 0.7989994562589205, disc_loss = 0.10131047295846536
Trained batch 364 in epoch 2, gen_loss = 0.7994089185375057, disc_loss = 0.10116893316631856
Trained batch 365 in epoch 2, gen_loss = 0.7991260075178303, disc_loss = 0.10114417813687784
Trained batch 366 in epoch 2, gen_loss = 0.7993836474353676, disc_loss = 0.10099591162786578
Trained batch 367 in epoch 2, gen_loss = 0.7992314466315767, disc_loss = 0.10092596780842818
Trained batch 368 in epoch 2, gen_loss = 0.7990244249018227, disc_loss = 0.10086992605359654
Trained batch 369 in epoch 2, gen_loss = 0.7997068041079753, disc_loss = 0.10087950652767275
Trained batch 370 in epoch 2, gen_loss = 0.8002233058615836, disc_loss = 0.10071970184265844
Trained batch 371 in epoch 2, gen_loss = 0.7995061243093142, disc_loss = 0.100782224880932
Trained batch 372 in epoch 2, gen_loss = 0.7990284562110901, disc_loss = 0.10080248088733201
Trained batch 373 in epoch 2, gen_loss = 0.7989694745464121, disc_loss = 0.10100973329013761
Trained batch 374 in epoch 2, gen_loss = 0.7985108866691589, disc_loss = 0.1012249831284086
Trained batch 375 in epoch 2, gen_loss = 0.7984901232288238, disc_loss = 0.1010592278870853
Trained batch 376 in epoch 2, gen_loss = 0.7986629124661656, disc_loss = 0.10088613350932493
Trained batch 377 in epoch 2, gen_loss = 0.7987149242686216, disc_loss = 0.10086962235992943
Trained batch 378 in epoch 2, gen_loss = 0.7983813897600903, disc_loss = 0.10096142004860816
Trained batch 379 in epoch 2, gen_loss = 0.7981573404450165, disc_loss = 0.10087009490173506
Trained batch 380 in epoch 2, gen_loss = 0.7982359827347002, disc_loss = 0.10085364601518616
Trained batch 381 in epoch 2, gen_loss = 0.7981393521368816, disc_loss = 0.10099853922647098
Trained batch 382 in epoch 2, gen_loss = 0.7980922924320629, disc_loss = 0.10107034269973207
Trained batch 383 in epoch 2, gen_loss = 0.7983635449782014, disc_loss = 0.10100354289412887
Trained batch 384 in epoch 2, gen_loss = 0.7984671156127732, disc_loss = 0.10085047244686972
Trained batch 385 in epoch 2, gen_loss = 0.7984767055882074, disc_loss = 0.10073261811528259
Trained batch 386 in epoch 2, gen_loss = 0.7987316441782377, disc_loss = 0.10057617954245603
Trained batch 387 in epoch 2, gen_loss = 0.7995841744327054, disc_loss = 0.10037286993183349
Trained batch 388 in epoch 2, gen_loss = 0.7991403808630524, disc_loss = 0.10042684782622023
Trained batch 389 in epoch 2, gen_loss = 0.7992656559516222, disc_loss = 0.1003068871008089
Trained batch 390 in epoch 2, gen_loss = 0.7996696311494579, disc_loss = 0.10007687552553385
Trained batch 391 in epoch 2, gen_loss = 0.8001380549097548, disc_loss = 0.09987234530675852
Trained batch 392 in epoch 2, gen_loss = 0.7997713565219753, disc_loss = 0.09988356983815214
Trained batch 393 in epoch 2, gen_loss = 0.799290130132346, disc_loss = 0.09988142379091551
Trained batch 394 in epoch 2, gen_loss = 0.8002290712127202, disc_loss = 0.1003145222728954
Trained batch 395 in epoch 2, gen_loss = 0.8002121916624031, disc_loss = 0.10033905887364815
Trained batch 396 in epoch 2, gen_loss = 0.7993626554756982, disc_loss = 0.10076051294775469
Trained batch 397 in epoch 2, gen_loss = 0.8008292580219969, disc_loss = 0.10207148193236647
Trained batch 398 in epoch 2, gen_loss = 0.8005556478386834, disc_loss = 0.10229382502676028
Trained batch 399 in epoch 2, gen_loss = 0.8006346731632948, disc_loss = 0.10336776801617815
Trained batch 400 in epoch 2, gen_loss = 0.8014169511503709, disc_loss = 0.10464771572463308
Trained batch 401 in epoch 2, gen_loss = 0.8013970336659038, disc_loss = 0.1046816273638747
Trained batch 402 in epoch 2, gen_loss = 0.801235012395802, disc_loss = 0.10497462419705193
Trained batch 403 in epoch 2, gen_loss = 0.8008703870495947, disc_loss = 0.10516583708594415
Trained batch 404 in epoch 2, gen_loss = 0.8010445851602672, disc_loss = 0.1052886227329756
Trained batch 405 in epoch 2, gen_loss = 0.8007748397847114, disc_loss = 0.1052985300649453
Trained batch 406 in epoch 2, gen_loss = 0.8000846434137452, disc_loss = 0.10545118569787729
Trained batch 407 in epoch 2, gen_loss = 0.80045206194707, disc_loss = 0.10535854356153411
Trained batch 408 in epoch 2, gen_loss = 0.8002499113893159, disc_loss = 0.10536923020176389
Trained batch 409 in epoch 2, gen_loss = 0.800023984836369, disc_loss = 0.1053444335305291
Trained batch 410 in epoch 2, gen_loss = 0.7998551935900157, disc_loss = 0.1053691925435642
Trained batch 411 in epoch 2, gen_loss = 0.7998663212344485, disc_loss = 0.10530330695763447
Trained batch 412 in epoch 2, gen_loss = 0.7996046145516504, disc_loss = 0.10522900546334918
Trained batch 413 in epoch 2, gen_loss = 0.7994401222409834, disc_loss = 0.10523891466296309
Trained batch 414 in epoch 2, gen_loss = 0.800096720457077, disc_loss = 0.1053469403613224
Trained batch 415 in epoch 2, gen_loss = 0.799960336361367, disc_loss = 0.10532300696538116
Trained batch 416 in epoch 2, gen_loss = 0.7999253686812284, disc_loss = 0.10522358678057968
Trained batch 417 in epoch 2, gen_loss = 0.7994697378440336, disc_loss = 0.10529514228586447
Trained batch 418 in epoch 2, gen_loss = 0.799587969208105, disc_loss = 0.10533109315513213
Trained batch 419 in epoch 2, gen_loss = 0.8001363517982619, disc_loss = 0.10518511369868758
Trained batch 420 in epoch 2, gen_loss = 0.7999551493736458, disc_loss = 0.10507024508942972
Trained batch 421 in epoch 2, gen_loss = 0.7998544800479265, disc_loss = 0.10511118282400672
Trained batch 422 in epoch 2, gen_loss = 0.7996768292664918, disc_loss = 0.10492486847745118
Trained batch 423 in epoch 2, gen_loss = 0.7996618250771513, disc_loss = 0.10475388508650281
Trained batch 424 in epoch 2, gen_loss = 0.799823796118007, disc_loss = 0.10456855560269426
Trained batch 425 in epoch 2, gen_loss = 0.7998197608290704, disc_loss = 0.1045459910654441
Trained batch 426 in epoch 2, gen_loss = 0.7996536862515174, disc_loss = 0.10438311149952911
Trained batch 427 in epoch 2, gen_loss = 0.800231788551139, disc_loss = 0.10422206094932403
Trained batch 428 in epoch 2, gen_loss = 0.8003847624733176, disc_loss = 0.10402356605924717
Trained batch 429 in epoch 2, gen_loss = 0.801005187492038, disc_loss = 0.1038108502991151
Trained batch 430 in epoch 2, gen_loss = 0.8011160609755328, disc_loss = 0.10360069446300271
Trained batch 431 in epoch 2, gen_loss = 0.8013856793857284, disc_loss = 0.10340849388201066
Trained batch 432 in epoch 2, gen_loss = 0.8013643848840964, disc_loss = 0.10323911237661612
Trained batch 433 in epoch 2, gen_loss = 0.8013599841138734, disc_loss = 0.10311745576697835
Trained batch 434 in epoch 2, gen_loss = 0.8019729783480195, disc_loss = 0.10311381769762643
Trained batch 435 in epoch 2, gen_loss = 0.8013907625177584, disc_loss = 0.10335153697588302
Trained batch 436 in epoch 2, gen_loss = 0.8015178268097631, disc_loss = 0.10323255632746138
Trained batch 437 in epoch 2, gen_loss = 0.8028610678704362, disc_loss = 0.10332978288026433
Trained batch 438 in epoch 2, gen_loss = 0.8033800685188494, disc_loss = 0.10316451894785522
Trained batch 439 in epoch 2, gen_loss = 0.8030915831300345, disc_loss = 0.10316117923622105
Trained batch 440 in epoch 2, gen_loss = 0.802970787092131, disc_loss = 0.10305379547786955
Trained batch 441 in epoch 2, gen_loss = 0.8038366734307276, disc_loss = 0.1029031005860791
Trained batch 442 in epoch 2, gen_loss = 0.8034420533454715, disc_loss = 0.10280918941725861
Trained batch 443 in epoch 2, gen_loss = 0.8035312709104907, disc_loss = 0.10264485760231142
Trained batch 444 in epoch 2, gen_loss = 0.8032456733537524, disc_loss = 0.10254128532212102
Trained batch 445 in epoch 2, gen_loss = 0.8031259000702289, disc_loss = 0.10239326905860094
Trained batch 446 in epoch 2, gen_loss = 0.8034949516690018, disc_loss = 0.10221853859772619
Trained batch 447 in epoch 2, gen_loss = 0.8033615684003702, disc_loss = 0.10212809760456107
Trained batch 448 in epoch 2, gen_loss = 0.8031881023488756, disc_loss = 0.10200737672287531
Trained batch 449 in epoch 2, gen_loss = 0.8034800550010469, disc_loss = 0.10202251275380453
Trained batch 450 in epoch 2, gen_loss = 0.8030446847764457, disc_loss = 0.10209026959148584
Trained batch 451 in epoch 2, gen_loss = 0.8031497072197694, disc_loss = 0.10197197599748595
Trained batch 452 in epoch 2, gen_loss = 0.8034803266688425, disc_loss = 0.10197513739662718
Trained batch 453 in epoch 2, gen_loss = 0.803541403969479, disc_loss = 0.10184612089054175
Trained batch 454 in epoch 2, gen_loss = 0.803484001329967, disc_loss = 0.10173915505081743
Trained batch 455 in epoch 2, gen_loss = 0.8029916477961498, disc_loss = 0.10174755539679736
Trained batch 456 in epoch 2, gen_loss = 0.8041587565216507, disc_loss = 0.10173829767192741
Trained batch 457 in epoch 2, gen_loss = 0.8046656504078203, disc_loss = 0.10166763470357683
Trained batch 458 in epoch 2, gen_loss = 0.8040194741910839, disc_loss = 0.10200269840057119
Trained batch 459 in epoch 2, gen_loss = 0.8045421700762666, disc_loss = 0.1018375856720883
Trained batch 460 in epoch 2, gen_loss = 0.8046035225505167, disc_loss = 0.10194287508920061
Trained batch 461 in epoch 2, gen_loss = 0.8040844901944652, disc_loss = 0.1019759224122995
Trained batch 462 in epoch 2, gen_loss = 0.8038250141602098, disc_loss = 0.1018884934275763
Trained batch 463 in epoch 2, gen_loss = 0.8038616662780786, disc_loss = 0.10181136111375587
Trained batch 464 in epoch 2, gen_loss = 0.8043207870375726, disc_loss = 0.10163889154391263
Trained batch 465 in epoch 2, gen_loss = 0.8038986519043027, disc_loss = 0.10170814675147058
Trained batch 466 in epoch 2, gen_loss = 0.8040024194651038, disc_loss = 0.10162076967064394
Trained batch 467 in epoch 2, gen_loss = 0.8037469478117095, disc_loss = 0.10173395830485174
Trained batch 468 in epoch 2, gen_loss = 0.8035659836426473, disc_loss = 0.10175020754861552
Trained batch 469 in epoch 2, gen_loss = 0.8029350067072726, disc_loss = 0.10186746479111149
Trained batch 470 in epoch 2, gen_loss = 0.8025191328201577, disc_loss = 0.10182978409380038
Trained batch 471 in epoch 2, gen_loss = 0.8027820011948125, disc_loss = 0.10176634189072933
Trained batch 472 in epoch 2, gen_loss = 0.8025773098932513, disc_loss = 0.10178374379763014
Trained batch 473 in epoch 2, gen_loss = 0.8022829601659051, disc_loss = 0.10177717883265597
Trained batch 474 in epoch 2, gen_loss = 0.8016122730782157, disc_loss = 0.10191994595292367
Trained batch 475 in epoch 2, gen_loss = 0.8020044921451256, disc_loss = 0.10206919555168818
Trained batch 476 in epoch 2, gen_loss = 0.8023802946073704, disc_loss = 0.10202166268238856
Trained batch 477 in epoch 2, gen_loss = 0.8019543030147274, disc_loss = 0.10190920371593416
Trained batch 478 in epoch 2, gen_loss = 0.8018311148272178, disc_loss = 0.1019084177685742
Trained batch 479 in epoch 2, gen_loss = 0.8018384361639619, disc_loss = 0.10181165374427413
Trained batch 480 in epoch 2, gen_loss = 0.8022258369070081, disc_loss = 0.10195469663801783
Trained batch 481 in epoch 2, gen_loss = 0.8035171754750968, disc_loss = 0.10201555329347918
Trained batch 482 in epoch 2, gen_loss = 0.803435595694536, disc_loss = 0.10196244545034124
Trained batch 483 in epoch 2, gen_loss = 0.802858030808366, disc_loss = 0.1019747635111028
Trained batch 484 in epoch 2, gen_loss = 0.8026814597783629, disc_loss = 0.10188563425746776
Trained batch 485 in epoch 2, gen_loss = 0.8026278435325427, disc_loss = 0.10194105620844741
Trained batch 486 in epoch 2, gen_loss = 0.8022697288275255, disc_loss = 0.10206824455035418
Trained batch 487 in epoch 2, gen_loss = 0.8025525129842953, disc_loss = 0.10221707414392932
Trained batch 488 in epoch 2, gen_loss = 0.8025055951257912, disc_loss = 0.10221011442625572
Trained batch 489 in epoch 2, gen_loss = 0.8022810291879031, disc_loss = 0.10215918778688932
Trained batch 490 in epoch 2, gen_loss = 0.8023369332316451, disc_loss = 0.10201265595003568
Trained batch 491 in epoch 2, gen_loss = 0.8030465199816518, disc_loss = 0.10204178707038121
Trained batch 492 in epoch 2, gen_loss = 0.8030156554242418, disc_loss = 0.10190950666174564
Trained batch 493 in epoch 2, gen_loss = 0.8026676138764933, disc_loss = 0.10191460998600674
Trained batch 494 in epoch 2, gen_loss = 0.8026203961685451, disc_loss = 0.10207702518638337
Trained batch 495 in epoch 2, gen_loss = 0.8025104897998033, disc_loss = 0.10211109643005917
Trained batch 496 in epoch 2, gen_loss = 0.8029382458515091, disc_loss = 0.10193970518362834
Trained batch 497 in epoch 2, gen_loss = 0.8030326037880886, disc_loss = 0.10186562660976825
Trained batch 498 in epoch 2, gen_loss = 0.8024493814828639, disc_loss = 0.10207101094250927
Trained batch 499 in epoch 2, gen_loss = 0.8025530501008034, disc_loss = 0.10218354681879283
Trained batch 500 in epoch 2, gen_loss = 0.8022454109139547, disc_loss = 0.10215878365431241
Trained batch 501 in epoch 2, gen_loss = 0.8019507142058406, disc_loss = 0.10221028014037951
Trained batch 502 in epoch 2, gen_loss = 0.8018095019915943, disc_loss = 0.10251984214243548
Trained batch 503 in epoch 2, gen_loss = 0.8014141496803079, disc_loss = 0.10257736005864683
Trained batch 504 in epoch 2, gen_loss = 0.8014997233848761, disc_loss = 0.10257507067653213
Trained batch 505 in epoch 2, gen_loss = 0.8022368054969509, disc_loss = 0.10244266096900104
Trained batch 506 in epoch 2, gen_loss = 0.8020117594998264, disc_loss = 0.10255698313021801
Trained batch 507 in epoch 2, gen_loss = 0.8022918287576652, disc_loss = 0.10239747183500078
Trained batch 508 in epoch 2, gen_loss = 0.8020834397590465, disc_loss = 0.10231941996219115
Trained batch 509 in epoch 2, gen_loss = 0.8022286221677182, disc_loss = 0.10242352704061013
Trained batch 510 in epoch 2, gen_loss = 0.8026054853212576, disc_loss = 0.10230920099290616
Trained batch 511 in epoch 2, gen_loss = 0.802418302570004, disc_loss = 0.10225607034226414
Trained batch 512 in epoch 2, gen_loss = 0.8025187206895728, disc_loss = 0.10211229001191857
Trained batch 513 in epoch 2, gen_loss = 0.802486366624962, disc_loss = 0.10204668050987016
Trained batch 514 in epoch 2, gen_loss = 0.8024468197984603, disc_loss = 0.10200207714461586
Trained batch 515 in epoch 2, gen_loss = 0.802829891501009, disc_loss = 0.10206692525034033
Trained batch 516 in epoch 2, gen_loss = 0.803121273994907, disc_loss = 0.10192630634547663
Trained batch 517 in epoch 2, gen_loss = 0.8027811427259077, disc_loss = 0.10194577702454158
Trained batch 518 in epoch 2, gen_loss = 0.8024629875299788, disc_loss = 0.10190730798910579
Trained batch 519 in epoch 2, gen_loss = 0.8030147744485965, disc_loss = 0.10196860100214299
Trained batch 520 in epoch 2, gen_loss = 0.8031753456638322, disc_loss = 0.10205179881912275
Trained batch 521 in epoch 2, gen_loss = 0.8026371329337701, disc_loss = 0.10215241319260834
Trained batch 522 in epoch 2, gen_loss = 0.8025767840231354, disc_loss = 0.10214863546605776
Trained batch 523 in epoch 2, gen_loss = 0.8022061100101653, disc_loss = 0.10210223801661539
Trained batch 524 in epoch 2, gen_loss = 0.8025950859274184, disc_loss = 0.10204645511649904
Trained batch 525 in epoch 2, gen_loss = 0.8025536832360713, disc_loss = 0.10192824641646314
Trained batch 526 in epoch 2, gen_loss = 0.8020222486196478, disc_loss = 0.10202479087509059
Trained batch 527 in epoch 2, gen_loss = 0.8023412180782268, disc_loss = 0.1019709081403121
Trained batch 528 in epoch 2, gen_loss = 0.8026923668519761, disc_loss = 0.10196957940725163
Trained batch 529 in epoch 2, gen_loss = 0.8024603584464991, disc_loss = 0.101878593334893
Trained batch 530 in epoch 2, gen_loss = 0.802059771370304, disc_loss = 0.10209323149419998
Trained batch 531 in epoch 2, gen_loss = 0.8021909686967843, disc_loss = 0.10214104352841027
Trained batch 532 in epoch 2, gen_loss = 0.8025892602234352, disc_loss = 0.10217714058776957
Trained batch 533 in epoch 2, gen_loss = 0.802150332358446, disc_loss = 0.10228892313211821
Trained batch 534 in epoch 2, gen_loss = 0.8019907808192422, disc_loss = 0.10230900009519586
Trained batch 535 in epoch 2, gen_loss = 0.8020615083401772, disc_loss = 0.10236793819731518
Trained batch 536 in epoch 2, gen_loss = 0.802174962377193, disc_loss = 0.10239019939325597
Trained batch 537 in epoch 2, gen_loss = 0.8017441386073052, disc_loss = 0.10247127567054393
Trained batch 538 in epoch 2, gen_loss = 0.8014991105929818, disc_loss = 0.10237522307845569
Trained batch 539 in epoch 2, gen_loss = 0.8017636011596079, disc_loss = 0.10233487291606488
Trained batch 540 in epoch 2, gen_loss = 0.8017857758373077, disc_loss = 0.10240164237327584
Trained batch 541 in epoch 2, gen_loss = 0.8012516245080976, disc_loss = 0.10257634906118866
Trained batch 542 in epoch 2, gen_loss = 0.8012644379068694, disc_loss = 0.10248952846747736
Trained batch 543 in epoch 2, gen_loss = 0.8010903660974958, disc_loss = 0.10242607888957377
Trained batch 544 in epoch 2, gen_loss = 0.801127560477738, disc_loss = 0.10237626948077744
Trained batch 545 in epoch 2, gen_loss = 0.8009139649269782, disc_loss = 0.10237688761572916
Trained batch 546 in epoch 2, gen_loss = 0.8007088660431082, disc_loss = 0.10231289678207263
Trained batch 547 in epoch 2, gen_loss = 0.8009966687455664, disc_loss = 0.10235077337817336
Trained batch 548 in epoch 2, gen_loss = 0.8010084504746783, disc_loss = 0.10220487681446505
Trained batch 549 in epoch 2, gen_loss = 0.8007891071384603, disc_loss = 0.10213365255093032
Trained batch 550 in epoch 2, gen_loss = 0.8006514660784207, disc_loss = 0.10208266570204075
Trained batch 551 in epoch 2, gen_loss = 0.8005272582497286, disc_loss = 0.10205846711439823
Trained batch 552 in epoch 2, gen_loss = 0.8009921172751656, disc_loss = 0.10197650339744083
Trained batch 553 in epoch 2, gen_loss = 0.8012441009928604, disc_loss = 0.10186183862455378
Trained batch 554 in epoch 2, gen_loss = 0.8007122085438119, disc_loss = 0.10198197607454416
Trained batch 555 in epoch 2, gen_loss = 0.8009766810339132, disc_loss = 0.10203383129639484
Trained batch 556 in epoch 2, gen_loss = 0.8008176560782873, disc_loss = 0.10199607548569756
Trained batch 557 in epoch 2, gen_loss = 0.800918333152289, disc_loss = 0.10184087411343624
Trained batch 558 in epoch 2, gen_loss = 0.8010663343776744, disc_loss = 0.10171110688480474
Trained batch 559 in epoch 2, gen_loss = 0.8006278876215219, disc_loss = 0.1017337909267683
Trained batch 560 in epoch 2, gen_loss = 0.8004796457694389, disc_loss = 0.10166261350792466
Trained batch 561 in epoch 2, gen_loss = 0.8009332277914808, disc_loss = 0.10193410225782636
Trained batch 562 in epoch 2, gen_loss = 0.800799218577136, disc_loss = 0.10190081216897783
Trained batch 563 in epoch 2, gen_loss = 0.8002333854001464, disc_loss = 0.10222023700740426
Trained batch 564 in epoch 2, gen_loss = 0.8003996273585126, disc_loss = 0.10266434900067022
Trained batch 565 in epoch 2, gen_loss = 0.8004142310825759, disc_loss = 0.10266381428764587
Trained batch 566 in epoch 2, gen_loss = 0.7999196105638299, disc_loss = 0.10283320117577568
Trained batch 567 in epoch 2, gen_loss = 0.7996422061303132, disc_loss = 0.1028824194406592
Trained batch 568 in epoch 2, gen_loss = 0.7992489690416098, disc_loss = 0.10295073415998938
Trained batch 569 in epoch 2, gen_loss = 0.7992521242614378, disc_loss = 0.10289875190835773
Trained batch 570 in epoch 2, gen_loss = 0.7990603464184208, disc_loss = 0.10294319055452551
Trained batch 571 in epoch 2, gen_loss = 0.7988304700572174, disc_loss = 0.1030443115908835
Trained batch 572 in epoch 2, gen_loss = 0.7984063409489903, disc_loss = 0.10322226326828124
Trained batch 573 in epoch 2, gen_loss = 0.7984449480780326, disc_loss = 0.10316014117545055
Trained batch 574 in epoch 2, gen_loss = 0.7982910422138546, disc_loss = 0.10313759761336057
Trained batch 575 in epoch 2, gen_loss = 0.7982782579234077, disc_loss = 0.10305882358160387
Trained batch 576 in epoch 2, gen_loss = 0.7979193034886901, disc_loss = 0.10306507920074814
Trained batch 577 in epoch 2, gen_loss = 0.7980262841835979, disc_loss = 0.10300310557082966
Trained batch 578 in epoch 2, gen_loss = 0.7980086468353172, disc_loss = 0.10297593907075121
Trained batch 579 in epoch 2, gen_loss = 0.7979392613316404, disc_loss = 0.10285403281771417
Trained batch 580 in epoch 2, gen_loss = 0.7977343731513327, disc_loss = 0.10291204236370868
Trained batch 581 in epoch 2, gen_loss = 0.7978903972303745, disc_loss = 0.10282625808761395
Trained batch 582 in epoch 2, gen_loss = 0.7978232433926793, disc_loss = 0.10280279985486848
Trained batch 583 in epoch 2, gen_loss = 0.7981213185783118, disc_loss = 0.10273616166772602
Trained batch 584 in epoch 2, gen_loss = 0.7980228427638355, disc_loss = 0.10269522002428515
Trained batch 585 in epoch 2, gen_loss = 0.797694980843889, disc_loss = 0.10272972008893616
Trained batch 586 in epoch 2, gen_loss = 0.7977202586969281, disc_loss = 0.10262697244941985
Trained batch 587 in epoch 2, gen_loss = 0.7981803569765318, disc_loss = 0.10254588475780321
Trained batch 588 in epoch 2, gen_loss = 0.7987363877340974, disc_loss = 0.10248118832214073
Trained batch 589 in epoch 2, gen_loss = 0.7982408184621294, disc_loss = 0.10290333811446267
Trained batch 590 in epoch 2, gen_loss = 0.7987684352849744, disc_loss = 0.10289157935545831
Trained batch 591 in epoch 2, gen_loss = 0.7988012719496682, disc_loss = 0.10280160616919701
Trained batch 592 in epoch 2, gen_loss = 0.7984393521967464, disc_loss = 0.10275884422129664
Trained batch 593 in epoch 2, gen_loss = 0.799001490277072, disc_loss = 0.10265914499069806
Trained batch 594 in epoch 2, gen_loss = 0.798476754066323, disc_loss = 0.10270798527205191
Trained batch 595 in epoch 2, gen_loss = 0.7986437817847969, disc_loss = 0.10264583039816294
Trained batch 596 in epoch 2, gen_loss = 0.7984603724787184, disc_loss = 0.1025953487940819
Trained batch 597 in epoch 2, gen_loss = 0.7983411442376299, disc_loss = 0.10254358868099077
Trained batch 598 in epoch 2, gen_loss = 0.7987208568890624, disc_loss = 0.10239420363676419
Trained batch 599 in epoch 2, gen_loss = 0.7988655671974023, disc_loss = 0.10231643529143185
Trained batch 600 in epoch 2, gen_loss = 0.7985575802611828, disc_loss = 0.10230670878183276
Trained batch 601 in epoch 2, gen_loss = 0.7981564958527239, disc_loss = 0.1024199067398386
Trained batch 602 in epoch 2, gen_loss = 0.7984670346747978, disc_loss = 0.10255140566713429
Trained batch 603 in epoch 2, gen_loss = 0.7984972270020586, disc_loss = 0.10252130136590772
Trained batch 604 in epoch 2, gen_loss = 0.7981420130276483, disc_loss = 0.10259492317414727
Trained batch 605 in epoch 2, gen_loss = 0.7980397959845295, disc_loss = 0.1025624022321167
Trained batch 606 in epoch 2, gen_loss = 0.7982768884306095, disc_loss = 0.10253541763331833
Trained batch 607 in epoch 2, gen_loss = 0.7982917998084113, disc_loss = 0.10243050433162257
Trained batch 608 in epoch 2, gen_loss = 0.7984393006572974, disc_loss = 0.10233078085418258
Trained batch 609 in epoch 2, gen_loss = 0.7982893712696482, disc_loss = 0.10221186790951207
Trained batch 610 in epoch 2, gen_loss = 0.7982265952663609, disc_loss = 0.10219492611007341
Trained batch 611 in epoch 2, gen_loss = 0.7984153535338788, disc_loss = 0.10207050660582491
Trained batch 612 in epoch 2, gen_loss = 0.798126760110575, disc_loss = 0.10205896290362514
Trained batch 613 in epoch 2, gen_loss = 0.7986011372618256, disc_loss = 0.10206712893261922
Trained batch 614 in epoch 2, gen_loss = 0.7991648747184412, disc_loss = 0.10197038598873509
Trained batch 615 in epoch 2, gen_loss = 0.7987415948761748, disc_loss = 0.10205050261975447
Trained batch 616 in epoch 2, gen_loss = 0.7987780788825822, disc_loss = 0.10196085996786963
Trained batch 617 in epoch 2, gen_loss = 0.7985162057440643, disc_loss = 0.10195482562485973
Trained batch 618 in epoch 2, gen_loss = 0.7986144848613246, disc_loss = 0.1018854300559217
Trained batch 619 in epoch 2, gen_loss = 0.7986733756238414, disc_loss = 0.10179439572046602
Trained batch 620 in epoch 2, gen_loss = 0.7983071910106425, disc_loss = 0.10182625463685312
Trained batch 621 in epoch 2, gen_loss = 0.79842964107009, disc_loss = 0.10175656705010694
Trained batch 622 in epoch 2, gen_loss = 0.798568436508194, disc_loss = 0.10168025076215904
Trained batch 623 in epoch 2, gen_loss = 0.7987563579032818, disc_loss = 0.10163802170427516
Trained batch 624 in epoch 2, gen_loss = 0.7985558678150178, disc_loss = 0.10164715254753828
Trained batch 625 in epoch 2, gen_loss = 0.7982589009756478, disc_loss = 0.10162722642351978
Trained batch 626 in epoch 2, gen_loss = 0.7982482255645916, disc_loss = 0.10157285501624931
Trained batch 627 in epoch 2, gen_loss = 0.7985030520398906, disc_loss = 0.10153348569959925
Trained batch 628 in epoch 2, gen_loss = 0.7984918416114983, disc_loss = 0.1014750557500034
Trained batch 629 in epoch 2, gen_loss = 0.7989255422164523, disc_loss = 0.10143066567058365
Trained batch 630 in epoch 2, gen_loss = 0.798685091658364, disc_loss = 0.10149944374535569
Trained batch 631 in epoch 2, gen_loss = 0.7991065383429015, disc_loss = 0.10162597661690574
Trained batch 632 in epoch 2, gen_loss = 0.7989988689079858, disc_loss = 0.10153049953711495
Trained batch 633 in epoch 2, gen_loss = 0.7988618732156814, disc_loss = 0.10148088417048287
Trained batch 634 in epoch 2, gen_loss = 0.7987086106003739, disc_loss = 0.10151428775495197
Trained batch 635 in epoch 2, gen_loss = 0.7994238859358823, disc_loss = 0.10170971159823239
Trained batch 636 in epoch 2, gen_loss = 0.7994376018152132, disc_loss = 0.10163774989761729
Trained batch 637 in epoch 2, gen_loss = 0.7993658750688768, disc_loss = 0.10154652381082267
Trained batch 638 in epoch 2, gen_loss = 0.7991955705185265, disc_loss = 0.10165095516277917
Trained batch 639 in epoch 2, gen_loss = 0.7993871205952019, disc_loss = 0.1017994316338445
Trained batch 640 in epoch 2, gen_loss = 0.7995888354160856, disc_loss = 0.10166719742264604
Trained batch 641 in epoch 2, gen_loss = 0.7995369669711478, disc_loss = 0.10158340779577042
Trained batch 642 in epoch 2, gen_loss = 0.7993550066536359, disc_loss = 0.10163795197611417
Trained batch 643 in epoch 2, gen_loss = 0.8000533030547711, disc_loss = 0.10156398027504777
Trained batch 644 in epoch 2, gen_loss = 0.7996046479820281, disc_loss = 0.10163363464783097
Trained batch 645 in epoch 2, gen_loss = 0.7994207344464842, disc_loss = 0.10166564864472662
Trained batch 646 in epoch 2, gen_loss = 0.7991793614911518, disc_loss = 0.10174825832886848
Trained batch 647 in epoch 2, gen_loss = 0.7990389584483187, disc_loss = 0.10163933778739316
Trained batch 648 in epoch 2, gen_loss = 0.7990526501405038, disc_loss = 0.10152607875085437
Trained batch 649 in epoch 2, gen_loss = 0.7991710682557179, disc_loss = 0.1015292230148155
Trained batch 650 in epoch 2, gen_loss = 0.7990297702142537, disc_loss = 0.10144455562819213
Trained batch 651 in epoch 2, gen_loss = 0.7987902498592628, disc_loss = 0.10149377402906631
Trained batch 652 in epoch 2, gen_loss = 0.7990675865691069, disc_loss = 0.10169877462334372
Trained batch 653 in epoch 2, gen_loss = 0.7987816656857091, disc_loss = 0.10173311574521278
Trained batch 654 in epoch 2, gen_loss = 0.7991495196600906, disc_loss = 0.1016337770613209
Trained batch 655 in epoch 2, gen_loss = 0.7991495218309688, disc_loss = 0.10155618109132686
Trained batch 656 in epoch 2, gen_loss = 0.7988796101222481, disc_loss = 0.10165640950072528
Trained batch 657 in epoch 2, gen_loss = 0.7991878042014536, disc_loss = 0.10180200138313295
Trained batch 658 in epoch 2, gen_loss = 0.7993291028081376, disc_loss = 0.10170288678055152
Trained batch 659 in epoch 2, gen_loss = 0.7988499463959173, disc_loss = 0.10202806892409695
Trained batch 660 in epoch 2, gen_loss = 0.7985185653016355, disc_loss = 0.10203187830560191
Trained batch 661 in epoch 2, gen_loss = 0.7986143844995613, disc_loss = 0.10195865107452626
Trained batch 662 in epoch 2, gen_loss = 0.7986014852606513, disc_loss = 0.10191047364820587
Trained batch 663 in epoch 2, gen_loss = 0.7984056562095522, disc_loss = 0.1019165180188727
Trained batch 664 in epoch 2, gen_loss = 0.7984150190550582, disc_loss = 0.10193114499316404
Trained batch 665 in epoch 2, gen_loss = 0.7985848755360365, disc_loss = 0.10181248376660564
Trained batch 666 in epoch 2, gen_loss = 0.7985293093560517, disc_loss = 0.10176687266096764
Trained batch 667 in epoch 2, gen_loss = 0.7987768020547793, disc_loss = 0.10171286286200637
Trained batch 668 in epoch 2, gen_loss = 0.7989633490062793, disc_loss = 0.10158587292933723
Trained batch 669 in epoch 2, gen_loss = 0.7990673365432824, disc_loss = 0.10147312162165989
Trained batch 670 in epoch 2, gen_loss = 0.798825498620373, disc_loss = 0.101456271052838
Trained batch 671 in epoch 2, gen_loss = 0.7988858405234558, disc_loss = 0.10139953898171716
Trained batch 672 in epoch 2, gen_loss = 0.7993774022159746, disc_loss = 0.10143619163424042
Trained batch 673 in epoch 2, gen_loss = 0.7990889179158281, disc_loss = 0.10141162099924701
Trained batch 674 in epoch 2, gen_loss = 0.7990466422946365, disc_loss = 0.10137334934953186
Trained batch 675 in epoch 2, gen_loss = 0.7991414013258099, disc_loss = 0.10131876669774527
Trained batch 676 in epoch 2, gen_loss = 0.798916026399618, disc_loss = 0.1013098691343887
Trained batch 677 in epoch 2, gen_loss = 0.7988071274177163, disc_loss = 0.10131924231138333
Trained batch 678 in epoch 2, gen_loss = 0.7986355554285035, disc_loss = 0.10136475758448747
Trained batch 679 in epoch 2, gen_loss = 0.7985722259125289, disc_loss = 0.1014398114522919
Trained batch 680 in epoch 2, gen_loss = 0.7983912321877025, disc_loss = 0.10159658907438121
Trained batch 681 in epoch 2, gen_loss = 0.7979628911728034, disc_loss = 0.10193703486242733
Trained batch 682 in epoch 2, gen_loss = 0.798478416738538, disc_loss = 0.10231409967900151
Trained batch 683 in epoch 2, gen_loss = 0.7985597046756605, disc_loss = 0.10223612505043939
Trained batch 684 in epoch 2, gen_loss = 0.7984522986151006, disc_loss = 0.10232268597821902
Trained batch 685 in epoch 2, gen_loss = 0.7982167854861685, disc_loss = 0.10248041978247094
Trained batch 686 in epoch 2, gen_loss = 0.7986127847407062, disc_loss = 0.10260065587364907
Trained batch 687 in epoch 2, gen_loss = 0.7986164483306712, disc_loss = 0.10266074782838439
Trained batch 688 in epoch 2, gen_loss = 0.7983543103336422, disc_loss = 0.10271974115433774
Trained batch 689 in epoch 2, gen_loss = 0.7982664690069531, disc_loss = 0.10269380193338662
Trained batch 690 in epoch 2, gen_loss = 0.7983543582573296, disc_loss = 0.1026159765134133
Trained batch 691 in epoch 2, gen_loss = 0.7985039689723467, disc_loss = 0.10271390591952627
Trained batch 692 in epoch 2, gen_loss = 0.7981774160614261, disc_loss = 0.1027342744190434
Trained batch 693 in epoch 2, gen_loss = 0.7979482475464214, disc_loss = 0.10269788631052852
Trained batch 694 in epoch 2, gen_loss = 0.7982751447948621, disc_loss = 0.10267791807946326
Trained batch 695 in epoch 2, gen_loss = 0.7983415492906653, disc_loss = 0.10257652181270265
Trained batch 696 in epoch 2, gen_loss = 0.7985598018641451, disc_loss = 0.1025866581437043
Trained batch 697 in epoch 2, gen_loss = 0.7982510901710024, disc_loss = 0.10262583863166265
Trained batch 698 in epoch 2, gen_loss = 0.7982019207764082, disc_loss = 0.1025663887554292
Trained batch 699 in epoch 2, gen_loss = 0.7986519544039454, disc_loss = 0.10265301972494593
Trained batch 700 in epoch 2, gen_loss = 0.7988199161819997, disc_loss = 0.10257297416168468
Trained batch 701 in epoch 2, gen_loss = 0.7986936361616493, disc_loss = 0.10250968694490542
Trained batch 702 in epoch 2, gen_loss = 0.7985486429327752, disc_loss = 0.10247760959589591
Trained batch 703 in epoch 2, gen_loss = 0.7987820664844052, disc_loss = 0.10237007602832322
Trained batch 704 in epoch 2, gen_loss = 0.798838942566662, disc_loss = 0.10237005173182445
Trained batch 705 in epoch 2, gen_loss = 0.7988180894267458, disc_loss = 0.10228875855501034
Trained batch 706 in epoch 2, gen_loss = 0.7989085622268822, disc_loss = 0.10221543180844529
Trained batch 707 in epoch 2, gen_loss = 0.798972831144508, disc_loss = 0.10216650089885682
Trained batch 708 in epoch 2, gen_loss = 0.7988654511687786, disc_loss = 0.10213608900938913
Trained batch 709 in epoch 2, gen_loss = 0.7987918846623998, disc_loss = 0.10213741925479451
Trained batch 710 in epoch 2, gen_loss = 0.7986850308047401, disc_loss = 0.1020771819147191
Trained batch 711 in epoch 2, gen_loss = 0.7989548523020878, disc_loss = 0.1021675123202646
Trained batch 712 in epoch 2, gen_loss = 0.7989442338866573, disc_loss = 0.10211617477515093
Trained batch 713 in epoch 2, gen_loss = 0.7986533881819883, disc_loss = 0.10219393609905568
Trained batch 714 in epoch 2, gen_loss = 0.7989871616546924, disc_loss = 0.102154784622257
Trained batch 715 in epoch 2, gen_loss = 0.7989642394071851, disc_loss = 0.10209530220866495
Trained batch 716 in epoch 2, gen_loss = 0.7987513774525338, disc_loss = 0.10210438481450206
Trained batch 717 in epoch 2, gen_loss = 0.7988287200917773, disc_loss = 0.10207501300130672
Trained batch 718 in epoch 2, gen_loss = 0.7988598144850246, disc_loss = 0.10201253726306438
Trained batch 719 in epoch 2, gen_loss = 0.7987593350725042, disc_loss = 0.1019596319943149
Trained batch 720 in epoch 2, gen_loss = 0.7985807701469956, disc_loss = 0.10191132567290749
Trained batch 721 in epoch 2, gen_loss = 0.7987405101760933, disc_loss = 0.10190330019447735
Trained batch 722 in epoch 2, gen_loss = 0.7985975901038486, disc_loss = 0.10192590274746281
Trained batch 723 in epoch 2, gen_loss = 0.7984868049703909, disc_loss = 0.1018389494901842
Trained batch 724 in epoch 2, gen_loss = 0.7987191578026476, disc_loss = 0.1018383014189272
Trained batch 725 in epoch 2, gen_loss = 0.7985099025747993, disc_loss = 0.10183745580430324
Trained batch 726 in epoch 2, gen_loss = 0.7986479315911887, disc_loss = 0.10177996597717807
Trained batch 727 in epoch 2, gen_loss = 0.7986095263162157, disc_loss = 0.10181600904312231
Trained batch 728 in epoch 2, gen_loss = 0.7987143850702644, disc_loss = 0.10172175330752493
Trained batch 729 in epoch 2, gen_loss = 0.7985815651204488, disc_loss = 0.10169901588472398
Trained batch 730 in epoch 2, gen_loss = 0.7989589773760611, disc_loss = 0.10174338782407476
Trained batch 731 in epoch 2, gen_loss = 0.7989842108771449, disc_loss = 0.10164628557407913
Trained batch 732 in epoch 2, gen_loss = 0.7991345064132633, disc_loss = 0.10153793904035877
Trained batch 733 in epoch 2, gen_loss = 0.7989787536924476, disc_loss = 0.10149972285562746
Trained batch 734 in epoch 2, gen_loss = 0.7991145689876712, disc_loss = 0.10152482440707837
Trained batch 735 in epoch 2, gen_loss = 0.7990329393145182, disc_loss = 0.10152445891087511
Trained batch 736 in epoch 2, gen_loss = 0.7992093032137509, disc_loss = 0.10141818742097193
Trained batch 737 in epoch 2, gen_loss = 0.7994227685175614, disc_loss = 0.10135048710259036
Trained batch 738 in epoch 2, gen_loss = 0.7990487828064352, disc_loss = 0.10155647260758204
Trained batch 739 in epoch 2, gen_loss = 0.7994346689130809, disc_loss = 0.10165313985324591
Trained batch 740 in epoch 2, gen_loss = 0.7994486204123529, disc_loss = 0.10156900058758123
Trained batch 741 in epoch 2, gen_loss = 0.7993726918719849, disc_loss = 0.10148623192210925
Trained batch 742 in epoch 2, gen_loss = 0.7989132746071386, disc_loss = 0.10163107127437561
Trained batch 743 in epoch 2, gen_loss = 0.799011397586074, disc_loss = 0.10159809108427977
Trained batch 744 in epoch 2, gen_loss = 0.79898886808613, disc_loss = 0.10159665050247571
Trained batch 745 in epoch 2, gen_loss = 0.7988605660663534, disc_loss = 0.10154419589223435
Trained batch 746 in epoch 2, gen_loss = 0.7989437441270514, disc_loss = 0.10149154101075776
Trained batch 747 in epoch 2, gen_loss = 0.7994588572073748, disc_loss = 0.1015395416746185
Trained batch 748 in epoch 2, gen_loss = 0.7994867981833037, disc_loss = 0.10145563724884721
Trained batch 749 in epoch 2, gen_loss = 0.7993039806683858, disc_loss = 0.10142141733691096
Trained batch 750 in epoch 2, gen_loss = 0.7994907470581217, disc_loss = 0.10148017475636956
Trained batch 751 in epoch 2, gen_loss = 0.7992053796002205, disc_loss = 0.10151982979299104
Trained batch 752 in epoch 2, gen_loss = 0.7990457356213574, disc_loss = 0.10151816817596654
Trained batch 753 in epoch 2, gen_loss = 0.799284507409331, disc_loss = 0.10156317835980014
Trained batch 754 in epoch 2, gen_loss = 0.7993405067368059, disc_loss = 0.10146476755301091
Trained batch 755 in epoch 2, gen_loss = 0.7995650629517893, disc_loss = 0.10141272783875663
Trained batch 756 in epoch 2, gen_loss = 0.7992852177456159, disc_loss = 0.1015603100620161
Trained batch 757 in epoch 2, gen_loss = 0.7991268327336827, disc_loss = 0.10155238910138331
Trained batch 758 in epoch 2, gen_loss = 0.7993321356723116, disc_loss = 0.10165218635043805
Trained batch 759 in epoch 2, gen_loss = 0.7993009130421438, disc_loss = 0.10161264716328955
Trained batch 760 in epoch 2, gen_loss = 0.7990384064272105, disc_loss = 0.10161472955025957
Trained batch 761 in epoch 2, gen_loss = 0.7992109060287476, disc_loss = 0.10150479268786201
Trained batch 762 in epoch 2, gen_loss = 0.7996281963500876, disc_loss = 0.10140161251534524
Trained batch 763 in epoch 2, gen_loss = 0.799829741891142, disc_loss = 0.10132058803114007
Trained batch 764 in epoch 2, gen_loss = 0.7995801858652651, disc_loss = 0.10134184606543749
Trained batch 765 in epoch 2, gen_loss = 0.799714634063661, disc_loss = 0.10136346706352135
Trained batch 766 in epoch 2, gen_loss = 0.7996880361589335, disc_loss = 0.101511147904126
Trained batch 767 in epoch 2, gen_loss = 0.7995012692020586, disc_loss = 0.10163060461854911
Trained batch 768 in epoch 2, gen_loss = 0.8000731143436755, disc_loss = 0.10163994558441353
Trained batch 769 in epoch 2, gen_loss = 0.7998012758694686, disc_loss = 0.1016606169922108
Trained batch 770 in epoch 2, gen_loss = 0.7996095959314576, disc_loss = 0.10163968987642134
Trained batch 771 in epoch 2, gen_loss = 0.7996818294333671, disc_loss = 0.10166287573339138
Trained batch 772 in epoch 2, gen_loss = 0.7999230240017445, disc_loss = 0.10162130664831646
Trained batch 773 in epoch 2, gen_loss = 0.7995508283145668, disc_loss = 0.1017170059590935
Trained batch 774 in epoch 2, gen_loss = 0.7996409870732215, disc_loss = 0.10170225139226645
Trained batch 775 in epoch 2, gen_loss = 0.7996204808815238, disc_loss = 0.1016255382594854
Trained batch 776 in epoch 2, gen_loss = 0.7994990008217948, disc_loss = 0.10163708781149895
Trained batch 777 in epoch 2, gen_loss = 0.8000509904405452, disc_loss = 0.10157158707117706
Trained batch 778 in epoch 2, gen_loss = 0.7997848293594586, disc_loss = 0.10164908872168889
Trained batch 779 in epoch 2, gen_loss = 0.7999917401717259, disc_loss = 0.10157750162582557
Trained batch 780 in epoch 2, gen_loss = 0.8004271687985077, disc_loss = 0.1015117227632872
Trained batch 781 in epoch 2, gen_loss = 0.8001954727770423, disc_loss = 0.1015140782062755
Trained batch 782 in epoch 2, gen_loss = 0.8003042705671084, disc_loss = 0.10140935798195853
Trained batch 783 in epoch 2, gen_loss = 0.8004998712971503, disc_loss = 0.10134156701530386
Trained batch 784 in epoch 2, gen_loss = 0.800334016532655, disc_loss = 0.10126431720912646
Trained batch 785 in epoch 2, gen_loss = 0.8001955744571055, disc_loss = 0.1011909373832094
Trained batch 786 in epoch 2, gen_loss = 0.7999736208473409, disc_loss = 0.10112727146945998
Trained batch 787 in epoch 2, gen_loss = 0.8001972678954226, disc_loss = 0.10108722500895448
Trained batch 788 in epoch 2, gen_loss = 0.7999185063086535, disc_loss = 0.1011234203103283
Trained batch 789 in epoch 2, gen_loss = 0.7997240746323067, disc_loss = 0.10109980942304188
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.7830385565757751, disc_loss = 0.051384780555963516
Trained batch 1 in epoch 3, gen_loss = 0.8539171516895294, disc_loss = 0.10036757029592991
Trained batch 2 in epoch 3, gen_loss = 0.7491893768310547, disc_loss = 0.10902474944790204
Trained batch 3 in epoch 3, gen_loss = 0.7664907276630402, disc_loss = 0.09698876459151506
Trained batch 4 in epoch 3, gen_loss = 0.7731625437736511, disc_loss = 0.08741347715258599
Trained batch 5 in epoch 3, gen_loss = 0.7675670981407166, disc_loss = 0.08932277001440525
Trained batch 6 in epoch 3, gen_loss = 0.7516410521098545, disc_loss = 0.08927581512502261
Trained batch 7 in epoch 3, gen_loss = 0.7807395607233047, disc_loss = 0.09024697868153453
Trained batch 8 in epoch 3, gen_loss = 0.779425753487481, disc_loss = 0.0847225437561671
Trained batch 9 in epoch 3, gen_loss = 0.7798292100429535, disc_loss = 0.0811254058033228
Trained batch 10 in epoch 3, gen_loss = 0.7768491344018416, disc_loss = 0.08296539532867345
Trained batch 11 in epoch 3, gen_loss = 0.7795637200276057, disc_loss = 0.08260034987082084
Trained batch 12 in epoch 3, gen_loss = 0.7913534778815049, disc_loss = 0.08316599377072774
Trained batch 13 in epoch 3, gen_loss = 0.8051924066884177, disc_loss = 0.07844750849264008
Trained batch 14 in epoch 3, gen_loss = 0.7980220476786296, disc_loss = 0.08199831893046697
Trained batch 15 in epoch 3, gen_loss = 0.8087139427661896, disc_loss = 0.07946850429289043
Trained batch 16 in epoch 3, gen_loss = 0.815598421237048, disc_loss = 0.07998209643889875
Trained batch 17 in epoch 3, gen_loss = 0.8167706827322642, disc_loss = 0.07650857294599216
Trained batch 18 in epoch 3, gen_loss = 0.8176129021142658, disc_loss = 0.07495768427064545
Trained batch 19 in epoch 3, gen_loss = 0.8149516701698303, disc_loss = 0.073519173450768
Trained batch 20 in epoch 3, gen_loss = 0.8304274820146107, disc_loss = 0.07288967179400581
Trained batch 21 in epoch 3, gen_loss = 0.8196781440214678, disc_loss = 0.0727956047789617
Trained batch 22 in epoch 3, gen_loss = 0.818143948264744, disc_loss = 0.07038937322795391
Trained batch 23 in epoch 3, gen_loss = 0.8263211200634638, disc_loss = 0.06994856715512772
Trained batch 24 in epoch 3, gen_loss = 0.8173341870307922, disc_loss = 0.07216254241764546
Trained batch 25 in epoch 3, gen_loss = 0.8149025348516611, disc_loss = 0.07326857466250658
Trained batch 26 in epoch 3, gen_loss = 0.8211684867187783, disc_loss = 0.07171317734928043
Trained batch 27 in epoch 3, gen_loss = 0.8194715891565595, disc_loss = 0.07076304851632033
Trained batch 28 in epoch 3, gen_loss = 0.8122735455118376, disc_loss = 0.0736715317671669
Trained batch 29 in epoch 3, gen_loss = 0.8243615806102753, disc_loss = 0.079295250462989
Trained batch 30 in epoch 3, gen_loss = 0.8313526972647636, disc_loss = 0.07762864736780044
Trained batch 31 in epoch 3, gen_loss = 0.8202514704316854, disc_loss = 0.0803379041608423
Trained batch 32 in epoch 3, gen_loss = 0.8166799129861774, disc_loss = 0.07901808529189139
Trained batch 33 in epoch 3, gen_loss = 0.8176777468008154, disc_loss = 0.08117387180819231
Trained batch 34 in epoch 3, gen_loss = 0.8182993071419852, disc_loss = 0.07979255105767931
Trained batch 35 in epoch 3, gen_loss = 0.8191297468211916, disc_loss = 0.08084919427831967
Trained batch 36 in epoch 3, gen_loss = 0.814699248687641, disc_loss = 0.08102335660038767
Trained batch 37 in epoch 3, gen_loss = 0.8082265226464522, disc_loss = 0.08506114996577564
Trained batch 38 in epoch 3, gen_loss = 0.8052150897490673, disc_loss = 0.08455362361975205
Trained batch 39 in epoch 3, gen_loss = 0.8111739844083786, disc_loss = 0.08865182679146529
Trained batch 40 in epoch 3, gen_loss = 0.8159635852022868, disc_loss = 0.0873737884912549
Trained batch 41 in epoch 3, gen_loss = 0.811731409458887, disc_loss = 0.08963943778404168
Trained batch 42 in epoch 3, gen_loss = 0.8140989417253539, disc_loss = 0.08816563927156981
Trained batch 43 in epoch 3, gen_loss = 0.8226297890598123, disc_loss = 0.08718069515783679
Trained batch 44 in epoch 3, gen_loss = 0.8199248009257847, disc_loss = 0.08657123984562026
Trained batch 45 in epoch 3, gen_loss = 0.819033180889876, disc_loss = 0.0858827379896589
Trained batch 46 in epoch 3, gen_loss = 0.8184897062626291, disc_loss = 0.0845735177714774
Trained batch 47 in epoch 3, gen_loss = 0.8161495712896188, disc_loss = 0.08417618228122592
Trained batch 48 in epoch 3, gen_loss = 0.8192083215226933, disc_loss = 0.08331707074325911
Trained batch 49 in epoch 3, gen_loss = 0.8151840639114379, disc_loss = 0.08346914380788803
Trained batch 50 in epoch 3, gen_loss = 0.8141549638673371, disc_loss = 0.08363321029088076
Trained batch 51 in epoch 3, gen_loss = 0.8137097931825198, disc_loss = 0.08321099857298228
Trained batch 52 in epoch 3, gen_loss = 0.8124907444108207, disc_loss = 0.0840191735692744
Trained batch 53 in epoch 3, gen_loss = 0.8106489291897526, disc_loss = 0.08337092027068138
Trained batch 54 in epoch 3, gen_loss = 0.8085738518021324, disc_loss = 0.08303832601417195
Trained batch 55 in epoch 3, gen_loss = 0.8083628597004073, disc_loss = 0.0827818705833384
Trained batch 56 in epoch 3, gen_loss = 0.8100564845821314, disc_loss = 0.08240712126880362
Trained batch 57 in epoch 3, gen_loss = 0.8101148368983433, disc_loss = 0.08198541049556486
Trained batch 58 in epoch 3, gen_loss = 0.8081608687416982, disc_loss = 0.08170687009469937
Trained batch 59 in epoch 3, gen_loss = 0.8122924387454986, disc_loss = 0.08150431892524163
Trained batch 60 in epoch 3, gen_loss = 0.8091321050143633, disc_loss = 0.08181672146330114
Trained batch 61 in epoch 3, gen_loss = 0.80847176044218, disc_loss = 0.08087338555243707
Trained batch 62 in epoch 3, gen_loss = 0.8188954497140551, disc_loss = 0.0849045477216206
Trained batch 63 in epoch 3, gen_loss = 0.8195924814790487, disc_loss = 0.08406865422148257
Trained batch 64 in epoch 3, gen_loss = 0.8153967233804557, disc_loss = 0.08510120728841195
Trained batch 65 in epoch 3, gen_loss = 0.8195179610541372, disc_loss = 0.08843535760586912
Trained batch 66 in epoch 3, gen_loss = 0.8166952239933298, disc_loss = 0.0884726960489999
Trained batch 67 in epoch 3, gen_loss = 0.8116825240499833, disc_loss = 0.09045515461441349
Trained batch 68 in epoch 3, gen_loss = 0.811968427637349, disc_loss = 0.09009715957918028
Trained batch 69 in epoch 3, gen_loss = 0.8131099164485931, disc_loss = 0.09182569235563279
Trained batch 70 in epoch 3, gen_loss = 0.8093258948393272, disc_loss = 0.09370012287522705
Trained batch 71 in epoch 3, gen_loss = 0.81043681419558, disc_loss = 0.09290560904062456
Trained batch 72 in epoch 3, gen_loss = 0.8091418685978407, disc_loss = 0.09265751820312787
Trained batch 73 in epoch 3, gen_loss = 0.8093072522330929, disc_loss = 0.0930326745115422
Trained batch 74 in epoch 3, gen_loss = 0.8077436606089274, disc_loss = 0.09320497790972392
Trained batch 75 in epoch 3, gen_loss = 0.8064307295962384, disc_loss = 0.09293450621005736
Trained batch 76 in epoch 3, gen_loss = 0.8080283867848383, disc_loss = 0.09261826067775875
Trained batch 77 in epoch 3, gen_loss = 0.8094903154250903, disc_loss = 0.09201632779187117
Trained batch 78 in epoch 3, gen_loss = 0.8098038155821305, disc_loss = 0.09099779083523192
Trained batch 79 in epoch 3, gen_loss = 0.8120864868164063, disc_loss = 0.09008649348979816
Trained batch 80 in epoch 3, gen_loss = 0.8112905930589747, disc_loss = 0.08955193185649904
Trained batch 81 in epoch 3, gen_loss = 0.808262454300392, disc_loss = 0.09027536044169854
Trained batch 82 in epoch 3, gen_loss = 0.8100302980606815, disc_loss = 0.09047147536268794
Trained batch 83 in epoch 3, gen_loss = 0.8160556639943805, disc_loss = 0.09080688046690609
Trained batch 84 in epoch 3, gen_loss = 0.8143342382767621, disc_loss = 0.09123014732099631
Trained batch 85 in epoch 3, gen_loss = 0.8121361094851827, disc_loss = 0.09176357864770432
Trained batch 86 in epoch 3, gen_loss = 0.8164286065375668, disc_loss = 0.09200815071790726
Trained batch 87 in epoch 3, gen_loss = 0.816559074954553, disc_loss = 0.09153906707863578
Trained batch 88 in epoch 3, gen_loss = 0.8156482383106531, disc_loss = 0.09106297090942606
Trained batch 89 in epoch 3, gen_loss = 0.813571404086219, disc_loss = 0.09115300388592813
Trained batch 90 in epoch 3, gen_loss = 0.8133661792828486, disc_loss = 0.090442551801411
Trained batch 91 in epoch 3, gen_loss = 0.815976069673248, disc_loss = 0.09163092314670591
Trained batch 92 in epoch 3, gen_loss = 0.8138176837275105, disc_loss = 0.09191819772084234
Trained batch 93 in epoch 3, gen_loss = 0.8114941792285189, disc_loss = 0.09314987922404358
Trained batch 94 in epoch 3, gen_loss = 0.8138603750028108, disc_loss = 0.09416204584076217
Trained batch 95 in epoch 3, gen_loss = 0.8150360751897097, disc_loss = 0.09436883625069943
Trained batch 96 in epoch 3, gen_loss = 0.8144968348680083, disc_loss = 0.0937106706413258
Trained batch 97 in epoch 3, gen_loss = 0.8130474905578458, disc_loss = 0.09323435720550466
Trained batch 98 in epoch 3, gen_loss = 0.8129522607784079, disc_loss = 0.09292127179790928
Trained batch 99 in epoch 3, gen_loss = 0.8120179665088654, disc_loss = 0.09276754560880363
Trained batch 100 in epoch 3, gen_loss = 0.8128578645167964, disc_loss = 0.09237496351067087
Trained batch 101 in epoch 3, gen_loss = 0.8173554300093183, disc_loss = 0.09187608437758743
Trained batch 102 in epoch 3, gen_loss = 0.8186826318213083, disc_loss = 0.0911003164133256
Trained batch 103 in epoch 3, gen_loss = 0.8179842136227168, disc_loss = 0.0908176737318102
Trained batch 104 in epoch 3, gen_loss = 0.8194037602061317, disc_loss = 0.0901304212265781
Trained batch 105 in epoch 3, gen_loss = 0.8189603804417376, disc_loss = 0.08968979558679012
Trained batch 106 in epoch 3, gen_loss = 0.8201888693827335, disc_loss = 0.08895816954253154
Trained batch 107 in epoch 3, gen_loss = 0.8216380289307347, disc_loss = 0.08829858318764579
Trained batch 108 in epoch 3, gen_loss = 0.8196264035111174, disc_loss = 0.0884318895074069
Trained batch 109 in epoch 3, gen_loss = 0.8208475140008059, disc_loss = 0.0885272715494714
Trained batch 110 in epoch 3, gen_loss = 0.8198188264090736, disc_loss = 0.08811469700791545
Trained batch 111 in epoch 3, gen_loss = 0.819801890956504, disc_loss = 0.08750830855985571
Trained batch 112 in epoch 3, gen_loss = 0.819605496077411, disc_loss = 0.0872607819851389
Trained batch 113 in epoch 3, gen_loss = 0.8217261977363051, disc_loss = 0.08662740791445239
Trained batch 114 in epoch 3, gen_loss = 0.8231596962265346, disc_loss = 0.0859770343841418
Trained batch 115 in epoch 3, gen_loss = 0.8244837173100176, disc_loss = 0.085564358400759
Trained batch 116 in epoch 3, gen_loss = 0.824700614835462, disc_loss = 0.08511578299614608
Trained batch 117 in epoch 3, gen_loss = 0.8266754842410653, disc_loss = 0.08556612304774887
Trained batch 118 in epoch 3, gen_loss = 0.8243068837318099, disc_loss = 0.08589095855523057
Trained batch 119 in epoch 3, gen_loss = 0.824027843773365, disc_loss = 0.08592048351032039
Trained batch 120 in epoch 3, gen_loss = 0.8239672405660645, disc_loss = 0.08534626156276415
Trained batch 121 in epoch 3, gen_loss = 0.8232624516135356, disc_loss = 0.08536054143590517
Trained batch 122 in epoch 3, gen_loss = 0.8224362779438981, disc_loss = 0.08541307578665938
Trained batch 123 in epoch 3, gen_loss = 0.821447505585609, disc_loss = 0.08594061492852145
Trained batch 124 in epoch 3, gen_loss = 0.8196427502632141, disc_loss = 0.08615414832532406
Trained batch 125 in epoch 3, gen_loss = 0.8187397193341028, disc_loss = 0.08588672064185615
Trained batch 126 in epoch 3, gen_loss = 0.8195953326901113, disc_loss = 0.08587204396548703
Trained batch 127 in epoch 3, gen_loss = 0.8180097755976021, disc_loss = 0.08620614600658882
Trained batch 128 in epoch 3, gen_loss = 0.8181465545365977, disc_loss = 0.08614713284223116
Trained batch 129 in epoch 3, gen_loss = 0.8183436315793258, disc_loss = 0.08586438669321629
Trained batch 130 in epoch 3, gen_loss = 0.8179483340896723, disc_loss = 0.08594698793048622
Trained batch 131 in epoch 3, gen_loss = 0.81862790295572, disc_loss = 0.0855786822256491
Trained batch 132 in epoch 3, gen_loss = 0.8185812763701704, disc_loss = 0.08529068102457918
Trained batch 133 in epoch 3, gen_loss = 0.818323866644902, disc_loss = 0.08553103923297195
Trained batch 134 in epoch 3, gen_loss = 0.8180767297744751, disc_loss = 0.08528178857156524
Trained batch 135 in epoch 3, gen_loss = 0.8171109969125074, disc_loss = 0.08531278836102608
Trained batch 136 in epoch 3, gen_loss = 0.815617040125993, disc_loss = 0.08542092844680713
Trained batch 137 in epoch 3, gen_loss = 0.8198757456696552, disc_loss = 0.08664348002091266
Trained batch 138 in epoch 3, gen_loss = 0.8180852892587511, disc_loss = 0.08678130455743924
Trained batch 139 in epoch 3, gen_loss = 0.8165453565972192, disc_loss = 0.08692581524540272
Trained batch 140 in epoch 3, gen_loss = 0.8160272832457901, disc_loss = 0.08687895270896719
Trained batch 141 in epoch 3, gen_loss = 0.8164513644198297, disc_loss = 0.08773986553169892
Trained batch 142 in epoch 3, gen_loss = 0.8164135505269458, disc_loss = 0.0877882735478086
Trained batch 143 in epoch 3, gen_loss = 0.814564095189174, disc_loss = 0.08784279960673302
Trained batch 144 in epoch 3, gen_loss = 0.8163359835230071, disc_loss = 0.08793453778429278
Trained batch 145 in epoch 3, gen_loss = 0.8148513824155886, disc_loss = 0.08838803268815965
Trained batch 146 in epoch 3, gen_loss = 0.814869989343241, disc_loss = 0.08798074684276873
Trained batch 147 in epoch 3, gen_loss = 0.8142969890220745, disc_loss = 0.08758446284745997
Trained batch 148 in epoch 3, gen_loss = 0.8132918393051864, disc_loss = 0.0874581429732326
Trained batch 149 in epoch 3, gen_loss = 0.813530596892039, disc_loss = 0.0879408465574185
Trained batch 150 in epoch 3, gen_loss = 0.8134711518982388, disc_loss = 0.08762116207192276
Trained batch 151 in epoch 3, gen_loss = 0.8121172299510554, disc_loss = 0.08790174283479389
Trained batch 152 in epoch 3, gen_loss = 0.8122490309422312, disc_loss = 0.08754092338038426
Trained batch 153 in epoch 3, gen_loss = 0.8118432551235347, disc_loss = 0.08729428897140087
Trained batch 154 in epoch 3, gen_loss = 0.8116091589773855, disc_loss = 0.08736039974516438
Trained batch 155 in epoch 3, gen_loss = 0.8096896826456754, disc_loss = 0.08783113466910063
Trained batch 156 in epoch 3, gen_loss = 0.8093080034681187, disc_loss = 0.08824583572471977
Trained batch 157 in epoch 3, gen_loss = 0.8083192132696321, disc_loss = 0.08824156816530077
Trained batch 158 in epoch 3, gen_loss = 0.8109042846931601, disc_loss = 0.08921735136295264
Trained batch 159 in epoch 3, gen_loss = 0.8094518188387155, disc_loss = 0.08945655615534634
Trained batch 160 in epoch 3, gen_loss = 0.80870181766356, disc_loss = 0.08938986097711214
Trained batch 161 in epoch 3, gen_loss = 0.8086113933427834, disc_loss = 0.08905581350403803
Trained batch 162 in epoch 3, gen_loss = 0.8096957663816908, disc_loss = 0.08919326140562449
Trained batch 163 in epoch 3, gen_loss = 0.8080889524483099, disc_loss = 0.0893079628259307
Trained batch 164 in epoch 3, gen_loss = 0.807250959222967, disc_loss = 0.08939897325454337
Trained batch 165 in epoch 3, gen_loss = 0.8086443004837955, disc_loss = 0.08937512479542968
Trained batch 166 in epoch 3, gen_loss = 0.8082189841898616, disc_loss = 0.08925095921058855
Trained batch 167 in epoch 3, gen_loss = 0.808801266409102, disc_loss = 0.08887437788680905
Trained batch 168 in epoch 3, gen_loss = 0.8087123720603582, disc_loss = 0.08903346140180114
Trained batch 169 in epoch 3, gen_loss = 0.8081313536447637, disc_loss = 0.08916854350005879
Trained batch 170 in epoch 3, gen_loss = 0.8082039000695211, disc_loss = 0.08916356288201628
Trained batch 171 in epoch 3, gen_loss = 0.8087585786747378, disc_loss = 0.08881417291542125
Trained batch 172 in epoch 3, gen_loss = 0.8104095179910604, disc_loss = 0.08863397771654101
Trained batch 173 in epoch 3, gen_loss = 0.8103530821443974, disc_loss = 0.08841246235901597
Trained batch 174 in epoch 3, gen_loss = 0.8107897594996861, disc_loss = 0.08816428650702748
Trained batch 175 in epoch 3, gen_loss = 0.8130774552171881, disc_loss = 0.0884466848378493
Trained batch 176 in epoch 3, gen_loss = 0.8116407259709417, disc_loss = 0.0886795472585212
Trained batch 177 in epoch 3, gen_loss = 0.8113488467891564, disc_loss = 0.08876519798813912
Trained batch 178 in epoch 3, gen_loss = 0.8131681927089585, disc_loss = 0.09076533859918237
Trained batch 179 in epoch 3, gen_loss = 0.8128326495488485, disc_loss = 0.09071362128274309
Trained batch 180 in epoch 3, gen_loss = 0.8120752075759087, disc_loss = 0.09069700154234032
Trained batch 181 in epoch 3, gen_loss = 0.8112944472622086, disc_loss = 0.0907385472290136
Trained batch 182 in epoch 3, gen_loss = 0.8123320617962405, disc_loss = 0.09103054396523153
Trained batch 183 in epoch 3, gen_loss = 0.8123044096257376, disc_loss = 0.09090791073749246
Trained batch 184 in epoch 3, gen_loss = 0.811855708586203, disc_loss = 0.09057555478569623
Trained batch 185 in epoch 3, gen_loss = 0.8127435067648529, disc_loss = 0.09018707321456043
Trained batch 186 in epoch 3, gen_loss = 0.8135626223635546, disc_loss = 0.08981785659284834
Trained batch 187 in epoch 3, gen_loss = 0.8139317286141375, disc_loss = 0.08956369592193911
Trained batch 188 in epoch 3, gen_loss = 0.8137939023593116, disc_loss = 0.08927568295605914
Trained batch 189 in epoch 3, gen_loss = 0.8140750254455366, disc_loss = 0.08913244731528194
Trained batch 190 in epoch 3, gen_loss = 0.8167036387932862, disc_loss = 0.0890353319786138
Trained batch 191 in epoch 3, gen_loss = 0.8153089371820291, disc_loss = 0.08928408808424138
Trained batch 192 in epoch 3, gen_loss = 0.8155300960021933, disc_loss = 0.08898224358306957
Trained batch 193 in epoch 3, gen_loss = 0.8162710915521249, disc_loss = 0.08866765827286183
Trained batch 194 in epoch 3, gen_loss = 0.816802526742984, disc_loss = 0.08843043562120352
Trained batch 195 in epoch 3, gen_loss = 0.8179422464905953, disc_loss = 0.08804798814734179
Trained batch 196 in epoch 3, gen_loss = 0.8176584370850306, disc_loss = 0.08774563684813716
Trained batch 197 in epoch 3, gen_loss = 0.8184080202170093, disc_loss = 0.0876011272487842
Trained batch 198 in epoch 3, gen_loss = 0.817695386445702, disc_loss = 0.0875888120654465
Trained batch 199 in epoch 3, gen_loss = 0.8190903341770173, disc_loss = 0.08768805255647749
Trained batch 200 in epoch 3, gen_loss = 0.8198299235965482, disc_loss = 0.08738522352511759
Trained batch 201 in epoch 3, gen_loss = 0.8196375662147408, disc_loss = 0.08709003347073599
Trained batch 202 in epoch 3, gen_loss = 0.8201385809870189, disc_loss = 0.08680429686264599
Trained batch 203 in epoch 3, gen_loss = 0.8205624997031455, disc_loss = 0.08650356441206646
Trained batch 204 in epoch 3, gen_loss = 0.8204530509506783, disc_loss = 0.08637787900955939
Trained batch 205 in epoch 3, gen_loss = 0.8202768520822803, disc_loss = 0.08627244339604835
Trained batch 206 in epoch 3, gen_loss = 0.820886782977892, disc_loss = 0.08613327769607594
Trained batch 207 in epoch 3, gen_loss = 0.820519298601609, disc_loss = 0.08603830884049575
Trained batch 208 in epoch 3, gen_loss = 0.8203607965884596, disc_loss = 0.08606269596919916
Trained batch 209 in epoch 3, gen_loss = 0.8210847567944299, disc_loss = 0.08592723025718615
Trained batch 210 in epoch 3, gen_loss = 0.8216494183404751, disc_loss = 0.08560896463144871
Trained batch 211 in epoch 3, gen_loss = 0.8211074642977625, disc_loss = 0.08552387113823502
Trained batch 212 in epoch 3, gen_loss = 0.8217667383207402, disc_loss = 0.0855273090504075
Trained batch 213 in epoch 3, gen_loss = 0.8219705778304661, disc_loss = 0.08530159711959624
Trained batch 214 in epoch 3, gen_loss = 0.8217789738677269, disc_loss = 0.08506051045084416
Trained batch 215 in epoch 3, gen_loss = 0.8219238856324443, disc_loss = 0.08499807670833198
Trained batch 216 in epoch 3, gen_loss = 0.820607986318351, disc_loss = 0.08507007936848336
Trained batch 217 in epoch 3, gen_loss = 0.8210556069645313, disc_loss = 0.08491638121237859
Trained batch 218 in epoch 3, gen_loss = 0.8214155715894481, disc_loss = 0.08462826187667101
Trained batch 219 in epoch 3, gen_loss = 0.8222709268331527, disc_loss = 0.08432289690033279
Trained batch 220 in epoch 3, gen_loss = 0.8240690341901995, disc_loss = 0.08442913524688504
Trained batch 221 in epoch 3, gen_loss = 0.8237862578920416, disc_loss = 0.08414785434315736
Trained batch 222 in epoch 3, gen_loss = 0.822194917987815, disc_loss = 0.08565341107831274
Trained batch 223 in epoch 3, gen_loss = 0.8240624949602144, disc_loss = 0.08548334719463517
Trained batch 224 in epoch 3, gen_loss = 0.8255138944254982, disc_loss = 0.08633215930312872
Trained batch 225 in epoch 3, gen_loss = 0.8250735181886538, disc_loss = 0.0860781387788598
Trained batch 226 in epoch 3, gen_loss = 0.824061448747366, disc_loss = 0.0866576675120495
Trained batch 227 in epoch 3, gen_loss = 0.8241275592069877, disc_loss = 0.0863894632845921
Trained batch 228 in epoch 3, gen_loss = 0.8251113471245661, disc_loss = 0.08642602505723591
Trained batch 229 in epoch 3, gen_loss = 0.8252905694038971, disc_loss = 0.08616704156460321
Trained batch 230 in epoch 3, gen_loss = 0.8260142363253093, disc_loss = 0.08587500249394478
Trained batch 231 in epoch 3, gen_loss = 0.8261245790997456, disc_loss = 0.08562684115744999
Trained batch 232 in epoch 3, gen_loss = 0.8262196335413937, disc_loss = 0.08549490072584587
Trained batch 233 in epoch 3, gen_loss = 0.8258363694971443, disc_loss = 0.08529119544192894
Trained batch 234 in epoch 3, gen_loss = 0.826098787657758, disc_loss = 0.08543671706017662
Trained batch 235 in epoch 3, gen_loss = 0.8264083419058282, disc_loss = 0.08550158020314146
Trained batch 236 in epoch 3, gen_loss = 0.8251692671564561, disc_loss = 0.08619821741626861
Trained batch 237 in epoch 3, gen_loss = 0.8271016910546968, disc_loss = 0.08646707321681521
Trained batch 238 in epoch 3, gen_loss = 0.8274113045826118, disc_loss = 0.08634129823204988
Trained batch 239 in epoch 3, gen_loss = 0.8267507830013832, disc_loss = 0.08633220048698907
Trained batch 240 in epoch 3, gen_loss = 0.8262405463521412, disc_loss = 0.08626186113835493
Trained batch 241 in epoch 3, gen_loss = 0.8252563551684057, disc_loss = 0.0862398860198715
Trained batch 242 in epoch 3, gen_loss = 0.8247518624052589, disc_loss = 0.08616583771743033
Trained batch 243 in epoch 3, gen_loss = 0.8256659787453589, disc_loss = 0.08591371442221837
Trained batch 244 in epoch 3, gen_loss = 0.8261257496415352, disc_loss = 0.08563450488584991
Trained batch 245 in epoch 3, gen_loss = 0.8260965850052795, disc_loss = 0.08569402700835248
Trained batch 246 in epoch 3, gen_loss = 0.8250469460419798, disc_loss = 0.08574839550549322
Trained batch 247 in epoch 3, gen_loss = 0.8250127923825095, disc_loss = 0.0855893183447
Trained batch 248 in epoch 3, gen_loss = 0.8243156196362522, disc_loss = 0.08570193947034788
Trained batch 249 in epoch 3, gen_loss = 0.8244724987745286, disc_loss = 0.08552176605537534
Trained batch 250 in epoch 3, gen_loss = 0.8240064975037518, disc_loss = 0.08558236192021355
Trained batch 251 in epoch 3, gen_loss = 0.8250277391265309, disc_loss = 0.08549042003569267
Trained batch 252 in epoch 3, gen_loss = 0.8254838299609927, disc_loss = 0.08526814193372788
Trained batch 253 in epoch 3, gen_loss = 0.825307495364054, disc_loss = 0.08536107243060714
Trained batch 254 in epoch 3, gen_loss = 0.8244767599246081, disc_loss = 0.08547404905525492
Trained batch 255 in epoch 3, gen_loss = 0.8257609697757289, disc_loss = 0.08568402036689804
Trained batch 256 in epoch 3, gen_loss = 0.8255392290970694, disc_loss = 0.08563724896917663
Trained batch 257 in epoch 3, gen_loss = 0.8248351485461227, disc_loss = 0.08562001568994435
Trained batch 258 in epoch 3, gen_loss = 0.8254832136354852, disc_loss = 0.0853915518926435
Trained batch 259 in epoch 3, gen_loss = 0.8253183705302385, disc_loss = 0.08524572047261665
Trained batch 260 in epoch 3, gen_loss = 0.8254072167179137, disc_loss = 0.08508997984672986
Trained batch 261 in epoch 3, gen_loss = 0.8256885965589349, disc_loss = 0.08497844443421897
Trained batch 262 in epoch 3, gen_loss = 0.826427630711871, disc_loss = 0.08475279906842532
Trained batch 263 in epoch 3, gen_loss = 0.8256445207604857, disc_loss = 0.08482554413477016
Trained batch 264 in epoch 3, gen_loss = 0.8264535374236557, disc_loss = 0.08479276473440651
Trained batch 265 in epoch 3, gen_loss = 0.8272243004320259, disc_loss = 0.08454095541072407
Trained batch 266 in epoch 3, gen_loss = 0.8273349081755578, disc_loss = 0.08426271502123901
Trained batch 267 in epoch 3, gen_loss = 0.8274137347714224, disc_loss = 0.08402577049877327
Trained batch 268 in epoch 3, gen_loss = 0.8265902507482408, disc_loss = 0.08411242521011364
Trained batch 269 in epoch 3, gen_loss = 0.8272023703213092, disc_loss = 0.08404054657245676
Trained batch 270 in epoch 3, gen_loss = 0.828490011696446, disc_loss = 0.08408112000893952
Trained batch 271 in epoch 3, gen_loss = 0.8276821774814058, disc_loss = 0.08412673717761851
Trained batch 272 in epoch 3, gen_loss = 0.8270147871840131, disc_loss = 0.08442080178171833
Trained batch 273 in epoch 3, gen_loss = 0.8275744609371589, disc_loss = 0.08463383747781389
Trained batch 274 in epoch 3, gen_loss = 0.8276664771816947, disc_loss = 0.08447007660500028
Trained batch 275 in epoch 3, gen_loss = 0.8272044368196225, disc_loss = 0.08432443418702029
Trained batch 276 in epoch 3, gen_loss = 0.8269599106983158, disc_loss = 0.08418621612706016
Trained batch 277 in epoch 3, gen_loss = 0.8271584479714469, disc_loss = 0.08397608281535318
Trained batch 278 in epoch 3, gen_loss = 0.828282378800881, disc_loss = 0.08374813159320196
Trained batch 279 in epoch 3, gen_loss = 0.8283020259014198, disc_loss = 0.08353573625042503
Trained batch 280 in epoch 3, gen_loss = 0.8277134293975354, disc_loss = 0.08375529450069437
Trained batch 281 in epoch 3, gen_loss = 0.8290122300386429, disc_loss = 0.08485492163978464
Trained batch 282 in epoch 3, gen_loss = 0.8288988474190446, disc_loss = 0.08469976558162445
Trained batch 283 in epoch 3, gen_loss = 0.8277918598811391, disc_loss = 0.0850528598218684
Trained batch 284 in epoch 3, gen_loss = 0.8276686441480068, disc_loss = 0.08506403967672796
Trained batch 285 in epoch 3, gen_loss = 0.8282662370613405, disc_loss = 0.08542090304964385
Trained batch 286 in epoch 3, gen_loss = 0.8284592745819158, disc_loss = 0.08531339239095458
Trained batch 287 in epoch 3, gen_loss = 0.8275627958484821, disc_loss = 0.08567697830019622
Trained batch 288 in epoch 3, gen_loss = 0.827736312233453, disc_loss = 0.08557502361768567
Trained batch 289 in epoch 3, gen_loss = 0.8281163087178921, disc_loss = 0.08563520490545137
Trained batch 290 in epoch 3, gen_loss = 0.8274720349057844, disc_loss = 0.08578718014227874
Trained batch 291 in epoch 3, gen_loss = 0.8269089373619589, disc_loss = 0.08588575039454417
Trained batch 292 in epoch 3, gen_loss = 0.8270212195228798, disc_loss = 0.08579850500392323
Trained batch 293 in epoch 3, gen_loss = 0.8273605871565488, disc_loss = 0.08565291271665368
Trained batch 294 in epoch 3, gen_loss = 0.8276723131284875, disc_loss = 0.08554835857160516
Trained batch 295 in epoch 3, gen_loss = 0.8270252476874236, disc_loss = 0.08560706163769134
Trained batch 296 in epoch 3, gen_loss = 0.8267805252211664, disc_loss = 0.08550543346526948
Trained batch 297 in epoch 3, gen_loss = 0.8262920410641088, disc_loss = 0.08542858770167168
Trained batch 298 in epoch 3, gen_loss = 0.8266144583257146, disc_loss = 0.08532859368505187
Trained batch 299 in epoch 3, gen_loss = 0.8264765798052152, disc_loss = 0.08532251950042943
Trained batch 300 in epoch 3, gen_loss = 0.8262106846535324, disc_loss = 0.08537317140095951
Trained batch 301 in epoch 3, gen_loss = 0.8258899820364074, disc_loss = 0.08534054858733388
Trained batch 302 in epoch 3, gen_loss = 0.8268231671832182, disc_loss = 0.0853887774609644
Trained batch 303 in epoch 3, gen_loss = 0.8269162569195032, disc_loss = 0.08518212391860097
Trained batch 304 in epoch 3, gen_loss = 0.8266806228239029, disc_loss = 0.08522818044866207
Trained batch 305 in epoch 3, gen_loss = 0.826690563676404, disc_loss = 0.08506373119132679
Trained batch 306 in epoch 3, gen_loss = 0.8272246348547236, disc_loss = 0.08495878511038685
Trained batch 307 in epoch 3, gen_loss = 0.8269195648563372, disc_loss = 0.08482608430438324
Trained batch 308 in epoch 3, gen_loss = 0.8264314162885487, disc_loss = 0.08482602011098928
Trained batch 309 in epoch 3, gen_loss = 0.8270002291087182, disc_loss = 0.08478512515524222
Trained batch 310 in epoch 3, gen_loss = 0.8276871817479946, disc_loss = 0.08474532190494695
Trained batch 311 in epoch 3, gen_loss = 0.8277655315513794, disc_loss = 0.08483750331633462
Trained batch 312 in epoch 3, gen_loss = 0.8283951239654431, disc_loss = 0.08484275154947948
Trained batch 313 in epoch 3, gen_loss = 0.8286503990934153, disc_loss = 0.0847772731338954
Trained batch 314 in epoch 3, gen_loss = 0.8286276220329224, disc_loss = 0.08458243523620897
Trained batch 315 in epoch 3, gen_loss = 0.8294410540521899, disc_loss = 0.08441635649474456
Trained batch 316 in epoch 3, gen_loss = 0.8299596829557269, disc_loss = 0.08427299498301294
Trained batch 317 in epoch 3, gen_loss = 0.8294007902812658, disc_loss = 0.084349674251774
Trained batch 318 in epoch 3, gen_loss = 0.8294396788162124, disc_loss = 0.08451886237146432
Trained batch 319 in epoch 3, gen_loss = 0.8295143631286919, disc_loss = 0.08440304408140946
Trained batch 320 in epoch 3, gen_loss = 0.8290416333719949, disc_loss = 0.08441378701060454
Trained batch 321 in epoch 3, gen_loss = 0.8298407868013619, disc_loss = 0.08426714477111927
Trained batch 322 in epoch 3, gen_loss = 0.8295588324498097, disc_loss = 0.08412629835619
Trained batch 323 in epoch 3, gen_loss = 0.8296285839176473, disc_loss = 0.08403658348618558
Trained batch 324 in epoch 3, gen_loss = 0.8308997628322015, disc_loss = 0.08406939851836516
Trained batch 325 in epoch 3, gen_loss = 0.8311258602910246, disc_loss = 0.08398087283002179
Trained batch 326 in epoch 3, gen_loss = 0.8306877564764169, disc_loss = 0.08390559708636926
Trained batch 327 in epoch 3, gen_loss = 0.8300296437994736, disc_loss = 0.08394267670412707
Trained batch 328 in epoch 3, gen_loss = 0.8298508935242801, disc_loss = 0.08395330330758924
Trained batch 329 in epoch 3, gen_loss = 0.8296658663135587, disc_loss = 0.08385164726694877
Trained batch 330 in epoch 3, gen_loss = 0.830741009953519, disc_loss = 0.0837202903102757
Trained batch 331 in epoch 3, gen_loss = 0.8325670640691217, disc_loss = 0.08377762786561556
Trained batch 332 in epoch 3, gen_loss = 0.8326305300444812, disc_loss = 0.08360546715166028
Trained batch 333 in epoch 3, gen_loss = 0.8320067113566542, disc_loss = 0.08356841720227977
Trained batch 334 in epoch 3, gen_loss = 0.8318470628403906, disc_loss = 0.08338794010733046
Trained batch 335 in epoch 3, gen_loss = 0.8317627549348843, disc_loss = 0.08329565027850636
Trained batch 336 in epoch 3, gen_loss = 0.83195038232676, disc_loss = 0.0832439264481561
Trained batch 337 in epoch 3, gen_loss = 0.8310993741426242, disc_loss = 0.08334530522694161
Trained batch 338 in epoch 3, gen_loss = 0.8307344538096482, disc_loss = 0.08331534429934084
Trained batch 339 in epoch 3, gen_loss = 0.8306315414169255, disc_loss = 0.0832259076565285
Trained batch 340 in epoch 3, gen_loss = 0.8318792975717976, disc_loss = 0.08317175984677594
Trained batch 341 in epoch 3, gen_loss = 0.8319745094281191, disc_loss = 0.08303911888928354
Trained batch 342 in epoch 3, gen_loss = 0.832227296888307, disc_loss = 0.08283723367014276
Trained batch 343 in epoch 3, gen_loss = 0.8318503080585669, disc_loss = 0.08281657335532526
Trained batch 344 in epoch 3, gen_loss = 0.831543448092281, disc_loss = 0.08285339986230585
Trained batch 345 in epoch 3, gen_loss = 0.8323546021832207, disc_loss = 0.08283216284178843
Trained batch 346 in epoch 3, gen_loss = 0.8319028977530147, disc_loss = 0.08290607831910553
Trained batch 347 in epoch 3, gen_loss = 0.8330880024138538, disc_loss = 0.08281447770255992
Trained batch 348 in epoch 3, gen_loss = 0.8334796866748941, disc_loss = 0.0827119351794308
Trained batch 349 in epoch 3, gen_loss = 0.8329595088107246, disc_loss = 0.08275848947199328
Trained batch 350 in epoch 3, gen_loss = 0.833790104528438, disc_loss = 0.08264312766587888
Trained batch 351 in epoch 3, gen_loss = 0.8346413535658609, disc_loss = 0.08245838660778562
Trained batch 352 in epoch 3, gen_loss = 0.833880773769222, disc_loss = 0.08250669650364108
Trained batch 353 in epoch 3, gen_loss = 0.8338288379422689, disc_loss = 0.08243330745657874
Trained batch 354 in epoch 3, gen_loss = 0.8338189535577533, disc_loss = 0.08257373391689969
Trained batch 355 in epoch 3, gen_loss = 0.8332971492677592, disc_loss = 0.08268077479769591
Trained batch 356 in epoch 3, gen_loss = 0.8327560692775149, disc_loss = 0.08273380991405382
Trained batch 357 in epoch 3, gen_loss = 0.8329020636208231, disc_loss = 0.08284596510637322
Trained batch 358 in epoch 3, gen_loss = 0.8326129223476878, disc_loss = 0.08271679163632868
Trained batch 359 in epoch 3, gen_loss = 0.833753135220872, disc_loss = 0.08260766140237037
Trained batch 360 in epoch 3, gen_loss = 0.8326983753168682, disc_loss = 0.08319085890845165
Trained batch 361 in epoch 3, gen_loss = 0.8328240195196637, disc_loss = 0.08320340729004688
Trained batch 362 in epoch 3, gen_loss = 0.8336520438844507, disc_loss = 0.08323352474760336
Trained batch 363 in epoch 3, gen_loss = 0.8335661721917299, disc_loss = 0.08330861926027625
Trained batch 364 in epoch 3, gen_loss = 0.8335768742920601, disc_loss = 0.08313200822584842
Trained batch 365 in epoch 3, gen_loss = 0.8336872464157844, disc_loss = 0.08296402795443851
Trained batch 366 in epoch 3, gen_loss = 0.8336014844253862, disc_loss = 0.08293216652427203
Trained batch 367 in epoch 3, gen_loss = 0.8326449399894994, disc_loss = 0.08329112685295632
Trained batch 368 in epoch 3, gen_loss = 0.8323738963461826, disc_loss = 0.08326613692299219
Trained batch 369 in epoch 3, gen_loss = 0.8328949500580092, disc_loss = 0.08327022983466048
Trained batch 370 in epoch 3, gen_loss = 0.8328708110633244, disc_loss = 0.08313057739588851
Trained batch 371 in epoch 3, gen_loss = 0.8331651507366088, disc_loss = 0.08294908409707889
Trained batch 372 in epoch 3, gen_loss = 0.8326461488535832, disc_loss = 0.0829289207964057
Trained batch 373 in epoch 3, gen_loss = 0.8322144291777024, disc_loss = 0.08333640756523784
Trained batch 374 in epoch 3, gen_loss = 0.8328236393133799, disc_loss = 0.08315474821130435
Trained batch 375 in epoch 3, gen_loss = 0.8327027736033531, disc_loss = 0.08299764027779406
Trained batch 376 in epoch 3, gen_loss = 0.8326669072124623, disc_loss = 0.08282481947177602
Trained batch 377 in epoch 3, gen_loss = 0.8327818318176522, disc_loss = 0.0826875569210166
Trained batch 378 in epoch 3, gen_loss = 0.833055385420379, disc_loss = 0.08264819678105906
Trained batch 379 in epoch 3, gen_loss = 0.8327067110883563, disc_loss = 0.08257481963618805
Trained batch 380 in epoch 3, gen_loss = 0.8331943299044461, disc_loss = 0.08244742179323682
Trained batch 381 in epoch 3, gen_loss = 0.8332412610347358, disc_loss = 0.08232393673577233
Trained batch 382 in epoch 3, gen_loss = 0.8330881867178427, disc_loss = 0.08226161848938496
Trained batch 383 in epoch 3, gen_loss = 0.8329170483630151, disc_loss = 0.08219229501749699
Trained batch 384 in epoch 3, gen_loss = 0.8329005697330871, disc_loss = 0.08208834970152223
Trained batch 385 in epoch 3, gen_loss = 0.8329316523563058, disc_loss = 0.0820009574931057
Trained batch 386 in epoch 3, gen_loss = 0.8325946701435464, disc_loss = 0.08192945099423714
Trained batch 387 in epoch 3, gen_loss = 0.8320719164210496, disc_loss = 0.08191706150885403
Trained batch 388 in epoch 3, gen_loss = 0.8324084469622389, disc_loss = 0.08211607260959927
Trained batch 389 in epoch 3, gen_loss = 0.8318915895162484, disc_loss = 0.08214102569871988
Trained batch 390 in epoch 3, gen_loss = 0.8319481470243401, disc_loss = 0.08205251253741172
Trained batch 391 in epoch 3, gen_loss = 0.8321638620477549, disc_loss = 0.0819580315954375
Trained batch 392 in epoch 3, gen_loss = 0.8318785282643394, disc_loss = 0.0819110035536095
Trained batch 393 in epoch 3, gen_loss = 0.83176589564321, disc_loss = 0.08185036389658294
Trained batch 394 in epoch 3, gen_loss = 0.8320535283299941, disc_loss = 0.08176847363385974
Trained batch 395 in epoch 3, gen_loss = 0.8320673361721665, disc_loss = 0.08166332170367241
Trained batch 396 in epoch 3, gen_loss = 0.8317470480723105, disc_loss = 0.08155540411620957
Trained batch 397 in epoch 3, gen_loss = 0.831959630900891, disc_loss = 0.08140512155696525
Trained batch 398 in epoch 3, gen_loss = 0.8324612617343291, disc_loss = 0.08125108245638828
Trained batch 399 in epoch 3, gen_loss = 0.8328771286457777, disc_loss = 0.08108592693228274
Trained batch 400 in epoch 3, gen_loss = 0.8326104866744871, disc_loss = 0.08101715346765785
Trained batch 401 in epoch 3, gen_loss = 0.8326614124709694, disc_loss = 0.08096423204432228
Trained batch 402 in epoch 3, gen_loss = 0.8322652009669368, disc_loss = 0.08096734547603959
Trained batch 403 in epoch 3, gen_loss = 0.8322922362401934, disc_loss = 0.08083530888422438
Trained batch 404 in epoch 3, gen_loss = 0.8326418837647379, disc_loss = 0.08097420699526499
Trained batch 405 in epoch 3, gen_loss = 0.8323144349705409, disc_loss = 0.08100826712095825
Trained batch 406 in epoch 3, gen_loss = 0.831505133200629, disc_loss = 0.08171149477344326
Trained batch 407 in epoch 3, gen_loss = 0.8327182359701278, disc_loss = 0.08187673113527982
Trained batch 408 in epoch 3, gen_loss = 0.8330942296894372, disc_loss = 0.08173690643844657
Trained batch 409 in epoch 3, gen_loss = 0.8330994920759667, disc_loss = 0.08172345483539308
Trained batch 410 in epoch 3, gen_loss = 0.8327862648633275, disc_loss = 0.08167727665472639
Trained batch 411 in epoch 3, gen_loss = 0.8327653727051124, disc_loss = 0.08159768221972202
Trained batch 412 in epoch 3, gen_loss = 0.8334170153441209, disc_loss = 0.08150339783699259
Trained batch 413 in epoch 3, gen_loss = 0.8331661937749328, disc_loss = 0.08146464904311343
Trained batch 414 in epoch 3, gen_loss = 0.8331312779202519, disc_loss = 0.0813242492007922
Trained batch 415 in epoch 3, gen_loss = 0.8335568904160306, disc_loss = 0.08131682559346351
Trained batch 416 in epoch 3, gen_loss = 0.833043446286405, disc_loss = 0.08128506465138291
Trained batch 417 in epoch 3, gen_loss = 0.8319957148658031, disc_loss = 0.08172936258062222
Trained batch 418 in epoch 3, gen_loss = 0.8324739341946377, disc_loss = 0.08166647014299269
Trained batch 419 in epoch 3, gen_loss = 0.8327906210507665, disc_loss = 0.08167190491443589
Trained batch 420 in epoch 3, gen_loss = 0.8324030537928085, disc_loss = 0.08175032605326374
Trained batch 421 in epoch 3, gen_loss = 0.8318892914395761, disc_loss = 0.08190142606954438
Trained batch 422 in epoch 3, gen_loss = 0.8324189140300661, disc_loss = 0.08186546262203942
Trained batch 423 in epoch 3, gen_loss = 0.8328660315359538, disc_loss = 0.08176281163468957
Trained batch 424 in epoch 3, gen_loss = 0.8331505893959719, disc_loss = 0.08166458977495923
Trained batch 425 in epoch 3, gen_loss = 0.8328649346397516, disc_loss = 0.08160544470162459
Trained batch 426 in epoch 3, gen_loss = 0.8327906879245258, disc_loss = 0.08146924870110507
Trained batch 427 in epoch 3, gen_loss = 0.8338539555111778, disc_loss = 0.08185214212460216
Trained batch 428 in epoch 3, gen_loss = 0.8333882970826609, disc_loss = 0.0819951447729881
Trained batch 429 in epoch 3, gen_loss = 0.8330827708161155, disc_loss = 0.08208865600443163
Trained batch 430 in epoch 3, gen_loss = 0.8334929127842534, disc_loss = 0.08207373837065254
Trained batch 431 in epoch 3, gen_loss = 0.8337203891326984, disc_loss = 0.08204917876153356
Trained batch 432 in epoch 3, gen_loss = 0.833191735708686, disc_loss = 0.0821302801319
Trained batch 433 in epoch 3, gen_loss = 0.8336013633122642, disc_loss = 0.0820683280976
Trained batch 434 in epoch 3, gen_loss = 0.8337793459152353, disc_loss = 0.0820078751564711
Trained batch 435 in epoch 3, gen_loss = 0.833727553555178, disc_loss = 0.08192901796054676
Trained batch 436 in epoch 3, gen_loss = 0.8334567428862748, disc_loss = 0.0820268877873568
Trained batch 437 in epoch 3, gen_loss = 0.8340074424738209, disc_loss = 0.0824828350397686
Trained batch 438 in epoch 3, gen_loss = 0.8335231290727108, disc_loss = 0.08245899306784187
Trained batch 439 in epoch 3, gen_loss = 0.8331448164175858, disc_loss = 0.08253426322374832
Trained batch 440 in epoch 3, gen_loss = 0.8335770213820226, disc_loss = 0.08249319948745963
Trained batch 441 in epoch 3, gen_loss = 0.8338569164680679, disc_loss = 0.08249699291499223
Trained batch 442 in epoch 3, gen_loss = 0.8344955244532557, disc_loss = 0.08237748938711448
Trained batch 443 in epoch 3, gen_loss = 0.8344834392537942, disc_loss = 0.0824321579976796
Trained batch 444 in epoch 3, gen_loss = 0.8346972590751862, disc_loss = 0.08229172176189636
Trained batch 445 in epoch 3, gen_loss = 0.8348638127336587, disc_loss = 0.08236165010608365
Trained batch 446 in epoch 3, gen_loss = 0.8348485102722842, disc_loss = 0.08223075715104072
Trained batch 447 in epoch 3, gen_loss = 0.8346255290588098, disc_loss = 0.08226564596822884
Trained batch 448 in epoch 3, gen_loss = 0.8347637050003145, disc_loss = 0.08218633943135728
Trained batch 449 in epoch 3, gen_loss = 0.8347419393724865, disc_loss = 0.08206129035602014
Trained batch 450 in epoch 3, gen_loss = 0.8351351315457117, disc_loss = 0.08193349741201046
Trained batch 451 in epoch 3, gen_loss = 0.8350458362065585, disc_loss = 0.08192102998841257
Trained batch 452 in epoch 3, gen_loss = 0.8353747990615583, disc_loss = 0.08179247895333809
Trained batch 453 in epoch 3, gen_loss = 0.8355256624290072, disc_loss = 0.08167457052133156
Trained batch 454 in epoch 3, gen_loss = 0.8354653018516499, disc_loss = 0.08157737317321065
Trained batch 455 in epoch 3, gen_loss = 0.8356685649538249, disc_loss = 0.08143394262317502
Trained batch 456 in epoch 3, gen_loss = 0.8357037114757938, disc_loss = 0.08132650148881604
Trained batch 457 in epoch 3, gen_loss = 0.8355347954680306, disc_loss = 0.08135398116174224
Trained batch 458 in epoch 3, gen_loss = 0.8355585402263276, disc_loss = 0.08130342900460842
Trained batch 459 in epoch 3, gen_loss = 0.8348370684877686, disc_loss = 0.08143735611406358
Trained batch 460 in epoch 3, gen_loss = 0.8356626161137786, disc_loss = 0.08149271979604782
Trained batch 461 in epoch 3, gen_loss = 0.8354148008735665, disc_loss = 0.08143871989568849
Trained batch 462 in epoch 3, gen_loss = 0.8356644271130695, disc_loss = 0.08153852240281023
Trained batch 463 in epoch 3, gen_loss = 0.8349974446384043, disc_loss = 0.08172015954162283
Trained batch 464 in epoch 3, gen_loss = 0.8350714168881858, disc_loss = 0.08167234164892986
Trained batch 465 in epoch 3, gen_loss = 0.835018970487967, disc_loss = 0.08155345632554763
Trained batch 466 in epoch 3, gen_loss = 0.8358289818309359, disc_loss = 0.08146843372004574
Trained batch 467 in epoch 3, gen_loss = 0.8357441836060622, disc_loss = 0.08139945780380796
Trained batch 468 in epoch 3, gen_loss = 0.8359196076133867, disc_loss = 0.08125376712078097
Trained batch 469 in epoch 3, gen_loss = 0.8361637114844424, disc_loss = 0.08113891403488022
Trained batch 470 in epoch 3, gen_loss = 0.835467818626173, disc_loss = 0.08138798538302792
Trained batch 471 in epoch 3, gen_loss = 0.8358628958842512, disc_loss = 0.0813652887285324
Trained batch 472 in epoch 3, gen_loss = 0.8362104783728561, disc_loss = 0.08124299841612011
Trained batch 473 in epoch 3, gen_loss = 0.8357728688902996, disc_loss = 0.08128156212358913
Trained batch 474 in epoch 3, gen_loss = 0.8359896601501264, disc_loss = 0.08124897678823848
Trained batch 475 in epoch 3, gen_loss = 0.8364562318981195, disc_loss = 0.08115581218388025
Trained batch 476 in epoch 3, gen_loss = 0.8362103287653853, disc_loss = 0.08113874729714929
Trained batch 477 in epoch 3, gen_loss = 0.8357569430039019, disc_loss = 0.08107294827684074
Trained batch 478 in epoch 3, gen_loss = 0.8360708956305318, disc_loss = 0.08126874137008738
Trained batch 479 in epoch 3, gen_loss = 0.8359679277365406, disc_loss = 0.08122622163888688
Trained batch 480 in epoch 3, gen_loss = 0.8360057066111456, disc_loss = 0.08108254422757023
Trained batch 481 in epoch 3, gen_loss = 0.8358101024296274, disc_loss = 0.08102066259777088
Trained batch 482 in epoch 3, gen_loss = 0.8358189624659023, disc_loss = 0.08090189075209278
Trained batch 483 in epoch 3, gen_loss = 0.8358677327017153, disc_loss = 0.08077518639447213
Trained batch 484 in epoch 3, gen_loss = 0.8358125173553979, disc_loss = 0.08070148045830812
Trained batch 485 in epoch 3, gen_loss = 0.8362501340270533, disc_loss = 0.08058060886369015
Trained batch 486 in epoch 3, gen_loss = 0.8364419646454053, disc_loss = 0.08096023644196362
Trained batch 487 in epoch 3, gen_loss = 0.836085673910184, disc_loss = 0.08115474308543212
Trained batch 488 in epoch 3, gen_loss = 0.8358272094058601, disc_loss = 0.08112358521091122
Trained batch 489 in epoch 3, gen_loss = 0.8360566002373793, disc_loss = 0.08112328433982875
Trained batch 490 in epoch 3, gen_loss = 0.8359722282031888, disc_loss = 0.08102062527591063
Trained batch 491 in epoch 3, gen_loss = 0.8365149991662522, disc_loss = 0.08089461448844673
Trained batch 492 in epoch 3, gen_loss = 0.8363274083780711, disc_loss = 0.0808666223796126
Trained batch 493 in epoch 3, gen_loss = 0.8364782522202503, disc_loss = 0.0807341130767093
Trained batch 494 in epoch 3, gen_loss = 0.8371961541248091, disc_loss = 0.08065281090787565
Trained batch 495 in epoch 3, gen_loss = 0.836924193667308, disc_loss = 0.08056235038149621
Trained batch 496 in epoch 3, gen_loss = 0.8363801896332256, disc_loss = 0.08058998556489076
Trained batch 497 in epoch 3, gen_loss = 0.8366320342064861, disc_loss = 0.08065169033441079
Trained batch 498 in epoch 3, gen_loss = 0.8363114596010449, disc_loss = 0.08063356264425303
Trained batch 499 in epoch 3, gen_loss = 0.8361013126969338, disc_loss = 0.08055781107768416
Trained batch 500 in epoch 3, gen_loss = 0.836496056256418, disc_loss = 0.08049417885314086
Trained batch 501 in epoch 3, gen_loss = 0.8362533798611972, disc_loss = 0.08052516936795764
Trained batch 502 in epoch 3, gen_loss = 0.835959797291822, disc_loss = 0.08058933634125807
Trained batch 503 in epoch 3, gen_loss = 0.8355225430476287, disc_loss = 0.08079441035506389
Trained batch 504 in epoch 3, gen_loss = 0.8351047694683075, disc_loss = 0.08078001807305482
Trained batch 505 in epoch 3, gen_loss = 0.834904436360706, disc_loss = 0.0806944692404315
Trained batch 506 in epoch 3, gen_loss = 0.8349768296618904, disc_loss = 0.08062697585150452
Trained batch 507 in epoch 3, gen_loss = 0.8351614278719182, disc_loss = 0.08051632801217475
Trained batch 508 in epoch 3, gen_loss = 0.835239020042663, disc_loss = 0.0804144727699239
Trained batch 509 in epoch 3, gen_loss = 0.8348495800705517, disc_loss = 0.08041548610975345
Trained batch 510 in epoch 3, gen_loss = 0.8346559702183636, disc_loss = 0.08036497597985422
Trained batch 511 in epoch 3, gen_loss = 0.8350980399991386, disc_loss = 0.08034357914220891
Trained batch 512 in epoch 3, gen_loss = 0.8348887728320228, disc_loss = 0.08029354006037494
Trained batch 513 in epoch 3, gen_loss = 0.8346346918826901, disc_loss = 0.08032460065362866
Trained batch 514 in epoch 3, gen_loss = 0.8344387926522968, disc_loss = 0.08019951796068729
Trained batch 515 in epoch 3, gen_loss = 0.8348840740184451, disc_loss = 0.08007774560878328
Trained batch 516 in epoch 3, gen_loss = 0.8349944863259446, disc_loss = 0.07995183213219421
Trained batch 517 in epoch 3, gen_loss = 0.8350955524614879, disc_loss = 0.0798227448829065
Trained batch 518 in epoch 3, gen_loss = 0.8349088627364135, disc_loss = 0.07977314880171607
Trained batch 519 in epoch 3, gen_loss = 0.8352130227937148, disc_loss = 0.07967410537127692
Trained batch 520 in epoch 3, gen_loss = 0.8350103984295522, disc_loss = 0.07957705323747047
Trained batch 521 in epoch 3, gen_loss = 0.8351434062152987, disc_loss = 0.0795979949171116
Trained batch 522 in epoch 3, gen_loss = 0.8346514181584747, disc_loss = 0.07962492154287905
Trained batch 523 in epoch 3, gen_loss = 0.8351246950621823, disc_loss = 0.07961115355155508
Trained batch 524 in epoch 3, gen_loss = 0.8348159103734153, disc_loss = 0.07963035590946674
Trained batch 525 in epoch 3, gen_loss = 0.8349125214742616, disc_loss = 0.07952610131338975
Trained batch 526 in epoch 3, gen_loss = 0.8347312983910092, disc_loss = 0.07946798481061292
Trained batch 527 in epoch 3, gen_loss = 0.834972013408939, disc_loss = 0.07935885157591353
Trained batch 528 in epoch 3, gen_loss = 0.8356913213806477, disc_loss = 0.07927542864670713
Trained batch 529 in epoch 3, gen_loss = 0.8358055068074532, disc_loss = 0.07915422688853348
Trained batch 530 in epoch 3, gen_loss = 0.8361025858396864, disc_loss = 0.07911193404669423
Trained batch 531 in epoch 3, gen_loss = 0.8357326503198846, disc_loss = 0.07928857546390727
Trained batch 532 in epoch 3, gen_loss = 0.8363039507539366, disc_loss = 0.07935492617670467
Trained batch 533 in epoch 3, gen_loss = 0.8363464850276597, disc_loss = 0.07924762738115165
Trained batch 534 in epoch 3, gen_loss = 0.8363117753345276, disc_loss = 0.07916096304934994
Trained batch 535 in epoch 3, gen_loss = 0.8361018380678412, disc_loss = 0.07913460103801882
Trained batch 536 in epoch 3, gen_loss = 0.8363640876122693, disc_loss = 0.0791006710127107
Trained batch 537 in epoch 3, gen_loss = 0.8362406580310772, disc_loss = 0.07912153354759387
Trained batch 538 in epoch 3, gen_loss = 0.836104355351602, disc_loss = 0.07906447353916232
Trained batch 539 in epoch 3, gen_loss = 0.8361853369408183, disc_loss = 0.07898895434379853
Trained batch 540 in epoch 3, gen_loss = 0.8360716670255784, disc_loss = 0.07891053634277388
Trained batch 541 in epoch 3, gen_loss = 0.8358447126686793, disc_loss = 0.07886885040065074
Trained batch 542 in epoch 3, gen_loss = 0.836683105313756, disc_loss = 0.07886608323154363
Trained batch 543 in epoch 3, gen_loss = 0.8366162386339377, disc_loss = 0.07876774934565593
Trained batch 544 in epoch 3, gen_loss = 0.836338776568754, disc_loss = 0.07888009296815603
Trained batch 545 in epoch 3, gen_loss = 0.8362246059126907, disc_loss = 0.07906948690619933
Trained batch 546 in epoch 3, gen_loss = 0.8361734492360346, disc_loss = 0.07902412353699832
Trained batch 547 in epoch 3, gen_loss = 0.8362544697240322, disc_loss = 0.07891839406670609
Trained batch 548 in epoch 3, gen_loss = 0.8363805515844314, disc_loss = 0.07884494762677692
Trained batch 549 in epoch 3, gen_loss = 0.8361124445633454, disc_loss = 0.07888094940476797
Trained batch 550 in epoch 3, gen_loss = 0.8362440927167121, disc_loss = 0.07895523553609361
Trained batch 551 in epoch 3, gen_loss = 0.8366466642397902, disc_loss = 0.07884473676381605
Trained batch 552 in epoch 3, gen_loss = 0.8364173086060323, disc_loss = 0.07882676308782634
Trained batch 553 in epoch 3, gen_loss = 0.8361081459999945, disc_loss = 0.07877699055940934
Trained batch 554 in epoch 3, gen_loss = 0.8367977484389468, disc_loss = 0.0787685720921234
Trained batch 555 in epoch 3, gen_loss = 0.8365599211278579, disc_loss = 0.07875734212701109
Trained batch 556 in epoch 3, gen_loss = 0.8360871422761647, disc_loss = 0.07882385842896716
Trained batch 557 in epoch 3, gen_loss = 0.8364942066878828, disc_loss = 0.07919023889801248
Trained batch 558 in epoch 3, gen_loss = 0.8366335678932278, disc_loss = 0.07907892967039495
Trained batch 559 in epoch 3, gen_loss = 0.8365636844187975, disc_loss = 0.07899574385457007
Trained batch 560 in epoch 3, gen_loss = 0.8365476309403166, disc_loss = 0.07897473567077448
Trained batch 561 in epoch 3, gen_loss = 0.8369438494969942, disc_loss = 0.07904078132138187
Trained batch 562 in epoch 3, gen_loss = 0.8365918595350446, disc_loss = 0.07911433922176515
Trained batch 563 in epoch 3, gen_loss = 0.8365889837872897, disc_loss = 0.07906076224382094
Trained batch 564 in epoch 3, gen_loss = 0.8362674493177802, disc_loss = 0.0790379639170998
Trained batch 565 in epoch 3, gen_loss = 0.8364900916604187, disc_loss = 0.07908059841732729
Trained batch 566 in epoch 3, gen_loss = 0.8364749326382155, disc_loss = 0.0789654870982392
Trained batch 567 in epoch 3, gen_loss = 0.8366744993123371, disc_loss = 0.07887603616519032
Trained batch 568 in epoch 3, gen_loss = 0.8363719885818569, disc_loss = 0.07888654380977835
Trained batch 569 in epoch 3, gen_loss = 0.8365885159948416, disc_loss = 0.07882747315360528
Trained batch 570 in epoch 3, gen_loss = 0.8372390030666325, disc_loss = 0.078753513949491
Trained batch 571 in epoch 3, gen_loss = 0.837266841082723, disc_loss = 0.07864337786218034
Trained batch 572 in epoch 3, gen_loss = 0.8366755483766293, disc_loss = 0.07873279040103963
Trained batch 573 in epoch 3, gen_loss = 0.8367752860128257, disc_loss = 0.07878739476846433
Trained batch 574 in epoch 3, gen_loss = 0.8365124397174172, disc_loss = 0.078756025781774
Trained batch 575 in epoch 3, gen_loss = 0.8363796200913688, disc_loss = 0.07867351132477375
Trained batch 576 in epoch 3, gen_loss = 0.8366177740605286, disc_loss = 0.07859179661149221
Trained batch 577 in epoch 3, gen_loss = 0.8366359042770722, disc_loss = 0.0785924765687423
Trained batch 578 in epoch 3, gen_loss = 0.83614045530815, disc_loss = 0.07877301440987614
Trained batch 579 in epoch 3, gen_loss = 0.8365397689157519, disc_loss = 0.07877423535422261
Trained batch 580 in epoch 3, gen_loss = 0.8370810018246433, disc_loss = 0.07878036860684366
Trained batch 581 in epoch 3, gen_loss = 0.8368481701284749, disc_loss = 0.0787716963859691
Trained batch 582 in epoch 3, gen_loss = 0.8364679265901523, disc_loss = 0.07884308171345122
Trained batch 583 in epoch 3, gen_loss = 0.8367673787862471, disc_loss = 0.07934702036755593
Trained batch 584 in epoch 3, gen_loss = 0.8364097542742379, disc_loss = 0.07933309709446298
Trained batch 585 in epoch 3, gen_loss = 0.8359088632739038, disc_loss = 0.0794100045042157
Trained batch 586 in epoch 3, gen_loss = 0.8358495080592888, disc_loss = 0.07957986255653926
Trained batch 587 in epoch 3, gen_loss = 0.8354550490067119, disc_loss = 0.0796768808955973
Trained batch 588 in epoch 3, gen_loss = 0.8354904735128827, disc_loss = 0.0797538375513587
Trained batch 589 in epoch 3, gen_loss = 0.8355665376125756, disc_loss = 0.07974975703410425
Trained batch 590 in epoch 3, gen_loss = 0.8359122132589369, disc_loss = 0.07967226900784347
Trained batch 591 in epoch 3, gen_loss = 0.835792007226799, disc_loss = 0.07972115455856044
Trained batch 592 in epoch 3, gen_loss = 0.8354389408688119, disc_loss = 0.07975072504302352
Trained batch 593 in epoch 3, gen_loss = 0.835354510832716, disc_loss = 0.07980457233164698
Trained batch 594 in epoch 3, gen_loss = 0.8355113644058965, disc_loss = 0.07977948049944239
Trained batch 595 in epoch 3, gen_loss = 0.8354681291736212, disc_loss = 0.0797013931067023
Trained batch 596 in epoch 3, gen_loss = 0.834988329728045, disc_loss = 0.07974630002855905
Trained batch 597 in epoch 3, gen_loss = 0.8352514342420476, disc_loss = 0.0796633050434391
Trained batch 598 in epoch 3, gen_loss = 0.8348259856684976, disc_loss = 0.07989157986468037
Trained batch 599 in epoch 3, gen_loss = 0.8345582223435243, disc_loss = 0.07988838223274797
Trained batch 600 in epoch 3, gen_loss = 0.8344394028583502, disc_loss = 0.07986352036237568
Trained batch 601 in epoch 3, gen_loss = 0.8346870202459766, disc_loss = 0.07981463359743109
Trained batch 602 in epoch 3, gen_loss = 0.8350213150776441, disc_loss = 0.07978546992098762
Trained batch 603 in epoch 3, gen_loss = 0.8351848322330722, disc_loss = 0.07974652695124167
Trained batch 604 in epoch 3, gen_loss = 0.8350216303482528, disc_loss = 0.07968380284487955
Trained batch 605 in epoch 3, gen_loss = 0.8356386955716822, disc_loss = 0.07962488693649275
Trained batch 606 in epoch 3, gen_loss = 0.8354225735589739, disc_loss = 0.0795739540504982
Trained batch 607 in epoch 3, gen_loss = 0.835787675049352, disc_loss = 0.07947646667353662
Trained batch 608 in epoch 3, gen_loss = 0.835719374453493, disc_loss = 0.0794247929358546
Trained batch 609 in epoch 3, gen_loss = 0.8359978033382385, disc_loss = 0.07939415016043626
Trained batch 610 in epoch 3, gen_loss = 0.8356757759560149, disc_loss = 0.07951737124680155
Trained batch 611 in epoch 3, gen_loss = 0.8360972204336933, disc_loss = 0.07980154577819204
Trained batch 612 in epoch 3, gen_loss = 0.8362041203757873, disc_loss = 0.07970045326614895
Trained batch 613 in epoch 3, gen_loss = 0.8359385438093533, disc_loss = 0.07966283123473052
Trained batch 614 in epoch 3, gen_loss = 0.8354730542597731, disc_loss = 0.07971401657545713
Trained batch 615 in epoch 3, gen_loss = 0.8358002336478079, disc_loss = 0.07966903831307813
Trained batch 616 in epoch 3, gen_loss = 0.8355915309254509, disc_loss = 0.07963956832263855
Trained batch 617 in epoch 3, gen_loss = 0.8360092310554387, disc_loss = 0.07972138240167866
Trained batch 618 in epoch 3, gen_loss = 0.8356923739725245, disc_loss = 0.07972942436074835
Trained batch 619 in epoch 3, gen_loss = 0.8357196496859673, disc_loss = 0.07966349502394517
Trained batch 620 in epoch 3, gen_loss = 0.836157996153486, disc_loss = 0.07960310526906052
Trained batch 621 in epoch 3, gen_loss = 0.8364825448518397, disc_loss = 0.07951693626276406
Trained batch 622 in epoch 3, gen_loss = 0.8364813868823442, disc_loss = 0.07943651135891293
Trained batch 623 in epoch 3, gen_loss = 0.8362881086098078, disc_loss = 0.07942102007263412
Trained batch 624 in epoch 3, gen_loss = 0.8366392018795014, disc_loss = 0.07939834899455309
Trained batch 625 in epoch 3, gen_loss = 0.8371487685952324, disc_loss = 0.07960939444988348
Trained batch 626 in epoch 3, gen_loss = 0.8366440260334258, disc_loss = 0.0796612860320026
Trained batch 627 in epoch 3, gen_loss = 0.8366473079392105, disc_loss = 0.07966825612346126
Trained batch 628 in epoch 3, gen_loss = 0.8370438120039165, disc_loss = 0.07963130670038476
Trained batch 629 in epoch 3, gen_loss = 0.8373428542935659, disc_loss = 0.07954697222966287
Trained batch 630 in epoch 3, gen_loss = 0.8372824585475559, disc_loss = 0.07949005181439185
Trained batch 631 in epoch 3, gen_loss = 0.8372441451477853, disc_loss = 0.07942099894155288
Trained batch 632 in epoch 3, gen_loss = 0.8374524017175039, disc_loss = 0.07936283422995942
Trained batch 633 in epoch 3, gen_loss = 0.8372616833222777, disc_loss = 0.07935239479962254
Trained batch 634 in epoch 3, gen_loss = 0.837236924293473, disc_loss = 0.07941099738071519
Trained batch 635 in epoch 3, gen_loss = 0.8370366718315478, disc_loss = 0.07943747304643523
Trained batch 636 in epoch 3, gen_loss = 0.8368780141816221, disc_loss = 0.0793930948134424
Trained batch 637 in epoch 3, gen_loss = 0.8369203602725809, disc_loss = 0.07934158358016405
Trained batch 638 in epoch 3, gen_loss = 0.8375104591600212, disc_loss = 0.07930779482306495
Trained batch 639 in epoch 3, gen_loss = 0.8371883308980614, disc_loss = 0.07934082293213578
Trained batch 640 in epoch 3, gen_loss = 0.8370399787998795, disc_loss = 0.07930424354546202
Trained batch 641 in epoch 3, gen_loss = 0.8378438012343701, disc_loss = 0.07950682339992525
Trained batch 642 in epoch 3, gen_loss = 0.8378533748315986, disc_loss = 0.07940347535277878
Trained batch 643 in epoch 3, gen_loss = 0.8375219915131604, disc_loss = 0.07954128647385084
Trained batch 644 in epoch 3, gen_loss = 0.8378629737584166, disc_loss = 0.07946300743681978
Trained batch 645 in epoch 3, gen_loss = 0.8380607411311507, disc_loss = 0.07938504058740825
Trained batch 646 in epoch 3, gen_loss = 0.8380044050618338, disc_loss = 0.07940529720998805
Trained batch 647 in epoch 3, gen_loss = 0.8377454110225777, disc_loss = 0.07948227991338497
Trained batch 648 in epoch 3, gen_loss = 0.8378374854386863, disc_loss = 0.07943239114684941
Trained batch 649 in epoch 3, gen_loss = 0.83752104644592, disc_loss = 0.07946899611216325
Trained batch 650 in epoch 3, gen_loss = 0.8376840009209564, disc_loss = 0.0794143211468482
Trained batch 651 in epoch 3, gen_loss = 0.8379135602182406, disc_loss = 0.07931476704307769
Trained batch 652 in epoch 3, gen_loss = 0.8378402097393141, disc_loss = 0.07928869901524477
Trained batch 653 in epoch 3, gen_loss = 0.8381475675452376, disc_loss = 0.07925103468940072
Trained batch 654 in epoch 3, gen_loss = 0.8382341220633674, disc_loss = 0.07921867150784904
Trained batch 655 in epoch 3, gen_loss = 0.8379385949725785, disc_loss = 0.07931637387756803
Trained batch 656 in epoch 3, gen_loss = 0.8383505885550239, disc_loss = 0.07923444511604182
Trained batch 657 in epoch 3, gen_loss = 0.8383219688224938, disc_loss = 0.07925245224987935
Trained batch 658 in epoch 3, gen_loss = 0.838396687925495, disc_loss = 0.07915888504550563
Trained batch 659 in epoch 3, gen_loss = 0.8378353569092173, disc_loss = 0.07942848654294556
Trained batch 660 in epoch 3, gen_loss = 0.8381310700017638, disc_loss = 0.07985049803458075
Trained batch 661 in epoch 3, gen_loss = 0.8377897025865371, disc_loss = 0.07983535301401716
Trained batch 662 in epoch 3, gen_loss = 0.8378447145448371, disc_loss = 0.07981866858281521
Trained batch 663 in epoch 3, gen_loss = 0.8378029137580509, disc_loss = 0.07976324630183089
Trained batch 664 in epoch 3, gen_loss = 0.8373776871907084, disc_loss = 0.0797912969793144
Trained batch 665 in epoch 3, gen_loss = 0.8373766556247935, disc_loss = 0.07973861842564456
Trained batch 666 in epoch 3, gen_loss = 0.8375745969286923, disc_loss = 0.07966640214624254
Trained batch 667 in epoch 3, gen_loss = 0.8376572233384955, disc_loss = 0.07963154060085734
Trained batch 668 in epoch 3, gen_loss = 0.8375410828266087, disc_loss = 0.07965791388031969
Trained batch 669 in epoch 3, gen_loss = 0.8372644728244241, disc_loss = 0.07969310871923148
Trained batch 670 in epoch 3, gen_loss = 0.8373923160901902, disc_loss = 0.07985824181097276
Trained batch 671 in epoch 3, gen_loss = 0.837212438517738, disc_loss = 0.07998971877220486
Trained batch 672 in epoch 3, gen_loss = 0.8372175042997675, disc_loss = 0.07993118566243645
Trained batch 673 in epoch 3, gen_loss = 0.8366845382338816, disc_loss = 0.08015282365330426
Trained batch 674 in epoch 3, gen_loss = 0.8370188818596027, disc_loss = 0.08019532784819602
Trained batch 675 in epoch 3, gen_loss = 0.8371003099535343, disc_loss = 0.08011246376709473
Trained batch 676 in epoch 3, gen_loss = 0.8369184586727109, disc_loss = 0.08011167982876564
Trained batch 677 in epoch 3, gen_loss = 0.8368104285283074, disc_loss = 0.0800439517527467
Trained batch 678 in epoch 3, gen_loss = 0.8369182424183622, disc_loss = 0.0799463849956381
Trained batch 679 in epoch 3, gen_loss = 0.8367789795731797, disc_loss = 0.0798675966271035
Trained batch 680 in epoch 3, gen_loss = 0.8366871804830436, disc_loss = 0.07985918035541993
Trained batch 681 in epoch 3, gen_loss = 0.8367866307846612, disc_loss = 0.07980342019660688
Trained batch 682 in epoch 3, gen_loss = 0.8366686070384253, disc_loss = 0.07976044491233406
Trained batch 683 in epoch 3, gen_loss = 0.836735388906727, disc_loss = 0.07969394266164224
Trained batch 684 in epoch 3, gen_loss = 0.8367346094037494, disc_loss = 0.07971104055942192
Trained batch 685 in epoch 3, gen_loss = 0.8365882838867149, disc_loss = 0.07965234495324705
Trained batch 686 in epoch 3, gen_loss = 0.8367317668996003, disc_loss = 0.0795600515501533
Trained batch 687 in epoch 3, gen_loss = 0.8367699317547471, disc_loss = 0.07949473910699707
Trained batch 688 in epoch 3, gen_loss = 0.8369097514578151, disc_loss = 0.07943126442875978
Trained batch 689 in epoch 3, gen_loss = 0.8367806634609251, disc_loss = 0.07940112259373933
Trained batch 690 in epoch 3, gen_loss = 0.8372453921696902, disc_loss = 0.07957704460003054
Trained batch 691 in epoch 3, gen_loss = 0.8368436066659889, disc_loss = 0.07967456673390388
Trained batch 692 in epoch 3, gen_loss = 0.8370542525815069, disc_loss = 0.07964057279522242
Trained batch 693 in epoch 3, gen_loss = 0.8366754816399528, disc_loss = 0.07968724565043701
Trained batch 694 in epoch 3, gen_loss = 0.8369367358067052, disc_loss = 0.07974237863832026
Trained batch 695 in epoch 3, gen_loss = 0.8367134157525397, disc_loss = 0.07980990972792751
Trained batch 696 in epoch 3, gen_loss = 0.8364157116994625, disc_loss = 0.07982666711249473
Trained batch 697 in epoch 3, gen_loss = 0.8364906250832758, disc_loss = 0.07983927467016018
Trained batch 698 in epoch 3, gen_loss = 0.8362931316246802, disc_loss = 0.07984604094795701
Trained batch 699 in epoch 3, gen_loss = 0.8364544273700033, disc_loss = 0.07986651775959347
Trained batch 700 in epoch 3, gen_loss = 0.8364917534309175, disc_loss = 0.08001982619303057
Trained batch 701 in epoch 3, gen_loss = 0.8363265982295713, disc_loss = 0.0799901337426506
Trained batch 702 in epoch 3, gen_loss = 0.8358760312051217, disc_loss = 0.08014274030727775
Trained batch 703 in epoch 3, gen_loss = 0.8361737353473224, disc_loss = 0.08020255267381965
Trained batch 704 in epoch 3, gen_loss = 0.8359743674173423, disc_loss = 0.08024810824596079
Trained batch 705 in epoch 3, gen_loss = 0.8358108127336664, disc_loss = 0.08040161959948308
Trained batch 706 in epoch 3, gen_loss = 0.8357996324754334, disc_loss = 0.08042587297066224
Trained batch 707 in epoch 3, gen_loss = 0.835665850694907, disc_loss = 0.08037733526947766
Trained batch 708 in epoch 3, gen_loss = 0.8356259773329048, disc_loss = 0.0804033793117562
Trained batch 709 in epoch 3, gen_loss = 0.8357283256843057, disc_loss = 0.08034502537396382
Trained batch 710 in epoch 3, gen_loss = 0.8357330229128128, disc_loss = 0.08034785463751075
Trained batch 711 in epoch 3, gen_loss = 0.8358994309235824, disc_loss = 0.08027348220165233
Trained batch 712 in epoch 3, gen_loss = 0.835849442664236, disc_loss = 0.08021814298396734
Trained batch 713 in epoch 3, gen_loss = 0.8361326423095388, disc_loss = 0.0801318369464067
Trained batch 714 in epoch 3, gen_loss = 0.8361232393688255, disc_loss = 0.08005251155423743
Trained batch 715 in epoch 3, gen_loss = 0.8358636064319637, disc_loss = 0.08005450344800574
Trained batch 716 in epoch 3, gen_loss = 0.8360853749255921, disc_loss = 0.080133242268931
Trained batch 717 in epoch 3, gen_loss = 0.8357200816398211, disc_loss = 0.08015114420111756
Trained batch 718 in epoch 3, gen_loss = 0.8358598129722771, disc_loss = 0.08009864493391071
Trained batch 719 in epoch 3, gen_loss = 0.83556865275734, disc_loss = 0.08016880160689147
Trained batch 720 in epoch 3, gen_loss = 0.8356987349120655, disc_loss = 0.08023875096009402
Trained batch 721 in epoch 3, gen_loss = 0.8358673078118929, disc_loss = 0.0801801560511116
Trained batch 722 in epoch 3, gen_loss = 0.8356706457596432, disc_loss = 0.08014444175097746
Trained batch 723 in epoch 3, gen_loss = 0.8355024168422209, disc_loss = 0.08010449881912389
Trained batch 724 in epoch 3, gen_loss = 0.8360412432818577, disc_loss = 0.08007658567279577
Trained batch 725 in epoch 3, gen_loss = 0.836251777188837, disc_loss = 0.0799871101287853
Trained batch 726 in epoch 3, gen_loss = 0.8360375005654489, disc_loss = 0.07997005539939853
Trained batch 727 in epoch 3, gen_loss = 0.8361852843273472, disc_loss = 0.07997667507503878
Trained batch 728 in epoch 3, gen_loss = 0.836245594814481, disc_loss = 0.07989957643511855
Trained batch 729 in epoch 3, gen_loss = 0.8358984945163335, disc_loss = 0.07994936576036558
Trained batch 730 in epoch 3, gen_loss = 0.8359991742142574, disc_loss = 0.07987948849022633
Trained batch 731 in epoch 3, gen_loss = 0.8359964008295471, disc_loss = 0.07991160161772876
Trained batch 732 in epoch 3, gen_loss = 0.8357610766347726, disc_loss = 0.07990902187086713
Trained batch 733 in epoch 3, gen_loss = 0.8355166712719998, disc_loss = 0.07986556903563176
Trained batch 734 in epoch 3, gen_loss = 0.8359258475352307, disc_loss = 0.07988109842550997
Trained batch 735 in epoch 3, gen_loss = 0.8361656894583417, disc_loss = 0.07984859328818224
Trained batch 736 in epoch 3, gen_loss = 0.8359385107314086, disc_loss = 0.079896259830514
Trained batch 737 in epoch 3, gen_loss = 0.8355763308643326, disc_loss = 0.07999723498030568
Trained batch 738 in epoch 3, gen_loss = 0.8363316560388417, disc_loss = 0.08017830998814476
Trained batch 739 in epoch 3, gen_loss = 0.8361163805868175, disc_loss = 0.08016879440260094
Trained batch 740 in epoch 3, gen_loss = 0.8359934432223419, disc_loss = 0.0801189465450774
Trained batch 741 in epoch 3, gen_loss = 0.8358245151785185, disc_loss = 0.08013315379840505
Trained batch 742 in epoch 3, gen_loss = 0.8359712465374177, disc_loss = 0.08013095842576605
Trained batch 743 in epoch 3, gen_loss = 0.8358856017791456, disc_loss = 0.08016767217126745
Trained batch 744 in epoch 3, gen_loss = 0.8356251926630135, disc_loss = 0.08014709679972405
Trained batch 745 in epoch 3, gen_loss = 0.8356464809211266, disc_loss = 0.08015155365276112
Trained batch 746 in epoch 3, gen_loss = 0.8357428938270094, disc_loss = 0.08010679929750351
Trained batch 747 in epoch 3, gen_loss = 0.8355771651800303, disc_loss = 0.08012693585021133
Trained batch 748 in epoch 3, gen_loss = 0.8360332173801391, disc_loss = 0.08012312490030507
Trained batch 749 in epoch 3, gen_loss = 0.8361057493289312, disc_loss = 0.08006581096847852
Trained batch 750 in epoch 3, gen_loss = 0.8357837426757686, disc_loss = 0.08013419708740536
Trained batch 751 in epoch 3, gen_loss = 0.836424066467171, disc_loss = 0.08025349536910653
Trained batch 752 in epoch 3, gen_loss = 0.836555970102984, disc_loss = 0.08019378186162725
Trained batch 753 in epoch 3, gen_loss = 0.8363324144079451, disc_loss = 0.08020474931190595
Trained batch 754 in epoch 3, gen_loss = 0.8363177400156362, disc_loss = 0.0801357203564107
Trained batch 755 in epoch 3, gen_loss = 0.8361177160232155, disc_loss = 0.08014023625267246
Trained batch 756 in epoch 3, gen_loss = 0.8365089603191638, disc_loss = 0.08018899310375299
Trained batch 757 in epoch 3, gen_loss = 0.8366372856977432, disc_loss = 0.0801498961627562
Trained batch 758 in epoch 3, gen_loss = 0.8362433572296097, disc_loss = 0.08026640432762848
Trained batch 759 in epoch 3, gen_loss = 0.8359112917200515, disc_loss = 0.08031644188357812
Trained batch 760 in epoch 3, gen_loss = 0.8360030812048568, disc_loss = 0.08025207690179896
Trained batch 761 in epoch 3, gen_loss = 0.8365603868025807, disc_loss = 0.08046252254562897
Trained batch 762 in epoch 3, gen_loss = 0.8361580207416615, disc_loss = 0.0805608072753893
Trained batch 763 in epoch 3, gen_loss = 0.8363244897486027, disc_loss = 0.08050358981498718
Trained batch 764 in epoch 3, gen_loss = 0.8363153038850797, disc_loss = 0.0804526313555007
Trained batch 765 in epoch 3, gen_loss = 0.8363164114345147, disc_loss = 0.08049668831745888
Trained batch 766 in epoch 3, gen_loss = 0.8360406627011578, disc_loss = 0.0805015232817135
Trained batch 767 in epoch 3, gen_loss = 0.8359963860129938, disc_loss = 0.08044579212825435
Trained batch 768 in epoch 3, gen_loss = 0.8361559568750533, disc_loss = 0.08036947355003754
Trained batch 769 in epoch 3, gen_loss = 0.8361656000474831, disc_loss = 0.08028185957099324
Trained batch 770 in epoch 3, gen_loss = 0.8361968346684204, disc_loss = 0.0802243894615951
Trained batch 771 in epoch 3, gen_loss = 0.8359408926392466, disc_loss = 0.08022233691076154
Trained batch 772 in epoch 3, gen_loss = 0.8361374108556943, disc_loss = 0.08015796966021844
Trained batch 773 in epoch 3, gen_loss = 0.8363689433311615, disc_loss = 0.08010088155426336
Trained batch 774 in epoch 3, gen_loss = 0.8360076697795622, disc_loss = 0.08014402532529447
Trained batch 775 in epoch 3, gen_loss = 0.8361070713354755, disc_loss = 0.0800798053003502
Trained batch 776 in epoch 3, gen_loss = 0.8362227940267885, disc_loss = 0.08001690040770415
Trained batch 777 in epoch 3, gen_loss = 0.8358925415878125, disc_loss = 0.08001633772056713
Trained batch 778 in epoch 3, gen_loss = 0.8362136369568699, disc_loss = 0.08006634656220331
Trained batch 779 in epoch 3, gen_loss = 0.8361671038545095, disc_loss = 0.08000106331772912
Trained batch 780 in epoch 3, gen_loss = 0.8360237887894756, disc_loss = 0.07995738315893272
Trained batch 781 in epoch 3, gen_loss = 0.835587269243072, disc_loss = 0.08002174197627074
Trained batch 782 in epoch 3, gen_loss = 0.8359924069537971, disc_loss = 0.07998622257124495
Trained batch 783 in epoch 3, gen_loss = 0.8362344993392423, disc_loss = 0.08007097162296806
Trained batch 784 in epoch 3, gen_loss = 0.8359245133627752, disc_loss = 0.08014487861210753
Trained batch 785 in epoch 3, gen_loss = 0.8358201724654846, disc_loss = 0.08009587920984164
Trained batch 786 in epoch 3, gen_loss = 0.8357528160684748, disc_loss = 0.08007490679176744
Trained batch 787 in epoch 3, gen_loss = 0.8357749899404908, disc_loss = 0.0800457758814815
Trained batch 788 in epoch 3, gen_loss = 0.8356509651747946, disc_loss = 0.07998964079290968
Trained batch 789 in epoch 3, gen_loss = 0.8354100897719589, disc_loss = 0.07994139322987463
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.7507951259613037, disc_loss = 0.04663893207907677
Trained batch 1 in epoch 4, gen_loss = 0.8257044553756714, disc_loss = 0.0327090322971344
Trained batch 2 in epoch 4, gen_loss = 0.7425589362780253, disc_loss = 0.0664009153842926
Trained batch 3 in epoch 4, gen_loss = 0.8341701775789261, disc_loss = 0.09509481489658356
Trained batch 4 in epoch 4, gen_loss = 0.8227800726890564, disc_loss = 0.0883925199508667
Trained batch 5 in epoch 4, gen_loss = 0.7688435663779577, disc_loss = 0.09538192550341289
Trained batch 6 in epoch 4, gen_loss = 0.786321005650929, disc_loss = 0.09267649480274745
Trained batch 7 in epoch 4, gen_loss = 0.7860317789018154, disc_loss = 0.0900917612016201
Trained batch 8 in epoch 4, gen_loss = 0.7964960568481021, disc_loss = 0.0833424727121989
Trained batch 9 in epoch 4, gen_loss = 0.8142633408308029, disc_loss = 0.08146905601024627
Trained batch 10 in epoch 4, gen_loss = 0.8159790987318213, disc_loss = 0.07941773262890903
Trained batch 11 in epoch 4, gen_loss = 0.8073504840334257, disc_loss = 0.07957156623403232
Trained batch 12 in epoch 4, gen_loss = 0.825119823217392, disc_loss = 0.08406973916750687
Trained batch 13 in epoch 4, gen_loss = 0.8236988548721585, disc_loss = 0.08770731730120522
Trained batch 14 in epoch 4, gen_loss = 0.8103233357270558, disc_loss = 0.08586895515521367
Trained batch 15 in epoch 4, gen_loss = 0.8040379900485277, disc_loss = 0.08399384515359998
Trained batch 16 in epoch 4, gen_loss = 0.8080192260882434, disc_loss = 0.08008910474531791
Trained batch 17 in epoch 4, gen_loss = 0.8179240077733994, disc_loss = 0.07730734244816834
Trained batch 18 in epoch 4, gen_loss = 0.8140006363391876, disc_loss = 0.07485031581630833
Trained batch 19 in epoch 4, gen_loss = 0.8182510390877724, disc_loss = 0.07354898201301693
Trained batch 20 in epoch 4, gen_loss = 0.8279358957495008, disc_loss = 0.07051207506585688
Trained batch 21 in epoch 4, gen_loss = 0.8283927670933984, disc_loss = 0.06799351381645961
Trained batch 22 in epoch 4, gen_loss = 0.8377664827782175, disc_loss = 0.06555614037358243
Trained batch 23 in epoch 4, gen_loss = 0.8438773341476917, disc_loss = 0.06731160171329975
Trained batch 24 in epoch 4, gen_loss = 0.8316338694095612, disc_loss = 0.07797231018543244
Trained batch 25 in epoch 4, gen_loss = 0.827985345171048, disc_loss = 0.07758987351105763
Trained batch 26 in epoch 4, gen_loss = 0.8441316496442866, disc_loss = 0.08209669755564795
Trained batch 27 in epoch 4, gen_loss = 0.8494189519967351, disc_loss = 0.0820134316704103
Trained batch 28 in epoch 4, gen_loss = 0.8422978284030125, disc_loss = 0.08321240056177666
Trained batch 29 in epoch 4, gen_loss = 0.8345796157916386, disc_loss = 0.08524653588732084
Trained batch 30 in epoch 4, gen_loss = 0.8348643212549148, disc_loss = 0.08526460081338882
Trained batch 31 in epoch 4, gen_loss = 0.8342272685840726, disc_loss = 0.08363225671928376
Trained batch 32 in epoch 4, gen_loss = 0.834669440984726, disc_loss = 0.0831223192314307
Trained batch 33 in epoch 4, gen_loss = 0.8380699429441901, disc_loss = 0.08156269350472618
Trained batch 34 in epoch 4, gen_loss = 0.8323083698749543, disc_loss = 0.08275151486907686
Trained batch 35 in epoch 4, gen_loss = 0.8426003745860524, disc_loss = 0.08531142709155877
Trained batch 36 in epoch 4, gen_loss = 0.8454030873002233, disc_loss = 0.0833514714361848
Trained batch 37 in epoch 4, gen_loss = 0.8414920905702993, disc_loss = 0.08269371288387399
Trained batch 38 in epoch 4, gen_loss = 0.8386795176909521, disc_loss = 0.08280076716954891
Trained batch 39 in epoch 4, gen_loss = 0.835560891777277, disc_loss = 0.0823547838255763
Trained batch 40 in epoch 4, gen_loss = 0.836649436049345, disc_loss = 0.08216082649986918
Trained batch 41 in epoch 4, gen_loss = 0.8361950438647043, disc_loss = 0.08120888790913991
Trained batch 42 in epoch 4, gen_loss = 0.8387921057468237, disc_loss = 0.0795531295846368
Trained batch 43 in epoch 4, gen_loss = 0.8345383358272639, disc_loss = 0.07858348371122371
Trained batch 44 in epoch 4, gen_loss = 0.8387786818875207, disc_loss = 0.07712732470697826
Trained batch 45 in epoch 4, gen_loss = 0.8441634988007338, disc_loss = 0.07601628375604101
Trained batch 46 in epoch 4, gen_loss = 0.8382394497698926, disc_loss = 0.07670455429940781
Trained batch 47 in epoch 4, gen_loss = 0.8406293820589781, disc_loss = 0.07695014871812116
Trained batch 48 in epoch 4, gen_loss = 0.8380615911921676, disc_loss = 0.07710721423583371
Trained batch 49 in epoch 4, gen_loss = 0.8399071425199509, disc_loss = 0.07735735405236482
Trained batch 50 in epoch 4, gen_loss = 0.8334990733978795, disc_loss = 0.07910306244065948
Trained batch 51 in epoch 4, gen_loss = 0.8421229966557943, disc_loss = 0.07959725052261582
Trained batch 52 in epoch 4, gen_loss = 0.8377561439883034, disc_loss = 0.07902802678071102
Trained batch 53 in epoch 4, gen_loss = 0.8352791429669769, disc_loss = 0.07937658988629226
Trained batch 54 in epoch 4, gen_loss = 0.8360731682994149, disc_loss = 0.07899669947271998
Trained batch 55 in epoch 4, gen_loss = 0.8337581492960453, disc_loss = 0.07830799141499613
Trained batch 56 in epoch 4, gen_loss = 0.8391793500958827, disc_loss = 0.07871738138298194
Trained batch 57 in epoch 4, gen_loss = 0.8336784937258425, disc_loss = 0.08156697384627729
Trained batch 58 in epoch 4, gen_loss = 0.8354805379600848, disc_loss = 0.08206535683218706
Trained batch 59 in epoch 4, gen_loss = 0.8368991161386172, disc_loss = 0.08141547959918777
Trained batch 60 in epoch 4, gen_loss = 0.8346205485648797, disc_loss = 0.081844244793546
Trained batch 61 in epoch 4, gen_loss = 0.8347468419421104, disc_loss = 0.08145842289612178
Trained batch 62 in epoch 4, gen_loss = 0.835767103093011, disc_loss = 0.08079765994279157
Trained batch 63 in epoch 4, gen_loss = 0.8354641576297581, disc_loss = 0.08015758215333335
Trained batch 64 in epoch 4, gen_loss = 0.8366531413335067, disc_loss = 0.07936013289369069
Trained batch 65 in epoch 4, gen_loss = 0.8335825317736828, disc_loss = 0.08005785236530231
Trained batch 66 in epoch 4, gen_loss = 0.8368789727118477, disc_loss = 0.07956380335919892
Trained batch 67 in epoch 4, gen_loss = 0.8370118443580234, disc_loss = 0.07868396805818467
Trained batch 68 in epoch 4, gen_loss = 0.835279294114182, disc_loss = 0.07886125997680685
Trained batch 69 in epoch 4, gen_loss = 0.8379483669996262, disc_loss = 0.07841707385544266
Trained batch 70 in epoch 4, gen_loss = 0.8410280225142627, disc_loss = 0.07841072349586117
Trained batch 71 in epoch 4, gen_loss = 0.8381472167869409, disc_loss = 0.07875128672458231
Trained batch 72 in epoch 4, gen_loss = 0.8377937711264989, disc_loss = 0.07820721524321053
Trained batch 73 in epoch 4, gen_loss = 0.8373675583987623, disc_loss = 0.07831306123753658
Trained batch 74 in epoch 4, gen_loss = 0.8414561156431833, disc_loss = 0.07958934279779593
Trained batch 75 in epoch 4, gen_loss = 0.8412143490032146, disc_loss = 0.07954709498996013
Trained batch 76 in epoch 4, gen_loss = 0.8386693585228611, disc_loss = 0.07989408910371266
Trained batch 77 in epoch 4, gen_loss = 0.8412397591731487, disc_loss = 0.0797308185018408
Trained batch 78 in epoch 4, gen_loss = 0.8417105655881423, disc_loss = 0.07908307612413847
Trained batch 79 in epoch 4, gen_loss = 0.840479477122426, disc_loss = 0.07893353023100644
Trained batch 80 in epoch 4, gen_loss = 0.8369998920846868, disc_loss = 0.07946334358442712
Trained batch 81 in epoch 4, gen_loss = 0.834099415962289, disc_loss = 0.08010638125876827
Trained batch 82 in epoch 4, gen_loss = 0.8353660821196545, disc_loss = 0.08027447780302491
Trained batch 83 in epoch 4, gen_loss = 0.8357238226703235, disc_loss = 0.07963455444024432
Trained batch 84 in epoch 4, gen_loss = 0.8329566938035629, disc_loss = 0.08032811768352985
Trained batch 85 in epoch 4, gen_loss = 0.8337869030791659, disc_loss = 0.08023489433405705
Trained batch 86 in epoch 4, gen_loss = 0.8364262577446028, disc_loss = 0.08052157844020717
Trained batch 87 in epoch 4, gen_loss = 0.8345349536023356, disc_loss = 0.08036564114842225
Trained batch 88 in epoch 4, gen_loss = 0.8319610923193814, disc_loss = 0.08033896423876286
Trained batch 89 in epoch 4, gen_loss = 0.8347346362140443, disc_loss = 0.08053351576543516
Trained batch 90 in epoch 4, gen_loss = 0.8327240377337068, disc_loss = 0.08083607700581734
Trained batch 91 in epoch 4, gen_loss = 0.8311324518011964, disc_loss = 0.08098788059357068
Trained batch 92 in epoch 4, gen_loss = 0.8312596553756345, disc_loss = 0.08067063857070221
Trained batch 93 in epoch 4, gen_loss = 0.8332722462872242, disc_loss = 0.08008724262819011
Trained batch 94 in epoch 4, gen_loss = 0.8331080960599999, disc_loss = 0.07972518889919708
Trained batch 95 in epoch 4, gen_loss = 0.832848365418613, disc_loss = 0.07923189292584236
Trained batch 96 in epoch 4, gen_loss = 0.8345328277533817, disc_loss = 0.07869263029820525
Trained batch 97 in epoch 4, gen_loss = 0.8338104386110695, disc_loss = 0.07870283135574083
Trained batch 98 in epoch 4, gen_loss = 0.8325142767092194, disc_loss = 0.07893981278469467
Trained batch 99 in epoch 4, gen_loss = 0.8328777971863747, disc_loss = 0.07847088271752
Trained batch 100 in epoch 4, gen_loss = 0.8354764931862897, disc_loss = 0.07786532976470961
Trained batch 101 in epoch 4, gen_loss = 0.8368381440055137, disc_loss = 0.07777935797896456
Trained batch 102 in epoch 4, gen_loss = 0.8371684964999412, disc_loss = 0.07759231450126587
Trained batch 103 in epoch 4, gen_loss = 0.8373367743423352, disc_loss = 0.07708229550805229
Trained batch 104 in epoch 4, gen_loss = 0.8359376569588979, disc_loss = 0.07731022263566653
Trained batch 105 in epoch 4, gen_loss = 0.8385199513637794, disc_loss = 0.07724537408717398
Trained batch 106 in epoch 4, gen_loss = 0.8390477274622873, disc_loss = 0.07687856096809155
Trained batch 107 in epoch 4, gen_loss = 0.839859654781995, disc_loss = 0.07649452404843436
Trained batch 108 in epoch 4, gen_loss = 0.8389446885760771, disc_loss = 0.07629147848678292
Trained batch 109 in epoch 4, gen_loss = 0.8398020519451661, disc_loss = 0.07576920109039004
Trained batch 110 in epoch 4, gen_loss = 0.8428157173298501, disc_loss = 0.07539978667019724
Trained batch 111 in epoch 4, gen_loss = 0.8463129978626966, disc_loss = 0.07579850874442075
Trained batch 112 in epoch 4, gen_loss = 0.8454452122734711, disc_loss = 0.07580974233229604
Trained batch 113 in epoch 4, gen_loss = 0.8445462728278679, disc_loss = 0.07594502635561583
Trained batch 114 in epoch 4, gen_loss = 0.8444022217522497, disc_loss = 0.07641797982480215
Trained batch 115 in epoch 4, gen_loss = 0.8434753394846258, disc_loss = 0.07624081091891075
Trained batch 116 in epoch 4, gen_loss = 0.8440989232980288, disc_loss = 0.0761478929183422
Trained batch 117 in epoch 4, gen_loss = 0.8423564583063126, disc_loss = 0.0764494566089016
Trained batch 118 in epoch 4, gen_loss = 0.8412052731053168, disc_loss = 0.0768342995468308
Trained batch 119 in epoch 4, gen_loss = 0.8438589729368686, disc_loss = 0.07695662596573433
Trained batch 120 in epoch 4, gen_loss = 0.8435610786449811, disc_loss = 0.0767240915293536
Trained batch 121 in epoch 4, gen_loss = 0.8438009978806387, disc_loss = 0.07661528048700973
Trained batch 122 in epoch 4, gen_loss = 0.8421153932567534, disc_loss = 0.0768734998698157
Trained batch 123 in epoch 4, gen_loss = 0.8453256206647042, disc_loss = 0.07977630360232245
Trained batch 124 in epoch 4, gen_loss = 0.8451498777866363, disc_loss = 0.08043536800146103
Trained batch 125 in epoch 4, gen_loss = 0.8445453234608211, disc_loss = 0.08036819863177481
Trained batch 126 in epoch 4, gen_loss = 0.8444875237040632, disc_loss = 0.0800057600626326
Trained batch 127 in epoch 4, gen_loss = 0.8420271680224687, disc_loss = 0.08052363505703397
Trained batch 128 in epoch 4, gen_loss = 0.8434142560459846, disc_loss = 0.08160854451531588
Trained batch 129 in epoch 4, gen_loss = 0.8408760990087802, disc_loss = 0.08176775497312729
Trained batch 130 in epoch 4, gen_loss = 0.839657055740138, disc_loss = 0.08156028557710975
Trained batch 131 in epoch 4, gen_loss = 0.8389680351723324, disc_loss = 0.08207774622309388
Trained batch 132 in epoch 4, gen_loss = 0.8382053780824619, disc_loss = 0.08184718130562539
Trained batch 133 in epoch 4, gen_loss = 0.83740666441953, disc_loss = 0.08165990944896172
Trained batch 134 in epoch 4, gen_loss = 0.8367464725618009, disc_loss = 0.08159651154721224
Trained batch 135 in epoch 4, gen_loss = 0.8396007933599108, disc_loss = 0.0819214423022726
Trained batch 136 in epoch 4, gen_loss = 0.8387797916457601, disc_loss = 0.08169254644291245
Trained batch 137 in epoch 4, gen_loss = 0.8372826012580291, disc_loss = 0.08164349452093028
Trained batch 138 in epoch 4, gen_loss = 0.8374769706949056, disc_loss = 0.08122023081125544
Trained batch 139 in epoch 4, gen_loss = 0.83693803442376, disc_loss = 0.08106572097167372
Trained batch 140 in epoch 4, gen_loss = 0.8359799032092939, disc_loss = 0.08081780525968008
Trained batch 141 in epoch 4, gen_loss = 0.8350580764908186, disc_loss = 0.0805095882928917
Trained batch 142 in epoch 4, gen_loss = 0.8353536702119387, disc_loss = 0.08034765096446433
Trained batch 143 in epoch 4, gen_loss = 0.8354965549790196, disc_loss = 0.08014023111253563
Trained batch 144 in epoch 4, gen_loss = 0.8339006524661492, disc_loss = 0.08029703306483811
Trained batch 145 in epoch 4, gen_loss = 0.8352923607581282, disc_loss = 0.07997180359463578
Trained batch 146 in epoch 4, gen_loss = 0.8374169661479742, disc_loss = 0.08039409288388936
Trained batch 147 in epoch 4, gen_loss = 0.8369704060055114, disc_loss = 0.08002828013755985
Trained batch 148 in epoch 4, gen_loss = 0.8360860765780378, disc_loss = 0.08066093244108578
Trained batch 149 in epoch 4, gen_loss = 0.8363654226064682, disc_loss = 0.08036514893174171
Trained batch 150 in epoch 4, gen_loss = 0.837296803068641, disc_loss = 0.08040967336948344
Trained batch 151 in epoch 4, gen_loss = 0.8381346007318873, disc_loss = 0.08002689214864452
Trained batch 152 in epoch 4, gen_loss = 0.8364922137431849, disc_loss = 0.08012880490837145
Trained batch 153 in epoch 4, gen_loss = 0.8362053325036903, disc_loss = 0.08007217226429032
Trained batch 154 in epoch 4, gen_loss = 0.835045079838845, disc_loss = 0.08014499774623302
Trained batch 155 in epoch 4, gen_loss = 0.8370489621391664, disc_loss = 0.08010781497861712
Trained batch 156 in epoch 4, gen_loss = 0.8374819131034195, disc_loss = 0.08004188645559891
Trained batch 157 in epoch 4, gen_loss = 0.837971322710001, disc_loss = 0.07974490970137375
Trained batch 158 in epoch 4, gen_loss = 0.8354107252081985, disc_loss = 0.08089378470285509
Trained batch 159 in epoch 4, gen_loss = 0.8354976465925574, disc_loss = 0.0807221132912673
Trained batch 160 in epoch 4, gen_loss = 0.8353232036095969, disc_loss = 0.08036908995568381
Trained batch 161 in epoch 4, gen_loss = 0.8353380849699915, disc_loss = 0.08008718046785136
Trained batch 162 in epoch 4, gen_loss = 0.8348096519525797, disc_loss = 0.08030859950038553
Trained batch 163 in epoch 4, gen_loss = 0.8345022236065167, disc_loss = 0.07999876600394888
Trained batch 164 in epoch 4, gen_loss = 0.8339741632793889, disc_loss = 0.07966060743413188
Trained batch 165 in epoch 4, gen_loss = 0.8334774409072945, disc_loss = 0.07979620760867753
Trained batch 166 in epoch 4, gen_loss = 0.8354837664230141, disc_loss = 0.07989746360052488
Trained batch 167 in epoch 4, gen_loss = 0.8343364637167681, disc_loss = 0.08024325497847583
Trained batch 168 in epoch 4, gen_loss = 0.8347007803310303, disc_loss = 0.07993015811155886
Trained batch 169 in epoch 4, gen_loss = 0.8356010396690929, disc_loss = 0.07958873169606223
Trained batch 170 in epoch 4, gen_loss = 0.8350043514667199, disc_loss = 0.07949613863656745
Trained batch 171 in epoch 4, gen_loss = 0.8339827305009199, disc_loss = 0.07943416920728809
Trained batch 172 in epoch 4, gen_loss = 0.8332402504592962, disc_loss = 0.07939241384021464
Trained batch 173 in epoch 4, gen_loss = 0.8338718076889542, disc_loss = 0.08175636156751163
Trained batch 174 in epoch 4, gen_loss = 0.833153863464083, disc_loss = 0.08200082626725946
Trained batch 175 in epoch 4, gen_loss = 0.8327656911516731, disc_loss = 0.08190652390476316
Trained batch 176 in epoch 4, gen_loss = 0.8325922463910055, disc_loss = 0.08174577583743017
Trained batch 177 in epoch 4, gen_loss = 0.8320039565978425, disc_loss = 0.08160604564786962
Trained batch 178 in epoch 4, gen_loss = 0.8307268181659656, disc_loss = 0.08194774800297601
Trained batch 179 in epoch 4, gen_loss = 0.830206476814217, disc_loss = 0.08205033908080724
Trained batch 180 in epoch 4, gen_loss = 0.8323836700363054, disc_loss = 0.08258955529505048
Trained batch 181 in epoch 4, gen_loss = 0.8312625621373837, disc_loss = 0.08284971194730682
Trained batch 182 in epoch 4, gen_loss = 0.8305519140157543, disc_loss = 0.08288053259294216
Trained batch 183 in epoch 4, gen_loss = 0.8310493637362252, disc_loss = 0.08318846983551655
Trained batch 184 in epoch 4, gen_loss = 0.8310047956737312, disc_loss = 0.08284997347037534
Trained batch 185 in epoch 4, gen_loss = 0.8310320241156445, disc_loss = 0.08260684555536636
Trained batch 186 in epoch 4, gen_loss = 0.8310200704291543, disc_loss = 0.08248752892455634
Trained batch 187 in epoch 4, gen_loss = 0.8301071291591259, disc_loss = 0.08247708171566433
Trained batch 188 in epoch 4, gen_loss = 0.8308140400540892, disc_loss = 0.0824926832503585
Trained batch 189 in epoch 4, gen_loss = 0.8313324967497273, disc_loss = 0.08236370371948731
Trained batch 190 in epoch 4, gen_loss = 0.8300204259874933, disc_loss = 0.08245274119313163
Trained batch 191 in epoch 4, gen_loss = 0.8303928805204729, disc_loss = 0.08227993496499646
Trained batch 192 in epoch 4, gen_loss = 0.8302982784614662, disc_loss = 0.08248895888308479
Trained batch 193 in epoch 4, gen_loss = 0.8296212635396683, disc_loss = 0.08261396892407198
Trained batch 194 in epoch 4, gen_loss = 0.8295289218425751, disc_loss = 0.08237452410543576
Trained batch 195 in epoch 4, gen_loss = 0.8286274691321411, disc_loss = 0.08251727766794514
Trained batch 196 in epoch 4, gen_loss = 0.8283757807942211, disc_loss = 0.0823086461496686
Trained batch 197 in epoch 4, gen_loss = 0.82807798232093, disc_loss = 0.08218559014112359
Trained batch 198 in epoch 4, gen_loss = 0.8278028049960209, disc_loss = 0.0821155284685855
Trained batch 199 in epoch 4, gen_loss = 0.8308201839029788, disc_loss = 0.08234409582801164
Trained batch 200 in epoch 4, gen_loss = 0.830340358896635, disc_loss = 0.08243868500920967
Trained batch 201 in epoch 4, gen_loss = 0.830747863296235, disc_loss = 0.08287180832006258
Trained batch 202 in epoch 4, gen_loss = 0.8295669345726521, disc_loss = 0.08342195031568041
Trained batch 203 in epoch 4, gen_loss = 0.8292210693745052, disc_loss = 0.08331419820623363
Trained batch 204 in epoch 4, gen_loss = 0.8296337501304906, disc_loss = 0.08319859147617002
Trained batch 205 in epoch 4, gen_loss = 0.8298596984263763, disc_loss = 0.08294881434514395
Trained batch 206 in epoch 4, gen_loss = 0.8295964833330993, disc_loss = 0.08275589173218766
Trained batch 207 in epoch 4, gen_loss = 0.8311407974419686, disc_loss = 0.08280354597641584
Trained batch 208 in epoch 4, gen_loss = 0.8304543217118276, disc_loss = 0.08282891029055324
Trained batch 209 in epoch 4, gen_loss = 0.8301899772314798, disc_loss = 0.08271840132240738
Trained batch 210 in epoch 4, gen_loss = 0.8300382182778905, disc_loss = 0.08255905731276596
Trained batch 211 in epoch 4, gen_loss = 0.8291733291632725, disc_loss = 0.08260581167063343
Trained batch 212 in epoch 4, gen_loss = 0.8313276732751461, disc_loss = 0.08292026498612944
Trained batch 213 in epoch 4, gen_loss = 0.8302488289425306, disc_loss = 0.0828058227948914
Trained batch 214 in epoch 4, gen_loss = 0.8295872814433519, disc_loss = 0.08254936864209729
Trained batch 215 in epoch 4, gen_loss = 0.8313955746039197, disc_loss = 0.08241404104908859
Trained batch 216 in epoch 4, gen_loss = 0.8315424044286052, disc_loss = 0.08208926301449537
Trained batch 217 in epoch 4, gen_loss = 0.8305600743501558, disc_loss = 0.08234869180794019
Trained batch 218 in epoch 4, gen_loss = 0.8315666771098359, disc_loss = 0.08316919416376309
Trained batch 219 in epoch 4, gen_loss = 0.8303270002657717, disc_loss = 0.0831926453308287
Trained batch 220 in epoch 4, gen_loss = 0.829478764560967, disc_loss = 0.08312382034502283
Trained batch 221 in epoch 4, gen_loss = 0.8289537533177985, disc_loss = 0.08291019257241944
Trained batch 222 in epoch 4, gen_loss = 0.8303029992922539, disc_loss = 0.08331000336734035
Trained batch 223 in epoch 4, gen_loss = 0.830473822807627, disc_loss = 0.08322158798026587
Trained batch 224 in epoch 4, gen_loss = 0.8291321016682519, disc_loss = 0.08376071992433734
Trained batch 225 in epoch 4, gen_loss = 0.8293913522389083, disc_loss = 0.0835903459475829
Trained batch 226 in epoch 4, gen_loss = 0.8288385998047396, disc_loss = 0.08342344510381311
Trained batch 227 in epoch 4, gen_loss = 0.829434251968275, disc_loss = 0.08342975374360226
Trained batch 228 in epoch 4, gen_loss = 0.8301287245281919, disc_loss = 0.08311083386997858
Trained batch 229 in epoch 4, gen_loss = 0.8300435305937477, disc_loss = 0.08290014052763581
Trained batch 230 in epoch 4, gen_loss = 0.8291389659627691, disc_loss = 0.08302179346207804
Trained batch 231 in epoch 4, gen_loss = 0.8282960762494597, disc_loss = 0.08297425575538314
Trained batch 232 in epoch 4, gen_loss = 0.8292970847930008, disc_loss = 0.08272098320987988
Trained batch 233 in epoch 4, gen_loss = 0.8288027135989605, disc_loss = 0.08268074515777138
Trained batch 234 in epoch 4, gen_loss = 0.8287938629059082, disc_loss = 0.08240780252963305
Trained batch 235 in epoch 4, gen_loss = 0.8302463746424449, disc_loss = 0.08214385841846845
Trained batch 236 in epoch 4, gen_loss = 0.8299464418666775, disc_loss = 0.08198233973234892
Trained batch 237 in epoch 4, gen_loss = 0.830300086811811, disc_loss = 0.08183444591489535
Trained batch 238 in epoch 4, gen_loss = 0.8303035658523129, disc_loss = 0.08164344177382636
Trained batch 239 in epoch 4, gen_loss = 0.8293435125301282, disc_loss = 0.08170828277167554
Trained batch 240 in epoch 4, gen_loss = 0.8299421075716058, disc_loss = 0.08149191285425574
Trained batch 241 in epoch 4, gen_loss = 0.8293953999753826, disc_loss = 0.08167795239262714
Trained batch 242 in epoch 4, gen_loss = 0.8288159908826459, disc_loss = 0.0816599950462641
Trained batch 243 in epoch 4, gen_loss = 0.8294250653659712, disc_loss = 0.08147121718168625
Trained batch 244 in epoch 4, gen_loss = 0.8294370944402656, disc_loss = 0.0812202111836903
Trained batch 245 in epoch 4, gen_loss = 0.8292238178049646, disc_loss = 0.08104448665948055
Trained batch 246 in epoch 4, gen_loss = 0.8296221336613783, disc_loss = 0.08082672616896722
Trained batch 247 in epoch 4, gen_loss = 0.830114384932864, disc_loss = 0.08075118875656757
Trained batch 248 in epoch 4, gen_loss = 0.8294127666088472, disc_loss = 0.08078370024506228
Trained batch 249 in epoch 4, gen_loss = 0.8306542690992356, disc_loss = 0.08083126812800764
Trained batch 250 in epoch 4, gen_loss = 0.8314102625704382, disc_loss = 0.0807036913122492
Trained batch 251 in epoch 4, gen_loss = 0.8300234978161161, disc_loss = 0.08132864181174054
Trained batch 252 in epoch 4, gen_loss = 0.8292290867552927, disc_loss = 0.08130971726265702
Trained batch 253 in epoch 4, gen_loss = 0.830442658090216, disc_loss = 0.08155383296882895
Trained batch 254 in epoch 4, gen_loss = 0.8295122212054683, disc_loss = 0.0818041092442239
Trained batch 255 in epoch 4, gen_loss = 0.8301984048448503, disc_loss = 0.08176770944191958
Trained batch 256 in epoch 4, gen_loss = 0.8297703108435011, disc_loss = 0.08171563834343323
Trained batch 257 in epoch 4, gen_loss = 0.8296480804912804, disc_loss = 0.08165592877483067
Trained batch 258 in epoch 4, gen_loss = 0.8309530795310915, disc_loss = 0.08249964100096562
Trained batch 259 in epoch 4, gen_loss = 0.8302777249079484, disc_loss = 0.08274819413558222
Trained batch 260 in epoch 4, gen_loss = 0.8301175604378127, disc_loss = 0.08270230034002285
Trained batch 261 in epoch 4, gen_loss = 0.8318393953883921, disc_loss = 0.08269673604020522
Trained batch 262 in epoch 4, gen_loss = 0.8324399624487293, disc_loss = 0.08247971787921263
Trained batch 263 in epoch 4, gen_loss = 0.8319688001365373, disc_loss = 0.08245814968055735
Trained batch 264 in epoch 4, gen_loss = 0.8321202768469756, disc_loss = 0.08224338582312724
Trained batch 265 in epoch 4, gen_loss = 0.8329364478139949, disc_loss = 0.08207790091059598
Trained batch 266 in epoch 4, gen_loss = 0.8326323525735948, disc_loss = 0.08189800675707253
Trained batch 267 in epoch 4, gen_loss = 0.8329888046232622, disc_loss = 0.08162707498005188
Trained batch 268 in epoch 4, gen_loss = 0.8331209004590059, disc_loss = 0.08139247490529344
Trained batch 269 in epoch 4, gen_loss = 0.834332760616585, disc_loss = 0.08137386012477456
Trained batch 270 in epoch 4, gen_loss = 0.833883178410055, disc_loss = 0.08150842663835446
Trained batch 271 in epoch 4, gen_loss = 0.8335807582034784, disc_loss = 0.08136764186886414
Trained batch 272 in epoch 4, gen_loss = 0.834292491713723, disc_loss = 0.08147132428424371
Trained batch 273 in epoch 4, gen_loss = 0.8352077538079589, disc_loss = 0.08152911397730456
Trained batch 274 in epoch 4, gen_loss = 0.8342801321636547, disc_loss = 0.08189825517548756
Trained batch 275 in epoch 4, gen_loss = 0.8345918614363325, disc_loss = 0.0817116528607743
Trained batch 276 in epoch 4, gen_loss = 0.8354061766651993, disc_loss = 0.08152787245823481
Trained batch 277 in epoch 4, gen_loss = 0.8364621179995777, disc_loss = 0.08132471484232613
Trained batch 278 in epoch 4, gen_loss = 0.8358172671769255, disc_loss = 0.08141951911538625
Trained batch 279 in epoch 4, gen_loss = 0.8358540571161679, disc_loss = 0.08119203541095235
Trained batch 280 in epoch 4, gen_loss = 0.8365630231718152, disc_loss = 0.08102235123448842
Trained batch 281 in epoch 4, gen_loss = 0.8372613777082862, disc_loss = 0.08082971502927706
Trained batch 282 in epoch 4, gen_loss = 0.8365435046357738, disc_loss = 0.08081334031947195
Trained batch 283 in epoch 4, gen_loss = 0.8374805914264329, disc_loss = 0.08069803563445072
Trained batch 284 in epoch 4, gen_loss = 0.8368449146287483, disc_loss = 0.08095387359264127
Trained batch 285 in epoch 4, gen_loss = 0.8380101929594587, disc_loss = 0.08125584929777713
Trained batch 286 in epoch 4, gen_loss = 0.837655276994672, disc_loss = 0.08119084678577318
Trained batch 287 in epoch 4, gen_loss = 0.8378132275409169, disc_loss = 0.0809864393053835
Trained batch 288 in epoch 4, gen_loss = 0.8384090228889228, disc_loss = 0.08079519603968595
Trained batch 289 in epoch 4, gen_loss = 0.8374045729637146, disc_loss = 0.08117439324550074
Trained batch 290 in epoch 4, gen_loss = 0.8377304152934412, disc_loss = 0.0810726788759078
Trained batch 291 in epoch 4, gen_loss = 0.8369227613080038, disc_loss = 0.08117405727365348
Trained batch 292 in epoch 4, gen_loss = 0.8373473905052341, disc_loss = 0.0812926130343877
Trained batch 293 in epoch 4, gen_loss = 0.8378780326064752, disc_loss = 0.08114355636861961
Trained batch 294 in epoch 4, gen_loss = 0.8373214903524366, disc_loss = 0.08120796959847212
Trained batch 295 in epoch 4, gen_loss = 0.8367208236375371, disc_loss = 0.08123265784800153
Trained batch 296 in epoch 4, gen_loss = 0.8375536293694468, disc_loss = 0.08190472182262727
Trained batch 297 in epoch 4, gen_loss = 0.836935578776686, disc_loss = 0.08193407774334086
Trained batch 298 in epoch 4, gen_loss = 0.837059123858959, disc_loss = 0.08185570733465977
Trained batch 299 in epoch 4, gen_loss = 0.837536719640096, disc_loss = 0.08163244534594317
Trained batch 300 in epoch 4, gen_loss = 0.8375804764883858, disc_loss = 0.0814815521196917
Trained batch 301 in epoch 4, gen_loss = 0.8375027077087503, disc_loss = 0.0813255646229037
Trained batch 302 in epoch 4, gen_loss = 0.837201202859973, disc_loss = 0.08116699192402485
Trained batch 303 in epoch 4, gen_loss = 0.836512837166849, disc_loss = 0.08114338360150884
Trained batch 304 in epoch 4, gen_loss = 0.8364363928310207, disc_loss = 0.08095435957256399
Trained batch 305 in epoch 4, gen_loss = 0.8386035526500029, disc_loss = 0.0810973689331387
Trained batch 306 in epoch 4, gen_loss = 0.8383756169278769, disc_loss = 0.08104771912304218
Trained batch 307 in epoch 4, gen_loss = 0.8379354771081503, disc_loss = 0.08096635927349426
Trained batch 308 in epoch 4, gen_loss = 0.8378252651313361, disc_loss = 0.08090373535239677
Trained batch 309 in epoch 4, gen_loss = 0.8375479640499238, disc_loss = 0.0808083428881101
Trained batch 310 in epoch 4, gen_loss = 0.8376765072920698, disc_loss = 0.0806178539913519
Trained batch 311 in epoch 4, gen_loss = 0.8372591225764691, disc_loss = 0.08051078527485235
Trained batch 312 in epoch 4, gen_loss = 0.8376163941221877, disc_loss = 0.08045985937392273
Trained batch 313 in epoch 4, gen_loss = 0.8368189080505614, disc_loss = 0.08077633100603322
Trained batch 314 in epoch 4, gen_loss = 0.837143079439799, disc_loss = 0.08058812321710682
Trained batch 315 in epoch 4, gen_loss = 0.8368987957888012, disc_loss = 0.08064109932548733
Trained batch 316 in epoch 4, gen_loss = 0.8378215738651504, disc_loss = 0.08061772381904467
Trained batch 317 in epoch 4, gen_loss = 0.8372621836152466, disc_loss = 0.08060133348529537
Trained batch 318 in epoch 4, gen_loss = 0.8374978210485093, disc_loss = 0.08038086403558341
Trained batch 319 in epoch 4, gen_loss = 0.8376932874321937, disc_loss = 0.08032511916535441
Trained batch 320 in epoch 4, gen_loss = 0.8372423201335182, disc_loss = 0.08045388745706865
Trained batch 321 in epoch 4, gen_loss = 0.8367008875986064, disc_loss = 0.0804253018472737
Trained batch 322 in epoch 4, gen_loss = 0.8365530283089393, disc_loss = 0.08033445868756472
Trained batch 323 in epoch 4, gen_loss = 0.8366883406300604, disc_loss = 0.08048356300576326
Trained batch 324 in epoch 4, gen_loss = 0.8367333582731393, disc_loss = 0.080301655396246
Trained batch 325 in epoch 4, gen_loss = 0.8356002127648863, disc_loss = 0.08076427589267766
Trained batch 326 in epoch 4, gen_loss = 0.8361637928617109, disc_loss = 0.08102166174486598
Trained batch 327 in epoch 4, gen_loss = 0.8354452862063559, disc_loss = 0.08102914554964206
Trained batch 328 in epoch 4, gen_loss = 0.8359278736686997, disc_loss = 0.081137791301455
Trained batch 329 in epoch 4, gen_loss = 0.8354681373545618, disc_loss = 0.08112981877374378
Trained batch 330 in epoch 4, gen_loss = 0.8351542698472648, disc_loss = 0.08109662886934067
Trained batch 331 in epoch 4, gen_loss = 0.8355784628944225, disc_loss = 0.08154616734091506
Trained batch 332 in epoch 4, gen_loss = 0.8349898120125493, disc_loss = 0.08147449727944873
Trained batch 333 in epoch 4, gen_loss = 0.8340321712329716, disc_loss = 0.08182323410895145
Trained batch 334 in epoch 4, gen_loss = 0.8347992545633174, disc_loss = 0.0818453166828449
Trained batch 335 in epoch 4, gen_loss = 0.8348855359391087, disc_loss = 0.08188685680839367
Trained batch 336 in epoch 4, gen_loss = 0.8343481162358463, disc_loss = 0.081959635630051
Trained batch 337 in epoch 4, gen_loss = 0.8338913484614277, disc_loss = 0.0819651047070924
Trained batch 338 in epoch 4, gen_loss = 0.8345205204500913, disc_loss = 0.08183155544267028
Trained batch 339 in epoch 4, gen_loss = 0.8344618962968097, disc_loss = 0.08169881606419735
Trained batch 340 in epoch 4, gen_loss = 0.8343311673210513, disc_loss = 0.0816042748719585
Trained batch 341 in epoch 4, gen_loss = 0.8341683491803052, disc_loss = 0.08151184268873075
Trained batch 342 in epoch 4, gen_loss = 0.8347469989655665, disc_loss = 0.08133844839294954
Trained batch 343 in epoch 4, gen_loss = 0.8346756302513355, disc_loss = 0.08130176121986277
Trained batch 344 in epoch 4, gen_loss = 0.834717238208522, disc_loss = 0.0811253869312181
Trained batch 345 in epoch 4, gen_loss = 0.834437718367301, disc_loss = 0.08099847731336607
Trained batch 346 in epoch 4, gen_loss = 0.8347389042721014, disc_loss = 0.08083758433148136
Trained batch 347 in epoch 4, gen_loss = 0.8343821370909954, disc_loss = 0.08074549784423547
Trained batch 348 in epoch 4, gen_loss = 0.8347709072182719, disc_loss = 0.08057036490198279
Trained batch 349 in epoch 4, gen_loss = 0.8357695231267385, disc_loss = 0.08047944622646486
Trained batch 350 in epoch 4, gen_loss = 0.8352229475465596, disc_loss = 0.08046953800662375
Trained batch 351 in epoch 4, gen_loss = 0.8351966267112981, disc_loss = 0.08030436992571181
Trained batch 352 in epoch 4, gen_loss = 0.8349789079626964, disc_loss = 0.08047932357113101
Trained batch 353 in epoch 4, gen_loss = 0.8346826133586592, disc_loss = 0.08041916680548572
Trained batch 354 in epoch 4, gen_loss = 0.8347885938597397, disc_loss = 0.08023441820339837
Trained batch 355 in epoch 4, gen_loss = 0.8358505660395944, disc_loss = 0.08050441369675937
Trained batch 356 in epoch 4, gen_loss = 0.835449222673555, disc_loss = 0.08042419860687326
Trained batch 357 in epoch 4, gen_loss = 0.8348674510277849, disc_loss = 0.08058452000841498
Trained batch 358 in epoch 4, gen_loss = 0.83557067267742, disc_loss = 0.08050431711936479
Trained batch 359 in epoch 4, gen_loss = 0.8355330077310403, disc_loss = 0.0804145130665145
Trained batch 360 in epoch 4, gen_loss = 0.8354886024777579, disc_loss = 0.08036440993991997
Trained batch 361 in epoch 4, gen_loss = 0.8354371734251633, disc_loss = 0.08023211837730766
Trained batch 362 in epoch 4, gen_loss = 0.8347463263788828, disc_loss = 0.08031240023785469
Trained batch 363 in epoch 4, gen_loss = 0.8344619584443805, disc_loss = 0.08035184042067728
Trained batch 364 in epoch 4, gen_loss = 0.8351824906590867, disc_loss = 0.080376168598153
Trained batch 365 in epoch 4, gen_loss = 0.8355090219954975, disc_loss = 0.08021494620759549
Trained batch 366 in epoch 4, gen_loss = 0.8345626874418285, disc_loss = 0.08076264159830049
Trained batch 367 in epoch 4, gen_loss = 0.8355392754563818, disc_loss = 0.08104861317880695
Trained batch 368 in epoch 4, gen_loss = 0.8358060308103639, disc_loss = 0.08100602302074351
Trained batch 369 in epoch 4, gen_loss = 0.8348988193917919, disc_loss = 0.08124975119843274
Trained batch 370 in epoch 4, gen_loss = 0.8344340884299933, disc_loss = 0.08130625107970761
Trained batch 371 in epoch 4, gen_loss = 0.8345744136360383, disc_loss = 0.08132580484223542
Trained batch 372 in epoch 4, gen_loss = 0.8342987461160399, disc_loss = 0.08133592713005022
Trained batch 373 in epoch 4, gen_loss = 0.8346547435789822, disc_loss = 0.081223392378499
Trained batch 374 in epoch 4, gen_loss = 0.834757419347763, disc_loss = 0.08117108134180308
Trained batch 375 in epoch 4, gen_loss = 0.8337975020738359, disc_loss = 0.08149419918884226
Trained batch 376 in epoch 4, gen_loss = 0.8338170500585824, disc_loss = 0.08150939307168166
Trained batch 377 in epoch 4, gen_loss = 0.8342256747856343, disc_loss = 0.0813630920558892
Trained batch 378 in epoch 4, gen_loss = 0.8338373031339419, disc_loss = 0.08128885069916068
Trained batch 379 in epoch 4, gen_loss = 0.8337664208914104, disc_loss = 0.08121038846132395
Trained batch 380 in epoch 4, gen_loss = 0.8333973682771517, disc_loss = 0.08122747861034679
Trained batch 381 in epoch 4, gen_loss = 0.8330800110444972, disc_loss = 0.08117937528971993
Trained batch 382 in epoch 4, gen_loss = 0.8328418481132069, disc_loss = 0.08108700012579055
Trained batch 383 in epoch 4, gen_loss = 0.8328935632792612, disc_loss = 0.08149935885497446
Trained batch 384 in epoch 4, gen_loss = 0.8318634497654902, disc_loss = 0.08184038673757346
Trained batch 385 in epoch 4, gen_loss = 0.8316461768175036, disc_loss = 0.08177539536613643
Trained batch 386 in epoch 4, gen_loss = 0.8313552760338598, disc_loss = 0.08208802623736842
Trained batch 387 in epoch 4, gen_loss = 0.831041559423368, disc_loss = 0.08213774295590971
Trained batch 388 in epoch 4, gen_loss = 0.8309765979073042, disc_loss = 0.08203015016071058
Trained batch 389 in epoch 4, gen_loss = 0.830715782672931, disc_loss = 0.0819346828171267
Trained batch 390 in epoch 4, gen_loss = 0.8305597690974965, disc_loss = 0.08179459474323426
Trained batch 391 in epoch 4, gen_loss = 0.8321271205739099, disc_loss = 0.0818223775654309
Trained batch 392 in epoch 4, gen_loss = 0.8318274115181454, disc_loss = 0.08183033608193994
Trained batch 393 in epoch 4, gen_loss = 0.831031982063642, disc_loss = 0.08185908379184488
Trained batch 394 in epoch 4, gen_loss = 0.8310507810568508, disc_loss = 0.08174791218406414
Trained batch 395 in epoch 4, gen_loss = 0.830743817367939, disc_loss = 0.08166164172239451
Trained batch 396 in epoch 4, gen_loss = 0.8306305066163955, disc_loss = 0.08163464346417326
Trained batch 397 in epoch 4, gen_loss = 0.8310172361644668, disc_loss = 0.08153498548331048
Trained batch 398 in epoch 4, gen_loss = 0.8302473745549233, disc_loss = 0.08216390164246909
Trained batch 399 in epoch 4, gen_loss = 0.8307376708090305, disc_loss = 0.08270277247997
Trained batch 400 in epoch 4, gen_loss = 0.8299591443187876, disc_loss = 0.08282693943004135
Trained batch 401 in epoch 4, gen_loss = 0.8299317398474584, disc_loss = 0.08268832545773826
Trained batch 402 in epoch 4, gen_loss = 0.82972319368689, disc_loss = 0.08297955805653008
Trained batch 403 in epoch 4, gen_loss = 0.8295355054116486, disc_loss = 0.08283483130755917
Trained batch 404 in epoch 4, gen_loss = 0.829171195000778, disc_loss = 0.08285867073975596
Trained batch 405 in epoch 4, gen_loss = 0.8294756572528426, disc_loss = 0.0829623252075404
Trained batch 406 in epoch 4, gen_loss = 0.829392763262006, disc_loss = 0.08289545753179003
Trained batch 407 in epoch 4, gen_loss = 0.8289806573998695, disc_loss = 0.08292738589978613
Trained batch 408 in epoch 4, gen_loss = 0.8294504539890802, disc_loss = 0.08282959173162512
Trained batch 409 in epoch 4, gen_loss = 0.8293892428642367, disc_loss = 0.08271571432989909
Trained batch 410 in epoch 4, gen_loss = 0.8293607262509293, disc_loss = 0.0825565576195318
Trained batch 411 in epoch 4, gen_loss = 0.8295762213399109, disc_loss = 0.08244647041587069
Trained batch 412 in epoch 4, gen_loss = 0.8297884718269182, disc_loss = 0.08236073785783952
Trained batch 413 in epoch 4, gen_loss = 0.8297196416463253, disc_loss = 0.08231710727385061
Trained batch 414 in epoch 4, gen_loss = 0.8289904493883432, disc_loss = 0.08248846737600593
Trained batch 415 in epoch 4, gen_loss = 0.8294474479670708, disc_loss = 0.0824266496369651
Trained batch 416 in epoch 4, gen_loss = 0.8295877445801842, disc_loss = 0.08227567399050192
Trained batch 417 in epoch 4, gen_loss = 0.8295506863502794, disc_loss = 0.08217942847705414
Trained batch 418 in epoch 4, gen_loss = 0.8302765572554741, disc_loss = 0.0822383460826585
Trained batch 419 in epoch 4, gen_loss = 0.8308047992842538, disc_loss = 0.08211123866383874
Trained batch 420 in epoch 4, gen_loss = 0.8305322363654112, disc_loss = 0.08211444542387107
Trained batch 421 in epoch 4, gen_loss = 0.8301458642663548, disc_loss = 0.08206135266950416
Trained batch 422 in epoch 4, gen_loss = 0.8307162814951957, disc_loss = 0.08193825980776097
Trained batch 423 in epoch 4, gen_loss = 0.8315417025730295, disc_loss = 0.08201414273990283
Trained batch 424 in epoch 4, gen_loss = 0.8320682364351609, disc_loss = 0.08186458884135765
Trained batch 425 in epoch 4, gen_loss = 0.8317048427924304, disc_loss = 0.08183582751692531
Trained batch 426 in epoch 4, gen_loss = 0.831344878366457, disc_loss = 0.08177309611755526
Trained batch 427 in epoch 4, gen_loss = 0.8313454623534301, disc_loss = 0.08162458144589632
Trained batch 428 in epoch 4, gen_loss = 0.8316683902607097, disc_loss = 0.08164301480976366
Trained batch 429 in epoch 4, gen_loss = 0.8316848321016445, disc_loss = 0.08157430096464448
Trained batch 430 in epoch 4, gen_loss = 0.8311863599686501, disc_loss = 0.0816141858528392
Trained batch 431 in epoch 4, gen_loss = 0.8308327395330977, disc_loss = 0.08152397557515306
Trained batch 432 in epoch 4, gen_loss = 0.8304616460623973, disc_loss = 0.08149935388787033
Trained batch 433 in epoch 4, gen_loss = 0.830336599855379, disc_loss = 0.08155123830433883
Trained batch 434 in epoch 4, gen_loss = 0.8301220031990402, disc_loss = 0.08184036786571659
Trained batch 435 in epoch 4, gen_loss = 0.8297654628206831, disc_loss = 0.08184804995715139
Trained batch 436 in epoch 4, gen_loss = 0.8293299897311754, disc_loss = 0.08189444175071042
Trained batch 437 in epoch 4, gen_loss = 0.8298751718649581, disc_loss = 0.08233805207671709
Trained batch 438 in epoch 4, gen_loss = 0.8300945048723243, disc_loss = 0.0822577041452899
Trained batch 439 in epoch 4, gen_loss = 0.8297799423336982, disc_loss = 0.0822929437293417
Trained batch 440 in epoch 4, gen_loss = 0.8295757242070845, disc_loss = 0.08247759996738091
Trained batch 441 in epoch 4, gen_loss = 0.829523982370601, disc_loss = 0.0824017183564401
Trained batch 442 in epoch 4, gen_loss = 0.8291926449900556, disc_loss = 0.08237321752398936
Trained batch 443 in epoch 4, gen_loss = 0.8299792276040928, disc_loss = 0.08245881413831166
Trained batch 444 in epoch 4, gen_loss = 0.829800058214852, disc_loss = 0.0823940022377653
Trained batch 445 in epoch 4, gen_loss = 0.8297979966674685, disc_loss = 0.08241223772119045
Trained batch 446 in epoch 4, gen_loss = 0.8301846830370175, disc_loss = 0.08240162433902222
Trained batch 447 in epoch 4, gen_loss = 0.8309380309656262, disc_loss = 0.08253456170911834
Trained batch 448 in epoch 4, gen_loss = 0.831359615171938, disc_loss = 0.08238531458077492
Trained batch 449 in epoch 4, gen_loss = 0.8307835096783108, disc_loss = 0.08237818908153309
Trained batch 450 in epoch 4, gen_loss = 0.8307009044613384, disc_loss = 0.08227043476434809
Trained batch 451 in epoch 4, gen_loss = 0.8306961691221305, disc_loss = 0.08231218452400536
Trained batch 452 in epoch 4, gen_loss = 0.8307315090107865, disc_loss = 0.08222290809177865
Trained batch 453 in epoch 4, gen_loss = 0.8301779824731633, disc_loss = 0.08225889070501083
Trained batch 454 in epoch 4, gen_loss = 0.831456525509174, disc_loss = 0.08238843823322556
Trained batch 455 in epoch 4, gen_loss = 0.8310934580993234, disc_loss = 0.0823614896957256
Trained batch 456 in epoch 4, gen_loss = 0.8306473789642885, disc_loss = 0.08235354140947045
Trained batch 457 in epoch 4, gen_loss = 0.830827477977786, disc_loss = 0.08229653293055413
Trained batch 458 in epoch 4, gen_loss = 0.8306037390154172, disc_loss = 0.08220837528011833
Trained batch 459 in epoch 4, gen_loss = 0.8302027067412501, disc_loss = 0.08219358169311738
Trained batch 460 in epoch 4, gen_loss = 0.8303568851921925, disc_loss = 0.08208019989633573
Trained batch 461 in epoch 4, gen_loss = 0.8305082904312001, disc_loss = 0.08195134386363806
Trained batch 462 in epoch 4, gen_loss = 0.8302491403810406, disc_loss = 0.08195766483355096
Trained batch 463 in epoch 4, gen_loss = 0.8298604395882837, disc_loss = 0.0819188373119185
Trained batch 464 in epoch 4, gen_loss = 0.8298069507844986, disc_loss = 0.08186763150276996
Trained batch 465 in epoch 4, gen_loss = 0.8300513465261254, disc_loss = 0.0817586156107933
Trained batch 466 in epoch 4, gen_loss = 0.8294987540684113, disc_loss = 0.08187130662139976
Trained batch 467 in epoch 4, gen_loss = 0.8299880924387875, disc_loss = 0.08192722202262753
Trained batch 468 in epoch 4, gen_loss = 0.8298319265532341, disc_loss = 0.08179533362253578
Trained batch 469 in epoch 4, gen_loss = 0.8297156831051441, disc_loss = 0.08171202869927313
Trained batch 470 in epoch 4, gen_loss = 0.8296107773821318, disc_loss = 0.08162677419943351
Trained batch 471 in epoch 4, gen_loss = 0.8299116347048242, disc_loss = 0.08170355506580702
Trained batch 472 in epoch 4, gen_loss = 0.8300383256051304, disc_loss = 0.08161357901084687
Trained batch 473 in epoch 4, gen_loss = 0.8302403567712519, disc_loss = 0.08149609306654283
Trained batch 474 in epoch 4, gen_loss = 0.8296035378857662, disc_loss = 0.08162686558734429
Trained batch 475 in epoch 4, gen_loss = 0.8299564605250078, disc_loss = 0.08178244005818264
Trained batch 476 in epoch 4, gen_loss = 0.8297934700857919, disc_loss = 0.08168330750148939
Trained batch 477 in epoch 4, gen_loss = 0.8300834129794372, disc_loss = 0.0815404612633349
Trained batch 478 in epoch 4, gen_loss = 0.8298085638028346, disc_loss = 0.08143531064462065
Trained batch 479 in epoch 4, gen_loss = 0.8297258134931326, disc_loss = 0.08138557182004054
Trained batch 480 in epoch 4, gen_loss = 0.8298150506683794, disc_loss = 0.08130895711187265
Trained batch 481 in epoch 4, gen_loss = 0.8304777229475283, disc_loss = 0.08119027316956723
Trained batch 482 in epoch 4, gen_loss = 0.830373860294034, disc_loss = 0.08105164416921065
Trained batch 483 in epoch 4, gen_loss = 0.8301017481433458, disc_loss = 0.0810869168259265
Trained batch 484 in epoch 4, gen_loss = 0.8300372750488754, disc_loss = 0.0811001166778127
Trained batch 485 in epoch 4, gen_loss = 0.8306830746156199, disc_loss = 0.08110476255324887
Trained batch 486 in epoch 4, gen_loss = 0.830346544175667, disc_loss = 0.08116110162599131
Trained batch 487 in epoch 4, gen_loss = 0.8303284162624938, disc_loss = 0.08103552066766825
Trained batch 488 in epoch 4, gen_loss = 0.8307513292337976, disc_loss = 0.08093182361686645
Trained batch 489 in epoch 4, gen_loss = 0.8303033913884844, disc_loss = 0.08092212483895068
Trained batch 490 in epoch 4, gen_loss = 0.8306569815167585, disc_loss = 0.08094363533673607
Trained batch 491 in epoch 4, gen_loss = 0.8307638497856574, disc_loss = 0.08090411074368692
Trained batch 492 in epoch 4, gen_loss = 0.8301575992702229, disc_loss = 0.08096319066009222
Trained batch 493 in epoch 4, gen_loss = 0.8302206029052194, disc_loss = 0.08082070118683553
Trained batch 494 in epoch 4, gen_loss = 0.8301881951515121, disc_loss = 0.08072752800553736
Trained batch 495 in epoch 4, gen_loss = 0.8310692882345568, disc_loss = 0.08080444690741358
Trained batch 496 in epoch 4, gen_loss = 0.8307835087929692, disc_loss = 0.08083484010017614
Trained batch 497 in epoch 4, gen_loss = 0.8308285569330774, disc_loss = 0.08075464347070718
Trained batch 498 in epoch 4, gen_loss = 0.8309732878614284, disc_loss = 0.0806606402975285
Trained batch 499 in epoch 4, gen_loss = 0.8308142900466919, disc_loss = 0.08060637834668159
Trained batch 500 in epoch 4, gen_loss = 0.8308376912585276, disc_loss = 0.08054890272443642
Trained batch 501 in epoch 4, gen_loss = 0.8305908663576818, disc_loss = 0.08049176223724487
Trained batch 502 in epoch 4, gen_loss = 0.8307883165939665, disc_loss = 0.0804387793300403
Trained batch 503 in epoch 4, gen_loss = 0.8315194518793196, disc_loss = 0.08052033761013595
Trained batch 504 in epoch 4, gen_loss = 0.8310271758844356, disc_loss = 0.08078758898052839
Trained batch 505 in epoch 4, gen_loss = 0.8306314390403009, disc_loss = 0.08083967967584671
Trained batch 506 in epoch 4, gen_loss = 0.8306525615310293, disc_loss = 0.08090047491255126
Trained batch 507 in epoch 4, gen_loss = 0.8306831516853468, disc_loss = 0.08092195762130688
Trained batch 508 in epoch 4, gen_loss = 0.8304809448995384, disc_loss = 0.0808978516220578
Trained batch 509 in epoch 4, gen_loss = 0.830491113428976, disc_loss = 0.08091505882786769
Trained batch 510 in epoch 4, gen_loss = 0.8300646127086796, disc_loss = 0.0810351798387423
Trained batch 511 in epoch 4, gen_loss = 0.829867617576383, disc_loss = 0.08108772221021354
Trained batch 512 in epoch 4, gen_loss = 0.8299213771002102, disc_loss = 0.08104667734158666
Trained batch 513 in epoch 4, gen_loss = 0.829855864150051, disc_loss = 0.08101091378799673
Trained batch 514 in epoch 4, gen_loss = 0.8301419792823421, disc_loss = 0.08107873111673929
Trained batch 515 in epoch 4, gen_loss = 0.8300915427448213, disc_loss = 0.08110173910047656
Trained batch 516 in epoch 4, gen_loss = 0.829953354954489, disc_loss = 0.0810756424524798
Trained batch 517 in epoch 4, gen_loss = 0.8297069863232867, disc_loss = 0.08116667645778435
Trained batch 518 in epoch 4, gen_loss = 0.8298764738733369, disc_loss = 0.08109176003146264
Trained batch 519 in epoch 4, gen_loss = 0.8300850747869565, disc_loss = 0.08118925317405508
Trained batch 520 in epoch 4, gen_loss = 0.8295017909866377, disc_loss = 0.08145093922851868
Trained batch 521 in epoch 4, gen_loss = 0.8296590114005225, disc_loss = 0.0814208936631337
Trained batch 522 in epoch 4, gen_loss = 0.8297066932426584, disc_loss = 0.08151518847672251
Trained batch 523 in epoch 4, gen_loss = 0.8297959233968313, disc_loss = 0.08139965320645853
Trained batch 524 in epoch 4, gen_loss = 0.8292313220387414, disc_loss = 0.0815360025990577
Trained batch 525 in epoch 4, gen_loss = 0.8298598306940536, disc_loss = 0.08175104291323473
Trained batch 526 in epoch 4, gen_loss = 0.8291841928601491, disc_loss = 0.08190173500233403
Trained batch 527 in epoch 4, gen_loss = 0.8291472912286267, disc_loss = 0.08190494490730943
Trained batch 528 in epoch 4, gen_loss = 0.8292693668141933, disc_loss = 0.08187387517472071
Trained batch 529 in epoch 4, gen_loss = 0.829246696211257, disc_loss = 0.08183217436637519
Trained batch 530 in epoch 4, gen_loss = 0.8287821213404337, disc_loss = 0.08190835846794976
Trained batch 531 in epoch 4, gen_loss = 0.8288310371843496, disc_loss = 0.08187385964998625
Trained batch 532 in epoch 4, gen_loss = 0.8290518240454496, disc_loss = 0.08182992357026793
Trained batch 533 in epoch 4, gen_loss = 0.8285891687155663, disc_loss = 0.08196428845102867
Trained batch 534 in epoch 4, gen_loss = 0.8286433405965288, disc_loss = 0.08193698278932927
Trained batch 535 in epoch 4, gen_loss = 0.8285459294470389, disc_loss = 0.08190098652310336
Trained batch 536 in epoch 4, gen_loss = 0.8281209378935105, disc_loss = 0.0820101829769447
Trained batch 537 in epoch 4, gen_loss = 0.8280703734509564, disc_loss = 0.08209446310775431
Trained batch 538 in epoch 4, gen_loss = 0.8278478896020737, disc_loss = 0.08212252279159532
Trained batch 539 in epoch 4, gen_loss = 0.827496987581253, disc_loss = 0.08216570639223963
Trained batch 540 in epoch 4, gen_loss = 0.8275225758552551, disc_loss = 0.08207387050231592
Trained batch 541 in epoch 4, gen_loss = 0.8277548427291462, disc_loss = 0.08210045877307984
Trained batch 542 in epoch 4, gen_loss = 0.8274348114735514, disc_loss = 0.08220482182656423
Trained batch 543 in epoch 4, gen_loss = 0.8276888656922999, disc_loss = 0.08250500182347263
Trained batch 544 in epoch 4, gen_loss = 0.8279093194445338, disc_loss = 0.0824129895879588
Trained batch 545 in epoch 4, gen_loss = 0.8273866596894387, disc_loss = 0.08256535349420575
Trained batch 546 in epoch 4, gen_loss = 0.8270293051407586, disc_loss = 0.08256849819552528
Trained batch 547 in epoch 4, gen_loss = 0.8274134040748986, disc_loss = 0.0829195347444637
Trained batch 548 in epoch 4, gen_loss = 0.8275044950196869, disc_loss = 0.08283648892341415
Trained batch 549 in epoch 4, gen_loss = 0.8271140362999656, disc_loss = 0.08290991891514171
Trained batch 550 in epoch 4, gen_loss = 0.826559369988104, disc_loss = 0.08299503990612965
Trained batch 551 in epoch 4, gen_loss = 0.8275677191390507, disc_loss = 0.0836725012547728
Trained batch 552 in epoch 4, gen_loss = 0.8271579467582013, disc_loss = 0.08362102434443307
Trained batch 553 in epoch 4, gen_loss = 0.8268589475309805, disc_loss = 0.08374369837047821
Trained batch 554 in epoch 4, gen_loss = 0.826984034894823, disc_loss = 0.0838841741552224
Trained batch 555 in epoch 4, gen_loss = 0.826514479282091, disc_loss = 0.08403224930864014
Trained batch 556 in epoch 4, gen_loss = 0.8263069850324086, disc_loss = 0.08430184791770828
Trained batch 557 in epoch 4, gen_loss = 0.8259115690185178, disc_loss = 0.08449793210433375
Trained batch 558 in epoch 4, gen_loss = 0.825836334010996, disc_loss = 0.08452326772411309
Trained batch 559 in epoch 4, gen_loss = 0.8259966330868858, disc_loss = 0.08453423807929669
Trained batch 560 in epoch 4, gen_loss = 0.8254347540265523, disc_loss = 0.08467553937127033
Trained batch 561 in epoch 4, gen_loss = 0.8252719728760024, disc_loss = 0.08465018347435999
Trained batch 562 in epoch 4, gen_loss = 0.8253862205661211, disc_loss = 0.08484138994350315
Trained batch 563 in epoch 4, gen_loss = 0.8249396209387069, disc_loss = 0.08484887483642034
Trained batch 564 in epoch 4, gen_loss = 0.8246514591495547, disc_loss = 0.0850272216232477
Trained batch 565 in epoch 4, gen_loss = 0.8246148530880891, disc_loss = 0.08507898977756921
Trained batch 566 in epoch 4, gen_loss = 0.8243561574180711, disc_loss = 0.08509081779491334
Trained batch 567 in epoch 4, gen_loss = 0.8240014666192969, disc_loss = 0.08507815591046508
Trained batch 568 in epoch 4, gen_loss = 0.8238135803562895, disc_loss = 0.08503130025284361
Trained batch 569 in epoch 4, gen_loss = 0.8244738402073843, disc_loss = 0.08546874731648386
Trained batch 570 in epoch 4, gen_loss = 0.8237250108017395, disc_loss = 0.08585123584039783
Trained batch 571 in epoch 4, gen_loss = 0.8235946561281497, disc_loss = 0.08594640080615149
Trained batch 572 in epoch 4, gen_loss = 0.8234810086445035, disc_loss = 0.08605902187565234
Trained batch 573 in epoch 4, gen_loss = 0.8233592356538939, disc_loss = 0.08603418964360442
Trained batch 574 in epoch 4, gen_loss = 0.8234457200506459, disc_loss = 0.08599953877537146
Trained batch 575 in epoch 4, gen_loss = 0.8231040049965183, disc_loss = 0.08611107729504713
Trained batch 576 in epoch 4, gen_loss = 0.8228468486919767, disc_loss = 0.08621259708364254
Trained batch 577 in epoch 4, gen_loss = 0.8225888992469615, disc_loss = 0.08627094579119376
Trained batch 578 in epoch 4, gen_loss = 0.82245080345447, disc_loss = 0.08626501252536947
Trained batch 579 in epoch 4, gen_loss = 0.8223846524953842, disc_loss = 0.08620831902813295
Trained batch 580 in epoch 4, gen_loss = 0.8219574430313045, disc_loss = 0.08628989854208778
Trained batch 581 in epoch 4, gen_loss = 0.821975849645654, disc_loss = 0.08625732869857161
Trained batch 582 in epoch 4, gen_loss = 0.8217302995316978, disc_loss = 0.08626861877317699
Trained batch 583 in epoch 4, gen_loss = 0.8213219598752178, disc_loss = 0.08624031138925316
Trained batch 584 in epoch 4, gen_loss = 0.8210072809814388, disc_loss = 0.08623187869914577
Trained batch 585 in epoch 4, gen_loss = 0.821653168254338, disc_loss = 0.08615799147139841
Trained batch 586 in epoch 4, gen_loss = 0.8215545652469135, disc_loss = 0.08608119793274334
Trained batch 587 in epoch 4, gen_loss = 0.8211880576651113, disc_loss = 0.08605091556982726
Trained batch 588 in epoch 4, gen_loss = 0.821080774827805, disc_loss = 0.08607499536082579
Trained batch 589 in epoch 4, gen_loss = 0.8216752617035882, disc_loss = 0.08601881232175787
Trained batch 590 in epoch 4, gen_loss = 0.8216396403796782, disc_loss = 0.08593431628874917
Trained batch 591 in epoch 4, gen_loss = 0.8212451370986732, disc_loss = 0.08590421335444458
Trained batch 592 in epoch 4, gen_loss = 0.8211355173165641, disc_loss = 0.08583886202104377
Trained batch 593 in epoch 4, gen_loss = 0.8209126840536843, disc_loss = 0.08581652667260531
Trained batch 594 in epoch 4, gen_loss = 0.8213229209435087, disc_loss = 0.08595293111034802
Trained batch 595 in epoch 4, gen_loss = 0.8215844107154232, disc_loss = 0.08586974531387123
Trained batch 596 in epoch 4, gen_loss = 0.8214938276177475, disc_loss = 0.08588183262514908
Trained batch 597 in epoch 4, gen_loss = 0.8211144187976684, disc_loss = 0.08585835907944668
Trained batch 598 in epoch 4, gen_loss = 0.8209828103524018, disc_loss = 0.08585067438536972
Trained batch 599 in epoch 4, gen_loss = 0.820573186079661, disc_loss = 0.08592172274366021
Trained batch 600 in epoch 4, gen_loss = 0.821259729080708, disc_loss = 0.08603403546821059
Trained batch 601 in epoch 4, gen_loss = 0.8213032250388517, disc_loss = 0.0859935694989869
Trained batch 602 in epoch 4, gen_loss = 0.821275023678642, disc_loss = 0.08594846060101073
Trained batch 603 in epoch 4, gen_loss = 0.8214345518129551, disc_loss = 0.08586393865380461
Trained batch 604 in epoch 4, gen_loss = 0.8219568779645873, disc_loss = 0.08578707055488893
Trained batch 605 in epoch 4, gen_loss = 0.8219734380150786, disc_loss = 0.08567977271260994
Trained batch 606 in epoch 4, gen_loss = 0.8218854108006007, disc_loss = 0.08569211129841733
Trained batch 607 in epoch 4, gen_loss = 0.8214792344523104, disc_loss = 0.08577179402652148
Trained batch 608 in epoch 4, gen_loss = 0.8218024285947553, disc_loss = 0.08569297842889388
Trained batch 609 in epoch 4, gen_loss = 0.8218980972884131, disc_loss = 0.08558451193155812
Trained batch 610 in epoch 4, gen_loss = 0.8214959509048837, disc_loss = 0.08553158475387897
Trained batch 611 in epoch 4, gen_loss = 0.8213966091473898, disc_loss = 0.08557623854284388
Trained batch 612 in epoch 4, gen_loss = 0.8209680687350511, disc_loss = 0.0856712170820349
Trained batch 613 in epoch 4, gen_loss = 0.8213762523491142, disc_loss = 0.08569691831955886
Trained batch 614 in epoch 4, gen_loss = 0.8215641673018292, disc_loss = 0.08557760408981059
Trained batch 615 in epoch 4, gen_loss = 0.8215874685095502, disc_loss = 0.08547575364203809
Trained batch 616 in epoch 4, gen_loss = 0.8212762231571747, disc_loss = 0.08545114567301068
Trained batch 617 in epoch 4, gen_loss = 0.8212271827517204, disc_loss = 0.08537440842264679
Trained batch 618 in epoch 4, gen_loss = 0.8210619614852265, disc_loss = 0.08543100806257066
Trained batch 619 in epoch 4, gen_loss = 0.8211093043127368, disc_loss = 0.0854754431473632
Trained batch 620 in epoch 4, gen_loss = 0.8207787471117028, disc_loss = 0.08551691826462937
Trained batch 621 in epoch 4, gen_loss = 0.8201841072829207, disc_loss = 0.08571363200951619
Trained batch 622 in epoch 4, gen_loss = 0.8201406111112567, disc_loss = 0.08567799796405612
Trained batch 623 in epoch 4, gen_loss = 0.8204762179117936, disc_loss = 0.08595581657181565
Trained batch 624 in epoch 4, gen_loss = 0.8205684322357177, disc_loss = 0.08587222459316253
Trained batch 625 in epoch 4, gen_loss = 0.8201015949630128, disc_loss = 0.08599414745458779
Trained batch 626 in epoch 4, gen_loss = 0.8203001060364159, disc_loss = 0.08606520870275665
Trained batch 627 in epoch 4, gen_loss = 0.8201312170286846, disc_loss = 0.08597629622016457
Trained batch 628 in epoch 4, gen_loss = 0.8203635511413477, disc_loss = 0.08586125939474434
Trained batch 629 in epoch 4, gen_loss = 0.8201043191410247, disc_loss = 0.08586180204348196
Trained batch 630 in epoch 4, gen_loss = 0.8198399062013098, disc_loss = 0.08588340015500406
Trained batch 631 in epoch 4, gen_loss = 0.8198240212624586, disc_loss = 0.08583883850546435
Trained batch 632 in epoch 4, gen_loss = 0.8198044276538806, disc_loss = 0.08575031496613841
Trained batch 633 in epoch 4, gen_loss = 0.8201813078265084, disc_loss = 0.0856402491848058
Trained batch 634 in epoch 4, gen_loss = 0.8197610096668634, disc_loss = 0.08574779621934094
Trained batch 635 in epoch 4, gen_loss = 0.819754606147982, disc_loss = 0.08578885400978227
Trained batch 636 in epoch 4, gen_loss = 0.8199693181638253, disc_loss = 0.08571447301480563
Trained batch 637 in epoch 4, gen_loss = 0.8197024890621628, disc_loss = 0.08582608633438202
Trained batch 638 in epoch 4, gen_loss = 0.8196323877768897, disc_loss = 0.08591438000161836
Trained batch 639 in epoch 4, gen_loss = 0.8194172156043351, disc_loss = 0.08589861643704352
Trained batch 640 in epoch 4, gen_loss = 0.8192264628298755, disc_loss = 0.08588550631944875
Trained batch 641 in epoch 4, gen_loss = 0.8197209907469348, disc_loss = 0.08630985172894838
Trained batch 642 in epoch 4, gen_loss = 0.8197527834638652, disc_loss = 0.08623698286996057
Trained batch 643 in epoch 4, gen_loss = 0.819248796619984, disc_loss = 0.08654640340072722
Trained batch 644 in epoch 4, gen_loss = 0.8194286003593326, disc_loss = 0.08691024177729391
Trained batch 645 in epoch 4, gen_loss = 0.819023702904905, disc_loss = 0.08715467882016818
Trained batch 646 in epoch 4, gen_loss = 0.8186271431088632, disc_loss = 0.08734615552894069
Trained batch 647 in epoch 4, gen_loss = 0.8186240937606788, disc_loss = 0.08740595666501948
Trained batch 648 in epoch 4, gen_loss = 0.8182940529932042, disc_loss = 0.08756829908860989
Trained batch 649 in epoch 4, gen_loss = 0.8182534336126768, disc_loss = 0.087597453460957
Trained batch 650 in epoch 4, gen_loss = 0.8179638500220948, disc_loss = 0.08757705885070032
Trained batch 651 in epoch 4, gen_loss = 0.8181330567122969, disc_loss = 0.08750420718945197
Trained batch 652 in epoch 4, gen_loss = 0.8181236348875084, disc_loss = 0.08742301526463735
Trained batch 653 in epoch 4, gen_loss = 0.8182550402591717, disc_loss = 0.08739021983117275
Trained batch 654 in epoch 4, gen_loss = 0.8182481219750324, disc_loss = 0.08730349048886818
Trained batch 655 in epoch 4, gen_loss = 0.8183261961108301, disc_loss = 0.08723623382364877
Trained batch 656 in epoch 4, gen_loss = 0.8182560358780523, disc_loss = 0.08714660371779896
Trained batch 657 in epoch 4, gen_loss = 0.818427659910863, disc_loss = 0.0870430114916823
Trained batch 658 in epoch 4, gen_loss = 0.8183908715776319, disc_loss = 0.0870027517679406
Trained batch 659 in epoch 4, gen_loss = 0.8186916143605203, disc_loss = 0.08692087451362926
Trained batch 660 in epoch 4, gen_loss = 0.8189357175588968, disc_loss = 0.08685142378803236
Trained batch 661 in epoch 4, gen_loss = 0.8187972095617715, disc_loss = 0.08689283905832204
Trained batch 662 in epoch 4, gen_loss = 0.8187969725236274, disc_loss = 0.08687479488220105
Trained batch 663 in epoch 4, gen_loss = 0.8190967672201525, disc_loss = 0.0869404426705743
Trained batch 664 in epoch 4, gen_loss = 0.8193711985322766, disc_loss = 0.08684039675399549
Trained batch 665 in epoch 4, gen_loss = 0.8191531593198175, disc_loss = 0.08681197642759832
Trained batch 666 in epoch 4, gen_loss = 0.8190073540721876, disc_loss = 0.08679392865008634
Trained batch 667 in epoch 4, gen_loss = 0.8189952741126101, disc_loss = 0.0868269259787672
Trained batch 668 in epoch 4, gen_loss = 0.8196290068562255, disc_loss = 0.08698058231233971
Trained batch 669 in epoch 4, gen_loss = 0.8190878542056724, disc_loss = 0.08732251205078478
Trained batch 670 in epoch 4, gen_loss = 0.8189032652072509, disc_loss = 0.08735629685650595
Trained batch 671 in epoch 4, gen_loss = 0.8193804960963982, disc_loss = 0.08734068121910761
Trained batch 672 in epoch 4, gen_loss = 0.8191787297180113, disc_loss = 0.08729529050753118
Trained batch 673 in epoch 4, gen_loss = 0.8190667064589633, disc_loss = 0.08724274471794595
Trained batch 674 in epoch 4, gen_loss = 0.8191089447780892, disc_loss = 0.08719116407274097
Trained batch 675 in epoch 4, gen_loss = 0.8193193014115977, disc_loss = 0.08727179004634406
Trained batch 676 in epoch 4, gen_loss = 0.819152550956171, disc_loss = 0.08728971042734966
Trained batch 677 in epoch 4, gen_loss = 0.8189126751152112, disc_loss = 0.08731462667863761
Trained batch 678 in epoch 4, gen_loss = 0.8193258807743421, disc_loss = 0.08738277861176386
Trained batch 679 in epoch 4, gen_loss = 0.8191696113961584, disc_loss = 0.08736360747887588
Trained batch 680 in epoch 4, gen_loss = 0.8189470070836827, disc_loss = 0.08732184278539405
Trained batch 681 in epoch 4, gen_loss = 0.8188621333180285, disc_loss = 0.08741219794989462
Trained batch 682 in epoch 4, gen_loss = 0.818880119793237, disc_loss = 0.08733575421182294
Trained batch 683 in epoch 4, gen_loss = 0.8190714979642316, disc_loss = 0.08726618292861296
Trained batch 684 in epoch 4, gen_loss = 0.8186927777572269, disc_loss = 0.08734674338305735
Trained batch 685 in epoch 4, gen_loss = 0.819192195555559, disc_loss = 0.08754255539946715
Trained batch 686 in epoch 4, gen_loss = 0.8190459615538734, disc_loss = 0.0874650478945961
Trained batch 687 in epoch 4, gen_loss = 0.8187752868980169, disc_loss = 0.08750249431766353
Trained batch 688 in epoch 4, gen_loss = 0.8188361308830743, disc_loss = 0.08746451521576186
Trained batch 689 in epoch 4, gen_loss = 0.8188788293496422, disc_loss = 0.08740446459960895
Trained batch 690 in epoch 4, gen_loss = 0.818721881521766, disc_loss = 0.08735331634056853
Trained batch 691 in epoch 4, gen_loss = 0.818614595069017, disc_loss = 0.08730374771773255
Trained batch 692 in epoch 4, gen_loss = 0.8185483364745824, disc_loss = 0.08722875556340079
Trained batch 693 in epoch 4, gen_loss = 0.8187078353908632, disc_loss = 0.08712641254835024
Trained batch 694 in epoch 4, gen_loss = 0.8187661457833626, disc_loss = 0.08702532717247875
Trained batch 695 in epoch 4, gen_loss = 0.8187507837582594, disc_loss = 0.08698803890394796
Trained batch 696 in epoch 4, gen_loss = 0.8183622178508014, disc_loss = 0.08700418197169066
Trained batch 697 in epoch 4, gen_loss = 0.8184419933994725, disc_loss = 0.08694163545096202
Trained batch 698 in epoch 4, gen_loss = 0.8183360461769186, disc_loss = 0.08691808858084278
Trained batch 699 in epoch 4, gen_loss = 0.8187022553597177, disc_loss = 0.08680778467362481
Trained batch 700 in epoch 4, gen_loss = 0.8185586060760025, disc_loss = 0.08677847144697473
Trained batch 701 in epoch 4, gen_loss = 0.8187559305178134, disc_loss = 0.08681376210607566
Trained batch 702 in epoch 4, gen_loss = 0.8185819080934077, disc_loss = 0.08679083702028603
Trained batch 703 in epoch 4, gen_loss = 0.818274410399185, disc_loss = 0.08676340725320518
Trained batch 704 in epoch 4, gen_loss = 0.8182136879322377, disc_loss = 0.08670740285690161
Trained batch 705 in epoch 4, gen_loss = 0.8187748675390276, disc_loss = 0.08707749153020404
Trained batch 706 in epoch 4, gen_loss = 0.8186048545375403, disc_loss = 0.08707091156024449
Trained batch 707 in epoch 4, gen_loss = 0.8185100741894905, disc_loss = 0.08703048984614849
Trained batch 708 in epoch 4, gen_loss = 0.8184157153867364, disc_loss = 0.08698213563992922
Trained batch 709 in epoch 4, gen_loss = 0.8183700195920299, disc_loss = 0.08701744672619331
Trained batch 710 in epoch 4, gen_loss = 0.8183218923550618, disc_loss = 0.08698080625888038
Trained batch 711 in epoch 4, gen_loss = 0.818419232169229, disc_loss = 0.08688145341859146
Trained batch 712 in epoch 4, gen_loss = 0.8181083329847451, disc_loss = 0.08684246625155628
Trained batch 713 in epoch 4, gen_loss = 0.8182035134035666, disc_loss = 0.08673688358332471
Trained batch 714 in epoch 4, gen_loss = 0.8185302424680937, disc_loss = 0.08664376094963376
Trained batch 715 in epoch 4, gen_loss = 0.8183893153038104, disc_loss = 0.08660533881808667
Trained batch 716 in epoch 4, gen_loss = 0.8186289605319583, disc_loss = 0.08650685559615305
Trained batch 717 in epoch 4, gen_loss = 0.8184665638673272, disc_loss = 0.08652109303706246
Trained batch 718 in epoch 4, gen_loss = 0.8190010644713098, disc_loss = 0.08677324741400043
Trained batch 719 in epoch 4, gen_loss = 0.8187895930061738, disc_loss = 0.08676408985241627
Trained batch 720 in epoch 4, gen_loss = 0.8184813444144848, disc_loss = 0.0867533607992257
Trained batch 721 in epoch 4, gen_loss = 0.8187266951865436, disc_loss = 0.0867633340826098
Trained batch 722 in epoch 4, gen_loss = 0.8189262425833553, disc_loss = 0.08671197871887544
Trained batch 723 in epoch 4, gen_loss = 0.818567392123009, disc_loss = 0.08673246122140293
Trained batch 724 in epoch 4, gen_loss = 0.8186051369124445, disc_loss = 0.0866490999005478
Trained batch 725 in epoch 4, gen_loss = 0.8186305569633636, disc_loss = 0.08658705836870084
Trained batch 726 in epoch 4, gen_loss = 0.8185800614432422, disc_loss = 0.08676019391273002
Trained batch 727 in epoch 4, gen_loss = 0.8185794972865791, disc_loss = 0.08668168680870313
Trained batch 728 in epoch 4, gen_loss = 0.8183113053257083, disc_loss = 0.08667303365878812
Trained batch 729 in epoch 4, gen_loss = 0.8183609045939902, disc_loss = 0.08657349011899061
Trained batch 730 in epoch 4, gen_loss = 0.8183905688992277, disc_loss = 0.08648119070955773
Trained batch 731 in epoch 4, gen_loss = 0.8184859634992855, disc_loss = 0.0864804851545194
Trained batch 732 in epoch 4, gen_loss = 0.8184052000348272, disc_loss = 0.08639530437943839
Trained batch 733 in epoch 4, gen_loss = 0.8186473232929973, disc_loss = 0.08633272068534421
Trained batch 734 in epoch 4, gen_loss = 0.8186694722191817, disc_loss = 0.0862521624775464
Trained batch 735 in epoch 4, gen_loss = 0.8186267754872856, disc_loss = 0.0861935630407812
Trained batch 736 in epoch 4, gen_loss = 0.8183597496519904, disc_loss = 0.08619057443599486
Trained batch 737 in epoch 4, gen_loss = 0.8187967841298922, disc_loss = 0.08618936599749658
Trained batch 738 in epoch 4, gen_loss = 0.818855803333858, disc_loss = 0.08611759260997519
Trained batch 739 in epoch 4, gen_loss = 0.8191042061190348, disc_loss = 0.08616555327977482
Trained batch 740 in epoch 4, gen_loss = 0.8189455732884194, disc_loss = 0.08610319726636656
Trained batch 741 in epoch 4, gen_loss = 0.8188471622624487, disc_loss = 0.08608887901258556
Trained batch 742 in epoch 4, gen_loss = 0.8189404072944441, disc_loss = 0.08599321251486905
Trained batch 743 in epoch 4, gen_loss = 0.819181334067096, disc_loss = 0.08593383966819934
Trained batch 744 in epoch 4, gen_loss = 0.8193531681627235, disc_loss = 0.08583390563476406
Trained batch 745 in epoch 4, gen_loss = 0.8192545553075085, disc_loss = 0.0858206969758261
Trained batch 746 in epoch 4, gen_loss = 0.8193819521660786, disc_loss = 0.08576612049087862
Trained batch 747 in epoch 4, gen_loss = 0.8193078179330749, disc_loss = 0.08571451386177843
Trained batch 748 in epoch 4, gen_loss = 0.8194901353128762, disc_loss = 0.08566402581001872
Trained batch 749 in epoch 4, gen_loss = 0.8196503336032231, disc_loss = 0.08558469483504692
Trained batch 750 in epoch 4, gen_loss = 0.8198988658689786, disc_loss = 0.08558402875420972
Trained batch 751 in epoch 4, gen_loss = 0.8200571676914362, disc_loss = 0.0855256060826929
Trained batch 752 in epoch 4, gen_loss = 0.8197049838534073, disc_loss = 0.08553531133430017
Trained batch 753 in epoch 4, gen_loss = 0.8195934760870921, disc_loss = 0.08557279577691217
Trained batch 754 in epoch 4, gen_loss = 0.8199439102845476, disc_loss = 0.08567056401034459
Trained batch 755 in epoch 4, gen_loss = 0.8205297745803677, disc_loss = 0.0856846566903331
Trained batch 756 in epoch 4, gen_loss = 0.820467295427776, disc_loss = 0.08565069894248538
Trained batch 757 in epoch 4, gen_loss = 0.8202247218201846, disc_loss = 0.08563992610854886
Trained batch 758 in epoch 4, gen_loss = 0.8198515971894321, disc_loss = 0.08577760537455598
Trained batch 759 in epoch 4, gen_loss = 0.8198070142222078, disc_loss = 0.08587424878374134
Trained batch 760 in epoch 4, gen_loss = 0.8200985541403215, disc_loss = 0.08589929538814452
Trained batch 761 in epoch 4, gen_loss = 0.8201305488041379, disc_loss = 0.08584958667624888
Trained batch 762 in epoch 4, gen_loss = 0.8201944170663741, disc_loss = 0.08577796642767414
Trained batch 763 in epoch 4, gen_loss = 0.8201692354382645, disc_loss = 0.08573304110630879
Trained batch 764 in epoch 4, gen_loss = 0.8200735824949601, disc_loss = 0.08569650113144342
Trained batch 765 in epoch 4, gen_loss = 0.8201833311711528, disc_loss = 0.08572419393107333
Trained batch 766 in epoch 4, gen_loss = 0.8201121030839201, disc_loss = 0.08572736393898298
Trained batch 767 in epoch 4, gen_loss = 0.8199269984615967, disc_loss = 0.08573816202260787
Trained batch 768 in epoch 4, gen_loss = 0.8198848591901856, disc_loss = 0.08572097868453929
Trained batch 769 in epoch 4, gen_loss = 0.8200465099765109, disc_loss = 0.08570343717303756
Trained batch 770 in epoch 4, gen_loss = 0.8201834597708186, disc_loss = 0.0856145271468526
Trained batch 771 in epoch 4, gen_loss = 0.8200908297470196, disc_loss = 0.08556724362644738
Trained batch 772 in epoch 4, gen_loss = 0.8199922784411121, disc_loss = 0.08550203155682821
Trained batch 773 in epoch 4, gen_loss = 0.820517456077174, disc_loss = 0.08551101148542431
Trained batch 774 in epoch 4, gen_loss = 0.8205128465544793, disc_loss = 0.08545672717834672
Trained batch 775 in epoch 4, gen_loss = 0.8202515701120047, disc_loss = 0.08549521917467649
Trained batch 776 in epoch 4, gen_loss = 0.8204815316000807, disc_loss = 0.08542809352288298
Trained batch 777 in epoch 4, gen_loss = 0.8202147991384516, disc_loss = 0.08549682677012406
Trained batch 778 in epoch 4, gen_loss = 0.8201218869857518, disc_loss = 0.0854463191375385
Trained batch 779 in epoch 4, gen_loss = 0.8199329321583112, disc_loss = 0.08542058490073452
Trained batch 780 in epoch 4, gen_loss = 0.8198554168971645, disc_loss = 0.08537693631032746
Trained batch 781 in epoch 4, gen_loss = 0.8201705436496174, disc_loss = 0.08541870766255023
Trained batch 782 in epoch 4, gen_loss = 0.8205039829662781, disc_loss = 0.08540604391288711
Trained batch 783 in epoch 4, gen_loss = 0.8202622501293615, disc_loss = 0.08551366274881804
Trained batch 784 in epoch 4, gen_loss = 0.8200811826879052, disc_loss = 0.08550181667183994
Trained batch 785 in epoch 4, gen_loss = 0.820126556675246, disc_loss = 0.08572840892754817
Trained batch 786 in epoch 4, gen_loss = 0.820789217002207, disc_loss = 0.08569740963415769
Trained batch 787 in epoch 4, gen_loss = 0.820353549030529, disc_loss = 0.08597759798708074
Trained batch 788 in epoch 4, gen_loss = 0.8205747958296303, disc_loss = 0.08593827656249507
Trained batch 789 in epoch 4, gen_loss = 0.8208509299196775, disc_loss = 0.08593082083035496
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.6414321660995483, disc_loss = 0.15500766038894653
Trained batch 1 in epoch 5, gen_loss = 0.6448725759983063, disc_loss = 0.11379802972078323
Trained batch 2 in epoch 5, gen_loss = 0.6541811426480612, disc_loss = 0.1009949545065562
Trained batch 3 in epoch 5, gen_loss = 0.7541747540235519, disc_loss = 0.09347275458276272
Trained batch 4 in epoch 5, gen_loss = 0.7419762253761292, disc_loss = 0.08696087971329688
Trained batch 5 in epoch 5, gen_loss = 0.758095254500707, disc_loss = 0.07916645643611749
Trained batch 6 in epoch 5, gen_loss = 0.7522061126572746, disc_loss = 0.07515867799520493
Trained batch 7 in epoch 5, gen_loss = 0.7699006646871567, disc_loss = 0.0691781344357878
Trained batch 8 in epoch 5, gen_loss = 0.7742682894070944, disc_loss = 0.06460336368117067
Trained batch 9 in epoch 5, gen_loss = 0.7820171654224396, disc_loss = 0.06665786895900964
Trained batch 10 in epoch 5, gen_loss = 0.8037909106774763, disc_loss = 0.06300929324193434
Trained batch 11 in epoch 5, gen_loss = 0.7858104159434637, disc_loss = 0.06302833184599876
Trained batch 12 in epoch 5, gen_loss = 0.8117566337952247, disc_loss = 0.0633883155309237
Trained batch 13 in epoch 5, gen_loss = 0.7966550290584564, disc_loss = 0.06326491758227348
Trained batch 14 in epoch 5, gen_loss = 0.7954274694124858, disc_loss = 0.06253835161526998
Trained batch 15 in epoch 5, gen_loss = 0.8035694099962711, disc_loss = 0.059226481476798654
Trained batch 16 in epoch 5, gen_loss = 0.8092818926362431, disc_loss = 0.06084462890730185
Trained batch 17 in epoch 5, gen_loss = 0.810050669643614, disc_loss = 0.059124565269384116
Trained batch 18 in epoch 5, gen_loss = 0.8021961262351588, disc_loss = 0.06269578351394127
Trained batch 19 in epoch 5, gen_loss = 0.8299528241157532, disc_loss = 0.07916231257840992
Trained batch 20 in epoch 5, gen_loss = 0.8310970181510562, disc_loss = 0.07737147604070958
Trained batch 21 in epoch 5, gen_loss = 0.819516962224787, disc_loss = 0.08046265225857496
Trained batch 22 in epoch 5, gen_loss = 0.8307717312937197, disc_loss = 0.08110281930345556
Trained batch 23 in epoch 5, gen_loss = 0.8232863023877144, disc_loss = 0.08424724304738145
Trained batch 24 in epoch 5, gen_loss = 0.8288651156425476, disc_loss = 0.08333556793630123
Trained batch 25 in epoch 5, gen_loss = 0.8339906747524555, disc_loss = 0.08244454968147553
Trained batch 26 in epoch 5, gen_loss = 0.8224411386030691, disc_loss = 0.08632686672111352
Trained batch 27 in epoch 5, gen_loss = 0.8203317373991013, disc_loss = 0.08616434243906822
Trained batch 28 in epoch 5, gen_loss = 0.8212402668492548, disc_loss = 0.08659763396557035
Trained batch 29 in epoch 5, gen_loss = 0.8228787382443746, disc_loss = 0.0858135965342323
Trained batch 30 in epoch 5, gen_loss = 0.820319321847731, disc_loss = 0.08485717236274673
Trained batch 31 in epoch 5, gen_loss = 0.8156233858317137, disc_loss = 0.08419592800782993
Trained batch 32 in epoch 5, gen_loss = 0.8180047851620298, disc_loss = 0.08317419440683091
Trained batch 33 in epoch 5, gen_loss = 0.8124814278939191, disc_loss = 0.08564960611436297
Trained batch 34 in epoch 5, gen_loss = 0.806171498979841, disc_loss = 0.08699558723185744
Trained batch 35 in epoch 5, gen_loss = 0.814907944864697, disc_loss = 0.08884490576262276
Trained batch 36 in epoch 5, gen_loss = 0.8119256431991989, disc_loss = 0.08827388956135995
Trained batch 37 in epoch 5, gen_loss = 0.813412462410174, disc_loss = 0.0873612942370145
Trained batch 38 in epoch 5, gen_loss = 0.8136370350153018, disc_loss = 0.0861636091214724
Trained batch 39 in epoch 5, gen_loss = 0.8107235118746757, disc_loss = 0.08610524446703494
Trained batch 40 in epoch 5, gen_loss = 0.8138570930899643, disc_loss = 0.08624940224718756
Trained batch 41 in epoch 5, gen_loss = 0.8154989026841664, disc_loss = 0.084507877849752
Trained batch 42 in epoch 5, gen_loss = 0.814885463825492, disc_loss = 0.08341228818997394
Trained batch 43 in epoch 5, gen_loss = 0.8120725940574299, disc_loss = 0.08356757694855332
Trained batch 44 in epoch 5, gen_loss = 0.8071356428994073, disc_loss = 0.08568419611288441
Trained batch 45 in epoch 5, gen_loss = 0.8119892218838567, disc_loss = 0.0862066235150332
Trained batch 46 in epoch 5, gen_loss = 0.808966116702303, disc_loss = 0.08587769573514765
Trained batch 47 in epoch 5, gen_loss = 0.8047227213780085, disc_loss = 0.0861928293403859
Trained batch 48 in epoch 5, gen_loss = 0.8034787080725845, disc_loss = 0.08580683472053129
Trained batch 49 in epoch 5, gen_loss = 0.8069880723953247, disc_loss = 0.08472530532628297
Trained batch 50 in epoch 5, gen_loss = 0.8018817924985698, disc_loss = 0.08474441037020262
Trained batch 51 in epoch 5, gen_loss = 0.8022080224293929, disc_loss = 0.08339251241145226
Trained batch 52 in epoch 5, gen_loss = 0.7997214794158936, disc_loss = 0.08270033990155976
Trained batch 53 in epoch 5, gen_loss = 0.8041083856865212, disc_loss = 0.08161313304056723
Trained batch 54 in epoch 5, gen_loss = 0.8032305500724098, disc_loss = 0.08119019598446109
Trained batch 55 in epoch 5, gen_loss = 0.8024957116161074, disc_loss = 0.08054973181736257
Trained batch 56 in epoch 5, gen_loss = 0.8074456955257215, disc_loss = 0.07975379491976478
Trained batch 57 in epoch 5, gen_loss = 0.8058323819061806, disc_loss = 0.07936819979985213
Trained batch 58 in epoch 5, gen_loss = 0.8103948447663906, disc_loss = 0.07842701891342461
Trained batch 59 in epoch 5, gen_loss = 0.812360766530037, disc_loss = 0.07749451656515399
Trained batch 60 in epoch 5, gen_loss = 0.8126978160905056, disc_loss = 0.07687088954033422
Trained batch 61 in epoch 5, gen_loss = 0.8150856850608703, disc_loss = 0.07887504234789841
Trained batch 62 in epoch 5, gen_loss = 0.8139941304449051, disc_loss = 0.07822093453317408
Trained batch 63 in epoch 5, gen_loss = 0.81179319601506, disc_loss = 0.07875393659924157
Trained batch 64 in epoch 5, gen_loss = 0.8163623653925383, disc_loss = 0.07818103871093346
Trained batch 65 in epoch 5, gen_loss = 0.8227079953208114, disc_loss = 0.07786054178282167
Trained batch 66 in epoch 5, gen_loss = 0.8222976229084071, disc_loss = 0.07764406983198514
Trained batch 67 in epoch 5, gen_loss = 0.8190333457554088, disc_loss = 0.07781241431503612
Trained batch 68 in epoch 5, gen_loss = 0.8188025528106136, disc_loss = 0.07745364073501981
Trained batch 69 in epoch 5, gen_loss = 0.8185071664197104, disc_loss = 0.07679463010281325
Trained batch 70 in epoch 5, gen_loss = 0.8187538528106582, disc_loss = 0.07620246810707408
Trained batch 71 in epoch 5, gen_loss = 0.8191911694076326, disc_loss = 0.07644005841575563
Trained batch 72 in epoch 5, gen_loss = 0.8188763497626945, disc_loss = 0.07586589698003579
Trained batch 73 in epoch 5, gen_loss = 0.820278067846556, disc_loss = 0.07506771901672757
Trained batch 74 in epoch 5, gen_loss = 0.8238245391845703, disc_loss = 0.07440829517940681
Trained batch 75 in epoch 5, gen_loss = 0.8200230527865259, disc_loss = 0.07559659256060657
Trained batch 76 in epoch 5, gen_loss = 0.8247483728767989, disc_loss = 0.07751245470112794
Trained batch 77 in epoch 5, gen_loss = 0.827746732876851, disc_loss = 0.07724080031785445
Trained batch 78 in epoch 5, gen_loss = 0.8249143595936932, disc_loss = 0.07888618477066106
Trained batch 79 in epoch 5, gen_loss = 0.8223698504269124, disc_loss = 0.07903693418484181
Trained batch 80 in epoch 5, gen_loss = 0.8257477585180306, disc_loss = 0.07971585668439482
Trained batch 81 in epoch 5, gen_loss = 0.8245875115801649, disc_loss = 0.07938539407147867
Trained batch 82 in epoch 5, gen_loss = 0.8252766340611929, disc_loss = 0.0788384856184922
Trained batch 83 in epoch 5, gen_loss = 0.824912537421499, disc_loss = 0.07830473813893539
Trained batch 84 in epoch 5, gen_loss = 0.8246301391545464, disc_loss = 0.0785387085421997
Trained batch 85 in epoch 5, gen_loss = 0.8246291910493097, disc_loss = 0.07822204400720291
Trained batch 86 in epoch 5, gen_loss = 0.823445907954512, disc_loss = 0.07821578431831694
Trained batch 87 in epoch 5, gen_loss = 0.8213956227356737, disc_loss = 0.07833761884830892
Trained batch 88 in epoch 5, gen_loss = 0.8246390196714508, disc_loss = 0.0784974539589681
Trained batch 89 in epoch 5, gen_loss = 0.8246525976392958, disc_loss = 0.0788838432273931
Trained batch 90 in epoch 5, gen_loss = 0.8207076997547359, disc_loss = 0.08121987123165157
Trained batch 91 in epoch 5, gen_loss = 0.8240307038244994, disc_loss = 0.08248109882697463
Trained batch 92 in epoch 5, gen_loss = 0.822877908906629, disc_loss = 0.08218937148890829
Trained batch 93 in epoch 5, gen_loss = 0.8217305198628851, disc_loss = 0.08221358891100959
Trained batch 94 in epoch 5, gen_loss = 0.8216275008101213, disc_loss = 0.08240934577035276
Trained batch 95 in epoch 5, gen_loss = 0.8251605437447628, disc_loss = 0.08252390534228955
Trained batch 96 in epoch 5, gen_loss = 0.8232020834057602, disc_loss = 0.08252284858260572
Trained batch 97 in epoch 5, gen_loss = 0.8221481430287264, disc_loss = 0.08243705611675978
Trained batch 98 in epoch 5, gen_loss = 0.8222778493707831, disc_loss = 0.08181846745763764
Trained batch 99 in epoch 5, gen_loss = 0.8211538374423981, disc_loss = 0.08150025853887201
Trained batch 100 in epoch 5, gen_loss = 0.8238449580598586, disc_loss = 0.08135650744016218
Trained batch 101 in epoch 5, gen_loss = 0.8224667135406943, disc_loss = 0.08118824085549396
Trained batch 102 in epoch 5, gen_loss = 0.8224885758844395, disc_loss = 0.08140752010626122
Trained batch 103 in epoch 5, gen_loss = 0.8209072855802683, disc_loss = 0.08123566799510556
Trained batch 104 in epoch 5, gen_loss = 0.8217089425949823, disc_loss = 0.08077312110080606
Trained batch 105 in epoch 5, gen_loss = 0.8210524759202633, disc_loss = 0.08097481008900224
Trained batch 106 in epoch 5, gen_loss = 0.820662896209788, disc_loss = 0.08101324860668072
Trained batch 107 in epoch 5, gen_loss = 0.8199543180289092, disc_loss = 0.08065354732658576
Trained batch 108 in epoch 5, gen_loss = 0.8186407657938266, disc_loss = 0.08127558017747664
Trained batch 109 in epoch 5, gen_loss = 0.8180423720316453, disc_loss = 0.08104558761485599
Trained batch 110 in epoch 5, gen_loss = 0.8172812435004089, disc_loss = 0.08091036946856761
Trained batch 111 in epoch 5, gen_loss = 0.8198229228811604, disc_loss = 0.0806382509181276
Trained batch 112 in epoch 5, gen_loss = 0.8195057437483189, disc_loss = 0.08049048606998625
Trained batch 113 in epoch 5, gen_loss = 0.8180778450087497, disc_loss = 0.08052192299969886
Trained batch 114 in epoch 5, gen_loss = 0.8165081552837206, disc_loss = 0.08033063559104567
Trained batch 115 in epoch 5, gen_loss = 0.8171030380602541, disc_loss = 0.07995370330674381
Trained batch 116 in epoch 5, gen_loss = 0.8202013913382832, disc_loss = 0.0795149106022894
Trained batch 117 in epoch 5, gen_loss = 0.8186779860722817, disc_loss = 0.07941198634709846
Trained batch 118 in epoch 5, gen_loss = 0.8169416995609508, disc_loss = 0.0796250697350552
Trained batch 119 in epoch 5, gen_loss = 0.8172641381621361, disc_loss = 0.07963906528117756
Trained batch 120 in epoch 5, gen_loss = 0.8218515101543142, disc_loss = 0.07960503272835381
Trained batch 121 in epoch 5, gen_loss = 0.8215584026985481, disc_loss = 0.07952723653651163
Trained batch 122 in epoch 5, gen_loss = 0.8203245115473987, disc_loss = 0.07928167969533582
Trained batch 123 in epoch 5, gen_loss = 0.8193705673179319, disc_loss = 0.07890642658176442
Trained batch 124 in epoch 5, gen_loss = 0.8190908255577087, disc_loss = 0.07904270543158054
Trained batch 125 in epoch 5, gen_loss = 0.8181188820846497, disc_loss = 0.07911188511680516
Trained batch 126 in epoch 5, gen_loss = 0.8155268458869513, disc_loss = 0.07988280599100853
Trained batch 127 in epoch 5, gen_loss = 0.8184022912755609, disc_loss = 0.08099901351670269
Trained batch 128 in epoch 5, gen_loss = 0.8208239032316578, disc_loss = 0.08054194775547167
Trained batch 129 in epoch 5, gen_loss = 0.8187708221949064, disc_loss = 0.08104482576824151
Trained batch 130 in epoch 5, gen_loss = 0.8180323311390768, disc_loss = 0.08091479411903228
Trained batch 131 in epoch 5, gen_loss = 0.8182904169414983, disc_loss = 0.0805755074164181
Trained batch 132 in epoch 5, gen_loss = 0.8200232615148214, disc_loss = 0.08165227700220912
Trained batch 133 in epoch 5, gen_loss = 0.819630175384123, disc_loss = 0.08119403370725575
Trained batch 134 in epoch 5, gen_loss = 0.8176050239139133, disc_loss = 0.0819947157745008
Trained batch 135 in epoch 5, gen_loss = 0.8178176840438562, disc_loss = 0.08166769059265361
Trained batch 136 in epoch 5, gen_loss = 0.8186843034124722, disc_loss = 0.08245725342392052
Trained batch 137 in epoch 5, gen_loss = 0.8191559267216835, disc_loss = 0.08205789434251146
Trained batch 138 in epoch 5, gen_loss = 0.8178004159344187, disc_loss = 0.0820379919044191
Trained batch 139 in epoch 5, gen_loss = 0.8172068927969252, disc_loss = 0.08196442716621927
Trained batch 140 in epoch 5, gen_loss = 0.8184384475363061, disc_loss = 0.0815454818281933
Trained batch 141 in epoch 5, gen_loss = 0.8175943590385814, disc_loss = 0.08155315307716668
Trained batch 142 in epoch 5, gen_loss = 0.8165151560223186, disc_loss = 0.08152790160498002
Trained batch 143 in epoch 5, gen_loss = 0.8167299533055888, disc_loss = 0.08122425173254062
Trained batch 144 in epoch 5, gen_loss = 0.8193368027950155, disc_loss = 0.08126310098530917
Trained batch 145 in epoch 5, gen_loss = 0.818880218349091, disc_loss = 0.08109569451325152
Trained batch 146 in epoch 5, gen_loss = 0.8183208793198982, disc_loss = 0.08112922122030436
Trained batch 147 in epoch 5, gen_loss = 0.8161001072542088, disc_loss = 0.08257902407313923
Trained batch 148 in epoch 5, gen_loss = 0.8164110355729225, disc_loss = 0.0829186786916232
Trained batch 149 in epoch 5, gen_loss = 0.8174213222662607, disc_loss = 0.08286928925663233
Trained batch 150 in epoch 5, gen_loss = 0.8157154530878888, disc_loss = 0.08293275494399845
Trained batch 151 in epoch 5, gen_loss = 0.8163760841677064, disc_loss = 0.08291131908711243
Trained batch 152 in epoch 5, gen_loss = 0.8158748013521332, disc_loss = 0.08281285864806254
Trained batch 153 in epoch 5, gen_loss = 0.8172108999320439, disc_loss = 0.08244559090197473
Trained batch 154 in epoch 5, gen_loss = 0.8166772546306733, disc_loss = 0.08248069304372034
Trained batch 155 in epoch 5, gen_loss = 0.8181348118262414, disc_loss = 0.08301232400565194
Trained batch 156 in epoch 5, gen_loss = 0.8167739624430419, disc_loss = 0.08303208999145942
Trained batch 157 in epoch 5, gen_loss = 0.8177834862395178, disc_loss = 0.08271465810086531
Trained batch 158 in epoch 5, gen_loss = 0.8191346979741031, disc_loss = 0.08296775730010474
Trained batch 159 in epoch 5, gen_loss = 0.8187783289700746, disc_loss = 0.08271566232433543
Trained batch 160 in epoch 5, gen_loss = 0.8177874325225072, disc_loss = 0.08272989963106117
Trained batch 161 in epoch 5, gen_loss = 0.8176322491080673, disc_loss = 0.0824260854817651
Trained batch 162 in epoch 5, gen_loss = 0.8182108387625291, disc_loss = 0.0822392616283857
Trained batch 163 in epoch 5, gen_loss = 0.8203149910380201, disc_loss = 0.08213041487672343
Trained batch 164 in epoch 5, gen_loss = 0.8193212259899486, disc_loss = 0.08226924860341982
Trained batch 165 in epoch 5, gen_loss = 0.8209706038595682, disc_loss = 0.08194208485130446
Trained batch 166 in epoch 5, gen_loss = 0.8217454502682486, disc_loss = 0.08169104938512434
Trained batch 167 in epoch 5, gen_loss = 0.8214445046725727, disc_loss = 0.0815405445505998
Trained batch 168 in epoch 5, gen_loss = 0.8231532577226853, disc_loss = 0.08156736872913922
Trained batch 169 in epoch 5, gen_loss = 0.821926306626376, disc_loss = 0.0820951040067217
Trained batch 170 in epoch 5, gen_loss = 0.8226568827852171, disc_loss = 0.08209002613803448
Trained batch 171 in epoch 5, gen_loss = 0.8220845322276271, disc_loss = 0.0819147257026025
Trained batch 172 in epoch 5, gen_loss = 0.8235392246632217, disc_loss = 0.08156341812815625
Trained batch 173 in epoch 5, gen_loss = 0.8230093155784168, disc_loss = 0.08156824723185821
Trained batch 174 in epoch 5, gen_loss = 0.8239911821910313, disc_loss = 0.08120841402028288
Trained batch 175 in epoch 5, gen_loss = 0.8256121284582398, disc_loss = 0.08087013637520034
Trained batch 176 in epoch 5, gen_loss = 0.8257403084113772, disc_loss = 0.08058362057443055
Trained batch 177 in epoch 5, gen_loss = 0.8273940166730559, disc_loss = 0.08035755235952942
Trained batch 178 in epoch 5, gen_loss = 0.8275732218220248, disc_loss = 0.0800798951372421
Trained batch 179 in epoch 5, gen_loss = 0.8266494909922282, disc_loss = 0.07991099560426342
Trained batch 180 in epoch 5, gen_loss = 0.8289379941824392, disc_loss = 0.0798670594369509
Trained batch 181 in epoch 5, gen_loss = 0.8282984121815189, disc_loss = 0.07982325021709714
Trained batch 182 in epoch 5, gen_loss = 0.8293532426240015, disc_loss = 0.07943834195452962
Trained batch 183 in epoch 5, gen_loss = 0.8282120380064716, disc_loss = 0.07955528741054561
Trained batch 184 in epoch 5, gen_loss = 0.8306542567304662, disc_loss = 0.07969236931688077
Trained batch 185 in epoch 5, gen_loss = 0.8309644351723373, disc_loss = 0.07932806569802504
Trained batch 186 in epoch 5, gen_loss = 0.8301252891673124, disc_loss = 0.07928882971565354
Trained batch 187 in epoch 5, gen_loss = 0.8298481113099038, disc_loss = 0.07904157918342884
Trained batch 188 in epoch 5, gen_loss = 0.8306903012845882, disc_loss = 0.07950661000278261
Trained batch 189 in epoch 5, gen_loss = 0.8294383823871613, disc_loss = 0.07998252546316699
Trained batch 190 in epoch 5, gen_loss = 0.8283134730074418, disc_loss = 0.08001949782458899
Trained batch 191 in epoch 5, gen_loss = 0.8291927917550007, disc_loss = 0.07991518367392321
Trained batch 192 in epoch 5, gen_loss = 0.8294546931518791, disc_loss = 0.08009448276900256
Trained batch 193 in epoch 5, gen_loss = 0.8281421311122855, disc_loss = 0.08027605055687353
Trained batch 194 in epoch 5, gen_loss = 0.8282302104509793, disc_loss = 0.08009885568649341
Trained batch 195 in epoch 5, gen_loss = 0.8275949924576039, disc_loss = 0.08027639274238324
Trained batch 196 in epoch 5, gen_loss = 0.8265733349746859, disc_loss = 0.08044175860391656
Trained batch 197 in epoch 5, gen_loss = 0.8271942864162753, disc_loss = 0.0804551499660569
Trained batch 198 in epoch 5, gen_loss = 0.8271884519850189, disc_loss = 0.08016423143483886
Trained batch 199 in epoch 5, gen_loss = 0.8276138052344322, disc_loss = 0.08004908641800285
Trained batch 200 in epoch 5, gen_loss = 0.8273198429624833, disc_loss = 0.07998448997661842
Trained batch 201 in epoch 5, gen_loss = 0.8264615880970908, disc_loss = 0.07982533323661525
Trained batch 202 in epoch 5, gen_loss = 0.8268702752484477, disc_loss = 0.0795661814675983
Trained batch 203 in epoch 5, gen_loss = 0.8287328955005197, disc_loss = 0.07948391335815483
Trained batch 204 in epoch 5, gen_loss = 0.8287157169202479, disc_loss = 0.07928641459382162
Trained batch 205 in epoch 5, gen_loss = 0.8283858270321077, disc_loss = 0.07903063110103017
Trained batch 206 in epoch 5, gen_loss = 0.8291169946320391, disc_loss = 0.07892046079651457
Trained batch 207 in epoch 5, gen_loss = 0.8281113132834435, disc_loss = 0.07897634900067575
Trained batch 208 in epoch 5, gen_loss = 0.828211542236748, disc_loss = 0.07872566357967956
Trained batch 209 in epoch 5, gen_loss = 0.8280836269969032, disc_loss = 0.07852453589439393
Trained batch 210 in epoch 5, gen_loss = 0.8279919090429189, disc_loss = 0.07866826678198095
Trained batch 211 in epoch 5, gen_loss = 0.8284974548051942, disc_loss = 0.07850814789955346
Trained batch 212 in epoch 5, gen_loss = 0.8280483646571916, disc_loss = 0.07833821886162243
Trained batch 213 in epoch 5, gen_loss = 0.8291721460975219, disc_loss = 0.07802848934813916
Trained batch 214 in epoch 5, gen_loss = 0.8306229729985082, disc_loss = 0.07782317710997061
Trained batch 215 in epoch 5, gen_loss = 0.8304463387639435, disc_loss = 0.07762220499312712
Trained batch 216 in epoch 5, gen_loss = 0.829132083923586, disc_loss = 0.07771574607127547
Trained batch 217 in epoch 5, gen_loss = 0.830796181061946, disc_loss = 0.07772646004487889
Trained batch 218 in epoch 5, gen_loss = 0.8309361580844339, disc_loss = 0.0774562068657788
Trained batch 219 in epoch 5, gen_loss = 0.830014263770797, disc_loss = 0.0776804138652303
Trained batch 220 in epoch 5, gen_loss = 0.8291693505118874, disc_loss = 0.07757416332132136
Trained batch 221 in epoch 5, gen_loss = 0.8298522851488612, disc_loss = 0.07798207213951124
Trained batch 222 in epoch 5, gen_loss = 0.8291214271511198, disc_loss = 0.07807045581963565
Trained batch 223 in epoch 5, gen_loss = 0.8293658585420677, disc_loss = 0.07781464039414589
Trained batch 224 in epoch 5, gen_loss = 0.8296567487716675, disc_loss = 0.07774413971437348
Trained batch 225 in epoch 5, gen_loss = 0.8293801437964482, disc_loss = 0.07760257074461047
Trained batch 226 in epoch 5, gen_loss = 0.8282816178998232, disc_loss = 0.07784621507782769
Trained batch 227 in epoch 5, gen_loss = 0.8292552499394668, disc_loss = 0.07827544753161962
Trained batch 228 in epoch 5, gen_loss = 0.8285068052304364, disc_loss = 0.07858903021205982
Trained batch 229 in epoch 5, gen_loss = 0.8274103112842726, disc_loss = 0.0790249928670085
Trained batch 230 in epoch 5, gen_loss = 0.827736378232122, disc_loss = 0.07910465063664304
Trained batch 231 in epoch 5, gen_loss = 0.8274105047357494, disc_loss = 0.07908359572997894
Trained batch 232 in epoch 5, gen_loss = 0.8273211968303238, disc_loss = 0.07901513981013339
Trained batch 233 in epoch 5, gen_loss = 0.8265442932263399, disc_loss = 0.07903256733766478
Trained batch 234 in epoch 5, gen_loss = 0.8279451616266941, disc_loss = 0.07891438904594868
Trained batch 235 in epoch 5, gen_loss = 0.8271872115842367, disc_loss = 0.07925275823701236
Trained batch 236 in epoch 5, gen_loss = 0.8280108787339447, disc_loss = 0.0799892614851018
Trained batch 237 in epoch 5, gen_loss = 0.8269085956721747, disc_loss = 0.08023753965727422
Trained batch 238 in epoch 5, gen_loss = 0.8278265779986043, disc_loss = 0.0803867096868519
Trained batch 239 in epoch 5, gen_loss = 0.827556295444568, disc_loss = 0.08051828953127066
Trained batch 240 in epoch 5, gen_loss = 0.8266237813407454, disc_loss = 0.08101812722277345
Trained batch 241 in epoch 5, gen_loss = 0.8262734134827764, disc_loss = 0.08103523344909849
Trained batch 242 in epoch 5, gen_loss = 0.8269692769757023, disc_loss = 0.081066329415443
Trained batch 243 in epoch 5, gen_loss = 0.8269189312809804, disc_loss = 0.08086121077725633
Trained batch 244 in epoch 5, gen_loss = 0.825884696902061, disc_loss = 0.08089353160894647
Trained batch 245 in epoch 5, gen_loss = 0.825801153250826, disc_loss = 0.0807672901518219
Trained batch 246 in epoch 5, gen_loss = 0.8260352054105596, disc_loss = 0.08064107845729662
Trained batch 247 in epoch 5, gen_loss = 0.8253178697439932, disc_loss = 0.08062297831319513
Trained batch 248 in epoch 5, gen_loss = 0.8252086902717989, disc_loss = 0.08045135816955662
Trained batch 249 in epoch 5, gen_loss = 0.8268444819450378, disc_loss = 0.0807034098058939
Trained batch 250 in epoch 5, gen_loss = 0.8264910925432031, disc_loss = 0.0806529789242849
Trained batch 251 in epoch 5, gen_loss = 0.8256796421039672, disc_loss = 0.08074660659841602
Trained batch 252 in epoch 5, gen_loss = 0.8270297472184825, disc_loss = 0.08092825534374347
Trained batch 253 in epoch 5, gen_loss = 0.8263212723994818, disc_loss = 0.08095556956635216
Trained batch 254 in epoch 5, gen_loss = 0.8259559425653196, disc_loss = 0.08087349614384128
Trained batch 255 in epoch 5, gen_loss = 0.8258184599690139, disc_loss = 0.08071782220213208
Trained batch 256 in epoch 5, gen_loss = 0.8278698754217838, disc_loss = 0.08076181127925328
Trained batch 257 in epoch 5, gen_loss = 0.8276980468469073, disc_loss = 0.08065949403500372
Trained batch 258 in epoch 5, gen_loss = 0.8271963789656356, disc_loss = 0.08071515280537624
Trained batch 259 in epoch 5, gen_loss = 0.8272097734304574, disc_loss = 0.08056839168644868
Trained batch 260 in epoch 5, gen_loss = 0.8264216611668525, disc_loss = 0.08088183874028852
Trained batch 261 in epoch 5, gen_loss = 0.8268737870318289, disc_loss = 0.08097417894324274
Trained batch 262 in epoch 5, gen_loss = 0.8258388813004294, disc_loss = 0.08111287013206192
Trained batch 263 in epoch 5, gen_loss = 0.8259467292915691, disc_loss = 0.08099250104560544
Trained batch 264 in epoch 5, gen_loss = 0.8255325679509145, disc_loss = 0.08100055319801816
Trained batch 265 in epoch 5, gen_loss = 0.8253997219236273, disc_loss = 0.08077773134595245
Trained batch 266 in epoch 5, gen_loss = 0.827406258618787, disc_loss = 0.08076915682785296
Trained batch 267 in epoch 5, gen_loss = 0.8270636263178356, disc_loss = 0.08073206356406878
Trained batch 268 in epoch 5, gen_loss = 0.8270538447071628, disc_loss = 0.08051459845086234
Trained batch 269 in epoch 5, gen_loss = 0.8261750221252442, disc_loss = 0.08055156076809875
Trained batch 270 in epoch 5, gen_loss = 0.8272898676650551, disc_loss = 0.08034486585465085
Trained batch 271 in epoch 5, gen_loss = 0.8281471847611315, disc_loss = 0.08041343175778713
Trained batch 272 in epoch 5, gen_loss = 0.8277069531080924, disc_loss = 0.0802342320550165
Trained batch 273 in epoch 5, gen_loss = 0.8274565169410985, disc_loss = 0.08019856551838835
Trained batch 274 in epoch 5, gen_loss = 0.8268196853724393, disc_loss = 0.08062000651928511
Trained batch 275 in epoch 5, gen_loss = 0.8265206293351408, disc_loss = 0.08087396274145314
Trained batch 276 in epoch 5, gen_loss = 0.8269611926285368, disc_loss = 0.08088731895527039
Trained batch 277 in epoch 5, gen_loss = 0.8269766905753733, disc_loss = 0.08071546152689689
Trained batch 278 in epoch 5, gen_loss = 0.8264983283576145, disc_loss = 0.08070436483883302
Trained batch 279 in epoch 5, gen_loss = 0.8266348053302084, disc_loss = 0.08065510773366051
Trained batch 280 in epoch 5, gen_loss = 0.8265231701402902, disc_loss = 0.0804629590746771
Trained batch 281 in epoch 5, gen_loss = 0.8259801025508989, disc_loss = 0.08053732742654517
Trained batch 282 in epoch 5, gen_loss = 0.8259741305883698, disc_loss = 0.08043479262571453
Trained batch 283 in epoch 5, gen_loss = 0.827481198688628, disc_loss = 0.08036865262498319
Trained batch 284 in epoch 5, gen_loss = 0.8264645047355117, disc_loss = 0.08098283755151849
Trained batch 285 in epoch 5, gen_loss = 0.8266755873923535, disc_loss = 0.08094680139964278
Trained batch 286 in epoch 5, gen_loss = 0.8273021815545883, disc_loss = 0.08123291429223084
Trained batch 287 in epoch 5, gen_loss = 0.8270438147915734, disc_loss = 0.08135787076834175
Trained batch 288 in epoch 5, gen_loss = 0.8265347394151259, disc_loss = 0.0815260451557727
Trained batch 289 in epoch 5, gen_loss = 0.8263416705460384, disc_loss = 0.08144217593402699
Trained batch 290 in epoch 5, gen_loss = 0.8268500869626442, disc_loss = 0.08164131905102648
Trained batch 291 in epoch 5, gen_loss = 0.8260308595961088, disc_loss = 0.08198007857044266
Trained batch 292 in epoch 5, gen_loss = 0.8263386127891801, disc_loss = 0.08182539002582075
Trained batch 293 in epoch 5, gen_loss = 0.8262988606683251, disc_loss = 0.08164690880953861
Trained batch 294 in epoch 5, gen_loss = 0.8264853263305405, disc_loss = 0.0816588986980713
Trained batch 295 in epoch 5, gen_loss = 0.8255551394981306, disc_loss = 0.08188567831608895
Trained batch 296 in epoch 5, gen_loss = 0.8256150028520963, disc_loss = 0.0817580765696487
Trained batch 297 in epoch 5, gen_loss = 0.826605740609585, disc_loss = 0.08182447101145783
Trained batch 298 in epoch 5, gen_loss = 0.8263528681917732, disc_loss = 0.08168437039124526
Trained batch 299 in epoch 5, gen_loss = 0.8252611352006595, disc_loss = 0.0821053830658396
Trained batch 300 in epoch 5, gen_loss = 0.8251891426271775, disc_loss = 0.08200279086135155
Trained batch 301 in epoch 5, gen_loss = 0.8264946192502975, disc_loss = 0.08255664185182937
Trained batch 302 in epoch 5, gen_loss = 0.8256003184877213, disc_loss = 0.08282666503399512
Trained batch 303 in epoch 5, gen_loss = 0.8245857264846563, disc_loss = 0.08287401355214809
Trained batch 304 in epoch 5, gen_loss = 0.8244000834519746, disc_loss = 0.08291691490372674
Trained batch 305 in epoch 5, gen_loss = 0.8242905394119375, disc_loss = 0.08302071422728058
Trained batch 306 in epoch 5, gen_loss = 0.824231449381148, disc_loss = 0.08292993632560833
Trained batch 307 in epoch 5, gen_loss = 0.823687398878785, disc_loss = 0.08315257651900704
Trained batch 308 in epoch 5, gen_loss = 0.8241599421092222, disc_loss = 0.08323861447593926
Trained batch 309 in epoch 5, gen_loss = 0.8240133797930133, disc_loss = 0.08313130477984106
Trained batch 310 in epoch 5, gen_loss = 0.8239152992078346, disc_loss = 0.08297853568311289
Trained batch 311 in epoch 5, gen_loss = 0.8235237490481291, disc_loss = 0.08305152631006561
Trained batch 312 in epoch 5, gen_loss = 0.8230067690530904, disc_loss = 0.08325330133493335
Trained batch 313 in epoch 5, gen_loss = 0.8228622778395939, disc_loss = 0.08326045125960164
Trained batch 314 in epoch 5, gen_loss = 0.8216072681404295, disc_loss = 0.08352099497403417
Trained batch 315 in epoch 5, gen_loss = 0.8212810018205945, disc_loss = 0.08370639832949714
Trained batch 316 in epoch 5, gen_loss = 0.8207214280069814, disc_loss = 0.08366583904680394
Trained batch 317 in epoch 5, gen_loss = 0.8211748265432861, disc_loss = 0.08401755469634473
Trained batch 318 in epoch 5, gen_loss = 0.820272201934952, disc_loss = 0.0844237780706449
Trained batch 319 in epoch 5, gen_loss = 0.819920918252319, disc_loss = 0.08430483470438048
Trained batch 320 in epoch 5, gen_loss = 0.820616163847231, disc_loss = 0.08417850800113887
Trained batch 321 in epoch 5, gen_loss = 0.8205912863800985, disc_loss = 0.0842185729640241
Trained batch 322 in epoch 5, gen_loss = 0.8201023999936071, disc_loss = 0.08417532929787326
Trained batch 323 in epoch 5, gen_loss = 0.819695388921249, disc_loss = 0.0842526792836042
Trained batch 324 in epoch 5, gen_loss = 0.8187887563155247, disc_loss = 0.08437316667575102
Trained batch 325 in epoch 5, gen_loss = 0.8185020931110791, disc_loss = 0.08443052899892345
Trained batch 326 in epoch 5, gen_loss = 0.8186648931889724, disc_loss = 0.08423646298502016
Trained batch 327 in epoch 5, gen_loss = 0.8191697376712066, disc_loss = 0.0840333567182647
Trained batch 328 in epoch 5, gen_loss = 0.8189794601459272, disc_loss = 0.0839025834433757
Trained batch 329 in epoch 5, gen_loss = 0.819243118889404, disc_loss = 0.08381691314280033
Trained batch 330 in epoch 5, gen_loss = 0.8197051030091289, disc_loss = 0.083594837740874
Trained batch 331 in epoch 5, gen_loss = 0.8197488220161703, disc_loss = 0.08338974808701818
Trained batch 332 in epoch 5, gen_loss = 0.819426401509895, disc_loss = 0.08325811008735373
Trained batch 333 in epoch 5, gen_loss = 0.8194816265099063, disc_loss = 0.08319168117086956
Trained batch 334 in epoch 5, gen_loss = 0.8195880762676695, disc_loss = 0.08299624917389296
Trained batch 335 in epoch 5, gen_loss = 0.8191425231773228, disc_loss = 0.08319705021512207
Trained batch 336 in epoch 5, gen_loss = 0.8183218924334212, disc_loss = 0.08346265613844822
Trained batch 337 in epoch 5, gen_loss = 0.8178478801215189, disc_loss = 0.08343186826560889
Trained batch 338 in epoch 5, gen_loss = 0.819061635254407, disc_loss = 0.0836643811980136
Trained batch 339 in epoch 5, gen_loss = 0.8184131165637689, disc_loss = 0.08376474233398981
Trained batch 340 in epoch 5, gen_loss = 0.8175037088107503, disc_loss = 0.0838131555424364
Trained batch 341 in epoch 5, gen_loss = 0.8183148697628613, disc_loss = 0.08400847370414967
Trained batch 342 in epoch 5, gen_loss = 0.8178525633957922, disc_loss = 0.0842701774877944
Trained batch 343 in epoch 5, gen_loss = 0.8175221514389959, disc_loss = 0.08449334352071462
Trained batch 344 in epoch 5, gen_loss = 0.8176516205504321, disc_loss = 0.08431974317122629
Trained batch 345 in epoch 5, gen_loss = 0.8182784564405507, disc_loss = 0.08417241834373229
Trained batch 346 in epoch 5, gen_loss = 0.8186149336934433, disc_loss = 0.08400497282519721
Trained batch 347 in epoch 5, gen_loss = 0.8182488454655669, disc_loss = 0.08400560052391014
Trained batch 348 in epoch 5, gen_loss = 0.818644506968878, disc_loss = 0.08407934938416013
Trained batch 349 in epoch 5, gen_loss = 0.8183318040200642, disc_loss = 0.0840183511136898
Trained batch 350 in epoch 5, gen_loss = 0.8182226727660905, disc_loss = 0.08390917961997779
Trained batch 351 in epoch 5, gen_loss = 0.818295649760826, disc_loss = 0.08454527836875059
Trained batch 352 in epoch 5, gen_loss = 0.8176042722068495, disc_loss = 0.08458370387965744
Trained batch 353 in epoch 5, gen_loss = 0.8168068801784246, disc_loss = 0.08485867335371632
Trained batch 354 in epoch 5, gen_loss = 0.8171949901211429, disc_loss = 0.08532949778133295
Trained batch 355 in epoch 5, gen_loss = 0.8166448005966926, disc_loss = 0.08554608261558029
Trained batch 356 in epoch 5, gen_loss = 0.816975472771487, disc_loss = 0.08542004217985882
Trained batch 357 in epoch 5, gen_loss = 0.8174665308031956, disc_loss = 0.08530488773379162
Trained batch 358 in epoch 5, gen_loss = 0.8165371438752974, disc_loss = 0.08581323042501564
Trained batch 359 in epoch 5, gen_loss = 0.8165921808116966, disc_loss = 0.08653115916531533
Trained batch 360 in epoch 5, gen_loss = 0.8161548966350978, disc_loss = 0.08684604671471585
Trained batch 361 in epoch 5, gen_loss = 0.8155823698195305, disc_loss = 0.08725871673388952
Trained batch 362 in epoch 5, gen_loss = 0.8160309360539617, disc_loss = 0.08724767460998342
Trained batch 363 in epoch 5, gen_loss = 0.8167453358297819, disc_loss = 0.08753992873755703
Trained batch 364 in epoch 5, gen_loss = 0.8169147925017631, disc_loss = 0.0874064885870847
Trained batch 365 in epoch 5, gen_loss = 0.8163261526757902, disc_loss = 0.08751480109083766
Trained batch 366 in epoch 5, gen_loss = 0.8167453599073582, disc_loss = 0.08764027098412004
Trained batch 367 in epoch 5, gen_loss = 0.8159909373878137, disc_loss = 0.08774564786480092
Trained batch 368 in epoch 5, gen_loss = 0.8158918012609973, disc_loss = 0.08763285688702573
Trained batch 369 in epoch 5, gen_loss = 0.8167995134720931, disc_loss = 0.087576297819111
Trained batch 370 in epoch 5, gen_loss = 0.8160977582886534, disc_loss = 0.08754203021476131
Trained batch 371 in epoch 5, gen_loss = 0.8155631744252738, disc_loss = 0.08754082233144311
Trained batch 372 in epoch 5, gen_loss = 0.8162154698339927, disc_loss = 0.0877136477910921
Trained batch 373 in epoch 5, gen_loss = 0.8168364324193588, disc_loss = 0.08751506108621304
Trained batch 374 in epoch 5, gen_loss = 0.8161002144018809, disc_loss = 0.08770979779213667
Trained batch 375 in epoch 5, gen_loss = 0.8156025369275124, disc_loss = 0.08821192456339981
Trained batch 376 in epoch 5, gen_loss = 0.8159988031621321, disc_loss = 0.08804953903878794
Trained batch 377 in epoch 5, gen_loss = 0.8159296008802596, disc_loss = 0.08798049255545257
Trained batch 378 in epoch 5, gen_loss = 0.8159087612477959, disc_loss = 0.08783406507970869
Trained batch 379 in epoch 5, gen_loss = 0.8161413946434071, disc_loss = 0.08781818807566244
Trained batch 380 in epoch 5, gen_loss = 0.815706227316944, disc_loss = 0.08789765441012899
Trained batch 381 in epoch 5, gen_loss = 0.8157837048407001, disc_loss = 0.08779487028688739
Trained batch 382 in epoch 5, gen_loss = 0.8154038264763884, disc_loss = 0.0877694531073964
Trained batch 383 in epoch 5, gen_loss = 0.8157428202684969, disc_loss = 0.08777414046198828
Trained batch 384 in epoch 5, gen_loss = 0.8155104526451655, disc_loss = 0.08772151606858938
Trained batch 385 in epoch 5, gen_loss = 0.8150958614182596, disc_loss = 0.08766499417713346
Trained batch 386 in epoch 5, gen_loss = 0.8151147731360847, disc_loss = 0.08753181230854387
Trained batch 387 in epoch 5, gen_loss = 0.8152170054537734, disc_loss = 0.08754286094395847
Trained batch 388 in epoch 5, gen_loss = 0.815168399047729, disc_loss = 0.08764059172469194
Trained batch 389 in epoch 5, gen_loss = 0.81491173910789, disc_loss = 0.08763148636819842
Trained batch 390 in epoch 5, gen_loss = 0.8143713746381842, disc_loss = 0.08771291162933001
Trained batch 391 in epoch 5, gen_loss = 0.8144842098105927, disc_loss = 0.08803130014637979
Trained batch 392 in epoch 5, gen_loss = 0.8144322986366185, disc_loss = 0.08791159118262638
Trained batch 393 in epoch 5, gen_loss = 0.8139878360904412, disc_loss = 0.08798939281091245
Trained batch 394 in epoch 5, gen_loss = 0.813569241007672, disc_loss = 0.08794643732047157
Trained batch 395 in epoch 5, gen_loss = 0.8132950047200377, disc_loss = 0.08791048411101178
Trained batch 396 in epoch 5, gen_loss = 0.8134267048661594, disc_loss = 0.08783634622776013
Trained batch 397 in epoch 5, gen_loss = 0.8127575391650799, disc_loss = 0.08784165224247617
Trained batch 398 in epoch 5, gen_loss = 0.8137960222580081, disc_loss = 0.08787901339384921
Trained batch 399 in epoch 5, gen_loss = 0.8136285405606032, disc_loss = 0.08784617932746187
Trained batch 400 in epoch 5, gen_loss = 0.813558092512692, disc_loss = 0.08773939120362599
Trained batch 401 in epoch 5, gen_loss = 0.8139059796410414, disc_loss = 0.08755349180897448
Trained batch 402 in epoch 5, gen_loss = 0.8138694018495289, disc_loss = 0.08760000390252537
Trained batch 403 in epoch 5, gen_loss = 0.8136106662378453, disc_loss = 0.08755226647435217
Trained batch 404 in epoch 5, gen_loss = 0.8137174268563588, disc_loss = 0.08742059530161413
Trained batch 405 in epoch 5, gen_loss = 0.8135550398691535, disc_loss = 0.08735744226861543
Trained batch 406 in epoch 5, gen_loss = 0.8135397067380479, disc_loss = 0.08723575755706657
Trained batch 407 in epoch 5, gen_loss = 0.8134569598033148, disc_loss = 0.08714688229876771
Trained batch 408 in epoch 5, gen_loss = 0.8141001861515138, disc_loss = 0.08730628168606598
Trained batch 409 in epoch 5, gen_loss = 0.8141951880077036, disc_loss = 0.08719690320559027
Trained batch 410 in epoch 5, gen_loss = 0.813380886023352, disc_loss = 0.08805168271653917
Trained batch 411 in epoch 5, gen_loss = 0.8143921394660635, disc_loss = 0.08857016542302534
Trained batch 412 in epoch 5, gen_loss = 0.8141943336110427, disc_loss = 0.08854453817920953
Trained batch 413 in epoch 5, gen_loss = 0.8133024881427414, disc_loss = 0.08894673177234577
Trained batch 414 in epoch 5, gen_loss = 0.8129669695015413, disc_loss = 0.08889548703354884
Trained batch 415 in epoch 5, gen_loss = 0.8132743782435472, disc_loss = 0.08877910186688845
Trained batch 416 in epoch 5, gen_loss = 0.8132075778871989, disc_loss = 0.0889104045145839
Trained batch 417 in epoch 5, gen_loss = 0.8132475516157287, disc_loss = 0.08884602878019926
Trained batch 418 in epoch 5, gen_loss = 0.8128983953118609, disc_loss = 0.08890988252976985
Trained batch 419 in epoch 5, gen_loss = 0.8126043515545981, disc_loss = 0.08890477051914093
Trained batch 420 in epoch 5, gen_loss = 0.812188444964393, disc_loss = 0.08881642046714126
Trained batch 421 in epoch 5, gen_loss = 0.8128734372238412, disc_loss = 0.08864816078051077
Trained batch 422 in epoch 5, gen_loss = 0.812991516809937, disc_loss = 0.0885497245950796
Trained batch 423 in epoch 5, gen_loss = 0.8126840320117069, disc_loss = 0.08846998871260164
Trained batch 424 in epoch 5, gen_loss = 0.8120322164367227, disc_loss = 0.0885594534808222
Trained batch 425 in epoch 5, gen_loss = 0.8125226182836882, disc_loss = 0.08874251605383178
Trained batch 426 in epoch 5, gen_loss = 0.8121458836405842, disc_loss = 0.0886672788192747
Trained batch 427 in epoch 5, gen_loss = 0.8116683836016699, disc_loss = 0.08864359059109936
Trained batch 428 in epoch 5, gen_loss = 0.8121122256581322, disc_loss = 0.08868520381471841
Trained batch 429 in epoch 5, gen_loss = 0.8116886227629906, disc_loss = 0.08877110418235493
Trained batch 430 in epoch 5, gen_loss = 0.8115163065164659, disc_loss = 0.08871976145502102
Trained batch 431 in epoch 5, gen_loss = 0.8115352962028097, disc_loss = 0.0886419899610768
Trained batch 432 in epoch 5, gen_loss = 0.8112175331104711, disc_loss = 0.08860816158070368
Trained batch 433 in epoch 5, gen_loss = 0.811534328669447, disc_loss = 0.08857125244940275
Trained batch 434 in epoch 5, gen_loss = 0.8116559491760429, disc_loss = 0.08846733030788172
Trained batch 435 in epoch 5, gen_loss = 0.811832900441021, disc_loss = 0.08830696476170571
Trained batch 436 in epoch 5, gen_loss = 0.8126729936839787, disc_loss = 0.08833895213006904
Trained batch 437 in epoch 5, gen_loss = 0.8124328122291391, disc_loss = 0.08828657374134687
Trained batch 438 in epoch 5, gen_loss = 0.8121312727689199, disc_loss = 0.08839909367662152
Trained batch 439 in epoch 5, gen_loss = 0.8126093424179337, disc_loss = 0.08841242003042928
Trained batch 440 in epoch 5, gen_loss = 0.8124986070624285, disc_loss = 0.088356272976364
Trained batch 441 in epoch 5, gen_loss = 0.8126413242309881, disc_loss = 0.08822870735980874
Trained batch 442 in epoch 5, gen_loss = 0.8127094676747548, disc_loss = 0.08820838833744922
Trained batch 443 in epoch 5, gen_loss = 0.8124745394195523, disc_loss = 0.08823603372559422
Trained batch 444 in epoch 5, gen_loss = 0.8123865161049232, disc_loss = 0.08842126430127394
Trained batch 445 in epoch 5, gen_loss = 0.811997599264966, disc_loss = 0.08849378666243278
Trained batch 446 in epoch 5, gen_loss = 0.8122737059657206, disc_loss = 0.08850462425716837
Trained batch 447 in epoch 5, gen_loss = 0.8120218436898929, disc_loss = 0.08851188498790309
Trained batch 448 in epoch 5, gen_loss = 0.811359192586954, disc_loss = 0.08856074838278885
Trained batch 449 in epoch 5, gen_loss = 0.8128691122266981, disc_loss = 0.08904794114538366
Trained batch 450 in epoch 5, gen_loss = 0.8123987161135198, disc_loss = 0.08939296877147948
Trained batch 451 in epoch 5, gen_loss = 0.8125261576038546, disc_loss = 0.08938979861260582
Trained batch 452 in epoch 5, gen_loss = 0.8129902355718297, disc_loss = 0.08942548731017126
Trained batch 453 in epoch 5, gen_loss = 0.8128521691860081, disc_loss = 0.08929564951742601
Trained batch 454 in epoch 5, gen_loss = 0.813153243457878, disc_loss = 0.08919953281612514
Trained batch 455 in epoch 5, gen_loss = 0.8128307042153258, disc_loss = 0.08909486308734733
Trained batch 456 in epoch 5, gen_loss = 0.8124655178652289, disc_loss = 0.08906016310705463
Trained batch 457 in epoch 5, gen_loss = 0.8128255397471799, disc_loss = 0.08898390632928004
Trained batch 458 in epoch 5, gen_loss = 0.8126284369715938, disc_loss = 0.08888848171587668
Trained batch 459 in epoch 5, gen_loss = 0.8130917906761169, disc_loss = 0.0888557700055611
Trained batch 460 in epoch 5, gen_loss = 0.8125898134682545, disc_loss = 0.08892030113956481
Trained batch 461 in epoch 5, gen_loss = 0.8124432492823828, disc_loss = 0.08881598309658113
Trained batch 462 in epoch 5, gen_loss = 0.8124788855373474, disc_loss = 0.08878614871157232
Trained batch 463 in epoch 5, gen_loss = 0.812313841463163, disc_loss = 0.088832239301249
Trained batch 464 in epoch 5, gen_loss = 0.8120320403447715, disc_loss = 0.0888073990762394
Trained batch 465 in epoch 5, gen_loss = 0.8117198743277865, disc_loss = 0.08906714765498887
Trained batch 466 in epoch 5, gen_loss = 0.8113685723800986, disc_loss = 0.08908100289190926
Trained batch 467 in epoch 5, gen_loss = 0.8111169631155128, disc_loss = 0.08903795718135805
Trained batch 468 in epoch 5, gen_loss = 0.8112288652452578, disc_loss = 0.08894852402884124
Trained batch 469 in epoch 5, gen_loss = 0.8115245325768248, disc_loss = 0.08888103482610685
Trained batch 470 in epoch 5, gen_loss = 0.8115198514770298, disc_loss = 0.08875112136877329
Trained batch 471 in epoch 5, gen_loss = 0.8115296173146216, disc_loss = 0.08864780746881802
Trained batch 472 in epoch 5, gen_loss = 0.8115807617945601, disc_loss = 0.0885270464373851
Trained batch 473 in epoch 5, gen_loss = 0.811499379858186, disc_loss = 0.0885687814298467
Trained batch 474 in epoch 5, gen_loss = 0.8109538361900731, disc_loss = 0.08860776767330734
Trained batch 475 in epoch 5, gen_loss = 0.8111568397584081, disc_loss = 0.08879931879370716
Trained batch 476 in epoch 5, gen_loss = 0.8106370993130362, disc_loss = 0.08900413936515586
Trained batch 477 in epoch 5, gen_loss = 0.8103633531716079, disc_loss = 0.08894407393208172
Trained batch 478 in epoch 5, gen_loss = 0.8104980498365669, disc_loss = 0.08921345507838843
Trained batch 479 in epoch 5, gen_loss = 0.8101089672495921, disc_loss = 0.0892414551480518
Trained batch 480 in epoch 5, gen_loss = 0.8097972572469414, disc_loss = 0.08917967171414044
Trained batch 481 in epoch 5, gen_loss = 0.8103324714043328, disc_loss = 0.0890696984406607
Trained batch 482 in epoch 5, gen_loss = 0.8105358538173494, disc_loss = 0.08929587670989474
Trained batch 483 in epoch 5, gen_loss = 0.80973370970527, disc_loss = 0.08987517742832646
Trained batch 484 in epoch 5, gen_loss = 0.8101594700641239, disc_loss = 0.0898246776216577
Trained batch 485 in epoch 5, gen_loss = 0.8104016758164261, disc_loss = 0.08973957202109842
Trained batch 486 in epoch 5, gen_loss = 0.8103726523979978, disc_loss = 0.08983133181937238
Trained batch 487 in epoch 5, gen_loss = 0.8099167227867197, disc_loss = 0.08997423946284919
Trained batch 488 in epoch 5, gen_loss = 0.8101320060118575, disc_loss = 0.08986913132650781
Trained batch 489 in epoch 5, gen_loss = 0.8102529941164718, disc_loss = 0.08975518551293989
Trained batch 490 in epoch 5, gen_loss = 0.8097672408442876, disc_loss = 0.08977130864407344
Trained batch 491 in epoch 5, gen_loss = 0.8103393342315666, disc_loss = 0.08975233093880844
Trained batch 492 in epoch 5, gen_loss = 0.8103459833480765, disc_loss = 0.08965403955565807
Trained batch 493 in epoch 5, gen_loss = 0.810114112882479, disc_loss = 0.08963474797401652
Trained batch 494 in epoch 5, gen_loss = 0.8098301422114325, disc_loss = 0.08963512289290777
Trained batch 495 in epoch 5, gen_loss = 0.8104750501412538, disc_loss = 0.08972805526836085
Trained batch 496 in epoch 5, gen_loss = 0.8102005807086975, disc_loss = 0.08966061466334152
Trained batch 497 in epoch 5, gen_loss = 0.8098009899557834, disc_loss = 0.08975625701854567
Trained batch 498 in epoch 5, gen_loss = 0.8097274553680229, disc_loss = 0.08967016946584105
Trained batch 499 in epoch 5, gen_loss = 0.8093866330981254, disc_loss = 0.08973093117959798
Trained batch 500 in epoch 5, gen_loss = 0.8090027627235877, disc_loss = 0.08975830031912067
Trained batch 501 in epoch 5, gen_loss = 0.809554037285516, disc_loss = 0.08976295771656105
Trained batch 502 in epoch 5, gen_loss = 0.8090748167772653, disc_loss = 0.08991935896774232
Trained batch 503 in epoch 5, gen_loss = 0.809296487874928, disc_loss = 0.08985487187820827
Trained batch 504 in epoch 5, gen_loss = 0.8097152526425844, disc_loss = 0.0897436393019144
Trained batch 505 in epoch 5, gen_loss = 0.8091555980472226, disc_loss = 0.0897532163110558
Trained batch 506 in epoch 5, gen_loss = 0.8091034019839835, disc_loss = 0.08967523732547752
Trained batch 507 in epoch 5, gen_loss = 0.8087699162795787, disc_loss = 0.08969679017419245
Trained batch 508 in epoch 5, gen_loss = 0.8091498632679286, disc_loss = 0.08987536028298332
Trained batch 509 in epoch 5, gen_loss = 0.809198679468211, disc_loss = 0.08973634417771417
Trained batch 510 in epoch 5, gen_loss = 0.8090994162685484, disc_loss = 0.08972378943567465
Trained batch 511 in epoch 5, gen_loss = 0.8093159362324513, disc_loss = 0.08974296727137698
Trained batch 512 in epoch 5, gen_loss = 0.8091754435214847, disc_loss = 0.08967803855250511
Trained batch 513 in epoch 5, gen_loss = 0.8092601550344364, disc_loss = 0.08965279836867164
Trained batch 514 in epoch 5, gen_loss = 0.8092773257528694, disc_loss = 0.08953129694552965
Trained batch 515 in epoch 5, gen_loss = 0.8091316260686217, disc_loss = 0.08945678670298626
Trained batch 516 in epoch 5, gen_loss = 0.8093946972137724, disc_loss = 0.08940825287641767
Trained batch 517 in epoch 5, gen_loss = 0.809369941763436, disc_loss = 0.0893166316978806
Trained batch 518 in epoch 5, gen_loss = 0.8102658983025707, disc_loss = 0.08922891765797011
Trained batch 519 in epoch 5, gen_loss = 0.8103795134677336, disc_loss = 0.08911051359564925
Trained batch 520 in epoch 5, gen_loss = 0.8102446064038378, disc_loss = 0.08913683577220809
Trained batch 521 in epoch 5, gen_loss = 0.8103408771798986, disc_loss = 0.08902691162487499
Trained batch 522 in epoch 5, gen_loss = 0.8105531195267665, disc_loss = 0.08894476347761389
Trained batch 523 in epoch 5, gen_loss = 0.8103181586124515, disc_loss = 0.08898213739464245
Trained batch 524 in epoch 5, gen_loss = 0.8102336150691622, disc_loss = 0.08899056416714475
Trained batch 525 in epoch 5, gen_loss = 0.8104688892912956, disc_loss = 0.08887192843297759
Trained batch 526 in epoch 5, gen_loss = 0.8106107855996778, disc_loss = 0.08874163301785316
Trained batch 527 in epoch 5, gen_loss = 0.8104319865392013, disc_loss = 0.08863971410072267
Trained batch 528 in epoch 5, gen_loss = 0.8108533198869521, disc_loss = 0.0886632411182631
Trained batch 529 in epoch 5, gen_loss = 0.8107891482564639, disc_loss = 0.08869015433351105
Trained batch 530 in epoch 5, gen_loss = 0.8110706788784142, disc_loss = 0.08868883950933955
Trained batch 531 in epoch 5, gen_loss = 0.811215445903459, disc_loss = 0.08867822385295049
Trained batch 532 in epoch 5, gen_loss = 0.8113673978518366, disc_loss = 0.08857899712220421
Trained batch 533 in epoch 5, gen_loss = 0.8115859341420485, disc_loss = 0.08845987225523434
Trained batch 534 in epoch 5, gen_loss = 0.8116601162424711, disc_loss = 0.08834013753857847
Trained batch 535 in epoch 5, gen_loss = 0.8124307630333438, disc_loss = 0.08826035266193047
Trained batch 536 in epoch 5, gen_loss = 0.8121636472711794, disc_loss = 0.08820684203701146
Trained batch 537 in epoch 5, gen_loss = 0.8128388406064874, disc_loss = 0.08814983207864001
Trained batch 538 in epoch 5, gen_loss = 0.8130956115771313, disc_loss = 0.08802725725283704
Trained batch 539 in epoch 5, gen_loss = 0.812831051758042, disc_loss = 0.0879411830894511
Trained batch 540 in epoch 5, gen_loss = 0.8128781711438227, disc_loss = 0.08784367554681634
Trained batch 541 in epoch 5, gen_loss = 0.8134368997328396, disc_loss = 0.08773165058200265
Trained batch 542 in epoch 5, gen_loss = 0.8140738188781352, disc_loss = 0.08762001990414402
Trained batch 543 in epoch 5, gen_loss = 0.8142887226251119, disc_loss = 0.08748918263453935
Trained batch 544 in epoch 5, gen_loss = 0.8146490958305674, disc_loss = 0.08735534904029117
Trained batch 545 in epoch 5, gen_loss = 0.8149281095563273, disc_loss = 0.08722604170694073
Trained batch 546 in epoch 5, gen_loss = 0.8150283750384991, disc_loss = 0.08713494479771997
Trained batch 547 in epoch 5, gen_loss = 0.8149507561848112, disc_loss = 0.08703723142134284
Trained batch 548 in epoch 5, gen_loss = 0.8150819705592262, disc_loss = 0.08696933626918248
Trained batch 549 in epoch 5, gen_loss = 0.8155141720446674, disc_loss = 0.08684021305462176
Trained batch 550 in epoch 5, gen_loss = 0.8163546631535255, disc_loss = 0.08695998782978247
Trained batch 551 in epoch 5, gen_loss = 0.8160323216107445, disc_loss = 0.08707337575944384
Trained batch 552 in epoch 5, gen_loss = 0.8164979597220153, disc_loss = 0.08694876431172568
Trained batch 553 in epoch 5, gen_loss = 0.8166572615665649, disc_loss = 0.08684286639423847
Trained batch 554 in epoch 5, gen_loss = 0.8168271427218978, disc_loss = 0.08677758639091039
Trained batch 555 in epoch 5, gen_loss = 0.8167909288899504, disc_loss = 0.08672000821043314
Trained batch 556 in epoch 5, gen_loss = 0.8173945645134582, disc_loss = 0.086748387238188
Trained batch 557 in epoch 5, gen_loss = 0.8177867877333822, disc_loss = 0.08661728157197864
Trained batch 558 in epoch 5, gen_loss = 0.8176590577967479, disc_loss = 0.08653467469590455
Trained batch 559 in epoch 5, gen_loss = 0.8175231479640518, disc_loss = 0.08648688181669319
Trained batch 560 in epoch 5, gen_loss = 0.817641098390926, disc_loss = 0.08639910695460125
Trained batch 561 in epoch 5, gen_loss = 0.8175627134766867, disc_loss = 0.08629981048398541
Trained batch 562 in epoch 5, gen_loss = 0.8178973561599454, disc_loss = 0.08625777131095397
Trained batch 563 in epoch 5, gen_loss = 0.8177325787379387, disc_loss = 0.08627738612571877
Trained batch 564 in epoch 5, gen_loss = 0.81794997110831, disc_loss = 0.08623636870488392
Trained batch 565 in epoch 5, gen_loss = 0.8180674979522455, disc_loss = 0.08619524748311394
Trained batch 566 in epoch 5, gen_loss = 0.8181724787494282, disc_loss = 0.08608699950506185
Trained batch 567 in epoch 5, gen_loss = 0.8179684087739024, disc_loss = 0.08605455110525109
Trained batch 568 in epoch 5, gen_loss = 0.8178220534261794, disc_loss = 0.08597692315465065
Trained batch 569 in epoch 5, gen_loss = 0.8180602022953201, disc_loss = 0.08584670436879
Trained batch 570 in epoch 5, gen_loss = 0.8186552263078672, disc_loss = 0.08574388773162603
Trained batch 571 in epoch 5, gen_loss = 0.8188885556130142, disc_loss = 0.08562747367586081
Trained batch 572 in epoch 5, gen_loss = 0.8184715411113819, disc_loss = 0.08570298804116498
Trained batch 573 in epoch 5, gen_loss = 0.8191599033331621, disc_loss = 0.08587166131555203
Trained batch 574 in epoch 5, gen_loss = 0.8188556451901146, disc_loss = 0.08591798996795778
Trained batch 575 in epoch 5, gen_loss = 0.8190426857003735, disc_loss = 0.08585211196138214
Trained batch 576 in epoch 5, gen_loss = 0.8186313286294556, disc_loss = 0.08586057912125744
Trained batch 577 in epoch 5, gen_loss = 0.8189461052314633, disc_loss = 0.08588047604041116
Trained batch 578 in epoch 5, gen_loss = 0.8187811017962935, disc_loss = 0.08581871478231254
Trained batch 579 in epoch 5, gen_loss = 0.8186126564597261, disc_loss = 0.0857383709272434
Trained batch 580 in epoch 5, gen_loss = 0.8184013853487583, disc_loss = 0.08569206327533353
Trained batch 581 in epoch 5, gen_loss = 0.8186793887021205, disc_loss = 0.08579527627023839
Trained batch 582 in epoch 5, gen_loss = 0.8190661260337404, disc_loss = 0.08566668575332463
Trained batch 583 in epoch 5, gen_loss = 0.8185301225581397, disc_loss = 0.08583081584449297
Trained batch 584 in epoch 5, gen_loss = 0.8192342141245166, disc_loss = 0.08576276475547726
Trained batch 585 in epoch 5, gen_loss = 0.8195860209420273, disc_loss = 0.08566678509929888
Trained batch 586 in epoch 5, gen_loss = 0.8193561355036, disc_loss = 0.08567096238394206
Trained batch 587 in epoch 5, gen_loss = 0.8192135190375808, disc_loss = 0.0856046582869932
Trained batch 588 in epoch 5, gen_loss = 0.8194673336118915, disc_loss = 0.08551488315183764
Trained batch 589 in epoch 5, gen_loss = 0.8193201172654911, disc_loss = 0.08542600781104322
Trained batch 590 in epoch 5, gen_loss = 0.8191674389512406, disc_loss = 0.08535927098540687
Trained batch 591 in epoch 5, gen_loss = 0.8196137606392842, disc_loss = 0.08540762770241378
Trained batch 592 in epoch 5, gen_loss = 0.8200850782768321, disc_loss = 0.08531178326093125
Trained batch 593 in epoch 5, gen_loss = 0.8198074355771646, disc_loss = 0.08539256627235549
Trained batch 594 in epoch 5, gen_loss = 0.8197581951858617, disc_loss = 0.08530014335107403
Trained batch 595 in epoch 5, gen_loss = 0.8198877305492459, disc_loss = 0.08518463813218495
Trained batch 596 in epoch 5, gen_loss = 0.8203052312784658, disc_loss = 0.08507640891937754
Trained batch 597 in epoch 5, gen_loss = 0.8203307931937501, disc_loss = 0.08497225454569261
Trained batch 598 in epoch 5, gen_loss = 0.8203311326209213, disc_loss = 0.08489730286851949
Trained batch 599 in epoch 5, gen_loss = 0.820343618641297, disc_loss = 0.08477882693832119
Trained batch 600 in epoch 5, gen_loss = 0.8208925994283546, disc_loss = 0.08485740540353907
Trained batch 601 in epoch 5, gen_loss = 0.8206446917845165, disc_loss = 0.08489025787038859
Trained batch 602 in epoch 5, gen_loss = 0.8208041156010446, disc_loss = 0.08478203616653311
Trained batch 603 in epoch 5, gen_loss = 0.8212848728559664, disc_loss = 0.08477788340201639
Trained batch 604 in epoch 5, gen_loss = 0.8208061644361039, disc_loss = 0.08481586053967476
Trained batch 605 in epoch 5, gen_loss = 0.820697773063537, disc_loss = 0.08474470914738012
Trained batch 606 in epoch 5, gen_loss = 0.8209093334352754, disc_loss = 0.0847194708846939
Trained batch 607 in epoch 5, gen_loss = 0.8211641660156218, disc_loss = 0.08459797816344929
Trained batch 608 in epoch 5, gen_loss = 0.8210102806635482, disc_loss = 0.08457040541907787
Trained batch 609 in epoch 5, gen_loss = 0.8209131620457915, disc_loss = 0.08450030742945974
Trained batch 610 in epoch 5, gen_loss = 0.8208981415351362, disc_loss = 0.08447633256736393
Trained batch 611 in epoch 5, gen_loss = 0.8210436320480179, disc_loss = 0.08438817094372329
Trained batch 612 in epoch 5, gen_loss = 0.8210521180419704, disc_loss = 0.08428665803408107
Trained batch 613 in epoch 5, gen_loss = 0.8210308420250393, disc_loss = 0.08422608280263186
Trained batch 614 in epoch 5, gen_loss = 0.8212434519112595, disc_loss = 0.08410783546666305
Trained batch 615 in epoch 5, gen_loss = 0.8214390406070592, disc_loss = 0.08401749042080497
Trained batch 616 in epoch 5, gen_loss = 0.822113473421171, disc_loss = 0.08399632173126965
Trained batch 617 in epoch 5, gen_loss = 0.8216033238905533, disc_loss = 0.08406627907276057
Trained batch 618 in epoch 5, gen_loss = 0.8217136828598953, disc_loss = 0.08396365721928188
Trained batch 619 in epoch 5, gen_loss = 0.8213563683052216, disc_loss = 0.08409562296864967
Trained batch 620 in epoch 5, gen_loss = 0.8216033407551463, disc_loss = 0.08403803882955449
Trained batch 621 in epoch 5, gen_loss = 0.8210977990048491, disc_loss = 0.08407281565261328
Trained batch 622 in epoch 5, gen_loss = 0.8212066982090952, disc_loss = 0.0839810244392239
Trained batch 623 in epoch 5, gen_loss = 0.8217289586766408, disc_loss = 0.08403894247917029
Trained batch 624 in epoch 5, gen_loss = 0.8218464192867279, disc_loss = 0.08400245824456215
Trained batch 625 in epoch 5, gen_loss = 0.8213396174743914, disc_loss = 0.08431031734060745
Trained batch 626 in epoch 5, gen_loss = 0.8210646963100494, disc_loss = 0.08431349890202616
Trained batch 627 in epoch 5, gen_loss = 0.8215644389485858, disc_loss = 0.08440092315743114
Trained batch 628 in epoch 5, gen_loss = 0.8214764482739999, disc_loss = 0.08435484883634578
Trained batch 629 in epoch 5, gen_loss = 0.8215598539227531, disc_loss = 0.08429992774294483
Trained batch 630 in epoch 5, gen_loss = 0.822080287001968, disc_loss = 0.08427359418214407
Trained batch 631 in epoch 5, gen_loss = 0.8223328776657581, disc_loss = 0.08418211052076349
Trained batch 632 in epoch 5, gen_loss = 0.8223593775035835, disc_loss = 0.08408080435712567
Trained batch 633 in epoch 5, gen_loss = 0.8218356634634151, disc_loss = 0.08410774966942774
Trained batch 634 in epoch 5, gen_loss = 0.8216839517664721, disc_loss = 0.08405527356337375
Trained batch 635 in epoch 5, gen_loss = 0.8221546023053193, disc_loss = 0.08406350906914885
Trained batch 636 in epoch 5, gen_loss = 0.8218038884493021, disc_loss = 0.08405728687296857
Trained batch 637 in epoch 5, gen_loss = 0.8224409730363416, disc_loss = 0.08404355540544635
Trained batch 638 in epoch 5, gen_loss = 0.8223713861664695, disc_loss = 0.08397779698849471
Trained batch 639 in epoch 5, gen_loss = 0.8227512675803155, disc_loss = 0.08389068703982047
Trained batch 640 in epoch 5, gen_loss = 0.8228759276048627, disc_loss = 0.08379504257484736
Trained batch 641 in epoch 5, gen_loss = 0.8224605020611457, disc_loss = 0.08380374082326425
Trained batch 642 in epoch 5, gen_loss = 0.8225967438651095, disc_loss = 0.08368982349176243
Trained batch 643 in epoch 5, gen_loss = 0.8229226647234111, disc_loss = 0.08361444429072164
Trained batch 644 in epoch 5, gen_loss = 0.8228341887625613, disc_loss = 0.08351443041144878
Trained batch 645 in epoch 5, gen_loss = 0.8227980475030816, disc_loss = 0.08351397684749343
Trained batch 646 in epoch 5, gen_loss = 0.8229479174801887, disc_loss = 0.08339821337398366
Trained batch 647 in epoch 5, gen_loss = 0.8225069960786237, disc_loss = 0.08345368045474184
Trained batch 648 in epoch 5, gen_loss = 0.8225940351585395, disc_loss = 0.08367980840703464
Trained batch 649 in epoch 5, gen_loss = 0.8226923485444142, disc_loss = 0.08357932827220513
Trained batch 650 in epoch 5, gen_loss = 0.8225104854128877, disc_loss = 0.08356461304879409
Trained batch 651 in epoch 5, gen_loss = 0.8221998044226798, disc_loss = 0.08365716223542127
Trained batch 652 in epoch 5, gen_loss = 0.822367486006268, disc_loss = 0.08356426260897613
Trained batch 653 in epoch 5, gen_loss = 0.8225914090871811, disc_loss = 0.08349859156853745
Trained batch 654 in epoch 5, gen_loss = 0.8224277233804456, disc_loss = 0.0834347567656113
Trained batch 655 in epoch 5, gen_loss = 0.8223189884660448, disc_loss = 0.08336844410542853
Trained batch 656 in epoch 5, gen_loss = 0.8225188555147731, disc_loss = 0.08335784593061225
Trained batch 657 in epoch 5, gen_loss = 0.8220333232796301, disc_loss = 0.08343187452925194
Trained batch 658 in epoch 5, gen_loss = 0.8218772070813071, disc_loss = 0.08336088864050795
Trained batch 659 in epoch 5, gen_loss = 0.8225435084917329, disc_loss = 0.08358912632772417
Trained batch 660 in epoch 5, gen_loss = 0.8223168925239892, disc_loss = 0.08357968903886388
Trained batch 661 in epoch 5, gen_loss = 0.8222148574641104, disc_loss = 0.08351519719621567
Trained batch 662 in epoch 5, gen_loss = 0.822257601252868, disc_loss = 0.08346662609690454
Trained batch 663 in epoch 5, gen_loss = 0.8222228917461561, disc_loss = 0.0834233896492655
Trained batch 664 in epoch 5, gen_loss = 0.822160671304043, disc_loss = 0.08340661665774826
Trained batch 665 in epoch 5, gen_loss = 0.8225154987237117, disc_loss = 0.0833035858834649
Trained batch 666 in epoch 5, gen_loss = 0.8228699206144199, disc_loss = 0.08320662305540946
Trained batch 667 in epoch 5, gen_loss = 0.8231161622676307, disc_loss = 0.08310984740379507
Trained batch 668 in epoch 5, gen_loss = 0.8232757261604828, disc_loss = 0.08302158904394137
Trained batch 669 in epoch 5, gen_loss = 0.823345172449724, disc_loss = 0.08291939960987266
Trained batch 670 in epoch 5, gen_loss = 0.8233547612647186, disc_loss = 0.08290233643206417
Trained batch 671 in epoch 5, gen_loss = 0.8239748517406129, disc_loss = 0.08287440192985482
Trained batch 672 in epoch 5, gen_loss = 0.8241887628855004, disc_loss = 0.08277682008230049
Trained batch 673 in epoch 5, gen_loss = 0.8239463616814741, disc_loss = 0.08276798234815856
Trained batch 674 in epoch 5, gen_loss = 0.8242334891690148, disc_loss = 0.08270438021807759
Trained batch 675 in epoch 5, gen_loss = 0.824431281779292, disc_loss = 0.08260045885576828
Trained batch 676 in epoch 5, gen_loss = 0.8244693694385855, disc_loss = 0.08253033935165299
Trained batch 677 in epoch 5, gen_loss = 0.8247267019695941, disc_loss = 0.08249686684756152
Trained batch 678 in epoch 5, gen_loss = 0.8247172865407632, disc_loss = 0.08240470594406918
Trained batch 679 in epoch 5, gen_loss = 0.824672191414763, disc_loss = 0.08233797548283987
Trained batch 680 in epoch 5, gen_loss = 0.8247625023870566, disc_loss = 0.08225838592202128
Trained batch 681 in epoch 5, gen_loss = 0.8250010545390093, disc_loss = 0.08215839598229553
Trained batch 682 in epoch 5, gen_loss = 0.8246779281695102, disc_loss = 0.08219861631904828
Trained batch 683 in epoch 5, gen_loss = 0.8252057433564063, disc_loss = 0.08246005780733469
Trained batch 684 in epoch 5, gen_loss = 0.8254398724893584, disc_loss = 0.0823623459174359
Trained batch 685 in epoch 5, gen_loss = 0.8251785065533468, disc_loss = 0.08238579592539905
Trained batch 686 in epoch 5, gen_loss = 0.8251836278639854, disc_loss = 0.08233404972521369
Trained batch 687 in epoch 5, gen_loss = 0.8254540952052488, disc_loss = 0.08227940661383273
Trained batch 688 in epoch 5, gen_loss = 0.8254000443765145, disc_loss = 0.08223506589981096
Trained batch 689 in epoch 5, gen_loss = 0.825718073438907, disc_loss = 0.08217931801345253
Trained batch 690 in epoch 5, gen_loss = 0.8261447503580543, disc_loss = 0.08208138506600765
Trained batch 691 in epoch 5, gen_loss = 0.8258815880197321, disc_loss = 0.08208223427053692
Trained batch 692 in epoch 5, gen_loss = 0.8259258252631706, disc_loss = 0.08202214561225403
Trained batch 693 in epoch 5, gen_loss = 0.8258200739148027, disc_loss = 0.08203981806703921
Trained batch 694 in epoch 5, gen_loss = 0.825733717782892, disc_loss = 0.08199551381679962
Trained batch 695 in epoch 5, gen_loss = 0.8257179118521597, disc_loss = 0.08194008327876057
Trained batch 696 in epoch 5, gen_loss = 0.8255883985048045, disc_loss = 0.08189590815240931
Trained batch 697 in epoch 5, gen_loss = 0.8263680256454856, disc_loss = 0.08197335176367344
Trained batch 698 in epoch 5, gen_loss = 0.8260267599884191, disc_loss = 0.08206487647544204
Trained batch 699 in epoch 5, gen_loss = 0.8259939240132059, disc_loss = 0.08204464498508189
Trained batch 700 in epoch 5, gen_loss = 0.8261098635944932, disc_loss = 0.08202669283935797
Trained batch 701 in epoch 5, gen_loss = 0.8256454824806958, disc_loss = 0.08222419112798708
Trained batch 702 in epoch 5, gen_loss = 0.8253935536907543, disc_loss = 0.08224620132880606
Trained batch 703 in epoch 5, gen_loss = 0.8256038192405619, disc_loss = 0.08228170836942313
Trained batch 704 in epoch 5, gen_loss = 0.8256113111972809, disc_loss = 0.08217871692692134
Trained batch 705 in epoch 5, gen_loss = 0.8254940760118765, disc_loss = 0.0821342225273591
Trained batch 706 in epoch 5, gen_loss = 0.8256941227376714, disc_loss = 0.08204734699255253
Trained batch 707 in epoch 5, gen_loss = 0.8259231560563637, disc_loss = 0.08195218831658532
Trained batch 708 in epoch 5, gen_loss = 0.8261083849142233, disc_loss = 0.08189995949943411
Trained batch 709 in epoch 5, gen_loss = 0.8256583909333591, disc_loss = 0.08202794963939929
Trained batch 710 in epoch 5, gen_loss = 0.825676732886525, disc_loss = 0.08194685476909375
Trained batch 711 in epoch 5, gen_loss = 0.8255925946607349, disc_loss = 0.08191478293221653
Trained batch 712 in epoch 5, gen_loss = 0.825697574132288, disc_loss = 0.08186310723026873
Trained batch 713 in epoch 5, gen_loss = 0.825602031847676, disc_loss = 0.08203490133754679
Trained batch 714 in epoch 5, gen_loss = 0.8252593200940352, disc_loss = 0.08216551628771361
Trained batch 715 in epoch 5, gen_loss = 0.8251438925469388, disc_loss = 0.08223455693760065
Trained batch 716 in epoch 5, gen_loss = 0.8250767039537762, disc_loss = 0.08235023127066042
Trained batch 717 in epoch 5, gen_loss = 0.8245577794346637, disc_loss = 0.08256126127742791
Trained batch 718 in epoch 5, gen_loss = 0.8252633588287529, disc_loss = 0.08283031331854503
Trained batch 719 in epoch 5, gen_loss = 0.8250118989497424, disc_loss = 0.08290515029802918
Trained batch 720 in epoch 5, gen_loss = 0.8245768223407365, disc_loss = 0.0830309494048481
Trained batch 721 in epoch 5, gen_loss = 0.8246784394715301, disc_loss = 0.08308341478996
Trained batch 722 in epoch 5, gen_loss = 0.8251177983907249, disc_loss = 0.0830337022782856
Trained batch 723 in epoch 5, gen_loss = 0.8251946503862492, disc_loss = 0.08295721846802459
Trained batch 724 in epoch 5, gen_loss = 0.8250013817178792, disc_loss = 0.08297759245181906
Trained batch 725 in epoch 5, gen_loss = 0.8245748871367825, disc_loss = 0.08317291375362512
Trained batch 726 in epoch 5, gen_loss = 0.8250017066523331, disc_loss = 0.08329618866702714
Trained batch 727 in epoch 5, gen_loss = 0.8252314015158585, disc_loss = 0.083270425468192
Trained batch 728 in epoch 5, gen_loss = 0.8247455951690019, disc_loss = 0.08341260342277454
Trained batch 729 in epoch 5, gen_loss = 0.8247514634507976, disc_loss = 0.08333151705869257
Trained batch 730 in epoch 5, gen_loss = 0.8249212988995005, disc_loss = 0.08328502520246153
Trained batch 731 in epoch 5, gen_loss = 0.8246462492099225, disc_loss = 0.08330507377987026
Trained batch 732 in epoch 5, gen_loss = 0.8247309163273763, disc_loss = 0.08325303082658031
Trained batch 733 in epoch 5, gen_loss = 0.8249959826713037, disc_loss = 0.0832229659610938
Trained batch 734 in epoch 5, gen_loss = 0.824838821377073, disc_loss = 0.08322432158755608
Trained batch 735 in epoch 5, gen_loss = 0.824613441389216, disc_loss = 0.08326378080022076
Trained batch 736 in epoch 5, gen_loss = 0.8247737439306329, disc_loss = 0.08343799262632347
Trained batch 737 in epoch 5, gen_loss = 0.8249765194770766, disc_loss = 0.0833471776049352
Trained batch 738 in epoch 5, gen_loss = 0.824688951402943, disc_loss = 0.08336845547696815
Trained batch 739 in epoch 5, gen_loss = 0.8248404106981045, disc_loss = 0.08331096275281664
Trained batch 740 in epoch 5, gen_loss = 0.824933889866197, disc_loss = 0.08324077049981647
Trained batch 741 in epoch 5, gen_loss = 0.824932041876721, disc_loss = 0.08317946773424062
Trained batch 742 in epoch 5, gen_loss = 0.8247212812123998, disc_loss = 0.0831576489629086
Trained batch 743 in epoch 5, gen_loss = 0.8251239782780089, disc_loss = 0.08312932415164366
Trained batch 744 in epoch 5, gen_loss = 0.8249173413587096, disc_loss = 0.08307879711907581
Trained batch 745 in epoch 5, gen_loss = 0.8250915856767276, disc_loss = 0.08298195990666388
Trained batch 746 in epoch 5, gen_loss = 0.8252311196113367, disc_loss = 0.082926325662089
Trained batch 747 in epoch 5, gen_loss = 0.8250010186895967, disc_loss = 0.08290880225489244
Trained batch 748 in epoch 5, gen_loss = 0.8249004510677704, disc_loss = 0.08285848135116183
Trained batch 749 in epoch 5, gen_loss = 0.8251563863356908, disc_loss = 0.08291162841767073
Trained batch 750 in epoch 5, gen_loss = 0.8253934262357603, disc_loss = 0.08282395402160529
Trained batch 751 in epoch 5, gen_loss = 0.8254673222198765, disc_loss = 0.08275892293734595
Trained batch 752 in epoch 5, gen_loss = 0.8256706010060482, disc_loss = 0.08267541605469636
Trained batch 753 in epoch 5, gen_loss = 0.8253809771344895, disc_loss = 0.08273064321158972
Trained batch 754 in epoch 5, gen_loss = 0.8253067802514461, disc_loss = 0.0826583721015035
Trained batch 755 in epoch 5, gen_loss = 0.8251988332344111, disc_loss = 0.08277449648699196
Trained batch 756 in epoch 5, gen_loss = 0.8254614109013481, disc_loss = 0.0826980409801715
Trained batch 757 in epoch 5, gen_loss = 0.8254102564031027, disc_loss = 0.08262628851591125
Trained batch 758 in epoch 5, gen_loss = 0.8249825027541838, disc_loss = 0.08267834408598926
Trained batch 759 in epoch 5, gen_loss = 0.8248625675706487, disc_loss = 0.08262101912772969
Trained batch 760 in epoch 5, gen_loss = 0.8253106664029121, disc_loss = 0.08281185756022608
Trained batch 761 in epoch 5, gen_loss = 0.8249449485477813, disc_loss = 0.08302101859544206
Trained batch 762 in epoch 5, gen_loss = 0.8250909751161523, disc_loss = 0.08296918511625043
Trained batch 763 in epoch 5, gen_loss = 0.8251574719373468, disc_loss = 0.08292946774824596
Trained batch 764 in epoch 5, gen_loss = 0.8247891982006871, disc_loss = 0.08305330420144243
Trained batch 765 in epoch 5, gen_loss = 0.8249549663798305, disc_loss = 0.08302425019754286
Trained batch 766 in epoch 5, gen_loss = 0.8247703626615904, disc_loss = 0.08303296924939056
Trained batch 767 in epoch 5, gen_loss = 0.824724105768837, disc_loss = 0.0829719109024154
Trained batch 768 in epoch 5, gen_loss = 0.8246040763175999, disc_loss = 0.08305195998521558
Trained batch 769 in epoch 5, gen_loss = 0.8246167718977123, disc_loss = 0.08300179934927396
Trained batch 770 in epoch 5, gen_loss = 0.8242227093796167, disc_loss = 0.08312137539941822
Trained batch 771 in epoch 5, gen_loss = 0.8245776147036354, disc_loss = 0.08311492475859551
Trained batch 772 in epoch 5, gen_loss = 0.8244159123336204, disc_loss = 0.0831471231282914
Trained batch 773 in epoch 5, gen_loss = 0.8242861425614788, disc_loss = 0.08314491598566065
Trained batch 774 in epoch 5, gen_loss = 0.824676685525525, disc_loss = 0.08310573563460381
Trained batch 775 in epoch 5, gen_loss = 0.8243322378965383, disc_loss = 0.0831597697508243
Trained batch 776 in epoch 5, gen_loss = 0.8244248730258745, disc_loss = 0.08306867665607612
Trained batch 777 in epoch 5, gen_loss = 0.8246680461732159, disc_loss = 0.08306428498844676
Trained batch 778 in epoch 5, gen_loss = 0.8243953597484412, disc_loss = 0.08308471725782587
Trained batch 779 in epoch 5, gen_loss = 0.8245144698482293, disc_loss = 0.08300421946586516
Trained batch 780 in epoch 5, gen_loss = 0.8247690331691664, disc_loss = 0.08306013457787136
Trained batch 781 in epoch 5, gen_loss = 0.8244140763645587, disc_loss = 0.08312088468224
Trained batch 782 in epoch 5, gen_loss = 0.8242996676443181, disc_loss = 0.08309684212213694
Trained batch 783 in epoch 5, gen_loss = 0.8243438836035072, disc_loss = 0.08305412339764096
Trained batch 784 in epoch 5, gen_loss = 0.8243977304856489, disc_loss = 0.08298943986534882
Trained batch 785 in epoch 5, gen_loss = 0.8241802355032841, disc_loss = 0.08308710653036264
Trained batch 786 in epoch 5, gen_loss = 0.8240066125629212, disc_loss = 0.08305596512312773
Trained batch 787 in epoch 5, gen_loss = 0.8236612350429375, disc_loss = 0.08317194875627568
Trained batch 788 in epoch 5, gen_loss = 0.8239672851426519, disc_loss = 0.08321103448324443
Trained batch 789 in epoch 5, gen_loss = 0.824217245359964, disc_loss = 0.08322619525479931
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.45152655243873596, disc_loss = 0.20398910343647003
Trained batch 1 in epoch 6, gen_loss = 0.6506732851266861, disc_loss = 0.12046660110354424
Trained batch 2 in epoch 6, gen_loss = 0.7034086088339487, disc_loss = 0.1167152648170789
Trained batch 3 in epoch 6, gen_loss = 0.6735403761267662, disc_loss = 0.1149465311318636
Trained batch 4 in epoch 6, gen_loss = 0.6633053362369538, disc_loss = 0.11290551573038102
Trained batch 5 in epoch 6, gen_loss = 0.7126889675855637, disc_loss = 0.13157153005401293
Trained batch 6 in epoch 6, gen_loss = 0.7041073398930686, disc_loss = 0.1283490721668516
Trained batch 7 in epoch 6, gen_loss = 0.6991186700761318, disc_loss = 0.1273480411618948
Trained batch 8 in epoch 6, gen_loss = 0.6977590554290347, disc_loss = 0.12301440371407403
Trained batch 9 in epoch 6, gen_loss = 0.6830167025327682, disc_loss = 0.12208894789218902
Trained batch 10 in epoch 6, gen_loss = 0.702152357860045, disc_loss = 0.1357338401404294
Trained batch 11 in epoch 6, gen_loss = 0.707301639020443, disc_loss = 0.12910167903949818
Trained batch 12 in epoch 6, gen_loss = 0.6957592757848593, disc_loss = 0.1299918250968823
Trained batch 13 in epoch 6, gen_loss = 0.7005165708916528, disc_loss = 0.13009920955768653
Trained batch 14 in epoch 6, gen_loss = 0.7213059326012929, disc_loss = 0.12473627105355263
Trained batch 15 in epoch 6, gen_loss = 0.7190122958272696, disc_loss = 0.12341755931265652
Trained batch 16 in epoch 6, gen_loss = 0.7269884330384871, disc_loss = 0.11981318737654124
Trained batch 17 in epoch 6, gen_loss = 0.7274855855438445, disc_loss = 0.11628240533173084
Trained batch 18 in epoch 6, gen_loss = 0.7339249708150563, disc_loss = 0.11240298536263015
Trained batch 19 in epoch 6, gen_loss = 0.737090177834034, disc_loss = 0.11145034469664097
Trained batch 20 in epoch 6, gen_loss = 0.7349893947442373, disc_loss = 0.10884855865013032
Trained batch 21 in epoch 6, gen_loss = 0.7391748116774992, disc_loss = 0.10678570717573166
Trained batch 22 in epoch 6, gen_loss = 0.743405159400857, disc_loss = 0.1084686472364094
Trained batch 23 in epoch 6, gen_loss = 0.7516660876572132, disc_loss = 0.10501386877149343
Trained batch 24 in epoch 6, gen_loss = 0.7545924127101898, disc_loss = 0.1021305599808693
Trained batch 25 in epoch 6, gen_loss = 0.7528656205305686, disc_loss = 0.0995837994492971
Trained batch 26 in epoch 6, gen_loss = 0.7563863186924545, disc_loss = 0.09885124862194061
Trained batch 27 in epoch 6, gen_loss = 0.751875350517886, disc_loss = 0.09881747514009476
Trained batch 28 in epoch 6, gen_loss = 0.7570565168199868, disc_loss = 0.09663279945480413
Trained batch 29 in epoch 6, gen_loss = 0.7634085009495417, disc_loss = 0.09471505209803581
Trained batch 30 in epoch 6, gen_loss = 0.7633425987535908, disc_loss = 0.09530874726272398
Trained batch 31 in epoch 6, gen_loss = 0.7642037505283952, disc_loss = 0.0936616852413863
Trained batch 32 in epoch 6, gen_loss = 0.764317200942473, disc_loss = 0.09265408190813931
Trained batch 33 in epoch 6, gen_loss = 0.7607075598310021, disc_loss = 0.0939926820642808
Trained batch 34 in epoch 6, gen_loss = 0.7586095716272082, disc_loss = 0.09292323929922922
Trained batch 35 in epoch 6, gen_loss = 0.7631891609893905, disc_loss = 0.09187146710852782
Trained batch 36 in epoch 6, gen_loss = 0.7618852056361534, disc_loss = 0.09110632297155019
Trained batch 37 in epoch 6, gen_loss = 0.7617080392021882, disc_loss = 0.09048060837544893
Trained batch 38 in epoch 6, gen_loss = 0.7733003993829092, disc_loss = 0.09158394963313372
Trained batch 39 in epoch 6, gen_loss = 0.7642049983143806, disc_loss = 0.09778633937239647
Trained batch 40 in epoch 6, gen_loss = 0.7678384824496943, disc_loss = 0.09577356528763364
Trained batch 41 in epoch 6, gen_loss = 0.7765679402010781, disc_loss = 0.09438723445470844
Trained batch 42 in epoch 6, gen_loss = 0.7807229369185692, disc_loss = 0.09245335990779621
Trained batch 43 in epoch 6, gen_loss = 0.7808436263691295, disc_loss = 0.09160903227430853
Trained batch 44 in epoch 6, gen_loss = 0.7858080042733087, disc_loss = 0.09053294190929996
Trained batch 45 in epoch 6, gen_loss = 0.7807873228321904, disc_loss = 0.09159031895029804
Trained batch 46 in epoch 6, gen_loss = 0.7873376709349612, disc_loss = 0.09163367696740526
Trained batch 47 in epoch 6, gen_loss = 0.7878568271795908, disc_loss = 0.0905537346455579
Trained batch 48 in epoch 6, gen_loss = 0.7836834995114074, disc_loss = 0.09118980933360908
Trained batch 49 in epoch 6, gen_loss = 0.7885121583938599, disc_loss = 0.09063733030110598
Trained batch 50 in epoch 6, gen_loss = 0.7921782638512406, disc_loss = 0.09045365412591719
Trained batch 51 in epoch 6, gen_loss = 0.7867266547221404, disc_loss = 0.09173296438530087
Trained batch 52 in epoch 6, gen_loss = 0.7878419464489199, disc_loss = 0.09632439310398866
Trained batch 53 in epoch 6, gen_loss = 0.7841257353623708, disc_loss = 0.09654093123282548
Trained batch 54 in epoch 6, gen_loss = 0.7832164125009017, disc_loss = 0.09601106647063386
Trained batch 55 in epoch 6, gen_loss = 0.7818827203341893, disc_loss = 0.09611273586883076
Trained batch 56 in epoch 6, gen_loss = 0.7799751810860216, disc_loss = 0.09611803283424754
Trained batch 57 in epoch 6, gen_loss = 0.7794399127877992, disc_loss = 0.09674993738660524
Trained batch 58 in epoch 6, gen_loss = 0.7794833082263752, disc_loss = 0.09586135673699743
Trained batch 59 in epoch 6, gen_loss = 0.7767188489437103, disc_loss = 0.09547559951121608
Trained batch 60 in epoch 6, gen_loss = 0.7824970288354842, disc_loss = 0.09510898037401379
Trained batch 61 in epoch 6, gen_loss = 0.7832682690312786, disc_loss = 0.09509945477569295
Trained batch 62 in epoch 6, gen_loss = 0.7799266728143843, disc_loss = 0.09616432596175443
Trained batch 63 in epoch 6, gen_loss = 0.7805529348552227, disc_loss = 0.09524182710447349
Trained batch 64 in epoch 6, gen_loss = 0.7834134450325599, disc_loss = 0.09600457907296144
Trained batch 65 in epoch 6, gen_loss = 0.7863247927391168, disc_loss = 0.09513912804311875
Trained batch 66 in epoch 6, gen_loss = 0.7862063922099213, disc_loss = 0.09521434770257615
Trained batch 67 in epoch 6, gen_loss = 0.7903388221474255, disc_loss = 0.09596432342796642
Trained batch 68 in epoch 6, gen_loss = 0.7893403993136641, disc_loss = 0.09605831720366859
Trained batch 69 in epoch 6, gen_loss = 0.7858884973185403, disc_loss = 0.0978091030514666
Trained batch 70 in epoch 6, gen_loss = 0.7864221359642458, disc_loss = 0.097458816041619
Trained batch 71 in epoch 6, gen_loss = 0.7890734217233129, disc_loss = 0.09810709428145653
Trained batch 72 in epoch 6, gen_loss = 0.7865880180711615, disc_loss = 0.09805604807828387
Trained batch 73 in epoch 6, gen_loss = 0.7862552404403687, disc_loss = 0.09730319580616983
Trained batch 74 in epoch 6, gen_loss = 0.7840039531389872, disc_loss = 0.09724796635409196
Trained batch 75 in epoch 6, gen_loss = 0.7839805860268442, disc_loss = 0.09689263423512641
Trained batch 76 in epoch 6, gen_loss = 0.7794949687146521, disc_loss = 0.09749269845907564
Trained batch 77 in epoch 6, gen_loss = 0.7812382743144647, disc_loss = 0.0967874220596292
Trained batch 78 in epoch 6, gen_loss = 0.7826909856705726, disc_loss = 0.09620067592757413
Trained batch 79 in epoch 6, gen_loss = 0.7846214283257723, disc_loss = 0.09655998481903225
Trained batch 80 in epoch 6, gen_loss = 0.7817241428075014, disc_loss = 0.09705805247304616
Trained batch 81 in epoch 6, gen_loss = 0.7812020157168551, disc_loss = 0.09642926392304461
Trained batch 82 in epoch 6, gen_loss = 0.7825996333576111, disc_loss = 0.09593432084713356
Trained batch 83 in epoch 6, gen_loss = 0.7835750902692477, disc_loss = 0.0951594005427545
Trained batch 84 in epoch 6, gen_loss = 0.7829767195617452, disc_loss = 0.09478994899374597
Trained batch 85 in epoch 6, gen_loss = 0.7839851278898328, disc_loss = 0.09520930790364049
Trained batch 86 in epoch 6, gen_loss = 0.7820957429792689, disc_loss = 0.09505077770472257
Trained batch 87 in epoch 6, gen_loss = 0.7802936024963856, disc_loss = 0.09467388242906467
Trained batch 88 in epoch 6, gen_loss = 0.7854661322041844, disc_loss = 0.09482410527096036
Trained batch 89 in epoch 6, gen_loss = 0.7847759945525064, disc_loss = 0.09422932145082288
Trained batch 90 in epoch 6, gen_loss = 0.7829535521648743, disc_loss = 0.09400727765655124
Trained batch 91 in epoch 6, gen_loss = 0.785729624978874, disc_loss = 0.09487530437257627
Trained batch 92 in epoch 6, gen_loss = 0.7844596553233362, disc_loss = 0.09532083500857635
Trained batch 93 in epoch 6, gen_loss = 0.7846323521213329, disc_loss = 0.0950760650547578
Trained batch 94 in epoch 6, gen_loss = 0.7831273621634434, disc_loss = 0.09558023208458173
Trained batch 95 in epoch 6, gen_loss = 0.7830838377897938, disc_loss = 0.09645244939019904
Trained batch 96 in epoch 6, gen_loss = 0.7826341952859741, disc_loss = 0.0968839651568956
Trained batch 97 in epoch 6, gen_loss = 0.7832470131771905, disc_loss = 0.09653520114643842
Trained batch 98 in epoch 6, gen_loss = 0.7854732573032379, disc_loss = 0.09612674072309575
Trained batch 99 in epoch 6, gen_loss = 0.7831067261099816, disc_loss = 0.0967844215966761
Trained batch 100 in epoch 6, gen_loss = 0.7842255568150247, disc_loss = 0.09630911599955347
Trained batch 101 in epoch 6, gen_loss = 0.7871862062636543, disc_loss = 0.09601471385023758
Trained batch 102 in epoch 6, gen_loss = 0.7852022841717433, disc_loss = 0.09593295734556555
Trained batch 103 in epoch 6, gen_loss = 0.7851049134937617, disc_loss = 0.09556095124795459
Trained batch 104 in epoch 6, gen_loss = 0.7866499483585357, disc_loss = 0.0955035797364655
Trained batch 105 in epoch 6, gen_loss = 0.7896813055816686, disc_loss = 0.0947276836366586
Trained batch 106 in epoch 6, gen_loss = 0.79084268936487, disc_loss = 0.09407540055635934
Trained batch 107 in epoch 6, gen_loss = 0.7897394523024559, disc_loss = 0.0942033747969954
Trained batch 108 in epoch 6, gen_loss = 0.7916464048241256, disc_loss = 0.09382972941486113
Trained batch 109 in epoch 6, gen_loss = 0.7940823162143881, disc_loss = 0.09482235976240852
Trained batch 110 in epoch 6, gen_loss = 0.7913348741896518, disc_loss = 0.09651535413823686
Trained batch 111 in epoch 6, gen_loss = 0.7902254129626921, disc_loss = 0.09724029978471142
Trained batch 112 in epoch 6, gen_loss = 0.7909154361855667, disc_loss = 0.09674658507636164
Trained batch 113 in epoch 6, gen_loss = 0.7908304121933485, disc_loss = 0.09677147630013917
Trained batch 114 in epoch 6, gen_loss = 0.7889927374280017, disc_loss = 0.09717396743919539
Trained batch 115 in epoch 6, gen_loss = 0.7892685324467462, disc_loss = 0.09701213388350503
Trained batch 116 in epoch 6, gen_loss = 0.7885930158643641, disc_loss = 0.09669805311749124
Trained batch 117 in epoch 6, gen_loss = 0.7903242467318551, disc_loss = 0.09700913815680197
Trained batch 118 in epoch 6, gen_loss = 0.7885276502420923, disc_loss = 0.09729391173655245
Trained batch 119 in epoch 6, gen_loss = 0.7868513680994511, disc_loss = 0.09723208316912253
Trained batch 120 in epoch 6, gen_loss = 0.7895704052172416, disc_loss = 0.09697183467878782
Trained batch 121 in epoch 6, gen_loss = 0.7915209441399965, disc_loss = 0.09706158795561946
Trained batch 122 in epoch 6, gen_loss = 0.7905032777689337, disc_loss = 0.097390915865336
Trained batch 123 in epoch 6, gen_loss = 0.7912839884238858, disc_loss = 0.09677853747721642
Trained batch 124 in epoch 6, gen_loss = 0.7920821964740753, disc_loss = 0.09678440707921981
Trained batch 125 in epoch 6, gen_loss = 0.7902984697194326, disc_loss = 0.09806800426708327
Trained batch 126 in epoch 6, gen_loss = 0.79084726088629, disc_loss = 0.0986430600989522
Trained batch 127 in epoch 6, gen_loss = 0.7927131892647594, disc_loss = 0.0985360712511465
Trained batch 128 in epoch 6, gen_loss = 0.7913898444452951, disc_loss = 0.0989559009786724
Trained batch 129 in epoch 6, gen_loss = 0.7906757943905317, disc_loss = 0.09870564765655078
Trained batch 130 in epoch 6, gen_loss = 0.7926779523605608, disc_loss = 0.10022891261650406
Trained batch 131 in epoch 6, gen_loss = 0.7912869049292622, disc_loss = 0.10069600266940666
Trained batch 132 in epoch 6, gen_loss = 0.7914171776825324, disc_loss = 0.10045276923959416
Trained batch 133 in epoch 6, gen_loss = 0.7910486008249112, disc_loss = 0.10100277218578467
Trained batch 134 in epoch 6, gen_loss = 0.7916631515379305, disc_loss = 0.10091026933104903
Trained batch 135 in epoch 6, gen_loss = 0.7889666896970833, disc_loss = 0.10235023586189046
Trained batch 136 in epoch 6, gen_loss = 0.790317074443302, disc_loss = 0.1028664993108624
Trained batch 137 in epoch 6, gen_loss = 0.7901191640159358, disc_loss = 0.10270220753939255
Trained batch 138 in epoch 6, gen_loss = 0.7925599485421352, disc_loss = 0.10255486539585128
Trained batch 139 in epoch 6, gen_loss = 0.7911017752119474, disc_loss = 0.10292140208184719
Trained batch 140 in epoch 6, gen_loss = 0.789505476858599, disc_loss = 0.10332993428546486
Trained batch 141 in epoch 6, gen_loss = 0.7907072970984688, disc_loss = 0.10424160973077089
Trained batch 142 in epoch 6, gen_loss = 0.7909794518580804, disc_loss = 0.10430691703841403
Trained batch 143 in epoch 6, gen_loss = 0.7892765558014313, disc_loss = 0.1042590206488967
Trained batch 144 in epoch 6, gen_loss = 0.7892434562074727, disc_loss = 0.10381787339675015
Trained batch 145 in epoch 6, gen_loss = 0.789153496492399, disc_loss = 0.10376102153262863
Trained batch 146 in epoch 6, gen_loss = 0.7883756081668698, disc_loss = 0.10385658219456673
Trained batch 147 in epoch 6, gen_loss = 0.7884224123648695, disc_loss = 0.10347872307977161
Trained batch 148 in epoch 6, gen_loss = 0.7877998838088657, disc_loss = 0.10327496269605303
Trained batch 149 in epoch 6, gen_loss = 0.7876232065757116, disc_loss = 0.10299307445685069
Trained batch 150 in epoch 6, gen_loss = 0.7870628125225472, disc_loss = 0.10279283080472063
Trained batch 151 in epoch 6, gen_loss = 0.7869126916323838, disc_loss = 0.10232449234708359
Trained batch 152 in epoch 6, gen_loss = 0.786320697443158, disc_loss = 0.10202220790818625
Trained batch 153 in epoch 6, gen_loss = 0.7857721705328334, disc_loss = 0.10157231437405209
Trained batch 154 in epoch 6, gen_loss = 0.787286990111874, disc_loss = 0.101159655855548
Trained batch 155 in epoch 6, gen_loss = 0.786830774293496, disc_loss = 0.10134195326230465
Trained batch 156 in epoch 6, gen_loss = 0.785838322844475, disc_loss = 0.1009664204280088
Trained batch 157 in epoch 6, gen_loss = 0.7873852500055409, disc_loss = 0.1007958578440962
Trained batch 158 in epoch 6, gen_loss = 0.7861879451094933, disc_loss = 0.10114106034520287
Trained batch 159 in epoch 6, gen_loss = 0.7857703832909465, disc_loss = 0.10110716978088022
Trained batch 160 in epoch 6, gen_loss = 0.7860028675254087, disc_loss = 0.10071785375475883
Trained batch 161 in epoch 6, gen_loss = 0.7868449472718768, disc_loss = 0.10054095294096588
Trained batch 162 in epoch 6, gen_loss = 0.786418994328727, disc_loss = 0.10024311820879304
Trained batch 163 in epoch 6, gen_loss = 0.7874365149111282, disc_loss = 0.09974890393091411
Trained batch 164 in epoch 6, gen_loss = 0.789058435866327, disc_loss = 0.09984141655943611
Trained batch 165 in epoch 6, gen_loss = 0.7872432263859783, disc_loss = 0.1001558935337038
Trained batch 166 in epoch 6, gen_loss = 0.7859909200739718, disc_loss = 0.10017844637532435
Trained batch 167 in epoch 6, gen_loss = 0.7876250717256751, disc_loss = 0.10000337496222485
Trained batch 168 in epoch 6, gen_loss = 0.7886264579888631, disc_loss = 0.0995283554908792
Trained batch 169 in epoch 6, gen_loss = 0.7877198831123464, disc_loss = 0.09946201426141402
Trained batch 170 in epoch 6, gen_loss = 0.7877254972332403, disc_loss = 0.09906632146030142
Trained batch 171 in epoch 6, gen_loss = 0.7890438345629115, disc_loss = 0.09886836622256873
Trained batch 172 in epoch 6, gen_loss = 0.7880152972102854, disc_loss = 0.09890494695891534
Trained batch 173 in epoch 6, gen_loss = 0.7884490382054756, disc_loss = 0.09896608165882785
Trained batch 174 in epoch 6, gen_loss = 0.7875765815802983, disc_loss = 0.0988875779722418
Trained batch 175 in epoch 6, gen_loss = 0.7873331150886688, disc_loss = 0.09869756437414749
Trained batch 176 in epoch 6, gen_loss = 0.7884930656791407, disc_loss = 0.0989627242719723
Trained batch 177 in epoch 6, gen_loss = 0.7883881476153148, disc_loss = 0.09878502566409245
Trained batch 178 in epoch 6, gen_loss = 0.7884265462446479, disc_loss = 0.09849294064847451
Trained batch 179 in epoch 6, gen_loss = 0.7870099662078751, disc_loss = 0.09881177703953452
Trained batch 180 in epoch 6, gen_loss = 0.7875065620762208, disc_loss = 0.09943701855797135
Trained batch 181 in epoch 6, gen_loss = 0.7869120137049601, disc_loss = 0.09932265129800026
Trained batch 182 in epoch 6, gen_loss = 0.785969852586913, disc_loss = 0.09926127941637743
Trained batch 183 in epoch 6, gen_loss = 0.7865556723073773, disc_loss = 0.09909724612193911
Trained batch 184 in epoch 6, gen_loss = 0.7870053766547023, disc_loss = 0.09869768677933796
Trained batch 185 in epoch 6, gen_loss = 0.7867157983203088, disc_loss = 0.09838672957673508
Trained batch 186 in epoch 6, gen_loss = 0.785813544363899, disc_loss = 0.09842119021291401
Trained batch 187 in epoch 6, gen_loss = 0.7852543445026621, disc_loss = 0.09843659414810703
Trained batch 188 in epoch 6, gen_loss = 0.786448383299762, disc_loss = 0.09806532578335868
Trained batch 189 in epoch 6, gen_loss = 0.7860159875530945, disc_loss = 0.09811216855519696
Trained batch 190 in epoch 6, gen_loss = 0.7855881369862882, disc_loss = 0.09809166969273103
Trained batch 191 in epoch 6, gen_loss = 0.7885762203174332, disc_loss = 0.09851079989069451
Trained batch 192 in epoch 6, gen_loss = 0.7881550478502877, disc_loss = 0.09850160495759291
Trained batch 193 in epoch 6, gen_loss = 0.7866705955611062, disc_loss = 0.09939192101052127
Trained batch 194 in epoch 6, gen_loss = 0.7877808685486133, disc_loss = 0.09969826367421028
Trained batch 195 in epoch 6, gen_loss = 0.7878439212027861, disc_loss = 0.09996593747364015
Trained batch 196 in epoch 6, gen_loss = 0.7868162177238368, disc_loss = 0.10008991827365711
Trained batch 197 in epoch 6, gen_loss = 0.7863514698816069, disc_loss = 0.09982657425030313
Trained batch 198 in epoch 6, gen_loss = 0.787671139342102, disc_loss = 0.09967198458748247
Trained batch 199 in epoch 6, gen_loss = 0.7881172333657741, disc_loss = 0.09927721702493728
Trained batch 200 in epoch 6, gen_loss = 0.7868019068122503, disc_loss = 0.0993420997384324
Trained batch 201 in epoch 6, gen_loss = 0.7874811189894629, disc_loss = 0.09936156062095768
Trained batch 202 in epoch 6, gen_loss = 0.7871383814682514, disc_loss = 0.09930675984199705
Trained batch 203 in epoch 6, gen_loss = 0.7866558632722088, disc_loss = 0.09912782261951589
Trained batch 204 in epoch 6, gen_loss = 0.7863154273207594, disc_loss = 0.09910358587597928
Trained batch 205 in epoch 6, gen_loss = 0.7869426418566009, disc_loss = 0.09906082923153361
Trained batch 206 in epoch 6, gen_loss = 0.7864133224683107, disc_loss = 0.09890682128784449
Trained batch 207 in epoch 6, gen_loss = 0.7879891064591132, disc_loss = 0.09863574800189011
Trained batch 208 in epoch 6, gen_loss = 0.7891509956435153, disc_loss = 0.0982402761301926
Trained batch 209 in epoch 6, gen_loss = 0.7880532232068834, disc_loss = 0.09848901437861579
Trained batch 210 in epoch 6, gen_loss = 0.7888279541691333, disc_loss = 0.09812950457653728
Trained batch 211 in epoch 6, gen_loss = 0.7883631776807443, disc_loss = 0.09793222931055527
Trained batch 212 in epoch 6, gen_loss = 0.7894509643176352, disc_loss = 0.09774935116090686
Trained batch 213 in epoch 6, gen_loss = 0.7895722596723342, disc_loss = 0.09739437813339667
Trained batch 214 in epoch 6, gen_loss = 0.7887220447839692, disc_loss = 0.09744268166291159
Trained batch 215 in epoch 6, gen_loss = 0.7906444292101595, disc_loss = 0.09728326475144261
Trained batch 216 in epoch 6, gen_loss = 0.7901744728538848, disc_loss = 0.09717628362369703
Trained batch 217 in epoch 6, gen_loss = 0.7910173632409594, disc_loss = 0.09689530867809823
Trained batch 218 in epoch 6, gen_loss = 0.7913504358568147, disc_loss = 0.09655035974364302
Trained batch 219 in epoch 6, gen_loss = 0.7906978611241687, disc_loss = 0.09640493768859994
Trained batch 220 in epoch 6, gen_loss = 0.7907854673279896, disc_loss = 0.09605577424573143
Trained batch 221 in epoch 6, gen_loss = 0.7923970392963908, disc_loss = 0.09636433696089027
Trained batch 222 in epoch 6, gen_loss = 0.7915476316026508, disc_loss = 0.09633173441071681
Trained batch 223 in epoch 6, gen_loss = 0.7912269113585353, disc_loss = 0.09616128435092312
Trained batch 224 in epoch 6, gen_loss = 0.7920380408234067, disc_loss = 0.09606467849678463
Trained batch 225 in epoch 6, gen_loss = 0.7928975004274234, disc_loss = 0.0960514111922378
Trained batch 226 in epoch 6, gen_loss = 0.7932481612140386, disc_loss = 0.09592505196511483
Trained batch 227 in epoch 6, gen_loss = 0.7930840843340807, disc_loss = 0.09575294922187663
Trained batch 228 in epoch 6, gen_loss = 0.7932712093451137, disc_loss = 0.0954911737788192
Trained batch 229 in epoch 6, gen_loss = 0.7932389600121457, disc_loss = 0.09530276656150818
Trained batch 230 in epoch 6, gen_loss = 0.7930749152903949, disc_loss = 0.09527209717215913
Trained batch 231 in epoch 6, gen_loss = 0.7939944163221737, disc_loss = 0.09542342647910118
Trained batch 232 in epoch 6, gen_loss = 0.7934821024217319, disc_loss = 0.09523714832609816
Trained batch 233 in epoch 6, gen_loss = 0.7933794075352514, disc_loss = 0.09508604514929983
Trained batch 234 in epoch 6, gen_loss = 0.7935148278449444, disc_loss = 0.09477569481476825
Trained batch 235 in epoch 6, gen_loss = 0.7921685452683497, disc_loss = 0.09480035218204987
Trained batch 236 in epoch 6, gen_loss = 0.7935992833934252, disc_loss = 0.09546424846168812
Trained batch 237 in epoch 6, gen_loss = 0.7937413634372359, disc_loss = 0.0951173883166258
Trained batch 238 in epoch 6, gen_loss = 0.791845695867698, disc_loss = 0.09606703034909948
Trained batch 239 in epoch 6, gen_loss = 0.7925190817564726, disc_loss = 0.09673193821217865
Trained batch 240 in epoch 6, gen_loss = 0.7918737099131113, disc_loss = 0.0970813275017308
Trained batch 241 in epoch 6, gen_loss = 0.7914545325454602, disc_loss = 0.0976335272454649
Trained batch 242 in epoch 6, gen_loss = 0.7909050675821893, disc_loss = 0.09756999911257515
Trained batch 243 in epoch 6, gen_loss = 0.7901037209590928, disc_loss = 0.09800360929678942
Trained batch 244 in epoch 6, gen_loss = 0.7919964431499948, disc_loss = 0.09911062319820024
Trained batch 245 in epoch 6, gen_loss = 0.7915598373345243, disc_loss = 0.09932394359805961
Trained batch 246 in epoch 6, gen_loss = 0.7911588051299817, disc_loss = 0.09955458757033957
Trained batch 247 in epoch 6, gen_loss = 0.7920454669623606, disc_loss = 0.09992813442893807
Trained batch 248 in epoch 6, gen_loss = 0.7913635314468399, disc_loss = 0.09991451589966634
Trained batch 249 in epoch 6, gen_loss = 0.791042898774147, disc_loss = 0.09987017587572336
Trained batch 250 in epoch 6, gen_loss = 0.7906116153376986, disc_loss = 0.09985366108200228
Trained batch 251 in epoch 6, gen_loss = 0.7906434582102866, disc_loss = 0.09994660901083123
Trained batch 252 in epoch 6, gen_loss = 0.7899004026599552, disc_loss = 0.10004137969564779
Trained batch 253 in epoch 6, gen_loss = 0.7896291725044176, disc_loss = 0.09991713209209714
Trained batch 254 in epoch 6, gen_loss = 0.7898985013073566, disc_loss = 0.09991919995084697
Trained batch 255 in epoch 6, gen_loss = 0.7899524298263714, disc_loss = 0.09971957235393347
Trained batch 256 in epoch 6, gen_loss = 0.7900565344303963, disc_loss = 0.09978490135114249
Trained batch 257 in epoch 6, gen_loss = 0.7896362819181856, disc_loss = 0.09975439541821562
Trained batch 258 in epoch 6, gen_loss = 0.7891389047547197, disc_loss = 0.09954186556968679
Trained batch 259 in epoch 6, gen_loss = 0.7889886348293378, disc_loss = 0.09960108241066337
Trained batch 260 in epoch 6, gen_loss = 0.788679684373154, disc_loss = 0.0993660414284559
Trained batch 261 in epoch 6, gen_loss = 0.7889227201692931, disc_loss = 0.09910465572171538
Trained batch 262 in epoch 6, gen_loss = 0.7890382487284366, disc_loss = 0.09897712972227611
Trained batch 263 in epoch 6, gen_loss = 0.7880438696028609, disc_loss = 0.09893620581450788
Trained batch 264 in epoch 6, gen_loss = 0.7876966446075799, disc_loss = 0.09942906327405066
Trained batch 265 in epoch 6, gen_loss = 0.7875108372672159, disc_loss = 0.09939559084132202
Trained batch 266 in epoch 6, gen_loss = 0.7888362870903943, disc_loss = 0.09949217083748807
Trained batch 267 in epoch 6, gen_loss = 0.7880375012755394, disc_loss = 0.0995819100748692
Trained batch 268 in epoch 6, gen_loss = 0.7885729494369607, disc_loss = 0.09944934489337041
Trained batch 269 in epoch 6, gen_loss = 0.7879124485784107, disc_loss = 0.0996612219898789
Trained batch 270 in epoch 6, gen_loss = 0.7880392442990053, disc_loss = 0.09957978486794827
Trained batch 271 in epoch 6, gen_loss = 0.7894374814761036, disc_loss = 0.10047334744868909
Trained batch 272 in epoch 6, gen_loss = 0.7880620795946854, disc_loss = 0.10117497914658362
Trained batch 273 in epoch 6, gen_loss = 0.7885802952695067, disc_loss = 0.10097613352874335
Trained batch 274 in epoch 6, gen_loss = 0.7885585861856287, disc_loss = 0.10097207322716713
Trained batch 275 in epoch 6, gen_loss = 0.787822588738324, disc_loss = 0.10108045778790678
Trained batch 276 in epoch 6, gen_loss = 0.7876108442618098, disc_loss = 0.10093898513095474
Trained batch 277 in epoch 6, gen_loss = 0.7880807961705777, disc_loss = 0.10162527694386973
Trained batch 278 in epoch 6, gen_loss = 0.7871761162862129, disc_loss = 0.1020916272689151
Trained batch 279 in epoch 6, gen_loss = 0.7876112127942698, disc_loss = 0.10183471123288784
Trained batch 280 in epoch 6, gen_loss = 0.7883915755884503, disc_loss = 0.10193348329951754
Trained batch 281 in epoch 6, gen_loss = 0.7879942823597725, disc_loss = 0.10182209964181092
Trained batch 282 in epoch 6, gen_loss = 0.787580436931482, disc_loss = 0.10164536068433165
Trained batch 283 in epoch 6, gen_loss = 0.787860518085285, disc_loss = 0.1014593216446294
Trained batch 284 in epoch 6, gen_loss = 0.7876786893919895, disc_loss = 0.10150354417008266
Trained batch 285 in epoch 6, gen_loss = 0.7869630242352719, disc_loss = 0.10136877965520728
Trained batch 286 in epoch 6, gen_loss = 0.7864034669116814, disc_loss = 0.10140349927523826
Trained batch 287 in epoch 6, gen_loss = 0.7865283951784173, disc_loss = 0.10125643387436867
Trained batch 288 in epoch 6, gen_loss = 0.7864972611818346, disc_loss = 0.10113191199859534
Trained batch 289 in epoch 6, gen_loss = 0.7877857795049404, disc_loss = 0.10115251230268643
Trained batch 290 in epoch 6, gen_loss = 0.7876898073863328, disc_loss = 0.1010334879620788
Trained batch 291 in epoch 6, gen_loss = 0.7874918185072403, disc_loss = 0.10083124296714181
Trained batch 292 in epoch 6, gen_loss = 0.7884757108859235, disc_loss = 0.10069184038317651
Trained batch 293 in epoch 6, gen_loss = 0.7880777924441967, disc_loss = 0.10056185509477343
Trained batch 294 in epoch 6, gen_loss = 0.7888622858766782, disc_loss = 0.10032132641743806
Trained batch 295 in epoch 6, gen_loss = 0.7890683175945604, disc_loss = 0.10007777927141334
Trained batch 296 in epoch 6, gen_loss = 0.7891981558566944, disc_loss = 0.09988854298687945
Trained batch 297 in epoch 6, gen_loss = 0.7893461864066604, disc_loss = 0.099831048874247
Trained batch 298 in epoch 6, gen_loss = 0.7890257894195442, disc_loss = 0.0998720329591263
Trained batch 299 in epoch 6, gen_loss = 0.789106454749902, disc_loss = 0.0997036991516749
Trained batch 300 in epoch 6, gen_loss = 0.7890198049553209, disc_loss = 0.09950917549555088
Trained batch 301 in epoch 6, gen_loss = 0.788560316953438, disc_loss = 0.09945535086194016
Trained batch 302 in epoch 6, gen_loss = 0.7884769869519539, disc_loss = 0.09924244122094053
Trained batch 303 in epoch 6, gen_loss = 0.7890310829603359, disc_loss = 0.09933946530432686
Trained batch 304 in epoch 6, gen_loss = 0.7887734754163711, disc_loss = 0.09911880440643576
Trained batch 305 in epoch 6, gen_loss = 0.7885743914281621, disc_loss = 0.09895599011356145
Trained batch 306 in epoch 6, gen_loss = 0.7892818607220043, disc_loss = 0.09881742343500693
Trained batch 307 in epoch 6, gen_loss = 0.7893820905259678, disc_loss = 0.09856622739900629
Trained batch 308 in epoch 6, gen_loss = 0.7889726199571369, disc_loss = 0.09868847022984406
Trained batch 309 in epoch 6, gen_loss = 0.7886660401859591, disc_loss = 0.09869326435990872
Trained batch 310 in epoch 6, gen_loss = 0.7884702455384172, disc_loss = 0.09859002818775714
Trained batch 311 in epoch 6, gen_loss = 0.7889235381705638, disc_loss = 0.09850445001696546
Trained batch 312 in epoch 6, gen_loss = 0.7882456759484812, disc_loss = 0.09872203973678355
Trained batch 313 in epoch 6, gen_loss = 0.787918866724725, disc_loss = 0.09867615453234524
Trained batch 314 in epoch 6, gen_loss = 0.78866521394442, disc_loss = 0.09853757722746759
Trained batch 315 in epoch 6, gen_loss = 0.7884320359252677, disc_loss = 0.09841900307072114
Trained batch 316 in epoch 6, gen_loss = 0.7882982762266033, disc_loss = 0.0983498015379304
Trained batch 317 in epoch 6, gen_loss = 0.7880799919366837, disc_loss = 0.09818149564213723
Trained batch 318 in epoch 6, gen_loss = 0.788222299380736, disc_loss = 0.09808161102679082
Trained batch 319 in epoch 6, gen_loss = 0.789417906012386, disc_loss = 0.09853807990439237
Trained batch 320 in epoch 6, gen_loss = 0.7890405477578766, disc_loss = 0.09871850740686755
Trained batch 321 in epoch 6, gen_loss = 0.7882688966411981, disc_loss = 0.09889262882263763
Trained batch 322 in epoch 6, gen_loss = 0.7898796242272522, disc_loss = 0.10001687234953831
Trained batch 323 in epoch 6, gen_loss = 0.7895216146185075, disc_loss = 0.099993868627482
Trained batch 324 in epoch 6, gen_loss = 0.7890707680812249, disc_loss = 0.09989802711285077
Trained batch 325 in epoch 6, gen_loss = 0.7887697586435481, disc_loss = 0.10013905087588755
Trained batch 326 in epoch 6, gen_loss = 0.7891217917659596, disc_loss = 0.10037636845757109
Trained batch 327 in epoch 6, gen_loss = 0.789317141309744, disc_loss = 0.10061526764184237
Trained batch 328 in epoch 6, gen_loss = 0.788810544553861, disc_loss = 0.10070748597745838
Trained batch 329 in epoch 6, gen_loss = 0.78843292602987, disc_loss = 0.10093373333414396
Trained batch 330 in epoch 6, gen_loss = 0.7886237218480816, disc_loss = 0.10075033650792617
Trained batch 331 in epoch 6, gen_loss = 0.7881495960685144, disc_loss = 0.1008079407781542
Trained batch 332 in epoch 6, gen_loss = 0.7879584985631364, disc_loss = 0.10069162947861282
Trained batch 333 in epoch 6, gen_loss = 0.7879479742514159, disc_loss = 0.10046779681108668
Trained batch 334 in epoch 6, gen_loss = 0.7876626834050933, disc_loss = 0.10062192509423441
Trained batch 335 in epoch 6, gen_loss = 0.7874888588807413, disc_loss = 0.10050515296115052
Trained batch 336 in epoch 6, gen_loss = 0.787202043685432, disc_loss = 0.1004041963497326
Trained batch 337 in epoch 6, gen_loss = 0.7871895371633169, disc_loss = 0.10025974740026265
Trained batch 338 in epoch 6, gen_loss = 0.7871055194234426, disc_loss = 0.10006325639190927
Trained batch 339 in epoch 6, gen_loss = 0.7872178062796593, disc_loss = 0.09987015410819475
Trained batch 340 in epoch 6, gen_loss = 0.7873410377159846, disc_loss = 0.09986843625383993
Trained batch 341 in epoch 6, gen_loss = 0.7874953066222152, disc_loss = 0.09961194708692836
Trained batch 342 in epoch 6, gen_loss = 0.7878083167027454, disc_loss = 0.09936220773411562
Trained batch 343 in epoch 6, gen_loss = 0.7879938156625559, disc_loss = 0.09913986178959698
Trained batch 344 in epoch 6, gen_loss = 0.7872586900773255, disc_loss = 0.09910911788651044
Trained batch 345 in epoch 6, gen_loss = 0.7875763659360092, disc_loss = 0.09891131346388532
Trained batch 346 in epoch 6, gen_loss = 0.7870496773410599, disc_loss = 0.09887791895750449
Trained batch 347 in epoch 6, gen_loss = 0.788192578173917, disc_loss = 0.0986753458146477
Trained batch 348 in epoch 6, gen_loss = 0.788321834665998, disc_loss = 0.09848188960599182
Trained batch 349 in epoch 6, gen_loss = 0.788047165615218, disc_loss = 0.09841609911727053
Trained batch 350 in epoch 6, gen_loss = 0.7878258938972766, disc_loss = 0.0982653872611431
Trained batch 351 in epoch 6, gen_loss = 0.7877668617293239, disc_loss = 0.09826591864376413
Trained batch 352 in epoch 6, gen_loss = 0.7877337838873985, disc_loss = 0.09811439996759379
Trained batch 353 in epoch 6, gen_loss = 0.7877952696408256, disc_loss = 0.09793360214049028
Trained batch 354 in epoch 6, gen_loss = 0.787494794835507, disc_loss = 0.09793845950822595
Trained batch 355 in epoch 6, gen_loss = 0.7886195890186878, disc_loss = 0.09805171512423104
Trained batch 356 in epoch 6, gen_loss = 0.7893358035748747, disc_loss = 0.09784937561789647
Trained batch 357 in epoch 6, gen_loss = 0.7897215093480808, disc_loss = 0.09763478641216149
Trained batch 358 in epoch 6, gen_loss = 0.7893273957426502, disc_loss = 0.09765789325253046
Trained batch 359 in epoch 6, gen_loss = 0.7891575880348682, disc_loss = 0.0975310281281256
Trained batch 360 in epoch 6, gen_loss = 0.7900397395328141, disc_loss = 0.09767383192033814
Trained batch 361 in epoch 6, gen_loss = 0.7899229219440598, disc_loss = 0.09758840434932413
Trained batch 362 in epoch 6, gen_loss = 0.7904415520590528, disc_loss = 0.09764210230699091
Trained batch 363 in epoch 6, gen_loss = 0.7896830016276338, disc_loss = 0.09771782011919461
Trained batch 364 in epoch 6, gen_loss = 0.7897092277873052, disc_loss = 0.09751250042184575
Trained batch 365 in epoch 6, gen_loss = 0.7894858717104125, disc_loss = 0.0975166129945813
Trained batch 366 in epoch 6, gen_loss = 0.7891275446648819, disc_loss = 0.09755964133106883
Trained batch 367 in epoch 6, gen_loss = 0.789166359230876, disc_loss = 0.09743411456862383
Trained batch 368 in epoch 6, gen_loss = 0.7890928052466736, disc_loss = 0.09727801579911373
Trained batch 369 in epoch 6, gen_loss = 0.78842570193716, disc_loss = 0.09727138807946765
Trained batch 370 in epoch 6, gen_loss = 0.7881349979867189, disc_loss = 0.09713107662280454
Trained batch 371 in epoch 6, gen_loss = 0.7878497351081141, disc_loss = 0.09727305952479602
Trained batch 372 in epoch 6, gen_loss = 0.7869669343607035, disc_loss = 0.09739450460684364
Trained batch 373 in epoch 6, gen_loss = 0.786295653425436, disc_loss = 0.09744557759719577
Trained batch 374 in epoch 6, gen_loss = 0.7875123174190521, disc_loss = 0.09812217280765374
Trained batch 375 in epoch 6, gen_loss = 0.7869458281771934, disc_loss = 0.09835404539579883
Trained batch 376 in epoch 6, gen_loss = 0.7872608666868994, disc_loss = 0.0982118370826665
Trained batch 377 in epoch 6, gen_loss = 0.7870850866591489, disc_loss = 0.09815107425428414
Trained batch 378 in epoch 6, gen_loss = 0.7872771047507867, disc_loss = 0.09794592023347959
Trained batch 379 in epoch 6, gen_loss = 0.786697753871742, disc_loss = 0.09809411696991638
Trained batch 380 in epoch 6, gen_loss = 0.7872417446352992, disc_loss = 0.09826667090081011
Trained batch 381 in epoch 6, gen_loss = 0.786644210600104, disc_loss = 0.09836874090388652
Trained batch 382 in epoch 6, gen_loss = 0.7869510447543221, disc_loss = 0.09823136041840592
Trained batch 383 in epoch 6, gen_loss = 0.7871760694154849, disc_loss = 0.09808128468284849
Trained batch 384 in epoch 6, gen_loss = 0.7875373190873629, disc_loss = 0.09816874332919523
Trained batch 385 in epoch 6, gen_loss = 0.7870618354316821, disc_loss = 0.09826374151912841
Trained batch 386 in epoch 6, gen_loss = 0.7867520427673054, disc_loss = 0.09829954255747703
Trained batch 387 in epoch 6, gen_loss = 0.787283868288871, disc_loss = 0.0985788010089591
Trained batch 388 in epoch 6, gen_loss = 0.7873659580562905, disc_loss = 0.09867575266194988
Trained batch 389 in epoch 6, gen_loss = 0.7871517250935237, disc_loss = 0.09882478916014616
Trained batch 390 in epoch 6, gen_loss = 0.7862759462707792, disc_loss = 0.09940698090702524
Trained batch 391 in epoch 6, gen_loss = 0.7863606745187117, disc_loss = 0.09924011983984739
Trained batch 392 in epoch 6, gen_loss = 0.787096152930466, disc_loss = 0.09960192785558052
Trained batch 393 in epoch 6, gen_loss = 0.7869835216079266, disc_loss = 0.09955994724792423
Trained batch 394 in epoch 6, gen_loss = 0.7872244914875755, disc_loss = 0.09934973716264284
Trained batch 395 in epoch 6, gen_loss = 0.7869568723018723, disc_loss = 0.09925727421568349
Trained batch 396 in epoch 6, gen_loss = 0.7871271338811149, disc_loss = 0.09909287182806571
Trained batch 397 in epoch 6, gen_loss = 0.7872519151649283, disc_loss = 0.09915462862138623
Trained batch 398 in epoch 6, gen_loss = 0.7867036394606856, disc_loss = 0.09916382614887298
Trained batch 399 in epoch 6, gen_loss = 0.7865157151222228, disc_loss = 0.09905754404608161
Trained batch 400 in epoch 6, gen_loss = 0.7870406955852176, disc_loss = 0.09904322376070623
Trained batch 401 in epoch 6, gen_loss = 0.7869258324305216, disc_loss = 0.098851464554408
Trained batch 402 in epoch 6, gen_loss = 0.7861745324974913, disc_loss = 0.09916439908961061
Trained batch 403 in epoch 6, gen_loss = 0.7866703460712244, disc_loss = 0.09913053381542611
Trained batch 404 in epoch 6, gen_loss = 0.7863016963005066, disc_loss = 0.09907487619346307
Trained batch 405 in epoch 6, gen_loss = 0.7864746072609436, disc_loss = 0.0989153251519858
Trained batch 406 in epoch 6, gen_loss = 0.7862226052131934, disc_loss = 0.09891917023359265
Trained batch 407 in epoch 6, gen_loss = 0.7863546471093216, disc_loss = 0.09896388777312548
Trained batch 408 in epoch 6, gen_loss = 0.7864058054163869, disc_loss = 0.09877358024944449
Trained batch 409 in epoch 6, gen_loss = 0.7860424184217686, disc_loss = 0.09880099445127133
Trained batch 410 in epoch 6, gen_loss = 0.7869015473808976, disc_loss = 0.09907712078134363
Trained batch 411 in epoch 6, gen_loss = 0.786954639750777, disc_loss = 0.09889484174748503
Trained batch 412 in epoch 6, gen_loss = 0.7872305236774841, disc_loss = 0.09873425461279711
Trained batch 413 in epoch 6, gen_loss = 0.7866097017762742, disc_loss = 0.09884448283338461
Trained batch 414 in epoch 6, gen_loss = 0.7870487967169428, disc_loss = 0.09903130368385689
Trained batch 415 in epoch 6, gen_loss = 0.7871097814864837, disc_loss = 0.0989213482557366
Trained batch 416 in epoch 6, gen_loss = 0.7867116377793913, disc_loss = 0.09893582631304539
Trained batch 417 in epoch 6, gen_loss = 0.7868598080708079, disc_loss = 0.09875094144645205
Trained batch 418 in epoch 6, gen_loss = 0.7867538843632882, disc_loss = 0.09863545935876614
Trained batch 419 in epoch 6, gen_loss = 0.7864748872461773, disc_loss = 0.09850744449843964
Trained batch 420 in epoch 6, gen_loss = 0.7871267271721448, disc_loss = 0.09860111848227768
Trained batch 421 in epoch 6, gen_loss = 0.7870275241221297, disc_loss = 0.09857773047240707
Trained batch 422 in epoch 6, gen_loss = 0.7867321949760401, disc_loss = 0.09859792674158482
Trained batch 423 in epoch 6, gen_loss = 0.7867871525714982, disc_loss = 0.09844304008831112
Trained batch 424 in epoch 6, gen_loss = 0.7871331579544965, disc_loss = 0.09838104462798904
Trained batch 425 in epoch 6, gen_loss = 0.786533321293307, disc_loss = 0.0986357716135156
Trained batch 426 in epoch 6, gen_loss = 0.7874501524820261, disc_loss = 0.09872336690019667
Trained batch 427 in epoch 6, gen_loss = 0.7873717741431477, disc_loss = 0.09864787007986664
Trained batch 428 in epoch 6, gen_loss = 0.787635759457008, disc_loss = 0.09848564066044935
Trained batch 429 in epoch 6, gen_loss = 0.787572079619696, disc_loss = 0.09837794475430665
Trained batch 430 in epoch 6, gen_loss = 0.7873576315262478, disc_loss = 0.09854138822331505
Trained batch 431 in epoch 6, gen_loss = 0.7870184668788204, disc_loss = 0.09855921645821245
Trained batch 432 in epoch 6, gen_loss = 0.7868851478325577, disc_loss = 0.0984340175108739
Trained batch 433 in epoch 6, gen_loss = 0.7877197647424338, disc_loss = 0.09841327637880354
Trained batch 434 in epoch 6, gen_loss = 0.7883021850695555, disc_loss = 0.0982296547370738
Trained batch 435 in epoch 6, gen_loss = 0.787845140886963, disc_loss = 0.09823348997331677
Trained batch 436 in epoch 6, gen_loss = 0.7879505675771962, disc_loss = 0.09804687917539402
Trained batch 437 in epoch 6, gen_loss = 0.7876466654207064, disc_loss = 0.09799219049581381
Trained batch 438 in epoch 6, gen_loss = 0.7885368044121118, disc_loss = 0.09850021172527029
Trained batch 439 in epoch 6, gen_loss = 0.7882406828078357, disc_loss = 0.09843117145144127
Trained batch 440 in epoch 6, gen_loss = 0.7879693241887081, disc_loss = 0.0984223362421638
Trained batch 441 in epoch 6, gen_loss = 0.7887383180236385, disc_loss = 0.09830084524846455
Trained batch 442 in epoch 6, gen_loss = 0.7885322194067135, disc_loss = 0.0982462090122646
Trained batch 443 in epoch 6, gen_loss = 0.7888017970699448, disc_loss = 0.09816085181391991
Trained batch 444 in epoch 6, gen_loss = 0.7889674755964386, disc_loss = 0.09797124390731032
Trained batch 445 in epoch 6, gen_loss = 0.7888717776991326, disc_loss = 0.09796070072156765
Trained batch 446 in epoch 6, gen_loss = 0.7890708561178289, disc_loss = 0.09779788423496272
Trained batch 447 in epoch 6, gen_loss = 0.7889080494642258, disc_loss = 0.09769157060613257
Trained batch 448 in epoch 6, gen_loss = 0.7892777383460234, disc_loss = 0.09756164847435492
Trained batch 449 in epoch 6, gen_loss = 0.7895293366909027, disc_loss = 0.09766271091790663
Trained batch 450 in epoch 6, gen_loss = 0.7893941247806845, disc_loss = 0.09757172508565853
Trained batch 451 in epoch 6, gen_loss = 0.7889917763197316, disc_loss = 0.09761835562798764
Trained batch 452 in epoch 6, gen_loss = 0.7891658015598525, disc_loss = 0.09756723112708357
Trained batch 453 in epoch 6, gen_loss = 0.7890733250699905, disc_loss = 0.09745502452846075
Trained batch 454 in epoch 6, gen_loss = 0.7891769861126994, disc_loss = 0.09729960219995988
Trained batch 455 in epoch 6, gen_loss = 0.7887374712971219, disc_loss = 0.09735582816095925
Trained batch 456 in epoch 6, gen_loss = 0.7889761979522538, disc_loss = 0.09763150779363297
Trained batch 457 in epoch 6, gen_loss = 0.7890909980478245, disc_loss = 0.09744942439598027
Trained batch 458 in epoch 6, gen_loss = 0.7896838008967879, disc_loss = 0.09727232834661059
Trained batch 459 in epoch 6, gen_loss = 0.7894524675348531, disc_loss = 0.097198102246646
Trained batch 460 in epoch 6, gen_loss = 0.7892454415236533, disc_loss = 0.09719268280665296
Trained batch 461 in epoch 6, gen_loss = 0.789589172575897, disc_loss = 0.09773660884581474
Trained batch 462 in epoch 6, gen_loss = 0.7901566994112975, disc_loss = 0.09755492564009152
Trained batch 463 in epoch 6, gen_loss = 0.7901976457957564, disc_loss = 0.0974545636864636
Trained batch 464 in epoch 6, gen_loss = 0.7897697430784985, disc_loss = 0.09759764312816563
Trained batch 465 in epoch 6, gen_loss = 0.7901197712820487, disc_loss = 0.09782734069205788
Trained batch 466 in epoch 6, gen_loss = 0.7899524854133165, disc_loss = 0.09772069068980549
Trained batch 467 in epoch 6, gen_loss = 0.7895768272061633, disc_loss = 0.0977652405277213
Trained batch 468 in epoch 6, gen_loss = 0.7901651935536724, disc_loss = 0.0976215847956537
Trained batch 469 in epoch 6, gen_loss = 0.7904898534429834, disc_loss = 0.09749556601126777
Trained batch 470 in epoch 6, gen_loss = 0.7904019416517513, disc_loss = 0.09746485635748968
Trained batch 471 in epoch 6, gen_loss = 0.7904895911529913, disc_loss = 0.09729068290237021
Trained batch 472 in epoch 6, gen_loss = 0.7904905652899067, disc_loss = 0.0972173309847555
Trained batch 473 in epoch 6, gen_loss = 0.7900624842331883, disc_loss = 0.09716338511430639
Trained batch 474 in epoch 6, gen_loss = 0.7901863819674442, disc_loss = 0.09703553956198065
Trained batch 475 in epoch 6, gen_loss = 0.7902211240109276, disc_loss = 0.09690060945102523
Trained batch 476 in epoch 6, gen_loss = 0.7902680791648928, disc_loss = 0.09674020204888324
Trained batch 477 in epoch 6, gen_loss = 0.7904144185108121, disc_loss = 0.09658311272749218
Trained batch 478 in epoch 6, gen_loss = 0.790039557380318, disc_loss = 0.09656162173846942
Trained batch 479 in epoch 6, gen_loss = 0.7902089465409518, disc_loss = 0.09646947083917136
Trained batch 480 in epoch 6, gen_loss = 0.7902489676297083, disc_loss = 0.09637857691274487
Trained batch 481 in epoch 6, gen_loss = 0.7899578464723721, disc_loss = 0.0963365103377037
Trained batch 482 in epoch 6, gen_loss = 0.7905512336124791, disc_loss = 0.0962342158168184
Trained batch 483 in epoch 6, gen_loss = 0.7906899007637639, disc_loss = 0.09617061298417527
Trained batch 484 in epoch 6, gen_loss = 0.7904522578740857, disc_loss = 0.09615770349106223
Trained batch 485 in epoch 6, gen_loss = 0.7910659085085363, disc_loss = 0.09601393783534015
Trained batch 486 in epoch 6, gen_loss = 0.7912051998369503, disc_loss = 0.095958131401813
Trained batch 487 in epoch 6, gen_loss = 0.7912035137414932, disc_loss = 0.0958830372689933
Trained batch 488 in epoch 6, gen_loss = 0.7908346370197756, disc_loss = 0.09605396487169227
Trained batch 489 in epoch 6, gen_loss = 0.7903143853557353, disc_loss = 0.09626400511787862
Trained batch 490 in epoch 6, gen_loss = 0.7900664643697486, disc_loss = 0.09621328038074334
Trained batch 491 in epoch 6, gen_loss = 0.7908482626686252, disc_loss = 0.09621323501252062
Trained batch 492 in epoch 6, gen_loss = 0.790458780152319, disc_loss = 0.09629447451409172
Trained batch 493 in epoch 6, gen_loss = 0.790754832236873, disc_loss = 0.09620336414529727
Trained batch 494 in epoch 6, gen_loss = 0.7906630070522578, disc_loss = 0.0961347553389843
Trained batch 495 in epoch 6, gen_loss = 0.7908837792854155, disc_loss = 0.09601463213743221
Trained batch 496 in epoch 6, gen_loss = 0.790613720954304, disc_loss = 0.09593129937557628
Trained batch 497 in epoch 6, gen_loss = 0.7904731271017986, disc_loss = 0.0958438424101795
Trained batch 498 in epoch 6, gen_loss = 0.7902195638788487, disc_loss = 0.09585584616493845
Trained batch 499 in epoch 6, gen_loss = 0.7901195042133331, disc_loss = 0.09589490081369877
Trained batch 500 in epoch 6, gen_loss = 0.7900799151190264, disc_loss = 0.09578120991022525
Trained batch 501 in epoch 6, gen_loss = 0.7898500038095679, disc_loss = 0.09577479020532859
Trained batch 502 in epoch 6, gen_loss = 0.7895696202281929, disc_loss = 0.09574485473912468
Trained batch 503 in epoch 6, gen_loss = 0.7894639556133558, disc_loss = 0.095885162374803
Trained batch 504 in epoch 6, gen_loss = 0.7897658578240045, disc_loss = 0.0957328244158537
Trained batch 505 in epoch 6, gen_loss = 0.7894594669342041, disc_loss = 0.09574438787613933
Trained batch 506 in epoch 6, gen_loss = 0.7897726695918472, disc_loss = 0.0956657840714182
Trained batch 507 in epoch 6, gen_loss = 0.7902864218931499, disc_loss = 0.09557655971409298
Trained batch 508 in epoch 6, gen_loss = 0.790696802682633, disc_loss = 0.09543687667265856
Trained batch 509 in epoch 6, gen_loss = 0.7900771909484676, disc_loss = 0.09589230406518076
Trained batch 510 in epoch 6, gen_loss = 0.7905333361163764, disc_loss = 0.09591505485504807
Trained batch 511 in epoch 6, gen_loss = 0.7908952179714106, disc_loss = 0.0958940014388645
Trained batch 512 in epoch 6, gen_loss = 0.790351609330893, disc_loss = 0.09606258767215829
Trained batch 513 in epoch 6, gen_loss = 0.7902674880820953, disc_loss = 0.09593566958267054
Trained batch 514 in epoch 6, gen_loss = 0.7901120498921107, disc_loss = 0.09591802207083956
Trained batch 515 in epoch 6, gen_loss = 0.7905781332028005, disc_loss = 0.09591152070292322
Trained batch 516 in epoch 6, gen_loss = 0.7902770905360954, disc_loss = 0.09592349308847344
Trained batch 517 in epoch 6, gen_loss = 0.7901187859561912, disc_loss = 0.09580389922664548
Trained batch 518 in epoch 6, gen_loss = 0.7908012612591819, disc_loss = 0.09604357160369441
Trained batch 519 in epoch 6, gen_loss = 0.7907649714786272, disc_loss = 0.09599915071247289
Trained batch 520 in epoch 6, gen_loss = 0.7902505888019093, disc_loss = 0.09620970349236894
Trained batch 521 in epoch 6, gen_loss = 0.7904309964385526, disc_loss = 0.09607204845910214
Trained batch 522 in epoch 6, gen_loss = 0.7906768144772568, disc_loss = 0.09613467208385809
Trained batch 523 in epoch 6, gen_loss = 0.7904801729867477, disc_loss = 0.09615222179465963
Trained batch 524 in epoch 6, gen_loss = 0.7901223738420577, disc_loss = 0.096209516408188
Trained batch 525 in epoch 6, gen_loss = 0.7902318426751366, disc_loss = 0.09616911684308102
Trained batch 526 in epoch 6, gen_loss = 0.790579023295607, disc_loss = 0.0961982689098061
Trained batch 527 in epoch 6, gen_loss = 0.7901493716759213, disc_loss = 0.09641986970690954
Trained batch 528 in epoch 6, gen_loss = 0.7909583476968884, disc_loss = 0.0963236372636205
Trained batch 529 in epoch 6, gen_loss = 0.7907497358209682, disc_loss = 0.09634586724118804
Trained batch 530 in epoch 6, gen_loss = 0.791082241384772, disc_loss = 0.09630594877859405
Trained batch 531 in epoch 6, gen_loss = 0.7916142137763196, disc_loss = 0.09617394234817055
Trained batch 532 in epoch 6, gen_loss = 0.7915908531556657, disc_loss = 0.0960691445218801
Trained batch 533 in epoch 6, gen_loss = 0.7917105608553475, disc_loss = 0.09593448726885886
Trained batch 534 in epoch 6, gen_loss = 0.7914733088462153, disc_loss = 0.09594657787722405
Trained batch 535 in epoch 6, gen_loss = 0.7912669868500375, disc_loss = 0.09586205333818806
Trained batch 536 in epoch 6, gen_loss = 0.7914197898332855, disc_loss = 0.09594957419849752
Trained batch 537 in epoch 6, gen_loss = 0.7911044512650337, disc_loss = 0.09601899990154132
Trained batch 538 in epoch 6, gen_loss = 0.7910441313360529, disc_loss = 0.09595197652413032
Trained batch 539 in epoch 6, gen_loss = 0.7913387550799935, disc_loss = 0.09602380494621617
Trained batch 540 in epoch 6, gen_loss = 0.7918016926528345, disc_loss = 0.09595367413310268
Trained batch 541 in epoch 6, gen_loss = 0.7910911600858083, disc_loss = 0.09648189670664029
Trained batch 542 in epoch 6, gen_loss = 0.7916821796261804, disc_loss = 0.09661291245007493
Trained batch 543 in epoch 6, gen_loss = 0.7920138825498083, disc_loss = 0.09656542645397541
Trained batch 544 in epoch 6, gen_loss = 0.7915685474872589, disc_loss = 0.09662338860606381
Trained batch 545 in epoch 6, gen_loss = 0.7913452572984137, disc_loss = 0.09659805452116789
Trained batch 546 in epoch 6, gen_loss = 0.791857335260189, disc_loss = 0.0967096991775731
Trained batch 547 in epoch 6, gen_loss = 0.7919571102209335, disc_loss = 0.0966079204995865
Trained batch 548 in epoch 6, gen_loss = 0.7918347605047764, disc_loss = 0.09656423477893644
Trained batch 549 in epoch 6, gen_loss = 0.7917029057307677, disc_loss = 0.09647747403857383
Trained batch 550 in epoch 6, gen_loss = 0.7917386764515117, disc_loss = 0.09639783631232711
Trained batch 551 in epoch 6, gen_loss = 0.7919620538427345, disc_loss = 0.09627382153226738
Trained batch 552 in epoch 6, gen_loss = 0.7923282819781553, disc_loss = 0.09614827076670382
Trained batch 553 in epoch 6, gen_loss = 0.7918463296085488, disc_loss = 0.0963138409786007
Trained batch 554 in epoch 6, gen_loss = 0.7918947063587808, disc_loss = 0.09621419123634024
Trained batch 555 in epoch 6, gen_loss = 0.7922236184529263, disc_loss = 0.09637353034261212
Trained batch 556 in epoch 6, gen_loss = 0.7926123089272415, disc_loss = 0.09634726593200672
Trained batch 557 in epoch 6, gen_loss = 0.7924410530422751, disc_loss = 0.09630856208676826
Trained batch 558 in epoch 6, gen_loss = 0.7923935555281494, disc_loss = 0.09624648475702952
Trained batch 559 in epoch 6, gen_loss = 0.7930721797581229, disc_loss = 0.09620857284337814
Trained batch 560 in epoch 6, gen_loss = 0.7931275144086589, disc_loss = 0.09613287166332073
Trained batch 561 in epoch 6, gen_loss = 0.7932053921591768, disc_loss = 0.09605031618616441
Trained batch 562 in epoch 6, gen_loss = 0.7931107742642425, disc_loss = 0.09597421833520778
Trained batch 563 in epoch 6, gen_loss = 0.7940608117703005, disc_loss = 0.0959942780785157
Trained batch 564 in epoch 6, gen_loss = 0.7939009647981256, disc_loss = 0.0959203646674884
Trained batch 565 in epoch 6, gen_loss = 0.7939796313485493, disc_loss = 0.09577858383197982
Trained batch 566 in epoch 6, gen_loss = 0.793999119778369, disc_loss = 0.09570466832469696
Trained batch 567 in epoch 6, gen_loss = 0.7941484405646022, disc_loss = 0.09563320942393595
Trained batch 568 in epoch 6, gen_loss = 0.7943620216134143, disc_loss = 0.09556413019936931
Trained batch 569 in epoch 6, gen_loss = 0.7939110759580345, disc_loss = 0.09559911949265944
Trained batch 570 in epoch 6, gen_loss = 0.7945038875118029, disc_loss = 0.09549175295163266
Trained batch 571 in epoch 6, gen_loss = 0.794290316427921, disc_loss = 0.0954297372608908
Trained batch 572 in epoch 6, gen_loss = 0.7947022321440579, disc_loss = 0.09545641805632056
Trained batch 573 in epoch 6, gen_loss = 0.7948522624342284, disc_loss = 0.0953869143734566
Trained batch 574 in epoch 6, gen_loss = 0.7946226183746172, disc_loss = 0.09538053272534971
Trained batch 575 in epoch 6, gen_loss = 0.7948186058654554, disc_loss = 0.09525247469557346
Trained batch 576 in epoch 6, gen_loss = 0.7944325238104709, disc_loss = 0.09552261623613653
Trained batch 577 in epoch 6, gen_loss = 0.7942991110795922, disc_loss = 0.0955176197256648
Trained batch 578 in epoch 6, gen_loss = 0.7951619491778918, disc_loss = 0.09586084543024423
Trained batch 579 in epoch 6, gen_loss = 0.7957336514674384, disc_loss = 0.09580343577946568
Trained batch 580 in epoch 6, gen_loss = 0.7954938514815345, disc_loss = 0.0957159722086023
Trained batch 581 in epoch 6, gen_loss = 0.7956104147987267, disc_loss = 0.09567754781929795
Trained batch 582 in epoch 6, gen_loss = 0.7957321242341455, disc_loss = 0.09559761749749834
Trained batch 583 in epoch 6, gen_loss = 0.7958932148981585, disc_loss = 0.09551338768844837
Trained batch 584 in epoch 6, gen_loss = 0.7960213421246944, disc_loss = 0.09547005129229819
Trained batch 585 in epoch 6, gen_loss = 0.7958006816614203, disc_loss = 0.09554113746770107
Trained batch 586 in epoch 6, gen_loss = 0.7958111581749566, disc_loss = 0.09549867447141996
Trained batch 587 in epoch 6, gen_loss = 0.7963223584553822, disc_loss = 0.09552483940116908
Trained batch 588 in epoch 6, gen_loss = 0.7966771281129841, disc_loss = 0.0954092244929136
Trained batch 589 in epoch 6, gen_loss = 0.796287548087411, disc_loss = 0.09553274037789995
Trained batch 590 in epoch 6, gen_loss = 0.7963591012757039, disc_loss = 0.09542267176428221
Trained batch 591 in epoch 6, gen_loss = 0.7962287922666685, disc_loss = 0.09537726480236931
Trained batch 592 in epoch 6, gen_loss = 0.7961619973283192, disc_loss = 0.0953424483424596
Trained batch 593 in epoch 6, gen_loss = 0.7967762818139812, disc_loss = 0.09531588518132866
Trained batch 594 in epoch 6, gen_loss = 0.7966563405609932, disc_loss = 0.0953108443745545
Trained batch 595 in epoch 6, gen_loss = 0.7964673514834186, disc_loss = 0.09527944234018558
Trained batch 596 in epoch 6, gen_loss = 0.7968021918281638, disc_loss = 0.09533699561328544
Trained batch 597 in epoch 6, gen_loss = 0.796391480393633, disc_loss = 0.0954718886622318
Trained batch 598 in epoch 6, gen_loss = 0.7972789913764183, disc_loss = 0.09559030214539155
Trained batch 599 in epoch 6, gen_loss = 0.7969773877163728, disc_loss = 0.09560753321275114
Trained batch 600 in epoch 6, gen_loss = 0.7966425435217763, disc_loss = 0.09558671190342967
Trained batch 601 in epoch 6, gen_loss = 0.7963158321440021, disc_loss = 0.09565396780810285
Trained batch 602 in epoch 6, gen_loss = 0.7963708109820067, disc_loss = 0.09563516408427437
Trained batch 603 in epoch 6, gen_loss = 0.7967989139308204, disc_loss = 0.09569696676824858
Trained batch 604 in epoch 6, gen_loss = 0.7964316750853515, disc_loss = 0.09577730918103013
Trained batch 605 in epoch 6, gen_loss = 0.7962685877045389, disc_loss = 0.09573014690955677
Trained batch 606 in epoch 6, gen_loss = 0.796065792269526, disc_loss = 0.09582521748626252
Trained batch 607 in epoch 6, gen_loss = 0.7962158648297191, disc_loss = 0.09580798078892067
Trained batch 608 in epoch 6, gen_loss = 0.7956233357854665, disc_loss = 0.09602359903147459
Trained batch 609 in epoch 6, gen_loss = 0.7954395538959347, disc_loss = 0.09603114486595646
Trained batch 610 in epoch 6, gen_loss = 0.7962040692909259, disc_loss = 0.09625905671091399
Trained batch 611 in epoch 6, gen_loss = 0.7967209222367386, disc_loss = 0.09615336404200278
Trained batch 612 in epoch 6, gen_loss = 0.7964014383260811, disc_loss = 0.09615344134255101
Trained batch 613 in epoch 6, gen_loss = 0.7963756368001044, disc_loss = 0.096129161132809
Trained batch 614 in epoch 6, gen_loss = 0.796211535029295, disc_loss = 0.09608815014968074
Trained batch 615 in epoch 6, gen_loss = 0.7964387060469621, disc_loss = 0.0964054738461681
Trained batch 616 in epoch 6, gen_loss = 0.7961475002417882, disc_loss = 0.09666758228087348
Trained batch 617 in epoch 6, gen_loss = 0.7956094286106166, disc_loss = 0.09690824103418098
Trained batch 618 in epoch 6, gen_loss = 0.7956303057166024, disc_loss = 0.09684494379697207
Trained batch 619 in epoch 6, gen_loss = 0.7959431980406084, disc_loss = 0.09679313269594024
Trained batch 620 in epoch 6, gen_loss = 0.7966454656323757, disc_loss = 0.09674348203456344
Trained batch 621 in epoch 6, gen_loss = 0.7964345041866088, disc_loss = 0.09669443343277913
Trained batch 622 in epoch 6, gen_loss = 0.7960759914610206, disc_loss = 0.09662034763785657
Trained batch 623 in epoch 6, gen_loss = 0.7960434936655637, disc_loss = 0.09651407444228728
Trained batch 624 in epoch 6, gen_loss = 0.7961268440723419, disc_loss = 0.09639848199784756
Trained batch 625 in epoch 6, gen_loss = 0.7961845585046866, disc_loss = 0.09629719798712018
Trained batch 626 in epoch 6, gen_loss = 0.7959650231605512, disc_loss = 0.09626151492115129
Trained batch 627 in epoch 6, gen_loss = 0.796306930862035, disc_loss = 0.09614249039441347
Trained batch 628 in epoch 6, gen_loss = 0.7963936233653173, disc_loss = 0.09602602386465134
Trained batch 629 in epoch 6, gen_loss = 0.796259299204463, disc_loss = 0.09594484048466834
Trained batch 630 in epoch 6, gen_loss = 0.7962312913262145, disc_loss = 0.09588564437018521
Trained batch 631 in epoch 6, gen_loss = 0.7964854402161097, disc_loss = 0.09577064936438316
Trained batch 632 in epoch 6, gen_loss = 0.7961868470031503, disc_loss = 0.09571789953074937
Trained batch 633 in epoch 6, gen_loss = 0.796119868896361, disc_loss = 0.09573985525180677
Trained batch 634 in epoch 6, gen_loss = 0.7962905748153296, disc_loss = 0.09568121433844716
Trained batch 635 in epoch 6, gen_loss = 0.7961981434773349, disc_loss = 0.09558367922480376
Trained batch 636 in epoch 6, gen_loss = 0.796064037683433, disc_loss = 0.09552716027530059
Trained batch 637 in epoch 6, gen_loss = 0.7961237885081283, disc_loss = 0.0954492791821497
Trained batch 638 in epoch 6, gen_loss = 0.7965234007354074, disc_loss = 0.09533771125713425
Trained batch 639 in epoch 6, gen_loss = 0.7967022140976041, disc_loss = 0.09523297925770749
Trained batch 640 in epoch 6, gen_loss = 0.7966811972642651, disc_loss = 0.09512736963023913
Trained batch 641 in epoch 6, gen_loss = 0.7972737305168051, disc_loss = 0.09511913340306635
Trained batch 642 in epoch 6, gen_loss = 0.7972745545451786, disc_loss = 0.09499196338859817
Trained batch 643 in epoch 6, gen_loss = 0.7972628356229444, disc_loss = 0.09488860199875805
Trained batch 644 in epoch 6, gen_loss = 0.7971565407838008, disc_loss = 0.09479995500151964
Trained batch 645 in epoch 6, gen_loss = 0.7971826384403388, disc_loss = 0.09471351614412232
Trained batch 646 in epoch 6, gen_loss = 0.7969950480383736, disc_loss = 0.09469682763876189
Trained batch 647 in epoch 6, gen_loss = 0.7972011289754768, disc_loss = 0.094696930727496
Trained batch 648 in epoch 6, gen_loss = 0.7975543088556621, disc_loss = 0.09460460827707418
Trained batch 649 in epoch 6, gen_loss = 0.7973848502911054, disc_loss = 0.09465998743875668
Trained batch 650 in epoch 6, gen_loss = 0.7969568305392786, disc_loss = 0.09471126683857492
Trained batch 651 in epoch 6, gen_loss = 0.797038053396655, disc_loss = 0.09463366976670601
Trained batch 652 in epoch 6, gen_loss = 0.7976501308849359, disc_loss = 0.09460535304047521
Trained batch 653 in epoch 6, gen_loss = 0.7972676706150037, disc_loss = 0.09471834431308399
Trained batch 654 in epoch 6, gen_loss = 0.796990183519043, disc_loss = 0.09462404771217409
Trained batch 655 in epoch 6, gen_loss = 0.7971617598086596, disc_loss = 0.09450668653632265
Trained batch 656 in epoch 6, gen_loss = 0.7971511913670434, disc_loss = 0.09441245876853688
Trained batch 657 in epoch 6, gen_loss = 0.7970405812049709, disc_loss = 0.09432512624217565
Trained batch 658 in epoch 6, gen_loss = 0.7970041688277255, disc_loss = 0.09430820353001311
Trained batch 659 in epoch 6, gen_loss = 0.797236913758697, disc_loss = 0.09418908407572996
Trained batch 660 in epoch 6, gen_loss = 0.7976708323349571, disc_loss = 0.09408473658816446
Trained batch 661 in epoch 6, gen_loss = 0.7978675793575016, disc_loss = 0.09396698870034917
Trained batch 662 in epoch 6, gen_loss = 0.797372568157104, disc_loss = 0.094300570278281
Trained batch 663 in epoch 6, gen_loss = 0.7975972214915666, disc_loss = 0.09426105619935565
Trained batch 664 in epoch 6, gen_loss = 0.7980214175425078, disc_loss = 0.0941621434979869
Trained batch 665 in epoch 6, gen_loss = 0.7980043033400813, disc_loss = 0.094059056761834
Trained batch 666 in epoch 6, gen_loss = 0.7979537554230468, disc_loss = 0.0941476252773355
Trained batch 667 in epoch 6, gen_loss = 0.7975851754228512, disc_loss = 0.09421857797769373
Trained batch 668 in epoch 6, gen_loss = 0.7978660523980544, disc_loss = 0.0941310278146969
Trained batch 669 in epoch 6, gen_loss = 0.7979146085568328, disc_loss = 0.09403614839955941
Trained batch 670 in epoch 6, gen_loss = 0.7979997183278137, disc_loss = 0.09392723528010391
Trained batch 671 in epoch 6, gen_loss = 0.7980954540627343, disc_loss = 0.09381522933143147
Trained batch 672 in epoch 6, gen_loss = 0.798022121146742, disc_loss = 0.0937036567548896
Trained batch 673 in epoch 6, gen_loss = 0.7980668062802946, disc_loss = 0.09360118285761124
Trained batch 674 in epoch 6, gen_loss = 0.7984214965502421, disc_loss = 0.09350155362100512
Trained batch 675 in epoch 6, gen_loss = 0.7983157277636274, disc_loss = 0.09346938853774815
Trained batch 676 in epoch 6, gen_loss = 0.7983434377251911, disc_loss = 0.09352890519560088
Trained batch 677 in epoch 6, gen_loss = 0.7985179878793284, disc_loss = 0.09341064760197712
Trained batch 678 in epoch 6, gen_loss = 0.7983096567625853, disc_loss = 0.09338814106705394
Trained batch 679 in epoch 6, gen_loss = 0.7985573111211552, disc_loss = 0.0932633044102284
Trained batch 680 in epoch 6, gen_loss = 0.7986644355911166, disc_loss = 0.09316432179141894
Trained batch 681 in epoch 6, gen_loss = 0.7988561962531808, disc_loss = 0.09308919004271152
Trained batch 682 in epoch 6, gen_loss = 0.798564877464691, disc_loss = 0.09310075619542973
Trained batch 683 in epoch 6, gen_loss = 0.7984624084150582, disc_loss = 0.09309656644234575
Trained batch 684 in epoch 6, gen_loss = 0.7987758169209, disc_loss = 0.0930569984467469
Trained batch 685 in epoch 6, gen_loss = 0.7986133273245641, disc_loss = 0.09301712959814741
Trained batch 686 in epoch 6, gen_loss = 0.7989963673955315, disc_loss = 0.09299126926408281
Trained batch 687 in epoch 6, gen_loss = 0.7987816538228545, disc_loss = 0.09300032603083351
Trained batch 688 in epoch 6, gen_loss = 0.7989823503314324, disc_loss = 0.09290578203202808
Trained batch 689 in epoch 6, gen_loss = 0.7991533183533213, disc_loss = 0.09285137063108277
Trained batch 690 in epoch 6, gen_loss = 0.7996586912275223, disc_loss = 0.0927451137553054
Trained batch 691 in epoch 6, gen_loss = 0.7992640856028981, disc_loss = 0.09281143358628659
Trained batch 692 in epoch 6, gen_loss = 0.799107040849771, disc_loss = 0.0928684968654534
Trained batch 693 in epoch 6, gen_loss = 0.7991381392355268, disc_loss = 0.09283943743624802
Trained batch 694 in epoch 6, gen_loss = 0.7991837542691677, disc_loss = 0.09278015415418706
Trained batch 695 in epoch 6, gen_loss = 0.7991717480893793, disc_loss = 0.09269519827740759
Trained batch 696 in epoch 6, gen_loss = 0.7989758804675667, disc_loss = 0.09272415696414806
Trained batch 697 in epoch 6, gen_loss = 0.7989756669048593, disc_loss = 0.09262178986490754
Trained batch 698 in epoch 6, gen_loss = 0.7990226546923319, disc_loss = 0.09260954494549438
Trained batch 699 in epoch 6, gen_loss = 0.7989476361445018, disc_loss = 0.09255414246847588
Trained batch 700 in epoch 6, gen_loss = 0.7991414144103776, disc_loss = 0.09246212088990526
Trained batch 701 in epoch 6, gen_loss = 0.799491874427877, disc_loss = 0.09235851208353017
Trained batch 702 in epoch 6, gen_loss = 0.7997215644563753, disc_loss = 0.09226045153033555
Trained batch 703 in epoch 6, gen_loss = 0.799485504288565, disc_loss = 0.09224266122460408
Trained batch 704 in epoch 6, gen_loss = 0.8001190936311763, disc_loss = 0.09235131702128242
Trained batch 705 in epoch 6, gen_loss = 0.8003452095195187, disc_loss = 0.09224058855219451
Trained batch 706 in epoch 6, gen_loss = 0.7999974532208315, disc_loss = 0.09240820020426703
Trained batch 707 in epoch 6, gen_loss = 0.8003162116149051, disc_loss = 0.09237157130129846
Trained batch 708 in epoch 6, gen_loss = 0.800509465598253, disc_loss = 0.09235295030972769
Trained batch 709 in epoch 6, gen_loss = 0.8005925732599177, disc_loss = 0.09239735640847767
Trained batch 710 in epoch 6, gen_loss = 0.8006265815635606, disc_loss = 0.09230604952754015
Trained batch 711 in epoch 6, gen_loss = 0.8001806728458136, disc_loss = 0.09257739435441875
Trained batch 712 in epoch 6, gen_loss = 0.80031460339692, disc_loss = 0.09265818308417124
Trained batch 713 in epoch 6, gen_loss = 0.800548876617469, disc_loss = 0.09261202337924673
Trained batch 714 in epoch 6, gen_loss = 0.8010133260613554, disc_loss = 0.09262151667600745
Trained batch 715 in epoch 6, gen_loss = 0.8005298550901466, disc_loss = 0.09273077488757211
Trained batch 716 in epoch 6, gen_loss = 0.8005315778644514, disc_loss = 0.09270603551089016
Trained batch 717 in epoch 6, gen_loss = 0.8003260720739126, disc_loss = 0.09267564493031721
Trained batch 718 in epoch 6, gen_loss = 0.8003142859905916, disc_loss = 0.09261464357106676
Trained batch 719 in epoch 6, gen_loss = 0.8009619386659728, disc_loss = 0.09292907277639541
Trained batch 720 in epoch 6, gen_loss = 0.8006135769260739, disc_loss = 0.09297327269979555
Trained batch 721 in epoch 6, gen_loss = 0.8003467387439802, disc_loss = 0.09300558961969169
Trained batch 722 in epoch 6, gen_loss = 0.8005885412584202, disc_loss = 0.09315494679295835
Trained batch 723 in epoch 6, gen_loss = 0.8003736320286166, disc_loss = 0.09318666127690459
Trained batch 724 in epoch 6, gen_loss = 0.7999363421571666, disc_loss = 0.0932842554974145
Trained batch 725 in epoch 6, gen_loss = 0.799624956590085, disc_loss = 0.09331087999497399
Trained batch 726 in epoch 6, gen_loss = 0.7997273109146129, disc_loss = 0.09349204224253783
Trained batch 727 in epoch 6, gen_loss = 0.7994883914406483, disc_loss = 0.093471356693164
Trained batch 728 in epoch 6, gen_loss = 0.7995561515843427, disc_loss = 0.0934222742189514
Trained batch 729 in epoch 6, gen_loss = 0.7993386640124125, disc_loss = 0.09345830158930118
Trained batch 730 in epoch 6, gen_loss = 0.7991040887160764, disc_loss = 0.09344154617222976
Trained batch 731 in epoch 6, gen_loss = 0.7991149791114317, disc_loss = 0.09358658764226352
Trained batch 732 in epoch 6, gen_loss = 0.7990177338803124, disc_loss = 0.0935417513730256
Trained batch 733 in epoch 6, gen_loss = 0.7988126212147341, disc_loss = 0.09349285797989985
Trained batch 734 in epoch 6, gen_loss = 0.7991890319350625, disc_loss = 0.09345957274947847
Trained batch 735 in epoch 6, gen_loss = 0.7989809546295715, disc_loss = 0.09350960524550275
Trained batch 736 in epoch 6, gen_loss = 0.7986887885886907, disc_loss = 0.09351856922642347
Trained batch 737 in epoch 6, gen_loss = 0.7987311496159571, disc_loss = 0.09355320156549374
Trained batch 738 in epoch 6, gen_loss = 0.7983271421534444, disc_loss = 0.093678626633868
Trained batch 739 in epoch 6, gen_loss = 0.7983944044725315, disc_loss = 0.09371030786754311
Trained batch 740 in epoch 6, gen_loss = 0.7982838236690372, disc_loss = 0.09372469252943189
Trained batch 741 in epoch 6, gen_loss = 0.7981829691447337, disc_loss = 0.09370374232731418
Trained batch 742 in epoch 6, gen_loss = 0.7984231249962007, disc_loss = 0.09363591630377809
Trained batch 743 in epoch 6, gen_loss = 0.7984449621490253, disc_loss = 0.09356252894166016
Trained batch 744 in epoch 6, gen_loss = 0.7980714809974568, disc_loss = 0.09370249426804933
Trained batch 745 in epoch 6, gen_loss = 0.7982317379428618, disc_loss = 0.09368839987800844
Trained batch 746 in epoch 6, gen_loss = 0.7981945623355697, disc_loss = 0.09368461854207308
Trained batch 747 in epoch 6, gen_loss = 0.7980645387408568, disc_loss = 0.09368325669298516
Trained batch 748 in epoch 6, gen_loss = 0.7982568171855127, disc_loss = 0.09363835420365009
Trained batch 749 in epoch 6, gen_loss = 0.7982165846029917, disc_loss = 0.09356962138414383
Trained batch 750 in epoch 6, gen_loss = 0.7979697988290444, disc_loss = 0.09356359615624348
Trained batch 751 in epoch 6, gen_loss = 0.7979096446899657, disc_loss = 0.09363189945988198
Trained batch 752 in epoch 6, gen_loss = 0.7980544300351643, disc_loss = 0.09361097346224474
Trained batch 753 in epoch 6, gen_loss = 0.7981136734510923, disc_loss = 0.09353292940940401
Trained batch 754 in epoch 6, gen_loss = 0.7978451205405178, disc_loss = 0.09364045398519528
Trained batch 755 in epoch 6, gen_loss = 0.7981370107995139, disc_loss = 0.09360114010987143
Trained batch 756 in epoch 6, gen_loss = 0.798054247189072, disc_loss = 0.0936234846041886
Trained batch 757 in epoch 6, gen_loss = 0.7979695673511022, disc_loss = 0.09361609516758718
Trained batch 758 in epoch 6, gen_loss = 0.7982151273525122, disc_loss = 0.09366949645701761
Trained batch 759 in epoch 6, gen_loss = 0.7985168567613552, disc_loss = 0.09357914940552099
Trained batch 760 in epoch 6, gen_loss = 0.798666577458225, disc_loss = 0.09348233123205886
Trained batch 761 in epoch 6, gen_loss = 0.7987352971016891, disc_loss = 0.09339851387617547
Trained batch 762 in epoch 6, gen_loss = 0.7989942201780617, disc_loss = 0.09330001189025561
Trained batch 763 in epoch 6, gen_loss = 0.7990631639801394, disc_loss = 0.09321652190194157
Trained batch 764 in epoch 6, gen_loss = 0.7994456198480394, disc_loss = 0.09313393794487115
Trained batch 765 in epoch 6, gen_loss = 0.7996780270851623, disc_loss = 0.09303884605777404
Trained batch 766 in epoch 6, gen_loss = 0.7999077537224533, disc_loss = 0.09295825826094001
Trained batch 767 in epoch 6, gen_loss = 0.7999445355962962, disc_loss = 0.09288901812154411
Trained batch 768 in epoch 6, gen_loss = 0.8002972324585884, disc_loss = 0.09285952092447501
Trained batch 769 in epoch 6, gen_loss = 0.8004775826807146, disc_loss = 0.09277683468656493
Trained batch 770 in epoch 6, gen_loss = 0.8005479491483686, disc_loss = 0.09273721166824785
Trained batch 771 in epoch 6, gen_loss = 0.8004387713621317, disc_loss = 0.09265579006012162
Trained batch 772 in epoch 6, gen_loss = 0.8010908034455422, disc_loss = 0.0926686568212193
Trained batch 773 in epoch 6, gen_loss = 0.8013241843197697, disc_loss = 0.09262190756053502
Trained batch 774 in epoch 6, gen_loss = 0.8012131116467137, disc_loss = 0.09266304328316642
Trained batch 775 in epoch 6, gen_loss = 0.8010097824267506, disc_loss = 0.09265843871740874
Trained batch 776 in epoch 6, gen_loss = 0.8009808809907587, disc_loss = 0.09258994247951333
Trained batch 777 in epoch 6, gen_loss = 0.8014116885576272, disc_loss = 0.09265018090519546
Trained batch 778 in epoch 6, gen_loss = 0.8011928364462356, disc_loss = 0.09264391065552467
Trained batch 779 in epoch 6, gen_loss = 0.8010508502905186, disc_loss = 0.09261366531778223
Trained batch 780 in epoch 6, gen_loss = 0.8011068152251836, disc_loss = 0.09254322078665683
Trained batch 781 in epoch 6, gen_loss = 0.8015548618095915, disc_loss = 0.09263812273007144
Trained batch 782 in epoch 6, gen_loss = 0.8013218869651414, disc_loss = 0.09277489690745243
Trained batch 783 in epoch 6, gen_loss = 0.801354896657321, disc_loss = 0.09270203185068178
Trained batch 784 in epoch 6, gen_loss = 0.8017539801870941, disc_loss = 0.0929409225963673
Trained batch 785 in epoch 6, gen_loss = 0.8013602884216163, disc_loss = 0.09309296927275018
Trained batch 786 in epoch 6, gen_loss = 0.8017784839512584, disc_loss = 0.09302815381470675
Trained batch 787 in epoch 6, gen_loss = 0.8017442871622628, disc_loss = 0.09296539820361939
Trained batch 788 in epoch 6, gen_loss = 0.8019027445555036, disc_loss = 0.09288288205059385
Trained batch 789 in epoch 6, gen_loss = 0.8022326733492597, disc_loss = 0.09278810785588207
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.7388364672660828, disc_loss = 0.059285737574100494
Trained batch 1 in epoch 7, gen_loss = 0.7974800765514374, disc_loss = 0.07576272264122963
Trained batch 2 in epoch 7, gen_loss = 0.8041964968045553, disc_loss = 0.06744275987148285
Trained batch 3 in epoch 7, gen_loss = 0.7993694692850113, disc_loss = 0.06406641192734241
Trained batch 4 in epoch 7, gen_loss = 0.8019123435020447, disc_loss = 0.05703550651669502
Trained batch 5 in epoch 7, gen_loss = 0.8057268559932709, disc_loss = 0.06950047674278419
Trained batch 6 in epoch 7, gen_loss = 0.7692031604903085, disc_loss = 0.07522817860756602
Trained batch 7 in epoch 7, gen_loss = 0.7941681072115898, disc_loss = 0.07169508514925838
Trained batch 8 in epoch 7, gen_loss = 0.8088575402895609, disc_loss = 0.06714536704950863
Trained batch 9 in epoch 7, gen_loss = 0.8342030465602874, disc_loss = 0.06547807939350606
Trained batch 10 in epoch 7, gen_loss = 0.817278265953064, disc_loss = 0.06756136803464456
Trained batch 11 in epoch 7, gen_loss = 0.8073316613833109, disc_loss = 0.06699671410024166
Trained batch 12 in epoch 7, gen_loss = 0.821085668527163, disc_loss = 0.06790791623867475
Trained batch 13 in epoch 7, gen_loss = 0.8152742598737989, disc_loss = 0.0659084218953337
Trained batch 14 in epoch 7, gen_loss = 0.8121689518292745, disc_loss = 0.06405078495542209
Trained batch 15 in epoch 7, gen_loss = 0.830882515758276, disc_loss = 0.06324159144423902
Trained batch 16 in epoch 7, gen_loss = 0.8176106775508207, disc_loss = 0.06894670317278188
Trained batch 17 in epoch 7, gen_loss = 0.8306134078237746, disc_loss = 0.0672550064822038
Trained batch 18 in epoch 7, gen_loss = 0.8344552297341196, disc_loss = 0.06557009643629978
Trained batch 19 in epoch 7, gen_loss = 0.8217130869626998, disc_loss = 0.06858703345060349
Trained batch 20 in epoch 7, gen_loss = 0.8358026487486703, disc_loss = 0.06698386548530488
Trained batch 21 in epoch 7, gen_loss = 0.8348647870800712, disc_loss = 0.06591001864184033
Trained batch 22 in epoch 7, gen_loss = 0.8289963577104651, disc_loss = 0.06474662021450374
Trained batch 23 in epoch 7, gen_loss = 0.8222477436065674, disc_loss = 0.06465352388719718
Trained batch 24 in epoch 7, gen_loss = 0.8262541675567627, disc_loss = 0.0639926701784134
Trained batch 25 in epoch 7, gen_loss = 0.8470824590096107, disc_loss = 0.06726207354894051
Trained batch 26 in epoch 7, gen_loss = 0.8401245276133219, disc_loss = 0.06981005050517895
Trained batch 27 in epoch 7, gen_loss = 0.8317812957933971, disc_loss = 0.07193675530808312
Trained batch 28 in epoch 7, gen_loss = 0.8374917445511654, disc_loss = 0.08011099901692621
Trained batch 29 in epoch 7, gen_loss = 0.8315660715103149, disc_loss = 0.08007140283783278
Trained batch 30 in epoch 7, gen_loss = 0.8233975864225819, disc_loss = 0.08252136962067697
Trained batch 31 in epoch 7, gen_loss = 0.8238511644303799, disc_loss = 0.08069105306640267
Trained batch 32 in epoch 7, gen_loss = 0.8195777553500552, disc_loss = 0.08073394406925548
Trained batch 33 in epoch 7, gen_loss = 0.8185251933686873, disc_loss = 0.08113851091440986
Trained batch 34 in epoch 7, gen_loss = 0.8251331516674587, disc_loss = 0.08234839822564806
Trained batch 35 in epoch 7, gen_loss = 0.8249468356370926, disc_loss = 0.08089583046320412
Trained batch 36 in epoch 7, gen_loss = 0.8211625427813143, disc_loss = 0.08134780189878232
Trained batch 37 in epoch 7, gen_loss = 0.8189561116067987, disc_loss = 0.08145742637938574
Trained batch 38 in epoch 7, gen_loss = 0.8133639769676404, disc_loss = 0.08142550681263973
Trained batch 39 in epoch 7, gen_loss = 0.8122635021805763, disc_loss = 0.08036824176087976
Trained batch 40 in epoch 7, gen_loss = 0.820739151501074, disc_loss = 0.08078914417362795
Trained batch 41 in epoch 7, gen_loss = 0.8138407057239896, disc_loss = 0.08241683182617028
Trained batch 42 in epoch 7, gen_loss = 0.813655436038971, disc_loss = 0.08144715402361959
Trained batch 43 in epoch 7, gen_loss = 0.8177333528345282, disc_loss = 0.08142865508456122
Trained batch 44 in epoch 7, gen_loss = 0.8129916932847765, disc_loss = 0.08258988385399182
Trained batch 45 in epoch 7, gen_loss = 0.8135747287584387, disc_loss = 0.08153685190431449
Trained batch 46 in epoch 7, gen_loss = 0.8100697322094694, disc_loss = 0.08222297761351505
Trained batch 47 in epoch 7, gen_loss = 0.8126325656970342, disc_loss = 0.08099737852656592
Trained batch 48 in epoch 7, gen_loss = 0.8172186150842783, disc_loss = 0.08040225517232807
Trained batch 49 in epoch 7, gen_loss = 0.8220094299316406, disc_loss = 0.07964794237166643
Trained batch 50 in epoch 7, gen_loss = 0.8237827946158016, disc_loss = 0.07890011176613032
Trained batch 51 in epoch 7, gen_loss = 0.823203655389639, disc_loss = 0.07890523980873135
Trained batch 52 in epoch 7, gen_loss = 0.8155985508324965, disc_loss = 0.08177750638492827
Trained batch 53 in epoch 7, gen_loss = 0.8133366538418664, disc_loss = 0.08234258779083137
Trained batch 54 in epoch 7, gen_loss = 0.8201439889994535, disc_loss = 0.08604189926250415
Trained batch 55 in epoch 7, gen_loss = 0.8182873183063099, disc_loss = 0.08562981187632042
Trained batch 56 in epoch 7, gen_loss = 0.8156671429935255, disc_loss = 0.0866562225774192
Trained batch 57 in epoch 7, gen_loss = 0.8170326095202873, disc_loss = 0.08658666276083939
Trained batch 58 in epoch 7, gen_loss = 0.8143049923040099, disc_loss = 0.08799977509020748
Trained batch 59 in epoch 7, gen_loss = 0.8161900202433269, disc_loss = 0.08730665057276686
Trained batch 60 in epoch 7, gen_loss = 0.8116263913326576, disc_loss = 0.08958949621950017
Trained batch 61 in epoch 7, gen_loss = 0.8116025328636169, disc_loss = 0.08909165057083292
Trained batch 62 in epoch 7, gen_loss = 0.8119154089973086, disc_loss = 0.08913759594517094
Trained batch 63 in epoch 7, gen_loss = 0.8212333023548126, disc_loss = 0.08994994140812196
Trained batch 64 in epoch 7, gen_loss = 0.8185454111832838, disc_loss = 0.08980356079454606
Trained batch 65 in epoch 7, gen_loss = 0.8151541794791366, disc_loss = 0.09076353312103135
Trained batch 66 in epoch 7, gen_loss = 0.8136440915847892, disc_loss = 0.09089798794419908
Trained batch 67 in epoch 7, gen_loss = 0.8116062187096652, disc_loss = 0.09099483700907406
Trained batch 68 in epoch 7, gen_loss = 0.809851480566937, disc_loss = 0.09150961573249188
Trained batch 69 in epoch 7, gen_loss = 0.8091442823410034, disc_loss = 0.09188883019877332
Trained batch 70 in epoch 7, gen_loss = 0.8113280719434711, disc_loss = 0.092015761121268
Trained batch 71 in epoch 7, gen_loss = 0.807770065135426, disc_loss = 0.09256557564044164
Trained batch 72 in epoch 7, gen_loss = 0.8070334392051174, disc_loss = 0.09171164762994198
Trained batch 73 in epoch 7, gen_loss = 0.8058957683073508, disc_loss = 0.0915179875100384
Trained batch 74 in epoch 7, gen_loss = 0.8071056906382242, disc_loss = 0.09161867760121822
Trained batch 75 in epoch 7, gen_loss = 0.8082719155048069, disc_loss = 0.09230509853774779
Trained batch 76 in epoch 7, gen_loss = 0.8064593192818877, disc_loss = 0.09373964971632927
Trained batch 77 in epoch 7, gen_loss = 0.8035844969443786, disc_loss = 0.09379212350512926
Trained batch 78 in epoch 7, gen_loss = 0.8036326690565182, disc_loss = 0.0933451713593323
Trained batch 79 in epoch 7, gen_loss = 0.8048112511634826, disc_loss = 0.09373791159596294
Trained batch 80 in epoch 7, gen_loss = 0.8019621269202527, disc_loss = 0.0933476344992717
Trained batch 81 in epoch 7, gen_loss = 0.801610075845951, disc_loss = 0.09302298104526793
Trained batch 82 in epoch 7, gen_loss = 0.8054931925003788, disc_loss = 0.09236988230013704
Trained batch 83 in epoch 7, gen_loss = 0.8067093165147872, disc_loss = 0.09184043927650366
Trained batch 84 in epoch 7, gen_loss = 0.805346575905295, disc_loss = 0.09120765190352412
Trained batch 85 in epoch 7, gen_loss = 0.8030867514222167, disc_loss = 0.09131628216439208
Trained batch 86 in epoch 7, gen_loss = 0.8061921438951601, disc_loss = 0.09051986175707016
Trained batch 87 in epoch 7, gen_loss = 0.8071106787432324, disc_loss = 0.09000284072350372
Trained batch 88 in epoch 7, gen_loss = 0.8076205782676011, disc_loss = 0.08988719190774339
Trained batch 89 in epoch 7, gen_loss = 0.8099192321300507, disc_loss = 0.08924999481274022
Trained batch 90 in epoch 7, gen_loss = 0.8070573872262305, disc_loss = 0.09027568598861223
Trained batch 91 in epoch 7, gen_loss = 0.8083191598239152, disc_loss = 0.08952060767004023
Trained batch 92 in epoch 7, gen_loss = 0.8116682851186363, disc_loss = 0.08974269981826505
Trained batch 93 in epoch 7, gen_loss = 0.8095060403042651, disc_loss = 0.09040472406814708
Trained batch 94 in epoch 7, gen_loss = 0.806902435578798, disc_loss = 0.09037272863482174
Trained batch 95 in epoch 7, gen_loss = 0.8074608960499366, disc_loss = 0.08989042268755536
Trained batch 96 in epoch 7, gen_loss = 0.8089765519210973, disc_loss = 0.0896027044383521
Trained batch 97 in epoch 7, gen_loss = 0.8070292533660421, disc_loss = 0.08983398464565374
Trained batch 98 in epoch 7, gen_loss = 0.8059419742738357, disc_loss = 0.08924260035608754
Trained batch 99 in epoch 7, gen_loss = 0.8052103179693222, disc_loss = 0.0894736759364605
Trained batch 100 in epoch 7, gen_loss = 0.8054270413842531, disc_loss = 0.08917033329310983
Trained batch 101 in epoch 7, gen_loss = 0.8032786267645219, disc_loss = 0.08934322346513178
Trained batch 102 in epoch 7, gen_loss = 0.8026327675986058, disc_loss = 0.08924060709123473
Trained batch 103 in epoch 7, gen_loss = 0.8011968668836814, disc_loss = 0.08885250476977
Trained batch 104 in epoch 7, gen_loss = 0.8032120358376276, disc_loss = 0.08946546181326821
Trained batch 105 in epoch 7, gen_loss = 0.8015430288494758, disc_loss = 0.08974644562826967
Trained batch 106 in epoch 7, gen_loss = 0.8019635944722969, disc_loss = 0.08921136017714705
Trained batch 107 in epoch 7, gen_loss = 0.8013857040140364, disc_loss = 0.08885164286389395
Trained batch 108 in epoch 7, gen_loss = 0.8027602505246434, disc_loss = 0.0893683347748507
Trained batch 109 in epoch 7, gen_loss = 0.8027560727162795, disc_loss = 0.08900805335830558
Trained batch 110 in epoch 7, gen_loss = 0.8008624186386933, disc_loss = 0.08934787778301281
Trained batch 111 in epoch 7, gen_loss = 0.8000497370958328, disc_loss = 0.08964546287565359
Trained batch 112 in epoch 7, gen_loss = 0.8023567779929237, disc_loss = 0.0896963819663609
Trained batch 113 in epoch 7, gen_loss = 0.7997690988214392, disc_loss = 0.0908071136984386
Trained batch 114 in epoch 7, gen_loss = 0.800368869304657, disc_loss = 0.09079199494874995
Trained batch 115 in epoch 7, gen_loss = 0.8021865163383812, disc_loss = 0.09023962396293364
Trained batch 116 in epoch 7, gen_loss = 0.8036769720224234, disc_loss = 0.08990365860617569
Trained batch 117 in epoch 7, gen_loss = 0.8046701353485302, disc_loss = 0.08936759146025121
Trained batch 118 in epoch 7, gen_loss = 0.8030584644870598, disc_loss = 0.08948762419030946
Trained batch 119 in epoch 7, gen_loss = 0.8034291674693426, disc_loss = 0.08901828448288143
Trained batch 120 in epoch 7, gen_loss = 0.8043980923565951, disc_loss = 0.08842140930312231
Trained batch 121 in epoch 7, gen_loss = 0.80587893626729, disc_loss = 0.08778259416919995
Trained batch 122 in epoch 7, gen_loss = 0.8062074281335846, disc_loss = 0.08723378986332232
Trained batch 123 in epoch 7, gen_loss = 0.805164764004369, disc_loss = 0.08689720254962242
Trained batch 124 in epoch 7, gen_loss = 0.8045291113853454, disc_loss = 0.08647035556286574
Trained batch 125 in epoch 7, gen_loss = 0.8063491824127379, disc_loss = 0.08610204343373577
Trained batch 126 in epoch 7, gen_loss = 0.8066456294435216, disc_loss = 0.08562808202975612
Trained batch 127 in epoch 7, gen_loss = 0.8073114245198667, disc_loss = 0.08524274483352201
Trained batch 128 in epoch 7, gen_loss = 0.8068452237188354, disc_loss = 0.08487403174039236
Trained batch 129 in epoch 7, gen_loss = 0.807533289377506, disc_loss = 0.08469490140246658
Trained batch 130 in epoch 7, gen_loss = 0.8062874738496678, disc_loss = 0.08457486582422302
Trained batch 131 in epoch 7, gen_loss = 0.8081521495725169, disc_loss = 0.08509920797818764
Trained batch 132 in epoch 7, gen_loss = 0.8074194771006591, disc_loss = 0.08465854619818747
Trained batch 133 in epoch 7, gen_loss = 0.8070073679311952, disc_loss = 0.08441480177579753
Trained batch 134 in epoch 7, gen_loss = 0.807838871302428, disc_loss = 0.08441570975852233
Trained batch 135 in epoch 7, gen_loss = 0.8062622095732128, disc_loss = 0.08455204876714989
Trained batch 136 in epoch 7, gen_loss = 0.8065850886985333, disc_loss = 0.0843306874829161
Trained batch 137 in epoch 7, gen_loss = 0.8057667224303536, disc_loss = 0.0840706969746321
Trained batch 138 in epoch 7, gen_loss = 0.8072522158245389, disc_loss = 0.08374842859992235
Trained batch 139 in epoch 7, gen_loss = 0.8066395470074245, disc_loss = 0.08350188605088209
Trained batch 140 in epoch 7, gen_loss = 0.8069888742257517, disc_loss = 0.08310958416141728
Trained batch 141 in epoch 7, gen_loss = 0.8086974201068072, disc_loss = 0.08279347160673688
Trained batch 142 in epoch 7, gen_loss = 0.8077631042553828, disc_loss = 0.08302438533311332
Trained batch 143 in epoch 7, gen_loss = 0.8098692666325304, disc_loss = 0.08274445235858569
Trained batch 144 in epoch 7, gen_loss = 0.8103040892502357, disc_loss = 0.08253912959761661
Trained batch 145 in epoch 7, gen_loss = 0.8090885902104312, disc_loss = 0.08282590032976171
Trained batch 146 in epoch 7, gen_loss = 0.8084973968616148, disc_loss = 0.08266058805569702
Trained batch 147 in epoch 7, gen_loss = 0.8069494108895998, disc_loss = 0.08278063838873562
Trained batch 148 in epoch 7, gen_loss = 0.8064059291109943, disc_loss = 0.08271728164122609
Trained batch 149 in epoch 7, gen_loss = 0.8067777506510416, disc_loss = 0.0824606589290003
Trained batch 150 in epoch 7, gen_loss = 0.8083768348820162, disc_loss = 0.08200695128827695
Trained batch 151 in epoch 7, gen_loss = 0.8082501782398475, disc_loss = 0.08173309016580645
Trained batch 152 in epoch 7, gen_loss = 0.8087961066002939, disc_loss = 0.08136984787491802
Trained batch 153 in epoch 7, gen_loss = 0.8097651101552047, disc_loss = 0.08109231154107815
Trained batch 154 in epoch 7, gen_loss = 0.8096697065138048, disc_loss = 0.08068990232723375
Trained batch 155 in epoch 7, gen_loss = 0.8097905665636063, disc_loss = 0.08049108781732428
Trained batch 156 in epoch 7, gen_loss = 0.8093880031518875, disc_loss = 0.08032888293883224
Trained batch 157 in epoch 7, gen_loss = 0.8095711401746243, disc_loss = 0.08049576626972685
Trained batch 158 in epoch 7, gen_loss = 0.8117141266288997, disc_loss = 0.08056513778865337
Trained batch 159 in epoch 7, gen_loss = 0.8107546824961901, disc_loss = 0.0805835364968516
Trained batch 160 in epoch 7, gen_loss = 0.8104708031837985, disc_loss = 0.08044922457117101
Trained batch 161 in epoch 7, gen_loss = 0.8111006264333371, disc_loss = 0.0801116914867803
Trained batch 162 in epoch 7, gen_loss = 0.8138803265577444, disc_loss = 0.07991330463873463
Trained batch 163 in epoch 7, gen_loss = 0.8144403187240042, disc_loss = 0.07960371413018281
Trained batch 164 in epoch 7, gen_loss = 0.8125349153171886, disc_loss = 0.08024246398020875
Trained batch 165 in epoch 7, gen_loss = 0.8120750702289213, disc_loss = 0.08019933296389968
Trained batch 166 in epoch 7, gen_loss = 0.8151875166835899, disc_loss = 0.08261689877215617
Trained batch 167 in epoch 7, gen_loss = 0.816512375715233, disc_loss = 0.08223624096163326
Trained batch 168 in epoch 7, gen_loss = 0.8165149008028606, disc_loss = 0.08196290956049629
Trained batch 169 in epoch 7, gen_loss = 0.8157570891520556, disc_loss = 0.08222425307201989
Trained batch 170 in epoch 7, gen_loss = 0.815750975706424, disc_loss = 0.08217052874640066
Trained batch 171 in epoch 7, gen_loss = 0.815705613687981, disc_loss = 0.08225410010362434
Trained batch 172 in epoch 7, gen_loss = 0.8150474939043122, disc_loss = 0.08207430596856367
Trained batch 173 in epoch 7, gen_loss = 0.8146117819451738, disc_loss = 0.0819372486044792
Trained batch 174 in epoch 7, gen_loss = 0.8127499086516244, disc_loss = 0.08228218522455011
Trained batch 175 in epoch 7, gen_loss = 0.8132366761565208, disc_loss = 0.08218063076492399
Trained batch 176 in epoch 7, gen_loss = 0.8125247349173336, disc_loss = 0.08204531510713073
Trained batch 177 in epoch 7, gen_loss = 0.8122933754760228, disc_loss = 0.08198281039557095
Trained batch 178 in epoch 7, gen_loss = 0.81175853553431, disc_loss = 0.08181706461118919
Trained batch 179 in epoch 7, gen_loss = 0.8134565088484023, disc_loss = 0.08167919573477572
Trained batch 180 in epoch 7, gen_loss = 0.8131484751543288, disc_loss = 0.08147778830269753
Trained batch 181 in epoch 7, gen_loss = 0.8115278033764808, disc_loss = 0.08171691167280896
Trained batch 182 in epoch 7, gen_loss = 0.8111729025840759, disc_loss = 0.0823301259591117
Trained batch 183 in epoch 7, gen_loss = 0.8110685695124709, disc_loss = 0.0821381546050796
Trained batch 184 in epoch 7, gen_loss = 0.8108444188092206, disc_loss = 0.08189032449311501
Trained batch 185 in epoch 7, gen_loss = 0.8113617092691442, disc_loss = 0.0816980757079618
Trained batch 186 in epoch 7, gen_loss = 0.8111143714603893, disc_loss = 0.08149638518013737
Trained batch 187 in epoch 7, gen_loss = 0.81044129329793, disc_loss = 0.08146113443604493
Trained batch 188 in epoch 7, gen_loss = 0.8108868352950566, disc_loss = 0.08120359993840336
Trained batch 189 in epoch 7, gen_loss = 0.81161705820184, disc_loss = 0.08206253946807823
Trained batch 190 in epoch 7, gen_loss = 0.8108834346551546, disc_loss = 0.08256070995557059
Trained batch 191 in epoch 7, gen_loss = 0.8105222911884388, disc_loss = 0.08246141059983832
Trained batch 192 in epoch 7, gen_loss = 0.8109358533676424, disc_loss = 0.08320629991436561
Trained batch 193 in epoch 7, gen_loss = 0.8101373705052838, disc_loss = 0.08333959500545386
Trained batch 194 in epoch 7, gen_loss = 0.8091212737254607, disc_loss = 0.08368607026835283
Trained batch 195 in epoch 7, gen_loss = 0.810562075400839, disc_loss = 0.08414680496504416
Trained batch 196 in epoch 7, gen_loss = 0.8096098503485549, disc_loss = 0.0841125291559448
Trained batch 197 in epoch 7, gen_loss = 0.8082262473274963, disc_loss = 0.08422855439247807
Trained batch 198 in epoch 7, gen_loss = 0.8082578688410659, disc_loss = 0.08510159556028532
Trained batch 199 in epoch 7, gen_loss = 0.8087900361418724, disc_loss = 0.0848356190789491
Trained batch 200 in epoch 7, gen_loss = 0.8080267621510064, disc_loss = 0.08490539647045717
Trained batch 201 in epoch 7, gen_loss = 0.8080809907157822, disc_loss = 0.08496780580112545
Trained batch 202 in epoch 7, gen_loss = 0.8071823854164537, disc_loss = 0.08506671296148172
Trained batch 203 in epoch 7, gen_loss = 0.8068607519654667, disc_loss = 0.08533490665585679
Trained batch 204 in epoch 7, gen_loss = 0.8058397461728352, disc_loss = 0.0855516796886194
Trained batch 205 in epoch 7, gen_loss = 0.8062910741394006, disc_loss = 0.0858390649274281
Trained batch 206 in epoch 7, gen_loss = 0.8050827366718347, disc_loss = 0.08591070027059115
Trained batch 207 in epoch 7, gen_loss = 0.8049822137332879, disc_loss = 0.08574375040076959
Trained batch 208 in epoch 7, gen_loss = 0.8052850625161349, disc_loss = 0.08549614403058182
Trained batch 209 in epoch 7, gen_loss = 0.8052273636772519, disc_loss = 0.08573838631134657
Trained batch 210 in epoch 7, gen_loss = 0.8049630963406856, disc_loss = 0.085782144404065
Trained batch 211 in epoch 7, gen_loss = 0.8041991391834223, disc_loss = 0.08571104085916337
Trained batch 212 in epoch 7, gen_loss = 0.8038694575918672, disc_loss = 0.0859099097567405
Trained batch 213 in epoch 7, gen_loss = 0.8047218542789745, disc_loss = 0.0855927850232921
Trained batch 214 in epoch 7, gen_loss = 0.8037528379018917, disc_loss = 0.08547937841436197
Trained batch 215 in epoch 7, gen_loss = 0.8044473917947875, disc_loss = 0.08527636716866659
Trained batch 216 in epoch 7, gen_loss = 0.8038751189060475, disc_loss = 0.08511717082752336
Trained batch 217 in epoch 7, gen_loss = 0.8040833916139165, disc_loss = 0.08483755584259373
Trained batch 218 in epoch 7, gen_loss = 0.8034892250958099, disc_loss = 0.0847737330126844
Trained batch 219 in epoch 7, gen_loss = 0.8044307443228635, disc_loss = 0.08550293603911996
Trained batch 220 in epoch 7, gen_loss = 0.804127541602467, disc_loss = 0.08551192879508254
Trained batch 221 in epoch 7, gen_loss = 0.8030579825779339, disc_loss = 0.08587862714823033
Trained batch 222 in epoch 7, gen_loss = 0.8020278966480306, disc_loss = 0.08632390918586019
Trained batch 223 in epoch 7, gen_loss = 0.802663182307567, disc_loss = 0.08650042558188684
Trained batch 224 in epoch 7, gen_loss = 0.8032046951187981, disc_loss = 0.08620414396954908
Trained batch 225 in epoch 7, gen_loss = 0.802187151877226, disc_loss = 0.08629938209248064
Trained batch 226 in epoch 7, gen_loss = 0.802394782656615, disc_loss = 0.08658921003899647
Trained batch 227 in epoch 7, gen_loss = 0.8009799164638185, disc_loss = 0.08692400883719847
Trained batch 228 in epoch 7, gen_loss = 0.8030729543694242, disc_loss = 0.08684225576445785
Trained batch 229 in epoch 7, gen_loss = 0.8030803986217665, disc_loss = 0.08664995065039914
Trained batch 230 in epoch 7, gen_loss = 0.8034079681227217, disc_loss = 0.08635955591770736
Trained batch 231 in epoch 7, gen_loss = 0.8026406263996815, disc_loss = 0.08634025896578257
Trained batch 232 in epoch 7, gen_loss = 0.8026204487796506, disc_loss = 0.08628268774135174
Trained batch 233 in epoch 7, gen_loss = 0.8021340199515351, disc_loss = 0.0861920627216116
Trained batch 234 in epoch 7, gen_loss = 0.8019747779724445, disc_loss = 0.08596916695700046
Trained batch 235 in epoch 7, gen_loss = 0.8023848692744465, disc_loss = 0.08631658367023377
Trained batch 236 in epoch 7, gen_loss = 0.8028999373379639, disc_loss = 0.08602001913331983
Trained batch 237 in epoch 7, gen_loss = 0.8029872652362374, disc_loss = 0.08577855774240584
Trained batch 238 in epoch 7, gen_loss = 0.8024130643162268, disc_loss = 0.08565640945969516
Trained batch 239 in epoch 7, gen_loss = 0.8024092343946297, disc_loss = 0.08567425531800836
Trained batch 240 in epoch 7, gen_loss = 0.8027987141332191, disc_loss = 0.08576380737373196
Trained batch 241 in epoch 7, gen_loss = 0.8026943039302984, disc_loss = 0.08556541550350337
Trained batch 242 in epoch 7, gen_loss = 0.8020347670763118, disc_loss = 0.08569985354480184
Trained batch 243 in epoch 7, gen_loss = 0.802593008416598, disc_loss = 0.08552393713416379
Trained batch 244 in epoch 7, gen_loss = 0.8030258692040735, disc_loss = 0.08525976090863042
Trained batch 245 in epoch 7, gen_loss = 0.8041350233361004, disc_loss = 0.08527498885353164
Trained batch 246 in epoch 7, gen_loss = 0.8034908706360018, disc_loss = 0.08545610537141682
Trained batch 247 in epoch 7, gen_loss = 0.804031523004655, disc_loss = 0.08528504718185193
Trained batch 248 in epoch 7, gen_loss = 0.804882325321795, disc_loss = 0.08511070702898216
Trained batch 249 in epoch 7, gen_loss = 0.8044138522148132, disc_loss = 0.08504532956331969
Trained batch 250 in epoch 7, gen_loss = 0.8039337232768298, disc_loss = 0.08498426935676322
Trained batch 251 in epoch 7, gen_loss = 0.8041701347581924, disc_loss = 0.08475044422176858
Trained batch 252 in epoch 7, gen_loss = 0.8043913709316329, disc_loss = 0.08459741013352814
Trained batch 253 in epoch 7, gen_loss = 0.8043191409486485, disc_loss = 0.08449035078492456
Trained batch 254 in epoch 7, gen_loss = 0.8041400713079115, disc_loss = 0.0844487356715927
Trained batch 255 in epoch 7, gen_loss = 0.8041435517370701, disc_loss = 0.08436906092538266
Trained batch 256 in epoch 7, gen_loss = 0.8043947581651146, disc_loss = 0.0842900661686399
Trained batch 257 in epoch 7, gen_loss = 0.8035996006440747, disc_loss = 0.08428607811039501
Trained batch 258 in epoch 7, gen_loss = 0.8043042743528211, disc_loss = 0.08411503004262576
Trained batch 259 in epoch 7, gen_loss = 0.8044847323344304, disc_loss = 0.08413638156623794
Trained batch 260 in epoch 7, gen_loss = 0.8033601100417389, disc_loss = 0.08425004028811536
Trained batch 261 in epoch 7, gen_loss = 0.8038636006926763, disc_loss = 0.08419581575902137
Trained batch 262 in epoch 7, gen_loss = 0.8038640325966897, disc_loss = 0.08399956312894595
Trained batch 263 in epoch 7, gen_loss = 0.8038989580941923, disc_loss = 0.08384441163136878
Trained batch 264 in epoch 7, gen_loss = 0.8040158564189694, disc_loss = 0.08373263016483694
Trained batch 265 in epoch 7, gen_loss = 0.8031004185515239, disc_loss = 0.08409213705366492
Trained batch 266 in epoch 7, gen_loss = 0.804047886575206, disc_loss = 0.08415917677574614
Trained batch 267 in epoch 7, gen_loss = 0.8039394450276646, disc_loss = 0.08402525132466386
Trained batch 268 in epoch 7, gen_loss = 0.802932311389526, disc_loss = 0.08438795881837495
Trained batch 269 in epoch 7, gen_loss = 0.8029705241874412, disc_loss = 0.0845393220514611
Trained batch 270 in epoch 7, gen_loss = 0.8032528456726638, disc_loss = 0.08480244098966631
Trained batch 271 in epoch 7, gen_loss = 0.8027289610575227, disc_loss = 0.08474220414235092
Trained batch 272 in epoch 7, gen_loss = 0.8028233730312668, disc_loss = 0.08471982524262898
Trained batch 273 in epoch 7, gen_loss = 0.80324297773577, disc_loss = 0.08447149910549395
Trained batch 274 in epoch 7, gen_loss = 0.8033723330497742, disc_loss = 0.08433233632960102
Trained batch 275 in epoch 7, gen_loss = 0.8033505444941313, disc_loss = 0.0842083146782133
Trained batch 276 in epoch 7, gen_loss = 0.8033845682867167, disc_loss = 0.0840268824921941
Trained batch 277 in epoch 7, gen_loss = 0.8027439436895384, disc_loss = 0.08401757145715917
Trained batch 278 in epoch 7, gen_loss = 0.8030963221758497, disc_loss = 0.08392740908249091
Trained batch 279 in epoch 7, gen_loss = 0.8039143860340119, disc_loss = 0.08384402859290796
Trained batch 280 in epoch 7, gen_loss = 0.8047366108334362, disc_loss = 0.08362643136328013
Trained batch 281 in epoch 7, gen_loss = 0.8042627228490005, disc_loss = 0.08357863193576007
Trained batch 282 in epoch 7, gen_loss = 0.8054252995619083, disc_loss = 0.08364523227849824
Trained batch 283 in epoch 7, gen_loss = 0.8054893908786102, disc_loss = 0.0834325789605123
Trained batch 284 in epoch 7, gen_loss = 0.8046320796012878, disc_loss = 0.08358068115224963
Trained batch 285 in epoch 7, gen_loss = 0.8042446426995151, disc_loss = 0.08363263027000052
Trained batch 286 in epoch 7, gen_loss = 0.803707542527428, disc_loss = 0.08359010002936013
Trained batch 287 in epoch 7, gen_loss = 0.8035266451123688, disc_loss = 0.08381005225884211
Trained batch 288 in epoch 7, gen_loss = 0.8028725631096784, disc_loss = 0.0839330917965479
Trained batch 289 in epoch 7, gen_loss = 0.8029402977433698, disc_loss = 0.0839604196813086
Trained batch 290 in epoch 7, gen_loss = 0.8029269477755753, disc_loss = 0.0837947479369202
Trained batch 291 in epoch 7, gen_loss = 0.8038117332409506, disc_loss = 0.08358430451624198
Trained batch 292 in epoch 7, gen_loss = 0.803806751864762, disc_loss = 0.08347717822615197
Trained batch 293 in epoch 7, gen_loss = 0.8033375677202834, disc_loss = 0.08350420264261109
Trained batch 294 in epoch 7, gen_loss = 0.804787275952808, disc_loss = 0.08380786395173961
Trained batch 295 in epoch 7, gen_loss = 0.8049402263116192, disc_loss = 0.08360993687214481
Trained batch 296 in epoch 7, gen_loss = 0.804071616243433, disc_loss = 0.08397403576408172
Trained batch 297 in epoch 7, gen_loss = 0.8046911750863862, disc_loss = 0.08400810773690674
Trained batch 298 in epoch 7, gen_loss = 0.8041443758983676, disc_loss = 0.08410551131120493
Trained batch 299 in epoch 7, gen_loss = 0.804384535352389, disc_loss = 0.08389612825587392
Trained batch 300 in epoch 7, gen_loss = 0.8041197348670706, disc_loss = 0.0837163412603132
Trained batch 301 in epoch 7, gen_loss = 0.803901467694352, disc_loss = 0.08366500742314074
Trained batch 302 in epoch 7, gen_loss = 0.804901366776759, disc_loss = 0.08375612110907685
Trained batch 303 in epoch 7, gen_loss = 0.8047821315887728, disc_loss = 0.083752790668146
Trained batch 304 in epoch 7, gen_loss = 0.804866455031223, disc_loss = 0.08364255641449671
Trained batch 305 in epoch 7, gen_loss = 0.8049245005339579, disc_loss = 0.08356985137523974
Trained batch 306 in epoch 7, gen_loss = 0.8059826207859897, disc_loss = 0.08337548679098827
Trained batch 307 in epoch 7, gen_loss = 0.806245869630343, disc_loss = 0.08332678470639633
Trained batch 308 in epoch 7, gen_loss = 0.8058868690987621, disc_loss = 0.08330185528736091
Trained batch 309 in epoch 7, gen_loss = 0.8064834727394965, disc_loss = 0.08329686643255334
Trained batch 310 in epoch 7, gen_loss = 0.8055558321560311, disc_loss = 0.08354146966045885
Trained batch 311 in epoch 7, gen_loss = 0.8057484345940443, disc_loss = 0.08335127552541402
Trained batch 312 in epoch 7, gen_loss = 0.8057540957920086, disc_loss = 0.08318491795430549
Trained batch 313 in epoch 7, gen_loss = 0.8058865649305331, disc_loss = 0.08320317988040721
Trained batch 314 in epoch 7, gen_loss = 0.8062828599460541, disc_loss = 0.08331061371025585
Trained batch 315 in epoch 7, gen_loss = 0.8049884484727171, disc_loss = 0.08411713327646633
Trained batch 316 in epoch 7, gen_loss = 0.804024725400311, disc_loss = 0.08445425215250686
Trained batch 317 in epoch 7, gen_loss = 0.8052657206290923, disc_loss = 0.08537613953106434
Trained batch 318 in epoch 7, gen_loss = 0.8054990728260207, disc_loss = 0.08566893755128391
Trained batch 319 in epoch 7, gen_loss = 0.8051014349795877, disc_loss = 0.08594029556261376
Trained batch 320 in epoch 7, gen_loss = 0.8049957734587779, disc_loss = 0.08618058335047644
Trained batch 321 in epoch 7, gen_loss = 0.8050956601126594, disc_loss = 0.08649650170982624
Trained batch 322 in epoch 7, gen_loss = 0.8056600515502894, disc_loss = 0.0866103168496222
Trained batch 323 in epoch 7, gen_loss = 0.8052399622989289, disc_loss = 0.08687227682704911
Trained batch 324 in epoch 7, gen_loss = 0.804607344865799, disc_loss = 0.08696639969944954
Trained batch 325 in epoch 7, gen_loss = 0.8057654734952319, disc_loss = 0.08742435652465542
Trained batch 326 in epoch 7, gen_loss = 0.805013456931537, disc_loss = 0.0877409860924661
Trained batch 327 in epoch 7, gen_loss = 0.8056681171604773, disc_loss = 0.08751391697811281
Trained batch 328 in epoch 7, gen_loss = 0.8066388601408904, disc_loss = 0.08735358267796076
Trained batch 329 in epoch 7, gen_loss = 0.8054295105464531, disc_loss = 0.08792580326623989
Trained batch 330 in epoch 7, gen_loss = 0.8069769989507796, disc_loss = 0.08844434248221605
Trained batch 331 in epoch 7, gen_loss = 0.8071617824305971, disc_loss = 0.08823545587933566
Trained batch 332 in epoch 7, gen_loss = 0.8070711243796993, disc_loss = 0.08817066906674488
Trained batch 333 in epoch 7, gen_loss = 0.8065924763144133, disc_loss = 0.0881562254943712
Trained batch 334 in epoch 7, gen_loss = 0.8066835229966178, disc_loss = 0.08796571259623143
Trained batch 335 in epoch 7, gen_loss = 0.8066426912056548, disc_loss = 0.0879005626110094
Trained batch 336 in epoch 7, gen_loss = 0.8059816189795644, disc_loss = 0.08821343460316475
Trained batch 337 in epoch 7, gen_loss = 0.8057935797780224, disc_loss = 0.08815740487543788
Trained batch 338 in epoch 7, gen_loss = 0.8061993863202829, disc_loss = 0.08819983205084955
Trained batch 339 in epoch 7, gen_loss = 0.8054402734426891, disc_loss = 0.08839614939163713
Trained batch 340 in epoch 7, gen_loss = 0.805675290983793, disc_loss = 0.08834844886644845
Trained batch 341 in epoch 7, gen_loss = 0.8060209872255548, disc_loss = 0.08837022403614563
Trained batch 342 in epoch 7, gen_loss = 0.8055019603700054, disc_loss = 0.08848150567567035
Trained batch 343 in epoch 7, gen_loss = 0.8059376536240411, disc_loss = 0.08827862522001703
Trained batch 344 in epoch 7, gen_loss = 0.8056732857572859, disc_loss = 0.08828550388739592
Trained batch 345 in epoch 7, gen_loss = 0.8066819970835151, disc_loss = 0.08822265581222456
Trained batch 346 in epoch 7, gen_loss = 0.8064108697928338, disc_loss = 0.08814971642273475
Trained batch 347 in epoch 7, gen_loss = 0.8059519412017416, disc_loss = 0.08808777641355135
Trained batch 348 in epoch 7, gen_loss = 0.8067233681166411, disc_loss = 0.08824349198501055
Trained batch 349 in epoch 7, gen_loss = 0.8059941319908415, disc_loss = 0.08855419914105109
Trained batch 350 in epoch 7, gen_loss = 0.8066488929793366, disc_loss = 0.0884817915244235
Trained batch 351 in epoch 7, gen_loss = 0.8066056136211212, disc_loss = 0.08836656394520435
Trained batch 352 in epoch 7, gen_loss = 0.8060635682037126, disc_loss = 0.08845389740430769
Trained batch 353 in epoch 7, gen_loss = 0.8061835096549179, disc_loss = 0.0883024503019149
Trained batch 354 in epoch 7, gen_loss = 0.806539457700622, disc_loss = 0.08826680663500873
Trained batch 355 in epoch 7, gen_loss = 0.8063120430942332, disc_loss = 0.0881578149326313
Trained batch 356 in epoch 7, gen_loss = 0.8054491016043335, disc_loss = 0.0883028279071679
Trained batch 357 in epoch 7, gen_loss = 0.805383698234345, disc_loss = 0.08820725587722143
Trained batch 358 in epoch 7, gen_loss = 0.8060768587011481, disc_loss = 0.08830028935789563
Trained batch 359 in epoch 7, gen_loss = 0.8059586150778665, disc_loss = 0.08816200178633961
Trained batch 360 in epoch 7, gen_loss = 0.8058777783385934, disc_loss = 0.08808595115974174
Trained batch 361 in epoch 7, gen_loss = 0.8052589620015898, disc_loss = 0.08833354880817193
Trained batch 362 in epoch 7, gen_loss = 0.805285997298795, disc_loss = 0.08830385977920586
Trained batch 363 in epoch 7, gen_loss = 0.8063771891724932, disc_loss = 0.08814376105482762
Trained batch 364 in epoch 7, gen_loss = 0.8059236353390837, disc_loss = 0.08821579585336659
Trained batch 365 in epoch 7, gen_loss = 0.8056865798645332, disc_loss = 0.08808723985741698
Trained batch 366 in epoch 7, gen_loss = 0.805716581662929, disc_loss = 0.08795347147968874
Trained batch 367 in epoch 7, gen_loss = 0.8051792676358119, disc_loss = 0.08800121836121315
Trained batch 368 in epoch 7, gen_loss = 0.8046051675711221, disc_loss = 0.08800595871559004
Trained batch 369 in epoch 7, gen_loss = 0.804237766040338, disc_loss = 0.0880801592122864
Trained batch 370 in epoch 7, gen_loss = 0.8051398521806352, disc_loss = 0.08798352068646577
Trained batch 371 in epoch 7, gen_loss = 0.8051150431556087, disc_loss = 0.08783100007642661
Trained batch 372 in epoch 7, gen_loss = 0.8044101584692743, disc_loss = 0.08795027018352425
Trained batch 373 in epoch 7, gen_loss = 0.8050139638829359, disc_loss = 0.08788877049271754
Trained batch 374 in epoch 7, gen_loss = 0.8048902470270792, disc_loss = 0.08773073283334573
Trained batch 375 in epoch 7, gen_loss = 0.8043770644258945, disc_loss = 0.08785135338102724
Trained batch 376 in epoch 7, gen_loss = 0.8036454738925559, disc_loss = 0.0881057689089911
Trained batch 377 in epoch 7, gen_loss = 0.8045307785745651, disc_loss = 0.08855753860598992
Trained batch 378 in epoch 7, gen_loss = 0.8053432602366546, disc_loss = 0.08837917307514628
Trained batch 379 in epoch 7, gen_loss = 0.804922219483476, disc_loss = 0.08833915877499078
Trained batch 380 in epoch 7, gen_loss = 0.804168363099336, disc_loss = 0.08843159587599161
Trained batch 381 in epoch 7, gen_loss = 0.8043088199892593, disc_loss = 0.08827397568609702
Trained batch 382 in epoch 7, gen_loss = 0.8039280703733858, disc_loss = 0.08869223726558312
Trained batch 383 in epoch 7, gen_loss = 0.8039188006271919, disc_loss = 0.08865549766536181
Trained batch 384 in epoch 7, gen_loss = 0.8038626748246032, disc_loss = 0.08857216806961345
Trained batch 385 in epoch 7, gen_loss = 0.8035354916913522, disc_loss = 0.0886024774722948
Trained batch 386 in epoch 7, gen_loss = 0.8037356475526972, disc_loss = 0.08854904881550976
Trained batch 387 in epoch 7, gen_loss = 0.803753395670468, disc_loss = 0.0885374550371594
Trained batch 388 in epoch 7, gen_loss = 0.8038637043577846, disc_loss = 0.08845982333803239
Trained batch 389 in epoch 7, gen_loss = 0.8032201433793092, disc_loss = 0.08864698099593321
Trained batch 390 in epoch 7, gen_loss = 0.8031750795481455, disc_loss = 0.08858333330820589
Trained batch 391 in epoch 7, gen_loss = 0.8031384154241912, disc_loss = 0.08847377690657669
Trained batch 392 in epoch 7, gen_loss = 0.802917872373081, disc_loss = 0.08850318449371644
Trained batch 393 in epoch 7, gen_loss = 0.8037781116321002, disc_loss = 0.08855226983878818
Trained batch 394 in epoch 7, gen_loss = 0.8035069684439068, disc_loss = 0.08856874947683721
Trained batch 395 in epoch 7, gen_loss = 0.8034297190230302, disc_loss = 0.08858936680763056
Trained batch 396 in epoch 7, gen_loss = 0.8035354455111909, disc_loss = 0.08842832577281094
Trained batch 397 in epoch 7, gen_loss = 0.8045671767924898, disc_loss = 0.08884731196241463
Trained batch 398 in epoch 7, gen_loss = 0.8039080146560096, disc_loss = 0.08919639029262359
Trained batch 399 in epoch 7, gen_loss = 0.8037625595927238, disc_loss = 0.08905032654292881
Trained batch 400 in epoch 7, gen_loss = 0.8049266585090809, disc_loss = 0.0890879037504333
Trained batch 401 in epoch 7, gen_loss = 0.8047098223842791, disc_loss = 0.08903852096800484
Trained batch 402 in epoch 7, gen_loss = 0.8042989450116311, disc_loss = 0.08919752526926639
Trained batch 403 in epoch 7, gen_loss = 0.8039484527146462, disc_loss = 0.08921791093958782
Trained batch 404 in epoch 7, gen_loss = 0.8050782417073662, disc_loss = 0.08988436590190287
Trained batch 405 in epoch 7, gen_loss = 0.8047012544324246, disc_loss = 0.08990032395595694
Trained batch 406 in epoch 7, gen_loss = 0.804578820376197, disc_loss = 0.08987774050975314
Trained batch 407 in epoch 7, gen_loss = 0.804806522878946, disc_loss = 0.08998379053767114
Trained batch 408 in epoch 7, gen_loss = 0.8048083793854656, disc_loss = 0.0900842820756447
Trained batch 409 in epoch 7, gen_loss = 0.8042187046713946, disc_loss = 0.09023010171949863
Trained batch 410 in epoch 7, gen_loss = 0.8048682805975568, disc_loss = 0.09018933407762915
Trained batch 411 in epoch 7, gen_loss = 0.804791408979777, disc_loss = 0.09011556861867893
Trained batch 412 in epoch 7, gen_loss = 0.8043754509228482, disc_loss = 0.09025450764318645
Trained batch 413 in epoch 7, gen_loss = 0.8047358789593702, disc_loss = 0.09013964441843367
Trained batch 414 in epoch 7, gen_loss = 0.8041299933410553, disc_loss = 0.09025038496018892
Trained batch 415 in epoch 7, gen_loss = 0.8035357704815956, disc_loss = 0.09039336228922296
Trained batch 416 in epoch 7, gen_loss = 0.8034984603774348, disc_loss = 0.09026332364844189
Trained batch 417 in epoch 7, gen_loss = 0.8037109098366003, disc_loss = 0.0901840846611267
Trained batch 418 in epoch 7, gen_loss = 0.8035305224910272, disc_loss = 0.09006739903890432
Trained batch 419 in epoch 7, gen_loss = 0.8036513819580986, disc_loss = 0.08992757449547449
Trained batch 420 in epoch 7, gen_loss = 0.8037824800631779, disc_loss = 0.08975654325919168
Trained batch 421 in epoch 7, gen_loss = 0.8038715053508632, disc_loss = 0.08965682383556078
Trained batch 422 in epoch 7, gen_loss = 0.8037166556004374, disc_loss = 0.08954659561862197
Trained batch 423 in epoch 7, gen_loss = 0.803909606247578, disc_loss = 0.08958325267523387
Trained batch 424 in epoch 7, gen_loss = 0.8037163668520311, disc_loss = 0.08948027421008138
Trained batch 425 in epoch 7, gen_loss = 0.8033019670858069, disc_loss = 0.08946943851056653
Trained batch 426 in epoch 7, gen_loss = 0.8034772068890252, disc_loss = 0.0897450606345223
Trained batch 427 in epoch 7, gen_loss = 0.8033360422493141, disc_loss = 0.08962625341281016
Trained batch 428 in epoch 7, gen_loss = 0.8028164974181524, disc_loss = 0.08966184650180918
Trained batch 429 in epoch 7, gen_loss = 0.8032943903013717, disc_loss = 0.08961950879717288
Trained batch 430 in epoch 7, gen_loss = 0.803607108144915, disc_loss = 0.08971638140417722
Trained batch 431 in epoch 7, gen_loss = 0.8028312152320588, disc_loss = 0.08997712632279015
Trained batch 432 in epoch 7, gen_loss = 0.8024535285820862, disc_loss = 0.0899830611237684
Trained batch 433 in epoch 7, gen_loss = 0.8022609901730366, disc_loss = 0.08992360821980898
Trained batch 434 in epoch 7, gen_loss = 0.8028203103049049, disc_loss = 0.09002414641623524
Trained batch 435 in epoch 7, gen_loss = 0.8025722256904348, disc_loss = 0.08993697774365818
Trained batch 436 in epoch 7, gen_loss = 0.8026649490237509, disc_loss = 0.0897593934886004
Trained batch 437 in epoch 7, gen_loss = 0.8025818501841532, disc_loss = 0.08965768663586887
Trained batch 438 in epoch 7, gen_loss = 0.8027558186195435, disc_loss = 0.08948615245342866
Trained batch 439 in epoch 7, gen_loss = 0.8026112960820848, disc_loss = 0.0895348044726151
Trained batch 440 in epoch 7, gen_loss = 0.8026358389935526, disc_loss = 0.08949309743966172
Trained batch 441 in epoch 7, gen_loss = 0.802493079552823, disc_loss = 0.08936951216099556
Trained batch 442 in epoch 7, gen_loss = 0.8025271625470362, disc_loss = 0.0892253328203045
Trained batch 443 in epoch 7, gen_loss = 0.8025148757271938, disc_loss = 0.08921063030012757
Trained batch 444 in epoch 7, gen_loss = 0.802298467547706, disc_loss = 0.08916251078206167
Trained batch 445 in epoch 7, gen_loss = 0.8024602860479612, disc_loss = 0.08907426373966272
Trained batch 446 in epoch 7, gen_loss = 0.8021502603487147, disc_loss = 0.0891119735398782
Trained batch 447 in epoch 7, gen_loss = 0.8024441934456783, disc_loss = 0.08906260782844454
Trained batch 448 in epoch 7, gen_loss = 0.8024845690796264, disc_loss = 0.0890823395566015
Trained batch 449 in epoch 7, gen_loss = 0.8023782091008292, disc_loss = 0.08895340617953075
Trained batch 450 in epoch 7, gen_loss = 0.802250457113968, disc_loss = 0.08893680737504607
Trained batch 451 in epoch 7, gen_loss = 0.8018915990153245, disc_loss = 0.08897297695666485
Trained batch 452 in epoch 7, gen_loss = 0.8017771278917132, disc_loss = 0.08894283941044384
Trained batch 453 in epoch 7, gen_loss = 0.8026463127477579, disc_loss = 0.08918908891362437
Trained batch 454 in epoch 7, gen_loss = 0.8022075610501426, disc_loss = 0.08923537252818818
Trained batch 455 in epoch 7, gen_loss = 0.8017465003619069, disc_loss = 0.08917363173238475
Trained batch 456 in epoch 7, gen_loss = 0.8029086150930016, disc_loss = 0.08921035777581794
Trained batch 457 in epoch 7, gen_loss = 0.8029970648377223, disc_loss = 0.0890996578539921
Trained batch 458 in epoch 7, gen_loss = 0.8035701912602567, disc_loss = 0.08907978449925813
Trained batch 459 in epoch 7, gen_loss = 0.8033142886084059, disc_loss = 0.08905510582313265
Trained batch 460 in epoch 7, gen_loss = 0.8030163152486797, disc_loss = 0.08912715877238621
Trained batch 461 in epoch 7, gen_loss = 0.8029517621059954, disc_loss = 0.08907256142167753
Trained batch 462 in epoch 7, gen_loss = 0.8033684622777976, disc_loss = 0.08919168991634127
Trained batch 463 in epoch 7, gen_loss = 0.8028214988138141, disc_loss = 0.08921397272457272
Trained batch 464 in epoch 7, gen_loss = 0.8029826236668454, disc_loss = 0.08909408490784386
Trained batch 465 in epoch 7, gen_loss = 0.803379412180876, disc_loss = 0.08897577269930121
Trained batch 466 in epoch 7, gen_loss = 0.8031718670300805, disc_loss = 0.0889927298049951
Trained batch 467 in epoch 7, gen_loss = 0.8033003040995353, disc_loss = 0.08884952756034958
Trained batch 468 in epoch 7, gen_loss = 0.8032535066101343, disc_loss = 0.08874383274672319
Trained batch 469 in epoch 7, gen_loss = 0.8029258665252239, disc_loss = 0.08866728984730991
Trained batch 470 in epoch 7, gen_loss = 0.8028643387518112, disc_loss = 0.0886752920209444
Trained batch 471 in epoch 7, gen_loss = 0.8035971515385781, disc_loss = 0.08859872300832895
Trained batch 472 in epoch 7, gen_loss = 0.8031169461523504, disc_loss = 0.08865906276698786
Trained batch 473 in epoch 7, gen_loss = 0.80270754706256, disc_loss = 0.08867479715189791
Trained batch 474 in epoch 7, gen_loss = 0.802983321829846, disc_loss = 0.08858950085349773
Trained batch 475 in epoch 7, gen_loss = 0.8034012567471055, disc_loss = 0.08852226617198218
Trained batch 476 in epoch 7, gen_loss = 0.8037848178320711, disc_loss = 0.08843520432671599
Trained batch 477 in epoch 7, gen_loss = 0.8038153624060762, disc_loss = 0.08836251701263391
Trained batch 478 in epoch 7, gen_loss = 0.8036272205365724, disc_loss = 0.08829179432414208
Trained batch 479 in epoch 7, gen_loss = 0.8035478955134749, disc_loss = 0.08826977667825607
Trained batch 480 in epoch 7, gen_loss = 0.804356868264581, disc_loss = 0.08829465068357836
Trained batch 481 in epoch 7, gen_loss = 0.8044320543400975, disc_loss = 0.08821633736954623
Trained batch 482 in epoch 7, gen_loss = 0.8038740452402127, disc_loss = 0.08870831194216111
Trained batch 483 in epoch 7, gen_loss = 0.8044697532107022, disc_loss = 0.08859981455424538
Trained batch 484 in epoch 7, gen_loss = 0.8051136550829583, disc_loss = 0.08878078307649216
Trained batch 485 in epoch 7, gen_loss = 0.805503636782552, disc_loss = 0.08864556368509377
Trained batch 486 in epoch 7, gen_loss = 0.8054863188178633, disc_loss = 0.08856119101320142
Trained batch 487 in epoch 7, gen_loss = 0.804637188977394, disc_loss = 0.08867040599245944
Trained batch 488 in epoch 7, gen_loss = 0.8043379674538025, disc_loss = 0.08860818766522201
Trained batch 489 in epoch 7, gen_loss = 0.8042940013870901, disc_loss = 0.08862681205441453
Trained batch 490 in epoch 7, gen_loss = 0.804910383557108, disc_loss = 0.08853537902471187
Trained batch 491 in epoch 7, gen_loss = 0.8048068964020992, disc_loss = 0.08852130170661683
Trained batch 492 in epoch 7, gen_loss = 0.804774647249895, disc_loss = 0.0884666234069706
Trained batch 493 in epoch 7, gen_loss = 0.8047566707679618, disc_loss = 0.08833448858630018
Trained batch 494 in epoch 7, gen_loss = 0.8050097505853634, disc_loss = 0.08837601808699394
Trained batch 495 in epoch 7, gen_loss = 0.8051218118278249, disc_loss = 0.08829765222148009
Trained batch 496 in epoch 7, gen_loss = 0.8045484654500451, disc_loss = 0.08873406924134948
Trained batch 497 in epoch 7, gen_loss = 0.8048424600477678, disc_loss = 0.08859257043028872
Trained batch 498 in epoch 7, gen_loss = 0.8052495048495237, disc_loss = 0.08873732393058782
Trained batch 499 in epoch 7, gen_loss = 0.8052701215147973, disc_loss = 0.08902910246513784
Trained batch 500 in epoch 7, gen_loss = 0.8049959595688803, disc_loss = 0.08901405369234597
Trained batch 501 in epoch 7, gen_loss = 0.8042502618168454, disc_loss = 0.08929882723044055
Trained batch 502 in epoch 7, gen_loss = 0.8047897741050417, disc_loss = 0.08941828892575521
Trained batch 503 in epoch 7, gen_loss = 0.8043329201283909, disc_loss = 0.0895537192589559
Trained batch 504 in epoch 7, gen_loss = 0.8044503136436538, disc_loss = 0.08956368408248862
Trained batch 505 in epoch 7, gen_loss = 0.8043933593237353, disc_loss = 0.0894837592132095
Trained batch 506 in epoch 7, gen_loss = 0.8042957249007516, disc_loss = 0.08942294760590651
Trained batch 507 in epoch 7, gen_loss = 0.8042957437789346, disc_loss = 0.08966517767238277
Trained batch 508 in epoch 7, gen_loss = 0.8041021212613418, disc_loss = 0.08964410405752408
Trained batch 509 in epoch 7, gen_loss = 0.8041111378108754, disc_loss = 0.08962737057978908
Trained batch 510 in epoch 7, gen_loss = 0.8039709944314453, disc_loss = 0.08950912152506309
Trained batch 511 in epoch 7, gen_loss = 0.8034876711899415, disc_loss = 0.08958207430805487
Trained batch 512 in epoch 7, gen_loss = 0.8035849975331253, disc_loss = 0.08951606716757339
Trained batch 513 in epoch 7, gen_loss = 0.8042847079293737, disc_loss = 0.08968459281903703
Trained batch 514 in epoch 7, gen_loss = 0.8039626381929639, disc_loss = 0.08971679847759818
Trained batch 515 in epoch 7, gen_loss = 0.8037019531394161, disc_loss = 0.08973401114019718
Trained batch 516 in epoch 7, gen_loss = 0.8039082138865783, disc_loss = 0.08974355439578023
Trained batch 517 in epoch 7, gen_loss = 0.8037781802843896, disc_loss = 0.08978208891407345
Trained batch 518 in epoch 7, gen_loss = 0.804052678606184, disc_loss = 0.08978560395172738
Trained batch 519 in epoch 7, gen_loss = 0.8040001841691824, disc_loss = 0.08976188371351991
Trained batch 520 in epoch 7, gen_loss = 0.8043250609725542, disc_loss = 0.08970725545463029
Trained batch 521 in epoch 7, gen_loss = 0.8038955601467483, disc_loss = 0.08992398456559728
Trained batch 522 in epoch 7, gen_loss = 0.8036011456303569, disc_loss = 0.08987629756039404
Trained batch 523 in epoch 7, gen_loss = 0.8036814279683674, disc_loss = 0.0898743353211783
Trained batch 524 in epoch 7, gen_loss = 0.8040313367616563, disc_loss = 0.0897627661394931
Trained batch 525 in epoch 7, gen_loss = 0.804200542970302, disc_loss = 0.08978204003326283
Trained batch 526 in epoch 7, gen_loss = 0.8038100173848856, disc_loss = 0.08995490007109558
Trained batch 527 in epoch 7, gen_loss = 0.8042474384560729, disc_loss = 0.08982233220718405
Trained batch 528 in epoch 7, gen_loss = 0.8040098038648162, disc_loss = 0.08973731224676894
Trained batch 529 in epoch 7, gen_loss = 0.8041376402917898, disc_loss = 0.0897299164747995
Trained batch 530 in epoch 7, gen_loss = 0.8039954051010577, disc_loss = 0.08969828130224836
Trained batch 531 in epoch 7, gen_loss = 0.8040697566772762, disc_loss = 0.08961245664955586
Trained batch 532 in epoch 7, gen_loss = 0.8041834432009685, disc_loss = 0.08950848258353812
Trained batch 533 in epoch 7, gen_loss = 0.8037680212254827, disc_loss = 0.08951406913533919
Trained batch 534 in epoch 7, gen_loss = 0.8041750842165725, disc_loss = 0.08961966418112828
Trained batch 535 in epoch 7, gen_loss = 0.8037061080781381, disc_loss = 0.08964051474615542
Trained batch 536 in epoch 7, gen_loss = 0.8037343054066379, disc_loss = 0.08951306079637461
Trained batch 537 in epoch 7, gen_loss = 0.8037824513300644, disc_loss = 0.08946298236082754
Trained batch 538 in epoch 7, gen_loss = 0.8038140064267811, disc_loss = 0.08933888417055247
Trained batch 539 in epoch 7, gen_loss = 0.8040247118031537, disc_loss = 0.08927914464880747
Trained batch 540 in epoch 7, gen_loss = 0.8045618650873576, disc_loss = 0.0892821640488924
Trained batch 541 in epoch 7, gen_loss = 0.8045891130762347, disc_loss = 0.08917137429056297
Trained batch 542 in epoch 7, gen_loss = 0.8044799729824944, disc_loss = 0.0891960695313897
Trained batch 543 in epoch 7, gen_loss = 0.804194129893885, disc_loss = 0.08920031711835798
Trained batch 544 in epoch 7, gen_loss = 0.805072981830037, disc_loss = 0.08981572009383812
Trained batch 545 in epoch 7, gen_loss = 0.8048567938935626, disc_loss = 0.08987526338881789
Trained batch 546 in epoch 7, gen_loss = 0.8048307187378515, disc_loss = 0.08979341464536009
Trained batch 547 in epoch 7, gen_loss = 0.8042917748654845, disc_loss = 0.08990399012457662
Trained batch 548 in epoch 7, gen_loss = 0.8042153368665004, disc_loss = 0.08984181727834033
Trained batch 549 in epoch 7, gen_loss = 0.8044039083610881, disc_loss = 0.0897178029387512
Trained batch 550 in epoch 7, gen_loss = 0.8042720528133551, disc_loss = 0.08967389795631711
Trained batch 551 in epoch 7, gen_loss = 0.8038189922985823, disc_loss = 0.08983410310938253
Trained batch 552 in epoch 7, gen_loss = 0.8042703375462813, disc_loss = 0.08982120178619679
Trained batch 553 in epoch 7, gen_loss = 0.8045266288927746, disc_loss = 0.08970143735267572
Trained batch 554 in epoch 7, gen_loss = 0.8047913003612209, disc_loss = 0.08961755337176827
Trained batch 555 in epoch 7, gen_loss = 0.8045009095891774, disc_loss = 0.08968328951737381
Trained batch 556 in epoch 7, gen_loss = 0.8043189648023842, disc_loss = 0.08961876307043984
Trained batch 557 in epoch 7, gen_loss = 0.8042294422571804, disc_loss = 0.08952393588913758
Trained batch 558 in epoch 7, gen_loss = 0.8048051242751597, disc_loss = 0.08982334213168068
Trained batch 559 in epoch 7, gen_loss = 0.804927006896053, disc_loss = 0.0897117977945267
Trained batch 560 in epoch 7, gen_loss = 0.8042457466563226, disc_loss = 0.09014155363594306
Trained batch 561 in epoch 7, gen_loss = 0.8045811862601928, disc_loss = 0.09014134938759047
Trained batch 562 in epoch 7, gen_loss = 0.8049454142208845, disc_loss = 0.09015376632785024
Trained batch 563 in epoch 7, gen_loss = 0.8047799934626471, disc_loss = 0.09019323081564132
Trained batch 564 in epoch 7, gen_loss = 0.8044950174546874, disc_loss = 0.09014578039502412
Trained batch 565 in epoch 7, gen_loss = 0.8039767084505027, disc_loss = 0.09019132579640607
Trained batch 566 in epoch 7, gen_loss = 0.8040611831704565, disc_loss = 0.09013019009235412
Trained batch 567 in epoch 7, gen_loss = 0.8041835202192756, disc_loss = 0.09000065106026252
Trained batch 568 in epoch 7, gen_loss = 0.8041239065005197, disc_loss = 0.08989856310797649
Trained batch 569 in epoch 7, gen_loss = 0.8037725089411987, disc_loss = 0.09001883183230172
Trained batch 570 in epoch 7, gen_loss = 0.8038697829910418, disc_loss = 0.08997574909027477
Trained batch 571 in epoch 7, gen_loss = 0.8037148228996284, disc_loss = 0.08990816940501384
Trained batch 572 in epoch 7, gen_loss = 0.8037215858749902, disc_loss = 0.08980816795635338
Trained batch 573 in epoch 7, gen_loss = 0.803796382783182, disc_loss = 0.08970320318705477
Trained batch 574 in epoch 7, gen_loss = 0.8036884249293286, disc_loss = 0.08965194283458201
Trained batch 575 in epoch 7, gen_loss = 0.8037327885524266, disc_loss = 0.08959359035199871
Trained batch 576 in epoch 7, gen_loss = 0.8042944555575967, disc_loss = 0.0895192877629988
Trained batch 577 in epoch 7, gen_loss = 0.804064488380013, disc_loss = 0.0895359363635699
Trained batch 578 in epoch 7, gen_loss = 0.8040857440140581, disc_loss = 0.08959364735188416
Trained batch 579 in epoch 7, gen_loss = 0.803640820188769, disc_loss = 0.0896034918580975
Trained batch 580 in epoch 7, gen_loss = 0.8034018092947449, disc_loss = 0.08960271590644182
Trained batch 581 in epoch 7, gen_loss = 0.8035919753853807, disc_loss = 0.08964699824081407
Trained batch 582 in epoch 7, gen_loss = 0.8036714155821203, disc_loss = 0.08962194317245718
Trained batch 583 in epoch 7, gen_loss = 0.8034181315707017, disc_loss = 0.08959865064698284
Trained batch 584 in epoch 7, gen_loss = 0.8031042583477803, disc_loss = 0.089586583020277
Trained batch 585 in epoch 7, gen_loss = 0.8034342447543714, disc_loss = 0.08945852042725723
Trained batch 586 in epoch 7, gen_loss = 0.8036210859349883, disc_loss = 0.0893798318391688
Trained batch 587 in epoch 7, gen_loss = 0.8036023454905368, disc_loss = 0.08933770602892097
Trained batch 588 in epoch 7, gen_loss = 0.8032446371577996, disc_loss = 0.08939513291670279
Trained batch 589 in epoch 7, gen_loss = 0.8031408492286326, disc_loss = 0.08929824665725483
Trained batch 590 in epoch 7, gen_loss = 0.8030353238437381, disc_loss = 0.08925229004172958
Trained batch 591 in epoch 7, gen_loss = 0.8035515603684896, disc_loss = 0.08928219385828974
Trained batch 592 in epoch 7, gen_loss = 0.8034975108067061, disc_loss = 0.08921063586623482
Trained batch 593 in epoch 7, gen_loss = 0.8029537127174512, disc_loss = 0.08938962476553791
Trained batch 594 in epoch 7, gen_loss = 0.8030537573730244, disc_loss = 0.08937645652996642
Trained batch 595 in epoch 7, gen_loss = 0.8033546871886957, disc_loss = 0.08929033912624539
Trained batch 596 in epoch 7, gen_loss = 0.8032620520747487, disc_loss = 0.08919667067096711
Trained batch 597 in epoch 7, gen_loss = 0.8033627646922268, disc_loss = 0.08908749140182316
Trained batch 598 in epoch 7, gen_loss = 0.8035167342732864, disc_loss = 0.08899175891425704
Trained batch 599 in epoch 7, gen_loss = 0.8039554838836193, disc_loss = 0.08902252650043617
Trained batch 600 in epoch 7, gen_loss = 0.8039823313818597, disc_loss = 0.08892166246187419
Trained batch 601 in epoch 7, gen_loss = 0.8039974084625212, disc_loss = 0.08885896995979241
Trained batch 602 in epoch 7, gen_loss = 0.8041615342322866, disc_loss = 0.08879784216477256
Trained batch 603 in epoch 7, gen_loss = 0.8045186102883706, disc_loss = 0.08879650469147754
Trained batch 604 in epoch 7, gen_loss = 0.8046702747010003, disc_loss = 0.08868531228374105
Trained batch 605 in epoch 7, gen_loss = 0.8041158684901278, disc_loss = 0.08879587682050102
Trained batch 606 in epoch 7, gen_loss = 0.8042276791823165, disc_loss = 0.08869599835268993
Trained batch 607 in epoch 7, gen_loss = 0.8041815109256851, disc_loss = 0.08864776285420368
Trained batch 608 in epoch 7, gen_loss = 0.804275546412554, disc_loss = 0.08856125311904597
Trained batch 609 in epoch 7, gen_loss = 0.8042562589782183, disc_loss = 0.08878069035250877
Trained batch 610 in epoch 7, gen_loss = 0.8038304111083479, disc_loss = 0.08888020549493852
Trained batch 611 in epoch 7, gen_loss = 0.8034768139127813, disc_loss = 0.08883128959983831
Trained batch 612 in epoch 7, gen_loss = 0.8033047262548817, disc_loss = 0.08892720725788426
Trained batch 613 in epoch 7, gen_loss = 0.8034494824537625, disc_loss = 0.08883792730594352
Trained batch 614 in epoch 7, gen_loss = 0.8035186828151951, disc_loss = 0.08884566084186478
Trained batch 615 in epoch 7, gen_loss = 0.8035455627197569, disc_loss = 0.08880063312811559
Trained batch 616 in epoch 7, gen_loss = 0.803623221536896, disc_loss = 0.08874271706356464
Trained batch 617 in epoch 7, gen_loss = 0.8036679377158483, disc_loss = 0.08872286252177118
Trained batch 618 in epoch 7, gen_loss = 0.8037136194682853, disc_loss = 0.08861377649460596
Trained batch 619 in epoch 7, gen_loss = 0.8033690441519984, disc_loss = 0.08861449503399912
Trained batch 620 in epoch 7, gen_loss = 0.8039394220196299, disc_loss = 0.08866914020530316
Trained batch 621 in epoch 7, gen_loss = 0.8037781702456367, disc_loss = 0.08877992240256867
Trained batch 622 in epoch 7, gen_loss = 0.80355972372127, disc_loss = 0.08877065515423711
Trained batch 623 in epoch 7, gen_loss = 0.8034701084192747, disc_loss = 0.08880640599333371
Trained batch 624 in epoch 7, gen_loss = 0.8037480141162873, disc_loss = 0.08884133157283068
Trained batch 625 in epoch 7, gen_loss = 0.8036095364310871, disc_loss = 0.08877224659773346
Trained batch 626 in epoch 7, gen_loss = 0.8034644189158505, disc_loss = 0.08877531038760617
Trained batch 627 in epoch 7, gen_loss = 0.8036605630805538, disc_loss = 0.0887506823218576
Trained batch 628 in epoch 7, gen_loss = 0.803702661409287, disc_loss = 0.08873856779697258
Trained batch 629 in epoch 7, gen_loss = 0.8038562246258296, disc_loss = 0.08872335166596468
Trained batch 630 in epoch 7, gen_loss = 0.803354671469959, disc_loss = 0.08879837206167814
Trained batch 631 in epoch 7, gen_loss = 0.8032822106269342, disc_loss = 0.0887266938836915
Trained batch 632 in epoch 7, gen_loss = 0.8033427634698708, disc_loss = 0.08869745336490643
Trained batch 633 in epoch 7, gen_loss = 0.8031755231720415, disc_loss = 0.08869877716303107
Trained batch 634 in epoch 7, gen_loss = 0.8036624879348935, disc_loss = 0.0886256809324378
Trained batch 635 in epoch 7, gen_loss = 0.8036469155512516, disc_loss = 0.08856151745150909
Trained batch 636 in epoch 7, gen_loss = 0.8036199518051028, disc_loss = 0.0884977059579181
Trained batch 637 in epoch 7, gen_loss = 0.8040829325170726, disc_loss = 0.08856856598895405
Trained batch 638 in epoch 7, gen_loss = 0.8038195964875915, disc_loss = 0.088564449913963
Trained batch 639 in epoch 7, gen_loss = 0.8038011942058801, disc_loss = 0.08846356616850244
Trained batch 640 in epoch 7, gen_loss = 0.804226426736055, disc_loss = 0.08836209994425501
Trained batch 641 in epoch 7, gen_loss = 0.8041107147653527, disc_loss = 0.08827814534219487
Trained batch 642 in epoch 7, gen_loss = 0.8036274345907416, disc_loss = 0.08831324047245329
Trained batch 643 in epoch 7, gen_loss = 0.8042364990026314, disc_loss = 0.08834733256509077
Trained batch 644 in epoch 7, gen_loss = 0.8041595464066942, disc_loss = 0.08832873569353837
Trained batch 645 in epoch 7, gen_loss = 0.80364548897042, disc_loss = 0.08850295081786558
Trained batch 646 in epoch 7, gen_loss = 0.8033546491697362, disc_loss = 0.08853521088780217
Trained batch 647 in epoch 7, gen_loss = 0.8035939721689548, disc_loss = 0.08846926617430362
Trained batch 648 in epoch 7, gen_loss = 0.8039928213198122, disc_loss = 0.08855527935144944
Trained batch 649 in epoch 7, gen_loss = 0.8036208891410094, disc_loss = 0.0886375016389558
Trained batch 650 in epoch 7, gen_loss = 0.8036056630164614, disc_loss = 0.08855393392887945
Trained batch 651 in epoch 7, gen_loss = 0.8041976589275284, disc_loss = 0.08846384063905871
Trained batch 652 in epoch 7, gen_loss = 0.8042431489705675, disc_loss = 0.0884422562876645
Trained batch 653 in epoch 7, gen_loss = 0.8048255704685089, disc_loss = 0.08849050343714494
Trained batch 654 in epoch 7, gen_loss = 0.8047019569473413, disc_loss = 0.0884780105501982
Trained batch 655 in epoch 7, gen_loss = 0.8047638327882785, disc_loss = 0.08837839670439546
Trained batch 656 in epoch 7, gen_loss = 0.8047389455672631, disc_loss = 0.08861345898847647
Trained batch 657 in epoch 7, gen_loss = 0.804440527474989, disc_loss = 0.08865750638915276
Trained batch 658 in epoch 7, gen_loss = 0.8045733097561936, disc_loss = 0.08870034254606875
Trained batch 659 in epoch 7, gen_loss = 0.8039714718858401, disc_loss = 0.08886575678673883
Trained batch 660 in epoch 7, gen_loss = 0.8043505430852772, disc_loss = 0.08893913456834797
Trained batch 661 in epoch 7, gen_loss = 0.8042669610944759, disc_loss = 0.08888489781285205
Trained batch 662 in epoch 7, gen_loss = 0.8041610311868503, disc_loss = 0.08881694735990076
Trained batch 663 in epoch 7, gen_loss = 0.8044051473668541, disc_loss = 0.08872800063291363
Trained batch 664 in epoch 7, gen_loss = 0.8042816428761733, disc_loss = 0.08875227949084868
Trained batch 665 in epoch 7, gen_loss = 0.804665158237065, disc_loss = 0.08876472252753896
Trained batch 666 in epoch 7, gen_loss = 0.804727367151981, disc_loss = 0.08873578011179747
Trained batch 667 in epoch 7, gen_loss = 0.8044927337480162, disc_loss = 0.08879683094104741
Trained batch 668 in epoch 7, gen_loss = 0.8044351194560617, disc_loss = 0.08876858735025508
Trained batch 669 in epoch 7, gen_loss = 0.8050273898377347, disc_loss = 0.08878467097294641
Trained batch 670 in epoch 7, gen_loss = 0.8047953925349496, disc_loss = 0.08875996260674762
Trained batch 671 in epoch 7, gen_loss = 0.8052754077084717, disc_loss = 0.08869778656905207
Trained batch 672 in epoch 7, gen_loss = 0.8052895605386986, disc_loss = 0.08863890040831926
Trained batch 673 in epoch 7, gen_loss = 0.8056229891957445, disc_loss = 0.08857609479044197
Trained batch 674 in epoch 7, gen_loss = 0.805562809087612, disc_loss = 0.08849911614562626
Trained batch 675 in epoch 7, gen_loss = 0.8054326552699304, disc_loss = 0.08847743581247533
Trained batch 676 in epoch 7, gen_loss = 0.8053663524866457, disc_loss = 0.08843256874172295
Trained batch 677 in epoch 7, gen_loss = 0.8051204424252553, disc_loss = 0.08844114237692988
Trained batch 678 in epoch 7, gen_loss = 0.805641865300149, disc_loss = 0.08844230177953553
Trained batch 679 in epoch 7, gen_loss = 0.8058014726375833, disc_loss = 0.088351146839833
Trained batch 680 in epoch 7, gen_loss = 0.8061652490308456, disc_loss = 0.08823638581007544
Trained batch 681 in epoch 7, gen_loss = 0.8060503779880462, disc_loss = 0.08817569668270932
Trained batch 682 in epoch 7, gen_loss = 0.8058326180211621, disc_loss = 0.08813653463473213
Trained batch 683 in epoch 7, gen_loss = 0.8059404844864767, disc_loss = 0.08802356213135154
Trained batch 684 in epoch 7, gen_loss = 0.8059522464762638, disc_loss = 0.087930420065557
Trained batch 685 in epoch 7, gen_loss = 0.805873883317928, disc_loss = 0.08787966634448259
Trained batch 686 in epoch 7, gen_loss = 0.8064225602791993, disc_loss = 0.0880643785016115
Trained batch 687 in epoch 7, gen_loss = 0.8063005256185005, disc_loss = 0.08799162742324433
Trained batch 688 in epoch 7, gen_loss = 0.8063407711176463, disc_loss = 0.08791479127987116
Trained batch 689 in epoch 7, gen_loss = 0.8060038102277811, disc_loss = 0.08795449772876673
Trained batch 690 in epoch 7, gen_loss = 0.8061293193210569, disc_loss = 0.08794012070834292
Trained batch 691 in epoch 7, gen_loss = 0.806212301069946, disc_loss = 0.08798028938095435
Trained batch 692 in epoch 7, gen_loss = 0.8062210648520857, disc_loss = 0.08790011144099383
Trained batch 693 in epoch 7, gen_loss = 0.805893586030611, disc_loss = 0.08802396253620942
Trained batch 694 in epoch 7, gen_loss = 0.8059591625663016, disc_loss = 0.08820134063901232
Trained batch 695 in epoch 7, gen_loss = 0.8060298857932118, disc_loss = 0.08818146121024487
Trained batch 696 in epoch 7, gen_loss = 0.8057943628285844, disc_loss = 0.088212180644851
Trained batch 697 in epoch 7, gen_loss = 0.805555345036922, disc_loss = 0.08825722893160957
Trained batch 698 in epoch 7, gen_loss = 0.8060318527047726, disc_loss = 0.08830214496728603
Trained batch 699 in epoch 7, gen_loss = 0.8061770693319185, disc_loss = 0.088211264730032
Trained batch 700 in epoch 7, gen_loss = 0.8067699548776411, disc_loss = 0.08824747283484644
Trained batch 701 in epoch 7, gen_loss = 0.8067355901851953, disc_loss = 0.08821727045973567
Trained batch 702 in epoch 7, gen_loss = 0.8068731659082735, disc_loss = 0.08815481983506747
Trained batch 703 in epoch 7, gen_loss = 0.8071135746061124, disc_loss = 0.08805594233721918
Trained batch 704 in epoch 7, gen_loss = 0.8069961341137581, disc_loss = 0.08803412069084374
Trained batch 705 in epoch 7, gen_loss = 0.8072038962803887, disc_loss = 0.08812263760209169
Trained batch 706 in epoch 7, gen_loss = 0.8070099309529408, disc_loss = 0.08812736468244729
Trained batch 707 in epoch 7, gen_loss = 0.8069876067466655, disc_loss = 0.08816845210184907
Trained batch 708 in epoch 7, gen_loss = 0.8067511312127618, disc_loss = 0.0882030534984909
Trained batch 709 in epoch 7, gen_loss = 0.8065307604175218, disc_loss = 0.08823705133260555
Trained batch 710 in epoch 7, gen_loss = 0.8069585520255415, disc_loss = 0.08834468935119871
Trained batch 711 in epoch 7, gen_loss = 0.8070275043922194, disc_loss = 0.08827898339786974
Trained batch 712 in epoch 7, gen_loss = 0.806883246542528, disc_loss = 0.08838532008439678
Trained batch 713 in epoch 7, gen_loss = 0.8068936316489506, disc_loss = 0.08830341051074386
Trained batch 714 in epoch 7, gen_loss = 0.8067094634046088, disc_loss = 0.08824033777040619
Trained batch 715 in epoch 7, gen_loss = 0.807314917819793, disc_loss = 0.08829294247344635
Trained batch 716 in epoch 7, gen_loss = 0.8071265439691238, disc_loss = 0.08832719420424481
Trained batch 717 in epoch 7, gen_loss = 0.8071301149043533, disc_loss = 0.088256374512563
Trained batch 718 in epoch 7, gen_loss = 0.8071768978126191, disc_loss = 0.08835690099906607
Trained batch 719 in epoch 7, gen_loss = 0.8072638925164938, disc_loss = 0.088288368897823
Trained batch 720 in epoch 7, gen_loss = 0.8069015010137333, disc_loss = 0.08837255735554823
Trained batch 721 in epoch 7, gen_loss = 0.8070460763912122, disc_loss = 0.08840171766010761
Trained batch 722 in epoch 7, gen_loss = 0.8070326555896432, disc_loss = 0.08833539344494026
Trained batch 723 in epoch 7, gen_loss = 0.8067067661091109, disc_loss = 0.08840404070903501
Trained batch 724 in epoch 7, gen_loss = 0.8065766976208523, disc_loss = 0.08844560179987858
Trained batch 725 in epoch 7, gen_loss = 0.8068437005288016, disc_loss = 0.08843402427777688
Trained batch 726 in epoch 7, gen_loss = 0.8064725690481588, disc_loss = 0.08852909329863576
Trained batch 727 in epoch 7, gen_loss = 0.806303643386115, disc_loss = 0.0885091037822089
Trained batch 728 in epoch 7, gen_loss = 0.8062598029527154, disc_loss = 0.08846317296298362
Trained batch 729 in epoch 7, gen_loss = 0.8064679720222133, disc_loss = 0.08864852179045955
Trained batch 730 in epoch 7, gen_loss = 0.8062566157160314, disc_loss = 0.08872418027376264
Trained batch 731 in epoch 7, gen_loss = 0.8065456629532283, disc_loss = 0.08868494866761924
Trained batch 732 in epoch 7, gen_loss = 0.8065538232762361, disc_loss = 0.08872171517558101
Trained batch 733 in epoch 7, gen_loss = 0.806230344588815, disc_loss = 0.08878353468271871
Trained batch 734 in epoch 7, gen_loss = 0.8060037008353642, disc_loss = 0.0888239410940279
Trained batch 735 in epoch 7, gen_loss = 0.8060795247311825, disc_loss = 0.08879745164228117
Trained batch 736 in epoch 7, gen_loss = 0.8060773676172849, disc_loss = 0.08887383094868714
Trained batch 737 in epoch 7, gen_loss = 0.8061642871720358, disc_loss = 0.088867360193454
Trained batch 738 in epoch 7, gen_loss = 0.8060311817429224, disc_loss = 0.08882265080003439
Trained batch 739 in epoch 7, gen_loss = 0.8058814710459193, disc_loss = 0.08881605912654383
Trained batch 740 in epoch 7, gen_loss = 0.8055371890264323, disc_loss = 0.0889120161327233
Trained batch 741 in epoch 7, gen_loss = 0.8059476854585894, disc_loss = 0.08902999261429287
Trained batch 742 in epoch 7, gen_loss = 0.8065881526566451, disc_loss = 0.08896949521013978
Trained batch 743 in epoch 7, gen_loss = 0.8063270825772516, disc_loss = 0.08897280179074295
Trained batch 744 in epoch 7, gen_loss = 0.805986925059517, disc_loss = 0.08907068410525786
Trained batch 745 in epoch 7, gen_loss = 0.8066006796209806, disc_loss = 0.08928670403335354
Trained batch 746 in epoch 7, gen_loss = 0.8065554749774166, disc_loss = 0.08921557143480184
Trained batch 747 in epoch 7, gen_loss = 0.8063378983082619, disc_loss = 0.08925611446337665
Trained batch 748 in epoch 7, gen_loss = 0.8064053036740052, disc_loss = 0.08919320152313989
Trained batch 749 in epoch 7, gen_loss = 0.8061420998970668, disc_loss = 0.08929373285422723
Trained batch 750 in epoch 7, gen_loss = 0.8058834365220584, disc_loss = 0.08927553575907582
Trained batch 751 in epoch 7, gen_loss = 0.8059475315298806, disc_loss = 0.08921081944557026
Trained batch 752 in epoch 7, gen_loss = 0.8060692364713585, disc_loss = 0.08912277439606696
Trained batch 753 in epoch 7, gen_loss = 0.8059091222934445, disc_loss = 0.08907446282266068
Trained batch 754 in epoch 7, gen_loss = 0.8056774099536289, disc_loss = 0.08901906036432611
Trained batch 755 in epoch 7, gen_loss = 0.8056192036580156, disc_loss = 0.08894662462204458
Trained batch 756 in epoch 7, gen_loss = 0.8056367903829723, disc_loss = 0.08888547589739137
Trained batch 757 in epoch 7, gen_loss = 0.8057988212495492, disc_loss = 0.0889430788657714
Trained batch 758 in epoch 7, gen_loss = 0.8055155334186805, disc_loss = 0.08907616321777874
Trained batch 759 in epoch 7, gen_loss = 0.8056383996025512, disc_loss = 0.08914233786053956
Trained batch 760 in epoch 7, gen_loss = 0.8058814141267859, disc_loss = 0.08920561970406152
Trained batch 761 in epoch 7, gen_loss = 0.8055913323570737, disc_loss = 0.08946706531349365
Trained batch 762 in epoch 7, gen_loss = 0.805289057377594, disc_loss = 0.08953902620192358
Trained batch 763 in epoch 7, gen_loss = 0.8053085017968847, disc_loss = 0.0897981437747196
Trained batch 764 in epoch 7, gen_loss = 0.8049731885296068, disc_loss = 0.08990544237293839
Trained batch 765 in epoch 7, gen_loss = 0.8050234678442111, disc_loss = 0.08985977429001746
Trained batch 766 in epoch 7, gen_loss = 0.8050319866764188, disc_loss = 0.09000162939350406
Trained batch 767 in epoch 7, gen_loss = 0.8048152724513784, disc_loss = 0.08999046804334891
Trained batch 768 in epoch 7, gen_loss = 0.8046895193883129, disc_loss = 0.08997813024847576
Trained batch 769 in epoch 7, gen_loss = 0.8050256880459847, disc_loss = 0.08990914176956012
Trained batch 770 in epoch 7, gen_loss = 0.8049345878852789, disc_loss = 0.08989335690056072
Trained batch 771 in epoch 7, gen_loss = 0.8047024295351666, disc_loss = 0.08995257949919822
Trained batch 772 in epoch 7, gen_loss = 0.8046265462314636, disc_loss = 0.08992726836512577
Trained batch 773 in epoch 7, gen_loss = 0.8044789615604613, disc_loss = 0.08990449501437349
Trained batch 774 in epoch 7, gen_loss = 0.804679869105739, disc_loss = 0.08985031712199411
Trained batch 775 in epoch 7, gen_loss = 0.8043822001320186, disc_loss = 0.08985108136890706
Trained batch 776 in epoch 7, gen_loss = 0.8042854713887322, disc_loss = 0.08979296191155603
Trained batch 777 in epoch 7, gen_loss = 0.8042656968139438, disc_loss = 0.08975538274555786
Trained batch 778 in epoch 7, gen_loss = 0.8043074351143623, disc_loss = 0.08970884820243132
Trained batch 779 in epoch 7, gen_loss = 0.80437864756737, disc_loss = 0.08962029411385838
Trained batch 780 in epoch 7, gen_loss = 0.8041777690531502, disc_loss = 0.08958822140343745
Trained batch 781 in epoch 7, gen_loss = 0.8041617104693142, disc_loss = 0.08952231753541304
Trained batch 782 in epoch 7, gen_loss = 0.8042256563787716, disc_loss = 0.08951676366458222
Trained batch 783 in epoch 7, gen_loss = 0.803893497365774, disc_loss = 0.08959226951487742
Trained batch 784 in epoch 7, gen_loss = 0.8041747346425512, disc_loss = 0.08958838025618131
Trained batch 785 in epoch 7, gen_loss = 0.8041867798445486, disc_loss = 0.08950134466518352
Trained batch 786 in epoch 7, gen_loss = 0.8043071808248493, disc_loss = 0.08947252103729882
Trained batch 787 in epoch 7, gen_loss = 0.8044083518954703, disc_loss = 0.08937804691900078
Trained batch 788 in epoch 7, gen_loss = 0.8042303024967058, disc_loss = 0.08935764386390628
Trained batch 789 in epoch 7, gen_loss = 0.8044157894729059, disc_loss = 0.08932968673025128
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.9744284152984619, disc_loss = 0.03184448927640915
Trained batch 1 in epoch 8, gen_loss = 0.9243285059928894, disc_loss = 0.02092008199542761
Trained batch 2 in epoch 8, gen_loss = 0.8536673982938131, disc_loss = 0.022828086589773495
Trained batch 3 in epoch 8, gen_loss = 0.769825279712677, disc_loss = 0.060173026751726866
Trained batch 4 in epoch 8, gen_loss = 0.8375997543334961, disc_loss = 0.07364396415650845
Trained batch 5 in epoch 8, gen_loss = 0.8413971960544586, disc_loss = 0.06966945249587297
Trained batch 6 in epoch 8, gen_loss = 0.7942725505147662, disc_loss = 0.0847496259957552
Trained batch 7 in epoch 8, gen_loss = 0.8218493983149529, disc_loss = 0.07567752315662801
Trained batch 8 in epoch 8, gen_loss = 0.8692509796884325, disc_loss = 0.08795777273674805
Trained batch 9 in epoch 8, gen_loss = 0.8667866230010987, disc_loss = 0.08463392462581396
Trained batch 10 in epoch 8, gen_loss = 0.8319705535065044, disc_loss = 0.11064455641264265
Trained batch 11 in epoch 8, gen_loss = 0.8199640239278475, disc_loss = 0.11242574127390981
Trained batch 12 in epoch 8, gen_loss = 0.8458255735727457, disc_loss = 0.11721852808617629
Trained batch 13 in epoch 8, gen_loss = 0.83408622443676, disc_loss = 0.11339525066848312
Trained batch 14 in epoch 8, gen_loss = 0.825195990006129, disc_loss = 0.11187175350884597
Trained batch 15 in epoch 8, gen_loss = 0.8225719910115004, disc_loss = 0.11031772976275533
Trained batch 16 in epoch 8, gen_loss = 0.8050999553764567, disc_loss = 0.11693190158728291
Trained batch 17 in epoch 8, gen_loss = 0.8092492868502935, disc_loss = 0.1159712178632617
Trained batch 18 in epoch 8, gen_loss = 0.808427947132211, disc_loss = 0.1122783831271686
Trained batch 19 in epoch 8, gen_loss = 0.808789698779583, disc_loss = 0.11113040605559946
Trained batch 20 in epoch 8, gen_loss = 0.8141485324927739, disc_loss = 0.10763982053668726
Trained batch 21 in epoch 8, gen_loss = 0.8110537190328945, disc_loss = 0.10967426789416508
Trained batch 22 in epoch 8, gen_loss = 0.8059157923511837, disc_loss = 0.10737651060132877
Trained batch 23 in epoch 8, gen_loss = 0.8203599266707897, disc_loss = 0.1104820891438673
Trained batch 24 in epoch 8, gen_loss = 0.8229834353923797, disc_loss = 0.10738179571926594
Trained batch 25 in epoch 8, gen_loss = 0.8125221030070231, disc_loss = 0.10953802278695199
Trained batch 26 in epoch 8, gen_loss = 0.8025672777935311, disc_loss = 0.10954094188356842
Trained batch 27 in epoch 8, gen_loss = 0.8041856661438942, disc_loss = 0.1106277712886887
Trained batch 28 in epoch 8, gen_loss = 0.8019044512304766, disc_loss = 0.10849701003010931
Trained batch 29 in epoch 8, gen_loss = 0.8015042791763941, disc_loss = 0.10647604335099459
Trained batch 30 in epoch 8, gen_loss = 0.7953360936334056, disc_loss = 0.10664317630712063
Trained batch 31 in epoch 8, gen_loss = 0.7924503805115819, disc_loss = 0.10499605064978823
Trained batch 32 in epoch 8, gen_loss = 0.7909059750311302, disc_loss = 0.10272405065144553
Trained batch 33 in epoch 8, gen_loss = 0.7910101141999749, disc_loss = 0.10120930166586357
Trained batch 34 in epoch 8, gen_loss = 0.7903720200061798, disc_loss = 0.10016074388154915
Trained batch 35 in epoch 8, gen_loss = 0.8000374924805429, disc_loss = 0.097977582210054
Trained batch 36 in epoch 8, gen_loss = 0.8025147004707439, disc_loss = 0.09837084731741531
Trained batch 37 in epoch 8, gen_loss = 0.7994424253702164, disc_loss = 0.0979421523546702
Trained batch 38 in epoch 8, gen_loss = 0.7961597312719394, disc_loss = 0.09895338237476654
Trained batch 39 in epoch 8, gen_loss = 0.7901588283479214, disc_loss = 0.09882492781616747
Trained batch 40 in epoch 8, gen_loss = 0.7889573421420121, disc_loss = 0.09746714685929984
Trained batch 41 in epoch 8, gen_loss = 0.7877971437715349, disc_loss = 0.09592803084247169
Trained batch 42 in epoch 8, gen_loss = 0.7907400734202806, disc_loss = 0.09712181201334609
Trained batch 43 in epoch 8, gen_loss = 0.7893802273002538, disc_loss = 0.09602276849645106
Trained batch 44 in epoch 8, gen_loss = 0.7860889163282182, disc_loss = 0.09561041829486688
Trained batch 45 in epoch 8, gen_loss = 0.788349182061527, disc_loss = 0.09387476357590893
Trained batch 46 in epoch 8, gen_loss = 0.79482379809339, disc_loss = 0.09310282612259084
Trained batch 47 in epoch 8, gen_loss = 0.7939293788125118, disc_loss = 0.09190719586331397
Trained batch 48 in epoch 8, gen_loss = 0.7949172349608674, disc_loss = 0.09067345680478885
Trained batch 49 in epoch 8, gen_loss = 0.7966459602117538, disc_loss = 0.0891867946088314
Trained batch 50 in epoch 8, gen_loss = 0.7945876314359552, disc_loss = 0.08845062276311949
Trained batch 51 in epoch 8, gen_loss = 0.7984023397931685, disc_loss = 0.08690843801014125
Trained batch 52 in epoch 8, gen_loss = 0.7998023466119226, disc_loss = 0.08569417111927045
Trained batch 53 in epoch 8, gen_loss = 0.797386771550885, disc_loss = 0.08563770979849829
Trained batch 54 in epoch 8, gen_loss = 0.7976556274023923, disc_loss = 0.08463645653629845
Trained batch 55 in epoch 8, gen_loss = 0.8019610531628132, disc_loss = 0.08342245289324117
Trained batch 56 in epoch 8, gen_loss = 0.8063656170117227, disc_loss = 0.08226268151938393
Trained batch 57 in epoch 8, gen_loss = 0.8055135170961248, disc_loss = 0.08147731161644232
Trained batch 58 in epoch 8, gen_loss = 0.8045111424842123, disc_loss = 0.08116682803542433
Trained batch 59 in epoch 8, gen_loss = 0.8075581555565198, disc_loss = 0.08247055903387567
Trained batch 60 in epoch 8, gen_loss = 0.8114199330572223, disc_loss = 0.08139611931792537
Trained batch 61 in epoch 8, gen_loss = 0.8090398085694159, disc_loss = 0.0822540848936525
Trained batch 62 in epoch 8, gen_loss = 0.8092816978219955, disc_loss = 0.08229432543296189
Trained batch 63 in epoch 8, gen_loss = 0.8082593181170523, disc_loss = 0.08160462275554892
Trained batch 64 in epoch 8, gen_loss = 0.8115156269990481, disc_loss = 0.08260971994067613
Trained batch 65 in epoch 8, gen_loss = 0.8107206473747889, disc_loss = 0.082444001991076
Trained batch 66 in epoch 8, gen_loss = 0.8097124548990335, disc_loss = 0.0827066724730739
Trained batch 67 in epoch 8, gen_loss = 0.8124841000227367, disc_loss = 0.08177329806665726
Trained batch 68 in epoch 8, gen_loss = 0.8127875556980354, disc_loss = 0.08164349380556656
Trained batch 69 in epoch 8, gen_loss = 0.8126575738191605, disc_loss = 0.08083794490833368
Trained batch 70 in epoch 8, gen_loss = 0.8142948901989091, disc_loss = 0.08005605731159449
Trained batch 71 in epoch 8, gen_loss = 0.8155725097490681, disc_loss = 0.07976480334117594
Trained batch 72 in epoch 8, gen_loss = 0.8104244858434756, disc_loss = 0.08339363141368104
Trained batch 73 in epoch 8, gen_loss = 0.8127209765685571, disc_loss = 0.08282207323842354
Trained batch 74 in epoch 8, gen_loss = 0.8155787607034047, disc_loss = 0.08330263116707405
Trained batch 75 in epoch 8, gen_loss = 0.8157695935744989, disc_loss = 0.08259400562383235
Trained batch 76 in epoch 8, gen_loss = 0.818255126863331, disc_loss = 0.08181168355483126
Trained batch 77 in epoch 8, gen_loss = 0.8178192717142594, disc_loss = 0.08107507105868979
Trained batch 78 in epoch 8, gen_loss = 0.8191875479643858, disc_loss = 0.08148354000730228
Trained batch 79 in epoch 8, gen_loss = 0.8155746851116419, disc_loss = 0.08328331495868042
Trained batch 80 in epoch 8, gen_loss = 0.8142938595495106, disc_loss = 0.08264509525242043
Trained batch 81 in epoch 8, gen_loss = 0.8223567601384186, disc_loss = 0.08383430523525287
Trained batch 82 in epoch 8, gen_loss = 0.8206228186567146, disc_loss = 0.08451797464211662
Trained batch 83 in epoch 8, gen_loss = 0.8182870053819248, disc_loss = 0.08582217921502888
Trained batch 84 in epoch 8, gen_loss = 0.8195679738241084, disc_loss = 0.08698791266583344
Trained batch 85 in epoch 8, gen_loss = 0.8203051454106043, disc_loss = 0.08686301927623707
Trained batch 86 in epoch 8, gen_loss = 0.8194098996705023, disc_loss = 0.08714141843348057
Trained batch 87 in epoch 8, gen_loss = 0.819077326154167, disc_loss = 0.08677760377229954
Trained batch 88 in epoch 8, gen_loss = 0.8175789295287614, disc_loss = 0.08789051015432296
Trained batch 89 in epoch 8, gen_loss = 0.8179672131935756, disc_loss = 0.08794758792759644
Trained batch 90 in epoch 8, gen_loss = 0.8159509494409456, disc_loss = 0.08800490537228492
Trained batch 91 in epoch 8, gen_loss = 0.8168244449340779, disc_loss = 0.0875892481746395
Trained batch 92 in epoch 8, gen_loss = 0.8167442721064373, disc_loss = 0.08693892535783591
Trained batch 93 in epoch 8, gen_loss = 0.8147535904290828, disc_loss = 0.08702730636132207
Trained batch 94 in epoch 8, gen_loss = 0.8155911756189246, disc_loss = 0.08666110265215761
Trained batch 95 in epoch 8, gen_loss = 0.8146411810691158, disc_loss = 0.08633351883812186
Trained batch 96 in epoch 8, gen_loss = 0.8163482660485297, disc_loss = 0.08570994458823782
Trained batch 97 in epoch 8, gen_loss = 0.8177677487232247, disc_loss = 0.08536459774501165
Trained batch 98 in epoch 8, gen_loss = 0.8178783218667964, disc_loss = 0.08535074430395558
Trained batch 99 in epoch 8, gen_loss = 0.8147162774205208, disc_loss = 0.08882097418420017
Trained batch 100 in epoch 8, gen_loss = 0.8135195501370005, disc_loss = 0.0890212189129526
Trained batch 101 in epoch 8, gen_loss = 0.8159189157041848, disc_loss = 0.08945367035145561
Trained batch 102 in epoch 8, gen_loss = 0.8158265407224303, disc_loss = 0.08894493231025424
Trained batch 103 in epoch 8, gen_loss = 0.815286375868779, disc_loss = 0.08884191286499397
Trained batch 104 in epoch 8, gen_loss = 0.8166282202516283, disc_loss = 0.08815196279791139
Trained batch 105 in epoch 8, gen_loss = 0.8130601543300556, disc_loss = 0.08921927406083581
Trained batch 106 in epoch 8, gen_loss = 0.812942537748925, disc_loss = 0.08920133903309285
Trained batch 107 in epoch 8, gen_loss = 0.8141791803969277, disc_loss = 0.08876751162353214
Trained batch 108 in epoch 8, gen_loss = 0.8153594196389574, disc_loss = 0.08855424164324452
Trained batch 109 in epoch 8, gen_loss = 0.814780368046327, disc_loss = 0.08815247036347335
Trained batch 110 in epoch 8, gen_loss = 0.8143368062672315, disc_loss = 0.08762529828829003
Trained batch 111 in epoch 8, gen_loss = 0.8134393441889968, disc_loss = 0.08735831428618569
Trained batch 112 in epoch 8, gen_loss = 0.8149506317830719, disc_loss = 0.08687527755489655
Trained batch 113 in epoch 8, gen_loss = 0.8155296356008764, disc_loss = 0.08755951257945414
Trained batch 114 in epoch 8, gen_loss = 0.8157269731811855, disc_loss = 0.08704664711233066
Trained batch 115 in epoch 8, gen_loss = 0.8146868281323334, disc_loss = 0.08700290673155466
Trained batch 116 in epoch 8, gen_loss = 0.8135877761066469, disc_loss = 0.0869887300934165
Trained batch 117 in epoch 8, gen_loss = 0.8156746378389456, disc_loss = 0.08660537987095067
Trained batch 118 in epoch 8, gen_loss = 0.816217269216265, disc_loss = 0.0866615445814839
Trained batch 119 in epoch 8, gen_loss = 0.8147984519600868, disc_loss = 0.08695542890733729
Trained batch 120 in epoch 8, gen_loss = 0.8162743306357013, disc_loss = 0.08643822049460381
Trained batch 121 in epoch 8, gen_loss = 0.8152092748978099, disc_loss = 0.08647054975058456
Trained batch 122 in epoch 8, gen_loss = 0.8164772221712562, disc_loss = 0.08679609513288833
Trained batch 123 in epoch 8, gen_loss = 0.8149193371495893, disc_loss = 0.08687835340688546
Trained batch 124 in epoch 8, gen_loss = 0.8165485305786133, disc_loss = 0.08712595794349909
Trained batch 125 in epoch 8, gen_loss = 0.8159120186926827, disc_loss = 0.08682955027602259
Trained batch 126 in epoch 8, gen_loss = 0.8164738604402918, disc_loss = 0.08639556959300763
Trained batch 127 in epoch 8, gen_loss = 0.8140631024725735, disc_loss = 0.08690403533546487
Trained batch 128 in epoch 8, gen_loss = 0.8153760049694269, disc_loss = 0.08697915415806595
Trained batch 129 in epoch 8, gen_loss = 0.816930620945417, disc_loss = 0.08678902929935317
Trained batch 130 in epoch 8, gen_loss = 0.8155805909906635, disc_loss = 0.08742573326240287
Trained batch 131 in epoch 8, gen_loss = 0.8150913218657175, disc_loss = 0.08747633544474163
Trained batch 132 in epoch 8, gen_loss = 0.8169561104666918, disc_loss = 0.08742926732629985
Trained batch 133 in epoch 8, gen_loss = 0.8176636775927757, disc_loss = 0.0869868093225827
Trained batch 134 in epoch 8, gen_loss = 0.8163925978872512, disc_loss = 0.08690298433519072
Trained batch 135 in epoch 8, gen_loss = 0.8163912427776, disc_loss = 0.08649756416322335
Trained batch 136 in epoch 8, gen_loss = 0.817872518170489, disc_loss = 0.08634618231278919
Trained batch 137 in epoch 8, gen_loss = 0.8176107259764187, disc_loss = 0.08590527234491015
Trained batch 138 in epoch 8, gen_loss = 0.8174140727777275, disc_loss = 0.08544427230820167
Trained batch 139 in epoch 8, gen_loss = 0.8166369097573417, disc_loss = 0.08537622034948851
Trained batch 140 in epoch 8, gen_loss = 0.8191506355366809, disc_loss = 0.08506147454472933
Trained batch 141 in epoch 8, gen_loss = 0.8187016987464797, disc_loss = 0.08470163687827512
Trained batch 142 in epoch 8, gen_loss = 0.8173557132274121, disc_loss = 0.0845762157187491
Trained batch 143 in epoch 8, gen_loss = 0.816219070305427, disc_loss = 0.08461441450829928
Trained batch 144 in epoch 8, gen_loss = 0.8169022921858162, disc_loss = 0.0853877224734631
Trained batch 145 in epoch 8, gen_loss = 0.8166339466833088, disc_loss = 0.08630256956341127
Trained batch 146 in epoch 8, gen_loss = 0.8141275794327665, disc_loss = 0.08694620247372761
Trained batch 147 in epoch 8, gen_loss = 0.8120239091080588, disc_loss = 0.08739306001823295
Trained batch 148 in epoch 8, gen_loss = 0.812996243070436, disc_loss = 0.08723296429461881
Trained batch 149 in epoch 8, gen_loss = 0.8133994487921397, disc_loss = 0.08682094081615409
Trained batch 150 in epoch 8, gen_loss = 0.8131959051485883, disc_loss = 0.08646624586514093
Trained batch 151 in epoch 8, gen_loss = 0.8122094955883528, disc_loss = 0.08638702614208389
Trained batch 152 in epoch 8, gen_loss = 0.8141635220035229, disc_loss = 0.08618448184669213
Trained batch 153 in epoch 8, gen_loss = 0.8141687671085457, disc_loss = 0.08578876567423924
Trained batch 154 in epoch 8, gen_loss = 0.8134756715066971, disc_loss = 0.08559064090612435
Trained batch 155 in epoch 8, gen_loss = 0.8131184383080556, disc_loss = 0.08555373482000178
Trained batch 156 in epoch 8, gen_loss = 0.8112385485582291, disc_loss = 0.0858261949637798
Trained batch 157 in epoch 8, gen_loss = 0.8106462525416024, disc_loss = 0.0856488508973978
Trained batch 158 in epoch 8, gen_loss = 0.8156595874882344, disc_loss = 0.08739871346046152
Trained batch 159 in epoch 8, gen_loss = 0.8151498533785343, disc_loss = 0.08723316310788505
Trained batch 160 in epoch 8, gen_loss = 0.814990332407981, disc_loss = 0.08692775418553848
Trained batch 161 in epoch 8, gen_loss = 0.8150739691875599, disc_loss = 0.0865627507403217
Trained batch 162 in epoch 8, gen_loss = 0.8149324275233263, disc_loss = 0.08642263540803838
Trained batch 163 in epoch 8, gen_loss = 0.8141055336085762, disc_loss = 0.08633466473235409
Trained batch 164 in epoch 8, gen_loss = 0.8154034285834342, disc_loss = 0.08711437943645499
Trained batch 165 in epoch 8, gen_loss = 0.8145706635641764, disc_loss = 0.087410837047206
Trained batch 166 in epoch 8, gen_loss = 0.8135812171918904, disc_loss = 0.08738396061907806
Trained batch 167 in epoch 8, gen_loss = 0.8143640696292832, disc_loss = 0.08710088181154181
Trained batch 168 in epoch 8, gen_loss = 0.8155137833053544, disc_loss = 0.08688826507960375
Trained batch 169 in epoch 8, gen_loss = 0.815681105852127, disc_loss = 0.08686077403562034
Trained batch 170 in epoch 8, gen_loss = 0.8145764292332164, disc_loss = 0.08704305620461006
Trained batch 171 in epoch 8, gen_loss = 0.8136996782796327, disc_loss = 0.08688868284983517
Trained batch 172 in epoch 8, gen_loss = 0.8145288866379358, disc_loss = 0.08713449991571938
Trained batch 173 in epoch 8, gen_loss = 0.8150196044609465, disc_loss = 0.08713990931088726
Trained batch 174 in epoch 8, gen_loss = 0.8140562977109637, disc_loss = 0.08687488970479795
Trained batch 175 in epoch 8, gen_loss = 0.8136627555570819, disc_loss = 0.08661284392424436
Trained batch 176 in epoch 8, gen_loss = 0.8129956819916849, disc_loss = 0.08683631878009455
Trained batch 177 in epoch 8, gen_loss = 0.8167679058701804, disc_loss = 0.08697442887769488
Trained batch 178 in epoch 8, gen_loss = 0.8150912733051364, disc_loss = 0.08705016868136949
Trained batch 179 in epoch 8, gen_loss = 0.8154357075691223, disc_loss = 0.08670134285154442
Trained batch 180 in epoch 8, gen_loss = 0.8160880231066961, disc_loss = 0.08664460539385595
Trained batch 181 in epoch 8, gen_loss = 0.81636716736542, disc_loss = 0.08626676304265857
Trained batch 182 in epoch 8, gen_loss = 0.8148343826903671, disc_loss = 0.08660823410590653
Trained batch 183 in epoch 8, gen_loss = 0.8168617814131405, disc_loss = 0.08646745711018372
Trained batch 184 in epoch 8, gen_loss = 0.8176225717003281, disc_loss = 0.08622934850989966
Trained batch 185 in epoch 8, gen_loss = 0.8165928923314617, disc_loss = 0.08610012038280407
Trained batch 186 in epoch 8, gen_loss = 0.8177027170033379, disc_loss = 0.08572621936884953
Trained batch 187 in epoch 8, gen_loss = 0.8186672726210128, disc_loss = 0.08544982885050172
Trained batch 188 in epoch 8, gen_loss = 0.8189468891532333, disc_loss = 0.0851506556201943
Trained batch 189 in epoch 8, gen_loss = 0.8180970904074217, disc_loss = 0.08495531374784676
Trained batch 190 in epoch 8, gen_loss = 0.8175688947682606, disc_loss = 0.08506374278091167
Trained batch 191 in epoch 8, gen_loss = 0.8177942400798202, disc_loss = 0.08473000188920803
Trained batch 192 in epoch 8, gen_loss = 0.8173943341087183, disc_loss = 0.08458815063856581
Trained batch 193 in epoch 8, gen_loss = 0.81503053685439, disc_loss = 0.0853833217874707
Trained batch 194 in epoch 8, gen_loss = 0.8163554076965038, disc_loss = 0.08577186729376897
Trained batch 195 in epoch 8, gen_loss = 0.8160699862910776, disc_loss = 0.0854949931452545
Trained batch 196 in epoch 8, gen_loss = 0.8156108785099184, disc_loss = 0.08553334545381934
Trained batch 197 in epoch 8, gen_loss = 0.8160173099751424, disc_loss = 0.08532177984733323
Trained batch 198 in epoch 8, gen_loss = 0.8155966956711295, disc_loss = 0.08501557279939777
Trained batch 199 in epoch 8, gen_loss = 0.8154557575285435, disc_loss = 0.08503833298105747
Trained batch 200 in epoch 8, gen_loss = 0.8150324799231629, disc_loss = 0.0848677677903973
Trained batch 201 in epoch 8, gen_loss = 0.8147432950168553, disc_loss = 0.08472951444898649
Trained batch 202 in epoch 8, gen_loss = 0.8145643286223482, disc_loss = 0.08463666388498885
Trained batch 203 in epoch 8, gen_loss = 0.8142260881323441, disc_loss = 0.08459901775452583
Trained batch 204 in epoch 8, gen_loss = 0.8131261704898463, disc_loss = 0.08496518369945812
Trained batch 205 in epoch 8, gen_loss = 0.8133493281394533, disc_loss = 0.08468417642023233
Trained batch 206 in epoch 8, gen_loss = 0.8140015954844617, disc_loss = 0.08463010317443506
Trained batch 207 in epoch 8, gen_loss = 0.8136587883703984, disc_loss = 0.08446290323851056
Trained batch 208 in epoch 8, gen_loss = 0.8129829626049151, disc_loss = 0.08458798365783321
Trained batch 209 in epoch 8, gen_loss = 0.8134695116962706, disc_loss = 0.08460752071280564
Trained batch 210 in epoch 8, gen_loss = 0.8132551491825502, disc_loss = 0.08454638279497764
Trained batch 211 in epoch 8, gen_loss = 0.8138730018487517, disc_loss = 0.0847702171644723
Trained batch 212 in epoch 8, gen_loss = 0.8129717348047265, disc_loss = 0.0849352344791864
Trained batch 213 in epoch 8, gen_loss = 0.8130861923237828, disc_loss = 0.08470839324241905
Trained batch 214 in epoch 8, gen_loss = 0.8125803419323855, disc_loss = 0.08474930060031109
Trained batch 215 in epoch 8, gen_loss = 0.8115701014520945, disc_loss = 0.08488283326625135
Trained batch 216 in epoch 8, gen_loss = 0.8119354238433223, disc_loss = 0.08467495090795964
Trained batch 217 in epoch 8, gen_loss = 0.8120174294491427, disc_loss = 0.08451855913607763
Trained batch 218 in epoch 8, gen_loss = 0.8127641646557202, disc_loss = 0.08430937503689909
Trained batch 219 in epoch 8, gen_loss = 0.8123821555213495, disc_loss = 0.08419010537168518
Trained batch 220 in epoch 8, gen_loss = 0.8116834167711335, disc_loss = 0.08434352096237613
Trained batch 221 in epoch 8, gen_loss = 0.8120604964258434, disc_loss = 0.0853450450635104
Trained batch 222 in epoch 8, gen_loss = 0.8109971283529906, disc_loss = 0.08569650732465256
Trained batch 223 in epoch 8, gen_loss = 0.8112011686233538, disc_loss = 0.08611376929080247
Trained batch 224 in epoch 8, gen_loss = 0.8099436014228397, disc_loss = 0.0865071548976832
Trained batch 225 in epoch 8, gen_loss = 0.8098739009779111, disc_loss = 0.08703342897290017
Trained batch 226 in epoch 8, gen_loss = 0.8090360481045845, disc_loss = 0.08749188134438535
Trained batch 227 in epoch 8, gen_loss = 0.8097727462126497, disc_loss = 0.08740319585705404
Trained batch 228 in epoch 8, gen_loss = 0.8087283889539377, disc_loss = 0.08770493668093302
Trained batch 229 in epoch 8, gen_loss = 0.8100404243106427, disc_loss = 0.08785334582157109
Trained batch 230 in epoch 8, gen_loss = 0.8103406409938614, disc_loss = 0.087658347259578
Trained batch 231 in epoch 8, gen_loss = 0.8094771716358333, disc_loss = 0.08772345097205633
Trained batch 232 in epoch 8, gen_loss = 0.8093150929575826, disc_loss = 0.08759410042603512
Trained batch 233 in epoch 8, gen_loss = 0.8108282852121907, disc_loss = 0.0875075920803361
Trained batch 234 in epoch 8, gen_loss = 0.8096150922014358, disc_loss = 0.08794630705279873
Trained batch 235 in epoch 8, gen_loss = 0.8092002453187764, disc_loss = 0.08790115367668538
Trained batch 236 in epoch 8, gen_loss = 0.8099427991527043, disc_loss = 0.08787086473597128
Trained batch 237 in epoch 8, gen_loss = 0.8090005425595436, disc_loss = 0.08791340749413401
Trained batch 238 in epoch 8, gen_loss = 0.8091527212364404, disc_loss = 0.08779839640989837
Trained batch 239 in epoch 8, gen_loss = 0.8093792588760456, disc_loss = 0.08758539033976073
Trained batch 240 in epoch 8, gen_loss = 0.8097499815507548, disc_loss = 0.08754945763954854
Trained batch 241 in epoch 8, gen_loss = 0.8093107774976857, disc_loss = 0.08745000241632181
Trained batch 242 in epoch 8, gen_loss = 0.8081952378828339, disc_loss = 0.08776670480875198
Trained batch 243 in epoch 8, gen_loss = 0.8097717562904123, disc_loss = 0.08792121312581003
Trained batch 244 in epoch 8, gen_loss = 0.8103174600065971, disc_loss = 0.08770197386264193
Trained batch 245 in epoch 8, gen_loss = 0.8096312784809407, disc_loss = 0.08767902665975981
Trained batch 246 in epoch 8, gen_loss = 0.8103125902563937, disc_loss = 0.0875481196946883
Trained batch 247 in epoch 8, gen_loss = 0.8094801432903735, disc_loss = 0.08771845806134684
Trained batch 248 in epoch 8, gen_loss = 0.8087768091494778, disc_loss = 0.08772126354471627
Trained batch 249 in epoch 8, gen_loss = 0.8094361983537673, disc_loss = 0.08801176726445556
Trained batch 250 in epoch 8, gen_loss = 0.8091598256413205, disc_loss = 0.08798991345180815
Trained batch 251 in epoch 8, gen_loss = 0.8086778546373049, disc_loss = 0.08785513421476242
Trained batch 252 in epoch 8, gen_loss = 0.8086335827475009, disc_loss = 0.08776627262693502
Trained batch 253 in epoch 8, gen_loss = 0.8101252480520038, disc_loss = 0.08788398406504998
Trained batch 254 in epoch 8, gen_loss = 0.8096682351009519, disc_loss = 0.0876687920816681
Trained batch 255 in epoch 8, gen_loss = 0.809632788063027, disc_loss = 0.08789871158296592
Trained batch 256 in epoch 8, gen_loss = 0.8104056070055016, disc_loss = 0.08761927307536282
Trained batch 257 in epoch 8, gen_loss = 0.8104933191870534, disc_loss = 0.08786984095927472
Trained batch 258 in epoch 8, gen_loss = 0.8109725505458802, disc_loss = 0.08758643812151144
Trained batch 259 in epoch 8, gen_loss = 0.811881562265066, disc_loss = 0.08761340238225575
Trained batch 260 in epoch 8, gen_loss = 0.8107344500178122, disc_loss = 0.08793341561481072
Trained batch 261 in epoch 8, gen_loss = 0.8104933082829905, disc_loss = 0.08884835660187457
Trained batch 262 in epoch 8, gen_loss = 0.8103030044089705, disc_loss = 0.08870503578703326
Trained batch 263 in epoch 8, gen_loss = 0.8096496199793888, disc_loss = 0.08872128842807742
Trained batch 264 in epoch 8, gen_loss = 0.8092134377866421, disc_loss = 0.08865263552387367
Trained batch 265 in epoch 8, gen_loss = 0.8083987873523755, disc_loss = 0.08868883054745488
Trained batch 266 in epoch 8, gen_loss = 0.8086493532086133, disc_loss = 0.0885208762017138
Trained batch 267 in epoch 8, gen_loss = 0.8085481719072185, disc_loss = 0.08830134422212506
Trained batch 268 in epoch 8, gen_loss = 0.8088085346727123, disc_loss = 0.08813240830907702
Trained batch 269 in epoch 8, gen_loss = 0.8091461736846853, disc_loss = 0.08797045023421998
Trained batch 270 in epoch 8, gen_loss = 0.8094536852352734, disc_loss = 0.08772411902960926
Trained batch 271 in epoch 8, gen_loss = 0.809109646060011, disc_loss = 0.08760942356072038
Trained batch 272 in epoch 8, gen_loss = 0.808728039155513, disc_loss = 0.08746908598616993
Trained batch 273 in epoch 8, gen_loss = 0.8089069002953759, disc_loss = 0.08724266377338855
Trained batch 274 in epoch 8, gen_loss = 0.8102068555355072, disc_loss = 0.08714191982353275
Trained batch 275 in epoch 8, gen_loss = 0.8094226706071176, disc_loss = 0.08726215544426678
Trained batch 276 in epoch 8, gen_loss = 0.8103142035351764, disc_loss = 0.08758026123087222
Trained batch 277 in epoch 8, gen_loss = 0.8099810372796847, disc_loss = 0.08738552636580824
Trained batch 278 in epoch 8, gen_loss = 0.8096218163608223, disc_loss = 0.08720501343716323
Trained batch 279 in epoch 8, gen_loss = 0.8094330452382564, disc_loss = 0.08711432425770908
Trained batch 280 in epoch 8, gen_loss = 0.8093310260475742, disc_loss = 0.08692606459984895
Trained batch 281 in epoch 8, gen_loss = 0.8096366830117313, disc_loss = 0.08674926959070647
Trained batch 282 in epoch 8, gen_loss = 0.8103469034176412, disc_loss = 0.08652484814830572
Trained batch 283 in epoch 8, gen_loss = 0.8104375085570443, disc_loss = 0.08650882854651083
Trained batch 284 in epoch 8, gen_loss = 0.8106578535155247, disc_loss = 0.08628453411357967
Trained batch 285 in epoch 8, gen_loss = 0.8107892742732188, disc_loss = 0.08615331331241902
Trained batch 286 in epoch 8, gen_loss = 0.8107052793278512, disc_loss = 0.0859994778007217
Trained batch 287 in epoch 8, gen_loss = 0.8111826540488336, disc_loss = 0.08594168029635006
Trained batch 288 in epoch 8, gen_loss = 0.8111226877332971, disc_loss = 0.0857158089701125
Trained batch 289 in epoch 8, gen_loss = 0.8114024058498185, disc_loss = 0.08555411659502264
Trained batch 290 in epoch 8, gen_loss = 0.8111485315557198, disc_loss = 0.08557456894697704
Trained batch 291 in epoch 8, gen_loss = 0.8119858763601682, disc_loss = 0.08589620545366142
Trained batch 292 in epoch 8, gen_loss = 0.8116541068505102, disc_loss = 0.08579138327237384
Trained batch 293 in epoch 8, gen_loss = 0.8109523904364125, disc_loss = 0.08580284739597416
Trained batch 294 in epoch 8, gen_loss = 0.8125735285928694, disc_loss = 0.08613455605266963
Trained batch 295 in epoch 8, gen_loss = 0.8118812742869597, disc_loss = 0.08640120154863375
Trained batch 296 in epoch 8, gen_loss = 0.8116837413824769, disc_loss = 0.086410915626445
Trained batch 297 in epoch 8, gen_loss = 0.8122520015743755, disc_loss = 0.08653533820300394
Trained batch 298 in epoch 8, gen_loss = 0.8117541749541177, disc_loss = 0.08661292918512355
Trained batch 299 in epoch 8, gen_loss = 0.8114339181780815, disc_loss = 0.08647863118909299
Trained batch 300 in epoch 8, gen_loss = 0.812721927003607, disc_loss = 0.08650688531551745
Trained batch 301 in epoch 8, gen_loss = 0.8126245473591697, disc_loss = 0.08631997849385174
Trained batch 302 in epoch 8, gen_loss = 0.8121823740280895, disc_loss = 0.08647687135958927
Trained batch 303 in epoch 8, gen_loss = 0.8125243264397508, disc_loss = 0.08633932578193612
Trained batch 304 in epoch 8, gen_loss = 0.8130884114836083, disc_loss = 0.08632599659203018
Trained batch 305 in epoch 8, gen_loss = 0.8130783753262626, disc_loss = 0.08619186943518667
Trained batch 306 in epoch 8, gen_loss = 0.8126912327659247, disc_loss = 0.08619116944737175
Trained batch 307 in epoch 8, gen_loss = 0.8138003435421299, disc_loss = 0.0861231500264741
Trained batch 308 in epoch 8, gen_loss = 0.8144909831119587, disc_loss = 0.08596546648064188
Trained batch 309 in epoch 8, gen_loss = 0.8135493631324461, disc_loss = 0.08616208856204344
Trained batch 310 in epoch 8, gen_loss = 0.8131180193838199, disc_loss = 0.08622651440885001
Trained batch 311 in epoch 8, gen_loss = 0.8137838600728756, disc_loss = 0.08615421285578169
Trained batch 312 in epoch 8, gen_loss = 0.8132998826214299, disc_loss = 0.0865877502696059
Trained batch 313 in epoch 8, gen_loss = 0.813632039602395, disc_loss = 0.0863917585919095
Trained batch 314 in epoch 8, gen_loss = 0.8151912084647588, disc_loss = 0.08703476731325425
Trained batch 315 in epoch 8, gen_loss = 0.8144689557861678, disc_loss = 0.0872853620573171
Trained batch 316 in epoch 8, gen_loss = 0.8143038107581695, disc_loss = 0.08718417005830853
Trained batch 317 in epoch 8, gen_loss = 0.814441869000219, disc_loss = 0.08758618227212028
Trained batch 318 in epoch 8, gen_loss = 0.8138527060190338, disc_loss = 0.08773997747470685
Trained batch 319 in epoch 8, gen_loss = 0.8140004717744886, disc_loss = 0.08759267636633013
Trained batch 320 in epoch 8, gen_loss = 0.8146358718196179, disc_loss = 0.08743150556906826
Trained batch 321 in epoch 8, gen_loss = 0.8151677825621196, disc_loss = 0.08737448595105583
Trained batch 322 in epoch 8, gen_loss = 0.8144565447011599, disc_loss = 0.08759341069753786
Trained batch 323 in epoch 8, gen_loss = 0.8149011261117312, disc_loss = 0.08738736942536945
Trained batch 324 in epoch 8, gen_loss = 0.8159079332535083, disc_loss = 0.08731177417991252
Trained batch 325 in epoch 8, gen_loss = 0.8163405224406646, disc_loss = 0.08711502185388485
Trained batch 326 in epoch 8, gen_loss = 0.8157552667531763, disc_loss = 0.0872762640767278
Trained batch 327 in epoch 8, gen_loss = 0.8154816181376213, disc_loss = 0.08733550157886362
Trained batch 328 in epoch 8, gen_loss = 0.8155362773630032, disc_loss = 0.08726220492749139
Trained batch 329 in epoch 8, gen_loss = 0.8148074490554404, disc_loss = 0.08726289106081381
Trained batch 330 in epoch 8, gen_loss = 0.8147523411271075, disc_loss = 0.08724533445469113
Trained batch 331 in epoch 8, gen_loss = 0.8146544783768883, disc_loss = 0.08723247664733734
Trained batch 332 in epoch 8, gen_loss = 0.8146167781438913, disc_loss = 0.0871194832826833
Trained batch 333 in epoch 8, gen_loss = 0.8147877853609131, disc_loss = 0.08698159570855919
Trained batch 334 in epoch 8, gen_loss = 0.8143615410399081, disc_loss = 0.08683858149921271
Trained batch 335 in epoch 8, gen_loss = 0.8146017684290806, disc_loss = 0.08669020136585459
Trained batch 336 in epoch 8, gen_loss = 0.8143239639456265, disc_loss = 0.0865925331448014
Trained batch 337 in epoch 8, gen_loss = 0.814192443645212, disc_loss = 0.08648599036996799
Trained batch 338 in epoch 8, gen_loss = 0.8148847080789133, disc_loss = 0.08633247226377767
Trained batch 339 in epoch 8, gen_loss = 0.8147898413679179, disc_loss = 0.08619757927680279
Trained batch 340 in epoch 8, gen_loss = 0.8142730082409823, disc_loss = 0.086148860318111
Trained batch 341 in epoch 8, gen_loss = 0.8147878253843353, disc_loss = 0.08607148729558838
Trained batch 342 in epoch 8, gen_loss = 0.8152763587219027, disc_loss = 0.08625218791088887
Trained batch 343 in epoch 8, gen_loss = 0.8152289523114992, disc_loss = 0.08625616823853709
Trained batch 344 in epoch 8, gen_loss = 0.815053226377653, disc_loss = 0.0861004232685419
Trained batch 345 in epoch 8, gen_loss = 0.8152330485899324, disc_loss = 0.08598751658466079
Trained batch 346 in epoch 8, gen_loss = 0.8145756500770448, disc_loss = 0.08605681507652277
Trained batch 347 in epoch 8, gen_loss = 0.8146127798947794, disc_loss = 0.08587997287629578
Trained batch 348 in epoch 8, gen_loss = 0.8141891998172148, disc_loss = 0.08585937556818683
Trained batch 349 in epoch 8, gen_loss = 0.8137343487569264, disc_loss = 0.0861255300124841
Trained batch 350 in epoch 8, gen_loss = 0.8136540275183838, disc_loss = 0.08616183268070815
Trained batch 351 in epoch 8, gen_loss = 0.8133949726311998, disc_loss = 0.08614138637362471
Trained batch 352 in epoch 8, gen_loss = 0.8138875112823994, disc_loss = 0.08618528871578046
Trained batch 353 in epoch 8, gen_loss = 0.8140040845689127, disc_loss = 0.08607672382998517
Trained batch 354 in epoch 8, gen_loss = 0.8132404052875412, disc_loss = 0.08631059612134392
Trained batch 355 in epoch 8, gen_loss = 0.8140211179852486, disc_loss = 0.08620362485800817
Trained batch 356 in epoch 8, gen_loss = 0.8143439004902079, disc_loss = 0.08611546463857428
Trained batch 357 in epoch 8, gen_loss = 0.8139897544124273, disc_loss = 0.08596974363363238
Trained batch 358 in epoch 8, gen_loss = 0.8140996230511944, disc_loss = 0.08583263341794024
Trained batch 359 in epoch 8, gen_loss = 0.814021477351586, disc_loss = 0.08568401846569032
Trained batch 360 in epoch 8, gen_loss = 0.8134954430555043, disc_loss = 0.08567453430413458
Trained batch 361 in epoch 8, gen_loss = 0.8140986221765286, disc_loss = 0.08549028646602239
Trained batch 362 in epoch 8, gen_loss = 0.8139204886169802, disc_loss = 0.08553233193926328
Trained batch 363 in epoch 8, gen_loss = 0.8135263984511186, disc_loss = 0.08543043879659049
Trained batch 364 in epoch 8, gen_loss = 0.8145219687729666, disc_loss = 0.08538788021478343
Trained batch 365 in epoch 8, gen_loss = 0.8147040158510208, disc_loss = 0.0851945840102198
Trained batch 366 in epoch 8, gen_loss = 0.814094280433265, disc_loss = 0.08548641550717545
Trained batch 367 in epoch 8, gen_loss = 0.8139531700669423, disc_loss = 0.08537528588709867
Trained batch 368 in epoch 8, gen_loss = 0.8152516434993847, disc_loss = 0.08564194255233376
Trained batch 369 in epoch 8, gen_loss = 0.8145673174310375, disc_loss = 0.08567592892040675
Trained batch 370 in epoch 8, gen_loss = 0.815004102223003, disc_loss = 0.08556547146190129
Trained batch 371 in epoch 8, gen_loss = 0.8145944262223859, disc_loss = 0.08568429457955062
Trained batch 372 in epoch 8, gen_loss = 0.8146357990941158, disc_loss = 0.08569554025532014
Trained batch 373 in epoch 8, gen_loss = 0.8149881529457429, disc_loss = 0.08555190778900197
Trained batch 374 in epoch 8, gen_loss = 0.8146536413033804, disc_loss = 0.08559560096015532
Trained batch 375 in epoch 8, gen_loss = 0.8149125334271725, disc_loss = 0.08569485121258
Trained batch 376 in epoch 8, gen_loss = 0.8152019025001981, disc_loss = 0.08579471126070311
Trained batch 377 in epoch 8, gen_loss = 0.8144680290783524, disc_loss = 0.08624691941662047
Trained batch 378 in epoch 8, gen_loss = 0.8150032941930212, disc_loss = 0.0862445603628547
Trained batch 379 in epoch 8, gen_loss = 0.8146196389668866, disc_loss = 0.08620790842871524
Trained batch 380 in epoch 8, gen_loss = 0.8155049303854545, disc_loss = 0.08610600403942696
Trained batch 381 in epoch 8, gen_loss = 0.8152048393537861, disc_loss = 0.08612223453966032
Trained batch 382 in epoch 8, gen_loss = 0.8153814808040002, disc_loss = 0.08596683185372511
Trained batch 383 in epoch 8, gen_loss = 0.8148657208463798, disc_loss = 0.0860111047780568
Trained batch 384 in epoch 8, gen_loss = 0.8154443961459321, disc_loss = 0.08634813364788696
Trained batch 385 in epoch 8, gen_loss = 0.8146598871044545, disc_loss = 0.08665212285053467
Trained batch 386 in epoch 8, gen_loss = 0.8145448644801936, disc_loss = 0.08657072252264242
Trained batch 387 in epoch 8, gen_loss = 0.8156807530940193, disc_loss = 0.08662464193874951
Trained batch 388 in epoch 8, gen_loss = 0.8152399131295613, disc_loss = 0.08658405964844561
Trained batch 389 in epoch 8, gen_loss = 0.8149097159122809, disc_loss = 0.08655424789310648
Trained batch 390 in epoch 8, gen_loss = 0.8150510849702693, disc_loss = 0.086472632661176
Trained batch 391 in epoch 8, gen_loss = 0.8144455601518251, disc_loss = 0.0867440061410889
Trained batch 392 in epoch 8, gen_loss = 0.8149883004696922, disc_loss = 0.08681901634147073
Trained batch 393 in epoch 8, gen_loss = 0.8146497090607125, disc_loss = 0.08697509452426419
Trained batch 394 in epoch 8, gen_loss = 0.8137796552875374, disc_loss = 0.08704648922091421
Trained batch 395 in epoch 8, gen_loss = 0.8142039273122345, disc_loss = 0.08704049157853605
Trained batch 396 in epoch 8, gen_loss = 0.8140964481031865, disc_loss = 0.08698593777010888
Trained batch 397 in epoch 8, gen_loss = 0.81361100407102, disc_loss = 0.08696125738612896
Trained batch 398 in epoch 8, gen_loss = 0.813101471516124, disc_loss = 0.08701503240178925
Trained batch 399 in epoch 8, gen_loss = 0.813231036067009, disc_loss = 0.08690282109891996
Trained batch 400 in epoch 8, gen_loss = 0.8138907252999018, disc_loss = 0.08687927716753058
Trained batch 401 in epoch 8, gen_loss = 0.8135158535259873, disc_loss = 0.08693974333310231
Trained batch 402 in epoch 8, gen_loss = 0.8133012230875475, disc_loss = 0.08690040454813845
Trained batch 403 in epoch 8, gen_loss = 0.8133176507631151, disc_loss = 0.08685348407678896
Trained batch 404 in epoch 8, gen_loss = 0.8133781731864552, disc_loss = 0.08678043811915466
Trained batch 405 in epoch 8, gen_loss = 0.8130737077720059, disc_loss = 0.08684529595104565
Trained batch 406 in epoch 8, gen_loss = 0.8128939637095102, disc_loss = 0.08675895290591133
Trained batch 407 in epoch 8, gen_loss = 0.8131175878293374, disc_loss = 0.08661767714154706
Trained batch 408 in epoch 8, gen_loss = 0.8131136419137708, disc_loss = 0.08648955923776099
Trained batch 409 in epoch 8, gen_loss = 0.8129536342330095, disc_loss = 0.08641201306543336
Trained batch 410 in epoch 8, gen_loss = 0.8125972009633289, disc_loss = 0.08684455360220224
Trained batch 411 in epoch 8, gen_loss = 0.8119448077620812, disc_loss = 0.08688091377962778
Trained batch 412 in epoch 8, gen_loss = 0.8117577058351069, disc_loss = 0.08681789507579789
Trained batch 413 in epoch 8, gen_loss = 0.8122023515367277, disc_loss = 0.08693713386844537
Trained batch 414 in epoch 8, gen_loss = 0.8118419236447437, disc_loss = 0.08691963009222085
Trained batch 415 in epoch 8, gen_loss = 0.8117200488654467, disc_loss = 0.08694731495835675
Trained batch 416 in epoch 8, gen_loss = 0.8116223440467597, disc_loss = 0.08687890405661697
Trained batch 417 in epoch 8, gen_loss = 0.8114306065454437, disc_loss = 0.08680023348101518
Trained batch 418 in epoch 8, gen_loss = 0.8117957721177604, disc_loss = 0.08692723771152676
Trained batch 419 in epoch 8, gen_loss = 0.8123765386286236, disc_loss = 0.08681034450862735
Trained batch 420 in epoch 8, gen_loss = 0.8120016427334584, disc_loss = 0.08675654311918801
Trained batch 421 in epoch 8, gen_loss = 0.8120028055957144, disc_loss = 0.08673588989602658
Trained batch 422 in epoch 8, gen_loss = 0.8119996111161883, disc_loss = 0.08666610806502278
Trained batch 423 in epoch 8, gen_loss = 0.8117988707040841, disc_loss = 0.08662395383767292
Trained batch 424 in epoch 8, gen_loss = 0.8120416909105638, disc_loss = 0.08649026939316708
Trained batch 425 in epoch 8, gen_loss = 0.8116163565239436, disc_loss = 0.08654370374251769
Trained batch 426 in epoch 8, gen_loss = 0.8114061851132949, disc_loss = 0.08655211697845115
Trained batch 427 in epoch 8, gen_loss = 0.8124711974480442, disc_loss = 0.08660366762403364
Trained batch 428 in epoch 8, gen_loss = 0.8129233234412186, disc_loss = 0.08650341645829675
Trained batch 429 in epoch 8, gen_loss = 0.8126102260378905, disc_loss = 0.08659141313414588
Trained batch 430 in epoch 8, gen_loss = 0.8122872872031759, disc_loss = 0.08659798154291933
Trained batch 431 in epoch 8, gen_loss = 0.8121566976662036, disc_loss = 0.08681427930800796
Trained batch 432 in epoch 8, gen_loss = 0.8122290789943369, disc_loss = 0.08667244296951121
Trained batch 433 in epoch 8, gen_loss = 0.8121443971785532, disc_loss = 0.08658298475169984
Trained batch 434 in epoch 8, gen_loss = 0.8128330911713085, disc_loss = 0.08672733946821128
Trained batch 435 in epoch 8, gen_loss = 0.812623690711249, disc_loss = 0.08672895592876599
Trained batch 436 in epoch 8, gen_loss = 0.8122043406390489, disc_loss = 0.08673196934905218
Trained batch 437 in epoch 8, gen_loss = 0.8122724715160997, disc_loss = 0.08684085458559601
Trained batch 438 in epoch 8, gen_loss = 0.8129070737910433, disc_loss = 0.08679858698023818
Trained batch 439 in epoch 8, gen_loss = 0.8126285735856403, disc_loss = 0.08680502368687568
Trained batch 440 in epoch 8, gen_loss = 0.8126962812038776, disc_loss = 0.08667537213309484
Trained batch 441 in epoch 8, gen_loss = 0.8128305793617645, disc_loss = 0.08653501838622657
Trained batch 442 in epoch 8, gen_loss = 0.8125790462536951, disc_loss = 0.08647376870101582
Trained batch 443 in epoch 8, gen_loss = 0.813072509056813, disc_loss = 0.08688197445401268
Trained batch 444 in epoch 8, gen_loss = 0.8131871784670969, disc_loss = 0.08684761548686898
Trained batch 445 in epoch 8, gen_loss = 0.8125747018598121, disc_loss = 0.08708794008430945
Trained batch 446 in epoch 8, gen_loss = 0.8130135884220968, disc_loss = 0.08707327575066545
Trained batch 447 in epoch 8, gen_loss = 0.8131529070170862, disc_loss = 0.08690941393017836
Trained batch 448 in epoch 8, gen_loss = 0.8125922434314057, disc_loss = 0.08688980702078489
Trained batch 449 in epoch 8, gen_loss = 0.8125791537761688, disc_loss = 0.08678032915832268
Trained batch 450 in epoch 8, gen_loss = 0.8124841874560337, disc_loss = 0.08676617753850978
Trained batch 451 in epoch 8, gen_loss = 0.812294057248968, disc_loss = 0.0868540097427744
Trained batch 452 in epoch 8, gen_loss = 0.8121981760260811, disc_loss = 0.08676237806422887
Trained batch 453 in epoch 8, gen_loss = 0.8118389668968806, disc_loss = 0.08678208525592075
Trained batch 454 in epoch 8, gen_loss = 0.8119709918787191, disc_loss = 0.08674264005948226
Trained batch 455 in epoch 8, gen_loss = 0.8126323664920372, disc_loss = 0.08667380099078607
Trained batch 456 in epoch 8, gen_loss = 0.8124134753152109, disc_loss = 0.0865973111026038
Trained batch 457 in epoch 8, gen_loss = 0.8127791638197337, disc_loss = 0.0865156918735646
Trained batch 458 in epoch 8, gen_loss = 0.8127788422154445, disc_loss = 0.08637870304603008
Trained batch 459 in epoch 8, gen_loss = 0.8127470795227134, disc_loss = 0.08632665943232891
Trained batch 460 in epoch 8, gen_loss = 0.8123350563638898, disc_loss = 0.08649449951647742
Trained batch 461 in epoch 8, gen_loss = 0.8131423808021463, disc_loss = 0.08650531101512252
Trained batch 462 in epoch 8, gen_loss = 0.8134414736447015, disc_loss = 0.08639562455233243
Trained batch 463 in epoch 8, gen_loss = 0.8132360653373701, disc_loss = 0.0863353127055673
Trained batch 464 in epoch 8, gen_loss = 0.8135483869942286, disc_loss = 0.08618569280952215
Trained batch 465 in epoch 8, gen_loss = 0.8138496490762981, disc_loss = 0.08622060202725647
Trained batch 466 in epoch 8, gen_loss = 0.8140419317006554, disc_loss = 0.08606852916502085
Trained batch 467 in epoch 8, gen_loss = 0.8135304146597528, disc_loss = 0.08630813696445563
Trained batch 468 in epoch 8, gen_loss = 0.8130740483940792, disc_loss = 0.0862946395776165
Trained batch 469 in epoch 8, gen_loss = 0.8135560096578395, disc_loss = 0.0862781582360572
Trained batch 470 in epoch 8, gen_loss = 0.8138558001528373, disc_loss = 0.0861316776563534
Trained batch 471 in epoch 8, gen_loss = 0.8144294440241183, disc_loss = 0.08600562368124975
Trained batch 472 in epoch 8, gen_loss = 0.8143390074340788, disc_loss = 0.08607160003095803
Trained batch 473 in epoch 8, gen_loss = 0.8135628202293492, disc_loss = 0.08626833785215259
Trained batch 474 in epoch 8, gen_loss = 0.8140911062140214, disc_loss = 0.08616637587547302
Trained batch 475 in epoch 8, gen_loss = 0.8140112144105575, disc_loss = 0.08612165302664292
Trained batch 476 in epoch 8, gen_loss = 0.8145859816289298, disc_loss = 0.08613566557566325
Trained batch 477 in epoch 8, gen_loss = 0.8143798030569962, disc_loss = 0.08603484464895027
Trained batch 478 in epoch 8, gen_loss = 0.8137349806150465, disc_loss = 0.0861678634359966
Trained batch 479 in epoch 8, gen_loss = 0.8135178377230962, disc_loss = 0.08609532110082606
Trained batch 480 in epoch 8, gen_loss = 0.8139364446770873, disc_loss = 0.08605442289069389
Trained batch 481 in epoch 8, gen_loss = 0.8139077036707233, disc_loss = 0.08598617675300703
Trained batch 482 in epoch 8, gen_loss = 0.8130802387529772, disc_loss = 0.08639839221385942
Trained batch 483 in epoch 8, gen_loss = 0.8130963072796499, disc_loss = 0.0864172812997679
Trained batch 484 in epoch 8, gen_loss = 0.8138409688300693, disc_loss = 0.08645108456617778
Trained batch 485 in epoch 8, gen_loss = 0.8136787404739317, disc_loss = 0.08637273931730186
Trained batch 486 in epoch 8, gen_loss = 0.813026061293036, disc_loss = 0.0865871646581122
Trained batch 487 in epoch 8, gen_loss = 0.8133053338674249, disc_loss = 0.08656149975131036
Trained batch 488 in epoch 8, gen_loss = 0.8136037074958864, disc_loss = 0.08669872774698739
Trained batch 489 in epoch 8, gen_loss = 0.8133493067050467, disc_loss = 0.08660240561834404
Trained batch 490 in epoch 8, gen_loss = 0.8130796591764555, disc_loss = 0.08662024467364106
Trained batch 491 in epoch 8, gen_loss = 0.8128975855141152, disc_loss = 0.08649314974805689
Trained batch 492 in epoch 8, gen_loss = 0.8129677054364589, disc_loss = 0.08639174532787554
Trained batch 493 in epoch 8, gen_loss = 0.8139157613761995, disc_loss = 0.08658490362407466
Trained batch 494 in epoch 8, gen_loss = 0.8140067872374949, disc_loss = 0.08644988472488793
Trained batch 495 in epoch 8, gen_loss = 0.8134791801773733, disc_loss = 0.0864918607084321
Trained batch 496 in epoch 8, gen_loss = 0.8129839704070293, disc_loss = 0.08654081601447143
Trained batch 497 in epoch 8, gen_loss = 0.8135411546651619, disc_loss = 0.08654433667255812
Trained batch 498 in epoch 8, gen_loss = 0.8145431728066805, disc_loss = 0.08654069626155143
Trained batch 499 in epoch 8, gen_loss = 0.8140769101381302, disc_loss = 0.08653954947367311
Trained batch 500 in epoch 8, gen_loss = 0.8134535434479248, disc_loss = 0.08675155338427859
Trained batch 501 in epoch 8, gen_loss = 0.8137863780635287, disc_loss = 0.0869140316030953
Trained batch 502 in epoch 8, gen_loss = 0.8137647528534618, disc_loss = 0.0868375031518237
Trained batch 503 in epoch 8, gen_loss = 0.8137786999817879, disc_loss = 0.0867031717687727
Trained batch 504 in epoch 8, gen_loss = 0.8133411432256793, disc_loss = 0.0867563029400783
Trained batch 505 in epoch 8, gen_loss = 0.8133907997796658, disc_loss = 0.08662780602517807
Trained batch 506 in epoch 8, gen_loss = 0.8131185162232002, disc_loss = 0.08660015506445774
Trained batch 507 in epoch 8, gen_loss = 0.8138596970499969, disc_loss = 0.0865300622233373
Trained batch 508 in epoch 8, gen_loss = 0.8138588205536128, disc_loss = 0.08641881396177944
Trained batch 509 in epoch 8, gen_loss = 0.813604714122473, disc_loss = 0.08634346212972613
Trained batch 510 in epoch 8, gen_loss = 0.8138900810958355, disc_loss = 0.0862392824354587
Trained batch 511 in epoch 8, gen_loss = 0.813892750767991, disc_loss = 0.08618454424868105
Trained batch 512 in epoch 8, gen_loss = 0.8140828188864576, disc_loss = 0.0860531073804313
Trained batch 513 in epoch 8, gen_loss = 0.8149516441014955, disc_loss = 0.08611001374729065
Trained batch 514 in epoch 8, gen_loss = 0.8151647456641337, disc_loss = 0.08598990484131772
Trained batch 515 in epoch 8, gen_loss = 0.8149004248223564, disc_loss = 0.08602178126010437
Trained batch 516 in epoch 8, gen_loss = 0.8147472566285493, disc_loss = 0.08602402871204413
Trained batch 517 in epoch 8, gen_loss = 0.8148340300933735, disc_loss = 0.08619577653749223
Trained batch 518 in epoch 8, gen_loss = 0.814661226176113, disc_loss = 0.08616834593603032
Trained batch 519 in epoch 8, gen_loss = 0.8144616442231032, disc_loss = 0.08612643374631611
Trained batch 520 in epoch 8, gen_loss = 0.8140167687767527, disc_loss = 0.08620087918602001
Trained batch 521 in epoch 8, gen_loss = 0.8146148147025785, disc_loss = 0.0861666911527857
Trained batch 522 in epoch 8, gen_loss = 0.8147189219412795, disc_loss = 0.08632763988386491
Trained batch 523 in epoch 8, gen_loss = 0.8144871442372562, disc_loss = 0.0862429581532781
Trained batch 524 in epoch 8, gen_loss = 0.8141252290634882, disc_loss = 0.08624470871474062
Trained batch 525 in epoch 8, gen_loss = 0.8144623105743539, disc_loss = 0.08613272373893868
Trained batch 526 in epoch 8, gen_loss = 0.8139189295117272, disc_loss = 0.08632148830555875
Trained batch 527 in epoch 8, gen_loss = 0.8146772733466192, disc_loss = 0.08670669932369933
Trained batch 528 in epoch 8, gen_loss = 0.8145106696226195, disc_loss = 0.08666618520460868
Trained batch 529 in epoch 8, gen_loss = 0.8141949704233206, disc_loss = 0.08661684703152135
Trained batch 530 in epoch 8, gen_loss = 0.8144306411401925, disc_loss = 0.086522169074433
Trained batch 531 in epoch 8, gen_loss = 0.814554573673951, disc_loss = 0.08639653761612069
Trained batch 532 in epoch 8, gen_loss = 0.8150595258816545, disc_loss = 0.0865486839097727
Trained batch 533 in epoch 8, gen_loss = 0.8144784644525149, disc_loss = 0.08680981448555038
Trained batch 534 in epoch 8, gen_loss = 0.8145352255518191, disc_loss = 0.08682476845439349
Trained batch 535 in epoch 8, gen_loss = 0.8147535238470605, disc_loss = 0.08670380764376762
Trained batch 536 in epoch 8, gen_loss = 0.8143770001010078, disc_loss = 0.08669926387082709
Trained batch 537 in epoch 8, gen_loss = 0.8142207454349915, disc_loss = 0.08667408018528751
Trained batch 538 in epoch 8, gen_loss = 0.8145875341374711, disc_loss = 0.08657690679485147
Trained batch 539 in epoch 8, gen_loss = 0.8142120082069326, disc_loss = 0.08656887995700041
Trained batch 540 in epoch 8, gen_loss = 0.8139566134613234, disc_loss = 0.08655156178637485
Trained batch 541 in epoch 8, gen_loss = 0.8137049208707915, disc_loss = 0.08651867181722528
Trained batch 542 in epoch 8, gen_loss = 0.8137954358237883, disc_loss = 0.0865884033575462
Trained batch 543 in epoch 8, gen_loss = 0.8135714718305013, disc_loss = 0.0865199962795219
Trained batch 544 in epoch 8, gen_loss = 0.8137354994038923, disc_loss = 0.08639604510107171
Trained batch 545 in epoch 8, gen_loss = 0.8136176107785641, disc_loss = 0.08628730344562194
Trained batch 546 in epoch 8, gen_loss = 0.8142379094085485, disc_loss = 0.08617026920701076
Trained batch 547 in epoch 8, gen_loss = 0.813966338325591, disc_loss = 0.08617515272603635
Trained batch 548 in epoch 8, gen_loss = 0.8137818128684831, disc_loss = 0.08618466627320957
Trained batch 549 in epoch 8, gen_loss = 0.8134681904315948, disc_loss = 0.08615371305156838
Trained batch 550 in epoch 8, gen_loss = 0.813659440692237, disc_loss = 0.08613650830033254
Trained batch 551 in epoch 8, gen_loss = 0.8138956643533015, disc_loss = 0.08603187872137388
Trained batch 552 in epoch 8, gen_loss = 0.8138187051250534, disc_loss = 0.08595255568663962
Trained batch 553 in epoch 8, gen_loss = 0.8136207566794936, disc_loss = 0.08586949550812317
Trained batch 554 in epoch 8, gen_loss = 0.8134139226363586, disc_loss = 0.08583991895052227
Trained batch 555 in epoch 8, gen_loss = 0.8135104062531492, disc_loss = 0.08584828765580443
Trained batch 556 in epoch 8, gen_loss = 0.8133883985625563, disc_loss = 0.08575630608337464
Trained batch 557 in epoch 8, gen_loss = 0.8134494933389849, disc_loss = 0.08595304549287831
Trained batch 558 in epoch 8, gen_loss = 0.8133118656965402, disc_loss = 0.08589890972113033
Trained batch 559 in epoch 8, gen_loss = 0.8128777575279985, disc_loss = 0.08586339753320707
Trained batch 560 in epoch 8, gen_loss = 0.8122640867284275, disc_loss = 0.0860175996348129
Trained batch 561 in epoch 8, gen_loss = 0.8124927099913465, disc_loss = 0.08618837835936678
Trained batch 562 in epoch 8, gen_loss = 0.8131244180469276, disc_loss = 0.08613301770262037
Trained batch 563 in epoch 8, gen_loss = 0.8130879552229077, disc_loss = 0.08613026689354938
Trained batch 564 in epoch 8, gen_loss = 0.8126025700991133, disc_loss = 0.0862713439043908
Trained batch 565 in epoch 8, gen_loss = 0.8130908082946872, disc_loss = 0.08627803308079711
Trained batch 566 in epoch 8, gen_loss = 0.8129102501499169, disc_loss = 0.08622604727784478
Trained batch 567 in epoch 8, gen_loss = 0.8130046900519183, disc_loss = 0.08624105644412339
Trained batch 568 in epoch 8, gen_loss = 0.8132095314915864, disc_loss = 0.08612751351220956
Trained batch 569 in epoch 8, gen_loss = 0.812642120478446, disc_loss = 0.08621244951429075
Trained batch 570 in epoch 8, gen_loss = 0.8123718458382762, disc_loss = 0.08617968696141827
Trained batch 571 in epoch 8, gen_loss = 0.8125822718118454, disc_loss = 0.08626060722513007
Trained batch 572 in epoch 8, gen_loss = 0.8126555234973968, disc_loss = 0.08615859367447477
Trained batch 573 in epoch 8, gen_loss = 0.8128346758229392, disc_loss = 0.08625369503094656
Trained batch 574 in epoch 8, gen_loss = 0.8126448510004126, disc_loss = 0.0862278491485378
Trained batch 575 in epoch 8, gen_loss = 0.8123101219534874, disc_loss = 0.08624040812396237
Trained batch 576 in epoch 8, gen_loss = 0.8125235286494474, disc_loss = 0.08620750587401295
Trained batch 577 in epoch 8, gen_loss = 0.8126703453311458, disc_loss = 0.08610168916969253
Trained batch 578 in epoch 8, gen_loss = 0.8124545442007984, disc_loss = 0.08605424220479112
Trained batch 579 in epoch 8, gen_loss = 0.8124283328138548, disc_loss = 0.08603090168265946
Trained batch 580 in epoch 8, gen_loss = 0.8127743235553604, disc_loss = 0.08597662293780178
Trained batch 581 in epoch 8, gen_loss = 0.8125910182384282, disc_loss = 0.08593904236299578
Trained batch 582 in epoch 8, gen_loss = 0.8125911434764109, disc_loss = 0.08582485894357872
Trained batch 583 in epoch 8, gen_loss = 0.8131025959163496, disc_loss = 0.08575674875843504
Trained batch 584 in epoch 8, gen_loss = 0.8135038293324984, disc_loss = 0.08565045033191514
Trained batch 585 in epoch 8, gen_loss = 0.8131139286549018, disc_loss = 0.0856222100015539
Trained batch 586 in epoch 8, gen_loss = 0.8128250514425248, disc_loss = 0.08557930074987562
Trained batch 587 in epoch 8, gen_loss = 0.8131154871919528, disc_loss = 0.0857013598698996
Trained batch 588 in epoch 8, gen_loss = 0.8127833424683135, disc_loss = 0.08569678158541992
Trained batch 589 in epoch 8, gen_loss = 0.8125832765789355, disc_loss = 0.08574632289109088
Trained batch 590 in epoch 8, gen_loss = 0.8122421855047067, disc_loss = 0.08577059799657154
Trained batch 591 in epoch 8, gen_loss = 0.8127476229659609, disc_loss = 0.08573468379688927
Trained batch 592 in epoch 8, gen_loss = 0.8130841161710215, disc_loss = 0.08575648687855289
Trained batch 593 in epoch 8, gen_loss = 0.8123840198974417, disc_loss = 0.08617789020153509
Trained batch 594 in epoch 8, gen_loss = 0.812566315426546, disc_loss = 0.0860975751825491
Trained batch 595 in epoch 8, gen_loss = 0.8129104137820685, disc_loss = 0.08637688198633142
Trained batch 596 in epoch 8, gen_loss = 0.8125453736115141, disc_loss = 0.08644242117640062
Trained batch 597 in epoch 8, gen_loss = 0.8125455295760496, disc_loss = 0.08636081113128061
Trained batch 598 in epoch 8, gen_loss = 0.8126080182438502, disc_loss = 0.08628133355091032
Trained batch 599 in epoch 8, gen_loss = 0.8124874452749888, disc_loss = 0.08619646977943679
Trained batch 600 in epoch 8, gen_loss = 0.8127404542611958, disc_loss = 0.08613461421216884
Trained batch 601 in epoch 8, gen_loss = 0.81279735856278, disc_loss = 0.08602034333053717
Trained batch 602 in epoch 8, gen_loss = 0.8132723721105661, disc_loss = 0.08591978432947328
Trained batch 603 in epoch 8, gen_loss = 0.8128821941598362, disc_loss = 0.08597394295456197
Trained batch 604 in epoch 8, gen_loss = 0.8128208234290446, disc_loss = 0.08588846868350486
Trained batch 605 in epoch 8, gen_loss = 0.8132481076339684, disc_loss = 0.08583743476828333
Trained batch 606 in epoch 8, gen_loss = 0.8135586600916389, disc_loss = 0.08572149504117263
Trained batch 607 in epoch 8, gen_loss = 0.813454053707813, disc_loss = 0.08568582739252106
Trained batch 608 in epoch 8, gen_loss = 0.8131327630068085, disc_loss = 0.085755092527699
Trained batch 609 in epoch 8, gen_loss = 0.8128779820731429, disc_loss = 0.0857137344380627
Trained batch 610 in epoch 8, gen_loss = 0.8135609221926687, disc_loss = 0.08573642211818364
Trained batch 611 in epoch 8, gen_loss = 0.813276415069898, disc_loss = 0.08572130925113372
Trained batch 612 in epoch 8, gen_loss = 0.8132145786946594, disc_loss = 0.08565720110876428
Trained batch 613 in epoch 8, gen_loss = 0.8132653814961933, disc_loss = 0.08555835688711183
Trained batch 614 in epoch 8, gen_loss = 0.8130991523827964, disc_loss = 0.08558783148968123
Trained batch 615 in epoch 8, gen_loss = 0.8134392063532557, disc_loss = 0.08550296223105548
Trained batch 616 in epoch 8, gen_loss = 0.8134298497506054, disc_loss = 0.08539675441200768
Trained batch 617 in epoch 8, gen_loss = 0.8134863695859137, disc_loss = 0.08530288536559706
Trained batch 618 in epoch 8, gen_loss = 0.8136222070754056, disc_loss = 0.08519092624967915
Trained batch 619 in epoch 8, gen_loss = 0.8140646066396467, disc_loss = 0.08524426020261261
Trained batch 620 in epoch 8, gen_loss = 0.8135718188807968, disc_loss = 0.08551150767039657
Trained batch 621 in epoch 8, gen_loss = 0.8133813197398109, disc_loss = 0.0854395354478066
Trained batch 622 in epoch 8, gen_loss = 0.8135602036984353, disc_loss = 0.0853643056459689
Trained batch 623 in epoch 8, gen_loss = 0.8137828540534545, disc_loss = 0.0852491871591132
Trained batch 624 in epoch 8, gen_loss = 0.8136164364814759, disc_loss = 0.08519841615855694
Trained batch 625 in epoch 8, gen_loss = 0.813839138982395, disc_loss = 0.0850973181551495
Trained batch 626 in epoch 8, gen_loss = 0.81366013102174, disc_loss = 0.08505960863137074
Trained batch 627 in epoch 8, gen_loss = 0.8138608272857727, disc_loss = 0.08494881869910677
Trained batch 628 in epoch 8, gen_loss = 0.8141308426856995, disc_loss = 0.08483524407320826
Trained batch 629 in epoch 8, gen_loss = 0.8140676383934323, disc_loss = 0.0848161797438349
Trained batch 630 in epoch 8, gen_loss = 0.8143882123301789, disc_loss = 0.08470782928948074
Trained batch 631 in epoch 8, gen_loss = 0.8145181966733329, disc_loss = 0.08462669362337623
Trained batch 632 in epoch 8, gen_loss = 0.8143882342801086, disc_loss = 0.08456545397580423
Trained batch 633 in epoch 8, gen_loss = 0.8146019616525632, disc_loss = 0.08453500708300703
Trained batch 634 in epoch 8, gen_loss = 0.8143592591360798, disc_loss = 0.0845337567396286
Trained batch 635 in epoch 8, gen_loss = 0.8143630651932843, disc_loss = 0.08459583475728924
Trained batch 636 in epoch 8, gen_loss = 0.8143412836679671, disc_loss = 0.08452183924311278
Trained batch 637 in epoch 8, gen_loss = 0.8140925681889991, disc_loss = 0.08461129019871869
Trained batch 638 in epoch 8, gen_loss = 0.8140010857059735, disc_loss = 0.08453049731961158
Trained batch 639 in epoch 8, gen_loss = 0.8144228140823543, disc_loss = 0.08464314824377653
Trained batch 640 in epoch 8, gen_loss = 0.8141840297420757, disc_loss = 0.0846848484454168
Trained batch 641 in epoch 8, gen_loss = 0.814058651526769, disc_loss = 0.0847221968370574
Trained batch 642 in epoch 8, gen_loss = 0.8143768628500112, disc_loss = 0.08466502624631948
Trained batch 643 in epoch 8, gen_loss = 0.814505349682725, disc_loss = 0.08458750698750156
Trained batch 644 in epoch 8, gen_loss = 0.8143025987832121, disc_loss = 0.08453868124200854
Trained batch 645 in epoch 8, gen_loss = 0.8147356314555779, disc_loss = 0.08452963278032032
Trained batch 646 in epoch 8, gen_loss = 0.8147526018586373, disc_loss = 0.0844942519852929
Trained batch 647 in epoch 8, gen_loss = 0.8150931768763212, disc_loss = 0.08441629758921027
Trained batch 648 in epoch 8, gen_loss = 0.8149359319904369, disc_loss = 0.08442748451924012
Trained batch 649 in epoch 8, gen_loss = 0.8148567570172823, disc_loss = 0.08433456391382677
Trained batch 650 in epoch 8, gen_loss = 0.8151803267533145, disc_loss = 0.08426623935947129
Trained batch 651 in epoch 8, gen_loss = 0.815935671146662, disc_loss = 0.08425837739490749
Trained batch 652 in epoch 8, gen_loss = 0.8158349407577222, disc_loss = 0.08428986488369394
Trained batch 653 in epoch 8, gen_loss = 0.8156052865201909, disc_loss = 0.08425333179157535
Trained batch 654 in epoch 8, gen_loss = 0.8155081431374295, disc_loss = 0.08425631879452075
Trained batch 655 in epoch 8, gen_loss = 0.8156888031559747, disc_loss = 0.08421425438747264
Trained batch 656 in epoch 8, gen_loss = 0.8158167621497876, disc_loss = 0.0841135381178043
Trained batch 657 in epoch 8, gen_loss = 0.8157751893562386, disc_loss = 0.08404938620727476
Trained batch 658 in epoch 8, gen_loss = 0.8159360315803331, disc_loss = 0.08402555868911454
Trained batch 659 in epoch 8, gen_loss = 0.8161595125993093, disc_loss = 0.08391649848640417
Trained batch 660 in epoch 8, gen_loss = 0.8161379549759419, disc_loss = 0.08382913287385238
Trained batch 661 in epoch 8, gen_loss = 0.8166840535636395, disc_loss = 0.0837738098509137
Trained batch 662 in epoch 8, gen_loss = 0.8167590453973543, disc_loss = 0.08374520987665582
Trained batch 663 in epoch 8, gen_loss = 0.8165219205330654, disc_loss = 0.08375482947610498
Trained batch 664 in epoch 8, gen_loss = 0.8167767100764397, disc_loss = 0.08380086468742755
Trained batch 665 in epoch 8, gen_loss = 0.8166778541363038, disc_loss = 0.08373801532976173
Trained batch 666 in epoch 8, gen_loss = 0.8167074165422877, disc_loss = 0.08369505154373853
Trained batch 667 in epoch 8, gen_loss = 0.8163480906786319, disc_loss = 0.08383308537583241
Trained batch 668 in epoch 8, gen_loss = 0.8170560821111249, disc_loss = 0.08422010552600272
Trained batch 669 in epoch 8, gen_loss = 0.8174813768756923, disc_loss = 0.084137620087435
Trained batch 670 in epoch 8, gen_loss = 0.8174202681120746, disc_loss = 0.08414694015075481
Trained batch 671 in epoch 8, gen_loss = 0.8173447218501851, disc_loss = 0.08411929509159
Trained batch 672 in epoch 8, gen_loss = 0.816941073886707, disc_loss = 0.0842513542672146
Trained batch 673 in epoch 8, gen_loss = 0.8168036801524969, disc_loss = 0.08438084140773697
Trained batch 674 in epoch 8, gen_loss = 0.8170973768940678, disc_loss = 0.08433970736684622
Trained batch 675 in epoch 8, gen_loss = 0.8165742061899964, disc_loss = 0.08442724957378835
Trained batch 676 in epoch 8, gen_loss = 0.8164829183012203, disc_loss = 0.08440422418044448
Trained batch 677 in epoch 8, gen_loss = 0.8169818611974913, disc_loss = 0.08433459290360983
Trained batch 678 in epoch 8, gen_loss = 0.8171607451691719, disc_loss = 0.08425161006019638
Trained batch 679 in epoch 8, gen_loss = 0.81761923563831, disc_loss = 0.08420792821904316
Trained batch 680 in epoch 8, gen_loss = 0.8177296279460498, disc_loss = 0.08419316638912049
Trained batch 681 in epoch 8, gen_loss = 0.8173920853921046, disc_loss = 0.08418433036644263
Trained batch 682 in epoch 8, gen_loss = 0.8175665757142956, disc_loss = 0.08410351348176359
Trained batch 683 in epoch 8, gen_loss = 0.8174891186910763, disc_loss = 0.08406093174166847
Trained batch 684 in epoch 8, gen_loss = 0.8177457063737577, disc_loss = 0.0839795144750689
Trained batch 685 in epoch 8, gen_loss = 0.8180376672709996, disc_loss = 0.08389773012380558
Trained batch 686 in epoch 8, gen_loss = 0.8179872750021311, disc_loss = 0.08382122631806994
Trained batch 687 in epoch 8, gen_loss = 0.8183680811766968, disc_loss = 0.08373475971707511
Trained batch 688 in epoch 8, gen_loss = 0.8180596995422906, disc_loss = 0.08377340005870222
Trained batch 689 in epoch 8, gen_loss = 0.817965654100197, disc_loss = 0.08368511063087246
Trained batch 690 in epoch 8, gen_loss = 0.8182535800333478, disc_loss = 0.08364695302236357
Trained batch 691 in epoch 8, gen_loss = 0.8180961032651063, disc_loss = 0.0836084520664992
Trained batch 692 in epoch 8, gen_loss = 0.8178785221401231, disc_loss = 0.08355295098780467
Trained batch 693 in epoch 8, gen_loss = 0.8179258919758481, disc_loss = 0.08354240955156877
Trained batch 694 in epoch 8, gen_loss = 0.8179935759777646, disc_loss = 0.08347843405958132
Trained batch 695 in epoch 8, gen_loss = 0.8180321879770563, disc_loss = 0.08339738416292801
Trained batch 696 in epoch 8, gen_loss = 0.8185208859710474, disc_loss = 0.08330808317494529
Trained batch 697 in epoch 8, gen_loss = 0.818647620585723, disc_loss = 0.08321169479336472
Trained batch 698 in epoch 8, gen_loss = 0.8187024386143992, disc_loss = 0.08311862700241744
Trained batch 699 in epoch 8, gen_loss = 0.8189287958826338, disc_loss = 0.08315494822870408
Trained batch 700 in epoch 8, gen_loss = 0.8186230986842755, disc_loss = 0.0831492823308145
Trained batch 701 in epoch 8, gen_loss = 0.8181442202326239, disc_loss = 0.08322948859765744
Trained batch 702 in epoch 8, gen_loss = 0.8181777302265846, disc_loss = 0.08320192128133723
Trained batch 703 in epoch 8, gen_loss = 0.8182752794501457, disc_loss = 0.08318603923808868
Trained batch 704 in epoch 8, gen_loss = 0.8180644923068108, disc_loss = 0.08312691210485096
Trained batch 705 in epoch 8, gen_loss = 0.8179020167410205, disc_loss = 0.08313524187212709
Trained batch 706 in epoch 8, gen_loss = 0.8183602190759597, disc_loss = 0.08308304071458006
Trained batch 707 in epoch 8, gen_loss = 0.8184819160881689, disc_loss = 0.08308222711791342
Trained batch 708 in epoch 8, gen_loss = 0.818351548548646, disc_loss = 0.08303305111321055
Trained batch 709 in epoch 8, gen_loss = 0.818352550184223, disc_loss = 0.08294984781458764
Trained batch 710 in epoch 8, gen_loss = 0.8185113516705617, disc_loss = 0.08287080530071979
Trained batch 711 in epoch 8, gen_loss = 0.8185811799563719, disc_loss = 0.08279575401749671
Trained batch 712 in epoch 8, gen_loss = 0.8184226075863938, disc_loss = 0.08272738153896024
Trained batch 713 in epoch 8, gen_loss = 0.8186726408178399, disc_loss = 0.0826366306765198
Trained batch 714 in epoch 8, gen_loss = 0.8189148523590781, disc_loss = 0.08259147484558862
Trained batch 715 in epoch 8, gen_loss = 0.8188463005773182, disc_loss = 0.08268068940768944
Trained batch 716 in epoch 8, gen_loss = 0.8187109151312164, disc_loss = 0.08263977097199303
Trained batch 717 in epoch 8, gen_loss = 0.8191897619235482, disc_loss = 0.08310821746582357
Trained batch 718 in epoch 8, gen_loss = 0.8195041301187455, disc_loss = 0.08302024692058646
Trained batch 719 in epoch 8, gen_loss = 0.8190315326468812, disc_loss = 0.08309478206404795
Trained batch 720 in epoch 8, gen_loss = 0.8195471883068137, disc_loss = 0.08303711373467469
Trained batch 721 in epoch 8, gen_loss = 0.8200020437177858, disc_loss = 0.08310772991710835
Trained batch 722 in epoch 8, gen_loss = 0.8197406790480739, disc_loss = 0.08308996720030842
Trained batch 723 in epoch 8, gen_loss = 0.8196184288977918, disc_loss = 0.08310742279288272
Trained batch 724 in epoch 8, gen_loss = 0.8197640656191727, disc_loss = 0.08307047850869853
Trained batch 725 in epoch 8, gen_loss = 0.8196498879305916, disc_loss = 0.083145736136856
Trained batch 726 in epoch 8, gen_loss = 0.8193679447433152, disc_loss = 0.08315352057113198
Trained batch 727 in epoch 8, gen_loss = 0.8194879087527375, disc_loss = 0.08305891128103403
Trained batch 728 in epoch 8, gen_loss = 0.8194603369314484, disc_loss = 0.08300309805825495
Trained batch 729 in epoch 8, gen_loss = 0.8195481154608399, disc_loss = 0.08305244432277467
Trained batch 730 in epoch 8, gen_loss = 0.8191932403519444, disc_loss = 0.08317025059581863
Trained batch 731 in epoch 8, gen_loss = 0.8191567307205799, disc_loss = 0.08316436468730451
Trained batch 732 in epoch 8, gen_loss = 0.8190224921638286, disc_loss = 0.0831356710725112
Trained batch 733 in epoch 8, gen_loss = 0.8190289879933365, disc_loss = 0.08305844631330275
Trained batch 734 in epoch 8, gen_loss = 0.8194089585826511, disc_loss = 0.08300864384034458
Trained batch 735 in epoch 8, gen_loss = 0.8194394286155052, disc_loss = 0.08292130631668007
Trained batch 736 in epoch 8, gen_loss = 0.8193519189448337, disc_loss = 0.0828520346665439
Trained batch 737 in epoch 8, gen_loss = 0.8192384891959064, disc_loss = 0.08279201230614731
Trained batch 738 in epoch 8, gen_loss = 0.8191164525903771, disc_loss = 0.08276981862163592
Trained batch 739 in epoch 8, gen_loss = 0.8193983527856904, disc_loss = 0.08271282366854517
Trained batch 740 in epoch 8, gen_loss = 0.8200708769674082, disc_loss = 0.08266096348734761
Trained batch 741 in epoch 8, gen_loss = 0.8196922469572879, disc_loss = 0.082777620714931
Trained batch 742 in epoch 8, gen_loss = 0.819735625831468, disc_loss = 0.08273933011371627
Trained batch 743 in epoch 8, gen_loss = 0.819590691236719, disc_loss = 0.08270587053860948
Trained batch 744 in epoch 8, gen_loss = 0.8201433677401319, disc_loss = 0.08291568058799177
Trained batch 745 in epoch 8, gen_loss = 0.819694747114629, disc_loss = 0.08307740850069488
Trained batch 746 in epoch 8, gen_loss = 0.8196627331306656, disc_loss = 0.08300557863989588
Trained batch 747 in epoch 8, gen_loss = 0.8197948572868332, disc_loss = 0.08333859086425148
Trained batch 748 in epoch 8, gen_loss = 0.819450983655787, disc_loss = 0.08336565763663466
Trained batch 749 in epoch 8, gen_loss = 0.8192444576819737, disc_loss = 0.08339452444265286
Trained batch 750 in epoch 8, gen_loss = 0.8191992405965706, disc_loss = 0.08335335177435142
Trained batch 751 in epoch 8, gen_loss = 0.8192435953607584, disc_loss = 0.08330263791635553
Trained batch 752 in epoch 8, gen_loss = 0.8188623942306159, disc_loss = 0.08329688020268206
Trained batch 753 in epoch 8, gen_loss = 0.8188871659476814, disc_loss = 0.08321663095993768
Trained batch 754 in epoch 8, gen_loss = 0.8189326727232397, disc_loss = 0.08314923311503518
Trained batch 755 in epoch 8, gen_loss = 0.8189649087963281, disc_loss = 0.08314280918548031
Trained batch 756 in epoch 8, gen_loss = 0.8188515098044548, disc_loss = 0.08322825298559713
Trained batch 757 in epoch 8, gen_loss = 0.818698375512868, disc_loss = 0.08330092819943277
Trained batch 758 in epoch 8, gen_loss = 0.8185778467944174, disc_loss = 0.08325361232218063
Trained batch 759 in epoch 8, gen_loss = 0.8190277869371991, disc_loss = 0.0833656197756921
Trained batch 760 in epoch 8, gen_loss = 0.8189023775042434, disc_loss = 0.08330854727016486
Trained batch 761 in epoch 8, gen_loss = 0.8186720148550244, disc_loss = 0.08339808594308344
Trained batch 762 in epoch 8, gen_loss = 0.8190553076223496, disc_loss = 0.08334272273304734
Trained batch 763 in epoch 8, gen_loss = 0.8191372143270458, disc_loss = 0.0833064199849495
Trained batch 764 in epoch 8, gen_loss = 0.819164092984854, disc_loss = 0.08330422602350415
Trained batch 765 in epoch 8, gen_loss = 0.8186040330415606, disc_loss = 0.08358502097661284
Trained batch 766 in epoch 8, gen_loss = 0.8189543320504752, disc_loss = 0.08372280826838262
Trained batch 767 in epoch 8, gen_loss = 0.8188422747965282, disc_loss = 0.0838135481608333
Trained batch 768 in epoch 8, gen_loss = 0.8188362312642433, disc_loss = 0.08385922970499732
Trained batch 769 in epoch 8, gen_loss = 0.8189708295967671, disc_loss = 0.0837804755268546
Trained batch 770 in epoch 8, gen_loss = 0.8188136208768639, disc_loss = 0.0837380444599574
Trained batch 771 in epoch 8, gen_loss = 0.8187103772950913, disc_loss = 0.08372746060066735
Trained batch 772 in epoch 8, gen_loss = 0.8188706782548887, disc_loss = 0.0837088063368899
Trained batch 773 in epoch 8, gen_loss = 0.8186792009329611, disc_loss = 0.0837959755520103
Trained batch 774 in epoch 8, gen_loss = 0.8188367674812194, disc_loss = 0.08374543016956698
Trained batch 775 in epoch 8, gen_loss = 0.8188754242950493, disc_loss = 0.08368326858473346
Trained batch 776 in epoch 8, gen_loss = 0.8193655756219473, disc_loss = 0.08374344012394375
Trained batch 777 in epoch 8, gen_loss = 0.8188270420832009, disc_loss = 0.08422933130556176
Trained batch 778 in epoch 8, gen_loss = 0.8191219987550963, disc_loss = 0.08430344148016558
Trained batch 779 in epoch 8, gen_loss = 0.8192352808438814, disc_loss = 0.0846079831942916
Trained batch 780 in epoch 8, gen_loss = 0.8189940436548826, disc_loss = 0.08466139226369608
Trained batch 781 in epoch 8, gen_loss = 0.8188725727445939, disc_loss = 0.08465721109010221
Trained batch 782 in epoch 8, gen_loss = 0.8187262740171732, disc_loss = 0.0846424917732086
Trained batch 783 in epoch 8, gen_loss = 0.8187636663871152, disc_loss = 0.0846696904793914
Trained batch 784 in epoch 8, gen_loss = 0.8187970885805264, disc_loss = 0.08475348631952219
Trained batch 785 in epoch 8, gen_loss = 0.8184328993009854, disc_loss = 0.08484767930482635
Trained batch 786 in epoch 8, gen_loss = 0.8185864585478999, disc_loss = 0.08479005889316223
Trained batch 787 in epoch 8, gen_loss = 0.8186467531217536, disc_loss = 0.08490440893804815
Trained batch 788 in epoch 8, gen_loss = 0.8185045263613132, disc_loss = 0.08484430453906494
Trained batch 789 in epoch 8, gen_loss = 0.8182190594039386, disc_loss = 0.0848745920754309
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.7125502824783325, disc_loss = 0.05337608605623245
Trained batch 1 in epoch 9, gen_loss = 0.6944802701473236, disc_loss = 0.09692046418786049
Trained batch 2 in epoch 9, gen_loss = 0.661780059337616, disc_loss = 0.0933584397037824
Trained batch 3 in epoch 9, gen_loss = 0.6788680851459503, disc_loss = 0.0860960241407156
Trained batch 4 in epoch 9, gen_loss = 0.6843269467353821, disc_loss = 0.09260694980621338
Trained batch 5 in epoch 9, gen_loss = 0.6823842823505402, disc_loss = 0.09181732684373856
Trained batch 6 in epoch 9, gen_loss = 0.6838819554873875, disc_loss = 0.09017588730369296
Trained batch 7 in epoch 9, gen_loss = 0.7343623265624046, disc_loss = 0.11537675838917494
Trained batch 8 in epoch 9, gen_loss = 0.7368731167581346, disc_loss = 0.10790201607677671
Trained batch 9 in epoch 9, gen_loss = 0.7204438388347626, disc_loss = 0.10693219304084778
Trained batch 10 in epoch 9, gen_loss = 0.7299661907282743, disc_loss = 0.1015607589347796
Trained batch 11 in epoch 9, gen_loss = 0.7261737783749899, disc_loss = 0.10051892977207899
Trained batch 12 in epoch 9, gen_loss = 0.7167906852868887, disc_loss = 0.09903551953343245
Trained batch 13 in epoch 9, gen_loss = 0.7312256225517818, disc_loss = 0.09612335238073554
Trained batch 14 in epoch 9, gen_loss = 0.7412100275357564, disc_loss = 0.0912641104310751
Trained batch 15 in epoch 9, gen_loss = 0.7361469641327858, disc_loss = 0.08964493835810572
Trained batch 16 in epoch 9, gen_loss = 0.7380127766553093, disc_loss = 0.08603967309874647
Trained batch 17 in epoch 9, gen_loss = 0.7513412402735816, disc_loss = 0.09186669294204977
Trained batch 18 in epoch 9, gen_loss = 0.7433398522828755, disc_loss = 0.09626383863781628
Trained batch 19 in epoch 9, gen_loss = 0.7465709418058395, disc_loss = 0.0951085725799203
Trained batch 20 in epoch 9, gen_loss = 0.756750518367404, disc_loss = 0.09258063332665534
Trained batch 21 in epoch 9, gen_loss = 0.7484994774514978, disc_loss = 0.09291769682683727
Trained batch 22 in epoch 9, gen_loss = 0.7540792200876318, disc_loss = 0.09377603864540225
Trained batch 23 in epoch 9, gen_loss = 0.7432514900962511, disc_loss = 0.09809092540914814
Trained batch 24 in epoch 9, gen_loss = 0.744048798084259, disc_loss = 0.09743148431181908
Trained batch 25 in epoch 9, gen_loss = 0.7469445765018463, disc_loss = 0.09698938735975669
Trained batch 26 in epoch 9, gen_loss = 0.745654598430351, disc_loss = 0.09617496681986032
Trained batch 27 in epoch 9, gen_loss = 0.7392311628375735, disc_loss = 0.09660983098936933
Trained batch 28 in epoch 9, gen_loss = 0.7496655871128214, disc_loss = 0.0956538120477364
Trained batch 29 in epoch 9, gen_loss = 0.7527721305688222, disc_loss = 0.09330796922246615
Trained batch 30 in epoch 9, gen_loss = 0.7554279585038463, disc_loss = 0.09254302084445953
Trained batch 31 in epoch 9, gen_loss = 0.7534260246902704, disc_loss = 0.09284980944357812
Trained batch 32 in epoch 9, gen_loss = 0.7560817924412814, disc_loss = 0.09109324724836783
Trained batch 33 in epoch 9, gen_loss = 0.762178989017711, disc_loss = 0.0917633437715909
Trained batch 34 in epoch 9, gen_loss = 0.76221866777965, disc_loss = 0.09036406778863498
Trained batch 35 in epoch 9, gen_loss = 0.7584466967317793, disc_loss = 0.08935041973988216
Trained batch 36 in epoch 9, gen_loss = 0.7632173267570702, disc_loss = 0.08986220408130337
Trained batch 37 in epoch 9, gen_loss = 0.7603546255513242, disc_loss = 0.09065546487507067
Trained batch 38 in epoch 9, gen_loss = 0.7648793825736413, disc_loss = 0.08927054340258622
Trained batch 39 in epoch 9, gen_loss = 0.7605279609560966, disc_loss = 0.0902311010286212
Trained batch 40 in epoch 9, gen_loss = 0.7665297330879584, disc_loss = 0.08851950897312746
Trained batch 41 in epoch 9, gen_loss = 0.7699777540706453, disc_loss = 0.0903810646739744
Trained batch 42 in epoch 9, gen_loss = 0.7697746199230815, disc_loss = 0.08987724841680637
Trained batch 43 in epoch 9, gen_loss = 0.766432602297176, disc_loss = 0.0912603752010248
Trained batch 44 in epoch 9, gen_loss = 0.7712528308232626, disc_loss = 0.09193906643324429
Trained batch 45 in epoch 9, gen_loss = 0.7702248640682386, disc_loss = 0.09273146667882153
Trained batch 46 in epoch 9, gen_loss = 0.7701775266769084, disc_loss = 0.09300734221618226
Trained batch 47 in epoch 9, gen_loss = 0.7740180070201556, disc_loss = 0.0918874426279217
Trained batch 48 in epoch 9, gen_loss = 0.7733544342371882, disc_loss = 0.09158867833261587
Trained batch 49 in epoch 9, gen_loss = 0.777439843416214, disc_loss = 0.09267692558467389
Trained batch 50 in epoch 9, gen_loss = 0.7742215757276497, disc_loss = 0.09302955332632158
Trained batch 51 in epoch 9, gen_loss = 0.7698208678227204, disc_loss = 0.09284320409194781
Trained batch 52 in epoch 9, gen_loss = 0.7734326022975849, disc_loss = 0.09435122692078915
Trained batch 53 in epoch 9, gen_loss = 0.7755947146150801, disc_loss = 0.0931883951028188
Trained batch 54 in epoch 9, gen_loss = 0.7714039304039695, disc_loss = 0.09460883655331352
Trained batch 55 in epoch 9, gen_loss = 0.7775743923016957, disc_loss = 0.09417678974568844
Trained batch 56 in epoch 9, gen_loss = 0.7794856188590067, disc_loss = 0.09314590287313126
Trained batch 57 in epoch 9, gen_loss = 0.7773673801586546, disc_loss = 0.0931834895806066
Trained batch 58 in epoch 9, gen_loss = 0.7814081200098587, disc_loss = 0.0919326906234531
Trained batch 59 in epoch 9, gen_loss = 0.7804565290609996, disc_loss = 0.09138175925860802
Trained batch 60 in epoch 9, gen_loss = 0.7831015108061619, disc_loss = 0.09104179352766177
Trained batch 61 in epoch 9, gen_loss = 0.7815623985182855, disc_loss = 0.09051024138687118
Trained batch 62 in epoch 9, gen_loss = 0.7852063396620372, disc_loss = 0.08959835075906344
Trained batch 63 in epoch 9, gen_loss = 0.788461109623313, disc_loss = 0.0887956777587533
Trained batch 64 in epoch 9, gen_loss = 0.7845892135913556, disc_loss = 0.09031759477578677
Trained batch 65 in epoch 9, gen_loss = 0.7869195865862297, disc_loss = 0.08921088444802797
Trained batch 66 in epoch 9, gen_loss = 0.7927363879645049, disc_loss = 0.08835571017394316
Trained batch 67 in epoch 9, gen_loss = 0.7943845277323442, disc_loss = 0.08950633240644545
Trained batch 68 in epoch 9, gen_loss = 0.7948573439017587, disc_loss = 0.08873419541919576
Trained batch 69 in epoch 9, gen_loss = 0.7914286937032428, disc_loss = 0.09093084731804472
Trained batch 70 in epoch 9, gen_loss = 0.7947666997640905, disc_loss = 0.09099486273464183
Trained batch 71 in epoch 9, gen_loss = 0.7921736737092336, disc_loss = 0.09037456715789934
Trained batch 72 in epoch 9, gen_loss = 0.7931402562415764, disc_loss = 0.08939637090653589
Trained batch 73 in epoch 9, gen_loss = 0.7950882186760774, disc_loss = 0.08900120290550026
Trained batch 74 in epoch 9, gen_loss = 0.7930118759473165, disc_loss = 0.08961632251739501
Trained batch 75 in epoch 9, gen_loss = 0.7936939887310329, disc_loss = 0.08891180417451419
Trained batch 76 in epoch 9, gen_loss = 0.7912102271984149, disc_loss = 0.08856362626924143
Trained batch 77 in epoch 9, gen_loss = 0.7942026242231711, disc_loss = 0.08759408977885659
Trained batch 78 in epoch 9, gen_loss = 0.7971595827537247, disc_loss = 0.08675035710529058
Trained batch 79 in epoch 9, gen_loss = 0.7985277265310288, disc_loss = 0.08580476712668314
Trained batch 80 in epoch 9, gen_loss = 0.7973633901572522, disc_loss = 0.08543475125168945
Trained batch 81 in epoch 9, gen_loss = 0.7990045343957296, disc_loss = 0.08458422618441103
Trained batch 82 in epoch 9, gen_loss = 0.7988937561770519, disc_loss = 0.08467208085783634
Trained batch 83 in epoch 9, gen_loss = 0.7999090793586913, disc_loss = 0.08384646416553074
Trained batch 84 in epoch 9, gen_loss = 0.7983273309819838, disc_loss = 0.08379548896542367
Trained batch 85 in epoch 9, gen_loss = 0.8007335898488067, disc_loss = 0.08302393030418559
Trained batch 86 in epoch 9, gen_loss = 0.802904457196422, disc_loss = 0.08224518557518036
Trained batch 87 in epoch 9, gen_loss = 0.8031141263517466, disc_loss = 0.08155883187216452
Trained batch 88 in epoch 9, gen_loss = 0.8055628183182706, disc_loss = 0.08112551191340336
Trained batch 89 in epoch 9, gen_loss = 0.8061779744095272, disc_loss = 0.08059480044369896
Trained batch 90 in epoch 9, gen_loss = 0.8039233913788428, disc_loss = 0.08059856560654365
Trained batch 91 in epoch 9, gen_loss = 0.8063833188751469, disc_loss = 0.08044574218397231
Trained batch 92 in epoch 9, gen_loss = 0.807635272061953, disc_loss = 0.08014078713673096
Trained batch 93 in epoch 9, gen_loss = 0.8088469334105228, disc_loss = 0.0795981555364709
Trained batch 94 in epoch 9, gen_loss = 0.8058433394683034, disc_loss = 0.08101010458837998
Trained batch 95 in epoch 9, gen_loss = 0.8085878503819307, disc_loss = 0.08186691202960598
Trained batch 96 in epoch 9, gen_loss = 0.812936988073526, disc_loss = 0.08134228481728699
Trained batch 97 in epoch 9, gen_loss = 0.8122776692010918, disc_loss = 0.08095209520044071
Trained batch 98 in epoch 9, gen_loss = 0.8105189637704329, disc_loss = 0.0808666047329704
Trained batch 99 in epoch 9, gen_loss = 0.8147076326608658, disc_loss = 0.08085574275813996
Trained batch 100 in epoch 9, gen_loss = 0.814158022403717, disc_loss = 0.08057012430180123
Trained batch 101 in epoch 9, gen_loss = 0.8146576314580207, disc_loss = 0.07998373623316486
Trained batch 102 in epoch 9, gen_loss = 0.8147730613217771, disc_loss = 0.07952460730719624
Trained batch 103 in epoch 9, gen_loss = 0.8160871422061553, disc_loss = 0.07889494641075054
Trained batch 104 in epoch 9, gen_loss = 0.816798080149151, disc_loss = 0.07913677235621781
Trained batch 105 in epoch 9, gen_loss = 0.8169078984350528, disc_loss = 0.07865991377500149
Trained batch 106 in epoch 9, gen_loss = 0.8150727058125433, disc_loss = 0.07887390127979985
Trained batch 107 in epoch 9, gen_loss = 0.8165985710091062, disc_loss = 0.0783582452977835
Trained batch 108 in epoch 9, gen_loss = 0.8153107707653571, disc_loss = 0.07808280713138503
Trained batch 109 in epoch 9, gen_loss = 0.8163804384795103, disc_loss = 0.07789884173226627
Trained batch 110 in epoch 9, gen_loss = 0.816107368147051, disc_loss = 0.07765807121622938
Trained batch 111 in epoch 9, gen_loss = 0.8151183873414993, disc_loss = 0.07789633340767718
Trained batch 112 in epoch 9, gen_loss = 0.8140375324055157, disc_loss = 0.07754508202351564
Trained batch 113 in epoch 9, gen_loss = 0.8144822565087101, disc_loss = 0.07728602754344281
Trained batch 114 in epoch 9, gen_loss = 0.8144644058269003, disc_loss = 0.07703249652910492
Trained batch 115 in epoch 9, gen_loss = 0.8170604073795779, disc_loss = 0.07655784552756312
Trained batch 116 in epoch 9, gen_loss = 0.8151809226753365, disc_loss = 0.07636007683303876
Trained batch 117 in epoch 9, gen_loss = 0.8185486222727824, disc_loss = 0.07605382617784001
Trained batch 118 in epoch 9, gen_loss = 0.8203948691111653, disc_loss = 0.075598242974394
Trained batch 119 in epoch 9, gen_loss = 0.8208624079823494, disc_loss = 0.07528559814672917
Trained batch 120 in epoch 9, gen_loss = 0.8192591484913156, disc_loss = 0.07595901031909157
Trained batch 121 in epoch 9, gen_loss = 0.8204227153395043, disc_loss = 0.07614951667024708
Trained batch 122 in epoch 9, gen_loss = 0.8222494178671178, disc_loss = 0.07563323454885948
Trained batch 123 in epoch 9, gen_loss = 0.8211757819498738, disc_loss = 0.07558027240297487
Trained batch 124 in epoch 9, gen_loss = 0.8236086225509643, disc_loss = 0.07532358336448669
Trained batch 125 in epoch 9, gen_loss = 0.8230120516012586, disc_loss = 0.07500361707357187
Trained batch 126 in epoch 9, gen_loss = 0.82260864128278, disc_loss = 0.07462962825349935
Trained batch 127 in epoch 9, gen_loss = 0.8205797993578017, disc_loss = 0.07517507809097879
Trained batch 128 in epoch 9, gen_loss = 0.8214656812276027, disc_loss = 0.07523654467722242
Trained batch 129 in epoch 9, gen_loss = 0.8212407987851363, disc_loss = 0.07527939983858511
Trained batch 130 in epoch 9, gen_loss = 0.8197162683683498, disc_loss = 0.07529709735558233
Trained batch 131 in epoch 9, gen_loss = 0.8218551734180162, disc_loss = 0.07519561670381915
Trained batch 132 in epoch 9, gen_loss = 0.8198464705531758, disc_loss = 0.07601648106946982
Trained batch 133 in epoch 9, gen_loss = 0.8207879360042402, disc_loss = 0.07614624842222947
Trained batch 134 in epoch 9, gen_loss = 0.8214991039699978, disc_loss = 0.07588986646797923
Trained batch 135 in epoch 9, gen_loss = 0.8196221199982306, disc_loss = 0.07574536697939038
Trained batch 136 in epoch 9, gen_loss = 0.8179287601561442, disc_loss = 0.07594552584481935
Trained batch 137 in epoch 9, gen_loss = 0.8192092245039733, disc_loss = 0.0756015964527277
Trained batch 138 in epoch 9, gen_loss = 0.8208842530524988, disc_loss = 0.07539424229172065
Trained batch 139 in epoch 9, gen_loss = 0.8213310003280639, disc_loss = 0.07509487136932357
Trained batch 140 in epoch 9, gen_loss = 0.8199349375481301, disc_loss = 0.07527507364697067
Trained batch 141 in epoch 9, gen_loss = 0.8195267004865996, disc_loss = 0.07505739751783475
Trained batch 142 in epoch 9, gen_loss = 0.8210409467036908, disc_loss = 0.07463342525794373
Trained batch 143 in epoch 9, gen_loss = 0.8211965022815598, disc_loss = 0.07425152296976496
Trained batch 144 in epoch 9, gen_loss = 0.8212619978806068, disc_loss = 0.07418031079758858
Trained batch 145 in epoch 9, gen_loss = 0.8212785092118668, disc_loss = 0.07379236293012557
Trained batch 146 in epoch 9, gen_loss = 0.8208679183810746, disc_loss = 0.07393469799588732
Trained batch 147 in epoch 9, gen_loss = 0.8200385405405147, disc_loss = 0.07371873606147396
Trained batch 148 in epoch 9, gen_loss = 0.8195021228502261, disc_loss = 0.07366602169037265
Trained batch 149 in epoch 9, gen_loss = 0.8192780395348866, disc_loss = 0.07334588721394539
Trained batch 150 in epoch 9, gen_loss = 0.8201335340935663, disc_loss = 0.07383501810940686
Trained batch 151 in epoch 9, gen_loss = 0.8201260970611322, disc_loss = 0.0734722089071415
Trained batch 152 in epoch 9, gen_loss = 0.8200892128196418, disc_loss = 0.07317189046857404
Trained batch 153 in epoch 9, gen_loss = 0.8199782058016046, disc_loss = 0.07294487220223074
Trained batch 154 in epoch 9, gen_loss = 0.8206454973067007, disc_loss = 0.07277115835778175
Trained batch 155 in epoch 9, gen_loss = 0.8230341707284634, disc_loss = 0.07333070806299265
Trained batch 156 in epoch 9, gen_loss = 0.8239231447505343, disc_loss = 0.07294950641359493
Trained batch 157 in epoch 9, gen_loss = 0.8221797920480559, disc_loss = 0.07467266231115106
Trained batch 158 in epoch 9, gen_loss = 0.822898342924298, disc_loss = 0.07453556094060904
Trained batch 159 in epoch 9, gen_loss = 0.825252415239811, disc_loss = 0.07549464327748864
Trained batch 160 in epoch 9, gen_loss = 0.8246037597241609, disc_loss = 0.07574891204141682
Trained batch 161 in epoch 9, gen_loss = 0.8253789900997539, disc_loss = 0.07599799944386806
Trained batch 162 in epoch 9, gen_loss = 0.8244567853541462, disc_loss = 0.07605923911088083
Trained batch 163 in epoch 9, gen_loss = 0.8234907744861231, disc_loss = 0.07644009887717845
Trained batch 164 in epoch 9, gen_loss = 0.8234710144274162, disc_loss = 0.07650945897806774
Trained batch 165 in epoch 9, gen_loss = 0.8245581639818398, disc_loss = 0.07612081598041646
Trained batch 166 in epoch 9, gen_loss = 0.8236857310026705, disc_loss = 0.07610123813107698
Trained batch 167 in epoch 9, gen_loss = 0.8248003714141392, disc_loss = 0.0760483305258233
Trained batch 168 in epoch 9, gen_loss = 0.8247811512128841, disc_loss = 0.07588571348618826
Trained batch 169 in epoch 9, gen_loss = 0.8230730635278365, disc_loss = 0.07601467922110768
Trained batch 170 in epoch 9, gen_loss = 0.823637643055609, disc_loss = 0.07571957002214172
Trained batch 171 in epoch 9, gen_loss = 0.8248212094916854, disc_loss = 0.07599620823206943
Trained batch 172 in epoch 9, gen_loss = 0.825450927191387, disc_loss = 0.07582374269175048
Trained batch 173 in epoch 9, gen_loss = 0.8240847279285562, disc_loss = 0.07658470806333868
Trained batch 174 in epoch 9, gen_loss = 0.8267044046946934, disc_loss = 0.07663991952581065
Trained batch 175 in epoch 9, gen_loss = 0.8269307904622771, disc_loss = 0.07643950926351616
Trained batch 176 in epoch 9, gen_loss = 0.8260701025946665, disc_loss = 0.07654744977036775
Trained batch 177 in epoch 9, gen_loss = 0.8250187849730588, disc_loss = 0.07652542255609558
Trained batch 178 in epoch 9, gen_loss = 0.8253906479094948, disc_loss = 0.07721395175591861
Trained batch 179 in epoch 9, gen_loss = 0.8247238990333345, disc_loss = 0.07705279978820019
Trained batch 180 in epoch 9, gen_loss = 0.8239400811616887, disc_loss = 0.07758283278601275
Trained batch 181 in epoch 9, gen_loss = 0.8233903305871146, disc_loss = 0.07750404668091745
Trained batch 182 in epoch 9, gen_loss = 0.8221749217132401, disc_loss = 0.07788679949287834
Trained batch 183 in epoch 9, gen_loss = 0.8225538073026616, disc_loss = 0.0780218451830518
Trained batch 184 in epoch 9, gen_loss = 0.8226814524547473, disc_loss = 0.0776914075319026
Trained batch 185 in epoch 9, gen_loss = 0.8225686963527433, disc_loss = 0.07753192688468644
Trained batch 186 in epoch 9, gen_loss = 0.8231556351809578, disc_loss = 0.07721283419286823
Trained batch 187 in epoch 9, gen_loss = 0.8233109836248641, disc_loss = 0.07695775459262919
Trained batch 188 in epoch 9, gen_loss = 0.8229450867289588, disc_loss = 0.07697433931013895
Trained batch 189 in epoch 9, gen_loss = 0.8225718909188321, disc_loss = 0.0778844262816404
Trained batch 190 in epoch 9, gen_loss = 0.8217362049986555, disc_loss = 0.07782108984224459
Trained batch 191 in epoch 9, gen_loss = 0.8230169263357917, disc_loss = 0.07798359651739399
Trained batch 192 in epoch 9, gen_loss = 0.8224657554700585, disc_loss = 0.07792709624983486
Trained batch 193 in epoch 9, gen_loss = 0.8215735299685567, disc_loss = 0.0779818316787174
Trained batch 194 in epoch 9, gen_loss = 0.8231409265444829, disc_loss = 0.0785967400822884
Trained batch 195 in epoch 9, gen_loss = 0.821851484933678, disc_loss = 0.07869908365668082
Trained batch 196 in epoch 9, gen_loss = 0.822447171973698, disc_loss = 0.07855175898840584
Trained batch 197 in epoch 9, gen_loss = 0.8220559771012779, disc_loss = 0.07843895642218565
Trained batch 198 in epoch 9, gen_loss = 0.8207715351377899, disc_loss = 0.07858437511264979
Trained batch 199 in epoch 9, gen_loss = 0.8210431578755378, disc_loss = 0.07860122328624129
Trained batch 200 in epoch 9, gen_loss = 0.821468172678307, disc_loss = 0.07838286490953383
Trained batch 201 in epoch 9, gen_loss = 0.8206007616354687, disc_loss = 0.07824529465841185
Trained batch 202 in epoch 9, gen_loss = 0.8211731029848747, disc_loss = 0.0779636212592495
Trained batch 203 in epoch 9, gen_loss = 0.820030530001603, disc_loss = 0.07841891688568627
Trained batch 204 in epoch 9, gen_loss = 0.8195330163327659, disc_loss = 0.07830408394518422
Trained batch 205 in epoch 9, gen_loss = 0.8195228894937385, disc_loss = 0.07859152820395324
Trained batch 206 in epoch 9, gen_loss = 0.8188315114537299, disc_loss = 0.07900897234426317
Trained batch 207 in epoch 9, gen_loss = 0.8178630574391439, disc_loss = 0.0791474204026879
Trained batch 208 in epoch 9, gen_loss = 0.8173847449453253, disc_loss = 0.07911510456299953
Trained batch 209 in epoch 9, gen_loss = 0.8173414437543778, disc_loss = 0.07896287119282143
Trained batch 210 in epoch 9, gen_loss = 0.8169863294651158, disc_loss = 0.07879122419909561
Trained batch 211 in epoch 9, gen_loss = 0.8180360150224758, disc_loss = 0.07881175715230265
Trained batch 212 in epoch 9, gen_loss = 0.8175040631786759, disc_loss = 0.07864464554463474
Trained batch 213 in epoch 9, gen_loss = 0.8185674511940679, disc_loss = 0.07838314624555479
Trained batch 214 in epoch 9, gen_loss = 0.8187080469242362, disc_loss = 0.07813399736444618
Trained batch 215 in epoch 9, gen_loss = 0.8176811257446254, disc_loss = 0.0783452108864569
Trained batch 216 in epoch 9, gen_loss = 0.8185190157406891, disc_loss = 0.07803747680227054
Trained batch 217 in epoch 9, gen_loss = 0.8176606672072629, disc_loss = 0.07790666523842363
Trained batch 218 in epoch 9, gen_loss = 0.8177566574588758, disc_loss = 0.07803329702075486
Trained batch 219 in epoch 9, gen_loss = 0.8178514710881494, disc_loss = 0.07776548438282176
Trained batch 220 in epoch 9, gen_loss = 0.8171488885426413, disc_loss = 0.07778748299302828
Trained batch 221 in epoch 9, gen_loss = 0.8164905070721566, disc_loss = 0.07775012758635991
Trained batch 222 in epoch 9, gen_loss = 0.816441449616522, disc_loss = 0.0784711428738362
Trained batch 223 in epoch 9, gen_loss = 0.8165632316044399, disc_loss = 0.07854299083451874
Trained batch 224 in epoch 9, gen_loss = 0.8155640109380087, disc_loss = 0.0786408730265167
Trained batch 225 in epoch 9, gen_loss = 0.8144672062017221, disc_loss = 0.07879820402579761
Trained batch 226 in epoch 9, gen_loss = 0.8161965464180262, disc_loss = 0.07954371424334428
Trained batch 227 in epoch 9, gen_loss = 0.8156008045924338, disc_loss = 0.07938056840283568
Trained batch 228 in epoch 9, gen_loss = 0.814486968465247, disc_loss = 0.08015233794772209
Trained batch 229 in epoch 9, gen_loss = 0.8144350197004235, disc_loss = 0.0804093939697613
Trained batch 230 in epoch 9, gen_loss = 0.815119279411448, disc_loss = 0.08040717365905578
Trained batch 231 in epoch 9, gen_loss = 0.8146918511082386, disc_loss = 0.08036213739903579
Trained batch 232 in epoch 9, gen_loss = 0.8138688884579572, disc_loss = 0.08036110549365758
Trained batch 233 in epoch 9, gen_loss = 0.8130340410603417, disc_loss = 0.08085616584867239
Trained batch 234 in epoch 9, gen_loss = 0.8126683673960098, disc_loss = 0.08070411418188125
Trained batch 235 in epoch 9, gen_loss = 0.8123999101630712, disc_loss = 0.08065828746500409
Trained batch 236 in epoch 9, gen_loss = 0.812671515509046, disc_loss = 0.08045985025475548
Trained batch 237 in epoch 9, gen_loss = 0.8132803853319472, disc_loss = 0.08056687191911355
Trained batch 238 in epoch 9, gen_loss = 0.8124326125847245, disc_loss = 0.08090319273268579
Trained batch 239 in epoch 9, gen_loss = 0.8121074475347996, disc_loss = 0.08085583359158287
Trained batch 240 in epoch 9, gen_loss = 0.8132220890017466, disc_loss = 0.08058944718595362
Trained batch 241 in epoch 9, gen_loss = 0.8141225007447329, disc_loss = 0.08053426989469646
Trained batch 242 in epoch 9, gen_loss = 0.8147368377128256, disc_loss = 0.08027491033261205
Trained batch 243 in epoch 9, gen_loss = 0.8133629496957435, disc_loss = 0.08057741300187639
Trained batch 244 in epoch 9, gen_loss = 0.8138524079809384, disc_loss = 0.08055079191619036
Trained batch 245 in epoch 9, gen_loss = 0.815446690815251, disc_loss = 0.08047342892524188
Trained batch 246 in epoch 9, gen_loss = 0.8154656937730457, disc_loss = 0.08028245729352781
Trained batch 247 in epoch 9, gen_loss = 0.8155758248702172, disc_loss = 0.08026785736963633
Trained batch 248 in epoch 9, gen_loss = 0.8146960481582396, disc_loss = 0.08068460923241803
Trained batch 249 in epoch 9, gen_loss = 0.8146339902877807, disc_loss = 0.08056929108500481
Trained batch 250 in epoch 9, gen_loss = 0.8140398862352409, disc_loss = 0.08088004229909396
Trained batch 251 in epoch 9, gen_loss = 0.8144682255529222, disc_loss = 0.08068724324010194
Trained batch 252 in epoch 9, gen_loss = 0.813358920836166, disc_loss = 0.08070774545723741
Trained batch 253 in epoch 9, gen_loss = 0.8123613577189408, disc_loss = 0.08098129099454936
Trained batch 254 in epoch 9, gen_loss = 0.8131549835205079, disc_loss = 0.08101266033801378
Trained batch 255 in epoch 9, gen_loss = 0.8136494634672999, disc_loss = 0.08099187818879727
Trained batch 256 in epoch 9, gen_loss = 0.8134241143553174, disc_loss = 0.08091229730890882
Trained batch 257 in epoch 9, gen_loss = 0.8127676597399305, disc_loss = 0.08106463364968004
Trained batch 258 in epoch 9, gen_loss = 0.8123017620856238, disc_loss = 0.08101408206588052
Trained batch 259 in epoch 9, gen_loss = 0.8120078011200978, disc_loss = 0.08114771774181953
Trained batch 260 in epoch 9, gen_loss = 0.812704092698079, disc_loss = 0.08135366302797165
Trained batch 261 in epoch 9, gen_loss = 0.8128744677732919, disc_loss = 0.08118414324317269
Trained batch 262 in epoch 9, gen_loss = 0.8132542702634978, disc_loss = 0.08094066814891286
Trained batch 263 in epoch 9, gen_loss = 0.8126084874525215, disc_loss = 0.0813058101374543
Trained batch 264 in epoch 9, gen_loss = 0.8134094712869177, disc_loss = 0.08131226647012639
Trained batch 265 in epoch 9, gen_loss = 0.8141257930967144, disc_loss = 0.08105670379936919
Trained batch 266 in epoch 9, gen_loss = 0.8138434011837963, disc_loss = 0.08124625643066476
Trained batch 267 in epoch 9, gen_loss = 0.8134568355866333, disc_loss = 0.08114016340322681
Trained batch 268 in epoch 9, gen_loss = 0.8145846624799821, disc_loss = 0.08106831110127576
Trained batch 269 in epoch 9, gen_loss = 0.8141155609378108, disc_loss = 0.08091790536073623
Trained batch 270 in epoch 9, gen_loss = 0.8139607844757418, disc_loss = 0.0807731981660717
Trained batch 271 in epoch 9, gen_loss = 0.8142800368368626, disc_loss = 0.08059823428801097
Trained batch 272 in epoch 9, gen_loss = 0.8147323295310304, disc_loss = 0.08037376251658458
Trained batch 273 in epoch 9, gen_loss = 0.8147670483067088, disc_loss = 0.08053128555226717
Trained batch 274 in epoch 9, gen_loss = 0.8149300629442389, disc_loss = 0.08034712966192853
Trained batch 275 in epoch 9, gen_loss = 0.8146063467298729, disc_loss = 0.08022288802633251
Trained batch 276 in epoch 9, gen_loss = 0.8141675148199612, disc_loss = 0.08030007612834338
Trained batch 277 in epoch 9, gen_loss = 0.8146870665841823, disc_loss = 0.08010007467844503
Trained batch 278 in epoch 9, gen_loss = 0.8149488153850734, disc_loss = 0.08005279294585668
Trained batch 279 in epoch 9, gen_loss = 0.8160644601498331, disc_loss = 0.0799315673698272
Trained batch 280 in epoch 9, gen_loss = 0.8146032792817656, disc_loss = 0.08021889486452863
Trained batch 281 in epoch 9, gen_loss = 0.8148719636683769, disc_loss = 0.08012124259315484
Trained batch 282 in epoch 9, gen_loss = 0.8155433720918932, disc_loss = 0.07994150736964845
Trained batch 283 in epoch 9, gen_loss = 0.815087196062988, disc_loss = 0.07996571602457216
Trained batch 284 in epoch 9, gen_loss = 0.81422815782982, disc_loss = 0.08021167797085486
Trained batch 285 in epoch 9, gen_loss = 0.8157372724759829, disc_loss = 0.08037906706046599
Trained batch 286 in epoch 9, gen_loss = 0.8158872484745464, disc_loss = 0.08019207705474274
Trained batch 287 in epoch 9, gen_loss = 0.8158424972660012, disc_loss = 0.07997304774794935
Trained batch 288 in epoch 9, gen_loss = 0.8155204109254592, disc_loss = 0.07997942470323462
Trained batch 289 in epoch 9, gen_loss = 0.815321978001759, disc_loss = 0.07983231644049801
Trained batch 290 in epoch 9, gen_loss = 0.8153209682182758, disc_loss = 0.07962453501663871
Trained batch 291 in epoch 9, gen_loss = 0.8153994952979153, disc_loss = 0.07984962041987335
Trained batch 292 in epoch 9, gen_loss = 0.8159364122172671, disc_loss = 0.079658274643708
Trained batch 293 in epoch 9, gen_loss = 0.8151526941734106, disc_loss = 0.07965711542867682
Trained batch 294 in epoch 9, gen_loss = 0.8153370190474947, disc_loss = 0.0796053961992769
Trained batch 295 in epoch 9, gen_loss = 0.8147421390623659, disc_loss = 0.07966227925734946
Trained batch 296 in epoch 9, gen_loss = 0.8158570303258671, disc_loss = 0.07963494987223887
Trained batch 297 in epoch 9, gen_loss = 0.8153949891960861, disc_loss = 0.07962763252599328
Trained batch 298 in epoch 9, gen_loss = 0.8156253135323923, disc_loss = 0.07952522140706463
Trained batch 299 in epoch 9, gen_loss = 0.8166058532396953, disc_loss = 0.07991157586996754
Trained batch 300 in epoch 9, gen_loss = 0.8172383031179739, disc_loss = 0.07970681111405656
Trained batch 301 in epoch 9, gen_loss = 0.8167182092635047, disc_loss = 0.07993952464312315
Trained batch 302 in epoch 9, gen_loss = 0.8165090505046027, disc_loss = 0.07976936291374585
Trained batch 303 in epoch 9, gen_loss = 0.8172551013137165, disc_loss = 0.08003477017566758
Trained batch 304 in epoch 9, gen_loss = 0.816731623157126, disc_loss = 0.08008537752340074
Trained batch 305 in epoch 9, gen_loss = 0.8172758155398898, disc_loss = 0.0798731480597281
Trained batch 306 in epoch 9, gen_loss = 0.8176526481631524, disc_loss = 0.07966732842914445
Trained batch 307 in epoch 9, gen_loss = 0.8174591637276983, disc_loss = 0.07956637127639411
Trained batch 308 in epoch 9, gen_loss = 0.8179044160256493, disc_loss = 0.07936785484040246
Trained batch 309 in epoch 9, gen_loss = 0.8178988350975898, disc_loss = 0.07916805819277802
Trained batch 310 in epoch 9, gen_loss = 0.8172350115714733, disc_loss = 0.07927112231612014
Trained batch 311 in epoch 9, gen_loss = 0.8183593893280396, disc_loss = 0.07937666542756443
Trained batch 312 in epoch 9, gen_loss = 0.8197387413094981, disc_loss = 0.07922723236532447
Trained batch 313 in epoch 9, gen_loss = 0.8196476635279929, disc_loss = 0.07908904594576853
Trained batch 314 in epoch 9, gen_loss = 0.8197007228457739, disc_loss = 0.0790841511731583
Trained batch 315 in epoch 9, gen_loss = 0.8197234508734715, disc_loss = 0.07900283208022578
Trained batch 316 in epoch 9, gen_loss = 0.8193127031582011, disc_loss = 0.07894518093003272
Trained batch 317 in epoch 9, gen_loss = 0.819748821311027, disc_loss = 0.07904026723531245
Trained batch 318 in epoch 9, gen_loss = 0.8196316542670271, disc_loss = 0.07886540730334936
Trained batch 319 in epoch 9, gen_loss = 0.8189167289063335, disc_loss = 0.07907597137964331
Trained batch 320 in epoch 9, gen_loss = 0.8186480124420095, disc_loss = 0.07892488859988447
Trained batch 321 in epoch 9, gen_loss = 0.818885298249144, disc_loss = 0.07877075018488472
Trained batch 322 in epoch 9, gen_loss = 0.8192525714543581, disc_loss = 0.07871406249725044
Trained batch 323 in epoch 9, gen_loss = 0.8184897016595911, disc_loss = 0.07869610200739569
Trained batch 324 in epoch 9, gen_loss = 0.8186595876400288, disc_loss = 0.0785467601968692
Trained batch 325 in epoch 9, gen_loss = 0.8187252868172581, disc_loss = 0.07835586405033532
Trained batch 326 in epoch 9, gen_loss = 0.8188873657028245, disc_loss = 0.07816752233750413
Trained batch 327 in epoch 9, gen_loss = 0.8183912771140657, disc_loss = 0.07814324631855436
Trained batch 328 in epoch 9, gen_loss = 0.8191030183099324, disc_loss = 0.07813537658098801
Trained batch 329 in epoch 9, gen_loss = 0.8191641047145382, disc_loss = 0.07798343032711383
Trained batch 330 in epoch 9, gen_loss = 0.8186461459113752, disc_loss = 0.0780231794708175
Trained batch 331 in epoch 9, gen_loss = 0.818912160145231, disc_loss = 0.07785059746736324
Trained batch 332 in epoch 9, gen_loss = 0.8202504000148257, disc_loss = 0.07790053812031811
Trained batch 333 in epoch 9, gen_loss = 0.8203039210356639, disc_loss = 0.07772864980768122
Trained batch 334 in epoch 9, gen_loss = 0.8205322578771791, disc_loss = 0.07756179511658291
Trained batch 335 in epoch 9, gen_loss = 0.8212421050383931, disc_loss = 0.07749393601746608
Trained batch 336 in epoch 9, gen_loss = 0.8207557383559931, disc_loss = 0.0776063517034496
Trained batch 337 in epoch 9, gen_loss = 0.8204892873764038, disc_loss = 0.07746685186081384
Trained batch 338 in epoch 9, gen_loss = 0.8209475484569516, disc_loss = 0.07735294932197329
Trained batch 339 in epoch 9, gen_loss = 0.8206597002113567, disc_loss = 0.07724669369704583
Trained batch 340 in epoch 9, gen_loss = 0.822157657391165, disc_loss = 0.07779016920373587
Trained batch 341 in epoch 9, gen_loss = 0.8224471755195082, disc_loss = 0.07768513268807478
Trained batch 342 in epoch 9, gen_loss = 0.8222973748129241, disc_loss = 0.07779591902004386
Trained batch 343 in epoch 9, gen_loss = 0.8236333566696145, disc_loss = 0.07796638857486636
Trained batch 344 in epoch 9, gen_loss = 0.8236055970191956, disc_loss = 0.07804098580626474
Trained batch 345 in epoch 9, gen_loss = 0.8229784509005574, disc_loss = 0.0785913694154665
Trained batch 346 in epoch 9, gen_loss = 0.8228625641432551, disc_loss = 0.07866323954004376
Trained batch 347 in epoch 9, gen_loss = 0.8248542196106636, disc_loss = 0.07874491752992416
Trained batch 348 in epoch 9, gen_loss = 0.8252813196113936, disc_loss = 0.07860483098401552
Trained batch 349 in epoch 9, gen_loss = 0.8243736338615417, disc_loss = 0.07915574126477752
Trained batch 350 in epoch 9, gen_loss = 0.8257783440782813, disc_loss = 0.0792370144744799
Trained batch 351 in epoch 9, gen_loss = 0.8259074322201989, disc_loss = 0.07928505585931073
Trained batch 352 in epoch 9, gen_loss = 0.8254734943000859, disc_loss = 0.07936524132810133
Trained batch 353 in epoch 9, gen_loss = 0.8251321495926313, disc_loss = 0.07934730171125992
Trained batch 354 in epoch 9, gen_loss = 0.8260026292062141, disc_loss = 0.07936083776745158
Trained batch 355 in epoch 9, gen_loss = 0.8254912992876567, disc_loss = 0.07939868015917333
Trained batch 356 in epoch 9, gen_loss = 0.8256944092381903, disc_loss = 0.07937694092069854
Trained batch 357 in epoch 9, gen_loss = 0.8254127271015551, disc_loss = 0.07924554921041488
Trained batch 358 in epoch 9, gen_loss = 0.8249000986638507, disc_loss = 0.0793212455616937
Trained batch 359 in epoch 9, gen_loss = 0.8253439775771565, disc_loss = 0.07916508932701416
Trained batch 360 in epoch 9, gen_loss = 0.8258846923915303, disc_loss = 0.07908298970919897
Trained batch 361 in epoch 9, gen_loss = 0.8259118031401661, disc_loss = 0.07894047588439278
Trained batch 362 in epoch 9, gen_loss = 0.8261016490702459, disc_loss = 0.0788388135265713
Trained batch 363 in epoch 9, gen_loss = 0.8258004740371809, disc_loss = 0.07871692722847501
Trained batch 364 in epoch 9, gen_loss = 0.8258694852868171, disc_loss = 0.07859930425678215
Trained batch 365 in epoch 9, gen_loss = 0.8260438759795955, disc_loss = 0.07859583802602656
Trained batch 366 in epoch 9, gen_loss = 0.8254281326275755, disc_loss = 0.07873892817615813
Trained batch 367 in epoch 9, gen_loss = 0.825018432315277, disc_loss = 0.07874885963721444
Trained batch 368 in epoch 9, gen_loss = 0.8261577777746247, disc_loss = 0.07879416574913312
Trained batch 369 in epoch 9, gen_loss = 0.8256461418963768, disc_loss = 0.07883936771871271
Trained batch 370 in epoch 9, gen_loss = 0.8252690366978915, disc_loss = 0.07881116926308591
Trained batch 371 in epoch 9, gen_loss = 0.8247763677950828, disc_loss = 0.07899033809981999
Trained batch 372 in epoch 9, gen_loss = 0.8257788464466944, disc_loss = 0.07899633851950993
Trained batch 373 in epoch 9, gen_loss = 0.8260958127796969, disc_loss = 0.07887943874905134
Trained batch 374 in epoch 9, gen_loss = 0.8256583522160847, disc_loss = 0.07885779828826586
Trained batch 375 in epoch 9, gen_loss = 0.8251620719724513, disc_loss = 0.07885459528126298
Trained batch 376 in epoch 9, gen_loss = 0.8250081015834758, disc_loss = 0.07879411902486172
Trained batch 377 in epoch 9, gen_loss = 0.8254131496583343, disc_loss = 0.07865458737723727
Trained batch 378 in epoch 9, gen_loss = 0.8256435941580418, disc_loss = 0.07857142507754718
Trained batch 379 in epoch 9, gen_loss = 0.8258619214359083, disc_loss = 0.07850800942825643
Trained batch 380 in epoch 9, gen_loss = 0.8258946705365119, disc_loss = 0.0784241749154614
Trained batch 381 in epoch 9, gen_loss = 0.8260935980300005, disc_loss = 0.0783163343522093
Trained batch 382 in epoch 9, gen_loss = 0.8262166773059039, disc_loss = 0.0781868413654849
Trained batch 383 in epoch 9, gen_loss = 0.8259915912834307, disc_loss = 0.07813411703682505
Trained batch 384 in epoch 9, gen_loss = 0.8268587473150971, disc_loss = 0.07800275503427952
Trained batch 385 in epoch 9, gen_loss = 0.8270357187856664, disc_loss = 0.07808756199062179
Trained batch 386 in epoch 9, gen_loss = 0.8272946390686725, disc_loss = 0.07797411989025983
Trained batch 387 in epoch 9, gen_loss = 0.826808074239603, disc_loss = 0.07813525733720396
Trained batch 388 in epoch 9, gen_loss = 0.8266532024258513, disc_loss = 0.07810290910514278
Trained batch 389 in epoch 9, gen_loss = 0.8273517124163798, disc_loss = 0.07799444254965354
Trained batch 390 in epoch 9, gen_loss = 0.8274935967172198, disc_loss = 0.07798113707271988
Trained batch 391 in epoch 9, gen_loss = 0.8271700963377953, disc_loss = 0.0779846787395678
Trained batch 392 in epoch 9, gen_loss = 0.8279217932060474, disc_loss = 0.07782302251791832
Trained batch 393 in epoch 9, gen_loss = 0.8274791332973441, disc_loss = 0.0779677002506359
Trained batch 394 in epoch 9, gen_loss = 0.8273284322098841, disc_loss = 0.07799791690858104
Trained batch 395 in epoch 9, gen_loss = 0.8269525505978652, disc_loss = 0.0780178697855033
Trained batch 396 in epoch 9, gen_loss = 0.8279234196437096, disc_loss = 0.0781708879100736
Trained batch 397 in epoch 9, gen_loss = 0.8277403764688789, disc_loss = 0.0780461561636784
Trained batch 398 in epoch 9, gen_loss = 0.8272848755195924, disc_loss = 0.0782025361989151
Trained batch 399 in epoch 9, gen_loss = 0.8273353677988052, disc_loss = 0.07808281524572522
Trained batch 400 in epoch 9, gen_loss = 0.8270792802075793, disc_loss = 0.07808474892114017
Trained batch 401 in epoch 9, gen_loss = 0.8271483034636844, disc_loss = 0.07805615988332983
Trained batch 402 in epoch 9, gen_loss = 0.8278321932918085, disc_loss = 0.0783883102709617
Trained batch 403 in epoch 9, gen_loss = 0.826909735356227, disc_loss = 0.07857353758933668
Trained batch 404 in epoch 9, gen_loss = 0.8266773925887214, disc_loss = 0.07865749265032786
Trained batch 405 in epoch 9, gen_loss = 0.8266208157163536, disc_loss = 0.07858414153839127
Trained batch 406 in epoch 9, gen_loss = 0.8261856712053097, disc_loss = 0.07861680157153114
Trained batch 407 in epoch 9, gen_loss = 0.8259096366225505, disc_loss = 0.07864058743157953
Trained batch 408 in epoch 9, gen_loss = 0.8258223590466096, disc_loss = 0.07861811298339612
Trained batch 409 in epoch 9, gen_loss = 0.8258849370770338, disc_loss = 0.07853641391436501
Trained batch 410 in epoch 9, gen_loss = 0.8250386057253881, disc_loss = 0.07884301522116736
Trained batch 411 in epoch 9, gen_loss = 0.8257959448162792, disc_loss = 0.07892024775207476
Trained batch 412 in epoch 9, gen_loss = 0.8258944346454472, disc_loss = 0.07882620329736365
Trained batch 413 in epoch 9, gen_loss = 0.8254208314965888, disc_loss = 0.07885734330646801
Trained batch 414 in epoch 9, gen_loss = 0.8254292271941541, disc_loss = 0.07920857162091387
Trained batch 415 in epoch 9, gen_loss = 0.8254389243486983, disc_loss = 0.07911190061489694
Trained batch 416 in epoch 9, gen_loss = 0.824904636870757, disc_loss = 0.07930958882528101
Trained batch 417 in epoch 9, gen_loss = 0.8248395970420974, disc_loss = 0.07916684821248055
Trained batch 418 in epoch 9, gen_loss = 0.8254459742856766, disc_loss = 0.079281003083278
Trained batch 419 in epoch 9, gen_loss = 0.8248741735305105, disc_loss = 0.07944688135314555
Trained batch 420 in epoch 9, gen_loss = 0.8250835186087321, disc_loss = 0.07935177179102093
Trained batch 421 in epoch 9, gen_loss = 0.8254560786542169, disc_loss = 0.0793807136327452
Trained batch 422 in epoch 9, gen_loss = 0.8253182045252329, disc_loss = 0.0792676846080638
Trained batch 423 in epoch 9, gen_loss = 0.8251879393070374, disc_loss = 0.07928848640887805
Trained batch 424 in epoch 9, gen_loss = 0.8248094440207762, disc_loss = 0.07935351184185814
Trained batch 425 in epoch 9, gen_loss = 0.8240976889788265, disc_loss = 0.07954239798053889
Trained batch 426 in epoch 9, gen_loss = 0.8245503362922535, disc_loss = 0.079800902942165
Trained batch 427 in epoch 9, gen_loss = 0.825296592698476, disc_loss = 0.07989881001412868
Trained batch 428 in epoch 9, gen_loss = 0.8247096122422696, disc_loss = 0.08044337324954413
Trained batch 429 in epoch 9, gen_loss = 0.825186390724293, disc_loss = 0.08033361769346303
Trained batch 430 in epoch 9, gen_loss = 0.8252541153862416, disc_loss = 0.08031546811977285
Trained batch 431 in epoch 9, gen_loss = 0.8252562946053567, disc_loss = 0.08026698155811539
Trained batch 432 in epoch 9, gen_loss = 0.8249839522959729, disc_loss = 0.08041217592792203
Trained batch 433 in epoch 9, gen_loss = 0.8254717564390551, disc_loss = 0.08026939746387268
Trained batch 434 in epoch 9, gen_loss = 0.8250032527008276, disc_loss = 0.08030792682849128
Trained batch 435 in epoch 9, gen_loss = 0.8245307135335896, disc_loss = 0.08039543694825074
Trained batch 436 in epoch 9, gen_loss = 0.8254526563721881, disc_loss = 0.08052736349420908
Trained batch 437 in epoch 9, gen_loss = 0.825671629478398, disc_loss = 0.08047112044304201
Trained batch 438 in epoch 9, gen_loss = 0.8257172837480055, disc_loss = 0.0803872921200711
Trained batch 439 in epoch 9, gen_loss = 0.8251492322168567, disc_loss = 0.08061164695430886
Trained batch 440 in epoch 9, gen_loss = 0.8248584688791072, disc_loss = 0.08053346006136362
Trained batch 441 in epoch 9, gen_loss = 0.8248757978235435, disc_loss = 0.08044889827187245
Trained batch 442 in epoch 9, gen_loss = 0.8248115349434838, disc_loss = 0.08049131675915579
Trained batch 443 in epoch 9, gen_loss = 0.8249360366581796, disc_loss = 0.08038606658275868
Trained batch 444 in epoch 9, gen_loss = 0.8243868123949244, disc_loss = 0.08037578241711252
Trained batch 445 in epoch 9, gen_loss = 0.8250795934900574, disc_loss = 0.08054990073323517
Trained batch 446 in epoch 9, gen_loss = 0.8248633725664493, disc_loss = 0.08042544061505555
Trained batch 447 in epoch 9, gen_loss = 0.8245048656660531, disc_loss = 0.08039600777971957
Trained batch 448 in epoch 9, gen_loss = 0.8247588369124186, disc_loss = 0.08024805964267334
Trained batch 449 in epoch 9, gen_loss = 0.8243583097060522, disc_loss = 0.08026543500522773
Trained batch 450 in epoch 9, gen_loss = 0.824063092338008, disc_loss = 0.08017540347252347
Trained batch 451 in epoch 9, gen_loss = 0.8242548578212746, disc_loss = 0.08009178581260211
Trained batch 452 in epoch 9, gen_loss = 0.8240358964365313, disc_loss = 0.08002684365703044
Trained batch 453 in epoch 9, gen_loss = 0.8246462001805789, disc_loss = 0.07991124928358631
Trained batch 454 in epoch 9, gen_loss = 0.8243833538595137, disc_loss = 0.07984878898976923
Trained batch 455 in epoch 9, gen_loss = 0.8243713493279198, disc_loss = 0.07989414227440168
Trained batch 456 in epoch 9, gen_loss = 0.8240408888922217, disc_loss = 0.07988031115586701
Trained batch 457 in epoch 9, gen_loss = 0.8246964902726844, disc_loss = 0.07975029390646901
Trained batch 458 in epoch 9, gen_loss = 0.824688940461165, disc_loss = 0.0796759467498929
Trained batch 459 in epoch 9, gen_loss = 0.8242416184233583, disc_loss = 0.07972510789075624
Trained batch 460 in epoch 9, gen_loss = 0.8244702576168705, disc_loss = 0.07961721810029411
Trained batch 461 in epoch 9, gen_loss = 0.8246489849054452, disc_loss = 0.07948917708887811
Trained batch 462 in epoch 9, gen_loss = 0.8253064570751355, disc_loss = 0.0794961658501535
Trained batch 463 in epoch 9, gen_loss = 0.8249311375849205, disc_loss = 0.07944843739447795
Trained batch 464 in epoch 9, gen_loss = 0.8246752649866125, disc_loss = 0.07935382322037733
Trained batch 465 in epoch 9, gen_loss = 0.8250051962587455, disc_loss = 0.07925931944276002
Trained batch 466 in epoch 9, gen_loss = 0.8255507142564213, disc_loss = 0.07917958046100251
Trained batch 467 in epoch 9, gen_loss = 0.8261545010738902, disc_loss = 0.0791989325099967
Trained batch 468 in epoch 9, gen_loss = 0.8261268129353838, disc_loss = 0.07930981896436418
Trained batch 469 in epoch 9, gen_loss = 0.8261870469818724, disc_loss = 0.07916860757395625
Trained batch 470 in epoch 9, gen_loss = 0.8258430744558889, disc_loss = 0.07922785744395289
Trained batch 471 in epoch 9, gen_loss = 0.8264913224946644, disc_loss = 0.07919071561270156
Trained batch 472 in epoch 9, gen_loss = 0.8265135206959464, disc_loss = 0.07906666553400095
Trained batch 473 in epoch 9, gen_loss = 0.8262046735875214, disc_loss = 0.07901217513580173
Trained batch 474 in epoch 9, gen_loss = 0.8275174895713204, disc_loss = 0.07924602940090393
Trained batch 475 in epoch 9, gen_loss = 0.8274931556412152, disc_loss = 0.07916874668811362
Trained batch 476 in epoch 9, gen_loss = 0.8276578554692259, disc_loss = 0.0790513362169297
Trained batch 477 in epoch 9, gen_loss = 0.8272628304723916, disc_loss = 0.0790721371664693
Trained batch 478 in epoch 9, gen_loss = 0.827116633444589, disc_loss = 0.07908055721539109
Trained batch 479 in epoch 9, gen_loss = 0.8275694640353322, disc_loss = 0.07912743012614859
Trained batch 480 in epoch 9, gen_loss = 0.8271288496912641, disc_loss = 0.07923088650453425
Trained batch 481 in epoch 9, gen_loss = 0.8270268276395639, disc_loss = 0.07918039663149917
Trained batch 482 in epoch 9, gen_loss = 0.8273224746094974, disc_loss = 0.07911634309637683
Trained batch 483 in epoch 9, gen_loss = 0.8275170704919445, disc_loss = 0.07925219236765334
Trained batch 484 in epoch 9, gen_loss = 0.8271836968426852, disc_loss = 0.07929877901699432
Trained batch 485 in epoch 9, gen_loss = 0.8266812900824801, disc_loss = 0.0795222330903596
Trained batch 486 in epoch 9, gen_loss = 0.8271662583708518, disc_loss = 0.07987626813528045
Trained batch 487 in epoch 9, gen_loss = 0.827377982498681, disc_loss = 0.07990807426337641
Trained batch 488 in epoch 9, gen_loss = 0.8271431489590487, disc_loss = 0.07990265081699457
Trained batch 489 in epoch 9, gen_loss = 0.8269011510269982, disc_loss = 0.07986292310097083
Trained batch 490 in epoch 9, gen_loss = 0.8269638703821147, disc_loss = 0.07973454397004819
Trained batch 491 in epoch 9, gen_loss = 0.8272347412094837, disc_loss = 0.07982414264830087
Trained batch 492 in epoch 9, gen_loss = 0.8270857681729973, disc_loss = 0.07975211968309195
Trained batch 493 in epoch 9, gen_loss = 0.8264502444368625, disc_loss = 0.08009997316964182
Trained batch 494 in epoch 9, gen_loss = 0.8270979479707853, disc_loss = 0.08014361807756652
Trained batch 495 in epoch 9, gen_loss = 0.8272778555871018, disc_loss = 0.08002186731262613
Trained batch 496 in epoch 9, gen_loss = 0.8270529245346845, disc_loss = 0.07993611705562538
Trained batch 497 in epoch 9, gen_loss = 0.8270581030103576, disc_loss = 0.07981951783287776
Trained batch 498 in epoch 9, gen_loss = 0.8267445407195655, disc_loss = 0.07975116609698367
Trained batch 499 in epoch 9, gen_loss = 0.8272867596745491, disc_loss = 0.07970097764022649
Trained batch 500 in epoch 9, gen_loss = 0.8269696857282025, disc_loss = 0.07967597478350064
Trained batch 501 in epoch 9, gen_loss = 0.8272975941459496, disc_loss = 0.07958962113978675
Trained batch 502 in epoch 9, gen_loss = 0.8273469185378869, disc_loss = 0.07952098264201557
Trained batch 503 in epoch 9, gen_loss = 0.8273720830560677, disc_loss = 0.07941763172303104
Trained batch 504 in epoch 9, gen_loss = 0.8271690794146888, disc_loss = 0.07935082829640348
Trained batch 505 in epoch 9, gen_loss = 0.8272866692114254, disc_loss = 0.07928984754133543
Trained batch 506 in epoch 9, gen_loss = 0.8274461899165806, disc_loss = 0.07924044287085709
Trained batch 507 in epoch 9, gen_loss = 0.8276205603179969, disc_loss = 0.07912596428627515
Trained batch 508 in epoch 9, gen_loss = 0.8273293070919622, disc_loss = 0.07917637800091552
Trained batch 509 in epoch 9, gen_loss = 0.8276854221142974, disc_loss = 0.07909420097392855
Trained batch 510 in epoch 9, gen_loss = 0.8276334895429779, disc_loss = 0.0790096284427959
Trained batch 511 in epoch 9, gen_loss = 0.8275221399380825, disc_loss = 0.07894807123921055
Trained batch 512 in epoch 9, gen_loss = 0.827503864237672, disc_loss = 0.07900403923451262
Trained batch 513 in epoch 9, gen_loss = 0.8275008925783959, disc_loss = 0.07893707740740263
Trained batch 514 in epoch 9, gen_loss = 0.8271850143242808, disc_loss = 0.07889652323628803
Trained batch 515 in epoch 9, gen_loss = 0.8269343387133391, disc_loss = 0.07895325410699602
Trained batch 516 in epoch 9, gen_loss = 0.8264147840454684, disc_loss = 0.07902794082539166
Trained batch 517 in epoch 9, gen_loss = 0.8268112410794815, disc_loss = 0.07903675542799145
Trained batch 518 in epoch 9, gen_loss = 0.8263403455760897, disc_loss = 0.07912308707481577
Trained batch 519 in epoch 9, gen_loss = 0.8259475587079158, disc_loss = 0.07912941337742198
Trained batch 520 in epoch 9, gen_loss = 0.8264492574557233, disc_loss = 0.07952755452768301
Trained batch 521 in epoch 9, gen_loss = 0.825930928076364, disc_loss = 0.07956156030946708
Trained batch 522 in epoch 9, gen_loss = 0.8257545319957441, disc_loss = 0.07965002126856413
Trained batch 523 in epoch 9, gen_loss = 0.8259961676165348, disc_loss = 0.0797136292512038
Trained batch 524 in epoch 9, gen_loss = 0.8257425842398689, disc_loss = 0.079633461228084
Trained batch 525 in epoch 9, gen_loss = 0.825712507271948, disc_loss = 0.07960362381659476
Trained batch 526 in epoch 9, gen_loss = 0.8256371429002715, disc_loss = 0.07948452340831284
Trained batch 527 in epoch 9, gen_loss = 0.8254068480861007, disc_loss = 0.0794648123873313
Trained batch 528 in epoch 9, gen_loss = 0.8251987893437167, disc_loss = 0.079426045768977
Trained batch 529 in epoch 9, gen_loss = 0.8253876597813841, disc_loss = 0.07943498163817907
Trained batch 530 in epoch 9, gen_loss = 0.8251591135665297, disc_loss = 0.07949064998043852
Trained batch 531 in epoch 9, gen_loss = 0.8248065355464929, disc_loss = 0.07955395432252128
Trained batch 532 in epoch 9, gen_loss = 0.8248558790889511, disc_loss = 0.07966186502322863
Trained batch 533 in epoch 9, gen_loss = 0.825155093149746, disc_loss = 0.079542576281305
Trained batch 534 in epoch 9, gen_loss = 0.8251226303176346, disc_loss = 0.07953535186596841
Trained batch 535 in epoch 9, gen_loss = 0.8253962331409774, disc_loss = 0.07943595307635894
Trained batch 536 in epoch 9, gen_loss = 0.8251331657781725, disc_loss = 0.07939250361229842
Trained batch 537 in epoch 9, gen_loss = 0.8254379030164732, disc_loss = 0.0792822193122403
Trained batch 538 in epoch 9, gen_loss = 0.8252406063349659, disc_loss = 0.07917575731852777
Trained batch 539 in epoch 9, gen_loss = 0.8252526249598574, disc_loss = 0.07927624492354139
Trained batch 540 in epoch 9, gen_loss = 0.8248353681480598, disc_loss = 0.07925977761893363
Trained batch 541 in epoch 9, gen_loss = 0.8246777840096132, disc_loss = 0.07923612926615835
Trained batch 542 in epoch 9, gen_loss = 0.8252238115882347, disc_loss = 0.0794112856755407
Trained batch 543 in epoch 9, gen_loss = 0.8252809851375573, disc_loss = 0.07946726312922478
Trained batch 544 in epoch 9, gen_loss = 0.8253834135488632, disc_loss = 0.07965373834509641
Trained batch 545 in epoch 9, gen_loss = 0.8254492069447871, disc_loss = 0.07964382686519197
Trained batch 546 in epoch 9, gen_loss = 0.8250770084491813, disc_loss = 0.07968286025955919
Trained batch 547 in epoch 9, gen_loss = 0.8253130284647872, disc_loss = 0.07972527814886268
Trained batch 548 in epoch 9, gen_loss = 0.8249105630350895, disc_loss = 0.07981116692611917
Trained batch 549 in epoch 9, gen_loss = 0.8251157770915465, disc_loss = 0.07989957733757116
Trained batch 550 in epoch 9, gen_loss = 0.8252786949087617, disc_loss = 0.07979341034021925
Trained batch 551 in epoch 9, gen_loss = 0.8252497620448687, disc_loss = 0.07973468731717626
Trained batch 552 in epoch 9, gen_loss = 0.8248890244400308, disc_loss = 0.07973009337305645
Trained batch 553 in epoch 9, gen_loss = 0.8251331293088005, disc_loss = 0.07975187924747702
Trained batch 554 in epoch 9, gen_loss = 0.8252785133348929, disc_loss = 0.07966394224581687
Trained batch 555 in epoch 9, gen_loss = 0.8251588237907389, disc_loss = 0.07962532489051333
Trained batch 556 in epoch 9, gen_loss = 0.8251160856744332, disc_loss = 0.07955212666547759
Trained batch 557 in epoch 9, gen_loss = 0.8253146800409509, disc_loss = 0.07952870375319888
Trained batch 558 in epoch 9, gen_loss = 0.8251675168495485, disc_loss = 0.07948746496381667
Trained batch 559 in epoch 9, gen_loss = 0.8249486402209316, disc_loss = 0.07955455306551552
Trained batch 560 in epoch 9, gen_loss = 0.8249810554233252, disc_loss = 0.07943844066272072
Trained batch 561 in epoch 9, gen_loss = 0.8249192790946926, disc_loss = 0.07940949660185659
Trained batch 562 in epoch 9, gen_loss = 0.825084534726812, disc_loss = 0.07937105174207824
Trained batch 563 in epoch 9, gen_loss = 0.8258412975474452, disc_loss = 0.07931110650096221
Trained batch 564 in epoch 9, gen_loss = 0.8256266066985848, disc_loss = 0.07927044321642776
Trained batch 565 in epoch 9, gen_loss = 0.8261029708195912, disc_loss = 0.07915810755760057
Trained batch 566 in epoch 9, gen_loss = 0.8263020831336, disc_loss = 0.07910264539162791
Trained batch 567 in epoch 9, gen_loss = 0.826295511770836, disc_loss = 0.07903861727493382
Trained batch 568 in epoch 9, gen_loss = 0.8259022125355598, disc_loss = 0.079127137981329
Trained batch 569 in epoch 9, gen_loss = 0.8257738739252091, disc_loss = 0.0790625965925293
Trained batch 570 in epoch 9, gen_loss = 0.8266630799569933, disc_loss = 0.07915466063657543
Trained batch 571 in epoch 9, gen_loss = 0.8267025370802079, disc_loss = 0.07907545096501448
Trained batch 572 in epoch 9, gen_loss = 0.8268691726275972, disc_loss = 0.07898305513348307
Trained batch 573 in epoch 9, gen_loss = 0.826942795089313, disc_loss = 0.0788884616216794
Trained batch 574 in epoch 9, gen_loss = 0.8270614006726638, disc_loss = 0.07881132879172978
Trained batch 575 in epoch 9, gen_loss = 0.826971526723355, disc_loss = 0.07875055368802147
Trained batch 576 in epoch 9, gen_loss = 0.827362429486197, disc_loss = 0.07869667247861004
Trained batch 577 in epoch 9, gen_loss = 0.8268482251460164, disc_loss = 0.07884022136376752
Trained batch 578 in epoch 9, gen_loss = 0.8267865931946585, disc_loss = 0.07888276470159156
Trained batch 579 in epoch 9, gen_loss = 0.8266113700024013, disc_loss = 0.07886578248460488
Trained batch 580 in epoch 9, gen_loss = 0.8265691500625184, disc_loss = 0.07879496803555298
Trained batch 581 in epoch 9, gen_loss = 0.8269060030323533, disc_loss = 0.07909920727642081
Trained batch 582 in epoch 9, gen_loss = 0.8266103657706932, disc_loss = 0.07909525601643794
Trained batch 583 in epoch 9, gen_loss = 0.8267390491721565, disc_loss = 0.07904408693996143
Trained batch 584 in epoch 9, gen_loss = 0.8266592839334765, disc_loss = 0.07897572540797484
Trained batch 585 in epoch 9, gen_loss = 0.8267281188187746, disc_loss = 0.07889653343561108
Trained batch 586 in epoch 9, gen_loss = 0.8266572617692476, disc_loss = 0.07889426739972079
Trained batch 587 in epoch 9, gen_loss = 0.8265959349315183, disc_loss = 0.07884084030852787
Trained batch 588 in epoch 9, gen_loss = 0.827446781364483, disc_loss = 0.07909024698289778
Trained batch 589 in epoch 9, gen_loss = 0.8271956977702803, disc_loss = 0.07912086630240082
Trained batch 590 in epoch 9, gen_loss = 0.8268296086747836, disc_loss = 0.0794237060692987
Trained batch 591 in epoch 9, gen_loss = 0.8267940616587529, disc_loss = 0.07974620292284149
Trained batch 592 in epoch 9, gen_loss = 0.8264137679871179, disc_loss = 0.07995036021220493
Trained batch 593 in epoch 9, gen_loss = 0.8262689380031644, disc_loss = 0.07996786600731388
Trained batch 594 in epoch 9, gen_loss = 0.8262358414525746, disc_loss = 0.08036515749521365
Trained batch 595 in epoch 9, gen_loss = 0.8261857072278957, disc_loss = 0.08037887695370455
Trained batch 596 in epoch 9, gen_loss = 0.826067330998991, disc_loss = 0.08035567709068507
Trained batch 597 in epoch 9, gen_loss = 0.8256848836722581, disc_loss = 0.08039093121456412
Trained batch 598 in epoch 9, gen_loss = 0.8258157025693056, disc_loss = 0.08042154368324103
Trained batch 599 in epoch 9, gen_loss = 0.8259009290238222, disc_loss = 0.08041076807149997
Trained batch 600 in epoch 9, gen_loss = 0.8255078850589854, disc_loss = 0.08052204326631969
Trained batch 601 in epoch 9, gen_loss = 0.8251404082557292, disc_loss = 0.08053362397229503
Trained batch 602 in epoch 9, gen_loss = 0.8255871672238877, disc_loss = 0.0804763688793897
Trained batch 603 in epoch 9, gen_loss = 0.8252660582298474, disc_loss = 0.08049974952429681
Trained batch 604 in epoch 9, gen_loss = 0.8254850773279332, disc_loss = 0.08060415979967384
Trained batch 605 in epoch 9, gen_loss = 0.8249449311408272, disc_loss = 0.08079413338579705
Trained batch 606 in epoch 9, gen_loss = 0.8245625292155063, disc_loss = 0.08086749623319413
Trained batch 607 in epoch 9, gen_loss = 0.8248426433358538, disc_loss = 0.08091307647593662
Trained batch 608 in epoch 9, gen_loss = 0.824784358391425, disc_loss = 0.08114786338893015
Trained batch 609 in epoch 9, gen_loss = 0.8241715101922145, disc_loss = 0.08152867402179075
Trained batch 610 in epoch 9, gen_loss = 0.8242349353437532, disc_loss = 0.08157050100333513
Trained batch 611 in epoch 9, gen_loss = 0.8239775319504582, disc_loss = 0.08171478279537576
Trained batch 612 in epoch 9, gen_loss = 0.8241768377251182, disc_loss = 0.08163704274474456
Trained batch 613 in epoch 9, gen_loss = 0.8239572818970448, disc_loss = 0.08160990730067563
Trained batch 614 in epoch 9, gen_loss = 0.8233905466591439, disc_loss = 0.08182227745864207
Trained batch 615 in epoch 9, gen_loss = 0.8235454964753869, disc_loss = 0.08176749208548965
Trained batch 616 in epoch 9, gen_loss = 0.8238857871516211, disc_loss = 0.0817709985555933
Trained batch 617 in epoch 9, gen_loss = 0.823522064871001, disc_loss = 0.08192318096051662
Trained batch 618 in epoch 9, gen_loss = 0.8233297718553435, disc_loss = 0.08184246353425915
Trained batch 619 in epoch 9, gen_loss = 0.8231600603749675, disc_loss = 0.08185452158382583
Trained batch 620 in epoch 9, gen_loss = 0.8236411040147913, disc_loss = 0.0819348560244253
Trained batch 621 in epoch 9, gen_loss = 0.8237331623624758, disc_loss = 0.08188398587113169
Trained batch 622 in epoch 9, gen_loss = 0.8232126574168045, disc_loss = 0.0820731758865054
Trained batch 623 in epoch 9, gen_loss = 0.8231499882367177, disc_loss = 0.08199941471236973
Trained batch 624 in epoch 9, gen_loss = 0.8232638886928558, disc_loss = 0.08199970316141844
Trained batch 625 in epoch 9, gen_loss = 0.8232268375424913, disc_loss = 0.08197231328162474
Trained batch 626 in epoch 9, gen_loss = 0.8229945503068312, disc_loss = 0.08202238059327886
Trained batch 627 in epoch 9, gen_loss = 0.823141338481645, disc_loss = 0.0820752863407396
Trained batch 628 in epoch 9, gen_loss = 0.822717346855112, disc_loss = 0.08209087619549092
Trained batch 629 in epoch 9, gen_loss = 0.8225373074648872, disc_loss = 0.08207280618537749
Trained batch 630 in epoch 9, gen_loss = 0.8227669190963739, disc_loss = 0.08200474869660597
Trained batch 631 in epoch 9, gen_loss = 0.8232278653620919, disc_loss = 0.08195051231238802
Trained batch 632 in epoch 9, gen_loss = 0.823112661757552, disc_loss = 0.08187438053701303
Trained batch 633 in epoch 9, gen_loss = 0.8232730055927102, disc_loss = 0.08177139444793766
Trained batch 634 in epoch 9, gen_loss = 0.8230402088071418, disc_loss = 0.08173241243793035
Trained batch 635 in epoch 9, gen_loss = 0.8232365286668891, disc_loss = 0.08184108985500094
Trained batch 636 in epoch 9, gen_loss = 0.823584649635821, disc_loss = 0.08176770559958002
Trained batch 637 in epoch 9, gen_loss = 0.8230410818956488, disc_loss = 0.08195365854863042
Trained batch 638 in epoch 9, gen_loss = 0.8228231300956953, disc_loss = 0.08187183503248088
Trained batch 639 in epoch 9, gen_loss = 0.8228673939593136, disc_loss = 0.08176644994964591
Trained batch 640 in epoch 9, gen_loss = 0.8232650136612879, disc_loss = 0.08181751743627366
Trained batch 641 in epoch 9, gen_loss = 0.8229965262138212, disc_loss = 0.0818028273713714
Trained batch 642 in epoch 9, gen_loss = 0.8228601319237407, disc_loss = 0.0817671407747023
Trained batch 643 in epoch 9, gen_loss = 0.8230105568163143, disc_loss = 0.08173853578769041
Trained batch 644 in epoch 9, gen_loss = 0.8227261304855347, disc_loss = 0.08177617793946072
Trained batch 645 in epoch 9, gen_loss = 0.8230235235240806, disc_loss = 0.08174407797441717
Trained batch 646 in epoch 9, gen_loss = 0.8227600141139082, disc_loss = 0.08168703331892743
Trained batch 647 in epoch 9, gen_loss = 0.822671115214442, disc_loss = 0.08160074758142187
Trained batch 648 in epoch 9, gen_loss = 0.8226270992509757, disc_loss = 0.08154504073895687
Trained batch 649 in epoch 9, gen_loss = 0.8228283910567944, disc_loss = 0.08145252822826689
Trained batch 650 in epoch 9, gen_loss = 0.8226072541945907, disc_loss = 0.08137839119423598
Trained batch 651 in epoch 9, gen_loss = 0.8225798230229712, disc_loss = 0.08133979837775825
Trained batch 652 in epoch 9, gen_loss = 0.8223755509345856, disc_loss = 0.0813737677204869
Trained batch 653 in epoch 9, gen_loss = 0.8222761309110426, disc_loss = 0.08128108507569093
Trained batch 654 in epoch 9, gen_loss = 0.8223345758350751, disc_loss = 0.08118549423960557
Trained batch 655 in epoch 9, gen_loss = 0.8223352779338999, disc_loss = 0.08110167319097034
Trained batch 656 in epoch 9, gen_loss = 0.8221598354648781, disc_loss = 0.0810403567122202
Trained batch 657 in epoch 9, gen_loss = 0.8227459537403199, disc_loss = 0.08102171775378218
Trained batch 658 in epoch 9, gen_loss = 0.8234594050054305, disc_loss = 0.0809896590770399
Trained batch 659 in epoch 9, gen_loss = 0.8233972821271781, disc_loss = 0.08092644511101146
Trained batch 660 in epoch 9, gen_loss = 0.8231118223129711, disc_loss = 0.08089136268729387
Trained batch 661 in epoch 9, gen_loss = 0.8235037008080958, disc_loss = 0.08079946052502514
Trained batch 662 in epoch 9, gen_loss = 0.8237843669917249, disc_loss = 0.0808611254967738
Trained batch 663 in epoch 9, gen_loss = 0.8232767774936665, disc_loss = 0.08118326045398835
Trained batch 664 in epoch 9, gen_loss = 0.8230727565915961, disc_loss = 0.08111554262809512
Trained batch 665 in epoch 9, gen_loss = 0.8232795430554284, disc_loss = 0.08104710060650029
Trained batch 666 in epoch 9, gen_loss = 0.8233781958269751, disc_loss = 0.0809471400599854
Trained batch 667 in epoch 9, gen_loss = 0.8233594543741135, disc_loss = 0.0809049894182781
Trained batch 668 in epoch 9, gen_loss = 0.8232977241500432, disc_loss = 0.08081404818152321
Trained batch 669 in epoch 9, gen_loss = 0.8229801618341189, disc_loss = 0.08079019547092603
Trained batch 670 in epoch 9, gen_loss = 0.8234137944244238, disc_loss = 0.08081481527070752
Trained batch 671 in epoch 9, gen_loss = 0.8236003322083325, disc_loss = 0.08073306630138263
Trained batch 672 in epoch 9, gen_loss = 0.823979180333873, disc_loss = 0.0806389545418466
Trained batch 673 in epoch 9, gen_loss = 0.8238475672038443, disc_loss = 0.08058634047321865
Trained batch 674 in epoch 9, gen_loss = 0.8241002813091984, disc_loss = 0.08050762184930069
Trained batch 675 in epoch 9, gen_loss = 0.823946725246469, disc_loss = 0.08044668671829329
Trained batch 676 in epoch 9, gen_loss = 0.8238878722909282, disc_loss = 0.08035907369558225
Trained batch 677 in epoch 9, gen_loss = 0.823727097571072, disc_loss = 0.08036713711065749
Trained batch 678 in epoch 9, gen_loss = 0.823913720552981, disc_loss = 0.08041663451561916
Trained batch 679 in epoch 9, gen_loss = 0.8236705628388068, disc_loss = 0.08037799293421866
Trained batch 680 in epoch 9, gen_loss = 0.8238071756390923, disc_loss = 0.08032130728039491
Trained batch 681 in epoch 9, gen_loss = 0.823851809998062, disc_loss = 0.08028182100171437
Trained batch 682 in epoch 9, gen_loss = 0.8240668878373778, disc_loss = 0.08020002141425803
Trained batch 683 in epoch 9, gen_loss = 0.8246208187083752, disc_loss = 0.0801677065288746
Trained batch 684 in epoch 9, gen_loss = 0.8243390906466185, disc_loss = 0.08026092482771534
Trained batch 685 in epoch 9, gen_loss = 0.8247018857878081, disc_loss = 0.08021410472783377
Trained batch 686 in epoch 9, gen_loss = 0.8250101693679499, disc_loss = 0.08011173492153832
Trained batch 687 in epoch 9, gen_loss = 0.8247518957007763, disc_loss = 0.08008607566291683
Trained batch 688 in epoch 9, gen_loss = 0.8252364680798202, disc_loss = 0.08000955556036772
Trained batch 689 in epoch 9, gen_loss = 0.8250844355078711, disc_loss = 0.07993109961566718
Trained batch 690 in epoch 9, gen_loss = 0.8252012011973799, disc_loss = 0.07983555378427382
Trained batch 691 in epoch 9, gen_loss = 0.8249839910365253, disc_loss = 0.07995742083543297
Trained batch 692 in epoch 9, gen_loss = 0.8246494353591621, disc_loss = 0.07996027146884029
Trained batch 693 in epoch 9, gen_loss = 0.8251073254803759, disc_loss = 0.07988804338032901
Trained batch 694 in epoch 9, gen_loss = 0.824956223089918, disc_loss = 0.07983952365386829
Trained batch 695 in epoch 9, gen_loss = 0.8248334636633423, disc_loss = 0.07986814022631566
Trained batch 696 in epoch 9, gen_loss = 0.8252380867428554, disc_loss = 0.07979273299821565
Trained batch 697 in epoch 9, gen_loss = 0.8250874800975821, disc_loss = 0.07975692620879855
Trained batch 698 in epoch 9, gen_loss = 0.8251096949045239, disc_loss = 0.079677886101757
Trained batch 699 in epoch 9, gen_loss = 0.8252715054580143, disc_loss = 0.07969725474981325
Trained batch 700 in epoch 9, gen_loss = 0.8252245929203768, disc_loss = 0.07964416508550906
Trained batch 701 in epoch 9, gen_loss = 0.8249016764157179, disc_loss = 0.07975323348865974
Trained batch 702 in epoch 9, gen_loss = 0.8251859354938925, disc_loss = 0.07972023784743348
Trained batch 703 in epoch 9, gen_loss = 0.8252311534332958, disc_loss = 0.07965029262810606
Trained batch 704 in epoch 9, gen_loss = 0.8256970673588151, disc_loss = 0.07957432893573815
Trained batch 705 in epoch 9, gen_loss = 0.8255740529079275, disc_loss = 0.07953019506131792
Trained batch 706 in epoch 9, gen_loss = 0.8256601516731726, disc_loss = 0.07946371909394291
Trained batch 707 in epoch 9, gen_loss = 0.8251685364182386, disc_loss = 0.0794824529491828
Trained batch 708 in epoch 9, gen_loss = 0.8258391538443115, disc_loss = 0.07970881965983402
Trained batch 709 in epoch 9, gen_loss = 0.8253213877829028, disc_loss = 0.08000075745225792
Trained batch 710 in epoch 9, gen_loss = 0.8254807654731552, disc_loss = 0.08000152793342219
Trained batch 711 in epoch 9, gen_loss = 0.8256082920294799, disc_loss = 0.08003449968972735
Trained batch 712 in epoch 9, gen_loss = 0.8253606334224155, disc_loss = 0.07998911639855753
Trained batch 713 in epoch 9, gen_loss = 0.8257302575502075, disc_loss = 0.07992519360526103
Trained batch 714 in epoch 9, gen_loss = 0.825670886414868, disc_loss = 0.07995949533956868
Trained batch 715 in epoch 9, gen_loss = 0.8255844286450461, disc_loss = 0.07993751753371355
Trained batch 716 in epoch 9, gen_loss = 0.8260040544648882, disc_loss = 0.07986561557592374
Trained batch 717 in epoch 9, gen_loss = 0.8260686436154384, disc_loss = 0.07977169567802117
Trained batch 718 in epoch 9, gen_loss = 0.8258715044391006, disc_loss = 0.07973927208021676
Trained batch 719 in epoch 9, gen_loss = 0.8257912943346633, disc_loss = 0.07980213707907953
Trained batch 720 in epoch 9, gen_loss = 0.8255315552389407, disc_loss = 0.07983419043238013
Trained batch 721 in epoch 9, gen_loss = 0.8257155732517427, disc_loss = 0.0797972227137154
Trained batch 722 in epoch 9, gen_loss = 0.8257305258125025, disc_loss = 0.07972996500430224
Trained batch 723 in epoch 9, gen_loss = 0.8257172130336419, disc_loss = 0.07966245219847239
Trained batch 724 in epoch 9, gen_loss = 0.8256779084945547, disc_loss = 0.07958563593826418
Trained batch 725 in epoch 9, gen_loss = 0.82578063762385, disc_loss = 0.07969424775968365
Trained batch 726 in epoch 9, gen_loss = 0.8254337837558338, disc_loss = 0.07986734416899482
Trained batch 727 in epoch 9, gen_loss = 0.8260115115279025, disc_loss = 0.0798837649572006
Trained batch 728 in epoch 9, gen_loss = 0.8259665109574876, disc_loss = 0.07984253517205128
Trained batch 729 in epoch 9, gen_loss = 0.8258614578883942, disc_loss = 0.07981510926165605
Trained batch 730 in epoch 9, gen_loss = 0.8255893937458582, disc_loss = 0.07979649693033723
Trained batch 731 in epoch 9, gen_loss = 0.8258967151651617, disc_loss = 0.07987425507229494
Trained batch 732 in epoch 9, gen_loss = 0.825774169350386, disc_loss = 0.07983337516933273
Trained batch 733 in epoch 9, gen_loss = 0.8254800622810785, disc_loss = 0.07987413734415856
Trained batch 734 in epoch 9, gen_loss = 0.8256897413406242, disc_loss = 0.07984017751426721
Trained batch 735 in epoch 9, gen_loss = 0.8264166801439031, disc_loss = 0.07980197625938276
Trained batch 736 in epoch 9, gen_loss = 0.826301750164666, disc_loss = 0.07975978618980546
Trained batch 737 in epoch 9, gen_loss = 0.8262108892686968, disc_loss = 0.0796859968582365
Trained batch 738 in epoch 9, gen_loss = 0.8261645502021413, disc_loss = 0.0796517286593339
Trained batch 739 in epoch 9, gen_loss = 0.8261996000602438, disc_loss = 0.07961748377671717
Trained batch 740 in epoch 9, gen_loss = 0.8268993673456504, disc_loss = 0.07975467378286175
Trained batch 741 in epoch 9, gen_loss = 0.8266771708456975, disc_loss = 0.07975512720277969
Trained batch 742 in epoch 9, gen_loss = 0.8264306653316056, disc_loss = 0.07971889469872855
Trained batch 743 in epoch 9, gen_loss = 0.8265293853818089, disc_loss = 0.07967431980350445
Trained batch 744 in epoch 9, gen_loss = 0.8268292013830787, disc_loss = 0.079601968408581
Trained batch 745 in epoch 9, gen_loss = 0.826913113688336, disc_loss = 0.07951238326698382
Trained batch 746 in epoch 9, gen_loss = 0.8268584555172058, disc_loss = 0.07945155389507212
Trained batch 747 in epoch 9, gen_loss = 0.826931550182442, disc_loss = 0.07938363989516296
Trained batch 748 in epoch 9, gen_loss = 0.8271666376469768, disc_loss = 0.07931315271464862
Trained batch 749 in epoch 9, gen_loss = 0.827921946644783, disc_loss = 0.07934651350229979
Trained batch 750 in epoch 9, gen_loss = 0.8282347272699587, disc_loss = 0.07929797698997863
Trained batch 751 in epoch 9, gen_loss = 0.8279024114079298, disc_loss = 0.07956410163983782
Trained batch 752 in epoch 9, gen_loss = 0.8280244508824975, disc_loss = 0.07951460233277297
Trained batch 753 in epoch 9, gen_loss = 0.8285647346502274, disc_loss = 0.07966368618502778
Trained batch 754 in epoch 9, gen_loss = 0.8283027144062598, disc_loss = 0.07980219592272446
Trained batch 755 in epoch 9, gen_loss = 0.8281813924984326, disc_loss = 0.0797432386759846
Trained batch 756 in epoch 9, gen_loss = 0.8282356445272816, disc_loss = 0.07966964171960694
Trained batch 757 in epoch 9, gen_loss = 0.8288604213332752, disc_loss = 0.07983455882410183
Trained batch 758 in epoch 9, gen_loss = 0.8286661125218915, disc_loss = 0.07987323674043255
Trained batch 759 in epoch 9, gen_loss = 0.828652895320403, disc_loss = 0.0798135625075941
Trained batch 760 in epoch 9, gen_loss = 0.8285339389696385, disc_loss = 0.07978628379746822
Trained batch 761 in epoch 9, gen_loss = 0.8286821686142073, disc_loss = 0.07985605207318318
Trained batch 762 in epoch 9, gen_loss = 0.8285397752474989, disc_loss = 0.07980449329500196
Trained batch 763 in epoch 9, gen_loss = 0.8287701919206774, disc_loss = 0.07976160291338544
Trained batch 764 in epoch 9, gen_loss = 0.8286365454882578, disc_loss = 0.07970742839662467
Trained batch 765 in epoch 9, gen_loss = 0.8287739012555727, disc_loss = 0.07962507808790116
Trained batch 766 in epoch 9, gen_loss = 0.8289989576112804, disc_loss = 0.07954932860738684
Trained batch 767 in epoch 9, gen_loss = 0.8292269662876303, disc_loss = 0.0795231712278716
Trained batch 768 in epoch 9, gen_loss = 0.8290070700319908, disc_loss = 0.0795393843174717
Trained batch 769 in epoch 9, gen_loss = 0.8289122324872327, disc_loss = 0.07947115370060329
Trained batch 770 in epoch 9, gen_loss = 0.8289224213585934, disc_loss = 0.07937857648297351
Trained batch 771 in epoch 9, gen_loss = 0.8296322182901783, disc_loss = 0.07944669959091924
Trained batch 772 in epoch 9, gen_loss = 0.8294823648164682, disc_loss = 0.07945236319345922
Trained batch 773 in epoch 9, gen_loss = 0.8296038092953906, disc_loss = 0.07943047338119619
Trained batch 774 in epoch 9, gen_loss = 0.8295235524254461, disc_loss = 0.07938312116649843
Trained batch 775 in epoch 9, gen_loss = 0.8293398897902867, disc_loss = 0.07932203283687074
Trained batch 776 in epoch 9, gen_loss = 0.8294035346274824, disc_loss = 0.07925684391215271
Trained batch 777 in epoch 9, gen_loss = 0.8291915421850578, disc_loss = 0.07923593262694106
Trained batch 778 in epoch 9, gen_loss = 0.8293684033511998, disc_loss = 0.07915702593466208
Trained batch 779 in epoch 9, gen_loss = 0.8300345634420713, disc_loss = 0.07914700073739275
Trained batch 780 in epoch 9, gen_loss = 0.8302967935686075, disc_loss = 0.07905881357750118
Trained batch 781 in epoch 9, gen_loss = 0.8303317899822884, disc_loss = 0.07903726593784206
Trained batch 782 in epoch 9, gen_loss = 0.8304375673086403, disc_loss = 0.07896254466201914
Trained batch 783 in epoch 9, gen_loss = 0.8308596873693929, disc_loss = 0.07894111019369139
Trained batch 784 in epoch 9, gen_loss = 0.8309467832373966, disc_loss = 0.07890409330368801
Trained batch 785 in epoch 9, gen_loss = 0.8312482056196105, disc_loss = 0.07884017883328384
Trained batch 786 in epoch 9, gen_loss = 0.8313978248887626, disc_loss = 0.07876773091953773
Trained batch 787 in epoch 9, gen_loss = 0.8314876013676528, disc_loss = 0.07870091085894232
Trained batch 788 in epoch 9, gen_loss = 0.8315621299057708, disc_loss = 0.07865098003812691
Trained batch 789 in epoch 9, gen_loss = 0.8316221829079374, disc_loss = 0.07860089297394586
Testing Epoch 9
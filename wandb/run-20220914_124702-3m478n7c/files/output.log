/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 915 in epoch 0, gen_loss = 0.5272733833982435, disc_loss = 0.020107393013529467
Testing Epoch 0
Training Epoch 1
Trained batch 915 in epoch 1, gen_loss = 0.46894413086394554, disc_loss = 0.001305575291910839
Testing Epoch 1
Training Epoch 2
Trained batch 915 in epoch 2, gen_loss = 0.46130228143461927, disc_loss = 0.017409805570796816
Testing Epoch 2

Training Epoch 3
Trained batch 915 in epoch 3, gen_loss = 0.4530141405988989, disc_loss = 0.0004953497882366107
Testing Epoch 3
Training Epoch 4
Trained batch 915 in epoch 4, gen_loss = 0.448189490226679, disc_loss = 0.0008264424718399664
Testing Epoch 4
Training Epoch 5
Trained batch 915 in epoch 5, gen_loss = 0.4439790436599452, disc_loss = 0.0006818736994287124
Testing Epoch 5

Training Epoch 6
Trained batch 915 in epoch 6, gen_loss = 0.43606703684514786, disc_loss = 0.0945634079055124
Testing Epoch 6
Training Epoch 7
Trained batch 915 in epoch 7, gen_loss = 0.4193138935029767, disc_loss = 0.04769006712346538
Testing Epoch 7
Training Epoch 8
Trained batch 915 in epoch 8, gen_loss = 0.4123757134260829, disc_loss = 0.01440866241919377
Testing Epoch 8
Training Epoch 9
Trained batch 915 in epoch 9, gen_loss = 0.39875519208967947, disc_loss = 0.07071794840177027
Testing Epoch 9
Training Epoch 10
Trained batch 915 in epoch 10, gen_loss = 0.40853744307654916, disc_loss = 0.059768364456935695
Testing Epoch 10
Training Epoch 11
Trained batch 915 in epoch 11, gen_loss = 0.4116285198965968, disc_loss = 0.017147333038429167
Testing Epoch 11
Training Epoch 12
Trained batch 915 in epoch 12, gen_loss = 0.4037430138534594, disc_loss = 0.03577751869719712
Testing Epoch 12
Training Epoch 13
Trained batch 915 in epoch 13, gen_loss = 0.4031619771208826, disc_loss = 0.003678762371654116
Testing Epoch 13
Training Epoch 14
Trained batch 915 in epoch 14, gen_loss = 0.3998704164341808, disc_loss = 0.0012648484144136402
Testing Epoch 14
Training Epoch 15
Trained batch 915 in epoch 15, gen_loss = 0.3988933455215271, disc_loss = 0.00032520964104981124
Testing Epoch 15
Training Epoch 16
Trained batch 915 in epoch 16, gen_loss = 0.3936472519516424, disc_loss = 0.027619390205151185
Testing Epoch 16
Training Epoch 17
Trained batch 915 in epoch 17, gen_loss = 0.40385451511069154, disc_loss = 0.0532210805572762
Testing Epoch 17

Training Epoch 18
Trained batch 915 in epoch 18, gen_loss = 0.3859652986823211, disc_loss = 0.16730644217210386
Testing Epoch 18
Training Epoch 19
Trained batch 915 in epoch 19, gen_loss = 0.40030262838870156, disc_loss = 0.1431255461221081
Testing Epoch 19

Training Epoch 20
Trained batch 915 in epoch 20, gen_loss = 0.406450610721736, disc_loss = 0.13178545728785404
Testing Epoch 20
/work3/soeba/HALOS/utils.py:110: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axs = plt.subplots(batch_size, 4, figsize=(8,10))
Training Epoch 21
Trained batch 915 in epoch 21, gen_loss = 0.40807107453718455, disc_loss = 0.12847941677395142
Testing Epoch 21
Training Epoch 22
Trained batch 915 in epoch 22, gen_loss = 0.4082466183498697, disc_loss = 0.1295363327577775
Testing Epoch 22
Training Epoch 23
Trained batch 915 in epoch 23, gen_loss = 0.40871954019543383, disc_loss = 0.12659660896782532
Testing Epoch 23
Training Epoch 24
Trained batch 915 in epoch 24, gen_loss = 0.4127010998507254, disc_loss = 0.1131776906529596
Testing Epoch 24
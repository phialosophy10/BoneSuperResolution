wandb: WARNING Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 0.4876778721809387, disc_loss = 0.4772074818611145
Trained batch 1 in epoch 0, gen_loss = 0.5089069902896881, disc_loss = 0.5250570178031921
Trained batch 2 in epoch 0, gen_loss = 0.49980902671813965, disc_loss = 0.489788015683492
Trained batch 3 in epoch 0, gen_loss = 0.5131512880325317, disc_loss = 0.46008457243442535
Trained batch 4 in epoch 0, gen_loss = 0.5044958233833313, disc_loss = 0.4229400098323822
Trained batch 5 in epoch 0, gen_loss = 0.4859984815120697, disc_loss = 0.387961467107137
Trained batch 6 in epoch 0, gen_loss = 0.47892242670059204, disc_loss = 0.35532040681157795
Trained batch 7 in epoch 0, gen_loss = 0.4631398133933544, disc_loss = 0.3282695598900318
Trained batch 8 in epoch 0, gen_loss = 0.4611470070150163, disc_loss = 0.30279527107874554
Trained batch 9 in epoch 0, gen_loss = 0.4664685517549515, disc_loss = 0.28232940658926964
Trained batch 10 in epoch 0, gen_loss = 0.46838126399300317, disc_loss = 0.2656675306233493
Trained batch 11 in epoch 0, gen_loss = 0.465467964609464, disc_loss = 0.2510200360169013
Trained batch 12 in epoch 0, gen_loss = 0.4630809472157405, disc_loss = 0.2393029716152411
Trained batch 13 in epoch 0, gen_loss = 0.46033293647425516, disc_loss = 0.22936309767620905
Trained batch 14 in epoch 0, gen_loss = 0.45462342103322345, disc_loss = 0.22524941265583037
Trained batch 15 in epoch 0, gen_loss = 0.4546917211264372, disc_loss = 0.2245045928284526
Trained batch 16 in epoch 0, gen_loss = 0.46109769449514504, disc_loss = 0.22811041246442235
Trained batch 17 in epoch 0, gen_loss = 0.4588249855571323, disc_loss = 0.22150039507283104
Trained batch 18 in epoch 0, gen_loss = 0.4540897341150987, disc_loss = 0.21649041458180077
Trained batch 19 in epoch 0, gen_loss = 0.457050459086895, disc_loss = 0.21158612743020058
Trained batch 20 in epoch 0, gen_loss = 0.45749705746060326, disc_loss = 0.20472337021714165
Trained batch 21 in epoch 0, gen_loss = 0.45805779641324823, disc_loss = 0.19816396351565013
Trained batch 22 in epoch 0, gen_loss = 0.45822964025580365, disc_loss = 0.19217435886030612
Trained batch 23 in epoch 0, gen_loss = 0.4589993432164192, disc_loss = 0.18693955335766077
Trained batch 24 in epoch 0, gen_loss = 0.45972025871276856, disc_loss = 0.18269598990678787
Trained batch 25 in epoch 0, gen_loss = 0.4622279084645785, disc_loss = 0.1789720095694065
Trained batch 26 in epoch 0, gen_loss = 0.46291852438891373, disc_loss = 0.17522717046516914
Trained batch 27 in epoch 0, gen_loss = 0.45962697586842943, disc_loss = 0.17213026780102933
Trained batch 28 in epoch 0, gen_loss = 0.45955385113584585, disc_loss = 0.16796251514862323
Trained batch 29 in epoch 0, gen_loss = 0.462141810854276, disc_loss = 0.16378394563992818
Trained batch 30 in epoch 0, gen_loss = 0.46221768663775537, disc_loss = 0.159678969652422
Trained batch 31 in epoch 0, gen_loss = 0.4613904096186161, disc_loss = 0.15575824561528862
Trained batch 32 in epoch 0, gen_loss = 0.4598148718024745, disc_loss = 0.15221652941721858
Trained batch 33 in epoch 0, gen_loss = 0.4585806131362915, disc_loss = 0.15008701263543436
Trained batch 34 in epoch 0, gen_loss = 0.45961236272539413, disc_loss = 0.14746139411415374
Trained batch 35 in epoch 0, gen_loss = 0.45999017937315834, disc_loss = 0.14485212560329172
Trained batch 36 in epoch 0, gen_loss = 0.45732500504803014, disc_loss = 0.14264126222681356
Trained batch 37 in epoch 0, gen_loss = 0.4570009575078362, disc_loss = 0.14134364026157478
Trained batch 38 in epoch 0, gen_loss = 0.4607177598354144, disc_loss = 0.13958037052399072
Trained batch 39 in epoch 0, gen_loss = 0.46416072770953176, disc_loss = 0.13749453192576766
Trained batch 40 in epoch 0, gen_loss = 0.4668756439918425, disc_loss = 0.13519022422956256
Trained batch 41 in epoch 0, gen_loss = 0.466914102435112, disc_loss = 0.1335401926189661
Trained batch 42 in epoch 0, gen_loss = 0.46602208739103274, disc_loss = 0.13270722165010695
Trained batch 43 in epoch 0, gen_loss = 0.46605039658871567, disc_loss = 0.1309069346805865
Trained batch 44 in epoch 0, gen_loss = 0.46749977336989507, disc_loss = 0.1288518620034059
Trained batch 45 in epoch 0, gen_loss = 0.46622084275535913, disc_loss = 0.127022967228423
Trained batch 46 in epoch 0, gen_loss = 0.4663491426630223, disc_loss = 0.12569972793472575
Trained batch 47 in epoch 0, gen_loss = 0.46663941629230976, disc_loss = 0.12421564028287928
Trained batch 48 in epoch 0, gen_loss = 0.4669160386737512, disc_loss = 0.12237059978806243
Trained batch 49 in epoch 0, gen_loss = 0.46822325050830843, disc_loss = 0.12039961479604244
Trained batch 50 in epoch 0, gen_loss = 0.46804750491591063, disc_loss = 0.11852209058170225
Trained batch 51 in epoch 0, gen_loss = 0.46762793052655, disc_loss = 0.1167298646357197
Trained batch 52 in epoch 0, gen_loss = 0.46800578483995403, disc_loss = 0.11497359012938896
Trained batch 53 in epoch 0, gen_loss = 0.46772316760487026, disc_loss = 0.11328316583401626
Trained batch 54 in epoch 0, gen_loss = 0.4669412146915089, disc_loss = 0.11164589266885411
Trained batch 55 in epoch 0, gen_loss = 0.4662572347692081, disc_loss = 0.11047233587929181
Trained batch 56 in epoch 0, gen_loss = 0.4649376064016108, disc_loss = 0.11064850447470681
Trained batch 57 in epoch 0, gen_loss = 0.4638418488461396, disc_loss = 0.11314538172606764
Trained batch 58 in epoch 0, gen_loss = 0.464516445236691, disc_loss = 0.11227109005390587
Trained batch 59 in epoch 0, gen_loss = 0.4648394798239072, disc_loss = 0.11161752926806609
Trained batch 60 in epoch 0, gen_loss = 0.46536388700125647, disc_loss = 0.11028918049863128
Trained batch 61 in epoch 0, gen_loss = 0.46646635426628974, disc_loss = 0.10954079945241252
Trained batch 62 in epoch 0, gen_loss = 0.4652977888546293, disc_loss = 0.10852896741458348
Trained batch 63 in epoch 0, gen_loss = 0.46452956460416317, disc_loss = 0.10754579014610499
Trained batch 64 in epoch 0, gen_loss = 0.4649051510370695, disc_loss = 0.10656447376196201
Trained batch 65 in epoch 0, gen_loss = 0.4645474914348487, disc_loss = 0.10554672946984117
Trained batch 66 in epoch 0, gen_loss = 0.4645335047102686, disc_loss = 0.10442906278950065
Trained batch 67 in epoch 0, gen_loss = 0.46438712013118405, disc_loss = 0.10344512442893841
Trained batch 68 in epoch 0, gen_loss = 0.4641344836656598, disc_loss = 0.10257143743228221
Trained batch 69 in epoch 0, gen_loss = 0.46547480693885257, disc_loss = 0.10170069826500756
Trained batch 70 in epoch 0, gen_loss = 0.4655910381968592, disc_loss = 0.10061326562623743
Trained batch 71 in epoch 0, gen_loss = 0.46566101246409947, disc_loss = 0.0996071064275586
Trained batch 72 in epoch 0, gen_loss = 0.46601241010509126, disc_loss = 0.09864051400186265
Trained batch 73 in epoch 0, gen_loss = 0.4658199186260636, disc_loss = 0.09755022476452428
Trained batch 74 in epoch 0, gen_loss = 0.46527378002802533, disc_loss = 0.0966158252209425
Trained batch 75 in epoch 0, gen_loss = 0.4664964056328723, disc_loss = 0.09563748957589269
Trained batch 76 in epoch 0, gen_loss = 0.46655486272527025, disc_loss = 0.09476057207816607
Trained batch 77 in epoch 0, gen_loss = 0.46788859023497653, disc_loss = 0.09407056490771282
Trained batch 78 in epoch 0, gen_loss = 0.4687207578858243, disc_loss = 0.0933375255782393
Trained batch 79 in epoch 0, gen_loss = 0.46831756718456746, disc_loss = 0.092696840967983
Trained batch 80 in epoch 0, gen_loss = 0.46847349699632623, disc_loss = 0.09206700950493048
Trained batch 81 in epoch 0, gen_loss = 0.4683674348563683, disc_loss = 0.09128591200200523
Trained batch 82 in epoch 0, gen_loss = 0.4683904924306525, disc_loss = 0.09061573338077729
Trained batch 83 in epoch 0, gen_loss = 0.46866460357393536, disc_loss = 0.08986645648699432
Trained batch 84 in epoch 0, gen_loss = 0.46846068746903363, disc_loss = 0.08904271991375615
Trained batch 85 in epoch 0, gen_loss = 0.46841075080771777, disc_loss = 0.08818687119542859
Trained batch 86 in epoch 0, gen_loss = 0.46849516068381825, disc_loss = 0.08739238669132364
Trained batch 87 in epoch 0, gen_loss = 0.46887761625376617, disc_loss = 0.08658257594586095
Trained batch 88 in epoch 0, gen_loss = 0.4684369122044424, disc_loss = 0.08578011738868911
Trained batch 89 in epoch 0, gen_loss = 0.46776724921332463, disc_loss = 0.0850506338601311
Trained batch 90 in epoch 0, gen_loss = 0.46847092515819677, disc_loss = 0.0843726177341663
Trained batch 91 in epoch 0, gen_loss = 0.4685981979836588, disc_loss = 0.08364782405450293
Trained batch 92 in epoch 0, gen_loss = 0.469479432670019, disc_loss = 0.0830005678518485
Trained batch 93 in epoch 0, gen_loss = 0.4695239178043731, disc_loss = 0.08230304466362329
Trained batch 94 in epoch 0, gen_loss = 0.4696428421296571, disc_loss = 0.0816440467575663
Trained batch 95 in epoch 0, gen_loss = 0.46915660332888365, disc_loss = 0.08107277564704418
Trained batch 96 in epoch 0, gen_loss = 0.46959971367698355, disc_loss = 0.08043374666540894
Trained batch 97 in epoch 0, gen_loss = 0.4697655609675816, disc_loss = 0.07979842646009459
Trained batch 98 in epoch 0, gen_loss = 0.4699580151625354, disc_loss = 0.0792393781094238
Trained batch 99 in epoch 0, gen_loss = 0.4701553738117218, disc_loss = 0.07880056876689195
Trained batch 100 in epoch 0, gen_loss = 0.4696807820017975, disc_loss = 0.07847235060416825
Trained batch 101 in epoch 0, gen_loss = 0.4701809544189304, disc_loss = 0.07828781096374288
Trained batch 102 in epoch 0, gen_loss = 0.4704807134507929, disc_loss = 0.0788307123392531
Trained batch 103 in epoch 0, gen_loss = 0.4704804320174914, disc_loss = 0.08235035378199357
Trained batch 104 in epoch 0, gen_loss = 0.47023034493128457, disc_loss = 0.08436637549173265
Trained batch 105 in epoch 0, gen_loss = 0.4704774781218115, disc_loss = 0.08778613215347505
Trained batch 106 in epoch 0, gen_loss = 0.47095499863134366, disc_loss = 0.09040356740773281
Trained batch 107 in epoch 0, gen_loss = 0.47030096114785586, disc_loss = 0.09036830164216182
Trained batch 108 in epoch 0, gen_loss = 0.46922786000671735, disc_loss = 0.09084018258326644
Trained batch 109 in epoch 0, gen_loss = 0.469878767024387, disc_loss = 0.09123379263010892
Trained batch 110 in epoch 0, gen_loss = 0.4695805010494885, disc_loss = 0.09140461448345098
Trained batch 111 in epoch 0, gen_loss = 0.46864298331950394, disc_loss = 0.09133362490683794
Trained batch 112 in epoch 0, gen_loss = 0.4685500519993031, disc_loss = 0.09134301108069125
Trained batch 113 in epoch 0, gen_loss = 0.46825286458458815, disc_loss = 0.09194553748034594
Trained batch 114 in epoch 0, gen_loss = 0.4688218653202057, disc_loss = 0.0947141425765079
Trained batch 115 in epoch 0, gen_loss = 0.4696296779759999, disc_loss = 0.09525094862128126
Trained batch 116 in epoch 0, gen_loss = 0.46972659179288095, disc_loss = 0.09601397111884549
Trained batch 117 in epoch 0, gen_loss = 0.46941326230259267, disc_loss = 0.09693845071024813
Trained batch 118 in epoch 0, gen_loss = 0.4691243041463259, disc_loss = 0.10254057791052747
Trained batch 119 in epoch 0, gen_loss = 0.46852140774329504, disc_loss = 0.10380032633741697
Trained batch 120 in epoch 0, gen_loss = 0.4683317199718854, disc_loss = 0.10486940854837086
Trained batch 121 in epoch 0, gen_loss = 0.468295228530149, disc_loss = 0.1053293200789905
Trained batch 122 in epoch 0, gen_loss = 0.4679160324054036, disc_loss = 0.10568186277296485
Trained batch 123 in epoch 0, gen_loss = 0.4667942826786349, disc_loss = 0.10579584514902483
Trained batch 124 in epoch 0, gen_loss = 0.4658537368774414, disc_loss = 0.10572570788860321
Trained batch 125 in epoch 0, gen_loss = 0.4655024778275263, disc_loss = 0.10554138890334538
Trained batch 126 in epoch 0, gen_loss = 0.46547936829994985, disc_loss = 0.10517982481502172
Trained batch 127 in epoch 0, gen_loss = 0.46538124582730234, disc_loss = 0.1046698871650733
Trained batch 128 in epoch 0, gen_loss = 0.4652841532415198, disc_loss = 0.10431875640800757
Trained batch 129 in epoch 0, gen_loss = 0.46488817242475655, disc_loss = 0.10388167414527673
Trained batch 130 in epoch 0, gen_loss = 0.4648672408275022, disc_loss = 0.10356841270477717
Trained batch 131 in epoch 0, gen_loss = 0.4652075553030679, disc_loss = 0.10498120031799331
Trained batch 132 in epoch 0, gen_loss = 0.46485266291109245, disc_loss = 0.10820881591031425
Trained batch 133 in epoch 0, gen_loss = 0.4647630212911919, disc_loss = 0.10845619790367227
Trained batch 134 in epoch 0, gen_loss = 0.4651401312262924, disc_loss = 0.10893788221809599
Trained batch 135 in epoch 0, gen_loss = 0.46508464261012916, disc_loss = 0.10885411824154503
Trained batch 136 in epoch 0, gen_loss = 0.4647267049681531, disc_loss = 0.10895485099214706
Trained batch 137 in epoch 0, gen_loss = 0.4643165605223697, disc_loss = 0.10971608412438545
Trained batch 138 in epoch 0, gen_loss = 0.4640531177572209, disc_loss = 0.11093873428783828
Trained batch 139 in epoch 0, gen_loss = 0.464416569684233, disc_loss = 0.11159936264157296
Trained batch 140 in epoch 0, gen_loss = 0.46408312160072596, disc_loss = 0.11158769223706942
Trained batch 141 in epoch 0, gen_loss = 0.4632893576168678, disc_loss = 0.11182822140169815
Trained batch 142 in epoch 0, gen_loss = 0.46378982671490915, disc_loss = 0.11150070222524497
Trained batch 143 in epoch 0, gen_loss = 0.463759846571419, disc_loss = 0.1111845997058683
Trained batch 144 in epoch 0, gen_loss = 0.4636210912260516, disc_loss = 0.11106584102943026
Trained batch 145 in epoch 0, gen_loss = 0.46407837920809447, disc_loss = 0.1108846756285184
Trained batch 146 in epoch 0, gen_loss = 0.4639843071804566, disc_loss = 0.11104092184378177
Trained batch 147 in epoch 0, gen_loss = 0.4647531889983126, disc_loss = 0.11168968415743596
Trained batch 148 in epoch 0, gen_loss = 0.464384212589904, disc_loss = 0.11183493079355099
Trained batch 149 in epoch 0, gen_loss = 0.4642641419172287, disc_loss = 0.11215141922235489
Trained batch 150 in epoch 0, gen_loss = 0.46378548275556, disc_loss = 0.11372345518197445
Trained batch 151 in epoch 0, gen_loss = 0.4639931842684746, disc_loss = 0.1133465876949853
Trained batch 152 in epoch 0, gen_loss = 0.4638918870025211, disc_loss = 0.11514530601162537
Trained batch 153 in epoch 0, gen_loss = 0.46345474406496273, disc_loss = 0.11544530966935994
Trained batch 154 in epoch 0, gen_loss = 0.46267647089496733, disc_loss = 0.11565961638285267
Trained batch 155 in epoch 0, gen_loss = 0.4626386073919443, disc_loss = 0.11565740050700231
Trained batch 156 in epoch 0, gen_loss = 0.46279886440866314, disc_loss = 0.1154737831063711
Trained batch 157 in epoch 0, gen_loss = 0.4621137516408027, disc_loss = 0.1155840997595953
Trained batch 158 in epoch 0, gen_loss = 0.4615190810752365, disc_loss = 0.11660152483942374
Trained batch 159 in epoch 0, gen_loss = 0.461538496054709, disc_loss = 0.11659928995650262
Trained batch 160 in epoch 0, gen_loss = 0.4616875505965689, disc_loss = 0.11664367460223458
Trained batch 161 in epoch 0, gen_loss = 0.4623573527291969, disc_loss = 0.11651075803847225
Trained batch 162 in epoch 0, gen_loss = 0.4628301491400947, disc_loss = 0.11731106826772719
Trained batch 163 in epoch 0, gen_loss = 0.46253513235871385, disc_loss = 0.11864446591949318
Trained batch 164 in epoch 0, gen_loss = 0.46202843080867423, disc_loss = 0.11903402794039611
Trained batch 165 in epoch 0, gen_loss = 0.46193704332213803, disc_loss = 0.1190297808049314
Trained batch 166 in epoch 0, gen_loss = 0.4617002402950904, disc_loss = 0.11997062215458847
Trained batch 167 in epoch 0, gen_loss = 0.4613573081081822, disc_loss = 0.12044719985819288
Trained batch 168 in epoch 0, gen_loss = 0.4613933014799152, disc_loss = 0.12081273215321395
Trained batch 169 in epoch 0, gen_loss = 0.46132407363723305, disc_loss = 0.12125972726327532
Trained batch 170 in epoch 0, gen_loss = 0.4613658252515291, disc_loss = 0.12198513918365651
Trained batch 171 in epoch 0, gen_loss = 0.46124540044124734, disc_loss = 0.12257847083775802
Trained batch 172 in epoch 0, gen_loss = 0.46077178237755173, disc_loss = 0.12287075117747219
Trained batch 173 in epoch 0, gen_loss = 0.46036374534683666, disc_loss = 0.12334633282460701
Trained batch 174 in epoch 0, gen_loss = 0.4600963647024972, disc_loss = 0.12407973031912531
Trained batch 175 in epoch 0, gen_loss = 0.45969055440615525, disc_loss = 0.12461646390147507
Trained batch 176 in epoch 0, gen_loss = 0.4595026102779949, disc_loss = 0.12480900228276091
Trained batch 177 in epoch 0, gen_loss = 0.45983481658308695, disc_loss = 0.1246699019638675
Trained batch 178 in epoch 0, gen_loss = 0.4597361394146967, disc_loss = 0.12523460989641078
Trained batch 179 in epoch 0, gen_loss = 0.4595150328344769, disc_loss = 0.1261995587290989
Trained batch 180 in epoch 0, gen_loss = 0.4592635684250468, disc_loss = 0.12720180185542582
Trained batch 181 in epoch 0, gen_loss = 0.4593586934791816, disc_loss = 0.1275919657200575
Trained batch 182 in epoch 0, gen_loss = 0.45875485640405955, disc_loss = 0.12802799715777563
Trained batch 183 in epoch 0, gen_loss = 0.45816210624964343, disc_loss = 0.12850224706546767
Trained batch 184 in epoch 0, gen_loss = 0.4580521704377355, disc_loss = 0.12868666328691147
Trained batch 185 in epoch 0, gen_loss = 0.45762079825965307, disc_loss = 0.12951461604285625
Trained batch 186 in epoch 0, gen_loss = 0.4573226712922999, disc_loss = 0.12978063924188282
Trained batch 187 in epoch 0, gen_loss = 0.4568831430787736, disc_loss = 0.13001460163913509
Trained batch 188 in epoch 0, gen_loss = 0.4567673898563183, disc_loss = 0.13014142028001882
Trained batch 189 in epoch 0, gen_loss = 0.4569315946415851, disc_loss = 0.13020207758404706
Trained batch 190 in epoch 0, gen_loss = 0.45661541694745966, disc_loss = 0.13013905635913006
Trained batch 191 in epoch 0, gen_loss = 0.45603782109295327, disc_loss = 0.13052524973560745
Trained batch 192 in epoch 0, gen_loss = 0.4559504221449244, disc_loss = 0.13147614662742985
Trained batch 193 in epoch 0, gen_loss = 0.4563867257735164, disc_loss = 0.13242700763200363
Trained batch 194 in epoch 0, gen_loss = 0.45601529876391095, disc_loss = 0.1330586256698156
Trained batch 195 in epoch 0, gen_loss = 0.4554959921812525, disc_loss = 0.1333614595196381
Trained batch 196 in epoch 0, gen_loss = 0.4548966324873987, disc_loss = 0.13383916343756133
Trained batch 197 in epoch 0, gen_loss = 0.4544272826175497, disc_loss = 0.13431782454176985
Trained batch 198 in epoch 0, gen_loss = 0.45388253624714797, disc_loss = 0.1346968907919062
Trained batch 199 in epoch 0, gen_loss = 0.45341974347829817, disc_loss = 0.13494796281680466
Trained batch 200 in epoch 0, gen_loss = 0.45327951392131066, disc_loss = 0.1350829552173318
Trained batch 201 in epoch 0, gen_loss = 0.45269847373561106, disc_loss = 0.13558904264159133
Trained batch 202 in epoch 0, gen_loss = 0.45221990214780045, disc_loss = 0.13597542317263012
Trained batch 203 in epoch 0, gen_loss = 0.45202165257697013, disc_loss = 0.13620251254635116
Trained batch 204 in epoch 0, gen_loss = 0.45209719800367587, disc_loss = 0.13633006838400188
Trained batch 205 in epoch 0, gen_loss = 0.45178646572585246, disc_loss = 0.13678135627030746
Trained batch 206 in epoch 0, gen_loss = 0.45133726809911684, disc_loss = 0.1373453309966458
Trained batch 207 in epoch 0, gen_loss = 0.4513955225165074, disc_loss = 0.1381143500419477
Trained batch 208 in epoch 0, gen_loss = 0.4514336313642383, disc_loss = 0.13847851680155004
Trained batch 209 in epoch 0, gen_loss = 0.45100887502942766, disc_loss = 0.13883743085676714
Trained batch 210 in epoch 0, gen_loss = 0.45071452728944933, disc_loss = 0.1392105042899107
Trained batch 211 in epoch 0, gen_loss = 0.4502530859888725, disc_loss = 0.1395605630153474
Trained batch 212 in epoch 0, gen_loss = 0.44985837639777315, disc_loss = 0.13996146078890478
Trained batch 213 in epoch 0, gen_loss = 0.4495558928106433, disc_loss = 0.1404690149057413
Trained batch 214 in epoch 0, gen_loss = 0.4495072240053221, disc_loss = 0.1409570869145005
Trained batch 215 in epoch 0, gen_loss = 0.4491924124735373, disc_loss = 0.1413374902439062
Trained batch 216 in epoch 0, gen_loss = 0.44887571661703046, disc_loss = 0.1416701940038512
Trained batch 217 in epoch 0, gen_loss = 0.44890037589116927, disc_loss = 0.14180565083724098
Trained batch 218 in epoch 0, gen_loss = 0.44876665203538657, disc_loss = 0.14214117687246572
Trained batch 219 in epoch 0, gen_loss = 0.4482720948078416, disc_loss = 0.14273954025385055
Trained batch 220 in epoch 0, gen_loss = 0.4477219909294698, disc_loss = 0.14328149653870056
Trained batch 221 in epoch 0, gen_loss = 0.44742224801768055, disc_loss = 0.1435907230553058
Trained batch 222 in epoch 0, gen_loss = 0.4469334309411156, disc_loss = 0.14401731474717636
Trained batch 223 in epoch 0, gen_loss = 0.4467644373487149, disc_loss = 0.14426092003538674
Trained batch 224 in epoch 0, gen_loss = 0.4466350589858161, disc_loss = 0.14456379094057614
Trained batch 225 in epoch 0, gen_loss = 0.44653280171672854, disc_loss = 0.14475524252428945
Trained batch 226 in epoch 0, gen_loss = 0.44631885379421554, disc_loss = 0.14501480290477498
Trained batch 227 in epoch 0, gen_loss = 0.445938242762758, disc_loss = 0.1455405017099621
Trained batch 228 in epoch 0, gen_loss = 0.4460957231219679, disc_loss = 0.1457533275944437
Trained batch 229 in epoch 0, gen_loss = 0.445732363410618, disc_loss = 0.14625095885408962
Trained batch 230 in epoch 0, gen_loss = 0.4452129816596126, disc_loss = 0.14672173312925674
Trained batch 231 in epoch 0, gen_loss = 0.4449120555715314, disc_loss = 0.14682515207999225
Trained batch 232 in epoch 0, gen_loss = 0.44477338890660983, disc_loss = 0.14709133483757278
Trained batch 233 in epoch 0, gen_loss = 0.4446972346203959, disc_loss = 0.14732445278165177
Trained batch 234 in epoch 0, gen_loss = 0.4442589120661959, disc_loss = 0.14775173351802726
Trained batch 235 in epoch 0, gen_loss = 0.4440231162865283, disc_loss = 0.148258227965463
Trained batch 236 in epoch 0, gen_loss = 0.44360933323952717, disc_loss = 0.14874489629004575
Trained batch 237 in epoch 0, gen_loss = 0.44299402219407696, disc_loss = 0.14897184228884572
Trained batch 238 in epoch 0, gen_loss = 0.442598059960489, disc_loss = 0.1491712016758809
Trained batch 239 in epoch 0, gen_loss = 0.44227311126887797, disc_loss = 0.1492418965169539
Trained batch 240 in epoch 0, gen_loss = 0.44210863855369853, disc_loss = 0.14934546835875115
Trained batch 241 in epoch 0, gen_loss = 0.4418878595937382, disc_loss = 0.14945337716643967
Trained batch 242 in epoch 0, gen_loss = 0.44155663153762187, disc_loss = 0.14954489921775374
Trained batch 243 in epoch 0, gen_loss = 0.4411526508018619, disc_loss = 0.14987107590756943
Trained batch 244 in epoch 0, gen_loss = 0.44096666671791857, disc_loss = 0.15001247377724064
Trained batch 245 in epoch 0, gen_loss = 0.4405329537585499, disc_loss = 0.15030396061881288
Trained batch 246 in epoch 0, gen_loss = 0.4401752128292192, disc_loss = 0.15077962281431265
Trained batch 247 in epoch 0, gen_loss = 0.4402741805439995, disc_loss = 0.1511078884134129
Trained batch 248 in epoch 0, gen_loss = 0.4401419257303797, disc_loss = 0.1511307627890244
Trained batch 249 in epoch 0, gen_loss = 0.4402731614112854, disc_loss = 0.1513135879486799
Trained batch 250 in epoch 0, gen_loss = 0.44011992406085193, disc_loss = 0.15171546555788393
Trained batch 251 in epoch 0, gen_loss = 0.43984168649665895, disc_loss = 0.15193700995887555
Trained batch 252 in epoch 0, gen_loss = 0.43939246302065643, disc_loss = 0.152080479273094
Trained batch 253 in epoch 0, gen_loss = 0.43900930365239543, disc_loss = 0.1520916993077111
Trained batch 254 in epoch 0, gen_loss = 0.4387346896470762, disc_loss = 0.15213463445212327
Trained batch 255 in epoch 0, gen_loss = 0.43830885679926723, disc_loss = 0.15224452629627194
Trained batch 256 in epoch 0, gen_loss = 0.4381177823135361, disc_loss = 0.1523244378486728
Trained batch 257 in epoch 0, gen_loss = 0.437779453027156, disc_loss = 0.15266299731451874
Trained batch 258 in epoch 0, gen_loss = 0.4374907150231733, disc_loss = 0.15338066759659516
Trained batch 259 in epoch 0, gen_loss = 0.43725453053529445, disc_loss = 0.1536347004513328
Trained batch 260 in epoch 0, gen_loss = 0.4369395167434809, disc_loss = 0.1537576802360372
Trained batch 261 in epoch 0, gen_loss = 0.4366261012681568, disc_loss = 0.15399758010135808
Trained batch 262 in epoch 0, gen_loss = 0.4363817325563032, disc_loss = 0.15411831975379825
Trained batch 263 in epoch 0, gen_loss = 0.4360991798792825, disc_loss = 0.15420844844739998
Trained batch 264 in epoch 0, gen_loss = 0.43576358219362654, disc_loss = 0.1543364609046927
Trained batch 265 in epoch 0, gen_loss = 0.4355281633990152, disc_loss = 0.15448704584592715
Trained batch 266 in epoch 0, gen_loss = 0.43525069851553844, disc_loss = 0.15443991915730948
Trained batch 267 in epoch 0, gen_loss = 0.43512727331314516, disc_loss = 0.15457258861400744
Trained batch 268 in epoch 0, gen_loss = 0.43473770228460373, disc_loss = 0.15466368872824654
Trained batch 269 in epoch 0, gen_loss = 0.43448837101459503, disc_loss = 0.15462098451400244
Trained batch 270 in epoch 0, gen_loss = 0.43428607059580815, disc_loss = 0.15474426481061757
Trained batch 271 in epoch 0, gen_loss = 0.4340629419859718, disc_loss = 0.154983024153968
Trained batch 272 in epoch 0, gen_loss = 0.434000680407325, disc_loss = 0.15508082851549207
Trained batch 273 in epoch 0, gen_loss = 0.43393882151937835, disc_loss = 0.15521363798447335
Trained batch 274 in epoch 0, gen_loss = 0.43369519851424476, disc_loss = 0.1556070440872149
Trained batch 275 in epoch 0, gen_loss = 0.43398796248695126, disc_loss = 0.15559995421410902
Trained batch 276 in epoch 0, gen_loss = 0.43382159542520987, disc_loss = 0.1558459959386273
Trained batch 277 in epoch 0, gen_loss = 0.43347748674505904, disc_loss = 0.15646654216023229
Trained batch 278 in epoch 0, gen_loss = 0.4333691537166582, disc_loss = 0.1563746887376018
Trained batch 279 in epoch 0, gen_loss = 0.43365090446812765, disc_loss = 0.1563203758294029
Trained batch 280 in epoch 0, gen_loss = 0.4334145669835318, disc_loss = 0.15643367880550993
Trained batch 281 in epoch 0, gen_loss = 0.4330744129334781, disc_loss = 0.15676089015571362
Trained batch 282 in epoch 0, gen_loss = 0.4331075033113729, disc_loss = 0.15691783743854545
Trained batch 283 in epoch 0, gen_loss = 0.43314179431804467, disc_loss = 0.15714449932615102
Trained batch 284 in epoch 0, gen_loss = 0.43308936671206827, disc_loss = 0.15741346200045786
Trained batch 285 in epoch 0, gen_loss = 0.4330321737936327, disc_loss = 0.1574251489075539
Trained batch 286 in epoch 0, gen_loss = 0.4332489719166573, disc_loss = 0.1574336954811101
Trained batch 287 in epoch 0, gen_loss = 0.4332739921907584, disc_loss = 0.15779134205594245
Trained batch 288 in epoch 0, gen_loss = 0.43322603100311385, disc_loss = 0.15771118026858383
Trained batch 289 in epoch 0, gen_loss = 0.432960150570705, disc_loss = 0.15776316270489119
Trained batch 290 in epoch 0, gen_loss = 0.43287867840213057, disc_loss = 0.15769109277125076
Trained batch 291 in epoch 0, gen_loss = 0.4326959228883051, disc_loss = 0.15756058638073403
Trained batch 292 in epoch 0, gen_loss = 0.4325028278518455, disc_loss = 0.157474707481499
Trained batch 293 in epoch 0, gen_loss = 0.43222519076194893, disc_loss = 0.1575140399718974
Trained batch 294 in epoch 0, gen_loss = 0.4320390242641255, disc_loss = 0.15788758499389988
Trained batch 295 in epoch 0, gen_loss = 0.43174929735628337, disc_loss = 0.15857616219216505
Trained batch 296 in epoch 0, gen_loss = 0.43187762972481725, disc_loss = 0.1589451559791059
Trained batch 297 in epoch 0, gen_loss = 0.43200558544005324, disc_loss = 0.1590755088942363
Trained batch 298 in epoch 0, gen_loss = 0.43190817370462575, disc_loss = 0.15910515678816017
Trained batch 299 in epoch 0, gen_loss = 0.4317926553885142, disc_loss = 0.15906094587097566
Trained batch 300 in epoch 0, gen_loss = 0.4316023358474934, disc_loss = 0.15917008012483683
Trained batch 301 in epoch 0, gen_loss = 0.43124858442915986, disc_loss = 0.1592154038194197
Trained batch 302 in epoch 0, gen_loss = 0.43134212798804733, disc_loss = 0.15906108253122164
Trained batch 303 in epoch 0, gen_loss = 0.43137484573219953, disc_loss = 0.15890836158130123
Trained batch 304 in epoch 0, gen_loss = 0.43123190872004774, disc_loss = 0.15889122853757906
Trained batch 305 in epoch 0, gen_loss = 0.43103645420541953, disc_loss = 0.1593774605445028
Trained batch 306 in epoch 0, gen_loss = 0.43094494744698464, disc_loss = 0.15932279151746037
Trained batch 307 in epoch 0, gen_loss = 0.4307184522221615, disc_loss = 0.15924044375537666
Trained batch 308 in epoch 0, gen_loss = 0.4306281284221168, disc_loss = 0.15902143158621387
Trained batch 309 in epoch 0, gen_loss = 0.43030588915271145, disc_loss = 0.15923372431387825
Trained batch 310 in epoch 0, gen_loss = 0.43018708648788967, disc_loss = 0.15943768549818318
Trained batch 311 in epoch 0, gen_loss = 0.42994593991301, disc_loss = 0.1594478084037128
Trained batch 312 in epoch 0, gen_loss = 0.4299755925758959, disc_loss = 0.15927624970246046
Trained batch 313 in epoch 0, gen_loss = 0.4299319226081204, disc_loss = 0.15961757142120486
Trained batch 314 in epoch 0, gen_loss = 0.42975575450866943, disc_loss = 0.1596361677916277
Trained batch 315 in epoch 0, gen_loss = 0.4292584429436092, disc_loss = 0.15976590414449007
Trained batch 316 in epoch 0, gen_loss = 0.4291809110047313, disc_loss = 0.15966413272339086
Trained batch 317 in epoch 0, gen_loss = 0.4291153537964671, disc_loss = 0.15958282446383304
Trained batch 318 in epoch 0, gen_loss = 0.4286746660183216, disc_loss = 0.15970232383257543
Trained batch 319 in epoch 0, gen_loss = 0.42839462934061884, disc_loss = 0.15956013115355744
Trained batch 320 in epoch 0, gen_loss = 0.4283971273082068, disc_loss = 0.15927119579781254
Trained batch 321 in epoch 0, gen_loss = 0.42817118560305295, disc_loss = 0.15909856818153623
Trained batch 322 in epoch 0, gen_loss = 0.42839790294783037, disc_loss = 0.15869402500221236
Trained batch 323 in epoch 0, gen_loss = 0.42823299912758817, disc_loss = 0.15853387370337674
Trained batch 324 in epoch 0, gen_loss = 0.428010454086157, disc_loss = 0.15905442141569578
Trained batch 325 in epoch 0, gen_loss = 0.42790456746984845, disc_loss = 0.1593171949126969
Trained batch 326 in epoch 0, gen_loss = 0.42779173581242924, disc_loss = 0.1596834976283053
Trained batch 327 in epoch 0, gen_loss = 0.4275608629715152, disc_loss = 0.16000495746550036
Trained batch 328 in epoch 0, gen_loss = 0.4274968585525965, disc_loss = 0.16000032375105247
Trained batch 329 in epoch 0, gen_loss = 0.4274092301274791, disc_loss = 0.16009977216070348
Trained batch 330 in epoch 0, gen_loss = 0.4274478418769433, disc_loss = 0.15993824398589637
Trained batch 331 in epoch 0, gen_loss = 0.4272702718714634, disc_loss = 0.15983078700591283
Trained batch 332 in epoch 0, gen_loss = 0.42720937290349165, disc_loss = 0.15972608332340424
Trained batch 333 in epoch 0, gen_loss = 0.4271488129914164, disc_loss = 0.15938621789529295
Trained batch 334 in epoch 0, gen_loss = 0.4275346466854437, disc_loss = 0.15932726396331146
Trained batch 335 in epoch 0, gen_loss = 0.4274494716276725, disc_loss = 0.15924408507444673
Trained batch 336 in epoch 0, gen_loss = 0.4274756836785053, disc_loss = 0.15886875507297432
Trained batch 337 in epoch 0, gen_loss = 0.4276427992525891, disc_loss = 0.15863019820941976
Trained batch 338 in epoch 0, gen_loss = 0.42740945003728953, disc_loss = 0.15865869681655834
Trained batch 339 in epoch 0, gen_loss = 0.4275796973529984, disc_loss = 0.15925000211333526
Trained batch 340 in epoch 0, gen_loss = 0.4276329029864929, disc_loss = 0.15894070505833696
Trained batch 341 in epoch 0, gen_loss = 0.4272049216673388, disc_loss = 0.15910191491943354
Trained batch 342 in epoch 0, gen_loss = 0.4269251427219491, disc_loss = 0.15959222121680094
Trained batch 343 in epoch 0, gen_loss = 0.4267186419388583, disc_loss = 0.16002750819072473
Trained batch 344 in epoch 0, gen_loss = 0.42652579537336377, disc_loss = 0.16007864356472873
Trained batch 345 in epoch 0, gen_loss = 0.4265638724227861, disc_loss = 0.15994296905536182
Trained batch 346 in epoch 0, gen_loss = 0.42649649113674326, disc_loss = 0.15990855944173823
Trained batch 347 in epoch 0, gen_loss = 0.42627579710264313, disc_loss = 0.16000212910959774
Trained batch 348 in epoch 0, gen_loss = 0.4261010992834425, disc_loss = 0.16045336875754987
Trained batch 349 in epoch 0, gen_loss = 0.42582964709826876, disc_loss = 0.1606870879658631
Trained batch 350 in epoch 0, gen_loss = 0.42574425122337123, disc_loss = 0.16082201530875642
Trained batch 351 in epoch 0, gen_loss = 0.42549656373871997, disc_loss = 0.16117035134018146
Trained batch 352 in epoch 0, gen_loss = 0.42529211444490017, disc_loss = 0.16137539759995917
Trained batch 353 in epoch 0, gen_loss = 0.4251777174445869, disc_loss = 0.16129324233717163
Trained batch 354 in epoch 0, gen_loss = 0.42499350418507215, disc_loss = 0.16126528380202576
Trained batch 355 in epoch 0, gen_loss = 0.424721415123243, disc_loss = 0.16119867649054928
Trained batch 356 in epoch 0, gen_loss = 0.42451761675482036, disc_loss = 0.16105605881003773
Trained batch 357 in epoch 0, gen_loss = 0.42440318661695087, disc_loss = 0.16119084038964196
Trained batch 358 in epoch 0, gen_loss = 0.4242705022890256, disc_loss = 0.16113283551586038
Trained batch 359 in epoch 0, gen_loss = 0.4243590232398775, disc_loss = 0.1611224664789107
Trained batch 360 in epoch 0, gen_loss = 0.4242839950273572, disc_loss = 0.16095771388746694
Trained batch 361 in epoch 0, gen_loss = 0.4239132260255392, disc_loss = 0.16110718042399344
Trained batch 362 in epoch 0, gen_loss = 0.4235871623041873, disc_loss = 0.16154310523888954
Trained batch 363 in epoch 0, gen_loss = 0.4235734888812998, disc_loss = 0.1616670128858679
Trained batch 364 in epoch 0, gen_loss = 0.4235242991414789, disc_loss = 0.1615085145382032
Trained batch 365 in epoch 0, gen_loss = 0.42335916705470267, disc_loss = 0.1614711800885331
Trained batch 366 in epoch 0, gen_loss = 0.42327838616410135, disc_loss = 0.16134598483750215
Trained batch 367 in epoch 0, gen_loss = 0.4230019665606644, disc_loss = 0.16122635632105495
Trained batch 368 in epoch 0, gen_loss = 0.42288048722879673, disc_loss = 0.161099726813757
Trained batch 369 in epoch 0, gen_loss = 0.42265655341986064, disc_loss = 0.16091532463560232
Trained batch 370 in epoch 0, gen_loss = 0.422499152126338, disc_loss = 0.1608035906024699
Trained batch 371 in epoch 0, gen_loss = 0.422382729348316, disc_loss = 0.16099730893088285
Trained batch 372 in epoch 0, gen_loss = 0.42226489779137416, disc_loss = 0.16086762494360154
Trained batch 373 in epoch 0, gen_loss = 0.42232032813490394, disc_loss = 0.16072904715005726
Trained batch 374 in epoch 0, gen_loss = 0.42214099780718484, disc_loss = 0.16081173306703567
Trained batch 375 in epoch 0, gen_loss = 0.42180537622659764, disc_loss = 0.16128121623571248
Trained batch 376 in epoch 0, gen_loss = 0.42175377640547107, disc_loss = 0.16137201872602383
Trained batch 377 in epoch 0, gen_loss = 0.42161525998796734, disc_loss = 0.16140931042492704
Trained batch 378 in epoch 0, gen_loss = 0.42147502656976904, disc_loss = 0.16149635953057095
Trained batch 379 in epoch 0, gen_loss = 0.42121379022535527, disc_loss = 0.16152278869167755
Trained batch 380 in epoch 0, gen_loss = 0.4211379220010102, disc_loss = 0.1614728412955139
Trained batch 381 in epoch 0, gen_loss = 0.420876907038439, disc_loss = 0.1614069112659437
Trained batch 382 in epoch 0, gen_loss = 0.4208616244730688, disc_loss = 0.16121582564345852
Trained batch 383 in epoch 0, gen_loss = 0.42072499574472505, disc_loss = 0.1610959903531087
Trained batch 384 in epoch 0, gen_loss = 0.4204712608417907, disc_loss = 0.16115224371095757
Trained batch 385 in epoch 0, gen_loss = 0.4204631910268507, disc_loss = 0.1610789106184028
Trained batch 386 in epoch 0, gen_loss = 0.4204746960669525, disc_loss = 0.16091928053502888
Trained batch 387 in epoch 0, gen_loss = 0.4202790338661253, disc_loss = 0.16089220297013976
Trained batch 388 in epoch 0, gen_loss = 0.4200253584697498, disc_loss = 0.1608442127666314
Trained batch 389 in epoch 0, gen_loss = 0.4200279010412021, disc_loss = 0.16109790563201293
Trained batch 390 in epoch 0, gen_loss = 0.4197627546842141, disc_loss = 0.16153860928686073
Trained batch 391 in epoch 0, gen_loss = 0.4197780978010625, disc_loss = 0.16131023330880062
Trained batch 392 in epoch 0, gen_loss = 0.41979743536495373, disc_loss = 0.16100316312704377
Trained batch 393 in epoch 0, gen_loss = 0.4196470392688277, disc_loss = 0.1610148852587049
Trained batch 394 in epoch 0, gen_loss = 0.41961002953444854, disc_loss = 0.16079494668335853
Trained batch 395 in epoch 0, gen_loss = 0.4194886674634134, disc_loss = 0.16081719975354095
Trained batch 396 in epoch 0, gen_loss = 0.4195387825857782, disc_loss = 0.16079017172757565
Trained batch 397 in epoch 0, gen_loss = 0.4194038116452682, disc_loss = 0.16072180030408817
Trained batch 398 in epoch 0, gen_loss = 0.41926690099532143, disc_loss = 0.16055986025653088
Trained batch 399 in epoch 0, gen_loss = 0.41926283851265905, disc_loss = 0.1605381136201322
Trained batch 400 in epoch 0, gen_loss = 0.4194467355336929, disc_loss = 0.1610550605262307
Trained batch 401 in epoch 0, gen_loss = 0.4190355634214866, disc_loss = 0.16171757704508838
Trained batch 402 in epoch 0, gen_loss = 0.4190257863874175, disc_loss = 0.1622814223835841
Trained batch 403 in epoch 0, gen_loss = 0.4189988269959346, disc_loss = 0.16284999625738894
Trained batch 404 in epoch 0, gen_loss = 0.41884991901892205, disc_loss = 0.1630880273970557
Trained batch 405 in epoch 0, gen_loss = 0.4185984249185459, disc_loss = 0.16346011107117672
Trained batch 406 in epoch 0, gen_loss = 0.41842903947361565, disc_loss = 0.16372721623949688
Trained batch 407 in epoch 0, gen_loss = 0.4182478082092369, disc_loss = 0.16381815373532327
Trained batch 408 in epoch 0, gen_loss = 0.41826271340433135, disc_loss = 0.16375398043825456
Trained batch 409 in epoch 0, gen_loss = 0.4180552907833239, disc_loss = 0.163813332068484
Trained batch 410 in epoch 0, gen_loss = 0.41787875090202276, disc_loss = 0.16388088557189398
Trained batch 411 in epoch 0, gen_loss = 0.4177679621334215, disc_loss = 0.16396868585165844
Trained batch 412 in epoch 0, gen_loss = 0.41768797084725223, disc_loss = 0.16398043762757183
Trained batch 413 in epoch 0, gen_loss = 0.41746274846187537, disc_loss = 0.16406429571589987
Trained batch 414 in epoch 0, gen_loss = 0.41743254403033886, disc_loss = 0.16410622447729112
Trained batch 415 in epoch 0, gen_loss = 0.41732263214026505, disc_loss = 0.16402268655096683
Trained batch 416 in epoch 0, gen_loss = 0.41712762762030825, disc_loss = 0.16396510313383394
Trained batch 417 in epoch 0, gen_loss = 0.41717739274912474, disc_loss = 0.16379306641848465
Trained batch 418 in epoch 0, gen_loss = 0.4170700948961026, disc_loss = 0.16375004407685242
Trained batch 419 in epoch 0, gen_loss = 0.4168937271549588, disc_loss = 0.16396076262352013
Trained batch 420 in epoch 0, gen_loss = 0.416719474376239, disc_loss = 0.16403798049320234
Trained batch 421 in epoch 0, gen_loss = 0.4167958300966787, disc_loss = 0.1638160329753471
Trained batch 422 in epoch 0, gen_loss = 0.41661098148524056, disc_loss = 0.16384899160047514
Trained batch 423 in epoch 0, gen_loss = 0.41629671621716247, disc_loss = 0.16402305207513976
Trained batch 424 in epoch 0, gen_loss = 0.41617171126253466, disc_loss = 0.16400523517061683
Trained batch 425 in epoch 0, gen_loss = 0.4160525189459044, disc_loss = 0.16398826047358378
Trained batch 426 in epoch 0, gen_loss = 0.41602796169578055, disc_loss = 0.16395155141518322
Trained batch 427 in epoch 0, gen_loss = 0.41588845424284443, disc_loss = 0.16395305022249154
Trained batch 428 in epoch 0, gen_loss = 0.41572865392222547, disc_loss = 0.1638725977434423
Trained batch 429 in epoch 0, gen_loss = 0.41564102658005647, disc_loss = 0.16384818576449572
Trained batch 430 in epoch 0, gen_loss = 0.415517641607404, disc_loss = 0.16378269883914226
Trained batch 431 in epoch 0, gen_loss = 0.41539485607710147, disc_loss = 0.16369298988677286
Trained batch 432 in epoch 0, gen_loss = 0.4153623047519226, disc_loss = 0.16356240384986165
Trained batch 433 in epoch 0, gen_loss = 0.4153258697503173, disc_loss = 0.16344627659029676
Trained batch 434 in epoch 0, gen_loss = 0.41531177306997363, disc_loss = 0.1637696905040193
Trained batch 435 in epoch 0, gen_loss = 0.41532052342497977, disc_loss = 0.1636118070316424
Trained batch 436 in epoch 0, gen_loss = 0.4152566270233565, disc_loss = 0.1635724410107807
Trained batch 437 in epoch 0, gen_loss = 0.41537852680574266, disc_loss = 0.1635076263111476
Trained batch 438 in epoch 0, gen_loss = 0.4152920690783064, disc_loss = 0.1633522327573533
Trained batch 439 in epoch 0, gen_loss = 0.41509070220318706, disc_loss = 0.1631741284138777
Trained batch 440 in epoch 0, gen_loss = 0.4149293300786527, disc_loss = 0.1629955860999436
Trained batch 441 in epoch 0, gen_loss = 0.41493727192619806, disc_loss = 0.1628696543261476
Trained batch 442 in epoch 0, gen_loss = 0.4149310222866842, disc_loss = 0.16278182546992873
Trained batch 443 in epoch 0, gen_loss = 0.41471397668660226, disc_loss = 0.16264939282995625
Trained batch 444 in epoch 0, gen_loss = 0.4146865391999148, disc_loss = 0.16255740052863454
Trained batch 445 in epoch 0, gen_loss = 0.4145031253986829, disc_loss = 0.16247876340966053
Trained batch 446 in epoch 0, gen_loss = 0.4144737359794728, disc_loss = 0.16231611716067232
Trained batch 447 in epoch 0, gen_loss = 0.41431765763887335, disc_loss = 0.16222100360651634
Trained batch 448 in epoch 0, gen_loss = 0.41445765018728636, disc_loss = 0.16212112791753294
Trained batch 449 in epoch 0, gen_loss = 0.41458695756064523, disc_loss = 0.16198429509997367
Trained batch 450 in epoch 0, gen_loss = 0.41461058968715286, disc_loss = 0.16178497368110523
Trained batch 451 in epoch 0, gen_loss = 0.4143569855827146, disc_loss = 0.1617769197750408
Trained batch 452 in epoch 0, gen_loss = 0.4144485540211069, disc_loss = 0.1618323026442896
Trained batch 453 in epoch 0, gen_loss = 0.4142878304362822, disc_loss = 0.16174835591917522
Trained batch 454 in epoch 0, gen_loss = 0.4142442627922519, disc_loss = 0.16178227907026207
Trained batch 455 in epoch 0, gen_loss = 0.414018581245552, disc_loss = 0.16179307296937495
Trained batch 456 in epoch 0, gen_loss = 0.4139866017017114, disc_loss = 0.16175589775686974
Trained batch 457 in epoch 0, gen_loss = 0.41400652778981556, disc_loss = 0.1620253502964713
Trained batch 458 in epoch 0, gen_loss = 0.41403801677533486, disc_loss = 0.16185642220485705
Trained batch 459 in epoch 0, gen_loss = 0.41401016433601795, disc_loss = 0.16186217746656875
Trained batch 460 in epoch 0, gen_loss = 0.41424582197195536, disc_loss = 0.16178880457376452
Testing Epoch 0
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-08-30 00:19:00,515
------------------------------------------------------------
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.4129718840122223, disc_loss = 0.23409855365753174
Trained batch 1 in epoch 1, gen_loss = 0.3984649032354355, disc_loss = 0.21763728559017181
Trained batch 2 in epoch 1, gen_loss = 0.41414811213811237, disc_loss = 0.21834408740202585
Trained batch 3 in epoch 1, gen_loss = 0.4059540778398514, disc_loss = 0.17983721941709518
Trained batch 4 in epoch 1, gen_loss = 0.39899617433547974, disc_loss = 0.17351812720298768
Trained batch 5 in epoch 1, gen_loss = 0.3840855459372203, disc_loss = 0.17092364033063254
Trained batch 6 in epoch 1, gen_loss = 0.383822568825313, disc_loss = 0.1571147676025118
Trained batch 7 in epoch 1, gen_loss = 0.3792707547545433, disc_loss = 0.15260216873139143
Trained batch 8 in epoch 1, gen_loss = 0.389981081088384, disc_loss = 0.14020287576648924
Trained batch 9 in epoch 1, gen_loss = 0.38857986629009245, disc_loss = 0.15146665498614312
Trained batch 10 in epoch 1, gen_loss = 0.39414970441298053, disc_loss = 0.16510115631602026
Trained batch 11 in epoch 1, gen_loss = 0.392535001039505, disc_loss = 0.1626143225779136
Trained batch 12 in epoch 1, gen_loss = 0.3896996814471025, disc_loss = 0.15574258852463502
Trained batch 13 in epoch 1, gen_loss = 0.39573061891964506, disc_loss = 0.1497575795011861
Trained batch 14 in epoch 1, gen_loss = 0.39229296843210854, disc_loss = 0.1472280169526736
Trained batch 15 in epoch 1, gen_loss = 0.39844133146107197, disc_loss = 0.14275966817513108
Trained batch 16 in epoch 1, gen_loss = 0.39751361047520356, disc_loss = 0.14032276588327744
Trained batch 17 in epoch 1, gen_loss = 0.39819331136014724, disc_loss = 0.13931777700781822
Trained batch 18 in epoch 1, gen_loss = 0.398228468079316, disc_loss = 0.14311153049531736
Trained batch 19 in epoch 1, gen_loss = 0.40281623750925066, disc_loss = 0.13922305069863797
Trained batch 20 in epoch 1, gen_loss = 0.4016012904189882, disc_loss = 0.1356670767778442
Trained batch 21 in epoch 1, gen_loss = 0.39712260934439575, disc_loss = 0.1344281607730822
Trained batch 22 in epoch 1, gen_loss = 0.39482771961585333, disc_loss = 0.13185766566058862
Trained batch 23 in epoch 1, gen_loss = 0.3979336606959502, disc_loss = 0.1429899021362265
Trained batch 24 in epoch 1, gen_loss = 0.3936802411079407, disc_loss = 0.14410062104463578
Trained batch 25 in epoch 1, gen_loss = 0.39388143099271333, disc_loss = 0.14314457057760313
Trained batch 26 in epoch 1, gen_loss = 0.39564254879951477, disc_loss = 0.1429373155589457
Trained batch 27 in epoch 1, gen_loss = 0.39430318985666546, disc_loss = 0.1446511114814452
Trained batch 28 in epoch 1, gen_loss = 0.39370080931433316, disc_loss = 0.14562527552760882
Trained batch 29 in epoch 1, gen_loss = 0.39202920893828075, disc_loss = 0.14886677041649818
Trained batch 30 in epoch 1, gen_loss = 0.3923303427234773, disc_loss = 0.14978808044425904
Trained batch 31 in epoch 1, gen_loss = 0.3919650539755821, disc_loss = 0.14666011952795088
Trained batch 32 in epoch 1, gen_loss = 0.39046914740042254, disc_loss = 0.14757479162830295
Trained batch 33 in epoch 1, gen_loss = 0.3904302391935797, disc_loss = 0.147228415178902
Trained batch 34 in epoch 1, gen_loss = 0.39213207023484364, disc_loss = 0.14383713219846997
Trained batch 35 in epoch 1, gen_loss = 0.39097948951853645, disc_loss = 0.14713172490398088
Trained batch 36 in epoch 1, gen_loss = 0.3912289690327, disc_loss = 0.14729242469813372
Trained batch 37 in epoch 1, gen_loss = 0.39370055261411163, disc_loss = 0.14491080835853754
Trained batch 38 in epoch 1, gen_loss = 0.39310404123404086, disc_loss = 0.14696511807732093
Trained batch 39 in epoch 1, gen_loss = 0.39435375556349755, disc_loss = 0.1478698211722076
Trained batch 40 in epoch 1, gen_loss = 0.3966999112105951, disc_loss = 0.14782038467322908
Trained batch 41 in epoch 1, gen_loss = 0.39606507264432456, disc_loss = 0.14778646640479565
Trained batch 42 in epoch 1, gen_loss = 0.3957492016082586, disc_loss = 0.14833233548804772
Trained batch 43 in epoch 1, gen_loss = 0.39588282054120844, disc_loss = 0.14772739676250654
Trained batch 44 in epoch 1, gen_loss = 0.394529398282369, disc_loss = 0.1474372573196888
Trained batch 45 in epoch 1, gen_loss = 0.3910589548556701, disc_loss = 0.1494038967496675
Trained batch 46 in epoch 1, gen_loss = 0.3920889141711783, disc_loss = 0.1508298415611399
Trained batch 47 in epoch 1, gen_loss = 0.39186942763626575, disc_loss = 0.15083515093040964
Trained batch 48 in epoch 1, gen_loss = 0.39128479908923713, disc_loss = 0.15038468650713258
Trained batch 49 in epoch 1, gen_loss = 0.39037705421447755, disc_loss = 0.14889638654887677
Trained batch 50 in epoch 1, gen_loss = 0.3886979946903154, disc_loss = 0.15108095832607327
Trained batch 51 in epoch 1, gen_loss = 0.3886920093343808, disc_loss = 0.15630834485189274
Trained batch 52 in epoch 1, gen_loss = 0.38928459893982365, disc_loss = 0.1568582793873436
Trained batch 53 in epoch 1, gen_loss = 0.3877213404134468, disc_loss = 0.158531470362235
Trained batch 54 in epoch 1, gen_loss = 0.3861549220301888, disc_loss = 0.16035960147326642
Trained batch 55 in epoch 1, gen_loss = 0.38522642318691525, disc_loss = 0.16099787310564093
Trained batch 56 in epoch 1, gen_loss = 0.3850703699546948, disc_loss = 0.16092713824228236
Trained batch 57 in epoch 1, gen_loss = 0.3850461470669714, disc_loss = 0.16093551335406714
Trained batch 58 in epoch 1, gen_loss = 0.3835778882948019, disc_loss = 0.16030124101345822
Trained batch 59 in epoch 1, gen_loss = 0.3831244026621183, disc_loss = 0.15917482593407234
Trained batch 60 in epoch 1, gen_loss = 0.3827550425881245, disc_loss = 0.1579195188327891
Trained batch 61 in epoch 1, gen_loss = 0.38241551912599997, disc_loss = 0.1563952354293677
Trained batch 62 in epoch 1, gen_loss = 0.3820262939210922, disc_loss = 0.15466673494804473
Trained batch 63 in epoch 1, gen_loss = 0.3827723818831146, disc_loss = 0.15331613866146654
Trained batch 64 in epoch 1, gen_loss = 0.3847014129161835, disc_loss = 0.1528467241388101
Trained batch 65 in epoch 1, gen_loss = 0.3850239456603021, disc_loss = 0.15289146464430925
Trained batch 66 in epoch 1, gen_loss = 0.3851654587396935, disc_loss = 0.1546893527925904
Trained batch 67 in epoch 1, gen_loss = 0.38574084902510924, disc_loss = 0.15652185711352265
Trained batch 68 in epoch 1, gen_loss = 0.38618404968925146, disc_loss = 0.15632044955872107
Trained batch 69 in epoch 1, gen_loss = 0.386405286192894, disc_loss = 0.15523664259484837
Trained batch 70 in epoch 1, gen_loss = 0.38635352002063267, disc_loss = 0.15510779021071716
Trained batch 71 in epoch 1, gen_loss = 0.3853999947508176, disc_loss = 0.15556106788830626
Trained batch 72 in epoch 1, gen_loss = 0.3863054579251433, disc_loss = 0.15617105130055178
Trained batch 73 in epoch 1, gen_loss = 0.3862889433229292, disc_loss = 0.15637786857582428
Trained batch 74 in epoch 1, gen_loss = 0.3858876919746399, disc_loss = 0.1556330739458402
Trained batch 75 in epoch 1, gen_loss = 0.3857826021941085, disc_loss = 0.1554211479072508
Trained batch 76 in epoch 1, gen_loss = 0.3856838434547573, disc_loss = 0.15642518879144224
Trained batch 77 in epoch 1, gen_loss = 0.3847230179951741, disc_loss = 0.15608038208805597
Trained batch 78 in epoch 1, gen_loss = 0.384312707412092, disc_loss = 0.15628549296267424
Trained batch 79 in epoch 1, gen_loss = 0.38508056849241257, disc_loss = 0.15814443295821548
Trained batch 80 in epoch 1, gen_loss = 0.385761245901202, disc_loss = 0.1583515892242208
Trained batch 81 in epoch 1, gen_loss = 0.38470011477063343, disc_loss = 0.15940761793313957
Trained batch 82 in epoch 1, gen_loss = 0.3856289810444935, disc_loss = 0.1588585634368012
Trained batch 83 in epoch 1, gen_loss = 0.385661376728898, disc_loss = 0.15881314172986008
Trained batch 84 in epoch 1, gen_loss = 0.3860405676505145, disc_loss = 0.1575319095131229
Trained batch 85 in epoch 1, gen_loss = 0.38501153990279796, disc_loss = 0.1566422174056602
Trained batch 86 in epoch 1, gen_loss = 0.3840519056237977, disc_loss = 0.15672504914731816
Trained batch 87 in epoch 1, gen_loss = 0.3840008100325411, disc_loss = 0.1560064020397311
Trained batch 88 in epoch 1, gen_loss = 0.3847983569911357, disc_loss = 0.15572488487938815
Trained batch 89 in epoch 1, gen_loss = 0.3849964357084698, disc_loss = 0.1553204805900653
Trained batch 90 in epoch 1, gen_loss = 0.38511768048936196, disc_loss = 0.15562980708021384
Trained batch 91 in epoch 1, gen_loss = 0.38459461571081827, disc_loss = 0.15640217936395304
Trained batch 92 in epoch 1, gen_loss = 0.3853389864326805, disc_loss = 0.1562043307849797
Trained batch 93 in epoch 1, gen_loss = 0.3857876484064346, disc_loss = 0.15658939752648485
Trained batch 94 in epoch 1, gen_loss = 0.3847970949976068, disc_loss = 0.15706327130135736
Trained batch 95 in epoch 1, gen_loss = 0.38492192576328915, disc_loss = 0.15749565802980214
Trained batch 96 in epoch 1, gen_loss = 0.38487339388463915, disc_loss = 0.1611416829538714
Trained batch 97 in epoch 1, gen_loss = 0.38532055184549213, disc_loss = 0.16055608628203674
Trained batch 98 in epoch 1, gen_loss = 0.38444997596018243, disc_loss = 0.16036496902204522
Trained batch 99 in epoch 1, gen_loss = 0.3843695566058159, disc_loss = 0.16000272493809461
Trained batch 100 in epoch 1, gen_loss = 0.38451156639816736, disc_loss = 0.1598344629280048
Trained batch 101 in epoch 1, gen_loss = 0.38423843944773955, disc_loss = 0.15932084083118858
Trained batch 102 in epoch 1, gen_loss = 0.3836967768599686, disc_loss = 0.15937582341936027
Trained batch 103 in epoch 1, gen_loss = 0.3827754926796143, disc_loss = 0.15892186341807246
Trained batch 104 in epoch 1, gen_loss = 0.382398396730423, disc_loss = 0.15883144406335695
Trained batch 105 in epoch 1, gen_loss = 0.3819722645687607, disc_loss = 0.15918212717855876
Trained batch 106 in epoch 1, gen_loss = 0.3820179369405051, disc_loss = 0.15949639312435535
Trained batch 107 in epoch 1, gen_loss = 0.38248949221990725, disc_loss = 0.15864373884957145
Trained batch 108 in epoch 1, gen_loss = 0.3827804266859632, disc_loss = 0.15825758734290754
Trained batch 109 in epoch 1, gen_loss = 0.38340502029115503, disc_loss = 0.15706632015379993
Trained batch 110 in epoch 1, gen_loss = 0.38326179766440177, disc_loss = 0.1572734258464865
Trained batch 111 in epoch 1, gen_loss = 0.38368044873433454, disc_loss = 0.15810322375702007
Trained batch 112 in epoch 1, gen_loss = 0.3847610541677053, disc_loss = 0.15790297381118334
Trained batch 113 in epoch 1, gen_loss = 0.38535094731732417, disc_loss = 0.15747306299837013
Trained batch 114 in epoch 1, gen_loss = 0.38464609825092816, disc_loss = 0.15744198534799658
Trained batch 115 in epoch 1, gen_loss = 0.3852879279132547, disc_loss = 0.15792933825788827
Trained batch 116 in epoch 1, gen_loss = 0.3858990518965273, disc_loss = 0.1571130442441019
Trained batch 117 in epoch 1, gen_loss = 0.3854695485304978, disc_loss = 0.1568687197641801
Trained batch 118 in epoch 1, gen_loss = 0.3860333992653534, disc_loss = 0.15609820362399607
Trained batch 119 in epoch 1, gen_loss = 0.3858999840915203, disc_loss = 0.15601223893463612
Trained batch 120 in epoch 1, gen_loss = 0.3859055229454986, disc_loss = 0.1550772682694364
Trained batch 121 in epoch 1, gen_loss = 0.3861066816283054, disc_loss = 0.15415157145652614
Trained batch 122 in epoch 1, gen_loss = 0.3861252713978775, disc_loss = 0.15394775981340952
Trained batch 123 in epoch 1, gen_loss = 0.3869129294349301, disc_loss = 0.15531945817412868
Trained batch 124 in epoch 1, gen_loss = 0.3872609703540802, disc_loss = 0.1564894427061081
Trained batch 125 in epoch 1, gen_loss = 0.3882855070488794, disc_loss = 0.15567305009989513
Trained batch 126 in epoch 1, gen_loss = 0.38879304115227825, disc_loss = 0.15471834352049302
Trained batch 127 in epoch 1, gen_loss = 0.38899928121827543, disc_loss = 0.15412513024057262
Trained batch 128 in epoch 1, gen_loss = 0.38964289958162823, disc_loss = 0.153408333254877
Trained batch 129 in epoch 1, gen_loss = 0.3899891167879105, disc_loss = 0.15252237577851002
Trained batch 130 in epoch 1, gen_loss = 0.3910377956073703, disc_loss = 0.15181570568385014
Trained batch 131 in epoch 1, gen_loss = 0.391409717725985, disc_loss = 0.15101030683427147
Trained batch 132 in epoch 1, gen_loss = 0.3917213015090254, disc_loss = 0.1500490746439848
Trained batch 133 in epoch 1, gen_loss = 0.3916309340231454, disc_loss = 0.14945177144523877
Trained batch 134 in epoch 1, gen_loss = 0.3922177762896926, disc_loss = 0.14863667808197162
Trained batch 135 in epoch 1, gen_loss = 0.39189088914324255, disc_loss = 0.14790160844431205
Trained batch 136 in epoch 1, gen_loss = 0.3909999610733812, disc_loss = 0.1475542343228403
Trained batch 137 in epoch 1, gen_loss = 0.39071388369885046, disc_loss = 0.14892043724008228
Trained batch 138 in epoch 1, gen_loss = 0.3916759651770695, disc_loss = 0.15160652341173708
Trained batch 139 in epoch 1, gen_loss = 0.3914266526699066, disc_loss = 0.15216696720038142
Trained batch 140 in epoch 1, gen_loss = 0.39196760413494514, disc_loss = 0.15329159479191962
Trained batch 141 in epoch 1, gen_loss = 0.39247418793154437, disc_loss = 0.15338226638629404
Trained batch 142 in epoch 1, gen_loss = 0.3924136693244214, disc_loss = 0.15360954143367447
Trained batch 143 in epoch 1, gen_loss = 0.39206489692959523, disc_loss = 0.1539367042067978
Trained batch 144 in epoch 1, gen_loss = 0.3921786509711167, disc_loss = 0.1538643216264659
Trained batch 145 in epoch 1, gen_loss = 0.39206417047814146, disc_loss = 0.15430753341276351
Trained batch 146 in epoch 1, gen_loss = 0.39205003190202775, disc_loss = 0.15476675848571622
Trained batch 147 in epoch 1, gen_loss = 0.3921950419206877, disc_loss = 0.15436620164561915
Trained batch 148 in epoch 1, gen_loss = 0.3925587844928639, disc_loss = 0.15391529896515327
Trained batch 149 in epoch 1, gen_loss = 0.3925075165430705, disc_loss = 0.1537784610191981
Trained batch 150 in epoch 1, gen_loss = 0.392174646159671, disc_loss = 0.1537830429953455
Trained batch 151 in epoch 1, gen_loss = 0.3921812102198601, disc_loss = 0.1539371021484074
Trained batch 152 in epoch 1, gen_loss = 0.39232529748499007, disc_loss = 0.15380541464082556
Trained batch 153 in epoch 1, gen_loss = 0.3928251688356523, disc_loss = 0.1540678059319397
Trained batch 154 in epoch 1, gen_loss = 0.39293563673573156, disc_loss = 0.15399655411320348
Trained batch 155 in epoch 1, gen_loss = 0.3926256811007475, disc_loss = 0.1541593726246785
Trained batch 156 in epoch 1, gen_loss = 0.39278467198845685, disc_loss = 0.15406251437724774
Trained batch 157 in epoch 1, gen_loss = 0.3924202090954479, disc_loss = 0.15394440114120894
Trained batch 158 in epoch 1, gen_loss = 0.39248186012483993, disc_loss = 0.15325310458458444
Trained batch 159 in epoch 1, gen_loss = 0.3925737200304866, disc_loss = 0.15340104706119745
Trained batch 160 in epoch 1, gen_loss = 0.3932782224616649, disc_loss = 0.15445102841494987
Trained batch 161 in epoch 1, gen_loss = 0.39345303343402016, disc_loss = 0.15449279627222337
Trained batch 162 in epoch 1, gen_loss = 0.39280453836259666, disc_loss = 0.1545038173672246
Trained batch 163 in epoch 1, gen_loss = 0.3924847528701875, disc_loss = 0.15456694489481246
Trained batch 164 in epoch 1, gen_loss = 0.39239409114375257, disc_loss = 0.1541804694542379
Trained batch 165 in epoch 1, gen_loss = 0.3919637915958841, disc_loss = 0.1548391273357423
Trained batch 166 in epoch 1, gen_loss = 0.39230548942874294, disc_loss = 0.15600839950991963
Trained batch 167 in epoch 1, gen_loss = 0.3919922991522721, disc_loss = 0.15633299669605635
Trained batch 168 in epoch 1, gen_loss = 0.3912959747765897, disc_loss = 0.1572713111940573
Trained batch 169 in epoch 1, gen_loss = 0.3910965305917403, disc_loss = 0.15731951732407598
Trained batch 170 in epoch 1, gen_loss = 0.39064064325644954, disc_loss = 0.15714964425267533
Trained batch 171 in epoch 1, gen_loss = 0.390316704677981, disc_loss = 0.15731787592779065
Trained batch 172 in epoch 1, gen_loss = 0.3900434174978664, disc_loss = 0.1578100825622247
Trained batch 173 in epoch 1, gen_loss = 0.38970733151353637, disc_loss = 0.15776271199614839
Trained batch 174 in epoch 1, gen_loss = 0.38937339987073627, disc_loss = 0.15779864428298815
Trained batch 175 in epoch 1, gen_loss = 0.38924996266988193, disc_loss = 0.15827188655649396
Trained batch 176 in epoch 1, gen_loss = 0.3895672901538806, disc_loss = 0.1583751187275695
Trained batch 177 in epoch 1, gen_loss = 0.38942399905638747, disc_loss = 0.15879452728739615
Trained batch 178 in epoch 1, gen_loss = 0.3897582833660381, disc_loss = 0.15866148369855054
Trained batch 179 in epoch 1, gen_loss = 0.3897597112589412, disc_loss = 0.15806235834542248
Trained batch 180 in epoch 1, gen_loss = 0.38957384146379503, disc_loss = 0.15756400903038556
Trained batch 181 in epoch 1, gen_loss = 0.3896415623334738, disc_loss = 0.1572448823519133
Trained batch 182 in epoch 1, gen_loss = 0.39020941557128574, disc_loss = 0.15700200014834195
Trained batch 183 in epoch 1, gen_loss = 0.3901018257374349, disc_loss = 0.15664031261416234
Trained batch 184 in epoch 1, gen_loss = 0.39047568537093497, disc_loss = 0.1578837891084117
Trained batch 185 in epoch 1, gen_loss = 0.39031960006042193, disc_loss = 0.15729944598210113
Trained batch 186 in epoch 1, gen_loss = 0.3901901415643845, disc_loss = 0.1569178885914744
Trained batch 187 in epoch 1, gen_loss = 0.38999329047634246, disc_loss = 0.15655283223679092
Trained batch 188 in epoch 1, gen_loss = 0.3899265357426235, disc_loss = 0.15602110848619194
Trained batch 189 in epoch 1, gen_loss = 0.39096298155031706, disc_loss = 0.15568407721033223
Trained batch 190 in epoch 1, gen_loss = 0.3909820439927865, disc_loss = 0.15517830955966605
Trained batch 191 in epoch 1, gen_loss = 0.39109038934111595, disc_loss = 0.15486861782846972
Trained batch 192 in epoch 1, gen_loss = 0.3908590890582979, disc_loss = 0.15470695204144932
Trained batch 193 in epoch 1, gen_loss = 0.39085522063614164, disc_loss = 0.1542511877133367
Trained batch 194 in epoch 1, gen_loss = 0.39087545520220046, disc_loss = 0.15485893180355048
Trained batch 195 in epoch 1, gen_loss = 0.39040273473579057, disc_loss = 0.1556245695077339
Trained batch 196 in epoch 1, gen_loss = 0.39080884054227527, disc_loss = 0.15542210496697328
Trained batch 197 in epoch 1, gen_loss = 0.39118253040795375, disc_loss = 0.15612936443225903
Trained batch 198 in epoch 1, gen_loss = 0.3913044487711173, disc_loss = 0.1563955806944538
Trained batch 199 in epoch 1, gen_loss = 0.3911454676091671, disc_loss = 0.1568139115907252
Trained batch 200 in epoch 1, gen_loss = 0.39143135046484456, disc_loss = 0.15671070930154168
Trained batch 201 in epoch 1, gen_loss = 0.39145148685663056, disc_loss = 0.1573838697248461
Trained batch 202 in epoch 1, gen_loss = 0.39133651635329714, disc_loss = 0.1579644434300843
Trained batch 203 in epoch 1, gen_loss = 0.39150360694118574, disc_loss = 0.15807231159552054
Trained batch 204 in epoch 1, gen_loss = 0.39140953174451504, disc_loss = 0.15847358414676133
Trained batch 205 in epoch 1, gen_loss = 0.3917899421117838, disc_loss = 0.1581441830047994
Trained batch 206 in epoch 1, gen_loss = 0.3919205271103532, disc_loss = 0.15831461323848092
Trained batch 207 in epoch 1, gen_loss = 0.3917780567247134, disc_loss = 0.15810962753871885
Trained batch 208 in epoch 1, gen_loss = 0.39173093395370046, disc_loss = 0.15795781147893537
Trained batch 209 in epoch 1, gen_loss = 0.3914481411377589, disc_loss = 0.15773396554092567
Trained batch 210 in epoch 1, gen_loss = 0.39133590163212817, disc_loss = 0.1579467901227316
Trained batch 211 in epoch 1, gen_loss = 0.3913018730170322, disc_loss = 0.15864797244024165
Trained batch 212 in epoch 1, gen_loss = 0.3914160987301052, disc_loss = 0.1584289493520215
Trained batch 213 in epoch 1, gen_loss = 0.3912363472942994, disc_loss = 0.158132605446137
Trained batch 214 in epoch 1, gen_loss = 0.39077121449071306, disc_loss = 0.15796859082440998
Trained batch 215 in epoch 1, gen_loss = 0.39114662287411867, disc_loss = 0.1577333576666812
Trained batch 216 in epoch 1, gen_loss = 0.39122467532685273, disc_loss = 0.1574515221202703
Trained batch 217 in epoch 1, gen_loss = 0.39128775880971084, disc_loss = 0.15728295681605098
Trained batch 218 in epoch 1, gen_loss = 0.3910332885507035, disc_loss = 0.15689323776184697
Trained batch 219 in epoch 1, gen_loss = 0.39115261733531953, disc_loss = 0.15778401434760203
Trained batch 220 in epoch 1, gen_loss = 0.39117466000949636, disc_loss = 0.15787184644675903
Trained batch 221 in epoch 1, gen_loss = 0.39111409611530135, disc_loss = 0.15858983028646526
Trained batch 222 in epoch 1, gen_loss = 0.3910779041559707, disc_loss = 0.15939949581508145
Trained batch 223 in epoch 1, gen_loss = 0.3908954719081521, disc_loss = 0.15954890010678874
Trained batch 224 in epoch 1, gen_loss = 0.3907936888270908, disc_loss = 0.15947564808858766
Trained batch 225 in epoch 1, gen_loss = 0.3907674001117723, disc_loss = 0.15959663341332853
Trained batch 226 in epoch 1, gen_loss = 0.3904456410901662, disc_loss = 0.15957351306264622
Trained batch 227 in epoch 1, gen_loss = 0.39051424437447596, disc_loss = 0.15934949699919998
Trained batch 228 in epoch 1, gen_loss = 0.3901380003800038, disc_loss = 0.1593456319553623
Trained batch 229 in epoch 1, gen_loss = 0.39005002962506335, disc_loss = 0.15907024214773074
Trained batch 230 in epoch 1, gen_loss = 0.3898877967229653, disc_loss = 0.15869285829074972
Trained batch 231 in epoch 1, gen_loss = 0.38996008950574645, disc_loss = 0.1582257802244918
Trained batch 232 in epoch 1, gen_loss = 0.39042309067279996, disc_loss = 0.15762772956311447
Trained batch 233 in epoch 1, gen_loss = 0.3906286901388413, disc_loss = 0.157271677437119
Trained batch 234 in epoch 1, gen_loss = 0.3905098190967073, disc_loss = 0.1570079526210085
Trained batch 235 in epoch 1, gen_loss = 0.3904144918009386, disc_loss = 0.1583765192525619
Trained batch 236 in epoch 1, gen_loss = 0.390059656734708, disc_loss = 0.15798473353438738
Trained batch 237 in epoch 1, gen_loss = 0.39004404266842274, disc_loss = 0.1578371459852998
Trained batch 238 in epoch 1, gen_loss = 0.3897085834497188, disc_loss = 0.15784435674049366
Trained batch 239 in epoch 1, gen_loss = 0.3898252376665672, disc_loss = 0.15733550887865325
Trained batch 240 in epoch 1, gen_loss = 0.3903598912771312, disc_loss = 0.15681651245447115
Trained batch 241 in epoch 1, gen_loss = 0.39024720457959766, disc_loss = 0.15738979423772698
Trained batch 242 in epoch 1, gen_loss = 0.3905610914338273, disc_loss = 0.15725693926828388
Trained batch 243 in epoch 1, gen_loss = 0.3904100484291061, disc_loss = 0.15739972948966946
Trained batch 244 in epoch 1, gen_loss = 0.3901280354480354, disc_loss = 0.15750110123534591
Trained batch 245 in epoch 1, gen_loss = 0.3905493835123574, disc_loss = 0.15706776485331658
Trained batch 246 in epoch 1, gen_loss = 0.39111150203928774, disc_loss = 0.15669986328132723
Trained batch 247 in epoch 1, gen_loss = 0.39111516216108877, disc_loss = 0.15639987783206086
Trained batch 248 in epoch 1, gen_loss = 0.39120339964288303, disc_loss = 0.15656752061532683
Trained batch 249 in epoch 1, gen_loss = 0.3908890460729599, disc_loss = 0.15701645228266717
Trained batch 250 in epoch 1, gen_loss = 0.39075303042077447, disc_loss = 0.15807826226332272
Trained batch 251 in epoch 1, gen_loss = 0.39081272530177286, disc_loss = 0.15843104591800106
Trained batch 252 in epoch 1, gen_loss = 0.3905959955081638, disc_loss = 0.15852289293476715
Trained batch 253 in epoch 1, gen_loss = 0.3904790669444978, disc_loss = 0.15870674391548464
Trained batch 254 in epoch 1, gen_loss = 0.39068285145011605, disc_loss = 0.1588785483848815
Trained batch 255 in epoch 1, gen_loss = 0.39065186539664865, disc_loss = 0.15904340022825636
Trained batch 256 in epoch 1, gen_loss = 0.3902394741425718, disc_loss = 0.1594046153968874
Trained batch 257 in epoch 1, gen_loss = 0.3900784500116526, disc_loss = 0.15979446150189222
Trained batch 258 in epoch 1, gen_loss = 0.3899963292145821, disc_loss = 0.1600866612607908
Trained batch 259 in epoch 1, gen_loss = 0.3900739942605679, disc_loss = 0.1602514203064717
Trained batch 260 in epoch 1, gen_loss = 0.3899616201718648, disc_loss = 0.16047184292041478
Trained batch 261 in epoch 1, gen_loss = 0.38968398985061936, disc_loss = 0.16083196286140508
Trained batch 262 in epoch 1, gen_loss = 0.38978971829885767, disc_loss = 0.16086316485482025
Trained batch 263 in epoch 1, gen_loss = 0.3897099256741278, disc_loss = 0.16076720407176198
Trained batch 264 in epoch 1, gen_loss = 0.38960086871992866, disc_loss = 0.16059627594812861
Trained batch 265 in epoch 1, gen_loss = 0.38986220462877946, disc_loss = 0.16024106729747659
Trained batch 266 in epoch 1, gen_loss = 0.3897472343194797, disc_loss = 0.16023064887479002
Trained batch 267 in epoch 1, gen_loss = 0.38959215025403604, disc_loss = 0.16028392392752774
Trained batch 268 in epoch 1, gen_loss = 0.38981722212192293, disc_loss = 0.16008057924451438
Trained batch 269 in epoch 1, gen_loss = 0.3898399456783577, disc_loss = 0.15998285092689374
Trained batch 270 in epoch 1, gen_loss = 0.38962891554920437, disc_loss = 0.16044701674327638
Trained batch 271 in epoch 1, gen_loss = 0.3892389102017178, disc_loss = 0.16116451767875867
Trained batch 272 in epoch 1, gen_loss = 0.3892572065849444, disc_loss = 0.16099461367278745
Trained batch 273 in epoch 1, gen_loss = 0.3890753695129478, disc_loss = 0.16107763475092657
Trained batch 274 in epoch 1, gen_loss = 0.38912789756601507, disc_loss = 0.1610232488675551
Trained batch 275 in epoch 1, gen_loss = 0.38926762158887973, disc_loss = 0.16083350631853807
Trained batch 276 in epoch 1, gen_loss = 0.38930656569959454, disc_loss = 0.16094900032888682
Trained batch 277 in epoch 1, gen_loss = 0.38899531531676973, disc_loss = 0.16149235366702938
Trained batch 278 in epoch 1, gen_loss = 0.3888072685528827, disc_loss = 0.16117941208958197
Trained batch 279 in epoch 1, gen_loss = 0.3886513697249549, disc_loss = 0.16127619996134723
Trained batch 280 in epoch 1, gen_loss = 0.3884475901457763, disc_loss = 0.1610977478935201
Trained batch 281 in epoch 1, gen_loss = 0.3885031041312725, disc_loss = 0.16105784169325593
Trained batch 282 in epoch 1, gen_loss = 0.38830909027648897, disc_loss = 0.16125765632403613
Trained batch 283 in epoch 1, gen_loss = 0.388364208835951, disc_loss = 0.16124718342448624
Trained batch 284 in epoch 1, gen_loss = 0.3883230353656568, disc_loss = 0.16129564548793593
Trained batch 285 in epoch 1, gen_loss = 0.388408833137759, disc_loss = 0.16107668263928873
Trained batch 286 in epoch 1, gen_loss = 0.388296564177769, disc_loss = 0.1611813109510867
Trained batch 287 in epoch 1, gen_loss = 0.38834405845652026, disc_loss = 0.16099709937245482
Trained batch 288 in epoch 1, gen_loss = 0.38826134821535396, disc_loss = 0.16093253916625747
Trained batch 289 in epoch 1, gen_loss = 0.388299743882541, disc_loss = 0.16080653821599894
Trained batch 290 in epoch 1, gen_loss = 0.3883871357260701, disc_loss = 0.160511800692868
Trained batch 291 in epoch 1, gen_loss = 0.3887106897692158, disc_loss = 0.16007534024139788
Trained batch 292 in epoch 1, gen_loss = 0.38890755715630565, disc_loss = 0.15965710172219894
Trained batch 293 in epoch 1, gen_loss = 0.3893127997919005, disc_loss = 0.15930788301336926
Trained batch 294 in epoch 1, gen_loss = 0.3893092744431253, disc_loss = 0.15891106912897804
Trained batch 295 in epoch 1, gen_loss = 0.389223962619498, disc_loss = 0.15860914525802475
Trained batch 296 in epoch 1, gen_loss = 0.3891787932376669, disc_loss = 0.15841665260669358
Trained batch 297 in epoch 1, gen_loss = 0.38933375427786937, disc_loss = 0.15833604889578068
Trained batch 298 in epoch 1, gen_loss = 0.3895393906030368, disc_loss = 0.15787759554077152
Trained batch 299 in epoch 1, gen_loss = 0.3897509584824244, disc_loss = 0.1574335361023744
Trained batch 300 in epoch 1, gen_loss = 0.38973670128572024, disc_loss = 0.15698717092705328
Trained batch 301 in epoch 1, gen_loss = 0.38991034800643165, disc_loss = 0.15654280657158387
Trained batch 302 in epoch 1, gen_loss = 0.39008214066524316, disc_loss = 0.15624158525771828
Trained batch 303 in epoch 1, gen_loss = 0.3900109489301318, disc_loss = 0.1562436023408449
Trained batch 304 in epoch 1, gen_loss = 0.3902540970044058, disc_loss = 0.1559544568789787
Trained batch 305 in epoch 1, gen_loss = 0.39038485356795244, disc_loss = 0.15550414892826595
Trained batch 306 in epoch 1, gen_loss = 0.39066360983087495, disc_loss = 0.15504313229373884
Trained batch 307 in epoch 1, gen_loss = 0.39054913799484053, disc_loss = 0.1546690449324231
Trained batch 308 in epoch 1, gen_loss = 0.3908509833913019, disc_loss = 0.15431184598326103
Trained batch 309 in epoch 1, gen_loss = 0.39084728071766517, disc_loss = 0.1541281377055472
Trained batch 310 in epoch 1, gen_loss = 0.3911771987028827, disc_loss = 0.1537029301729712
Trained batch 311 in epoch 1, gen_loss = 0.39108792424966127, disc_loss = 0.15499322702033588
Trained batch 312 in epoch 1, gen_loss = 0.3910139222114612, disc_loss = 0.15495144090832422
Trained batch 313 in epoch 1, gen_loss = 0.3911183927279369, disc_loss = 0.15555635311160307
Trained batch 314 in epoch 1, gen_loss = 0.391094623387806, disc_loss = 0.15595035882341482
Trained batch 315 in epoch 1, gen_loss = 0.39094657573518876, disc_loss = 0.1561019664712816
Trained batch 316 in epoch 1, gen_loss = 0.39073024394008266, disc_loss = 0.1563217476633163
Trained batch 317 in epoch 1, gen_loss = 0.39086431695980095, disc_loss = 0.1562671399259436
Trained batch 318 in epoch 1, gen_loss = 0.3909511767958399, disc_loss = 0.15631993384126772
Trained batch 319 in epoch 1, gen_loss = 0.39101485908031464, disc_loss = 0.1559807211451698
Trained batch 320 in epoch 1, gen_loss = 0.39133258326402703, disc_loss = 0.1555721086284546
Trained batch 321 in epoch 1, gen_loss = 0.391177304690669, disc_loss = 0.1552971241972554
Trained batch 322 in epoch 1, gen_loss = 0.391379365057399, disc_loss = 0.15495864814579857
Trained batch 323 in epoch 1, gen_loss = 0.3914955951917319, disc_loss = 0.15479017829200553
Trained batch 324 in epoch 1, gen_loss = 0.391630135682913, disc_loss = 0.1544059788607634
Trained batch 325 in epoch 1, gen_loss = 0.39150639472563575, disc_loss = 0.15445686185423949
Trained batch 326 in epoch 1, gen_loss = 0.3914838106989496, disc_loss = 0.15449978095630257
Trained batch 327 in epoch 1, gen_loss = 0.3918671328120115, disc_loss = 0.1556594023685448
Trained batch 328 in epoch 1, gen_loss = 0.39201354862708815, disc_loss = 0.1553417855483058
Trained batch 329 in epoch 1, gen_loss = 0.39185486751975435, disc_loss = 0.15609505772590637
Trained batch 330 in epoch 1, gen_loss = 0.39181550094728385, disc_loss = 0.15624660442602958
Trained batch 331 in epoch 1, gen_loss = 0.39188532674887094, disc_loss = 0.15643857334213085
Trained batch 332 in epoch 1, gen_loss = 0.3921012315485213, disc_loss = 0.1563260264180086
Trained batch 333 in epoch 1, gen_loss = 0.39182476030138436, disc_loss = 0.15671458275999853
Trained batch 334 in epoch 1, gen_loss = 0.39153414235186224, disc_loss = 0.15714992220277216
Trained batch 335 in epoch 1, gen_loss = 0.3911237871895234, disc_loss = 0.15734481720608615
Trained batch 336 in epoch 1, gen_loss = 0.3911172160408971, disc_loss = 0.1574599435359505
Trained batch 337 in epoch 1, gen_loss = 0.39088314560038095, disc_loss = 0.1577504334761899
Trained batch 338 in epoch 1, gen_loss = 0.39069310525173984, disc_loss = 0.1579942623466517
Trained batch 339 in epoch 1, gen_loss = 0.3905135493068134, disc_loss = 0.1581577608909677
Trained batch 340 in epoch 1, gen_loss = 0.3902169554289485, disc_loss = 0.15828854136190806
Trained batch 341 in epoch 1, gen_loss = 0.3905444783948318, disc_loss = 0.15816257251372115
Trained batch 342 in epoch 1, gen_loss = 0.3903359418012658, disc_loss = 0.1582312402111796
Trained batch 343 in epoch 1, gen_loss = 0.39016867732239324, disc_loss = 0.15841171221244474
Trained batch 344 in epoch 1, gen_loss = 0.38994528728982675, disc_loss = 0.15857748633277588
Trained batch 345 in epoch 1, gen_loss = 0.3900567158798262, disc_loss = 0.15871474428931412
Trained batch 346 in epoch 1, gen_loss = 0.39010116174516485, disc_loss = 0.1587728301240319
Trained batch 347 in epoch 1, gen_loss = 0.3898870131407661, disc_loss = 0.1588871804247985
Trained batch 348 in epoch 1, gen_loss = 0.38972079711179, disc_loss = 0.15907382527446337
Trained batch 349 in epoch 1, gen_loss = 0.3897900552409036, disc_loss = 0.1589809847516673
Trained batch 350 in epoch 1, gen_loss = 0.3898591816934765, disc_loss = 0.15910517861615558
Trained batch 351 in epoch 1, gen_loss = 0.3896325560794635, disc_loss = 0.15894216233441097
Trained batch 352 in epoch 1, gen_loss = 0.38957281161637886, disc_loss = 0.1589158652904351
Trained batch 353 in epoch 1, gen_loss = 0.38972658449310366, disc_loss = 0.1589070925815294
Trained batch 354 in epoch 1, gen_loss = 0.3897710848022515, disc_loss = 0.15857853490701865
Trained batch 355 in epoch 1, gen_loss = 0.38957736214225214, disc_loss = 0.15862840836804903
Trained batch 356 in epoch 1, gen_loss = 0.3896519348067062, disc_loss = 0.1583358339380984
Trained batch 357 in epoch 1, gen_loss = 0.3898245338454593, disc_loss = 0.15799759061975852
Trained batch 358 in epoch 1, gen_loss = 0.3898779487543451, disc_loss = 0.15774920782006882
Trained batch 359 in epoch 1, gen_loss = 0.3899978453086482, disc_loss = 0.1575610538530681
Trained batch 360 in epoch 1, gen_loss = 0.3900060048559036, disc_loss = 0.1574938184790664
Trained batch 361 in epoch 1, gen_loss = 0.38972220598663415, disc_loss = 0.1577503867035742
Trained batch 362 in epoch 1, gen_loss = 0.38977399148231695, disc_loss = 0.15749036520719528
Trained batch 363 in epoch 1, gen_loss = 0.3898291696722691, disc_loss = 0.1574704828211567
Trained batch 364 in epoch 1, gen_loss = 0.3898126745060699, disc_loss = 0.1573568435564433
Trained batch 365 in epoch 1, gen_loss = 0.3900531606107462, disc_loss = 0.15708446787680433
Trained batch 366 in epoch 1, gen_loss = 0.390166640200472, disc_loss = 0.1570013174406514
Trained batch 367 in epoch 1, gen_loss = 0.39004276822442596, disc_loss = 0.15681995864471662
Trained batch 368 in epoch 1, gen_loss = 0.39032053705153424, disc_loss = 0.15663668313404408
Trained batch 369 in epoch 1, gen_loss = 0.39009727295991536, disc_loss = 0.1568602176332796
Trained batch 370 in epoch 1, gen_loss = 0.39030357906117913, disc_loss = 0.15718222622360503
Trained batch 371 in epoch 1, gen_loss = 0.3900276225420736, disc_loss = 0.15719267667862036
Trained batch 372 in epoch 1, gen_loss = 0.38976205521869917, disc_loss = 0.1571820994124975
Trained batch 373 in epoch 1, gen_loss = 0.3897128890064311, disc_loss = 0.1575251395968511
Trained batch 374 in epoch 1, gen_loss = 0.38981327692667644, disc_loss = 0.1574166697859764
Trained batch 375 in epoch 1, gen_loss = 0.3897776226414011, disc_loss = 0.15764946080347958
Trained batch 376 in epoch 1, gen_loss = 0.38959265269082166, disc_loss = 0.15793807359921205
Trained batch 377 in epoch 1, gen_loss = 0.38938383994594455, disc_loss = 0.15799816620964852
Trained batch 378 in epoch 1, gen_loss = 0.38916605679529637, disc_loss = 0.158113477707381
Trained batch 379 in epoch 1, gen_loss = 0.38875832373374386, disc_loss = 0.15834273243028868
Trained batch 380 in epoch 1, gen_loss = 0.38872534204812187, disc_loss = 0.15822571099508465
Trained batch 381 in epoch 1, gen_loss = 0.38892505395942956, disc_loss = 0.15804128106976054
Trained batch 382 in epoch 1, gen_loss = 0.3888227416314282, disc_loss = 0.15794964352569132
Trained batch 383 in epoch 1, gen_loss = 0.3888087742573892, disc_loss = 0.15787541936151683
Trained batch 384 in epoch 1, gen_loss = 0.38879653288946525, disc_loss = 0.15772213070810615
Trained batch 385 in epoch 1, gen_loss = 0.3885295108115117, disc_loss = 0.15771212616037827
Trained batch 386 in epoch 1, gen_loss = 0.3884362203745263, disc_loss = 0.15819060238371832
Trained batch 387 in epoch 1, gen_loss = 0.3884720476248215, disc_loss = 0.15812790434154653
Trained batch 388 in epoch 1, gen_loss = 0.38834708036524473, disc_loss = 0.15851447409483338
Trained batch 389 in epoch 1, gen_loss = 0.38859525823440305, disc_loss = 0.1586024383130746
Trained batch 390 in epoch 1, gen_loss = 0.38849277794361115, disc_loss = 0.15860891374556915
Trained batch 391 in epoch 1, gen_loss = 0.38838458361522277, disc_loss = 0.1585897269031527
Trained batch 392 in epoch 1, gen_loss = 0.3883624546627962, disc_loss = 0.15837399858706477
Trained batch 393 in epoch 1, gen_loss = 0.38822518754277735, disc_loss = 0.15803068098115738
Trained batch 394 in epoch 1, gen_loss = 0.3880832066641578, disc_loss = 0.15771644838814494
Trained batch 395 in epoch 1, gen_loss = 0.38796890079222546, disc_loss = 0.15736171666702087
Trained batch 396 in epoch 1, gen_loss = 0.38797697571272816, disc_loss = 0.15704756455791538
Trained batch 397 in epoch 1, gen_loss = 0.38810708014360024, disc_loss = 0.15672912542244896
Trained batch 398 in epoch 1, gen_loss = 0.3882222494161816, disc_loss = 0.15636178810513557
Trained batch 399 in epoch 1, gen_loss = 0.38829099711030723, disc_loss = 0.15600843222578986
Trained batch 400 in epoch 1, gen_loss = 0.3883280586497742, disc_loss = 0.15567573118824837
Trained batch 401 in epoch 1, gen_loss = 0.38825874619964346, disc_loss = 0.1553924956720378
Trained batch 402 in epoch 1, gen_loss = 0.38832507532080707, disc_loss = 0.15520171085996531
Trained batch 403 in epoch 1, gen_loss = 0.388364965630935, disc_loss = 0.1552839785293298
Trained batch 404 in epoch 1, gen_loss = 0.38838418747907805, disc_loss = 0.1554916132448448
Trained batch 405 in epoch 1, gen_loss = 0.3882974100303767, disc_loss = 0.15537463947717706
Trained batch 406 in epoch 1, gen_loss = 0.3881591068951445, disc_loss = 0.15547876057034263
Trained batch 407 in epoch 1, gen_loss = 0.3881413514050199, disc_loss = 0.15566396188018294
Trained batch 408 in epoch 1, gen_loss = 0.3880664230777465, disc_loss = 0.1559711744334813
Trained batch 409 in epoch 1, gen_loss = 0.38811510252516446, disc_loss = 0.15597929620842746
Trained batch 410 in epoch 1, gen_loss = 0.3879760205383138, disc_loss = 0.1560094759044965
Trained batch 411 in epoch 1, gen_loss = 0.38790441373164214, disc_loss = 0.1561673642791699
Trained batch 412 in epoch 1, gen_loss = 0.38789389500750754, disc_loss = 0.15616447343908196
Trained batch 413 in epoch 1, gen_loss = 0.3875024568127549, disc_loss = 0.1564152448501096
Trained batch 414 in epoch 1, gen_loss = 0.3877143404929035, disc_loss = 0.15648666595793273
Trained batch 415 in epoch 1, gen_loss = 0.3874399153730617, disc_loss = 0.15711060027332188
Trained batch 416 in epoch 1, gen_loss = 0.38749360555796314, disc_loss = 0.1570920352879867
Trained batch 417 in epoch 1, gen_loss = 0.38732827497583827, disc_loss = 0.15709571180972115
Trained batch 418 in epoch 1, gen_loss = 0.38710019308940324, disc_loss = 0.1571731864050173
Trained batch 419 in epoch 1, gen_loss = 0.38686529323458674, disc_loss = 0.1572435758010085
Trained batch 420 in epoch 1, gen_loss = 0.38678147450903533, disc_loss = 0.1573741945754427
Trained batch 421 in epoch 1, gen_loss = 0.38683736589141365, disc_loss = 0.15740760003318083
Trained batch 422 in epoch 1, gen_loss = 0.38686301645516785, disc_loss = 0.15729915309063297
Trained batch 423 in epoch 1, gen_loss = 0.3868911682786244, disc_loss = 0.15708536869749637
Trained batch 424 in epoch 1, gen_loss = 0.38677285836023445, disc_loss = 0.1572418942236725
Trained batch 425 in epoch 1, gen_loss = 0.3867245183934068, disc_loss = 0.15725813852185863
Trained batch 426 in epoch 1, gen_loss = 0.3868261025367911, disc_loss = 0.1569978109249012
Trained batch 427 in epoch 1, gen_loss = 0.38673185456161185, disc_loss = 0.15721688275747697
Trained batch 428 in epoch 1, gen_loss = 0.38663023067659985, disc_loss = 0.15736198969541382
Trained batch 429 in epoch 1, gen_loss = 0.3867246384884036, disc_loss = 0.15765277399183358
Trained batch 430 in epoch 1, gen_loss = 0.3866155799262208, disc_loss = 0.15783854591900054
Trained batch 431 in epoch 1, gen_loss = 0.38662720068047446, disc_loss = 0.1578903945262061
Trained batch 432 in epoch 1, gen_loss = 0.3866489340678098, disc_loss = 0.1578677876402923
Trained batch 433 in epoch 1, gen_loss = 0.38643322689329973, disc_loss = 0.157760375524841
Trained batch 434 in epoch 1, gen_loss = 0.3862769147787971, disc_loss = 0.15800284079393778
Trained batch 435 in epoch 1, gen_loss = 0.38656479479112754, disc_loss = 0.15785603668463818
Trained batch 436 in epoch 1, gen_loss = 0.38678455465309136, disc_loss = 0.1576521180685209
Trained batch 437 in epoch 1, gen_loss = 0.3868689981701712, disc_loss = 0.15746550243900723
Trained batch 438 in epoch 1, gen_loss = 0.38692975400656393, disc_loss = 0.15717951321002765
Trained batch 439 in epoch 1, gen_loss = 0.3870122880082239, disc_loss = 0.15698047882072966
Trained batch 440 in epoch 1, gen_loss = 0.3868988108675496, disc_loss = 0.15728858774506788
Trained batch 441 in epoch 1, gen_loss = 0.3867868842784636, disc_loss = 0.15788725442231982
Trained batch 442 in epoch 1, gen_loss = 0.3867181124119403, disc_loss = 0.15787910579853012
Trained batch 443 in epoch 1, gen_loss = 0.3866886496879496, disc_loss = 0.1579266619000181
Trained batch 444 in epoch 1, gen_loss = 0.38642622872015064, disc_loss = 0.157989665286176
Trained batch 445 in epoch 1, gen_loss = 0.38658133814019474, disc_loss = 0.15792934104357534
Trained batch 446 in epoch 1, gen_loss = 0.38661602016130014, disc_loss = 0.15798352097663237
Trained batch 447 in epoch 1, gen_loss = 0.38656721600065275, disc_loss = 0.15791712716911985
Trained batch 448 in epoch 1, gen_loss = 0.3865903602344687, disc_loss = 0.1578388265780026
Trained batch 449 in epoch 1, gen_loss = 0.38647623635000655, disc_loss = 0.158180412242396
Trained batch 450 in epoch 1, gen_loss = 0.3864603832595364, disc_loss = 0.15810395581255401
Trained batch 451 in epoch 1, gen_loss = 0.38663220257226344, disc_loss = 0.15794709340290092
Trained batch 452 in epoch 1, gen_loss = 0.38668440315239216, disc_loss = 0.15771833129399856
Trained batch 453 in epoch 1, gen_loss = 0.38661162958927614, disc_loss = 0.15836639972895974
Trained batch 454 in epoch 1, gen_loss = 0.38665099573004375, disc_loss = 0.15839686179021886
Trained batch 455 in epoch 1, gen_loss = 0.38667230134862557, disc_loss = 0.158794570532464
Trained batch 456 in epoch 1, gen_loss = 0.3867725800046253, disc_loss = 0.1586783750683754
Trained batch 457 in epoch 1, gen_loss = 0.38657738408277126, disc_loss = 0.15875377040559743
Trained batch 458 in epoch 1, gen_loss = 0.386546517671583, disc_loss = 0.1587234358881521
Trained batch 459 in epoch 1, gen_loss = 0.38644955491890076, disc_loss = 0.15875539844248282
Trained batch 460 in epoch 1, gen_loss = 0.38632769042266424, disc_loss = 0.15877127142950342
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.42721542716026306, disc_loss = 0.10953693091869354
Trained batch 1 in epoch 2, gen_loss = 0.36512403190135956, disc_loss = 0.14749012887477875
Trained batch 2 in epoch 2, gen_loss = 0.3946906129519145, disc_loss = 0.12169434130191803
Trained batch 3 in epoch 2, gen_loss = 0.41250430792570114, disc_loss = 0.10145870596170425
Trained batch 4 in epoch 2, gen_loss = 0.4082472622394562, disc_loss = 0.10621211528778077
Trained batch 5 in epoch 2, gen_loss = 0.41004517177740735, disc_loss = 0.0982859618961811
Trained batch 6 in epoch 2, gen_loss = 0.4138058679444449, disc_loss = 0.10154961475304194
Trained batch 7 in epoch 2, gen_loss = 0.4119134470820427, disc_loss = 0.1083301343023777
Trained batch 8 in epoch 2, gen_loss = 0.4120251536369324, disc_loss = 0.10412857515944375
Trained batch 9 in epoch 2, gen_loss = 0.4175879269838333, disc_loss = 0.10714857056736946
Trained batch 10 in epoch 2, gen_loss = 0.4146489202976227, disc_loss = 0.10715191743590614
Trained batch 11 in epoch 2, gen_loss = 0.41167815029621124, disc_loss = 0.10828026942908764
Trained batch 12 in epoch 2, gen_loss = 0.41400665503281814, disc_loss = 0.10979211846223244
Trained batch 13 in epoch 2, gen_loss = 0.4086654101099287, disc_loss = 0.10589713789522648
Trained batch 14 in epoch 2, gen_loss = 0.40276040037473043, disc_loss = 0.10763162846366564
Trained batch 15 in epoch 2, gen_loss = 0.4044323395937681, disc_loss = 0.10225101630203426
Trained batch 16 in epoch 2, gen_loss = 0.40318266609135794, disc_loss = 0.10456490407095236
Trained batch 17 in epoch 2, gen_loss = 0.40865672131379444, disc_loss = 0.10738107458584839
Trained batch 18 in epoch 2, gen_loss = 0.4066719067724128, disc_loss = 0.1081731858614244
Trained batch 19 in epoch 2, gen_loss = 0.40814378410577773, disc_loss = 0.10838744398206472
Trained batch 20 in epoch 2, gen_loss = 0.40998803292001995, disc_loss = 0.11178650157082648
Trained batch 21 in epoch 2, gen_loss = 0.40580587359991943, disc_loss = 0.11813627572899515
Trained batch 22 in epoch 2, gen_loss = 0.4045333253300708, disc_loss = 0.12033402385271114
Trained batch 23 in epoch 2, gen_loss = 0.4046330451965332, disc_loss = 0.12260589857275288
Trained batch 24 in epoch 2, gen_loss = 0.400753470659256, disc_loss = 0.12593549713492394
Trained batch 25 in epoch 2, gen_loss = 0.39986176444933963, disc_loss = 0.12589614193599957
Trained batch 26 in epoch 2, gen_loss = 0.3984084990289476, disc_loss = 0.12419037396709125
Trained batch 27 in epoch 2, gen_loss = 0.3965253212622234, disc_loss = 0.12328904774039984
Trained batch 28 in epoch 2, gen_loss = 0.3928268161313287, disc_loss = 0.1228221838587317
Trained batch 29 in epoch 2, gen_loss = 0.39337835311889646, disc_loss = 0.12822987623512744
Trained batch 30 in epoch 2, gen_loss = 0.3931582329734679, disc_loss = 0.12680477877297708
Trained batch 31 in epoch 2, gen_loss = 0.3898903736844659, disc_loss = 0.13243781321216375
Trained batch 32 in epoch 2, gen_loss = 0.3898640518838709, disc_loss = 0.1357553552723292
Trained batch 33 in epoch 2, gen_loss = 0.39062628763563495, disc_loss = 0.1414585197892259
Trained batch 34 in epoch 2, gen_loss = 0.39035603744643077, disc_loss = 0.14194420629314014
Trained batch 35 in epoch 2, gen_loss = 0.38914260930485195, disc_loss = 0.14434535604798132
Trained batch 36 in epoch 2, gen_loss = 0.3885502638043584, disc_loss = 0.1432669475875996
Trained batch 37 in epoch 2, gen_loss = 0.38660993309397446, disc_loss = 0.14269985778159217
Trained batch 38 in epoch 2, gen_loss = 0.3883055861179645, disc_loss = 0.14110834485827348
Trained batch 39 in epoch 2, gen_loss = 0.3886509992182255, disc_loss = 0.14198284419253468
Trained batch 40 in epoch 2, gen_loss = 0.3875597097524783, disc_loss = 0.14457355848536257
Trained batch 41 in epoch 2, gen_loss = 0.38670011290482115, disc_loss = 0.14279590573694026
Trained batch 42 in epoch 2, gen_loss = 0.3893873587597248, disc_loss = 0.14186908122758532
Trained batch 43 in epoch 2, gen_loss = 0.38884876058860257, disc_loss = 0.1422265787524256
Trained batch 44 in epoch 2, gen_loss = 0.38686340385013157, disc_loss = 0.14414581085244815
Trained batch 45 in epoch 2, gen_loss = 0.3887022895657498, disc_loss = 0.14222254166784493
Trained batch 46 in epoch 2, gen_loss = 0.38858180350445687, disc_loss = 0.14086808058175634
Trained batch 47 in epoch 2, gen_loss = 0.3869539083292087, disc_loss = 0.1417588295104603
Trained batch 48 in epoch 2, gen_loss = 0.38786922364818804, disc_loss = 0.14298625883399224
Trained batch 49 in epoch 2, gen_loss = 0.388383691906929, disc_loss = 0.1446472568809986
Trained batch 50 in epoch 2, gen_loss = 0.3897286098377377, disc_loss = 0.14452523796581754
Trained batch 51 in epoch 2, gen_loss = 0.3902619481086731, disc_loss = 0.14325623400509357
Trained batch 52 in epoch 2, gen_loss = 0.3918950889470442, disc_loss = 0.14199982794388286
Trained batch 53 in epoch 2, gen_loss = 0.39271095008761797, disc_loss = 0.14074060486422646
Trained batch 54 in epoch 2, gen_loss = 0.39244438030503015, disc_loss = 0.1389494612812996
Trained batch 55 in epoch 2, gen_loss = 0.39314299023577143, disc_loss = 0.1400610175249832
Trained batch 56 in epoch 2, gen_loss = 0.39401158376743917, disc_loss = 0.14301048336844696
Trained batch 57 in epoch 2, gen_loss = 0.39478024686204977, disc_loss = 0.14134273485376916
Trained batch 58 in epoch 2, gen_loss = 0.3954633646092172, disc_loss = 0.1415414296216884
Trained batch 59 in epoch 2, gen_loss = 0.3948434109489123, disc_loss = 0.14133281571169695
Trained batch 60 in epoch 2, gen_loss = 0.39569321616751246, disc_loss = 0.14136107717869711
Trained batch 61 in epoch 2, gen_loss = 0.39490423183287343, disc_loss = 0.14282355757970963
Trained batch 62 in epoch 2, gen_loss = 0.39378310006762307, disc_loss = 0.14305351449856682
Trained batch 63 in epoch 2, gen_loss = 0.39146157167851925, disc_loss = 0.14401618053670973
Trained batch 64 in epoch 2, gen_loss = 0.3914806659405048, disc_loss = 0.14442450438554472
Trained batch 65 in epoch 2, gen_loss = 0.39017688550732355, disc_loss = 0.14441633980834123
Trained batch 66 in epoch 2, gen_loss = 0.39032357664250616, disc_loss = 0.14461846193715708
Trained batch 67 in epoch 2, gen_loss = 0.38963379184989366, disc_loss = 0.1445209606386283
Trained batch 68 in epoch 2, gen_loss = 0.3896247023257656, disc_loss = 0.1437361217711283
Trained batch 69 in epoch 2, gen_loss = 0.3897424348763057, disc_loss = 0.14441106798393386
Trained batch 70 in epoch 2, gen_loss = 0.3899001634456742, disc_loss = 0.1443385585722789
Trained batch 71 in epoch 2, gen_loss = 0.38907360947794384, disc_loss = 0.14490974911799034
Trained batch 72 in epoch 2, gen_loss = 0.3894121777521421, disc_loss = 0.14713946607423156
Trained batch 73 in epoch 2, gen_loss = 0.3886654538077277, disc_loss = 0.1503039156464306
Trained batch 74 in epoch 2, gen_loss = 0.38833824117978416, disc_loss = 0.15049874931573867
Trained batch 75 in epoch 2, gen_loss = 0.38837461918592453, disc_loss = 0.15209021880046317
Trained batch 76 in epoch 2, gen_loss = 0.3891616157897107, disc_loss = 0.15356836100290347
Trained batch 77 in epoch 2, gen_loss = 0.38875504793264926, disc_loss = 0.15342357535010728
Trained batch 78 in epoch 2, gen_loss = 0.3887614671942554, disc_loss = 0.15300453001562553
Trained batch 79 in epoch 2, gen_loss = 0.3882847025990486, disc_loss = 0.1531601539812982
Trained batch 80 in epoch 2, gen_loss = 0.3879001239935557, disc_loss = 0.1529848254573198
Trained batch 81 in epoch 2, gen_loss = 0.38805113260338947, disc_loss = 0.15335716697864415
Trained batch 82 in epoch 2, gen_loss = 0.38868938009422943, disc_loss = 0.1537440874310861
Trained batch 83 in epoch 2, gen_loss = 0.3883787099094618, disc_loss = 0.153036212193824
Trained batch 84 in epoch 2, gen_loss = 0.3888539668391733, disc_loss = 0.15210782885551452
Trained batch 85 in epoch 2, gen_loss = 0.38780563134093615, disc_loss = 0.1524366168088691
Trained batch 86 in epoch 2, gen_loss = 0.3874087446722491, disc_loss = 0.15198844208799558
Trained batch 87 in epoch 2, gen_loss = 0.3872189965437759, disc_loss = 0.15171469731087034
Trained batch 88 in epoch 2, gen_loss = 0.3863975556378954, disc_loss = 0.1525205234798153
Trained batch 89 in epoch 2, gen_loss = 0.386042187611262, disc_loss = 0.15272307478719288
Trained batch 90 in epoch 2, gen_loss = 0.38640363399799055, disc_loss = 0.15217865856139215
Trained batch 91 in epoch 2, gen_loss = 0.3853494139469188, disc_loss = 0.15383894838716672
Trained batch 92 in epoch 2, gen_loss = 0.38542809954253576, disc_loss = 0.1550880814752271
Trained batch 93 in epoch 2, gen_loss = 0.385495218824833, disc_loss = 0.15595722769169099
Trained batch 94 in epoch 2, gen_loss = 0.38521356237562077, disc_loss = 0.1555583125666568
Trained batch 95 in epoch 2, gen_loss = 0.38524055108428, disc_loss = 0.15474863932467997
Trained batch 96 in epoch 2, gen_loss = 0.38531003416199044, disc_loss = 0.1541489198343041
Trained batch 97 in epoch 2, gen_loss = 0.3853331524498609, disc_loss = 0.1536638593795348
Trained batch 98 in epoch 2, gen_loss = 0.3845074408584171, disc_loss = 0.1534374744603128
Trained batch 99 in epoch 2, gen_loss = 0.3841447165608406, disc_loss = 0.15274709939956665
Trained batch 100 in epoch 2, gen_loss = 0.3839400142136187, disc_loss = 0.15240707218942076
Trained batch 101 in epoch 2, gen_loss = 0.3839762500103782, disc_loss = 0.15146822533478924
Trained batch 102 in epoch 2, gen_loss = 0.38411960237234544, disc_loss = 0.15037573902931028
Trained batch 103 in epoch 2, gen_loss = 0.38424210565594524, disc_loss = 0.14958580518857792
Trained batch 104 in epoch 2, gen_loss = 0.38424016265642075, disc_loss = 0.14929122122980298
Trained batch 105 in epoch 2, gen_loss = 0.38551453571274596, disc_loss = 0.14827380853019795
Trained batch 106 in epoch 2, gen_loss = 0.3850375611648381, disc_loss = 0.14846536172466857
Trained batch 107 in epoch 2, gen_loss = 0.3856238372347973, disc_loss = 0.14973652793991346
Trained batch 108 in epoch 2, gen_loss = 0.38545086569742326, disc_loss = 0.14900960906519803
Trained batch 109 in epoch 2, gen_loss = 0.38610659539699554, disc_loss = 0.14840300465849313
Trained batch 110 in epoch 2, gen_loss = 0.38589464490478104, disc_loss = 0.14732957688403558
Trained batch 111 in epoch 2, gen_loss = 0.38699701907379286, disc_loss = 0.1468243499486042
Trained batch 112 in epoch 2, gen_loss = 0.388476467765538, disc_loss = 0.1463457901459352
Trained batch 113 in epoch 2, gen_loss = 0.38876935970364956, disc_loss = 0.1454566008362331
Trained batch 114 in epoch 2, gen_loss = 0.38930385397828143, disc_loss = 0.1450607175088447
Trained batch 115 in epoch 2, gen_loss = 0.38916072249412537, disc_loss = 0.14570565775422187
Trained batch 116 in epoch 2, gen_loss = 0.3896637872243539, disc_loss = 0.1451986736148341
Trained batch 117 in epoch 2, gen_loss = 0.38942715904470215, disc_loss = 0.14432394820249686
Trained batch 118 in epoch 2, gen_loss = 0.38996214626216086, disc_loss = 0.14322144240767015
Trained batch 119 in epoch 2, gen_loss = 0.3896956970294317, disc_loss = 0.14400454284623265
Trained batch 120 in epoch 2, gen_loss = 0.3904426097869873, disc_loss = 0.14446730797817883
Trained batch 121 in epoch 2, gen_loss = 0.38952480671835726, disc_loss = 0.14376732777254503
Trained batch 122 in epoch 2, gen_loss = 0.3886170486609141, disc_loss = 0.1444902540888728
Trained batch 123 in epoch 2, gen_loss = 0.38909792299232177, disc_loss = 0.14406350456298359
Trained batch 124 in epoch 2, gen_loss = 0.3889810767173767, disc_loss = 0.14503804549574853
Trained batch 125 in epoch 2, gen_loss = 0.3880355793332297, disc_loss = 0.14456860221449344
Trained batch 126 in epoch 2, gen_loss = 0.3871303907060248, disc_loss = 0.14448299097615902
Trained batch 127 in epoch 2, gen_loss = 0.38663638825528324, disc_loss = 0.14517331318347715
Trained batch 128 in epoch 2, gen_loss = 0.3861196983692258, disc_loss = 0.1444029932220777
Trained batch 129 in epoch 2, gen_loss = 0.3860701973621662, disc_loss = 0.1440955036534713
Trained batch 130 in epoch 2, gen_loss = 0.38633944788051927, disc_loss = 0.14542702028087076
Trained batch 131 in epoch 2, gen_loss = 0.3860441708203518, disc_loss = 0.14599691506362322
Trained batch 132 in epoch 2, gen_loss = 0.38653811117760223, disc_loss = 0.14540044431175506
Trained batch 133 in epoch 2, gen_loss = 0.386810298731078, disc_loss = 0.14508402013956612
Trained batch 134 in epoch 2, gen_loss = 0.38651107417212593, disc_loss = 0.1446967390400392
Trained batch 135 in epoch 2, gen_loss = 0.3866666412967093, disc_loss = 0.1441381419187083
Trained batch 136 in epoch 2, gen_loss = 0.3863975916900774, disc_loss = 0.1438221034668658
Trained batch 137 in epoch 2, gen_loss = 0.3861188292503357, disc_loss = 0.1442867833311143
Trained batch 138 in epoch 2, gen_loss = 0.38577467481867017, disc_loss = 0.1441660814469667
Trained batch 139 in epoch 2, gen_loss = 0.3859787949493953, disc_loss = 0.14385043648736817
Trained batch 140 in epoch 2, gen_loss = 0.3853310999718118, disc_loss = 0.14339731010139412
Trained batch 141 in epoch 2, gen_loss = 0.3857391986628653, disc_loss = 0.14277487137997655
Trained batch 142 in epoch 2, gen_loss = 0.3857461955997494, disc_loss = 0.1434907007154885
Trained batch 143 in epoch 2, gen_loss = 0.385968623475896, disc_loss = 0.14391395299591953
Trained batch 144 in epoch 2, gen_loss = 0.3863001363030795, disc_loss = 0.14306983969591816
Trained batch 145 in epoch 2, gen_loss = 0.38633303915801115, disc_loss = 0.1425549443173286
Trained batch 146 in epoch 2, gen_loss = 0.3863987545577847, disc_loss = 0.14188759314010338
Trained batch 147 in epoch 2, gen_loss = 0.3856587264988873, disc_loss = 0.14305554764546655
Trained batch 148 in epoch 2, gen_loss = 0.3861771035914453, disc_loss = 0.1435626903361322
Trained batch 149 in epoch 2, gen_loss = 0.38656534274419146, disc_loss = 0.14420674961060287
Trained batch 150 in epoch 2, gen_loss = 0.38612424064156237, disc_loss = 0.14510358821921396
Trained batch 151 in epoch 2, gen_loss = 0.3859741068200061, disc_loss = 0.14449388196838922
Trained batch 152 in epoch 2, gen_loss = 0.38611587083417603, disc_loss = 0.1440720432164038
Trained batch 153 in epoch 2, gen_loss = 0.38541378912987645, disc_loss = 0.14370780032998942
Trained batch 154 in epoch 2, gen_loss = 0.38505672024142357, disc_loss = 0.14358420017505846
Trained batch 155 in epoch 2, gen_loss = 0.3856227218340605, disc_loss = 0.14340462575021845
Trained batch 156 in epoch 2, gen_loss = 0.3857424680594426, disc_loss = 0.14311641821293694
Trained batch 157 in epoch 2, gen_loss = 0.3852460107094125, disc_loss = 0.14326785557867983
Trained batch 158 in epoch 2, gen_loss = 0.3854001687382752, disc_loss = 0.14272530663922522
Trained batch 159 in epoch 2, gen_loss = 0.38613140154629944, disc_loss = 0.14221081716241316
Trained batch 160 in epoch 2, gen_loss = 0.3862085188767925, disc_loss = 0.1436852301985766
Trained batch 161 in epoch 2, gen_loss = 0.38612618177761265, disc_loss = 0.14376398425457287
Trained batch 162 in epoch 2, gen_loss = 0.3862894142697925, disc_loss = 0.14324468203985985
Trained batch 163 in epoch 2, gen_loss = 0.38633718668687633, disc_loss = 0.14281070117679676
Trained batch 164 in epoch 2, gen_loss = 0.3862529071894559, disc_loss = 0.1425444063702316
Trained batch 165 in epoch 2, gen_loss = 0.38649592880743094, disc_loss = 0.142046544061278
Trained batch 166 in epoch 2, gen_loss = 0.3866133352596603, disc_loss = 0.1420800207952361
Trained batch 167 in epoch 2, gen_loss = 0.3868828305885905, disc_loss = 0.14158808092941486
Trained batch 168 in epoch 2, gen_loss = 0.38711447105605223, disc_loss = 0.14192665362807774
Trained batch 169 in epoch 2, gen_loss = 0.387030611669316, disc_loss = 0.14270407416145592
Trained batch 170 in epoch 2, gen_loss = 0.3870098425282372, disc_loss = 0.1425848125605381
Trained batch 171 in epoch 2, gen_loss = 0.38702271012372746, disc_loss = 0.1422369873346111
Trained batch 172 in epoch 2, gen_loss = 0.3872019527964509, disc_loss = 0.14220778341539678
Trained batch 173 in epoch 2, gen_loss = 0.3877233247989896, disc_loss = 0.14186247274408054
Trained batch 174 in epoch 2, gen_loss = 0.38759098376546586, disc_loss = 0.14139296977647714
Trained batch 175 in epoch 2, gen_loss = 0.3874225721440532, disc_loss = 0.1415982106171379
Trained batch 176 in epoch 2, gen_loss = 0.38763651689567136, disc_loss = 0.1421254962830052
Trained batch 177 in epoch 2, gen_loss = 0.38765280467740604, disc_loss = 0.1423534197900235
Trained batch 178 in epoch 2, gen_loss = 0.38742262824287627, disc_loss = 0.14216227045896665
Trained batch 179 in epoch 2, gen_loss = 0.3876916305886375, disc_loss = 0.14233592921454047
Trained batch 180 in epoch 2, gen_loss = 0.3875548721018417, disc_loss = 0.14246794012328867
Trained batch 181 in epoch 2, gen_loss = 0.3873741801950958, disc_loss = 0.14268441325319664
Trained batch 182 in epoch 2, gen_loss = 0.3873636242144746, disc_loss = 0.14305947434991761
Trained batch 183 in epoch 2, gen_loss = 0.38735819267837895, disc_loss = 0.14289631385801602
Trained batch 184 in epoch 2, gen_loss = 0.3871754374053027, disc_loss = 0.14264131610256595
Trained batch 185 in epoch 2, gen_loss = 0.3872237096550644, disc_loss = 0.14240022367166896
Trained batch 186 in epoch 2, gen_loss = 0.38744252442038635, disc_loss = 0.14201558511803813
Trained batch 187 in epoch 2, gen_loss = 0.3875761475968868, disc_loss = 0.14253959565998076
Trained batch 188 in epoch 2, gen_loss = 0.3883839464061475, disc_loss = 0.14333469179217462
Trained batch 189 in epoch 2, gen_loss = 0.3881049496562857, disc_loss = 0.14302881841400736
Trained batch 190 in epoch 2, gen_loss = 0.3876435884630493, disc_loss = 0.1426603519382121
Trained batch 191 in epoch 2, gen_loss = 0.387357111244152, disc_loss = 0.142347115004668
Trained batch 192 in epoch 2, gen_loss = 0.3877167525686748, disc_loss = 0.14221615601967963
Trained batch 193 in epoch 2, gen_loss = 0.38737292050086347, disc_loss = 0.14204190098248498
Trained batch 194 in epoch 2, gen_loss = 0.3875605301979261, disc_loss = 0.14468644516399273
Trained batch 195 in epoch 2, gen_loss = 0.3884541270684223, disc_loss = 0.14433714788293048
Trained batch 196 in epoch 2, gen_loss = 0.3884506836760468, disc_loss = 0.14475828079213648
Trained batch 197 in epoch 2, gen_loss = 0.38836937661122795, disc_loss = 0.14464612740722269
Trained batch 198 in epoch 2, gen_loss = 0.3885347772782771, disc_loss = 0.14423036868286193
Trained batch 199 in epoch 2, gen_loss = 0.38832719445228575, disc_loss = 0.14459205933846533
Trained batch 200 in epoch 2, gen_loss = 0.3878072639602927, disc_loss = 0.14498166333124116
Trained batch 201 in epoch 2, gen_loss = 0.3874896848850911, disc_loss = 0.14533093425048754
Trained batch 202 in epoch 2, gen_loss = 0.38714225083736364, disc_loss = 0.14556982600373294
Trained batch 203 in epoch 2, gen_loss = 0.3869515254217036, disc_loss = 0.14556770210209138
Trained batch 204 in epoch 2, gen_loss = 0.3870695875912178, disc_loss = 0.14560005876530963
Trained batch 205 in epoch 2, gen_loss = 0.38769942550983244, disc_loss = 0.14579804394466495
Trained batch 206 in epoch 2, gen_loss = 0.387565673261449, disc_loss = 0.1455092081071242
Trained batch 207 in epoch 2, gen_loss = 0.38750560467059797, disc_loss = 0.14587210814576024
Trained batch 208 in epoch 2, gen_loss = 0.38762734666395415, disc_loss = 0.14620637595118804
Trained batch 209 in epoch 2, gen_loss = 0.3877327530156998, disc_loss = 0.14631951040632668
Trained batch 210 in epoch 2, gen_loss = 0.3873529977990553, disc_loss = 0.14708419688822816
Trained batch 211 in epoch 2, gen_loss = 0.3871502304133379, disc_loss = 0.14719717809930444
Trained batch 212 in epoch 2, gen_loss = 0.38725769253963593, disc_loss = 0.14714066139444218
Trained batch 213 in epoch 2, gen_loss = 0.38713090121746063, disc_loss = 0.1471185389749497
Trained batch 214 in epoch 2, gen_loss = 0.3866461293641911, disc_loss = 0.14721608038038708
Trained batch 215 in epoch 2, gen_loss = 0.38665493936450396, disc_loss = 0.14689166261814535
Trained batch 216 in epoch 2, gen_loss = 0.3863721864838754, disc_loss = 0.1468425096883889
Trained batch 217 in epoch 2, gen_loss = 0.3864902056958697, disc_loss = 0.14685483342634703
Trained batch 218 in epoch 2, gen_loss = 0.3864144576738959, disc_loss = 0.14682051584498795
Trained batch 219 in epoch 2, gen_loss = 0.3862715414979241, disc_loss = 0.1471930989910933
Trained batch 220 in epoch 2, gen_loss = 0.3865640170164238, disc_loss = 0.14665310261813225
Trained batch 221 in epoch 2, gen_loss = 0.38624705964917533, disc_loss = 0.1472158388545116
Trained batch 222 in epoch 2, gen_loss = 0.3863237414659406, disc_loss = 0.14692713559141607
Trained batch 223 in epoch 2, gen_loss = 0.38644710063402143, disc_loss = 0.14672369834235205
Trained batch 224 in epoch 2, gen_loss = 0.3866939026779599, disc_loss = 0.14660814522041216
Trained batch 225 in epoch 2, gen_loss = 0.3862289796888301, disc_loss = 0.14659471089531362
Trained batch 226 in epoch 2, gen_loss = 0.38639727221711617, disc_loss = 0.1464518020955214
Trained batch 227 in epoch 2, gen_loss = 0.3863024659324111, disc_loss = 0.14618198660185985
Trained batch 228 in epoch 2, gen_loss = 0.38635780353212984, disc_loss = 0.14577922591020448
Trained batch 229 in epoch 2, gen_loss = 0.38607921496681546, disc_loss = 0.14596743611213953
Trained batch 230 in epoch 2, gen_loss = 0.3863790282955417, disc_loss = 0.1470963642871999
Trained batch 231 in epoch 2, gen_loss = 0.38685068899187547, disc_loss = 0.14664153025710377
Trained batch 232 in epoch 2, gen_loss = 0.38668718793361484, disc_loss = 0.14681435421173153
Trained batch 233 in epoch 2, gen_loss = 0.3865249058884433, disc_loss = 0.1467075739851874
Trained batch 234 in epoch 2, gen_loss = 0.3866226111320739, disc_loss = 0.14665847068771404
Trained batch 235 in epoch 2, gen_loss = 0.38678735103142464, disc_loss = 0.14655532337472602
Trained batch 236 in epoch 2, gen_loss = 0.38640058795108073, disc_loss = 0.14671236568991142
Trained batch 237 in epoch 2, gen_loss = 0.38659337513587055, disc_loss = 0.146384765589688
Trained batch 238 in epoch 2, gen_loss = 0.3866328587093114, disc_loss = 0.14623922589683133
Trained batch 239 in epoch 2, gen_loss = 0.38655891865491865, disc_loss = 0.14638734969000022
Trained batch 240 in epoch 2, gen_loss = 0.386411198441913, disc_loss = 0.14613824897287297
Trained batch 241 in epoch 2, gen_loss = 0.3865418477245599, disc_loss = 0.14572476609494567
Trained batch 242 in epoch 2, gen_loss = 0.38649138244091236, disc_loss = 0.1453413770921191
Trained batch 243 in epoch 2, gen_loss = 0.38648731249277707, disc_loss = 0.14501792041310033
Trained batch 244 in epoch 2, gen_loss = 0.3865729121529326, disc_loss = 0.144956417184095
Trained batch 245 in epoch 2, gen_loss = 0.38676868839477135, disc_loss = 0.14469803044405893
Trained batch 246 in epoch 2, gen_loss = 0.38705089881352567, disc_loss = 0.14546041762237608
Trained batch 247 in epoch 2, gen_loss = 0.38689707652215033, disc_loss = 0.14517279580656078
Trained batch 248 in epoch 2, gen_loss = 0.3869173087508803, disc_loss = 0.14528458728548513
Trained batch 249 in epoch 2, gen_loss = 0.38688067996501924, disc_loss = 0.14564402262866497
Trained batch 250 in epoch 2, gen_loss = 0.3869313984753126, disc_loss = 0.14543815561202894
Trained batch 251 in epoch 2, gen_loss = 0.38677462710747645, disc_loss = 0.1452379044411438
Trained batch 252 in epoch 2, gen_loss = 0.3869698541202093, disc_loss = 0.14526793877538957
Trained batch 253 in epoch 2, gen_loss = 0.38683277415478323, disc_loss = 0.14492868184750005
Trained batch 254 in epoch 2, gen_loss = 0.3872453163651859, disc_loss = 0.14445780852407802
Trained batch 255 in epoch 2, gen_loss = 0.38713284209370613, disc_loss = 0.14409160761715611
Trained batch 256 in epoch 2, gen_loss = 0.3870103634053167, disc_loss = 0.14361434944466858
Trained batch 257 in epoch 2, gen_loss = 0.3870730604543242, disc_loss = 0.1432438199949819
Trained batch 258 in epoch 2, gen_loss = 0.38728741962016777, disc_loss = 0.143053888469129
Trained batch 259 in epoch 2, gen_loss = 0.38783720972446295, disc_loss = 0.14268217134074523
Trained batch 260 in epoch 2, gen_loss = 0.3877364583170734, disc_loss = 0.14257348641410642
Trained batch 261 in epoch 2, gen_loss = 0.3878507746084956, disc_loss = 0.14256771279939714
Trained batch 262 in epoch 2, gen_loss = 0.38803332670106633, disc_loss = 0.1427176095715267
Trained batch 263 in epoch 2, gen_loss = 0.38811617468794185, disc_loss = 0.1432124090268079
Trained batch 264 in epoch 2, gen_loss = 0.38824046940173745, disc_loss = 0.14286557163270014
Trained batch 265 in epoch 2, gen_loss = 0.3880251511595303, disc_loss = 0.14309673921618246
Trained batch 266 in epoch 2, gen_loss = 0.3886381128754062, disc_loss = 0.14337815280152616
Trained batch 267 in epoch 2, gen_loss = 0.3885756953438716, disc_loss = 0.14300372760131289
Trained batch 268 in epoch 2, gen_loss = 0.38846598582196856, disc_loss = 0.14382915024309798
Trained batch 269 in epoch 2, gen_loss = 0.388342864535473, disc_loss = 0.14432032403570635
Trained batch 270 in epoch 2, gen_loss = 0.3881753542326473, disc_loss = 0.144167987622898
Trained batch 271 in epoch 2, gen_loss = 0.38812247860957594, disc_loss = 0.14410954242681756
Trained batch 272 in epoch 2, gen_loss = 0.3878294328848521, disc_loss = 0.14424146144163041
Trained batch 273 in epoch 2, gen_loss = 0.3877247077052611, disc_loss = 0.14427372497798752
Trained batch 274 in epoch 2, gen_loss = 0.3876781911199743, disc_loss = 0.1444098132306879
Trained batch 275 in epoch 2, gen_loss = 0.3871812285936397, disc_loss = 0.14439749069835828
Trained batch 276 in epoch 2, gen_loss = 0.3871558774464397, disc_loss = 0.14426289740882625
Trained batch 277 in epoch 2, gen_loss = 0.3870374202299461, disc_loss = 0.1441123486905218
Trained batch 278 in epoch 2, gen_loss = 0.38722726862917667, disc_loss = 0.1438301941880616
Trained batch 279 in epoch 2, gen_loss = 0.38734246705259595, disc_loss = 0.14397232833185367
Trained batch 280 in epoch 2, gen_loss = 0.38739818048222635, disc_loss = 0.1435465163939046
Trained batch 281 in epoch 2, gen_loss = 0.3871638321496071, disc_loss = 0.14341771806728967
Trained batch 282 in epoch 2, gen_loss = 0.38739009954482845, disc_loss = 0.14307762261861837
Trained batch 283 in epoch 2, gen_loss = 0.3876581128004571, disc_loss = 0.14322681274448693
Trained batch 284 in epoch 2, gen_loss = 0.38761642282469233, disc_loss = 0.14396165829609361
Trained batch 285 in epoch 2, gen_loss = 0.38778567074478926, disc_loss = 0.14366264173018556
Trained batch 286 in epoch 2, gen_loss = 0.3881489635552263, disc_loss = 0.14345387126017323
Trained batch 287 in epoch 2, gen_loss = 0.3880481341232856, disc_loss = 0.14346090997181213
Trained batch 288 in epoch 2, gen_loss = 0.38795256635309505, disc_loss = 0.14325219254206004
Trained batch 289 in epoch 2, gen_loss = 0.3878940392157127, disc_loss = 0.14328973288808403
Trained batch 290 in epoch 2, gen_loss = 0.3878926001873213, disc_loss = 0.14392277675831236
Trained batch 291 in epoch 2, gen_loss = 0.3876745545700805, disc_loss = 0.1436344805071513
Trained batch 292 in epoch 2, gen_loss = 0.388013754891861, disc_loss = 0.14336759398084248
Trained batch 293 in epoch 2, gen_loss = 0.3881135853577633, disc_loss = 0.14315583624680633
Trained batch 294 in epoch 2, gen_loss = 0.38820537955073986, disc_loss = 0.14294449580296623
Trained batch 295 in epoch 2, gen_loss = 0.38794854524973277, disc_loss = 0.14293347816989832
Trained batch 296 in epoch 2, gen_loss = 0.38830349983189644, disc_loss = 0.14292103784027124
Trained batch 297 in epoch 2, gen_loss = 0.38833404677426253, disc_loss = 0.14283198232593752
Trained batch 298 in epoch 2, gen_loss = 0.3880293977300459, disc_loss = 0.14259984974054787
Trained batch 299 in epoch 2, gen_loss = 0.3878642503420512, disc_loss = 0.14278761758779487
Trained batch 300 in epoch 2, gen_loss = 0.38779886309490647, disc_loss = 0.14258587357287986
Trained batch 301 in epoch 2, gen_loss = 0.3875022854236578, disc_loss = 0.14303023942332987
Trained batch 302 in epoch 2, gen_loss = 0.3873964433032687, disc_loss = 0.1428978660208459
Trained batch 303 in epoch 2, gen_loss = 0.38757482867099735, disc_loss = 0.14278568427299002
Trained batch 304 in epoch 2, gen_loss = 0.3873972887875604, disc_loss = 0.1430372467966842
Trained batch 305 in epoch 2, gen_loss = 0.3873038418542326, disc_loss = 0.14329129732000867
Trained batch 306 in epoch 2, gen_loss = 0.38694744593545743, disc_loss = 0.1434747045404651
Trained batch 307 in epoch 2, gen_loss = 0.3869665575685439, disc_loss = 0.14354086698141771
Trained batch 308 in epoch 2, gen_loss = 0.38718903064727783, disc_loss = 0.14357600302637394
Trained batch 309 in epoch 2, gen_loss = 0.3871263454037328, disc_loss = 0.14355950232354864
Trained batch 310 in epoch 2, gen_loss = 0.3868589963751974, disc_loss = 0.1438018833122357
Trained batch 311 in epoch 2, gen_loss = 0.3870645385140028, disc_loss = 0.14403592156938827
Trained batch 312 in epoch 2, gen_loss = 0.3869371752198131, disc_loss = 0.14427189459316075
Trained batch 313 in epoch 2, gen_loss = 0.38677040814973745, disc_loss = 0.1442866908789725
Trained batch 314 in epoch 2, gen_loss = 0.3866773063228244, disc_loss = 0.14432787390810156
Trained batch 315 in epoch 2, gen_loss = 0.3866709179327458, disc_loss = 0.14420316667189892
Trained batch 316 in epoch 2, gen_loss = 0.38669866765335154, disc_loss = 0.14441581142696108
Trained batch 317 in epoch 2, gen_loss = 0.3869595957814522, disc_loss = 0.1448003507435978
Trained batch 318 in epoch 2, gen_loss = 0.3868163342012507, disc_loss = 0.14484651323092582
Trained batch 319 in epoch 2, gen_loss = 0.38675242606550453, disc_loss = 0.14483590248855763
Trained batch 320 in epoch 2, gen_loss = 0.3869599789102501, disc_loss = 0.1446145657983803
Trained batch 321 in epoch 2, gen_loss = 0.38695789975409184, disc_loss = 0.1444556431451477
Trained batch 322 in epoch 2, gen_loss = 0.3866236948930073, disc_loss = 0.14474849584555663
Trained batch 323 in epoch 2, gen_loss = 0.386540925797121, disc_loss = 0.14471041224322018
Trained batch 324 in epoch 2, gen_loss = 0.3863859951496124, disc_loss = 0.14478417957631443
Trained batch 325 in epoch 2, gen_loss = 0.3867974543681174, disc_loss = 0.14476191267896832
Trained batch 326 in epoch 2, gen_loss = 0.38691729134011343, disc_loss = 0.1445093368000667
Trained batch 327 in epoch 2, gen_loss = 0.38702590363781625, disc_loss = 0.14421558124013245
Trained batch 328 in epoch 2, gen_loss = 0.3871422001474896, disc_loss = 0.1438518690177463
Trained batch 329 in epoch 2, gen_loss = 0.38745762353593655, disc_loss = 0.14352061463463486
Trained batch 330 in epoch 2, gen_loss = 0.38751398715727997, disc_loss = 0.14322334766005282
Trained batch 331 in epoch 2, gen_loss = 0.38773438011307315, disc_loss = 0.14284733534756913
Trained batch 332 in epoch 2, gen_loss = 0.38774737366684925, disc_loss = 0.14259375564686888
Trained batch 333 in epoch 2, gen_loss = 0.3876031693405734, disc_loss = 0.1426516834222628
Trained batch 334 in epoch 2, gen_loss = 0.3875674125863545, disc_loss = 0.14286888828918115
Trained batch 335 in epoch 2, gen_loss = 0.3877703956372681, disc_loss = 0.14250028094587228
Trained batch 336 in epoch 2, gen_loss = 0.3878599005566153, disc_loss = 0.14225263466909308
Trained batch 337 in epoch 2, gen_loss = 0.3878369047444248, disc_loss = 0.1420393664411892
Trained batch 338 in epoch 2, gen_loss = 0.3877800172057475, disc_loss = 0.14189568621306997
Trained batch 339 in epoch 2, gen_loss = 0.38782472654300576, disc_loss = 0.14200156271895942
Trained batch 340 in epoch 2, gen_loss = 0.3877463794348876, disc_loss = 0.142040893413629
Trained batch 341 in epoch 2, gen_loss = 0.3880432372727589, disc_loss = 0.14223608002066612
Trained batch 342 in epoch 2, gen_loss = 0.38815455038762997, disc_loss = 0.14211303358435978
Trained batch 343 in epoch 2, gen_loss = 0.38792536840882413, disc_loss = 0.14217858395517566
Trained batch 344 in epoch 2, gen_loss = 0.3878698344679846, disc_loss = 0.14203044141548268
Trained batch 345 in epoch 2, gen_loss = 0.3881106726351501, disc_loss = 0.14179869765964892
Trained batch 346 in epoch 2, gen_loss = 0.38791536554823003, disc_loss = 0.14269819798790756
Trained batch 347 in epoch 2, gen_loss = 0.38782052627240104, disc_loss = 0.14253259406307306
Trained batch 348 in epoch 2, gen_loss = 0.3874264258709883, disc_loss = 0.1425908332888069
Trained batch 349 in epoch 2, gen_loss = 0.38752170383930207, disc_loss = 0.1425525327133281
Trained batch 350 in epoch 2, gen_loss = 0.38769086074625325, disc_loss = 0.14250773487564844
Trained batch 351 in epoch 2, gen_loss = 0.38753430418331514, disc_loss = 0.14262539849997583
Trained batch 352 in epoch 2, gen_loss = 0.38739378028483296, disc_loss = 0.1424312160031147
Trained batch 353 in epoch 2, gen_loss = 0.38729186280299044, disc_loss = 0.14235213368415495
Trained batch 354 in epoch 2, gen_loss = 0.3872697038549772, disc_loss = 0.14293711423664027
Trained batch 355 in epoch 2, gen_loss = 0.3872473304358761, disc_loss = 0.1431253460246358
Trained batch 356 in epoch 2, gen_loss = 0.38738423811287437, disc_loss = 0.1430144464122314
Trained batch 357 in epoch 2, gen_loss = 0.38730592442957384, disc_loss = 0.14318665130552966
Trained batch 358 in epoch 2, gen_loss = 0.3872064078086598, disc_loss = 0.14322423603914908
Trained batch 359 in epoch 2, gen_loss = 0.3870870606766807, disc_loss = 0.14309090573547614
Trained batch 360 in epoch 2, gen_loss = 0.38722231497064524, disc_loss = 0.1431300054688698
Trained batch 361 in epoch 2, gen_loss = 0.38725560689499366, disc_loss = 0.14291249912293905
Trained batch 362 in epoch 2, gen_loss = 0.38720779551947415, disc_loss = 0.14292006860628273
Trained batch 363 in epoch 2, gen_loss = 0.3871794874360273, disc_loss = 0.14287793711032515
Trained batch 364 in epoch 2, gen_loss = 0.38726684655228705, disc_loss = 0.14300164001649374
Trained batch 365 in epoch 2, gen_loss = 0.3868422441876651, disc_loss = 0.1433707772158697
Trained batch 366 in epoch 2, gen_loss = 0.38685576966900265, disc_loss = 0.1435082181374611
Trained batch 367 in epoch 2, gen_loss = 0.3869524318319948, disc_loss = 0.1434308664529058
Trained batch 368 in epoch 2, gen_loss = 0.38677671757655413, disc_loss = 0.14358028829057365
Trained batch 369 in epoch 2, gen_loss = 0.38670484363227275, disc_loss = 0.14374011085444205
Trained batch 370 in epoch 2, gen_loss = 0.38681277813455167, disc_loss = 0.14374372679388747
Trained batch 371 in epoch 2, gen_loss = 0.38682142585035295, disc_loss = 0.1437660259324857
Trained batch 372 in epoch 2, gen_loss = 0.38682505987764365, disc_loss = 0.1435706417198635
Trained batch 373 in epoch 2, gen_loss = 0.3868483059944954, disc_loss = 0.1433249889589089
Trained batch 374 in epoch 2, gen_loss = 0.38689480125904085, disc_loss = 0.1432728653649489
Trained batch 375 in epoch 2, gen_loss = 0.3867891118960812, disc_loss = 0.14337754938157
Trained batch 376 in epoch 2, gen_loss = 0.38675337085198974, disc_loss = 0.1433351268641038
Trained batch 377 in epoch 2, gen_loss = 0.38689855998628353, disc_loss = 0.14342110528162233
Trained batch 378 in epoch 2, gen_loss = 0.3867974197565723, disc_loss = 0.14350050958094623
Trained batch 379 in epoch 2, gen_loss = 0.38681020042613934, disc_loss = 0.14333463210220398
Trained batch 380 in epoch 2, gen_loss = 0.3866400893513612, disc_loss = 0.14312459799287514
Trained batch 381 in epoch 2, gen_loss = 0.3866524383893812, disc_loss = 0.14353880318398562
Trained batch 382 in epoch 2, gen_loss = 0.38673872576525564, disc_loss = 0.1432983309867021
Trained batch 383 in epoch 2, gen_loss = 0.3867353966537242, disc_loss = 0.1430540129658766
Trained batch 384 in epoch 2, gen_loss = 0.38707970415616966, disc_loss = 0.14297556242385467
Trained batch 385 in epoch 2, gen_loss = 0.387278169895392, disc_loss = 0.1431853143893993
Trained batch 386 in epoch 2, gen_loss = 0.38726835522694797, disc_loss = 0.14320650504232993
Trained batch 387 in epoch 2, gen_loss = 0.38757536725438746, disc_loss = 0.14305410778015545
Trained batch 388 in epoch 2, gen_loss = 0.387519189240387, disc_loss = 0.14322279774820895
Trained batch 389 in epoch 2, gen_loss = 0.387584025088029, disc_loss = 0.14324378105692373
Trained batch 390 in epoch 2, gen_loss = 0.38741849240896953, disc_loss = 0.14339513000091322
Trained batch 391 in epoch 2, gen_loss = 0.38745254920605493, disc_loss = 0.14338838816525376
Trained batch 392 in epoch 2, gen_loss = 0.38778182663232014, disc_loss = 0.14321572900425084
Trained batch 393 in epoch 2, gen_loss = 0.38770710117169443, disc_loss = 0.1431316149983612
Trained batch 394 in epoch 2, gen_loss = 0.3878356688007524, disc_loss = 0.1430281657018239
Trained batch 395 in epoch 2, gen_loss = 0.38798950525997866, disc_loss = 0.14306006556132225
Trained batch 396 in epoch 2, gen_loss = 0.3879317695683136, disc_loss = 0.1430558438227519
Trained batch 397 in epoch 2, gen_loss = 0.3879605448201074, disc_loss = 0.1431460126523097
Trained batch 398 in epoch 2, gen_loss = 0.38792170726117636, disc_loss = 0.14321903964705335
Trained batch 399 in epoch 2, gen_loss = 0.3881858536973596, disc_loss = 0.14317962421104313
Trained batch 400 in epoch 2, gen_loss = 0.3880290554422987, disc_loss = 0.14319193290727691
Trained batch 401 in epoch 2, gen_loss = 0.3881182195757752, disc_loss = 0.14329509353682177
Trained batch 402 in epoch 2, gen_loss = 0.3883316695468301, disc_loss = 0.14328281483416522
Trained batch 403 in epoch 2, gen_loss = 0.3881702087819576, disc_loss = 0.1431775293912333
Trained batch 404 in epoch 2, gen_loss = 0.388107109989649, disc_loss = 0.14336334770476378
Trained batch 405 in epoch 2, gen_loss = 0.38809810810048007, disc_loss = 0.1437522267069429
Trained batch 406 in epoch 2, gen_loss = 0.3881181995830606, disc_loss = 0.14348626815935903
Trained batch 407 in epoch 2, gen_loss = 0.3879591848555149, disc_loss = 0.1434848255423062
Trained batch 408 in epoch 2, gen_loss = 0.3879259481916801, disc_loss = 0.14324786100527476
Trained batch 409 in epoch 2, gen_loss = 0.387906322791809, disc_loss = 0.14338287871058394
Trained batch 410 in epoch 2, gen_loss = 0.38809530625523153, disc_loss = 0.14329458952602678
Trained batch 411 in epoch 2, gen_loss = 0.3879874275219672, disc_loss = 0.14315852882720312
Trained batch 412 in epoch 2, gen_loss = 0.3879832324118649, disc_loss = 0.14310324753095682
Trained batch 413 in epoch 2, gen_loss = 0.38810052708295234, disc_loss = 0.14308794172129768
Trained batch 414 in epoch 2, gen_loss = 0.38835234659982015, disc_loss = 0.14286230016185578
Trained batch 415 in epoch 2, gen_loss = 0.3882426624186337, disc_loss = 0.14299218718392345
Trained batch 416 in epoch 2, gen_loss = 0.38817923121172176, disc_loss = 0.14284561613766694
Trained batch 417 in epoch 2, gen_loss = 0.3881800223551869, disc_loss = 0.1427150193120589
Trained batch 418 in epoch 2, gen_loss = 0.3879380603465374, disc_loss = 0.14308491546598426
Trained batch 419 in epoch 2, gen_loss = 0.3881419964134693, disc_loss = 0.1429550863625038
Trained batch 420 in epoch 2, gen_loss = 0.38804470080519515, disc_loss = 0.14288354089877384
Trained batch 421 in epoch 2, gen_loss = 0.3878256701533263, disc_loss = 0.14290511389196767
Trained batch 422 in epoch 2, gen_loss = 0.3878252153630516, disc_loss = 0.14281412384893313
Trained batch 423 in epoch 2, gen_loss = 0.38771022543451694, disc_loss = 0.14296766729006227
Trained batch 424 in epoch 2, gen_loss = 0.38759393015328575, disc_loss = 0.14295239494127385
Trained batch 425 in epoch 2, gen_loss = 0.3876095246611067, disc_loss = 0.14278754967968788
Trained batch 426 in epoch 2, gen_loss = 0.3875612659462721, disc_loss = 0.14272289723157883
Trained batch 427 in epoch 2, gen_loss = 0.38749102729363977, disc_loss = 0.14256437417015294
Trained batch 428 in epoch 2, gen_loss = 0.3877590849891409, disc_loss = 0.14233570252404068
Trained batch 429 in epoch 2, gen_loss = 0.3878310404198114, disc_loss = 0.14232815185258554
Trained batch 430 in epoch 2, gen_loss = 0.38807183874040635, disc_loss = 0.14250007036667137
Trained batch 431 in epoch 2, gen_loss = 0.38805625211723427, disc_loss = 0.14245460834354162
Trained batch 432 in epoch 2, gen_loss = 0.38813697138917364, disc_loss = 0.14225733531402385
Trained batch 433 in epoch 2, gen_loss = 0.3882046009881705, disc_loss = 0.14224772721803683
Trained batch 434 in epoch 2, gen_loss = 0.38797159534076164, disc_loss = 0.14226813199876367
Trained batch 435 in epoch 2, gen_loss = 0.38766466925313714, disc_loss = 0.14257420886547192
Trained batch 436 in epoch 2, gen_loss = 0.3878217568318413, disc_loss = 0.14273583796940897
Trained batch 437 in epoch 2, gen_loss = 0.38792437236739075, disc_loss = 0.1427099417605901
Trained batch 438 in epoch 2, gen_loss = 0.38782093468586787, disc_loss = 0.14312322054202573
Trained batch 439 in epoch 2, gen_loss = 0.3875968730246479, disc_loss = 0.14345036474141207
Trained batch 440 in epoch 2, gen_loss = 0.38735387503019536, disc_loss = 0.14347126464995127
Trained batch 441 in epoch 2, gen_loss = 0.3872786228675648, disc_loss = 0.14361015063335453
Trained batch 442 in epoch 2, gen_loss = 0.38726321363960375, disc_loss = 0.14353651149749216
Trained batch 443 in epoch 2, gen_loss = 0.387116555460133, disc_loss = 0.14350412200364443
Trained batch 444 in epoch 2, gen_loss = 0.3871944940826866, disc_loss = 0.14345188671618364
Trained batch 445 in epoch 2, gen_loss = 0.38705426511342217, disc_loss = 0.14344850595155104
Trained batch 446 in epoch 2, gen_loss = 0.3870265169498371, disc_loss = 0.14355181039246404
Trained batch 447 in epoch 2, gen_loss = 0.38698060168618603, disc_loss = 0.14339531736914068
Trained batch 448 in epoch 2, gen_loss = 0.38709473367655994, disc_loss = 0.14321147849604918
Trained batch 449 in epoch 2, gen_loss = 0.38718494564294814, disc_loss = 0.14306124897466765
Trained batch 450 in epoch 2, gen_loss = 0.38723334276887633, disc_loss = 0.14302591716833496
Trained batch 451 in epoch 2, gen_loss = 0.3870941127230108, disc_loss = 0.14308846977630021
Trained batch 452 in epoch 2, gen_loss = 0.3869292162704152, disc_loss = 0.14323659163897665
Trained batch 453 in epoch 2, gen_loss = 0.3872037808603652, disc_loss = 0.14362848755218385
Trained batch 454 in epoch 2, gen_loss = 0.3872310597490478, disc_loss = 0.14357239219186071
Trained batch 455 in epoch 2, gen_loss = 0.3871933056139632, disc_loss = 0.14345987998929463
Trained batch 456 in epoch 2, gen_loss = 0.3870804597108056, disc_loss = 0.1434492779084577
Trained batch 457 in epoch 2, gen_loss = 0.3871137925696165, disc_loss = 0.1434612550882533
Trained batch 458 in epoch 2, gen_loss = 0.386982626547481, disc_loss = 0.14360677356748539
Trained batch 459 in epoch 2, gen_loss = 0.38701593982784643, disc_loss = 0.14346126850856386
Trained batch 460 in epoch 2, gen_loss = 0.38696052780508217, disc_loss = 0.1436359740939161
Testing Epoch 2

Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.3806764483451843, disc_loss = 0.12050026655197144
Trained batch 1 in epoch 3, gen_loss = 0.45947393774986267, disc_loss = 0.081325339153409
Trained batch 2 in epoch 3, gen_loss = 0.421735147635142, disc_loss = 0.08397234852115314
Trained batch 3 in epoch 3, gen_loss = 0.40676888078451157, disc_loss = 0.08010382670909166
Trained batch 4 in epoch 3, gen_loss = 0.3918981492519379, disc_loss = 0.09313597455620766
Trained batch 5 in epoch 3, gen_loss = 0.3754131942987442, disc_loss = 0.10130677931010723
Trained batch 6 in epoch 3, gen_loss = 0.38241497959409443, disc_loss = 0.10751078650355339
Trained batch 7 in epoch 3, gen_loss = 0.3902481906116009, disc_loss = 0.14516610512509942
Trained batch 8 in epoch 3, gen_loss = 0.3835662802060445, disc_loss = 0.14712480910950237
Trained batch 9 in epoch 3, gen_loss = 0.3834154635667801, disc_loss = 0.14002331383526326
Trained batch 10 in epoch 3, gen_loss = 0.38075143640691583, disc_loss = 0.13773008402098308
Trained batch 11 in epoch 3, gen_loss = 0.3821580807367961, disc_loss = 0.13565282430499792
Trained batch 12 in epoch 3, gen_loss = 0.38472782648526704, disc_loss = 0.13137382698746827
Trained batch 13 in epoch 3, gen_loss = 0.3920638476099287, disc_loss = 0.13716644660702773
Trained batch 14 in epoch 3, gen_loss = 0.38732492327690127, disc_loss = 0.1402054804066817
Trained batch 15 in epoch 3, gen_loss = 0.38709896989166737, disc_loss = 0.13631057157181203
Trained batch 16 in epoch 3, gen_loss = 0.3894086865817799, disc_loss = 0.134394478491124
Trained batch 17 in epoch 3, gen_loss = 0.39201755159431034, disc_loss = 0.1327295276439852
Trained batch 18 in epoch 3, gen_loss = 0.3911255786293431, disc_loss = 0.13683198608065905
Trained batch 19 in epoch 3, gen_loss = 0.39203151762485505, disc_loss = 0.15270968060940504
Trained batch 20 in epoch 3, gen_loss = 0.39273313539368765, disc_loss = 0.15134859457612038
Trained batch 21 in epoch 3, gen_loss = 0.3887868428772146, disc_loss = 0.15363518639721654
Trained batch 22 in epoch 3, gen_loss = 0.3884878521380217, disc_loss = 0.15038929733893144
Trained batch 23 in epoch 3, gen_loss = 0.3905327481528123, disc_loss = 0.14597434705744186
Trained batch 24 in epoch 3, gen_loss = 0.39041111946105955, disc_loss = 0.14142152041196823
Trained batch 25 in epoch 3, gen_loss = 0.3911827584871879, disc_loss = 0.13680196925997734
Trained batch 26 in epoch 3, gen_loss = 0.39153081289044134, disc_loss = 0.1342262832654847
Trained batch 27 in epoch 3, gen_loss = 0.3909922604049955, disc_loss = 0.13113445123391493
Trained batch 28 in epoch 3, gen_loss = 0.38749381591533794, disc_loss = 0.12938491768878083
Trained batch 29 in epoch 3, gen_loss = 0.38846731980641686, disc_loss = 0.12683576419949533
Trained batch 30 in epoch 3, gen_loss = 0.3853380814675362, disc_loss = 0.12436570840016488
Trained batch 31 in epoch 3, gen_loss = 0.38740023504942656, disc_loss = 0.12254279537592083
Trained batch 32 in epoch 3, gen_loss = 0.39111664710622845, disc_loss = 0.1218055458457181
Trained batch 33 in epoch 3, gen_loss = 0.3944743985638899, disc_loss = 0.12334900075460181
Trained batch 34 in epoch 3, gen_loss = 0.39317372356142316, disc_loss = 0.12361207380890846
Trained batch 35 in epoch 3, gen_loss = 0.3910661041736603, disc_loss = 0.12104532981498374
Trained batch 36 in epoch 3, gen_loss = 0.3906159344557169, disc_loss = 0.12044491185932546
Trained batch 37 in epoch 3, gen_loss = 0.38758000025623723, disc_loss = 0.12621755299991683
Trained batch 38 in epoch 3, gen_loss = 0.3888999323050181, disc_loss = 0.1253232977902278
Trained batch 39 in epoch 3, gen_loss = 0.38865152224898336, disc_loss = 0.12387983044609427
Trained batch 40 in epoch 3, gen_loss = 0.3879685794434896, disc_loss = 0.12452650715301676
Trained batch 41 in epoch 3, gen_loss = 0.3885848444132578, disc_loss = 0.12280953693247977
Trained batch 42 in epoch 3, gen_loss = 0.39119252978369246, disc_loss = 0.12222587039997411
Trained batch 43 in epoch 3, gen_loss = 0.3932558643546971, disc_loss = 0.12169741991568696
Trained batch 44 in epoch 3, gen_loss = 0.39277940922313265, disc_loss = 0.12181864728530248
Trained batch 45 in epoch 3, gen_loss = 0.392717191706533, disc_loss = 0.12045897705399472
Trained batch 46 in epoch 3, gen_loss = 0.39294489076796996, disc_loss = 0.11971028117423362
Trained batch 47 in epoch 3, gen_loss = 0.39493753761053085, disc_loss = 0.12050032367308934
Trained batch 48 in epoch 3, gen_loss = 0.39382768832907383, disc_loss = 0.12511992515349873
Trained batch 49 in epoch 3, gen_loss = 0.3944653540849686, disc_loss = 0.12521332621574402
Trained batch 50 in epoch 3, gen_loss = 0.39572805166244507, disc_loss = 0.12486563345380858
Trained batch 51 in epoch 3, gen_loss = 0.3943051506693547, disc_loss = 0.12594101277108377
Trained batch 52 in epoch 3, gen_loss = 0.3964749456576581, disc_loss = 0.12456709652576807
Trained batch 53 in epoch 3, gen_loss = 0.3988709157263791, disc_loss = 0.12757813930511475
Trained batch 54 in epoch 3, gen_loss = 0.3975055781277743, disc_loss = 0.12691876888275147
Trained batch 55 in epoch 3, gen_loss = 0.39622590956943377, disc_loss = 0.129184007112469
Trained batch 56 in epoch 3, gen_loss = 0.39571007458787216, disc_loss = 0.12975917050712987
Trained batch 57 in epoch 3, gen_loss = 0.395302279755987, disc_loss = 0.12822479452809382
Trained batch 58 in epoch 3, gen_loss = 0.39394459380941876, disc_loss = 0.1293040908620519
Trained batch 59 in epoch 3, gen_loss = 0.3932953099409739, disc_loss = 0.13085794231543937
Trained batch 60 in epoch 3, gen_loss = 0.3935731966964534, disc_loss = 0.12961154547138293
Trained batch 61 in epoch 3, gen_loss = 0.3937691858699245, disc_loss = 0.13060710921643243
Trained batch 62 in epoch 3, gen_loss = 0.3953307999504937, disc_loss = 0.13165734643264423
Trained batch 63 in epoch 3, gen_loss = 0.39545038994401693, disc_loss = 0.1316962293931283
Trained batch 64 in epoch 3, gen_loss = 0.3945202451485854, disc_loss = 0.1316676789178298
Trained batch 65 in epoch 3, gen_loss = 0.3946195944692149, disc_loss = 0.1311123769053004
Trained batch 66 in epoch 3, gen_loss = 0.39468022380302203, disc_loss = 0.13063270326203374
Trained batch 67 in epoch 3, gen_loss = 0.3943079806425992, disc_loss = 0.12916905339807272
Trained batch 68 in epoch 3, gen_loss = 0.3952637591223786, disc_loss = 0.1284025364919849
Trained batch 69 in epoch 3, gen_loss = 0.39487883406026025, disc_loss = 0.12856245738055025
Trained batch 70 in epoch 3, gen_loss = 0.3952055493710746, disc_loss = 0.12820814943439524
Trained batch 71 in epoch 3, gen_loss = 0.39589035511016846, disc_loss = 0.12739232901690734
Trained batch 72 in epoch 3, gen_loss = 0.39685304605797544, disc_loss = 0.125866294519542
Trained batch 73 in epoch 3, gen_loss = 0.3962716287052309, disc_loss = 0.12527222679676236
Trained batch 74 in epoch 3, gen_loss = 0.39634831229845685, disc_loss = 0.12597314029932022
Trained batch 75 in epoch 3, gen_loss = 0.39780281837049286, disc_loss = 0.1301477036782001
Trained batch 76 in epoch 3, gen_loss = 0.39663693966803615, disc_loss = 0.13022637028585782
Trained batch 77 in epoch 3, gen_loss = 0.3951157533969635, disc_loss = 0.13387536018704757
Trained batch 78 in epoch 3, gen_loss = 0.39455586634104767, disc_loss = 0.13339105578540247
Trained batch 79 in epoch 3, gen_loss = 0.395413001999259, disc_loss = 0.13257750179618596
Trained batch 80 in epoch 3, gen_loss = 0.3959393295240991, disc_loss = 0.1326626620174926
Trained batch 81 in epoch 3, gen_loss = 0.396026479034889, disc_loss = 0.13156282829075325
Trained batch 82 in epoch 3, gen_loss = 0.39586788667253703, disc_loss = 0.13051309669951358
Trained batch 83 in epoch 3, gen_loss = 0.39537638674179715, disc_loss = 0.13057671975167023
Trained batch 84 in epoch 3, gen_loss = 0.39413749785984264, disc_loss = 0.1301965991363806
Trained batch 85 in epoch 3, gen_loss = 0.39364649286103803, disc_loss = 0.1308196487641612
Trained batch 86 in epoch 3, gen_loss = 0.39389342172392483, disc_loss = 0.1332011499452865
Trained batch 87 in epoch 3, gen_loss = 0.39320494336160744, disc_loss = 0.13499522708695044
Trained batch 88 in epoch 3, gen_loss = 0.39253670412502933, disc_loss = 0.13774890770738044
Trained batch 89 in epoch 3, gen_loss = 0.39243724313047196, disc_loss = 0.13702157446079785
Trained batch 90 in epoch 3, gen_loss = 0.39239027834200596, disc_loss = 0.13745982412781035
Trained batch 91 in epoch 3, gen_loss = 0.3925018362377001, disc_loss = 0.13693350342952687
Trained batch 92 in epoch 3, gen_loss = 0.39187693852250294, disc_loss = 0.1367208277506213
Trained batch 93 in epoch 3, gen_loss = 0.39145785601849253, disc_loss = 0.1364595756093238
Trained batch 94 in epoch 3, gen_loss = 0.3919131282128786, disc_loss = 0.13660127920539755
Trained batch 95 in epoch 3, gen_loss = 0.39245847643663484, disc_loss = 0.13599849639770886
Trained batch 96 in epoch 3, gen_loss = 0.3919000671696417, disc_loss = 0.13601049312303976
Trained batch 97 in epoch 3, gen_loss = 0.39170339490686146, disc_loss = 0.13547241733390458
Trained batch 98 in epoch 3, gen_loss = 0.3912339291789315, disc_loss = 0.13515838574279437
Trained batch 99 in epoch 3, gen_loss = 0.3907180252671242, disc_loss = 0.13696589663624764
Trained batch 100 in epoch 3, gen_loss = 0.39058650543194007, disc_loss = 0.13780569115487656
Trained batch 101 in epoch 3, gen_loss = 0.3900917204571705, disc_loss = 0.1378959486005353
Trained batch 102 in epoch 3, gen_loss = 0.39018837948447294, disc_loss = 0.13744494210458497
Trained batch 103 in epoch 3, gen_loss = 0.389627107920555, disc_loss = 0.13729970536839503
Trained batch 104 in epoch 3, gen_loss = 0.3890802743889037, disc_loss = 0.13682727338302703
Trained batch 105 in epoch 3, gen_loss = 0.3878902382445785, disc_loss = 0.13719033386628582
Trained batch 106 in epoch 3, gen_loss = 0.38803891656554745, disc_loss = 0.13770299140259484
Trained batch 107 in epoch 3, gen_loss = 0.38906735678513843, disc_loss = 0.1389170257995526
Trained batch 108 in epoch 3, gen_loss = 0.3896873524976433, disc_loss = 0.13870310557818194
Trained batch 109 in epoch 3, gen_loss = 0.3893360907381231, disc_loss = 0.13848133744163946
Trained batch 110 in epoch 3, gen_loss = 0.38893094551455865, disc_loss = 0.1385300928005227
Trained batch 111 in epoch 3, gen_loss = 0.3896473433290209, disc_loss = 0.13833848353741424
Trained batch 112 in epoch 3, gen_loss = 0.3893681537788526, disc_loss = 0.13805285458807395
Trained batch 113 in epoch 3, gen_loss = 0.3880586435920314, disc_loss = 0.13800448041997457
Trained batch 114 in epoch 3, gen_loss = 0.3883225881535074, disc_loss = 0.13761589352203452
Trained batch 115 in epoch 3, gen_loss = 0.3884585502332655, disc_loss = 0.13784567915416998
Trained batch 116 in epoch 3, gen_loss = 0.3879729185858343, disc_loss = 0.13788097479149827
Trained batch 117 in epoch 3, gen_loss = 0.38842313749305274, disc_loss = 0.13752304074370256
Trained batch 118 in epoch 3, gen_loss = 0.3881418589784318, disc_loss = 0.13659391246986488
Trained batch 119 in epoch 3, gen_loss = 0.3879503679772218, disc_loss = 0.1366213883118083
Trained batch 120 in epoch 3, gen_loss = 0.38827775923673774, disc_loss = 0.1360991102266164
Trained batch 121 in epoch 3, gen_loss = 0.38802059141338846, disc_loss = 0.13553607477577495
Trained batch 122 in epoch 3, gen_loss = 0.3886955491895598, disc_loss = 0.13509757055075672
Trained batch 123 in epoch 3, gen_loss = 0.389130093637974, disc_loss = 0.1348521442212645
Trained batch 124 in epoch 3, gen_loss = 0.3892037615776062, disc_loss = 0.13475649632513523
Trained batch 125 in epoch 3, gen_loss = 0.38979862654019914, disc_loss = 0.13435567993788966
Trained batch 126 in epoch 3, gen_loss = 0.39032142932020775, disc_loss = 0.13385162521593683
Trained batch 127 in epoch 3, gen_loss = 0.38972930144518614, disc_loss = 0.13359572809713427
Trained batch 128 in epoch 3, gen_loss = 0.38891424319540807, disc_loss = 0.13376995368117048
Trained batch 129 in epoch 3, gen_loss = 0.38982998041006234, disc_loss = 0.13289359402484618
Trained batch 130 in epoch 3, gen_loss = 0.39062951721307887, disc_loss = 0.1325761670858123
Trained batch 131 in epoch 3, gen_loss = 0.3902641184853785, disc_loss = 0.13215637191509208
Trained batch 132 in epoch 3, gen_loss = 0.3901155673919764, disc_loss = 0.13244672317085857
Trained batch 133 in epoch 3, gen_loss = 0.3896138221025467, disc_loss = 0.13177809907373653
Trained batch 134 in epoch 3, gen_loss = 0.38912671274609034, disc_loss = 0.1313764207754974
Trained batch 135 in epoch 3, gen_loss = 0.38973794395432754, disc_loss = 0.1306788070976515
Trained batch 136 in epoch 3, gen_loss = 0.3895563857398764, disc_loss = 0.13087481117542207
Trained batch 137 in epoch 3, gen_loss = 0.3888769946668459, disc_loss = 0.13136103477976893
Trained batch 138 in epoch 3, gen_loss = 0.38861002210232853, disc_loss = 0.13101540418783966
Trained batch 139 in epoch 3, gen_loss = 0.38911938454423634, disc_loss = 0.13066775334466782
Trained batch 140 in epoch 3, gen_loss = 0.3896135254531887, disc_loss = 0.13016410070266707
Trained batch 141 in epoch 3, gen_loss = 0.3897329734664568, disc_loss = 0.12950277941065355
Trained batch 142 in epoch 3, gen_loss = 0.3891752572743209, disc_loss = 0.130252388742316
Trained batch 143 in epoch 3, gen_loss = 0.389359751302335, disc_loss = 0.1302233274586292
Trained batch 144 in epoch 3, gen_loss = 0.38924309467447216, disc_loss = 0.12972359152446533
Trained batch 145 in epoch 3, gen_loss = 0.38879039393712395, disc_loss = 0.13007975174496844
Trained batch 146 in epoch 3, gen_loss = 0.3892162809161102, disc_loss = 0.12945736292116092
Trained batch 147 in epoch 3, gen_loss = 0.3897832593805081, disc_loss = 0.13077658078809445
Trained batch 148 in epoch 3, gen_loss = 0.3898479906504586, disc_loss = 0.1302163685053187
Trained batch 149 in epoch 3, gen_loss = 0.3900579982995987, disc_loss = 0.13107990007847548
Trained batch 150 in epoch 3, gen_loss = 0.39028185073113597, disc_loss = 0.1319033448393179
Trained batch 151 in epoch 3, gen_loss = 0.3907634655111714, disc_loss = 0.13130588183718683
Trained batch 152 in epoch 3, gen_loss = 0.391027252268947, disc_loss = 0.1308928173571046
Trained batch 153 in epoch 3, gen_loss = 0.39083652817583703, disc_loss = 0.13057311436814534
Trained batch 154 in epoch 3, gen_loss = 0.39053551496997957, disc_loss = 0.13006098908522437
Trained batch 155 in epoch 3, gen_loss = 0.39049206387538177, disc_loss = 0.12999406441425285
Trained batch 156 in epoch 3, gen_loss = 0.3902181992485265, disc_loss = 0.13062252297665283
Trained batch 157 in epoch 3, gen_loss = 0.39063194903391824, disc_loss = 0.12999413118850958
Trained batch 158 in epoch 3, gen_loss = 0.39055079409161453, disc_loss = 0.12988473811192708
Trained batch 159 in epoch 3, gen_loss = 0.39036786630749704, disc_loss = 0.12981724914861842
Trained batch 160 in epoch 3, gen_loss = 0.3901962969243897, disc_loss = 0.1294099616222315
Trained batch 161 in epoch 3, gen_loss = 0.39086282786763743, disc_loss = 0.1289140420080519
Trained batch 162 in epoch 3, gen_loss = 0.39074789435585583, disc_loss = 0.12908368414850688
Trained batch 163 in epoch 3, gen_loss = 0.3899994161797733, disc_loss = 0.13043612958409073
Trained batch 164 in epoch 3, gen_loss = 0.39007112781206765, disc_loss = 0.1304540043414542
Trained batch 165 in epoch 3, gen_loss = 0.39014215013348913, disc_loss = 0.1307003730459206
Trained batch 166 in epoch 3, gen_loss = 0.3899772226096627, disc_loss = 0.1309189845411899
Trained batch 167 in epoch 3, gen_loss = 0.3904238346786726, disc_loss = 0.13064785606582605
Trained batch 168 in epoch 3, gen_loss = 0.39052768677649413, disc_loss = 0.13071290957989426
Trained batch 169 in epoch 3, gen_loss = 0.3903642587801989, disc_loss = 0.13103834560469668
Trained batch 170 in epoch 3, gen_loss = 0.3904301233110372, disc_loss = 0.1311590690165758
Trained batch 171 in epoch 3, gen_loss = 0.3905438170876614, disc_loss = 0.1307035410278585
Trained batch 172 in epoch 3, gen_loss = 0.39029601233543, disc_loss = 0.1307288795343541
Trained batch 173 in epoch 3, gen_loss = 0.3899320972034301, disc_loss = 0.13136117694492655
Trained batch 174 in epoch 3, gen_loss = 0.3902109319823129, disc_loss = 0.13096477943871704
Trained batch 175 in epoch 3, gen_loss = 0.3901253550906073, disc_loss = 0.1308783870296214
Trained batch 176 in epoch 3, gen_loss = 0.3909073972095877, disc_loss = 0.1303562709146132
Trained batch 177 in epoch 3, gen_loss = 0.3911908633923263, disc_loss = 0.13027626651684554
Trained batch 178 in epoch 3, gen_loss = 0.39144028698265887, disc_loss = 0.1298390950216761
Trained batch 179 in epoch 3, gen_loss = 0.39152538826068245, disc_loss = 0.12998287929221988
Trained batch 180 in epoch 3, gen_loss = 0.3918130979024244, disc_loss = 0.13017283613634043
Trained batch 181 in epoch 3, gen_loss = 0.39191892202738876, disc_loss = 0.12972340817757688
Trained batch 182 in epoch 3, gen_loss = 0.39238888676700695, disc_loss = 0.13030133020804555
Trained batch 183 in epoch 3, gen_loss = 0.3928234024864176, disc_loss = 0.1296641198290593
Trained batch 184 in epoch 3, gen_loss = 0.3924075975611403, disc_loss = 0.130356843417158
Trained batch 185 in epoch 3, gen_loss = 0.3922887768155785, disc_loss = 0.12973449241009452
Trained batch 186 in epoch 3, gen_loss = 0.3925556046440002, disc_loss = 0.12939008709820196
Trained batch 187 in epoch 3, gen_loss = 0.3923136301814242, disc_loss = 0.12903076521259674
Trained batch 188 in epoch 3, gen_loss = 0.391806088269703, disc_loss = 0.129091671534947
Trained batch 189 in epoch 3, gen_loss = 0.39185410910531093, disc_loss = 0.12943811197029917
Trained batch 190 in epoch 3, gen_loss = 0.391902706229874, disc_loss = 0.12929113217049243
Trained batch 191 in epoch 3, gen_loss = 0.39185565104708076, disc_loss = 0.1290768045000732
Trained batch 192 in epoch 3, gen_loss = 0.39187228772306687, disc_loss = 0.12870221473083596
Trained batch 193 in epoch 3, gen_loss = 0.39153194028077665, disc_loss = 0.12893789092597274
Trained batch 194 in epoch 3, gen_loss = 0.39152173201243085, disc_loss = 0.12854682652231975
Trained batch 195 in epoch 3, gen_loss = 0.39195864784474277, disc_loss = 0.1280093558740859
Trained batch 196 in epoch 3, gen_loss = 0.39230380642232554, disc_loss = 0.12766369226090798
Trained batch 197 in epoch 3, gen_loss = 0.39200113683637944, disc_loss = 0.12746708285101135
Trained batch 198 in epoch 3, gen_loss = 0.39232352510768564, disc_loss = 0.12711884888197908
Trained batch 199 in epoch 3, gen_loss = 0.3925992080569267, disc_loss = 0.1266051425971091
Trained batch 200 in epoch 3, gen_loss = 0.3926722054457783, disc_loss = 0.12621123097206824
Trained batch 201 in epoch 3, gen_loss = 0.39262522063633004, disc_loss = 0.12582449821552427
Trained batch 202 in epoch 3, gen_loss = 0.3922727015511743, disc_loss = 0.1253352981115797
Trained batch 203 in epoch 3, gen_loss = 0.39201250438596685, disc_loss = 0.12491850823383122
Trained batch 204 in epoch 3, gen_loss = 0.3923628664598232, disc_loss = 0.12437768049719856
Trained batch 205 in epoch 3, gen_loss = 0.3920363741881639, disc_loss = 0.124035926427222
Trained batch 206 in epoch 3, gen_loss = 0.3924353266683754, disc_loss = 0.12357469243199928
Trained batch 207 in epoch 3, gen_loss = 0.39258650016899294, disc_loss = 0.1232790442971656
Trained batch 208 in epoch 3, gen_loss = 0.393124321573659, disc_loss = 0.12305971972965167
Trained batch 209 in epoch 3, gen_loss = 0.3935986699092956, disc_loss = 0.12275584201727595
Trained batch 210 in epoch 3, gen_loss = 0.3938754658563442, disc_loss = 0.1224451477670274
Trained batch 211 in epoch 3, gen_loss = 0.39391736658114307, disc_loss = 0.1221139341206202
Trained batch 212 in epoch 3, gen_loss = 0.39391700720563183, disc_loss = 0.12160987554756408
Trained batch 213 in epoch 3, gen_loss = 0.39426026820579424, disc_loss = 0.1210938093435263
Trained batch 214 in epoch 3, gen_loss = 0.3942126107770343, disc_loss = 0.1206867154427739
Trained batch 215 in epoch 3, gen_loss = 0.3937713059562224, disc_loss = 0.12046248546836001
Trained batch 216 in epoch 3, gen_loss = 0.3938506698828139, disc_loss = 0.12053229434904965
Trained batch 217 in epoch 3, gen_loss = 0.39381564032593996, disc_loss = 0.12027789049123952
Trained batch 218 in epoch 3, gen_loss = 0.39412836900584775, disc_loss = 0.11981627851146269
Trained batch 219 in epoch 3, gen_loss = 0.3943668419664556, disc_loss = 0.11933506762778218
Trained batch 220 in epoch 3, gen_loss = 0.3944988099698028, disc_loss = 0.11891051795653898
Trained batch 221 in epoch 3, gen_loss = 0.39462384286227525, disc_loss = 0.11843011167470936
Trained batch 222 in epoch 3, gen_loss = 0.39456615292972513, disc_loss = 0.11822097389353231
Trained batch 223 in epoch 3, gen_loss = 0.3949236257800034, disc_loss = 0.11794780721954469
Trained batch 224 in epoch 3, gen_loss = 0.395351279841529, disc_loss = 0.11767764798469013
Trained batch 225 in epoch 3, gen_loss = 0.39530457160641663, disc_loss = 0.11719731831989061
Trained batch 226 in epoch 3, gen_loss = 0.3953094093810094, disc_loss = 0.11694430302631618
Trained batch 227 in epoch 3, gen_loss = 0.39555607082550986, disc_loss = 0.11663215434619863
Trained batch 228 in epoch 3, gen_loss = 0.39549554812856114, disc_loss = 0.11650753223365702
Trained batch 229 in epoch 3, gen_loss = 0.3958892901306567, disc_loss = 0.11606817095257017
Trained batch 230 in epoch 3, gen_loss = 0.3957380565988037, disc_loss = 0.11575574568549404
Trained batch 231 in epoch 3, gen_loss = 0.3955018874900094, disc_loss = 0.11536012475523327
Trained batch 232 in epoch 3, gen_loss = 0.39514743092234045, disc_loss = 0.11544842162277437
Trained batch 233 in epoch 3, gen_loss = 0.39529808145812434, disc_loss = 0.11501832194546731
Trained batch 234 in epoch 3, gen_loss = 0.39553967853809924, disc_loss = 0.11516832331631412
Trained batch 235 in epoch 3, gen_loss = 0.39560425900301693, disc_loss = 0.11495409157300779
Trained batch 236 in epoch 3, gen_loss = 0.3954402540303484, disc_loss = 0.11492497687334124
Trained batch 237 in epoch 3, gen_loss = 0.3955828076651116, disc_loss = 0.11472563964839116
Trained batch 238 in epoch 3, gen_loss = 0.39541029281696016, disc_loss = 0.11498669980319848
Trained batch 239 in epoch 3, gen_loss = 0.395144992445906, disc_loss = 0.11568147024372592
Trained batch 240 in epoch 3, gen_loss = 0.39526918072918144, disc_loss = 0.11536600500638926
Trained batch 241 in epoch 3, gen_loss = 0.3954761385425063, disc_loss = 0.1156268143941733
Trained batch 242 in epoch 3, gen_loss = 0.39587037896913757, disc_loss = 0.11531258259091234
Trained batch 243 in epoch 3, gen_loss = 0.3955709098792467, disc_loss = 0.11571789689774274
Trained batch 244 in epoch 3, gen_loss = 0.3956278854486894, disc_loss = 0.11587808975683792
Trained batch 245 in epoch 3, gen_loss = 0.395569375375422, disc_loss = 0.11573421371706981
Trained batch 246 in epoch 3, gen_loss = 0.3952388991469796, disc_loss = 0.11581848149644097
Trained batch 247 in epoch 3, gen_loss = 0.3950314627539727, disc_loss = 0.11566519410905218
Trained batch 248 in epoch 3, gen_loss = 0.3952201080609517, disc_loss = 0.11571609086345837
Trained batch 249 in epoch 3, gen_loss = 0.39529470229148866, disc_loss = 0.11560300968214869
Trained batch 250 in epoch 3, gen_loss = 0.39548022825404466, disc_loss = 0.11564978361649224
Trained batch 251 in epoch 3, gen_loss = 0.395538351956814, disc_loss = 0.11561102453722721
Trained batch 252 in epoch 3, gen_loss = 0.39534908132590796, disc_loss = 0.1153577820696084
Trained batch 253 in epoch 3, gen_loss = 0.395375663722594, disc_loss = 0.11504332047674483
Trained batch 254 in epoch 3, gen_loss = 0.3950346148481556, disc_loss = 0.1150566360347119
Trained batch 255 in epoch 3, gen_loss = 0.3951307591050863, disc_loss = 0.1154636434330314
Trained batch 256 in epoch 3, gen_loss = 0.3951784055752513, disc_loss = 0.11534114354126997
Trained batch 257 in epoch 3, gen_loss = 0.3954140513904335, disc_loss = 0.1151777932225445
Trained batch 258 in epoch 3, gen_loss = 0.3953242323803626, disc_loss = 0.11554190977818142
Trained batch 259 in epoch 3, gen_loss = 0.3957203089044644, disc_loss = 0.11521561410493003
Trained batch 260 in epoch 3, gen_loss = 0.3952786093470694, disc_loss = 0.11520562150740418
Trained batch 261 in epoch 3, gen_loss = 0.39576472353389247, disc_loss = 0.11499428121685867
Trained batch 262 in epoch 3, gen_loss = 0.39605051868315433, disc_loss = 0.1150165043679197
Trained batch 263 in epoch 3, gen_loss = 0.3963754064205921, disc_loss = 0.11511224229947072
Trained batch 264 in epoch 3, gen_loss = 0.39634920459873274, disc_loss = 0.11500736804995335
Trained batch 265 in epoch 3, gen_loss = 0.39637793847044606, disc_loss = 0.11490715539811137
Trained batch 266 in epoch 3, gen_loss = 0.39645897817522396, disc_loss = 0.11481709745869542
Trained batch 267 in epoch 3, gen_loss = 0.3967816322597105, disc_loss = 0.11473709707315177
Trained batch 268 in epoch 3, gen_loss = 0.3970468961616431, disc_loss = 0.11451349196588573
Trained batch 269 in epoch 3, gen_loss = 0.3968816346592373, disc_loss = 0.11425179406931554
Trained batch 270 in epoch 3, gen_loss = 0.39698825287203066, disc_loss = 0.11390127274259321
Trained batch 271 in epoch 3, gen_loss = 0.3972975352012059, disc_loss = 0.11354474182692631
Trained batch 272 in epoch 3, gen_loss = 0.3972467650205661, disc_loss = 0.11328346199345785
Trained batch 273 in epoch 3, gen_loss = 0.3973754784704125, disc_loss = 0.1132702238103171
Trained batch 274 in epoch 3, gen_loss = 0.397172122001648, disc_loss = 0.11414437382397327
Trained batch 275 in epoch 3, gen_loss = 0.39727871983811475, disc_loss = 0.11469169621409821
Trained batch 276 in epoch 3, gen_loss = 0.39713662636839525, disc_loss = 0.11442331543750389
Trained batch 277 in epoch 3, gen_loss = 0.39715903096919436, disc_loss = 0.11442293927890898
Trained batch 278 in epoch 3, gen_loss = 0.39703515802233025, disc_loss = 0.11424417071725412
Trained batch 279 in epoch 3, gen_loss = 0.39706868614469254, disc_loss = 0.11423283825029752
Trained batch 280 in epoch 3, gen_loss = 0.3970095250105943, disc_loss = 0.11404962147324217
Trained batch 281 in epoch 3, gen_loss = 0.39704907458301975, disc_loss = 0.11390637325334317
Trained batch 282 in epoch 3, gen_loss = 0.3969627302863994, disc_loss = 0.11372925474410449
Trained batch 283 in epoch 3, gen_loss = 0.39693165790866797, disc_loss = 0.1135800591715887
Trained batch 284 in epoch 3, gen_loss = 0.39682192394607946, disc_loss = 0.11420728393356529
Trained batch 285 in epoch 3, gen_loss = 0.39661506808304287, disc_loss = 0.11452521348919173
Trained batch 286 in epoch 3, gen_loss = 0.3965531910545735, disc_loss = 0.11420208096621032
Trained batch 287 in epoch 3, gen_loss = 0.3966152373080452, disc_loss = 0.11411595127558233
Trained batch 288 in epoch 3, gen_loss = 0.39676981865328487, disc_loss = 0.11380674704509726
Trained batch 289 in epoch 3, gen_loss = 0.39668416843332094, disc_loss = 0.11360599432333277
Trained batch 290 in epoch 3, gen_loss = 0.3968251966119222, disc_loss = 0.11326654933559424
Trained batch 291 in epoch 3, gen_loss = 0.3965041132210052, disc_loss = 0.11309719968217183
Trained batch 292 in epoch 3, gen_loss = 0.3964543371070367, disc_loss = 0.11286657889383137
Trained batch 293 in epoch 3, gen_loss = 0.3966994484265645, disc_loss = 0.11270682643908932
Trained batch 294 in epoch 3, gen_loss = 0.39653601757550644, disc_loss = 0.11250411687197827
Trained batch 295 in epoch 3, gen_loss = 0.3970451641928505, disc_loss = 0.11218959104735404
Trained batch 296 in epoch 3, gen_loss = 0.3972177109132311, disc_loss = 0.11207382237030701
Trained batch 297 in epoch 3, gen_loss = 0.3971901325971488, disc_loss = 0.11185179982371879
Trained batch 298 in epoch 3, gen_loss = 0.3971822766157297, disc_loss = 0.11175819724661151
Trained batch 299 in epoch 3, gen_loss = 0.3974620258808136, disc_loss = 0.11153199639481803
Trained batch 300 in epoch 3, gen_loss = 0.3974642774393392, disc_loss = 0.11118186968363253
Trained batch 301 in epoch 3, gen_loss = 0.39759252965450287, disc_loss = 0.11083613829502206
Trained batch 302 in epoch 3, gen_loss = 0.39770657837194184, disc_loss = 0.11064947378074769
Trained batch 303 in epoch 3, gen_loss = 0.3977738128680932, disc_loss = 0.11060169472751256
Trained batch 304 in epoch 3, gen_loss = 0.39761194303387504, disc_loss = 0.11030103905034847
Trained batch 305 in epoch 3, gen_loss = 0.3975104302947038, disc_loss = 0.11034634562050985
Trained batch 306 in epoch 3, gen_loss = 0.3972778709587134, disc_loss = 0.11067842309900137
Trained batch 307 in epoch 3, gen_loss = 0.39695555436146723, disc_loss = 0.11060711195958513
Trained batch 308 in epoch 3, gen_loss = 0.39694341708541303, disc_loss = 0.11033779831187239
Trained batch 309 in epoch 3, gen_loss = 0.39711691814084205, disc_loss = 0.110230514791704
Trained batch 310 in epoch 3, gen_loss = 0.39680948843909997, disc_loss = 0.1100826311820573
Trained batch 311 in epoch 3, gen_loss = 0.3967804560103478, disc_loss = 0.10983903592643447
Trained batch 312 in epoch 3, gen_loss = 0.39703483274950385, disc_loss = 0.10985114005284187
Trained batch 313 in epoch 3, gen_loss = 0.39671262870928287, disc_loss = 0.10965323446994754
Trained batch 314 in epoch 3, gen_loss = 0.39685046956652686, disc_loss = 0.10942042530292556
Trained batch 315 in epoch 3, gen_loss = 0.3970330363210243, disc_loss = 0.10911469554375339
Trained batch 316 in epoch 3, gen_loss = 0.3971039530606676, disc_loss = 0.1089825338422547
Trained batch 317 in epoch 3, gen_loss = 0.3969249612880203, disc_loss = 0.10873534260083388
Trained batch 318 in epoch 3, gen_loss = 0.39732916153336767, disc_loss = 0.10851300188097927
Trained batch 319 in epoch 3, gen_loss = 0.39761984050273896, disc_loss = 0.10824385498126503
Trained batch 320 in epoch 3, gen_loss = 0.39756439667995846, disc_loss = 0.1079705298973996
Trained batch 321 in epoch 3, gen_loss = 0.3976543880767704, disc_loss = 0.10785811891062011
Trained batch 322 in epoch 3, gen_loss = 0.3974966177076747, disc_loss = 0.10799743734796073
Trained batch 323 in epoch 3, gen_loss = 0.3976344183823209, disc_loss = 0.10796597325473012
Trained batch 324 in epoch 3, gen_loss = 0.3976711008181939, disc_loss = 0.10772345952403087
Trained batch 325 in epoch 3, gen_loss = 0.3975226147774538, disc_loss = 0.10821112466153283
Trained batch 326 in epoch 3, gen_loss = 0.39764098344592874, disc_loss = 0.10805032718129205
Trained batch 327 in epoch 3, gen_loss = 0.39775962191747455, disc_loss = 0.10778432703156751
Trained batch 328 in epoch 3, gen_loss = 0.39759368410951096, disc_loss = 0.1076612560429517
Trained batch 329 in epoch 3, gen_loss = 0.3977251116073493, disc_loss = 0.10748456476369139
Trained batch 330 in epoch 3, gen_loss = 0.39796470443287646, disc_loss = 0.10721637364026733
Trained batch 331 in epoch 3, gen_loss = 0.3980409708547305, disc_loss = 0.10699328829826091
Trained batch 332 in epoch 3, gen_loss = 0.39820622637107206, disc_loss = 0.10675928731904821
Trained batch 333 in epoch 3, gen_loss = 0.39829721350869735, disc_loss = 0.10649334376365571
Trained batch 334 in epoch 3, gen_loss = 0.3982327120517617, disc_loss = 0.1062794386033914
Trained batch 335 in epoch 3, gen_loss = 0.3982767697778486, disc_loss = 0.10604534788511782
Trained batch 336 in epoch 3, gen_loss = 0.3984370766655274, disc_loss = 0.10576263461427801
Trained batch 337 in epoch 3, gen_loss = 0.3985001634387575, disc_loss = 0.1056298203766346
Trained batch 338 in epoch 3, gen_loss = 0.3983568060362937, disc_loss = 0.1057635058915369
Trained batch 339 in epoch 3, gen_loss = 0.3986080469454036, disc_loss = 0.10568326128756299
Trained batch 340 in epoch 3, gen_loss = 0.3988169763794393, disc_loss = 0.10541880228269922
Trained batch 341 in epoch 3, gen_loss = 0.39869004993410834, disc_loss = 0.10514137533095758
Trained batch 342 in epoch 3, gen_loss = 0.39870499982430707, disc_loss = 0.10487283458363036
Trained batch 343 in epoch 3, gen_loss = 0.39875970720205195, disc_loss = 0.10466309940594054
Trained batch 344 in epoch 3, gen_loss = 0.3988132299720377, disc_loss = 0.10440245571721724
Trained batch 345 in epoch 3, gen_loss = 0.398785369330748, disc_loss = 0.10415843258089671
Trained batch 346 in epoch 3, gen_loss = 0.39877045558234114, disc_loss = 0.10391262686551046
Trained batch 347 in epoch 3, gen_loss = 0.3989130026478877, disc_loss = 0.10365061686995129
Trained batch 348 in epoch 3, gen_loss = 0.39874543441742405, disc_loss = 0.10342445783583944
Trained batch 349 in epoch 3, gen_loss = 0.39890274260725295, disc_loss = 0.10317783863682832
Trained batch 350 in epoch 3, gen_loss = 0.39914003277775906, disc_loss = 0.10297112711081732
Trained batch 351 in epoch 3, gen_loss = 0.3991288353943012, disc_loss = 0.10278956700825471
Trained batch 352 in epoch 3, gen_loss = 0.3990657588746663, disc_loss = 0.1025758615745068
Trained batch 353 in epoch 3, gen_loss = 0.3991330334190595, disc_loss = 0.10235149974508559
Trained batch 354 in epoch 3, gen_loss = 0.399054207852189, disc_loss = 0.10220542255474228
Trained batch 355 in epoch 3, gen_loss = 0.3988527057043622, disc_loss = 0.1026122982671296
Trained batch 356 in epoch 3, gen_loss = 0.3990524702546309, disc_loss = 0.10258782359951434
Trained batch 357 in epoch 3, gen_loss = 0.3990034222103364, disc_loss = 0.10242560680945242
Trained batch 358 in epoch 3, gen_loss = 0.3988968395423092, disc_loss = 0.10220983950032082
Trained batch 359 in epoch 3, gen_loss = 0.3984910514619615, disc_loss = 0.10220113760636498
Trained batch 360 in epoch 3, gen_loss = 0.3984873832262784, disc_loss = 0.10228704369866864
Trained batch 361 in epoch 3, gen_loss = 0.39869987124896183, disc_loss = 0.1020329839097161
Trained batch 362 in epoch 3, gen_loss = 0.3986925646129062, disc_loss = 0.10206858550785905
Trained batch 363 in epoch 3, gen_loss = 0.3988118799669402, disc_loss = 0.101825994615965
Trained batch 364 in epoch 3, gen_loss = 0.3989742911025269, disc_loss = 0.10162830259140632
Trained batch 365 in epoch 3, gen_loss = 0.39886305770261693, disc_loss = 0.10151431504178976
Trained batch 366 in epoch 3, gen_loss = 0.3987874490201311, disc_loss = 0.10161026859813312
Trained batch 367 in epoch 3, gen_loss = 0.3989128423449786, disc_loss = 0.1017264457971222
Trained batch 368 in epoch 3, gen_loss = 0.3989020434175403, disc_loss = 0.10191619838651038
Trained batch 369 in epoch 3, gen_loss = 0.39935625324378143, disc_loss = 0.1017351669964154
Trained batch 370 in epoch 3, gen_loss = 0.399471399115745, disc_loss = 0.10173362904451687
Trained batch 371 in epoch 3, gen_loss = 0.3993277423163896, disc_loss = 0.10166907175544208
Trained batch 372 in epoch 3, gen_loss = 0.39922284169107597, disc_loss = 0.10145202011678957
Trained batch 373 in epoch 3, gen_loss = 0.3991177138638369, disc_loss = 0.10170327708931928
Trained batch 374 in epoch 3, gen_loss = 0.39900645025571185, disc_loss = 0.10195178413639466
Trained batch 375 in epoch 3, gen_loss = 0.399237342733652, disc_loss = 0.10179592985313068
Trained batch 376 in epoch 3, gen_loss = 0.39925455169589197, disc_loss = 0.10170310021523851
Trained batch 377 in epoch 3, gen_loss = 0.39902393062594077, disc_loss = 0.10156283130691875
Trained batch 378 in epoch 3, gen_loss = 0.3990706579666339, disc_loss = 0.1014176158155843
Trained batch 379 in epoch 3, gen_loss = 0.3989302156002898, disc_loss = 0.10141136868072576
Trained batch 380 in epoch 3, gen_loss = 0.3991043031841438, disc_loss = 0.10119243248505151
Trained batch 381 in epoch 3, gen_loss = 0.39903472512180266, disc_loss = 0.10101617046470963
Trained batch 382 in epoch 3, gen_loss = 0.39909874715942006, disc_loss = 0.10082542046894838
Trained batch 383 in epoch 3, gen_loss = 0.3990071308799088, disc_loss = 0.10067706767343527
Trained batch 384 in epoch 3, gen_loss = 0.3990614704497449, disc_loss = 0.10049791750921444
Trained batch 385 in epoch 3, gen_loss = 0.3991305543196634, disc_loss = 0.10035842100949717
Trained batch 386 in epoch 3, gen_loss = 0.39932968688873666, disc_loss = 0.10013393631556314
Trained batch 387 in epoch 3, gen_loss = 0.3996339333579712, disc_loss = 0.09992877477251914
Trained batch 388 in epoch 3, gen_loss = 0.3995135081764358, disc_loss = 0.09976455448362928
Trained batch 389 in epoch 3, gen_loss = 0.39964202489608375, disc_loss = 0.09984157098552737
Trained batch 390 in epoch 3, gen_loss = 0.3996491038128543, disc_loss = 0.09995588768616585
Trained batch 391 in epoch 3, gen_loss = 0.3996327626613938, disc_loss = 0.09989366237292713
Trained batch 392 in epoch 3, gen_loss = 0.39973592128765795, disc_loss = 0.09994651716316247
Trained batch 393 in epoch 3, gen_loss = 0.3999957974035728, disc_loss = 0.09995411977238083
Trained batch 394 in epoch 3, gen_loss = 0.39998460080050213, disc_loss = 0.09979660300467211
Trained batch 395 in epoch 3, gen_loss = 0.39995392818342557, disc_loss = 0.0996011946176301
Trained batch 396 in epoch 3, gen_loss = 0.39999767424778016, disc_loss = 0.09942379271287836
Trained batch 397 in epoch 3, gen_loss = 0.3999495409691154, disc_loss = 0.0995640412520561
Trained batch 398 in epoch 3, gen_loss = 0.40029364951272356, disc_loss = 0.09939469301134796
Trained batch 399 in epoch 3, gen_loss = 0.4004012017697096, disc_loss = 0.09947242160560563
Trained batch 400 in epoch 3, gen_loss = 0.40038594625834517, disc_loss = 0.09934202294815285
Trained batch 401 in epoch 3, gen_loss = 0.40038533130688453, disc_loss = 0.09920970547193689
Trained batch 402 in epoch 3, gen_loss = 0.40038191399562445, disc_loss = 0.09899646637928915
Trained batch 403 in epoch 3, gen_loss = 0.4002819853548956, disc_loss = 0.09931424812247774
Trained batch 404 in epoch 3, gen_loss = 0.40016700934480737, disc_loss = 0.09982662987147953
Trained batch 405 in epoch 3, gen_loss = 0.40032076813610906, disc_loss = 0.0996649437492227
Trained batch 406 in epoch 3, gen_loss = 0.40024102378535914, disc_loss = 0.0994603615780464
Trained batch 407 in epoch 3, gen_loss = 0.4003323032429405, disc_loss = 0.09937655677626311
Trained batch 408 in epoch 3, gen_loss = 0.40026703797517604, disc_loss = 0.09935493878610341
Trained batch 409 in epoch 3, gen_loss = 0.4001771993753387, disc_loss = 0.09926281991392011
Trained batch 410 in epoch 3, gen_loss = 0.4002708700596561, disc_loss = 0.09906899754791872
Trained batch 411 in epoch 3, gen_loss = 0.4003640153599017, disc_loss = 0.09903491624558652
Trained batch 412 in epoch 3, gen_loss = 0.40025348719615333, disc_loss = 0.09905530717765088
Trained batch 413 in epoch 3, gen_loss = 0.4000691148106027, disc_loss = 0.09890362249399369
Trained batch 414 in epoch 3, gen_loss = 0.40010529770908587, disc_loss = 0.0987852146265557
Trained batch 415 in epoch 3, gen_loss = 0.4002397136332897, disc_loss = 0.09860016069545124
Trained batch 416 in epoch 3, gen_loss = 0.4003872609824585, disc_loss = 0.09843298259282784
Trained batch 417 in epoch 3, gen_loss = 0.4002701982356715, disc_loss = 0.09833347951351669
Trained batch 418 in epoch 3, gen_loss = 0.40040538070594495, disc_loss = 0.09826323026146624
Trained batch 419 in epoch 3, gen_loss = 0.40040190262453895, disc_loss = 0.09839712525717914
Trained batch 420 in epoch 3, gen_loss = 0.4006476141777854, disc_loss = 0.09840573061416877
Trained batch 421 in epoch 3, gen_loss = 0.40060372007966605, disc_loss = 0.09820028396888296
Trained batch 422 in epoch 3, gen_loss = 0.4004223852574684, disc_loss = 0.09805122259828146
Trained batch 423 in epoch 3, gen_loss = 0.4003568377416089, disc_loss = 0.09796099772211164
Trained batch 424 in epoch 3, gen_loss = 0.4003429455616895, disc_loss = 0.09795640380724388
Trained batch 425 in epoch 3, gen_loss = 0.40036363745799086, disc_loss = 0.09779424969535408
Trained batch 426 in epoch 3, gen_loss = 0.4005710183178234, disc_loss = 0.09773870399418075
Trained batch 427 in epoch 3, gen_loss = 0.4004385263145527, disc_loss = 0.09754038402140489
Trained batch 428 in epoch 3, gen_loss = 0.4004297270363583, disc_loss = 0.09755217404015762
Trained batch 429 in epoch 3, gen_loss = 0.400462555608084, disc_loss = 0.09739485483313369
Trained batch 430 in epoch 3, gen_loss = 0.4005019189033597, disc_loss = 0.09725471733574455
Trained batch 431 in epoch 3, gen_loss = 0.40055887235535514, disc_loss = 0.09706427148301844
Trained batch 432 in epoch 3, gen_loss = 0.4005894038748796, disc_loss = 0.09697976314374536
Trained batch 433 in epoch 3, gen_loss = 0.4004607487658751, disc_loss = 0.09735031692045075
Trained batch 434 in epoch 3, gen_loss = 0.4008084223188203, disc_loss = 0.09805143049051021
Trained batch 435 in epoch 3, gen_loss = 0.4007759456514218, disc_loss = 0.09796664006837191
Trained batch 436 in epoch 3, gen_loss = 0.40079484781084124, disc_loss = 0.09795287431343469
Trained batch 437 in epoch 3, gen_loss = 0.40088755783697244, disc_loss = 0.09803793558076909
Trained batch 438 in epoch 3, gen_loss = 0.4007515708379159, disc_loss = 0.09810297584038118
Trained batch 439 in epoch 3, gen_loss = 0.40056959729303016, disc_loss = 0.09825450082902204
Trained batch 440 in epoch 3, gen_loss = 0.4007093500928814, disc_loss = 0.09809120297600893
Trained batch 441 in epoch 3, gen_loss = 0.4008114803161017, disc_loss = 0.09795293141982404
Trained batch 442 in epoch 3, gen_loss = 0.4008164424659436, disc_loss = 0.0978907717824924
Trained batch 443 in epoch 3, gen_loss = 0.40077246202004924, disc_loss = 0.0979743670118419
Trained batch 444 in epoch 3, gen_loss = 0.40095627930726896, disc_loss = 0.09814177444309331
Trained batch 445 in epoch 3, gen_loss = 0.40068584934478385, disc_loss = 0.09817323849574065
Trained batch 446 in epoch 3, gen_loss = 0.4006528621685318, disc_loss = 0.09802680811792679
Trained batch 447 in epoch 3, gen_loss = 0.40072956016021116, disc_loss = 0.09789322648430243
Trained batch 448 in epoch 3, gen_loss = 0.4008058621517003, disc_loss = 0.09799331614959213
Trained batch 449 in epoch 3, gen_loss = 0.4008786586258147, disc_loss = 0.09824256654414866
Trained batch 450 in epoch 3, gen_loss = 0.4010026589069028, disc_loss = 0.09824801022455328
Trained batch 451 in epoch 3, gen_loss = 0.40106281143637884, disc_loss = 0.09807815206591534
Trained batch 452 in epoch 3, gen_loss = 0.40131987174088857, disc_loss = 0.0979262880701366
Trained batch 453 in epoch 3, gen_loss = 0.40125641725662, disc_loss = 0.09777912236175743
Trained batch 454 in epoch 3, gen_loss = 0.40105352585132303, disc_loss = 0.0975939534625018
Trained batch 455 in epoch 3, gen_loss = 0.4010133855044842, disc_loss = 0.09768651407252867
Trained batch 456 in epoch 3, gen_loss = 0.4007408867388377, disc_loss = 0.09845661941948357
Trained batch 457 in epoch 3, gen_loss = 0.4008651518925829, disc_loss = 0.09837481368324967
Trained batch 458 in epoch 3, gen_loss = 0.40092185977237677, disc_loss = 0.09824373553789065
Trained batch 459 in epoch 3, gen_loss = 0.40106167320324027, disc_loss = 0.09806852317415178
Trained batch 460 in epoch 3, gen_loss = 0.4012673684676661, disc_loss = 0.09793813936533548
Testing Epoch 3

Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.33535394072532654, disc_loss = 0.1083228811621666
Trained batch 1 in epoch 4, gen_loss = 0.42335672676563263, disc_loss = 0.13753050193190575
Trained batch 2 in epoch 4, gen_loss = 0.4029413163661957, disc_loss = 0.13595866908629736
Trained batch 3 in epoch 4, gen_loss = 0.38162241131067276, disc_loss = 0.1361518446356058
Trained batch 4 in epoch 4, gen_loss = 0.37306602001190187, disc_loss = 0.11202204190194606
Trained batch 5 in epoch 4, gen_loss = 0.39278244972229004, disc_loss = 0.0956892656783263
Trained batch 6 in epoch 4, gen_loss = 0.3893316260405949, disc_loss = 0.0861081765698535
Trained batch 7 in epoch 4, gen_loss = 0.3833060897886753, disc_loss = 0.08220819220878184
Trained batch 8 in epoch 4, gen_loss = 0.3795839448769887, disc_loss = 0.0784301735046837
Trained batch 9 in epoch 4, gen_loss = 0.38406982123851774, disc_loss = 0.0754064315930009
Trained batch 10 in epoch 4, gen_loss = 0.3855634033679962, disc_loss = 0.07008190656250174
Trained batch 11 in epoch 4, gen_loss = 0.3922061249613762, disc_loss = 0.07247599524756272
Trained batch 12 in epoch 4, gen_loss = 0.3955080532110654, disc_loss = 0.08677108070025077
Trained batch 13 in epoch 4, gen_loss = 0.39119445426123484, disc_loss = 0.08925174602440425
Trained batch 14 in epoch 4, gen_loss = 0.3972651700178782, disc_loss = 0.08581839948892593
Trained batch 15 in epoch 4, gen_loss = 0.3967149816453457, disc_loss = 0.08323417929932475
Trained batch 16 in epoch 4, gen_loss = 0.404308301561019, disc_loss = 0.07918041478842497
Trained batch 17 in epoch 4, gen_loss = 0.401134204533365, disc_loss = 0.07685131512375341
Trained batch 18 in epoch 4, gen_loss = 0.404841201870065, disc_loss = 0.07360160816460848
Trained batch 19 in epoch 4, gen_loss = 0.407700477540493, disc_loss = 0.07241574632935226
Trained batch 20 in epoch 4, gen_loss = 0.4107001892157963, disc_loss = 0.07104388176507893
Trained batch 21 in epoch 4, gen_loss = 0.41015609150583093, disc_loss = 0.07084835096347061
Trained batch 22 in epoch 4, gen_loss = 0.41143542787303095, disc_loss = 0.06960252360643251
Trained batch 23 in epoch 4, gen_loss = 0.4130656570196152, disc_loss = 0.07057130162138492
Trained batch 24 in epoch 4, gen_loss = 0.4138402283191681, disc_loss = 0.0726431829854846
Trained batch 25 in epoch 4, gen_loss = 0.4150002575837649, disc_loss = 0.07495732100393909
Trained batch 26 in epoch 4, gen_loss = 0.413969858928963, disc_loss = 0.07406052515876514
Trained batch 27 in epoch 4, gen_loss = 0.40886486215250833, disc_loss = 0.07396454320821379
Trained batch 28 in epoch 4, gen_loss = 0.4084886600231302, disc_loss = 0.07680715527385473
Trained batch 29 in epoch 4, gen_loss = 0.40765389502048494, disc_loss = 0.07634061907107631
Trained batch 30 in epoch 4, gen_loss = 0.40368731560245635, disc_loss = 0.07716496177618543
Trained batch 31 in epoch 4, gen_loss = 0.4050250602886081, disc_loss = 0.07579789098235779
Trained batch 32 in epoch 4, gen_loss = 0.4070403268842986, disc_loss = 0.07434669179333882
Trained batch 33 in epoch 4, gen_loss = 0.40834927646552815, disc_loss = 0.07340176915749907
Trained batch 34 in epoch 4, gen_loss = 0.40761847155434744, disc_loss = 0.07415469871567829
Trained batch 35 in epoch 4, gen_loss = 0.4087844640016556, disc_loss = 0.07404453335847291
Trained batch 36 in epoch 4, gen_loss = 0.40894224353738734, disc_loss = 0.07278785283199034
Trained batch 37 in epoch 4, gen_loss = 0.409095057531407, disc_loss = 0.07137432505719755
Trained batch 38 in epoch 4, gen_loss = 0.4091984224625123, disc_loss = 0.07144109720889574
Trained batch 39 in epoch 4, gen_loss = 0.41185773238539697, disc_loss = 0.07631850473117083
Trained batch 40 in epoch 4, gen_loss = 0.41034430338115224, disc_loss = 0.07668593805283308
Trained batch 41 in epoch 4, gen_loss = 0.4086728798491614, disc_loss = 0.07602081676235511
Trained batch 42 in epoch 4, gen_loss = 0.40692251851392347, disc_loss = 0.07649134443856256
Trained batch 43 in epoch 4, gen_loss = 0.4073246568441391, disc_loss = 0.07805620910684494
Trained batch 44 in epoch 4, gen_loss = 0.40540944867663914, disc_loss = 0.07726290505379438
Trained batch 45 in epoch 4, gen_loss = 0.4069530568692995, disc_loss = 0.07999114382445165
Trained batch 46 in epoch 4, gen_loss = 0.40498052125281475, disc_loss = 0.07906676264123079
Trained batch 47 in epoch 4, gen_loss = 0.4041436941673358, disc_loss = 0.07987146473412092
Trained batch 48 in epoch 4, gen_loss = 0.404108035929349, disc_loss = 0.07882114900846263
Trained batch 49 in epoch 4, gen_loss = 0.40273272931575776, disc_loss = 0.07944243377074599
Trained batch 50 in epoch 4, gen_loss = 0.401623244379081, disc_loss = 0.08011184740519407
Trained batch 51 in epoch 4, gen_loss = 0.40152900551374143, disc_loss = 0.0796680362859311
Trained batch 52 in epoch 4, gen_loss = 0.40200433809802216, disc_loss = 0.07861309876349175
Trained batch 53 in epoch 4, gen_loss = 0.40164597608425, disc_loss = 0.07787889364623914
Trained batch 54 in epoch 4, gen_loss = 0.4022672263058749, disc_loss = 0.07699146018448201
Trained batch 55 in epoch 4, gen_loss = 0.4028635929737772, disc_loss = 0.07660528629951711
Trained batch 56 in epoch 4, gen_loss = 0.4021797776222229, disc_loss = 0.07660135847369307
Trained batch 57 in epoch 4, gen_loss = 0.40327122293669604, disc_loss = 0.07969002796593926
Trained batch 58 in epoch 4, gen_loss = 0.4013574416354551, disc_loss = 0.08027907610886682
Trained batch 59 in epoch 4, gen_loss = 0.40085469186306, disc_loss = 0.08003089649913211
Trained batch 60 in epoch 4, gen_loss = 0.40213460511848576, disc_loss = 0.0797330118318806
Trained batch 61 in epoch 4, gen_loss = 0.4029976172793296, disc_loss = 0.0791744279014247
Trained batch 62 in epoch 4, gen_loss = 0.402637503449879, disc_loss = 0.07813466477784373
Trained batch 63 in epoch 4, gen_loss = 0.4029786204919219, disc_loss = 0.07726759834622499
Trained batch 64 in epoch 4, gen_loss = 0.40256421657708974, disc_loss = 0.07666782024674691
Trained batch 65 in epoch 4, gen_loss = 0.4023436276298581, disc_loss = 0.07662764145061374
Trained batch 66 in epoch 4, gen_loss = 0.40233796479097056, disc_loss = 0.07830660599770385
Trained batch 67 in epoch 4, gen_loss = 0.4017235649859204, disc_loss = 0.07857367164893624
Trained batch 68 in epoch 4, gen_loss = 0.40238639625950134, disc_loss = 0.07768747419712768
Trained batch 69 in epoch 4, gen_loss = 0.4018617412873677, disc_loss = 0.07724693187379411
Trained batch 70 in epoch 4, gen_loss = 0.4026333668702085, disc_loss = 0.07673579762676652
Trained batch 71 in epoch 4, gen_loss = 0.402257530639569, disc_loss = 0.0768739955059977
Trained batch 72 in epoch 4, gen_loss = 0.4026245993294128, disc_loss = 0.07611975633883722
Trained batch 73 in epoch 4, gen_loss = 0.40177269118863185, disc_loss = 0.07608608567986537
Trained batch 74 in epoch 4, gen_loss = 0.4030190233389537, disc_loss = 0.07668224591761827
Trained batch 75 in epoch 4, gen_loss = 0.40266767732406916, disc_loss = 0.0768326596283403
Trained batch 76 in epoch 4, gen_loss = 0.4031869053066551, disc_loss = 0.07648656012901625
Trained batch 77 in epoch 4, gen_loss = 0.4049307440335934, disc_loss = 0.07574176044466022
Trained batch 78 in epoch 4, gen_loss = 0.40528507134582425, disc_loss = 0.07501760824241593
Trained batch 79 in epoch 4, gen_loss = 0.40438196547329425, disc_loss = 0.07432652566349134
Trained batch 80 in epoch 4, gen_loss = 0.4036080943949429, disc_loss = 0.07429902516535403
Trained batch 81 in epoch 4, gen_loss = 0.40354899262509697, disc_loss = 0.07437531617129357
Trained batch 82 in epoch 4, gen_loss = 0.40455527585673046, disc_loss = 0.07364806475633957
Trained batch 83 in epoch 4, gen_loss = 0.40423476766972316, disc_loss = 0.07407887037178236
Trained batch 84 in epoch 4, gen_loss = 0.4053301888353684, disc_loss = 0.07448299734250588
Trained batch 85 in epoch 4, gen_loss = 0.40614507087441376, disc_loss = 0.0738884778585025
Trained batch 86 in epoch 4, gen_loss = 0.4052296236328695, disc_loss = 0.07625869290111051
Trained batch 87 in epoch 4, gen_loss = 0.4053310839967294, disc_loss = 0.07612315536773001
Trained batch 88 in epoch 4, gen_loss = 0.4056386016727833, disc_loss = 0.07557180303075675
Trained batch 89 in epoch 4, gen_loss = 0.40515254570378195, disc_loss = 0.07514718035236001
Trained batch 90 in epoch 4, gen_loss = 0.4049596472100897, disc_loss = 0.07478487206070306
Trained batch 91 in epoch 4, gen_loss = 0.40535205116738443, disc_loss = 0.07419923118963513
Trained batch 92 in epoch 4, gen_loss = 0.4052937921657357, disc_loss = 0.07352917493190816
Trained batch 93 in epoch 4, gen_loss = 0.40552217275538344, disc_loss = 0.0728992317961727
Trained batch 94 in epoch 4, gen_loss = 0.40593895222011367, disc_loss = 0.07233145145797416
Trained batch 95 in epoch 4, gen_loss = 0.40599494613707066, disc_loss = 0.07185309513200384
Trained batch 96 in epoch 4, gen_loss = 0.4066356193159044, disc_loss = 0.0713951798232714
Trained batch 97 in epoch 4, gen_loss = 0.40703181770383096, disc_loss = 0.07083972323951977
Trained batch 98 in epoch 4, gen_loss = 0.4075930476790727, disc_loss = 0.07028969667964813
Trained batch 99 in epoch 4, gen_loss = 0.40785947054624555, disc_loss = 0.06988149696029723
Trained batch 100 in epoch 4, gen_loss = 0.40743499256596705, disc_loss = 0.0694234786592055
Trained batch 101 in epoch 4, gen_loss = 0.4079250395298004, disc_loss = 0.06974318522192977
Trained batch 102 in epoch 4, gen_loss = 0.40751413378900697, disc_loss = 0.06970993090348626
Trained batch 103 in epoch 4, gen_loss = 0.40675419425735104, disc_loss = 0.06984315770499122
Trained batch 104 in epoch 4, gen_loss = 0.4070475995540619, disc_loss = 0.06941015625461226
Trained batch 105 in epoch 4, gen_loss = 0.4067378418063218, disc_loss = 0.06952747826482046
Trained batch 106 in epoch 4, gen_loss = 0.40620256640086666, disc_loss = 0.07155479599556355
Trained batch 107 in epoch 4, gen_loss = 0.40662262174818253, disc_loss = 0.07124650365397057
Trained batch 108 in epoch 4, gen_loss = 0.40639222980639256, disc_loss = 0.07248959325493202
Trained batch 109 in epoch 4, gen_loss = 0.4056467061693018, disc_loss = 0.07374616831710393
Trained batch 110 in epoch 4, gen_loss = 0.40560149018828934, disc_loss = 0.07329271054986092
Trained batch 111 in epoch 4, gen_loss = 0.4058392862124102, disc_loss = 0.07342577372245225
Trained batch 112 in epoch 4, gen_loss = 0.4057455872539925, disc_loss = 0.07340676626767469
Trained batch 113 in epoch 4, gen_loss = 0.40582668336859923, disc_loss = 0.07285555226630286
Trained batch 114 in epoch 4, gen_loss = 0.4059964739758035, disc_loss = 0.07256866492654966
Trained batch 115 in epoch 4, gen_loss = 0.4053552906061041, disc_loss = 0.07226951153756216
Trained batch 116 in epoch 4, gen_loss = 0.40587366034841943, disc_loss = 0.07184307433219038
Trained batch 117 in epoch 4, gen_loss = 0.40558843920796606, disc_loss = 0.07145758269954536
Trained batch 118 in epoch 4, gen_loss = 0.40585046731123403, disc_loss = 0.07107001104775597
Trained batch 119 in epoch 4, gen_loss = 0.4063364826142788, disc_loss = 0.07174935328463714
Trained batch 120 in epoch 4, gen_loss = 0.4064364416047561, disc_loss = 0.07148048740403712
Trained batch 121 in epoch 4, gen_loss = 0.40668700146870534, disc_loss = 0.07124098637675652
Trained batch 122 in epoch 4, gen_loss = 0.4069235487197473, disc_loss = 0.07074189036933144
Trained batch 123 in epoch 4, gen_loss = 0.4072057599982908, disc_loss = 0.07075921502414971
Trained batch 124 in epoch 4, gen_loss = 0.408303249835968, disc_loss = 0.07119365843385458
Trained batch 125 in epoch 4, gen_loss = 0.4086135663683452, disc_loss = 0.07080616214356962
Trained batch 126 in epoch 4, gen_loss = 0.40916070295131113, disc_loss = 0.0704454935456472
Trained batch 127 in epoch 4, gen_loss = 0.4088421433698386, disc_loss = 0.06998128371196799
Trained batch 128 in epoch 4, gen_loss = 0.4089595693950505, disc_loss = 0.0700090117752552
Trained batch 129 in epoch 4, gen_loss = 0.40914873159848725, disc_loss = 0.06959253685692182
Trained batch 130 in epoch 4, gen_loss = 0.40989930029133803, disc_loss = 0.07003635337277678
Trained batch 131 in epoch 4, gen_loss = 0.40955390216726245, disc_loss = 0.0700409811300536
Trained batch 132 in epoch 4, gen_loss = 0.40893085177679706, disc_loss = 0.0734412658231375
Trained batch 133 in epoch 4, gen_loss = 0.4089761483135508, disc_loss = 0.0730670626177939
Trained batch 134 in epoch 4, gen_loss = 0.40951007648750587, disc_loss = 0.07285046120760617
Trained batch 135 in epoch 4, gen_loss = 0.4094064202817047, disc_loss = 0.07287994888611138
Trained batch 136 in epoch 4, gen_loss = 0.4095124484848802, disc_loss = 0.07246852762670848
Trained batch 137 in epoch 4, gen_loss = 0.40904707645160565, disc_loss = 0.07201494728687449
Trained batch 138 in epoch 4, gen_loss = 0.40916209705441975, disc_loss = 0.0716490847252899
Trained batch 139 in epoch 4, gen_loss = 0.40844251002584187, disc_loss = 0.07159287225721138
Trained batch 140 in epoch 4, gen_loss = 0.4080480106756197, disc_loss = 0.07201792974791206
Trained batch 141 in epoch 4, gen_loss = 0.40834160883661724, disc_loss = 0.07244906804039025
Trained batch 142 in epoch 4, gen_loss = 0.40787291672679926, disc_loss = 0.07250483348392524
Trained batch 143 in epoch 4, gen_loss = 0.40825719551907647, disc_loss = 0.07226555017081814
Trained batch 144 in epoch 4, gen_loss = 0.40843497740811313, disc_loss = 0.07233188803596743
Trained batch 145 in epoch 4, gen_loss = 0.40864891385378904, disc_loss = 0.07209412716584254
Trained batch 146 in epoch 4, gen_loss = 0.4080434818657077, disc_loss = 0.07227320881674484
Trained batch 147 in epoch 4, gen_loss = 0.4087227957474219, disc_loss = 0.07198578450275031
Trained batch 148 in epoch 4, gen_loss = 0.4096093357809438, disc_loss = 0.07184914583277782
Trained batch 149 in epoch 4, gen_loss = 0.4093987262248993, disc_loss = 0.07188990691055853
Trained batch 150 in epoch 4, gen_loss = 0.40948653517179934, disc_loss = 0.07214561162750847
Trained batch 151 in epoch 4, gen_loss = 0.4089978309838395, disc_loss = 0.07258239181369151
Trained batch 152 in epoch 4, gen_loss = 0.4093745993632896, disc_loss = 0.07219924981663235
Trained batch 153 in epoch 4, gen_loss = 0.4098005817308054, disc_loss = 0.07370032413028084
Trained batch 154 in epoch 4, gen_loss = 0.4090155751474442, disc_loss = 0.07567711111398474
Trained batch 155 in epoch 4, gen_loss = 0.4089382711129311, disc_loss = 0.07554075684852134
Trained batch 156 in epoch 4, gen_loss = 0.40917569664633197, disc_loss = 0.07621745252091984
Trained batch 157 in epoch 4, gen_loss = 0.4084099031324628, disc_loss = 0.07614999197871436
Trained batch 158 in epoch 4, gen_loss = 0.4080756182940501, disc_loss = 0.07640704830651576
Trained batch 159 in epoch 4, gen_loss = 0.40816103518009184, disc_loss = 0.07610677652410232
Trained batch 160 in epoch 4, gen_loss = 0.4080907706148136, disc_loss = 0.0762804928438171
Trained batch 161 in epoch 4, gen_loss = 0.407754076115879, disc_loss = 0.0760720465734693
Trained batch 162 in epoch 4, gen_loss = 0.40728746875663474, disc_loss = 0.0769582292682097
Trained batch 163 in epoch 4, gen_loss = 0.40753624370185343, disc_loss = 0.07703200120637875
Trained batch 164 in epoch 4, gen_loss = 0.40776128100626396, disc_loss = 0.0767777215068539
Trained batch 165 in epoch 4, gen_loss = 0.4076103939708457, disc_loss = 0.07643135221315975
Trained batch 166 in epoch 4, gen_loss = 0.40766817384851195, disc_loss = 0.07637052944565784
Trained batch 167 in epoch 4, gen_loss = 0.407580800177086, disc_loss = 0.07705908962192812
Trained batch 168 in epoch 4, gen_loss = 0.40757482362216746, disc_loss = 0.07838615776761573
Trained batch 169 in epoch 4, gen_loss = 0.40765335472191083, disc_loss = 0.078691345820313
Trained batch 170 in epoch 4, gen_loss = 0.4075424343521832, disc_loss = 0.07847367198211931
Trained batch 171 in epoch 4, gen_loss = 0.40729472145091655, disc_loss = 0.07858155357521461
Trained batch 172 in epoch 4, gen_loss = 0.40792099347693384, disc_loss = 0.07903472417588696
Trained batch 173 in epoch 4, gen_loss = 0.40803202387245224, disc_loss = 0.07918665379863875
Trained batch 174 in epoch 4, gen_loss = 0.4084421844141824, disc_loss = 0.07941904286720923
Trained batch 175 in epoch 4, gen_loss = 0.4081600804559209, disc_loss = 0.07914439514173534
Trained batch 176 in epoch 4, gen_loss = 0.4078864665691462, disc_loss = 0.0791112095443795
Trained batch 177 in epoch 4, gen_loss = 0.4078054048037261, disc_loss = 0.07872751962623736
Trained batch 178 in epoch 4, gen_loss = 0.4079081707493553, disc_loss = 0.07864338218354147
Trained batch 179 in epoch 4, gen_loss = 0.40792440159453286, disc_loss = 0.07824678522689889
Trained batch 180 in epoch 4, gen_loss = 0.40752572792669683, disc_loss = 0.07815805968998299
Trained batch 181 in epoch 4, gen_loss = 0.407451596561369, disc_loss = 0.07786171864155311
Trained batch 182 in epoch 4, gen_loss = 0.40706308324480317, disc_loss = 0.07778591374851397
Trained batch 183 in epoch 4, gen_loss = 0.4071178548038006, disc_loss = 0.07761489961589889
Trained batch 184 in epoch 4, gen_loss = 0.4071100776259964, disc_loss = 0.07735825754148332
Trained batch 185 in epoch 4, gen_loss = 0.40727294901365874, disc_loss = 0.0770772020407622
Trained batch 186 in epoch 4, gen_loss = 0.4073421617242742, disc_loss = 0.07673729794040163
Trained batch 187 in epoch 4, gen_loss = 0.40733932656176547, disc_loss = 0.07641354579963978
Trained batch 188 in epoch 4, gen_loss = 0.4068967215913944, disc_loss = 0.07624352165798425
Trained batch 189 in epoch 4, gen_loss = 0.40687958566766036, disc_loss = 0.07603691865592019
Trained batch 190 in epoch 4, gen_loss = 0.4066046749422063, disc_loss = 0.07628089964087487
Trained batch 191 in epoch 4, gen_loss = 0.4064903638015191, disc_loss = 0.07727750819807018
Trained batch 192 in epoch 4, gen_loss = 0.4070324672318493, disc_loss = 0.07750018074423307
Trained batch 193 in epoch 4, gen_loss = 0.40709190009181034, disc_loss = 0.07737244095547681
Trained batch 194 in epoch 4, gen_loss = 0.4072973787784576, disc_loss = 0.07705907903086298
Trained batch 195 in epoch 4, gen_loss = 0.4069016267146383, disc_loss = 0.07691002087144903
Trained batch 196 in epoch 4, gen_loss = 0.4072602910136208, disc_loss = 0.07658510690857538
Trained batch 197 in epoch 4, gen_loss = 0.4074371858979716, disc_loss = 0.07635524113323879
Trained batch 198 in epoch 4, gen_loss = 0.4075520550785352, disc_loss = 0.07625287322645735
Trained batch 199 in epoch 4, gen_loss = 0.4074640741944313, disc_loss = 0.07767293006880209
Trained batch 200 in epoch 4, gen_loss = 0.4076386065921973, disc_loss = 0.07912415014672561
Trained batch 201 in epoch 4, gen_loss = 0.40778540974796407, disc_loss = 0.07918013500206468
Trained batch 202 in epoch 4, gen_loss = 0.40775678560064343, disc_loss = 0.07935050835264067
Trained batch 203 in epoch 4, gen_loss = 0.4077923273046811, disc_loss = 0.08008968998796727
Trained batch 204 in epoch 4, gen_loss = 0.4076156867713463, disc_loss = 0.08044147819235194
Trained batch 205 in epoch 4, gen_loss = 0.4071874851451337, disc_loss = 0.08055261056644172
Trained batch 206 in epoch 4, gen_loss = 0.40771249253392794, disc_loss = 0.08115279174900213
Trained batch 207 in epoch 4, gen_loss = 0.407560084015131, disc_loss = 0.08097706583570331
Trained batch 208 in epoch 4, gen_loss = 0.4071017409625806, disc_loss = 0.08198108947189729
Trained batch 209 in epoch 4, gen_loss = 0.4074323852856954, disc_loss = 0.08210251539546465
Trained batch 210 in epoch 4, gen_loss = 0.4072736292653739, disc_loss = 0.0823213665225318
Trained batch 211 in epoch 4, gen_loss = 0.40689780211673593, disc_loss = 0.08236744949585353
Trained batch 212 in epoch 4, gen_loss = 0.40669649629525734, disc_loss = 0.0823859371520369
Trained batch 213 in epoch 4, gen_loss = 0.4069794804971909, disc_loss = 0.08248963985792318
Trained batch 214 in epoch 4, gen_loss = 0.40702641869700235, disc_loss = 0.08255918544695474
Trained batch 215 in epoch 4, gen_loss = 0.4071631285327452, disc_loss = 0.08299412046067624
Trained batch 216 in epoch 4, gen_loss = 0.4071693419036777, disc_loss = 0.08284524215969004
Trained batch 217 in epoch 4, gen_loss = 0.40664352927732905, disc_loss = 0.0827267214617427
Trained batch 218 in epoch 4, gen_loss = 0.4069021161832766, disc_loss = 0.08290842592877816
Trained batch 219 in epoch 4, gen_loss = 0.4068475146185268, disc_loss = 0.08318368537478488
Trained batch 220 in epoch 4, gen_loss = 0.4065162004119131, disc_loss = 0.08307750441125547
Trained batch 221 in epoch 4, gen_loss = 0.40623197241409403, disc_loss = 0.0828471465921449
Trained batch 222 in epoch 4, gen_loss = 0.40599854724824164, disc_loss = 0.08359638927922054
Trained batch 223 in epoch 4, gen_loss = 0.40597711224108934, disc_loss = 0.08377501896341398
Trained batch 224 in epoch 4, gen_loss = 0.4058929663234287, disc_loss = 0.08369162492247091
Trained batch 225 in epoch 4, gen_loss = 0.40626240119469903, disc_loss = 0.08338608979082675
Trained batch 226 in epoch 4, gen_loss = 0.406505901514171, disc_loss = 0.08314523124443736
Trained batch 227 in epoch 4, gen_loss = 0.406351459523042, disc_loss = 0.08287037232392386
Trained batch 228 in epoch 4, gen_loss = 0.40639220236690804, disc_loss = 0.08268513650669997
Trained batch 229 in epoch 4, gen_loss = 0.40624456107616425, disc_loss = 0.0824795800038492
Trained batch 230 in epoch 4, gen_loss = 0.40654894296741073, disc_loss = 0.08293732794130713
Trained batch 231 in epoch 4, gen_loss = 0.4062512847113198, disc_loss = 0.08306579050760524
Trained batch 232 in epoch 4, gen_loss = 0.4063910895662758, disc_loss = 0.08288929759936463
Trained batch 233 in epoch 4, gen_loss = 0.4065728342940665, disc_loss = 0.08279236003111762
Trained batch 234 in epoch 4, gen_loss = 0.40647192166206686, disc_loss = 0.0827605472421868
Trained batch 235 in epoch 4, gen_loss = 0.40667127855753493, disc_loss = 0.08267327771971981
Trained batch 236 in epoch 4, gen_loss = 0.40705546636118667, disc_loss = 0.0823877916380543
Trained batch 237 in epoch 4, gen_loss = 0.40748836500804964, disc_loss = 0.0833117321834062
Trained batch 238 in epoch 4, gen_loss = 0.40752583517689084, disc_loss = 0.0840996471233666
Trained batch 239 in epoch 4, gen_loss = 0.40763376504182813, disc_loss = 0.08408651803426134
Trained batch 240 in epoch 4, gen_loss = 0.4076422682936261, disc_loss = 0.08396543106218776
Trained batch 241 in epoch 4, gen_loss = 0.40731175280799553, disc_loss = 0.08394073348392324
Trained batch 242 in epoch 4, gen_loss = 0.4073163425480878, disc_loss = 0.08378571720885826
Trained batch 243 in epoch 4, gen_loss = 0.4070386634986909, disc_loss = 0.08375875601262527
Trained batch 244 in epoch 4, gen_loss = 0.40705757068128, disc_loss = 0.08365496237173069
Trained batch 245 in epoch 4, gen_loss = 0.4070856115682338, disc_loss = 0.0833732970948596
Trained batch 246 in epoch 4, gen_loss = 0.4069443207520705, disc_loss = 0.08314828494533534
Trained batch 247 in epoch 4, gen_loss = 0.40694322328894367, disc_loss = 0.08304605957293403
Trained batch 248 in epoch 4, gen_loss = 0.4069370299458025, disc_loss = 0.08278702751333156
Trained batch 249 in epoch 4, gen_loss = 0.4072417981624603, disc_loss = 0.08249701661430299
Trained batch 250 in epoch 4, gen_loss = 0.4076173087040267, disc_loss = 0.08259370270559928
Trained batch 251 in epoch 4, gen_loss = 0.4073100946252308, disc_loss = 0.08375670335676876
Trained batch 252 in epoch 4, gen_loss = 0.40762798470470746, disc_loss = 0.08380766416690036
Trained batch 253 in epoch 4, gen_loss = 0.40734421725817554, disc_loss = 0.0838442056780813
Trained batch 254 in epoch 4, gen_loss = 0.4068877221322527, disc_loss = 0.08404442688961532
Trained batch 255 in epoch 4, gen_loss = 0.40695237496402115, disc_loss = 0.08393018303286226
Trained batch 256 in epoch 4, gen_loss = 0.40658726128622713, disc_loss = 0.08398953738807183
Trained batch 257 in epoch 4, gen_loss = 0.40614501427310384, disc_loss = 0.08395287155375866
Trained batch 258 in epoch 4, gen_loss = 0.4061382333514313, disc_loss = 0.0838530484252541
Trained batch 259 in epoch 4, gen_loss = 0.4063634577852029, disc_loss = 0.08359119548784712
Trained batch 260 in epoch 4, gen_loss = 0.4063928902605941, disc_loss = 0.08330207275069708
Trained batch 261 in epoch 4, gen_loss = 0.4063278135225063, disc_loss = 0.0831151308459834
Trained batch 262 in epoch 4, gen_loss = 0.4062258753033192, disc_loss = 0.08290100414058045
Trained batch 263 in epoch 4, gen_loss = 0.4058048745447939, disc_loss = 0.082692961735919
Trained batch 264 in epoch 4, gen_loss = 0.40565454206376705, disc_loss = 0.08247022559725732
Trained batch 265 in epoch 4, gen_loss = 0.4056759690655802, disc_loss = 0.0822585856916621
Trained batch 266 in epoch 4, gen_loss = 0.40577772282036056, disc_loss = 0.08201155165377795
Trained batch 267 in epoch 4, gen_loss = 0.4056014434170367, disc_loss = 0.08185324168576401
Trained batch 268 in epoch 4, gen_loss = 0.4055666829352042, disc_loss = 0.08204356673585604
Trained batch 269 in epoch 4, gen_loss = 0.40599281357394323, disc_loss = 0.08257127609621319
Trained batch 270 in epoch 4, gen_loss = 0.4060929039307626, disc_loss = 0.08229645723270809
Trained batch 271 in epoch 4, gen_loss = 0.406026495511041, disc_loss = 0.08216756274957922
Trained batch 272 in epoch 4, gen_loss = 0.405811492230866, disc_loss = 0.08197268660968313
Trained batch 273 in epoch 4, gen_loss = 0.4058890109949738, disc_loss = 0.08172463763838321
Trained batch 274 in epoch 4, gen_loss = 0.40610566420988603, disc_loss = 0.08149271321059628
Trained batch 275 in epoch 4, gen_loss = 0.40620839109887247, disc_loss = 0.08122709433149979
Trained batch 276 in epoch 4, gen_loss = 0.40648156178557054, disc_loss = 0.0810427666164343
Trained batch 277 in epoch 4, gen_loss = 0.40626480221319544, disc_loss = 0.08121552392538878
Trained batch 278 in epoch 4, gen_loss = 0.4058588836141812, disc_loss = 0.08290886530973098
Trained batch 279 in epoch 4, gen_loss = 0.40554262633834565, disc_loss = 0.08335445458568366
Trained batch 280 in epoch 4, gen_loss = 0.40555337177476847, disc_loss = 0.08344407073881649
Trained batch 281 in epoch 4, gen_loss = 0.4060004694876096, disc_loss = 0.08371543088194697
Trained batch 282 in epoch 4, gen_loss = 0.4058006541678425, disc_loss = 0.0836729311923967
Trained batch 283 in epoch 4, gen_loss = 0.40546315037448644, disc_loss = 0.08381689491216093
Trained batch 284 in epoch 4, gen_loss = 0.4050994938925693, disc_loss = 0.08377212256421906
Trained batch 285 in epoch 4, gen_loss = 0.4050777647253517, disc_loss = 0.0841512968877682
Trained batch 286 in epoch 4, gen_loss = 0.40492431232738163, disc_loss = 0.08456333803713893
Trained batch 287 in epoch 4, gen_loss = 0.4048489685066872, disc_loss = 0.08451734958442911
Trained batch 288 in epoch 4, gen_loss = 0.40494513604467713, disc_loss = 0.08449986720599466
Trained batch 289 in epoch 4, gen_loss = 0.40470811734939444, disc_loss = 0.08475663907793832
Trained batch 290 in epoch 4, gen_loss = 0.40465227957443684, disc_loss = 0.08455093819936066
Trained batch 291 in epoch 4, gen_loss = 0.40445548061230413, disc_loss = 0.08466577645206237
Trained batch 292 in epoch 4, gen_loss = 0.40400932673301304, disc_loss = 0.08478454994228461
Trained batch 293 in epoch 4, gen_loss = 0.40387616402843374, disc_loss = 0.08472882482844095
Trained batch 294 in epoch 4, gen_loss = 0.4040915950880212, disc_loss = 0.08467381129799001
Trained batch 295 in epoch 4, gen_loss = 0.4042813749732198, disc_loss = 0.08442375236788664
Trained batch 296 in epoch 4, gen_loss = 0.4041978885429074, disc_loss = 0.08444447548721325
Trained batch 297 in epoch 4, gen_loss = 0.40417595817738733, disc_loss = 0.0842563985337522
Trained batch 298 in epoch 4, gen_loss = 0.40415970587411454, disc_loss = 0.0841836588796739
Trained batch 299 in epoch 4, gen_loss = 0.4039423974355062, disc_loss = 0.08436873742534469
Trained batch 300 in epoch 4, gen_loss = 0.40400871505768987, disc_loss = 0.08438643133515288
Trained batch 301 in epoch 4, gen_loss = 0.40385940068999665, disc_loss = 0.08440650499808226
Trained batch 302 in epoch 4, gen_loss = 0.4039643114746207, disc_loss = 0.08421860324071333
Trained batch 303 in epoch 4, gen_loss = 0.4041298692555804, disc_loss = 0.08396490869314507
Trained batch 304 in epoch 4, gen_loss = 0.40421192206320217, disc_loss = 0.08375696091775278
Trained batch 305 in epoch 4, gen_loss = 0.4040205401727577, disc_loss = 0.0835573299699676
Trained batch 306 in epoch 4, gen_loss = 0.40413436730443847, disc_loss = 0.08338891033611051
Trained batch 307 in epoch 4, gen_loss = 0.40426724839520145, disc_loss = 0.08323176753822134
Trained batch 308 in epoch 4, gen_loss = 0.4040684317115055, disc_loss = 0.08307856629515205
Trained batch 309 in epoch 4, gen_loss = 0.40406586210573875, disc_loss = 0.08375829621218145
Trained batch 310 in epoch 4, gen_loss = 0.40448937126677903, disc_loss = 0.08406264959741683
Trained batch 311 in epoch 4, gen_loss = 0.40447614848231656, disc_loss = 0.08391230951737946
Trained batch 312 in epoch 4, gen_loss = 0.4042809260919833, disc_loss = 0.08378168993656294
Trained batch 313 in epoch 4, gen_loss = 0.4043404464698901, disc_loss = 0.08361524282539394
Trained batch 314 in epoch 4, gen_loss = 0.4045871615409851, disc_loss = 0.08350827804663115
Trained batch 315 in epoch 4, gen_loss = 0.4046228158323071, disc_loss = 0.0833099477561898
Trained batch 316 in epoch 4, gen_loss = 0.4045751292246749, disc_loss = 0.08307260124024579
Trained batch 317 in epoch 4, gen_loss = 0.40456081898707263, disc_loss = 0.0828600003363553
Trained batch 318 in epoch 4, gen_loss = 0.4045439053291811, disc_loss = 0.08265798569724057
Trained batch 319 in epoch 4, gen_loss = 0.4046853382140398, disc_loss = 0.08242745858588023
Trained batch 320 in epoch 4, gen_loss = 0.4045922938165635, disc_loss = 0.08240137760298227
Trained batch 321 in epoch 4, gen_loss = 0.40466354241282304, disc_loss = 0.0823409554146531
Trained batch 322 in epoch 4, gen_loss = 0.4049489124456057, disc_loss = 0.08219020669968459
Trained batch 323 in epoch 4, gen_loss = 0.4047120131644202, disc_loss = 0.08207220776598717
Trained batch 324 in epoch 4, gen_loss = 0.4046892868555509, disc_loss = 0.0818655108101666
Trained batch 325 in epoch 4, gen_loss = 0.40464570578987613, disc_loss = 0.0817778745703285
Trained batch 326 in epoch 4, gen_loss = 0.4049195747492146, disc_loss = 0.08155696771452232
Trained batch 327 in epoch 4, gen_loss = 0.4050212318032253, disc_loss = 0.08140359148411534
Trained batch 328 in epoch 4, gen_loss = 0.40511189505322004, disc_loss = 0.0812040479431965
Trained batch 329 in epoch 4, gen_loss = 0.40510595332492483, disc_loss = 0.08103105543378854
Trained batch 330 in epoch 4, gen_loss = 0.40502312383262773, disc_loss = 0.08088549147880554
Trained batch 331 in epoch 4, gen_loss = 0.40498990350099934, disc_loss = 0.08078458399304289
Trained batch 332 in epoch 4, gen_loss = 0.40483086021454845, disc_loss = 0.08071105281875522
Trained batch 333 in epoch 4, gen_loss = 0.4048858027079862, disc_loss = 0.08067036903195618
Trained batch 334 in epoch 4, gen_loss = 0.4048841258483147, disc_loss = 0.08047841109696831
Trained batch 335 in epoch 4, gen_loss = 0.4044995479108322, disc_loss = 0.0803041869034392
Trained batch 336 in epoch 4, gen_loss = 0.4043669257567261, disc_loss = 0.08020509770748037
Trained batch 337 in epoch 4, gen_loss = 0.404266036032925, disc_loss = 0.080097562034157
Trained batch 338 in epoch 4, gen_loss = 0.4042541853270348, disc_loss = 0.07998820008699038
Trained batch 339 in epoch 4, gen_loss = 0.4044037504231229, disc_loss = 0.07980505847235156
Trained batch 340 in epoch 4, gen_loss = 0.4045859195095353, disc_loss = 0.07963028544822265
Trained batch 341 in epoch 4, gen_loss = 0.4043911235374317, disc_loss = 0.07952064928348171
Trained batch 342 in epoch 4, gen_loss = 0.40439724687584633, disc_loss = 0.07942123295272274
Trained batch 343 in epoch 4, gen_loss = 0.40467057325119193, disc_loss = 0.0792473117173866
Trained batch 344 in epoch 4, gen_loss = 0.4046423203703286, disc_loss = 0.07917588805185928
Trained batch 345 in epoch 4, gen_loss = 0.40478689391488976, disc_loss = 0.07912337895875764
Trained batch 346 in epoch 4, gen_loss = 0.4049351978027168, disc_loss = 0.07913369358643374
Trained batch 347 in epoch 4, gen_loss = 0.40494631350725546, disc_loss = 0.07898619945091463
Trained batch 348 in epoch 4, gen_loss = 0.4049733607338629, disc_loss = 0.07883618265673262
Trained batch 349 in epoch 4, gen_loss = 0.40490240514278414, disc_loss = 0.07870093621978802
Trained batch 350 in epoch 4, gen_loss = 0.40505690868423877, disc_loss = 0.07853711580730274
Trained batch 351 in epoch 4, gen_loss = 0.40525406057184393, disc_loss = 0.07835069584887772
Trained batch 352 in epoch 4, gen_loss = 0.40540776973743275, disc_loss = 0.07825478006328428
Trained batch 353 in epoch 4, gen_loss = 0.4051727880697466, disc_loss = 0.0783972929423875
Trained batch 354 in epoch 4, gen_loss = 0.4050961257706226, disc_loss = 0.07869802371690601
Trained batch 355 in epoch 4, gen_loss = 0.40543418268809156, disc_loss = 0.07855059664168008
Trained batch 356 in epoch 4, gen_loss = 0.40542439928575724, disc_loss = 0.07843562521703061
Trained batch 357 in epoch 4, gen_loss = 0.40545781947381004, disc_loss = 0.07830052542260864
Trained batch 358 in epoch 4, gen_loss = 0.40555620450827407, disc_loss = 0.07814720960873539
Trained batch 359 in epoch 4, gen_loss = 0.4055928598675463, disc_loss = 0.07800385238887328
Trained batch 360 in epoch 4, gen_loss = 0.4055889064750513, disc_loss = 0.07793502838652674
Trained batch 361 in epoch 4, gen_loss = 0.40543200437864546, disc_loss = 0.07778744513647456
Trained batch 362 in epoch 4, gen_loss = 0.4055933238882007, disc_loss = 0.07771532238427724
Trained batch 363 in epoch 4, gen_loss = 0.4055424878721709, disc_loss = 0.07753774210692967
Trained batch 364 in epoch 4, gen_loss = 0.405489300620066, disc_loss = 0.07737915682899829
Trained batch 365 in epoch 4, gen_loss = 0.4054807523886363, disc_loss = 0.0772821532391887
Trained batch 366 in epoch 4, gen_loss = 0.4057300629992576, disc_loss = 0.07759469650731465
Trained batch 367 in epoch 4, gen_loss = 0.4058054314683313, disc_loss = 0.07743334520795464
Trained batch 368 in epoch 4, gen_loss = 0.40550713164373464, disc_loss = 0.07759063872243695
Trained batch 369 in epoch 4, gen_loss = 0.40539742611549995, disc_loss = 0.07744913827250334
Trained batch 370 in epoch 4, gen_loss = 0.4054256375587854, disc_loss = 0.07739485263186846
Trained batch 371 in epoch 4, gen_loss = 0.4054180237074052, disc_loss = 0.07736856455449015
Trained batch 372 in epoch 4, gen_loss = 0.4054240509268426, disc_loss = 0.07719445562279775
Trained batch 373 in epoch 4, gen_loss = 0.40571096539497375, disc_loss = 0.07702348435940072
Trained batch 374 in epoch 4, gen_loss = 0.40569874993960064, disc_loss = 0.07686491247390707
Trained batch 375 in epoch 4, gen_loss = 0.4059020349795514, disc_loss = 0.07668974705937101
Trained batch 376 in epoch 4, gen_loss = 0.4057507547364627, disc_loss = 0.07666929217984292
Trained batch 377 in epoch 4, gen_loss = 0.40538224183693133, disc_loss = 0.07698876869608524
Trained batch 378 in epoch 4, gen_loss = 0.4054682643243694, disc_loss = 0.07709444453448333
Trained batch 379 in epoch 4, gen_loss = 0.4053254042016832, disc_loss = 0.07700035985387665
Trained batch 380 in epoch 4, gen_loss = 0.4053211099519504, disc_loss = 0.0768618645926258
Trained batch 381 in epoch 4, gen_loss = 0.4055056233368619, disc_loss = 0.07667933428947721
Trained batch 382 in epoch 4, gen_loss = 0.4054720453898527, disc_loss = 0.07651532245021771
Trained batch 383 in epoch 4, gen_loss = 0.40552708545389277, disc_loss = 0.07635415053058144
Trained batch 384 in epoch 4, gen_loss = 0.40545965680828344, disc_loss = 0.076240379127444
Trained batch 385 in epoch 4, gen_loss = 0.4055242639594745, disc_loss = 0.07608992427495824
Trained batch 386 in epoch 4, gen_loss = 0.405698584416732, disc_loss = 0.07591658362935873
Trained batch 387 in epoch 4, gen_loss = 0.4055597897350174, disc_loss = 0.07574185460311428
Trained batch 388 in epoch 4, gen_loss = 0.40580941257869063, disc_loss = 0.07556798292927272
Trained batch 389 in epoch 4, gen_loss = 0.4059730262328417, disc_loss = 0.07541761639145896
Trained batch 390 in epoch 4, gen_loss = 0.4060387260011395, disc_loss = 0.07523955035564082
Trained batch 391 in epoch 4, gen_loss = 0.40611137267278163, disc_loss = 0.07508316367617524
Trained batch 392 in epoch 4, gen_loss = 0.40627574124409044, disc_loss = 0.07492474220342385
Trained batch 393 in epoch 4, gen_loss = 0.40639590286663946, disc_loss = 0.07492400359995852
Trained batch 394 in epoch 4, gen_loss = 0.4064868854570992, disc_loss = 0.0750082386280351
Trained batch 395 in epoch 4, gen_loss = 0.4068190058072408, disc_loss = 0.07497711094199783
Trained batch 396 in epoch 4, gen_loss = 0.4070021515379024, disc_loss = 0.07480759934524557
Trained batch 397 in epoch 4, gen_loss = 0.4070299595744167, disc_loss = 0.07467427503331635
Trained batch 398 in epoch 4, gen_loss = 0.4070935657149867, disc_loss = 0.07450306316240128
Trained batch 399 in epoch 4, gen_loss = 0.4071445208787918, disc_loss = 0.07433058507158422
Trained batch 400 in epoch 4, gen_loss = 0.4072586187995283, disc_loss = 0.07420478823787517
Trained batch 401 in epoch 4, gen_loss = 0.40716664381881257, disc_loss = 0.07410546542673524
Trained batch 402 in epoch 4, gen_loss = 0.40718908722584063, disc_loss = 0.07396261828833678
Trained batch 403 in epoch 4, gen_loss = 0.4075733974280924, disc_loss = 0.07391179568194185
Trained batch 404 in epoch 4, gen_loss = 0.4076117553828675, disc_loss = 0.07376793364844757
Trained batch 405 in epoch 4, gen_loss = 0.4076952743412826, disc_loss = 0.07361207810560874
Trained batch 406 in epoch 4, gen_loss = 0.40775160473160427, disc_loss = 0.07355158170913999
Trained batch 407 in epoch 4, gen_loss = 0.407877932722662, disc_loss = 0.07349050634736926
Trained batch 408 in epoch 4, gen_loss = 0.4080366962259148, disc_loss = 0.0733414968842308
Trained batch 409 in epoch 4, gen_loss = 0.4081003681915562, disc_loss = 0.0732103247093264
Trained batch 410 in epoch 4, gen_loss = 0.40807168689667456, disc_loss = 0.07306633933522079
Trained batch 411 in epoch 4, gen_loss = 0.4078985628427811, disc_loss = 0.07302625415263499
Trained batch 412 in epoch 4, gen_loss = 0.40801499946354086, disc_loss = 0.07310935652298406
Trained batch 413 in epoch 4, gen_loss = 0.4081679605631437, disc_loss = 0.07295729514494863
Trained batch 414 in epoch 4, gen_loss = 0.40813880871577435, disc_loss = 0.07286765756175281
Trained batch 415 in epoch 4, gen_loss = 0.4082807070360734, disc_loss = 0.07270590759379467
Trained batch 416 in epoch 4, gen_loss = 0.40843746559225397, disc_loss = 0.07261900073900032
Trained batch 417 in epoch 4, gen_loss = 0.40849143744370586, disc_loss = 0.0724984374795216
Trained batch 418 in epoch 4, gen_loss = 0.408501699389023, disc_loss = 0.07243335431859538
Trained batch 419 in epoch 4, gen_loss = 0.4088032561398688, disc_loss = 0.07238216023071714
Trained batch 420 in epoch 4, gen_loss = 0.40887049576732154, disc_loss = 0.07224327455122122
Trained batch 421 in epoch 4, gen_loss = 0.4089677525216369, disc_loss = 0.07217191649773004
Trained batch 422 in epoch 4, gen_loss = 0.4089606185190503, disc_loss = 0.07201906350654842
Trained batch 423 in epoch 4, gen_loss = 0.4088608234558465, disc_loss = 0.07210611141471297
Trained batch 424 in epoch 4, gen_loss = 0.40904119098887726, disc_loss = 0.07237513409598785
Trained batch 425 in epoch 4, gen_loss = 0.4091536119370393, disc_loss = 0.07233507094135237
Trained batch 426 in epoch 4, gen_loss = 0.40889094550101485, disc_loss = 0.07261080780574743
Trained batch 427 in epoch 4, gen_loss = 0.409098932536963, disc_loss = 0.07293545439726212
Trained batch 428 in epoch 4, gen_loss = 0.4091101081082315, disc_loss = 0.0728662911963178
Trained batch 429 in epoch 4, gen_loss = 0.4089938817329185, disc_loss = 0.07285897846788514
Trained batch 430 in epoch 4, gen_loss = 0.40884176657260707, disc_loss = 0.0729583509832517
Trained batch 431 in epoch 4, gen_loss = 0.40867097965545124, disc_loss = 0.07310619326610188
Trained batch 432 in epoch 4, gen_loss = 0.40887403378035125, disc_loss = 0.07311578881959098
Trained batch 433 in epoch 4, gen_loss = 0.4089766427668558, disc_loss = 0.07296660686907475
Trained batch 434 in epoch 4, gen_loss = 0.4089793734851925, disc_loss = 0.07284392647488021
Trained batch 435 in epoch 4, gen_loss = 0.40889259133863887, disc_loss = 0.0727916402088632
Trained batch 436 in epoch 4, gen_loss = 0.4088351269608504, disc_loss = 0.07268803082704885
Trained batch 437 in epoch 4, gen_loss = 0.4086396878576714, disc_loss = 0.07277827968684845
Trained batch 438 in epoch 4, gen_loss = 0.4087933971968762, disc_loss = 0.07269664634239768
Trained batch 439 in epoch 4, gen_loss = 0.40869307470592586, disc_loss = 0.07261393674945628
Trained batch 440 in epoch 4, gen_loss = 0.4087296589161533, disc_loss = 0.07253576116741987
Trained batch 441 in epoch 4, gen_loss = 0.4086559323164133, disc_loss = 0.07242969904575346
Trained batch 442 in epoch 4, gen_loss = 0.4087971592864387, disc_loss = 0.07240107606541424
Trained batch 443 in epoch 4, gen_loss = 0.4086759652237634, disc_loss = 0.0723042455774539
Trained batch 444 in epoch 4, gen_loss = 0.4088722194848436, disc_loss = 0.07215906448787852
Trained batch 445 in epoch 4, gen_loss = 0.40912096082095073, disc_loss = 0.0720269957937367
Trained batch 446 in epoch 4, gen_loss = 0.40912424337943926, disc_loss = 0.07199769928192999
Trained batch 447 in epoch 4, gen_loss = 0.40898640819692184, disc_loss = 0.07203131180098613
Trained batch 448 in epoch 4, gen_loss = 0.4091179367561383, disc_loss = 0.07191307911387995
Trained batch 449 in epoch 4, gen_loss = 0.4092693003680971, disc_loss = 0.0717876905720267
Trained batch 450 in epoch 4, gen_loss = 0.4094081460900952, disc_loss = 0.07167164839911554
Trained batch 451 in epoch 4, gen_loss = 0.40936112951124665, disc_loss = 0.07155125177943403
Trained batch 452 in epoch 4, gen_loss = 0.4092887718945939, disc_loss = 0.07149150659418593
Trained batch 453 in epoch 4, gen_loss = 0.4093618320736066, disc_loss = 0.07154811161574354
Trained batch 454 in epoch 4, gen_loss = 0.409254111627956, disc_loss = 0.07158140285697939
Trained batch 455 in epoch 4, gen_loss = 0.40936668576639995, disc_loss = 0.07146320599253829
Trained batch 456 in epoch 4, gen_loss = 0.4095101469324767, disc_loss = 0.07135248142834631
Trained batch 457 in epoch 4, gen_loss = 0.4093499595551512, disc_loss = 0.07130177876419962
Trained batch 458 in epoch 4, gen_loss = 0.4091204098366964, disc_loss = 0.07125682503285297
Trained batch 459 in epoch 4, gen_loss = 0.4092128790591074, disc_loss = 0.07136126689653358
Trained batch 460 in epoch 4, gen_loss = 0.40918391613277594, disc_loss = 0.07124934512152137
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.3201410174369812, disc_loss = 0.01659187115728855
Trained batch 1 in epoch 5, gen_loss = 0.351946622133255, disc_loss = 0.011290627531707287
Trained batch 2 in epoch 5, gen_loss = 0.3649023771286011, disc_loss = 0.01069380653401216
Trained batch 3 in epoch 5, gen_loss = 0.3827546536922455, disc_loss = 0.01182013750076294
Trained batch 4 in epoch 5, gen_loss = 0.3826876044273376, disc_loss = 0.01573673337697983
Trained batch 5 in epoch 5, gen_loss = 0.39756164451440174, disc_loss = 0.025966232021649677
Trained batch 6 in epoch 5, gen_loss = 0.400812885590962, disc_loss = 0.058912966932569234
Trained batch 7 in epoch 5, gen_loss = 0.41699427738785744, disc_loss = 0.0628241989761591
Trained batch 8 in epoch 5, gen_loss = 0.4188756975862715, disc_loss = 0.06308644844426049
Trained batch 9 in epoch 5, gen_loss = 0.41147983968257906, disc_loss = 0.06864732131361961
Trained batch 10 in epoch 5, gen_loss = 0.40578970042142, disc_loss = 0.06317462645132434
Trained batch 11 in epoch 5, gen_loss = 0.41151674340168637, disc_loss = 0.058770403964444995
Trained batch 12 in epoch 5, gen_loss = 0.4121306607356438, disc_loss = 0.05761050325460159
Trained batch 13 in epoch 5, gen_loss = 0.41118088364601135, disc_loss = 0.05437149087499295
Trained batch 14 in epoch 5, gen_loss = 0.40883477926254275, disc_loss = 0.05161894578486681
Trained batch 15 in epoch 5, gen_loss = 0.4041486419737339, disc_loss = 0.049358026415575296
Trained batch 16 in epoch 5, gen_loss = 0.4049525856971741, disc_loss = 0.04786153844393352
Trained batch 17 in epoch 5, gen_loss = 0.40760914815796745, disc_loss = 0.0591464233584702
Trained batch 18 in epoch 5, gen_loss = 0.40566311227647883, disc_loss = 0.07476625714058939
Trained batch 19 in epoch 5, gen_loss = 0.40661319345235825, disc_loss = 0.07227037050761283
Trained batch 20 in epoch 5, gen_loss = 0.40917693149475826, disc_loss = 0.07409429465908379
Trained batch 21 in epoch 5, gen_loss = 0.4076986610889435, disc_loss = 0.07596416420049289
Trained batch 22 in epoch 5, gen_loss = 0.4095717059529346, disc_loss = 0.07689459674546252
Trained batch 23 in epoch 5, gen_loss = 0.41132906824350357, disc_loss = 0.08274810066601883
Trained batch 24 in epoch 5, gen_loss = 0.41332884311676027, disc_loss = 0.08225848991423845
Trained batch 25 in epoch 5, gen_loss = 0.4126873188293897, disc_loss = 0.08064947982963461
Trained batch 26 in epoch 5, gen_loss = 0.4132861351525342, disc_loss = 0.07937573217269447
Trained batch 27 in epoch 5, gen_loss = 0.4133262825863702, disc_loss = 0.07920277800544032
Trained batch 28 in epoch 5, gen_loss = 0.4069473676640412, disc_loss = 0.0848138685948376
Trained batch 29 in epoch 5, gen_loss = 0.40837668230136237, disc_loss = 0.08299883396054307
Trained batch 30 in epoch 5, gen_loss = 0.4090253782849158, disc_loss = 0.08206437459035267
Trained batch 31 in epoch 5, gen_loss = 0.4103397303260863, disc_loss = 0.07989714763243683
Trained batch 32 in epoch 5, gen_loss = 0.4104834817575686, disc_loss = 0.07863174054320111
Trained batch 33 in epoch 5, gen_loss = 0.40860093034365597, disc_loss = 0.07807931208106525
Trained batch 34 in epoch 5, gen_loss = 0.40811981516225, disc_loss = 0.07660471549523729
Trained batch 35 in epoch 5, gen_loss = 0.4075305076936881, disc_loss = 0.07504275169533987
Trained batch 36 in epoch 5, gen_loss = 0.4063503109925502, disc_loss = 0.07431713720733249
Trained batch 37 in epoch 5, gen_loss = 0.4073769077658653, disc_loss = 0.07642654062395818
Trained batch 38 in epoch 5, gen_loss = 0.4064265141884486, disc_loss = 0.07869608210734068
Trained batch 39 in epoch 5, gen_loss = 0.40692716278135777, disc_loss = 0.0771880529122427
Trained batch 40 in epoch 5, gen_loss = 0.40913348917554065, disc_loss = 0.07585160772702317
Trained batch 41 in epoch 5, gen_loss = 0.4089350349136761, disc_loss = 0.0752844916257475
Trained batch 42 in epoch 5, gen_loss = 0.4094390325074972, disc_loss = 0.07481480937797663
Trained batch 43 in epoch 5, gen_loss = 0.4112499386749484, disc_loss = 0.07989168076098642
Trained batch 44 in epoch 5, gen_loss = 0.4121614432997174, disc_loss = 0.07956647485908534
Trained batch 45 in epoch 5, gen_loss = 0.41136534285286197, disc_loss = 0.07822018300952471
Trained batch 46 in epoch 5, gen_loss = 0.41213457413176274, disc_loss = 0.07680888202516957
Trained batch 47 in epoch 5, gen_loss = 0.411092024606963, disc_loss = 0.07566104097835098
Trained batch 48 in epoch 5, gen_loss = 0.41184902343214774, disc_loss = 0.07435362077109059
Trained batch 49 in epoch 5, gen_loss = 0.41348704129457475, disc_loss = 0.07310383083298802
Trained batch 50 in epoch 5, gen_loss = 0.41371603485415964, disc_loss = 0.07198787938949525
Trained batch 51 in epoch 5, gen_loss = 0.41452061012387276, disc_loss = 0.07116593805571589
Trained batch 52 in epoch 5, gen_loss = 0.4152302238738762, disc_loss = 0.06999063386388545
Trained batch 53 in epoch 5, gen_loss = 0.4171489711712908, disc_loss = 0.06896736450424348
Trained batch 54 in epoch 5, gen_loss = 0.4185929615389217, disc_loss = 0.06803137292577462
Trained batch 55 in epoch 5, gen_loss = 0.4188058315111058, disc_loss = 0.0669315036419513
Trained batch 56 in epoch 5, gen_loss = 0.4209568994609933, disc_loss = 0.06591138725675512
Trained batch 57 in epoch 5, gen_loss = 0.4232373168242389, disc_loss = 0.0650232851922769
Trained batch 58 in epoch 5, gen_loss = 0.42411054872860343, disc_loss = 0.06405452728839749
Trained batch 59 in epoch 5, gen_loss = 0.42338723316788673, disc_loss = 0.06307975231514623
Trained batch 60 in epoch 5, gen_loss = 0.4245475699178508, disc_loss = 0.062277092926631694
Trained batch 61 in epoch 5, gen_loss = 0.42428827646278566, disc_loss = 0.06141608500582797
Trained batch 62 in epoch 5, gen_loss = 0.4245911933599956, disc_loss = 0.061060672396764396
Trained batch 63 in epoch 5, gen_loss = 0.4252988507505506, disc_loss = 0.06024022377823712
Trained batch 64 in epoch 5, gen_loss = 0.4261298837570044, disc_loss = 0.0594101879817362
Trained batch 65 in epoch 5, gen_loss = 0.42597058754075656, disc_loss = 0.0595247870043033
Trained batch 66 in epoch 5, gen_loss = 0.42747065803008294, disc_loss = 0.05923150505509172
Trained batch 67 in epoch 5, gen_loss = 0.42906760358635115, disc_loss = 0.059726345880121434
Trained batch 68 in epoch 5, gen_loss = 0.42842148114805634, disc_loss = 0.059206289151494486
Trained batch 69 in epoch 5, gen_loss = 0.427578738118921, disc_loss = 0.05874828449450433
Trained batch 70 in epoch 5, gen_loss = 0.4263399732364735, disc_loss = 0.05833704904062857
Trained batch 71 in epoch 5, gen_loss = 0.4265135003046857, disc_loss = 0.05774779057052607
Trained batch 72 in epoch 5, gen_loss = 0.4269803425628845, disc_loss = 0.057584462183438344
Trained batch 73 in epoch 5, gen_loss = 0.426184039059523, disc_loss = 0.05858534119545004
Trained batch 74 in epoch 5, gen_loss = 0.42667816976706185, disc_loss = 0.05892635512476166
Trained batch 75 in epoch 5, gen_loss = 0.42525707244088773, disc_loss = 0.059328995234529044
Trained batch 76 in epoch 5, gen_loss = 0.424326412670024, disc_loss = 0.06052922291148986
Trained batch 77 in epoch 5, gen_loss = 0.4239999084518506, disc_loss = 0.06080218660645187
Trained batch 78 in epoch 5, gen_loss = 0.42468134115768386, disc_loss = 0.0603295553628874
Trained batch 79 in epoch 5, gen_loss = 0.4245425557717681, disc_loss = 0.06009062345256098
Trained batch 80 in epoch 5, gen_loss = 0.42380354084350447, disc_loss = 0.05949834278313282
Trained batch 81 in epoch 5, gen_loss = 0.4221606830634722, disc_loss = 0.05993152468283547
Trained batch 82 in epoch 5, gen_loss = 0.4228441709854517, disc_loss = 0.061734944082661926
Trained batch 83 in epoch 5, gen_loss = 0.42286712481152444, disc_loss = 0.061815637069576906
Trained batch 84 in epoch 5, gen_loss = 0.422386754786267, disc_loss = 0.06159811768790378
Trained batch 85 in epoch 5, gen_loss = 0.4230004734424658, disc_loss = 0.06301646640112754
Trained batch 86 in epoch 5, gen_loss = 0.4228287210752224, disc_loss = 0.06450803898510406
Trained batch 87 in epoch 5, gen_loss = 0.4218257386237383, disc_loss = 0.06478789147645743
Trained batch 88 in epoch 5, gen_loss = 0.4221445360545362, disc_loss = 0.06457749502524064
Trained batch 89 in epoch 5, gen_loss = 0.4226010867291027, disc_loss = 0.06432708782764772
Trained batch 90 in epoch 5, gen_loss = 0.42132074246694756, disc_loss = 0.06523365600566779
Trained batch 91 in epoch 5, gen_loss = 0.4215660077398238, disc_loss = 0.06764744189264171
Trained batch 92 in epoch 5, gen_loss = 0.4215402704092764, disc_loss = 0.06787996922910053
Trained batch 93 in epoch 5, gen_loss = 0.4207262525216062, disc_loss = 0.06765924718607455
Trained batch 94 in epoch 5, gen_loss = 0.4208025287640722, disc_loss = 0.0677805391532418
Trained batch 95 in epoch 5, gen_loss = 0.42118681827560067, disc_loss = 0.06716596660650491
Trained batch 96 in epoch 5, gen_loss = 0.42122904833444613, disc_loss = 0.06715680105304442
Trained batch 97 in epoch 5, gen_loss = 0.42119966705842893, disc_loss = 0.06682832363745844
Trained batch 98 in epoch 5, gen_loss = 0.4211068886398065, disc_loss = 0.06630421902589274
Trained batch 99 in epoch 5, gen_loss = 0.42145718142390254, disc_loss = 0.0658338056365028
Trained batch 100 in epoch 5, gen_loss = 0.42145985527203816, disc_loss = 0.06523942723317017
Trained batch 101 in epoch 5, gen_loss = 0.4208754404794936, disc_loss = 0.0648069481876697
Trained batch 102 in epoch 5, gen_loss = 0.42036864118089956, disc_loss = 0.06522664718004395
Trained batch 103 in epoch 5, gen_loss = 0.42084110599870866, disc_loss = 0.0661875392184951
Trained batch 104 in epoch 5, gen_loss = 0.42040560912518277, disc_loss = 0.066083759468581
Trained batch 105 in epoch 5, gen_loss = 0.4209850291317364, disc_loss = 0.06578143071910401
Trained batch 106 in epoch 5, gen_loss = 0.42116026273954693, disc_loss = 0.06538967684642455
Trained batch 107 in epoch 5, gen_loss = 0.4218280661713194, disc_loss = 0.06489089196030465
Trained batch 108 in epoch 5, gen_loss = 0.422167292291965, disc_loss = 0.06441211923444216
Trained batch 109 in epoch 5, gen_loss = 0.42161388221112167, disc_loss = 0.06440538009628653
Trained batch 110 in epoch 5, gen_loss = 0.4221694272112202, disc_loss = 0.06419449850816179
Trained batch 111 in epoch 5, gen_loss = 0.4216713472934706, disc_loss = 0.0639901893030453
Trained batch 112 in epoch 5, gen_loss = 0.42053598231446426, disc_loss = 0.06539835748716002
Trained batch 113 in epoch 5, gen_loss = 0.4206410846427867, disc_loss = 0.06579626692262919
Trained batch 114 in epoch 5, gen_loss = 0.42065278615640556, disc_loss = 0.06554243963859652
Trained batch 115 in epoch 5, gen_loss = 0.42044192128654184, disc_loss = 0.06542789464784336
Trained batch 116 in epoch 5, gen_loss = 0.4200223466524711, disc_loss = 0.06514513757652961
Trained batch 117 in epoch 5, gen_loss = 0.4204488367599956, disc_loss = 0.06501326224593035
Trained batch 118 in epoch 5, gen_loss = 0.4201231036616975, disc_loss = 0.06465366226816628
Trained batch 119 in epoch 5, gen_loss = 0.41945855331917603, disc_loss = 0.06516531005036086
Trained batch 120 in epoch 5, gen_loss = 0.4197717768347953, disc_loss = 0.0666626505322816
Trained batch 121 in epoch 5, gen_loss = 0.4190269446030992, disc_loss = 0.06623256990502847
Trained batch 122 in epoch 5, gen_loss = 0.41805022434005895, disc_loss = 0.06681140871885104
Trained batch 123 in epoch 5, gen_loss = 0.418403371808029, disc_loss = 0.0663649974195587
Trained batch 124 in epoch 5, gen_loss = 0.4184114683866501, disc_loss = 0.06657333984225988
Trained batch 125 in epoch 5, gen_loss = 0.4185690509658011, disc_loss = 0.06679044541947189
Trained batch 126 in epoch 5, gen_loss = 0.4188672284207006, disc_loss = 0.0667518954210746
Trained batch 127 in epoch 5, gen_loss = 0.4188024684553966, disc_loss = 0.06635095075034769
Trained batch 128 in epoch 5, gen_loss = 0.419451253243195, disc_loss = 0.06593637134475533
Trained batch 129 in epoch 5, gen_loss = 0.41863769143819807, disc_loss = 0.06684712699542825
Trained batch 130 in epoch 5, gen_loss = 0.4194588382508009, disc_loss = 0.06765717382450367
Trained batch 131 in epoch 5, gen_loss = 0.41915562398957484, disc_loss = 0.06782058418276861
Trained batch 132 in epoch 5, gen_loss = 0.41912743527638285, disc_loss = 0.06847274903544134
Trained batch 133 in epoch 5, gen_loss = 0.4192638371640177, disc_loss = 0.06824895003532518
Trained batch 134 in epoch 5, gen_loss = 0.4194207815108476, disc_loss = 0.067849947946767
Trained batch 135 in epoch 5, gen_loss = 0.41923743891803655, disc_loss = 0.06744237735812716
Trained batch 136 in epoch 5, gen_loss = 0.4199795706646286, disc_loss = 0.06711029138987082
Trained batch 137 in epoch 5, gen_loss = 0.4192515483153039, disc_loss = 0.06683776134868032
Trained batch 138 in epoch 5, gen_loss = 0.4188311156823481, disc_loss = 0.06645141105777283
Trained batch 139 in epoch 5, gen_loss = 0.41868726004447254, disc_loss = 0.06620518919745726
Trained batch 140 in epoch 5, gen_loss = 0.4184619028728904, disc_loss = 0.06604444685372267
Trained batch 141 in epoch 5, gen_loss = 0.418301506046678, disc_loss = 0.06685903962885201
Trained batch 142 in epoch 5, gen_loss = 0.41817661359176767, disc_loss = 0.06739900006515372
Trained batch 143 in epoch 5, gen_loss = 0.4181065483846598, disc_loss = 0.06712911100152673
Trained batch 144 in epoch 5, gen_loss = 0.41840137890700635, disc_loss = 0.06771407855096562
Trained batch 145 in epoch 5, gen_loss = 0.4178906823061917, disc_loss = 0.06763533380979748
Trained batch 146 in epoch 5, gen_loss = 0.4176938514522955, disc_loss = 0.06732600276694209
Trained batch 147 in epoch 5, gen_loss = 0.4183166418727991, disc_loss = 0.06704039239274287
Trained batch 148 in epoch 5, gen_loss = 0.4181097902907621, disc_loss = 0.06665938073181665
Trained batch 149 in epoch 5, gen_loss = 0.4178536946574847, disc_loss = 0.06724030922477443
Trained batch 150 in epoch 5, gen_loss = 0.4180249979361793, disc_loss = 0.06713379757318473
Trained batch 151 in epoch 5, gen_loss = 0.4178319358708043, disc_loss = 0.06701180898265816
Trained batch 152 in epoch 5, gen_loss = 0.4178149572579689, disc_loss = 0.06669287498602096
Trained batch 153 in epoch 5, gen_loss = 0.4173206105441242, disc_loss = 0.06652636950013119
Trained batch 154 in epoch 5, gen_loss = 0.41655245779022093, disc_loss = 0.06634929010103788
Trained batch 155 in epoch 5, gen_loss = 0.41750491878543144, disc_loss = 0.06668187408612515
Trained batch 156 in epoch 5, gen_loss = 0.4174951302587606, disc_loss = 0.06637022660297763
Trained batch 157 in epoch 5, gen_loss = 0.4170964953454235, disc_loss = 0.0660819151627395
Trained batch 158 in epoch 5, gen_loss = 0.41667678155614146, disc_loss = 0.0657835062534648
Trained batch 159 in epoch 5, gen_loss = 0.41670549744740126, disc_loss = 0.06583041740232147
Trained batch 160 in epoch 5, gen_loss = 0.4166436240724895, disc_loss = 0.06749008517851185
Trained batch 161 in epoch 5, gen_loss = 0.4158387078363218, disc_loss = 0.06846591798634624
Trained batch 162 in epoch 5, gen_loss = 0.4154525127696113, disc_loss = 0.0687589748745407
Trained batch 163 in epoch 5, gen_loss = 0.4151636679179785, disc_loss = 0.07036570869045468
Trained batch 164 in epoch 5, gen_loss = 0.41560860772927605, disc_loss = 0.07123771617471268
Trained batch 165 in epoch 5, gen_loss = 0.4157491013048643, disc_loss = 0.07116903463962028
Trained batch 166 in epoch 5, gen_loss = 0.41557402319893866, disc_loss = 0.0711412313868275
Trained batch 167 in epoch 5, gen_loss = 0.4156085198656434, disc_loss = 0.07102774682876077
Trained batch 168 in epoch 5, gen_loss = 0.4154522199426177, disc_loss = 0.07080211916376324
Trained batch 169 in epoch 5, gen_loss = 0.41515580424491094, disc_loss = 0.07066171796554152
Trained batch 170 in epoch 5, gen_loss = 0.41510965592331356, disc_loss = 0.07043235832335133
Trained batch 171 in epoch 5, gen_loss = 0.41501232158652573, disc_loss = 0.07043867983292182
Trained batch 172 in epoch 5, gen_loss = 0.4152367906591107, disc_loss = 0.07014781258720366
Trained batch 173 in epoch 5, gen_loss = 0.4154673459372301, disc_loss = 0.06997756853207261
Trained batch 174 in epoch 5, gen_loss = 0.415250375185694, disc_loss = 0.07004048015922308
Trained batch 175 in epoch 5, gen_loss = 0.41531823279166763, disc_loss = 0.06982315903720022
Trained batch 176 in epoch 5, gen_loss = 0.4155216209464154, disc_loss = 0.06959729808472138
Trained batch 177 in epoch 5, gen_loss = 0.415342559389184, disc_loss = 0.0693991159591196
Trained batch 178 in epoch 5, gen_loss = 0.4154809827411641, disc_loss = 0.06909891162275769
Trained batch 179 in epoch 5, gen_loss = 0.41533327160610095, disc_loss = 0.0688848501433515
Trained batch 180 in epoch 5, gen_loss = 0.41533342687135244, disc_loss = 0.06870049297377386
Trained batch 181 in epoch 5, gen_loss = 0.41539452716216935, disc_loss = 0.06865452718665148
Trained batch 182 in epoch 5, gen_loss = 0.4150368135646393, disc_loss = 0.06846315745020011
Trained batch 183 in epoch 5, gen_loss = 0.41524685101340647, disc_loss = 0.06815244578857622
Trained batch 184 in epoch 5, gen_loss = 0.41559723704247864, disc_loss = 0.06800240585832178
Trained batch 185 in epoch 5, gen_loss = 0.41589801181708613, disc_loss = 0.06779804329578114
Trained batch 186 in epoch 5, gen_loss = 0.4156151075254787, disc_loss = 0.0675340611338217
Trained batch 187 in epoch 5, gen_loss = 0.4159420623265682, disc_loss = 0.06728882068629435
Trained batch 188 in epoch 5, gen_loss = 0.41596966217119224, disc_loss = 0.06697295380697127
Trained batch 189 in epoch 5, gen_loss = 0.41594518164270805, disc_loss = 0.06669833439304249
Trained batch 190 in epoch 5, gen_loss = 0.41597832349270425, disc_loss = 0.06640383606308496
Trained batch 191 in epoch 5, gen_loss = 0.41603721406621236, disc_loss = 0.0661781187542753
Trained batch 192 in epoch 5, gen_loss = 0.41630073200544543, disc_loss = 0.06595154427271818
Trained batch 193 in epoch 5, gen_loss = 0.41634517424192624, disc_loss = 0.06570828495038308
Trained batch 194 in epoch 5, gen_loss = 0.4162341167529424, disc_loss = 0.06559905694702114
Trained batch 195 in epoch 5, gen_loss = 0.41635250596671686, disc_loss = 0.06533556112458891
Trained batch 196 in epoch 5, gen_loss = 0.41574925206942004, disc_loss = 0.06520567448847563
Trained batch 197 in epoch 5, gen_loss = 0.415699369753852, disc_loss = 0.06495538452931802
Trained batch 198 in epoch 5, gen_loss = 0.41565598173057616, disc_loss = 0.06468267146563485
Trained batch 199 in epoch 5, gen_loss = 0.41568711943924425, disc_loss = 0.06441861062543466
Trained batch 200 in epoch 5, gen_loss = 0.41592627237388746, disc_loss = 0.06416828807359978
Trained batch 201 in epoch 5, gen_loss = 0.416146879517796, disc_loss = 0.06393675875186108
Trained batch 202 in epoch 5, gen_loss = 0.4161663433454307, disc_loss = 0.06368708739681124
Trained batch 203 in epoch 5, gen_loss = 0.41595031971148416, disc_loss = 0.06346168407175105
Trained batch 204 in epoch 5, gen_loss = 0.41579744590491785, disc_loss = 0.06337899461888322
Trained batch 205 in epoch 5, gen_loss = 0.4154664607157985, disc_loss = 0.06311241143328834
Trained batch 206 in epoch 5, gen_loss = 0.41528007568080644, disc_loss = 0.0628568720328959
Trained batch 207 in epoch 5, gen_loss = 0.41572012917066997, disc_loss = 0.06269714599161838
Trained batch 208 in epoch 5, gen_loss = 0.41575287638954, disc_loss = 0.06244507147017064
Trained batch 209 in epoch 5, gen_loss = 0.4156061644355456, disc_loss = 0.06222700372205249
Trained batch 210 in epoch 5, gen_loss = 0.41486936419213555, disc_loss = 0.06233571962590254
Trained batch 211 in epoch 5, gen_loss = 0.4149997440289776, disc_loss = 0.062213305122535326
Trained batch 212 in epoch 5, gen_loss = 0.4152257937080983, disc_loss = 0.061942407384759667
Trained batch 213 in epoch 5, gen_loss = 0.41489111896708747, disc_loss = 0.06192314083835928
Trained batch 214 in epoch 5, gen_loss = 0.41476781389047934, disc_loss = 0.06311858728268119
Trained batch 215 in epoch 5, gen_loss = 0.41457086987793446, disc_loss = 0.06310964457225055
Trained batch 216 in epoch 5, gen_loss = 0.41417061396732857, disc_loss = 0.06310668696267402
Trained batch 217 in epoch 5, gen_loss = 0.4139023578358353, disc_loss = 0.06289636419334133
Trained batch 218 in epoch 5, gen_loss = 0.413746576943354, disc_loss = 0.06343318393122252
Trained batch 219 in epoch 5, gen_loss = 0.41346305547790096, disc_loss = 0.06384791109118272
Trained batch 220 in epoch 5, gen_loss = 0.4133600295264257, disc_loss = 0.06365022613199184
Trained batch 221 in epoch 5, gen_loss = 0.4138303073542612, disc_loss = 0.06360401745533219
Trained batch 222 in epoch 5, gen_loss = 0.4135497241143154, disc_loss = 0.06346781283299618
Trained batch 223 in epoch 5, gen_loss = 0.41364105039143134, disc_loss = 0.06325095481172736
Trained batch 224 in epoch 5, gen_loss = 0.41389513035615283, disc_loss = 0.06312853450576464
Trained batch 225 in epoch 5, gen_loss = 0.4136726549637001, disc_loss = 0.06297832824685405
Trained batch 226 in epoch 5, gen_loss = 0.41387743683375977, disc_loss = 0.06337631784281017
Trained batch 227 in epoch 5, gen_loss = 0.41379065347606675, disc_loss = 0.06374675778900846
Trained batch 228 in epoch 5, gen_loss = 0.41387834058318074, disc_loss = 0.06357776864907627
Trained batch 229 in epoch 5, gen_loss = 0.41399573184873745, disc_loss = 0.06347670665253764
Trained batch 230 in epoch 5, gen_loss = 0.41331337431034487, disc_loss = 0.06390411809925393
Trained batch 231 in epoch 5, gen_loss = 0.4133166094663842, disc_loss = 0.0638382582250854
Trained batch 232 in epoch 5, gen_loss = 0.4132423226285902, disc_loss = 0.06371107528010152
Trained batch 233 in epoch 5, gen_loss = 0.41300822011171245, disc_loss = 0.06353684400136654
Trained batch 234 in epoch 5, gen_loss = 0.41304884787569657, disc_loss = 0.06329951522118868
Trained batch 235 in epoch 5, gen_loss = 0.4131354499545138, disc_loss = 0.0630802322668418
Trained batch 236 in epoch 5, gen_loss = 0.4127281121438063, disc_loss = 0.06292155959529465
Trained batch 237 in epoch 5, gen_loss = 0.4125145455243207, disc_loss = 0.06297429355972704
Trained batch 238 in epoch 5, gen_loss = 0.4127738071161334, disc_loss = 0.06276491686125056
Trained batch 239 in epoch 5, gen_loss = 0.41281452495604753, disc_loss = 0.06268486774448927
Trained batch 240 in epoch 5, gen_loss = 0.4125675704345664, disc_loss = 0.06258785633053399
Trained batch 241 in epoch 5, gen_loss = 0.41264892357193733, disc_loss = 0.0623559154808706
Trained batch 242 in epoch 5, gen_loss = 0.41265658310656683, disc_loss = 0.062423500117420413
Trained batch 243 in epoch 5, gen_loss = 0.41211677397616575, disc_loss = 0.06292262708111743
Trained batch 244 in epoch 5, gen_loss = 0.412067164754381, disc_loss = 0.06282993328130367
Trained batch 245 in epoch 5, gen_loss = 0.41204652438561123, disc_loss = 0.06281320697332664
Trained batch 246 in epoch 5, gen_loss = 0.41182889925082206, disc_loss = 0.06275329981300874
Trained batch 247 in epoch 5, gen_loss = 0.41172503746084627, disc_loss = 0.06253912171439058
Trained batch 248 in epoch 5, gen_loss = 0.4118043566683689, disc_loss = 0.06231565287254422
Trained batch 249 in epoch 5, gen_loss = 0.4118953399062157, disc_loss = 0.0625133833438158
Trained batch 250 in epoch 5, gen_loss = 0.41151739668798637, disc_loss = 0.064238212334801
Trained batch 251 in epoch 5, gen_loss = 0.4112879135424182, disc_loss = 0.06426933743355293
Trained batch 252 in epoch 5, gen_loss = 0.4116376985320932, disc_loss = 0.06441509680962373
Trained batch 253 in epoch 5, gen_loss = 0.4113400081597914, disc_loss = 0.06448869564108492
Trained batch 254 in epoch 5, gen_loss = 0.4113962994486678, disc_loss = 0.0652661707325309
Trained batch 255 in epoch 5, gen_loss = 0.4112304051523097, disc_loss = 0.0651437088381499
Trained batch 256 in epoch 5, gen_loss = 0.4115705731893792, disc_loss = 0.06547392093022046
Trained batch 257 in epoch 5, gen_loss = 0.4114070869115896, disc_loss = 0.06527816819734583
Trained batch 258 in epoch 5, gen_loss = 0.41142606430302253, disc_loss = 0.06509249860917049
Trained batch 259 in epoch 5, gen_loss = 0.41132862550707966, disc_loss = 0.0651922288350761
Trained batch 260 in epoch 5, gen_loss = 0.41153231759866077, disc_loss = 0.06600549627966122
Trained batch 261 in epoch 5, gen_loss = 0.4117018100983314, disc_loss = 0.06578545958756377
Trained batch 262 in epoch 5, gen_loss = 0.41160676047602535, disc_loss = 0.06578683531258836
Trained batch 263 in epoch 5, gen_loss = 0.4115915380305413, disc_loss = 0.06574396358337253
Trained batch 264 in epoch 5, gen_loss = 0.41154264869554985, disc_loss = 0.06571068853350742
Trained batch 265 in epoch 5, gen_loss = 0.411237644017639, disc_loss = 0.06561480365567525
Trained batch 266 in epoch 5, gen_loss = 0.41100866221979765, disc_loss = 0.06553508459558982
Trained batch 267 in epoch 5, gen_loss = 0.41094061548807725, disc_loss = 0.06535711596414114
Trained batch 268 in epoch 5, gen_loss = 0.41100864223166467, disc_loss = 0.0651650997709663
Trained batch 269 in epoch 5, gen_loss = 0.4112524296950411, disc_loss = 0.06494465352174032
Trained batch 270 in epoch 5, gen_loss = 0.4111150625776981, disc_loss = 0.0647601475818873
Trained batch 271 in epoch 5, gen_loss = 0.41107264933559823, disc_loss = 0.0645540836318533
Trained batch 272 in epoch 5, gen_loss = 0.4112346782024963, disc_loss = 0.0643365894710379
Trained batch 273 in epoch 5, gen_loss = 0.41147784241577134, disc_loss = 0.06413013773059377
Trained batch 274 in epoch 5, gen_loss = 0.4113926714658737, disc_loss = 0.06402607708661394
Trained batch 275 in epoch 5, gen_loss = 0.41155774108525633, disc_loss = 0.06382005931168416
Trained batch 276 in epoch 5, gen_loss = 0.4113767137919092, disc_loss = 0.06366306797026351
Trained batch 277 in epoch 5, gen_loss = 0.41143455817330654, disc_loss = 0.06354942129382181
Trained batch 278 in epoch 5, gen_loss = 0.411246847668429, disc_loss = 0.06339079603105516
Trained batch 279 in epoch 5, gen_loss = 0.41123753802052565, disc_loss = 0.06324417536712384
Trained batch 280 in epoch 5, gen_loss = 0.41115870016537526, disc_loss = 0.06304424967835541
Trained batch 281 in epoch 5, gen_loss = 0.4111057175917828, disc_loss = 0.06298149563207008
Trained batch 282 in epoch 5, gen_loss = 0.4111300827441704, disc_loss = 0.06280780006891162
Trained batch 283 in epoch 5, gen_loss = 0.41098573704210806, disc_loss = 0.06271456088706799
Trained batch 284 in epoch 5, gen_loss = 0.41093492272653076, disc_loss = 0.06255955725352753
Trained batch 285 in epoch 5, gen_loss = 0.41101449358088155, disc_loss = 0.062397412250756276
Trained batch 286 in epoch 5, gen_loss = 0.4106623442642365, disc_loss = 0.0625277242318237
Trained batch 287 in epoch 5, gen_loss = 0.41057089990418816, disc_loss = 0.06278899749061868
Trained batch 288 in epoch 5, gen_loss = 0.4107020740174917, disc_loss = 0.06260178021435661
Trained batch 289 in epoch 5, gen_loss = 0.4106493564001445, disc_loss = 0.06248573913110484
Trained batch 290 in epoch 5, gen_loss = 0.4107325733015218, disc_loss = 0.062365574907844314
Trained batch 291 in epoch 5, gen_loss = 0.41100826497151427, disc_loss = 0.0621780301157181
Trained batch 292 in epoch 5, gen_loss = 0.410879089106065, disc_loss = 0.06206811666043647
Trained batch 293 in epoch 5, gen_loss = 0.4109483908126954, disc_loss = 0.06191715081444099
Trained batch 294 in epoch 5, gen_loss = 0.411001070323637, disc_loss = 0.061770966443848815
Trained batch 295 in epoch 5, gen_loss = 0.4109732964252298, disc_loss = 0.061617884215445735
Trained batch 296 in epoch 5, gen_loss = 0.4110394114697421, disc_loss = 0.06143561580378299
Trained batch 297 in epoch 5, gen_loss = 0.4110985733818688, disc_loss = 0.061247195534395595
Trained batch 298 in epoch 5, gen_loss = 0.4109158775579172, disc_loss = 0.061192249983586494
Trained batch 299 in epoch 5, gen_loss = 0.4110278138021628, disc_loss = 0.06103115305770188
Trained batch 300 in epoch 5, gen_loss = 0.41076901827341694, disc_loss = 0.06105160067612893
Trained batch 301 in epoch 5, gen_loss = 0.4108371909781797, disc_loss = 0.06094002490400627
Trained batch 302 in epoch 5, gen_loss = 0.41087004625954643, disc_loss = 0.06078174666781286
Trained batch 303 in epoch 5, gen_loss = 0.4107317155423133, disc_loss = 0.06065061229654882
Trained batch 304 in epoch 5, gen_loss = 0.41087947140951625, disc_loss = 0.060480690431460496
Trained batch 305 in epoch 5, gen_loss = 0.410888739222405, disc_loss = 0.06030187109527878
Trained batch 306 in epoch 5, gen_loss = 0.4108524809345749, disc_loss = 0.06012909455340149
Trained batch 307 in epoch 5, gen_loss = 0.4111104357455458, disc_loss = 0.05997622228384792
Trained batch 308 in epoch 5, gen_loss = 0.411136916106187, disc_loss = 0.059813896622086804
Trained batch 309 in epoch 5, gen_loss = 0.4110713043039845, disc_loss = 0.05970133946787926
Trained batch 310 in epoch 5, gen_loss = 0.4111066514751919, disc_loss = 0.05956107476827991
Trained batch 311 in epoch 5, gen_loss = 0.41140325009249723, disc_loss = 0.05942320745462217
Trained batch 312 in epoch 5, gen_loss = 0.41132143392159154, disc_loss = 0.05925300292158946
Trained batch 313 in epoch 5, gen_loss = 0.41134731685090214, disc_loss = 0.059082078682199404
Trained batch 314 in epoch 5, gen_loss = 0.41140026880635155, disc_loss = 0.05893505647896774
Trained batch 315 in epoch 5, gen_loss = 0.4114545016443428, disc_loss = 0.05876814632652964
Trained batch 316 in epoch 5, gen_loss = 0.4114564991429777, disc_loss = 0.05859878632807017
Trained batch 317 in epoch 5, gen_loss = 0.41129161000439207, disc_loss = 0.05847634511572197
Trained batch 318 in epoch 5, gen_loss = 0.4113080345070848, disc_loss = 0.05832537935118316
Trained batch 319 in epoch 5, gen_loss = 0.41146865994669496, disc_loss = 0.05817269922408741
Trained batch 320 in epoch 5, gen_loss = 0.41148475114244537, disc_loss = 0.058002379154235215
Trained batch 321 in epoch 5, gen_loss = 0.4114789366259338, disc_loss = 0.05786887433680688
Trained batch 322 in epoch 5, gen_loss = 0.41146894565123154, disc_loss = 0.057710649850763865
Trained batch 323 in epoch 5, gen_loss = 0.4116792740001355, disc_loss = 0.057555625458063996
Trained batch 324 in epoch 5, gen_loss = 0.4115331561290301, disc_loss = 0.05744197085069922
Trained batch 325 in epoch 5, gen_loss = 0.41152152140264864, disc_loss = 0.057364455882768416
Trained batch 326 in epoch 5, gen_loss = 0.4114343251019078, disc_loss = 0.057225720280502275
Trained batch 327 in epoch 5, gen_loss = 0.411227493160745, disc_loss = 0.05754089323809461
Trained batch 328 in epoch 5, gen_loss = 0.41161290739626144, disc_loss = 0.058441262704951515
Trained batch 329 in epoch 5, gen_loss = 0.4116396886381236, disc_loss = 0.058694703788073226
Trained batch 330 in epoch 5, gen_loss = 0.4114892056431295, disc_loss = 0.05889992956269049
Trained batch 331 in epoch 5, gen_loss = 0.41150779290551165, disc_loss = 0.05885816496903503
Trained batch 332 in epoch 5, gen_loss = 0.4114314075615313, disc_loss = 0.05873433718815804
Trained batch 333 in epoch 5, gen_loss = 0.41132937733106273, disc_loss = 0.05865150961249754
Trained batch 334 in epoch 5, gen_loss = 0.41106153081602126, disc_loss = 0.05860748073197345
Trained batch 335 in epoch 5, gen_loss = 0.41088249902462676, disc_loss = 0.05855916414016281
Trained batch 336 in epoch 5, gen_loss = 0.41066100676088024, disc_loss = 0.0585407566304045
Trained batch 337 in epoch 5, gen_loss = 0.4106869976636926, disc_loss = 0.05853787536413227
Trained batch 338 in epoch 5, gen_loss = 0.4107394776249354, disc_loss = 0.0585895352365015
Trained batch 339 in epoch 5, gen_loss = 0.41071692867314114, disc_loss = 0.058641471211141084
Trained batch 340 in epoch 5, gen_loss = 0.4105852631267564, disc_loss = 0.05855781627720621
Trained batch 341 in epoch 5, gen_loss = 0.4105652771585169, disc_loss = 0.05851780768206114
Trained batch 342 in epoch 5, gen_loss = 0.410513023636779, disc_loss = 0.058431261831367765
Trained batch 343 in epoch 5, gen_loss = 0.41066371385268, disc_loss = 0.058345856287159284
Trained batch 344 in epoch 5, gen_loss = 0.4108878618997076, disc_loss = 0.05827533064032162
Trained batch 345 in epoch 5, gen_loss = 0.41096608947984054, disc_loss = 0.05818295260390665
Trained batch 346 in epoch 5, gen_loss = 0.41095356591668525, disc_loss = 0.058136663956551544
Trained batch 347 in epoch 5, gen_loss = 0.41091724164013205, disc_loss = 0.05798741264921752
Trained batch 348 in epoch 5, gen_loss = 0.4109385872211702, disc_loss = 0.05810157015097773
Trained batch 349 in epoch 5, gen_loss = 0.41088614587272915, disc_loss = 0.05820823439263872
Trained batch 350 in epoch 5, gen_loss = 0.41103511356730066, disc_loss = 0.05811675943359945
Trained batch 351 in epoch 5, gen_loss = 0.41130606207827275, disc_loss = 0.058021574342009524
Trained batch 352 in epoch 5, gen_loss = 0.41144720171565036, disc_loss = 0.05792940209326849
Trained batch 353 in epoch 5, gen_loss = 0.41142189288038317, disc_loss = 0.05794231333417323
Trained batch 354 in epoch 5, gen_loss = 0.41164051172598987, disc_loss = 0.057815756535970826
Trained batch 355 in epoch 5, gen_loss = 0.4117026561347956, disc_loss = 0.05769340066354345
Trained batch 356 in epoch 5, gen_loss = 0.4117047271224297, disc_loss = 0.057554544596632826
Trained batch 357 in epoch 5, gen_loss = 0.4120113099170797, disc_loss = 0.05744612472672952
Trained batch 358 in epoch 5, gen_loss = 0.41212541699243455, disc_loss = 0.05739328065695122
Trained batch 359 in epoch 5, gen_loss = 0.41223823879328036, disc_loss = 0.057254473398077405
Trained batch 360 in epoch 5, gen_loss = 0.41240262873780364, disc_loss = 0.05711895781195106
Trained batch 361 in epoch 5, gen_loss = 0.41227425762467623, disc_loss = 0.057013640505678496
Trained batch 362 in epoch 5, gen_loss = 0.4121981762739581, disc_loss = 0.05689740512576519
Trained batch 363 in epoch 5, gen_loss = 0.4120387339575605, disc_loss = 0.056757486736207466
Trained batch 364 in epoch 5, gen_loss = 0.41220388816644066, disc_loss = 0.05662325841872251
Trained batch 365 in epoch 5, gen_loss = 0.41222756795707294, disc_loss = 0.0565291717826628
Trained batch 366 in epoch 5, gen_loss = 0.4122151137616394, disc_loss = 0.056448692991334835
Trained batch 367 in epoch 5, gen_loss = 0.41219784614994476, disc_loss = 0.05631057775336439
Trained batch 368 in epoch 5, gen_loss = 0.4122678010363566, disc_loss = 0.05617403782157071
Trained batch 369 in epoch 5, gen_loss = 0.41246933771951777, disc_loss = 0.056066309771425016
Trained batch 370 in epoch 5, gen_loss = 0.41260779526516433, disc_loss = 0.05593553658529634
Trained batch 371 in epoch 5, gen_loss = 0.4127565108399878, disc_loss = 0.05580601418486005
Trained batch 372 in epoch 5, gen_loss = 0.41284180602343407, disc_loss = 0.0556674871653638
Trained batch 373 in epoch 5, gen_loss = 0.41281283702601723, disc_loss = 0.05553207035863742
Trained batch 374 in epoch 5, gen_loss = 0.4128590794801712, disc_loss = 0.05539422155047456
Trained batch 375 in epoch 5, gen_loss = 0.4129622854847223, disc_loss = 0.05532370363684133
Trained batch 376 in epoch 5, gen_loss = 0.41290327894750894, disc_loss = 0.055231499780878546
Trained batch 377 in epoch 5, gen_loss = 0.4132890008665897, disc_loss = 0.055115793630845414
Trained batch 378 in epoch 5, gen_loss = 0.41324077774635404, disc_loss = 0.05498974970455888
Trained batch 379 in epoch 5, gen_loss = 0.4132429998564093, disc_loss = 0.05485620659187828
Trained batch 380 in epoch 5, gen_loss = 0.4131734906610229, disc_loss = 0.05472365889106718
Trained batch 381 in epoch 5, gen_loss = 0.4131012746566877, disc_loss = 0.05459036997882698
Trained batch 382 in epoch 5, gen_loss = 0.4129921608354031, disc_loss = 0.054519179342168704
Trained batch 383 in epoch 5, gen_loss = 0.4128831070459758, disc_loss = 0.054412586080313
Trained batch 384 in epoch 5, gen_loss = 0.4128590663919201, disc_loss = 0.05428957254746808
Trained batch 385 in epoch 5, gen_loss = 0.4129729814866046, disc_loss = 0.054171954307565225
Trained batch 386 in epoch 5, gen_loss = 0.4129326216857255, disc_loss = 0.054077498279680385
Trained batch 387 in epoch 5, gen_loss = 0.4128840631354101, disc_loss = 0.05396024278573903
Trained batch 388 in epoch 5, gen_loss = 0.4130372842893502, disc_loss = 0.05385737182814293
Trained batch 389 in epoch 5, gen_loss = 0.4131019659913503, disc_loss = 0.05375038420912834
Trained batch 390 in epoch 5, gen_loss = 0.4130888417782381, disc_loss = 0.053641576093057045
Trained batch 391 in epoch 5, gen_loss = 0.4128591711347809, disc_loss = 0.053533378087473577
Trained batch 392 in epoch 5, gen_loss = 0.41277162298446396, disc_loss = 0.053433349774913444
Trained batch 393 in epoch 5, gen_loss = 0.41248271372263806, disc_loss = 0.05335402245890954
Trained batch 394 in epoch 5, gen_loss = 0.4125204842679108, disc_loss = 0.05325637524299135
Trained batch 395 in epoch 5, gen_loss = 0.4125574237544729, disc_loss = 0.05313633449288612
Trained batch 396 in epoch 5, gen_loss = 0.4125954699080897, disc_loss = 0.05302616092376411
Trained batch 397 in epoch 5, gen_loss = 0.41269432161770875, disc_loss = 0.052907472753068945
Trained batch 399 in epoch 5, gen_loss = 0.41263035509735346, disc_loss = 0.05268558842537459
Trained batch 400 in epoch 5, gen_loss = 0.41261534615793727, disc_loss = 0.05257122371255181
Trained batch 401 in epoch 5, gen_loss = 0.4128835544879757, disc_loss = 0.05246591388968408
Trained batch 402 in epoch 5, gen_loss = 0.4128492164330802, disc_loss = 0.05236535957811063
Trained batch 403 in epoch 5, gen_loss = 0.412920728436496, disc_loss = 0.052297686132726874
Trained batch 404 in epoch 5, gen_loss = 0.41279732603349806, disc_loss = 0.05227597541474726
Trained batch 405 in epoch 5, gen_loss = 0.41297536776424043, disc_loss = 0.052185795213132546
Trained batch 406 in epoch 5, gen_loss = 0.41291151992079667, disc_loss = 0.05207703976562425
Trained batch 407 in epoch 5, gen_loss = 0.412788338630515, disc_loss = 0.051990233791430536
Trained batch 408 in epoch 5, gen_loss = 0.4127786487049462, disc_loss = 0.051896010091173075
Trained batch 409 in epoch 5, gen_loss = 0.41262912019723796, disc_loss = 0.05192489450990518
Trained batch 410 in epoch 5, gen_loss = 0.4129622872655989, disc_loss = 0.05184222962718611
Trained batch 411 in epoch 5, gen_loss = 0.41300797075467205, disc_loss = 0.051795278341866556
Trained batch 412 in epoch 5, gen_loss = 0.4130650421392542, disc_loss = 0.051685239912797734
Trained batch 413 in epoch 5, gen_loss = 0.4130993717606517, disc_loss = 0.05158868088816621
Trained batch 414 in epoch 5, gen_loss = 0.4132299599518259, disc_loss = 0.05147911332244704
Trained batch 415 in epoch 5, gen_loss = 0.4132825900943807, disc_loss = 0.05137160226597469
Trained batch 416 in epoch 5, gen_loss = 0.41319152108913987, disc_loss = 0.05126173257419049
Trained batch 417 in epoch 5, gen_loss = 0.41308309426575757, disc_loss = 0.05115244264266583
Trained batch 418 in epoch 5, gen_loss = 0.41304915293446587, disc_loss = 0.05111269248585019
Trained batch 419 in epoch 5, gen_loss = 0.41305734958677065, disc_loss = 0.05100365520865169
Trained batch 420 in epoch 5, gen_loss = 0.41297281174223666, disc_loss = 0.05090507473674937
Trained batch 421 in epoch 5, gen_loss = 0.41302508585402187, disc_loss = 0.0507986798614343
Trained batch 422 in epoch 5, gen_loss = 0.41296249392043893, disc_loss = 0.05072017105232405
Trained batch 423 in epoch 5, gen_loss = 0.4128992306244261, disc_loss = 0.05066864257557581
Trained batch 424 in epoch 5, gen_loss = 0.4127047955639222, disc_loss = 0.05065854957929867
Trained batch 425 in epoch 5, gen_loss = 0.4127860543943347, disc_loss = 0.050562940726489564
Trained batch 426 in epoch 5, gen_loss = 0.4128183836610312, disc_loss = 0.050475446708539644
Trained batch 427 in epoch 5, gen_loss = 0.4128696782357782, disc_loss = 0.05038684083063973
Trained batch 428 in epoch 5, gen_loss = 0.4130680114030838, disc_loss = 0.05030396253593474
Trained batch 429 in epoch 5, gen_loss = 0.4132661907825359, disc_loss = 0.05029488136872736
Trained batch 430 in epoch 5, gen_loss = 0.413256517107968, disc_loss = 0.05021288217663367
Trained batch 431 in epoch 5, gen_loss = 0.4131013758963457, disc_loss = 0.05015192454933034
Trained batch 432 in epoch 5, gen_loss = 0.41315628092641365, disc_loss = 0.05005253241053303
Trained batch 433 in epoch 5, gen_loss = 0.4133090302348137, disc_loss = 0.04996001661255149
Trained batch 434 in epoch 5, gen_loss = 0.4132931077274783, disc_loss = 0.04985559160136029
Trained batch 435 in epoch 5, gen_loss = 0.413453921778213, disc_loss = 0.04976759697876683
Trained batch 436 in epoch 5, gen_loss = 0.4134556337065773, disc_loss = 0.04970023541357496
Trained batch 437 in epoch 5, gen_loss = 0.4133676629700617, disc_loss = 0.04978974254378734
Trained batch 438 in epoch 5, gen_loss = 0.41334199311385666, disc_loss = 0.04973753598828403
Trained batch 439 in epoch 5, gen_loss = 0.41355161060663786, disc_loss = 0.0496796260910659
Trained batch 440 in epoch 5, gen_loss = 0.41350469476376533, disc_loss = 0.04975167635560052
Trained batch 441 in epoch 5, gen_loss = 0.41352655792533005, disc_loss = 0.04986385796145363
Trained batch 442 in epoch 5, gen_loss = 0.41348146299072636, disc_loss = 0.04977811402304867
Trained batch 443 in epoch 5, gen_loss = 0.413627090050025, disc_loss = 0.049710539084133434
Trained batch 444 in epoch 5, gen_loss = 0.4135471884789092, disc_loss = 0.04964858149387612
Trained batch 445 in epoch 5, gen_loss = 0.4137827936777085, disc_loss = 0.04955236335867606
Trained batch 446 in epoch 5, gen_loss = 0.4137834858240964, disc_loss = 0.04968584119967316
Trained batch 447 in epoch 5, gen_loss = 0.41399777637395474, disc_loss = 0.05001728438998855
Trained batch 448 in epoch 5, gen_loss = 0.41406342237855914, disc_loss = 0.04994027853843845
Trained batch 449 in epoch 5, gen_loss = 0.41386896633439596, disc_loss = 0.049921101725453304
Trained batch 450 in epoch 5, gen_loss = 0.41377374599223127, disc_loss = 0.0498289567425624
Trained batch 451 in epoch 5, gen_loss = 0.4137842594851962, disc_loss = 0.04979662408493871
Trained batch 452 in epoch 5, gen_loss = 0.4140338159883786, disc_loss = 0.04981398728067594
Trained batch 453 in epoch 5, gen_loss = 0.4139915869165097, disc_loss = 0.04983813237729134
Trained batch 454 in epoch 5, gen_loss = 0.41369331161399464, disc_loss = 0.05007587885023555
Trained batch 455 in epoch 5, gen_loss = 0.4137205934772889, disc_loss = 0.05002029544496173
Trained batch 456 in epoch 5, gen_loss = 0.4139441492716645, disc_loss = 0.04994321319669958
Trained batch 457 in epoch 5, gen_loss = 0.4139717710916132, disc_loss = 0.05002521715629195
Trained batch 458 in epoch 5, gen_loss = 0.41400334924004956, disc_loss = 0.04995210672331028
Trained batch 459 in epoch 5, gen_loss = 0.41391667571404706, disc_loss = 0.04993022905267856
Trained batch 460 in epoch 5, gen_loss = 0.41387230561896676, disc_loss = 0.049841567068391046
Testing Epoch 5
  0%|          | 0/25 [00:00<?, ?it/s]
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-08-30 00:31:51,301

Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.42271894216537476, disc_loss = 0.018322907388210297
Trained batch 1 in epoch 6, gen_loss = 0.40724344551563263, disc_loss = 0.023156847804784775
Trained batch 2 in epoch 6, gen_loss = 0.3990285297234853, disc_loss = 0.028668959935506184
Trained batch 3 in epoch 6, gen_loss = 0.409585103392601, disc_loss = 0.029204323887825012
Trained batch 4 in epoch 6, gen_loss = 0.41299421191215513, disc_loss = 0.02489994904026389
Trained batch 5 in epoch 6, gen_loss = 0.40426718691984814, disc_loss = 0.0316523362416774
Trained batch 6 in epoch 6, gen_loss = 0.40792892234666006, disc_loss = 0.03148239631471889
Trained batch 7 in epoch 6, gen_loss = 0.41560452058911324, disc_loss = 0.03249793400755152
Trained batch 8 in epoch 6, gen_loss = 0.4124670624732971, disc_loss = 0.032719424977484673
Trained batch 9 in epoch 6, gen_loss = 0.4034256815910339, disc_loss = 0.030546352593228222
Trained batch 10 in epoch 6, gen_loss = 0.40291257067160174, disc_loss = 0.02901880523528565
Trained batch 11 in epoch 6, gen_loss = 0.40623769412438077, disc_loss = 0.027638046730620165
Trained batch 12 in epoch 6, gen_loss = 0.40436574816703796, disc_loss = 0.026740195981871624
Trained batch 13 in epoch 6, gen_loss = 0.4091826358011791, disc_loss = 0.02590707247145474
Trained batch 14 in epoch 6, gen_loss = 0.4086679518222809, disc_loss = 0.02461267588660121
Trained batch 15 in epoch 6, gen_loss = 0.4039417766034603, disc_loss = 0.024244955653557554
Trained batch 16 in epoch 6, gen_loss = 0.4002333914532381, disc_loss = 0.02499729233300861
Trained batch 17 in epoch 6, gen_loss = 0.4061668316523234, disc_loss = 0.024518144135880802
Trained batch 18 in epoch 6, gen_loss = 0.40661936370949997, disc_loss = 0.02374387397675922
Trained batch 19 in epoch 6, gen_loss = 0.40430532991886137, disc_loss = 0.024332532868720592
Trained batch 20 in epoch 6, gen_loss = 0.40879576688721064, disc_loss = 0.024165529425122907
Trained batch 21 in epoch 6, gen_loss = 0.41004442355849524, disc_loss = 0.0235652148257941
Trained batch 22 in epoch 6, gen_loss = 0.40878677109013434, disc_loss = 0.022855969085155622
Trained batch 23 in epoch 6, gen_loss = 0.4084644267956416, disc_loss = 0.02243136294418946
Trained batch 24 in epoch 6, gen_loss = 0.4096373188495636, disc_loss = 0.022033928204327823
Trained batch 25 in epoch 6, gen_loss = 0.40730885015084195, disc_loss = 0.02142868389805349
Trained batch 26 in epoch 6, gen_loss = 0.4074840435275325, disc_loss = 0.02111560297715995
Trained batch 27 in epoch 6, gen_loss = 0.40588206372090746, disc_loss = 0.020540134365936474
Trained batch 28 in epoch 6, gen_loss = 0.4033702704413184, disc_loss = 0.02112094754481624
Trained batch 29 in epoch 6, gen_loss = 0.4040662964185079, disc_loss = 0.021807387393588822
Trained batch 30 in epoch 6, gen_loss = 0.405008465051651, disc_loss = 0.021371610597857544
Trained batch 31 in epoch 6, gen_loss = 0.4056491879746318, disc_loss = 0.020871977481874637
Trained batch 32 in epoch 6, gen_loss = 0.40377936038103973, disc_loss = 0.023122739540695242
Trained batch 33 in epoch 6, gen_loss = 0.40144910444231596, disc_loss = 0.025013145210002277
Trained batch 34 in epoch 6, gen_loss = 0.399141777413232, disc_loss = 0.0245426024576383
Trained batch 35 in epoch 6, gen_loss = 0.3976891355382072, disc_loss = 0.024466960264059406
Trained batch 36 in epoch 6, gen_loss = 0.39719365819080454, disc_loss = 0.02397562698083552
Trained batch 37 in epoch 6, gen_loss = 0.39625578334456996, disc_loss = 0.02475696403876339
Trained batch 38 in epoch 6, gen_loss = 0.3991187658065405, disc_loss = 0.02551685133948922
Trained batch 39 in epoch 6, gen_loss = 0.3993019014596939, disc_loss = 0.025026895035989583
Trained batch 40 in epoch 6, gen_loss = 0.3989798993599124, disc_loss = 0.02464519679637217
Trained batch 41 in epoch 6, gen_loss = 0.39772123098373413, disc_loss = 0.024203385780787186
Trained batch 42 in epoch 6, gen_loss = 0.39757043192552965, disc_loss = 0.02388216030978879
Trained batch 43 in epoch 6, gen_loss = 0.3976556299762292, disc_loss = 0.023544167761098255
Trained batch 44 in epoch 6, gen_loss = 0.3963503758112589, disc_loss = 0.023950708243581982
Trained batch 45 in epoch 6, gen_loss = 0.3965536012597706, disc_loss = 0.02381736922847188
Trained batch 46 in epoch 6, gen_loss = 0.3973648617876337, disc_loss = 0.02346449418667149
Trained batch 47 in epoch 6, gen_loss = 0.3984133768826723, disc_loss = 0.023083018624068547
Trained batch 48 in epoch 6, gen_loss = 0.39992676219161677, disc_loss = 0.022758218089156613
Trained batch 49 in epoch 6, gen_loss = 0.4014026653766632, disc_loss = 0.022617407804355026
Trained batch 50 in epoch 6, gen_loss = 0.40080184328789803, disc_loss = 0.022590488843692868
Trained batch 51 in epoch 6, gen_loss = 0.3992518283999883, disc_loss = 0.023603828256734863
Trained batch 52 in epoch 6, gen_loss = 0.4005667286099128, disc_loss = 0.024507002650215378
Trained batch 53 in epoch 6, gen_loss = 0.4005244164555161, disc_loss = 0.02415882265712652
Trained batch 54 in epoch 6, gen_loss = 0.40065373832529244, disc_loss = 0.02394539030607451
Trained batch 55 in epoch 6, gen_loss = 0.4000810555049351, disc_loss = 0.023651949944905937
Trained batch 56 in epoch 6, gen_loss = 0.40164842417365626, disc_loss = 0.02339406760834288
Trained batch 57 in epoch 6, gen_loss = 0.40247212658668385, disc_loss = 0.02311645394415948
Trained batch 58 in epoch 6, gen_loss = 0.40232667276414774, disc_loss = 0.02283256204198983
Trained batch 59 in epoch 6, gen_loss = 0.40232573052247367, disc_loss = 0.022570536316682894
Trained batch 60 in epoch 6, gen_loss = 0.4026156952146624, disc_loss = 0.02255303693599388
Trained batch 61 in epoch 6, gen_loss = 0.4022912224454264, disc_loss = 0.02227629379429404
Trained batch 62 in epoch 6, gen_loss = 0.40411576723295545, disc_loss = 0.021997304300644567
Trained batch 63 in epoch 6, gen_loss = 0.4044980211183429, disc_loss = 0.021756570327852387
Trained batch 64 in epoch 6, gen_loss = 0.40533184638390174, disc_loss = 0.021742926889027542
Trained batch 65 in epoch 6, gen_loss = 0.4060347820773269, disc_loss = 0.021516915742364345
Trained batch 66 in epoch 6, gen_loss = 0.4063414148430326, disc_loss = 0.02136219132330213
Trained batch 67 in epoch 6, gen_loss = 0.4059097074410495, disc_loss = 0.02114133213591926
Trained batch 68 in epoch 6, gen_loss = 0.40547654291857843, disc_loss = 0.021201517918835514
Trained batch 69 in epoch 6, gen_loss = 0.40613859508718764, disc_loss = 0.02094247652483838
Trained batch 70 in epoch 6, gen_loss = 0.4071222228903166, disc_loss = 0.020836726145845065
Trained batch 71 in epoch 6, gen_loss = 0.4077746942639351, disc_loss = 0.020699065062217414
Trained batch 72 in epoch 6, gen_loss = 0.40724764294820287, disc_loss = 0.02050501127944213
Trained batch 73 in epoch 6, gen_loss = 0.4068007589997472, disc_loss = 0.020538115615931316
Trained batch 74 in epoch 6, gen_loss = 0.40717597166697184, disc_loss = 0.02035046540821592
Trained batch 75 in epoch 6, gen_loss = 0.40722847769134923, disc_loss = 0.020630222138654637
Trained batch 76 in epoch 6, gen_loss = 0.4074311059016686, disc_loss = 0.02141038437869835
Trained batch 77 in epoch 6, gen_loss = 0.40738241030619693, disc_loss = 0.02123949498248597
Trained batch 78 in epoch 6, gen_loss = 0.4078010924254792, disc_loss = 0.021316467283317184
Trained batch 79 in epoch 6, gen_loss = 0.4079614493995905, disc_loss = 0.021115312637994064
Trained batch 80 in epoch 6, gen_loss = 0.4085693226920234, disc_loss = 0.02103403944775094
Trained batch 81 in epoch 6, gen_loss = 0.40844671319170694, disc_loss = 0.02084691006485827
Trained batch 82 in epoch 6, gen_loss = 0.40859290095696965, disc_loss = 0.020655924409448384
Trained batch 83 in epoch 6, gen_loss = 0.4088077750943956, disc_loss = 0.02053093716191749
Trained batch 84 in epoch 6, gen_loss = 0.4083390681182637, disc_loss = 0.020421554027673077
Trained batch 85 in epoch 6, gen_loss = 0.40819318869779275, disc_loss = 0.020286097310396822
Trained batch 86 in epoch 6, gen_loss = 0.40881062307577026, disc_loss = 0.020100843236278528
Trained batch 87 in epoch 6, gen_loss = 0.4090697728097439, disc_loss = 0.019982580973936074
Trained batch 88 in epoch 6, gen_loss = 0.4089337235756135, disc_loss = 0.020004722268812444
Trained batch 89 in epoch 6, gen_loss = 0.4094148215320375, disc_loss = 0.019870974940972196
Trained batch 90 in epoch 6, gen_loss = 0.4093919628924066, disc_loss = 0.019793998316994736
Trained batch 91 in epoch 6, gen_loss = 0.4093176421263944, disc_loss = 0.019927529608020963
Trained batch 92 in epoch 6, gen_loss = 0.40783705538319004, disc_loss = 0.02089630042312927
Trained batch 93 in epoch 6, gen_loss = 0.4080725201266877, disc_loss = 0.021350321449101605
Trained batch 94 in epoch 6, gen_loss = 0.4083005927110973, disc_loss = 0.021211229137292033
Trained batch 95 in epoch 6, gen_loss = 0.4086337083329757, disc_loss = 0.021109443303430453
Trained batch 96 in epoch 6, gen_loss = 0.4082423697427376, disc_loss = 0.020990311840222667
Trained batch 97 in epoch 6, gen_loss = 0.40841466674999316, disc_loss = 0.02085992048627564
Trained batch 98 in epoch 6, gen_loss = 0.40823269372034554, disc_loss = 0.020707969840691245
Trained batch 99 in epoch 6, gen_loss = 0.4077360326051712, disc_loss = 0.020701475120149554
Trained batch 100 in epoch 6, gen_loss = 0.4083572744142891, disc_loss = 0.021108146033037713
Trained batch 101 in epoch 6, gen_loss = 0.4084801849196939, disc_loss = 0.02103322594170915
Trained batch 102 in epoch 6, gen_loss = 0.4084715652234346, disc_loss = 0.020895059803699694
Trained batch 103 in epoch 6, gen_loss = 0.40808955465371793, disc_loss = 0.020729729854233134
Trained batch 104 in epoch 6, gen_loss = 0.4075892380305699, disc_loss = 0.020571596452611543
Trained batch 105 in epoch 6, gen_loss = 0.4073648939155183, disc_loss = 0.020480930332955467
Trained batch 106 in epoch 6, gen_loss = 0.40771276510764504, disc_loss = 0.02032093391057417
Trained batch 107 in epoch 6, gen_loss = 0.40806092459846427, disc_loss = 0.020177204737491492
Trained batch 108 in epoch 6, gen_loss = 0.4077263931068805, disc_loss = 0.02007360575900097
Trained batch 109 in epoch 6, gen_loss = 0.40755176191980186, disc_loss = 0.019921910608271982
Trained batch 110 in epoch 6, gen_loss = 0.40821399801486247, disc_loss = 0.019832798185431072
Trained batch 111 in epoch 6, gen_loss = 0.4090397030647312, disc_loss = 0.019690428390666575
Trained batch 112 in epoch 6, gen_loss = 0.4086906247961838, disc_loss = 0.019563347970720676
Trained batch 113 in epoch 6, gen_loss = 0.4092301506745188, disc_loss = 0.019503170113781828
Trained batch 114 in epoch 6, gen_loss = 0.40952900648117063, disc_loss = 0.01936221229843795
Trained batch 115 in epoch 6, gen_loss = 0.4102740978886341, disc_loss = 0.019251301412968415
Trained batch 116 in epoch 6, gen_loss = 0.41024883155129915, disc_loss = 0.019172040508805305
Trained batch 117 in epoch 6, gen_loss = 0.4108242086939893, disc_loss = 0.019051686495589883
Trained batch 118 in epoch 6, gen_loss = 0.4107837113512664, disc_loss = 0.01892297194894998
Trained batch 119 in epoch 6, gen_loss = 0.4113584987819195, disc_loss = 0.01899138968049859
Trained batch 120 in epoch 6, gen_loss = 0.4108089851446388, disc_loss = 0.019824175729824246
Trained batch 121 in epoch 6, gen_loss = 0.41163402869076027, disc_loss = 0.02120617611837558
Trained batch 122 in epoch 6, gen_loss = 0.4121546173483376, disc_loss = 0.02111861317577522
Trained batch 123 in epoch 6, gen_loss = 0.4121385709412636, disc_loss = 0.021056668754036147
Trained batch 124 in epoch 6, gen_loss = 0.4115163927078247, disc_loss = 0.021156004887074233
Trained batch 125 in epoch 6, gen_loss = 0.4115232728303425, disc_loss = 0.021191312380815074
Trained batch 126 in epoch 6, gen_loss = 0.41136075309881076, disc_loss = 0.021355715114623308
Trained batch 127 in epoch 6, gen_loss = 0.4113284251652658, disc_loss = 0.021366252996813273
Trained batch 128 in epoch 6, gen_loss = 0.41142350804898165, disc_loss = 0.02135423862180391
Trained batch 129 in epoch 6, gen_loss = 0.41156410024716306, disc_loss = 0.02128314385548807
Trained batch 130 in epoch 6, gen_loss = 0.4117111258834373, disc_loss = 0.021258387014355142
Trained batch 131 in epoch 6, gen_loss = 0.41136548577836063, disc_loss = 0.021547363996929067
Trained batch 132 in epoch 6, gen_loss = 0.41183656431678545, disc_loss = 0.021439204752249152
Trained batch 133 in epoch 6, gen_loss = 0.41203906109083943, disc_loss = 0.02139200779275774
Trained batch 134 in epoch 6, gen_loss = 0.4121387146137379, disc_loss = 0.021702902712341814
Trained batch 135 in epoch 6, gen_loss = 0.4113214927561143, disc_loss = 0.022399247709579545
Trained batch 136 in epoch 6, gen_loss = 0.41162595805460517, disc_loss = 0.022319649138834573
Trained batch 137 in epoch 6, gen_loss = 0.41162451086700824, disc_loss = 0.0232038079943184
Trained batch 138 in epoch 6, gen_loss = 0.4114931369428154, disc_loss = 0.02393298530817139
Trained batch 139 in epoch 6, gen_loss = 0.4114946576101439, disc_loss = 0.0238260893849656
Trained batch 140 in epoch 6, gen_loss = 0.41173691931345785, disc_loss = 0.023938310395344987
Trained batch 141 in epoch 6, gen_loss = 0.4118779891393554, disc_loss = 0.0238472194587943
Trained batch 142 in epoch 6, gen_loss = 0.411765049387525, disc_loss = 0.02375288399822124
Trained batch 143 in epoch 6, gen_loss = 0.41201818361878395, disc_loss = 0.02365731047272372
Trained batch 144 in epoch 6, gen_loss = 0.41151715763683977, disc_loss = 0.02352751343800076
Trained batch 145 in epoch 6, gen_loss = 0.4111010411830798, disc_loss = 0.023412525918564363
Trained batch 146 in epoch 6, gen_loss = 0.4107149385270618, disc_loss = 0.02329222903251141
Trained batch 147 in epoch 6, gen_loss = 0.41074083745479584, disc_loss = 0.02316975796507118
Trained batch 148 in epoch 6, gen_loss = 0.41047571649487385, disc_loss = 0.023083081640828177
Trained batch 149 in epoch 6, gen_loss = 0.4104039680957794, disc_loss = 0.022977372355138262
Trained batch 150 in epoch 6, gen_loss = 0.4105823314347804, disc_loss = 0.022851694948872587
Trained batch 151 in epoch 6, gen_loss = 0.41069864854216576, disc_loss = 0.02300855836610457
Trained batch 152 in epoch 6, gen_loss = 0.4103979674819248, disc_loss = 0.02366543630004124
Trained batch 153 in epoch 6, gen_loss = 0.41057854736006105, disc_loss = 0.02458750955494387
Trained batch 154 in epoch 6, gen_loss = 0.41030894690944303, disc_loss = 0.024721046591237666
Trained batch 155 in epoch 6, gen_loss = 0.4105362735497646, disc_loss = 0.024618251828285746
Trained batch 156 in epoch 6, gen_loss = 0.4103626914464744, disc_loss = 0.024599005954612972
Trained batch 157 in epoch 6, gen_loss = 0.4102652585959133, disc_loss = 0.024588667604883638
Trained batch 158 in epoch 6, gen_loss = 0.4099900876201174, disc_loss = 0.024483543885110308
Trained batch 159 in epoch 6, gen_loss = 0.4096255674958229, disc_loss = 0.024353932178928516
Trained batch 160 in epoch 6, gen_loss = 0.409605178958881, disc_loss = 0.024230263453347157
Trained batch 161 in epoch 6, gen_loss = 0.40960854494277343, disc_loss = 0.024113802385895892
Trained batch 162 in epoch 6, gen_loss = 0.4100269049954561, disc_loss = 0.024027314525600408
Trained batch 163 in epoch 6, gen_loss = 0.4099585054124274, disc_loss = 0.024198589355275944
Trained batch 164 in epoch 6, gen_loss = 0.41033817023941965, disc_loss = 0.024104064954162546
Trained batch 165 in epoch 6, gen_loss = 0.40990967061146194, disc_loss = 0.025343527077663554
Trained batch 166 in epoch 6, gen_loss = 0.40985933178199263, disc_loss = 0.027191917141509092
Trained batch 167 in epoch 6, gen_loss = 0.40960082731076647, disc_loss = 0.027653138399944596
Trained batch 168 in epoch 6, gen_loss = 0.4096298658636195, disc_loss = 0.027698176766927603
Trained batch 169 in epoch 6, gen_loss = 0.40922942985506616, disc_loss = 0.027641173684969544
Trained batch 170 in epoch 6, gen_loss = 0.40897756936954477, disc_loss = 0.02783458080001132
Trained batch 171 in epoch 6, gen_loss = 0.4090624515746915, disc_loss = 0.028093948194129
Trained batch 172 in epoch 6, gen_loss = 0.4088878674658737, disc_loss = 0.028046074040729358
Trained batch 173 in epoch 6, gen_loss = 0.4084735618925643, disc_loss = 0.028068668297331394
Trained batch 174 in epoch 6, gen_loss = 0.4085515410559518, disc_loss = 0.02794268297563706
Trained batch 175 in epoch 6, gen_loss = 0.40894262052395125, disc_loss = 0.02794783810333518
Trained batch 176 in epoch 6, gen_loss = 0.40846213008050863, disc_loss = 0.028383703578768644
Trained batch 177 in epoch 6, gen_loss = 0.4091577881507659, disc_loss = 0.02854249373423668
Trained batch 178 in epoch 6, gen_loss = 0.4091540053903058, disc_loss = 0.028434434247478924
Trained batch 179 in epoch 6, gen_loss = 0.4087242305278778, disc_loss = 0.028319388889293702
Trained batch 180 in epoch 6, gen_loss = 0.4084585695964855, disc_loss = 0.02827797897252671
Trained batch 181 in epoch 6, gen_loss = 0.40826406632805917, disc_loss = 0.028193405857514384
Trained batch 182 in epoch 6, gen_loss = 0.40842439128401503, disc_loss = 0.028063481151955862
Trained batch 183 in epoch 6, gen_loss = 0.40858633767651475, disc_loss = 0.027949699656228007
Trained batch 184 in epoch 6, gen_loss = 0.40909522014695243, disc_loss = 0.028106904845382717
Trained batch 185 in epoch 6, gen_loss = 0.40901837361756194, disc_loss = 0.028144035418267533
Trained batch 186 in epoch 6, gen_loss = 0.40902695235084086, disc_loss = 0.028045961334504547
Trained batch 187 in epoch 6, gen_loss = 0.40923534460524297, disc_loss = 0.027931773061665926
Trained batch 188 in epoch 6, gen_loss = 0.4093600350712973, disc_loss = 0.02787430233336867
Trained batch 189 in epoch 6, gen_loss = 0.40965786356675, disc_loss = 0.02790786602142218
Trained batch 190 in epoch 6, gen_loss = 0.4093894548129037, disc_loss = 0.027847301729355026
Trained batch 191 in epoch 6, gen_loss = 0.40921360192199546, disc_loss = 0.027805891244497616
Trained batch 192 in epoch 6, gen_loss = 0.40895249544030027, disc_loss = 0.027748441533547455
Trained batch 193 in epoch 6, gen_loss = 0.40895261223783197, disc_loss = 0.02767401869101546
Trained batch 194 in epoch 6, gen_loss = 0.40897326744519746, disc_loss = 0.02770981231513314
Trained batch 195 in epoch 6, gen_loss = 0.4087711055668033, disc_loss = 0.027602800427061716
Trained batch 196 in epoch 6, gen_loss = 0.40906869760019526, disc_loss = 0.027522657919902032
Trained batch 197 in epoch 6, gen_loss = 0.4092833169481971, disc_loss = 0.027403681541350904
Trained batch 198 in epoch 6, gen_loss = 0.4090708952453268, disc_loss = 0.02733351516036607
Trained batch 199 in epoch 6, gen_loss = 0.40938300132751465, disc_loss = 0.02724893766688183
Trained batch 200 in epoch 6, gen_loss = 0.40960946026726147, disc_loss = 0.02717619281104622
Trained batch 201 in epoch 6, gen_loss = 0.4098150806851906, disc_loss = 0.02708411608859528
Trained batch 202 in epoch 6, gen_loss = 0.40978844456484753, disc_loss = 0.027006552341334485
Trained batch 203 in epoch 6, gen_loss = 0.4095310695907649, disc_loss = 0.027056106587634514
Trained batch 204 in epoch 6, gen_loss = 0.4095456970901024, disc_loss = 0.026995219315243204
Trained batch 205 in epoch 6, gen_loss = 0.40937872245473766, disc_loss = 0.027090856956896708
Trained batch 206 in epoch 6, gen_loss = 0.409434641904877, disc_loss = 0.02775554401026184
Trained batch 207 in epoch 6, gen_loss = 0.4095510294517645, disc_loss = 0.027679094541011952
Trained batch 208 in epoch 6, gen_loss = 0.40957581283943506, disc_loss = 0.02791978771526491
Trained batch 209 in epoch 6, gen_loss = 0.4097723607506071, disc_loss = 0.02787211271934211
Trained batch 210 in epoch 6, gen_loss = 0.4101190260518784, disc_loss = 0.02784845836557695
Trained batch 211 in epoch 6, gen_loss = 0.4101536791279631, disc_loss = 0.027838671454755624
Trained batch 212 in epoch 6, gen_loss = 0.410404729451372, disc_loss = 0.027747946137676078
Trained batch 213 in epoch 6, gen_loss = 0.41037888588192306, disc_loss = 0.027687162393704057
Trained batch 214 in epoch 6, gen_loss = 0.41039456489474274, disc_loss = 0.027975690769854674
Trained batch 215 in epoch 6, gen_loss = 0.4100095698678935, disc_loss = 0.02990933644576688
Trained batch 216 in epoch 6, gen_loss = 0.4099507912787424, disc_loss = 0.03011462352268638
Trained batch 217 in epoch 6, gen_loss = 0.4100742746110356, disc_loss = 0.03169961997154041
Trained batch 218 in epoch 6, gen_loss = 0.4098567499962027, disc_loss = 0.03200001302536696
Trained batch 219 in epoch 6, gen_loss = 0.4098481977527792, disc_loss = 0.03203914574220438
Trained batch 220 in epoch 6, gen_loss = 0.40963263695056623, disc_loss = 0.03198849302569059
Trained batch 221 in epoch 6, gen_loss = 0.409350121343458, disc_loss = 0.031914019963477515
Trained batch 222 in epoch 6, gen_loss = 0.4096044263230311, disc_loss = 0.031821119680482846
Trained batch 223 in epoch 6, gen_loss = 0.409718467321779, disc_loss = 0.03173205935205
Trained batch 224 in epoch 6, gen_loss = 0.4094044358200497, disc_loss = 0.031686581540852785
Trained batch 225 in epoch 6, gen_loss = 0.4093615100183318, disc_loss = 0.031696052317285034
Trained batch 226 in epoch 6, gen_loss = 0.40915695069119795, disc_loss = 0.03162477477884437
Trained batch 227 in epoch 6, gen_loss = 0.40905168717890455, disc_loss = 0.0315667937015461
Trained batch 228 in epoch 6, gen_loss = 0.4088037159765652, disc_loss = 0.03161233713785309
Trained batch 229 in epoch 6, gen_loss = 0.4093407047831494, disc_loss = 0.03177488512440544
Trained batch 230 in epoch 6, gen_loss = 0.40913713365406185, disc_loss = 0.03192241759003176
Trained batch 231 in epoch 6, gen_loss = 0.40909656188611326, disc_loss = 0.03192236308000404
Trained batch 232 in epoch 6, gen_loss = 0.40906476245417617, disc_loss = 0.031853403142641415
Trained batch 233 in epoch 6, gen_loss = 0.40927211252542645, disc_loss = 0.0318979838063033
Trained batch 234 in epoch 6, gen_loss = 0.40927327300639865, disc_loss = 0.03189061253747724
Trained batch 235 in epoch 6, gen_loss = 0.4098957732824956, disc_loss = 0.031866271117844194
Trained batch 236 in epoch 6, gen_loss = 0.4099469822418841, disc_loss = 0.03179915259368246
Trained batch 237 in epoch 6, gen_loss = 0.4099650789960092, disc_loss = 0.03173793627520507
Trained batch 238 in epoch 6, gen_loss = 0.410026025946669, disc_loss = 0.03163046471455045
Trained batch 239 in epoch 6, gen_loss = 0.41025000177323817, disc_loss = 0.031519216689048335
Trained batch 240 in epoch 6, gen_loss = 0.4103952788465745, disc_loss = 0.031406948221190466
Trained batch 241 in epoch 6, gen_loss = 0.4104795389431567, disc_loss = 0.03130413889346167
Trained batch 242 in epoch 6, gen_loss = 0.4103718796139391, disc_loss = 0.03131238296398042
Trained batch 243 in epoch 6, gen_loss = 0.4102765540363359, disc_loss = 0.03176833990365877
Trained batch 244 in epoch 6, gen_loss = 0.41000809195090315, disc_loss = 0.03230388713810517
Trained batch 245 in epoch 6, gen_loss = 0.41008062563776, disc_loss = 0.03219834553850133
Trained batch 246 in epoch 6, gen_loss = 0.41057088560903604, disc_loss = 0.03217369955229132
Trained batch 247 in epoch 6, gen_loss = 0.4106104108354738, disc_loss = 0.03218130404580264
Trained batch 248 in epoch 6, gen_loss = 0.4106188771954502, disc_loss = 0.032212330192985784
Trained batch 249 in epoch 6, gen_loss = 0.4107929905653, disc_loss = 0.03223261330276728
Trained batch 250 in epoch 6, gen_loss = 0.41096992666027937, disc_loss = 0.03225251157356211
Trained batch 251 in epoch 6, gen_loss = 0.4108120320098741, disc_loss = 0.03228118682339314
Trained batch 252 in epoch 6, gen_loss = 0.41071015207663825, disc_loss = 0.0322374101698752
Trained batch 253 in epoch 6, gen_loss = 0.4109225088921119, disc_loss = 0.0321818529444886
Trained batch 254 in epoch 6, gen_loss = 0.4108961273642147, disc_loss = 0.032097617120427246
Trained batch 255 in epoch 6, gen_loss = 0.41082775488030165, disc_loss = 0.03203360387851717
Trained batch 256 in epoch 6, gen_loss = 0.4109138260787563, disc_loss = 0.03214041669110148
Trained batch 257 in epoch 6, gen_loss = 0.41115220422430554, disc_loss = 0.03203632154631927
Trained batch 258 in epoch 6, gen_loss = 0.410925003437462, disc_loss = 0.03199689825781006
Trained batch 259 in epoch 6, gen_loss = 0.41092483940032815, disc_loss = 0.03190447459749591
Trained batch 260 in epoch 6, gen_loss = 0.4109849463934186, disc_loss = 0.031803362967153845
Trained batch 261 in epoch 6, gen_loss = 0.41105152291195995, disc_loss = 0.031698303705948686
Trained batch 262 in epoch 6, gen_loss = 0.41140377589504984, disc_loss = 0.03160043304056609
Trained batch 263 in epoch 6, gen_loss = 0.4116876795887947, disc_loss = 0.031510343605821785
Trained batch 264 in epoch 6, gen_loss = 0.41150308206396286, disc_loss = 0.031408437364295404
Trained batch 265 in epoch 6, gen_loss = 0.4114975202128403, disc_loss = 0.031314857034502847
Trained batch 266 in epoch 6, gen_loss = 0.4114422599474589, disc_loss = 0.031213712247179243
Trained batch 267 in epoch 6, gen_loss = 0.41142150815298306, disc_loss = 0.031117838154088206
Trained batch 268 in epoch 6, gen_loss = 0.4111944812602713, disc_loss = 0.031020826885137416
Trained batch 269 in epoch 6, gen_loss = 0.4113241810489584, disc_loss = 0.030943378864753027
Trained batch 270 in epoch 6, gen_loss = 0.41128419191195076, disc_loss = 0.030856843862503876
Trained batch 271 in epoch 6, gen_loss = 0.4111478273921153, disc_loss = 0.03077276409535176
Trained batch 272 in epoch 6, gen_loss = 0.4113150492255941, disc_loss = 0.03067472406181988
Trained batch 273 in epoch 6, gen_loss = 0.41114550731042876, disc_loss = 0.03062616246174613
Trained batch 274 in epoch 6, gen_loss = 0.4115427163514224, disc_loss = 0.030592552311718466
Trained batch 275 in epoch 6, gen_loss = 0.4116593494579412, disc_loss = 0.030499396703975355
Trained batch 276 in epoch 6, gen_loss = 0.4117472076028693, disc_loss = 0.03041183804279523
Trained batch 277 in epoch 6, gen_loss = 0.4117674369820588, disc_loss = 0.030321951017534134
Trained batch 278 in epoch 6, gen_loss = 0.4117796383664599, disc_loss = 0.030226430309916376
Trained batch 279 in epoch 6, gen_loss = 0.41160554992301124, disc_loss = 0.030149191782610225
Trained batch 280 in epoch 6, gen_loss = 0.4120806975296808, disc_loss = 0.03008486509647923
Trained batch 281 in epoch 6, gen_loss = 0.41238016323417637, disc_loss = 0.030010087252099145
Trained batch 282 in epoch 6, gen_loss = 0.41240645034153134, disc_loss = 0.029932798865471733
Trained batch 283 in epoch 6, gen_loss = 0.4126821903275772, disc_loss = 0.02985309741072829
Trained batch 284 in epoch 6, gen_loss = 0.4127430740155672, disc_loss = 0.02976942272007204
Trained batch 285 in epoch 6, gen_loss = 0.41282945204448035, disc_loss = 0.0296898006569021
Trained batch 286 in epoch 6, gen_loss = 0.4129992391174263, disc_loss = 0.029606323616209244
Trained batch 287 in epoch 6, gen_loss = 0.41295792690167826, disc_loss = 0.029518487842223193
Trained batch 288 in epoch 6, gen_loss = 0.41294586586292226, disc_loss = 0.029430924267040817
Trained batch 289 in epoch 6, gen_loss = 0.41315256223596375, disc_loss = 0.02936163162491445
Trained batch 290 in epoch 6, gen_loss = 0.41332160658443096, disc_loss = 0.029284001865721856
Trained batch 291 in epoch 6, gen_loss = 0.41332092044288166, disc_loss = 0.02924538813595188
Trained batch 292 in epoch 6, gen_loss = 0.4132716513331026, disc_loss = 0.029186451353081868
Trained batch 293 in epoch 6, gen_loss = 0.41318282474871393, disc_loss = 0.029098277254232845
Trained batch 294 in epoch 6, gen_loss = 0.41308727072457135, disc_loss = 0.02903350415971067
Trained batch 295 in epoch 6, gen_loss = 0.41325494375180555, disc_loss = 0.028979094650256575
Trained batch 296 in epoch 6, gen_loss = 0.4133116098164709, disc_loss = 0.028894729476409527
Trained batch 297 in epoch 6, gen_loss = 0.41314276982873877, disc_loss = 0.028812881929474888
Trained batch 298 in epoch 6, gen_loss = 0.41314194423697864, disc_loss = 0.02874551249518492
Trained batch 299 in epoch 6, gen_loss = 0.4131416880091031, disc_loss = 0.02866150653998678
Trained batch 300 in epoch 6, gen_loss = 0.4132613231771412, disc_loss = 0.028581538603508046
Trained batch 301 in epoch 6, gen_loss = 0.41320569300098925, disc_loss = 0.028507405949836685
Trained batch 302 in epoch 6, gen_loss = 0.4130463449671717, disc_loss = 0.028424637004112203
Trained batch 303 in epoch 6, gen_loss = 0.41329984013971527, disc_loss = 0.028347799532256385
Trained batch 304 in epoch 6, gen_loss = 0.41343220443022055, disc_loss = 0.028281431900886972
Trained batch 305 in epoch 6, gen_loss = 0.41337720777084624, disc_loss = 0.028202568458581916
Trained batch 306 in epoch 6, gen_loss = 0.4134879394734721, disc_loss = 0.02812700677459835
Trained batch 307 in epoch 6, gen_loss = 0.4133326685080281, disc_loss = 0.028045645067558998
Trained batch 308 in epoch 6, gen_loss = 0.4132082788303832, disc_loss = 0.027976284101213597
Trained batch 309 in epoch 6, gen_loss = 0.41335563082848825, disc_loss = 0.027901609806013444
Trained batch 310 in epoch 6, gen_loss = 0.41353718874155515, disc_loss = 0.027830663898516555
Trained batch 311 in epoch 6, gen_loss = 0.41357810747547025, disc_loss = 0.02775062773248348
Trained batch 312 in epoch 6, gen_loss = 0.41357977093218234, disc_loss = 0.027682398790315078
Trained batch 313 in epoch 6, gen_loss = 0.4136640714232329, disc_loss = 0.027608848664061325
Trained batch 314 in epoch 6, gen_loss = 0.41379968145537, disc_loss = 0.027539599616642273
Trained batch 315 in epoch 6, gen_loss = 0.4136335895974425, disc_loss = 0.0274644964271449
Trained batch 316 in epoch 6, gen_loss = 0.4137217942096458, disc_loss = 0.02739043820396724
Trained batch 317 in epoch 6, gen_loss = 0.4138511374311627, disc_loss = 0.02731801470325756
Trained batch 318 in epoch 6, gen_loss = 0.41384667401029773, disc_loss = 0.027247424889939798
Trained batch 319 in epoch 6, gen_loss = 0.4137048406526446, disc_loss = 0.027176220617548097
Trained batch 320 in epoch 6, gen_loss = 0.4138614163963223, disc_loss = 0.027102367939410087
Trained batch 321 in epoch 6, gen_loss = 0.41399870655551463, disc_loss = 0.027032904289315762
Trained batch 322 in epoch 6, gen_loss = 0.41409222601737034, disc_loss = 0.026960324479451535
Trained batch 323 in epoch 6, gen_loss = 0.4141984270126731, disc_loss = 0.026885525870315133
Trained batch 324 in epoch 6, gen_loss = 0.4144444939723382, disc_loss = 0.026827882047599325
Trained batch 325 in epoch 6, gen_loss = 0.41460743263089583, disc_loss = 0.026753092278937803
Trained batch 326 in epoch 6, gen_loss = 0.4145446426095583, disc_loss = 0.026686612045284167
Trained batch 327 in epoch 6, gen_loss = 0.41426692557771033, disc_loss = 0.026650489025419895
Trained batch 328 in epoch 6, gen_loss = 0.41409320282356354, disc_loss = 0.026593916229960313
Trained batch 329 in epoch 6, gen_loss = 0.4140851551836187, disc_loss = 0.026534152715325807
Trained batch 330 in epoch 6, gen_loss = 0.4139872563389493, disc_loss = 0.026466460596049752
Trained batch 331 in epoch 6, gen_loss = 0.41423591953444194, disc_loss = 0.026423390459617127
Trained batch 332 in epoch 6, gen_loss = 0.41435227469281033, disc_loss = 0.026362338275354995
Trained batch 333 in epoch 6, gen_loss = 0.4143908557420719, disc_loss = 0.02630242984463087
Trained batch 334 in epoch 6, gen_loss = 0.4143566553272418, disc_loss = 0.02623186576972479
Trained batch 335 in epoch 6, gen_loss = 0.4142893764766909, disc_loss = 0.02617912982462994
Trained batch 336 in epoch 6, gen_loss = 0.41415124070396764, disc_loss = 0.026128170604179185
Trained batch 337 in epoch 6, gen_loss = 0.4142666462610459, disc_loss = 0.02605965708454068
Trained batch 338 in epoch 6, gen_loss = 0.4142904392385905, disc_loss = 0.02599606291146449
Trained batch 339 in epoch 6, gen_loss = 0.4143242031335831, disc_loss = 0.025928692933281556
Trained batch 340 in epoch 6, gen_loss = 0.41446707701403374, disc_loss = 0.02586214816268763
Trained batch 341 in epoch 6, gen_loss = 0.4144343543819517, disc_loss = 0.02581160646258739
Trained batch 342 in epoch 6, gen_loss = 0.41457330468097164, disc_loss = 0.02576116530860044
Trained batch 343 in epoch 6, gen_loss = 0.4145542442105537, disc_loss = 0.025693283942907097
Trained batch 344 in epoch 6, gen_loss = 0.4149530633636143, disc_loss = 0.025642061955632938
Trained batch 345 in epoch 6, gen_loss = 0.41494571766412325, disc_loss = 0.025595629384547385
Trained batch 346 in epoch 6, gen_loss = 0.41504635470744855, disc_loss = 0.025529699112887168
Trained batch 347 in epoch 6, gen_loss = 0.41515248654217557, disc_loss = 0.02547339500789798
Trained batch 348 in epoch 6, gen_loss = 0.4152762584153424, disc_loss = 0.025408230397722185
Trained batch 349 in epoch 6, gen_loss = 0.41540564945765907, disc_loss = 0.025379000759816594
Trained batch 350 in epoch 6, gen_loss = 0.41552286805250704, disc_loss = 0.02531848678848258
Trained batch 351 in epoch 6, gen_loss = 0.4152824188667265, disc_loss = 0.025279690688793464
Trained batch 352 in epoch 6, gen_loss = 0.41548859549649375, disc_loss = 0.02525051961792765
Trained batch 353 in epoch 6, gen_loss = 0.41558120521785175, disc_loss = 0.02518732533500777
Trained batch 354 in epoch 6, gen_loss = 0.4156340819849095, disc_loss = 0.025139477492218287
Trained batch 355 in epoch 6, gen_loss = 0.4156192449873753, disc_loss = 0.025081017017992358
Trained batch 356 in epoch 6, gen_loss = 0.4158296737851215, disc_loss = 0.0250229844562605
Trained batch 357 in epoch 6, gen_loss = 0.4159807139934774, disc_loss = 0.024967684799430675
Trained batch 358 in epoch 6, gen_loss = 0.41586536401493635, disc_loss = 0.0249335607838062
Trained batch 359 in epoch 6, gen_loss = 0.41589057329628204, disc_loss = 0.024894489033613354
Trained batch 360 in epoch 6, gen_loss = 0.41555163338574014, disc_loss = 0.024863760543011974
Trained batch 361 in epoch 6, gen_loss = 0.41583686029713457, disc_loss = 0.025383999196874257
Trained batch 362 in epoch 6, gen_loss = 0.4159382539839784, disc_loss = 0.025399053552683144
Trained batch 363 in epoch 6, gen_loss = 0.41564869716927244, disc_loss = 0.025815795161659
Trained batch 364 in epoch 6, gen_loss = 0.41578398616346596, disc_loss = 0.025815563318510985
Trained batch 365 in epoch 6, gen_loss = 0.4158509201853653, disc_loss = 0.02579494557200926
Trained batch 366 in epoch 6, gen_loss = 0.41589721030370413, disc_loss = 0.025816163648305617
Trained batch 367 in epoch 6, gen_loss = 0.41583849489688873, disc_loss = 0.025827868756807773
Trained batch 368 in epoch 6, gen_loss = 0.41579428194015006, disc_loss = 0.025791084864568017
Trained batch 369 in epoch 6, gen_loss = 0.4159389110030355, disc_loss = 0.025814079192492206
Trained batch 370 in epoch 6, gen_loss = 0.41592589149256604, disc_loss = 0.026085318742706528
Trained batch 371 in epoch 6, gen_loss = 0.4157177087280058, disc_loss = 0.026297277782202488
Trained batch 372 in epoch 6, gen_loss = 0.4158173014906712, disc_loss = 0.026239509787909867
Trained batch 373 in epoch 6, gen_loss = 0.41598193586510135, disc_loss = 0.02623575620158989
Trained batch 374 in epoch 6, gen_loss = 0.4158899702231089, disc_loss = 0.026196248535066843
Trained batch 375 in epoch 6, gen_loss = 0.41593322831582513, disc_loss = 0.02616723644562026
Trained batch 376 in epoch 6, gen_loss = 0.41587189393271184, disc_loss = 0.026118414362877686
Trained batch 377 in epoch 6, gen_loss = 0.4159045828870995, disc_loss = 0.0261075298484198
Trained batch 378 in epoch 6, gen_loss = 0.4157640390628875, disc_loss = 0.02605474151002543
Trained batch 379 in epoch 6, gen_loss = 0.41568809888864816, disc_loss = 0.02608633006579782
Trained batch 380 in epoch 6, gen_loss = 0.4156256653661803, disc_loss = 0.026088264655918274
Trained batch 381 in epoch 6, gen_loss = 0.4157038342734282, disc_loss = 0.0260334579366703
Trained batch 382 in epoch 6, gen_loss = 0.4157209700610557, disc_loss = 0.025990641109314663
Trained batch 383 in epoch 6, gen_loss = 0.4157307112279038, disc_loss = 0.025944346925825812
Trained batch 384 in epoch 6, gen_loss = 0.41564781828360126, disc_loss = 0.025887529786627787
Trained batch 385 in epoch 6, gen_loss = 0.41548381730373657, disc_loss = 0.025843584193447556
Trained batch 386 in epoch 6, gen_loss = 0.41567218295979563, disc_loss = 0.025797591366605394
Trained batch 387 in epoch 6, gen_loss = 0.4157748370594585, disc_loss = 0.02587311442451763
Trained batch 388 in epoch 6, gen_loss = 0.4158201881883077, disc_loss = 0.025822367115726736
Trained batch 389 in epoch 6, gen_loss = 0.41581333463008585, disc_loss = 0.025774393615145715
Trained batch 390 in epoch 6, gen_loss = 0.4157133383671646, disc_loss = 0.025782978202661743
Trained batch 391 in epoch 6, gen_loss = 0.41580199153751746, disc_loss = 0.02578954281028816
Trained batch 392 in epoch 6, gen_loss = 0.4159507733264952, disc_loss = 0.025733139623624793
Trained batch 393 in epoch 6, gen_loss = 0.41586572597474614, disc_loss = 0.02568921416484973
Trained batch 394 in epoch 6, gen_loss = 0.41591476020933704, disc_loss = 0.025655527867353225
Trained batch 395 in epoch 6, gen_loss = 0.41583882001313294, disc_loss = 0.02560863526587403
Trained batch 396 in epoch 6, gen_loss = 0.4159247430806196, disc_loss = 0.02555744832566932
Trained batch 397 in epoch 6, gen_loss = 0.41591435491140166, disc_loss = 0.025504776983915
Trained batch 398 in epoch 6, gen_loss = 0.41613393319878067, disc_loss = 0.02548011966145371
Trained batch 399 in epoch 6, gen_loss = 0.41617535904049874, disc_loss = 0.025439326738123783
Trained batch 400 in epoch 6, gen_loss = 0.4162355398299391, disc_loss = 0.02538543279245589
Trained batch 401 in epoch 6, gen_loss = 0.4163398985097657, disc_loss = 0.025333520346460168
Trained batch 402 in epoch 6, gen_loss = 0.4164991543695294, disc_loss = 0.025293940661484306
Trained batch 403 in epoch 6, gen_loss = 0.4165615038854061, disc_loss = 0.025253444455338107
Trained batch 404 in epoch 6, gen_loss = 0.41625411245557997, disc_loss = 0.025227834573475483
Trained batch 405 in epoch 6, gen_loss = 0.41628261710622627, disc_loss = 0.025190604778965522
Trained batch 406 in epoch 6, gen_loss = 0.41628608144179025, disc_loss = 0.02514664168556562
Trained batch 407 in epoch 6, gen_loss = 0.41641973426529005, disc_loss = 0.025100728704059935
Trained batch 408 in epoch 6, gen_loss = 0.41631771999349804, disc_loss = 0.025107319165626883
Trained batch 409 in epoch 6, gen_loss = 0.4161233532719496, disc_loss = 0.025128843768772374
Trained batch 410 in epoch 6, gen_loss = 0.4161366967534207, disc_loss = 0.025091498382638803
Trained batch 411 in epoch 6, gen_loss = 0.4162633938407435, disc_loss = 0.025044692844690446
Trained batch 412 in epoch 6, gen_loss = 0.41628168469191174, disc_loss = 0.024998091102056835
Trained batch 413 in epoch 6, gen_loss = 0.4161921504183092, disc_loss = 0.024951380348521405
Trained batch 414 in epoch 6, gen_loss = 0.41615026980997566, disc_loss = 0.024903182772336056
Trained batch 415 in epoch 6, gen_loss = 0.4161171011196879, disc_loss = 0.024850795292317904
Trained batch 416 in epoch 6, gen_loss = 0.4160892656095308, disc_loss = 0.02479996910816778
Trained batch 417 in epoch 6, gen_loss = 0.4159617292823974, disc_loss = 0.024748054932932143
Trained batch 418 in epoch 6, gen_loss = 0.4160165268225431, disc_loss = 0.0246972339094432
Trained batch 419 in epoch 6, gen_loss = 0.41608136147260666, disc_loss = 0.024649635815460768
Trained batch 420 in epoch 6, gen_loss = 0.416064173266327, disc_loss = 0.024616169681299187
Trained batch 421 in epoch 6, gen_loss = 0.41596951628748274, disc_loss = 0.02460176854999074
Trained batch 422 in epoch 6, gen_loss = 0.41606208224104935, disc_loss = 0.024640009544754565
Trained batch 423 in epoch 6, gen_loss = 0.4161009188249426, disc_loss = 0.024597052555039245
Trained batch 424 in epoch 6, gen_loss = 0.41605923533439637, disc_loss = 0.02456857248045066
Trained batch 425 in epoch 6, gen_loss = 0.4158902276010021, disc_loss = 0.024535606833865665
Trained batch 426 in epoch 6, gen_loss = 0.41602147030327863, disc_loss = 0.024501563501337094
Trained batch 427 in epoch 6, gen_loss = 0.41611342347949465, disc_loss = 0.024464949351848564
Trained batch 428 in epoch 6, gen_loss = 0.41609622798599566, disc_loss = 0.02442744546211683
Trained batch 429 in epoch 6, gen_loss = 0.41597376840059147, disc_loss = 0.02438879562108669
Trained batch 430 in epoch 6, gen_loss = 0.4158514543088572, disc_loss = 0.024339785479579615
Trained batch 431 in epoch 6, gen_loss = 0.41582634217209286, disc_loss = 0.02429680857285685
Trained batch 432 in epoch 6, gen_loss = 0.4157590666489017, disc_loss = 0.024251677241073126
Trained batch 433 in epoch 6, gen_loss = 0.41571096876799235, disc_loss = 0.02420403995800094
Trained batch 434 in epoch 6, gen_loss = 0.4157467982549777, disc_loss = 0.02415540433734998
Trained batch 435 in epoch 6, gen_loss = 0.415840447154067, disc_loss = 0.024112218369328236
Trained batch 436 in epoch 6, gen_loss = 0.4156921823046573, disc_loss = 0.024074457842617955
Trained batch 437 in epoch 6, gen_loss = 0.4156403587833387, disc_loss = 0.024045799528227343
Trained batch 438 in epoch 6, gen_loss = 0.41532534598489557, disc_loss = 0.024011048056601054
Trained batch 439 in epoch 6, gen_loss = 0.4152540875429457, disc_loss = 0.023990653684913096
Trained batch 440 in epoch 6, gen_loss = 0.4152404453749019, disc_loss = 0.023947799338614927
Trained batch 441 in epoch 6, gen_loss = 0.41515936685633337, disc_loss = 0.023909628506100893
Trained batch 442 in epoch 6, gen_loss = 0.4152773146435585, disc_loss = 0.02386321969809637
Trained batch 443 in epoch 6, gen_loss = 0.4152341295738478, disc_loss = 0.023832706451365673
Trained batch 444 in epoch 6, gen_loss = 0.41519438443558937, disc_loss = 0.023798745309703804
Trained batch 445 in epoch 6, gen_loss = 0.4153058524222652, disc_loss = 0.023783228957332304
Trained batch 446 in epoch 6, gen_loss = 0.4151767327614812, disc_loss = 0.02373862168928754
Trained batch 447 in epoch 6, gen_loss = 0.41521979675495196, disc_loss = 0.02369324027729038
Trained batch 448 in epoch 6, gen_loss = 0.4150584284340618, disc_loss = 0.023648573222045347
Trained batch 449 in epoch 6, gen_loss = 0.4150392294592328, disc_loss = 0.02360644655664348
Trained batch 450 in epoch 6, gen_loss = 0.41511617683518487, disc_loss = 0.023576396205121787
Trained batch 451 in epoch 6, gen_loss = 0.4149246373403389, disc_loss = 0.023534929292766887
Trained batch 452 in epoch 6, gen_loss = 0.4150326536849108, disc_loss = 0.023508963114982902
Trained batch 453 in epoch 6, gen_loss = 0.414957608551706, disc_loss = 0.023469764143864456
Trained batch 454 in epoch 6, gen_loss = 0.4149983293407566, disc_loss = 0.023438504370502555
Trained batch 455 in epoch 6, gen_loss = 0.41492676172862974, disc_loss = 0.02340115028129188
Trained batch 456 in epoch 6, gen_loss = 0.41476964331038413, disc_loss = 0.023377253166022884
Trained batch 457 in epoch 6, gen_loss = 0.4146850296503592, disc_loss = 0.02334623446019049
Trained batch 458 in epoch 6, gen_loss = 0.41458316247967075, disc_loss = 0.02331845753436628
Trained batch 459 in epoch 6, gen_loss = 0.4144932500046232, disc_loss = 0.023284838908939096
Trained batch 460 in epoch 6, gen_loss = 0.4144363751121819, disc_loss = 0.023246865854406662
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.41153448820114136, disc_loss = 0.004397248849272728
Trained batch 1 in epoch 7, gen_loss = 0.4515116959810257, disc_loss = 0.006931553594768047
Trained batch 2 in epoch 7, gen_loss = 0.4405349592367808, disc_loss = 0.005627405131235719
Trained batch 3 in epoch 7, gen_loss = 0.4179265648126602, disc_loss = 0.013573064643424004
Trained batch 4 in epoch 7, gen_loss = 0.41753901839256286, disc_loss = 0.02137809037230909
Trained batch 5 in epoch 7, gen_loss = 0.4134514679511388, disc_loss = 0.018326882699814934
Trained batch 6 in epoch 7, gen_loss = 0.4112536779471806, disc_loss = 0.02007047469461603
Trained batch 7 in epoch 7, gen_loss = 0.41781046614050865, disc_loss = 0.01842302441946231
Trained batch 8 in epoch 7, gen_loss = 0.4183056586318546, disc_loss = 0.01903990581114259
Trained batch 9 in epoch 7, gen_loss = 0.4183355450630188, disc_loss = 0.01811773094814271
Trained batch 10 in epoch 7, gen_loss = 0.41925184564156964, disc_loss = 0.016764768907292324
Trained batch 11 in epoch 7, gen_loss = 0.41641779989004135, disc_loss = 0.015804350337324042
Trained batch 12 in epoch 7, gen_loss = 0.4119336513372568, disc_loss = 0.014880120431861052
Trained batch 13 in epoch 7, gen_loss = 0.4104197067873819, disc_loss = 0.014347495577697243
Trained batch 14 in epoch 7, gen_loss = 0.4103200097878774, disc_loss = 0.014058431300024191
Trained batch 15 in epoch 7, gen_loss = 0.41450569592416286, disc_loss = 0.014132697717286646
Trained batch 16 in epoch 7, gen_loss = 0.4135602274361779, disc_loss = 0.013822811272214441
Trained batch 17 in epoch 7, gen_loss = 0.41151679886711967, disc_loss = 0.013622316894017987
Trained batch 18 in epoch 7, gen_loss = 0.4084156939857884, disc_loss = 0.014032957634251369
Trained batch 19 in epoch 7, gen_loss = 0.4044914111495018, disc_loss = 0.013748160656541586
Trained batch 20 in epoch 7, gen_loss = 0.4095992829118456, disc_loss = 0.01343770573536555
Trained batch 21 in epoch 7, gen_loss = 0.4090797237374566, disc_loss = 0.013018665242601524
Trained batch 22 in epoch 7, gen_loss = 0.41106535429539887, disc_loss = 0.012898126698058584
Trained batch 23 in epoch 7, gen_loss = 0.40819573899110156, disc_loss = 0.015098316284517447
Trained batch 24 in epoch 7, gen_loss = 0.41144322872161865, disc_loss = 0.024223538935184478
Trained batch 25 in epoch 7, gen_loss = 0.40851237109074223, disc_loss = 0.024200796221311275
Trained batch 26 in epoch 7, gen_loss = 0.4043695562415653, disc_loss = 0.024818436553080876
Trained batch 27 in epoch 7, gen_loss = 0.40042477207524435, disc_loss = 0.03846955791647945
Trained batch 28 in epoch 7, gen_loss = 0.401482787625543, disc_loss = 0.04455425063597745
Trained batch 29 in epoch 7, gen_loss = 0.402724219361941, disc_loss = 0.04480985167125861
Trained batch 30 in epoch 7, gen_loss = 0.4022568493120132, disc_loss = 0.04556423798203468
Trained batch 31 in epoch 7, gen_loss = 0.4011107971891761, disc_loss = 0.04562318685930222
Trained batch 32 in epoch 7, gen_loss = 0.4037070156949939, disc_loss = 0.045994463856473114
Trained batch 33 in epoch 7, gen_loss = 0.40314947156345143, disc_loss = 0.047228782602092796
Trained batch 34 in epoch 7, gen_loss = 0.40547086937086924, disc_loss = 0.04645717979541847
Trained batch 35 in epoch 7, gen_loss = 0.40657709787289303, disc_loss = 0.04715603015696009
Trained batch 36 in epoch 7, gen_loss = 0.40601507312542684, disc_loss = 0.04965291237710295
Trained batch 37 in epoch 7, gen_loss = 0.407782970290435, disc_loss = 0.05129543696775248
Trained batch 38 in epoch 7, gen_loss = 0.40609515553865677, disc_loss = 0.05066085325028652
Trained batch 39 in epoch 7, gen_loss = 0.40491214394569397, disc_loss = 0.04996425309218466
Trained batch 40 in epoch 7, gen_loss = 0.4043898095444935, disc_loss = 0.051405238351080476
Trained batch 41 in epoch 7, gen_loss = 0.4049724901006335, disc_loss = 0.0546168593157615
Trained batch 42 in epoch 7, gen_loss = 0.4050838171049606, disc_loss = 0.05363641718272553
Trained batch 43 in epoch 7, gen_loss = 0.4046166241168976, disc_loss = 0.05288736458698457
Trained batch 44 in epoch 7, gen_loss = 0.40440754493077596, disc_loss = 0.052163057029247284
Trained batch 45 in epoch 7, gen_loss = 0.404819267599479, disc_loss = 0.051762574068878006
Trained batch 46 in epoch 7, gen_loss = 0.40671862756952326, disc_loss = 0.05279146784797628
Trained batch 47 in epoch 7, gen_loss = 0.40869314533968765, disc_loss = 0.052119985998918615
Trained batch 48 in epoch 7, gen_loss = 0.40759960546785473, disc_loss = 0.053123904582189053
Trained batch 49 in epoch 7, gen_loss = 0.40810586988925934, disc_loss = 0.053649101704359055
Trained batch 50 in epoch 7, gen_loss = 0.40843073293274523, disc_loss = 0.052746774948329904
Trained batch 51 in epoch 7, gen_loss = 0.40814974502875256, disc_loss = 0.05201856506307824
Trained batch 52 in epoch 7, gen_loss = 0.40825420111980076, disc_loss = 0.05159876475391804
Trained batch 53 in epoch 7, gen_loss = 0.4080413541308156, disc_loss = 0.05191796667080511
Trained batch 54 in epoch 7, gen_loss = 0.40886346697807313, disc_loss = 0.05141234920275482
Trained batch 55 in epoch 7, gen_loss = 0.4087886687900339, disc_loss = 0.05062764029051842
Trained batch 56 in epoch 7, gen_loss = 0.41016835444851923, disc_loss = 0.05013991742836017
Trained batch 57 in epoch 7, gen_loss = 0.4109035458030372, disc_loss = 0.04951023882865135
Trained batch 58 in epoch 7, gen_loss = 0.4110170718977007, disc_loss = 0.049306449630313505
Trained batch 59 in epoch 7, gen_loss = 0.4106512665748596, disc_loss = 0.049840454019916554
Trained batch 60 in epoch 7, gen_loss = 0.4121149446143479, disc_loss = 0.051057809208076996
Trained batch 61 in epoch 7, gen_loss = 0.41182436962281505, disc_loss = 0.05052886880002916
Trained batch 62 in epoch 7, gen_loss = 0.4109883743619162, disc_loss = 0.05022389696733583
Trained batch 63 in epoch 7, gen_loss = 0.4108214061707258, disc_loss = 0.04955873001017608
Trained batch 64 in epoch 7, gen_loss = 0.41006281467584466, disc_loss = 0.04891586244965975
Trained batch 65 in epoch 7, gen_loss = 0.41005293166998663, disc_loss = 0.04861450337833076
Trained batch 66 in epoch 7, gen_loss = 0.41034993217952215, disc_loss = 0.04797937726574158
Trained batch 67 in epoch 7, gen_loss = 0.41081399952664094, disc_loss = 0.047705033547518885
Trained batch 68 in epoch 7, gen_loss = 0.4111787676811218, disc_loss = 0.04766705316369948
Trained batch 69 in epoch 7, gen_loss = 0.41099446543625423, disc_loss = 0.0470406502851152
Trained batch 70 in epoch 7, gen_loss = 0.41144688700286436, disc_loss = 0.04712188599014681
Trained batch 71 in epoch 7, gen_loss = 0.4111889621449841, disc_loss = 0.04831185231644971
Trained batch 72 in epoch 7, gen_loss = 0.41151381314617314, disc_loss = 0.05174123259478134
Trained batch 73 in epoch 7, gen_loss = 0.41222177284794886, disc_loss = 0.051195954183443776
Trained batch 74 in epoch 7, gen_loss = 0.41243856072425844, disc_loss = 0.05082203250067929
Trained batch 75 in epoch 7, gen_loss = 0.4124048085589158, disc_loss = 0.05042796244685489
Trained batch 76 in epoch 7, gen_loss = 0.4121267145330256, disc_loss = 0.049983240745647195
Trained batch 77 in epoch 7, gen_loss = 0.4123766406988486, disc_loss = 0.0496292447235483
Trained batch 78 in epoch 7, gen_loss = 0.4125289690645435, disc_loss = 0.04911929147046861
Trained batch 79 in epoch 7, gen_loss = 0.41403124704957006, disc_loss = 0.04867288670211565
Trained batch 80 in epoch 7, gen_loss = 0.41424523128403556, disc_loss = 0.04841187117724783
Trained batch 81 in epoch 7, gen_loss = 0.4136200281904965, disc_loss = 0.04799728793739455
Trained batch 82 in epoch 7, gen_loss = 0.4134029006383505, disc_loss = 0.048932116330006575
Trained batch 83 in epoch 7, gen_loss = 0.4128328966242926, disc_loss = 0.051586466073612905
Trained batch 84 in epoch 7, gen_loss = 0.4129134956528159, disc_loss = 0.05166963170939947
Trained batch 85 in epoch 7, gen_loss = 0.413196662830752, disc_loss = 0.05277136304729813
Trained batch 86 in epoch 7, gen_loss = 0.41300427057277195, disc_loss = 0.05431059917873949
Trained batch 87 in epoch 7, gen_loss = 0.4117768383161588, disc_loss = 0.05546513257749294
Trained batch 88 in epoch 7, gen_loss = 0.41226011380720673, disc_loss = 0.055401962153676355
Trained batch 89 in epoch 7, gen_loss = 0.41188629865646365, disc_loss = 0.055101759056560694
Trained batch 90 in epoch 7, gen_loss = 0.4113455437696897, disc_loss = 0.05468129041952664
Trained batch 91 in epoch 7, gen_loss = 0.41065433167892956, disc_loss = 0.05426842618844998
Trained batch 92 in epoch 7, gen_loss = 0.41063990772411385, disc_loss = 0.054142858640300814
Trained batch 93 in epoch 7, gen_loss = 0.4102187993678641, disc_loss = 0.05406292168017318
Trained batch 94 in epoch 7, gen_loss = 0.4093856676628715, disc_loss = 0.05373331803191257
Trained batch 95 in epoch 7, gen_loss = 0.40925157722085714, disc_loss = 0.05330866145231994
Trained batch 96 in epoch 7, gen_loss = 0.40824148704096214, disc_loss = 0.054977917071604696
Trained batch 97 in epoch 7, gen_loss = 0.4085314626596412, disc_loss = 0.05804263561612413
Trained batch 98 in epoch 7, gen_loss = 0.4083062470561326, disc_loss = 0.05781830129251261
Trained batch 99 in epoch 7, gen_loss = 0.40842288225889206, disc_loss = 0.058178137734066694
Trained batch 100 in epoch 7, gen_loss = 0.40821829733282033, disc_loss = 0.057817892169137255
Trained batch 101 in epoch 7, gen_loss = 0.40776555473897974, disc_loss = 0.057470573831404394
Trained batch 102 in epoch 7, gen_loss = 0.4080557577239657, disc_loss = 0.05708193584363365
Trained batch 103 in epoch 7, gen_loss = 0.4087867885828018, disc_loss = 0.05675041054760536
Trained batch 104 in epoch 7, gen_loss = 0.408753806636447, disc_loss = 0.056413563329815154
Trained batch 105 in epoch 7, gen_loss = 0.408710224167356, disc_loss = 0.056117024648284435
Trained batch 106 in epoch 7, gen_loss = 0.4090529050782462, disc_loss = 0.056197545123417104
Trained batch 107 in epoch 7, gen_loss = 0.40943097819884616, disc_loss = 0.05576391863697036
Trained batch 108 in epoch 7, gen_loss = 0.4096329742615376, disc_loss = 0.055327388327654214
Trained batch 109 in epoch 7, gen_loss = 0.4093741452152079, disc_loss = 0.05493637771049345
Trained batch 110 in epoch 7, gen_loss = 0.4088940566724485, disc_loss = 0.05449509421187277
Trained batch 111 in epoch 7, gen_loss = 0.4093937064920153, disc_loss = 0.05405709750526252
Trained batch 112 in epoch 7, gen_loss = 0.4098953546675961, disc_loss = 0.05366765057659848
Trained batch 113 in epoch 7, gen_loss = 0.41035842529514377, disc_loss = 0.053230868182716926
Trained batch 114 in epoch 7, gen_loss = 0.41051943094834037, disc_loss = 0.05296956122974339
Trained batch 115 in epoch 7, gen_loss = 0.41099338952837317, disc_loss = 0.053457169604873095
Trained batch 116 in epoch 7, gen_loss = 0.41039534435312974, disc_loss = 0.05452491397547544
Trained batch 117 in epoch 7, gen_loss = 0.41015626843702996, disc_loss = 0.054259853094216375
Trained batch 118 in epoch 7, gen_loss = 0.41079010232156066, disc_loss = 0.05396848062773337
Trained batch 119 in epoch 7, gen_loss = 0.41117342611153923, disc_loss = 0.053610674179314324
Trained batch 120 in epoch 7, gen_loss = 0.41131050897038673, disc_loss = 0.053224228503382646
Trained batch 121 in epoch 7, gen_loss = 0.4108191804319132, disc_loss = 0.0528445719038976
Trained batch 122 in epoch 7, gen_loss = 0.4111881706772781, disc_loss = 0.05245144369186667
Trained batch 123 in epoch 7, gen_loss = 0.4116429172215923, disc_loss = 0.052184469810116194
Trained batch 124 in epoch 7, gen_loss = 0.4119637808799744, disc_loss = 0.051821155466139315
Trained batch 125 in epoch 7, gen_loss = 0.4119985359055655, disc_loss = 0.051475864605948565
Trained batch 126 in epoch 7, gen_loss = 0.4121635593767241, disc_loss = 0.05127094927295221
Trained batch 127 in epoch 7, gen_loss = 0.41203876212239265, disc_loss = 0.05118264107295545
Trained batch 128 in epoch 7, gen_loss = 0.41199145136877546, disc_loss = 0.05103902998849634
Trained batch 129 in epoch 7, gen_loss = 0.41212817545120534, disc_loss = 0.050812561473307705
Trained batch 130 in epoch 7, gen_loss = 0.41185042284827195, disc_loss = 0.05050581847210877
Trained batch 131 in epoch 7, gen_loss = 0.41201131813453906, disc_loss = 0.05034540847621181
Trained batch 132 in epoch 7, gen_loss = 0.4125927921972777, disc_loss = 0.049995156988865676
Trained batch 133 in epoch 7, gen_loss = 0.4123889770525605, disc_loss = 0.04965206630416771
Trained batch 134 in epoch 7, gen_loss = 0.41206762194633484, disc_loss = 0.04943348521159755
Trained batch 135 in epoch 7, gen_loss = 0.41263911851188717, disc_loss = 0.049238204312346434
Trained batch 136 in epoch 7, gen_loss = 0.41295094907718854, disc_loss = 0.04894212565391603
Trained batch 137 in epoch 7, gen_loss = 0.4128114624299865, disc_loss = 0.04862106464924696
Trained batch 138 in epoch 7, gen_loss = 0.4127572341788587, disc_loss = 0.04829438690350746
Trained batch 139 in epoch 7, gen_loss = 0.4130148606640952, disc_loss = 0.04798067023511976
Trained batch 140 in epoch 7, gen_loss = 0.4133054800067388, disc_loss = 0.047718381393595154
Trained batch 141 in epoch 7, gen_loss = 0.4131978620106066, disc_loss = 0.04741164948135405
Trained batch 142 in epoch 7, gen_loss = 0.41337187640316836, disc_loss = 0.04710588999209808
Trained batch 143 in epoch 7, gen_loss = 0.4131024446752336, disc_loss = 0.046850008712176025
Trained batch 144 in epoch 7, gen_loss = 0.4134131320591631, disc_loss = 0.04658210420467217
Trained batch 145 in epoch 7, gen_loss = 0.41343568387913376, disc_loss = 0.04637592198161332
Trained batch 146 in epoch 7, gen_loss = 0.41310337246680745, disc_loss = 0.046144777861404786
Trained batch 147 in epoch 7, gen_loss = 0.41240473011055506, disc_loss = 0.04589430842787732
Trained batch 148 in epoch 7, gen_loss = 0.4125037435317199, disc_loss = 0.04573607520706602
Trained batch 149 in epoch 7, gen_loss = 0.4130436744292577, disc_loss = 0.045459123539427916
Trained batch 150 in epoch 7, gen_loss = 0.41329728214946015, disc_loss = 0.045248484818745924
Trained batch 151 in epoch 7, gen_loss = 0.41327570692489024, disc_loss = 0.04498160889335467
Trained batch 152 in epoch 7, gen_loss = 0.41280871824501386, disc_loss = 0.04473519576956926
Trained batch 153 in epoch 7, gen_loss = 0.41238487811831687, disc_loss = 0.04450395140591283
Trained batch 154 in epoch 7, gen_loss = 0.413286514436045, disc_loss = 0.04431822952183504
Trained batch 155 in epoch 7, gen_loss = 0.41328096580811036, disc_loss = 0.04408838314851985
Trained batch 156 in epoch 7, gen_loss = 0.4137220008737722, disc_loss = 0.04383389212511432
Trained batch 157 in epoch 7, gen_loss = 0.4137617515612252, disc_loss = 0.04358071364356276
Trained batch 158 in epoch 7, gen_loss = 0.4135807831332369, disc_loss = 0.04332892342804456
Trained batch 159 in epoch 7, gen_loss = 0.413614534586668, disc_loss = 0.04308424533810466
Trained batch 160 in epoch 7, gen_loss = 0.41329096229920476, disc_loss = 0.04283905983902514
Trained batch 161 in epoch 7, gen_loss = 0.41326150114153637, disc_loss = 0.04259366007740207
Trained batch 162 in epoch 7, gen_loss = 0.4133490503199993, disc_loss = 0.042356030352733616
Trained batch 163 in epoch 7, gen_loss = 0.41319172920250313, disc_loss = 0.04212311956543112
Trained batch 164 in epoch 7, gen_loss = 0.41317240704189645, disc_loss = 0.041916197377511046
Trained batch 165 in epoch 7, gen_loss = 0.41317063785461056, disc_loss = 0.04169454890112561
Trained batch 166 in epoch 7, gen_loss = 0.41320413101219133, disc_loss = 0.04157047447731752
Trained batch 167 in epoch 7, gen_loss = 0.41353328845330645, disc_loss = 0.041362354617809786
Trained batch 168 in epoch 7, gen_loss = 0.4134668924752072, disc_loss = 0.04115857983548084
Trained batch 169 in epoch 7, gen_loss = 0.4131160292555304, disc_loss = 0.041021911334246396
Trained batch 170 in epoch 7, gen_loss = 0.4131286583448711, disc_loss = 0.04083824713785223
Trained batch 171 in epoch 7, gen_loss = 0.4131777203360269, disc_loss = 0.040719697484746575
Trained batch 172 in epoch 7, gen_loss = 0.41315288764203906, disc_loss = 0.04050806324896699
Trained batch 173 in epoch 7, gen_loss = 0.41347799612872904, disc_loss = 0.040332420747834205
Trained batch 174 in epoch 7, gen_loss = 0.41338093417031424, disc_loss = 0.04012149153277278
Trained batch 175 in epoch 7, gen_loss = 0.41353739374740556, disc_loss = 0.03992064589560455
Trained batch 176 in epoch 7, gen_loss = 0.41347016772981415, disc_loss = 0.03970971128687599
Trained batch 177 in epoch 7, gen_loss = 0.41346247176106055, disc_loss = 0.039501614259095506
Trained batch 178 in epoch 7, gen_loss = 0.4132859157450372, disc_loss = 0.03934515433323533
Trained batch 179 in epoch 7, gen_loss = 0.41318926595979266, disc_loss = 0.039154290754555
Trained batch 180 in epoch 7, gen_loss = 0.4135563772027664, disc_loss = 0.039051852353658136
Trained batch 181 in epoch 7, gen_loss = 0.4137555508168189, disc_loss = 0.03889085518728409
Trained batch 182 in epoch 7, gen_loss = 0.4138145686173048, disc_loss = 0.038715109198552665
Trained batch 183 in epoch 7, gen_loss = 0.4137709500349086, disc_loss = 0.03858405663429395
Trained batch 184 in epoch 7, gen_loss = 0.41339926945196614, disc_loss = 0.03841457996970496
Trained batch 185 in epoch 7, gen_loss = 0.4137430026005673, disc_loss = 0.03823184408497826
Trained batch 186 in epoch 7, gen_loss = 0.41350904266464517, disc_loss = 0.03804814587421915
Trained batch 187 in epoch 7, gen_loss = 0.41376960277557373, disc_loss = 0.037868795718284366
Trained batch 188 in epoch 7, gen_loss = 0.4139909201828891, disc_loss = 0.037681808278812144
Trained batch 189 in epoch 7, gen_loss = 0.4138120792414013, disc_loss = 0.03751953508410799
Trained batch 190 in epoch 7, gen_loss = 0.41384136864028054, disc_loss = 0.037359620975964354
Trained batch 191 in epoch 7, gen_loss = 0.4141405451421936, disc_loss = 0.03717781430896139
Trained batch 192 in epoch 7, gen_loss = 0.4139804546697152, disc_loss = 0.03702469661088728
Trained batch 193 in epoch 7, gen_loss = 0.4141075752445103, disc_loss = 0.03686128248767831
Trained batch 194 in epoch 7, gen_loss = 0.41400010616351396, disc_loss = 0.03673968708429199
Trained batch 195 in epoch 7, gen_loss = 0.4143121596805903, disc_loss = 0.03659692636396432
Trained batch 196 in epoch 7, gen_loss = 0.4145647123985484, disc_loss = 0.03642545391209802
Trained batch 197 in epoch 7, gen_loss = 0.41442082912632916, disc_loss = 0.03626935949638448
Trained batch 198 in epoch 7, gen_loss = 0.4147674011525197, disc_loss = 0.03610747547038648
Trained batch 199 in epoch 7, gen_loss = 0.41501553639769556, disc_loss = 0.036000510001322254
Trained batch 200 in epoch 7, gen_loss = 0.4150248983902718, disc_loss = 0.03584850070168686
Trained batch 201 in epoch 7, gen_loss = 0.41511580687348204, disc_loss = 0.03568724164103001
Trained batch 202 in epoch 7, gen_loss = 0.4150942744586268, disc_loss = 0.03555242960189878
Trained batch 203 in epoch 7, gen_loss = 0.41504407235804724, disc_loss = 0.03542461223197261
Trained batch 204 in epoch 7, gen_loss = 0.415331046028835, disc_loss = 0.03526438570853959
Trained batch 205 in epoch 7, gen_loss = 0.4151412064878686, disc_loss = 0.03510846306899906
Trained batch 206 in epoch 7, gen_loss = 0.4149975716203883, disc_loss = 0.03495733708408684
Trained batch 207 in epoch 7, gen_loss = 0.41454934858931947, disc_loss = 0.03479980236107412
Trained batch 208 in epoch 7, gen_loss = 0.414436871497825, disc_loss = 0.0346489571019312
Trained batch 209 in epoch 7, gen_loss = 0.41428358200050536, disc_loss = 0.034521085790003694
Trained batch 210 in epoch 7, gen_loss = 0.41436794908690794, disc_loss = 0.034384420438409204
Trained batch 211 in epoch 7, gen_loss = 0.4142559361907671, disc_loss = 0.034276293446793095
Trained batch 212 in epoch 7, gen_loss = 0.41416167107546276, disc_loss = 0.03420467115610733
Trained batch 213 in epoch 7, gen_loss = 0.41401117329842574, disc_loss = 0.034088666621534695
Trained batch 214 in epoch 7, gen_loss = 0.4139517372430757, disc_loss = 0.033941372971288686
Trained batch 215 in epoch 7, gen_loss = 0.414088883333736, disc_loss = 0.03379635418187482
Trained batch 216 in epoch 7, gen_loss = 0.4142529380760984, disc_loss = 0.03365446340447197
Trained batch 217 in epoch 7, gen_loss = 0.4148554838852051, disc_loss = 0.03355033521822423
Trained batch 218 in epoch 7, gen_loss = 0.4149274657306061, disc_loss = 0.03341423534813707
Trained batch 219 in epoch 7, gen_loss = 0.41470866013656965, disc_loss = 0.03328721239337359
Trained batch 220 in epoch 7, gen_loss = 0.4149032717916221, disc_loss = 0.03317815409783628
Trained batch 221 in epoch 7, gen_loss = 0.41497548313828203, disc_loss = 0.033067093261198756
Trained batch 222 in epoch 7, gen_loss = 0.41514336207522406, disc_loss = 0.03295425689912865
Trained batch 223 in epoch 7, gen_loss = 0.41522730035441263, disc_loss = 0.03284132745154368
Trained batch 224 in epoch 7, gen_loss = 0.41533525851037767, disc_loss = 0.032709570906849374
Trained batch 225 in epoch 7, gen_loss = 0.4152557732520905, disc_loss = 0.03258385271991941
Trained batch 226 in epoch 7, gen_loss = 0.41511254268595826, disc_loss = 0.032451684827739906
Trained batch 227 in epoch 7, gen_loss = 0.4155306094571164, disc_loss = 0.0323992371875711
Trained batch 228 in epoch 7, gen_loss = 0.4153375170116341, disc_loss = 0.03244770695577379
Trained batch 229 in epoch 7, gen_loss = 0.415244752427806, disc_loss = 0.03246449990015801
Trained batch 230 in epoch 7, gen_loss = 0.415188983663336, disc_loss = 0.032389556850988044
Trained batch 231 in epoch 7, gen_loss = 0.4151672037511036, disc_loss = 0.03228765208944518
Trained batch 232 in epoch 7, gen_loss = 0.41496227943846087, disc_loss = 0.03219230493726489
Trained batch 233 in epoch 7, gen_loss = 0.4148214017478829, disc_loss = 0.03209946608533048
Trained batch 234 in epoch 7, gen_loss = 0.41512675488248785, disc_loss = 0.03200584243329123
Trained batch 235 in epoch 7, gen_loss = 0.4152549568374278, disc_loss = 0.031883927905671614
Trained batch 236 in epoch 7, gen_loss = 0.4151547123611225, disc_loss = 0.031780019660877214
Trained batch 237 in epoch 7, gen_loss = 0.4149256031803724, disc_loss = 0.03166858144711014
Trained batch 238 in epoch 7, gen_loss = 0.4149661309798891, disc_loss = 0.03154870338843177
Trained batch 239 in epoch 7, gen_loss = 0.4150483210881551, disc_loss = 0.031429648564274736
Trained batch 240 in epoch 7, gen_loss = 0.4150016644188972, disc_loss = 0.03131079300658399
Trained batch 241 in epoch 7, gen_loss = 0.4151239471494659, disc_loss = 0.031196825083129664
Trained batch 242 in epoch 7, gen_loss = 0.4149499542919206, disc_loss = 0.031083650638851424
Trained batch 243 in epoch 7, gen_loss = 0.41486897405053746, disc_loss = 0.030974731941852473
Trained batch 244 in epoch 7, gen_loss = 0.4148526028710969, disc_loss = 0.030862674845040454
Trained batch 245 in epoch 7, gen_loss = 0.41477374962674896, disc_loss = 0.030758251738923836
Trained batch 246 in epoch 7, gen_loss = 0.4147136701263397, disc_loss = 0.030666111957146087
Trained batch 247 in epoch 7, gen_loss = 0.41450192358705307, disc_loss = 0.03055540913145148
Trained batch 248 in epoch 7, gen_loss = 0.41429396123292456, disc_loss = 0.030449132534140444
Trained batch 249 in epoch 7, gen_loss = 0.4144419859647751, disc_loss = 0.03036194814182818
Trained batch 250 in epoch 7, gen_loss = 0.4143343566660862, disc_loss = 0.030258904817881457
Trained batch 251 in epoch 7, gen_loss = 0.4144198688722792, disc_loss = 0.030189046471764052
Trained batch 252 in epoch 7, gen_loss = 0.41444580156812555, disc_loss = 0.030128134957518385
Trained batch 253 in epoch 7, gen_loss = 0.4141682936685292, disc_loss = 0.030019806631048775
Trained batch 254 in epoch 7, gen_loss = 0.4141650425452812, disc_loss = 0.02991747346195374
Trained batch 255 in epoch 7, gen_loss = 0.4143505331594497, disc_loss = 0.0298100980990057
Trained batch 256 in epoch 7, gen_loss = 0.4144428414129562, disc_loss = 0.02971112055265515
Trained batch 257 in epoch 7, gen_loss = 0.41436840813289316, disc_loss = 0.029619283520241173
Trained batch 258 in epoch 7, gen_loss = 0.41433026247503213, disc_loss = 0.029540789253384048
Trained batch 259 in epoch 7, gen_loss = 0.41458154309254425, disc_loss = 0.029445754744721435
Trained batch 260 in epoch 7, gen_loss = 0.4143490314026902, disc_loss = 0.029344356760660977
Trained batch 261 in epoch 7, gen_loss = 0.41413167289650166, disc_loss = 0.029251979631087423
Trained batch 262 in epoch 7, gen_loss = 0.41395527849632524, disc_loss = 0.02919235934163426
Trained batch 263 in epoch 7, gen_loss = 0.41372160997354623, disc_loss = 0.029164348929153868
Trained batch 264 in epoch 7, gen_loss = 0.41368806991937024, disc_loss = 0.0290905660888145
Trained batch 265 in epoch 7, gen_loss = 0.4136858324807389, disc_loss = 0.029016815251110585
Trained batch 266 in epoch 7, gen_loss = 0.4137197547637568, disc_loss = 0.028927750821828788
Trained batch 267 in epoch 7, gen_loss = 0.4135306643238708, disc_loss = 0.028831653537597063
Trained batch 268 in epoch 7, gen_loss = 0.4136138621537659, disc_loss = 0.028744597116928394
Trained batch 269 in epoch 7, gen_loss = 0.4134727290383092, disc_loss = 0.028659565306130657
Trained batch 270 in epoch 7, gen_loss = 0.4135963270145149, disc_loss = 0.02857439275367041
Trained batch 271 in epoch 7, gen_loss = 0.41363692272673636, disc_loss = 0.028490900395006652
Trained batch 272 in epoch 7, gen_loss = 0.41368758995017724, disc_loss = 0.028395383254601024
Trained batch 273 in epoch 7, gen_loss = 0.41383419528494786, disc_loss = 0.028307577905272316
Trained batch 274 in epoch 7, gen_loss = 0.41370926835320215, disc_loss = 0.02821950774893842
Trained batch 275 in epoch 7, gen_loss = 0.41371041158403177, disc_loss = 0.028154763169552916
Trained batch 276 in epoch 7, gen_loss = 0.41392855556002595, disc_loss = 0.028063050924299372
Trained batch 277 in epoch 7, gen_loss = 0.4137609884035673, disc_loss = 0.02802210725197341
Trained batch 278 in epoch 7, gen_loss = 0.4136240034761395, disc_loss = 0.02793734483871489
Trained batch 279 in epoch 7, gen_loss = 0.41360473345432963, disc_loss = 0.027894927274402497
Trained batch 280 in epoch 7, gen_loss = 0.4132028265567861, disc_loss = 0.027928691866950156
Trained batch 281 in epoch 7, gen_loss = 0.41300061514191594, disc_loss = 0.02847053112498491
Trained batch 282 in epoch 7, gen_loss = 0.41299808867828586, disc_loss = 0.029045216731773196
Trained batch 283 in epoch 7, gen_loss = 0.41298237495439155, disc_loss = 0.029008220054019034
Trained batch 284 in epoch 7, gen_loss = 0.41293812090890447, disc_loss = 0.028999784980132653
Trained batch 285 in epoch 7, gen_loss = 0.41280410287680325, disc_loss = 0.02894364943047269
Trained batch 286 in epoch 7, gen_loss = 0.41251238235613197, disc_loss = 0.028930320033725702
Trained batch 287 in epoch 7, gen_loss = 0.4126699784149726, disc_loss = 0.02886276363844647
Trained batch 288 in epoch 7, gen_loss = 0.41283473960256084, disc_loss = 0.028823595425552306
Trained batch 289 in epoch 7, gen_loss = 0.4127856096317028, disc_loss = 0.028830414865133835
Trained batch 290 in epoch 7, gen_loss = 0.41256484829683077, disc_loss = 0.02893692656592994
Trained batch 291 in epoch 7, gen_loss = 0.4123303141087702, disc_loss = 0.03002745313298799
Trained batch 292 in epoch 7, gen_loss = 0.4123552758945947, disc_loss = 0.030830765259849485
Trained batch 293 in epoch 7, gen_loss = 0.4124054310678625, disc_loss = 0.030759477185649278
Trained batch 294 in epoch 7, gen_loss = 0.41237988108295504, disc_loss = 0.031070531824982518
Trained batch 295 in epoch 7, gen_loss = 0.4124658711858698, disc_loss = 0.030997315206961404
Trained batch 296 in epoch 7, gen_loss = 0.4124665906533649, disc_loss = 0.030996655806215474
Trained batch 297 in epoch 7, gen_loss = 0.4121994470189882, disc_loss = 0.03101145119121886
Trained batch 298 in epoch 7, gen_loss = 0.41189882727371013, disc_loss = 0.031080752616611165
Trained batch 299 in epoch 7, gen_loss = 0.41184532423814135, disc_loss = 0.03103613392682746
Trained batch 300 in epoch 7, gen_loss = 0.4118009587855038, disc_loss = 0.031289067291855766
Trained batch 301 in epoch 7, gen_loss = 0.4120185487712456, disc_loss = 0.032731159546239834
Trained batch 302 in epoch 7, gen_loss = 0.41205435361799236, disc_loss = 0.032887476222073234
Trained batch 303 in epoch 7, gen_loss = 0.41181957290360804, disc_loss = 0.03343426765748422
Trained batch 304 in epoch 7, gen_loss = 0.4117402014185171, disc_loss = 0.033463335708241726
Trained batch 305 in epoch 7, gen_loss = 0.41162994640325407, disc_loss = 0.033829333965995294
Trained batch 306 in epoch 7, gen_loss = 0.41133380353644927, disc_loss = 0.033784071911059636
Trained batch 307 in epoch 7, gen_loss = 0.4110625333019665, disc_loss = 0.033887070784339224
Trained batch 308 in epoch 7, gen_loss = 0.41116099691313834, disc_loss = 0.03381170405897773
Trained batch 309 in epoch 7, gen_loss = 0.4112087636224685, disc_loss = 0.03372986530809994
Trained batch 310 in epoch 7, gen_loss = 0.4110944349666117, disc_loss = 0.033644369946361496
Trained batch 311 in epoch 7, gen_loss = 0.4109163336837903, disc_loss = 0.03354859272486721
Trained batch 312 in epoch 7, gen_loss = 0.41082163645436587, disc_loss = 0.03347741254641059
Trained batch 313 in epoch 7, gen_loss = 0.41084572539967334, disc_loss = 0.033411556997953375
Trained batch 314 in epoch 7, gen_loss = 0.4106445378727383, disc_loss = 0.033326670035926834
Trained batch 315 in epoch 7, gen_loss = 0.4106590400768232, disc_loss = 0.0332332704462335
Trained batch 316 in epoch 7, gen_loss = 0.41044737008467835, disc_loss = 0.03314824935198653
Trained batch 317 in epoch 7, gen_loss = 0.4103446693727805, disc_loss = 0.03308074994513519
Trained batch 318 in epoch 7, gen_loss = 0.41030860806707303, disc_loss = 0.03300048913558519
Trained batch 319 in epoch 7, gen_loss = 0.4104676629416645, disc_loss = 0.03294486310260254
Trained batch 320 in epoch 7, gen_loss = 0.4102086195507525, disc_loss = 0.03298608168330032
Trained batch 321 in epoch 7, gen_loss = 0.41014576920811435, disc_loss = 0.03326402584839936
Trained batch 322 in epoch 7, gen_loss = 0.41005405442264425, disc_loss = 0.03327572713577226
Trained batch 323 in epoch 7, gen_loss = 0.40995629012216755, disc_loss = 0.03319809022632623
Trained batch 324 in epoch 7, gen_loss = 0.4102139248297765, disc_loss = 0.03312171343069237
Trained batch 325 in epoch 7, gen_loss = 0.41051629962730996, disc_loss = 0.03304597683625147
Trained batch 326 in epoch 7, gen_loss = 0.410447013396371, disc_loss = 0.0329673298960694
Trained batch 327 in epoch 7, gen_loss = 0.4104595671339733, disc_loss = 0.03290343647411025
Trained batch 328 in epoch 7, gen_loss = 0.4103742076995525, disc_loss = 0.03281395146156177
Trained batch 329 in epoch 7, gen_loss = 0.4103100460587126, disc_loss = 0.03290283517192372
Trained batch 330 in epoch 7, gen_loss = 0.4105181577882738, disc_loss = 0.03305124448474463
Trained batch 331 in epoch 7, gen_loss = 0.4105950735778694, disc_loss = 0.03296771623174581
Trained batch 332 in epoch 7, gen_loss = 0.41056666905815536, disc_loss = 0.032919851633057266
Trained batch 333 in epoch 7, gen_loss = 0.4103145083624446, disc_loss = 0.03312520784378877
Trained batch 334 in epoch 7, gen_loss = 0.4105987426060349, disc_loss = 0.03314447530906703
Trained batch 335 in epoch 7, gen_loss = 0.41070967265183017, disc_loss = 0.03327764897853956
Trained batch 336 in epoch 7, gen_loss = 0.4106870209604767, disc_loss = 0.03319618248557589
Trained batch 337 in epoch 7, gen_loss = 0.41070038318281343, disc_loss = 0.033225717795213695
Trained batch 338 in epoch 7, gen_loss = 0.41067653551565864, disc_loss = 0.033144571452338394
Trained batch 339 in epoch 7, gen_loss = 0.41062175552634633, disc_loss = 0.03306082545519423
Trained batch 340 in epoch 7, gen_loss = 0.4103427453299771, disc_loss = 0.03300267558263566
Trained batch 341 in epoch 7, gen_loss = 0.41029334260009187, disc_loss = 0.03292735411624876
Trained batch 342 in epoch 7, gen_loss = 0.4103852868427688, disc_loss = 0.032956722835296055
Trained batch 343 in epoch 7, gen_loss = 0.41045463630972906, disc_loss = 0.03287301630764485
Trained batch 344 in epoch 7, gen_loss = 0.4105592909930409, disc_loss = 0.032813743466133444
Trained batch 345 in epoch 7, gen_loss = 0.4106624900777905, disc_loss = 0.032733564790623594
Trained batch 346 in epoch 7, gen_loss = 0.4105437792172006, disc_loss = 0.03266252185250243
Trained batch 347 in epoch 7, gen_loss = 0.41071058347307404, disc_loss = 0.03262977490279203
Trained batch 348 in epoch 7, gen_loss = 0.41065729928221606, disc_loss = 0.032564960570237396
Trained batch 349 in epoch 7, gen_loss = 0.4103388604096004, disc_loss = 0.03248609826434404
Trained batch 350 in epoch 7, gen_loss = 0.41040332101688765, disc_loss = 0.03241402124442118
Trained batch 351 in epoch 7, gen_loss = 0.4103342985565012, disc_loss = 0.03233884021425514
Trained batch 352 in epoch 7, gen_loss = 0.4102870455544664, disc_loss = 0.03226315286261143
Trained batch 353 in epoch 7, gen_loss = 0.41021765263403875, disc_loss = 0.03233843837867328
Trained batch 354 in epoch 7, gen_loss = 0.410420466560713, disc_loss = 0.03260783542826457
Trained batch 355 in epoch 7, gen_loss = 0.4105198626103026, disc_loss = 0.032533319102563595
Trained batch 356 in epoch 7, gen_loss = 0.4105365690396947, disc_loss = 0.03247980081152787
Trained batch 357 in epoch 7, gen_loss = 0.41057155360389685, disc_loss = 0.032444889304051226
Trained batch 358 in epoch 7, gen_loss = 0.4106950220291329, disc_loss = 0.03238717601556736
Trained batch 359 in epoch 7, gen_loss = 0.41070890525976816, disc_loss = 0.03233540652694905
Trained batch 360 in epoch 7, gen_loss = 0.410790119144725, disc_loss = 0.03230804610556286
Trained batch 361 in epoch 7, gen_loss = 0.4106194179361038, disc_loss = 0.03222689946447062
Trained batch 362 in epoch 7, gen_loss = 0.4106495873001981, disc_loss = 0.03216530547410599
Trained batch 363 in epoch 7, gen_loss = 0.4108273504854559, disc_loss = 0.032098881977707515
Trained batch 364 in epoch 7, gen_loss = 0.41082737764267074, disc_loss = 0.03202072659520152
Trained batch 365 in epoch 7, gen_loss = 0.41099818498710466, disc_loss = 0.03194544322806527
Trained batch 366 in epoch 7, gen_loss = 0.4110994610214753, disc_loss = 0.031868158625844835
Trained batch 367 in epoch 7, gen_loss = 0.41117222874384857, disc_loss = 0.03179075465089662
Trained batch 368 in epoch 7, gen_loss = 0.41113044616329636, disc_loss = 0.03172046576783081
Trained batch 369 in epoch 7, gen_loss = 0.4111639756608654, disc_loss = 0.031643556473097086
Trained batch 370 in epoch 7, gen_loss = 0.4110690324775614, disc_loss = 0.03156874101418208
Trained batch 371 in epoch 7, gen_loss = 0.41106328600516884, disc_loss = 0.031496920174748824
Trained batch 372 in epoch 7, gen_loss = 0.4109860968653702, disc_loss = 0.03144260996518202
Trained batch 373 in epoch 7, gen_loss = 0.4106936775904926, disc_loss = 0.03153570075295268
Trained batch 374 in epoch 7, gen_loss = 0.41073207624753316, disc_loss = 0.031527478160957495
Trained batch 375 in epoch 7, gen_loss = 0.410743865243932, disc_loss = 0.03151593183692386
Trained batch 376 in epoch 7, gen_loss = 0.4106515902106895, disc_loss = 0.031482333300106566
Trained batch 377 in epoch 7, gen_loss = 0.4105515358624635, disc_loss = 0.031474218558441236
Trained batch 378 in epoch 7, gen_loss = 0.4108000084718488, disc_loss = 0.031465352679993515
Trained batch 379 in epoch 7, gen_loss = 0.41094916839348644, disc_loss = 0.03139439263675166
Trained batch 380 in epoch 7, gen_loss = 0.4108969029479139, disc_loss = 0.031326249069497575
Trained batch 381 in epoch 7, gen_loss = 0.4108679775168134, disc_loss = 0.031262348492566434
Trained batch 382 in epoch 7, gen_loss = 0.4108535231871642, disc_loss = 0.031187462084865874
Trained batch 383 in epoch 7, gen_loss = 0.41092281811870635, disc_loss = 0.031117874320746825
Trained batch 384 in epoch 7, gen_loss = 0.4109697527699656, disc_loss = 0.03105084250511771
Trained batch 385 in epoch 7, gen_loss = 0.41091400462111044, disc_loss = 0.030998677640810726
Trained batch 386 in epoch 7, gen_loss = 0.4107611642173402, disc_loss = 0.030925920869052912
Trained batch 387 in epoch 7, gen_loss = 0.4106917543355952, disc_loss = 0.03087184695855801
Trained batch 388 in epoch 7, gen_loss = 0.41070086683283125, disc_loss = 0.03080473586756516
Trained batch 389 in epoch 7, gen_loss = 0.4106585750213036, disc_loss = 0.030738034445004395
Trained batch 390 in epoch 7, gen_loss = 0.41057448626479226, disc_loss = 0.030664755569180222
Trained batch 391 in epoch 7, gen_loss = 0.41069188873682705, disc_loss = 0.03059939533407914
Trained batch 392 in epoch 7, gen_loss = 0.4105440626162609, disc_loss = 0.030527840424731903
Trained batch 393 in epoch 7, gen_loss = 0.41068734001689755, disc_loss = 0.030461738280228665
Trained batch 394 in epoch 7, gen_loss = 0.41084049608134016, disc_loss = 0.03040073646668675
Trained batch 395 in epoch 7, gen_loss = 0.41083731983948235, disc_loss = 0.03033555676099948
Trained batch 396 in epoch 7, gen_loss = 0.4108907929445694, disc_loss = 0.03029950877818131
Trained batch 397 in epoch 7, gen_loss = 0.4109881254446566, disc_loss = 0.030244067185511578
Trained batch 398 in epoch 7, gen_loss = 0.41110411883894366, disc_loss = 0.030223405250653923
Trained batch 399 in epoch 7, gen_loss = 0.41113711550831794, disc_loss = 0.030171703911037184
Trained batch 400 in epoch 7, gen_loss = 0.4112725254900735, disc_loss = 0.030113550026708298
Trained batch 401 in epoch 7, gen_loss = 0.4111657476988598, disc_loss = 0.030063951645736855
Trained batch 402 in epoch 7, gen_loss = 0.41117690936211615, disc_loss = 0.03001516932915092
Trained batch 403 in epoch 7, gen_loss = 0.4112543177486646, disc_loss = 0.02995122036732973
Trained batch 404 in epoch 7, gen_loss = 0.41121650286662725, disc_loss = 0.029888133983484205
Trained batch 405 in epoch 7, gen_loss = 0.4112258520472813, disc_loss = 0.0298511404343399
Trained batch 406 in epoch 7, gen_loss = 0.4113295959899115, disc_loss = 0.029793125072137182
Trained batch 407 in epoch 7, gen_loss = 0.41140130921906115, disc_loss = 0.02976089525641417
Trained batch 408 in epoch 7, gen_loss = 0.41132203728179184, disc_loss = 0.0296999060754917
Trained batch 409 in epoch 7, gen_loss = 0.411305938479377, disc_loss = 0.0296488772140725
Trained batch 410 in epoch 7, gen_loss = 0.4112678096967312, disc_loss = 0.029624346287359105
Trained batch 411 in epoch 7, gen_loss = 0.4112854163768222, disc_loss = 0.029570752687557846
Trained batch 412 in epoch 7, gen_loss = 0.41146878858455443, disc_loss = 0.029509078759190427
Trained batch 413 in epoch 7, gen_loss = 0.4114441704634883, disc_loss = 0.02947375870136553
Trained batch 414 in epoch 7, gen_loss = 0.41153367736253393, disc_loss = 0.029414498384660447
Trained batch 415 in epoch 7, gen_loss = 0.41164464596658945, disc_loss = 0.029358590417429626
Trained batch 416 in epoch 7, gen_loss = 0.4115161204652535, disc_loss = 0.029301354808429127
Trained batch 417 in epoch 7, gen_loss = 0.41158314206098257, disc_loss = 0.02923858795553428
Trained batch 418 in epoch 7, gen_loss = 0.41147373086797306, disc_loss = 0.029181430309117375
Trained batch 419 in epoch 7, gen_loss = 0.41147908653531756, disc_loss = 0.0291249340704997
Trained batch 420 in epoch 7, gen_loss = 0.4115821403449052, disc_loss = 0.02906411576511741
Trained batch 421 in epoch 7, gen_loss = 0.41135220081320306, disc_loss = 0.029006440335911172
Trained batch 422 in epoch 7, gen_loss = 0.4114193516842862, disc_loss = 0.02896840910671662
Trained batch 423 in epoch 7, gen_loss = 0.41142662874651403, disc_loss = 0.028905379434911324
Trained batch 424 in epoch 7, gen_loss = 0.41138538115164813, disc_loss = 0.02884422532227986
Trained batch 425 in epoch 7, gen_loss = 0.41131876017286184, disc_loss = 0.02878780141822609
Trained batch 426 in epoch 7, gen_loss = 0.41122909438135474, disc_loss = 0.02872677339596425
Trained batch 427 in epoch 7, gen_loss = 0.41127507144881187, disc_loss = 0.028677778797785568
Trained batch 428 in epoch 7, gen_loss = 0.4112120051900824, disc_loss = 0.02861762121493444
Trained batch 429 in epoch 7, gen_loss = 0.4110824050598366, disc_loss = 0.028567787129865137
Trained batch 430 in epoch 7, gen_loss = 0.4112543532162421, disc_loss = 0.02852125009932402
Trained batch 431 in epoch 7, gen_loss = 0.41121186433290996, disc_loss = 0.02846037204155302
Trained batch 432 in epoch 7, gen_loss = 0.411163291052913, disc_loss = 0.028403008671253747
Trained batch 433 in epoch 7, gen_loss = 0.4111468591448349, disc_loss = 0.028346049092916024
Trained batch 434 in epoch 7, gen_loss = 0.41108057896296185, disc_loss = 0.0282915650620714
Trained batch 435 in epoch 7, gen_loss = 0.41104637134239214, disc_loss = 0.02823845218918329
Trained batch 436 in epoch 7, gen_loss = 0.41108499273009924, disc_loss = 0.028193279212123334
Trained batch 437 in epoch 7, gen_loss = 0.4110334951039319, disc_loss = 0.02814697518043186
Trained batch 438 in epoch 7, gen_loss = 0.41094104806491616, disc_loss = 0.0281257678824636
Trained batch 439 in epoch 7, gen_loss = 0.4109068642285737, disc_loss = 0.028079573704268446
Trained batch 440 in epoch 7, gen_loss = 0.41085170138449895, disc_loss = 0.02805269308928865
Trained batch 441 in epoch 7, gen_loss = 0.41082626075496503, disc_loss = 0.02799544142921586
Trained batch 442 in epoch 7, gen_loss = 0.410757212754566, disc_loss = 0.027940889914534802
Trained batch 443 in epoch 7, gen_loss = 0.41066911957553914, disc_loss = 0.027888078812555922
Trained batch 444 in epoch 7, gen_loss = 0.410774510228232, disc_loss = 0.027834439282357862
Trained batch 445 in epoch 7, gen_loss = 0.4107330954662888, disc_loss = 0.027783761610644515
Trained batch 446 in epoch 7, gen_loss = 0.410808813718608, disc_loss = 0.0277309210276152
Trained batch 447 in epoch 7, gen_loss = 0.410740404988506, disc_loss = 0.02768017075816585
Trained batch 448 in epoch 7, gen_loss = 0.41074165131042156, disc_loss = 0.02762611553369542
Trained batch 449 in epoch 7, gen_loss = 0.41060578339629705, disc_loss = 0.02758417191139112
Trained batch 450 in epoch 7, gen_loss = 0.4106713181192225, disc_loss = 0.02752984469258815
Trained batch 451 in epoch 7, gen_loss = 0.41059930503895853, disc_loss = 0.0274769274679639
Trained batch 452 in epoch 7, gen_loss = 0.41071420322454, disc_loss = 0.027432822066751898
Trained batch 453 in epoch 7, gen_loss = 0.4107574550722139, disc_loss = 0.02737762180561126
Trained batch 454 in epoch 7, gen_loss = 0.41085623928478787, disc_loss = 0.02732381296630662
Trained batch 455 in epoch 7, gen_loss = 0.41106498600882396, disc_loss = 0.027281048074017458
Trained batch 456 in epoch 7, gen_loss = 0.4110973646265151, disc_loss = 0.02722717169926989
Trained batch 457 in epoch 7, gen_loss = 0.4111441819558498, disc_loss = 0.027181480182070433
Trained batch 458 in epoch 7, gen_loss = 0.4109118830794083, disc_loss = 0.027130804261525438
Trained batch 459 in epoch 7, gen_loss = 0.41076321601867677, disc_loss = 0.027078230657270583
Trained batch 460 in epoch 7, gen_loss = 0.41066959532636366, disc_loss = 0.027062824046958457
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.41425621509552, disc_loss = 0.0029526231810450554
Trained batch 1 in epoch 8, gen_loss = 0.39746031165122986, disc_loss = 0.00809755316004157
Trained batch 2 in epoch 8, gen_loss = 0.4141679008801778, disc_loss = 0.00658918172121048
Trained batch 3 in epoch 8, gen_loss = 0.414589561522007, disc_loss = 0.006140438839793205
Trained batch 4 in epoch 8, gen_loss = 0.41171478033065795, disc_loss = 0.0067878255620598795
Trained batch 5 in epoch 8, gen_loss = 0.4169025768836339, disc_loss = 0.00750234288473924
Trained batch 6 in epoch 8, gen_loss = 0.41724241631371634, disc_loss = 0.007524791572775159
Trained batch 7 in epoch 8, gen_loss = 0.4179524555802345, disc_loss = 0.007741054520010948
Trained batch 8 in epoch 8, gen_loss = 0.4241924484570821, disc_loss = 0.007311897895609339
Trained batch 9 in epoch 8, gen_loss = 0.41656152009963987, disc_loss = 0.006891433289274574
Trained batch 10 in epoch 8, gen_loss = 0.41456972739913245, disc_loss = 0.006812371228906241
Trained batch 11 in epoch 8, gen_loss = 0.41198356697956723, disc_loss = 0.00655026458359013
Trained batch 12 in epoch 8, gen_loss = 0.408427146764902, disc_loss = 0.006927628822338123
Trained batch 13 in epoch 8, gen_loss = 0.40920068323612213, disc_loss = 0.0073223677131214315
Trained batch 14 in epoch 8, gen_loss = 0.411323744058609, disc_loss = 0.007147331318507592
Trained batch 15 in epoch 8, gen_loss = 0.41337647661566734, disc_loss = 0.006927761773113161
Trained batch 16 in epoch 8, gen_loss = 0.4092677603749668, disc_loss = 0.006732253974084468
Trained batch 17 in epoch 8, gen_loss = 0.41118830773565507, disc_loss = 0.006596630348617004
Trained batch 18 in epoch 8, gen_loss = 0.4114911477816732, disc_loss = 0.006517789191811492
Trained batch 19 in epoch 8, gen_loss = 0.40831120163202284, disc_loss = 0.006468122114893049
Trained batch 20 in epoch 8, gen_loss = 0.40629881904238746, disc_loss = 0.0066176417749375105
Trained batch 21 in epoch 8, gen_loss = 0.4066976539113305, disc_loss = 0.00654165001205084
Trained batch 22 in epoch 8, gen_loss = 0.405940153028654, disc_loss = 0.006372936859564937
Trained batch 23 in epoch 8, gen_loss = 0.4049600052336852, disc_loss = 0.0062074182205833495
Trained batch 24 in epoch 8, gen_loss = 0.4045121264457703, disc_loss = 0.006162701193243265
Trained batch 25 in epoch 8, gen_loss = 0.40338313350310695, disc_loss = 0.006100979257518282
Trained batch 26 in epoch 8, gen_loss = 0.4059291062531648, disc_loss = 0.006008952942297414
Trained batch 27 in epoch 8, gen_loss = 0.4057478585413524, disc_loss = 0.005873993238700288
Trained batch 28 in epoch 8, gen_loss = 0.40461163582472964, disc_loss = 0.005758210807910253
Trained batch 29 in epoch 8, gen_loss = 0.40194754898548124, disc_loss = 0.00578492145674924
Trained batch 30 in epoch 8, gen_loss = 0.4028628324308703, disc_loss = 0.005708093927692502
Trained batch 31 in epoch 8, gen_loss = 0.40488592255860567, disc_loss = 0.005780176892585587
Trained batch 32 in epoch 8, gen_loss = 0.40597269209948456, disc_loss = 0.005702181387636246
Trained batch 33 in epoch 8, gen_loss = 0.406463565195308, disc_loss = 0.0068503917153815135
Trained batch 34 in epoch 8, gen_loss = 0.403653450523104, disc_loss = 0.00988460362090596
Trained batch 35 in epoch 8, gen_loss = 0.40460410383012557, disc_loss = 0.012696923772131817
Trained batch 36 in epoch 8, gen_loss = 0.4034426848630647, disc_loss = 0.013284592392124437
Trained batch 37 in epoch 8, gen_loss = 0.4026054394872565, disc_loss = 0.014584242690991806
Trained batch 38 in epoch 8, gen_loss = 0.4024411867826413, disc_loss = 0.01625899223682399
Trained batch 39 in epoch 8, gen_loss = 0.40172233879566194, disc_loss = 0.02308665940654464
Trained batch 40 in epoch 8, gen_loss = 0.4024644334141801, disc_loss = 0.03000035789431777
Trained batch 41 in epoch 8, gen_loss = 0.39906188490844907, disc_loss = 0.03323007462036219
Trained batch 42 in epoch 8, gen_loss = 0.3987052489158719, disc_loss = 0.03405755600718738
Trained batch 43 in epoch 8, gen_loss = 0.39713808352297003, disc_loss = 0.03437227762664075
Trained batch 44 in epoch 8, gen_loss = 0.39608247412575615, disc_loss = 0.03481402503223055
Trained batch 45 in epoch 8, gen_loss = 0.3965765147105507, disc_loss = 0.03483855649930141
Trained batch 46 in epoch 8, gen_loss = 0.3961728868332315, disc_loss = 0.034388073586284165
Trained batch 47 in epoch 8, gen_loss = 0.3972085832307736, disc_loss = 0.034328579907499567
Trained batch 48 in epoch 8, gen_loss = 0.3982471209399554, disc_loss = 0.033933975301416855
Trained batch 49 in epoch 8, gen_loss = 0.3998266851902008, disc_loss = 0.03431170139927417
Trained batch 50 in epoch 8, gen_loss = 0.3994025827622881, disc_loss = 0.0339891498990576
Trained batch 51 in epoch 8, gen_loss = 0.3982128013785069, disc_loss = 0.03394175940999188
Trained batch 52 in epoch 8, gen_loss = 0.4001573194872658, disc_loss = 0.03527635916241638
Trained batch 53 in epoch 8, gen_loss = 0.39798156751526725, disc_loss = 0.040621640130498064
Trained batch 54 in epoch 8, gen_loss = 0.398974793065678, disc_loss = 0.040609271117401397
Trained batch 55 in epoch 8, gen_loss = 0.39863739162683487, disc_loss = 0.0407915077812504
Trained batch 56 in epoch 8, gen_loss = 0.3991705006674716, disc_loss = 0.040423536611916985
Trained batch 57 in epoch 8, gen_loss = 0.3982724922484365, disc_loss = 0.04106667776319102
Trained batch 58 in epoch 8, gen_loss = 0.400341855772471, disc_loss = 0.04361234918252518
Trained batch 59 in epoch 8, gen_loss = 0.400523342192173, disc_loss = 0.04308998012371982
Trained batch 60 in epoch 8, gen_loss = 0.39855182317436716, disc_loss = 0.042969617370485526
Trained batch 61 in epoch 8, gen_loss = 0.39753798755907244, disc_loss = 0.04242670339637346
Trained batch 62 in epoch 8, gen_loss = 0.398427900340822, disc_loss = 0.041870685127962916
Trained batch 63 in epoch 8, gen_loss = 0.3988363458774984, disc_loss = 0.04140596482830006
Trained batch 64 in epoch 8, gen_loss = 0.3993715011156522, disc_loss = 0.04085934209064222
Trained batch 65 in epoch 8, gen_loss = 0.39932097088206897, disc_loss = 0.04054084768391807
Trained batch 66 in epoch 8, gen_loss = 0.39880779830377494, disc_loss = 0.040680920215212364
Trained batch 67 in epoch 8, gen_loss = 0.4002840120126219, disc_loss = 0.04076326428570182
Trained batch 68 in epoch 8, gen_loss = 0.4014864827411762, disc_loss = 0.04026462799410565
Trained batch 69 in epoch 8, gen_loss = 0.4010694056749344, disc_loss = 0.040188974970286444
Trained batch 70 in epoch 8, gen_loss = 0.40082731339293465, disc_loss = 0.04206708134283167
Trained batch 71 in epoch 8, gen_loss = 0.400790440539519, disc_loss = 0.04220138958771713
Trained batch 72 in epoch 8, gen_loss = 0.40147435379354923, disc_loss = 0.042330371066034864
Trained batch 73 in epoch 8, gen_loss = 0.40210199758813187, disc_loss = 0.04186542815767933
Trained batch 74 in epoch 8, gen_loss = 0.4024416534105937, disc_loss = 0.041730000975852215
Trained batch 75 in epoch 8, gen_loss = 0.40244996979048375, disc_loss = 0.041353619881096836
Trained batch 76 in epoch 8, gen_loss = 0.4021421396113061, disc_loss = 0.040943274059780425
Trained batch 77 in epoch 8, gen_loss = 0.4023622427231226, disc_loss = 0.04073945504840081
Trained batch 78 in epoch 8, gen_loss = 0.40233299437957476, disc_loss = 0.0402843467095466
Trained batch 79 in epoch 8, gen_loss = 0.4020473174750805, disc_loss = 0.03993732936505694
Trained batch 80 in epoch 8, gen_loss = 0.401804076300727, disc_loss = 0.03968172992096731
Trained batch 81 in epoch 8, gen_loss = 0.4010235056644533, disc_loss = 0.04040229068671512
Trained batch 82 in epoch 8, gen_loss = 0.40201850397041045, disc_loss = 0.042656948972291435
Trained batch 83 in epoch 8, gen_loss = 0.402368453286943, disc_loss = 0.042414125080020834
Trained batch 84 in epoch 8, gen_loss = 0.40242365563617033, disc_loss = 0.04272389896487927
Trained batch 85 in epoch 8, gen_loss = 0.40258266447588453, disc_loss = 0.04233641342292432
Trained batch 86 in epoch 8, gen_loss = 0.4024820834740825, disc_loss = 0.042070202189551174
Trained batch 87 in epoch 8, gen_loss = 0.40241924029859627, disc_loss = 0.04188518666672859
Trained batch 88 in epoch 8, gen_loss = 0.4030331503809168, disc_loss = 0.04180145841562765
Trained batch 89 in epoch 8, gen_loss = 0.4033656722969479, disc_loss = 0.04141724269785401
Trained batch 90 in epoch 8, gen_loss = 0.4028158895261995, disc_loss = 0.0418932858194419
Trained batch 91 in epoch 8, gen_loss = 0.4031614567274633, disc_loss = 0.04151369519177419
Trained batch 92 in epoch 8, gen_loss = 0.40323565531802436, disc_loss = 0.041334192130854853
Trained batch 93 in epoch 8, gen_loss = 0.403383694747661, disc_loss = 0.04118396465894469
Trained batch 94 in epoch 8, gen_loss = 0.40286312322867546, disc_loss = 0.040876736210070944
Trained batch 95 in epoch 8, gen_loss = 0.4029627464090784, disc_loss = 0.0405381333087765
Trained batch 96 in epoch 8, gen_loss = 0.4036043989904148, disc_loss = 0.04023805622865936
Trained batch 97 in epoch 8, gen_loss = 0.40340900968532173, disc_loss = 0.03988600181349154
Trained batch 98 in epoch 8, gen_loss = 0.4025634837270987, disc_loss = 0.03979159034835645
Trained batch 99 in epoch 8, gen_loss = 0.4030557480454445, disc_loss = 0.039747128423769026
Trained batch 100 in epoch 8, gen_loss = 0.4033447020124681, disc_loss = 0.039736365081078494
Trained batch 101 in epoch 8, gen_loss = 0.40255268239507486, disc_loss = 0.03967197941771398
Trained batch 102 in epoch 8, gen_loss = 0.40291569765331675, disc_loss = 0.039770699831774656
Trained batch 103 in epoch 8, gen_loss = 0.4028402188649544, disc_loss = 0.03954188551870175
Trained batch 104 in epoch 8, gen_loss = 0.40338118587221417, disc_loss = 0.03928577540043209
Trained batch 105 in epoch 8, gen_loss = 0.40381830255940276, disc_loss = 0.03897677695176582
Trained batch 106 in epoch 8, gen_loss = 0.4038403098271272, disc_loss = 0.03865467885587469
Trained batch 107 in epoch 8, gen_loss = 0.4038114986485905, disc_loss = 0.03837254133584254
Trained batch 108 in epoch 8, gen_loss = 0.4037772540105592, disc_loss = 0.038053764008976726
Trained batch 109 in epoch 8, gen_loss = 0.40369446900757877, disc_loss = 0.037778429919853806
Trained batch 110 in epoch 8, gen_loss = 0.40357464954659744, disc_loss = 0.03750170787863501
Trained batch 111 in epoch 8, gen_loss = 0.4031634152467762, disc_loss = 0.0371966558575098
Trained batch 112 in epoch 8, gen_loss = 0.40332078828220874, disc_loss = 0.03691198897704614
Trained batch 113 in epoch 8, gen_loss = 0.4036038849960294, disc_loss = 0.03663319423631357
Trained batch 114 in epoch 8, gen_loss = 0.4036731929882713, disc_loss = 0.03636432596198891
Trained batch 115 in epoch 8, gen_loss = 0.40378714378537806, disc_loss = 0.03620014606236384
Trained batch 116 in epoch 8, gen_loss = 0.4038090339073768, disc_loss = 0.035939620811746925
Trained batch 117 in epoch 8, gen_loss = 0.4040738861944716, disc_loss = 0.03574271406583741
Trained batch 118 in epoch 8, gen_loss = 0.40398766839203715, disc_loss = 0.035502975219625886
Trained batch 119 in epoch 8, gen_loss = 0.4040908972422282, disc_loss = 0.03538816284853965
Trained batch 120 in epoch 8, gen_loss = 0.40379968334820643, disc_loss = 0.035141140861390543
Trained batch 121 in epoch 8, gen_loss = 0.404460789727383, disc_loss = 0.035368170184617645
Trained batch 122 in epoch 8, gen_loss = 0.4040904641151428, disc_loss = 0.03657913270853157
Trained batch 123 in epoch 8, gen_loss = 0.40474231829566343, disc_loss = 0.03778506505243
Trained batch 124 in epoch 8, gen_loss = 0.404815943479538, disc_loss = 0.03841097261756658
Trained batch 125 in epoch 8, gen_loss = 0.40523325994847315, disc_loss = 0.03829218110897475
Trained batch 126 in epoch 8, gen_loss = 0.4060126916160734, disc_loss = 0.03816287410922173
Trained batch 127 in epoch 8, gen_loss = 0.40580150624737144, disc_loss = 0.03813778170297155
Trained batch 128 in epoch 8, gen_loss = 0.40616302273070165, disc_loss = 0.03801484421155481
Trained batch 129 in epoch 8, gen_loss = 0.4058217179316741, disc_loss = 0.03779645689691489
Trained batch 130 in epoch 8, gen_loss = 0.40637853445897576, disc_loss = 0.03770411934504527
Trained batch 131 in epoch 8, gen_loss = 0.4064181108366359, disc_loss = 0.0376026135389552
Trained batch 132 in epoch 8, gen_loss = 0.4063753649256283, disc_loss = 0.037397967273355426
Trained batch 133 in epoch 8, gen_loss = 0.4063653839168264, disc_loss = 0.037148386281706504
Trained batch 134 in epoch 8, gen_loss = 0.40615647148202966, disc_loss = 0.036924357222462144
Trained batch 135 in epoch 8, gen_loss = 0.40615394711494446, disc_loss = 0.03669516040998347
Trained batch 136 in epoch 8, gen_loss = 0.40616784826682434, disc_loss = 0.036471921994765524
Trained batch 137 in epoch 8, gen_loss = 0.40564773480097455, disc_loss = 0.03625898695199926
Trained batch 138 in epoch 8, gen_loss = 0.4056989436955761, disc_loss = 0.03603144188699641
Trained batch 139 in epoch 8, gen_loss = 0.4054067241294043, disc_loss = 0.035803081950039735
Trained batch 140 in epoch 8, gen_loss = 0.40515854510855165, disc_loss = 0.0355771457816058
Trained batch 141 in epoch 8, gen_loss = 0.4049583383848969, disc_loss = 0.03536359845778682
Trained batch 142 in epoch 8, gen_loss = 0.4047246815024556, disc_loss = 0.03525080350129963
Trained batch 143 in epoch 8, gen_loss = 0.40447373998661834, disc_loss = 0.035040013336886965
Trained batch 144 in epoch 8, gen_loss = 0.4042383549542263, disc_loss = 0.03497465972242684
Trained batch 145 in epoch 8, gen_loss = 0.40399008662733316, disc_loss = 0.034967656566263876
Trained batch 146 in epoch 8, gen_loss = 0.40439836346373265, disc_loss = 0.034913008247001644
Trained batch 147 in epoch 8, gen_loss = 0.4043874718450211, disc_loss = 0.03509990779078893
Trained batch 148 in epoch 8, gen_loss = 0.4050952930178418, disc_loss = 0.035607122822395906
Trained batch 149 in epoch 8, gen_loss = 0.4052163420120875, disc_loss = 0.03544948223357399
Trained batch 150 in epoch 8, gen_loss = 0.4053171800067093, disc_loss = 0.035359556490666424
Trained batch 151 in epoch 8, gen_loss = 0.4052902336575483, disc_loss = 0.035315596504676104
Trained batch 152 in epoch 8, gen_loss = 0.4057963248950983, disc_loss = 0.03525697736349565
Trained batch 153 in epoch 8, gen_loss = 0.4057979777261808, disc_loss = 0.03531175464173997
Trained batch 154 in epoch 8, gen_loss = 0.4058618151372479, disc_loss = 0.03531196842631025
Trained batch 155 in epoch 8, gen_loss = 0.40617355761619717, disc_loss = 0.03519508405588567
Trained batch 156 in epoch 8, gen_loss = 0.4060459023068665, disc_loss = 0.03501237322617868
Trained batch 157 in epoch 8, gen_loss = 0.40607989060727856, disc_loss = 0.034837434687239086
Trained batch 158 in epoch 8, gen_loss = 0.4057811056293032, disc_loss = 0.034678603522479534
Trained batch 159 in epoch 8, gen_loss = 0.40582682117819785, disc_loss = 0.03451156762894243
Trained batch 160 in epoch 8, gen_loss = 0.4056476623005008, disc_loss = 0.03431685272349704
Trained batch 161 in epoch 8, gen_loss = 0.4059975509658272, disc_loss = 0.03412196677419598
Trained batch 162 in epoch 8, gen_loss = 0.4059944820184649, disc_loss = 0.033926311023304796
Trained batch 163 in epoch 8, gen_loss = 0.40585053748473887, disc_loss = 0.033738773451016356
Trained batch 164 in epoch 8, gen_loss = 0.40597478620933763, disc_loss = 0.033549893095694255
Trained batch 165 in epoch 8, gen_loss = 0.405624474208039, disc_loss = 0.03338333697434156
Trained batch 166 in epoch 8, gen_loss = 0.405503722186574, disc_loss = 0.033205843307524026
Trained batch 167 in epoch 8, gen_loss = 0.4056658824639661, disc_loss = 0.03305314746519018
Trained batch 168 in epoch 8, gen_loss = 0.40555620722516755, disc_loss = 0.03289339628302046
Trained batch 169 in epoch 8, gen_loss = 0.4056925035574857, disc_loss = 0.032718137436655956
Trained batch 170 in epoch 8, gen_loss = 0.4053451685529006, disc_loss = 0.032551621946054154
Trained batch 171 in epoch 8, gen_loss = 0.40505342722632165, disc_loss = 0.032378306080381454
Trained batch 172 in epoch 8, gen_loss = 0.4049939211737903, disc_loss = 0.032202124324454955
Trained batch 173 in epoch 8, gen_loss = 0.4050042058887153, disc_loss = 0.03203183266497485
Trained batch 174 in epoch 8, gen_loss = 0.40524318439619883, disc_loss = 0.03186253744377089
Trained batch 175 in epoch 8, gen_loss = 0.40548620660873974, disc_loss = 0.03169476703161225
Trained batch 176 in epoch 8, gen_loss = 0.4054910858808938, disc_loss = 0.031532425344605944
Trained batch 177 in epoch 8, gen_loss = 0.4055126567235154, disc_loss = 0.031366338498832844
Trained batch 178 in epoch 8, gen_loss = 0.40538906102073924, disc_loss = 0.03120973176132971
Trained batch 179 in epoch 8, gen_loss = 0.4060466287864579, disc_loss = 0.031067556712595333
Trained batch 180 in epoch 8, gen_loss = 0.40620089910965596, disc_loss = 0.030922455790977493
Trained batch 181 in epoch 8, gen_loss = 0.40670059866957614, disc_loss = 0.030789546126750514
Trained batch 182 in epoch 8, gen_loss = 0.4066804150740306, disc_loss = 0.03064028126291951
Trained batch 183 in epoch 8, gen_loss = 0.4066069765907267, disc_loss = 0.0304915620711298
Trained batch 184 in epoch 8, gen_loss = 0.4067403727286571, disc_loss = 0.03034017167268069
Trained batch 185 in epoch 8, gen_loss = 0.40668398894930397, disc_loss = 0.030194137115857653
Trained batch 186 in epoch 8, gen_loss = 0.40632046161488417, disc_loss = 0.030054518639827197
Trained batch 187 in epoch 8, gen_loss = 0.4061715881875221, disc_loss = 0.029901919266620176
Trained batch 188 in epoch 8, gen_loss = 0.4064225841451574, disc_loss = 0.02978446059084187
Trained batch 189 in epoch 8, gen_loss = 0.40653032754596913, disc_loss = 0.029641386570629518
Trained batch 190 in epoch 8, gen_loss = 0.4065241821461323, disc_loss = 0.029509525861303416
Trained batch 191 in epoch 8, gen_loss = 0.40660931495949626, disc_loss = 0.029368584706996142
Trained batch 192 in epoch 8, gen_loss = 0.4064891222536255, disc_loss = 0.029226321874818537
Trained batch 193 in epoch 8, gen_loss = 0.4062996872307099, disc_loss = 0.029088469426814926
Trained batch 194 in epoch 8, gen_loss = 0.4063668535305904, disc_loss = 0.02895075443905229
Trained batch 195 in epoch 8, gen_loss = 0.4061623416384872, disc_loss = 0.028814236261069357
Trained batch 196 in epoch 8, gen_loss = 0.40583242392782026, disc_loss = 0.02867958689437054
Trained batch 197 in epoch 8, gen_loss = 0.40549567341804504, disc_loss = 0.028549696354670546
Trained batch 198 in epoch 8, gen_loss = 0.405480750841112, disc_loss = 0.02845490944569453
Trained batch 199 in epoch 8, gen_loss = 0.4056337189674377, disc_loss = 0.028320862547843717
Trained batch 200 in epoch 8, gen_loss = 0.4054383439804191, disc_loss = 0.028207390983264653
Trained batch 201 in epoch 8, gen_loss = 0.40527085915650474, disc_loss = 0.02807828756383537
Trained batch 202 in epoch 8, gen_loss = 0.4050916179353968, disc_loss = 0.027958802324306826
Trained batch 203 in epoch 8, gen_loss = 0.4053073784007746, disc_loss = 0.0278407281964296
Trained batch 204 in epoch 8, gen_loss = 0.40540720049927875, disc_loss = 0.02771891423262565
Trained batch 205 in epoch 8, gen_loss = 0.4053638108725687, disc_loss = 0.02759995298896401
Trained batch 206 in epoch 8, gen_loss = 0.40571245450328514, disc_loss = 0.027476705669803356
Trained batch 207 in epoch 8, gen_loss = 0.40554844143872076, disc_loss = 0.027363935833049115
Trained batch 208 in epoch 8, gen_loss = 0.4055489516999733, disc_loss = 0.027246463770363213
Trained batch 209 in epoch 8, gen_loss = 0.4057195478961581, disc_loss = 0.02712745799272809
Trained batch 210 in epoch 8, gen_loss = 0.40578341851302235, disc_loss = 0.027010337521887043
Trained batch 211 in epoch 8, gen_loss = 0.4055318234945243, disc_loss = 0.026897805327228887
Trained batch 212 in epoch 8, gen_loss = 0.40555410583813983, disc_loss = 0.026782160296384683
Trained batch 213 in epoch 8, gen_loss = 0.40534818283865387, disc_loss = 0.0266672321176374
Trained batch 214 in epoch 8, gen_loss = 0.40545829492946006, disc_loss = 0.02655996680313851
Trained batch 215 in epoch 8, gen_loss = 0.40534904116281756, disc_loss = 0.02645191357900061
Trained batch 216 in epoch 8, gen_loss = 0.4052404177628355, disc_loss = 0.026336648929027266
Trained batch 217 in epoch 8, gen_loss = 0.4053195781937433, disc_loss = 0.02622588713698243
Trained batch 218 in epoch 8, gen_loss = 0.405367846902647, disc_loss = 0.02611654066772
Trained batch 219 in epoch 8, gen_loss = 0.4052533355626193, disc_loss = 0.026007625157415698
Trained batch 220 in epoch 8, gen_loss = 0.405123568228467, disc_loss = 0.025896316622826376
Trained batch 221 in epoch 8, gen_loss = 0.40481379977217663, disc_loss = 0.025785493248075178
Trained batch 222 in epoch 8, gen_loss = 0.4050341645431091, disc_loss = 0.025693474330150026
Trained batch 223 in epoch 8, gen_loss = 0.40530041818107876, disc_loss = 0.0256004292282991
Trained batch 224 in epoch 8, gen_loss = 0.40551569514804414, disc_loss = 0.025503534704653753
Trained batch 225 in epoch 8, gen_loss = 0.40553657090769407, disc_loss = 0.025403861320099537
Trained batch 226 in epoch 8, gen_loss = 0.40521634097666465, disc_loss = 0.025301382448196016
Trained batch 227 in epoch 8, gen_loss = 0.4051853107255802, disc_loss = 0.025200070451798017
Trained batch 228 in epoch 8, gen_loss = 0.405157283403988, disc_loss = 0.025100819544874815
Trained batch 229 in epoch 8, gen_loss = 0.40505685832189475, disc_loss = 0.025000455515945087
Trained batch 230 in epoch 8, gen_loss = 0.4046692288283146, disc_loss = 0.024927850250251495
Trained batch 231 in epoch 8, gen_loss = 0.40438386271225996, disc_loss = 0.0248271622785351
Trained batch 232 in epoch 8, gen_loss = 0.4047103499905746, disc_loss = 0.02476623904283754
Trained batch 233 in epoch 8, gen_loss = 0.40439963633688086, disc_loss = 0.0246946986607459
Trained batch 234 in epoch 8, gen_loss = 0.40438746898732286, disc_loss = 0.024608654529847045
Trained batch 235 in epoch 8, gen_loss = 0.4042739409763934, disc_loss = 0.02451514461081696
Trained batch 236 in epoch 8, gen_loss = 0.4044129983030794, disc_loss = 0.024420142123664293
Trained batch 237 in epoch 8, gen_loss = 0.40429118801565733, disc_loss = 0.024326369248549726
Trained batch 238 in epoch 8, gen_loss = 0.4040824722296025, disc_loss = 0.02422983039981027
Trained batch 239 in epoch 8, gen_loss = 0.4041938230395317, disc_loss = 0.02414734531970074
Trained batch 240 in epoch 8, gen_loss = 0.4041448214489395, disc_loss = 0.024052828273067397
Trained batch 241 in epoch 8, gen_loss = 0.40395868477249935, disc_loss = 0.023961873818381326
Trained batch 242 in epoch 8, gen_loss = 0.4038314417065907, disc_loss = 0.02387042365749769
Trained batch 243 in epoch 8, gen_loss = 0.40377372710919773, disc_loss = 0.02377926880497577
Trained batch 244 in epoch 8, gen_loss = 0.40389908844110917, disc_loss = 0.023692904372832606
Trained batch 245 in epoch 8, gen_loss = 0.40381053102210285, disc_loss = 0.023604889400303364
Trained batch 246 in epoch 8, gen_loss = 0.4037611701710504, disc_loss = 0.023515624251510752
Trained batch 247 in epoch 8, gen_loss = 0.4037795576357072, disc_loss = 0.023430637265142475
Trained batch 248 in epoch 8, gen_loss = 0.40385664143715516, disc_loss = 0.023345902115181387
Trained batch 249 in epoch 8, gen_loss = 0.40375511276721954, disc_loss = 0.023258299541659654
Trained batch 250 in epoch 8, gen_loss = 0.4036745470596025, disc_loss = 0.023171584788836033
Trained batch 251 in epoch 8, gen_loss = 0.403750122657844, disc_loss = 0.023086123635053694
Trained batch 252 in epoch 8, gen_loss = 0.40359608528642316, disc_loss = 0.023005927387411473
Trained batch 253 in epoch 8, gen_loss = 0.4032844660554345, disc_loss = 0.022925733776550418
Trained batch 254 in epoch 8, gen_loss = 0.40333205578373926, disc_loss = 0.02284339068676619
Trained batch 255 in epoch 8, gen_loss = 0.40314647008199245, disc_loss = 0.02276927319508104
Trained batch 256 in epoch 8, gen_loss = 0.4029146821350439, disc_loss = 0.02269103945004627
Trained batch 257 in epoch 8, gen_loss = 0.40279444104941314, disc_loss = 0.02260953861797705
Trained batch 258 in epoch 8, gen_loss = 0.40256624309252587, disc_loss = 0.0225314569100378
Trained batch 259 in epoch 8, gen_loss = 0.4023111496980374, disc_loss = 0.02245101948053791
Trained batch 260 in epoch 8, gen_loss = 0.40199940734439427, disc_loss = 0.02237266268745293
Trained batch 261 in epoch 8, gen_loss = 0.40203156077679786, disc_loss = 0.022295677636302153
Trained batch 262 in epoch 8, gen_loss = 0.4020016328236903, disc_loss = 0.02221710704658322
Trained batch 263 in epoch 8, gen_loss = 0.40181012553247536, disc_loss = 0.022139863888503787
Trained batch 264 in epoch 8, gen_loss = 0.4014234829623744, disc_loss = 0.02206427786666197
Trained batch 265 in epoch 8, gen_loss = 0.4011759075679277, disc_loss = 0.021986126953112733
Trained batch 266 in epoch 8, gen_loss = 0.4009315869334932, disc_loss = 0.0219127383956874
Trained batch 267 in epoch 8, gen_loss = 0.40104590912363425, disc_loss = 0.021839979008264118
Trained batch 268 in epoch 8, gen_loss = 0.4009135281286275, disc_loss = 0.021764143970777666
Trained batch 269 in epoch 8, gen_loss = 0.4011615554491679, disc_loss = 0.02170071046695941
Trained batch 270 in epoch 8, gen_loss = 0.40108948286169127, disc_loss = 0.021642715486309517
Trained batch 271 in epoch 8, gen_loss = 0.400842432918794, disc_loss = 0.021570639306446537
Trained batch 272 in epoch 8, gen_loss = 0.4009288041801243, disc_loss = 0.021526863254374747
Trained batch 273 in epoch 8, gen_loss = 0.40078756050036773, disc_loss = 0.021474031974513925
Trained batch 274 in epoch 8, gen_loss = 0.4006486562165347, disc_loss = 0.021400740099647507
Trained batch 275 in epoch 8, gen_loss = 0.4005093238707902, disc_loss = 0.021334191212730915
Trained batch 276 in epoch 8, gen_loss = 0.40055450743286186, disc_loss = 0.02127085941371303
Trained batch 277 in epoch 8, gen_loss = 0.40045491611357215, disc_loss = 0.0212032239446115
Trained batch 278 in epoch 8, gen_loss = 0.40033790234169225, disc_loss = 0.021142519672074117
Trained batch 279 in epoch 8, gen_loss = 0.4003774589725903, disc_loss = 0.021075741255273377
Trained batch 280 in epoch 8, gen_loss = 0.4004010895393073, disc_loss = 0.021010643411908312
Trained batch 281 in epoch 8, gen_loss = 0.4003844795920325, disc_loss = 0.020940158260632835
Trained batch 282 in epoch 8, gen_loss = 0.4002360228725541, disc_loss = 0.020871935916205623
Trained batch 283 in epoch 8, gen_loss = 0.4002411346620237, disc_loss = 0.020805040392024497
Trained batch 284 in epoch 8, gen_loss = 0.4001961318024418, disc_loss = 0.020739421265183442
Trained batch 285 in epoch 8, gen_loss = 0.3999954250517425, disc_loss = 0.020678642160711823
Trained batch 286 in epoch 8, gen_loss = 0.3998897857574636, disc_loss = 0.02062058908976809
Trained batch 287 in epoch 8, gen_loss = 0.40007767195088995, disc_loss = 0.020566907748919522
Trained batch 288 in epoch 8, gen_loss = 0.3998542817818665, disc_loss = 0.0205053155375709
Trained batch 289 in epoch 8, gen_loss = 0.399841597162444, disc_loss = 0.02044690233245813
Trained batch 290 in epoch 8, gen_loss = 0.4000180974039425, disc_loss = 0.020385259905225148
Trained batch 291 in epoch 8, gen_loss = 0.39984291332633526, disc_loss = 0.02032450836650989
Trained batch 292 in epoch 8, gen_loss = 0.39958687803037335, disc_loss = 0.0202644646335425
Trained batch 293 in epoch 8, gen_loss = 0.3996077985787878, disc_loss = 0.020202772807073305
Trained batch 294 in epoch 8, gen_loss = 0.3994170098991717, disc_loss = 0.02013966438905099
Trained batch 295 in epoch 8, gen_loss = 0.3993670389660307, disc_loss = 0.020079958488979074
Trained batch 296 in epoch 8, gen_loss = 0.39945261526589443, disc_loss = 0.020021931555589366
Trained batch 297 in epoch 8, gen_loss = 0.3995478641266791, disc_loss = 0.019968872773070388
Trained batch 298 in epoch 8, gen_loss = 0.39942644491642215, disc_loss = 0.01990766128187183
Trained batch 299 in epoch 8, gen_loss = 0.3993060462673505, disc_loss = 0.019848472497348363
Trained batch 300 in epoch 8, gen_loss = 0.3991125278496663, disc_loss = 0.019789238657997272
Trained batch 301 in epoch 8, gen_loss = 0.39908166663930905, disc_loss = 0.01972823920590334
Trained batch 302 in epoch 8, gen_loss = 0.39905899241812554, disc_loss = 0.019667407973414354
Trained batch 303 in epoch 8, gen_loss = 0.3988197994859595, disc_loss = 0.0196077929408363
Trained batch 304 in epoch 8, gen_loss = 0.39893566457951657, disc_loss = 0.019551806196906284
Trained batch 305 in epoch 8, gen_loss = 0.39909008700473636, disc_loss = 0.019495846477665883
Trained batch 306 in epoch 8, gen_loss = 0.3990905745992443, disc_loss = 0.019436347101896952
Trained batch 307 in epoch 8, gen_loss = 0.3991336383215793, disc_loss = 0.019383182184462278
Trained batch 308 in epoch 8, gen_loss = 0.39920357332646267, disc_loss = 0.019326868723975463
Trained batch 309 in epoch 8, gen_loss = 0.3991759433861702, disc_loss = 0.019269606890156867
Trained batch 310 in epoch 8, gen_loss = 0.39921310802747967, disc_loss = 0.019214332527466047
Trained batch 311 in epoch 8, gen_loss = 0.3992649706510397, disc_loss = 0.01915884568827609
Trained batch 312 in epoch 8, gen_loss = 0.3988610142336105, disc_loss = 0.019110017151128464
Trained batch 313 in epoch 8, gen_loss = 0.39909566056196855, disc_loss = 0.019062690358241176
Trained batch 314 in epoch 8, gen_loss = 0.3991566662750547, disc_loss = 0.019014916524645827
Trained batch 315 in epoch 8, gen_loss = 0.39936173330002195, disc_loss = 0.018961587794054345
Trained batch 316 in epoch 8, gen_loss = 0.3994616092379537, disc_loss = 0.018909290197895903
Trained batch 317 in epoch 8, gen_loss = 0.3993127832435212, disc_loss = 0.01886246274606143
Trained batch 318 in epoch 8, gen_loss = 0.3994215913700833, disc_loss = 0.018815845849582208
Trained batch 319 in epoch 8, gen_loss = 0.39944038465619086, disc_loss = 0.01876094691506296
Trained batch 320 in epoch 8, gen_loss = 0.3994382915095748, disc_loss = 0.01870741658355182
Trained batch 321 in epoch 8, gen_loss = 0.3992820654226386, disc_loss = 0.018652978145317838
Trained batch 322 in epoch 8, gen_loss = 0.3992798754674362, disc_loss = 0.01860314807040046
Trained batch 323 in epoch 8, gen_loss = 0.39924274210208727, disc_loss = 0.018549465507133805
Trained batch 324 in epoch 8, gen_loss = 0.3988969404880817, disc_loss = 0.018507599770807875
Trained batch 325 in epoch 8, gen_loss = 0.39875343195134144, disc_loss = 0.01845958693691478
Trained batch 326 in epoch 8, gen_loss = 0.3986473737871246, disc_loss = 0.018413691471376392
Trained batch 327 in epoch 8, gen_loss = 0.39873371455000667, disc_loss = 0.018363863446610618
Trained batch 328 in epoch 8, gen_loss = 0.39888855090257247, disc_loss = 0.018314345810904895
Trained batch 329 in epoch 8, gen_loss = 0.3988700317614006, disc_loss = 0.018265514581280787
Trained batch 330 in epoch 8, gen_loss = 0.3988377083644406, disc_loss = 0.018213695187045662
Trained batch 331 in epoch 8, gen_loss = 0.3989711476557226, disc_loss = 0.018164217994893418
Trained batch 332 in epoch 8, gen_loss = 0.39901692453805393, disc_loss = 0.018116397155636177
Trained batch 333 in epoch 8, gen_loss = 0.3990150413470354, disc_loss = 0.01807223509301426
Trained batch 334 in epoch 8, gen_loss = 0.3989578207037342, disc_loss = 0.018023089064396362
Trained batch 335 in epoch 8, gen_loss = 0.39896922407760504, disc_loss = 0.017974211378064604
Trained batch 336 in epoch 8, gen_loss = 0.39904286175170356, disc_loss = 0.017931149193660553
Trained batch 337 in epoch 8, gen_loss = 0.3989389371237106, disc_loss = 0.017882138698708992
Trained batch 338 in epoch 8, gen_loss = 0.3988003442421072, disc_loss = 0.017836913734311816
Trained batch 339 in epoch 8, gen_loss = 0.3987848901573349, disc_loss = 0.017789287503247205
Trained batch 340 in epoch 8, gen_loss = 0.3987656933995636, disc_loss = 0.017740569165853176
Trained batch 341 in epoch 8, gen_loss = 0.3988729026059658, disc_loss = 0.01769803349052594
Trained batch 342 in epoch 8, gen_loss = 0.3989856699291541, disc_loss = 0.01766358666446429
Trained batch 343 in epoch 8, gen_loss = 0.3989817114590212, disc_loss = 0.017615771272049156
Trained batch 344 in epoch 8, gen_loss = 0.39875921365143596, disc_loss = 0.01757755734033181
Trained batch 345 in epoch 8, gen_loss = 0.39866623161845127, disc_loss = 0.017536404348487262
Trained batch 346 in epoch 8, gen_loss = 0.39881220889366326, disc_loss = 0.017490804800965022
Trained batch 347 in epoch 8, gen_loss = 0.39873783727144374, disc_loss = 0.01744613783191836
Trained batch 348 in epoch 8, gen_loss = 0.39889778260856784, disc_loss = 0.01740052329074794
Trained batch 349 in epoch 8, gen_loss = 0.39899571776390075, disc_loss = 0.01735817632438349
Trained batch 350 in epoch 8, gen_loss = 0.3988246279224711, disc_loss = 0.017312984597508362
Trained batch 351 in epoch 8, gen_loss = 0.39867202429608867, disc_loss = 0.017266915251225742
Trained batch 352 in epoch 8, gen_loss = 0.3985282086448021, disc_loss = 0.01722962981770633
Trained batch 353 in epoch 8, gen_loss = 0.39847038492644576, disc_loss = 0.01718443745449922
Trained batch 354 in epoch 8, gen_loss = 0.39856329568674864, disc_loss = 0.017149272855554877
Trained batch 355 in epoch 8, gen_loss = 0.39865011236305986, disc_loss = 0.017112766380102656
Trained batch 356 in epoch 8, gen_loss = 0.3986500691132051, disc_loss = 0.01707463384298112
Trained batch 357 in epoch 8, gen_loss = 0.39847194865429203, disc_loss = 0.01703988540431162
Trained batch 358 in epoch 8, gen_loss = 0.39860106062424216, disc_loss = 0.017005401822377753
Trained batch 359 in epoch 8, gen_loss = 0.39855334733923276, disc_loss = 0.01696271272117479
Trained batch 360 in epoch 8, gen_loss = 0.39842989628004566, disc_loss = 0.016922211258380657
Trained batch 361 in epoch 8, gen_loss = 0.3983051094396338, disc_loss = 0.01688276355229421
Trained batch 362 in epoch 8, gen_loss = 0.3984053871355766, disc_loss = 0.016840944853649776
Trained batch 363 in epoch 8, gen_loss = 0.39838327311879984, disc_loss = 0.01679936949493732
Trained batch 364 in epoch 8, gen_loss = 0.3984304648556121, disc_loss = 0.016757974249616978
Trained batch 365 in epoch 8, gen_loss = 0.3985574247081423, disc_loss = 0.016715889700874176
Trained batch 366 in epoch 8, gen_loss = 0.39859164410780823, disc_loss = 0.01667435496743535
Trained batch 367 in epoch 8, gen_loss = 0.39863171792872576, disc_loss = 0.016632083591779836
Trained batch 368 in epoch 8, gen_loss = 0.3986141569407652, disc_loss = 0.016590536128777537
Trained batch 369 in epoch 8, gen_loss = 0.39864890164620165, disc_loss = 0.016550419506037962
Trained batch 370 in epoch 8, gen_loss = 0.3987089062154775, disc_loss = 0.016511315744711624
Trained batch 371 in epoch 8, gen_loss = 0.39863357268353944, disc_loss = 0.0164699460409822
Trained batch 372 in epoch 8, gen_loss = 0.3985341670685735, disc_loss = 0.016434036268935047
Trained batch 373 in epoch 8, gen_loss = 0.3984667336877017, disc_loss = 0.01639412253357988
Trained batch 374 in epoch 8, gen_loss = 0.3983700393040975, disc_loss = 0.01635823418200016
Trained batch 375 in epoch 8, gen_loss = 0.39837075032769365, disc_loss = 0.016318932821493635
Trained batch 376 in epoch 8, gen_loss = 0.39822787757893774, disc_loss = 0.016279027156843075
Trained batch 377 in epoch 8, gen_loss = 0.3983162917472698, disc_loss = 0.016240699488359194
Trained batch 378 in epoch 8, gen_loss = 0.39811348828602594, disc_loss = 0.016202433285423822
Trained batch 379 in epoch 8, gen_loss = 0.3981268140830492, disc_loss = 0.01616517157342873
Trained batch 380 in epoch 8, gen_loss = 0.3980771681768062, disc_loss = 0.016128331129475842
Trained batch 381 in epoch 8, gen_loss = 0.39806584553568775, disc_loss = 0.016094314707296838
Trained batch 382 in epoch 8, gen_loss = 0.3981582984600615, disc_loss = 0.01605952493773467
Trained batch 383 in epoch 8, gen_loss = 0.3979901953134686, disc_loss = 0.016022409862065008
Trained batch 384 in epoch 8, gen_loss = 0.39787510083867356, disc_loss = 0.015984476457180624
Trained batch 385 in epoch 8, gen_loss = 0.3979081173326067, disc_loss = 0.015948799387201996
Trained batch 386 in epoch 8, gen_loss = 0.3980208026192293, disc_loss = 0.01591980628800417
Trained batch 387 in epoch 8, gen_loss = 0.39808460470941875, disc_loss = 0.01588885348017769
Trained batch 388 in epoch 8, gen_loss = 0.3980272514961066, disc_loss = 0.0158537154503114
Trained batch 389 in epoch 8, gen_loss = 0.3982140262157489, disc_loss = 0.015819821960161417
Trained batch 390 in epoch 8, gen_loss = 0.39811154971342255, disc_loss = 0.015782652583563952
Trained batch 391 in epoch 8, gen_loss = 0.39811989474965603, disc_loss = 0.01574735496964125
Trained batch 392 in epoch 8, gen_loss = 0.39806247546169293, disc_loss = 0.01571267877045412
Trained batch 393 in epoch 8, gen_loss = 0.3979803635384226, disc_loss = 0.015677755827091275
Trained batch 394 in epoch 8, gen_loss = 0.3979934094072897, disc_loss = 0.015643392461116273
Trained batch 395 in epoch 8, gen_loss = 0.39804735636771327, disc_loss = 0.015608657824964442
Trained batch 396 in epoch 8, gen_loss = 0.39803227954907744, disc_loss = 0.015573182993953208
Trained batch 397 in epoch 8, gen_loss = 0.39784050931283577, disc_loss = 0.015537940643156818
Trained batch 398 in epoch 8, gen_loss = 0.39775580623394863, disc_loss = 0.015504617659482443
Trained batch 399 in epoch 8, gen_loss = 0.3977185294032097, disc_loss = 0.015473489515134133
Trained batch 400 in epoch 8, gen_loss = 0.3974878962646399, disc_loss = 0.015438492035091463
Trained batch 401 in epoch 8, gen_loss = 0.3976439067825156, disc_loss = 0.015406210081181513
Trained batch 402 in epoch 8, gen_loss = 0.39785887178948737, disc_loss = 0.015372496703755175
Trained batch 403 in epoch 8, gen_loss = 0.397688857325823, disc_loss = 0.015337956218639075
Trained batch 404 in epoch 8, gen_loss = 0.3976114228183841, disc_loss = 0.01530582875093836
Trained batch 405 in epoch 8, gen_loss = 0.3976295711518508, disc_loss = 0.015274673184779073
Trained batch 406 in epoch 8, gen_loss = 0.39756770560138055, disc_loss = 0.015240871987914259
Trained batch 407 in epoch 8, gen_loss = 0.3977027032159123, disc_loss = 0.015206980684489085
Trained batch 408 in epoch 8, gen_loss = 0.3976491769834952, disc_loss = 0.015173764402117389
Trained batch 409 in epoch 8, gen_loss = 0.39777935278124926, disc_loss = 0.015140385347384414
Trained batch 410 in epoch 8, gen_loss = 0.39788547100231886, disc_loss = 0.015106744941611776
Trained batch 411 in epoch 8, gen_loss = 0.3979997998736437, disc_loss = 0.015073707143299154
Trained batch 412 in epoch 8, gen_loss = 0.3979964915834385, disc_loss = 0.015041626481616702
Trained batch 413 in epoch 8, gen_loss = 0.3979711833495449, disc_loss = 0.015007432201508306
Trained batch 414 in epoch 8, gen_loss = 0.3980496277292091, disc_loss = 0.014974481468257236
Trained batch 415 in epoch 8, gen_loss = 0.3981113996929847, disc_loss = 0.014943263253371697
Trained batch 416 in epoch 8, gen_loss = 0.3980943274726685, disc_loss = 0.014912495648653674
Trained batch 417 in epoch 8, gen_loss = 0.3980198526068738, disc_loss = 0.014880604986558138
Trained batch 418 in epoch 8, gen_loss = 0.3979536583002541, disc_loss = 0.014847583637843997
Trained batch 419 in epoch 8, gen_loss = 0.39789603125481376, disc_loss = 0.014816223869344131
Trained batch 420 in epoch 8, gen_loss = 0.3978723208298309, disc_loss = 0.01478553215548343
Trained batch 421 in epoch 8, gen_loss = 0.39795316296731126, disc_loss = 0.014757517473088021
Trained batch 422 in epoch 8, gen_loss = 0.39799673795418256, disc_loss = 0.01472571352551786
Trained batch 423 in epoch 8, gen_loss = 0.3979866092075717, disc_loss = 0.014694511105157083
Trained batch 424 in epoch 8, gen_loss = 0.3979125578964458, disc_loss = 0.014665828984340323
Trained batch 425 in epoch 8, gen_loss = 0.39778335070666015, disc_loss = 0.014637426478119279
Trained batch 426 in epoch 8, gen_loss = 0.3977346261854194, disc_loss = 0.014609178538549804
Trained batch 427 in epoch 8, gen_loss = 0.3976458997648453, disc_loss = 0.014577518404400516
Trained batch 428 in epoch 8, gen_loss = 0.39762809247403713, disc_loss = 0.014547453084168195
Trained batch 429 in epoch 8, gen_loss = 0.3976247743118641, disc_loss = 0.014515872789969192
Trained batch 430 in epoch 8, gen_loss = 0.3976476861816548, disc_loss = 0.014487033498931564
Trained batch 431 in epoch 8, gen_loss = 0.39760257662446413, disc_loss = 0.014457161101745442
Trained batch 432 in epoch 8, gen_loss = 0.39757396669641104, disc_loss = 0.014427760774033106
Trained batch 433 in epoch 8, gen_loss = 0.3975804968638354, disc_loss = 0.014397496420327865
Trained batch 434 in epoch 8, gen_loss = 0.39763396889313884, disc_loss = 0.014366683746345513
Trained batch 435 in epoch 8, gen_loss = 0.3975704201591124, disc_loss = 0.014336579413860268
Trained batch 436 in epoch 8, gen_loss = 0.39765735649135076, disc_loss = 0.014306177008732966
Trained batch 437 in epoch 8, gen_loss = 0.3976593466654216, disc_loss = 0.014276182950638048
Trained batch 438 in epoch 8, gen_loss = 0.39780723104987437, disc_loss = 0.014248060366692518
Trained batch 439 in epoch 8, gen_loss = 0.39787019362503834, disc_loss = 0.014223351557897827
Trained batch 440 in epoch 8, gen_loss = 0.3978908754665565, disc_loss = 0.014195338918726106
Trained batch 441 in epoch 8, gen_loss = 0.3980127136766641, disc_loss = 0.01416841327034704
Trained batch 442 in epoch 8, gen_loss = 0.39781807406761305, disc_loss = 0.014149559746626723
Trained batch 443 in epoch 8, gen_loss = 0.39773040949492844, disc_loss = 0.014123457515673074
Trained batch 444 in epoch 8, gen_loss = 0.39773193450456257, disc_loss = 0.01409520810820539
Trained batch 445 in epoch 8, gen_loss = 0.39775532390504675, disc_loss = 0.014066704038860518
Trained batch 446 in epoch 8, gen_loss = 0.3977768684526951, disc_loss = 0.014037579215981767
Trained batch 447 in epoch 8, gen_loss = 0.39777833629133447, disc_loss = 0.014008891409373194
Trained batch 448 in epoch 8, gen_loss = 0.3979487505415766, disc_loss = 0.013981496292178857
Trained batch 449 in epoch 8, gen_loss = 0.3981278974480099, disc_loss = 0.013959684026582788
Trained batch 450 in epoch 8, gen_loss = 0.3981718622528, disc_loss = 0.013938947875277777
Trained batch 451 in epoch 8, gen_loss = 0.3982721347592573, disc_loss = 0.01391388680729232
Trained batch 452 in epoch 8, gen_loss = 0.3982691754963224, disc_loss = 0.013887427131507635
Trained batch 453 in epoch 8, gen_loss = 0.39817797277729944, disc_loss = 0.013862476891854426
Trained batch 454 in epoch 8, gen_loss = 0.39815569402097345, disc_loss = 0.01383815282638502
Trained batch 455 in epoch 8, gen_loss = 0.39820965399083336, disc_loss = 0.01381468952259686
Trained batch 456 in epoch 8, gen_loss = 0.39817957798552983, disc_loss = 0.013788716553728743
Trained batch 457 in epoch 8, gen_loss = 0.3982485260765625, disc_loss = 0.013767218493803619
Trained batch 458 in epoch 8, gen_loss = 0.3982852083145923, disc_loss = 0.01374007280548722
Trained batch 459 in epoch 8, gen_loss = 0.39822931542344714, disc_loss = 0.013715759815607706
Trained batch 460 in epoch 8, gen_loss = 0.398369816469267, disc_loss = 0.013712757969085216
Testing Epoch 8
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-08-30 00:39:33,654
------------------------------------------------------------
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.31933262944221497, disc_loss = 0.0024450398050248623
Trained batch 1 in epoch 9, gen_loss = 0.3506436347961426, disc_loss = 0.003952005645260215
Trained batch 2 in epoch 9, gen_loss = 0.3788239856561025, disc_loss = 0.0033071471067766347
Trained batch 3 in epoch 9, gen_loss = 0.37665095180273056, disc_loss = 0.002868235664209351
Trained batch 4 in epoch 9, gen_loss = 0.37782350182533264, disc_loss = 0.002480247791390866
Trained batch 5 in epoch 9, gen_loss = 0.3697342773278554, disc_loss = 0.0023685362248215824
Trained batch 6 in epoch 9, gen_loss = 0.3723009739603315, disc_loss = 0.0021615029462347074
Trained batch 7 in epoch 9, gen_loss = 0.36995042860507965, disc_loss = 0.0022158499123179354
Trained batch 8 in epoch 9, gen_loss = 0.36606697572602165, disc_loss = 0.0021111249289889303
Trained batch 9 in epoch 9, gen_loss = 0.3643893122673035, disc_loss = 0.002001404872862622
Trained batch 10 in epoch 9, gen_loss = 0.368251616304571, disc_loss = 0.0020056159648282283
Trained batch 11 in epoch 9, gen_loss = 0.37101736416419345, disc_loss = 0.0019403300296592836
Trained batch 12 in epoch 9, gen_loss = 0.3763115704059601, disc_loss = 0.0019321584438260358
Trained batch 13 in epoch 9, gen_loss = 0.3752746880054474, disc_loss = 0.0018835867563861289
Trained batch 14 in epoch 9, gen_loss = 0.3746377209822337, disc_loss = 0.0018805742845870554
Trained batch 15 in epoch 9, gen_loss = 0.37534903176128864, disc_loss = 0.0018511319758545142
Trained batch 16 in epoch 9, gen_loss = 0.37778183291940126, disc_loss = 0.0019692708293030806
Trained batch 17 in epoch 9, gen_loss = 0.3786915921502643, disc_loss = 0.0019582295693301908
Trained batch 18 in epoch 9, gen_loss = 0.3800660858028813, disc_loss = 0.0019021389093004952
Trained batch 19 in epoch 9, gen_loss = 0.3870358273386955, disc_loss = 0.0019217344437493012
Trained batch 20 in epoch 9, gen_loss = 0.386949360370636, disc_loss = 0.0019028817408806866
Trained batch 21 in epoch 9, gen_loss = 0.3887841471216895, disc_loss = 0.0018563799015034667
Trained batch 22 in epoch 9, gen_loss = 0.3901553050331447, disc_loss = 0.0018978151011928592
Trained batch 23 in epoch 9, gen_loss = 0.3865924080212911, disc_loss = 0.0019371887829038315
Trained batch 24 in epoch 9, gen_loss = 0.38813403248786926, disc_loss = 0.0019125485070981085
Trained batch 25 in epoch 9, gen_loss = 0.3877733808297377, disc_loss = 0.00190056036808528
Trained batch 26 in epoch 9, gen_loss = 0.38729726605945164, disc_loss = 0.0018773086011168306
Trained batch 27 in epoch 9, gen_loss = 0.3888237795659474, disc_loss = 0.001863635575448695
Trained batch 28 in epoch 9, gen_loss = 0.38770818402027263, disc_loss = 0.00193123895763259
Trained batch 29 in epoch 9, gen_loss = 0.38758932252724965, disc_loss = 0.0019212829240132124
Trained batch 30 in epoch 9, gen_loss = 0.3861238331564011, disc_loss = 0.0019086738428731838
Trained batch 31 in epoch 9, gen_loss = 0.38554272148758173, disc_loss = 0.0019321079143992392
Trained batch 32 in epoch 9, gen_loss = 0.38425406271761114, disc_loss = 0.0019224155323833904
Trained batch 33 in epoch 9, gen_loss = 0.38679156759205985, disc_loss = 0.0019598235838416524
Trained batch 34 in epoch 9, gen_loss = 0.38813654950686866, disc_loss = 0.0019504234909878246
Trained batch 35 in epoch 9, gen_loss = 0.3891616827911801, disc_loss = 0.0019485209793654373
Trained batch 36 in epoch 9, gen_loss = 0.3893211967236287, disc_loss = 0.001943828140045642
Trained batch 37 in epoch 9, gen_loss = 0.38973647199178996, disc_loss = 0.0019708186017324855
Trained batch 38 in epoch 9, gen_loss = 0.39018519643025523, disc_loss = 0.001973629718682227
Trained batch 39 in epoch 9, gen_loss = 0.3893589973449707, disc_loss = 0.001953652473457623
Trained batch 40 in epoch 9, gen_loss = 0.3894203261631291, disc_loss = 0.0019380805641980615
Trained batch 41 in epoch 9, gen_loss = 0.38905095557371777, disc_loss = 0.001976867296477957
Trained batch 42 in epoch 9, gen_loss = 0.3881842597972515, disc_loss = 0.001964560673344707
Trained batch 43 in epoch 9, gen_loss = 0.3901895582675934, disc_loss = 0.0019662162482167
Trained batch 44 in epoch 9, gen_loss = 0.39018945164150665, disc_loss = 0.0019471835099264152
Trained batch 45 in epoch 9, gen_loss = 0.39007572959298675, disc_loss = 0.0019354837523955528
Trained batch 46 in epoch 9, gen_loss = 0.39098930485705113, disc_loss = 0.0019318118475952206
Trained batch 47 in epoch 9, gen_loss = 0.39112231011192006, disc_loss = 0.0019131875366535194
Trained batch 48 in epoch 9, gen_loss = 0.39186156890830215, disc_loss = 0.0019274712124440288
Trained batch 49 in epoch 9, gen_loss = 0.3926294195652008, disc_loss = 0.0019273854640778154
Trained batch 50 in epoch 9, gen_loss = 0.3922442910717983, disc_loss = 0.001923493012630691
Trained batch 51 in epoch 9, gen_loss = 0.39210399182943195, disc_loss = 0.0019360939880313638
Trained batch 52 in epoch 9, gen_loss = 0.39286393826862553, disc_loss = 0.0019347754379576247
Trained batch 53 in epoch 9, gen_loss = 0.3927806615829468, disc_loss = 0.0019187663166559542
Trained batch 54 in epoch 9, gen_loss = 0.39375870607116004, disc_loss = 0.0019278178891082378
Trained batch 55 in epoch 9, gen_loss = 0.3934519402682781, disc_loss = 0.0019257889705061512
Trained batch 56 in epoch 9, gen_loss = 0.3934906433548844, disc_loss = 0.0019290054619328625
Trained batch 57 in epoch 9, gen_loss = 0.39395504521912544, disc_loss = 0.0019197860533965688
Trained batch 58 in epoch 9, gen_loss = 0.39433870477191474, disc_loss = 0.0019089669448923382
Trained batch 59 in epoch 9, gen_loss = 0.3925317113598188, disc_loss = 0.0020146987449455385
Trained batch 60 in epoch 9, gen_loss = 0.39209168905117475, disc_loss = 0.0020366802966206897
Trained batch 61 in epoch 9, gen_loss = 0.3922603510079845, disc_loss = 0.0020393702143337578
Trained batch 62 in epoch 9, gen_loss = 0.39237283383096966, disc_loss = 0.002031775499095342
Trained batch 63 in epoch 9, gen_loss = 0.3925737696699798, disc_loss = 0.002017998934206844
Trained batch 64 in epoch 9, gen_loss = 0.3933206617832184, disc_loss = 0.002012246486265212
Trained batch 65 in epoch 9, gen_loss = 0.39393121500809986, disc_loss = 0.00200659535899335
Trained batch 66 in epoch 9, gen_loss = 0.3935208431820371, disc_loss = 0.001989866187274734
Trained batch 67 in epoch 9, gen_loss = 0.39378366356386857, disc_loss = 0.002017086006269571
Trained batch 68 in epoch 9, gen_loss = 0.3937504218108412, disc_loss = 0.002038123819173948
Trained batch 69 in epoch 9, gen_loss = 0.3935960454600198, disc_loss = 0.002047031796038417
Trained batch 70 in epoch 9, gen_loss = 0.3935503741385232, disc_loss = 0.002086745152859883
Trained batch 71 in epoch 9, gen_loss = 0.39287176521288025, disc_loss = 0.002092938754584692
Trained batch 72 in epoch 9, gen_loss = 0.39222498911700837, disc_loss = 0.002084213379955506
Trained batch 73 in epoch 9, gen_loss = 0.39212554975135905, disc_loss = 0.002088923649893872
Trained batch 74 in epoch 9, gen_loss = 0.3923655601342519, disc_loss = 0.0020883001084439456
Trained batch 75 in epoch 9, gen_loss = 0.3921589447479499, disc_loss = 0.002079424476649269
Trained batch 76 in epoch 9, gen_loss = 0.39300057330688876, disc_loss = 0.0021537937588276125
Trained batch 77 in epoch 9, gen_loss = 0.39201717919264084, disc_loss = 0.002158596563206699
Trained batch 78 in epoch 9, gen_loss = 0.3924173675005949, disc_loss = 0.002207021471378217
Trained batch 79 in epoch 9, gen_loss = 0.3919777125120163, disc_loss = 0.0022030824395187663
Trained batch 80 in epoch 9, gen_loss = 0.39188567282241066, disc_loss = 0.002193488567969819
Trained batch 81 in epoch 9, gen_loss = 0.3919911017505134, disc_loss = 0.0021986966071048434
Trained batch 82 in epoch 9, gen_loss = 0.39160083395889006, disc_loss = 0.002194650571495968
Trained batch 83 in epoch 9, gen_loss = 0.39118300484759466, disc_loss = 0.002200704128231986
Trained batch 84 in epoch 9, gen_loss = 0.3914087779381696, disc_loss = 0.0022103822317577023
Trained batch 85 in epoch 9, gen_loss = 0.3910828430292218, disc_loss = 0.0022164808097566197
Trained batch 86 in epoch 9, gen_loss = 0.39120901179039613, disc_loss = 0.0022063048418621994
Trained batch 87 in epoch 9, gen_loss = 0.392191620035605, disc_loss = 0.002219979945617855
Trained batch 88 in epoch 9, gen_loss = 0.39183905787682266, disc_loss = 0.002221155569632276
Trained batch 89 in epoch 9, gen_loss = 0.39183501303195956, disc_loss = 0.002210999508517691
Trained batch 90 in epoch 9, gen_loss = 0.39181803772737694, disc_loss = 0.0022017777351161037
Trained batch 91 in epoch 9, gen_loss = 0.39195881071298017, disc_loss = 0.0021910376463378984
Trained batch 92 in epoch 9, gen_loss = 0.392009457272868, disc_loss = 0.0021813352828875423
Trained batch 93 in epoch 9, gen_loss = 0.3919463122778751, disc_loss = 0.002168277556576984
Trained batch 94 in epoch 9, gen_loss = 0.3917953456702985, disc_loss = 0.002159026194682443
Trained batch 95 in epoch 9, gen_loss = 0.39284619099150103, disc_loss = 0.0021592513615663242
Trained batch 96 in epoch 9, gen_loss = 0.3929456002318982, disc_loss = 0.0021613098293322033
Trained batch 97 in epoch 9, gen_loss = 0.39348481108947675, disc_loss = 0.002165432941591443
Trained batch 98 in epoch 9, gen_loss = 0.39364828936981433, disc_loss = 0.002161567457457722
Trained batch 99 in epoch 9, gen_loss = 0.3934899911284447, disc_loss = 0.002149554457864724
Trained batch 100 in epoch 9, gen_loss = 0.3930339255545399, disc_loss = 0.002144269249286724
Trained batch 101 in epoch 9, gen_loss = 0.39296356836954754, disc_loss = 0.0021378285948908432
Trained batch 102 in epoch 9, gen_loss = 0.3930181753866881, disc_loss = 0.002130257507709298
Trained batch 103 in epoch 9, gen_loss = 0.39287263040359205, disc_loss = 0.002124049722624477
Trained batch 104 in epoch 9, gen_loss = 0.39322950925145833, disc_loss = 0.002114459508032139
Trained batch 105 in epoch 9, gen_loss = 0.39385625073369945, disc_loss = 0.002106549195782721
Trained batch 106 in epoch 9, gen_loss = 0.39395799007371207, disc_loss = 0.0020957460205906255
Trained batch 107 in epoch 9, gen_loss = 0.3938014614913199, disc_loss = 0.002088060169761
Trained batch 108 in epoch 9, gen_loss = 0.3941641698736663, disc_loss = 0.0020871230154383687
Trained batch 109 in epoch 9, gen_loss = 0.3939045643264597, disc_loss = 0.00207684316132641
Trained batch 110 in epoch 9, gen_loss = 0.39408502036386783, disc_loss = 0.002074699835780471
Trained batch 111 in epoch 9, gen_loss = 0.3937754066927092, disc_loss = 0.0020759487436277724
Trained batch 112 in epoch 9, gen_loss = 0.3933803555184761, disc_loss = 0.002078454584538508
Trained batch 113 in epoch 9, gen_loss = 0.3936856284476163, disc_loss = 0.0020690982280045815
Trained batch 114 in epoch 9, gen_loss = 0.39385599286659906, disc_loss = 0.0020616664920690593
Trained batch 115 in epoch 9, gen_loss = 0.3929893032744013, disc_loss = 0.0020722685194100605
Trained batch 116 in epoch 9, gen_loss = 0.3930925156316187, disc_loss = 0.002081251548479797
Trained batch 117 in epoch 9, gen_loss = 0.39328455015764396, disc_loss = 0.0020724737753310255
Trained batch 118 in epoch 9, gen_loss = 0.39373055426012565, disc_loss = 0.002067684245338867
Trained batch 119 in epoch 9, gen_loss = 0.3934809098641078, disc_loss = 0.002068202128187598
Trained batch 120 in epoch 9, gen_loss = 0.39332472095804766, disc_loss = 0.002061815896313945
Trained batch 121 in epoch 9, gen_loss = 0.3928565734722575, disc_loss = 0.002056349981595289
Trained batch 122 in epoch 9, gen_loss = 0.39271166218005543, disc_loss = 0.0020484631740094383
Trained batch 123 in epoch 9, gen_loss = 0.39288735197436425, disc_loss = 0.0020388973578284947
Trained batch 124 in epoch 9, gen_loss = 0.39285705614089966, disc_loss = 0.00203154222574085
Trained batch 125 in epoch 9, gen_loss = 0.39216775577219704, disc_loss = 0.002024720994836932
Trained batch 126 in epoch 9, gen_loss = 0.39200490666186716, disc_loss = 0.002028440821028542
Trained batch 127 in epoch 9, gen_loss = 0.39189199660904706, disc_loss = 0.0020213845400576247
Trained batch 128 in epoch 9, gen_loss = 0.39251885233923445, disc_loss = 0.002019402244337654
Trained batch 129 in epoch 9, gen_loss = 0.3923506982051409, disc_loss = 0.0020314597757533194
Trained batch 130 in epoch 9, gen_loss = 0.39190631012880167, disc_loss = 0.0020272023504855864
Trained batch 131 in epoch 9, gen_loss = 0.3921736397526481, disc_loss = 0.00202672827237455
Trained batch 132 in epoch 9, gen_loss = 0.39182811728993755, disc_loss = 0.002017478257701277
Trained batch 133 in epoch 9, gen_loss = 0.3915645315575956, disc_loss = 0.0020147744012795
Trained batch 134 in epoch 9, gen_loss = 0.39199389130980883, disc_loss = 0.0020156357105372957
Trained batch 135 in epoch 9, gen_loss = 0.3915768796030213, disc_loss = 0.0020125758485793244
Trained batch 136 in epoch 9, gen_loss = 0.391373501641907, disc_loss = 0.002007527657135315
Trained batch 137 in epoch 9, gen_loss = 0.3908141726169033, disc_loss = 0.0020074705636311
Trained batch 138 in epoch 9, gen_loss = 0.39108141506318567, disc_loss = 0.002001168684976966
Trained batch 139 in epoch 9, gen_loss = 0.39095924198627474, disc_loss = 0.0019958200802128495
Trained batch 140 in epoch 9, gen_loss = 0.39072744474343374, disc_loss = 0.001997358644965719
Trained batch 141 in epoch 9, gen_loss = 0.3903333162757712, disc_loss = 0.001990754459410722
Trained batch 142 in epoch 9, gen_loss = 0.3903361029558248, disc_loss = 0.00198490141322706
Trained batch 143 in epoch 9, gen_loss = 0.3900318005018764, disc_loss = 0.001983703343285015
Trained batch 144 in epoch 9, gen_loss = 0.38996996756257685, disc_loss = 0.001977706336464476
Trained batch 145 in epoch 9, gen_loss = 0.38994513697003663, disc_loss = 0.001970417760089295
Trained batch 146 in epoch 9, gen_loss = 0.3898238428190452, disc_loss = 0.0019635603502614514
Trained batch 147 in epoch 9, gen_loss = 0.39000204547836975, disc_loss = 0.001958355209648584
Trained batch 148 in epoch 9, gen_loss = 0.39058267490175747, disc_loss = 0.0019585934288693504
Trained batch 149 in epoch 9, gen_loss = 0.39041647017002107, disc_loss = 0.001957959964638576
Trained batch 150 in epoch 9, gen_loss = 0.38994068696798867, disc_loss = 0.0019530632493813948
Trained batch 151 in epoch 9, gen_loss = 0.39008517680983795, disc_loss = 0.001948473295334751
Trained batch 152 in epoch 9, gen_loss = 0.38987528070125704, disc_loss = 0.0019443503918059267
Trained batch 153 in epoch 9, gen_loss = 0.38976154718306155, disc_loss = 0.0019369676241245992
Trained batch 154 in epoch 9, gen_loss = 0.39006661253590735, disc_loss = 0.001932076110519589
Trained batch 155 in epoch 9, gen_loss = 0.39005551277062833, disc_loss = 0.0019258956890553236
Trained batch 156 in epoch 9, gen_loss = 0.39009414243090684, disc_loss = 0.0019188964862530684
Trained batch 157 in epoch 9, gen_loss = 0.39024871663202215, disc_loss = 0.0019132325232700928
Trained batch 158 in epoch 9, gen_loss = 0.3899656864082288, disc_loss = 0.0019089493925431333
Trained batch 159 in epoch 9, gen_loss = 0.38968708738684654, disc_loss = 0.0019032103002246004
Trained batch 160 in epoch 9, gen_loss = 0.3896260898305763, disc_loss = 0.0018967918907754956
Trained batch 161 in epoch 9, gen_loss = 0.3896841905367227, disc_loss = 0.0018925253143045407
Trained batch 162 in epoch 9, gen_loss = 0.38971308934176624, disc_loss = 0.0018877926767529474
Trained batch 163 in epoch 9, gen_loss = 0.38934389320088597, disc_loss = 0.0018862673765042705
Trained batch 164 in epoch 9, gen_loss = 0.3892571004954251, disc_loss = 0.0018828909466692219
Trained batch 165 in epoch 9, gen_loss = 0.38906795630253943, disc_loss = 0.0018798098390983664
Trained batch 166 in epoch 9, gen_loss = 0.3891080707133173, disc_loss = 0.0018771380980075253
Trained batch 167 in epoch 9, gen_loss = 0.38938551112299874, disc_loss = 0.0018787315608018876
Trained batch 168 in epoch 9, gen_loss = 0.38915342462838753, disc_loss = 0.001878714455861995
Trained batch 169 in epoch 9, gen_loss = 0.3893763275707469, disc_loss = 0.0018833789094488192
Trained batch 170 in epoch 9, gen_loss = 0.3893267393809313, disc_loss = 0.0018828815235266167
Trained batch 171 in epoch 9, gen_loss = 0.3890293429410735, disc_loss = 0.0018852300583899325
Trained batch 172 in epoch 9, gen_loss = 0.38868881925682114, disc_loss = 0.0018933675789564977
Trained batch 173 in epoch 9, gen_loss = 0.3885221051416178, disc_loss = 0.001898448952760055
Trained batch 174 in epoch 9, gen_loss = 0.38844528760228836, disc_loss = 0.0018988521260741567
Trained batch 175 in epoch 9, gen_loss = 0.3883809364316138, disc_loss = 0.0019048439131769226
Trained batch 176 in epoch 9, gen_loss = 0.3880848035974018, disc_loss = 0.0019124885346861503
Trained batch 177 in epoch 9, gen_loss = 0.3881020499079415, disc_loss = 0.0019102881278638634
Trained batch 178 in epoch 9, gen_loss = 0.3881880482814831, disc_loss = 0.0019106241375566903
Trained batch 179 in epoch 9, gen_loss = 0.38817272666427827, disc_loss = 0.0019516619611143445
Trained batch 180 in epoch 9, gen_loss = 0.38858531604814267, disc_loss = 0.0019867384091703973
Trained batch 181 in epoch 9, gen_loss = 0.38851354230236224, disc_loss = 0.0020028872196025285
Trained batch 182 in epoch 9, gen_loss = 0.38867289984161085, disc_loss = 0.0020202462465370003
Trained batch 183 in epoch 9, gen_loss = 0.38893555963168974, disc_loss = 0.002019125092255822
Trained batch 184 in epoch 9, gen_loss = 0.3888888876180391, disc_loss = 0.0020191741927929625
Trained batch 185 in epoch 9, gen_loss = 0.3890345780759729, disc_loss = 0.0020235863909180405
Trained batch 186 in epoch 9, gen_loss = 0.38941518715358675, disc_loss = 0.002024324966612008
Trained batch 187 in epoch 9, gen_loss = 0.3894633650779724, disc_loss = 0.0020230141442957672
Trained batch 188 in epoch 9, gen_loss = 0.38948648143066933, disc_loss = 0.0020249522086011155
Trained batch 189 in epoch 9, gen_loss = 0.3892863044613286, disc_loss = 0.002035306847200876
Trained batch 190 in epoch 9, gen_loss = 0.3893268481287033, disc_loss = 0.0020358337839719164
Trained batch 191 in epoch 9, gen_loss = 0.38920561332876485, disc_loss = 0.0020366522740005166
Trained batch 192 in epoch 9, gen_loss = 0.3890047553598572, disc_loss = 0.0020383623283274396
Trained batch 193 in epoch 9, gen_loss = 0.389137726315518, disc_loss = 0.0020392100136491864
Trained batch 194 in epoch 9, gen_loss = 0.38905555651738094, disc_loss = 0.0020557642815849527
Trained batch 195 in epoch 9, gen_loss = 0.38947029274945355, disc_loss = 0.0020636284545097233
Trained batch 196 in epoch 9, gen_loss = 0.38918553860054406, disc_loss = 0.0020611302222144144
Trained batch 197 in epoch 9, gen_loss = 0.3896953550854115, disc_loss = 0.002061620948194159
Trained batch 198 in epoch 9, gen_loss = 0.3897733547579703, disc_loss = 0.0020649492791526246
Trained batch 199 in epoch 9, gen_loss = 0.389634360820055, disc_loss = 0.0020653227597358637
Trained batch 200 in epoch 9, gen_loss = 0.38970746314940763, disc_loss = 0.002072800478761302
Trained batch 201 in epoch 9, gen_loss = 0.3898831797708379, disc_loss = 0.0020874782720705183
Trained batch 202 in epoch 9, gen_loss = 0.38985987014958423, disc_loss = 0.002097907088171654
Trained batch 203 in epoch 9, gen_loss = 0.3897835737934299, disc_loss = 0.0021289144206093624
Trained batch 204 in epoch 9, gen_loss = 0.38997361907144873, disc_loss = 0.002157970401742382
Trained batch 205 in epoch 9, gen_loss = 0.38991147525680875, disc_loss = 0.0021575959599961173
Trained batch 206 in epoch 9, gen_loss = 0.3895572386502068, disc_loss = 0.002191594043456396
Trained batch 207 in epoch 9, gen_loss = 0.38959319488360333, disc_loss = 0.0022152958260378977
Trained batch 208 in epoch 9, gen_loss = 0.39028211643821314, disc_loss = 0.0022237669945578647
Trained batch 209 in epoch 9, gen_loss = 0.3907528139296032, disc_loss = 0.002223376428342557
Trained batch 210 in epoch 9, gen_loss = 0.3909163847918759, disc_loss = 0.0022258536834424245
Trained batch 211 in epoch 9, gen_loss = 0.39103974486297033, disc_loss = 0.002234577069241325
Trained batch 212 in epoch 9, gen_loss = 0.3910634456106195, disc_loss = 0.002248105223284064
Trained batch 213 in epoch 9, gen_loss = 0.3906896404016798, disc_loss = 0.002302198407238036
Trained batch 214 in epoch 9, gen_loss = 0.3907830967459568, disc_loss = 0.002301018805037318
Trained batch 215 in epoch 9, gen_loss = 0.39076922833919525, disc_loss = 0.002299840419490701
Trained batch 216 in epoch 9, gen_loss = 0.3909896087536614, disc_loss = 0.002312718366738409
Trained batch 217 in epoch 9, gen_loss = 0.3910522964022575, disc_loss = 0.00231415430193878
Trained batch 218 in epoch 9, gen_loss = 0.3911750237691348, disc_loss = 0.0023128936674815847
Trained batch 219 in epoch 9, gen_loss = 0.39113004397262224, disc_loss = 0.0023164333402581343
Trained batch 220 in epoch 9, gen_loss = 0.39125671510782717, disc_loss = 0.0023384128802042977
Trained batch 221 in epoch 9, gen_loss = 0.39131257099074285, disc_loss = 0.002344046383498337
Trained batch 222 in epoch 9, gen_loss = 0.3915460346258275, disc_loss = 0.002350070569904379
Trained batch 223 in epoch 9, gen_loss = 0.3916782593088491, disc_loss = 0.0023840408391281797
Trained batch 224 in epoch 9, gen_loss = 0.39176869140730963, disc_loss = 0.002391101330673943
Trained batch 225 in epoch 9, gen_loss = 0.39183859302934293, disc_loss = 0.002419528557323496
Trained batch 226 in epoch 9, gen_loss = 0.3918939075280916, disc_loss = 0.002431959455108705
Trained batch 227 in epoch 9, gen_loss = 0.3921734800464229, disc_loss = 0.0024436222337770454
Trained batch 228 in epoch 9, gen_loss = 0.3922803288724225, disc_loss = 0.002446430913979944
Trained batch 229 in epoch 9, gen_loss = 0.39228747020597043, disc_loss = 0.002459960092496856
Trained batch 230 in epoch 9, gen_loss = 0.39212192253116923, disc_loss = 0.0025112106244571638
Trained batch 231 in epoch 9, gen_loss = 0.39267787041849106, disc_loss = 0.0026280882119518257
Trained batch 232 in epoch 9, gen_loss = 0.39278410189653157, disc_loss = 0.0027122795239566573
Trained batch 233 in epoch 9, gen_loss = 0.39292334949868357, disc_loss = 0.004258187119321675
Trained batch 234 in epoch 9, gen_loss = 0.3930618390123895, disc_loss = 0.0063747453857510485
Trained batch 235 in epoch 9, gen_loss = 0.39348712487746096, disc_loss = 0.007045503166825826
Trained batch 236 in epoch 9, gen_loss = 0.3930890512365832, disc_loss = 0.007793319468309843
Trained batch 237 in epoch 9, gen_loss = 0.3931470552161962, disc_loss = 0.008181779666660949
Trained batch 238 in epoch 9, gen_loss = 0.39294084295568105, disc_loss = 0.008372980569124954
Trained batch 239 in epoch 9, gen_loss = 0.3932273929317792, disc_loss = 0.008463094963371987
Trained batch 240 in epoch 9, gen_loss = 0.39324872906771935, disc_loss = 0.008542868658210464
Trained batch 241 in epoch 9, gen_loss = 0.3932398177129178, disc_loss = 0.00864260110110314
Trained batch 242 in epoch 9, gen_loss = 0.39368087850480415, disc_loss = 0.008763429273538858
Trained batch 243 in epoch 9, gen_loss = 0.3939886860183028, disc_loss = 0.008927934839090592
Trained batch 244 in epoch 9, gen_loss = 0.394221732811052, disc_loss = 0.009280717971364075
Trained batch 245 in epoch 9, gen_loss = 0.394303442259145, disc_loss = 0.00954283918306133
Trained batch 246 in epoch 9, gen_loss = 0.3944021269136112, disc_loss = 0.009547924092897264
Trained batch 247 in epoch 9, gen_loss = 0.39433914326852365, disc_loss = 0.009655243256871003
Trained batch 248 in epoch 9, gen_loss = 0.39424540718875256, disc_loss = 0.009663297467253518
Trained batch 249 in epoch 9, gen_loss = 0.39435567378997805, disc_loss = 0.009668917620321736
Trained batch 250 in epoch 9, gen_loss = 0.39410274959655395, disc_loss = 0.009813944844156132
Trained batch 251 in epoch 9, gen_loss = 0.39409947939335355, disc_loss = 0.009846712552918314
Trained batch 252 in epoch 9, gen_loss = 0.39397782923675806, disc_loss = 0.009934954229041035
Trained batch 253 in epoch 9, gen_loss = 0.39428313170361706, disc_loss = 0.009980327928004287
Trained batch 254 in epoch 9, gen_loss = 0.39461129553177776, disc_loss = 0.010079379673526786
Trained batch 255 in epoch 9, gen_loss = 0.3944700703723356, disc_loss = 0.010184304572021574
Trained batch 256 in epoch 9, gen_loss = 0.3945318371173473, disc_loss = 0.010190356488145728
Trained batch 257 in epoch 9, gen_loss = 0.3945778353038684, disc_loss = 0.010173125109272511
Trained batch 258 in epoch 9, gen_loss = 0.3949760924665164, disc_loss = 0.010168049164236843
Trained batch 259 in epoch 9, gen_loss = 0.3951600243265812, disc_loss = 0.010155540652564153
Trained batch 260 in epoch 9, gen_loss = 0.3953001902249581, disc_loss = 0.010151655225652374
Trained batch 261 in epoch 9, gen_loss = 0.3954334510419205, disc_loss = 0.010132829116378335
Trained batch 262 in epoch 9, gen_loss = 0.3953779717135339, disc_loss = 0.01021536009562354
Trained batch 263 in epoch 9, gen_loss = 0.39541277729652147, disc_loss = 0.011651581130122808
Trained batch 264 in epoch 9, gen_loss = 0.3954726535194325, disc_loss = 0.011724733763137164
Trained batch 265 in epoch 9, gen_loss = 0.39544552172485153, disc_loss = 0.012217555130101894
Trained batch 266 in epoch 9, gen_loss = 0.3958420397413804, disc_loss = 0.01239129182885223
Trained batch 267 in epoch 9, gen_loss = 0.395991541556458, disc_loss = 0.012418947486448407
Trained batch 268 in epoch 9, gen_loss = 0.39609251179659677, disc_loss = 0.012421702541762333
Trained batch 269 in epoch 9, gen_loss = 0.39606683011408206, disc_loss = 0.012423737807397696
Trained batch 270 in epoch 9, gen_loss = 0.39599482797608604, disc_loss = 0.012391722728231943
Trained batch 271 in epoch 9, gen_loss = 0.39604735056705337, disc_loss = 0.01236017406314632
Trained batch 272 in epoch 9, gen_loss = 0.3959271292110066, disc_loss = 0.012348941562913917
Trained batch 273 in epoch 9, gen_loss = 0.39566648756935646, disc_loss = 0.012544904534499345
Trained batch 274 in epoch 9, gen_loss = 0.39564760240641506, disc_loss = 0.012815389204558662
Trained batch 275 in epoch 9, gen_loss = 0.39576700394568237, disc_loss = 0.012943202931479469
Trained batch 276 in epoch 9, gen_loss = 0.39584709085282005, disc_loss = 0.013343782205973494
Trained batch 277 in epoch 9, gen_loss = 0.39634342255781024, disc_loss = 0.013560524094546642
Trained batch 278 in epoch 9, gen_loss = 0.39637333827634014, disc_loss = 0.01378075487884162
Trained batch 279 in epoch 9, gen_loss = 0.39628370947071484, disc_loss = 0.01386936051983087
Trained batch 280 in epoch 9, gen_loss = 0.39611920937100337, disc_loss = 0.01389438833762126
Trained batch 281 in epoch 9, gen_loss = 0.3958128994026928, disc_loss = 0.013891274365224936
Trained batch 282 in epoch 9, gen_loss = 0.39611692100026163, disc_loss = 0.013895554449730108
Trained batch 283 in epoch 9, gen_loss = 0.39637910469736853, disc_loss = 0.013894240763554888
Trained batch 284 in epoch 9, gen_loss = 0.39665424980615316, disc_loss = 0.013920289825182407
Trained batch 285 in epoch 9, gen_loss = 0.39670638281565446, disc_loss = 0.013921649147832922
Trained batch 286 in epoch 9, gen_loss = 0.39662308881922465, disc_loss = 0.014040101927791102
Trained batch 287 in epoch 9, gen_loss = 0.39686623215675354, disc_loss = 0.014439702058047664
Trained batch 288 in epoch 9, gen_loss = 0.39740935225800245, disc_loss = 0.014439869389883774
Trained batch 289 in epoch 9, gen_loss = 0.39716011265228535, disc_loss = 0.014991588056978674
Trained batch 290 in epoch 9, gen_loss = 0.3973534564996503, disc_loss = 0.015314507744430253
Trained batch 291 in epoch 9, gen_loss = 0.3973755735444696, disc_loss = 0.015305379158235155
Trained batch 292 in epoch 9, gen_loss = 0.3976712895131355, disc_loss = 0.015276744114449597
Trained batch 293 in epoch 9, gen_loss = 0.3975191836048957, disc_loss = 0.015244305366452238
Trained batch 294 in epoch 9, gen_loss = 0.3973447274353545, disc_loss = 0.015204102518944607
Trained batch 295 in epoch 9, gen_loss = 0.397280650163019, disc_loss = 0.015160733869895528
Trained batch 296 in epoch 9, gen_loss = 0.3971636653548539, disc_loss = 0.015115403557495724
Trained batch 297 in epoch 9, gen_loss = 0.39714772669260934, disc_loss = 0.015078714609438328
Trained batch 298 in epoch 9, gen_loss = 0.39698877601719224, disc_loss = 0.015037764111233184
Trained batch 299 in epoch 9, gen_loss = 0.3972300590078036, disc_loss = 0.01499445402509688
Trained batch 300 in epoch 9, gen_loss = 0.39737435046620545, disc_loss = 0.014950343324343343
Trained batch 301 in epoch 9, gen_loss = 0.3972557239382472, disc_loss = 0.014906120222310122
Trained batch 302 in epoch 9, gen_loss = 0.3970961121245973, disc_loss = 0.014871779813319014
Trained batch 303 in epoch 9, gen_loss = 0.3972295435439599, disc_loss = 0.014831457900742718
Trained batch 304 in epoch 9, gen_loss = 0.3972805114066015, disc_loss = 0.01479060328966312
Trained batch 305 in epoch 9, gen_loss = 0.3972868308717129, disc_loss = 0.01474821593082096
Trained batch 306 in epoch 9, gen_loss = 0.3969587628344371, disc_loss = 0.014717131689098339
Trained batch 307 in epoch 9, gen_loss = 0.3971307402500859, disc_loss = 0.014679300834465614
Trained batch 308 in epoch 9, gen_loss = 0.3970119776656327, disc_loss = 0.014650215340354766
Trained batch 309 in epoch 9, gen_loss = 0.39704355847450995, disc_loss = 0.014627073638914754
Trained batch 310 in epoch 9, gen_loss = 0.3971708066210486, disc_loss = 0.01462464393292467
Trained batch 311 in epoch 9, gen_loss = 0.39729213810119873, disc_loss = 0.014640993301164156
Trained batch 312 in epoch 9, gen_loss = 0.3971270954075713, disc_loss = 0.014681238091748636
Trained batch 313 in epoch 9, gen_loss = 0.39706788938136617, disc_loss = 0.015197576035316856
Trained batch 314 in epoch 9, gen_loss = 0.39684607935330224, disc_loss = 0.015664711304652017
Trained batch 315 in epoch 9, gen_loss = 0.3970427668735951, disc_loss = 0.015660297072343704
Trained batch 316 in epoch 9, gen_loss = 0.3970104513296194, disc_loss = 0.01562790782392842
Trained batch 317 in epoch 9, gen_loss = 0.3970506063797189, disc_loss = 0.015606236538473435
Trained batch 318 in epoch 9, gen_loss = 0.3969028039038368, disc_loss = 0.015578100842979904
Trained batch 319 in epoch 9, gen_loss = 0.39681646740064025, disc_loss = 0.01555339546448522
Trained batch 320 in epoch 9, gen_loss = 0.396791070885376, disc_loss = 0.01551655935311423
Trained batch 321 in epoch 9, gen_loss = 0.39684093276166027, disc_loss = 0.015483395992423933
Trained batch 322 in epoch 9, gen_loss = 0.396678919116779, disc_loss = 0.015446903041150168
Trained batch 323 in epoch 9, gen_loss = 0.39655694485078624, disc_loss = 0.015411955869094078
Trained batch 324 in epoch 9, gen_loss = 0.39652701863875756, disc_loss = 0.015377085393545433
Trained batch 325 in epoch 9, gen_loss = 0.3966026495387949, disc_loss = 0.015337508424446615
Trained batch 326 in epoch 9, gen_loss = 0.396530427790563, disc_loss = 0.015311712112714926
Trained batch 327 in epoch 9, gen_loss = 0.3966566641337988, disc_loss = 0.015282891745921848
Trained batch 328 in epoch 9, gen_loss = 0.3966101831034686, disc_loss = 0.01524928514474131
Trained batch 329 in epoch 9, gen_loss = 0.3967401991287867, disc_loss = 0.015209312804544232
Trained batch 330 in epoch 9, gen_loss = 0.3969209295925417, disc_loss = 0.01516974836941724
Trained batch 331 in epoch 9, gen_loss = 0.39681654917188436, disc_loss = 0.015131897180648352
Trained batch 332 in epoch 9, gen_loss = 0.39685465963753136, disc_loss = 0.015096228631799229
Trained batch 333 in epoch 9, gen_loss = 0.39687043785335063, disc_loss = 0.015060465674656359
Trained batch 334 in epoch 9, gen_loss = 0.39685583559434806, disc_loss = 0.015026479900237729
Trained batch 335 in epoch 9, gen_loss = 0.39679552446163835, disc_loss = 0.015001870374925645
Trained batch 336 in epoch 9, gen_loss = 0.396791516054278, disc_loss = 0.014986132033057344
Trained batch 337 in epoch 9, gen_loss = 0.39684981195884345, disc_loss = 0.014960051926656092
Trained batch 338 in epoch 9, gen_loss = 0.3968559465752942, disc_loss = 0.014926917311648913
Trained batch 339 in epoch 9, gen_loss = 0.3968650760019527, disc_loss = 0.014886601743637585
Trained batch 340 in epoch 9, gen_loss = 0.3968934867738629, disc_loss = 0.01484748355814193
Trained batch 341 in epoch 9, gen_loss = 0.39697927567693925, disc_loss = 0.014810349988139763
Trained batch 342 in epoch 9, gen_loss = 0.396862170699734, disc_loss = 0.014778192067327407
Trained batch 343 in epoch 9, gen_loss = 0.3966799957980943, disc_loss = 0.0147636734038188
Trained batch 344 in epoch 9, gen_loss = 0.39669469068015834, disc_loss = 0.014725655190936843
Trained batch 345 in epoch 9, gen_loss = 0.39681708916074276, disc_loss = 0.014702782595248872
Trained batch 346 in epoch 9, gen_loss = 0.3967760036932976, disc_loss = 0.014671452340612226
Trained batch 347 in epoch 9, gen_loss = 0.3969687630219021, disc_loss = 0.014636618436960472
Trained batch 348 in epoch 9, gen_loss = 0.3969509580244649, disc_loss = 0.014600540724627001
Trained batch 349 in epoch 9, gen_loss = 0.39689908819539205, disc_loss = 0.014562745849169525
Trained batch 350 in epoch 9, gen_loss = 0.3968491335200448, disc_loss = 0.014524593961092132
Trained batch 351 in epoch 9, gen_loss = 0.39686587114225735, disc_loss = 0.014488086888708163
Trained batch 352 in epoch 9, gen_loss = 0.39682861537838793, disc_loss = 0.01445059709975802
Trained batch 353 in epoch 9, gen_loss = 0.39664584549806886, disc_loss = 0.014412890697959653
Trained batch 354 in epoch 9, gen_loss = 0.3966964954221752, disc_loss = 0.01437616367204587
Trained batch 355 in epoch 9, gen_loss = 0.3965882005986203, disc_loss = 0.014339004355656725
Trained batch 356 in epoch 9, gen_loss = 0.3966275137178704, disc_loss = 0.014302849344529618
Trained batch 357 in epoch 9, gen_loss = 0.3965553431537564, disc_loss = 0.014267671543242431
Trained batch 358 in epoch 9, gen_loss = 0.39650751413741153, disc_loss = 0.014234501523618173
Trained batch 359 in epoch 9, gen_loss = 0.3965053505367703, disc_loss = 0.014199261308628289
Trained batch 360 in epoch 9, gen_loss = 0.39657200951325267, disc_loss = 0.014162925588143757
Trained batch 361 in epoch 9, gen_loss = 0.3964738721511641, disc_loss = 0.014127609524676494
Trained batch 362 in epoch 9, gen_loss = 0.3965738598801216, disc_loss = 0.01409323737310687
Trained batch 363 in epoch 9, gen_loss = 0.39649065444757653, disc_loss = 0.01406014755455864
Trained batch 364 in epoch 9, gen_loss = 0.3965447819396241, disc_loss = 0.014025341991928394
Trained batch 365 in epoch 9, gen_loss = 0.3964654675435499, disc_loss = 0.013994235827369982
Trained batch 366 in epoch 9, gen_loss = 0.3963772487250596, disc_loss = 0.013963773516888605
Trained batch 367 in epoch 9, gen_loss = 0.39644758330415125, disc_loss = 0.013936711123634545
Trained batch 368 in epoch 9, gen_loss = 0.39629747849815905, disc_loss = 0.013908040229146568
Trained batch 369 in epoch 9, gen_loss = 0.3964808182941901, disc_loss = 0.013879011703711757
Trained batch 370 in epoch 9, gen_loss = 0.3965427543757097, disc_loss = 0.013845161954850973
Trained batch 371 in epoch 9, gen_loss = 0.39648755783996276, disc_loss = 0.013812087547448363
Trained batch 372 in epoch 9, gen_loss = 0.3965521507544428, disc_loss = 0.013783700529319902
Trained batch 373 in epoch 9, gen_loss = 0.39633449298494, disc_loss = 0.013752248806643604
Trained batch 374 in epoch 9, gen_loss = 0.3963718138535817, disc_loss = 0.01371840375677372
Trained batch 375 in epoch 9, gen_loss = 0.3962599685058949, disc_loss = 0.013687327044843845
Trained batch 376 in epoch 9, gen_loss = 0.3962847226020196, disc_loss = 0.013657750270486282
Trained batch 377 in epoch 9, gen_loss = 0.39611355936716475, disc_loss = 0.013624708074737566
Trained batch 378 in epoch 9, gen_loss = 0.3960260778744177, disc_loss = 0.01359215858628934
Trained batch 379 in epoch 9, gen_loss = 0.3961659076182466, disc_loss = 0.013560848403875225
Trained batch 380 in epoch 9, gen_loss = 0.39604753302776907, disc_loss = 0.013529384060331382
Trained batch 381 in epoch 9, gen_loss = 0.3962253442141398, disc_loss = 0.013500308519971669
Trained batch 382 in epoch 9, gen_loss = 0.39645071829579204, disc_loss = 0.013472223306207263
Trained batch 383 in epoch 9, gen_loss = 0.39641197545764345, disc_loss = 0.013441361864806822
Trained batch 384 in epoch 9, gen_loss = 0.3963159800349892, disc_loss = 0.01340946793547142
Trained batch 385 in epoch 9, gen_loss = 0.3962078527619802, disc_loss = 0.013378091160855811
Trained batch 386 in epoch 9, gen_loss = 0.39611083376931283, disc_loss = 0.013348567952463303
Trained batch 387 in epoch 9, gen_loss = 0.3961055079071792, disc_loss = 0.013317984376869587
Trained batch 388 in epoch 9, gen_loss = 0.3960579400044174, disc_loss = 0.01328593676707499
Trained batch 389 in epoch 9, gen_loss = 0.39609975669628533, disc_loss = 0.01325525646068108
Trained batch 390 in epoch 9, gen_loss = 0.3963135616553714, disc_loss = 0.013227729132468039
Trained batch 391 in epoch 9, gen_loss = 0.39614212056811976, disc_loss = 0.013197879345282172
Trained batch 392 in epoch 9, gen_loss = 0.39617456294804737, disc_loss = 0.013170109044241485
Trained batch 393 in epoch 9, gen_loss = 0.3961389393068207, disc_loss = 0.01314471373813189
Trained batch 394 in epoch 9, gen_loss = 0.3959929765025272, disc_loss = 0.013115892873758663
Trained batch 395 in epoch 9, gen_loss = 0.3961349364482995, disc_loss = 0.01308708126136958
Trained batch 396 in epoch 9, gen_loss = 0.3962266335559432, disc_loss = 0.013062526717645958
Trained batch 397 in epoch 9, gen_loss = 0.3961573959744755, disc_loss = 0.013037068983446339
Trained batch 398 in epoch 9, gen_loss = 0.39619326621368717, disc_loss = 0.013010726181351413
Trained batch 399 in epoch 9, gen_loss = 0.3963131342083216, disc_loss = 0.012984880722942762
Trained batch 400 in epoch 9, gen_loss = 0.39618440481492706, disc_loss = 0.012957803141488287
Trained batch 401 in epoch 9, gen_loss = 0.3961086518580641, disc_loss = 0.01293299909720466
Trained batch 402 in epoch 9, gen_loss = 0.39604006888848675, disc_loss = 0.01290856661198767
Trained batch 403 in epoch 9, gen_loss = 0.39611951438802306, disc_loss = 0.012881202144331604
Trained batch 404 in epoch 9, gen_loss = 0.3958873759817194, disc_loss = 0.01286584500533839
Trained batch 405 in epoch 9, gen_loss = 0.3958868634671413, disc_loss = 0.012840233816022026
Trained batch 406 in epoch 9, gen_loss = 0.3958548116303193, disc_loss = 0.012813301955484751
Trained batch 407 in epoch 9, gen_loss = 0.39570268718343155, disc_loss = 0.012786094157205547
Trained batch 408 in epoch 9, gen_loss = 0.3954015065959147, disc_loss = 0.012762386004854914
Trained batch 409 in epoch 9, gen_loss = 0.3953034150164302, disc_loss = 0.012733635469339788
Trained batch 410 in epoch 9, gen_loss = 0.3953852744868202, disc_loss = 0.012707694783158727
Trained batch 411 in epoch 9, gen_loss = 0.3952579016535028, disc_loss = 0.012681594987069845
Trained batch 412 in epoch 9, gen_loss = 0.3952153975969365, disc_loss = 0.012657529264620842
Trained batch 413 in epoch 9, gen_loss = 0.39526995037488893, disc_loss = 0.012631525098827583
Trained batch 414 in epoch 9, gen_loss = 0.395284032103527, disc_loss = 0.012603988837596612
Trained batch 415 in epoch 9, gen_loss = 0.39519739960535216, disc_loss = 0.012576877724103933
Trained batch 416 in epoch 9, gen_loss = 0.39509419578728344, disc_loss = 0.01254887708236086
Trained batch 417 in epoch 9, gen_loss = 0.3949212493936411, disc_loss = 0.012521786799901678
Trained batch 418 in epoch 9, gen_loss = 0.3948928085744808, disc_loss = 0.01249463657897437
Trained batch 419 in epoch 9, gen_loss = 0.39479992708989553, disc_loss = 0.01246773982281974
Trained batch 420 in epoch 9, gen_loss = 0.3947522686241358, disc_loss = 0.012440952197250395
Trained batch 421 in epoch 9, gen_loss = 0.39473844739780606, disc_loss = 0.01241521301714624
Trained batch 422 in epoch 9, gen_loss = 0.3947048840370584, disc_loss = 0.012389191429364114
Trained batch 423 in epoch 9, gen_loss = 0.3945194768877524, disc_loss = 0.01236279659689281
Trained batch 424 in epoch 9, gen_loss = 0.39451345724218034, disc_loss = 0.012336938793168349
Trained batch 425 in epoch 9, gen_loss = 0.39434526343021037, disc_loss = 0.012310394858219989
Trained batch 426 in epoch 9, gen_loss = 0.3943590357794974, disc_loss = 0.012283884589473087
Trained batch 427 in epoch 9, gen_loss = 0.3942795148658975, disc_loss = 0.012257959767381843
Trained batch 428 in epoch 9, gen_loss = 0.3943698688959464, disc_loss = 0.012232316101061088
Trained batch 429 in epoch 9, gen_loss = 0.39425183250460516, disc_loss = 0.012210000067581097
Trained batch 430 in epoch 9, gen_loss = 0.39422156922778506, disc_loss = 0.012183635693320058
Trained batch 431 in epoch 9, gen_loss = 0.3942952467197621, disc_loss = 0.012158393854204204
Trained batch 432 in epoch 9, gen_loss = 0.3942485032538619, disc_loss = 0.012133613861419743
Trained batch 433 in epoch 9, gen_loss = 0.3943936909261387, disc_loss = 0.012109284568953538
Trained batch 434 in epoch 9, gen_loss = 0.3944075937243714, disc_loss = 0.012083585104294891
Trained batch 435 in epoch 9, gen_loss = 0.39453392769765416, disc_loss = 0.012060568079463454
Trained batch 436 in epoch 9, gen_loss = 0.3946073612441187, disc_loss = 0.012037557835351822
Trained batch 437 in epoch 9, gen_loss = 0.39454577414140307, disc_loss = 0.012015104549511688
Trained batch 438 in epoch 9, gen_loss = 0.3945172528199563, disc_loss = 0.011990909171364948
Trained batch 439 in epoch 9, gen_loss = 0.3946107762103731, disc_loss = 0.011967496322573755
Trained batch 440 in epoch 9, gen_loss = 0.39447561203757653, disc_loss = 0.011942250729995715
Trained batch 441 in epoch 9, gen_loss = 0.39453399147652934, disc_loss = 0.011918096529078624
Trained batch 442 in epoch 9, gen_loss = 0.3944484095002943, disc_loss = 0.011894950292490498
Trained batch 443 in epoch 9, gen_loss = 0.39444892309807444, disc_loss = 0.011872024071242384
Trained batch 444 in epoch 9, gen_loss = 0.39448794159996375, disc_loss = 0.011848422361072152
Trained batch 445 in epoch 9, gen_loss = 0.39448390279650153, disc_loss = 0.01182473623525297
Trained batch 446 in epoch 9, gen_loss = 0.39446017372794867, disc_loss = 0.01180069023804214
Trained batch 447 in epoch 9, gen_loss = 0.3944780543845679, disc_loss = 0.011778008230586627
Trained batch 448 in epoch 9, gen_loss = 0.39452689826355747, disc_loss = 0.011754320463438401
Trained batch 449 in epoch 9, gen_loss = 0.3946236109071308, disc_loss = 0.011731185244991341
Trained batch 450 in epoch 9, gen_loss = 0.39467587227831924, disc_loss = 0.011708727728409234
Trained batch 451 in epoch 9, gen_loss = 0.3946424870364434, disc_loss = 0.011685384726290904
Trained batch 452 in epoch 9, gen_loss = 0.3945937927721878, disc_loss = 0.01166134561444417
Trained batch 453 in epoch 9, gen_loss = 0.3946930485149837, disc_loss = 0.011637786826778343
Trained batch 454 in epoch 9, gen_loss = 0.394603420482887, disc_loss = 0.011613613913720986
Trained batch 455 in epoch 9, gen_loss = 0.39455468469021615, disc_loss = 0.011590678693768527
Trained batch 456 in epoch 9, gen_loss = 0.39460004315073693, disc_loss = 0.011569227115531336
Trained batch 457 in epoch 9, gen_loss = 0.3946698209734463, disc_loss = 0.011546368688964142
Trained batch 458 in epoch 9, gen_loss = 0.39471226151472605, disc_loss = 0.011523618736818701
Trained batch 459 in epoch 9, gen_loss = 0.39456275520117384, disc_loss = 0.011502224050143369
Trained batch 460 in epoch 9, gen_loss = 0.3944438564673939, disc_loss = 0.011480840170122643
Testing Epoch 9
Training Epoch 10
Trained batch 0 in epoch 10, gen_loss = 0.4007837772369385, disc_loss = 0.0010337637504562736
Trained batch 1 in epoch 10, gen_loss = 0.41265980899333954, disc_loss = 0.0010798517032526433
Trained batch 2 in epoch 10, gen_loss = 0.395536611477534, disc_loss = 0.0010403676812226574
Trained batch 3 in epoch 10, gen_loss = 0.40024667233228683, disc_loss = 0.0012166322849225253
Trained batch 4 in epoch 10, gen_loss = 0.3999434769153595, disc_loss = 0.0012454646173864603
Trained batch 5 in epoch 10, gen_loss = 0.40280359983444214, disc_loss = 0.0012005622459885974
Trained batch 6 in epoch 10, gen_loss = 0.4008338323661259, disc_loss = 0.0012501994413988931
Trained batch 7 in epoch 10, gen_loss = 0.3928615152835846, disc_loss = 0.0012455106189008802
Trained batch 8 in epoch 10, gen_loss = 0.3869684040546417, disc_loss = 0.0012408725581028396
Trained batch 9 in epoch 10, gen_loss = 0.3833401769399643, disc_loss = 0.0014000049442984164
Trained batch 10 in epoch 10, gen_loss = 0.38498604026707733, disc_loss = 0.001367636183700101
Trained batch 11 in epoch 10, gen_loss = 0.3836270645260811, disc_loss = 0.0014312872760153066
Trained batch 12 in epoch 10, gen_loss = 0.38151153463583726, disc_loss = 0.0015062774047971917
Trained batch 13 in epoch 10, gen_loss = 0.38211294795785633, disc_loss = 0.001478452909006072
Trained batch 14 in epoch 10, gen_loss = 0.38465829094251, disc_loss = 0.0014361738692969083
Trained batch 15 in epoch 10, gen_loss = 0.38305882923305035, disc_loss = 0.0014206522901076823
Trained batch 16 in epoch 10, gen_loss = 0.38626398058498607, disc_loss = 0.0014827232260037871
Trained batch 17 in epoch 10, gen_loss = 0.3893239696820577, disc_loss = 0.0015205670691405733
Trained batch 18 in epoch 10, gen_loss = 0.3909616031144795, disc_loss = 0.0015045292001511705
Trained batch 19 in epoch 10, gen_loss = 0.38880871534347533, disc_loss = 0.0015428349899593741
Trained batch 20 in epoch 10, gen_loss = 0.3879034277938661, disc_loss = 0.0015978642373478838
Trained batch 21 in epoch 10, gen_loss = 0.39070316742766986, disc_loss = 0.0015913211179643192
Trained batch 22 in epoch 10, gen_loss = 0.38648129934849945, disc_loss = 0.0016740918635269222
Trained batch 23 in epoch 10, gen_loss = 0.38445374742150307, disc_loss = 0.0017838062243148063
Trained batch 24 in epoch 10, gen_loss = 0.38612562775611875, disc_loss = 0.0019148199586197733
Trained batch 25 in epoch 10, gen_loss = 0.38475154684140134, disc_loss = 0.001897017404329605
Trained batch 26 in epoch 10, gen_loss = 0.38650461037953693, disc_loss = 0.0018804678089778732
Trained batch 27 in epoch 10, gen_loss = 0.38486590342862265, disc_loss = 0.0019238456900763725
Trained batch 28 in epoch 10, gen_loss = 0.386406940632853, disc_loss = 0.0019229873894424788
Trained batch 29 in epoch 10, gen_loss = 0.38657839596271515, disc_loss = 0.0019012323309046527
Trained batch 30 in epoch 10, gen_loss = 0.3856983982747601, disc_loss = 0.0018790212625096883
Trained batch 31 in epoch 10, gen_loss = 0.3839044403284788, disc_loss = 0.0018932256280095316
Trained batch 32 in epoch 10, gen_loss = 0.385019965244062, disc_loss = 0.0019209359941834753
Trained batch 33 in epoch 10, gen_loss = 0.38310544981675987, disc_loss = 0.0019060408333590364
Trained batch 34 in epoch 10, gen_loss = 0.3833703449794224, disc_loss = 0.001914260453278465
Trained batch 35 in epoch 10, gen_loss = 0.38306151661607957, disc_loss = 0.001902950005993868
Trained batch 36 in epoch 10, gen_loss = 0.38186822952450933, disc_loss = 0.0019994091236259083
Trained batch 37 in epoch 10, gen_loss = 0.381074016031466, disc_loss = 0.0020107704943879263
Trained batch 38 in epoch 10, gen_loss = 0.3822113871574402, disc_loss = 0.0020218024251218406
Trained batch 39 in epoch 10, gen_loss = 0.38176379501819613, disc_loss = 0.002449483404052444
Trained batch 40 in epoch 10, gen_loss = 0.384419487016957, disc_loss = 0.0037530939372983282
Trained batch 41 in epoch 10, gen_loss = 0.38425135896319434, disc_loss = 0.0038024355973383145
Trained batch 42 in epoch 10, gen_loss = 0.38407403230667114, disc_loss = 0.0037690346741095877
Trained batch 43 in epoch 10, gen_loss = 0.38270675255493686, disc_loss = 0.003880385375602848
Trained batch 44 in epoch 10, gen_loss = 0.38160256544748944, disc_loss = 0.004074745276011526
Trained batch 45 in epoch 10, gen_loss = 0.3820609165274579, disc_loss = 0.004063440256488874
Trained batch 46 in epoch 10, gen_loss = 0.3812119757875483, disc_loss = 0.0040680600077587555
Trained batch 47 in epoch 10, gen_loss = 0.37995941874881584, disc_loss = 0.004163707182063566
Trained batch 48 in epoch 10, gen_loss = 0.3798997900923904, disc_loss = 0.004323798557268266
Trained batch 49 in epoch 10, gen_loss = 0.38033340871334076, disc_loss = 0.0042940336861647666
Trained batch 50 in epoch 10, gen_loss = 0.3828678078511182, disc_loss = 0.004283092603288299
Trained batch 51 in epoch 10, gen_loss = 0.38202392768401366, disc_loss = 0.004343309849411106
Trained batch 52 in epoch 10, gen_loss = 0.3833566977168029, disc_loss = 0.004357488999441969
Trained batch 53 in epoch 10, gen_loss = 0.3836110068692101, disc_loss = 0.004330052992035808
Trained batch 54 in epoch 10, gen_loss = 0.3832044211300937, disc_loss = 0.004287700352936305
Trained batch 55 in epoch 10, gen_loss = 0.3843099187527384, disc_loss = 0.004253757300570474
Trained batch 56 in epoch 10, gen_loss = 0.3845159406201881, disc_loss = 0.004283394123296858
Trained batch 57 in epoch 10, gen_loss = 0.3849335487546592, disc_loss = 0.004244517549021362
Trained batch 58 in epoch 10, gen_loss = 0.38451567595287905, disc_loss = 0.004205513601507045
Trained batch 59 in epoch 10, gen_loss = 0.3844668224453926, disc_loss = 0.00418074411766914
Trained batch 60 in epoch 10, gen_loss = 0.3856062591075897, disc_loss = 0.004160895155452681
Trained batch 61 in epoch 10, gen_loss = 0.3862439576656588, disc_loss = 0.004132375682538916
Trained batch 62 in epoch 10, gen_loss = 0.38689997508412316, disc_loss = 0.004182783042317227
Trained batch 63 in epoch 10, gen_loss = 0.3867026614025235, disc_loss = 0.004156321467235102
Trained batch 64 in epoch 10, gen_loss = 0.3874533602824578, disc_loss = 0.004404613037163821
Trained batch 65 in epoch 10, gen_loss = 0.38828762914195203, disc_loss = 0.004406096136804219
Trained batch 66 in epoch 10, gen_loss = 0.38807282252098196, disc_loss = 0.004994180892705361
Trained batch 67 in epoch 10, gen_loss = 0.3885406238191268, disc_loss = 0.006315306382020935
Trained batch 68 in epoch 10, gen_loss = 0.38921576608782227, disc_loss = 0.006495899593363098
Trained batch 69 in epoch 10, gen_loss = 0.3889159458024161, disc_loss = 0.006770814614303942
Trained batch 70 in epoch 10, gen_loss = 0.39048907874335703, disc_loss = 0.006903135681747865
Trained batch 71 in epoch 10, gen_loss = 0.3909655710061391, disc_loss = 0.006943645736707064
Trained batch 72 in epoch 10, gen_loss = 0.39150733204737104, disc_loss = 0.006903590741312157
Trained batch 73 in epoch 10, gen_loss = 0.3919312764663954, disc_loss = 0.006885709119897739
Trained batch 74 in epoch 10, gen_loss = 0.3922675665219625, disc_loss = 0.006859947112388909
Trained batch 75 in epoch 10, gen_loss = 0.3918013674648185, disc_loss = 0.00703890633150494
Trained batch 76 in epoch 10, gen_loss = 0.39129046495858727, disc_loss = 0.007130047951994295
Trained batch 77 in epoch 10, gen_loss = 0.3908614271726364, disc_loss = 0.00710128961602608
Trained batch 78 in epoch 10, gen_loss = 0.3912906239304361, disc_loss = 0.007044251154978536
Trained batch 79 in epoch 10, gen_loss = 0.3910432759672403, disc_loss = 0.007085262141481507
Trained batch 80 in epoch 10, gen_loss = 0.3923503204628273, disc_loss = 0.007112700568316619
Trained batch 81 in epoch 10, gen_loss = 0.3928001657491777, disc_loss = 0.007066528464769717
Trained batch 82 in epoch 10, gen_loss = 0.3926240299121443, disc_loss = 0.007073776699681149
Trained batch 83 in epoch 10, gen_loss = 0.39228901125135873, disc_loss = 0.0070290464555866836
Trained batch 84 in epoch 10, gen_loss = 0.39144832912613364, disc_loss = 0.007010924001224339
Trained batch 85 in epoch 10, gen_loss = 0.3915328078491743, disc_loss = 0.006974982624321223
Trained batch 86 in epoch 10, gen_loss = 0.3913613848987667, disc_loss = 0.006942042488144475
Trained batch 87 in epoch 10, gen_loss = 0.39151404899629677, disc_loss = 0.006901304445240054
Trained batch 88 in epoch 10, gen_loss = 0.3911615807688638, disc_loss = 0.006902522989548743
Trained batch 89 in epoch 10, gen_loss = 0.39202535814709133, disc_loss = 0.007101186350660605
Trained batch 90 in epoch 10, gen_loss = 0.3922023445695311, disc_loss = 0.007121160151795126
Trained batch 91 in epoch 10, gen_loss = 0.39325127135152405, disc_loss = 0.007224992723659734
Trained batch 92 in epoch 10, gen_loss = 0.3947132659214799, disc_loss = 0.007187525137147355
Trained batch 93 in epoch 10, gen_loss = 0.39504181387576653, disc_loss = 0.007156340966367737
Trained batch 94 in epoch 10, gen_loss = 0.3949587765492891, disc_loss = 0.007131209813891665
Trained batch 95 in epoch 10, gen_loss = 0.3949138441433509, disc_loss = 0.0070747885571715114
Trained batch 96 in epoch 10, gen_loss = 0.394953332610966, disc_loss = 0.007123935146775749
Trained batch 97 in epoch 10, gen_loss = 0.39472561101524195, disc_loss = 0.007116707146395834
Trained batch 98 in epoch 10, gen_loss = 0.39570670868411206, disc_loss = 0.007076739253607964
Trained batch 99 in epoch 10, gen_loss = 0.39590090155601504, disc_loss = 0.007036165548488498
Trained batch 100 in epoch 10, gen_loss = 0.3955129609249606, disc_loss = 0.006989655548264042
Trained batch 101 in epoch 10, gen_loss = 0.3953766790675182, disc_loss = 0.006942636847002979
Trained batch 102 in epoch 10, gen_loss = 0.39480851605100536, disc_loss = 0.006893306172642748
Trained batch 103 in epoch 10, gen_loss = 0.39471858310011715, disc_loss = 0.00684598738175387
Trained batch 104 in epoch 10, gen_loss = 0.39453462362289426, disc_loss = 0.006823789530123274
Trained batch 105 in epoch 10, gen_loss = 0.3946115689457588, disc_loss = 0.006771166405842622
Trained batch 106 in epoch 10, gen_loss = 0.3943551606106981, disc_loss = 0.006735543088299858
Trained batch 107 in epoch 10, gen_loss = 0.3940006654571604, disc_loss = 0.006695779349818757
Trained batch 108 in epoch 10, gen_loss = 0.39384578455478775, disc_loss = 0.006647593388761129
Trained batch 109 in epoch 10, gen_loss = 0.39377280284057964, disc_loss = 0.006611062488941984
Trained batch 110 in epoch 10, gen_loss = 0.3944862098307223, disc_loss = 0.006583197258396057
Trained batch 111 in epoch 10, gen_loss = 0.39455136976071764, disc_loss = 0.00654415472776496
Trained batch 112 in epoch 10, gen_loss = 0.39425660551121805, disc_loss = 0.006511234653602659
Trained batch 113 in epoch 10, gen_loss = 0.39434945818625, disc_loss = 0.006481175944045709
Trained batch 114 in epoch 10, gen_loss = 0.39399686118830807, disc_loss = 0.006441328412367274
Trained batch 115 in epoch 10, gen_loss = 0.39387735852907446, disc_loss = 0.006401082696513562
Trained batch 116 in epoch 10, gen_loss = 0.3938014036060398, disc_loss = 0.006359524396049161
Trained batch 117 in epoch 10, gen_loss = 0.39450519342543716, disc_loss = 0.0063210543831100025
Trained batch 118 in epoch 10, gen_loss = 0.395245576856517, disc_loss = 0.00627958050345955
Trained batch 119 in epoch 10, gen_loss = 0.39543569684028623, disc_loss = 0.006242756082792766
Trained batch 120 in epoch 10, gen_loss = 0.39489051404078146, disc_loss = 0.006209242377961286
Trained batch 121 in epoch 10, gen_loss = 0.3949104085808895, disc_loss = 0.00617122404338395
Trained batch 122 in epoch 10, gen_loss = 0.3948003703016576, disc_loss = 0.006144482318720803
Trained batch 123 in epoch 10, gen_loss = 0.3949806805579893, disc_loss = 0.006108079779697882
Trained batch 124 in epoch 10, gen_loss = 0.3946507580280304, disc_loss = 0.006071782833896577
Trained batch 125 in epoch 10, gen_loss = 0.39464214846255286, disc_loss = 0.00603372030355598
Trained batch 126 in epoch 10, gen_loss = 0.39421263337135315, disc_loss = 0.0059978466941131734
Trained batch 127 in epoch 10, gen_loss = 0.39359780261293054, disc_loss = 0.005961426956673677
Trained batch 128 in epoch 10, gen_loss = 0.3934321315713631, disc_loss = 0.005926498196578707
Trained batch 129 in epoch 10, gen_loss = 0.3929245575116231, disc_loss = 0.005892831302033021
Trained batch 130 in epoch 10, gen_loss = 0.3928211508816435, disc_loss = 0.005858130493549673
Trained batch 131 in epoch 10, gen_loss = 0.3926971893418919, disc_loss = 0.005822690491296464
Trained batch 132 in epoch 10, gen_loss = 0.3924473019919001, disc_loss = 0.005786712301537899
Trained batch 133 in epoch 10, gen_loss = 0.392315537849469, disc_loss = 0.005754768248098388
Trained batch 134 in epoch 10, gen_loss = 0.3921801511888151, disc_loss = 0.005723098580966945
Trained batch 135 in epoch 10, gen_loss = 0.3923956609385855, disc_loss = 0.005695179024341461
Trained batch 136 in epoch 10, gen_loss = 0.3924054081422569, disc_loss = 0.005672283920996489
Trained batch 137 in epoch 10, gen_loss = 0.39290383026219794, disc_loss = 0.005649329640605635
Trained batch 138 in epoch 10, gen_loss = 0.39286449465820256, disc_loss = 0.005617131012585684
Trained batch 139 in epoch 10, gen_loss = 0.3922660429562841, disc_loss = 0.005600880325073376
Trained batch 140 in epoch 10, gen_loss = 0.3922396073950098, disc_loss = 0.005595386981904665
Trained batch 141 in epoch 10, gen_loss = 0.39230570595868874, disc_loss = 0.00556678495051759
Trained batch 142 in epoch 10, gen_loss = 0.3916793205104508, disc_loss = 0.005549308989633369
Trained batch 143 in epoch 10, gen_loss = 0.39207644098334843, disc_loss = 0.005531315086247762
Trained batch 144 in epoch 10, gen_loss = 0.39218859055946614, disc_loss = 0.005507690587145244
Trained batch 145 in epoch 10, gen_loss = 0.39236626131077335, disc_loss = 0.005479653466378071
Trained batch 146 in epoch 10, gen_loss = 0.39231393734614056, disc_loss = 0.0054562030230224335
Trained batch 147 in epoch 10, gen_loss = 0.39254750452331594, disc_loss = 0.00543877122627974
Trained batch 148 in epoch 10, gen_loss = 0.392163802113309, disc_loss = 0.005419601347209924
Trained batch 149 in epoch 10, gen_loss = 0.3926668018102646, disc_loss = 0.005398483457975089
Trained batch 150 in epoch 10, gen_loss = 0.39261469876529365, disc_loss = 0.00539438388409056
Trained batch 151 in epoch 10, gen_loss = 0.39253328622956024, disc_loss = 0.005365475610137525
Trained batch 152 in epoch 10, gen_loss = 0.39213019882152284, disc_loss = 0.005350259224750296
Trained batch 153 in epoch 10, gen_loss = 0.39208938645852076, disc_loss = 0.0053264805714466745
Trained batch 154 in epoch 10, gen_loss = 0.3923938532029429, disc_loss = 0.005304842980037774
Trained batch 155 in epoch 10, gen_loss = 0.39250170993499267, disc_loss = 0.005283379563106558
Trained batch 156 in epoch 10, gen_loss = 0.3925831798155596, disc_loss = 0.005261852062651354
Trained batch 157 in epoch 10, gen_loss = 0.392478398884399, disc_loss = 0.005236614774765234
Trained batch 158 in epoch 10, gen_loss = 0.39244892818372956, disc_loss = 0.005217864019239802
Trained batch 159 in epoch 10, gen_loss = 0.39231071919202803, disc_loss = 0.00519761402028962
Trained batch 160 in epoch 10, gen_loss = 0.3923185878658887, disc_loss = 0.005173848702583856
Trained batch 161 in epoch 10, gen_loss = 0.39228623222421716, disc_loss = 0.005150169323853872
Trained batch 162 in epoch 10, gen_loss = 0.3925292791764429, disc_loss = 0.00514196166111602
Trained batch 163 in epoch 10, gen_loss = 0.39216828637006806, disc_loss = 0.005122422667294059
Trained batch 164 in epoch 10, gen_loss = 0.3924261255697771, disc_loss = 0.005109176003712822
Trained batch 165 in epoch 10, gen_loss = 0.3924461127404707, disc_loss = 0.0051083781297812355
Trained batch 166 in epoch 10, gen_loss = 0.3923344888729963, disc_loss = 0.005423288589516309
Trained batch 167 in epoch 10, gen_loss = 0.39255347404451596, disc_loss = 0.006242804670667586
Trained batch 168 in epoch 10, gen_loss = 0.39268530437932214, disc_loss = 0.00623406667727977
Trained batch 169 in epoch 10, gen_loss = 0.3924131724764319, disc_loss = 0.006325838129337439
Trained batch 170 in epoch 10, gen_loss = 0.3921156070734325, disc_loss = 0.0063497873618164
Trained batch 171 in epoch 10, gen_loss = 0.39201017521148507, disc_loss = 0.0063848400516922825
Trained batch 172 in epoch 10, gen_loss = 0.39198553527710756, disc_loss = 0.006657168495931765
Trained batch 173 in epoch 10, gen_loss = 0.39168353241750564, disc_loss = 0.008830745983467406
Trained batch 174 in epoch 10, gen_loss = 0.3921304888384683, disc_loss = 0.00939476793432342
Trained batch 175 in epoch 10, gen_loss = 0.3925616109574383, disc_loss = 0.009448066830703861
Trained batch 176 in epoch 10, gen_loss = 0.3926920261086717, disc_loss = 0.009479642656926423
Trained batch 177 in epoch 10, gen_loss = 0.39278369522496553, disc_loss = 0.00949893125366901
Trained batch 178 in epoch 10, gen_loss = 0.39294897461070694, disc_loss = 0.009482864790606473
Trained batch 179 in epoch 10, gen_loss = 0.3928076770570543, disc_loss = 0.009447626845212654
Trained batch 180 in epoch 10, gen_loss = 0.39266213560631263, disc_loss = 0.009411365404153932
Trained batch 181 in epoch 10, gen_loss = 0.39219107798167635, disc_loss = 0.009700795956042974
Trained batch 182 in epoch 10, gen_loss = 0.39237739463321497, disc_loss = 0.01130126051597114
Trained batch 183 in epoch 10, gen_loss = 0.39237893567137094, disc_loss = 0.011314855577834152
Trained batch 184 in epoch 10, gen_loss = 0.39234212508072724, disc_loss = 0.01152614251697889
Trained batch 185 in epoch 10, gen_loss = 0.39183348289100073, disc_loss = 0.011840222917261823
Trained batch 186 in epoch 10, gen_loss = 0.3918936297217792, disc_loss = 0.012989538809518643
Trained batch 187 in epoch 10, gen_loss = 0.3911006361880201, disc_loss = 0.014162943572762045
Trained batch 188 in epoch 10, gen_loss = 0.39135485651001095, disc_loss = 0.01432299463475054
Trained batch 189 in epoch 10, gen_loss = 0.39129080631231006, disc_loss = 0.014669561575436474
Trained batch 190 in epoch 10, gen_loss = 0.39098128926067455, disc_loss = 0.014716446607529687
Trained batch 191 in epoch 10, gen_loss = 0.39064775174483657, disc_loss = 0.015056919125224036
Trained batch 192 in epoch 10, gen_loss = 0.39068605461268846, disc_loss = 0.015207966599598952
Trained batch 193 in epoch 10, gen_loss = 0.39084207473956434, disc_loss = 0.015169242042304045
Trained batch 194 in epoch 10, gen_loss = 0.3909834948869852, disc_loss = 0.01521345432429837
Trained batch 195 in epoch 10, gen_loss = 0.39095768895076244, disc_loss = 0.015285133584331227
Trained batch 196 in epoch 10, gen_loss = 0.3912973602108544, disc_loss = 0.015460040581620624
Trained batch 197 in epoch 10, gen_loss = 0.39147644121237474, disc_loss = 0.015546735499002453
Trained batch 198 in epoch 10, gen_loss = 0.3917001924622598, disc_loss = 0.015510909493904953
Trained batch 199 in epoch 10, gen_loss = 0.3918878960609436, disc_loss = 0.01548654260172043
Trained batch 200 in epoch 10, gen_loss = 0.3917405264294563, disc_loss = 0.015445482882958331
Trained batch 201 in epoch 10, gen_loss = 0.39187727691513474, disc_loss = 0.015666171067537243
Trained batch 202 in epoch 10, gen_loss = 0.392065379566747, disc_loss = 0.015662979699896072
Trained batch 203 in epoch 10, gen_loss = 0.39244359015834096, disc_loss = 0.015769022259537094
Trained batch 204 in epoch 10, gen_loss = 0.39243618467958963, disc_loss = 0.01571961054180908
Trained batch 205 in epoch 10, gen_loss = 0.39245778220949823, disc_loss = 0.015769110285582075
Trained batch 206 in epoch 10, gen_loss = 0.3924210336473253, disc_loss = 0.015713359978936324
Trained batch 207 in epoch 10, gen_loss = 0.3928068381949113, disc_loss = 0.01566154904083725
Trained batch 208 in epoch 10, gen_loss = 0.392841706578241, disc_loss = 0.015610633053121705
Trained batch 209 in epoch 10, gen_loss = 0.3925697963862192, disc_loss = 0.015572559618989804
Trained batch 210 in epoch 10, gen_loss = 0.39253765867219714, disc_loss = 0.015621108482415253
Trained batch 211 in epoch 10, gen_loss = 0.3926084481601445, disc_loss = 0.01556480419437647
Trained batch 212 in epoch 10, gen_loss = 0.3929197285936472, disc_loss = 0.01557007089241937
Trained batch 213 in epoch 10, gen_loss = 0.39287070484361913, disc_loss = 0.015510432200754392
Trained batch 214 in epoch 10, gen_loss = 0.39280145043550535, disc_loss = 0.015522634944618615
Trained batch 215 in epoch 10, gen_loss = 0.3927132004389056, disc_loss = 0.015470731234354726
Trained batch 216 in epoch 10, gen_loss = 0.3927241923622272, disc_loss = 0.015493281690451029
Trained batch 217 in epoch 10, gen_loss = 0.39244402835675335, disc_loss = 0.015472631075381037
Trained batch 218 in epoch 10, gen_loss = 0.3924625898332901, disc_loss = 0.015503625426394652
Trained batch 219 in epoch 10, gen_loss = 0.39230581494894895, disc_loss = 0.015491325597130609
Trained batch 220 in epoch 10, gen_loss = 0.3928934546077953, disc_loss = 0.01577945095982099
Trained batch 221 in epoch 10, gen_loss = 0.392721485984218, disc_loss = 0.015734793681773013
Trained batch 222 in epoch 10, gen_loss = 0.3924344375796382, disc_loss = 0.015744383948554406
Trained batch 223 in epoch 10, gen_loss = 0.39218447064714773, disc_loss = 0.015804819700861117
Trained batch 224 in epoch 10, gen_loss = 0.39216825405756633, disc_loss = 0.015757607592580217
Trained batch 225 in epoch 10, gen_loss = 0.39238403486994516, disc_loss = 0.015749268809156246
Trained batch 226 in epoch 10, gen_loss = 0.3923978113655477, disc_loss = 0.015689528172339276
Trained batch 227 in epoch 10, gen_loss = 0.39246950886751475, disc_loss = 0.015766282164054644
Trained batch 228 in epoch 10, gen_loss = 0.3928844706200096, disc_loss = 0.015795597195011203
Trained batch 229 in epoch 10, gen_loss = 0.3929252827944963, disc_loss = 0.01591237190473096
Trained batch 230 in epoch 10, gen_loss = 0.3929082819651732, disc_loss = 0.0159328535700104
Trained batch 231 in epoch 10, gen_loss = 0.3928774335774882, disc_loss = 0.01607909291061364
Trained batch 232 in epoch 10, gen_loss = 0.3929702495044905, disc_loss = 0.016041971401855062
Trained batch 233 in epoch 10, gen_loss = 0.39314130942026776, disc_loss = 0.016011937758706223
Trained batch 234 in epoch 10, gen_loss = 0.39335908585406365, disc_loss = 0.015974622224259407
Trained batch 235 in epoch 10, gen_loss = 0.39366585028878714, disc_loss = 0.01593437459629613
Trained batch 236 in epoch 10, gen_loss = 0.39382037998251773, disc_loss = 0.015880733007812706
Trained batch 237 in epoch 10, gen_loss = 0.3938832324342567, disc_loss = 0.015835064379674454
Trained batch 238 in epoch 10, gen_loss = 0.3933248580998457, disc_loss = 0.01598619582632237
Trained batch 239 in epoch 10, gen_loss = 0.3933392309894164, disc_loss = 0.016163740899355617
Trained batch 240 in epoch 10, gen_loss = 0.39340032210488535, disc_loss = 0.016223950746770622
Trained batch 241 in epoch 10, gen_loss = 0.3934890069991104, disc_loss = 0.01649506118635393
Trained batch 242 in epoch 10, gen_loss = 0.3933795616950518, disc_loss = 0.01664186596588726
Trained batch 243 in epoch 10, gen_loss = 0.3930180317065755, disc_loss = 0.01683890415960541
Trained batch 244 in epoch 10, gen_loss = 0.3929042684788607, disc_loss = 0.016973629710264504
Trained batch 245 in epoch 10, gen_loss = 0.3930862800377171, disc_loss = 0.016941358913133694
Trained batch 246 in epoch 10, gen_loss = 0.3929720686273536, disc_loss = 0.01708073016144863
Trained batch 247 in epoch 10, gen_loss = 0.3930098880683222, disc_loss = 0.01723210553633004
Trained batch 248 in epoch 10, gen_loss = 0.3924927944878498, disc_loss = 0.01785006907714314
Trained batch 249 in epoch 10, gen_loss = 0.39268941354751585, disc_loss = 0.018962313095573335
Trained batch 250 in epoch 10, gen_loss = 0.39271653220947994, disc_loss = 0.01911844323023753
Trained batch 251 in epoch 10, gen_loss = 0.3925135741158137, disc_loss = 0.01920833894918259
Trained batch 252 in epoch 10, gen_loss = 0.3925355653988985, disc_loss = 0.019536845984669926
Trained batch 253 in epoch 10, gen_loss = 0.3923384172944572, disc_loss = 0.020072659853878835
Trained batch 254 in epoch 10, gen_loss = 0.39268650809923805, disc_loss = 0.02098977376807335
Trained batch 255 in epoch 10, gen_loss = 0.392679002485238, disc_loss = 0.02095719063299839
Trained batch 256 in epoch 10, gen_loss = 0.3925562545019365, disc_loss = 0.020926400687969526
Trained batch 257 in epoch 10, gen_loss = 0.3924134140328843, disc_loss = 0.02111430756626795
Trained batch 258 in epoch 10, gen_loss = 0.39265081781217953, disc_loss = 0.021440024788376363
Trained batch 259 in epoch 10, gen_loss = 0.39271702090134986, disc_loss = 0.02138384265619187
Trained batch 260 in epoch 10, gen_loss = 0.392568015161602, disc_loss = 0.02137702694421427
Trained batch 261 in epoch 10, gen_loss = 0.39239290754758677, disc_loss = 0.02138799537223842
Trained batch 262 in epoch 10, gen_loss = 0.3922617680219643, disc_loss = 0.02171187227664466
Trained batch 263 in epoch 10, gen_loss = 0.3924603193546786, disc_loss = 0.022283236752352394
Trained batch 264 in epoch 10, gen_loss = 0.39237946226911724, disc_loss = 0.022659665404572944
Trained batch 265 in epoch 10, gen_loss = 0.3923630244973907, disc_loss = 0.02282165195591594
Trained batch 266 in epoch 10, gen_loss = 0.3924686275841145, disc_loss = 0.022775665454458346
Trained batch 267 in epoch 10, gen_loss = 0.39245863192117036, disc_loss = 0.022735006939150645
Trained batch 268 in epoch 10, gen_loss = 0.39250298060449085, disc_loss = 0.022697337337451048
Trained batch 269 in epoch 10, gen_loss = 0.3926093976806711, disc_loss = 0.022670899726950598
Trained batch 270 in epoch 10, gen_loss = 0.39253870191609286, disc_loss = 0.022617504054360863
Trained batch 271 in epoch 10, gen_loss = 0.3926029793698998, disc_loss = 0.022647821363695104
Trained batch 272 in epoch 10, gen_loss = 0.39284394195664935, disc_loss = 0.02281675115782058
Trained batch 273 in epoch 10, gen_loss = 0.39293959965235997, disc_loss = 0.02276807245636957
Trained batch 274 in epoch 10, gen_loss = 0.3930279471657493, disc_loss = 0.02285659338813275
Trained batch 275 in epoch 10, gen_loss = 0.39319510714731354, disc_loss = 0.02295096148272801
Trained batch 276 in epoch 10, gen_loss = 0.3934578282308062, disc_loss = 0.024662069302633916
Trained batch 277 in epoch 10, gen_loss = 0.3935044738028547, disc_loss = 0.02511936275953454
Trained batch 278 in epoch 10, gen_loss = 0.3932917475914015, disc_loss = 0.025189017842350173
Trained batch 279 in epoch 10, gen_loss = 0.3933340308921678, disc_loss = 0.025219869971624575
Trained batch 280 in epoch 10, gen_loss = 0.39332885122808275, disc_loss = 0.02519828664326172
Trained batch 281 in epoch 10, gen_loss = 0.3932453838857353, disc_loss = 0.025470384652974045
Trained batch 282 in epoch 10, gen_loss = 0.39346214339084423, disc_loss = 0.02576849298829759
Trained batch 283 in epoch 10, gen_loss = 0.393355984817928, disc_loss = 0.025704795749231676
Trained batch 284 in epoch 10, gen_loss = 0.3929381461519944, disc_loss = 0.02606408101171582
Trained batch 285 in epoch 10, gen_loss = 0.39279178066270337, disc_loss = 0.027244598681670517
Trained batch 286 in epoch 10, gen_loss = 0.39250205400098076, disc_loss = 0.027415675145593385
Trained batch 287 in epoch 10, gen_loss = 0.39239680860191584, disc_loss = 0.027435979655921174
Trained batch 288 in epoch 10, gen_loss = 0.3923795371732085, disc_loss = 0.027393282860417603
Trained batch 289 in epoch 10, gen_loss = 0.39212912629390584, disc_loss = 0.027339726585718194
Trained batch 290 in epoch 10, gen_loss = 0.39250041078456077, disc_loss = 0.02736103091960216
Trained batch 291 in epoch 10, gen_loss = 0.39230137889924116, disc_loss = 0.027483898153200056
Trained batch 292 in epoch 10, gen_loss = 0.3924073240252485, disc_loss = 0.027496364789716135
Trained batch 293 in epoch 10, gen_loss = 0.39239082419547905, disc_loss = 0.02752349867373008
Trained batch 294 in epoch 10, gen_loss = 0.39203596296956983, disc_loss = 0.027823537684803418
Trained batch 295 in epoch 10, gen_loss = 0.39235969663069054, disc_loss = 0.028264615126662083
Trained batch 296 in epoch 10, gen_loss = 0.3925584142256265, disc_loss = 0.028348480531967774
Trained batch 297 in epoch 10, gen_loss = 0.39248045068859255, disc_loss = 0.028421251574021783
Trained batch 298 in epoch 10, gen_loss = 0.3925476259611123, disc_loss = 0.028449487310591274
Trained batch 299 in epoch 10, gen_loss = 0.3924134145180384, disc_loss = 0.028383566161695246
Trained batch 300 in epoch 10, gen_loss = 0.39262708635425253, disc_loss = 0.028339531503546598
Trained batch 301 in epoch 10, gen_loss = 0.39256787734315884, disc_loss = 0.028352802368389777
Trained batch 302 in epoch 10, gen_loss = 0.39255409468912056, disc_loss = 0.028292246662747274
Trained batch 303 in epoch 10, gen_loss = 0.3924183391622807, disc_loss = 0.028259432178042755
Trained batch 304 in epoch 10, gen_loss = 0.3923557327419031, disc_loss = 0.02934324500937259
Trained batch 305 in epoch 10, gen_loss = 0.39293240867798623, disc_loss = 0.030321239002636374
Trained batch 306 in epoch 10, gen_loss = 0.3926207910531507, disc_loss = 0.03045914930265688
Trained batch 307 in epoch 10, gen_loss = 0.3928788404960137, disc_loss = 0.030586787888420407
Trained batch 308 in epoch 10, gen_loss = 0.3931275203004238, disc_loss = 0.030702331222813805
Trained batch 309 in epoch 10, gen_loss = 0.3930553599711387, disc_loss = 0.03072038700451113
Trained batch 310 in epoch 10, gen_loss = 0.3933197796536412, disc_loss = 0.030710386180085314
Trained batch 311 in epoch 10, gen_loss = 0.3933452799534186, disc_loss = 0.030733974807588264
Trained batch 312 in epoch 10, gen_loss = 0.3934903781825361, disc_loss = 0.030689449351914703
Trained batch 313 in epoch 10, gen_loss = 0.39335401289781946, disc_loss = 0.030616187505723588
Trained batch 314 in epoch 10, gen_loss = 0.3932428486763485, disc_loss = 0.03066481018091537
Trained batch 315 in epoch 10, gen_loss = 0.39317413749574104, disc_loss = 0.03075305164734173
Trained batch 316 in epoch 10, gen_loss = 0.3931556148483926, disc_loss = 0.03084964128629795
Trained batch 317 in epoch 10, gen_loss = 0.39316112027977995, disc_loss = 0.030856284234195407
Trained batch 318 in epoch 10, gen_loss = 0.3935687119684249, disc_loss = 0.030796884244153142
Trained batch 319 in epoch 10, gen_loss = 0.393523392546922, disc_loss = 0.030732739242739626
Trained batch 320 in epoch 10, gen_loss = 0.39366814169185554, disc_loss = 0.030900538052182725
Trained batch 321 in epoch 10, gen_loss = 0.39382918493718094, disc_loss = 0.03094432480171936
Trained batch 322 in epoch 10, gen_loss = 0.3940792230445165, disc_loss = 0.030891233029048715
Trained batch 323 in epoch 10, gen_loss = 0.3941359864892783, disc_loss = 0.030848545419342562
Trained batch 324 in epoch 10, gen_loss = 0.3941581958073836, disc_loss = 0.030869742282666267
Trained batch 325 in epoch 10, gen_loss = 0.39398546663164363, disc_loss = 0.031014602923082998
Trained batch 326 in epoch 10, gen_loss = 0.39429745205680894, disc_loss = 0.03128037794844877
Trained batch 327 in epoch 10, gen_loss = 0.39453808227326814, disc_loss = 0.031200608872118542
Trained batch 328 in epoch 10, gen_loss = 0.3949046349634153, disc_loss = 0.031177437751367124
Trained batch 329 in epoch 10, gen_loss = 0.39495835484880387, disc_loss = 0.03109960190027557
Trained batch 330 in epoch 10, gen_loss = 0.3949243926029551, disc_loss = 0.031024094027033766
Trained batch 331 in epoch 10, gen_loss = 0.3949907803571368, disc_loss = 0.030958000739197616
Trained batch 332 in epoch 10, gen_loss = 0.39496215497767245, disc_loss = 0.03093448038004596
Trained batch 333 in epoch 10, gen_loss = 0.39508470705526316, disc_loss = 0.03108888323046546
Trained batch 334 in epoch 10, gen_loss = 0.39526676918143655, disc_loss = 0.031107545972440337
Trained batch 335 in epoch 10, gen_loss = 0.39524231984147, disc_loss = 0.03106776005733991
Trained batch 336 in epoch 10, gen_loss = 0.39534973151959724, disc_loss = 0.03114892843625721
Trained batch 337 in epoch 10, gen_loss = 0.3952323308534171, disc_loss = 0.03109436179683461
Trained batch 338 in epoch 10, gen_loss = 0.3950682002007082, disc_loss = 0.031028140905302204
Trained batch 339 in epoch 10, gen_loss = 0.3951830919174587, disc_loss = 0.030977992505615795
Trained batch 340 in epoch 10, gen_loss = 0.3954257191625858, disc_loss = 0.030949372323325498
Trained batch 341 in epoch 10, gen_loss = 0.39564285475259636, disc_loss = 0.030908543366342456
Trained batch 342 in epoch 10, gen_loss = 0.3959741148413444, disc_loss = 0.0308458301521778
Trained batch 343 in epoch 10, gen_loss = 0.3960489501613517, disc_loss = 0.030766601382881988
Trained batch 344 in epoch 10, gen_loss = 0.3960399235504261, disc_loss = 0.03075817362439103
Trained batch 345 in epoch 10, gen_loss = 0.3958585066774677, disc_loss = 0.0308733816252553
Trained batch 346 in epoch 10, gen_loss = 0.39596193462009044, disc_loss = 0.03084823948778051
Trained batch 347 in epoch 10, gen_loss = 0.39592214185616065, disc_loss = 0.030830524284753885
Trained batch 348 in epoch 10, gen_loss = 0.3958639504233199, disc_loss = 0.030834196526010157
Trained batch 349 in epoch 10, gen_loss = 0.39596683280808587, disc_loss = 0.030761246436075973
Trained batch 350 in epoch 10, gen_loss = 0.39625674265402333, disc_loss = 0.030722077277573912
Trained batch 351 in epoch 10, gen_loss = 0.39617225392298266, disc_loss = 0.03074573857719026
Trained batch 352 in epoch 10, gen_loss = 0.396307854071555, disc_loss = 0.030732695176529965
Trained batch 353 in epoch 10, gen_loss = 0.39650910385584426, disc_loss = 0.030657886487687018
Trained batch 354 in epoch 10, gen_loss = 0.3967224996694377, disc_loss = 0.03058426944033938
Trained batch 355 in epoch 10, gen_loss = 0.3966265914312909, disc_loss = 0.030523768682072065
Trained batch 356 in epoch 10, gen_loss = 0.3965932176727541, disc_loss = 0.030469405437110082
Trained batch 357 in epoch 10, gen_loss = 0.3965914142864376, disc_loss = 0.030417789295042588
Trained batch 358 in epoch 10, gen_loss = 0.39665835846765457, disc_loss = 0.0303497419346897
Trained batch 359 in epoch 10, gen_loss = 0.39667794671323564, disc_loss = 0.030296986403603416
Trained batch 360 in epoch 10, gen_loss = 0.3968260542507647, disc_loss = 0.030348879446074305
Trained batch 361 in epoch 10, gen_loss = 0.39706820117834524, disc_loss = 0.03028324321240382
Trained batch 362 in epoch 10, gen_loss = 0.3969437455342821, disc_loss = 0.030273646215995462
Trained batch 363 in epoch 10, gen_loss = 0.39698285511234305, disc_loss = 0.03019951968319499
Trained batch 364 in epoch 10, gen_loss = 0.3970276601510505, disc_loss = 0.0301950634415708
Trained batch 365 in epoch 10, gen_loss = 0.39707294220481415, disc_loss = 0.03012072224815025
Trained batch 366 in epoch 10, gen_loss = 0.3971082253904369, disc_loss = 0.03005211055627707
Trained batch 367 in epoch 10, gen_loss = 0.3969693850401951, disc_loss = 0.02997697434677874
Trained batch 368 in epoch 10, gen_loss = 0.39700198625807515, disc_loss = 0.029905627584173207
Trained batch 369 in epoch 10, gen_loss = 0.3971082869413737, disc_loss = 0.029853991146287503
Trained batch 370 in epoch 10, gen_loss = 0.3971510605831352, disc_loss = 0.029783327685044
Trained batch 371 in epoch 10, gen_loss = 0.39741646017759075, disc_loss = 0.02970807907585886
Trained batch 372 in epoch 10, gen_loss = 0.39753720228218203, disc_loss = 0.02963668428799612
Trained batch 373 in epoch 10, gen_loss = 0.39763622551678335, disc_loss = 0.02956591546628873
Trained batch 374 in epoch 10, gen_loss = 0.39768966976801556, disc_loss = 0.029495709946068625
Trained batch 375 in epoch 10, gen_loss = 0.3976651166981839, disc_loss = 0.02942426656862037
Trained batch 376 in epoch 10, gen_loss = 0.3977553253939044, disc_loss = 0.029350331206608377
Trained batch 377 in epoch 10, gen_loss = 0.39784244625341325, disc_loss = 0.029297017645418505
Trained batch 378 in epoch 10, gen_loss = 0.3979018217340937, disc_loss = 0.0292244726726859
Trained batch 379 in epoch 10, gen_loss = 0.3980156934575031, disc_loss = 0.029160246737668975
Trained batch 380 in epoch 10, gen_loss = 0.39822865752723274, disc_loss = 0.029092305499370995
Trained batch 381 in epoch 10, gen_loss = 0.39834535668033577, disc_loss = 0.029026617005306506
Trained batch 382 in epoch 10, gen_loss = 0.39847946820620145, disc_loss = 0.028959149754346002
Trained batch 383 in epoch 10, gen_loss = 0.39840563014149666, disc_loss = 0.02889214591050404
Trained batch 384 in epoch 10, gen_loss = 0.398563244280877, disc_loss = 0.028824079132263924
Trained batch 385 in epoch 10, gen_loss = 0.39843266391692383, disc_loss = 0.028759156572125813
Trained batch 386 in epoch 10, gen_loss = 0.39849171735519584, disc_loss = 0.028692257022051963
Trained batch 387 in epoch 10, gen_loss = 0.39846227686737, disc_loss = 0.028630931287423046
Trained batch 388 in epoch 10, gen_loss = 0.39848174625926275, disc_loss = 0.028563508238992952
Trained batch 389 in epoch 10, gen_loss = 0.3984824329614639, disc_loss = 0.028494970417187477
Trained batch 390 in epoch 10, gen_loss = 0.3983865510624693, disc_loss = 0.028426998240403983
Trained batch 391 in epoch 10, gen_loss = 0.398415062272427, disc_loss = 0.028359913136227988
Trained batch 392 in epoch 10, gen_loss = 0.3984165317532974, disc_loss = 0.028292544949183634
Trained batch 393 in epoch 10, gen_loss = 0.39821257256916937, disc_loss = 0.02822499464828578
Trained batch 394 in epoch 10, gen_loss = 0.3981905729710301, disc_loss = 0.02816102886159869
Trained batch 395 in epoch 10, gen_loss = 0.39830989495973396, disc_loss = 0.028104176491409578
Trained batch 396 in epoch 10, gen_loss = 0.39827872493705463, disc_loss = 0.028039767880752794
Trained batch 397 in epoch 10, gen_loss = 0.3982869851679059, disc_loss = 0.027981250929463672
Trained batch 398 in epoch 10, gen_loss = 0.398260904434032, disc_loss = 0.027922543425131636
Trained batch 399 in epoch 10, gen_loss = 0.3984649541974068, disc_loss = 0.0278650792024564
Trained batch 400 in epoch 10, gen_loss = 0.3984823436511128, disc_loss = 0.02780527676783149
Trained batch 401 in epoch 10, gen_loss = 0.39850710102574743, disc_loss = 0.02773909035673949
Trained batch 402 in epoch 10, gen_loss = 0.39849073412104813, disc_loss = 0.027674861777765635
Trained batch 403 in epoch 10, gen_loss = 0.39834897360294175, disc_loss = 0.027609581200090137
Trained batch 404 in epoch 10, gen_loss = 0.39833138011119984, disc_loss = 0.027546887375402875
Trained batch 405 in epoch 10, gen_loss = 0.39817766213945566, disc_loss = 0.027485543779118143
Trained batch 406 in epoch 10, gen_loss = 0.39822252911197464, disc_loss = 0.02742236442188904
Trained batch 407 in epoch 10, gen_loss = 0.3980587172303714, disc_loss = 0.027363795623886307
Trained batch 408 in epoch 10, gen_loss = 0.3981011354690076, disc_loss = 0.027301695645265373
Trained batch 409 in epoch 10, gen_loss = 0.39805990733751434, disc_loss = 0.02724313818020519
Trained batch 410 in epoch 10, gen_loss = 0.3981201774882574, disc_loss = 0.02718095163420441
Trained batch 411 in epoch 10, gen_loss = 0.39803002224963846, disc_loss = 0.027118752338670338
Trained batch 412 in epoch 10, gen_loss = 0.39812188027268747, disc_loss = 0.02706259463915994
Trained batch 413 in epoch 10, gen_loss = 0.3981987940516449, disc_loss = 0.02700828800454808
Trained batch 414 in epoch 10, gen_loss = 0.398135017056063, disc_loss = 0.026947415650104094
Trained batch 415 in epoch 10, gen_loss = 0.3980677890089842, disc_loss = 0.026886547264719132
Trained batch 416 in epoch 10, gen_loss = 0.3980916484082631, disc_loss = 0.026830888397397577
Trained batch 417 in epoch 10, gen_loss = 0.39800852715398705, disc_loss = 0.026769960435601977
Trained batch 418 in epoch 10, gen_loss = 0.39791745103913445, disc_loss = 0.026712178310428287
Trained batch 419 in epoch 10, gen_loss = 0.39804138732807975, disc_loss = 0.026653554130877766
Trained batch 420 in epoch 10, gen_loss = 0.3979495777228666, disc_loss = 0.026598443226853383
Trained batch 421 in epoch 10, gen_loss = 0.3980419425320286, disc_loss = 0.02654200441687328
Trained batch 422 in epoch 10, gen_loss = 0.398011997377337, disc_loss = 0.026485058714593838
Trained batch 423 in epoch 10, gen_loss = 0.39797315268584016, disc_loss = 0.026426180168098928
Trained batch 424 in epoch 10, gen_loss = 0.3981348705291748, disc_loss = 0.026368404271300223
Trained batch 425 in epoch 10, gen_loss = 0.3983933296002133, disc_loss = 0.026309907495398337
Trained batch 426 in epoch 10, gen_loss = 0.39841180432596585, disc_loss = 0.026253455108035992
Trained batch 427 in epoch 10, gen_loss = 0.39841466738241854, disc_loss = 0.026196573917790986
Trained batch 428 in epoch 10, gen_loss = 0.39851985138890905, disc_loss = 0.026143342511899908
Trained batch 429 in epoch 10, gen_loss = 0.3987123144920482, disc_loss = 0.0260862962694752
Trained batch 430 in epoch 10, gen_loss = 0.39853295780666464, disc_loss = 0.026029712079187937
Trained batch 431 in epoch 10, gen_loss = 0.3985303333374085, disc_loss = 0.025972320313384343
Trained batch 432 in epoch 10, gen_loss = 0.39844375153612044, disc_loss = 0.0259177681632925
Trained batch 433 in epoch 10, gen_loss = 0.3983467444434144, disc_loss = 0.02586037024462913
Trained batch 434 in epoch 10, gen_loss = 0.398407422400069, disc_loss = 0.02580457227893345
Trained batch 435 in epoch 10, gen_loss = 0.3984369584316507, disc_loss = 0.02575150043372526
Trained batch 436 in epoch 10, gen_loss = 0.39841569281551875, disc_loss = 0.02569561433611817
Trained batch 437 in epoch 10, gen_loss = 0.3984041343268738, disc_loss = 0.02563992773791877
Trained batch 438 in epoch 10, gen_loss = 0.3983300242038414, disc_loss = 0.025596221217594972
Trained batch 439 in epoch 10, gen_loss = 0.3985789253630421, disc_loss = 0.025542590902874838
Trained batch 440 in epoch 10, gen_loss = 0.3984191144675084, disc_loss = 0.025490235589294696
Trained batch 441 in epoch 10, gen_loss = 0.39845910432381865, disc_loss = 0.025440875192465708
Trained batch 442 in epoch 10, gen_loss = 0.3983372700806396, disc_loss = 0.025386924670407922
Trained batch 443 in epoch 10, gen_loss = 0.39839177222939226, disc_loss = 0.02534069076205629
Trained batch 444 in epoch 10, gen_loss = 0.39848126152927954, disc_loss = 0.025291456872325264
Trained batch 445 in epoch 10, gen_loss = 0.398354904868143, disc_loss = 0.025237503388453892
Trained batch 446 in epoch 10, gen_loss = 0.398443630011023, disc_loss = 0.02518874335246498
Trained batch 447 in epoch 10, gen_loss = 0.3984523637087217, disc_loss = 0.02513666883688919
Trained batch 448 in epoch 10, gen_loss = 0.3985117480722992, disc_loss = 0.025085984316980156
Trained batch 449 in epoch 10, gen_loss = 0.398521741827329, disc_loss = 0.025035370031061273
Trained batch 450 in epoch 10, gen_loss = 0.39854619409186876, disc_loss = 0.02498401105641377
Trained batch 451 in epoch 10, gen_loss = 0.3985192848254094, disc_loss = 0.02493200207024038
Trained batch 452 in epoch 10, gen_loss = 0.39859456942307764, disc_loss = 0.02488094410847741
Trained batch 453 in epoch 10, gen_loss = 0.398624843569054, disc_loss = 0.024830814959462898
Trained batch 454 in epoch 10, gen_loss = 0.39855599874978537, disc_loss = 0.02477977147382162
Trained batch 455 in epoch 10, gen_loss = 0.3985671321943141, disc_loss = 0.02473006491766826
Trained batch 456 in epoch 10, gen_loss = 0.39865469606491355, disc_loss = 0.024682181583935522
Trained batch 457 in epoch 10, gen_loss = 0.3985197287719843, disc_loss = 0.024634800598434047
Trained batch 458 in epoch 10, gen_loss = 0.3985882200187068, disc_loss = 0.024589067630617918
Trained batch 459 in epoch 10, gen_loss = 0.3984636582758116, disc_loss = 0.02453891047727033
Trained batch 460 in epoch 10, gen_loss = 0.3982010023454265, disc_loss = 0.024534641511772644
Testing Epoch 10
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-08-30 00:44:42,159
------------------------------------------------------------
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-08-30 00:44:42,183
------------------------------------------------------------
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-08-30 00:44:42,205
------------------------------------------------------------
Training Epoch 11
Trained batch 0 in epoch 11, gen_loss = 0.44571128487586975, disc_loss = 0.00703493133187294
Trained batch 1 in epoch 11, gen_loss = 0.3750753551721573, disc_loss = 0.007706162985414267
Trained batch 2 in epoch 11, gen_loss = 0.3876868585745494, disc_loss = 0.006210468088587125
Trained batch 3 in epoch 11, gen_loss = 0.3847584053874016, disc_loss = 0.005285088671371341
Trained batch 4 in epoch 11, gen_loss = 0.38347101807594297, disc_loss = 0.005112458299845457
Trained batch 5 in epoch 11, gen_loss = 0.39544005195299786, disc_loss = 0.005546429194509983
Trained batch 6 in epoch 11, gen_loss = 0.38844662478991915, disc_loss = 0.005600560123899153
Trained batch 7 in epoch 11, gen_loss = 0.38801995292305946, disc_loss = 0.00562987825833261
Trained batch 8 in epoch 11, gen_loss = 0.39543406830893624, disc_loss = 0.006117728435330921
Trained batch 9 in epoch 11, gen_loss = 0.397532519698143, disc_loss = 0.005987050523981452
Trained batch 10 in epoch 11, gen_loss = 0.39607760310173035, disc_loss = 0.005782007324424657
Trained batch 11 in epoch 11, gen_loss = 0.4018462176124255, disc_loss = 0.005642990581691265
Trained batch 12 in epoch 11, gen_loss = 0.4007268066589649, disc_loss = 0.005421150654840928
Trained batch 13 in epoch 11, gen_loss = 0.40088116909776417, disc_loss = 0.005198606988415122
Trained batch 14 in epoch 11, gen_loss = 0.4004541834195455, disc_loss = 0.005099322010452548
Trained batch 15 in epoch 11, gen_loss = 0.4006522726267576, disc_loss = 0.005374336600652896
Trained batch 16 in epoch 11, gen_loss = 0.4031979318927316, disc_loss = 0.005483374314601807
Trained batch 17 in epoch 11, gen_loss = 0.4060281531678306, disc_loss = 0.005366677198455566
Trained batch 18 in epoch 11, gen_loss = 0.4057714641094208, disc_loss = 0.005207742552125924
Trained batch 19 in epoch 11, gen_loss = 0.40371249318122865, disc_loss = 0.005078740604221821
Trained batch 20 in epoch 11, gen_loss = 0.403328979299182, disc_loss = 0.004990903904572839
Trained batch 21 in epoch 11, gen_loss = 0.40018267929553986, disc_loss = 0.004871478198434819
Trained batch 22 in epoch 11, gen_loss = 0.3982508454633796, disc_loss = 0.00472528301179409
Trained batch 23 in epoch 11, gen_loss = 0.40289680287241936, disc_loss = 0.004653378564398736
Trained batch 24 in epoch 11, gen_loss = 0.40362643003463744, disc_loss = 0.004530145507305861
Trained batch 25 in epoch 11, gen_loss = 0.40209523416482484, disc_loss = 0.00466828691199995
Trained batch 26 in epoch 11, gen_loss = 0.39981360567940605, disc_loss = 0.005448190547111962
Trained batch 27 in epoch 11, gen_loss = 0.39876656234264374, disc_loss = 0.00531166886711227
Trained batch 28 in epoch 11, gen_loss = 0.4005925788961608, disc_loss = 0.005655734302026445
Trained batch 29 in epoch 11, gen_loss = 0.40051715075969696, disc_loss = 0.0055743821508561575
Trained batch 30 in epoch 11, gen_loss = 0.4014442495761379, disc_loss = 0.0055361235769645824
Trained batch 31 in epoch 11, gen_loss = 0.4016653327271342, disc_loss = 0.006012464647938032
Trained batch 32 in epoch 11, gen_loss = 0.4023372946363507, disc_loss = 0.006218537779976473
Trained batch 33 in epoch 11, gen_loss = 0.40082304793245654, disc_loss = 0.006138153880944147
Trained batch 34 in epoch 11, gen_loss = 0.40058339067867826, disc_loss = 0.006040241555976016
Trained batch 35 in epoch 11, gen_loss = 0.4010895813504855, disc_loss = 0.005995123026271661
Trained batch 36 in epoch 11, gen_loss = 0.4008903430925833, disc_loss = 0.005955503813016253
Trained batch 37 in epoch 11, gen_loss = 0.4011658171289845, disc_loss = 0.005888199605243771
Trained batch 38 in epoch 11, gen_loss = 0.399814805159202, disc_loss = 0.005981958471238613
Trained batch 39 in epoch 11, gen_loss = 0.4000675618648529, disc_loss = 0.005912922893185168
Trained batch 40 in epoch 11, gen_loss = 0.39937760190265936, disc_loss = 0.006238440153893174
Trained batch 41 in epoch 11, gen_loss = 0.3992505648306438, disc_loss = 0.006257463168973724
Trained batch 42 in epoch 11, gen_loss = 0.39757296235062356, disc_loss = 0.006176660026878465
Trained batch 43 in epoch 11, gen_loss = 0.39767153561115265, disc_loss = 0.0067440315139141276
Trained batch 44 in epoch 11, gen_loss = 0.39711461663246156, disc_loss = 0.010545833879667852
Trained batch 45 in epoch 11, gen_loss = 0.39807758447916614, disc_loss = 0.01846748134424991
Trained batch 46 in epoch 11, gen_loss = 0.3982503033698873, disc_loss = 0.02012059026635549
Trained batch 47 in epoch 11, gen_loss = 0.3969878014177084, disc_loss = 0.021466395948664285
Trained batch 48 in epoch 11, gen_loss = 0.39617657418153723, disc_loss = 0.022105261811758488
Trained batch 49 in epoch 11, gen_loss = 0.3963704597949982, disc_loss = 0.02216052161063999
Trained batch 50 in epoch 11, gen_loss = 0.3964674507870394, disc_loss = 0.0222335522948746
Trained batch 51 in epoch 11, gen_loss = 0.3967195623196088, disc_loss = 0.022025604638306853
Trained batch 52 in epoch 11, gen_loss = 0.396379457892112, disc_loss = 0.022101817525185224
Trained batch 53 in epoch 11, gen_loss = 0.39642613574310587, disc_loss = 0.022102745090335333
Trained batch 54 in epoch 11, gen_loss = 0.3961856571110812, disc_loss = 0.021867154889994047
Trained batch 55 in epoch 11, gen_loss = 0.39584235155156683, disc_loss = 0.022009871746247103
Trained batch 56 in epoch 11, gen_loss = 0.39478397683093425, disc_loss = 0.022461583654053117
Trained batch 57 in epoch 11, gen_loss = 0.39606753505509473, disc_loss = 0.02598050536571777
Trained batch 58 in epoch 11, gen_loss = 0.39534930455482614, disc_loss = 0.026108764597388395
Trained batch 59 in epoch 11, gen_loss = 0.3945554261406263, disc_loss = 0.02617606627366816
Trained batch 60 in epoch 11, gen_loss = 0.3940797966034686, disc_loss = 0.026424872043893717
Trained batch 61 in epoch 11, gen_loss = 0.39498470098741595, disc_loss = 0.026230729541801397
Trained batch 62 in epoch 11, gen_loss = 0.39510011294531444, disc_loss = 0.026215708766516948
Trained batch 63 in epoch 11, gen_loss = 0.3952082609757781, disc_loss = 0.02768476665005437
Trained batch 64 in epoch 11, gen_loss = 0.39703523104007427, disc_loss = 0.03527154907799111
Trained batch 65 in epoch 11, gen_loss = 0.396451885953094, disc_loss = 0.035409678757952694
Trained batch 66 in epoch 11, gen_loss = 0.39651859651750593, disc_loss = 0.042836648950686874
Trained batch 67 in epoch 11, gen_loss = 0.3958611878402093, disc_loss = 0.042953426699729305
Trained batch 68 in epoch 11, gen_loss = 0.39711454078771063, disc_loss = 0.04512349885645444
Trained batch 69 in epoch 11, gen_loss = 0.3962102689913341, disc_loss = 0.045247385408064084
Trained batch 70 in epoch 11, gen_loss = 0.39572814358791836, disc_loss = 0.04630087942711379
Trained batch 71 in epoch 11, gen_loss = 0.39491581088966793, disc_loss = 0.04658509653462614
Trained batch 72 in epoch 11, gen_loss = 0.3957591865160694, disc_loss = 0.047356009352569506
Trained batch 73 in epoch 11, gen_loss = 0.3955788564037632, disc_loss = 0.04788159334566444
Trained batch 74 in epoch 11, gen_loss = 0.3953898501396179, disc_loss = 0.04916974541731179
Trained batch 75 in epoch 11, gen_loss = 0.396352546779733, disc_loss = 0.05142564264947156
Trained batch 76 in epoch 11, gen_loss = 0.39528229639127654, disc_loss = 0.05143089492974633
Trained batch 77 in epoch 11, gen_loss = 0.39452946988435894, disc_loss = 0.05239456182477088
Trained batch 78 in epoch 11, gen_loss = 0.39438490362107, disc_loss = 0.05226628366515889
Trained batch 79 in epoch 11, gen_loss = 0.3945658128708601, disc_loss = 0.05189036198135
Trained batch 80 in epoch 11, gen_loss = 0.39453213266384457, disc_loss = 0.05137186931779631
Trained batch 81 in epoch 11, gen_loss = 0.39529171477003794, disc_loss = 0.050872471203414225
Trained batch 82 in epoch 11, gen_loss = 0.3953530605298927, disc_loss = 0.05040811329619981
Trained batch 83 in epoch 11, gen_loss = 0.39585022912138984, disc_loss = 0.0499874407597374
Trained batch 84 in epoch 11, gen_loss = 0.39470219997798695, disc_loss = 0.05009972072644707
Trained batch 85 in epoch 11, gen_loss = 0.39335061263206395, disc_loss = 0.053702360373748426
Trained batch 86 in epoch 11, gen_loss = 0.39482149824328805, disc_loss = 0.05636501488618381
Trained batch 87 in epoch 11, gen_loss = 0.3950372978367589, disc_loss = 0.05668445664659058
Trained batch 88 in epoch 11, gen_loss = 0.39484742953536217, disc_loss = 0.05747145536523103
Trained batch 89 in epoch 11, gen_loss = 0.39448691242271, disc_loss = 0.0574765371857211
Trained batch 90 in epoch 11, gen_loss = 0.39467146141188486, disc_loss = 0.05696878306680246
Trained batch 91 in epoch 11, gen_loss = 0.39478006213903427, disc_loss = 0.05782762067341853
Trained batch 92 in epoch 11, gen_loss = 0.3930655365349144, disc_loss = 0.059741654010209186
Trained batch 93 in epoch 11, gen_loss = 0.3933078066465702, disc_loss = 0.059250936652731866
Trained batch 94 in epoch 11, gen_loss = 0.39414056884615045, disc_loss = 0.05899731354836963
Trained batch 95 in epoch 11, gen_loss = 0.39412247482687235, disc_loss = 0.058763270060201954
Trained batch 96 in epoch 11, gen_loss = 0.3939440871022411, disc_loss = 0.05840992972437177
Trained batch 97 in epoch 11, gen_loss = 0.39393414830674933, disc_loss = 0.058417537674897026
Trained batch 98 in epoch 11, gen_loss = 0.3947100705570645, disc_loss = 0.05911136575447715
Trained batch 99 in epoch 11, gen_loss = 0.3952825638651848, disc_loss = 0.05864314966602251
Trained batch 100 in epoch 11, gen_loss = 0.3959095309866537, disc_loss = 0.058351312853893875
Trained batch 101 in epoch 11, gen_loss = 0.39592358499181035, disc_loss = 0.05783122226221524
Trained batch 102 in epoch 11, gen_loss = 0.3963668366659035, disc_loss = 0.057351957335254375
Trained batch 103 in epoch 11, gen_loss = 0.3960317677030197, disc_loss = 0.056947390582466215
Trained batch 104 in epoch 11, gen_loss = 0.39550686734063284, disc_loss = 0.05653399124165021
Trained batch 105 in epoch 11, gen_loss = 0.39568341003274016, disc_loss = 0.056409949030428425
Trained batch 106 in epoch 11, gen_loss = 0.3963285456193942, disc_loss = 0.056394385728793586
Trained batch 107 in epoch 11, gen_loss = 0.3969224081547172, disc_loss = 0.05595835717179364
Trained batch 108 in epoch 11, gen_loss = 0.39626039414230835, disc_loss = 0.05549644598301603
Trained batch 109 in epoch 11, gen_loss = 0.39601438885385337, disc_loss = 0.055236953105354175
Trained batch 110 in epoch 11, gen_loss = 0.3965378492265134, disc_loss = 0.055333827007645824
Trained batch 111 in epoch 11, gen_loss = 0.3964510363127504, disc_loss = 0.05619745383696032
Trained batch 112 in epoch 11, gen_loss = 0.39659708369094715, disc_loss = 0.05605170939867673
Trained batch 113 in epoch 11, gen_loss = 0.396120239506688, disc_loss = 0.05568447495655467
Trained batch 114 in epoch 11, gen_loss = 0.39633213799932726, disc_loss = 0.055381290879829424
Trained batch 115 in epoch 11, gen_loss = 0.3962697422709958, disc_loss = 0.05518625812115276
Trained batch 116 in epoch 11, gen_loss = 0.39590132440257275, disc_loss = 0.05488868621894373
Trained batch 117 in epoch 11, gen_loss = 0.3959075646885371, disc_loss = 0.05473019524232753
Trained batch 118 in epoch 11, gen_loss = 0.39558123340125845, disc_loss = 0.05464389006716802
Trained batch 119 in epoch 11, gen_loss = 0.39607094451785085, disc_loss = 0.05459813532070257
Trained batch 120 in epoch 11, gen_loss = 0.3957301784645427, disc_loss = 0.05419750605355794
Trained batch 121 in epoch 11, gen_loss = 0.39537474439769493, disc_loss = 0.05384569537070137
Trained batch 122 in epoch 11, gen_loss = 0.39482258151217203, disc_loss = 0.053812761084986775
Trained batch 123 in epoch 11, gen_loss = 0.39540549151359067, disc_loss = 0.05373835318624192
Trained batch 124 in epoch 11, gen_loss = 0.39591980195045473, disc_loss = 0.053356230909004806
Trained batch 125 in epoch 11, gen_loss = 0.3958362452094517, disc_loss = 0.05295781848309118
Trained batch 126 in epoch 11, gen_loss = 0.3960967354887114, disc_loss = 0.052616186251159845
Trained batch 127 in epoch 11, gen_loss = 0.3959720393177122, disc_loss = 0.052236690376957995
Trained batch 128 in epoch 11, gen_loss = 0.39589998796004655, disc_loss = 0.05188421872733233
Trained batch 129 in epoch 11, gen_loss = 0.39625351979182316, disc_loss = 0.0516943376744166
Trained batch 130 in epoch 11, gen_loss = 0.3958530983397069, disc_loss = 0.05133956525908456
Trained batch 131 in epoch 11, gen_loss = 0.39538864520463074, disc_loss = 0.05108150720038931
Trained batch 132 in epoch 11, gen_loss = 0.3953503722086885, disc_loss = 0.05100689544272434
Trained batch 133 in epoch 11, gen_loss = 0.3964073206506558, disc_loss = 0.05095060799555825
Trained batch 134 in epoch 11, gen_loss = 0.3969094393429933, disc_loss = 0.05081433785078978
Trained batch 135 in epoch 11, gen_loss = 0.39675353642772226, disc_loss = 0.05058725149651496
Trained batch 136 in epoch 11, gen_loss = 0.39736591899482004, disc_loss = 0.05030759129788808
Trained batch 137 in epoch 11, gen_loss = 0.39728519989960437, disc_loss = 0.05058594533424501
Trained batch 138 in epoch 11, gen_loss = 0.3977169975531187, disc_loss = 0.05192827234520383
Trained batch 139 in epoch 11, gen_loss = 0.39763154834508896, disc_loss = 0.05169731053423935
Trained batch 140 in epoch 11, gen_loss = 0.3968192880035292, disc_loss = 0.05167092104997248
Trained batch 141 in epoch 11, gen_loss = 0.39672546928197566, disc_loss = 0.051388763470089874
Trained batch 142 in epoch 11, gen_loss = 0.39684450126194454, disc_loss = 0.051067830032467114
Trained batch 143 in epoch 11, gen_loss = 0.3966704836736123, disc_loss = 0.05096638643913644
Trained batch 144 in epoch 11, gen_loss = 0.39571086620462353, disc_loss = 0.05139462029529286
Trained batch 145 in epoch 11, gen_loss = 0.39559892820168846, disc_loss = 0.051860890684534526
Trained batch 146 in epoch 11, gen_loss = 0.39568965613436535, disc_loss = 0.05184465095711251
Trained batch 147 in epoch 11, gen_loss = 0.3956656647292343, disc_loss = 0.051745851664187235
Trained batch 148 in epoch 11, gen_loss = 0.39585209312854996, disc_loss = 0.05145870805592995
Trained batch 149 in epoch 11, gen_loss = 0.3960679018497467, disc_loss = 0.05116113071795553
Trained batch 150 in epoch 11, gen_loss = 0.3956097774947716, disc_loss = 0.051395365192758426
Trained batch 151 in epoch 11, gen_loss = 0.3960041164567596, disc_loss = 0.05161711779625253
Trained batch 152 in epoch 11, gen_loss = 0.3962479089599809, disc_loss = 0.05143176637790805
Trained batch 153 in epoch 11, gen_loss = 0.39640078761360864, disc_loss = 0.05116329447505391
Trained batch 154 in epoch 11, gen_loss = 0.39646590217467276, disc_loss = 0.05093194828068297
Trained batch 155 in epoch 11, gen_loss = 0.39642983159193623, disc_loss = 0.050968936287786044
Trained batch 156 in epoch 11, gen_loss = 0.3967152763703826, disc_loss = 0.050808961391982856
Trained batch 157 in epoch 11, gen_loss = 0.3961399853984012, disc_loss = 0.05091953143341867
Trained batch 158 in epoch 11, gen_loss = 0.39662915974293117, disc_loss = 0.05173734156268432
Trained batch 159 in epoch 11, gen_loss = 0.3967782765626907, disc_loss = 0.05171674739249284
Trained batch 160 in epoch 11, gen_loss = 0.39655991555741116, disc_loss = 0.051445086725252845
Trained batch 161 in epoch 11, gen_loss = 0.3964372663586228, disc_loss = 0.051261097263188365
Trained batch 162 in epoch 11, gen_loss = 0.3959854398768372, disc_loss = 0.05120378246022377
Trained batch 163 in epoch 11, gen_loss = 0.39623878169350507, disc_loss = 0.05336045826041344
Trained batch 164 in epoch 11, gen_loss = 0.3956946074962616, disc_loss = 0.054839712269886425
Trained batch 165 in epoch 11, gen_loss = 0.39552361257823115, disc_loss = 0.05609511438313961
Trained batch 166 in epoch 11, gen_loss = 0.39521958299739635, disc_loss = 0.056639394250246666
Trained batch 167 in epoch 11, gen_loss = 0.3950474670245534, disc_loss = 0.056846306106308475
Trained batch 168 in epoch 11, gen_loss = 0.39483925700187683, disc_loss = 0.05685623887424859
Trained batch 169 in epoch 11, gen_loss = 0.3948182283078923, disc_loss = 0.0568045954726746
Trained batch 170 in epoch 11, gen_loss = 0.3948460327602967, disc_loss = 0.05665099163463459
Trained batch 171 in epoch 11, gen_loss = 0.39425344280032226, disc_loss = 0.056508648795411426
Trained batch 172 in epoch 11, gen_loss = 0.39366693079816123, disc_loss = 0.057021564918414105
Trained batch 173 in epoch 11, gen_loss = 0.39353575720184153, disc_loss = 0.05932830676741513
Trained batch 174 in epoch 11, gen_loss = 0.39280192136764525, disc_loss = 0.05998943678103388
Trained batch 175 in epoch 11, gen_loss = 0.39240322702310304, disc_loss = 0.0617159702405016
Trained batch 176 in epoch 11, gen_loss = 0.3925773442465033, disc_loss = 0.06312736102884983
Trained batch 177 in epoch 11, gen_loss = 0.3927715340357148, disc_loss = 0.06450893830513225
Trained batch 178 in epoch 11, gen_loss = 0.39278298083630353, disc_loss = 0.06931371753905281
Trained batch 179 in epoch 11, gen_loss = 0.39236630002657574, disc_loss = 0.07069166228304513
Trained batch 180 in epoch 11, gen_loss = 0.39254990664634914, disc_loss = 0.07184167947357736
Trained batch 181 in epoch 11, gen_loss = 0.3924219758955987, disc_loss = 0.0719824697794188
Trained batch 182 in epoch 11, gen_loss = 0.39209402600924176, disc_loss = 0.07231972720906586
Trained batch 183 in epoch 11, gen_loss = 0.3921475564332112, disc_loss = 0.07265538851978541
Trained batch 184 in epoch 11, gen_loss = 0.39191542364455556, disc_loss = 0.0728643893805408
Trained batch 185 in epoch 11, gen_loss = 0.39176771653595793, disc_loss = 0.07325750553444708
Trained batch 186 in epoch 11, gen_loss = 0.3916708844549516, disc_loss = 0.07327736021806411
Trained batch 187 in epoch 11, gen_loss = 0.3916970840159883, disc_loss = 0.07320043922307842
Trained batch 188 in epoch 11, gen_loss = 0.3923689423414765, disc_loss = 0.07334305312627404
Trained batch 189 in epoch 11, gen_loss = 0.39216342678195554, disc_loss = 0.07327328459727332
Trained batch 190 in epoch 11, gen_loss = 0.39193419589422135, disc_loss = 0.07327133255367074
Trained batch 191 in epoch 11, gen_loss = 0.3919551425303022, disc_loss = 0.07383638769897516
Trained batch 192 in epoch 11, gen_loss = 0.3922319992836275, disc_loss = 0.0753350563050571
Trained batch 193 in epoch 11, gen_loss = 0.39181573750432, disc_loss = 0.07524207415006402
Trained batch 194 in epoch 11, gen_loss = 0.39178570356124487, disc_loss = 0.07519492308418146
Trained batch 195 in epoch 11, gen_loss = 0.39154353205646786, disc_loss = 0.07505973987400114
Trained batch 196 in epoch 11, gen_loss = 0.391246724098467, disc_loss = 0.07484842672457134
Trained batch 197 in epoch 11, gen_loss = 0.3912156142971732, disc_loss = 0.0746450164000212
Trained batch 198 in epoch 11, gen_loss = 0.3911003392545422, disc_loss = 0.0747949208645384
Trained batch 199 in epoch 11, gen_loss = 0.3913793978095055, disc_loss = 0.07573598610353656
Trained batch 200 in epoch 11, gen_loss = 0.3918848426187809, disc_loss = 0.07553098608498734
Trained batch 201 in epoch 11, gen_loss = 0.39241950317184526, disc_loss = 0.07524939663454631
Trained batch 202 in epoch 11, gen_loss = 0.3918203577913087, disc_loss = 0.07497331308398231
Trained batch 203 in epoch 11, gen_loss = 0.39144648144058153, disc_loss = 0.07478470345342751
Trained batch 204 in epoch 11, gen_loss = 0.3912947833538055, disc_loss = 0.07486561930329516
Trained batch 205 in epoch 11, gen_loss = 0.3912478183369035, disc_loss = 0.07661042341768054
Trained batch 206 in epoch 11, gen_loss = 0.39100955102754675, disc_loss = 0.07647215318641117
Trained batch 207 in epoch 11, gen_loss = 0.3911309210726848, disc_loss = 0.0768207775780376
Trained batch 208 in epoch 11, gen_loss = 0.3911567123597889, disc_loss = 0.0765062666968242
Trained batch 209 in epoch 11, gen_loss = 0.3911328608081454, disc_loss = 0.07617922267943089
Trained batch 210 in epoch 11, gen_loss = 0.39133516914471633, disc_loss = 0.07590478390865735
Trained batch 211 in epoch 11, gen_loss = 0.3917352243695619, disc_loss = 0.07557988766128337
Trained batch 212 in epoch 11, gen_loss = 0.39189600748635234, disc_loss = 0.07524304899841792
Trained batch 213 in epoch 11, gen_loss = 0.3919539182821167, disc_loss = 0.07491522654564615
Trained batch 214 in epoch 11, gen_loss = 0.3919737564962964, disc_loss = 0.07458421402654156
Trained batch 215 in epoch 11, gen_loss = 0.39202290400862694, disc_loss = 0.07430210406137458
Trained batch 216 in epoch 11, gen_loss = 0.3922021719991886, disc_loss = 0.07399327122640671
Trained batch 217 in epoch 11, gen_loss = 0.3925198423206259, disc_loss = 0.07368910622915441
Trained batch 218 in epoch 11, gen_loss = 0.3920842443154827, disc_loss = 0.07338477932363238
Trained batch 219 in epoch 11, gen_loss = 0.39213332046161997, disc_loss = 0.07307910376588221
Trained batch 220 in epoch 11, gen_loss = 0.39207440857434167, disc_loss = 0.07281158903794895
Trained batch 221 in epoch 11, gen_loss = 0.39209405312667023, disc_loss = 0.07250377706038086
Trained batch 222 in epoch 11, gen_loss = 0.3920759137703164, disc_loss = 0.07240400878365899
Trained batch 223 in epoch 11, gen_loss = 0.3921906542299049, disc_loss = 0.07213619511769918
Trained batch 224 in epoch 11, gen_loss = 0.39236717210875616, disc_loss = 0.07199361773725185
Trained batch 225 in epoch 11, gen_loss = 0.3921699390738411, disc_loss = 0.07184179001013888
Trained batch 226 in epoch 11, gen_loss = 0.3927943327090814, disc_loss = 0.07177851000279681
Trained batch 227 in epoch 11, gen_loss = 0.39248854849945036, disc_loss = 0.0718512692511196
Trained batch 228 in epoch 11, gen_loss = 0.3923604471454454, disc_loss = 0.07242312727142207
Trained batch 229 in epoch 11, gen_loss = 0.3921589716621067, disc_loss = 0.07229605222262604
Trained batch 230 in epoch 11, gen_loss = 0.3920190476235889, disc_loss = 0.0720414781844187
Trained batch 231 in epoch 11, gen_loss = 0.39192650646998967, disc_loss = 0.07186459596489621
Trained batch 232 in epoch 11, gen_loss = 0.39201814601349727, disc_loss = 0.07160408569743673
Trained batch 233 in epoch 11, gen_loss = 0.3921965840790007, disc_loss = 0.07132995375889775
Trained batch 234 in epoch 11, gen_loss = 0.39193652931680073, disc_loss = 0.0711257083668433
Trained batch 235 in epoch 11, gen_loss = 0.39236619487657387, disc_loss = 0.07091570721832656
Trained batch 236 in epoch 11, gen_loss = 0.39257603921467743, disc_loss = 0.07064489458043144
Trained batch 237 in epoch 11, gen_loss = 0.39332140205788013, disc_loss = 0.07043244051570934
Trained batch 238 in epoch 11, gen_loss = 0.39346109187253847, disc_loss = 0.07016959945499804
Trained batch 239 in epoch 11, gen_loss = 0.39359648351867993, disc_loss = 0.06994452113382674
Trained batch 240 in epoch 11, gen_loss = 0.3937481708546397, disc_loss = 0.069699946057662
Trained batch 241 in epoch 11, gen_loss = 0.3934988766169745, disc_loss = 0.06943614831798486
Trained batch 242 in epoch 11, gen_loss = 0.39351180220337073, disc_loss = 0.0693242488890779
Trained batch 243 in epoch 11, gen_loss = 0.3930987975880748, disc_loss = 0.07021531893310641
Trained batch 244 in epoch 11, gen_loss = 0.39340616586257, disc_loss = 0.07133113757174994
Trained batch 245 in epoch 11, gen_loss = 0.3938282640968881, disc_loss = 0.07114537066412802
Trained batch 246 in epoch 11, gen_loss = 0.39360922297485446, disc_loss = 0.07095732957761931
Trained batch 247 in epoch 11, gen_loss = 0.39363640546798706, disc_loss = 0.07079947068479904
Trained batch 248 in epoch 11, gen_loss = 0.3936839463959736, disc_loss = 0.07054415743622226
Trained batch 249 in epoch 11, gen_loss = 0.393546226978302, disc_loss = 0.07027401975635439
Trained batch 250 in epoch 11, gen_loss = 0.39351452726766883, disc_loss = 0.0700171540326168
Trained batch 251 in epoch 11, gen_loss = 0.39325556135366835, disc_loss = 0.06977380032462645
Trained batch 252 in epoch 11, gen_loss = 0.3932629757719078, disc_loss = 0.06978934833305067
Trained batch 253 in epoch 11, gen_loss = 0.393526899298345, disc_loss = 0.06965535747961647
Trained batch 254 in epoch 11, gen_loss = 0.3934175222527747, disc_loss = 0.06959551874566458
Trained batch 255 in epoch 11, gen_loss = 0.3933444165159017, disc_loss = 0.07057644785618322
Trained batch 256 in epoch 11, gen_loss = 0.39342918609366806, disc_loss = 0.07062846567963725
Trained batch 257 in epoch 11, gen_loss = 0.39336372034032213, disc_loss = 0.0709197366503681
Trained batch 258 in epoch 11, gen_loss = 0.39356736522383673, disc_loss = 0.07106834110034392
Trained batch 259 in epoch 11, gen_loss = 0.39366944948068033, disc_loss = 0.07107323666837496
Trained batch 260 in epoch 11, gen_loss = 0.39372059154784544, disc_loss = 0.07127266397995881
Trained batch 261 in epoch 11, gen_loss = 0.39410518792294363, disc_loss = 0.07105303367774024
Trained batch 262 in epoch 11, gen_loss = 0.39416298338215616, disc_loss = 0.07083615461743291
Trained batch 263 in epoch 11, gen_loss = 0.39424801606572035, disc_loss = 0.0706020744109992
Trained batch 264 in epoch 11, gen_loss = 0.3946934327764331, disc_loss = 0.07037415805026748
Trained batch 265 in epoch 11, gen_loss = 0.39472889575294984, disc_loss = 0.07012452478468054
Trained batch 266 in epoch 11, gen_loss = 0.3947674084022251, disc_loss = 0.06989879276837163
Trained batch 267 in epoch 11, gen_loss = 0.3950846882453605, disc_loss = 0.06965939197324411
Trained batch 268 in epoch 11, gen_loss = 0.3954930708754018, disc_loss = 0.06942591852799307
Trained batch 269 in epoch 11, gen_loss = 0.3957140917027438, disc_loss = 0.069201343764413
Trained batch 270 in epoch 11, gen_loss = 0.39553560717959246, disc_loss = 0.06966527192200435
Trained batch 271 in epoch 11, gen_loss = 0.39610862622366233, disc_loss = 0.07068220488573014
Trained batch 272 in epoch 11, gen_loss = 0.39617351505345916, disc_loss = 0.07090326795276022
Trained batch 273 in epoch 11, gen_loss = 0.3960322401601903, disc_loss = 0.07111944618080844
Trained batch 274 in epoch 11, gen_loss = 0.39596485994078895, disc_loss = 0.0710873820929026
Trained batch 275 in epoch 11, gen_loss = 0.3958221901802049, disc_loss = 0.07089750620830075
Trained batch 276 in epoch 11, gen_loss = 0.395700252551034, disc_loss = 0.07070214319083208
Trained batch 277 in epoch 11, gen_loss = 0.3957307672114681, disc_loss = 0.07047747435942694
Trained batch 278 in epoch 11, gen_loss = 0.3957052153925742, disc_loss = 0.0702432113521028
Trained batch 279 in epoch 11, gen_loss = 0.3956351942249707, disc_loss = 0.07001152012214464
Trained batch 280 in epoch 11, gen_loss = 0.3956011201775371, disc_loss = 0.0699504278757646
Trained batch 281 in epoch 11, gen_loss = 0.39558526630519975, disc_loss = 0.07031239986878735
Trained batch 282 in epoch 11, gen_loss = 0.3956231030474282, disc_loss = 0.07115916444676477
Trained batch 283 in epoch 11, gen_loss = 0.39547666844347834, disc_loss = 0.07099944792776434
Trained batch 284 in epoch 11, gen_loss = 0.39537278194176523, disc_loss = 0.0710899250704403
Trained batch 285 in epoch 11, gen_loss = 0.39528933615534456, disc_loss = 0.07107128035130592
Trained batch 286 in epoch 11, gen_loss = 0.39556202552044434, disc_loss = 0.07124254843690643
Trained batch 287 in epoch 11, gen_loss = 0.39542691978729433, disc_loss = 0.07132755948421415
Trained batch 288 in epoch 11, gen_loss = 0.3953031492274525, disc_loss = 0.07116906677056942
Trained batch 289 in epoch 11, gen_loss = 0.395293586829613, disc_loss = 0.07096656846958373
Trained batch 290 in epoch 11, gen_loss = 0.39547714928990785, disc_loss = 0.07075167685679938
Trained batch 291 in epoch 11, gen_loss = 0.39539072815686055, disc_loss = 0.07052689853797296
Trained batch 292 in epoch 11, gen_loss = 0.3955237203287183, disc_loss = 0.07029683443037443
Trained batch 293 in epoch 11, gen_loss = 0.395461441505523, disc_loss = 0.07006873064563565
Trained batch 294 in epoch 11, gen_loss = 0.3954858781927723, disc_loss = 0.06984654539580441
Trained batch 295 in epoch 11, gen_loss = 0.39542611134616107, disc_loss = 0.06962773294858257
Trained batch 296 in epoch 11, gen_loss = 0.39512694795123654, disc_loss = 0.06942980539332762
Trained batch 297 in epoch 11, gen_loss = 0.3950757962345277, disc_loss = 0.06925952451806766
Trained batch 298 in epoch 11, gen_loss = 0.39500535630860856, disc_loss = 0.06904251458057915
Trained batch 299 in epoch 11, gen_loss = 0.3947764115532239, disc_loss = 0.06898430031491444
Trained batch 300 in epoch 11, gen_loss = 0.39470007976028215, disc_loss = 0.0687862011794298
Trained batch 301 in epoch 11, gen_loss = 0.3947548462657739, disc_loss = 0.06860484298556081
Trained batch 302 in epoch 11, gen_loss = 0.3949751310025898, disc_loss = 0.06855658158773661
Trained batch 303 in epoch 11, gen_loss = 0.39469308435524764, disc_loss = 0.06840386012290285
Trained batch 304 in epoch 11, gen_loss = 0.394664525106305, disc_loss = 0.06824809102509476
Trained batch 305 in epoch 11, gen_loss = 0.39467254816706665, disc_loss = 0.06818055574328706
Trained batch 306 in epoch 11, gen_loss = 0.3946472098656508, disc_loss = 0.06800159559348531
Trained batch 307 in epoch 11, gen_loss = 0.3945247142926439, disc_loss = 0.06781851451060819
Trained batch 308 in epoch 11, gen_loss = 0.3945513629990488, disc_loss = 0.06771128775753853
Trained batch 309 in epoch 11, gen_loss = 0.3947317805982405, disc_loss = 0.06809169654058472
Trained batch 310 in epoch 11, gen_loss = 0.39478849176425257, disc_loss = 0.06793576055895117
Trained batch 311 in epoch 11, gen_loss = 0.39442004817418563, disc_loss = 0.0678684586899367
Trained batch 312 in epoch 11, gen_loss = 0.3944863192380046, disc_loss = 0.06767362082219376
Trained batch 313 in epoch 11, gen_loss = 0.3947010031741136, disc_loss = 0.06751638609740979
Trained batch 314 in epoch 11, gen_loss = 0.39465220381343175, disc_loss = 0.06731959199163294
Trained batch 315 in epoch 11, gen_loss = 0.39459586039751393, disc_loss = 0.06716416370421294
Trained batch 316 in epoch 11, gen_loss = 0.3946137207351649, disc_loss = 0.06699504177174193
Trained batch 317 in epoch 11, gen_loss = 0.39458630613560947, disc_loss = 0.06682261993959195
Trained batch 318 in epoch 11, gen_loss = 0.39460347195777773, disc_loss = 0.06669983652648064
Trained batch 319 in epoch 11, gen_loss = 0.3946672312915325, disc_loss = 0.06678942255166476
Trained batch 320 in epoch 11, gen_loss = 0.39461999119627883, disc_loss = 0.06698914957987115
Trained batch 321 in epoch 11, gen_loss = 0.3945191902403506, disc_loss = 0.06689591004197942
Trained batch 322 in epoch 11, gen_loss = 0.3943890335021004, disc_loss = 0.06670365056481455
Trained batch 323 in epoch 11, gen_loss = 0.3945075120822883, disc_loss = 0.06651369077627789
Trained batch 324 in epoch 11, gen_loss = 0.39460947990417483, disc_loss = 0.0663239597564993
Trained batch 325 in epoch 11, gen_loss = 0.3944147402889158, disc_loss = 0.06632872723240085
Trained batch 326 in epoch 11, gen_loss = 0.3947089602458732, disc_loss = 0.06698685959451448
Trained batch 327 in epoch 11, gen_loss = 0.39476728593794314, disc_loss = 0.06689927405351205
Trained batch 328 in epoch 11, gen_loss = 0.3949431898383746, disc_loss = 0.06677305386231867
Trained batch 329 in epoch 11, gen_loss = 0.3950099339087804, disc_loss = 0.06661573938644406
Trained batch 330 in epoch 11, gen_loss = 0.39526065418727446, disc_loss = 0.0664466554306031
Trained batch 331 in epoch 11, gen_loss = 0.395186028028109, disc_loss = 0.0662763071399328
Trained batch 332 in epoch 11, gen_loss = 0.39493829888982457, disc_loss = 0.06614030327147304
Trained batch 333 in epoch 11, gen_loss = 0.39512681648759784, disc_loss = 0.06620898994569761
Trained batch 334 in epoch 11, gen_loss = 0.3946022184927072, disc_loss = 0.06650964497699778
Trained batch 335 in epoch 11, gen_loss = 0.3948263381386087, disc_loss = 0.06638342676021802
Trained batch 336 in epoch 11, gen_loss = 0.3952436929109896, disc_loss = 0.06626327653161253
Trained batch 337 in epoch 11, gen_loss = 0.3954904972625202, disc_loss = 0.06612344503956544
Trained batch 338 in epoch 11, gen_loss = 0.39564155969647885, disc_loss = 0.06594096180010356
Trained batch 339 in epoch 11, gen_loss = 0.3958076598013149, disc_loss = 0.0658285105963895
Trained batch 340 in epoch 11, gen_loss = 0.3958741794408591, disc_loss = 0.06565027713674582
Trained batch 341 in epoch 11, gen_loss = 0.39598052665504097, disc_loss = 0.06549225868698079
Trained batch 342 in epoch 11, gen_loss = 0.3959579843995175, disc_loss = 0.06531691021128468
Trained batch 343 in epoch 11, gen_loss = 0.3960219562746758, disc_loss = 0.06514663319847937
Trained batch 344 in epoch 11, gen_loss = 0.39632169103276904, disc_loss = 0.06496837645485673
Trained batch 345 in epoch 11, gen_loss = 0.3963377332756285, disc_loss = 0.06479295684668004
Trained batch 346 in epoch 11, gen_loss = 0.39642594372504725, disc_loss = 0.06462000938929531
Trained batch 347 in epoch 11, gen_loss = 0.3965164215742857, disc_loss = 0.06446754901292573
Trained batch 348 in epoch 11, gen_loss = 0.3963448068815521, disc_loss = 0.06431655138984514
Trained batch 349 in epoch 11, gen_loss = 0.39628643870353697, disc_loss = 0.06420510475058108
Trained batch 350 in epoch 11, gen_loss = 0.3962409805368494, disc_loss = 0.06404494117624378
Trained batch 351 in epoch 11, gen_loss = 0.3963409424336119, disc_loss = 0.0639015389467452
Trained batch 352 in epoch 11, gen_loss = 0.3962351554851694, disc_loss = 0.06385433324216931
Trained batch 353 in epoch 11, gen_loss = 0.3961832764121772, disc_loss = 0.06470427443970542
Trained batch 354 in epoch 11, gen_loss = 0.39627994030294283, disc_loss = 0.06457793983027443
Trained batch 355 in epoch 11, gen_loss = 0.3963794061976872, disc_loss = 0.06458305416490066
Trained batch 356 in epoch 11, gen_loss = 0.39630248132540064, disc_loss = 0.06453044523344133
Trained batch 357 in epoch 11, gen_loss = 0.3964554740729945, disc_loss = 0.06437383704706923
Trained batch 358 in epoch 11, gen_loss = 0.396374419373058, disc_loss = 0.06429059503789379
Trained batch 359 in epoch 11, gen_loss = 0.3962621590329541, disc_loss = 0.06433084494524842
Trained batch 360 in epoch 11, gen_loss = 0.39653019272719725, disc_loss = 0.0642015939530687
Trained batch 361 in epoch 11, gen_loss = 0.39664746047054206, disc_loss = 0.0640453737665184
Trained batch 362 in epoch 11, gen_loss = 0.39683092773453266, disc_loss = 0.06392309817706156
Trained batch 363 in epoch 11, gen_loss = 0.3968615308403969, disc_loss = 0.06382482970622112
Trained batch 364 in epoch 11, gen_loss = 0.39705670214679145, disc_loss = 0.06366278581410545
Trained batch 365 in epoch 11, gen_loss = 0.39703549786669307, disc_loss = 0.06349803982467946
Trained batch 366 in epoch 11, gen_loss = 0.39704457899855006, disc_loss = 0.06333493502691327
Trained batch 367 in epoch 11, gen_loss = 0.396972195447787, disc_loss = 0.06318983555779002
Trained batch 368 in epoch 11, gen_loss = 0.3970487068500622, disc_loss = 0.06311128299297174
Trained batch 369 in epoch 11, gen_loss = 0.39697802461482384, disc_loss = 0.06307696869936646
Trained batch 370 in epoch 11, gen_loss = 0.39690615425534004, disc_loss = 0.06300490232739306
Trained batch 371 in epoch 11, gen_loss = 0.39686627469716534, disc_loss = 0.06318136594716399
Trained batch 372 in epoch 11, gen_loss = 0.39719399410342404, disc_loss = 0.06404137908700784
Trained batch 373 in epoch 11, gen_loss = 0.39713679859663714, disc_loss = 0.06395025026080582
Trained batch 374 in epoch 11, gen_loss = 0.39718269379933674, disc_loss = 0.06391846270052096
Trained batch 375 in epoch 11, gen_loss = 0.39715086280348455, disc_loss = 0.06377730612888279
Trained batch 376 in epoch 11, gen_loss = 0.3971545350014057, disc_loss = 0.06362457286297228
Trained batch 377 in epoch 11, gen_loss = 0.3971105518322142, disc_loss = 0.06353626623885243
Trained batch 378 in epoch 11, gen_loss = 0.3969047984064097, disc_loss = 0.06346643629537939
Trained batch 379 in epoch 11, gen_loss = 0.39713597783916876, disc_loss = 0.06333506363627844
Trained batch 380 in epoch 11, gen_loss = 0.39707432378308355, disc_loss = 0.06323387783223622
Trained batch 381 in epoch 11, gen_loss = 0.39689333822714723, disc_loss = 0.06314653282953397
Trained batch 382 in epoch 11, gen_loss = 0.3969687334706827, disc_loss = 0.06303306507474352
Trained batch 383 in epoch 11, gen_loss = 0.3970674885592113, disc_loss = 0.06315665327262347
Trained batch 384 in epoch 11, gen_loss = 0.396992278950555, disc_loss = 0.06316722201776098
Trained batch 385 in epoch 11, gen_loss = 0.3969451321839051, disc_loss = 0.06302351075516521
Trained batch 386 in epoch 11, gen_loss = 0.3974605421379247, disc_loss = 0.06291401758248549
Trained batch 387 in epoch 11, gen_loss = 0.3974845687445906, disc_loss = 0.062781943406156
Trained batch 388 in epoch 11, gen_loss = 0.3975269093458328, disc_loss = 0.06266539575888806
Trained batch 389 in epoch 11, gen_loss = 0.3975870802616462, disc_loss = 0.06255380200305714
Trained batch 390 in epoch 11, gen_loss = 0.3975821767774079, disc_loss = 0.0624176516689484
Trained batch 391 in epoch 11, gen_loss = 0.3975051857379018, disc_loss = 0.06227959300170424
Trained batch 392 in epoch 11, gen_loss = 0.39748480832607086, disc_loss = 0.0621355074705466
Trained batch 393 in epoch 11, gen_loss = 0.3974750942838979, disc_loss = 0.062008658917455314
Trained batch 394 in epoch 11, gen_loss = 0.39766726614553716, disc_loss = 0.062022324445763534
Trained batch 395 in epoch 11, gen_loss = 0.3976499790495092, disc_loss = 0.0622409813857468
Trained batch 396 in epoch 11, gen_loss = 0.39789856823926006, disc_loss = 0.06215388832381582
Trained batch 397 in epoch 11, gen_loss = 0.3978198684340146, disc_loss = 0.06248122045299946
Trained batch 398 in epoch 11, gen_loss = 0.39761881421980705, disc_loss = 0.06269552870210082
Trained batch 399 in epoch 11, gen_loss = 0.39737969644367693, disc_loss = 0.06281241262040567
Trained batch 400 in epoch 11, gen_loss = 0.3974407082632593, disc_loss = 0.06268055367915243
Trained batch 401 in epoch 11, gen_loss = 0.39771781861782074, disc_loss = 0.06270496879613945
Trained batch 402 in epoch 11, gen_loss = 0.3977776360570941, disc_loss = 0.06258923830938232
Trained batch 403 in epoch 11, gen_loss = 0.3978260499563548, disc_loss = 0.06253478333692869
Trained batch 404 in epoch 11, gen_loss = 0.3978885852996214, disc_loss = 0.06242511807480988
Trained batch 405 in epoch 11, gen_loss = 0.39789633240018574, disc_loss = 0.06231667037784888
Trained batch 406 in epoch 11, gen_loss = 0.3977329375849309, disc_loss = 0.06220395738288705
Trained batch 407 in epoch 11, gen_loss = 0.3978025065917595, disc_loss = 0.06214004123809419
Trained batch 408 in epoch 11, gen_loss = 0.3977474726936928, disc_loss = 0.06206409212072041
Trained batch 409 in epoch 11, gen_loss = 0.39766291481692617, disc_loss = 0.061928023636999834
Trained batch 410 in epoch 11, gen_loss = 0.39747631948649736, disc_loss = 0.06201803766093568
Trained batch 411 in epoch 11, gen_loss = 0.3977837095995551, disc_loss = 0.06284498013115207
Trained batch 412 in epoch 11, gen_loss = 0.3977387872937228, disc_loss = 0.06312394512255765
Trained batch 413 in epoch 11, gen_loss = 0.39760268886308164, disc_loss = 0.06329508818931212
Trained batch 414 in epoch 11, gen_loss = 0.39730350159737, disc_loss = 0.06322372618849467
Trained batch 415 in epoch 11, gen_loss = 0.39738328074320006, disc_loss = 0.06325303561047455
Trained batch 416 in epoch 11, gen_loss = 0.39731386761299425, disc_loss = 0.06323197335998663
Trained batch 417 in epoch 11, gen_loss = 0.3972860013611579, disc_loss = 0.06313022206766915
Trained batch 418 in epoch 11, gen_loss = 0.39740567602804, disc_loss = 0.06307018660553475
Trained batch 419 in epoch 11, gen_loss = 0.3971754830508005, disc_loss = 0.06302506434343134
Trained batch 420 in epoch 11, gen_loss = 0.39724862872846334, disc_loss = 0.06298347114200423
Trained batch 421 in epoch 11, gen_loss = 0.3971497176382779, disc_loss = 0.06294564157117476
Trained batch 422 in epoch 11, gen_loss = 0.39691245915196466, disc_loss = 0.0635230399907102
Trained batch 423 in epoch 11, gen_loss = 0.3970996279902053, disc_loss = 0.06385271134621569
Trained batch 424 in epoch 11, gen_loss = 0.39706056237220766, disc_loss = 0.06389750255655278
Trained batch 425 in epoch 11, gen_loss = 0.39679151311726635, disc_loss = 0.06394233513774324
Trained batch 426 in epoch 11, gen_loss = 0.39668429351522994, disc_loss = 0.06384553893172647
Trained batch 427 in epoch 11, gen_loss = 0.3967120882088893, disc_loss = 0.06371168517039776
Trained batch 428 in epoch 11, gen_loss = 0.3968445600329579, disc_loss = 0.06358203637556961
Trained batch 429 in epoch 11, gen_loss = 0.3969036852204522, disc_loss = 0.06345854859290168
Trained batch 430 in epoch 11, gen_loss = 0.3968889515527163, disc_loss = 0.06335019484311429
Trained batch 431 in epoch 11, gen_loss = 0.39679002451399964, disc_loss = 0.0632399188347066
Trained batch 432 in epoch 11, gen_loss = 0.3968625889777036, disc_loss = 0.06313853880216305
Trained batch 433 in epoch 11, gen_loss = 0.396688593766107, disc_loss = 0.06338468828176316
Trained batch 434 in epoch 11, gen_loss = 0.39640106106626577, disc_loss = 0.06430490033048065
Trained batch 435 in epoch 11, gen_loss = 0.3961952690957883, disc_loss = 0.0647295155896754
Trained batch 436 in epoch 11, gen_loss = 0.396367633506417, disc_loss = 0.06489040764651817
Trained batch 437 in epoch 11, gen_loss = 0.39610935210092973, disc_loss = 0.06512594541809075
Trained batch 438 in epoch 11, gen_loss = 0.3960105718404123, disc_loss = 0.06524862129090604
Trained batch 439 in epoch 11, gen_loss = 0.39599415761503304, disc_loss = 0.06531643986712549
Trained batch 440 in epoch 11, gen_loss = 0.39571855485844776, disc_loss = 0.06538314291892695
Trained batch 441 in epoch 11, gen_loss = 0.3956261853017419, disc_loss = 0.06532175015348402
Trained batch 442 in epoch 11, gen_loss = 0.39561342493406, disc_loss = 0.06532657993105966
Trained batch 443 in epoch 11, gen_loss = 0.39541428992608646, disc_loss = 0.06539457854196043
Trained batch 444 in epoch 11, gen_loss = 0.39561571639575316, disc_loss = 0.06529728246047005
Trained batch 445 in epoch 11, gen_loss = 0.39565619685992, disc_loss = 0.06517450705707291
Trained batch 446 in epoch 11, gen_loss = 0.39564040196555306, disc_loss = 0.06527818784886509
Trained batch 447 in epoch 11, gen_loss = 0.3953166620007583, disc_loss = 0.065639928570038
Trained batch 448 in epoch 11, gen_loss = 0.3953256457048429, disc_loss = 0.06553046100042793
Trained batch 449 in epoch 11, gen_loss = 0.39548017329639856, disc_loss = 0.06575169427579061
Trained batch 450 in epoch 11, gen_loss = 0.3954820574122892, disc_loss = 0.06581026286004471
Trained batch 451 in epoch 11, gen_loss = 0.3953662829852737, disc_loss = 0.06577268107722109
Trained batch 452 in epoch 11, gen_loss = 0.3954087680012448, disc_loss = 0.06573578237584704
Trained batch 453 in epoch 11, gen_loss = 0.3954717611426299, disc_loss = 0.06561031586455698
Trained batch 454 in epoch 11, gen_loss = 0.3954831245836321, disc_loss = 0.06547625648052237
Trained batch 455 in epoch 11, gen_loss = 0.3954507346477425, disc_loss = 0.0653535545882238
Trained batch 456 in epoch 11, gen_loss = 0.3953679535921084, disc_loss = 0.065224341140791
Trained batch 457 in epoch 11, gen_loss = 0.39547018745840895, disc_loss = 0.06511529387172116
Trained batch 458 in epoch 11, gen_loss = 0.3954680737976415, disc_loss = 0.06499322371867795
Trained batch 459 in epoch 11, gen_loss = 0.39549102873905845, disc_loss = 0.06488516035479615
Trained batch 460 in epoch 11, gen_loss = 0.39546932186325306, disc_loss = 0.06481566577856863
Testing Epoch 11
Training Epoch 12
Trained batch 0 in epoch 12, gen_loss = 0.4000028669834137, disc_loss = 0.1441202163696289
Trained batch 1 in epoch 12, gen_loss = 0.3808325380086899, disc_loss = 0.08779895305633545
Trained batch 2 in epoch 12, gen_loss = 0.4012659688790639, disc_loss = 0.08892776568730672
Trained batch 3 in epoch 12, gen_loss = 0.3935363069176674, disc_loss = 0.07534425053745508
Trained batch 4 in epoch 12, gen_loss = 0.38229665756225584, disc_loss = 0.08648418560624123
Trained batch 5 in epoch 12, gen_loss = 0.3947560787200928, disc_loss = 0.0863458023717006
Trained batch 6 in epoch 12, gen_loss = 0.40576653821127756, disc_loss = 0.07465238410181232
Trained batch 7 in epoch 12, gen_loss = 0.40527332574129105, disc_loss = 0.06619212630903348
Trained batch 8 in epoch 12, gen_loss = 0.3957643475797441, disc_loss = 0.060972572976930275
Trained batch 9 in epoch 12, gen_loss = 0.3961331307888031, disc_loss = 0.05638137380592525
Trained batch 10 in epoch 12, gen_loss = 0.39281955090436066, disc_loss = 0.05756928835233504
Trained batch 11 in epoch 12, gen_loss = 0.40305427213509876, disc_loss = 0.056174550166664027
Trained batch 12 in epoch 12, gen_loss = 0.40529515880804795, disc_loss = 0.05250827276792664
Trained batch 13 in epoch 12, gen_loss = 0.40605110994407106, disc_loss = 0.04925283892745418
Trained batch 14 in epoch 12, gen_loss = 0.40099032322565714, disc_loss = 0.04697348000481725
Trained batch 15 in epoch 12, gen_loss = 0.3985284324735403, disc_loss = 0.048290717153577134
Trained batch 16 in epoch 12, gen_loss = 0.40226149734328775, disc_loss = 0.04622782802428393
Trained batch 17 in epoch 12, gen_loss = 0.40217749774456024, disc_loss = 0.05140406754799187
Trained batch 18 in epoch 12, gen_loss = 0.3991353213787079, disc_loss = 0.050101540124926125
Trained batch 19 in epoch 12, gen_loss = 0.3978100404143333, disc_loss = 0.05444872335065156
Trained batch 20 in epoch 12, gen_loss = 0.40256665576071965, disc_loss = 0.05300755836513071
Trained batch 21 in epoch 12, gen_loss = 0.405545635656877, disc_loss = 0.05242723855189979
Trained batch 22 in epoch 12, gen_loss = 0.40713454070298566, disc_loss = 0.05039732018485665
Trained batch 23 in epoch 12, gen_loss = 0.40667007118463516, disc_loss = 0.048505526986749224
Trained batch 24 in epoch 12, gen_loss = 0.4049300503730774, disc_loss = 0.046845658738166096
Trained batch 25 in epoch 12, gen_loss = 0.4055888389165585, disc_loss = 0.045264562215799324
Trained batch 26 in epoch 12, gen_loss = 0.4047089770988182, disc_loss = 0.04394482885038963
Trained batch 27 in epoch 12, gen_loss = 0.4029010257550648, disc_loss = 0.04259831904034529
Trained batch 28 in epoch 12, gen_loss = 0.4020006029770292, disc_loss = 0.04175630308173854
Trained batch 29 in epoch 12, gen_loss = 0.40210319459438326, disc_loss = 0.04064754607776801
Trained batch 30 in epoch 12, gen_loss = 0.4025379592372525, disc_loss = 0.039711160104601614
Trained batch 31 in epoch 12, gen_loss = 0.4038798473775387, disc_loss = 0.03911303717177361
Trained batch 32 in epoch 12, gen_loss = 0.404426811319409, disc_loss = 0.03813831542025913
Trained batch 33 in epoch 12, gen_loss = 0.4018157229704015, disc_loss = 0.03865497756530257
Trained batch 34 in epoch 12, gen_loss = 0.40260180916105, disc_loss = 0.03817593077463763
Trained batch 35 in epoch 12, gen_loss = 0.4036395152409871, disc_loss = 0.03817702876403928
Trained batch 36 in epoch 12, gen_loss = 0.4064866739350396, disc_loss = 0.037443191442336585
Trained batch 37 in epoch 12, gen_loss = 0.4073943676132905, disc_loss = 0.03668300699638693
Trained batch 38 in epoch 12, gen_loss = 0.4052836772723076, disc_loss = 0.03602828309895136
Trained batch 39 in epoch 12, gen_loss = 0.4049163445830345, disc_loss = 0.03901216643862426
Trained batch 40 in epoch 12, gen_loss = 0.40570891048850083, disc_loss = 0.04022989272162682
Trained batch 41 in epoch 12, gen_loss = 0.40572941587084815, disc_loss = 0.03959796027768226
Trained batch 42 in epoch 12, gen_loss = 0.406554916570353, disc_loss = 0.038852544144055874
Trained batch 43 in epoch 12, gen_loss = 0.40543802692131564, disc_loss = 0.038090978897261346
Trained batch 44 in epoch 12, gen_loss = 0.4047396229373084, disc_loss = 0.03735172509526213
Trained batch 45 in epoch 12, gen_loss = 0.402838167289029, disc_loss = 0.03712076269616575
Trained batch 46 in epoch 12, gen_loss = 0.402894451897195, disc_loss = 0.03656726105614228
Trained batch 47 in epoch 12, gen_loss = 0.40234596220155555, disc_loss = 0.03586801818649595
Trained batch 48 in epoch 12, gen_loss = 0.4035936709569425, disc_loss = 0.0353031812463792
Trained batch 49 in epoch 12, gen_loss = 0.4024406999349594, disc_loss = 0.034672647109255196
Trained batch 50 in epoch 12, gen_loss = 0.4029112230328953, disc_loss = 0.03426607357630251
Trained batch 51 in epoch 12, gen_loss = 0.40353714846647704, disc_loss = 0.033742631310955264
Trained batch 52 in epoch 12, gen_loss = 0.402606911254379, disc_loss = 0.03322022789562086
Trained batch 53 in epoch 12, gen_loss = 0.40135665734608966, disc_loss = 0.032670217747282654
Trained batch 54 in epoch 12, gen_loss = 0.3999560534954071, disc_loss = 0.03233906275338747
Trained batch 55 in epoch 12, gen_loss = 0.4003375417419842, disc_loss = 0.03194738682525765
Trained batch 56 in epoch 12, gen_loss = 0.40098300367070916, disc_loss = 0.031923244699116865
Trained batch 57 in epoch 12, gen_loss = 0.40070059021999094, disc_loss = 0.03174391119933591
Trained batch 58 in epoch 12, gen_loss = 0.40074437351550085, disc_loss = 0.031544407458691776
Trained batch 59 in epoch 12, gen_loss = 0.3997704063852628, disc_loss = 0.03164895714726299
Trained batch 60 in epoch 12, gen_loss = 0.4011591257619076, disc_loss = 0.03145115047723788
Trained batch 61 in epoch 12, gen_loss = 0.40126891866807013, disc_loss = 0.031249320712841807
Trained batch 62 in epoch 12, gen_loss = 0.40071650393425473, disc_loss = 0.0323011216796225
Trained batch 63 in epoch 12, gen_loss = 0.4009761866182089, disc_loss = 0.032416780515632126
Trained batch 64 in epoch 12, gen_loss = 0.4011456379523644, disc_loss = 0.03208791582773511
Trained batch 65 in epoch 12, gen_loss = 0.40082312217264465, disc_loss = 0.0322770255998793
Trained batch 66 in epoch 12, gen_loss = 0.40169990418562246, disc_loss = 0.031916118025390516
Trained batch 67 in epoch 12, gen_loss = 0.401516615467913, disc_loss = 0.03160995946895769
Trained batch 68 in epoch 12, gen_loss = 0.4011958306250365, disc_loss = 0.031326447795752596
Trained batch 69 in epoch 12, gen_loss = 0.40046949982643126, disc_loss = 0.03104962725857539
Trained batch 70 in epoch 12, gen_loss = 0.40015233990172266, disc_loss = 0.030774337482232024
Trained batch 71 in epoch 12, gen_loss = 0.4006783167521159, disc_loss = 0.030456271986218378
Trained batch 72 in epoch 12, gen_loss = 0.3999607167015337, disc_loss = 0.03033822961789492
Trained batch 73 in epoch 12, gen_loss = 0.40022584071030487, disc_loss = 0.03003203763777541
Trained batch 74 in epoch 12, gen_loss = 0.39929901242256166, disc_loss = 0.02969879892965158
Trained batch 75 in epoch 12, gen_loss = 0.39807476809150294, disc_loss = 0.02997471752429479
Trained batch 76 in epoch 12, gen_loss = 0.4004755267849216, disc_loss = 0.03319510979602089
Trained batch 77 in epoch 12, gen_loss = 0.39984386968307006, disc_loss = 0.03432405460625887
Trained batch 78 in epoch 12, gen_loss = 0.3991818424267105, disc_loss = 0.035353275581817084
Trained batch 79 in epoch 12, gen_loss = 0.3994159195572138, disc_loss = 0.03547498208936304
Trained batch 80 in epoch 12, gen_loss = 0.40013293241277154, disc_loss = 0.035174207014526115
Trained batch 81 in epoch 12, gen_loss = 0.40041706838258884, disc_loss = 0.035325762758985524
Trained batch 82 in epoch 12, gen_loss = 0.4003053235720439, disc_loss = 0.03545761428189924
Trained batch 83 in epoch 12, gen_loss = 0.39988807979084195, disc_loss = 0.03519122580820251
Trained batch 84 in epoch 12, gen_loss = 0.3995145121041466, disc_loss = 0.034988659653155244
Trained batch 85 in epoch 12, gen_loss = 0.39913903488669283, disc_loss = 0.03564862676268054
Trained batch 86 in epoch 12, gen_loss = 0.3994350142177494, disc_loss = 0.040757993974819266
Trained batch 87 in epoch 12, gen_loss = 0.39919335124167526, disc_loss = 0.04170943012418733
Trained batch 88 in epoch 12, gen_loss = 0.3987674753317672, disc_loss = 0.042517992918997
Trained batch 89 in epoch 12, gen_loss = 0.3979452871614032, disc_loss = 0.04302811749900381
Trained batch 90 in epoch 12, gen_loss = 0.39741271635988257, disc_loss = 0.042966228705104234
Trained batch 91 in epoch 12, gen_loss = 0.39659388428149017, disc_loss = 0.042794831167987504
Trained batch 92 in epoch 12, gen_loss = 0.3970047011170336, disc_loss = 0.04241247815130058
Trained batch 93 in epoch 12, gen_loss = 0.3970706710155974, disc_loss = 0.04200838422501817
Trained batch 94 in epoch 12, gen_loss = 0.3974007349265249, disc_loss = 0.04160197165941722
Trained batch 95 in epoch 12, gen_loss = 0.3973423633724451, disc_loss = 0.041217805201692194
Trained batch 96 in epoch 12, gen_loss = 0.3970414817947702, disc_loss = 0.040839248908126784
Trained batch 97 in epoch 12, gen_loss = 0.39691730147721815, disc_loss = 0.040514815964603
Trained batch 98 in epoch 12, gen_loss = 0.3971011159997998, disc_loss = 0.040525851249130385
Trained batch 99 in epoch 12, gen_loss = 0.39671910911798475, disc_loss = 0.040787891768850386
Trained batch 100 in epoch 12, gen_loss = 0.39671599717423467, disc_loss = 0.04047167008410733
Trained batch 101 in epoch 12, gen_loss = 0.3970278098302729, disc_loss = 0.04023669569241796
Trained batch 102 in epoch 12, gen_loss = 0.39694452401503777, disc_loss = 0.040042542739436755
Trained batch 103 in epoch 12, gen_loss = 0.39634646446659016, disc_loss = 0.039817668699050464
Trained batch 104 in epoch 12, gen_loss = 0.39657492268653144, disc_loss = 0.03956340356685576
Trained batch 105 in epoch 12, gen_loss = 0.3968839105570091, disc_loss = 0.039452241562342026
Trained batch 106 in epoch 12, gen_loss = 0.3973982211585357, disc_loss = 0.03953437841819408
Trained batch 107 in epoch 12, gen_loss = 0.39714954876237446, disc_loss = 0.03928058447437016
Trained batch 108 in epoch 12, gen_loss = 0.397721334608323, disc_loss = 0.03950597282174394
Trained batch 109 in epoch 12, gen_loss = 0.39828264821659437, disc_loss = 0.039715583059428766
Trained batch 110 in epoch 12, gen_loss = 0.39806954522390625, disc_loss = 0.03951992691486134
Trained batch 111 in epoch 12, gen_loss = 0.39754896025572506, disc_loss = 0.04077605257459384
Trained batch 112 in epoch 12, gen_loss = 0.39811438664925836, disc_loss = 0.041729422858957435
Trained batch 113 in epoch 12, gen_loss = 0.39828150549478697, disc_loss = 0.04167946957035415
Trained batch 114 in epoch 12, gen_loss = 0.39777845196101974, disc_loss = 0.041500037370006675
Trained batch 115 in epoch 12, gen_loss = 0.3976330731449456, disc_loss = 0.04129658033669894
Trained batch 116 in epoch 12, gen_loss = 0.39770941347138494, disc_loss = 0.04103786218513408
Trained batch 117 in epoch 12, gen_loss = 0.3972673522213758, disc_loss = 0.04078876130456515
Trained batch 118 in epoch 12, gen_loss = 0.3968140755881782, disc_loss = 0.040683821966762054
Trained batch 119 in epoch 12, gen_loss = 0.39746957619984946, disc_loss = 0.040471433572626364
Trained batch 120 in epoch 12, gen_loss = 0.3971733820339865, disc_loss = 0.04029023041178988
Trained batch 121 in epoch 12, gen_loss = 0.39700311520060555, disc_loss = 0.04128177522406837
Trained batch 122 in epoch 12, gen_loss = 0.3963915906785949, disc_loss = 0.042681431961889435
Trained batch 123 in epoch 12, gen_loss = 0.39708946044406584, disc_loss = 0.044005233768163426
Trained batch 124 in epoch 12, gen_loss = 0.39718502974510195, disc_loss = 0.043735821027308705
Trained batch 125 in epoch 12, gen_loss = 0.3962322681669205, disc_loss = 0.045068340187537526
Trained batch 126 in epoch 12, gen_loss = 0.3969043871079843, disc_loss = 0.045970022579376386
Trained batch 127 in epoch 12, gen_loss = 0.39691181667149067, disc_loss = 0.046250999341282295
Trained batch 128 in epoch 12, gen_loss = 0.39679895722588826, disc_loss = 0.04634611723338102
Trained batch 129 in epoch 12, gen_loss = 0.3968899857539397, disc_loss = 0.046857647930916686
Trained batch 130 in epoch 12, gen_loss = 0.3969394446329306, disc_loss = 0.04778179889260471
Trained batch 131 in epoch 12, gen_loss = 0.3969713652675802, disc_loss = 0.0485935942587358
Trained batch 132 in epoch 12, gen_loss = 0.3965615060992707, disc_loss = 0.04877633309075819
Trained batch 133 in epoch 12, gen_loss = 0.39649711704965845, disc_loss = 0.05070918847445343
Trained batch 134 in epoch 12, gen_loss = 0.3960320068730248, disc_loss = 0.052966501139518285
Trained batch 135 in epoch 12, gen_loss = 0.396695186767508, disc_loss = 0.05331056991331827
Trained batch 136 in epoch 12, gen_loss = 0.3968491177924358, disc_loss = 0.05325611766740462
Trained batch 137 in epoch 12, gen_loss = 0.3962624168050462, disc_loss = 0.05348613614256939
Trained batch 138 in epoch 12, gen_loss = 0.39617290235251834, disc_loss = 0.053468567369465564
Trained batch 139 in epoch 12, gen_loss = 0.39657243958541327, disc_loss = 0.05366763886662999
Trained batch 140 in epoch 12, gen_loss = 0.3967327183865486, disc_loss = 0.0553052288955672
Trained batch 141 in epoch 12, gen_loss = 0.3967318765714135, disc_loss = 0.0550176483073967
Trained batch 142 in epoch 12, gen_loss = 0.3971850792844812, disc_loss = 0.0549002000768962
Trained batch 143 in epoch 12, gen_loss = 0.3967485243661536, disc_loss = 0.05475129059373608
Trained batch 144 in epoch 12, gen_loss = 0.39711589114419343, disc_loss = 0.05455343062058091
Trained batch 145 in epoch 12, gen_loss = 0.3971237987279892, disc_loss = 0.054223852579749814
Trained batch 146 in epoch 12, gen_loss = 0.39658958023908186, disc_loss = 0.05415384095402903
Trained batch 147 in epoch 12, gen_loss = 0.3963842716168713, disc_loss = 0.05414302321465535
Trained batch 148 in epoch 12, gen_loss = 0.39672958850860596, disc_loss = 0.053843655345348906
Trained batch 149 in epoch 12, gen_loss = 0.3958358778556188, disc_loss = 0.05462352802666525
Trained batch 150 in epoch 12, gen_loss = 0.3962448032091785, disc_loss = 0.055430003155072204
Trained batch 151 in epoch 12, gen_loss = 0.39646062019624206, disc_loss = 0.05520762476494143
Trained batch 152 in epoch 12, gen_loss = 0.3963610212397731, disc_loss = 0.05514649764689453
Trained batch 153 in epoch 12, gen_loss = 0.39651956051201015, disc_loss = 0.05518328536652609
Trained batch 154 in epoch 12, gen_loss = 0.39650514087369365, disc_loss = 0.0550394770388882
Trained batch 155 in epoch 12, gen_loss = 0.3967738411365411, disc_loss = 0.054792789016993575
Trained batch 156 in epoch 12, gen_loss = 0.3967545476688701, disc_loss = 0.0547888889629987
Trained batch 157 in epoch 12, gen_loss = 0.3967310756067686, disc_loss = 0.05562962010750382
Trained batch 158 in epoch 12, gen_loss = 0.39748960733413696, disc_loss = 0.05636308697468174
Trained batch 159 in epoch 12, gen_loss = 0.39768669810146096, disc_loss = 0.05613390923535917
Trained batch 160 in epoch 12, gen_loss = 0.39745969191101027, disc_loss = 0.055971293927095135
Trained batch 161 in epoch 12, gen_loss = 0.3973344349198871, disc_loss = 0.055732172514300474
Trained batch 162 in epoch 12, gen_loss = 0.39775809682220037, disc_loss = 0.05543571128081416
Trained batch 163 in epoch 12, gen_loss = 0.39755385459923165, disc_loss = 0.05515197942476356
Trained batch 164 in epoch 12, gen_loss = 0.3974355161190033, disc_loss = 0.0549197569235482
Trained batch 165 in epoch 12, gen_loss = 0.39730918263814535, disc_loss = 0.055091923907825566
Trained batch 166 in epoch 12, gen_loss = 0.39734668039276216, disc_loss = 0.056667138289794056
Trained batch 167 in epoch 12, gen_loss = 0.397246883383819, disc_loss = 0.05644659940541411
Trained batch 168 in epoch 12, gen_loss = 0.39746694663572596, disc_loss = 0.056267566689615245
Trained batch 169 in epoch 12, gen_loss = 0.3973121341537027, disc_loss = 0.056350245477412554
Trained batch 170 in epoch 12, gen_loss = 0.3979626207323799, disc_loss = 0.05638689850320854
Trained batch 171 in epoch 12, gen_loss = 0.3981470659721729, disc_loss = 0.05620609012399908
Trained batch 172 in epoch 12, gen_loss = 0.3979240967703693, disc_loss = 0.05590407795816488
Trained batch 173 in epoch 12, gen_loss = 0.39788858866554566, disc_loss = 0.05563997121891756
Trained batch 174 in epoch 12, gen_loss = 0.397928592136928, disc_loss = 0.055457238906196187
Trained batch 175 in epoch 12, gen_loss = 0.3979085319760171, disc_loss = 0.055181392418241805
Trained batch 176 in epoch 12, gen_loss = 0.3981112192916331, disc_loss = 0.05495068605326242
Trained batch 177 in epoch 12, gen_loss = 0.3983453199099959, disc_loss = 0.055007984607972286
Trained batch 178 in epoch 12, gen_loss = 0.39896800847692865, disc_loss = 0.055246040118369144
Trained batch 179 in epoch 12, gen_loss = 0.39890525821182465, disc_loss = 0.05511573074747705
Trained batch 180 in epoch 12, gen_loss = 0.3990222381952718, disc_loss = 0.055745593604029704
Trained batch 181 in epoch 12, gen_loss = 0.3986291292604509, disc_loss = 0.055973413735525786
Trained batch 182 in epoch 12, gen_loss = 0.3991918016652592, disc_loss = 0.05571317818534911
Trained batch 183 in epoch 12, gen_loss = 0.3985955619617649, disc_loss = 0.05589846338641465
Trained batch 184 in epoch 12, gen_loss = 0.3988234864698874, disc_loss = 0.05571451229672577
Trained batch 185 in epoch 12, gen_loss = 0.3988155735436306, disc_loss = 0.05561791306551826
Trained batch 186 in epoch 12, gen_loss = 0.398851729331807, disc_loss = 0.05535622074811615
Trained batch 187 in epoch 12, gen_loss = 0.3984915579253055, disc_loss = 0.055107815778180164
Trained batch 188 in epoch 12, gen_loss = 0.39820338367785096, disc_loss = 0.054851809979746584
Trained batch 189 in epoch 12, gen_loss = 0.3984479918291694, disc_loss = 0.054635056774867206
Trained batch 190 in epoch 12, gen_loss = 0.39861047174293956, disc_loss = 0.05441187555214185
Trained batch 191 in epoch 12, gen_loss = 0.3982435300325354, disc_loss = 0.05454305822301345
Trained batch 192 in epoch 12, gen_loss = 0.3984205599275895, disc_loss = 0.05594702782061125
Trained batch 193 in epoch 12, gen_loss = 0.3983592523127487, disc_loss = 0.055768008055837495
Trained batch 194 in epoch 12, gen_loss = 0.39783249191748793, disc_loss = 0.05642815863665862
Trained batch 195 in epoch 12, gen_loss = 0.3981127895566882, disc_loss = 0.05646693289317951
Trained batch 196 in epoch 12, gen_loss = 0.3983039789393469, disc_loss = 0.05643149999532905
Trained batch 197 in epoch 12, gen_loss = 0.39830544410329877, disc_loss = 0.056171554089006454
Trained batch 198 in epoch 12, gen_loss = 0.39824684855326936, disc_loss = 0.05594056384666032
Trained batch 199 in epoch 12, gen_loss = 0.3977880151569843, disc_loss = 0.05568097103387117
Trained batch 200 in epoch 12, gen_loss = 0.3975547162157979, disc_loss = 0.05542100073922592
Trained batch 201 in epoch 12, gen_loss = 0.39795792279857223, disc_loss = 0.05517018844470345
Trained batch 202 in epoch 12, gen_loss = 0.3978952213461176, disc_loss = 0.05490888853493179
Trained batch 203 in epoch 12, gen_loss = 0.39760325425395776, disc_loss = 0.054654366567310896
Trained batch 204 in epoch 12, gen_loss = 0.39750211922133843, disc_loss = 0.054399904155558565
Trained batch 205 in epoch 12, gen_loss = 0.397251661396721, disc_loss = 0.05415597259297569
Trained batch 206 in epoch 12, gen_loss = 0.3970965057755438, disc_loss = 0.053909470101116574
Trained batch 207 in epoch 12, gen_loss = 0.3972569236961695, disc_loss = 0.053665824081130825
Trained batch 208 in epoch 12, gen_loss = 0.39700380894556, disc_loss = 0.053421103724158196
Trained batch 209 in epoch 12, gen_loss = 0.397062121118818, disc_loss = 0.0532320713613271
Trained batch 210 in epoch 12, gen_loss = 0.3966642201511781, disc_loss = 0.053022297115784614
Trained batch 211 in epoch 12, gen_loss = 0.39618846816274356, disc_loss = 0.05351073362420858
Trained batch 212 in epoch 12, gen_loss = 0.39618086003361735, disc_loss = 0.05402214990321005
Trained batch 213 in epoch 12, gen_loss = 0.3962477753374064, disc_loss = 0.05399578230816732
Trained batch 214 in epoch 12, gen_loss = 0.39594930465831313, disc_loss = 0.054175600538376806
Trained batch 215 in epoch 12, gen_loss = 0.3956890790550797, disc_loss = 0.054567477621646876
Trained batch 216 in epoch 12, gen_loss = 0.3952534503651105, disc_loss = 0.056016101256176
Trained batch 217 in epoch 12, gen_loss = 0.3950413211223182, disc_loss = 0.055991714964449886
Trained batch 218 in epoch 12, gen_loss = 0.39509528984217884, disc_loss = 0.056292073323803885
Trained batch 219 in epoch 12, gen_loss = 0.3955992739308964, disc_loss = 0.0563801042301665
Trained batch 220 in epoch 12, gen_loss = 0.3956594844749071, disc_loss = 0.05648370022143814
Trained batch 221 in epoch 12, gen_loss = 0.39541615760541177, disc_loss = 0.05647951365251363
Trained batch 222 in epoch 12, gen_loss = 0.39562472701072693, disc_loss = 0.05656405886522423
Trained batch 223 in epoch 12, gen_loss = 0.39578550468598095, disc_loss = 0.05635314999692907
Trained batch 224 in epoch 12, gen_loss = 0.39561086985800004, disc_loss = 0.05612411046297186
Trained batch 225 in epoch 12, gen_loss = 0.3956426516570876, disc_loss = 0.055905888012643346
Trained batch 226 in epoch 12, gen_loss = 0.3959575554085198, disc_loss = 0.0556747501424723
Trained batch 227 in epoch 12, gen_loss = 0.39605685088195297, disc_loss = 0.05545022498955133
Trained batch 228 in epoch 12, gen_loss = 0.39594584651388975, disc_loss = 0.055252548398685895
Trained batch 229 in epoch 12, gen_loss = 0.3959188409473585, disc_loss = 0.05502974698724954
Trained batch 230 in epoch 12, gen_loss = 0.39598242790151983, disc_loss = 0.054801983156068115
Trained batch 231 in epoch 12, gen_loss = 0.39606863375881624, disc_loss = 0.0546046007075347
Trained batch 232 in epoch 12, gen_loss = 0.3959930123433535, disc_loss = 0.05454169406631538
Trained batch 233 in epoch 12, gen_loss = 0.39586502097101295, disc_loss = 0.05445247770159736
Trained batch 234 in epoch 12, gen_loss = 0.39590312229826097, disc_loss = 0.054602586329379615
Trained batch 235 in epoch 12, gen_loss = 0.3958224281668663, disc_loss = 0.054912986196340774
Trained batch 236 in epoch 12, gen_loss = 0.3959879765782175, disc_loss = 0.05496795528336479
Trained batch 237 in epoch 12, gen_loss = 0.39628017975502655, disc_loss = 0.054778930009147075
Trained batch 238 in epoch 12, gen_loss = 0.3962519158878087, disc_loss = 0.05457333380270703
Trained batch 239 in epoch 12, gen_loss = 0.39615683803955715, disc_loss = 0.05437601885447899
Trained batch 240 in epoch 12, gen_loss = 0.3962458516799563, disc_loss = 0.054197462627285496
Trained batch 241 in epoch 12, gen_loss = 0.3961624091814372, disc_loss = 0.0539967722898303
Trained batch 242 in epoch 12, gen_loss = 0.39612662412011573, disc_loss = 0.05378863885385509
Trained batch 243 in epoch 12, gen_loss = 0.396112751521048, disc_loss = 0.05358347125527006
Trained batch 244 in epoch 12, gen_loss = 0.39614611864089966, disc_loss = 0.05337708599257226
Trained batch 245 in epoch 12, gen_loss = 0.3963821547302773, disc_loss = 0.0531892857677114
Trained batch 246 in epoch 12, gen_loss = 0.3964520065408004, disc_loss = 0.05298412798598469
Trained batch 247 in epoch 12, gen_loss = 0.39652135030877206, disc_loss = 0.052780434003873396
Trained batch 248 in epoch 12, gen_loss = 0.39665375727726276, disc_loss = 0.05258298725596663
Trained batch 249 in epoch 12, gen_loss = 0.39646185076236723, disc_loss = 0.05238593277148902
Trained batch 250 in epoch 12, gen_loss = 0.3964197512166909, disc_loss = 0.05218951079894258
Trained batch 251 in epoch 12, gen_loss = 0.396182235507738, disc_loss = 0.052020695113155636
Trained batch 252 in epoch 12, gen_loss = 0.39609561430606915, disc_loss = 0.05183796728629869
Trained batch 253 in epoch 12, gen_loss = 0.39623910669736034, disc_loss = 0.05166208031715634
Trained batch 254 in epoch 12, gen_loss = 0.39626132203083414, disc_loss = 0.051472252747043964
Trained batch 255 in epoch 12, gen_loss = 0.39604857261292636, disc_loss = 0.05130401439328125
Trained batch 256 in epoch 12, gen_loss = 0.39624792836055683, disc_loss = 0.051138478125615866
Trained batch 257 in epoch 12, gen_loss = 0.39649269874243775, disc_loss = 0.05095367880390105
Trained batch 258 in epoch 12, gen_loss = 0.3966052639208245, disc_loss = 0.05076585087069386
Trained batch 259 in epoch 12, gen_loss = 0.39657825449338324, disc_loss = 0.05058703136343796
Trained batch 260 in epoch 12, gen_loss = 0.39661527707658967, disc_loss = 0.05040259574632735
Trained batch 261 in epoch 12, gen_loss = 0.39678760054912277, disc_loss = 0.05021851034106274
Trained batch 262 in epoch 12, gen_loss = 0.39685728250800884, disc_loss = 0.050038558859448926
Trained batch 263 in epoch 12, gen_loss = 0.3970225215183966, disc_loss = 0.04986407885250325
Trained batch 264 in epoch 12, gen_loss = 0.3972734850532604, disc_loss = 0.04968676512164749
Trained batch 265 in epoch 12, gen_loss = 0.39729098908435134, disc_loss = 0.04951226907341104
Trained batch 266 in epoch 12, gen_loss = 0.39699197239643624, disc_loss = 0.04934920173501142
Trained batch 267 in epoch 12, gen_loss = 0.39698786221778215, disc_loss = 0.04917467298653366
Trained batch 268 in epoch 12, gen_loss = 0.3967893722996836, disc_loss = 0.04900200450775598
Trained batch 269 in epoch 12, gen_loss = 0.396739880906211, disc_loss = 0.048830683204276415
Trained batch 270 in epoch 12, gen_loss = 0.39670789967603787, disc_loss = 0.04865991212324518
Trained batch 271 in epoch 12, gen_loss = 0.3968518021352151, disc_loss = 0.048495237138601675
Trained batch 272 in epoch 12, gen_loss = 0.3969618823283758, disc_loss = 0.04832567263909721
Trained batch 273 in epoch 12, gen_loss = 0.39691650334500916, disc_loss = 0.04815951445527429
Trained batch 274 in epoch 12, gen_loss = 0.3969805383682251, disc_loss = 0.047998704175380144
Trained batch 275 in epoch 12, gen_loss = 0.39695730654225836, disc_loss = 0.04784783356708299
Trained batch 276 in epoch 12, gen_loss = 0.39711454349304365, disc_loss = 0.047682210599620314
Trained batch 277 in epoch 12, gen_loss = 0.3970134902557881, disc_loss = 0.04752105599597579
Trained batch 278 in epoch 12, gen_loss = 0.3970448964385576, disc_loss = 0.047362999587510064
Trained batch 279 in epoch 12, gen_loss = 0.3972106481237071, disc_loss = 0.047202575272448095
Trained batch 280 in epoch 12, gen_loss = 0.39737273842838733, disc_loss = 0.04704116366047982
Trained batch 281 in epoch 12, gen_loss = 0.3969773938681217, disc_loss = 0.04688760711058499
Trained batch 282 in epoch 12, gen_loss = 0.3970024403540069, disc_loss = 0.04672973986563697
Trained batch 283 in epoch 12, gen_loss = 0.3971810829891285, disc_loss = 0.046583139329401016
Trained batch 284 in epoch 12, gen_loss = 0.3974377082105269, disc_loss = 0.04642772520974017
Trained batch 285 in epoch 12, gen_loss = 0.39751953376339866, disc_loss = 0.046273966728533796
Trained batch 286 in epoch 12, gen_loss = 0.3976541502135141, disc_loss = 0.046119113848625784
Trained batch 287 in epoch 12, gen_loss = 0.3978467183187604, disc_loss = 0.04596940090009917
Trained batch 288 in epoch 12, gen_loss = 0.3977178790990044, disc_loss = 0.04581742280543134
Trained batch 289 in epoch 12, gen_loss = 0.39781036253633173, disc_loss = 0.045669254136336004
Trained batch 290 in epoch 12, gen_loss = 0.39782693326678065, disc_loss = 0.04552440365289956
Trained batch 291 in epoch 12, gen_loss = 0.3977640648818996, disc_loss = 0.04537921474627793
Trained batch 292 in epoch 12, gen_loss = 0.3979106302350861, disc_loss = 0.04523397143294482
Trained batch 293 in epoch 12, gen_loss = 0.3979746213778347, disc_loss = 0.045086483581175354
Trained batch 294 in epoch 12, gen_loss = 0.3980806590136835, disc_loss = 0.04494219038209294
Trained batch 295 in epoch 12, gen_loss = 0.39810157396100665, disc_loss = 0.04479709329835542
Trained batch 296 in epoch 12, gen_loss = 0.3978765328925868, disc_loss = 0.04465365368537354
Trained batch 297 in epoch 12, gen_loss = 0.39770301406415515, disc_loss = 0.04450963559988636
Trained batch 298 in epoch 12, gen_loss = 0.3977822938491668, disc_loss = 0.044368690902205264
Trained batch 299 in epoch 12, gen_loss = 0.39787490248680113, disc_loss = 0.044230387675731134
Trained batch 300 in epoch 12, gen_loss = 0.3978615207133499, disc_loss = 0.044088617302910534
Trained batch 301 in epoch 12, gen_loss = 0.3980103763720847, disc_loss = 0.04394932785256463
Trained batch 302 in epoch 12, gen_loss = 0.39799864368863624, disc_loss = 0.0438093523150648
Trained batch 303 in epoch 12, gen_loss = 0.3981164196800244, disc_loss = 0.043674858757233447
Trained batch 304 in epoch 12, gen_loss = 0.39794254488632325, disc_loss = 0.04354121815718588
Trained batch 305 in epoch 12, gen_loss = 0.39768095674857595, disc_loss = 0.0434031336837649
Trained batch 306 in epoch 12, gen_loss = 0.39752813241769125, disc_loss = 0.043267699249744024
Trained batch 307 in epoch 12, gen_loss = 0.39743965544870924, disc_loss = 0.043143165712063385
Trained batch 308 in epoch 12, gen_loss = 0.39760023664116473, disc_loss = 0.043024858285018924
Trained batch 309 in epoch 12, gen_loss = 0.3975087579219572, disc_loss = 0.04289475398198251
Trained batch 310 in epoch 12, gen_loss = 0.3975999661005578, disc_loss = 0.042772672585304525
Trained batch 311 in epoch 12, gen_loss = 0.39777949767617077, disc_loss = 0.04270788636177969
Trained batch 312 in epoch 12, gen_loss = 0.3977245534189974, disc_loss = 0.04258678691497388
Trained batch 313 in epoch 12, gen_loss = 0.39784386260494303, disc_loss = 0.042468190194659264
Trained batch 314 in epoch 12, gen_loss = 0.39780073733556837, disc_loss = 0.04234539134989655
Trained batch 315 in epoch 12, gen_loss = 0.39757213996181007, disc_loss = 0.04235607935587251
Trained batch 316 in epoch 12, gen_loss = 0.397708859729466, disc_loss = 0.04236361131142555
Trained batch 317 in epoch 12, gen_loss = 0.3977211296745816, disc_loss = 0.04243033124520531
Trained batch 318 in epoch 12, gen_loss = 0.3979048358983007, disc_loss = 0.042399664219690714
Trained batch 319 in epoch 12, gen_loss = 0.39787543304264544, disc_loss = 0.04230994869722053
Trained batch 320 in epoch 12, gen_loss = 0.39791427798731677, disc_loss = 0.042292823162034296
Trained batch 321 in epoch 12, gen_loss = 0.3980804191242834, disc_loss = 0.04217792168745528
Trained batch 322 in epoch 12, gen_loss = 0.39827896447004546, disc_loss = 0.042069527594482195
Trained batch 323 in epoch 12, gen_loss = 0.3983843642068498, disc_loss = 0.041982558826099574
Trained batch 324 in epoch 12, gen_loss = 0.3983623522061568, disc_loss = 0.04187054673353067
Trained batch 325 in epoch 12, gen_loss = 0.39836460799892986, disc_loss = 0.04180981432790497
Trained batch 326 in epoch 12, gen_loss = 0.39861659473235456, disc_loss = 0.04171396081908307
Trained batch 327 in epoch 12, gen_loss = 0.39875674820164353, disc_loss = 0.0421797185767124
Trained batch 328 in epoch 12, gen_loss = 0.3983769911400815, disc_loss = 0.04336619382514689
Trained batch 329 in epoch 12, gen_loss = 0.3982601021275376, disc_loss = 0.04410855179426797
Trained batch 330 in epoch 12, gen_loss = 0.397959161471024, disc_loss = 0.04456233398375464
Trained batch 331 in epoch 12, gen_loss = 0.3976478464452617, disc_loss = 0.044922865217506706
Trained batch 332 in epoch 12, gen_loss = 0.3973331701111149, disc_loss = 0.045215115228013414
Trained batch 333 in epoch 12, gen_loss = 0.3972897716981922, disc_loss = 0.045485931116819915
Trained batch 334 in epoch 12, gen_loss = 0.3971264567837786, disc_loss = 0.04571700039138989
Trained batch 335 in epoch 12, gen_loss = 0.39697949100463165, disc_loss = 0.04586642012388135
Trained batch 336 in epoch 12, gen_loss = 0.39683693231743944, disc_loss = 0.04592176116394979
Trained batch 337 in epoch 12, gen_loss = 0.39673642602545267, disc_loss = 0.04598943784160639
Trained batch 338 in epoch 12, gen_loss = 0.39676176455520246, disc_loss = 0.04595352539787163
Trained batch 339 in epoch 12, gen_loss = 0.39698638013180565, disc_loss = 0.046071523359483654
Trained batch 340 in epoch 12, gen_loss = 0.39708896737294463, disc_loss = 0.046111888481615404
Trained batch 341 in epoch 12, gen_loss = 0.3968657544481824, disc_loss = 0.04615579869826896
Trained batch 342 in epoch 12, gen_loss = 0.3970336502216995, disc_loss = 0.04608125282239723
Trained batch 343 in epoch 12, gen_loss = 0.39714797308971717, disc_loss = 0.04603841824207975
Trained batch 344 in epoch 12, gen_loss = 0.39721837337466254, disc_loss = 0.045933281535795636
Trained batch 345 in epoch 12, gen_loss = 0.3971971234661995, disc_loss = 0.04591654230587486
Trained batch 346 in epoch 12, gen_loss = 0.3968948606798903, disc_loss = 0.04605345791125246
Trained batch 347 in epoch 12, gen_loss = 0.39720491859419593, disc_loss = 0.046326950773189976
Trained batch 348 in epoch 12, gen_loss = 0.3972100873389695, disc_loss = 0.04626586231907408
Trained batch 349 in epoch 12, gen_loss = 0.39723570006234304, disc_loss = 0.04672177316088762
Trained batch 350 in epoch 12, gen_loss = 0.3972579511651966, disc_loss = 0.04669614216084579
Trained batch 351 in epoch 12, gen_loss = 0.3974417618221857, disc_loss = 0.04670402146505446
Trained batch 352 in epoch 12, gen_loss = 0.3973540567473717, disc_loss = 0.04663189020662149
Trained batch 353 in epoch 12, gen_loss = 0.39733975696361673, disc_loss = 0.04660832868510131
Trained batch 354 in epoch 12, gen_loss = 0.3974628703694948, disc_loss = 0.04651185269664291
Trained batch 355 in epoch 12, gen_loss = 0.3974605794535594, disc_loss = 0.04648975949221699
Trained batch 356 in epoch 12, gen_loss = 0.397352983804644, disc_loss = 0.04667576305119514
Trained batch 357 in epoch 12, gen_loss = 0.3971697161983511, disc_loss = 0.04698718818653812
Trained batch 358 in epoch 12, gen_loss = 0.39716504094992505, disc_loss = 0.04718927736848095
Trained batch 359 in epoch 12, gen_loss = 0.39725276687079003, disc_loss = 0.04712798358717312
Trained batch 360 in epoch 12, gen_loss = 0.39713060657733695, disc_loss = 0.04712844679488122
Trained batch 361 in epoch 12, gen_loss = 0.3972925040767996, disc_loss = 0.04715383611876744
Trained batch 362 in epoch 12, gen_loss = 0.39735993348862514, disc_loss = 0.04705499046925999
Trained batch 363 in epoch 12, gen_loss = 0.3972130331036809, disc_loss = 0.04704690229270484
Trained batch 364 in epoch 12, gen_loss = 0.3971631746586055, disc_loss = 0.04698760341087433
Trained batch 365 in epoch 12, gen_loss = 0.3974377435576069, disc_loss = 0.04693574359630301
Trained batch 366 in epoch 12, gen_loss = 0.3976450754121474, disc_loss = 0.0468280061480541
Trained batch 367 in epoch 12, gen_loss = 0.3976687918538633, disc_loss = 0.04675011143958925
Trained batch 368 in epoch 12, gen_loss = 0.3976196118486606, disc_loss = 0.046706797040211474
Trained batch 369 in epoch 12, gen_loss = 0.39788590379663413, disc_loss = 0.04660509046972603
Trained batch 370 in epoch 12, gen_loss = 0.3981418444139938, disc_loss = 0.04649878606561702
Trained batch 371 in epoch 12, gen_loss = 0.3980831083270811, disc_loss = 0.04644137613915948
Trained batch 372 in epoch 12, gen_loss = 0.3983359332858078, disc_loss = 0.046490467036137954
Trained batch 373 in epoch 12, gen_loss = 0.39850760821033926, disc_loss = 0.04639697583880335
Trained batch 374 in epoch 12, gen_loss = 0.3985412522157033, disc_loss = 0.04634218496084213
Trained batch 375 in epoch 12, gen_loss = 0.3986198451132216, disc_loss = 0.04623872233168321
Trained batch 376 in epoch 12, gen_loss = 0.3985487247177397, disc_loss = 0.046235313350013615
Trained batch 377 in epoch 12, gen_loss = 0.3989123305473378, disc_loss = 0.04637283802515379
Trained batch 378 in epoch 12, gen_loss = 0.3991332693433384, disc_loss = 0.04627885485908365
Trained batch 379 in epoch 12, gen_loss = 0.3991938045934627, disc_loss = 0.04618982614116057
Trained batch 380 in epoch 12, gen_loss = 0.39915397708497335, disc_loss = 0.04610700328196362
Trained batch 381 in epoch 12, gen_loss = 0.3990091071390981, disc_loss = 0.04599415968021095
Trained batch 382 in epoch 12, gen_loss = 0.3989304679959001, disc_loss = 0.04590230452884037
Trained batch 383 in epoch 12, gen_loss = 0.39889626880176365, disc_loss = 0.04579913743509678
Trained batch 384 in epoch 12, gen_loss = 0.39903003859829594, disc_loss = 0.045704120339511274
Trained batch 385 in epoch 12, gen_loss = 0.3990920091076836, disc_loss = 0.045684179493800346
Trained batch 386 in epoch 12, gen_loss = 0.39937914626850946, disc_loss = 0.04558174371676043
Trained batch 387 in epoch 12, gen_loss = 0.39943722297543105, disc_loss = 0.045505425080263354
Trained batch 388 in epoch 12, gen_loss = 0.3993422178345658, disc_loss = 0.045467691959281735
Trained batch 389 in epoch 12, gen_loss = 0.3995352017573821, disc_loss = 0.04543441475655597
Trained batch 390 in epoch 12, gen_loss = 0.3994565610690495, disc_loss = 0.04537231761300008
Trained batch 391 in epoch 12, gen_loss = 0.3993287476501903, disc_loss = 0.04560791486660399
Trained batch 392 in epoch 12, gen_loss = 0.3993883242892248, disc_loss = 0.04594670105654434
Trained batch 393 in epoch 12, gen_loss = 0.3992694564125865, disc_loss = 0.045848622248002194
Trained batch 394 in epoch 12, gen_loss = 0.3991871107228195, disc_loss = 0.045776282992402585
Trained batch 395 in epoch 12, gen_loss = 0.3991512946709238, disc_loss = 0.04569608935818189
Trained batch 396 in epoch 12, gen_loss = 0.39940985324100525, disc_loss = 0.04559568138980783
Trained batch 397 in epoch 12, gen_loss = 0.39940146734966103, disc_loss = 0.045496060161958986
Trained batch 398 in epoch 12, gen_loss = 0.3992717080098346, disc_loss = 0.04545348255257858
Trained batch 399 in epoch 12, gen_loss = 0.3993700946867466, disc_loss = 0.04546214240603149
Trained batch 400 in epoch 12, gen_loss = 0.3992847216099575, disc_loss = 0.045359560765762655
Trained batch 401 in epoch 12, gen_loss = 0.3992510165148114, disc_loss = 0.0454154058663054
Trained batch 402 in epoch 12, gen_loss = 0.39936625151421234, disc_loss = 0.045423093116691994
Trained batch 403 in epoch 12, gen_loss = 0.39932233441879256, disc_loss = 0.045345380384760846
Trained batch 404 in epoch 12, gen_loss = 0.3993273155924715, disc_loss = 0.04526569925271619
Trained batch 405 in epoch 12, gen_loss = 0.39940597454608956, disc_loss = 0.045238112160257006
Trained batch 406 in epoch 12, gen_loss = 0.3994069936380925, disc_loss = 0.045142631198643396
Trained batch 407 in epoch 12, gen_loss = 0.3993964488161545, disc_loss = 0.04517920856596902
Trained batch 408 in epoch 12, gen_loss = 0.39938020786329703, disc_loss = 0.045380763662865156
Trained batch 409 in epoch 12, gen_loss = 0.3993171039150982, disc_loss = 0.04532301135974504
Trained batch 410 in epoch 12, gen_loss = 0.3993864139211149, disc_loss = 0.04533399874344468
Trained batch 411 in epoch 12, gen_loss = 0.3996201546736134, disc_loss = 0.045326174443669036
Trained batch 412 in epoch 12, gen_loss = 0.3995090617683263, disc_loss = 0.04524704196871446
Trained batch 413 in epoch 12, gen_loss = 0.3992948514827784, disc_loss = 0.04516597080566349
Trained batch 414 in epoch 12, gen_loss = 0.39937636184405134, disc_loss = 0.045126549003039855
Trained batch 415 in epoch 12, gen_loss = 0.39938217494636774, disc_loss = 0.04509592235486847
Trained batch 416 in epoch 12, gen_loss = 0.39926564772066164, disc_loss = 0.04513269526285412
Trained batch 417 in epoch 12, gen_loss = 0.39939881975285746, disc_loss = 0.04520155371024171
Trained batch 418 in epoch 12, gen_loss = 0.39961028198638227, disc_loss = 0.04512286054743965
Trained batch 419 in epoch 12, gen_loss = 0.3996480705482619, disc_loss = 0.04504485148160408
Trained batch 420 in epoch 12, gen_loss = 0.39976159927397614, disc_loss = 0.044961184759861
Trained batch 421 in epoch 12, gen_loss = 0.39990941756427006, disc_loss = 0.04486643292023072
Trained batch 422 in epoch 12, gen_loss = 0.39989207688516476, disc_loss = 0.04477029145160254
Trained batch 423 in epoch 12, gen_loss = 0.40003436881135096, disc_loss = 0.04467231162300966
Trained batch 424 in epoch 12, gen_loss = 0.4000677812099457, disc_loss = 0.04457317330162315
Trained batch 425 in epoch 12, gen_loss = 0.4000524859613096, disc_loss = 0.044475515376330474
Trained batch 426 in epoch 12, gen_loss = 0.40007922821078423, disc_loss = 0.04437950193070626
Trained batch 427 in epoch 12, gen_loss = 0.4000330636295203, disc_loss = 0.04428210599994217
Trained batch 428 in epoch 12, gen_loss = 0.40000174498502467, disc_loss = 0.04418780341839943
Trained batch 429 in epoch 12, gen_loss = 0.39997875135998395, disc_loss = 0.04409175977587353
Trained batch 430 in epoch 12, gen_loss = 0.4000018973361588, disc_loss = 0.04399429495811566
Trained batch 431 in epoch 12, gen_loss = 0.39997212657773934, disc_loss = 0.04389712692688961
Trained batch 432 in epoch 12, gen_loss = 0.3998080275901195, disc_loss = 0.04380032196200042
Trained batch 433 in epoch 12, gen_loss = 0.3999066656360978, disc_loss = 0.043710159362628544
Trained batch 434 in epoch 12, gen_loss = 0.39990941505322514, disc_loss = 0.04361478591862338
Trained batch 435 in epoch 12, gen_loss = 0.3999145229201798, disc_loss = 0.0435218466985159
Trained batch 436 in epoch 12, gen_loss = 0.39991019199041805, disc_loss = 0.04342678800125093
Trained batch 437 in epoch 12, gen_loss = 0.3999934891179272, disc_loss = 0.04333273463693264
Trained batch 438 in epoch 12, gen_loss = 0.4000178554470827, disc_loss = 0.043238378765277884
Trained batch 439 in epoch 12, gen_loss = 0.399888806857846, disc_loss = 0.043170574397399006
Trained batch 440 in epoch 12, gen_loss = 0.3998084683266897, disc_loss = 0.04308315095979543
Trained batch 441 in epoch 12, gen_loss = 0.39972643095713395, disc_loss = 0.042992500421312974
Trained batch 442 in epoch 12, gen_loss = 0.399704462182172, disc_loss = 0.04291481861653349
Trained batch 443 in epoch 12, gen_loss = 0.3995705034818735, disc_loss = 0.042829331540741734
Trained batch 444 in epoch 12, gen_loss = 0.39956236789735516, disc_loss = 0.042743390899549205
Trained batch 445 in epoch 12, gen_loss = 0.3995393928257339, disc_loss = 0.04265901580663824
Trained batch 446 in epoch 12, gen_loss = 0.3994045879616833, disc_loss = 0.042570702073224706
Trained batch 447 in epoch 12, gen_loss = 0.39939468626731206, disc_loss = 0.04248718697843807
Trained batch 448 in epoch 12, gen_loss = 0.3994960841994509, disc_loss = 0.04240665899253635
Trained batch 449 in epoch 12, gen_loss = 0.3994275895754496, disc_loss = 0.04232258941564295
Trained batch 450 in epoch 12, gen_loss = 0.39956665078710824, disc_loss = 0.042238679881767265
Trained batch 451 in epoch 12, gen_loss = 0.3994946765293062, disc_loss = 0.04217533880548008
Trained batch 452 in epoch 12, gen_loss = 0.39957237934434653, disc_loss = 0.042149115579971676
Trained batch 453 in epoch 12, gen_loss = 0.3996307521664624, disc_loss = 0.04210397107977962
Trained batch 454 in epoch 12, gen_loss = 0.39953429233896864, disc_loss = 0.04207934652874758
Trained batch 455 in epoch 12, gen_loss = 0.3996076928941827, disc_loss = 0.04200926233948976
Trained batch 456 in epoch 12, gen_loss = 0.3995638037145268, disc_loss = 0.041929649351128015
Trained batch 457 in epoch 12, gen_loss = 0.3993962415571296, disc_loss = 0.04205145978360685
Trained batch 458 in epoch 12, gen_loss = 0.3995086709138874, disc_loss = 0.0427821989735276
Trained batch 459 in epoch 12, gen_loss = 0.3993723807775456, disc_loss = 0.04304526978192608
Trained batch 460 in epoch 12, gen_loss = 0.39930188067564476, disc_loss = 0.04301148994751032
Testing Epoch 12
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-08-30 00:49:50,722
------------------------------------------------------------
Training Epoch 13
Trained batch 0 in epoch 13, gen_loss = 0.4524216651916504, disc_loss = 0.04412605240941048
Trained batch 1 in epoch 13, gen_loss = 0.4363734871149063, disc_loss = 0.025560458889231086
Trained batch 2 in epoch 13, gen_loss = 0.4177231192588806, disc_loss = 0.01923157476509611
Trained batch 3 in epoch 13, gen_loss = 0.41197384148836136, disc_loss = 0.016079911147244275
Trained batch 4 in epoch 13, gen_loss = 0.42254467606544494, disc_loss = 0.014562220964580774
Trained batch 5 in epoch 13, gen_loss = 0.42181624968846637, disc_loss = 0.013277113515262803
Trained batch 6 in epoch 13, gen_loss = 0.40841282265526907, disc_loss = 0.028258548317743198
Trained batch 7 in epoch 13, gen_loss = 0.4081798121333122, disc_loss = 0.06847332330653444
Trained batch 8 in epoch 13, gen_loss = 0.4041537245114644, disc_loss = 0.0638750874851313
Trained batch 9 in epoch 13, gen_loss = 0.3998933583498001, disc_loss = 0.07026528124697506
Trained batch 10 in epoch 13, gen_loss = 0.39643659645860846, disc_loss = 0.06502652265639468
Trained batch 11 in epoch 13, gen_loss = 0.3952920114000638, disc_loss = 0.06187922053504735
Trained batch 12 in epoch 13, gen_loss = 0.38992925790640026, disc_loss = 0.057969357997465595
Trained batch 13 in epoch 13, gen_loss = 0.3875675584588732, disc_loss = 0.055068400189546604
Trained batch 14 in epoch 13, gen_loss = 0.38849212527275084, disc_loss = 0.05298265619203448
Trained batch 15 in epoch 13, gen_loss = 0.39314369671046734, disc_loss = 0.050321362243266776
Trained batch 16 in epoch 13, gen_loss = 0.3905373934437247, disc_loss = 0.04870715268942363
Trained batch 17 in epoch 13, gen_loss = 0.38964055313004387, disc_loss = 0.0463693122793403
Trained batch 18 in epoch 13, gen_loss = 0.3882494866847992, disc_loss = 0.050673339466907476
Trained batch 19 in epoch 13, gen_loss = 0.3846131727099419, disc_loss = 0.07260571620427073
Trained batch 20 in epoch 13, gen_loss = 0.3819154075213841, disc_loss = 0.080400556104169
Trained batch 21 in epoch 13, gen_loss = 0.3784596012397246, disc_loss = 0.08529457157816399
Trained batch 22 in epoch 13, gen_loss = 0.3769351282845373, disc_loss = 0.0889085503295064
Trained batch 23 in epoch 13, gen_loss = 0.3766652395327886, disc_loss = 0.09065989199249695
Trained batch 24 in epoch 13, gen_loss = 0.3787036609649658, disc_loss = 0.09171915631741286
Trained batch 25 in epoch 13, gen_loss = 0.3823251793017754, disc_loss = 0.09208738413424446
Trained batch 26 in epoch 13, gen_loss = 0.3785163395934635, disc_loss = 0.09385308578472447
Trained batch 27 in epoch 13, gen_loss = 0.38097612879105974, disc_loss = 0.09341278628978346
Trained batch 28 in epoch 13, gen_loss = 0.38226309418678284, disc_loss = 0.09301346061943934
Trained batch 29 in epoch 13, gen_loss = 0.3816744883855184, disc_loss = 0.09306895394499103
Trained batch 30 in epoch 13, gen_loss = 0.3835486558175856, disc_loss = 0.09098323792098992
Trained batch 31 in epoch 13, gen_loss = 0.38550020661205053, disc_loss = 0.08916065967059694
Trained batch 32 in epoch 13, gen_loss = 0.3852457918904044, disc_loss = 0.08784312131165554
Trained batch 33 in epoch 13, gen_loss = 0.3858362243455999, disc_loss = 0.08768248851137127
Trained batch 34 in epoch 13, gen_loss = 0.38704235809189935, disc_loss = 0.08812147578490633
Trained batch 35 in epoch 13, gen_loss = 0.38759680340687436, disc_loss = 0.08971223718900648
Trained batch 36 in epoch 13, gen_loss = 0.3876175695174449, disc_loss = 0.08969405623203194
Trained batch 37 in epoch 13, gen_loss = 0.38881245961314753, disc_loss = 0.08809423458909518
Trained batch 38 in epoch 13, gen_loss = 0.38785835259999984, disc_loss = 0.08605402760589734
Trained batch 39 in epoch 13, gen_loss = 0.38857367932796477, disc_loss = 0.08416425625327975
Trained batch 40 in epoch 13, gen_loss = 0.39034623198392915, disc_loss = 0.08258093182542701
Trained batch 41 in epoch 13, gen_loss = 0.39197563131650287, disc_loss = 0.0830411039780648
Trained batch 42 in epoch 13, gen_loss = 0.3907447187013404, disc_loss = 0.08391402070518843
Trained batch 43 in epoch 13, gen_loss = 0.38955369049852545, disc_loss = 0.08267858520742845
Trained batch 44 in epoch 13, gen_loss = 0.391679009464052, disc_loss = 0.08763994539363516
Trained batch 45 in epoch 13, gen_loss = 0.3917410963255426, disc_loss = 0.08750278371102783
Trained batch 46 in epoch 13, gen_loss = 0.39110248202973225, disc_loss = 0.08670713750526626
Trained batch 47 in epoch 13, gen_loss = 0.39210470020771027, disc_loss = 0.08533132904752468
Trained batch 48 in epoch 13, gen_loss = 0.3912618342711001, disc_loss = 0.08407125909033479
Trained batch 49 in epoch 13, gen_loss = 0.3913706260919571, disc_loss = 0.08263251526281237
Trained batch 50 in epoch 13, gen_loss = 0.39188211104449105, disc_loss = 0.08159651773452174
Trained batch 51 in epoch 13, gen_loss = 0.3930584748203938, disc_loss = 0.08122565631324855
Trained batch 52 in epoch 13, gen_loss = 0.3918953779733406, disc_loss = 0.08121954219169775
Trained batch 53 in epoch 13, gen_loss = 0.39233101186928926, disc_loss = 0.08189928398847028
Trained batch 54 in epoch 13, gen_loss = 0.393254108320583, disc_loss = 0.08143539149314165
Trained batch 55 in epoch 13, gen_loss = 0.3939290754497051, disc_loss = 0.08009569285370942
Trained batch 56 in epoch 13, gen_loss = 0.39436569130211546, disc_loss = 0.07910770029156354
Trained batch 57 in epoch 13, gen_loss = 0.39471907554001645, disc_loss = 0.07825897760881946
Trained batch 58 in epoch 13, gen_loss = 0.39574061510926584, disc_loss = 0.07702476870647426
Trained batch 59 in epoch 13, gen_loss = 0.39686173597971597, disc_loss = 0.07587064177108307
Trained batch 60 in epoch 13, gen_loss = 0.39838814393418737, disc_loss = 0.07469287161242033
Trained batch 61 in epoch 13, gen_loss = 0.39881841501882, disc_loss = 0.07367732394636879
Trained batch 62 in epoch 13, gen_loss = 0.4000330146342989, disc_loss = 0.07263572080179102
Trained batch 63 in epoch 13, gen_loss = 0.3986447863280773, disc_loss = 0.07212273349432508
Trained batch 64 in epoch 13, gen_loss = 0.400202764914586, disc_loss = 0.0733561322451211
Trained batch 65 in epoch 13, gen_loss = 0.400533066554503, disc_loss = 0.07350162171871599
Trained batch 66 in epoch 13, gen_loss = 0.4010677324302161, disc_loss = 0.07254291301481981
Trained batch 67 in epoch 13, gen_loss = 0.4015546861816855, disc_loss = 0.07169378456413089
Trained batch 68 in epoch 13, gen_loss = 0.4020287770292033, disc_loss = 0.07088858858965662
Trained batch 69 in epoch 13, gen_loss = 0.4026881477662495, disc_loss = 0.07024663844411927
Trained batch 70 in epoch 13, gen_loss = 0.4041916169750858, disc_loss = 0.06971510261638274
Trained batch 71 in epoch 13, gen_loss = 0.4028158067829079, disc_loss = 0.07120756042422727
Trained batch 72 in epoch 13, gen_loss = 0.40472789619066946, disc_loss = 0.07291972395415379
Trained batch 73 in epoch 13, gen_loss = 0.405840273241739, disc_loss = 0.0722851905329908
Trained batch 74 in epoch 13, gen_loss = 0.40524094144503275, disc_loss = 0.0714735416136682
Trained batch 75 in epoch 13, gen_loss = 0.40472502261400223, disc_loss = 0.07081701185578775
Trained batch 76 in epoch 13, gen_loss = 0.40457671880722046, disc_loss = 0.07000880589853826
Trained batch 77 in epoch 13, gen_loss = 0.4041525710087556, disc_loss = 0.06916893050313377
Trained batch 78 in epoch 13, gen_loss = 0.4041520851322367, disc_loss = 0.0684294081116213
Trained batch 79 in epoch 13, gen_loss = 0.4041496757417917, disc_loss = 0.06809246722841636
Trained batch 80 in epoch 13, gen_loss = 0.4029652369611057, disc_loss = 0.06875828144221026
Trained batch 81 in epoch 13, gen_loss = 0.4042991221677966, disc_loss = 0.06885425833894349
Trained batch 82 in epoch 13, gen_loss = 0.40400884524885433, disc_loss = 0.06837074197155524
Trained batch 83 in epoch 13, gen_loss = 0.4041820814212163, disc_loss = 0.0681833149754398
Trained batch 84 in epoch 13, gen_loss = 0.40296003888635074, disc_loss = 0.0709504758939147
Trained batch 85 in epoch 13, gen_loss = 0.40237670374471085, disc_loss = 0.07413179309345609
Trained batch 86 in epoch 13, gen_loss = 0.4021977761696125, disc_loss = 0.07367168541398199
Trained batch 87 in epoch 13, gen_loss = 0.4020603583617644, disc_loss = 0.07341340758880092
Trained batch 88 in epoch 13, gen_loss = 0.4028499997063969, disc_loss = 0.07271118014213744
Trained batch 89 in epoch 13, gen_loss = 0.40333663754993015, disc_loss = 0.07198363073791067
Trained batch 90 in epoch 13, gen_loss = 0.4030941911451109, disc_loss = 0.07150082684193666
Trained batch 91 in epoch 13, gen_loss = 0.4027505711368892, disc_loss = 0.07120636875903152
Trained batch 92 in epoch 13, gen_loss = 0.4022271319102215, disc_loss = 0.0706964430489367
Trained batch 93 in epoch 13, gen_loss = 0.4026510214551966, disc_loss = 0.07041800573983407
Trained batch 94 in epoch 13, gen_loss = 0.4024285846634915, disc_loss = 0.07105328594579509
Trained batch 95 in epoch 13, gen_loss = 0.40161478736748296, disc_loss = 0.07292565762569818
Trained batch 96 in epoch 13, gen_loss = 0.4019689421678327, disc_loss = 0.07276225217723663
Trained batch 97 in epoch 13, gen_loss = 0.40172428896232526, disc_loss = 0.07267851318821919
Trained batch 98 in epoch 13, gen_loss = 0.4003787606653541, disc_loss = 0.07248065256598321
Trained batch 99 in epoch 13, gen_loss = 0.40060515105724337, disc_loss = 0.07220916365273297
Trained batch 100 in epoch 13, gen_loss = 0.40060348705490034, disc_loss = 0.0716411011607045
Trained batch 101 in epoch 13, gen_loss = 0.4010574020007077, disc_loss = 0.0711419920930091
Trained batch 102 in epoch 13, gen_loss = 0.40098867283284084, disc_loss = 0.0713871414004599
Trained batch 103 in epoch 13, gen_loss = 0.4017000258542024, disc_loss = 0.07214611958569059
Trained batch 104 in epoch 13, gen_loss = 0.40144943651698883, disc_loss = 0.07154194879389944
Trained batch 105 in epoch 13, gen_loss = 0.4011632409298195, disc_loss = 0.07173079804007737
Trained batch 106 in epoch 13, gen_loss = 0.40136935499226933, disc_loss = 0.07120868306015139
Trained batch 107 in epoch 13, gen_loss = 0.4019723581495108, disc_loss = 0.07168421225139389
Trained batch 108 in epoch 13, gen_loss = 0.401672844493061, disc_loss = 0.0736187261042245
Trained batch 109 in epoch 13, gen_loss = 0.40270633589137683, disc_loss = 0.07378103103150022
Trained batch 110 in epoch 13, gen_loss = 0.40258319420857475, disc_loss = 0.07338724379335437
Trained batch 111 in epoch 13, gen_loss = 0.4031622143728392, disc_loss = 0.0728838515933603
Trained batch 112 in epoch 13, gen_loss = 0.4029611161852305, disc_loss = 0.07244996297939689
Trained batch 113 in epoch 13, gen_loss = 0.4026813423424436, disc_loss = 0.07217706811794064
Trained batch 114 in epoch 13, gen_loss = 0.40331238326819047, disc_loss = 0.07192445876805678
Trained batch 115 in epoch 13, gen_loss = 0.40284137402115194, disc_loss = 0.0716322948192728
Trained batch 116 in epoch 13, gen_loss = 0.4027905652665684, disc_loss = 0.07109538080473231
Trained batch 117 in epoch 13, gen_loss = 0.4025764558779991, disc_loss = 0.07074713839565293
Trained batch 118 in epoch 13, gen_loss = 0.4035278891815859, disc_loss = 0.07063894440271273
Trained batch 119 in epoch 13, gen_loss = 0.40320311511556306, disc_loss = 0.0703711082227528
Trained batch 120 in epoch 13, gen_loss = 0.4031441159977401, disc_loss = 0.06999366468757637
Trained batch 121 in epoch 13, gen_loss = 0.4033252882664321, disc_loss = 0.06958546710857114
Trained batch 122 in epoch 13, gen_loss = 0.40323566372801617, disc_loss = 0.06908335461001086
Trained batch 123 in epoch 13, gen_loss = 0.4037427306175232, disc_loss = 0.06857460503646683
Trained batch 124 in epoch 13, gen_loss = 0.40437680077552796, disc_loss = 0.06807465052604675
Trained batch 125 in epoch 13, gen_loss = 0.40429876933968256, disc_loss = 0.06758967342801274
Trained batch 126 in epoch 13, gen_loss = 0.4045975684650301, disc_loss = 0.06716254764185177
Trained batch 127 in epoch 13, gen_loss = 0.40415077074430883, disc_loss = 0.0674318199744448
Trained batch 128 in epoch 13, gen_loss = 0.4045537730982137, disc_loss = 0.07115295587121978
Trained batch 129 in epoch 13, gen_loss = 0.40472254134141483, disc_loss = 0.07155986451185667
Trained batch 130 in epoch 13, gen_loss = 0.404614295895773, disc_loss = 0.07193672366952168
Trained batch 131 in epoch 13, gen_loss = 0.40365124290639703, disc_loss = 0.0718032895784938
Trained batch 132 in epoch 13, gen_loss = 0.4037191233688727, disc_loss = 0.07147559114640817
Trained batch 133 in epoch 13, gen_loss = 0.403827704155623, disc_loss = 0.07100606896678235
Trained batch 134 in epoch 13, gen_loss = 0.4036351923589353, disc_loss = 0.07057635862104318
Trained batch 135 in epoch 13, gen_loss = 0.4033258671269697, disc_loss = 0.07016273826935931
Trained batch 136 in epoch 13, gen_loss = 0.40369859468327823, disc_loss = 0.06989534153691392
Trained batch 137 in epoch 13, gen_loss = 0.4031699230705482, disc_loss = 0.06952828222183861
Trained batch 138 in epoch 13, gen_loss = 0.40305290162134516, disc_loss = 0.06958448725397424
Trained batch 139 in epoch 13, gen_loss = 0.4036869121449334, disc_loss = 0.07034616533533804
Trained batch 140 in epoch 13, gen_loss = 0.40346219184550836, disc_loss = 0.07066571579730892
Trained batch 141 in epoch 13, gen_loss = 0.40410401178917416, disc_loss = 0.07034245838450504
Trained batch 142 in epoch 13, gen_loss = 0.40428445076608993, disc_loss = 0.06998932423473864
Trained batch 143 in epoch 13, gen_loss = 0.40362701937556267, disc_loss = 0.06967516400618479
Trained batch 144 in epoch 13, gen_loss = 0.40326050787136475, disc_loss = 0.06925058800984045
Trained batch 145 in epoch 13, gen_loss = 0.4032350917385049, disc_loss = 0.06886708567378251
Trained batch 146 in epoch 13, gen_loss = 0.4031994000178616, disc_loss = 0.06848413723387889
Trained batch 147 in epoch 13, gen_loss = 0.4032375764202427, disc_loss = 0.06829912027318936
Trained batch 148 in epoch 13, gen_loss = 0.4031556464681689, disc_loss = 0.0679107257321277
Trained batch 149 in epoch 13, gen_loss = 0.40300327956676485, disc_loss = 0.06777723351493478
Trained batch 150 in epoch 13, gen_loss = 0.40339925056261733, disc_loss = 0.06955815505680461
Trained batch 151 in epoch 13, gen_loss = 0.4028779929013629, disc_loss = 0.06974991782887005
Trained batch 152 in epoch 13, gen_loss = 0.40257207299369613, disc_loss = 0.06949761181801947
Trained batch 153 in epoch 13, gen_loss = 0.402872922745618, disc_loss = 0.06919278575155835
Trained batch 154 in epoch 13, gen_loss = 0.4030105302410741, disc_loss = 0.06891925379994415
Trained batch 155 in epoch 13, gen_loss = 0.40296174662235457, disc_loss = 0.06914532453848575
Trained batch 156 in epoch 13, gen_loss = 0.40307519921831264, disc_loss = 0.06955871889427019
Trained batch 157 in epoch 13, gen_loss = 0.4033988767032382, disc_loss = 0.06919695536570647
Trained batch 158 in epoch 13, gen_loss = 0.4035991032918294, disc_loss = 0.06903603968778683
Trained batch 159 in epoch 13, gen_loss = 0.40347662903368475, disc_loss = 0.06870312002138235
Trained batch 160 in epoch 13, gen_loss = 0.40303617086469756, disc_loss = 0.06837732373210399
Trained batch 161 in epoch 13, gen_loss = 0.4035386167190693, disc_loss = 0.06826354138392174
Trained batch 162 in epoch 13, gen_loss = 0.40344456880370533, disc_loss = 0.0692341600836146
Trained batch 163 in epoch 13, gen_loss = 0.4040950918343009, disc_loss = 0.07113286914735488
Trained batch 164 in epoch 13, gen_loss = 0.40375128731583104, disc_loss = 0.07131639554757964
Trained batch 165 in epoch 13, gen_loss = 0.40299601727221385, disc_loss = 0.07177743314013603
Trained batch 166 in epoch 13, gen_loss = 0.402442137995166, disc_loss = 0.07157968540681516
Trained batch 167 in epoch 13, gen_loss = 0.402771573691141, disc_loss = 0.07138945322505952
Trained batch 168 in epoch 13, gen_loss = 0.40302930269720993, disc_loss = 0.07101766932645492
Trained batch 169 in epoch 13, gen_loss = 0.40262783169746397, disc_loss = 0.07075147380066268
Trained batch 170 in epoch 13, gen_loss = 0.40238213225414876, disc_loss = 0.07045903831328217
Trained batch 171 in epoch 13, gen_loss = 0.4020871090334515, disc_loss = 0.07078169921932873
Trained batch 172 in epoch 13, gen_loss = 0.40255923061012533, disc_loss = 0.07176897079398521
Trained batch 173 in epoch 13, gen_loss = 0.4020729532529568, disc_loss = 0.07192860576912932
Trained batch 174 in epoch 13, gen_loss = 0.40219207440103805, disc_loss = 0.07201888304735933
Trained batch 175 in epoch 13, gen_loss = 0.4018546471541578, disc_loss = 0.07198636236981573
Trained batch 176 in epoch 13, gen_loss = 0.40146472191406507, disc_loss = 0.07220219533448502
Trained batch 177 in epoch 13, gen_loss = 0.40159705431943526, disc_loss = 0.07302822619467304
Trained batch 178 in epoch 13, gen_loss = 0.4012656887816317, disc_loss = 0.07266603548641644
Trained batch 179 in epoch 13, gen_loss = 0.40121752123037974, disc_loss = 0.07255605538893077
Trained batch 180 in epoch 13, gen_loss = 0.40086842966343156, disc_loss = 0.0722119530755512
Trained batch 181 in epoch 13, gen_loss = 0.40109125614821256, disc_loss = 0.07196878297970845
Trained batch 182 in epoch 13, gen_loss = 0.40109336034196325, disc_loss = 0.07165794125427313
Trained batch 183 in epoch 13, gen_loss = 0.4009049573670263, disc_loss = 0.07129399558913935
Trained batch 184 in epoch 13, gen_loss = 0.4006195831943203, disc_loss = 0.0717211275436991
Trained batch 185 in epoch 13, gen_loss = 0.40104649977017476, disc_loss = 0.07178090303956021
Trained batch 186 in epoch 13, gen_loss = 0.40086967741104373, disc_loss = 0.07152709175140302
Trained batch 187 in epoch 13, gen_loss = 0.4006249787325555, disc_loss = 0.07135074828909908
Trained batch 188 in epoch 13, gen_loss = 0.40078999567284157, disc_loss = 0.07113628642801097
Trained batch 189 in epoch 13, gen_loss = 0.40111699794468125, disc_loss = 0.07114283008697002
Trained batch 190 in epoch 13, gen_loss = 0.4011672685283641, disc_loss = 0.07100160241965692
Trained batch 191 in epoch 13, gen_loss = 0.40142534921566647, disc_loss = 0.07075596868041127
Trained batch 192 in epoch 13, gen_loss = 0.40188266344638685, disc_loss = 0.070450635091281
Trained batch 193 in epoch 13, gen_loss = 0.4013851530773124, disc_loss = 0.07013545081153819
Trained batch 194 in epoch 13, gen_loss = 0.4012012830147376, disc_loss = 0.07017478503000278
Trained batch 195 in epoch 13, gen_loss = 0.4011663344441628, disc_loss = 0.07057107030414045
Trained batch 196 in epoch 13, gen_loss = 0.40095018281549366, disc_loss = 0.07024178610698599
Trained batch 197 in epoch 13, gen_loss = 0.4009066287315253, disc_loss = 0.0703954753687022
Trained batch 198 in epoch 13, gen_loss = 0.40130429261892886, disc_loss = 0.07009833081199521
Trained batch 199 in epoch 13, gen_loss = 0.4012871593236923, disc_loss = 0.07022212147479877
Trained batch 200 in epoch 13, gen_loss = 0.40126203956888684, disc_loss = 0.070025100069241
Trained batch 201 in epoch 13, gen_loss = 0.40081353942946635, disc_loss = 0.07022983295667806
Trained batch 202 in epoch 13, gen_loss = 0.40125575544211667, disc_loss = 0.07038837196672418
Trained batch 203 in epoch 13, gen_loss = 0.4016909844735089, disc_loss = 0.0701185925429979
Trained batch 204 in epoch 13, gen_loss = 0.40170505919107574, disc_loss = 0.06981404415081914
Trained batch 205 in epoch 13, gen_loss = 0.4017494630466387, disc_loss = 0.06961211126785978
Trained batch 206 in epoch 13, gen_loss = 0.40166547160217725, disc_loss = 0.06940530645908509
Trained batch 207 in epoch 13, gen_loss = 0.40209048628233945, disc_loss = 0.06940975769584139
Trained batch 208 in epoch 13, gen_loss = 0.4018416403298173, disc_loss = 0.06989162239250526
Trained batch 209 in epoch 13, gen_loss = 0.4020647058884303, disc_loss = 0.07039244798056427
Trained batch 210 in epoch 13, gen_loss = 0.40229507645159535, disc_loss = 0.07018466889240307
Trained batch 211 in epoch 13, gen_loss = 0.40228736428719647, disc_loss = 0.07040912182210891
Trained batch 212 in epoch 13, gen_loss = 0.4025883487132793, disc_loss = 0.07087851069570288
Trained batch 213 in epoch 13, gen_loss = 0.40266217569881513, disc_loss = 0.0706096545479774
Trained batch 214 in epoch 13, gen_loss = 0.40267928575360495, disc_loss = 0.0704079576832957
Trained batch 215 in epoch 13, gen_loss = 0.40272833848441086, disc_loss = 0.07015478324265806
Trained batch 216 in epoch 13, gen_loss = 0.4025898774922718, disc_loss = 0.06988336640723428
Trained batch 217 in epoch 13, gen_loss = 0.40247519888462274, disc_loss = 0.06982663289618192
Trained batch 218 in epoch 13, gen_loss = 0.40253819899471927, disc_loss = 0.0699956398244658
Trained batch 219 in epoch 13, gen_loss = 0.4023280467499386, disc_loss = 0.0697481010151519
Trained batch 220 in epoch 13, gen_loss = 0.4022578499975248, disc_loss = 0.06989638902230096
Trained batch 221 in epoch 13, gen_loss = 0.4026289043931274, disc_loss = 0.07080208554209487
Trained batch 222 in epoch 13, gen_loss = 0.4021592041302155, disc_loss = 0.07076021878992629
Trained batch 223 in epoch 13, gen_loss = 0.401938982440957, disc_loss = 0.07048002576837982
Trained batch 224 in epoch 13, gen_loss = 0.4018488174014621, disc_loss = 0.07024761428849564
Trained batch 225 in epoch 13, gen_loss = 0.40148756395926516, disc_loss = 0.0699755877907495
Trained batch 226 in epoch 13, gen_loss = 0.4011535150889258, disc_loss = 0.06994791234954206
Trained batch 227 in epoch 13, gen_loss = 0.40143775939941406, disc_loss = 0.06968693353497145
Trained batch 228 in epoch 13, gen_loss = 0.4013911116071143, disc_loss = 0.06946195150404258
Trained batch 229 in epoch 13, gen_loss = 0.401128437726394, disc_loss = 0.0693496441954504
Trained batch 230 in epoch 13, gen_loss = 0.40102979192486055, disc_loss = 0.06931780090805514
Trained batch 231 in epoch 13, gen_loss = 0.40075397054696904, disc_loss = 0.06988259661011398
Trained batch 232 in epoch 13, gen_loss = 0.40080917342026345, disc_loss = 0.0702607800440599
Trained batch 233 in epoch 13, gen_loss = 0.400704202743677, disc_loss = 0.07000110886640783
Trained batch 234 in epoch 13, gen_loss = 0.4007396301056476, disc_loss = 0.06975301185107612
Trained batch 235 in epoch 13, gen_loss = 0.4004403437345715, disc_loss = 0.06951659031101834
Trained batch 236 in epoch 13, gen_loss = 0.40020991767509073, disc_loss = 0.06940230046976593
Trained batch 237 in epoch 13, gen_loss = 0.40049142296574697, disc_loss = 0.06933702345734008
Trained batch 238 in epoch 13, gen_loss = 0.40061541543844853, disc_loss = 0.06907339784936302
Trained batch 239 in epoch 13, gen_loss = 0.40036991027494273, disc_loss = 0.06929412733685845
Trained batch 240 in epoch 13, gen_loss = 0.40063513425870556, disc_loss = 0.07057259699785734
Trained batch 241 in epoch 13, gen_loss = 0.40028412467684626, disc_loss = 0.07059881781912909
Trained batch 242 in epoch 13, gen_loss = 0.3998955372920252, disc_loss = 0.07076128515119783
Trained batch 243 in epoch 13, gen_loss = 0.39964711959244775, disc_loss = 0.0706201827756633
Trained batch 244 in epoch 13, gen_loss = 0.39944371240479604, disc_loss = 0.0703807967315827
Trained batch 245 in epoch 13, gen_loss = 0.39976937669079476, disc_loss = 0.07012715103952744
Trained batch 246 in epoch 13, gen_loss = 0.3999008973117782, disc_loss = 0.06998724384452047
Trained batch 247 in epoch 13, gen_loss = 0.399841439820105, disc_loss = 0.06973461566808363
Trained batch 248 in epoch 13, gen_loss = 0.39946090253481426, disc_loss = 0.06964507883407145
Trained batch 249 in epoch 13, gen_loss = 0.3993321920633316, disc_loss = 0.06949786819890141
Trained batch 250 in epoch 13, gen_loss = 0.3990650529642979, disc_loss = 0.06936600959054622
Trained batch 251 in epoch 13, gen_loss = 0.3994082998898294, disc_loss = 0.06917545485812875
Trained batch 252 in epoch 13, gen_loss = 0.3994549370330313, disc_loss = 0.06905192280696197
Trained batch 253 in epoch 13, gen_loss = 0.39963003359441684, disc_loss = 0.06942963426727361
Trained batch 254 in epoch 13, gen_loss = 0.399677039010852, disc_loss = 0.06986177087049274
Trained batch 255 in epoch 13, gen_loss = 0.39970661303959787, disc_loss = 0.06966527086842689
Trained batch 256 in epoch 13, gen_loss = 0.3997136557380513, disc_loss = 0.06951335888240008
Trained batch 257 in epoch 13, gen_loss = 0.3995244751373927, disc_loss = 0.06929521159767064
Trained batch 258 in epoch 13, gen_loss = 0.3995128415496193, disc_loss = 0.06905499084324047
Trained batch 259 in epoch 13, gen_loss = 0.3993618272818052, disc_loss = 0.06882454042788595
Trained batch 260 in epoch 13, gen_loss = 0.39933829711771557, disc_loss = 0.06857880203488687
Trained batch 261 in epoch 13, gen_loss = 0.39935106209671223, disc_loss = 0.06834053496282746
Trained batch 262 in epoch 13, gen_loss = 0.3991848287020346, disc_loss = 0.06862177315235364
Trained batch 263 in epoch 13, gen_loss = 0.3992716150753426, disc_loss = 0.07022815844693193
Trained batch 264 in epoch 13, gen_loss = 0.3991081683140881, disc_loss = 0.070379203564997
Trained batch 265 in epoch 13, gen_loss = 0.3990589360097297, disc_loss = 0.07056706304192767
Trained batch 266 in epoch 13, gen_loss = 0.399308743548304, disc_loss = 0.07068044994347328
Trained batch 267 in epoch 13, gen_loss = 0.39883689048574933, disc_loss = 0.07068789753812685
Trained batch 268 in epoch 13, gen_loss = 0.39866137471340846, disc_loss = 0.07063230415840796
Trained batch 269 in epoch 13, gen_loss = 0.3986287964714898, disc_loss = 0.07050608579345323
Trained batch 270 in epoch 13, gen_loss = 0.39846055490064447, disc_loss = 0.07034478707039708
Trained batch 271 in epoch 13, gen_loss = 0.39828378740040693, disc_loss = 0.07029348067418836
Trained batch 272 in epoch 13, gen_loss = 0.3981215164556608, disc_loss = 0.07028153056326585
Trained batch 273 in epoch 13, gen_loss = 0.39817175312633935, disc_loss = 0.07024321034142789
Trained batch 274 in epoch 13, gen_loss = 0.3981493854522705, disc_loss = 0.07040619146417487
Trained batch 275 in epoch 13, gen_loss = 0.3984447365653688, disc_loss = 0.07048323270662324
Trained batch 276 in epoch 13, gen_loss = 0.3985656332022877, disc_loss = 0.07025036757764834
Trained batch 277 in epoch 13, gen_loss = 0.3983790522856678, disc_loss = 0.07006976165199022
Trained batch 278 in epoch 13, gen_loss = 0.3982601518272072, disc_loss = 0.07033030332256389
Trained batch 279 in epoch 13, gen_loss = 0.39862716304404394, disc_loss = 0.07041548659492816
Trained batch 280 in epoch 13, gen_loss = 0.3991146267945232, disc_loss = 0.07020598653292953
Trained batch 281 in epoch 13, gen_loss = 0.39902286379472585, disc_loss = 0.07000924853264545
Trained batch 282 in epoch 13, gen_loss = 0.39911937113364254, disc_loss = 0.06979718987991237
Trained batch 283 in epoch 13, gen_loss = 0.39883196679219396, disc_loss = 0.06988236813766646
Trained batch 284 in epoch 13, gen_loss = 0.3991047130342115, disc_loss = 0.07037340237252544
Trained batch 285 in epoch 13, gen_loss = 0.39929801705000284, disc_loss = 0.0701801101872502
Trained batch 286 in epoch 13, gen_loss = 0.3991182962568795, disc_loss = 0.07020519252944388
Trained batch 287 in epoch 13, gen_loss = 0.3991931609602438, disc_loss = 0.07000940118127295
Trained batch 288 in epoch 13, gen_loss = 0.3991987615514379, disc_loss = 0.06992180509795677
Trained batch 289 in epoch 13, gen_loss = 0.3991592519242188, disc_loss = 0.06972415478065096
Trained batch 290 in epoch 13, gen_loss = 0.3991543291155825, disc_loss = 0.06984823942184448
Trained batch 291 in epoch 13, gen_loss = 0.3991476016705983, disc_loss = 0.07029773442916674
Trained batch 292 in epoch 13, gen_loss = 0.39899675420933617, disc_loss = 0.07025481259558387
Trained batch 293 in epoch 13, gen_loss = 0.39894895356934085, disc_loss = 0.07012599303710218
Trained batch 294 in epoch 13, gen_loss = 0.39889993657500056, disc_loss = 0.07000981304100004
Trained batch 295 in epoch 13, gen_loss = 0.3987782805956699, disc_loss = 0.07001700743126708
Trained batch 296 in epoch 13, gen_loss = 0.39835240634202157, disc_loss = 0.07017109053905564
Trained batch 297 in epoch 13, gen_loss = 0.398266281157532, disc_loss = 0.07025157585240051
Trained batch 298 in epoch 13, gen_loss = 0.3985885495326192, disc_loss = 0.07054922782059099
Trained batch 299 in epoch 13, gen_loss = 0.39843139072259265, disc_loss = 0.07197592924038569
Trained batch 300 in epoch 13, gen_loss = 0.39836405143389275, disc_loss = 0.07208660725145245
Trained batch 301 in epoch 13, gen_loss = 0.3984043685016253, disc_loss = 0.07211080669665969
Trained batch 302 in epoch 13, gen_loss = 0.398124633252424, disc_loss = 0.0719974688177455
Trained batch 303 in epoch 13, gen_loss = 0.3981928179334653, disc_loss = 0.07203709797345494
Trained batch 304 in epoch 13, gen_loss = 0.398294462239156, disc_loss = 0.07204212646503917
Trained batch 305 in epoch 13, gen_loss = 0.39822112208877514, disc_loss = 0.07185194967010247
Trained batch 306 in epoch 13, gen_loss = 0.39829465261499736, disc_loss = 0.07172901990917491
Trained batch 307 in epoch 13, gen_loss = 0.39840919021275134, disc_loss = 0.07191758311970474
Trained batch 308 in epoch 13, gen_loss = 0.3979589165607317, disc_loss = 0.07225542604127555
Trained batch 309 in epoch 13, gen_loss = 0.3982024996511398, disc_loss = 0.0721264079874081
Trained batch 310 in epoch 13, gen_loss = 0.3984730684488916, disc_loss = 0.07206495014585292
Trained batch 311 in epoch 13, gen_loss = 0.398386906259335, disc_loss = 0.0719221890426408
Trained batch 312 in epoch 13, gen_loss = 0.39834220959736516, disc_loss = 0.07196726505986799
Trained batch 313 in epoch 13, gen_loss = 0.3985479180790057, disc_loss = 0.07240849568443314
Trained batch 314 in epoch 13, gen_loss = 0.39863306917841473, disc_loss = 0.07245180863473151
Trained batch 315 in epoch 13, gen_loss = 0.3986566003553475, disc_loss = 0.0723010385585831
Trained batch 316 in epoch 13, gen_loss = 0.3985845100616431, disc_loss = 0.07241391374697256
Trained batch 317 in epoch 13, gen_loss = 0.39829461051608034, disc_loss = 0.07284741258869569
Trained batch 318 in epoch 13, gen_loss = 0.3985379644695868, disc_loss = 0.0732143267720564
Trained batch 319 in epoch 13, gen_loss = 0.3985398944467306, disc_loss = 0.07306447550072334
Trained batch 320 in epoch 13, gen_loss = 0.398219816224226, disc_loss = 0.07302855729847868
Trained batch 321 in epoch 13, gen_loss = 0.3981191997202287, disc_loss = 0.07284349735004839
Trained batch 322 in epoch 13, gen_loss = 0.39812050100081475, disc_loss = 0.0726996709047687
Trained batch 323 in epoch 13, gen_loss = 0.3982257084162147, disc_loss = 0.07250470149813702
Trained batch 324 in epoch 13, gen_loss = 0.3982779711026412, disc_loss = 0.07254019083025363
Trained batch 325 in epoch 13, gen_loss = 0.398241807895204, disc_loss = 0.07268024118548613
Trained batch 326 in epoch 13, gen_loss = 0.3982044164922988, disc_loss = 0.07257856584982861
Trained batch 327 in epoch 13, gen_loss = 0.39836636040268875, disc_loss = 0.07242644949327791
Trained batch 328 in epoch 13, gen_loss = 0.3984483072822942, disc_loss = 0.07237012422499232
Trained batch 329 in epoch 13, gen_loss = 0.3987359064998049, disc_loss = 0.07248141761925636
Trained batch 330 in epoch 13, gen_loss = 0.3987961670783351, disc_loss = 0.07260135418012333
Trained batch 331 in epoch 13, gen_loss = 0.39896944973124077, disc_loss = 0.07241203304918775
Trained batch 332 in epoch 13, gen_loss = 0.3989100090197257, disc_loss = 0.07226225474217275
Trained batch 333 in epoch 13, gen_loss = 0.398703260068408, disc_loss = 0.0720897570620486
Trained batch 334 in epoch 13, gen_loss = 0.3984443185044758, disc_loss = 0.07195994553170097
Trained batch 335 in epoch 13, gen_loss = 0.3985482527918759, disc_loss = 0.07181463013624861
Trained batch 336 in epoch 13, gen_loss = 0.3983935594381847, disc_loss = 0.07163182872372406
Trained batch 337 in epoch 13, gen_loss = 0.3982592218020964, disc_loss = 0.07156394570569932
Trained batch 338 in epoch 13, gen_loss = 0.3983681488529419, disc_loss = 0.07138817401047917
Trained batch 339 in epoch 13, gen_loss = 0.39852765255114614, disc_loss = 0.07130352946491364
Trained batch 340 in epoch 13, gen_loss = 0.3984503736419062, disc_loss = 0.0714561563405779
Trained batch 341 in epoch 13, gen_loss = 0.39851479580876426, disc_loss = 0.0716869365723466
Trained batch 342 in epoch 13, gen_loss = 0.3984054801415424, disc_loss = 0.071520599419843
Trained batch 343 in epoch 13, gen_loss = 0.3982828744622164, disc_loss = 0.07139510965667838
Trained batch 344 in epoch 13, gen_loss = 0.3981763286003168, disc_loss = 0.07121590821585362
Trained batch 345 in epoch 13, gen_loss = 0.39802491449551775, disc_loss = 0.07144757938124455
Trained batch 346 in epoch 13, gen_loss = 0.3980849938365156, disc_loss = 0.07129525362919233
Trained batch 347 in epoch 13, gen_loss = 0.39824424410003356, disc_loss = 0.07124451676051764
Trained batch 348 in epoch 13, gen_loss = 0.39814950188456427, disc_loss = 0.07152340904593382
Trained batch 349 in epoch 13, gen_loss = 0.39848324051925116, disc_loss = 0.07168809315721904
Trained batch 350 in epoch 13, gen_loss = 0.398457313195253, disc_loss = 0.07154088698996183
Trained batch 351 in epoch 13, gen_loss = 0.39837688571688806, disc_loss = 0.07138320378461768
Trained batch 352 in epoch 13, gen_loss = 0.39828816326414224, disc_loss = 0.07137662579936026
Trained batch 353 in epoch 13, gen_loss = 0.39822015839781466, disc_loss = 0.07119921961073149
Trained batch 354 in epoch 13, gen_loss = 0.3981005070914685, disc_loss = 0.0711169689264096
Trained batch 355 in epoch 13, gen_loss = 0.39799861710393025, disc_loss = 0.07131388329304336
Trained batch 356 in epoch 13, gen_loss = 0.3981083551374804, disc_loss = 0.0713420450186529
Trained batch 357 in epoch 13, gen_loss = 0.39838028237140377, disc_loss = 0.07154762187150604
Trained batch 358 in epoch 13, gen_loss = 0.3982295483599798, disc_loss = 0.07243381394981342
Trained batch 359 in epoch 13, gen_loss = 0.39843272467454277, disc_loss = 0.07261448784006966
Trained batch 360 in epoch 13, gen_loss = 0.39848344486175813, disc_loss = 0.07247277572647852
Trained batch 361 in epoch 13, gen_loss = 0.3982592085942379, disc_loss = 0.07255415791820591
Trained batch 362 in epoch 13, gen_loss = 0.39838421541797225, disc_loss = 0.0726208381057196
Trained batch 363 in epoch 13, gen_loss = 0.3986161559165179, disc_loss = 0.0724838446969023
Trained batch 364 in epoch 13, gen_loss = 0.3985714010996361, disc_loss = 0.07251991726560135
Trained batch 365 in epoch 13, gen_loss = 0.3986463574438147, disc_loss = 0.07244891374081862
Trained batch 366 in epoch 13, gen_loss = 0.39878577538017357, disc_loss = 0.07256223151729282
Trained batch 367 in epoch 13, gen_loss = 0.3986664202226245, disc_loss = 0.07267243477880307
Trained batch 368 in epoch 13, gen_loss = 0.398600078129833, disc_loss = 0.07258713948048227
Trained batch 369 in epoch 13, gen_loss = 0.3987822261211034, disc_loss = 0.07330148163679484
Trained batch 370 in epoch 13, gen_loss = 0.39882435382537124, disc_loss = 0.0731436399958847
Trained batch 371 in epoch 13, gen_loss = 0.39885549375446894, disc_loss = 0.0730410987230879
Trained batch 372 in epoch 13, gen_loss = 0.3989447820282494, disc_loss = 0.07297228837021234
Trained batch 373 in epoch 13, gen_loss = 0.3991606254628635, disc_loss = 0.07285910715314156
Trained batch 374 in epoch 13, gen_loss = 0.39912959361076356, disc_loss = 0.07269504537930091
Trained batch 375 in epoch 13, gen_loss = 0.3992052800319296, disc_loss = 0.07255443843190577
Trained batch 376 in epoch 13, gen_loss = 0.3990552106017459, disc_loss = 0.07239939628134355
Trained batch 377 in epoch 13, gen_loss = 0.3989700287895859, disc_loss = 0.07230299699401098
Trained batch 378 in epoch 13, gen_loss = 0.3988432005087115, disc_loss = 0.07242722170412698
Trained batch 379 in epoch 13, gen_loss = 0.3989811483966677, disc_loss = 0.07285888730303237
Trained batch 380 in epoch 13, gen_loss = 0.3991040553790065, disc_loss = 0.07286955918774517
Trained batch 381 in epoch 13, gen_loss = 0.3990092688674078, disc_loss = 0.07276940761202293
Trained batch 382 in epoch 13, gen_loss = 0.3990640483076828, disc_loss = 0.07274968733442047
Trained batch 383 in epoch 13, gen_loss = 0.3990575348337491, disc_loss = 0.07258903785259463
Trained batch 384 in epoch 13, gen_loss = 0.39892982089674317, disc_loss = 0.07246061347715266
Trained batch 385 in epoch 13, gen_loss = 0.3987241192802864, disc_loss = 0.07234193066164002
Trained batch 386 in epoch 13, gen_loss = 0.3989004324880989, disc_loss = 0.07267016609432778
Trained batch 387 in epoch 13, gen_loss = 0.3988474284865193, disc_loss = 0.07254086128560845
Trained batch 388 in epoch 13, gen_loss = 0.398610580319917, disc_loss = 0.07288947518541451
Trained batch 389 in epoch 13, gen_loss = 0.3987422954577666, disc_loss = 0.07281239120624004
Trained batch 390 in epoch 13, gen_loss = 0.39882131298179824, disc_loss = 0.07268857847318015
Trained batch 391 in epoch 13, gen_loss = 0.3987293568800907, disc_loss = 0.07258327969597006
Trained batch 392 in epoch 13, gen_loss = 0.398795035352537, disc_loss = 0.07246199492412517
Trained batch 393 in epoch 13, gen_loss = 0.39863416340750485, disc_loss = 0.0723145915772104
Trained batch 394 in epoch 13, gen_loss = 0.39863685565658763, disc_loss = 0.07218883354924148
Trained batch 395 in epoch 13, gen_loss = 0.3987667912034073, disc_loss = 0.07203343211475646
Trained batch 396 in epoch 13, gen_loss = 0.398823626470806, disc_loss = 0.0719295304493805
Trained batch 397 in epoch 13, gen_loss = 0.398787984970826, disc_loss = 0.07179474832967447
Trained batch 398 in epoch 13, gen_loss = 0.3986582296683376, disc_loss = 0.07168102151898663
Trained batch 399 in epoch 13, gen_loss = 0.3985767664760351, disc_loss = 0.0716411945456639
Trained batch 400 in epoch 13, gen_loss = 0.39860497047181737, disc_loss = 0.07147262913832195
Trained batch 401 in epoch 13, gen_loss = 0.39869014837255523, disc_loss = 0.07155194203485156
Trained batch 402 in epoch 13, gen_loss = 0.398476039431527, disc_loss = 0.07228534969572838
Trained batch 403 in epoch 13, gen_loss = 0.3985414786061438, disc_loss = 0.07217937801494309
Trained batch 404 in epoch 13, gen_loss = 0.3985994146193987, disc_loss = 0.07266936800270168
Trained batch 405 in epoch 13, gen_loss = 0.3985483933405336, disc_loss = 0.0730979407132773
Trained batch 406 in epoch 13, gen_loss = 0.3985516030606825, disc_loss = 0.07309093781694294
Trained batch 407 in epoch 13, gen_loss = 0.3986273830135663, disc_loss = 0.07332784817188832
Trained batch 408 in epoch 13, gen_loss = 0.3986672684003788, disc_loss = 0.07320731784920675
Trained batch 409 in epoch 13, gen_loss = 0.39840628926346944, disc_loss = 0.07351701479041722
Trained batch 410 in epoch 13, gen_loss = 0.3984061283061684, disc_loss = 0.07352923777253523
Trained batch 411 in epoch 13, gen_loss = 0.39847248611808983, disc_loss = 0.07340472725048228
Trained batch 412 in epoch 13, gen_loss = 0.39837547133678963, disc_loss = 0.07327934043802159
Trained batch 413 in epoch 13, gen_loss = 0.3983323666928471, disc_loss = 0.07315549034409333
Trained batch 414 in epoch 13, gen_loss = 0.3982891820281385, disc_loss = 0.07306842002793248
Trained batch 415 in epoch 13, gen_loss = 0.3984275533316227, disc_loss = 0.07292226336385983
Trained batch 416 in epoch 13, gen_loss = 0.3985308128581059, disc_loss = 0.07279507054476071
Trained batch 417 in epoch 13, gen_loss = 0.3984546689895922, disc_loss = 0.07268256769609152
Trained batch 418 in epoch 13, gen_loss = 0.39853776639287397, disc_loss = 0.07262672445467876
Trained batch 419 in epoch 13, gen_loss = 0.3985031996454511, disc_loss = 0.07247123437090999
Trained batch 420 in epoch 13, gen_loss = 0.398494345983247, disc_loss = 0.07235742886406933
Trained batch 421 in epoch 13, gen_loss = 0.3985921278666546, disc_loss = 0.07221446564571128
Trained batch 422 in epoch 13, gen_loss = 0.3986202137408245, disc_loss = 0.07224570271552455
Trained batch 423 in epoch 13, gen_loss = 0.3984517400275986, disc_loss = 0.07287278726152233
Trained batch 424 in epoch 13, gen_loss = 0.3984467941873214, disc_loss = 0.07283245076589724
Trained batch 425 in epoch 13, gen_loss = 0.3984312803392679, disc_loss = 0.07294158330143477
Trained batch 426 in epoch 13, gen_loss = 0.39845912273650425, disc_loss = 0.07281702673564332
Trained batch 427 in epoch 13, gen_loss = 0.3984305392776694, disc_loss = 0.0727044460537765
Trained batch 428 in epoch 13, gen_loss = 0.39809766724393086, disc_loss = 0.07262640376521018
Trained batch 429 in epoch 13, gen_loss = 0.3980799742909365, disc_loss = 0.07255956419245448
Trained batch 430 in epoch 13, gen_loss = 0.3980600773043533, disc_loss = 0.07241221417493582
Trained batch 431 in epoch 13, gen_loss = 0.39797875636981594, disc_loss = 0.07233315920543477
Trained batch 432 in epoch 13, gen_loss = 0.39792636085052135, disc_loss = 0.07221070341507778
Trained batch 433 in epoch 13, gen_loss = 0.3977054532634498, disc_loss = 0.07212115387316398
Trained batch 434 in epoch 13, gen_loss = 0.3977344362900175, disc_loss = 0.07198914468031505
Trained batch 435 in epoch 13, gen_loss = 0.39777518255174704, disc_loss = 0.07210468499570949
Trained batch 436 in epoch 13, gen_loss = 0.3975170800969584, disc_loss = 0.07223597119905446
Trained batch 437 in epoch 13, gen_loss = 0.39752018220348445, disc_loss = 0.07214142479955062
Trained batch 438 in epoch 13, gen_loss = 0.3975734734453753, disc_loss = 0.07209487323031882
Trained batch 439 in epoch 13, gen_loss = 0.39762197170745245, disc_loss = 0.07197149100882763
Trained batch 440 in epoch 13, gen_loss = 0.39754745479073383, disc_loss = 0.07192909653782169
Trained batch 441 in epoch 13, gen_loss = 0.39762212288865134, disc_loss = 0.07184039788295375
Trained batch 442 in epoch 13, gen_loss = 0.3974669772803649, disc_loss = 0.07171162838877324
Trained batch 443 in epoch 13, gen_loss = 0.3972976118460432, disc_loss = 0.07161832982590338
Trained batch 444 in epoch 13, gen_loss = 0.3973642550157697, disc_loss = 0.07148477826058194
Trained batch 445 in epoch 13, gen_loss = 0.3973135905415488, disc_loss = 0.07137013681967964
Trained batch 446 in epoch 13, gen_loss = 0.39736614317968655, disc_loss = 0.07127595889971694
Trained batch 447 in epoch 13, gen_loss = 0.3975611951069108, disc_loss = 0.07131837110916552
Trained batch 448 in epoch 13, gen_loss = 0.39757438179910315, disc_loss = 0.07120644944182748
Trained batch 449 in epoch 13, gen_loss = 0.39761155333783893, disc_loss = 0.07114596518377463
Trained batch 450 in epoch 13, gen_loss = 0.3974313063922848, disc_loss = 0.07122333855791525
Trained batch 451 in epoch 13, gen_loss = 0.3976523307176818, disc_loss = 0.07112166111613005
Trained batch 452 in epoch 13, gen_loss = 0.3979135265545077, disc_loss = 0.07133033645501727
Trained batch 453 in epoch 13, gen_loss = 0.3977970402146226, disc_loss = 0.07133754003907877
Trained batch 454 in epoch 13, gen_loss = 0.39782200357416175, disc_loss = 0.07120318974030541
Trained batch 455 in epoch 13, gen_loss = 0.39772342341510875, disc_loss = 0.07114363072456367
Trained batch 456 in epoch 13, gen_loss = 0.39772351219826246, disc_loss = 0.07143664982422566
Trained batch 457 in epoch 13, gen_loss = 0.3978012521714623, disc_loss = 0.07181981716337553
Trained batch 458 in epoch 13, gen_loss = 0.3976787320279348, disc_loss = 0.0718902850681855
Trained batch 459 in epoch 13, gen_loss = 0.39762869898391806, disc_loss = 0.07191704378422836
Trained batch 460 in epoch 13, gen_loss = 0.3977789887895812, disc_loss = 0.0718416523899471
Testing Epoch 13
Training Epoch 14
Trained batch 0 in epoch 14, gen_loss = 0.3996790945529938, disc_loss = 0.05804886668920517
Trained batch 1 in epoch 14, gen_loss = 0.39235422015190125, disc_loss = 0.048537109047174454
Trained batch 2 in epoch 14, gen_loss = 0.4000293513139089, disc_loss = 0.044630383451779686
Trained batch 3 in epoch 14, gen_loss = 0.3980652093887329, disc_loss = 0.039344281889498234
Trained batch 4 in epoch 14, gen_loss = 0.39870419502258303, disc_loss = 0.042088297009468076
Trained batch 5 in epoch 14, gen_loss = 0.40513384838898975, disc_loss = 0.03987962193787098
Trained batch 6 in epoch 14, gen_loss = 0.40280901959964205, disc_loss = 0.037188456526824405
Trained batch 7 in epoch 14, gen_loss = 0.4109339900314808, disc_loss = 0.03689313167706132
Trained batch 8 in epoch 14, gen_loss = 0.4115685058964623, disc_loss = 0.03630261537101534
Trained batch 9 in epoch 14, gen_loss = 0.4129841536283493, disc_loss = 0.03343478487804532
Trained batch 10 in epoch 14, gen_loss = 0.4136318970810283, disc_loss = 0.03386091280051253
Trained batch 11 in epoch 14, gen_loss = 0.4160614535212517, disc_loss = 0.03164127212949097
Trained batch 12 in epoch 14, gen_loss = 0.41303391181505644, disc_loss = 0.03231787903664204
Trained batch 13 in epoch 14, gen_loss = 0.4084311063800539, disc_loss = 0.059146476576903036
Trained batch 14 in epoch 14, gen_loss = 0.41211453080177307, disc_loss = 0.06297276311864455
Trained batch 15 in epoch 14, gen_loss = 0.4124153833836317, disc_loss = 0.06070374738192186
Trained batch 16 in epoch 14, gen_loss = 0.41180872391251955, disc_loss = 0.05989367114927839
Trained batch 17 in epoch 14, gen_loss = 0.41550203661123913, disc_loss = 0.0571487289853394
Trained batch 18 in epoch 14, gen_loss = 0.4225129500815743, disc_loss = 0.05548218956315204
Trained batch 19 in epoch 14, gen_loss = 0.4196547791361809, disc_loss = 0.05365877994336188
Trained batch 20 in epoch 14, gen_loss = 0.4189815634772891, disc_loss = 0.051665507656122954
Trained batch 21 in epoch 14, gen_loss = 0.41587466543371027, disc_loss = 0.05128163391385566
Trained batch 22 in epoch 14, gen_loss = 0.4194408499676248, disc_loss = 0.05061339542431676
Trained batch 23 in epoch 14, gen_loss = 0.421823401004076, disc_loss = 0.050899701697441437
Trained batch 24 in epoch 14, gen_loss = 0.4195102381706238, disc_loss = 0.0556330769136548
Trained batch 25 in epoch 14, gen_loss = 0.4210475729062007, disc_loss = 0.05756099797928563
Trained batch 26 in epoch 14, gen_loss = 0.42295611677346406, disc_loss = 0.05583075523652412
Trained batch 27 in epoch 14, gen_loss = 0.42393031822783606, disc_loss = 0.054058191599324346
Trained batch 28 in epoch 14, gen_loss = 0.42388052981475305, disc_loss = 0.0525082459930202
Trained batch 29 in epoch 14, gen_loss = 0.42352982560793556, disc_loss = 0.05100545985624194
Trained batch 30 in epoch 14, gen_loss = 0.4218935255081423, disc_loss = 0.04968742046865725
Trained batch 31 in epoch 14, gen_loss = 0.4199237432330847, disc_loss = 0.04855518642580137
Trained batch 32 in epoch 14, gen_loss = 0.4190701399788712, disc_loss = 0.048127589295759346
Trained batch 33 in epoch 14, gen_loss = 0.418877033626332, disc_loss = 0.047453200718497526
Trained batch 34 in epoch 14, gen_loss = 0.4193642454487937, disc_loss = 0.0497622333999191
Trained batch 35 in epoch 14, gen_loss = 0.4157417110270924, disc_loss = 0.055027538858768016
Trained batch 36 in epoch 14, gen_loss = 0.41713080535063873, disc_loss = 0.05484387253385943
Trained batch 37 in epoch 14, gen_loss = 0.4184762772760893, disc_loss = 0.054403609890294705
Trained batch 38 in epoch 14, gen_loss = 0.4162940642772577, disc_loss = 0.0532283905463723
Trained batch 39 in epoch 14, gen_loss = 0.4144209049642086, disc_loss = 0.053443486266769466
Trained batch 40 in epoch 14, gen_loss = 0.41429718965437357, disc_loss = 0.05242456379914429
Trained batch 41 in epoch 14, gen_loss = 0.4154672274986903, disc_loss = 0.051846879600946395
Trained batch 42 in epoch 14, gen_loss = 0.4148595353891683, disc_loss = 0.053273979682735235
Trained batch 43 in epoch 14, gen_loss = 0.41595912115140393, disc_loss = 0.05509369246746329
Trained batch 44 in epoch 14, gen_loss = 0.4158209906684028, disc_loss = 0.0552008593454957
Trained batch 45 in epoch 14, gen_loss = 0.4149813541899557, disc_loss = 0.055900888699714255
Trained batch 46 in epoch 14, gen_loss = 0.41640957048598753, disc_loss = 0.05808048182107667
Trained batch 47 in epoch 14, gen_loss = 0.41632750754555065, disc_loss = 0.0570526349862727
Trained batch 48 in epoch 14, gen_loss = 0.4158738790726175, disc_loss = 0.05612350418707546
Trained batch 49 in epoch 14, gen_loss = 0.4148281389474869, disc_loss = 0.05536994989961386
Trained batch 50 in epoch 14, gen_loss = 0.4143296743140501, disc_loss = 0.05448370768378178
Trained batch 51 in epoch 14, gen_loss = 0.4150636070049726, disc_loss = 0.05357680618404769
Trained batch 52 in epoch 14, gen_loss = 0.41459951985557125, disc_loss = 0.0533985578332026
Trained batch 53 in epoch 14, gen_loss = 0.4131593969133165, disc_loss = 0.05387274436307726
Trained batch 54 in epoch 14, gen_loss = 0.4117124351588162, disc_loss = 0.054844367351721636
Trained batch 55 in epoch 14, gen_loss = 0.41101787398968426, disc_loss = 0.05738717994453119
Trained batch 56 in epoch 14, gen_loss = 0.41168178591811866, disc_loss = 0.05795383268738525
Trained batch 57 in epoch 14, gen_loss = 0.4124976843595505, disc_loss = 0.057826482385782335
Trained batch 58 in epoch 14, gen_loss = 0.41216897206791375, disc_loss = 0.05737050507470208
Trained batch 59 in epoch 14, gen_loss = 0.4110494847098986, disc_loss = 0.05691111381165683
Trained batch 60 in epoch 14, gen_loss = 0.4108139672240273, disc_loss = 0.05652764984635544
Trained batch 61 in epoch 14, gen_loss = 0.4104791610471664, disc_loss = 0.055845995148223256
Trained batch 62 in epoch 14, gen_loss = 0.40894175238079494, disc_loss = 0.05749532561157904
Trained batch 63 in epoch 14, gen_loss = 0.4093873305246234, disc_loss = 0.05800987179100048
Trained batch 64 in epoch 14, gen_loss = 0.40879418758245617, disc_loss = 0.05764740749907035
Trained batch 65 in epoch 14, gen_loss = 0.40742364977345324, disc_loss = 0.0580958152669623
Trained batch 66 in epoch 14, gen_loss = 0.4085953057701908, disc_loss = 0.05825558158833144
Trained batch 67 in epoch 14, gen_loss = 0.40812313863459754, disc_loss = 0.05755133079090977
Trained batch 68 in epoch 14, gen_loss = 0.4076761391715727, disc_loss = 0.057513169633845486
Trained batch 69 in epoch 14, gen_loss = 0.40838408853326524, disc_loss = 0.058050723812942
Trained batch 70 in epoch 14, gen_loss = 0.40789343227802866, disc_loss = 0.05732799676889685
Trained batch 71 in epoch 14, gen_loss = 0.4076962015695042, disc_loss = 0.05712459923233837
Trained batch 72 in epoch 14, gen_loss = 0.40711397544978417, disc_loss = 0.05701790350706202
Trained batch 73 in epoch 14, gen_loss = 0.40808195721458745, disc_loss = 0.05669542843777988
Trained batch 74 in epoch 14, gen_loss = 0.40767807126045225, disc_loss = 0.056732593762377895
Trained batch 75 in epoch 14, gen_loss = 0.4070990262062926, disc_loss = 0.059487248709621396
Trained batch 76 in epoch 14, gen_loss = 0.40731060388800383, disc_loss = 0.058947061309469986
Trained batch 77 in epoch 14, gen_loss = 0.4080074299604465, disc_loss = 0.05901751909643794
Trained batch 78 in epoch 14, gen_loss = 0.40776452837111077, disc_loss = 0.05867717729857828
Trained batch 79 in epoch 14, gen_loss = 0.4065430764108896, disc_loss = 0.058215024264063685
Trained batch 80 in epoch 14, gen_loss = 0.4061000762898245, disc_loss = 0.05793752414346845
Trained batch 81 in epoch 14, gen_loss = 0.4052361729668408, disc_loss = 0.05738621712775856
Trained batch 82 in epoch 14, gen_loss = 0.4048808568931488, disc_loss = 0.056899027304207705
Trained batch 83 in epoch 14, gen_loss = 0.404628754726478, disc_loss = 0.056324990200144906
Trained batch 84 in epoch 14, gen_loss = 0.40460491916712593, disc_loss = 0.0557134455508169
Trained batch 85 in epoch 14, gen_loss = 0.4041055932987568, disc_loss = 0.055501294116554564
Trained batch 86 in epoch 14, gen_loss = 0.4044476168594141, disc_loss = 0.0560463307553838
Trained batch 87 in epoch 14, gen_loss = 0.40294829349626193, disc_loss = 0.056926191562194035
Trained batch 88 in epoch 14, gen_loss = 0.4032428626264079, disc_loss = 0.05671698306006997
Trained batch 89 in epoch 14, gen_loss = 0.40323049823443097, disc_loss = 0.05748617002326581
Trained batch 90 in epoch 14, gen_loss = 0.4037782445058718, disc_loss = 0.058751293417107275
Trained batch 91 in epoch 14, gen_loss = 0.40361184562030045, disc_loss = 0.058385014078458364
Trained batch 92 in epoch 14, gen_loss = 0.403341422798813, disc_loss = 0.058081135784666386
Trained batch 93 in epoch 14, gen_loss = 0.4041030010644426, disc_loss = 0.05775781137313932
Trained batch 94 in epoch 14, gen_loss = 0.4044446593836734, disc_loss = 0.057353506639207665
Trained batch 95 in epoch 14, gen_loss = 0.4043405506139, disc_loss = 0.05701805145751374
Trained batch 96 in epoch 14, gen_loss = 0.40364988685883196, disc_loss = 0.056539195800949
Trained batch 97 in epoch 14, gen_loss = 0.4034160494196172, disc_loss = 0.05670964331081023
Trained batch 98 in epoch 14, gen_loss = 0.403759476813403, disc_loss = 0.05866992873412491
Trained batch 99 in epoch 14, gen_loss = 0.4032563814520836, disc_loss = 0.0597601876500994
Trained batch 100 in epoch 14, gen_loss = 0.40239893416366956, disc_loss = 0.06003309617575148
Trained batch 101 in epoch 14, gen_loss = 0.40187182847191305, disc_loss = 0.05969993590249443
Trained batch 102 in epoch 14, gen_loss = 0.40174180790058617, disc_loss = 0.05923420466591143
Trained batch 103 in epoch 14, gen_loss = 0.4015672834446797, disc_loss = 0.058821613049636096
Trained batch 104 in epoch 14, gen_loss = 0.40166693670409065, disc_loss = 0.05842586015129373
Trained batch 105 in epoch 14, gen_loss = 0.4021360927595283, disc_loss = 0.058065439108759165
Trained batch 106 in epoch 14, gen_loss = 0.40187686932421174, disc_loss = 0.05840768784319408
Trained batch 107 in epoch 14, gen_loss = 0.40250871385689135, disc_loss = 0.06036291506865786
Trained batch 108 in epoch 14, gen_loss = 0.4021281701162321, disc_loss = 0.06025074307012175
Trained batch 109 in epoch 14, gen_loss = 0.4019608657468449, disc_loss = 0.06028189212930474
Trained batch 110 in epoch 14, gen_loss = 0.40176866559294966, disc_loss = 0.06060385530361453
Trained batch 111 in epoch 14, gen_loss = 0.4022259823977947, disc_loss = 0.060147732321638614
Trained batch 112 in epoch 14, gen_loss = 0.4018036855005585, disc_loss = 0.060255294838771886
Trained batch 113 in epoch 14, gen_loss = 0.40202584888851434, disc_loss = 0.06093729701579401
Trained batch 114 in epoch 14, gen_loss = 0.4026926100254059, disc_loss = 0.060723640178532705
Trained batch 115 in epoch 14, gen_loss = 0.40280009472164613, disc_loss = 0.06035060449182216
Trained batch 116 in epoch 14, gen_loss = 0.4023776576559768, disc_loss = 0.06001116266139807
Trained batch 117 in epoch 14, gen_loss = 0.4026162990574109, disc_loss = 0.05971702957778412
Trained batch 118 in epoch 14, gen_loss = 0.40261891208776907, disc_loss = 0.059814073200173234
Trained batch 119 in epoch 14, gen_loss = 0.4018078804016113, disc_loss = 0.059582722396589814
Trained batch 120 in epoch 14, gen_loss = 0.40226466990699455, disc_loss = 0.05943928516569955
Trained batch 121 in epoch 14, gen_loss = 0.40182310806923227, disc_loss = 0.0603599212987379
Trained batch 122 in epoch 14, gen_loss = 0.40234717629789335, disc_loss = 0.06033057197776994
Trained batch 123 in epoch 14, gen_loss = 0.40237474273289403, disc_loss = 0.05992744734600907
Trained batch 124 in epoch 14, gen_loss = 0.40252497601509096, disc_loss = 0.05950473458319903
Trained batch 125 in epoch 14, gen_loss = 0.4028683103739269, disc_loss = 0.059313757529866604
Trained batch 126 in epoch 14, gen_loss = 0.4043001131279262, disc_loss = 0.05900997943501538
Trained batch 127 in epoch 14, gen_loss = 0.40384756913408637, disc_loss = 0.05868038092012284
Trained batch 128 in epoch 14, gen_loss = 0.40317926942840104, disc_loss = 0.05881455054781003
Trained batch 129 in epoch 14, gen_loss = 0.40356499140079205, disc_loss = 0.058905062416138555
Trained batch 130 in epoch 14, gen_loss = 0.40328435656678585, disc_loss = 0.05959616123009046
Trained batch 131 in epoch 14, gen_loss = 0.4037418846379627, disc_loss = 0.059222243719198035
Trained batch 132 in epoch 14, gen_loss = 0.4040460875607971, disc_loss = 0.060368581366886324
Trained batch 133 in epoch 14, gen_loss = 0.40349503884564586, disc_loss = 0.0632394187416492
Trained batch 134 in epoch 14, gen_loss = 0.4041943426485415, disc_loss = 0.06343751537992999
Trained batch 135 in epoch 14, gen_loss = 0.4041164228144814, disc_loss = 0.06332709962803432
Trained batch 136 in epoch 14, gen_loss = 0.4039425201659655, disc_loss = 0.06300527060635551
Trained batch 137 in epoch 14, gen_loss = 0.4040477033974468, disc_loss = 0.06269044790120012
Trained batch 138 in epoch 14, gen_loss = 0.404038712275114, disc_loss = 0.06277054863841199
Trained batch 139 in epoch 14, gen_loss = 0.4033833893282073, disc_loss = 0.06373663528024086
Trained batch 140 in epoch 14, gen_loss = 0.40363479421493853, disc_loss = 0.06346467403523254
Trained batch 141 in epoch 14, gen_loss = 0.40373656405529507, disc_loss = 0.06340564610961248
Trained batch 142 in epoch 14, gen_loss = 0.4033261081138691, disc_loss = 0.06323076377564169
Trained batch 143 in epoch 14, gen_loss = 0.40315600919226807, disc_loss = 0.06295138184214011
Trained batch 144 in epoch 14, gen_loss = 0.40307595812041186, disc_loss = 0.06262060640829391
Trained batch 145 in epoch 14, gen_loss = 0.4027403662466023, disc_loss = 0.06239360681262939
Trained batch 146 in epoch 14, gen_loss = 0.40305733721272474, disc_loss = 0.062056775699008485
Trained batch 147 in epoch 14, gen_loss = 0.403213055552663, disc_loss = 0.061744177758039254
Trained batch 148 in epoch 14, gen_loss = 0.40309877883667916, disc_loss = 0.06162907065036113
Trained batch 149 in epoch 14, gen_loss = 0.4030017654101054, disc_loss = 0.06134948837881287
Trained batch 150 in epoch 14, gen_loss = 0.4035051792662665, disc_loss = 0.06097038278343859
Trained batch 151 in epoch 14, gen_loss = 0.40342311992457036, disc_loss = 0.06072831566224953
Trained batch 152 in epoch 14, gen_loss = 0.4036387916094337, disc_loss = 0.061356332865269744
Trained batch 153 in epoch 14, gen_loss = 0.403619800101627, disc_loss = 0.061322212854230944
Trained batch 154 in epoch 14, gen_loss = 0.4041157066822052, disc_loss = 0.06101279359671377
Trained batch 155 in epoch 14, gen_loss = 0.4036974018582931, disc_loss = 0.061986757251314625
Trained batch 156 in epoch 14, gen_loss = 0.4043322442823155, disc_loss = 0.062261204953026617
Trained batch 157 in epoch 14, gen_loss = 0.40431418750859516, disc_loss = 0.06211126147757603
Trained batch 158 in epoch 14, gen_loss = 0.40406998111017095, disc_loss = 0.06191521457765462
Trained batch 159 in epoch 14, gen_loss = 0.40396362617611886, disc_loss = 0.061822934413794425
Trained batch 160 in epoch 14, gen_loss = 0.4038040750885602, disc_loss = 0.06152178430987626
Trained batch 161 in epoch 14, gen_loss = 0.40352823631263074, disc_loss = 0.06135668813101487
Trained batch 162 in epoch 14, gen_loss = 0.40334435803758584, disc_loss = 0.06108111504785305
Trained batch 163 in epoch 14, gen_loss = 0.40297409964770803, disc_loss = 0.06078085610529453
Trained batch 164 in epoch 14, gen_loss = 0.40269369699738244, disc_loss = 0.06047290458033482
Trained batch 165 in epoch 14, gen_loss = 0.4025861136166446, disc_loss = 0.06050295134198414
Trained batch 166 in epoch 14, gen_loss = 0.40322591230540933, disc_loss = 0.06117307500144143
Trained batch 167 in epoch 14, gen_loss = 0.4036492400226139, disc_loss = 0.06085834601738801
Trained batch 168 in epoch 14, gen_loss = 0.40330937786920534, disc_loss = 0.06067376529257855
Trained batch 169 in epoch 14, gen_loss = 0.4035010244916467, disc_loss = 0.061191294939421555
Trained batch 170 in epoch 14, gen_loss = 0.4035890773374435, disc_loss = 0.06450143729320221
Trained batch 171 in epoch 14, gen_loss = 0.40361093747061355, disc_loss = 0.06425755630723785
Trained batch 172 in epoch 14, gen_loss = 0.4037120881452726, disc_loss = 0.0644807414544714
Trained batch 173 in epoch 14, gen_loss = 0.4037296112583972, disc_loss = 0.06439311245199421
Trained batch 174 in epoch 14, gen_loss = 0.4036544678892408, disc_loss = 0.06427939610289676
Trained batch 175 in epoch 14, gen_loss = 0.403092217377641, disc_loss = 0.06440833053784445
Trained batch 176 in epoch 14, gen_loss = 0.4030672879205585, disc_loss = 0.06430448580659547
Trained batch 177 in epoch 14, gen_loss = 0.402931754508715, disc_loss = 0.0640779283222104
Trained batch 178 in epoch 14, gen_loss = 0.4027557812589507, disc_loss = 0.06402369804534666
Trained batch 179 in epoch 14, gen_loss = 0.40288653208149805, disc_loss = 0.06391412395880454
Trained batch 180 in epoch 14, gen_loss = 0.4029005179747692, disc_loss = 0.06366527417561461
Trained batch 181 in epoch 14, gen_loss = 0.40328358064641007, disc_loss = 0.06530224253003905
Trained batch 182 in epoch 14, gen_loss = 0.4031371628977562, disc_loss = 0.06801809435150499
Trained batch 183 in epoch 14, gen_loss = 0.4031526281133942, disc_loss = 0.06815515385191563
Trained batch 184 in epoch 14, gen_loss = 0.40362185400885503, disc_loss = 0.06888576826030338
Trained batch 185 in epoch 14, gen_loss = 0.4034687637962321, disc_loss = 0.06897537810327385
Trained batch 186 in epoch 14, gen_loss = 0.4029591062808419, disc_loss = 0.06880347438176526
Trained batch 187 in epoch 14, gen_loss = 0.40241322032314664, disc_loss = 0.06882273833307022
Trained batch 188 in epoch 14, gen_loss = 0.402389501610761, disc_loss = 0.0693280554115378
Trained batch 189 in epoch 14, gen_loss = 0.40228187661421927, disc_loss = 0.06980605783725255
Trained batch 190 in epoch 14, gen_loss = 0.4020949182398032, disc_loss = 0.0701874769902276
Trained batch 191 in epoch 14, gen_loss = 0.4017825808065633, disc_loss = 0.07018519790047624
Trained batch 192 in epoch 14, gen_loss = 0.4015586564577923, disc_loss = 0.069891717000213
Trained batch 193 in epoch 14, gen_loss = 0.40130785891075726, disc_loss = 0.06960719538199686
Trained batch 194 in epoch 14, gen_loss = 0.4011610876291226, disc_loss = 0.06947710002557589
Trained batch 195 in epoch 14, gen_loss = 0.40128883232875745, disc_loss = 0.06980233442285383
Trained batch 196 in epoch 14, gen_loss = 0.40150309304900583, disc_loss = 0.07070015038500733
Trained batch 197 in epoch 14, gen_loss = 0.401189880238639, disc_loss = 0.07081741076245
Trained batch 198 in epoch 14, gen_loss = 0.4019163319812947, disc_loss = 0.072866135623175
Trained batch 199 in epoch 14, gen_loss = 0.40159769982099536, disc_loss = 0.07263606486376376
Trained batch 200 in epoch 14, gen_loss = 0.4012410987668963, disc_loss = 0.07301286639024814
Trained batch 201 in epoch 14, gen_loss = 0.40131728188826304, disc_loss = 0.07276940720598443
Trained batch 202 in epoch 14, gen_loss = 0.4013681367700323, disc_loss = 0.07257366784632646
Trained batch 203 in epoch 14, gen_loss = 0.40139271055950837, disc_loss = 0.07227135188968889
Trained batch 204 in epoch 14, gen_loss = 0.40131569344822954, disc_loss = 0.0723662833478756
Trained batch 205 in epoch 14, gen_loss = 0.4011110831232904, disc_loss = 0.07219515808234081
Trained batch 206 in epoch 14, gen_loss = 0.4013534014063757, disc_loss = 0.07192882050980548
Trained batch 207 in epoch 14, gen_loss = 0.40154677027693164, disc_loss = 0.07166367805509183
Trained batch 208 in epoch 14, gen_loss = 0.4015516044135299, disc_loss = 0.07142694406300498
Trained batch 209 in epoch 14, gen_loss = 0.4014434935081573, disc_loss = 0.07132165791644227
Trained batch 210 in epoch 14, gen_loss = 0.4013970283817906, disc_loss = 0.07157616046703116
Trained batch 211 in epoch 14, gen_loss = 0.4008352388188524, disc_loss = 0.07310140924967544
Trained batch 212 in epoch 14, gen_loss = 0.4009077830213896, disc_loss = 0.07322564995257368
Trained batch 213 in epoch 14, gen_loss = 0.4010700860591692, disc_loss = 0.07317447987446021
Trained batch 214 in epoch 14, gen_loss = 0.40078571411066277, disc_loss = 0.07320055983700724
Trained batch 215 in epoch 14, gen_loss = 0.40061488982152055, disc_loss = 0.07301466921948034
Trained batch 216 in epoch 14, gen_loss = 0.4008247405977293, disc_loss = 0.07281118030938823
Trained batch 217 in epoch 14, gen_loss = 0.4006483304664629, disc_loss = 0.07261522434258816
Trained batch 218 in epoch 14, gen_loss = 0.40058261251340715, disc_loss = 0.07240930688248513
Trained batch 219 in epoch 14, gen_loss = 0.40066616494547236, disc_loss = 0.07332083866084842
Trained batch 220 in epoch 14, gen_loss = 0.3999282079854163, disc_loss = 0.07424130117545975
Trained batch 221 in epoch 14, gen_loss = 0.3999571366621567, disc_loss = 0.07422541164549755
Trained batch 222 in epoch 14, gen_loss = 0.4003657991308802, disc_loss = 0.07411527151300368
Trained batch 223 in epoch 14, gen_loss = 0.4004154451457517, disc_loss = 0.07410427657305263
Trained batch 224 in epoch 14, gen_loss = 0.40071119401190014, disc_loss = 0.07391617724051078
Trained batch 225 in epoch 14, gen_loss = 0.40055378308865874, disc_loss = 0.07373781613098969
Trained batch 226 in epoch 14, gen_loss = 0.40047539869069004, disc_loss = 0.07351970005911747
Trained batch 227 in epoch 14, gen_loss = 0.4003243839793038, disc_loss = 0.07327953698685426
Trained batch 228 in epoch 14, gen_loss = 0.4001179241197078, disc_loss = 0.07314139102304996
Trained batch 229 in epoch 14, gen_loss = 0.39978274780771006, disc_loss = 0.07299723747064886
Trained batch 230 in epoch 14, gen_loss = 0.399761329481612, disc_loss = 0.07270115538544598
Trained batch 231 in epoch 14, gen_loss = 0.39988211054226447, disc_loss = 0.07269133147703291
Trained batch 232 in epoch 14, gen_loss = 0.39972024209509593, disc_loss = 0.07403481577806846
Trained batch 233 in epoch 14, gen_loss = 0.3997919046216541, disc_loss = 0.07405835672273722
Trained batch 234 in epoch 14, gen_loss = 0.39961697357766174, disc_loss = 0.07397630140581664
Trained batch 235 in epoch 14, gen_loss = 0.39988817009380306, disc_loss = 0.07396440184675157
Trained batch 236 in epoch 14, gen_loss = 0.40002614536365877, disc_loss = 0.07375204739581306
Trained batch 237 in epoch 14, gen_loss = 0.400135408053879, disc_loss = 0.07352146735227033
Trained batch 238 in epoch 14, gen_loss = 0.40008824203303667, disc_loss = 0.07357546447476208
Trained batch 239 in epoch 14, gen_loss = 0.4001602377742529, disc_loss = 0.07347179834808533
Trained batch 240 in epoch 14, gen_loss = 0.4000067588451987, disc_loss = 0.07331015817681907
Trained batch 241 in epoch 14, gen_loss = 0.4002871869270467, disc_loss = 0.07322275295684283
Trained batch 242 in epoch 14, gen_loss = 0.4009363051549888, disc_loss = 0.07405091400944279
Trained batch 243 in epoch 14, gen_loss = 0.40059718685071977, disc_loss = 0.0741806318716253
Trained batch 244 in epoch 14, gen_loss = 0.40053432717615245, disc_loss = 0.07406721319243008
Trained batch 245 in epoch 14, gen_loss = 0.4005755236962946, disc_loss = 0.07395587039626832
Trained batch 246 in epoch 14, gen_loss = 0.40040665430578626, disc_loss = 0.07367653484920017
Trained batch 247 in epoch 14, gen_loss = 0.4007072602548907, disc_loss = 0.07344838406800502
Trained batch 248 in epoch 14, gen_loss = 0.4009229892707733, disc_loss = 0.0732516210496306
Trained batch 249 in epoch 14, gen_loss = 0.4010669469833374, disc_loss = 0.07303536079078912
Trained batch 250 in epoch 14, gen_loss = 0.4007632408246576, disc_loss = 0.07287315612443653
Trained batch 251 in epoch 14, gen_loss = 0.400391587425792, disc_loss = 0.07320111603402192
Trained batch 252 in epoch 14, gen_loss = 0.40050610581876733, disc_loss = 0.07346992969895776
Trained batch 253 in epoch 14, gen_loss = 0.40097268758796334, disc_loss = 0.07323446526654123
Trained batch 254 in epoch 14, gen_loss = 0.4009986731351591, disc_loss = 0.07310529437427428
Trained batch 255 in epoch 14, gen_loss = 0.40097439277451485, disc_loss = 0.07286486878729193
Trained batch 256 in epoch 14, gen_loss = 0.40114410343337153, disc_loss = 0.07276821280702775
Trained batch 257 in epoch 14, gen_loss = 0.4009712556766909, disc_loss = 0.07268140776183947
Trained batch 258 in epoch 14, gen_loss = 0.40084069276868606, disc_loss = 0.0724407640217469
Trained batch 259 in epoch 14, gen_loss = 0.4007094382093503, disc_loss = 0.07252118525166924
Trained batch 260 in epoch 14, gen_loss = 0.4010091680904915, disc_loss = 0.07266257746837376
Trained batch 261 in epoch 14, gen_loss = 0.40111199533211367, disc_loss = 0.07253444617798993
Trained batch 262 in epoch 14, gen_loss = 0.4013527687284883, disc_loss = 0.07229581486589555
Trained batch 263 in epoch 14, gen_loss = 0.40136505606951134, disc_loss = 0.07212741066221938
Trained batch 264 in epoch 14, gen_loss = 0.40160981158040604, disc_loss = 0.07193408992914659
Trained batch 265 in epoch 14, gen_loss = 0.4015962349292927, disc_loss = 0.0717070200830642
Trained batch 266 in epoch 14, gen_loss = 0.40163524800472045, disc_loss = 0.07172930894649765
Trained batch 267 in epoch 14, gen_loss = 0.40190505725679115, disc_loss = 0.07157601223938834
Trained batch 268 in epoch 14, gen_loss = 0.4021556872639071, disc_loss = 0.07163917164917218
Trained batch 269 in epoch 14, gen_loss = 0.40176822896356934, disc_loss = 0.07175787510350347
Trained batch 270 in epoch 14, gen_loss = 0.40178533827686663, disc_loss = 0.07152890003324106
Trained batch 271 in epoch 14, gen_loss = 0.4016532249310437, disc_loss = 0.07134164614013999
Trained batch 272 in epoch 14, gen_loss = 0.40182943429265705, disc_loss = 0.07126918990819991
Trained batch 273 in epoch 14, gen_loss = 0.4016365222904804, disc_loss = 0.0711549625895156
Trained batch 274 in epoch 14, gen_loss = 0.4016129792820324, disc_loss = 0.07096992880444634
Trained batch 275 in epoch 14, gen_loss = 0.4021507670050082, disc_loss = 0.07106987638331518
Trained batch 276 in epoch 14, gen_loss = 0.4022316074113123, disc_loss = 0.07089787653381752
Trained batch 277 in epoch 14, gen_loss = 0.4020642944805914, disc_loss = 0.07075092489596643
Trained batch 278 in epoch 14, gen_loss = 0.4020179311434428, disc_loss = 0.0705473136096712
Trained batch 279 in epoch 14, gen_loss = 0.402112877368927, disc_loss = 0.07045044283316071
Trained batch 280 in epoch 14, gen_loss = 0.40192797642161415, disc_loss = 0.07075441495127631
Trained batch 281 in epoch 14, gen_loss = 0.4020841489446924, disc_loss = 0.07109806947211952
Trained batch 282 in epoch 14, gen_loss = 0.40232588124359453, disc_loss = 0.07101185861053505
Trained batch 283 in epoch 14, gen_loss = 0.40206361457075873, disc_loss = 0.07145066962341293
Trained batch 284 in epoch 14, gen_loss = 0.4025320733848371, disc_loss = 0.07182324553856201
Trained batch 285 in epoch 14, gen_loss = 0.4026552093820972, disc_loss = 0.07160916936525202
Trained batch 286 in epoch 14, gen_loss = 0.4024939409324101, disc_loss = 0.0714771060844176
Trained batch 287 in epoch 14, gen_loss = 0.40235293480671114, disc_loss = 0.07134103433862846
Trained batch 288 in epoch 14, gen_loss = 0.4021484236197488, disc_loss = 0.07187063002372386
Trained batch 289 in epoch 14, gen_loss = 0.40228666139060054, disc_loss = 0.07227886314343275
Trained batch 290 in epoch 14, gen_loss = 0.40210588977918593, disc_loss = 0.0724367243605842
Trained batch 291 in epoch 14, gen_loss = 0.40205712004067146, disc_loss = 0.0724244092508181
Trained batch 292 in epoch 14, gen_loss = 0.40194559148147246, disc_loss = 0.07252697171420876
Trained batch 293 in epoch 14, gen_loss = 0.40183931001189616, disc_loss = 0.07245568878201096
Trained batch 294 in epoch 14, gen_loss = 0.4020305159738508, disc_loss = 0.07247051314087742
Trained batch 295 in epoch 14, gen_loss = 0.4018764961007479, disc_loss = 0.07230668535418305
Trained batch 296 in epoch 14, gen_loss = 0.40211242617982806, disc_loss = 0.0723080056114279
Trained batch 297 in epoch 14, gen_loss = 0.4021233809274315, disc_loss = 0.07210693759968717
Trained batch 298 in epoch 14, gen_loss = 0.40225675183793774, disc_loss = 0.07197954001397293
Trained batch 299 in epoch 14, gen_loss = 0.4021895103653272, disc_loss = 0.07180814236712953
Trained batch 300 in epoch 14, gen_loss = 0.4020821809570655, disc_loss = 0.07236971560420091
Trained batch 301 in epoch 14, gen_loss = 0.4021964391927845, disc_loss = 0.07315445923560995
Trained batch 302 in epoch 14, gen_loss = 0.40206091012498335, disc_loss = 0.07313682198241697
Trained batch 303 in epoch 14, gen_loss = 0.40177942567357894, disc_loss = 0.07338309597138218
Trained batch 304 in epoch 14, gen_loss = 0.40174992328784503, disc_loss = 0.07329756847475885
Trained batch 305 in epoch 14, gen_loss = 0.40170403681938943, disc_loss = 0.07313546329870625
Trained batch 306 in epoch 14, gen_loss = 0.401791181257571, disc_loss = 0.07294442647831448
Trained batch 307 in epoch 14, gen_loss = 0.40169793154512135, disc_loss = 0.07275345093304557
Trained batch 308 in epoch 14, gen_loss = 0.4015968151655784, disc_loss = 0.07254444607940402
Trained batch 309 in epoch 14, gen_loss = 0.4015207592518099, disc_loss = 0.07233003503492763
Trained batch 310 in epoch 14, gen_loss = 0.4014011447069346, disc_loss = 0.07211599145623648
Trained batch 311 in epoch 14, gen_loss = 0.40155338944915014, disc_loss = 0.07191280945419119
Trained batch 312 in epoch 14, gen_loss = 0.40142353874045056, disc_loss = 0.07192211692182782
Trained batch 313 in epoch 14, gen_loss = 0.4013667386618389, disc_loss = 0.07205657351311225
Trained batch 314 in epoch 14, gen_loss = 0.40115195408700005, disc_loss = 0.07234714574047497
Trained batch 315 in epoch 14, gen_loss = 0.4013114649849602, disc_loss = 0.07244630951340063
Trained batch 316 in epoch 14, gen_loss = 0.4011494768342761, disc_loss = 0.0725927740829036
Trained batch 317 in epoch 14, gen_loss = 0.4014143123754165, disc_loss = 0.07268932730006347
Trained batch 318 in epoch 14, gen_loss = 0.4015100440448354, disc_loss = 0.07270153374834494
Trained batch 319 in epoch 14, gen_loss = 0.40134830633178353, disc_loss = 0.07271328865317628
Trained batch 320 in epoch 14, gen_loss = 0.4014309491509589, disc_loss = 0.07254747321069055
Trained batch 321 in epoch 14, gen_loss = 0.40126013209730943, disc_loss = 0.072852580108165
Trained batch 322 in epoch 14, gen_loss = 0.40108375421987597, disc_loss = 0.07285073868953407
Trained batch 323 in epoch 14, gen_loss = 0.4014763275598302, disc_loss = 0.07268169142282856
Trained batch 324 in epoch 14, gen_loss = 0.40165755721238944, disc_loss = 0.07255919753932036
Trained batch 325 in epoch 14, gen_loss = 0.4014787661151652, disc_loss = 0.0724383291211322
Trained batch 326 in epoch 14, gen_loss = 0.4015916841110323, disc_loss = 0.07263574727016305
Trained batch 327 in epoch 14, gen_loss = 0.401574091031784, disc_loss = 0.07246312598993139
Trained batch 328 in epoch 14, gen_loss = 0.40129629538414324, disc_loss = 0.07269567767537473
Trained batch 329 in epoch 14, gen_loss = 0.40143330584872855, disc_loss = 0.07276075362707629
Trained batch 330 in epoch 14, gen_loss = 0.4013362544901061, disc_loss = 0.0725948105529626
Trained batch 331 in epoch 14, gen_loss = 0.4012015614523945, disc_loss = 0.0725208495137652
Trained batch 332 in epoch 14, gen_loss = 0.4008549424084099, disc_loss = 0.07244265757993355
Trained batch 333 in epoch 14, gen_loss = 0.40090835817202836, disc_loss = 0.07279189812677528
Trained batch 334 in epoch 14, gen_loss = 0.40079997751250196, disc_loss = 0.07314545875276203
Trained batch 335 in epoch 14, gen_loss = 0.40070471318349954, disc_loss = 0.07297607567272194
Trained batch 336 in epoch 14, gen_loss = 0.40087945878682574, disc_loss = 0.07290445563855971
Trained batch 337 in epoch 14, gen_loss = 0.40064766976607624, disc_loss = 0.07295002920013031
Trained batch 338 in epoch 14, gen_loss = 0.40080519121656727, disc_loss = 0.0729711236800328
Trained batch 339 in epoch 14, gen_loss = 0.40053447967066486, disc_loss = 0.07307271470370538
Trained batch 340 in epoch 14, gen_loss = 0.4006890813626152, disc_loss = 0.07297311807897958
Trained batch 341 in epoch 14, gen_loss = 0.40063812274333327, disc_loss = 0.07320545985750114
Trained batch 342 in epoch 14, gen_loss = 0.4004290918914639, disc_loss = 0.07342570939212603
Trained batch 343 in epoch 14, gen_loss = 0.4003548315444658, disc_loss = 0.07332946702859602
Trained batch 344 in epoch 14, gen_loss = 0.4004881054594897, disc_loss = 0.07330791233782319
Trained batch 345 in epoch 14, gen_loss = 0.4003771832051305, disc_loss = 0.0732000652603762
Trained batch 346 in epoch 14, gen_loss = 0.40014529133736226, disc_loss = 0.07330931442379092
Trained batch 347 in epoch 14, gen_loss = 0.4002366556689657, disc_loss = 0.07316198335403855
Trained batch 348 in epoch 14, gen_loss = 0.40054334653141166, disc_loss = 0.07308809335922614
Trained batch 349 in epoch 14, gen_loss = 0.4007155806677682, disc_loss = 0.07302808602473565
Trained batch 350 in epoch 14, gen_loss = 0.40081426620143773, disc_loss = 0.07305040202525437
Trained batch 351 in epoch 14, gen_loss = 0.40078975996849214, disc_loss = 0.07285740324401889
Trained batch 352 in epoch 14, gen_loss = 0.40084412018570614, disc_loss = 0.07285796294236825
Trained batch 353 in epoch 14, gen_loss = 0.4011183000553799, disc_loss = 0.07267503082320767
Trained batch 354 in epoch 14, gen_loss = 0.40099770645020716, disc_loss = 0.07271317192943583
Trained batch 355 in epoch 14, gen_loss = 0.4011330623807532, disc_loss = 0.07263446956862475
Trained batch 356 in epoch 14, gen_loss = 0.40117782863582213, disc_loss = 0.07248672226010835
Trained batch 357 in epoch 14, gen_loss = 0.4012189892916706, disc_loss = 0.07245200193700427
Trained batch 358 in epoch 14, gen_loss = 0.4012783545803559, disc_loss = 0.07233786097050626
Trained batch 359 in epoch 14, gen_loss = 0.4015799647404088, disc_loss = 0.0722441954512356
Trained batch 360 in epoch 14, gen_loss = 0.40144408186717045, disc_loss = 0.07211216562105101
Trained batch 361 in epoch 14, gen_loss = 0.4011923919395847, disc_loss = 0.07258803994544057
Trained batch 362 in epoch 14, gen_loss = 0.4014253631111019, disc_loss = 0.07320464913766657
Trained batch 363 in epoch 14, gen_loss = 0.4013755533557672, disc_loss = 0.07317364382926006
Trained batch 364 in epoch 14, gen_loss = 0.4013044501004154, disc_loss = 0.0730204008238977
Trained batch 365 in epoch 14, gen_loss = 0.40116756861327124, disc_loss = 0.07293346401334541
Trained batch 366 in epoch 14, gen_loss = 0.4010273555968698, disc_loss = 0.0728358135708387
Trained batch 367 in epoch 14, gen_loss = 0.400941700472132, disc_loss = 0.07287163368638848
Trained batch 368 in epoch 14, gen_loss = 0.40076299855702613, disc_loss = 0.07292521597822588
Trained batch 369 in epoch 14, gen_loss = 0.4006517603590682, disc_loss = 0.0727829660389673
Trained batch 370 in epoch 14, gen_loss = 0.40075554600301777, disc_loss = 0.07265774531897429
Trained batch 371 in epoch 14, gen_loss = 0.40070551193209103, disc_loss = 0.07253489869406386
Trained batch 372 in epoch 14, gen_loss = 0.40060594645965514, disc_loss = 0.07236773784874112
Trained batch 373 in epoch 14, gen_loss = 0.4005694532776899, disc_loss = 0.07219527379415411
Trained batch 374 in epoch 14, gen_loss = 0.40048515343666075, disc_loss = 0.07207681236167748
Trained batch 375 in epoch 14, gen_loss = 0.400603564337213, disc_loss = 0.07199057461594806
Trained batch 376 in epoch 14, gen_loss = 0.4008534094541079, disc_loss = 0.07190293802407914
Trained batch 377 in epoch 14, gen_loss = 0.4010334223035782, disc_loss = 0.07178687676294614
Trained batch 378 in epoch 14, gen_loss = 0.4008931403581574, disc_loss = 0.0717407747621508
Trained batch 379 in epoch 14, gen_loss = 0.4007650235765859, disc_loss = 0.07160058439660229
Trained batch 380 in epoch 14, gen_loss = 0.4009918026880329, disc_loss = 0.07151170665999566
Trained batch 381 in epoch 14, gen_loss = 0.400819627324324, disc_loss = 0.07151610061467786
Trained batch 382 in epoch 14, gen_loss = 0.40098527828644837, disc_loss = 0.07146259530036474
Trained batch 383 in epoch 14, gen_loss = 0.4011347700531284, disc_loss = 0.07134568478310636
Trained batch 384 in epoch 14, gen_loss = 0.4009647432859842, disc_loss = 0.07129948319649541
Trained batch 385 in epoch 14, gen_loss = 0.4008689924997369, disc_loss = 0.07117115659397964
Trained batch 386 in epoch 14, gen_loss = 0.40092042234824915, disc_loss = 0.07111207915118653
Trained batch 387 in epoch 14, gen_loss = 0.40088500904360996, disc_loss = 0.07103000744005915
Trained batch 388 in epoch 14, gen_loss = 0.40078594093151143, disc_loss = 0.07093447902189583
Trained batch 389 in epoch 14, gen_loss = 0.40089378219384414, disc_loss = 0.071075040823183
Trained batch 390 in epoch 14, gen_loss = 0.40075306506717906, disc_loss = 0.07102709923349225
Trained batch 391 in epoch 14, gen_loss = 0.40061886494561116, disc_loss = 0.07099863016806847
Trained batch 392 in epoch 14, gen_loss = 0.4004520535014058, disc_loss = 0.0708946298769943
Trained batch 393 in epoch 14, gen_loss = 0.40043464696346803, disc_loss = 0.07096526459294376
Trained batch 394 in epoch 14, gen_loss = 0.40028289986562127, disc_loss = 0.0709776449759927
Trained batch 395 in epoch 14, gen_loss = 0.40011092019502564, disc_loss = 0.07087162749917068
Trained batch 396 in epoch 14, gen_loss = 0.4002996335552081, disc_loss = 0.07092786362155408
Trained batch 397 in epoch 14, gen_loss = 0.40014551849520985, disc_loss = 0.07088060410758808
Trained batch 398 in epoch 14, gen_loss = 0.400257373588127, disc_loss = 0.07075755903147217
Trained batch 399 in epoch 14, gen_loss = 0.4002701435238123, disc_loss = 0.07063860251568257
Trained batch 400 in epoch 14, gen_loss = 0.4004259064905067, disc_loss = 0.07062605696909148
Trained batch 401 in epoch 14, gen_loss = 0.4004237441281181, disc_loss = 0.07060121092481993
Trained batch 402 in epoch 14, gen_loss = 0.4004137852499562, disc_loss = 0.07047213098639737
Trained batch 403 in epoch 14, gen_loss = 0.4004614297853838, disc_loss = 0.07040476091298284
Trained batch 404 in epoch 14, gen_loss = 0.4006607213873922, disc_loss = 0.07043786667471315
Trained batch 405 in epoch 14, gen_loss = 0.40100130328697525, disc_loss = 0.07044146190227693
Trained batch 406 in epoch 14, gen_loss = 0.40095093319105574, disc_loss = 0.07049916606368978
Trained batch 407 in epoch 14, gen_loss = 0.40120457616799016, disc_loss = 0.07049591120277696
Trained batch 408 in epoch 14, gen_loss = 0.40101707506296397, disc_loss = 0.070413606669435
Trained batch 409 in epoch 14, gen_loss = 0.40100108348741764, disc_loss = 0.07026353440270192
Trained batch 410 in epoch 14, gen_loss = 0.40108252963880553, disc_loss = 0.070128287399446
Trained batch 411 in epoch 14, gen_loss = 0.4010923426706814, disc_loss = 0.07004576836016427
Trained batch 412 in epoch 14, gen_loss = 0.40115638824121136, disc_loss = 0.06990273511510785
Trained batch 413 in epoch 14, gen_loss = 0.40103522036674516, disc_loss = 0.06985569786694315
Trained batch 414 in epoch 14, gen_loss = 0.4009677861828402, disc_loss = 0.06972517617136599
Trained batch 415 in epoch 14, gen_loss = 0.4010305176130854, disc_loss = 0.06985666441659515
Trained batch 416 in epoch 14, gen_loss = 0.4007669497879861, disc_loss = 0.0700792229647259
Trained batch 417 in epoch 14, gen_loss = 0.4006943294163526, disc_loss = 0.06999947989814019
Trained batch 418 in epoch 14, gen_loss = 0.4006299340212829, disc_loss = 0.0699335012167052
Trained batch 419 in epoch 14, gen_loss = 0.400696234972704, disc_loss = 0.06986038306994098
Trained batch 420 in epoch 14, gen_loss = 0.4005468908936281, disc_loss = 0.06972026132542702
Trained batch 421 in epoch 14, gen_loss = 0.4007240374223881, disc_loss = 0.06965200393350345
Trained batch 422 in epoch 14, gen_loss = 0.4006772585935345, disc_loss = 0.06985526116692568
Trained batch 423 in epoch 14, gen_loss = 0.4007825029767909, disc_loss = 0.07020046859364605
Trained batch 424 in epoch 14, gen_loss = 0.4006304143456852, disc_loss = 0.07029006265980356
Trained batch 425 in epoch 14, gen_loss = 0.4005272953023373, disc_loss = 0.07026376399023572
Trained batch 426 in epoch 14, gen_loss = 0.40051945045904475, disc_loss = 0.07021730944112956
Trained batch 427 in epoch 14, gen_loss = 0.400545038839924, disc_loss = 0.0704080137406763
Trained batch 428 in epoch 14, gen_loss = 0.4007849789860643, disc_loss = 0.07042596702374918
Trained batch 429 in epoch 14, gen_loss = 0.40097110423930854, disc_loss = 0.07054321084518073
Trained batch 430 in epoch 14, gen_loss = 0.4009069246510065, disc_loss = 0.07097877072399426
Trained batch 431 in epoch 14, gen_loss = 0.4008423585306715, disc_loss = 0.07112573540372844
Trained batch 432 in epoch 14, gen_loss = 0.4007085869411398, disc_loss = 0.07108256983512681
Trained batch 433 in epoch 14, gen_loss = 0.4005957634492953, disc_loss = 0.07110849950325242
Trained batch 434 in epoch 14, gen_loss = 0.40064415760423944, disc_loss = 0.07107272504818166
Trained batch 435 in epoch 14, gen_loss = 0.400858219268672, disc_loss = 0.07113914368161504
Trained batch 436 in epoch 14, gen_loss = 0.40097644004450783, disc_loss = 0.07100898364145368
Trained batch 437 in epoch 14, gen_loss = 0.4009564282142953, disc_loss = 0.07096272227290558
Trained batch 438 in epoch 14, gen_loss = 0.40079520082690995, disc_loss = 0.0709897186394976
Trained batch 439 in epoch 14, gen_loss = 0.4011514002626592, disc_loss = 0.07111223011531613
Trained batch 440 in epoch 14, gen_loss = 0.4011306489000515, disc_loss = 0.07112823789960403
Trained batch 441 in epoch 14, gen_loss = 0.4010604185081715, disc_loss = 0.07126488005616007
Trained batch 442 in epoch 14, gen_loss = 0.4009084882504784, disc_loss = 0.07139186983251142
Trained batch 443 in epoch 14, gen_loss = 0.401118192989547, disc_loss = 0.07136653333499625
Trained batch 444 in epoch 14, gen_loss = 0.4009224338477917, disc_loss = 0.07127726327502326
Trained batch 445 in epoch 14, gen_loss = 0.4009513819565153, disc_loss = 0.07114998041965367
Trained batch 446 in epoch 14, gen_loss = 0.40086786105595446, disc_loss = 0.07103824385043891
Trained batch 447 in epoch 14, gen_loss = 0.40067135562588063, disc_loss = 0.07113166889757849
Trained batch 448 in epoch 14, gen_loss = 0.4005828582098861, disc_loss = 0.0714664527055349
Trained batch 449 in epoch 14, gen_loss = 0.4003855452272627, disc_loss = 0.07161800839420822
Trained batch 450 in epoch 14, gen_loss = 0.4003174879202029, disc_loss = 0.07182725141869813
Trained batch 451 in epoch 14, gen_loss = 0.40025292132544305, disc_loss = 0.07188707632548381
Trained batch 452 in epoch 14, gen_loss = 0.40012504821581557, disc_loss = 0.07187734346499637
Trained batch 453 in epoch 14, gen_loss = 0.40007969605765153, disc_loss = 0.07189776201523217
Trained batch 454 in epoch 14, gen_loss = 0.4002040094726688, disc_loss = 0.07244443606462453
Trained batch 455 in epoch 14, gen_loss = 0.40020927590759175, disc_loss = 0.07259590091722969
Trained batch 456 in epoch 14, gen_loss = 0.4002030007296631, disc_loss = 0.07258971070940046
Trained batch 457 in epoch 14, gen_loss = 0.40012517896802147, disc_loss = 0.07261968345084435
Trained batch 458 in epoch 14, gen_loss = 0.40007508450343976, disc_loss = 0.0725509491678092
Trained batch 459 in epoch 14, gen_loss = 0.40006898576798644, disc_loss = 0.07242743986375307
Trained batch 460 in epoch 14, gen_loss = 0.3999690128381237, disc_loss = 0.07239989750087261
Testing Epoch 14
Training Epoch 15
Trained batch 0 in epoch 15, gen_loss = 0.37751978635787964, disc_loss = 0.07231397181749344
Trained batch 1 in epoch 15, gen_loss = 0.37314437329769135, disc_loss = 0.08160752430558205
Trained batch 2 in epoch 15, gen_loss = 0.37887102365493774, disc_loss = 0.06285914406180382
Trained batch 3 in epoch 15, gen_loss = 0.411960631608963, disc_loss = 0.06991621758788824
Trained batch 4 in epoch 15, gen_loss = 0.41315301060676574, disc_loss = 0.06573350355029106
Trained batch 5 in epoch 15, gen_loss = 0.40600211918354034, disc_loss = 0.05911661218851805
Trained batch 6 in epoch 15, gen_loss = 0.4001585159982954, disc_loss = 0.07390085102191993
Trained batch 7 in epoch 15, gen_loss = 0.39605413004755974, disc_loss = 0.10159489721991122
Trained batch 8 in epoch 15, gen_loss = 0.40907009773784214, disc_loss = 0.10161398951378134
Trained batch 9 in epoch 15, gen_loss = 0.4100111097097397, disc_loss = 0.09631687942892313
Trained batch 10 in epoch 15, gen_loss = 0.4076784009283239, disc_loss = 0.10132008198310029
Trained batch 11 in epoch 15, gen_loss = 0.40577985097964603, disc_loss = 0.09692147110278408
Trained batch 12 in epoch 15, gen_loss = 0.41074259693805987, disc_loss = 0.10070348573991886
Trained batch 13 in epoch 15, gen_loss = 0.41368724192891804, disc_loss = 0.09741851541080646
Trained batch 14 in epoch 15, gen_loss = 0.41361443797747294, disc_loss = 0.09652056954801083
Trained batch 15 in epoch 15, gen_loss = 0.41277542896568775, disc_loss = 0.09788407071027905
Trained batch 16 in epoch 15, gen_loss = 0.4095708973267499, disc_loss = 0.09576436953947824
Trained batch 17 in epoch 15, gen_loss = 0.40949860711892444, disc_loss = 0.09278807820131381
Trained batch 18 in epoch 15, gen_loss = 0.4102178639487216, disc_loss = 0.09133725917260897
Trained batch 19 in epoch 15, gen_loss = 0.4071953326463699, disc_loss = 0.08816037587821483
Trained batch 20 in epoch 15, gen_loss = 0.40587199869610013, disc_loss = 0.08622545873125394
Trained batch 21 in epoch 15, gen_loss = 0.40289972857995465, disc_loss = 0.08347019976512952
Trained batch 22 in epoch 15, gen_loss = 0.3984697033529696, disc_loss = 0.08727192894920059
Trained batch 23 in epoch 15, gen_loss = 0.40152009949088097, disc_loss = 0.09251867436493437
Trained batch 24 in epoch 15, gen_loss = 0.40007460474967954, disc_loss = 0.08935460910201072
Trained batch 25 in epoch 15, gen_loss = 0.39965127179255855, disc_loss = 0.09465934493793891
Trained batch 26 in epoch 15, gen_loss = 0.4019592547858203, disc_loss = 0.0955839183319498
Trained batch 27 in epoch 15, gen_loss = 0.40190553452287403, disc_loss = 0.09339021864746298
Trained batch 28 in epoch 15, gen_loss = 0.40144502088941375, disc_loss = 0.09283636741597077
Trained batch 29 in epoch 15, gen_loss = 0.40408463080724083, disc_loss = 0.09163672092060247
Trained batch 30 in epoch 15, gen_loss = 0.4034306743452626, disc_loss = 0.0900138865315145
Trained batch 31 in epoch 15, gen_loss = 0.40291065350174904, disc_loss = 0.09136696846690029
Trained batch 32 in epoch 15, gen_loss = 0.4030742383364475, disc_loss = 0.08909537609327924
Trained batch 33 in epoch 15, gen_loss = 0.402034201166209, disc_loss = 0.08714129342971479
Trained batch 34 in epoch 15, gen_loss = 0.401962844814573, disc_loss = 0.08506719209253788
Trained batch 35 in epoch 15, gen_loss = 0.40160703079568016, disc_loss = 0.08317546593025327
Trained batch 36 in epoch 15, gen_loss = 0.39907069544534424, disc_loss = 0.08385814308516078
Trained batch 37 in epoch 15, gen_loss = 0.4014395169521633, disc_loss = 0.08528264401186454
Trained batch 38 in epoch 15, gen_loss = 0.3986841700015924, disc_loss = 0.08646543271457538
Trained batch 39 in epoch 15, gen_loss = 0.39993029087781906, disc_loss = 0.08538934341631829
Trained batch 40 in epoch 15, gen_loss = 0.40025231605622824, disc_loss = 0.0836915143015908
Trained batch 41 in epoch 15, gen_loss = 0.39912326350098565, disc_loss = 0.08265417335288865
Trained batch 42 in epoch 15, gen_loss = 0.39986422242120256, disc_loss = 0.08124812666413396
Trained batch 43 in epoch 15, gen_loss = 0.3998420177535577, disc_loss = 0.07982953358441591
Trained batch 44 in epoch 15, gen_loss = 0.40146519541740416, disc_loss = 0.07843651192055809
Trained batch 45 in epoch 15, gen_loss = 0.39979725363461865, disc_loss = 0.07859878533560297
Trained batch 46 in epoch 15, gen_loss = 0.3992036568357589, disc_loss = 0.07707279123999972
Trained batch 47 in epoch 15, gen_loss = 0.3994431464622418, disc_loss = 0.0758538154574732
Trained batch 48 in epoch 15, gen_loss = 0.4008081427642277, disc_loss = 0.07485539983121717
Trained batch 49 in epoch 15, gen_loss = 0.40185605943202973, disc_loss = 0.0734997777827084
Trained batch 50 in epoch 15, gen_loss = 0.4010146160920461, disc_loss = 0.07227532258805107
Trained batch 51 in epoch 15, gen_loss = 0.3997620487442383, disc_loss = 0.07145999776772581
Trained batch 52 in epoch 15, gen_loss = 0.39873719046700673, disc_loss = 0.07150863212937454
Trained batch 53 in epoch 15, gen_loss = 0.39955990899492194, disc_loss = 0.07498423772415629
Trained batch 54 in epoch 15, gen_loss = 0.3992002481764013, disc_loss = 0.07627238892018795
Trained batch 55 in epoch 15, gen_loss = 0.4008969169642244, disc_loss = 0.0776447104622743
Trained batch 56 in epoch 15, gen_loss = 0.40151404393346685, disc_loss = 0.07868861331882183
Trained batch 57 in epoch 15, gen_loss = 0.4017707022099659, disc_loss = 0.08116294665197873
Trained batch 58 in epoch 15, gen_loss = 0.40203744627661625, disc_loss = 0.08431068533179113
Trained batch 59 in epoch 15, gen_loss = 0.4015938480695089, disc_loss = 0.08466967235629758
Trained batch 60 in epoch 15, gen_loss = 0.4007034878261754, disc_loss = 0.08434937726400915
Trained batch 61 in epoch 15, gen_loss = 0.39936808184269934, disc_loss = 0.08344119549879143
Trained batch 62 in epoch 15, gen_loss = 0.3999459133261726, disc_loss = 0.08323540080279584
Trained batch 63 in epoch 15, gen_loss = 0.3998026358895004, disc_loss = 0.08300930392579176
Trained batch 64 in epoch 15, gen_loss = 0.3990296295055976, disc_loss = 0.08391225375235081
Trained batch 65 in epoch 15, gen_loss = 0.397766394145561, disc_loss = 0.08894344162421697
Trained batch 66 in epoch 15, gen_loss = 0.3985302670678096, disc_loss = 0.0891214678369796
Trained batch 67 in epoch 15, gen_loss = 0.3984724169268328, disc_loss = 0.08919558972668122
Trained batch 68 in epoch 15, gen_loss = 0.39753963333972986, disc_loss = 0.09137180223521116
Trained batch 69 in epoch 15, gen_loss = 0.399599363548415, disc_loss = 0.09092626010200806
Trained batch 70 in epoch 15, gen_loss = 0.3988430785461211, disc_loss = 0.09122432991337608
Trained batch 71 in epoch 15, gen_loss = 0.39878236543801093, disc_loss = 0.09145915686773758
Trained batch 72 in epoch 15, gen_loss = 0.3979429798583462, disc_loss = 0.09149041335570486
Trained batch 73 in epoch 15, gen_loss = 0.3978397540144018, disc_loss = 0.09070932152806907
Trained batch 74 in epoch 15, gen_loss = 0.3981402627627055, disc_loss = 0.08980932913720607
Trained batch 75 in epoch 15, gen_loss = 0.3989539056232101, disc_loss = 0.08906818977802207
Trained batch 76 in epoch 15, gen_loss = 0.3982882789977185, disc_loss = 0.08886998652347497
Trained batch 77 in epoch 15, gen_loss = 0.39789401644315475, disc_loss = 0.08858104023891382
Trained batch 78 in epoch 15, gen_loss = 0.39763003927242907, disc_loss = 0.08797101150679437
Trained batch 79 in epoch 15, gen_loss = 0.3976224470883608, disc_loss = 0.08702266797190532
Trained batch 80 in epoch 15, gen_loss = 0.39828060328224557, disc_loss = 0.08627183012158414
Trained batch 81 in epoch 15, gen_loss = 0.39866684522570633, disc_loss = 0.08594589011471082
Trained batch 82 in epoch 15, gen_loss = 0.39787113917879313, disc_loss = 0.08715740908834949
Trained batch 83 in epoch 15, gen_loss = 0.3968996877471606, disc_loss = 0.0876960765370833
Trained batch 84 in epoch 15, gen_loss = 0.39741584553438075, disc_loss = 0.08697235112023705
Trained batch 85 in epoch 15, gen_loss = 0.3966896433469861, disc_loss = 0.08713355141713522
Trained batch 86 in epoch 15, gen_loss = 0.398333843069515, disc_loss = 0.08775834397723277
Trained batch 87 in epoch 15, gen_loss = 0.398097868331454, disc_loss = 0.08915860528676686
Trained batch 88 in epoch 15, gen_loss = 0.3987427759036589, disc_loss = 0.08872078678288152
Trained batch 89 in epoch 15, gen_loss = 0.3990910506910748, disc_loss = 0.0880989750329819
Trained batch 90 in epoch 15, gen_loss = 0.39947437388556345, disc_loss = 0.08723948652354571
Trained batch 91 in epoch 15, gen_loss = 0.4000898110477821, disc_loss = 0.08638107149011415
Trained batch 92 in epoch 15, gen_loss = 0.39823025833534936, disc_loss = 0.08883714631840747
Trained batch 93 in epoch 15, gen_loss = 0.3996639427669505, disc_loss = 0.09012714840788791
Trained batch 94 in epoch 15, gen_loss = 0.3992057121113727, disc_loss = 0.08947179937048962
Trained batch 95 in epoch 15, gen_loss = 0.3988721133209765, disc_loss = 0.08905406847285728
Trained batch 96 in epoch 15, gen_loss = 0.3984767962055108, disc_loss = 0.08852598040374283
Trained batch 97 in epoch 15, gen_loss = 0.39836370899361007, disc_loss = 0.08817048697751395
Trained batch 98 in epoch 15, gen_loss = 0.39845276225094844, disc_loss = 0.08781162434906671
Trained batch 99 in epoch 15, gen_loss = 0.3988593526184559, disc_loss = 0.08703730261884629
Trained batch 100 in epoch 15, gen_loss = 0.39902985818905407, disc_loss = 0.08629917044487626
Trained batch 101 in epoch 15, gen_loss = 0.3993135616183281, disc_loss = 0.08577674306819544
Trained batch 102 in epoch 15, gen_loss = 0.3985559912850556, disc_loss = 0.0859009026124784
Trained batch 103 in epoch 15, gen_loss = 0.3991302794848497, disc_loss = 0.08580230120032166
Trained batch 104 in epoch 15, gen_loss = 0.3984295009147553, disc_loss = 0.08626504740012543
Trained batch 105 in epoch 15, gen_loss = 0.39908729985637487, disc_loss = 0.08633552197331809
Trained batch 106 in epoch 15, gen_loss = 0.39901917546151955, disc_loss = 0.08586330343664528
Trained batch 107 in epoch 15, gen_loss = 0.39943449295781275, disc_loss = 0.08514186269948604
Trained batch 108 in epoch 15, gen_loss = 0.3993184343663924, disc_loss = 0.08455681352269485
Trained batch 109 in epoch 15, gen_loss = 0.3992865823886611, disc_loss = 0.08422647893259472
Trained batch 110 in epoch 15, gen_loss = 0.400442777050508, disc_loss = 0.08486187916987382
Trained batch 111 in epoch 15, gen_loss = 0.3992658612717475, disc_loss = 0.08613588703363868
Trained batch 112 in epoch 15, gen_loss = 0.39949976066045, disc_loss = 0.08607636282500704
Trained batch 113 in epoch 15, gen_loss = 0.39995156895173223, disc_loss = 0.08578951012245134
Trained batch 114 in epoch 15, gen_loss = 0.39951753266479656, disc_loss = 0.085364847039075
Trained batch 115 in epoch 15, gen_loss = 0.39914147311757353, disc_loss = 0.08540142728176353
Trained batch 116 in epoch 15, gen_loss = 0.39932725788691104, disc_loss = 0.08541234202969533
Trained batch 117 in epoch 15, gen_loss = 0.3993865351303149, disc_loss = 0.08502164816925839
Trained batch 118 in epoch 15, gen_loss = 0.3991381226717925, disc_loss = 0.0847717692856403
Trained batch 119 in epoch 15, gen_loss = 0.39829115830361844, disc_loss = 0.08473815175238997
Trained batch 120 in epoch 15, gen_loss = 0.39807457483011827, disc_loss = 0.08435399691027796
Trained batch 121 in epoch 15, gen_loss = 0.3977486463110955, disc_loss = 0.08608131424417018
Trained batch 122 in epoch 15, gen_loss = 0.39741189172112845, disc_loss = 0.08832112023591752
Trained batch 123 in epoch 15, gen_loss = 0.39740312183576243, disc_loss = 0.08876284051896824
Trained batch 124 in epoch 15, gen_loss = 0.39723569858074187, disc_loss = 0.08838995065540076
Trained batch 125 in epoch 15, gen_loss = 0.3969930898812082, disc_loss = 0.0878640607457667
Trained batch 126 in epoch 15, gen_loss = 0.3973428641013273, disc_loss = 0.08792120079678578
Trained batch 127 in epoch 15, gen_loss = 0.39675599930342287, disc_loss = 0.08848105652577942
Trained batch 128 in epoch 15, gen_loss = 0.39714789240397225, disc_loss = 0.08817663216284773
Trained batch 129 in epoch 15, gen_loss = 0.39705107429852854, disc_loss = 0.08829782128763887
Trained batch 130 in epoch 15, gen_loss = 0.3960542595796003, disc_loss = 0.08846668909723295
Trained batch 131 in epoch 15, gen_loss = 0.39567070804310567, disc_loss = 0.08831273560468672
Trained batch 132 in epoch 15, gen_loss = 0.39625981304430424, disc_loss = 0.0881722720648001
Trained batch 133 in epoch 15, gen_loss = 0.39580677749950494, disc_loss = 0.08799717029723436
Trained batch 134 in epoch 15, gen_loss = 0.39617002771960363, disc_loss = 0.08747745234243295
Trained batch 135 in epoch 15, gen_loss = 0.39558222374933605, disc_loss = 0.08727034636745777
Trained batch 136 in epoch 15, gen_loss = 0.3958093331460535, disc_loss = 0.08702843585289526
Trained batch 137 in epoch 15, gen_loss = 0.39613289925931155, disc_loss = 0.08685372654429596
Trained batch 138 in epoch 15, gen_loss = 0.39589501660075976, disc_loss = 0.08654803121395463
Trained batch 139 in epoch 15, gen_loss = 0.39574039312345644, disc_loss = 0.08627138407235699
Trained batch 140 in epoch 15, gen_loss = 0.39536435077799126, disc_loss = 0.08610387926538152
Trained batch 141 in epoch 15, gen_loss = 0.39597552647473105, disc_loss = 0.0858966516737472
Trained batch 142 in epoch 15, gen_loss = 0.39623420899147754, disc_loss = 0.0855528402852116
Trained batch 143 in epoch 15, gen_loss = 0.3965430337314804, disc_loss = 0.08561792333946666
Trained batch 144 in epoch 15, gen_loss = 0.3968417668137057, disc_loss = 0.08563399644375876
Trained batch 145 in epoch 15, gen_loss = 0.397538240947952, disc_loss = 0.08614440222130451
Trained batch 146 in epoch 15, gen_loss = 0.3975396297213172, disc_loss = 0.08590551347275373
Trained batch 147 in epoch 15, gen_loss = 0.3974254281335586, disc_loss = 0.08562993508058826
Trained batch 148 in epoch 15, gen_loss = 0.39741793764917643, disc_loss = 0.08523223901030001
Trained batch 149 in epoch 15, gen_loss = 0.3975656987229983, disc_loss = 0.08495521922285358
Trained batch 150 in epoch 15, gen_loss = 0.3976316589195997, disc_loss = 0.08525052488417617
Trained batch 151 in epoch 15, gen_loss = 0.39763271249830723, disc_loss = 0.08563185413980759
Trained batch 152 in epoch 15, gen_loss = 0.3983798563675164, disc_loss = 0.0869673516759588
Trained batch 153 in epoch 15, gen_loss = 0.39753066071055154, disc_loss = 0.08780405795588703
Trained batch 154 in epoch 15, gen_loss = 0.3977220622762557, disc_loss = 0.08740243781358004
Trained batch 155 in epoch 15, gen_loss = 0.3974500238322295, disc_loss = 0.08725480796793142
Trained batch 156 in epoch 15, gen_loss = 0.3973339719187682, disc_loss = 0.08690599690838034
Trained batch 157 in epoch 15, gen_loss = 0.39718936789262144, disc_loss = 0.08743960195209217
Trained batch 158 in epoch 15, gen_loss = 0.39708816002374925, disc_loss = 0.08934231338518783
Trained batch 159 in epoch 15, gen_loss = 0.3962281118147075, disc_loss = 0.08954554304364137
Trained batch 160 in epoch 15, gen_loss = 0.3961798477432002, disc_loss = 0.08939223451343198
Trained batch 161 in epoch 15, gen_loss = 0.39575673170663694, disc_loss = 0.0897731077052469
Trained batch 162 in epoch 15, gen_loss = 0.39590788756045825, disc_loss = 0.08964494905474545
Trained batch 163 in epoch 15, gen_loss = 0.39545118508905897, disc_loss = 0.09068013902003991
Trained batch 164 in epoch 15, gen_loss = 0.39557504879705835, disc_loss = 0.0904665058478713
Trained batch 165 in epoch 15, gen_loss = 0.3958286162779992, disc_loss = 0.09029595822612026
Trained batch 166 in epoch 15, gen_loss = 0.39532569452317173, disc_loss = 0.09024339347163182
Trained batch 167 in epoch 15, gen_loss = 0.39519116184895947, disc_loss = 0.08993132921889246
Trained batch 168 in epoch 15, gen_loss = 0.39493072835298687, disc_loss = 0.08999787662839571
Trained batch 169 in epoch 15, gen_loss = 0.39517222914625616, disc_loss = 0.09096374226295773
Trained batch 170 in epoch 15, gen_loss = 0.3955466066710433, disc_loss = 0.0922920658084297
Trained batch 171 in epoch 15, gen_loss = 0.3952181035176266, disc_loss = 0.09274690350799193
Trained batch 172 in epoch 15, gen_loss = 0.3953814472938549, disc_loss = 0.09313538183345099
Trained batch 173 in epoch 15, gen_loss = 0.3945667189599454, disc_loss = 0.09396721160938513
Trained batch 174 in epoch 15, gen_loss = 0.3943736683470862, disc_loss = 0.09396690133959056
Trained batch 175 in epoch 15, gen_loss = 0.3942103960805319, disc_loss = 0.09372077140935951
Trained batch 176 in epoch 15, gen_loss = 0.3941500236590703, disc_loss = 0.09353393012668285
Trained batch 177 in epoch 15, gen_loss = 0.3939573347066226, disc_loss = 0.09331429493875149
Trained batch 178 in epoch 15, gen_loss = 0.39368822995843833, disc_loss = 0.09310005228009137
Trained batch 179 in epoch 15, gen_loss = 0.39395238682627676, disc_loss = 0.09298103962404032
Trained batch 180 in epoch 15, gen_loss = 0.394239978648681, disc_loss = 0.09293260558595809
Trained batch 181 in epoch 15, gen_loss = 0.3944306921336677, disc_loss = 0.09366517912616933
Trained batch 182 in epoch 15, gen_loss = 0.39390062903120215, disc_loss = 0.0952123090614631
Trained batch 183 in epoch 15, gen_loss = 0.3939355048958374, disc_loss = 0.09542956516531337
Trained batch 184 in epoch 15, gen_loss = 0.3937910530212763, disc_loss = 0.0956021700910217
Trained batch 185 in epoch 15, gen_loss = 0.3936193677526648, disc_loss = 0.09588642071391787
Trained batch 186 in epoch 15, gen_loss = 0.39324669587739647, disc_loss = 0.096349503481412
Trained batch 187 in epoch 15, gen_loss = 0.39286960479109845, disc_loss = 0.0965744190938533
Trained batch 188 in epoch 15, gen_loss = 0.3926938172212984, disc_loss = 0.09662759944146114
Trained batch 189 in epoch 15, gen_loss = 0.3925513702787851, disc_loss = 0.09686096374827781
Trained batch 190 in epoch 15, gen_loss = 0.39300576577948027, disc_loss = 0.09684025868285857
Trained batch 191 in epoch 15, gen_loss = 0.39277572953142226, disc_loss = 0.09719619963531538
Trained batch 192 in epoch 15, gen_loss = 0.39275244133151255, disc_loss = 0.097758585244533
Trained batch 193 in epoch 15, gen_loss = 0.39214323791339223, disc_loss = 0.09800260461694033
Trained batch 194 in epoch 15, gen_loss = 0.392837265592355, disc_loss = 0.0977317326487257
Trained batch 195 in epoch 15, gen_loss = 0.3926846518048218, disc_loss = 0.09747733504093271
Trained batch 196 in epoch 15, gen_loss = 0.39246570330283365, disc_loss = 0.0974287937730929
Trained batch 197 in epoch 15, gen_loss = 0.39237164314648115, disc_loss = 0.09806665719364478
Trained batch 198 in epoch 15, gen_loss = 0.3927208781991173, disc_loss = 0.09917555189218803
Trained batch 199 in epoch 15, gen_loss = 0.39275867663323877, disc_loss = 0.09926762429531663
Trained batch 200 in epoch 15, gen_loss = 0.39295995079759344, disc_loss = 0.09910165482844731
Trained batch 201 in epoch 15, gen_loss = 0.39271546524054934, disc_loss = 0.0991483853880943
Trained batch 202 in epoch 15, gen_loss = 0.3924289546136198, disc_loss = 0.09933390796386403
Trained batch 203 in epoch 15, gen_loss = 0.3923087227432167, disc_loss = 0.09907878812530316
Trained batch 204 in epoch 15, gen_loss = 0.3921282024645224, disc_loss = 0.09955818632663023
Trained batch 205 in epoch 15, gen_loss = 0.39257387346723704, disc_loss = 0.09933347428145195
Trained batch 206 in epoch 15, gen_loss = 0.39213583312460765, disc_loss = 0.09945943209698091
Trained batch 207 in epoch 15, gen_loss = 0.3925500249203581, disc_loss = 0.09928048777734287
Trained batch 208 in epoch 15, gen_loss = 0.3926500422104694, disc_loss = 0.0988750259066669
Trained batch 209 in epoch 15, gen_loss = 0.39255627046028774, disc_loss = 0.09871506686100648
Trained batch 210 in epoch 15, gen_loss = 0.3921051752087064, disc_loss = 0.0995638480198115
Trained batch 211 in epoch 15, gen_loss = 0.391836321649124, disc_loss = 0.09947250778611116
Trained batch 212 in epoch 15, gen_loss = 0.3914623263995972, disc_loss = 0.099723380448148
Trained batch 213 in epoch 15, gen_loss = 0.39221568565780873, disc_loss = 0.09943413440677747
Trained batch 214 in epoch 15, gen_loss = 0.3924104782731034, disc_loss = 0.09950917126221019
Trained batch 215 in epoch 15, gen_loss = 0.39270212811728317, disc_loss = 0.09940170036646089
Trained batch 216 in epoch 15, gen_loss = 0.39265667423949263, disc_loss = 0.09914117954104865
Trained batch 217 in epoch 15, gen_loss = 0.3922124170792212, disc_loss = 0.09914588947447205
Trained batch 218 in epoch 15, gen_loss = 0.392434548773722, disc_loss = 0.09941211498032014
Trained batch 219 in epoch 15, gen_loss = 0.39228703427043826, disc_loss = 0.09911578057587823
Trained batch 220 in epoch 15, gen_loss = 0.3921278753566526, disc_loss = 0.09926136927384192
Trained batch 221 in epoch 15, gen_loss = 0.3920328033802746, disc_loss = 0.09987523752843609
Trained batch 222 in epoch 15, gen_loss = 0.3921882270296593, disc_loss = 0.09966236608929832
Trained batch 223 in epoch 15, gen_loss = 0.39204060439286487, disc_loss = 0.09944157678650559
Trained batch 224 in epoch 15, gen_loss = 0.3924364052216212, disc_loss = 0.09936701460431019
Trained batch 225 in epoch 15, gen_loss = 0.3921148026015906, disc_loss = 0.09936769379599564
Trained batch 226 in epoch 15, gen_loss = 0.3921433229672226, disc_loss = 0.09911061889422229
Trained batch 227 in epoch 15, gen_loss = 0.3918587197467946, disc_loss = 0.09901635591022409
Trained batch 228 in epoch 15, gen_loss = 0.39150639437952417, disc_loss = 0.09869274477917685
Trained batch 229 in epoch 15, gen_loss = 0.3914456776302794, disc_loss = 0.09832003751121786
Trained batch 230 in epoch 15, gen_loss = 0.391200838086409, disc_loss = 0.09816600907658472
Trained batch 231 in epoch 15, gen_loss = 0.3910330394604083, disc_loss = 0.0987649883970554
Trained batch 232 in epoch 15, gen_loss = 0.3913061886770019, disc_loss = 0.09871479363256641
Trained batch 233 in epoch 15, gen_loss = 0.39126806795342356, disc_loss = 0.09848951282075201
Trained batch 234 in epoch 15, gen_loss = 0.3909870762140193, disc_loss = 0.09870702321145763
Trained batch 235 in epoch 15, gen_loss = 0.3912045660791761, disc_loss = 0.09876645045055045
Trained batch 236 in epoch 15, gen_loss = 0.39173448821411855, disc_loss = 0.09881752834337044
Trained batch 237 in epoch 15, gen_loss = 0.3914146907314533, disc_loss = 0.09961369287363496
Trained batch 238 in epoch 15, gen_loss = 0.39117056075249756, disc_loss = 0.09935328953170751
Trained batch 239 in epoch 15, gen_loss = 0.3913377392416199, disc_loss = 0.09993387283369277
Trained batch 240 in epoch 15, gen_loss = 0.3913914576729304, disc_loss = 0.0997567530296341
Trained batch 241 in epoch 15, gen_loss = 0.39113807339559903, disc_loss = 0.09947346833203573
Trained batch 242 in epoch 15, gen_loss = 0.3913084818625156, disc_loss = 0.09936405634392559
Trained batch 243 in epoch 15, gen_loss = 0.39135168083622807, disc_loss = 0.09946922642239904
Trained batch 244 in epoch 15, gen_loss = 0.39132045282393085, disc_loss = 0.09924065274927689
Trained batch 245 in epoch 15, gen_loss = 0.3910294978962681, disc_loss = 0.09893609238485616
Trained batch 246 in epoch 15, gen_loss = 0.39093519638665775, disc_loss = 0.09879508497276407
Trained batch 247 in epoch 15, gen_loss = 0.3916058721201074, disc_loss = 0.0999002457003019
Trained batch 248 in epoch 15, gen_loss = 0.3915977601904467, disc_loss = 0.0995721142611889
Trained batch 249 in epoch 15, gen_loss = 0.3916709161400795, disc_loss = 0.0995601402260363
Trained batch 250 in epoch 15, gen_loss = 0.3917320827207717, disc_loss = 0.0992217446339736
Trained batch 251 in epoch 15, gen_loss = 0.39186654257632436, disc_loss = 0.0989113760306426
Trained batch 252 in epoch 15, gen_loss = 0.39185072281379474, disc_loss = 0.09871447811882368
Trained batch 253 in epoch 15, gen_loss = 0.39164558117549253, disc_loss = 0.09859811987977211
Trained batch 254 in epoch 15, gen_loss = 0.39166231102803173, disc_loss = 0.09827439894205799
Trained batch 255 in epoch 15, gen_loss = 0.3916630683816038, disc_loss = 0.09795036994910333
Trained batch 256 in epoch 15, gen_loss = 0.3918964536389488, disc_loss = 0.09762200190239959
Trained batch 257 in epoch 15, gen_loss = 0.3918188180225764, disc_loss = 0.09735147886396955
Trained batch 258 in epoch 15, gen_loss = 0.39173786215570444, disc_loss = 0.09721112297668075
Trained batch 259 in epoch 15, gen_loss = 0.391634978640538, disc_loss = 0.09695445232881376
Trained batch 260 in epoch 15, gen_loss = 0.3918575171195684, disc_loss = 0.09672916700199989
Trained batch 261 in epoch 15, gen_loss = 0.3920261853637586, disc_loss = 0.09644198946242455
Trained batch 262 in epoch 15, gen_loss = 0.39231428215032293, disc_loss = 0.09613318203420806
Trained batch 263 in epoch 15, gen_loss = 0.3923060983758081, disc_loss = 0.09591843542346562
Trained batch 264 in epoch 15, gen_loss = 0.39276942931256204, disc_loss = 0.0961192403656413
Trained batch 265 in epoch 15, gen_loss = 0.3927198601956654, disc_loss = 0.09655144014150689
Trained batch 266 in epoch 15, gen_loss = 0.3931821370950799, disc_loss = 0.09633583857674388
Trained batch 267 in epoch 15, gen_loss = 0.3934012032600481, disc_loss = 0.09607705930873418
Trained batch 268 in epoch 15, gen_loss = 0.3931122574553614, disc_loss = 0.09594534882811698
Trained batch 269 in epoch 15, gen_loss = 0.3930805480590573, disc_loss = 0.09599871295676739
Trained batch 270 in epoch 15, gen_loss = 0.39298389071248113, disc_loss = 0.09596645570535392
Trained batch 271 in epoch 15, gen_loss = 0.39291695039719343, disc_loss = 0.09569267116089844
Trained batch 272 in epoch 15, gen_loss = 0.392883986725912, disc_loss = 0.09579099994152784
Trained batch 273 in epoch 15, gen_loss = 0.39293244573539193, disc_loss = 0.09574219449525223
Trained batch 274 in epoch 15, gen_loss = 0.393128105672923, disc_loss = 0.09547556064684283
Trained batch 275 in epoch 15, gen_loss = 0.3932664372242879, disc_loss = 0.09529356917946775
Trained batch 276 in epoch 15, gen_loss = 0.3931101816117979, disc_loss = 0.09505893092683183
Trained batch 277 in epoch 15, gen_loss = 0.39340687071462327, disc_loss = 0.09532417996498428
Trained batch 278 in epoch 15, gen_loss = 0.39301087880860947, disc_loss = 0.09558718207235511
Trained batch 279 in epoch 15, gen_loss = 0.39299865072327, disc_loss = 0.09533889145656887
Trained batch 280 in epoch 15, gen_loss = 0.39315858159837347, disc_loss = 0.09504928019268975
Trained batch 281 in epoch 15, gen_loss = 0.3930702164557809, disc_loss = 0.09486335070460294
Trained batch 282 in epoch 15, gen_loss = 0.3930312556744464, disc_loss = 0.09530161956634517
Trained batch 283 in epoch 15, gen_loss = 0.3928892257242975, disc_loss = 0.09521163568149885
Trained batch 284 in epoch 15, gen_loss = 0.39298702494094245, disc_loss = 0.09501245055478393
Trained batch 285 in epoch 15, gen_loss = 0.39303009519418636, disc_loss = 0.09491489710077852
Trained batch 286 in epoch 15, gen_loss = 0.3928145712780205, disc_loss = 0.09480466399964867
Trained batch 287 in epoch 15, gen_loss = 0.39290629187598825, disc_loss = 0.09469348877448486
Trained batch 288 in epoch 15, gen_loss = 0.3929606382718961, disc_loss = 0.09459583342371825
Trained batch 289 in epoch 15, gen_loss = 0.392824098005377, disc_loss = 0.0945975525079873
Trained batch 290 in epoch 15, gen_loss = 0.39242881603052526, disc_loss = 0.09445772367078312
Trained batch 291 in epoch 15, gen_loss = 0.39268290348453067, disc_loss = 0.0942752034792498
Trained batch 292 in epoch 15, gen_loss = 0.3926000379966794, disc_loss = 0.09465923484211387
Trained batch 293 in epoch 15, gen_loss = 0.3928764844123198, disc_loss = 0.09489241456232812
Trained batch 294 in epoch 15, gen_loss = 0.3931677461175595, disc_loss = 0.09473193250912226
Trained batch 295 in epoch 15, gen_loss = 0.3927895149367081, disc_loss = 0.09507358148127694
Trained batch 296 in epoch 15, gen_loss = 0.39293842318684163, disc_loss = 0.09490896511496819
Trained batch 297 in epoch 15, gen_loss = 0.39295724979383034, disc_loss = 0.09471994606878033
Trained batch 298 in epoch 15, gen_loss = 0.39299672607793457, disc_loss = 0.09449513735916204
Trained batch 299 in epoch 15, gen_loss = 0.393245148708423, disc_loss = 0.09423906448918085
Trained batch 300 in epoch 15, gen_loss = 0.3930354013890523, disc_loss = 0.0940031480025562
Trained batch 301 in epoch 15, gen_loss = 0.3932349486954954, disc_loss = 0.09391740988014846
Trained batch 302 in epoch 15, gen_loss = 0.3936354518428494, disc_loss = 0.09374453192238662
Trained batch 303 in epoch 15, gen_loss = 0.39360170051651566, disc_loss = 0.0935608868726137
Trained batch 304 in epoch 15, gen_loss = 0.3936595146284729, disc_loss = 0.09340866653584555
Trained batch 305 in epoch 15, gen_loss = 0.393707333485675, disc_loss = 0.09326408990640558
Trained batch 306 in epoch 15, gen_loss = 0.3939639176044868, disc_loss = 0.09302495043506355
Trained batch 307 in epoch 15, gen_loss = 0.3940584190770403, disc_loss = 0.09279806206498731
Trained batch 308 in epoch 15, gen_loss = 0.3940551775269524, disc_loss = 0.09278497180349908
Trained batch 309 in epoch 15, gen_loss = 0.3941726955194627, disc_loss = 0.09304491236745831
Trained batch 310 in epoch 15, gen_loss = 0.39397380719039216, disc_loss = 0.09280184622542555
Trained batch 311 in epoch 15, gen_loss = 0.39372013428081304, disc_loss = 0.09284006006335123
Trained batch 312 in epoch 15, gen_loss = 0.3936732840328552, disc_loss = 0.09272911732558149
Trained batch 313 in epoch 15, gen_loss = 0.3938607450598364, disc_loss = 0.09250972743567293
Trained batch 314 in epoch 15, gen_loss = 0.39382798203400204, disc_loss = 0.09228772587542022
Trained batch 315 in epoch 15, gen_loss = 0.39362441026900385, disc_loss = 0.09213003853654277
Trained batch 316 in epoch 15, gen_loss = 0.39381796051087065, disc_loss = 0.09195056716597137
Trained batch 317 in epoch 15, gen_loss = 0.39400025457143784, disc_loss = 0.0916961020549888
Trained batch 318 in epoch 15, gen_loss = 0.39389235878999707, disc_loss = 0.09158777478253206
Trained batch 319 in epoch 15, gen_loss = 0.3937685613986105, disc_loss = 0.09182189896237106
Trained batch 320 in epoch 15, gen_loss = 0.39359142935350305, disc_loss = 0.09162947695667499
Trained batch 321 in epoch 15, gen_loss = 0.39374929143590215, disc_loss = 0.09161158748294997
Trained batch 322 in epoch 15, gen_loss = 0.39395213380871175, disc_loss = 0.09138579960716398
Trained batch 323 in epoch 15, gen_loss = 0.3941009023031335, disc_loss = 0.09118818083525072
Trained batch 324 in epoch 15, gen_loss = 0.394081358221861, disc_loss = 0.09096447177804433
Trained batch 325 in epoch 15, gen_loss = 0.39412669668351213, disc_loss = 0.09071252966139672
Trained batch 326 in epoch 15, gen_loss = 0.3939345187823707, disc_loss = 0.09079339227921099
Trained batch 327 in epoch 15, gen_loss = 0.3943569855083053, disc_loss = 0.09151267589967153
Trained batch 328 in epoch 15, gen_loss = 0.3942948390013541, disc_loss = 0.09147110330308915
Trained batch 329 in epoch 15, gen_loss = 0.39430792128497905, disc_loss = 0.09151184791699052
Trained batch 330 in epoch 15, gen_loss = 0.3942600768228312, disc_loss = 0.09180682301352482
Trained batch 331 in epoch 15, gen_loss = 0.3940702915999545, disc_loss = 0.09172297136981535
Trained batch 332 in epoch 15, gen_loss = 0.39409137116717147, disc_loss = 0.09153439649646436
Trained batch 333 in epoch 15, gen_loss = 0.39415062656124195, disc_loss = 0.09137400364904792
Trained batch 334 in epoch 15, gen_loss = 0.3940872817341961, disc_loss = 0.0913864379748702
Trained batch 335 in epoch 15, gen_loss = 0.39435300927254413, disc_loss = 0.09140340786793136
Trained batch 336 in epoch 15, gen_loss = 0.39426922634553485, disc_loss = 0.09162678905881566
Trained batch 337 in epoch 15, gen_loss = 0.39451989685818994, disc_loss = 0.09192097484900137
Trained batch 338 in epoch 15, gen_loss = 0.3944659580787023, disc_loss = 0.09195055718366112
Trained batch 339 in epoch 15, gen_loss = 0.39456627566148256, disc_loss = 0.0917908427058993
Trained batch 340 in epoch 15, gen_loss = 0.3945368575123398, disc_loss = 0.09192532934849301
Trained batch 341 in epoch 15, gen_loss = 0.3942785428194275, disc_loss = 0.09232359658654408
Trained batch 342 in epoch 15, gen_loss = 0.3942692676455912, disc_loss = 0.09215034114647624
Trained batch 343 in epoch 15, gen_loss = 0.3945036516199971, disc_loss = 0.0919842370054793
Trained batch 344 in epoch 15, gen_loss = 0.3943656533092692, disc_loss = 0.09182111462443203
Trained batch 345 in epoch 15, gen_loss = 0.3941921285552786, disc_loss = 0.09191299808303142
Trained batch 346 in epoch 15, gen_loss = 0.394230763618472, disc_loss = 0.09194422237607261
Trained batch 347 in epoch 15, gen_loss = 0.39422041079264947, disc_loss = 0.09178671147941944
Trained batch 348 in epoch 15, gen_loss = 0.39455035717405357, disc_loss = 0.09176122246945229
Trained batch 349 in epoch 15, gen_loss = 0.3944478402393205, disc_loss = 0.09172672398654477
Trained batch 350 in epoch 15, gen_loss = 0.39453043009650673, disc_loss = 0.09174664158565111
Trained batch 351 in epoch 15, gen_loss = 0.3943574208004231, disc_loss = 0.09164985596593893
Trained batch 352 in epoch 15, gen_loss = 0.3943902262125069, disc_loss = 0.09146507466660428
Trained batch 353 in epoch 15, gen_loss = 0.3941684399368399, disc_loss = 0.09148297644362359
Trained batch 354 in epoch 15, gen_loss = 0.39428596635099866, disc_loss = 0.09188373093296524
Trained batch 355 in epoch 15, gen_loss = 0.39423204811938695, disc_loss = 0.09191368244263982
Trained batch 356 in epoch 15, gen_loss = 0.3943308322619991, disc_loss = 0.09184497910230852
Trained batch 357 in epoch 15, gen_loss = 0.3943716282201879, disc_loss = 0.09184324354526467
Trained batch 358 in epoch 15, gen_loss = 0.3944162863791819, disc_loss = 0.091702463860237
Trained batch 359 in epoch 15, gen_loss = 0.3945267072568337, disc_loss = 0.0920293221483007
Trained batch 360 in epoch 15, gen_loss = 0.3943388753898256, disc_loss = 0.09264545869391794
Trained batch 361 in epoch 15, gen_loss = 0.3942789900945036, disc_loss = 0.0925817607788791
Trained batch 362 in epoch 15, gen_loss = 0.3942419853338525, disc_loss = 0.09264226541302831
Trained batch 363 in epoch 15, gen_loss = 0.3940071877460558, disc_loss = 0.0925958328957127
Trained batch 364 in epoch 15, gen_loss = 0.3940910377322811, disc_loss = 0.09240391236819225
Trained batch 365 in epoch 15, gen_loss = 0.3939902087459799, disc_loss = 0.09233287175038392
Trained batch 366 in epoch 15, gen_loss = 0.39381858848583473, disc_loss = 0.09214365324741407
Trained batch 367 in epoch 15, gen_loss = 0.3939706244627419, disc_loss = 0.0923273456966221
Trained batch 368 in epoch 15, gen_loss = 0.3936735791807898, disc_loss = 0.09248314580569665
Trained batch 369 in epoch 15, gen_loss = 0.39371668644048075, disc_loss = 0.0925352223494367
Trained batch 370 in epoch 15, gen_loss = 0.39379011472119796, disc_loss = 0.09314624500031661
Trained batch 371 in epoch 15, gen_loss = 0.39374496575484996, disc_loss = 0.09291492507452526
Trained batch 372 in epoch 15, gen_loss = 0.3936107874955313, disc_loss = 0.09279258514007918
Trained batch 373 in epoch 15, gen_loss = 0.39365976471155084, disc_loss = 0.09258484266160484
Trained batch 374 in epoch 15, gen_loss = 0.39358383397261304, disc_loss = 0.09236962566773096
Trained batch 375 in epoch 15, gen_loss = 0.3936791954601699, disc_loss = 0.09215354848098248
Trained batch 376 in epoch 15, gen_loss = 0.39369822651226893, disc_loss = 0.09194412515980416
Trained batch 377 in epoch 15, gen_loss = 0.39369417659977757, disc_loss = 0.09175259137289628
Trained batch 378 in epoch 15, gen_loss = 0.3937988706267289, disc_loss = 0.09153125324043246
Trained batch 379 in epoch 15, gen_loss = 0.3937014312728455, disc_loss = 0.09130586726640008
Trained batch 380 in epoch 15, gen_loss = 0.39355469927230846, disc_loss = 0.09114967620738457
Trained batch 381 in epoch 15, gen_loss = 0.39363290045741967, disc_loss = 0.09093533880052922
Trained batch 382 in epoch 15, gen_loss = 0.3936354831133437, disc_loss = 0.09073464039168454
Trained batch 383 in epoch 15, gen_loss = 0.3936704652927195, disc_loss = 0.09073312619148055
Trained batch 384 in epoch 15, gen_loss = 0.3935448184802935, disc_loss = 0.0905606506295599
Trained batch 385 in epoch 15, gen_loss = 0.3936134618875894, disc_loss = 0.090492215178849
Trained batch 386 in epoch 15, gen_loss = 0.3937669163449482, disc_loss = 0.09030150536216738
Trained batch 387 in epoch 15, gen_loss = 0.39399344593132896, disc_loss = 0.0900943796990497
Trained batch 388 in epoch 15, gen_loss = 0.3940663903491969, disc_loss = 0.08988667574201191
Trained batch 389 in epoch 15, gen_loss = 0.3939407316920085, disc_loss = 0.08972782817167732
Trained batch 390 in epoch 15, gen_loss = 0.3939973469204305, disc_loss = 0.08951995028968891
Trained batch 391 in epoch 15, gen_loss = 0.39396618356053925, disc_loss = 0.08936539710717922
Trained batch 392 in epoch 15, gen_loss = 0.39392231192449273, disc_loss = 0.08934579945332904
Trained batch 393 in epoch 15, gen_loss = 0.39398908369280966, disc_loss = 0.0892456349689835
Trained batch 394 in epoch 15, gen_loss = 0.3940412186746356, disc_loss = 0.0893547341722665
Trained batch 395 in epoch 15, gen_loss = 0.3938835255350127, disc_loss = 0.08930938855763713
Trained batch 396 in epoch 15, gen_loss = 0.393971741161959, disc_loss = 0.0891710375963478
Trained batch 397 in epoch 15, gen_loss = 0.39381583757586214, disc_loss = 0.08926948668416496
Trained batch 398 in epoch 15, gen_loss = 0.39391608767790304, disc_loss = 0.08930605755684744
Trained batch 399 in epoch 15, gen_loss = 0.39382643859833477, disc_loss = 0.08922361303353682
Trained batch 400 in epoch 15, gen_loss = 0.39376256141133437, disc_loss = 0.08902369290265136
Trained batch 401 in epoch 15, gen_loss = 0.3938977935939879, disc_loss = 0.08894053147179051
Trained batch 402 in epoch 15, gen_loss = 0.3935827419494577, disc_loss = 0.08942215171672645
Trained batch 403 in epoch 15, gen_loss = 0.39361762259118627, disc_loss = 0.08956632753234763
Trained batch 404 in epoch 15, gen_loss = 0.3937794902074484, disc_loss = 0.08964006830190803
Trained batch 405 in epoch 15, gen_loss = 0.3934427864225627, disc_loss = 0.08970484714909213
Trained batch 406 in epoch 15, gen_loss = 0.39344152130863885, disc_loss = 0.08950822324897059
Trained batch 407 in epoch 15, gen_loss = 0.3934386180092891, disc_loss = 0.08933322425639513
Trained batch 408 in epoch 15, gen_loss = 0.3933901621033335, disc_loss = 0.08932365304027617
Trained batch 409 in epoch 15, gen_loss = 0.3934846371048834, disc_loss = 0.08918453364110575
Trained batch 410 in epoch 15, gen_loss = 0.3934988782281133, disc_loss = 0.08899156385330242
Trained batch 411 in epoch 15, gen_loss = 0.39350296603967844, disc_loss = 0.08891065650646693
Trained batch 412 in epoch 15, gen_loss = 0.39336202966531886, disc_loss = 0.0892127264904413
Trained batch 413 in epoch 15, gen_loss = 0.39336471853480826, disc_loss = 0.08931518940408016
Trained batch 414 in epoch 15, gen_loss = 0.3932942362793957, disc_loss = 0.08918237529515502
Trained batch 415 in epoch 15, gen_loss = 0.39333834287782127, disc_loss = 0.08909073176059443
Trained batch 416 in epoch 15, gen_loss = 0.39320597206231217, disc_loss = 0.0889442544475162
Trained batch 417 in epoch 15, gen_loss = 0.392961445001609, disc_loss = 0.08879212094426298
Trained batch 418 in epoch 15, gen_loss = 0.39306757497759026, disc_loss = 0.08866116685930613
Trained batch 419 in epoch 15, gen_loss = 0.3928922422230244, disc_loss = 0.08857202182656952
Trained batch 420 in epoch 15, gen_loss = 0.3930622508081291, disc_loss = 0.08860436590242414
Trained batch 421 in epoch 15, gen_loss = 0.39311445991716115, disc_loss = 0.0884366710383392
Trained batch 422 in epoch 15, gen_loss = 0.39310024516661396, disc_loss = 0.08872251020167596
Trained batch 423 in epoch 15, gen_loss = 0.39330565026205666, disc_loss = 0.08861931732785448
Trained batch 424 in epoch 15, gen_loss = 0.3933674361775903, disc_loss = 0.08860879641683662
Trained batch 425 in epoch 15, gen_loss = 0.39326857705491247, disc_loss = 0.08860855802736232
Trained batch 426 in epoch 15, gen_loss = 0.393486171158192, disc_loss = 0.08848932091870827
Trained batch 427 in epoch 15, gen_loss = 0.39352329211118064, disc_loss = 0.08841134861512022
Trained batch 428 in epoch 15, gen_loss = 0.3935800932851427, disc_loss = 0.08837454312313826
Trained batch 429 in epoch 15, gen_loss = 0.3936162535880887, disc_loss = 0.08819015204993098
Trained batch 430 in epoch 15, gen_loss = 0.39346925381856285, disc_loss = 0.08827513926975826
Trained batch 431 in epoch 15, gen_loss = 0.39373248329179156, disc_loss = 0.08853217425187015
Trained batch 432 in epoch 15, gen_loss = 0.3938394637292307, disc_loss = 0.08838413645003602
Trained batch 433 in epoch 15, gen_loss = 0.39380387120669885, disc_loss = 0.08854184034902791
Trained batch 434 in epoch 15, gen_loss = 0.3939226896255866, disc_loss = 0.0883983229340493
Trained batch 435 in epoch 15, gen_loss = 0.3939840989443687, disc_loss = 0.0882197536160708
Trained batch 436 in epoch 15, gen_loss = 0.3940853523239664, disc_loss = 0.08803319946587836
Trained batch 437 in epoch 15, gen_loss = 0.39415058422170274, disc_loss = 0.08785689611744867
Trained batch 438 in epoch 15, gen_loss = 0.39405093102764704, disc_loss = 0.08772936413925914
Trained batch 439 in epoch 15, gen_loss = 0.39408106881786475, disc_loss = 0.0875694420971823
Trained batch 440 in epoch 15, gen_loss = 0.3939840022195764, disc_loss = 0.08743086757345332
Trained batch 441 in epoch 15, gen_loss = 0.3938789654573704, disc_loss = 0.08724949803894462
Trained batch 442 in epoch 15, gen_loss = 0.3940055676090529, disc_loss = 0.08712120143944738
Trained batch 443 in epoch 15, gen_loss = 0.39407613460679314, disc_loss = 0.08712462047198871
Trained batch 444 in epoch 15, gen_loss = 0.39408496025573003, disc_loss = 0.08703227567203929
Trained batch 445 in epoch 15, gen_loss = 0.3940322541134774, disc_loss = 0.0868734337698518
Trained batch 446 in epoch 15, gen_loss = 0.39395595260247823, disc_loss = 0.08671757185069107
Trained batch 447 in epoch 15, gen_loss = 0.3938226833873029, disc_loss = 0.08658395158376411
Trained batch 448 in epoch 15, gen_loss = 0.39365046336948206, disc_loss = 0.08654067180387029
Trained batch 449 in epoch 15, gen_loss = 0.39358180188470415, disc_loss = 0.08636962414201763
Trained batch 450 in epoch 15, gen_loss = 0.39382439769160194, disc_loss = 0.08631438902783685
Trained batch 451 in epoch 15, gen_loss = 0.393942852760047, disc_loss = 0.08626863288289283
Trained batch 452 in epoch 15, gen_loss = 0.3941656042868991, disc_loss = 0.08610240541086028
Trained batch 453 in epoch 15, gen_loss = 0.3942462989346571, disc_loss = 0.08597861821988868
Trained batch 454 in epoch 15, gen_loss = 0.3942269547627522, disc_loss = 0.08584596621138708
Trained batch 455 in epoch 15, gen_loss = 0.39422274037803473, disc_loss = 0.08575927399164229
Trained batch 456 in epoch 15, gen_loss = 0.39429588042020275, disc_loss = 0.08573449722591062
Trained batch 457 in epoch 15, gen_loss = 0.39444074688650116, disc_loss = 0.0855796686882015
Trained batch 458 in epoch 15, gen_loss = 0.394670909818481, disc_loss = 0.0854086867434202
Trained batch 459 in epoch 15, gen_loss = 0.39461379475567654, disc_loss = 0.0853210712540085
Trained batch 460 in epoch 15, gen_loss = 0.39479797183174375, disc_loss = 0.0853729692132186
Testing Epoch 15
Training Epoch 16
Trained batch 0 in epoch 16, gen_loss = 0.34871336817741394, disc_loss = 0.045580580830574036
Trained batch 1 in epoch 16, gen_loss = 0.4215020388364792, disc_loss = 0.05523185431957245
Trained batch 2 in epoch 16, gen_loss = 0.42469748854637146, disc_loss = 0.055152200162410736
Trained batch 3 in epoch 16, gen_loss = 0.4338703826069832, disc_loss = 0.057092031463980675
Trained batch 4 in epoch 16, gen_loss = 0.43957569599151614, disc_loss = 0.04892848841845989
Trained batch 5 in epoch 16, gen_loss = 0.4343273639678955, disc_loss = 0.04971087072044611
Trained batch 6 in epoch 16, gen_loss = 0.43548783659935, disc_loss = 0.05266954403902803
Trained batch 7 in epoch 16, gen_loss = 0.43609223514795303, disc_loss = 0.05799297778867185
Trained batch 8 in epoch 16, gen_loss = 0.4295775360531277, disc_loss = 0.05590527277025911
Trained batch 9 in epoch 16, gen_loss = 0.43075215220451357, disc_loss = 0.051595840509980916
Trained batch 10 in epoch 16, gen_loss = 0.43258384411985223, disc_loss = 0.050646510229192
Trained batch 11 in epoch 16, gen_loss = 0.4219023585319519, disc_loss = 0.05100334303764006
Trained batch 12 in epoch 16, gen_loss = 0.42653075089821446, disc_loss = 0.054955375810655266
Trained batch 13 in epoch 16, gen_loss = 0.4270020957504, disc_loss = 0.05860652874356934
Trained batch 14 in epoch 16, gen_loss = 0.43167238831520083, disc_loss = 0.06819517606248458
Trained batch 15 in epoch 16, gen_loss = 0.4256071038544178, disc_loss = 0.0775261110975407
Trained batch 16 in epoch 16, gen_loss = 0.42464647573583264, disc_loss = 0.07918357186238556
Trained batch 17 in epoch 16, gen_loss = 0.4261252284049988, disc_loss = 0.07635516502584021
Trained batch 18 in epoch 16, gen_loss = 0.42211239588888066, disc_loss = 0.07379542021571021
Trained batch 19 in epoch 16, gen_loss = 0.4187459900975227, disc_loss = 0.07624527630396187
Trained batch 20 in epoch 16, gen_loss = 0.4207073904219128, disc_loss = 0.07417705091869548
Trained batch 21 in epoch 16, gen_loss = 0.4223608510060744, disc_loss = 0.07357877192341468
Trained batch 22 in epoch 16, gen_loss = 0.4194161697574284, disc_loss = 0.07216403605011494
Trained batch 23 in epoch 16, gen_loss = 0.4188199241956075, disc_loss = 0.07076649883917223
Trained batch 24 in epoch 16, gen_loss = 0.42080911159515383, disc_loss = 0.0713592417910695
Trained batch 25 in epoch 16, gen_loss = 0.41788389591070324, disc_loss = 0.06995961159610978
Trained batch 26 in epoch 16, gen_loss = 0.42107171482510036, disc_loss = 0.06770621298777836
Trained batch 27 in epoch 16, gen_loss = 0.4201703390904835, disc_loss = 0.06551045412197709
Trained batch 28 in epoch 16, gen_loss = 0.41860070927389736, disc_loss = 0.06424011090963051
Trained batch 29 in epoch 16, gen_loss = 0.4169148921966553, disc_loss = 0.0644931818669041
Trained batch 30 in epoch 16, gen_loss = 0.4147040613235966, disc_loss = 0.06985436049440215
Trained batch 31 in epoch 16, gen_loss = 0.41070201620459557, disc_loss = 0.07670243555912748
Trained batch 32 in epoch 16, gen_loss = 0.4084958253484784, disc_loss = 0.07808853262527422
Trained batch 33 in epoch 16, gen_loss = 0.40950098195496726, disc_loss = 0.07682962206137531
Trained batch 34 in epoch 16, gen_loss = 0.408846561397825, disc_loss = 0.07550455278583935
Trained batch 35 in epoch 16, gen_loss = 0.4040326240162055, disc_loss = 0.07675552130159405
Trained batch 36 in epoch 16, gen_loss = 0.404321877940281, disc_loss = 0.07680687056602659
Trained batch 37 in epoch 16, gen_loss = 0.4048336034542636, disc_loss = 0.07604935628018882
Trained batch 38 in epoch 16, gen_loss = 0.40532905894976395, disc_loss = 0.07448144830190219
Trained batch 39 in epoch 16, gen_loss = 0.4037739437073469, disc_loss = 0.07496483940631152
Trained batch 40 in epoch 16, gen_loss = 0.4055617099128118, disc_loss = 0.0770720957619388
Trained batch 41 in epoch 16, gen_loss = 0.403495454007671, disc_loss = 0.0770249105989933
Trained batch 42 in epoch 16, gen_loss = 0.4026976397564245, disc_loss = 0.07547224871814251
Trained batch 43 in epoch 16, gen_loss = 0.4007899331098253, disc_loss = 0.07421946136111562
Trained batch 44 in epoch 16, gen_loss = 0.4019620700014962, disc_loss = 0.07357176575395796
Trained batch 45 in epoch 16, gen_loss = 0.4006280351592147, disc_loss = 0.07752452175254407
Trained batch 46 in epoch 16, gen_loss = 0.4012428404802972, disc_loss = 0.0807917095879291
Trained batch 47 in epoch 16, gen_loss = 0.3979201444114248, disc_loss = 0.08065442368388176
Trained batch 48 in epoch 16, gen_loss = 0.3971249482461384, disc_loss = 0.08023809694818088
Trained batch 49 in epoch 16, gen_loss = 0.3964340046048164, disc_loss = 0.08003575600683689
Trained batch 50 in epoch 16, gen_loss = 0.39463652495075674, disc_loss = 0.08264656985799472
Trained batch 51 in epoch 16, gen_loss = 0.3929279690178541, disc_loss = 0.08132028708664271
Trained batch 52 in epoch 16, gen_loss = 0.3919431480034342, disc_loss = 0.08206472250650514
Trained batch 53 in epoch 16, gen_loss = 0.3928627562191751, disc_loss = 0.08166229821465633
Trained batch 54 in epoch 16, gen_loss = 0.3936894625425339, disc_loss = 0.08110950067639351
Trained batch 55 in epoch 16, gen_loss = 0.39335255830415655, disc_loss = 0.08022975648886391
Trained batch 56 in epoch 16, gen_loss = 0.3929033459801423, disc_loss = 0.0808601723820494
Trained batch 57 in epoch 16, gen_loss = 0.3941268276037841, disc_loss = 0.08210302471857646
Trained batch 58 in epoch 16, gen_loss = 0.39549907309524085, disc_loss = 0.08110215306534606
Trained batch 59 in epoch 16, gen_loss = 0.3953825138509274, disc_loss = 0.08150315837313732
Trained batch 60 in epoch 16, gen_loss = 0.39563838551278974, disc_loss = 0.08033431501540005
Trained batch 61 in epoch 16, gen_loss = 0.3970426111932724, disc_loss = 0.08184479726778884
Trained batch 62 in epoch 16, gen_loss = 0.3975343332877235, disc_loss = 0.08101622163066788
Trained batch 63 in epoch 16, gen_loss = 0.39739675470627844, disc_loss = 0.08203173259971663
Trained batch 64 in epoch 16, gen_loss = 0.3975231571839406, disc_loss = 0.08329779179050373
Trained batch 65 in epoch 16, gen_loss = 0.39697310215596, disc_loss = 0.08305253082829894
Trained batch 66 in epoch 16, gen_loss = 0.3950524901721015, disc_loss = 0.0836215651413398
Trained batch 67 in epoch 16, gen_loss = 0.3954072145416456, disc_loss = 0.08281703737071332
Trained batch 68 in epoch 16, gen_loss = 0.39522027688613837, disc_loss = 0.08476406298037889
Trained batch 69 in epoch 16, gen_loss = 0.394609468962465, disc_loss = 0.08543511357690607
Trained batch 70 in epoch 16, gen_loss = 0.39423936836316553, disc_loss = 0.08464593566219572
Trained batch 71 in epoch 16, gen_loss = 0.39457894137336147, disc_loss = 0.08383492059591743
Trained batch 72 in epoch 16, gen_loss = 0.39453242065971844, disc_loss = 0.08331397874918703
Trained batch 73 in epoch 16, gen_loss = 0.3944104247399279, disc_loss = 0.08309872231974795
Trained batch 74 in epoch 16, gen_loss = 0.39538303037484485, disc_loss = 0.08263492688536644
Trained batch 75 in epoch 16, gen_loss = 0.3958004420917285, disc_loss = 0.08249913455036126
Trained batch 76 in epoch 16, gen_loss = 0.3981468102761677, disc_loss = 0.08523416930398384
Trained batch 77 in epoch 16, gen_loss = 0.3981775815288226, disc_loss = 0.08446220330034311
Trained batch 78 in epoch 16, gen_loss = 0.39835299664660345, disc_loss = 0.0846634716785784
Trained batch 79 in epoch 16, gen_loss = 0.39813389237970115, disc_loss = 0.08699782660696656
Trained batch 80 in epoch 16, gen_loss = 0.39821152793772424, disc_loss = 0.08708349810798227
Trained batch 81 in epoch 16, gen_loss = 0.39757743714059274, disc_loss = 0.08885218041789968
Trained batch 82 in epoch 16, gen_loss = 0.39834244656993684, disc_loss = 0.0900616926107421
Trained batch 83 in epoch 16, gen_loss = 0.39770559700472013, disc_loss = 0.09005870690037097
Trained batch 84 in epoch 16, gen_loss = 0.39829196176108195, disc_loss = 0.08954527183052371
Trained batch 85 in epoch 16, gen_loss = 0.3982598038260327, disc_loss = 0.08893509549197069
Trained batch 86 in epoch 16, gen_loss = 0.39846092000089844, disc_loss = 0.0890267373373111
Trained batch 87 in epoch 16, gen_loss = 0.3972843497652899, disc_loss = 0.08989588190293447
Trained batch 88 in epoch 16, gen_loss = 0.3982657996121417, disc_loss = 0.08975163213071528
Trained batch 89 in epoch 16, gen_loss = 0.39792651385068895, disc_loss = 0.0892278436364399
Trained batch 90 in epoch 16, gen_loss = 0.39773327161322586, disc_loss = 0.0887947143720729
Trained batch 91 in epoch 16, gen_loss = 0.3973880178578522, disc_loss = 0.08938474505734832
Trained batch 92 in epoch 16, gen_loss = 0.3975664795406403, disc_loss = 0.08907751200260014
Trained batch 93 in epoch 16, gen_loss = 0.3980382466886906, disc_loss = 0.08898705337196589
Trained batch 94 in epoch 16, gen_loss = 0.39711619599869374, disc_loss = 0.08839564297936464
Trained batch 95 in epoch 16, gen_loss = 0.3969737339454393, disc_loss = 0.08859296831845616
Trained batch 96 in epoch 16, gen_loss = 0.3976149585136433, disc_loss = 0.08906885695442096
Trained batch 97 in epoch 16, gen_loss = 0.398118333396863, disc_loss = 0.08831919218432538
Trained batch 98 in epoch 16, gen_loss = 0.39760297010041246, disc_loss = 0.08791801150925833
Trained batch 99 in epoch 16, gen_loss = 0.3967688281834125, disc_loss = 0.08767360283061862
Trained batch 100 in epoch 16, gen_loss = 0.39717463588360513, disc_loss = 0.08796544858060851
Trained batch 101 in epoch 16, gen_loss = 0.39672812541910246, disc_loss = 0.08851511643140339
Trained batch 102 in epoch 16, gen_loss = 0.39628769717748885, disc_loss = 0.08871274924321661
Trained batch 103 in epoch 16, gen_loss = 0.39598350040614605, disc_loss = 0.08820626431574616
Trained batch 104 in epoch 16, gen_loss = 0.3955054290237881, disc_loss = 0.08868230742712815
Trained batch 105 in epoch 16, gen_loss = 0.3962165776569888, disc_loss = 0.08853425962393577
Trained batch 106 in epoch 16, gen_loss = 0.39616566687543814, disc_loss = 0.08792276748360317
Trained batch 107 in epoch 16, gen_loss = 0.3961153947920711, disc_loss = 0.08749614526621169
Trained batch 108 in epoch 16, gen_loss = 0.3960008562431423, disc_loss = 0.08719175057742026
Trained batch 109 in epoch 16, gen_loss = 0.3953711213036017, disc_loss = 0.08666229613802649
Trained batch 110 in epoch 16, gen_loss = 0.3951537277515944, disc_loss = 0.08630322376350025
Trained batch 111 in epoch 16, gen_loss = 0.3951999243082745, disc_loss = 0.08589062048122287
Trained batch 112 in epoch 16, gen_loss = 0.3947220358964616, disc_loss = 0.08552728606536325
Trained batch 113 in epoch 16, gen_loss = 0.3956061014742182, disc_loss = 0.08571688268791165
Trained batch 114 in epoch 16, gen_loss = 0.39528257056422855, disc_loss = 0.08822804209978684
Trained batch 115 in epoch 16, gen_loss = 0.39621551630311996, disc_loss = 0.08853508988074188
Trained batch 116 in epoch 16, gen_loss = 0.3962431530921887, disc_loss = 0.08835212357788004
Trained batch 117 in epoch 16, gen_loss = 0.39670317519014164, disc_loss = 0.08808218416268543
Trained batch 118 in epoch 16, gen_loss = 0.39675994442791496, disc_loss = 0.08741413992868752
Trained batch 119 in epoch 16, gen_loss = 0.3963643961896499, disc_loss = 0.08736176264161864
Trained batch 120 in epoch 16, gen_loss = 0.39632455955359563, disc_loss = 0.08734511519389704
Trained batch 121 in epoch 16, gen_loss = 0.3965790329165146, disc_loss = 0.08708637925322915
Trained batch 122 in epoch 16, gen_loss = 0.3963191100979239, disc_loss = 0.0870970682339455
Trained batch 123 in epoch 16, gen_loss = 0.3963452653298455, disc_loss = 0.08666501786079138
Trained batch 124 in epoch 16, gen_loss = 0.3963359605073929, disc_loss = 0.08671167674660683
Trained batch 125 in epoch 16, gen_loss = 0.3958230909137499, disc_loss = 0.08666472471067829
Trained batch 126 in epoch 16, gen_loss = 0.3956361510387556, disc_loss = 0.08676784400512853
Trained batch 127 in epoch 16, gen_loss = 0.39571246213745326, disc_loss = 0.08681907775462605
Trained batch 128 in epoch 16, gen_loss = 0.3952746990808221, disc_loss = 0.08659012430860091
Trained batch 129 in epoch 16, gen_loss = 0.39561643245128486, disc_loss = 0.08618169541542346
Trained batch 130 in epoch 16, gen_loss = 0.3952417320195045, disc_loss = 0.08585858239813615
Trained batch 131 in epoch 16, gen_loss = 0.3951711199726119, disc_loss = 0.08576733870149562
Trained batch 132 in epoch 16, gen_loss = 0.39492627115626083, disc_loss = 0.08657671054615114
Trained batch 133 in epoch 16, gen_loss = 0.39497333865112333, disc_loss = 0.08717346338749822
Trained batch 134 in epoch 16, gen_loss = 0.3951010462310579, disc_loss = 0.0866670331745236
Trained batch 135 in epoch 16, gen_loss = 0.3940888764884542, disc_loss = 0.08787265236434691
Trained batch 136 in epoch 16, gen_loss = 0.39475013554966365, disc_loss = 0.08791244717953849
Trained batch 137 in epoch 16, gen_loss = 0.39475649325312046, disc_loss = 0.0880714965093395
Trained batch 138 in epoch 16, gen_loss = 0.39420820322396943, disc_loss = 0.0878160154219154
Trained batch 139 in epoch 16, gen_loss = 0.3937608136662415, disc_loss = 0.08768261564629419
Trained batch 140 in epoch 16, gen_loss = 0.39430689737729147, disc_loss = 0.08737381278200353
Trained batch 141 in epoch 16, gen_loss = 0.3933484534352598, disc_loss = 0.08749572156180799
Trained batch 142 in epoch 16, gen_loss = 0.3934403754822858, disc_loss = 0.08719685254292889
Trained batch 143 in epoch 16, gen_loss = 0.39317837202300626, disc_loss = 0.08695601446864505
Trained batch 144 in epoch 16, gen_loss = 0.3934757044603085, disc_loss = 0.08661653936423104
Trained batch 145 in epoch 16, gen_loss = 0.3933428622884293, disc_loss = 0.08639793164313656
Trained batch 146 in epoch 16, gen_loss = 0.39347546552719714, disc_loss = 0.08602880215158268
Trained batch 147 in epoch 16, gen_loss = 0.3933872615767492, disc_loss = 0.08575258607900627
Trained batch 148 in epoch 16, gen_loss = 0.39406774358061336, disc_loss = 0.08523715352452041
Trained batch 149 in epoch 16, gen_loss = 0.3936243678132693, disc_loss = 0.08529893780748049
Trained batch 150 in epoch 16, gen_loss = 0.393482415387962, disc_loss = 0.0857716015731262
Trained batch 151 in epoch 16, gen_loss = 0.39340786449611187, disc_loss = 0.08532128516143482
Trained batch 152 in epoch 16, gen_loss = 0.393341526389122, disc_loss = 0.08623916537689617
Trained batch 153 in epoch 16, gen_loss = 0.3937179929056725, disc_loss = 0.08601427541489338
Trained batch 154 in epoch 16, gen_loss = 0.3943830144982184, disc_loss = 0.08589086579459329
Trained batch 155 in epoch 16, gen_loss = 0.3941053424317103, disc_loss = 0.08570862254605462
Trained batch 156 in epoch 16, gen_loss = 0.39368856570143607, disc_loss = 0.08556017544191734
Trained batch 157 in epoch 16, gen_loss = 0.3938385198199296, disc_loss = 0.08516852245253476
Trained batch 158 in epoch 16, gen_loss = 0.39366707065195405, disc_loss = 0.08494921163333662
Trained batch 159 in epoch 16, gen_loss = 0.3933084179647267, disc_loss = 0.0854967438033782
Trained batch 160 in epoch 16, gen_loss = 0.3929527038187714, disc_loss = 0.08534693425255162
Trained batch 161 in epoch 16, gen_loss = 0.39331376065074664, disc_loss = 0.08619594908560868
Trained batch 162 in epoch 16, gen_loss = 0.39295750609570484, disc_loss = 0.08610899978391598
Trained batch 163 in epoch 16, gen_loss = 0.3930669028039386, disc_loss = 0.086178359314345
Trained batch 164 in epoch 16, gen_loss = 0.39345446075453905, disc_loss = 0.08622509316738808
Trained batch 165 in epoch 16, gen_loss = 0.39341937517186243, disc_loss = 0.08593339496572693
Trained batch 166 in epoch 16, gen_loss = 0.39389043484262365, disc_loss = 0.08547337587454362
Trained batch 167 in epoch 16, gen_loss = 0.3939882301326309, disc_loss = 0.08502275523884843
Trained batch 168 in epoch 16, gen_loss = 0.394243139575219, disc_loss = 0.08464999004823745
Trained batch 169 in epoch 16, gen_loss = 0.39412425046457966, disc_loss = 0.08450901275500655
Trained batch 170 in epoch 16, gen_loss = 0.3938011060855542, disc_loss = 0.08413805514682977
Trained batch 171 in epoch 16, gen_loss = 0.3934076952553073, disc_loss = 0.08426550072401243
Trained batch 172 in epoch 16, gen_loss = 0.3932696311287797, disc_loss = 0.08392035419046018
Trained batch 173 in epoch 16, gen_loss = 0.39323072246778973, disc_loss = 0.0836350835228189
Trained batch 174 in epoch 16, gen_loss = 0.39303077859537944, disc_loss = 0.08353433703205415
Trained batch 175 in epoch 16, gen_loss = 0.39264474191110244, disc_loss = 0.0837882279725322
Trained batch 176 in epoch 16, gen_loss = 0.39314627487443937, disc_loss = 0.08410503568475024
Trained batch 177 in epoch 16, gen_loss = 0.39340018380558894, disc_loss = 0.08372493491644102
Trained batch 178 in epoch 16, gen_loss = 0.3933492708306073, disc_loss = 0.0840472744819422
Trained batch 179 in epoch 16, gen_loss = 0.3931537948548794, disc_loss = 0.08385630001107024
Trained batch 180 in epoch 16, gen_loss = 0.3935199323115428, disc_loss = 0.08361183415110433
Trained batch 181 in epoch 16, gen_loss = 0.3936248260376218, disc_loss = 0.0832194614653977
Trained batch 182 in epoch 16, gen_loss = 0.39320305388807597, disc_loss = 0.08344617330779631
Trained batch 183 in epoch 16, gen_loss = 0.3927561594578235, disc_loss = 0.08374605983313498
Trained batch 184 in epoch 16, gen_loss = 0.39292449298742654, disc_loss = 0.08346014911359226
Trained batch 185 in epoch 16, gen_loss = 0.39283301472984333, disc_loss = 0.08369409720042861
Trained batch 186 in epoch 16, gen_loss = 0.393155134696374, disc_loss = 0.08378172078652975
Trained batch 187 in epoch 16, gen_loss = 0.3931688375454, disc_loss = 0.08348233005566959
Trained batch 188 in epoch 16, gen_loss = 0.3937616172448668, disc_loss = 0.0832337513221083
Trained batch 189 in epoch 16, gen_loss = 0.3933650842622707, disc_loss = 0.08362895682160007
Trained batch 190 in epoch 16, gen_loss = 0.39396070911310105, disc_loss = 0.0836535017810645
Trained batch 191 in epoch 16, gen_loss = 0.3937781269196421, disc_loss = 0.08332006187508038
Trained batch 192 in epoch 16, gen_loss = 0.3935831239340837, disc_loss = 0.08334980754982776
Trained batch 193 in epoch 16, gen_loss = 0.3933563082642162, disc_loss = 0.08320443382601916
Trained batch 194 in epoch 16, gen_loss = 0.3933115455584648, disc_loss = 0.0828341293363617
Trained batch 195 in epoch 16, gen_loss = 0.3932437596424502, disc_loss = 0.08270647243254495
Trained batch 196 in epoch 16, gen_loss = 0.39353330614905674, disc_loss = 0.08265344533350716
Trained batch 197 in epoch 16, gen_loss = 0.39382803086379564, disc_loss = 0.08257680028357138
Trained batch 198 in epoch 16, gen_loss = 0.39370160044437674, disc_loss = 0.08256013690957323
Trained batch 199 in epoch 16, gen_loss = 0.3931339880079031, disc_loss = 0.0825762218190357
Trained batch 200 in epoch 16, gen_loss = 0.3935131174859716, disc_loss = 0.0824221315844661
Trained batch 201 in epoch 16, gen_loss = 0.3931313879271545, disc_loss = 0.08262477870016258
Trained batch 202 in epoch 16, gen_loss = 0.3930340131074924, disc_loss = 0.08231129225233359
Trained batch 203 in epoch 16, gen_loss = 0.393491626297142, disc_loss = 0.08256240016963406
Trained batch 204 in epoch 16, gen_loss = 0.3941399079270479, disc_loss = 0.08223009255328556
Trained batch 205 in epoch 16, gen_loss = 0.3940020940691522, disc_loss = 0.08289694359743045
Trained batch 206 in epoch 16, gen_loss = 0.39415232880391937, disc_loss = 0.08360302527907534
Trained batch 207 in epoch 16, gen_loss = 0.39426963210392457, disc_loss = 0.08340603292722684
Trained batch 208 in epoch 16, gen_loss = 0.3939334137730621, disc_loss = 0.08306410027730265
Trained batch 209 in epoch 16, gen_loss = 0.39371198082254044, disc_loss = 0.08307759991980025
Trained batch 210 in epoch 16, gen_loss = 0.39400785151533607, disc_loss = 0.08349121735824086
Trained batch 211 in epoch 16, gen_loss = 0.3941557392618566, disc_loss = 0.0833577154300896
Trained batch 212 in epoch 16, gen_loss = 0.39403960941263205, disc_loss = 0.08393898967898368
Trained batch 213 in epoch 16, gen_loss = 0.3943462729036251, disc_loss = 0.08539575559008762
Trained batch 214 in epoch 16, gen_loss = 0.39395612346571546, disc_loss = 0.08519599380101575
Trained batch 215 in epoch 16, gen_loss = 0.3936034131243273, disc_loss = 0.0849808596410892
Trained batch 216 in epoch 16, gen_loss = 0.39361189662860835, disc_loss = 0.08473754965610081
Trained batch 217 in epoch 16, gen_loss = 0.3935745866336954, disc_loss = 0.08445972576310191
Trained batch 218 in epoch 16, gen_loss = 0.3941538058323403, disc_loss = 0.0841371196930267
Trained batch 219 in epoch 16, gen_loss = 0.3947100885212421, disc_loss = 0.08381750892255116
Trained batch 220 in epoch 16, gen_loss = 0.3944206277574349, disc_loss = 0.08403340606145325
Trained batch 221 in epoch 16, gen_loss = 0.3944497584356918, disc_loss = 0.08380940050171974
Trained batch 222 in epoch 16, gen_loss = 0.3947434484825006, disc_loss = 0.08464311434565772
Trained batch 223 in epoch 16, gen_loss = 0.39445628059495774, disc_loss = 0.08479039813807633
Trained batch 224 in epoch 16, gen_loss = 0.39418968657652537, disc_loss = 0.08516939398729138
Trained batch 225 in epoch 16, gen_loss = 0.39404524750677883, disc_loss = 0.08546748873159553
Trained batch 226 in epoch 16, gen_loss = 0.3941154210184114, disc_loss = 0.08535697725129679
Trained batch 227 in epoch 16, gen_loss = 0.3944000134473307, disc_loss = 0.08514406981779948
Trained batch 228 in epoch 16, gen_loss = 0.3939174558788408, disc_loss = 0.08563969065089544
Trained batch 229 in epoch 16, gen_loss = 0.3939911288411721, disc_loss = 0.08555121912985392
Trained batch 230 in epoch 16, gen_loss = 0.3940363356690386, disc_loss = 0.08526131034590852
Trained batch 231 in epoch 16, gen_loss = 0.3939125108179347, disc_loss = 0.08506528000299145
Trained batch 232 in epoch 16, gen_loss = 0.39382679210456145, disc_loss = 0.08482990996280582
Trained batch 233 in epoch 16, gen_loss = 0.39361609728672564, disc_loss = 0.0846936166103388
Trained batch 234 in epoch 16, gen_loss = 0.3937503897763313, disc_loss = 0.0844060791497852
Trained batch 235 in epoch 16, gen_loss = 0.39382968520966627, disc_loss = 0.08449011721048441
Trained batch 236 in epoch 16, gen_loss = 0.39367489617333634, disc_loss = 0.0841959534126495
Trained batch 237 in epoch 16, gen_loss = 0.39375824831864414, disc_loss = 0.08405615268822979
Trained batch 238 in epoch 16, gen_loss = 0.39362435092736486, disc_loss = 0.08387373361315688
Trained batch 239 in epoch 16, gen_loss = 0.3937581846490502, disc_loss = 0.08413922648566464
Trained batch 240 in epoch 16, gen_loss = 0.39411805706152775, disc_loss = 0.0839518052815649
Trained batch 241 in epoch 16, gen_loss = 0.39369469677860086, disc_loss = 0.08431893182256497
Trained batch 242 in epoch 16, gen_loss = 0.3939480313670979, disc_loss = 0.08433073227113658
Trained batch 243 in epoch 16, gen_loss = 0.39377444536715256, disc_loss = 0.0842316268072998
Trained batch 244 in epoch 16, gen_loss = 0.3942130467721394, disc_loss = 0.0840162672710662
Trained batch 245 in epoch 16, gen_loss = 0.3941220148670964, disc_loss = 0.08569295657420062
Trained batch 246 in epoch 16, gen_loss = 0.3943420813271874, disc_loss = 0.08553341910363692
Trained batch 247 in epoch 16, gen_loss = 0.39479252702045825, disc_loss = 0.08571151269960307
Trained batch 248 in epoch 16, gen_loss = 0.39471290311420776, disc_loss = 0.08558271995869028
Trained batch 249 in epoch 16, gen_loss = 0.39483289927244186, disc_loss = 0.0853143096268177
Trained batch 250 in epoch 16, gen_loss = 0.3949241958172673, disc_loss = 0.08509044335093868
Trained batch 251 in epoch 16, gen_loss = 0.39480520968162824, disc_loss = 0.08481179217674903
Trained batch 252 in epoch 16, gen_loss = 0.39500736819189997, disc_loss = 0.08470676658240703
Trained batch 253 in epoch 16, gen_loss = 0.3947114726807189, disc_loss = 0.08454572038329024
Trained batch 254 in epoch 16, gen_loss = 0.39474993950011683, disc_loss = 0.08424600322237787
Trained batch 255 in epoch 16, gen_loss = 0.3946716179489158, disc_loss = 0.08401836891789571
Trained batch 256 in epoch 16, gen_loss = 0.3942877401521698, disc_loss = 0.08423825907466592
Trained batch 257 in epoch 16, gen_loss = 0.39483780402314755, disc_loss = 0.0854654242284596
Trained batch 258 in epoch 16, gen_loss = 0.3948264050092476, disc_loss = 0.08524265014081042
Trained batch 259 in epoch 16, gen_loss = 0.39427934776131923, disc_loss = 0.08539499440230429
Trained batch 260 in epoch 16, gen_loss = 0.3941312489952621, disc_loss = 0.08536109622653532
Trained batch 261 in epoch 16, gen_loss = 0.39428825898252373, disc_loss = 0.08533424284408679
Trained batch 262 in epoch 16, gen_loss = 0.3941092386331848, disc_loss = 0.08529843288356927
Trained batch 263 in epoch 16, gen_loss = 0.39375690319998696, disc_loss = 0.08516924275494547
Trained batch 264 in epoch 16, gen_loss = 0.3939727868111628, disc_loss = 0.0850767956765474
Trained batch 265 in epoch 16, gen_loss = 0.3940663220626967, disc_loss = 0.08479237799791801
Trained batch 266 in epoch 16, gen_loss = 0.3938210640618864, disc_loss = 0.08465265786477577
Trained batch 267 in epoch 16, gen_loss = 0.39368783054289536, disc_loss = 0.08445716796289962
Trained batch 268 in epoch 16, gen_loss = 0.3939743259693167, disc_loss = 0.0844327733993918
Trained batch 269 in epoch 16, gen_loss = 0.3936996849046813, disc_loss = 0.08448143510009956
Trained batch 270 in epoch 16, gen_loss = 0.3938342985521823, disc_loss = 0.08422170231304375
Trained batch 271 in epoch 16, gen_loss = 0.39385930048849654, disc_loss = 0.08404715226018145
Trained batch 272 in epoch 16, gen_loss = 0.393644386104175, disc_loss = 0.08393181042725241
Trained batch 273 in epoch 16, gen_loss = 0.39372021019676307, disc_loss = 0.08398988808634399
Trained batch 274 in epoch 16, gen_loss = 0.39387869200923226, disc_loss = 0.08401541781357744
Trained batch 275 in epoch 16, gen_loss = 0.39417789331164915, disc_loss = 0.08377690635203128
Trained batch 276 in epoch 16, gen_loss = 0.39414008112375487, disc_loss = 0.0835165097697601
Trained batch 277 in epoch 16, gen_loss = 0.3939408767673609, disc_loss = 0.08332088261695324
Trained batch 278 in epoch 16, gen_loss = 0.39383825857365856, disc_loss = 0.08312982122170134
Trained batch 279 in epoch 16, gen_loss = 0.39379792399704455, disc_loss = 0.08302625028216945
Trained batch 280 in epoch 16, gen_loss = 0.39395721553695584, disc_loss = 0.08285667961032471
Trained batch 281 in epoch 16, gen_loss = 0.3938870094452344, disc_loss = 0.08262855110769259
Trained batch 282 in epoch 16, gen_loss = 0.3939543850325022, disc_loss = 0.08249009995928606
Trained batch 283 in epoch 16, gen_loss = 0.3940330408513546, disc_loss = 0.08224939000399285
Trained batch 284 in epoch 16, gen_loss = 0.3939175817527269, disc_loss = 0.08257887799031378
Trained batch 285 in epoch 16, gen_loss = 0.39425677733196246, disc_loss = 0.08283857164018742
Trained batch 286 in epoch 16, gen_loss = 0.39413964930104045, disc_loss = 0.08258306410630925
Trained batch 287 in epoch 16, gen_loss = 0.39390470072006184, disc_loss = 0.08251676671271627
Trained batch 288 in epoch 16, gen_loss = 0.39401020470581255, disc_loss = 0.082297781092408
Trained batch 289 in epoch 16, gen_loss = 0.39411789420349846, disc_loss = 0.08219230985911243
Trained batch 290 in epoch 16, gen_loss = 0.3941631886045548, disc_loss = 0.0819988427683711
Trained batch 291 in epoch 16, gen_loss = 0.39418047845159493, disc_loss = 0.08187028313093908
Trained batch 292 in epoch 16, gen_loss = 0.3945303790703568, disc_loss = 0.08184977474943464
Trained batch 293 in epoch 16, gen_loss = 0.39467459810631617, disc_loss = 0.08196257375700235
Trained batch 294 in epoch 16, gen_loss = 0.3947655109530788, disc_loss = 0.08188279424241539
Trained batch 295 in epoch 16, gen_loss = 0.39458720662907976, disc_loss = 0.08195358710174726
Trained batch 296 in epoch 16, gen_loss = 0.3942902943602315, disc_loss = 0.0818110546034444
Trained batch 297 in epoch 16, gen_loss = 0.394254626493726, disc_loss = 0.08164643525339713
Trained batch 298 in epoch 16, gen_loss = 0.3944074696422022, disc_loss = 0.08139838612510708
Trained batch 299 in epoch 16, gen_loss = 0.39441927964488666, disc_loss = 0.08144756431691348
Trained batch 300 in epoch 16, gen_loss = 0.3948897516905667, disc_loss = 0.08176500857977871
Trained batch 301 in epoch 16, gen_loss = 0.39458336631785956, disc_loss = 0.08215463339406627
Trained batch 302 in epoch 16, gen_loss = 0.39480862144393103, disc_loss = 0.08199645450074386
Trained batch 303 in epoch 16, gen_loss = 0.3947428231078543, disc_loss = 0.0819117333648089
Trained batch 304 in epoch 16, gen_loss = 0.39468913376331327, disc_loss = 0.08173041833167682
Trained batch 305 in epoch 16, gen_loss = 0.39471316663852707, disc_loss = 0.0815886697074508
Trained batch 306 in epoch 16, gen_loss = 0.39457265595853913, disc_loss = 0.08149295458903821
Trained batch 307 in epoch 16, gen_loss = 0.39450865205038677, disc_loss = 0.08152997700267701
Trained batch 308 in epoch 16, gen_loss = 0.3946616582596572, disc_loss = 0.08133834690566877
Trained batch 309 in epoch 16, gen_loss = 0.3949863941919419, disc_loss = 0.08137344180516178
Trained batch 310 in epoch 16, gen_loss = 0.3950795951476051, disc_loss = 0.08118554327181778
Trained batch 311 in epoch 16, gen_loss = 0.39512628092406654, disc_loss = 0.08099146604311103
Trained batch 312 in epoch 16, gen_loss = 0.39515857027171136, disc_loss = 0.08084032014785959
Trained batch 313 in epoch 16, gen_loss = 0.39528271873855286, disc_loss = 0.08084139086982342
Trained batch 314 in epoch 16, gen_loss = 0.3952070230056369, disc_loss = 0.0807783722079226
Trained batch 315 in epoch 16, gen_loss = 0.3951424055178709, disc_loss = 0.08067617841548275
Trained batch 316 in epoch 16, gen_loss = 0.39513491987241933, disc_loss = 0.08048894938246026
Trained batch 317 in epoch 16, gen_loss = 0.3953584018836981, disc_loss = 0.0803120370702408
Trained batch 318 in epoch 16, gen_loss = 0.39532474995967365, disc_loss = 0.0803348797761768
Trained batch 319 in epoch 16, gen_loss = 0.3956466650124639, disc_loss = 0.08043924746161793
Trained batch 320 in epoch 16, gen_loss = 0.3957306434896505, disc_loss = 0.08034855323753717
Trained batch 321 in epoch 16, gen_loss = 0.39618852220892165, disc_loss = 0.08014344100649498
Trained batch 322 in epoch 16, gen_loss = 0.39613669672433066, disc_loss = 0.0800214839389911
Trained batch 323 in epoch 16, gen_loss = 0.39588661294108557, disc_loss = 0.07993519199828122
Trained batch 324 in epoch 16, gen_loss = 0.3957301552937581, disc_loss = 0.07972306898007026
Trained batch 325 in epoch 16, gen_loss = 0.3958996986410369, disc_loss = 0.0795191692394073
Trained batch 326 in epoch 16, gen_loss = 0.3959410621212163, disc_loss = 0.07930867303026105
Trained batch 327 in epoch 16, gen_loss = 0.39580391915287916, disc_loss = 0.07934337233976893
Trained batch 328 in epoch 16, gen_loss = 0.39598263310987536, disc_loss = 0.07935937312587325
Trained batch 329 in epoch 16, gen_loss = 0.39579935060306026, disc_loss = 0.07919211841724587
Trained batch 330 in epoch 16, gen_loss = 0.39592622832769353, disc_loss = 0.07939411810348851
Trained batch 331 in epoch 16, gen_loss = 0.39637392512466535, disc_loss = 0.07958299592866686
Trained batch 332 in epoch 16, gen_loss = 0.39654963855091874, disc_loss = 0.07942256769696782
Trained batch 333 in epoch 16, gen_loss = 0.3965757636877591, disc_loss = 0.07946882510423928
Trained batch 334 in epoch 16, gen_loss = 0.39665567390064693, disc_loss = 0.07926493338517733
Trained batch 335 in epoch 16, gen_loss = 0.39647143622416825, disc_loss = 0.07937668658892758
Trained batch 336 in epoch 16, gen_loss = 0.3963611526995101, disc_loss = 0.08038614938195894
Trained batch 337 in epoch 16, gen_loss = 0.3965197078134181, disc_loss = 0.08025355899662397
Trained batch 338 in epoch 16, gen_loss = 0.39641413307998735, disc_loss = 0.08032690936144563
Trained batch 339 in epoch 16, gen_loss = 0.39616439101450585, disc_loss = 0.08024317051612717
Trained batch 340 in epoch 16, gen_loss = 0.39596920536934804, disc_loss = 0.08056617490237147
Trained batch 341 in epoch 16, gen_loss = 0.3959405699755713, disc_loss = 0.0806739735417068
Trained batch 342 in epoch 16, gen_loss = 0.39591079024983566, disc_loss = 0.08054034149344826
Trained batch 343 in epoch 16, gen_loss = 0.3960374938107507, disc_loss = 0.0803666629985538
Trained batch 344 in epoch 16, gen_loss = 0.39588210371093474, disc_loss = 0.08041855018261983
Trained batch 345 in epoch 16, gen_loss = 0.39574161925584594, disc_loss = 0.08028314374871767
Trained batch 346 in epoch 16, gen_loss = 0.3957383166730232, disc_loss = 0.08014045908284892
Trained batch 347 in epoch 16, gen_loss = 0.39565910908511315, disc_loss = 0.07994665556865606
Trained batch 348 in epoch 16, gen_loss = 0.3958835046322093, disc_loss = 0.07981823852557934
Trained batch 349 in epoch 16, gen_loss = 0.3958638625911304, disc_loss = 0.07969943377854569
Trained batch 350 in epoch 16, gen_loss = 0.39568614463011426, disc_loss = 0.07966544508053112
Trained batch 351 in epoch 16, gen_loss = 0.39595417386259546, disc_loss = 0.07950660635304468
Trained batch 352 in epoch 16, gen_loss = 0.3957921721188948, disc_loss = 0.07946356972969709
Trained batch 353 in epoch 16, gen_loss = 0.3956587995260449, disc_loss = 0.0793259355060672
Trained batch 354 in epoch 16, gen_loss = 0.3957534419398912, disc_loss = 0.0793942268386903
Trained batch 355 in epoch 16, gen_loss = 0.3956464681816235, disc_loss = 0.07955360349027042
Trained batch 356 in epoch 16, gen_loss = 0.39583131625037904, disc_loss = 0.07942526867086229
Trained batch 357 in epoch 16, gen_loss = 0.3959936778055889, disc_loss = 0.0792421471931082
Trained batch 358 in epoch 16, gen_loss = 0.3961071359164868, disc_loss = 0.07914484633667224
Trained batch 359 in epoch 16, gen_loss = 0.3961737856682804, disc_loss = 0.07905824864283204
Trained batch 360 in epoch 16, gen_loss = 0.39631919521539166, disc_loss = 0.07901752332529863
Trained batch 361 in epoch 16, gen_loss = 0.3965590563679927, disc_loss = 0.07895506227913812
Trained batch 362 in epoch 16, gen_loss = 0.3963824960893179, disc_loss = 0.07902627338760483
Trained batch 363 in epoch 16, gen_loss = 0.3964701915917161, disc_loss = 0.07925835690860238
Trained batch 364 in epoch 16, gen_loss = 0.3964798477006285, disc_loss = 0.0791001729973375
Trained batch 365 in epoch 16, gen_loss = 0.3963304146147165, disc_loss = 0.07923947651285292
Trained batch 366 in epoch 16, gen_loss = 0.3966211483735155, disc_loss = 0.07943200060148654
Trained batch 367 in epoch 16, gen_loss = 0.39665830690089776, disc_loss = 0.07927907360515193
Trained batch 368 in epoch 16, gen_loss = 0.39654351819336897, disc_loss = 0.07922621082443855
Trained batch 369 in epoch 16, gen_loss = 0.3964512620020557, disc_loss = 0.07923880842690532
Trained batch 370 in epoch 16, gen_loss = 0.39642604233601664, disc_loss = 0.07927177481935674
Trained batch 371 in epoch 16, gen_loss = 0.3961618565503628, disc_loss = 0.07943773406848151
Trained batch 372 in epoch 16, gen_loss = 0.3962351680201436, disc_loss = 0.07965132183627532
Trained batch 373 in epoch 16, gen_loss = 0.39618881385434757, disc_loss = 0.07971700869580323
Trained batch 374 in epoch 16, gen_loss = 0.39632532974084217, disc_loss = 0.07961313507954279
Trained batch 375 in epoch 16, gen_loss = 0.3964469808926608, disc_loss = 0.07947201473004323
Trained batch 376 in epoch 16, gen_loss = 0.3965783216039445, disc_loss = 0.07938287156172077
Trained batch 377 in epoch 16, gen_loss = 0.39637514432429005, disc_loss = 0.07940912796627908
Trained batch 378 in epoch 16, gen_loss = 0.3962556304985112, disc_loss = 0.07938859000369552
Trained batch 379 in epoch 16, gen_loss = 0.39666095034856547, disc_loss = 0.07965727099462559
Trained batch 380 in epoch 16, gen_loss = 0.3966873059357245, disc_loss = 0.07953425488016737
Trained batch 381 in epoch 16, gen_loss = 0.3967538907811904, disc_loss = 0.07945625428402923
Trained batch 382 in epoch 16, gen_loss = 0.3968934023426967, disc_loss = 0.07940704495142707
Trained batch 383 in epoch 16, gen_loss = 0.39689358878725517, disc_loss = 0.07933306608659525
Trained batch 384 in epoch 16, gen_loss = 0.39674800607291133, disc_loss = 0.0793149108817051
Trained batch 385 in epoch 16, gen_loss = 0.3969003487513473, disc_loss = 0.07936542456091376
Trained batch 386 in epoch 16, gen_loss = 0.39712130850137667, disc_loss = 0.07949287221028208
Trained batch 387 in epoch 16, gen_loss = 0.39721034163820373, disc_loss = 0.07963819600180867
Trained batch 388 in epoch 16, gen_loss = 0.3972239286320375, disc_loss = 0.07947502076472598
Trained batch 389 in epoch 16, gen_loss = 0.3970373026453532, disc_loss = 0.0795392353565265
Trained batch 390 in epoch 16, gen_loss = 0.3973115805698478, disc_loss = 0.07950722187986155
Trained batch 391 in epoch 16, gen_loss = 0.39734466301695426, disc_loss = 0.07937456866992372
Trained batch 392 in epoch 16, gen_loss = 0.3972601264563529, disc_loss = 0.07927783243073762
Trained batch 393 in epoch 16, gen_loss = 0.3974507106515357, disc_loss = 0.07912136862045012
Trained batch 394 in epoch 16, gen_loss = 0.39748472431792486, disc_loss = 0.07894569442053384
Trained batch 395 in epoch 16, gen_loss = 0.39734047256184346, disc_loss = 0.07893373161516708
Trained batch 396 in epoch 16, gen_loss = 0.39745349018489684, disc_loss = 0.0790254852689934
Trained batch 397 in epoch 16, gen_loss = 0.3975108127722788, disc_loss = 0.07886145262038288
Trained batch 398 in epoch 16, gen_loss = 0.39746095934756714, disc_loss = 0.0787253895713796
Trained batch 399 in epoch 16, gen_loss = 0.39763304460793736, disc_loss = 0.07857179391663521
Trained batch 400 in epoch 16, gen_loss = 0.39787143130700786, disc_loss = 0.07840148981502675
Trained batch 401 in epoch 16, gen_loss = 0.3977280943770314, disc_loss = 0.0783330838969765
Trained batch 402 in epoch 16, gen_loss = 0.3977269836084423, disc_loss = 0.07825417055404067
Trained batch 403 in epoch 16, gen_loss = 0.39766848297549945, disc_loss = 0.07847519588223335
Trained batch 404 in epoch 16, gen_loss = 0.3978773529514854, disc_loss = 0.07880780829783575
Trained batch 405 in epoch 16, gen_loss = 0.3978099005636323, disc_loss = 0.07864440302708613
Trained batch 406 in epoch 16, gen_loss = 0.39767932880862045, disc_loss = 0.07927702576452889
Trained batch 407 in epoch 16, gen_loss = 0.39764235318437513, disc_loss = 0.07944251294247806
Trained batch 408 in epoch 16, gen_loss = 0.39772841877196996, disc_loss = 0.07947804271027191
Trained batch 409 in epoch 16, gen_loss = 0.39778099885074103, disc_loss = 0.07947805400756074
Trained batch 410 in epoch 16, gen_loss = 0.3975203695305943, disc_loss = 0.07970124980267092
Trained batch 411 in epoch 16, gen_loss = 0.3978572412240274, disc_loss = 0.08017192539098916
Trained batch 412 in epoch 16, gen_loss = 0.39785528193807485, disc_loss = 0.08004726146147124
Trained batch 413 in epoch 16, gen_loss = 0.39778121157688795, disc_loss = 0.07996131127457255
Trained batch 414 in epoch 16, gen_loss = 0.39775332330939284, disc_loss = 0.08004529697439039
Trained batch 415 in epoch 16, gen_loss = 0.3978472290775524, disc_loss = 0.0809236968231674
Trained batch 416 in epoch 16, gen_loss = 0.3976601927900772, disc_loss = 0.08113148410489662
Trained batch 417 in epoch 16, gen_loss = 0.39776045679333105, disc_loss = 0.08114546913938801
Trained batch 418 in epoch 16, gen_loss = 0.3977129367982573, disc_loss = 0.0812665167040145
Trained batch 419 in epoch 16, gen_loss = 0.39763882653344246, disc_loss = 0.0812476595287167
Trained batch 420 in epoch 16, gen_loss = 0.39760567368209504, disc_loss = 0.08127723470100173
Trained batch 421 in epoch 16, gen_loss = 0.397536100757913, disc_loss = 0.08115483233837578
Trained batch 422 in epoch 16, gen_loss = 0.39742669114407075, disc_loss = 0.08109509983225495
Trained batch 423 in epoch 16, gen_loss = 0.3973281529363034, disc_loss = 0.08102518156223562
Trained batch 424 in epoch 16, gen_loss = 0.3975106791538351, disc_loss = 0.08099310516872826
Trained batch 425 in epoch 16, gen_loss = 0.39744903969233025, disc_loss = 0.08104672172312305
Trained batch 426 in epoch 16, gen_loss = 0.3976969349370349, disc_loss = 0.08097794388074088
Trained batch 427 in epoch 16, gen_loss = 0.39772714615285953, disc_loss = 0.08095173523369655
Trained batch 428 in epoch 16, gen_loss = 0.3976092755725056, disc_loss = 0.0810159039759622
Trained batch 429 in epoch 16, gen_loss = 0.39758738171915675, disc_loss = 0.08109876476661411
Trained batch 430 in epoch 16, gen_loss = 0.3975232886258521, disc_loss = 0.081096105376937
Trained batch 431 in epoch 16, gen_loss = 0.39752392619158383, disc_loss = 0.08097790625308537
Trained batch 432 in epoch 16, gen_loss = 0.3976418686725251, disc_loss = 0.08082589646908896
Trained batch 433 in epoch 16, gen_loss = 0.39771731146332306, disc_loss = 0.08073060268167115
Trained batch 434 in epoch 16, gen_loss = 0.39765193842608354, disc_loss = 0.08075932108893477
Trained batch 435 in epoch 16, gen_loss = 0.39754558494741765, disc_loss = 0.08092250297734634
Trained batch 436 in epoch 16, gen_loss = 0.3974550114411784, disc_loss = 0.08126779441515014
Trained batch 437 in epoch 16, gen_loss = 0.3975471325184657, disc_loss = 0.08165991509154644
Trained batch 438 in epoch 16, gen_loss = 0.3973927037251566, disc_loss = 0.08167576179298697
Trained batch 439 in epoch 16, gen_loss = 0.39740609516474334, disc_loss = 0.08158526243218645
Trained batch 440 in epoch 16, gen_loss = 0.39715527038590437, disc_loss = 0.0817598933544086
Trained batch 441 in epoch 16, gen_loss = 0.39734657071699386, disc_loss = 0.08258636510294622
Trained batch 442 in epoch 16, gen_loss = 0.3973935489662614, disc_loss = 0.08260628179506174
Trained batch 443 in epoch 16, gen_loss = 0.39735481334296435, disc_loss = 0.08256213625825874
Trained batch 444 in epoch 16, gen_loss = 0.39735888915785245, disc_loss = 0.08257301644411649
Trained batch 445 in epoch 16, gen_loss = 0.39724825994182594, disc_loss = 0.0825238844647068
Trained batch 446 in epoch 16, gen_loss = 0.39723279495500613, disc_loss = 0.08247387836326822
Trained batch 447 in epoch 16, gen_loss = 0.3972756779819195, disc_loss = 0.08241132885866266
Trained batch 448 in epoch 16, gen_loss = 0.39707139124450813, disc_loss = 0.08243203049894829
Trained batch 449 in epoch 16, gen_loss = 0.39693592439095177, disc_loss = 0.08247668878485759
Trained batch 450 in epoch 16, gen_loss = 0.39697773040926904, disc_loss = 0.08290117023772914
Trained batch 451 in epoch 16, gen_loss = 0.39685640678600925, disc_loss = 0.0831692440608368
Trained batch 452 in epoch 16, gen_loss = 0.3966617114825491, disc_loss = 0.08330992633522083
Trained batch 453 in epoch 16, gen_loss = 0.39660719539231665, disc_loss = 0.08338850283264983
Trained batch 454 in epoch 16, gen_loss = 0.3965362013368816, disc_loss = 0.08372359642206313
Trained batch 455 in epoch 16, gen_loss = 0.3967024803226977, disc_loss = 0.08370629906768731
Trained batch 456 in epoch 16, gen_loss = 0.39668699874006685, disc_loss = 0.08362845335913827
Trained batch 457 in epoch 16, gen_loss = 0.3966253081979189, disc_loss = 0.08357085840264132
Trained batch 458 in epoch 16, gen_loss = 0.3964315139585071, disc_loss = 0.08349269413853912
Trained batch 459 in epoch 16, gen_loss = 0.39628335985800495, disc_loss = 0.08341433254839933
Trained batch 460 in epoch 16, gen_loss = 0.3963089110471163, disc_loss = 0.08331322406141851
Testing Epoch 16
Training Epoch 17
Trained batch 0 in epoch 17, gen_loss = 0.42339569330215454, disc_loss = 0.07546348124742508
Trained batch 1 in epoch 17, gen_loss = 0.4163365364074707, disc_loss = 0.10226457193493843
Trained batch 2 in epoch 17, gen_loss = 0.38108713428179425, disc_loss = 0.17623453587293625
Trained batch 3 in epoch 17, gen_loss = 0.3978632017970085, disc_loss = 0.1684564035385847
Trained batch 4 in epoch 17, gen_loss = 0.4077790081501007, disc_loss = 0.14157375544309617
Trained batch 5 in epoch 17, gen_loss = 0.3972935974597931, disc_loss = 0.1383539860447248
Trained batch 6 in epoch 17, gen_loss = 0.3960439605372293, disc_loss = 0.12749098347766058
Trained batch 7 in epoch 17, gen_loss = 0.3871864974498749, disc_loss = 0.12416346929967403
Trained batch 8 in epoch 17, gen_loss = 0.37965571880340576, disc_loss = 0.12465530799494849
Trained batch 9 in epoch 17, gen_loss = 0.3842128783464432, disc_loss = 0.1166151013225317
Trained batch 10 in epoch 17, gen_loss = 0.38934912193905225, disc_loss = 0.1106204969639128
Trained batch 11 in epoch 17, gen_loss = 0.38763993481794995, disc_loss = 0.11772492124388616
Trained batch 12 in epoch 17, gen_loss = 0.3888810322834895, disc_loss = 0.12678343143600684
Trained batch 13 in epoch 17, gen_loss = 0.3906084682260241, disc_loss = 0.11879701965621539
Trained batch 14 in epoch 17, gen_loss = 0.3850229720274607, disc_loss = 0.1150052160024643
Trained batch 15 in epoch 17, gen_loss = 0.38030202873051167, disc_loss = 0.11009659594856203
Trained batch 16 in epoch 17, gen_loss = 0.3839406546424417, disc_loss = 0.10579161762314684
Trained batch 17 in epoch 17, gen_loss = 0.38379127780596417, disc_loss = 0.10147206754320198
Trained batch 18 in epoch 17, gen_loss = 0.3814851296575446, disc_loss = 0.0995996012107322
Trained batch 19 in epoch 17, gen_loss = 0.38029488623142244, disc_loss = 0.09622399006038904
Trained batch 20 in epoch 17, gen_loss = 0.37729815642038983, disc_loss = 0.09761318936944008
Trained batch 21 in epoch 17, gen_loss = 0.3773508938876065, disc_loss = 0.09652239643037319
Trained batch 22 in epoch 17, gen_loss = 0.38610799675402435, disc_loss = 0.1018641443680162
Trained batch 23 in epoch 17, gen_loss = 0.3825197046001752, disc_loss = 0.09958286195372541
Trained batch 24 in epoch 17, gen_loss = 0.3796126174926758, disc_loss = 0.1015054415166378
Trained batch 25 in epoch 17, gen_loss = 0.38162962748454166, disc_loss = 0.09821155853569508
Trained batch 26 in epoch 17, gen_loss = 0.3839108535537013, disc_loss = 0.10641932004579792
Trained batch 27 in epoch 17, gen_loss = 0.38176279834338595, disc_loss = 0.10902015292750937
Trained batch 28 in epoch 17, gen_loss = 0.3838844792596225, disc_loss = 0.10674474516819263
Trained batch 29 in epoch 17, gen_loss = 0.3831537713607152, disc_loss = 0.10542895073692003
Trained batch 30 in epoch 17, gen_loss = 0.38177098189630815, disc_loss = 0.10621375302153249
Trained batch 31 in epoch 17, gen_loss = 0.3823654754087329, disc_loss = 0.10320444422541186
Trained batch 32 in epoch 17, gen_loss = 0.38382241852355725, disc_loss = 0.10138984639762026
Trained batch 33 in epoch 17, gen_loss = 0.38649053345708284, disc_loss = 0.09894221352741998
Trained batch 34 in epoch 17, gen_loss = 0.38718542541776385, disc_loss = 0.09647836999169418
Trained batch 35 in epoch 17, gen_loss = 0.38554538206921685, disc_loss = 0.09653472419207294
Trained batch 36 in epoch 17, gen_loss = 0.38501504385793534, disc_loss = 0.09649953845183591
Trained batch 37 in epoch 17, gen_loss = 0.38703727486886474, disc_loss = 0.09414066577722367
Trained batch 38 in epoch 17, gen_loss = 0.38747561054352003, disc_loss = 0.0930913233747467
Trained batch 39 in epoch 17, gen_loss = 0.3892564870417118, disc_loss = 0.09215712517034262
Trained batch 40 in epoch 17, gen_loss = 0.390288861059561, disc_loss = 0.09194992852919712
Trained batch 41 in epoch 17, gen_loss = 0.3896787265936534, disc_loss = 0.09059829972240896
Trained batch 42 in epoch 17, gen_loss = 0.3886122031267299, disc_loss = 0.09140409284466228
Trained batch 43 in epoch 17, gen_loss = 0.3882207748564807, disc_loss = 0.0918168354229155
Trained batch 44 in epoch 17, gen_loss = 0.38925795687569514, disc_loss = 0.09197520810282893
Trained batch 45 in epoch 17, gen_loss = 0.39015475239442743, disc_loss = 0.09026803290876358
Trained batch 46 in epoch 17, gen_loss = 0.3899010851028118, disc_loss = 0.09007031173306576
Trained batch 47 in epoch 17, gen_loss = 0.39090952711800736, disc_loss = 0.08917392460474123
Trained batch 48 in epoch 17, gen_loss = 0.39278860238133645, disc_loss = 0.08897017607731479
Trained batch 49 in epoch 17, gen_loss = 0.393643906712532, disc_loss = 0.0883109637722373
Trained batch 50 in epoch 17, gen_loss = 0.39141884621451883, disc_loss = 0.08835737768779783
Trained batch 51 in epoch 17, gen_loss = 0.3905092947758161, disc_loss = 0.08733537474360603
Trained batch 52 in epoch 17, gen_loss = 0.3916171328076776, disc_loss = 0.08783731338972191
Trained batch 53 in epoch 17, gen_loss = 0.3903414375252194, disc_loss = 0.08729123755323666
Trained batch 54 in epoch 17, gen_loss = 0.3924928524277427, disc_loss = 0.08602044721218673
Trained batch 55 in epoch 17, gen_loss = 0.3929359087986605, disc_loss = 0.08473673620859959
Trained batch 56 in epoch 17, gen_loss = 0.3932443966991023, disc_loss = 0.08344222209824805
Trained batch 57 in epoch 17, gen_loss = 0.3915254494239544, disc_loss = 0.08316306484028183
Trained batch 58 in epoch 17, gen_loss = 0.39108219742774963, disc_loss = 0.08263316166476678
Trained batch 59 in epoch 17, gen_loss = 0.3911057258645693, disc_loss = 0.08162310523912311
Trained batch 60 in epoch 17, gen_loss = 0.39235796596183153, disc_loss = 0.08069757842382447
Trained batch 61 in epoch 17, gen_loss = 0.39220649052050804, disc_loss = 0.08003669148010592
Trained batch 62 in epoch 17, gen_loss = 0.39078837869659305, disc_loss = 0.08239421071041197
Trained batch 63 in epoch 17, gen_loss = 0.3924105637706816, disc_loss = 0.08275255758780986
Trained batch 64 in epoch 17, gen_loss = 0.39316579149319575, disc_loss = 0.0824049598322465
Trained batch 65 in epoch 17, gen_loss = 0.392564266016989, disc_loss = 0.08179491989766106
Trained batch 66 in epoch 17, gen_loss = 0.3923239272032211, disc_loss = 0.08143028628025482
Trained batch 67 in epoch 17, gen_loss = 0.39191869646310806, disc_loss = 0.08093574999228996
Trained batch 68 in epoch 17, gen_loss = 0.39334364775298297, disc_loss = 0.07992856506852136
Trained batch 69 in epoch 17, gen_loss = 0.3934576975447791, disc_loss = 0.0789217408746481
Trained batch 70 in epoch 17, gen_loss = 0.3926586848749241, disc_loss = 0.07951249166483611
Trained batch 71 in epoch 17, gen_loss = 0.3933522043128808, disc_loss = 0.07906461553648114
Trained batch 72 in epoch 17, gen_loss = 0.3950353293386224, disc_loss = 0.07972775506850792
Trained batch 73 in epoch 17, gen_loss = 0.3942786749150302, disc_loss = 0.08129179039718332
Trained batch 74 in epoch 17, gen_loss = 0.3939435970783234, disc_loss = 0.0811227789024512
Trained batch 75 in epoch 17, gen_loss = 0.3942369501057424, disc_loss = 0.08045950205996633
Trained batch 76 in epoch 17, gen_loss = 0.39436515662577243, disc_loss = 0.07999669162967762
Trained batch 77 in epoch 17, gen_loss = 0.39405892942196286, disc_loss = 0.07912298325353707
Trained batch 78 in epoch 17, gen_loss = 0.3939028608648083, disc_loss = 0.0782601714511461
Trained batch 79 in epoch 17, gen_loss = 0.39408722929656503, disc_loss = 0.07744702531490474
Trained batch 80 in epoch 17, gen_loss = 0.39402227490036573, disc_loss = 0.07669354526808968
Trained batch 81 in epoch 17, gen_loss = 0.3940853429276769, disc_loss = 0.07606114862804733
Trained batch 82 in epoch 17, gen_loss = 0.39317982670772506, disc_loss = 0.07623100718371122
Trained batch 83 in epoch 17, gen_loss = 0.39356135293131783, disc_loss = 0.07586213172457758
Trained batch 84 in epoch 17, gen_loss = 0.3939541655428269, disc_loss = 0.07535836041411932
Trained batch 85 in epoch 17, gen_loss = 0.393177074055339, disc_loss = 0.07549159690131281
Trained batch 86 in epoch 17, gen_loss = 0.3927598862812437, disc_loss = 0.07639851303364353
Trained batch 87 in epoch 17, gen_loss = 0.3943837054751136, disc_loss = 0.07603899366222322
Trained batch 88 in epoch 17, gen_loss = 0.39433793238039766, disc_loss = 0.07660294359738237
Trained batch 89 in epoch 17, gen_loss = 0.3950653880834579, disc_loss = 0.07828348719825347
Trained batch 90 in epoch 17, gen_loss = 0.3949528254650451, disc_loss = 0.07895871663240941
Trained batch 91 in epoch 17, gen_loss = 0.39490967243909836, disc_loss = 0.07877677640594218
Trained batch 92 in epoch 17, gen_loss = 0.39458396710375304, disc_loss = 0.07857808032103124
Trained batch 93 in epoch 17, gen_loss = 0.3938915837318339, disc_loss = 0.07820549609258454
Trained batch 94 in epoch 17, gen_loss = 0.39302847322664763, disc_loss = 0.07795705044347989
Trained batch 95 in epoch 17, gen_loss = 0.393231565443178, disc_loss = 0.07736358186230063
Trained batch 96 in epoch 17, gen_loss = 0.3940116993545257, disc_loss = 0.07776867029900403
Trained batch 97 in epoch 17, gen_loss = 0.3929534478455174, disc_loss = 0.0795556769839355
Trained batch 98 in epoch 17, gen_loss = 0.3934368048653458, disc_loss = 0.08091904937919944
Trained batch 99 in epoch 17, gen_loss = 0.3931643876433373, disc_loss = 0.08071384534239769
Trained batch 100 in epoch 17, gen_loss = 0.3928441443655751, disc_loss = 0.08069258286516265
Trained batch 101 in epoch 17, gen_loss = 0.3931802014509837, disc_loss = 0.08164042417033046
Trained batch 102 in epoch 17, gen_loss = 0.39234279371002345, disc_loss = 0.0822572344281141
Trained batch 103 in epoch 17, gen_loss = 0.39208864993773973, disc_loss = 0.08289435957200252
Trained batch 104 in epoch 17, gen_loss = 0.3915583346571241, disc_loss = 0.08375031713928495
Trained batch 105 in epoch 17, gen_loss = 0.3913755638981765, disc_loss = 0.08358658421433197
Trained batch 106 in epoch 17, gen_loss = 0.39069826664211593, disc_loss = 0.0840750444576005
Trained batch 107 in epoch 17, gen_loss = 0.3909878109892209, disc_loss = 0.08399862899548477
Trained batch 108 in epoch 17, gen_loss = 0.39014204871763875, disc_loss = 0.08386465121026433
Trained batch 109 in epoch 17, gen_loss = 0.3901589474894784, disc_loss = 0.08398945284160701
Trained batch 110 in epoch 17, gen_loss = 0.38898827148987364, disc_loss = 0.08524337310243298
Trained batch 111 in epoch 17, gen_loss = 0.38905150283660206, disc_loss = 0.08620008832908102
Trained batch 112 in epoch 17, gen_loss = 0.38934512634192947, disc_loss = 0.08636201634607484
Trained batch 113 in epoch 17, gen_loss = 0.3890551966533326, disc_loss = 0.0857266828483134
Trained batch 114 in epoch 17, gen_loss = 0.3898570832998856, disc_loss = 0.08600665450744006
Trained batch 115 in epoch 17, gen_loss = 0.38995816635674446, disc_loss = 0.08610637373579987
Trained batch 116 in epoch 17, gen_loss = 0.39087892699445415, disc_loss = 0.08562366982810518
Trained batch 117 in epoch 17, gen_loss = 0.39068863957615224, disc_loss = 0.08518793515987315
Trained batch 118 in epoch 17, gen_loss = 0.38965872706485394, disc_loss = 0.0858273584426952
Trained batch 119 in epoch 17, gen_loss = 0.38995036979516345, disc_loss = 0.08631468595316012
Trained batch 120 in epoch 17, gen_loss = 0.3897534204908639, disc_loss = 0.08591595741589207
Trained batch 121 in epoch 17, gen_loss = 0.38872805408767014, disc_loss = 0.08581084947361321
Trained batch 122 in epoch 17, gen_loss = 0.3891350593024153, disc_loss = 0.08538103585199612
Trained batch 123 in epoch 17, gen_loss = 0.38893783188635306, disc_loss = 0.0854654907278957
Trained batch 124 in epoch 17, gen_loss = 0.38860656785964964, disc_loss = 0.08519150704145431
Trained batch 125 in epoch 17, gen_loss = 0.3879507834476138, disc_loss = 0.08465694180793232
Trained batch 126 in epoch 17, gen_loss = 0.3879403856795604, disc_loss = 0.08408537121328312
Trained batch 127 in epoch 17, gen_loss = 0.3868991786148399, disc_loss = 0.0839294101606356
Trained batch 128 in epoch 17, gen_loss = 0.3872454549915107, disc_loss = 0.08343242689274079
Trained batch 129 in epoch 17, gen_loss = 0.38728725130741415, disc_loss = 0.08301095723246153
Trained batch 130 in epoch 17, gen_loss = 0.38758869344041547, disc_loss = 0.08304101508821694
Trained batch 131 in epoch 17, gen_loss = 0.3874848945574327, disc_loss = 0.08326965622660337
Trained batch 132 in epoch 17, gen_loss = 0.3878773437406784, disc_loss = 0.08292070996100293
Trained batch 133 in epoch 17, gen_loss = 0.38878106225782366, disc_loss = 0.0830702006733462
Trained batch 134 in epoch 17, gen_loss = 0.3885799628716928, disc_loss = 0.08276333735772858
Trained batch 135 in epoch 17, gen_loss = 0.38815845702500906, disc_loss = 0.08349731316625633
Trained batch 136 in epoch 17, gen_loss = 0.38837476846945546, disc_loss = 0.08733701981930402
Trained batch 137 in epoch 17, gen_loss = 0.3880737242491349, disc_loss = 0.08724590681115355
Trained batch 138 in epoch 17, gen_loss = 0.3880725882465033, disc_loss = 0.08723750312497719
Trained batch 139 in epoch 17, gen_loss = 0.38814256084816795, disc_loss = 0.08755070523225836
Trained batch 140 in epoch 17, gen_loss = 0.3874087151906169, disc_loss = 0.08752059089746458
Trained batch 141 in epoch 17, gen_loss = 0.38771353515101153, disc_loss = 0.08708728890551228
Trained batch 142 in epoch 17, gen_loss = 0.38747529216579624, disc_loss = 0.08711716734602318
Trained batch 143 in epoch 17, gen_loss = 0.3877041515790754, disc_loss = 0.08684722653641883
Trained batch 144 in epoch 17, gen_loss = 0.387022393736346, disc_loss = 0.08695177331823727
Trained batch 145 in epoch 17, gen_loss = 0.38701231634780153, disc_loss = 0.08725333375830764
Trained batch 146 in epoch 17, gen_loss = 0.3869182862797562, disc_loss = 0.08699012508451127
Trained batch 147 in epoch 17, gen_loss = 0.3863481538924011, disc_loss = 0.08676036415823005
Trained batch 148 in epoch 17, gen_loss = 0.38610559681918, disc_loss = 0.08650452132343046
Trained batch 149 in epoch 17, gen_loss = 0.38609260082244873, disc_loss = 0.08609647024422884
Trained batch 150 in epoch 17, gen_loss = 0.3861115099183771, disc_loss = 0.08581770891138654
Trained batch 151 in epoch 17, gen_loss = 0.385766417180237, disc_loss = 0.08554291138180385
Trained batch 152 in epoch 17, gen_loss = 0.3852453973947787, disc_loss = 0.08536387971462378
Trained batch 153 in epoch 17, gen_loss = 0.38555145186263245, disc_loss = 0.08505436232579607
Trained batch 154 in epoch 17, gen_loss = 0.38554505032877767, disc_loss = 0.08544192339383787
Trained batch 155 in epoch 17, gen_loss = 0.3860872962918037, disc_loss = 0.08745909029713426
Trained batch 156 in epoch 17, gen_loss = 0.3858829820232027, disc_loss = 0.08736143224415885
Trained batch 157 in epoch 17, gen_loss = 0.3861038722569429, disc_loss = 0.08700501685372636
Trained batch 158 in epoch 17, gen_loss = 0.38645343529353354, disc_loss = 0.0867564950208619
Trained batch 159 in epoch 17, gen_loss = 0.38628847934305666, disc_loss = 0.08648894710931927
Trained batch 160 in epoch 17, gen_loss = 0.38632068500755734, disc_loss = 0.08623489540833865
Trained batch 161 in epoch 17, gen_loss = 0.3866261865621732, disc_loss = 0.08602159141482395
Trained batch 162 in epoch 17, gen_loss = 0.3864632521304616, disc_loss = 0.08583842016802244
Trained batch 163 in epoch 17, gen_loss = 0.3867901776258538, disc_loss = 0.08582274879260761
Trained batch 164 in epoch 17, gen_loss = 0.38679819630854057, disc_loss = 0.08561000765273065
Trained batch 165 in epoch 17, gen_loss = 0.38657691320741033, disc_loss = 0.08563244122877178
Trained batch 166 in epoch 17, gen_loss = 0.3869438744233754, disc_loss = 0.08596870450381033
Trained batch 167 in epoch 17, gen_loss = 0.38681329041719437, disc_loss = 0.08589651342481375
Trained batch 168 in epoch 17, gen_loss = 0.3868413883200764, disc_loss = 0.08677344830960211
Trained batch 169 in epoch 17, gen_loss = 0.3877390856251997, disc_loss = 0.087000342107871
Trained batch 170 in epoch 17, gen_loss = 0.38768463891152055, disc_loss = 0.08679064591987092
Trained batch 171 in epoch 17, gen_loss = 0.38747471726911015, disc_loss = 0.0864935415515373
Trained batch 172 in epoch 17, gen_loss = 0.38732773220608, disc_loss = 0.08647487148900941
Trained batch 173 in epoch 17, gen_loss = 0.3880892877263584, disc_loss = 0.08684778817254922
Trained batch 174 in epoch 17, gen_loss = 0.3880832806655339, disc_loss = 0.08674381354025432
Trained batch 175 in epoch 17, gen_loss = 0.38837673599747097, disc_loss = 0.08666273718699813
Trained batch 176 in epoch 17, gen_loss = 0.3886246182824259, disc_loss = 0.086603022101572
Trained batch 177 in epoch 17, gen_loss = 0.3886420705010382, disc_loss = 0.08652142389269357
Trained batch 178 in epoch 17, gen_loss = 0.3888516254598202, disc_loss = 0.08635758271430458
Trained batch 179 in epoch 17, gen_loss = 0.3892517886228032, disc_loss = 0.08603434343304898
Trained batch 180 in epoch 17, gen_loss = 0.3892256413375475, disc_loss = 0.08572151653921406
Trained batch 181 in epoch 17, gen_loss = 0.3884257164139014, disc_loss = 0.08617163275542496
Trained batch 182 in epoch 17, gen_loss = 0.389050433300232, disc_loss = 0.08583458907942955
Trained batch 183 in epoch 17, gen_loss = 0.38923712325808796, disc_loss = 0.08544580391911871
Trained batch 184 in epoch 17, gen_loss = 0.38910529992064913, disc_loss = 0.08535663522276524
Trained batch 185 in epoch 17, gen_loss = 0.3888438155734411, disc_loss = 0.08540958523129423
Trained batch 186 in epoch 17, gen_loss = 0.38919277791989676, disc_loss = 0.08584019697624891
Trained batch 187 in epoch 17, gen_loss = 0.3894453857965926, disc_loss = 0.08553998870279719
Trained batch 188 in epoch 17, gen_loss = 0.3890135568128061, disc_loss = 0.08539974723484307
Trained batch 189 in epoch 17, gen_loss = 0.38859325216004725, disc_loss = 0.08539609240956213
Trained batch 190 in epoch 17, gen_loss = 0.3890612754990293, disc_loss = 0.08512163316801737
Trained batch 191 in epoch 17, gen_loss = 0.3888739273728182, disc_loss = 0.08491973856871482
Trained batch 192 in epoch 17, gen_loss = 0.3891743626156002, disc_loss = 0.08473565667346505
Trained batch 193 in epoch 17, gen_loss = 0.3892113902058798, disc_loss = 0.08462039241567254
Trained batch 194 in epoch 17, gen_loss = 0.38912570698138993, disc_loss = 0.08467726813008387
Trained batch 195 in epoch 17, gen_loss = 0.38956880972397573, disc_loss = 0.08517963848342854
Trained batch 196 in epoch 17, gen_loss = 0.3896223836895173, disc_loss = 0.08482867925130019
Trained batch 197 in epoch 17, gen_loss = 0.3894771181724288, disc_loss = 0.0851877272985123
Trained batch 198 in epoch 17, gen_loss = 0.3896497037991806, disc_loss = 0.08520181731194557
Trained batch 199 in epoch 17, gen_loss = 0.38946379370987416, disc_loss = 0.08515383451711386
Trained batch 200 in epoch 17, gen_loss = 0.38938548263922257, disc_loss = 0.08574116533501676
Trained batch 201 in epoch 17, gen_loss = 0.3900953824124714, disc_loss = 0.08549019439367227
Trained batch 202 in epoch 17, gen_loss = 0.3903978438359763, disc_loss = 0.08568202960649
Trained batch 203 in epoch 17, gen_loss = 0.3899242355689114, disc_loss = 0.08537284761904647
Trained batch 204 in epoch 17, gen_loss = 0.38939742162460234, disc_loss = 0.08594640742805673
Trained batch 205 in epoch 17, gen_loss = 0.3898752273141759, disc_loss = 0.08612247963788584
Trained batch 206 in epoch 17, gen_loss = 0.39034131666024524, disc_loss = 0.0858422627510584
Trained batch 207 in epoch 17, gen_loss = 0.3902273802086711, disc_loss = 0.08557166038707902
Trained batch 208 in epoch 17, gen_loss = 0.390214447413335, disc_loss = 0.08565121223820311
Trained batch 209 in epoch 17, gen_loss = 0.3905680350604511, disc_loss = 0.08536253081457246
Trained batch 210 in epoch 17, gen_loss = 0.3904361125275987, disc_loss = 0.0851120432856453
Trained batch 211 in epoch 17, gen_loss = 0.39038218986594453, disc_loss = 0.08478466246962407
Trained batch 212 in epoch 17, gen_loss = 0.3905463612555338, disc_loss = 0.08467808479067165
Trained batch 213 in epoch 17, gen_loss = 0.39054193138797705, disc_loss = 0.08485287735586829
Trained batch 214 in epoch 17, gen_loss = 0.3903766158708306, disc_loss = 0.08459573649303165
Trained batch 215 in epoch 17, gen_loss = 0.390470450192138, disc_loss = 0.08427380844174574
Trained batch 216 in epoch 17, gen_loss = 0.3903219184155838, disc_loss = 0.08414716389854246
Trained batch 217 in epoch 17, gen_loss = 0.3902445663142642, disc_loss = 0.0847610493207675
Trained batch 218 in epoch 17, gen_loss = 0.3907769921843864, disc_loss = 0.08602765185086558
Trained batch 219 in epoch 17, gen_loss = 0.3910860036584464, disc_loss = 0.08578426712192595
Trained batch 220 in epoch 17, gen_loss = 0.39077464723748856, disc_loss = 0.08604506126339484
Trained batch 221 in epoch 17, gen_loss = 0.3907720346574311, disc_loss = 0.08582236942927446
Trained batch 222 in epoch 17, gen_loss = 0.3908749371767044, disc_loss = 0.08552887634428494
Trained batch 223 in epoch 17, gen_loss = 0.39108506503647994, disc_loss = 0.0853641508770774
Trained batch 224 in epoch 17, gen_loss = 0.39103779269589317, disc_loss = 0.08522192133383619
Trained batch 225 in epoch 17, gen_loss = 0.39151198205958426, disc_loss = 0.0855422582996564
Trained batch 226 in epoch 17, gen_loss = 0.3917904889399785, disc_loss = 0.08526302942604089
Trained batch 227 in epoch 17, gen_loss = 0.3918054542389878, disc_loss = 0.08495137775561919
Trained batch 228 in epoch 17, gen_loss = 0.3916114448329767, disc_loss = 0.08469691887644311
Trained batch 229 in epoch 17, gen_loss = 0.39133066930200744, disc_loss = 0.08444811127189061
Trained batch 230 in epoch 17, gen_loss = 0.39128553951199435, disc_loss = 0.08425134207924335
Trained batch 231 in epoch 17, gen_loss = 0.3911182228475809, disc_loss = 0.08407384872131435
Trained batch 232 in epoch 17, gen_loss = 0.39079024140671087, disc_loss = 0.084063584284753
Trained batch 233 in epoch 17, gen_loss = 0.39070267803393877, disc_loss = 0.08384539875098401
Trained batch 234 in epoch 17, gen_loss = 0.39109368394029903, disc_loss = 0.0835808676964742
Trained batch 235 in epoch 17, gen_loss = 0.39100640980621515, disc_loss = 0.08331716118648774
Trained batch 236 in epoch 17, gen_loss = 0.39108118974458317, disc_loss = 0.08313077661102708
Trained batch 237 in epoch 17, gen_loss = 0.390736577954112, disc_loss = 0.08345217637702071
Trained batch 238 in epoch 17, gen_loss = 0.39103497352809585, disc_loss = 0.08340733468329932
Trained batch 239 in epoch 17, gen_loss = 0.3912099876130621, disc_loss = 0.08327516301457459
Trained batch 240 in epoch 17, gen_loss = 0.39087775739149433, disc_loss = 0.08342446018535937
Trained batch 241 in epoch 17, gen_loss = 0.39098895944593365, disc_loss = 0.08327503034013732
Trained batch 242 in epoch 17, gen_loss = 0.3912602675917708, disc_loss = 0.08306068112621459
Trained batch 243 in epoch 17, gen_loss = 0.39123962080625235, disc_loss = 0.08282080107582275
Trained batch 244 in epoch 17, gen_loss = 0.39089716678979447, disc_loss = 0.08275321929962659
Trained batch 245 in epoch 17, gen_loss = 0.3910303979021747, disc_loss = 0.08257853413545867
Trained batch 246 in epoch 17, gen_loss = 0.3910272241483333, disc_loss = 0.08242317551166302
Trained batch 247 in epoch 17, gen_loss = 0.39144559871525536, disc_loss = 0.08249815526012812
Trained batch 248 in epoch 17, gen_loss = 0.3914039366575609, disc_loss = 0.08235205980354404
Trained batch 249 in epoch 17, gen_loss = 0.3915839332938194, disc_loss = 0.08206645907834172
Trained batch 250 in epoch 17, gen_loss = 0.3918902688173659, disc_loss = 0.08203458369327375
Trained batch 251 in epoch 17, gen_loss = 0.3920872028739679, disc_loss = 0.0818068309029239
Trained batch 252 in epoch 17, gen_loss = 0.3920570056546818, disc_loss = 0.0816227194002789
Trained batch 253 in epoch 17, gen_loss = 0.39211556978347734, disc_loss = 0.08152454635715038
Trained batch 254 in epoch 17, gen_loss = 0.3920774760783887, disc_loss = 0.0821331061751527
Trained batch 255 in epoch 17, gen_loss = 0.39213284134166315, disc_loss = 0.08225712141211261
Trained batch 256 in epoch 17, gen_loss = 0.391978567154491, disc_loss = 0.08239572523125531
Trained batch 257 in epoch 17, gen_loss = 0.392003809354564, disc_loss = 0.08220203130238855
Trained batch 258 in epoch 17, gen_loss = 0.3919803434012019, disc_loss = 0.0820063484372377
Trained batch 259 in epoch 17, gen_loss = 0.3920758024431192, disc_loss = 0.08223188886633859
Trained batch 260 in epoch 17, gen_loss = 0.3919248082514467, disc_loss = 0.08238827899969058
Trained batch 261 in epoch 17, gen_loss = 0.3916430020036588, disc_loss = 0.08216628163185624
Trained batch 262 in epoch 17, gen_loss = 0.3914449983789894, disc_loss = 0.08196038198604216
Trained batch 263 in epoch 17, gen_loss = 0.39140054984300426, disc_loss = 0.08178307286421345
Trained batch 264 in epoch 17, gen_loss = 0.3915267466936471, disc_loss = 0.0817844989551407
Trained batch 265 in epoch 17, gen_loss = 0.39172919749989543, disc_loss = 0.08256934934358735
Trained batch 266 in epoch 17, gen_loss = 0.3919416323918082, disc_loss = 0.08253443401223154
Trained batch 267 in epoch 17, gen_loss = 0.39234737868406877, disc_loss = 0.08255154637744956
Trained batch 268 in epoch 17, gen_loss = 0.3923593047715474, disc_loss = 0.08269456700252224
Trained batch 269 in epoch 17, gen_loss = 0.39232358628952946, disc_loss = 0.08283594389687533
Trained batch 270 in epoch 17, gen_loss = 0.3927261434028069, disc_loss = 0.08315022422749947
Trained batch 271 in epoch 17, gen_loss = 0.3927012914791703, disc_loss = 0.08303255112225409
Trained batch 272 in epoch 17, gen_loss = 0.3926025602297905, disc_loss = 0.08330165134613221
Trained batch 273 in epoch 17, gen_loss = 0.39287354808001623, disc_loss = 0.0832295681377125
Trained batch 274 in epoch 17, gen_loss = 0.39291028049859134, disc_loss = 0.08298318336971781
Trained batch 275 in epoch 17, gen_loss = 0.3928471377686314, disc_loss = 0.08277500932023901
Trained batch 276 in epoch 17, gen_loss = 0.3926280411464643, disc_loss = 0.08274483342826475
Trained batch 277 in epoch 17, gen_loss = 0.39246836578031236, disc_loss = 0.08254119183988773
Trained batch 278 in epoch 17, gen_loss = 0.39270401711318653, disc_loss = 0.08230485959065324
Trained batch 279 in epoch 17, gen_loss = 0.39268677346408365, disc_loss = 0.08225475246020193
Trained batch 280 in epoch 17, gen_loss = 0.3925544393126226, disc_loss = 0.08206620558870963
Trained batch 281 in epoch 17, gen_loss = 0.39237133677758224, disc_loss = 0.08250199195909057
Trained batch 282 in epoch 17, gen_loss = 0.3928989782244915, disc_loss = 0.08276843409590397
Trained batch 283 in epoch 17, gen_loss = 0.3930854683505817, disc_loss = 0.0825139372773521
Trained batch 284 in epoch 17, gen_loss = 0.39296568480500005, disc_loss = 0.08233458765439297
Trained batch 285 in epoch 17, gen_loss = 0.3929587610430651, disc_loss = 0.08225574192975263
Trained batch 286 in epoch 17, gen_loss = 0.3932333706459517, disc_loss = 0.08219860514580477
Trained batch 287 in epoch 17, gen_loss = 0.3938538046657211, disc_loss = 0.08257418979256828
Trained batch 288 in epoch 17, gen_loss = 0.39380692894277275, disc_loss = 0.08238632333461698
Trained batch 289 in epoch 17, gen_loss = 0.39355252801344315, disc_loss = 0.08232872037473937
Trained batch 290 in epoch 17, gen_loss = 0.39360323901643457, disc_loss = 0.08213898994963091
Trained batch 291 in epoch 17, gen_loss = 0.3937095094931452, disc_loss = 0.08195840265946336
Trained batch 292 in epoch 17, gen_loss = 0.393803259567596, disc_loss = 0.08173400879783536
Trained batch 293 in epoch 17, gen_loss = 0.3939656812418886, disc_loss = 0.08156887957902283
Trained batch 294 in epoch 17, gen_loss = 0.3939994821609077, disc_loss = 0.08148488002371485
Trained batch 295 in epoch 17, gen_loss = 0.39408380553327704, disc_loss = 0.08132021019952623
Trained batch 296 in epoch 17, gen_loss = 0.3941364301876588, disc_loss = 0.08133143331128037
Trained batch 297 in epoch 17, gen_loss = 0.39408241717407366, disc_loss = 0.0813246429772835
Trained batch 298 in epoch 17, gen_loss = 0.3943545309496564, disc_loss = 0.0812152661040525
Trained batch 299 in epoch 17, gen_loss = 0.3944362305104733, disc_loss = 0.08101875128534933
Trained batch 300 in epoch 17, gen_loss = 0.39448533615598647, disc_loss = 0.08080491374410763
Trained batch 301 in epoch 17, gen_loss = 0.3946120011194652, disc_loss = 0.0808785310082927
Trained batch 302 in epoch 17, gen_loss = 0.39434607277805656, disc_loss = 0.08194928378075755
Trained batch 303 in epoch 17, gen_loss = 0.3943007285951784, disc_loss = 0.0821304779138269
Trained batch 304 in epoch 17, gen_loss = 0.39433969762481624, disc_loss = 0.08199910858920852
Trained batch 305 in epoch 17, gen_loss = 0.3942895162047124, disc_loss = 0.08181799121894966
Trained batch 306 in epoch 17, gen_loss = 0.3940687346050716, disc_loss = 0.08174010868872901
Trained batch 307 in epoch 17, gen_loss = 0.3940503473889518, disc_loss = 0.08163769023384077
Trained batch 308 in epoch 17, gen_loss = 0.3942753624858208, disc_loss = 0.081734479923392
Trained batch 309 in epoch 17, gen_loss = 0.39414944682390457, disc_loss = 0.08176198710176734
Trained batch 310 in epoch 17, gen_loss = 0.394294704607062, disc_loss = 0.08158970037565066
Trained batch 311 in epoch 17, gen_loss = 0.394225409349952, disc_loss = 0.08149828167500882
Trained batch 312 in epoch 17, gen_loss = 0.3941089917962163, disc_loss = 0.08132908002030069
Trained batch 313 in epoch 17, gen_loss = 0.39420865433421104, disc_loss = 0.08120627567516106
Trained batch 314 in epoch 17, gen_loss = 0.3943653525341125, disc_loss = 0.08098769433619012
Trained batch 315 in epoch 17, gen_loss = 0.39409347901804537, disc_loss = 0.08078946826590484
Trained batch 316 in epoch 17, gen_loss = 0.39404512048707774, disc_loss = 0.08076070785252172
Trained batch 317 in epoch 17, gen_loss = 0.3943313757109942, disc_loss = 0.0809631420316983
Trained batch 318 in epoch 17, gen_loss = 0.3940839602562327, disc_loss = 0.08075447511628597
Trained batch 319 in epoch 17, gen_loss = 0.39421157850883903, disc_loss = 0.08065727011126
Trained batch 320 in epoch 17, gen_loss = 0.3943073918979116, disc_loss = 0.0805176115417824
Trained batch 321 in epoch 17, gen_loss = 0.3942747221137426, disc_loss = 0.08031855830459954
Trained batch 322 in epoch 17, gen_loss = 0.39433233799764617, disc_loss = 0.08017090730219156
Trained batch 323 in epoch 17, gen_loss = 0.3941677407258087, disc_loss = 0.08000344428647724
Trained batch 324 in epoch 17, gen_loss = 0.39434389201494363, disc_loss = 0.07983921047873221
Trained batch 325 in epoch 17, gen_loss = 0.3944803859832828, disc_loss = 0.07963405986047961
Trained batch 326 in epoch 17, gen_loss = 0.3941839685042699, disc_loss = 0.07995315303951958
Trained batch 327 in epoch 17, gen_loss = 0.3944397419236782, disc_loss = 0.08010637308130177
Trained batch 328 in epoch 17, gen_loss = 0.3946769985293907, disc_loss = 0.08020491864090633
Trained batch 329 in epoch 17, gen_loss = 0.394674527509646, disc_loss = 0.0801728176122362
Trained batch 330 in epoch 17, gen_loss = 0.39437307921601206, disc_loss = 0.08028247729619103
Trained batch 331 in epoch 17, gen_loss = 0.3946437625192016, disc_loss = 0.08027882894209351
Trained batch 332 in epoch 17, gen_loss = 0.3946963023763519, disc_loss = 0.08018461482839899
Trained batch 333 in epoch 17, gen_loss = 0.3946114988651818, disc_loss = 0.08028034720859842
Trained batch 334 in epoch 17, gen_loss = 0.39456447563064634, disc_loss = 0.08010194755312222
Trained batch 335 in epoch 17, gen_loss = 0.39457832644915297, disc_loss = 0.08004221952121172
Trained batch 336 in epoch 17, gen_loss = 0.39459627897696964, disc_loss = 0.07986888851008712
Trained batch 337 in epoch 17, gen_loss = 0.3946992729807041, disc_loss = 0.07966478103110512
Trained batch 338 in epoch 17, gen_loss = 0.39471370038908843, disc_loss = 0.0794999771902563
Trained batch 339 in epoch 17, gen_loss = 0.39468607617651713, disc_loss = 0.07930160702534897
Trained batch 340 in epoch 17, gen_loss = 0.39457015264943196, disc_loss = 0.07921654248987038
Trained batch 341 in epoch 17, gen_loss = 0.39453002274559257, disc_loss = 0.07956613278648222
Trained batch 342 in epoch 17, gen_loss = 0.3943885643437027, disc_loss = 0.0796785325371272
Trained batch 343 in epoch 17, gen_loss = 0.39448017631332544, disc_loss = 0.0795093752839061
Trained batch 344 in epoch 17, gen_loss = 0.39451947354752087, disc_loss = 0.07955787485546392
Trained batch 345 in epoch 17, gen_loss = 0.3944271913584257, disc_loss = 0.07978613813800704
Trained batch 346 in epoch 17, gen_loss = 0.3946260352557262, disc_loss = 0.07960950105212178
Trained batch 347 in epoch 17, gen_loss = 0.3950382700168538, disc_loss = 0.07961252084183881
Trained batch 348 in epoch 17, gen_loss = 0.3952968054395009, disc_loss = 0.07940847476021011
Trained batch 349 in epoch 17, gen_loss = 0.39514766493013925, disc_loss = 0.07923925303188818
Trained batch 350 in epoch 17, gen_loss = 0.3949053281138086, disc_loss = 0.07911848790805649
Trained batch 351 in epoch 17, gen_loss = 0.39487446747212246, disc_loss = 0.07911392714330842
Trained batch 352 in epoch 17, gen_loss = 0.3949022347545489, disc_loss = 0.07925562069041618
Trained batch 353 in epoch 17, gen_loss = 0.3947509965401585, disc_loss = 0.07908209105743105
Trained batch 354 in epoch 17, gen_loss = 0.3946353197517529, disc_loss = 0.07916986037465468
Trained batch 355 in epoch 17, gen_loss = 0.39486647711208694, disc_loss = 0.07898297532346477
Trained batch 356 in epoch 17, gen_loss = 0.39499249666177927, disc_loss = 0.07881303568806301
Trained batch 357 in epoch 17, gen_loss = 0.39503501751069914, disc_loss = 0.07873929184783438
Trained batch 358 in epoch 17, gen_loss = 0.3950260034593699, disc_loss = 0.07860316509448387
Trained batch 359 in epoch 17, gen_loss = 0.39511165515416197, disc_loss = 0.07854205296478338
Trained batch 360 in epoch 17, gen_loss = 0.39523962614774044, disc_loss = 0.07862866935100912
Trained batch 361 in epoch 17, gen_loss = 0.39515078244782287, disc_loss = 0.0785232588072508
Trained batch 362 in epoch 17, gen_loss = 0.3949745641020704, disc_loss = 0.07863179887786056
Trained batch 363 in epoch 17, gen_loss = 0.3948473792400334, disc_loss = 0.07852790327640352
Trained batch 364 in epoch 17, gen_loss = 0.39502965322096056, disc_loss = 0.07844340229687626
Trained batch 365 in epoch 17, gen_loss = 0.39516341470466937, disc_loss = 0.07835148490680371
Trained batch 366 in epoch 17, gen_loss = 0.395097778303097, disc_loss = 0.07862732537111079
Trained batch 367 in epoch 17, gen_loss = 0.39505059996862774, disc_loss = 0.0785860268642073
Trained batch 368 in epoch 17, gen_loss = 0.39517692906585167, disc_loss = 0.07910431004798187
Trained batch 369 in epoch 17, gen_loss = 0.3951227981899236, disc_loss = 0.07895066152653984
Trained batch 370 in epoch 17, gen_loss = 0.3949944942868302, disc_loss = 0.07909112825808981
Trained batch 371 in epoch 17, gen_loss = 0.3950638194638555, disc_loss = 0.07900665408521089
Trained batch 372 in epoch 17, gen_loss = 0.39511243807246793, disc_loss = 0.07896759023954818
Trained batch 373 in epoch 17, gen_loss = 0.39494936395297076, disc_loss = 0.0789869176921121
Trained batch 374 in epoch 17, gen_loss = 0.3951257425546646, disc_loss = 0.07933742632965247
Trained batch 375 in epoch 17, gen_loss = 0.39521513265022573, disc_loss = 0.07914535191524377
Trained batch 376 in epoch 17, gen_loss = 0.39527873094107174, disc_loss = 0.07907437944700768
Trained batch 377 in epoch 17, gen_loss = 0.39518112050635473, disc_loss = 0.07904548945506572
Trained batch 378 in epoch 17, gen_loss = 0.394964920538711, disc_loss = 0.07902421557042247
Trained batch 379 in epoch 17, gen_loss = 0.39482127149638374, disc_loss = 0.07971511279771987
Trained batch 380 in epoch 17, gen_loss = 0.39495978420331407, disc_loss = 0.07974560615995269
Trained batch 381 in epoch 17, gen_loss = 0.3950209934752025, disc_loss = 0.0797704647280549
Trained batch 382 in epoch 17, gen_loss = 0.3949955372290574, disc_loss = 0.07982747373961438
Trained batch 383 in epoch 17, gen_loss = 0.3950400644680485, disc_loss = 0.07975828707276378
Trained batch 384 in epoch 17, gen_loss = 0.3951786448042114, disc_loss = 0.07957858791115222
Trained batch 385 in epoch 17, gen_loss = 0.39503732088161875, disc_loss = 0.07955184063049024
Trained batch 386 in epoch 17, gen_loss = 0.3951297278783118, disc_loss = 0.07943868172626933
Trained batch 387 in epoch 17, gen_loss = 0.3952323356163256, disc_loss = 0.07925811364344254
Trained batch 388 in epoch 17, gen_loss = 0.3951585764367047, disc_loss = 0.07940538538318213
Trained batch 389 in epoch 17, gen_loss = 0.3953382176084396, disc_loss = 0.07959825702680227
Trained batch 390 in epoch 17, gen_loss = 0.3951883122820379, disc_loss = 0.07952316742285591
Trained batch 391 in epoch 17, gen_loss = 0.395184564157104, disc_loss = 0.07947372379522695
Trained batch 392 in epoch 17, gen_loss = 0.39491035385441237, disc_loss = 0.0795802497198336
Trained batch 393 in epoch 17, gen_loss = 0.3949422412339201, disc_loss = 0.07984651735307753
Trained batch 394 in epoch 17, gen_loss = 0.39497228766543957, disc_loss = 0.07970887796976898
Trained batch 395 in epoch 17, gen_loss = 0.39476815554680245, disc_loss = 0.07986772606958344
Trained batch 396 in epoch 17, gen_loss = 0.3948408277794456, disc_loss = 0.0797038422592491
Trained batch 397 in epoch 17, gen_loss = 0.3947747696060032, disc_loss = 0.07968267340718502
Trained batch 398 in epoch 17, gen_loss = 0.3948913973599747, disc_loss = 0.07950671136678013
Trained batch 399 in epoch 17, gen_loss = 0.3950307931378484, disc_loss = 0.07937052555382251
Trained batch 400 in epoch 17, gen_loss = 0.3949032250856818, disc_loss = 0.07923186006038414
Trained batch 401 in epoch 17, gen_loss = 0.3949801374356545, disc_loss = 0.07955522277851158
Trained batch 402 in epoch 17, gen_loss = 0.39484042746405446, disc_loss = 0.07950495599905404
Trained batch 403 in epoch 17, gen_loss = 0.39463634593504493, disc_loss = 0.07979110073722383
Trained batch 404 in epoch 17, gen_loss = 0.39473194358525454, disc_loss = 0.07981292438451891
Trained batch 405 in epoch 17, gen_loss = 0.39484130253492317, disc_loss = 0.0798557776581551
Trained batch 406 in epoch 17, gen_loss = 0.39479387066434585, disc_loss = 0.07984616781793151
Trained batch 407 in epoch 17, gen_loss = 0.39454769799668415, disc_loss = 0.07970977493324409
Trained batch 408 in epoch 17, gen_loss = 0.3944640224093621, disc_loss = 0.07961088130227803
Trained batch 409 in epoch 17, gen_loss = 0.39457026970822634, disc_loss = 0.07949099847365443
Trained batch 410 in epoch 17, gen_loss = 0.3944571905400051, disc_loss = 0.07966233740522188
Trained batch 411 in epoch 17, gen_loss = 0.39437044032135055, disc_loss = 0.0801339248349004
Trained batch 412 in epoch 17, gen_loss = 0.3945057923583084, disc_loss = 0.0800927822178198
Trained batch 413 in epoch 17, gen_loss = 0.39489206934464727, disc_loss = 0.08005454212625102
Trained batch 414 in epoch 17, gen_loss = 0.3947741551930646, disc_loss = 0.08008552440947078
Trained batch 415 in epoch 17, gen_loss = 0.39470763121230096, disc_loss = 0.07998591695930092
Trained batch 416 in epoch 17, gen_loss = 0.39477247517886493, disc_loss = 0.07986658778961757
Trained batch 417 in epoch 17, gen_loss = 0.39496211040961116, disc_loss = 0.07988955345646474
Trained batch 418 in epoch 17, gen_loss = 0.3948937734513408, disc_loss = 0.080044412220826
Trained batch 419 in epoch 17, gen_loss = 0.39505471647495316, disc_loss = 0.07998452866449952
Trained batch 420 in epoch 17, gen_loss = 0.3953305435081559, disc_loss = 0.08012567699893496
Trained batch 421 in epoch 17, gen_loss = 0.39542752839801437, disc_loss = 0.08009560205377815
Trained batch 422 in epoch 17, gen_loss = 0.3955132498033785, disc_loss = 0.0799656351830097
Trained batch 423 in epoch 17, gen_loss = 0.3953459320133025, disc_loss = 0.07996388663590517
Trained batch 424 in epoch 17, gen_loss = 0.3951135567005943, disc_loss = 0.08022087400450426
Trained batch 425 in epoch 17, gen_loss = 0.3953354376512514, disc_loss = 0.08088300928053721
Trained batch 426 in epoch 17, gen_loss = 0.3955655439606316, disc_loss = 0.08074490795788776
Trained batch 427 in epoch 17, gen_loss = 0.39551791670584235, disc_loss = 0.08069413949987878
Trained batch 428 in epoch 17, gen_loss = 0.3954109102487564, disc_loss = 0.08064828895570793
Trained batch 429 in epoch 17, gen_loss = 0.3952551626535349, disc_loss = 0.08060049366119296
Trained batch 430 in epoch 17, gen_loss = 0.39520020865923844, disc_loss = 0.08054537430682204
Trained batch 431 in epoch 17, gen_loss = 0.3952329940059119, disc_loss = 0.08043600068669077
Trained batch 432 in epoch 17, gen_loss = 0.3951803096516303, disc_loss = 0.08035883895932389
Trained batch 433 in epoch 17, gen_loss = 0.3953728350008138, disc_loss = 0.08034093957823542
Trained batch 434 in epoch 17, gen_loss = 0.395412872406258, disc_loss = 0.08025123152410847
Trained batch 435 in epoch 17, gen_loss = 0.3952474753039146, disc_loss = 0.08020644606766078
Trained batch 436 in epoch 17, gen_loss = 0.3952414721796114, disc_loss = 0.08007087369259762
Trained batch 437 in epoch 17, gen_loss = 0.39524346627465123, disc_loss = 0.0799499152815097
Trained batch 438 in epoch 17, gen_loss = 0.3951954891510596, disc_loss = 0.0798958851987653
Trained batch 439 in epoch 17, gen_loss = 0.3952637957239693, disc_loss = 0.07997297101908109
Trained batch 440 in epoch 17, gen_loss = 0.3950977956289066, disc_loss = 0.08011196907651938
Trained batch 441 in epoch 17, gen_loss = 0.3952595560866244, disc_loss = 0.0800541945863768
Trained batch 442 in epoch 17, gen_loss = 0.39516954419978856, disc_loss = 0.07994296077563182
Trained batch 443 in epoch 17, gen_loss = 0.3953045782809322, disc_loss = 0.0798805383420004
Trained batch 444 in epoch 17, gen_loss = 0.39535241009814015, disc_loss = 0.07986099691956901
Trained batch 445 in epoch 17, gen_loss = 0.3952191986912035, disc_loss = 0.08014968778069377
Trained batch 446 in epoch 17, gen_loss = 0.3953246826626844, disc_loss = 0.08031307609639311
Trained batch 447 in epoch 17, gen_loss = 0.3954589548188129, disc_loss = 0.08015402184641321
Trained batch 448 in epoch 17, gen_loss = 0.3955268213703797, disc_loss = 0.08005925369363917
Trained batch 449 in epoch 17, gen_loss = 0.3955484649538994, disc_loss = 0.08001876082892219
Trained batch 450 in epoch 17, gen_loss = 0.3955218487660795, disc_loss = 0.07996542140750623
Trained batch 451 in epoch 17, gen_loss = 0.3955849375147208, disc_loss = 0.07982234401933322
Trained batch 452 in epoch 17, gen_loss = 0.3955883178818831, disc_loss = 0.07978486602562614
Trained batch 453 in epoch 17, gen_loss = 0.3957273128077322, disc_loss = 0.0797726343804355
Trained batch 454 in epoch 17, gen_loss = 0.39573431424387207, disc_loss = 0.07968460338415354
Trained batch 455 in epoch 17, gen_loss = 0.39580207092589453, disc_loss = 0.07958296035097814
Trained batch 456 in epoch 17, gen_loss = 0.39583604011676504, disc_loss = 0.07947883093668479
Trained batch 457 in epoch 17, gen_loss = 0.3957545243561528, disc_loss = 0.07948879122237906
Trained batch 458 in epoch 17, gen_loss = 0.3955142151621172, disc_loss = 0.07947604792204753
Trained batch 459 in epoch 17, gen_loss = 0.3957207975504191, disc_loss = 0.07946358668698889
Trained batch 460 in epoch 17, gen_loss = 0.3953982069603533, disc_loss = 0.07942114661118407
Testing Epoch 17
Training Epoch 18
Trained batch 0 in epoch 18, gen_loss = 0.4374156892299652, disc_loss = 0.021052472293376923
Trained batch 1 in epoch 18, gen_loss = 0.41698744893074036, disc_loss = 0.015879125334322453
Trained batch 2 in epoch 18, gen_loss = 0.4031570057074229, disc_loss = 0.017430686081449192
Trained batch 3 in epoch 18, gen_loss = 0.40898775309324265, disc_loss = 0.02205068478360772
Trained batch 4 in epoch 18, gen_loss = 0.4027661859989166, disc_loss = 0.020096566528081894
Trained batch 5 in epoch 18, gen_loss = 0.39710499346256256, disc_loss = 0.019365643461545307
Trained batch 6 in epoch 18, gen_loss = 0.38522958755493164, disc_loss = 0.02921987750700542
Trained batch 7 in epoch 18, gen_loss = 0.37942812964320183, disc_loss = 0.043874780647456646
Trained batch 8 in epoch 18, gen_loss = 0.38604501883188885, disc_loss = 0.04130107847352823
Trained batch 9 in epoch 18, gen_loss = 0.3799379408359528, disc_loss = 0.04033282492309809
Trained batch 10 in epoch 18, gen_loss = 0.37732936306433246, disc_loss = 0.04654580032960935
Trained batch 11 in epoch 18, gen_loss = 0.375682070851326, disc_loss = 0.045453044741104044
Trained batch 12 in epoch 18, gen_loss = 0.3737782652561481, disc_loss = 0.04565399641600939
Trained batch 13 in epoch 18, gen_loss = 0.37609748755182537, disc_loss = 0.05229085776954889
Trained batch 14 in epoch 18, gen_loss = 0.37931449015935265, disc_loss = 0.05190740786492824
Trained batch 15 in epoch 18, gen_loss = 0.3775518983602524, disc_loss = 0.05532019317615777
Trained batch 16 in epoch 18, gen_loss = 0.38007277250289917, disc_loss = 0.06438109552597299
Trained batch 17 in epoch 18, gen_loss = 0.3795321087042491, disc_loss = 0.06558625162061718
Trained batch 18 in epoch 18, gen_loss = 0.38179055797426326, disc_loss = 0.06313679808456647
Trained batch 19 in epoch 18, gen_loss = 0.3808006152510643, disc_loss = 0.06156905079260468
Trained batch 20 in epoch 18, gen_loss = 0.3825584210100628, disc_loss = 0.05982316258762564
Trained batch 21 in epoch 18, gen_loss = 0.38167533007535065, disc_loss = 0.060931601730937306
Trained batch 22 in epoch 18, gen_loss = 0.3818116887756016, disc_loss = 0.059757991410467934
Trained batch 23 in epoch 18, gen_loss = 0.3837128368516763, disc_loss = 0.05878787060889105
Trained batch 24 in epoch 18, gen_loss = 0.38147672057151794, disc_loss = 0.05713253363966942
Trained batch 25 in epoch 18, gen_loss = 0.380867579808602, disc_loss = 0.05714117678312155
Trained batch 26 in epoch 18, gen_loss = 0.3825184835327996, disc_loss = 0.0571147796732408
Trained batch 27 in epoch 18, gen_loss = 0.38236106293542044, disc_loss = 0.0569267062736409
Trained batch 28 in epoch 18, gen_loss = 0.3789126379736539, disc_loss = 0.06452924347129362
Trained batch 29 in epoch 18, gen_loss = 0.379782509803772, disc_loss = 0.06400815757612387
Trained batch 30 in epoch 18, gen_loss = 0.38234263081704417, disc_loss = 0.06387943834547073
Trained batch 31 in epoch 18, gen_loss = 0.37970447819679976, disc_loss = 0.06461174541618675
Trained batch 32 in epoch 18, gen_loss = 0.38023159178820526, disc_loss = 0.06305310736890092
Trained batch 33 in epoch 18, gen_loss = 0.3811461890445036, disc_loss = 0.06216809041250278
Trained batch 34 in epoch 18, gen_loss = 0.3794675316129412, disc_loss = 0.06202530272837196
Trained batch 35 in epoch 18, gen_loss = 0.3771011572745111, disc_loss = 0.06715318113048044
Trained batch 36 in epoch 18, gen_loss = 0.37861131574656515, disc_loss = 0.07262323079379024
Trained batch 37 in epoch 18, gen_loss = 0.3783632187466872, disc_loss = 0.07155882358845127
Trained batch 38 in epoch 18, gen_loss = 0.37764920867406404, disc_loss = 0.07137033828080465
Trained batch 39 in epoch 18, gen_loss = 0.3776630163192749, disc_loss = 0.07033508669119329
Trained batch 40 in epoch 18, gen_loss = 0.3799342215061188, disc_loss = 0.06985485033563725
Trained batch 41 in epoch 18, gen_loss = 0.381703556293533, disc_loss = 0.06903446321597412
Trained batch 42 in epoch 18, gen_loss = 0.38090851972269457, disc_loss = 0.0682302649934278
Trained batch 43 in epoch 18, gen_loss = 0.37981540777466516, disc_loss = 0.06755823970095
Trained batch 44 in epoch 18, gen_loss = 0.3805876208676232, disc_loss = 0.06761042283227046
Trained batch 45 in epoch 18, gen_loss = 0.3797288161257039, disc_loss = 0.06998084102878752
Trained batch 46 in epoch 18, gen_loss = 0.3820082063370563, disc_loss = 0.07237179044317057
Trained batch 47 in epoch 18, gen_loss = 0.38423638232052326, disc_loss = 0.07108822024504964
Trained batch 48 in epoch 18, gen_loss = 0.3842481040224737, disc_loss = 0.07247808569928213
Trained batch 49 in epoch 18, gen_loss = 0.3853570365905762, disc_loss = 0.07266959944739938
Trained batch 50 in epoch 18, gen_loss = 0.3865872422854106, disc_loss = 0.07149272373713114
Trained batch 51 in epoch 18, gen_loss = 0.3859915647369165, disc_loss = 0.07037866912567271
Trained batch 52 in epoch 18, gen_loss = 0.38582609565752857, disc_loss = 0.06975635199122271
Trained batch 53 in epoch 18, gen_loss = 0.3866048918830024, disc_loss = 0.06864072429016232
Trained batch 54 in epoch 18, gen_loss = 0.38547678914937106, disc_loss = 0.06883463417603211
Trained batch 55 in epoch 18, gen_loss = 0.38502431394798414, disc_loss = 0.0682855306159971
Trained batch 56 in epoch 18, gen_loss = 0.3840631680530414, disc_loss = 0.06872539606206772
Trained batch 57 in epoch 18, gen_loss = 0.3827420950963579, disc_loss = 0.06905446771596527
Trained batch 58 in epoch 18, gen_loss = 0.3829779513811661, disc_loss = 0.06911868606772968
Trained batch 59 in epoch 18, gen_loss = 0.38278799653053286, disc_loss = 0.06993455332703888
Trained batch 60 in epoch 18, gen_loss = 0.3822737316616246, disc_loss = 0.06925599815965187
Trained batch 61 in epoch 18, gen_loss = 0.3825405086240461, disc_loss = 0.06834802681940698
Trained batch 62 in epoch 18, gen_loss = 0.382570537309798, disc_loss = 0.06856547285699183
Trained batch 63 in epoch 18, gen_loss = 0.3844573311507702, disc_loss = 0.06905094698595349
Trained batch 64 in epoch 18, gen_loss = 0.3838736822971931, disc_loss = 0.06811852505287298
Trained batch 65 in epoch 18, gen_loss = 0.3836180459369313, disc_loss = 0.06863868974544333
Trained batch 66 in epoch 18, gen_loss = 0.38494106726859934, disc_loss = 0.0687317467197331
Trained batch 67 in epoch 18, gen_loss = 0.3840205818414688, disc_loss = 0.06867022849345471
Trained batch 68 in epoch 18, gen_loss = 0.3844955960909526, disc_loss = 0.06975394761378782
Trained batch 69 in epoch 18, gen_loss = 0.3843935123511723, disc_loss = 0.06911515546962618
Trained batch 70 in epoch 18, gen_loss = 0.3853683891430707, disc_loss = 0.06863032681473964
Trained batch 71 in epoch 18, gen_loss = 0.38554875883791184, disc_loss = 0.06794535033663528
Trained batch 72 in epoch 18, gen_loss = 0.38492202636313766, disc_loss = 0.06761291762176033
Trained batch 73 in epoch 18, gen_loss = 0.3847731589465528, disc_loss = 0.06755810196989694
Trained batch 74 in epoch 18, gen_loss = 0.3851722073554993, disc_loss = 0.06733003846059243
Trained batch 75 in epoch 18, gen_loss = 0.38504008125317724, disc_loss = 0.0671844459506438
Trained batch 76 in epoch 18, gen_loss = 0.3859163929115642, disc_loss = 0.06685082378567427
Trained batch 77 in epoch 18, gen_loss = 0.385377294360063, disc_loss = 0.06633844015260155
Trained batch 78 in epoch 18, gen_loss = 0.3866821923587896, disc_loss = 0.06580698613926203
Trained batch 79 in epoch 18, gen_loss = 0.38601259849965575, disc_loss = 0.06535120072076098
Trained batch 80 in epoch 18, gen_loss = 0.3873198632104897, disc_loss = 0.06497810933922912
Trained batch 81 in epoch 18, gen_loss = 0.3871440149661971, disc_loss = 0.06469516221025004
Trained batch 82 in epoch 18, gen_loss = 0.387652194284531, disc_loss = 0.06463835218988628
Trained batch 83 in epoch 18, gen_loss = 0.387448940603506, disc_loss = 0.06449008778491545
Trained batch 84 in epoch 18, gen_loss = 0.38760858844308294, disc_loss = 0.06419978717013317
Trained batch 85 in epoch 18, gen_loss = 0.38870096033395724, disc_loss = 0.06627730086315857
Trained batch 86 in epoch 18, gen_loss = 0.38828160125633765, disc_loss = 0.06581547750352786
Trained batch 87 in epoch 18, gen_loss = 0.3873457959429784, disc_loss = 0.06711127453441308
Trained batch 88 in epoch 18, gen_loss = 0.38794406511810386, disc_loss = 0.0675285579636693
Trained batch 89 in epoch 18, gen_loss = 0.3883644524547789, disc_loss = 0.06689858969507946
Trained batch 90 in epoch 18, gen_loss = 0.38873619594416775, disc_loss = 0.06666711356572724
Trained batch 91 in epoch 18, gen_loss = 0.3879182795467584, disc_loss = 0.06698151879296031
Trained batch 92 in epoch 18, gen_loss = 0.388308818622302, disc_loss = 0.06696376908490415
Trained batch 93 in epoch 18, gen_loss = 0.3881164488006145, disc_loss = 0.06688679634851027
Trained batch 94 in epoch 18, gen_loss = 0.3875277387468438, disc_loss = 0.06670624518668965
Trained batch 95 in epoch 18, gen_loss = 0.38675247225910425, disc_loss = 0.06728768960844415
Trained batch 96 in epoch 18, gen_loss = 0.38759020339582384, disc_loss = 0.06859080592343181
Trained batch 97 in epoch 18, gen_loss = 0.3877586317913873, disc_loss = 0.06803304802778425
Trained batch 98 in epoch 18, gen_loss = 0.38735044544393366, disc_loss = 0.06794900132926425
Trained batch 99 in epoch 18, gen_loss = 0.3881981933116913, disc_loss = 0.06750379832461477
Trained batch 100 in epoch 18, gen_loss = 0.38827118867694743, disc_loss = 0.06831355822632218
Trained batch 101 in epoch 18, gen_loss = 0.3880237919442794, disc_loss = 0.07002068502718911
Trained batch 102 in epoch 18, gen_loss = 0.3882846557399602, disc_loss = 0.06957209517148513
Trained batch 103 in epoch 18, gen_loss = 0.38843521361167616, disc_loss = 0.06927823291446727
Trained batch 104 in epoch 18, gen_loss = 0.38812110253742765, disc_loss = 0.06890469314087005
Trained batch 105 in epoch 18, gen_loss = 0.3882014026057045, disc_loss = 0.06862047251384214
Trained batch 106 in epoch 18, gen_loss = 0.38811239126686736, disc_loss = 0.06815587598656382
Trained batch 107 in epoch 18, gen_loss = 0.38788502387426516, disc_loss = 0.06780446370787642
Trained batch 108 in epoch 18, gen_loss = 0.3872217035621678, disc_loss = 0.06751039769466317
Trained batch 109 in epoch 18, gen_loss = 0.38674667315049605, disc_loss = 0.06702366608449004
Trained batch 110 in epoch 18, gen_loss = 0.38633390804668805, disc_loss = 0.0669275511660286
Trained batch 111 in epoch 18, gen_loss = 0.3862562243427549, disc_loss = 0.06697195743410182
Trained batch 112 in epoch 18, gen_loss = 0.3861876050982855, disc_loss = 0.06735741658614272
Trained batch 113 in epoch 18, gen_loss = 0.3854559725313856, disc_loss = 0.06968394694686458
Trained batch 114 in epoch 18, gen_loss = 0.385112081144167, disc_loss = 0.069484552498097
Trained batch 115 in epoch 18, gen_loss = 0.38568439180481023, disc_loss = 0.06975513961615748
Trained batch 116 in epoch 18, gen_loss = 0.3849003521295694, disc_loss = 0.07037262537349494
Trained batch 117 in epoch 18, gen_loss = 0.38495885542893815, disc_loss = 0.07067454980402174
Trained batch 118 in epoch 18, gen_loss = 0.3849502909584206, disc_loss = 0.07056034213918097
Trained batch 119 in epoch 18, gen_loss = 0.38494157542785007, disc_loss = 0.07020645826123655
Trained batch 120 in epoch 18, gen_loss = 0.3862900536907606, disc_loss = 0.0698934437414585
Trained batch 121 in epoch 18, gen_loss = 0.3861040709937205, disc_loss = 0.07016777489945049
Trained batch 122 in epoch 18, gen_loss = 0.3871095502764229, disc_loss = 0.06973643838692971
Trained batch 123 in epoch 18, gen_loss = 0.3872790014551532, disc_loss = 0.06963636153828233
Trained batch 124 in epoch 18, gen_loss = 0.3875192258358002, disc_loss = 0.06965533713996411
Trained batch 125 in epoch 18, gen_loss = 0.38796372143995195, disc_loss = 0.0694231330786669
Trained batch 126 in epoch 18, gen_loss = 0.3886111378669739, disc_loss = 0.06896303032385552
Trained batch 127 in epoch 18, gen_loss = 0.388837780803442, disc_loss = 0.06876430609554518
Trained batch 128 in epoch 18, gen_loss = 0.38864826509194783, disc_loss = 0.06885618533101655
Trained batch 129 in epoch 18, gen_loss = 0.3893664577832589, disc_loss = 0.06862972466131816
Trained batch 130 in epoch 18, gen_loss = 0.3897322545979769, disc_loss = 0.06829514429826318
Trained batch 131 in epoch 18, gen_loss = 0.38981731755263876, disc_loss = 0.06794357826143052
Trained batch 132 in epoch 18, gen_loss = 0.3893297637315621, disc_loss = 0.06768935937014289
Trained batch 133 in epoch 18, gen_loss = 0.3899875189831008, disc_loss = 0.06748114483180775
Trained batch 134 in epoch 18, gen_loss = 0.391203714300085, disc_loss = 0.06726180051487905
Trained batch 135 in epoch 18, gen_loss = 0.3909447324626586, disc_loss = 0.06765601894927814
Trained batch 136 in epoch 18, gen_loss = 0.3906211193895688, disc_loss = 0.06740335593965367
Trained batch 137 in epoch 18, gen_loss = 0.3907894122859706, disc_loss = 0.06702832885734412
Trained batch 138 in epoch 18, gen_loss = 0.3902426259123164, disc_loss = 0.06671291028263329
Trained batch 139 in epoch 18, gen_loss = 0.3896183016044753, disc_loss = 0.0668345875106752
Trained batch 140 in epoch 18, gen_loss = 0.389798844114263, disc_loss = 0.06656535338372627
Trained batch 141 in epoch 18, gen_loss = 0.3898410180085142, disc_loss = 0.06630961397584055
Trained batch 142 in epoch 18, gen_loss = 0.39012899140377977, disc_loss = 0.06600220789286224
Trained batch 143 in epoch 18, gen_loss = 0.3894552929947774, disc_loss = 0.06595120124984533
Trained batch 144 in epoch 18, gen_loss = 0.38982586593463503, disc_loss = 0.06555981122214219
Trained batch 145 in epoch 18, gen_loss = 0.3899703129921874, disc_loss = 0.06527613188867291
Trained batch 146 in epoch 18, gen_loss = 0.3898983180117445, disc_loss = 0.06502253719333077
Trained batch 147 in epoch 18, gen_loss = 0.3899520691987631, disc_loss = 0.06465833674411516
Trained batch 148 in epoch 18, gen_loss = 0.38980517931432535, disc_loss = 0.0645925638409669
Trained batch 149 in epoch 18, gen_loss = 0.389777074654897, disc_loss = 0.06435917623341084
Trained batch 150 in epoch 18, gen_loss = 0.3903548109610349, disc_loss = 0.06425850068693918
Trained batch 151 in epoch 18, gen_loss = 0.39095769234393773, disc_loss = 0.0642015359511501
Trained batch 152 in epoch 18, gen_loss = 0.3907982371990977, disc_loss = 0.0645540970213273
Trained batch 153 in epoch 18, gen_loss = 0.3906447084306122, disc_loss = 0.06472815940906475
Trained batch 154 in epoch 18, gen_loss = 0.391440902410015, disc_loss = 0.06575194539562348
Trained batch 155 in epoch 18, gen_loss = 0.3913108072219751, disc_loss = 0.06548168612882876
Trained batch 156 in epoch 18, gen_loss = 0.39056039976466234, disc_loss = 0.06635103149303964
Trained batch 157 in epoch 18, gen_loss = 0.39089956860753555, disc_loss = 0.06615849034978619
Trained batch 158 in epoch 18, gen_loss = 0.3911869614004339, disc_loss = 0.06703988193247304
Trained batch 159 in epoch 18, gen_loss = 0.3910833762958646, disc_loss = 0.06670894891722128
Trained batch 160 in epoch 18, gen_loss = 0.3905457341522904, disc_loss = 0.06659233860486413
Trained batch 161 in epoch 18, gen_loss = 0.3904361454425035, disc_loss = 0.06635433673444721
Trained batch 162 in epoch 18, gen_loss = 0.3903254232157959, disc_loss = 0.06635782770538257
Trained batch 163 in epoch 18, gen_loss = 0.3904299370762778, disc_loss = 0.06699963076403592
Trained batch 164 in epoch 18, gen_loss = 0.3904830074671543, disc_loss = 0.06663690620299542
Trained batch 165 in epoch 18, gen_loss = 0.39042651024927577, disc_loss = 0.06648205608937395
Trained batch 166 in epoch 18, gen_loss = 0.39054910240772955, disc_loss = 0.06635910687510839
Trained batch 167 in epoch 18, gen_loss = 0.39053388631769587, disc_loss = 0.06680916750892288
Trained batch 168 in epoch 18, gen_loss = 0.39054207248095224, disc_loss = 0.06685215922502372
Trained batch 169 in epoch 18, gen_loss = 0.39060091358773846, disc_loss = 0.06664200328728732
Trained batch 170 in epoch 18, gen_loss = 0.39089899749783746, disc_loss = 0.06654723868732564
Trained batch 171 in epoch 18, gen_loss = 0.39082041971905285, disc_loss = 0.06655212665020033
Trained batch 172 in epoch 18, gen_loss = 0.39123622806086017, disc_loss = 0.06627584440429087
Trained batch 173 in epoch 18, gen_loss = 0.3908259430150876, disc_loss = 0.06613021275435371
Trained batch 174 in epoch 18, gen_loss = 0.3906358650752476, disc_loss = 0.06612577050924301
Trained batch 175 in epoch 18, gen_loss = 0.3912128416652029, disc_loss = 0.06596731906756759
Trained batch 176 in epoch 18, gen_loss = 0.3917684757103354, disc_loss = 0.06603250315802245
Trained batch 177 in epoch 18, gen_loss = 0.3918472265594461, disc_loss = 0.06575750851522336
Trained batch 178 in epoch 18, gen_loss = 0.3925133981851226, disc_loss = 0.06579387565689714
Trained batch 179 in epoch 18, gen_loss = 0.3927458612455262, disc_loss = 0.06558862034645345
Trained batch 180 in epoch 18, gen_loss = 0.3925575014636003, disc_loss = 0.06542174075601509
Trained batch 181 in epoch 18, gen_loss = 0.3923378919179623, disc_loss = 0.06596610566171315
Trained batch 182 in epoch 18, gen_loss = 0.39270631065134143, disc_loss = 0.06623012232568747
Trained batch 183 in epoch 18, gen_loss = 0.3931199219887671, disc_loss = 0.06623848707860579
Trained batch 184 in epoch 18, gen_loss = 0.39373810726243097, disc_loss = 0.06613218444021972
Trained batch 185 in epoch 18, gen_loss = 0.39348020781111975, disc_loss = 0.06614109451171532
Trained batch 186 in epoch 18, gen_loss = 0.3928451305404704, disc_loss = 0.06723160533742471
Trained batch 187 in epoch 18, gen_loss = 0.39347454176304186, disc_loss = 0.06726956932230833
Trained batch 188 in epoch 18, gen_loss = 0.3936353672749151, disc_loss = 0.067004012525397
Trained batch 189 in epoch 18, gen_loss = 0.39337070176475925, disc_loss = 0.06687794957113893
Trained batch 190 in epoch 18, gen_loss = 0.3930065588177187, disc_loss = 0.0669433978332587
Trained batch 191 in epoch 18, gen_loss = 0.39313420886173844, disc_loss = 0.067056580078012
Trained batch 192 in epoch 18, gen_loss = 0.3934278052705557, disc_loss = 0.06675965154611076
Trained batch 193 in epoch 18, gen_loss = 0.39326949494401203, disc_loss = 0.0667352665734199
Trained batch 194 in epoch 18, gen_loss = 0.39356747835110395, disc_loss = 0.06687899122062402
Trained batch 195 in epoch 18, gen_loss = 0.3938885071143812, disc_loss = 0.06699013403065655
Trained batch 196 in epoch 18, gen_loss = 0.3944629235618611, disc_loss = 0.06804698112841487
Trained batch 197 in epoch 18, gen_loss = 0.3940716145014522, disc_loss = 0.0683905789064187
Trained batch 198 in epoch 18, gen_loss = 0.39389000930378787, disc_loss = 0.0683106450860075
Trained batch 199 in epoch 18, gen_loss = 0.39391215816140174, disc_loss = 0.06833891256712377
Trained batch 200 in epoch 18, gen_loss = 0.3939026101904722, disc_loss = 0.06823403218677684
Trained batch 201 in epoch 18, gen_loss = 0.39397935525025474, disc_loss = 0.06795125958592732
Trained batch 202 in epoch 18, gen_loss = 0.39383008503561534, disc_loss = 0.06787886267316899
Trained batch 203 in epoch 18, gen_loss = 0.39347046029333976, disc_loss = 0.06806039575067367
Trained batch 204 in epoch 18, gen_loss = 0.3935668506273409, disc_loss = 0.06820778005824583
Trained batch 205 in epoch 18, gen_loss = 0.3938983516785705, disc_loss = 0.06804234630798975
Trained batch 206 in epoch 18, gen_loss = 0.3933536824972733, disc_loss = 0.06788784059007531
Trained batch 207 in epoch 18, gen_loss = 0.3931375793539561, disc_loss = 0.06772221580523854
Trained batch 208 in epoch 18, gen_loss = 0.3926619097376554, disc_loss = 0.06809840959599286
Trained batch 209 in epoch 18, gen_loss = 0.3931734215645563, disc_loss = 0.06860889088628548
Trained batch 210 in epoch 18, gen_loss = 0.3934756370517315, disc_loss = 0.06836054793236804
Trained batch 211 in epoch 18, gen_loss = 0.3934524984292264, disc_loss = 0.06813772175162328
Trained batch 212 in epoch 18, gen_loss = 0.3933236889995879, disc_loss = 0.06786662402689597
Trained batch 213 in epoch 18, gen_loss = 0.3930209366796173, disc_loss = 0.06811558695022608
Trained batch 214 in epoch 18, gen_loss = 0.39374195157095443, disc_loss = 0.06838049739166055
Trained batch 215 in epoch 18, gen_loss = 0.3937794669634766, disc_loss = 0.06820627814589965
Trained batch 216 in epoch 18, gen_loss = 0.3937760838715162, disc_loss = 0.06848412095075516
Trained batch 217 in epoch 18, gen_loss = 0.3936876563030645, disc_loss = 0.06922550009426857
Trained batch 218 in epoch 18, gen_loss = 0.3933514100775871, disc_loss = 0.06937514455163996
Trained batch 219 in epoch 18, gen_loss = 0.3934099630876021, disc_loss = 0.06921003090471707
Trained batch 220 in epoch 18, gen_loss = 0.3934973583501928, disc_loss = 0.06897193664153911
Trained batch 221 in epoch 18, gen_loss = 0.3936794169314273, disc_loss = 0.06894087711315569
Trained batch 222 in epoch 18, gen_loss = 0.39379253836490646, disc_loss = 0.06899738599517019
Trained batch 223 in epoch 18, gen_loss = 0.39349178144974367, disc_loss = 0.06935024235281162
Trained batch 224 in epoch 18, gen_loss = 0.3934599040614234, disc_loss = 0.06955756393157773
Trained batch 225 in epoch 18, gen_loss = 0.39347168750467554, disc_loss = 0.06944887719603371
Trained batch 226 in epoch 18, gen_loss = 0.3935947780567119, disc_loss = 0.06923190296303465
Trained batch 227 in epoch 18, gen_loss = 0.3939182279925597, disc_loss = 0.06901427680675529
Trained batch 228 in epoch 18, gen_loss = 0.39377466976382325, disc_loss = 0.06897243179429696
Trained batch 229 in epoch 18, gen_loss = 0.3935781548852506, disc_loss = 0.06892350084836717
Trained batch 230 in epoch 18, gen_loss = 0.3936453571309259, disc_loss = 0.06866457179043588
Trained batch 231 in epoch 18, gen_loss = 0.3932941257953644, disc_loss = 0.0686391481029769
Trained batch 232 in epoch 18, gen_loss = 0.3936678585576397, disc_loss = 0.06845554357290652
Trained batch 233 in epoch 18, gen_loss = 0.3935658564934364, disc_loss = 0.06847997321389042
Trained batch 234 in epoch 18, gen_loss = 0.3936990349850756, disc_loss = 0.06824455698357618
Trained batch 235 in epoch 18, gen_loss = 0.39335476190356883, disc_loss = 0.06815407827291321
Trained batch 236 in epoch 18, gen_loss = 0.3937269092109133, disc_loss = 0.06826710026271107
Trained batch 237 in epoch 18, gen_loss = 0.3939183957937385, disc_loss = 0.0681454725524395
Trained batch 238 in epoch 18, gen_loss = 0.39374376552873075, disc_loss = 0.06791297548205034
Trained batch 239 in epoch 18, gen_loss = 0.3936797708272934, disc_loss = 0.06767681267810985
Trained batch 240 in epoch 18, gen_loss = 0.39411745575948376, disc_loss = 0.06743960088327589
Trained batch 241 in epoch 18, gen_loss = 0.3942114917699956, disc_loss = 0.06730218157403109
Trained batch 242 in epoch 18, gen_loss = 0.39433684368682986, disc_loss = 0.0673049423391375
Trained batch 243 in epoch 18, gen_loss = 0.39402894162740865, disc_loss = 0.0671882484314322
Trained batch 244 in epoch 18, gen_loss = 0.3937711545399257, disc_loss = 0.0680425970187905
Trained batch 245 in epoch 18, gen_loss = 0.3941154368524629, disc_loss = 0.06797795015485669
Trained batch 246 in epoch 18, gen_loss = 0.39405080470961595, disc_loss = 0.06787855652828327
Trained batch 247 in epoch 18, gen_loss = 0.3938801063885612, disc_loss = 0.06800414415662207
Trained batch 248 in epoch 18, gen_loss = 0.39398689023462163, disc_loss = 0.0679705228664011
Trained batch 249 in epoch 18, gen_loss = 0.393755227804184, disc_loss = 0.06784980646893382
Trained batch 250 in epoch 18, gen_loss = 0.39371759150607655, disc_loss = 0.06761795416311082
Trained batch 251 in epoch 18, gen_loss = 0.3935751548362157, disc_loss = 0.06764154772215064
Trained batch 252 in epoch 18, gen_loss = 0.3937604351948372, disc_loss = 0.0676059522537198
Trained batch 253 in epoch 18, gen_loss = 0.3939551959826252, disc_loss = 0.06739022938798614
Trained batch 254 in epoch 18, gen_loss = 0.3939878828385297, disc_loss = 0.06719953265479382
Trained batch 255 in epoch 18, gen_loss = 0.39406742341816425, disc_loss = 0.06715466365494649
Trained batch 256 in epoch 18, gen_loss = 0.3942484278159383, disc_loss = 0.06692642691374869
Trained batch 257 in epoch 18, gen_loss = 0.3945122675378193, disc_loss = 0.06669358589664795
Trained batch 258 in epoch 18, gen_loss = 0.39468040705647706, disc_loss = 0.0665340508553685
Trained batch 259 in epoch 18, gen_loss = 0.39471647716485536, disc_loss = 0.06645828393431237
Trained batch 260 in epoch 18, gen_loss = 0.3947068706326101, disc_loss = 0.0664258353033913
Trained batch 261 in epoch 18, gen_loss = 0.39475277123105434, disc_loss = 0.0662631134445715
Trained batch 262 in epoch 18, gen_loss = 0.39499074843899834, disc_loss = 0.06639761422820985
Trained batch 263 in epoch 18, gen_loss = 0.39531882457209355, disc_loss = 0.06626031214413657
Trained batch 264 in epoch 18, gen_loss = 0.39542105310368086, disc_loss = 0.06637366093203144
Trained batch 265 in epoch 18, gen_loss = 0.3954935169085524, disc_loss = 0.06621277706585545
Trained batch 266 in epoch 18, gen_loss = 0.3959016702818067, disc_loss = 0.06599948577206122
Trained batch 267 in epoch 18, gen_loss = 0.3959029504834716, disc_loss = 0.06588958389709579
Trained batch 268 in epoch 18, gen_loss = 0.3960351180631432, disc_loss = 0.06574958875484516
Trained batch 269 in epoch 18, gen_loss = 0.39586909424375605, disc_loss = 0.06590905048436037
Trained batch 270 in epoch 18, gen_loss = 0.3962367433243572, disc_loss = 0.06645426387482793
Trained batch 271 in epoch 18, gen_loss = 0.39631668817909327, disc_loss = 0.06631570198806003
Trained batch 272 in epoch 18, gen_loss = 0.3963529902063447, disc_loss = 0.06615449557415186
Trained batch 273 in epoch 18, gen_loss = 0.3965391720080898, disc_loss = 0.06600541029682885
Trained batch 274 in epoch 18, gen_loss = 0.3964629820260135, disc_loss = 0.0658033305000175
Trained batch 275 in epoch 18, gen_loss = 0.3962736242059348, disc_loss = 0.06563238854911449
Trained batch 276 in epoch 18, gen_loss = 0.3965230779957685, disc_loss = 0.06557827246533404
Trained batch 277 in epoch 18, gen_loss = 0.3968070065803665, disc_loss = 0.06581246847514625
Trained batch 278 in epoch 18, gen_loss = 0.3967821141938582, disc_loss = 0.06573817643961172
Trained batch 279 in epoch 18, gen_loss = 0.3967676659779889, disc_loss = 0.06558361284966979
Trained batch 280 in epoch 18, gen_loss = 0.3966028601249342, disc_loss = 0.06549843584992708
Trained batch 281 in epoch 18, gen_loss = 0.396452377768273, disc_loss = 0.0653349129971883
Trained batch 282 in epoch 18, gen_loss = 0.39645950343499337, disc_loss = 0.06515073471508473
Trained batch 283 in epoch 18, gen_loss = 0.39651044762470355, disc_loss = 0.06495833433967765
Trained batch 284 in epoch 18, gen_loss = 0.39667822227143407, disc_loss = 0.06475799836937272
Trained batch 285 in epoch 18, gen_loss = 0.3967073497238693, disc_loss = 0.06459286677735773
Trained batch 286 in epoch 18, gen_loss = 0.39671621609232566, disc_loss = 0.06444855758965742
Trained batch 287 in epoch 18, gen_loss = 0.3965079765766859, disc_loss = 0.06428706190328942
Trained batch 288 in epoch 18, gen_loss = 0.39654067859930153, disc_loss = 0.06415165997203762
Trained batch 289 in epoch 18, gen_loss = 0.39699437340785715, disc_loss = 0.06410153295266731
Trained batch 290 in epoch 18, gen_loss = 0.39722017273050814, disc_loss = 0.06398257497006778
Trained batch 291 in epoch 18, gen_loss = 0.39752360198595754, disc_loss = 0.06379597982047253
Trained batch 292 in epoch 18, gen_loss = 0.39739642859318963, disc_loss = 0.06360208765530495
Trained batch 293 in epoch 18, gen_loss = 0.3975354870971368, disc_loss = 0.06342058102156789
Trained batch 294 in epoch 18, gen_loss = 0.3972531823788659, disc_loss = 0.0634547786992359
Trained batch 295 in epoch 18, gen_loss = 0.3976220031445091, disc_loss = 0.06333549906392708
Trained batch 296 in epoch 18, gen_loss = 0.3976570679884567, disc_loss = 0.06326283212682163
Trained batch 297 in epoch 18, gen_loss = 0.3975729163261068, disc_loss = 0.06318324293484974
Trained batch 298 in epoch 18, gen_loss = 0.3976394702558932, disc_loss = 0.06309114005821555
Trained batch 299 in epoch 18, gen_loss = 0.39786359121402104, disc_loss = 0.06323151059914381
Trained batch 300 in epoch 18, gen_loss = 0.3976210505265334, disc_loss = 0.06318165208878261
Trained batch 301 in epoch 18, gen_loss = 0.3977931227707705, disc_loss = 0.06301035228592423
Trained batch 302 in epoch 18, gen_loss = 0.397817466617024, disc_loss = 0.06293495483665724
Trained batch 303 in epoch 18, gen_loss = 0.3977050201869325, disc_loss = 0.06294290870765078
Trained batch 304 in epoch 18, gen_loss = 0.3975982475476187, disc_loss = 0.06289805301968925
Trained batch 305 in epoch 18, gen_loss = 0.39726777647445405, disc_loss = 0.06278151272357825
Trained batch 306 in epoch 18, gen_loss = 0.39734126807035763, disc_loss = 0.06264848260099753
Trained batch 307 in epoch 18, gen_loss = 0.3974754657451208, disc_loss = 0.06252219815067221
Trained batch 308 in epoch 18, gen_loss = 0.3973887083406973, disc_loss = 0.06267041808693492
Trained batch 309 in epoch 18, gen_loss = 0.39799678700585517, disc_loss = 0.06273471596951206
Trained batch 310 in epoch 18, gen_loss = 0.3981084393343358, disc_loss = 0.06260295562488041
Trained batch 311 in epoch 18, gen_loss = 0.3984150738479235, disc_loss = 0.06266196289857945
Trained batch 312 in epoch 18, gen_loss = 0.398345202969286, disc_loss = 0.06327822631129774
Trained batch 313 in epoch 18, gen_loss = 0.3986460904406894, disc_loss = 0.06362056122813967
Trained batch 314 in epoch 18, gen_loss = 0.39879813648405527, disc_loss = 0.06350926874382865
Trained batch 315 in epoch 18, gen_loss = 0.3987549337782437, disc_loss = 0.06349075746374747
Trained batch 316 in epoch 18, gen_loss = 0.398605724708515, disc_loss = 0.06356999494740592
Trained batch 317 in epoch 18, gen_loss = 0.3986124115170173, disc_loss = 0.06351550883297229
Trained batch 318 in epoch 18, gen_loss = 0.3985593572118813, disc_loss = 0.06338474180018033
Trained batch 319 in epoch 18, gen_loss = 0.39852735297754405, disc_loss = 0.06326459450501716
Trained batch 320 in epoch 18, gen_loss = 0.3987263698258504, disc_loss = 0.0631801703483493
Trained batch 321 in epoch 18, gen_loss = 0.3988532785858427, disc_loss = 0.06327404630058069
Trained batch 322 in epoch 18, gen_loss = 0.39893210192582923, disc_loss = 0.06350115054480202
Trained batch 323 in epoch 18, gen_loss = 0.3992770374925048, disc_loss = 0.0635392209155669
Trained batch 324 in epoch 18, gen_loss = 0.39937565684318543, disc_loss = 0.0633946709205898
Trained batch 325 in epoch 18, gen_loss = 0.39939358885302867, disc_loss = 0.06327966483955506
Trained batch 326 in epoch 18, gen_loss = 0.3993514906558057, disc_loss = 0.06331925921068052
Trained batch 327 in epoch 18, gen_loss = 0.3991024772205004, disc_loss = 0.06400339516510097
Trained batch 328 in epoch 18, gen_loss = 0.3992918496073923, disc_loss = 0.06388696687194126
Trained batch 329 in epoch 18, gen_loss = 0.3990901537013776, disc_loss = 0.06419437919235364
Trained batch 330 in epoch 18, gen_loss = 0.3988714618805312, disc_loss = 0.06453086326484009
Trained batch 331 in epoch 18, gen_loss = 0.39875963240502826, disc_loss = 0.06450575128820422
Trained batch 332 in epoch 18, gen_loss = 0.399073536689575, disc_loss = 0.06462240649678104
Trained batch 333 in epoch 18, gen_loss = 0.3990565889966702, disc_loss = 0.06468290481911582
Trained batch 334 in epoch 18, gen_loss = 0.3989950598175846, disc_loss = 0.06474694034585089
Trained batch 335 in epoch 18, gen_loss = 0.39890052812794846, disc_loss = 0.06473118679769825
Trained batch 336 in epoch 18, gen_loss = 0.39889181146635855, disc_loss = 0.06491806905147363
Trained batch 337 in epoch 18, gen_loss = 0.3984092254434112, disc_loss = 0.06504000001311434
Trained batch 338 in epoch 18, gen_loss = 0.3984145719920639, disc_loss = 0.06499770400045676
Trained batch 339 in epoch 18, gen_loss = 0.39837536557632336, disc_loss = 0.06499239986296743
Trained batch 340 in epoch 18, gen_loss = 0.3985888032444761, disc_loss = 0.06513731142156416
Trained batch 341 in epoch 18, gen_loss = 0.39820104462710043, disc_loss = 0.06560642132671735
Trained batch 342 in epoch 18, gen_loss = 0.39811659867144883, disc_loss = 0.06559453756784689
Trained batch 343 in epoch 18, gen_loss = 0.39859413286281187, disc_loss = 0.06549013787095413
Trained batch 344 in epoch 18, gen_loss = 0.3984519302845001, disc_loss = 0.06534705031798153
Trained batch 345 in epoch 18, gen_loss = 0.39825276022701595, disc_loss = 0.06546669405335938
Trained batch 346 in epoch 18, gen_loss = 0.39818252232301476, disc_loss = 0.06542587014430495
Trained batch 347 in epoch 18, gen_loss = 0.3981823617185669, disc_loss = 0.0653655847317764
Trained batch 348 in epoch 18, gen_loss = 0.39823967688063155, disc_loss = 0.06529053743998053
Trained batch 349 in epoch 18, gen_loss = 0.3982733997276851, disc_loss = 0.06526209226011166
Trained batch 350 in epoch 18, gen_loss = 0.3984825131390509, disc_loss = 0.06527483670645927
Trained batch 351 in epoch 18, gen_loss = 0.3985441302541982, disc_loss = 0.06520644255083012
Trained batch 352 in epoch 18, gen_loss = 0.39869645516527946, disc_loss = 0.0651162205878698
Trained batch 353 in epoch 18, gen_loss = 0.39869285000246124, disc_loss = 0.06505776654881568
Trained batch 354 in epoch 18, gen_loss = 0.39853903584077327, disc_loss = 0.06512868380646261
Trained batch 355 in epoch 18, gen_loss = 0.3985381946804818, disc_loss = 0.06516804668942487
Trained batch 356 in epoch 18, gen_loss = 0.3984173414420013, disc_loss = 0.06511397582951005
Trained batch 357 in epoch 18, gen_loss = 0.39861523355851625, disc_loss = 0.0653283894309181
Trained batch 358 in epoch 18, gen_loss = 0.39859927530740297, disc_loss = 0.06538460470481794
Trained batch 359 in epoch 18, gen_loss = 0.39860572061604926, disc_loss = 0.06553051312738616
Trained batch 360 in epoch 18, gen_loss = 0.398411477619261, disc_loss = 0.06555757595618304
Trained batch 361 in epoch 18, gen_loss = 0.3985204150828209, disc_loss = 0.06546725076880533
Trained batch 362 in epoch 18, gen_loss = 0.3984478170221502, disc_loss = 0.06543059044032673
Trained batch 363 in epoch 18, gen_loss = 0.3981258330436853, disc_loss = 0.06606526517662333
Trained batch 364 in epoch 18, gen_loss = 0.3982507331730568, disc_loss = 0.06613833284107586
Trained batch 365 in epoch 18, gen_loss = 0.39831906255802824, disc_loss = 0.06599974867765654
Trained batch 366 in epoch 18, gen_loss = 0.39813811731923177, disc_loss = 0.0660785071346249
Trained batch 367 in epoch 18, gen_loss = 0.39826180154214735, disc_loss = 0.06609633369953372
Trained batch 368 in epoch 18, gen_loss = 0.39841930685327626, disc_loss = 0.06606870551838422
Trained batch 369 in epoch 18, gen_loss = 0.3980597654709945, disc_loss = 0.06648388192233806
Trained batch 370 in epoch 18, gen_loss = 0.39823208978233954, disc_loss = 0.06645133469198551
Trained batch 371 in epoch 18, gen_loss = 0.3981917924297753, disc_loss = 0.06644493141537032
Trained batch 372 in epoch 18, gen_loss = 0.39812584153448927, disc_loss = 0.06661875614267213
Trained batch 373 in epoch 18, gen_loss = 0.3983028094398784, disc_loss = 0.06658351234469144
Trained batch 374 in epoch 18, gen_loss = 0.39820567599932355, disc_loss = 0.06652951044216752
Trained batch 375 in epoch 18, gen_loss = 0.3982189417360945, disc_loss = 0.06652833688186799
Trained batch 376 in epoch 18, gen_loss = 0.3980584870282788, disc_loss = 0.06646100670193132
Trained batch 377 in epoch 18, gen_loss = 0.3979833927104082, disc_loss = 0.06637057963950885
Trained batch 378 in epoch 18, gen_loss = 0.3981087056816725, disc_loss = 0.06639983910344796
Trained batch 379 in epoch 18, gen_loss = 0.3981449486393678, disc_loss = 0.06664897735157099
Trained batch 380 in epoch 18, gen_loss = 0.3983479895460324, disc_loss = 0.06679856470539149
Trained batch 381 in epoch 18, gen_loss = 0.3982388175906935, disc_loss = 0.0666532980373217
Trained batch 382 in epoch 18, gen_loss = 0.3980064390533587, disc_loss = 0.06657315388822797
Trained batch 383 in epoch 18, gen_loss = 0.39808371911446255, disc_loss = 0.06643804042808672
Trained batch 384 in epoch 18, gen_loss = 0.3980597249873273, disc_loss = 0.0663877698157418
Trained batch 385 in epoch 18, gen_loss = 0.39814653761028623, disc_loss = 0.06646223150439792
Trained batch 386 in epoch 18, gen_loss = 0.39811008259923575, disc_loss = 0.06634070453154602
Trained batch 387 in epoch 18, gen_loss = 0.398067983846689, disc_loss = 0.06694300058321816
Trained batch 388 in epoch 18, gen_loss = 0.3982433940267195, disc_loss = 0.06706894746835518
Trained batch 389 in epoch 18, gen_loss = 0.3983225481632428, disc_loss = 0.0671626970398789
Trained batch 390 in epoch 18, gen_loss = 0.3981200112863575, disc_loss = 0.0675171564376015
Trained batch 391 in epoch 18, gen_loss = 0.39800162339697076, disc_loss = 0.06747500908594313
Trained batch 392 in epoch 18, gen_loss = 0.3981050512262883, disc_loss = 0.06764349108561873
Trained batch 393 in epoch 18, gen_loss = 0.39830344295138637, disc_loss = 0.0675488739087705
Trained batch 394 in epoch 18, gen_loss = 0.3982604954816118, disc_loss = 0.06747017637060224
Trained batch 395 in epoch 18, gen_loss = 0.39849703186991237, disc_loss = 0.06739299660054685
Trained batch 396 in epoch 18, gen_loss = 0.39832645857364163, disc_loss = 0.06729963566680962
Trained batch 397 in epoch 18, gen_loss = 0.3980763355391708, disc_loss = 0.06737354931646218
Trained batch 398 in epoch 18, gen_loss = 0.3983001392288017, disc_loss = 0.06723322600177617
Trained batch 399 in epoch 18, gen_loss = 0.39841979414224626, disc_loss = 0.06716744405566714
Trained batch 400 in epoch 18, gen_loss = 0.3984199835921166, disc_loss = 0.06704053384347115
Trained batch 401 in epoch 18, gen_loss = 0.3985850466276283, disc_loss = 0.06692021424807978
Trained batch 402 in epoch 18, gen_loss = 0.39867504255351593, disc_loss = 0.06680161020055266
Trained batch 403 in epoch 18, gen_loss = 0.3987401528376164, disc_loss = 0.06669193365505094
Trained batch 404 in epoch 18, gen_loss = 0.39872637582413945, disc_loss = 0.06658678085508722
Trained batch 405 in epoch 18, gen_loss = 0.3986025548039986, disc_loss = 0.06646069299012165
Trained batch 406 in epoch 18, gen_loss = 0.39868386994122873, disc_loss = 0.0665868983343152
Trained batch 407 in epoch 18, gen_loss = 0.3989507344861825, disc_loss = 0.06670864600364082
Trained batch 408 in epoch 18, gen_loss = 0.39904459932031144, disc_loss = 0.0665924845042486
Trained batch 409 in epoch 18, gen_loss = 0.3991102585705315, disc_loss = 0.0665126616737192
Trained batch 410 in epoch 18, gen_loss = 0.3991213692510795, disc_loss = 0.06648026686954854
Trained batch 411 in epoch 18, gen_loss = 0.3994570579198958, disc_loss = 0.06639252269518499
Trained batch 412 in epoch 18, gen_loss = 0.3994471200586231, disc_loss = 0.06638236236634504
Trained batch 413 in epoch 18, gen_loss = 0.3996271257095291, disc_loss = 0.06627688564670582
Trained batch 414 in epoch 18, gen_loss = 0.3994654952761639, disc_loss = 0.06619496004970138
Trained batch 415 in epoch 18, gen_loss = 0.39947380419247425, disc_loss = 0.06606588251284287
Trained batch 416 in epoch 18, gen_loss = 0.3995430554560334, disc_loss = 0.06595938486701472
Trained batch 417 in epoch 18, gen_loss = 0.39975466390260667, disc_loss = 0.06582330176094324
Trained batch 418 in epoch 18, gen_loss = 0.39961047054475135, disc_loss = 0.06569411231178195
Trained batch 419 in epoch 18, gen_loss = 0.3994800082274846, disc_loss = 0.0656312770243468
Trained batch 420 in epoch 18, gen_loss = 0.3994588650886916, disc_loss = 0.06555320036590913
Trained batch 421 in epoch 18, gen_loss = 0.3993720655192696, disc_loss = 0.06548404358923259
Trained batch 422 in epoch 18, gen_loss = 0.39958845674287063, disc_loss = 0.06537334598825438
Trained batch 423 in epoch 18, gen_loss = 0.39943063329413253, disc_loss = 0.06565661534100314
Trained batch 424 in epoch 18, gen_loss = 0.39950497515061323, disc_loss = 0.0657741794417448
Trained batch 425 in epoch 18, gen_loss = 0.39958689931972485, disc_loss = 0.06566650171965326
Trained batch 426 in epoch 18, gen_loss = 0.39962700260606804, disc_loss = 0.06570586698147222
Trained batch 427 in epoch 18, gen_loss = 0.3995560961906041, disc_loss = 0.06566638307902684
Trained batch 428 in epoch 18, gen_loss = 0.39939891798790794, disc_loss = 0.06563465882392301
Trained batch 429 in epoch 18, gen_loss = 0.39933362000210343, disc_loss = 0.06551278563931065
Trained batch 430 in epoch 18, gen_loss = 0.39960074238046966, disc_loss = 0.06604335774622183
Trained batch 431 in epoch 18, gen_loss = 0.3996079785542356, disc_loss = 0.06614964373767618
Trained batch 432 in epoch 18, gen_loss = 0.3996563325990981, disc_loss = 0.06626996497234316
Trained batch 433 in epoch 18, gen_loss = 0.39951276271024605, disc_loss = 0.06626347759159171
Trained batch 434 in epoch 18, gen_loss = 0.39961198027106537, disc_loss = 0.06616966055021033
Trained batch 435 in epoch 18, gen_loss = 0.3998191562404326, disc_loss = 0.0660837007795435
Trained batch 436 in epoch 18, gen_loss = 0.3997207900479402, disc_loss = 0.06608513340213308
Trained batch 437 in epoch 18, gen_loss = 0.399373779422072, disc_loss = 0.0664281778231042
Trained batch 438 in epoch 18, gen_loss = 0.3994975137547643, disc_loss = 0.0664852284953626
Trained batch 439 in epoch 18, gen_loss = 0.3995268546044827, disc_loss = 0.06642663378839973
Trained batch 440 in epoch 18, gen_loss = 0.3997042021648684, disc_loss = 0.06635535361304407
Trained batch 441 in epoch 18, gen_loss = 0.3996620141812579, disc_loss = 0.06627707215283082
Trained batch 442 in epoch 18, gen_loss = 0.39970115883355756, disc_loss = 0.06628311998852052
Trained batch 443 in epoch 18, gen_loss = 0.39962144840408015, disc_loss = 0.06623978498244977
Trained batch 444 in epoch 18, gen_loss = 0.3996804720230317, disc_loss = 0.06618117679935995
Trained batch 445 in epoch 18, gen_loss = 0.3997250649025622, disc_loss = 0.06619187831907897
Trained batch 446 in epoch 18, gen_loss = 0.39963908510186796, disc_loss = 0.0661669098563759
Trained batch 447 in epoch 18, gen_loss = 0.3995400385132858, disc_loss = 0.06623504767256756
Trained batch 448 in epoch 18, gen_loss = 0.39970333160695626, disc_loss = 0.06636506352959437
Trained batch 449 in epoch 18, gen_loss = 0.3995682447486454, disc_loss = 0.06640033027260668
Trained batch 450 in epoch 18, gen_loss = 0.39957803216847504, disc_loss = 0.06635897677544579
Trained batch 451 in epoch 18, gen_loss = 0.39955288943199985, disc_loss = 0.06623876901792643
Trained batch 452 in epoch 18, gen_loss = 0.3995222312461988, disc_loss = 0.06615805435230827
Trained batch 453 in epoch 18, gen_loss = 0.3994325325877656, disc_loss = 0.06614191121306878
Trained batch 454 in epoch 18, gen_loss = 0.3991749909552899, disc_loss = 0.06611998992572937
Trained batch 455 in epoch 18, gen_loss = 0.39906532650715426, disc_loss = 0.06610341868547134
Trained batch 456 in epoch 18, gen_loss = 0.39877247895140616, disc_loss = 0.0662349903521982
Trained batch 457 in epoch 18, gen_loss = 0.39899997413158417, disc_loss = 0.06611709460701518
Trained batch 458 in epoch 18, gen_loss = 0.3989931028782672, disc_loss = 0.06600968108445503
Trained batch 459 in epoch 18, gen_loss = 0.39904018264749774, disc_loss = 0.06588409426925784
Trained batch 460 in epoch 18, gen_loss = 0.39892054909997804, disc_loss = 0.06585133307332622
Testing Epoch 18
Training Epoch 19
Trained batch 0 in epoch 19, gen_loss = 0.3808712363243103, disc_loss = 0.027387196198105812
Trained batch 1 in epoch 19, gen_loss = 0.37541918456554413, disc_loss = 0.044275843538343906
Trained batch 2 in epoch 19, gen_loss = 0.39315419395764667, disc_loss = 0.05000490757326285
Trained batch 3 in epoch 19, gen_loss = 0.3787379860877991, disc_loss = 0.07319839531555772
Trained batch 4 in epoch 19, gen_loss = 0.39206618070602417, disc_loss = 0.09350287206470967
Trained batch 5 in epoch 19, gen_loss = 0.38167572021484375, disc_loss = 0.09573940839618444
Trained batch 6 in epoch 19, gen_loss = 0.38163903781345915, disc_loss = 0.10049217433801719
Trained batch 7 in epoch 19, gen_loss = 0.3744696341454983, disc_loss = 0.09795534634031355
Trained batch 8 in epoch 19, gen_loss = 0.37441374527083504, disc_loss = 0.09729985168410672
Trained batch 9 in epoch 19, gen_loss = 0.3854320079088211, disc_loss = 0.09612846914678812
Trained batch 10 in epoch 19, gen_loss = 0.39044723456556146, disc_loss = 0.08879755928435108
Trained batch 11 in epoch 19, gen_loss = 0.38786181310812634, disc_loss = 0.08524942537769675
Trained batch 12 in epoch 19, gen_loss = 0.3870756992926964, disc_loss = 0.08029592424057998
Trained batch 13 in epoch 19, gen_loss = 0.39060234810624805, disc_loss = 0.08570515617196049
Trained batch 14 in epoch 19, gen_loss = 0.3936064183712006, disc_loss = 0.08495362636943658
Trained batch 15 in epoch 19, gen_loss = 0.3908360805362463, disc_loss = 0.08368703385349363
Trained batch 16 in epoch 19, gen_loss = 0.3932768772630131, disc_loss = 0.08372694856541998
Trained batch 17 in epoch 19, gen_loss = 0.3968787127070957, disc_loss = 0.08059478271752596
Trained batch 18 in epoch 19, gen_loss = 0.3967119659248151, disc_loss = 0.07852110374522836
Trained batch 19 in epoch 19, gen_loss = 0.3950629994273186, disc_loss = 0.0780078842304647
Trained batch 20 in epoch 19, gen_loss = 0.39914790931202115, disc_loss = 0.08271078614606744
Trained batch 21 in epoch 19, gen_loss = 0.4005405875769528, disc_loss = 0.08202665561640804
Trained batch 22 in epoch 19, gen_loss = 0.4004910938117815, disc_loss = 0.07998052377091802
Trained batch 23 in epoch 19, gen_loss = 0.40185446416338283, disc_loss = 0.07923444709740579
Trained batch 24 in epoch 19, gen_loss = 0.40000385880470274, disc_loss = 0.07732547484338284
Trained batch 25 in epoch 19, gen_loss = 0.40016654019172376, disc_loss = 0.0758046624608911
Trained batch 26 in epoch 19, gen_loss = 0.403396295176612, disc_loss = 0.07448051697402089
Trained batch 27 in epoch 19, gen_loss = 0.40266157580273493, disc_loss = 0.07375401850523693
Trained batch 28 in epoch 19, gen_loss = 0.40254569978549565, disc_loss = 0.07286914174669776
Trained batch 29 in epoch 19, gen_loss = 0.4022522896528244, disc_loss = 0.07224754101286332
Trained batch 30 in epoch 19, gen_loss = 0.40512842036062674, disc_loss = 0.07456157242338504
Trained batch 31 in epoch 19, gen_loss = 0.40274936705827713, disc_loss = 0.07435960770817474
Trained batch 32 in epoch 19, gen_loss = 0.4018293862993067, disc_loss = 0.07422195854737904
Trained batch 33 in epoch 19, gen_loss = 0.40318378806114197, disc_loss = 0.07779532040962402
Trained batch 34 in epoch 19, gen_loss = 0.40173984936305457, disc_loss = 0.07645347421722752
Trained batch 35 in epoch 19, gen_loss = 0.39934179104036754, disc_loss = 0.07504011995883451
Trained batch 36 in epoch 19, gen_loss = 0.39804660790675395, disc_loss = 0.07423849257867078
Trained batch 37 in epoch 19, gen_loss = 0.39874018022888585, disc_loss = 0.07413825721136834
Trained batch 38 in epoch 19, gen_loss = 0.3963367786162939, disc_loss = 0.07357939070042892
Trained batch 39 in epoch 19, gen_loss = 0.39717841893434525, disc_loss = 0.07274201014079154
Trained batch 40 in epoch 19, gen_loss = 0.3982404862962118, disc_loss = 0.07608812524959808
Trained batch 41 in epoch 19, gen_loss = 0.39678998433408286, disc_loss = 0.07889092735768784
Trained batch 42 in epoch 19, gen_loss = 0.39626622269319933, disc_loss = 0.07901785423069499
Trained batch 43 in epoch 19, gen_loss = 0.39640547131950205, disc_loss = 0.07907237760214643
Trained batch 44 in epoch 19, gen_loss = 0.398813294702106, disc_loss = 0.081938421436482
Trained batch 45 in epoch 19, gen_loss = 0.3985870817433233, disc_loss = 0.08129051850055871
Trained batch 46 in epoch 19, gen_loss = 0.39716321293343887, disc_loss = 0.08115387474127272
Trained batch 47 in epoch 19, gen_loss = 0.3987454318751891, disc_loss = 0.08466778109626223
Trained batch 48 in epoch 19, gen_loss = 0.3976510982124173, disc_loss = 0.08445021848441386
Trained batch 49 in epoch 19, gen_loss = 0.3976075518131256, disc_loss = 0.0843081671372056
Trained batch 50 in epoch 19, gen_loss = 0.3982288048547857, disc_loss = 0.0871783603421029
Trained batch 51 in epoch 19, gen_loss = 0.3972114576743199, disc_loss = 0.08677231380715966
Trained batch 52 in epoch 19, gen_loss = 0.3966830204117973, disc_loss = 0.08623674234269925
Trained batch 53 in epoch 19, gen_loss = 0.3973381944276668, disc_loss = 0.08569414744636526
Trained batch 54 in epoch 19, gen_loss = 0.397133023630489, disc_loss = 0.08675573383542624
Trained batch 55 in epoch 19, gen_loss = 0.39577785985810415, disc_loss = 0.08578569239138492
Trained batch 56 in epoch 19, gen_loss = 0.39528873405958476, disc_loss = 0.08540389840409421
Trained batch 57 in epoch 19, gen_loss = 0.39581436638174383, disc_loss = 0.0844397721812129
Trained batch 58 in epoch 19, gen_loss = 0.398050181946512, disc_loss = 0.0836014908943641
Trained batch 59 in epoch 19, gen_loss = 0.39881763557593025, disc_loss = 0.08275673765068253
Trained batch 60 in epoch 19, gen_loss = 0.39777458642349867, disc_loss = 0.08200846133051348
Trained batch 61 in epoch 19, gen_loss = 0.3989285696898737, disc_loss = 0.08126098851883604
Trained batch 62 in epoch 19, gen_loss = 0.3992710298015958, disc_loss = 0.080849921271678
Trained batch 63 in epoch 19, gen_loss = 0.39889927953481674, disc_loss = 0.08189491074881516
Trained batch 64 in epoch 19, gen_loss = 0.4003629647768461, disc_loss = 0.08507209405876123
Trained batch 65 in epoch 19, gen_loss = 0.40021232357530884, disc_loss = 0.08438785427786184
Trained batch 66 in epoch 19, gen_loss = 0.3993592849418299, disc_loss = 0.08421960459160271
Trained batch 67 in epoch 19, gen_loss = 0.39864184181479845, disc_loss = 0.08380376457181923
Trained batch 68 in epoch 19, gen_loss = 0.39871578760769055, disc_loss = 0.08298676093851311
Trained batch 69 in epoch 19, gen_loss = 0.39790733797209604, disc_loss = 0.08491421778287206
Trained batch 70 in epoch 19, gen_loss = 0.3990168512707025, disc_loss = 0.08747202756119446
Trained batch 71 in epoch 19, gen_loss = 0.3986010580427117, disc_loss = 0.08763022617333466
Trained batch 72 in epoch 19, gen_loss = 0.3979379955219896, disc_loss = 0.08766280900533885
Trained batch 73 in epoch 19, gen_loss = 0.3972105295271487, disc_loss = 0.08804665636774656
Trained batch 74 in epoch 19, gen_loss = 0.3970156455039978, disc_loss = 0.08735589002569516
Trained batch 75 in epoch 19, gen_loss = 0.3966012757859732, disc_loss = 0.0867353972831839
Trained batch 76 in epoch 19, gen_loss = 0.395815689068336, disc_loss = 0.08637661912611552
Trained batch 77 in epoch 19, gen_loss = 0.39521845334615463, disc_loss = 0.08749321341896668
Trained batch 78 in epoch 19, gen_loss = 0.3960347990446453, disc_loss = 0.0873450077598608
Trained batch 79 in epoch 19, gen_loss = 0.3960546016693115, disc_loss = 0.0868071491830051
Trained batch 80 in epoch 19, gen_loss = 0.3958705759342806, disc_loss = 0.08649278616095767
Trained batch 81 in epoch 19, gen_loss = 0.39593733847141266, disc_loss = 0.08600648383541805
Trained batch 82 in epoch 19, gen_loss = 0.3962445409901171, disc_loss = 0.08530570158218763
Trained batch 83 in epoch 19, gen_loss = 0.3955395090438071, disc_loss = 0.08477555938242447
Trained batch 84 in epoch 19, gen_loss = 0.3959381930968341, disc_loss = 0.08417454401359839
Trained batch 85 in epoch 19, gen_loss = 0.3955387538948724, disc_loss = 0.08355263707249663
Trained batch 86 in epoch 19, gen_loss = 0.3959626805508274, disc_loss = 0.08334525725964842
Trained batch 87 in epoch 19, gen_loss = 0.39610306546092033, disc_loss = 0.08319283115931532
Trained batch 88 in epoch 19, gen_loss = 0.39586530743020304, disc_loss = 0.08402290362655447
Trained batch 89 in epoch 19, gen_loss = 0.3961296021938324, disc_loss = 0.08369088504049513
Trained batch 90 in epoch 19, gen_loss = 0.39600346212858684, disc_loss = 0.0831726888542647
Trained batch 91 in epoch 19, gen_loss = 0.3965142670532931, disc_loss = 0.08241954858860244
Trained batch 92 in epoch 19, gen_loss = 0.3975145787962021, disc_loss = 0.08240467998930202
Trained batch 93 in epoch 19, gen_loss = 0.396383912639415, disc_loss = 0.08299245304883794
Trained batch 94 in epoch 19, gen_loss = 0.39683929619036223, disc_loss = 0.08263449264984382
Trained batch 95 in epoch 19, gen_loss = 0.39643920088807744, disc_loss = 0.08323999249842018
Trained batch 96 in epoch 19, gen_loss = 0.39603361518112656, disc_loss = 0.08247106441671086
Trained batch 97 in epoch 19, gen_loss = 0.3956167363390631, disc_loss = 0.08278545573809926
Trained batch 98 in epoch 19, gen_loss = 0.39540851898867674, disc_loss = 0.08218721812120591
Trained batch 99 in epoch 19, gen_loss = 0.3957877206802368, disc_loss = 0.08161928221583366
Trained batch 100 in epoch 19, gen_loss = 0.3957256031508493, disc_loss = 0.08123519644141197
Trained batch 101 in epoch 19, gen_loss = 0.3961421210391849, disc_loss = 0.08073285707802165
Trained batch 102 in epoch 19, gen_loss = 0.3962113536098628, disc_loss = 0.0806157444648951
Trained batch 103 in epoch 19, gen_loss = 0.3969382680952549, disc_loss = 0.08076308950638542
Trained batch 104 in epoch 19, gen_loss = 0.39646681887762886, disc_loss = 0.08021671580416816
Trained batch 105 in epoch 19, gen_loss = 0.39640302478142503, disc_loss = 0.0795614433931714
Trained batch 106 in epoch 19, gen_loss = 0.3967183839494937, disc_loss = 0.07960263130507458
Trained batch 107 in epoch 19, gen_loss = 0.3962934210344597, disc_loss = 0.07925268786062521
Trained batch 108 in epoch 19, gen_loss = 0.39552539012847693, disc_loss = 0.07888990790164525
Trained batch 109 in epoch 19, gen_loss = 0.39612841308116914, disc_loss = 0.07825181403790007
Trained batch 110 in epoch 19, gen_loss = 0.3962953963258245, disc_loss = 0.0776421414302276
Trained batch 111 in epoch 19, gen_loss = 0.3966517134436539, disc_loss = 0.07703507794732493
Trained batch 112 in epoch 19, gen_loss = 0.3962562078923251, disc_loss = 0.07688167743978247
Trained batch 113 in epoch 19, gen_loss = 0.39535751677396, disc_loss = 0.07712052331158989
Trained batch 114 in epoch 19, gen_loss = 0.39555585021558015, disc_loss = 0.07694847369971483
Trained batch 115 in epoch 19, gen_loss = 0.3953675936008322, disc_loss = 0.07694065757095814
Trained batch 116 in epoch 19, gen_loss = 0.39519404040442574, disc_loss = 0.07688483812360682
Trained batch 117 in epoch 19, gen_loss = 0.39566328161853853, disc_loss = 0.07635932770099933
Trained batch 118 in epoch 19, gen_loss = 0.395672755581992, disc_loss = 0.07597909877937631
Trained batch 119 in epoch 19, gen_loss = 0.39525460128982864, disc_loss = 0.07595195985243966
Trained batch 120 in epoch 19, gen_loss = 0.39523814655532524, disc_loss = 0.07675299532557568
Trained batch 121 in epoch 19, gen_loss = 0.3951386438041437, disc_loss = 0.07686589405581844
Trained batch 122 in epoch 19, gen_loss = 0.3948311398668987, disc_loss = 0.07654778008932263
Trained batch 123 in epoch 19, gen_loss = 0.3951661416119145, disc_loss = 0.07634775413410558
Trained batch 124 in epoch 19, gen_loss = 0.3948167827129364, disc_loss = 0.07640247834473848
Trained batch 125 in epoch 19, gen_loss = 0.394219576366364, disc_loss = 0.07639064687851166
Trained batch 126 in epoch 19, gen_loss = 0.39410010871924755, disc_loss = 0.07615764249174849
Trained batch 127 in epoch 19, gen_loss = 0.39415895263664424, disc_loss = 0.07579326132690767
Trained batch 128 in epoch 19, gen_loss = 0.3935726848683616, disc_loss = 0.07566055586893661
Trained batch 129 in epoch 19, gen_loss = 0.39348327930157, disc_loss = 0.0755381666482068
Trained batch 130 in epoch 19, gen_loss = 0.3938945609194632, disc_loss = 0.07524682761290828
Trained batch 131 in epoch 19, gen_loss = 0.3935877743995551, disc_loss = 0.07493355557689386
Trained batch 132 in epoch 19, gen_loss = 0.39371644755951446, disc_loss = 0.0745347053778911
Trained batch 133 in epoch 19, gen_loss = 0.39488430098811195, disc_loss = 0.07423246713744393
Trained batch 134 in epoch 19, gen_loss = 0.3947341956474163, disc_loss = 0.07405003834239862
Trained batch 135 in epoch 19, gen_loss = 0.3944764827542445, disc_loss = 0.07392637251520201
Trained batch 136 in epoch 19, gen_loss = 0.3950263522837284, disc_loss = 0.07395014390485348
Trained batch 137 in epoch 19, gen_loss = 0.39521486063798267, disc_loss = 0.073667891924202
Trained batch 138 in epoch 19, gen_loss = 0.39549138906190723, disc_loss = 0.07328287373370618
Trained batch 139 in epoch 19, gen_loss = 0.39639575225966317, disc_loss = 0.07287469993877624
Trained batch 140 in epoch 19, gen_loss = 0.39605282490135085, disc_loss = 0.07350679278928549
Trained batch 141 in epoch 19, gen_loss = 0.3955727899578256, disc_loss = 0.07569340079314482
Trained batch 142 in epoch 19, gen_loss = 0.39592590261172583, disc_loss = 0.07575123776010909
Trained batch 143 in epoch 19, gen_loss = 0.3962188849432601, disc_loss = 0.0755001471649545
Trained batch 144 in epoch 19, gen_loss = 0.39585192470714964, disc_loss = 0.07510840263988437
Trained batch 145 in epoch 19, gen_loss = 0.3954913552901516, disc_loss = 0.07490448656887429
Trained batch 146 in epoch 19, gen_loss = 0.3957333307282454, disc_loss = 0.07461016648607392
Trained batch 147 in epoch 19, gen_loss = 0.3960265442728996, disc_loss = 0.07431154029217323
Trained batch 148 in epoch 19, gen_loss = 0.3963129568420001, disc_loss = 0.07420069322415046
Trained batch 149 in epoch 19, gen_loss = 0.3958886722723643, disc_loss = 0.0743015308988591
Trained batch 150 in epoch 19, gen_loss = 0.3955519175687373, disc_loss = 0.07428814873518731
Trained batch 151 in epoch 19, gen_loss = 0.39549789813004044, disc_loss = 0.0755127299589252
Trained batch 152 in epoch 19, gen_loss = 0.3952515339539721, disc_loss = 0.07529821169556551
Trained batch 153 in epoch 19, gen_loss = 0.3950324433964568, disc_loss = 0.07531246117787896
Trained batch 154 in epoch 19, gen_loss = 0.394244441101628, disc_loss = 0.07630614283224267
Trained batch 155 in epoch 19, gen_loss = 0.3943941190074652, disc_loss = 0.07646155845111188
Trained batch 156 in epoch 19, gen_loss = 0.3951221767124856, disc_loss = 0.0761492776085332
Trained batch 157 in epoch 19, gen_loss = 0.3952844797433177, disc_loss = 0.0759950644761041
Trained batch 158 in epoch 19, gen_loss = 0.3949199856827094, disc_loss = 0.07579630623284564
Trained batch 159 in epoch 19, gen_loss = 0.39515790082514285, disc_loss = 0.07538247103220783
Trained batch 160 in epoch 19, gen_loss = 0.3958504533175356, disc_loss = 0.07515786298382912
Trained batch 161 in epoch 19, gen_loss = 0.3955516988112603, disc_loss = 0.07483712286561911
Trained batch 162 in epoch 19, gen_loss = 0.39518177399606064, disc_loss = 0.0752135748957838
Trained batch 163 in epoch 19, gen_loss = 0.39513736690689877, disc_loss = 0.07510717305718217
Trained batch 164 in epoch 19, gen_loss = 0.39518800739086035, disc_loss = 0.07481394602606693
Trained batch 165 in epoch 19, gen_loss = 0.39565483669200574, disc_loss = 0.07445369759035936
Trained batch 166 in epoch 19, gen_loss = 0.3955967708262141, disc_loss = 0.07410585322043674
Trained batch 167 in epoch 19, gen_loss = 0.3953857615235306, disc_loss = 0.0738459734767232
Trained batch 168 in epoch 19, gen_loss = 0.3952729509779688, disc_loss = 0.0739505981100646
Trained batch 169 in epoch 19, gen_loss = 0.3959217392346438, disc_loss = 0.07510710610076785
Trained batch 170 in epoch 19, gen_loss = 0.3961638367315482, disc_loss = 0.07493340495799543
Trained batch 171 in epoch 19, gen_loss = 0.3956395512403444, disc_loss = 0.07487638205354817
Trained batch 172 in epoch 19, gen_loss = 0.39614661373844035, disc_loss = 0.07469301065160877
Trained batch 173 in epoch 19, gen_loss = 0.39679312260671595, disc_loss = 0.07435853621419306
Trained batch 174 in epoch 19, gen_loss = 0.39654857311929975, disc_loss = 0.07422657745757273
Trained batch 175 in epoch 19, gen_loss = 0.39635400897399947, disc_loss = 0.07392951500580901
Trained batch 176 in epoch 19, gen_loss = 0.39644350422977725, disc_loss = 0.07364924068399574
Trained batch 177 in epoch 19, gen_loss = 0.39610387535577407, disc_loss = 0.07362095364421774
Trained batch 178 in epoch 19, gen_loss = 0.39604202145970735, disc_loss = 0.07333189189205123
Trained batch 179 in epoch 19, gen_loss = 0.3960408533612887, disc_loss = 0.07307785526435408
Trained batch 180 in epoch 19, gen_loss = 0.39637464334292966, disc_loss = 0.072742508389879
Trained batch 181 in epoch 19, gen_loss = 0.39612577577213665, disc_loss = 0.07346805877430918
Trained batch 182 in epoch 19, gen_loss = 0.3969273557428454, disc_loss = 0.07396896684776401
Trained batch 183 in epoch 19, gen_loss = 0.39686353213113285, disc_loss = 0.07369591421751387
Trained batch 184 in epoch 19, gen_loss = 0.3967394914176013, disc_loss = 0.0742430302389973
Trained batch 185 in epoch 19, gen_loss = 0.39665306655950444, disc_loss = 0.07394669543931721
Trained batch 186 in epoch 19, gen_loss = 0.3964141016019219, disc_loss = 0.07370921828470288
Trained batch 187 in epoch 19, gen_loss = 0.3966413496973667, disc_loss = 0.07345140248319094
Trained batch 188 in epoch 19, gen_loss = 0.3967827694125907, disc_loss = 0.07323688535246427
Trained batch 189 in epoch 19, gen_loss = 0.39624219003476596, disc_loss = 0.0732137813624975
Trained batch 190 in epoch 19, gen_loss = 0.3958791626997643, disc_loss = 0.0732486215103125
Trained batch 191 in epoch 19, gen_loss = 0.3958058284285168, disc_loss = 0.0741012746633108
Trained batch 192 in epoch 19, gen_loss = 0.3958064317703247, disc_loss = 0.07393557298928499
Trained batch 193 in epoch 19, gen_loss = 0.3956304095762292, disc_loss = 0.07375728316393863
Trained batch 194 in epoch 19, gen_loss = 0.39529961760227494, disc_loss = 0.07367190707665988
Trained batch 195 in epoch 19, gen_loss = 0.39569881071849744, disc_loss = 0.07337911398035987
Trained batch 196 in epoch 19, gen_loss = 0.39603756239571547, disc_loss = 0.0731130328908714
Trained batch 197 in epoch 19, gen_loss = 0.39632256509679736, disc_loss = 0.07280452208442971
Trained batch 198 in epoch 19, gen_loss = 0.3960708593902875, disc_loss = 0.07277040140020039
Trained batch 199 in epoch 19, gen_loss = 0.39601278826594355, disc_loss = 0.07316224792506545
Trained batch 200 in epoch 19, gen_loss = 0.39581710278098264, disc_loss = 0.07325618882288239
Trained batch 201 in epoch 19, gen_loss = 0.3958993813779094, disc_loss = 0.07298948297203325
Trained batch 202 in epoch 19, gen_loss = 0.39574545093357855, disc_loss = 0.07272099518662163
Trained batch 203 in epoch 19, gen_loss = 0.3956783015061827, disc_loss = 0.07268658264394046
Trained batch 204 in epoch 19, gen_loss = 0.39517299096758773, disc_loss = 0.07333134723963534
Trained batch 205 in epoch 19, gen_loss = 0.3953840268179051, disc_loss = 0.07349322286425429
Trained batch 206 in epoch 19, gen_loss = 0.3955191144908684, disc_loss = 0.07338254017404457
Trained batch 207 in epoch 19, gen_loss = 0.3955281338152977, disc_loss = 0.07323160843225196
Trained batch 208 in epoch 19, gen_loss = 0.39568433065733843, disc_loss = 0.07316497000798797
Trained batch 209 in epoch 19, gen_loss = 0.3956241154954547, disc_loss = 0.07292456967933547
Trained batch 210 in epoch 19, gen_loss = 0.3956622799143407, disc_loss = 0.07288068851182387
Trained batch 211 in epoch 19, gen_loss = 0.3961751746400347, disc_loss = 0.07290395666001681
Trained batch 212 in epoch 19, gen_loss = 0.3959655652583485, disc_loss = 0.07276339602040154
Trained batch 213 in epoch 19, gen_loss = 0.3958172761948309, disc_loss = 0.07281822332172333
Trained batch 214 in epoch 19, gen_loss = 0.3960070443707843, disc_loss = 0.07281828332519115
Trained batch 215 in epoch 19, gen_loss = 0.3957933399964262, disc_loss = 0.07280965856949075
Trained batch 216 in epoch 19, gen_loss = 0.3959247973932099, disc_loss = 0.07255989419133295
Trained batch 217 in epoch 19, gen_loss = 0.3963328672384997, disc_loss = 0.07329048998568446
Trained batch 218 in epoch 19, gen_loss = 0.3962021961331912, disc_loss = 0.07353418564942737
Trained batch 219 in epoch 19, gen_loss = 0.3963204791600054, disc_loss = 0.07336014376699247
Trained batch 220 in epoch 19, gen_loss = 0.3961807016064139, disc_loss = 0.07327148066707191
Trained batch 221 in epoch 19, gen_loss = 0.39596642607504184, disc_loss = 0.07343029611332862
Trained batch 222 in epoch 19, gen_loss = 0.39576655813396777, disc_loss = 0.07354403391998311
Trained batch 223 in epoch 19, gen_loss = 0.3959852649963328, disc_loss = 0.07347866198896165
Trained batch 224 in epoch 19, gen_loss = 0.3957876948515574, disc_loss = 0.07331739918639263
Trained batch 225 in epoch 19, gen_loss = 0.39604960803964495, disc_loss = 0.07321875368912531
Trained batch 226 in epoch 19, gen_loss = 0.39617477639656234, disc_loss = 0.07326317704508352
Trained batch 227 in epoch 19, gen_loss = 0.39616139664461736, disc_loss = 0.07333259625572777
Trained batch 228 in epoch 19, gen_loss = 0.3960687479077468, disc_loss = 0.07332556227457966
Trained batch 229 in epoch 19, gen_loss = 0.3962708434332972, disc_loss = 0.07323375747174672
Trained batch 230 in epoch 19, gen_loss = 0.39675256519606616, disc_loss = 0.07318287150474725
Trained batch 231 in epoch 19, gen_loss = 0.39704640980424555, disc_loss = 0.07293427720714103
Trained batch 232 in epoch 19, gen_loss = 0.3970927702255003, disc_loss = 0.07266905621621486
Trained batch 233 in epoch 19, gen_loss = 0.3971953576701319, disc_loss = 0.07271468727730024
Trained batch 234 in epoch 19, gen_loss = 0.3973591134903279, disc_loss = 0.07314970473501277
Trained batch 235 in epoch 19, gen_loss = 0.39717869056483446, disc_loss = 0.07331546221591406
Trained batch 236 in epoch 19, gen_loss = 0.3973833269710782, disc_loss = 0.07325868380063445
Trained batch 237 in epoch 19, gen_loss = 0.397812801248887, disc_loss = 0.07307506996762603
Trained batch 238 in epoch 19, gen_loss = 0.39803154124375667, disc_loss = 0.07380944545766549
Trained batch 239 in epoch 19, gen_loss = 0.39777064820130664, disc_loss = 0.07405176261284699
Trained batch 240 in epoch 19, gen_loss = 0.39782871819136056, disc_loss = 0.07391530243656695
Trained batch 241 in epoch 19, gen_loss = 0.3982164748936645, disc_loss = 0.07425279754467985
Trained batch 242 in epoch 19, gen_loss = 0.3981079217583064, disc_loss = 0.07459188432819804
Trained batch 243 in epoch 19, gen_loss = 0.3978491291159489, disc_loss = 0.07442360483567978
Trained batch 244 in epoch 19, gen_loss = 0.3977350520844362, disc_loss = 0.07455435592148985
Trained batch 245 in epoch 19, gen_loss = 0.39756965976420455, disc_loss = 0.07504103559152625
Trained batch 246 in epoch 19, gen_loss = 0.3975869861208958, disc_loss = 0.0749497699366528
Trained batch 247 in epoch 19, gen_loss = 0.39748392590591985, disc_loss = 0.07490597056194899
Trained batch 248 in epoch 19, gen_loss = 0.3978693670776474, disc_loss = 0.07476512630690772
Trained batch 249 in epoch 19, gen_loss = 0.39786056518554686, disc_loss = 0.07545256821066142
Trained batch 250 in epoch 19, gen_loss = 0.3978462790350515, disc_loss = 0.0753144413544481
Trained batch 251 in epoch 19, gen_loss = 0.39790325458087616, disc_loss = 0.07522769159238253
Trained batch 252 in epoch 19, gen_loss = 0.3977626558584658, disc_loss = 0.07524075982687266
Trained batch 253 in epoch 19, gen_loss = 0.3977056349825671, disc_loss = 0.07508302493915549
Trained batch 254 in epoch 19, gen_loss = 0.39757303139742683, disc_loss = 0.07483944361846821
Trained batch 255 in epoch 19, gen_loss = 0.39777163811959326, disc_loss = 0.07459037364606047
Trained batch 256 in epoch 19, gen_loss = 0.3979525436223249, disc_loss = 0.07464503190309853
Trained batch 257 in epoch 19, gen_loss = 0.39762010246284246, disc_loss = 0.07486195802370939
Trained batch 258 in epoch 19, gen_loss = 0.39756217334261273, disc_loss = 0.07464621175066155
Trained batch 259 in epoch 19, gen_loss = 0.39739911533319033, disc_loss = 0.0745810740484068
Trained batch 260 in epoch 19, gen_loss = 0.39749688663701904, disc_loss = 0.07434405583774108
Trained batch 261 in epoch 19, gen_loss = 0.39722082985721474, disc_loss = 0.07412558865470399
Trained batch 262 in epoch 19, gen_loss = 0.39706307944236147, disc_loss = 0.07450580622774226
Trained batch 263 in epoch 19, gen_loss = 0.397077130210219, disc_loss = 0.07459974681577561
Trained batch 264 in epoch 19, gen_loss = 0.3973262862214502, disc_loss = 0.07436024545920344
Trained batch 265 in epoch 19, gen_loss = 0.3972620640258144, disc_loss = 0.07434808095230867
Trained batch 266 in epoch 19, gen_loss = 0.3974913683500183, disc_loss = 0.07422813966395926
Trained batch 267 in epoch 19, gen_loss = 0.39750740732719647, disc_loss = 0.07403860700580833
Trained batch 268 in epoch 19, gen_loss = 0.3971502497293692, disc_loss = 0.07444987568630383
Trained batch 269 in epoch 19, gen_loss = 0.39757661996064364, disc_loss = 0.07502300842078748
Trained batch 270 in epoch 19, gen_loss = 0.3974700062037394, disc_loss = 0.07488666483754382
Trained batch 271 in epoch 19, gen_loss = 0.39723206037545905, disc_loss = 0.07507579289513695
Trained batch 272 in epoch 19, gen_loss = 0.3970361154376369, disc_loss = 0.07499783875714074
Trained batch 273 in epoch 19, gen_loss = 0.39755141419650863, disc_loss = 0.07476500662070883
Trained batch 274 in epoch 19, gen_loss = 0.39748138416897166, disc_loss = 0.0745559858429161
Trained batch 275 in epoch 19, gen_loss = 0.3976324930571128, disc_loss = 0.07461819484276508
Trained batch 276 in epoch 19, gen_loss = 0.3977401188779824, disc_loss = 0.07442774102831468
Trained batch 277 in epoch 19, gen_loss = 0.3976503530209013, disc_loss = 0.07433242517985779
Trained batch 278 in epoch 19, gen_loss = 0.3973657066890416, disc_loss = 0.0743010274391608
Trained batch 279 in epoch 19, gen_loss = 0.39739267538700784, disc_loss = 0.07419572548075978
Trained batch 280 in epoch 19, gen_loss = 0.3971845661405991, disc_loss = 0.07395765073332286
Trained batch 281 in epoch 19, gen_loss = 0.3976362257773149, disc_loss = 0.0737833750652189
Trained batch 282 in epoch 19, gen_loss = 0.39767714987374025, disc_loss = 0.07357054297868228
Trained batch 283 in epoch 19, gen_loss = 0.39760333824325617, disc_loss = 0.073455537780857
Trained batch 284 in epoch 19, gen_loss = 0.39784440440044067, disc_loss = 0.07332889116777663
Trained batch 285 in epoch 19, gen_loss = 0.39812584679860336, disc_loss = 0.07310343510634103
Trained batch 286 in epoch 19, gen_loss = 0.3983257104503153, disc_loss = 0.07294894528059283
Trained batch 287 in epoch 19, gen_loss = 0.39833099653737414, disc_loss = 0.07275259320481887
Trained batch 288 in epoch 19, gen_loss = 0.39812240344842825, disc_loss = 0.07256390007734814
Trained batch 289 in epoch 19, gen_loss = 0.3980308040462691, disc_loss = 0.07235124089658775
Trained batch 290 in epoch 19, gen_loss = 0.398122692128637, disc_loss = 0.07231760413235508
Trained batch 291 in epoch 19, gen_loss = 0.3982621803879738, disc_loss = 0.07211289185175851
Trained batch 292 in epoch 19, gen_loss = 0.39846980968433027, disc_loss = 0.07199436312051866
Trained batch 293 in epoch 19, gen_loss = 0.39844826401090944, disc_loss = 0.07216486276830641
Trained batch 294 in epoch 19, gen_loss = 0.39866397360623895, disc_loss = 0.07202749152873027
Trained batch 295 in epoch 19, gen_loss = 0.39872542124342275, disc_loss = 0.07206082660264361
Trained batch 296 in epoch 19, gen_loss = 0.39824173165491533, disc_loss = 0.0720866149078164
Trained batch 297 in epoch 19, gen_loss = 0.39849848455230663, disc_loss = 0.0718705656144443
Trained batch 298 in epoch 19, gen_loss = 0.3986368185301688, disc_loss = 0.07170752217264278
Trained batch 299 in epoch 19, gen_loss = 0.39863552192846935, disc_loss = 0.07153258478268981
Trained batch 300 in epoch 19, gen_loss = 0.3986659105433974, disc_loss = 0.07171359564799605
Trained batch 301 in epoch 19, gen_loss = 0.3987316334287062, disc_loss = 0.07167823233376473
Trained batch 302 in epoch 19, gen_loss = 0.3988258503254491, disc_loss = 0.07158905477339875
Trained batch 303 in epoch 19, gen_loss = 0.3987978841913374, disc_loss = 0.07147152403884224
Trained batch 304 in epoch 19, gen_loss = 0.39889062506253603, disc_loss = 0.0713469716430199
Trained batch 305 in epoch 19, gen_loss = 0.39862099182761573, disc_loss = 0.07132808090449354
Trained batch 306 in epoch 19, gen_loss = 0.39846501608624907, disc_loss = 0.07127053112835177
Trained batch 307 in epoch 19, gen_loss = 0.39880765751971825, disc_loss = 0.07126442741530088
Trained batch 308 in epoch 19, gen_loss = 0.3989944458972289, disc_loss = 0.07109280341096873
Trained batch 309 in epoch 19, gen_loss = 0.3990462868444381, disc_loss = 0.07089794571962088
Trained batch 310 in epoch 19, gen_loss = 0.399098862980723, disc_loss = 0.07071774088181675
Trained batch 311 in epoch 19, gen_loss = 0.39912716920177144, disc_loss = 0.07056463297265463
Trained batch 312 in epoch 19, gen_loss = 0.3991736262179792, disc_loss = 0.07039201470871513
Trained batch 313 in epoch 19, gen_loss = 0.3991956893046191, disc_loss = 0.0703452241897678
Trained batch 314 in epoch 19, gen_loss = 0.39921237911496843, disc_loss = 0.07042079391105781
Trained batch 315 in epoch 19, gen_loss = 0.39916618243802954, disc_loss = 0.07023389872658668
Trained batch 316 in epoch 19, gen_loss = 0.3993887162358979, disc_loss = 0.0700497250909967
Trained batch 317 in epoch 19, gen_loss = 0.3994329221218637, disc_loss = 0.07007376884209847
Trained batch 318 in epoch 19, gen_loss = 0.3992120472241345, disc_loss = 0.0701701779992883
Trained batch 319 in epoch 19, gen_loss = 0.3992605797015131, disc_loss = 0.07000573920086026
Trained batch 320 in epoch 19, gen_loss = 0.39932840013429755, disc_loss = 0.06989379658877293
Trained batch 321 in epoch 19, gen_loss = 0.39926416107586454, disc_loss = 0.06971047134051875
Trained batch 322 in epoch 19, gen_loss = 0.398935666578842, disc_loss = 0.06972339244461373
Trained batch 323 in epoch 19, gen_loss = 0.3992277599043316, disc_loss = 0.0701555509240953
Trained batch 324 in epoch 19, gen_loss = 0.3991267721469586, disc_loss = 0.07008101037201973
Trained batch 325 in epoch 19, gen_loss = 0.3993222931045696, disc_loss = 0.06992461160111006
Trained batch 326 in epoch 19, gen_loss = 0.39920095547988144, disc_loss = 0.06979201963906168
Trained batch 327 in epoch 19, gen_loss = 0.3991702520629255, disc_loss = 0.06962017150788863
Trained batch 328 in epoch 19, gen_loss = 0.39954215632383583, disc_loss = 0.06944579577588654
Trained batch 329 in epoch 19, gen_loss = 0.39954312588229324, disc_loss = 0.06932450346366474
Trained batch 330 in epoch 19, gen_loss = 0.39945132980894105, disc_loss = 0.06928821478399175
Trained batch 331 in epoch 19, gen_loss = 0.39959040912519017, disc_loss = 0.06929474874646459
Trained batch 332 in epoch 19, gen_loss = 0.3995420694709182, disc_loss = 0.0692101137142058
Trained batch 333 in epoch 19, gen_loss = 0.3992822792180284, disc_loss = 0.06904644021641708
Trained batch 334 in epoch 19, gen_loss = 0.3991691070706097, disc_loss = 0.0700255767400585
Trained batch 335 in epoch 19, gen_loss = 0.3994648638403132, disc_loss = 0.07007929119503215
Trained batch 336 in epoch 19, gen_loss = 0.39975590318529824, disc_loss = 0.06997610296976672
Trained batch 337 in epoch 19, gen_loss = 0.39977143122952363, disc_loss = 0.06981390005131886
Trained batch 338 in epoch 19, gen_loss = 0.39965551150935236, disc_loss = 0.06985513409077682
Trained batch 339 in epoch 19, gen_loss = 0.399764297201353, disc_loss = 0.06971153879592962
Trained batch 340 in epoch 19, gen_loss = 0.39987363886973026, disc_loss = 0.06952667660202798
Trained batch 341 in epoch 19, gen_loss = 0.3997645756306007, disc_loss = 0.06948830376853023
Trained batch 342 in epoch 19, gen_loss = 0.3998212901218292, disc_loss = 0.06946680327719919
Trained batch 343 in epoch 19, gen_loss = 0.3997332535164301, disc_loss = 0.06956104024551636
Trained batch 344 in epoch 19, gen_loss = 0.399783127117848, disc_loss = 0.06953262226737064
Trained batch 345 in epoch 19, gen_loss = 0.3999057531012276, disc_loss = 0.06940329177143602
Trained batch 346 in epoch 19, gen_loss = 0.3998342348794085, disc_loss = 0.06934437807380982
Trained batch 347 in epoch 19, gen_loss = 0.39983591129039897, disc_loss = 0.06934513966285291
Trained batch 348 in epoch 19, gen_loss = 0.3997304752084792, disc_loss = 0.06926946868228707
Trained batch 349 in epoch 19, gen_loss = 0.400022634778704, disc_loss = 0.06929967936660562
Trained batch 350 in epoch 19, gen_loss = 0.4000850319862366, disc_loss = 0.06919046650584947
Trained batch 351 in epoch 19, gen_loss = 0.39990244196219876, disc_loss = 0.06909038552972065
Trained batch 352 in epoch 19, gen_loss = 0.3999173314476824, disc_loss = 0.06899471763553093
Trained batch 353 in epoch 19, gen_loss = 0.3998795347025165, disc_loss = 0.0689736587011208
Trained batch 354 in epoch 19, gen_loss = 0.39973100197147315, disc_loss = 0.06890539354841474
Trained batch 355 in epoch 19, gen_loss = 0.3996575227781628, disc_loss = 0.068812546895796
Trained batch 356 in epoch 19, gen_loss = 0.3996318483553013, disc_loss = 0.0687002595514059
Trained batch 357 in epoch 19, gen_loss = 0.3995907671291735, disc_loss = 0.06860940615703773
Trained batch 358 in epoch 19, gen_loss = 0.3994679153795694, disc_loss = 0.06852980748254775
Trained batch 359 in epoch 19, gen_loss = 0.3992356808649169, disc_loss = 0.06838763826526702
Trained batch 360 in epoch 19, gen_loss = 0.3993940295605118, disc_loss = 0.06821906547787034
Trained batch 361 in epoch 19, gen_loss = 0.3996329338840358, disc_loss = 0.06811311574735118
Trained batch 362 in epoch 19, gen_loss = 0.3991997844177829, disc_loss = 0.0681718970589935
Trained batch 363 in epoch 19, gen_loss = 0.39941075587501895, disc_loss = 0.06814158751097109
Trained batch 364 in epoch 19, gen_loss = 0.39925138154258466, disc_loss = 0.06799634135238929
Trained batch 365 in epoch 19, gen_loss = 0.39906808371589486, disc_loss = 0.06789531091564015
Trained batch 366 in epoch 19, gen_loss = 0.39915313346346976, disc_loss = 0.06776797724253313
Trained batch 367 in epoch 19, gen_loss = 0.399324056206514, disc_loss = 0.06772056834913952
Trained batch 368 in epoch 19, gen_loss = 0.3994164662713281, disc_loss = 0.06760623957709407
Trained batch 369 in epoch 19, gen_loss = 0.3995543907220299, disc_loss = 0.06757305500575819
Trained batch 370 in epoch 19, gen_loss = 0.39938719032427694, disc_loss = 0.06746383244799314
Trained batch 371 in epoch 19, gen_loss = 0.39935401222237976, disc_loss = 0.06740169908591015
Trained batch 372 in epoch 19, gen_loss = 0.3994766265633279, disc_loss = 0.0673492135724737
Trained batch 373 in epoch 19, gen_loss = 0.39958171048425734, disc_loss = 0.06722010200454749
Trained batch 374 in epoch 19, gen_loss = 0.3996234120130539, disc_loss = 0.06708649067083995
Trained batch 375 in epoch 19, gen_loss = 0.39978206264687344, disc_loss = 0.06694471416004161
Trained batch 376 in epoch 19, gen_loss = 0.3999437262509166, disc_loss = 0.0667884594239591
Trained batch 377 in epoch 19, gen_loss = 0.39998859762357025, disc_loss = 0.06664682934849114
Trained batch 378 in epoch 19, gen_loss = 0.4000351463191427, disc_loss = 0.06659631352714389
Trained batch 379 in epoch 19, gen_loss = 0.4000425991651259, disc_loss = 0.06676794529990539
Trained batch 380 in epoch 19, gen_loss = 0.3999913182706032, disc_loss = 0.06699490950264408
Trained batch 381 in epoch 19, gen_loss = 0.39975543924807255, disc_loss = 0.06737306901541446
Trained batch 382 in epoch 19, gen_loss = 0.39977432040414984, disc_loss = 0.06740196607763789
Trained batch 383 in epoch 19, gen_loss = 0.40000281812778365, disc_loss = 0.06732250796873511
Trained batch 384 in epoch 19, gen_loss = 0.39987939631010033, disc_loss = 0.06736837838619174
Trained batch 385 in epoch 19, gen_loss = 0.39982262635941335, disc_loss = 0.06722415352742057
Trained batch 386 in epoch 19, gen_loss = 0.3997168158606965, disc_loss = 0.06721815780931434
Trained batch 387 in epoch 19, gen_loss = 0.3995983156269973, disc_loss = 0.067271654966969
Trained batch 388 in epoch 19, gen_loss = 0.3996269383053547, disc_loss = 0.06715300784309833
Trained batch 389 in epoch 19, gen_loss = 0.39974710180973394, disc_loss = 0.06704608168309698
Trained batch 390 in epoch 19, gen_loss = 0.3996185441989728, disc_loss = 0.06696845079198137
Trained batch 391 in epoch 19, gen_loss = 0.3995280867556528, disc_loss = 0.06683321669697762
Trained batch 392 in epoch 19, gen_loss = 0.39963040116027415, disc_loss = 0.06669859286236551
Trained batch 393 in epoch 19, gen_loss = 0.39988061207048786, disc_loss = 0.06655248880461993
Trained batch 394 in epoch 19, gen_loss = 0.39995681903784785, disc_loss = 0.06647716485246827
Trained batch 395 in epoch 19, gen_loss = 0.39988360467432726, disc_loss = 0.06642598831894422
Trained batch 396 in epoch 19, gen_loss = 0.39986684103906905, disc_loss = 0.0663845781377641
Trained batch 397 in epoch 19, gen_loss = 0.3998293900984016, disc_loss = 0.06632163424288208
Trained batch 398 in epoch 19, gen_loss = 0.3999706545942708, disc_loss = 0.06628733081626415
Trained batch 399 in epoch 19, gen_loss = 0.39989942077547314, disc_loss = 0.06617969687096775
Trained batch 400 in epoch 19, gen_loss = 0.4001657983980274, disc_loss = 0.06605504683574238
Trained batch 401 in epoch 19, gen_loss = 0.4001149155236595, disc_loss = 0.06607546683271133
Trained batch 402 in epoch 19, gen_loss = 0.4002504951826692, disc_loss = 0.06615112317037346
Trained batch 403 in epoch 19, gen_loss = 0.4002729412721525, disc_loss = 0.06602777946408432
Trained batch 404 in epoch 19, gen_loss = 0.400054790613092, disc_loss = 0.06604607417995548
Trained batch 405 in epoch 19, gen_loss = 0.39996056937672236, disc_loss = 0.06598200014989658
Trained batch 406 in epoch 19, gen_loss = 0.4001572010924248, disc_loss = 0.06588718793480783
Trained batch 407 in epoch 19, gen_loss = 0.40013287840958905, disc_loss = 0.06577382766751244
Trained batch 408 in epoch 19, gen_loss = 0.4000603304151218, disc_loss = 0.0656543427390618
Trained batch 409 in epoch 19, gen_loss = 0.39996362106829153, disc_loss = 0.06559961363218907
Trained batch 410 in epoch 19, gen_loss = 0.40010613402455975, disc_loss = 0.06595127891359392
Trained batch 411 in epoch 19, gen_loss = 0.3999472308578422, disc_loss = 0.06595401546818394
Trained batch 412 in epoch 19, gen_loss = 0.3999904048861372, disc_loss = 0.06582540934837759
Trained batch 413 in epoch 19, gen_loss = 0.400024449803691, disc_loss = 0.06573183184876534
Trained batch 414 in epoch 19, gen_loss = 0.39997440493968595, disc_loss = 0.06561279311686395
Trained batch 415 in epoch 19, gen_loss = 0.3998234811812066, disc_loss = 0.0655124253557565
Trained batch 416 in epoch 19, gen_loss = 0.399756812398954, disc_loss = 0.06541730610461687
Trained batch 417 in epoch 19, gen_loss = 0.39958672877846724, disc_loss = 0.06534342913839378
Trained batch 418 in epoch 19, gen_loss = 0.3998359740847335, disc_loss = 0.06522605364124218
Trained batch 419 in epoch 19, gen_loss = 0.39973511905187653, disc_loss = 0.065134089315931
Trained batch 420 in epoch 19, gen_loss = 0.39996145609014105, disc_loss = 0.0650043451534739
Trained batch 421 in epoch 19, gen_loss = 0.3998659628474317, disc_loss = 0.06514143476801179
Trained batch 422 in epoch 19, gen_loss = 0.3996762153175142, disc_loss = 0.0654934626292816
Trained batch 423 in epoch 19, gen_loss = 0.399735721320195, disc_loss = 0.0654066211658196
Trained batch 424 in epoch 19, gen_loss = 0.399505980961463, disc_loss = 0.06539095264585579
Trained batch 425 in epoch 19, gen_loss = 0.399427362415992, disc_loss = 0.06537568642202538
Trained batch 426 in epoch 19, gen_loss = 0.39929681168367487, disc_loss = 0.06533812487659325
Trained batch 427 in epoch 19, gen_loss = 0.3992359108665836, disc_loss = 0.06538119701947147
Trained batch 428 in epoch 19, gen_loss = 0.39931420092677183, disc_loss = 0.06569340111718172
Trained batch 429 in epoch 19, gen_loss = 0.39937198075444197, disc_loss = 0.06557940719865782
Trained batch 430 in epoch 19, gen_loss = 0.3993723396289653, disc_loss = 0.06553384033734035
Trained batch 431 in epoch 19, gen_loss = 0.399524976361405, disc_loss = 0.06541667270249929
Trained batch 432 in epoch 19, gen_loss = 0.3995125084151847, disc_loss = 0.06530776426763925
Trained batch 433 in epoch 19, gen_loss = 0.3996005393736373, disc_loss = 0.06520692580100577
Trained batch 434 in epoch 19, gen_loss = 0.39955083477771147, disc_loss = 0.06514089324179737
Trained batch 435 in epoch 19, gen_loss = 0.3995008865422612, disc_loss = 0.06521206913908961
Trained batch 436 in epoch 19, gen_loss = 0.399298966033235, disc_loss = 0.065667490502585
Trained batch 437 in epoch 19, gen_loss = 0.3995242979904832, disc_loss = 0.06581639138701027
Trained batch 438 in epoch 19, gen_loss = 0.39948845028469937, disc_loss = 0.06582279502496904
Trained batch 439 in epoch 19, gen_loss = 0.3995275969871066, disc_loss = 0.06571194434707815
Trained batch 440 in epoch 19, gen_loss = 0.3995443205782075, disc_loss = 0.0655874186586124
Trained batch 441 in epoch 19, gen_loss = 0.399560099037794, disc_loss = 0.06546030059136551
Trained batch 442 in epoch 19, gen_loss = 0.3993720880816806, disc_loss = 0.06548852278823643
Trained batch 443 in epoch 19, gen_loss = 0.39947129520881286, disc_loss = 0.06564279882707172
Trained batch 444 in epoch 19, gen_loss = 0.39956799360473505, disc_loss = 0.06558457313712393
Trained batch 445 in epoch 19, gen_loss = 0.39943655901024694, disc_loss = 0.0655179954772907
Trained batch 446 in epoch 19, gen_loss = 0.3994150776124374, disc_loss = 0.06555551515946319
Trained batch 447 in epoch 19, gen_loss = 0.399218863574788, disc_loss = 0.06598479658714496
Trained batch 448 in epoch 19, gen_loss = 0.39924264156605993, disc_loss = 0.06598681774413533
Trained batch 449 in epoch 19, gen_loss = 0.3991654708981514, disc_loss = 0.06589369592153364
Trained batch 450 in epoch 19, gen_loss = 0.3989903218796407, disc_loss = 0.06579606927220943
Trained batch 451 in epoch 19, gen_loss = 0.3990115224985422, disc_loss = 0.0657020122620516
Trained batch 452 in epoch 19, gen_loss = 0.39904823902558545, disc_loss = 0.06566102459007014
Trained batch 453 in epoch 19, gen_loss = 0.39925615735647435, disc_loss = 0.06565042191271214
Trained batch 454 in epoch 19, gen_loss = 0.3993481574805228, disc_loss = 0.06560185226601559
Trained batch 455 in epoch 19, gen_loss = 0.39927077865260735, disc_loss = 0.06550290191284659
Trained batch 456 in epoch 19, gen_loss = 0.3990187910701305, disc_loss = 0.0655163405646511
Trained batch 457 in epoch 19, gen_loss = 0.3990986823189727, disc_loss = 0.0654356809959271
Trained batch 458 in epoch 19, gen_loss = 0.39933864402225594, disc_loss = 0.06532241203994663
Trained batch 459 in epoch 19, gen_loss = 0.39920521822312605, disc_loss = 0.06538973907008767
Trained batch 460 in epoch 19, gen_loss = 0.3993560996658114, disc_loss = 0.06535129706070247
Testing Epoch 19
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-08-30 01:07:49,439
------------------------------------------------------------
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-08-30 01:07:49,462
------------------------------------------------------------
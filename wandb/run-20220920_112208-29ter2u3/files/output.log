/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 1.075941562652588, disc_loss = 0.6879106163978577
Trained batch 1 in epoch 0, gen_loss = 1.022131860256195, disc_loss = 0.6154638528823853
Trained batch 2 in epoch 0, gen_loss = 1.0522452592849731, disc_loss = 0.7287074327468872
Trained batch 3 in epoch 0, gen_loss = 0.9802761822938919, disc_loss = 0.6571516543626785
Trained batch 4 in epoch 0, gen_loss = 0.9335836291313171, disc_loss = 0.5920770049095154
Trained batch 5 in epoch 0, gen_loss = 0.9052566389242808, disc_loss = 0.5301939596732458
Trained batch 6 in epoch 0, gen_loss = 0.8897551894187927, disc_loss = 0.48212810286453794
Trained batch 7 in epoch 0, gen_loss = 0.8839848339557648, disc_loss = 0.44527685083448887
Trained batch 8 in epoch 0, gen_loss = 0.8706519603729248, disc_loss = 0.41456154816680485
Trained batch 9 in epoch 0, gen_loss = 0.8636072278022766, disc_loss = 0.3865156352519989
Trained batch 10 in epoch 0, gen_loss = 0.8594553362239491, disc_loss = 0.3628979027271271
Trained batch 11 in epoch 0, gen_loss = 0.854601244131724, disc_loss = 0.3422367200255394
Trained batch 12 in epoch 0, gen_loss = 0.8525296357961801, disc_loss = 0.3248250845533151
Trained batch 13 in epoch 0, gen_loss = 0.8519344414983477, disc_loss = 0.31040078508002417
Trained batch 14 in epoch 0, gen_loss = 0.8477081298828125, disc_loss = 0.29830060501893363
Trained batch 15 in epoch 0, gen_loss = 0.8468304723501205, disc_loss = 0.28806354384869337
Trained batch 16 in epoch 0, gen_loss = 0.84187592828975, disc_loss = 0.2839970457203248
Trained batch 17 in epoch 0, gen_loss = 0.8434937563207414, disc_loss = 0.2824440457754665
Trained batch 18 in epoch 0, gen_loss = 0.8414324490647567, disc_loss = 0.278913698698345
Trained batch 19 in epoch 0, gen_loss = 0.8508926421403885, disc_loss = 0.27261836677789686
Trained batch 20 in epoch 0, gen_loss = 0.8605120664551145, disc_loss = 0.266956104409127
Trained batch 21 in epoch 0, gen_loss = 0.874104692177339, disc_loss = 0.2625552788376808
Trained batch 22 in epoch 0, gen_loss = 0.8849469293718752, disc_loss = 0.25478167572747107
Trained batch 23 in epoch 0, gen_loss = 0.8952802394827207, disc_loss = 0.24683265388011932
Trained batch 24 in epoch 0, gen_loss = 0.9039191126823425, disc_loss = 0.23921308308839798
Trained batch 25 in epoch 0, gen_loss = 0.9125037674720471, disc_loss = 0.23165972158312798
Trained batch 26 in epoch 0, gen_loss = 0.9209997852643331, disc_loss = 0.22463751998212603
Trained batch 27 in epoch 0, gen_loss = 0.9281071616070611, disc_loss = 0.21798403268413885
Trained batch 28 in epoch 0, gen_loss = 0.9352825900603985, disc_loss = 0.21174885371121868
Trained batch 29 in epoch 0, gen_loss = 0.9408676207065583, disc_loss = 0.20574110311766466
Trained batch 30 in epoch 0, gen_loss = 0.9462898873513744, disc_loss = 0.2002226388262164
Trained batch 31 in epoch 0, gen_loss = 0.9503255132585764, disc_loss = 0.1949470303952694
Trained batch 32 in epoch 0, gen_loss = 0.955103767640663, disc_loss = 0.18996783458825314
Trained batch 33 in epoch 0, gen_loss = 0.9595141638727749, disc_loss = 0.1852199254447923
Trained batch 34 in epoch 0, gen_loss = 0.9636474898883275, disc_loss = 0.1807195144040244
Trained batch 35 in epoch 0, gen_loss = 0.9679639819595549, disc_loss = 0.17648004952611196
Trained batch 36 in epoch 0, gen_loss = 0.9713744005641421, disc_loss = 0.17240580861028787
Trained batch 37 in epoch 0, gen_loss = 0.9770522352896238, disc_loss = 0.16861163663040651
Trained batch 38 in epoch 0, gen_loss = 0.9816621068196419, disc_loss = 0.16496700760072622
Trained batch 39 in epoch 0, gen_loss = 0.9849729344248772, disc_loss = 0.16144127817824483
Trained batch 40 in epoch 0, gen_loss = 0.9894113119055585, disc_loss = 0.158133387838195
Trained batch 41 in epoch 0, gen_loss = 0.9925979361647651, disc_loss = 0.15491664312070325
Trained batch 42 in epoch 0, gen_loss = 0.9968898698341014, disc_loss = 0.1518283057091541
Trained batch 43 in epoch 0, gen_loss = 0.9998364570465955, disc_loss = 0.14885472434318878
Trained batch 44 in epoch 0, gen_loss = 1.0031615959273443, disc_loss = 0.14600324270625908
Trained batch 45 in epoch 0, gen_loss = 1.0057636460532313, disc_loss = 0.14329951539959596
Trained batch 46 in epoch 0, gen_loss = 1.0085104640494003, disc_loss = 0.14069363395584392
Trained batch 47 in epoch 0, gen_loss = 1.0102119309206803, disc_loss = 0.13816961793539426
Trained batch 48 in epoch 0, gen_loss = 1.0125621472086226, disc_loss = 0.1358255705206978
Trained batch 49 in epoch 0, gen_loss = 1.0162023532390594, disc_loss = 0.1336009331047535
Trained batch 50 in epoch 0, gen_loss = 1.0191855138423396, disc_loss = 0.1314111048465266
Trained batch 51 in epoch 0, gen_loss = 1.0216804249928548, disc_loss = 0.12934254571938744
Trained batch 52 in epoch 0, gen_loss = 1.0239799303828545, disc_loss = 0.12737941418616278
Trained batch 53 in epoch 0, gen_loss = 1.0262009004751842, disc_loss = 0.12548337662937464
Trained batch 54 in epoch 0, gen_loss = 1.0283095500685953, disc_loss = 0.12365779795429924
Trained batch 55 in epoch 0, gen_loss = 1.0305011112775122, disc_loss = 0.12189045644897435
Trained batch 56 in epoch 0, gen_loss = 1.0316023251466584, disc_loss = 0.12014803424346865
Trained batch 57 in epoch 0, gen_loss = 1.033157933374931, disc_loss = 0.11846579123159935
Trained batch 58 in epoch 0, gen_loss = 1.0354213926751734, disc_loss = 0.11676234859278646
Trained batch 59 in epoch 0, gen_loss = 1.0373103628555933, disc_loss = 0.11508668664221962
Trained batch 60 in epoch 0, gen_loss = 1.0395433111268966, disc_loss = 0.11348560681474991
Trained batch 61 in epoch 0, gen_loss = 1.040956457776408, disc_loss = 0.11190005397844699
Trained batch 62 in epoch 0, gen_loss = 1.0428286327256098, disc_loss = 0.11037201440287014
Trained batch 63 in epoch 0, gen_loss = 1.044506429694593, disc_loss = 0.1089032621239312
Trained batch 64 in epoch 0, gen_loss = 1.0465966435579153, disc_loss = 0.1074699260867559
Trained batch 65 in epoch 0, gen_loss = 1.0473483033252484, disc_loss = 0.10605979775727699
Trained batch 66 in epoch 0, gen_loss = 1.0487555825888222, disc_loss = 0.10470459799268353
Trained batch 67 in epoch 0, gen_loss = 1.050021982368301, disc_loss = 0.10339705007808174
Trained batch 68 in epoch 0, gen_loss = 1.051362377146016, disc_loss = 0.10213446193307206
Trained batch 69 in epoch 0, gen_loss = 1.0533763553415025, disc_loss = 0.1008799338181104
Trained batch 70 in epoch 0, gen_loss = 1.0545764582257875, disc_loss = 0.09965210321398688
Trained batch 71 in epoch 0, gen_loss = 1.0565977899564638, disc_loss = 0.0984714693752014
Trained batch 72 in epoch 0, gen_loss = 1.0572999087098527, disc_loss = 0.09731512345781881
Trained batch 73 in epoch 0, gen_loss = 1.0579680937367517, disc_loss = 0.09620617843560271
Trained batch 74 in epoch 0, gen_loss = 1.059072417418162, disc_loss = 0.09518494243423144
Trained batch 75 in epoch 0, gen_loss = 1.0597822485785735, disc_loss = 0.09423201668419336
Trained batch 76 in epoch 0, gen_loss = 1.0605977657553438, disc_loss = 0.09351760579587577
Trained batch 77 in epoch 0, gen_loss = 1.0624615435416882, disc_loss = 0.09299105697144301
Trained batch 78 in epoch 0, gen_loss = 1.06362824123117, disc_loss = 0.09229162660769269
Trained batch 79 in epoch 0, gen_loss = 1.0646890856325626, disc_loss = 0.09166525905020535
Trained batch 80 in epoch 0, gen_loss = 1.0661111783098292, disc_loss = 0.09126265094052126
Trained batch 81 in epoch 0, gen_loss = 1.0667229200281747, disc_loss = 0.09079110763240152
Trained batch 82 in epoch 0, gen_loss = 1.0668560446026814, disc_loss = 0.09006766144590206
Trained batch 83 in epoch 0, gen_loss = 1.0667939008701415, disc_loss = 0.08917435267496676
Trained batch 84 in epoch 0, gen_loss = 1.0667606178451987, disc_loss = 0.08831133152193883
Trained batch 85 in epoch 0, gen_loss = 1.066925933887792, disc_loss = 0.08748129696780166
Trained batch 86 in epoch 0, gen_loss = 1.0669387270664346, disc_loss = 0.08672988669540005
Trained batch 87 in epoch 0, gen_loss = 1.067184068262577, disc_loss = 0.08607042400928383
Trained batch 88 in epoch 0, gen_loss = 1.0672901286168044, disc_loss = 0.08534772375996193
Trained batch 89 in epoch 0, gen_loss = 1.0677089605066512, disc_loss = 0.08460042017201583
Trained batch 90 in epoch 0, gen_loss = 1.0685808848548721, disc_loss = 0.08388272658563577
Trained batch 91 in epoch 0, gen_loss = 1.068955196634583, disc_loss = 0.08315472904106845
Trained batch 92 in epoch 0, gen_loss = 1.0692376776408123, disc_loss = 0.08249205587211475
Trained batch 93 in epoch 0, gen_loss = 1.0689466601990638, disc_loss = 0.08173789412892879
Trained batch 94 in epoch 0, gen_loss = 1.0688834133901095, disc_loss = 0.08102529762606872
Trained batch 95 in epoch 0, gen_loss = 1.068843540425102, disc_loss = 0.0803091741205814
Trained batch 96 in epoch 0, gen_loss = 1.0692529917992268, disc_loss = 0.07961059290646892
Trained batch 97 in epoch 0, gen_loss = 1.069385510926344, disc_loss = 0.07894959606762443
Trained batch 98 in epoch 0, gen_loss = 1.06928350166841, disc_loss = 0.0782712921970571
Trained batch 99 in epoch 0, gen_loss = 1.068881465792656, disc_loss = 0.07759787340648472
Trained batch 100 in epoch 0, gen_loss = 1.068868104184028, disc_loss = 0.07696213978942078
Trained batch 101 in epoch 0, gen_loss = 1.0689853821315018, disc_loss = 0.07633510774330181
Trained batch 102 in epoch 0, gen_loss = 1.069619753407043, disc_loss = 0.0757634096860307
Trained batch 103 in epoch 0, gen_loss = 1.0701373878579874, disc_loss = 0.07529359314447412
Trained batch 104 in epoch 0, gen_loss = 1.0703029059228444, disc_loss = 0.07487776038192567
Trained batch 105 in epoch 0, gen_loss = 1.0702995314912975, disc_loss = 0.07440419813161189
Trained batch 106 in epoch 0, gen_loss = 1.0702590702850128, disc_loss = 0.07384302237323512
Trained batch 107 in epoch 0, gen_loss = 1.070257415926015, disc_loss = 0.0732561679970887
Trained batch 108 in epoch 0, gen_loss = 1.0705508010103069, disc_loss = 0.07268011205992021
Trained batch 109 in epoch 0, gen_loss = 1.0704922117970206, disc_loss = 0.07215372555127197
Trained batch 110 in epoch 0, gen_loss = 1.070356156911936, disc_loss = 0.0716012731647572
Trained batch 111 in epoch 0, gen_loss = 1.0703724159726076, disc_loss = 0.07104299818664524
Trained batch 112 in epoch 0, gen_loss = 1.0707455245794448, disc_loss = 0.0705119243501562
Trained batch 113 in epoch 0, gen_loss = 1.070255425415541, disc_loss = 0.06996327091269848
Trained batch 114 in epoch 0, gen_loss = 1.0705030705617822, disc_loss = 0.06951271225900754
Trained batch 115 in epoch 0, gen_loss = 1.070812794155088, disc_loss = 0.06904773502450051
Trained batch 116 in epoch 0, gen_loss = 1.0708903008037143, disc_loss = 0.06855101012585
Trained batch 117 in epoch 0, gen_loss = 1.0711166853621854, disc_loss = 0.06804184536686388
Trained batch 118 in epoch 0, gen_loss = 1.0710486459131001, disc_loss = 0.06754187521125589
Trained batch 119 in epoch 0, gen_loss = 1.0711141680677732, disc_loss = 0.06706368706654757
Trained batch 120 in epoch 0, gen_loss = 1.0709305267688656, disc_loss = 0.0665915009203898
Trained batch 121 in epoch 0, gen_loss = 1.0705749368081328, disc_loss = 0.06611366640990142
Trained batch 122 in epoch 0, gen_loss = 1.070412662455706, disc_loss = 0.0656382175147291
Trained batch 123 in epoch 0, gen_loss = 1.070420287789837, disc_loss = 0.065164225979618
Trained batch 124 in epoch 0, gen_loss = 1.070266062259674, disc_loss = 0.06469898085668684
Trained batch 125 in epoch 0, gen_loss = 1.0703072685097892, disc_loss = 0.06424111961608842
Trained batch 126 in epoch 0, gen_loss = 1.0701257323655557, disc_loss = 0.06379420240959666
Trained batch 127 in epoch 0, gen_loss = 1.0699555580504239, disc_loss = 0.0633681884901307
Trained batch 128 in epoch 0, gen_loss = 1.0699016655138296, disc_loss = 0.06293143268833443
Trained batch 129 in epoch 0, gen_loss = 1.0699856331715216, disc_loss = 0.062495870089444974
Trained batch 130 in epoch 0, gen_loss = 1.0703270458083116, disc_loss = 0.062084874731865324
Trained batch 131 in epoch 0, gen_loss = 1.0703572238033467, disc_loss = 0.06168095383327454
Trained batch 132 in epoch 0, gen_loss = 1.070342541189122, disc_loss = 0.06126617501258738
Trained batch 133 in epoch 0, gen_loss = 1.0703981247410845, disc_loss = 0.06085746211291694
Trained batch 134 in epoch 0, gen_loss = 1.0708481130776581, disc_loss = 0.06046079869416577
Trained batch 135 in epoch 0, gen_loss = 1.0709741084891207, disc_loss = 0.06006707284969332
Trained batch 136 in epoch 0, gen_loss = 1.0708985715886972, disc_loss = 0.05967198806155446
Trained batch 137 in epoch 0, gen_loss = 1.0704321977884874, disc_loss = 0.05928139873793808
Trained batch 138 in epoch 0, gen_loss = 1.0701682923509062, disc_loss = 0.05890001166317103
Trained batch 139 in epoch 0, gen_loss = 1.070071376647268, disc_loss = 0.05852015962092472
Trained batch 140 in epoch 0, gen_loss = 1.0703124353226194, disc_loss = 0.05815175240727287
Trained batch 141 in epoch 0, gen_loss = 1.070162341208525, disc_loss = 0.05779131754747474
Trained batch 142 in epoch 0, gen_loss = 1.0702005628939275, disc_loss = 0.05742815225808458
Trained batch 143 in epoch 0, gen_loss = 1.0702056259744697, disc_loss = 0.057073675513189905
Trained batch 144 in epoch 0, gen_loss = 1.0699106837141104, disc_loss = 0.05672433028511446
Trained batch 145 in epoch 0, gen_loss = 1.0698362813420492, disc_loss = 0.056377387704480794
Trained batch 146 in epoch 0, gen_loss = 1.0701759262960784, disc_loss = 0.056042188578950505
Trained batch 147 in epoch 0, gen_loss = 1.0701559890766401, disc_loss = 0.05570559925085085
Trained batch 148 in epoch 0, gen_loss = 1.070150280558823, disc_loss = 0.055371082691013214
Trained batch 149 in epoch 0, gen_loss = 1.0700085858503978, disc_loss = 0.05504147295219203
Trained batch 150 in epoch 0, gen_loss = 1.069857273275489, disc_loss = 0.05471720103951578
Trained batch 151 in epoch 0, gen_loss = 1.0698213361595805, disc_loss = 0.0544029611597867
Trained batch 152 in epoch 0, gen_loss = 1.069707566227009, disc_loss = 0.05408869651176668
Trained batch 153 in epoch 0, gen_loss = 1.0696675820010049, disc_loss = 0.053774505530109075
Trained batch 154 in epoch 0, gen_loss = 1.069787585735321, disc_loss = 0.053461836140242316
Trained batch 155 in epoch 0, gen_loss = 1.0699398613128908, disc_loss = 0.05315298310672052
Trained batch 156 in epoch 0, gen_loss = 1.0698557359397791, disc_loss = 0.05285164410141623
Trained batch 157 in epoch 0, gen_loss = 1.0699144907390015, disc_loss = 0.05255731633168798
Trained batch 158 in epoch 0, gen_loss = 1.070020227687164, disc_loss = 0.052259104475730435
Trained batch 159 in epoch 0, gen_loss = 1.0701288495212793, disc_loss = 0.05196549862448592
Trained batch 160 in epoch 0, gen_loss = 1.0698231906624314, disc_loss = 0.05167653337873009
Trained batch 161 in epoch 0, gen_loss = 1.0695894025726083, disc_loss = 0.05138586796992631
Trained batch 162 in epoch 0, gen_loss = 1.0696556154935637, disc_loss = 0.05110036670316034
Trained batch 163 in epoch 0, gen_loss = 1.0696636485617335, disc_loss = 0.05082009504435629
Trained batch 164 in epoch 0, gen_loss = 1.0695904063455985, disc_loss = 0.05054055264388973
Trained batch 165 in epoch 0, gen_loss = 1.0691789657954711, disc_loss = 0.050262872480327285
Trained batch 166 in epoch 0, gen_loss = 1.0689267416200239, disc_loss = 0.049988592024000286
Trained batch 167 in epoch 0, gen_loss = 1.0686152964120819, disc_loss = 0.04971910680233989
Trained batch 168 in epoch 0, gen_loss = 1.0687275606499622, disc_loss = 0.04945541743585873
Trained batch 169 in epoch 0, gen_loss = 1.0687347948551178, disc_loss = 0.04919242238187615
Trained batch 170 in epoch 0, gen_loss = 1.0686953921764217, disc_loss = 0.04893380296498276
Trained batch 171 in epoch 0, gen_loss = 1.0684183853310207, disc_loss = 0.0486721187575482
Trained batch 172 in epoch 0, gen_loss = 1.0682401440047116, disc_loss = 0.0484161337385374
Trained batch 173 in epoch 0, gen_loss = 1.0682004378444847, disc_loss = 0.048164699917081104
Trained batch 174 in epoch 0, gen_loss = 1.0681935920034136, disc_loss = 0.04791941941848823
Trained batch 175 in epoch 0, gen_loss = 1.0682947950606996, disc_loss = 0.04768020564436235
Trained batch 176 in epoch 0, gen_loss = 1.0680450978925673, disc_loss = 0.04744030461557167
Trained batch 177 in epoch 0, gen_loss = 1.0679502925846014, disc_loss = 0.04720367601120405
Trained batch 178 in epoch 0, gen_loss = 1.067631258977858, disc_loss = 0.046972036288853464
Trained batch 179 in epoch 0, gen_loss = 1.0676071998145846, disc_loss = 0.04674120695692384
Trained batch 180 in epoch 0, gen_loss = 1.067711650666611, disc_loss = 0.04651849990124037
Trained batch 181 in epoch 0, gen_loss = 1.0676266351243953, disc_loss = 0.046293079295287747
Trained batch 182 in epoch 0, gen_loss = 1.0674577127388918, disc_loss = 0.04607052985538062
Trained batch 183 in epoch 0, gen_loss = 1.0673174971471662, disc_loss = 0.04584780135242592
Trained batch 184 in epoch 0, gen_loss = 1.0671446294397922, disc_loss = 0.045635647354395806
Trained batch 185 in epoch 0, gen_loss = 1.0670890510082245, disc_loss = 0.045439518690209395
Trained batch 186 in epoch 0, gen_loss = 1.0668437981350536, disc_loss = 0.04523958319818033
Trained batch 187 in epoch 0, gen_loss = 1.0669676867571283, disc_loss = 0.04503985879288867
Trained batch 188 in epoch 0, gen_loss = 1.0669618639996443, disc_loss = 0.04483650815944192
Trained batch 189 in epoch 0, gen_loss = 1.0668080383225491, disc_loss = 0.04463182155435023
Trained batch 190 in epoch 0, gen_loss = 1.0666663500026883, disc_loss = 0.04442779750548576
Trained batch 191 in epoch 0, gen_loss = 1.0667615349714954, disc_loss = 0.04422800512838876
Trained batch 192 in epoch 0, gen_loss = 1.066423979139081, disc_loss = 0.04402352507597733
Trained batch 193 in epoch 0, gen_loss = 1.0662416542313762, disc_loss = 0.04382214534634091
Trained batch 194 in epoch 0, gen_loss = 1.0660921955719973, disc_loss = 0.04362040276472003
Trained batch 195 in epoch 0, gen_loss = 1.0661998795611518, disc_loss = 0.0434188416527052
Trained batch 196 in epoch 0, gen_loss = 1.0660601064638437, disc_loss = 0.04321767485743096
Trained batch 197 in epoch 0, gen_loss = 1.065745823612117, disc_loss = 0.04301982334429266
Trained batch 198 in epoch 0, gen_loss = 1.065552689621796, disc_loss = 0.04282561278710114
Trained batch 199 in epoch 0, gen_loss = 1.0657442632317542, disc_loss = 0.04264457882381976
Trained batch 200 in epoch 0, gen_loss = 1.0655609295142823, disc_loss = 0.04247083528829155
Trained batch 201 in epoch 0, gen_loss = 1.0654490091422997, disc_loss = 0.04231199569594447
Trained batch 202 in epoch 0, gen_loss = 1.0655658694323649, disc_loss = 0.04215866881491515
Trained batch 203 in epoch 0, gen_loss = 1.0654224662804137, disc_loss = 0.041990005539036264
Trained batch 204 in epoch 0, gen_loss = 1.065215796668355, disc_loss = 0.04181084641959609
Trained batch 205 in epoch 0, gen_loss = 1.0651701118760897, disc_loss = 0.04163206971331852
Trained batch 206 in epoch 0, gen_loss = 1.064825369252099, disc_loss = 0.04145202038422731
Trained batch 207 in epoch 0, gen_loss = 1.0647800240952234, disc_loss = 0.04127339828231085
Trained batch 208 in epoch 0, gen_loss = 1.064583029758417, disc_loss = 0.0411005064635649
Trained batch 209 in epoch 0, gen_loss = 1.0645041519687288, disc_loss = 0.040933992365552556
Trained batch 210 in epoch 0, gen_loss = 1.064579976960946, disc_loss = 0.04076419599680892
Trained batch 211 in epoch 0, gen_loss = 1.0643381512952301, disc_loss = 0.04059284820028071
Trained batch 212 in epoch 0, gen_loss = 1.0644468637139584, disc_loss = 0.04043012350237985
Trained batch 213 in epoch 0, gen_loss = 1.0641681092364765, disc_loss = 0.040284444234185965
Trained batch 214 in epoch 0, gen_loss = 1.0642980256745982, disc_loss = 0.04015746300736832
Trained batch 215 in epoch 0, gen_loss = 1.0643730905872804, disc_loss = 0.040032550494221074
Trained batch 216 in epoch 0, gen_loss = 1.0642202672321126, disc_loss = 0.039894016841555247
Trained batch 217 in epoch 0, gen_loss = 1.0639269562489395, disc_loss = 0.03975085500166367
Trained batch 218 in epoch 0, gen_loss = 1.06399602895458, disc_loss = 0.03960192151001939
Trained batch 219 in epoch 0, gen_loss = 1.0638961339538748, disc_loss = 0.03944611992178993
Trained batch 220 in epoch 0, gen_loss = 1.063811309467074, disc_loss = 0.03928915817475966
Trained batch 221 in epoch 0, gen_loss = 1.0637684590644665, disc_loss = 0.03913314181782708
Trained batch 222 in epoch 0, gen_loss = 1.0637589241357128, disc_loss = 0.038975914194762304
Trained batch 223 in epoch 0, gen_loss = 1.0636343777711903, disc_loss = 0.038818391551363414
Trained batch 224 in epoch 0, gen_loss = 1.0636553406715392, disc_loss = 0.03866657545583116
Trained batch 225 in epoch 0, gen_loss = 1.0635646457693217, disc_loss = 0.03851232634222679
Trained batch 226 in epoch 0, gen_loss = 1.0635474539538312, disc_loss = 0.0383637561647443
Trained batch 227 in epoch 0, gen_loss = 1.0632617306291012, disc_loss = 0.03821981290820986
Trained batch 228 in epoch 0, gen_loss = 1.0630873191825168, disc_loss = 0.03808254050700945
Trained batch 229 in epoch 0, gen_loss = 1.0633228291635928, disc_loss = 0.037948963428726015
Trained batch 230 in epoch 0, gen_loss = 1.063304897510644, disc_loss = 0.037809102338420233
Trained batch 231 in epoch 0, gen_loss = 1.0632762996287182, disc_loss = 0.037667789213471754
Trained batch 232 in epoch 0, gen_loss = 1.0629632508805893, disc_loss = 0.03752269313666698
Trained batch 233 in epoch 0, gen_loss = 1.062921402291355, disc_loss = 0.03737658060864251
Trained batch 234 in epoch 0, gen_loss = 1.0628663849323354, disc_loss = 0.037230825729351096
Trained batch 235 in epoch 0, gen_loss = 1.0625376620535123, disc_loss = 0.03708446538667747
Trained batch 236 in epoch 0, gen_loss = 1.0624238428687245, disc_loss = 0.03694305514508096
Trained batch 237 in epoch 0, gen_loss = 1.0623080735447026, disc_loss = 0.0368029898650819
Trained batch 238 in epoch 0, gen_loss = 1.0622152908077798, disc_loss = 0.03666530468766129
Trained batch 239 in epoch 0, gen_loss = 1.0621448814868928, disc_loss = 0.0365295977438412
Trained batch 240 in epoch 0, gen_loss = 1.0621647701223855, disc_loss = 0.03639315941015498
Trained batch 241 in epoch 0, gen_loss = 1.062209834737226, disc_loss = 0.03625998110221776
Trained batch 242 in epoch 0, gen_loss = 1.0622675556214258, disc_loss = 0.03612620122788221
Trained batch 243 in epoch 0, gen_loss = 1.0625362283870823, disc_loss = 0.03599355913618518
Trained batch 244 in epoch 0, gen_loss = 1.0624888103835437, disc_loss = 0.035861909284959644
Trained batch 245 in epoch 0, gen_loss = 1.0624531022901458, disc_loss = 0.03573315853926891
Trained batch 246 in epoch 0, gen_loss = 1.062351084913802, disc_loss = 0.03560368878661319
Trained batch 247 in epoch 0, gen_loss = 1.0622655557047935, disc_loss = 0.03547569314738916
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 1.0166183710098267, disc_loss = 0.003384385723620653
Trained batch 1 in epoch 1, gen_loss = 1.0231358408927917, disc_loss = 0.0037508143577724695
Trained batch 2 in epoch 1, gen_loss = 1.0129852096239726, disc_loss = 0.004038473746428887
Trained batch 3 in epoch 1, gen_loss = 1.0203572064638138, disc_loss = 0.004342754953540862
Trained batch 4 in epoch 1, gen_loss = 1.0269597172737122, disc_loss = 0.00459893299266696
Trained batch 5 in epoch 1, gen_loss = 1.0234375894069672, disc_loss = 0.004785523594667514
Trained batch 6 in epoch 1, gen_loss = 1.0293001702853612, disc_loss = 0.0048473419488540715
Trained batch 7 in epoch 1, gen_loss = 1.0331229493021965, disc_loss = 0.004821884504053742
Trained batch 8 in epoch 1, gen_loss = 1.0338293115297954, disc_loss = 0.00482819193146295
Trained batch 9 in epoch 1, gen_loss = 1.0294762194156646, disc_loss = 0.004719631397165358
Trained batch 10 in epoch 1, gen_loss = 1.028621570630507, disc_loss = 0.00458272646011954
Trained batch 11 in epoch 1, gen_loss = 1.0298278878132503, disc_loss = 0.004444163738905142
Trained batch 12 in epoch 1, gen_loss = 1.02662697663674, disc_loss = 0.004329319756764632
Trained batch 13 in epoch 1, gen_loss = 1.0243129857948847, disc_loss = 0.004228905974222081
Trained batch 14 in epoch 1, gen_loss = 1.0227561831474303, disc_loss = 0.004114447689304749
Trained batch 15 in epoch 1, gen_loss = 1.0217324532568455, disc_loss = 0.004070913360919803
Trained batch 16 in epoch 1, gen_loss = 1.0189484392895418, disc_loss = 0.004097387249417165
Trained batch 17 in epoch 1, gen_loss = 1.018426905075709, disc_loss = 0.004105980508029461
Trained batch 18 in epoch 1, gen_loss = 1.0154222218613875, disc_loss = 0.004140449491770644
Trained batch 19 in epoch 1, gen_loss = 1.0160868734121322, disc_loss = 0.004263337352313101
Trained batch 20 in epoch 1, gen_loss = 1.0144323536327906, disc_loss = 0.004429926120099567
Trained batch 21 in epoch 1, gen_loss = 1.0155293426730416, disc_loss = 0.004496086304160682
Trained batch 22 in epoch 1, gen_loss = 1.015654628691466, disc_loss = 0.004472128014363672
Trained batch 23 in epoch 1, gen_loss = 1.0168805147210758, disc_loss = 0.004425613529747352
Trained batch 24 in epoch 1, gen_loss = 1.0179302239418029, disc_loss = 0.004372449005022645
Trained batch 25 in epoch 1, gen_loss = 1.0180117098184733, disc_loss = 0.004300684480068202
Trained batch 26 in epoch 1, gen_loss = 1.0192802901621218, disc_loss = 0.004241317907279289
Trained batch 27 in epoch 1, gen_loss = 1.0183808995144707, disc_loss = 0.004186669397833092
Trained batch 28 in epoch 1, gen_loss = 1.017647751446428, disc_loss = 0.004148455248374878
Trained batch 29 in epoch 1, gen_loss = 1.0167786061763764, disc_loss = 0.004125727542365591
Trained batch 30 in epoch 1, gen_loss = 1.0161322201451948, disc_loss = 0.004118716509471978
Trained batch 31 in epoch 1, gen_loss = 1.01500403881073, disc_loss = 0.004109096924366895
Trained batch 32 in epoch 1, gen_loss = 1.0156202244036125, disc_loss = 0.0041054914860675735
Trained batch 33 in epoch 1, gen_loss = 1.0159312767141007, disc_loss = 0.004092171233530869
Trained batch 34 in epoch 1, gen_loss = 1.0148674522127423, disc_loss = 0.00407384714510824
Trained batch 35 in epoch 1, gen_loss = 1.0139588001701567, disc_loss = 0.0040505310818035566
Trained batch 36 in epoch 1, gen_loss = 1.013574877300778, disc_loss = 0.004030622774735093
Trained batch 37 in epoch 1, gen_loss = 1.012660092429111, disc_loss = 0.004000137198569351
Trained batch 38 in epoch 1, gen_loss = 1.0124672437325501, disc_loss = 0.0039678446482867
Trained batch 39 in epoch 1, gen_loss = 1.0122399002313613, disc_loss = 0.0039359551039524375
Trained batch 40 in epoch 1, gen_loss = 1.0126076180760453, disc_loss = 0.003931443104747592
Trained batch 41 in epoch 1, gen_loss = 1.0128928848675318, disc_loss = 0.003924391897661346
Trained batch 42 in epoch 1, gen_loss = 1.0123316798099251, disc_loss = 0.003925945913029271
Trained batch 43 in epoch 1, gen_loss = 1.0121092200279236, disc_loss = 0.003924599388317967
Trained batch 44 in epoch 1, gen_loss = 1.0115728351804945, disc_loss = 0.003923921219797598
Trained batch 45 in epoch 1, gen_loss = 1.0113299359445986, disc_loss = 0.003921576507349053
Trained batch 46 in epoch 1, gen_loss = 1.0103664905466931, disc_loss = 0.003938251388001632
Trained batch 47 in epoch 1, gen_loss = 1.010726161301136, disc_loss = 0.003992730378134486
Trained batch 48 in epoch 1, gen_loss = 1.0115115374934918, disc_loss = 0.004069069813822909
Trained batch 49 in epoch 1, gen_loss = 1.0098315691947937, disc_loss = 0.004156341454945505
Trained batch 50 in epoch 1, gen_loss = 1.0100071360083187, disc_loss = 0.0042100135264370375
Trained batch 51 in epoch 1, gen_loss = 1.0101730892291436, disc_loss = 0.00422492085579926
Trained batch 52 in epoch 1, gen_loss = 1.0095678016824543, disc_loss = 0.004229803740943097
Trained batch 53 in epoch 1, gen_loss = 1.0089946499577276, disc_loss = 0.004222229774179006
Trained batch 54 in epoch 1, gen_loss = 1.008077131618153, disc_loss = 0.004215971528637138
Trained batch 55 in epoch 1, gen_loss = 1.0070396342447825, disc_loss = 0.0042003663589379615
Trained batch 56 in epoch 1, gen_loss = 1.007540683997305, disc_loss = 0.004170166786041176
Trained batch 57 in epoch 1, gen_loss = 1.0068916483172055, disc_loss = 0.00414908023808023
Trained batch 58 in epoch 1, gen_loss = 1.0060618317733376, disc_loss = 0.004139803326294079
Trained batch 59 in epoch 1, gen_loss = 1.006054523587227, disc_loss = 0.0041173430159688
Trained batch 60 in epoch 1, gen_loss = 1.0060529620921026, disc_loss = 0.004103389522824131
Trained batch 61 in epoch 1, gen_loss = 1.0069837079894157, disc_loss = 0.004084450087600177
Trained batch 62 in epoch 1, gen_loss = 1.0070900964358496, disc_loss = 0.004056239419335883
Trained batch 63 in epoch 1, gen_loss = 1.0066729495301843, disc_loss = 0.0040287129013449885
Trained batch 64 in epoch 1, gen_loss = 1.0060325081531818, disc_loss = 0.003995740119940959
Trained batch 65 in epoch 1, gen_loss = 1.0061674560561324, disc_loss = 0.003973340361633084
Trained batch 66 in epoch 1, gen_loss = 1.0066126504940773, disc_loss = 0.003951419120543261
Trained batch 67 in epoch 1, gen_loss = 1.0065977266606163, disc_loss = 0.0039344317252364225
Trained batch 68 in epoch 1, gen_loss = 1.006612593713014, disc_loss = 0.003909190748885706
Trained batch 69 in epoch 1, gen_loss = 1.0065819697720664, disc_loss = 0.0038812183525546323
Trained batch 70 in epoch 1, gen_loss = 1.007009273683521, disc_loss = 0.003858575074356312
Trained batch 71 in epoch 1, gen_loss = 1.0062214583158493, disc_loss = 0.0038552889939940846
Trained batch 72 in epoch 1, gen_loss = 1.005975361556223, disc_loss = 0.0038573116985825846
Trained batch 73 in epoch 1, gen_loss = 1.0058229396472107, disc_loss = 0.0038623508849382603
Trained batch 74 in epoch 1, gen_loss = 1.0062064909934998, disc_loss = 0.00386684923277547
Trained batch 75 in epoch 1, gen_loss = 1.0065709705415524, disc_loss = 0.0038653058995566283
Trained batch 76 in epoch 1, gen_loss = 1.0063918263881237, disc_loss = 0.0038527511559160693
Trained batch 77 in epoch 1, gen_loss = 1.0065365884548578, disc_loss = 0.0038342579545524833
Trained batch 78 in epoch 1, gen_loss = 1.0058511676667612, disc_loss = 0.0038116430477651802
Trained batch 79 in epoch 1, gen_loss = 1.0059708908200264, disc_loss = 0.003794645112066064
Trained batch 80 in epoch 1, gen_loss = 1.0058295631114347, disc_loss = 0.003781571543062635
Trained batch 81 in epoch 1, gen_loss = 1.0055163822522977, disc_loss = 0.0037691321567541397
Trained batch 82 in epoch 1, gen_loss = 1.0051512847463768, disc_loss = 0.0037547758463433527
Trained batch 83 in epoch 1, gen_loss = 1.0048554490009944, disc_loss = 0.003735623620395061
Trained batch 84 in epoch 1, gen_loss = 1.0043466224389919, disc_loss = 0.003715275801882586
Trained batch 85 in epoch 1, gen_loss = 1.0042376254880152, disc_loss = 0.0036971355060137117
Trained batch 86 in epoch 1, gen_loss = 1.0044360462276416, disc_loss = 0.003679430852215951
Trained batch 87 in epoch 1, gen_loss = 1.004537495699796, disc_loss = 0.003662928130572916
Trained batch 88 in epoch 1, gen_loss = 1.0044040653143036, disc_loss = 0.0036449352438886013
Trained batch 89 in epoch 1, gen_loss = 1.0042945331997342, disc_loss = 0.0036279686170423197
Trained batch 90 in epoch 1, gen_loss = 1.0040581265648643, disc_loss = 0.0036178696069068144
Trained batch 91 in epoch 1, gen_loss = 1.0041341561338175, disc_loss = 0.003613385547752209
Trained batch 92 in epoch 1, gen_loss = 1.0038873316139303, disc_loss = 0.0036188119419059287
Trained batch 93 in epoch 1, gen_loss = 1.0037759517101532, disc_loss = 0.0036248795011952677
Trained batch 94 in epoch 1, gen_loss = 1.0033538241135447, disc_loss = 0.00363273975856014
Trained batch 95 in epoch 1, gen_loss = 1.003441710025072, disc_loss = 0.0036491715230416353
Trained batch 96 in epoch 1, gen_loss = 1.0038417700639706, disc_loss = 0.003667220140845736
Trained batch 97 in epoch 1, gen_loss = 1.0038435422644323, disc_loss = 0.0036770653880049227
Trained batch 98 in epoch 1, gen_loss = 1.0043577846854623, disc_loss = 0.00368173201121578
Trained batch 99 in epoch 1, gen_loss = 1.004417086839676, disc_loss = 0.0036758677999023347
Trained batch 100 in epoch 1, gen_loss = 1.0045702799712077, disc_loss = 0.0036672785945033822
Trained batch 101 in epoch 1, gen_loss = 1.0047254714311338, disc_loss = 0.0036572018083568443
Trained batch 102 in epoch 1, gen_loss = 1.0051234543902203, disc_loss = 0.003648304969334559
Trained batch 103 in epoch 1, gen_loss = 1.005087706905145, disc_loss = 0.003637098359132114
Trained batch 104 in epoch 1, gen_loss = 1.004715314933232, disc_loss = 0.0036247842734502185
Trained batch 105 in epoch 1, gen_loss = 1.0045997809689, disc_loss = 0.0036143448724376285
Trained batch 106 in epoch 1, gen_loss = 1.0044791436641016, disc_loss = 0.003604636232751622
Trained batch 107 in epoch 1, gen_loss = 1.0043642366373982, disc_loss = 0.0035904394473483853
Trained batch 108 in epoch 1, gen_loss = 1.0047078821637214, disc_loss = 0.003577712390341138
Trained batch 109 in epoch 1, gen_loss = 1.004712112383409, disc_loss = 0.0035656398109329694
Trained batch 110 in epoch 1, gen_loss = 1.0048632847296226, disc_loss = 0.00355065787769015
Trained batch 111 in epoch 1, gen_loss = 1.0046578996947833, disc_loss = 0.0035335031207068823
Trained batch 112 in epoch 1, gen_loss = 1.0044635170328933, disc_loss = 0.0035160936835526894
Trained batch 113 in epoch 1, gen_loss = 1.0045151318374432, disc_loss = 0.003501932612587616
Trained batch 114 in epoch 1, gen_loss = 1.0042192832283352, disc_loss = 0.003489303765008631
Trained batch 115 in epoch 1, gen_loss = 1.0046858438130082, disc_loss = 0.003479860674846789
Trained batch 116 in epoch 1, gen_loss = 1.004685340783535, disc_loss = 0.003469459646835159
Trained batch 117 in epoch 1, gen_loss = 1.0051948640306116, disc_loss = 0.003462602855969157
Trained batch 118 in epoch 1, gen_loss = 1.005294419136368, disc_loss = 0.003459106103571899
Trained batch 119 in epoch 1, gen_loss = 1.005263658364614, disc_loss = 0.0034561431772696474
Trained batch 120 in epoch 1, gen_loss = 1.005646839614742, disc_loss = 0.0034602784921130367
Trained batch 121 in epoch 1, gen_loss = 1.0050618453103988, disc_loss = 0.003450179453481172
Trained batch 122 in epoch 1, gen_loss = 1.0056683794269716, disc_loss = 0.0034557269409117176
Trained batch 123 in epoch 1, gen_loss = 1.0059304516161642, disc_loss = 0.003491722621894892
Trained batch 124 in epoch 1, gen_loss = 1.005684287071228, disc_loss = 0.0035440778620541096
Trained batch 125 in epoch 1, gen_loss = 1.005642040381356, disc_loss = 0.003593549697792956
Trained batch 126 in epoch 1, gen_loss = 1.005439127524068, disc_loss = 0.0036177025139918478
Trained batch 127 in epoch 1, gen_loss = 1.0054212603718042, disc_loss = 0.0036182798958179774
Trained batch 128 in epoch 1, gen_loss = 1.0053160292233607, disc_loss = 0.0036081391108734894
Trained batch 129 in epoch 1, gen_loss = 1.0050756064745097, disc_loss = 0.0035970647604419634
Trained batch 130 in epoch 1, gen_loss = 1.0045557117644157, disc_loss = 0.0035848331189792574
Trained batch 131 in epoch 1, gen_loss = 1.0044603090394626, disc_loss = 0.003577231773471629
Trained batch 132 in epoch 1, gen_loss = 1.004314856869834, disc_loss = 0.0035704413176815314
Trained batch 133 in epoch 1, gen_loss = 1.0043445171704932, disc_loss = 0.0035600108407270997
Trained batch 134 in epoch 1, gen_loss = 1.004068609961757, disc_loss = 0.003545592169932745
Trained batch 135 in epoch 1, gen_loss = 1.0040174705140732, disc_loss = 0.0035328295129789587
Trained batch 136 in epoch 1, gen_loss = 1.0037590526316287, disc_loss = 0.0035232516229968436
Trained batch 137 in epoch 1, gen_loss = 1.0038112695666328, disc_loss = 0.003516986242333508
Trained batch 138 in epoch 1, gen_loss = 1.0038148447764006, disc_loss = 0.003513397524977545
Trained batch 139 in epoch 1, gen_loss = 1.0040397831371852, disc_loss = 0.003512285283899733
Trained batch 140 in epoch 1, gen_loss = 1.003952497286154, disc_loss = 0.003509289353874558
Trained batch 141 in epoch 1, gen_loss = 1.0040384833241853, disc_loss = 0.003508130598380427
Trained batch 142 in epoch 1, gen_loss = 1.0038727963721001, disc_loss = 0.003502554808893091
Trained batch 143 in epoch 1, gen_loss = 1.0039354430304632, disc_loss = 0.0034980806020838725
Trained batch 144 in epoch 1, gen_loss = 1.0040822448401616, disc_loss = 0.0034945771210537903
Trained batch 145 in epoch 1, gen_loss = 1.0042027096225792, disc_loss = 0.003487974920386627
Trained batch 146 in epoch 1, gen_loss = 1.0041536457684574, disc_loss = 0.003478894157487215
Trained batch 147 in epoch 1, gen_loss = 1.0041437712875572, disc_loss = 0.003473099341578278
Trained batch 148 in epoch 1, gen_loss = 1.0044255448667796, disc_loss = 0.003471065804849835
Trained batch 149 in epoch 1, gen_loss = 1.0042510271072387, disc_loss = 0.0034694222500547766
Trained batch 150 in epoch 1, gen_loss = 1.0040277487394826, disc_loss = 0.003461933811966157
Trained batch 151 in epoch 1, gen_loss = 1.003961647419553, disc_loss = 0.0034490706794282518
Trained batch 152 in epoch 1, gen_loss = 1.0043111342230653, disc_loss = 0.0034398905525069223
Trained batch 153 in epoch 1, gen_loss = 1.0040551396933468, disc_loss = 0.003427810312321337
Trained batch 154 in epoch 1, gen_loss = 1.0043931703413687, disc_loss = 0.0034231556939982597
Trained batch 155 in epoch 1, gen_loss = 1.0041286719915195, disc_loss = 0.0034230156825521053
Trained batch 156 in epoch 1, gen_loss = 1.0041662815270151, disc_loss = 0.003421172650922446
Trained batch 157 in epoch 1, gen_loss = 1.003867566208296, disc_loss = 0.003413559537369145
Trained batch 158 in epoch 1, gen_loss = 1.0037684354392238, disc_loss = 0.0034030748329142916
Trained batch 159 in epoch 1, gen_loss = 1.0035401225090026, disc_loss = 0.003392951770365471
Trained batch 160 in epoch 1, gen_loss = 1.0036918798588819, disc_loss = 0.0033868756615238623
Trained batch 161 in epoch 1, gen_loss = 1.003404199709127, disc_loss = 0.0033818484020971314
Trained batch 162 in epoch 1, gen_loss = 1.0030673855652839, disc_loss = 0.003374481455857174
Trained batch 163 in epoch 1, gen_loss = 1.0031148874905051, disc_loss = 0.003368678990405098
Trained batch 164 in epoch 1, gen_loss = 1.003059327241146, disc_loss = 0.0033603442628218822
Trained batch 165 in epoch 1, gen_loss = 1.003041208508503, disc_loss = 0.0033530261590571917
Trained batch 166 in epoch 1, gen_loss = 1.0026907128488232, disc_loss = 0.0033449277018258224
Trained batch 167 in epoch 1, gen_loss = 1.0027921107553301, disc_loss = 0.0033380241858096617
Trained batch 168 in epoch 1, gen_loss = 1.0026948427307536, disc_loss = 0.003332507264106011
Trained batch 169 in epoch 1, gen_loss = 1.0026031785151537, disc_loss = 0.00332647019326139
Trained batch 170 in epoch 1, gen_loss = 1.0025041716837744, disc_loss = 0.0033193179889587543
Trained batch 171 in epoch 1, gen_loss = 1.0025487514429314, disc_loss = 0.0033105387295552986
Trained batch 172 in epoch 1, gen_loss = 1.0025128112362989, disc_loss = 0.003300380208018112
Trained batch 173 in epoch 1, gen_loss = 1.0024830726371414, disc_loss = 0.003290520763511759
Trained batch 174 in epoch 1, gen_loss = 1.0024569385392326, disc_loss = 0.0032807338264371666
Trained batch 175 in epoch 1, gen_loss = 1.0024500851604072, disc_loss = 0.0032697237938092176
Trained batch 176 in epoch 1, gen_loss = 1.0023997372153115, disc_loss = 0.0032584388881111465
Trained batch 177 in epoch 1, gen_loss = 1.0023962530527222, disc_loss = 0.0032473132367444673
Trained batch 178 in epoch 1, gen_loss = 1.0024658484831868, disc_loss = 0.003236490915732344
Trained batch 179 in epoch 1, gen_loss = 1.0023853139744865, disc_loss = 0.0032256605051871803
Trained batch 180 in epoch 1, gen_loss = 1.0021956342359932, disc_loss = 0.0032169169113451606
Trained batch 181 in epoch 1, gen_loss = 1.0021130940416356, disc_loss = 0.00320851950967623
Trained batch 182 in epoch 1, gen_loss = 1.0019219745703734, disc_loss = 0.0031978733566604923
Trained batch 183 in epoch 1, gen_loss = 1.001751669075178, disc_loss = 0.0031866222757937226
Trained batch 184 in epoch 1, gen_loss = 1.0017165712408118, disc_loss = 0.0031764239267874006
Trained batch 185 in epoch 1, gen_loss = 1.001613183367637, disc_loss = 0.0031670969397690828
Trained batch 186 in epoch 1, gen_loss = 1.0013166917836602, disc_loss = 0.00315826915249348
Trained batch 187 in epoch 1, gen_loss = 1.0012393260889865, disc_loss = 0.0031505283104513396
Trained batch 188 in epoch 1, gen_loss = 1.00129561417948, disc_loss = 0.003142812365059933
Trained batch 189 in epoch 1, gen_loss = 1.001350287073537, disc_loss = 0.0031378967546563793
Trained batch 190 in epoch 1, gen_loss = 1.0011124442385129, disc_loss = 0.0031368457791468626
Trained batch 191 in epoch 1, gen_loss = 1.0012690195192893, disc_loss = 0.003138719162355604
Trained batch 192 in epoch 1, gen_loss = 1.0009570967965793, disc_loss = 0.0031399345719086615
Trained batch 193 in epoch 1, gen_loss = 1.0011054136089443, disc_loss = 0.00314328619747029
Trained batch 194 in epoch 1, gen_loss = 1.001162269176581, disc_loss = 0.003150206660398115
Trained batch 195 in epoch 1, gen_loss = 1.0013143699996325, disc_loss = 0.0031596474766455666
Trained batch 196 in epoch 1, gen_loss = 1.0012363053215336, disc_loss = 0.003170849676811264
Trained batch 197 in epoch 1, gen_loss = 1.0012943332243447, disc_loss = 0.003180489223332831
Trained batch 198 in epoch 1, gen_loss = 1.0011459148708899, disc_loss = 0.003185248902727424
Trained batch 199 in epoch 1, gen_loss = 1.0012023124098777, disc_loss = 0.0031824575114296747
Trained batch 200 in epoch 1, gen_loss = 1.0013934940247986, disc_loss = 0.0031757689913994268
Trained batch 201 in epoch 1, gen_loss = 1.0014096359805305, disc_loss = 0.0031671858983953476
Trained batch 202 in epoch 1, gen_loss = 1.0013845254634988, disc_loss = 0.0031614425262950106
Trained batch 203 in epoch 1, gen_loss = 1.0011869309579624, disc_loss = 0.0031580265968645395
Trained batch 204 in epoch 1, gen_loss = 1.0013387624810381, disc_loss = 0.003156311358552335
Trained batch 205 in epoch 1, gen_loss = 1.0013722085837022, disc_loss = 0.003151355617006029
Trained batch 206 in epoch 1, gen_loss = 1.0014279438677618, disc_loss = 0.00314852642401567
Trained batch 207 in epoch 1, gen_loss = 1.0013361825392797, disc_loss = 0.0031500053026740295
Trained batch 208 in epoch 1, gen_loss = 1.001279809258201, disc_loss = 0.0031567442038154415
Trained batch 209 in epoch 1, gen_loss = 1.0011323962892804, disc_loss = 0.0031641374669215154
Trained batch 210 in epoch 1, gen_loss = 1.001062273414214, disc_loss = 0.0031680494091160137
Trained batch 211 in epoch 1, gen_loss = 1.0009493102442544, disc_loss = 0.003164955651506184
Trained batch 212 in epoch 1, gen_loss = 1.001000999285022, disc_loss = 0.0031587403478590607
Trained batch 213 in epoch 1, gen_loss = 1.0012380625600013, disc_loss = 0.0031517984244371893
Trained batch 214 in epoch 1, gen_loss = 1.001158238288968, disc_loss = 0.0031430758275957996
Trained batch 215 in epoch 1, gen_loss = 1.0011567757637412, disc_loss = 0.003138675698277506
Trained batch 216 in epoch 1, gen_loss = 1.0009354839127185, disc_loss = 0.0031407754750244214
Trained batch 217 in epoch 1, gen_loss = 1.00080713082891, disc_loss = 0.0031445285320333247
Trained batch 218 in epoch 1, gen_loss = 1.0005459948761823, disc_loss = 0.003146180348283692
Trained batch 219 in epoch 1, gen_loss = 1.0006209351799704, disc_loss = 0.0031488357810303567
Trained batch 220 in epoch 1, gen_loss = 1.000727281850927, disc_loss = 0.0031503349957709534
Trained batch 221 in epoch 1, gen_loss = 1.0005523492624093, disc_loss = 0.0031469202871006485
Trained batch 222 in epoch 1, gen_loss = 1.0004940329645782, disc_loss = 0.003140299099668727
Trained batch 223 in epoch 1, gen_loss = 1.0004688009087528, disc_loss = 0.0031320199019059408
Trained batch 224 in epoch 1, gen_loss = 1.0005472773975796, disc_loss = 0.0031235422090523774
Trained batch 225 in epoch 1, gen_loss = 1.000597974104164, disc_loss = 0.0031148975336948923
Trained batch 226 in epoch 1, gen_loss = 1.000596925288045, disc_loss = 0.003106398647445939
Trained batch 227 in epoch 1, gen_loss = 1.0005257053856265, disc_loss = 0.0030988672969805633
Trained batch 228 in epoch 1, gen_loss = 1.000527583095184, disc_loss = 0.003093474857228519
Trained batch 229 in epoch 1, gen_loss = 1.0003279906252156, disc_loss = 0.0030899970787172408
Trained batch 230 in epoch 1, gen_loss = 1.0002127883238194, disc_loss = 0.003087066713160154
Trained batch 231 in epoch 1, gen_loss = 1.0002365798271935, disc_loss = 0.003083286233394856
Trained batch 232 in epoch 1, gen_loss = 1.0002785422259646, disc_loss = 0.0030787044825320146
Trained batch 233 in epoch 1, gen_loss = 1.0001777751832945, disc_loss = 0.0030737439818226565
Trained batch 234 in epoch 1, gen_loss = 1.0002600015477932, disc_loss = 0.003069445904483028
Trained batch 235 in epoch 1, gen_loss = 1.0002555329415759, disc_loss = 0.00306389790760369
Trained batch 236 in epoch 1, gen_loss = 1.0002144089730982, disc_loss = 0.0030571494781007433
Trained batch 237 in epoch 1, gen_loss = 1.000099507950935, disc_loss = 0.003048746779604087
Trained batch 238 in epoch 1, gen_loss = 0.9998944581303137, disc_loss = 0.003040306108894614
Trained batch 239 in epoch 1, gen_loss = 0.999816449979941, disc_loss = 0.003031985587828482
Trained batch 240 in epoch 1, gen_loss = 0.9997842277234026, disc_loss = 0.003023945583954175
Trained batch 241 in epoch 1, gen_loss = 0.9997974126792151, disc_loss = 0.003016590111415587
Trained batch 242 in epoch 1, gen_loss = 0.9998837155079154, disc_loss = 0.0030104906596205056
Trained batch 243 in epoch 1, gen_loss = 0.9999234373452234, disc_loss = 0.0030048072660631944
Trained batch 244 in epoch 1, gen_loss = 0.9998101959423144, disc_loss = 0.0029986252613859823
Trained batch 245 in epoch 1, gen_loss = 0.9997164388982261, disc_loss = 0.0029919041946295617
Trained batch 246 in epoch 1, gen_loss = 0.9996251060895109, disc_loss = 0.0029848324199044994
Trained batch 247 in epoch 1, gen_loss = 0.9994900286678345, disc_loss = 0.002977852840089209
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.9827641844749451, disc_loss = 0.0009830924682319164
Trained batch 1 in epoch 2, gen_loss = 0.9856882989406586, disc_loss = 0.0009700442606117576
Trained batch 2 in epoch 2, gen_loss = 0.9822981158892313, disc_loss = 0.0010363892070017755
Trained batch 3 in epoch 2, gen_loss = 0.9907145649194717, disc_loss = 0.0011658101720968261
Trained batch 4 in epoch 2, gen_loss = 0.9925653219223023, disc_loss = 0.0011864515603519977
Trained batch 5 in epoch 2, gen_loss = 0.993165006240209, disc_loss = 0.0012033519354493667
Trained batch 6 in epoch 2, gen_loss = 0.9916568228176662, disc_loss = 0.0012144390077862357
Trained batch 7 in epoch 2, gen_loss = 0.9910550564527512, disc_loss = 0.0012031251317239366
Trained batch 8 in epoch 2, gen_loss = 0.9922696749369303, disc_loss = 0.0012361251994863981
Trained batch 9 in epoch 2, gen_loss = 0.9925127029418945, disc_loss = 0.0012915177794639021
Trained batch 10 in epoch 2, gen_loss = 0.9956611069765958, disc_loss = 0.00133722623154013
Trained batch 11 in epoch 2, gen_loss = 0.9951592882474264, disc_loss = 0.0013614887575386092
Trained batch 12 in epoch 2, gen_loss = 0.9982179128206693, disc_loss = 0.0014022742263757838
Trained batch 13 in epoch 2, gen_loss = 0.9966709400926318, disc_loss = 0.0014000541954633913
Trained batch 14 in epoch 2, gen_loss = 0.9955692251523336, disc_loss = 0.0013886951026506722
Trained batch 15 in epoch 2, gen_loss = 0.994840431958437, disc_loss = 0.0013675069603777956
Trained batch 16 in epoch 2, gen_loss = 0.9968284964561462, disc_loss = 0.0013449339791858459
Trained batch 17 in epoch 2, gen_loss = 0.9967690474457211, disc_loss = 0.0013281904814195717
Trained batch 18 in epoch 2, gen_loss = 0.9960228392952367, disc_loss = 0.0013272027932352533
Trained batch 19 in epoch 2, gen_loss = 0.9950783014297485, disc_loss = 0.0013249996554804966
Trained batch 20 in epoch 2, gen_loss = 0.9948044986951918, disc_loss = 0.00132079775877563
Trained batch 21 in epoch 2, gen_loss = 0.9954248585484244, disc_loss = 0.0013178307060363957
Trained batch 22 in epoch 2, gen_loss = 0.9946275508922079, disc_loss = 0.001324358813808826
Trained batch 23 in epoch 2, gen_loss = 0.9939810658494631, disc_loss = 0.0013460827443244245
Trained batch 24 in epoch 2, gen_loss = 0.9943133950233459, disc_loss = 0.0013895747321657837
Trained batch 25 in epoch 2, gen_loss = 0.9940452461059277, disc_loss = 0.001429663297200862
Trained batch 26 in epoch 2, gen_loss = 0.994390692975786, disc_loss = 0.0014618652920169687
Trained batch 27 in epoch 2, gen_loss = 0.9956686475447246, disc_loss = 0.0014880227951964895
Trained batch 28 in epoch 2, gen_loss = 0.9967678394810907, disc_loss = 0.0014930941015963667
Trained batch 29 in epoch 2, gen_loss = 0.9963118672370911, disc_loss = 0.0015042583749163897
Trained batch 30 in epoch 2, gen_loss = 0.997748855621584, disc_loss = 0.0015427995033772482
Trained batch 31 in epoch 2, gen_loss = 0.9968164190649986, disc_loss = 0.0015936084218992619
Trained batch 32 in epoch 2, gen_loss = 0.9942831993103027, disc_loss = 0.0016736849052408202
Trained batch 33 in epoch 2, gen_loss = 0.9945632008945241, disc_loss = 0.0017565136265201384
Trained batch 34 in epoch 2, gen_loss = 0.994337112562997, disc_loss = 0.0018214228147241686
Trained batch 35 in epoch 2, gen_loss = 0.9941449264685313, disc_loss = 0.0018686434600062461
Trained batch 36 in epoch 2, gen_loss = 0.993548343310485, disc_loss = 0.0018982109031639993
Trained batch 37 in epoch 2, gen_loss = 0.992223239258716, disc_loss = 0.0019407591301531188
Trained batch 38 in epoch 2, gen_loss = 0.9910825338119116, disc_loss = 0.0019886134093842255
Trained batch 39 in epoch 2, gen_loss = 0.9900901302695274, disc_loss = 0.002026713096711319
Trained batch 40 in epoch 2, gen_loss = 0.990688104455064, disc_loss = 0.0020534241296600825
Trained batch 41 in epoch 2, gen_loss = 0.9909105996290842, disc_loss = 0.002065199226351632
Trained batch 42 in epoch 2, gen_loss = 0.9904112372287485, disc_loss = 0.0020633048775909077
Trained batch 43 in epoch 2, gen_loss = 0.9897889278151772, disc_loss = 0.0020497248029145835
Trained batch 44 in epoch 2, gen_loss = 0.9904422521591186, disc_loss = 0.0020388637630579373
Trained batch 45 in epoch 2, gen_loss = 0.9911544685778411, disc_loss = 0.0020220309518702816
Trained batch 46 in epoch 2, gen_loss = 0.9912779229752561, disc_loss = 0.0020021939330655053
Trained batch 47 in epoch 2, gen_loss = 0.9914604624112447, disc_loss = 0.0019877020519440216
Trained batch 48 in epoch 2, gen_loss = 0.9908051198842575, disc_loss = 0.0019825007635814957
Trained batch 49 in epoch 2, gen_loss = 0.9910120749473572, disc_loss = 0.0019881947396788746
Trained batch 50 in epoch 2, gen_loss = 0.990598063842923, disc_loss = 0.00199282274001698
Trained batch 51 in epoch 2, gen_loss = 0.990111761368238, disc_loss = 0.001996000688030528
Trained batch 52 in epoch 2, gen_loss = 0.9906722892005488, disc_loss = 0.0020028715920283125
Trained batch 53 in epoch 2, gen_loss = 0.9904464030707324, disc_loss = 0.002002799345602937
Trained batch 54 in epoch 2, gen_loss = 0.9910453677177429, disc_loss = 0.001993790581102737
Trained batch 55 in epoch 2, gen_loss = 0.9910703535590853, disc_loss = 0.0019785081957317224
Trained batch 56 in epoch 2, gen_loss = 0.9917128357970924, disc_loss = 0.0019644121629218653
Trained batch 57 in epoch 2, gen_loss = 0.9910065120664137, disc_loss = 0.0019627592600641192
Trained batch 58 in epoch 2, gen_loss = 0.9912649453696558, disc_loss = 0.001975806071857085
Trained batch 59 in epoch 2, gen_loss = 0.9907002339760462, disc_loss = 0.001984865634585731
Trained batch 60 in epoch 2, gen_loss = 0.9905481084448392, disc_loss = 0.001986881444177239
Trained batch 61 in epoch 2, gen_loss = 0.9901812653387746, disc_loss = 0.0019807595198207927
Trained batch 62 in epoch 2, gen_loss = 0.9894967580598498, disc_loss = 0.0019750497239227924
Trained batch 63 in epoch 2, gen_loss = 0.9890314200893044, disc_loss = 0.001967045010133006
Trained batch 64 in epoch 2, gen_loss = 0.9887829468800471, disc_loss = 0.001965645153541118
Trained batch 65 in epoch 2, gen_loss = 0.9884403212503954, disc_loss = 0.001960905297892168
Trained batch 66 in epoch 2, gen_loss = 0.9881330310408749, disc_loss = 0.0019507259451923198
Trained batch 67 in epoch 2, gen_loss = 0.987194737090784, disc_loss = 0.0019382944489788154
Trained batch 68 in epoch 2, gen_loss = 0.9877152261526688, disc_loss = 0.0019286843700050983
Trained batch 69 in epoch 2, gen_loss = 0.9884622531277792, disc_loss = 0.0019250567195870515
Trained batch 70 in epoch 2, gen_loss = 0.9883461241990747, disc_loss = 0.0019178717949716244
Trained batch 71 in epoch 2, gen_loss = 0.9888227722711034, disc_loss = 0.0019177711971375782
Trained batch 72 in epoch 2, gen_loss = 0.9892034571464747, disc_loss = 0.001910809005693571
Trained batch 73 in epoch 2, gen_loss = 0.9889861490275409, disc_loss = 0.0018973301355160671
Trained batch 74 in epoch 2, gen_loss = 0.9889819669723511, disc_loss = 0.001885915210004896
Trained batch 75 in epoch 2, gen_loss = 0.9892145630560423, disc_loss = 0.001876819136668928
Trained batch 76 in epoch 2, gen_loss = 0.9897898900044428, disc_loss = 0.0018718669670271118
Trained batch 77 in epoch 2, gen_loss = 0.9897149403889974, disc_loss = 0.0018692034533999574
Trained batch 78 in epoch 2, gen_loss = 0.9891526563258111, disc_loss = 0.0018649417207034045
Trained batch 79 in epoch 2, gen_loss = 0.9891437739133835, disc_loss = 0.0018556484435976017
Trained batch 80 in epoch 2, gen_loss = 0.9889740826171122, disc_loss = 0.0018465765069215845
Trained batch 81 in epoch 2, gen_loss = 0.9886751465681123, disc_loss = 0.0018365584780950463
Trained batch 82 in epoch 2, gen_loss = 0.9884550815605255, disc_loss = 0.00183159527747544
Trained batch 83 in epoch 2, gen_loss = 0.9882728081373942, disc_loss = 0.001831847658087056
Trained batch 84 in epoch 2, gen_loss = 0.9885468153392567, disc_loss = 0.0018269490019199165
Trained batch 85 in epoch 2, gen_loss = 0.9885606786539388, disc_loss = 0.001817590425056297
Trained batch 86 in epoch 2, gen_loss = 0.9883505236143353, disc_loss = 0.0018102965637474139
Trained batch 87 in epoch 2, gen_loss = 0.9883523549545895, disc_loss = 0.0018006465245641514
Trained batch 88 in epoch 2, gen_loss = 0.9881391351142627, disc_loss = 0.0017921230736125805
Trained batch 89 in epoch 2, gen_loss = 0.9882036328315735, disc_loss = 0.0017857336186959097
Trained batch 90 in epoch 2, gen_loss = 0.988516934625395, disc_loss = 0.001781601236831233
Trained batch 91 in epoch 2, gen_loss = 0.9883798250685567, disc_loss = 0.001778468616817997
Trained batch 92 in epoch 2, gen_loss = 0.9883411699725736, disc_loss = 0.0017774575834302731
Trained batch 93 in epoch 2, gen_loss = 0.9886072988205767, disc_loss = 0.001773798542884872
Trained batch 94 in epoch 2, gen_loss = 0.9889006602136712, disc_loss = 0.0017694702231031106
Trained batch 95 in epoch 2, gen_loss = 0.9888456022987763, disc_loss = 0.0017646760540325583
Trained batch 96 in epoch 2, gen_loss = 0.9885383819796375, disc_loss = 0.001759884077887598
Trained batch 97 in epoch 2, gen_loss = 0.9884925241373024, disc_loss = 0.0017579895870674554
Trained batch 98 in epoch 2, gen_loss = 0.9884336410146771, disc_loss = 0.0017553915491920304
Trained batch 99 in epoch 2, gen_loss = 0.9887567716836929, disc_loss = 0.0017524365201825277
Trained batch 100 in epoch 2, gen_loss = 0.9888305870613249, disc_loss = 0.001747953390246165
Trained batch 101 in epoch 2, gen_loss = 0.9887578049126793, disc_loss = 0.0017433727174933416
Trained batch 102 in epoch 2, gen_loss = 0.9885381442829243, disc_loss = 0.0017387253097801026
Trained batch 103 in epoch 2, gen_loss = 0.9882971237485225, disc_loss = 0.0017333686997657283
Trained batch 104 in epoch 2, gen_loss = 0.9883716781934102, disc_loss = 0.0017316885885693843
Trained batch 105 in epoch 2, gen_loss = 0.9879386475626027, disc_loss = 0.001738245807091688
Trained batch 106 in epoch 2, gen_loss = 0.9880348666806087, disc_loss = 0.0017459972116391166
Trained batch 107 in epoch 2, gen_loss = 0.988162851995892, disc_loss = 0.0017481343836859902
Trained batch 108 in epoch 2, gen_loss = 0.98763139969712, disc_loss = 0.0017467855637115553
Trained batch 109 in epoch 2, gen_loss = 0.9875158163634213, disc_loss = 0.001747246597237377
Trained batch 110 in epoch 2, gen_loss = 0.9877316720850833, disc_loss = 0.0017440859065810637
Trained batch 111 in epoch 2, gen_loss = 0.9879552386701107, disc_loss = 0.001741190882187636
Trained batch 112 in epoch 2, gen_loss = 0.9878226043903722, disc_loss = 0.0017373214019421256
Trained batch 113 in epoch 2, gen_loss = 0.9875750180922056, disc_loss = 0.001734074186268181
Trained batch 114 in epoch 2, gen_loss = 0.9876944205035334, disc_loss = 0.0017301647443040882
Trained batch 115 in epoch 2, gen_loss = 0.98753322660923, disc_loss = 0.0017244745480450641
Trained batch 116 in epoch 2, gen_loss = 0.9874553644759023, disc_loss = 0.0017188374200859703
Trained batch 117 in epoch 2, gen_loss = 0.9871464295912598, disc_loss = 0.001714838085147568
Trained batch 118 in epoch 2, gen_loss = 0.9871540375116492, disc_loss = 0.0017131237521525002
Trained batch 119 in epoch 2, gen_loss = 0.9873876705765724, disc_loss = 0.0017106122613768093
Trained batch 120 in epoch 2, gen_loss = 0.9878888302598118, disc_loss = 0.0017098435397983399
Trained batch 121 in epoch 2, gen_loss = 0.9876357365827091, disc_loss = 0.001714440788329411
Trained batch 122 in epoch 2, gen_loss = 0.9877417698139097, disc_loss = 0.0017269707338816327
Trained batch 123 in epoch 2, gen_loss = 0.98827711516811, disc_loss = 0.0017350716971709663
Trained batch 124 in epoch 2, gen_loss = 0.98805704164505, disc_loss = 0.0017416958906687795
Trained batch 125 in epoch 2, gen_loss = 0.9876264470910269, disc_loss = 0.0017513316443433897
Trained batch 126 in epoch 2, gen_loss = 0.9875404121368889, disc_loss = 0.0017567147270732331
Trained batch 127 in epoch 2, gen_loss = 0.9878125805407763, disc_loss = 0.0017612965007174353
Trained batch 128 in epoch 2, gen_loss = 0.9876840276311535, disc_loss = 0.0017664069657271743
Trained batch 129 in epoch 2, gen_loss = 0.9879814051664793, disc_loss = 0.0017741042910179553
Trained batch 130 in epoch 2, gen_loss = 0.9876188644926056, disc_loss = 0.0017859974066470928
Trained batch 131 in epoch 2, gen_loss = 0.9878433549946005, disc_loss = 0.0018028886446369472
Trained batch 132 in epoch 2, gen_loss = 0.98770364782864, disc_loss = 0.0018171715165866552
Trained batch 133 in epoch 2, gen_loss = 0.9879563842246781, disc_loss = 0.0018324664634923491
Trained batch 134 in epoch 2, gen_loss = 0.9879970908164978, disc_loss = 0.0018512499298796886
Trained batch 135 in epoch 2, gen_loss = 0.9882456068606937, disc_loss = 0.001874533018374624
Trained batch 136 in epoch 2, gen_loss = 0.9885415025871166, disc_loss = 0.001894256479470535
Trained batch 137 in epoch 2, gen_loss = 0.9884557469167571, disc_loss = 0.0019071278861636106
Trained batch 138 in epoch 2, gen_loss = 0.9884040724459312, disc_loss = 0.0019119787620373821
Trained batch 139 in epoch 2, gen_loss = 0.9887525464807237, disc_loss = 0.0019116231086497594
Trained batch 140 in epoch 2, gen_loss = 0.9887492589071287, disc_loss = 0.0019077923432065187
Trained batch 141 in epoch 2, gen_loss = 0.9887236205624862, disc_loss = 0.001903184525206239
Trained batch 142 in epoch 2, gen_loss = 0.9885656658586088, disc_loss = 0.0018980028844516647
Trained batch 143 in epoch 2, gen_loss = 0.9883481471074952, disc_loss = 0.0018957144174136273
Trained batch 144 in epoch 2, gen_loss = 0.9883753636787678, disc_loss = 0.0018941195091585917
Trained batch 145 in epoch 2, gen_loss = 0.988281296540613, disc_loss = 0.001891121267076352
Trained batch 146 in epoch 2, gen_loss = 0.988477187902749, disc_loss = 0.0018867451216879802
Trained batch 147 in epoch 2, gen_loss = 0.9882431839768951, disc_loss = 0.0018844843005943993
Trained batch 148 in epoch 2, gen_loss = 0.9883383140467957, disc_loss = 0.001881589019599202
Trained batch 149 in epoch 2, gen_loss = 0.9880705571174622, disc_loss = 0.0018784911274754752
Trained batch 150 in epoch 2, gen_loss = 0.9879222583297073, disc_loss = 0.001877129885494487
Trained batch 151 in epoch 2, gen_loss = 0.9878168004123788, disc_loss = 0.001876660362636597
Trained batch 152 in epoch 2, gen_loss = 0.9878586557955523, disc_loss = 0.001877047773983232
Trained batch 153 in epoch 2, gen_loss = 0.9881578409052515, disc_loss = 0.0018764235651537824
Trained batch 154 in epoch 2, gen_loss = 0.9878941124485385, disc_loss = 0.0018791924024211062
Trained batch 155 in epoch 2, gen_loss = 0.9882427136867474, disc_loss = 0.0018884652739731022
Trained batch 156 in epoch 2, gen_loss = 0.9885526770239423, disc_loss = 0.0019054275015695317
Trained batch 157 in epoch 2, gen_loss = 0.9885676137254208, disc_loss = 0.0019196947167857397
Trained batch 158 in epoch 2, gen_loss = 0.9886856262788832, disc_loss = 0.0019251049496965635
Trained batch 159 in epoch 2, gen_loss = 0.9884893015027046, disc_loss = 0.0019234049072110793
Trained batch 160 in epoch 2, gen_loss = 0.9884988469366701, disc_loss = 0.0019187117483530495
Trained batch 161 in epoch 2, gen_loss = 0.9888660230754335, disc_loss = 0.0019132711275704896
Trained batch 162 in epoch 2, gen_loss = 0.988938047842014, disc_loss = 0.0019073026526885027
Trained batch 163 in epoch 2, gen_loss = 0.9890910852246169, disc_loss = 0.0019017051165020548
Trained batch 164 in epoch 2, gen_loss = 0.989251211195281, disc_loss = 0.0018974704939561586
Trained batch 165 in epoch 2, gen_loss = 0.989107046500746, disc_loss = 0.0018948613962646663
Trained batch 166 in epoch 2, gen_loss = 0.9891825043512675, disc_loss = 0.001896134923103483
Trained batch 167 in epoch 2, gen_loss = 0.9891196844123659, disc_loss = 0.0018988306841319648
Trained batch 168 in epoch 2, gen_loss = 0.9892078955497967, disc_loss = 0.001900425968490563
Trained batch 169 in epoch 2, gen_loss = 0.9891045773730559, disc_loss = 0.001900592477485428
Trained batch 170 in epoch 2, gen_loss = 0.9891637671760648, disc_loss = 0.0018987268980794004
Trained batch 171 in epoch 2, gen_loss = 0.9891572563454162, disc_loss = 0.0018947649998238398
Trained batch 172 in epoch 2, gen_loss = 0.9893195598111676, disc_loss = 0.001890361540199855
Trained batch 173 in epoch 2, gen_loss = 0.9893736479611233, disc_loss = 0.0018852128879429408
Trained batch 174 in epoch 2, gen_loss = 0.9892098552840096, disc_loss = 0.0018787567719950207
Trained batch 175 in epoch 2, gen_loss = 0.9889587038619951, disc_loss = 0.001871534938717642
Trained batch 176 in epoch 2, gen_loss = 0.9887533056533943, disc_loss = 0.0018642643521839784
Trained batch 177 in epoch 2, gen_loss = 0.9885716605722235, disc_loss = 0.0018578036024439243
Trained batch 178 in epoch 2, gen_loss = 0.9885221939513137, disc_loss = 0.0018510330915867284
Trained batch 179 in epoch 2, gen_loss = 0.9883903808063931, disc_loss = 0.001845033873946199
Trained batch 180 in epoch 2, gen_loss = 0.9886427228622015, disc_loss = 0.0018398609926965272
Trained batch 181 in epoch 2, gen_loss = 0.9886825333584796, disc_loss = 0.0018358637967689352
Trained batch 182 in epoch 2, gen_loss = 0.988720956395884, disc_loss = 0.001834398172439529
Trained batch 183 in epoch 2, gen_loss = 0.9887831327707871, disc_loss = 0.0018337750497385455
Trained batch 184 in epoch 2, gen_loss = 0.9889701237549653, disc_loss = 0.0018306931461887182
Trained batch 185 in epoch 2, gen_loss = 0.988897922859397, disc_loss = 0.001827222172431247
Trained batch 186 in epoch 2, gen_loss = 0.989083747175288, disc_loss = 0.001824974848136784
Trained batch 187 in epoch 2, gen_loss = 0.9888997011362238, disc_loss = 0.0018231334917722865
Trained batch 188 in epoch 2, gen_loss = 0.9888893933523268, disc_loss = 0.0018222067497729781
Trained batch 189 in epoch 2, gen_loss = 0.988926868375979, disc_loss = 0.0018201933585499461
Trained batch 190 in epoch 2, gen_loss = 0.9886824944256488, disc_loss = 0.0018169294015128966
Trained batch 191 in epoch 2, gen_loss = 0.9885283848270774, disc_loss = 0.0018142296012229053
Trained batch 192 in epoch 2, gen_loss = 0.9886481184415866, disc_loss = 0.0018120217794513841
Trained batch 193 in epoch 2, gen_loss = 0.9886144153850595, disc_loss = 0.0018081919766588079
Trained batch 194 in epoch 2, gen_loss = 0.9888719350863726, disc_loss = 0.0018047698934634145
Trained batch 195 in epoch 2, gen_loss = 0.9887628260315681, disc_loss = 0.001801286752178923
Trained batch 196 in epoch 2, gen_loss = 0.988840209953676, disc_loss = 0.0017974101146446722
Trained batch 197 in epoch 2, gen_loss = 0.9889898122561098, disc_loss = 0.0017934701537167786
Trained batch 198 in epoch 2, gen_loss = 0.9889214230542207, disc_loss = 0.0017904924584468405
Trained batch 199 in epoch 2, gen_loss = 0.9889274489879608, disc_loss = 0.0017862930125556887
Trained batch 200 in epoch 2, gen_loss = 0.989132297572805, disc_loss = 0.0017819701516143607
Trained batch 201 in epoch 2, gen_loss = 0.9891428829419731, disc_loss = 0.001776765748434285
Trained batch 202 in epoch 2, gen_loss = 0.9893442838650032, disc_loss = 0.0017722483794319586
Trained batch 203 in epoch 2, gen_loss = 0.9893866082032522, disc_loss = 0.0017679157854039588
Trained batch 204 in epoch 2, gen_loss = 0.9892351897751412, disc_loss = 0.0017635850525438421
Trained batch 205 in epoch 2, gen_loss = 0.9891185326483644, disc_loss = 0.0017591210724152986
Trained batch 206 in epoch 2, gen_loss = 0.9891175964604253, disc_loss = 0.0017538538283065573
Trained batch 207 in epoch 2, gen_loss = 0.9889948058586854, disc_loss = 0.0017486922882268957
Trained batch 208 in epoch 2, gen_loss = 0.989068808167745, disc_loss = 0.0017436601279490586
Trained batch 209 in epoch 2, gen_loss = 0.9891034739358084, disc_loss = 0.0017383305477865396
Trained batch 210 in epoch 2, gen_loss = 0.9891024435300962, disc_loss = 0.0017326945991815903
Trained batch 211 in epoch 2, gen_loss = 0.9891684755401792, disc_loss = 0.0017273739888552435
Trained batch 212 in epoch 2, gen_loss = 0.9891497515176944, disc_loss = 0.0017222594324949726
Trained batch 213 in epoch 2, gen_loss = 0.9890825754014131, disc_loss = 0.0017170816427096725
Trained batch 214 in epoch 2, gen_loss = 0.9890761990879857, disc_loss = 0.0017130652058133205
Trained batch 215 in epoch 2, gen_loss = 0.9890468043309671, disc_loss = 0.001709632863046998
Trained batch 216 in epoch 2, gen_loss = 0.9888911667507365, disc_loss = 0.0017061168663225176
Trained batch 217 in epoch 2, gen_loss = 0.9887853885462524, disc_loss = 0.0017025239288768466
Trained batch 218 in epoch 2, gen_loss = 0.9887841613325354, disc_loss = 0.0017007128051141933
Trained batch 219 in epoch 2, gen_loss = 0.9887101850726387, disc_loss = 0.0016995796343756162
Trained batch 220 in epoch 2, gen_loss = 0.9888642923864304, disc_loss = 0.0016985298358262158
Trained batch 221 in epoch 2, gen_loss = 0.9887078936035568, disc_loss = 0.0016965184605634259
Trained batch 222 in epoch 2, gen_loss = 0.9888820648193359, disc_loss = 0.0016939749598248357
Trained batch 223 in epoch 2, gen_loss = 0.9889350693140712, disc_loss = 0.0016923419033056625
Trained batch 224 in epoch 2, gen_loss = 0.9889288971159194, disc_loss = 0.0016900051460187469
Trained batch 225 in epoch 2, gen_loss = 0.9887855480202531, disc_loss = 0.0016871641271034733
Trained batch 226 in epoch 2, gen_loss = 0.9887156867245745, disc_loss = 0.0016856418139432527
Trained batch 227 in epoch 2, gen_loss = 0.988435405649637, disc_loss = 0.0016862421029496513
Trained batch 228 in epoch 2, gen_loss = 0.988450305690932, disc_loss = 0.0016887002753187379
Trained batch 229 in epoch 2, gen_loss = 0.988463965187902, disc_loss = 0.0016902386658804733
Trained batch 230 in epoch 2, gen_loss = 0.9884604385920933, disc_loss = 0.0016918448669315837
Trained batch 231 in epoch 2, gen_loss = 0.9885417644319863, disc_loss = 0.0016950167806373492
Trained batch 232 in epoch 2, gen_loss = 0.9884222183104748, disc_loss = 0.001696121476464725
Trained batch 233 in epoch 2, gen_loss = 0.9885769868508364, disc_loss = 0.0016971418117153116
Trained batch 234 in epoch 2, gen_loss = 0.988724932772048, disc_loss = 0.0017016176770916804
Trained batch 235 in epoch 2, gen_loss = 0.9885718067318706, disc_loss = 0.0017052089277027427
Trained batch 236 in epoch 2, gen_loss = 0.9886630710670213, disc_loss = 0.0017056039739341204
Trained batch 237 in epoch 2, gen_loss = 0.9886507847729851, disc_loss = 0.001705262649798484
Trained batch 238 in epoch 2, gen_loss = 0.9887757989651987, disc_loss = 0.0017051968436637528
Trained batch 239 in epoch 2, gen_loss = 0.9889849076668421, disc_loss = 0.0017060491326750101
Trained batch 240 in epoch 2, gen_loss = 0.9889261314483104, disc_loss = 0.0017064323567174747
Trained batch 241 in epoch 2, gen_loss = 0.9888567720070358, disc_loss = 0.0017069314420319448
Trained batch 242 in epoch 2, gen_loss = 0.9887163062645085, disc_loss = 0.0017071080611110378
Trained batch 243 in epoch 2, gen_loss = 0.9886319869365848, disc_loss = 0.001707652561055481
Trained batch 244 in epoch 2, gen_loss = 0.988506737777165, disc_loss = 0.001708615978238914
Trained batch 245 in epoch 2, gen_loss = 0.9883475378761447, disc_loss = 0.0017093541349068556
Trained batch 246 in epoch 2, gen_loss = 0.9882833354386241, disc_loss = 0.001710442262692264
Trained batch 247 in epoch 2, gen_loss = 0.9883803595458308, disc_loss = 0.001710402692673773
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 1.0485966205596924, disc_loss = 0.0019402995239943266
Trained batch 1 in epoch 3, gen_loss = 1.0068639516830444, disc_loss = 0.0026071107713505626
Trained batch 2 in epoch 3, gen_loss = 1.00119415918986, disc_loss = 0.002796530956402421
Trained batch 3 in epoch 3, gen_loss = 0.9991493374109268, disc_loss = 0.0027785018319264054
Trained batch 4 in epoch 3, gen_loss = 1.001881515979767, disc_loss = 0.0027246243320405484
Trained batch 5 in epoch 3, gen_loss = 1.0002161959807079, disc_loss = 0.0025832108804024756
Trained batch 6 in epoch 3, gen_loss = 0.9923723680632455, disc_loss = 0.002494089588123773
Trained batch 7 in epoch 3, gen_loss = 0.9894503578543663, disc_loss = 0.002562312569352798
Trained batch 8 in epoch 3, gen_loss = 0.9889073305659823, disc_loss = 0.002681004465557635
Trained batch 9 in epoch 3, gen_loss = 0.9814471065998077, disc_loss = 0.0027270591468550264
Trained batch 10 in epoch 3, gen_loss = 0.9826567227190192, disc_loss = 0.0027312079804356804
Trained batch 11 in epoch 3, gen_loss = 0.9813794692357382, disc_loss = 0.00268238351175872
Trained batch 12 in epoch 3, gen_loss = 0.9805681155278132, disc_loss = 0.0025928761057842234
Trained batch 13 in epoch 3, gen_loss = 0.9781212168080466, disc_loss = 0.002490651560947299
Trained batch 14 in epoch 3, gen_loss = 0.9766121983528138, disc_loss = 0.0023911016527563334
Trained batch 15 in epoch 3, gen_loss = 0.9774466641247272, disc_loss = 0.002300498537806561
Trained batch 16 in epoch 3, gen_loss = 0.9775221032254836, disc_loss = 0.0022117342895773403
Trained batch 17 in epoch 3, gen_loss = 0.9755269885063171, disc_loss = 0.0021307126573649133
Trained batch 18 in epoch 3, gen_loss = 0.9788467444871601, disc_loss = 0.0020677690106247993
Trained batch 19 in epoch 3, gen_loss = 0.9765184998512269, disc_loss = 0.002007462063920684
Trained batch 20 in epoch 3, gen_loss = 0.9768091695649284, disc_loss = 0.001994602839528982
Trained batch 21 in epoch 3, gen_loss = 0.9780020036480643, disc_loss = 0.0020327675288585438
Trained batch 22 in epoch 3, gen_loss = 0.9781469650890516, disc_loss = 0.0020804927689428237
Trained batch 23 in epoch 3, gen_loss = 0.978965791563193, disc_loss = 0.002121942673208347
Trained batch 24 in epoch 3, gen_loss = 0.9798541569709778, disc_loss = 0.0021249239263124763
Trained batch 25 in epoch 3, gen_loss = 0.9795333857719715, disc_loss = 0.0021013123757886486
Trained batch 26 in epoch 3, gen_loss = 0.9784403178426955, disc_loss = 0.0020719314903814207
Trained batch 27 in epoch 3, gen_loss = 0.9802912707839694, disc_loss = 0.002048812846104348
Trained batch 28 in epoch 3, gen_loss = 0.9800993286330124, disc_loss = 0.0020291161631105534
Trained batch 29 in epoch 3, gen_loss = 0.9803712805112202, disc_loss = 0.0020185133810931197
Trained batch 30 in epoch 3, gen_loss = 0.9792039009832567, disc_loss = 0.0019941311874126476
Trained batch 31 in epoch 3, gen_loss = 0.9784243237227201, disc_loss = 0.0019643502182589145
Trained batch 32 in epoch 3, gen_loss = 0.9780845425345681, disc_loss = 0.0019310695951748075
Trained batch 33 in epoch 3, gen_loss = 0.9777715171084684, disc_loss = 0.0018976307405597147
Trained batch 34 in epoch 3, gen_loss = 0.9786686658859253, disc_loss = 0.0018636720620894007
Trained batch 35 in epoch 3, gen_loss = 0.9804626007874807, disc_loss = 0.0018360359762381348
Trained batch 36 in epoch 3, gen_loss = 0.9801446344401386, disc_loss = 0.0018147561082465422
Trained batch 37 in epoch 3, gen_loss = 0.980290246637244, disc_loss = 0.001801047952061421
Trained batch 38 in epoch 3, gen_loss = 0.9808556880706396, disc_loss = 0.0017843894803753267
Trained batch 39 in epoch 3, gen_loss = 0.981559669971466, disc_loss = 0.0017675622395472601
Trained batch 40 in epoch 3, gen_loss = 0.9812616444215542, disc_loss = 0.00175197129194602
Trained batch 41 in epoch 3, gen_loss = 0.9809094255878812, disc_loss = 0.0017425532541459514
Trained batch 42 in epoch 3, gen_loss = 0.981856738412103, disc_loss = 0.0017397864830008773
Trained batch 43 in epoch 3, gen_loss = 0.9819684746590528, disc_loss = 0.0017292747824368153
Trained batch 44 in epoch 3, gen_loss = 0.9833836065398323, disc_loss = 0.0017102547274488542
Trained batch 45 in epoch 3, gen_loss = 0.9830538695273192, disc_loss = 0.001687904392146384
Trained batch 46 in epoch 3, gen_loss = 0.9822515540934623, disc_loss = 0.001669134801015892
Trained batch 47 in epoch 3, gen_loss = 0.98237444460392, disc_loss = 0.0016522266450920142
Trained batch 48 in epoch 3, gen_loss = 0.9818047783812698, disc_loss = 0.0016342774294886965
Trained batch 49 in epoch 3, gen_loss = 0.9819888412952423, disc_loss = 0.0016154567617923021
Trained batch 50 in epoch 3, gen_loss = 0.9819880455147987, disc_loss = 0.0015966723326082323
Trained batch 51 in epoch 3, gen_loss = 0.9818683621975092, disc_loss = 0.0015798155184781465
Trained batch 52 in epoch 3, gen_loss = 0.9815654102361427, disc_loss = 0.0015629036538742202
Trained batch 53 in epoch 3, gen_loss = 0.9815882047017416, disc_loss = 0.0015471119345252023
Trained batch 54 in epoch 3, gen_loss = 0.9828825430436567, disc_loss = 0.0015333115673539313
Trained batch 55 in epoch 3, gen_loss = 0.9830756368381637, disc_loss = 0.0015264921156423433
Trained batch 56 in epoch 3, gen_loss = 0.983161118992588, disc_loss = 0.001523834624605482
Trained batch 57 in epoch 3, gen_loss = 0.9836432152780993, disc_loss = 0.0015169041480162535
Trained batch 58 in epoch 3, gen_loss = 0.983679132946467, disc_loss = 0.001510380074713316
Trained batch 59 in epoch 3, gen_loss = 0.9830884655316671, disc_loss = 0.0015001486463006586
Trained batch 60 in epoch 3, gen_loss = 0.9824539462073905, disc_loss = 0.00148772156117942
Trained batch 61 in epoch 3, gen_loss = 0.9819536401379493, disc_loss = 0.00147440415927239
Trained batch 62 in epoch 3, gen_loss = 0.9813707414127532, disc_loss = 0.0014614462482905577
Trained batch 63 in epoch 3, gen_loss = 0.9811791349202394, disc_loss = 0.001449665282962087
Trained batch 64 in epoch 3, gen_loss = 0.981933382841257, disc_loss = 0.001441372933690078
Trained batch 65 in epoch 3, gen_loss = 0.9818796497402769, disc_loss = 0.0014341331737920302
Trained batch 66 in epoch 3, gen_loss = 0.9820506065639097, disc_loss = 0.0014323216850813756
Trained batch 67 in epoch 3, gen_loss = 0.9827349632978439, disc_loss = 0.0014336399044088252
Trained batch 68 in epoch 3, gen_loss = 0.9825591842333475, disc_loss = 0.0014302330606185117
Trained batch 69 in epoch 3, gen_loss = 0.9834318152495793, disc_loss = 0.001424186845542863
Trained batch 70 in epoch 3, gen_loss = 0.9831504922517589, disc_loss = 0.0014255534665672186
Trained batch 71 in epoch 3, gen_loss = 0.9833879768848419, disc_loss = 0.0014345318090312907
Trained batch 72 in epoch 3, gen_loss = 0.9830003217475055, disc_loss = 0.0014457022890844063
Trained batch 73 in epoch 3, gen_loss = 0.9830858409404755, disc_loss = 0.0014573594018804363
Trained batch 74 in epoch 3, gen_loss = 0.9827247818311056, disc_loss = 0.0014673275616951286
Trained batch 75 in epoch 3, gen_loss = 0.9830539924533743, disc_loss = 0.0014798016874058369
Trained batch 76 in epoch 3, gen_loss = 0.982966587915049, disc_loss = 0.001493133464676945
Trained batch 77 in epoch 3, gen_loss = 0.9826994324341799, disc_loss = 0.0015023288470752633
Trained batch 78 in epoch 3, gen_loss = 0.982753864572018, disc_loss = 0.0015048890992044176
Trained batch 79 in epoch 3, gen_loss = 0.982790706306696, disc_loss = 0.0015013906107924414
Trained batch 80 in epoch 3, gen_loss = 0.9825061257974601, disc_loss = 0.0014970516218274924
Trained batch 81 in epoch 3, gen_loss = 0.9823280543815799, disc_loss = 0.0015005312367376486
Trained batch 82 in epoch 3, gen_loss = 0.9821907425501261, disc_loss = 0.0015040261156194989
Trained batch 83 in epoch 3, gen_loss = 0.9825377492677598, disc_loss = 0.0015004218210898606
Trained batch 84 in epoch 3, gen_loss = 0.9824177377364215, disc_loss = 0.0014907950021819595
Trained batch 85 in epoch 3, gen_loss = 0.9817350000836128, disc_loss = 0.0014816865448157716
Trained batch 86 in epoch 3, gen_loss = 0.9818149291235825, disc_loss = 0.001472263501946354
Trained batch 87 in epoch 3, gen_loss = 0.9818711233409968, disc_loss = 0.0014640208583759058
Trained batch 88 in epoch 3, gen_loss = 0.9817745444479953, disc_loss = 0.0014570961984952263
Trained batch 89 in epoch 3, gen_loss = 0.9818903605143229, disc_loss = 0.0014552567561622709
Trained batch 90 in epoch 3, gen_loss = 0.9820022321009374, disc_loss = 0.001461226492480549
Trained batch 91 in epoch 3, gen_loss = 0.9812567253475604, disc_loss = 0.001463610830124589
Trained batch 92 in epoch 3, gen_loss = 0.9809297560363688, disc_loss = 0.0014633079659023512
Trained batch 93 in epoch 3, gen_loss = 0.980820117478675, disc_loss = 0.001460868681340102
Trained batch 94 in epoch 3, gen_loss = 0.9801672565309625, disc_loss = 0.0014578865687853019
Trained batch 95 in epoch 3, gen_loss = 0.9799965588996807, disc_loss = 0.0014544056266458938
Trained batch 96 in epoch 3, gen_loss = 0.9793971254653537, disc_loss = 0.001447861271876765
Trained batch 97 in epoch 3, gen_loss = 0.9792677273555678, disc_loss = 0.001439549882981774
Trained batch 98 in epoch 3, gen_loss = 0.9791396898452682, disc_loss = 0.0014315892182610401
Trained batch 99 in epoch 3, gen_loss = 0.9788386642932891, disc_loss = 0.0014233426784630865
Trained batch 100 in epoch 3, gen_loss = 0.978671655796542, disc_loss = 0.0014164906138056281
Trained batch 101 in epoch 3, gen_loss = 0.9782003912271238, disc_loss = 0.0014129732484363165
Trained batch 102 in epoch 3, gen_loss = 0.9782457235947396, disc_loss = 0.0014119120382532044
Trained batch 103 in epoch 3, gen_loss = 0.9782362786623148, disc_loss = 0.0014082672893821907
Trained batch 104 in epoch 3, gen_loss = 0.9782960573832195, disc_loss = 0.0014026794504995146
Trained batch 105 in epoch 3, gen_loss = 0.9787139127839286, disc_loss = 0.0013974657433792807
Trained batch 106 in epoch 3, gen_loss = 0.9786463619392609, disc_loss = 0.0013939088676124811
Trained batch 107 in epoch 3, gen_loss = 0.9784429354800118, disc_loss = 0.0013926803916951434
Trained batch 108 in epoch 3, gen_loss = 0.9787979186128039, disc_loss = 0.001391689484263984
Trained batch 109 in epoch 3, gen_loss = 0.9785539876330983, disc_loss = 0.0013899797478436747
Trained batch 110 in epoch 3, gen_loss = 0.9785413398399009, disc_loss = 0.0013973537113030885
Trained batch 111 in epoch 3, gen_loss = 0.9788421626601901, disc_loss = 0.001410530502783201
Trained batch 112 in epoch 3, gen_loss = 0.9788872225094686, disc_loss = 0.0014309445406367953
Trained batch 113 in epoch 3, gen_loss = 0.9791847174627739, disc_loss = 0.0014530202473938595
Trained batch 114 in epoch 3, gen_loss = 0.9792036761408267, disc_loss = 0.0014637394818355857
Trained batch 115 in epoch 3, gen_loss = 0.9792440790554573, disc_loss = 0.0014645957853645086
Trained batch 116 in epoch 3, gen_loss = 0.9794852682667919, disc_loss = 0.001460639543982589
Trained batch 117 in epoch 3, gen_loss = 0.9794602444616415, disc_loss = 0.0014563179949803626
Trained batch 118 in epoch 3, gen_loss = 0.9795807670144474, disc_loss = 0.0014525529333711171
Trained batch 119 in epoch 3, gen_loss = 0.9795430491367976, disc_loss = 0.0014484865629735093
Trained batch 120 in epoch 3, gen_loss = 0.9796280314114468, disc_loss = 0.0014454691260976117
Trained batch 121 in epoch 3, gen_loss = 0.9796244321299381, disc_loss = 0.0014475983916781843
Trained batch 122 in epoch 3, gen_loss = 0.9794546486885567, disc_loss = 0.0014606730518408302
Trained batch 123 in epoch 3, gen_loss = 0.9795089657268217, disc_loss = 0.0014793161789120564
Trained batch 124 in epoch 3, gen_loss = 0.9790709066390991, disc_loss = 0.001492907046340406
Trained batch 125 in epoch 3, gen_loss = 0.9795136527409629, disc_loss = 0.0014926253777322552
Trained batch 126 in epoch 3, gen_loss = 0.9795362728787219, disc_loss = 0.001485786361777495
Trained batch 127 in epoch 3, gen_loss = 0.9793620053678751, disc_loss = 0.00147912190959687
Trained batch 128 in epoch 3, gen_loss = 0.9794557972471843, disc_loss = 0.0014721591340543976
Trained batch 129 in epoch 3, gen_loss = 0.9795153975486756, disc_loss = 0.001466245201523774
Trained batch 130 in epoch 3, gen_loss = 0.9796578005979989, disc_loss = 0.0014638889408563726
Trained batch 131 in epoch 3, gen_loss = 0.9799703662142609, disc_loss = 0.0014641615800263191
Trained batch 132 in epoch 3, gen_loss = 0.9798997380679711, disc_loss = 0.001463091441192069
Trained batch 133 in epoch 3, gen_loss = 0.9799680251683762, disc_loss = 0.0014593944486939528
Trained batch 134 in epoch 3, gen_loss = 0.9802780447182832, disc_loss = 0.0014565075652811814
Trained batch 135 in epoch 3, gen_loss = 0.9802751352681833, disc_loss = 0.0014551847852999344
Trained batch 136 in epoch 3, gen_loss = 0.9804558514678565, disc_loss = 0.0014535176481059106
Trained batch 137 in epoch 3, gen_loss = 0.9804020657919456, disc_loss = 0.0014513986618797956
Trained batch 138 in epoch 3, gen_loss = 0.9804936141418896, disc_loss = 0.0014490009923700056
Trained batch 139 in epoch 3, gen_loss = 0.9802474192210606, disc_loss = 0.0014467037773491548
Trained batch 140 in epoch 3, gen_loss = 0.9801318780750248, disc_loss = 0.001443499534932487
Trained batch 141 in epoch 3, gen_loss = 0.9804555513489415, disc_loss = 0.0014394360289476076
Trained batch 142 in epoch 3, gen_loss = 0.980377886678789, disc_loss = 0.001436632422899658
Trained batch 143 in epoch 3, gen_loss = 0.9804552412695355, disc_loss = 0.0014342281776609728
Trained batch 144 in epoch 3, gen_loss = 0.980195768948259, disc_loss = 0.0014325667847076367
Trained batch 145 in epoch 3, gen_loss = 0.9802675063479437, disc_loss = 0.001433760447631756
Trained batch 146 in epoch 3, gen_loss = 0.9805052503436601, disc_loss = 0.0014376690798141316
Trained batch 147 in epoch 3, gen_loss = 0.9805755675644487, disc_loss = 0.0014386415777325227
Trained batch 148 in epoch 3, gen_loss = 0.9804319091291236, disc_loss = 0.0014395641909924729
Trained batch 149 in epoch 3, gen_loss = 0.9806076498826345, disc_loss = 0.0014409610722213983
Trained batch 150 in epoch 3, gen_loss = 0.9806464511827128, disc_loss = 0.0014393955672665543
Trained batch 151 in epoch 3, gen_loss = 0.9805392619026335, disc_loss = 0.001435570103287893
Trained batch 152 in epoch 3, gen_loss = 0.9804070833461737, disc_loss = 0.0014312744971510826
Trained batch 153 in epoch 3, gen_loss = 0.9804054324503069, disc_loss = 0.0014270129424592407
Trained batch 154 in epoch 3, gen_loss = 0.9804041997078926, disc_loss = 0.0014229049677059295
Trained batch 155 in epoch 3, gen_loss = 0.9801374425490698, disc_loss = 0.0014185035867670265
Trained batch 156 in epoch 3, gen_loss = 0.9799843552006278, disc_loss = 0.0014150195271607228
Trained batch 157 in epoch 3, gen_loss = 0.9800360387639154, disc_loss = 0.001413077664196114
Trained batch 158 in epoch 3, gen_loss = 0.9800772067135984, disc_loss = 0.0014111042255535722
Trained batch 159 in epoch 3, gen_loss = 0.9800533752888441, disc_loss = 0.001408692901895847
Trained batch 160 in epoch 3, gen_loss = 0.9800457861852943, disc_loss = 0.0014063453335048898
Trained batch 161 in epoch 3, gen_loss = 0.9798448001161034, disc_loss = 0.0014046595186098581
Trained batch 162 in epoch 3, gen_loss = 0.9800413974955038, disc_loss = 0.0014024342765940204
Trained batch 163 in epoch 3, gen_loss = 0.9800885919390655, disc_loss = 0.0013999455685091272
Trained batch 164 in epoch 3, gen_loss = 0.980264336051363, disc_loss = 0.001400150199223197
Trained batch 165 in epoch 3, gen_loss = 0.9804710110267961, disc_loss = 0.0014004698794626866
Trained batch 166 in epoch 3, gen_loss = 0.9808519875218055, disc_loss = 0.0014028232021837267
Trained batch 167 in epoch 3, gen_loss = 0.9807323118050894, disc_loss = 0.00140842618462297
Trained batch 168 in epoch 3, gen_loss = 0.9808726628151165, disc_loss = 0.0014145061829728047
Trained batch 169 in epoch 3, gen_loss = 0.9808013695127824, disc_loss = 0.0014169656240162166
Trained batch 170 in epoch 3, gen_loss = 0.98068717732067, disc_loss = 0.0014185949544591166
Trained batch 171 in epoch 3, gen_loss = 0.9805304203615632, disc_loss = 0.001420569208147394
Trained batch 172 in epoch 3, gen_loss = 0.9804476565019243, disc_loss = 0.001422626058560274
Trained batch 173 in epoch 3, gen_loss = 0.9805323724774109, disc_loss = 0.0014241521183840245
Trained batch 174 in epoch 3, gen_loss = 0.9803314134052822, disc_loss = 0.001424655704093831
Trained batch 175 in epoch 3, gen_loss = 0.9801876734603535, disc_loss = 0.0014243175517714751
Trained batch 176 in epoch 3, gen_loss = 0.9802126857520497, disc_loss = 0.0014226605233047052
Trained batch 177 in epoch 3, gen_loss = 0.9804272089111671, disc_loss = 0.001420900595813906
Trained batch 178 in epoch 3, gen_loss = 0.9806763260058184, disc_loss = 0.0014235260206997894
Trained batch 179 in epoch 3, gen_loss = 0.9806285079982545, disc_loss = 0.0014342307798667915
Trained batch 180 in epoch 3, gen_loss = 0.9806761382693086, disc_loss = 0.0014456912993520334
Trained batch 181 in epoch 3, gen_loss = 0.9806209989301451, disc_loss = 0.001456046858188379
Trained batch 182 in epoch 3, gen_loss = 0.9806775659159884, disc_loss = 0.0014675736167758214
Trained batch 183 in epoch 3, gen_loss = 0.9805842148868934, disc_loss = 0.0014759806230279576
Trained batch 184 in epoch 3, gen_loss = 0.9807210409963453, disc_loss = 0.0014797734612649357
Trained batch 185 in epoch 3, gen_loss = 0.9806378445317668, disc_loss = 0.0014798592398023254
Trained batch 186 in epoch 3, gen_loss = 0.9806898806821853, disc_loss = 0.0014768817594628483
Trained batch 187 in epoch 3, gen_loss = 0.9806299821493474, disc_loss = 0.0014722328041704925
Trained batch 188 in epoch 3, gen_loss = 0.9806594523803267, disc_loss = 0.001467377785408485
Trained batch 189 in epoch 3, gen_loss = 0.9809386331784098, disc_loss = 0.0014621649142722353
Trained batch 190 in epoch 3, gen_loss = 0.9807392249556737, disc_loss = 0.0014586768863376484
Trained batch 191 in epoch 3, gen_loss = 0.9810093240812421, disc_loss = 0.0014599631901243508
Trained batch 192 in epoch 3, gen_loss = 0.9809677230261769, disc_loss = 0.0014670654136682692
Trained batch 193 in epoch 3, gen_loss = 0.9812014287280053, disc_loss = 0.001479393330621101
Trained batch 194 in epoch 3, gen_loss = 0.98119324415158, disc_loss = 0.0014962217636191502
Trained batch 195 in epoch 3, gen_loss = 0.981432609412135, disc_loss = 0.0015137173904804513
Trained batch 196 in epoch 3, gen_loss = 0.9814697682554951, disc_loss = 0.0015274001398303447
Trained batch 197 in epoch 3, gen_loss = 0.9815792209572263, disc_loss = 0.0015364186729497342
Trained batch 198 in epoch 3, gen_loss = 0.98167118924347, disc_loss = 0.001541553989190833
Trained batch 199 in epoch 3, gen_loss = 0.9816630762815476, disc_loss = 0.0015409895530319772
Trained batch 200 in epoch 3, gen_loss = 0.9817431895294, disc_loss = 0.001536789038901991
Trained batch 201 in epoch 3, gen_loss = 0.9819084214101924, disc_loss = 0.0015324260330629896
Trained batch 202 in epoch 3, gen_loss = 0.9819387561581993, disc_loss = 0.0015269128593967153
Trained batch 203 in epoch 3, gen_loss = 0.982042612398372, disc_loss = 0.0015220396446381404
Trained batch 204 in epoch 3, gen_loss = 0.9820995464557555, disc_loss = 0.0015194817211921896
Trained batch 205 in epoch 3, gen_loss = 0.9820319984144378, disc_loss = 0.0015162141303909327
Trained batch 206 in epoch 3, gen_loss = 0.9821888712293284, disc_loss = 0.0015114010358060561
Trained batch 207 in epoch 3, gen_loss = 0.9821441878493016, disc_loss = 0.0015085459144756896
Trained batch 208 in epoch 3, gen_loss = 0.982052573461852, disc_loss = 0.0015090026197293284
Trained batch 209 in epoch 3, gen_loss = 0.9819950555052076, disc_loss = 0.0015100722482505565
Trained batch 210 in epoch 3, gen_loss = 0.9818830846045254, disc_loss = 0.0015107210237539474
Trained batch 211 in epoch 3, gen_loss = 0.9818165684646031, disc_loss = 0.0015109407374764934
Trained batch 212 in epoch 3, gen_loss = 0.981872044538668, disc_loss = 0.0015096218726092714
Trained batch 213 in epoch 3, gen_loss = 0.9817414993994704, disc_loss = 0.00150679302345809
Trained batch 214 in epoch 3, gen_loss = 0.9818596277126046, disc_loss = 0.0015037600114822475
Trained batch 215 in epoch 3, gen_loss = 0.9819917979615705, disc_loss = 0.0015016840675175277
Trained batch 216 in epoch 3, gen_loss = 0.9819262250227863, disc_loss = 0.0015005627165554942
Trained batch 217 in epoch 3, gen_loss = 0.9819449030478066, disc_loss = 0.0014990936814425
Trained batch 218 in epoch 3, gen_loss = 0.9819175881337902, disc_loss = 0.001496879667916535
Trained batch 219 in epoch 3, gen_loss = 0.9820845983245156, disc_loss = 0.0014958334527116015
Trained batch 220 in epoch 3, gen_loss = 0.982173175833344, disc_loss = 0.0014947941849414866
Trained batch 221 in epoch 3, gen_loss = 0.9823097941037771, disc_loss = 0.0014922773804534478
Trained batch 222 in epoch 3, gen_loss = 0.9822670047593224, disc_loss = 0.0014909054169633881
Trained batch 223 in epoch 3, gen_loss = 0.9823391940444708, disc_loss = 0.0014893890876399901
Trained batch 224 in epoch 3, gen_loss = 0.9823288400967916, disc_loss = 0.0014874519052035693
Trained batch 225 in epoch 3, gen_loss = 0.9822900042069697, disc_loss = 0.001485417482254623
Trained batch 226 in epoch 3, gen_loss = 0.982422141776736, disc_loss = 0.0014830344744562068
Trained batch 227 in epoch 3, gen_loss = 0.9824612480506563, disc_loss = 0.001481546517568763
Trained batch 228 in epoch 3, gen_loss = 0.9824301428669925, disc_loss = 0.0014791733931748025
Trained batch 229 in epoch 3, gen_loss = 0.9824945561263873, disc_loss = 0.0014766850988329997
Trained batch 230 in epoch 3, gen_loss = 0.9824832321761491, disc_loss = 0.0014744871738215594
Trained batch 231 in epoch 3, gen_loss = 0.9823974139731506, disc_loss = 0.0014721565243360538
Trained batch 232 in epoch 3, gen_loss = 0.9823949730959062, disc_loss = 0.0014694456135716225
Trained batch 233 in epoch 3, gen_loss = 0.9824075515453632, disc_loss = 0.0014673802790452894
Trained batch 234 in epoch 3, gen_loss = 0.9823996647875359, disc_loss = 0.0014655405218326587
Trained batch 235 in epoch 3, gen_loss = 0.9826078301264067, disc_loss = 0.0014626415671092079
Trained batch 236 in epoch 3, gen_loss = 0.9825605377869264, disc_loss = 0.0014598950976260274
Trained batch 237 in epoch 3, gen_loss = 0.9826494482885889, disc_loss = 0.001458062240418571
Trained batch 238 in epoch 3, gen_loss = 0.9825961472599077, disc_loss = 0.0014550870251072235
Trained batch 239 in epoch 3, gen_loss = 0.9826705160240332, disc_loss = 0.0014530531954126977
Trained batch 240 in epoch 3, gen_loss = 0.9825099407389946, disc_loss = 0.0014516627680485163
Trained batch 241 in epoch 3, gen_loss = 0.9824940882438471, disc_loss = 0.001450147352172716
Trained batch 242 in epoch 3, gen_loss = 0.9825940627620053, disc_loss = 0.0014492172651795802
Trained batch 243 in epoch 3, gen_loss = 0.9827449209377414, disc_loss = 0.0014479310011069413
Trained batch 244 in epoch 3, gen_loss = 0.982807344319869, disc_loss = 0.0014469987402755615
Trained batch 245 in epoch 3, gen_loss = 0.9826011536567192, disc_loss = 0.0014467255993910906
Trained batch 246 in epoch 3, gen_loss = 0.9827051708090161, disc_loss = 0.001445186768280463
Trained batch 247 in epoch 3, gen_loss = 0.9827493383519111, disc_loss = 0.0014420678291513
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.9907420873641968, disc_loss = 0.0007439941400662065
Trained batch 1 in epoch 4, gen_loss = 0.983958899974823, disc_loss = 0.0008831711602397263
Trained batch 2 in epoch 4, gen_loss = 0.9829724431037903, disc_loss = 0.0008707599869618813
Trained batch 3 in epoch 4, gen_loss = 0.9789310246706009, disc_loss = 0.0007729915523668751
Trained batch 4 in epoch 4, gen_loss = 0.979535436630249, disc_loss = 0.0007506150635890662
Trained batch 5 in epoch 4, gen_loss = 0.9739265839258829, disc_loss = 0.0008022411978648355
Trained batch 6 in epoch 4, gen_loss = 0.9798123155321393, disc_loss = 0.0008178830861912242
Trained batch 7 in epoch 4, gen_loss = 0.9817683771252632, disc_loss = 0.000801612957729958
Trained batch 8 in epoch 4, gen_loss = 0.978187726603614, disc_loss = 0.000787256505443818
Trained batch 9 in epoch 4, gen_loss = 0.9785382807254791, disc_loss = 0.0007645685691386461
Trained batch 10 in epoch 4, gen_loss = 0.9767362908883528, disc_loss = 0.000766672924245623
Trained batch 11 in epoch 4, gen_loss = 0.9799900899330775, disc_loss = 0.0007658129228123774
Trained batch 12 in epoch 4, gen_loss = 0.9868696148578937, disc_loss = 0.0008161491803968182
Trained batch 13 in epoch 4, gen_loss = 0.9832990680422101, disc_loss = 0.0008564523554274014
Trained batch 14 in epoch 4, gen_loss = 0.9824629624684652, disc_loss = 0.0008488283997091155
Trained batch 15 in epoch 4, gen_loss = 0.9826880730688572, disc_loss = 0.0008398158061027061
Trained batch 16 in epoch 4, gen_loss = 0.9859514271511751, disc_loss = 0.0008631155874087091
Trained batch 17 in epoch 4, gen_loss = 0.9851805998219384, disc_loss = 0.00089209192729969
Trained batch 18 in epoch 4, gen_loss = 0.9858982908098322, disc_loss = 0.0009115759963414779
Trained batch 19 in epoch 4, gen_loss = 0.9869890004396439, disc_loss = 0.0009223329048836604
Trained batch 20 in epoch 4, gen_loss = 0.9872858609472003, disc_loss = 0.0009263057034418342
Trained batch 21 in epoch 4, gen_loss = 0.9876190207221291, disc_loss = 0.0009221854720222341
Trained batch 22 in epoch 4, gen_loss = 0.9875941198805104, disc_loss = 0.0009099947536647644
Trained batch 23 in epoch 4, gen_loss = 0.9864407355586687, disc_loss = 0.0008934693687479012
Trained batch 24 in epoch 4, gen_loss = 0.9850434064865112, disc_loss = 0.0008743727847468108
Trained batch 25 in epoch 4, gen_loss = 0.9845040899056655, disc_loss = 0.0008566381539612149
Trained batch 26 in epoch 4, gen_loss = 0.9837653460326018, disc_loss = 0.0008395230591607591
Trained batch 27 in epoch 4, gen_loss = 0.9840979618685586, disc_loss = 0.0008234585371350736
Trained batch 28 in epoch 4, gen_loss = 0.9836090864806339, disc_loss = 0.0008091375087227287
Trained batch 29 in epoch 4, gen_loss = 0.9840412596861522, disc_loss = 0.0008000385132618248
Trained batch 30 in epoch 4, gen_loss = 0.9835145435025615, disc_loss = 0.0007980741981056429
Trained batch 31 in epoch 4, gen_loss = 0.983882587403059, disc_loss = 0.0008087853020697366
Trained batch 32 in epoch 4, gen_loss = 0.9830983010205355, disc_loss = 0.0008201499638909644
Trained batch 33 in epoch 4, gen_loss = 0.9817723859758938, disc_loss = 0.0008207928142784273
Trained batch 34 in epoch 4, gen_loss = 0.9820058567183358, disc_loss = 0.0008211258250022573
Trained batch 35 in epoch 4, gen_loss = 0.9821056740151511, disc_loss = 0.0008282408283169692
Trained batch 36 in epoch 4, gen_loss = 0.9825436730642576, disc_loss = 0.0008415438382684983
Trained batch 37 in epoch 4, gen_loss = 0.9842683719961267, disc_loss = 0.0008623916824274746
Trained batch 38 in epoch 4, gen_loss = 0.9852713636862926, disc_loss = 0.0008746177862541607
Trained batch 39 in epoch 4, gen_loss = 0.9852575913071633, disc_loss = 0.0008860926769557409
Trained batch 40 in epoch 4, gen_loss = 0.9851909861332033, disc_loss = 0.000891119955823098
Trained batch 41 in epoch 4, gen_loss = 0.9861347689515069, disc_loss = 0.0008920119545932504
Trained batch 42 in epoch 4, gen_loss = 0.9851535350777382, disc_loss = 0.0008928985050662832
Trained batch 43 in epoch 4, gen_loss = 0.9850469163872979, disc_loss = 0.0008967603644123301
Trained batch 44 in epoch 4, gen_loss = 0.9854908797476026, disc_loss = 0.0008997301273565325
Trained batch 45 in epoch 4, gen_loss = 0.9851972460746765, disc_loss = 0.0008934498233113276
Trained batch 46 in epoch 4, gen_loss = 0.9855921420645206, disc_loss = 0.0008847558093158171
Trained batch 47 in epoch 4, gen_loss = 0.9853710345923901, disc_loss = 0.0008773470156787274
Trained batch 48 in epoch 4, gen_loss = 0.9852973526837875, disc_loss = 0.0008716760393308134
Trained batch 49 in epoch 4, gen_loss = 0.9849238920211792, disc_loss = 0.0008733539585955441
Trained batch 50 in epoch 4, gen_loss = 0.9855577758714265, disc_loss = 0.0009016824233363949
Trained batch 51 in epoch 4, gen_loss = 0.9850362321505179, disc_loss = 0.0009525526301541294
Trained batch 52 in epoch 4, gen_loss = 0.9846538428990346, disc_loss = 0.0010074485501907063
Trained batch 53 in epoch 4, gen_loss = 0.9833776432055014, disc_loss = 0.0010503051668853947
Trained batch 54 in epoch 4, gen_loss = 0.9827754161574623, disc_loss = 0.0010861883850090883
Trained batch 55 in epoch 4, gen_loss = 0.9823466060417039, disc_loss = 0.0011118754316287646
Trained batch 56 in epoch 4, gen_loss = 0.9823767333699945, disc_loss = 0.0011297104769925539
Trained batch 57 in epoch 4, gen_loss = 0.982053969440789, disc_loss = 0.0011428030275996647
Trained batch 58 in epoch 4, gen_loss = 0.9825385233103219, disc_loss = 0.001147089879249491
Trained batch 59 in epoch 4, gen_loss = 0.9823968877394994, disc_loss = 0.001144543478343015
Trained batch 60 in epoch 4, gen_loss = 0.9828645880105066, disc_loss = 0.0011437948102314697
Trained batch 61 in epoch 4, gen_loss = 0.9830374717712402, disc_loss = 0.0011404292571598725
Trained batch 62 in epoch 4, gen_loss = 0.9832860136788989, disc_loss = 0.001137142162030888
Trained batch 63 in epoch 4, gen_loss = 0.9825742617249489, disc_loss = 0.0011324857205181615
Trained batch 64 in epoch 4, gen_loss = 0.9824644868190472, disc_loss = 0.0011266025204139834
Trained batch 65 in epoch 4, gen_loss = 0.9818915480917151, disc_loss = 0.0011254477334053565
Trained batch 66 in epoch 4, gen_loss = 0.9815753547113333, disc_loss = 0.0011284644428793508
Trained batch 67 in epoch 4, gen_loss = 0.9813847997609306, disc_loss = 0.001129288922289989
Trained batch 68 in epoch 4, gen_loss = 0.9813134791194529, disc_loss = 0.0011236660049188936
Trained batch 69 in epoch 4, gen_loss = 0.9810885838099889, disc_loss = 0.001118367091320189
Trained batch 70 in epoch 4, gen_loss = 0.9817806230464452, disc_loss = 0.0011121944375139413
Trained batch 71 in epoch 4, gen_loss = 0.9815396583742566, disc_loss = 0.0011057380219830924
Trained batch 72 in epoch 4, gen_loss = 0.981438937252515, disc_loss = 0.001098640391456397
Trained batch 73 in epoch 4, gen_loss = 0.9817242493500581, disc_loss = 0.0010900281871530555
Trained batch 74 in epoch 4, gen_loss = 0.9820196787516277, disc_loss = 0.0010817560988167921
Trained batch 75 in epoch 4, gen_loss = 0.9819540757881967, disc_loss = 0.0010728631658773673
Trained batch 76 in epoch 4, gen_loss = 0.981823795027547, disc_loss = 0.001064283205589352
Trained batch 77 in epoch 4, gen_loss = 0.9817621746124365, disc_loss = 0.0010568242652926785
Trained batch 78 in epoch 4, gen_loss = 0.9810799096204057, disc_loss = 0.0010503990969125512
Trained batch 79 in epoch 4, gen_loss = 0.9818510912358761, disc_loss = 0.0010458547170856037
Trained batch 80 in epoch 4, gen_loss = 0.9820724563834108, disc_loss = 0.0010412434003902254
Trained batch 81 in epoch 4, gen_loss = 0.9820765983767625, disc_loss = 0.0010374793591170868
Trained batch 82 in epoch 4, gen_loss = 0.9817646081189075, disc_loss = 0.001033821916740657
Trained batch 83 in epoch 4, gen_loss = 0.9816315954639798, disc_loss = 0.0010329336045764475
Trained batch 84 in epoch 4, gen_loss = 0.9817846866214976, disc_loss = 0.0010318798944354058
Trained batch 85 in epoch 4, gen_loss = 0.9816160818865133, disc_loss = 0.001029076020850605
Trained batch 86 in epoch 4, gen_loss = 0.9820677994311541, disc_loss = 0.0010254018740653563
Trained batch 87 in epoch 4, gen_loss = 0.9817247973247007, disc_loss = 0.0010198890780553813
Trained batch 88 in epoch 4, gen_loss = 0.9819770060228498, disc_loss = 0.0010153650616170065
Trained batch 89 in epoch 4, gen_loss = 0.9818068994416131, disc_loss = 0.001010913451642005
Trained batch 90 in epoch 4, gen_loss = 0.9817647809510702, disc_loss = 0.0010060655780822284
Trained batch 91 in epoch 4, gen_loss = 0.981685278856236, disc_loss = 0.0009999145100743551
Trained batch 92 in epoch 4, gen_loss = 0.9819268955979296, disc_loss = 0.0009954875930943477
Trained batch 93 in epoch 4, gen_loss = 0.9816708475985425, disc_loss = 0.0009947343385144276
Trained batch 94 in epoch 4, gen_loss = 0.9815220312068337, disc_loss = 0.0009980755968411502
Trained batch 95 in epoch 4, gen_loss = 0.9809657266984383, disc_loss = 0.0010016795677074697
Trained batch 96 in epoch 4, gen_loss = 0.9805590018783648, disc_loss = 0.0010024872476465463
Trained batch 97 in epoch 4, gen_loss = 0.9807602112390557, disc_loss = 0.001002192980733377
Trained batch 98 in epoch 4, gen_loss = 0.9812947312990824, disc_loss = 0.0010020222968769945
Trained batch 99 in epoch 4, gen_loss = 0.9817080110311508, disc_loss = 0.0009992918977513908
Trained batch 100 in epoch 4, gen_loss = 0.9818891505203625, disc_loss = 0.0009940984228967071
Trained batch 101 in epoch 4, gen_loss = 0.9822024802366892, disc_loss = 0.000987680103600153
Trained batch 102 in epoch 4, gen_loss = 0.9820604156521917, disc_loss = 0.0009832380289207347
Trained batch 103 in epoch 4, gen_loss = 0.9819372015503737, disc_loss = 0.0009781173461166103
Trained batch 104 in epoch 4, gen_loss = 0.9822110488301232, disc_loss = 0.0009737949083847481
Trained batch 105 in epoch 4, gen_loss = 0.9824287953241816, disc_loss = 0.000973716131927674
Trained batch 106 in epoch 4, gen_loss = 0.9821372605929864, disc_loss = 0.0009752387204316279
Trained batch 107 in epoch 4, gen_loss = 0.9822310148565857, disc_loss = 0.0009775451399036683
Trained batch 108 in epoch 4, gen_loss = 0.9821243783749571, disc_loss = 0.0009816902315291072
Trained batch 109 in epoch 4, gen_loss = 0.9820243878798052, disc_loss = 0.0009884977594166147
Trained batch 110 in epoch 4, gen_loss = 0.9818137051822903, disc_loss = 0.0009972074030802022
Trained batch 111 in epoch 4, gen_loss = 0.9818783881408828, disc_loss = 0.0010063256140711019
Trained batch 112 in epoch 4, gen_loss = 0.9818328175924521, disc_loss = 0.0010141902868491721
Trained batch 113 in epoch 4, gen_loss = 0.9816113595376935, disc_loss = 0.0010202760466582778
Trained batch 114 in epoch 4, gen_loss = 0.9817405109820159, disc_loss = 0.001023258222013955
Trained batch 115 in epoch 4, gen_loss = 0.9823256700203337, disc_loss = 0.0010243956175741162
Trained batch 116 in epoch 4, gen_loss = 0.9824333598471096, disc_loss = 0.0010223426131241056
Trained batch 117 in epoch 4, gen_loss = 0.9822916661278677, disc_loss = 0.0010194984253326241
Trained batch 118 in epoch 4, gen_loss = 0.9822863360412982, disc_loss = 0.001015739792521589
Trained batch 119 in epoch 4, gen_loss = 0.9820616414149602, disc_loss = 0.001011922972247703
Trained batch 120 in epoch 4, gen_loss = 0.9817784285742389, disc_loss = 0.0010095857897261542
Trained batch 121 in epoch 4, gen_loss = 0.9821106605842466, disc_loss = 0.001007741598887598
Trained batch 122 in epoch 4, gen_loss = 0.9825593611089195, disc_loss = 0.0010069993121560846
Trained batch 123 in epoch 4, gen_loss = 0.9823777492969267, disc_loss = 0.0010088643811609326
Trained batch 124 in epoch 4, gen_loss = 0.9823887414932251, disc_loss = 0.0010157689040061087
Trained batch 125 in epoch 4, gen_loss = 0.9823523504393441, disc_loss = 0.0010255287391676877
Trained batch 126 in epoch 4, gen_loss = 0.9822557854840136, disc_loss = 0.0010350388912465716
Trained batch 127 in epoch 4, gen_loss = 0.9820117224007845, disc_loss = 0.001041531886357916
Trained batch 128 in epoch 4, gen_loss = 0.982280175815257, disc_loss = 0.0010462850411224014
Trained batch 129 in epoch 4, gen_loss = 0.9824588564726022, disc_loss = 0.001049081107843309
Trained batch 130 in epoch 4, gen_loss = 0.9823949432555046, disc_loss = 0.0010502307952598505
Trained batch 131 in epoch 4, gen_loss = 0.9826052283698862, disc_loss = 0.0010501740429335218
Trained batch 132 in epoch 4, gen_loss = 0.9828320226274935, disc_loss = 0.0010485983209919073
Trained batch 133 in epoch 4, gen_loss = 0.9825217363549702, disc_loss = 0.0010479606421744283
Trained batch 134 in epoch 4, gen_loss = 0.982698028617435, disc_loss = 0.0010472452468497473
Trained batch 135 in epoch 4, gen_loss = 0.98263359245132, disc_loss = 0.001045363747406929
Trained batch 136 in epoch 4, gen_loss = 0.9821828925696603, disc_loss = 0.0010443221772154182
Trained batch 137 in epoch 4, gen_loss = 0.9820883675761845, disc_loss = 0.0010447196594517056
Trained batch 138 in epoch 4, gen_loss = 0.9821569636571321, disc_loss = 0.001043966466941194
Trained batch 139 in epoch 4, gen_loss = 0.9821044738803592, disc_loss = 0.0010410902175603302
Trained batch 140 in epoch 4, gen_loss = 0.982205792099026, disc_loss = 0.0010373776500750703
Trained batch 141 in epoch 4, gen_loss = 0.9821470488964672, disc_loss = 0.0010328818297892495
Trained batch 142 in epoch 4, gen_loss = 0.9820218077906362, disc_loss = 0.0010291211729563147
Trained batch 143 in epoch 4, gen_loss = 0.9820758663117886, disc_loss = 0.0010259189637306715
Trained batch 144 in epoch 4, gen_loss = 0.9818628611235783, disc_loss = 0.0010217561386525631
Trained batch 145 in epoch 4, gen_loss = 0.9819082303406441, disc_loss = 0.0010181307893928958
Trained batch 146 in epoch 4, gen_loss = 0.9818826763808322, disc_loss = 0.0010205932744766022
Trained batch 147 in epoch 4, gen_loss = 0.9819041695949193, disc_loss = 0.0010279853379108466
Trained batch 148 in epoch 4, gen_loss = 0.9817857314276215, disc_loss = 0.0010341547102192354
Trained batch 149 in epoch 4, gen_loss = 0.9817479526996613, disc_loss = 0.0010349897904476772
Trained batch 150 in epoch 4, gen_loss = 0.9817530662808197, disc_loss = 0.0010345897063711621
Trained batch 151 in epoch 4, gen_loss = 0.9818383576838594, disc_loss = 0.0010338373486822668
Trained batch 152 in epoch 4, gen_loss = 0.9818697474361245, disc_loss = 0.0010340182731548946
Trained batch 153 in epoch 4, gen_loss = 0.9818570753196617, disc_loss = 0.0010333588991658883
Trained batch 154 in epoch 4, gen_loss = 0.9817329533638492, disc_loss = 0.0010313162005566542
Trained batch 155 in epoch 4, gen_loss = 0.9817598336018049, disc_loss = 0.0010301438029646538
Trained batch 156 in epoch 4, gen_loss = 0.9816600433580435, disc_loss = 0.0010296487576434993
Trained batch 157 in epoch 4, gen_loss = 0.98157791019995, disc_loss = 0.0010289855119389117
Trained batch 158 in epoch 4, gen_loss = 0.9813640237604297, disc_loss = 0.0010285413455739384
Trained batch 159 in epoch 4, gen_loss = 0.9813201054930687, disc_loss = 0.001027841127870488
Trained batch 160 in epoch 4, gen_loss = 0.9813627789479605, disc_loss = 0.0010282254994048604
Trained batch 161 in epoch 4, gen_loss = 0.9813900983627931, disc_loss = 0.0010290908203948934
Trained batch 162 in epoch 4, gen_loss = 0.9814427549853647, disc_loss = 0.0010279711247336096
Trained batch 163 in epoch 4, gen_loss = 0.9814018861549657, disc_loss = 0.001026957254308821
Trained batch 164 in epoch 4, gen_loss = 0.9814028761603616, disc_loss = 0.0010270404117887445
Trained batch 165 in epoch 4, gen_loss = 0.9814849811864187, disc_loss = 0.001028691683909912
Trained batch 166 in epoch 4, gen_loss = 0.981504297898915, disc_loss = 0.001030105296843044
Trained batch 167 in epoch 4, gen_loss = 0.9813097165454001, disc_loss = 0.0010289574475748288
Trained batch 168 in epoch 4, gen_loss = 0.9813678924148604, disc_loss = 0.001026718421238502
Trained batch 169 in epoch 4, gen_loss = 0.9811716493438272, disc_loss = 0.001023340385461993
Trained batch 170 in epoch 4, gen_loss = 0.9809376499806232, disc_loss = 0.0010201507950901485
Trained batch 171 in epoch 4, gen_loss = 0.9811028730730678, disc_loss = 0.0010190640146733089
Trained batch 172 in epoch 4, gen_loss = 0.9811115950518261, disc_loss = 0.0010189604701546983
Trained batch 173 in epoch 4, gen_loss = 0.9810213230807205, disc_loss = 0.0010196388330800331
Trained batch 174 in epoch 4, gen_loss = 0.9811020227840969, disc_loss = 0.0010226512924834553
Trained batch 175 in epoch 4, gen_loss = 0.9812537570568648, disc_loss = 0.0010252717843699925
Trained batch 176 in epoch 4, gen_loss = 0.9810826539319787, disc_loss = 0.0010271828954100167
Trained batch 177 in epoch 4, gen_loss = 0.9810011668151684, disc_loss = 0.0010303376774562607
Trained batch 178 in epoch 4, gen_loss = 0.9808475531679292, disc_loss = 0.001032848607497706
Trained batch 179 in epoch 4, gen_loss = 0.9806162397066752, disc_loss = 0.0010344490659513718
Trained batch 180 in epoch 4, gen_loss = 0.9805619548697498, disc_loss = 0.0010362826369751698
Trained batch 181 in epoch 4, gen_loss = 0.9808037579059601, disc_loss = 0.0010371000554277
Trained batch 182 in epoch 4, gen_loss = 0.9809464414914449, disc_loss = 0.0010358613883615904
Trained batch 183 in epoch 4, gen_loss = 0.9811158902619196, disc_loss = 0.0010350800032977966
Trained batch 184 in epoch 4, gen_loss = 0.9810152198817279, disc_loss = 0.001036098727018799
Trained batch 185 in epoch 4, gen_loss = 0.9810554785754091, disc_loss = 0.0010375406445061628
Trained batch 186 in epoch 4, gen_loss = 0.9811219643144047, disc_loss = 0.0010385424847139373
Trained batch 187 in epoch 4, gen_loss = 0.9810721053087965, disc_loss = 0.0010380213453243686
Trained batch 188 in epoch 4, gen_loss = 0.9811342282900735, disc_loss = 0.0010366345971031853
Trained batch 189 in epoch 4, gen_loss = 0.981273626340063, disc_loss = 0.0010349081080149565
Trained batch 190 in epoch 4, gen_loss = 0.9812629656641895, disc_loss = 0.0010333623551502726
Trained batch 191 in epoch 4, gen_loss = 0.9812119072303176, disc_loss = 0.001032623456770428
Trained batch 192 in epoch 4, gen_loss = 0.9809998511650402, disc_loss = 0.0010324940982653513
Trained batch 193 in epoch 4, gen_loss = 0.9810278289711353, disc_loss = 0.001031385538301469
Trained batch 194 in epoch 4, gen_loss = 0.9812612151488279, disc_loss = 0.001030399949582389
Trained batch 195 in epoch 4, gen_loss = 0.9815140138475262, disc_loss = 0.001030303618772079
Trained batch 196 in epoch 4, gen_loss = 0.9815670914456324, disc_loss = 0.0010297915513856517
Trained batch 197 in epoch 4, gen_loss = 0.9815853042433961, disc_loss = 0.0010298962675145535
Trained batch 198 in epoch 4, gen_loss = 0.9815127894506982, disc_loss = 0.0010302433246529039
Trained batch 199 in epoch 4, gen_loss = 0.9815069499611855, disc_loss = 0.001030098667688435
Trained batch 200 in epoch 4, gen_loss = 0.9812760106959746, disc_loss = 0.0010291885030606475
Trained batch 201 in epoch 4, gen_loss = 0.9813754148412459, disc_loss = 0.0010284157165863302
Trained batch 202 in epoch 4, gen_loss = 0.9815685681521599, disc_loss = 0.0010285206252922364
Trained batch 203 in epoch 4, gen_loss = 0.9812815797095206, disc_loss = 0.0010291271468946326
Trained batch 204 in epoch 4, gen_loss = 0.9813259421325311, disc_loss = 0.0010297981819149288
Trained batch 205 in epoch 4, gen_loss = 0.9812264668131337, disc_loss = 0.0010295557543393496
Trained batch 206 in epoch 4, gen_loss = 0.9811520112885369, disc_loss = 0.0010294745039871943
Trained batch 207 in epoch 4, gen_loss = 0.9811893466573495, disc_loss = 0.001029241131198852
Trained batch 208 in epoch 4, gen_loss = 0.9809172079323581, disc_loss = 0.001029357670736165
Trained batch 209 in epoch 4, gen_loss = 0.981133652868725, disc_loss = 0.0010307832761013525
Trained batch 210 in epoch 4, gen_loss = 0.981026761339739, disc_loss = 0.0010336847713501834
Trained batch 211 in epoch 4, gen_loss = 0.9809603657362596, disc_loss = 0.0010376109711151518
Trained batch 212 in epoch 4, gen_loss = 0.9809787956201974, disc_loss = 0.001041471786133534
Trained batch 213 in epoch 4, gen_loss = 0.9808639396573896, disc_loss = 0.0010449473892184078
Trained batch 214 in epoch 4, gen_loss = 0.9809142051741134, disc_loss = 0.0010466449543411389
Trained batch 215 in epoch 4, gen_loss = 0.9809671662471913, disc_loss = 0.0010479988938001312
Trained batch 216 in epoch 4, gen_loss = 0.9809988250930188, disc_loss = 0.0010498827104703501
Trained batch 217 in epoch 4, gen_loss = 0.9811189800774286, disc_loss = 0.0010514471167538298
Trained batch 218 in epoch 4, gen_loss = 0.9809941554178386, disc_loss = 0.0010517409841315267
Trained batch 219 in epoch 4, gen_loss = 0.981005920605226, disc_loss = 0.001051794064617504
Trained batch 220 in epoch 4, gen_loss = 0.9807195102467257, disc_loss = 0.0010551634731616117
Trained batch 221 in epoch 4, gen_loss = 0.9807651601396166, disc_loss = 0.0010635186001702488
Trained batch 222 in epoch 4, gen_loss = 0.980455596885339, disc_loss = 0.0010741704594888913
Trained batch 223 in epoch 4, gen_loss = 0.9805474009897027, disc_loss = 0.0010845649330804008
Trained batch 224 in epoch 4, gen_loss = 0.980411269929674, disc_loss = 0.0010913980841481437
Trained batch 225 in epoch 4, gen_loss = 0.9803597389069278, disc_loss = 0.0010958269720874414
Trained batch 226 in epoch 4, gen_loss = 0.9803463535686947, disc_loss = 0.0010982160873163392
Trained batch 227 in epoch 4, gen_loss = 0.9802704296613994, disc_loss = 0.0010985812860829021
Trained batch 228 in epoch 4, gen_loss = 0.9801635312721719, disc_loss = 0.001097146972356055
Trained batch 229 in epoch 4, gen_loss = 0.98019750273746, disc_loss = 0.0010947119901412287
Trained batch 230 in epoch 4, gen_loss = 0.9803246424827741, disc_loss = 0.0010919949257528626
Trained batch 231 in epoch 4, gen_loss = 0.9805477359171572, disc_loss = 0.0010896250532823615
Trained batch 232 in epoch 4, gen_loss = 0.9805922753821115, disc_loss = 0.0010872501837461386
Trained batch 233 in epoch 4, gen_loss = 0.9808993207083808, disc_loss = 0.0010851949712552098
Trained batch 234 in epoch 4, gen_loss = 0.9808804243168933, disc_loss = 0.0010842637012791919
Trained batch 235 in epoch 4, gen_loss = 0.9807337679095187, disc_loss = 0.001084331181581069
Trained batch 236 in epoch 4, gen_loss = 0.9806327847488822, disc_loss = 0.0010833962044859392
Trained batch 237 in epoch 4, gen_loss = 0.9806768874160382, disc_loss = 0.001081829981833399
Trained batch 238 in epoch 4, gen_loss = 0.9806414014624751, disc_loss = 0.001080255958136701
Trained batch 239 in epoch 4, gen_loss = 0.980535696943601, disc_loss = 0.0010785738420963753
Trained batch 240 in epoch 4, gen_loss = 0.9803490114409894, disc_loss = 0.0010762373193194202
Trained batch 241 in epoch 4, gen_loss = 0.9802923953730213, disc_loss = 0.001073195791922602
Trained batch 242 in epoch 4, gen_loss = 0.9801542739318722, disc_loss = 0.001069882896838043
Trained batch 243 in epoch 4, gen_loss = 0.9801438905176569, disc_loss = 0.0010667686453461266
Trained batch 244 in epoch 4, gen_loss = 0.9801339268684387, disc_loss = 0.001064350668991897
Trained batch 245 in epoch 4, gen_loss = 0.9800404395029797, disc_loss = 0.0010626394226172242
Trained batch 246 in epoch 4, gen_loss = 0.9799948800430607, disc_loss = 0.0010610502516060901
Trained batch 247 in epoch 4, gen_loss = 0.9799453568074011, disc_loss = 0.001058756572033857
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 1.003313660621643, disc_loss = 0.00048195538693107665
Trained batch 1 in epoch 5, gen_loss = 0.9890696704387665, disc_loss = 0.0005666230135830119
Trained batch 2 in epoch 5, gen_loss = 0.9821312626202902, disc_loss = 0.0005628679549166312
Trained batch 3 in epoch 5, gen_loss = 0.9873017221689224, disc_loss = 0.0005619593648589216
Trained batch 4 in epoch 5, gen_loss = 0.9874195456504822, disc_loss = 0.0005759434017818422
Trained batch 5 in epoch 5, gen_loss = 0.9858098824818929, disc_loss = 0.0005932540273837125
Trained batch 6 in epoch 5, gen_loss = 0.9871652211461749, disc_loss = 0.0006303801991245044
Trained batch 7 in epoch 5, gen_loss = 0.9829488918185234, disc_loss = 0.0006856708751001861
Trained batch 8 in epoch 5, gen_loss = 0.9809915290938483, disc_loss = 0.0007277980104037044
Trained batch 9 in epoch 5, gen_loss = 0.9823519825935364, disc_loss = 0.0007640700408956036
Trained batch 10 in epoch 5, gen_loss = 0.9828479290008545, disc_loss = 0.0007855025072455068
Trained batch 11 in epoch 5, gen_loss = 0.9817809214194616, disc_loss = 0.0008165821758060096
Trained batch 12 in epoch 5, gen_loss = 0.9836162099471459, disc_loss = 0.0008810069300055217
Trained batch 13 in epoch 5, gen_loss = 0.9830017600740705, disc_loss = 0.0009594483729285587
Trained batch 14 in epoch 5, gen_loss = 0.9821618715922038, disc_loss = 0.0010208548104856164
Trained batch 15 in epoch 5, gen_loss = 0.9814679622650146, disc_loss = 0.001034499879096984
Trained batch 16 in epoch 5, gen_loss = 0.9823873323552749, disc_loss = 0.001018665821688688
Trained batch 17 in epoch 5, gen_loss = 0.9810869230164422, disc_loss = 0.001012644137113562
Trained batch 18 in epoch 5, gen_loss = 0.9802943091643485, disc_loss = 0.0010167212718730106
Trained batch 19 in epoch 5, gen_loss = 0.9802324295043945, disc_loss = 0.001017838490952272
Trained batch 20 in epoch 5, gen_loss = 0.9796109426589239, disc_loss = 0.001035715881568779
Trained batch 21 in epoch 5, gen_loss = 0.9790577536279504, disc_loss = 0.0010527093294182453
Trained batch 22 in epoch 5, gen_loss = 0.979207808556764, disc_loss = 0.0010672336730235459
Trained batch 23 in epoch 5, gen_loss = 0.9795574471354485, disc_loss = 0.0010666453902861879
Trained batch 24 in epoch 5, gen_loss = 0.9800062251091003, disc_loss = 0.0010514319234061985
Trained batch 25 in epoch 5, gen_loss = 0.9798237291666178, disc_loss = 0.0010352062806934835
Trained batch 26 in epoch 5, gen_loss = 0.9805179503228929, disc_loss = 0.0010229261533822864
Trained batch 27 in epoch 5, gen_loss = 0.979204631277493, disc_loss = 0.0010205990869768097
Trained batch 28 in epoch 5, gen_loss = 0.9797704528118002, disc_loss = 0.0010160568505445302
Trained batch 29 in epoch 5, gen_loss = 0.979574582974116, disc_loss = 0.0010278096529267107
Trained batch 30 in epoch 5, gen_loss = 0.9793612783954989, disc_loss = 0.0010438613366380695
Trained batch 31 in epoch 5, gen_loss = 0.97811577655375, disc_loss = 0.0010589977200652356
Trained batch 32 in epoch 5, gen_loss = 0.9780387372681589, disc_loss = 0.0010703911565625194
Trained batch 33 in epoch 5, gen_loss = 0.9774376189007479, disc_loss = 0.0010833750805913417
Trained batch 34 in epoch 5, gen_loss = 0.9760704142706734, disc_loss = 0.0011030432460497
Trained batch 35 in epoch 5, gen_loss = 0.9758633706304762, disc_loss = 0.0011160745464925033
Trained batch 36 in epoch 5, gen_loss = 0.9771957912960568, disc_loss = 0.0011268910295896334
Trained batch 37 in epoch 5, gen_loss = 0.9764990790894157, disc_loss = 0.0011289186038897913
Trained batch 38 in epoch 5, gen_loss = 0.9761538230455838, disc_loss = 0.0011264711091569506
Trained batch 39 in epoch 5, gen_loss = 0.9755769342184066, disc_loss = 0.0011188037758984137
Trained batch 40 in epoch 5, gen_loss = 0.9761389261338769, disc_loss = 0.0011077024626102662
Trained batch 41 in epoch 5, gen_loss = 0.9759558183806283, disc_loss = 0.0011009601786056357
Trained batch 42 in epoch 5, gen_loss = 0.9760929456976957, disc_loss = 0.0011031324616470916
Trained batch 43 in epoch 5, gen_loss = 0.9765303297476335, disc_loss = 0.0011053399774193001
Trained batch 44 in epoch 5, gen_loss = 0.9764295710457696, disc_loss = 0.0011033169271993555
Trained batch 45 in epoch 5, gen_loss = 0.9762657388396885, disc_loss = 0.0010997590060983582
Trained batch 46 in epoch 5, gen_loss = 0.9761476516723633, disc_loss = 0.0010995037570110265
Trained batch 47 in epoch 5, gen_loss = 0.9769285693764687, disc_loss = 0.0010968964252242586
Trained batch 48 in epoch 5, gen_loss = 0.9765331368057095, disc_loss = 0.001085725898631107
Trained batch 49 in epoch 5, gen_loss = 0.9767590761184692, disc_loss = 0.0010733699926640838
Trained batch 50 in epoch 5, gen_loss = 0.9778951406478882, disc_loss = 0.0010629355309385003
Trained batch 51 in epoch 5, gen_loss = 0.9774671128162971, disc_loss = 0.0010518009613196438
Trained batch 52 in epoch 5, gen_loss = 0.9772236504644718, disc_loss = 0.0010424559652576892
Trained batch 53 in epoch 5, gen_loss = 0.9777096686539827, disc_loss = 0.0010338737241302927
Trained batch 54 in epoch 5, gen_loss = 0.9779899217865684, disc_loss = 0.001023499049584974
Trained batch 55 in epoch 5, gen_loss = 0.9779863410762378, disc_loss = 0.0010135630888856082
Trained batch 56 in epoch 5, gen_loss = 0.9786554229886908, disc_loss = 0.0010058442329816323
Trained batch 57 in epoch 5, gen_loss = 0.9792187902434119, disc_loss = 0.0009988834163182061
Trained batch 58 in epoch 5, gen_loss = 0.9786493980278403, disc_loss = 0.0009933128618532633
Trained batch 59 in epoch 5, gen_loss = 0.979730220635732, disc_loss = 0.0009934593753617568
Trained batch 60 in epoch 5, gen_loss = 0.9794420326342348, disc_loss = 0.000996389837084399
Trained batch 61 in epoch 5, gen_loss = 0.9797904943266222, disc_loss = 0.0009989615012478503
Trained batch 62 in epoch 5, gen_loss = 0.9799216219357082, disc_loss = 0.0009966926655680356
Trained batch 63 in epoch 5, gen_loss = 0.980396400205791, disc_loss = 0.0009925479139383242
Trained batch 64 in epoch 5, gen_loss = 0.9803755677663363, disc_loss = 0.0009933277395947908
Trained batch 65 in epoch 5, gen_loss = 0.9798444365010117, disc_loss = 0.000998749461635298
Trained batch 66 in epoch 5, gen_loss = 0.9800991496043419, disc_loss = 0.00100580889274672
Trained batch 67 in epoch 5, gen_loss = 0.980242892223246, disc_loss = 0.0010147040323799422
Trained batch 68 in epoch 5, gen_loss = 0.9797433640645898, disc_loss = 0.0010225463753896834
Trained batch 69 in epoch 5, gen_loss = 0.9802786001137325, disc_loss = 0.0010290199745213613
Trained batch 70 in epoch 5, gen_loss = 0.9798513365463472, disc_loss = 0.0010380039018624738
Trained batch 71 in epoch 5, gen_loss = 0.9794967472553253, disc_loss = 0.0010434757669928432
Trained batch 72 in epoch 5, gen_loss = 0.9799105582171923, disc_loss = 0.0010436842324090994
Trained batch 73 in epoch 5, gen_loss = 0.9797026200874431, disc_loss = 0.0010438304684735281
Trained batch 74 in epoch 5, gen_loss = 0.9798209158579508, disc_loss = 0.0010459060831150661
Trained batch 75 in epoch 5, gen_loss = 0.9793319960958079, disc_loss = 0.0010459154164939384
Trained batch 76 in epoch 5, gen_loss = 0.9792596496544875, disc_loss = 0.001041529198591416
Trained batch 77 in epoch 5, gen_loss = 0.9791036492738968, disc_loss = 0.0010351951563139805
Trained batch 78 in epoch 5, gen_loss = 0.979636225519301, disc_loss = 0.0010295534816635418
Trained batch 79 in epoch 5, gen_loss = 0.9795583464205265, disc_loss = 0.001025571821446647
Trained batch 80 in epoch 5, gen_loss = 0.9794000210585417, disc_loss = 0.0010225422602049132
Trained batch 81 in epoch 5, gen_loss = 0.9789987402718242, disc_loss = 0.0010203741623582773
Trained batch 82 in epoch 5, gen_loss = 0.979690925902631, disc_loss = 0.0010211846285572567
Trained batch 83 in epoch 5, gen_loss = 0.9795280943314234, disc_loss = 0.001024913078470577
Trained batch 84 in epoch 5, gen_loss = 0.9798114685451284, disc_loss = 0.0010313555225045146
Trained batch 85 in epoch 5, gen_loss = 0.9795905566492746, disc_loss = 0.0010371318186476264
Trained batch 86 in epoch 5, gen_loss = 0.9798114059985369, disc_loss = 0.0010435940003980636
Trained batch 87 in epoch 5, gen_loss = 0.9794554737481204, disc_loss = 0.001049053714682073
Trained batch 88 in epoch 5, gen_loss = 0.9796130710773254, disc_loss = 0.0010519708173867483
Trained batch 89 in epoch 5, gen_loss = 0.9796741035249498, disc_loss = 0.0010535758192418143
Trained batch 90 in epoch 5, gen_loss = 0.9800279467970461, disc_loss = 0.0010523570136673707
Trained batch 91 in epoch 5, gen_loss = 0.9794380172439243, disc_loss = 0.0010481523669390615
Trained batch 92 in epoch 5, gen_loss = 0.9794145719979399, disc_loss = 0.0010450403872621996
Trained batch 93 in epoch 5, gen_loss = 0.9795583930421383, disc_loss = 0.0010438354861144808
Trained batch 94 in epoch 5, gen_loss = 0.979260728233739, disc_loss = 0.0010420381260030952
Trained batch 95 in epoch 5, gen_loss = 0.9790643447389206, disc_loss = 0.0010408960791513284
Trained batch 96 in epoch 5, gen_loss = 0.9789227695809197, disc_loss = 0.001039328810593267
Trained batch 97 in epoch 5, gen_loss = 0.9789268599480999, disc_loss = 0.0010380568039218647
Trained batch 98 in epoch 5, gen_loss = 0.9786742654713717, disc_loss = 0.0010363006158237995
Trained batch 99 in epoch 5, gen_loss = 0.9785357767343521, disc_loss = 0.001034349712135736
Trained batch 100 in epoch 5, gen_loss = 0.9781518985729406, disc_loss = 0.0010326977563897461
Trained batch 101 in epoch 5, gen_loss = 0.9776417975332222, disc_loss = 0.0010320455205110907
Trained batch 102 in epoch 5, gen_loss = 0.9769738524862863, disc_loss = 0.0010337418584419795
Trained batch 103 in epoch 5, gen_loss = 0.977018035375155, disc_loss = 0.0010338130766915409
Trained batch 104 in epoch 5, gen_loss = 0.9772482599530902, disc_loss = 0.00103230354392768
Trained batch 105 in epoch 5, gen_loss = 0.9771815538406372, disc_loss = 0.0010297791227887227
Trained batch 106 in epoch 5, gen_loss = 0.9770125897131233, disc_loss = 0.0010279422758090544
Trained batch 107 in epoch 5, gen_loss = 0.9770570066240098, disc_loss = 0.0010234802361487204
Trained batch 108 in epoch 5, gen_loss = 0.9771797000815016, disc_loss = 0.0010174674813960328
Trained batch 109 in epoch 5, gen_loss = 0.9776479894464666, disc_loss = 0.0010119079424343496
Trained batch 110 in epoch 5, gen_loss = 0.9773250893429593, disc_loss = 0.0010059615840971772
Trained batch 111 in epoch 5, gen_loss = 0.9772851419235978, disc_loss = 0.0009997319131278865
Trained batch 112 in epoch 5, gen_loss = 0.9771772369874262, disc_loss = 0.0009940058936620444
Trained batch 113 in epoch 5, gen_loss = 0.9770140825656423, disc_loss = 0.0009877988180194638
Trained batch 114 in epoch 5, gen_loss = 0.9771712038827979, disc_loss = 0.000981703817176268
Trained batch 115 in epoch 5, gen_loss = 0.9770693023656977, disc_loss = 0.0009761912196750175
Trained batch 116 in epoch 5, gen_loss = 0.9766708913012447, disc_loss = 0.0009702391102591641
Trained batch 117 in epoch 5, gen_loss = 0.9768250352245266, disc_loss = 0.0009642929850951216
Trained batch 118 in epoch 5, gen_loss = 0.9767279043918898, disc_loss = 0.0009583239859369184
Trained batch 119 in epoch 5, gen_loss = 0.9769932130972544, disc_loss = 0.0009528120431544569
Trained batch 120 in epoch 5, gen_loss = 0.9767294752696329, disc_loss = 0.0009478939841943985
Trained batch 121 in epoch 5, gen_loss = 0.9769819227398419, disc_loss = 0.0009450029014499064
Trained batch 122 in epoch 5, gen_loss = 0.9769151506385183, disc_loss = 0.0009410530101598763
Trained batch 123 in epoch 5, gen_loss = 0.9769653221291881, disc_loss = 0.0009378660348198948
Trained batch 124 in epoch 5, gen_loss = 0.9772249073982239, disc_loss = 0.0009355781590566039
Trained batch 125 in epoch 5, gen_loss = 0.977384791960792, disc_loss = 0.0009326803496122242
Trained batch 126 in epoch 5, gen_loss = 0.977209714923318, disc_loss = 0.0009284388907822069
Trained batch 127 in epoch 5, gen_loss = 0.977061630692333, disc_loss = 0.0009242034168437385
Trained batch 128 in epoch 5, gen_loss = 0.9772942264874777, disc_loss = 0.0009216736903316666
Trained batch 129 in epoch 5, gen_loss = 0.9774944759332217, disc_loss = 0.0009191461008203288
Trained batch 130 in epoch 5, gen_loss = 0.9778834649624716, disc_loss = 0.0009167165593652922
Trained batch 131 in epoch 5, gen_loss = 0.9778662102692055, disc_loss = 0.0009138775986326491
Trained batch 132 in epoch 5, gen_loss = 0.9782038089027978, disc_loss = 0.0009109260406278606
Trained batch 133 in epoch 5, gen_loss = 0.9784989850734597, disc_loss = 0.0009082375728931806
Trained batch 134 in epoch 5, gen_loss = 0.9785111038773148, disc_loss = 0.000905194408820804
Trained batch 135 in epoch 5, gen_loss = 0.978614000713124, disc_loss = 0.000902219981285538
Trained batch 136 in epoch 5, gen_loss = 0.9787572665806235, disc_loss = 0.0008985335094408969
Trained batch 137 in epoch 5, gen_loss = 0.9788905589476876, disc_loss = 0.0008965306909015889
Trained batch 138 in epoch 5, gen_loss = 0.9786625851830133, disc_loss = 0.0008974890838119222
Trained batch 139 in epoch 5, gen_loss = 0.9788241471563067, disc_loss = 0.0008984744866860898
Trained batch 140 in epoch 5, gen_loss = 0.9788162403918327, disc_loss = 0.0008979263132956566
Trained batch 141 in epoch 5, gen_loss = 0.9786975870669727, disc_loss = 0.0008980736829599523
Trained batch 142 in epoch 5, gen_loss = 0.9786481448820421, disc_loss = 0.0008965100463352759
Trained batch 143 in epoch 5, gen_loss = 0.9783381070527766, disc_loss = 0.0008934128907438006
Trained batch 144 in epoch 5, gen_loss = 0.9785844330129952, disc_loss = 0.0008911956121727567
Trained batch 145 in epoch 5, gen_loss = 0.9786826490539394, disc_loss = 0.0008885550778359175
Trained batch 146 in epoch 5, gen_loss = 0.9789469878689773, disc_loss = 0.0008855333278940826
Trained batch 147 in epoch 5, gen_loss = 0.9788351638897045, disc_loss = 0.0008829103818562864
Trained batch 148 in epoch 5, gen_loss = 0.9786962442750099, disc_loss = 0.000883289514189186
Trained batch 149 in epoch 5, gen_loss = 0.9785809846719106, disc_loss = 0.0008888459273536379
Trained batch 150 in epoch 5, gen_loss = 0.9787072476172289, disc_loss = 0.0009001048028527679
Trained batch 151 in epoch 5, gen_loss = 0.9784048007507073, disc_loss = 0.0009130178895199941
Trained batch 152 in epoch 5, gen_loss = 0.9785510009410334, disc_loss = 0.0009268107890604929
Trained batch 153 in epoch 5, gen_loss = 0.9786073472592738, disc_loss = 0.0009385294607135939
Trained batch 154 in epoch 5, gen_loss = 0.9786957060137103, disc_loss = 0.0009458878173327614
Trained batch 155 in epoch 5, gen_loss = 0.9784347926959013, disc_loss = 0.000948726188933226
Trained batch 156 in epoch 5, gen_loss = 0.9788054144306547, disc_loss = 0.0009501171800690543
Trained batch 157 in epoch 5, gen_loss = 0.9788602545291563, disc_loss = 0.0009498060811708881
Trained batch 158 in epoch 5, gen_loss = 0.9788452548051031, disc_loss = 0.000948723721714784
Trained batch 159 in epoch 5, gen_loss = 0.978711074963212, disc_loss = 0.0009472810275838129
Trained batch 160 in epoch 5, gen_loss = 0.9791225739147352, disc_loss = 0.0009480297125468135
Trained batch 161 in epoch 5, gen_loss = 0.9792055793014574, disc_loss = 0.000951440064028124
Trained batch 162 in epoch 5, gen_loss = 0.9790639859035702, disc_loss = 0.0009547687795204596
Trained batch 163 in epoch 5, gen_loss = 0.9787624903568407, disc_loss = 0.0009564534317710573
Trained batch 164 in epoch 5, gen_loss = 0.9787591735521952, disc_loss = 0.0009577047515477082
Trained batch 165 in epoch 5, gen_loss = 0.9786511577037443, disc_loss = 0.0009586469265730513
Trained batch 166 in epoch 5, gen_loss = 0.9784096482985034, disc_loss = 0.0009586612401532935
Trained batch 167 in epoch 5, gen_loss = 0.9782968727605683, disc_loss = 0.0009587483248088531
Trained batch 168 in epoch 5, gen_loss = 0.9782871977817378, disc_loss = 0.0009594090834339894
Trained batch 169 in epoch 5, gen_loss = 0.9782481645836549, disc_loss = 0.0009601298241999329
Trained batch 170 in epoch 5, gen_loss = 0.9782632679967155, disc_loss = 0.000960302738131062
Trained batch 171 in epoch 5, gen_loss = 0.9783148155655972, disc_loss = 0.0009603100457583381
Trained batch 172 in epoch 5, gen_loss = 0.9783630505462603, disc_loss = 0.0009602526042306246
Trained batch 173 in epoch 5, gen_loss = 0.9784460821370969, disc_loss = 0.0009593024280192545
Trained batch 174 in epoch 5, gen_loss = 0.9784977350916181, disc_loss = 0.0009571721499586212
Trained batch 175 in epoch 5, gen_loss = 0.97854408249259, disc_loss = 0.0009541541246355998
Trained batch 176 in epoch 5, gen_loss = 0.9786594577428311, disc_loss = 0.0009508194261438366
Trained batch 177 in epoch 5, gen_loss = 0.9785914839653487, disc_loss = 0.0009474696689926276
Trained batch 178 in epoch 5, gen_loss = 0.9787802739516317, disc_loss = 0.0009438707312769334
Trained batch 179 in epoch 5, gen_loss = 0.9786831792857912, disc_loss = 0.0009406009845810736
Trained batch 180 in epoch 5, gen_loss = 0.9789757586974466, disc_loss = 0.000938242260985416
Trained batch 181 in epoch 5, gen_loss = 0.9787715768421089, disc_loss = 0.0009387410560860759
Trained batch 182 in epoch 5, gen_loss = 0.9789895154739339, disc_loss = 0.0009401877981017705
Trained batch 183 in epoch 5, gen_loss = 0.9791657163397126, disc_loss = 0.0009411534463098454
Trained batch 184 in epoch 5, gen_loss = 0.9791973233222961, disc_loss = 0.0009402776453203547
Trained batch 185 in epoch 5, gen_loss = 0.9791867781069971, disc_loss = 0.0009395914427342734
Trained batch 186 in epoch 5, gen_loss = 0.9792317544075257, disc_loss = 0.000939962916533129
Trained batch 187 in epoch 5, gen_loss = 0.9794956664455697, disc_loss = 0.0009398136789194665
Trained batch 188 in epoch 5, gen_loss = 0.9793400184187309, disc_loss = 0.0009388633492148959
Trained batch 189 in epoch 5, gen_loss = 0.9789354631775304, disc_loss = 0.0009380231113601966
Trained batch 190 in epoch 5, gen_loss = 0.9789420787576606, disc_loss = 0.0009380423408111372
Trained batch 191 in epoch 5, gen_loss = 0.978964576497674, disc_loss = 0.0009412718398683259
Trained batch 192 in epoch 5, gen_loss = 0.9789668871331091, disc_loss = 0.0009456481442272836
Trained batch 193 in epoch 5, gen_loss = 0.9790238781073659, disc_loss = 0.0009488908715903779
Trained batch 194 in epoch 5, gen_loss = 0.979210325387808, disc_loss = 0.0009512967891238917
Trained batch 195 in epoch 5, gen_loss = 0.9792236366442272, disc_loss = 0.0009547865325026689
Trained batch 196 in epoch 5, gen_loss = 0.9792324604116721, disc_loss = 0.0009599269379868744
Trained batch 197 in epoch 5, gen_loss = 0.9789511456031992, disc_loss = 0.0009662784217689845
Trained batch 198 in epoch 5, gen_loss = 0.9787945310075079, disc_loss = 0.0009717821424660839
Trained batch 199 in epoch 5, gen_loss = 0.9787668013572692, disc_loss = 0.0009757293366419618
Trained batch 200 in epoch 5, gen_loss = 0.9788945942968872, disc_loss = 0.000980927916017792
Trained batch 201 in epoch 5, gen_loss = 0.9787011745542583, disc_loss = 0.000989796512092851
Trained batch 202 in epoch 5, gen_loss = 0.9786438269568194, disc_loss = 0.0010021326805664493
Trained batch 203 in epoch 5, gen_loss = 0.9784743023269317, disc_loss = 0.0010116486275150878
Trained batch 204 in epoch 5, gen_loss = 0.9783496595010525, disc_loss = 0.001016737001794731
Trained batch 205 in epoch 5, gen_loss = 0.9783275358885237, disc_loss = 0.0010193170488244645
Trained batch 206 in epoch 5, gen_loss = 0.9784352693004884, disc_loss = 0.0010205260473742164
Trained batch 207 in epoch 5, gen_loss = 0.97822855756833, disc_loss = 0.0010217688772032629
Trained batch 208 in epoch 5, gen_loss = 0.9782932380740152, disc_loss = 0.0010243632952386345
Trained batch 209 in epoch 5, gen_loss = 0.9782916999998547, disc_loss = 0.0010270907134760083
Trained batch 210 in epoch 5, gen_loss = 0.9780456065001646, disc_loss = 0.0010274629219229911
Trained batch 211 in epoch 5, gen_loss = 0.978056308795821, disc_loss = 0.0010274964916565947
Trained batch 212 in epoch 5, gen_loss = 0.9780659837901872, disc_loss = 0.0010295193988071238
Trained batch 213 in epoch 5, gen_loss = 0.9781176887940024, disc_loss = 0.0010325412569778631
Trained batch 214 in epoch 5, gen_loss = 0.9783669266589853, disc_loss = 0.0010354009842727507
Trained batch 215 in epoch 5, gen_loss = 0.978313938887031, disc_loss = 0.0010396572617065868
Trained batch 216 in epoch 5, gen_loss = 0.9783312675590339, disc_loss = 0.0010470701431188182
Trained batch 217 in epoch 5, gen_loss = 0.978303291382046, disc_loss = 0.001054136679158546
Trained batch 218 in epoch 5, gen_loss = 0.9782843529905902, disc_loss = 0.00105848174914824
Trained batch 219 in epoch 5, gen_loss = 0.9782433992082422, disc_loss = 0.0010604161564101973
Trained batch 220 in epoch 5, gen_loss = 0.9784881108486814, disc_loss = 0.0010612631377045537
Trained batch 221 in epoch 5, gen_loss = 0.9785402997120006, disc_loss = 0.001061181272070662
Trained batch 222 in epoch 5, gen_loss = 0.9784739263389143, disc_loss = 0.001059833156689375
Trained batch 223 in epoch 5, gen_loss = 0.9786594994366169, disc_loss = 0.0010580740328285693
Trained batch 224 in epoch 5, gen_loss = 0.9787519489394294, disc_loss = 0.0010560175050826123
Trained batch 225 in epoch 5, gen_loss = 0.9787609996521367, disc_loss = 0.001054672343915007
Trained batch 226 in epoch 5, gen_loss = 0.9787093327434052, disc_loss = 0.0010544561665855956
Trained batch 227 in epoch 5, gen_loss = 0.9787145884413468, disc_loss = 0.0010529171639446805
Trained batch 228 in epoch 5, gen_loss = 0.9785983505207378, disc_loss = 0.0010500971543578243
Trained batch 229 in epoch 5, gen_loss = 0.9787472595339236, disc_loss = 0.0010475726354027006
Trained batch 230 in epoch 5, gen_loss = 0.9785575440951756, disc_loss = 0.0010450002101090742
Trained batch 231 in epoch 5, gen_loss = 0.9787981281506604, disc_loss = 0.0010421837226925257
Trained batch 232 in epoch 5, gen_loss = 0.9788403705465947, disc_loss = 0.0010394146749619873
Trained batch 233 in epoch 5, gen_loss = 0.9788349003363879, disc_loss = 0.0010375839044413585
Trained batch 234 in epoch 5, gen_loss = 0.9789066180269769, disc_loss = 0.0010364464319439883
Trained batch 235 in epoch 5, gen_loss = 0.9788383914757584, disc_loss = 0.001034474749018446
Trained batch 236 in epoch 5, gen_loss = 0.9789456161768627, disc_loss = 0.0010316905372516735
Trained batch 237 in epoch 5, gen_loss = 0.9788974951796171, disc_loss = 0.0010293504370458644
Trained batch 238 in epoch 5, gen_loss = 0.9787682965709574, disc_loss = 0.0010276511883865807
Trained batch 239 in epoch 5, gen_loss = 0.9787533591190974, disc_loss = 0.0010263657015457284
Trained batch 240 in epoch 5, gen_loss = 0.9788828855728213, disc_loss = 0.0010246237683403635
Trained batch 241 in epoch 5, gen_loss = 0.9788128497186771, disc_loss = 0.001022313427312823
Trained batch 242 in epoch 5, gen_loss = 0.9788249017279825, disc_loss = 0.0010199515529143634
Trained batch 243 in epoch 5, gen_loss = 0.9787843664650058, disc_loss = 0.0010173419212777411
Trained batch 244 in epoch 5, gen_loss = 0.9787204766760067, disc_loss = 0.0010147404512485527
Trained batch 245 in epoch 5, gen_loss = 0.9788586211398365, disc_loss = 0.001012983476379659
Trained batch 246 in epoch 5, gen_loss = 0.9787707632852469, disc_loss = 0.0010118126913505466
Trained batch 247 in epoch 5, gen_loss = 0.9787390683927844, disc_loss = 0.0010104571636240448
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.9845811724662781, disc_loss = 0.0005742670618928969
Trained batch 1 in epoch 6, gen_loss = 0.9733410775661469, disc_loss = 0.0005922870768699795
Trained batch 2 in epoch 6, gen_loss = 0.9873205622037252, disc_loss = 0.0005969201059391102
Trained batch 3 in epoch 6, gen_loss = 0.9802867323160172, disc_loss = 0.0005780298379249871
Trained batch 4 in epoch 6, gen_loss = 0.9799999117851257, disc_loss = 0.0005566538777202368
Trained batch 5 in epoch 6, gen_loss = 0.9813846945762634, disc_loss = 0.0005366946085511396
Trained batch 6 in epoch 6, gen_loss = 0.9869132893426078, disc_loss = 0.0005323454721032508
Trained batch 7 in epoch 6, gen_loss = 0.9832433089613914, disc_loss = 0.0005532607247005217
Trained batch 8 in epoch 6, gen_loss = 0.9797763029734293, disc_loss = 0.0006281981800889804
Trained batch 9 in epoch 6, gen_loss = 0.9795696854591369, disc_loss = 0.0006996929587330669
Trained batch 10 in epoch 6, gen_loss = 0.9798307418823242, disc_loss = 0.0007366156787611544
Trained batch 11 in epoch 6, gen_loss = 0.9777995049953461, disc_loss = 0.0007241680577863008
Trained batch 12 in epoch 6, gen_loss = 0.977688940671774, disc_loss = 0.0007332156842144636
Trained batch 13 in epoch 6, gen_loss = 0.97836862717356, disc_loss = 0.0007692676569734301
Trained batch 14 in epoch 6, gen_loss = 0.976354432106018, disc_loss = 0.0007945242105051875
Trained batch 15 in epoch 6, gen_loss = 0.9758818931877613, disc_loss = 0.0007882761747168843
Trained batch 16 in epoch 6, gen_loss = 0.976607175434337, disc_loss = 0.0007652314807808794
Trained batch 17 in epoch 6, gen_loss = 0.9755504462454054, disc_loss = 0.000736835854089198
Trained batch 18 in epoch 6, gen_loss = 0.97658308869914, disc_loss = 0.0007118699110211118
Trained batch 19 in epoch 6, gen_loss = 0.9765938311815262, disc_loss = 0.0006960203521884978
Trained batch 20 in epoch 6, gen_loss = 0.9772448908715021, disc_loss = 0.0006799978409184231
Trained batch 21 in epoch 6, gen_loss = 0.9772925593636252, disc_loss = 0.0006616470200242475
Trained batch 22 in epoch 6, gen_loss = 0.9784312870191492, disc_loss = 0.000647809404535624
Trained batch 23 in epoch 6, gen_loss = 0.9790020634730657, disc_loss = 0.0006318096044803193
Trained batch 24 in epoch 6, gen_loss = 0.9772566318511963, disc_loss = 0.0006180022552143783
Trained batch 25 in epoch 6, gen_loss = 0.9780900340813857, disc_loss = 0.0006082792007453883
Trained batch 26 in epoch 6, gen_loss = 0.9802851721092507, disc_loss = 0.0006025300686747802
Trained batch 27 in epoch 6, gen_loss = 0.9808377857719149, disc_loss = 0.000598357106874963
Trained batch 28 in epoch 6, gen_loss = 0.9781496812557352, disc_loss = 0.0006064996183528725
Trained batch 29 in epoch 6, gen_loss = 0.9776284297307333, disc_loss = 0.0006328869281181444
Trained batch 30 in epoch 6, gen_loss = 0.9773407097785703, disc_loss = 0.0006769065831547543
Trained batch 31 in epoch 6, gen_loss = 0.9769219979643822, disc_loss = 0.000732832077119383
Trained batch 32 in epoch 6, gen_loss = 0.976095848011248, disc_loss = 0.0007870132015368929
Trained batch 33 in epoch 6, gen_loss = 0.9771133959293365, disc_loss = 0.0008143371926374076
Trained batch 34 in epoch 6, gen_loss = 0.9758016637393406, disc_loss = 0.000826926514439817
Trained batch 35 in epoch 6, gen_loss = 0.9757741871807311, disc_loss = 0.0008326079421547345
Trained batch 36 in epoch 6, gen_loss = 0.9753805898331307, disc_loss = 0.000832217838300543
Trained batch 37 in epoch 6, gen_loss = 0.9775782211830741, disc_loss = 0.0008333420739386623
Trained batch 38 in epoch 6, gen_loss = 0.9774665939502227, disc_loss = 0.0008398925972123367
Trained batch 39 in epoch 6, gen_loss = 0.9775314703583717, disc_loss = 0.0008656467121909373
Trained batch 40 in epoch 6, gen_loss = 0.9770362508006212, disc_loss = 0.0008944043159916452
Trained batch 41 in epoch 6, gen_loss = 0.9761432040305364, disc_loss = 0.0009154412975823064
Trained batch 42 in epoch 6, gen_loss = 0.9765871957291005, disc_loss = 0.0009293109056713103
Trained batch 43 in epoch 6, gen_loss = 0.9768786281347275, disc_loss = 0.0009383645149434662
Trained batch 44 in epoch 6, gen_loss = 0.9765799827045865, disc_loss = 0.0009420331683941185
Trained batch 45 in epoch 6, gen_loss = 0.97602527944938, disc_loss = 0.000941552710213253
Trained batch 46 in epoch 6, gen_loss = 0.9762946329218276, disc_loss = 0.0009436815669958262
Trained batch 47 in epoch 6, gen_loss = 0.9761519022285938, disc_loss = 0.0009476480287654946
Trained batch 48 in epoch 6, gen_loss = 0.9765285642779603, disc_loss = 0.0009473237810105237
Trained batch 49 in epoch 6, gen_loss = 0.9774899935722351, disc_loss = 0.0009439325833227486
Trained batch 50 in epoch 6, gen_loss = 0.9779976582994648, disc_loss = 0.0009426145686530599
Trained batch 51 in epoch 6, gen_loss = 0.9773343790035981, disc_loss = 0.0009433728029342511
Trained batch 52 in epoch 6, gen_loss = 0.9774494643481273, disc_loss = 0.0009451228422376345
Trained batch 53 in epoch 6, gen_loss = 0.9768909712632498, disc_loss = 0.0009444504588221511
Trained batch 54 in epoch 6, gen_loss = 0.977240480076183, disc_loss = 0.0009422929999841885
Trained batch 55 in epoch 6, gen_loss = 0.9773741832801274, disc_loss = 0.0009390933960925654
Trained batch 56 in epoch 6, gen_loss = 0.9774977460242155, disc_loss = 0.0009301747614109333
Trained batch 57 in epoch 6, gen_loss = 0.9770419628455721, disc_loss = 0.0009196091027817978
Trained batch 58 in epoch 6, gen_loss = 0.9771260002912101, disc_loss = 0.0009116370362127041
Trained batch 59 in epoch 6, gen_loss = 0.977158788839976, disc_loss = 0.0009050197186297737
Trained batch 60 in epoch 6, gen_loss = 0.9771523299764414, disc_loss = 0.0008979155419615753
Trained batch 61 in epoch 6, gen_loss = 0.9771828286109432, disc_loss = 0.0008898885585480339
Trained batch 62 in epoch 6, gen_loss = 0.9775393652537513, disc_loss = 0.0008830828144074609
Trained batch 63 in epoch 6, gen_loss = 0.977344362065196, disc_loss = 0.0008816979920993617
Trained batch 64 in epoch 6, gen_loss = 0.9772769359441904, disc_loss = 0.0008844445087911132
Trained batch 65 in epoch 6, gen_loss = 0.9775235391024387, disc_loss = 0.0008830170814745185
Trained batch 66 in epoch 6, gen_loss = 0.9768315411325711, disc_loss = 0.0008790324178850974
Trained batch 67 in epoch 6, gen_loss = 0.9767824376330656, disc_loss = 0.0008733892262920135
Trained batch 68 in epoch 6, gen_loss = 0.9767433923223744, disc_loss = 0.0008672356843421965
Trained batch 69 in epoch 6, gen_loss = 0.9761581148420061, disc_loss = 0.0008609752802710448
Trained batch 70 in epoch 6, gen_loss = 0.9760552166213452, disc_loss = 0.0008567799830441953
Trained batch 71 in epoch 6, gen_loss = 0.9762838184833527, disc_loss = 0.0008580443892343384
Trained batch 72 in epoch 6, gen_loss = 0.9766537881877324, disc_loss = 0.0008630163868736119
Trained batch 73 in epoch 6, gen_loss = 0.9761576169245952, disc_loss = 0.0008709737197244289
Trained batch 74 in epoch 6, gen_loss = 0.9762077713012696, disc_loss = 0.0008796527252222101
Trained batch 75 in epoch 6, gen_loss = 0.9753772083081698, disc_loss = 0.0008843958341075402
Trained batch 76 in epoch 6, gen_loss = 0.9754008255995713, disc_loss = 0.0008851866262009391
Trained batch 77 in epoch 6, gen_loss = 0.9753506764387473, disc_loss = 0.0008831094190752945
Trained batch 78 in epoch 6, gen_loss = 0.9756115546709374, disc_loss = 0.0008768165267449863
Trained batch 79 in epoch 6, gen_loss = 0.975350733101368, disc_loss = 0.0008688847177836578
Trained batch 80 in epoch 6, gen_loss = 0.9755602434829429, disc_loss = 0.0008616279189066708
Trained batch 81 in epoch 6, gen_loss = 0.9758525905085773, disc_loss = 0.0008554146653495547
Trained batch 82 in epoch 6, gen_loss = 0.975727520075189, disc_loss = 0.0008494122681791434
Trained batch 83 in epoch 6, gen_loss = 0.9758354262227104, disc_loss = 0.000844369152522025
Trained batch 84 in epoch 6, gen_loss = 0.9753834044232088, disc_loss = 0.0008404771735727349
Trained batch 85 in epoch 6, gen_loss = 0.9754404959290527, disc_loss = 0.0008384388767258632
Trained batch 86 in epoch 6, gen_loss = 0.9753455040098606, disc_loss = 0.000837033789139241
Trained batch 87 in epoch 6, gen_loss = 0.9752408814701167, disc_loss = 0.000834570913866628
Trained batch 88 in epoch 6, gen_loss = 0.976183795527126, disc_loss = 0.0008400121443444507
Trained batch 89 in epoch 6, gen_loss = 0.9762075867917802, disc_loss = 0.0008440389601875925
Trained batch 90 in epoch 6, gen_loss = 0.9760241410234473, disc_loss = 0.0008484006451268854
Trained batch 91 in epoch 6, gen_loss = 0.9762104795030926, disc_loss = 0.0008522257602358561
Trained batch 92 in epoch 6, gen_loss = 0.9757704331028846, disc_loss = 0.0008536924035989389
Trained batch 93 in epoch 6, gen_loss = 0.9758568456832398, disc_loss = 0.0008513130739261892
Trained batch 94 in epoch 6, gen_loss = 0.9759419955705342, disc_loss = 0.0008466729183534258
Trained batch 95 in epoch 6, gen_loss = 0.9761759769171476, disc_loss = 0.0008413223486058996
Trained batch 96 in epoch 6, gen_loss = 0.9758293014211753, disc_loss = 0.0008368063520054458
Trained batch 97 in epoch 6, gen_loss = 0.975631097749788, disc_loss = 0.0008345263688207357
Trained batch 98 in epoch 6, gen_loss = 0.9754536013410549, disc_loss = 0.0008346742163694491
Trained batch 99 in epoch 6, gen_loss = 0.9753352403640747, disc_loss = 0.0008384349179686979
Trained batch 100 in epoch 6, gen_loss = 0.975150986473159, disc_loss = 0.0008448081034567612
Trained batch 101 in epoch 6, gen_loss = 0.9750262498855591, disc_loss = 0.000851451625303347
Trained batch 102 in epoch 6, gen_loss = 0.9753709556986985, disc_loss = 0.0008602264315766978
Trained batch 103 in epoch 6, gen_loss = 0.9754353538155556, disc_loss = 0.0008690632289821784
Trained batch 104 in epoch 6, gen_loss = 0.9754630457787287, disc_loss = 0.0008757289637634087
Trained batch 105 in epoch 6, gen_loss = 0.9753509326925818, disc_loss = 0.0008794940719249184
Trained batch 106 in epoch 6, gen_loss = 0.975534552725676, disc_loss = 0.0008798101030194383
Trained batch 107 in epoch 6, gen_loss = 0.9757287447099332, disc_loss = 0.0008779527577442221
Trained batch 108 in epoch 6, gen_loss = 0.9755715459858606, disc_loss = 0.0008743795162545295
Trained batch 109 in epoch 6, gen_loss = 0.9754285297610543, disc_loss = 0.0008700852933212776
Trained batch 110 in epoch 6, gen_loss = 0.9752058043136252, disc_loss = 0.0008658742435645681
Trained batch 111 in epoch 6, gen_loss = 0.9747098710920129, disc_loss = 0.0008618459521260645
Trained batch 112 in epoch 6, gen_loss = 0.9747811249927082, disc_loss = 0.0008571845478279335
Trained batch 113 in epoch 6, gen_loss = 0.974890483053107, disc_loss = 0.0008527470947643579
Trained batch 114 in epoch 6, gen_loss = 0.9747777576031892, disc_loss = 0.0008491421973778178
Trained batch 115 in epoch 6, gen_loss = 0.9750591310961493, disc_loss = 0.000848357465844762
Trained batch 116 in epoch 6, gen_loss = 0.9747171035179725, disc_loss = 0.0008512608976596887
Trained batch 117 in epoch 6, gen_loss = 0.9744246248471535, disc_loss = 0.0008565397786126488
Trained batch 118 in epoch 6, gen_loss = 0.9742500842118463, disc_loss = 0.0008614007858050784
Trained batch 119 in epoch 6, gen_loss = 0.9741138403614362, disc_loss = 0.000864230442190698
Trained batch 120 in epoch 6, gen_loss = 0.9742383577606895, disc_loss = 0.0008648371801149746
Trained batch 121 in epoch 6, gen_loss = 0.9743832906738656, disc_loss = 0.0008641819977277859
Trained batch 122 in epoch 6, gen_loss = 0.9742659868263617, disc_loss = 0.0008629052241983997
Trained batch 123 in epoch 6, gen_loss = 0.9746020979458286, disc_loss = 0.0008625677343638193
Trained batch 124 in epoch 6, gen_loss = 0.9744077715873718, disc_loss = 0.0008636597823351622
Trained batch 125 in epoch 6, gen_loss = 0.9745266125315711, disc_loss = 0.0008645550008781905
Trained batch 126 in epoch 6, gen_loss = 0.9749293937457828, disc_loss = 0.00086476748642387
Trained batch 127 in epoch 6, gen_loss = 0.9749489407986403, disc_loss = 0.0008630030956737755
Trained batch 128 in epoch 6, gen_loss = 0.9752866408621618, disc_loss = 0.0008604685837301866
Trained batch 129 in epoch 6, gen_loss = 0.975141572035276, disc_loss = 0.0008577851574115741
Trained batch 130 in epoch 6, gen_loss = 0.9753958423629062, disc_loss = 0.0008558775844827351
Trained batch 131 in epoch 6, gen_loss = 0.9756287218946399, disc_loss = 0.0008540963440971224
Trained batch 132 in epoch 6, gen_loss = 0.9756933513440584, disc_loss = 0.0008509339908263961
Trained batch 133 in epoch 6, gen_loss = 0.9755781688796941, disc_loss = 0.0008477169556418128
Trained batch 134 in epoch 6, gen_loss = 0.9754460648254112, disc_loss = 0.0008458071681498378
Trained batch 135 in epoch 6, gen_loss = 0.9754878172979635, disc_loss = 0.0008437008710804067
Trained batch 136 in epoch 6, gen_loss = 0.975547522088907, disc_loss = 0.0008408206894851024
Trained batch 137 in epoch 6, gen_loss = 0.9752977106018342, disc_loss = 0.00083885132208588
Trained batch 138 in epoch 6, gen_loss = 0.9753441763438767, disc_loss = 0.0008393808983252954
Trained batch 139 in epoch 6, gen_loss = 0.9754575554813657, disc_loss = 0.0008389620260069412
Trained batch 140 in epoch 6, gen_loss = 0.97527699183065, disc_loss = 0.0008370217562534232
Trained batch 141 in epoch 6, gen_loss = 0.9753231158558752, disc_loss = 0.0008347969072621683
Trained batch 142 in epoch 6, gen_loss = 0.9753659880244648, disc_loss = 0.0008327232118552694
Trained batch 143 in epoch 6, gen_loss = 0.9754480943083763, disc_loss = 0.0008306195369287808
Trained batch 144 in epoch 6, gen_loss = 0.9755310893058777, disc_loss = 0.0008283588039720881
Trained batch 145 in epoch 6, gen_loss = 0.9753164306078872, disc_loss = 0.0008261192706413567
Trained batch 146 in epoch 6, gen_loss = 0.9750892345597144, disc_loss = 0.000823577759442154
Trained batch 147 in epoch 6, gen_loss = 0.9754347180998003, disc_loss = 0.0008217196402649672
Trained batch 148 in epoch 6, gen_loss = 0.9756032204467978, disc_loss = 0.0008207203198424322
Trained batch 149 in epoch 6, gen_loss = 0.975440681775411, disc_loss = 0.0008182022724455843
Trained batch 150 in epoch 6, gen_loss = 0.9755993548607984, disc_loss = 0.0008160477760093694
Trained batch 151 in epoch 6, gen_loss = 0.9755382153548693, disc_loss = 0.0008156108225720297
Trained batch 152 in epoch 6, gen_loss = 0.9758088222516128, disc_loss = 0.0008159751442315824
Trained batch 153 in epoch 6, gen_loss = 0.9761034211555084, disc_loss = 0.0008159750042930729
Trained batch 154 in epoch 6, gen_loss = 0.9758471773516747, disc_loss = 0.0008154006945269723
Trained batch 155 in epoch 6, gen_loss = 0.9758921712636948, disc_loss = 0.000816692354885909
Trained batch 156 in epoch 6, gen_loss = 0.9756955060229939, disc_loss = 0.000817139962966892
Trained batch 157 in epoch 6, gen_loss = 0.9758879361273367, disc_loss = 0.0008173576685823971
Trained batch 158 in epoch 6, gen_loss = 0.9758122923239222, disc_loss = 0.0008169411016780438
Trained batch 159 in epoch 6, gen_loss = 0.9762286301702261, disc_loss = 0.0008170048276952002
Trained batch 160 in epoch 6, gen_loss = 0.9764335388722627, disc_loss = 0.0008156716777300983
Trained batch 161 in epoch 6, gen_loss = 0.9762342432398855, disc_loss = 0.000813321872645943
Trained batch 162 in epoch 6, gen_loss = 0.9763005789072235, disc_loss = 0.0008101180264372035
Trained batch 163 in epoch 6, gen_loss = 0.976851423339146, disc_loss = 0.000807433310156495
Trained batch 164 in epoch 6, gen_loss = 0.9768063111738725, disc_loss = 0.0008056761589338721
Trained batch 165 in epoch 6, gen_loss = 0.9768149526004332, disc_loss = 0.0008040367131589923
Trained batch 166 in epoch 6, gen_loss = 0.9769054644122095, disc_loss = 0.0008022327320775697
Trained batch 167 in epoch 6, gen_loss = 0.9765841733841669, disc_loss = 0.0007999832894364815
Trained batch 168 in epoch 6, gen_loss = 0.9765168336721567, disc_loss = 0.0007987070519383445
Trained batch 169 in epoch 6, gen_loss = 0.9764949910780962, disc_loss = 0.0007976911674417994
Trained batch 170 in epoch 6, gen_loss = 0.9767427395658883, disc_loss = 0.0007965748194245654
Trained batch 171 in epoch 6, gen_loss = 0.9769208209459171, disc_loss = 0.0007960163280205412
Trained batch 172 in epoch 6, gen_loss = 0.976992176791836, disc_loss = 0.0007964617504086884
Trained batch 173 in epoch 6, gen_loss = 0.9771432585414799, disc_loss = 0.000797841647083218
Trained batch 174 in epoch 6, gen_loss = 0.9771095156669617, disc_loss = 0.000801473384323929
Trained batch 175 in epoch 6, gen_loss = 0.9774104597216303, disc_loss = 0.0008051800495278175
Trained batch 176 in epoch 6, gen_loss = 0.977074846372766, disc_loss = 0.0008065695381107724
Trained batch 177 in epoch 6, gen_loss = 0.9770400139053216, disc_loss = 0.0008091591991839951
Trained batch 178 in epoch 6, gen_loss = 0.9774453310327157, disc_loss = 0.000812358621575521
Trained batch 179 in epoch 6, gen_loss = 0.9774981273545159, disc_loss = 0.0008148995189306636
Trained batch 180 in epoch 6, gen_loss = 0.977560474069079, disc_loss = 0.0008169813840572841
Trained batch 181 in epoch 6, gen_loss = 0.977409323493203, disc_loss = 0.0008174904895905446
Trained batch 182 in epoch 6, gen_loss = 0.9771988782726351, disc_loss = 0.0008165271980738868
Trained batch 183 in epoch 6, gen_loss = 0.9772254973649979, disc_loss = 0.0008141647905058167
Trained batch 184 in epoch 6, gen_loss = 0.9772330016703219, disc_loss = 0.0008114165580844053
Trained batch 185 in epoch 6, gen_loss = 0.9771845831025031, disc_loss = 0.0008099729954753252
Trained batch 186 in epoch 6, gen_loss = 0.9774130605121347, disc_loss = 0.0008093448762625038
Trained batch 187 in epoch 6, gen_loss = 0.9774663831959379, disc_loss = 0.0008079012169470475
Trained batch 188 in epoch 6, gen_loss = 0.9771881604951526, disc_loss = 0.0008058559747595123
Trained batch 189 in epoch 6, gen_loss = 0.9771001724820388, disc_loss = 0.0008046197306707894
Trained batch 190 in epoch 6, gen_loss = 0.9770633996469188, disc_loss = 0.0008045353692668583
Trained batch 191 in epoch 6, gen_loss = 0.9769920716062188, disc_loss = 0.0008049307998589939
Trained batch 192 in epoch 6, gen_loss = 0.9769767982972101, disc_loss = 0.0008058521029216097
Trained batch 193 in epoch 6, gen_loss = 0.9770171175298002, disc_loss = 0.0008063876770974434
Trained batch 194 in epoch 6, gen_loss = 0.9767195732165606, disc_loss = 0.0008067120075560151
Trained batch 195 in epoch 6, gen_loss = 0.9768267821292488, disc_loss = 0.0008083268957288594
Trained batch 196 in epoch 6, gen_loss = 0.9767727349615339, disc_loss = 0.0008114700094527249
Trained batch 197 in epoch 6, gen_loss = 0.9767882956398858, disc_loss = 0.0008146942286244171
Trained batch 198 in epoch 6, gen_loss = 0.9766910588321973, disc_loss = 0.0008186769254046993
Trained batch 199 in epoch 6, gen_loss = 0.9766034066677094, disc_loss = 0.0008266471308888868
Trained batch 200 in epoch 6, gen_loss = 0.9767676906206122, disc_loss = 0.0008385623185501541
Trained batch 201 in epoch 6, gen_loss = 0.976595155083307, disc_loss = 0.0008488591756939076
Trained batch 202 in epoch 6, gen_loss = 0.9764053075771614, disc_loss = 0.0008559198826413804
Trained batch 203 in epoch 6, gen_loss = 0.9765897726311403, disc_loss = 0.0008603905398380376
Trained batch 204 in epoch 6, gen_loss = 0.976623322324055, disc_loss = 0.000864453435443887
Trained batch 205 in epoch 6, gen_loss = 0.9764536332736895, disc_loss = 0.0008667455031084421
Trained batch 206 in epoch 6, gen_loss = 0.976630245141937, disc_loss = 0.000866094004061379
Trained batch 207 in epoch 6, gen_loss = 0.9766595664505775, disc_loss = 0.0008637550823690477
Trained batch 208 in epoch 6, gen_loss = 0.9767075845499358, disc_loss = 0.000861067371944224
Trained batch 209 in epoch 6, gen_loss = 0.976503376733689, disc_loss = 0.000859596208015102
Trained batch 210 in epoch 6, gen_loss = 0.9764450342169305, disc_loss = 0.0008593789964993771
Trained batch 211 in epoch 6, gen_loss = 0.9764893645385526, disc_loss = 0.000859505879661982
Trained batch 212 in epoch 6, gen_loss = 0.9767127378445836, disc_loss = 0.0008603039912512185
Trained batch 213 in epoch 6, gen_loss = 0.9768112558070744, disc_loss = 0.0008601178243760646
Trained batch 214 in epoch 6, gen_loss = 0.9768311894217203, disc_loss = 0.0008585690702095108
Trained batch 215 in epoch 6, gen_loss = 0.9769612892910287, disc_loss = 0.0008560347321488532
Trained batch 216 in epoch 6, gen_loss = 0.9770670978155004, disc_loss = 0.000853689951411221
Trained batch 217 in epoch 6, gen_loss = 0.9769351118748341, disc_loss = 0.0008525210455403911
Trained batch 218 in epoch 6, gen_loss = 0.9769368710583204, disc_loss = 0.0008525862665496103
Trained batch 219 in epoch 6, gen_loss = 0.976850006797097, disc_loss = 0.0008541278513307175
Trained batch 220 in epoch 6, gen_loss = 0.9768131833810073, disc_loss = 0.0008583030534636364
Trained batch 221 in epoch 6, gen_loss = 0.9771022203269305, disc_loss = 0.0008615052629302063
Trained batch 222 in epoch 6, gen_loss = 0.9770909090747748, disc_loss = 0.000862587438953723
Trained batch 223 in epoch 6, gen_loss = 0.9770436313535485, disc_loss = 0.0008627194088798465
Trained batch 224 in epoch 6, gen_loss = 0.9769867769877116, disc_loss = 0.0008618495518910802
Trained batch 225 in epoch 6, gen_loss = 0.9770761388065541, disc_loss = 0.0008601428250899637
Trained batch 226 in epoch 6, gen_loss = 0.9768715285519671, disc_loss = 0.0008576475967199742
Trained batch 227 in epoch 6, gen_loss = 0.9768092854504, disc_loss = 0.0008557033450638859
Trained batch 228 in epoch 6, gen_loss = 0.9768663152857119, disc_loss = 0.0008538429140861606
Trained batch 229 in epoch 6, gen_loss = 0.9769524032654969, disc_loss = 0.00085266718853508
Trained batch 230 in epoch 6, gen_loss = 0.977117094900701, disc_loss = 0.0008522400942941507
Trained batch 231 in epoch 6, gen_loss = 0.9771471403796097, disc_loss = 0.0008517719628610488
Trained batch 232 in epoch 6, gen_loss = 0.9772591017858153, disc_loss = 0.0008508156270064541
Trained batch 233 in epoch 6, gen_loss = 0.977336637994163, disc_loss = 0.000849876789879611
Trained batch 234 in epoch 6, gen_loss = 0.9773757138150804, disc_loss = 0.0008483242418151349
Trained batch 235 in epoch 6, gen_loss = 0.9773960083217944, disc_loss = 0.0008466245959980524
Trained batch 236 in epoch 6, gen_loss = 0.9773529858528813, disc_loss = 0.0008447176477437611
Trained batch 237 in epoch 6, gen_loss = 0.9773276648601564, disc_loss = 0.0008428818645286412
Trained batch 238 in epoch 6, gen_loss = 0.9773100858951712, disc_loss = 0.0008418667664757256
Trained batch 239 in epoch 6, gen_loss = 0.9772983382145564, disc_loss = 0.000842044341819322
Trained batch 240 in epoch 6, gen_loss = 0.977440174684485, disc_loss = 0.0008425697744910941
Trained batch 241 in epoch 6, gen_loss = 0.9774872833047031, disc_loss = 0.0008423279780627052
Trained batch 242 in epoch 6, gen_loss = 0.9775914473788728, disc_loss = 0.0008411509531728326
Trained batch 243 in epoch 6, gen_loss = 0.9777100472176661, disc_loss = 0.0008391789176174989
Trained batch 244 in epoch 6, gen_loss = 0.9776207247558906, disc_loss = 0.0008372791048509962
Trained batch 245 in epoch 6, gen_loss = 0.9776809431188475, disc_loss = 0.000836440151329228
Trained batch 246 in epoch 6, gen_loss = 0.9775784307645883, disc_loss = 0.0008366765853381425
Trained batch 247 in epoch 6, gen_loss = 0.9774725280942456, disc_loss = 0.0008371082042304483
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.9574010372161865, disc_loss = 0.0006694375188089907
Trained batch 1 in epoch 7, gen_loss = 0.959801435470581, disc_loss = 0.000579517480218783
Trained batch 2 in epoch 7, gen_loss = 0.970506489276886, disc_loss = 0.0005676077174333235
Trained batch 3 in epoch 7, gen_loss = 0.9718420952558517, disc_loss = 0.0007021748897386715
Trained batch 4 in epoch 7, gen_loss = 0.9687965512275696, disc_loss = 0.0009033689391799271
Trained batch 5 in epoch 7, gen_loss = 0.9745156864325205, disc_loss = 0.001005268646016096
Trained batch 6 in epoch 7, gen_loss = 0.9734507628849575, disc_loss = 0.0010506694920227996
Trained batch 7 in epoch 7, gen_loss = 0.9702607169747353, disc_loss = 0.0011308344328426756
Trained batch 8 in epoch 7, gen_loss = 0.9751742747094896, disc_loss = 0.0011989347080493139
Trained batch 9 in epoch 7, gen_loss = 0.9725799262523651, disc_loss = 0.0012292914499994368
Trained batch 10 in epoch 7, gen_loss = 0.9755484136668119, disc_loss = 0.0012358327406797218
Trained batch 11 in epoch 7, gen_loss = 0.9786681185166041, disc_loss = 0.0012068753955342497
Trained batch 12 in epoch 7, gen_loss = 0.9791777088091924, disc_loss = 0.0011657092299383993
Trained batch 13 in epoch 7, gen_loss = 0.98317922438894, disc_loss = 0.00113378231097678
Trained batch 14 in epoch 7, gen_loss = 0.9797674854596455, disc_loss = 0.0011315611695560317
Trained batch 15 in epoch 7, gen_loss = 0.9803509823977947, disc_loss = 0.0011884391315106768
Trained batch 16 in epoch 7, gen_loss = 0.9781734557712779, disc_loss = 0.0012667186674661934
Trained batch 17 in epoch 7, gen_loss = 0.9766175117757585, disc_loss = 0.0013270865407927583
Trained batch 18 in epoch 7, gen_loss = 0.9763325860625819, disc_loss = 0.0013580131436404038
Trained batch 19 in epoch 7, gen_loss = 0.9762152135372162, disc_loss = 0.0013686722930287942
Trained batch 20 in epoch 7, gen_loss = 0.9757660684131441, disc_loss = 0.0013722829226892265
Trained batch 21 in epoch 7, gen_loss = 0.9742540175264532, disc_loss = 0.0013698291123463687
Trained batch 22 in epoch 7, gen_loss = 0.9756327193716298, disc_loss = 0.001364337556246344
Trained batch 23 in epoch 7, gen_loss = 0.97569011648496, disc_loss = 0.001354689780176462
Trained batch 24 in epoch 7, gen_loss = 0.9740224862098694, disc_loss = 0.0013385654357261955
Trained batch 25 in epoch 7, gen_loss = 0.9734535790406741, disc_loss = 0.001322740368777886
Trained batch 26 in epoch 7, gen_loss = 0.9730263462773076, disc_loss = 0.0013186573460525661
Trained batch 27 in epoch 7, gen_loss = 0.9727149307727814, disc_loss = 0.0013501598878065124
Trained batch 28 in epoch 7, gen_loss = 0.9725806322591058, disc_loss = 0.0014233701232146344
Trained batch 29 in epoch 7, gen_loss = 0.9721867183844248, disc_loss = 0.0014986926515121012
Trained batch 30 in epoch 7, gen_loss = 0.9728937591275861, disc_loss = 0.0015658220828270479
Trained batch 31 in epoch 7, gen_loss = 0.9736468195915222, disc_loss = 0.0016018758160498692
Trained batch 32 in epoch 7, gen_loss = 0.9745927001490737, disc_loss = 0.001606745996413696
Trained batch 33 in epoch 7, gen_loss = 0.9737650313798119, disc_loss = 0.0015966383319156354
Trained batch 34 in epoch 7, gen_loss = 0.9729150005749294, disc_loss = 0.001570738632498043
Trained batch 35 in epoch 7, gen_loss = 0.9733986357847849, disc_loss = 0.001540264345951275
Trained batch 36 in epoch 7, gen_loss = 0.9718121580175452, disc_loss = 0.0015106342388379916
Trained batch 37 in epoch 7, gen_loss = 0.9718447798176816, disc_loss = 0.0014850068707202904
Trained batch 38 in epoch 7, gen_loss = 0.9727227687835693, disc_loss = 0.0014576953029833161
Trained batch 39 in epoch 7, gen_loss = 0.972251595556736, disc_loss = 0.0014278584028943441
Trained batch 40 in epoch 7, gen_loss = 0.9726838382279, disc_loss = 0.0014023736861772927
Trained batch 41 in epoch 7, gen_loss = 0.9719760190872919, disc_loss = 0.0013833783194145543
Trained batch 42 in epoch 7, gen_loss = 0.9719038910643999, disc_loss = 0.0013688393729078302
Trained batch 43 in epoch 7, gen_loss = 0.9713665612719276, disc_loss = 0.0013584354607949288
Trained batch 44 in epoch 7, gen_loss = 0.9714663598272536, disc_loss = 0.0013532002540563959
Trained batch 45 in epoch 7, gen_loss = 0.9707651138305664, disc_loss = 0.0013483904622262344
Trained batch 46 in epoch 7, gen_loss = 0.9716520892812851, disc_loss = 0.0013482449433835659
Trained batch 47 in epoch 7, gen_loss = 0.9715129062533379, disc_loss = 0.0013563172888098052
Trained batch 48 in epoch 7, gen_loss = 0.9709221270619607, disc_loss = 0.0013657726296366249
Trained batch 49 in epoch 7, gen_loss = 0.9703388333320617, disc_loss = 0.0013723138655768708
Trained batch 50 in epoch 7, gen_loss = 0.9694421513407838, disc_loss = 0.0013746033159002442
Trained batch 51 in epoch 7, gen_loss = 0.9695104280343423, disc_loss = 0.0013695393958746886
Trained batch 52 in epoch 7, gen_loss = 0.9706748510306736, disc_loss = 0.0013601338245932293
Trained batch 53 in epoch 7, gen_loss = 0.9706132709980011, disc_loss = 0.0013497252490466322
Trained batch 54 in epoch 7, gen_loss = 0.970161421732469, disc_loss = 0.0013383290979122235
Trained batch 55 in epoch 7, gen_loss = 0.9702358948332923, disc_loss = 0.0013262122660567652
Trained batch 56 in epoch 7, gen_loss = 0.9702152630739045, disc_loss = 0.0013145226061041875
Trained batch 57 in epoch 7, gen_loss = 0.9696517268131519, disc_loss = 0.0013060420846911789
Trained batch 58 in epoch 7, gen_loss = 0.9704000717502529, disc_loss = 0.0012966928815161336
Trained batch 59 in epoch 7, gen_loss = 0.9702737202246984, disc_loss = 0.001285376700980123
Trained batch 60 in epoch 7, gen_loss = 0.9712508555318489, disc_loss = 0.0012769171320184394
Trained batch 61 in epoch 7, gen_loss = 0.970868174106844, disc_loss = 0.0012668388479787315
Trained batch 62 in epoch 7, gen_loss = 0.9705701139238145, disc_loss = 0.00125669035921982
Trained batch 63 in epoch 7, gen_loss = 0.9705160604789853, disc_loss = 0.001245663629106275
Trained batch 64 in epoch 7, gen_loss = 0.9712566164823678, disc_loss = 0.0012349488325596142
Trained batch 65 in epoch 7, gen_loss = 0.9716404595158317, disc_loss = 0.0012264411740364846
Trained batch 66 in epoch 7, gen_loss = 0.9727643505850835, disc_loss = 0.0012182923543802115
Trained batch 67 in epoch 7, gen_loss = 0.9724933794316124, disc_loss = 0.0012086111686692353
Trained batch 68 in epoch 7, gen_loss = 0.9722199941026992, disc_loss = 0.0011981906157587587
Trained batch 69 in epoch 7, gen_loss = 0.9722975696836199, disc_loss = 0.0011877652785707532
Trained batch 70 in epoch 7, gen_loss = 0.9726117689844588, disc_loss = 0.001178998480842803
Trained batch 71 in epoch 7, gen_loss = 0.9734029016560979, disc_loss = 0.0011710604315643043
Trained batch 72 in epoch 7, gen_loss = 0.9731271332257414, disc_loss = 0.001162702061015832
Trained batch 73 in epoch 7, gen_loss = 0.9727246849923521, disc_loss = 0.0011557887770027879
Trained batch 74 in epoch 7, gen_loss = 0.9729832084973653, disc_loss = 0.001149630524450913
Trained batch 75 in epoch 7, gen_loss = 0.9734389648625725, disc_loss = 0.0011428425469172286
Trained batch 76 in epoch 7, gen_loss = 0.9738732769891814, disc_loss = 0.0011347614046543014
Trained batch 77 in epoch 7, gen_loss = 0.9739613487170293, disc_loss = 0.0011261767145837299
Trained batch 78 in epoch 7, gen_loss = 0.974072658562962, disc_loss = 0.0011179642390778076
Trained batch 79 in epoch 7, gen_loss = 0.9747328251600266, disc_loss = 0.001109455219557276
Trained batch 80 in epoch 7, gen_loss = 0.9753581491517432, disc_loss = 0.001099794153066605
Trained batch 81 in epoch 7, gen_loss = 0.9751335498763294, disc_loss = 0.001089264159750977
Trained batch 82 in epoch 7, gen_loss = 0.9753086459205811, disc_loss = 0.0010820782404317218
Trained batch 83 in epoch 7, gen_loss = 0.9756731994095302, disc_loss = 0.0010744404992562653
Trained batch 84 in epoch 7, gen_loss = 0.9756786143078523, disc_loss = 0.0010659190396408497
Trained batch 85 in epoch 7, gen_loss = 0.9756318573341813, disc_loss = 0.0010571536595518917
Trained batch 86 in epoch 7, gen_loss = 0.9755326118962518, disc_loss = 0.0010487881320831098
Trained batch 87 in epoch 7, gen_loss = 0.9755622561682354, disc_loss = 0.0010398684404539051
Trained batch 88 in epoch 7, gen_loss = 0.9755639340100664, disc_loss = 0.0010314761447456006
Trained batch 89 in epoch 7, gen_loss = 0.9760518266095055, disc_loss = 0.0010241957741931806
Trained batch 90 in epoch 7, gen_loss = 0.975844640653212, disc_loss = 0.0010179642251766912
Trained batch 91 in epoch 7, gen_loss = 0.9756118221127469, disc_loss = 0.0010116838974404939
Trained batch 92 in epoch 7, gen_loss = 0.9755957286844972, disc_loss = 0.001005173974854481
Trained batch 93 in epoch 7, gen_loss = 0.9752177031750374, disc_loss = 0.0009981397865402037
Trained batch 94 in epoch 7, gen_loss = 0.9758372614258214, disc_loss = 0.000991628389640123
Trained batch 95 in epoch 7, gen_loss = 0.9757058322429657, disc_loss = 0.000986218399854503
Trained batch 96 in epoch 7, gen_loss = 0.9760168409839118, disc_loss = 0.0009823131128082283
Trained batch 97 in epoch 7, gen_loss = 0.9756917965655424, disc_loss = 0.000978769327790657
Trained batch 98 in epoch 7, gen_loss = 0.9758903209609214, disc_loss = 0.0009756335487996105
Trained batch 99 in epoch 7, gen_loss = 0.9754117572307587, disc_loss = 0.0009722370353119913
Trained batch 100 in epoch 7, gen_loss = 0.9757475144792311, disc_loss = 0.000969426743461437
Trained batch 101 in epoch 7, gen_loss = 0.9761642872118482, disc_loss = 0.00096689767216209
Trained batch 102 in epoch 7, gen_loss = 0.9764029412593657, disc_loss = 0.000964222776107897
Trained batch 103 in epoch 7, gen_loss = 0.9763807619993503, disc_loss = 0.0009614421977368273
Trained batch 104 in epoch 7, gen_loss = 0.9764112251145499, disc_loss = 0.0009626222526310899
Trained batch 105 in epoch 7, gen_loss = 0.9765878465940367, disc_loss = 0.0009656170761170973
Trained batch 106 in epoch 7, gen_loss = 0.9766121172459326, disc_loss = 0.0009675031517268916
Trained batch 107 in epoch 7, gen_loss = 0.9766264419864725, disc_loss = 0.0009650917319824523
Trained batch 108 in epoch 7, gen_loss = 0.9764679785168499, disc_loss = 0.0009601941854754942
Trained batch 109 in epoch 7, gen_loss = 0.9766269402070479, disc_loss = 0.0009544946032375182
Trained batch 110 in epoch 7, gen_loss = 0.976372224790556, disc_loss = 0.0009485176327346766
Trained batch 111 in epoch 7, gen_loss = 0.9766335231917245, disc_loss = 0.0009432780385135889
Trained batch 112 in epoch 7, gen_loss = 0.9765933082167026, disc_loss = 0.0009407184955476478
Trained batch 113 in epoch 7, gen_loss = 0.9769004400362048, disc_loss = 0.0009453087880964423
Trained batch 114 in epoch 7, gen_loss = 0.9770577881647193, disc_loss = 0.0009594239528624989
Trained batch 115 in epoch 7, gen_loss = 0.9769991703074554, disc_loss = 0.0009758763572508229
Trained batch 116 in epoch 7, gen_loss = 0.9768385932995722, disc_loss = 0.0009898105249431732
Trained batch 117 in epoch 7, gen_loss = 0.9768878989300486, disc_loss = 0.0010008153287837896
Trained batch 118 in epoch 7, gen_loss = 0.9765738439159233, disc_loss = 0.0010086376682958886
Trained batch 119 in epoch 7, gen_loss = 0.9765449538826942, disc_loss = 0.00101056344974495
Trained batch 120 in epoch 7, gen_loss = 0.9766756655756107, disc_loss = 0.0010076328744767387
Trained batch 121 in epoch 7, gen_loss = 0.9764065840205208, disc_loss = 0.0010024410288172133
Trained batch 122 in epoch 7, gen_loss = 0.9763754867925877, disc_loss = 0.0009961848496696042
Trained batch 123 in epoch 7, gen_loss = 0.9766032465042607, disc_loss = 0.0009896139477683801
Trained batch 124 in epoch 7, gen_loss = 0.9766235685348511, disc_loss = 0.000982978309271857
Trained batch 125 in epoch 7, gen_loss = 0.9765233004850055, disc_loss = 0.0009769292191199456
Trained batch 126 in epoch 7, gen_loss = 0.9765460298755976, disc_loss = 0.000971360559489094
Trained batch 127 in epoch 7, gen_loss = 0.9765664879232645, disc_loss = 0.0009663609705512499
Trained batch 128 in epoch 7, gen_loss = 0.976803413657255, disc_loss = 0.0009627648452820271
Trained batch 129 in epoch 7, gen_loss = 0.9768762047474201, disc_loss = 0.0009605425976377984
Trained batch 130 in epoch 7, gen_loss = 0.9767054474080792, disc_loss = 0.0009572212853138371
Trained batch 131 in epoch 7, gen_loss = 0.976453010783051, disc_loss = 0.0009543392483134415
Trained batch 132 in epoch 7, gen_loss = 0.9762294019075265, disc_loss = 0.000952838029217017
Trained batch 133 in epoch 7, gen_loss = 0.9757994969389332, disc_loss = 0.0009528173447791626
Trained batch 134 in epoch 7, gen_loss = 0.9759669926431443, disc_loss = 0.0009525762299610371
Trained batch 135 in epoch 7, gen_loss = 0.9761047731427586, disc_loss = 0.0009506284779276672
Trained batch 136 in epoch 7, gen_loss = 0.9761377368530217, disc_loss = 0.000946993904951348
Trained batch 137 in epoch 7, gen_loss = 0.9759442879669908, disc_loss = 0.0009424536511305369
Trained batch 138 in epoch 7, gen_loss = 0.9758398339902754, disc_loss = 0.0009372003603451918
Trained batch 139 in epoch 7, gen_loss = 0.9759775566203254, disc_loss = 0.000932117215208044
Trained batch 140 in epoch 7, gen_loss = 0.9761073170824254, disc_loss = 0.000927526415870624
Trained batch 141 in epoch 7, gen_loss = 0.9760233331734026, disc_loss = 0.0009228170559984225
Trained batch 142 in epoch 7, gen_loss = 0.9760286883040742, disc_loss = 0.0009179627331514302
Trained batch 143 in epoch 7, gen_loss = 0.9757998556726508, disc_loss = 0.0009132130925435275
Trained batch 144 in epoch 7, gen_loss = 0.975761956593086, disc_loss = 0.0009085876197787001
Trained batch 145 in epoch 7, gen_loss = 0.9755996424857885, disc_loss = 0.0009040521440448635
Trained batch 146 in epoch 7, gen_loss = 0.9753669715252052, disc_loss = 0.000899820753153838
Trained batch 147 in epoch 7, gen_loss = 0.9750531972260088, disc_loss = 0.00089523064417409
Trained batch 148 in epoch 7, gen_loss = 0.9752809181309386, disc_loss = 0.0008913840417439219
Trained batch 149 in epoch 7, gen_loss = 0.9755656333764394, disc_loss = 0.0008876452541638476
Trained batch 150 in epoch 7, gen_loss = 0.9756540758720297, disc_loss = 0.0008867965840205661
Trained batch 151 in epoch 7, gen_loss = 0.9753330714608494, disc_loss = 0.0008900153813891322
Trained batch 152 in epoch 7, gen_loss = 0.975293684239481, disc_loss = 0.0008920686859888591
Trained batch 153 in epoch 7, gen_loss = 0.975132416208069, disc_loss = 0.0008910526809707441
Trained batch 154 in epoch 7, gen_loss = 0.9755952985055985, disc_loss = 0.000892028427446231
Trained batch 155 in epoch 7, gen_loss = 0.9758663104894834, disc_loss = 0.0008946768612076994
Trained batch 156 in epoch 7, gen_loss = 0.9759520110051343, disc_loss = 0.0008990040849219521
Trained batch 157 in epoch 7, gen_loss = 0.9760909208768531, disc_loss = 0.0009050985498543935
Trained batch 158 in epoch 7, gen_loss = 0.975899135541616, disc_loss = 0.0009111079846621555
Trained batch 159 in epoch 7, gen_loss = 0.9758053913712501, disc_loss = 0.0009155097323855444
Trained batch 160 in epoch 7, gen_loss = 0.9759393152983292, disc_loss = 0.0009183625276496935
Trained batch 161 in epoch 7, gen_loss = 0.9759993799674658, disc_loss = 0.0009195096360520965
Trained batch 162 in epoch 7, gen_loss = 0.9759039578993628, disc_loss = 0.0009200396117121496
Trained batch 163 in epoch 7, gen_loss = 0.9758638001796676, disc_loss = 0.0009210454052485946
Trained batch 164 in epoch 7, gen_loss = 0.9758517886653091, disc_loss = 0.0009211392795391889
Trained batch 165 in epoch 7, gen_loss = 0.975908126457628, disc_loss = 0.0009202313394999659
Trained batch 166 in epoch 7, gen_loss = 0.9756297672580102, disc_loss = 0.0009183409428788617
Trained batch 167 in epoch 7, gen_loss = 0.9754460801680883, disc_loss = 0.000915432826548654
Trained batch 168 in epoch 7, gen_loss = 0.975349165278779, disc_loss = 0.0009121364200406449
Trained batch 169 in epoch 7, gen_loss = 0.9753996631678413, disc_loss = 0.0009082365727141116
Trained batch 170 in epoch 7, gen_loss = 0.9753272704213684, disc_loss = 0.0009041350369432897
Trained batch 171 in epoch 7, gen_loss = 0.9751178674226584, disc_loss = 0.0009005122741401402
Trained batch 172 in epoch 7, gen_loss = 0.975063143782533, disc_loss = 0.0008972372220946217
Trained batch 173 in epoch 7, gen_loss = 0.9748639043035179, disc_loss = 0.0008946518480126083
Trained batch 174 in epoch 7, gen_loss = 0.9750315056528364, disc_loss = 0.0008948897787403049
Trained batch 175 in epoch 7, gen_loss = 0.9748029448091984, disc_loss = 0.0008988711789987229
Trained batch 176 in epoch 7, gen_loss = 0.974808658920439, disc_loss = 0.000904851999297596
Trained batch 177 in epoch 7, gen_loss = 0.9747300050901563, disc_loss = 0.0009064711235480624
Trained batch 178 in epoch 7, gen_loss = 0.9744166292291779, disc_loss = 0.0009055732146676827
Trained batch 179 in epoch 7, gen_loss = 0.9744862192206912, disc_loss = 0.000904867630662112
Trained batch 180 in epoch 7, gen_loss = 0.9743827923885366, disc_loss = 0.0009041860718466599
Trained batch 181 in epoch 7, gen_loss = 0.9743690333523594, disc_loss = 0.0009038903313761854
Trained batch 182 in epoch 7, gen_loss = 0.9743625108010131, disc_loss = 0.0009045831966780055
Trained batch 183 in epoch 7, gen_loss = 0.9743282986075982, disc_loss = 0.0009055328689061317
Trained batch 184 in epoch 7, gen_loss = 0.9743324463431899, disc_loss = 0.0009062980088512287
Trained batch 185 in epoch 7, gen_loss = 0.9744647516999193, disc_loss = 0.0009061901252597861
Trained batch 186 in epoch 7, gen_loss = 0.9746583317690355, disc_loss = 0.0009046644184839249
Trained batch 187 in epoch 7, gen_loss = 0.9745890273058668, disc_loss = 0.000901789305142766
Trained batch 188 in epoch 7, gen_loss = 0.9747426834686723, disc_loss = 0.0008986567476765553
Trained batch 189 in epoch 7, gen_loss = 0.9745716465146919, disc_loss = 0.0008955476575034768
Trained batch 190 in epoch 7, gen_loss = 0.9744511355904384, disc_loss = 0.0008925765853208192
Trained batch 191 in epoch 7, gen_loss = 0.9743583699067434, disc_loss = 0.0008896465227887044
Trained batch 192 in epoch 7, gen_loss = 0.9746121748741426, disc_loss = 0.0008874231744515396
Trained batch 193 in epoch 7, gen_loss = 0.9746412831483428, disc_loss = 0.0008854272193425411
Trained batch 194 in epoch 7, gen_loss = 0.9746102556204185, disc_loss = 0.0008830010273810237
Trained batch 195 in epoch 7, gen_loss = 0.9746395367748883, disc_loss = 0.0008798993874325807
Trained batch 196 in epoch 7, gen_loss = 0.9747223975089601, disc_loss = 0.0008765929847628323
Trained batch 197 in epoch 7, gen_loss = 0.9747874255132194, disc_loss = 0.0008730690377603304
Trained batch 198 in epoch 7, gen_loss = 0.9746935912712136, disc_loss = 0.0008696322909225218
Trained batch 199 in epoch 7, gen_loss = 0.9746448886394501, disc_loss = 0.0008662035446468508
Trained batch 200 in epoch 7, gen_loss = 0.9745178952145932, disc_loss = 0.0008630733451961229
Trained batch 201 in epoch 7, gen_loss = 0.9745622891010625, disc_loss = 0.0008607704663824401
Trained batch 202 in epoch 7, gen_loss = 0.9742276187013523, disc_loss = 0.000859795437306808
Trained batch 203 in epoch 7, gen_loss = 0.9745642858393052, disc_loss = 0.000860557981307947
Trained batch 204 in epoch 7, gen_loss = 0.9745768436571447, disc_loss = 0.0008619932477680467
Trained batch 205 in epoch 7, gen_loss = 0.9744394774575835, disc_loss = 0.0008632746822928594
Trained batch 206 in epoch 7, gen_loss = 0.9745839644169462, disc_loss = 0.0008632908724270905
Trained batch 207 in epoch 7, gen_loss = 0.9745553961166968, disc_loss = 0.0008620650092220436
Trained batch 208 in epoch 7, gen_loss = 0.9746137777584021, disc_loss = 0.0008597830441361516
Trained batch 209 in epoch 7, gen_loss = 0.9745623844010489, disc_loss = 0.0008571878144894505
Trained batch 210 in epoch 7, gen_loss = 0.9745162705674556, disc_loss = 0.000854726170848446
Trained batch 211 in epoch 7, gen_loss = 0.9746117847708037, disc_loss = 0.0008519883100097155
Trained batch 212 in epoch 7, gen_loss = 0.9747056314643, disc_loss = 0.0008505991828942698
Trained batch 213 in epoch 7, gen_loss = 0.9748751885980089, disc_loss = 0.0008512834725122481
Trained batch 214 in epoch 7, gen_loss = 0.9749145116916923, disc_loss = 0.0008526664029611925
Trained batch 215 in epoch 7, gen_loss = 0.9748053277532259, disc_loss = 0.0008554658402486153
Trained batch 216 in epoch 7, gen_loss = 0.9748033254926655, disc_loss = 0.000858495799204429
Trained batch 217 in epoch 7, gen_loss = 0.9746605887872364, disc_loss = 0.0008609696137056677
Trained batch 218 in epoch 7, gen_loss = 0.9746343313831173, disc_loss = 0.0008625391013303678
Trained batch 219 in epoch 7, gen_loss = 0.9745231246406382, disc_loss = 0.0008627462129383772
Trained batch 220 in epoch 7, gen_loss = 0.9743835098063784, disc_loss = 0.0008618774011571011
Trained batch 221 in epoch 7, gen_loss = 0.97455547172744, disc_loss = 0.0008610878569736808
Trained batch 222 in epoch 7, gen_loss = 0.974384150430226, disc_loss = 0.0008623328815828257
Trained batch 223 in epoch 7, gen_loss = 0.9742159212806395, disc_loss = 0.0008640099767944776
Trained batch 224 in epoch 7, gen_loss = 0.9745827873547872, disc_loss = 0.0008641013239199917
Trained batch 225 in epoch 7, gen_loss = 0.9743974501580264, disc_loss = 0.000862103219317124
Trained batch 226 in epoch 7, gen_loss = 0.9745915752675565, disc_loss = 0.0008618090556122132
Trained batch 227 in epoch 7, gen_loss = 0.9746236929245162, disc_loss = 0.0008647326720069701
Trained batch 228 in epoch 7, gen_loss = 0.9745473684702378, disc_loss = 0.0008677242539302491
Trained batch 229 in epoch 7, gen_loss = 0.9746456747469695, disc_loss = 0.0008686419358760443
Trained batch 230 in epoch 7, gen_loss = 0.9745616809630291, disc_loss = 0.0008684681920995896
Trained batch 231 in epoch 7, gen_loss = 0.9745202552655647, disc_loss = 0.000867473372009358
Trained batch 232 in epoch 7, gen_loss = 0.9744480254824069, disc_loss = 0.0008655025364177565
Trained batch 233 in epoch 7, gen_loss = 0.9743235600300324, disc_loss = 0.0008635029427331084
Trained batch 234 in epoch 7, gen_loss = 0.9743045499984254, disc_loss = 0.0008625599638648093
Trained batch 235 in epoch 7, gen_loss = 0.9744911615626287, disc_loss = 0.0008624719071815627
Trained batch 236 in epoch 7, gen_loss = 0.9746070765744784, disc_loss = 0.0008622484348217253
Trained batch 237 in epoch 7, gen_loss = 0.974593441526429, disc_loss = 0.0008614189587014986
Trained batch 238 in epoch 7, gen_loss = 0.9743770363440574, disc_loss = 0.0008595800424232362
Trained batch 239 in epoch 7, gen_loss = 0.9743925258517265, disc_loss = 0.0008577011724507126
Trained batch 240 in epoch 7, gen_loss = 0.9743974782619239, disc_loss = 0.0008562672760094133
Trained batch 241 in epoch 7, gen_loss = 0.9744124954397028, disc_loss = 0.0008550654155825658
Trained batch 242 in epoch 7, gen_loss = 0.9742468585693297, disc_loss = 0.0008546790752920166
Trained batch 243 in epoch 7, gen_loss = 0.9742470532655716, disc_loss = 0.0008556353893001244
Trained batch 244 in epoch 7, gen_loss = 0.9742297189576286, disc_loss = 0.000857466034952323
Trained batch 245 in epoch 7, gen_loss = 0.974211123173799, disc_loss = 0.0008602544118279243
Trained batch 246 in epoch 7, gen_loss = 0.9742698416053525, disc_loss = 0.0008648346302661336
Trained batch 247 in epoch 7, gen_loss = 0.9743816696347729, disc_loss = 0.000871903803800383
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.95393306016922, disc_loss = 0.0025144745595753193
Trained batch 1 in epoch 8, gen_loss = 0.9540183842182159, disc_loss = 0.002284493180923164
Trained batch 2 in epoch 8, gen_loss = 0.9578757882118225, disc_loss = 0.0021275784044216075
Trained batch 3 in epoch 8, gen_loss = 0.9548038095235825, disc_loss = 0.0019566426635719836
Trained batch 4 in epoch 8, gen_loss = 0.9671849131584167, disc_loss = 0.001761860866099596
Trained batch 5 in epoch 8, gen_loss = 0.9723463952541351, disc_loss = 0.001596754426524664
Trained batch 6 in epoch 8, gen_loss = 0.9702356117112296, disc_loss = 0.0014932744920120708
Trained batch 7 in epoch 8, gen_loss = 0.9720753133296967, disc_loss = 0.00141436902777059
Trained batch 8 in epoch 8, gen_loss = 0.9686185783810086, disc_loss = 0.0013381347202488945
Trained batch 9 in epoch 8, gen_loss = 0.9688367784023285, disc_loss = 0.001269726880127564
Trained batch 10 in epoch 8, gen_loss = 0.9708451249382712, disc_loss = 0.0012016707756133242
Trained batch 11 in epoch 8, gen_loss = 0.9699733257293701, disc_loss = 0.0011391155421733856
Trained batch 12 in epoch 8, gen_loss = 0.965826364663931, disc_loss = 0.001090868403060505
Trained batch 13 in epoch 8, gen_loss = 0.9671602674892971, disc_loss = 0.0010547804205478834
Trained batch 14 in epoch 8, gen_loss = 0.9711073319117228, disc_loss = 0.0010199822446641824
Trained batch 15 in epoch 8, gen_loss = 0.9713071808218956, disc_loss = 0.000996537539322162
Trained batch 16 in epoch 8, gen_loss = 0.9715778617297902, disc_loss = 0.0009931515224332757
Trained batch 17 in epoch 8, gen_loss = 0.974291291501787, disc_loss = 0.0009923018418097247
Trained batch 18 in epoch 8, gen_loss = 0.9786601380298012, disc_loss = 0.0009837247412896862
Trained batch 19 in epoch 8, gen_loss = 0.9769732713699341, disc_loss = 0.0010131889866897836
Trained batch 20 in epoch 8, gen_loss = 0.9793694473448253, disc_loss = 0.0010867645171293546
Trained batch 21 in epoch 8, gen_loss = 0.9795100255446001, disc_loss = 0.0011694830424279314
Trained batch 22 in epoch 8, gen_loss = 0.9790613210719564, disc_loss = 0.001233112514930089
Trained batch 23 in epoch 8, gen_loss = 0.9789393668373426, disc_loss = 0.0012593996386082533
Trained batch 24 in epoch 8, gen_loss = 0.977881715297699, disc_loss = 0.0012567386333830655
Trained batch 25 in epoch 8, gen_loss = 0.9776758391123551, disc_loss = 0.0012288179467969502
Trained batch 26 in epoch 8, gen_loss = 0.9782703563019082, disc_loss = 0.0011974845935280125
Trained batch 27 in epoch 8, gen_loss = 0.9795385066952024, disc_loss = 0.0011712421214074961
Trained batch 28 in epoch 8, gen_loss = 0.9791181765753647, disc_loss = 0.0011616602242956388
Trained batch 29 in epoch 8, gen_loss = 0.9788972576459248, disc_loss = 0.0011810601960557203
Trained batch 30 in epoch 8, gen_loss = 0.9802113963711646, disc_loss = 0.0012274673922107585
Trained batch 31 in epoch 8, gen_loss = 0.9795244857668877, disc_loss = 0.001256896273844177
Trained batch 32 in epoch 8, gen_loss = 0.9787487622463342, disc_loss = 0.0012589578135785732
Trained batch 33 in epoch 8, gen_loss = 0.979068002280067, disc_loss = 0.001251197885721922
Trained batch 34 in epoch 8, gen_loss = 0.9780140961919512, disc_loss = 0.0012396949709260038
Trained batch 35 in epoch 8, gen_loss = 0.9786560949352052, disc_loss = 0.0012263052760519916
Trained batch 36 in epoch 8, gen_loss = 0.9781167845468264, disc_loss = 0.0012149143259267549
Trained batch 37 in epoch 8, gen_loss = 0.9772355399633709, disc_loss = 0.0012066486800138495
Trained batch 38 in epoch 8, gen_loss = 0.9771638527894632, disc_loss = 0.0011982272934311857
Trained batch 39 in epoch 8, gen_loss = 0.975098904967308, disc_loss = 0.0011854275304358452
Trained batch 40 in epoch 8, gen_loss = 0.9759833492883822, disc_loss = 0.001174220405007917
Trained batch 41 in epoch 8, gen_loss = 0.9754608770211538, disc_loss = 0.0011715920533918376
Trained batch 42 in epoch 8, gen_loss = 0.975845644640368, disc_loss = 0.0011774525276471882
Trained batch 43 in epoch 8, gen_loss = 0.9754852137782357, disc_loss = 0.0011848890320503745
Trained batch 44 in epoch 8, gen_loss = 0.9759106450610691, disc_loss = 0.0011950914735077984
Trained batch 45 in epoch 8, gen_loss = 0.97560112113538, disc_loss = 0.0012019853241761903
Trained batch 46 in epoch 8, gen_loss = 0.9758702009282214, disc_loss = 0.001200215468688452
Trained batch 47 in epoch 8, gen_loss = 0.976112479964892, disc_loss = 0.0011905545215995517
Trained batch 48 in epoch 8, gen_loss = 0.9763823698978035, disc_loss = 0.0011808136157330353
Trained batch 49 in epoch 8, gen_loss = 0.9759976184368133, disc_loss = 0.001168584410334006
Trained batch 50 in epoch 8, gen_loss = 0.9761900130440208, disc_loss = 0.0011536665021113174
Trained batch 51 in epoch 8, gen_loss = 0.9762880102946208, disc_loss = 0.0011385674336522173
Trained batch 52 in epoch 8, gen_loss = 0.9756857797784625, disc_loss = 0.0011223182318301625
Trained batch 53 in epoch 8, gen_loss = 0.9747915786725504, disc_loss = 0.0011064070131396875
Trained batch 54 in epoch 8, gen_loss = 0.9745030522346496, disc_loss = 0.0010904084182005714
Trained batch 55 in epoch 8, gen_loss = 0.975098189498697, disc_loss = 0.001074887591260319
Trained batch 56 in epoch 8, gen_loss = 0.9747744850945055, disc_loss = 0.001063768568616197
Trained batch 57 in epoch 8, gen_loss = 0.9744134699476177, disc_loss = 0.0010600871901260689
Trained batch 58 in epoch 8, gen_loss = 0.9743597962088504, disc_loss = 0.0010546781620902593
Trained batch 59 in epoch 8, gen_loss = 0.9745053291320801, disc_loss = 0.0010485253757603157
Trained batch 60 in epoch 8, gen_loss = 0.9740695582061517, disc_loss = 0.0010411542831713974
Trained batch 61 in epoch 8, gen_loss = 0.9744212617797237, disc_loss = 0.0010323003004868365
Trained batch 62 in epoch 8, gen_loss = 0.9744001693195767, disc_loss = 0.0010257864575130894
Trained batch 63 in epoch 8, gen_loss = 0.9747872231528163, disc_loss = 0.0010200672882092476
Trained batch 64 in epoch 8, gen_loss = 0.9744472531171945, disc_loss = 0.0010133080162072125
Trained batch 65 in epoch 8, gen_loss = 0.974134601426847, disc_loss = 0.0010058890642760548
Trained batch 66 in epoch 8, gen_loss = 0.9744607557111712, disc_loss = 0.0009973700603108798
Trained batch 67 in epoch 8, gen_loss = 0.9739783432553796, disc_loss = 0.0009902163146762177
Trained batch 68 in epoch 8, gen_loss = 0.9729785409526549, disc_loss = 0.000983291394178472
Trained batch 69 in epoch 8, gen_loss = 0.9739002679075514, disc_loss = 0.0009742893532217879
Trained batch 70 in epoch 8, gen_loss = 0.9740552432100538, disc_loss = 0.0009674830366299868
Trained batch 71 in epoch 8, gen_loss = 0.9742538448837068, disc_loss = 0.0009620170130801853
Trained batch 72 in epoch 8, gen_loss = 0.9737595189107607, disc_loss = 0.0009547048104824881
Trained batch 73 in epoch 8, gen_loss = 0.9732169525043385, disc_loss = 0.0009459500685585914
Trained batch 74 in epoch 8, gen_loss = 0.9732902367909749, disc_loss = 0.0009366621705703438
Trained batch 75 in epoch 8, gen_loss = 0.9733655146862331, disc_loss = 0.0009301480052894668
Trained batch 76 in epoch 8, gen_loss = 0.9733259035395337, disc_loss = 0.0009287386027455039
Trained batch 77 in epoch 8, gen_loss = 0.9737910590110681, disc_loss = 0.0009297487357308945
Trained batch 78 in epoch 8, gen_loss = 0.9736162197740772, disc_loss = 0.0009286176565079655
Trained batch 79 in epoch 8, gen_loss = 0.9737820960581303, disc_loss = 0.0009228936600266024
Trained batch 80 in epoch 8, gen_loss = 0.9734039255130438, disc_loss = 0.0009146041472522933
Trained batch 81 in epoch 8, gen_loss = 0.9738481139264455, disc_loss = 0.0009070196893157028
Trained batch 82 in epoch 8, gen_loss = 0.9739804016538414, disc_loss = 0.0008995289646414479
Trained batch 83 in epoch 8, gen_loss = 0.9731785137028921, disc_loss = 0.0008929354014634598
Trained batch 84 in epoch 8, gen_loss = 0.9735586383763482, disc_loss = 0.0008852402148905265
Trained batch 85 in epoch 8, gen_loss = 0.9739638338255328, disc_loss = 0.0008772703259574185
Trained batch 86 in epoch 8, gen_loss = 0.9736814026174874, disc_loss = 0.0008698629669312537
Trained batch 87 in epoch 8, gen_loss = 0.9732950621030547, disc_loss = 0.0008634616287136768
Trained batch 88 in epoch 8, gen_loss = 0.9725909286670471, disc_loss = 0.0008582484983941122
Trained batch 89 in epoch 8, gen_loss = 0.9727823310428195, disc_loss = 0.0008534641708441389
Trained batch 90 in epoch 8, gen_loss = 0.9724193654217563, disc_loss = 0.0008490639430110005
Trained batch 91 in epoch 8, gen_loss = 0.9723055855087612, disc_loss = 0.0008459853268742218
Trained batch 92 in epoch 8, gen_loss = 0.9722038404915923, disc_loss = 0.0008444979526190167
Trained batch 93 in epoch 8, gen_loss = 0.9721658863919846, disc_loss = 0.0008416012060479261
Trained batch 94 in epoch 8, gen_loss = 0.9721602552815487, disc_loss = 0.0008371327772405684
Trained batch 95 in epoch 8, gen_loss = 0.9724488432208697, disc_loss = 0.0008322023518303467
Trained batch 96 in epoch 8, gen_loss = 0.9724820078033762, disc_loss = 0.0008266953025049213
Trained batch 97 in epoch 8, gen_loss = 0.9723739733501356, disc_loss = 0.0008212157383463726
Trained batch 98 in epoch 8, gen_loss = 0.9720949663056268, disc_loss = 0.0008190301553560233
Trained batch 99 in epoch 8, gen_loss = 0.9721579164266586, disc_loss = 0.0008208440254384186
Trained batch 100 in epoch 8, gen_loss = 0.971959370787781, disc_loss = 0.0008204558385607537
Trained batch 101 in epoch 8, gen_loss = 0.9720491468906403, disc_loss = 0.0008184233720028572
Trained batch 102 in epoch 8, gen_loss = 0.9725123719104285, disc_loss = 0.0008160268216228872
Trained batch 103 in epoch 8, gen_loss = 0.9723436201994236, disc_loss = 0.000813163232473576
Trained batch 104 in epoch 8, gen_loss = 0.9725593657720657, disc_loss = 0.0008107446049550725
Trained batch 105 in epoch 8, gen_loss = 0.9723173306798035, disc_loss = 0.0008099505348067362
Trained batch 106 in epoch 8, gen_loss = 0.9725286810197563, disc_loss = 0.0008109296103841494
Trained batch 107 in epoch 8, gen_loss = 0.9722021591884119, disc_loss = 0.0008122411472194708
Trained batch 108 in epoch 8, gen_loss = 0.9723073533915598, disc_loss = 0.0008125143549394358
Trained batch 109 in epoch 8, gen_loss = 0.9720096712762659, disc_loss = 0.0008125370769200593
Trained batch 110 in epoch 8, gen_loss = 0.9722075279768523, disc_loss = 0.0008126302644020987
Trained batch 111 in epoch 8, gen_loss = 0.9725401625037193, disc_loss = 0.0008129212665153318
Trained batch 112 in epoch 8, gen_loss = 0.9725562698018234, disc_loss = 0.0008126830591241195
Trained batch 113 in epoch 8, gen_loss = 0.9725466982314461, disc_loss = 0.0008113642692670079
Trained batch 114 in epoch 8, gen_loss = 0.9726723375527755, disc_loss = 0.0008097108356077629
Trained batch 115 in epoch 8, gen_loss = 0.9728554338216782, disc_loss = 0.0008072819291555788
Trained batch 116 in epoch 8, gen_loss = 0.9729612408540188, disc_loss = 0.0008037837977674352
Trained batch 117 in epoch 8, gen_loss = 0.9728666877342482, disc_loss = 0.0008004310165218204
Trained batch 118 in epoch 8, gen_loss = 0.9726119817805892, disc_loss = 0.0007968753398476294
Trained batch 119 in epoch 8, gen_loss = 0.9729479029774666, disc_loss = 0.0007946742413575217
Trained batch 120 in epoch 8, gen_loss = 0.9726612292045405, disc_loss = 0.0007941915240179178
Trained batch 121 in epoch 8, gen_loss = 0.9724116129953353, disc_loss = 0.0007990828929249518
Trained batch 122 in epoch 8, gen_loss = 0.9725298954219352, disc_loss = 0.0008086664882551016
Trained batch 123 in epoch 8, gen_loss = 0.9726225478995231, disc_loss = 0.0008168539306714065
Trained batch 124 in epoch 8, gen_loss = 0.9726424698829651, disc_loss = 0.0008198517222190276
Trained batch 125 in epoch 8, gen_loss = 0.9727081727413904, disc_loss = 0.0008199040022436603
Trained batch 126 in epoch 8, gen_loss = 0.972360887396054, disc_loss = 0.0008197006881539527
Trained batch 127 in epoch 8, gen_loss = 0.972085197456181, disc_loss = 0.0008214656833160916
Trained batch 128 in epoch 8, gen_loss = 0.9724250385003497, disc_loss = 0.0008267915177983846
Trained batch 129 in epoch 8, gen_loss = 0.9725510478019714, disc_loss = 0.0008318378434453805
Trained batch 130 in epoch 8, gen_loss = 0.9722632879519281, disc_loss = 0.000836276208101203
Trained batch 131 in epoch 8, gen_loss = 0.9725563589370612, disc_loss = 0.000840372153382332
Trained batch 132 in epoch 8, gen_loss = 0.9724723611559186, disc_loss = 0.0008435085836204497
Trained batch 133 in epoch 8, gen_loss = 0.9725335827514306, disc_loss = 0.0008454348753187319
Trained batch 134 in epoch 8, gen_loss = 0.9720006598366632, disc_loss = 0.0008473642063715185
Trained batch 135 in epoch 8, gen_loss = 0.9719339490813368, disc_loss = 0.0008504697792993872
Trained batch 136 in epoch 8, gen_loss = 0.9718604005166214, disc_loss = 0.000853089601788024
Trained batch 137 in epoch 8, gen_loss = 0.9719067811965942, disc_loss = 0.0008540592031710295
Trained batch 138 in epoch 8, gen_loss = 0.971802419466938, disc_loss = 0.0008537801408264183
Trained batch 139 in epoch 8, gen_loss = 0.9717835609401976, disc_loss = 0.0008533723699136837
Trained batch 140 in epoch 8, gen_loss = 0.9719174060415714, disc_loss = 0.0008522391122978855
Trained batch 141 in epoch 8, gen_loss = 0.9719919898140599, disc_loss = 0.0008494315360890846
Trained batch 142 in epoch 8, gen_loss = 0.9720017672418715, disc_loss = 0.0008456434315140522
Trained batch 143 in epoch 8, gen_loss = 0.9718559599585004, disc_loss = 0.0008417492908847635
Trained batch 144 in epoch 8, gen_loss = 0.9716390807053138, disc_loss = 0.0008392287712295315
Trained batch 145 in epoch 8, gen_loss = 0.9715083821179116, disc_loss = 0.0008373217046626027
Trained batch 146 in epoch 8, gen_loss = 0.9714251951295503, disc_loss = 0.0008348751967403797
Trained batch 147 in epoch 8, gen_loss = 0.9713140258917937, disc_loss = 0.0008325716975181225
Trained batch 148 in epoch 8, gen_loss = 0.9714617081136512, disc_loss = 0.0008308097454305151
Trained batch 149 in epoch 8, gen_loss = 0.9713560752073924, disc_loss = 0.0008284223693772219
Trained batch 150 in epoch 8, gen_loss = 0.9714302491668044, disc_loss = 0.0008266788294626745
Trained batch 151 in epoch 8, gen_loss = 0.9711691145049898, disc_loss = 0.0008243024746518227
Trained batch 152 in epoch 8, gen_loss = 0.9708841622265336, disc_loss = 0.0008210202615694417
Trained batch 153 in epoch 8, gen_loss = 0.9709733790391452, disc_loss = 0.0008186198680853628
Trained batch 154 in epoch 8, gen_loss = 0.9709093420736251, disc_loss = 0.0008181982980703093
Trained batch 155 in epoch 8, gen_loss = 0.9709686037057486, disc_loss = 0.0008172979211779491
Trained batch 156 in epoch 8, gen_loss = 0.9708187815490043, disc_loss = 0.0008151352428349185
Trained batch 157 in epoch 8, gen_loss = 0.9709011006958878, disc_loss = 0.0008123410132358476
Trained batch 158 in epoch 8, gen_loss = 0.9710062022479076, disc_loss = 0.0008094147296729292
Trained batch 159 in epoch 8, gen_loss = 0.970821138471365, disc_loss = 0.0008063812313594098
Trained batch 160 in epoch 8, gen_loss = 0.9705840489879158, disc_loss = 0.0008037097290952209
Trained batch 161 in epoch 8, gen_loss = 0.9707307815551758, disc_loss = 0.0008010307288646733
Trained batch 162 in epoch 8, gen_loss = 0.9707374580067359, disc_loss = 0.0007979897318866413
Trained batch 163 in epoch 8, gen_loss = 0.9708921894794558, disc_loss = 0.0007947626937693269
Trained batch 164 in epoch 8, gen_loss = 0.9708745898622455, disc_loss = 0.0007913653261670279
Trained batch 165 in epoch 8, gen_loss = 0.9710281530776655, disc_loss = 0.0007883228665092926
Trained batch 166 in epoch 8, gen_loss = 0.9710419459971126, disc_loss = 0.0007862799272358049
Trained batch 167 in epoch 8, gen_loss = 0.971065950180803, disc_loss = 0.0007839749974837538
Trained batch 168 in epoch 8, gen_loss = 0.970935543613321, disc_loss = 0.0007809293383185493
Trained batch 169 in epoch 8, gen_loss = 0.9708733818110298, disc_loss = 0.0007783778683754945
Trained batch 170 in epoch 8, gen_loss = 0.9709704249922992, disc_loss = 0.0007766911737676655
Trained batch 171 in epoch 8, gen_loss = 0.9710980653762817, disc_loss = 0.000774782072217339
Trained batch 172 in epoch 8, gen_loss = 0.9713526047723142, disc_loss = 0.0007722816455098558
Trained batch 173 in epoch 8, gen_loss = 0.9715705424889751, disc_loss = 0.0007711378078882305
Trained batch 174 in epoch 8, gen_loss = 0.9716474519457136, disc_loss = 0.0007703853978143473
Trained batch 175 in epoch 8, gen_loss = 0.9717602932995016, disc_loss = 0.0007690044235873343
Trained batch 176 in epoch 8, gen_loss = 0.971896949460951, disc_loss = 0.000766928297928587
Trained batch 177 in epoch 8, gen_loss = 0.9718221881416407, disc_loss = 0.0007643064395217173
Trained batch 178 in epoch 8, gen_loss = 0.9715575276140395, disc_loss = 0.0007612338148489303
Trained batch 179 in epoch 8, gen_loss = 0.9714445971780353, disc_loss = 0.0007596991673280071
Trained batch 180 in epoch 8, gen_loss = 0.9716167637656407, disc_loss = 0.0007595903118261913
Trained batch 181 in epoch 8, gen_loss = 0.9715982521628286, disc_loss = 0.0007585231955150388
Trained batch 182 in epoch 8, gen_loss = 0.9715869469069393, disc_loss = 0.0007559754391127047
Trained batch 183 in epoch 8, gen_loss = 0.9715708374329235, disc_loss = 0.0007531192790654883
Trained batch 184 in epoch 8, gen_loss = 0.9715061239294104, disc_loss = 0.0007524315106550333
Trained batch 185 in epoch 8, gen_loss = 0.9715621106086239, disc_loss = 0.0007543230033573514
Trained batch 186 in epoch 8, gen_loss = 0.9716341769631534, disc_loss = 0.0007549950981078132
Trained batch 187 in epoch 8, gen_loss = 0.9716606311341549, disc_loss = 0.0007537165055258269
Trained batch 188 in epoch 8, gen_loss = 0.9719490803108013, disc_loss = 0.0007521850678289959
Trained batch 189 in epoch 8, gen_loss = 0.9721121750379863, disc_loss = 0.0007508090347217053
Trained batch 190 in epoch 8, gen_loss = 0.972193256722695, disc_loss = 0.0007495507853153206
Trained batch 191 in epoch 8, gen_loss = 0.9722791338960329, disc_loss = 0.0007478940364459655
Trained batch 192 in epoch 8, gen_loss = 0.9723154525682716, disc_loss = 0.0007453527117728309
Trained batch 193 in epoch 8, gen_loss = 0.9723433081022242, disc_loss = 0.0007424665511899013
Trained batch 194 in epoch 8, gen_loss = 0.9725057916763501, disc_loss = 0.0007395889993625669
Trained batch 195 in epoch 8, gen_loss = 0.9723930307188813, disc_loss = 0.0007368767525191771
Trained batch 196 in epoch 8, gen_loss = 0.9724079948391406, disc_loss = 0.0007341966793227108
Trained batch 197 in epoch 8, gen_loss = 0.9724260198347496, disc_loss = 0.0007312284402415213
Trained batch 198 in epoch 8, gen_loss = 0.972315640006233, disc_loss = 0.0007281824397964487
Trained batch 199 in epoch 8, gen_loss = 0.97211899548769, disc_loss = 0.0007250909857248189
Trained batch 200 in epoch 8, gen_loss = 0.9722712914742048, disc_loss = 0.0007223023712143895
Trained batch 201 in epoch 8, gen_loss = 0.9721492018439982, disc_loss = 0.0007200787193430034
Trained batch 202 in epoch 8, gen_loss = 0.9719992291751166, disc_loss = 0.0007185221308775778
Trained batch 203 in epoch 8, gen_loss = 0.9719405872564689, disc_loss = 0.0007188379113715343
Trained batch 204 in epoch 8, gen_loss = 0.9720927793805192, disc_loss = 0.0007214508642635603
Trained batch 205 in epoch 8, gen_loss = 0.9719627652932139, disc_loss = 0.0007228035273796707
Trained batch 206 in epoch 8, gen_loss = 0.9717998700441369, disc_loss = 0.0007221220092958172
Trained batch 207 in epoch 8, gen_loss = 0.9716935249475332, disc_loss = 0.0007205313543706255
Trained batch 208 in epoch 8, gen_loss = 0.971720603664526, disc_loss = 0.0007187947771527568
Trained batch 209 in epoch 8, gen_loss = 0.971741976908275, disc_loss = 0.0007168323663617706
Trained batch 210 in epoch 8, gen_loss = 0.9716017833818191, disc_loss = 0.0007146555832167866
Trained batch 211 in epoch 8, gen_loss = 0.9716786365464049, disc_loss = 0.000712538035619424
Trained batch 212 in epoch 8, gen_loss = 0.9716237539976416, disc_loss = 0.000710277713137294
Trained batch 213 in epoch 8, gen_loss = 0.9715420528550014, disc_loss = 0.0007080136877609739
Trained batch 214 in epoch 8, gen_loss = 0.9714174134786739, disc_loss = 0.000706245668224319
Trained batch 215 in epoch 8, gen_loss = 0.9712175702055296, disc_loss = 0.0007048451446920539
Trained batch 216 in epoch 8, gen_loss = 0.9711247732013052, disc_loss = 0.0007038129855581444
Trained batch 217 in epoch 8, gen_loss = 0.9711066760601254, disc_loss = 0.0007028558900672729
Trained batch 218 in epoch 8, gen_loss = 0.9710606622369322, disc_loss = 0.0007014847726674886
Trained batch 219 in epoch 8, gen_loss = 0.9709985134276476, disc_loss = 0.0006997033701653973
Trained batch 220 in epoch 8, gen_loss = 0.9709325279045968, disc_loss = 0.0006977554662358563
Trained batch 221 in epoch 8, gen_loss = 0.970956379228884, disc_loss = 0.0006960709578633468
Trained batch 222 in epoch 8, gen_loss = 0.9711091550476348, disc_loss = 0.0006946501657632994
Trained batch 223 in epoch 8, gen_loss = 0.9711305126547813, disc_loss = 0.0006933810879153108
Trained batch 224 in epoch 8, gen_loss = 0.9710816446940104, disc_loss = 0.0006920380985441928
Trained batch 225 in epoch 8, gen_loss = 0.9709503695500635, disc_loss = 0.0006907205767666847
Trained batch 226 in epoch 8, gen_loss = 0.9709973737006671, disc_loss = 0.0006894265719620708
Trained batch 227 in epoch 8, gen_loss = 0.9710318966392886, disc_loss = 0.0006878207763325088
Trained batch 228 in epoch 8, gen_loss = 0.9708808558997108, disc_loss = 0.0006862813803213791
Trained batch 229 in epoch 8, gen_loss = 0.9707801126915475, disc_loss = 0.0006849904266899735
Trained batch 230 in epoch 8, gen_loss = 0.9707744704696523, disc_loss = 0.0006833093400739206
Trained batch 231 in epoch 8, gen_loss = 0.9708235315207777, disc_loss = 0.0006813854053752007
Trained batch 232 in epoch 8, gen_loss = 0.9706403127044055, disc_loss = 0.0006793534687706249
Trained batch 233 in epoch 8, gen_loss = 0.9709530378508772, disc_loss = 0.0006775957029501899
Trained batch 234 in epoch 8, gen_loss = 0.9710196264246677, disc_loss = 0.0006764235615264625
Trained batch 235 in epoch 8, gen_loss = 0.9710180542226565, disc_loss = 0.0006759314921386619
Trained batch 236 in epoch 8, gen_loss = 0.9710136425646045, disc_loss = 0.0006758244679936204
Trained batch 237 in epoch 8, gen_loss = 0.9710533005349776, disc_loss = 0.0006761445150027803
Trained batch 238 in epoch 8, gen_loss = 0.9709861779811492, disc_loss = 0.000677146242466798
Trained batch 239 in epoch 8, gen_loss = 0.9711025002102057, disc_loss = 0.0006792115541126502
Trained batch 240 in epoch 8, gen_loss = 0.9709561632876574, disc_loss = 0.0006830589356687291
Trained batch 241 in epoch 8, gen_loss = 0.9708160565904349, disc_loss = 0.0006883872208937864
Trained batch 242 in epoch 8, gen_loss = 0.9707216102890517, disc_loss = 0.0006939951983642661
Trained batch 243 in epoch 8, gen_loss = 0.9707378271173258, disc_loss = 0.0006996593470293952
Trained batch 244 in epoch 8, gen_loss = 0.9706878302048664, disc_loss = 0.000704619839991804
Trained batch 245 in epoch 8, gen_loss = 0.9707042167826396, disc_loss = 0.000708661009382449
Trained batch 246 in epoch 8, gen_loss = 0.970542566496351, disc_loss = 0.0007125585280341824
Trained batch 247 in epoch 8, gen_loss = 0.9704396542041532, disc_loss = 0.0007170257964800487
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.9778083562850952, disc_loss = 0.0016388994408771396
Trained batch 1 in epoch 9, gen_loss = 0.9953616857528687, disc_loss = 0.0015149587416090071
Trained batch 2 in epoch 9, gen_loss = 0.9821860790252686, disc_loss = 0.0013894987059757113
Trained batch 3 in epoch 9, gen_loss = 0.9798821210861206, disc_loss = 0.001295810769079253
Trained batch 4 in epoch 9, gen_loss = 0.9745163798332215, disc_loss = 0.0012100404943339526
Trained batch 5 in epoch 9, gen_loss = 0.9711549282073975, disc_loss = 0.0011165963854485501
Trained batch 6 in epoch 9, gen_loss = 0.9707621335983276, disc_loss = 0.001026007642004905
Trained batch 7 in epoch 9, gen_loss = 0.967631421983242, disc_loss = 0.0009496055245108437
Trained batch 8 in epoch 9, gen_loss = 0.9727241396903992, disc_loss = 0.0008855242566722962
Trained batch 9 in epoch 9, gen_loss = 0.9690919697284699, disc_loss = 0.0008311098557896912
Trained batch 10 in epoch 9, gen_loss = 0.9698156931183555, disc_loss = 0.0007895489001053978
Trained batch 11 in epoch 9, gen_loss = 0.9695239116748174, disc_loss = 0.0007484941039971696
Trained batch 12 in epoch 9, gen_loss = 0.9684241138971769, disc_loss = 0.0007054492934212948
Trained batch 13 in epoch 9, gen_loss = 0.9706889092922211, disc_loss = 0.0006692196995053175
Trained batch 14 in epoch 9, gen_loss = 0.9710519790649415, disc_loss = 0.0006419035392658164
Trained batch 15 in epoch 9, gen_loss = 0.9689454436302185, disc_loss = 0.0006232204705156619
Trained batch 16 in epoch 9, gen_loss = 0.9689910762450274, disc_loss = 0.0006174659715992782
Trained batch 17 in epoch 9, gen_loss = 0.9718352225091722, disc_loss = 0.0006263674666923988
Trained batch 18 in epoch 9, gen_loss = 0.973394230792397, disc_loss = 0.0006399701370882164
Trained batch 19 in epoch 9, gen_loss = 0.9734977304935455, disc_loss = 0.0006650298528256826
Trained batch 20 in epoch 9, gen_loss = 0.9722888583228702, disc_loss = 0.0007022829612694858
Trained batch 21 in epoch 9, gen_loss = 0.9726441448385065, disc_loss = 0.0007533483744323762
Trained batch 22 in epoch 9, gen_loss = 0.9717847290246383, disc_loss = 0.0008146503887078522
Trained batch 23 in epoch 9, gen_loss = 0.9717566718657812, disc_loss = 0.0008682085305432944
Trained batch 24 in epoch 9, gen_loss = 0.9719167470932006, disc_loss = 0.0009077181096654386
Trained batch 25 in epoch 9, gen_loss = 0.9719134248220004, disc_loss = 0.0009338270969097861
Trained batch 26 in epoch 9, gen_loss = 0.9726304080751207, disc_loss = 0.0009425312778653784
Trained batch 27 in epoch 9, gen_loss = 0.9731746571404594, disc_loss = 0.0009398598413099535
Trained batch 28 in epoch 9, gen_loss = 0.9726542049440844, disc_loss = 0.0009296427908401679
Trained batch 29 in epoch 9, gen_loss = 0.9719247877597809, disc_loss = 0.0009152340790024027
Trained batch 30 in epoch 9, gen_loss = 0.9728996234555398, disc_loss = 0.0009024983296366108
Trained batch 31 in epoch 9, gen_loss = 0.9728150591254234, disc_loss = 0.0008914692925827694
Trained batch 32 in epoch 9, gen_loss = 0.9728153907891476, disc_loss = 0.000878063054353168
Trained batch 33 in epoch 9, gen_loss = 0.9726045727729797, disc_loss = 0.0008634105744182735
Trained batch 34 in epoch 9, gen_loss = 0.971999522617885, disc_loss = 0.0008483475207218102
Trained batch 35 in epoch 9, gen_loss = 0.9737974603970846, disc_loss = 0.0008353594150523552
Trained batch 36 in epoch 9, gen_loss = 0.9737229927166088, disc_loss = 0.0008239744536301776
Trained batch 37 in epoch 9, gen_loss = 0.9722264283581784, disc_loss = 0.0008159791637138513
Trained batch 38 in epoch 9, gen_loss = 0.9709150623052548, disc_loss = 0.0008121040852692646
Trained batch 39 in epoch 9, gen_loss = 0.9706253334879875, disc_loss = 0.0008124217740260065
Trained batch 40 in epoch 9, gen_loss = 0.9724356822851228, disc_loss = 0.0008164050111478967
Trained batch 41 in epoch 9, gen_loss = 0.9718103153364999, disc_loss = 0.0008230198443578999
Trained batch 42 in epoch 9, gen_loss = 0.9718895124834638, disc_loss = 0.0008252564314103057
Trained batch 43 in epoch 9, gen_loss = 0.9713858447291635, disc_loss = 0.0008235953970473598
Trained batch 44 in epoch 9, gen_loss = 0.9714533779356215, disc_loss = 0.0008233472058135602
Trained batch 45 in epoch 9, gen_loss = 0.9710274014783942, disc_loss = 0.0008245152041680464
Trained batch 46 in epoch 9, gen_loss = 0.9710969683971811, disc_loss = 0.0008216798206434605
Trained batch 47 in epoch 9, gen_loss = 0.9705521215995153, disc_loss = 0.0008174763412777489
Trained batch 48 in epoch 9, gen_loss = 0.9720458887061294, disc_loss = 0.0008152565783440915
Trained batch 49 in epoch 9, gen_loss = 0.9725048089027405, disc_loss = 0.0008181806618813425
Trained batch 50 in epoch 9, gen_loss = 0.9726450922442418, disc_loss = 0.0008242361204169106
Trained batch 51 in epoch 9, gen_loss = 0.972237786421409, disc_loss = 0.0008293819723453802
Trained batch 52 in epoch 9, gen_loss = 0.971832552046146, disc_loss = 0.0008322683806566276
Trained batch 53 in epoch 9, gen_loss = 0.9724253791349905, disc_loss = 0.0008322446816169691
Trained batch 54 in epoch 9, gen_loss = 0.9731880686499855, disc_loss = 0.0008333955002440647
Trained batch 55 in epoch 9, gen_loss = 0.9729090950318745, disc_loss = 0.0008357986516784877
Trained batch 56 in epoch 9, gen_loss = 0.9732580760069061, disc_loss = 0.000838013647712375
Trained batch 57 in epoch 9, gen_loss = 0.9730380824927626, disc_loss = 0.0008369000289380422
Trained batch 58 in epoch 9, gen_loss = 0.9729502625384573, disc_loss = 0.0008321183475160624
Trained batch 59 in epoch 9, gen_loss = 0.9728411207596461, disc_loss = 0.0008266024990007282
Trained batch 60 in epoch 9, gen_loss = 0.972758873564298, disc_loss = 0.0008217799897137724
Trained batch 61 in epoch 9, gen_loss = 0.9723864024685275, disc_loss = 0.0008182019772638957
Trained batch 62 in epoch 9, gen_loss = 0.9722386116073245, disc_loss = 0.0008154490201305303
Trained batch 63 in epoch 9, gen_loss = 0.9729200275614858, disc_loss = 0.0008409743641095702
Trained batch 64 in epoch 9, gen_loss = 0.9733959518946134, disc_loss = 0.0008629228561543501
Trained batch 65 in epoch 9, gen_loss = 0.9749924296682532, disc_loss = 0.0008962590346169291
Trained batch 66 in epoch 9, gen_loss = 0.9765534569968038, disc_loss = 0.0010109226525163472
Trained batch 67 in epoch 9, gen_loss = 0.9773424329126582, disc_loss = 0.0011669958544456784
Trained batch 68 in epoch 9, gen_loss = 0.9776407609815183, disc_loss = 0.0012633602296852548
Trained batch 69 in epoch 9, gen_loss = 0.9775503150054387, disc_loss = 0.0013048128823616675
Trained batch 70 in epoch 9, gen_loss = 0.9775487797361024, disc_loss = 0.001330271973209062
Trained batch 71 in epoch 9, gen_loss = 0.977720265587171, disc_loss = 0.0013457888530360328
Trained batch 72 in epoch 9, gen_loss = 0.9772742627418205, disc_loss = 0.0013480947100978397
Trained batch 73 in epoch 9, gen_loss = 0.9775068324965399, disc_loss = 0.0013489973293994931
Trained batch 74 in epoch 9, gen_loss = 0.9773853047688802, disc_loss = 0.0013542397258182366
Trained batch 75 in epoch 9, gen_loss = 0.9772804418676778, disc_loss = 0.0013649318563310725
Trained batch 76 in epoch 9, gen_loss = 0.9772048902201962, disc_loss = 0.001377414476561856
Trained batch 77 in epoch 9, gen_loss = 0.9770674438048632, disc_loss = 0.0013855332628083534
Trained batch 78 in epoch 9, gen_loss = 0.9769288135480277, disc_loss = 0.0013879581245511204
Trained batch 79 in epoch 9, gen_loss = 0.977135282754898, disc_loss = 0.0013849866882083006
Trained batch 80 in epoch 9, gen_loss = 0.9776914649539523, disc_loss = 0.0013799623853561502
Trained batch 81 in epoch 9, gen_loss = 0.9778622265269117, disc_loss = 0.0013750418644432525
Trained batch 82 in epoch 9, gen_loss = 0.9778486590787588, disc_loss = 0.0013649733596851669
Trained batch 83 in epoch 9, gen_loss = 0.9778765553519839, disc_loss = 0.001352584898649227
Trained batch 84 in epoch 9, gen_loss = 0.9784380449968226, disc_loss = 0.0013399965270175873
Trained batch 85 in epoch 9, gen_loss = 0.9785755359849264, disc_loss = 0.0013302400180945433
Trained batch 86 in epoch 9, gen_loss = 0.9787399117974029, disc_loss = 0.0013274737053695295
Trained batch 87 in epoch 9, gen_loss = 0.9784429642287168, disc_loss = 0.001321829523724525
Trained batch 88 in epoch 9, gen_loss = 0.977943498097109, disc_loss = 0.0013135194459935294
Trained batch 89 in epoch 9, gen_loss = 0.9777993798255921, disc_loss = 0.0013102440076181664
Trained batch 90 in epoch 9, gen_loss = 0.9773469750697796, disc_loss = 0.0013059457910508123
Trained batch 91 in epoch 9, gen_loss = 0.9772474817607714, disc_loss = 0.0013013217745617073
Trained batch 92 in epoch 9, gen_loss = 0.9769755044291096, disc_loss = 0.0012969032824364922
Trained batch 93 in epoch 9, gen_loss = 0.977001501524702, disc_loss = 0.0012965446930661045
Trained batch 94 in epoch 9, gen_loss = 0.9764016182799088, disc_loss = 0.0012996540322140055
Trained batch 95 in epoch 9, gen_loss = 0.9764854529251655, disc_loss = 0.0012998467588355804
Trained batch 96 in epoch 9, gen_loss = 0.9766347807707246, disc_loss = 0.001294828077343763
Trained batch 97 in epoch 9, gen_loss = 0.9766170546716574, disc_loss = 0.001288663406145987
Trained batch 98 in epoch 9, gen_loss = 0.9769871553989372, disc_loss = 0.0012825592047643066
Trained batch 99 in epoch 9, gen_loss = 0.9770617741346359, disc_loss = 0.001275127409317065
Trained batch 100 in epoch 9, gen_loss = 0.9769662217338486, disc_loss = 0.00126579420417455
Trained batch 101 in epoch 9, gen_loss = 0.9770233070149141, disc_loss = 0.001258545455308266
Trained batch 102 in epoch 9, gen_loss = 0.9769112126341144, disc_loss = 0.0012516171803688902
Trained batch 103 in epoch 9, gen_loss = 0.9773204521490977, disc_loss = 0.001243379029731911
Trained batch 104 in epoch 9, gen_loss = 0.9775151933942522, disc_loss = 0.0012335566396359354
Trained batch 105 in epoch 9, gen_loss = 0.9772432502710594, disc_loss = 0.0012244665731658351
Trained batch 106 in epoch 9, gen_loss = 0.9772606854126832, disc_loss = 0.0012159417579211643
Trained batch 107 in epoch 9, gen_loss = 0.977097010170972, disc_loss = 0.0012074363977363748
Trained batch 108 in epoch 9, gen_loss = 0.9769164285528551, disc_loss = 0.0012015203893005232
Trained batch 109 in epoch 9, gen_loss = 0.9778386652469635, disc_loss = 0.001206884003477171
Trained batch 110 in epoch 9, gen_loss = 0.9776434495642379, disc_loss = 0.001216022364337937
Trained batch 111 in epoch 9, gen_loss = 0.9777381303054946, disc_loss = 0.0012185534085022351
Trained batch 112 in epoch 9, gen_loss = 0.9776070951360517, disc_loss = 0.0012195755730679803
Trained batch 113 in epoch 9, gen_loss = 0.9776615286082552, disc_loss = 0.0012208872077488259
Trained batch 114 in epoch 9, gen_loss = 0.9774829994077268, disc_loss = 0.0012197147968792074
Trained batch 115 in epoch 9, gen_loss = 0.9772648497902113, disc_loss = 0.0012168860969189875
Trained batch 116 in epoch 9, gen_loss = 0.9769304058490655, disc_loss = 0.0012137245468429138
Trained batch 117 in epoch 9, gen_loss = 0.9769641186221171, disc_loss = 0.001212460984341737
Trained batch 118 in epoch 9, gen_loss = 0.9767008043136918, disc_loss = 0.0012134662418461898
Trained batch 119 in epoch 9, gen_loss = 0.9766143570343654, disc_loss = 0.0012137888775517543
Trained batch 120 in epoch 9, gen_loss = 0.9766738370430371, disc_loss = 0.0012115574858443858
Trained batch 121 in epoch 9, gen_loss = 0.976353077126331, disc_loss = 0.001208899628092367
Trained batch 122 in epoch 9, gen_loss = 0.9760120961724258, disc_loss = 0.0012050972791479491
Trained batch 123 in epoch 9, gen_loss = 0.9759500872704291, disc_loss = 0.0012016366780435125
Trained batch 124 in epoch 9, gen_loss = 0.9757616105079651, disc_loss = 0.0011976360171101986
Trained batch 125 in epoch 9, gen_loss = 0.9757755271026066, disc_loss = 0.001191093937479078
Trained batch 126 in epoch 9, gen_loss = 0.9755059095818227, disc_loss = 0.001186528195916697
Trained batch 127 in epoch 9, gen_loss = 0.9754539644345641, disc_loss = 0.0011824944044747099
Trained batch 128 in epoch 9, gen_loss = 0.9753476261168488, disc_loss = 0.0011787320944740502
Trained batch 129 in epoch 9, gen_loss = 0.9751102479604574, disc_loss = 0.0011728636065247253
Trained batch 130 in epoch 9, gen_loss = 0.9748465973912305, disc_loss = 0.001165366338682361
Trained batch 131 in epoch 9, gen_loss = 0.9749544271917054, disc_loss = 0.0011581462250350423
Trained batch 132 in epoch 9, gen_loss = 0.9748191851422303, disc_loss = 0.00115235962393375
Trained batch 133 in epoch 9, gen_loss = 0.9747963102895822, disc_loss = 0.0011491326539414073
Trained batch 134 in epoch 9, gen_loss = 0.9747256005251849, disc_loss = 0.0011444216295516257
Trained batch 135 in epoch 9, gen_loss = 0.974744431236211, disc_loss = 0.0011383147398994291
Trained batch 136 in epoch 9, gen_loss = 0.9747449542484145, disc_loss = 0.001131150420405902
Trained batch 137 in epoch 9, gen_loss = 0.9750508432802947, disc_loss = 0.0011241082525963936
Trained batch 138 in epoch 9, gen_loss = 0.9749584794044495, disc_loss = 0.0011176318485078757
Trained batch 139 in epoch 9, gen_loss = 0.9751339124781745, disc_loss = 0.0011116158832529825
Trained batch 140 in epoch 9, gen_loss = 0.9747830802667226, disc_loss = 0.0011074544023061898
Trained batch 141 in epoch 9, gen_loss = 0.9745371790838914, disc_loss = 0.0011046819715157257
Trained batch 142 in epoch 9, gen_loss = 0.9747348961296615, disc_loss = 0.0010995109800828972
Trained batch 143 in epoch 9, gen_loss = 0.9747080732550886, disc_loss = 0.0010944603774179188
Trained batch 144 in epoch 9, gen_loss = 0.9747328055316005, disc_loss = 0.0010902854216541967
Trained batch 145 in epoch 9, gen_loss = 0.9746877081590156, disc_loss = 0.0010850947084740977
Trained batch 146 in epoch 9, gen_loss = 0.9745506031983564, disc_loss = 0.0010799751221043925
Trained batch 147 in epoch 9, gen_loss = 0.974534590502043, disc_loss = 0.0010758226617818346
Trained batch 148 in epoch 9, gen_loss = 0.9744147010297584, disc_loss = 0.0010709677425981968
Trained batch 149 in epoch 9, gen_loss = 0.9742449708779652, disc_loss = 0.0010652715684652018
Trained batch 150 in epoch 9, gen_loss = 0.9742354466425662, disc_loss = 0.001059524381987362
Trained batch 151 in epoch 9, gen_loss = 0.9742220095113704, disc_loss = 0.0010539921655244573
Trained batch 152 in epoch 9, gen_loss = 0.974017885775348, disc_loss = 0.00104809739466017
Trained batch 153 in epoch 9, gen_loss = 0.9738425550522742, disc_loss = 0.001042426809197588
Trained batch 154 in epoch 9, gen_loss = 0.9740253933014408, disc_loss = 0.0010370049621879814
Trained batch 155 in epoch 9, gen_loss = 0.973762013973334, disc_loss = 0.0010332931362940238
Trained batch 156 in epoch 9, gen_loss = 0.9737338397153623, disc_loss = 0.001029590421147158
Trained batch 157 in epoch 9, gen_loss = 0.9736787627769422, disc_loss = 0.0010244553736293146
Trained batch 158 in epoch 9, gen_loss = 0.9736167923459467, disc_loss = 0.0010192320832569715
Trained batch 159 in epoch 9, gen_loss = 0.9736362207680941, disc_loss = 0.0010139566749785445
Trained batch 160 in epoch 9, gen_loss = 0.9739580298802868, disc_loss = 0.0010088273696999084
Trained batch 161 in epoch 9, gen_loss = 0.9739103663114854, disc_loss = 0.0010040995739809997
Trained batch 162 in epoch 9, gen_loss = 0.9740814840866744, disc_loss = 0.0010006816137654913
Trained batch 163 in epoch 9, gen_loss = 0.9741807209282387, disc_loss = 0.0009984342180293269
Trained batch 164 in epoch 9, gen_loss = 0.9740765636617487, disc_loss = 0.000995694058788517
Trained batch 165 in epoch 9, gen_loss = 0.9740556255880609, disc_loss = 0.0009918615946241834
Trained batch 166 in epoch 9, gen_loss = 0.9739794102971425, disc_loss = 0.0009871072584273807
Trained batch 167 in epoch 9, gen_loss = 0.9740060823304313, disc_loss = 0.0009831017119029724
Trained batch 168 in epoch 9, gen_loss = 0.9738947586900384, disc_loss = 0.000981276502613028
Trained batch 169 in epoch 9, gen_loss = 0.9738155308891745, disc_loss = 0.0009802468984750757
Trained batch 170 in epoch 9, gen_loss = 0.9735697804138674, disc_loss = 0.0009785412378610543
Trained batch 171 in epoch 9, gen_loss = 0.9734234837598579, disc_loss = 0.0009757729757713901
Trained batch 172 in epoch 9, gen_loss = 0.9732328284682566, disc_loss = 0.0009722102256296633
Trained batch 173 in epoch 9, gen_loss = 0.9729549323005238, disc_loss = 0.000969247357005216
Trained batch 174 in epoch 9, gen_loss = 0.9728257765088762, disc_loss = 0.0009666207623169092
Trained batch 175 in epoch 9, gen_loss = 0.9728445092385466, disc_loss = 0.000963658512360284
Trained batch 176 in epoch 9, gen_loss = 0.9726993370864351, disc_loss = 0.0009612080993460975
Trained batch 177 in epoch 9, gen_loss = 0.9727226241251056, disc_loss = 0.0009590986696054918
Trained batch 178 in epoch 9, gen_loss = 0.9724430811471779, disc_loss = 0.0009564253840271602
Trained batch 179 in epoch 9, gen_loss = 0.9725362459818522, disc_loss = 0.0009536064267902273
Trained batch 180 in epoch 9, gen_loss = 0.9726128545255293, disc_loss = 0.0009509802279634998
Trained batch 181 in epoch 9, gen_loss = 0.9722788851339739, disc_loss = 0.0009494193390320096
Trained batch 182 in epoch 9, gen_loss = 0.9723242553856855, disc_loss = 0.0009471968375687116
Trained batch 183 in epoch 9, gen_loss = 0.9726310346437537, disc_loss = 0.0009435071571478265
Trained batch 184 in epoch 9, gen_loss = 0.9724339794468235, disc_loss = 0.0009400206357649704
Trained batch 185 in epoch 9, gen_loss = 0.9724327489253013, disc_loss = 0.0009367971679337212
Trained batch 186 in epoch 9, gen_loss = 0.9724781557837909, disc_loss = 0.0009336092427309433
Trained batch 187 in epoch 9, gen_loss = 0.9725409492533258, disc_loss = 0.0009301542602460881
Trained batch 188 in epoch 9, gen_loss = 0.9725167587320641, disc_loss = 0.0009265210118856793
Trained batch 189 in epoch 9, gen_loss = 0.9724286280180279, disc_loss = 0.0009227023564897919
Trained batch 190 in epoch 9, gen_loss = 0.9724829512116797, disc_loss = 0.0009189471167406184
Trained batch 191 in epoch 9, gen_loss = 0.9724438373620311, disc_loss = 0.0009154339259869934
Trained batch 192 in epoch 9, gen_loss = 0.9725572686121253, disc_loss = 0.0009125561494569636
Trained batch 193 in epoch 9, gen_loss = 0.9723657922646434, disc_loss = 0.0009113717428918631
Trained batch 194 in epoch 9, gen_loss = 0.9725771855085324, disc_loss = 0.0009118940747635534
Trained batch 195 in epoch 9, gen_loss = 0.9724741371310487, disc_loss = 0.0009134436063783253
Trained batch 196 in epoch 9, gen_loss = 0.9722696400535893, disc_loss = 0.0009154317632990034
Trained batch 197 in epoch 9, gen_loss = 0.9723003377216031, disc_loss = 0.0009168760952888988
Trained batch 198 in epoch 9, gen_loss = 0.9725192854152852, disc_loss = 0.0009169925461861366
Trained batch 199 in epoch 9, gen_loss = 0.9724443203210831, disc_loss = 0.0009163837647793116
Trained batch 200 in epoch 9, gen_loss = 0.9723198615496431, disc_loss = 0.0009148815196889003
Trained batch 201 in epoch 9, gen_loss = 0.9724081556985874, disc_loss = 0.0009129110708317517
Trained batch 202 in epoch 9, gen_loss = 0.9721979977462092, disc_loss = 0.0009104474780999647
Trained batch 203 in epoch 9, gen_loss = 0.9721228115114511, disc_loss = 0.0009074670292737245
Trained batch 204 in epoch 9, gen_loss = 0.9720725652648181, disc_loss = 0.0009040668131868786
Trained batch 205 in epoch 9, gen_loss = 0.9720263562156158, disc_loss = 0.0009002779570613871
Trained batch 206 in epoch 9, gen_loss = 0.972280085950658, disc_loss = 0.0008965653302946583
Trained batch 207 in epoch 9, gen_loss = 0.9722882747077025, disc_loss = 0.0008929154655561433
Trained batch 208 in epoch 9, gen_loss = 0.9722889253967687, disc_loss = 0.000889914642178908
Trained batch 209 in epoch 9, gen_loss = 0.9723696927229564, disc_loss = 0.0008888200520665296
Trained batch 210 in epoch 9, gen_loss = 0.9722336479837861, disc_loss = 0.0008884938132383097
Trained batch 211 in epoch 9, gen_loss = 0.9721853463154919, disc_loss = 0.0008875995559067649
Trained batch 212 in epoch 9, gen_loss = 0.9720536031073808, disc_loss = 0.0008866993899368616
Trained batch 213 in epoch 9, gen_loss = 0.9717780866912592, disc_loss = 0.0008873468610783386
Trained batch 214 in epoch 9, gen_loss = 0.9718414021092792, disc_loss = 0.0008884505766070296
Trained batch 215 in epoch 9, gen_loss = 0.9718942222771821, disc_loss = 0.0008881671226306396
Trained batch 216 in epoch 9, gen_loss = 0.9718741604260036, disc_loss = 0.000887572588246157
Trained batch 217 in epoch 9, gen_loss = 0.9717968661303914, disc_loss = 0.000886787103375296
Trained batch 218 in epoch 9, gen_loss = 0.9717393141903289, disc_loss = 0.0008873488050625026
Trained batch 219 in epoch 9, gen_loss = 0.9717490990053523, disc_loss = 0.0008887069521403068
Trained batch 220 in epoch 9, gen_loss = 0.9715209139418278, disc_loss = 0.000889131067069437
Trained batch 221 in epoch 9, gen_loss = 0.9713251491387686, disc_loss = 0.0008885095475806838
Trained batch 222 in epoch 9, gen_loss = 0.9711663931474558, disc_loss = 0.0008874297829949393
Trained batch 223 in epoch 9, gen_loss = 0.9710969810507127, disc_loss = 0.0008859694303282595
Trained batch 224 in epoch 9, gen_loss = 0.9711063114802042, disc_loss = 0.0008841570554068312
Trained batch 225 in epoch 9, gen_loss = 0.9709899193417709, disc_loss = 0.0008818749208966542
Trained batch 226 in epoch 9, gen_loss = 0.9708425205709651, disc_loss = 0.0008795509257303584
Trained batch 227 in epoch 9, gen_loss = 0.9707272146877489, disc_loss = 0.0008776853429209727
Trained batch 228 in epoch 9, gen_loss = 0.9705518796454351, disc_loss = 0.000875960533035915
Trained batch 229 in epoch 9, gen_loss = 0.9706438085307245, disc_loss = 0.0008740329670178218
Trained batch 230 in epoch 9, gen_loss = 0.9707471297416852, disc_loss = 0.0008716501266714709
Trained batch 231 in epoch 9, gen_loss = 0.9707775095413471, disc_loss = 0.0008690697566886103
Trained batch 232 in epoch 9, gen_loss = 0.9708003880128329, disc_loss = 0.000866921313490235
Trained batch 233 in epoch 9, gen_loss = 0.9709338387872419, disc_loss = 0.0008645574444716868
Trained batch 234 in epoch 9, gen_loss = 0.9709840764390661, disc_loss = 0.0008619862164623361
Trained batch 235 in epoch 9, gen_loss = 0.9708814103219469, disc_loss = 0.000859494280290565
Trained batch 236 in epoch 9, gen_loss = 0.9708699236942243, disc_loss = 0.0008571560627595179
Trained batch 237 in epoch 9, gen_loss = 0.9708624394500956, disc_loss = 0.0008549177102639904
Trained batch 238 in epoch 9, gen_loss = 0.9707798656060606, disc_loss = 0.0008526763854529826
Trained batch 239 in epoch 9, gen_loss = 0.9707154211898644, disc_loss = 0.000850376862763369
Trained batch 240 in epoch 9, gen_loss = 0.9706005748376807, disc_loss = 0.0008482298397974022
Trained batch 241 in epoch 9, gen_loss = 0.9706963485430095, disc_loss = 0.0008465245505963252
Trained batch 242 in epoch 9, gen_loss = 0.9706867241565093, disc_loss = 0.0008443559783078738
Trained batch 243 in epoch 9, gen_loss = 0.9707528816871955, disc_loss = 0.0008423597719229292
Trained batch 244 in epoch 9, gen_loss = 0.9706663900492143, disc_loss = 0.0008406286725978729
Trained batch 245 in epoch 9, gen_loss = 0.9707214197492212, disc_loss = 0.0008396319561705137
Trained batch 246 in epoch 9, gen_loss = 0.9707056187425065, disc_loss = 0.0008396408647305411
Trained batch 247 in epoch 9, gen_loss = 0.970693193135723, disc_loss = 0.000840246160042889
Testing Epoch 9
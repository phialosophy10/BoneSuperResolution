/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 1
Epoch 1, batch no. 10, gen. loss: 49886928.0, disc. loss: 0.7493152022361755
Epoch 1, batch no. 20, gen. loss: 73065736.0, disc. loss: 0.5381189584732056
Epoch 1, batch no. 30, gen. loss: 50174816.0, disc. loss: 0.3469140827655792
Epoch 1, batch no. 40, gen. loss: 58435992.0, disc. loss: 0.3295653760433197
Epoch 1, batch no. 50, gen. loss: 62346664.0, disc. loss: 0.3502337336540222
Epoch 1, batch no. 60, gen. loss: 54352328.0, disc. loss: 0.3311915993690491
Epoch 1, batch no. 70, gen. loss: 21134302.0, disc. loss: 0.32835420966148376
Epoch 1, batch no. 80, gen. loss: 46773660.0, disc. loss: 0.3279976546764374
Epoch 1, batch no. 90, gen. loss: 24569258.0, disc. loss: 0.33093053102493286
Epoch 1, batch no. 100, gen. loss: 20137306.0, disc. loss: 0.32657745480537415
Epoch 1, batch no. 110, gen. loss: 33654928.0, disc. loss: 0.3277180790901184
Epoch 1, batch no. 120, gen. loss: 24432684.0, disc. loss: 0.3258441388607025
Epoch 1, batch no. 130, gen. loss: 23039832.0, disc. loss: 0.3273642659187317
Epoch 1, batch no. 140, gen. loss: 37998312.0, disc. loss: 0.3421081602573395
Epoch 1, batch no. 150, gen. loss: 17095604.0, disc. loss: 0.32932785153388977
Epoch 1, batch no. 160, gen. loss: 35274344.0, disc. loss: 0.32901138067245483
Epoch 1, batch no. 170, gen. loss: 36885664.0, disc. loss: 0.32792291045188904
Epoch 1, batch no. 180, gen. loss: 29205196.0, disc. loss: 0.337063729763031
Epoch 1, batch no. 190, gen. loss: 46229464.0, disc. loss: 0.3289277255535126
Epoch 1, batch no. 200, gen. loss: 34111236.0, disc. loss: 0.32671013474464417
Epoch 1, batch no. 210, gen. loss: 27874024.0, disc. loss: 0.32550182938575745
Epoch 1, batch no. 220, gen. loss: 29548390.0, disc. loss: 0.3266950845718384
Epoch 1, batch no. 230, gen. loss: 29935524.0, disc. loss: 0.326285183429718
Epoch 1, batch no. 240, gen. loss: 37324252.0, disc. loss: 0.3256666660308838
Epoch 1, batch no. 250, gen. loss: 39128400.0, disc. loss: 0.32564958930015564
Epoch 1, batch no. 260, gen. loss: 38381884.0, disc. loss: 0.3270493745803833
Epoch 1, batch no. 270, gen. loss: 39033556.0, disc. loss: 0.32683128118515015
Epoch 1, batch no. 280, gen. loss: 28572670.0, disc. loss: 0.3253553807735443
Epoch 1, batch no. 290, gen. loss: 14287331.0, disc. loss: 0.3255496919155121
Epoch 1, batch no. 300, gen. loss: 49247404.0, disc. loss: 0.325822114944458
Epoch 1, batch no. 310, gen. loss: 37236692.0, disc. loss: 0.3257092833518982
Epoch 1, batch no. 320, gen. loss: 56118216.0, disc. loss: 0.3253093361854553
Epoch 1, batch no. 330, gen. loss: 28486306.0, disc. loss: 0.32668375968933105
Epoch 1, batch no. 340, gen. loss: 26367338.0, disc. loss: 0.32627126574516296
Epoch 1, batch no. 350, gen. loss: 40005516.0, disc. loss: 0.3254828453063965
Epoch 1, batch no. 360, gen. loss: 41264416.0, disc. loss: 0.3256310224533081
Epoch 1, batch no. 370, gen. loss: 49836520.0, disc. loss: 0.325179785490036
Epoch 1, batch no. 380, gen. loss: 18116410.0, disc. loss: 0.3253122866153717
Epoch 1, batch no. 390, gen. loss: 21840392.0, disc. loss: 0.325291246175766
Epoch 1, batch no. 400, gen. loss: 43458260.0, disc. loss: 0.39642098546028137
Epoch 1, batch no. 410, gen. loss: 34835388.0, disc. loss: 0.3397020697593689
Epoch 1, batch no. 420, gen. loss: 30956830.0, disc. loss: 0.32969990372657776
Epoch 1, batch no. 430, gen. loss: 29469488.0, disc. loss: 0.4056897759437561
Epoch 1, batch no. 440, gen. loss: 29382564.0, disc. loss: 1.0078588724136353
Epoch 1, batch no. 450, gen. loss: 27536076.0, disc. loss: 0.33045560121536255
Epoch 1, batch no. 460, gen. loss: 24571452.0, disc. loss: 0.3682328164577484
Epoch 1, batch no. 470, gen. loss: 26817728.0, disc. loss: 0.3615996241569519
Epoch 1, batch no. 480, gen. loss: 40076512.0, disc. loss: 0.6580066084861755
Epoch 1, batch no. 490, gen. loss: 36081696.0, disc. loss: 0.3691697418689728
Epoch 1, batch no. 500, gen. loss: 31221524.0, disc. loss: 0.3361186385154724
Epoch 1, batch no. 510, gen. loss: 46271484.0, disc. loss: 0.3322620391845703
Epoch 1, batch no. 520, gen. loss: 18734624.0, disc. loss: 0.33319830894470215
Epoch 1, batch no. 530, gen. loss: 20019384.0, disc. loss: 0.32663363218307495
Epoch 1, batch no. 540, gen. loss: 21842004.0, disc. loss: 0.3273240327835083
Epoch 1, batch no. 550, gen. loss: 23096094.0, disc. loss: 0.32518264651298523
Epoch 1, batch no. 560, gen. loss: 46799508.0, disc. loss: 0.3262673020362854
Epoch 1, batch no. 570, gen. loss: 42310444.0, disc. loss: 0.32688286900520325
Epoch 1, batch no. 580, gen. loss: 17539668.0, disc. loss: 0.32549339532852173
Epoch 1, batch no. 590, gen. loss: 22262752.0, disc. loss: 0.32581645250320435
Epoch 1, batch no. 600, gen. loss: 33048936.0, disc. loss: 0.3258514702320099
Epoch 1, batch no. 610, gen. loss: 30441908.0, disc. loss: 0.32536807656288147
Epoch 1, batch no. 620, gen. loss: 30981164.0, disc. loss: 0.3258008658885956
Epoch 1, batch no. 630, gen. loss: 24639548.0, disc. loss: 0.3252963721752167
Epoch 1, batch no. 640, gen. loss: 31289788.0, disc. loss: 0.3251885175704956
Epoch 1, batch no. 650, gen. loss: 28029948.0, disc. loss: 0.3256950080394745
Epoch 1, batch no. 660, gen. loss: 44029752.0, disc. loss: 0.3368762135505676
Epoch 1, batch no. 670, gen. loss: 32290636.0, disc. loss: 0.3252022862434387
Epoch 1, batch no. 680, gen. loss: 13711825.0, disc. loss: 0.3253457546234131
Epoch 1, batch no. 690, gen. loss: 26832126.0, disc. loss: 0.3253015875816345
Epoch 1, batch no. 700, gen. loss: 38657728.0, disc. loss: 0.32580333948135376
Epoch 1, batch no. 710, gen. loss: 24968444.0, disc. loss: 0.32561564445495605
Epoch 1, batch no. 720, gen. loss: 19107702.0, disc. loss: 0.32513779401779175
Epoch 1, batch no. 730, gen. loss: 32413980.0, disc. loss: 0.3252580165863037
Epoch 1, batch no. 740, gen. loss: 22094836.0, disc. loss: 0.3253258168697357
Epoch 1, batch no. 750, gen. loss: 20605486.0, disc. loss: 0.32540076971054077
Epoch 1, batch no. 760, gen. loss: 17954740.0, disc. loss: 0.3252301812171936
Testing Epoch 1
Discriminator training/validation loss in epoch 1/1 was 0.3596/0.3280
Generator GAN training/validation loss in epoch 1/1 was 33039704.1592/85419275.7086
Average PSNR of validation set in epoch 1/1 was 6.1252
Average SSIM of validation set in epoch 1/1 was 0.0037
Average discriminator guess on reals in epoch 1/1 was 0.8981
Average discriminator guess on fakes in epoch 1/1 was 0.0000
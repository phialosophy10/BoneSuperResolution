/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 1.0871031284332275, disc_loss = 0.6269732713699341
Trained batch 1 in epoch 0, gen_loss = 1.2254258394241333, disc_loss = 0.9711524248123169
Trained batch 2 in epoch 0, gen_loss = 1.1442849040031433, disc_loss = 0.7729840079943339
Trained batch 3 in epoch 0, gen_loss = 1.0657888501882553, disc_loss = 0.661260575056076
Trained batch 4 in epoch 0, gen_loss = 1.0226545929908752, disc_loss = 0.5750103622674942
Trained batch 5 in epoch 0, gen_loss = 0.9790407915910085, disc_loss = 0.50807403276364
Trained batch 6 in epoch 0, gen_loss = 0.9468780755996704, disc_loss = 0.4589941991227014
Trained batch 7 in epoch 0, gen_loss = 0.9155604839324951, disc_loss = 0.43218191899359226
Trained batch 8 in epoch 0, gen_loss = 0.8949344224399991, disc_loss = 0.4106158001555337
Trained batch 9 in epoch 0, gen_loss = 0.9028579711914062, disc_loss = 0.39541611522436143
Trained batch 10 in epoch 0, gen_loss = 0.8901542154225436, disc_loss = 0.3808210329575972
Trained batch 11 in epoch 0, gen_loss = 0.8799820393323898, disc_loss = 0.3725242540240288
Trained batch 12 in epoch 0, gen_loss = 0.8783429173322824, disc_loss = 0.3605725306731004
Trained batch 13 in epoch 0, gen_loss = 0.8745200761726925, disc_loss = 0.34566710889339447
Trained batch 14 in epoch 0, gen_loss = 0.8656230409940083, disc_loss = 0.3317249397436778
Trained batch 15 in epoch 0, gen_loss = 0.8581696413457394, disc_loss = 0.32333486899733543
Trained batch 16 in epoch 0, gen_loss = 0.8611217596951652, disc_loss = 0.3149860185735366
Trained batch 17 in epoch 0, gen_loss = 0.8493931293487549, disc_loss = 0.3100672952002949
Trained batch 18 in epoch 0, gen_loss = 0.8423961714694375, disc_loss = 0.3072930346978338
Trained batch 19 in epoch 0, gen_loss = 0.8402248293161392, disc_loss = 0.30371799096465113
Trained batch 20 in epoch 0, gen_loss = 0.8404541526521955, disc_loss = 0.3005220010167077
Trained batch 21 in epoch 0, gen_loss = 0.8466388366439126, disc_loss = 0.29590407758951187
Trained batch 22 in epoch 0, gen_loss = 0.848433054011801, disc_loss = 0.28907779247864435
Trained batch 23 in epoch 0, gen_loss = 0.8484134425719579, disc_loss = 0.2827620307604472
Trained batch 24 in epoch 0, gen_loss = 0.8488461828231811, disc_loss = 0.276959525346756
Trained batch 25 in epoch 0, gen_loss = 0.8521716411297138, disc_loss = 0.2718010831337709
Trained batch 26 in epoch 0, gen_loss = 0.8544657760196261, disc_loss = 0.26696855271304093
Trained batch 27 in epoch 0, gen_loss = 0.8542025515011379, disc_loss = 0.26104445436171125
Trained batch 28 in epoch 0, gen_loss = 0.8521235646872685, disc_loss = 0.2551560342825692
Trained batch 29 in epoch 0, gen_loss = 0.8550868093967438, disc_loss = 0.2491135078171889
Trained batch 30 in epoch 0, gen_loss = 0.8588148028619828, disc_loss = 0.2439424313845173
Trained batch 31 in epoch 0, gen_loss = 0.860558470711112, disc_loss = 0.2383019682019949
Trained batch 32 in epoch 0, gen_loss = 0.8630072727347865, disc_loss = 0.23277699755448283
Trained batch 33 in epoch 0, gen_loss = 0.8653575217022615, disc_loss = 0.22772548665456913
Trained batch 34 in epoch 0, gen_loss = 0.8669697216578892, disc_loss = 0.22295350996511323
Trained batch 35 in epoch 0, gen_loss = 0.8716278904014163, disc_loss = 0.21856342680338356
Trained batch 36 in epoch 0, gen_loss = 0.8764753921611889, disc_loss = 0.21440313041612907
Trained batch 37 in epoch 0, gen_loss = 0.8817519639667711, disc_loss = 0.21031350240503488
Trained batch 38 in epoch 0, gen_loss = 0.8865153055924636, disc_loss = 0.20635429597817934
Trained batch 39 in epoch 0, gen_loss = 0.888585202395916, disc_loss = 0.20365368910133838
Trained batch 40 in epoch 0, gen_loss = 0.8973203504957804, disc_loss = 0.20033030866122828
Trained batch 41 in epoch 0, gen_loss = 0.9039806084973472, disc_loss = 0.1967603259143375
Trained batch 42 in epoch 0, gen_loss = 0.9094438816225806, disc_loss = 0.19404394889986792
Trained batch 43 in epoch 0, gen_loss = 0.9144649248231541, disc_loss = 0.19156616553664207
Trained batch 44 in epoch 0, gen_loss = 0.9209150009685092, disc_loss = 0.18916863269276088
Trained batch 45 in epoch 0, gen_loss = 0.9269914588202601, disc_loss = 0.18616484818251236
Trained batch 46 in epoch 0, gen_loss = 0.9313940963846572, disc_loss = 0.18307476665111297
Trained batch 47 in epoch 0, gen_loss = 0.9345156215131283, disc_loss = 0.18016822325686613
Trained batch 48 in epoch 0, gen_loss = 0.9401572930569552, disc_loss = 0.17739002999602532
Trained batch 49 in epoch 0, gen_loss = 0.9420421373844147, disc_loss = 0.17445122979581357
Trained batch 50 in epoch 0, gen_loss = 0.9412795036446815, disc_loss = 0.1721482073121211
Trained batch 51 in epoch 0, gen_loss = 0.946539492561267, disc_loss = 0.17054305447695348
Trained batch 52 in epoch 0, gen_loss = 0.9414362412578655, disc_loss = 0.17043497026810106
Trained batch 53 in epoch 0, gen_loss = 0.9477359939504553, disc_loss = 0.17337035298071526
Trained batch 54 in epoch 0, gen_loss = 0.9456940813498064, disc_loss = 0.17198298891836947
Trained batch 55 in epoch 0, gen_loss = 0.9407367376344544, disc_loss = 0.17084572883322835
Trained batch 56 in epoch 0, gen_loss = 0.9398126173437688, disc_loss = 0.16910347884945703
Trained batch 57 in epoch 0, gen_loss = 0.9390736664163655, disc_loss = 0.16704644667434282
Trained batch 58 in epoch 0, gen_loss = 0.940546844975423, disc_loss = 0.16485701633964556
Trained batch 59 in epoch 0, gen_loss = 0.941154471039772, disc_loss = 0.1628996099655827
Trained batch 60 in epoch 0, gen_loss = 0.943260883698698, disc_loss = 0.16087087512504858
Trained batch 61 in epoch 0, gen_loss = 0.9461685947833522, disc_loss = 0.15889968314478475
Trained batch 62 in epoch 0, gen_loss = 0.9447717770697579, disc_loss = 0.1571190571855931
Trained batch 63 in epoch 0, gen_loss = 0.9441243400797248, disc_loss = 0.15514756354968995
Trained batch 64 in epoch 0, gen_loss = 0.9458234300980202, disc_loss = 0.1532725601242139
Trained batch 65 in epoch 0, gen_loss = 0.9461229858976422, disc_loss = 0.15142851842172217
Trained batch 66 in epoch 0, gen_loss = 0.9460054529247, disc_loss = 0.14967770557572593
Trained batch 67 in epoch 0, gen_loss = 0.946670709287419, disc_loss = 0.14805188660016833
Trained batch 68 in epoch 0, gen_loss = 0.9476761990699215, disc_loss = 0.1464173212863397
Trained batch 69 in epoch 0, gen_loss = 0.9521655082702637, disc_loss = 0.14489621328456062
Trained batch 70 in epoch 0, gen_loss = 0.9518126106598008, disc_loss = 0.14369957044091022
Trained batch 71 in epoch 0, gen_loss = 0.9525608859128423, disc_loss = 0.1421710952805976
Trained batch 72 in epoch 0, gen_loss = 0.9551507324388583, disc_loss = 0.1410969231941112
Trained batch 73 in epoch 0, gen_loss = 0.9522135297994356, disc_loss = 0.14146157147715221
Trained batch 74 in epoch 0, gen_loss = 0.9548796931902568, disc_loss = 0.1405263980726401
Trained batch 75 in epoch 0, gen_loss = 0.9556347594449395, disc_loss = 0.13914215608843064
Trained batch 76 in epoch 0, gen_loss = 0.9554981109383819, disc_loss = 0.13779077422502753
Trained batch 77 in epoch 0, gen_loss = 0.9568204383055369, disc_loss = 0.13635829315544704
Trained batch 78 in epoch 0, gen_loss = 0.9569360251668133, disc_loss = 0.13508066850938374
Trained batch 79 in epoch 0, gen_loss = 0.9579415373504162, disc_loss = 0.13377672219648956
Trained batch 80 in epoch 0, gen_loss = 0.958423067022253, disc_loss = 0.1324611883840443
Trained batch 81 in epoch 0, gen_loss = 0.9635793988297625, disc_loss = 0.1314133308464434
Trained batch 82 in epoch 0, gen_loss = 0.9653989751654936, disc_loss = 0.130102351442518
Trained batch 83 in epoch 0, gen_loss = 0.9661616796538943, disc_loss = 0.12885897298387827
Trained batch 84 in epoch 0, gen_loss = 0.9669674887376674, disc_loss = 0.12762799558832366
Trained batch 85 in epoch 0, gen_loss = 0.9673006243483965, disc_loss = 0.12654287677778062
Trained batch 86 in epoch 0, gen_loss = 0.9680095815110481, disc_loss = 0.12533346223163194
Trained batch 87 in epoch 0, gen_loss = 0.9683756665749983, disc_loss = 0.12429335491139103
Trained batch 88 in epoch 0, gen_loss = 0.9681982217210062, disc_loss = 0.12338569444300754
Trained batch 89 in epoch 0, gen_loss = 0.9670585506492191, disc_loss = 0.12242673823816909
Trained batch 90 in epoch 0, gen_loss = 0.9681406106267657, disc_loss = 0.1214932780712843
Trained batch 91 in epoch 0, gen_loss = 0.9687990591577862, disc_loss = 0.12064702195398834
Trained batch 92 in epoch 0, gen_loss = 0.9655008283994531, disc_loss = 0.12134772396936852
Trained batch 93 in epoch 0, gen_loss = 0.9706568648206427, disc_loss = 0.12671889763008407
Trained batch 94 in epoch 0, gen_loss = 0.9694584808851543, disc_loss = 0.12682645934584894
Trained batch 95 in epoch 0, gen_loss = 0.9669254310429096, disc_loss = 0.12823676242260262
Trained batch 96 in epoch 0, gen_loss = 0.966626904674412, disc_loss = 0.12927226847056875
Trained batch 97 in epoch 0, gen_loss = 0.9657825657299587, disc_loss = 0.1308437438529669
Trained batch 98 in epoch 0, gen_loss = 0.9638950282877142, disc_loss = 0.13126875341615893
Trained batch 99 in epoch 0, gen_loss = 0.9621627688407898, disc_loss = 0.13104060949757695
Trained batch 100 in epoch 0, gen_loss = 0.9620193833171731, disc_loss = 0.13101220368822614
Trained batch 101 in epoch 0, gen_loss = 0.960359635890699, disc_loss = 0.13067946453377896
Trained batch 102 in epoch 0, gen_loss = 0.9589250296064951, disc_loss = 0.13063634427499424
Trained batch 103 in epoch 0, gen_loss = 0.9580283818336633, disc_loss = 0.1301300988640063
Trained batch 104 in epoch 0, gen_loss = 0.9570161251794724, disc_loss = 0.1294953638776427
Trained batch 105 in epoch 0, gen_loss = 0.9592731662516324, disc_loss = 0.12944184737455733
Trained batch 106 in epoch 0, gen_loss = 0.9574673058830689, disc_loss = 0.12993093700122052
Trained batch 107 in epoch 0, gen_loss = 0.9580382434306322, disc_loss = 0.12934002709678477
Trained batch 108 in epoch 0, gen_loss = 0.9590439561310165, disc_loss = 0.12891882680219793
Trained batch 109 in epoch 0, gen_loss = 0.9579157352447509, disc_loss = 0.12866868242960083
Trained batch 110 in epoch 0, gen_loss = 0.9595020429508107, disc_loss = 0.12795317792207808
Trained batch 111 in epoch 0, gen_loss = 0.9597403433706079, disc_loss = 0.12720288810253674
Trained batch 112 in epoch 0, gen_loss = 0.9591136891230018, disc_loss = 0.12652837186722102
Trained batch 113 in epoch 0, gen_loss = 0.9601787856796331, disc_loss = 0.12582077077802337
Trained batch 114 in epoch 0, gen_loss = 0.9599982308304829, disc_loss = 0.12536158534171787
Trained batch 115 in epoch 0, gen_loss = 0.961184099316597, disc_loss = 0.12530773805839748
Trained batch 116 in epoch 0, gen_loss = 0.9589376867326915, disc_loss = 0.12631264422884864
Trained batch 117 in epoch 0, gen_loss = 0.9584692120552063, disc_loss = 0.12606553195075967
Trained batch 118 in epoch 0, gen_loss = 0.9609514995783317, disc_loss = 0.12863404026740238
Trained batch 119 in epoch 0, gen_loss = 0.9575725128253301, disc_loss = 0.1300087274828305
Trained batch 120 in epoch 0, gen_loss = 0.9562326980031226, disc_loss = 0.13013885821377444
Trained batch 121 in epoch 0, gen_loss = 0.955815428104557, disc_loss = 0.13232686253050802
Trained batch 122 in epoch 0, gen_loss = 0.954790338268125, disc_loss = 0.13254884168566242
Trained batch 123 in epoch 0, gen_loss = 0.9530015111930908, disc_loss = 0.13332924695925846
Trained batch 124 in epoch 0, gen_loss = 0.9522505493164063, disc_loss = 0.13302138720452786
Trained batch 125 in epoch 0, gen_loss = 0.9515945854641142, disc_loss = 0.13333589593983358
Trained batch 126 in epoch 0, gen_loss = 0.9502484404195951, disc_loss = 0.1331133728509578
Trained batch 127 in epoch 0, gen_loss = 0.948446003254503, disc_loss = 0.133296067462652
Trained batch 128 in epoch 0, gen_loss = 0.9484031251234601, disc_loss = 0.13392723217433275
Trained batch 129 in epoch 0, gen_loss = 0.9472184873544253, disc_loss = 0.1340444344597367
Trained batch 130 in epoch 0, gen_loss = 0.9459022811350931, disc_loss = 0.13411497021847554
Trained batch 131 in epoch 0, gen_loss = 0.9459643905813043, disc_loss = 0.13397178238709317
Trained batch 132 in epoch 0, gen_loss = 0.9450339616689467, disc_loss = 0.13364811408284463
Trained batch 133 in epoch 0, gen_loss = 0.9448406109169348, disc_loss = 0.1330796758324575
Trained batch 134 in epoch 0, gen_loss = 0.9442341270270171, disc_loss = 0.13266161218009614
Trained batch 135 in epoch 0, gen_loss = 0.9437791560502613, disc_loss = 0.13218528307590852
Trained batch 136 in epoch 0, gen_loss = 0.9434694217069306, disc_loss = 0.13168812582582018
Trained batch 137 in epoch 0, gen_loss = 0.9452090228813282, disc_loss = 0.1313570647270999
Trained batch 138 in epoch 0, gen_loss = 0.9429387355879914, disc_loss = 0.13200665808034887
Trained batch 139 in epoch 0, gen_loss = 0.942446939434324, disc_loss = 0.13180328225716947
Trained batch 140 in epoch 0, gen_loss = 0.943215734569739, disc_loss = 0.13134851640896172
Trained batch 141 in epoch 0, gen_loss = 0.9414474896981683, disc_loss = 0.13173251033721256
Trained batch 142 in epoch 0, gen_loss = 0.9429251230680026, disc_loss = 0.13209297389469363
Trained batch 143 in epoch 0, gen_loss = 0.9410151292880377, disc_loss = 0.13229213004362667
Trained batch 144 in epoch 0, gen_loss = 0.9398869535018658, disc_loss = 0.1321731589092263
Trained batch 145 in epoch 0, gen_loss = 0.9412031136963466, disc_loss = 0.13339217692256383
Trained batch 146 in epoch 0, gen_loss = 0.941473820582539, disc_loss = 0.13283009861348843
Trained batch 147 in epoch 0, gen_loss = 0.9396124047202032, disc_loss = 0.13348074744430347
Trained batch 148 in epoch 0, gen_loss = 0.9398426713559451, disc_loss = 0.13408644811169013
Trained batch 149 in epoch 0, gen_loss = 0.9384829306602478, disc_loss = 0.13400777343660594
Trained batch 150 in epoch 0, gen_loss = 0.9378135575363967, disc_loss = 0.13398825297045786
Trained batch 151 in epoch 0, gen_loss = 0.9381946184133229, disc_loss = 0.13436460194766128
Trained batch 152 in epoch 0, gen_loss = 0.936521019031799, disc_loss = 0.13514207482484042
Trained batch 153 in epoch 0, gen_loss = 0.9356193554091763, disc_loss = 0.13531950342335872
Trained batch 154 in epoch 0, gen_loss = 0.9345827206488578, disc_loss = 0.13537292464846565
Trained batch 155 in epoch 0, gen_loss = 0.9336123157006043, disc_loss = 0.13529853086966354
Trained batch 156 in epoch 0, gen_loss = 0.9319429940478817, disc_loss = 0.13548208444503843
Trained batch 157 in epoch 0, gen_loss = 0.9327606185327603, disc_loss = 0.13595591206103563
Trained batch 158 in epoch 0, gen_loss = 0.9312333858238077, disc_loss = 0.13643589281951482
Trained batch 159 in epoch 0, gen_loss = 0.9302872743457555, disc_loss = 0.1366187566309236
Trained batch 160 in epoch 0, gen_loss = 0.9296649672229838, disc_loss = 0.13646552118224017
Trained batch 161 in epoch 0, gen_loss = 0.9285140626224471, disc_loss = 0.13668950705754537
Trained batch 162 in epoch 0, gen_loss = 0.9294733035783826, disc_loss = 0.1373812255843834
Trained batch 163 in epoch 0, gen_loss = 0.9276012640173842, disc_loss = 0.1382639816417018
Trained batch 164 in epoch 0, gen_loss = 0.9279496799815785, disc_loss = 0.13896310685033147
Trained batch 165 in epoch 0, gen_loss = 0.9266526296914342, disc_loss = 0.1390681434983769
Trained batch 166 in epoch 0, gen_loss = 0.9252813426320424, disc_loss = 0.13931006151892825
Trained batch 167 in epoch 0, gen_loss = 0.9249617748317265, disc_loss = 0.13945150760091132
Trained batch 168 in epoch 0, gen_loss = 0.9246605426602109, disc_loss = 0.1393455524747012
Trained batch 169 in epoch 0, gen_loss = 0.9230714678764343, disc_loss = 0.13950167073703865
Trained batch 170 in epoch 0, gen_loss = 0.9229913413176063, disc_loss = 0.13938902652882346
Trained batch 171 in epoch 0, gen_loss = 0.9224999352943065, disc_loss = 0.1391712905687475
Trained batch 172 in epoch 0, gen_loss = 0.9213083424320111, disc_loss = 0.13911435717576845
Trained batch 173 in epoch 0, gen_loss = 0.9210146408656548, disc_loss = 0.13897547604323462
Trained batch 174 in epoch 0, gen_loss = 0.9204998125348772, disc_loss = 0.13876034377941063
Trained batch 175 in epoch 0, gen_loss = 0.9199162173000249, disc_loss = 0.1385146359045228
Trained batch 176 in epoch 0, gen_loss = 0.9192353439869854, disc_loss = 0.13838982294802948
Trained batch 177 in epoch 0, gen_loss = 0.9207551285122217, disc_loss = 0.13897097226902005
Trained batch 178 in epoch 0, gen_loss = 0.918953561250058, disc_loss = 0.1399156637593854
Trained batch 179 in epoch 0, gen_loss = 0.9192071199417114, disc_loss = 0.1396688964528342
Trained batch 180 in epoch 0, gen_loss = 0.9194788458597595, disc_loss = 0.1394616481822334
Trained batch 181 in epoch 0, gen_loss = 0.9180624062543387, disc_loss = 0.13958174746565438
Trained batch 182 in epoch 0, gen_loss = 0.9186773394626346, disc_loss = 0.13967182868938954
Trained batch 183 in epoch 0, gen_loss = 0.9184837610177372, disc_loss = 0.13941715567615692
Trained batch 184 in epoch 0, gen_loss = 0.9191303198401992, disc_loss = 0.13890978302303197
Trained batch 185 in epoch 0, gen_loss = 0.9196028321660975, disc_loss = 0.13861740055063398
Trained batch 186 in epoch 0, gen_loss = 0.9178693119217368, disc_loss = 0.13886581722866087
Trained batch 187 in epoch 0, gen_loss = 0.9190751913380115, disc_loss = 0.13990151758325545
Trained batch 188 in epoch 0, gen_loss = 0.9178256562777928, disc_loss = 0.1399104768932654
Trained batch 189 in epoch 0, gen_loss = 0.9166140951608357, disc_loss = 0.14013743968190331
Trained batch 190 in epoch 0, gen_loss = 0.9168653853276637, disc_loss = 0.140610630160773
Trained batch 191 in epoch 0, gen_loss = 0.9161069930220643, disc_loss = 0.14074937140685506
Trained batch 192 in epoch 0, gen_loss = 0.9153630764373226, disc_loss = 0.14052988414126666
Trained batch 193 in epoch 0, gen_loss = 0.9147224957795487, disc_loss = 0.14034354297885882
Trained batch 194 in epoch 0, gen_loss = 0.9140501566422291, disc_loss = 0.14053519485661617
Trained batch 195 in epoch 0, gen_loss = 0.9147808399735665, disc_loss = 0.14143774957795227
Trained batch 196 in epoch 0, gen_loss = 0.9136240839353068, disc_loss = 0.14203011515895425
Trained batch 197 in epoch 0, gen_loss = 0.9139284985234039, disc_loss = 0.14229352504127857
Trained batch 198 in epoch 0, gen_loss = 0.9130996567520064, disc_loss = 0.14209680430516225
Trained batch 199 in epoch 0, gen_loss = 0.9120776817202568, disc_loss = 0.14212902060709895
Trained batch 200 in epoch 0, gen_loss = 0.9109280358499555, disc_loss = 0.14207419070104757
Trained batch 201 in epoch 0, gen_loss = 0.9102662807644004, disc_loss = 0.14185872614051742
Trained batch 202 in epoch 0, gen_loss = 0.9101287194073494, disc_loss = 0.1416252569520268
Trained batch 203 in epoch 0, gen_loss = 0.9098388219580931, disc_loss = 0.1413696470268655
Trained batch 204 in epoch 0, gen_loss = 0.909437222015567, disc_loss = 0.1409800918454804
Trained batch 205 in epoch 0, gen_loss = 0.909110503867992, disc_loss = 0.14071063126790004
Trained batch 206 in epoch 0, gen_loss = 0.908625152375963, disc_loss = 0.1405481225428518
Trained batch 207 in epoch 0, gen_loss = 0.9087864011526108, disc_loss = 0.14036408862851274
Trained batch 208 in epoch 0, gen_loss = 0.9078098144827847, disc_loss = 0.14033821404301094
Trained batch 209 in epoch 0, gen_loss = 0.9090935113884154, disc_loss = 0.14095194816057172
Trained batch 210 in epoch 0, gen_loss = 0.9081971484337937, disc_loss = 0.14144952341878866
Trained batch 211 in epoch 0, gen_loss = 0.9082116158503406, disc_loss = 0.14121413421553541
Trained batch 212 in epoch 0, gen_loss = 0.9083211405176512, disc_loss = 0.14125445185167967
Trained batch 213 in epoch 0, gen_loss = 0.9070120852127254, disc_loss = 0.141829454113738
Trained batch 214 in epoch 0, gen_loss = 0.9076566399529923, disc_loss = 0.14204878482187902
Trained batch 215 in epoch 0, gen_loss = 0.9076064847133778, disc_loss = 0.14172306354157627
Trained batch 216 in epoch 0, gen_loss = 0.9067650280789845, disc_loss = 0.1416487633443785
Trained batch 217 in epoch 0, gen_loss = 0.9065161369262486, disc_loss = 0.14135843752071672
Trained batch 218 in epoch 0, gen_loss = 0.906464641224848, disc_loss = 0.14115548349032392
Trained batch 219 in epoch 0, gen_loss = 0.9056215963580392, disc_loss = 0.14100948948921127
Trained batch 220 in epoch 0, gen_loss = 0.9055584569322578, disc_loss = 0.14062271686060127
Trained batch 221 in epoch 0, gen_loss = 0.9053449671010714, disc_loss = 0.14037604798638337
Trained batch 222 in epoch 0, gen_loss = 0.9046623664051963, disc_loss = 0.14021732024180247
Trained batch 223 in epoch 0, gen_loss = 0.9051451853343419, disc_loss = 0.140119262380592
Trained batch 224 in epoch 0, gen_loss = 0.9039819836616516, disc_loss = 0.14011204826335114
Trained batch 225 in epoch 0, gen_loss = 0.9045721669640161, disc_loss = 0.14018385179044135
Trained batch 226 in epoch 0, gen_loss = 0.9035987636066218, disc_loss = 0.14024565688084137
Trained batch 227 in epoch 0, gen_loss = 0.9036547915454496, disc_loss = 0.14019901881386576
Trained batch 228 in epoch 0, gen_loss = 0.905064477410379, disc_loss = 0.14048867767847523
Trained batch 229 in epoch 0, gen_loss = 0.903717203243919, disc_loss = 0.14089223846955143
Trained batch 230 in epoch 0, gen_loss = 0.9040097380097294, disc_loss = 0.14103955456995088
Trained batch 231 in epoch 0, gen_loss = 0.9033282584157484, disc_loss = 0.14095176638360937
Trained batch 232 in epoch 0, gen_loss = 0.9030773678051044, disc_loss = 0.14089319261006786
Trained batch 233 in epoch 0, gen_loss = 0.9025104832954896, disc_loss = 0.14086322598636913
Trained batch 234 in epoch 0, gen_loss = 0.9019943217013745, disc_loss = 0.1406574017903272
Trained batch 235 in epoch 0, gen_loss = 0.9022397909124019, disc_loss = 0.14023269988375447
Trained batch 236 in epoch 0, gen_loss = 0.9016027888165244, disc_loss = 0.14000029164810474
Trained batch 237 in epoch 0, gen_loss = 0.9023013776089964, disc_loss = 0.13991763011528915
Trained batch 238 in epoch 0, gen_loss = 0.9018869058357621, disc_loss = 0.13959471723181682
Trained batch 239 in epoch 0, gen_loss = 0.9018867048124473, disc_loss = 0.1392242420387144
Trained batch 240 in epoch 0, gen_loss = 0.9018166253180919, disc_loss = 0.13884283938441286
Trained batch 241 in epoch 0, gen_loss = 0.9022078169278862, disc_loss = 0.13858412762657424
Trained batch 242 in epoch 0, gen_loss = 0.9017939700020684, disc_loss = 0.1383107620916126
Trained batch 243 in epoch 0, gen_loss = 0.9026508692835198, disc_loss = 0.13817174753296327
Trained batch 244 in epoch 0, gen_loss = 0.9017527052334376, disc_loss = 0.13834359070324168
Trained batch 245 in epoch 0, gen_loss = 0.9024769365787506, disc_loss = 0.13803892802992246
Trained batch 246 in epoch 0, gen_loss = 0.9033738106851154, disc_loss = 0.13761839779614196
Trained batch 247 in epoch 0, gen_loss = 0.9044374619280139, disc_loss = 0.13714234593264277
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 1.0531339645385742, disc_loss = 0.02745519019663334
Trained batch 1 in epoch 1, gen_loss = 0.9581116437911987, disc_loss = 0.03668552357703447
Trained batch 2 in epoch 1, gen_loss = 1.0003913243611653, disc_loss = 0.03155111831923326
Trained batch 3 in epoch 1, gen_loss = 1.0759627521038055, disc_loss = 0.03812596062198281
Trained batch 4 in epoch 1, gen_loss = 1.0876293420791625, disc_loss = 0.03387714400887489
Trained batch 5 in epoch 1, gen_loss = 1.0482332309087117, disc_loss = 0.03574587901433309
Trained batch 6 in epoch 1, gen_loss = 1.0434445142745972, disc_loss = 0.032774611110133786
Trained batch 7 in epoch 1, gen_loss = 1.0449241697788239, disc_loss = 0.03059742145705968
Trained batch 8 in epoch 1, gen_loss = 1.030263344446818, disc_loss = 0.029662066967123084
Trained batch 9 in epoch 1, gen_loss = 1.032419466972351, disc_loss = 0.0290301282890141
Trained batch 10 in epoch 1, gen_loss = 1.0224132429469714, disc_loss = 0.029443303038450806
Trained batch 11 in epoch 1, gen_loss = 1.0041480163733165, disc_loss = 0.03380660875700414
Trained batch 12 in epoch 1, gen_loss = 1.025159551547124, disc_loss = 0.055358161505025164
Trained batch 13 in epoch 1, gen_loss = 0.9971713381154197, disc_loss = 0.06052001279645732
Trained batch 14 in epoch 1, gen_loss = 0.9923962434132894, disc_loss = 0.06800955664366484
Trained batch 15 in epoch 1, gen_loss = 0.9677972942590714, disc_loss = 0.07575867074774578
Trained batch 16 in epoch 1, gen_loss = 0.9664731095818913, disc_loss = 0.0848079142434632
Trained batch 17 in epoch 1, gen_loss = 0.9580100443628099, disc_loss = 0.08811502598433031
Trained batch 18 in epoch 1, gen_loss = 0.9408111791861685, disc_loss = 0.0905483202812703
Trained batch 19 in epoch 1, gen_loss = 0.9299995511770248, disc_loss = 0.09183482513763011
Trained batch 20 in epoch 1, gen_loss = 0.9207618037859598, disc_loss = 0.09288667519355104
Trained batch 21 in epoch 1, gen_loss = 0.914075946266001, disc_loss = 0.09375650930980389
Trained batch 22 in epoch 1, gen_loss = 0.9121509634930155, disc_loss = 0.09474389113323844
Trained batch 23 in epoch 1, gen_loss = 0.8972717200716337, disc_loss = 0.10198591203273584
Trained batch 24 in epoch 1, gen_loss = 0.9022759222984313, disc_loss = 0.10832360554486513
Trained batch 25 in epoch 1, gen_loss = 0.8991914024719825, disc_loss = 0.10778547497466207
Trained batch 26 in epoch 1, gen_loss = 0.8927763148590371, disc_loss = 0.10879026922500795
Trained batch 27 in epoch 1, gen_loss = 0.8888791842120034, disc_loss = 0.10846300705868218
Trained batch 28 in epoch 1, gen_loss = 0.8873335040848831, disc_loss = 0.1078265513903622
Trained batch 29 in epoch 1, gen_loss = 0.8880224863688151, disc_loss = 0.10674308206265172
Trained batch 30 in epoch 1, gen_loss = 0.881697008686681, disc_loss = 0.10779671289867931
Trained batch 31 in epoch 1, gen_loss = 0.8802721761167049, disc_loss = 0.10759975170367397
Trained batch 32 in epoch 1, gen_loss = 0.8802682775439639, disc_loss = 0.1071742291308262
Trained batch 33 in epoch 1, gen_loss = 0.8741990625858307, disc_loss = 0.10709591924815494
Trained batch 34 in epoch 1, gen_loss = 0.8777206693376813, disc_loss = 0.1102323260956577
Trained batch 35 in epoch 1, gen_loss = 0.870105117559433, disc_loss = 0.11433880706317723
Trained batch 36 in epoch 1, gen_loss = 0.8720239803597734, disc_loss = 0.11508636189171591
Trained batch 37 in epoch 1, gen_loss = 0.8735831034810919, disc_loss = 0.11716957363349043
Trained batch 38 in epoch 1, gen_loss = 0.867455855394021, disc_loss = 0.11897218621407564
Trained batch 39 in epoch 1, gen_loss = 0.8658316016197205, disc_loss = 0.11896226753015071
Trained batch 40 in epoch 1, gen_loss = 0.8678343165211562, disc_loss = 0.11867144824255531
Trained batch 41 in epoch 1, gen_loss = 0.8657345658256894, disc_loss = 0.1173050285849188
Trained batch 42 in epoch 1, gen_loss = 0.8705450712248336, disc_loss = 0.11512218946374433
Trained batch 43 in epoch 1, gen_loss = 0.874119986187328, disc_loss = 0.11322225031273608
Trained batch 44 in epoch 1, gen_loss = 0.8678360356224908, disc_loss = 0.11444927331888013
Trained batch 45 in epoch 1, gen_loss = 0.8733570420223734, disc_loss = 0.11448556551223864
Trained batch 46 in epoch 1, gen_loss = 0.875826451372593, disc_loss = 0.11377461454731987
Trained batch 47 in epoch 1, gen_loss = 0.8684807866811752, disc_loss = 0.11650092226530735
Trained batch 48 in epoch 1, gen_loss = 0.8702421504624036, disc_loss = 0.11551950592547655
Trained batch 49 in epoch 1, gen_loss = 0.871165726184845, disc_loss = 0.11511104816570877
Trained batch 50 in epoch 1, gen_loss = 0.8681308942682603, disc_loss = 0.11504124581594677
Trained batch 51 in epoch 1, gen_loss = 0.869354893381779, disc_loss = 0.11413494191275766
Trained batch 52 in epoch 1, gen_loss = 0.8740693971795855, disc_loss = 0.11289620077905227
Trained batch 53 in epoch 1, gen_loss = 0.8713588725637507, disc_loss = 0.11341705740670915
Trained batch 54 in epoch 1, gen_loss = 0.8765715219757774, disc_loss = 0.11343747595833106
Trained batch 55 in epoch 1, gen_loss = 0.8762270786932537, disc_loss = 0.11178042249022317
Trained batch 56 in epoch 1, gen_loss = 0.8748655130988673, disc_loss = 0.11086282305615514
Trained batch 57 in epoch 1, gen_loss = 0.879383150873513, disc_loss = 0.10961592693588343
Trained batch 58 in epoch 1, gen_loss = 0.8798583725751457, disc_loss = 0.10827809087616408
Trained batch 59 in epoch 1, gen_loss = 0.880621482928594, disc_loss = 0.1069236147062232
Trained batch 60 in epoch 1, gen_loss = 0.8781636171653623, disc_loss = 0.10635160754022539
Trained batch 61 in epoch 1, gen_loss = 0.8808734936098899, disc_loss = 0.10747055963222538
Trained batch 62 in epoch 1, gen_loss = 0.8778796148678613, disc_loss = 0.1074239466309784
Trained batch 63 in epoch 1, gen_loss = 0.8775143474340439, disc_loss = 0.10698029400373343
Trained batch 64 in epoch 1, gen_loss = 0.8778847685227027, disc_loss = 0.10567656934547882
Trained batch 65 in epoch 1, gen_loss = 0.8752003447576002, disc_loss = 0.1056298125450584
Trained batch 66 in epoch 1, gen_loss = 0.8788882200397662, disc_loss = 0.10672088096668916
Trained batch 67 in epoch 1, gen_loss = 0.874992516987464, disc_loss = 0.1077705735258539
Trained batch 68 in epoch 1, gen_loss = 0.8762454943380494, disc_loss = 0.10705174663630516
Trained batch 69 in epoch 1, gen_loss = 0.8785243775163378, disc_loss = 0.10615362978673407
Trained batch 70 in epoch 1, gen_loss = 0.8761194969566775, disc_loss = 0.1056102905291277
Trained batch 71 in epoch 1, gen_loss = 0.8761048904723592, disc_loss = 0.10473916592956004
Trained batch 72 in epoch 1, gen_loss = 0.8771835941157929, disc_loss = 0.1039654438651792
Trained batch 73 in epoch 1, gen_loss = 0.8761689252144581, disc_loss = 0.10306832422124776
Trained batch 74 in epoch 1, gen_loss = 0.8751844000816346, disc_loss = 0.10230749007314444
Trained batch 75 in epoch 1, gen_loss = 0.8794729058679781, disc_loss = 0.10188974034482319
Trained batch 76 in epoch 1, gen_loss = 0.8790025904581145, disc_loss = 0.10104722071245506
Trained batch 77 in epoch 1, gen_loss = 0.8812336684801639, disc_loss = 0.10013407978635186
Trained batch 78 in epoch 1, gen_loss = 0.878645930863634, disc_loss = 0.10043303483413367
Trained batch 79 in epoch 1, gen_loss = 0.8801473848521709, disc_loss = 0.10074768535559997
Trained batch 80 in epoch 1, gen_loss = 0.8773559442272892, disc_loss = 0.10145185412954033
Trained batch 81 in epoch 1, gen_loss = 0.879232958322618, disc_loss = 0.10471144776291601
Trained batch 82 in epoch 1, gen_loss = 0.8754560372915613, disc_loss = 0.10692165903073836
Trained batch 83 in epoch 1, gen_loss = 0.8747202143782661, disc_loss = 0.10745845135257003
Trained batch 84 in epoch 1, gen_loss = 0.8768233705969418, disc_loss = 0.10808441151371774
Trained batch 85 in epoch 1, gen_loss = 0.8741286743518918, disc_loss = 0.1089494719040082
Trained batch 86 in epoch 1, gen_loss = 0.8747582093052481, disc_loss = 0.10865577613271174
Trained batch 87 in epoch 1, gen_loss = 0.8749729774215005, disc_loss = 0.10813010004560718
Trained batch 88 in epoch 1, gen_loss = 0.872680090786366, disc_loss = 0.1086536856326327
Trained batch 89 in epoch 1, gen_loss = 0.8739192181163364, disc_loss = 0.10859261696330375
Trained batch 90 in epoch 1, gen_loss = 0.8731765334422772, disc_loss = 0.10814711258101922
Trained batch 91 in epoch 1, gen_loss = 0.8719418314488038, disc_loss = 0.10783728482404156
Trained batch 92 in epoch 1, gen_loss = 0.87257533496426, disc_loss = 0.10740911234570767
Trained batch 93 in epoch 1, gen_loss = 0.8701477589759421, disc_loss = 0.10777486792389065
Trained batch 94 in epoch 1, gen_loss = 0.8706490046099613, disc_loss = 0.10809463226285419
Trained batch 95 in epoch 1, gen_loss = 0.8723603865752617, disc_loss = 0.10751216314383782
Trained batch 96 in epoch 1, gen_loss = 0.8695837978235225, disc_loss = 0.11005546397423928
Trained batch 97 in epoch 1, gen_loss = 0.8690344721687083, disc_loss = 0.11001235823508124
Trained batch 98 in epoch 1, gen_loss = 0.8715527858396973, disc_loss = 0.11040641020306131
Trained batch 99 in epoch 1, gen_loss = 0.8690150135755539, disc_loss = 0.11093135937117041
Trained batch 100 in epoch 1, gen_loss = 0.8672853129925114, disc_loss = 0.11081331502646208
Trained batch 101 in epoch 1, gen_loss = 0.8684171151881125, disc_loss = 0.1105647518701267
Trained batch 102 in epoch 1, gen_loss = 0.8707158490292077, disc_loss = 0.110016568979809
Trained batch 103 in epoch 1, gen_loss = 0.8693913995073392, disc_loss = 0.10965492647105399
Trained batch 104 in epoch 1, gen_loss = 0.8678376078605652, disc_loss = 0.10929040354454801
Trained batch 105 in epoch 1, gen_loss = 0.8684871146139109, disc_loss = 0.10871162215458616
Trained batch 106 in epoch 1, gen_loss = 0.8690277739105937, disc_loss = 0.10836099247474258
Trained batch 107 in epoch 1, gen_loss = 0.8685841074696293, disc_loss = 0.107591181450213
Trained batch 108 in epoch 1, gen_loss = 0.8674792253643001, disc_loss = 0.1073865375199586
Trained batch 109 in epoch 1, gen_loss = 0.8677553930065849, disc_loss = 0.10765718655999411
Trained batch 110 in epoch 1, gen_loss = 0.8675008464503933, disc_loss = 0.1070173347268153
Trained batch 111 in epoch 1, gen_loss = 0.8677717638867242, disc_loss = 0.1062593822883043
Trained batch 112 in epoch 1, gen_loss = 0.8686566669329078, disc_loss = 0.10568844170136525
Trained batch 113 in epoch 1, gen_loss = 0.8675509398443657, disc_loss = 0.105582990070903
Trained batch 114 in epoch 1, gen_loss = 0.8689272486645242, disc_loss = 0.10594972390681505
Trained batch 115 in epoch 1, gen_loss = 0.8661655788791591, disc_loss = 0.10749021473597607
Trained batch 116 in epoch 1, gen_loss = 0.866027623669714, disc_loss = 0.10753677771864538
Trained batch 117 in epoch 1, gen_loss = 0.86657483446396, disc_loss = 0.10895517821250073
Trained batch 118 in epoch 1, gen_loss = 0.8649930738601364, disc_loss = 0.10964297446101404
Trained batch 119 in epoch 1, gen_loss = 0.8639333600799243, disc_loss = 0.11018911711095522
Trained batch 120 in epoch 1, gen_loss = 0.8629563815337568, disc_loss = 0.11070005988994659
Trained batch 121 in epoch 1, gen_loss = 0.8629593160308775, disc_loss = 0.11061626726944672
Trained batch 122 in epoch 1, gen_loss = 0.8620495912505359, disc_loss = 0.11034750386436538
Trained batch 123 in epoch 1, gen_loss = 0.8622576104056451, disc_loss = 0.11023694426271945
Trained batch 124 in epoch 1, gen_loss = 0.8644823303222656, disc_loss = 0.10964084785431623
Trained batch 125 in epoch 1, gen_loss = 0.8648072064868988, disc_loss = 0.10914694431370922
Trained batch 126 in epoch 1, gen_loss = 0.8635030440458162, disc_loss = 0.10947508918576118
Trained batch 127 in epoch 1, gen_loss = 0.8656912101432681, disc_loss = 0.10993678386876127
Trained batch 128 in epoch 1, gen_loss = 0.8646520519441412, disc_loss = 0.10970258992165327
Trained batch 129 in epoch 1, gen_loss = 0.8649629680009988, disc_loss = 0.10945786818718681
Trained batch 130 in epoch 1, gen_loss = 0.8668007500299061, disc_loss = 0.1092501447273006
Trained batch 131 in epoch 1, gen_loss = 0.8665205055113995, disc_loss = 0.10885501045479694
Trained batch 132 in epoch 1, gen_loss = 0.8652383555146984, disc_loss = 0.10856045700637694
Trained batch 133 in epoch 1, gen_loss = 0.8674435757879001, disc_loss = 0.10825968908368429
Trained batch 134 in epoch 1, gen_loss = 0.8694467606367888, disc_loss = 0.10768872159360736
Trained batch 135 in epoch 1, gen_loss = 0.8686044049613616, disc_loss = 0.10744892566820935
Trained batch 136 in epoch 1, gen_loss = 0.8688509899334316, disc_loss = 0.10693604789375172
Trained batch 137 in epoch 1, gen_loss = 0.8691569929537566, disc_loss = 0.10646945796232077
Trained batch 138 in epoch 1, gen_loss = 0.8706585426124738, disc_loss = 0.1058442041800498
Trained batch 139 in epoch 1, gen_loss = 0.8694535498108182, disc_loss = 0.10584367787066315
Trained batch 140 in epoch 1, gen_loss = 0.870763306499373, disc_loss = 0.10584270813442925
Trained batch 141 in epoch 1, gen_loss = 0.8692203516691503, disc_loss = 0.10573160498153786
Trained batch 142 in epoch 1, gen_loss = 0.8706611278173807, disc_loss = 0.10589941509615083
Trained batch 143 in epoch 1, gen_loss = 0.8709772518939443, disc_loss = 0.10531109917469116
Trained batch 144 in epoch 1, gen_loss = 0.8697569033195233, disc_loss = 0.10527044153804409
Trained batch 145 in epoch 1, gen_loss = 0.8701372273164253, disc_loss = 0.10476323902887637
Trained batch 146 in epoch 1, gen_loss = 0.8717960885592869, disc_loss = 0.10478625661332389
Trained batch 147 in epoch 1, gen_loss = 0.8727462529330641, disc_loss = 0.10416659736703779
Trained batch 148 in epoch 1, gen_loss = 0.871762683327566, disc_loss = 0.1039250238404778
Trained batch 149 in epoch 1, gen_loss = 0.8714119422435761, disc_loss = 0.10342278081923723
Trained batch 150 in epoch 1, gen_loss = 0.8739068141046739, disc_loss = 0.10341836792102319
Trained batch 151 in epoch 1, gen_loss = 0.8745393396208161, disc_loss = 0.10282939581788685
Trained batch 152 in epoch 1, gen_loss = 0.8737824422861237, disc_loss = 0.10258679138192164
Trained batch 153 in epoch 1, gen_loss = 0.8731437093251712, disc_loss = 0.10220149398914405
Trained batch 154 in epoch 1, gen_loss = 0.8743705118856122, disc_loss = 0.10187394816067911
Trained batch 155 in epoch 1, gen_loss = 0.8741841484338809, disc_loss = 0.10151815736809602
Trained batch 156 in epoch 1, gen_loss = 0.876267676140852, disc_loss = 0.10116795571461605
Trained batch 157 in epoch 1, gen_loss = 0.876923072564451, disc_loss = 0.10060400790475969
Trained batch 158 in epoch 1, gen_loss = 0.8756009272809299, disc_loss = 0.10061482833288375
Trained batch 159 in epoch 1, gen_loss = 0.8759307030588388, disc_loss = 0.10023477716604248
Trained batch 160 in epoch 1, gen_loss = 0.8766352204802614, disc_loss = 0.10008798364943229
Trained batch 161 in epoch 1, gen_loss = 0.8769473521797745, disc_loss = 0.09954188298434019
Trained batch 162 in epoch 1, gen_loss = 0.8772362624209351, disc_loss = 0.09909248353193509
Trained batch 163 in epoch 1, gen_loss = 0.8759364500278379, disc_loss = 0.0996600077941832
Trained batch 164 in epoch 1, gen_loss = 0.877746109528975, disc_loss = 0.10002359116845058
Trained batch 165 in epoch 1, gen_loss = 0.8770114014665764, disc_loss = 0.09996598807488938
Trained batch 166 in epoch 1, gen_loss = 0.8776566457605648, disc_loss = 0.09992190844150717
Trained batch 167 in epoch 1, gen_loss = 0.8785163557955197, disc_loss = 0.09939739885850854
Trained batch 168 in epoch 1, gen_loss = 0.8786092714445125, disc_loss = 0.09900046209942483
Trained batch 169 in epoch 1, gen_loss = 0.8774716492961435, disc_loss = 0.09889099246767515
Trained batch 170 in epoch 1, gen_loss = 0.8787894133935895, disc_loss = 0.0992917311241665
Trained batch 171 in epoch 1, gen_loss = 0.877411751206531, disc_loss = 0.099521609580924
Trained batch 172 in epoch 1, gen_loss = 0.8772346236113179, disc_loss = 0.09933152032014779
Trained batch 173 in epoch 1, gen_loss = 0.8781458858785958, disc_loss = 0.09940055633049416
Trained batch 174 in epoch 1, gen_loss = 0.8790154586519514, disc_loss = 0.09896751737488167
Trained batch 175 in epoch 1, gen_loss = 0.8777674500915137, disc_loss = 0.09927366353804246
Trained batch 176 in epoch 1, gen_loss = 0.8776719863131895, disc_loss = 0.09894649046183811
Trained batch 177 in epoch 1, gen_loss = 0.8790411477008563, disc_loss = 0.09924125748299313
Trained batch 178 in epoch 1, gen_loss = 0.8782471248557447, disc_loss = 0.09904441338906575
Trained batch 179 in epoch 1, gen_loss = 0.8781123283836577, disc_loss = 0.09861255370390912
Trained batch 180 in epoch 1, gen_loss = 0.8781568444236207, disc_loss = 0.09866796165848798
Trained batch 181 in epoch 1, gen_loss = 0.8768093382919228, disc_loss = 0.0990133972807818
Trained batch 182 in epoch 1, gen_loss = 0.8774638765496634, disc_loss = 0.09921707607337522
Trained batch 183 in epoch 1, gen_loss = 0.8756232443063156, disc_loss = 0.10059117407882182
Trained batch 184 in epoch 1, gen_loss = 0.8765325423833487, disc_loss = 0.10131203817656717
Trained batch 185 in epoch 1, gen_loss = 0.8757397583735886, disc_loss = 0.10156323924480427
Trained batch 186 in epoch 1, gen_loss = 0.8741201879506443, disc_loss = 0.10281940286152344
Trained batch 187 in epoch 1, gen_loss = 0.8750004016972602, disc_loss = 0.1054893214840125
Trained batch 188 in epoch 1, gen_loss = 0.8757122991577028, disc_loss = 0.10664059871699287
Trained batch 189 in epoch 1, gen_loss = 0.8756606942728946, disc_loss = 0.10688457233635218
Trained batch 190 in epoch 1, gen_loss = 0.87575893814027, disc_loss = 0.10696893141980415
Trained batch 191 in epoch 1, gen_loss = 0.874652013493081, disc_loss = 0.10694524067124196
Trained batch 192 in epoch 1, gen_loss = 0.8744864272330092, disc_loss = 0.1071438118767167
Trained batch 193 in epoch 1, gen_loss = 0.8742654593949465, disc_loss = 0.1070122985294108
Trained batch 194 in epoch 1, gen_loss = 0.873687647550534, disc_loss = 0.1069261903134294
Trained batch 195 in epoch 1, gen_loss = 0.8736026366146243, disc_loss = 0.10684730131084061
Trained batch 196 in epoch 1, gen_loss = 0.8733861567405274, disc_loss = 0.10692598953899847
Trained batch 197 in epoch 1, gen_loss = 0.8730005408176268, disc_loss = 0.10676870268835413
Trained batch 198 in epoch 1, gen_loss = 0.872216430441219, disc_loss = 0.10662136286328636
Trained batch 199 in epoch 1, gen_loss = 0.8733883753418923, disc_loss = 0.10666572026442736
Trained batch 200 in epoch 1, gen_loss = 0.8729552439789274, disc_loss = 0.10635017239910305
Trained batch 201 in epoch 1, gen_loss = 0.8714920418097241, disc_loss = 0.10671645133193619
Trained batch 202 in epoch 1, gen_loss = 0.872729421836402, disc_loss = 0.10770922205112692
Trained batch 203 in epoch 1, gen_loss = 0.8719787448644638, disc_loss = 0.10763285527754501
Trained batch 204 in epoch 1, gen_loss = 0.8711242649613358, disc_loss = 0.10761197328840087
Trained batch 205 in epoch 1, gen_loss = 0.8709045764312003, disc_loss = 0.1076627441284075
Trained batch 206 in epoch 1, gen_loss = 0.8701140111771183, disc_loss = 0.10755178249094653
Trained batch 207 in epoch 1, gen_loss = 0.8691525711463048, disc_loss = 0.10746543742984963
Trained batch 208 in epoch 1, gen_loss = 0.8693585760855789, disc_loss = 0.10731794053697558
Trained batch 209 in epoch 1, gen_loss = 0.8694617736907232, disc_loss = 0.10697685206486356
Trained batch 210 in epoch 1, gen_loss = 0.8703238805888388, disc_loss = 0.10653992987268768
Trained batch 211 in epoch 1, gen_loss = 0.871065320833674, disc_loss = 0.10611222917653339
Trained batch 212 in epoch 1, gen_loss = 0.8719185310910006, disc_loss = 0.10566965536489872
Trained batch 213 in epoch 1, gen_loss = 0.8717493364744098, disc_loss = 0.10552990673736573
Trained batch 214 in epoch 1, gen_loss = 0.8703569439954536, disc_loss = 0.10610260326242031
Trained batch 215 in epoch 1, gen_loss = 0.8708719186208866, disc_loss = 0.10585724826712438
Trained batch 216 in epoch 1, gen_loss = 0.8710673201468683, disc_loss = 0.10569742749861445
Trained batch 217 in epoch 1, gen_loss = 0.8703437305371696, disc_loss = 0.10566708153763085
Trained batch 218 in epoch 1, gen_loss = 0.8701708314081306, disc_loss = 0.1053994517628801
Trained batch 219 in epoch 1, gen_loss = 0.8705983015623959, disc_loss = 0.10578847627832809
Trained batch 220 in epoch 1, gen_loss = 0.8702629820793463, disc_loss = 0.10558520530969984
Trained batch 221 in epoch 1, gen_loss = 0.8693861615013432, disc_loss = 0.10552295415267886
Trained batch 222 in epoch 1, gen_loss = 0.8706505135570406, disc_loss = 0.10540097878803185
Trained batch 223 in epoch 1, gen_loss = 0.8711443527468613, disc_loss = 0.10526178198883177
Trained batch 224 in epoch 1, gen_loss = 0.8698308992385865, disc_loss = 0.10573097971164518
Trained batch 225 in epoch 1, gen_loss = 0.8692977362501938, disc_loss = 0.10561650761081713
Trained batch 226 in epoch 1, gen_loss = 0.8700943247862324, disc_loss = 0.10586965484913882
Trained batch 227 in epoch 1, gen_loss = 0.8694910184856046, disc_loss = 0.10574099546085977
Trained batch 228 in epoch 1, gen_loss = 0.8692290379490915, disc_loss = 0.10549813203562425
Trained batch 229 in epoch 1, gen_loss = 0.8685916535232379, disc_loss = 0.10532265526202061
Trained batch 230 in epoch 1, gen_loss = 0.8695355341548011, disc_loss = 0.10554588615523401
Trained batch 231 in epoch 1, gen_loss = 0.8685307515592411, disc_loss = 0.10560053603418557
Trained batch 232 in epoch 1, gen_loss = 0.8685403824364167, disc_loss = 0.10542255733162165
Trained batch 233 in epoch 1, gen_loss = 0.8688143672596695, disc_loss = 0.10509014879870746
Trained batch 234 in epoch 1, gen_loss = 0.8678898080866387, disc_loss = 0.10508563552210305
Trained batch 235 in epoch 1, gen_loss = 0.8679946792327752, disc_loss = 0.10503079295868717
Trained batch 236 in epoch 1, gen_loss = 0.868803930684987, disc_loss = 0.10498869009237374
Trained batch 237 in epoch 1, gen_loss = 0.8675225489780682, disc_loss = 0.10545941171854609
Trained batch 238 in epoch 1, gen_loss = 0.8672437276301523, disc_loss = 0.10526402817189569
Trained batch 239 in epoch 1, gen_loss = 0.867961927006642, disc_loss = 0.10539888639080648
Trained batch 240 in epoch 1, gen_loss = 0.8669150766000708, disc_loss = 0.10545247844594272
Trained batch 241 in epoch 1, gen_loss = 0.8663552142371816, disc_loss = 0.10533294117478423
Trained batch 242 in epoch 1, gen_loss = 0.8662867246831886, disc_loss = 0.10513092686686619
Trained batch 243 in epoch 1, gen_loss = 0.8660197905341133, disc_loss = 0.10504076164597492
Trained batch 244 in epoch 1, gen_loss = 0.8655483574283366, disc_loss = 0.10485921602848233
Trained batch 245 in epoch 1, gen_loss = 0.8662054948205871, disc_loss = 0.10488213538532941
Trained batch 246 in epoch 1, gen_loss = 0.8661602318045581, disc_loss = 0.10465972306893061
Trained batch 247 in epoch 1, gen_loss = 0.8653092857810759, disc_loss = 0.10466034176023377
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 1.050044298171997, disc_loss = 0.10702667385339737
Trained batch 1 in epoch 2, gen_loss = 0.9200755953788757, disc_loss = 0.073837760835886
Trained batch 2 in epoch 2, gen_loss = 0.8888031641642252, disc_loss = 0.07760899513959885
Trained batch 3 in epoch 2, gen_loss = 0.8881350308656693, disc_loss = 0.06811864301562309
Trained batch 4 in epoch 2, gen_loss = 0.9017294526100159, disc_loss = 0.06518256664276123
Trained batch 5 in epoch 2, gen_loss = 0.9075010418891907, disc_loss = 0.05779785507669052
Trained batch 6 in epoch 2, gen_loss = 0.880750264440264, disc_loss = 0.06024499104491302
Trained batch 7 in epoch 2, gen_loss = 0.9115742594003677, disc_loss = 0.0692754767369479
Trained batch 8 in epoch 2, gen_loss = 0.881553139951494, disc_loss = 0.07103292623327838
Trained batch 9 in epoch 2, gen_loss = 0.8733241260051727, disc_loss = 0.0695258429273963
Trained batch 10 in epoch 2, gen_loss = 0.8762857426296581, disc_loss = 0.06601061519574035
Trained batch 11 in epoch 2, gen_loss = 0.8979927947123846, disc_loss = 0.062161536111185946
Trained batch 12 in epoch 2, gen_loss = 0.9024888689701374, disc_loss = 0.05826737301853987
Trained batch 13 in epoch 2, gen_loss = 0.898224264383316, disc_loss = 0.05651206549789224
Trained batch 14 in epoch 2, gen_loss = 0.9044159809748332, disc_loss = 0.05346957743167877
Trained batch 15 in epoch 2, gen_loss = 0.9023332335054874, disc_loss = 0.05189930507913232
Trained batch 16 in epoch 2, gen_loss = 0.9005981368177077, disc_loss = 0.05021529885775903
Trained batch 17 in epoch 2, gen_loss = 0.9171693556838565, disc_loss = 0.048923909146752625
Trained batch 18 in epoch 2, gen_loss = 0.9220115605153536, disc_loss = 0.04707401064469626
Trained batch 19 in epoch 2, gen_loss = 0.9159919947385788, disc_loss = 0.04836020967923105
Trained batch 20 in epoch 2, gen_loss = 0.9236108320099967, disc_loss = 0.049154212565294335
Trained batch 21 in epoch 2, gen_loss = 0.9198480383916334, disc_loss = 0.04817935845560648
Trained batch 22 in epoch 2, gen_loss = 0.9145820399989253, disc_loss = 0.04790328803431729
Trained batch 23 in epoch 2, gen_loss = 0.9213154266277949, disc_loss = 0.04659454233478755
Trained batch 24 in epoch 2, gen_loss = 0.9299467039108277, disc_loss = 0.04578110944479704
Trained batch 25 in epoch 2, gen_loss = 0.9335267727191632, disc_loss = 0.04444684016589935
Trained batch 26 in epoch 2, gen_loss = 0.9312173061900668, disc_loss = 0.04347905130298049
Trained batch 27 in epoch 2, gen_loss = 0.9320872255734035, disc_loss = 0.04292679119056889
Trained batch 28 in epoch 2, gen_loss = 0.9269328220137234, disc_loss = 0.042532523066319265
Trained batch 29 in epoch 2, gen_loss = 0.928457498550415, disc_loss = 0.04158861407389244
Trained batch 30 in epoch 2, gen_loss = 0.9331440656415878, disc_loss = 0.04142665808960315
Trained batch 31 in epoch 2, gen_loss = 0.9230002351105213, disc_loss = 0.0460374666727148
Trained batch 32 in epoch 2, gen_loss = 0.9278944297270342, disc_loss = 0.0504338587210937
Trained batch 33 in epoch 2, gen_loss = 0.9219932310721454, disc_loss = 0.05088339587125708
Trained batch 34 in epoch 2, gen_loss = 0.9197461979729789, disc_loss = 0.050521102494427136
Trained batch 35 in epoch 2, gen_loss = 0.9218156337738037, disc_loss = 0.04955271786699692
Trained batch 36 in epoch 2, gen_loss = 0.9188831706304808, disc_loss = 0.04941927430194777
Trained batch 37 in epoch 2, gen_loss = 0.9182659466015665, disc_loss = 0.04941913456116852
Trained batch 38 in epoch 2, gen_loss = 0.9217669734588037, disc_loss = 0.04857003755676441
Trained batch 39 in epoch 2, gen_loss = 0.921562984585762, disc_loss = 0.04782375618815422
Trained batch 40 in epoch 2, gen_loss = 0.9186281183870827, disc_loss = 0.047362886187506885
Trained batch 41 in epoch 2, gen_loss = 0.924291805142448, disc_loss = 0.047514368913003376
Trained batch 42 in epoch 2, gen_loss = 0.9244806419971378, disc_loss = 0.04680052980087524
Trained batch 43 in epoch 2, gen_loss = 0.9233747111125425, disc_loss = 0.04624980247833512
Trained batch 44 in epoch 2, gen_loss = 0.9189982348018222, disc_loss = 0.046148697038491567
Trained batch 45 in epoch 2, gen_loss = 0.9256227288557135, disc_loss = 0.04967576184350511
Trained batch 46 in epoch 2, gen_loss = 0.9198153272588202, disc_loss = 0.052615310441940386
Trained batch 47 in epoch 2, gen_loss = 0.9159890239437422, disc_loss = 0.05382191902026534
Trained batch 48 in epoch 2, gen_loss = 0.9207637772268179, disc_loss = 0.05973968654870987
Trained batch 49 in epoch 2, gen_loss = 0.9168342936038971, disc_loss = 0.0603427742421627
Trained batch 50 in epoch 2, gen_loss = 0.9116865665304894, disc_loss = 0.06132746049586464
Trained batch 51 in epoch 2, gen_loss = 0.9083205954386637, disc_loss = 0.0631315981825957
Trained batch 52 in epoch 2, gen_loss = 0.9069773397355709, disc_loss = 0.06380112792523403
Trained batch 53 in epoch 2, gen_loss = 0.9012149064629166, disc_loss = 0.06590999235157613
Trained batch 54 in epoch 2, gen_loss = 0.9022479013963179, disc_loss = 0.06647104918956756
Trained batch 55 in epoch 2, gen_loss = 0.9008442355053765, disc_loss = 0.06597740455929722
Trained batch 56 in epoch 2, gen_loss = 0.8976727504479257, disc_loss = 0.0657769148809868
Trained batch 57 in epoch 2, gen_loss = 0.8965810897021458, disc_loss = 0.06601999186236283
Trained batch 58 in epoch 2, gen_loss = 0.8946068145461001, disc_loss = 0.065707481008465
Trained batch 59 in epoch 2, gen_loss = 0.8929570645093918, disc_loss = 0.06513800000150999
Trained batch 60 in epoch 2, gen_loss = 0.8940783094187252, disc_loss = 0.06609995589881647
Trained batch 61 in epoch 2, gen_loss = 0.888930655294849, disc_loss = 0.06728795098681603
Trained batch 62 in epoch 2, gen_loss = 0.8903969242459252, disc_loss = 0.06668225161376454
Trained batch 63 in epoch 2, gen_loss = 0.8924129530787468, disc_loss = 0.0666887461557053
Trained batch 64 in epoch 2, gen_loss = 0.8899095938755915, disc_loss = 0.0662917927480661
Trained batch 65 in epoch 2, gen_loss = 0.8893943203218055, disc_loss = 0.06577572576475865
Trained batch 66 in epoch 2, gen_loss = 0.8906418948031184, disc_loss = 0.06507393089470578
Trained batch 67 in epoch 2, gen_loss = 0.8913153734277276, disc_loss = 0.06503329064477892
Trained batch 68 in epoch 2, gen_loss = 0.8864688380904819, disc_loss = 0.06752320983703586
Trained batch 69 in epoch 2, gen_loss = 0.8874688233648028, disc_loss = 0.06697057738368001
Trained batch 70 in epoch 2, gen_loss = 0.8914234252043174, disc_loss = 0.06751857873734454
Trained batch 71 in epoch 2, gen_loss = 0.8898196725381745, disc_loss = 0.06756652733828458
Trained batch 72 in epoch 2, gen_loss = 0.8892544246699712, disc_loss = 0.06719697534731806
Trained batch 73 in epoch 2, gen_loss = 0.8895728926400881, disc_loss = 0.06669860078978378
Trained batch 74 in epoch 2, gen_loss = 0.8909138854344686, disc_loss = 0.06609403682251772
Trained batch 75 in epoch 2, gen_loss = 0.8892833574822074, disc_loss = 0.06593742096600563
Trained batch 76 in epoch 2, gen_loss = 0.8921896312143895, disc_loss = 0.06581534525113446
Trained batch 77 in epoch 2, gen_loss = 0.8910801112651825, disc_loss = 0.06530089850704639
Trained batch 78 in epoch 2, gen_loss = 0.8900229002856002, disc_loss = 0.06506763155796105
Trained batch 79 in epoch 2, gen_loss = 0.8915783859789371, disc_loss = 0.0646583060035482
Trained batch 80 in epoch 2, gen_loss = 0.8916850053233865, disc_loss = 0.06432614776731273
Trained batch 81 in epoch 2, gen_loss = 0.8887368753188993, disc_loss = 0.06453276814029711
Trained batch 82 in epoch 2, gen_loss = 0.8912924966180181, disc_loss = 0.06424988615494895
Trained batch 83 in epoch 2, gen_loss = 0.8925607438598361, disc_loss = 0.06364127269591249
Trained batch 84 in epoch 2, gen_loss = 0.8909545218243319, disc_loss = 0.06334535548573031
Trained batch 85 in epoch 2, gen_loss = 0.8912777720495711, disc_loss = 0.06310423951985877
Trained batch 86 in epoch 2, gen_loss = 0.8894290033428148, disc_loss = 0.06299278502962713
Trained batch 87 in epoch 2, gen_loss = 0.8913489431142807, disc_loss = 0.06282057019416243
Trained batch 88 in epoch 2, gen_loss = 0.890901493222526, disc_loss = 0.06247172796617398
Trained batch 89 in epoch 2, gen_loss = 0.8907638397481706, disc_loss = 0.06221285477901498
Trained batch 90 in epoch 2, gen_loss = 0.8914659527631906, disc_loss = 0.06183702411682724
Trained batch 91 in epoch 2, gen_loss = 0.8948434895795324, disc_loss = 0.06199628312100211
Trained batch 92 in epoch 2, gen_loss = 0.8929309223287849, disc_loss = 0.06219294005303934
Trained batch 93 in epoch 2, gen_loss = 0.892852985478462, disc_loss = 0.061748190436195186
Trained batch 94 in epoch 2, gen_loss = 0.8949128859921506, disc_loss = 0.06149144744206416
Trained batch 95 in epoch 2, gen_loss = 0.8961331055810055, disc_loss = 0.06104054840398021
Trained batch 96 in epoch 2, gen_loss = 0.8958712478273922, disc_loss = 0.06074059319672818
Trained batch 97 in epoch 2, gen_loss = 0.8970878629051909, disc_loss = 0.06033678579961463
Trained batch 98 in epoch 2, gen_loss = 0.8983542672311416, disc_loss = 0.05992261699466693
Trained batch 99 in epoch 2, gen_loss = 0.8988934111595154, disc_loss = 0.05945567887276411
Trained batch 100 in epoch 2, gen_loss = 0.8999743662258186, disc_loss = 0.059004943744085804
Trained batch 101 in epoch 2, gen_loss = 0.9018564831976797, disc_loss = 0.05856199508678971
Trained batch 102 in epoch 2, gen_loss = 0.9024690077142808, disc_loss = 0.058071248549787166
Trained batch 103 in epoch 2, gen_loss = 0.9029093682765961, disc_loss = 0.05758999314947197
Trained batch 104 in epoch 2, gen_loss = 0.9032365435645694, disc_loss = 0.057166007311926004
Trained batch 105 in epoch 2, gen_loss = 0.9034044928145859, disc_loss = 0.05677535717885168
Trained batch 106 in epoch 2, gen_loss = 0.9037954027407638, disc_loss = 0.05653740593589077
Trained batch 107 in epoch 2, gen_loss = 0.904116521830912, disc_loss = 0.056128227384760976
Trained batch 108 in epoch 2, gen_loss = 0.9068718213553822, disc_loss = 0.05583209707615299
Trained batch 109 in epoch 2, gen_loss = 0.909514491666447, disc_loss = 0.055498637064275415
Trained batch 110 in epoch 2, gen_loss = 0.9102054533657727, disc_loss = 0.055108361508328096
Trained batch 111 in epoch 2, gen_loss = 0.9100807671036039, disc_loss = 0.05479165771144575
Trained batch 112 in epoch 2, gen_loss = 0.910043272824414, disc_loss = 0.054454992937369155
Trained batch 113 in epoch 2, gen_loss = 0.9094427379599789, disc_loss = 0.054314793504186366
Trained batch 114 in epoch 2, gen_loss = 0.9101346637891686, disc_loss = 0.05408017687985431
Trained batch 115 in epoch 2, gen_loss = 0.9091214460545572, disc_loss = 0.054024339340434505
Trained batch 116 in epoch 2, gen_loss = 0.9101293295876592, disc_loss = 0.0540374028775045
Trained batch 117 in epoch 2, gen_loss = 0.9079143147347337, disc_loss = 0.054208591682994266
Trained batch 118 in epoch 2, gen_loss = 0.9087637106911475, disc_loss = 0.054144669551120586
Trained batch 119 in epoch 2, gen_loss = 0.9079731345176697, disc_loss = 0.0539661237426723
Trained batch 120 in epoch 2, gen_loss = 0.9076789085530053, disc_loss = 0.05382997992887231
Trained batch 121 in epoch 2, gen_loss = 0.9067692356031449, disc_loss = 0.05373429868095478
Trained batch 122 in epoch 2, gen_loss = 0.9075206586015903, disc_loss = 0.05341623945358565
Trained batch 123 in epoch 2, gen_loss = 0.9074556164203151, disc_loss = 0.05313065672864116
Trained batch 124 in epoch 2, gen_loss = 0.9090662460327148, disc_loss = 0.05282776875048876
Trained batch 125 in epoch 2, gen_loss = 0.9086084578718457, disc_loss = 0.05254226149104181
Trained batch 126 in epoch 2, gen_loss = 0.9089145552454971, disc_loss = 0.052346519751870255
Trained batch 127 in epoch 2, gen_loss = 0.9099684222601354, disc_loss = 0.05206446292140754
Trained batch 128 in epoch 2, gen_loss = 0.9091481390849564, disc_loss = 0.05203082719312389
Trained batch 129 in epoch 2, gen_loss = 0.9115514851533449, disc_loss = 0.05262822715852123
Trained batch 130 in epoch 2, gen_loss = 0.9088470731072753, disc_loss = 0.05405873925432222
Trained batch 131 in epoch 2, gen_loss = 0.9097274790207545, disc_loss = 0.053808768089352685
Trained batch 132 in epoch 2, gen_loss = 0.9102472465737421, disc_loss = 0.053754123901122046
Trained batch 133 in epoch 2, gen_loss = 0.908852083024694, disc_loss = 0.05409362570924768
Trained batch 134 in epoch 2, gen_loss = 0.9077618921244586, disc_loss = 0.05405345706062185
Trained batch 135 in epoch 2, gen_loss = 0.9088414806653472, disc_loss = 0.05432650789974586
Trained batch 136 in epoch 2, gen_loss = 0.906732832863383, disc_loss = 0.05479558098408645
Trained batch 137 in epoch 2, gen_loss = 0.9059959922147833, disc_loss = 0.054763059395000986
Trained batch 138 in epoch 2, gen_loss = 0.9065694007084524, disc_loss = 0.05546307953061174
Trained batch 139 in epoch 2, gen_loss = 0.9039679348468781, disc_loss = 0.05609967062648918
Trained batch 140 in epoch 2, gen_loss = 0.9034778581443408, disc_loss = 0.05612118397542137
Trained batch 141 in epoch 2, gen_loss = 0.9043892722734264, disc_loss = 0.05654206633908858
Trained batch 142 in epoch 2, gen_loss = 0.9018754187997404, disc_loss = 0.05755860304420853
Trained batch 143 in epoch 2, gen_loss = 0.9014396232863268, disc_loss = 0.05754023433999262
Trained batch 144 in epoch 2, gen_loss = 0.9010828811546852, disc_loss = 0.05778432756276994
Trained batch 145 in epoch 2, gen_loss = 0.9006985009533085, disc_loss = 0.05857530481832689
Trained batch 146 in epoch 2, gen_loss = 0.9001063769366465, disc_loss = 0.05888277825069468
Trained batch 147 in epoch 2, gen_loss = 0.8985860359829825, disc_loss = 0.05932537597805463
Trained batch 148 in epoch 2, gen_loss = 0.8985657951975828, disc_loss = 0.05918770621611968
Trained batch 149 in epoch 2, gen_loss = 0.8985046207904815, disc_loss = 0.059002710438023014
Trained batch 150 in epoch 2, gen_loss = 0.8990543405741256, disc_loss = 0.05875559817900918
Trained batch 151 in epoch 2, gen_loss = 0.8975768473587538, disc_loss = 0.059044731934064704
Trained batch 152 in epoch 2, gen_loss = 0.8986999598983066, disc_loss = 0.05939622808345198
Trained batch 153 in epoch 2, gen_loss = 0.8971067810213411, disc_loss = 0.059629906071712833
Trained batch 154 in epoch 2, gen_loss = 0.8971075661720768, disc_loss = 0.059556230139588155
Trained batch 155 in epoch 2, gen_loss = 0.8983118109978162, disc_loss = 0.05937375845268178
Trained batch 156 in epoch 2, gen_loss = 0.8978351191350609, disc_loss = 0.059202855518147066
Trained batch 157 in epoch 2, gen_loss = 0.8968704497512383, disc_loss = 0.05915585967205182
Trained batch 158 in epoch 2, gen_loss = 0.8977967444455849, disc_loss = 0.05960569690631808
Trained batch 159 in epoch 2, gen_loss = 0.8957813754677773, disc_loss = 0.06064627566956915
Trained batch 160 in epoch 2, gen_loss = 0.8962129532180217, disc_loss = 0.06072559703419112
Trained batch 161 in epoch 2, gen_loss = 0.8957286918604815, disc_loss = 0.06076650575010313
Trained batch 162 in epoch 2, gen_loss = 0.8956270210582055, disc_loss = 0.060670316659279765
Trained batch 163 in epoch 2, gen_loss = 0.8943654193383891, disc_loss = 0.06086599634301553
Trained batch 164 in epoch 2, gen_loss = 0.8943932706659491, disc_loss = 0.06091318648082741
Trained batch 165 in epoch 2, gen_loss = 0.893631703164204, disc_loss = 0.06080229655020388
Trained batch 166 in epoch 2, gen_loss = 0.8936068126541412, disc_loss = 0.06086634280728901
Trained batch 167 in epoch 2, gen_loss = 0.8922942404945692, disc_loss = 0.061033849720843136
Trained batch 168 in epoch 2, gen_loss = 0.8923208138646459, disc_loss = 0.060848341742254924
Trained batch 169 in epoch 2, gen_loss = 0.8919058130067937, disc_loss = 0.06078305810361224
Trained batch 170 in epoch 2, gen_loss = 0.8920039489255314, disc_loss = 0.06056766731021871
Trained batch 171 in epoch 2, gen_loss = 0.8924596867589063, disc_loss = 0.060303490321953285
Trained batch 172 in epoch 2, gen_loss = 0.8920725553021954, disc_loss = 0.06010387880415413
Trained batch 173 in epoch 2, gen_loss = 0.8919302584796116, disc_loss = 0.060649560181017234
Trained batch 174 in epoch 2, gen_loss = 0.8913021959577287, disc_loss = 0.06050804182354893
Trained batch 175 in epoch 2, gen_loss = 0.8904721093448725, disc_loss = 0.060503309841310096
Trained batch 176 in epoch 2, gen_loss = 0.8906425315108003, disc_loss = 0.060835508971690794
Trained batch 177 in epoch 2, gen_loss = 0.8898721588461587, disc_loss = 0.06091970259198145
Trained batch 178 in epoch 2, gen_loss = 0.8907776648105856, disc_loss = 0.06131201461685936
Trained batch 179 in epoch 2, gen_loss = 0.889373767707083, disc_loss = 0.06165839859491421
Trained batch 180 in epoch 2, gen_loss = 0.8885838685773354, disc_loss = 0.061576615643394256
Trained batch 181 in epoch 2, gen_loss = 0.8890716305800846, disc_loss = 0.06149435104229129
Trained batch 182 in epoch 2, gen_loss = 0.8885310253158945, disc_loss = 0.061450639215445586
Trained batch 183 in epoch 2, gen_loss = 0.8887891361246938, disc_loss = 0.061221558393141175
Trained batch 184 in epoch 2, gen_loss = 0.8880776063815967, disc_loss = 0.061135915621511036
Trained batch 185 in epoch 2, gen_loss = 0.8888824787191165, disc_loss = 0.06101066145985838
Trained batch 186 in epoch 2, gen_loss = 0.8875571365024955, disc_loss = 0.06109693697728416
Trained batch 187 in epoch 2, gen_loss = 0.8881890504284108, disc_loss = 0.06090113806459022
Trained batch 188 in epoch 2, gen_loss = 0.887901521549023, disc_loss = 0.060737760831163355
Trained batch 189 in epoch 2, gen_loss = 0.8882710027067284, disc_loss = 0.06069369761665401
Trained batch 190 in epoch 2, gen_loss = 0.8870541668687192, disc_loss = 0.06084011489749735
Trained batch 191 in epoch 2, gen_loss = 0.8877780878295501, disc_loss = 0.06077547940367367
Trained batch 192 in epoch 2, gen_loss = 0.8872627273124735, disc_loss = 0.060571132271207986
Trained batch 193 in epoch 2, gen_loss = 0.8866375260746356, disc_loss = 0.06040860404807728
Trained batch 194 in epoch 2, gen_loss = 0.8880067880337055, disc_loss = 0.06044047218389236
Trained batch 195 in epoch 2, gen_loss = 0.8875539053459557, disc_loss = 0.060253208612414955
Trained batch 196 in epoch 2, gen_loss = 0.8871556577948749, disc_loss = 0.06012334558772405
Trained batch 197 in epoch 2, gen_loss = 0.8876953489250607, disc_loss = 0.05988519563048025
Trained batch 198 in epoch 2, gen_loss = 0.8876938256786098, disc_loss = 0.059781387612111304
Trained batch 199 in epoch 2, gen_loss = 0.887566242814064, disc_loss = 0.059572133827023206
Trained batch 200 in epoch 2, gen_loss = 0.8874491138837823, disc_loss = 0.05938290396417996
Trained batch 201 in epoch 2, gen_loss = 0.8872478380061612, disc_loss = 0.05917654706091426
Trained batch 202 in epoch 2, gen_loss = 0.8877174672234822, disc_loss = 0.05902542282593221
Trained batch 203 in epoch 2, gen_loss = 0.8884068195726357, disc_loss = 0.05883173994701721
Trained batch 204 in epoch 2, gen_loss = 0.8876252360460235, disc_loss = 0.058741464079698415
Trained batch 205 in epoch 2, gen_loss = 0.887949792505468, disc_loss = 0.05853427306848388
Trained batch 206 in epoch 2, gen_loss = 0.8883911581431034, disc_loss = 0.05830340198542617
Trained batch 207 in epoch 2, gen_loss = 0.8889843079333122, disc_loss = 0.05817144062781993
Trained batch 208 in epoch 2, gen_loss = 0.887986742423482, disc_loss = 0.05826919653751491
Trained batch 209 in epoch 2, gen_loss = 0.8882932075432368, disc_loss = 0.058084397802927665
Trained batch 210 in epoch 2, gen_loss = 0.8894035892463973, disc_loss = 0.05801857768235755
Trained batch 211 in epoch 2, gen_loss = 0.8888422045505272, disc_loss = 0.05796465299197666
Trained batch 212 in epoch 2, gen_loss = 0.8891202482818997, disc_loss = 0.057762069566428945
Trained batch 213 in epoch 2, gen_loss = 0.8889489460771329, disc_loss = 0.05758494612212493
Trained batch 214 in epoch 2, gen_loss = 0.8894491586574288, disc_loss = 0.05761570254730624
Trained batch 215 in epoch 2, gen_loss = 0.888696040544245, disc_loss = 0.057652021309843766
Trained batch 216 in epoch 2, gen_loss = 0.888464914763578, disc_loss = 0.057508301590719534
Trained batch 217 in epoch 2, gen_loss = 0.8889640531408678, disc_loss = 0.057343803448688
Trained batch 218 in epoch 2, gen_loss = 0.8893367098346693, disc_loss = 0.05714490862997019
Trained batch 219 in epoch 2, gen_loss = 0.8890366556969556, disc_loss = 0.05699333949437873
Trained batch 220 in epoch 2, gen_loss = 0.8888711163361148, disc_loss = 0.0568868845355659
Trained batch 221 in epoch 2, gen_loss = 0.8887837314390922, disc_loss = 0.0566900106071419
Trained batch 222 in epoch 2, gen_loss = 0.889527689715672, disc_loss = 0.05656246419561684
Trained batch 223 in epoch 2, gen_loss = 0.8889458272606134, disc_loss = 0.05646803422548276
Trained batch 224 in epoch 2, gen_loss = 0.8898979332711962, disc_loss = 0.05633790489286184
Trained batch 225 in epoch 2, gen_loss = 0.8898489013709853, disc_loss = 0.056146847838288653
Trained batch 226 in epoch 2, gen_loss = 0.8891915799762709, disc_loss = 0.05607342852550325
Trained batch 227 in epoch 2, gen_loss = 0.8900929268514901, disc_loss = 0.05613149494635301
Trained batch 228 in epoch 2, gen_loss = 0.8894626373286851, disc_loss = 0.056137463147040274
Trained batch 229 in epoch 2, gen_loss = 0.8898652633895044, disc_loss = 0.05595643462451256
Trained batch 230 in epoch 2, gen_loss = 0.8902617958717016, disc_loss = 0.05578924238568905
Trained batch 231 in epoch 2, gen_loss = 0.8896606898513334, disc_loss = 0.05568744738762877
Trained batch 232 in epoch 2, gen_loss = 0.8903547545870998, disc_loss = 0.055641554252048676
Trained batch 233 in epoch 2, gen_loss = 0.8895413213306003, disc_loss = 0.05570356107245271
Trained batch 234 in epoch 2, gen_loss = 0.8900875598826307, disc_loss = 0.055592240658687786
Trained batch 235 in epoch 2, gen_loss = 0.8909988110348329, disc_loss = 0.055443911035781945
Trained batch 236 in epoch 2, gen_loss = 0.8903607042026922, disc_loss = 0.05547083880878073
Trained batch 237 in epoch 2, gen_loss = 0.8909484410987181, disc_loss = 0.05545569912084386
Trained batch 238 in epoch 2, gen_loss = 0.8899716794740206, disc_loss = 0.05553452317918569
Trained batch 239 in epoch 2, gen_loss = 0.8907414339482784, disc_loss = 0.05548952249422048
Trained batch 240 in epoch 2, gen_loss = 0.8902862846109383, disc_loss = 0.055408271079828875
Trained batch 241 in epoch 2, gen_loss = 0.8905278929501526, disc_loss = 0.05535402735079492
Trained batch 242 in epoch 2, gen_loss = 0.8907537045792787, disc_loss = 0.05517979690214857
Trained batch 243 in epoch 2, gen_loss = 0.8902661964053014, disc_loss = 0.05510296315702869
Trained batch 244 in epoch 2, gen_loss = 0.8900839041690437, disc_loss = 0.05502134254772444
Trained batch 245 in epoch 2, gen_loss = 0.8908523558601131, disc_loss = 0.05515617717102897
Trained batch 246 in epoch 2, gen_loss = 0.8898792983549326, disc_loss = 0.055499535857092754
Trained batch 247 in epoch 2, gen_loss = 0.8904416303961508, disc_loss = 0.05557912146867884
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.635088324546814, disc_loss = 0.08672242611646652
Trained batch 1 in epoch 3, gen_loss = 0.7817761898040771, disc_loss = 0.07998008653521538
Trained batch 2 in epoch 3, gen_loss = 0.7694410681724548, disc_loss = 0.06676111121972401
Trained batch 3 in epoch 3, gen_loss = 0.8278031498193741, disc_loss = 0.056432337034493685
Trained batch 4 in epoch 3, gen_loss = 0.7875906229019165, disc_loss = 0.0667830366641283
Trained batch 5 in epoch 3, gen_loss = 0.8584451874097189, disc_loss = 0.10319809274127086
Trained batch 6 in epoch 3, gen_loss = 0.8347325154713222, disc_loss = 0.09881831625742572
Trained batch 7 in epoch 3, gen_loss = 0.8138128519058228, disc_loss = 0.10185764660127461
Trained batch 8 in epoch 3, gen_loss = 0.8221072223451402, disc_loss = 0.1094364815702041
Trained batch 9 in epoch 3, gen_loss = 0.7995586276054383, disc_loss = 0.11605690363794566
Trained batch 10 in epoch 3, gen_loss = 0.7984488985755227, disc_loss = 0.12042336115105585
Trained batch 11 in epoch 3, gen_loss = 0.820820818344752, disc_loss = 0.1355594776881238
Trained batch 12 in epoch 3, gen_loss = 0.8236083984375, disc_loss = 0.14439219537262732
Trained batch 13 in epoch 3, gen_loss = 0.8244075179100037, disc_loss = 0.15407708140888385
Trained batch 14 in epoch 3, gen_loss = 0.8220399260520935, disc_loss = 0.15437345169484615
Trained batch 15 in epoch 3, gen_loss = 0.8115348182618618, disc_loss = 0.1512819497147575
Trained batch 16 in epoch 3, gen_loss = 0.8071892121258903, disc_loss = 0.1468470588545589
Trained batch 17 in epoch 3, gen_loss = 0.8103119234244028, disc_loss = 0.14223581024756035
Trained batch 18 in epoch 3, gen_loss = 0.8020801387335125, disc_loss = 0.13876385565258956
Trained batch 19 in epoch 3, gen_loss = 0.8078926593065262, disc_loss = 0.1344375972636044
Trained batch 20 in epoch 3, gen_loss = 0.8107033031327384, disc_loss = 0.13017451026964755
Trained batch 21 in epoch 3, gen_loss = 0.8058495060964064, disc_loss = 0.12786612126298927
Trained batch 22 in epoch 3, gen_loss = 0.8130707144737244, disc_loss = 0.12342694628497829
Trained batch 23 in epoch 3, gen_loss = 0.8102221464117368, disc_loss = 0.11991371292000015
Trained batch 24 in epoch 3, gen_loss = 0.817911159992218, disc_loss = 0.11846037641167641
Trained batch 25 in epoch 3, gen_loss = 0.8126744880126073, disc_loss = 0.11630985011848119
Trained batch 26 in epoch 3, gen_loss = 0.8112006651030647, disc_loss = 0.11393195721838209
Trained batch 27 in epoch 3, gen_loss = 0.8271934581654412, disc_loss = 0.11734998439039503
Trained batch 28 in epoch 3, gen_loss = 0.8216338137100483, disc_loss = 0.11516227945685387
Trained batch 29 in epoch 3, gen_loss = 0.8183035274346669, disc_loss = 0.11270781817535559
Trained batch 30 in epoch 3, gen_loss = 0.821507457763918, disc_loss = 0.11086633933647987
Trained batch 31 in epoch 3, gen_loss = 0.8192360810935497, disc_loss = 0.10871830373071134
Trained batch 32 in epoch 3, gen_loss = 0.8158270770853217, disc_loss = 0.1074991501641996
Trained batch 33 in epoch 3, gen_loss = 0.8225824938100927, disc_loss = 0.10736521201975205
Trained batch 34 in epoch 3, gen_loss = 0.8182015861783709, disc_loss = 0.10640613053526198
Trained batch 35 in epoch 3, gen_loss = 0.8184481213490168, disc_loss = 0.10438279435038567
Trained batch 36 in epoch 3, gen_loss = 0.8234855339333818, disc_loss = 0.104626752234794
Trained batch 37 in epoch 3, gen_loss = 0.8190981526123849, disc_loss = 0.10348727034502908
Trained batch 38 in epoch 3, gen_loss = 0.8174590804638007, disc_loss = 0.10151926404199539
Trained batch 39 in epoch 3, gen_loss = 0.8228580132126808, disc_loss = 0.09944972079247236
Trained batch 40 in epoch 3, gen_loss = 0.8257036790615175, disc_loss = 0.0988726530496667
Trained batch 41 in epoch 3, gen_loss = 0.8197128375371298, disc_loss = 0.10096814465664682
Trained batch 42 in epoch 3, gen_loss = 0.819769095542819, disc_loss = 0.10013834768256476
Trained batch 43 in epoch 3, gen_loss = 0.8227331787347794, disc_loss = 0.10007536529817364
Trained batch 44 in epoch 3, gen_loss = 0.8188746624522739, disc_loss = 0.09986752238538531
Trained batch 45 in epoch 3, gen_loss = 0.8197646102179652, disc_loss = 0.09860161181701266
Trained batch 46 in epoch 3, gen_loss = 0.8206542134284973, disc_loss = 0.09706018528247133
Trained batch 47 in epoch 3, gen_loss = 0.8194137004514536, disc_loss = 0.0954909671175604
Trained batch 48 in epoch 3, gen_loss = 0.8212163995723335, disc_loss = 0.09642154727207154
Trained batch 49 in epoch 3, gen_loss = 0.8204855275154114, disc_loss = 0.09574536178261042
Trained batch 50 in epoch 3, gen_loss = 0.8207210910086539, disc_loss = 0.09449803789018416
Trained batch 51 in epoch 3, gen_loss = 0.8244049480328193, disc_loss = 0.09378092295418565
Trained batch 52 in epoch 3, gen_loss = 0.8218375568119984, disc_loss = 0.09303726547590967
Trained batch 53 in epoch 3, gen_loss = 0.8241044437443769, disc_loss = 0.0921903221902472
Trained batch 54 in epoch 3, gen_loss = 0.8234679493037137, disc_loss = 0.0908988607539372
Trained batch 55 in epoch 3, gen_loss = 0.8255576863884926, disc_loss = 0.08944476038284067
Trained batch 56 in epoch 3, gen_loss = 0.8248100521271688, disc_loss = 0.08819326573754088
Trained batch 57 in epoch 3, gen_loss = 0.8277854744730324, disc_loss = 0.08685723769253698
Trained batch 58 in epoch 3, gen_loss = 0.827289039805784, disc_loss = 0.08632407337427139
Trained batch 59 in epoch 3, gen_loss = 0.8291118929783503, disc_loss = 0.08506025094538927
Trained batch 60 in epoch 3, gen_loss = 0.8291786098089374, disc_loss = 0.08402579485392961
Trained batch 61 in epoch 3, gen_loss = 0.8316617069705841, disc_loss = 0.0828609666336448
Trained batch 62 in epoch 3, gen_loss = 0.8350364991596767, disc_loss = 0.08177042978682689
Trained batch 63 in epoch 3, gen_loss = 0.8362133428454399, disc_loss = 0.08062254796095658
Trained batch 64 in epoch 3, gen_loss = 0.8345252816493695, disc_loss = 0.07994191751170616
Trained batch 65 in epoch 3, gen_loss = 0.8366668757164117, disc_loss = 0.07910066265895059
Trained batch 66 in epoch 3, gen_loss = 0.8382463828841252, disc_loss = 0.07821299896033397
Trained batch 67 in epoch 3, gen_loss = 0.8411732684163487, disc_loss = 0.07725074976299177
Trained batch 68 in epoch 3, gen_loss = 0.838341418383778, disc_loss = 0.07713114288028168
Trained batch 69 in epoch 3, gen_loss = 0.839963813338961, disc_loss = 0.07623389904786433
Trained batch 70 in epoch 3, gen_loss = 0.8421210764159619, disc_loss = 0.07549478335332283
Trained batch 71 in epoch 3, gen_loss = 0.8424446971880065, disc_loss = 0.0745976745383814
Trained batch 72 in epoch 3, gen_loss = 0.8415635897688669, disc_loss = 0.07404571527946893
Trained batch 73 in epoch 3, gen_loss = 0.8442531783838529, disc_loss = 0.07335695852147969
Trained batch 74 in epoch 3, gen_loss = 0.8450278886159261, disc_loss = 0.072518689930439
Trained batch 75 in epoch 3, gen_loss = 0.8459211478107854, disc_loss = 0.07170048520263088
Trained batch 76 in epoch 3, gen_loss = 0.8463630869791106, disc_loss = 0.07091585021804679
Trained batch 77 in epoch 3, gen_loss = 0.8480556798286927, disc_loss = 0.07016548948983352
Trained batch 78 in epoch 3, gen_loss = 0.8486644912369644, disc_loss = 0.06939665735050847
Trained batch 79 in epoch 3, gen_loss = 0.8521766684949398, disc_loss = 0.06879107123240828
Trained batch 80 in epoch 3, gen_loss = 0.8527548070307132, disc_loss = 0.06811676284781208
Trained batch 81 in epoch 3, gen_loss = 0.8531173133268589, disc_loss = 0.067446065975762
Trained batch 82 in epoch 3, gen_loss = 0.8556861690728061, disc_loss = 0.06687152542802224
Trained batch 83 in epoch 3, gen_loss = 0.8602758376371293, disc_loss = 0.06654032040387392
Trained batch 84 in epoch 3, gen_loss = 0.8610580472385182, disc_loss = 0.06608372917946648
Trained batch 85 in epoch 3, gen_loss = 0.8592188178106795, disc_loss = 0.06592578601178735
Trained batch 86 in epoch 3, gen_loss = 0.8619171682445482, disc_loss = 0.06530803442001343
Trained batch 87 in epoch 3, gen_loss = 0.8647446605292234, disc_loss = 0.06536738938567313
Trained batch 88 in epoch 3, gen_loss = 0.8645624752794758, disc_loss = 0.0649750850508722
Trained batch 89 in epoch 3, gen_loss = 0.8635474284489949, disc_loss = 0.06474292013380263
Trained batch 90 in epoch 3, gen_loss = 0.8632326217798086, disc_loss = 0.06432056447470581
Trained batch 91 in epoch 3, gen_loss = 0.867619092049806, disc_loss = 0.06432696938028802
Trained batch 92 in epoch 3, gen_loss = 0.8693840606238252, disc_loss = 0.06379544933236414
Trained batch 93 in epoch 3, gen_loss = 0.8687895625195605, disc_loss = 0.06342447949375243
Trained batch 94 in epoch 3, gen_loss = 0.8682488566950748, disc_loss = 0.06296263360663464
Trained batch 95 in epoch 3, gen_loss = 0.8697704275449117, disc_loss = 0.06319222350915273
Trained batch 96 in epoch 3, gen_loss = 0.8678722277130049, disc_loss = 0.06341340062544518
Trained batch 97 in epoch 3, gen_loss = 0.8672750872008654, disc_loss = 0.06322599879028845
Trained batch 98 in epoch 3, gen_loss = 0.8688324376790211, disc_loss = 0.06288164063836589
Trained batch 99 in epoch 3, gen_loss = 0.8703629887104034, disc_loss = 0.0627541933953762
Trained batch 100 in epoch 3, gen_loss = 0.8688777106823308, disc_loss = 0.0625437823778922
Trained batch 101 in epoch 3, gen_loss = 0.8670316467098161, disc_loss = 0.06235753186047077
Trained batch 102 in epoch 3, gen_loss = 0.8675046013396921, disc_loss = 0.06189823432744128
Trained batch 103 in epoch 3, gen_loss = 0.8680723412678792, disc_loss = 0.061660263078430526
Trained batch 104 in epoch 3, gen_loss = 0.8683995530718849, disc_loss = 0.061145237953002966
Trained batch 105 in epoch 3, gen_loss = 0.8676664413146253, disc_loss = 0.060704087596913835
Trained batch 106 in epoch 3, gen_loss = 0.8684633825426904, disc_loss = 0.0604686658420365
Trained batch 107 in epoch 3, gen_loss = 0.8700022476690786, disc_loss = 0.06002831811309551
Trained batch 108 in epoch 3, gen_loss = 0.8678089150595009, disc_loss = 0.060242259998831454
Trained batch 109 in epoch 3, gen_loss = 0.8692076282067732, disc_loss = 0.06057465808381411
Trained batch 110 in epoch 3, gen_loss = 0.8660305647162704, disc_loss = 0.06168704406517717
Trained batch 111 in epoch 3, gen_loss = 0.8687197124319417, disc_loss = 0.06251570516282559
Trained batch 112 in epoch 3, gen_loss = 0.8659930730288008, disc_loss = 0.06332370784314992
Trained batch 113 in epoch 3, gen_loss = 0.8646486396329445, disc_loss = 0.06340432834092594
Trained batch 114 in epoch 3, gen_loss = 0.8659317229105079, disc_loss = 0.06363077228888869
Trained batch 115 in epoch 3, gen_loss = 0.8648695252065001, disc_loss = 0.06356345432216366
Trained batch 116 in epoch 3, gen_loss = 0.8634328027056832, disc_loss = 0.06347974103628698
Trained batch 117 in epoch 3, gen_loss = 0.865300616975558, disc_loss = 0.0637586297412103
Trained batch 118 in epoch 3, gen_loss = 0.8631112886076214, disc_loss = 0.06435472161720406
Trained batch 119 in epoch 3, gen_loss = 0.8624807258447011, disc_loss = 0.06423040936157728
Trained batch 120 in epoch 3, gen_loss = 0.8635968373826712, disc_loss = 0.06404241495034542
Trained batch 121 in epoch 3, gen_loss = 0.8628916691561215, disc_loss = 0.06398806971742114
Trained batch 122 in epoch 3, gen_loss = 0.8622001937734403, disc_loss = 0.06360368800493396
Trained batch 123 in epoch 3, gen_loss = 0.8617180023462542, disc_loss = 0.06322043789024916
Trained batch 124 in epoch 3, gen_loss = 0.8625327973365784, disc_loss = 0.06279158334061503
Trained batch 125 in epoch 3, gen_loss = 0.8629255521865118, disc_loss = 0.0629161867527439
Trained batch 126 in epoch 3, gen_loss = 0.8614660417001079, disc_loss = 0.06286365689533785
Trained batch 127 in epoch 3, gen_loss = 0.861478722654283, disc_loss = 0.062453168797219405
Trained batch 128 in epoch 3, gen_loss = 0.8617478766182597, disc_loss = 0.06248812984256435
Trained batch 129 in epoch 3, gen_loss = 0.8617375227121207, disc_loss = 0.06211316194027089
Trained batch 130 in epoch 3, gen_loss = 0.8606980383851146, disc_loss = 0.062173193686762614
Trained batch 131 in epoch 3, gen_loss = 0.8624746790437987, disc_loss = 0.062101674333186536
Trained batch 132 in epoch 3, gen_loss = 0.862657157998336, disc_loss = 0.061766098537027164
Trained batch 133 in epoch 3, gen_loss = 0.8630353990775436, disc_loss = 0.061388853197194525
Trained batch 134 in epoch 3, gen_loss = 0.8626944087169789, disc_loss = 0.061097139268423674
Trained batch 135 in epoch 3, gen_loss = 0.8640995503348463, disc_loss = 0.06122166508301983
Trained batch 136 in epoch 3, gen_loss = 0.8623355618358528, disc_loss = 0.06146286893975887
Trained batch 137 in epoch 3, gen_loss = 0.8619327847508417, disc_loss = 0.061225773533806205
Trained batch 138 in epoch 3, gen_loss = 0.8646976767684058, disc_loss = 0.0626330460461942
Trained batch 139 in epoch 3, gen_loss = 0.8632734588214329, disc_loss = 0.06282410691824875
Trained batch 140 in epoch 3, gen_loss = 0.8625424736780478, disc_loss = 0.06262820191245447
Trained batch 141 in epoch 3, gen_loss = 0.8610306856497912, disc_loss = 0.0629018520851108
Trained batch 142 in epoch 3, gen_loss = 0.8609591351522432, disc_loss = 0.06256075868695661
Trained batch 143 in epoch 3, gen_loss = 0.8608988556596968, disc_loss = 0.06227520490776644
Trained batch 144 in epoch 3, gen_loss = 0.8603025872131874, disc_loss = 0.062232882500594035
Trained batch 145 in epoch 3, gen_loss = 0.8601756279599176, disc_loss = 0.06192807722772944
Trained batch 146 in epoch 3, gen_loss = 0.8610467172804332, disc_loss = 0.0616774702425666
Trained batch 147 in epoch 3, gen_loss = 0.8605322990868542, disc_loss = 0.061629985506344284
Trained batch 148 in epoch 3, gen_loss = 0.8584036323048124, disc_loss = 0.06250489695347695
Trained batch 149 in epoch 3, gen_loss = 0.8594542225201924, disc_loss = 0.06276313023952146
Trained batch 150 in epoch 3, gen_loss = 0.8590120152132401, disc_loss = 0.06251828958101521
Trained batch 151 in epoch 3, gen_loss = 0.8593578107262912, disc_loss = 0.06232075200501928
Trained batch 152 in epoch 3, gen_loss = 0.8597387387082468, disc_loss = 0.062055725637774645
Trained batch 153 in epoch 3, gen_loss = 0.8587218840400894, disc_loss = 0.06186766599232404
Trained batch 154 in epoch 3, gen_loss = 0.8581158699527863, disc_loss = 0.0618276386581842
Trained batch 155 in epoch 3, gen_loss = 0.8596421762918814, disc_loss = 0.061766328513980485
Trained batch 156 in epoch 3, gen_loss = 0.8588783870077437, disc_loss = 0.06166787444062199
Trained batch 157 in epoch 3, gen_loss = 0.8589840508714507, disc_loss = 0.06135652110251728
Trained batch 158 in epoch 3, gen_loss = 0.8595868334080439, disc_loss = 0.061148485294748214
Trained batch 159 in epoch 3, gen_loss = 0.8597084276378155, disc_loss = 0.06087653713475447
Trained batch 160 in epoch 3, gen_loss = 0.8576261382665693, disc_loss = 0.06142413673737312
Trained batch 161 in epoch 3, gen_loss = 0.858980252418989, disc_loss = 0.061897335617147664
Trained batch 162 in epoch 3, gen_loss = 0.8581107906037313, disc_loss = 0.06183980855279448
Trained batch 163 in epoch 3, gen_loss = 0.8583817583758656, disc_loss = 0.06157996982233826
Trained batch 164 in epoch 3, gen_loss = 0.8593103705030499, disc_loss = 0.06150127786747885
Trained batch 165 in epoch 3, gen_loss = 0.8580947611705366, disc_loss = 0.061852662877392876
Trained batch 166 in epoch 3, gen_loss = 0.8584826777795118, disc_loss = 0.0615434449997
Trained batch 167 in epoch 3, gen_loss = 0.8590086797873179, disc_loss = 0.061351871553121044
Trained batch 168 in epoch 3, gen_loss = 0.8594032279133091, disc_loss = 0.061069272483351845
Trained batch 169 in epoch 3, gen_loss = 0.8592480133561528, disc_loss = 0.06082251089734628
Trained batch 170 in epoch 3, gen_loss = 0.8595306360930727, disc_loss = 0.06052049643997299
Trained batch 171 in epoch 3, gen_loss = 0.8594636116610017, disc_loss = 0.060227795777474204
Trained batch 172 in epoch 3, gen_loss = 0.8595977670195475, disc_loss = 0.05996613294112286
Trained batch 173 in epoch 3, gen_loss = 0.8598165121571771, disc_loss = 0.059687068977596604
Trained batch 174 in epoch 3, gen_loss = 0.861714609009879, disc_loss = 0.059683114303542034
Trained batch 175 in epoch 3, gen_loss = 0.8619131787934087, disc_loss = 0.05939222246524878
Trained batch 176 in epoch 3, gen_loss = 0.8608914219726951, disc_loss = 0.059333043801729796
Trained batch 177 in epoch 3, gen_loss = 0.8619050728471092, disc_loss = 0.05909935333452114
Trained batch 178 in epoch 3, gen_loss = 0.8628875013836269, disc_loss = 0.059022274167490237
Trained batch 179 in epoch 3, gen_loss = 0.8625603679153654, disc_loss = 0.058830286787512405
Trained batch 180 in epoch 3, gen_loss = 0.8625650448693755, disc_loss = 0.05861720607168355
Trained batch 181 in epoch 3, gen_loss = 0.862730297086003, disc_loss = 0.058355552991238104
Trained batch 182 in epoch 3, gen_loss = 0.8630995545230928, disc_loss = 0.058097486600503734
Trained batch 183 in epoch 3, gen_loss = 0.864230398574601, disc_loss = 0.05790004148097385
Trained batch 184 in epoch 3, gen_loss = 0.8637278202417734, disc_loss = 0.05772086723984496
Trained batch 185 in epoch 3, gen_loss = 0.8632490891282276, disc_loss = 0.0575613363430665
Trained batch 186 in epoch 3, gen_loss = 0.8643572432472106, disc_loss = 0.057342608292452635
Trained batch 187 in epoch 3, gen_loss = 0.86570273054407, disc_loss = 0.05722397790498477
Trained batch 188 in epoch 3, gen_loss = 0.8648067381646898, disc_loss = 0.057308346414987846
Trained batch 189 in epoch 3, gen_loss = 0.8649144244821448, disc_loss = 0.05713497511797438
Trained batch 190 in epoch 3, gen_loss = 0.8650065301600551, disc_loss = 0.0568980579264462
Trained batch 191 in epoch 3, gen_loss = 0.8645481715599695, disc_loss = 0.056730570307991
Trained batch 192 in epoch 3, gen_loss = 0.86528176903107, disc_loss = 0.056565612252956074
Trained batch 193 in epoch 3, gen_loss = 0.8646941799478433, disc_loss = 0.05647818274440762
Trained batch 194 in epoch 3, gen_loss = 0.8651547786517021, disc_loss = 0.05636715505701991
Trained batch 195 in epoch 3, gen_loss = 0.8644779415763154, disc_loss = 0.05623775995954187
Trained batch 196 in epoch 3, gen_loss = 0.8648202679484024, disc_loss = 0.056044348215372276
Trained batch 197 in epoch 3, gen_loss = 0.8639176873245624, disc_loss = 0.05606989149295847
Trained batch 198 in epoch 3, gen_loss = 0.8650160470799585, disc_loss = 0.05646109918656586
Trained batch 199 in epoch 3, gen_loss = 0.8640092805027961, disc_loss = 0.05659655072493479
Trained batch 200 in epoch 3, gen_loss = 0.8636056964670248, disc_loss = 0.05684947186098689
Trained batch 201 in epoch 3, gen_loss = 0.8644253130596463, disc_loss = 0.056678459774426156
Trained batch 202 in epoch 3, gen_loss = 0.8638771892768409, disc_loss = 0.05655670144682374
Trained batch 203 in epoch 3, gen_loss = 0.8649167812922421, disc_loss = 0.056373603612312355
Trained batch 204 in epoch 3, gen_loss = 0.8648746705636745, disc_loss = 0.056259326625433634
Trained batch 205 in epoch 3, gen_loss = 0.8649515072697574, disc_loss = 0.05612115157560165
Trained batch 206 in epoch 3, gen_loss = 0.8651806910832723, disc_loss = 0.056022651032387204
Trained batch 207 in epoch 3, gen_loss = 0.8657227333348531, disc_loss = 0.055924168740882754
Trained batch 208 in epoch 3, gen_loss = 0.8667831954203153, disc_loss = 0.05584069965941983
Trained batch 209 in epoch 3, gen_loss = 0.8674646386078426, disc_loss = 0.05565088292628172
Trained batch 210 in epoch 3, gen_loss = 0.8677635099650559, disc_loss = 0.05556576890358922
Trained batch 211 in epoch 3, gen_loss = 0.8673085038954357, disc_loss = 0.055485763804512624
Trained batch 212 in epoch 3, gen_loss = 0.8681492422108359, disc_loss = 0.055446278975026006
Trained batch 213 in epoch 3, gen_loss = 0.8683660896582024, disc_loss = 0.05523045135392137
Trained batch 214 in epoch 3, gen_loss = 0.8679050731104474, disc_loss = 0.05511072939694967
Trained batch 215 in epoch 3, gen_loss = 0.8680939461897921, disc_loss = 0.05488554292565419
Trained batch 216 in epoch 3, gen_loss = 0.869746731997635, disc_loss = 0.05485645994921708
Trained batch 217 in epoch 3, gen_loss = 0.8704800258535857, disc_loss = 0.05467575163059278
Trained batch 218 in epoch 3, gen_loss = 0.8704008498148287, disc_loss = 0.05449138900273603
Trained batch 219 in epoch 3, gen_loss = 0.8702264555475928, disc_loss = 0.05433954567309807
Trained batch 220 in epoch 3, gen_loss = 0.8701718085491819, disc_loss = 0.054152670383824215
Trained batch 221 in epoch 3, gen_loss = 0.8710176488300702, disc_loss = 0.05417154356417758
Trained batch 222 in epoch 3, gen_loss = 0.8706801060603873, disc_loss = 0.054019663086152664
Trained batch 223 in epoch 3, gen_loss = 0.8709235026368073, disc_loss = 0.05383212512242608
Trained batch 224 in epoch 3, gen_loss = 0.8714381959703233, disc_loss = 0.053641946129500864
Trained batch 225 in epoch 3, gen_loss = 0.8722541094881243, disc_loss = 0.05344900150527864
Trained batch 226 in epoch 3, gen_loss = 0.8728846532132657, disc_loss = 0.05326157101811554
Trained batch 227 in epoch 3, gen_loss = 0.873035207913633, disc_loss = 0.053080700133649406
Trained batch 228 in epoch 3, gen_loss = 0.8732035425552634, disc_loss = 0.05287948774181989
Trained batch 229 in epoch 3, gen_loss = 0.8731092859869418, disc_loss = 0.05270464947933088
Trained batch 230 in epoch 3, gen_loss = 0.8739603827526043, disc_loss = 0.05263253662219166
Trained batch 231 in epoch 3, gen_loss = 0.8740100151505964, disc_loss = 0.052469011408212626
Trained batch 232 in epoch 3, gen_loss = 0.8739344991839495, disc_loss = 0.05233328285439204
Trained batch 233 in epoch 3, gen_loss = 0.8740751109062097, disc_loss = 0.05214450186373204
Trained batch 234 in epoch 3, gen_loss = 0.8746043897689657, disc_loss = 0.05195487341744469
Trained batch 235 in epoch 3, gen_loss = 0.8750229606689033, disc_loss = 0.05188300697748565
Trained batch 236 in epoch 3, gen_loss = 0.8747135871070347, disc_loss = 0.05174991958047644
Trained batch 237 in epoch 3, gen_loss = 0.8758185172782225, disc_loss = 0.05160292978750683
Trained batch 238 in epoch 3, gen_loss = 0.8769417579702753, disc_loss = 0.05143023850435243
Trained batch 239 in epoch 3, gen_loss = 0.8775704878071944, disc_loss = 0.051257029063223554
Trained batch 240 in epoch 3, gen_loss = 0.8775677515263379, disc_loss = 0.051195363251345535
Trained batch 241 in epoch 3, gen_loss = 0.8776096260744678, disc_loss = 0.05105091146124173
Trained batch 242 in epoch 3, gen_loss = 0.8779888241379349, disc_loss = 0.0508721777786014
Trained batch 243 in epoch 3, gen_loss = 0.8780954340930844, disc_loss = 0.05071324021860835
Trained batch 244 in epoch 3, gen_loss = 0.8790131206415137, disc_loss = 0.05062762467304663
Trained batch 245 in epoch 3, gen_loss = 0.8794367378804742, disc_loss = 0.050470483561266
Trained batch 246 in epoch 3, gen_loss = 0.878982712624044, disc_loss = 0.05041409211859167
Trained batch 247 in epoch 3, gen_loss = 0.8785930622008539, disc_loss = 0.050333230925213183
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 1.3146260976791382, disc_loss = 0.04795520380139351
Trained batch 1 in epoch 4, gen_loss = 1.1767026782035828, disc_loss = 0.031828537583351135
Trained batch 2 in epoch 4, gen_loss = 1.0891565680503845, disc_loss = 0.024269815534353256
Trained batch 3 in epoch 4, gen_loss = 1.0370056182146072, disc_loss = 0.020907262340188026
Trained batch 4 in epoch 4, gen_loss = 1.0074509143829347, disc_loss = 0.01834833938628435
Trained batch 5 in epoch 4, gen_loss = 1.0003024737040203, disc_loss = 0.016882274765521288
Trained batch 6 in epoch 4, gen_loss = 0.9622352804456439, disc_loss = 0.018259344223354543
Trained batch 7 in epoch 4, gen_loss = 0.9775501936674118, disc_loss = 0.023033991805277765
Trained batch 8 in epoch 4, gen_loss = 0.9559174908532037, disc_loss = 0.023371536595125992
Trained batch 9 in epoch 4, gen_loss = 0.9836146354675293, disc_loss = 0.02568187741562724
Trained batch 10 in epoch 4, gen_loss = 1.0061804489655928, disc_loss = 0.025724848309023815
Trained batch 11 in epoch 4, gen_loss = 1.000165154536565, disc_loss = 0.024732231472929318
Trained batch 12 in epoch 4, gen_loss = 0.9948729001558744, disc_loss = 0.02433483789746578
Trained batch 13 in epoch 4, gen_loss = 0.9929809144565037, disc_loss = 0.023456157451229438
Trained batch 14 in epoch 4, gen_loss = 0.9894235650698344, disc_loss = 0.02253382404645284
Trained batch 15 in epoch 4, gen_loss = 0.9905091859400272, disc_loss = 0.021655208780430257
Trained batch 16 in epoch 4, gen_loss = 0.9788203239440918, disc_loss = 0.021226785529185745
Trained batch 17 in epoch 4, gen_loss = 0.9725506769286262, disc_loss = 0.02038160336410834
Trained batch 18 in epoch 4, gen_loss = 0.9662660172111109, disc_loss = 0.01971102192213661
Trained batch 19 in epoch 4, gen_loss = 0.9701514422893525, disc_loss = 0.019299761159345508
Trained batch 20 in epoch 4, gen_loss = 0.9709155218941825, disc_loss = 0.01869733463085833
Trained batch 21 in epoch 4, gen_loss = 0.9696424495090138, disc_loss = 0.018133522900329394
Trained batch 22 in epoch 4, gen_loss = 0.9627652712490248, disc_loss = 0.017784931130059387
Trained batch 23 in epoch 4, gen_loss = 0.9601506392161051, disc_loss = 0.017231527871141832
Trained batch 24 in epoch 4, gen_loss = 0.9602522039413453, disc_loss = 0.017184789776802063
Trained batch 25 in epoch 4, gen_loss = 0.9561518018062298, disc_loss = 0.01671036805670995
Trained batch 26 in epoch 4, gen_loss = 0.9537351948243601, disc_loss = 0.01624971084917585
Trained batch 27 in epoch 4, gen_loss = 0.9540654165404183, disc_loss = 0.015895962532210563
Trained batch 28 in epoch 4, gen_loss = 0.951817995515363, disc_loss = 0.015578337029778752
Trained batch 29 in epoch 4, gen_loss = 0.9534081796805064, disc_loss = 0.015305725003903111
Trained batch 30 in epoch 4, gen_loss = 0.9529342920549454, disc_loss = 0.014974245726461373
Trained batch 31 in epoch 4, gen_loss = 0.9547777585685253, disc_loss = 0.014665045237052254
Trained batch 32 in epoch 4, gen_loss = 0.9548793995019161, disc_loss = 0.01436331443432154
Trained batch 33 in epoch 4, gen_loss = 0.9535845009719625, disc_loss = 0.01407393250230919
Trained batch 34 in epoch 4, gen_loss = 0.9528982264654977, disc_loss = 0.013805907193039145
Trained batch 35 in epoch 4, gen_loss = 0.952099965678321, disc_loss = 0.013637750306063227
Trained batch 36 in epoch 4, gen_loss = 0.9477577724972287, disc_loss = 0.013760930128596924
Trained batch 37 in epoch 4, gen_loss = 0.944466222273676, disc_loss = 0.01389525316067432
Trained batch 38 in epoch 4, gen_loss = 0.9478946053064786, disc_loss = 0.01394697044713375
Trained batch 39 in epoch 4, gen_loss = 0.9477256923913956, disc_loss = 0.013733804947696627
Trained batch 40 in epoch 4, gen_loss = 0.9442907324651393, disc_loss = 0.014010058693224338
Trained batch 41 in epoch 4, gen_loss = 0.9451920986175537, disc_loss = 0.01670183740290148
Trained batch 42 in epoch 4, gen_loss = 0.9362304723540018, disc_loss = 0.020842234777329965
Trained batch 43 in epoch 4, gen_loss = 0.9371117786927656, disc_loss = 0.020872340516441247
Trained batch 44 in epoch 4, gen_loss = 0.9388638655344645, disc_loss = 0.021896312861806818
Trained batch 45 in epoch 4, gen_loss = 0.9309215208758479, disc_loss = 0.024130109596349623
Trained batch 46 in epoch 4, gen_loss = 0.9311712866133832, disc_loss = 0.02424413732629507
Trained batch 47 in epoch 4, gen_loss = 0.9305434363583723, disc_loss = 0.02540822953839476
Trained batch 48 in epoch 4, gen_loss = 0.923909071756869, disc_loss = 0.02708324461187027
Trained batch 49 in epoch 4, gen_loss = 0.9203893148899078, disc_loss = 0.027430650796741247
Trained batch 50 in epoch 4, gen_loss = 0.9230607549349467, disc_loss = 0.029325604347475602
Trained batch 51 in epoch 4, gen_loss = 0.9163653701543808, disc_loss = 0.030844366518207468
Trained batch 52 in epoch 4, gen_loss = 0.9133348802350602, disc_loss = 0.03084978870696054
Trained batch 53 in epoch 4, gen_loss = 0.9170231797077038, disc_loss = 0.03376835462188831
Trained batch 54 in epoch 4, gen_loss = 0.913855487650091, disc_loss = 0.033821383677423
Trained batch 55 in epoch 4, gen_loss = 0.9072075039148331, disc_loss = 0.03555389016401023
Trained batch 56 in epoch 4, gen_loss = 0.9106719849402445, disc_loss = 0.03740172115922497
Trained batch 57 in epoch 4, gen_loss = 0.9079845742932682, disc_loss = 0.03717810141950332
Trained batch 58 in epoch 4, gen_loss = 0.9035067174394252, disc_loss = 0.03824731399762934
Trained batch 59 in epoch 4, gen_loss = 0.9038019349177678, disc_loss = 0.03841548780910671
Trained batch 60 in epoch 4, gen_loss = 0.904616364690124, disc_loss = 0.03838583810224396
Trained batch 61 in epoch 4, gen_loss = 0.9000371415768901, disc_loss = 0.03907107377064324
Trained batch 62 in epoch 4, gen_loss = 0.9007961721647353, disc_loss = 0.0388426362196841
Trained batch 63 in epoch 4, gen_loss = 0.9007825860753655, disc_loss = 0.038408026986871846
Trained batch 64 in epoch 4, gen_loss = 0.8986082452994126, disc_loss = 0.038207494739729626
Trained batch 65 in epoch 4, gen_loss = 0.9004663996624224, disc_loss = 0.03780502674988273
Trained batch 66 in epoch 4, gen_loss = 0.898907686347392, disc_loss = 0.037657088461095715
Trained batch 67 in epoch 4, gen_loss = 0.8997342560221168, disc_loss = 0.037306313553605884
Trained batch 68 in epoch 4, gen_loss = 0.9005812009175619, disc_loss = 0.03781093828434098
Trained batch 69 in epoch 4, gen_loss = 0.8971635520458221, disc_loss = 0.03805472939940435
Trained batch 70 in epoch 4, gen_loss = 0.8941886324278066, disc_loss = 0.03845886743142152
Trained batch 71 in epoch 4, gen_loss = 0.8961741377909979, disc_loss = 0.039798234110801585
Trained batch 72 in epoch 4, gen_loss = 0.8940674229843976, disc_loss = 0.039895430551714274
Trained batch 73 in epoch 4, gen_loss = 0.8912359806331428, disc_loss = 0.04013106849900371
Trained batch 74 in epoch 4, gen_loss = 0.8905793166160584, disc_loss = 0.04007274586707354
Trained batch 75 in epoch 4, gen_loss = 0.8914508678411183, disc_loss = 0.04041246078467291
Trained batch 76 in epoch 4, gen_loss = 0.8905969695611433, disc_loss = 0.04011476943390323
Trained batch 77 in epoch 4, gen_loss = 0.8886644481084286, disc_loss = 0.04036160686220496
Trained batch 78 in epoch 4, gen_loss = 0.8899225132374824, disc_loss = 0.04005501224789061
Trained batch 79 in epoch 4, gen_loss = 0.8898465692996979, disc_loss = 0.039673666935414076
Trained batch 80 in epoch 4, gen_loss = 0.8892834311650123, disc_loss = 0.039683696894366065
Trained batch 81 in epoch 4, gen_loss = 0.8871884047985077, disc_loss = 0.03963500856444603
Trained batch 82 in epoch 4, gen_loss = 0.8879405712506857, disc_loss = 0.039337627297963
Trained batch 83 in epoch 4, gen_loss = 0.8900097204106194, disc_loss = 0.03912199246475384
Trained batch 84 in epoch 4, gen_loss = 0.8897339308963103, disc_loss = 0.038748474397203504
Trained batch 85 in epoch 4, gen_loss = 0.8878710339235705, disc_loss = 0.03884223742453858
Trained batch 86 in epoch 4, gen_loss = 0.8879842134727829, disc_loss = 0.03857248186551292
Trained batch 87 in epoch 4, gen_loss = 0.8883538158102469, disc_loss = 0.038648435549641195
Trained batch 88 in epoch 4, gen_loss = 0.8877675633751945, disc_loss = 0.03843289789523971
Trained batch 89 in epoch 4, gen_loss = 0.8854690545135074, disc_loss = 0.03845836975508266
Trained batch 90 in epoch 4, gen_loss = 0.8864397170779469, disc_loss = 0.03824251071437375
Trained batch 91 in epoch 4, gen_loss = 0.8867285828227582, disc_loss = 0.038044333579423634
Trained batch 92 in epoch 4, gen_loss = 0.8882356465503733, disc_loss = 0.03774157571055556
Trained batch 93 in epoch 4, gen_loss = 0.8891437522908474, disc_loss = 0.03745484514597883
Trained batch 94 in epoch 4, gen_loss = 0.8869356324798182, disc_loss = 0.03780270583535496
Trained batch 95 in epoch 4, gen_loss = 0.8890150679896275, disc_loss = 0.038036776202109955
Trained batch 96 in epoch 4, gen_loss = 0.8865491741711331, disc_loss = 0.03846294129478563
Trained batch 97 in epoch 4, gen_loss = 0.8882602015320136, disc_loss = 0.03866700170447632
Trained batch 98 in epoch 4, gen_loss = 0.8879087826218268, disc_loss = 0.038507222188542585
Trained batch 99 in epoch 4, gen_loss = 0.8857877671718597, disc_loss = 0.03977243211120367
Trained batch 100 in epoch 4, gen_loss = 0.8822087374064002, disc_loss = 0.04103215639986614
Trained batch 101 in epoch 4, gen_loss = 0.8831126800939149, disc_loss = 0.04150549260278543
Trained batch 102 in epoch 4, gen_loss = 0.8832482371515441, disc_loss = 0.04122104760693404
Trained batch 103 in epoch 4, gen_loss = 0.8826524706987234, disc_loss = 0.040964985373788156
Trained batch 104 in epoch 4, gen_loss = 0.8820557157198589, disc_loss = 0.04073274305888585
Trained batch 105 in epoch 4, gen_loss = 0.882315772884297, disc_loss = 0.0404319745084306
Trained batch 106 in epoch 4, gen_loss = 0.8831252628397719, disc_loss = 0.04017422823496511
Trained batch 107 in epoch 4, gen_loss = 0.8823958513913331, disc_loss = 0.03996531109980963
Trained batch 108 in epoch 4, gen_loss = 0.8810543603853348, disc_loss = 0.039942403759704814
Trained batch 109 in epoch 4, gen_loss = 0.8819572725079277, disc_loss = 0.03979326276616617
Trained batch 110 in epoch 4, gen_loss = 0.8820648134291709, disc_loss = 0.03964159547074421
Trained batch 111 in epoch 4, gen_loss = 0.8801763297191688, disc_loss = 0.04013329062477818
Trained batch 112 in epoch 4, gen_loss = 0.8813654843684846, disc_loss = 0.040234791197344265
Trained batch 113 in epoch 4, gen_loss = 0.8818292152463344, disc_loss = 0.04001692622867331
Trained batch 114 in epoch 4, gen_loss = 0.8807806315629378, disc_loss = 0.03981205478472554
Trained batch 115 in epoch 4, gen_loss = 0.8813611145677238, disc_loss = 0.039569035236691606
Trained batch 116 in epoch 4, gen_loss = 0.8818369996853364, disc_loss = 0.039341975449242145
Trained batch 117 in epoch 4, gen_loss = 0.882317822363417, disc_loss = 0.0391644856624179
Trained batch 118 in epoch 4, gen_loss = 0.8828554574181052, disc_loss = 0.038898580848481974
Trained batch 119 in epoch 4, gen_loss = 0.8829045991102854, disc_loss = 0.038660230184905234
Trained batch 120 in epoch 4, gen_loss = 0.8832432149855558, disc_loss = 0.03846770212485278
Trained batch 121 in epoch 4, gen_loss = 0.8836241496390984, disc_loss = 0.03822457449907651
Trained batch 122 in epoch 4, gen_loss = 0.8829649008386503, disc_loss = 0.0380701658777832
Trained batch 123 in epoch 4, gen_loss = 0.8823478962144544, disc_loss = 0.037863719923001145
Trained batch 124 in epoch 4, gen_loss = 0.8830900754928589, disc_loss = 0.03763899322599173
Trained batch 125 in epoch 4, gen_loss = 0.883099470346693, disc_loss = 0.03752343174040554
Trained batch 126 in epoch 4, gen_loss = 0.8821284996242974, disc_loss = 0.03742172018309513
Trained batch 127 in epoch 4, gen_loss = 0.8815882722847164, disc_loss = 0.03723246044683037
Trained batch 128 in epoch 4, gen_loss = 0.88412580702656, disc_loss = 0.038182339573264584
Trained batch 129 in epoch 4, gen_loss = 0.8811744556977199, disc_loss = 0.03943667617411568
Trained batch 130 in epoch 4, gen_loss = 0.880543337068485, disc_loss = 0.0394749766471618
Trained batch 131 in epoch 4, gen_loss = 0.8816194945212567, disc_loss = 0.04060217331050697
Trained batch 132 in epoch 4, gen_loss = 0.8792891233487237, disc_loss = 0.04149796292045735
Trained batch 133 in epoch 4, gen_loss = 0.8779677588548234, disc_loss = 0.041892745705849645
Trained batch 134 in epoch 4, gen_loss = 0.8792887899610732, disc_loss = 0.04272733992310586
Trained batch 135 in epoch 4, gen_loss = 0.8780433623229756, disc_loss = 0.04284745536278933
Trained batch 136 in epoch 4, gen_loss = 0.8762025545983418, disc_loss = 0.04306065720118528
Trained batch 137 in epoch 4, gen_loss = 0.8756372531255087, disc_loss = 0.04296987171055398
Trained batch 138 in epoch 4, gen_loss = 0.8760023352911146, disc_loss = 0.04320305845157491
Trained batch 139 in epoch 4, gen_loss = 0.8760953907455716, disc_loss = 0.04301128820516169
Trained batch 140 in epoch 4, gen_loss = 0.8743540839100561, disc_loss = 0.043354068948814634
Trained batch 141 in epoch 4, gen_loss = 0.8733814220193407, disc_loss = 0.0434496837379542
Trained batch 142 in epoch 4, gen_loss = 0.873541087120563, disc_loss = 0.04453068535931252
Trained batch 143 in epoch 4, gen_loss = 0.8721036600569884, disc_loss = 0.04465672318797766
Trained batch 144 in epoch 4, gen_loss = 0.8709891964649332, disc_loss = 0.0446203605560907
Trained batch 145 in epoch 4, gen_loss = 0.8707451889776203, disc_loss = 0.04450512236647614
Trained batch 146 in epoch 4, gen_loss = 0.8713052199811352, disc_loss = 0.04469867935720958
Trained batch 147 in epoch 4, gen_loss = 0.8697531440773526, disc_loss = 0.04513307684101164
Trained batch 148 in epoch 4, gen_loss = 0.8684668176926222, disc_loss = 0.04512834457068035
Trained batch 149 in epoch 4, gen_loss = 0.8689035387833913, disc_loss = 0.04541260667766134
Trained batch 150 in epoch 4, gen_loss = 0.8681471864908736, disc_loss = 0.04532057267077119
Trained batch 151 in epoch 4, gen_loss = 0.8672850771169913, disc_loss = 0.045292321133035184
Trained batch 152 in epoch 4, gen_loss = 0.8667894777129678, disc_loss = 0.04515045878227825
Trained batch 153 in epoch 4, gen_loss = 0.8671676365586071, disc_loss = 0.045006704994465234
Trained batch 154 in epoch 4, gen_loss = 0.8677891196743135, disc_loss = 0.044975653729371484
Trained batch 155 in epoch 4, gen_loss = 0.866341124360378, disc_loss = 0.04526070782986398
Trained batch 156 in epoch 4, gen_loss = 0.8678944600615531, disc_loss = 0.045240864424616285
Trained batch 157 in epoch 4, gen_loss = 0.86839796357517, disc_loss = 0.04504588075996011
Trained batch 158 in epoch 4, gen_loss = 0.8683901665345678, disc_loss = 0.044839475924770035
Trained batch 159 in epoch 4, gen_loss = 0.8681679785251617, disc_loss = 0.04465137942461297
Trained batch 160 in epoch 4, gen_loss = 0.8694653977518496, disc_loss = 0.04454052215731292
Trained batch 161 in epoch 4, gen_loss = 0.8700246729968507, disc_loss = 0.04434132052263544
Trained batch 162 in epoch 4, gen_loss = 0.8698051842443782, disc_loss = 0.04415929532307057
Trained batch 163 in epoch 4, gen_loss = 0.8691983462833777, disc_loss = 0.044090751831124465
Trained batch 164 in epoch 4, gen_loss = 0.8691398447210138, disc_loss = 0.04388748383093061
Trained batch 165 in epoch 4, gen_loss = 0.8691930713423763, disc_loss = 0.04397227828873389
Trained batch 166 in epoch 4, gen_loss = 0.8683220897606033, disc_loss = 0.0438745762584006
Trained batch 167 in epoch 4, gen_loss = 0.8686453731996673, disc_loss = 0.04369673497110073
Trained batch 168 in epoch 4, gen_loss = 0.8681741296892336, disc_loss = 0.043804973700034194
Trained batch 169 in epoch 4, gen_loss = 0.8681098064955544, disc_loss = 0.04367179190739989
Trained batch 170 in epoch 4, gen_loss = 0.8689840631178248, disc_loss = 0.0435614884825565
Trained batch 171 in epoch 4, gen_loss = 0.8682790069386016, disc_loss = 0.04350091235950416
Trained batch 172 in epoch 4, gen_loss = 0.8679579672096782, disc_loss = 0.043337456445947206
Trained batch 173 in epoch 4, gen_loss = 0.8675125159066299, disc_loss = 0.043213856882876024
Trained batch 174 in epoch 4, gen_loss = 0.8686751692635672, disc_loss = 0.043065963807914935
Trained batch 175 in epoch 4, gen_loss = 0.868794481862675, disc_loss = 0.04285978940474293
Trained batch 176 in epoch 4, gen_loss = 0.868488732704335, disc_loss = 0.04271690580878133
Trained batch 177 in epoch 4, gen_loss = 0.8693515095817909, disc_loss = 0.042672922853066515
Trained batch 178 in epoch 4, gen_loss = 0.8688322725242743, disc_loss = 0.04265999288022435
Trained batch 179 in epoch 4, gen_loss = 0.8675341102812025, disc_loss = 0.04290620736105161
Trained batch 180 in epoch 4, gen_loss = 0.869607611914366, disc_loss = 0.04391300787078988
Trained batch 181 in epoch 4, gen_loss = 0.8692246164594378, disc_loss = 0.04380036708080097
Trained batch 182 in epoch 4, gen_loss = 0.8676071088822161, disc_loss = 0.04416008910184594
Trained batch 183 in epoch 4, gen_loss = 0.8672628674818121, disc_loss = 0.04414533467143369
Trained batch 184 in epoch 4, gen_loss = 0.867488119408891, disc_loss = 0.04401243034800565
Trained batch 185 in epoch 4, gen_loss = 0.8677369753519694, disc_loss = 0.04408219438396715
Trained batch 186 in epoch 4, gen_loss = 0.8672901694787377, disc_loss = 0.043995016874536316
Trained batch 187 in epoch 4, gen_loss = 0.868134340390246, disc_loss = 0.04388372306563357
Trained batch 188 in epoch 4, gen_loss = 0.8674694252392602, disc_loss = 0.043821114610644085
Trained batch 189 in epoch 4, gen_loss = 0.8676600638188814, disc_loss = 0.04364783874908952
Trained batch 190 in epoch 4, gen_loss = 0.8681329089309533, disc_loss = 0.04350331837447916
Trained batch 191 in epoch 4, gen_loss = 0.8679625581329068, disc_loss = 0.04332108713424532
Trained batch 192 in epoch 4, gen_loss = 0.8686255874411429, disc_loss = 0.04314008379509489
Trained batch 193 in epoch 4, gen_loss = 0.8680844709430773, disc_loss = 0.043080950724729096
Trained batch 194 in epoch 4, gen_loss = 0.8682097034576611, disc_loss = 0.04290108275002776
Trained batch 195 in epoch 4, gen_loss = 0.8684131329765126, disc_loss = 0.042731830938149015
Trained batch 196 in epoch 4, gen_loss = 0.8694357856881195, disc_loss = 0.04268841796464802
Trained batch 197 in epoch 4, gen_loss = 0.86951061210247, disc_loss = 0.04265696825600709
Trained batch 198 in epoch 4, gen_loss = 0.8690147735365671, disc_loss = 0.04259035516595795
Trained batch 199 in epoch 4, gen_loss = 0.8681073740124703, disc_loss = 0.04263912429334596
Trained batch 200 in epoch 4, gen_loss = 0.8694907115466559, disc_loss = 0.04264240405424984
Trained batch 201 in epoch 4, gen_loss = 0.8687214152057572, disc_loss = 0.042692559847313134
Trained batch 202 in epoch 4, gen_loss = 0.8693502254674, disc_loss = 0.042918069015160716
Trained batch 203 in epoch 4, gen_loss = 0.8683778789697909, disc_loss = 0.042996287320777045
Trained batch 204 in epoch 4, gen_loss = 0.8683082813169898, disc_loss = 0.04287449271622591
Trained batch 205 in epoch 4, gen_loss = 0.8688716674313962, disc_loss = 0.042869708539230875
Trained batch 206 in epoch 4, gen_loss = 0.8683678850459592, disc_loss = 0.042784961896548096
Trained batch 207 in epoch 4, gen_loss = 0.8681124167946669, disc_loss = 0.04269453742801069
Trained batch 208 in epoch 4, gen_loss = 0.8684315302155234, disc_loss = 0.042549037202996645
Trained batch 209 in epoch 4, gen_loss = 0.868351945139113, disc_loss = 0.04242157323418983
Trained batch 210 in epoch 4, gen_loss = 0.8686289343788726, disc_loss = 0.04227029972034396
Trained batch 211 in epoch 4, gen_loss = 0.8696889666453848, disc_loss = 0.04267191555008362
Trained batch 212 in epoch 4, gen_loss = 0.8679268420302252, disc_loss = 0.04354057155173499
Trained batch 213 in epoch 4, gen_loss = 0.8678737562672, disc_loss = 0.043452294902423416
Trained batch 214 in epoch 4, gen_loss = 0.8680055941260139, disc_loss = 0.043995276364216275
Trained batch 215 in epoch 4, gen_loss = 0.8672782487615391, disc_loss = 0.04407069410619981
Trained batch 216 in epoch 4, gen_loss = 0.866648348932442, disc_loss = 0.04483414004655546
Trained batch 217 in epoch 4, gen_loss = 0.8656196562795464, disc_loss = 0.04518228966888006
Trained batch 218 in epoch 4, gen_loss = 0.865689036644757, disc_loss = 0.04507327495891278
Trained batch 219 in epoch 4, gen_loss = 0.8660944999618964, disc_loss = 0.04524836128111929
Trained batch 220 in epoch 4, gen_loss = 0.8654238704372855, disc_loss = 0.045211395453155986
Trained batch 221 in epoch 4, gen_loss = 0.8645473612589879, disc_loss = 0.045284412207652454
Trained batch 222 in epoch 4, gen_loss = 0.8648769089726589, disc_loss = 0.045157000900668015
Trained batch 223 in epoch 4, gen_loss = 0.8649625103654606, disc_loss = 0.045201718418476436
Trained batch 224 in epoch 4, gen_loss = 0.864332760837343, disc_loss = 0.04511819229564733
Trained batch 225 in epoch 4, gen_loss = 0.8639123280227712, disc_loss = 0.045003957957837036
Trained batch 226 in epoch 4, gen_loss = 0.8646016823300181, disc_loss = 0.044981998865316224
Trained batch 227 in epoch 4, gen_loss = 0.8643761704626837, disc_loss = 0.04486195430396484
Trained batch 228 in epoch 4, gen_loss = 0.8638625224344595, disc_loss = 0.04480253066664244
Trained batch 229 in epoch 4, gen_loss = 0.8651333105304967, disc_loss = 0.045224441436078885
Trained batch 230 in epoch 4, gen_loss = 0.8639436657036538, disc_loss = 0.0454605760806728
Trained batch 231 in epoch 4, gen_loss = 0.8637777290724474, disc_loss = 0.04537211008699097
Trained batch 232 in epoch 4, gen_loss = 0.864034251210004, disc_loss = 0.045464974330426414
Trained batch 233 in epoch 4, gen_loss = 0.8637858245872024, disc_loss = 0.045376897871128134
Trained batch 234 in epoch 4, gen_loss = 0.8638926240992039, disc_loss = 0.04522474011644087
Trained batch 235 in epoch 4, gen_loss = 0.8636901708225072, disc_loss = 0.04509526430984359
Trained batch 236 in epoch 4, gen_loss = 0.8637903985343401, disc_loss = 0.0449340829708248
Trained batch 237 in epoch 4, gen_loss = 0.8644754717580411, disc_loss = 0.04501757090480826
Trained batch 238 in epoch 4, gen_loss = 0.8641329541116579, disc_loss = 0.04499025941167853
Trained batch 239 in epoch 4, gen_loss = 0.8636963567386071, disc_loss = 0.04492662634972173
Trained batch 240 in epoch 4, gen_loss = 0.8646823084947974, disc_loss = 0.044861188473342244
Trained batch 241 in epoch 4, gen_loss = 0.8645909016043687, disc_loss = 0.044732605343807706
Trained batch 242 in epoch 4, gen_loss = 0.8649741795082642, disc_loss = 0.044594091487810815
Trained batch 243 in epoch 4, gen_loss = 0.864930009866347, disc_loss = 0.044468659806431686
Trained batch 244 in epoch 4, gen_loss = 0.8650900973349201, disc_loss = 0.04444891401965703
Trained batch 245 in epoch 4, gen_loss = 0.8644270888431286, disc_loss = 0.04442407784991088
Trained batch 246 in epoch 4, gen_loss = 0.8645933428515307, disc_loss = 0.044364267068458835
Trained batch 247 in epoch 4, gen_loss = 0.8638500231167963, disc_loss = 0.0444067747899211
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 1.1593520641326904, disc_loss = 0.08723950386047363
Trained batch 1 in epoch 5, gen_loss = 1.0334780812263489, disc_loss = 0.05157509259879589
Trained batch 2 in epoch 5, gen_loss = 0.9433078765869141, disc_loss = 0.04598484436670939
Trained batch 3 in epoch 5, gen_loss = 0.9442657828330994, disc_loss = 0.03810418024659157
Trained batch 4 in epoch 5, gen_loss = 0.9273352026939392, disc_loss = 0.03383374474942684
Trained batch 5 in epoch 5, gen_loss = 0.9481366574764252, disc_loss = 0.034307102051874004
Trained batch 6 in epoch 5, gen_loss = 0.9172774979046413, disc_loss = 0.034693410620093346
Trained batch 7 in epoch 5, gen_loss = 0.9182378947734833, disc_loss = 0.03125098318560049
Trained batch 8 in epoch 5, gen_loss = 0.9221240348286099, disc_loss = 0.02859141305088997
Trained batch 9 in epoch 5, gen_loss = 0.9075479805469513, disc_loss = 0.027328279241919516
Trained batch 10 in epoch 5, gen_loss = 0.9025602503256365, disc_loss = 0.026288270272991875
Trained batch 11 in epoch 5, gen_loss = 0.9001451333363851, disc_loss = 0.025170023475463193
Trained batch 12 in epoch 5, gen_loss = 0.8985225145633404, disc_loss = 0.02484598720016388
Trained batch 13 in epoch 5, gen_loss = 0.890331255538123, disc_loss = 0.02443784787984831
Trained batch 14 in epoch 5, gen_loss = 0.8898959557215372, disc_loss = 0.023726377822458743
Trained batch 15 in epoch 5, gen_loss = 0.9018706455826759, disc_loss = 0.024295495299156755
Trained batch 16 in epoch 5, gen_loss = 0.9032405544729794, disc_loss = 0.02340305443195736
Trained batch 17 in epoch 5, gen_loss = 0.8983766999509599, disc_loss = 0.022967780112392373
Trained batch 18 in epoch 5, gen_loss = 0.8945124808110689, disc_loss = 0.022629972253190845
Trained batch 19 in epoch 5, gen_loss = 0.8996279150247574, disc_loss = 0.022802153322845697
Trained batch 20 in epoch 5, gen_loss = 0.9030482258115496, disc_loss = 0.022062457210960843
Trained batch 21 in epoch 5, gen_loss = 0.8970466310327704, disc_loss = 0.02161395401609215
Trained batch 22 in epoch 5, gen_loss = 0.8942141066426816, disc_loss = 0.021960840722464996
Trained batch 23 in epoch 5, gen_loss = 0.8915118277072906, disc_loss = 0.021868201011481386
Trained batch 24 in epoch 5, gen_loss = 0.8984444189071655, disc_loss = 0.021646969206631183
Trained batch 25 in epoch 5, gen_loss = 0.8997845741418692, disc_loss = 0.02111715475956981
Trained batch 26 in epoch 5, gen_loss = 0.9007683749552127, disc_loss = 0.020546746974879945
Trained batch 27 in epoch 5, gen_loss = 0.8944045986448016, disc_loss = 0.021314332078743194
Trained batch 28 in epoch 5, gen_loss = 0.8971952138275936, disc_loss = 0.022025461934892267
Trained batch 29 in epoch 5, gen_loss = 0.8925986488660177, disc_loss = 0.02265214406264325
Trained batch 30 in epoch 5, gen_loss = 0.8996758307180097, disc_loss = 0.022942405269150774
Trained batch 31 in epoch 5, gen_loss = 0.8948720917105675, disc_loss = 0.023106783934053965
Trained batch 32 in epoch 5, gen_loss = 0.891795115037398, disc_loss = 0.02296495879294746
Trained batch 33 in epoch 5, gen_loss = 0.898700615938972, disc_loss = 0.025591980131781277
Trained batch 34 in epoch 5, gen_loss = 0.8889587504523141, disc_loss = 0.02886506501319153
Trained batch 35 in epoch 5, gen_loss = 0.8905870003832711, disc_loss = 0.029741048308399815
Trained batch 36 in epoch 5, gen_loss = 0.8834794244250735, disc_loss = 0.03140524927073637
Trained batch 37 in epoch 5, gen_loss = 0.8858180516644528, disc_loss = 0.032680806667102796
Trained batch 38 in epoch 5, gen_loss = 0.8864536927296565, disc_loss = 0.03239793455801331
Trained batch 39 in epoch 5, gen_loss = 0.8796255379915238, disc_loss = 0.03372330005513504
Trained batch 40 in epoch 5, gen_loss = 0.8796515552009024, disc_loss = 0.03398622900656447
Trained batch 41 in epoch 5, gen_loss = 0.8823511884326026, disc_loss = 0.03358437800558195
Trained batch 42 in epoch 5, gen_loss = 0.8819581422694894, disc_loss = 0.03545583911283418
Trained batch 43 in epoch 5, gen_loss = 0.8739286593415521, disc_loss = 0.03957374958025122
Trained batch 44 in epoch 5, gen_loss = 0.869706216123369, disc_loss = 0.039874698770129016
Trained batch 45 in epoch 5, gen_loss = 0.8725603676360586, disc_loss = 0.042447483136683055
Trained batch 46 in epoch 5, gen_loss = 0.870178260701768, disc_loss = 0.04265728708792557
Trained batch 47 in epoch 5, gen_loss = 0.8673111374179522, disc_loss = 0.042585446703014895
Trained batch 48 in epoch 5, gen_loss = 0.8661239512112676, disc_loss = 0.042358303604153345
Trained batch 49 in epoch 5, gen_loss = 0.8692114925384522, disc_loss = 0.042488198848441246
Trained batch 50 in epoch 5, gen_loss = 0.8685805972884683, disc_loss = 0.04204371386189379
Trained batch 51 in epoch 5, gen_loss = 0.8683971911668777, disc_loss = 0.041487179920435525
Trained batch 52 in epoch 5, gen_loss = 0.8668732137050269, disc_loss = 0.04112225947550164
Trained batch 53 in epoch 5, gen_loss = 0.867186998879468, disc_loss = 0.04061647550271893
Trained batch 54 in epoch 5, gen_loss = 0.871181321144104, disc_loss = 0.041420645105906505
Trained batch 55 in epoch 5, gen_loss = 0.8698986577136176, disc_loss = 0.040977668191771954
Trained batch 56 in epoch 5, gen_loss = 0.8661917981348539, disc_loss = 0.04130054478484549
Trained batch 57 in epoch 5, gen_loss = 0.8637392860034416, disc_loss = 0.04101490220536703
Trained batch 58 in epoch 5, gen_loss = 0.8693824107364073, disc_loss = 0.04624549783292716
Trained batch 59 in epoch 5, gen_loss = 0.8658041447401047, disc_loss = 0.04672409746951113
Trained batch 60 in epoch 5, gen_loss = 0.8624265692273124, disc_loss = 0.047177420448145414
Trained batch 61 in epoch 5, gen_loss = 0.8617135997741453, disc_loss = 0.04953331876576187
Trained batch 62 in epoch 5, gen_loss = 0.8585315649471585, disc_loss = 0.05021511577808904
Trained batch 63 in epoch 5, gen_loss = 0.8570246184244752, disc_loss = 0.05037779574195156
Trained batch 64 in epoch 5, gen_loss = 0.8567230783976041, disc_loss = 0.05116967493668199
Trained batch 65 in epoch 5, gen_loss = 0.8533378839492798, disc_loss = 0.052102516355896085
Trained batch 66 in epoch 5, gen_loss = 0.8515530415435335, disc_loss = 0.0520323808860979
Trained batch 67 in epoch 5, gen_loss = 0.8532889976220972, disc_loss = 0.05265505856368691
Trained batch 68 in epoch 5, gen_loss = 0.8527026055515676, disc_loss = 0.05219211656789201
Trained batch 69 in epoch 5, gen_loss = 0.8493747583457402, disc_loss = 0.05273173366939383
Trained batch 70 in epoch 5, gen_loss = 0.8481010081062854, disc_loss = 0.05281885876648233
Trained batch 71 in epoch 5, gen_loss = 0.8492883899145656, disc_loss = 0.05233247133825595
Trained batch 72 in epoch 5, gen_loss = 0.8508686096700904, disc_loss = 0.05228622482885441
Trained batch 73 in epoch 5, gen_loss = 0.8490941162044937, disc_loss = 0.05205140746752354
Trained batch 74 in epoch 5, gen_loss = 0.8473883978525798, disc_loss = 0.05184422970438997
Trained batch 75 in epoch 5, gen_loss = 0.8493751381572924, disc_loss = 0.05170356316222368
Trained batch 76 in epoch 5, gen_loss = 0.8484733027297181, disc_loss = 0.05120924785854174
Trained batch 77 in epoch 5, gen_loss = 0.8485206143978314, disc_loss = 0.051461396529936254
Trained batch 78 in epoch 5, gen_loss = 0.8450784683227539, disc_loss = 0.052448189929363474
Trained batch 79 in epoch 5, gen_loss = 0.8467249639332295, disc_loss = 0.052803602284984666
Trained batch 80 in epoch 5, gen_loss = 0.8457022066469546, disc_loss = 0.05281657503089971
Trained batch 81 in epoch 5, gen_loss = 0.8452942473132435, disc_loss = 0.05243575857475218
Trained batch 82 in epoch 5, gen_loss = 0.845658675733819, disc_loss = 0.052118164077625574
Trained batch 83 in epoch 5, gen_loss = 0.8473928812004271, disc_loss = 0.052084470727658344
Trained batch 84 in epoch 5, gen_loss = 0.8443267422563889, disc_loss = 0.053384675112936424
Trained batch 85 in epoch 5, gen_loss = 0.844102217707523, disc_loss = 0.0530564286691938
Trained batch 86 in epoch 5, gen_loss = 0.847202957361594, disc_loss = 0.05375303668986963
Trained batch 87 in epoch 5, gen_loss = 0.8451488139954481, disc_loss = 0.053618233465716585
Trained batch 88 in epoch 5, gen_loss = 0.8454569283496128, disc_loss = 0.05315578411322799
Trained batch 89 in epoch 5, gen_loss = 0.8457201845116086, disc_loss = 0.05267619720867111
Trained batch 90 in epoch 5, gen_loss = 0.8466450028367095, disc_loss = 0.05220221921003291
Trained batch 91 in epoch 5, gen_loss = 0.8446136648240297, disc_loss = 0.052380067706310554
Trained batch 92 in epoch 5, gen_loss = 0.8454220717953097, disc_loss = 0.052275317135236914
Trained batch 93 in epoch 5, gen_loss = 0.8460800635053757, disc_loss = 0.05179374987517107
Trained batch 94 in epoch 5, gen_loss = 0.8454762044705842, disc_loss = 0.05137931212880894
Trained batch 95 in epoch 5, gen_loss = 0.8473563889662424, disc_loss = 0.051655820517529115
Trained batch 96 in epoch 5, gen_loss = 0.8455844386336729, disc_loss = 0.051578189241555855
Trained batch 97 in epoch 5, gen_loss = 0.8452665921376676, disc_loss = 0.051332068197163086
Trained batch 98 in epoch 5, gen_loss = 0.8463726278507349, disc_loss = 0.05090178370080663
Trained batch 99 in epoch 5, gen_loss = 0.847963724732399, disc_loss = 0.052088592811487616
Trained batch 100 in epoch 5, gen_loss = 0.8459653777651267, disc_loss = 0.05233003606208333
Trained batch 101 in epoch 5, gen_loss = 0.8450269862717273, disc_loss = 0.052039661221023575
Trained batch 102 in epoch 5, gen_loss = 0.8433785982502316, disc_loss = 0.056309123618474
Trained batch 103 in epoch 5, gen_loss = 0.8414069752280529, disc_loss = 0.056517616035237625
Trained batch 104 in epoch 5, gen_loss = 0.8409984060696193, disc_loss = 0.05628631662666088
Trained batch 105 in epoch 5, gen_loss = 0.8408476603481004, disc_loss = 0.05614053694759759
Trained batch 106 in epoch 5, gen_loss = 0.8399866401592148, disc_loss = 0.056264148115519885
Trained batch 107 in epoch 5, gen_loss = 0.8394278348596008, disc_loss = 0.05606644122464651
Trained batch 108 in epoch 5, gen_loss = 0.8384987515047055, disc_loss = 0.055983974141231095
Trained batch 109 in epoch 5, gen_loss = 0.839170168204741, disc_loss = 0.05592371887019412
Trained batch 110 in epoch 5, gen_loss = 0.8387884578189334, disc_loss = 0.05559968563669303
Trained batch 111 in epoch 5, gen_loss = 0.8399964395378318, disc_loss = 0.05530624575164568
Trained batch 112 in epoch 5, gen_loss = 0.8381625783126966, disc_loss = 0.05540725982344124
Trained batch 113 in epoch 5, gen_loss = 0.8382725757465028, disc_loss = 0.055258112955478986
Trained batch 114 in epoch 5, gen_loss = 0.8391597867012024, disc_loss = 0.05602305017654662
Trained batch 115 in epoch 5, gen_loss = 0.8357519086064964, disc_loss = 0.05807595293374796
Trained batch 116 in epoch 5, gen_loss = 0.8359204770153404, disc_loss = 0.057867102687143616
Trained batch 117 in epoch 5, gen_loss = 0.8354761544930733, disc_loss = 0.05824084824219472
Trained batch 118 in epoch 5, gen_loss = 0.8345018995910132, disc_loss = 0.059553373178482805
Trained batch 119 in epoch 5, gen_loss = 0.8343965977430343, disc_loss = 0.05923466276920711
Trained batch 120 in epoch 5, gen_loss = 0.8334332083867602, disc_loss = 0.05913129129854978
Trained batch 121 in epoch 5, gen_loss = 0.8324079450036659, disc_loss = 0.05901869842553603
Trained batch 122 in epoch 5, gen_loss = 0.8343582264776153, disc_loss = 0.060285984421133754
Trained batch 123 in epoch 5, gen_loss = 0.8328600059593877, disc_loss = 0.06040365114853147
Trained batch 124 in epoch 5, gen_loss = 0.8325686230659485, disc_loss = 0.06007560519501567
Trained batch 125 in epoch 5, gen_loss = 0.833272282566343, disc_loss = 0.06009416037889582
Trained batch 126 in epoch 5, gen_loss = 0.8314838766113041, disc_loss = 0.06023062335503265
Trained batch 127 in epoch 5, gen_loss = 0.8325070212595165, disc_loss = 0.05985230000442243
Trained batch 128 in epoch 5, gen_loss = 0.8324416081110636, disc_loss = 0.05959006554497651
Trained batch 129 in epoch 5, gen_loss = 0.8326015958419213, disc_loss = 0.059237227184124865
Trained batch 130 in epoch 5, gen_loss = 0.8325781685705403, disc_loss = 0.05889639797627585
Trained batch 131 in epoch 5, gen_loss = 0.833505908648173, disc_loss = 0.05858054331320366
Trained batch 132 in epoch 5, gen_loss = 0.8335331557388592, disc_loss = 0.05830643561675696
Trained batch 133 in epoch 5, gen_loss = 0.8338695057292482, disc_loss = 0.057969364021390454
Trained batch 134 in epoch 5, gen_loss = 0.834944325906259, disc_loss = 0.058524533585403805
Trained batch 135 in epoch 5, gen_loss = 0.8333934764651691, disc_loss = 0.05890179258730153
Trained batch 136 in epoch 5, gen_loss = 0.8336601783759403, disc_loss = 0.058603889400642505
Trained batch 137 in epoch 5, gen_loss = 0.8351796420588009, disc_loss = 0.05835928055592745
Trained batch 138 in epoch 5, gen_loss = 0.8352032462469965, disc_loss = 0.05808081111046586
Trained batch 139 in epoch 5, gen_loss = 0.8350192785263062, disc_loss = 0.05814470502747489
Trained batch 140 in epoch 5, gen_loss = 0.8355473749181057, disc_loss = 0.05890435712570523
Trained batch 141 in epoch 5, gen_loss = 0.8339216310373494, disc_loss = 0.05997446738511429
Trained batch 142 in epoch 5, gen_loss = 0.8345889365756428, disc_loss = 0.06102194384691286
Trained batch 143 in epoch 5, gen_loss = 0.8347969026201301, disc_loss = 0.060936753641322464
Trained batch 144 in epoch 5, gen_loss = 0.833054032407958, disc_loss = 0.06154743710789701
Trained batch 145 in epoch 5, gen_loss = 0.8325582942734026, disc_loss = 0.06148574647034378
Trained batch 146 in epoch 5, gen_loss = 0.8331467387627582, disc_loss = 0.06151352511389422
Trained batch 147 in epoch 5, gen_loss = 0.8337639638701001, disc_loss = 0.06121193119513525
Trained batch 148 in epoch 5, gen_loss = 0.8341234726393782, disc_loss = 0.060903057459141784
Trained batch 149 in epoch 5, gen_loss = 0.8342141596476237, disc_loss = 0.060605157380923626
Trained batch 150 in epoch 5, gen_loss = 0.8346820434197685, disc_loss = 0.06025362963054255
Trained batch 151 in epoch 5, gen_loss = 0.833787551051692, disc_loss = 0.060078573520417865
Trained batch 152 in epoch 5, gen_loss = 0.8342967909925124, disc_loss = 0.06005230588302796
Trained batch 153 in epoch 5, gen_loss = 0.8340216159046471, disc_loss = 0.059865834756887386
Trained batch 154 in epoch 5, gen_loss = 0.834868271504679, disc_loss = 0.05957680579214807
Trained batch 155 in epoch 5, gen_loss = 0.8347440079236642, disc_loss = 0.059313740070837624
Trained batch 156 in epoch 5, gen_loss = 0.834644013909018, disc_loss = 0.05904535249551865
Trained batch 157 in epoch 5, gen_loss = 0.8349855851523483, disc_loss = 0.05875025201246991
Trained batch 158 in epoch 5, gen_loss = 0.8355197456647765, disc_loss = 0.058437948182529814
Trained batch 159 in epoch 5, gen_loss = 0.8364960990846158, disc_loss = 0.058176128534250894
Trained batch 160 in epoch 5, gen_loss = 0.8372193671161343, disc_loss = 0.057886314332508335
Trained batch 161 in epoch 5, gen_loss = 0.8366694983876781, disc_loss = 0.057691808217952466
Trained batch 162 in epoch 5, gen_loss = 0.837648283850196, disc_loss = 0.057398104865926725
Trained batch 163 in epoch 5, gen_loss = 0.8375928056676213, disc_loss = 0.057114144636704244
Trained batch 164 in epoch 5, gen_loss = 0.8372001228910504, disc_loss = 0.057161310797726565
Trained batch 165 in epoch 5, gen_loss = 0.8361056224409357, disc_loss = 0.057296079131830706
Trained batch 166 in epoch 5, gen_loss = 0.8378090986948528, disc_loss = 0.05805814478959063
Trained batch 167 in epoch 5, gen_loss = 0.8370186115304629, disc_loss = 0.057971183861982786
Trained batch 168 in epoch 5, gen_loss = 0.8368593979869369, disc_loss = 0.05772504679715404
Trained batch 169 in epoch 5, gen_loss = 0.8374036631163428, disc_loss = 0.05791189418283894
Trained batch 170 in epoch 5, gen_loss = 0.8355616188188743, disc_loss = 0.058782956511196166
Trained batch 171 in epoch 5, gen_loss = 0.8367628042781076, disc_loss = 0.05865340148975943
Trained batch 172 in epoch 5, gen_loss = 0.8369751379669057, disc_loss = 0.05846534572229478
Trained batch 173 in epoch 5, gen_loss = 0.8372369987526159, disc_loss = 0.05817335606659709
Trained batch 174 in epoch 5, gen_loss = 0.8367910885810852, disc_loss = 0.05798612880121384
Trained batch 175 in epoch 5, gen_loss = 0.8369572203267704, disc_loss = 0.05771859230695885
Trained batch 176 in epoch 5, gen_loss = 0.8365632666032866, disc_loss = 0.05748252397255793
Trained batch 177 in epoch 5, gen_loss = 0.8373658221759154, disc_loss = 0.05731436627226348
Trained batch 178 in epoch 5, gen_loss = 0.8381914153445367, disc_loss = 0.0570566129985177
Trained batch 179 in epoch 5, gen_loss = 0.8381924543115827, disc_loss = 0.056793275359086695
Trained batch 180 in epoch 5, gen_loss = 0.8378502683744905, disc_loss = 0.056552658549597415
Trained batch 181 in epoch 5, gen_loss = 0.8371913112126864, disc_loss = 0.05651764258752567
Trained batch 182 in epoch 5, gen_loss = 0.837352952019113, disc_loss = 0.05633187167030947
Trained batch 183 in epoch 5, gen_loss = 0.8388292789459229, disc_loss = 0.05688884784720595
Trained batch 184 in epoch 5, gen_loss = 0.8378811945786347, disc_loss = 0.05686423421359143
Trained batch 185 in epoch 5, gen_loss = 0.8368398085717232, disc_loss = 0.05728083413584979
Trained batch 186 in epoch 5, gen_loss = 0.8381000196232515, disc_loss = 0.05721403348862248
Trained batch 187 in epoch 5, gen_loss = 0.8386990808426066, disc_loss = 0.057045005343636455
Trained batch 188 in epoch 5, gen_loss = 0.8379429976145426, disc_loss = 0.056988765345147206
Trained batch 189 in epoch 5, gen_loss = 0.838168131677728, disc_loss = 0.05677414935719418
Trained batch 190 in epoch 5, gen_loss = 0.8384471607457905, disc_loss = 0.05658399834692556
Trained batch 191 in epoch 5, gen_loss = 0.8381191880131761, disc_loss = 0.0564163139424636
Trained batch 192 in epoch 5, gen_loss = 0.8381892411820011, disc_loss = 0.05630563172738555
Trained batch 193 in epoch 5, gen_loss = 0.8390384574526364, disc_loss = 0.056069180717422944
Trained batch 194 in epoch 5, gen_loss = 0.8396561488127097, disc_loss = 0.05582055495813107
Trained batch 195 in epoch 5, gen_loss = 0.8394492624365554, disc_loss = 0.055650399365861504
Trained batch 196 in epoch 5, gen_loss = 0.8400912163826415, disc_loss = 0.05542355507782419
Trained batch 197 in epoch 5, gen_loss = 0.8405537235014366, disc_loss = 0.05535191414651997
Trained batch 198 in epoch 5, gen_loss = 0.8403576040387752, disc_loss = 0.05515921271719675
Trained batch 199 in epoch 5, gen_loss = 0.8400420048832893, disc_loss = 0.054991663401015106
Trained batch 200 in epoch 5, gen_loss = 0.8405253842695436, disc_loss = 0.05477269315878995
Trained batch 201 in epoch 5, gen_loss = 0.8409082606287286, disc_loss = 0.05454497375424103
Trained batch 202 in epoch 5, gen_loss = 0.8417407861484095, disc_loss = 0.054437562057133675
Trained batch 203 in epoch 5, gen_loss = 0.8421192595771715, disc_loss = 0.054242771986287595
Trained batch 204 in epoch 5, gen_loss = 0.8420746867249652, disc_loss = 0.05405807297949384
Trained batch 205 in epoch 5, gen_loss = 0.8425420597918982, disc_loss = 0.05383918889644511
Trained batch 206 in epoch 5, gen_loss = 0.8436305528677605, disc_loss = 0.05368541528871238
Trained batch 207 in epoch 5, gen_loss = 0.8442630475530257, disc_loss = 0.05345566119873323
Trained batch 208 in epoch 5, gen_loss = 0.8447237063252755, disc_loss = 0.053260266170369094
Trained batch 209 in epoch 5, gen_loss = 0.8447818957623981, disc_loss = 0.05305537385866046
Trained batch 210 in epoch 5, gen_loss = 0.8450451662755125, disc_loss = 0.05284061698657924
Trained batch 211 in epoch 5, gen_loss = 0.8455075298277837, disc_loss = 0.05261915293522179
Trained batch 212 in epoch 5, gen_loss = 0.845949412511548, disc_loss = 0.05240025697713237
Trained batch 213 in epoch 5, gen_loss = 0.8466370896758321, disc_loss = 0.05220798442410044
Trained batch 214 in epoch 5, gen_loss = 0.8476480306581009, disc_loss = 0.05200212968859908
Trained batch 215 in epoch 5, gen_loss = 0.8479129459570955, disc_loss = 0.05179604635944728
Trained batch 216 in epoch 5, gen_loss = 0.8479653077740823, disc_loss = 0.051597414557577416
Trained batch 217 in epoch 5, gen_loss = 0.8481789753524536, disc_loss = 0.051390041005498634
Trained batch 218 in epoch 5, gen_loss = 0.8493531417084611, disc_loss = 0.051229005022459244
Trained batch 219 in epoch 5, gen_loss = 0.8496518752791665, disc_loss = 0.051016564428044316
Trained batch 220 in epoch 5, gen_loss = 0.8499517082089213, disc_loss = 0.05082327798135343
Trained batch 221 in epoch 5, gen_loss = 0.8508626654878393, disc_loss = 0.05068964802928538
Trained batch 222 in epoch 5, gen_loss = 0.8502656560842232, disc_loss = 0.05059003224178748
Trained batch 223 in epoch 5, gen_loss = 0.8502800073474646, disc_loss = 0.05044075004947705
Trained batch 224 in epoch 5, gen_loss = 0.8509237866931492, disc_loss = 0.05030918682408002
Trained batch 225 in epoch 5, gen_loss = 0.8520391129814417, disc_loss = 0.050523000231540174
Trained batch 226 in epoch 5, gen_loss = 0.8511765806685461, disc_loss = 0.05066061103388273
Trained batch 227 in epoch 5, gen_loss = 0.8507180846574014, disc_loss = 0.050514911528137564
Trained batch 228 in epoch 5, gen_loss = 0.8514854330162814, disc_loss = 0.05034642481737197
Trained batch 229 in epoch 5, gen_loss = 0.8514471339142841, disc_loss = 0.05020372044578519
Trained batch 230 in epoch 5, gen_loss = 0.8506150191480463, disc_loss = 0.050362788751576244
Trained batch 231 in epoch 5, gen_loss = 0.8517181577867475, disc_loss = 0.050509656231513184
Trained batch 232 in epoch 5, gen_loss = 0.8528532155593578, disc_loss = 0.05040772997698239
Trained batch 233 in epoch 5, gen_loss = 0.8530994065296955, disc_loss = 0.050273989985943734
Trained batch 234 in epoch 5, gen_loss = 0.8525043586467175, disc_loss = 0.050247571108109776
Trained batch 235 in epoch 5, gen_loss = 0.852339935504784, disc_loss = 0.050159940249444444
Trained batch 236 in epoch 5, gen_loss = 0.8530350204258529, disc_loss = 0.05017159755620713
Trained batch 237 in epoch 5, gen_loss = 0.8534055647729826, disc_loss = 0.049989951553386675
Trained batch 238 in epoch 5, gen_loss = 0.8533039980852454, disc_loss = 0.0498403899710641
Trained batch 239 in epoch 5, gen_loss = 0.8533537765343984, disc_loss = 0.04966722219057071
Trained batch 240 in epoch 5, gen_loss = 0.8524854922690333, disc_loss = 0.04975793215241361
Trained batch 241 in epoch 5, gen_loss = 0.8541211823293985, disc_loss = 0.05048410943709314
Trained batch 242 in epoch 5, gen_loss = 0.8534716860747632, disc_loss = 0.05040318272632274
Trained batch 243 in epoch 5, gen_loss = 0.8527679147778965, disc_loss = 0.05041063717971021
Trained batch 244 in epoch 5, gen_loss = 0.8533255696296692, disc_loss = 0.05025458841261511
Trained batch 245 in epoch 5, gen_loss = 0.853471818735929, disc_loss = 0.05014879774960985
Trained batch 246 in epoch 5, gen_loss = 0.8536537272727441, disc_loss = 0.04998724260424011
Trained batch 247 in epoch 5, gen_loss = 0.8531891963174266, disc_loss = 0.04993301455584925
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.818164587020874, disc_loss = 0.009979404509067535
Trained batch 1 in epoch 6, gen_loss = 0.8344147801399231, disc_loss = 0.028194237500429153
Trained batch 2 in epoch 6, gen_loss = 0.864092230796814, disc_loss = 0.021378809586167336
Trained batch 3 in epoch 6, gen_loss = 0.8258792757987976, disc_loss = 0.027408582624047995
Trained batch 4 in epoch 6, gen_loss = 0.8596443295478821, disc_loss = 0.026519548520445822
Trained batch 5 in epoch 6, gen_loss = 0.8748558262983958, disc_loss = 0.02360379168142875
Trained batch 6 in epoch 6, gen_loss = 0.8605826156479972, disc_loss = 0.022563652534570013
Trained batch 7 in epoch 6, gen_loss = 0.8565285429358482, disc_loss = 0.02148862776812166
Trained batch 8 in epoch 6, gen_loss = 0.8444394734170702, disc_loss = 0.02086181493682994
Trained batch 9 in epoch 6, gen_loss = 0.8605857074260712, disc_loss = 0.020506401639431716
Trained batch 10 in epoch 6, gen_loss = 0.8626211502335288, disc_loss = 0.022330240346491337
Trained batch 11 in epoch 6, gen_loss = 0.8418015241622925, disc_loss = 0.027481851711248357
Trained batch 12 in epoch 6, gen_loss = 0.8568419951658982, disc_loss = 0.027220071436694034
Trained batch 13 in epoch 6, gen_loss = 0.8603067908968244, disc_loss = 0.033101574052125216
Trained batch 14 in epoch 6, gen_loss = 0.8366235971450806, disc_loss = 0.04297190252691507
Trained batch 15 in epoch 6, gen_loss = 0.8425823152065277, disc_loss = 0.04229205654701218
Trained batch 16 in epoch 6, gen_loss = 0.8415684279273538, disc_loss = 0.045791003579164255
Trained batch 17 in epoch 6, gen_loss = 0.8368702928225199, disc_loss = 0.04619744663230247
Trained batch 18 in epoch 6, gen_loss = 0.8503194859153346, disc_loss = 0.04639098945220834
Trained batch 19 in epoch 6, gen_loss = 0.8613528490066529, disc_loss = 0.045265230489894746
Trained batch 20 in epoch 6, gen_loss = 0.859368432135809, disc_loss = 0.043771358694703805
Trained batch 21 in epoch 6, gen_loss = 0.8605205362493341, disc_loss = 0.042273487176068804
Trained batch 22 in epoch 6, gen_loss = 0.8531989714373713, disc_loss = 0.041942576796788235
Trained batch 23 in epoch 6, gen_loss = 0.8627538060148557, disc_loss = 0.04800983002254119
Trained batch 24 in epoch 6, gen_loss = 0.8478998911380767, disc_loss = 0.05252230148762464
Trained batch 25 in epoch 6, gen_loss = 0.852678066262832, disc_loss = 0.05353193425645049
Trained batch 26 in epoch 6, gen_loss = 0.847772623653765, disc_loss = 0.053069822041800725
Trained batch 27 in epoch 6, gen_loss = 0.8478945695928165, disc_loss = 0.051693459606862495
Trained batch 28 in epoch 6, gen_loss = 0.8496500736680525, disc_loss = 0.052344051061262345
Trained batch 29 in epoch 6, gen_loss = 0.8464902192354202, disc_loss = 0.05154761029407382
Trained batch 30 in epoch 6, gen_loss = 0.8414274636776217, disc_loss = 0.05142749536542162
Trained batch 31 in epoch 6, gen_loss = 0.8407344622537494, disc_loss = 0.05054263517376967
Trained batch 32 in epoch 6, gen_loss = 0.8439272705352667, disc_loss = 0.050316741548930156
Trained batch 33 in epoch 6, gen_loss = 0.8449303551631815, disc_loss = 0.04971201989032766
Trained batch 34 in epoch 6, gen_loss = 0.8405433986868177, disc_loss = 0.04995650837996176
Trained batch 35 in epoch 6, gen_loss = 0.8453679407636324, disc_loss = 0.0489051882436292
Trained batch 36 in epoch 6, gen_loss = 0.8454978699619705, disc_loss = 0.048096006157229074
Trained batch 37 in epoch 6, gen_loss = 0.8473227408371473, disc_loss = 0.047081511884339546
Trained batch 38 in epoch 6, gen_loss = 0.8480883248341389, disc_loss = 0.04616141593895662
Trained batch 39 in epoch 6, gen_loss = 0.8476407550275326, disc_loss = 0.045439074444584546
Trained batch 40 in epoch 6, gen_loss = 0.8475614837030085, disc_loss = 0.04457771587299138
Trained batch 41 in epoch 6, gen_loss = 0.8516031581731069, disc_loss = 0.04550060904806569
Trained batch 42 in epoch 6, gen_loss = 0.845925588247388, disc_loss = 0.046381898830796395
Trained batch 43 in epoch 6, gen_loss = 0.8500995087352666, disc_loss = 0.046287566677413204
Trained batch 44 in epoch 6, gen_loss = 0.8502980927626292, disc_loss = 0.04543256024933524
Trained batch 45 in epoch 6, gen_loss = 0.8499315309783687, disc_loss = 0.045020829825459616
Trained batch 46 in epoch 6, gen_loss = 0.8480765699072087, disc_loss = 0.044632282761975804
Trained batch 47 in epoch 6, gen_loss = 0.8496969236681858, disc_loss = 0.044137252087239176
Trained batch 48 in epoch 6, gen_loss = 0.8490334280899593, disc_loss = 0.043613399150876364
Trained batch 49 in epoch 6, gen_loss = 0.84944560110569, disc_loss = 0.04296312814578414
Trained batch 50 in epoch 6, gen_loss = 0.8498054935651667, disc_loss = 0.04239204765169644
Trained batch 51 in epoch 6, gen_loss = 0.850035504079782, disc_loss = 0.04180478095076978
Trained batch 52 in epoch 6, gen_loss = 0.8498221270318301, disc_loss = 0.04117911205328298
Trained batch 53 in epoch 6, gen_loss = 0.8507125769500379, disc_loss = 0.04059041189719682
Trained batch 54 in epoch 6, gen_loss = 0.8536639945073561, disc_loss = 0.040117293308404356
Trained batch 55 in epoch 6, gen_loss = 0.8550020429704871, disc_loss = 0.03950310414490689
Trained batch 56 in epoch 6, gen_loss = 0.8569397774704716, disc_loss = 0.03978003844978255
Trained batch 57 in epoch 6, gen_loss = 0.8534959220680697, disc_loss = 0.04003307482645173
Trained batch 58 in epoch 6, gen_loss = 0.8514515722202043, disc_loss = 0.039896328025892124
Trained batch 59 in epoch 6, gen_loss = 0.8566434676448504, disc_loss = 0.04037285679175208
Trained batch 60 in epoch 6, gen_loss = 0.8565971289501816, disc_loss = 0.040034752423096384
Trained batch 61 in epoch 6, gen_loss = 0.8550724593862411, disc_loss = 0.040024559727058776
Trained batch 62 in epoch 6, gen_loss = 0.8558962226860107, disc_loss = 0.03956250458334883
Trained batch 63 in epoch 6, gen_loss = 0.8565662517212331, disc_loss = 0.039098055007343646
Trained batch 64 in epoch 6, gen_loss = 0.8598741215008956, disc_loss = 0.03903461330068799
Trained batch 65 in epoch 6, gen_loss = 0.8592248301614415, disc_loss = 0.038579430099520265
Trained batch 66 in epoch 6, gen_loss = 0.8572545607588185, disc_loss = 0.03848918689303656
Trained batch 67 in epoch 6, gen_loss = 0.8586951156749445, disc_loss = 0.03818729509572115
Trained batch 68 in epoch 6, gen_loss = 0.8583922882874807, disc_loss = 0.03793478884693721
Trained batch 69 in epoch 6, gen_loss = 0.8588142254522868, disc_loss = 0.03757815747521818
Trained batch 70 in epoch 6, gen_loss = 0.8590515629506447, disc_loss = 0.03725370194789179
Trained batch 71 in epoch 6, gen_loss = 0.8602696934507953, disc_loss = 0.03690349307402761
Trained batch 72 in epoch 6, gen_loss = 0.8614862418338044, disc_loss = 0.03652137236618628
Trained batch 73 in epoch 6, gen_loss = 0.8611883227084134, disc_loss = 0.036176019241227896
Trained batch 74 in epoch 6, gen_loss = 0.8621397833029429, disc_loss = 0.03610169894372423
Trained batch 75 in epoch 6, gen_loss = 0.8588951547679148, disc_loss = 0.036615050220126774
Trained batch 76 in epoch 6, gen_loss = 0.8613131143055953, disc_loss = 0.036913713337490696
Trained batch 77 in epoch 6, gen_loss = 0.8625435175803992, disc_loss = 0.03652731667702588
Trained batch 78 in epoch 6, gen_loss = 0.8629979985424235, disc_loss = 0.03616744088291933
Trained batch 79 in epoch 6, gen_loss = 0.8616169575601816, disc_loss = 0.036067235906375575
Trained batch 80 in epoch 6, gen_loss = 0.8643870769459524, disc_loss = 0.035817346909301884
Trained batch 81 in epoch 6, gen_loss = 0.8653733574035691, disc_loss = 0.03558650098900061
Trained batch 82 in epoch 6, gen_loss = 0.8649403966334929, disc_loss = 0.03535946933777038
Trained batch 83 in epoch 6, gen_loss = 0.8643197811075619, disc_loss = 0.035212287962037535
Trained batch 84 in epoch 6, gen_loss = 0.8644633752458236, disc_loss = 0.03489361336893019
Trained batch 85 in epoch 6, gen_loss = 0.8647722854863765, disc_loss = 0.03454079321412326
Trained batch 86 in epoch 6, gen_loss = 0.8653259486302562, disc_loss = 0.03425299019242326
Trained batch 87 in epoch 6, gen_loss = 0.8655889146029949, disc_loss = 0.03396147930338471
Trained batch 88 in epoch 6, gen_loss = 0.865468744816405, disc_loss = 0.03364048583244675
Trained batch 89 in epoch 6, gen_loss = 0.8662632044818667, disc_loss = 0.03341298091949688
Trained batch 90 in epoch 6, gen_loss = 0.8665401100457369, disc_loss = 0.033090097282163715
Trained batch 91 in epoch 6, gen_loss = 0.8665360150777776, disc_loss = 0.03278585450986967
Trained batch 92 in epoch 6, gen_loss = 0.8668367628769208, disc_loss = 0.03248691127725666
Trained batch 93 in epoch 6, gen_loss = 0.8679719329514402, disc_loss = 0.032238592428373215
Trained batch 94 in epoch 6, gen_loss = 0.8684578076789253, disc_loss = 0.031963417218311835
Trained batch 95 in epoch 6, gen_loss = 0.8690723506733775, disc_loss = 0.03167810520972125
Trained batch 96 in epoch 6, gen_loss = 0.8701491014859111, disc_loss = 0.031597139361823345
Trained batch 97 in epoch 6, gen_loss = 0.8703350366986528, disc_loss = 0.031347207439949315
Trained batch 98 in epoch 6, gen_loss = 0.8711079434312955, disc_loss = 0.031082755608502963
Trained batch 99 in epoch 6, gen_loss = 0.8717519268393517, disc_loss = 0.03082139164209366
Trained batch 100 in epoch 6, gen_loss = 0.8726266430746211, disc_loss = 0.0305588951168379
Trained batch 101 in epoch 6, gen_loss = 0.8738496189608294, disc_loss = 0.030331531548689977
Trained batch 102 in epoch 6, gen_loss = 0.8740057855555154, disc_loss = 0.030116769783560513
Trained batch 103 in epoch 6, gen_loss = 0.8747681324871687, disc_loss = 0.029871234410585694
Trained batch 104 in epoch 6, gen_loss = 0.8752066087155115, disc_loss = 0.029628650790878706
Trained batch 105 in epoch 6, gen_loss = 0.8758918685170839, disc_loss = 0.029386667670892937
Trained batch 106 in epoch 6, gen_loss = 0.8767687870520298, disc_loss = 0.029156796856147943
Trained batch 107 in epoch 6, gen_loss = 0.8771961786680751, disc_loss = 0.02893366174410201
Trained batch 108 in epoch 6, gen_loss = 0.8773958215472895, disc_loss = 0.028695432764025183
Trained batch 109 in epoch 6, gen_loss = 0.8777351913127032, disc_loss = 0.028471213845874775
Trained batch 110 in epoch 6, gen_loss = 0.8784315304176228, disc_loss = 0.028244102692550368
Trained batch 111 in epoch 6, gen_loss = 0.8786436135747603, disc_loss = 0.028048086770078435
Trained batch 112 in epoch 6, gen_loss = 0.8792176138510747, disc_loss = 0.02783873269284985
Trained batch 113 in epoch 6, gen_loss = 0.8798170379902187, disc_loss = 0.02763291983456727
Trained batch 114 in epoch 6, gen_loss = 0.8802131017912989, disc_loss = 0.027424110261642414
Trained batch 115 in epoch 6, gen_loss = 0.8803227304898459, disc_loss = 0.02725880291987339
Trained batch 116 in epoch 6, gen_loss = 0.8806403618083041, disc_loss = 0.027094713284864895
Trained batch 117 in epoch 6, gen_loss = 0.8809149328429821, disc_loss = 0.02690757633486794
Trained batch 118 in epoch 6, gen_loss = 0.8811931692752517, disc_loss = 0.02671438448538049
Trained batch 119 in epoch 6, gen_loss = 0.8816539339721203, disc_loss = 0.02652025290299207
Trained batch 120 in epoch 6, gen_loss = 0.8816692181362593, disc_loss = 0.026334981029960982
Trained batch 121 in epoch 6, gen_loss = 0.8826029195648725, disc_loss = 0.02618638759280448
Trained batch 122 in epoch 6, gen_loss = 0.8829211929464728, disc_loss = 0.02604184240269346
Trained batch 123 in epoch 6, gen_loss = 0.8832658084650193, disc_loss = 0.02587087863996144
Trained batch 124 in epoch 6, gen_loss = 0.8835066373348236, disc_loss = 0.02571737203747034
Trained batch 125 in epoch 6, gen_loss = 0.8840220629695862, disc_loss = 0.025540397421176
Trained batch 126 in epoch 6, gen_loss = 0.8843883864992247, disc_loss = 0.025387988785120445
Trained batch 127 in epoch 6, gen_loss = 0.8848000455182046, disc_loss = 0.025216765534423757
Trained batch 128 in epoch 6, gen_loss = 0.8853929636552352, disc_loss = 0.025047687936372073
Trained batch 129 in epoch 6, gen_loss = 0.8857698644583042, disc_loss = 0.024896724643902135
Trained batch 130 in epoch 6, gen_loss = 0.8864188524147937, disc_loss = 0.024757329161271793
Trained batch 131 in epoch 6, gen_loss = 0.8866936458331166, disc_loss = 0.02461046318763472
Trained batch 132 in epoch 6, gen_loss = 0.8871093349797385, disc_loss = 0.024448510697041462
Trained batch 133 in epoch 6, gen_loss = 0.8874883649509344, disc_loss = 0.02429070279398349
Trained batch 134 in epoch 6, gen_loss = 0.8876365681489309, disc_loss = 0.024133345491632267
Trained batch 135 in epoch 6, gen_loss = 0.8879488656187758, disc_loss = 0.023981760814101163
Trained batch 136 in epoch 6, gen_loss = 0.8883205232394003, disc_loss = 0.02385633209393951
Trained batch 137 in epoch 6, gen_loss = 0.8879855752423189, disc_loss = 0.023740587435473783
Trained batch 138 in epoch 6, gen_loss = 0.888174616389995, disc_loss = 0.02359325457163316
Trained batch 139 in epoch 6, gen_loss = 0.8889993916664805, disc_loss = 0.023455029696093074
Trained batch 140 in epoch 6, gen_loss = 0.8895833874847872, disc_loss = 0.023310522396936484
Trained batch 141 in epoch 6, gen_loss = 0.8901736952469382, disc_loss = 0.023180726538477858
Trained batch 142 in epoch 6, gen_loss = 0.8902917702298064, disc_loss = 0.02304745224871106
Trained batch 143 in epoch 6, gen_loss = 0.890292601659894, disc_loss = 0.022904418565708004
Trained batch 144 in epoch 6, gen_loss = 0.8905844073871086, disc_loss = 0.022769637238876574
Trained batch 145 in epoch 6, gen_loss = 0.891123669808858, disc_loss = 0.022638511470812438
Trained batch 146 in epoch 6, gen_loss = 0.8914719672024656, disc_loss = 0.022500543744258937
Trained batch 147 in epoch 6, gen_loss = 0.8914945864596883, disc_loss = 0.022365057680478972
Trained batch 148 in epoch 6, gen_loss = 0.8914357673801832, disc_loss = 0.02224902775851172
Trained batch 149 in epoch 6, gen_loss = 0.891667612195015, disc_loss = 0.022120703981878858
Trained batch 150 in epoch 6, gen_loss = 0.8919480121293605, disc_loss = 0.021992243917362875
Trained batch 151 in epoch 6, gen_loss = 0.8923100442870667, disc_loss = 0.021872837048967517
Trained batch 152 in epoch 6, gen_loss = 0.8923986758671555, disc_loss = 0.02175998711027205
Trained batch 153 in epoch 6, gen_loss = 0.8924256785736455, disc_loss = 0.021648987996174242
Trained batch 154 in epoch 6, gen_loss = 0.892786092335178, disc_loss = 0.021530118903085108
Trained batch 155 in epoch 6, gen_loss = 0.8928488896061213, disc_loss = 0.021415560786875013
Trained batch 156 in epoch 6, gen_loss = 0.8930068564642767, disc_loss = 0.0213044486334844
Trained batch 157 in epoch 6, gen_loss = 0.8932645994273922, disc_loss = 0.021183599019423127
Trained batch 158 in epoch 6, gen_loss = 0.8933119652031353, disc_loss = 0.02106885030520084
Trained batch 159 in epoch 6, gen_loss = 0.8933340622112155, disc_loss = 0.020956399626447818
Trained batch 160 in epoch 6, gen_loss = 0.8933601581161807, disc_loss = 0.020860287473646936
Trained batch 161 in epoch 6, gen_loss = 0.8935949829993425, disc_loss = 0.020746435205463643
Trained batch 162 in epoch 6, gen_loss = 0.8942940935401097, disc_loss = 0.020660671776880517
Trained batch 163 in epoch 6, gen_loss = 0.8943587201761036, disc_loss = 0.02054713429065376
Trained batch 164 in epoch 6, gen_loss = 0.8945634406624419, disc_loss = 0.020448389203485216
Trained batch 165 in epoch 6, gen_loss = 0.8950100151530231, disc_loss = 0.02034779686160969
Trained batch 166 in epoch 6, gen_loss = 0.8947525900638033, disc_loss = 0.020240464557274553
Trained batch 167 in epoch 6, gen_loss = 0.8945475076990468, disc_loss = 0.02014101674735901
Trained batch 168 in epoch 6, gen_loss = 0.8945818164292172, disc_loss = 0.020036944947288145
Trained batch 169 in epoch 6, gen_loss = 0.8948553413152694, disc_loss = 0.019934965567389395
Trained batch 170 in epoch 6, gen_loss = 0.8951203821346774, disc_loss = 0.019833564255876762
Trained batch 171 in epoch 6, gen_loss = 0.895005117148854, disc_loss = 0.019738557500775557
Trained batch 172 in epoch 6, gen_loss = 0.8950756676279741, disc_loss = 0.01965768186434716
Trained batch 173 in epoch 6, gen_loss = 0.8953265652231787, disc_loss = 0.019587026915684258
Trained batch 174 in epoch 6, gen_loss = 0.8952877192837851, disc_loss = 0.01948720599923815
Trained batch 175 in epoch 6, gen_loss = 0.8954639846289699, disc_loss = 0.019389365447833286
Trained batch 176 in epoch 6, gen_loss = 0.8955174534671051, disc_loss = 0.019293788133852057
Trained batch 177 in epoch 6, gen_loss = 0.8954462105973383, disc_loss = 0.019199907896108925
Trained batch 178 in epoch 6, gen_loss = 0.8953189142256476, disc_loss = 0.019106410356633907
Trained batch 179 in epoch 6, gen_loss = 0.8955595975120862, disc_loss = 0.01901588777416489
Trained batch 180 in epoch 6, gen_loss = 0.8955182964959856, disc_loss = 0.01892720836405102
Trained batch 181 in epoch 6, gen_loss = 0.8956496815432559, disc_loss = 0.01883444180302731
Trained batch 182 in epoch 6, gen_loss = 0.8956362271243757, disc_loss = 0.018742633501291683
Trained batch 183 in epoch 6, gen_loss = 0.8957018497521463, disc_loss = 0.018651400281511167
Trained batch 184 in epoch 6, gen_loss = 0.8957504299846856, disc_loss = 0.018567311562396386
Trained batch 185 in epoch 6, gen_loss = 0.8959753123983261, disc_loss = 0.018478234850561187
Trained batch 186 in epoch 6, gen_loss = 0.8959610269350164, disc_loss = 0.018403592978897976
Trained batch 187 in epoch 6, gen_loss = 0.8957494004292691, disc_loss = 0.018327149464699263
Trained batch 188 in epoch 6, gen_loss = 0.8956700978140352, disc_loss = 0.018242194221192408
Trained batch 189 in epoch 6, gen_loss = 0.8957713276147843, disc_loss = 0.018158812358926392
Trained batch 190 in epoch 6, gen_loss = 0.8962355095366533, disc_loss = 0.018093656681487776
Trained batch 191 in epoch 6, gen_loss = 0.8962441796126465, disc_loss = 0.018009833200873498
Trained batch 192 in epoch 6, gen_loss = 0.8963538406735257, disc_loss = 0.01793784597270924
Trained batch 193 in epoch 6, gen_loss = 0.8960948182442754, disc_loss = 0.017867829165776672
Trained batch 194 in epoch 6, gen_loss = 0.8963550942066388, disc_loss = 0.017797143294070013
Trained batch 195 in epoch 6, gen_loss = 0.8964986811791148, disc_loss = 0.01771577380120051
Trained batch 196 in epoch 6, gen_loss = 0.8966359464347665, disc_loss = 0.017640911728772454
Trained batch 197 in epoch 6, gen_loss = 0.8968250439925627, disc_loss = 0.017562125988817314
Trained batch 198 in epoch 6, gen_loss = 0.8971135081657812, disc_loss = 0.017485279709816764
Trained batch 199 in epoch 6, gen_loss = 0.8972397367656231, disc_loss = 0.017423973309923894
Trained batch 200 in epoch 6, gen_loss = 0.8971981158600518, disc_loss = 0.017349767750615617
Trained batch 201 in epoch 6, gen_loss = 0.8970575927212687, disc_loss = 0.017276069109609334
Trained batch 202 in epoch 6, gen_loss = 0.8968952305504841, disc_loss = 0.017223703887731093
Trained batch 203 in epoch 6, gen_loss = 0.8970148740153686, disc_loss = 0.017157740858451957
Trained batch 204 in epoch 6, gen_loss = 0.8970290819319283, disc_loss = 0.01708857764932895
Trained batch 205 in epoch 6, gen_loss = 0.8973432219433553, disc_loss = 0.017017491135262495
Trained batch 206 in epoch 6, gen_loss = 0.8973295341655252, disc_loss = 0.016947181650734357
Trained batch 207 in epoch 6, gen_loss = 0.8979953147757512, disc_loss = 0.01690988220966224
Trained batch 208 in epoch 6, gen_loss = 0.8979647272226343, disc_loss = 0.016845929462565155
Trained batch 209 in epoch 6, gen_loss = 0.8974350646847771, disc_loss = 0.016785707226621784
Trained batch 210 in epoch 6, gen_loss = 0.8971837757605512, disc_loss = 0.016788514312776025
Trained batch 211 in epoch 6, gen_loss = 0.8994418949169932, disc_loss = 0.016881954091280384
Trained batch 212 in epoch 6, gen_loss = 0.9011352167163097, disc_loss = 0.01689190940413309
Trained batch 213 in epoch 6, gen_loss = 0.9020849570771244, disc_loss = 0.016854320103890114
Trained batch 214 in epoch 6, gen_loss = 0.9031014490959256, disc_loss = 0.016886062425734517
Trained batch 215 in epoch 6, gen_loss = 0.904254107977505, disc_loss = 0.016855023542087077
Trained batch 216 in epoch 6, gen_loss = 0.9054368826376128, disc_loss = 0.01680614627320491
Trained batch 217 in epoch 6, gen_loss = 0.9062018928998107, disc_loss = 0.016746919236355247
Trained batch 218 in epoch 6, gen_loss = 0.9067238012677459, disc_loss = 0.01668712667872083
Trained batch 219 in epoch 6, gen_loss = 0.9072733081199906, disc_loss = 0.016625304692107337
Trained batch 220 in epoch 6, gen_loss = 0.9076486598042881, disc_loss = 0.016576358003908456
Trained batch 221 in epoch 6, gen_loss = 0.907906012894871, disc_loss = 0.016525081613180774
Trained batch 222 in epoch 6, gen_loss = 0.9079151689471685, disc_loss = 0.016470680980642447
Trained batch 223 in epoch 6, gen_loss = 0.907480144208031, disc_loss = 0.016463143125812558
Trained batch 224 in epoch 6, gen_loss = 0.908468118376202, disc_loss = 0.016476669690778687
Trained batch 225 in epoch 6, gen_loss = 0.9094418963763566, disc_loss = 0.01647169917535482
Trained batch 226 in epoch 6, gen_loss = 0.9099870380588565, disc_loss = 0.016442531751087223
Trained batch 227 in epoch 6, gen_loss = 0.9097925025904388, disc_loss = 0.016430830994004123
Trained batch 228 in epoch 6, gen_loss = 0.909616872863478, disc_loss = 0.016384171076448364
Trained batch 229 in epoch 6, gen_loss = 0.9092362122691195, disc_loss = 0.016353731904604027
Trained batch 230 in epoch 6, gen_loss = 0.9095497821574603, disc_loss = 0.016340247329699433
Trained batch 231 in epoch 6, gen_loss = 0.9094490924015127, disc_loss = 0.0163011034245097
Trained batch 232 in epoch 6, gen_loss = 0.9093393546573082, disc_loss = 0.016245996584024584
Trained batch 233 in epoch 6, gen_loss = 0.9083559213795214, disc_loss = 0.016386245111198537
Trained batch 234 in epoch 6, gen_loss = 0.9088366362642735, disc_loss = 0.016593881962484028
Trained batch 235 in epoch 6, gen_loss = 0.9086680984345533, disc_loss = 0.01657741075288899
Trained batch 236 in epoch 6, gen_loss = 0.9083605646332608, disc_loss = 0.01655479230994618
Trained batch 237 in epoch 6, gen_loss = 0.9088971212881953, disc_loss = 0.016529676892321182
Trained batch 238 in epoch 6, gen_loss = 0.9094620667491498, disc_loss = 0.01648933269038687
Trained batch 239 in epoch 6, gen_loss = 0.9097872116913398, disc_loss = 0.016436369195677494
Trained batch 240 in epoch 6, gen_loss = 0.9096297848026782, disc_loss = 0.016396476367886537
Trained batch 241 in epoch 6, gen_loss = 0.9091828348469143, disc_loss = 0.016381973287664078
Trained batch 242 in epoch 6, gen_loss = 0.9088536688575038, disc_loss = 0.01633840306890063
Trained batch 243 in epoch 6, gen_loss = 0.9089509479579378, disc_loss = 0.016506341572747888
Trained batch 244 in epoch 6, gen_loss = 0.9086847311379959, disc_loss = 0.01647502033809694
Trained batch 245 in epoch 6, gen_loss = 0.9085645851323275, disc_loss = 0.016433099220881646
Trained batch 246 in epoch 6, gen_loss = 0.9075351057023655, disc_loss = 0.01660955202273708
Trained batch 247 in epoch 6, gen_loss = 0.9086317954765212, disc_loss = 0.016692729753671184
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 1.0322363376617432, disc_loss = 0.03943919762969017
Trained batch 1 in epoch 7, gen_loss = 0.9843681454658508, disc_loss = 0.024258893448859453
Trained batch 2 in epoch 7, gen_loss = 0.9413878917694092, disc_loss = 0.018994299384454887
Trained batch 3 in epoch 7, gen_loss = 0.9319183826446533, disc_loss = 0.016353541752323508
Trained batch 4 in epoch 7, gen_loss = 0.9163279175758362, disc_loss = 0.014278724510222673
Trained batch 5 in epoch 7, gen_loss = 0.9078703820705414, disc_loss = 0.012875796606143316
Trained batch 6 in epoch 7, gen_loss = 0.8997796518462045, disc_loss = 0.0118286098752703
Trained batch 7 in epoch 7, gen_loss = 0.8950705379247665, disc_loss = 0.010660570143954828
Trained batch 8 in epoch 7, gen_loss = 0.8901264270146688, disc_loss = 0.00972630875185132
Trained batch 9 in epoch 7, gen_loss = 0.8849814414978028, disc_loss = 0.009002854488790036
Trained batch 10 in epoch 7, gen_loss = 0.88360811363567, disc_loss = 0.008468348024920984
Trained batch 11 in epoch 7, gen_loss = 0.8828691591819128, disc_loss = 0.007955831262127807
Trained batch 12 in epoch 7, gen_loss = 0.8822349493320172, disc_loss = 0.007661717460275843
Trained batch 13 in epoch 7, gen_loss = 0.8801159347806659, disc_loss = 0.0072856347375948515
Trained batch 14 in epoch 7, gen_loss = 0.8801501035690308, disc_loss = 0.0070806305389851335
Trained batch 15 in epoch 7, gen_loss = 0.8674233630299568, disc_loss = 0.009663985882070847
Trained batch 16 in epoch 7, gen_loss = 0.8838075960383696, disc_loss = 0.015524903052102993
Trained batch 17 in epoch 7, gen_loss = 0.885657850239012, disc_loss = 0.014943740964453254
Trained batch 18 in epoch 7, gen_loss = 0.8714071669076618, disc_loss = 0.01702119205392113
Trained batch 19 in epoch 7, gen_loss = 0.8710680902004242, disc_loss = 0.01653057454386726
Trained batch 20 in epoch 7, gen_loss = 0.8816725923901513, disc_loss = 0.019077447608911564
Trained batch 21 in epoch 7, gen_loss = 0.8785692561756481, disc_loss = 0.019204482235099105
Trained batch 22 in epoch 7, gen_loss = 0.8683179539182911, disc_loss = 0.021225948504212756
Trained batch 23 in epoch 7, gen_loss = 0.8689447914560636, disc_loss = 0.020815836391799774
Trained batch 24 in epoch 7, gen_loss = 0.8771280169486999, disc_loss = 0.0209342582244426
Trained batch 25 in epoch 7, gen_loss = 0.8849806258311639, disc_loss = 0.022278788114468064
Trained batch 26 in epoch 7, gen_loss = 0.8798836116437558, disc_loss = 0.022599421622645523
Trained batch 27 in epoch 7, gen_loss = 0.8709308483770916, disc_loss = 0.024563135753851384
Trained batch 28 in epoch 7, gen_loss = 0.876080913790341, disc_loss = 0.024265837092916
Trained batch 29 in epoch 7, gen_loss = 0.8801838596661885, disc_loss = 0.024346580270988245
Trained batch 30 in epoch 7, gen_loss = 0.8823868651543895, disc_loss = 0.023876513151692286
Trained batch 31 in epoch 7, gen_loss = 0.880675682798028, disc_loss = 0.02367622120800661
Trained batch 32 in epoch 7, gen_loss = 0.8754474809675505, disc_loss = 0.02416149679938275
Trained batch 33 in epoch 7, gen_loss = 0.8778056642588448, disc_loss = 0.024313677602228436
Trained batch 34 in epoch 7, gen_loss = 0.8796766553606306, disc_loss = 0.023811468355623738
Trained batch 35 in epoch 7, gen_loss = 0.8793435013956494, disc_loss = 0.023399698580356523
Trained batch 36 in epoch 7, gen_loss = 0.8737873886082623, disc_loss = 0.02414591673988144
Trained batch 37 in epoch 7, gen_loss = 0.8779430687427521, disc_loss = 0.024396798947188807
Trained batch 38 in epoch 7, gen_loss = 0.8779577949108222, disc_loss = 0.023904090932307717
Trained batch 39 in epoch 7, gen_loss = 0.8736329302191734, disc_loss = 0.02388037270284258
Trained batch 40 in epoch 7, gen_loss = 0.8772488439955363, disc_loss = 0.02366124679016449
Trained batch 41 in epoch 7, gen_loss = 0.8815608265854064, disc_loss = 0.02377660168401365
Trained batch 42 in epoch 7, gen_loss = 0.8822057870931403, disc_loss = 0.023347216414634223
Trained batch 43 in epoch 7, gen_loss = 0.8822346451607618, disc_loss = 0.02302823587722907
Trained batch 44 in epoch 7, gen_loss = 0.8798680557145013, disc_loss = 0.02275158704465462
Trained batch 45 in epoch 7, gen_loss = 0.8745810648669368, disc_loss = 0.02332133815482097
Trained batch 46 in epoch 7, gen_loss = 0.8767792519102705, disc_loss = 0.023396255086830006
Trained batch 47 in epoch 7, gen_loss = 0.8804862921436628, disc_loss = 0.023901756382353295
Trained batch 48 in epoch 7, gen_loss = 0.8787665768545501, disc_loss = 0.023607379619070158
Trained batch 49 in epoch 7, gen_loss = 0.8749143183231354, disc_loss = 0.023898202772252262
Trained batch 50 in epoch 7, gen_loss = 0.869228649373148, disc_loss = 0.025153278277310377
Trained batch 51 in epoch 7, gen_loss = 0.8738648559038455, disc_loss = 0.02604958342943484
Trained batch 52 in epoch 7, gen_loss = 0.8752509692929825, disc_loss = 0.02694022500413066
Trained batch 53 in epoch 7, gen_loss = 0.8688253771375727, disc_loss = 0.029250495545393614
Trained batch 54 in epoch 7, gen_loss = 0.8675410801714117, disc_loss = 0.0291195106734945
Trained batch 55 in epoch 7, gen_loss = 0.868879150067057, disc_loss = 0.03069528058819872
Trained batch 56 in epoch 7, gen_loss = 0.8639778076556691, disc_loss = 0.031932934330318845
Trained batch 57 in epoch 7, gen_loss = 0.8637028233758335, disc_loss = 0.032097070184857426
Trained batch 58 in epoch 7, gen_loss = 0.8631525928691283, disc_loss = 0.031864117321921355
Trained batch 59 in epoch 7, gen_loss = 0.8626533806324005, disc_loss = 0.03237256078282371
Trained batch 60 in epoch 7, gen_loss = 0.8630860750792456, disc_loss = 0.03205941065947418
Trained batch 61 in epoch 7, gen_loss = 0.8588795315834784, disc_loss = 0.03311830564897748
Trained batch 62 in epoch 7, gen_loss = 0.8609666105300661, disc_loss = 0.035374204299250055
Trained batch 63 in epoch 7, gen_loss = 0.8589471746236086, disc_loss = 0.03531729335009004
Trained batch 64 in epoch 7, gen_loss = 0.8563238116411063, disc_loss = 0.03557144917476063
Trained batch 65 in epoch 7, gen_loss = 0.8558042437741251, disc_loss = 0.03539544838889869
Trained batch 66 in epoch 7, gen_loss = 0.8578394686997827, disc_loss = 0.03553323028956665
Trained batch 67 in epoch 7, gen_loss = 0.8569887683672064, disc_loss = 0.03520620659144376
Trained batch 68 in epoch 7, gen_loss = 0.8550526853920757, disc_loss = 0.03514976422572373
Trained batch 69 in epoch 7, gen_loss = 0.8568237730434962, disc_loss = 0.034914506423021
Trained batch 70 in epoch 7, gen_loss = 0.8556845381226338, disc_loss = 0.03487726824003941
Trained batch 71 in epoch 7, gen_loss = 0.857085283431742, disc_loss = 0.034572815014851384
Trained batch 72 in epoch 7, gen_loss = 0.8592004245274687, disc_loss = 0.03426933588064594
Trained batch 73 in epoch 7, gen_loss = 0.8571967571168333, disc_loss = 0.034509788528462315
Trained batch 74 in epoch 7, gen_loss = 0.8576227482159933, disc_loss = 0.035360907648379604
Trained batch 75 in epoch 7, gen_loss = 0.8554550134821942, disc_loss = 0.03539410173145466
Trained batch 76 in epoch 7, gen_loss = 0.8557559352416497, disc_loss = 0.03521487468478645
Trained batch 77 in epoch 7, gen_loss = 0.8555590113004049, disc_loss = 0.034941796150703266
Trained batch 78 in epoch 7, gen_loss = 0.8572702249394187, disc_loss = 0.03471651950061227
Trained batch 79 in epoch 7, gen_loss = 0.8563908793032169, disc_loss = 0.03442885070980992
Trained batch 80 in epoch 7, gen_loss = 0.856448538509416, disc_loss = 0.03409508429180233
Trained batch 81 in epoch 7, gen_loss = 0.8571278721821017, disc_loss = 0.033737742072312026
Trained batch 82 in epoch 7, gen_loss = 0.858585648507957, disc_loss = 0.03341649189108915
Trained batch 83 in epoch 7, gen_loss = 0.8591474713314147, disc_loss = 0.033073572644276454
Trained batch 84 in epoch 7, gen_loss = 0.8604566041161033, disc_loss = 0.032752573788713886
Trained batch 85 in epoch 7, gen_loss = 0.8602980451528416, disc_loss = 0.032478540878591325
Trained batch 86 in epoch 7, gen_loss = 0.8600043955890612, disc_loss = 0.032186677864078306
Trained batch 87 in epoch 7, gen_loss = 0.8603028438308022, disc_loss = 0.031857883936027065
Trained batch 88 in epoch 7, gen_loss = 0.860867154062464, disc_loss = 0.03153353883215132
Trained batch 89 in epoch 7, gen_loss = 0.8602919982539283, disc_loss = 0.03130631090607494
Trained batch 90 in epoch 7, gen_loss = 0.8603683507049477, disc_loss = 0.031011383154091764
Trained batch 91 in epoch 7, gen_loss = 0.8595468959082728, disc_loss = 0.03077697660014762
Trained batch 92 in epoch 7, gen_loss = 0.861420419908339, disc_loss = 0.03073788615774804
Trained batch 93 in epoch 7, gen_loss = 0.8598262731065142, disc_loss = 0.030705500208336782
Trained batch 94 in epoch 7, gen_loss = 0.860051931832966, disc_loss = 0.030536922305136136
Trained batch 95 in epoch 7, gen_loss = 0.8638363194962343, disc_loss = 0.030800432357258007
Trained batch 96 in epoch 7, gen_loss = 0.8638796535963865, disc_loss = 0.030614541404275705
Trained batch 97 in epoch 7, gen_loss = 0.864431234038606, disc_loss = 0.030434421104455024
Trained batch 98 in epoch 7, gen_loss = 0.8641294776791274, disc_loss = 0.03024389143478163
Trained batch 99 in epoch 7, gen_loss = 0.863421186208725, disc_loss = 0.030094792733434586
Trained batch 100 in epoch 7, gen_loss = 0.8652156072087808, disc_loss = 0.030250695932859388
Trained batch 101 in epoch 7, gen_loss = 0.8654109636942545, disc_loss = 0.030004143470660875
Trained batch 102 in epoch 7, gen_loss = 0.8652313878235308, disc_loss = 0.029771312449615703
Trained batch 103 in epoch 7, gen_loss = 0.8631299911783292, disc_loss = 0.029962801833440047
Trained batch 104 in epoch 7, gen_loss = 0.8638780281657265, disc_loss = 0.029754458299084078
Trained batch 105 in epoch 7, gen_loss = 0.863847811829369, disc_loss = 0.02958677292862942
Trained batch 106 in epoch 7, gen_loss = 0.8642322465638134, disc_loss = 0.029424869718691595
Trained batch 107 in epoch 7, gen_loss = 0.8632282184229957, disc_loss = 0.02958113908189935
Trained batch 108 in epoch 7, gen_loss = 0.8631462411049309, disc_loss = 0.029469445221758355
Trained batch 109 in epoch 7, gen_loss = 0.8625417964024977, disc_loss = 0.029405444955707273
Trained batch 110 in epoch 7, gen_loss = 0.8633756991979238, disc_loss = 0.029202954392662055
Trained batch 111 in epoch 7, gen_loss = 0.864269203373364, disc_loss = 0.02900287648870809
Trained batch 112 in epoch 7, gen_loss = 0.8648878636613356, disc_loss = 0.028804129403727376
Trained batch 113 in epoch 7, gen_loss = 0.8658914482384398, disc_loss = 0.029373223323522036
Trained batch 114 in epoch 7, gen_loss = 0.8626729167026023, disc_loss = 0.030410333044584032
Trained batch 115 in epoch 7, gen_loss = 0.8602309160191437, disc_loss = 0.03144549090487497
Trained batch 116 in epoch 7, gen_loss = 0.8603354605854067, disc_loss = 0.034481252871979125
Trained batch 117 in epoch 7, gen_loss = 0.8581377192068909, disc_loss = 0.03553295451397929
Trained batch 118 in epoch 7, gen_loss = 0.8560968627448843, disc_loss = 0.036963422635977135
Trained batch 119 in epoch 7, gen_loss = 0.8569240232308706, disc_loss = 0.03844132361506733
Trained batch 120 in epoch 7, gen_loss = 0.8546778805984938, disc_loss = 0.039471342176399075
Trained batch 121 in epoch 7, gen_loss = 0.8539794639485782, disc_loss = 0.040677911802347685
Trained batch 122 in epoch 7, gen_loss = 0.8513714007245816, disc_loss = 0.041537533569096674
Trained batch 123 in epoch 7, gen_loss = 0.8509258964369374, disc_loss = 0.043052562904889666
Trained batch 124 in epoch 7, gen_loss = 0.8502816038131714, disc_loss = 0.0430350452978164
Trained batch 125 in epoch 7, gen_loss = 0.8485111575278025, disc_loss = 0.0436628385509793
Trained batch 126 in epoch 7, gen_loss = 0.8489674677060345, disc_loss = 0.043510599577007446
Trained batch 127 in epoch 7, gen_loss = 0.8493928457610309, disc_loss = 0.0443419778621319
Trained batch 128 in epoch 7, gen_loss = 0.8467530760654184, disc_loss = 0.04545368930115545
Trained batch 129 in epoch 7, gen_loss = 0.8450801757665781, disc_loss = 0.04584161685242389
Trained batch 130 in epoch 7, gen_loss = 0.8455547431043087, disc_loss = 0.046358083042437
Trained batch 131 in epoch 7, gen_loss = 0.843596364512588, disc_loss = 0.04677952713311904
Trained batch 132 in epoch 7, gen_loss = 0.8439551430537289, disc_loss = 0.04671368047882123
Trained batch 133 in epoch 7, gen_loss = 0.8442403273795968, disc_loss = 0.046632428502372064
Trained batch 134 in epoch 7, gen_loss = 0.8423886254981712, disc_loss = 0.04685151317777733
Trained batch 135 in epoch 7, gen_loss = 0.8424117459970362, disc_loss = 0.046685469694613645
Trained batch 136 in epoch 7, gen_loss = 0.8417296983899861, disc_loss = 0.04648787905054208
Trained batch 137 in epoch 7, gen_loss = 0.8419528283934662, disc_loss = 0.046454707094792116
Trained batch 138 in epoch 7, gen_loss = 0.8412971436548576, disc_loss = 0.04631165907008024
Trained batch 139 in epoch 7, gen_loss = 0.840004215495927, disc_loss = 0.04652721125000556
Trained batch 140 in epoch 7, gen_loss = 0.8422845251171301, disc_loss = 0.04670363325288797
Trained batch 141 in epoch 7, gen_loss = 0.8429682300963872, disc_loss = 0.046437323790266584
Trained batch 142 in epoch 7, gen_loss = 0.8427516042769372, disc_loss = 0.04618067457340658
Trained batch 143 in epoch 7, gen_loss = 0.843087031195561, disc_loss = 0.04594954373735365
Trained batch 144 in epoch 7, gen_loss = 0.8423662896814017, disc_loss = 0.045790075242583606
Trained batch 145 in epoch 7, gen_loss = 0.8422111562670094, disc_loss = 0.04552540535662221
Trained batch 146 in epoch 7, gen_loss = 0.8422487248368815, disc_loss = 0.04531654870600066
Trained batch 147 in epoch 7, gen_loss = 0.8423809413168881, disc_loss = 0.04508820664282334
Trained batch 148 in epoch 7, gen_loss = 0.841578205959909, disc_loss = 0.044986801982963544
Trained batch 149 in epoch 7, gen_loss = 0.8430841064453125, disc_loss = 0.04521935718599707
Trained batch 150 in epoch 7, gen_loss = 0.8430966501993848, disc_loss = 0.04499418681197559
Trained batch 151 in epoch 7, gen_loss = 0.8410402646190241, disc_loss = 0.04555575876024944
Trained batch 152 in epoch 7, gen_loss = 0.8404499720903783, disc_loss = 0.04564671605989775
Trained batch 153 in epoch 7, gen_loss = 0.8408008492612219, disc_loss = 0.04548633056723017
Trained batch 154 in epoch 7, gen_loss = 0.8407141177884994, disc_loss = 0.0452808182671546
Trained batch 155 in epoch 7, gen_loss = 0.8391787455632136, disc_loss = 0.0456142218840213
Trained batch 156 in epoch 7, gen_loss = 0.8405539670567603, disc_loss = 0.04775616693737543
Trained batch 157 in epoch 7, gen_loss = 0.8396988431864147, disc_loss = 0.04773790156910832
Trained batch 158 in epoch 7, gen_loss = 0.8388684478195958, disc_loss = 0.04766146586651463
Trained batch 159 in epoch 7, gen_loss = 0.8388502910733223, disc_loss = 0.048209644491726066
Trained batch 160 in epoch 7, gen_loss = 0.8376377798755716, disc_loss = 0.04834656783969645
Trained batch 161 in epoch 7, gen_loss = 0.8365858443725256, disc_loss = 0.04845770201099646
Trained batch 162 in epoch 7, gen_loss = 0.8371364181758436, disc_loss = 0.0482642947356188
Trained batch 163 in epoch 7, gen_loss = 0.8368083365806719, disc_loss = 0.048242511691968526
Trained batch 164 in epoch 7, gen_loss = 0.8363502657774723, disc_loss = 0.04839788996896735
Trained batch 165 in epoch 7, gen_loss = 0.8357867095843855, disc_loss = 0.048330299610956515
Trained batch 166 in epoch 7, gen_loss = 0.8349390518879463, disc_loss = 0.04847785367485426
Trained batch 167 in epoch 7, gen_loss = 0.8344291423757871, disc_loss = 0.04830212264537944
Trained batch 168 in epoch 7, gen_loss = 0.83546473041794, disc_loss = 0.04820968848708246
Trained batch 169 in epoch 7, gen_loss = 0.835865403624142, disc_loss = 0.04807420222718707
Trained batch 170 in epoch 7, gen_loss = 0.8357282120581956, disc_loss = 0.04783398424253434
Trained batch 171 in epoch 7, gen_loss = 0.8344631503487743, disc_loss = 0.047950352708603323
Trained batch 172 in epoch 7, gen_loss = 0.8345517354204476, disc_loss = 0.047756065990011386
Trained batch 173 in epoch 7, gen_loss = 0.8356470273829054, disc_loss = 0.04784825542037129
Trained batch 174 in epoch 7, gen_loss = 0.8346766591072082, disc_loss = 0.047850729135264246
Trained batch 175 in epoch 7, gen_loss = 0.8342286995188757, disc_loss = 0.04770834027890074
Trained batch 176 in epoch 7, gen_loss = 0.8349655678043257, disc_loss = 0.047575477398879365
Trained batch 177 in epoch 7, gen_loss = 0.8352482071083583, disc_loss = 0.04734548315630828
Trained batch 178 in epoch 7, gen_loss = 0.8345368730955284, disc_loss = 0.04727856315771253
Trained batch 179 in epoch 7, gen_loss = 0.834423377778795, disc_loss = 0.047081087388667384
Trained batch 180 in epoch 7, gen_loss = 0.8350839107734722, disc_loss = 0.04731362270196457
Trained batch 181 in epoch 7, gen_loss = 0.8350378946288601, disc_loss = 0.04715269977344548
Trained batch 182 in epoch 7, gen_loss = 0.834454927288118, disc_loss = 0.04710951383744717
Trained batch 183 in epoch 7, gen_loss = 0.8345437639433405, disc_loss = 0.04700884243610072
Trained batch 184 in epoch 7, gen_loss = 0.834837345174841, disc_loss = 0.046941067664758175
Trained batch 185 in epoch 7, gen_loss = 0.8351478605501114, disc_loss = 0.046729405962621734
Trained batch 186 in epoch 7, gen_loss = 0.8346801349186005, disc_loss = 0.04662343823938645
Trained batch 187 in epoch 7, gen_loss = 0.8355403976871613, disc_loss = 0.04662640317605729
Trained batch 188 in epoch 7, gen_loss = 0.8347316072100684, disc_loss = 0.046616872665398414
Trained batch 189 in epoch 7, gen_loss = 0.833477971428319, disc_loss = 0.04700606053719591
Trained batch 190 in epoch 7, gen_loss = 0.8353715161378471, disc_loss = 0.04756608297341352
Trained batch 191 in epoch 7, gen_loss = 0.8368963319808245, disc_loss = 0.047761752232569656
Trained batch 192 in epoch 7, gen_loss = 0.8362625136276601, disc_loss = 0.04767056455271116
Trained batch 193 in epoch 7, gen_loss = 0.8353797341744924, disc_loss = 0.0476828924267428
Trained batch 194 in epoch 7, gen_loss = 0.834657729894687, disc_loss = 0.047640271323661394
Trained batch 195 in epoch 7, gen_loss = 0.8353040495089122, disc_loss = 0.047497569594047585
Trained batch 196 in epoch 7, gen_loss = 0.8363385300345832, disc_loss = 0.047349692167487314
Trained batch 197 in epoch 7, gen_loss = 0.8356738391548696, disc_loss = 0.04731790512692033
Trained batch 198 in epoch 7, gen_loss = 0.8357045707391135, disc_loss = 0.047167337177808036
Trained batch 199 in epoch 7, gen_loss = 0.836030381321907, disc_loss = 0.04696463659289293
Trained batch 200 in epoch 7, gen_loss = 0.8375042499001346, disc_loss = 0.046881527708268804
Trained batch 201 in epoch 7, gen_loss = 0.8380166761355825, disc_loss = 0.046860078514535164
Trained batch 202 in epoch 7, gen_loss = 0.836279556375419, disc_loss = 0.047458261287005005
Trained batch 203 in epoch 7, gen_loss = 0.8363471238636503, disc_loss = 0.04727829001072392
Trained batch 204 in epoch 7, gen_loss = 0.8367468674008439, disc_loss = 0.047185562722521224
Trained batch 205 in epoch 7, gen_loss = 0.8378607130166397, disc_loss = 0.047104217752913756
Trained batch 206 in epoch 7, gen_loss = 0.8376095093390792, disc_loss = 0.046962108884843576
Trained batch 207 in epoch 7, gen_loss = 0.8372868669147675, disc_loss = 0.04680567844032059
Trained batch 208 in epoch 7, gen_loss = 0.8376591604862487, disc_loss = 0.046607516484299415
Trained batch 209 in epoch 7, gen_loss = 0.836960924807049, disc_loss = 0.04657531376329384
Trained batch 210 in epoch 7, gen_loss = 0.8375926161829329, disc_loss = 0.04655381381374859
Trained batch 211 in epoch 7, gen_loss = 0.838188074388594, disc_loss = 0.04645108941279106
Trained batch 212 in epoch 7, gen_loss = 0.8370114959461589, disc_loss = 0.046591526606806634
Trained batch 213 in epoch 7, gen_loss = 0.83799962991866, disc_loss = 0.046785042456908274
Trained batch 214 in epoch 7, gen_loss = 0.8377972699875056, disc_loss = 0.04664523281092041
Trained batch 215 in epoch 7, gen_loss = 0.8365338003193891, disc_loss = 0.04673204386576631
Trained batch 216 in epoch 7, gen_loss = 0.8370322700469724, disc_loss = 0.046560792751344185
Trained batch 217 in epoch 7, gen_loss = 0.8375327300041093, disc_loss = 0.046390901013157855
Trained batch 218 in epoch 7, gen_loss = 0.8380483446055895, disc_loss = 0.04621786199463319
Trained batch 219 in epoch 7, gen_loss = 0.8377048766071146, disc_loss = 0.046090990140907125
Trained batch 220 in epoch 7, gen_loss = 0.8378965377268208, disc_loss = 0.04590822753445899
Trained batch 221 in epoch 7, gen_loss = 0.8375125197139947, disc_loss = 0.04582071357704531
Trained batch 222 in epoch 7, gen_loss = 0.837783578799979, disc_loss = 0.045640574802640374
Trained batch 223 in epoch 7, gen_loss = 0.8384059460035392, disc_loss = 0.04553346521424828
Trained batch 224 in epoch 7, gen_loss = 0.8383713563283285, disc_loss = 0.04545546308263308
Trained batch 225 in epoch 7, gen_loss = 0.8377151787281036, disc_loss = 0.04552602042769601
Trained batch 226 in epoch 7, gen_loss = 0.838122175916176, disc_loss = 0.04535341708888074
Trained batch 227 in epoch 7, gen_loss = 0.8386886870129067, disc_loss = 0.04524248488463886
Trained batch 228 in epoch 7, gen_loss = 0.8384766815531202, disc_loss = 0.04511601300239075
Trained batch 229 in epoch 7, gen_loss = 0.8386085476564324, disc_loss = 0.044971040264784316
Trained batch 230 in epoch 7, gen_loss = 0.8397924737496809, disc_loss = 0.04500109575047799
Trained batch 231 in epoch 7, gen_loss = 0.8397133283574005, disc_loss = 0.04487195527602533
Trained batch 232 in epoch 7, gen_loss = 0.8392026439756795, disc_loss = 0.04480623084624086
Trained batch 233 in epoch 7, gen_loss = 0.8395520491987212, disc_loss = 0.04466493398400867
Trained batch 234 in epoch 7, gen_loss = 0.8401166083964896, disc_loss = 0.04450865541782943
Trained batch 235 in epoch 7, gen_loss = 0.8407780939744691, disc_loss = 0.044383421300523675
Trained batch 236 in epoch 7, gen_loss = 0.8409612246706516, disc_loss = 0.04421881303085085
Trained batch 237 in epoch 7, gen_loss = 0.8407887548458677, disc_loss = 0.04406274502662582
Trained batch 238 in epoch 7, gen_loss = 0.841095951062366, disc_loss = 0.04391234707589959
Trained batch 239 in epoch 7, gen_loss = 0.8413049983481566, disc_loss = 0.0437463413894875
Trained batch 240 in epoch 7, gen_loss = 0.841551687954867, disc_loss = 0.04359025448750071
Trained batch 241 in epoch 7, gen_loss = 0.8420305313650241, disc_loss = 0.04345200200130286
Trained batch 242 in epoch 7, gen_loss = 0.8421054148870241, disc_loss = 0.043287554737602055
Trained batch 243 in epoch 7, gen_loss = 0.8422009011761087, disc_loss = 0.04313387236363239
Trained batch 244 in epoch 7, gen_loss = 0.8423796721867153, disc_loss = 0.042971079183590354
Trained batch 245 in epoch 7, gen_loss = 0.8426713172982379, disc_loss = 0.04282198726990813
Trained batch 246 in epoch 7, gen_loss = 0.8431715236501656, disc_loss = 0.04268433780952353
Trained batch 247 in epoch 7, gen_loss = 0.8435006406038038, disc_loss = 0.04252745860797023
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.8397969603538513, disc_loss = 0.0043806592002511024
Trained batch 1 in epoch 8, gen_loss = 0.873363584280014, disc_loss = 0.004021211760118604
Trained batch 2 in epoch 8, gen_loss = 0.8802757263183594, disc_loss = 0.004007513790080945
Trained batch 3 in epoch 8, gen_loss = 0.8783860206604004, disc_loss = 0.004280049935914576
Trained batch 4 in epoch 8, gen_loss = 0.8852925658226013, disc_loss = 0.004044334776699543
Trained batch 5 in epoch 8, gen_loss = 0.8885637025038401, disc_loss = 0.003968784934841096
Trained batch 6 in epoch 8, gen_loss = 0.8865259630339486, disc_loss = 0.003926550370774099
Trained batch 7 in epoch 8, gen_loss = 0.8931005671620369, disc_loss = 0.003914498083759099
Trained batch 8 in epoch 8, gen_loss = 0.8938496377733018, disc_loss = 0.003989508323785331
Trained batch 9 in epoch 8, gen_loss = 0.8937825977802276, disc_loss = 0.003867017338052392
Trained batch 10 in epoch 8, gen_loss = 0.8911522247574546, disc_loss = 0.0038223380476913667
Trained batch 11 in epoch 8, gen_loss = 0.8943332185347875, disc_loss = 0.003803348906027774
Trained batch 12 in epoch 8, gen_loss = 0.895089525442857, disc_loss = 0.003802815219387412
Trained batch 13 in epoch 8, gen_loss = 0.8979079297610691, disc_loss = 0.003728946521213012
Trained batch 14 in epoch 8, gen_loss = 0.8924346963564554, disc_loss = 0.003823464938128988
Trained batch 15 in epoch 8, gen_loss = 0.8964589312672615, disc_loss = 0.0038416026363847777
Trained batch 16 in epoch 8, gen_loss = 0.902927980703466, disc_loss = 0.0040518834173460215
Trained batch 17 in epoch 8, gen_loss = 0.9033679200543298, disc_loss = 0.0040210736398067735
Trained batch 18 in epoch 8, gen_loss = 0.9018230532345018, disc_loss = 0.004118235683754871
Trained batch 19 in epoch 8, gen_loss = 0.9006167858839035, disc_loss = 0.004409110080450774
Trained batch 20 in epoch 8, gen_loss = 0.9015858939715794, disc_loss = 0.004335549704375721
Trained batch 21 in epoch 8, gen_loss = 0.9101606905460358, disc_loss = 0.004490538817745718
Trained batch 22 in epoch 8, gen_loss = 0.9123238765675089, disc_loss = 0.004463454799564636
Trained batch 23 in epoch 8, gen_loss = 0.9120324825247129, disc_loss = 0.00443175063507321
Trained batch 24 in epoch 8, gen_loss = 0.9120564579963684, disc_loss = 0.004565260233357548
Trained batch 25 in epoch 8, gen_loss = 0.9085649595810816, disc_loss = 0.004682390780474704
Trained batch 26 in epoch 8, gen_loss = 0.9084277086787753, disc_loss = 0.004627419126875422
Trained batch 27 in epoch 8, gen_loss = 0.9077828292335782, disc_loss = 0.004543355849039342
Trained batch 28 in epoch 8, gen_loss = 0.90699885836963, disc_loss = 0.004478568018510424
Trained batch 29 in epoch 8, gen_loss = 0.909008099635442, disc_loss = 0.0045107455303271616
Trained batch 30 in epoch 8, gen_loss = 0.9078986683199483, disc_loss = 0.004501494428803844
Trained batch 31 in epoch 8, gen_loss = 0.9101412333548069, disc_loss = 0.004533385566901416
Trained batch 32 in epoch 8, gen_loss = 0.9098714499762564, disc_loss = 0.004559840781219078
Trained batch 33 in epoch 8, gen_loss = 0.9087683330563938, disc_loss = 0.004571058979148374
Trained batch 34 in epoch 8, gen_loss = 0.9101905005318778, disc_loss = 0.0047880012542009355
Trained batch 35 in epoch 8, gen_loss = 0.9101936204565896, disc_loss = 0.004761869812177287
Trained batch 36 in epoch 8, gen_loss = 0.9098801371213552, disc_loss = 0.00515078692822843
Trained batch 37 in epoch 8, gen_loss = 0.9118417548505884, disc_loss = 0.005167254357059535
Trained batch 38 in epoch 8, gen_loss = 0.9094975346173996, disc_loss = 0.005318303485042774
Trained batch 39 in epoch 8, gen_loss = 0.9095811933279038, disc_loss = 0.005324181111063808
Trained batch 40 in epoch 8, gen_loss = 0.9103984222179506, disc_loss = 0.0052911728143510296
Trained batch 41 in epoch 8, gen_loss = 0.9120141665140787, disc_loss = 0.0053999759589454955
Trained batch 42 in epoch 8, gen_loss = 0.9124985503595929, disc_loss = 0.0053898893448329245
Trained batch 43 in epoch 8, gen_loss = 0.9125239781358025, disc_loss = 0.005373711983503943
Trained batch 44 in epoch 8, gen_loss = 0.9132582770453559, disc_loss = 0.005326014953768916
Trained batch 45 in epoch 8, gen_loss = 0.9150374220765155, disc_loss = 0.0053277254691752405
Trained batch 46 in epoch 8, gen_loss = 0.916921336600121, disc_loss = 0.005336684680127717
Trained batch 47 in epoch 8, gen_loss = 0.9169931846360365, disc_loss = 0.005326903376650686
Trained batch 48 in epoch 8, gen_loss = 0.918584330957763, disc_loss = 0.0052978862267063585
Trained batch 49 in epoch 8, gen_loss = 0.9188232147693634, disc_loss = 0.0052584974374622106
Trained batch 50 in epoch 8, gen_loss = 0.9181486566861471, disc_loss = 0.0052164025906035125
Trained batch 51 in epoch 8, gen_loss = 0.9181246872131641, disc_loss = 0.005183242140516926
Trained batch 52 in epoch 8, gen_loss = 0.9189222758671023, disc_loss = 0.005176026448783166
Trained batch 53 in epoch 8, gen_loss = 0.9210176512047097, disc_loss = 0.005184246093483159
Trained batch 54 in epoch 8, gen_loss = 0.9226980816234241, disc_loss = 0.005293901641429825
Trained batch 55 in epoch 8, gen_loss = 0.9247889327151435, disc_loss = 0.005303069504277248
Trained batch 56 in epoch 8, gen_loss = 0.9256039816036559, disc_loss = 0.005262978795687096
Trained batch 57 in epoch 8, gen_loss = 0.9253912896945559, disc_loss = 0.005223498270236726
Trained batch 58 in epoch 8, gen_loss = 0.9244566084974903, disc_loss = 0.005213706114850307
Trained batch 59 in epoch 8, gen_loss = 0.9252833982308706, disc_loss = 0.005200497798311213
Trained batch 60 in epoch 8, gen_loss = 0.9252333015692039, disc_loss = 0.005183409930008357
Trained batch 61 in epoch 8, gen_loss = 0.9243631295619472, disc_loss = 0.005139592479193403
Trained batch 62 in epoch 8, gen_loss = 0.9249844617313809, disc_loss = 0.00511967669433308
Trained batch 63 in epoch 8, gen_loss = 0.9246129179373384, disc_loss = 0.005085293123556767
Trained batch 64 in epoch 8, gen_loss = 0.9237732685529269, disc_loss = 0.005047334422572301
Trained batch 65 in epoch 8, gen_loss = 0.9233363514596765, disc_loss = 0.00504730299651397
Trained batch 66 in epoch 8, gen_loss = 0.9232269498839307, disc_loss = 0.005043991125508475
Trained batch 67 in epoch 8, gen_loss = 0.9238822688074673, disc_loss = 0.005027512314400691
Trained batch 68 in epoch 8, gen_loss = 0.9242663331653761, disc_loss = 0.0049855786078758
Trained batch 69 in epoch 8, gen_loss = 0.9246702364512852, disc_loss = 0.004959448603247958
Trained batch 70 in epoch 8, gen_loss = 0.9246876609157508, disc_loss = 0.004928753445659515
Trained batch 71 in epoch 8, gen_loss = 0.9244857281446457, disc_loss = 0.004922094311849732
Trained batch 72 in epoch 8, gen_loss = 0.9247775477905796, disc_loss = 0.0048959396671095536
Trained batch 73 in epoch 8, gen_loss = 0.9251272976398468, disc_loss = 0.004864021025069461
Trained batch 74 in epoch 8, gen_loss = 0.9257279165585836, disc_loss = 0.004830122279624144
Trained batch 75 in epoch 8, gen_loss = 0.9255463386836805, disc_loss = 0.00482314746018107
Trained batch 76 in epoch 8, gen_loss = 0.9259949891598194, disc_loss = 0.004805764927250611
Trained batch 77 in epoch 8, gen_loss = 0.9253639578819275, disc_loss = 0.00482267204624338
Trained batch 78 in epoch 8, gen_loss = 0.9252527265609065, disc_loss = 0.004798788135234691
Trained batch 79 in epoch 8, gen_loss = 0.9267174504697323, disc_loss = 0.004825416865060106
Trained batch 80 in epoch 8, gen_loss = 0.9265098917631456, disc_loss = 0.004835824953553117
Trained batch 81 in epoch 8, gen_loss = 0.9265986855437116, disc_loss = 0.004823272502640399
Trained batch 82 in epoch 8, gen_loss = 0.9266083139971079, disc_loss = 0.004795930381998958
Trained batch 83 in epoch 8, gen_loss = 0.9269019819441295, disc_loss = 0.004770399462099054
Trained batch 84 in epoch 8, gen_loss = 0.9268684723797966, disc_loss = 0.004750208104686702
Trained batch 85 in epoch 8, gen_loss = 0.9268316127533136, disc_loss = 0.00475503031305189
Trained batch 86 in epoch 8, gen_loss = 0.9275437709928929, disc_loss = 0.004758144228387324
Trained batch 87 in epoch 8, gen_loss = 0.927465602078221, disc_loss = 0.004746843722056259
Trained batch 88 in epoch 8, gen_loss = 0.9274762748332506, disc_loss = 0.004751880046273215
Trained batch 89 in epoch 8, gen_loss = 0.9273083488146464, disc_loss = 0.00472494104049272
Trained batch 90 in epoch 8, gen_loss = 0.9277116695603171, disc_loss = 0.004710910724128013
Trained batch 91 in epoch 8, gen_loss = 0.9274247774611348, disc_loss = 0.004691559780874978
Trained batch 92 in epoch 8, gen_loss = 0.9270782938567541, disc_loss = 0.004674530430366436
Trained batch 93 in epoch 8, gen_loss = 0.9270709226740167, disc_loss = 0.004648250589602964
Trained batch 94 in epoch 8, gen_loss = 0.9267893502586766, disc_loss = 0.004622461511998585
Trained batch 95 in epoch 8, gen_loss = 0.926505325982968, disc_loss = 0.004596417958964594
Trained batch 96 in epoch 8, gen_loss = 0.926347003155148, disc_loss = 0.004571684842602801
Trained batch 97 in epoch 8, gen_loss = 0.9264311042367196, disc_loss = 0.004553468565323523
Trained batch 98 in epoch 8, gen_loss = 0.9265095699917186, disc_loss = 0.004534001269311917
Trained batch 99 in epoch 8, gen_loss = 0.9264672386646271, disc_loss = 0.004511877559125423
Trained batch 100 in epoch 8, gen_loss = 0.9266084432601929, disc_loss = 0.004489474835353766
Trained batch 101 in epoch 8, gen_loss = 0.92660178974563, disc_loss = 0.004470981394999898
Trained batch 102 in epoch 8, gen_loss = 0.9265297946420689, disc_loss = 0.004450391964462486
Trained batch 103 in epoch 8, gen_loss = 0.926666867847626, disc_loss = 0.004429063267217806
Trained batch 104 in epoch 8, gen_loss = 0.9267191165969485, disc_loss = 0.004404966073066351
Trained batch 105 in epoch 8, gen_loss = 0.9268179327811835, disc_loss = 0.0044153738681244545
Trained batch 106 in epoch 8, gen_loss = 0.9265455664875352, disc_loss = 0.0043952831743876925
Trained batch 107 in epoch 8, gen_loss = 0.9258930594832809, disc_loss = 0.004376528542100762
Trained batch 108 in epoch 8, gen_loss = 0.9261252486377681, disc_loss = 0.004371291332997792
Trained batch 109 in epoch 8, gen_loss = 0.9267962108958852, disc_loss = 0.004360288651448421
Trained batch 110 in epoch 8, gen_loss = 0.9268593036376678, disc_loss = 0.00434784900904675
Trained batch 111 in epoch 8, gen_loss = 0.926554127995457, disc_loss = 0.00433229321060935
Trained batch 112 in epoch 8, gen_loss = 0.9263220429420471, disc_loss = 0.004318164468874776
Trained batch 113 in epoch 8, gen_loss = 0.9265533293548384, disc_loss = 0.00430737174700194
Trained batch 114 in epoch 8, gen_loss = 0.9263409345046334, disc_loss = 0.0042890816633387105
Trained batch 115 in epoch 8, gen_loss = 0.9259284411011071, disc_loss = 0.004272760276417729
Trained batch 116 in epoch 8, gen_loss = 0.9259900695238358, disc_loss = 0.0042585073005105565
Trained batch 117 in epoch 8, gen_loss = 0.9258514188103757, disc_loss = 0.004246543207939841
Trained batch 118 in epoch 8, gen_loss = 0.9257302189073643, disc_loss = 0.004229199222461203
Trained batch 119 in epoch 8, gen_loss = 0.9257056847214699, disc_loss = 0.004214788512520802
Trained batch 120 in epoch 8, gen_loss = 0.9254737117073752, disc_loss = 0.004197347352150366
Trained batch 121 in epoch 8, gen_loss = 0.9249625806925726, disc_loss = 0.004187043617884094
Trained batch 122 in epoch 8, gen_loss = 0.9246657195130015, disc_loss = 0.0041673077664118475
Trained batch 123 in epoch 8, gen_loss = 0.9245883567679313, disc_loss = 0.004154915399398775
Trained batch 124 in epoch 8, gen_loss = 0.9246230111122131, disc_loss = 0.004138152055442333
Trained batch 125 in epoch 8, gen_loss = 0.9248031401444995, disc_loss = 0.004129265447975033
Trained batch 126 in epoch 8, gen_loss = 0.9248180671001044, disc_loss = 0.004123249408370984
Trained batch 127 in epoch 8, gen_loss = 0.924653431866318, disc_loss = 0.004106598838916398
Trained batch 128 in epoch 8, gen_loss = 0.9246583950611972, disc_loss = 0.004095517811834697
Trained batch 129 in epoch 8, gen_loss = 0.9242801858828618, disc_loss = 0.004075493507731992
Trained batch 130 in epoch 8, gen_loss = 0.9239874063557341, disc_loss = 0.004066150258686251
Trained batch 131 in epoch 8, gen_loss = 0.9237766180074576, disc_loss = 0.004050095221662725
Trained batch 132 in epoch 8, gen_loss = 0.9235071853587502, disc_loss = 0.00404404327308381
Trained batch 133 in epoch 8, gen_loss = 0.9237844005449495, disc_loss = 0.004028867619153835
Trained batch 134 in epoch 8, gen_loss = 0.9241718097969338, disc_loss = 0.004018323276950805
Trained batch 135 in epoch 8, gen_loss = 0.9242904479889309, disc_loss = 0.004003147601478678
Trained batch 136 in epoch 8, gen_loss = 0.9243850882035972, disc_loss = 0.004030415506176922
Trained batch 137 in epoch 8, gen_loss = 0.9240546438141145, disc_loss = 0.004025537635375193
Trained batch 138 in epoch 8, gen_loss = 0.9238302274573621, disc_loss = 0.0040178217375718
Trained batch 139 in epoch 8, gen_loss = 0.9235780732972282, disc_loss = 0.004000060867318618
Trained batch 140 in epoch 8, gen_loss = 0.9239838537594951, disc_loss = 0.003990687633012521
Trained batch 141 in epoch 8, gen_loss = 0.9239798473640227, disc_loss = 0.003994497639441889
Trained batch 142 in epoch 8, gen_loss = 0.9237314070854987, disc_loss = 0.003979912427436378
Trained batch 143 in epoch 8, gen_loss = 0.923954662349489, disc_loss = 0.003969948408161549
Trained batch 144 in epoch 8, gen_loss = 0.9239092596646012, disc_loss = 0.003969525227098373
Trained batch 145 in epoch 8, gen_loss = 0.9238201224640624, disc_loss = 0.003957529114527398
Trained batch 146 in epoch 8, gen_loss = 0.9237336439340293, disc_loss = 0.003946896383481823
Trained batch 147 in epoch 8, gen_loss = 0.923544504352518, disc_loss = 0.0039476285998495545
Trained batch 148 in epoch 8, gen_loss = 0.9236694134321789, disc_loss = 0.003938513239939391
Trained batch 149 in epoch 8, gen_loss = 0.92355299949646, disc_loss = 0.003924065029714256
Trained batch 150 in epoch 8, gen_loss = 0.9235125977471964, disc_loss = 0.003911870315097371
Trained batch 151 in epoch 8, gen_loss = 0.9235395526415423, disc_loss = 0.003915653106799398
Trained batch 152 in epoch 8, gen_loss = 0.92405496586382, disc_loss = 0.00390940472206673
Trained batch 153 in epoch 8, gen_loss = 0.9240301057889864, disc_loss = 0.003904301760107424
Trained batch 154 in epoch 8, gen_loss = 0.9240146694644805, disc_loss = 0.0038956296427415742
Trained batch 155 in epoch 8, gen_loss = 0.9238641006060135, disc_loss = 0.003909460544281711
Trained batch 156 in epoch 8, gen_loss = 0.9237029989054248, disc_loss = 0.0038994027599751663
Trained batch 157 in epoch 8, gen_loss = 0.9237524991548514, disc_loss = 0.003894993048780185
Trained batch 158 in epoch 8, gen_loss = 0.9238790708517878, disc_loss = 0.0038891151311672614
Trained batch 159 in epoch 8, gen_loss = 0.9239146132022142, disc_loss = 0.003894144019432133
Trained batch 160 in epoch 8, gen_loss = 0.9236618050877352, disc_loss = 0.003881790175576989
Trained batch 161 in epoch 8, gen_loss = 0.9245715030917415, disc_loss = 0.003931669751900811
Trained batch 162 in epoch 8, gen_loss = 0.9243164552501374, disc_loss = 0.003940289723686874
Trained batch 163 in epoch 8, gen_loss = 0.9241685718297958, disc_loss = 0.003939212580273927
Trained batch 164 in epoch 8, gen_loss = 0.923970390811111, disc_loss = 0.003932537024868935
Trained batch 165 in epoch 8, gen_loss = 0.9237032051546028, disc_loss = 0.003940277530233858
Trained batch 166 in epoch 8, gen_loss = 0.9237358284567645, disc_loss = 0.003934539909597241
Trained batch 167 in epoch 8, gen_loss = 0.9261735330025355, disc_loss = 0.004218042328526887
Trained batch 168 in epoch 8, gen_loss = 0.9262250534881501, disc_loss = 0.004262298587351465
Trained batch 169 in epoch 8, gen_loss = 0.9262682739426108, disc_loss = 0.004276032819111339
Trained batch 170 in epoch 8, gen_loss = 0.9261050255675065, disc_loss = 0.004279369463169217
Trained batch 171 in epoch 8, gen_loss = 0.9256225089694179, disc_loss = 0.004290877580832213
Trained batch 172 in epoch 8, gen_loss = 0.9247565624341799, disc_loss = 0.004295882237994386
Trained batch 173 in epoch 8, gen_loss = 0.9241194139266836, disc_loss = 0.004309327493491315
Trained batch 174 in epoch 8, gen_loss = 0.9235570464815412, disc_loss = 0.0043183513883767385
Trained batch 175 in epoch 8, gen_loss = 0.9243219650604508, disc_loss = 0.004364483026041522
Trained batch 176 in epoch 8, gen_loss = 0.9247940118703465, disc_loss = 0.004370889733650717
Trained batch 177 in epoch 8, gen_loss = 0.9251336026727484, disc_loss = 0.004377521712495161
Trained batch 178 in epoch 8, gen_loss = 0.9253127531632365, disc_loss = 0.004373734423438056
Trained batch 179 in epoch 8, gen_loss = 0.925451088613934, disc_loss = 0.004372206096821982
Trained batch 180 in epoch 8, gen_loss = 0.9253506946958889, disc_loss = 0.004375771667617914
Trained batch 181 in epoch 8, gen_loss = 0.9254658212373544, disc_loss = 0.004373283797726649
Trained batch 182 in epoch 8, gen_loss = 0.9250879974964538, disc_loss = 0.0043727528969273784
Trained batch 183 in epoch 8, gen_loss = 0.9250758912252344, disc_loss = 0.004391603616607861
Trained batch 184 in epoch 8, gen_loss = 0.9248345329954818, disc_loss = 0.004404339835525969
Trained batch 185 in epoch 8, gen_loss = 0.9243419455584659, disc_loss = 0.004425218170483707
Trained batch 186 in epoch 8, gen_loss = 0.9247751545141087, disc_loss = 0.00448254498536076
Trained batch 187 in epoch 8, gen_loss = 0.9238180197933887, disc_loss = 0.004530460912451901
Trained batch 188 in epoch 8, gen_loss = 0.924931096336829, disc_loss = 0.004659090311236916
Trained batch 189 in epoch 8, gen_loss = 0.9238765252263923, disc_loss = 0.004871090973947981
Trained batch 190 in epoch 8, gen_loss = 0.9248551723220586, disc_loss = 0.005212427708759163
Trained batch 191 in epoch 8, gen_loss = 0.9249962996691465, disc_loss = 0.00522736045907853
Trained batch 192 in epoch 8, gen_loss = 0.9251218546239823, disc_loss = 0.005235539418114397
Trained batch 193 in epoch 8, gen_loss = 0.9246353319625265, disc_loss = 0.005259880975498482
Trained batch 194 in epoch 8, gen_loss = 0.9239636149161902, disc_loss = 0.005338775860265089
Trained batch 195 in epoch 8, gen_loss = 0.9233906229539793, disc_loss = 0.005334336521479358
Trained batch 196 in epoch 8, gen_loss = 0.9228266946555395, disc_loss = 0.005346171086923536
Trained batch 197 in epoch 8, gen_loss = 0.9209320054511831, disc_loss = 0.00589248551363878
Trained batch 198 in epoch 8, gen_loss = 0.9224850307756932, disc_loss = 0.007989466023612673
Trained batch 199 in epoch 8, gen_loss = 0.9220855578780174, disc_loss = 0.008073145413654857
Trained batch 200 in epoch 8, gen_loss = 0.9208046702010122, disc_loss = 0.008382934948953044
Trained batch 201 in epoch 8, gen_loss = 0.920313706197361, disc_loss = 0.008636164231719173
Trained batch 202 in epoch 8, gen_loss = 0.9208034356239394, disc_loss = 0.009293624297990992
Trained batch 203 in epoch 8, gen_loss = 0.921087857262761, disc_loss = 0.011401475609768657
Trained batch 204 in epoch 8, gen_loss = 0.9217730449467171, disc_loss = 0.012651448971137586
Trained batch 205 in epoch 8, gen_loss = 0.9222483574186714, disc_loss = 0.014265460117598001
Trained batch 206 in epoch 8, gen_loss = 0.9219730401384658, disc_loss = 0.015105412239861194
Trained batch 207 in epoch 8, gen_loss = 0.9217263603439698, disc_loss = 0.0157716432244902
Trained batch 208 in epoch 8, gen_loss = 0.9213035993598865, disc_loss = 0.015787642611230782
Trained batch 209 in epoch 8, gen_loss = 0.92114056235268, disc_loss = 0.015849972180911297
Trained batch 210 in epoch 8, gen_loss = 0.9207862818975584, disc_loss = 0.015814225080696714
Trained batch 211 in epoch 8, gen_loss = 0.9204361573705133, disc_loss = 0.015789404943616147
Trained batch 212 in epoch 8, gen_loss = 0.9201567122634028, disc_loss = 0.015742206827413834
Trained batch 213 in epoch 8, gen_loss = 0.920012973179327, disc_loss = 0.015702042158009816
Trained batch 214 in epoch 8, gen_loss = 0.9195183038711547, disc_loss = 0.015658992970210697
Trained batch 215 in epoch 8, gen_loss = 0.9190656981534429, disc_loss = 0.015636202042245445
Trained batch 216 in epoch 8, gen_loss = 0.9180487240514448, disc_loss = 0.0157873191466246
Trained batch 217 in epoch 8, gen_loss = 0.9182307698311062, disc_loss = 0.015839975207099913
Trained batch 218 in epoch 8, gen_loss = 0.9179799202914651, disc_loss = 0.015828393007943312
Trained batch 219 in epoch 8, gen_loss = 0.9174332954666832, disc_loss = 0.015864844018572265
Trained batch 220 in epoch 8, gen_loss = 0.9172106431080744, disc_loss = 0.015835305422489697
Trained batch 221 in epoch 8, gen_loss = 0.9171567322971584, disc_loss = 0.015807900979993277
Trained batch 222 in epoch 8, gen_loss = 0.9164951499802114, disc_loss = 0.015833149442236218
Trained batch 223 in epoch 8, gen_loss = 0.9160101940589291, disc_loss = 0.01596894103516076
Trained batch 224 in epoch 8, gen_loss = 0.9146391503016154, disc_loss = 0.01620464945781148
Trained batch 225 in epoch 8, gen_loss = 0.9147649267605976, disc_loss = 0.016488599186594212
Trained batch 226 in epoch 8, gen_loss = 0.9132158921678686, disc_loss = 0.016768067139241893
Trained batch 227 in epoch 8, gen_loss = 0.9123987735886323, disc_loss = 0.01684595126476907
Trained batch 228 in epoch 8, gen_loss = 0.9131870943906526, disc_loss = 0.017451791441999376
Trained batch 229 in epoch 8, gen_loss = 0.9119503614695176, disc_loss = 0.017698028181051918
Trained batch 230 in epoch 8, gen_loss = 0.911175346735752, disc_loss = 0.017719155426935425
Trained batch 231 in epoch 8, gen_loss = 0.9108003411313583, disc_loss = 0.017781076004933404
Trained batch 232 in epoch 8, gen_loss = 0.9107211968929471, disc_loss = 0.017740542883984745
Trained batch 233 in epoch 8, gen_loss = 0.9104244905149835, disc_loss = 0.017694807447727896
Trained batch 234 in epoch 8, gen_loss = 0.9104268670082092, disc_loss = 0.017811746534178073
Trained batch 235 in epoch 8, gen_loss = 0.9090334126504801, disc_loss = 0.018275567712716094
Trained batch 236 in epoch 8, gen_loss = 0.9077027628693399, disc_loss = 0.01863821314889466
Trained batch 237 in epoch 8, gen_loss = 0.9065343306845978, disc_loss = 0.019020274738847678
Trained batch 238 in epoch 8, gen_loss = 0.9066720293156771, disc_loss = 0.019599605573313972
Trained batch 239 in epoch 8, gen_loss = 0.9061970462401708, disc_loss = 0.019782242384098935
Trained batch 240 in epoch 8, gen_loss = 0.9054509915751541, disc_loss = 0.019784156406487636
Trained batch 241 in epoch 8, gen_loss = 0.9053700822444002, disc_loss = 0.019734011529579234
Trained batch 242 in epoch 8, gen_loss = 0.9049488440953164, disc_loss = 0.019784347492906383
Trained batch 243 in epoch 8, gen_loss = 0.905208013341075, disc_loss = 0.019737634736735406
Trained batch 244 in epoch 8, gen_loss = 0.9051891302575871, disc_loss = 0.019681796604026185
Trained batch 245 in epoch 8, gen_loss = 0.9049696796308688, disc_loss = 0.019677782852895467
Trained batch 246 in epoch 8, gen_loss = 0.9043358878085488, disc_loss = 0.01970063780127131
Trained batch 247 in epoch 8, gen_loss = 0.9041567528920789, disc_loss = 0.019662737558622124
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.9107224941253662, disc_loss = 0.008782303892076015
Trained batch 1 in epoch 9, gen_loss = 0.9084105491638184, disc_loss = 0.007132934173569083
Trained batch 2 in epoch 9, gen_loss = 0.8631908098856608, disc_loss = 0.009732534332821766
Trained batch 3 in epoch 9, gen_loss = 0.85051029920578, disc_loss = 0.011864461819641292
Trained batch 4 in epoch 9, gen_loss = 0.896922516822815, disc_loss = 0.012295362260192632
Trained batch 5 in epoch 9, gen_loss = 0.9152377645174662, disc_loss = 0.013470013237868747
Trained batch 6 in epoch 9, gen_loss = 0.9170826928956168, disc_loss = 0.012941115070134401
Trained batch 7 in epoch 9, gen_loss = 0.9097631871700287, disc_loss = 0.012080173997674137
Trained batch 8 in epoch 9, gen_loss = 0.9019573132197062, disc_loss = 0.01169262065862616
Trained batch 9 in epoch 9, gen_loss = 0.8994088292121887, disc_loss = 0.011137635493651033
Trained batch 10 in epoch 9, gen_loss = 0.8981123295697299, disc_loss = 0.010508830193430185
Trained batch 11 in epoch 9, gen_loss = 0.8952044546604156, disc_loss = 0.010678618176219365
Trained batch 12 in epoch 9, gen_loss = 0.8979417635844305, disc_loss = 0.010327525902539492
Trained batch 13 in epoch 9, gen_loss = 0.8962114027568272, disc_loss = 0.009909171777378236
Trained batch 14 in epoch 9, gen_loss = 0.8994153062502543, disc_loss = 0.009761627111583949
Trained batch 15 in epoch 9, gen_loss = 0.8919480219483376, disc_loss = 0.010065859562018886
Trained batch 16 in epoch 9, gen_loss = 0.8947465805446401, disc_loss = 0.009764680145856212
Trained batch 17 in epoch 9, gen_loss = 0.9002158145109812, disc_loss = 0.01006781082186434
Trained batch 18 in epoch 9, gen_loss = 0.8982542345398351, disc_loss = 0.00996314195033751
Trained batch 19 in epoch 9, gen_loss = 0.8923669010400772, disc_loss = 0.009869536152109504
Trained batch 20 in epoch 9, gen_loss = 0.8924218728428795, disc_loss = 0.009594900710951714
Trained batch 21 in epoch 9, gen_loss = 0.8873650241981853, disc_loss = 0.010236074385995214
Trained batch 22 in epoch 9, gen_loss = 0.8842483007389567, disc_loss = 0.011433237839652144
Trained batch 23 in epoch 9, gen_loss = 0.8865843887130419, disc_loss = 0.01134986279066652
Trained batch 24 in epoch 9, gen_loss = 0.8759939527511597, disc_loss = 0.013071894384920598
Trained batch 25 in epoch 9, gen_loss = 0.879758759186818, disc_loss = 0.012942012077054152
Trained batch 26 in epoch 9, gen_loss = 0.8759418041617782, disc_loss = 0.012942479888874071
Trained batch 27 in epoch 9, gen_loss = 0.8780483369316373, disc_loss = 0.013429477977167283
Trained batch 28 in epoch 9, gen_loss = 0.8790261519366297, disc_loss = 0.013231976551870847
Trained batch 29 in epoch 9, gen_loss = 0.8780370632807414, disc_loss = 0.013150743534788489
Trained batch 30 in epoch 9, gen_loss = 0.8782696339391893, disc_loss = 0.012971686304456765
Trained batch 31 in epoch 9, gen_loss = 0.8766948841512203, disc_loss = 0.012785323386196978
Trained batch 32 in epoch 9, gen_loss = 0.8789334044311986, disc_loss = 0.012660070872780952
Trained batch 33 in epoch 9, gen_loss = 0.8815995910588432, disc_loss = 0.01247654204695102
Trained batch 34 in epoch 9, gen_loss = 0.8824741738183158, disc_loss = 0.012231117313993829
Trained batch 35 in epoch 9, gen_loss = 0.8808290345801247, disc_loss = 0.012125591424086856
Trained batch 36 in epoch 9, gen_loss = 0.8787092985333623, disc_loss = 0.011962978433616258
Trained batch 37 in epoch 9, gen_loss = 0.8854008113083086, disc_loss = 0.012402112706025181
Trained batch 38 in epoch 9, gen_loss = 0.8872580482409551, disc_loss = 0.012254481287434315
Trained batch 39 in epoch 9, gen_loss = 0.8856203570961952, disc_loss = 0.01228582566836849
Trained batch 40 in epoch 9, gen_loss = 0.8858899125238744, disc_loss = 0.012132246444774111
Trained batch 41 in epoch 9, gen_loss = 0.8848289960906619, disc_loss = 0.012344422118206109
Trained batch 42 in epoch 9, gen_loss = 0.8810712736706401, disc_loss = 0.012681037523285595
Trained batch 43 in epoch 9, gen_loss = 0.8829654400998895, disc_loss = 0.01254993182903325
Trained batch 44 in epoch 9, gen_loss = 0.8863401492436727, disc_loss = 0.012592893104172415
Trained batch 45 in epoch 9, gen_loss = 0.8861545363198156, disc_loss = 0.012486953986808658
Trained batch 46 in epoch 9, gen_loss = 0.8864913671574695, disc_loss = 0.012397468833133895
Trained batch 47 in epoch 9, gen_loss = 0.8859561296800772, disc_loss = 0.012342085935718691
Trained batch 48 in epoch 9, gen_loss = 0.8883404524958863, disc_loss = 0.012679390865853247
Trained batch 49 in epoch 9, gen_loss = 0.8880965340137482, disc_loss = 0.012694626031443477
Trained batch 50 in epoch 9, gen_loss = 0.8831112244549919, disc_loss = 0.013727826696327505
Trained batch 51 in epoch 9, gen_loss = 0.8860058005039508, disc_loss = 0.015988180727268066
Trained batch 52 in epoch 9, gen_loss = 0.8810222115156785, disc_loss = 0.017155824993508605
Trained batch 53 in epoch 9, gen_loss = 0.8814899501977144, disc_loss = 0.01720205779808263
Trained batch 54 in epoch 9, gen_loss = 0.881766431981867, disc_loss = 0.017436950171197004
Trained batch 55 in epoch 9, gen_loss = 0.8814352729490825, disc_loss = 0.017440916230303367
Trained batch 56 in epoch 9, gen_loss = 0.8806178120144627, disc_loss = 0.017464709574389354
Trained batch 57 in epoch 9, gen_loss = 0.8822090605209614, disc_loss = 0.01791486509369108
Trained batch 58 in epoch 9, gen_loss = 0.880702923920195, disc_loss = 0.017814521180560528
Trained batch 59 in epoch 9, gen_loss = 0.8808375020821889, disc_loss = 0.01768336360498021
Trained batch 60 in epoch 9, gen_loss = 0.8809398334534442, disc_loss = 0.01748991207998307
Trained batch 61 in epoch 9, gen_loss = 0.8802856629894625, disc_loss = 0.017303625654969967
Trained batch 62 in epoch 9, gen_loss = 0.879653377192361, disc_loss = 0.01710223720689851
Trained batch 63 in epoch 9, gen_loss = 0.8800701200962067, disc_loss = 0.016889446087589022
Trained batch 64 in epoch 9, gen_loss = 0.8803175541070791, disc_loss = 0.016685748293709297
Trained batch 65 in epoch 9, gen_loss = 0.880101203918457, disc_loss = 0.016555351184003732
Trained batch 66 in epoch 9, gen_loss = 0.8815943874529938, disc_loss = 0.016406561248004436
Trained batch 67 in epoch 9, gen_loss = 0.8824467448627248, disc_loss = 0.016298569451250574
Trained batch 68 in epoch 9, gen_loss = 0.8815388532652371, disc_loss = 0.016317331151145954
Trained batch 69 in epoch 9, gen_loss = 0.8809803094182695, disc_loss = 0.016296528399522815
Trained batch 70 in epoch 9, gen_loss = 0.8791220389621358, disc_loss = 0.016391658906260848
Trained batch 71 in epoch 9, gen_loss = 0.8841204543908437, disc_loss = 0.02134866354107443
Trained batch 72 in epoch 9, gen_loss = 0.8811706998576857, disc_loss = 0.02186862214736334
Trained batch 73 in epoch 9, gen_loss = 0.8768150588950595, disc_loss = 0.023647238361976436
Trained batch 74 in epoch 9, gen_loss = 0.87682581504186, disc_loss = 0.027482624538242816
Trained batch 75 in epoch 9, gen_loss = 0.8737377093026513, disc_loss = 0.028158240792292514
Trained batch 76 in epoch 9, gen_loss = 0.8706008900295604, disc_loss = 0.028872442310796928
Trained batch 77 in epoch 9, gen_loss = 0.8665600579518539, disc_loss = 0.029990318959626634
Trained batch 78 in epoch 9, gen_loss = 0.8654239585128012, disc_loss = 0.03035521822026636
Trained batch 79 in epoch 9, gen_loss = 0.864204615354538, disc_loss = 0.030278895783703776
Trained batch 80 in epoch 9, gen_loss = 0.8620585629969467, disc_loss = 0.0301518048286254
Trained batch 81 in epoch 9, gen_loss = 0.861617748330279, disc_loss = 0.030081049618651955
Trained batch 82 in epoch 9, gen_loss = 0.860248857952026, disc_loss = 0.030144306471997714
Trained batch 83 in epoch 9, gen_loss = 0.8579354137182236, disc_loss = 0.03028052939944679
Trained batch 84 in epoch 9, gen_loss = 0.8589729954214657, disc_loss = 0.030691924614503104
Trained batch 85 in epoch 9, gen_loss = 0.8586184035900027, disc_loss = 0.03042680119315899
Trained batch 86 in epoch 9, gen_loss = 0.8571731235789156, disc_loss = 0.03049163360833779
Trained batch 87 in epoch 9, gen_loss = 0.8582508834925565, disc_loss = 0.030218140581961383
Trained batch 88 in epoch 9, gen_loss = 0.8585951475614912, disc_loss = 0.03007923558438092
Trained batch 89 in epoch 9, gen_loss = 0.8577777763207753, disc_loss = 0.029965805986689197
Trained batch 90 in epoch 9, gen_loss = 0.8574910871275179, disc_loss = 0.02977298814189303
Trained batch 91 in epoch 9, gen_loss = 0.8577402577452038, disc_loss = 0.02952120039085655
Trained batch 92 in epoch 9, gen_loss = 0.8580810504574929, disc_loss = 0.029250071819631324
Trained batch 93 in epoch 9, gen_loss = 0.8576523908909331, disc_loss = 0.028978691220858156
Trained batch 94 in epoch 9, gen_loss = 0.8574603814827768, disc_loss = 0.02871569234044536
Trained batch 95 in epoch 9, gen_loss = 0.8578211857626835, disc_loss = 0.028492838753057487
Trained batch 96 in epoch 9, gen_loss = 0.8555350039423126, disc_loss = 0.028727956373033298
Trained batch 97 in epoch 9, gen_loss = 0.8574709825369776, disc_loss = 0.028692788850725154
Trained batch 98 in epoch 9, gen_loss = 0.8572246907937406, disc_loss = 0.02861905471196003
Trained batch 99 in epoch 9, gen_loss = 0.8572398459911347, disc_loss = 0.028395234940107913
Trained batch 100 in epoch 9, gen_loss = 0.8575321577563144, disc_loss = 0.02818148599080004
Trained batch 101 in epoch 9, gen_loss = 0.8584554061001423, disc_loss = 0.0281499131130712
Trained batch 102 in epoch 9, gen_loss = 0.8558054010844925, disc_loss = 0.02870942123496489
Trained batch 103 in epoch 9, gen_loss = 0.8557320002179879, disc_loss = 0.028872702908791743
Trained batch 104 in epoch 9, gen_loss = 0.8549356256212507, disc_loss = 0.028833808902917164
Trained batch 105 in epoch 9, gen_loss = 0.8582581506585175, disc_loss = 0.02907396541284573
Trained batch 106 in epoch 9, gen_loss = 0.8588778142617127, disc_loss = 0.028861159900481874
Trained batch 107 in epoch 9, gen_loss = 0.8582799545040837, disc_loss = 0.028814272720073524
Trained batch 108 in epoch 9, gen_loss = 0.8578696349345216, disc_loss = 0.028620524235804558
Trained batch 109 in epoch 9, gen_loss = 0.8587068178436973, disc_loss = 0.02842200541318479
Trained batch 110 in epoch 9, gen_loss = 0.8593163109040475, disc_loss = 0.02819815532488933
Trained batch 111 in epoch 9, gen_loss = 0.8601423230554376, disc_loss = 0.02798721293428181
Trained batch 112 in epoch 9, gen_loss = 0.860059873720186, disc_loss = 0.027775513504804894
Trained batch 113 in epoch 9, gen_loss = 0.860312898430908, disc_loss = 0.0275862583943659
Trained batch 114 in epoch 9, gen_loss = 0.8599422574043274, disc_loss = 0.027390560744654225
Trained batch 115 in epoch 9, gen_loss = 0.8590094565317549, disc_loss = 0.027355779261440682
Trained batch 116 in epoch 9, gen_loss = 0.8597329737793686, disc_loss = 0.027168631468079667
Trained batch 117 in epoch 9, gen_loss = 0.861301036709446, disc_loss = 0.027231465308863858
Trained batch 118 in epoch 9, gen_loss = 0.8607247927609611, disc_loss = 0.027075653459422856
Trained batch 119 in epoch 9, gen_loss = 0.8611658955613772, disc_loss = 0.026907045434927567
Trained batch 120 in epoch 9, gen_loss = 0.8599953779504319, disc_loss = 0.026846779951025263
Trained batch 121 in epoch 9, gen_loss = 0.8616204935996259, disc_loss = 0.026793208181262625
Trained batch 122 in epoch 9, gen_loss = 0.8620276325117282, disc_loss = 0.026654581980386036
Trained batch 123 in epoch 9, gen_loss = 0.8627613302200071, disc_loss = 0.02649384355285175
Trained batch 124 in epoch 9, gen_loss = 0.8628447179794312, disc_loss = 0.02630191656202078
Trained batch 125 in epoch 9, gen_loss = 0.8617748206570035, disc_loss = 0.02623376397356864
Trained batch 126 in epoch 9, gen_loss = 0.8605718157422824, disc_loss = 0.026197847851559403
Trained batch 127 in epoch 9, gen_loss = 0.8602917031385005, disc_loss = 0.026494852580071893
Trained batch 128 in epoch 9, gen_loss = 0.8591915493787721, disc_loss = 0.026667862401394418
Trained batch 129 in epoch 9, gen_loss = 0.8587954791692587, disc_loss = 0.027442995365709065
Trained batch 130 in epoch 9, gen_loss = 0.8576919436454773, disc_loss = 0.027538910273547847
Trained batch 131 in epoch 9, gen_loss = 0.8579044102719335, disc_loss = 0.02736343951035065
Trained batch 132 in epoch 9, gen_loss = 0.8570737421960759, disc_loss = 0.027256069491316277
Trained batch 133 in epoch 9, gen_loss = 0.8569200710574193, disc_loss = 0.027167166009851133
Trained batch 134 in epoch 9, gen_loss = 0.8564487567654362, disc_loss = 0.027100074080819332
Trained batch 135 in epoch 9, gen_loss = 0.8577291934805757, disc_loss = 0.02814826775712016
Trained batch 136 in epoch 9, gen_loss = 0.8550864101326379, disc_loss = 0.02960052728367439
Trained batch 137 in epoch 9, gen_loss = 0.8532755785230277, disc_loss = 0.030487823863581256
Trained batch 138 in epoch 9, gen_loss = 0.8522865193353283, disc_loss = 0.03135294612939302
Trained batch 139 in epoch 9, gen_loss = 0.8508036954062326, disc_loss = 0.032480902021883855
Trained batch 140 in epoch 9, gen_loss = 0.8485494099610241, disc_loss = 0.033716280102492016
Trained batch 141 in epoch 9, gen_loss = 0.8467757974711942, disc_loss = 0.03421300928711786
Trained batch 142 in epoch 9, gen_loss = 0.8453610055930131, disc_loss = 0.03483176586654532
Trained batch 143 in epoch 9, gen_loss = 0.8441776711907651, disc_loss = 0.03501739291823469
Trained batch 144 in epoch 9, gen_loss = 0.8443719329505132, disc_loss = 0.0351399550503441
Trained batch 145 in epoch 9, gen_loss = 0.8430830991431458, disc_loss = 0.035138435747908196
Trained batch 146 in epoch 9, gen_loss = 0.8425758128263512, disc_loss = 0.03508862949033477
Trained batch 147 in epoch 9, gen_loss = 0.8425653641288345, disc_loss = 0.03506810892360738
Trained batch 148 in epoch 9, gen_loss = 0.841288560988919, disc_loss = 0.035347502400486064
Trained batch 149 in epoch 9, gen_loss = 0.8413873251279195, disc_loss = 0.03518931959134837
Trained batch 150 in epoch 9, gen_loss = 0.8417089802539901, disc_loss = 0.03511192562329947
Trained batch 151 in epoch 9, gen_loss = 0.8416601325336256, disc_loss = 0.035006856830717116
Trained batch 152 in epoch 9, gen_loss = 0.8406363406212501, disc_loss = 0.03501697679908544
Trained batch 153 in epoch 9, gen_loss = 0.8422049338167364, disc_loss = 0.03514001686912175
Trained batch 154 in epoch 9, gen_loss = 0.8410969549609769, disc_loss = 0.035163521493274355
Trained batch 155 in epoch 9, gen_loss = 0.8413154188639078, disc_loss = 0.03499705594283743
Trained batch 156 in epoch 9, gen_loss = 0.8422865901783014, disc_loss = 0.03486319244868911
Trained batch 157 in epoch 9, gen_loss = 0.841825049511994, disc_loss = 0.03476452462292642
Trained batch 158 in epoch 9, gen_loss = 0.8413108733465087, disc_loss = 0.03479565741236573
Trained batch 159 in epoch 9, gen_loss = 0.8409816268831491, disc_loss = 0.035090267893974667
Trained batch 160 in epoch 9, gen_loss = 0.8397457744023815, disc_loss = 0.035218323751566756
Trained batch 161 in epoch 9, gen_loss = 0.8395783411867824, disc_loss = 0.03516562906507817
Trained batch 162 in epoch 9, gen_loss = 0.8399788678789432, disc_loss = 0.03499291704659082
Trained batch 163 in epoch 9, gen_loss = 0.8415771355716194, disc_loss = 0.03491582393237367
Trained batch 164 in epoch 9, gen_loss = 0.8420886881423719, disc_loss = 0.034742191529861
Trained batch 165 in epoch 9, gen_loss = 0.8408380919192211, disc_loss = 0.03491751616820693
Trained batch 166 in epoch 9, gen_loss = 0.8416135332541551, disc_loss = 0.035201073412275956
Trained batch 167 in epoch 9, gen_loss = 0.8405382686427662, disc_loss = 0.03535674783467714
Trained batch 168 in epoch 9, gen_loss = 0.8400287465936334, disc_loss = 0.03534931205102854
Trained batch 169 in epoch 9, gen_loss = 0.8399008894667906, disc_loss = 0.035190896739197126
Trained batch 170 in epoch 9, gen_loss = 0.8409457175355208, disc_loss = 0.0351031207866226
Trained batch 171 in epoch 9, gen_loss = 0.8418462234874104, disc_loss = 0.03497541729945603
Trained batch 172 in epoch 9, gen_loss = 0.8424479386020947, disc_loss = 0.03484384764545743
Trained batch 173 in epoch 9, gen_loss = 0.8423378816966353, disc_loss = 0.03468733298024912
Trained batch 174 in epoch 9, gen_loss = 0.8415862151554653, disc_loss = 0.03462832954313074
Trained batch 175 in epoch 9, gen_loss = 0.8411919708279046, disc_loss = 0.034637729986570776
Trained batch 176 in epoch 9, gen_loss = 0.8413557592084853, disc_loss = 0.034588071880704264
Trained batch 177 in epoch 9, gen_loss = 0.8408781872706467, disc_loss = 0.03463369139124838
Trained batch 178 in epoch 9, gen_loss = 0.8415163219308054, disc_loss = 0.034656957686779885
Trained batch 179 in epoch 9, gen_loss = 0.8421940979030397, disc_loss = 0.03467884417623281
Trained batch 180 in epoch 9, gen_loss = 0.8413696927918913, disc_loss = 0.034838844955132155
Trained batch 181 in epoch 9, gen_loss = 0.8419413006567693, disc_loss = 0.03484159267947569
Trained batch 182 in epoch 9, gen_loss = 0.8420097479403345, disc_loss = 0.03510192527227063
Trained batch 183 in epoch 9, gen_loss = 0.8401714148728744, disc_loss = 0.03592575205813931
Trained batch 184 in epoch 9, gen_loss = 0.8413749997680252, disc_loss = 0.03664217327494879
Trained batch 185 in epoch 9, gen_loss = 0.8396169379834206, disc_loss = 0.037025916299992995
Trained batch 186 in epoch 9, gen_loss = 0.8398555338701462, disc_loss = 0.036892699446270175
Trained batch 187 in epoch 9, gen_loss = 0.8410039436309895, disc_loss = 0.03705923092809129
Trained batch 188 in epoch 9, gen_loss = 0.8404237312614602, disc_loss = 0.037026240928936256
Trained batch 189 in epoch 9, gen_loss = 0.8391725129202793, disc_loss = 0.03727435702948194
Trained batch 190 in epoch 9, gen_loss = 0.8389224029336301, disc_loss = 0.0379038095591268
Trained batch 191 in epoch 9, gen_loss = 0.8378410954028368, disc_loss = 0.03812533715972677
Trained batch 192 in epoch 9, gen_loss = 0.8378158792312899, disc_loss = 0.03821644986077294
Trained batch 193 in epoch 9, gen_loss = 0.83782982887681, disc_loss = 0.0380678302704443
Trained batch 194 in epoch 9, gen_loss = 0.8374646315207848, disc_loss = 0.03810757362785248
Trained batch 195 in epoch 9, gen_loss = 0.8370685869333695, disc_loss = 0.03799928374569483
Trained batch 196 in epoch 9, gen_loss = 0.8358309211464703, disc_loss = 0.03840291654681645
Trained batch 197 in epoch 9, gen_loss = 0.8372371187715819, disc_loss = 0.03885048623620109
Trained batch 198 in epoch 9, gen_loss = 0.836207098996819, disc_loss = 0.038974093277962064
Trained batch 199 in epoch 9, gen_loss = 0.8348343098163604, disc_loss = 0.03917598597239703
Trained batch 200 in epoch 9, gen_loss = 0.8359681836408169, disc_loss = 0.03960474858069746
Trained batch 201 in epoch 9, gen_loss = 0.8354501113443091, disc_loss = 0.03956086816966976
Trained batch 202 in epoch 9, gen_loss = 0.8345948237503691, disc_loss = 0.03952412605927936
Trained batch 203 in epoch 9, gen_loss = 0.8359385410360262, disc_loss = 0.039648880794023476
Trained batch 204 in epoch 9, gen_loss = 0.8362371665675465, disc_loss = 0.03949261632089208
Trained batch 205 in epoch 9, gen_loss = 0.8359941342501964, disc_loss = 0.03943599633040648
Trained batch 206 in epoch 9, gen_loss = 0.8361712521401005, disc_loss = 0.039290809769921255
Trained batch 207 in epoch 9, gen_loss = 0.8362371526085414, disc_loss = 0.03913102467329456
Trained batch 208 in epoch 9, gen_loss = 0.8361363023091731, disc_loss = 0.0389664800788619
Trained batch 209 in epoch 9, gen_loss = 0.8361613091968355, disc_loss = 0.038905429314555866
Trained batch 210 in epoch 9, gen_loss = 0.8360436522000209, disc_loss = 0.03878258782001963
Trained batch 211 in epoch 9, gen_loss = 0.8355313578866562, disc_loss = 0.03869000079663787
Trained batch 212 in epoch 9, gen_loss = 0.8360964322873684, disc_loss = 0.03856226826139109
Trained batch 213 in epoch 9, gen_loss = 0.8364194275062775, disc_loss = 0.038402572715933496
Trained batch 214 in epoch 9, gen_loss = 0.8361118125361066, disc_loss = 0.03827526163699668
Trained batch 215 in epoch 9, gen_loss = 0.8362431021200286, disc_loss = 0.03812442943065738
Trained batch 216 in epoch 9, gen_loss = 0.8374284755799078, disc_loss = 0.038044905974551145
Trained batch 217 in epoch 9, gen_loss = 0.8370645032563341, disc_loss = 0.03794291169263012
Trained batch 218 in epoch 9, gen_loss = 0.8379666573925105, disc_loss = 0.03782119966626644
Trained batch 219 in epoch 9, gen_loss = 0.8378731589425694, disc_loss = 0.03770462463144213
Trained batch 220 in epoch 9, gen_loss = 0.838877507734083, disc_loss = 0.037855193682638635
Trained batch 221 in epoch 9, gen_loss = 0.8377604793320905, disc_loss = 0.03823992733105279
Trained batch 222 in epoch 9, gen_loss = 0.8376771657990768, disc_loss = 0.03839688626798747
Trained batch 223 in epoch 9, gen_loss = 0.8380911996854203, disc_loss = 0.03826286068527095
Trained batch 224 in epoch 9, gen_loss = 0.8386885129080879, disc_loss = 0.03813132657152083
Trained batch 225 in epoch 9, gen_loss = 0.8383089430564272, disc_loss = 0.0380534181738091
Trained batch 226 in epoch 9, gen_loss = 0.83799053551342, disc_loss = 0.037985954591635174
Trained batch 227 in epoch 9, gen_loss = 0.8388167635390633, disc_loss = 0.037897945261200924
Trained batch 228 in epoch 9, gen_loss = 0.8391910952772116, disc_loss = 0.03782296184181972
Trained batch 229 in epoch 9, gen_loss = 0.8391626311385113, disc_loss = 0.03769928640685975
Trained batch 230 in epoch 9, gen_loss = 0.8394493241330762, disc_loss = 0.03757806089444658
Trained batch 231 in epoch 9, gen_loss = 0.839425922981624, disc_loss = 0.03780543777874896
Trained batch 232 in epoch 9, gen_loss = 0.838008431917608, disc_loss = 0.03840666567475051
Trained batch 233 in epoch 9, gen_loss = 0.8380095426343445, disc_loss = 0.03837986114737379
Trained batch 234 in epoch 9, gen_loss = 0.8391948266232268, disc_loss = 0.03851632459406206
Trained batch 235 in epoch 9, gen_loss = 0.8393798659918672, disc_loss = 0.038479939144562485
Trained batch 236 in epoch 9, gen_loss = 0.8391699049040235, disc_loss = 0.03848395738082659
Trained batch 237 in epoch 9, gen_loss = 0.8393877912469271, disc_loss = 0.03842425162653525
Trained batch 238 in epoch 9, gen_loss = 0.8397225380941415, disc_loss = 0.03830946615028145
Trained batch 239 in epoch 9, gen_loss = 0.8400032902757327, disc_loss = 0.03817578221399647
Trained batch 240 in epoch 9, gen_loss = 0.8400246849693204, disc_loss = 0.03805553249404205
Trained batch 241 in epoch 9, gen_loss = 0.8400348993864927, disc_loss = 0.03800962840145346
Trained batch 242 in epoch 9, gen_loss = 0.8402486799185168, disc_loss = 0.03787168309882038
Trained batch 243 in epoch 9, gen_loss = 0.8407707326724881, disc_loss = 0.0377450768309111
Trained batch 244 in epoch 9, gen_loss = 0.8413205012983206, disc_loss = 0.03762519935488093
Trained batch 245 in epoch 9, gen_loss = 0.8415924022352792, disc_loss = 0.037483792562734305
Trained batch 246 in epoch 9, gen_loss = 0.8420725969167856, disc_loss = 0.03734867619765311
Trained batch 247 in epoch 9, gen_loss = 0.8422672904787525, disc_loss = 0.037215442494339036
Testing Epoch 9
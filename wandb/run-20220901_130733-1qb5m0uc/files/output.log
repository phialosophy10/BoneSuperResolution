wandb: WARNING Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 0.47918325662612915, disc_loss = 0.5738001465797424
Trained batch 1 in epoch 0, gen_loss = 0.5239690244197845, disc_loss = 0.5476514995098114
Trained batch 2 in epoch 0, gen_loss = 0.5353789130846659, disc_loss = 0.5686028798421224
Trained batch 3 in epoch 0, gen_loss = 0.5117915868759155, disc_loss = 0.5680703520774841
Trained batch 4 in epoch 0, gen_loss = 0.519134247303009, disc_loss = 0.5163606405258179
Trained batch 5 in epoch 0, gen_loss = 0.5082202752431234, disc_loss = 0.47177332391341525
Trained batch 6 in epoch 0, gen_loss = 0.49198509965624126, disc_loss = 0.42955886253288816
Trained batch 7 in epoch 0, gen_loss = 0.4937818795442581, disc_loss = 0.39996069483458996
Trained batch 8 in epoch 0, gen_loss = 0.4875025947888692, disc_loss = 0.3699910458591249
Trained batch 9 in epoch 0, gen_loss = 0.48078943192958834, disc_loss = 0.3495636060833931
Trained batch 10 in epoch 0, gen_loss = 0.47490866617722943, disc_loss = 0.3281022147698836
Trained batch 11 in epoch 0, gen_loss = 0.47416578233242035, disc_loss = 0.3103257517019908
Trained batch 12 in epoch 0, gen_loss = 0.4735260812135843, disc_loss = 0.2943095782628426
Trained batch 13 in epoch 0, gen_loss = 0.47215295902320314, disc_loss = 0.2805467045732907
Trained batch 14 in epoch 0, gen_loss = 0.4746680915355682, disc_loss = 0.26759705146153767
Trained batch 15 in epoch 0, gen_loss = 0.4741639830172062, disc_loss = 0.25596344377845526
Trained batch 16 in epoch 0, gen_loss = 0.4761088104809032, disc_loss = 0.24960664703565486
Trained batch 17 in epoch 0, gen_loss = 0.47748421298133004, disc_loss = 0.2465798921055264
Trained batch 18 in epoch 0, gen_loss = 0.4745354934742576, disc_loss = 0.23940108873342214
Trained batch 19 in epoch 0, gen_loss = 0.46895729899406435, disc_loss = 0.23408400714397432
Trained batch 20 in epoch 0, gen_loss = 0.4664297983759925, disc_loss = 0.22860275492781684
Trained batch 21 in epoch 0, gen_loss = 0.4686418365348469, disc_loss = 0.22630035267634827
Trained batch 22 in epoch 0, gen_loss = 0.4696580728758936, disc_loss = 0.22306317220563474
Trained batch 23 in epoch 0, gen_loss = 0.4667627674837907, disc_loss = 0.22373398145039877
Trained batch 24 in epoch 0, gen_loss = 0.46773181319236756, disc_loss = 0.22288854360580446
Trained batch 25 in epoch 0, gen_loss = 0.46841615438461304, disc_loss = 0.21998536987946585
Trained batch 26 in epoch 0, gen_loss = 0.4683891910093802, disc_loss = 0.21608946941517018
Trained batch 27 in epoch 0, gen_loss = 0.466206787952355, disc_loss = 0.21317115745374135
Trained batch 28 in epoch 0, gen_loss = 0.4670794863125374, disc_loss = 0.21057542696081358
Trained batch 29 in epoch 0, gen_loss = 0.4668334464232127, disc_loss = 0.20644798303643863
Trained batch 30 in epoch 0, gen_loss = 0.46735940921691155, disc_loss = 0.20216002988238488
Trained batch 31 in epoch 0, gen_loss = 0.4667869498953223, disc_loss = 0.19782720669172704
Trained batch 32 in epoch 0, gen_loss = 0.467197243011359, disc_loss = 0.1936485760591247
Trained batch 33 in epoch 0, gen_loss = 0.46576020998113293, disc_loss = 0.19029524768976605
Trained batch 34 in epoch 0, gen_loss = 0.46450858882495333, disc_loss = 0.18709538046802793
Trained batch 35 in epoch 0, gen_loss = 0.4650978239046203, disc_loss = 0.1833889071519176
Trained batch 36 in epoch 0, gen_loss = 0.465270613496368, disc_loss = 0.1804346986920447
Trained batch 37 in epoch 0, gen_loss = 0.4643867196221101, disc_loss = 0.17787169204338601
Trained batch 38 in epoch 0, gen_loss = 0.46720908620418644, disc_loss = 0.17525930177324858
Trained batch 39 in epoch 0, gen_loss = 0.4698698468506336, disc_loss = 0.17272126814350486
Trained batch 40 in epoch 0, gen_loss = 0.46984489516514105, disc_loss = 0.16989292776802692
Trained batch 41 in epoch 0, gen_loss = 0.47326233699208214, disc_loss = 0.167082548939756
Trained batch 42 in epoch 0, gen_loss = 0.47492904164070304, disc_loss = 0.1647775971092457
Trained batch 43 in epoch 0, gen_loss = 0.4768253429369493, disc_loss = 0.16278881520371546
Trained batch 44 in epoch 0, gen_loss = 0.47798855702082316, disc_loss = 0.1603523919151889
Trained batch 45 in epoch 0, gen_loss = 0.47964000831479614, disc_loss = 0.15780843421816826
Trained batch 46 in epoch 0, gen_loss = 0.47927984024616, disc_loss = 0.15569433649169637
Trained batch 47 in epoch 0, gen_loss = 0.47919997945427895, disc_loss = 0.15396239406739673
Trained batch 48 in epoch 0, gen_loss = 0.47936289955158623, disc_loss = 0.1523847888622965
Trained batch 49 in epoch 0, gen_loss = 0.48066754400730133, disc_loss = 0.1502745631337166
Trained batch 50 in epoch 0, gen_loss = 0.48253384933752175, disc_loss = 0.14796858207852231
Trained batch 51 in epoch 0, gen_loss = 0.48236991121218753, disc_loss = 0.14604704110668257
Trained batch 52 in epoch 0, gen_loss = 0.4822649539641614, disc_loss = 0.14418582196505564
Trained batch 53 in epoch 0, gen_loss = 0.4812823815478219, disc_loss = 0.142343001647128
Trained batch 54 in epoch 0, gen_loss = 0.4818372742696242, disc_loss = 0.14112508554350245
Trained batch 55 in epoch 0, gen_loss = 0.4846881686576775, disc_loss = 0.13962073451174156
Trained batch 56 in epoch 0, gen_loss = 0.48618826270103455, disc_loss = 0.1379542127251625
Trained batch 57 in epoch 0, gen_loss = 0.4864977192262123, disc_loss = 0.13620437604599986
Trained batch 58 in epoch 0, gen_loss = 0.4860862862255614, disc_loss = 0.13452464878811674
Trained batch 59 in epoch 0, gen_loss = 0.48569177836179733, disc_loss = 0.1327431606128812
Trained batch 60 in epoch 0, gen_loss = 0.485982287614072, disc_loss = 0.1310356394922147
Trained batch 61 in epoch 0, gen_loss = 0.48692294041956624, disc_loss = 0.12942793009982956
Trained batch 62 in epoch 0, gen_loss = 0.4862557810450357, disc_loss = 0.12780654859093446
Trained batch 63 in epoch 0, gen_loss = 0.48636833764612675, disc_loss = 0.12629410924273543
Trained batch 64 in epoch 0, gen_loss = 0.4876100971148564, disc_loss = 0.12488610237263716
Trained batch 65 in epoch 0, gen_loss = 0.48811713764161774, disc_loss = 0.12367561603472992
Trained batch 66 in epoch 0, gen_loss = 0.4886932808961441, disc_loss = 0.12489499693819836
Trained batch 67 in epoch 0, gen_loss = 0.4895278627381605, disc_loss = 0.12486638169845238
Trained batch 68 in epoch 0, gen_loss = 0.49032414823338605, disc_loss = 0.1237468684659056
Trained batch 69 in epoch 0, gen_loss = 0.4901323258876801, disc_loss = 0.12249214061136757
Trained batch 70 in epoch 0, gen_loss = 0.4906078258030851, disc_loss = 0.12116348205632727
Trained batch 71 in epoch 0, gen_loss = 0.491282952328523, disc_loss = 0.11987529480312434
Trained batch 72 in epoch 0, gen_loss = 0.4917370717819423, disc_loss = 0.1185795426725933
Trained batch 73 in epoch 0, gen_loss = 0.49248739593737834, disc_loss = 0.11741344487244212
Trained batch 74 in epoch 0, gen_loss = 0.4921727379163106, disc_loss = 0.11629588417708873
Trained batch 75 in epoch 0, gen_loss = 0.49128175644498123, disc_loss = 0.1151250914768561
Trained batch 76 in epoch 0, gen_loss = 0.4910171751852159, disc_loss = 0.11398702949382268
Trained batch 77 in epoch 0, gen_loss = 0.4917509471758818, disc_loss = 0.11285201921008337
Trained batch 78 in epoch 0, gen_loss = 0.49205684586416315, disc_loss = 0.11176226415400263
Trained batch 79 in epoch 0, gen_loss = 0.4922120444476604, disc_loss = 0.11068392302840949
Trained batch 80 in epoch 0, gen_loss = 0.4932319036236516, disc_loss = 0.10980786691293304
Trained batch 81 in epoch 0, gen_loss = 0.49390776782501034, disc_loss = 0.10898415399033849
Trained batch 82 in epoch 0, gen_loss = 0.49458901781633674, disc_loss = 0.10795689033097532
Trained batch 83 in epoch 0, gen_loss = 0.493969331185023, disc_loss = 0.10711878666742927
Trained batch 84 in epoch 0, gen_loss = 0.4952924630221199, disc_loss = 0.10626348822432406
Trained batch 85 in epoch 0, gen_loss = 0.4954676544943521, disc_loss = 0.10580238106465617
Trained batch 86 in epoch 0, gen_loss = 0.49403929025277327, disc_loss = 0.10588792347531209
Trained batch 87 in epoch 0, gen_loss = 0.49452774497595703, disc_loss = 0.10581884723664685
Trained batch 88 in epoch 0, gen_loss = 0.49402246682831413, disc_loss = 0.10576631953374724
Trained batch 89 in epoch 0, gen_loss = 0.49379335708088345, disc_loss = 0.1055027760979202
Trained batch 90 in epoch 0, gen_loss = 0.4940618315895835, disc_loss = 0.10555542837623712
Trained batch 91 in epoch 0, gen_loss = 0.4935151672233706, disc_loss = 0.10760227732522332
Trained batch 92 in epoch 0, gen_loss = 0.4947617678873001, disc_loss = 0.1101321492704653
Trained batch 93 in epoch 0, gen_loss = 0.4948116052658, disc_loss = 0.10989066058809453
Trained batch 94 in epoch 0, gen_loss = 0.4937452372751738, disc_loss = 0.10998168160256587
Trained batch 95 in epoch 0, gen_loss = 0.49356967707475025, disc_loss = 0.10965457135656227
Trained batch 96 in epoch 0, gen_loss = 0.49397567068178627, disc_loss = 0.10899843947635483
Trained batch 97 in epoch 0, gen_loss = 0.4936668146021512, disc_loss = 0.10982153834585025
Trained batch 98 in epoch 0, gen_loss = 0.49291034780367454, disc_loss = 0.11304808697766727
Trained batch 99 in epoch 0, gen_loss = 0.4929330411553383, disc_loss = 0.11342054199427366
Trained batch 100 in epoch 0, gen_loss = 0.49321642281985517, disc_loss = 0.11547204656618656
Trained batch 101 in epoch 0, gen_loss = 0.49267129103342694, disc_loss = 0.11673358006074148
Trained batch 102 in epoch 0, gen_loss = 0.49271141730465934, disc_loss = 0.11849880605502036
Trained batch 103 in epoch 0, gen_loss = 0.49327756464481354, disc_loss = 0.11900866457905906
Trained batch 104 in epoch 0, gen_loss = 0.49307353496551515, disc_loss = 0.11964666783100082
Trained batch 105 in epoch 0, gen_loss = 0.4928724079761865, disc_loss = 0.12013973292174204
Trained batch 106 in epoch 0, gen_loss = 0.4924593665332438, disc_loss = 0.12231570924414653
Trained batch 107 in epoch 0, gen_loss = 0.49240650788501455, disc_loss = 0.12405911829598525
Trained batch 108 in epoch 0, gen_loss = 0.4915985506062114, disc_loss = 0.12496364755778137
Trained batch 109 in epoch 0, gen_loss = 0.4908974552696401, disc_loss = 0.12595067603344268
Trained batch 110 in epoch 0, gen_loss = 0.49040032426516217, disc_loss = 0.12629345002340842
Trained batch 111 in epoch 0, gen_loss = 0.4904962168740375, disc_loss = 0.12627089000307024
Trained batch 112 in epoch 0, gen_loss = 0.4904413666345377, disc_loss = 0.12653127790684193
Trained batch 113 in epoch 0, gen_loss = 0.49009989803297477, disc_loss = 0.1279010867144455
Trained batch 114 in epoch 0, gen_loss = 0.48917166953501495, disc_loss = 0.12914044886179593
Trained batch 115 in epoch 0, gen_loss = 0.48847911301357994, disc_loss = 0.13171790414971524
Trained batch 116 in epoch 0, gen_loss = 0.4881609589116186, disc_loss = 0.13249114821227187
Trained batch 117 in epoch 0, gen_loss = 0.4871424860873465, disc_loss = 0.13338643770222947
Trained batch 118 in epoch 0, gen_loss = 0.4862839529494278, disc_loss = 0.13454342592789345
Trained batch 119 in epoch 0, gen_loss = 0.48567358578244846, disc_loss = 0.13523883922025562
Trained batch 120 in epoch 0, gen_loss = 0.48590520812460214, disc_loss = 0.13542298089004745
Trained batch 121 in epoch 0, gen_loss = 0.4852799113656654, disc_loss = 0.13557577136232227
Trained batch 122 in epoch 0, gen_loss = 0.48495852002283424, disc_loss = 0.13542871549725533
Trained batch 123 in epoch 0, gen_loss = 0.48493085489157706, disc_loss = 0.13515294658681076
Trained batch 124 in epoch 0, gen_loss = 0.4844175782203674, disc_loss = 0.1360344913303852
Trained batch 125 in epoch 0, gen_loss = 0.48347735310357715, disc_loss = 0.13693201533030896
Trained batch 126 in epoch 0, gen_loss = 0.4832131156301874, disc_loss = 0.13685285566946653
Trained batch 127 in epoch 0, gen_loss = 0.48308801325038075, disc_loss = 0.1371997396054212
Trained batch 128 in epoch 0, gen_loss = 0.48297366060951885, disc_loss = 0.13778019023611565
Trained batch 129 in epoch 0, gen_loss = 0.4826746443143258, disc_loss = 0.1381213559840734
Trained batch 130 in epoch 0, gen_loss = 0.4824225270111142, disc_loss = 0.13822471688835675
Trained batch 131 in epoch 0, gen_loss = 0.4828329316594384, disc_loss = 0.13783677325894436
Trained batch 132 in epoch 0, gen_loss = 0.48322594076170955, disc_loss = 0.1375458609396802
Trained batch 133 in epoch 0, gen_loss = 0.4829406589269638, disc_loss = 0.13740589644815496
Trained batch 134 in epoch 0, gen_loss = 0.4829025818241967, disc_loss = 0.13710466730925772
Trained batch 135 in epoch 0, gen_loss = 0.4829583807903178, disc_loss = 0.13684840683880098
Trained batch 136 in epoch 0, gen_loss = 0.483516653523828, disc_loss = 0.1370878815379021
Trained batch 137 in epoch 0, gen_loss = 0.4827167575342068, disc_loss = 0.13970359034188415
Trained batch 138 in epoch 0, gen_loss = 0.4824290228404587, disc_loss = 0.13943963436235626
Trained batch 139 in epoch 0, gen_loss = 0.48269905405385155, disc_loss = 0.1392943553360445
Trained batch 140 in epoch 0, gen_loss = 0.48253538274595925, disc_loss = 0.13991270808780448
Trained batch 141 in epoch 0, gen_loss = 0.4826685452545193, disc_loss = 0.14091670940774428
Trained batch 142 in epoch 0, gen_loss = 0.482524549002414, disc_loss = 0.14230069025725753
Trained batch 143 in epoch 0, gen_loss = 0.4823178365412686, disc_loss = 0.1427208423976683
Trained batch 144 in epoch 0, gen_loss = 0.4828429532462153, disc_loss = 0.14272499153840132
Trained batch 145 in epoch 0, gen_loss = 0.48299801247577145, disc_loss = 0.14323794145188104
Trained batch 146 in epoch 0, gen_loss = 0.48308111757648237, disc_loss = 0.143600054617439
Trained batch 147 in epoch 0, gen_loss = 0.4829743999887157, disc_loss = 0.14386885771779595
Trained batch 148 in epoch 0, gen_loss = 0.482738887103612, disc_loss = 0.144136480011996
Trained batch 149 in epoch 0, gen_loss = 0.4825353107849757, disc_loss = 0.1439692059904337
Trained batch 150 in epoch 0, gen_loss = 0.48271508899745563, disc_loss = 0.14380320810422992
Trained batch 151 in epoch 0, gen_loss = 0.482750566774293, disc_loss = 0.14403454354032874
Trained batch 152 in epoch 0, gen_loss = 0.4825567782314774, disc_loss = 0.14430276243612658
Trained batch 153 in epoch 0, gen_loss = 0.4822002738327175, disc_loss = 0.14577073151511805
Trained batch 154 in epoch 0, gen_loss = 0.4820978056999945, disc_loss = 0.14640647425286232
Trained batch 155 in epoch 0, gen_loss = 0.48123753051727247, disc_loss = 0.14729848640182844
Trained batch 156 in epoch 0, gen_loss = 0.4807356316952189, disc_loss = 0.1480594805329089
Trained batch 157 in epoch 0, gen_loss = 0.48110647688183605, disc_loss = 0.14860066802158386
Trained batch 158 in epoch 0, gen_loss = 0.48108163119861913, disc_loss = 0.14868731967776827
Trained batch 159 in epoch 0, gen_loss = 0.48085529934614896, disc_loss = 0.14883317558560522
Trained batch 160 in epoch 0, gen_loss = 0.4806820039423356, disc_loss = 0.14908787351309882
Trained batch 161 in epoch 0, gen_loss = 0.48036881913373497, disc_loss = 0.14926925248661896
Trained batch 162 in epoch 0, gen_loss = 0.4801100766731918, disc_loss = 0.14989525136863527
Trained batch 163 in epoch 0, gen_loss = 0.4801636118350959, disc_loss = 0.15055954894732412
Trained batch 164 in epoch 0, gen_loss = 0.47987390305056715, disc_loss = 0.1515862934742913
Trained batch 165 in epoch 0, gen_loss = 0.47944238602396955, disc_loss = 0.15159243239785533
Trained batch 166 in epoch 0, gen_loss = 0.4794568264198874, disc_loss = 0.15264485359281124
Trained batch 167 in epoch 0, gen_loss = 0.479407506861857, disc_loss = 0.15383681781323894
Trained batch 168 in epoch 0, gen_loss = 0.4793815542254928, disc_loss = 0.15383367842206588
Trained batch 169 in epoch 0, gen_loss = 0.47979507341104394, disc_loss = 0.15397487232352006
Trained batch 170 in epoch 0, gen_loss = 0.47947968690716036, disc_loss = 0.15456333985192733
Trained batch 171 in epoch 0, gen_loss = 0.4793268605027088, disc_loss = 0.15493530686944723
Trained batch 172 in epoch 0, gen_loss = 0.4789014081389918, disc_loss = 0.15545263277054522
Trained batch 173 in epoch 0, gen_loss = 0.4790751973445388, disc_loss = 0.15641466992768063
Trained batch 174 in epoch 0, gen_loss = 0.4788903573581151, disc_loss = 0.1565083427301475
Trained batch 175 in epoch 0, gen_loss = 0.47885351306335494, disc_loss = 0.15643946015784008
Trained batch 176 in epoch 0, gen_loss = 0.4784794838751777, disc_loss = 0.15641071519019914
Trained batch 177 in epoch 0, gen_loss = 0.47804591193627777, disc_loss = 0.15696992149597475
Trained batch 178 in epoch 0, gen_loss = 0.47810234787077877, disc_loss = 0.15704317284779176
Trained batch 179 in epoch 0, gen_loss = 0.4778054186039501, disc_loss = 0.1570536355384522
Trained batch 180 in epoch 0, gen_loss = 0.47733316385284974, disc_loss = 0.15715335772594036
Trained batch 181 in epoch 0, gen_loss = 0.47664085849300847, disc_loss = 0.15777352953759524
Trained batch 182 in epoch 0, gen_loss = 0.47643167138751086, disc_loss = 0.15804502190869363
Trained batch 183 in epoch 0, gen_loss = 0.47605455391432927, disc_loss = 0.15849323937183488
Trained batch 184 in epoch 0, gen_loss = 0.4760457526993107, disc_loss = 0.15843609678181442
Trained batch 185 in epoch 0, gen_loss = 0.4761678158275543, disc_loss = 0.15834649582143112
Trained batch 186 in epoch 0, gen_loss = 0.4760622082547071, disc_loss = 0.15841470437652286
Trained batch 187 in epoch 0, gen_loss = 0.4760190489444327, disc_loss = 0.15930469724488386
Trained batch 188 in epoch 0, gen_loss = 0.47601771307370017, disc_loss = 0.15983893736093133
Trained batch 189 in epoch 0, gen_loss = 0.47543671491898987, disc_loss = 0.16039332474925017
Trained batch 190 in epoch 0, gen_loss = 0.4753761887550354, disc_loss = 0.1607606043717312
Trained batch 191 in epoch 0, gen_loss = 0.475011321871231, disc_loss = 0.1611196122636708
Trained batch 192 in epoch 0, gen_loss = 0.47469081718069284, disc_loss = 0.16133262898406217
Trained batch 193 in epoch 0, gen_loss = 0.4743454927943416, disc_loss = 0.1615528605071847
Trained batch 194 in epoch 0, gen_loss = 0.4738775283862383, disc_loss = 0.16176028880171286
Trained batch 195 in epoch 0, gen_loss = 0.47370449043050106, disc_loss = 0.16197358651504834
Trained batch 196 in epoch 0, gen_loss = 0.47334162036174443, disc_loss = 0.16217575356515532
Trained batch 197 in epoch 0, gen_loss = 0.47295069062348566, disc_loss = 0.16232166373443724
Trained batch 198 in epoch 0, gen_loss = 0.472604979821785, disc_loss = 0.16263351497713047
Trained batch 199 in epoch 0, gen_loss = 0.47229178354144097, disc_loss = 0.1626543358899653
Trained batch 200 in epoch 0, gen_loss = 0.4719680409822891, disc_loss = 0.16273127186728353
Trained batch 201 in epoch 0, gen_loss = 0.4722016322435719, disc_loss = 0.16294696936291633
Trained batch 202 in epoch 0, gen_loss = 0.4721210544626114, disc_loss = 0.16348086093813916
Trained batch 203 in epoch 0, gen_loss = 0.47192442402535795, disc_loss = 0.16376716433567742
Trained batch 204 in epoch 0, gen_loss = 0.47137466712695797, disc_loss = 0.1641071925257764
Trained batch 205 in epoch 0, gen_loss = 0.4710923797875932, disc_loss = 0.16416396376071046
Trained batch 206 in epoch 0, gen_loss = 0.4708962362745534, disc_loss = 0.16427474279982457
Trained batch 207 in epoch 0, gen_loss = 0.4707508273422718, disc_loss = 0.1648284384730057
Trained batch 208 in epoch 0, gen_loss = 0.47054617185341685, disc_loss = 0.16493537282330567
Trained batch 209 in epoch 0, gen_loss = 0.47064943867070336, disc_loss = 0.1650891182145902
Trained batch 210 in epoch 0, gen_loss = 0.4707587344386566, disc_loss = 0.16517974685224313
Trained batch 211 in epoch 0, gen_loss = 0.47033921657305844, disc_loss = 0.16544549534413613
Trained batch 212 in epoch 0, gen_loss = 0.4696935604155903, disc_loss = 0.1656036928401027
Trained batch 213 in epoch 0, gen_loss = 0.46940035407788283, disc_loss = 0.16582365572522176
Trained batch 214 in epoch 0, gen_loss = 0.46928453057311303, disc_loss = 0.1657679575993571
Trained batch 215 in epoch 0, gen_loss = 0.46908598862312456, disc_loss = 0.1657464314010684
Trained batch 216 in epoch 0, gen_loss = 0.4687189088988414, disc_loss = 0.16616297113249928
Trained batch 217 in epoch 0, gen_loss = 0.46906630107022207, disc_loss = 0.16697101884547177
Trained batch 218 in epoch 0, gen_loss = 0.46882814223363517, disc_loss = 0.1679725807721484
Trained batch 219 in epoch 0, gen_loss = 0.4685625408183445, disc_loss = 0.16817006084390662
Trained batch 220 in epoch 0, gen_loss = 0.46868300437927246, disc_loss = 0.16843361614853547
Trained batch 221 in epoch 0, gen_loss = 0.4681403167075939, disc_loss = 0.16867357849873402
Trained batch 222 in epoch 0, gen_loss = 0.4680741477440291, disc_loss = 0.16896450701649948
Trained batch 223 in epoch 0, gen_loss = 0.468059073202312, disc_loss = 0.16889089174635177
Trained batch 224 in epoch 0, gen_loss = 0.4679474817381965, disc_loss = 0.16917738353212675
Trained batch 225 in epoch 0, gen_loss = 0.4676543697055462, disc_loss = 0.16935478330515655
Trained batch 226 in epoch 0, gen_loss = 0.46795231931010006, disc_loss = 0.16942560746609378
Trained batch 227 in epoch 0, gen_loss = 0.46771077994714705, disc_loss = 0.16986234363560615
Trained batch 228 in epoch 0, gen_loss = 0.4674174939180566, disc_loss = 0.17006310815699235
Trained batch 229 in epoch 0, gen_loss = 0.4672206567681354, disc_loss = 0.17004171838255033
Trained batch 230 in epoch 0, gen_loss = 0.4669499352122798, disc_loss = 0.16987083337846257
Trained batch 231 in epoch 0, gen_loss = 0.46659587272282305, disc_loss = 0.1698997226415266
Trained batch 232 in epoch 0, gen_loss = 0.46636456366260676, disc_loss = 0.16983273204879698
Trained batch 233 in epoch 0, gen_loss = 0.46644181229619897, disc_loss = 0.16974949424401817
Trained batch 234 in epoch 0, gen_loss = 0.46640295335587034, disc_loss = 0.16993852500268752
Trained batch 235 in epoch 0, gen_loss = 0.4657559891120862, disc_loss = 0.1701157891302038
Trained batch 236 in epoch 0, gen_loss = 0.4656395004268437, disc_loss = 0.17004198076415666
Trained batch 237 in epoch 0, gen_loss = 0.4653433411061263, disc_loss = 0.1700395879280918
Trained batch 238 in epoch 0, gen_loss = 0.4650231771888094, disc_loss = 0.17014244063192333
Trained batch 239 in epoch 0, gen_loss = 0.4647930288066467, disc_loss = 0.17016219715587794
Trained batch 240 in epoch 0, gen_loss = 0.4644416652279771, disc_loss = 0.17007223651184086
Trained batch 241 in epoch 0, gen_loss = 0.4643242271724811, disc_loss = 0.1700750082146284
Trained batch 242 in epoch 0, gen_loss = 0.46434565679526624, disc_loss = 0.17034287733857523
Trained batch 243 in epoch 0, gen_loss = 0.46391987434176146, disc_loss = 0.17036905196174734
Trained batch 244 in epoch 0, gen_loss = 0.4635878915689429, disc_loss = 0.17064573711582592
Trained batch 245 in epoch 0, gen_loss = 0.4635739492449334, disc_loss = 0.17063054038075412
Trained batch 246 in epoch 0, gen_loss = 0.4637418426724098, disc_loss = 0.17054526871334202
Trained batch 247 in epoch 0, gen_loss = 0.4636087016232552, disc_loss = 0.1706458829613703
Trained batch 248 in epoch 0, gen_loss = 0.4634017044281864, disc_loss = 0.1709499885907853
Trained batch 249 in epoch 0, gen_loss = 0.4633956644535065, disc_loss = 0.1714826187044382
Trained batch 250 in epoch 0, gen_loss = 0.4632870887380197, disc_loss = 0.17158511911789734
Trained batch 251 in epoch 0, gen_loss = 0.46297317483122385, disc_loss = 0.17157686426348628
Trained batch 252 in epoch 0, gen_loss = 0.4628168472895038, disc_loss = 0.17178022297533604
Trained batch 253 in epoch 0, gen_loss = 0.46265260828292276, disc_loss = 0.17180863857327952
Trained batch 254 in epoch 0, gen_loss = 0.462330462067735, disc_loss = 0.17181668072646739
Trained batch 255 in epoch 0, gen_loss = 0.4620787352323532, disc_loss = 0.1718435465154471
Trained batch 256 in epoch 0, gen_loss = 0.46198918615333767, disc_loss = 0.171684394275284
Trained batch 257 in epoch 0, gen_loss = 0.46176791965037356, disc_loss = 0.17158937692468942
Trained batch 258 in epoch 0, gen_loss = 0.46131604058401926, disc_loss = 0.17174166609249059
Trained batch 259 in epoch 0, gen_loss = 0.46105512758860223, disc_loss = 0.17204506874371034
Trained batch 260 in epoch 0, gen_loss = 0.46090426424454, disc_loss = 0.17255461965312904
Trained batch 261 in epoch 0, gen_loss = 0.4609351395878173, disc_loss = 0.17261100305912605
Trained batch 262 in epoch 0, gen_loss = 0.4606040388685669, disc_loss = 0.17261036552007208
Trained batch 263 in epoch 0, gen_loss = 0.4605708814254313, disc_loss = 0.17256026993025886
Trained batch 264 in epoch 0, gen_loss = 0.46037430268413615, disc_loss = 0.17251770503397257
Trained batch 265 in epoch 0, gen_loss = 0.46002724083294544, disc_loss = 0.17249930707415692
Trained batch 266 in epoch 0, gen_loss = 0.45982930812049894, disc_loss = 0.1727386475418614
Trained batch 267 in epoch 0, gen_loss = 0.4598600970052961, disc_loss = 0.17335020540865945
Trained batch 268 in epoch 0, gen_loss = 0.4596345180915634, disc_loss = 0.1734096433510346
Trained batch 269 in epoch 0, gen_loss = 0.4595107942819595, disc_loss = 0.17370857343905502
Trained batch 270 in epoch 0, gen_loss = 0.45945176900092966, disc_loss = 0.17356006153670184
Trained batch 271 in epoch 0, gen_loss = 0.4592535226222347, disc_loss = 0.1735101061845746
Trained batch 272 in epoch 0, gen_loss = 0.45910701668742815, disc_loss = 0.17339885061531712
Trained batch 273 in epoch 0, gen_loss = 0.45896723833832426, disc_loss = 0.17324343401204495
Trained batch 274 in epoch 0, gen_loss = 0.4588594476743178, disc_loss = 0.17316853221167217
Trained batch 275 in epoch 0, gen_loss = 0.45844841510921286, disc_loss = 0.17315544178574413
Trained batch 276 in epoch 0, gen_loss = 0.4582731792642752, disc_loss = 0.1731644457992879
Trained batch 277 in epoch 0, gen_loss = 0.45796119823730247, disc_loss = 0.17309179833735064
Trained batch 278 in epoch 0, gen_loss = 0.4577074711040784, disc_loss = 0.17299982516836093
Trained batch 279 in epoch 0, gen_loss = 0.45766991579106875, disc_loss = 0.17279543127598507
Trained batch 280 in epoch 0, gen_loss = 0.4576783760374551, disc_loss = 0.17270410290233182
Trained batch 281 in epoch 0, gen_loss = 0.4573332962203533, disc_loss = 0.17255930831087818
Trained batch 282 in epoch 0, gen_loss = 0.4571938703211795, disc_loss = 0.17248288430141898
Trained batch 283 in epoch 0, gen_loss = 0.45745455683536934, disc_loss = 0.1726015197165625
Trained batch 284 in epoch 0, gen_loss = 0.4574015257651346, disc_loss = 0.1728464277820629
Trained batch 285 in epoch 0, gen_loss = 0.4572032579592058, disc_loss = 0.17299689270451768
Trained batch 286 in epoch 0, gen_loss = 0.45713730047388773, disc_loss = 0.1730439934606959
Trained batch 287 in epoch 0, gen_loss = 0.4570870849614342, disc_loss = 0.1730573164531961
Trained batch 288 in epoch 0, gen_loss = 0.4571240282388707, disc_loss = 0.172956294061094
Trained batch 289 in epoch 0, gen_loss = 0.45697010693878964, disc_loss = 0.17286894214821272
Trained batch 290 in epoch 0, gen_loss = 0.45674978795739796, disc_loss = 0.1728322828169336
Trained batch 291 in epoch 0, gen_loss = 0.45643881300132566, disc_loss = 0.17274915678299044
Trained batch 292 in epoch 0, gen_loss = 0.45603493964712777, disc_loss = 0.17267225775549844
Trained batch 293 in epoch 0, gen_loss = 0.4558633883185938, disc_loss = 0.1724457883333065
Trained batch 294 in epoch 0, gen_loss = 0.45587683491787667, disc_loss = 0.17227548273690677
Trained batch 295 in epoch 0, gen_loss = 0.4558393595790541, disc_loss = 0.1721829041410741
Trained batch 296 in epoch 0, gen_loss = 0.4554398239461661, disc_loss = 0.17210684660257716
Trained batch 297 in epoch 0, gen_loss = 0.45561291977463153, disc_loss = 0.17218418168091534
Trained batch 298 in epoch 0, gen_loss = 0.4553560350451581, disc_loss = 0.1725065133917491
Trained batch 299 in epoch 0, gen_loss = 0.45544073402881624, disc_loss = 0.17272153386225303
Trained batch 300 in epoch 0, gen_loss = 0.45515582232776275, disc_loss = 0.1726659246630645
Trained batch 301 in epoch 0, gen_loss = 0.45501198377830304, disc_loss = 0.17279973970294393
Trained batch 302 in epoch 0, gen_loss = 0.45478160930151984, disc_loss = 0.1732756562235922
Trained batch 303 in epoch 0, gen_loss = 0.4546506001957153, disc_loss = 0.17352474523757241
Trained batch 304 in epoch 0, gen_loss = 0.45475522172255595, disc_loss = 0.17343254913804962
Trained batch 305 in epoch 0, gen_loss = 0.45453106042216807, disc_loss = 0.17360953659160075
Trained batch 306 in epoch 0, gen_loss = 0.45445758055786356, disc_loss = 0.17355989758228635
Trained batch 307 in epoch 0, gen_loss = 0.4541867117022539, disc_loss = 0.17349197293401925
Trained batch 308 in epoch 0, gen_loss = 0.4540212945259119, disc_loss = 0.1732730019512107
Trained batch 309 in epoch 0, gen_loss = 0.45362013232323434, disc_loss = 0.17312118217589395
Trained batch 310 in epoch 0, gen_loss = 0.4535471500882765, disc_loss = 0.17296662364885737
Trained batch 311 in epoch 0, gen_loss = 0.4534981105572138, disc_loss = 0.17284098123080838
Trained batch 312 in epoch 0, gen_loss = 0.453463314725949, disc_loss = 0.17282449650450254
Trained batch 313 in epoch 0, gen_loss = 0.4534095356798476, disc_loss = 0.17279446152317676
Trained batch 314 in epoch 0, gen_loss = 0.45310614004967703, disc_loss = 0.1727998368678585
Trained batch 315 in epoch 0, gen_loss = 0.4528522593311117, disc_loss = 0.1728208793468679
Trained batch 316 in epoch 0, gen_loss = 0.45271401206025563, disc_loss = 0.17265891879561948
Trained batch 317 in epoch 0, gen_loss = 0.45260347997617423, disc_loss = 0.17251620766173745
Trained batch 318 in epoch 0, gen_loss = 0.45264114789828236, disc_loss = 0.17226053523279283
Trained batch 319 in epoch 0, gen_loss = 0.45277565708383916, disc_loss = 0.1720150720910169
Trained batch 320 in epoch 0, gen_loss = 0.45262288991535937, disc_loss = 0.1720125564835339
Trained batch 321 in epoch 0, gen_loss = 0.45218979914366086, disc_loss = 0.17259442881443857
Trained batch 322 in epoch 0, gen_loss = 0.45219168731302667, disc_loss = 0.17262222722818607
Trained batch 323 in epoch 0, gen_loss = 0.45209090163310367, disc_loss = 0.17253287372259815
Trained batch 324 in epoch 0, gen_loss = 0.45225778002005357, disc_loss = 0.17252017485407684
Trained batch 325 in epoch 0, gen_loss = 0.4522794619476868, disc_loss = 0.17242325720108725
Trained batch 326 in epoch 0, gen_loss = 0.452292355466691, disc_loss = 0.17255996907021656
Trained batch 327 in epoch 0, gen_loss = 0.45184039342694166, disc_loss = 0.17267275057596768
Trained batch 328 in epoch 0, gen_loss = 0.4519117214578263, disc_loss = 0.17245705050945645
Trained batch 329 in epoch 0, gen_loss = 0.4519812041159832, disc_loss = 0.17288261653121673
Trained batch 330 in epoch 0, gen_loss = 0.451717063469469, disc_loss = 0.1730525057053818
Trained batch 331 in epoch 0, gen_loss = 0.451616220355752, disc_loss = 0.17288911085665584
Trained batch 332 in epoch 0, gen_loss = 0.4516034963073673, disc_loss = 0.1729523551513304
Trained batch 333 in epoch 0, gen_loss = 0.45134238863062714, disc_loss = 0.1727988941784569
Trained batch 334 in epoch 0, gen_loss = 0.45098778071688184, disc_loss = 0.17274903500480437
Trained batch 335 in epoch 0, gen_loss = 0.4509277804089444, disc_loss = 0.17267955419430064
Trained batch 336 in epoch 0, gen_loss = 0.4509007190561436, disc_loss = 0.17253585899309518
Trained batch 337 in epoch 0, gen_loss = 0.45078486935979517, disc_loss = 0.1722860170208667
Trained batch 338 in epoch 0, gen_loss = 0.45064978569658104, disc_loss = 0.17229925343288785
Trained batch 339 in epoch 0, gen_loss = 0.45075336870025184, disc_loss = 0.17235429117127377
Trained batch 340 in epoch 0, gen_loss = 0.4506581952669753, disc_loss = 0.17227919754787974
Trained batch 341 in epoch 0, gen_loss = 0.4505313048411531, disc_loss = 0.1722079143908463
Trained batch 342 in epoch 0, gen_loss = 0.4502944905452061, disc_loss = 0.17223982283785808
Trained batch 343 in epoch 0, gen_loss = 0.450211385568214, disc_loss = 0.17206007643970986
Trained batch 344 in epoch 0, gen_loss = 0.4502863321615302, disc_loss = 0.17195866063669107
Trained batch 345 in epoch 0, gen_loss = 0.45007396571208974, disc_loss = 0.17186961610494667
Trained batch 346 in epoch 0, gen_loss = 0.44987123981332916, disc_loss = 0.17178132982994362
Trained batch 347 in epoch 0, gen_loss = 0.4498701483525079, disc_loss = 0.17164510200549474
Trained batch 348 in epoch 0, gen_loss = 0.4499813149173485, disc_loss = 0.1713898616034356
Trained batch 349 in epoch 0, gen_loss = 0.449782093337604, disc_loss = 0.17119444339403084
Trained batch 350 in epoch 0, gen_loss = 0.44962561979592697, disc_loss = 0.1711548868556138
Trained batch 351 in epoch 0, gen_loss = 0.44982520236887713, disc_loss = 0.17110046760221434
Trained batch 352 in epoch 0, gen_loss = 0.44964218055222593, disc_loss = 0.17084081282063518
Trained batch 353 in epoch 0, gen_loss = 0.44951005414717615, disc_loss = 0.17084825002077947
Trained batch 354 in epoch 0, gen_loss = 0.44962682816344246, disc_loss = 0.17142896145372324
Trained batch 355 in epoch 0, gen_loss = 0.4496484308430318, disc_loss = 0.1712068739671553
Trained batch 356 in epoch 0, gen_loss = 0.44940911888742313, disc_loss = 0.17114039663882816
Trained batch 357 in epoch 0, gen_loss = 0.44917212659753236, disc_loss = 0.17107261098172077
Trained batch 358 in epoch 0, gen_loss = 0.4489011952970021, disc_loss = 0.17095718303472218
Trained batch 359 in epoch 0, gen_loss = 0.4487055975529883, disc_loss = 0.17075760044778387
Trained batch 360 in epoch 0, gen_loss = 0.448586776150891, disc_loss = 0.17063928887743368
Trained batch 361 in epoch 0, gen_loss = 0.44840674069375624, disc_loss = 0.17041817207650914
Trained batch 362 in epoch 0, gen_loss = 0.4482963301918723, disc_loss = 0.17032274360622257
Trained batch 363 in epoch 0, gen_loss = 0.4482726405610095, disc_loss = 0.170479092941425
Trained batch 364 in epoch 0, gen_loss = 0.4482664569599988, disc_loss = 0.17024751435199828
Trained batch 365 in epoch 0, gen_loss = 0.4480927247004431, disc_loss = 0.1699675353844472
Trained batch 366 in epoch 0, gen_loss = 0.4481700817148432, disc_loss = 0.16981624126718545
Trained batch 367 in epoch 0, gen_loss = 0.44800412517202937, disc_loss = 0.1696235302977426
Trained batch 368 in epoch 0, gen_loss = 0.44773159626376663, disc_loss = 0.1695462002401268
Trained batch 369 in epoch 0, gen_loss = 0.4478159642702824, disc_loss = 0.1694170133588282
Trained batch 370 in epoch 0, gen_loss = 0.44780726027938556, disc_loss = 0.16919328944099882
Trained batch 371 in epoch 0, gen_loss = 0.44780258273565643, disc_loss = 0.16947040731908494
Trained batch 372 in epoch 0, gen_loss = 0.4480519730987242, disc_loss = 0.16970010562213111
Trained batch 373 in epoch 0, gen_loss = 0.4480064056295762, disc_loss = 0.16936608401928993
Trained batch 374 in epoch 0, gen_loss = 0.44791614945729574, disc_loss = 0.16931994332869849
Trained batch 375 in epoch 0, gen_loss = 0.44788217845749345, disc_loss = 0.16926423212552957
Trained batch 376 in epoch 0, gen_loss = 0.44789255274069406, disc_loss = 0.16909813738628154
Trained batch 377 in epoch 0, gen_loss = 0.44786544278185203, disc_loss = 0.16882484323448604
Trained batch 378 in epoch 0, gen_loss = 0.44776940841158963, disc_loss = 0.16874928913990866
Trained batch 379 in epoch 0, gen_loss = 0.447816495832644, disc_loss = 0.1689642848544999
Trained batch 380 in epoch 0, gen_loss = 0.4477872775764916, disc_loss = 0.16867100808212138
Trained batch 381 in epoch 0, gen_loss = 0.4476244287341053, disc_loss = 0.16858479005152954
Trained batch 382 in epoch 0, gen_loss = 0.4475179722352688, disc_loss = 0.1687264578519073
Trained batch 383 in epoch 0, gen_loss = 0.4474399137155463, disc_loss = 0.1687842525910431
Trained batch 384 in epoch 0, gen_loss = 0.4472587633442569, disc_loss = 0.1687656984216981
Trained batch 385 in epoch 0, gen_loss = 0.44721199865477074, disc_loss = 0.16855013641707328
Trained batch 386 in epoch 0, gen_loss = 0.4469531414890782, disc_loss = 0.168531577572111
Trained batch 387 in epoch 0, gen_loss = 0.4469384918968702, disc_loss = 0.16843832815161994
Trained batch 388 in epoch 0, gen_loss = 0.4467643025142062, disc_loss = 0.16827945454299909
Trained batch 389 in epoch 0, gen_loss = 0.44672052546953545, disc_loss = 0.16796713252671255
Trained batch 390 in epoch 0, gen_loss = 0.44652852705677454, disc_loss = 0.16831515903782357
Trained batch 391 in epoch 0, gen_loss = 0.4466472804090198, disc_loss = 0.16851653606269737
Trained batch 392 in epoch 0, gen_loss = 0.4466798727900624, disc_loss = 0.16832205066433692
Trained batch 393 in epoch 0, gen_loss = 0.44655783421497053, disc_loss = 0.16845887752845506
Trained batch 394 in epoch 0, gen_loss = 0.44648915891405905, disc_loss = 0.16828839447868021
Trained batch 395 in epoch 0, gen_loss = 0.44634121656417847, disc_loss = 0.16812650250703698
Trained batch 396 in epoch 0, gen_loss = 0.4462659370989283, disc_loss = 0.16796809248157052
Trained batch 397 in epoch 0, gen_loss = 0.4461533003416493, disc_loss = 0.1679044431871056
Trained batch 398 in epoch 0, gen_loss = 0.44614988259205546, disc_loss = 0.16776402015472414
Trained batch 399 in epoch 0, gen_loss = 0.4462837468832731, disc_loss = 0.16752777009271086
Trained batch 400 in epoch 0, gen_loss = 0.44611129744391786, disc_loss = 0.16723262820569357
Trained batch 401 in epoch 0, gen_loss = 0.4460305908870934, disc_loss = 0.1671279533048026
Trained batch 402 in epoch 0, gen_loss = 0.44601482005036497, disc_loss = 0.16706859676292163
Trained batch 403 in epoch 0, gen_loss = 0.4460656074161577, disc_loss = 0.16678999274010115
Trained batch 404 in epoch 0, gen_loss = 0.4460398406894119, disc_loss = 0.1666318866573734
Trained batch 405 in epoch 0, gen_loss = 0.4461077754867488, disc_loss = 0.16660858910952883
Trained batch 406 in epoch 0, gen_loss = 0.4460035500274536, disc_loss = 0.16655493646640449
Trained batch 407 in epoch 0, gen_loss = 0.44608063740180987, disc_loss = 0.16654247133170857
Trained batch 408 in epoch 0, gen_loss = 0.4460117310504167, disc_loss = 0.16645989164455013
Trained batch 409 in epoch 0, gen_loss = 0.44569227310215553, disc_loss = 0.16649940315543152
Trained batch 410 in epoch 0, gen_loss = 0.4454580993547927, disc_loss = 0.1671986238002197
Trained batch 411 in epoch 0, gen_loss = 0.44545646539880235, disc_loss = 0.16698476066360773
Trained batch 412 in epoch 0, gen_loss = 0.445448754919066, disc_loss = 0.16720999602327624
Trained batch 413 in epoch 0, gen_loss = 0.4453368947845726, disc_loss = 0.16712424060068845
Trained batch 414 in epoch 0, gen_loss = 0.44507169622972786, disc_loss = 0.16704789423439875
Trained batch 415 in epoch 0, gen_loss = 0.4447478601852289, disc_loss = 0.16708995840655497
Trained batch 416 in epoch 0, gen_loss = 0.4446769280256413, disc_loss = 0.16692510447342046
Trained batch 417 in epoch 0, gen_loss = 0.444373773544599, disc_loss = 0.16677972153898632
Trained batch 418 in epoch 0, gen_loss = 0.44420677779113477, disc_loss = 0.16666307431914643
Trained batch 419 in epoch 0, gen_loss = 0.44429609718776886, disc_loss = 0.16651047026472432
Trained batch 420 in epoch 0, gen_loss = 0.4443448460583449, disc_loss = 0.16619697960885574
Trained batch 421 in epoch 0, gen_loss = 0.44430770551988863, disc_loss = 0.16603943328615897
Trained batch 422 in epoch 0, gen_loss = 0.4442419842343522, disc_loss = 0.16586140514159878
Trained batch 423 in epoch 0, gen_loss = 0.44435498097314025, disc_loss = 0.16605469339333898
Trained batch 424 in epoch 0, gen_loss = 0.4442771741923164, disc_loss = 0.16639114289599308
Trained batch 425 in epoch 0, gen_loss = 0.44437819908202536, disc_loss = 0.16668491842916033
Trained batch 426 in epoch 0, gen_loss = 0.44421127585114023, disc_loss = 0.16681606485671963
Trained batch 427 in epoch 0, gen_loss = 0.4440809505704407, disc_loss = 0.16688427044444273
Trained batch 428 in epoch 0, gen_loss = 0.4440457866047368, disc_loss = 0.1670201470194024
Trained batch 429 in epoch 0, gen_loss = 0.4438912617605786, disc_loss = 0.16735536602520665
Trained batch 430 in epoch 0, gen_loss = 0.44373609184389046, disc_loss = 0.16766784225186449
Trained batch 431 in epoch 0, gen_loss = 0.4436433855444193, disc_loss = 0.16760431920799115
Trained batch 432 in epoch 0, gen_loss = 0.4434887236866059, disc_loss = 0.16778335265178604
Trained batch 433 in epoch 0, gen_loss = 0.44333431097219617, disc_loss = 0.1679678570376151
Trained batch 434 in epoch 0, gen_loss = 0.44318021905833277, disc_loss = 0.16806422774305288
Trained batch 435 in epoch 0, gen_loss = 0.44313002801542983, disc_loss = 0.16800540884734566
Trained batch 436 in epoch 0, gen_loss = 0.4432962643881957, disc_loss = 0.1678476255105753
Trained batch 437 in epoch 0, gen_loss = 0.44322259036917666, disc_loss = 0.16766511363968184
Trained batch 438 in epoch 0, gen_loss = 0.44307682474816307, disc_loss = 0.16762626141411568
Trained batch 439 in epoch 0, gen_loss = 0.44285017319700937, disc_loss = 0.16773166189986197
Trained batch 440 in epoch 0, gen_loss = 0.44277575686405035, disc_loss = 0.16764539822327848
Trained batch 441 in epoch 0, gen_loss = 0.442560443511376, disc_loss = 0.16790703745617855
Trained batch 442 in epoch 0, gen_loss = 0.44238898084072176, disc_loss = 0.16821368766052996
Trained batch 443 in epoch 0, gen_loss = 0.4423719996938834, disc_loss = 0.16813129821775463
Trained batch 444 in epoch 0, gen_loss = 0.4423827307947566, disc_loss = 0.16799929362167135
Trained batch 445 in epoch 0, gen_loss = 0.4423089517873499, disc_loss = 0.1680062837781794
Trained batch 446 in epoch 0, gen_loss = 0.4421137162636324, disc_loss = 0.1680481771144691
Trained batch 447 in epoch 0, gen_loss = 0.4419476803658264, disc_loss = 0.16793975331321626
Trained batch 448 in epoch 0, gen_loss = 0.4419374887422889, disc_loss = 0.16785085656761062
Trained batch 449 in epoch 0, gen_loss = 0.44184778259860147, disc_loss = 0.16773165110912588
Trained batch 450 in epoch 0, gen_loss = 0.44186622955053717, disc_loss = 0.1675745134723028
Trained batch 451 in epoch 0, gen_loss = 0.4416689415157369, disc_loss = 0.16787308839405268
Trained batch 452 in epoch 0, gen_loss = 0.4414476595703866, disc_loss = 0.168151400892874
Trained batch 453 in epoch 0, gen_loss = 0.4415589598569576, disc_loss = 0.16805105931269176
Trained batch 454 in epoch 0, gen_loss = 0.4415431870863988, disc_loss = 0.16778721946117642
Trained batch 455 in epoch 0, gen_loss = 0.4415610287534563, disc_loss = 0.16765954277657888
Trained batch 456 in epoch 0, gen_loss = 0.4415874479896913, disc_loss = 0.16753658594429102
Trained batch 457 in epoch 0, gen_loss = 0.44157012379585914, disc_loss = 0.1675885315236176
Trained batch 458 in epoch 0, gen_loss = 0.44155683464214435, disc_loss = 0.16744905371778931
Trained batch 459 in epoch 0, gen_loss = 0.441417992633322, disc_loss = 0.1672224325573315
Trained batch 460 in epoch 0, gen_loss = 0.44143660511991206, disc_loss = 0.16713118617000652
Trained batch 461 in epoch 0, gen_loss = 0.44140873888096255, disc_loss = 0.16709196292573497
Trained batch 462 in epoch 0, gen_loss = 0.44135423735202517, disc_loss = 0.16692221247576997
Trained batch 463 in epoch 0, gen_loss = 0.4414251158977377, disc_loss = 0.16670949125244958
Trained batch 464 in epoch 0, gen_loss = 0.441328150674861, disc_loss = 0.1665387995060413
Trained batch 465 in epoch 0, gen_loss = 0.44124703006938804, disc_loss = 0.16631510621936024
Trained batch 466 in epoch 0, gen_loss = 0.44109335516198545, disc_loss = 0.16645691135391688
Trained batch 467 in epoch 0, gen_loss = 0.44119040954571503, disc_loss = 0.16655802998978358
Trained batch 468 in epoch 0, gen_loss = 0.44109397853361265, disc_loss = 0.16641745717922
Trained batch 469 in epoch 0, gen_loss = 0.44102877156531556, disc_loss = 0.16647950375967838
Trained batch 470 in epoch 0, gen_loss = 0.44095131356245393, disc_loss = 0.1663646792593529
Trained batch 471 in epoch 0, gen_loss = 0.44103277177881384, disc_loss = 0.16614305838879387
Trained batch 472 in epoch 0, gen_loss = 0.4409546245984245, disc_loss = 0.16593060497564696
Trained batch 473 in epoch 0, gen_loss = 0.44093187668906986, disc_loss = 0.16574292884597294
Trained batch 474 in epoch 0, gen_loss = 0.4409935635014584, disc_loss = 0.16556228185954847
Trained batch 475 in epoch 0, gen_loss = 0.44101218447214413, disc_loss = 0.16535893088879705
Trained batch 476 in epoch 0, gen_loss = 0.4409102447627725, disc_loss = 0.1651616855612341
Trained batch 477 in epoch 0, gen_loss = 0.44070789903776414, disc_loss = 0.1651023791237855
Trained batch 478 in epoch 0, gen_loss = 0.44085092683923516, disc_loss = 0.16510741297536702
Trained batch 479 in epoch 0, gen_loss = 0.4408740579461058, disc_loss = 0.16503836571549377
Trained batch 480 in epoch 0, gen_loss = 0.44078312736786823, disc_loss = 0.16495026078020955
Trained batch 481 in epoch 0, gen_loss = 0.4406187167058842, disc_loss = 0.16487882212113542
Trained batch 482 in epoch 0, gen_loss = 0.4405707275768738, disc_loss = 0.164668742559588
Trained batch 483 in epoch 0, gen_loss = 0.4405881437388333, disc_loss = 0.16456392806115722
Trained batch 484 in epoch 0, gen_loss = 0.4404896451025894, disc_loss = 0.16493249331245718
Trained batch 485 in epoch 0, gen_loss = 0.4405191137221615, disc_loss = 0.16490065682020208
Trained batch 486 in epoch 0, gen_loss = 0.44052516973483735, disc_loss = 0.16478266675614234
Trained batch 487 in epoch 0, gen_loss = 0.4403664545446146, disc_loss = 0.1648541313336521
Trained batch 488 in epoch 0, gen_loss = 0.44028017832945215, disc_loss = 0.16498149967998083
Trained batch 489 in epoch 0, gen_loss = 0.44029625696795327, disc_loss = 0.16484226126755988
Trained batch 490 in epoch 0, gen_loss = 0.4402750307455082, disc_loss = 0.16464153662050815
Trained batch 491 in epoch 0, gen_loss = 0.44030927048950663, disc_loss = 0.1644493785603502
Trained batch 492 in epoch 0, gen_loss = 0.4402946936189524, disc_loss = 0.16440074334703159
Trained batch 493 in epoch 0, gen_loss = 0.4401793091403328, disc_loss = 0.16437566670992595
Trained batch 494 in epoch 0, gen_loss = 0.44006404539551397, disc_loss = 0.16430291384458542
Trained batch 495 in epoch 0, gen_loss = 0.4400478987804344, disc_loss = 0.1642406537317701
Trained batch 496 in epoch 0, gen_loss = 0.44001681721906066, disc_loss = 0.16437419431969913
Trained batch 497 in epoch 0, gen_loss = 0.4399109474985475, disc_loss = 0.16424820370164261
Trained batch 498 in epoch 0, gen_loss = 0.43979845633487663, disc_loss = 0.16415431172790412
Trained batch 499 in epoch 0, gen_loss = 0.4397689182162285, disc_loss = 0.16409542337059974
Trained batch 500 in epoch 0, gen_loss = 0.4396791055411874, disc_loss = 0.16397077942679741
Trained batch 501 in epoch 0, gen_loss = 0.4397255436357749, disc_loss = 0.16382458325163776
Trained batch 502 in epoch 0, gen_loss = 0.43958086865559726, disc_loss = 0.16374168496127156
Trained batch 503 in epoch 0, gen_loss = 0.43943923126373974, disc_loss = 0.16360583812707946
Trained batch 504 in epoch 0, gen_loss = 0.4393021098457941, disc_loss = 0.1635845109377757
Trained batch 505 in epoch 0, gen_loss = 0.43923945130095654, disc_loss = 0.1635439728383019
Trained batch 506 in epoch 0, gen_loss = 0.43924907907931765, disc_loss = 0.16338098275473367
Trained batch 507 in epoch 0, gen_loss = 0.4391720876919003, disc_loss = 0.1632390685936832
Trained batch 508 in epoch 0, gen_loss = 0.43914722078909807, disc_loss = 0.1630467120814183
Trained batch 509 in epoch 0, gen_loss = 0.4391741416617936, disc_loss = 0.16289824418285315
Trained batch 510 in epoch 0, gen_loss = 0.4391450064289593, disc_loss = 0.16290231485014559
Trained batch 511 in epoch 0, gen_loss = 0.4389969629701227, disc_loss = 0.16314368539315183
Trained batch 512 in epoch 0, gen_loss = 0.43907175298787465, disc_loss = 0.1630910772242044
Trained batch 513 in epoch 0, gen_loss = 0.4389826091810887, disc_loss = 0.16307585980699685
Trained batch 514 in epoch 0, gen_loss = 0.43886473410337873, disc_loss = 0.1631707379106179
Trained batch 515 in epoch 0, gen_loss = 0.43873365777869555, disc_loss = 0.16308337035625017
Trained batch 516 in epoch 0, gen_loss = 0.4385685378854925, disc_loss = 0.1630658153840836
Trained batch 517 in epoch 0, gen_loss = 0.4385954096165403, disc_loss = 0.16297343835004507
Trained batch 518 in epoch 0, gen_loss = 0.438564111042574, disc_loss = 0.1628626263296673
Trained batch 519 in epoch 0, gen_loss = 0.43850824878765987, disc_loss = 0.16275990530848503
Trained batch 520 in epoch 0, gen_loss = 0.4385767184955831, disc_loss = 0.16266137704739414
Trained batch 521 in epoch 0, gen_loss = 0.43852891821514145, disc_loss = 0.1624632427732949
Trained batch 522 in epoch 0, gen_loss = 0.4385523664449871, disc_loss = 0.16234609162004
Trained batch 523 in epoch 0, gen_loss = 0.4385847026723942, disc_loss = 0.1623044296857396
Trained batch 524 in epoch 0, gen_loss = 0.43859352690832953, disc_loss = 0.1623023130425385
Trained batch 525 in epoch 0, gen_loss = 0.43849046805965586, disc_loss = 0.16210426208864145
Trained batch 526 in epoch 0, gen_loss = 0.4382828523809589, disc_loss = 0.1620346490413912
Trained batch 527 in epoch 0, gen_loss = 0.43832795818646747, disc_loss = 0.16199826477377705
Trained batch 528 in epoch 0, gen_loss = 0.4383203293740862, disc_loss = 0.16185215546525944
Trained batch 529 in epoch 0, gen_loss = 0.438295864215437, disc_loss = 0.16177114182204572
Trained batch 530 in epoch 0, gen_loss = 0.4383655418896181, disc_loss = 0.1625307529126408
Trained batch 531 in epoch 0, gen_loss = 0.4382590519866549, disc_loss = 0.16312322537309693
Trained batch 532 in epoch 0, gen_loss = 0.4381444832173789, disc_loss = 0.16313247068122896
Trained batch 533 in epoch 0, gen_loss = 0.43816429131039963, disc_loss = 0.1634990686362379
Trained batch 534 in epoch 0, gen_loss = 0.43805210796472066, disc_loss = 0.16366403176684247
Trained batch 535 in epoch 0, gen_loss = 0.4380813262133456, disc_loss = 0.16353356578290018
Trained batch 536 in epoch 0, gen_loss = 0.4381945464531137, disc_loss = 0.16338188770041565
Trained batch 537 in epoch 0, gen_loss = 0.4382235639932874, disc_loss = 0.16336880620139682
Trained batch 538 in epoch 0, gen_loss = 0.438141315180207, disc_loss = 0.16350150798103583
Trained batch 539 in epoch 0, gen_loss = 0.43790162012532907, disc_loss = 0.1636677624312816
Trained batch 540 in epoch 0, gen_loss = 0.43765959154656103, disc_loss = 0.16380122335638003
Trained batch 541 in epoch 0, gen_loss = 0.4376951247673633, disc_loss = 0.1638195051835692
Trained batch 542 in epoch 0, gen_loss = 0.437525220832772, disc_loss = 0.1638370979145087
Trained batch 543 in epoch 0, gen_loss = 0.43744123354554176, disc_loss = 0.1638541558127412
Trained batch 544 in epoch 0, gen_loss = 0.43734371733228, disc_loss = 0.16399859172215156
Trained batch 545 in epoch 0, gen_loss = 0.4372763002202624, disc_loss = 0.16426559113266267
Trained batch 546 in epoch 0, gen_loss = 0.4371982811791805, disc_loss = 0.16429234328773384
Trained batch 547 in epoch 0, gen_loss = 0.4371529409158839, disc_loss = 0.16426442828654808
Trained batch 548 in epoch 0, gen_loss = 0.43705078215764087, disc_loss = 0.16430807812563492
Trained batch 549 in epoch 0, gen_loss = 0.437093583128669, disc_loss = 0.16431517550891095
Trained batch 550 in epoch 0, gen_loss = 0.4370568065807737, disc_loss = 0.1642040359752148
Trained batch 551 in epoch 0, gen_loss = 0.4369360998380875, disc_loss = 0.16402877747094718
Trained batch 552 in epoch 0, gen_loss = 0.437001102710072, disc_loss = 0.16394070147875206
Trained batch 553 in epoch 0, gen_loss = 0.4369501381682145, disc_loss = 0.16380736052936165
Trained batch 554 in epoch 0, gen_loss = 0.43705104299493736, disc_loss = 0.16401110580107114
Trained batch 555 in epoch 0, gen_loss = 0.4370765798597885, disc_loss = 0.16413157059402345
Trained batch 556 in epoch 0, gen_loss = 0.4369531381387043, disc_loss = 0.1641546086118936
Trained batch 557 in epoch 0, gen_loss = 0.43688025376275447, disc_loss = 0.1641294282316948
Trained batch 558 in epoch 0, gen_loss = 0.4368209096741378, disc_loss = 0.16422331563741874
Trained batch 559 in epoch 0, gen_loss = 0.43669188512223106, disc_loss = 0.16416468885061997
Trained batch 560 in epoch 0, gen_loss = 0.4366637268062156, disc_loss = 0.1641246263010829
Trained batch 561 in epoch 0, gen_loss = 0.4364388103586923, disc_loss = 0.16403812274761048
Trained batch 562 in epoch 0, gen_loss = 0.4363614415508392, disc_loss = 0.16407560411556152
Trained batch 563 in epoch 0, gen_loss = 0.4362842195951347, disc_loss = 0.16406036243635289
Trained batch 564 in epoch 0, gen_loss = 0.43615663642376923, disc_loss = 0.16399507811375424
Trained batch 565 in epoch 0, gen_loss = 0.4361706841539578, disc_loss = 0.16398857042930573
Trained batch 566 in epoch 0, gen_loss = 0.4360530228211135, disc_loss = 0.16393938451690018
Trained batch 567 in epoch 0, gen_loss = 0.43597143222118767, disc_loss = 0.16390563045221734
Trained batch 568 in epoch 0, gen_loss = 0.43588784860810414, disc_loss = 0.16381588208968695
Trained batch 569 in epoch 0, gen_loss = 0.43592225470040974, disc_loss = 0.16377691890586887
Trained batch 570 in epoch 0, gen_loss = 0.43594264107284947, disc_loss = 0.1638614649112922
Trained batch 571 in epoch 0, gen_loss = 0.4359712822141347, disc_loss = 0.16395605298189017
Trained batch 572 in epoch 0, gen_loss = 0.4358540102449387, disc_loss = 0.16398696656002423
Trained batch 573 in epoch 0, gen_loss = 0.435936641661963, disc_loss = 0.16391940238376113
Trained batch 574 in epoch 0, gen_loss = 0.4358734754894091, disc_loss = 0.16376359119363454
Trained batch 575 in epoch 0, gen_loss = 0.43571053988610703, disc_loss = 0.16374528380886963
Trained batch 576 in epoch 0, gen_loss = 0.43579377520642204, disc_loss = 0.16364614072819103
Trained batch 577 in epoch 0, gen_loss = 0.43567616391965674, disc_loss = 0.16355825656425582
Trained batch 578 in epoch 0, gen_loss = 0.43564329693972137, disc_loss = 0.16356168424836096
Trained batch 579 in epoch 0, gen_loss = 0.43567809585867256, disc_loss = 0.1637756594553076
Trained batch 580 in epoch 0, gen_loss = 0.4356166631650186, disc_loss = 0.16359143493866962
Trained batch 581 in epoch 0, gen_loss = 0.43541843569565475, disc_loss = 0.16350838324355915
Trained batch 582 in epoch 0, gen_loss = 0.4353374649177898, disc_loss = 0.16333524200356028
Trained batch 583 in epoch 0, gen_loss = 0.43533826716346286, disc_loss = 0.1632294821336049
Trained batch 584 in epoch 0, gen_loss = 0.43544426198698516, disc_loss = 0.16314554951893978
Trained batch 585 in epoch 0, gen_loss = 0.4354167365987146, disc_loss = 0.16304383679919277
Trained batch 586 in epoch 0, gen_loss = 0.43540003905913693, disc_loss = 0.16290486918752806
Trained batch 587 in epoch 0, gen_loss = 0.4353906285195124, disc_loss = 0.16302425126690848
Trained batch 588 in epoch 0, gen_loss = 0.4353733318770883, disc_loss = 0.16323478301079447
Trained batch 589 in epoch 0, gen_loss = 0.4353642542483443, disc_loss = 0.16331825810721365
Trained batch 590 in epoch 0, gen_loss = 0.4352446037601497, disc_loss = 0.16333674662155548
Trained batch 591 in epoch 0, gen_loss = 0.4351653749676975, disc_loss = 0.1632541894686182
Trained batch 592 in epoch 0, gen_loss = 0.4351244829155341, disc_loss = 0.16322205489592448
Trained batch 593 in epoch 0, gen_loss = 0.43516897397611276, disc_loss = 0.16299791304200184
Trained batch 594 in epoch 0, gen_loss = 0.4350927507176119, disc_loss = 0.16297682036622232
Trained batch 595 in epoch 0, gen_loss = 0.4352104343823939, disc_loss = 0.1629851691349841
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.4456862211227417, disc_loss = 0.049944210797548294
Trained batch 1 in epoch 1, gen_loss = 0.4455128163099289, disc_loss = 0.07439392618834972
Trained batch 2 in epoch 1, gen_loss = 0.4488734304904938, disc_loss = 0.0757173237701257
Trained batch 3 in epoch 1, gen_loss = 0.4566127583384514, disc_loss = 0.08993337955325842
Trained batch 4 in epoch 1, gen_loss = 0.44166103601455686, disc_loss = 0.1385637752711773
Trained batch 5 in epoch 1, gen_loss = 0.4506814231475194, disc_loss = 0.1324609499424696
Trained batch 6 in epoch 1, gen_loss = 0.4441445895603725, disc_loss = 0.13003347867301532
Trained batch 7 in epoch 1, gen_loss = 0.4347264729440212, disc_loss = 0.12475828127935529
Trained batch 8 in epoch 1, gen_loss = 0.4313567943043179, disc_loss = 0.12819494348433283
Trained batch 9 in epoch 1, gen_loss = 0.43535032868385315, disc_loss = 0.1287016484886408
Trained batch 10 in epoch 1, gen_loss = 0.43051422184163873, disc_loss = 0.12610311907800761
Trained batch 11 in epoch 1, gen_loss = 0.4298710922400157, disc_loss = 0.12562871320794025
Trained batch 12 in epoch 1, gen_loss = 0.43033579221138585, disc_loss = 0.1328022167659723
Trained batch 13 in epoch 1, gen_loss = 0.42863394958632334, disc_loss = 0.13132304778056486
Trained batch 14 in epoch 1, gen_loss = 0.42641149163246156, disc_loss = 0.13149922663966815
Trained batch 15 in epoch 1, gen_loss = 0.42987012304365635, disc_loss = 0.1264819644857198
Trained batch 16 in epoch 1, gen_loss = 0.42821771958295035, disc_loss = 0.12239916184369255
Trained batch 17 in epoch 1, gen_loss = 0.42926878068182206, disc_loss = 0.12104986111323039
Trained batch 18 in epoch 1, gen_loss = 0.43062770837231684, disc_loss = 0.1204378099033707
Trained batch 19 in epoch 1, gen_loss = 0.42986622601747515, disc_loss = 0.12303474433720112
Trained batch 20 in epoch 1, gen_loss = 0.4326094119321732, disc_loss = 0.1269863329472996
Trained batch 21 in epoch 1, gen_loss = 0.4310272810134021, disc_loss = 0.12531118602915245
Trained batch 22 in epoch 1, gen_loss = 0.42897137092507404, disc_loss = 0.12418268815330837
Trained batch 23 in epoch 1, gen_loss = 0.4323136731982231, disc_loss = 0.12292267630497615
Trained batch 24 in epoch 1, gen_loss = 0.42960389256477355, disc_loss = 0.12300991296768188
Trained batch 25 in epoch 1, gen_loss = 0.42785350061379945, disc_loss = 0.12173258112027095
Trained batch 26 in epoch 1, gen_loss = 0.42672139516583196, disc_loss = 0.12089162844198721
Trained batch 27 in epoch 1, gen_loss = 0.4267022524561201, disc_loss = 0.11970037727483682
Trained batch 28 in epoch 1, gen_loss = 0.4272753699072476, disc_loss = 0.11945493801914413
Trained batch 29 in epoch 1, gen_loss = 0.42687491575876874, disc_loss = 0.1196732498705387
Trained batch 30 in epoch 1, gen_loss = 0.4293969888840952, disc_loss = 0.11852480543236579
Trained batch 31 in epoch 1, gen_loss = 0.43175568245351315, disc_loss = 0.11837623547762632
Trained batch 32 in epoch 1, gen_loss = 0.4316961169242859, disc_loss = 0.11741510056185
Trained batch 33 in epoch 1, gen_loss = 0.43314441600266623, disc_loss = 0.11631593261571492
Trained batch 34 in epoch 1, gen_loss = 0.4353072532585689, disc_loss = 0.1146737491445882
Trained batch 35 in epoch 1, gen_loss = 0.4375853579905298, disc_loss = 0.11318362504243851
Trained batch 36 in epoch 1, gen_loss = 0.4376790958481866, disc_loss = 0.11282007899638768
Trained batch 37 in epoch 1, gen_loss = 0.43490693757408544, disc_loss = 0.1194145810839377
Trained batch 38 in epoch 1, gen_loss = 0.4366009281231807, disc_loss = 0.12096281750844075
Trained batch 39 in epoch 1, gen_loss = 0.4383523792028427, disc_loss = 0.11878718212246894
Trained batch 40 in epoch 1, gen_loss = 0.43750636606681637, disc_loss = 0.11655473068538236
Trained batch 41 in epoch 1, gen_loss = 0.4385719143209003, disc_loss = 0.11593903898305837
Trained batch 42 in epoch 1, gen_loss = 0.43873005550961164, disc_loss = 0.11688413813190404
Trained batch 43 in epoch 1, gen_loss = 0.4390030421993949, disc_loss = 0.11626062927428972
Trained batch 44 in epoch 1, gen_loss = 0.4402711285485162, disc_loss = 0.11428590541084607
Trained batch 45 in epoch 1, gen_loss = 0.4418211151724276, disc_loss = 0.1127541029582853
Trained batch 46 in epoch 1, gen_loss = 0.44174850240666813, disc_loss = 0.11059896752951627
Trained batch 47 in epoch 1, gen_loss = 0.4423345463971297, disc_loss = 0.10969297690705086
Trained batch 48 in epoch 1, gen_loss = 0.44176425191820884, disc_loss = 0.10803583289059449
Trained batch 49 in epoch 1, gen_loss = 0.44168224692344665, disc_loss = 0.10620793612673879
Trained batch 50 in epoch 1, gen_loss = 0.44359880218318865, disc_loss = 0.10440885514824413
Trained batch 51 in epoch 1, gen_loss = 0.4444936284652123, disc_loss = 0.10286821738386956
Trained batch 52 in epoch 1, gen_loss = 0.4433276169704941, disc_loss = 0.10461217866121035
Trained batch 53 in epoch 1, gen_loss = 0.4441323600433491, disc_loss = 0.1066924758358962
Trained batch 54 in epoch 1, gen_loss = 0.4443701180544766, disc_loss = 0.10528431892056357
Trained batch 55 in epoch 1, gen_loss = 0.442790370966707, disc_loss = 0.10428865930797267
Trained batch 56 in epoch 1, gen_loss = 0.4443354313833672, disc_loss = 0.1063089824134582
Trained batch 57 in epoch 1, gen_loss = 0.44426428244031707, disc_loss = 0.10683283811948936
Trained batch 58 in epoch 1, gen_loss = 0.44591078010656066, disc_loss = 0.10640423351867219
Trained batch 59 in epoch 1, gen_loss = 0.44439538071552914, disc_loss = 0.10684566620426873
Trained batch 60 in epoch 1, gen_loss = 0.4442825478608491, disc_loss = 0.10678886413024585
Trained batch 61 in epoch 1, gen_loss = 0.44408995634125126, disc_loss = 0.10739078443317164
Trained batch 62 in epoch 1, gen_loss = 0.4447207394100371, disc_loss = 0.10666213206769455
Trained batch 63 in epoch 1, gen_loss = 0.4445502860471606, disc_loss = 0.10605882747040596
Trained batch 64 in epoch 1, gen_loss = 0.44404844045639036, disc_loss = 0.1056520288810134
Trained batch 65 in epoch 1, gen_loss = 0.4438461282036521, disc_loss = 0.10828165403764808
Trained batch 66 in epoch 1, gen_loss = 0.4431395539596899, disc_loss = 0.1089470451975714
Trained batch 67 in epoch 1, gen_loss = 0.4419627614757594, disc_loss = 0.10910375250558205
Trained batch 68 in epoch 1, gen_loss = 0.441387512113737, disc_loss = 0.10895681541844987
Trained batch 69 in epoch 1, gen_loss = 0.44077223539352417, disc_loss = 0.1094118232040533
Trained batch 70 in epoch 1, gen_loss = 0.440720689548573, disc_loss = 0.11235337052494287
Trained batch 71 in epoch 1, gen_loss = 0.44170563626620507, disc_loss = 0.11152960751981784
Trained batch 72 in epoch 1, gen_loss = 0.4407219421373655, disc_loss = 0.11092077572000762
Trained batch 73 in epoch 1, gen_loss = 0.44007857828526886, disc_loss = 0.11069109933954235
Trained batch 74 in epoch 1, gen_loss = 0.4391727558771769, disc_loss = 0.11030657180895408
Trained batch 75 in epoch 1, gen_loss = 0.43834749726872696, disc_loss = 0.11147884993911966
Trained batch 76 in epoch 1, gen_loss = 0.4386110398676488, disc_loss = 0.11106058218601075
Trained batch 77 in epoch 1, gen_loss = 0.4390772114961575, disc_loss = 0.11070948904857804
Trained batch 78 in epoch 1, gen_loss = 0.4403226609471478, disc_loss = 0.11364823757800498
Trained batch 79 in epoch 1, gen_loss = 0.44043403305113316, disc_loss = 0.11407911506248639
Trained batch 80 in epoch 1, gen_loss = 0.4407261805033978, disc_loss = 0.11379002898149652
Trained batch 81 in epoch 1, gen_loss = 0.4407202009020782, disc_loss = 0.11340461806507736
Trained batch 82 in epoch 1, gen_loss = 0.4408746293510299, disc_loss = 0.11317976437374411
Trained batch 83 in epoch 1, gen_loss = 0.44099982118322734, disc_loss = 0.113307993049689
Trained batch 84 in epoch 1, gen_loss = 0.4403796094305375, disc_loss = 0.11339565409237848
Trained batch 85 in epoch 1, gen_loss = 0.4400956308425859, disc_loss = 0.11305045950508048
Trained batch 86 in epoch 1, gen_loss = 0.4407401917309597, disc_loss = 0.11229321565050845
Trained batch 87 in epoch 1, gen_loss = 0.4404769130051136, disc_loss = 0.1124597049466419
Trained batch 88 in epoch 1, gen_loss = 0.44161829285407334, disc_loss = 0.11343357083126065
Trained batch 89 in epoch 1, gen_loss = 0.44154761532942455, disc_loss = 0.11319142686617044
Trained batch 90 in epoch 1, gen_loss = 0.4417847319618686, disc_loss = 0.11266766872338868
Trained batch 91 in epoch 1, gen_loss = 0.44168640090071637, disc_loss = 0.11295111630233409
Trained batch 92 in epoch 1, gen_loss = 0.44131824854881535, disc_loss = 0.11316523331427766
Trained batch 93 in epoch 1, gen_loss = 0.44112917463830176, disc_loss = 0.11310105532051083
Trained batch 94 in epoch 1, gen_loss = 0.44206762815776623, disc_loss = 0.112447871179565
Trained batch 95 in epoch 1, gen_loss = 0.4414754630997777, disc_loss = 0.11450905243206459
Trained batch 96 in epoch 1, gen_loss = 0.4426144057327939, disc_loss = 0.11568053926043596
Trained batch 97 in epoch 1, gen_loss = 0.4425730562331725, disc_loss = 0.115274119884612
Trained batch 98 in epoch 1, gen_loss = 0.4425965333827818, disc_loss = 0.11474943671827063
Trained batch 99 in epoch 1, gen_loss = 0.44266499161720274, disc_loss = 0.11458062744699418
Trained batch 100 in epoch 1, gen_loss = 0.44263381562610665, disc_loss = 0.11529606380638215
Trained batch 101 in epoch 1, gen_loss = 0.4417555381854375, disc_loss = 0.11604952278053936
Trained batch 102 in epoch 1, gen_loss = 0.4412684530309103, disc_loss = 0.11707123411475744
Trained batch 103 in epoch 1, gen_loss = 0.4413419064994042, disc_loss = 0.11721478738428022
Trained batch 104 in epoch 1, gen_loss = 0.4411978795414879, disc_loss = 0.11630487687708367
Trained batch 105 in epoch 1, gen_loss = 0.44103803668382036, disc_loss = 0.11559678365494001
Trained batch 106 in epoch 1, gen_loss = 0.44085722326118254, disc_loss = 0.11489031899929325
Trained batch 107 in epoch 1, gen_loss = 0.44061528891324997, disc_loss = 0.11486012858545615
Trained batch 108 in epoch 1, gen_loss = 0.4398593970941841, disc_loss = 0.11488944016089407
Trained batch 109 in epoch 1, gen_loss = 0.4399185752326792, disc_loss = 0.11571069140495224
Trained batch 110 in epoch 1, gen_loss = 0.4396185869569177, disc_loss = 0.11735569918108685
Trained batch 111 in epoch 1, gen_loss = 0.43957430656467167, disc_loss = 0.11712480021274782
Trained batch 112 in epoch 1, gen_loss = 0.438684982272376, disc_loss = 0.11726249573933603
Trained batch 113 in epoch 1, gen_loss = 0.43835382712514775, disc_loss = 0.116978878555656
Trained batch 114 in epoch 1, gen_loss = 0.4382229830907739, disc_loss = 0.11675704255214205
Trained batch 115 in epoch 1, gen_loss = 0.43761153390695307, disc_loss = 0.11678352262343056
Trained batch 116 in epoch 1, gen_loss = 0.43677279022004867, disc_loss = 0.11683629762827076
Trained batch 117 in epoch 1, gen_loss = 0.43681631881301686, disc_loss = 0.11622721835244763
Trained batch 118 in epoch 1, gen_loss = 0.4369804936797679, disc_loss = 0.11562874388074924
Trained batch 119 in epoch 1, gen_loss = 0.43666796013712883, disc_loss = 0.1151018045609817
Trained batch 120 in epoch 1, gen_loss = 0.43648320190177475, disc_loss = 0.11477626069672098
Trained batch 121 in epoch 1, gen_loss = 0.43682437011452974, disc_loss = 0.11455727506764844
Trained batch 122 in epoch 1, gen_loss = 0.43680842693259075, disc_loss = 0.11435054621954517
Trained batch 123 in epoch 1, gen_loss = 0.43671525077473733, disc_loss = 0.1138837970868354
Trained batch 124 in epoch 1, gen_loss = 0.4365794606208801, disc_loss = 0.11378788734227419
Trained batch 125 in epoch 1, gen_loss = 0.4367431752265446, disc_loss = 0.11354842167791157
Trained batch 126 in epoch 1, gen_loss = 0.43736842626661765, disc_loss = 0.11335569345135624
Trained batch 127 in epoch 1, gen_loss = 0.437228474766016, disc_loss = 0.11340187921450706
Trained batch 128 in epoch 1, gen_loss = 0.4377615451812744, disc_loss = 0.11347711063892574
Trained batch 129 in epoch 1, gen_loss = 0.4381513221905782, disc_loss = 0.11300670717341396
Trained batch 130 in epoch 1, gen_loss = 0.4381252945834444, disc_loss = 0.1126247197460696
Trained batch 131 in epoch 1, gen_loss = 0.43883516481428436, disc_loss = 0.11265321330618903
Trained batch 132 in epoch 1, gen_loss = 0.4379438056533498, disc_loss = 0.11219663022408136
Trained batch 133 in epoch 1, gen_loss = 0.437054513328111, disc_loss = 0.11407838751381236
Trained batch 134 in epoch 1, gen_loss = 0.4370659410953522, disc_loss = 0.11499335203595736
Trained batch 135 in epoch 1, gen_loss = 0.4379521430853535, disc_loss = 0.11471121468553867
Trained batch 136 in epoch 1, gen_loss = 0.43751241429878845, disc_loss = 0.11495202546599355
Trained batch 137 in epoch 1, gen_loss = 0.4373315408609916, disc_loss = 0.11484453368905014
Trained batch 138 in epoch 1, gen_loss = 0.43676761071458997, disc_loss = 0.11472488002409395
Trained batch 139 in epoch 1, gen_loss = 0.4368646930371012, disc_loss = 0.11576470153273216
Trained batch 140 in epoch 1, gen_loss = 0.43661777897084014, disc_loss = 0.11549958656046619
Trained batch 141 in epoch 1, gen_loss = 0.43694629719559575, disc_loss = 0.11558159142339104
Trained batch 142 in epoch 1, gen_loss = 0.43672362866101566, disc_loss = 0.11568922560557827
Trained batch 143 in epoch 1, gen_loss = 0.43637811785770786, disc_loss = 0.11604000364766559
Trained batch 144 in epoch 1, gen_loss = 0.43671984138159914, disc_loss = 0.11587527086637144
Trained batch 145 in epoch 1, gen_loss = 0.43646070769388384, disc_loss = 0.11543296870124871
Trained batch 146 in epoch 1, gen_loss = 0.4367061222897095, disc_loss = 0.11547129130510449
Trained batch 147 in epoch 1, gen_loss = 0.4367478491889464, disc_loss = 0.11655367246979999
Trained batch 148 in epoch 1, gen_loss = 0.4369775892904141, disc_loss = 0.11697155177818248
Trained batch 149 in epoch 1, gen_loss = 0.4366549054781596, disc_loss = 0.11700291152422627
Trained batch 150 in epoch 1, gen_loss = 0.43664977053143333, disc_loss = 0.11768555873696575
Trained batch 151 in epoch 1, gen_loss = 0.4360802087344621, disc_loss = 0.1176849665475617
Trained batch 152 in epoch 1, gen_loss = 0.43626248680688196, disc_loss = 0.11750959069924612
Trained batch 153 in epoch 1, gen_loss = 0.4358476150732536, disc_loss = 0.11736381577037565
Trained batch 154 in epoch 1, gen_loss = 0.4358872269430468, disc_loss = 0.1173840495907972
Trained batch 155 in epoch 1, gen_loss = 0.4357890981512192, disc_loss = 0.11737209291627201
Trained batch 156 in epoch 1, gen_loss = 0.4357852759254966, disc_loss = 0.1171435376890241
Trained batch 157 in epoch 1, gen_loss = 0.4357739436098292, disc_loss = 0.11690546469055588
Trained batch 158 in epoch 1, gen_loss = 0.4360017982668847, disc_loss = 0.11670239410896159
Trained batch 159 in epoch 1, gen_loss = 0.43599714171141385, disc_loss = 0.11618312351056374
Trained batch 160 in epoch 1, gen_loss = 0.4360178721987683, disc_loss = 0.11589962401953728
Trained batch 161 in epoch 1, gen_loss = 0.4359152857904081, disc_loss = 0.1157806220487404
Trained batch 162 in epoch 1, gen_loss = 0.4358738558424031, disc_loss = 0.11525456685618572
Trained batch 163 in epoch 1, gen_loss = 0.4354665417496751, disc_loss = 0.11526070549379944
Trained batch 164 in epoch 1, gen_loss = 0.43579165772958234, disc_loss = 0.1160785210459973
Trained batch 165 in epoch 1, gen_loss = 0.43621181202940196, disc_loss = 0.11580727712240026
Trained batch 166 in epoch 1, gen_loss = 0.436367224790379, disc_loss = 0.11586122219813262
Trained batch 167 in epoch 1, gen_loss = 0.4367759465461686, disc_loss = 0.11557128205562808
Trained batch 168 in epoch 1, gen_loss = 0.4365888063371534, disc_loss = 0.11570450836054143
Trained batch 169 in epoch 1, gen_loss = 0.4372088847791447, disc_loss = 0.11642817044630646
Trained batch 170 in epoch 1, gen_loss = 0.43689543113373874, disc_loss = 0.11658147060753483
Trained batch 171 in epoch 1, gen_loss = 0.43701886593602424, disc_loss = 0.11649889508153984
Trained batch 172 in epoch 1, gen_loss = 0.4369480596112378, disc_loss = 0.1161701147837532
Trained batch 173 in epoch 1, gen_loss = 0.4366642128804634, disc_loss = 0.116230019127372
Trained batch 174 in epoch 1, gen_loss = 0.43677678057125635, disc_loss = 0.11605718413101776
Trained batch 175 in epoch 1, gen_loss = 0.43660064007748256, disc_loss = 0.11792463712415403
Trained batch 176 in epoch 1, gen_loss = 0.43608131566963626, disc_loss = 0.12049426976591349
Trained batch 177 in epoch 1, gen_loss = 0.4359424204638835, disc_loss = 0.12072510151401832
Trained batch 178 in epoch 1, gen_loss = 0.4356635928819965, disc_loss = 0.12134818446057635
Trained batch 179 in epoch 1, gen_loss = 0.43551490588320624, disc_loss = 0.12133475410131117
Trained batch 180 in epoch 1, gen_loss = 0.4350591981937872, disc_loss = 0.12137401911291135
Trained batch 181 in epoch 1, gen_loss = 0.4345654804300476, disc_loss = 0.12138651328284171
Trained batch 182 in epoch 1, gen_loss = 0.4346453166398846, disc_loss = 0.12168925789393525
Trained batch 183 in epoch 1, gen_loss = 0.43491817897428636, disc_loss = 0.12140105802909998
Trained batch 184 in epoch 1, gen_loss = 0.43515861388799304, disc_loss = 0.12146080007927643
Trained batch 185 in epoch 1, gen_loss = 0.43476622784009544, disc_loss = 0.12130651411209856
Trained batch 186 in epoch 1, gen_loss = 0.4347674585281209, disc_loss = 0.1210005784227966
Trained batch 187 in epoch 1, gen_loss = 0.43471191791777913, disc_loss = 0.12074995536773288
Trained batch 188 in epoch 1, gen_loss = 0.43453509861199313, disc_loss = 0.12049824827739959
Trained batch 189 in epoch 1, gen_loss = 0.4350024231170353, disc_loss = 0.12026699664267271
Trained batch 190 in epoch 1, gen_loss = 0.43496959231286775, disc_loss = 0.11978120439203153
Trained batch 191 in epoch 1, gen_loss = 0.43500703511138755, disc_loss = 0.11982000852488757
Trained batch 192 in epoch 1, gen_loss = 0.43509140749669445, disc_loss = 0.11980125123219941
Trained batch 193 in epoch 1, gen_loss = 0.43521472151131974, disc_loss = 0.11954547496051672
Trained batch 194 in epoch 1, gen_loss = 0.4349718191684821, disc_loss = 0.11963276114696876
Trained batch 195 in epoch 1, gen_loss = 0.43523795294518375, disc_loss = 0.11942135105954901
Trained batch 196 in epoch 1, gen_loss = 0.4350636711883061, disc_loss = 0.1191319617948632
Trained batch 197 in epoch 1, gen_loss = 0.4358229057656394, disc_loss = 0.11876027517942618
Trained batch 198 in epoch 1, gen_loss = 0.43550439276287906, disc_loss = 0.11870207119471014
Trained batch 199 in epoch 1, gen_loss = 0.4355076919496059, disc_loss = 0.11858890662435442
Trained batch 200 in epoch 1, gen_loss = 0.4357614477178944, disc_loss = 0.11821801188072903
Trained batch 201 in epoch 1, gen_loss = 0.4355060931774649, disc_loss = 0.11848337821533332
Trained batch 202 in epoch 1, gen_loss = 0.4357333598759374, disc_loss = 0.11912345686661345
Trained batch 203 in epoch 1, gen_loss = 0.4357641630020796, disc_loss = 0.11883850938494445
Trained batch 204 in epoch 1, gen_loss = 0.43527792648571295, disc_loss = 0.11853572604950609
Trained batch 205 in epoch 1, gen_loss = 0.434900664878123, disc_loss = 0.1186222772077811
Trained batch 206 in epoch 1, gen_loss = 0.43528912234421513, disc_loss = 0.11897476646005388
Trained batch 207 in epoch 1, gen_loss = 0.4351155899751645, disc_loss = 0.11905308743455233
Trained batch 208 in epoch 1, gen_loss = 0.4353355893678072, disc_loss = 0.12000654861063621
Trained batch 209 in epoch 1, gen_loss = 0.4352653117406936, disc_loss = 0.1203746229631915
Trained batch 210 in epoch 1, gen_loss = 0.43548501992677624, disc_loss = 0.12019393927201417
Trained batch 211 in epoch 1, gen_loss = 0.4356785089058696, disc_loss = 0.12003835053886024
Trained batch 212 in epoch 1, gen_loss = 0.43561894736939194, disc_loss = 0.11971483969440062
Trained batch 213 in epoch 1, gen_loss = 0.43579360898410047, disc_loss = 0.11947660780485685
Trained batch 214 in epoch 1, gen_loss = 0.4358098074447277, disc_loss = 0.1194243346752469
Trained batch 215 in epoch 1, gen_loss = 0.43541053530794604, disc_loss = 0.1196016100347387
Trained batch 216 in epoch 1, gen_loss = 0.43535765181488706, disc_loss = 0.11929691128415583
Trained batch 217 in epoch 1, gen_loss = 0.43526466163473393, disc_loss = 0.11905669987013717
Trained batch 218 in epoch 1, gen_loss = 0.43502600212075393, disc_loss = 0.11902193907546262
Trained batch 219 in epoch 1, gen_loss = 0.43485341031442987, disc_loss = 0.11868549553592773
Trained batch 220 in epoch 1, gen_loss = 0.4347216427595907, disc_loss = 0.11838555693778112
Trained batch 221 in epoch 1, gen_loss = 0.43508162718635424, disc_loss = 0.11813548885638246
Trained batch 222 in epoch 1, gen_loss = 0.43485451225742633, disc_loss = 0.11785114460077654
Trained batch 223 in epoch 1, gen_loss = 0.43484241142868996, disc_loss = 0.1178510373366797
Trained batch 224 in epoch 1, gen_loss = 0.43467530131340026, disc_loss = 0.11782422483381298
Trained batch 225 in epoch 1, gen_loss = 0.43487344906393405, disc_loss = 0.11753249397929923
Trained batch 226 in epoch 1, gen_loss = 0.43503247930089806, disc_loss = 0.11805406546359677
Trained batch 227 in epoch 1, gen_loss = 0.4345124988702306, disc_loss = 0.11894776167658468
Trained batch 228 in epoch 1, gen_loss = 0.4343278163385183, disc_loss = 0.1187717209744987
Trained batch 229 in epoch 1, gen_loss = 0.4345525766196458, disc_loss = 0.1184453439493866
Trained batch 230 in epoch 1, gen_loss = 0.4344849223956401, disc_loss = 0.11819770835839953
Trained batch 231 in epoch 1, gen_loss = 0.4344157476363511, disc_loss = 0.11815342018461047
Trained batch 232 in epoch 1, gen_loss = 0.43428520186776254, disc_loss = 0.11798911852274457
Trained batch 233 in epoch 1, gen_loss = 0.43443671862284344, disc_loss = 0.11794175599645983
Trained batch 234 in epoch 1, gen_loss = 0.4341663922401185, disc_loss = 0.1178563040344322
Trained batch 235 in epoch 1, gen_loss = 0.4339624798651469, disc_loss = 0.11795961468922511
Trained batch 236 in epoch 1, gen_loss = 0.43389099584853097, disc_loss = 0.11794212935610285
Trained batch 237 in epoch 1, gen_loss = 0.43367567520682554, disc_loss = 0.11785926141173524
Trained batch 238 in epoch 1, gen_loss = 0.43386814883563307, disc_loss = 0.11756526418887546
Trained batch 239 in epoch 1, gen_loss = 0.43398570716381074, disc_loss = 0.11738399343642716
Trained batch 240 in epoch 1, gen_loss = 0.43407782689664376, disc_loss = 0.1172736868517342
Trained batch 241 in epoch 1, gen_loss = 0.43411968500653575, disc_loss = 0.11709211091318529
Trained batch 242 in epoch 1, gen_loss = 0.43400009264671263, disc_loss = 0.11701354533510566
Trained batch 243 in epoch 1, gen_loss = 0.4341238294957114, disc_loss = 0.11693987985080505
Trained batch 244 in epoch 1, gen_loss = 0.43391525562928646, disc_loss = 0.11692928999130214
Trained batch 245 in epoch 1, gen_loss = 0.43384215538579274, disc_loss = 0.11685476402517378
Trained batch 246 in epoch 1, gen_loss = 0.4337769501846329, disc_loss = 0.11697022676060677
Trained batch 247 in epoch 1, gen_loss = 0.4341511999166781, disc_loss = 0.11708001845381072
Trained batch 248 in epoch 1, gen_loss = 0.43395278312595015, disc_loss = 0.1170120179301584
Trained batch 249 in epoch 1, gen_loss = 0.4340720671415329, disc_loss = 0.1166827362664044
Trained batch 250 in epoch 1, gen_loss = 0.4342463825090948, disc_loss = 0.1163933545952121
Trained batch 251 in epoch 1, gen_loss = 0.43461440610034124, disc_loss = 0.1161130312719338
Trained batch 252 in epoch 1, gen_loss = 0.43458285126761487, disc_loss = 0.11589929698911226
Trained batch 253 in epoch 1, gen_loss = 0.4344943105939805, disc_loss = 0.11558041823147906
Trained batch 254 in epoch 1, gen_loss = 0.4346460850799785, disc_loss = 0.11544146279567012
Trained batch 255 in epoch 1, gen_loss = 0.434998941491358, disc_loss = 0.11553101083336514
Trained batch 256 in epoch 1, gen_loss = 0.435215588557581, disc_loss = 0.1152886578900167
Trained batch 257 in epoch 1, gen_loss = 0.4351169134295264, disc_loss = 0.11502079154877354
Trained batch 258 in epoch 1, gen_loss = 0.43537372304665994, disc_loss = 0.11491451542249172
Trained batch 259 in epoch 1, gen_loss = 0.43525060082857425, disc_loss = 0.11559908631114432
Trained batch 260 in epoch 1, gen_loss = 0.43527361305280665, disc_loss = 0.11659385601122832
Trained batch 261 in epoch 1, gen_loss = 0.43505382890464694, disc_loss = 0.11657577662423026
Trained batch 262 in epoch 1, gen_loss = 0.43482034321973534, disc_loss = 0.11647350916518572
Trained batch 263 in epoch 1, gen_loss = 0.4349174861880866, disc_loss = 0.11659582902211696
Trained batch 264 in epoch 1, gen_loss = 0.4344972440656626, disc_loss = 0.11660394474934295
Trained batch 265 in epoch 1, gen_loss = 0.43460908857055175, disc_loss = 0.11636900657059666
Trained batch 266 in epoch 1, gen_loss = 0.4347310462471251, disc_loss = 0.1162755171967189
Trained batch 267 in epoch 1, gen_loss = 0.4345028261417773, disc_loss = 0.11616293598425144
Trained batch 268 in epoch 1, gen_loss = 0.434342974291415, disc_loss = 0.1163560137824332
Trained batch 269 in epoch 1, gen_loss = 0.434088788429896, disc_loss = 0.11616187188429412
Trained batch 270 in epoch 1, gen_loss = 0.43425840271355043, disc_loss = 0.11585785615226989
Trained batch 271 in epoch 1, gen_loss = 0.4341664359192638, disc_loss = 0.11578591569559649
Trained batch 272 in epoch 1, gen_loss = 0.4339119765784714, disc_loss = 0.11608383727120065
Trained batch 273 in epoch 1, gen_loss = 0.4338676773936209, disc_loss = 0.11578987174782984
Trained batch 274 in epoch 1, gen_loss = 0.4339465880393982, disc_loss = 0.11567308897660537
Trained batch 275 in epoch 1, gen_loss = 0.43387068214191904, disc_loss = 0.11553498117617615
Trained batch 276 in epoch 1, gen_loss = 0.4340768083123093, disc_loss = 0.11534340959714746
Trained batch 277 in epoch 1, gen_loss = 0.4339917717005709, disc_loss = 0.11503088157020992
Trained batch 278 in epoch 1, gen_loss = 0.43401286454610927, disc_loss = 0.11471854923726944
Trained batch 279 in epoch 1, gen_loss = 0.4341242910495826, disc_loss = 0.1145562375130664
Trained batch 280 in epoch 1, gen_loss = 0.43417287975867874, disc_loss = 0.1150535772392175
Trained batch 281 in epoch 1, gen_loss = 0.4340309317864425, disc_loss = 0.1152616673122748
Trained batch 282 in epoch 1, gen_loss = 0.43390256756186063, disc_loss = 0.11536550462943611
Trained batch 283 in epoch 1, gen_loss = 0.43410111355109954, disc_loss = 0.1151098194236959
Trained batch 284 in epoch 1, gen_loss = 0.4343061998225095, disc_loss = 0.11492214577043788
Trained batch 285 in epoch 1, gen_loss = 0.4343080159042265, disc_loss = 0.11478066280601429
Trained batch 286 in epoch 1, gen_loss = 0.434368007170614, disc_loss = 0.1146087948953285
Trained batch 287 in epoch 1, gen_loss = 0.4346478069201112, disc_loss = 0.1143399937007214
Trained batch 288 in epoch 1, gen_loss = 0.43456637735597814, disc_loss = 0.11405886595288878
Trained batch 289 in epoch 1, gen_loss = 0.434769580282014, disc_loss = 0.11388954863530294
Trained batch 290 in epoch 1, gen_loss = 0.43465463914412406, disc_loss = 0.11366439310200128
Trained batch 291 in epoch 1, gen_loss = 0.4346320648511795, disc_loss = 0.11365838245845923
Trained batch 292 in epoch 1, gen_loss = 0.4346914759268126, disc_loss = 0.11338498376297157
Trained batch 293 in epoch 1, gen_loss = 0.4345739882211296, disc_loss = 0.11313661653231703
Trained batch 294 in epoch 1, gen_loss = 0.43459782378148226, disc_loss = 0.112964698473402
Trained batch 295 in epoch 1, gen_loss = 0.43456225157589523, disc_loss = 0.1126731196701577
Trained batch 296 in epoch 1, gen_loss = 0.43481229551713474, disc_loss = 0.11238852606440333
Trained batch 297 in epoch 1, gen_loss = 0.4347231482099367, disc_loss = 0.11212627808782179
Trained batch 298 in epoch 1, gen_loss = 0.4347910223198575, disc_loss = 0.1119413242198801
Trained batch 299 in epoch 1, gen_loss = 0.4348447926839193, disc_loss = 0.11185612593156596
Trained batch 300 in epoch 1, gen_loss = 0.43476605019300085, disc_loss = 0.11198526971425823
Trained batch 301 in epoch 1, gen_loss = 0.43498147718164304, disc_loss = 0.1119430042365381
Trained batch 302 in epoch 1, gen_loss = 0.43506617160520145, disc_loss = 0.11187150084994513
Trained batch 303 in epoch 1, gen_loss = 0.43522659208821624, disc_loss = 0.11243300114476465
Trained batch 304 in epoch 1, gen_loss = 0.4354221812037171, disc_loss = 0.11255902153607764
Trained batch 305 in epoch 1, gen_loss = 0.43523481809625436, disc_loss = 0.1123560164154209
Trained batch 306 in epoch 1, gen_loss = 0.4349977092556534, disc_loss = 0.11205222407592527
Trained batch 307 in epoch 1, gen_loss = 0.4348974148561428, disc_loss = 0.11174285832441763
Trained batch 308 in epoch 1, gen_loss = 0.43502995014962254, disc_loss = 0.11164991294476882
Trained batch 309 in epoch 1, gen_loss = 0.434865050065902, disc_loss = 0.11159158194918306
Trained batch 310 in epoch 1, gen_loss = 0.43494183639621425, disc_loss = 0.11146646081335196
Trained batch 311 in epoch 1, gen_loss = 0.4349451140524485, disc_loss = 0.11138001967591639
Trained batch 312 in epoch 1, gen_loss = 0.43517961526831117, disc_loss = 0.11132341194540833
Trained batch 313 in epoch 1, gen_loss = 0.4350869413583901, disc_loss = 0.1112319874031481
Trained batch 314 in epoch 1, gen_loss = 0.43493763378688266, disc_loss = 0.11096581506528079
Trained batch 315 in epoch 1, gen_loss = 0.43491392827863934, disc_loss = 0.1109004351693571
Trained batch 316 in epoch 1, gen_loss = 0.43466437314211004, disc_loss = 0.11098856410475841
Trained batch 317 in epoch 1, gen_loss = 0.4347505250816825, disc_loss = 0.11106786206540353
Trained batch 318 in epoch 1, gen_loss = 0.43458363936986294, disc_loss = 0.11095203463642107
Trained batch 319 in epoch 1, gen_loss = 0.4342642925679684, disc_loss = 0.1109060163347749
Trained batch 320 in epoch 1, gen_loss = 0.43439483382620175, disc_loss = 0.11112538636647559
Trained batch 321 in epoch 1, gen_loss = 0.4343036559427747, disc_loss = 0.11124405942521758
Trained batch 322 in epoch 1, gen_loss = 0.4342976329680936, disc_loss = 0.11125653587431639
Trained batch 323 in epoch 1, gen_loss = 0.4343363160704389, disc_loss = 0.11171139852304793
Trained batch 324 in epoch 1, gen_loss = 0.4341290893921485, disc_loss = 0.11184988482353779
Trained batch 325 in epoch 1, gen_loss = 0.43398696330427394, disc_loss = 0.11173673202369384
Trained batch 326 in epoch 1, gen_loss = 0.4337864274825525, disc_loss = 0.11161991058128233
Trained batch 327 in epoch 1, gen_loss = 0.4335702961174453, disc_loss = 0.11161619663045447
Trained batch 328 in epoch 1, gen_loss = 0.43342662763450646, disc_loss = 0.11145062030980923
Trained batch 329 in epoch 1, gen_loss = 0.4332474684173411, disc_loss = 0.11124391362466143
Trained batch 330 in epoch 1, gen_loss = 0.4331506520419683, disc_loss = 0.11099438680746675
Trained batch 331 in epoch 1, gen_loss = 0.43335868624678575, disc_loss = 0.11078823603274503
Trained batch 332 in epoch 1, gen_loss = 0.43347164066704186, disc_loss = 0.11061799797780432
Trained batch 333 in epoch 1, gen_loss = 0.4335303510912878, disc_loss = 0.11042504400449867
Trained batch 334 in epoch 1, gen_loss = 0.43360689753916726, disc_loss = 0.11024415606160218
Trained batch 335 in epoch 1, gen_loss = 0.43357624113559723, disc_loss = 0.10998868648173465
Trained batch 336 in epoch 1, gen_loss = 0.4335714292986103, disc_loss = 0.10978409321564153
Trained batch 337 in epoch 1, gen_loss = 0.43349436375163714, disc_loss = 0.10950651907323468
Trained batch 338 in epoch 1, gen_loss = 0.43331325062959947, disc_loss = 0.10928561733238905
Trained batch 339 in epoch 1, gen_loss = 0.4333646635798847, disc_loss = 0.10911119427148472
Trained batch 340 in epoch 1, gen_loss = 0.43340427941940396, disc_loss = 0.10898391684227762
Trained batch 341 in epoch 1, gen_loss = 0.43362154528411506, disc_loss = 0.10917558739157884
Trained batch 342 in epoch 1, gen_loss = 0.4336089912378406, disc_loss = 0.10969465289199752
Trained batch 343 in epoch 1, gen_loss = 0.4336730583982412, disc_loss = 0.10942608023029861
Trained batch 344 in epoch 1, gen_loss = 0.4337724294351495, disc_loss = 0.10949611331511667
Trained batch 345 in epoch 1, gen_loss = 0.433685582755618, disc_loss = 0.10963255537652297
Trained batch 346 in epoch 1, gen_loss = 0.4335032631066072, disc_loss = 0.10953486090531353
Trained batch 347 in epoch 1, gen_loss = 0.43400423759701606, disc_loss = 0.1100495563439982
Trained batch 348 in epoch 1, gen_loss = 0.43368833215325475, disc_loss = 0.11010361793998064
Trained batch 349 in epoch 1, gen_loss = 0.4337921142578125, disc_loss = 0.11001699618196913
Trained batch 350 in epoch 1, gen_loss = 0.433841408827366, disc_loss = 0.10996734773596892
Trained batch 351 in epoch 1, gen_loss = 0.4337091805752028, disc_loss = 0.10988551247282885
Trained batch 352 in epoch 1, gen_loss = 0.4335435361261071, disc_loss = 0.10972964145485892
Trained batch 353 in epoch 1, gen_loss = 0.4337322963664761, disc_loss = 0.10969523262853424
Trained batch 354 in epoch 1, gen_loss = 0.43379253216192754, disc_loss = 0.10956210098688451
Trained batch 355 in epoch 1, gen_loss = 0.43389141450772123, disc_loss = 0.10943777611468698
Trained batch 356 in epoch 1, gen_loss = 0.434003826533379, disc_loss = 0.10933780264505903
Trained batch 357 in epoch 1, gen_loss = 0.43411983982477775, disc_loss = 0.1091242644379134
Trained batch 358 in epoch 1, gen_loss = 0.4341329211644143, disc_loss = 0.108877490990611
Trained batch 359 in epoch 1, gen_loss = 0.4341251598464118, disc_loss = 0.10866613521809793
Trained batch 360 in epoch 1, gen_loss = 0.43426929368867107, disc_loss = 0.10843642200717388
Trained batch 361 in epoch 1, gen_loss = 0.43441709415030083, disc_loss = 0.10826022482801291
Trained batch 362 in epoch 1, gen_loss = 0.4343259962629681, disc_loss = 0.1081163224484515
Trained batch 363 in epoch 1, gen_loss = 0.4343546772232422, disc_loss = 0.10804764665714414
Trained batch 364 in epoch 1, gen_loss = 0.43423412466702394, disc_loss = 0.10798623361050674
Trained batch 365 in epoch 1, gen_loss = 0.4344541645440899, disc_loss = 0.10795273262590088
Trained batch 366 in epoch 1, gen_loss = 0.43448421164169626, disc_loss = 0.10777969471856505
Trained batch 367 in epoch 1, gen_loss = 0.43444720769058104, disc_loss = 0.10758359622179894
Trained batch 368 in epoch 1, gen_loss = 0.4343864950868819, disc_loss = 0.1074736015265429
Trained batch 369 in epoch 1, gen_loss = 0.4342703743560894, disc_loss = 0.10747565761258876
Trained batch 370 in epoch 1, gen_loss = 0.43431325614291705, disc_loss = 0.10753301923938918
Trained batch 371 in epoch 1, gen_loss = 0.4342031478881836, disc_loss = 0.10753969889464637
Trained batch 372 in epoch 1, gen_loss = 0.4344692046456938, disc_loss = 0.10747918364000145
Trained batch 373 in epoch 1, gen_loss = 0.43451659349515476, disc_loss = 0.10729094332004374
Trained batch 374 in epoch 1, gen_loss = 0.43438619391123456, disc_loss = 0.1072310219630599
Trained batch 375 in epoch 1, gen_loss = 0.43442131230171693, disc_loss = 0.10740485621190214
Trained batch 376 in epoch 1, gen_loss = 0.4343986438503316, disc_loss = 0.10721915843958327
Trained batch 377 in epoch 1, gen_loss = 0.434350905358476, disc_loss = 0.10705643782155617
Trained batch 378 in epoch 1, gen_loss = 0.4344391411558619, disc_loss = 0.10691875327712706
Trained batch 379 in epoch 1, gen_loss = 0.4342925949316276, disc_loss = 0.10691411589566423
Trained batch 380 in epoch 1, gen_loss = 0.4343719654508776, disc_loss = 0.10682324337922135
Trained batch 381 in epoch 1, gen_loss = 0.4343116386398595, disc_loss = 0.10666409915274117
Trained batch 382 in epoch 1, gen_loss = 0.4344643534163582, disc_loss = 0.10650070038120756
Trained batch 383 in epoch 1, gen_loss = 0.43431553593836725, disc_loss = 0.10634148232687342
Trained batch 384 in epoch 1, gen_loss = 0.43469375998942883, disc_loss = 0.1062552185729146
Trained batch 385 in epoch 1, gen_loss = 0.43458689394083666, disc_loss = 0.10611772561600248
Trained batch 386 in epoch 1, gen_loss = 0.43491534322731257, disc_loss = 0.10590200098496153
Trained batch 387 in epoch 1, gen_loss = 0.4350302492066757, disc_loss = 0.10568451145231801
Trained batch 388 in epoch 1, gen_loss = 0.43502842146510634, disc_loss = 0.10553613819593712
Trained batch 389 in epoch 1, gen_loss = 0.4351811010868121, disc_loss = 0.10530865882786039
Trained batch 390 in epoch 1, gen_loss = 0.4350753050021198, disc_loss = 0.10513910560456612
Trained batch 391 in epoch 1, gen_loss = 0.4348930641248518, disc_loss = 0.10502691373789722
Trained batch 392 in epoch 1, gen_loss = 0.4350127387441145, disc_loss = 0.10479725015043985
Trained batch 393 in epoch 1, gen_loss = 0.4352923709577715, disc_loss = 0.10470263568476447
Trained batch 394 in epoch 1, gen_loss = 0.43535940096348147, disc_loss = 0.10446915822928843
Trained batch 395 in epoch 1, gen_loss = 0.4353942380409048, disc_loss = 0.1042340349928109
Trained batch 396 in epoch 1, gen_loss = 0.43525065913308475, disc_loss = 0.10405718616587614
Trained batch 397 in epoch 1, gen_loss = 0.43537415489180004, disc_loss = 0.10382546077075241
Trained batch 398 in epoch 1, gen_loss = 0.4354594672532906, disc_loss = 0.10359124545204013
Trained batch 399 in epoch 1, gen_loss = 0.4354986751824617, disc_loss = 0.10343017869628966
Trained batch 400 in epoch 1, gen_loss = 0.43556332112547763, disc_loss = 0.10334851279706135
Trained batch 401 in epoch 1, gen_loss = 0.43593352647563116, disc_loss = 0.10323810967528702
Trained batch 402 in epoch 1, gen_loss = 0.43591838564825414, disc_loss = 0.10303876544845755
Trained batch 403 in epoch 1, gen_loss = 0.4357432372646757, disc_loss = 0.10285260537086
Trained batch 404 in epoch 1, gen_loss = 0.43581592035882266, disc_loss = 0.10305370053299415
Trained batch 405 in epoch 1, gen_loss = 0.4360313296611673, disc_loss = 0.10319744242731427
Trained batch 406 in epoch 1, gen_loss = 0.43607109477537565, disc_loss = 0.10301954581125362
Trained batch 407 in epoch 1, gen_loss = 0.4360387182118846, disc_loss = 0.1028809869643666
Trained batch 408 in epoch 1, gen_loss = 0.4360556944949703, disc_loss = 0.10278311516625083
Trained batch 409 in epoch 1, gen_loss = 0.436361370290198, disc_loss = 0.10270892400748846
Trained batch 410 in epoch 1, gen_loss = 0.4362367102989605, disc_loss = 0.10266535982054516
Trained batch 411 in epoch 1, gen_loss = 0.43626302017748936, disc_loss = 0.10256601267864981
Trained batch 412 in epoch 1, gen_loss = 0.4362395208770946, disc_loss = 0.10234915261037342
Trained batch 413 in epoch 1, gen_loss = 0.4361930376521631, disc_loss = 0.1021844476600884
Trained batch 414 in epoch 1, gen_loss = 0.43626478910446165, disc_loss = 0.1020712032353124
Trained batch 415 in epoch 1, gen_loss = 0.43635761078733665, disc_loss = 0.10224400302887751
Trained batch 416 in epoch 1, gen_loss = 0.43644754449240597, disc_loss = 0.10210673685902528
Trained batch 417 in epoch 1, gen_loss = 0.43629815960614876, disc_loss = 0.10192937542278872
Trained batch 418 in epoch 1, gen_loss = 0.4362938079742941, disc_loss = 0.10172101622558508
Trained batch 419 in epoch 1, gen_loss = 0.4363785933880579, disc_loss = 0.10152348419873132
Trained batch 420 in epoch 1, gen_loss = 0.4365135254316262, disc_loss = 0.10137190577527619
Trained batch 421 in epoch 1, gen_loss = 0.4364891853095231, disc_loss = 0.10121735596534977
Trained batch 422 in epoch 1, gen_loss = 0.43648033383044793, disc_loss = 0.10100509954427081
Trained batch 423 in epoch 1, gen_loss = 0.4366106132291398, disc_loss = 0.10083056768657253
Trained batch 424 in epoch 1, gen_loss = 0.43687707354040706, disc_loss = 0.10064932135755525
Trained batch 425 in epoch 1, gen_loss = 0.4369241212595237, disc_loss = 0.1004799884490389
Trained batch 426 in epoch 1, gen_loss = 0.4370402325930584, disc_loss = 0.10033836126528174
Trained batch 427 in epoch 1, gen_loss = 0.43694776568178817, disc_loss = 0.10012478140513544
Trained batch 428 in epoch 1, gen_loss = 0.43695323721512214, disc_loss = 0.09998653521044897
Trained batch 429 in epoch 1, gen_loss = 0.4372084106816802, disc_loss = 0.09979879233423014
Trained batch 430 in epoch 1, gen_loss = 0.43727905989523, disc_loss = 0.0996130115639963
Trained batch 431 in epoch 1, gen_loss = 0.4373879349204125, disc_loss = 0.09941878328229198
Trained batch 432 in epoch 1, gen_loss = 0.4375550495697224, disc_loss = 0.09922151420884884
Trained batch 433 in epoch 1, gen_loss = 0.4377567739942656, disc_loss = 0.09904719312559418
Trained batch 434 in epoch 1, gen_loss = 0.43789286764188745, disc_loss = 0.0989082924529225
Trained batch 435 in epoch 1, gen_loss = 0.4380155546129297, disc_loss = 0.09877314665696559
Trained batch 436 in epoch 1, gen_loss = 0.4381915891470571, disc_loss = 0.09856809474297669
Trained batch 437 in epoch 1, gen_loss = 0.43807901169883606, disc_loss = 0.09854426612380092
Trained batch 438 in epoch 1, gen_loss = 0.43823868803391425, disc_loss = 0.09843337586561138
Trained batch 439 in epoch 1, gen_loss = 0.43828983008861544, disc_loss = 0.09825183344708587
Trained batch 440 in epoch 1, gen_loss = 0.43810546330583877, disc_loss = 0.09807263151478537
Trained batch 441 in epoch 1, gen_loss = 0.43812022260411293, disc_loss = 0.09788235688447211
Trained batch 442 in epoch 1, gen_loss = 0.43834429535316827, disc_loss = 0.09769243897100738
Trained batch 443 in epoch 1, gen_loss = 0.4383840477681375, disc_loss = 0.0975267346570822
Trained batch 444 in epoch 1, gen_loss = 0.43848438209362245, disc_loss = 0.09733184302497781
Trained batch 445 in epoch 1, gen_loss = 0.43853092748220723, disc_loss = 0.09713778203152822
Trained batch 446 in epoch 1, gen_loss = 0.4386710970593779, disc_loss = 0.09696182763824861
Trained batch 447 in epoch 1, gen_loss = 0.4386451787182263, disc_loss = 0.09680071489960287
Trained batch 448 in epoch 1, gen_loss = 0.43857109327624266, disc_loss = 0.09661133104068266
Trained batch 449 in epoch 1, gen_loss = 0.4384494861629274, disc_loss = 0.09643095177701778
Trained batch 450 in epoch 1, gen_loss = 0.43856834407127615, disc_loss = 0.09624653656299983
Trained batch 451 in epoch 1, gen_loss = 0.43851900555654966, disc_loss = 0.09608267694175969
Trained batch 452 in epoch 1, gen_loss = 0.43842486237848044, disc_loss = 0.09600159711519021
Trained batch 453 in epoch 1, gen_loss = 0.4383941333461963, disc_loss = 0.09590932597828791
Trained batch 454 in epoch 1, gen_loss = 0.4381929603251782, disc_loss = 0.09571533456731302
Trained batch 455 in epoch 1, gen_loss = 0.4381242156551595, disc_loss = 0.09558516622953966
Trained batch 456 in epoch 1, gen_loss = 0.4382726453587054, disc_loss = 0.09539792723586901
Trained batch 457 in epoch 1, gen_loss = 0.4382949809840673, disc_loss = 0.09520709656349761
Trained batch 458 in epoch 1, gen_loss = 0.438378177696843, disc_loss = 0.09503664864604575
Trained batch 459 in epoch 1, gen_loss = 0.4386547202649324, disc_loss = 0.09488167959346396
Trained batch 460 in epoch 1, gen_loss = 0.4385642197928563, disc_loss = 0.09475091695098647
Trained batch 461 in epoch 1, gen_loss = 0.43851384868869536, disc_loss = 0.09457143904334861
Trained batch 462 in epoch 1, gen_loss = 0.43846279369832114, disc_loss = 0.09440229095510543
Trained batch 463 in epoch 1, gen_loss = 0.4385560238412742, disc_loss = 0.09423215984134004
Trained batch 464 in epoch 1, gen_loss = 0.438477619360852, disc_loss = 0.09409500802917185
Trained batch 465 in epoch 1, gen_loss = 0.438591350365606, disc_loss = 0.09393618695333984
Trained batch 466 in epoch 1, gen_loss = 0.43851232739281093, disc_loss = 0.09379804296901637
Trained batch 467 in epoch 1, gen_loss = 0.4385472424646728, disc_loss = 0.09363315855232505
Trained batch 468 in epoch 1, gen_loss = 0.43862337928845174, disc_loss = 0.09361044500769773
Trained batch 469 in epoch 1, gen_loss = 0.43854002756007177, disc_loss = 0.0935368190321358
Trained batch 470 in epoch 1, gen_loss = 0.43862379179385563, disc_loss = 0.0933824609708033
Trained batch 471 in epoch 1, gen_loss = 0.4385488707635362, disc_loss = 0.09321367572322171
Trained batch 472 in epoch 1, gen_loss = 0.43846194298020374, disc_loss = 0.09331271870467363
Trained batch 473 in epoch 1, gen_loss = 0.43872082648398003, disc_loss = 0.09329105287059387
Trained batch 474 in epoch 1, gen_loss = 0.43864485426952965, disc_loss = 0.0932519973481172
Trained batch 475 in epoch 1, gen_loss = 0.4388553070671418, disc_loss = 0.09308271279300273
Trained batch 476 in epoch 1, gen_loss = 0.43895829498642897, disc_loss = 0.09292469219162092
Trained batch 477 in epoch 1, gen_loss = 0.43902543823090556, disc_loss = 0.09279377080274115
Trained batch 478 in epoch 1, gen_loss = 0.439017018594921, disc_loss = 0.09266577219096692
Trained batch 479 in epoch 1, gen_loss = 0.4392175150414308, disc_loss = 0.09250679294539926
Trained batch 480 in epoch 1, gen_loss = 0.4394994357023814, disc_loss = 0.09234433626976801
Trained batch 481 in epoch 1, gen_loss = 0.43957617693422246, disc_loss = 0.0921911227659813
Trained batch 482 in epoch 1, gen_loss = 0.43958148946426423, disc_loss = 0.09203614382455068
Trained batch 483 in epoch 1, gen_loss = 0.43976573929313784, disc_loss = 0.09187950697642835
Trained batch 484 in epoch 1, gen_loss = 0.4398768947296536, disc_loss = 0.09171460086729416
Trained batch 485 in epoch 1, gen_loss = 0.4399857583605213, disc_loss = 0.0915489774216503
Trained batch 486 in epoch 1, gen_loss = 0.4399491277441107, disc_loss = 0.09137884454583668
Trained batch 487 in epoch 1, gen_loss = 0.4399780689692888, disc_loss = 0.0912506966908905
Trained batch 488 in epoch 1, gen_loss = 0.4401177390952783, disc_loss = 0.09122952614512851
Trained batch 489 in epoch 1, gen_loss = 0.4399685309857738, disc_loss = 0.09124683576388931
Trained batch 490 in epoch 1, gen_loss = 0.44005021058371985, disc_loss = 0.0910998386844932
Trained batch 491 in epoch 1, gen_loss = 0.4402354956884694, disc_loss = 0.09098246102827048
Trained batch 492 in epoch 1, gen_loss = 0.440143424889137, disc_loss = 0.09092428552413749
Trained batch 493 in epoch 1, gen_loss = 0.4401751613086052, disc_loss = 0.09122934518759007
Trained batch 494 in epoch 1, gen_loss = 0.44018763448252823, disc_loss = 0.09124992359429598
Trained batch 495 in epoch 1, gen_loss = 0.44040385633707047, disc_loss = 0.09125472634332255
Trained batch 496 in epoch 1, gen_loss = 0.4403393241601211, disc_loss = 0.09121324813604295
Trained batch 497 in epoch 1, gen_loss = 0.4404605785646592, disc_loss = 0.09108415684554293
Trained batch 498 in epoch 1, gen_loss = 0.44046097354802916, disc_loss = 0.09094368413889516
Trained batch 499 in epoch 1, gen_loss = 0.44057293778657913, disc_loss = 0.09085862971656024
Trained batch 500 in epoch 1, gen_loss = 0.440439282003753, disc_loss = 0.0909586301177532
Trained batch 501 in epoch 1, gen_loss = 0.44050524048358797, disc_loss = 0.09085139168975541
Trained batch 502 in epoch 1, gen_loss = 0.4406568374240375, disc_loss = 0.090709661115072
Trained batch 503 in epoch 1, gen_loss = 0.4405355437525681, disc_loss = 0.09071922320170357
Trained batch 504 in epoch 1, gen_loss = 0.4404441796316959, disc_loss = 0.09058452785789671
Trained batch 505 in epoch 1, gen_loss = 0.4404946929027912, disc_loss = 0.09064979470066226
Trained batch 506 in epoch 1, gen_loss = 0.4405461545644192, disc_loss = 0.09067208525822067
Trained batch 507 in epoch 1, gen_loss = 0.44044475709124814, disc_loss = 0.09069113860339455
Trained batch 508 in epoch 1, gen_loss = 0.4402988711719663, disc_loss = 0.09080372553333377
Trained batch 509 in epoch 1, gen_loss = 0.4401263801490559, disc_loss = 0.09069852386509963
Trained batch 510 in epoch 1, gen_loss = 0.44004808118432004, disc_loss = 0.09064097209139171
Trained batch 511 in epoch 1, gen_loss = 0.44020160217769444, disc_loss = 0.09061398446829116
Trained batch 512 in epoch 1, gen_loss = 0.4401294933541244, disc_loss = 0.09051624749611054
Trained batch 513 in epoch 1, gen_loss = 0.4400857987338931, disc_loss = 0.09045090921520317
Trained batch 514 in epoch 1, gen_loss = 0.4400902550197342, disc_loss = 0.09039293255078272
Trained batch 515 in epoch 1, gen_loss = 0.43995810571567034, disc_loss = 0.09028583495199045
Trained batch 516 in epoch 1, gen_loss = 0.4399580107551479, disc_loss = 0.09019857499662001
Trained batch 517 in epoch 1, gen_loss = 0.4402474778844583, disc_loss = 0.09026384634293012
Trained batch 518 in epoch 1, gen_loss = 0.4402785441893833, disc_loss = 0.09018589756657909
Trained batch 519 in epoch 1, gen_loss = 0.4401980723326023, disc_loss = 0.09009297135680054
Trained batch 520 in epoch 1, gen_loss = 0.44026062001193556, disc_loss = 0.09000976282330998
Trained batch 521 in epoch 1, gen_loss = 0.44025617837905884, disc_loss = 0.08991333893839255
Trained batch 522 in epoch 1, gen_loss = 0.44031577971879654, disc_loss = 0.08977442333229015
Trained batch 523 in epoch 1, gen_loss = 0.4402160518269502, disc_loss = 0.08967985306112877
Trained batch 524 in epoch 1, gen_loss = 0.44039334433419364, disc_loss = 0.0896572785664882
Trained batch 525 in epoch 1, gen_loss = 0.4403933315562658, disc_loss = 0.08958632570687866
Trained batch 526 in epoch 1, gen_loss = 0.4403994722995179, disc_loss = 0.08946849846332361
Trained batch 527 in epoch 1, gen_loss = 0.44050882863953256, disc_loss = 0.08960549857389803
Trained batch 528 in epoch 1, gen_loss = 0.44036675981177276, disc_loss = 0.08948117210256862
Trained batch 529 in epoch 1, gen_loss = 0.4402438720442214, disc_loss = 0.08939584178217458
Trained batch 530 in epoch 1, gen_loss = 0.4402184173773462, disc_loss = 0.08924865348548708
Trained batch 531 in epoch 1, gen_loss = 0.44019250017135664, disc_loss = 0.0891534813025028
Trained batch 532 in epoch 1, gen_loss = 0.44030018276613603, disc_loss = 0.08926669705840873
Trained batch 533 in epoch 1, gen_loss = 0.44024935649352126, disc_loss = 0.08959869625158469
Trained batch 534 in epoch 1, gen_loss = 0.4402774734474788, disc_loss = 0.08957198656851721
Trained batch 535 in epoch 1, gen_loss = 0.4402990460729421, disc_loss = 0.0894888817496014
Trained batch 536 in epoch 1, gen_loss = 0.44018218121049124, disc_loss = 0.08954827155695892
Trained batch 537 in epoch 1, gen_loss = 0.4402847720455503, disc_loss = 0.08947786026665436
Trained batch 538 in epoch 1, gen_loss = 0.4400848108784387, disc_loss = 0.0894013431064909
Trained batch 539 in epoch 1, gen_loss = 0.44000511528165254, disc_loss = 0.08927401205766257
Trained batch 540 in epoch 1, gen_loss = 0.4400156623444584, disc_loss = 0.0891544465130529
Trained batch 541 in epoch 1, gen_loss = 0.44005454394870136, disc_loss = 0.08904060303333226
Trained batch 542 in epoch 1, gen_loss = 0.44012200903716886, disc_loss = 0.08901079606717627
Trained batch 543 in epoch 1, gen_loss = 0.4402093691751361, disc_loss = 0.08889944418778588
Trained batch 544 in epoch 1, gen_loss = 0.44025056340278834, disc_loss = 0.08875854767072912
Trained batch 545 in epoch 1, gen_loss = 0.4401817405289346, disc_loss = 0.08867868780919211
Trained batch 546 in epoch 1, gen_loss = 0.440196950485763, disc_loss = 0.08858303863800368
Trained batch 547 in epoch 1, gen_loss = 0.4401351528337402, disc_loss = 0.08867769804443267
Trained batch 548 in epoch 1, gen_loss = 0.44020509627564575, disc_loss = 0.08889855438154631
Trained batch 549 in epoch 1, gen_loss = 0.4403263558582826, disc_loss = 0.08880034864456816
Trained batch 550 in epoch 1, gen_loss = 0.4402402573942922, disc_loss = 0.08867032740589657
Trained batch 551 in epoch 1, gen_loss = 0.44015597568257997, disc_loss = 0.08861939674344561
Trained batch 552 in epoch 1, gen_loss = 0.440135807499532, disc_loss = 0.08852401572308262
Trained batch 553 in epoch 1, gen_loss = 0.44032891218412656, disc_loss = 0.08860778708905251
Trained batch 554 in epoch 1, gen_loss = 0.440389896298314, disc_loss = 0.08857635287651876
Trained batch 555 in epoch 1, gen_loss = 0.4404075245955865, disc_loss = 0.08846030419310488
Trained batch 556 in epoch 1, gen_loss = 0.4404171870576629, disc_loss = 0.08833003006842075
Trained batch 557 in epoch 1, gen_loss = 0.44055220340528795, disc_loss = 0.08824146809523732
Trained batch 558 in epoch 1, gen_loss = 0.4405342428436859, disc_loss = 0.08819177442385227
Trained batch 559 in epoch 1, gen_loss = 0.4405368925205299, disc_loss = 0.08810956352556656
Trained batch 560 in epoch 1, gen_loss = 0.4407397311001538, disc_loss = 0.08797220309860938
Trained batch 561 in epoch 1, gen_loss = 0.44088629386603195, disc_loss = 0.08791756964523968
Trained batch 562 in epoch 1, gen_loss = 0.44083319104162455, disc_loss = 0.08777956526269921
Trained batch 563 in epoch 1, gen_loss = 0.4408961722085662, disc_loss = 0.08766127288909563
Trained batch 564 in epoch 1, gen_loss = 0.4409095437653297, disc_loss = 0.08759859267259594
Trained batch 565 in epoch 1, gen_loss = 0.44113205478595763, disc_loss = 0.08754346141585086
Trained batch 566 in epoch 1, gen_loss = 0.4411480791038937, disc_loss = 0.08740240453891916
Trained batch 567 in epoch 1, gen_loss = 0.4410975815229852, disc_loss = 0.08735791118454818
Trained batch 568 in epoch 1, gen_loss = 0.4411190570134061, disc_loss = 0.08725294719085176
Trained batch 569 in epoch 1, gen_loss = 0.4410677099959892, disc_loss = 0.08731208652290598
Trained batch 570 in epoch 1, gen_loss = 0.44103501964158226, disc_loss = 0.08762145182851787
Trained batch 571 in epoch 1, gen_loss = 0.44107483837987993, disc_loss = 0.08751046247096485
Trained batch 572 in epoch 1, gen_loss = 0.44122026759292443, disc_loss = 0.08760486419489819
Trained batch 573 in epoch 1, gen_loss = 0.44122268430862693, disc_loss = 0.08752888792684425
Trained batch 574 in epoch 1, gen_loss = 0.44108325258545256, disc_loss = 0.08748414302487736
Trained batch 575 in epoch 1, gen_loss = 0.4413435001236697, disc_loss = 0.08740008000071005
Trained batch 576 in epoch 1, gen_loss = 0.44146577742731963, disc_loss = 0.08728861713062075
Trained batch 577 in epoch 1, gen_loss = 0.4416071587470988, disc_loss = 0.08720355399539469
Trained batch 578 in epoch 1, gen_loss = 0.441540769808033, disc_loss = 0.08720598901124971
Trained batch 579 in epoch 1, gen_loss = 0.44166248846670675, disc_loss = 0.08713141368091877
Trained batch 580 in epoch 1, gen_loss = 0.4415571333106332, disc_loss = 0.08704390177878323
Trained batch 581 in epoch 1, gen_loss = 0.44151869206289246, disc_loss = 0.08698525527312942
Trained batch 582 in epoch 1, gen_loss = 0.4415816227629091, disc_loss = 0.08687009037940366
Trained batch 583 in epoch 1, gen_loss = 0.4415276127625002, disc_loss = 0.08675788417107694
Trained batch 584 in epoch 1, gen_loss = 0.44168148524740825, disc_loss = 0.08664829625119257
Trained batch 585 in epoch 1, gen_loss = 0.4418572962996089, disc_loss = 0.08652491563511536
Trained batch 586 in epoch 1, gen_loss = 0.4418235957317905, disc_loss = 0.08652022805737626
Trained batch 587 in epoch 1, gen_loss = 0.4418840238533052, disc_loss = 0.08641461584064476
Trained batch 588 in epoch 1, gen_loss = 0.4420470979399916, disc_loss = 0.08633525542604954
Trained batch 589 in epoch 1, gen_loss = 0.44193645306562973, disc_loss = 0.08644244556741441
Trained batch 590 in epoch 1, gen_loss = 0.4420403162940908, disc_loss = 0.08663027139314389
Trained batch 591 in epoch 1, gen_loss = 0.4419301817243969, disc_loss = 0.08664603284214044
Trained batch 592 in epoch 1, gen_loss = 0.44192573397999874, disc_loss = 0.08662184551012707
Trained batch 593 in epoch 1, gen_loss = 0.4419143999666477, disc_loss = 0.08655902072442351
Trained batch 594 in epoch 1, gen_loss = 0.4419661860506074, disc_loss = 0.0864785161291977
Trained batch 595 in epoch 1, gen_loss = 0.44193754115160677, disc_loss = 0.086741505298551
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.4049604535102844, disc_loss = 0.13599705696105957
Trained batch 1 in epoch 2, gen_loss = 0.4090545177459717, disc_loss = 0.10177040472626686
Trained batch 2 in epoch 2, gen_loss = 0.428117702404658, disc_loss = 0.1002361848950386
Trained batch 3 in epoch 2, gen_loss = 0.4367288202047348, disc_loss = 0.09399986453354359
Trained batch 4 in epoch 2, gen_loss = 0.43904815912246703, disc_loss = 0.0810641199350357
Trained batch 5 in epoch 2, gen_loss = 0.4426758984724681, disc_loss = 0.07068390647570293
Trained batch 6 in epoch 2, gen_loss = 0.4397695575441633, disc_loss = 0.06317285262048244
Trained batch 7 in epoch 2, gen_loss = 0.4357209876179695, disc_loss = 0.058016108116135
Trained batch 8 in epoch 2, gen_loss = 0.4338812265131209, disc_loss = 0.05738363849620024
Trained batch 9 in epoch 2, gen_loss = 0.4317188709974289, disc_loss = 0.05307405330240726
Trained batch 10 in epoch 2, gen_loss = 0.43259442123499786, disc_loss = 0.04921972650018605
Trained batch 11 in epoch 2, gen_loss = 0.4391944731275241, disc_loss = 0.04932237043976784
Trained batch 12 in epoch 2, gen_loss = 0.43311139711966884, disc_loss = 0.05104497247017347
Trained batch 13 in epoch 2, gen_loss = 0.43591407367161344, disc_loss = 0.05243141097681863
Trained batch 14 in epoch 2, gen_loss = 0.43671345710754395, disc_loss = 0.05214886640508969
Trained batch 15 in epoch 2, gen_loss = 0.4377738647162914, disc_loss = 0.049971997272223234
Trained batch 16 in epoch 2, gen_loss = 0.43972280796836405, disc_loss = 0.048283341176369614
Trained batch 17 in epoch 2, gen_loss = 0.4409646491209666, disc_loss = 0.04667016346421507
Trained batch 18 in epoch 2, gen_loss = 0.4454918284165232, disc_loss = 0.04522517833270525
Trained batch 19 in epoch 2, gen_loss = 0.4469910651445389, disc_loss = 0.045519576966762544
Trained batch 20 in epoch 2, gen_loss = 0.45069769450596403, disc_loss = 0.05152288717882974
Trained batch 21 in epoch 2, gen_loss = 0.4498970847238194, disc_loss = 0.05223125930536877
Trained batch 22 in epoch 2, gen_loss = 0.44728061168090155, disc_loss = 0.05251711185859597
Trained batch 23 in epoch 2, gen_loss = 0.448525366683801, disc_loss = 0.053601548075675964
Trained batch 24 in epoch 2, gen_loss = 0.4472528910636902, disc_loss = 0.05251026146113873
Trained batch 25 in epoch 2, gen_loss = 0.4440729044950925, disc_loss = 0.051498739765240595
Trained batch 26 in epoch 2, gen_loss = 0.443717431139063, disc_loss = 0.0510004507722678
Trained batch 27 in epoch 2, gen_loss = 0.4429444372653961, disc_loss = 0.053020469046064785
Trained batch 28 in epoch 2, gen_loss = 0.4410838135357561, disc_loss = 0.06397565711161186
Trained batch 29 in epoch 2, gen_loss = 0.4390405019124349, disc_loss = 0.06310480559865633
Trained batch 30 in epoch 2, gen_loss = 0.4425384190774733, disc_loss = 0.06414129392754647
Trained batch 31 in epoch 2, gen_loss = 0.4422314651310444, disc_loss = 0.06363961740862578
Trained batch 32 in epoch 2, gen_loss = 0.44326776085477887, disc_loss = 0.06230549265940984
Trained batch 33 in epoch 2, gen_loss = 0.4450077993028304, disc_loss = 0.06078466345720431
Trained batch 34 in epoch 2, gen_loss = 0.44856146233422417, disc_loss = 0.06055067575403622
Trained batch 35 in epoch 2, gen_loss = 0.4466840583417151, disc_loss = 0.061461299347380795
Trained batch 36 in epoch 2, gen_loss = 0.4481951570188677, disc_loss = 0.06167054589133005
Trained batch 37 in epoch 2, gen_loss = 0.4484917992039731, disc_loss = 0.060351381323447355
Trained batch 38 in epoch 2, gen_loss = 0.4488689525005145, disc_loss = 0.059415282777104624
Trained batch 39 in epoch 2, gen_loss = 0.44920329228043554, disc_loss = 0.05851268889382481
Trained batch 40 in epoch 2, gen_loss = 0.4497819651917713, disc_loss = 0.05821763869465851
Trained batch 41 in epoch 2, gen_loss = 0.44990688207603635, disc_loss = 0.05774733504014356
Trained batch 42 in epoch 2, gen_loss = 0.44945059127585835, disc_loss = 0.057667312060677725
Trained batch 43 in epoch 2, gen_loss = 0.4489268646998839, disc_loss = 0.0568103123117577
Trained batch 44 in epoch 2, gen_loss = 0.4509518159760369, disc_loss = 0.05648628928595119
Trained batch 45 in epoch 2, gen_loss = 0.45063695311546326, disc_loss = 0.05565865086796491
Trained batch 46 in epoch 2, gen_loss = 0.45171405533526804, disc_loss = 0.05554051197906758
Trained batch 47 in epoch 2, gen_loss = 0.4498698798318704, disc_loss = 0.05485699838027358
Trained batch 48 in epoch 2, gen_loss = 0.44952618954133017, disc_loss = 0.054598955171448846
Trained batch 49 in epoch 2, gen_loss = 0.4481558895111084, disc_loss = 0.054796172529459
Trained batch 50 in epoch 2, gen_loss = 0.44591667488509534, disc_loss = 0.057829699241647534
Trained batch 51 in epoch 2, gen_loss = 0.44690106637202776, disc_loss = 0.060787870190464534
Trained batch 52 in epoch 2, gen_loss = 0.44772946216025444, disc_loss = 0.06000744358126847
Trained batch 53 in epoch 2, gen_loss = 0.44756621729444573, disc_loss = 0.05971734436159885
Trained batch 54 in epoch 2, gen_loss = 0.4480003291910345, disc_loss = 0.059042073244398294
Trained batch 55 in epoch 2, gen_loss = 0.44681096768804957, disc_loss = 0.058426234438749294
Trained batch 56 in epoch 2, gen_loss = 0.4477977109582801, disc_loss = 0.058289397540583945
Trained batch 57 in epoch 2, gen_loss = 0.44965890923450735, disc_loss = 0.05897099161841746
Trained batch 58 in epoch 2, gen_loss = 0.44968499369540454, disc_loss = 0.05891488438819425
Trained batch 59 in epoch 2, gen_loss = 0.44964709182580315, disc_loss = 0.058840540268768865
Trained batch 60 in epoch 2, gen_loss = 0.4493101024236835, disc_loss = 0.058089089228725826
Trained batch 61 in epoch 2, gen_loss = 0.4482253376514681, disc_loss = 0.05806333202147676
Trained batch 62 in epoch 2, gen_loss = 0.4481765036545103, disc_loss = 0.057402732796848766
Trained batch 63 in epoch 2, gen_loss = 0.44853481696918607, disc_loss = 0.05893439261126332
Trained batch 64 in epoch 2, gen_loss = 0.44826393173291135, disc_loss = 0.05969423098632923
Trained batch 65 in epoch 2, gen_loss = 0.4486214324380412, disc_loss = 0.05908138860920162
Trained batch 66 in epoch 2, gen_loss = 0.44966641691193654, disc_loss = 0.058810451054083765
Trained batch 67 in epoch 2, gen_loss = 0.4482103069038952, disc_loss = 0.05863544320249382
Trained batch 68 in epoch 2, gen_loss = 0.44886960456336755, disc_loss = 0.0583189785534489
Trained batch 69 in epoch 2, gen_loss = 0.4490475003208433, disc_loss = 0.057759399100073744
Trained batch 70 in epoch 2, gen_loss = 0.4501745276887652, disc_loss = 0.05746218160739247
Trained batch 71 in epoch 2, gen_loss = 0.44934243833025295, disc_loss = 0.05710047501553264
Trained batch 72 in epoch 2, gen_loss = 0.44894365088580407, disc_loss = 0.05687134751208024
Trained batch 73 in epoch 2, gen_loss = 0.4496670760012962, disc_loss = 0.05717723491928867
Trained batch 74 in epoch 2, gen_loss = 0.44972060004870096, disc_loss = 0.05737123725314935
Trained batch 75 in epoch 2, gen_loss = 0.4501312218214336, disc_loss = 0.05682266449653789
Trained batch 76 in epoch 2, gen_loss = 0.4500159698647338, disc_loss = 0.0563858352214485
Trained batch 77 in epoch 2, gen_loss = 0.45044571657975513, disc_loss = 0.056128779999338664
Trained batch 78 in epoch 2, gen_loss = 0.451057182082647, disc_loss = 0.05588084261251401
Trained batch 79 in epoch 2, gen_loss = 0.4511864218860865, disc_loss = 0.055341178574599324
Trained batch 80 in epoch 2, gen_loss = 0.4504793871332098, disc_loss = 0.05483321541989291
Trained batch 81 in epoch 2, gen_loss = 0.4510076205904891, disc_loss = 0.05518075478513066
Trained batch 82 in epoch 2, gen_loss = 0.4510803240609456, disc_loss = 0.05541224625096264
Trained batch 83 in epoch 2, gen_loss = 0.45172513489212307, disc_loss = 0.05489279868613396
Trained batch 84 in epoch 2, gen_loss = 0.4524208619314082, disc_loss = 0.05489435171818032
Trained batch 85 in epoch 2, gen_loss = 0.4519836795191432, disc_loss = 0.05448696491590073
Trained batch 86 in epoch 2, gen_loss = 0.45110640957437714, disc_loss = 0.054373787716031075
Trained batch 87 in epoch 2, gen_loss = 0.4518507363444025, disc_loss = 0.05419703943400898
Trained batch 88 in epoch 2, gen_loss = 0.45196138104695954, disc_loss = 0.053705692940046276
Trained batch 89 in epoch 2, gen_loss = 0.4528175840775172, disc_loss = 0.05326253662092818
Trained batch 90 in epoch 2, gen_loss = 0.4526719346151247, disc_loss = 0.052757205426242654
Trained batch 91 in epoch 2, gen_loss = 0.45231757636951364, disc_loss = 0.052415522954264736
Trained batch 92 in epoch 2, gen_loss = 0.4521411378537455, disc_loss = 0.05278182631078106
Trained batch 93 in epoch 2, gen_loss = 0.45229531412428997, disc_loss = 0.05299131168508308
Trained batch 94 in epoch 2, gen_loss = 0.4520931005477905, disc_loss = 0.052679843244780054
Trained batch 95 in epoch 2, gen_loss = 0.4531866380323966, disc_loss = 0.05366351182359116
Trained batch 96 in epoch 2, gen_loss = 0.4527030384417662, disc_loss = 0.0537934640336052
Trained batch 97 in epoch 2, gen_loss = 0.4527244841565891, disc_loss = 0.05351805463148167
Trained batch 98 in epoch 2, gen_loss = 0.4522688840374802, disc_loss = 0.05418872416038254
Trained batch 99 in epoch 2, gen_loss = 0.4518984717130661, disc_loss = 0.05436301235575229
Trained batch 100 in epoch 2, gen_loss = 0.45148717560390433, disc_loss = 0.05397192416897062
Trained batch 101 in epoch 2, gen_loss = 0.450853069915491, disc_loss = 0.05444299859250439
Trained batch 102 in epoch 2, gen_loss = 0.4505372883625401, disc_loss = 0.05539479409118445
Trained batch 103 in epoch 2, gen_loss = 0.4507698370860173, disc_loss = 0.05527923412424011
Trained batch 104 in epoch 2, gen_loss = 0.44995052104904537, disc_loss = 0.055255089012817254
Trained batch 105 in epoch 2, gen_loss = 0.4508577368731769, disc_loss = 0.055125162554553374
Trained batch 106 in epoch 2, gen_loss = 0.4509034087167722, disc_loss = 0.05480758891501856
Trained batch 107 in epoch 2, gen_loss = 0.4504202753305435, disc_loss = 0.05480289770100542
Trained batch 108 in epoch 2, gen_loss = 0.45080610644926716, disc_loss = 0.055853117569221546
Trained batch 109 in epoch 2, gen_loss = 0.4504042861136523, disc_loss = 0.05621531335213645
Trained batch 110 in epoch 2, gen_loss = 0.4502080442669155, disc_loss = 0.056296811854416456
Trained batch 111 in epoch 2, gen_loss = 0.45073287827628, disc_loss = 0.057916969198101596
Trained batch 112 in epoch 2, gen_loss = 0.44974678306453, disc_loss = 0.06007304168265082
Trained batch 113 in epoch 2, gen_loss = 0.449236700670761, disc_loss = 0.059817450876723514
Trained batch 114 in epoch 2, gen_loss = 0.4491461440272953, disc_loss = 0.059799736677466526
Trained batch 115 in epoch 2, gen_loss = 0.44923540461679984, disc_loss = 0.05997777133296918
Trained batch 116 in epoch 2, gen_loss = 0.44900404184292525, disc_loss = 0.05999769904435827
Trained batch 117 in epoch 2, gen_loss = 0.4484820989734035, disc_loss = 0.0598362638828171
Trained batch 118 in epoch 2, gen_loss = 0.4485496748395327, disc_loss = 0.05957093384476895
Trained batch 119 in epoch 2, gen_loss = 0.4483116514980793, disc_loss = 0.05979498072604959
Trained batch 120 in epoch 2, gen_loss = 0.4481851468401507, disc_loss = 0.05967101953877521
Trained batch 121 in epoch 2, gen_loss = 0.4479108230500925, disc_loss = 0.059770532444760695
Trained batch 122 in epoch 2, gen_loss = 0.44836651333948463, disc_loss = 0.059705098443551034
Trained batch 123 in epoch 2, gen_loss = 0.448044061180084, disc_loss = 0.059424669485569244
Trained batch 124 in epoch 2, gen_loss = 0.4481622841358185, disc_loss = 0.05917079556360841
Trained batch 125 in epoch 2, gen_loss = 0.4477928973852642, disc_loss = 0.058878879243921906
Trained batch 126 in epoch 2, gen_loss = 0.44761902164286516, disc_loss = 0.058570322166307004
Trained batch 127 in epoch 2, gen_loss = 0.4487773540895432, disc_loss = 0.058876760846032994
Trained batch 128 in epoch 2, gen_loss = 0.44881451314733933, disc_loss = 0.0596796536002337
Trained batch 129 in epoch 2, gen_loss = 0.4491500013149702, disc_loss = 0.05942239738785877
Trained batch 130 in epoch 2, gen_loss = 0.449154518032802, disc_loss = 0.05903726883360561
Trained batch 131 in epoch 2, gen_loss = 0.44868109059153183, disc_loss = 0.05895299330762954
Trained batch 132 in epoch 2, gen_loss = 0.4492113753817135, disc_loss = 0.058771124617301655
Trained batch 133 in epoch 2, gen_loss = 0.44898994778519247, disc_loss = 0.058798768422079845
Trained batch 134 in epoch 2, gen_loss = 0.44949575574309736, disc_loss = 0.05886942392767028
Trained batch 135 in epoch 2, gen_loss = 0.449332136879949, disc_loss = 0.05932442067697754
Trained batch 136 in epoch 2, gen_loss = 0.4497347709036221, disc_loss = 0.05953607231337767
Trained batch 137 in epoch 2, gen_loss = 0.4497581143742022, disc_loss = 0.05925780468944298
Trained batch 138 in epoch 2, gen_loss = 0.4497172883946261, disc_loss = 0.059221514765334
Trained batch 139 in epoch 2, gen_loss = 0.4498768925666809, disc_loss = 0.059149877450961084
Trained batch 140 in epoch 2, gen_loss = 0.4501258284910351, disc_loss = 0.058909797991447625
Trained batch 141 in epoch 2, gen_loss = 0.4497620956578725, disc_loss = 0.058664391948644756
Trained batch 142 in epoch 2, gen_loss = 0.4492746514457089, disc_loss = 0.05854091241343559
Trained batch 143 in epoch 2, gen_loss = 0.4494321033772495, disc_loss = 0.05938257065200661
Trained batch 144 in epoch 2, gen_loss = 0.4492294469784046, disc_loss = 0.059409641914455025
Trained batch 145 in epoch 2, gen_loss = 0.4491597250716327, disc_loss = 0.059433890382236204
Trained batch 146 in epoch 2, gen_loss = 0.4494901074438679, disc_loss = 0.059862656509313654
Trained batch 147 in epoch 2, gen_loss = 0.44938440278575226, disc_loss = 0.05991051623257934
Trained batch 148 in epoch 2, gen_loss = 0.4494275066676556, disc_loss = 0.059760142195869816
Trained batch 149 in epoch 2, gen_loss = 0.44928862114747364, disc_loss = 0.06050403058839341
Trained batch 150 in epoch 2, gen_loss = 0.44882320114318897, disc_loss = 0.06124637419333225
Trained batch 151 in epoch 2, gen_loss = 0.4489435767264743, disc_loss = 0.061146998168336915
Trained batch 152 in epoch 2, gen_loss = 0.4497792379918441, disc_loss = 0.061594409956383746
Trained batch 153 in epoch 2, gen_loss = 0.44958141987973993, disc_loss = 0.06210561742848874
Trained batch 154 in epoch 2, gen_loss = 0.449588103448191, disc_loss = 0.06186877830675052
Trained batch 155 in epoch 2, gen_loss = 0.4499826278441992, disc_loss = 0.06195199776452799
Trained batch 156 in epoch 2, gen_loss = 0.44967915374002637, disc_loss = 0.0618716793484796
Trained batch 157 in epoch 2, gen_loss = 0.4491788182832018, disc_loss = 0.06155721656683408
Trained batch 158 in epoch 2, gen_loss = 0.4492642877611724, disc_loss = 0.061261997262379096
Trained batch 159 in epoch 2, gen_loss = 0.44974849950522183, disc_loss = 0.06096948634658474
Trained batch 160 in epoch 2, gen_loss = 0.4499531434559674, disc_loss = 0.06069843256151917
Trained batch 161 in epoch 2, gen_loss = 0.4492110889634968, disc_loss = 0.06040877981950747
Trained batch 162 in epoch 2, gen_loss = 0.4487898256515433, disc_loss = 0.06024892575341774
Trained batch 163 in epoch 2, gen_loss = 0.4490443469911087, disc_loss = 0.060316167155666865
Trained batch 164 in epoch 2, gen_loss = 0.4491847630703088, disc_loss = 0.06010422553923545
Trained batch 165 in epoch 2, gen_loss = 0.4493224566959473, disc_loss = 0.06009574042330215
Trained batch 166 in epoch 2, gen_loss = 0.44988957672062035, disc_loss = 0.059809761687912445
Trained batch 167 in epoch 2, gen_loss = 0.4494633110506194, disc_loss = 0.05950204134708093
Trained batch 168 in epoch 2, gen_loss = 0.44931677601041176, disc_loss = 0.059218705606994014
Trained batch 169 in epoch 2, gen_loss = 0.44892518257393554, disc_loss = 0.058978077596710886
Trained batch 170 in epoch 2, gen_loss = 0.4493565477474391, disc_loss = 0.05869625447514026
Trained batch 171 in epoch 2, gen_loss = 0.4493981715898181, disc_loss = 0.05838603221778866
Trained batch 172 in epoch 2, gen_loss = 0.44966162818704725, disc_loss = 0.058126438761700615
Trained batch 173 in epoch 2, gen_loss = 0.44999320188473013, disc_loss = 0.05790113171444799
Trained batch 174 in epoch 2, gen_loss = 0.4497267058917454, disc_loss = 0.0580570097666766
Trained batch 175 in epoch 2, gen_loss = 0.45021703907034616, disc_loss = 0.057926151327344334
Trained batch 176 in epoch 2, gen_loss = 0.4505012654988779, disc_loss = 0.057725090152021014
Trained batch 177 in epoch 2, gen_loss = 0.4504835322666704, disc_loss = 0.05754768163792454
Trained batch 178 in epoch 2, gen_loss = 0.4501061188109094, disc_loss = 0.0573136298136796
Trained batch 179 in epoch 2, gen_loss = 0.45020657579104106, disc_loss = 0.057030017081544634
Trained batch 180 in epoch 2, gen_loss = 0.45050510517141434, disc_loss = 0.056768767996202354
Trained batch 181 in epoch 2, gen_loss = 0.4505554804435143, disc_loss = 0.05657825093706149
Trained batch 182 in epoch 2, gen_loss = 0.4507676595872869, disc_loss = 0.05631686885754675
Trained batch 183 in epoch 2, gen_loss = 0.45082590275484585, disc_loss = 0.056101539134270635
Trained batch 184 in epoch 2, gen_loss = 0.45147143215746494, disc_loss = 0.05597587983199471
Trained batch 185 in epoch 2, gen_loss = 0.45166627662156217, disc_loss = 0.05581172435764744
Trained batch 186 in epoch 2, gen_loss = 0.4514456149091058, disc_loss = 0.05557130717169394
Trained batch 187 in epoch 2, gen_loss = 0.45189923618702177, disc_loss = 0.05541836370050194
Trained batch 188 in epoch 2, gen_loss = 0.451652345203218, disc_loss = 0.05523362825501454
Trained batch 189 in epoch 2, gen_loss = 0.4518684459360022, disc_loss = 0.05512519885393742
Trained batch 190 in epoch 2, gen_loss = 0.45189848120924064, disc_loss = 0.05492317774796283
Trained batch 191 in epoch 2, gen_loss = 0.45220011410613853, disc_loss = 0.05467753546690801
Trained batch 192 in epoch 2, gen_loss = 0.45237788558006287, disc_loss = 0.05444219953819646
Trained batch 193 in epoch 2, gen_loss = 0.45233115031547155, disc_loss = 0.054195975930401194
Trained batch 194 in epoch 2, gen_loss = 0.4524174745266254, disc_loss = 0.0542755040483406
Trained batch 195 in epoch 2, gen_loss = 0.45204702551875797, disc_loss = 0.055786933738035054
Trained batch 196 in epoch 2, gen_loss = 0.45206864684971454, disc_loss = 0.056068106112424944
Trained batch 197 in epoch 2, gen_loss = 0.45175185332996676, disc_loss = 0.05609230925517176
Trained batch 198 in epoch 2, gen_loss = 0.4520046008591676, disc_loss = 0.05589383496813963
Trained batch 199 in epoch 2, gen_loss = 0.4519212406873703, disc_loss = 0.055757292851340026
Trained batch 200 in epoch 2, gen_loss = 0.45190895137502185, disc_loss = 0.055625904710564895
Trained batch 201 in epoch 2, gen_loss = 0.4522167456032026, disc_loss = 0.05583148472481361
Trained batch 202 in epoch 2, gen_loss = 0.4517839217714488, disc_loss = 0.05665339515521535
Trained batch 203 in epoch 2, gen_loss = 0.4516477988046758, disc_loss = 0.05681817267117474
Trained batch 204 in epoch 2, gen_loss = 0.45171255294869583, disc_loss = 0.05682852019942025
Trained batch 205 in epoch 2, gen_loss = 0.4511967385278165, disc_loss = 0.056634085033613356
Trained batch 206 in epoch 2, gen_loss = 0.4512748885269902, disc_loss = 0.056466653778843114
Trained batch 207 in epoch 2, gen_loss = 0.4510765621581903, disc_loss = 0.056489282357058704
Trained batch 208 in epoch 2, gen_loss = 0.4506411489687468, disc_loss = 0.05704272698619933
Trained batch 209 in epoch 2, gen_loss = 0.45082377408232005, disc_loss = 0.05694780108252806
Trained batch 210 in epoch 2, gen_loss = 0.4510198580145271, disc_loss = 0.05692772868958906
Trained batch 211 in epoch 2, gen_loss = 0.4505620181279362, disc_loss = 0.057000464370983814
Trained batch 212 in epoch 2, gen_loss = 0.4507222966129231, disc_loss = 0.05683315932497102
Trained batch 213 in epoch 2, gen_loss = 0.45046768678682986, disc_loss = 0.05662093218198377
Trained batch 214 in epoch 2, gen_loss = 0.450420088962067, disc_loss = 0.05646123055931787
Trained batch 215 in epoch 2, gen_loss = 0.45060264884873674, disc_loss = 0.05629973320281823
Trained batch 216 in epoch 2, gen_loss = 0.4504786824575767, disc_loss = 0.056506697927528673
Trained batch 217 in epoch 2, gen_loss = 0.45083119248578307, disc_loss = 0.05687788918127366
Trained batch 218 in epoch 2, gen_loss = 0.4510796525979151, disc_loss = 0.05672322985711911
Trained batch 219 in epoch 2, gen_loss = 0.45086179822683337, disc_loss = 0.056548935562287544
Trained batch 220 in epoch 2, gen_loss = 0.4510940597877244, disc_loss = 0.056384407993136355
Trained batch 221 in epoch 2, gen_loss = 0.4506492633540351, disc_loss = 0.05619565748844531
Trained batch 222 in epoch 2, gen_loss = 0.4505239215934223, disc_loss = 0.05609508210191745
Trained batch 223 in epoch 2, gen_loss = 0.45043035676436766, disc_loss = 0.05589026017904481
Trained batch 224 in epoch 2, gen_loss = 0.45076478534274633, disc_loss = 0.05608767911584841
Trained batch 225 in epoch 2, gen_loss = 0.450984289952084, disc_loss = 0.056056636787407035
Trained batch 226 in epoch 2, gen_loss = 0.4508425515916379, disc_loss = 0.05621214660442545
Trained batch 227 in epoch 2, gen_loss = 0.4508396702115996, disc_loss = 0.056479075790807735
Trained batch 228 in epoch 2, gen_loss = 0.45121453279491075, disc_loss = 0.05638016265609574
Trained batch 229 in epoch 2, gen_loss = 0.45073878622573355, disc_loss = 0.05648066615078436
Trained batch 230 in epoch 2, gen_loss = 0.45092721922057016, disc_loss = 0.056453015879038476
Trained batch 231 in epoch 2, gen_loss = 0.4507695721655056, disc_loss = 0.056365990880796496
Trained batch 232 in epoch 2, gen_loss = 0.45113080126021554, disc_loss = 0.056334229591882154
Trained batch 233 in epoch 2, gen_loss = 0.45075784228805804, disc_loss = 0.056240532720365964
Trained batch 234 in epoch 2, gen_loss = 0.4507086829936251, disc_loss = 0.05605127617439374
Trained batch 235 in epoch 2, gen_loss = 0.4508419160620641, disc_loss = 0.05595674488290955
Trained batch 236 in epoch 2, gen_loss = 0.4513579850961387, disc_loss = 0.05579198952882162
Trained batch 237 in epoch 2, gen_loss = 0.4509115057582615, disc_loss = 0.055806920521289986
Trained batch 238 in epoch 2, gen_loss = 0.4512017295699738, disc_loss = 0.05563819545777086
Trained batch 239 in epoch 2, gen_loss = 0.4512220434844494, disc_loss = 0.05598480018670671
Trained batch 240 in epoch 2, gen_loss = 0.45104571558627843, disc_loss = 0.05616166674690437
Trained batch 241 in epoch 2, gen_loss = 0.45097348007781446, disc_loss = 0.05599798551714433
Trained batch 242 in epoch 2, gen_loss = 0.45142564422799725, disc_loss = 0.05620240346708722
Trained batch 243 in epoch 2, gen_loss = 0.45134867153695374, disc_loss = 0.05606725544966452
Trained batch 244 in epoch 2, gen_loss = 0.4512625009429698, disc_loss = 0.05601823342279816
Trained batch 245 in epoch 2, gen_loss = 0.45156145229087613, disc_loss = 0.05588648043671335
Trained batch 246 in epoch 2, gen_loss = 0.4516171160255849, disc_loss = 0.055838935765313354
Trained batch 247 in epoch 2, gen_loss = 0.4512209704806728, disc_loss = 0.05581566210152702
Trained batch 248 in epoch 2, gen_loss = 0.4510117666309617, disc_loss = 0.05575885481002879
Trained batch 249 in epoch 2, gen_loss = 0.4508863798379898, disc_loss = 0.05574430117942393
Trained batch 250 in epoch 2, gen_loss = 0.4507988531038581, disc_loss = 0.0556058959304485
Trained batch 251 in epoch 2, gen_loss = 0.45112107942501706, disc_loss = 0.05553159247233813
Trained batch 252 in epoch 2, gen_loss = 0.45106007306000934, disc_loss = 0.05544480495338913
Trained batch 253 in epoch 2, gen_loss = 0.45080433950180143, disc_loss = 0.05530775337861338
Trained batch 254 in epoch 2, gen_loss = 0.4506400602705338, disc_loss = 0.055229158080456885
Trained batch 255 in epoch 2, gen_loss = 0.45011685020290315, disc_loss = 0.055141198807177716
Trained batch 256 in epoch 2, gen_loss = 0.45012210222533705, disc_loss = 0.055013064949153576
Trained batch 257 in epoch 2, gen_loss = 0.4503741227379141, disc_loss = 0.05499634132431748
Trained batch 258 in epoch 2, gen_loss = 0.4503948351361116, disc_loss = 0.0548470794424616
Trained batch 259 in epoch 2, gen_loss = 0.4503550954736196, disc_loss = 0.05469659490403361
Trained batch 260 in epoch 2, gen_loss = 0.45051751648329225, disc_loss = 0.05464945290544538
Trained batch 261 in epoch 2, gen_loss = 0.45072387716242374, disc_loss = 0.054473876094673086
Trained batch 262 in epoch 2, gen_loss = 0.4504039046202322, disc_loss = 0.05526346517301841
Trained batch 263 in epoch 2, gen_loss = 0.4507716118612073, disc_loss = 0.055758239300992114
Trained batch 264 in epoch 2, gen_loss = 0.45087231937444433, disc_loss = 0.05564988736449829
Trained batch 265 in epoch 2, gen_loss = 0.45062708742636487, disc_loss = 0.055583833403451216
Trained batch 266 in epoch 2, gen_loss = 0.4506256372741099, disc_loss = 0.0554210349258161
Trained batch 267 in epoch 2, gen_loss = 0.45062682521877007, disc_loss = 0.05525680659721091
Trained batch 268 in epoch 2, gen_loss = 0.4507262681275052, disc_loss = 0.055076693383748314
Trained batch 269 in epoch 2, gen_loss = 0.4507426296119337, disc_loss = 0.054898050943113584
Trained batch 270 in epoch 2, gen_loss = 0.45083811142347835, disc_loss = 0.05476542250717203
Trained batch 271 in epoch 2, gen_loss = 0.45079826344462004, disc_loss = 0.0545891427934882
Trained batch 272 in epoch 2, gen_loss = 0.45080061644424885, disc_loss = 0.05442851885211664
Trained batch 273 in epoch 2, gen_loss = 0.45094240712423395, disc_loss = 0.054249614944518375
Trained batch 274 in epoch 2, gen_loss = 0.4510284846479243, disc_loss = 0.054118685253303156
Trained batch 275 in epoch 2, gen_loss = 0.4509096000937448, disc_loss = 0.05394185577229043
Trained batch 276 in epoch 2, gen_loss = 0.45080634833242916, disc_loss = 0.0537815970630933
Trained batch 277 in epoch 2, gen_loss = 0.4510694296239949, disc_loss = 0.053625912557979175
Trained batch 278 in epoch 2, gen_loss = 0.45114679362184257, disc_loss = 0.05345542856081519
Trained batch 279 in epoch 2, gen_loss = 0.4510963444198881, disc_loss = 0.05328485371012773
Trained batch 280 in epoch 2, gen_loss = 0.45085492168032826, disc_loss = 0.05318545134492828
Trained batch 281 in epoch 2, gen_loss = 0.4509469193558321, disc_loss = 0.0530452597357914
Trained batch 282 in epoch 2, gen_loss = 0.4508081908360808, disc_loss = 0.05293801696082518
Trained batch 283 in epoch 2, gen_loss = 0.450792574336831, disc_loss = 0.05290593640406577
Trained batch 284 in epoch 2, gen_loss = 0.4504640061604349, disc_loss = 0.052745270908793856
Trained batch 285 in epoch 2, gen_loss = 0.4502490572370849, disc_loss = 0.052830460289219665
Trained batch 286 in epoch 2, gen_loss = 0.45042538092526824, disc_loss = 0.05275728636281727
Trained batch 287 in epoch 2, gen_loss = 0.4502262566238642, disc_loss = 0.05267473882284119
Trained batch 288 in epoch 2, gen_loss = 0.4501578151973474, disc_loss = 0.05256268123300121
Trained batch 289 in epoch 2, gen_loss = 0.45020530367719713, disc_loss = 0.05252199047405658
Trained batch 290 in epoch 2, gen_loss = 0.4499703005621933, disc_loss = 0.05254253662188131
Trained batch 291 in epoch 2, gen_loss = 0.45011203286990725, disc_loss = 0.052668304798155
Trained batch 292 in epoch 2, gen_loss = 0.45014248701899534, disc_loss = 0.0526844094898361
Trained batch 293 in epoch 2, gen_loss = 0.45009414577970697, disc_loss = 0.052559002096682385
Trained batch 294 in epoch 2, gen_loss = 0.4502001581555706, disc_loss = 0.05246165741740142
Trained batch 295 in epoch 2, gen_loss = 0.45000089312324654, disc_loss = 0.052407408218100866
Trained batch 296 in epoch 2, gen_loss = 0.45024115178320145, disc_loss = 0.052264101800166995
Trained batch 297 in epoch 2, gen_loss = 0.4504865106920268, disc_loss = 0.05217946127944645
Trained batch 298 in epoch 2, gen_loss = 0.4503976867151101, disc_loss = 0.05209488734092103
Trained batch 299 in epoch 2, gen_loss = 0.45056084235509236, disc_loss = 0.051955535101393856
Trained batch 300 in epoch 2, gen_loss = 0.45068909935776974, disc_loss = 0.051835394906888765
Trained batch 301 in epoch 2, gen_loss = 0.4507887652575575, disc_loss = 0.051685290108897435
Trained batch 302 in epoch 2, gen_loss = 0.45094539318541094, disc_loss = 0.05155548183462604
Trained batch 303 in epoch 2, gen_loss = 0.45108831879731853, disc_loss = 0.051415988329896016
Trained batch 304 in epoch 2, gen_loss = 0.45125083620430995, disc_loss = 0.051265096534654254
Trained batch 305 in epoch 2, gen_loss = 0.4511675229843925, disc_loss = 0.05116379630350161
Trained batch 306 in epoch 2, gen_loss = 0.45123258097164015, disc_loss = 0.05111143839202748
Trained batch 307 in epoch 2, gen_loss = 0.45127648947300847, disc_loss = 0.05098613303656654
Trained batch 308 in epoch 2, gen_loss = 0.4513064264093788, disc_loss = 0.05094436366068844
Trained batch 309 in epoch 2, gen_loss = 0.45134168238409106, disc_loss = 0.05084069901025824
Trained batch 310 in epoch 2, gen_loss = 0.4515310212538557, disc_loss = 0.05070817632708471
Trained batch 311 in epoch 2, gen_loss = 0.45163403699795407, disc_loss = 0.05059999739601969
Trained batch 312 in epoch 2, gen_loss = 0.4515777531142433, disc_loss = 0.05056791664354098
Trained batch 313 in epoch 2, gen_loss = 0.45126417734820373, disc_loss = 0.05061820611968684
Trained batch 314 in epoch 2, gen_loss = 0.4511762324779753, disc_loss = 0.05070832548958678
Trained batch 315 in epoch 2, gen_loss = 0.4509841644122631, disc_loss = 0.05078277149667987
Trained batch 316 in epoch 2, gen_loss = 0.450916557375941, disc_loss = 0.0507491073594649
Trained batch 317 in epoch 2, gen_loss = 0.4509667417725677, disc_loss = 0.0506204240472179
Trained batch 318 in epoch 2, gen_loss = 0.4508189189022985, disc_loss = 0.05061697423440582
Trained batch 319 in epoch 2, gen_loss = 0.45113927461206915, disc_loss = 0.05058093840052606
Trained batch 320 in epoch 2, gen_loss = 0.45140149455946926, disc_loss = 0.05048081600411891
Trained batch 321 in epoch 2, gen_loss = 0.451407844235438, disc_loss = 0.05047888595824888
Trained batch 322 in epoch 2, gen_loss = 0.4514222245651871, disc_loss = 0.05037402174934376
Trained batch 323 in epoch 2, gen_loss = 0.45151268414877077, disc_loss = 0.05032106758135566
Trained batch 324 in epoch 2, gen_loss = 0.45157286717341494, disc_loss = 0.05022315776835267
Trained batch 325 in epoch 2, gen_loss = 0.451483077249644, disc_loss = 0.05010112588568105
Trained batch 326 in epoch 2, gen_loss = 0.4514750147449132, disc_loss = 0.04996748135171671
Trained batch 327 in epoch 2, gen_loss = 0.4515850562147978, disc_loss = 0.049876924335854354
Trained batch 328 in epoch 2, gen_loss = 0.4514651988777346, disc_loss = 0.049825859597196244
Trained batch 329 in epoch 2, gen_loss = 0.4513474056214997, disc_loss = 0.0497075895454283
Trained batch 330 in epoch 2, gen_loss = 0.45122275782855975, disc_loss = 0.0495928007943325
Trained batch 331 in epoch 2, gen_loss = 0.4512911841093776, disc_loss = 0.049466083265268745
Trained batch 332 in epoch 2, gen_loss = 0.4515677903507565, disc_loss = 0.04935816213259244
Trained batch 333 in epoch 2, gen_loss = 0.4514422120448358, disc_loss = 0.04940773402675317
Trained batch 334 in epoch 2, gen_loss = 0.45151106181429396, disc_loss = 0.049415791044428725
Trained batch 335 in epoch 2, gen_loss = 0.45125665941408705, disc_loss = 0.04928242662572302
Trained batch 336 in epoch 2, gen_loss = 0.45116717313092963, disc_loss = 0.049515276430147075
Trained batch 337 in epoch 2, gen_loss = 0.451418850548874, disc_loss = 0.04980632291484029
Trained batch 338 in epoch 2, gen_loss = 0.4512940630272778, disc_loss = 0.04969275160486587
Trained batch 339 in epoch 2, gen_loss = 0.4511755222783369, disc_loss = 0.04961839522207704
Trained batch 340 in epoch 2, gen_loss = 0.45091879254212475, disc_loss = 0.04951784319088649
Trained batch 341 in epoch 2, gen_loss = 0.45105307466453975, disc_loss = 0.04941662800857764
Trained batch 342 in epoch 2, gen_loss = 0.45100354809455206, disc_loss = 0.04931998659745293
Trained batch 343 in epoch 2, gen_loss = 0.45084752896150876, disc_loss = 0.04921943067199399
Trained batch 344 in epoch 2, gen_loss = 0.4507828796255416, disc_loss = 0.04909880008899431
Trained batch 345 in epoch 2, gen_loss = 0.45085478535277307, disc_loss = 0.048977486367978024
Trained batch 346 in epoch 2, gen_loss = 0.4509867434027559, disc_loss = 0.04892702383373029
Trained batch 347 in epoch 2, gen_loss = 0.45113137253056995, disc_loss = 0.0488061952343125
Trained batch 348 in epoch 2, gen_loss = 0.4512059630500553, disc_loss = 0.04869892402154455
Trained batch 349 in epoch 2, gen_loss = 0.45107551574707033, disc_loss = 0.048639517414516636
Trained batch 350 in epoch 2, gen_loss = 0.4510648800776555, disc_loss = 0.04854755420794981
Trained batch 351 in epoch 2, gen_loss = 0.45099677137014543, disc_loss = 0.04856178438454994
Trained batch 352 in epoch 2, gen_loss = 0.45084984435913583, disc_loss = 0.04860363135420356
Trained batch 353 in epoch 2, gen_loss = 0.4509970640900445, disc_loss = 0.0484964510539052
Trained batch 354 in epoch 2, gen_loss = 0.4510411373326476, disc_loss = 0.04839309456981194
Trained batch 355 in epoch 2, gen_loss = 0.45110387062088825, disc_loss = 0.04828905159204654
Trained batch 356 in epoch 2, gen_loss = 0.45093216289993093, disc_loss = 0.048177083026805595
Trained batch 357 in epoch 2, gen_loss = 0.4508199321324599, disc_loss = 0.04807044929231637
Trained batch 358 in epoch 2, gen_loss = 0.4506565498442371, disc_loss = 0.04798318983592653
Trained batch 359 in epoch 2, gen_loss = 0.450677896456586, disc_loss = 0.047864341297342135
Trained batch 360 in epoch 2, gen_loss = 0.4505102115985099, disc_loss = 0.04777251950328411
Trained batch 361 in epoch 2, gen_loss = 0.45052465755307214, disc_loss = 0.04765315699257286
Trained batch 362 in epoch 2, gen_loss = 0.4506037649865321, disc_loss = 0.04755243748944694
Trained batch 363 in epoch 2, gen_loss = 0.4505388943867369, disc_loss = 0.047436932407595875
Trained batch 364 in epoch 2, gen_loss = 0.4503875013083628, disc_loss = 0.047336160459185705
Trained batch 365 in epoch 2, gen_loss = 0.4504238828772404, disc_loss = 0.04728674003727164
Trained batch 366 in epoch 2, gen_loss = 0.4504106225856968, disc_loss = 0.04719571416629149
Trained batch 367 in epoch 2, gen_loss = 0.45051284984725976, disc_loss = 0.047120145994046216
Trained batch 368 in epoch 2, gen_loss = 0.4502856661956808, disc_loss = 0.04704251468085702
Trained batch 369 in epoch 2, gen_loss = 0.450231661184414, disc_loss = 0.046984374700617546
Trained batch 370 in epoch 2, gen_loss = 0.4500473923278305, disc_loss = 0.04692539950892972
Trained batch 371 in epoch 2, gen_loss = 0.4501117318868637, disc_loss = 0.046817640667550904
Trained batch 372 in epoch 2, gen_loss = 0.4502191135295275, disc_loss = 0.04672210056449589
Trained batch 373 in epoch 2, gen_loss = 0.4503719477570631, disc_loss = 0.046610330138106476
Trained batch 374 in epoch 2, gen_loss = 0.4504835476875305, disc_loss = 0.04650936187927922
Trained batch 375 in epoch 2, gen_loss = 0.4505833626744595, disc_loss = 0.04640080203535035
Trained batch 376 in epoch 2, gen_loss = 0.4505303466509761, disc_loss = 0.04629337217594529
Trained batch 377 in epoch 2, gen_loss = 0.4504878111774959, disc_loss = 0.04630398360159859
Trained batch 378 in epoch 2, gen_loss = 0.45034430925009433, disc_loss = 0.04666727175936103
Trained batch 379 in epoch 2, gen_loss = 0.4502976232453396, disc_loss = 0.04680320763788921
Trained batch 380 in epoch 2, gen_loss = 0.4503748299568657, disc_loss = 0.04684326814468021
Trained batch 381 in epoch 2, gen_loss = 0.4502096079406938, disc_loss = 0.04683529603275524
Trained batch 382 in epoch 2, gen_loss = 0.45014646960612065, disc_loss = 0.046779614570489826
Trained batch 383 in epoch 2, gen_loss = 0.45033227365153533, disc_loss = 0.04671818190278524
Trained batch 384 in epoch 2, gen_loss = 0.4505674322704216, disc_loss = 0.04671278890681925
Trained batch 385 in epoch 2, gen_loss = 0.4504285958918883, disc_loss = 0.04684955146708984
Trained batch 386 in epoch 2, gen_loss = 0.45062022392447915, disc_loss = 0.046781053965145994
Trained batch 387 in epoch 2, gen_loss = 0.45065778409390106, disc_loss = 0.046854856156398415
Trained batch 388 in epoch 2, gen_loss = 0.45080156137826816, disc_loss = 0.04681271913277038
Trained batch 389 in epoch 2, gen_loss = 0.4507015768534098, disc_loss = 0.0467804341756094
Trained batch 390 in epoch 2, gen_loss = 0.45060975289405764, disc_loss = 0.04672032316594058
Trained batch 391 in epoch 2, gen_loss = 0.4505330087731079, disc_loss = 0.04661490590601437
Trained batch 392 in epoch 2, gen_loss = 0.450435191772063, disc_loss = 0.046575750872426436
Trained batch 393 in epoch 2, gen_loss = 0.4506313280405732, disc_loss = 0.046577822323652165
Trained batch 394 in epoch 2, gen_loss = 0.4506593614439421, disc_loss = 0.04653675465762049
Trained batch 395 in epoch 2, gen_loss = 0.4505592381412333, disc_loss = 0.04661612126228371
Trained batch 396 in epoch 2, gen_loss = 0.4506881902139793, disc_loss = 0.04663362423596101
Trained batch 397 in epoch 2, gen_loss = 0.45068236541508433, disc_loss = 0.04653165209453422
Trained batch 398 in epoch 2, gen_loss = 0.4508978098556213, disc_loss = 0.04657867656236416
Trained batch 399 in epoch 2, gen_loss = 0.4509974183887243, disc_loss = 0.04659784848685376
Trained batch 400 in epoch 2, gen_loss = 0.45114044544108195, disc_loss = 0.046518019366860765
Trained batch 401 in epoch 2, gen_loss = 0.45105102650858275, disc_loss = 0.046571802015448756
Trained batch 402 in epoch 2, gen_loss = 0.45115304902824516, disc_loss = 0.04652922235027177
Trained batch 403 in epoch 2, gen_loss = 0.45130463792841036, disc_loss = 0.04643637492289158
Trained batch 404 in epoch 2, gen_loss = 0.45112256738874645, disc_loss = 0.04650241129997152
Trained batch 405 in epoch 2, gen_loss = 0.4509371731228429, disc_loss = 0.04640681908254883
Trained batch 406 in epoch 2, gen_loss = 0.4509535030592279, disc_loss = 0.04630942528390072
Trained batch 407 in epoch 2, gen_loss = 0.45089274644851685, disc_loss = 0.04620931922188759
Trained batch 408 in epoch 2, gen_loss = 0.45079696469901537, disc_loss = 0.046125890273819414
Trained batch 409 in epoch 2, gen_loss = 0.450748029423923, disc_loss = 0.04605340561602356
Trained batch 410 in epoch 2, gen_loss = 0.4509726677207761, disc_loss = 0.04596178974716079
Trained batch 411 in epoch 2, gen_loss = 0.4508950491842714, disc_loss = 0.0458864295861946
Trained batch 412 in epoch 2, gen_loss = 0.45101279799643784, disc_loss = 0.04586343385040147
Trained batch 413 in epoch 2, gen_loss = 0.4507839794176212, disc_loss = 0.045844875032010214
Trained batch 414 in epoch 2, gen_loss = 0.45054055524159625, disc_loss = 0.04577246822573873
Trained batch 415 in epoch 2, gen_loss = 0.4503218559548259, disc_loss = 0.045728131035083115
Trained batch 416 in epoch 2, gen_loss = 0.45047131681042035, disc_loss = 0.04572086418449557
Trained batch 417 in epoch 2, gen_loss = 0.4504692362683812, disc_loss = 0.045630459596835184
Trained batch 418 in epoch 2, gen_loss = 0.45069213222205495, disc_loss = 0.04557400714574929
Trained batch 419 in epoch 2, gen_loss = 0.4504936678778558, disc_loss = 0.04556653129180804
Trained batch 420 in epoch 2, gen_loss = 0.4504808819633765, disc_loss = 0.045481755987756535
Trained batch 421 in epoch 2, gen_loss = 0.4505552588057179, disc_loss = 0.045526020929561616
Trained batch 422 in epoch 2, gen_loss = 0.4504277697691681, disc_loss = 0.045562200639044634
Trained batch 423 in epoch 2, gen_loss = 0.4505461988584051, disc_loss = 0.04548199801543235
Trained batch 424 in epoch 2, gen_loss = 0.45051949430914484, disc_loss = 0.04547642274704926
Trained batch 425 in epoch 2, gen_loss = 0.4505565306390395, disc_loss = 0.045419917698783424
Trained batch 426 in epoch 2, gen_loss = 0.4505549688110307, disc_loss = 0.04550713644334632
Trained batch 427 in epoch 2, gen_loss = 0.4507883936863079, disc_loss = 0.045696206511624995
Trained batch 428 in epoch 2, gen_loss = 0.45091130037407773, disc_loss = 0.04561095918031596
Trained batch 429 in epoch 2, gen_loss = 0.4510276779878971, disc_loss = 0.04558762250966284
Trained batch 430 in epoch 2, gen_loss = 0.4510624762062683, disc_loss = 0.045528131661387784
Trained batch 431 in epoch 2, gen_loss = 0.45127979631501214, disc_loss = 0.0454609083902108
Trained batch 432 in epoch 2, gen_loss = 0.4512033381996199, disc_loss = 0.045469874228989626
Trained batch 433 in epoch 2, gen_loss = 0.4512702361229927, disc_loss = 0.04543677574208152
Trained batch 434 in epoch 2, gen_loss = 0.451431183157296, disc_loss = 0.045374342252168506
Trained batch 435 in epoch 2, gen_loss = 0.4513391911846782, disc_loss = 0.04552522575196494
Trained batch 436 in epoch 2, gen_loss = 0.45165469164979266, disc_loss = 0.0456126390091086
Trained batch 437 in epoch 2, gen_loss = 0.4515387571021302, disc_loss = 0.04552641379238706
Trained batch 438 in epoch 2, gen_loss = 0.451402573148319, disc_loss = 0.045558166778211506
Trained batch 439 in epoch 2, gen_loss = 0.45152437287298114, disc_loss = 0.04553719335764816
Trained batch 440 in epoch 2, gen_loss = 0.45139474616029096, disc_loss = 0.04550168976343982
Trained batch 441 in epoch 2, gen_loss = 0.45131698324939246, disc_loss = 0.04545450737021391
Trained batch 442 in epoch 2, gen_loss = 0.45117831028341976, disc_loss = 0.04536843211884121
Trained batch 443 in epoch 2, gen_loss = 0.4511043450853846, disc_loss = 0.045284629462765076
Trained batch 444 in epoch 2, gen_loss = 0.45110176024811993, disc_loss = 0.045244612158642394
Trained batch 445 in epoch 2, gen_loss = 0.4512624239440456, disc_loss = 0.045292093956241626
Trained batch 446 in epoch 2, gen_loss = 0.4510783773140619, disc_loss = 0.04520689732013833
Trained batch 447 in epoch 2, gen_loss = 0.45095822740612285, disc_loss = 0.04520071566574708
Trained batch 448 in epoch 2, gen_loss = 0.45115027336076, disc_loss = 0.045164316175982586
Trained batch 449 in epoch 2, gen_loss = 0.4512003024419149, disc_loss = 0.045115184201341536
Trained batch 450 in epoch 2, gen_loss = 0.4512516130629241, disc_loss = 0.045075397398488024
Trained batch 451 in epoch 2, gen_loss = 0.4513074824240355, disc_loss = 0.04501100923078943
Trained batch 452 in epoch 2, gen_loss = 0.4513009674107002, disc_loss = 0.044942047801608875
Trained batch 453 in epoch 2, gen_loss = 0.4513815619084278, disc_loss = 0.044863540425872026
Trained batch 454 in epoch 2, gen_loss = 0.45144042746051327, disc_loss = 0.044798792005199324
Trained batch 455 in epoch 2, gen_loss = 0.4514316334797625, disc_loss = 0.044751519989835
Trained batch 456 in epoch 2, gen_loss = 0.45138242332105827, disc_loss = 0.04472666992591918
Trained batch 457 in epoch 2, gen_loss = 0.45140032763043864, disc_loss = 0.04478603361406278
Trained batch 458 in epoch 2, gen_loss = 0.4514353248678261, disc_loss = 0.04471945650530634
Trained batch 459 in epoch 2, gen_loss = 0.45142730889113053, disc_loss = 0.044637988582658376
Trained batch 460 in epoch 2, gen_loss = 0.45165754864376173, disc_loss = 0.044614680864951226
Trained batch 461 in epoch 2, gen_loss = 0.4516768102651035, disc_loss = 0.04454881450548381
Trained batch 462 in epoch 2, gen_loss = 0.4515997323953822, disc_loss = 0.04448610377049408
Trained batch 463 in epoch 2, gen_loss = 0.451685746553643, disc_loss = 0.04441846968758659
Trained batch 464 in epoch 2, gen_loss = 0.4516951100800627, disc_loss = 0.04438753928188034
Trained batch 465 in epoch 2, gen_loss = 0.45169321911273597, disc_loss = 0.04431859736606607
Trained batch 466 in epoch 2, gen_loss = 0.4515074451296437, disc_loss = 0.044271086609864514
Trained batch 467 in epoch 2, gen_loss = 0.4514499062783698, disc_loss = 0.04420869595681628
Trained batch 468 in epoch 2, gen_loss = 0.4512524499313664, disc_loss = 0.04416097603293497
Trained batch 469 in epoch 2, gen_loss = 0.4512785083435951, disc_loss = 0.04412406412686439
Trained batch 470 in epoch 2, gen_loss = 0.4511551585546724, disc_loss = 0.044126644517016256
Trained batch 471 in epoch 2, gen_loss = 0.4512439759100898, disc_loss = 0.044059184502210406
Trained batch 472 in epoch 2, gen_loss = 0.45125787599646267, disc_loss = 0.04398097829739652
Trained batch 473 in epoch 2, gen_loss = 0.4512616251339892, disc_loss = 0.043906465422299215
Trained batch 474 in epoch 2, gen_loss = 0.45127467701309604, disc_loss = 0.04384476024657488
Trained batch 475 in epoch 2, gen_loss = 0.451296578310117, disc_loss = 0.04378763620522531
Trained batch 476 in epoch 2, gen_loss = 0.4512333616895496, disc_loss = 0.04370830101947021
Trained batch 477 in epoch 2, gen_loss = 0.4513088457255184, disc_loss = 0.04363180373241993
Trained batch 478 in epoch 2, gen_loss = 0.45127104375208094, disc_loss = 0.043557153416832514
Trained batch 479 in epoch 2, gen_loss = 0.45138550555954376, disc_loss = 0.04348451150872279
Trained batch 480 in epoch 2, gen_loss = 0.45129606133934863, disc_loss = 0.043419636393899175
Trained batch 481 in epoch 2, gen_loss = 0.45126593137677773, disc_loss = 0.04336732069389794
Trained batch 482 in epoch 2, gen_loss = 0.45136085053901986, disc_loss = 0.04334664672485882
Trained batch 483 in epoch 2, gen_loss = 0.45130483424367984, disc_loss = 0.043278908575423186
Trained batch 484 in epoch 2, gen_loss = 0.4512761704700509, disc_loss = 0.0432182505717213
Trained batch 485 in epoch 2, gen_loss = 0.4512496656841702, disc_loss = 0.04338461376722795
Trained batch 486 in epoch 2, gen_loss = 0.45117681588235575, disc_loss = 0.04374506162265335
Trained batch 487 in epoch 2, gen_loss = 0.45120631836232594, disc_loss = 0.04372212190665763
Trained batch 488 in epoch 2, gen_loss = 0.4513450721412105, disc_loss = 0.04419176573703229
Trained batch 489 in epoch 2, gen_loss = 0.4511251916082538, disc_loss = 0.04433461147056399
Trained batch 490 in epoch 2, gen_loss = 0.45119064105503914, disc_loss = 0.044329342592598645
Trained batch 491 in epoch 2, gen_loss = 0.4511812936847772, disc_loss = 0.04433340508759597
Trained batch 492 in epoch 2, gen_loss = 0.4512852796071925, disc_loss = 0.04437378199174093
Trained batch 493 in epoch 2, gen_loss = 0.45121431163689385, disc_loss = 0.044409340525588946
Trained batch 494 in epoch 2, gen_loss = 0.45119015670786, disc_loss = 0.04440304763295283
Trained batch 495 in epoch 2, gen_loss = 0.4512227575384801, disc_loss = 0.04433384852299857
Trained batch 496 in epoch 2, gen_loss = 0.4514298802410333, disc_loss = 0.044298393482256164
Trained batch 497 in epoch 2, gen_loss = 0.4514490242703373, disc_loss = 0.044235112226893566
Trained batch 498 in epoch 2, gen_loss = 0.451623683702014, disc_loss = 0.044178470445681135
Trained batch 499 in epoch 2, gen_loss = 0.4517397518157959, disc_loss = 0.04413024497311562
Trained batch 500 in epoch 2, gen_loss = 0.45169657129727436, disc_loss = 0.04408751631772774
Trained batch 501 in epoch 2, gen_loss = 0.4517519586233504, disc_loss = 0.04412530141370557
Trained batch 502 in epoch 2, gen_loss = 0.45178642655698725, disc_loss = 0.04408790087364392
Trained batch 503 in epoch 2, gen_loss = 0.45167688132515027, disc_loss = 0.044107839035513324
Trained batch 504 in epoch 2, gen_loss = 0.45184667612066365, disc_loss = 0.04406468377236535
Trained batch 505 in epoch 2, gen_loss = 0.4517868856785326, disc_loss = 0.04402100906906127
Trained batch 506 in epoch 2, gen_loss = 0.4518464804283496, disc_loss = 0.04397221839356675
Trained batch 507 in epoch 2, gen_loss = 0.4518529949343111, disc_loss = 0.04392177916194246
Trained batch 508 in epoch 2, gen_loss = 0.4518168817451754, disc_loss = 0.04386291997909751
Trained batch 509 in epoch 2, gen_loss = 0.45190787210183986, disc_loss = 0.043875004156657
Trained batch 510 in epoch 2, gen_loss = 0.4519364486818444, disc_loss = 0.04388949853402732
Trained batch 511 in epoch 2, gen_loss = 0.4518756053294055, disc_loss = 0.043872439858205325
Trained batch 512 in epoch 2, gen_loss = 0.45199141196804904, disc_loss = 0.04384586333658466
Trained batch 513 in epoch 2, gen_loss = 0.4521083307057503, disc_loss = 0.04377044181625725
Trained batch 514 in epoch 2, gen_loss = 0.4522169516503232, disc_loss = 0.04370663611272585
Trained batch 515 in epoch 2, gen_loss = 0.4520838933513146, disc_loss = 0.04363753648778034
Trained batch 516 in epoch 2, gen_loss = 0.4519798414388985, disc_loss = 0.04364385440715046
Trained batch 517 in epoch 2, gen_loss = 0.4521602888134916, disc_loss = 0.04364938423411496
Trained batch 518 in epoch 2, gen_loss = 0.4521105535227899, disc_loss = 0.043579700422654494
Trained batch 519 in epoch 2, gen_loss = 0.45207234878952685, disc_loss = 0.043752998428849076
Trained batch 520 in epoch 2, gen_loss = 0.4522253275489624, disc_loss = 0.04385966658878235
Trained batch 521 in epoch 2, gen_loss = 0.4523018479233044, disc_loss = 0.04384312205644631
Trained batch 522 in epoch 2, gen_loss = 0.4521922128948153, disc_loss = 0.04400646972183288
Trained batch 523 in epoch 2, gen_loss = 0.45216923366293654, disc_loss = 0.043949549569826545
Trained batch 524 in epoch 2, gen_loss = 0.4523572853065672, disc_loss = 0.043937955527078534
Trained batch 525 in epoch 2, gen_loss = 0.4523215207196914, disc_loss = 0.04387381105566886
Trained batch 526 in epoch 2, gen_loss = 0.45223605022032304, disc_loss = 0.043867559895004224
Trained batch 527 in epoch 2, gen_loss = 0.4520919944978122, disc_loss = 0.043963936383299755
Trained batch 528 in epoch 2, gen_loss = 0.4520124049403041, disc_loss = 0.0440593402135575
Trained batch 529 in epoch 2, gen_loss = 0.45202778448473735, disc_loss = 0.04401551332887051
Trained batch 530 in epoch 2, gen_loss = 0.4520445403742925, disc_loss = 0.04395311388753621
Trained batch 531 in epoch 2, gen_loss = 0.4520800202188635, disc_loss = 0.04392491932083061
Trained batch 532 in epoch 2, gen_loss = 0.4523109424628639, disc_loss = 0.04395180888732591
Trained batch 533 in epoch 2, gen_loss = 0.4522242090117172, disc_loss = 0.043887590019778815
Trained batch 534 in epoch 2, gen_loss = 0.45210845598550603, disc_loss = 0.043917636127672466
Trained batch 535 in epoch 2, gen_loss = 0.4521293163633169, disc_loss = 0.04394046158821725
Trained batch 536 in epoch 2, gen_loss = 0.45195656010336493, disc_loss = 0.04393203986645633
Trained batch 537 in epoch 2, gen_loss = 0.45206514660088987, disc_loss = 0.04388569337644763
Trained batch 538 in epoch 2, gen_loss = 0.4519175304331452, disc_loss = 0.043920098670891354
Trained batch 539 in epoch 2, gen_loss = 0.45170975691742365, disc_loss = 0.04427025129121763
Trained batch 540 in epoch 2, gen_loss = 0.4517975176879086, disc_loss = 0.04429386671143627
Trained batch 541 in epoch 2, gen_loss = 0.45177187014549863, disc_loss = 0.0442767054034995
Trained batch 542 in epoch 2, gen_loss = 0.45160086269097655, disc_loss = 0.04428738516173969
Trained batch 543 in epoch 2, gen_loss = 0.4515095278072883, disc_loss = 0.04422660548281034
Trained batch 544 in epoch 2, gen_loss = 0.45152674907938056, disc_loss = 0.04417005457462521
Trained batch 545 in epoch 2, gen_loss = 0.45162608864761533, disc_loss = 0.044109868950077465
Trained batch 546 in epoch 2, gen_loss = 0.4515480964122786, disc_loss = 0.04406360295725479
Trained batch 547 in epoch 2, gen_loss = 0.45161744337664905, disc_loss = 0.04404746661520135
Trained batch 548 in epoch 2, gen_loss = 0.45153942085354704, disc_loss = 0.043998401710434475
Trained batch 549 in epoch 2, gen_loss = 0.4516195101629604, disc_loss = 0.044020283720032735
Trained batch 550 in epoch 2, gen_loss = 0.4517716213168336, disc_loss = 0.04398720296684605
Trained batch 551 in epoch 2, gen_loss = 0.4518306875682395, disc_loss = 0.04394902945901065
Trained batch 552 in epoch 2, gen_loss = 0.4518673337497504, disc_loss = 0.043885417897287914
Trained batch 553 in epoch 2, gen_loss = 0.4518450924635794, disc_loss = 0.04382592000047061
Trained batch 554 in epoch 2, gen_loss = 0.45172351759833257, disc_loss = 0.04376129306483645
Trained batch 555 in epoch 2, gen_loss = 0.4515820848856041, disc_loss = 0.04375792567939799
Trained batch 556 in epoch 2, gen_loss = 0.45162930030583054, disc_loss = 0.043715337095732
Trained batch 557 in epoch 2, gen_loss = 0.4515831284625556, disc_loss = 0.04364738672784793
Trained batch 558 in epoch 2, gen_loss = 0.4515437240144221, disc_loss = 0.04357718503892368
Trained batch 559 in epoch 2, gen_loss = 0.45145340418176994, disc_loss = 0.043574865543216997
Trained batch 560 in epoch 2, gen_loss = 0.45135911560738573, disc_loss = 0.04360873865232589
Trained batch 561 in epoch 2, gen_loss = 0.4513631329417653, disc_loss = 0.04355812384962399
Trained batch 562 in epoch 2, gen_loss = 0.4513168364075107, disc_loss = 0.04349945975570124
Trained batch 563 in epoch 2, gen_loss = 0.45134207225860434, disc_loss = 0.043453074172667576
Trained batch 564 in epoch 2, gen_loss = 0.45144751166875385, disc_loss = 0.0433898511911388
Trained batch 565 in epoch 2, gen_loss = 0.4514986695754654, disc_loss = 0.04336045708428318
Trained batch 566 in epoch 2, gen_loss = 0.45158994492189386, disc_loss = 0.04329580580815673
Trained batch 567 in epoch 2, gen_loss = 0.4514797189286057, disc_loss = 0.04324590452884416
Trained batch 568 in epoch 2, gen_loss = 0.45153250577998705, disc_loss = 0.043205912145565024
Trained batch 569 in epoch 2, gen_loss = 0.4516251399328834, disc_loss = 0.04326922415526943
Trained batch 570 in epoch 2, gen_loss = 0.4516706732860171, disc_loss = 0.04321899912328232
Trained batch 571 in epoch 2, gen_loss = 0.4515525264131439, disc_loss = 0.04315653330584584
Trained batch 572 in epoch 2, gen_loss = 0.45157028555245926, disc_loss = 0.04310212360961561
Trained batch 573 in epoch 2, gen_loss = 0.45153369253520764, disc_loss = 0.04303506381228852
Trained batch 574 in epoch 2, gen_loss = 0.45165897607803346, disc_loss = 0.042988333916696514
Trained batch 575 in epoch 2, gen_loss = 0.4516355834590892, disc_loss = 0.04293195390507915
Trained batch 576 in epoch 2, gen_loss = 0.45163140821704834, disc_loss = 0.04288186707600073
Trained batch 577 in epoch 2, gen_loss = 0.4516447739205146, disc_loss = 0.04283235368969815
Trained batch 578 in epoch 2, gen_loss = 0.45162530318031247, disc_loss = 0.04276962677621651
Trained batch 579 in epoch 2, gen_loss = 0.4516476408160966, disc_loss = 0.042716804120272144
Trained batch 580 in epoch 2, gen_loss = 0.451571513063526, disc_loss = 0.042664376372013
Trained batch 581 in epoch 2, gen_loss = 0.45152635703381805, disc_loss = 0.04260722102350924
Trained batch 582 in epoch 2, gen_loss = 0.4514480630897535, disc_loss = 0.04254460829113631
Trained batch 583 in epoch 2, gen_loss = 0.4513218545750396, disc_loss = 0.04249518128249105
Trained batch 584 in epoch 2, gen_loss = 0.4513942420992077, disc_loss = 0.042446805271678247
Trained batch 585 in epoch 2, gen_loss = 0.45142556442132176, disc_loss = 0.042402355711582934
Trained batch 586 in epoch 2, gen_loss = 0.45145773217462803, disc_loss = 0.042360540059771155
Trained batch 587 in epoch 2, gen_loss = 0.45143520421519573, disc_loss = 0.04230834958127693
Trained batch 588 in epoch 2, gen_loss = 0.45128725608257364, disc_loss = 0.04229210017419757
Trained batch 589 in epoch 2, gen_loss = 0.45130543410778046, disc_loss = 0.04230739836170638
Trained batch 590 in epoch 2, gen_loss = 0.45133563982048613, disc_loss = 0.04225392515066689
Trained batch 591 in epoch 2, gen_loss = 0.4513280659511283, disc_loss = 0.04224314372215697
Trained batch 592 in epoch 2, gen_loss = 0.4513000468982613, disc_loss = 0.042190028867302665
Trained batch 593 in epoch 2, gen_loss = 0.45117157466885216, disc_loss = 0.04216786058578854
Trained batch 594 in epoch 2, gen_loss = 0.4511292079416644, disc_loss = 0.04212955641599388
Trained batch 595 in epoch 2, gen_loss = 0.4512437300494053, disc_loss = 0.042138134217633544
Testing Epoch 2
Training Epoch 3
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-09-01 13:17:32,793
------------------------------------------------------------
Trained batch 0 in epoch 3, gen_loss = 0.44254937767982483, disc_loss = 0.04915882274508476
Trained batch 1 in epoch 3, gen_loss = 0.41619983315467834, disc_loss = 0.030394450295716524
Trained batch 2 in epoch 3, gen_loss = 0.44352151950200397, disc_loss = 0.02430850639939308
Trained batch 3 in epoch 3, gen_loss = 0.4426666498184204, disc_loss = 0.022196989506483078
Trained batch 4 in epoch 3, gen_loss = 0.4357802987098694, disc_loss = 0.02068699970841408
Trained batch 5 in epoch 3, gen_loss = 0.4357929180065791, disc_loss = 0.02162806348254283
Trained batch 6 in epoch 3, gen_loss = 0.4393784872123173, disc_loss = 0.019814879234348024
Trained batch 7 in epoch 3, gen_loss = 0.4376891143620014, disc_loss = 0.018584266304969788
Trained batch 8 in epoch 3, gen_loss = 0.4346476627720727, disc_loss = 0.017786979571812682
Trained batch 9 in epoch 3, gen_loss = 0.4409082382917404, disc_loss = 0.01761492444202304
Trained batch 10 in epoch 3, gen_loss = 0.4449786841869354, disc_loss = 0.018110209652646023
Trained batch 11 in epoch 3, gen_loss = 0.4420912340283394, disc_loss = 0.019279842032119632
Trained batch 12 in epoch 3, gen_loss = 0.44191815990668076, disc_loss = 0.019059888946895417
Trained batch 13 in epoch 3, gen_loss = 0.44263945307050434, disc_loss = 0.01814260789459305
Trained batch 14 in epoch 3, gen_loss = 0.44942713578542076, disc_loss = 0.018497307132929564
Trained batch 15 in epoch 3, gen_loss = 0.4487566575407982, disc_loss = 0.017781712231226265
Trained batch 16 in epoch 3, gen_loss = 0.4497931669740116, disc_loss = 0.017139111809870777
Trained batch 17 in epoch 3, gen_loss = 0.44622596767213607, disc_loss = 0.016661945006085768
Trained batch 18 in epoch 3, gen_loss = 0.44598624737639175, disc_loss = 0.01892346408414213
Trained batch 19 in epoch 3, gen_loss = 0.44572354704141615, disc_loss = 0.02149718990549445
Trained batch 20 in epoch 3, gen_loss = 0.4436654618808201, disc_loss = 0.020895065562356086
Trained batch 21 in epoch 3, gen_loss = 0.44391562180085614, disc_loss = 0.020607278343628754
Trained batch 22 in epoch 3, gen_loss = 0.44440248219863226, disc_loss = 0.02016303299561791
Trained batch 23 in epoch 3, gen_loss = 0.44403650363286334, disc_loss = 0.02171473189567526
Trained batch 24 in epoch 3, gen_loss = 0.4426953935623169, disc_loss = 0.024048544615507126
Trained batch 25 in epoch 3, gen_loss = 0.44332833702747637, disc_loss = 0.024310672655701637
Trained batch 26 in epoch 3, gen_loss = 0.44205489313160934, disc_loss = 0.02375841961690673
Trained batch 27 in epoch 3, gen_loss = 0.438605004123279, disc_loss = 0.024153613818011115
Trained batch 28 in epoch 3, gen_loss = 0.4408824834330329, disc_loss = 0.024656700484197717
Trained batch 29 in epoch 3, gen_loss = 0.4403297364711761, disc_loss = 0.02432904243469238
Trained batch 30 in epoch 3, gen_loss = 0.43997572987310346, disc_loss = 0.02378325871822815
Trained batch 31 in epoch 3, gen_loss = 0.4418825274333358, disc_loss = 0.023272162361536175
Trained batch 32 in epoch 3, gen_loss = 0.43894455107775604, disc_loss = 0.02353224152642669
Trained batch 33 in epoch 3, gen_loss = 0.43932655979605284, disc_loss = 0.024026856757700443
Trained batch 34 in epoch 3, gen_loss = 0.441981976372855, disc_loss = 0.023792641130941254
Trained batch 35 in epoch 3, gen_loss = 0.4419466339879566, disc_loss = 0.02434132056724694
Trained batch 36 in epoch 3, gen_loss = 0.44295417859747604, disc_loss = 0.0240227505061272
Trained batch 37 in epoch 3, gen_loss = 0.4449744185334758, disc_loss = 0.023651485723492346
Trained batch 38 in epoch 3, gen_loss = 0.44614599606929684, disc_loss = 0.023479288157362204
Trained batch 39 in epoch 3, gen_loss = 0.4459722816944122, disc_loss = 0.023020785534754395
Trained batch 40 in epoch 3, gen_loss = 0.4459371886602262, disc_loss = 0.022868628590935615
Trained batch 41 in epoch 3, gen_loss = 0.4463826950107302, disc_loss = 0.022816230676003864
Trained batch 42 in epoch 3, gen_loss = 0.4456801040228023, disc_loss = 0.022520334524817245
Trained batch 43 in epoch 3, gen_loss = 0.4456420215693387, disc_loss = 0.022507626901973377
Trained batch 44 in epoch 3, gen_loss = 0.44532630377345617, disc_loss = 0.022369505796167585
Trained batch 45 in epoch 3, gen_loss = 0.4448315455861714, disc_loss = 0.022148013438867485
Trained batch 46 in epoch 3, gen_loss = 0.44472143751509646, disc_loss = 0.022145910941539927
Trained batch 47 in epoch 3, gen_loss = 0.4457542213300864, disc_loss = 0.02186660491861403
Trained batch 48 in epoch 3, gen_loss = 0.44414655712186074, disc_loss = 0.021572631612724186
Trained batch 49 in epoch 3, gen_loss = 0.44447161912918093, disc_loss = 0.021279643615707756
Trained batch 50 in epoch 3, gen_loss = 0.4435168440435447, disc_loss = 0.02103821413737594
Trained batch 51 in epoch 3, gen_loss = 0.4434966783110912, disc_loss = 0.020885111773028396
Trained batch 52 in epoch 3, gen_loss = 0.44369820041476554, disc_loss = 0.020788788769113005
Trained batch 53 in epoch 3, gen_loss = 0.4435873594548967, disc_loss = 0.020546536797795584
Trained batch 54 in epoch 3, gen_loss = 0.44321980801495636, disc_loss = 0.020862835146148097
Trained batch 55 in epoch 3, gen_loss = 0.44369895064405035, disc_loss = 0.020715978021533892
Trained batch 56 in epoch 3, gen_loss = 0.4444126627947155, disc_loss = 0.0214395711541568
Trained batch 57 in epoch 3, gen_loss = 0.44325222074985504, disc_loss = 0.02220259981775849
Trained batch 58 in epoch 3, gen_loss = 0.4430917693396746, disc_loss = 0.021921096267020802
Trained batch 59 in epoch 3, gen_loss = 0.4427993083993594, disc_loss = 0.021667905144083004
Trained batch 60 in epoch 3, gen_loss = 0.44360518308936575, disc_loss = 0.021524841294120082
Trained batch 61 in epoch 3, gen_loss = 0.44349978431578607, disc_loss = 0.02157282125535271
Trained batch 62 in epoch 3, gen_loss = 0.44345592459042865, disc_loss = 0.023402913865293303
Trained batch 63 in epoch 3, gen_loss = 0.4436007044278085, disc_loss = 0.02798730431095464
Trained batch 64 in epoch 3, gen_loss = 0.442036725466068, disc_loss = 0.028257655115941395
Trained batch 65 in epoch 3, gen_loss = 0.44076954370195215, disc_loss = 0.028994261477650565
Trained batch 66 in epoch 3, gen_loss = 0.4402389117141268, disc_loss = 0.028818340603706995
Trained batch 67 in epoch 3, gen_loss = 0.4402776474461836, disc_loss = 0.029492174377938843
Trained batch 68 in epoch 3, gen_loss = 0.439159473647242, disc_loss = 0.032809088566758925
Trained batch 69 in epoch 3, gen_loss = 0.4395582343850817, disc_loss = 0.03289915609971753
Trained batch 70 in epoch 3, gen_loss = 0.4394382435671041, disc_loss = 0.03293190617770166
Trained batch 71 in epoch 3, gen_loss = 0.4391785276432832, disc_loss = 0.033042114687203944
Trained batch 72 in epoch 3, gen_loss = 0.43930212153147347, disc_loss = 0.03296516176746928
Trained batch 73 in epoch 3, gen_loss = 0.4390969240182155, disc_loss = 0.033008339179277014
Trained batch 74 in epoch 3, gen_loss = 0.43816161036491397, disc_loss = 0.033267227057367565
Trained batch 75 in epoch 3, gen_loss = 0.4384897174803834, disc_loss = 0.03332615549994731
Trained batch 76 in epoch 3, gen_loss = 0.4386132591730588, disc_loss = 0.033128469499045764
Trained batch 77 in epoch 3, gen_loss = 0.43739799734873647, disc_loss = 0.033410315037681125
Trained batch 78 in epoch 3, gen_loss = 0.43753699373595323, disc_loss = 0.034733321936211634
Trained batch 79 in epoch 3, gen_loss = 0.43768739365041254, disc_loss = 0.034591212210943925
Trained batch 80 in epoch 3, gen_loss = 0.43725787268744576, disc_loss = 0.03583498767657596
Trained batch 81 in epoch 3, gen_loss = 0.4376554943439437, disc_loss = 0.03843033485818745
Trained batch 82 in epoch 3, gen_loss = 0.43678802503160685, disc_loss = 0.03843517327142588
Trained batch 83 in epoch 3, gen_loss = 0.43734069097609746, disc_loss = 0.038354869172464875
Trained batch 84 in epoch 3, gen_loss = 0.43664092596839454, disc_loss = 0.03805484270457836
Trained batch 85 in epoch 3, gen_loss = 0.4371264317007952, disc_loss = 0.0382944535908051
Trained batch 86 in epoch 3, gen_loss = 0.43688236981972883, disc_loss = 0.037960288098788465
Trained batch 87 in epoch 3, gen_loss = 0.43607890605926514, disc_loss = 0.03869172830706124
Trained batch 88 in epoch 3, gen_loss = 0.43659489844622235, disc_loss = 0.03866697213183461
Trained batch 89 in epoch 3, gen_loss = 0.43697453174326156, disc_loss = 0.03856523115084403
Trained batch 90 in epoch 3, gen_loss = 0.4367257340268774, disc_loss = 0.038370811549312135
Trained batch 91 in epoch 3, gen_loss = 0.4367590313372405, disc_loss = 0.038363686352765755
Trained batch 92 in epoch 3, gen_loss = 0.43642890229020065, disc_loss = 0.03809650532240348
Trained batch 93 in epoch 3, gen_loss = 0.4358903940053696, disc_loss = 0.037922120529246775
Trained batch 94 in epoch 3, gen_loss = 0.4361382173864465, disc_loss = 0.03777720637521462
Trained batch 95 in epoch 3, gen_loss = 0.4362334456915657, disc_loss = 0.037499881102121435
Trained batch 96 in epoch 3, gen_loss = 0.4360901605837124, disc_loss = 0.03738088449271223
Trained batch 97 in epoch 3, gen_loss = 0.4364162607460606, disc_loss = 0.03838682118138032
Trained batch 98 in epoch 3, gen_loss = 0.43538854489422807, disc_loss = 0.03913909178509405
Trained batch 99 in epoch 3, gen_loss = 0.436087346971035, disc_loss = 0.03890252739656717
Trained batch 100 in epoch 3, gen_loss = 0.43662593535857624, disc_loss = 0.0388443904910421
Trained batch 101 in epoch 3, gen_loss = 0.4362555821152294, disc_loss = 0.03852914202520076
Trained batch 102 in epoch 3, gen_loss = 0.43638824172390317, disc_loss = 0.03846914022799256
Trained batch 103 in epoch 3, gen_loss = 0.43586605013563084, disc_loss = 0.03825635165692522
Trained batch 104 in epoch 3, gen_loss = 0.4364431605452583, disc_loss = 0.03799196458643391
Trained batch 105 in epoch 3, gen_loss = 0.43708703174905955, disc_loss = 0.03768524438810517
Trained batch 106 in epoch 3, gen_loss = 0.43694836653281593, disc_loss = 0.03744131254432636
Trained batch 107 in epoch 3, gen_loss = 0.43675603441618105, disc_loss = 0.03716980446026557
Trained batch 108 in epoch 3, gen_loss = 0.4369279572723109, disc_loss = 0.03689072800612231
Trained batch 109 in epoch 3, gen_loss = 0.4374120750210502, disc_loss = 0.03661638166840103
Trained batch 110 in epoch 3, gen_loss = 0.43751303838179995, disc_loss = 0.03649647978998653
Trained batch 111 in epoch 3, gen_loss = 0.4381746511374201, disc_loss = 0.036366905921438174
Trained batch 112 in epoch 3, gen_loss = 0.43802089685887363, disc_loss = 0.036082253696611236
Trained batch 113 in epoch 3, gen_loss = 0.4378251145806229, disc_loss = 0.035802196502979645
Trained batch 114 in epoch 3, gen_loss = 0.4377711721088575, disc_loss = 0.03557771791339569
Trained batch 115 in epoch 3, gen_loss = 0.43808520790831795, disc_loss = 0.035478176938466215
Trained batch 116 in epoch 3, gen_loss = 0.4382157246781211, disc_loss = 0.03531484000591768
Trained batch 117 in epoch 3, gen_loss = 0.4374118146754928, disc_loss = 0.03564692655246768
Trained batch 118 in epoch 3, gen_loss = 0.4369753809536205, disc_loss = 0.03564889300536333
Trained batch 119 in epoch 3, gen_loss = 0.43719203571478527, disc_loss = 0.03551466695110624
Trained batch 120 in epoch 3, gen_loss = 0.437244809117199, disc_loss = 0.0353575969415078
Trained batch 121 in epoch 3, gen_loss = 0.4370703858430268, disc_loss = 0.03513173584551474
Trained batch 122 in epoch 3, gen_loss = 0.43764104688070654, disc_loss = 0.03497212176869919
Trained batch 123 in epoch 3, gen_loss = 0.4378550795297469, disc_loss = 0.03490137509746297
Trained batch 124 in epoch 3, gen_loss = 0.4385455710887909, disc_loss = 0.03493510520085692
Trained batch 125 in epoch 3, gen_loss = 0.43924403971149806, disc_loss = 0.03470544852242465
Trained batch 126 in epoch 3, gen_loss = 0.4396985325756974, disc_loss = 0.03453945448827438
Trained batch 127 in epoch 3, gen_loss = 0.4398219052236527, disc_loss = 0.03483341318133171
Trained batch 128 in epoch 3, gen_loss = 0.4393640350001727, disc_loss = 0.03560635203120205
Trained batch 129 in epoch 3, gen_loss = 0.4394859009064161, disc_loss = 0.035590802344421926
Trained batch 130 in epoch 3, gen_loss = 0.43937530567627825, disc_loss = 0.03548440599870932
Trained batch 131 in epoch 3, gen_loss = 0.43906868610418204, disc_loss = 0.0353879812138268
Trained batch 132 in epoch 3, gen_loss = 0.43950988161832766, disc_loss = 0.035337397671143585
Trained batch 133 in epoch 3, gen_loss = 0.43924512391659754, disc_loss = 0.03513953249220417
Trained batch 134 in epoch 3, gen_loss = 0.4395120720068614, disc_loss = 0.03498869365495112
Trained batch 135 in epoch 3, gen_loss = 0.4390202754122369, disc_loss = 0.034840988080866414
Trained batch 136 in epoch 3, gen_loss = 0.43908606698043157, disc_loss = 0.03467239747775623
Trained batch 137 in epoch 3, gen_loss = 0.4394497746142788, disc_loss = 0.03458339252266223
Trained batch 138 in epoch 3, gen_loss = 0.43946235771659464, disc_loss = 0.03464969559472135
Trained batch 139 in epoch 3, gen_loss = 0.4395406001380512, disc_loss = 0.03445575876560594
Trained batch 140 in epoch 3, gen_loss = 0.439566618584572, disc_loss = 0.03465614447383382
Trained batch 141 in epoch 3, gen_loss = 0.4391687642520582, disc_loss = 0.035886682629008106
Trained batch 142 in epoch 3, gen_loss = 0.4393082179806449, disc_loss = 0.03737777039747347
Trained batch 143 in epoch 3, gen_loss = 0.4393285701258315, disc_loss = 0.03720585799439707
Trained batch 144 in epoch 3, gen_loss = 0.43893383063119035, disc_loss = 0.03725132535629232
Trained batch 145 in epoch 3, gen_loss = 0.43852560222148895, disc_loss = 0.03706544394643135
Trained batch 146 in epoch 3, gen_loss = 0.4385223727242476, disc_loss = 0.03692690793070055
Trained batch 147 in epoch 3, gen_loss = 0.4384736501284548, disc_loss = 0.03673349179931589
Trained batch 148 in epoch 3, gen_loss = 0.43825598231097995, disc_loss = 0.03659630153053159
Trained batch 149 in epoch 3, gen_loss = 0.43791454792022705, disc_loss = 0.03669199867794911
Trained batch 150 in epoch 3, gen_loss = 0.438124669308694, disc_loss = 0.03684200799178998
Trained batch 151 in epoch 3, gen_loss = 0.4381010973531949, disc_loss = 0.037026690944146956
Trained batch 152 in epoch 3, gen_loss = 0.43856191031293934, disc_loss = 0.03701992302499955
Trained batch 153 in epoch 3, gen_loss = 0.4389086222493803, disc_loss = 0.037008321940802134
Trained batch 154 in epoch 3, gen_loss = 0.4388661524941844, disc_loss = 0.03693931255369417
Trained batch 155 in epoch 3, gen_loss = 0.43882377464801836, disc_loss = 0.03687659074337436
Trained batch 156 in epoch 3, gen_loss = 0.4392388388989078, disc_loss = 0.036855732523806535
Trained batch 157 in epoch 3, gen_loss = 0.4393778507468067, disc_loss = 0.03678928268483923
Trained batch 158 in epoch 3, gen_loss = 0.43918539817978003, disc_loss = 0.036603888297605816
Trained batch 159 in epoch 3, gen_loss = 0.4392939265817404, disc_loss = 0.03660078565590084
Trained batch 160 in epoch 3, gen_loss = 0.43888889484523985, disc_loss = 0.03700876384047988
Trained batch 161 in epoch 3, gen_loss = 0.4394783517460764, disc_loss = 0.03692547411278442
Trained batch 162 in epoch 3, gen_loss = 0.43951808528666114, disc_loss = 0.0368736097074908
Trained batch 163 in epoch 3, gen_loss = 0.4393235286924897, disc_loss = 0.03673556848520004
Trained batch 164 in epoch 3, gen_loss = 0.4389433326143207, disc_loss = 0.03707717554925969
Trained batch 165 in epoch 3, gen_loss = 0.4395835916680026, disc_loss = 0.03728358480652951
Trained batch 166 in epoch 3, gen_loss = 0.43919530350291086, disc_loss = 0.03731783737657134
Trained batch 167 in epoch 3, gen_loss = 0.43937691088233677, disc_loss = 0.037485348543019166
Trained batch 168 in epoch 3, gen_loss = 0.43940004336058036, disc_loss = 0.03767666096672328
Trained batch 169 in epoch 3, gen_loss = 0.4394110016963061, disc_loss = 0.037845526498687616
Trained batch 170 in epoch 3, gen_loss = 0.4395265981816409, disc_loss = 0.03767864139238645
Trained batch 171 in epoch 3, gen_loss = 0.4391952181278273, disc_loss = 0.03776543174848654
Trained batch 172 in epoch 3, gen_loss = 0.439359161550599, disc_loss = 0.03764538339882917
Trained batch 173 in epoch 3, gen_loss = 0.4397540935154619, disc_loss = 0.03752989291973498
Trained batch 174 in epoch 3, gen_loss = 0.4389363588605608, disc_loss = 0.037478677694286616
Trained batch 175 in epoch 3, gen_loss = 0.43956847895275464, disc_loss = 0.03731831920925866
Trained batch 176 in epoch 3, gen_loss = 0.43978421987786803, disc_loss = 0.03718800015621266
Trained batch 177 in epoch 3, gen_loss = 0.44001314596513685, disc_loss = 0.037034133407339624
Trained batch 178 in epoch 3, gen_loss = 0.4401366232826723, disc_loss = 0.03695499534879983
Trained batch 179 in epoch 3, gen_loss = 0.4401546017991172, disc_loss = 0.036800874024629594
Trained batch 180 in epoch 3, gen_loss = 0.44059702144801943, disc_loss = 0.03667056393289928
Trained batch 181 in epoch 3, gen_loss = 0.44047045429329296, disc_loss = 0.0365028515621856
Trained batch 182 in epoch 3, gen_loss = 0.4409806736505748, disc_loss = 0.03635535025307553
Trained batch 183 in epoch 3, gen_loss = 0.44141195406732353, disc_loss = 0.03619690664092322
Trained batch 184 in epoch 3, gen_loss = 0.4413429962622153, disc_loss = 0.03606058819773229
Trained batch 185 in epoch 3, gen_loss = 0.44106894571294064, disc_loss = 0.03590772264406726
Trained batch 186 in epoch 3, gen_loss = 0.4412232140168787, disc_loss = 0.03575678076346051
Trained batch 187 in epoch 3, gen_loss = 0.4414523258171183, disc_loss = 0.035589986369311016
Trained batch 188 in epoch 3, gen_loss = 0.4418025942391189, disc_loss = 0.03542996487437339
Trained batch 189 in epoch 3, gen_loss = 0.44187125155800266, disc_loss = 0.03533860234984834
Trained batch 190 in epoch 3, gen_loss = 0.44160991517036996, disc_loss = 0.035252036777914976
Trained batch 191 in epoch 3, gen_loss = 0.4416832164861262, disc_loss = 0.03509828296955675
Trained batch 192 in epoch 3, gen_loss = 0.4418080972575153, disc_loss = 0.03501155151179726
Trained batch 193 in epoch 3, gen_loss = 0.44145308173808856, disc_loss = 0.03488612179308362
Trained batch 194 in epoch 3, gen_loss = 0.4416128794352214, disc_loss = 0.034754549105389
Trained batch 195 in epoch 3, gen_loss = 0.44163592418237607, disc_loss = 0.034607093560281306
Trained batch 196 in epoch 3, gen_loss = 0.44216419945513535, disc_loss = 0.03449868901306527
Trained batch 197 in epoch 3, gen_loss = 0.4418949537506007, disc_loss = 0.034352772880928834
Trained batch 198 in epoch 3, gen_loss = 0.44190285014147734, disc_loss = 0.03427434052064566
Trained batch 199 in epoch 3, gen_loss = 0.442061772942543, disc_loss = 0.034159672947134824
Trained batch 200 in epoch 3, gen_loss = 0.442058801651001, disc_loss = 0.034024454379889796
Trained batch 201 in epoch 3, gen_loss = 0.44247788397392424, disc_loss = 0.03388410430207922
Trained batch 202 in epoch 3, gen_loss = 0.44224432389724433, disc_loss = 0.03375015961318254
Trained batch 203 in epoch 3, gen_loss = 0.4422707569365408, disc_loss = 0.03360210254893401
Trained batch 204 in epoch 3, gen_loss = 0.44260433010938693, disc_loss = 0.033466610865576604
Trained batch 205 in epoch 3, gen_loss = 0.4430040630322058, disc_loss = 0.033419261305611035
Trained batch 206 in epoch 3, gen_loss = 0.44263876420288273, disc_loss = 0.033345617577748524
Trained batch 207 in epoch 3, gen_loss = 0.4426705642388417, disc_loss = 0.03324229238317527
Trained batch 208 in epoch 3, gen_loss = 0.44249864927889626, disc_loss = 0.03316896619457912
Trained batch 209 in epoch 3, gen_loss = 0.4425184800511315, disc_loss = 0.033149197798532745
Trained batch 210 in epoch 3, gen_loss = 0.4425868123628517, disc_loss = 0.03302959658501237
Trained batch 211 in epoch 3, gen_loss = 0.44256524024706967, disc_loss = 0.03297428686044372
Trained batch 212 in epoch 3, gen_loss = 0.4422154598672625, disc_loss = 0.03294419353290028
Trained batch 213 in epoch 3, gen_loss = 0.44251922483199113, disc_loss = 0.03286367567216925
Trained batch 214 in epoch 3, gen_loss = 0.4425761020460794, disc_loss = 0.03275455549077759
Trained batch 215 in epoch 3, gen_loss = 0.44245333776429846, disc_loss = 0.03269355198157158
Trained batch 216 in epoch 3, gen_loss = 0.44266650753636516, disc_loss = 0.03258071440993057
Trained batch 217 in epoch 3, gen_loss = 0.4427871474432289, disc_loss = 0.03245267893696084
Trained batch 218 in epoch 3, gen_loss = 0.4431460333741419, disc_loss = 0.03237050558763586
Trained batch 219 in epoch 3, gen_loss = 0.44329148422588, disc_loss = 0.032251546979585495
Trained batch 220 in epoch 3, gen_loss = 0.4435532683700458, disc_loss = 0.032136492594461295
Trained batch 221 in epoch 3, gen_loss = 0.4433856327254493, disc_loss = 0.032013998852480574
Trained batch 222 in epoch 3, gen_loss = 0.4432939408605943, disc_loss = 0.031914924721404773
Trained batch 223 in epoch 3, gen_loss = 0.4431735837299909, disc_loss = 0.03190947620376911
Trained batch 224 in epoch 3, gen_loss = 0.44305442611376444, disc_loss = 0.032185156282244456
Trained batch 225 in epoch 3, gen_loss = 0.4433135534018542, disc_loss = 0.032682900015157605
Trained batch 226 in epoch 3, gen_loss = 0.44319998574677016, disc_loss = 0.03276579663268237
Trained batch 227 in epoch 3, gen_loss = 0.44320651993416904, disc_loss = 0.03278183479887319
Trained batch 228 in epoch 3, gen_loss = 0.4431879201570453, disc_loss = 0.03269617174808993
Trained batch 229 in epoch 3, gen_loss = 0.44356095803820567, disc_loss = 0.0328006106702125
Trained batch 230 in epoch 3, gen_loss = 0.4433318545549979, disc_loss = 0.03275803586939809
Trained batch 231 in epoch 3, gen_loss = 0.4433591800003216, disc_loss = 0.03267954722556671
Trained batch 232 in epoch 3, gen_loss = 0.4432462259423579, disc_loss = 0.032608911737823626
Trained batch 233 in epoch 3, gen_loss = 0.4430895305087424, disc_loss = 0.03252356415355785
Trained batch 234 in epoch 3, gen_loss = 0.44310417251384004, disc_loss = 0.03246639499619128
Trained batch 235 in epoch 3, gen_loss = 0.4432698274820538, disc_loss = 0.03246887617298576
Trained batch 236 in epoch 3, gen_loss = 0.44345442114500055, disc_loss = 0.032376818526889894
Trained batch 237 in epoch 3, gen_loss = 0.4433624550324528, disc_loss = 0.03226309893711494
Trained batch 238 in epoch 3, gen_loss = 0.4434200156183921, disc_loss = 0.03217409372575207
Trained batch 239 in epoch 3, gen_loss = 0.4434470201532046, disc_loss = 0.032067091831898625
Trained batch 240 in epoch 3, gen_loss = 0.44299629713984445, disc_loss = 0.032037173694432465
Trained batch 241 in epoch 3, gen_loss = 0.44288113232979104, disc_loss = 0.03196769649805578
Trained batch 242 in epoch 3, gen_loss = 0.44304044182899066, disc_loss = 0.03187049270239601
Trained batch 243 in epoch 3, gen_loss = 0.4428129310979218, disc_loss = 0.03186980545898655
Trained batch 244 in epoch 3, gen_loss = 0.4428086504644277, disc_loss = 0.03179392579239698
Trained batch 245 in epoch 3, gen_loss = 0.4428789332145598, disc_loss = 0.03170637026470821
Trained batch 246 in epoch 3, gen_loss = 0.4431587563835175, disc_loss = 0.03169734121737662
Trained batch 247 in epoch 3, gen_loss = 0.44301577260898006, disc_loss = 0.03162496557530586
Trained batch 248 in epoch 3, gen_loss = 0.4433366834638588, disc_loss = 0.031562966001911996
Trained batch 249 in epoch 3, gen_loss = 0.4434188607931137, disc_loss = 0.03146550782304257
Trained batch 250 in epoch 3, gen_loss = 0.4436246726617395, disc_loss = 0.03140478738791409
Trained batch 251 in epoch 3, gen_loss = 0.44365353669439045, disc_loss = 0.03132121069338321
Trained batch 252 in epoch 3, gen_loss = 0.44362069036178436, disc_loss = 0.031728302944900665
Trained batch 253 in epoch 3, gen_loss = 0.44412659624899464, disc_loss = 0.03275306129325768
Trained batch 254 in epoch 3, gen_loss = 0.44399580943818184, disc_loss = 0.03277255027445362
Trained batch 255 in epoch 3, gen_loss = 0.44385051156859845, disc_loss = 0.03285368480555917
Trained batch 256 in epoch 3, gen_loss = 0.4437357392524467, disc_loss = 0.03306153591573673
Trained batch 257 in epoch 3, gen_loss = 0.44385045200817347, disc_loss = 0.033549531033558615
Trained batch 258 in epoch 3, gen_loss = 0.443702400075883, disc_loss = 0.03357240037981809
Trained batch 259 in epoch 3, gen_loss = 0.4436426308292609, disc_loss = 0.03351162660132664
Trained batch 260 in epoch 3, gen_loss = 0.4434509015859772, disc_loss = 0.033484023787844854
Trained batch 261 in epoch 3, gen_loss = 0.4436184266823849, disc_loss = 0.033412112224356534
Trained batch 262 in epoch 3, gen_loss = 0.44365618528068745, disc_loss = 0.0333216109236936
Trained batch 263 in epoch 3, gen_loss = 0.443640813005693, disc_loss = 0.03322728916519378
Trained batch 264 in epoch 3, gen_loss = 0.44379242321230333, disc_loss = 0.03323531915468849
Trained batch 265 in epoch 3, gen_loss = 0.44369799414075406, disc_loss = 0.03315112617871675
Trained batch 266 in epoch 3, gen_loss = 0.44405104604999673, disc_loss = 0.03317689634632835
Trained batch 267 in epoch 3, gen_loss = 0.4439547704671746, disc_loss = 0.033112188105283775
Trained batch 268 in epoch 3, gen_loss = 0.44376363752056674, disc_loss = 0.033101836114699454
Trained batch 269 in epoch 3, gen_loss = 0.4439400030506982, disc_loss = 0.03321628789848614
Trained batch 270 in epoch 3, gen_loss = 0.4437817385715752, disc_loss = 0.03320145978063097
Trained batch 271 in epoch 3, gen_loss = 0.4437495697947109, disc_loss = 0.03311191647063585
Trained batch 272 in epoch 3, gen_loss = 0.44360263913105696, disc_loss = 0.0330542265718987
Trained batch 273 in epoch 3, gen_loss = 0.4438765598257093, disc_loss = 0.033004874512247304
Trained batch 274 in epoch 3, gen_loss = 0.4440593672882427, disc_loss = 0.032961035728962584
Trained batch 275 in epoch 3, gen_loss = 0.44404752314954565, disc_loss = 0.032880005898271294
Trained batch 276 in epoch 3, gen_loss = 0.4439803268289738, disc_loss = 0.03281481961706243
Trained batch 277 in epoch 3, gen_loss = 0.4439827650785446, disc_loss = 0.03271877460714376
Trained batch 278 in epoch 3, gen_loss = 0.4440338296488622, disc_loss = 0.03281257997807716
Trained batch 279 in epoch 3, gen_loss = 0.4436793739242213, disc_loss = 0.03322668968882811
Trained batch 280 in epoch 3, gen_loss = 0.4438248429434155, disc_loss = 0.03338494188205283
Trained batch 281 in epoch 3, gen_loss = 0.44403047806827733, disc_loss = 0.033298899313098096
Trained batch 282 in epoch 3, gen_loss = 0.44398565005919116, disc_loss = 0.03325075068339942
Trained batch 283 in epoch 3, gen_loss = 0.4440757283862208, disc_loss = 0.03321480681434352
Trained batch 284 in epoch 3, gen_loss = 0.44421785233313577, disc_loss = 0.033329977081238964
Trained batch 285 in epoch 3, gen_loss = 0.4439509415126347, disc_loss = 0.03331970618760956
Trained batch 286 in epoch 3, gen_loss = 0.44376758280946815, disc_loss = 0.033233140493850205
Trained batch 287 in epoch 3, gen_loss = 0.4437060854915116, disc_loss = 0.03321119766446322
Trained batch 288 in epoch 3, gen_loss = 0.44356059491840616, disc_loss = 0.03325370001722656
Trained batch 289 in epoch 3, gen_loss = 0.44371041121154, disc_loss = 0.0332884876499081
Trained batch 290 in epoch 3, gen_loss = 0.44405375333995756, disc_loss = 0.03321116370200163
Trained batch 291 in epoch 3, gen_loss = 0.4439701130741263, disc_loss = 0.033119864942831284
Trained batch 292 in epoch 3, gen_loss = 0.4438045258814971, disc_loss = 0.033063990158527935
Trained batch 293 in epoch 3, gen_loss = 0.44371702050676154, disc_loss = 0.03300856382880664
Trained batch 294 in epoch 3, gen_loss = 0.44368721115387094, disc_loss = 0.03293413032335624
Trained batch 295 in epoch 3, gen_loss = 0.4435849811982464, disc_loss = 0.03287691719801719
Trained batch 296 in epoch 3, gen_loss = 0.44370901113006, disc_loss = 0.032801374732689174
Trained batch 297 in epoch 3, gen_loss = 0.4434319897586067, disc_loss = 0.03279505095885279
Trained batch 298 in epoch 3, gen_loss = 0.44363857421986636, disc_loss = 0.0327727354363691
Trained batch 299 in epoch 3, gen_loss = 0.44366894781589505, disc_loss = 0.03272873879953598
Trained batch 300 in epoch 3, gen_loss = 0.44367560417549157, disc_loss = 0.032672632320867576
Trained batch 301 in epoch 3, gen_loss = 0.4435218142357883, disc_loss = 0.03259527804993019
Trained batch 302 in epoch 3, gen_loss = 0.4435525186384472, disc_loss = 0.032587391219068035
Trained batch 303 in epoch 3, gen_loss = 0.44359389496477025, disc_loss = 0.03259259814283149
Trained batch 304 in epoch 3, gen_loss = 0.44396029085409444, disc_loss = 0.03257097481200319
Trained batch 305 in epoch 3, gen_loss = 0.44395852692766125, disc_loss = 0.032521147593654987
Trained batch 306 in epoch 3, gen_loss = 0.4438323951311143, disc_loss = 0.032444399343924867
Trained batch 307 in epoch 3, gen_loss = 0.44380278130630396, disc_loss = 0.03235330158321477
Trained batch 308 in epoch 3, gen_loss = 0.4437980425203502, disc_loss = 0.032281979019557726
Trained batch 309 in epoch 3, gen_loss = 0.4435647155969374, disc_loss = 0.032192777078448524
Trained batch 310 in epoch 3, gen_loss = 0.44359802893120376, disc_loss = 0.03211338330476494
Trained batch 311 in epoch 3, gen_loss = 0.443687369235051, disc_loss = 0.032035296249280996
Trained batch 312 in epoch 3, gen_loss = 0.4434987779813834, disc_loss = 0.03197234108844718
Trained batch 313 in epoch 3, gen_loss = 0.443615913580937, disc_loss = 0.0318916091646489
Trained batch 314 in epoch 3, gen_loss = 0.4437209416003454, disc_loss = 0.03181332952549888
Trained batch 315 in epoch 3, gen_loss = 0.4435286912359769, disc_loss = 0.03178792958121299
Trained batch 316 in epoch 3, gen_loss = 0.44359913477762264, disc_loss = 0.03176210742746406
Trained batch 317 in epoch 3, gen_loss = 0.44377328886550926, disc_loss = 0.031826464233058946
Trained batch 318 in epoch 3, gen_loss = 0.4436418440274684, disc_loss = 0.0318464930118193
Trained batch 319 in epoch 3, gen_loss = 0.44341486040502787, disc_loss = 0.03179447959628305
Trained batch 320 in epoch 3, gen_loss = 0.44344011988966636, disc_loss = 0.03171140736192349
Trained batch 321 in epoch 3, gen_loss = 0.4434989363140201, disc_loss = 0.03164293655694711
Trained batch 322 in epoch 3, gen_loss = 0.4434284047445646, disc_loss = 0.03157249907530475
Trained batch 323 in epoch 3, gen_loss = 0.4434009108830381, disc_loss = 0.031496554460048815
Trained batch 324 in epoch 3, gen_loss = 0.4433833566078773, disc_loss = 0.03142638159700884
Trained batch 325 in epoch 3, gen_loss = 0.44331477847567363, disc_loss = 0.03134037668108255
Trained batch 326 in epoch 3, gen_loss = 0.4432988036480883, disc_loss = 0.03125759252754328
Trained batch 327 in epoch 3, gen_loss = 0.4434246716157692, disc_loss = 0.031174750585483794
Trained batch 328 in epoch 3, gen_loss = 0.443524373882085, disc_loss = 0.031091098394103373
Trained batch 329 in epoch 3, gen_loss = 0.44363241240833745, disc_loss = 0.031011385221570504
Trained batch 330 in epoch 3, gen_loss = 0.4434806762145005, disc_loss = 0.030958682506167953
Trained batch 331 in epoch 3, gen_loss = 0.4434515462223306, disc_loss = 0.03090074618209535
Trained batch 332 in epoch 3, gen_loss = 0.4434385016873792, disc_loss = 0.030818180532779196
Trained batch 333 in epoch 3, gen_loss = 0.443411762129047, disc_loss = 0.030741419031808968
Trained batch 334 in epoch 3, gen_loss = 0.44364033955246657, disc_loss = 0.030673808478680786
Trained batch 335 in epoch 3, gen_loss = 0.44373547631715027, disc_loss = 0.030595056760440848
Trained batch 336 in epoch 3, gen_loss = 0.4435526829445044, disc_loss = 0.03051931963257978
Trained batch 337 in epoch 3, gen_loss = 0.4436739657581205, disc_loss = 0.03046397821903339
Trained batch 338 in epoch 3, gen_loss = 0.44385754297264907, disc_loss = 0.030386421744983676
Trained batch 339 in epoch 3, gen_loss = 0.44379700580063985, disc_loss = 0.03031958445619025
Trained batch 340 in epoch 3, gen_loss = 0.4437640533069711, disc_loss = 0.030279900948994975
Trained batch 341 in epoch 3, gen_loss = 0.4436888701734487, disc_loss = 0.030233695437962855
Trained batch 342 in epoch 3, gen_loss = 0.4438012543815913, disc_loss = 0.030182607077556302
Trained batch 343 in epoch 3, gen_loss = 0.4438418648097404, disc_loss = 0.030127963332085717
Trained batch 344 in epoch 3, gen_loss = 0.4437658479248268, disc_loss = 0.0300591047886975
Trained batch 345 in epoch 3, gen_loss = 0.44385769274193426, disc_loss = 0.029987549501460455
Trained batch 346 in epoch 3, gen_loss = 0.4439766333151276, disc_loss = 0.02992039428613221
Trained batch 347 in epoch 3, gen_loss = 0.44408155412509526, disc_loss = 0.029847903338384055
Trained batch 348 in epoch 3, gen_loss = 0.444202106285915, disc_loss = 0.029795246012642298
Trained batch 349 in epoch 3, gen_loss = 0.44440315212522236, disc_loss = 0.029725778759457172
Trained batch 350 in epoch 3, gen_loss = 0.44439524955559323, disc_loss = 0.029695634771950353
Trained batch 351 in epoch 3, gen_loss = 0.44446845742111857, disc_loss = 0.0296967091026917
Trained batch 352 in epoch 3, gen_loss = 0.44427179108260373, disc_loss = 0.02964112759309243
Trained batch 353 in epoch 3, gen_loss = 0.44416461068358126, disc_loss = 0.029573420957809494
Trained batch 354 in epoch 3, gen_loss = 0.44435975501235103, disc_loss = 0.029518902981916156
Trained batch 355 in epoch 3, gen_loss = 0.44426211898916224, disc_loss = 0.029453646855329405
Trained batch 356 in epoch 3, gen_loss = 0.44435583802164436, disc_loss = 0.02941607623178439
Trained batch 357 in epoch 3, gen_loss = 0.4443440355735118, disc_loss = 0.02936318981677148
Trained batch 358 in epoch 3, gen_loss = 0.4443706252448738, disc_loss = 0.029304310101574717
Trained batch 359 in epoch 3, gen_loss = 0.44450705779923333, disc_loss = 0.029273815021669078
Trained batch 360 in epoch 3, gen_loss = 0.44437984820878407, disc_loss = 0.029208353798645562
Trained batch 361 in epoch 3, gen_loss = 0.4443821474004187, disc_loss = 0.02916201280792712
Trained batch 362 in epoch 3, gen_loss = 0.44446917514498896, disc_loss = 0.02911218389748152
Trained batch 363 in epoch 3, gen_loss = 0.44474151935223694, disc_loss = 0.02913339245248238
Trained batch 364 in epoch 3, gen_loss = 0.44461478958391165, disc_loss = 0.029075152764403044
Trained batch 365 in epoch 3, gen_loss = 0.4445576138509427, disc_loss = 0.029036154617463835
Trained batch 366 in epoch 3, gen_loss = 0.4446901543426254, disc_loss = 0.028980364838401895
Trained batch 367 in epoch 3, gen_loss = 0.44469617801192013, disc_loss = 0.028972366574832806
Trained batch 368 in epoch 3, gen_loss = 0.4448454002862377, disc_loss = 0.02890786402076382
Trained batch 369 in epoch 3, gen_loss = 0.4448628554473052, disc_loss = 0.028855328631234935
Trained batch 370 in epoch 3, gen_loss = 0.444957270615827, disc_loss = 0.02881099623276518
Trained batch 371 in epoch 3, gen_loss = 0.44472413093492547, disc_loss = 0.02875243184865222
Trained batch 372 in epoch 3, gen_loss = 0.4445383195583047, disc_loss = 0.028711479795777088
Trained batch 373 in epoch 3, gen_loss = 0.44466956087293474, disc_loss = 0.02865324286248455
Trained batch 374 in epoch 3, gen_loss = 0.44472501301765444, disc_loss = 0.028587998929743966
Trained batch 375 in epoch 3, gen_loss = 0.44474852655796293, disc_loss = 0.028529186746070873
Trained batch 376 in epoch 3, gen_loss = 0.4446416901182433, disc_loss = 0.028483181715688474
Trained batch 377 in epoch 3, gen_loss = 0.44455525728445205, disc_loss = 0.028549699160201406
Trained batch 378 in epoch 3, gen_loss = 0.4446769825386812, disc_loss = 0.0286478357749566
Trained batch 379 in epoch 3, gen_loss = 0.4447669190795798, disc_loss = 0.02861786594332539
Trained batch 380 in epoch 3, gen_loss = 0.44473585517700576, disc_loss = 0.028620162512495956
Trained batch 381 in epoch 3, gen_loss = 0.4446685308717308, disc_loss = 0.02868187059684905
Trained batch 382 in epoch 3, gen_loss = 0.4446787888636477, disc_loss = 0.0287666057094241
Trained batch 383 in epoch 3, gen_loss = 0.4448562450706959, disc_loss = 0.029079829117714933
Trained batch 384 in epoch 3, gen_loss = 0.444527198200102, disc_loss = 0.029302415317650158
Trained batch 385 in epoch 3, gen_loss = 0.444641144473318, disc_loss = 0.029275134522491978
Trained batch 386 in epoch 3, gen_loss = 0.4447553344937258, disc_loss = 0.029326751826388775
Trained batch 387 in epoch 3, gen_loss = 0.44469432978285955, disc_loss = 0.029302471569984116
Trained batch 388 in epoch 3, gen_loss = 0.44459181119972757, disc_loss = 0.02929731552575291
Trained batch 389 in epoch 3, gen_loss = 0.4445182521373798, disc_loss = 0.029249217173156258
Trained batch 390 in epoch 3, gen_loss = 0.44442473523452153, disc_loss = 0.029247341713870462
Trained batch 391 in epoch 3, gen_loss = 0.4445125599752884, disc_loss = 0.02919055908806717
Trained batch 392 in epoch 3, gen_loss = 0.4445382128386704, disc_loss = 0.029163409503764514
Trained batch 393 in epoch 3, gen_loss = 0.4445317314209672, disc_loss = 0.029149028397552897
Trained batch 394 in epoch 3, gen_loss = 0.4447083496594731, disc_loss = 0.029096743519288263
Trained batch 395 in epoch 3, gen_loss = 0.4447949214866667, disc_loss = 0.02904845412992261
Trained batch 396 in epoch 3, gen_loss = 0.44472380586775484, disc_loss = 0.028996865221085754
Trained batch 397 in epoch 3, gen_loss = 0.44474698992530304, disc_loss = 0.028995380737472456
Trained batch 398 in epoch 3, gen_loss = 0.4447394967975473, disc_loss = 0.028984679455955262
Trained batch 399 in epoch 3, gen_loss = 0.44464813970029354, disc_loss = 0.028928908204543403
Trained batch 400 in epoch 3, gen_loss = 0.44469289024571823, disc_loss = 0.029086741576426454
Trained batch 401 in epoch 3, gen_loss = 0.44455893271004976, disc_loss = 0.029709398451687498
Trained batch 402 in epoch 3, gen_loss = 0.44452936988018876, disc_loss = 0.029791635520659183
Trained batch 403 in epoch 3, gen_loss = 0.44471663273502104, disc_loss = 0.03009357410517641
Trained batch 404 in epoch 3, gen_loss = 0.44450023888069906, disc_loss = 0.030487662113996016
Trained batch 405 in epoch 3, gen_loss = 0.4443938608093215, disc_loss = 0.030526114381698367
Trained batch 406 in epoch 3, gen_loss = 0.4446693026902342, disc_loss = 0.03061671245840884
Trained batch 407 in epoch 3, gen_loss = 0.4445853285199287, disc_loss = 0.030675659021796368
Trained batch 408 in epoch 3, gen_loss = 0.444673357426683, disc_loss = 0.030716768369729877
Trained batch 409 in epoch 3, gen_loss = 0.44496820372779194, disc_loss = 0.030874352513176457
Trained batch 410 in epoch 3, gen_loss = 0.4449606470382997, disc_loss = 0.030825155813795337
Trained batch 411 in epoch 3, gen_loss = 0.4448720620384494, disc_loss = 0.030835004461798092
Trained batch 412 in epoch 3, gen_loss = 0.4449591745620201, disc_loss = 0.030793969600053265
Trained batch 413 in epoch 3, gen_loss = 0.44505680197678904, disc_loss = 0.0307519101590629
Trained batch 414 in epoch 3, gen_loss = 0.44517574037414, disc_loss = 0.030700510053008976
Trained batch 415 in epoch 3, gen_loss = 0.4452654386225801, disc_loss = 0.03066278679706067
Trained batch 416 in epoch 3, gen_loss = 0.445447480292629, disc_loss = 0.03064153855722353
Trained batch 417 in epoch 3, gen_loss = 0.4454210083307832, disc_loss = 0.030603122003443325
Trained batch 418 in epoch 3, gen_loss = 0.4454480581750164, disc_loss = 0.03056482200484127
Trained batch 419 in epoch 3, gen_loss = 0.44561013210387457, disc_loss = 0.030552828832462964
Trained batch 420 in epoch 3, gen_loss = 0.44559704478732765, disc_loss = 0.030528142965883194
Trained batch 421 in epoch 3, gen_loss = 0.4455520904742146, disc_loss = 0.030482182302953614
Trained batch 422 in epoch 3, gen_loss = 0.44575633746230575, disc_loss = 0.03042600519600683
Trained batch 423 in epoch 3, gen_loss = 0.44602189859691654, disc_loss = 0.030401204360697313
Trained batch 424 in epoch 3, gen_loss = 0.44611483461716595, disc_loss = 0.030408693323569262
Trained batch 425 in epoch 3, gen_loss = 0.4461818580896082, disc_loss = 0.030369240411845837
Trained batch 426 in epoch 3, gen_loss = 0.4463714418422422, disc_loss = 0.030381288638434416
Trained batch 427 in epoch 3, gen_loss = 0.44667136028548265, disc_loss = 0.030511897376620984
Trained batch 428 in epoch 3, gen_loss = 0.44681777403904843, disc_loss = 0.030682105220971513
Trained batch 429 in epoch 3, gen_loss = 0.44690798063610876, disc_loss = 0.030717856027077623
Trained batch 430 in epoch 3, gen_loss = 0.4468639457723657, disc_loss = 0.03068601556301653
Trained batch 431 in epoch 3, gen_loss = 0.44675668211722813, disc_loss = 0.030695637982851756
Trained batch 432 in epoch 3, gen_loss = 0.4467928527959775, disc_loss = 0.03068255929235481
Trained batch 433 in epoch 3, gen_loss = 0.44668077303242576, disc_loss = 0.030652719753159183
Trained batch 434 in epoch 3, gen_loss = 0.44669420177909147, disc_loss = 0.0305985142867584
Trained batch 435 in epoch 3, gen_loss = 0.4467207041628864, disc_loss = 0.030545815508791305
Trained batch 436 in epoch 3, gen_loss = 0.44668284945138803, disc_loss = 0.030490730620080977
Trained batch 437 in epoch 3, gen_loss = 0.4465638273927175, disc_loss = 0.030473588793070723
Trained batch 438 in epoch 3, gen_loss = 0.4467894452579472, disc_loss = 0.030446802791534736
Trained batch 439 in epoch 3, gen_loss = 0.4467582820491357, disc_loss = 0.03042146966697394
Trained batch 440 in epoch 3, gen_loss = 0.4467095055547701, disc_loss = 0.030489569417435396
Trained batch 441 in epoch 3, gen_loss = 0.4465088310284852, disc_loss = 0.03098779714643129
Trained batch 442 in epoch 3, gen_loss = 0.4465754367831598, disc_loss = 0.03125882532361382
Trained batch 443 in epoch 3, gen_loss = 0.44673450029379613, disc_loss = 0.03123052704917804
Trained batch 444 in epoch 3, gen_loss = 0.4465235424845406, disc_loss = 0.031239073143309256
Trained batch 445 in epoch 3, gen_loss = 0.44662499314199117, disc_loss = 0.031199124430289552
Trained batch 446 in epoch 3, gen_loss = 0.44656745952781146, disc_loss = 0.031237603335535068
Trained batch 447 in epoch 3, gen_loss = 0.44661759305745363, disc_loss = 0.03128323574440271
Trained batch 448 in epoch 3, gen_loss = 0.4465738082914416, disc_loss = 0.031243237896505037
Trained batch 449 in epoch 3, gen_loss = 0.44643053147527906, disc_loss = 0.03125410452847265
Trained batch 450 in epoch 3, gen_loss = 0.44643347199898864, disc_loss = 0.03140339584444998
Trained batch 451 in epoch 3, gen_loss = 0.44637849129143015, disc_loss = 0.03202532157992153
Trained batch 452 in epoch 3, gen_loss = 0.4462958336797508, disc_loss = 0.03199345877889552
Trained batch 453 in epoch 3, gen_loss = 0.4463751743412228, disc_loss = 0.03203886819106941
Trained batch 454 in epoch 3, gen_loss = 0.44629586397946536, disc_loss = 0.03221062837260683
Trained batch 455 in epoch 3, gen_loss = 0.44648973094789607, disc_loss = 0.032651465512268864
Trained batch 456 in epoch 3, gen_loss = 0.44639188677268166, disc_loss = 0.0325991345963826
Trained batch 457 in epoch 3, gen_loss = 0.4461363831201495, disc_loss = 0.03320545390173061
Trained batch 458 in epoch 3, gen_loss = 0.4461264005803335, disc_loss = 0.03344440073219244
Trained batch 459 in epoch 3, gen_loss = 0.4460363272091617, disc_loss = 0.03350348573977775
Trained batch 460 in epoch 3, gen_loss = 0.44572576195195546, disc_loss = 0.03356863643293251
Trained batch 461 in epoch 3, gen_loss = 0.4456869185744942, disc_loss = 0.033606460440432195
Trained batch 462 in epoch 3, gen_loss = 0.4457131503210212, disc_loss = 0.03362086071878205
Trained batch 463 in epoch 3, gen_loss = 0.4456515271088173, disc_loss = 0.03366496805091597
Trained batch 464 in epoch 3, gen_loss = 0.44531963832916754, disc_loss = 0.03411287389124834
Trained batch 465 in epoch 3, gen_loss = 0.44532681873683766, disc_loss = 0.03417255758365832
Trained batch 466 in epoch 3, gen_loss = 0.445345387596645, disc_loss = 0.03418433320174109
Trained batch 467 in epoch 3, gen_loss = 0.4453445716928213, disc_loss = 0.0341247612143803
Trained batch 468 in epoch 3, gen_loss = 0.4453463632541933, disc_loss = 0.03408515286484936
Trained batch 469 in epoch 3, gen_loss = 0.4453740317770775, disc_loss = 0.034060312165046465
Trained batch 470 in epoch 3, gen_loss = 0.44540251889552784, disc_loss = 0.034057813963008506
Trained batch 471 in epoch 3, gen_loss = 0.4455651431896929, disc_loss = 0.03408129241710166
Trained batch 472 in epoch 3, gen_loss = 0.44573149752919317, disc_loss = 0.03411043113162524
Trained batch 473 in epoch 3, gen_loss = 0.4456129531191371, disc_loss = 0.034077197167421164
Trained batch 474 in epoch 3, gen_loss = 0.4456672499681774, disc_loss = 0.03405821932724824
Trained batch 475 in epoch 3, gen_loss = 0.44571245630749134, disc_loss = 0.03401210684155138
Trained batch 476 in epoch 3, gen_loss = 0.445828083176283, disc_loss = 0.03426995719548713
Trained batch 477 in epoch 3, gen_loss = 0.4457094545269611, disc_loss = 0.03486811562108118
Trained batch 478 in epoch 3, gen_loss = 0.4458647750489149, disc_loss = 0.034897805434128654
Trained batch 479 in epoch 3, gen_loss = 0.44596001617610453, disc_loss = 0.034858952237118504
Trained batch 480 in epoch 3, gen_loss = 0.4459106493392754, disc_loss = 0.03482864107384798
Trained batch 481 in epoch 3, gen_loss = 0.44584824361247144, disc_loss = 0.03478369940626841
Trained batch 482 in epoch 3, gen_loss = 0.4458971777564497, disc_loss = 0.03473774623656048
Trained batch 483 in epoch 3, gen_loss = 0.44580387859797677, disc_loss = 0.034691677158910104
Trained batch 484 in epoch 3, gen_loss = 0.4458552981160351, disc_loss = 0.03463151480512905
Trained batch 485 in epoch 3, gen_loss = 0.4458638647333585, disc_loss = 0.03459150665736692
Trained batch 486 in epoch 3, gen_loss = 0.4458761099550024, disc_loss = 0.03456147782766553
Trained batch 487 in epoch 3, gen_loss = 0.4459804097404245, disc_loss = 0.03452584071544793
Trained batch 488 in epoch 3, gen_loss = 0.44594242175420123, disc_loss = 0.034501070705678594
Trained batch 489 in epoch 3, gen_loss = 0.4459334919647295, disc_loss = 0.03447300973490869
Trained batch 490 in epoch 3, gen_loss = 0.4457602774052902, disc_loss = 0.03450474613478935
Trained batch 491 in epoch 3, gen_loss = 0.44577389107487064, disc_loss = 0.034585260158135914
Trained batch 492 in epoch 3, gen_loss = 0.44575622828930433, disc_loss = 0.03453176437299056
Trained batch 493 in epoch 3, gen_loss = 0.4457873884844876, disc_loss = 0.034477193078670934
Trained batch 494 in epoch 3, gen_loss = 0.44565663999981353, disc_loss = 0.03442496777079397
Trained batch 495 in epoch 3, gen_loss = 0.4455615163690621, disc_loss = 0.03437381992426385
Trained batch 496 in epoch 3, gen_loss = 0.4456686987963241, disc_loss = 0.034323605373820336
Trained batch 497 in epoch 3, gen_loss = 0.44574478711469107, disc_loss = 0.03427890120644541
Trained batch 498 in epoch 3, gen_loss = 0.4458400065411547, disc_loss = 0.03424289163980327
Trained batch 499 in epoch 3, gen_loss = 0.44589013373851777, disc_loss = 0.03420443884888664
Trained batch 500 in epoch 3, gen_loss = 0.4458505464885049, disc_loss = 0.0341628103757727
Trained batch 501 in epoch 3, gen_loss = 0.4459518141361822, disc_loss = 0.034126589889638126
Trained batch 502 in epoch 3, gen_loss = 0.44595676725711786, disc_loss = 0.03407741635787869
Trained batch 503 in epoch 3, gen_loss = 0.4459559866005466, disc_loss = 0.03403297513178254
Trained batch 504 in epoch 3, gen_loss = 0.4460053542462906, disc_loss = 0.03401792051667108
Trained batch 505 in epoch 3, gen_loss = 0.4460533736015968, disc_loss = 0.03396132186454585
Trained batch 506 in epoch 3, gen_loss = 0.4461689716024982, disc_loss = 0.03392010329877205
Trained batch 507 in epoch 3, gen_loss = 0.4461241519357276, disc_loss = 0.03388127189644752
Trained batch 508 in epoch 3, gen_loss = 0.44620660017656205, disc_loss = 0.03382882521092555
Trained batch 509 in epoch 3, gen_loss = 0.44623365121729236, disc_loss = 0.03378733262721011
Trained batch 510 in epoch 3, gen_loss = 0.44617044604921063, disc_loss = 0.03374377828239009
Trained batch 511 in epoch 3, gen_loss = 0.44600256253033876, disc_loss = 0.03375428450681284
Trained batch 512 in epoch 3, gen_loss = 0.4461272937512537, disc_loss = 0.0337135455708181
Trained batch 513 in epoch 3, gen_loss = 0.44606454571861237, disc_loss = 0.03367351792464649
Trained batch 514 in epoch 3, gen_loss = 0.44600291900264405, disc_loss = 0.033630492860559844
Trained batch 515 in epoch 3, gen_loss = 0.44599662004977236, disc_loss = 0.033592774076549724
Trained batch 516 in epoch 3, gen_loss = 0.4459886948651917, disc_loss = 0.03356030643052949
Trained batch 517 in epoch 3, gen_loss = 0.4459768750032403, disc_loss = 0.03350703451381529
Trained batch 518 in epoch 3, gen_loss = 0.44594129724769005, disc_loss = 0.03345427193287724
Trained batch 519 in epoch 3, gen_loss = 0.44602538800010316, disc_loss = 0.03342357791037872
Trained batch 520 in epoch 3, gen_loss = 0.4461306749401532, disc_loss = 0.033367335438395845
Trained batch 521 in epoch 3, gen_loss = 0.446218141136955, disc_loss = 0.033357445317877175
Trained batch 522 in epoch 3, gen_loss = 0.44620039124561767, disc_loss = 0.033308533936949096
Trained batch 523 in epoch 3, gen_loss = 0.4461642085140898, disc_loss = 0.03344544602286085
Trained batch 524 in epoch 3, gen_loss = 0.44641062702451434, disc_loss = 0.0338723665081142
Trained batch 525 in epoch 3, gen_loss = 0.4461378998516177, disc_loss = 0.0339585586903376
Trained batch 526 in epoch 3, gen_loss = 0.4460705194120389, disc_loss = 0.033924441003069225
Trained batch 527 in epoch 3, gen_loss = 0.44614055357647664, disc_loss = 0.03391165739925451
Trained batch 528 in epoch 3, gen_loss = 0.4460907642692609, disc_loss = 0.03390174727695017
Trained batch 529 in epoch 3, gen_loss = 0.44602626792664796, disc_loss = 0.03400409385728878
Trained batch 530 in epoch 3, gen_loss = 0.4460232523313799, disc_loss = 0.03395063570690062
Trained batch 531 in epoch 3, gen_loss = 0.4459516231278728, disc_loss = 0.03405718976251879
Trained batch 532 in epoch 3, gen_loss = 0.44560802989337056, disc_loss = 0.03439555430695708
Trained batch 533 in epoch 3, gen_loss = 0.4455366697204247, disc_loss = 0.034438005299307406
Trained batch 534 in epoch 3, gen_loss = 0.44562668399276023, disc_loss = 0.03444978774037804
Trained batch 535 in epoch 3, gen_loss = 0.4456627027534727, disc_loss = 0.03442536383726523
Trained batch 536 in epoch 3, gen_loss = 0.44552003893328335, disc_loss = 0.034496482055429614
Trained batch 537 in epoch 3, gen_loss = 0.445627457479562, disc_loss = 0.034451546597114475
Trained batch 538 in epoch 3, gen_loss = 0.4457720877509391, disc_loss = 0.034700933200651034
Trained batch 539 in epoch 3, gen_loss = 0.4457427906217398, disc_loss = 0.03466812617067869
Trained batch 540 in epoch 3, gen_loss = 0.44557732922092164, disc_loss = 0.03481044912884656
Trained batch 541 in epoch 3, gen_loss = 0.4456065607796736, disc_loss = 0.034812753188004544
Trained batch 542 in epoch 3, gen_loss = 0.44576276078628135, disc_loss = 0.034759161681276414
Trained batch 543 in epoch 3, gen_loss = 0.4456675917677143, disc_loss = 0.03478235881458899
Trained batch 544 in epoch 3, gen_loss = 0.4456429472757042, disc_loss = 0.0348242313895853
Trained batch 545 in epoch 3, gen_loss = 0.4455554360325957, disc_loss = 0.03477088409951878
Trained batch 546 in epoch 3, gen_loss = 0.4454124071916235, disc_loss = 0.03472659320628417
Trained batch 547 in epoch 3, gen_loss = 0.4453682215326894, disc_loss = 0.03468596809212268
Trained batch 548 in epoch 3, gen_loss = 0.44532821972079184, disc_loss = 0.0347041352020105
Trained batch 549 in epoch 3, gen_loss = 0.44535809874534604, disc_loss = 0.034659790693443604
Trained batch 550 in epoch 3, gen_loss = 0.4454395391871838, disc_loss = 0.03477351705394956
Trained batch 551 in epoch 3, gen_loss = 0.4453740907104119, disc_loss = 0.0348399696939969
Trained batch 552 in epoch 3, gen_loss = 0.44546198526946373, disc_loss = 0.0348335574309478
Trained batch 553 in epoch 3, gen_loss = 0.44551446382964993, disc_loss = 0.034962593795082764
Trained batch 554 in epoch 3, gen_loss = 0.44550155100521743, disc_loss = 0.03492380823512134
Trained batch 555 in epoch 3, gen_loss = 0.44550382683603024, disc_loss = 0.034903440452365056
Trained batch 556 in epoch 3, gen_loss = 0.44544543778018847, disc_loss = 0.03486062406271335
Trained batch 557 in epoch 3, gen_loss = 0.445415469854536, disc_loss = 0.034810171888617125
Trained batch 558 in epoch 3, gen_loss = 0.4455303636667767, disc_loss = 0.034827756582574386
Trained batch 559 in epoch 3, gen_loss = 0.4455727013626269, disc_loss = 0.03479933578263236
Trained batch 560 in epoch 3, gen_loss = 0.4455896949598071, disc_loss = 0.03474558586688005
Trained batch 561 in epoch 3, gen_loss = 0.44550680271034987, disc_loss = 0.034690756890574784
Trained batch 562 in epoch 3, gen_loss = 0.4454599924345847, disc_loss = 0.03464108699358682
Trained batch 563 in epoch 3, gen_loss = 0.4455114632105151, disc_loss = 0.034587027008417356
Trained batch 564 in epoch 3, gen_loss = 0.44556008039322575, disc_loss = 0.03453859280077823
Trained batch 565 in epoch 3, gen_loss = 0.44555814827499457, disc_loss = 0.03448947868844685
Trained batch 566 in epoch 3, gen_loss = 0.445464175161651, disc_loss = 0.034447662738879496
Trained batch 567 in epoch 3, gen_loss = 0.44542197384674787, disc_loss = 0.03442041607676927
Trained batch 568 in epoch 3, gen_loss = 0.44546416438526765, disc_loss = 0.03441416582801365
Trained batch 569 in epoch 3, gen_loss = 0.4455287654148905, disc_loss = 0.03439633120790843
Trained batch 570 in epoch 3, gen_loss = 0.4454648948279446, disc_loss = 0.03434575624044678
Trained batch 571 in epoch 3, gen_loss = 0.44557240266691556, disc_loss = 0.03431967372958829
Trained batch 572 in epoch 3, gen_loss = 0.44563012561040816, disc_loss = 0.03428674355290674
Trained batch 573 in epoch 3, gen_loss = 0.44567226060383824, disc_loss = 0.034244987121880545
Trained batch 574 in epoch 3, gen_loss = 0.4456766508454862, disc_loss = 0.03420674502323179
Trained batch 575 in epoch 3, gen_loss = 0.4456159425381985, disc_loss = 0.0341587751661589
Trained batch 576 in epoch 3, gen_loss = 0.44578440118083923, disc_loss = 0.03411030260954162
Trained batch 577 in epoch 3, gen_loss = 0.4458313757573032, disc_loss = 0.03406143569102298
Trained batch 578 in epoch 3, gen_loss = 0.4458796202827612, disc_loss = 0.0340092869110354
Trained batch 579 in epoch 3, gen_loss = 0.44582771956920625, disc_loss = 0.03395625645784533
Trained batch 580 in epoch 3, gen_loss = 0.44582816825060756, disc_loss = 0.03391377015717379
Trained batch 581 in epoch 3, gen_loss = 0.44583242890965896, disc_loss = 0.03386393637209171
Trained batch 582 in epoch 3, gen_loss = 0.4457811446889187, disc_loss = 0.03381934093501528
Trained batch 583 in epoch 3, gen_loss = 0.44573805338307604, disc_loss = 0.03377028403696859
Trained batch 584 in epoch 3, gen_loss = 0.4456595145739042, disc_loss = 0.03374907981453097
Trained batch 585 in epoch 3, gen_loss = 0.4457205914901792, disc_loss = 0.03374844208024379
Trained batch 586 in epoch 3, gen_loss = 0.4458051348768263, disc_loss = 0.03371419505536671
Trained batch 587 in epoch 3, gen_loss = 0.44586094742526816, disc_loss = 0.03366790478217548
Trained batch 588 in epoch 3, gen_loss = 0.44573134138345316, disc_loss = 0.03365340874236273
Trained batch 589 in epoch 3, gen_loss = 0.44567923550888644, disc_loss = 0.033637324421887556
Trained batch 590 in epoch 3, gen_loss = 0.44575860198782585, disc_loss = 0.03360220999299358
Trained batch 591 in epoch 3, gen_loss = 0.44573049040863644, disc_loss = 0.03355352092192924
Trained batch 592 in epoch 3, gen_loss = 0.44575074083889515, disc_loss = 0.03351571049633896
Trained batch 593 in epoch 3, gen_loss = 0.4456593384245028, disc_loss = 0.03347295029708169
Trained batch 594 in epoch 3, gen_loss = 0.44576588568567227, disc_loss = 0.033439904557415794
Trained batch 595 in epoch 3, gen_loss = 0.445873157890051, disc_loss = 0.033396601606232285
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.4903795123100281, disc_loss = 0.014496447518467903
Trained batch 1 in epoch 4, gen_loss = 0.4938381612300873, disc_loss = 0.012826172169297934
Trained batch 2 in epoch 4, gen_loss = 0.4820830126603444, disc_loss = 0.01339345145970583
Trained batch 3 in epoch 4, gen_loss = 0.4791158214211464, disc_loss = 0.011106066638603806
Trained batch 4 in epoch 4, gen_loss = 0.4784161865711212, disc_loss = 0.009874055907130242
Trained batch 5 in epoch 4, gen_loss = 0.48034362494945526, disc_loss = 0.0096487522435685
Trained batch 6 in epoch 4, gen_loss = 0.47850559864725384, disc_loss = 0.009273088470633541
Trained batch 7 in epoch 4, gen_loss = 0.4898664690554142, disc_loss = 0.009625260427128524
Trained batch 8 in epoch 4, gen_loss = 0.48472170035044354, disc_loss = 0.0093532956412269
Trained batch 9 in epoch 4, gen_loss = 0.4802945554256439, disc_loss = 0.009358030511066318
Trained batch 10 in epoch 4, gen_loss = 0.47056522423570807, disc_loss = 0.009150653357871553
Trained batch 11 in epoch 4, gen_loss = 0.4719485466678937, disc_loss = 0.009539421220930914
Trained batch 12 in epoch 4, gen_loss = 0.4685291372812711, disc_loss = 0.009125700901047541
Trained batch 13 in epoch 4, gen_loss = 0.4656081050634384, disc_loss = 0.008767390224550451
Trained batch 14 in epoch 4, gen_loss = 0.4618927041689555, disc_loss = 0.008873360541959604
Trained batch 15 in epoch 4, gen_loss = 0.45954591408371925, disc_loss = 0.009398724825587124
Trained batch 16 in epoch 4, gen_loss = 0.4607562896083383, disc_loss = 0.009173106210415853
Trained batch 17 in epoch 4, gen_loss = 0.460732650425699, disc_loss = 0.008906393027346995
Trained batch 18 in epoch 4, gen_loss = 0.4604069418028781, disc_loss = 0.008682308694053637
Trained batch 19 in epoch 4, gen_loss = 0.4593996718525887, disc_loss = 0.009146288852207363
Trained batch 20 in epoch 4, gen_loss = 0.457262655099233, disc_loss = 0.008897733364609025
Trained batch 21 in epoch 4, gen_loss = 0.45701570537957276, disc_loss = 0.00874336891468953
Trained batch 22 in epoch 4, gen_loss = 0.4577857061572697, disc_loss = 0.008937768455918716
Trained batch 23 in epoch 4, gen_loss = 0.4599924869835377, disc_loss = 0.008912557328585535
Trained batch 24 in epoch 4, gen_loss = 0.46009633064270017, disc_loss = 0.009021284189075232
Trained batch 25 in epoch 4, gen_loss = 0.45950753872211164, disc_loss = 0.009214859509554047
Trained batch 26 in epoch 4, gen_loss = 0.4588267074690925, disc_loss = 0.008994617861592107
Trained batch 27 in epoch 4, gen_loss = 0.4575587138533592, disc_loss = 0.008831406328161913
Trained batch 28 in epoch 4, gen_loss = 0.4571326416114281, disc_loss = 0.008719000017976966
Trained batch 29 in epoch 4, gen_loss = 0.4591532230377197, disc_loss = 0.008640058757737278
Trained batch 30 in epoch 4, gen_loss = 0.4586731349268267, disc_loss = 0.008512799658121602
Trained batch 31 in epoch 4, gen_loss = 0.45913863368332386, disc_loss = 0.008602058689575642
Trained batch 32 in epoch 4, gen_loss = 0.4600585446213231, disc_loss = 0.011046444094090752
Trained batch 33 in epoch 4, gen_loss = 0.45612280596705046, disc_loss = 0.01836328750804943
Trained batch 34 in epoch 4, gen_loss = 0.45566139561789376, disc_loss = 0.020153833872505595
Trained batch 35 in epoch 4, gen_loss = 0.4550772574212816, disc_loss = 0.020077557044310704
Trained batch 36 in epoch 4, gen_loss = 0.4531336692539421, disc_loss = 0.020490173502145586
Trained batch 37 in epoch 4, gen_loss = 0.45498534801759216, disc_loss = 0.020828324370086193
Trained batch 38 in epoch 4, gen_loss = 0.4548813234537076, disc_loss = 0.021034887872445278
Trained batch 39 in epoch 4, gen_loss = 0.4526918031275272, disc_loss = 0.021991584636271
Trained batch 40 in epoch 4, gen_loss = 0.45466883516893153, disc_loss = 0.0253157839179039
Trained batch 41 in epoch 4, gen_loss = 0.4539822474831626, disc_loss = 0.0256137429248719
Trained batch 42 in epoch 4, gen_loss = 0.45294525942137076, disc_loss = 0.02788352273231329
Trained batch 43 in epoch 4, gen_loss = 0.4536354128610004, disc_loss = 0.03275340490720489
Trained batch 44 in epoch 4, gen_loss = 0.4532731380727556, disc_loss = 0.03292185639341672
Trained batch 45 in epoch 4, gen_loss = 0.4543321009563363, disc_loss = 0.0335126588040072
Trained batch 46 in epoch 4, gen_loss = 0.4542052580955181, disc_loss = 0.03438453447628528
Trained batch 47 in epoch 4, gen_loss = 0.4534546633561452, disc_loss = 0.03470566286705434
Trained batch 48 in epoch 4, gen_loss = 0.4532915201722359, disc_loss = 0.034976327677770536
Trained batch 49 in epoch 4, gen_loss = 0.45393784761428835, disc_loss = 0.035893577262759206
Trained batch 50 in epoch 4, gen_loss = 0.45471736847185623, disc_loss = 0.036316702398015
Trained batch 51 in epoch 4, gen_loss = 0.45564891627201665, disc_loss = 0.03579238922191927
Trained batch 52 in epoch 4, gen_loss = 0.45589551273381934, disc_loss = 0.03561830037396471
Trained batch 53 in epoch 4, gen_loss = 0.456154966795886, disc_loss = 0.035092364608620606
Trained batch 54 in epoch 4, gen_loss = 0.4540599877184088, disc_loss = 0.03549378367818214
Trained batch 55 in epoch 4, gen_loss = 0.4525274879166058, disc_loss = 0.03638866120516988
Trained batch 56 in epoch 4, gen_loss = 0.45359893744451957, disc_loss = 0.036235037660062835
Trained batch 57 in epoch 4, gen_loss = 0.45471364568019734, disc_loss = 0.03768188447755729
Trained batch 58 in epoch 4, gen_loss = 0.453853199542579, disc_loss = 0.038731773202386445
Trained batch 59 in epoch 4, gen_loss = 0.45412803987662, disc_loss = 0.039181482349522415
Trained batch 60 in epoch 4, gen_loss = 0.45416446445418185, disc_loss = 0.0390848707881008
Trained batch 61 in epoch 4, gen_loss = 0.4537341719673526, disc_loss = 0.038783148103844256
Trained batch 62 in epoch 4, gen_loss = 0.4525716631185441, disc_loss = 0.03875348243182377
Trained batch 63 in epoch 4, gen_loss = 0.4525742554105818, disc_loss = 0.038761015857744496
Trained batch 64 in epoch 4, gen_loss = 0.4521582057842842, disc_loss = 0.03942378426257234
Trained batch 65 in epoch 4, gen_loss = 0.4526333831476443, disc_loss = 0.04169747379439121
Trained batch 66 in epoch 4, gen_loss = 0.4517833608299939, disc_loss = 0.04657785938496688
Trained batch 67 in epoch 4, gen_loss = 0.450968655593255, disc_loss = 0.047991818029378706
Trained batch 68 in epoch 4, gen_loss = 0.45007249151451, disc_loss = 0.04983849704022641
Trained batch 69 in epoch 4, gen_loss = 0.4498051153762, disc_loss = 0.05135869031905064
Trained batch 70 in epoch 4, gen_loss = 0.44883005719789315, disc_loss = 0.0515267145819962
Trained batch 71 in epoch 4, gen_loss = 0.4492899311913384, disc_loss = 0.051547470185646996
Trained batch 72 in epoch 4, gen_loss = 0.44939848004955135, disc_loss = 0.05115191431154739
Trained batch 73 in epoch 4, gen_loss = 0.4491378431384628, disc_loss = 0.05072126690474515
Trained batch 74 in epoch 4, gen_loss = 0.44942976713180544, disc_loss = 0.05027659427995483
Trained batch 75 in epoch 4, gen_loss = 0.44933744010172394, disc_loss = 0.05028867399883702
Trained batch 76 in epoch 4, gen_loss = 0.4495015465593957, disc_loss = 0.05232420807414047
Trained batch 77 in epoch 4, gen_loss = 0.44885697425940096, disc_loss = 0.05509657099341544
Trained batch 78 in epoch 4, gen_loss = 0.44975196636175807, disc_loss = 0.054570779163107465
Trained batch 79 in epoch 4, gen_loss = 0.44852149598300456, disc_loss = 0.05488333455868997
Trained batch 80 in epoch 4, gen_loss = 0.4476002473154186, disc_loss = 0.05447574321433534
Trained batch 81 in epoch 4, gen_loss = 0.44810026484291726, disc_loss = 0.053907617046384186
Trained batch 82 in epoch 4, gen_loss = 0.44749703787895573, disc_loss = 0.053392414772232256
Trained batch 83 in epoch 4, gen_loss = 0.4473132998460815, disc_loss = 0.052847482901554374
Trained batch 84 in epoch 4, gen_loss = 0.446555919156355, disc_loss = 0.0525395375347751
Trained batch 85 in epoch 4, gen_loss = 0.4465827155251836, disc_loss = 0.052045733142687484
Trained batch 86 in epoch 4, gen_loss = 0.44627159628374824, disc_loss = 0.05156843649523183
Trained batch 87 in epoch 4, gen_loss = 0.44604416902769695, disc_loss = 0.05119808892909945
Trained batch 88 in epoch 4, gen_loss = 0.4460245186693213, disc_loss = 0.050900612136328155
Trained batch 89 in epoch 4, gen_loss = 0.44557618697484336, disc_loss = 0.05051082520124813
Trained batch 90 in epoch 4, gen_loss = 0.44527598593261214, disc_loss = 0.05037660346683729
Trained batch 91 in epoch 4, gen_loss = 0.4457760330127633, disc_loss = 0.05091972736662011
Trained batch 92 in epoch 4, gen_loss = 0.44530667348574565, disc_loss = 0.051950627662521856
Trained batch 93 in epoch 4, gen_loss = 0.4457923452904884, disc_loss = 0.05184381033610949
Trained batch 94 in epoch 4, gen_loss = 0.446385531676443, disc_loss = 0.05143351825934492
Trained batch 95 in epoch 4, gen_loss = 0.4467671765014529, disc_loss = 0.05099624457943719
Trained batch 96 in epoch 4, gen_loss = 0.4469097517814833, disc_loss = 0.05057406139838481
Trained batch 97 in epoch 4, gen_loss = 0.4471889950182973, disc_loss = 0.050208615885135165
Trained batch 98 in epoch 4, gen_loss = 0.44690933612862016, disc_loss = 0.050239019345191094
Trained batch 99 in epoch 4, gen_loss = 0.44751833081245423, disc_loss = 0.049909537532366814
Trained batch 100 in epoch 4, gen_loss = 0.4479679801676533, disc_loss = 0.049560306035904306
Trained batch 101 in epoch 4, gen_loss = 0.44768840658898446, disc_loss = 0.04916246076954492
Trained batch 102 in epoch 4, gen_loss = 0.4469195071933339, disc_loss = 0.04879302186529758
Trained batch 103 in epoch 4, gen_loss = 0.44707389920949936, disc_loss = 0.048449510121897146
Trained batch 104 in epoch 4, gen_loss = 0.4474010847863697, disc_loss = 0.04810203427803658
Trained batch 105 in epoch 4, gen_loss = 0.4472453512673108, disc_loss = 0.047734954715091385
Trained batch 106 in epoch 4, gen_loss = 0.4474241134719314, disc_loss = 0.047365599655694215
Trained batch 107 in epoch 4, gen_loss = 0.4474603144658936, disc_loss = 0.047073157042851324
Trained batch 108 in epoch 4, gen_loss = 0.44708625876575436, disc_loss = 0.04692067630127619
Trained batch 109 in epoch 4, gen_loss = 0.447794278643348, disc_loss = 0.04701047719625587
Trained batch 110 in epoch 4, gen_loss = 0.447639778390661, disc_loss = 0.04688017694950775
Trained batch 111 in epoch 4, gen_loss = 0.44774462814841953, disc_loss = 0.04653848214989661
Trained batch 112 in epoch 4, gen_loss = 0.44789507141155477, disc_loss = 0.04618301448222678
Trained batch 113 in epoch 4, gen_loss = 0.4489707175576896, disc_loss = 0.04592035437541965
Trained batch 114 in epoch 4, gen_loss = 0.44905798279720804, disc_loss = 0.04562330101414219
Trained batch 115 in epoch 4, gen_loss = 0.4491825347830509, disc_loss = 0.04532499931319135
Trained batch 116 in epoch 4, gen_loss = 0.44961371100865877, disc_loss = 0.04499289676801771
Trained batch 117 in epoch 4, gen_loss = 0.44958582621509746, disc_loss = 0.044728720671165796
Trained batch 118 in epoch 4, gen_loss = 0.45015033203012805, disc_loss = 0.04443088812487466
Trained batch 119 in epoch 4, gen_loss = 0.4504965916275978, disc_loss = 0.0441860026291882
Trained batch 120 in epoch 4, gen_loss = 0.45053293931582744, disc_loss = 0.04399191668980624
Trained batch 121 in epoch 4, gen_loss = 0.45071176378453365, disc_loss = 0.04378898517366071
Trained batch 122 in epoch 4, gen_loss = 0.4506978794811218, disc_loss = 0.04358119077647362
Trained batch 123 in epoch 4, gen_loss = 0.45095009573044315, disc_loss = 0.043442808715025746
Trained batch 124 in epoch 4, gen_loss = 0.4505245988368988, disc_loss = 0.043212978519499304
Trained batch 125 in epoch 4, gen_loss = 0.450116599362994, disc_loss = 0.043098235155440985
Trained batch 126 in epoch 4, gen_loss = 0.45020710788373874, disc_loss = 0.04310931755948489
Trained batch 127 in epoch 4, gen_loss = 0.4501726955641061, disc_loss = 0.042836546163016465
Trained batch 128 in epoch 4, gen_loss = 0.4511551891648492, disc_loss = 0.04315848442790813
Trained batch 129 in epoch 4, gen_loss = 0.4510566227711164, disc_loss = 0.04310747034704456
Trained batch 130 in epoch 4, gen_loss = 0.4510429185310393, disc_loss = 0.04296112790675336
Trained batch 131 in epoch 4, gen_loss = 0.4509488863475395, disc_loss = 0.04310083004758891
Trained batch 132 in epoch 4, gen_loss = 0.4512982440174074, disc_loss = 0.04313569215539479
Trained batch 133 in epoch 4, gen_loss = 0.4516560192873229, disc_loss = 0.04303708902574075
Trained batch 134 in epoch 4, gen_loss = 0.4519624129489616, disc_loss = 0.042857979562271525
Trained batch 135 in epoch 4, gen_loss = 0.4519363231956959, disc_loss = 0.04283456380396862
Trained batch 136 in epoch 4, gen_loss = 0.4521642607929063, disc_loss = 0.04258906892942686
Trained batch 137 in epoch 4, gen_loss = 0.4520947162223899, disc_loss = 0.042410534550098404
Trained batch 138 in epoch 4, gen_loss = 0.452030718755379, disc_loss = 0.0421678703479308
Trained batch 139 in epoch 4, gen_loss = 0.45131205575806754, disc_loss = 0.04193791743767049
Trained batch 140 in epoch 4, gen_loss = 0.4506257083399076, disc_loss = 0.041723372190133896
Trained batch 141 in epoch 4, gen_loss = 0.450092259637067, disc_loss = 0.041487348521731686
Trained batch 142 in epoch 4, gen_loss = 0.44992048236039967, disc_loss = 0.041239618421434525
Trained batch 143 in epoch 4, gen_loss = 0.4490701090544462, disc_loss = 0.04098476447203817
Trained batch 144 in epoch 4, gen_loss = 0.44888814420535644, disc_loss = 0.0408293012497497
Trained batch 145 in epoch 4, gen_loss = 0.4488845518598818, disc_loss = 0.04065453600814591
Trained batch 146 in epoch 4, gen_loss = 0.4493765220755622, disc_loss = 0.04054315450607615
Trained batch 147 in epoch 4, gen_loss = 0.4495015627629048, disc_loss = 0.04034386431433361
Trained batch 148 in epoch 4, gen_loss = 0.4490157915841813, disc_loss = 0.040397562458486164
Trained batch 149 in epoch 4, gen_loss = 0.4490360826253891, disc_loss = 0.04082745484697322
Trained batch 150 in epoch 4, gen_loss = 0.4493340125541813, disc_loss = 0.040660388789306216
Trained batch 151 in epoch 4, gen_loss = 0.4489632976290427, disc_loss = 0.041366864948557985
Trained batch 152 in epoch 4, gen_loss = 0.44917166427849164, disc_loss = 0.04169002844605083
Trained batch 153 in epoch 4, gen_loss = 0.4492586585995439, disc_loss = 0.041528031239044166
Trained batch 154 in epoch 4, gen_loss = 0.44917200515347144, disc_loss = 0.04132483851224665
Trained batch 155 in epoch 4, gen_loss = 0.4488632636956679, disc_loss = 0.04125611698672844
Trained batch 156 in epoch 4, gen_loss = 0.4489351932410222, disc_loss = 0.04107260454600309
Trained batch 157 in epoch 4, gen_loss = 0.4481301860341543, disc_loss = 0.04120708315609659
Trained batch 158 in epoch 4, gen_loss = 0.4484513073972186, disc_loss = 0.041189451751726794
Trained batch 159 in epoch 4, gen_loss = 0.44832020439207554, disc_loss = 0.042035424636560494
Trained batch 160 in epoch 4, gen_loss = 0.4475900175408547, disc_loss = 0.04410157340827473
Trained batch 161 in epoch 4, gen_loss = 0.4471807676700898, disc_loss = 0.04426865300083142
Trained batch 162 in epoch 4, gen_loss = 0.4477570150161813, disc_loss = 0.04515148673857922
Trained batch 163 in epoch 4, gen_loss = 0.44725417000491446, disc_loss = 0.04615629847990576
Trained batch 164 in epoch 4, gen_loss = 0.4471731778347131, disc_loss = 0.04643656365065412
Trained batch 165 in epoch 4, gen_loss = 0.4475632550486599, disc_loss = 0.046700282378615926
Trained batch 166 in epoch 4, gen_loss = 0.4475698096309593, disc_loss = 0.0473473685247054
Trained batch 167 in epoch 4, gen_loss = 0.44758634127321695, disc_loss = 0.04746661816136025
Trained batch 168 in epoch 4, gen_loss = 0.44790594288583335, disc_loss = 0.047634014912148026
Trained batch 169 in epoch 4, gen_loss = 0.44760221313027776, disc_loss = 0.04772653165273368
Trained batch 170 in epoch 4, gen_loss = 0.4471618604590321, disc_loss = 0.04773967662739039
Trained batch 171 in epoch 4, gen_loss = 0.4476835795266684, disc_loss = 0.04791197806412657
Trained batch 172 in epoch 4, gen_loss = 0.4477254486497427, disc_loss = 0.04776992896205686
Trained batch 173 in epoch 4, gen_loss = 0.4475041016422469, disc_loss = 0.047590528055490265
Trained batch 174 in epoch 4, gen_loss = 0.4469082161358425, disc_loss = 0.04740600507972496
Trained batch 175 in epoch 4, gen_loss = 0.44702258706092834, disc_loss = 0.047306749342665586
Trained batch 176 in epoch 4, gen_loss = 0.44671197951176744, disc_loss = 0.04747900178150858
Trained batch 177 in epoch 4, gen_loss = 0.44719809745804645, disc_loss = 0.04816335277223771
Trained batch 178 in epoch 4, gen_loss = 0.44712278146983525, disc_loss = 0.04798795803913108
Trained batch 179 in epoch 4, gen_loss = 0.4466215428378847, disc_loss = 0.04789779834811472
Trained batch 180 in epoch 4, gen_loss = 0.4466529215238371, disc_loss = 0.04773204745621889
Trained batch 181 in epoch 4, gen_loss = 0.446845442711652, disc_loss = 0.04769700838017513
Trained batch 182 in epoch 4, gen_loss = 0.446547315583203, disc_loss = 0.04761920566797827
Trained batch 183 in epoch 4, gen_loss = 0.44694525635112886, disc_loss = 0.04741980992611903
Trained batch 184 in epoch 4, gen_loss = 0.44705860711432793, disc_loss = 0.047224585815156636
Trained batch 185 in epoch 4, gen_loss = 0.44734261289078703, disc_loss = 0.04717727975108691
Trained batch 186 in epoch 4, gen_loss = 0.44775780971674994, disc_loss = 0.04781361291045572
Trained batch 187 in epoch 4, gen_loss = 0.44698747025525315, disc_loss = 0.048088722250503584
Trained batch 188 in epoch 4, gen_loss = 0.4464229454123785, disc_loss = 0.0479098046765165
Trained batch 189 in epoch 4, gen_loss = 0.4462893638171648, disc_loss = 0.04782049384605336
Trained batch 190 in epoch 4, gen_loss = 0.4463026690545506, disc_loss = 0.04865715121460289
Trained batch 191 in epoch 4, gen_loss = 0.44578311204289395, disc_loss = 0.04971815221991468
Trained batch 192 in epoch 4, gen_loss = 0.4461281915711615, disc_loss = 0.04956595813179958
Trained batch 193 in epoch 4, gen_loss = 0.446509385999945, disc_loss = 0.049446397127353194
Trained batch 194 in epoch 4, gen_loss = 0.4465911898857508, disc_loss = 0.049248203188658524
Trained batch 195 in epoch 4, gen_loss = 0.44641912789369115, disc_loss = 0.04927114096270608
Trained batch 196 in epoch 4, gen_loss = 0.4465098403734604, disc_loss = 0.04950791736591967
Trained batch 197 in epoch 4, gen_loss = 0.4460677561735866, disc_loss = 0.04952430620911823
Trained batch 198 in epoch 4, gen_loss = 0.44577487075149114, disc_loss = 0.04939580847504525
Trained batch 199 in epoch 4, gen_loss = 0.44551274821162223, disc_loss = 0.04919959997059777
Trained batch 200 in epoch 4, gen_loss = 0.4456100884954728, disc_loss = 0.04904033410691874
Trained batch 201 in epoch 4, gen_loss = 0.44523384001585514, disc_loss = 0.04892576892749582
Trained batch 202 in epoch 4, gen_loss = 0.4451384120093191, disc_loss = 0.048868156283671776
Trained batch 203 in epoch 4, gen_loss = 0.4449022984972187, disc_loss = 0.04877605653760553
Trained batch 204 in epoch 4, gen_loss = 0.44470885061636206, disc_loss = 0.04874994481527587
Trained batch 205 in epoch 4, gen_loss = 0.44441609026737583, disc_loss = 0.04916274818157759
Trained batch 206 in epoch 4, gen_loss = 0.44518352116363635, disc_loss = 0.0496199332146145
Trained batch 207 in epoch 4, gen_loss = 0.44565244749761546, disc_loss = 0.04944618700224405
Trained batch 208 in epoch 4, gen_loss = 0.4456700460192119, disc_loss = 0.04925726096783029
Trained batch 209 in epoch 4, gen_loss = 0.4453233371178309, disc_loss = 0.04921725130906063
Trained batch 210 in epoch 4, gen_loss = 0.4451822461957615, disc_loss = 0.04905213672729536
Trained batch 211 in epoch 4, gen_loss = 0.4455780627311401, disc_loss = 0.048859907355915125
Trained batch 212 in epoch 4, gen_loss = 0.44551659497856533, disc_loss = 0.04867391911567027
Trained batch 213 in epoch 4, gen_loss = 0.44537070699941333, disc_loss = 0.04847731900392709
Trained batch 214 in epoch 4, gen_loss = 0.4452858478523964, disc_loss = 0.04826845280652822
Trained batch 215 in epoch 4, gen_loss = 0.4450409529661691, disc_loss = 0.04807011825377466
Trained batch 216 in epoch 4, gen_loss = 0.4452071671936369, disc_loss = 0.04788278028892551
Trained batch 217 in epoch 4, gen_loss = 0.4452316602435681, disc_loss = 0.04768340418824431
Trained batch 218 in epoch 4, gen_loss = 0.4454786147428974, disc_loss = 0.047496610255189003
Trained batch 219 in epoch 4, gen_loss = 0.4455231410535899, disc_loss = 0.04732888873708858
Trained batch 220 in epoch 4, gen_loss = 0.44540883054560665, disc_loss = 0.047141276820398426
Trained batch 221 in epoch 4, gen_loss = 0.44527484691357827, disc_loss = 0.047042419208918475
Trained batch 222 in epoch 4, gen_loss = 0.44519171613214265, disc_loss = 0.04685990118960361
Trained batch 223 in epoch 4, gen_loss = 0.4451794770679304, disc_loss = 0.04670088141574524
Trained batch 224 in epoch 4, gen_loss = 0.4452815188301934, disc_loss = 0.04651238282107645
Trained batch 225 in epoch 4, gen_loss = 0.4455616054809199, disc_loss = 0.04643706080248266
Trained batch 226 in epoch 4, gen_loss = 0.44581755063607303, disc_loss = 0.04634086838984936
Trained batch 227 in epoch 4, gen_loss = 0.44586455717421414, disc_loss = 0.0461612769541445
Trained batch 228 in epoch 4, gen_loss = 0.4456836020321825, disc_loss = 0.04611566167845346
Trained batch 229 in epoch 4, gen_loss = 0.44582950796770016, disc_loss = 0.04601828639355043
Trained batch 230 in epoch 4, gen_loss = 0.4457650129155163, disc_loss = 0.045877177606929435
Trained batch 231 in epoch 4, gen_loss = 0.4458998764126465, disc_loss = 0.04577065574743881
Trained batch 232 in epoch 4, gen_loss = 0.44598047569585975, disc_loss = 0.04559620497188663
Trained batch 233 in epoch 4, gen_loss = 0.44621221428243524, disc_loss = 0.045572860391301095
Trained batch 234 in epoch 4, gen_loss = 0.4460746737236672, disc_loss = 0.045723900692339274
Trained batch 235 in epoch 4, gen_loss = 0.4461941090175661, disc_loss = 0.045820056683762725
Trained batch 236 in epoch 4, gen_loss = 0.4462693529792979, disc_loss = 0.045672752299122044
Trained batch 237 in epoch 4, gen_loss = 0.44610131024813454, disc_loss = 0.045521304079824514
Trained batch 238 in epoch 4, gen_loss = 0.44592748239449376, disc_loss = 0.04539053034325711
Trained batch 239 in epoch 4, gen_loss = 0.4456490986049175, disc_loss = 0.045227312467371425
Trained batch 240 in epoch 4, gen_loss = 0.44568964801883304, disc_loss = 0.04513900609555581
Trained batch 241 in epoch 4, gen_loss = 0.4458528504637647, disc_loss = 0.04500941007806004
Trained batch 242 in epoch 4, gen_loss = 0.4458781013518204, disc_loss = 0.04498454506045261
Trained batch 243 in epoch 4, gen_loss = 0.4458516361039193, disc_loss = 0.04482575641853399
Trained batch 244 in epoch 4, gen_loss = 0.4458418037210192, disc_loss = 0.044802820758551964
Trained batch 245 in epoch 4, gen_loss = 0.4456758231409197, disc_loss = 0.04484830145549968
Trained batch 246 in epoch 4, gen_loss = 0.4455997744793834, disc_loss = 0.044752965760436136
Trained batch 247 in epoch 4, gen_loss = 0.4455563987214719, disc_loss = 0.04459275485902664
Trained batch 248 in epoch 4, gen_loss = 0.4455465845554229, disc_loss = 0.04443917030947335
Trained batch 249 in epoch 4, gen_loss = 0.4458428746461868, disc_loss = 0.04432532879896462
Trained batch 250 in epoch 4, gen_loss = 0.44573267368206465, disc_loss = 0.044212417307855245
Trained batch 251 in epoch 4, gen_loss = 0.44595573333993793, disc_loss = 0.044062120717994514
Trained batch 252 in epoch 4, gen_loss = 0.4459377166781972, disc_loss = 0.043911981506810596
Trained batch 253 in epoch 4, gen_loss = 0.4459344309380674, disc_loss = 0.0437844834679107
Trained batch 254 in epoch 4, gen_loss = 0.4457898342141918, disc_loss = 0.04369689938338364
Trained batch 255 in epoch 4, gen_loss = 0.4456127096200362, disc_loss = 0.04372405817412073
Trained batch 256 in epoch 4, gen_loss = 0.4458993465751989, disc_loss = 0.043802479571927386
Trained batch 257 in epoch 4, gen_loss = 0.44580648285011915, disc_loss = 0.04364765535267575
Trained batch 258 in epoch 4, gen_loss = 0.44562629486603167, disc_loss = 0.04353169583927653
Trained batch 259 in epoch 4, gen_loss = 0.4457834583062392, disc_loss = 0.04352043238647569
Trained batch 260 in epoch 4, gen_loss = 0.4458356531643776, disc_loss = 0.04342649149676335
Trained batch 261 in epoch 4, gen_loss = 0.44583103288220993, disc_loss = 0.04327812937856119
Trained batch 262 in epoch 4, gen_loss = 0.4458084177834906, disc_loss = 0.0431576697244362
Trained batch 263 in epoch 4, gen_loss = 0.44564670809742174, disc_loss = 0.043028601619880646
Trained batch 264 in epoch 4, gen_loss = 0.44540364123740284, disc_loss = 0.04290805686581529
Trained batch 265 in epoch 4, gen_loss = 0.4452982362275733, disc_loss = 0.04278526888439026
Trained batch 266 in epoch 4, gen_loss = 0.4453543951448876, disc_loss = 0.04264853111632196
Trained batch 267 in epoch 4, gen_loss = 0.4454356162850536, disc_loss = 0.0425333451382371
Trained batch 268 in epoch 4, gen_loss = 0.44542514978731435, disc_loss = 0.04239578294778956
Trained batch 269 in epoch 4, gen_loss = 0.4454856390202487, disc_loss = 0.04225745207664591
Trained batch 270 in epoch 4, gen_loss = 0.4456080983485683, disc_loss = 0.0421142328334663
Trained batch 271 in epoch 4, gen_loss = 0.4454965012914994, disc_loss = 0.04197285672382671
Trained batch 272 in epoch 4, gen_loss = 0.4454841463120429, disc_loss = 0.0418488723532921
Trained batch 273 in epoch 4, gen_loss = 0.4453810013993813, disc_loss = 0.04171062981961363
Trained batch 274 in epoch 4, gen_loss = 0.44534288438883696, disc_loss = 0.041577982440252195
Trained batch 275 in epoch 4, gen_loss = 0.44515400369098224, disc_loss = 0.04150240858713084
Trained batch 276 in epoch 4, gen_loss = 0.4451641564119594, disc_loss = 0.041379838137944575
Trained batch 277 in epoch 4, gen_loss = 0.44518009203372244, disc_loss = 0.04127324862144351
Trained batch 278 in epoch 4, gen_loss = 0.4452605229338437, disc_loss = 0.04115296021524456
Trained batch 279 in epoch 4, gen_loss = 0.4452733049435275, disc_loss = 0.04102321426616982
Trained batch 280 in epoch 4, gen_loss = 0.44520308528082225, disc_loss = 0.04089680710953272
Trained batch 281 in epoch 4, gen_loss = 0.4448416550108727, disc_loss = 0.04080317021968464
Trained batch 282 in epoch 4, gen_loss = 0.4444418057746685, disc_loss = 0.04069035489592609
Trained batch 283 in epoch 4, gen_loss = 0.44462280605040805, disc_loss = 0.04057551376869194
Trained batch 284 in epoch 4, gen_loss = 0.4443699213496426, disc_loss = 0.040471471246462644
Trained batch 285 in epoch 4, gen_loss = 0.4443791826496591, disc_loss = 0.04036052510226992
Trained batch 286 in epoch 4, gen_loss = 0.4444453562593626, disc_loss = 0.04026466369051292
Trained batch 287 in epoch 4, gen_loss = 0.44422951113018727, disc_loss = 0.040144958680482686
Trained batch 288 in epoch 4, gen_loss = 0.44404556656378774, disc_loss = 0.040076677650406595
Trained batch 289 in epoch 4, gen_loss = 0.443974152926741, disc_loss = 0.03997472934906596
Trained batch 290 in epoch 4, gen_loss = 0.4440042972564697, disc_loss = 0.03988713223672763
Trained batch 291 in epoch 4, gen_loss = 0.44401962065125167, disc_loss = 0.03980457148521067
Trained batch 292 in epoch 4, gen_loss = 0.444006851813899, disc_loss = 0.03974114436459165
Trained batch 293 in epoch 4, gen_loss = 0.444151550227282, disc_loss = 0.03980980851991596
Trained batch 294 in epoch 4, gen_loss = 0.44406552941112193, disc_loss = 0.0397790876406608
Trained batch 295 in epoch 4, gen_loss = 0.4439718525957417, disc_loss = 0.039721793902572244
Trained batch 296 in epoch 4, gen_loss = 0.4438833273219741, disc_loss = 0.03969659942738486
Trained batch 297 in epoch 4, gen_loss = 0.44375803976651007, disc_loss = 0.039844078235265694
Trained batch 298 in epoch 4, gen_loss = 0.4435564372252461, disc_loss = 0.03975664826894933
Trained batch 299 in epoch 4, gen_loss = 0.4434359280268351, disc_loss = 0.03967377201809237
Trained batch 300 in epoch 4, gen_loss = 0.443434385267207, disc_loss = 0.03957089608955967
Trained batch 301 in epoch 4, gen_loss = 0.44344049287552867, disc_loss = 0.039454477442897214
Trained batch 302 in epoch 4, gen_loss = 0.44329117145081953, disc_loss = 0.039445304122781105
Trained batch 303 in epoch 4, gen_loss = 0.4431027256344494, disc_loss = 0.03934257810990522
Trained batch 304 in epoch 4, gen_loss = 0.4432513210617128, disc_loss = 0.03927443631023901
Trained batch 305 in epoch 4, gen_loss = 0.4435287031278112, disc_loss = 0.03917737540581988
Trained batch 306 in epoch 4, gen_loss = 0.44362002815019813, disc_loss = 0.03907597353924612
Trained batch 307 in epoch 4, gen_loss = 0.4435097922558908, disc_loss = 0.03897226126048133
Trained batch 308 in epoch 4, gen_loss = 0.4434157081406479, disc_loss = 0.03891406984228195
Trained batch 309 in epoch 4, gen_loss = 0.4434180127036187, disc_loss = 0.03884508185118677
Trained batch 310 in epoch 4, gen_loss = 0.44330634124026036, disc_loss = 0.03873449370079341
Trained batch 311 in epoch 4, gen_loss = 0.4432047750705328, disc_loss = 0.03865498522123417
Trained batch 312 in epoch 4, gen_loss = 0.4435804869039371, disc_loss = 0.038769192593439986
Trained batch 313 in epoch 4, gen_loss = 0.44386969914861546, disc_loss = 0.0386671273224649
Trained batch 314 in epoch 4, gen_loss = 0.4438764585389031, disc_loss = 0.03859052760526538
Trained batch 315 in epoch 4, gen_loss = 0.44373096440789067, disc_loss = 0.038963692883159255
Trained batch 316 in epoch 4, gen_loss = 0.44376915495854447, disc_loss = 0.039050366889614885
Trained batch 317 in epoch 4, gen_loss = 0.44381988995105215, disc_loss = 0.03902960970043058
Trained batch 318 in epoch 4, gen_loss = 0.44368883173293827, disc_loss = 0.03893671827799521
Trained batch 319 in epoch 4, gen_loss = 0.44368732124567034, disc_loss = 0.03883471798762912
Trained batch 320 in epoch 4, gen_loss = 0.4437609196080597, disc_loss = 0.03877444618825461
Trained batch 321 in epoch 4, gen_loss = 0.44344818462496216, disc_loss = 0.03868998691688367
Trained batch 322 in epoch 4, gen_loss = 0.4433433713374123, disc_loss = 0.03866725806406362
Trained batch 323 in epoch 4, gen_loss = 0.44338565273785296, disc_loss = 0.0385723666296582
Trained batch 324 in epoch 4, gen_loss = 0.4434516743513254, disc_loss = 0.03851221902869069
Trained batch 325 in epoch 4, gen_loss = 0.44321704294783937, disc_loss = 0.03845307149672938
Trained batch 326 in epoch 4, gen_loss = 0.4429340330650318, disc_loss = 0.03853831650825952
Trained batch 327 in epoch 4, gen_loss = 0.44316992627047913, disc_loss = 0.03870107675192696
Trained batch 328 in epoch 4, gen_loss = 0.44339252704907334, disc_loss = 0.038663972852791245
Trained batch 329 in epoch 4, gen_loss = 0.4433233812902913, disc_loss = 0.038568147606301034
Trained batch 330 in epoch 4, gen_loss = 0.44338303993475764, disc_loss = 0.03851671811907898
Trained batch 331 in epoch 4, gen_loss = 0.44349227782832573, disc_loss = 0.038422962297202955
Trained batch 332 in epoch 4, gen_loss = 0.44350975796625064, disc_loss = 0.03832875406677211
Trained batch 333 in epoch 4, gen_loss = 0.4436264138914154, disc_loss = 0.038254019784780144
Trained batch 334 in epoch 4, gen_loss = 0.4436582992325968, disc_loss = 0.03815403576773494
Trained batch 335 in epoch 4, gen_loss = 0.443546073777335, disc_loss = 0.0380900139377142
Trained batch 336 in epoch 4, gen_loss = 0.4433185504169068, disc_loss = 0.038286058210079674
Trained batch 337 in epoch 4, gen_loss = 0.4436205334564638, disc_loss = 0.038520608532666804
Trained batch 338 in epoch 4, gen_loss = 0.4436242711403377, disc_loss = 0.03843614171673942
Trained batch 339 in epoch 4, gen_loss = 0.4435386350926231, disc_loss = 0.038403415581321015
Trained batch 340 in epoch 4, gen_loss = 0.44356466772968817, disc_loss = 0.03831287216711953
Trained batch 341 in epoch 4, gen_loss = 0.44378976271166437, disc_loss = 0.03822033319006843
Trained batch 342 in epoch 4, gen_loss = 0.4439065648411175, disc_loss = 0.03813950652691044
Trained batch 343 in epoch 4, gen_loss = 0.4439438203739565, disc_loss = 0.038122795482956655
Trained batch 344 in epoch 4, gen_loss = 0.44400364687477334, disc_loss = 0.03807448592387896
Trained batch 345 in epoch 4, gen_loss = 0.4438253409428404, disc_loss = 0.037991182713074924
Trained batch 346 in epoch 4, gen_loss = 0.4436118649989796, disc_loss = 0.03808138368823042
Trained batch 347 in epoch 4, gen_loss = 0.4437575672549763, disc_loss = 0.03805878294508733
Trained batch 348 in epoch 4, gen_loss = 0.44390932143930034, disc_loss = 0.03800212192805457
Trained batch 349 in epoch 4, gen_loss = 0.4437781264952251, disc_loss = 0.03791580616496503
Trained batch 350 in epoch 4, gen_loss = 0.44375001254924, disc_loss = 0.0378531288379469
Trained batch 351 in epoch 4, gen_loss = 0.4437287953597578, disc_loss = 0.03778947219226128
Trained batch 352 in epoch 4, gen_loss = 0.4435295458387045, disc_loss = 0.03791105629422467
Trained batch 353 in epoch 4, gen_loss = 0.4432315887872782, disc_loss = 0.03823278348045792
Trained batch 354 in epoch 4, gen_loss = 0.443243584834354, disc_loss = 0.038393180579943974
Trained batch 355 in epoch 4, gen_loss = 0.4431222602725029, disc_loss = 0.0383084587153738
Trained batch 356 in epoch 4, gen_loss = 0.44308200445161816, disc_loss = 0.038317831497931595
Trained batch 357 in epoch 4, gen_loss = 0.443241192059144, disc_loss = 0.0382365648200288
Trained batch 358 in epoch 4, gen_loss = 0.4433309534632064, disc_loss = 0.038231289905332505
Trained batch 359 in epoch 4, gen_loss = 0.44345287672347494, disc_loss = 0.038230276670462145
Trained batch 360 in epoch 4, gen_loss = 0.443360127983331, disc_loss = 0.038220839387894584
Trained batch 361 in epoch 4, gen_loss = 0.44352062441696777, disc_loss = 0.03817304692910315
Trained batch 362 in epoch 4, gen_loss = 0.4434766285018816, disc_loss = 0.03810033637943059
Trained batch 363 in epoch 4, gen_loss = 0.44359273185114284, disc_loss = 0.03807665751658503
Trained batch 364 in epoch 4, gen_loss = 0.4434519789806784, disc_loss = 0.03812410244718194
Trained batch 365 in epoch 4, gen_loss = 0.4436764175611767, disc_loss = 0.03866994105243821
Trained batch 366 in epoch 4, gen_loss = 0.44338775355094784, disc_loss = 0.03858635649313435
Trained batch 367 in epoch 4, gen_loss = 0.4432122875005007, disc_loss = 0.039179114702046325
Trained batch 368 in epoch 4, gen_loss = 0.44346714108617, disc_loss = 0.039316720994275196
Trained batch 369 in epoch 4, gen_loss = 0.4434928422844088, disc_loss = 0.03941866817531755
Trained batch 370 in epoch 4, gen_loss = 0.44339584075215693, disc_loss = 0.039335830781026426
Trained batch 371 in epoch 4, gen_loss = 0.44345517160110576, disc_loss = 0.03931520096782435
Trained batch 372 in epoch 4, gen_loss = 0.4435021583260544, disc_loss = 0.039225126433138795
Trained batch 373 in epoch 4, gen_loss = 0.4435708813648173, disc_loss = 0.03913614384326984
Trained batch 374 in epoch 4, gen_loss = 0.4435430141290029, disc_loss = 0.039043952144682405
Trained batch 375 in epoch 4, gen_loss = 0.44358105600831355, disc_loss = 0.038949451175211196
Trained batch 376 in epoch 4, gen_loss = 0.4436010021904103, disc_loss = 0.03885387375441921
Trained batch 377 in epoch 4, gen_loss = 0.4435914274719026, disc_loss = 0.03878147885691197
Trained batch 378 in epoch 4, gen_loss = 0.44367588572892164, disc_loss = 0.03871568290290661
Trained batch 379 in epoch 4, gen_loss = 0.44354223279576555, disc_loss = 0.038670697797236864
Trained batch 380 in epoch 4, gen_loss = 0.4434262413991092, disc_loss = 0.038603115185185916
Trained batch 381 in epoch 4, gen_loss = 0.4433171324704954, disc_loss = 0.03866944820327557
Trained batch 382 in epoch 4, gen_loss = 0.44330076161314863, disc_loss = 0.03901102558609983
Trained batch 383 in epoch 4, gen_loss = 0.4431977057829499, disc_loss = 0.03926248304560431
Trained batch 384 in epoch 4, gen_loss = 0.4431754508575836, disc_loss = 0.03951183336291027
Trained batch 385 in epoch 4, gen_loss = 0.4429903183267524, disc_loss = 0.039472589794054165
Trained batch 386 in epoch 4, gen_loss = 0.4427766344035935, disc_loss = 0.03951046879954386
Trained batch 387 in epoch 4, gen_loss = 0.4428418850929467, disc_loss = 0.03945875442322804
Trained batch 388 in epoch 4, gen_loss = 0.44273941475505385, disc_loss = 0.03943148522893958
Trained batch 389 in epoch 4, gen_loss = 0.4426410728540176, disc_loss = 0.03944179938556865
Trained batch 390 in epoch 4, gen_loss = 0.44258751070407953, disc_loss = 0.03935404044583135
Trained batch 391 in epoch 4, gen_loss = 0.44260439565595316, disc_loss = 0.03927768327709173
Trained batch 392 in epoch 4, gen_loss = 0.44277961942682437, disc_loss = 0.039193201340905585
Trained batch 393 in epoch 4, gen_loss = 0.44281888136706377, disc_loss = 0.03917713852381797
Trained batch 394 in epoch 4, gen_loss = 0.44283583103855956, disc_loss = 0.039140792987957786
Trained batch 395 in epoch 4, gen_loss = 0.4425962862342295, disc_loss = 0.039059574000838426
Trained batch 396 in epoch 4, gen_loss = 0.44255229155122483, disc_loss = 0.03898990500052119
Trained batch 397 in epoch 4, gen_loss = 0.4425647093273287, disc_loss = 0.038936417264367765
Trained batch 398 in epoch 4, gen_loss = 0.442707869268599, disc_loss = 0.03885598507894198
Trained batch 399 in epoch 4, gen_loss = 0.4427688261121511, disc_loss = 0.038778665784047914
Trained batch 400 in epoch 4, gen_loss = 0.4429013801185865, disc_loss = 0.038751185108719395
Trained batch 401 in epoch 4, gen_loss = 0.4431989844610442, disc_loss = 0.038749307552723225
Trained batch 402 in epoch 4, gen_loss = 0.44325583500246846, disc_loss = 0.03878984227892076
Trained batch 403 in epoch 4, gen_loss = 0.4434364515513477, disc_loss = 0.038939369779015603
Trained batch 404 in epoch 4, gen_loss = 0.4435506107630553, disc_loss = 0.03903589838379879
Trained batch 405 in epoch 4, gen_loss = 0.44343832083817186, disc_loss = 0.038986041275967886
Trained batch 406 in epoch 4, gen_loss = 0.44345683606309444, disc_loss = 0.03895000738254233
Trained batch 407 in epoch 4, gen_loss = 0.44362940186379, disc_loss = 0.03888092749847976
Trained batch 408 in epoch 4, gen_loss = 0.4435077555167937, disc_loss = 0.03890684610551501
Trained batch 409 in epoch 4, gen_loss = 0.44366010681885043, disc_loss = 0.03883684677889616
Trained batch 410 in epoch 4, gen_loss = 0.4438211200736155, disc_loss = 0.038759793843756774
Trained batch 411 in epoch 4, gen_loss = 0.4438984452665431, disc_loss = 0.03871367740878853
Trained batch 412 in epoch 4, gen_loss = 0.443759625385229, disc_loss = 0.03872519812025761
Trained batch 413 in epoch 4, gen_loss = 0.4438277982571275, disc_loss = 0.03865819472531622
Trained batch 414 in epoch 4, gen_loss = 0.4437757716839572, disc_loss = 0.038575708909880324
Trained batch 415 in epoch 4, gen_loss = 0.44380452311955965, disc_loss = 0.038498386712700054
Trained batch 416 in epoch 4, gen_loss = 0.443833012089169, disc_loss = 0.038487348141599834
Trained batch 417 in epoch 4, gen_loss = 0.4438501437457555, disc_loss = 0.03841085662022589
Trained batch 418 in epoch 4, gen_loss = 0.443902048617957, disc_loss = 0.03841619358480261
Trained batch 419 in epoch 4, gen_loss = 0.443903362041428, disc_loss = 0.038499354105442765
Trained batch 420 in epoch 4, gen_loss = 0.4439867037633819, disc_loss = 0.038496633097883357
Trained batch 421 in epoch 4, gen_loss = 0.44407747050314716, disc_loss = 0.03844876941381755
Trained batch 422 in epoch 4, gen_loss = 0.4441293058102294, disc_loss = 0.038384664814751904
Trained batch 423 in epoch 4, gen_loss = 0.4438035377775723, disc_loss = 0.03832273387112918
Trained batch 424 in epoch 4, gen_loss = 0.4435655617012697, disc_loss = 0.03829529883887838
Trained batch 425 in epoch 4, gen_loss = 0.4435866608726027, disc_loss = 0.03822639727300391
Trained batch 426 in epoch 4, gen_loss = 0.44365299508778216, disc_loss = 0.03815447706707363
Trained batch 427 in epoch 4, gen_loss = 0.4438885288121544, disc_loss = 0.03809745750655464
Trained batch 428 in epoch 4, gen_loss = 0.4438213414245552, disc_loss = 0.038019911457712836
Trained batch 429 in epoch 4, gen_loss = 0.4437190416247346, disc_loss = 0.03793978927938571
Trained batch 430 in epoch 4, gen_loss = 0.4437937258014546, disc_loss = 0.03786228996595657
Trained batch 431 in epoch 4, gen_loss = 0.44392413466616915, disc_loss = 0.0377870156134358
Trained batch 432 in epoch 4, gen_loss = 0.4438973509687199, disc_loss = 0.037708057878930425
Trained batch 433 in epoch 4, gen_loss = 0.44389628958866895, disc_loss = 0.037627023746675814
Trained batch 434 in epoch 4, gen_loss = 0.44374675291708143, disc_loss = 0.037547024876821315
Trained batch 435 in epoch 4, gen_loss = 0.4437295773297275, disc_loss = 0.037470428952349165
Trained batch 436 in epoch 4, gen_loss = 0.4436561283175951, disc_loss = 0.03739605932144845
Trained batch 437 in epoch 4, gen_loss = 0.44361942713935626, disc_loss = 0.037330522237039386
Trained batch 438 in epoch 4, gen_loss = 0.4436167259965779, disc_loss = 0.03725898302115653
Trained batch 439 in epoch 4, gen_loss = 0.44375489448959177, disc_loss = 0.03719145280457187
Trained batch 440 in epoch 4, gen_loss = 0.4438952402192719, disc_loss = 0.03711329009637338
Trained batch 441 in epoch 4, gen_loss = 0.44389947453235606, disc_loss = 0.03703831716196199
Trained batch 442 in epoch 4, gen_loss = 0.4437968114697906, disc_loss = 0.03696053927873617
Trained batch 443 in epoch 4, gen_loss = 0.44381278652597117, disc_loss = 0.03690330624509066
Trained batch 444 in epoch 4, gen_loss = 0.44393426059337143, disc_loss = 0.03683310303983561
Trained batch 445 in epoch 4, gen_loss = 0.4438576570674443, disc_loss = 0.036769101305367764
Trained batch 446 in epoch 4, gen_loss = 0.4436550815766823, disc_loss = 0.03669492944281223
Trained batch 447 in epoch 4, gen_loss = 0.44351636491982, disc_loss = 0.03664154946610714
Trained batch 448 in epoch 4, gen_loss = 0.44356908962827485, disc_loss = 0.03657152443421063
Trained batch 449 in epoch 4, gen_loss = 0.44349452588293287, disc_loss = 0.03650836954358965
Trained batch 450 in epoch 4, gen_loss = 0.44344251766437437, disc_loss = 0.0364333093563867
Trained batch 451 in epoch 4, gen_loss = 0.44352480749377104, disc_loss = 0.036361624105046376
Trained batch 452 in epoch 4, gen_loss = 0.44352176397315185, disc_loss = 0.03628726097370681
Trained batch 453 in epoch 4, gen_loss = 0.443547744714216, disc_loss = 0.03621910878104293
Trained batch 454 in epoch 4, gen_loss = 0.44341621896722816, disc_loss = 0.036169661175214
Trained batch 455 in epoch 4, gen_loss = 0.44352520845438304, disc_loss = 0.03610348936962781
Trained batch 456 in epoch 4, gen_loss = 0.44353193592451334, disc_loss = 0.03603056038085869
Trained batch 457 in epoch 4, gen_loss = 0.44354898043334745, disc_loss = 0.03596338792754882
Trained batch 458 in epoch 4, gen_loss = 0.4433764756894579, disc_loss = 0.03594550491951828
Trained batch 459 in epoch 4, gen_loss = 0.4433831114483916, disc_loss = 0.03590943129763574
Trained batch 460 in epoch 4, gen_loss = 0.4433010175274665, disc_loss = 0.036044183964467326
Trained batch 461 in epoch 4, gen_loss = 0.44340689009402223, disc_loss = 0.03650944607354523
Trained batch 462 in epoch 4, gen_loss = 0.44332932833718947, disc_loss = 0.036504854433556326
Trained batch 463 in epoch 4, gen_loss = 0.4432782704203293, disc_loss = 0.03673957305075199
Trained batch 464 in epoch 4, gen_loss = 0.44343861021021364, disc_loss = 0.03796488742784707
Trained batch 465 in epoch 4, gen_loss = 0.44333657507221075, disc_loss = 0.03842777126446734
Trained batch 466 in epoch 4, gen_loss = 0.4432773801320625, disc_loss = 0.03849935430257603
Trained batch 467 in epoch 4, gen_loss = 0.44327961793567383, disc_loss = 0.038480074299622774
Trained batch 468 in epoch 4, gen_loss = 0.44308451853835507, disc_loss = 0.03858640644181051
Trained batch 469 in epoch 4, gen_loss = 0.44302014607064266, disc_loss = 0.03861314770418833
Trained batch 470 in epoch 4, gen_loss = 0.44301626212784184, disc_loss = 0.03861388327176198
Trained batch 471 in epoch 4, gen_loss = 0.4429565147828248, disc_loss = 0.03856474715551377
Trained batch 472 in epoch 4, gen_loss = 0.4430525127727436, disc_loss = 0.0385924290041646
Trained batch 473 in epoch 4, gen_loss = 0.44285361758012814, disc_loss = 0.03869016762019257
Trained batch 474 in epoch 4, gen_loss = 0.44279823842801547, disc_loss = 0.03873239242275687
Trained batch 475 in epoch 4, gen_loss = 0.44284353524196046, disc_loss = 0.0386836543251729
Trained batch 476 in epoch 4, gen_loss = 0.44273203311476317, disc_loss = 0.03870797878086364
Trained batch 477 in epoch 4, gen_loss = 0.4428585404880875, disc_loss = 0.03872216276962809
Trained batch 478 in epoch 4, gen_loss = 0.4428177384469106, disc_loss = 0.03866539662558049
Trained batch 479 in epoch 4, gen_loss = 0.4428282455851634, disc_loss = 0.03862325211084681
Trained batch 480 in epoch 4, gen_loss = 0.443049485123331, disc_loss = 0.03861098620690127
Trained batch 481 in epoch 4, gen_loss = 0.44294368781736776, disc_loss = 0.038586274604313076
Trained batch 482 in epoch 4, gen_loss = 0.44291971941665587, disc_loss = 0.03865164431538934
Trained batch 483 in epoch 4, gen_loss = 0.4429735855376425, disc_loss = 0.039110186051342574
Trained batch 484 in epoch 4, gen_loss = 0.4429729758464184, disc_loss = 0.03947823253056976
Trained batch 485 in epoch 4, gen_loss = 0.44323528714386035, disc_loss = 0.03965512533919357
Trained batch 486 in epoch 4, gen_loss = 0.4431499930010684, disc_loss = 0.0396051686137601
Trained batch 487 in epoch 4, gen_loss = 0.4431795231753685, disc_loss = 0.03958045937012133
Trained batch 488 in epoch 4, gen_loss = 0.4430525722801076, disc_loss = 0.03956322218024825
Trained batch 489 in epoch 4, gen_loss = 0.4429825071777616, disc_loss = 0.03953066977187611
Trained batch 490 in epoch 4, gen_loss = 0.4428542734649176, disc_loss = 0.03948804741021617
Trained batch 491 in epoch 4, gen_loss = 0.44270403319742624, disc_loss = 0.03951609468161378
Trained batch 492 in epoch 4, gen_loss = 0.4424278306912699, disc_loss = 0.03970596651002598
Trained batch 493 in epoch 4, gen_loss = 0.4424512662626954, disc_loss = 0.040200933425212165
Trained batch 494 in epoch 4, gen_loss = 0.4424043428416204, disc_loss = 0.04027499484622644
Trained batch 495 in epoch 4, gen_loss = 0.442348045927863, disc_loss = 0.04023007378911585
Trained batch 496 in epoch 4, gen_loss = 0.44241961572971383, disc_loss = 0.04022708114272197
Trained batch 497 in epoch 4, gen_loss = 0.44235345517775143, disc_loss = 0.04017401067680309
Trained batch 498 in epoch 4, gen_loss = 0.44239586042258927, disc_loss = 0.04012147588366064
Trained batch 499 in epoch 4, gen_loss = 0.4422326780557632, disc_loss = 0.040129728372674436
Trained batch 500 in epoch 4, gen_loss = 0.44230591471561653, disc_loss = 0.0402545129128373
Trained batch 501 in epoch 4, gen_loss = 0.4421762548594836, disc_loss = 0.04022287959149441
Trained batch 502 in epoch 4, gen_loss = 0.4420462476448795, disc_loss = 0.04017489079791482
Trained batch 503 in epoch 4, gen_loss = 0.4419566473908841, disc_loss = 0.04010442834826083
Trained batch 504 in epoch 4, gen_loss = 0.4418777021441129, disc_loss = 0.0400725356916353
Trained batch 505 in epoch 4, gen_loss = 0.4416920078012783, disc_loss = 0.040082637358202854
Trained batch 506 in epoch 4, gen_loss = 0.4418089309270095, disc_loss = 0.04004776152815207
Trained batch 507 in epoch 4, gen_loss = 0.4418322560707415, disc_loss = 0.04002075043725085
Trained batch 508 in epoch 4, gen_loss = 0.44189328540753287, disc_loss = 0.0399639245249836
Trained batch 509 in epoch 4, gen_loss = 0.4417947422055637, disc_loss = 0.03990568708874943
Trained batch 510 in epoch 4, gen_loss = 0.44183778249587563, disc_loss = 0.039856363127532976
Trained batch 511 in epoch 4, gen_loss = 0.4419484925456345, disc_loss = 0.039808934470329405
Trained batch 512 in epoch 4, gen_loss = 0.44214750695646854, disc_loss = 0.039744650808455274
Trained batch 513 in epoch 4, gen_loss = 0.44217792112771637, disc_loss = 0.03969197165074211
Trained batch 514 in epoch 4, gen_loss = 0.44233797643948525, disc_loss = 0.0396426037781266
Trained batch 515 in epoch 4, gen_loss = 0.44241427202788436, disc_loss = 0.03957515115111474
Trained batch 516 in epoch 4, gen_loss = 0.442457166008608, disc_loss = 0.03951046631646269
Trained batch 517 in epoch 4, gen_loss = 0.4423356041254684, disc_loss = 0.039460975316741496
Trained batch 518 in epoch 4, gen_loss = 0.44242551423221654, disc_loss = 0.039450831983600936
Trained batch 519 in epoch 4, gen_loss = 0.4423685898574499, disc_loss = 0.039389881638075726
Trained batch 520 in epoch 4, gen_loss = 0.44235872907739227, disc_loss = 0.039354836524887846
Trained batch 521 in epoch 4, gen_loss = 0.4423612058733615, disc_loss = 0.03932343922525116
Trained batch 522 in epoch 4, gen_loss = 0.4424154984107665, disc_loss = 0.03926181683297239
Trained batch 523 in epoch 4, gen_loss = 0.4424369199812867, disc_loss = 0.0391991826192874
Trained batch 524 in epoch 4, gen_loss = 0.4424781421252659, disc_loss = 0.03913478495952274
Trained batch 525 in epoch 4, gen_loss = 0.4425156947097851, disc_loss = 0.03906826307765162
Trained batch 526 in epoch 4, gen_loss = 0.44253506289487543, disc_loss = 0.039002279152358536
Trained batch 527 in epoch 4, gen_loss = 0.4425818912233367, disc_loss = 0.038953635566885525
Trained batch 528 in epoch 4, gen_loss = 0.44260878689122335, disc_loss = 0.03900927105973103
Trained batch 529 in epoch 4, gen_loss = 0.442408705151306, disc_loss = 0.039264933041402335
Trained batch 530 in epoch 4, gen_loss = 0.4424748669909892, disc_loss = 0.03922616498564105
Trained batch 531 in epoch 4, gen_loss = 0.44258685959012883, disc_loss = 0.03926221402125657
Trained batch 532 in epoch 4, gen_loss = 0.44261817055392666, disc_loss = 0.03920759642313236
Trained batch 533 in epoch 4, gen_loss = 0.4425522941216994, disc_loss = 0.03917605992561827
Trained batch 534 in epoch 4, gen_loss = 0.4424869436526967, disc_loss = 0.03911776905487701
Trained batch 535 in epoch 4, gen_loss = 0.4426500109483057, disc_loss = 0.039067944020481166
Trained batch 536 in epoch 4, gen_loss = 0.4426860946405755, disc_loss = 0.039007214711826416
Trained batch 537 in epoch 4, gen_loss = 0.4427140043792228, disc_loss = 0.03895422352562731
Trained batch 538 in epoch 4, gen_loss = 0.44261469298037176, disc_loss = 0.038934820380445455
Trained batch 539 in epoch 4, gen_loss = 0.4425420215284383, disc_loss = 0.038907036556500116
Trained batch 540 in epoch 4, gen_loss = 0.4424980146717452, disc_loss = 0.03887457787420759
Trained batch 541 in epoch 4, gen_loss = 0.4426513993322189, disc_loss = 0.038836051499027746
Trained batch 542 in epoch 4, gen_loss = 0.4426329272008513, disc_loss = 0.03878884345788721
Trained batch 543 in epoch 4, gen_loss = 0.4426832089529318, disc_loss = 0.038737380218449025
Trained batch 544 in epoch 4, gen_loss = 0.4426383978729948, disc_loss = 0.03868117247229664
Trained batch 545 in epoch 4, gen_loss = 0.4427024824169529, disc_loss = 0.038628246482110315
Trained batch 546 in epoch 4, gen_loss = 0.44281134107431064, disc_loss = 0.038582495732532585
Trained batch 547 in epoch 4, gen_loss = 0.4426711080391912, disc_loss = 0.038595569803104156
Trained batch 548 in epoch 4, gen_loss = 0.44275898007312975, disc_loss = 0.039067729005169374
Trained batch 549 in epoch 4, gen_loss = 0.4425854378938675, disc_loss = 0.039287908158942376
Trained batch 550 in epoch 4, gen_loss = 0.4425547437204856, disc_loss = 0.03925037329649712
Trained batch 551 in epoch 4, gen_loss = 0.4424759628440159, disc_loss = 0.03926117053851013
Trained batch 552 in epoch 4, gen_loss = 0.44227026437980144, disc_loss = 0.03927514434347492
Trained batch 553 in epoch 4, gen_loss = 0.4423305529980023, disc_loss = 0.03923548718734513
Trained batch 554 in epoch 4, gen_loss = 0.44227596338804775, disc_loss = 0.03921144076807609
Trained batch 555 in epoch 4, gen_loss = 0.4422158263891721, disc_loss = 0.039156486748017555
Trained batch 556 in epoch 4, gen_loss = 0.4422856928309162, disc_loss = 0.03911881356690701
Trained batch 557 in epoch 4, gen_loss = 0.44231234928826707, disc_loss = 0.039135796567475206
Trained batch 558 in epoch 4, gen_loss = 0.44235619748001237, disc_loss = 0.03931462444733222
Trained batch 559 in epoch 4, gen_loss = 0.44241660029760427, disc_loss = 0.039820952871897526
Trained batch 560 in epoch 4, gen_loss = 0.44232629321900707, disc_loss = 0.039883740763005646
Trained batch 561 in epoch 4, gen_loss = 0.44213646751069513, disc_loss = 0.039993376612374926
Trained batch 562 in epoch 4, gen_loss = 0.44230332166009434, disc_loss = 0.04028510876524313
Trained batch 563 in epoch 4, gen_loss = 0.44238569957356083, disc_loss = 0.04025429467289174
Trained batch 564 in epoch 4, gen_loss = 0.4423008273660609, disc_loss = 0.040262856372772195
Trained batch 565 in epoch 4, gen_loss = 0.4422527932867987, disc_loss = 0.04021476437428196
Trained batch 566 in epoch 4, gen_loss = 0.44231709207176534, disc_loss = 0.040170916221868344
Trained batch 567 in epoch 4, gen_loss = 0.442331744803929, disc_loss = 0.040162748665775135
Trained batch 568 in epoch 4, gen_loss = 0.44227688153305456, disc_loss = 0.040661686041551154
Trained batch 569 in epoch 4, gen_loss = 0.44226131742460684, disc_loss = 0.04096032498249163
Trained batch 570 in epoch 4, gen_loss = 0.4423095499884644, disc_loss = 0.04095153259594587
Trained batch 571 in epoch 4, gen_loss = 0.4422912276708163, disc_loss = 0.04099421831819887
Trained batch 572 in epoch 4, gen_loss = 0.44222792332917193, disc_loss = 0.04099021516748449
Trained batch 573 in epoch 4, gen_loss = 0.44227587382344835, disc_loss = 0.04099631221447374
Trained batch 574 in epoch 4, gen_loss = 0.4421808576065561, disc_loss = 0.0409690675418824
Trained batch 575 in epoch 4, gen_loss = 0.44208085050599444, disc_loss = 0.0410721474347358
Trained batch 576 in epoch 4, gen_loss = 0.4421660901665481, disc_loss = 0.04128645280613346
Trained batch 577 in epoch 4, gen_loss = 0.44217348237969883, disc_loss = 0.04122433338393248
Trained batch 578 in epoch 4, gen_loss = 0.44203205841604704, disc_loss = 0.04141987560418256
Trained batch 579 in epoch 4, gen_loss = 0.4420881107963365, disc_loss = 0.04137771693259028
Trained batch 580 in epoch 4, gen_loss = 0.4421160126204335, disc_loss = 0.04155709860940975
Trained batch 581 in epoch 4, gen_loss = 0.44191234218295905, disc_loss = 0.041741261454347096
Trained batch 582 in epoch 4, gen_loss = 0.44193277524634045, disc_loss = 0.04170753357981493
Trained batch 583 in epoch 4, gen_loss = 0.44182553244371936, disc_loss = 0.04180530085880628
Trained batch 584 in epoch 4, gen_loss = 0.44172530612374983, disc_loss = 0.04185344647878829
Trained batch 585 in epoch 4, gen_loss = 0.4416501515961344, disc_loss = 0.04185640583420331
Trained batch 586 in epoch 4, gen_loss = 0.44162219473409897, disc_loss = 0.04187863111040623
Trained batch 587 in epoch 4, gen_loss = 0.4415714134569882, disc_loss = 0.041831553475313574
Trained batch 588 in epoch 4, gen_loss = 0.4415659599373013, disc_loss = 0.04181239042938679
Trained batch 589 in epoch 4, gen_loss = 0.44153963377920247, disc_loss = 0.041805629304736476
Trained batch 590 in epoch 4, gen_loss = 0.44150428481513476, disc_loss = 0.04175976303787413
Trained batch 591 in epoch 4, gen_loss = 0.4414917403781736, disc_loss = 0.04176020329523945
Trained batch 592 in epoch 4, gen_loss = 0.44143646623794786, disc_loss = 0.04184961241582003
Trained batch 593 in epoch 4, gen_loss = 0.44142994746214614, disc_loss = 0.04184308487440613
Trained batch 594 in epoch 4, gen_loss = 0.4415962848342767, disc_loss = 0.04185520738496312
Trained batch 595 in epoch 4, gen_loss = 0.44162394841445374, disc_loss = 0.04179598871913845
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.4006286561489105, disc_loss = 0.04309527575969696
Trained batch 1 in epoch 5, gen_loss = 0.4421188533306122, disc_loss = 0.028303710743784904
Trained batch 2 in epoch 5, gen_loss = 0.4266793727874756, disc_loss = 0.020457761051754158
Trained batch 3 in epoch 5, gen_loss = 0.44276009500026703, disc_loss = 0.018878075992688537
Trained batch 4 in epoch 5, gen_loss = 0.43178182244300845, disc_loss = 0.017264173179864884
Trained batch 5 in epoch 5, gen_loss = 0.4315243909756343, disc_loss = 0.01721378539999326
Trained batch 6 in epoch 5, gen_loss = 0.4441484340599605, disc_loss = 0.01637310308537313
Trained batch 7 in epoch 5, gen_loss = 0.4406431280076504, disc_loss = 0.014860696159303188
Trained batch 8 in epoch 5, gen_loss = 0.437878989511066, disc_loss = 0.018341977563169267
Trained batch 9 in epoch 5, gen_loss = 0.4457386821508408, disc_loss = 0.026515652239322663
Trained batch 10 in epoch 5, gen_loss = 0.4429970248179002, disc_loss = 0.024714884686876427
Trained batch 11 in epoch 5, gen_loss = 0.44049035757780075, disc_loss = 0.028285333498691518
Trained batch 12 in epoch 5, gen_loss = 0.44587265757414013, disc_loss = 0.026897046643380936
Trained batch 13 in epoch 5, gen_loss = 0.43934462113039835, disc_loss = 0.04369343092132892
Trained batch 14 in epoch 5, gen_loss = 0.4321005543073018, disc_loss = 0.044964136369526383
Trained batch 15 in epoch 5, gen_loss = 0.42698037438094616, disc_loss = 0.04410427616676316
Trained batch 16 in epoch 5, gen_loss = 0.42660553841029897, disc_loss = 0.04215640810263507
Trained batch 17 in epoch 5, gen_loss = 0.42959680491023594, disc_loss = 0.04044977415146099
Trained batch 18 in epoch 5, gen_loss = 0.43331728483501236, disc_loss = 0.03930092941185361
Trained batch 19 in epoch 5, gen_loss = 0.4316464334726334, disc_loss = 0.03802566677331924
Trained batch 20 in epoch 5, gen_loss = 0.4314754434994289, disc_loss = 0.03859050252607891
Trained batch 21 in epoch 5, gen_loss = 0.4313969205726277, disc_loss = 0.04705322432247075
Trained batch 22 in epoch 5, gen_loss = 0.4264326238113901, disc_loss = 0.058428145945072174
Trained batch 23 in epoch 5, gen_loss = 0.4280443452298641, disc_loss = 0.058324104795853295
Trained batch 24 in epoch 5, gen_loss = 0.42739961624145506, disc_loss = 0.05765003532171249
Trained batch 25 in epoch 5, gen_loss = 0.42501861774004424, disc_loss = 0.056252841192942396
Trained batch 26 in epoch 5, gen_loss = 0.42595154488528214, disc_loss = 0.05481848203473621
Trained batch 27 in epoch 5, gen_loss = 0.42626078001090456, disc_loss = 0.05327641611386623
Trained batch 28 in epoch 5, gen_loss = 0.42615950929707497, disc_loss = 0.05215449753249514
Trained batch 29 in epoch 5, gen_loss = 0.4233107815186183, disc_loss = 0.05103314065684875
Trained batch 30 in epoch 5, gen_loss = 0.421963018755759, disc_loss = 0.052814817897254424
Trained batch 31 in epoch 5, gen_loss = 0.4236824996769428, disc_loss = 0.05736377713037655
Trained batch 32 in epoch 5, gen_loss = 0.4222315676284559, disc_loss = 0.05582155153211771
Trained batch 33 in epoch 5, gen_loss = 0.4237588188227485, disc_loss = 0.054887351648443765
Trained batch 34 in epoch 5, gen_loss = 0.4237466548170362, disc_loss = 0.05378039182562913
Trained batch 35 in epoch 5, gen_loss = 0.4228074947992961, disc_loss = 0.05279723193962127
Trained batch 36 in epoch 5, gen_loss = 0.4234048466424684, disc_loss = 0.05159082549397607
Trained batch 37 in epoch 5, gen_loss = 0.4254169119031806, disc_loss = 0.05116954773027254
Trained batch 38 in epoch 5, gen_loss = 0.4241975423617241, disc_loss = 0.05346036734632575
Trained batch 39 in epoch 5, gen_loss = 0.4270166590809822, disc_loss = 0.05627633867552504
Trained batch 40 in epoch 5, gen_loss = 0.42914303773786966, disc_loss = 0.05512941809280253
Trained batch 41 in epoch 5, gen_loss = 0.42816354476270224, disc_loss = 0.05444909799622283
Trained batch 42 in epoch 5, gen_loss = 0.4277499630007633, disc_loss = 0.05338808997036066
Trained batch 43 in epoch 5, gen_loss = 0.42865597388961096, disc_loss = 0.052894487881778994
Trained batch 44 in epoch 5, gen_loss = 0.42913019723362394, disc_loss = 0.05282150133409434
Trained batch 45 in epoch 5, gen_loss = 0.4306878052327944, disc_loss = 0.05332257006438854
Trained batch 46 in epoch 5, gen_loss = 0.4311813420437752, disc_loss = 0.05315087552360715
Trained batch 47 in epoch 5, gen_loss = 0.4316539180775483, disc_loss = 0.05229470125050284
Trained batch 48 in epoch 5, gen_loss = 0.43137504373277935, disc_loss = 0.05282500940279997
Trained batch 49 in epoch 5, gen_loss = 0.4318221694231033, disc_loss = 0.052202807022258636
Trained batch 50 in epoch 5, gen_loss = 0.43174664530099605, disc_loss = 0.05157005986856187
Trained batch 51 in epoch 5, gen_loss = 0.4313121713124789, disc_loss = 0.05172457448385943
Trained batch 52 in epoch 5, gen_loss = 0.4320216072055529, disc_loss = 0.05255965399116559
Trained batch 53 in epoch 5, gen_loss = 0.4330270003389429, disc_loss = 0.05174953779378147
Trained batch 54 in epoch 5, gen_loss = 0.4324414632537148, disc_loss = 0.05109433083879677
Trained batch 55 in epoch 5, gen_loss = 0.43128906350050655, disc_loss = 0.051998573080969175
Trained batch 56 in epoch 5, gen_loss = 0.430889194994642, disc_loss = 0.05125071712066991
Trained batch 57 in epoch 5, gen_loss = 0.432039773155903, disc_loss = 0.050734840389662264
Trained batch 58 in epoch 5, gen_loss = 0.4321048951755136, disc_loss = 0.04998699492790689
Trained batch 59 in epoch 5, gen_loss = 0.43172285755475365, disc_loss = 0.049245884416935344
Trained batch 60 in epoch 5, gen_loss = 0.4314648328257389, disc_loss = 0.04858203484966862
Trained batch 61 in epoch 5, gen_loss = 0.43153695377611345, disc_loss = 0.04798918574177209
Trained batch 62 in epoch 5, gen_loss = 0.4318550938651675, disc_loss = 0.047367741656859245
Trained batch 63 in epoch 5, gen_loss = 0.4328617970459163, disc_loss = 0.04676255405502161
Trained batch 64 in epoch 5, gen_loss = 0.4332274661614345, disc_loss = 0.04622063925489783
Trained batch 65 in epoch 5, gen_loss = 0.4328208633444526, disc_loss = 0.04560289167178174
Trained batch 66 in epoch 5, gen_loss = 0.43126853677763866, disc_loss = 0.04501499325982226
Trained batch 67 in epoch 5, gen_loss = 0.4305768893922077, disc_loss = 0.04488516446915181
Trained batch 68 in epoch 5, gen_loss = 0.43081564013508783, disc_loss = 0.0464139641330078
Trained batch 69 in epoch 5, gen_loss = 0.42906406819820403, disc_loss = 0.0474159347292568
Trained batch 70 in epoch 5, gen_loss = 0.42898165382130043, disc_loss = 0.04693928351756972
Trained batch 71 in epoch 5, gen_loss = 0.42919499509864384, disc_loss = 0.046487162432943784
Trained batch 72 in epoch 5, gen_loss = 0.42900574288956106, disc_loss = 0.045963667129000574
Trained batch 73 in epoch 5, gen_loss = 0.42894369323511383, disc_loss = 0.045458431607364
Trained batch 74 in epoch 5, gen_loss = 0.42784348686536156, disc_loss = 0.04492582139869531
Trained batch 75 in epoch 5, gen_loss = 0.4272360484066762, disc_loss = 0.04446195644375525
Trained batch 76 in epoch 5, gen_loss = 0.4281832417110344, disc_loss = 0.04396784431966288
Trained batch 77 in epoch 5, gen_loss = 0.4283697681549268, disc_loss = 0.04353602706359174
Trained batch 78 in epoch 5, gen_loss = 0.42949597141410734, disc_loss = 0.043075252913787394
Trained batch 79 in epoch 5, gen_loss = 0.4296839840710163, disc_loss = 0.042609617265407
Trained batch 80 in epoch 5, gen_loss = 0.42895285803594707, disc_loss = 0.04215693792880133
Trained batch 81 in epoch 5, gen_loss = 0.4283586827720084, disc_loss = 0.041684235102587903
Trained batch 82 in epoch 5, gen_loss = 0.4282576635659459, disc_loss = 0.04131404600801866
Trained batch 83 in epoch 5, gen_loss = 0.42888505153712775, disc_loss = 0.04085915493557141
Trained batch 84 in epoch 5, gen_loss = 0.4283560370697695, disc_loss = 0.04042484473765773
Trained batch 85 in epoch 5, gen_loss = 0.4274946198213932, disc_loss = 0.04005799064044516
Trained batch 86 in epoch 5, gen_loss = 0.42780952823573143, disc_loss = 0.03963284664412682
Trained batch 87 in epoch 5, gen_loss = 0.42760633338581433, disc_loss = 0.03924080971310931
Trained batch 88 in epoch 5, gen_loss = 0.4272176164589571, disc_loss = 0.03887367930807424
Trained batch 89 in epoch 5, gen_loss = 0.4275075882673264, disc_loss = 0.038487106732403235
Trained batch 90 in epoch 5, gen_loss = 0.4270328044236361, disc_loss = 0.0381247361579521
Trained batch 91 in epoch 5, gen_loss = 0.42703966278096905, disc_loss = 0.037756035453639925
Trained batch 92 in epoch 5, gen_loss = 0.4264814046121413, disc_loss = 0.03740131883551517
Trained batch 93 in epoch 5, gen_loss = 0.42658018875629344, disc_loss = 0.03703104453953974
Trained batch 94 in epoch 5, gen_loss = 0.42640600455434696, disc_loss = 0.036667132522224595
Trained batch 95 in epoch 5, gen_loss = 0.42614781204611063, disc_loss = 0.03631209285958903
Trained batch 96 in epoch 5, gen_loss = 0.42505814457677077, disc_loss = 0.03596217692445618
Trained batch 97 in epoch 5, gen_loss = 0.4256927413599832, disc_loss = 0.035633075084271174
Trained batch 98 in epoch 5, gen_loss = 0.42589787040093935, disc_loss = 0.035320405015778364
Trained batch 99 in epoch 5, gen_loss = 0.42579337775707243, disc_loss = 0.03499838979681954
Trained batch 100 in epoch 5, gen_loss = 0.42540302636599775, disc_loss = 0.034682250666976125
Trained batch 101 in epoch 5, gen_loss = 0.4260074446598689, disc_loss = 0.034363939132377064
Trained batch 102 in epoch 5, gen_loss = 0.42608666246377147, disc_loss = 0.03406172849970318
Trained batch 103 in epoch 5, gen_loss = 0.42537659148757273, disc_loss = 0.0337694821086748
Trained batch 104 in epoch 5, gen_loss = 0.42480692210651577, disc_loss = 0.033475486546133956
Trained batch 105 in epoch 5, gen_loss = 0.4247609447195845, disc_loss = 0.033187666470799945
Trained batch 106 in epoch 5, gen_loss = 0.4247664756306978, disc_loss = 0.032943835579920734
Trained batch 107 in epoch 5, gen_loss = 0.4248175000150998, disc_loss = 0.0326782750004592
Trained batch 108 in epoch 5, gen_loss = 0.4252398191788875, disc_loss = 0.032402896420568775
Trained batch 109 in epoch 5, gen_loss = 0.42507398345253683, disc_loss = 0.032140851367942314
Trained batch 110 in epoch 5, gen_loss = 0.4254675628365697, disc_loss = 0.03189098151182538
Trained batch 111 in epoch 5, gen_loss = 0.4257324103798185, disc_loss = 0.03164683996666489
Trained batch 112 in epoch 5, gen_loss = 0.4255298228390449, disc_loss = 0.031393917893529334
Trained batch 113 in epoch 5, gen_loss = 0.4260459435090684, disc_loss = 0.03117654179917289
Trained batch 114 in epoch 5, gen_loss = 0.4265302349691806, disc_loss = 0.030971777825818763
Trained batch 115 in epoch 5, gen_loss = 0.42621706554601935, disc_loss = 0.03073547801388235
Trained batch 116 in epoch 5, gen_loss = 0.42583693474785894, disc_loss = 0.030496145001588724
Trained batch 117 in epoch 5, gen_loss = 0.4256908514742124, disc_loss = 0.030257556137581496
Trained batch 118 in epoch 5, gen_loss = 0.4262877650120679, disc_loss = 0.030027467203756965
Trained batch 119 in epoch 5, gen_loss = 0.4264455161988735, disc_loss = 0.02979784582469923
Trained batch 120 in epoch 5, gen_loss = 0.42639224194298103, disc_loss = 0.029587874510363977
Trained batch 121 in epoch 5, gen_loss = 0.4268809723072365, disc_loss = 0.029368251085006555
Trained batch 122 in epoch 5, gen_loss = 0.4268334052427028, disc_loss = 0.02915096166165076
Trained batch 123 in epoch 5, gen_loss = 0.4269148529537262, disc_loss = 0.028939439109601683
Trained batch 124 in epoch 5, gen_loss = 0.4275506911277771, disc_loss = 0.028728562012314798
Trained batch 125 in epoch 5, gen_loss = 0.42814511486462187, disc_loss = 0.028525507048008932
Trained batch 126 in epoch 5, gen_loss = 0.42794111840368254, disc_loss = 0.028319215801669153
Trained batch 127 in epoch 5, gen_loss = 0.42812007083557546, disc_loss = 0.028130733637226513
Trained batch 128 in epoch 5, gen_loss = 0.42818473984104716, disc_loss = 0.027925176109194524
Trained batch 129 in epoch 5, gen_loss = 0.42798371360852167, disc_loss = 0.027747491002082826
Trained batch 130 in epoch 5, gen_loss = 0.4279131948492909, disc_loss = 0.027552355294122952
Trained batch 131 in epoch 5, gen_loss = 0.42741208523511887, disc_loss = 0.027362416643000237
Trained batch 132 in epoch 5, gen_loss = 0.42743336616602157, disc_loss = 0.027170383376664574
Trained batch 133 in epoch 5, gen_loss = 0.42733675708521657, disc_loss = 0.026984155423063507
Trained batch 134 in epoch 5, gen_loss = 0.42761142894073767, disc_loss = 0.02679991764361384
Trained batch 135 in epoch 5, gen_loss = 0.4279353563838145, disc_loss = 0.026619393623310745
Trained batch 136 in epoch 5, gen_loss = 0.42774635553359985, disc_loss = 0.026447013464083312
Trained batch 137 in epoch 5, gen_loss = 0.4278292046940845, disc_loss = 0.026301853893581185
Trained batch 138 in epoch 5, gen_loss = 0.4276927147837852, disc_loss = 0.02612492335263452
Trained batch 139 in epoch 5, gen_loss = 0.42790727189608985, disc_loss = 0.025952747949798193
Trained batch 140 in epoch 5, gen_loss = 0.42796555541931314, disc_loss = 0.02578915798283638
Trained batch 141 in epoch 5, gen_loss = 0.4276924357867577, disc_loss = 0.02563157372511136
Trained batch 142 in epoch 5, gen_loss = 0.4277242688865928, disc_loss = 0.02548487128696398
Trained batch 143 in epoch 5, gen_loss = 0.42758650291297173, disc_loss = 0.02531978822581651
Trained batch 144 in epoch 5, gen_loss = 0.42773925107100913, disc_loss = 0.025165907443693743
Trained batch 145 in epoch 5, gen_loss = 0.4274984745130147, disc_loss = 0.02501734494381546
Trained batch 146 in epoch 5, gen_loss = 0.4277216471782347, disc_loss = 0.02486652950677058
Trained batch 147 in epoch 5, gen_loss = 0.42797553499002716, disc_loss = 0.024713618815341662
Trained batch 148 in epoch 5, gen_loss = 0.4279341197653905, disc_loss = 0.024561867895286107
Trained batch 149 in epoch 5, gen_loss = 0.42820816655953725, disc_loss = 0.024418781425338237
Trained batch 150 in epoch 5, gen_loss = 0.42807365608531117, disc_loss = 0.024267471342236543
Trained batch 151 in epoch 5, gen_loss = 0.42803337032857697, disc_loss = 0.024117605807412856
Trained batch 152 in epoch 5, gen_loss = 0.42781179714826195, disc_loss = 0.02396978215570105
Trained batch 153 in epoch 5, gen_loss = 0.4278311928758374, disc_loss = 0.023826220843868404
Trained batch 154 in epoch 5, gen_loss = 0.42775464404013847, disc_loss = 0.023684365831075176
Trained batch 155 in epoch 5, gen_loss = 0.427939803363421, disc_loss = 0.023564520142733667
Trained batch 156 in epoch 5, gen_loss = 0.4276896802483091, disc_loss = 0.023446215067509633
Trained batch 157 in epoch 5, gen_loss = 0.4277138315801379, disc_loss = 0.023319690523645544
Trained batch 158 in epoch 5, gen_loss = 0.42737371235523586, disc_loss = 0.023181694824799145
Trained batch 159 in epoch 5, gen_loss = 0.4274557579308748, disc_loss = 0.023047429761936654
Trained batch 160 in epoch 5, gen_loss = 0.4272679073840195, disc_loss = 0.0229150561033025
Trained batch 161 in epoch 5, gen_loss = 0.4274354577064514, disc_loss = 0.022789333644466774
Trained batch 162 in epoch 5, gen_loss = 0.4276566169013275, disc_loss = 0.02265954528223906
Trained batch 163 in epoch 5, gen_loss = 0.4275123135345738, disc_loss = 0.022530219721375033
Trained batch 164 in epoch 5, gen_loss = 0.4276878606189381, disc_loss = 0.022413902985863387
Trained batch 165 in epoch 5, gen_loss = 0.42776470658290816, disc_loss = 0.02230023582541687
Trained batch 166 in epoch 5, gen_loss = 0.42795668997450503, disc_loss = 0.022177175431188842
Trained batch 167 in epoch 5, gen_loss = 0.42814044565671966, disc_loss = 0.022055578747226502
Trained batch 168 in epoch 5, gen_loss = 0.428080993291189, disc_loss = 0.0219381665514738
Trained batch 169 in epoch 5, gen_loss = 0.4281097247320063, disc_loss = 0.02181870356982793
Trained batch 170 in epoch 5, gen_loss = 0.42843375289649294, disc_loss = 0.02171088941054887
Trained batch 171 in epoch 5, gen_loss = 0.42855787346529406, disc_loss = 0.021600728612907533
Trained batch 172 in epoch 5, gen_loss = 0.42876102641827796, disc_loss = 0.021485002295550153
Trained batch 173 in epoch 5, gen_loss = 0.42881904148507394, disc_loss = 0.021375309531416357
Trained batch 174 in epoch 5, gen_loss = 0.42885663628578186, disc_loss = 0.02126280115651233
Trained batch 175 in epoch 5, gen_loss = 0.4285125984725627, disc_loss = 0.021159432791385123
Trained batch 176 in epoch 5, gen_loss = 0.4283245236186658, disc_loss = 0.021046814229865533
Trained batch 177 in epoch 5, gen_loss = 0.4283900081776501, disc_loss = 0.020940620032285622
Trained batch 178 in epoch 5, gen_loss = 0.4283726138775575, disc_loss = 0.020830002998381687
Trained batch 179 in epoch 5, gen_loss = 0.42828592889838746, disc_loss = 0.02072429422987625
Trained batch 180 in epoch 5, gen_loss = 0.4282499596229574, disc_loss = 0.020634402635440394
Trained batch 181 in epoch 5, gen_loss = 0.4285699075067436, disc_loss = 0.02053118388457633
Trained batch 182 in epoch 5, gen_loss = 0.4285670320192973, disc_loss = 0.0204324992545346
Trained batch 183 in epoch 5, gen_loss = 0.4285985062951627, disc_loss = 0.02033629028174682
Trained batch 184 in epoch 5, gen_loss = 0.42828937946139156, disc_loss = 0.020234928693546837
Trained batch 185 in epoch 5, gen_loss = 0.42836664344674796, disc_loss = 0.020135618813250773
Trained batch 186 in epoch 5, gen_loss = 0.4279900841853198, disc_loss = 0.020037025294172013
Trained batch 187 in epoch 5, gen_loss = 0.42761862737701295, disc_loss = 0.019942184643909098
Trained batch 188 in epoch 5, gen_loss = 0.4276794493198395, disc_loss = 0.019847652783725786
Trained batch 189 in epoch 5, gen_loss = 0.42738928277241556, disc_loss = 0.019757026674127893
Trained batch 190 in epoch 5, gen_loss = 0.4275531558154141, disc_loss = 0.01966400503751417
Trained batch 191 in epoch 5, gen_loss = 0.42753120015064877, disc_loss = 0.019574633811619908
Trained batch 192 in epoch 5, gen_loss = 0.4276900174086576, disc_loss = 0.019481291276658524
Trained batch 193 in epoch 5, gen_loss = 0.4274912806823082, disc_loss = 0.01938988407473704
Trained batch 194 in epoch 5, gen_loss = 0.42736854874170743, disc_loss = 0.01930018234400986
Trained batch 195 in epoch 5, gen_loss = 0.4273958035877773, disc_loss = 0.019209971670441483
Trained batch 196 in epoch 5, gen_loss = 0.42769385927219683, disc_loss = 0.01912176349852707
Trained batch 197 in epoch 5, gen_loss = 0.4275855260967004, disc_loss = 0.019036385418866018
Trained batch 198 in epoch 5, gen_loss = 0.42760143043407844, disc_loss = 0.018947912051328387
Trained batch 199 in epoch 5, gen_loss = 0.42735160380601883, disc_loss = 0.018860269549768417
Trained batch 200 in epoch 5, gen_loss = 0.42739607045306494, disc_loss = 0.018774254507019153
Trained batch 201 in epoch 5, gen_loss = 0.42727302486943725, disc_loss = 0.018696038428196074
Trained batch 202 in epoch 5, gen_loss = 0.4270634611545525, disc_loss = 0.018613390581512575
Trained batch 203 in epoch 5, gen_loss = 0.42695962900624557, disc_loss = 0.018530036378126846
Trained batch 204 in epoch 5, gen_loss = 0.4271348607249376, disc_loss = 0.018457467727385823
Trained batch 205 in epoch 5, gen_loss = 0.42725936808053727, disc_loss = 0.018375602266547785
Trained batch 206 in epoch 5, gen_loss = 0.4272109570998501, disc_loss = 0.01829381437425542
Trained batch 207 in epoch 5, gen_loss = 0.427383990958333, disc_loss = 0.01821409441506078
Trained batch 208 in epoch 5, gen_loss = 0.42752782408700607, disc_loss = 0.018135646480117795
Trained batch 209 in epoch 5, gen_loss = 0.42723227682567777, disc_loss = 0.018060601244880153
Trained batch 210 in epoch 5, gen_loss = 0.4271369014306091, disc_loss = 0.01798235423481136
Trained batch 211 in epoch 5, gen_loss = 0.42707601723805916, disc_loss = 0.017906933416116034
Trained batch 212 in epoch 5, gen_loss = 0.42712705445961213, disc_loss = 0.017830802662792165
Trained batch 213 in epoch 5, gen_loss = 0.4272055891908218, disc_loss = 0.01775608967204152
Trained batch 214 in epoch 5, gen_loss = 0.4271232298640318, disc_loss = 0.01768025901374342
Trained batch 215 in epoch 5, gen_loss = 0.42745388340618873, disc_loss = 0.017612639920790336
Trained batch 216 in epoch 5, gen_loss = 0.4274600784075425, disc_loss = 0.017539149426537552
Trained batch 217 in epoch 5, gen_loss = 0.427560239620165, disc_loss = 0.01746653563956038
Trained batch 218 in epoch 5, gen_loss = 0.4276472867623856, disc_loss = 0.01739606595562014
Trained batch 219 in epoch 5, gen_loss = 0.42768047181042756, disc_loss = 0.017323575487402692
Trained batch 220 in epoch 5, gen_loss = 0.4276082504928382, disc_loss = 0.017258313197929125
Trained batch 221 in epoch 5, gen_loss = 0.42757198187682005, disc_loss = 0.01719045125552126
Trained batch 222 in epoch 5, gen_loss = 0.4274439480272644, disc_loss = 0.017119833258306398
Trained batch 223 in epoch 5, gen_loss = 0.42735452071896624, disc_loss = 0.01705517211926885
Trained batch 224 in epoch 5, gen_loss = 0.4274354063140021, disc_loss = 0.016985160627195406
Trained batch 225 in epoch 5, gen_loss = 0.42766917674942356, disc_loss = 0.016922418153288453
Trained batch 226 in epoch 5, gen_loss = 0.42740845653979265, disc_loss = 0.016861247677778586
Trained batch 227 in epoch 5, gen_loss = 0.42755663604067085, disc_loss = 0.01679682081591812
Trained batch 228 in epoch 5, gen_loss = 0.42764493198373954, disc_loss = 0.016737775957947964
Trained batch 229 in epoch 5, gen_loss = 0.4272952434809312, disc_loss = 0.01668471998443989
Trained batch 230 in epoch 5, gen_loss = 0.42725648456837706, disc_loss = 0.01662504227047794
Trained batch 231 in epoch 5, gen_loss = 0.4271996082930729, disc_loss = 0.016647586068600128
Trained batch 232 in epoch 5, gen_loss = 0.42730172458124777, disc_loss = 0.016597617221216755
Trained batch 233 in epoch 5, gen_loss = 0.42739354545234615, disc_loss = 0.01661027408688544
Trained batch 234 in epoch 5, gen_loss = 0.42744894839347675, disc_loss = 0.016600125595590376
Trained batch 235 in epoch 5, gen_loss = 0.4275098825662823, disc_loss = 0.016553840157477247
Trained batch 236 in epoch 5, gen_loss = 0.42787404993415384, disc_loss = 0.016509067319738304
Trained batch 237 in epoch 5, gen_loss = 0.42799560249853535, disc_loss = 0.01645404547834456
Trained batch 238 in epoch 5, gen_loss = 0.42798579749203125, disc_loss = 0.016417977284682937
Trained batch 239 in epoch 5, gen_loss = 0.4281798300643762, disc_loss = 0.016380463196643782
Trained batch 240 in epoch 5, gen_loss = 0.4281551086061723, disc_loss = 0.016332200231297226
Trained batch 241 in epoch 5, gen_loss = 0.4285572055450156, disc_loss = 0.016292315718721723
Trained batch 242 in epoch 5, gen_loss = 0.42853575307155345, disc_loss = 0.01627998925896875
Trained batch 243 in epoch 5, gen_loss = 0.42899899111419426, disc_loss = 0.016244180019101374
Trained batch 244 in epoch 5, gen_loss = 0.42899243430215483, disc_loss = 0.01621177932390069
Trained batch 245 in epoch 5, gen_loss = 0.4291111142412434, disc_loss = 0.01617097024516225
Trained batch 246 in epoch 5, gen_loss = 0.4291322039447815, disc_loss = 0.016130736182059204
Trained batch 247 in epoch 5, gen_loss = 0.4292891753777381, disc_loss = 0.016080274113788148
Trained batch 248 in epoch 5, gen_loss = 0.42949686711093027, disc_loss = 0.016078236238398855
Trained batch 249 in epoch 5, gen_loss = 0.42944459164142607, disc_loss = 0.016047870031092315
Trained batch 250 in epoch 5, gen_loss = 0.42924560410567963, disc_loss = 0.016065810638687672
Trained batch 251 in epoch 5, gen_loss = 0.4292135245743252, disc_loss = 0.016053611965617165
Trained batch 252 in epoch 5, gen_loss = 0.42931897626092785, disc_loss = 0.01601906573600522
Trained batch 253 in epoch 5, gen_loss = 0.4295879099078066, disc_loss = 0.015975593769369193
Trained batch 254 in epoch 5, gen_loss = 0.42943599270839317, disc_loss = 0.015937703676686128
Trained batch 255 in epoch 5, gen_loss = 0.4295137773733586, disc_loss = 0.015888287202415086
Trained batch 256 in epoch 5, gen_loss = 0.42932358256573805, disc_loss = 0.015911151720700126
Trained batch 257 in epoch 5, gen_loss = 0.4295356109622837, disc_loss = 0.015961035028868895
Trained batch 258 in epoch 5, gen_loss = 0.42948335179030667, disc_loss = 0.015955503127882867
Trained batch 259 in epoch 5, gen_loss = 0.42953816262575295, disc_loss = 0.015913277886395988
Trained batch 260 in epoch 5, gen_loss = 0.4297120117821456, disc_loss = 0.015866231646520797
Trained batch 261 in epoch 5, gen_loss = 0.4296529980106208, disc_loss = 0.01585059102050576
Trained batch 262 in epoch 5, gen_loss = 0.4299889628424844, disc_loss = 0.015877402952815558
Trained batch 263 in epoch 5, gen_loss = 0.4301963191140782, disc_loss = 0.015852794988225498
Trained batch 264 in epoch 5, gen_loss = 0.4303360887293546, disc_loss = 0.015844713571867994
Trained batch 265 in epoch 5, gen_loss = 0.43047198574793966, disc_loss = 0.0158174517551346
Trained batch 266 in epoch 5, gen_loss = 0.4306535485308715, disc_loss = 0.01577642748929379
Trained batch 267 in epoch 5, gen_loss = 0.43091900390920357, disc_loss = 0.015735617158117828
Trained batch 268 in epoch 5, gen_loss = 0.4308700855115089, disc_loss = 0.015708255813955622
Trained batch 269 in epoch 5, gen_loss = 0.4309308053166778, disc_loss = 0.01572486512682021
Trained batch 270 in epoch 5, gen_loss = 0.4311656549407987, disc_loss = 0.01568406317047981
Trained batch 271 in epoch 5, gen_loss = 0.43127417137079377, disc_loss = 0.01571380326341194
Trained batch 272 in epoch 5, gen_loss = 0.43138278502247707, disc_loss = 0.01568473435660326
Trained batch 273 in epoch 5, gen_loss = 0.4316728462050431, disc_loss = 0.015775695669610925
Trained batch 274 in epoch 5, gen_loss = 0.43128073074600914, disc_loss = 0.016136002657850358
Trained batch 275 in epoch 5, gen_loss = 0.4316553472392801, disc_loss = 0.016370395234316937
Trained batch 276 in epoch 5, gen_loss = 0.43179048409530835, disc_loss = 0.01633138196847136
Trained batch 277 in epoch 5, gen_loss = 0.43158942921984966, disc_loss = 0.01630565971043966
Trained batch 278 in epoch 5, gen_loss = 0.4312988762146256, disc_loss = 0.016534991235652517
Trained batch 279 in epoch 5, gen_loss = 0.43136230898754935, disc_loss = 0.01652554757269432
Trained batch 280 in epoch 5, gen_loss = 0.4311398956062955, disc_loss = 0.01708008258170995
Trained batch 281 in epoch 5, gen_loss = 0.4308364628054572, disc_loss = 0.017058978722916243
Trained batch 282 in epoch 5, gen_loss = 0.4306398058316733, disc_loss = 0.017493685207645618
Trained batch 283 in epoch 5, gen_loss = 0.43037464144364207, disc_loss = 0.017652916558444316
Trained batch 284 in epoch 5, gen_loss = 0.43043155440113, disc_loss = 0.01810085256543141
Trained batch 285 in epoch 5, gen_loss = 0.43041265490171793, disc_loss = 0.018471381679532228
Trained batch 286 in epoch 5, gen_loss = 0.43049286113798824, disc_loss = 0.018432117273742235
Trained batch 287 in epoch 5, gen_loss = 0.4305415865447786, disc_loss = 0.018666570542538667
Trained batch 288 in epoch 5, gen_loss = 0.43043202574277833, disc_loss = 0.01876951836792359
Trained batch 289 in epoch 5, gen_loss = 0.43041826486587526, disc_loss = 0.018885725276175373
Trained batch 290 in epoch 5, gen_loss = 0.43050936202413026, disc_loss = 0.01889846874825029
Trained batch 291 in epoch 5, gen_loss = 0.4308316376927781, disc_loss = 0.019285806737384083
Trained batch 292 in epoch 5, gen_loss = 0.43068772686626317, disc_loss = 0.019393443185979114
Trained batch 293 in epoch 5, gen_loss = 0.43063827953776534, disc_loss = 0.01945226881724345
Trained batch 294 in epoch 5, gen_loss = 0.4306187741837259, disc_loss = 0.01948167902251737
Trained batch 295 in epoch 5, gen_loss = 0.4305343905816207, disc_loss = 0.019477078825238515
Trained batch 296 in epoch 5, gen_loss = 0.4304179517106978, disc_loss = 0.01944598329358543
Trained batch 297 in epoch 5, gen_loss = 0.430475803629664, disc_loss = 0.019586522140362043
Trained batch 298 in epoch 5, gen_loss = 0.4305418354013692, disc_loss = 0.02038598133688699
Trained batch 299 in epoch 5, gen_loss = 0.4305888784925143, disc_loss = 0.020397570414546255
Trained batch 300 in epoch 5, gen_loss = 0.43089540347308414, disc_loss = 0.020418932582901488
Trained batch 301 in epoch 5, gen_loss = 0.4310117927410745, disc_loss = 0.02076420164705618
Trained batch 302 in epoch 5, gen_loss = 0.43070270952218437, disc_loss = 0.0208439795141302
Trained batch 303 in epoch 5, gen_loss = 0.4303458718288886, disc_loss = 0.021064588667190708
Trained batch 304 in epoch 5, gen_loss = 0.43062555643378714, disc_loss = 0.021078655663038008
Trained batch 305 in epoch 5, gen_loss = 0.43067797619143344, disc_loss = 0.021137941508855233
Trained batch 306 in epoch 5, gen_loss = 0.43036549390333095, disc_loss = 0.02122454743427361
Trained batch 307 in epoch 5, gen_loss = 0.4303237602308199, disc_loss = 0.021219113891923123
Trained batch 308 in epoch 5, gen_loss = 0.4304224453311908, disc_loss = 0.021183096338440226
Trained batch 309 in epoch 5, gen_loss = 0.4303946553699432, disc_loss = 0.02113144443588211
Trained batch 310 in epoch 5, gen_loss = 0.43018644348601437, disc_loss = 0.021129794133201218
Trained batch 311 in epoch 5, gen_loss = 0.4301140997081231, disc_loss = 0.021131717285383135
Trained batch 312 in epoch 5, gen_loss = 0.4299661741850856, disc_loss = 0.021265619474957094
Trained batch 313 in epoch 5, gen_loss = 0.42997583215403706, disc_loss = 0.021269304602581914
Trained batch 314 in epoch 5, gen_loss = 0.43013613053730554, disc_loss = 0.021274368242094558
Trained batch 315 in epoch 5, gen_loss = 0.4299320637048045, disc_loss = 0.021271499052505256
Trained batch 316 in epoch 5, gen_loss = 0.4299144917858136, disc_loss = 0.02129362872764997
Trained batch 317 in epoch 5, gen_loss = 0.4300960057748939, disc_loss = 0.021373573153604806
Trained batch 318 in epoch 5, gen_loss = 0.4303226720389901, disc_loss = 0.02133051280208154
Trained batch 319 in epoch 5, gen_loss = 0.430276058614254, disc_loss = 0.021319770567424713
Trained batch 320 in epoch 5, gen_loss = 0.43029651862809964, disc_loss = 0.02129918128444967
Trained batch 321 in epoch 5, gen_loss = 0.43048127134394204, disc_loss = 0.021245357180260098
Trained batch 322 in epoch 5, gen_loss = 0.43062547402854306, disc_loss = 0.02122775998850275
Trained batch 323 in epoch 5, gen_loss = 0.4307599958078361, disc_loss = 0.021175584343713305
Trained batch 324 in epoch 5, gen_loss = 0.4309808388123145, disc_loss = 0.021131834229096196
Trained batch 325 in epoch 5, gen_loss = 0.43105892544509444, disc_loss = 0.021085530486989173
Trained batch 326 in epoch 5, gen_loss = 0.4309375746352228, disc_loss = 0.021033752049228308
Trained batch 327 in epoch 5, gen_loss = 0.4308456701294678, disc_loss = 0.02112374474080109
Trained batch 328 in epoch 5, gen_loss = 0.43091617520094644, disc_loss = 0.021110025118812804
Trained batch 329 in epoch 5, gen_loss = 0.4310631844130429, disc_loss = 0.021061982488556005
Trained batch 330 in epoch 5, gen_loss = 0.43112665522854854, disc_loss = 0.02100843054226957
Trained batch 331 in epoch 5, gen_loss = 0.4311419172459338, disc_loss = 0.020954411916914453
Trained batch 332 in epoch 5, gen_loss = 0.4311482070444582, disc_loss = 0.020908730396477913
Trained batch 333 in epoch 5, gen_loss = 0.4312284283652277, disc_loss = 0.020864900906673426
Trained batch 334 in epoch 5, gen_loss = 0.4312859067276343, disc_loss = 0.020815296998984222
Trained batch 335 in epoch 5, gen_loss = 0.43131139040702865, disc_loss = 0.020790265576146168
Trained batch 336 in epoch 5, gen_loss = 0.4312107660296409, disc_loss = 0.020755006201794643
Trained batch 337 in epoch 5, gen_loss = 0.43106804488325967, disc_loss = 0.020801901174970962
Trained batch 338 in epoch 5, gen_loss = 0.4310813363322818, disc_loss = 0.020811227111456294
Trained batch 339 in epoch 5, gen_loss = 0.4310896334402701, disc_loss = 0.020765381793642197
Trained batch 340 in epoch 5, gen_loss = 0.43093856225265437, disc_loss = 0.020725818360128778
Trained batch 341 in epoch 5, gen_loss = 0.4308256223710657, disc_loss = 0.020709855436709605
Trained batch 342 in epoch 5, gen_loss = 0.4308835933576867, disc_loss = 0.02066776275861487
Trained batch 343 in epoch 5, gen_loss = 0.4310280529912128, disc_loss = 0.02070160506822461
Trained batch 344 in epoch 5, gen_loss = 0.430992745489314, disc_loss = 0.02067459926677301
Trained batch 345 in epoch 5, gen_loss = 0.43105499902901623, disc_loss = 0.02063606044437704
Trained batch 346 in epoch 5, gen_loss = 0.4311106363016178, disc_loss = 0.020592236358293946
Trained batch 347 in epoch 5, gen_loss = 0.43096002747957735, disc_loss = 0.02056374038327432
Trained batch 348 in epoch 5, gen_loss = 0.43114029746342525, disc_loss = 0.020543584635782784
Trained batch 349 in epoch 5, gen_loss = 0.43128875502518244, disc_loss = 0.02056805589735242
Trained batch 350 in epoch 5, gen_loss = 0.4312497925894213, disc_loss = 0.02055815703725108
Trained batch 351 in epoch 5, gen_loss = 0.43095166684890335, disc_loss = 0.021006751645142107
Trained batch 352 in epoch 5, gen_loss = 0.43108278724019317, disc_loss = 0.021886253078790018
Trained batch 353 in epoch 5, gen_loss = 0.43096724834482547, disc_loss = 0.021930762023025713
Trained batch 354 in epoch 5, gen_loss = 0.43100163768714583, disc_loss = 0.021950275501774124
Trained batch 355 in epoch 5, gen_loss = 0.4309867893377047, disc_loss = 0.02195067189763342
Trained batch 356 in epoch 5, gen_loss = 0.4311545198204137, disc_loss = 0.022015655135112378
Trained batch 357 in epoch 5, gen_loss = 0.4312580000588348, disc_loss = 0.022056051668796855
Trained batch 358 in epoch 5, gen_loss = 0.43107424298700847, disc_loss = 0.022213724899380713
Trained batch 359 in epoch 5, gen_loss = 0.4310556609597471, disc_loss = 0.02222746484751244
Trained batch 360 in epoch 5, gen_loss = 0.4311324876431283, disc_loss = 0.022312596774082167
Trained batch 361 in epoch 5, gen_loss = 0.43097732319028337, disc_loss = 0.022378771595119175
Trained batch 362 in epoch 5, gen_loss = 0.4308853019695965, disc_loss = 0.022349851648194956
Trained batch 363 in epoch 5, gen_loss = 0.4309731628541108, disc_loss = 0.02234114470199559
Trained batch 364 in epoch 5, gen_loss = 0.43132278706929456, disc_loss = 0.022646052064693035
Trained batch 365 in epoch 5, gen_loss = 0.4311460011480936, disc_loss = 0.022899053757692193
Trained batch 366 in epoch 5, gen_loss = 0.4311366104787312, disc_loss = 0.022880536730893526
Trained batch 367 in epoch 5, gen_loss = 0.4313308629814697, disc_loss = 0.02303382093384204
Trained batch 368 in epoch 5, gen_loss = 0.4312877011331439, disc_loss = 0.023027333848337394
Trained batch 369 in epoch 5, gen_loss = 0.43118463206935576, disc_loss = 0.023377123979436285
Trained batch 370 in epoch 5, gen_loss = 0.43128326149642304, disc_loss = 0.023354191401775054
Trained batch 371 in epoch 5, gen_loss = 0.431577103993585, disc_loss = 0.024097937948799
Trained batch 372 in epoch 5, gen_loss = 0.43154660762155345, disc_loss = 0.024090428318236594
Trained batch 373 in epoch 5, gen_loss = 0.4313805150316361, disc_loss = 0.024584738152627062
Trained batch 374 in epoch 5, gen_loss = 0.4315074075857798, disc_loss = 0.024946575585442284
Trained batch 375 in epoch 5, gen_loss = 0.4315254243605949, disc_loss = 0.02512012507631493
Trained batch 376 in epoch 5, gen_loss = 0.4315864245360347, disc_loss = 0.025121810446760127
Trained batch 377 in epoch 5, gen_loss = 0.4316938120536703, disc_loss = 0.025186878765462627
Trained batch 378 in epoch 5, gen_loss = 0.4318384042987723, disc_loss = 0.025191183075109758
Trained batch 379 in epoch 5, gen_loss = 0.4319897046214656, disc_loss = 0.025222688446152268
Trained batch 380 in epoch 5, gen_loss = 0.4318198179948361, disc_loss = 0.025248599454718995
Trained batch 381 in epoch 5, gen_loss = 0.4318034595063844, disc_loss = 0.025321855890888877
Trained batch 382 in epoch 5, gen_loss = 0.43178075762081397, disc_loss = 0.02626091784915544
Trained batch 383 in epoch 5, gen_loss = 0.4317622650414705, disc_loss = 0.026758817939783814
Trained batch 384 in epoch 5, gen_loss = 0.43191285636517907, disc_loss = 0.026779835490667103
Trained batch 385 in epoch 5, gen_loss = 0.43188693779737836, disc_loss = 0.026975219329478883
Trained batch 386 in epoch 5, gen_loss = 0.4317090154002187, disc_loss = 0.027011383934613095
Trained batch 387 in epoch 5, gen_loss = 0.4314794293076722, disc_loss = 0.027096972804091696
Trained batch 388 in epoch 5, gen_loss = 0.431467649179743, disc_loss = 0.02708194737477051
Trained batch 389 in epoch 5, gen_loss = 0.43136306015344766, disc_loss = 0.027125801598259176
Trained batch 390 in epoch 5, gen_loss = 0.43115195723445826, disc_loss = 0.027571321327818078
Trained batch 391 in epoch 5, gen_loss = 0.4311200327867148, disc_loss = 0.02794882441646353
Trained batch 392 in epoch 5, gen_loss = 0.43130801674973873, disc_loss = 0.028072761247022213
Trained batch 393 in epoch 5, gen_loss = 0.4312455516478737, disc_loss = 0.028019701684695114
Trained batch 394 in epoch 5, gen_loss = 0.4310630379598352, disc_loss = 0.028156761722226593
Trained batch 395 in epoch 5, gen_loss = 0.4311938875100829, disc_loss = 0.02816779372568073
Trained batch 396 in epoch 5, gen_loss = 0.43128545556020376, disc_loss = 0.02813486765069601
Trained batch 397 in epoch 5, gen_loss = 0.43135601993481715, disc_loss = 0.028088745711097523
Trained batch 398 in epoch 5, gen_loss = 0.43147157338030057, disc_loss = 0.028047488106911846
Trained batch 399 in epoch 5, gen_loss = 0.43155101731419565, disc_loss = 0.028024862660968212
Trained batch 400 in epoch 5, gen_loss = 0.4314124845804419, disc_loss = 0.027985592930986455
Trained batch 401 in epoch 5, gen_loss = 0.4314090851231001, disc_loss = 0.02798631102795393
Trained batch 402 in epoch 5, gen_loss = 0.4313577835820153, disc_loss = 0.027964883840702955
Trained batch 403 in epoch 5, gen_loss = 0.4314399371200269, disc_loss = 0.027982842788909387
Trained batch 404 in epoch 5, gen_loss = 0.4314258649025434, disc_loss = 0.028008788873234557
Trained batch 405 in epoch 5, gen_loss = 0.4317019710987072, disc_loss = 0.02820360215852184
Trained batch 406 in epoch 5, gen_loss = 0.4315780158124919, disc_loss = 0.028876493429520263
Trained batch 407 in epoch 5, gen_loss = 0.4316812633883719, disc_loss = 0.029178071578487518
Trained batch 408 in epoch 5, gen_loss = 0.43166499907346695, disc_loss = 0.02917636622940042
Trained batch 409 in epoch 5, gen_loss = 0.4316184112938439, disc_loss = 0.02913059160516529
Trained batch 410 in epoch 5, gen_loss = 0.4317290145550331, disc_loss = 0.02910834417928808
Trained batch 411 in epoch 5, gen_loss = 0.4316829527610714, disc_loss = 0.02905661363501635
Trained batch 412 in epoch 5, gen_loss = 0.4318484142242275, disc_loss = 0.02900616420837701
Trained batch 413 in epoch 5, gen_loss = 0.4318246820554641, disc_loss = 0.02895408072863179
Trained batch 414 in epoch 5, gen_loss = 0.4318828557629183, disc_loss = 0.02890195767647665
Trained batch 415 in epoch 5, gen_loss = 0.431635502152718, disc_loss = 0.02885469706150336
Trained batch 416 in epoch 5, gen_loss = 0.4316614508914719, disc_loss = 0.02882077559305029
Trained batch 417 in epoch 5, gen_loss = 0.4316206088191585, disc_loss = 0.028759696403057113
Trained batch 418 in epoch 5, gen_loss = 0.43170728923881824, disc_loss = 0.028704648775488655
Trained batch 419 in epoch 5, gen_loss = 0.4316424715377036, disc_loss = 0.028692369314099086
Trained batch 420 in epoch 5, gen_loss = 0.4316157545018366, disc_loss = 0.028696703806689844
Trained batch 421 in epoch 5, gen_loss = 0.4314301188381927, disc_loss = 0.0288349966746446
Trained batch 422 in epoch 5, gen_loss = 0.43137166587455333, disc_loss = 0.028977170507599716
Trained batch 423 in epoch 5, gen_loss = 0.4312000686548791, disc_loss = 0.029491967249514518
Trained batch 424 in epoch 5, gen_loss = 0.43126952192362616, disc_loss = 0.03015498363823794
Trained batch 425 in epoch 5, gen_loss = 0.4312967746190622, disc_loss = 0.03013554802235487
Trained batch 426 in epoch 5, gen_loss = 0.43112042246155213, disc_loss = 0.030384210385742055
Trained batch 427 in epoch 5, gen_loss = 0.43142469770440434, disc_loss = 0.030516616034236624
Trained batch 428 in epoch 5, gen_loss = 0.43133145445710297, disc_loss = 0.030497018339292588
Trained batch 429 in epoch 5, gen_loss = 0.43125000505946404, disc_loss = 0.030484101800302175
Trained batch 430 in epoch 5, gen_loss = 0.43110123601701034, disc_loss = 0.03046539943182318
Trained batch 431 in epoch 5, gen_loss = 0.4312747983192956, disc_loss = 0.030414267430454923
Trained batch 432 in epoch 5, gen_loss = 0.4313875363137375, disc_loss = 0.030371411493011508
Trained batch 433 in epoch 5, gen_loss = 0.43139687091249473, disc_loss = 0.030364884177602674
Trained batch 434 in epoch 5, gen_loss = 0.4313808341821035, disc_loss = 0.03058061766111688
Trained batch 435 in epoch 5, gen_loss = 0.4316192580335731, disc_loss = 0.03064751077615314
Trained batch 436 in epoch 5, gen_loss = 0.43178721130303443, disc_loss = 0.03059135131283239
Trained batch 437 in epoch 5, gen_loss = 0.43176520884581354, disc_loss = 0.03053726419645944
Trained batch 438 in epoch 5, gen_loss = 0.431792775224173, disc_loss = 0.030509184889234434
Trained batch 439 in epoch 5, gen_loss = 0.4317482116547498, disc_loss = 0.03046354869491717
Trained batch 440 in epoch 5, gen_loss = 0.4317924007266557, disc_loss = 0.030453136461351886
Trained batch 441 in epoch 5, gen_loss = 0.4320049991165351, disc_loss = 0.03042521315117944
Trained batch 442 in epoch 5, gen_loss = 0.43208680438134256, disc_loss = 0.030387097578884668
Trained batch 443 in epoch 5, gen_loss = 0.4321217418119714, disc_loss = 0.03035793002502917
Trained batch 444 in epoch 5, gen_loss = 0.43210711854227474, disc_loss = 0.03035744830908442
Trained batch 445 in epoch 5, gen_loss = 0.4320865157206497, disc_loss = 0.03035441542178969
Trained batch 446 in epoch 5, gen_loss = 0.4323524750052416, disc_loss = 0.03033365625955823
Trained batch 447 in epoch 5, gen_loss = 0.43236009616936955, disc_loss = 0.030300542824729097
Trained batch 448 in epoch 5, gen_loss = 0.4323919898683085, disc_loss = 0.030270515731846984
Trained batch 449 in epoch 5, gen_loss = 0.4323259268866645, disc_loss = 0.030212348269350413
Trained batch 450 in epoch 5, gen_loss = 0.43231973230442294, disc_loss = 0.030160097178420726
Trained batch 451 in epoch 5, gen_loss = 0.43226566455796755, disc_loss = 0.030120368439351845
Trained batch 452 in epoch 5, gen_loss = 0.43232116392642983, disc_loss = 0.030185144438067035
Trained batch 453 in epoch 5, gen_loss = 0.43250098108982726, disc_loss = 0.03017069676112474
Trained batch 454 in epoch 5, gen_loss = 0.4325352886220911, disc_loss = 0.030114855946062113
Trained batch 455 in epoch 5, gen_loss = 0.43265334451407716, disc_loss = 0.030061755240782525
Trained batch 456 in epoch 5, gen_loss = 0.43278354595474394, disc_loss = 0.030020871793971494
Trained batch 457 in epoch 5, gen_loss = 0.43291049993975195, disc_loss = 0.03014996826092562
Trained batch 458 in epoch 5, gen_loss = 0.4328313012138691, disc_loss = 0.030788311926792083
Trained batch 459 in epoch 5, gen_loss = 0.43287546686504197, disc_loss = 0.030753295570257647
Trained batch 460 in epoch 5, gen_loss = 0.4331589766541686, disc_loss = 0.03083405206651667
Trained batch 461 in epoch 5, gen_loss = 0.4331695336800117, disc_loss = 0.030844014227940617
Trained batch 462 in epoch 5, gen_loss = 0.4332706223425031, disc_loss = 0.030802367256348853
Trained batch 463 in epoch 5, gen_loss = 0.4333695959428261, disc_loss = 0.030773962255023372
Trained batch 464 in epoch 5, gen_loss = 0.4334078511884136, disc_loss = 0.03072895662163094
Trained batch 465 in epoch 5, gen_loss = 0.43349039490642466, disc_loss = 0.030686747156085582
Trained batch 466 in epoch 5, gen_loss = 0.4334026834183638, disc_loss = 0.03063845455101083
Trained batch 467 in epoch 5, gen_loss = 0.43342580767268807, disc_loss = 0.030587623776663016
Trained batch 468 in epoch 5, gen_loss = 0.43331252651682284, disc_loss = 0.030543027621662135
Trained batch 469 in epoch 5, gen_loss = 0.433448074979985, disc_loss = 0.030505033536130523
Trained batch 470 in epoch 5, gen_loss = 0.43344704980809723, disc_loss = 0.03045872560452132
Trained batch 471 in epoch 5, gen_loss = 0.4335499551084082, disc_loss = 0.03050367686018482
Trained batch 472 in epoch 5, gen_loss = 0.43370411902603084, disc_loss = 0.030561638562093405
Trained batch 473 in epoch 5, gen_loss = 0.43370747541073507, disc_loss = 0.030529074299390887
Trained batch 474 in epoch 5, gen_loss = 0.43368160530140526, disc_loss = 0.030484463387463044
Trained batch 475 in epoch 5, gen_loss = 0.4337681761684538, disc_loss = 0.030446881895245078
Trained batch 476 in epoch 5, gen_loss = 0.43397740079421915, disc_loss = 0.030416223454089987
Trained batch 477 in epoch 5, gen_loss = 0.43408854648657924, disc_loss = 0.030367155393018586
Trained batch 478 in epoch 5, gen_loss = 0.43413700987750153, disc_loss = 0.030313669104325452
Trained batch 479 in epoch 5, gen_loss = 0.4339629661291838, disc_loss = 0.03030202390436898
Trained batch 480 in epoch 5, gen_loss = 0.4338913229052094, disc_loss = 0.030376035233392242
Trained batch 481 in epoch 5, gen_loss = 0.434051802049534, disc_loss = 0.03038986078371715
Trained batch 482 in epoch 5, gen_loss = 0.43416429565560005, disc_loss = 0.030343230271193258
Trained batch 483 in epoch 5, gen_loss = 0.434146789726147, disc_loss = 0.03029770760201418
Trained batch 484 in epoch 5, gen_loss = 0.4342579155853114, disc_loss = 0.030245289483261245
Trained batch 485 in epoch 5, gen_loss = 0.43418418711105, disc_loss = 0.030191413941553606
Trained batch 486 in epoch 5, gen_loss = 0.43409765794781446, disc_loss = 0.030141675531399462
Trained batch 487 in epoch 5, gen_loss = 0.4340696811798166, disc_loss = 0.03010264418272065
Trained batch 488 in epoch 5, gen_loss = 0.4342656631045546, disc_loss = 0.03006063367631515
Trained batch 489 in epoch 5, gen_loss = 0.4342648875348422, disc_loss = 0.030021200521269394
Trained batch 490 in epoch 5, gen_loss = 0.4342301497027248, disc_loss = 0.02998729752563509
Trained batch 491 in epoch 5, gen_loss = 0.43424297705656145, disc_loss = 0.02994058359479645
Trained batch 492 in epoch 5, gen_loss = 0.4344876105717665, disc_loss = 0.03001806419083006
Trained batch 493 in epoch 5, gen_loss = 0.43441370690641135, disc_loss = 0.03020102301021465
Trained batch 494 in epoch 5, gen_loss = 0.4346023177257692, disc_loss = 0.030318089020720713
Trained batch 495 in epoch 5, gen_loss = 0.43470600133220993, disc_loss = 0.030269510710974327
Trained batch 496 in epoch 5, gen_loss = 0.43468401027877085, disc_loss = 0.0302822940490514
Trained batch 497 in epoch 5, gen_loss = 0.4347342504674651, disc_loss = 0.03023392919579102
Trained batch 498 in epoch 5, gen_loss = 0.43478508320504533, disc_loss = 0.030196173049608442
Trained batch 499 in epoch 5, gen_loss = 0.4348255562782288, disc_loss = 0.030153221206972374
Trained batch 500 in epoch 5, gen_loss = 0.43471363514007444, disc_loss = 0.030270718635030152
Trained batch 501 in epoch 5, gen_loss = 0.4349160499544258, disc_loss = 0.03078467299650605
Trained batch 502 in epoch 5, gen_loss = 0.43496418579909246, disc_loss = 0.030988196094583344
Trained batch 503 in epoch 5, gen_loss = 0.43502153278816313, disc_loss = 0.030972523934675367
Trained batch 504 in epoch 5, gen_loss = 0.4348369328692408, disc_loss = 0.031050413369551524
Trained batch 505 in epoch 5, gen_loss = 0.4349593510151852, disc_loss = 0.031042915310852393
Trained batch 506 in epoch 5, gen_loss = 0.43493893577972575, disc_loss = 0.031229330401516774
Trained batch 507 in epoch 5, gen_loss = 0.4350807856269709, disc_loss = 0.031578566895763015
Trained batch 508 in epoch 5, gen_loss = 0.43508953137107353, disc_loss = 0.03155974757812793
Trained batch 509 in epoch 5, gen_loss = 0.43481794356131087, disc_loss = 0.031669962006465845
Trained batch 510 in epoch 5, gen_loss = 0.43476528938269193, disc_loss = 0.03234436496597425
Trained batch 511 in epoch 5, gen_loss = 0.43460804416099563, disc_loss = 0.03321963142138884
Trained batch 512 in epoch 5, gen_loss = 0.43453393978217425, disc_loss = 0.033450762933931635
Trained batch 513 in epoch 5, gen_loss = 0.43453878262859374, disc_loss = 0.03346869224299231
Trained batch 514 in epoch 5, gen_loss = 0.4345816457155839, disc_loss = 0.033499192173628914
Trained batch 515 in epoch 5, gen_loss = 0.4343678574691447, disc_loss = 0.03352421821955079
Trained batch 516 in epoch 5, gen_loss = 0.43443076909164857, disc_loss = 0.03350869796983717
Trained batch 517 in epoch 5, gen_loss = 0.43457774921503767, disc_loss = 0.033455164966660705
Trained batch 518 in epoch 5, gen_loss = 0.43450903743218366, disc_loss = 0.033406965764955415
Trained batch 519 in epoch 5, gen_loss = 0.4344228298045122, disc_loss = 0.03337521668402657
Trained batch 520 in epoch 5, gen_loss = 0.43434153471478115, disc_loss = 0.0334343598396276
Trained batch 521 in epoch 5, gen_loss = 0.43431747913132224, disc_loss = 0.033406106805316464
Trained batch 522 in epoch 5, gen_loss = 0.43440028198818403, disc_loss = 0.033388125477136106
Trained batch 523 in epoch 5, gen_loss = 0.4342396855354309, disc_loss = 0.033416547794970296
Trained batch 524 in epoch 5, gen_loss = 0.434268707207271, disc_loss = 0.033374330181672816
Trained batch 525 in epoch 5, gen_loss = 0.43416233139799576, disc_loss = 0.033381598474176336
Trained batch 526 in epoch 5, gen_loss = 0.4342781623129148, disc_loss = 0.03334100083231509
Trained batch 527 in epoch 5, gen_loss = 0.4343735973040263, disc_loss = 0.03334909932582929
Trained batch 528 in epoch 5, gen_loss = 0.43447340379815924, disc_loss = 0.033312784201757796
Trained batch 529 in epoch 5, gen_loss = 0.43460115419243867, disc_loss = 0.0332725710852757
Trained batch 530 in epoch 5, gen_loss = 0.4347032777782663, disc_loss = 0.03322504706555371
Trained batch 531 in epoch 5, gen_loss = 0.4347765472038348, disc_loss = 0.03316912256357176
Trained batch 532 in epoch 5, gen_loss = 0.43464507679778236, disc_loss = 0.03313274065484284
Trained batch 533 in epoch 5, gen_loss = 0.4345871015880885, disc_loss = 0.03309809197501667
Trained batch 534 in epoch 5, gen_loss = 0.4346187956422289, disc_loss = 0.033056278563557175
Trained batch 535 in epoch 5, gen_loss = 0.43470645456838963, disc_loss = 0.033009855313193566
Trained batch 536 in epoch 5, gen_loss = 0.43480313462474046, disc_loss = 0.03298000287584565
Trained batch 537 in epoch 5, gen_loss = 0.434930306661971, disc_loss = 0.03297847928674061
Trained batch 538 in epoch 5, gen_loss = 0.4349833575936107, disc_loss = 0.03293977388079712
Trained batch 539 in epoch 5, gen_loss = 0.43489471265563256, disc_loss = 0.0330850825733419
Trained batch 540 in epoch 5, gen_loss = 0.435154419950108, disc_loss = 0.03338591910596565
Trained batch 541 in epoch 5, gen_loss = 0.43510081407328816, disc_loss = 0.033360677487964355
Trained batch 542 in epoch 5, gen_loss = 0.43507644824999253, disc_loss = 0.03337314747755019
Trained batch 543 in epoch 5, gen_loss = 0.4351129470502629, disc_loss = 0.03332735084854101
Trained batch 544 in epoch 5, gen_loss = 0.4350689030568534, disc_loss = 0.033279595237199665
Trained batch 545 in epoch 5, gen_loss = 0.4350529894396499, disc_loss = 0.03324186101392928
Trained batch 546 in epoch 5, gen_loss = 0.4350975184161659, disc_loss = 0.033213599789521604
Trained batch 547 in epoch 5, gen_loss = 0.43509596564473896, disc_loss = 0.0331823649923708
Trained batch 548 in epoch 5, gen_loss = 0.43500823602216054, disc_loss = 0.0333229462161935
Trained batch 549 in epoch 5, gen_loss = 0.4350488868626681, disc_loss = 0.03361138322327117
Trained batch 550 in epoch 5, gen_loss = 0.4351169250621553, disc_loss = 0.03365685520528861
Trained batch 551 in epoch 5, gen_loss = 0.43496185460168385, disc_loss = 0.03365267382827554
Trained batch 552 in epoch 5, gen_loss = 0.4349389080005356, disc_loss = 0.03363161240885401
Trained batch 553 in epoch 5, gen_loss = 0.43513137010675906, disc_loss = 0.03361209517446538
Trained batch 554 in epoch 5, gen_loss = 0.43510816113368883, disc_loss = 0.033579692639083274
Trained batch 555 in epoch 5, gen_loss = 0.4350955590820141, disc_loss = 0.03384225334986381
Trained batch 556 in epoch 5, gen_loss = 0.4349106031752574, disc_loss = 0.03427157840500059
Trained batch 557 in epoch 5, gen_loss = 0.4349512997814404, disc_loss = 0.03424526219140224
Trained batch 558 in epoch 5, gen_loss = 0.43499393603882763, disc_loss = 0.034299457857463585
Trained batch 559 in epoch 5, gen_loss = 0.4348160784159388, disc_loss = 0.03445906944626975
Trained batch 560 in epoch 5, gen_loss = 0.43474508861806943, disc_loss = 0.034775365026353956
Trained batch 561 in epoch 5, gen_loss = 0.43472432077355233, disc_loss = 0.03474498125397206
Trained batch 562 in epoch 5, gen_loss = 0.4347316520569803, disc_loss = 0.03474642392136256
Trained batch 563 in epoch 5, gen_loss = 0.4348080058364158, disc_loss = 0.034718239126959816
Trained batch 564 in epoch 5, gen_loss = 0.43469408692511835, disc_loss = 0.0346776377016151
Trained batch 565 in epoch 5, gen_loss = 0.4345698043861996, disc_loss = 0.034724127794344424
Trained batch 566 in epoch 5, gen_loss = 0.4346793290273643, disc_loss = 0.034811865522138566
Trained batch 567 in epoch 5, gen_loss = 0.4346464019740971, disc_loss = 0.03481796377647543
Trained batch 568 in epoch 5, gen_loss = 0.43457569896860576, disc_loss = 0.034778286457619906
Trained batch 569 in epoch 5, gen_loss = 0.4345099614377607, disc_loss = 0.03474102762891306
Trained batch 570 in epoch 5, gen_loss = 0.434723208434945, disc_loss = 0.03481575392774631
Trained batch 571 in epoch 5, gen_loss = 0.4347490006601894, disc_loss = 0.034799527626206216
Trained batch 572 in epoch 5, gen_loss = 0.4346722300452088, disc_loss = 0.03477276074208391
Trained batch 573 in epoch 5, gen_loss = 0.4347276755118619, disc_loss = 0.03478461869230546
Trained batch 574 in epoch 5, gen_loss = 0.4348518104138582, disc_loss = 0.0349903992128194
Trained batch 575 in epoch 5, gen_loss = 0.43467644658974475, disc_loss = 0.03507440736919105
Trained batch 576 in epoch 5, gen_loss = 0.43476746488278617, disc_loss = 0.03502921260384104
Trained batch 577 in epoch 5, gen_loss = 0.4347112647492993, disc_loss = 0.034984528420816875
Trained batch 578 in epoch 5, gen_loss = 0.434746754241525, disc_loss = 0.03493993396091473
Trained batch 579 in epoch 5, gen_loss = 0.4346584198289904, disc_loss = 0.03491851495727415
Trained batch 580 in epoch 5, gen_loss = 0.4347094052219555, disc_loss = 0.034901606518712706
Trained batch 581 in epoch 5, gen_loss = 0.4348251270674348, disc_loss = 0.034967667804238836
Trained batch 582 in epoch 5, gen_loss = 0.4347167301852748, disc_loss = 0.03507842897979852
Trained batch 583 in epoch 5, gen_loss = 0.434734878219562, disc_loss = 0.035038687025829955
Trained batch 584 in epoch 5, gen_loss = 0.4348079449091202, disc_loss = 0.03499076301649882
Trained batch 585 in epoch 5, gen_loss = 0.43493275919058216, disc_loss = 0.03496371737125873
Trained batch 586 in epoch 5, gen_loss = 0.4349123334458171, disc_loss = 0.03495383928224501
Trained batch 587 in epoch 5, gen_loss = 0.43473330129976984, disc_loss = 0.03506235079384459
Trained batch 588 in epoch 5, gen_loss = 0.4345600057032801, disc_loss = 0.03544979655568872
Trained batch 589 in epoch 5, gen_loss = 0.4346692887908321, disc_loss = 0.03551982626559655
Trained batch 590 in epoch 5, gen_loss = 0.43476345257710686, disc_loss = 0.035498323819013834
Trained batch 591 in epoch 5, gen_loss = 0.4347929749637842, disc_loss = 0.03546071540728696
Trained batch 592 in epoch 5, gen_loss = 0.4347753517744312, disc_loss = 0.0354290267699563
Trained batch 593 in epoch 5, gen_loss = 0.43480666664112294, disc_loss = 0.035413208560467785
Trained batch 594 in epoch 5, gen_loss = 0.4349175989627838, disc_loss = 0.0353662525423012
Trained batch 595 in epoch 5, gen_loss = 0.434916661439726, disc_loss = 0.03534594604346258
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.4232988655567169, disc_loss = 0.006434448529034853
Trained batch 1 in epoch 6, gen_loss = 0.4242255389690399, disc_loss = 0.014876573579385877
Trained batch 2 in epoch 6, gen_loss = 0.4108413755893707, disc_loss = 0.012214347099264463
Trained batch 3 in epoch 6, gen_loss = 0.40462107211351395, disc_loss = 0.012038076762109995
Trained batch 4 in epoch 6, gen_loss = 0.4062775731086731, disc_loss = 0.01475510187447071
Trained batch 5 in epoch 6, gen_loss = 0.4130728542804718, disc_loss = 0.014803722811241945
Trained batch 6 in epoch 6, gen_loss = 0.4140787890979222, disc_loss = 0.015931430937988416
Trained batch 7 in epoch 6, gen_loss = 0.4161408320069313, disc_loss = 0.01668098452500999
Trained batch 8 in epoch 6, gen_loss = 0.4201343191994561, disc_loss = 0.019917927061518032
Trained batch 9 in epoch 6, gen_loss = 0.42230849862098696, disc_loss = 0.018903956562280656
Trained batch 10 in epoch 6, gen_loss = 0.42695323445580224, disc_loss = 0.017955253493379463
Trained batch 11 in epoch 6, gen_loss = 0.43143226206302643, disc_loss = 0.017382081986094516
Trained batch 12 in epoch 6, gen_loss = 0.43385080190805286, disc_loss = 0.01643360284372018
Trained batch 13 in epoch 6, gen_loss = 0.4372248649597168, disc_loss = 0.015907558812094585
Trained batch 14 in epoch 6, gen_loss = 0.4385083874066671, disc_loss = 0.015917000236610572
Trained batch 15 in epoch 6, gen_loss = 0.4395124949514866, disc_loss = 0.01577098068082705
Trained batch 16 in epoch 6, gen_loss = 0.4368579685688019, disc_loss = 0.021866113440517115
Trained batch 17 in epoch 6, gen_loss = 0.4417356865273582, disc_loss = 0.04283503572353058
Trained batch 18 in epoch 6, gen_loss = 0.44215159824019984, disc_loss = 0.042435763746892154
Trained batch 19 in epoch 6, gen_loss = 0.4393727362155914, disc_loss = 0.04350336533971131
Trained batch 20 in epoch 6, gen_loss = 0.4369241481735593, disc_loss = 0.042028657027653286
Trained batch 21 in epoch 6, gen_loss = 0.4368563782085072, disc_loss = 0.04086234640668739
Trained batch 22 in epoch 6, gen_loss = 0.4378861137058424, disc_loss = 0.039444244507214295
Trained batch 23 in epoch 6, gen_loss = 0.43415752549966175, disc_loss = 0.03860631864517927
Trained batch 24 in epoch 6, gen_loss = 0.4321939611434937, disc_loss = 0.037861309796571735
Trained batch 25 in epoch 6, gen_loss = 0.43121549028616685, disc_loss = 0.04029409343806597
Trained batch 26 in epoch 6, gen_loss = 0.42808273765775895, disc_loss = 0.053119955101498854
Trained batch 27 in epoch 6, gen_loss = 0.4295618938548224, disc_loss = 0.054580681425120146
Trained batch 28 in epoch 6, gen_loss = 0.4328911653880415, disc_loss = 0.0543390666616374
Trained batch 29 in epoch 6, gen_loss = 0.43231277068456014, disc_loss = 0.05402398345371087
Trained batch 30 in epoch 6, gen_loss = 0.43244467435344575, disc_loss = 0.053004966628166936
Trained batch 31 in epoch 6, gen_loss = 0.43497104197740555, disc_loss = 0.052788641885854304
Trained batch 32 in epoch 6, gen_loss = 0.4338675078117486, disc_loss = 0.052155834030021324
Trained batch 33 in epoch 6, gen_loss = 0.4326392543666503, disc_loss = 0.055134199340553844
Trained batch 34 in epoch 6, gen_loss = 0.43114690695490154, disc_loss = 0.05744336141007287
Trained batch 35 in epoch 6, gen_loss = 0.43189076003101134, disc_loss = 0.056091892584744424
Trained batch 36 in epoch 6, gen_loss = 0.431690915210827, disc_loss = 0.05587320266341841
Trained batch 37 in epoch 6, gen_loss = 0.43100494146347046, disc_loss = 0.05692829951447876
Trained batch 38 in epoch 6, gen_loss = 0.42994995147753984, disc_loss = 0.056521390445339374
Trained batch 39 in epoch 6, gen_loss = 0.4303653821349144, disc_loss = 0.0564083821605891
Trained batch 40 in epoch 6, gen_loss = 0.4292420803046808, disc_loss = 0.05649509694336391
Trained batch 41 in epoch 6, gen_loss = 0.4317452183791569, disc_loss = 0.05573652493989184
Trained batch 42 in epoch 6, gen_loss = 0.43165378237879554, disc_loss = 0.05501369023045828
Trained batch 43 in epoch 6, gen_loss = 0.43337789990685205, disc_loss = 0.05411199027333747
Trained batch 44 in epoch 6, gen_loss = 0.4336131824387444, disc_loss = 0.05417100576062997
Trained batch 45 in epoch 6, gen_loss = 0.43120908801970276, disc_loss = 0.05687867870311374
Trained batch 46 in epoch 6, gen_loss = 0.43119195484100503, disc_loss = 0.05629079313354289
Trained batch 47 in epoch 6, gen_loss = 0.43387402407824993, disc_loss = 0.05654388635108868
Trained batch 48 in epoch 6, gen_loss = 0.43333371500579676, disc_loss = 0.05575622112623283
Trained batch 49 in epoch 6, gen_loss = 0.4344086158275604, disc_loss = 0.05495184136554599
Trained batch 50 in epoch 6, gen_loss = 0.43315423645225226, disc_loss = 0.05446311121112576
Trained batch 51 in epoch 6, gen_loss = 0.4343097966450911, disc_loss = 0.05557777780967836
Trained batch 52 in epoch 6, gen_loss = 0.4331932798871454, disc_loss = 0.05835459555305962
Trained batch 53 in epoch 6, gen_loss = 0.432615394393603, disc_loss = 0.06443756727363777
Trained batch 54 in epoch 6, gen_loss = 0.43385267853736875, disc_loss = 0.06400260496884584
Trained batch 55 in epoch 6, gen_loss = 0.4329452770096915, disc_loss = 0.06364116889225054
Trained batch 56 in epoch 6, gen_loss = 0.4324088399870354, disc_loss = 0.06279218234448579
Trained batch 57 in epoch 6, gen_loss = 0.43271482812947243, disc_loss = 0.06198726290965389
Trained batch 58 in epoch 6, gen_loss = 0.431791878352731, disc_loss = 0.061231883258511456
Trained batch 59 in epoch 6, gen_loss = 0.43111231674750644, disc_loss = 0.060847345103199287
Trained batch 60 in epoch 6, gen_loss = 0.43042794553959957, disc_loss = 0.060094442691837176
Trained batch 61 in epoch 6, gen_loss = 0.4315626818326212, disc_loss = 0.060565833287734176
Trained batch 62 in epoch 6, gen_loss = 0.43094024535209413, disc_loss = 0.06288334909116938
Trained batch 63 in epoch 6, gen_loss = 0.43164112512022257, disc_loss = 0.06342976661107969
Trained batch 64 in epoch 6, gen_loss = 0.43268598318099977, disc_loss = 0.06277250110243375
Trained batch 65 in epoch 6, gen_loss = 0.4327498665361693, disc_loss = 0.061970375958039906
Trained batch 66 in epoch 6, gen_loss = 0.4326672006898852, disc_loss = 0.061251026995257654
Trained batch 67 in epoch 6, gen_loss = 0.4315661700332866, disc_loss = 0.06050812826930162
Trained batch 68 in epoch 6, gen_loss = 0.4313096896461818, disc_loss = 0.059780240733770355
Trained batch 69 in epoch 6, gen_loss = 0.4299940288066864, disc_loss = 0.05909660658133881
Trained batch 70 in epoch 6, gen_loss = 0.4300502291027929, disc_loss = 0.05853351381358127
Trained batch 71 in epoch 6, gen_loss = 0.43049557217293316, disc_loss = 0.05958210425968799
Trained batch 72 in epoch 6, gen_loss = 0.4308798905104807, disc_loss = 0.062303307096231476
Trained batch 73 in epoch 6, gen_loss = 0.42907144048729456, disc_loss = 0.06258506264940307
Trained batch 74 in epoch 6, gen_loss = 0.4279745916525523, disc_loss = 0.06281751193106175
Trained batch 75 in epoch 6, gen_loss = 0.4274282788759784, disc_loss = 0.06232561085275129
Trained batch 76 in epoch 6, gen_loss = 0.42732992265131564, disc_loss = 0.06192792635169122
Trained batch 77 in epoch 6, gen_loss = 0.4269840400188397, disc_loss = 0.06203777307214645
Trained batch 78 in epoch 6, gen_loss = 0.4269177736360816, disc_loss = 0.062008518183344526
Trained batch 79 in epoch 6, gen_loss = 0.4266792755573988, disc_loss = 0.06161817873362452
Trained batch 80 in epoch 6, gen_loss = 0.42773743948818727, disc_loss = 0.06182344342915364
Trained batch 81 in epoch 6, gen_loss = 0.42695819531998985, disc_loss = 0.06223645408796828
Trained batch 82 in epoch 6, gen_loss = 0.42645463024277286, disc_loss = 0.06156272356993103
Trained batch 83 in epoch 6, gen_loss = 0.4267433988196509, disc_loss = 0.06109145125152454
Trained batch 84 in epoch 6, gen_loss = 0.4264655786402085, disc_loss = 0.06043900341781623
Trained batch 85 in epoch 6, gen_loss = 0.4267635723186094, disc_loss = 0.060060034641389586
Trained batch 86 in epoch 6, gen_loss = 0.4277237115920275, disc_loss = 0.059985936999363804
Trained batch 87 in epoch 6, gen_loss = 0.42810034548694437, disc_loss = 0.06036056580805135
Trained batch 88 in epoch 6, gen_loss = 0.4287000847666451, disc_loss = 0.06092182574584411
Trained batch 89 in epoch 6, gen_loss = 0.42810365392102134, disc_loss = 0.06056663704932564
Trained batch 90 in epoch 6, gen_loss = 0.42718152914728436, disc_loss = 0.06024597728993375
Trained batch 91 in epoch 6, gen_loss = 0.4273050041950267, disc_loss = 0.06027772217361337
Trained batch 92 in epoch 6, gen_loss = 0.42810442402798643, disc_loss = 0.059817041966423234
Trained batch 93 in epoch 6, gen_loss = 0.42884815785479036, disc_loss = 0.05936188215607817
Trained batch 94 in epoch 6, gen_loss = 0.42941317683772035, disc_loss = 0.05888374945344894
Trained batch 95 in epoch 6, gen_loss = 0.42952758135894936, disc_loss = 0.058738185398397036
Trained batch 96 in epoch 6, gen_loss = 0.43013793076436546, disc_loss = 0.05831382092875764
Trained batch 97 in epoch 6, gen_loss = 0.43076867230084476, disc_loss = 0.05801990762714068
Trained batch 98 in epoch 6, gen_loss = 0.43078069584538237, disc_loss = 0.05783721553914324
Trained batch 99 in epoch 6, gen_loss = 0.43041508764028547, disc_loss = 0.05746092674788088
Trained batch 100 in epoch 6, gen_loss = 0.43106573731592385, disc_loss = 0.05707876890953077
Trained batch 101 in epoch 6, gen_loss = 0.43060878591210233, disc_loss = 0.05684232578028505
Trained batch 102 in epoch 6, gen_loss = 0.4302493429299697, disc_loss = 0.05721312173126826
Trained batch 103 in epoch 6, gen_loss = 0.43101197108626366, disc_loss = 0.05863980695945569
Trained batch 104 in epoch 6, gen_loss = 0.4305449931394486, disc_loss = 0.05876992399405156
Trained batch 105 in epoch 6, gen_loss = 0.4313217741700838, disc_loss = 0.05830726063950866
Trained batch 106 in epoch 6, gen_loss = 0.431274384538704, disc_loss = 0.057903294072912954
Trained batch 107 in epoch 6, gen_loss = 0.4308370503562468, disc_loss = 0.0574596016107265
Trained batch 108 in epoch 6, gen_loss = 0.43071589694110624, disc_loss = 0.05744584984308399
Trained batch 109 in epoch 6, gen_loss = 0.4306672136891972, disc_loss = 0.0592535436111079
Trained batch 110 in epoch 6, gen_loss = 0.4302351681498794, disc_loss = 0.05979273857146099
Trained batch 111 in epoch 6, gen_loss = 0.4305679007832493, disc_loss = 0.05935619237217387
Trained batch 112 in epoch 6, gen_loss = 0.4302621130394725, disc_loss = 0.06021040412226478
Trained batch 113 in epoch 6, gen_loss = 0.430122244776341, disc_loss = 0.06029445349173457
Trained batch 114 in epoch 6, gen_loss = 0.42919219006662784, disc_loss = 0.06019476854201892
Trained batch 115 in epoch 6, gen_loss = 0.4286162583478566, disc_loss = 0.059932762512070095
Trained batch 116 in epoch 6, gen_loss = 0.42925167058268165, disc_loss = 0.062955819719081
Trained batch 117 in epoch 6, gen_loss = 0.42890666652533965, disc_loss = 0.0627034504905785
Trained batch 118 in epoch 6, gen_loss = 0.4285858408743594, disc_loss = 0.06294315829168723
Trained batch 119 in epoch 6, gen_loss = 0.4288951198259989, disc_loss = 0.06443818982612963
Trained batch 120 in epoch 6, gen_loss = 0.42856084561545, disc_loss = 0.06573635759601786
Trained batch 121 in epoch 6, gen_loss = 0.42832753624095293, disc_loss = 0.06590688132039714
Trained batch 122 in epoch 6, gen_loss = 0.4285614459010644, disc_loss = 0.06585878943570139
Trained batch 123 in epoch 6, gen_loss = 0.4278247918813459, disc_loss = 0.06572940090535989
Trained batch 124 in epoch 6, gen_loss = 0.4276224474906921, disc_loss = 0.06563644371554256
Trained batch 125 in epoch 6, gen_loss = 0.4276613583640447, disc_loss = 0.0658011934756937
Trained batch 126 in epoch 6, gen_loss = 0.4269865061354449, disc_loss = 0.06611666022836575
Trained batch 127 in epoch 6, gen_loss = 0.42747301678173244, disc_loss = 0.06607337139939773
Trained batch 128 in epoch 6, gen_loss = 0.42764596375384073, disc_loss = 0.06567938558309692
Trained batch 129 in epoch 6, gen_loss = 0.42772525548934937, disc_loss = 0.06529769483738794
Trained batch 130 in epoch 6, gen_loss = 0.4274550633121083, disc_loss = 0.06499014108420442
Trained batch 131 in epoch 6, gen_loss = 0.4276816632711526, disc_loss = 0.06459628704892979
Trained batch 132 in epoch 6, gen_loss = 0.4279837402185999, disc_loss = 0.06417110207651679
Trained batch 133 in epoch 6, gen_loss = 0.4275105241964112, disc_loss = 0.06381150914370012
Trained batch 134 in epoch 6, gen_loss = 0.42753316848366346, disc_loss = 0.0634352716272352
Trained batch 135 in epoch 6, gen_loss = 0.42718620642143135, disc_loss = 0.06319364572204102
Trained batch 136 in epoch 6, gen_loss = 0.4272834190922062, disc_loss = 0.06279395176369669
Trained batch 137 in epoch 6, gen_loss = 0.4275410596443259, disc_loss = 0.06282315930635061
Trained batch 138 in epoch 6, gen_loss = 0.42693716266172393, disc_loss = 0.06349011642938789
Trained batch 139 in epoch 6, gen_loss = 0.4272722623177937, disc_loss = 0.06348502522534026
Trained batch 140 in epoch 6, gen_loss = 0.4272325742751994, disc_loss = 0.0631086377010859
Trained batch 141 in epoch 6, gen_loss = 0.4274164297631089, disc_loss = 0.06273360317900882
Trained batch 142 in epoch 6, gen_loss = 0.42773549560900337, disc_loss = 0.06250584448225327
Trained batch 143 in epoch 6, gen_loss = 0.427891459936897, disc_loss = 0.06211260951628598
Trained batch 144 in epoch 6, gen_loss = 0.4280177656946511, disc_loss = 0.0617331522388448
Trained batch 145 in epoch 6, gen_loss = 0.4282271717100927, disc_loss = 0.061425904867762365
Trained batch 146 in epoch 6, gen_loss = 0.42798857968680715, disc_loss = 0.06119292274713009
Trained batch 147 in epoch 6, gen_loss = 0.4277385265843288, disc_loss = 0.06085998365793981
Trained batch 148 in epoch 6, gen_loss = 0.42783251744788764, disc_loss = 0.0605830849685875
Trained batch 149 in epoch 6, gen_loss = 0.4271403656403224, disc_loss = 0.06024865134619176
Trained batch 150 in epoch 6, gen_loss = 0.42699744429019904, disc_loss = 0.05997003539964951
Trained batch 151 in epoch 6, gen_loss = 0.4270288781508019, disc_loss = 0.060542711733815896
Trained batch 152 in epoch 6, gen_loss = 0.42751098166104234, disc_loss = 0.06217002638865238
Trained batch 153 in epoch 6, gen_loss = 0.42763477234871355, disc_loss = 0.0619167401183203
Trained batch 154 in epoch 6, gen_loss = 0.42720789563271305, disc_loss = 0.061710418186961644
Trained batch 155 in epoch 6, gen_loss = 0.4272931554378607, disc_loss = 0.06146317739815762
Trained batch 156 in epoch 6, gen_loss = 0.4275862240487603, disc_loss = 0.061146715599568975
Trained batch 157 in epoch 6, gen_loss = 0.4277814136275762, disc_loss = 0.06087972606013564
Trained batch 158 in epoch 6, gen_loss = 0.42754240343405764, disc_loss = 0.06069264408939008
Trained batch 159 in epoch 6, gen_loss = 0.4273641612380743, disc_loss = 0.06070192125916947
Trained batch 160 in epoch 6, gen_loss = 0.4272583034467993, disc_loss = 0.060826650505411146
Trained batch 161 in epoch 6, gen_loss = 0.4271933725218714, disc_loss = 0.06078500346924512
Trained batch 162 in epoch 6, gen_loss = 0.4276197181523212, disc_loss = 0.06139006552806387
Trained batch 163 in epoch 6, gen_loss = 0.42715973407030106, disc_loss = 0.061992056761504856
Trained batch 164 in epoch 6, gen_loss = 0.4273386113571398, disc_loss = 0.06200945811120398
Trained batch 165 in epoch 6, gen_loss = 0.42738892353442776, disc_loss = 0.06175991196286337
Trained batch 166 in epoch 6, gen_loss = 0.42732044751058795, disc_loss = 0.06157258785647636
Trained batch 167 in epoch 6, gen_loss = 0.4272997086601598, disc_loss = 0.061527253164621515
Trained batch 168 in epoch 6, gen_loss = 0.4275505964219923, disc_loss = 0.06126238658373966
Trained batch 169 in epoch 6, gen_loss = 0.4275979054324767, disc_loss = 0.060985786755404926
Trained batch 170 in epoch 6, gen_loss = 0.42766151389880486, disc_loss = 0.060746456145129184
Trained batch 171 in epoch 6, gen_loss = 0.4275021939430126, disc_loss = 0.06055198182341058
Trained batch 172 in epoch 6, gen_loss = 0.4275255251482043, disc_loss = 0.06029909358472924
Trained batch 173 in epoch 6, gen_loss = 0.427939143674127, disc_loss = 0.06081430879742678
Trained batch 174 in epoch 6, gen_loss = 0.4271297691549574, disc_loss = 0.06219831049708383
Trained batch 175 in epoch 6, gen_loss = 0.42717232927680016, disc_loss = 0.061910182229687714
Trained batch 176 in epoch 6, gen_loss = 0.42730779735381996, disc_loss = 0.06162776916661421
Trained batch 177 in epoch 6, gen_loss = 0.42732436268517143, disc_loss = 0.061402612593380757
Trained batch 178 in epoch 6, gen_loss = 0.42765033211787984, disc_loss = 0.06114677185005399
Trained batch 179 in epoch 6, gen_loss = 0.427826086183389, disc_loss = 0.060971766640432176
Trained batch 180 in epoch 6, gen_loss = 0.4278104970468342, disc_loss = 0.06084837012497183
Trained batch 181 in epoch 6, gen_loss = 0.42799494751207123, disc_loss = 0.06069429660123865
Trained batch 182 in epoch 6, gen_loss = 0.4279949114622314, disc_loss = 0.060517514167770826
Trained batch 183 in epoch 6, gen_loss = 0.4282792931341607, disc_loss = 0.06024242777367244
Trained batch 184 in epoch 6, gen_loss = 0.428885312821414, disc_loss = 0.060218305259036854
Trained batch 185 in epoch 6, gen_loss = 0.4290769542417219, disc_loss = 0.060261967939935546
Trained batch 186 in epoch 6, gen_loss = 0.4296341853983262, disc_loss = 0.05997667121227811
Trained batch 187 in epoch 6, gen_loss = 0.4301813872570687, disc_loss = 0.05975595409139753
Trained batch 188 in epoch 6, gen_loss = 0.43017346423769753, disc_loss = 0.05951218992205603
Trained batch 189 in epoch 6, gen_loss = 0.4303568951393429, disc_loss = 0.059220600459038424
Trained batch 190 in epoch 6, gen_loss = 0.4299837990581053, disc_loss = 0.05947063767463359
Trained batch 191 in epoch 6, gen_loss = 0.43046998139470816, disc_loss = 0.059341454041714314
Trained batch 192 in epoch 6, gen_loss = 0.4309194112688766, disc_loss = 0.05939805795018769
Trained batch 193 in epoch 6, gen_loss = 0.43102274205266816, disc_loss = 0.05913457821949011
Trained batch 194 in epoch 6, gen_loss = 0.43094884615678053, disc_loss = 0.05890313217129845
Trained batch 195 in epoch 6, gen_loss = 0.43078918618207074, disc_loss = 0.0588355092735657
Trained batch 196 in epoch 6, gen_loss = 0.4310578823392161, disc_loss = 0.05859747421478635
Trained batch 197 in epoch 6, gen_loss = 0.43095395781777124, disc_loss = 0.05835254862199001
Trained batch 198 in epoch 6, gen_loss = 0.43096334371135464, disc_loss = 0.05814354518784126
Trained batch 199 in epoch 6, gen_loss = 0.43092398554086686, disc_loss = 0.05792428720043972
Trained batch 200 in epoch 6, gen_loss = 0.4305871612396999, disc_loss = 0.05767179841398081
Trained batch 201 in epoch 6, gen_loss = 0.43029193137541855, disc_loss = 0.057460424995123605
Trained batch 202 in epoch 6, gen_loss = 0.4301515126169609, disc_loss = 0.05734855011610195
Trained batch 203 in epoch 6, gen_loss = 0.43043005977775534, disc_loss = 0.05738283582168686
Trained batch 204 in epoch 6, gen_loss = 0.43036034427038056, disc_loss = 0.05720702540356575
Trained batch 205 in epoch 6, gen_loss = 0.4304048024045611, disc_loss = 0.05702939793892494
Trained batch 206 in epoch 6, gen_loss = 0.43077622735557924, disc_loss = 0.05691399169491901
Trained batch 207 in epoch 6, gen_loss = 0.43102240906311917, disc_loss = 0.056667509564879134
Trained batch 208 in epoch 6, gen_loss = 0.4311309376972144, disc_loss = 0.05647170692949632
Trained batch 209 in epoch 6, gen_loss = 0.43139991533188593, disc_loss = 0.05625984920188785
Trained batch 210 in epoch 6, gen_loss = 0.4316306625497285, disc_loss = 0.056015108738500644
Trained batch 211 in epoch 6, gen_loss = 0.43195440634241644, disc_loss = 0.05578974878222172
Trained batch 212 in epoch 6, gen_loss = 0.4323330182984401, disc_loss = 0.05561912534190036
Trained batch 213 in epoch 6, gen_loss = 0.4324086742980458, disc_loss = 0.05557973376936584
Trained batch 214 in epoch 6, gen_loss = 0.4327650693959968, disc_loss = 0.055838491477418775
Trained batch 215 in epoch 6, gen_loss = 0.4323824553026093, disc_loss = 0.05563488431464605
Trained batch 216 in epoch 6, gen_loss = 0.43225165501168245, disc_loss = 0.05658613407580946
Trained batch 217 in epoch 6, gen_loss = 0.4327816241378084, disc_loss = 0.056963725045425906
Trained batch 218 in epoch 6, gen_loss = 0.4326343370354883, disc_loss = 0.056826601191912886
Trained batch 219 in epoch 6, gen_loss = 0.43253782188350504, disc_loss = 0.05666755399328064
Trained batch 220 in epoch 6, gen_loss = 0.4325809156463157, disc_loss = 0.05648621168762985
Trained batch 221 in epoch 6, gen_loss = 0.43242309047832145, disc_loss = 0.056287677555873585
Trained batch 222 in epoch 6, gen_loss = 0.4323762385299922, disc_loss = 0.0560831363049791
Trained batch 223 in epoch 6, gen_loss = 0.4322647067851254, disc_loss = 0.05607875520945527
Trained batch 224 in epoch 6, gen_loss = 0.4326583625210656, disc_loss = 0.05638014672117101
Trained batch 225 in epoch 6, gen_loss = 0.4322610322089322, disc_loss = 0.056950804649695624
Trained batch 226 in epoch 6, gen_loss = 0.4321700615504765, disc_loss = 0.05692215018909802
Trained batch 227 in epoch 6, gen_loss = 0.43206610347618135, disc_loss = 0.05674373080316735
Trained batch 228 in epoch 6, gen_loss = 0.43203628778978204, disc_loss = 0.056683064755621695
Trained batch 229 in epoch 6, gen_loss = 0.43199831182542053, disc_loss = 0.05697021641080146
Trained batch 230 in epoch 6, gen_loss = 0.43187958053696207, disc_loss = 0.05742393990019054
Trained batch 231 in epoch 6, gen_loss = 0.43237321438460513, disc_loss = 0.05731958195422616
Trained batch 232 in epoch 6, gen_loss = 0.4327178889078132, disc_loss = 0.057263175876963036
Trained batch 233 in epoch 6, gen_loss = 0.4326248600696906, disc_loss = 0.05706901999954612
Trained batch 234 in epoch 6, gen_loss = 0.43278200233236275, disc_loss = 0.05686888147462556
Trained batch 235 in epoch 6, gen_loss = 0.43281569483421617, disc_loss = 0.05672692369780172
Trained batch 236 in epoch 6, gen_loss = 0.43295992439306236, disc_loss = 0.05652052238347787
Trained batch 237 in epoch 6, gen_loss = 0.4327257490959488, disc_loss = 0.05631046878573086
Trained batch 238 in epoch 6, gen_loss = 0.43251298461499077, disc_loss = 0.056194471750626626
Trained batch 239 in epoch 6, gen_loss = 0.4322628166526556, disc_loss = 0.0561735880735796
Trained batch 240 in epoch 6, gen_loss = 0.43246148668878803, disc_loss = 0.055993351774267015
Trained batch 241 in epoch 6, gen_loss = 0.43250114834013065, disc_loss = 0.055998002415646085
Trained batch 242 in epoch 6, gen_loss = 0.4321466013482569, disc_loss = 0.05627053540483608
Trained batch 243 in epoch 6, gen_loss = 0.4323875487583583, disc_loss = 0.05635056510132539
Trained batch 244 in epoch 6, gen_loss = 0.4322780387742179, disc_loss = 0.05614702191812043
Trained batch 245 in epoch 6, gen_loss = 0.432116511512578, disc_loss = 0.055970704466922254
Trained batch 246 in epoch 6, gen_loss = 0.4318922110173384, disc_loss = 0.05590353373377791
Trained batch 247 in epoch 6, gen_loss = 0.43200366535494406, disc_loss = 0.05575705275705625
Trained batch 248 in epoch 6, gen_loss = 0.4320788715019762, disc_loss = 0.05556320910151285
Trained batch 249 in epoch 6, gen_loss = 0.4321826013326645, disc_loss = 0.05541897621192038
Trained batch 250 in epoch 6, gen_loss = 0.43236209897406075, disc_loss = 0.055367886539608
Trained batch 251 in epoch 6, gen_loss = 0.43256045783322955, disc_loss = 0.0551873036486555
Trained batch 252 in epoch 6, gen_loss = 0.43269125651936285, disc_loss = 0.05501287764218073
Trained batch 253 in epoch 6, gen_loss = 0.4327445950095109, disc_loss = 0.05525343783940445
Trained batch 254 in epoch 6, gen_loss = 0.4331528771157358, disc_loss = 0.0563296595716155
Trained batch 255 in epoch 6, gen_loss = 0.4330888366093859, disc_loss = 0.05612851092337223
Trained batch 256 in epoch 6, gen_loss = 0.4332523090830109, disc_loss = 0.05603574120153307
Trained batch 257 in epoch 6, gen_loss = 0.4331976589999458, disc_loss = 0.05586211592890322
Trained batch 258 in epoch 6, gen_loss = 0.4330873579132051, disc_loss = 0.05567120098145715
Trained batch 259 in epoch 6, gen_loss = 0.43306681169913364, disc_loss = 0.0555285237210158
Trained batch 260 in epoch 6, gen_loss = 0.43306034563601703, disc_loss = 0.05548277102460749
Trained batch 261 in epoch 6, gen_loss = 0.4329440434470431, disc_loss = 0.055301354691485755
Trained batch 262 in epoch 6, gen_loss = 0.4333107453335374, disc_loss = 0.055125166837324324
Trained batch 263 in epoch 6, gen_loss = 0.43321069341265794, disc_loss = 0.05497590734122434
Trained batch 264 in epoch 6, gen_loss = 0.43328644734508587, disc_loss = 0.0548023755626999
Trained batch 265 in epoch 6, gen_loss = 0.43321281066514494, disc_loss = 0.054634565646809186
Trained batch 266 in epoch 6, gen_loss = 0.43301973896526663, disc_loss = 0.05454984678946129
Trained batch 267 in epoch 6, gen_loss = 0.43317702334763397, disc_loss = 0.0544162552522273
Trained batch 268 in epoch 6, gen_loss = 0.43278002173927194, disc_loss = 0.05531710417262628
Trained batch 269 in epoch 6, gen_loss = 0.43234726930106127, disc_loss = 0.05653134924359619
Trained batch 270 in epoch 6, gen_loss = 0.43241071404126297, disc_loss = 0.05646920773781479
Trained batch 271 in epoch 6, gen_loss = 0.4323984059121679, disc_loss = 0.05648735219523694
Trained batch 272 in epoch 6, gen_loss = 0.4324187304510738, disc_loss = 0.05630986574498234
Trained batch 273 in epoch 6, gen_loss = 0.4319708919438132, disc_loss = 0.05619610985231171
Trained batch 274 in epoch 6, gen_loss = 0.4318640445579182, disc_loss = 0.05609235207296231
Trained batch 275 in epoch 6, gen_loss = 0.432051671695882, disc_loss = 0.05591462770362209
Trained batch 276 in epoch 6, gen_loss = 0.4321171770457326, disc_loss = 0.05574766020811691
Trained batch 277 in epoch 6, gen_loss = 0.4322661965442218, disc_loss = 0.05557336184370378
Trained batch 278 in epoch 6, gen_loss = 0.4320554275025604, disc_loss = 0.05543426909453927
Trained batch 279 in epoch 6, gen_loss = 0.4321108687136854, disc_loss = 0.05527361770925511
Trained batch 280 in epoch 6, gen_loss = 0.43221521642708693, disc_loss = 0.055123662481621385
Trained batch 281 in epoch 6, gen_loss = 0.4321122722211459, disc_loss = 0.05495977849395721
Trained batch 282 in epoch 6, gen_loss = 0.43226728769999934, disc_loss = 0.05481100172074281
Trained batch 283 in epoch 6, gen_loss = 0.43219944047676007, disc_loss = 0.054671216698717585
Trained batch 284 in epoch 6, gen_loss = 0.43209398252922193, disc_loss = 0.054549539515650586
Trained batch 285 in epoch 6, gen_loss = 0.4316864597213852, disc_loss = 0.054925421065605294
Trained batch 286 in epoch 6, gen_loss = 0.4319071635759666, disc_loss = 0.055731024120963514
Trained batch 287 in epoch 6, gen_loss = 0.4317777742528253, disc_loss = 0.055806507416289404
Trained batch 288 in epoch 6, gen_loss = 0.43173322555928084, disc_loss = 0.05573756597891037
Trained batch 289 in epoch 6, gen_loss = 0.4318874823636022, disc_loss = 0.05564224303314655
Trained batch 290 in epoch 6, gen_loss = 0.43190481306351336, disc_loss = 0.055620832178306434
Trained batch 291 in epoch 6, gen_loss = 0.43198409411188676, disc_loss = 0.0554950213751896
Trained batch 292 in epoch 6, gen_loss = 0.43184203763870654, disc_loss = 0.055393853083367334
Trained batch 293 in epoch 6, gen_loss = 0.43173919648540265, disc_loss = 0.05540507207117772
Trained batch 294 in epoch 6, gen_loss = 0.43198961888329457, disc_loss = 0.05598583268317378
Trained batch 295 in epoch 6, gen_loss = 0.43193887627205335, disc_loss = 0.056051776154482785
Trained batch 296 in epoch 6, gen_loss = 0.4318272121225543, disc_loss = 0.055952855584961096
Trained batch 297 in epoch 6, gen_loss = 0.4321079873198631, disc_loss = 0.05607762482898598
Trained batch 298 in epoch 6, gen_loss = 0.43191081385150004, disc_loss = 0.05619788648448511
Trained batch 299 in epoch 6, gen_loss = 0.4320591856042544, disc_loss = 0.056033461610786615
Trained batch 300 in epoch 6, gen_loss = 0.43208636863287103, disc_loss = 0.05606647100194397
Trained batch 301 in epoch 6, gen_loss = 0.43192750225398713, disc_loss = 0.05594936941614658
Trained batch 302 in epoch 6, gen_loss = 0.4318946744545852, disc_loss = 0.05586283999608934
Trained batch 303 in epoch 6, gen_loss = 0.4319870567047282, disc_loss = 0.05573022232151983
Trained batch 304 in epoch 6, gen_loss = 0.43226819224044927, disc_loss = 0.05563106372128012
Trained batch 305 in epoch 6, gen_loss = 0.43236301664043875, disc_loss = 0.05549150342091285
Trained batch 306 in epoch 6, gen_loss = 0.432320215414712, disc_loss = 0.055337920446701175
Trained batch 307 in epoch 6, gen_loss = 0.4323331553053546, disc_loss = 0.05523791522325875
Trained batch 308 in epoch 6, gen_loss = 0.43246965635941637, disc_loss = 0.055116353105922444
Trained batch 309 in epoch 6, gen_loss = 0.43250259583996187, disc_loss = 0.05503919931699432
Trained batch 310 in epoch 6, gen_loss = 0.4324275466023534, disc_loss = 0.055259006794158766
Trained batch 311 in epoch 6, gen_loss = 0.4328198723303966, disc_loss = 0.055516950853276424
Trained batch 312 in epoch 6, gen_loss = 0.4326087360184033, disc_loss = 0.0553863861437399
Trained batch 313 in epoch 6, gen_loss = 0.43240371213597095, disc_loss = 0.05533064224247103
Trained batch 314 in epoch 6, gen_loss = 0.43220142192310756, disc_loss = 0.05532569459358615
Trained batch 315 in epoch 6, gen_loss = 0.4322789760330055, disc_loss = 0.05533997788642168
Trained batch 316 in epoch 6, gen_loss = 0.4321449417797173, disc_loss = 0.055233801140711414
Trained batch 317 in epoch 6, gen_loss = 0.43224577558865335, disc_loss = 0.055113648572561784
Trained batch 318 in epoch 6, gen_loss = 0.4323608867800722, disc_loss = 0.05504926675813839
Trained batch 319 in epoch 6, gen_loss = 0.4321795332245529, disc_loss = 0.055216284292691854
Trained batch 320 in epoch 6, gen_loss = 0.43223892407625264, disc_loss = 0.05557834615675599
Trained batch 321 in epoch 6, gen_loss = 0.43226466906366884, disc_loss = 0.05579550102532419
Trained batch 322 in epoch 6, gen_loss = 0.43229010350563946, disc_loss = 0.05569646585784599
Trained batch 323 in epoch 6, gen_loss = 0.4322639089307667, disc_loss = 0.05554785266558835
Trained batch 324 in epoch 6, gen_loss = 0.4321589432312892, disc_loss = 0.05546510030873693
Trained batch 325 in epoch 6, gen_loss = 0.43220557272434235, disc_loss = 0.05546840887511023
Trained batch 326 in epoch 6, gen_loss = 0.4321485652106982, disc_loss = 0.05538515031582673
Trained batch 327 in epoch 6, gen_loss = 0.43180866993781997, disc_loss = 0.05547540015171895
Trained batch 328 in epoch 6, gen_loss = 0.43169297581385696, disc_loss = 0.05562572926707498
Trained batch 329 in epoch 6, gen_loss = 0.4314358992106987, disc_loss = 0.05587897452412907
Trained batch 330 in epoch 6, gen_loss = 0.431898037742632, disc_loss = 0.05634152662329758
Trained batch 331 in epoch 6, gen_loss = 0.43180257432072994, disc_loss = 0.05622506045584892
Trained batch 332 in epoch 6, gen_loss = 0.43175383489411157, disc_loss = 0.05618096204955612
Trained batch 333 in epoch 6, gen_loss = 0.43196596365845846, disc_loss = 0.05605293955224493
Trained batch 334 in epoch 6, gen_loss = 0.43193198522525045, disc_loss = 0.05590643469911458
Trained batch 335 in epoch 6, gen_loss = 0.4317326032157455, disc_loss = 0.055783583386246824
Trained batch 336 in epoch 6, gen_loss = 0.4318828579226304, disc_loss = 0.05577773980254678
Trained batch 337 in epoch 6, gen_loss = 0.43195569471142, disc_loss = 0.05624921656538837
Trained batch 338 in epoch 6, gen_loss = 0.4320397192398004, disc_loss = 0.05703826650021087
Trained batch 339 in epoch 6, gen_loss = 0.4319595349185607, disc_loss = 0.05715151336317992
Trained batch 340 in epoch 6, gen_loss = 0.4319961182882359, disc_loss = 0.05724039985429594
Trained batch 341 in epoch 6, gen_loss = 0.43205633132081284, disc_loss = 0.057176171526944604
Trained batch 342 in epoch 6, gen_loss = 0.4321739784830166, disc_loss = 0.057294877265028805
Trained batch 343 in epoch 6, gen_loss = 0.43248129358818366, disc_loss = 0.05746195356220787
Trained batch 344 in epoch 6, gen_loss = 0.43250421492949775, disc_loss = 0.05737738684629617
Trained batch 345 in epoch 6, gen_loss = 0.43234878933498627, disc_loss = 0.05730673020188778
Trained batch 346 in epoch 6, gen_loss = 0.4324078493743534, disc_loss = 0.057189588724858305
Trained batch 347 in epoch 6, gen_loss = 0.43240194485105315, disc_loss = 0.0570452632931136
Trained batch 348 in epoch 6, gen_loss = 0.43221193492241783, disc_loss = 0.056922346952619475
Trained batch 349 in epoch 6, gen_loss = 0.4321039972134999, disc_loss = 0.05682571647023516
Trained batch 350 in epoch 6, gen_loss = 0.4322831905805148, disc_loss = 0.056769955283736656
Trained batch 351 in epoch 6, gen_loss = 0.4323246188631112, disc_loss = 0.05668807520388244
Trained batch 352 in epoch 6, gen_loss = 0.432200105180146, disc_loss = 0.05684495081586853
Trained batch 353 in epoch 6, gen_loss = 0.4324487837526084, disc_loss = 0.057614923950737224
Trained batch 354 in epoch 6, gen_loss = 0.4325599302708263, disc_loss = 0.057493373314836914
Trained batch 355 in epoch 6, gen_loss = 0.4323996538191699, disc_loss = 0.057461707762526244
Trained batch 356 in epoch 6, gen_loss = 0.4325209699091123, disc_loss = 0.057323730666795615
Trained batch 357 in epoch 6, gen_loss = 0.4325328552523139, disc_loss = 0.057195789842767505
Trained batch 358 in epoch 6, gen_loss = 0.4325854914434109, disc_loss = 0.05705978204742655
Trained batch 359 in epoch 6, gen_loss = 0.43260576046175425, disc_loss = 0.056953991474842446
Trained batch 360 in epoch 6, gen_loss = 0.4325070485183737, disc_loss = 0.057122871260367684
Trained batch 361 in epoch 6, gen_loss = 0.43221353109699584, disc_loss = 0.057292023067779384
Trained batch 362 in epoch 6, gen_loss = 0.432261281269641, disc_loss = 0.05719069896532689
Trained batch 363 in epoch 6, gen_loss = 0.4325109011196828, disc_loss = 0.05709935717187453
Trained batch 364 in epoch 6, gen_loss = 0.4326116782345184, disc_loss = 0.05697365333645107
Trained batch 365 in epoch 6, gen_loss = 0.4324582396634941, disc_loss = 0.05687300292800481
Trained batch 366 in epoch 6, gen_loss = 0.4326462370498304, disc_loss = 0.05682594354368482
Trained batch 367 in epoch 6, gen_loss = 0.4326284932701484, disc_loss = 0.05691405977805793
Trained batch 368 in epoch 6, gen_loss = 0.432593053999309, disc_loss = 0.05682082409998225
Trained batch 369 in epoch 6, gen_loss = 0.43263778686523435, disc_loss = 0.05678628936183412
Trained batch 370 in epoch 6, gen_loss = 0.43295866684772255, disc_loss = 0.05676139113330094
Trained batch 371 in epoch 6, gen_loss = 0.4330165248404267, disc_loss = 0.056727522847703306
Trained batch 372 in epoch 6, gen_loss = 0.4331987194976602, disc_loss = 0.056593616339490414
Trained batch 373 in epoch 6, gen_loss = 0.43339043839730046, disc_loss = 0.05649497775724506
Trained batch 374 in epoch 6, gen_loss = 0.4332282915910085, disc_loss = 0.056394531869639955
Trained batch 375 in epoch 6, gen_loss = 0.4331765765363866, disc_loss = 0.05661090307229971
Trained batch 376 in epoch 6, gen_loss = 0.4330599311175966, disc_loss = 0.0574014939661743
Trained batch 377 in epoch 6, gen_loss = 0.4329803059340785, disc_loss = 0.05729675530850217
Trained batch 378 in epoch 6, gen_loss = 0.43297323419424977, disc_loss = 0.05764997592638185
Trained batch 379 in epoch 6, gen_loss = 0.43299651240047654, disc_loss = 0.05764797267528545
Trained batch 380 in epoch 6, gen_loss = 0.4329093020419123, disc_loss = 0.05766448683992732
Trained batch 381 in epoch 6, gen_loss = 0.4332382290463173, disc_loss = 0.05768729383930447
Trained batch 382 in epoch 6, gen_loss = 0.4333829037047553, disc_loss = 0.05756040382765564
Trained batch 383 in epoch 6, gen_loss = 0.4334132374109079, disc_loss = 0.05748323595010637
Trained batch 384 in epoch 6, gen_loss = 0.4333115734837272, disc_loss = 0.05752708655842519
Trained batch 385 in epoch 6, gen_loss = 0.4336818190281873, disc_loss = 0.058045326267644144
Trained batch 386 in epoch 6, gen_loss = 0.43366871570123877, disc_loss = 0.05799979837226275
Trained batch 387 in epoch 6, gen_loss = 0.43363835969843817, disc_loss = 0.05806687293146958
Trained batch 388 in epoch 6, gen_loss = 0.4337464894304545, disc_loss = 0.058149102638334345
Trained batch 389 in epoch 6, gen_loss = 0.43362387204781555, disc_loss = 0.058037117910452
Trained batch 390 in epoch 6, gen_loss = 0.4335234122508017, disc_loss = 0.0579796550769235
Trained batch 391 in epoch 6, gen_loss = 0.433489589286702, disc_loss = 0.05788650251901233
Trained batch 392 in epoch 6, gen_loss = 0.433605185674347, disc_loss = 0.05775937306133049
Trained batch 393 in epoch 6, gen_loss = 0.4338914904043759, disc_loss = 0.05763079608946585
Trained batch 394 in epoch 6, gen_loss = 0.43401533319980284, disc_loss = 0.05754629501813575
Trained batch 395 in epoch 6, gen_loss = 0.43417288265143983, disc_loss = 0.05771910971162295
Trained batch 396 in epoch 6, gen_loss = 0.4340911322186516, disc_loss = 0.05815698258972889
Trained batch 397 in epoch 6, gen_loss = 0.4342191680591909, disc_loss = 0.058043392583372155
Trained batch 398 in epoch 6, gen_loss = 0.4342931765960273, disc_loss = 0.057988851713973624
Trained batch 399 in epoch 6, gen_loss = 0.43409104868769643, disc_loss = 0.057874260430689904
Trained batch 400 in epoch 6, gen_loss = 0.4342372069632323, disc_loss = 0.05787218765975754
Trained batch 401 in epoch 6, gen_loss = 0.4341876413395156, disc_loss = 0.0580121177823204
Trained batch 402 in epoch 6, gen_loss = 0.4341480003545065, disc_loss = 0.05793355321442297
Trained batch 403 in epoch 6, gen_loss = 0.43407928936257223, disc_loss = 0.05785099868570445
Trained batch 404 in epoch 6, gen_loss = 0.4340341100722183, disc_loss = 0.05777399292284692
Trained batch 405 in epoch 6, gen_loss = 0.4341665273669905, disc_loss = 0.05779787456488301
Trained batch 406 in epoch 6, gen_loss = 0.43404934637669557, disc_loss = 0.05769894620591285
Trained batch 407 in epoch 6, gen_loss = 0.43398222838546713, disc_loss = 0.05766365678716159
Trained batch 408 in epoch 6, gen_loss = 0.4339500629960179, disc_loss = 0.05755584031425435
Trained batch 409 in epoch 6, gen_loss = 0.43388236862857166, disc_loss = 0.05744900347483231
Trained batch 410 in epoch 6, gen_loss = 0.4338241842396358, disc_loss = 0.057492387811868585
Trained batch 411 in epoch 6, gen_loss = 0.43369972944548985, disc_loss = 0.05761616156454587
Trained batch 412 in epoch 6, gen_loss = 0.43365930233682903, disc_loss = 0.057532359512193584
Trained batch 413 in epoch 6, gen_loss = 0.4337848816516895, disc_loss = 0.05742548555270701
Trained batch 414 in epoch 6, gen_loss = 0.433759412564427, disc_loss = 0.05736786912318813
Trained batch 415 in epoch 6, gen_loss = 0.4337365531290953, disc_loss = 0.057279511231732055
Trained batch 416 in epoch 6, gen_loss = 0.4338918925761033, disc_loss = 0.05743690650034651
Trained batch 417 in epoch 6, gen_loss = 0.4336492380029277, disc_loss = 0.05760713845143834
Trained batch 418 in epoch 6, gen_loss = 0.4336949061237827, disc_loss = 0.05748283961312156
Trained batch 419 in epoch 6, gen_loss = 0.43378879811082566, disc_loss = 0.057364615115026635
Trained batch 420 in epoch 6, gen_loss = 0.43387348082739496, disc_loss = 0.05727449225398962
Trained batch 421 in epoch 6, gen_loss = 0.433943103063163, disc_loss = 0.0571572949085826
Trained batch 422 in epoch 6, gen_loss = 0.4336987857841149, disc_loss = 0.05704529383539026
Trained batch 423 in epoch 6, gen_loss = 0.433710089410251, disc_loss = 0.056931441285173
Trained batch 424 in epoch 6, gen_loss = 0.4334953845949734, disc_loss = 0.05684501292950967
Trained batch 425 in epoch 6, gen_loss = 0.43347182841927795, disc_loss = 0.056744095943693264
Trained batch 426 in epoch 6, gen_loss = 0.4335457649108118, disc_loss = 0.056650074918599545
Trained batch 427 in epoch 6, gen_loss = 0.433560087093126, disc_loss = 0.056543808909150485
Trained batch 428 in epoch 6, gen_loss = 0.43361299938255254, disc_loss = 0.05646211683906458
Trained batch 429 in epoch 6, gen_loss = 0.43351823403391726, disc_loss = 0.05635730849882198
Trained batch 430 in epoch 6, gen_loss = 0.43340200144287605, disc_loss = 0.05625078140643453
Trained batch 431 in epoch 6, gen_loss = 0.4334399719481115, disc_loss = 0.05615517452005642
Trained batch 432 in epoch 6, gen_loss = 0.4332981325737599, disc_loss = 0.05608177854621452
Trained batch 433 in epoch 6, gen_loss = 0.4334139537564071, disc_loss = 0.055983619423248386
Trained batch 434 in epoch 6, gen_loss = 0.4333708180093217, disc_loss = 0.055890980069579065
Trained batch 435 in epoch 6, gen_loss = 0.4332570761032061, disc_loss = 0.05580139683277577
Trained batch 436 in epoch 6, gen_loss = 0.4333069702307747, disc_loss = 0.05571047919301542
Trained batch 437 in epoch 6, gen_loss = 0.43353125099177775, disc_loss = 0.055681556550420175
Trained batch 438 in epoch 6, gen_loss = 0.4335094858682237, disc_loss = 0.05557449939734979
Trained batch 439 in epoch 6, gen_loss = 0.4334828053685752, disc_loss = 0.055494481126185165
Trained batch 440 in epoch 6, gen_loss = 0.4334621696380261, disc_loss = 0.055482626218948505
Trained batch 441 in epoch 6, gen_loss = 0.4336508711403851, disc_loss = 0.05544044155357785
Trained batch 442 in epoch 6, gen_loss = 0.4336350018633677, disc_loss = 0.05533925801280121
Trained batch 443 in epoch 6, gen_loss = 0.43359194890604363, disc_loss = 0.0552267748705187
Trained batch 444 in epoch 6, gen_loss = 0.4335886659916867, disc_loss = 0.055120705558887026
Trained batch 445 in epoch 6, gen_loss = 0.4335752832515357, disc_loss = 0.05501978707316044
Trained batch 446 in epoch 6, gen_loss = 0.4335824928561046, disc_loss = 0.05491874073538304
Trained batch 447 in epoch 6, gen_loss = 0.4335964483075908, disc_loss = 0.05480893943812199
Trained batch 448 in epoch 6, gen_loss = 0.4336271279373254, disc_loss = 0.05469973760248392
Trained batch 449 in epoch 6, gen_loss = 0.43364185889561974, disc_loss = 0.05459357104885081
Trained batch 450 in epoch 6, gen_loss = 0.43363606295405893, disc_loss = 0.05452647535625985
Trained batch 451 in epoch 6, gen_loss = 0.43354621727382187, disc_loss = 0.05444960096393572
Trained batch 452 in epoch 6, gen_loss = 0.4335296063233685, disc_loss = 0.054352768202400696
Trained batch 453 in epoch 6, gen_loss = 0.43351029627648746, disc_loss = 0.05424856005897048
Trained batch 454 in epoch 6, gen_loss = 0.43347756980539676, disc_loss = 0.05417301684597527
Trained batch 455 in epoch 6, gen_loss = 0.43349602753133104, disc_loss = 0.05408259299522462
Trained batch 456 in epoch 6, gen_loss = 0.43350738045684095, disc_loss = 0.05400347590744006
Trained batch 457 in epoch 6, gen_loss = 0.43362037896068856, disc_loss = 0.053897897026595136
Trained batch 458 in epoch 6, gen_loss = 0.4336542493637351, disc_loss = 0.05378967621475296
Trained batch 459 in epoch 6, gen_loss = 0.4338362338750259, disc_loss = 0.05371915565742909
Trained batch 460 in epoch 6, gen_loss = 0.43386762739520784, disc_loss = 0.05361274459223524
Trained batch 461 in epoch 6, gen_loss = 0.4340284518349222, disc_loss = 0.053506959440364016
Trained batch 462 in epoch 6, gen_loss = 0.43403319670108687, disc_loss = 0.05340765404050313
Trained batch 463 in epoch 6, gen_loss = 0.43406655812828704, disc_loss = 0.05331320647082034
Trained batch 464 in epoch 6, gen_loss = 0.4340335483833026, disc_loss = 0.053214080262208176
Trained batch 465 in epoch 6, gen_loss = 0.43421097867222813, disc_loss = 0.0531255138944035
Trained batch 466 in epoch 6, gen_loss = 0.43410369032710727, disc_loss = 0.05305609442951752
Trained batch 467 in epoch 6, gen_loss = 0.4341674137573976, disc_loss = 0.05295548843952198
Trained batch 468 in epoch 6, gen_loss = 0.434229899698229, disc_loss = 0.05285876369707461
Trained batch 469 in epoch 6, gen_loss = 0.43416539639868634, disc_loss = 0.05275828012740834
Trained batch 470 in epoch 6, gen_loss = 0.43418045288185153, disc_loss = 0.052653120233995675
Trained batch 471 in epoch 6, gen_loss = 0.43418016644605134, disc_loss = 0.05257221618598185
Trained batch 472 in epoch 6, gen_loss = 0.43423748753539604, disc_loss = 0.052469310137575165
Trained batch 473 in epoch 6, gen_loss = 0.4342317719499773, disc_loss = 0.05237639965518979
Trained batch 474 in epoch 6, gen_loss = 0.4341311390148966, disc_loss = 0.05228049719853228
Trained batch 475 in epoch 6, gen_loss = 0.4342956046472077, disc_loss = 0.05218206705112683
Trained batch 476 in epoch 6, gen_loss = 0.43456877808650834, disc_loss = 0.05210791369538902
Trained batch 477 in epoch 6, gen_loss = 0.4346326012865769, disc_loss = 0.052053889051707124
Trained batch 478 in epoch 6, gen_loss = 0.43468339862554706, disc_loss = 0.05195903583110888
Trained batch 479 in epoch 6, gen_loss = 0.43469670017560325, disc_loss = 0.05200825640398155
Trained batch 480 in epoch 6, gen_loss = 0.4345820624838252, disc_loss = 0.05193223688691436
Trained batch 481 in epoch 6, gen_loss = 0.434613483142556, disc_loss = 0.0519015821169374
Trained batch 482 in epoch 6, gen_loss = 0.43464554676604816, disc_loss = 0.05181258210601906
Trained batch 483 in epoch 6, gen_loss = 0.43456870840847, disc_loss = 0.05171394582370235
Trained batch 484 in epoch 6, gen_loss = 0.4344139434627651, disc_loss = 0.05162992908177686
Trained batch 485 in epoch 6, gen_loss = 0.4343149659564956, disc_loss = 0.05157501317815541
Trained batch 486 in epoch 6, gen_loss = 0.43435912430898366, disc_loss = 0.05150493337902828
Trained batch 487 in epoch 6, gen_loss = 0.434398493317307, disc_loss = 0.05143935033969474
Trained batch 488 in epoch 6, gen_loss = 0.4342676807644421, disc_loss = 0.05142854146348933
Trained batch 489 in epoch 6, gen_loss = 0.43426399237039137, disc_loss = 0.05140901232109766
Trained batch 490 in epoch 6, gen_loss = 0.4342661766437795, disc_loss = 0.05132631504435904
Trained batch 491 in epoch 6, gen_loss = 0.43427037502207405, disc_loss = 0.05123589680921968
Trained batch 492 in epoch 6, gen_loss = 0.43415281097980835, disc_loss = 0.05117638332582255
Trained batch 493 in epoch 6, gen_loss = 0.4342770357484277, disc_loss = 0.05108617871447357
Trained batch 494 in epoch 6, gen_loss = 0.43437696153467353, disc_loss = 0.05100958808043012
Trained batch 495 in epoch 6, gen_loss = 0.4343206536986174, disc_loss = 0.05107338358638733
Trained batch 496 in epoch 6, gen_loss = 0.43454003987657713, disc_loss = 0.051712793769817085
Trained batch 497 in epoch 6, gen_loss = 0.4344515686173994, disc_loss = 0.05166609768323735
Trained batch 498 in epoch 6, gen_loss = 0.43434745975152284, disc_loss = 0.051671139124635314
Trained batch 499 in epoch 6, gen_loss = 0.43433052927255633, disc_loss = 0.051612296184059235
Trained batch 500 in epoch 6, gen_loss = 0.4344762515522049, disc_loss = 0.05161408044001879
Trained batch 501 in epoch 6, gen_loss = 0.4345076481303371, disc_loss = 0.05157658686829857
Trained batch 502 in epoch 6, gen_loss = 0.43443362518522893, disc_loss = 0.051545672345939826
Trained batch 503 in epoch 6, gen_loss = 0.43449363071057534, disc_loss = 0.051504739310263496
Trained batch 504 in epoch 6, gen_loss = 0.43446688156316776, disc_loss = 0.05146565971536433
Trained batch 505 in epoch 6, gen_loss = 0.43450739190512494, disc_loss = 0.05142049735233468
Trained batch 506 in epoch 6, gen_loss = 0.43456427179850066, disc_loss = 0.05135628817046403
Trained batch 507 in epoch 6, gen_loss = 0.4346624635101303, disc_loss = 0.05132237941486849
Trained batch 508 in epoch 6, gen_loss = 0.43450147604427075, disc_loss = 0.05149114189883566
Trained batch 509 in epoch 6, gen_loss = 0.4347290777692608, disc_loss = 0.05143406165206768
Trained batch 510 in epoch 6, gen_loss = 0.43481549527313845, disc_loss = 0.05159720497564896
Trained batch 511 in epoch 6, gen_loss = 0.4347025969764218, disc_loss = 0.05208562447432996
Trained batch 512 in epoch 6, gen_loss = 0.4346748677029712, disc_loss = 0.0522524928742181
Trained batch 513 in epoch 6, gen_loss = 0.4346258650146106, disc_loss = 0.052460853624201095
Trained batch 514 in epoch 6, gen_loss = 0.43457301640973506, disc_loss = 0.05259758834907948
Trained batch 515 in epoch 6, gen_loss = 0.43455054327961085, disc_loss = 0.05272741131114506
Trained batch 516 in epoch 6, gen_loss = 0.43437765927794364, disc_loss = 0.052802374465318984
Trained batch 517 in epoch 6, gen_loss = 0.43433881156923226, disc_loss = 0.05291840354022013
Trained batch 518 in epoch 6, gen_loss = 0.43436772435157056, disc_loss = 0.05306266673646781
Trained batch 519 in epoch 6, gen_loss = 0.4343107903232941, disc_loss = 0.05331567956197362
Trained batch 520 in epoch 6, gen_loss = 0.4343735571099792, disc_loss = 0.05336007627930256
Trained batch 521 in epoch 6, gen_loss = 0.43423099142153143, disc_loss = 0.05332182680829375
Trained batch 522 in epoch 6, gen_loss = 0.4341315073219358, disc_loss = 0.053416899144987845
Trained batch 523 in epoch 6, gen_loss = 0.4342769062473574, disc_loss = 0.05356458192540134
Trained batch 524 in epoch 6, gen_loss = 0.43430164064679827, disc_loss = 0.053504350410242166
Trained batch 525 in epoch 6, gen_loss = 0.43418990081254066, disc_loss = 0.05376631103433003
Trained batch 526 in epoch 6, gen_loss = 0.4341029412832387, disc_loss = 0.05381362490573336
Trained batch 527 in epoch 6, gen_loss = 0.4341065635283788, disc_loss = 0.05415691421005635
Trained batch 528 in epoch 6, gen_loss = 0.43412759517000843, disc_loss = 0.05455755040759048
Trained batch 529 in epoch 6, gen_loss = 0.43427082913101844, disc_loss = 0.05453018254890405
Trained batch 530 in epoch 6, gen_loss = 0.4344409828244405, disc_loss = 0.05452050200379375
Trained batch 531 in epoch 6, gen_loss = 0.43451440239087086, disc_loss = 0.05464321434194978
Trained batch 532 in epoch 6, gen_loss = 0.4345413901568801, disc_loss = 0.05458026179584271
Trained batch 533 in epoch 6, gen_loss = 0.4346248177106907, disc_loss = 0.0546356197808475
Trained batch 534 in epoch 6, gen_loss = 0.4346003539094301, disc_loss = 0.054588128930549616
Trained batch 535 in epoch 6, gen_loss = 0.4346469114187048, disc_loss = 0.0545923426280792
Trained batch 536 in epoch 6, gen_loss = 0.4346366639576811, disc_loss = 0.05487586627020613
Trained batch 537 in epoch 6, gen_loss = 0.43470864330304154, disc_loss = 0.05480812665301835
Trained batch 538 in epoch 6, gen_loss = 0.43475233894774556, disc_loss = 0.05491734609303301
Trained batch 539 in epoch 6, gen_loss = 0.4347410789794392, disc_loss = 0.054850752597795455
Trained batch 540 in epoch 6, gen_loss = 0.43480884191509533, disc_loss = 0.0548094433165102
Trained batch 541 in epoch 6, gen_loss = 0.434854663771017, disc_loss = 0.05472943923870837
Trained batch 542 in epoch 6, gen_loss = 0.43485073385756756, disc_loss = 0.05465005891454195
Trained batch 543 in epoch 6, gen_loss = 0.4348324712037164, disc_loss = 0.054563198816835856
Trained batch 544 in epoch 6, gen_loss = 0.43493009417428885, disc_loss = 0.054509264930928926
Trained batch 545 in epoch 6, gen_loss = 0.43485613041745, disc_loss = 0.054453893939473225
Trained batch 546 in epoch 6, gen_loss = 0.4346607221763792, disc_loss = 0.05450773456004505
Trained batch 547 in epoch 6, gen_loss = 0.43465787194071026, disc_loss = 0.0544439413866035
Trained batch 548 in epoch 6, gen_loss = 0.4346477844784603, disc_loss = 0.05435525459654711
Trained batch 549 in epoch 6, gen_loss = 0.43469662622971966, disc_loss = 0.05434660268735818
Trained batch 550 in epoch 6, gen_loss = 0.4347052765628171, disc_loss = 0.054265937104926
Trained batch 551 in epoch 6, gen_loss = 0.4348989149582559, disc_loss = 0.054238576078838065
Trained batch 552 in epoch 6, gen_loss = 0.43494088637893497, disc_loss = 0.054341790366961636
Trained batch 553 in epoch 6, gen_loss = 0.43503013796539514, disc_loss = 0.054311033635440584
Trained batch 554 in epoch 6, gen_loss = 0.4351701530787322, disc_loss = 0.05425818650899371
Trained batch 555 in epoch 6, gen_loss = 0.43516355661822737, disc_loss = 0.05429996945183362
Trained batch 556 in epoch 6, gen_loss = 0.4354347109901627, disc_loss = 0.05435902876587153
Trained batch 557 in epoch 6, gen_loss = 0.4354009833387149, disc_loss = 0.05433076975064346
Trained batch 558 in epoch 6, gen_loss = 0.43543625608326497, disc_loss = 0.054299957614995155
Trained batch 559 in epoch 6, gen_loss = 0.43552900164255076, disc_loss = 0.054229662305858385
Trained batch 560 in epoch 6, gen_loss = 0.4356216615640331, disc_loss = 0.05414502451124928
Trained batch 561 in epoch 6, gen_loss = 0.435618979226652, disc_loss = 0.054106456664675895
Trained batch 562 in epoch 6, gen_loss = 0.43559234106307765, disc_loss = 0.054178210524147376
Trained batch 563 in epoch 6, gen_loss = 0.43544280381067424, disc_loss = 0.05426856076488509
Trained batch 564 in epoch 6, gen_loss = 0.4354173181858738, disc_loss = 0.05426534024907886
Trained batch 565 in epoch 6, gen_loss = 0.4354581152065904, disc_loss = 0.05420211575844723
Trained batch 566 in epoch 6, gen_loss = 0.43555218338756124, disc_loss = 0.054132429641019386
Trained batch 567 in epoch 6, gen_loss = 0.4356298434062743, disc_loss = 0.054065004008753276
Trained batch 568 in epoch 6, gen_loss = 0.4357141358990661, disc_loss = 0.054030668027682624
Trained batch 569 in epoch 6, gen_loss = 0.435663932875583, disc_loss = 0.05418187343687015
Trained batch 570 in epoch 6, gen_loss = 0.4357922104319424, disc_loss = 0.054587847719151664
Trained batch 571 in epoch 6, gen_loss = 0.4357765626969871, disc_loss = 0.05451676959189801
Trained batch 572 in epoch 6, gen_loss = 0.4356846841634048, disc_loss = 0.05447772448682543
Trained batch 573 in epoch 6, gen_loss = 0.4355266647679465, disc_loss = 0.054448307376234864
Trained batch 574 in epoch 6, gen_loss = 0.4354254895189534, disc_loss = 0.0543831269617152
Trained batch 575 in epoch 6, gen_loss = 0.4354345087065465, disc_loss = 0.054488724108523456
Trained batch 576 in epoch 6, gen_loss = 0.4353177360480125, disc_loss = 0.054464451501798045
Trained batch 577 in epoch 6, gen_loss = 0.4352831466181468, disc_loss = 0.05444294044540093
Trained batch 578 in epoch 6, gen_loss = 0.4354365893184418, disc_loss = 0.054416667114676257
Trained batch 579 in epoch 6, gen_loss = 0.4353950738393027, disc_loss = 0.05436397507778722
Trained batch 580 in epoch 6, gen_loss = 0.43537754841187326, disc_loss = 0.05430667181322976
Trained batch 581 in epoch 6, gen_loss = 0.4353840052057378, disc_loss = 0.054278152435937976
Trained batch 582 in epoch 6, gen_loss = 0.4355017483541119, disc_loss = 0.05426110122249003
Trained batch 583 in epoch 6, gen_loss = 0.4355991150010122, disc_loss = 0.05424562263843118
Trained batch 584 in epoch 6, gen_loss = 0.4356019890715933, disc_loss = 0.05424711262433129
Trained batch 585 in epoch 6, gen_loss = 0.4356714950384947, disc_loss = 0.05417069505205626
Trained batch 586 in epoch 6, gen_loss = 0.4357650058131405, disc_loss = 0.05424583600270776
Trained batch 587 in epoch 6, gen_loss = 0.4356463220553333, disc_loss = 0.05435090197597117
Trained batch 588 in epoch 6, gen_loss = 0.43560692733738743, disc_loss = 0.05428253525135966
Trained batch 589 in epoch 6, gen_loss = 0.43564226349531593, disc_loss = 0.05437785951318062
Trained batch 590 in epoch 6, gen_loss = 0.4356432484491222, disc_loss = 0.05429948232524324
Trained batch 591 in epoch 6, gen_loss = 0.43558226057605165, disc_loss = 0.05466449461095475
Trained batch 592 in epoch 6, gen_loss = 0.43567900678761695, disc_loss = 0.05467604552662631
Trained batch 593 in epoch 6, gen_loss = 0.43573698647295184, disc_loss = 0.054792349358083
Trained batch 594 in epoch 6, gen_loss = 0.435510143762877, disc_loss = 0.05496030118934685
Trained batch 595 in epoch 6, gen_loss = 0.4354305775373574, disc_loss = 0.05489847464010357
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.43533748388290405, disc_loss = 0.04614150524139404
Trained batch 1 in epoch 7, gen_loss = 0.42877961695194244, disc_loss = 0.031769352965056896
Trained batch 2 in epoch 7, gen_loss = 0.43264944354693097, disc_loss = 0.05163300968706608
Trained batch 3 in epoch 7, gen_loss = 0.43551912158727646, disc_loss = 0.049691752064973116
Trained batch 4 in epoch 7, gen_loss = 0.4315694749355316, disc_loss = 0.04579095020890236
Trained batch 5 in epoch 7, gen_loss = 0.4259142180283864, disc_loss = 0.04691997977594534
Trained batch 6 in epoch 7, gen_loss = 0.429380863904953, disc_loss = 0.042351214082113335
Trained batch 7 in epoch 7, gen_loss = 0.4322686903178692, disc_loss = 0.038058012491092086
Trained batch 8 in epoch 7, gen_loss = 0.4383253686957889, disc_loss = 0.03493222159643968
Trained batch 9 in epoch 7, gen_loss = 0.4294904381036758, disc_loss = 0.03729863632470369
Trained batch 10 in epoch 7, gen_loss = 0.4240892366929488, disc_loss = 0.04464672048660842
Trained batch 11 in epoch 7, gen_loss = 0.4180302570263545, disc_loss = 0.05313354187334577
Trained batch 12 in epoch 7, gen_loss = 0.4212073775438162, disc_loss = 0.06445001825117148
Trained batch 13 in epoch 7, gen_loss = 0.424698354942458, disc_loss = 0.061501283065548966
Trained batch 14 in epoch 7, gen_loss = 0.42673017382621764, disc_loss = 0.05894625621537367
Trained batch 15 in epoch 7, gen_loss = 0.42372834868729115, disc_loss = 0.05938430444803089
Trained batch 16 in epoch 7, gen_loss = 0.4225638912004583, disc_loss = 0.05785022204851403
Trained batch 17 in epoch 7, gen_loss = 0.4215036928653717, disc_loss = 0.055504392004675336
Trained batch 18 in epoch 7, gen_loss = 0.42247765315206426, disc_loss = 0.05438680221375666
Trained batch 19 in epoch 7, gen_loss = 0.42319837808609007, disc_loss = 0.0540776951238513
Trained batch 20 in epoch 7, gen_loss = 0.41994773206256686, disc_loss = 0.060168455576612836
Trained batch 21 in epoch 7, gen_loss = 0.42166308787736023, disc_loss = 0.05970364351841537
Trained batch 22 in epoch 7, gen_loss = 0.42291236053342407, disc_loss = 0.05838217764444973
Trained batch 23 in epoch 7, gen_loss = 0.4201412710050742, disc_loss = 0.05623394898915043
Trained batch 24 in epoch 7, gen_loss = 0.4197626197338104, disc_loss = 0.05461638879030943
Trained batch 25 in epoch 7, gen_loss = 0.4176552502008585, disc_loss = 0.053837602492421865
Trained batch 26 in epoch 7, gen_loss = 0.4169318311744266, disc_loss = 0.054196617359088525
Trained batch 27 in epoch 7, gen_loss = 0.41572598261492594, disc_loss = 0.0543119982882802
Trained batch 28 in epoch 7, gen_loss = 0.4129026994622987, disc_loss = 0.05895882392109468
Trained batch 29 in epoch 7, gen_loss = 0.41671590705712636, disc_loss = 0.0727310514387985
Trained batch 30 in epoch 7, gen_loss = 0.4198961709776232, disc_loss = 0.0706992853853491
Trained batch 31 in epoch 7, gen_loss = 0.41899888310581446, disc_loss = 0.06894087040564045
Trained batch 32 in epoch 7, gen_loss = 0.4176455763253299, disc_loss = 0.06788306158374656
Trained batch 33 in epoch 7, gen_loss = 0.4163176391054602, disc_loss = 0.06637574425515007
Trained batch 34 in epoch 7, gen_loss = 0.41815848350524903, disc_loss = 0.06477958887283292
Trained batch 35 in epoch 7, gen_loss = 0.4173070929116673, disc_loss = 0.06326225097291172
Trained batch 36 in epoch 7, gen_loss = 0.4182851306489996, disc_loss = 0.06172694650956908
Trained batch 37 in epoch 7, gen_loss = 0.416487234203439, disc_loss = 0.0603342654036456
Trained batch 38 in epoch 7, gen_loss = 0.41603379524671114, disc_loss = 0.0597709366478599
Trained batch 39 in epoch 7, gen_loss = 0.41568546518683436, disc_loss = 0.05999877757858485
Trained batch 40 in epoch 7, gen_loss = 0.41471262821337074, disc_loss = 0.06064655147947189
Trained batch 41 in epoch 7, gen_loss = 0.4151712166411536, disc_loss = 0.05983809086804589
Trained batch 42 in epoch 7, gen_loss = 0.41677230319311453, disc_loss = 0.06076230531081904
Trained batch 43 in epoch 7, gen_loss = 0.41755122623660346, disc_loss = 0.06314257674173197
Trained batch 44 in epoch 7, gen_loss = 0.41879332860310875, disc_loss = 0.06483496864222818
Trained batch 45 in epoch 7, gen_loss = 0.41713507343893463, disc_loss = 0.06515259690501768
Trained batch 46 in epoch 7, gen_loss = 0.4166446480345219, disc_loss = 0.0638936958572966
Trained batch 47 in epoch 7, gen_loss = 0.4177560241272052, disc_loss = 0.06277655909070745
Trained batch 48 in epoch 7, gen_loss = 0.4181840340701901, disc_loss = 0.06185207468438513
Trained batch 49 in epoch 7, gen_loss = 0.41705196917057036, disc_loss = 0.0613491945527494
Trained batch 50 in epoch 7, gen_loss = 0.4164511175716625, disc_loss = 0.06063935483860619
Trained batch 51 in epoch 7, gen_loss = 0.41592590740093816, disc_loss = 0.06124789283897441
Trained batch 52 in epoch 7, gen_loss = 0.41498268494066204, disc_loss = 0.06404829800199226
Trained batch 53 in epoch 7, gen_loss = 0.4169669344469353, disc_loss = 0.06683675380837586
Trained batch 54 in epoch 7, gen_loss = 0.4186368785121224, disc_loss = 0.06576948462223464
Trained batch 55 in epoch 7, gen_loss = 0.4182602193738733, disc_loss = 0.06519204908649304
Trained batch 56 in epoch 7, gen_loss = 0.41696704845679433, disc_loss = 0.06492053768025678
Trained batch 57 in epoch 7, gen_loss = 0.4183944299303252, disc_loss = 0.0645643991482412
Trained batch 58 in epoch 7, gen_loss = 0.41952886116706717, disc_loss = 0.06392116546315157
Trained batch 59 in epoch 7, gen_loss = 0.41944233427445093, disc_loss = 0.06319784703664481
Trained batch 60 in epoch 7, gen_loss = 0.4190734703032697, disc_loss = 0.06357144669736506
Trained batch 61 in epoch 7, gen_loss = 0.4189520141770763, disc_loss = 0.06590928901888189
Trained batch 62 in epoch 7, gen_loss = 0.41845523932623485, disc_loss = 0.0671144397042337
Trained batch 63 in epoch 7, gen_loss = 0.4185608495026827, disc_loss = 0.06729645231098402
Trained batch 64 in epoch 7, gen_loss = 0.4194605712707226, disc_loss = 0.06676122450198119
Trained batch 65 in epoch 7, gen_loss = 0.4184275066310709, disc_loss = 0.06637687993828546
Trained batch 66 in epoch 7, gen_loss = 0.4187182503849713, disc_loss = 0.06577062925129239
Trained batch 67 in epoch 7, gen_loss = 0.4191688185229021, disc_loss = 0.06497016150559135
Trained batch 68 in epoch 7, gen_loss = 0.41957923899526184, disc_loss = 0.06445064480699923
Trained batch 69 in epoch 7, gen_loss = 0.4191039217369897, disc_loss = 0.06408474907012922
Trained batch 70 in epoch 7, gen_loss = 0.4185438424768582, disc_loss = 0.06419994465639474
Trained batch 71 in epoch 7, gen_loss = 0.41975950863626266, disc_loss = 0.06445516649788867
Trained batch 72 in epoch 7, gen_loss = 0.42042577225868016, disc_loss = 0.06368731832361385
Trained batch 73 in epoch 7, gen_loss = 0.4198254898593232, disc_loss = 0.06310528781063654
Trained batch 74 in epoch 7, gen_loss = 0.420783847173055, disc_loss = 0.06243710435926914
Trained batch 75 in epoch 7, gen_loss = 0.42088816511003596, disc_loss = 0.061952158343046904
Trained batch 76 in epoch 7, gen_loss = 0.42088777678353445, disc_loss = 0.06121553242351715
Trained batch 77 in epoch 7, gen_loss = 0.4199488911873255, disc_loss = 0.06056389878862179
Trained batch 78 in epoch 7, gen_loss = 0.41947938558421555, disc_loss = 0.06023538808185089
Trained batch 79 in epoch 7, gen_loss = 0.42019783370196817, disc_loss = 0.06019551621284336
Trained batch 80 in epoch 7, gen_loss = 0.4205453038951497, disc_loss = 0.060068022896662174
Trained batch 81 in epoch 7, gen_loss = 0.4209815394587633, disc_loss = 0.059747104941890006
Trained batch 82 in epoch 7, gen_loss = 0.4208890228386385, disc_loss = 0.059103037612176085
Trained batch 83 in epoch 7, gen_loss = 0.4219351545685813, disc_loss = 0.05920161026352573
Trained batch 84 in epoch 7, gen_loss = 0.42091046747039346, disc_loss = 0.0603115713223815
Trained batch 85 in epoch 7, gen_loss = 0.4212198489627173, disc_loss = 0.060099082403318134
Trained batch 86 in epoch 7, gen_loss = 0.4216371500629118, disc_loss = 0.059749135073145915
Trained batch 87 in epoch 7, gen_loss = 0.42116405273025687, disc_loss = 0.059183074457740244
Trained batch 88 in epoch 7, gen_loss = 0.4214414177315958, disc_loss = 0.05863746948372782
Trained batch 89 in epoch 7, gen_loss = 0.4206719328959783, disc_loss = 0.05840599476877186
Trained batch 90 in epoch 7, gen_loss = 0.4204388644014086, disc_loss = 0.05833012776469791
Trained batch 91 in epoch 7, gen_loss = 0.42214843598396884, disc_loss = 0.060004379701517195
Trained batch 92 in epoch 7, gen_loss = 0.421884286467747, disc_loss = 0.059619834606525715
Trained batch 93 in epoch 7, gen_loss = 0.42075895090052423, disc_loss = 0.06012844145694311
Trained batch 94 in epoch 7, gen_loss = 0.42119838971840706, disc_loss = 0.06065397217477623
Trained batch 95 in epoch 7, gen_loss = 0.42142725891123217, disc_loss = 0.06013983554051568
Trained batch 96 in epoch 7, gen_loss = 0.4213062457202636, disc_loss = 0.060266234863971924
Trained batch 97 in epoch 7, gen_loss = 0.42108171174720843, disc_loss = 0.05983646886841375
Trained batch 98 in epoch 7, gen_loss = 0.42119203161711644, disc_loss = 0.059371849841842746
Trained batch 99 in epoch 7, gen_loss = 0.4218644484877586, disc_loss = 0.0589634944871068
Trained batch 100 in epoch 7, gen_loss = 0.42120927572250366, disc_loss = 0.058716667391876184
Trained batch 101 in epoch 7, gen_loss = 0.42060861196003707, disc_loss = 0.05919630657516274
Trained batch 102 in epoch 7, gen_loss = 0.4210755020669363, disc_loss = 0.05898231032837942
Trained batch 103 in epoch 7, gen_loss = 0.4223032593727112, disc_loss = 0.0600175832828077
Trained batch 104 in epoch 7, gen_loss = 0.42169791346504576, disc_loss = 0.06032634295877956
Trained batch 105 in epoch 7, gen_loss = 0.42176023912879657, disc_loss = 0.06028928126226056
Trained batch 106 in epoch 7, gen_loss = 0.42228397727012634, disc_loss = 0.05978818926263914
Trained batch 107 in epoch 7, gen_loss = 0.42160021789647917, disc_loss = 0.05954603263590899
Trained batch 108 in epoch 7, gen_loss = 0.42226068661847244, disc_loss = 0.0592507983070858
Trained batch 109 in epoch 7, gen_loss = 0.4227572817694057, disc_loss = 0.058881016050211406
Trained batch 110 in epoch 7, gen_loss = 0.4228789317715275, disc_loss = 0.05973161861871008
Trained batch 111 in epoch 7, gen_loss = 0.4220291282981634, disc_loss = 0.060003538591055464
Trained batch 112 in epoch 7, gen_loss = 0.4220541670786596, disc_loss = 0.05962401556790666
Trained batch 113 in epoch 7, gen_loss = 0.4216120347642062, disc_loss = 0.05942933847147383
Trained batch 114 in epoch 7, gen_loss = 0.42197485851204913, disc_loss = 0.06017755708130806
Trained batch 115 in epoch 7, gen_loss = 0.4216628388084214, disc_loss = 0.061375257759836724
Trained batch 116 in epoch 7, gen_loss = 0.42152889824321127, disc_loss = 0.06109311927555718
Trained batch 117 in epoch 7, gen_loss = 0.42170199246729834, disc_loss = 0.06072671788002727
Trained batch 118 in epoch 7, gen_loss = 0.42202959641689014, disc_loss = 0.06049853435741002
Trained batch 119 in epoch 7, gen_loss = 0.4223486120502154, disc_loss = 0.06013553959783167
Trained batch 120 in epoch 7, gen_loss = 0.422297885102674, disc_loss = 0.05980057345533913
Trained batch 121 in epoch 7, gen_loss = 0.4228000833851392, disc_loss = 0.05945406428950488
Trained batch 122 in epoch 7, gen_loss = 0.4232917360173977, disc_loss = 0.05915032977586597
Trained batch 123 in epoch 7, gen_loss = 0.42364105582237244, disc_loss = 0.0593434696220943
Trained batch 124 in epoch 7, gen_loss = 0.42383109211921693, disc_loss = 0.05939316590875387
Trained batch 125 in epoch 7, gen_loss = 0.42399514904097907, disc_loss = 0.05917624389338824
Trained batch 126 in epoch 7, gen_loss = 0.42468095529736494, disc_loss = 0.05881584522967029
Trained batch 127 in epoch 7, gen_loss = 0.42513482458889484, disc_loss = 0.058435410624952056
Trained batch 128 in epoch 7, gen_loss = 0.42552193352418355, disc_loss = 0.058072490364948444
Trained batch 129 in epoch 7, gen_loss = 0.425664484500885, disc_loss = 0.057729940539082654
Trained batch 130 in epoch 7, gen_loss = 0.4257677099631943, disc_loss = 0.05739909011643124
Trained batch 131 in epoch 7, gen_loss = 0.42581426736080286, disc_loss = 0.05706544094860102
Trained batch 132 in epoch 7, gen_loss = 0.42618625101290253, disc_loss = 0.056684198659753667
Trained batch 133 in epoch 7, gen_loss = 0.42598907004541425, disc_loss = 0.05633446456405765
Trained batch 134 in epoch 7, gen_loss = 0.4259907927778032, disc_loss = 0.05784346278135975
Trained batch 135 in epoch 7, gen_loss = 0.42590846274705496, disc_loss = 0.059409029059358597
Trained batch 136 in epoch 7, gen_loss = 0.4256979351061104, disc_loss = 0.059956267955339086
Trained batch 137 in epoch 7, gen_loss = 0.4258961321219154, disc_loss = 0.06042525063241846
Trained batch 138 in epoch 7, gen_loss = 0.42586998030436124, disc_loss = 0.060813236944779435
Trained batch 139 in epoch 7, gen_loss = 0.4255045365009989, disc_loss = 0.06103865359577217
Trained batch 140 in epoch 7, gen_loss = 0.4253761772568344, disc_loss = 0.06114829864339731
Trained batch 141 in epoch 7, gen_loss = 0.42525653520100554, disc_loss = 0.06106029061639918
Trained batch 142 in epoch 7, gen_loss = 0.42530177752454795, disc_loss = 0.06109700027944429
Trained batch 143 in epoch 7, gen_loss = 0.4254369621889459, disc_loss = 0.06098101447504531
Trained batch 144 in epoch 7, gen_loss = 0.4256954591849755, disc_loss = 0.06133598807621105
Trained batch 145 in epoch 7, gen_loss = 0.4256969955686021, disc_loss = 0.06115029636477057
Trained batch 146 in epoch 7, gen_loss = 0.4262431450441581, disc_loss = 0.06092415534935537
Trained batch 147 in epoch 7, gen_loss = 0.42634891356165344, disc_loss = 0.06065023627849547
Trained batch 148 in epoch 7, gen_loss = 0.4263031296682038, disc_loss = 0.06072461562881234
Trained batch 149 in epoch 7, gen_loss = 0.42693303803602856, disc_loss = 0.06305831390433013
Trained batch 150 in epoch 7, gen_loss = 0.4269495561028158, disc_loss = 0.06286802648918222
Trained batch 151 in epoch 7, gen_loss = 0.42678897180839587, disc_loss = 0.06305706763554267
Trained batch 152 in epoch 7, gen_loss = 0.42735347852987404, disc_loss = 0.06313906232917718
Trained batch 153 in epoch 7, gen_loss = 0.4272699880522567, disc_loss = 0.06291572342312278
Trained batch 154 in epoch 7, gen_loss = 0.4276525368613581, disc_loss = 0.0626767777297045
Trained batch 155 in epoch 7, gen_loss = 0.42745091823431164, disc_loss = 0.06248686922630534
Trained batch 156 in epoch 7, gen_loss = 0.42778168248522813, disc_loss = 0.062236740891554745
Trained batch 157 in epoch 7, gen_loss = 0.4273505554169039, disc_loss = 0.06211848827255772
Trained batch 158 in epoch 7, gen_loss = 0.4275588162665097, disc_loss = 0.06177399993095102
Trained batch 159 in epoch 7, gen_loss = 0.42743860799819233, disc_loss = 0.061643695962266064
Trained batch 160 in epoch 7, gen_loss = 0.4271874975713884, disc_loss = 0.06185324706704072
Trained batch 161 in epoch 7, gen_loss = 0.4272437676971341, disc_loss = 0.06199711781098611
Trained batch 162 in epoch 7, gen_loss = 0.4276530490331123, disc_loss = 0.06167952982320284
Trained batch 163 in epoch 7, gen_loss = 0.4273783166597529, disc_loss = 0.06157802704937484
Trained batch 164 in epoch 7, gen_loss = 0.42798726432251205, disc_loss = 0.061344217212701384
Trained batch 165 in epoch 7, gen_loss = 0.4275920561638223, disc_loss = 0.06112962018373052
Trained batch 166 in epoch 7, gen_loss = 0.4277982051501017, disc_loss = 0.06088703084168231
Trained batch 167 in epoch 7, gen_loss = 0.4278803114734945, disc_loss = 0.060555107617152056
Trained batch 168 in epoch 7, gen_loss = 0.4282729288882758, disc_loss = 0.06025563957191695
Trained batch 169 in epoch 7, gen_loss = 0.42832721682155833, disc_loss = 0.059937920889762394
Trained batch 170 in epoch 7, gen_loss = 0.4292375734675, disc_loss = 0.059696235816533626
Trained batch 171 in epoch 7, gen_loss = 0.42942377249168795, disc_loss = 0.059584487475952956
Trained batch 172 in epoch 7, gen_loss = 0.42964674351532334, disc_loss = 0.05998736032893117
Trained batch 173 in epoch 7, gen_loss = 0.4302339903239546, disc_loss = 0.05985399426346452
Trained batch 174 in epoch 7, gen_loss = 0.4303584383215223, disc_loss = 0.05958529223022716
Trained batch 175 in epoch 7, gen_loss = 0.4301946676251563, disc_loss = 0.0592688773308923
Trained batch 176 in epoch 7, gen_loss = 0.43032620249494996, disc_loss = 0.05903368478767195
Trained batch 177 in epoch 7, gen_loss = 0.4304333280646399, disc_loss = 0.058854269509967624
Trained batch 178 in epoch 7, gen_loss = 0.4305061203474439, disc_loss = 0.058578272550444864
Trained batch 179 in epoch 7, gen_loss = 0.4306492025653521, disc_loss = 0.058333080564625564
Trained batch 180 in epoch 7, gen_loss = 0.43086382121012357, disc_loss = 0.05807680818020721
Trained batch 181 in epoch 7, gen_loss = 0.43090793867032606, disc_loss = 0.0579105261636509
Trained batch 182 in epoch 7, gen_loss = 0.4310923435323225, disc_loss = 0.05764987009521472
Trained batch 183 in epoch 7, gen_loss = 0.431156058350335, disc_loss = 0.057430182616530066
Trained batch 184 in epoch 7, gen_loss = 0.43099525876947353, disc_loss = 0.057159036043024546
Trained batch 185 in epoch 7, gen_loss = 0.43128006833214916, disc_loss = 0.05695160157648065
Trained batch 186 in epoch 7, gen_loss = 0.4309694653845088, disc_loss = 0.056744247951350586
Trained batch 187 in epoch 7, gen_loss = 0.4311023939480173, disc_loss = 0.05647192452291146
Trained batch 188 in epoch 7, gen_loss = 0.4309030173632203, disc_loss = 0.05626663401791895
Trained batch 189 in epoch 7, gen_loss = 0.43119646467660605, disc_loss = 0.05601195942757553
Trained batch 190 in epoch 7, gen_loss = 0.4311992916137136, disc_loss = 0.055822207565609544
Trained batch 191 in epoch 7, gen_loss = 0.4319770522415638, disc_loss = 0.056117272060267474
Trained batch 192 in epoch 7, gen_loss = 0.4312602574961173, disc_loss = 0.05689451173478689
Trained batch 193 in epoch 7, gen_loss = 0.43137926324126646, disc_loss = 0.05711711764326031
Trained batch 194 in epoch 7, gen_loss = 0.4313733591483189, disc_loss = 0.056912833927438046
Trained batch 195 in epoch 7, gen_loss = 0.43090158229579734, disc_loss = 0.0567309638290495
Trained batch 196 in epoch 7, gen_loss = 0.43113639935624176, disc_loss = 0.05668158551942803
Trained batch 197 in epoch 7, gen_loss = 0.4307999297825977, disc_loss = 0.05694131642307221
Trained batch 198 in epoch 7, gen_loss = 0.43046741659317783, disc_loss = 0.056927316889971796
Trained batch 199 in epoch 7, gen_loss = 0.43026689887046815, disc_loss = 0.05725547498790547
Trained batch 200 in epoch 7, gen_loss = 0.43064035141645973, disc_loss = 0.057342378012557975
Trained batch 201 in epoch 7, gen_loss = 0.4308591948287322, disc_loss = 0.057428075892776986
Trained batch 202 in epoch 7, gen_loss = 0.4307941274689923, disc_loss = 0.057309601095784916
Trained batch 203 in epoch 7, gen_loss = 0.43051087900119667, disc_loss = 0.05787829534999807
Trained batch 204 in epoch 7, gen_loss = 0.4307817473644164, disc_loss = 0.0580894666723907
Trained batch 205 in epoch 7, gen_loss = 0.4310494100005881, disc_loss = 0.05794304817037892
Trained batch 206 in epoch 7, gen_loss = 0.43098897173784784, disc_loss = 0.05808647975532545
Trained batch 207 in epoch 7, gen_loss = 0.431300549982832, disc_loss = 0.05807116614932266
Trained batch 208 in epoch 7, gen_loss = 0.4316409474069422, disc_loss = 0.057887175559338054
Trained batch 209 in epoch 7, gen_loss = 0.43175957188719793, disc_loss = 0.05781955528959987
Trained batch 210 in epoch 7, gen_loss = 0.4316469784031547, disc_loss = 0.05785234560042408
Trained batch 211 in epoch 7, gen_loss = 0.4316342697953278, disc_loss = 0.05768823174469805
Trained batch 212 in epoch 7, gen_loss = 0.43184493908859756, disc_loss = 0.057765085099291215
Trained batch 213 in epoch 7, gen_loss = 0.43137846079385167, disc_loss = 0.05758525441383299
Trained batch 214 in epoch 7, gen_loss = 0.4312071449534838, disc_loss = 0.05778541360267026
Trained batch 215 in epoch 7, gen_loss = 0.43119070471988785, disc_loss = 0.05792477812954328
Trained batch 216 in epoch 7, gen_loss = 0.4309426469187583, disc_loss = 0.05769216813670669
Trained batch 217 in epoch 7, gen_loss = 0.43092589914251905, disc_loss = 0.057981188026675526
Trained batch 218 in epoch 7, gen_loss = 0.4310295051091338, disc_loss = 0.057781232063781864
Trained batch 219 in epoch 7, gen_loss = 0.4308799147605896, disc_loss = 0.057619875713928854
Trained batch 220 in epoch 7, gen_loss = 0.4309348188913785, disc_loss = 0.057392526422184786
Trained batch 221 in epoch 7, gen_loss = 0.4306724315828031, disc_loss = 0.05750867609052105
Trained batch 222 in epoch 7, gen_loss = 0.43029067735500937, disc_loss = 0.057499338296396585
Trained batch 223 in epoch 7, gen_loss = 0.43017845787107944, disc_loss = 0.0572993781783485
Trained batch 224 in epoch 7, gen_loss = 0.43043748166826035, disc_loss = 0.05712175988488727
Trained batch 225 in epoch 7, gen_loss = 0.4306498074953535, disc_loss = 0.0569273238235145
Trained batch 226 in epoch 7, gen_loss = 0.4307065031076843, disc_loss = 0.056773024020380126
Trained batch 227 in epoch 7, gen_loss = 0.43087269679496165, disc_loss = 0.05661342453554665
Trained batch 228 in epoch 7, gen_loss = 0.4307471578818742, disc_loss = 0.05648134116441272
Trained batch 229 in epoch 7, gen_loss = 0.4305055721946385, disc_loss = 0.05636792325050287
Trained batch 230 in epoch 7, gen_loss = 0.4304569136528742, disc_loss = 0.056382258761335506
Trained batch 231 in epoch 7, gen_loss = 0.43115348651491364, disc_loss = 0.057577006418482755
Trained batch 232 in epoch 7, gen_loss = 0.4312654601913665, disc_loss = 0.057439998859467684
Trained batch 233 in epoch 7, gen_loss = 0.43106453490053487, disc_loss = 0.05769041465181443
Trained batch 234 in epoch 7, gen_loss = 0.4312372123941462, disc_loss = 0.05764606867302605
Trained batch 235 in epoch 7, gen_loss = 0.43115608343633555, disc_loss = 0.05754084917874533
Trained batch 236 in epoch 7, gen_loss = 0.4312622261701254, disc_loss = 0.0577549786122225
Trained batch 237 in epoch 7, gen_loss = 0.43140697679599793, disc_loss = 0.057668354327031296
Trained batch 238 in epoch 7, gen_loss = 0.4316634736549904, disc_loss = 0.05792501771035429
Trained batch 239 in epoch 7, gen_loss = 0.4314544375985861, disc_loss = 0.05816440982356046
Trained batch 240 in epoch 7, gen_loss = 0.4311764380001923, disc_loss = 0.05816741865437432
Trained batch 241 in epoch 7, gen_loss = 0.43126625672352215, disc_loss = 0.05815515174214875
Trained batch 242 in epoch 7, gen_loss = 0.4312303103046653, disc_loss = 0.057962782876451076
Trained batch 243 in epoch 7, gen_loss = 0.4312723787104497, disc_loss = 0.05833435746780062
Trained batch 244 in epoch 7, gen_loss = 0.4315421219991178, disc_loss = 0.059576713107526304
Trained batch 245 in epoch 7, gen_loss = 0.4314555141741667, disc_loss = 0.05976944529958736
Trained batch 246 in epoch 7, gen_loss = 0.4312461112674914, disc_loss = 0.05970766244131906
Trained batch 247 in epoch 7, gen_loss = 0.43087307676192255, disc_loss = 0.05958380454385112
Trained batch 248 in epoch 7, gen_loss = 0.43099726431341057, disc_loss = 0.05939541242074176
Trained batch 249 in epoch 7, gen_loss = 0.43073003041744234, disc_loss = 0.05927252858504653
Trained batch 250 in epoch 7, gen_loss = 0.4307368004702002, disc_loss = 0.059292315869068954
Trained batch 251 in epoch 7, gen_loss = 0.43120200376188944, disc_loss = 0.05909139182167276
Trained batch 252 in epoch 7, gen_loss = 0.43100165743601654, disc_loss = 0.05954563056335972
Trained batch 253 in epoch 7, gen_loss = 0.4308708333593654, disc_loss = 0.0604690813576788
Trained batch 254 in epoch 7, gen_loss = 0.43095350838175006, disc_loss = 0.060532843113383826
Trained batch 255 in epoch 7, gen_loss = 0.4309587056050077, disc_loss = 0.060811697137978626
Trained batch 256 in epoch 7, gen_loss = 0.43126288473838037, disc_loss = 0.060664145004163686
Trained batch 257 in epoch 7, gen_loss = 0.4313441831474156, disc_loss = 0.060488012261948616
Trained batch 258 in epoch 7, gen_loss = 0.43112178164099174, disc_loss = 0.06065715173022052
Trained batch 259 in epoch 7, gen_loss = 0.4309690553408403, disc_loss = 0.060484567746663324
Trained batch 260 in epoch 7, gen_loss = 0.4312341909755692, disc_loss = 0.060434471633841934
Trained batch 261 in epoch 7, gen_loss = 0.43154981231871453, disc_loss = 0.06022859681646503
Trained batch 262 in epoch 7, gen_loss = 0.4312801365616657, disc_loss = 0.06003313553926779
Trained batch 263 in epoch 7, gen_loss = 0.4315551905469461, disc_loss = 0.05983359308271302
Trained batch 264 in epoch 7, gen_loss = 0.43152270710693214, disc_loss = 0.05963521080161884
Trained batch 265 in epoch 7, gen_loss = 0.431493262263169, disc_loss = 0.0594263600441102
Trained batch 266 in epoch 7, gen_loss = 0.4315631545884779, disc_loss = 0.059219678061620123
Trained batch 267 in epoch 7, gen_loss = 0.43183893832697795, disc_loss = 0.05901826952528486
Trained batch 268 in epoch 7, gen_loss = 0.4318486004513879, disc_loss = 0.05881222019744102
Trained batch 269 in epoch 7, gen_loss = 0.43190557139891167, disc_loss = 0.058619452213558056
Trained batch 270 in epoch 7, gen_loss = 0.4316809027837211, disc_loss = 0.058448442513109405
Trained batch 271 in epoch 7, gen_loss = 0.4315067308352274, disc_loss = 0.058290446941528525
Trained batch 272 in epoch 7, gen_loss = 0.4311997136135241, disc_loss = 0.05829055931831918
Trained batch 273 in epoch 7, gen_loss = 0.43119897546559355, disc_loss = 0.0584476104483729
Trained batch 274 in epoch 7, gen_loss = 0.43104360699653627, disc_loss = 0.05836334701034833
Trained batch 275 in epoch 7, gen_loss = 0.4310136789429015, disc_loss = 0.05827737467083405
Trained batch 276 in epoch 7, gen_loss = 0.4310806688418888, disc_loss = 0.05827843413742037
Trained batch 277 in epoch 7, gen_loss = 0.43120375629380453, disc_loss = 0.05810024428245002
Trained batch 278 in epoch 7, gen_loss = 0.4311976777823595, disc_loss = 0.057973590666948946
Trained batch 279 in epoch 7, gen_loss = 0.4310941305543695, disc_loss = 0.05786645686270536
Trained batch 280 in epoch 7, gen_loss = 0.4315156638622284, disc_loss = 0.05792480280036206
Trained batch 281 in epoch 7, gen_loss = 0.43160392206611364, disc_loss = 0.0577742216178936
Trained batch 282 in epoch 7, gen_loss = 0.43173941959340667, disc_loss = 0.05787924779891678
Trained batch 283 in epoch 7, gen_loss = 0.43220935552053047, disc_loss = 0.05791214192499289
Trained batch 284 in epoch 7, gen_loss = 0.43237287663576895, disc_loss = 0.05786101626019859
Trained batch 285 in epoch 7, gen_loss = 0.43232430205061717, disc_loss = 0.05771883448888711
Trained batch 286 in epoch 7, gen_loss = 0.43272391522387593, disc_loss = 0.05755202716966046
Trained batch 287 in epoch 7, gen_loss = 0.4326474680047896, disc_loss = 0.057414840202707436
Trained batch 288 in epoch 7, gen_loss = 0.43289820061010476, disc_loss = 0.05723728729930793
Trained batch 289 in epoch 7, gen_loss = 0.4326442650679884, disc_loss = 0.05706884072499414
Trained batch 290 in epoch 7, gen_loss = 0.43274982831732106, disc_loss = 0.05692312778997846
Trained batch 291 in epoch 7, gen_loss = 0.4329659785718134, disc_loss = 0.056766532159774015
Trained batch 292 in epoch 7, gen_loss = 0.43302045157338165, disc_loss = 0.05666913656889756
Trained batch 293 in epoch 7, gen_loss = 0.433162209128036, disc_loss = 0.05654190289613721
Trained batch 294 in epoch 7, gen_loss = 0.43305386426085135, disc_loss = 0.05638557852687851
Trained batch 295 in epoch 7, gen_loss = 0.4331954109507638, disc_loss = 0.05625478017405053
Trained batch 296 in epoch 7, gen_loss = 0.4333984168490978, disc_loss = 0.05609500319979182
Trained batch 297 in epoch 7, gen_loss = 0.4336112438632338, disc_loss = 0.055928837363420664
Trained batch 298 in epoch 7, gen_loss = 0.4336307007931547, disc_loss = 0.055765137879215304
Trained batch 299 in epoch 7, gen_loss = 0.43358646631240844, disc_loss = 0.05560991937837874
Trained batch 300 in epoch 7, gen_loss = 0.43367804869068816, disc_loss = 0.055495118554464956
Trained batch 301 in epoch 7, gen_loss = 0.4338841787631938, disc_loss = 0.05538249713914555
Trained batch 302 in epoch 7, gen_loss = 0.4340625456457484, disc_loss = 0.05523289329673566
Trained batch 303 in epoch 7, gen_loss = 0.43386407000453847, disc_loss = 0.055286646308224205
Trained batch 304 in epoch 7, gen_loss = 0.43387053325528, disc_loss = 0.055360845930599534
Trained batch 305 in epoch 7, gen_loss = 0.43432295614597843, disc_loss = 0.0563417547253064
Trained batch 306 in epoch 7, gen_loss = 0.4342431663884402, disc_loss = 0.05621361813404831
Trained batch 307 in epoch 7, gen_loss = 0.43423174350679694, disc_loss = 0.0562147157857884
Trained batch 308 in epoch 7, gen_loss = 0.4342021887163514, disc_loss = 0.05605083157181812
Trained batch 309 in epoch 7, gen_loss = 0.4342520062961886, disc_loss = 0.05590030818261326
Trained batch 310 in epoch 7, gen_loss = 0.4341761945144923, disc_loss = 0.05573829673335459
Trained batch 311 in epoch 7, gen_loss = 0.43425618532376414, disc_loss = 0.055601922331753977
Trained batch 312 in epoch 7, gen_loss = 0.434361690625596, disc_loss = 0.05554509773692741
Trained batch 313 in epoch 7, gen_loss = 0.4342105270001539, disc_loss = 0.05544469341454778
Trained batch 314 in epoch 7, gen_loss = 0.4340869100320907, disc_loss = 0.055359229524545965
Trained batch 315 in epoch 7, gen_loss = 0.43423821003753926, disc_loss = 0.05522347477049555
Trained batch 316 in epoch 7, gen_loss = 0.43407137254811234, disc_loss = 0.05552349504809063
Trained batch 317 in epoch 7, gen_loss = 0.43371939677862253, disc_loss = 0.056083569123772846
Trained batch 318 in epoch 7, gen_loss = 0.4338950746485432, disc_loss = 0.05597923870846559
Trained batch 319 in epoch 7, gen_loss = 0.43389129647985103, disc_loss = 0.056004454541107404
Trained batch 320 in epoch 7, gen_loss = 0.43368378216603837, disc_loss = 0.05608635780697462
Trained batch 321 in epoch 7, gen_loss = 0.43376791782630897, disc_loss = 0.05620416834218694
Trained batch 322 in epoch 7, gen_loss = 0.4336664278994404, disc_loss = 0.05654463902816476
Trained batch 323 in epoch 7, gen_loss = 0.43358721685262375, disc_loss = 0.05669469514755348
Trained batch 324 in epoch 7, gen_loss = 0.43359498326595014, disc_loss = 0.056600038623437286
Trained batch 325 in epoch 7, gen_loss = 0.43376677816996545, disc_loss = 0.056585087008814275
Trained batch 326 in epoch 7, gen_loss = 0.43363605945482164, disc_loss = 0.05647602129588046
Trained batch 327 in epoch 7, gen_loss = 0.43368712376530577, disc_loss = 0.05632697045732085
Trained batch 328 in epoch 7, gen_loss = 0.4335201984118546, disc_loss = 0.05638375201143642
Trained batch 329 in epoch 7, gen_loss = 0.4335336710467483, disc_loss = 0.0570170338625427
Trained batch 330 in epoch 7, gen_loss = 0.43338298032290984, disc_loss = 0.05701092626052568
Trained batch 331 in epoch 7, gen_loss = 0.4333064364022519, disc_loss = 0.05711382212249158
Trained batch 332 in epoch 7, gen_loss = 0.43344770913367514, disc_loss = 0.057044368974903635
Trained batch 333 in epoch 7, gen_loss = 0.43319034237347676, disc_loss = 0.057712720282526386
Trained batch 334 in epoch 7, gen_loss = 0.43284824668471494, disc_loss = 0.058546185237008025
Trained batch 335 in epoch 7, gen_loss = 0.43301916486095815, disc_loss = 0.0584529005427612
Trained batch 336 in epoch 7, gen_loss = 0.43312111903722633, disc_loss = 0.05846958958892047
Trained batch 337 in epoch 7, gen_loss = 0.4329000789914611, disc_loss = 0.0586917667075187
Trained batch 338 in epoch 7, gen_loss = 0.4329419613411996, disc_loss = 0.05918747841539878
Trained batch 339 in epoch 7, gen_loss = 0.4329147615853478, disc_loss = 0.05925128043505966
Trained batch 340 in epoch 7, gen_loss = 0.4326602462624525, disc_loss = 0.05918771675187013
Trained batch 341 in epoch 7, gen_loss = 0.43266996967862226, disc_loss = 0.05909168209311449
Trained batch 342 in epoch 7, gen_loss = 0.43256717007987355, disc_loss = 0.05907153558602377
Trained batch 343 in epoch 7, gen_loss = 0.4327307583460974, disc_loss = 0.058954545328539776
Trained batch 344 in epoch 7, gen_loss = 0.4326156995434692, disc_loss = 0.058956533961295
Trained batch 345 in epoch 7, gen_loss = 0.43242222165441235, disc_loss = 0.059279799363791214
Trained batch 346 in epoch 7, gen_loss = 0.4325164308293752, disc_loss = 0.05948619856848046
Trained batch 347 in epoch 7, gen_loss = 0.4323463096529588, disc_loss = 0.05947754382163864
Trained batch 348 in epoch 7, gen_loss = 0.4320138633080403, disc_loss = 0.05942752532444809
Trained batch 349 in epoch 7, gen_loss = 0.43233776075499397, disc_loss = 0.059583881560580004
Trained batch 350 in epoch 7, gen_loss = 0.4319978167868068, disc_loss = 0.060006219288068915
Trained batch 351 in epoch 7, gen_loss = 0.4321195038712837, disc_loss = 0.05995239792537177
Trained batch 352 in epoch 7, gen_loss = 0.43207786415859256, disc_loss = 0.05985524395557263
Trained batch 353 in epoch 7, gen_loss = 0.4321081948987508, disc_loss = 0.059728930466860994
Trained batch 354 in epoch 7, gen_loss = 0.4319098016745608, disc_loss = 0.05971774386412556
Trained batch 355 in epoch 7, gen_loss = 0.43193943924113604, disc_loss = 0.059593399229925126
Trained batch 356 in epoch 7, gen_loss = 0.43210230705116975, disc_loss = 0.059532514929181844
Trained batch 357 in epoch 7, gen_loss = 0.4320297356923865, disc_loss = 0.059448143932318016
Trained batch 358 in epoch 7, gen_loss = 0.4320146766877772, disc_loss = 0.05934215694715199
Trained batch 359 in epoch 7, gen_loss = 0.4318195184899701, disc_loss = 0.05943931886188996
Trained batch 360 in epoch 7, gen_loss = 0.4318536441577108, disc_loss = 0.059503038263546915
Trained batch 361 in epoch 7, gen_loss = 0.43193968389574333, disc_loss = 0.05936054449762573
Trained batch 362 in epoch 7, gen_loss = 0.4320989809417199, disc_loss = 0.059360227449450735
Trained batch 363 in epoch 7, gen_loss = 0.4320009322939338, disc_loss = 0.059388488568851705
Trained batch 364 in epoch 7, gen_loss = 0.4321277428163241, disc_loss = 0.05926499192424323
Trained batch 365 in epoch 7, gen_loss = 0.4321840249938392, disc_loss = 0.05958627682634696
Trained batch 366 in epoch 7, gen_loss = 0.4321597665954351, disc_loss = 0.06011139312365704
Trained batch 367 in epoch 7, gen_loss = 0.43203501046999643, disc_loss = 0.06007914983290349
Trained batch 368 in epoch 7, gen_loss = 0.432264432674501, disc_loss = 0.060024322322910516
Trained batch 369 in epoch 7, gen_loss = 0.4322918251559541, disc_loss = 0.059947189297904636
Trained batch 370 in epoch 7, gen_loss = 0.4321934731019475, disc_loss = 0.059928595951339106
Trained batch 371 in epoch 7, gen_loss = 0.43253846795007744, disc_loss = 0.05980486714879491
Trained batch 372 in epoch 7, gen_loss = 0.43263879426363006, disc_loss = 0.05979952507467576
Trained batch 373 in epoch 7, gen_loss = 0.4325634663436502, disc_loss = 0.06000965773588654
Trained batch 374 in epoch 7, gen_loss = 0.43262164878845216, disc_loss = 0.06028969164378941
Trained batch 375 in epoch 7, gen_loss = 0.4326631135921529, disc_loss = 0.06034816630826173
Trained batch 376 in epoch 7, gen_loss = 0.43270413202063157, disc_loss = 0.06022667229874677
Trained batch 377 in epoch 7, gen_loss = 0.4325803046819394, disc_loss = 0.060211570206019416
Trained batch 378 in epoch 7, gen_loss = 0.4325712302743917, disc_loss = 0.06015396667804107
Trained batch 379 in epoch 7, gen_loss = 0.4324475786403606, disc_loss = 0.060014397393005264
Trained batch 380 in epoch 7, gen_loss = 0.4325203525582011, disc_loss = 0.05989624653928217
Trained batch 381 in epoch 7, gen_loss = 0.43241660827429507, disc_loss = 0.05981306424205977
Trained batch 382 in epoch 7, gen_loss = 0.4326285523005005, disc_loss = 0.059844712799113464
Trained batch 383 in epoch 7, gen_loss = 0.43259385383377474, disc_loss = 0.0601277987073748
Trained batch 384 in epoch 7, gen_loss = 0.4324586560199787, disc_loss = 0.06010380109300377
Trained batch 385 in epoch 7, gen_loss = 0.43245689462812453, disc_loss = 0.0599916078158717
Trained batch 386 in epoch 7, gen_loss = 0.432458542191089, disc_loss = 0.05988082376029583
Trained batch 387 in epoch 7, gen_loss = 0.43268348115313915, disc_loss = 0.059830477803863934
Trained batch 388 in epoch 7, gen_loss = 0.43272929426024076, disc_loss = 0.059704185697515816
Trained batch 389 in epoch 7, gen_loss = 0.432634404530892, disc_loss = 0.0596379820514136
Trained batch 390 in epoch 7, gen_loss = 0.432717440911876, disc_loss = 0.05953839210891034
Trained batch 391 in epoch 7, gen_loss = 0.43291927182248663, disc_loss = 0.05976519022049021
Trained batch 392 in epoch 7, gen_loss = 0.4329878614300687, disc_loss = 0.05962933611027593
Trained batch 393 in epoch 7, gen_loss = 0.43300875983564985, disc_loss = 0.05954436526390332
Trained batch 394 in epoch 7, gen_loss = 0.4329366351230235, disc_loss = 0.059448859922564296
Trained batch 395 in epoch 7, gen_loss = 0.4328460298252828, disc_loss = 0.059340093305423815
Trained batch 396 in epoch 7, gen_loss = 0.4330039819331854, disc_loss = 0.05923204949437652
Trained batch 397 in epoch 7, gen_loss = 0.4330095425622547, disc_loss = 0.05924711132775431
Trained batch 398 in epoch 7, gen_loss = 0.43295374475326154, disc_loss = 0.05924890843630864
Trained batch 399 in epoch 7, gen_loss = 0.4330402575433254, disc_loss = 0.05930604958615732
Trained batch 400 in epoch 7, gen_loss = 0.4331718682499598, disc_loss = 0.05925110683595283
Trained batch 401 in epoch 7, gen_loss = 0.43294997061069923, disc_loss = 0.0591641906388243
Trained batch 402 in epoch 7, gen_loss = 0.4329007584462982, disc_loss = 0.05904879526318358
Trained batch 403 in epoch 7, gen_loss = 0.4330452564034131, disc_loss = 0.058974341659387114
Trained batch 404 in epoch 7, gen_loss = 0.43310164051291383, disc_loss = 0.058925633145680216
Trained batch 405 in epoch 7, gen_loss = 0.4328277050861584, disc_loss = 0.05889668672063429
Trained batch 406 in epoch 7, gen_loss = 0.43280312931508336, disc_loss = 0.05887623506950567
Trained batch 407 in epoch 7, gen_loss = 0.43306496206159684, disc_loss = 0.05881737331875746
Trained batch 408 in epoch 7, gen_loss = 0.43308058461233573, disc_loss = 0.05874303417237052
Trained batch 409 in epoch 7, gen_loss = 0.4329322973402535, disc_loss = 0.05866787520339485
Trained batch 410 in epoch 7, gen_loss = 0.4327852805745573, disc_loss = 0.058598159669066834
Trained batch 411 in epoch 7, gen_loss = 0.4330456829765468, disc_loss = 0.05852325232100483
Trained batch 412 in epoch 7, gen_loss = 0.4330631338655227, disc_loss = 0.058392286068956044
Trained batch 413 in epoch 7, gen_loss = 0.4330167179378334, disc_loss = 0.05831407070675064
Trained batch 414 in epoch 7, gen_loss = 0.432975762364376, disc_loss = 0.058187878901049137
Trained batch 415 in epoch 7, gen_loss = 0.43301028142181724, disc_loss = 0.058156578494303036
Trained batch 416 in epoch 7, gen_loss = 0.4327097770264395, disc_loss = 0.05846445367568814
Trained batch 417 in epoch 7, gen_loss = 0.4327652156352997, disc_loss = 0.0584209672187602
Trained batch 418 in epoch 7, gen_loss = 0.4329061286972929, disc_loss = 0.058389735594280685
Trained batch 419 in epoch 7, gen_loss = 0.43296290884415306, disc_loss = 0.05826829889556393
Trained batch 420 in epoch 7, gen_loss = 0.43297762301642084, disc_loss = 0.05816670100540896
Trained batch 421 in epoch 7, gen_loss = 0.43328341432092315, disc_loss = 0.058047421419467796
Trained batch 422 in epoch 7, gen_loss = 0.43319651611307836, disc_loss = 0.05793281102687314
Trained batch 423 in epoch 7, gen_loss = 0.43320082064788296, disc_loss = 0.057813591266134404
Trained batch 424 in epoch 7, gen_loss = 0.4331486207597396, disc_loss = 0.05768667159766397
Trained batch 425 in epoch 7, gen_loss = 0.4330322436743499, disc_loss = 0.05756629641034461
Trained batch 426 in epoch 7, gen_loss = 0.43302424067077366, disc_loss = 0.05744552685861722
Trained batch 427 in epoch 7, gen_loss = 0.43290100037773077, disc_loss = 0.05737922114600802
Trained batch 428 in epoch 7, gen_loss = 0.433038132729786, disc_loss = 0.057267998456455645
Trained batch 429 in epoch 7, gen_loss = 0.432761175687923, disc_loss = 0.05729834349923442
Trained batch 430 in epoch 7, gen_loss = 0.43266048626390796, disc_loss = 0.057189732799176864
Trained batch 431 in epoch 7, gen_loss = 0.4328456292687743, disc_loss = 0.05710582564535326
Trained batch 432 in epoch 7, gen_loss = 0.4327650421210855, disc_loss = 0.05698646134675392
Trained batch 433 in epoch 7, gen_loss = 0.432870242727517, disc_loss = 0.05686731174671894
Trained batch 434 in epoch 7, gen_loss = 0.43288675656263853, disc_loss = 0.05676074176759127
Trained batch 435 in epoch 7, gen_loss = 0.4328568315287249, disc_loss = 0.05670416676984041
Trained batch 436 in epoch 7, gen_loss = 0.4329302888576717, disc_loss = 0.056601559710784795
Trained batch 437 in epoch 7, gen_loss = 0.4328236428161734, disc_loss = 0.05650289512726321
Trained batch 438 in epoch 7, gen_loss = 0.4328253101515064, disc_loss = 0.0563900427153474
Trained batch 439 in epoch 7, gen_loss = 0.4326385044238784, disc_loss = 0.05634768126394853
Trained batch 440 in epoch 7, gen_loss = 0.4327738562138443, disc_loss = 0.05622879511469768
Trained batch 441 in epoch 7, gen_loss = 0.4329076838169702, disc_loss = 0.05624774032076441
Trained batch 442 in epoch 7, gen_loss = 0.4328893411643887, disc_loss = 0.056402367990123395
Trained batch 443 in epoch 7, gen_loss = 0.43317114159062103, disc_loss = 0.0567005115360869
Trained batch 444 in epoch 7, gen_loss = 0.4331893891430973, disc_loss = 0.056599455760540755
Trained batch 445 in epoch 7, gen_loss = 0.4333458081756472, disc_loss = 0.056495306928299634
Trained batch 446 in epoch 7, gen_loss = 0.4330459489785051, disc_loss = 0.056718925691795194
Trained batch 447 in epoch 7, gen_loss = 0.43312441777171834, disc_loss = 0.056962459670882835
Trained batch 448 in epoch 7, gen_loss = 0.43304293106552755, disc_loss = 0.056874684597944265
Trained batch 449 in epoch 7, gen_loss = 0.4328230325380961, disc_loss = 0.05682749588301198
Trained batch 450 in epoch 7, gen_loss = 0.43269107393309175, disc_loss = 0.056903480152039894
Trained batch 451 in epoch 7, gen_loss = 0.43280840045319197, disc_loss = 0.057430796711025675
Trained batch 452 in epoch 7, gen_loss = 0.4326822981402837, disc_loss = 0.05742798645972433
Trained batch 453 in epoch 7, gen_loss = 0.4326848734974336, disc_loss = 0.05747764372822751
Trained batch 454 in epoch 7, gen_loss = 0.432670097560673, disc_loss = 0.05754309842557452
Trained batch 455 in epoch 7, gen_loss = 0.43271152518297495, disc_loss = 0.0581292869066697
Trained batch 456 in epoch 7, gen_loss = 0.4326850700821866, disc_loss = 0.05809782774603357
Trained batch 457 in epoch 7, gen_loss = 0.4327000617069969, disc_loss = 0.05801017345163125
Trained batch 458 in epoch 7, gen_loss = 0.43258794213691826, disc_loss = 0.05795199688055303
Trained batch 459 in epoch 7, gen_loss = 0.4325074273607005, disc_loss = 0.05788997475958794
Trained batch 460 in epoch 7, gen_loss = 0.4324123806394879, disc_loss = 0.05780695059837737
Trained batch 461 in epoch 7, gen_loss = 0.43245553222053496, disc_loss = 0.05775206153295144
Trained batch 462 in epoch 7, gen_loss = 0.43241228217955024, disc_loss = 0.05764306061116669
Trained batch 463 in epoch 7, gen_loss = 0.4322840973477939, disc_loss = 0.057534713278512534
Trained batch 464 in epoch 7, gen_loss = 0.4325285747487058, disc_loss = 0.05744863777441443
Trained batch 465 in epoch 7, gen_loss = 0.43251887948727913, disc_loss = 0.05743087139909951
Trained batch 466 in epoch 7, gen_loss = 0.43254424468863445, disc_loss = 0.057425211549176174
Trained batch 467 in epoch 7, gen_loss = 0.4323394192207573, disc_loss = 0.05788760296413357
Trained batch 468 in epoch 7, gen_loss = 0.432331044091853, disc_loss = 0.058479905335494735
Trained batch 469 in epoch 7, gen_loss = 0.4324704736471176, disc_loss = 0.05837531004427992
Trained batch 470 in epoch 7, gen_loss = 0.4323599118335991, disc_loss = 0.05830260126005202
Trained batch 471 in epoch 7, gen_loss = 0.43228393767849876, disc_loss = 0.058217858507443945
Trained batch 472 in epoch 7, gen_loss = 0.43222525173967535, disc_loss = 0.05820108034813395
Trained batch 473 in epoch 7, gen_loss = 0.43210555587891286, disc_loss = 0.05813221454881682
Trained batch 474 in epoch 7, gen_loss = 0.4321702310913487, disc_loss = 0.05816961599660939
Trained batch 475 in epoch 7, gen_loss = 0.432041552199536, disc_loss = 0.05807775432026765
Trained batch 476 in epoch 7, gen_loss = 0.43184753915048996, disc_loss = 0.0583254389813369
Trained batch 477 in epoch 7, gen_loss = 0.4319558563840938, disc_loss = 0.05881519663239202
Trained batch 478 in epoch 7, gen_loss = 0.431985419204688, disc_loss = 0.058741070241190976
Trained batch 479 in epoch 7, gen_loss = 0.4317961179340879, disc_loss = 0.05869919536295735
Trained batch 480 in epoch 7, gen_loss = 0.4316085315543748, disc_loss = 0.058722603497368416
Trained batch 481 in epoch 7, gen_loss = 0.4316914567561565, disc_loss = 0.05870953652499576
Trained batch 482 in epoch 7, gen_loss = 0.43189130004641924, disc_loss = 0.05863428086198589
Trained batch 483 in epoch 7, gen_loss = 0.4319479764123593, disc_loss = 0.058787386537787374
Trained batch 484 in epoch 7, gen_loss = 0.4317947482325367, disc_loss = 0.05898889325914386
Trained batch 485 in epoch 7, gen_loss = 0.43189084959128266, disc_loss = 0.0592107710092225
Trained batch 486 in epoch 7, gen_loss = 0.43180189968624155, disc_loss = 0.059599485436217285
Trained batch 487 in epoch 7, gen_loss = 0.43185466124874644, disc_loss = 0.05960185810223176
Trained batch 488 in epoch 7, gen_loss = 0.4318781954622951, disc_loss = 0.05953337187052215
Trained batch 489 in epoch 7, gen_loss = 0.43186532277233747, disc_loss = 0.05942596815554995
Trained batch 490 in epoch 7, gen_loss = 0.43182050562681834, disc_loss = 0.05934573104083462
Trained batch 491 in epoch 7, gen_loss = 0.43177214113435125, disc_loss = 0.05927291811903848
Trained batch 492 in epoch 7, gen_loss = 0.4316817376362141, disc_loss = 0.05918612568374746
Trained batch 493 in epoch 7, gen_loss = 0.43162807671406006, disc_loss = 0.05921032548144927
Trained batch 494 in epoch 7, gen_loss = 0.43158744585634484, disc_loss = 0.05916018007332553
Trained batch 495 in epoch 7, gen_loss = 0.4315517644488042, disc_loss = 0.05920587609204719
Trained batch 496 in epoch 7, gen_loss = 0.43157821773763155, disc_loss = 0.059172429436240605
Trained batch 497 in epoch 7, gen_loss = 0.43172766477707397, disc_loss = 0.05913007786697577
Trained batch 498 in epoch 7, gen_loss = 0.4315907593838915, disc_loss = 0.05961731871270868
Trained batch 499 in epoch 7, gen_loss = 0.4317178151011467, disc_loss = 0.05985474906070158
Trained batch 500 in epoch 7, gen_loss = 0.43184086585235215, disc_loss = 0.05976551601583298
Trained batch 501 in epoch 7, gen_loss = 0.43187537249103486, disc_loss = 0.05970866377771539
Trained batch 502 in epoch 7, gen_loss = 0.43186794176964355, disc_loss = 0.05961617475947658
Trained batch 503 in epoch 7, gen_loss = 0.4320260931456846, disc_loss = 0.05951147918757568
Trained batch 504 in epoch 7, gen_loss = 0.4319827179507454, disc_loss = 0.05942364134180295
Trained batch 505 in epoch 7, gen_loss = 0.4320034503112197, disc_loss = 0.059324060947258804
Trained batch 506 in epoch 7, gen_loss = 0.43198868838052545, disc_loss = 0.059219579872283976
Trained batch 507 in epoch 7, gen_loss = 0.4319802434660318, disc_loss = 0.059118533789777876
Trained batch 508 in epoch 7, gen_loss = 0.43196511227630213, disc_loss = 0.05901246937952409
Trained batch 509 in epoch 7, gen_loss = 0.4321406921335295, disc_loss = 0.05892668036588778
Trained batch 510 in epoch 7, gen_loss = 0.4321339773688531, disc_loss = 0.05886694759361941
Trained batch 511 in epoch 7, gen_loss = 0.432072157622315, disc_loss = 0.05879189780853267
Trained batch 512 in epoch 7, gen_loss = 0.4321625811895664, disc_loss = 0.058771435922505534
Trained batch 513 in epoch 7, gen_loss = 0.43215528553793864, disc_loss = 0.05868955547169416
Trained batch 514 in epoch 7, gen_loss = 0.4320470669894543, disc_loss = 0.05861599974072023
Trained batch 515 in epoch 7, gen_loss = 0.431933559708355, disc_loss = 0.05860194720484879
Trained batch 516 in epoch 7, gen_loss = 0.4320423301575954, disc_loss = 0.05851288180126371
Trained batch 517 in epoch 7, gen_loss = 0.4320201350800319, disc_loss = 0.05843536937600325
Trained batch 518 in epoch 7, gen_loss = 0.43205493056934924, disc_loss = 0.058401932792293054
Trained batch 519 in epoch 7, gen_loss = 0.4320213063978232, disc_loss = 0.05832869686284819
Trained batch 520 in epoch 7, gen_loss = 0.43186378885139204, disc_loss = 0.05836367170190557
Trained batch 521 in epoch 7, gen_loss = 0.4317472335022528, disc_loss = 0.05829481769065904
Trained batch 522 in epoch 7, gen_loss = 0.4317290727084727, disc_loss = 0.05830921608746322
Trained batch 523 in epoch 7, gen_loss = 0.43182646454745577, disc_loss = 0.0582637294681693
Trained batch 524 in epoch 7, gen_loss = 0.43199184690202985, disc_loss = 0.058215464197010514
Trained batch 525 in epoch 7, gen_loss = 0.43203181464635826, disc_loss = 0.058132783070245594
Trained batch 526 in epoch 7, gen_loss = 0.43188327601783866, disc_loss = 0.058204240725416356
Trained batch 527 in epoch 7, gen_loss = 0.43188830611832213, disc_loss = 0.05814748429155302
Trained batch 528 in epoch 7, gen_loss = 0.43186039188859143, disc_loss = 0.05829843030476657
Trained batch 529 in epoch 7, gen_loss = 0.43192140488129743, disc_loss = 0.05825835129307618
Trained batch 530 in epoch 7, gen_loss = 0.43186279261404065, disc_loss = 0.05822705104552462
Trained batch 531 in epoch 7, gen_loss = 0.4320423938053891, disc_loss = 0.05822133004299498
Trained batch 532 in epoch 7, gen_loss = 0.4320795917935935, disc_loss = 0.05818436135744107
Trained batch 533 in epoch 7, gen_loss = 0.43211697784255954, disc_loss = 0.058475328786804406
Trained batch 534 in epoch 7, gen_loss = 0.4321577033149862, disc_loss = 0.05840620638010588
Trained batch 535 in epoch 7, gen_loss = 0.43222436219898624, disc_loss = 0.05843559033958478
Trained batch 536 in epoch 7, gen_loss = 0.43229060582608486, disc_loss = 0.0584725336179491
Trained batch 537 in epoch 7, gen_loss = 0.4323208711515129, disc_loss = 0.05837999143833329
Trained batch 538 in epoch 7, gen_loss = 0.4324401872498648, disc_loss = 0.05828663032002581
Trained batch 539 in epoch 7, gen_loss = 0.43246424992879234, disc_loss = 0.05823104302700678
Trained batch 540 in epoch 7, gen_loss = 0.4322930987573155, disc_loss = 0.05820545489218107
Trained batch 541 in epoch 7, gen_loss = 0.4323913271356773, disc_loss = 0.05824266595214372
Trained batch 542 in epoch 7, gen_loss = 0.4323344589048108, disc_loss = 0.05833215509115977
Trained batch 543 in epoch 7, gen_loss = 0.4323432460317717, disc_loss = 0.058268329311377945
Trained batch 544 in epoch 7, gen_loss = 0.43232943481261576, disc_loss = 0.05891439331430566
Trained batch 545 in epoch 7, gen_loss = 0.43228567519904054, disc_loss = 0.05882295703936723
Trained batch 546 in epoch 7, gen_loss = 0.4321738855821341, disc_loss = 0.0588068384145109
Trained batch 547 in epoch 7, gen_loss = 0.4321579677562644, disc_loss = 0.05883107100312605
Trained batch 548 in epoch 7, gen_loss = 0.4322195189355284, disc_loss = 0.058852410813766395
Trained batch 549 in epoch 7, gen_loss = 0.4322962685064836, disc_loss = 0.05882051742000675
Trained batch 550 in epoch 7, gen_loss = 0.4322189118598204, disc_loss = 0.0589400438634939
Trained batch 551 in epoch 7, gen_loss = 0.43231391129286395, disc_loss = 0.058861220584072144
Trained batch 552 in epoch 7, gen_loss = 0.43234241838696635, disc_loss = 0.059009591509481964
Trained batch 553 in epoch 7, gen_loss = 0.43225898580215466, disc_loss = 0.05921734337373855
Trained batch 554 in epoch 7, gen_loss = 0.43227272973404274, disc_loss = 0.05917051516867637
Trained batch 555 in epoch 7, gen_loss = 0.43233080235102195, disc_loss = 0.05917274295779535
Trained batch 556 in epoch 7, gen_loss = 0.4321228541313425, disc_loss = 0.05919348870327151
Trained batch 557 in epoch 7, gen_loss = 0.4321391274852137, disc_loss = 0.05919315343293759
Trained batch 558 in epoch 7, gen_loss = 0.43205534382881544, disc_loss = 0.059117817456129276
Trained batch 559 in epoch 7, gen_loss = 0.4321678747556039, disc_loss = 0.05906466758668622
Trained batch 560 in epoch 7, gen_loss = 0.4322859114185374, disc_loss = 0.058987130827242225
Trained batch 561 in epoch 7, gen_loss = 0.43225088057993144, disc_loss = 0.05902026929052421
Trained batch 562 in epoch 7, gen_loss = 0.4321958643399166, disc_loss = 0.05898228895082924
Trained batch 563 in epoch 7, gen_loss = 0.43231774597091877, disc_loss = 0.059358999172327974
Trained batch 564 in epoch 7, gen_loss = 0.43215605938329105, disc_loss = 0.06007202820135363
Trained batch 565 in epoch 7, gen_loss = 0.4322354193816337, disc_loss = 0.06026025678486935
Trained batch 566 in epoch 7, gen_loss = 0.4322957749719973, disc_loss = 0.06059620040550999
Trained batch 567 in epoch 7, gen_loss = 0.43224104268240254, disc_loss = 0.06091565291133289
Trained batch 568 in epoch 7, gen_loss = 0.43219831957758414, disc_loss = 0.06101770399126874
Trained batch 569 in epoch 7, gen_loss = 0.43233715138937295, disc_loss = 0.061011701808801215
Trained batch 570 in epoch 7, gen_loss = 0.43231360439452526, disc_loss = 0.06102554430906219
Trained batch 571 in epoch 7, gen_loss = 0.4322278384457935, disc_loss = 0.06129616591387422
Trained batch 572 in epoch 7, gen_loss = 0.43213947889692494, disc_loss = 0.061346273420274544
Trained batch 573 in epoch 7, gen_loss = 0.4321361398551522, disc_loss = 0.06154290538643023
Trained batch 574 in epoch 7, gen_loss = 0.4321477584735207, disc_loss = 0.06153811677601998
Trained batch 575 in epoch 7, gen_loss = 0.431999650111215, disc_loss = 0.0615854148309154
Trained batch 576 in epoch 7, gen_loss = 0.4319471290764404, disc_loss = 0.061731083902483566
Trained batch 577 in epoch 7, gen_loss = 0.43213888502657205, disc_loss = 0.061654996107151944
Trained batch 578 in epoch 7, gen_loss = 0.4321325169120222, disc_loss = 0.06161487872619021
Trained batch 579 in epoch 7, gen_loss = 0.4321319846757527, disc_loss = 0.061638810029173076
Trained batch 580 in epoch 7, gen_loss = 0.4321920391614589, disc_loss = 0.06175791399702494
Trained batch 581 in epoch 7, gen_loss = 0.4321871838209146, disc_loss = 0.06174770917997878
Trained batch 582 in epoch 7, gen_loss = 0.4322876536621238, disc_loss = 0.06167677489563018
Trained batch 583 in epoch 7, gen_loss = 0.4323209063341356, disc_loss = 0.06172721783195188
Trained batch 584 in epoch 7, gen_loss = 0.43211336059448047, disc_loss = 0.06203282010566411
Trained batch 585 in epoch 7, gen_loss = 0.43230149449952227, disc_loss = 0.06198601664954625
Trained batch 586 in epoch 7, gen_loss = 0.432375897388442, disc_loss = 0.062076378898898193
Trained batch 587 in epoch 7, gen_loss = 0.4324979106483816, disc_loss = 0.061985459960727844
Trained batch 588 in epoch 7, gen_loss = 0.43240985400810306, disc_loss = 0.061907751763600014
Trained batch 589 in epoch 7, gen_loss = 0.4324628055095673, disc_loss = 0.06186888512437058
Trained batch 590 in epoch 7, gen_loss = 0.4324875189568186, disc_loss = 0.06178839395473539
Trained batch 591 in epoch 7, gen_loss = 0.4326234911946026, disc_loss = 0.061812525342542654
Trained batch 592 in epoch 7, gen_loss = 0.43249493319710836, disc_loss = 0.061849024031754164
Trained batch 593 in epoch 7, gen_loss = 0.4325070138832535, disc_loss = 0.061794533257479294
Trained batch 594 in epoch 7, gen_loss = 0.43252036576511477, disc_loss = 0.06184188248785291
Trained batch 595 in epoch 7, gen_loss = 0.43251919881409445, disc_loss = 0.06205635746408116
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.47573181986808777, disc_loss = 0.09105394780635834
Trained batch 1 in epoch 8, gen_loss = 0.49637411534786224, disc_loss = 0.05982348136603832
Trained batch 2 in epoch 8, gen_loss = 0.4589438736438751, disc_loss = 0.05608602985739708
Trained batch 3 in epoch 8, gen_loss = 0.45883312076330185, disc_loss = 0.046254136599600315
Trained batch 4 in epoch 8, gen_loss = 0.43633587956428527, disc_loss = 0.039884593710303305
Trained batch 5 in epoch 8, gen_loss = 0.4396233807007472, disc_loss = 0.04090810101479292
Trained batch 6 in epoch 8, gen_loss = 0.44584854585783823, disc_loss = 0.04253783422921385
Trained batch 7 in epoch 8, gen_loss = 0.4426114559173584, disc_loss = 0.048933762358501554
Trained batch 8 in epoch 8, gen_loss = 0.4432374934355418, disc_loss = 0.04702256268097295
Trained batch 9 in epoch 8, gen_loss = 0.44511182606220245, disc_loss = 0.043247791938483715
Trained batch 10 in epoch 8, gen_loss = 0.4437111507762562, disc_loss = 0.04045857751572674
Trained batch 11 in epoch 8, gen_loss = 0.4419452448685964, disc_loss = 0.0381492346059531
Trained batch 12 in epoch 8, gen_loss = 0.43712543982725877, disc_loss = 0.037730517940452464
Trained batch 13 in epoch 8, gen_loss = 0.4379149377346039, disc_loss = 0.036672142799943686
Trained batch 14 in epoch 8, gen_loss = 0.4360830903053284, disc_loss = 0.05961202960461378
Trained batch 15 in epoch 8, gen_loss = 0.43028323352336884, disc_loss = 0.06503414158942178
Trained batch 16 in epoch 8, gen_loss = 0.4308200653861551, disc_loss = 0.06404516873333384
Trained batch 17 in epoch 8, gen_loss = 0.43549103869332206, disc_loss = 0.061056062734375395
Trained batch 18 in epoch 8, gen_loss = 0.4361648418401417, disc_loss = 0.06036586250717703
Trained batch 19 in epoch 8, gen_loss = 0.43729300498962403, disc_loss = 0.058120469888672234
Trained batch 20 in epoch 8, gen_loss = 0.44352569182713825, disc_loss = 0.056323193944990635
Trained batch 21 in epoch 8, gen_loss = 0.44314935126087884, disc_loss = 0.05825952868061987
Trained batch 22 in epoch 8, gen_loss = 0.44615599772204523, disc_loss = 0.06018777989336978
Trained batch 23 in epoch 8, gen_loss = 0.4493898116052151, disc_loss = 0.05853557963079462
Trained batch 24 in epoch 8, gen_loss = 0.4484283137321472, disc_loss = 0.057261982522904875
Trained batch 25 in epoch 8, gen_loss = 0.44658844746076143, disc_loss = 0.05662158600842723
Trained batch 26 in epoch 8, gen_loss = 0.4477185916017603, disc_loss = 0.05657394019955838
Trained batch 27 in epoch 8, gen_loss = 0.4471577214343207, disc_loss = 0.05485508341475257
Trained batch 28 in epoch 8, gen_loss = 0.4467685705628888, disc_loss = 0.053229737609367944
Trained batch 29 in epoch 8, gen_loss = 0.44729507466157276, disc_loss = 0.05187323816741506
Trained batch 30 in epoch 8, gen_loss = 0.4477262439266328, disc_loss = 0.0516578234551895
Trained batch 31 in epoch 8, gen_loss = 0.44930186681449413, disc_loss = 0.052543145284289494
Trained batch 32 in epoch 8, gen_loss = 0.44706269376205676, disc_loss = 0.05368313523517414
Trained batch 33 in epoch 8, gen_loss = 0.44691195645753073, disc_loss = 0.05609842447344871
Trained batch 34 in epoch 8, gen_loss = 0.44962927528790064, disc_loss = 0.055083086474665574
Trained batch 35 in epoch 8, gen_loss = 0.4480244277252091, disc_loss = 0.05482477366199924
Trained batch 36 in epoch 8, gen_loss = 0.45184212359222203, disc_loss = 0.05374292017438927
Trained batch 37 in epoch 8, gen_loss = 0.4506242047799261, disc_loss = 0.05285065567218944
Trained batch 38 in epoch 8, gen_loss = 0.4482696606562688, disc_loss = 0.05195956681974423
Trained batch 39 in epoch 8, gen_loss = 0.4474520176649094, disc_loss = 0.05089322854764759
Trained batch 40 in epoch 8, gen_loss = 0.4474559273661637, disc_loss = 0.05005518537832469
Trained batch 41 in epoch 8, gen_loss = 0.4494654160170328, disc_loss = 0.05065971657278992
Trained batch 42 in epoch 8, gen_loss = 0.44695482836213224, disc_loss = 0.05321070006073907
Trained batch 43 in epoch 8, gen_loss = 0.4461317766796459, disc_loss = 0.05220286514271389
Trained batch 44 in epoch 8, gen_loss = 0.4455492655436198, disc_loss = 0.053192200594478184
Trained batch 45 in epoch 8, gen_loss = 0.4439491772133371, disc_loss = 0.05476843954428383
Trained batch 46 in epoch 8, gen_loss = 0.4430198441160486, disc_loss = 0.054082024327300963
Trained batch 47 in epoch 8, gen_loss = 0.4428436079372962, disc_loss = 0.05410679782895992
Trained batch 48 in epoch 8, gen_loss = 0.4431288668087551, disc_loss = 0.053966415285760044
Trained batch 49 in epoch 8, gen_loss = 0.4427448445558548, disc_loss = 0.0533201365172863
Trained batch 50 in epoch 8, gen_loss = 0.4433234976787193, disc_loss = 0.053545158283383236
Trained batch 51 in epoch 8, gen_loss = 0.4432820053054736, disc_loss = 0.053141151913083516
Trained batch 52 in epoch 8, gen_loss = 0.4425001009455267, disc_loss = 0.054253531936204656
Trained batch 53 in epoch 8, gen_loss = 0.4422531928177233, disc_loss = 0.05393069609999657
Trained batch 54 in epoch 8, gen_loss = 0.4417133878577839, disc_loss = 0.053852210397070104
Trained batch 55 in epoch 8, gen_loss = 0.4423480049840042, disc_loss = 0.05508065489786012
Trained batch 56 in epoch 8, gen_loss = 0.44152145375285234, disc_loss = 0.05497964170941135
Trained batch 57 in epoch 8, gen_loss = 0.4413092526896247, disc_loss = 0.05442829587464702
Trained batch 58 in epoch 8, gen_loss = 0.44158335914046076, disc_loss = 0.05377351701007051
Trained batch 59 in epoch 8, gen_loss = 0.44084868679443995, disc_loss = 0.053219039520869656
Trained batch 60 in epoch 8, gen_loss = 0.4412021720018543, disc_loss = 0.052837679376367665
Trained batch 61 in epoch 8, gen_loss = 0.44165258974798266, disc_loss = 0.05252891658775268
Trained batch 62 in epoch 8, gen_loss = 0.4419326597735995, disc_loss = 0.05241376989417606
Trained batch 63 in epoch 8, gen_loss = 0.44165669567883015, disc_loss = 0.053090175380930305
Trained batch 64 in epoch 8, gen_loss = 0.44091679591398975, disc_loss = 0.05256618977739261
Trained batch 65 in epoch 8, gen_loss = 0.4414783138217348, disc_loss = 0.05187960814289523
Trained batch 66 in epoch 8, gen_loss = 0.44310945895180776, disc_loss = 0.05163286647189464
Trained batch 67 in epoch 8, gen_loss = 0.442269107874702, disc_loss = 0.05163557765841046
Trained batch 68 in epoch 8, gen_loss = 0.441880092240762, disc_loss = 0.05241572742174933
Trained batch 69 in epoch 8, gen_loss = 0.44051207091127126, disc_loss = 0.05590976022982171
Trained batch 70 in epoch 8, gen_loss = 0.4402033254294328, disc_loss = 0.056528929712801754
Trained batch 71 in epoch 8, gen_loss = 0.44138315030270153, disc_loss = 0.05937502371509456
Trained batch 72 in epoch 8, gen_loss = 0.4406039984258887, disc_loss = 0.05919395283834167
Trained batch 73 in epoch 8, gen_loss = 0.4405533824418042, disc_loss = 0.05985891495554431
Trained batch 74 in epoch 8, gen_loss = 0.43962884028752647, disc_loss = 0.05980521826694409
Trained batch 75 in epoch 8, gen_loss = 0.4386675969550484, disc_loss = 0.06045065240591372
Trained batch 76 in epoch 8, gen_loss = 0.4396988989470841, disc_loss = 0.06078152154124789
Trained batch 77 in epoch 8, gen_loss = 0.4396683795329852, disc_loss = 0.06026113633878338
Trained batch 78 in epoch 8, gen_loss = 0.43970212114008167, disc_loss = 0.06051226308027023
Trained batch 79 in epoch 8, gen_loss = 0.44038469940423963, disc_loss = 0.06067445500520989
Trained batch 80 in epoch 8, gen_loss = 0.44058903242334907, disc_loss = 0.06118874425459423
Trained batch 81 in epoch 8, gen_loss = 0.44072546028509374, disc_loss = 0.06092800371485149
Trained batch 82 in epoch 8, gen_loss = 0.44038315099405956, disc_loss = 0.0620049362867532
Trained batch 83 in epoch 8, gen_loss = 0.43973670048373087, disc_loss = 0.06272484582760149
Trained batch 84 in epoch 8, gen_loss = 0.4403608616660623, disc_loss = 0.06246435145902283
Trained batch 85 in epoch 8, gen_loss = 0.4406601987605871, disc_loss = 0.06184476362757905
Trained batch 86 in epoch 8, gen_loss = 0.4400488545839814, disc_loss = 0.06230904161930084
Trained batch 87 in epoch 8, gen_loss = 0.44083446569063445, disc_loss = 0.06170544965954667
Trained batch 88 in epoch 8, gen_loss = 0.44124000360456744, disc_loss = 0.0617857366758451
Trained batch 89 in epoch 8, gen_loss = 0.4410612278514438, disc_loss = 0.06284665951712264
Trained batch 90 in epoch 8, gen_loss = 0.4418256767503508, disc_loss = 0.06273296882736158
Trained batch 91 in epoch 8, gen_loss = 0.44180806823398755, disc_loss = 0.062361772455599
Trained batch 92 in epoch 8, gen_loss = 0.4418391143122027, disc_loss = 0.0618134878716001
Trained batch 93 in epoch 8, gen_loss = 0.44182819032922704, disc_loss = 0.0617022631947506
Trained batch 94 in epoch 8, gen_loss = 0.4421164421658767, disc_loss = 0.06139885201854141
Trained batch 95 in epoch 8, gen_loss = 0.44199462855855626, disc_loss = 0.061010099297467
Trained batch 96 in epoch 8, gen_loss = 0.44184317416751506, disc_loss = 0.060682387859320515
Trained batch 97 in epoch 8, gen_loss = 0.4421074122798686, disc_loss = 0.06071381796417492
Trained batch 98 in epoch 8, gen_loss = 0.4420375438651653, disc_loss = 0.06030596372191653
Trained batch 99 in epoch 8, gen_loss = 0.44177755385637285, disc_loss = 0.05995170344598591
Trained batch 100 in epoch 8, gen_loss = 0.4411899226136727, disc_loss = 0.05951017446557779
Trained batch 101 in epoch 8, gen_loss = 0.44084767383687634, disc_loss = 0.05923915901860478
Trained batch 102 in epoch 8, gen_loss = 0.44103965018559427, disc_loss = 0.060067095649112195
Trained batch 103 in epoch 8, gen_loss = 0.44091852754354477, disc_loss = 0.061309575595749684
Trained batch 104 in epoch 8, gen_loss = 0.4407150382087344, disc_loss = 0.06102653953823305
Trained batch 105 in epoch 8, gen_loss = 0.4406928833363191, disc_loss = 0.06102831333981089
Trained batch 106 in epoch 8, gen_loss = 0.440394662808035, disc_loss = 0.061920447980062424
Trained batch 107 in epoch 8, gen_loss = 0.4399739365886759, disc_loss = 0.06210949778108409
Trained batch 108 in epoch 8, gen_loss = 0.44062104575130917, disc_loss = 0.06195963050213155
Trained batch 109 in epoch 8, gen_loss = 0.44028412103652953, disc_loss = 0.06219612447206269
Trained batch 110 in epoch 8, gen_loss = 0.4398197719642708, disc_loss = 0.06214933985894596
Trained batch 111 in epoch 8, gen_loss = 0.4391134721892221, disc_loss = 0.06173389904766476
Trained batch 112 in epoch 8, gen_loss = 0.4391028693819468, disc_loss = 0.062266040107119926
Trained batch 113 in epoch 8, gen_loss = 0.43936232150646676, disc_loss = 0.06247831156411976
Trained batch 114 in epoch 8, gen_loss = 0.43873923032180123, disc_loss = 0.06345730755154205
Trained batch 115 in epoch 8, gen_loss = 0.43994455090884504, disc_loss = 0.06431058056427744
Trained batch 116 in epoch 8, gen_loss = 0.4399890461538592, disc_loss = 0.06410546980511683
Trained batch 117 in epoch 8, gen_loss = 0.4396679242283611, disc_loss = 0.06442108628008578
Trained batch 118 in epoch 8, gen_loss = 0.43908493358547945, disc_loss = 0.06441290949729561
Trained batch 119 in epoch 8, gen_loss = 0.4386653964718183, disc_loss = 0.06445861499911795
Trained batch 120 in epoch 8, gen_loss = 0.4385091086064488, disc_loss = 0.06467363414593226
Trained batch 121 in epoch 8, gen_loss = 0.43763626867630445, disc_loss = 0.06663311044609205
Trained batch 122 in epoch 8, gen_loss = 0.4374042773634438, disc_loss = 0.06665733575487767
Trained batch 123 in epoch 8, gen_loss = 0.43721957913329523, disc_loss = 0.0665562452162586
Trained batch 124 in epoch 8, gen_loss = 0.43700507974624636, disc_loss = 0.06621704054623842
Trained batch 125 in epoch 8, gen_loss = 0.43669617507192826, disc_loss = 0.06624772134310906
Trained batch 126 in epoch 8, gen_loss = 0.4365902336563651, disc_loss = 0.06602985242484358
Trained batch 127 in epoch 8, gen_loss = 0.436515249311924, disc_loss = 0.06604533893550979
Trained batch 128 in epoch 8, gen_loss = 0.4364131903925607, disc_loss = 0.0672395273884253
Trained batch 129 in epoch 8, gen_loss = 0.4363378478930547, disc_loss = 0.06770758302882314
Trained batch 130 in epoch 8, gen_loss = 0.43659210660075415, disc_loss = 0.06758881210285517
Trained batch 131 in epoch 8, gen_loss = 0.4364869711977063, disc_loss = 0.06750159110224833
Trained batch 132 in epoch 8, gen_loss = 0.43645475278223367, disc_loss = 0.06711065583631284
Trained batch 133 in epoch 8, gen_loss = 0.4372595668728672, disc_loss = 0.06686514562496276
Trained batch 134 in epoch 8, gen_loss = 0.4374392708142599, disc_loss = 0.06649601729241786
Trained batch 135 in epoch 8, gen_loss = 0.4379081585827996, disc_loss = 0.06613809984478661
Trained batch 136 in epoch 8, gen_loss = 0.4377012120111145, disc_loss = 0.0661980190729029
Trained batch 137 in epoch 8, gen_loss = 0.43731968536757043, disc_loss = 0.06579863851674009
Trained batch 138 in epoch 8, gen_loss = 0.4374396022704008, disc_loss = 0.06563392149539088
Trained batch 139 in epoch 8, gen_loss = 0.436709155355181, disc_loss = 0.0653907885708447
Trained batch 140 in epoch 8, gen_loss = 0.4362786735625977, disc_loss = 0.06566822911275828
Trained batch 141 in epoch 8, gen_loss = 0.43707205858868614, disc_loss = 0.06673118180241173
Trained batch 142 in epoch 8, gen_loss = 0.43704439960159625, disc_loss = 0.06694212281698739
Trained batch 143 in epoch 8, gen_loss = 0.4371890243556764, disc_loss = 0.06709113920805976
Trained batch 144 in epoch 8, gen_loss = 0.43750191474783007, disc_loss = 0.06866120713409679
Trained batch 145 in epoch 8, gen_loss = 0.4373020450138066, disc_loss = 0.07010537954302479
Trained batch 146 in epoch 8, gen_loss = 0.4375491953220497, disc_loss = 0.06973574520247121
Trained batch 147 in epoch 8, gen_loss = 0.4378397674173922, disc_loss = 0.06948814900415773
Trained batch 148 in epoch 8, gen_loss = 0.43797115591548436, disc_loss = 0.06915345434849494
Trained batch 149 in epoch 8, gen_loss = 0.43773239076137543, disc_loss = 0.06887262366091211
Trained batch 150 in epoch 8, gen_loss = 0.43770425406512836, disc_loss = 0.06850873752318273
Trained batch 151 in epoch 8, gen_loss = 0.43781425647045435, disc_loss = 0.06819684396032244
Trained batch 152 in epoch 8, gen_loss = 0.4377777218039519, disc_loss = 0.06790934971174578
Trained batch 153 in epoch 8, gen_loss = 0.4377522263434026, disc_loss = 0.06788649047761187
Trained batch 154 in epoch 8, gen_loss = 0.4373804159702793, disc_loss = 0.06776689916488625
Trained batch 155 in epoch 8, gen_loss = 0.4371996346192482, disc_loss = 0.06742636234356233
Trained batch 156 in epoch 8, gen_loss = 0.43754326405039257, disc_loss = 0.06709171098413741
Trained batch 157 in epoch 8, gen_loss = 0.43768653726275963, disc_loss = 0.06710314870918099
Trained batch 158 in epoch 8, gen_loss = 0.4379445145714958, disc_loss = 0.06764527243919342
Trained batch 159 in epoch 8, gen_loss = 0.43775315638631584, disc_loss = 0.06775399700272829
Trained batch 160 in epoch 8, gen_loss = 0.4379272858918824, disc_loss = 0.06759394110637422
Trained batch 161 in epoch 8, gen_loss = 0.4387788792819153, disc_loss = 0.06776902426816063
Trained batch 162 in epoch 8, gen_loss = 0.43850169189137184, disc_loss = 0.06740569539848099
Trained batch 163 in epoch 8, gen_loss = 0.43785602563038106, disc_loss = 0.06789767498536627
Trained batch 164 in epoch 8, gen_loss = 0.43816984061038855, disc_loss = 0.06762450961113879
Trained batch 165 in epoch 8, gen_loss = 0.4383956793561039, disc_loss = 0.06761904896225736
Trained batch 166 in epoch 8, gen_loss = 0.4387147676445053, disc_loss = 0.0673567716891091
Trained batch 167 in epoch 8, gen_loss = 0.4380571682538305, disc_loss = 0.06732410956950237
Trained batch 168 in epoch 8, gen_loss = 0.4381662905216217, disc_loss = 0.06721110306349555
Trained batch 169 in epoch 8, gen_loss = 0.43792270562228036, disc_loss = 0.06689914474263788
Trained batch 170 in epoch 8, gen_loss = 0.43819785815233375, disc_loss = 0.06654946778884582
Trained batch 171 in epoch 8, gen_loss = 0.4383997983017633, disc_loss = 0.06624215802849205
Trained batch 172 in epoch 8, gen_loss = 0.43791360283173575, disc_loss = 0.06603798251383738
Trained batch 173 in epoch 8, gen_loss = 0.4379939601339143, disc_loss = 0.0667486079304811
Trained batch 174 in epoch 8, gen_loss = 0.4375099844591958, disc_loss = 0.06646311123988458
Trained batch 175 in epoch 8, gen_loss = 0.4379014652222395, disc_loss = 0.06647080621703273
Trained batch 176 in epoch 8, gen_loss = 0.43754846228044586, disc_loss = 0.06665391435499414
Trained batch 177 in epoch 8, gen_loss = 0.4378318701232417, disc_loss = 0.06682153094790122
Trained batch 178 in epoch 8, gen_loss = 0.4378285432994033, disc_loss = 0.06682794173274127
Trained batch 179 in epoch 8, gen_loss = 0.4381725364261203, disc_loss = 0.0669514696062025
Trained batch 180 in epoch 8, gen_loss = 0.4388630940110644, disc_loss = 0.06718376314380715
Trained batch 181 in epoch 8, gen_loss = 0.43895241618156433, disc_loss = 0.06699983481379164
Trained batch 182 in epoch 8, gen_loss = 0.4388655280806328, disc_loss = 0.06672081164506778
Trained batch 183 in epoch 8, gen_loss = 0.43874984623297403, disc_loss = 0.06674665877210867
Trained batch 184 in epoch 8, gen_loss = 0.4389207870573611, disc_loss = 0.06663970033562666
Trained batch 185 in epoch 8, gen_loss = 0.4391068026263227, disc_loss = 0.06744137779378923
Trained batch 186 in epoch 8, gen_loss = 0.4388509145713745, disc_loss = 0.0682615799191881
Trained batch 187 in epoch 8, gen_loss = 0.4389353553031353, disc_loss = 0.06803028144318848
Trained batch 188 in epoch 8, gen_loss = 0.43909321417884223, disc_loss = 0.06790185488622498
Trained batch 189 in epoch 8, gen_loss = 0.43890048720334707, disc_loss = 0.06826088680934748
Trained batch 190 in epoch 8, gen_loss = 0.43857765197753906, disc_loss = 0.06811813795110162
Trained batch 191 in epoch 8, gen_loss = 0.4382184130760531, disc_loss = 0.06787043855971812
Trained batch 192 in epoch 8, gen_loss = 0.438322055833945, disc_loss = 0.0676266965866475
Trained batch 193 in epoch 8, gen_loss = 0.4382404685020447, disc_loss = 0.06732776601674016
Trained batch 194 in epoch 8, gen_loss = 0.43813221362920907, disc_loss = 0.06714378010768157
Trained batch 195 in epoch 8, gen_loss = 0.43839444068013406, disc_loss = 0.06721861633871283
Trained batch 196 in epoch 8, gen_loss = 0.43835433001445634, disc_loss = 0.0672456943973672
Trained batch 197 in epoch 8, gen_loss = 0.43799022908764657, disc_loss = 0.06714074405832123
Trained batch 198 in epoch 8, gen_loss = 0.43806667633392105, disc_loss = 0.06731856462718853
Trained batch 199 in epoch 8, gen_loss = 0.43832877427339556, disc_loss = 0.06716158473864198
Trained batch 200 in epoch 8, gen_loss = 0.4384086216563609, disc_loss = 0.06710549829462867
Trained batch 201 in epoch 8, gen_loss = 0.4380723153895671, disc_loss = 0.06713085024073573
Trained batch 202 in epoch 8, gen_loss = 0.4385898381912062, disc_loss = 0.06719587060618283
Trained batch 203 in epoch 8, gen_loss = 0.43936121332294803, disc_loss = 0.06707443729700412
Trained batch 204 in epoch 8, gen_loss = 0.43914727888456206, disc_loss = 0.06680277627324913
Trained batch 205 in epoch 8, gen_loss = 0.4394501559074643, disc_loss = 0.06652312751552
Trained batch 206 in epoch 8, gen_loss = 0.439555353300583, disc_loss = 0.06627680982152621
Trained batch 207 in epoch 8, gen_loss = 0.4392032108914394, disc_loss = 0.06633930733928886
Trained batch 208 in epoch 8, gen_loss = 0.4395323320153798, disc_loss = 0.06625763599595955
Trained batch 209 in epoch 8, gen_loss = 0.43963495450360435, disc_loss = 0.06640438769190084
Trained batch 210 in epoch 8, gen_loss = 0.4392578510029056, disc_loss = 0.06635116912883605
Trained batch 211 in epoch 8, gen_loss = 0.4391920458314554, disc_loss = 0.0661680290370055
Trained batch 212 in epoch 8, gen_loss = 0.4390757804465406, disc_loss = 0.0660899411624586
Trained batch 213 in epoch 8, gen_loss = 0.4390083047274117, disc_loss = 0.06582732265379941
Trained batch 214 in epoch 8, gen_loss = 0.43910805929538815, disc_loss = 0.06556935210733912
Trained batch 215 in epoch 8, gen_loss = 0.43928610533475876, disc_loss = 0.06538325547309662
Trained batch 216 in epoch 8, gen_loss = 0.43936324394243653, disc_loss = 0.0652736409691759
Trained batch 217 in epoch 8, gen_loss = 0.4389946203713023, disc_loss = 0.06512914950865398
Trained batch 218 in epoch 8, gen_loss = 0.4389648998164695, disc_loss = 0.06502585062867702
Trained batch 219 in epoch 8, gen_loss = 0.43882618275555696, disc_loss = 0.06509411061521281
Trained batch 220 in epoch 8, gen_loss = 0.43921389919600334, disc_loss = 0.06532499373667111
Trained batch 221 in epoch 8, gen_loss = 0.439136580975206, disc_loss = 0.06505762869576076
Trained batch 222 in epoch 8, gen_loss = 0.4391519559605774, disc_loss = 0.06481698328303381
Trained batch 223 in epoch 8, gen_loss = 0.4389016775946532, disc_loss = 0.06479052669601515
Trained batch 224 in epoch 8, gen_loss = 0.43915436996353996, disc_loss = 0.0646752402269178
Trained batch 225 in epoch 8, gen_loss = 0.4393525743379002, disc_loss = 0.06473799696835005
Trained batch 226 in epoch 8, gen_loss = 0.43894043065902943, disc_loss = 0.0651604146635086
Trained batch 227 in epoch 8, gen_loss = 0.4389763858757521, disc_loss = 0.06495729046301883
Trained batch 228 in epoch 8, gen_loss = 0.43890139135210793, disc_loss = 0.06525725402816414
Trained batch 229 in epoch 8, gen_loss = 0.4385113660408103, disc_loss = 0.0651761363543894
Trained batch 230 in epoch 8, gen_loss = 0.43816502140713975, disc_loss = 0.06566056772034405
Trained batch 231 in epoch 8, gen_loss = 0.4385487398710744, disc_loss = 0.0665925008501729
Trained batch 232 in epoch 8, gen_loss = 0.4384571311299893, disc_loss = 0.06634355475526511
Trained batch 233 in epoch 8, gen_loss = 0.4380745326097195, disc_loss = 0.06627505280586898
Trained batch 234 in epoch 8, gen_loss = 0.4381224784445255, disc_loss = 0.06663317295148018
Trained batch 235 in epoch 8, gen_loss = 0.437754712746305, disc_loss = 0.06696094643577176
Trained batch 236 in epoch 8, gen_loss = 0.4378744668095424, disc_loss = 0.0667093103999107
Trained batch 237 in epoch 8, gen_loss = 0.4379587540356051, disc_loss = 0.06659853447643461
Trained batch 238 in epoch 8, gen_loss = 0.4378609365499169, disc_loss = 0.06641144247211235
Trained batch 239 in epoch 8, gen_loss = 0.43754547921319803, disc_loss = 0.06650136731914244
Trained batch 240 in epoch 8, gen_loss = 0.43708988801572335, disc_loss = 0.06726973059614232
Trained batch 241 in epoch 8, gen_loss = 0.43713416971943597, disc_loss = 0.06737225235840075
Trained batch 242 in epoch 8, gen_loss = 0.43716133585192046, disc_loss = 0.06754933166750726
Trained batch 243 in epoch 8, gen_loss = 0.43713193679930734, disc_loss = 0.0676018387846435
Trained batch 244 in epoch 8, gen_loss = 0.4371348152355272, disc_loss = 0.06742611700973036
Trained batch 245 in epoch 8, gen_loss = 0.43697473406791687, disc_loss = 0.06724894107546567
Trained batch 246 in epoch 8, gen_loss = 0.4368060710217789, disc_loss = 0.06707620416552974
Trained batch 247 in epoch 8, gen_loss = 0.4365709951568034, disc_loss = 0.06688092155720017
Trained batch 248 in epoch 8, gen_loss = 0.4363163251235303, disc_loss = 0.06664872611779346
Trained batch 249 in epoch 8, gen_loss = 0.4365649393796921, disc_loss = 0.06651218440569938
Trained batch 250 in epoch 8, gen_loss = 0.43680313562017037, disc_loss = 0.06634524600595176
Trained batch 251 in epoch 8, gen_loss = 0.4365934823004026, disc_loss = 0.06616261220973221
Trained batch 252 in epoch 8, gen_loss = 0.4366006852374246, disc_loss = 0.06594672984086537
Trained batch 253 in epoch 8, gen_loss = 0.43650675512204956, disc_loss = 0.06591588868319577
Trained batch 254 in epoch 8, gen_loss = 0.4367828281486736, disc_loss = 0.06614746041778548
Trained batch 255 in epoch 8, gen_loss = 0.436592742218636, disc_loss = 0.06651227146539895
Trained batch 256 in epoch 8, gen_loss = 0.4366105026076276, disc_loss = 0.06635399640570412
Trained batch 257 in epoch 8, gen_loss = 0.43680190000423164, disc_loss = 0.06618198898418756
Trained batch 258 in epoch 8, gen_loss = 0.4366364454900896, disc_loss = 0.06606684691492022
Trained batch 259 in epoch 8, gen_loss = 0.43630107996555473, disc_loss = 0.06631671135994391
Trained batch 260 in epoch 8, gen_loss = 0.4367095258272471, disc_loss = 0.06609570233765062
Trained batch 261 in epoch 8, gen_loss = 0.4366374481042833, disc_loss = 0.06587831205546231
Trained batch 262 in epoch 8, gen_loss = 0.4366344221417895, disc_loss = 0.06570417782603391
Trained batch 263 in epoch 8, gen_loss = 0.43661888587203895, disc_loss = 0.06555826270028553
Trained batch 264 in epoch 8, gen_loss = 0.436329281779955, disc_loss = 0.06557938734350621
Trained batch 265 in epoch 8, gen_loss = 0.43649721717027795, disc_loss = 0.0653787587709809
Trained batch 266 in epoch 8, gen_loss = 0.4366906394672751, disc_loss = 0.06516086807202422
Trained batch 267 in epoch 8, gen_loss = 0.4367000728623191, disc_loss = 0.06496156082460795
Trained batch 268 in epoch 8, gen_loss = 0.43657652618273485, disc_loss = 0.06477099216325022
Trained batch 269 in epoch 8, gen_loss = 0.4366530801411028, disc_loss = 0.06457206955938427
Trained batch 270 in epoch 8, gen_loss = 0.43643555276068374, disc_loss = 0.06437455832861996
Trained batch 271 in epoch 8, gen_loss = 0.43625855139073205, disc_loss = 0.06444762170876321
Trained batch 272 in epoch 8, gen_loss = 0.4364178401209933, disc_loss = 0.06535132775499379
Trained batch 273 in epoch 8, gen_loss = 0.4362276943713209, disc_loss = 0.06637152632779993
Trained batch 274 in epoch 8, gen_loss = 0.43626064842397516, disc_loss = 0.06685965776782145
Trained batch 275 in epoch 8, gen_loss = 0.43617816582538077, disc_loss = 0.06686711333273654
Trained batch 276 in epoch 8, gen_loss = 0.43585778347852, disc_loss = 0.06698476996891442
Trained batch 277 in epoch 8, gen_loss = 0.4359286495035501, disc_loss = 0.06702329620732356
Trained batch 278 in epoch 8, gen_loss = 0.435788284706813, disc_loss = 0.0672415906736981
Trained batch 279 in epoch 8, gen_loss = 0.43548386373690195, disc_loss = 0.06819315675446498
Trained batch 280 in epoch 8, gen_loss = 0.4356793576712286, disc_loss = 0.06805352796054713
Trained batch 281 in epoch 8, gen_loss = 0.43557792035400444, disc_loss = 0.06794990910587052
Trained batch 282 in epoch 8, gen_loss = 0.4357189717225388, disc_loss = 0.06804727528296911
Trained batch 283 in epoch 8, gen_loss = 0.4355686207262563, disc_loss = 0.0679828579780239
Trained batch 284 in epoch 8, gen_loss = 0.43539618755641735, disc_loss = 0.06782575874801791
Trained batch 285 in epoch 8, gen_loss = 0.43537789479002253, disc_loss = 0.06782957075580538
Trained batch 286 in epoch 8, gen_loss = 0.43531095784300294, disc_loss = 0.06783949719086445
Trained batch 287 in epoch 8, gen_loss = 0.43545692403697306, disc_loss = 0.06764376099777615
Trained batch 288 in epoch 8, gen_loss = 0.4356355532024146, disc_loss = 0.06743059361475974
Trained batch 289 in epoch 8, gen_loss = 0.4357226041884258, disc_loss = 0.0672558024397184
Trained batch 290 in epoch 8, gen_loss = 0.4355061616479736, disc_loss = 0.06795357801404196
Trained batch 291 in epoch 8, gen_loss = 0.4352732584492801, disc_loss = 0.06838092293386182
Trained batch 292 in epoch 8, gen_loss = 0.435165544520466, disc_loss = 0.06820589219420232
Trained batch 293 in epoch 8, gen_loss = 0.4350373195547636, disc_loss = 0.06825946840983467
Trained batch 294 in epoch 8, gen_loss = 0.4350592446529259, disc_loss = 0.06806413459954626
Trained batch 295 in epoch 8, gen_loss = 0.4346428212483187, disc_loss = 0.06814185025900402
Trained batch 296 in epoch 8, gen_loss = 0.43439900975436074, disc_loss = 0.06803281107911156
Trained batch 297 in epoch 8, gen_loss = 0.43486526008420345, disc_loss = 0.0682234617525199
Trained batch 298 in epoch 8, gen_loss = 0.43478306828932617, disc_loss = 0.06818205972255073
Trained batch 299 in epoch 8, gen_loss = 0.43458065162102383, disc_loss = 0.06813669402773181
Trained batch 300 in epoch 8, gen_loss = 0.43456509917281394, disc_loss = 0.06799547295658494
Trained batch 301 in epoch 8, gen_loss = 0.434520487359028, disc_loss = 0.06781245349283448
Trained batch 302 in epoch 8, gen_loss = 0.4347295802418548, disc_loss = 0.06761929981730165
Trained batch 303 in epoch 8, gen_loss = 0.43475889081233426, disc_loss = 0.06749799808389262
Trained batch 304 in epoch 8, gen_loss = 0.4347921908878889, disc_loss = 0.06735671127184492
Trained batch 305 in epoch 8, gen_loss = 0.43474825106415094, disc_loss = 0.06716725499265724
Trained batch 306 in epoch 8, gen_loss = 0.43482429895804836, disc_loss = 0.06702237066597426
Trained batch 307 in epoch 8, gen_loss = 0.4347586752725886, disc_loss = 0.06686594395281432
Trained batch 308 in epoch 8, gen_loss = 0.4347332302227761, disc_loss = 0.0666799602373036
Trained batch 309 in epoch 8, gen_loss = 0.43473485958191654, disc_loss = 0.0666045460429403
Trained batch 310 in epoch 8, gen_loss = 0.4347998707815765, disc_loss = 0.06671191619595339
Trained batch 311 in epoch 8, gen_loss = 0.43485219556933796, disc_loss = 0.06660375374560364
Trained batch 312 in epoch 8, gen_loss = 0.43462466117673026, disc_loss = 0.06647017847496671
Trained batch 313 in epoch 8, gen_loss = 0.43442261959337125, disc_loss = 0.06634189744307926
Trained batch 314 in epoch 8, gen_loss = 0.43450390914129833, disc_loss = 0.0662670554090587
Trained batch 315 in epoch 8, gen_loss = 0.4345816096550302, disc_loss = 0.06610915862919786
Trained batch 316 in epoch 8, gen_loss = 0.4344251456696904, disc_loss = 0.06591564782657176
Trained batch 317 in epoch 8, gen_loss = 0.43423608170365385, disc_loss = 0.06578267376530189
Trained batch 318 in epoch 8, gen_loss = 0.43422468048651763, disc_loss = 0.06564187651155604
Trained batch 319 in epoch 8, gen_loss = 0.43440351709723474, disc_loss = 0.06552929439058061
Trained batch 320 in epoch 8, gen_loss = 0.43445017237529576, disc_loss = 0.06578006252727683
Trained batch 321 in epoch 8, gen_loss = 0.43421891646355576, disc_loss = 0.06565534202844737
Trained batch 322 in epoch 8, gen_loss = 0.43392367527211784, disc_loss = 0.06604094304801787
Trained batch 323 in epoch 8, gen_loss = 0.4340704906685853, disc_loss = 0.06606009077959131
Trained batch 324 in epoch 8, gen_loss = 0.4342034943287189, disc_loss = 0.06589564197051984
Trained batch 325 in epoch 8, gen_loss = 0.434329481578312, disc_loss = 0.06573367934456907
Trained batch 326 in epoch 8, gen_loss = 0.4341591605717254, disc_loss = 0.06555337397472802
Trained batch 327 in epoch 8, gen_loss = 0.4340036934832247, disc_loss = 0.0653856325079687
Trained batch 328 in epoch 8, gen_loss = 0.4338625515485607, disc_loss = 0.06529509321019325
Trained batch 329 in epoch 8, gen_loss = 0.43390871358640265, disc_loss = 0.0651739629056079
Trained batch 330 in epoch 8, gen_loss = 0.43387198430173707, disc_loss = 0.06509452706112827
Trained batch 331 in epoch 8, gen_loss = 0.4337918054626649, disc_loss = 0.06493104258355831
Trained batch 332 in epoch 8, gen_loss = 0.4337454745182404, disc_loss = 0.06476596639527976
Trained batch 333 in epoch 8, gen_loss = 0.43368211522430716, disc_loss = 0.06459531507421352
Trained batch 334 in epoch 8, gen_loss = 0.4336913518051603, disc_loss = 0.06442462214227043
Trained batch 335 in epoch 8, gen_loss = 0.43371854287882644, disc_loss = 0.0643816037890723
Trained batch 336 in epoch 8, gen_loss = 0.43370577277344835, disc_loss = 0.064220854647745
Trained batch 337 in epoch 8, gen_loss = 0.4338181526703242, disc_loss = 0.06435630013670265
Trained batch 338 in epoch 8, gen_loss = 0.4336517593853593, disc_loss = 0.06468828973582888
Trained batch 339 in epoch 8, gen_loss = 0.4337386149693938, disc_loss = 0.0645323140272761
Trained batch 340 in epoch 8, gen_loss = 0.4339667466903362, disc_loss = 0.06452207039506379
Trained batch 341 in epoch 8, gen_loss = 0.43394017934102064, disc_loss = 0.06447374676381461
Trained batch 342 in epoch 8, gen_loss = 0.4340111160591114, disc_loss = 0.06431417955416893
Trained batch 343 in epoch 8, gen_loss = 0.43409586498557134, disc_loss = 0.06418433477614768
Trained batch 344 in epoch 8, gen_loss = 0.43433580787285514, disc_loss = 0.064066915070989
Trained batch 345 in epoch 8, gen_loss = 0.43446423009985446, disc_loss = 0.06392607396479287
Trained batch 346 in epoch 8, gen_loss = 0.43437160564430854, disc_loss = 0.06380706589658254
Trained batch 347 in epoch 8, gen_loss = 0.4344298520992542, disc_loss = 0.06379980275985496
Trained batch 348 in epoch 8, gen_loss = 0.4347587940002922, disc_loss = 0.06369924817479784
Trained batch 349 in epoch 8, gen_loss = 0.4346333026885986, disc_loss = 0.06360398634203843
Trained batch 350 in epoch 8, gen_loss = 0.43461967584414357, disc_loss = 0.06349189015917289
Trained batch 351 in epoch 8, gen_loss = 0.43462141027504747, disc_loss = 0.06342438185079531
Trained batch 352 in epoch 8, gen_loss = 0.43466533699386856, disc_loss = 0.06350311586269239
Trained batch 353 in epoch 8, gen_loss = 0.4347446592850874, disc_loss = 0.06336708087737193
Trained batch 354 in epoch 8, gen_loss = 0.43460445395657715, disc_loss = 0.06337143580206263
Trained batch 355 in epoch 8, gen_loss = 0.4343894665663162, disc_loss = 0.06328316099596408
Trained batch 356 in epoch 8, gen_loss = 0.43427797609350594, disc_loss = 0.06323173840162384
Trained batch 357 in epoch 8, gen_loss = 0.434206482584916, disc_loss = 0.06307001060977911
Trained batch 358 in epoch 8, gen_loss = 0.4342420797660158, disc_loss = 0.06295966113914936
Trained batch 359 in epoch 8, gen_loss = 0.4343130999141269, disc_loss = 0.06284022452051027
Trained batch 360 in epoch 8, gen_loss = 0.4344426048429389, disc_loss = 0.0627314514581145
Trained batch 361 in epoch 8, gen_loss = 0.4346322137347901, disc_loss = 0.06260077977161957
Trained batch 362 in epoch 8, gen_loss = 0.43481663304583756, disc_loss = 0.06253680162716749
Trained batch 363 in epoch 8, gen_loss = 0.43504283438017083, disc_loss = 0.062391449623116914
Trained batch 364 in epoch 8, gen_loss = 0.435036643727185, disc_loss = 0.06231230143967965
Trained batch 365 in epoch 8, gen_loss = 0.4350594978352062, disc_loss = 0.0621604650329717
Trained batch 366 in epoch 8, gen_loss = 0.43508373334882045, disc_loss = 0.06209202477332885
Trained batch 367 in epoch 8, gen_loss = 0.43522556952160335, disc_loss = 0.061936045691887244
Trained batch 368 in epoch 8, gen_loss = 0.43501651093242616, disc_loss = 0.06183706018897051
Trained batch 369 in epoch 8, gen_loss = 0.4350908555694529, disc_loss = 0.06169434918115872
Trained batch 370 in epoch 8, gen_loss = 0.4351231250962157, disc_loss = 0.06155225756450122
Trained batch 371 in epoch 8, gen_loss = 0.43516345979065024, disc_loss = 0.06140390307998024
Trained batch 372 in epoch 8, gen_loss = 0.43491348352572873, disc_loss = 0.06127042710985839
Trained batch 373 in epoch 8, gen_loss = 0.4347443469067946, disc_loss = 0.06128285717801813
Trained batch 374 in epoch 8, gen_loss = 0.43505362526575725, disc_loss = 0.061450770538300274
Trained batch 375 in epoch 8, gen_loss = 0.4353404328861135, disc_loss = 0.06130818651736456
Trained batch 376 in epoch 8, gen_loss = 0.43563578884544674, disc_loss = 0.061176051290592164
Trained batch 377 in epoch 8, gen_loss = 0.43567217531658353, disc_loss = 0.06103314816207679
Trained batch 378 in epoch 8, gen_loss = 0.4358664384617969, disc_loss = 0.060921126628899085
Trained batch 379 in epoch 8, gen_loss = 0.43596512102767043, disc_loss = 0.06077473538707157
Trained batch 380 in epoch 8, gen_loss = 0.4358636891748023, disc_loss = 0.060630317877616316
Trained batch 381 in epoch 8, gen_loss = 0.4357659595174939, disc_loss = 0.06048180268899445
Trained batch 382 in epoch 8, gen_loss = 0.43576453108700386, disc_loss = 0.06040440641487061
Trained batch 383 in epoch 8, gen_loss = 0.4357049788037936, disc_loss = 0.06030127251566834
Trained batch 384 in epoch 8, gen_loss = 0.4357905678160779, disc_loss = 0.06026502399366688
Trained batch 385 in epoch 8, gen_loss = 0.43566820720316835, disc_loss = 0.06014069760582588
Trained batch 386 in epoch 8, gen_loss = 0.43568210661873336, disc_loss = 0.05999806418820003
Trained batch 387 in epoch 8, gen_loss = 0.43572659936455105, disc_loss = 0.05986565174762947
Trained batch 388 in epoch 8, gen_loss = 0.4356784242131103, disc_loss = 0.05972591294681984
Trained batch 389 in epoch 8, gen_loss = 0.4355058611967625, disc_loss = 0.05959210189668318
Trained batch 390 in epoch 8, gen_loss = 0.43544271115756705, disc_loss = 0.059465772002492374
Trained batch 391 in epoch 8, gen_loss = 0.43534997797438074, disc_loss = 0.05935214542040164
Trained batch 392 in epoch 8, gen_loss = 0.43542345546887423, disc_loss = 0.059210418732410286
Trained batch 393 in epoch 8, gen_loss = 0.4355012901543361, disc_loss = 0.05906969650830544
Trained batch 394 in epoch 8, gen_loss = 0.43539760738988464, disc_loss = 0.058929430839570265
Trained batch 395 in epoch 8, gen_loss = 0.43551419442049183, disc_loss = 0.0588098845345843
Trained batch 396 in epoch 8, gen_loss = 0.43552447896760416, disc_loss = 0.05869147839066889
Trained batch 397 in epoch 8, gen_loss = 0.4354596798443914, disc_loss = 0.05855596767874182
Trained batch 398 in epoch 8, gen_loss = 0.43530911864493427, disc_loss = 0.05842588167581567
Trained batch 399 in epoch 8, gen_loss = 0.43520854324102404, disc_loss = 0.05829614182468504
Trained batch 400 in epoch 8, gen_loss = 0.43519027720663017, disc_loss = 0.05815876726562766
Trained batch 401 in epoch 8, gen_loss = 0.4351253525831213, disc_loss = 0.05802553040392475
Trained batch 402 in epoch 8, gen_loss = 0.4352349124238745, disc_loss = 0.05792080401038525
Trained batch 403 in epoch 8, gen_loss = 0.43535456046609594, disc_loss = 0.05779048594148221
Trained batch 404 in epoch 8, gen_loss = 0.43531740977440353, disc_loss = 0.057672628971897524
Trained batch 405 in epoch 8, gen_loss = 0.435331124757311, disc_loss = 0.057541089836654846
Trained batch 406 in epoch 8, gen_loss = 0.43524970161826954, disc_loss = 0.057409117254600184
Trained batch 407 in epoch 8, gen_loss = 0.43520880724285166, disc_loss = 0.05727653555610838
Trained batch 408 in epoch 8, gen_loss = 0.43525152290945823, disc_loss = 0.057151766057287896
Trained batch 409 in epoch 8, gen_loss = 0.4352867529886525, disc_loss = 0.057034335415469616
Trained batch 410 in epoch 8, gen_loss = 0.4353678012561334, disc_loss = 0.05693942953157182
Trained batch 411 in epoch 8, gen_loss = 0.43542137807144704, disc_loss = 0.056831143071391234
Trained batch 412 in epoch 8, gen_loss = 0.43549447320852674, disc_loss = 0.05671014983294933
Trained batch 413 in epoch 8, gen_loss = 0.4356899283790358, disc_loss = 0.05663351162285027
Trained batch 414 in epoch 8, gen_loss = 0.4357970806489508, disc_loss = 0.0565070373438164
Trained batch 415 in epoch 8, gen_loss = 0.4358638825897987, disc_loss = 0.056409258361292396
Trained batch 416 in epoch 8, gen_loss = 0.4358148344700857, disc_loss = 0.056304172437964116
Trained batch 417 in epoch 8, gen_loss = 0.4356633601576518, disc_loss = 0.05646218283438351
Trained batch 418 in epoch 8, gen_loss = 0.4358745055153148, disc_loss = 0.05677076714248941
Trained batch 419 in epoch 8, gen_loss = 0.4358575434911819, disc_loss = 0.05666244616454822
Trained batch 420 in epoch 8, gen_loss = 0.4359777271747589, disc_loss = 0.056572095154189546
Trained batch 421 in epoch 8, gen_loss = 0.4359977335020264, disc_loss = 0.056523149031417454
Trained batch 422 in epoch 8, gen_loss = 0.4360685408397206, disc_loss = 0.05645774486012334
Trained batch 423 in epoch 8, gen_loss = 0.436102050655293, disc_loss = 0.0563547230465118
Trained batch 424 in epoch 8, gen_loss = 0.43614848319221944, disc_loss = 0.05627376833547126
Trained batch 425 in epoch 8, gen_loss = 0.43622305569514425, disc_loss = 0.05624530311540521
Trained batch 426 in epoch 8, gen_loss = 0.4364122783272272, disc_loss = 0.05618108422669912
Trained batch 427 in epoch 8, gen_loss = 0.4363952380056693, disc_loss = 0.05607944283205755
Trained batch 428 in epoch 8, gen_loss = 0.4364106098671893, disc_loss = 0.05598829531801174
Trained batch 429 in epoch 8, gen_loss = 0.43643300609533175, disc_loss = 0.05587500324635225
Trained batch 430 in epoch 8, gen_loss = 0.4364043615948573, disc_loss = 0.05582280730528286
Trained batch 431 in epoch 8, gen_loss = 0.4363618315094047, disc_loss = 0.05574356373431834
Trained batch 432 in epoch 8, gen_loss = 0.4364175764159848, disc_loss = 0.05563522167191959
Trained batch 433 in epoch 8, gen_loss = 0.4364611033333062, disc_loss = 0.05557534500284867
Trained batch 434 in epoch 8, gen_loss = 0.43640674612988, disc_loss = 0.05558485804907121
Trained batch 435 in epoch 8, gen_loss = 0.4365386573956647, disc_loss = 0.055635876354970755
Trained batch 436 in epoch 8, gen_loss = 0.43660452648213033, disc_loss = 0.05552086661339607
Trained batch 437 in epoch 8, gen_loss = 0.43653995839700305, disc_loss = 0.05547358522767873
Trained batch 438 in epoch 8, gen_loss = 0.4364935522877817, disc_loss = 0.05536247051113067
Trained batch 439 in epoch 8, gen_loss = 0.4365809716284275, disc_loss = 0.055292321880750187
Trained batch 440 in epoch 8, gen_loss = 0.43670758138708515, disc_loss = 0.05518221247111301
Trained batch 441 in epoch 8, gen_loss = 0.4366255604168948, disc_loss = 0.05507307956511433
Trained batch 442 in epoch 8, gen_loss = 0.4366829361657257, disc_loss = 0.05497716390002208
Trained batch 443 in epoch 8, gen_loss = 0.4364190053295445, disc_loss = 0.05489486507150588
Trained batch 444 in epoch 8, gen_loss = 0.43637057596378115, disc_loss = 0.054864563860438684
Trained batch 445 in epoch 8, gen_loss = 0.43617809487030645, disc_loss = 0.054763068541604606
Trained batch 446 in epoch 8, gen_loss = 0.43616289167062816, disc_loss = 0.0547854120221189
Trained batch 447 in epoch 8, gen_loss = 0.43617098399304916, disc_loss = 0.05478129935935223
Trained batch 448 in epoch 8, gen_loss = 0.4363557666473771, disc_loss = 0.054923235748340696
Trained batch 449 in epoch 8, gen_loss = 0.4362765198283725, disc_loss = 0.0549858576975142
Trained batch 450 in epoch 8, gen_loss = 0.4359485364277453, disc_loss = 0.05525825394910167
Trained batch 451 in epoch 8, gen_loss = 0.43613431240077566, disc_loss = 0.055232925332806576
Trained batch 452 in epoch 8, gen_loss = 0.43624953586797316, disc_loss = 0.05530460957678294
Trained batch 453 in epoch 8, gen_loss = 0.43623680165160594, disc_loss = 0.05519862538501046
Trained batch 454 in epoch 8, gen_loss = 0.4362052261829376, disc_loss = 0.055105450553410165
Trained batch 455 in epoch 8, gen_loss = 0.43611739928785126, disc_loss = 0.05508825756464431
Trained batch 456 in epoch 8, gen_loss = 0.43614446308211113, disc_loss = 0.055020702991092525
Trained batch 457 in epoch 8, gen_loss = 0.4361410559394995, disc_loss = 0.05495463106750743
Trained batch 458 in epoch 8, gen_loss = 0.43611714282846137, disc_loss = 0.05487846140851204
Trained batch 459 in epoch 8, gen_loss = 0.4360839771187824, disc_loss = 0.05478968880716306
Trained batch 460 in epoch 8, gen_loss = 0.4359128449330361, disc_loss = 0.054731792207189114
Trained batch 461 in epoch 8, gen_loss = 0.43587648287996067, disc_loss = 0.05542014004688839
Trained batch 462 in epoch 8, gen_loss = 0.435579918501959, disc_loss = 0.05597164732158651
Trained batch 463 in epoch 8, gen_loss = 0.43536025722479, disc_loss = 0.05608838978915973
Trained batch 464 in epoch 8, gen_loss = 0.4353909395074332, disc_loss = 0.056155349226588366
Trained batch 465 in epoch 8, gen_loss = 0.4355113348991574, disc_loss = 0.05625829432417475
Trained batch 466 in epoch 8, gen_loss = 0.4354674525766352, disc_loss = 0.056317667499268365
Trained batch 467 in epoch 8, gen_loss = 0.4354144774823107, disc_loss = 0.056448081166495405
Trained batch 468 in epoch 8, gen_loss = 0.4353241836592587, disc_loss = 0.056553718688061784
Trained batch 469 in epoch 8, gen_loss = 0.4353489996905022, disc_loss = 0.05674746454287162
Trained batch 470 in epoch 8, gen_loss = 0.4352311783029269, disc_loss = 0.0569244699039538
Trained batch 471 in epoch 8, gen_loss = 0.4352551281957303, disc_loss = 0.0570805436399789
Trained batch 472 in epoch 8, gen_loss = 0.43518334853976776, disc_loss = 0.057138104811330456
Trained batch 473 in epoch 8, gen_loss = 0.4349233460954473, disc_loss = 0.05714516722123661
Trained batch 474 in epoch 8, gen_loss = 0.43491367710264106, disc_loss = 0.05710293202857046
Trained batch 475 in epoch 8, gen_loss = 0.43471276566010564, disc_loss = 0.05718158693453923
Trained batch 476 in epoch 8, gen_loss = 0.4347349476514372, disc_loss = 0.05746577815269852
Trained batch 477 in epoch 8, gen_loss = 0.43474172086895263, disc_loss = 0.05760066416241213
Trained batch 478 in epoch 8, gen_loss = 0.4346235731698277, disc_loss = 0.05762938264658235
Trained batch 479 in epoch 8, gen_loss = 0.4345190519466996, disc_loss = 0.0577397725006449
Trained batch 480 in epoch 8, gen_loss = 0.43464657137646745, disc_loss = 0.05784288799272087
Trained batch 481 in epoch 8, gen_loss = 0.4344223727823788, disc_loss = 0.05783883924354486
Trained batch 482 in epoch 8, gen_loss = 0.4343988993523284, disc_loss = 0.058009315321152534
Trained batch 483 in epoch 8, gen_loss = 0.4342966800755706, disc_loss = 0.05803912736461998
Trained batch 484 in epoch 8, gen_loss = 0.43441399157661753, disc_loss = 0.058171322020538846
Trained batch 485 in epoch 8, gen_loss = 0.43445290477923404, disc_loss = 0.05812159376918365
Trained batch 486 in epoch 8, gen_loss = 0.4343271654489349, disc_loss = 0.05807413750622628
Trained batch 487 in epoch 8, gen_loss = 0.4342391487272059, disc_loss = 0.0582618620175082
Trained batch 488 in epoch 8, gen_loss = 0.4343171684044758, disc_loss = 0.05845395534333596
Trained batch 489 in epoch 8, gen_loss = 0.4341627693906122, disc_loss = 0.058386115639052376
Trained batch 490 in epoch 8, gen_loss = 0.4342159213699294, disc_loss = 0.058292163843706314
Trained batch 491 in epoch 8, gen_loss = 0.43427040991259785, disc_loss = 0.058226538398511316
Trained batch 492 in epoch 8, gen_loss = 0.4341545572870885, disc_loss = 0.058187073969865936
Trained batch 493 in epoch 8, gen_loss = 0.4341594191335956, disc_loss = 0.05809315049178099
Trained batch 494 in epoch 8, gen_loss = 0.4341524019987896, disc_loss = 0.058015075091253775
Trained batch 495 in epoch 8, gen_loss = 0.4341157397195216, disc_loss = 0.05795349739351115
Trained batch 496 in epoch 8, gen_loss = 0.43433363204990594, disc_loss = 0.05829204064119285
Trained batch 497 in epoch 8, gen_loss = 0.43414739558256293, disc_loss = 0.05844722092609823
Trained batch 498 in epoch 8, gen_loss = 0.43428904648295386, disc_loss = 0.05839987791083634
Trained batch 499 in epoch 8, gen_loss = 0.4342163342833519, disc_loss = 0.058332440851721915
Trained batch 500 in epoch 8, gen_loss = 0.4341530304350063, disc_loss = 0.05833612412015374
Trained batch 501 in epoch 8, gen_loss = 0.43408600617927384, disc_loss = 0.058241226089342804
Trained batch 502 in epoch 8, gen_loss = 0.4341013585596862, disc_loss = 0.05817254240417235
Trained batch 503 in epoch 8, gen_loss = 0.4341590557661321, disc_loss = 0.058094029143426776
Trained batch 504 in epoch 8, gen_loss = 0.434246694392497, disc_loss = 0.05811582459090739
Trained batch 505 in epoch 8, gen_loss = 0.4341474278524459, disc_loss = 0.058143490703183816
Trained batch 506 in epoch 8, gen_loss = 0.4341370014279082, disc_loss = 0.05809574322067789
Trained batch 507 in epoch 8, gen_loss = 0.43420227130097666, disc_loss = 0.05825926174866182
Trained batch 508 in epoch 8, gen_loss = 0.4340649509476772, disc_loss = 0.058231118538147955
Trained batch 509 in epoch 8, gen_loss = 0.43400967343180785, disc_loss = 0.05816647638155915
Trained batch 510 in epoch 8, gen_loss = 0.434073546744606, disc_loss = 0.05806618158381119
Trained batch 511 in epoch 8, gen_loss = 0.4340120239648968, disc_loss = 0.05801653254502526
Trained batch 512 in epoch 8, gen_loss = 0.4340040090023658, disc_loss = 0.05791926227889403
Trained batch 513 in epoch 8, gen_loss = 0.43388856124089387, disc_loss = 0.058094810803623775
Trained batch 514 in epoch 8, gen_loss = 0.4338005467525964, disc_loss = 0.05837505550250339
Trained batch 515 in epoch 8, gen_loss = 0.4339074283376221, disc_loss = 0.0583639652364483
Trained batch 516 in epoch 8, gen_loss = 0.43399936053001215, disc_loss = 0.05858718643525194
Trained batch 517 in epoch 8, gen_loss = 0.4339476982023725, disc_loss = 0.05860768943983687
Trained batch 518 in epoch 8, gen_loss = 0.4340030941430314, disc_loss = 0.0585983123326125
Trained batch 519 in epoch 8, gen_loss = 0.43391029880597043, disc_loss = 0.05849904136132234
Trained batch 520 in epoch 8, gen_loss = 0.43401168587111694, disc_loss = 0.05845018559593114
Trained batch 521 in epoch 8, gen_loss = 0.4338776267693874, disc_loss = 0.05843827205173086
Trained batch 522 in epoch 8, gen_loss = 0.43384966265631, disc_loss = 0.05834231223692017
Trained batch 523 in epoch 8, gen_loss = 0.43375892772246866, disc_loss = 0.05824435516109491
Trained batch 524 in epoch 8, gen_loss = 0.43375448448317394, disc_loss = 0.05817280811878542
Trained batch 525 in epoch 8, gen_loss = 0.43368074620857894, disc_loss = 0.05809689962930142
Trained batch 526 in epoch 8, gen_loss = 0.43360291735270895, disc_loss = 0.05805332938507835
Trained batch 527 in epoch 8, gen_loss = 0.43391036411578005, disc_loss = 0.05851054439545172
Trained batch 528 in epoch 8, gen_loss = 0.43385260159216665, disc_loss = 0.05895120665626442
Trained batch 529 in epoch 8, gen_loss = 0.43378261502059, disc_loss = 0.058873199604293505
Trained batch 530 in epoch 8, gen_loss = 0.4337522178158697, disc_loss = 0.059025163903899086
Trained batch 531 in epoch 8, gen_loss = 0.43366741338618714, disc_loss = 0.059146811614509784
Trained batch 532 in epoch 8, gen_loss = 0.43365342006450747, disc_loss = 0.05907176526509728
Trained batch 533 in epoch 8, gen_loss = 0.433747662754541, disc_loss = 0.05905579070234497
Trained batch 534 in epoch 8, gen_loss = 0.4337843895515549, disc_loss = 0.05899574718629576
Trained batch 535 in epoch 8, gen_loss = 0.43371769424472284, disc_loss = 0.05890240873611504
Trained batch 536 in epoch 8, gen_loss = 0.4339066997475686, disc_loss = 0.0588357057209947
Trained batch 537 in epoch 8, gen_loss = 0.43388330504353606, disc_loss = 0.05880279258390383
Trained batch 538 in epoch 8, gen_loss = 0.43397726773773365, disc_loss = 0.05870505746891152
Trained batch 539 in epoch 8, gen_loss = 0.4339832347852212, disc_loss = 0.058633430016278805
Trained batch 540 in epoch 8, gen_loss = 0.43407866815983037, disc_loss = 0.05881214069242136
Trained batch 541 in epoch 8, gen_loss = 0.4342429695094204, disc_loss = 0.058927204986137245
Trained batch 542 in epoch 8, gen_loss = 0.43431791284466315, disc_loss = 0.058834310731221105
Trained batch 543 in epoch 8, gen_loss = 0.4341072654899429, disc_loss = 0.05894688479234259
Trained batch 544 in epoch 8, gen_loss = 0.43409396136572603, disc_loss = 0.05900807449756481
Trained batch 545 in epoch 8, gen_loss = 0.4340894963496771, disc_loss = 0.0589094632249769
Trained batch 546 in epoch 8, gen_loss = 0.4340446262298598, disc_loss = 0.0589444912060026
Trained batch 547 in epoch 8, gen_loss = 0.43401352027906986, disc_loss = 0.05911005746843429
Trained batch 548 in epoch 8, gen_loss = 0.43397172585211163, disc_loss = 0.05906255776953217
Trained batch 549 in epoch 8, gen_loss = 0.43394095242023467, disc_loss = 0.059020048863762484
Trained batch 550 in epoch 8, gen_loss = 0.4339838061488475, disc_loss = 0.05893372277435111
Trained batch 551 in epoch 8, gen_loss = 0.43395085589609284, disc_loss = 0.058862130619514653
Trained batch 552 in epoch 8, gen_loss = 0.4340866433345388, disc_loss = 0.05896171376700252
Trained batch 553 in epoch 8, gen_loss = 0.434014134028328, disc_loss = 0.05908966725078556
Trained batch 554 in epoch 8, gen_loss = 0.4341315377939929, disc_loss = 0.05911532051416601
Trained batch 555 in epoch 8, gen_loss = 0.43412251942020524, disc_loss = 0.05919796201901296
Trained batch 556 in epoch 8, gen_loss = 0.43420115659010045, disc_loss = 0.05913973441456162
Trained batch 557 in epoch 8, gen_loss = 0.4341526926097904, disc_loss = 0.059226684535579846
Trained batch 558 in epoch 8, gen_loss = 0.4340852431832998, disc_loss = 0.05919221928884644
Trained batch 559 in epoch 8, gen_loss = 0.4341471689088004, disc_loss = 0.059412075874778175
Trained batch 560 in epoch 8, gen_loss = 0.43418403445293136, disc_loss = 0.05944211402810021
Trained batch 561 in epoch 8, gen_loss = 0.43423177704904425, disc_loss = 0.05936495907351149
Trained batch 562 in epoch 8, gen_loss = 0.43416372084490573, disc_loss = 0.05928084689778066
Trained batch 563 in epoch 8, gen_loss = 0.4339920222125155, disc_loss = 0.059206966424265095
Trained batch 564 in epoch 8, gen_loss = 0.43394547964619323, disc_loss = 0.059142078018739025
Trained batch 565 in epoch 8, gen_loss = 0.43393206896503905, disc_loss = 0.059210543755636065
Trained batch 566 in epoch 8, gen_loss = 0.43394295537492794, disc_loss = 0.05915355660157636
Trained batch 567 in epoch 8, gen_loss = 0.43376683517241144, disc_loss = 0.059261909516734844
Trained batch 568 in epoch 8, gen_loss = 0.433861357885002, disc_loss = 0.059299293062150454
Trained batch 569 in epoch 8, gen_loss = 0.43394751475568405, disc_loss = 0.05922407159671645
Trained batch 570 in epoch 8, gen_loss = 0.43385068229326224, disc_loss = 0.05921072874425367
Trained batch 571 in epoch 8, gen_loss = 0.4337500214472517, disc_loss = 0.05916275037249055
Trained batch 572 in epoch 8, gen_loss = 0.43364829683179007, disc_loss = 0.05915283544491294
Trained batch 573 in epoch 8, gen_loss = 0.4337248724304425, disc_loss = 0.059223359043041456
Trained batch 574 in epoch 8, gen_loss = 0.43363913929980735, disc_loss = 0.059169777999024675
Trained batch 575 in epoch 8, gen_loss = 0.43351858849119806, disc_loss = 0.05939004588799435
Trained batch 576 in epoch 8, gen_loss = 0.4335294774954612, disc_loss = 0.059815282868447374
Trained batch 577 in epoch 8, gen_loss = 0.4335741034119187, disc_loss = 0.05974932092082426
Trained batch 578 in epoch 8, gen_loss = 0.43354797358134045, disc_loss = 0.059692538748310306
Trained batch 579 in epoch 8, gen_loss = 0.433435240131, disc_loss = 0.05962055170194021
Trained batch 580 in epoch 8, gen_loss = 0.4335034791245518, disc_loss = 0.05958050019556589
Trained batch 581 in epoch 8, gen_loss = 0.43351884795628054, disc_loss = 0.059629218257192355
Trained batch 582 in epoch 8, gen_loss = 0.43345009109986177, disc_loss = 0.05960627144408663
Trained batch 583 in epoch 8, gen_loss = 0.4334435471626994, disc_loss = 0.05951909423600053
Trained batch 584 in epoch 8, gen_loss = 0.4334240512970166, disc_loss = 0.05950289567271805
Trained batch 585 in epoch 8, gen_loss = 0.4335139952727145, disc_loss = 0.05948025028820471
Trained batch 586 in epoch 8, gen_loss = 0.4335497798972479, disc_loss = 0.05953727618099414
Trained batch 587 in epoch 8, gen_loss = 0.4333734792612848, disc_loss = 0.05961990013020113
Trained batch 588 in epoch 8, gen_loss = 0.433315571783354, disc_loss = 0.0595962286168624
Trained batch 589 in epoch 8, gen_loss = 0.43340508710529846, disc_loss = 0.059632365607214556
Trained batch 590 in epoch 8, gen_loss = 0.433291190923168, disc_loss = 0.05961489608683095
Trained batch 591 in epoch 8, gen_loss = 0.43327955755631664, disc_loss = 0.059537855347829266
Trained batch 592 in epoch 8, gen_loss = 0.43331740040200156, disc_loss = 0.05956027840820108
Trained batch 593 in epoch 8, gen_loss = 0.43325435377732674, disc_loss = 0.05965789372959058
Trained batch 594 in epoch 8, gen_loss = 0.43321165377352416, disc_loss = 0.059627066408244875
Trained batch 595 in epoch 8, gen_loss = 0.43324401894671805, disc_loss = 0.05959100999374055
Testing Epoch 8

Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.46282798051834106, disc_loss = 0.014448518864810467
Trained batch 1 in epoch 9, gen_loss = 0.4558895230293274, disc_loss = 0.060525314416736364
Trained batch 2 in epoch 9, gen_loss = 0.4431203802426656, disc_loss = 0.05445916919658581
Trained batch 3 in epoch 9, gen_loss = 0.44028591364622116, disc_loss = 0.04894713289104402
Trained batch 4 in epoch 9, gen_loss = 0.4484566986560822, disc_loss = 0.04185665231198073
Trained batch 5 in epoch 9, gen_loss = 0.4476892451445262, disc_loss = 0.03729016132031878
Trained batch 6 in epoch 9, gen_loss = 0.4491860270500183, disc_loss = 0.03511910127209766
Trained batch 7 in epoch 9, gen_loss = 0.4427136890590191, disc_loss = 0.03227425122167915
Trained batch 8 in epoch 9, gen_loss = 0.4601951274606917, disc_loss = 0.039951083871225514
Trained batch 9 in epoch 9, gen_loss = 0.45426544547080994, disc_loss = 0.05032158894464374
Trained batch 10 in epoch 9, gen_loss = 0.45247373255816375, disc_loss = 0.047215883281420575
Trained batch 11 in epoch 9, gen_loss = 0.4562152177095413, disc_loss = 0.04557399273229142
Trained batch 12 in epoch 9, gen_loss = 0.45652361328785235, disc_loss = 0.04270541230933024
Trained batch 13 in epoch 9, gen_loss = 0.4519057593175343, disc_loss = 0.04138925704838974
Trained batch 14 in epoch 9, gen_loss = 0.4527415374914805, disc_loss = 0.03951696126411359
Trained batch 15 in epoch 9, gen_loss = 0.4512349124997854, disc_loss = 0.03748714513494633
Trained batch 16 in epoch 9, gen_loss = 0.4536864389391506, disc_loss = 0.037239431321401804
Trained batch 17 in epoch 9, gen_loss = 0.4491156389315923, disc_loss = 0.03581321185144285
Trained batch 18 in epoch 9, gen_loss = 0.44753690142380564, disc_loss = 0.03536129995298229
Trained batch 19 in epoch 9, gen_loss = 0.4437157064676285, disc_loss = 0.034084632783196865
Trained batch 20 in epoch 9, gen_loss = 0.44064731966881526, disc_loss = 0.03297880542508903
Trained batch 21 in epoch 9, gen_loss = 0.43821908804503357, disc_loss = 0.03188483986410905
Trained batch 22 in epoch 9, gen_loss = 0.4377310988695725, disc_loss = 0.03070805272411393
Trained batch 23 in epoch 9, gen_loss = 0.4379453621804714, disc_loss = 0.030229449446778744
Trained batch 24 in epoch 9, gen_loss = 0.4390700614452362, disc_loss = 0.029380781073123217
Trained batch 25 in epoch 9, gen_loss = 0.43907826909652126, disc_loss = 0.028767303796485066
Trained batch 26 in epoch 9, gen_loss = 0.43679146303070915, disc_loss = 0.028625513892620802
Trained batch 27 in epoch 9, gen_loss = 0.43746824243238996, disc_loss = 0.030609930150343904
Trained batch 28 in epoch 9, gen_loss = 0.43900695237620124, disc_loss = 0.03217636172434893
Trained batch 29 in epoch 9, gen_loss = 0.440154093503952, disc_loss = 0.03214224876525502
Trained batch 30 in epoch 9, gen_loss = 0.43509017844353953, disc_loss = 0.03316543084539233
Trained batch 31 in epoch 9, gen_loss = 0.43574261851608753, disc_loss = 0.03444870097155217
Trained batch 32 in epoch 9, gen_loss = 0.43494632388606214, disc_loss = 0.04666140315715562
Trained batch 33 in epoch 9, gen_loss = 0.4330409817835864, disc_loss = 0.04767580112606725
Trained batch 34 in epoch 9, gen_loss = 0.4299426938806261, disc_loss = 0.04890283390081355
Trained batch 35 in epoch 9, gen_loss = 0.42917316738102174, disc_loss = 0.04850826806957937
Trained batch 36 in epoch 9, gen_loss = 0.43041215393994303, disc_loss = 0.04837219055893051
Trained batch 37 in epoch 9, gen_loss = 0.4309772598116021, disc_loss = 0.04806346447501136
Trained batch 38 in epoch 9, gen_loss = 0.4290821147270692, disc_loss = 0.04810497452481053
Trained batch 39 in epoch 9, gen_loss = 0.4275790974497795, disc_loss = 0.04876485114218667
Trained batch 40 in epoch 9, gen_loss = 0.43027128969750755, disc_loss = 0.04854202317073941
Trained batch 41 in epoch 9, gen_loss = 0.43128965936955954, disc_loss = 0.04783014244666057
Trained batch 42 in epoch 9, gen_loss = 0.4310412483159886, disc_loss = 0.04974104118598408
Trained batch 43 in epoch 9, gen_loss = 0.4307719509709965, disc_loss = 0.050919974910688
Trained batch 44 in epoch 9, gen_loss = 0.4301408138540056, disc_loss = 0.05091132497828868
Trained batch 45 in epoch 9, gen_loss = 0.4302676119234251, disc_loss = 0.051007831236347556
Trained batch 46 in epoch 9, gen_loss = 0.42935272100123956, disc_loss = 0.050149779459659725
Trained batch 47 in epoch 9, gen_loss = 0.4294424255688985, disc_loss = 0.04948014433224065
Trained batch 48 in epoch 9, gen_loss = 0.42813064492478664, disc_loss = 0.04959802946303876
Trained batch 49 in epoch 9, gen_loss = 0.4291595482826233, disc_loss = 0.04947837986983359
Trained batch 50 in epoch 9, gen_loss = 0.42759372440038945, disc_loss = 0.04904835573488883
Trained batch 51 in epoch 9, gen_loss = 0.42740106124144334, disc_loss = 0.050117173205273084
Trained batch 52 in epoch 9, gen_loss = 0.42932694812990585, disc_loss = 0.05218213519854647
Trained batch 53 in epoch 9, gen_loss = 0.42788795850895067, disc_loss = 0.05186087180239459
Trained batch 54 in epoch 9, gen_loss = 0.4277215415781194, disc_loss = 0.05110610256987539
Trained batch 55 in epoch 9, gen_loss = 0.42762577001537594, disc_loss = 0.050665551472255696
Trained batch 56 in epoch 9, gen_loss = 0.4273633214465359, disc_loss = 0.05045292383517351
Trained batch 57 in epoch 9, gen_loss = 0.42868840283360976, disc_loss = 0.04972025117001914
Trained batch 58 in epoch 9, gen_loss = 0.42913712283312266, disc_loss = 0.05058166379172165
Trained batch 59 in epoch 9, gen_loss = 0.4274501716097196, disc_loss = 0.05095426906676342
Trained batch 60 in epoch 9, gen_loss = 0.4267785299996861, disc_loss = 0.05040722741119442
Trained batch 61 in epoch 9, gen_loss = 0.4274467571127799, disc_loss = 0.04986674258215053
Trained batch 62 in epoch 9, gen_loss = 0.42709408251066056, disc_loss = 0.04923715452027936
Trained batch 63 in epoch 9, gen_loss = 0.428880809340626, disc_loss = 0.04882101584371412
Trained batch 64 in epoch 9, gen_loss = 0.4292701551547417, disc_loss = 0.04833169118859447
Trained batch 65 in epoch 9, gen_loss = 0.42918526539296814, disc_loss = 0.04828848777987966
Trained batch 66 in epoch 9, gen_loss = 0.4291969764588484, disc_loss = 0.04792271446742451
Trained batch 67 in epoch 9, gen_loss = 0.4300234471173847, disc_loss = 0.048094161272542006
Trained batch 68 in epoch 9, gen_loss = 0.4298253201920053, disc_loss = 0.04833668414368362
Trained batch 69 in epoch 9, gen_loss = 0.4300101854971477, disc_loss = 0.04780868468140917
Trained batch 70 in epoch 9, gen_loss = 0.43187149435701505, disc_loss = 0.04782275651568468
Trained batch 71 in epoch 9, gen_loss = 0.4315117212633292, disc_loss = 0.04987744082205205
Trained batch 72 in epoch 9, gen_loss = 0.4323702817910338, disc_loss = 0.049826504388339306
Trained batch 73 in epoch 9, gen_loss = 0.4325067195537928, disc_loss = 0.049520403631283225
Trained batch 74 in epoch 9, gen_loss = 0.43194652915000914, disc_loss = 0.049563827992727356
Trained batch 75 in epoch 9, gen_loss = 0.43128008709142085, disc_loss = 0.049227457940823546
Trained batch 76 in epoch 9, gen_loss = 0.4315751806482092, disc_loss = 0.048962084195491945
Trained batch 77 in epoch 9, gen_loss = 0.43237420228811413, disc_loss = 0.04863828676752746
Trained batch 78 in epoch 9, gen_loss = 0.4322896871385695, disc_loss = 0.0488401941683945
Trained batch 79 in epoch 9, gen_loss = 0.43254900462925433, disc_loss = 0.0500790286634583
Trained batch 80 in epoch 9, gen_loss = 0.43272604434578504, disc_loss = 0.04953556484255342
Trained batch 81 in epoch 9, gen_loss = 0.4332116126287274, disc_loss = 0.049435901881490905
Trained batch 82 in epoch 9, gen_loss = 0.4324834156467254, disc_loss = 0.0492101245649518
Trained batch 83 in epoch 9, gen_loss = 0.4329978617883864, disc_loss = 0.04872706926627351
Trained batch 84 in epoch 9, gen_loss = 0.4323947787284851, disc_loss = 0.04825019450200831
Trained batch 85 in epoch 9, gen_loss = 0.4327608312285224, disc_loss = 0.047864368136668965
Trained batch 86 in epoch 9, gen_loss = 0.4341975238131381, disc_loss = 0.047508747686214485
Trained batch 87 in epoch 9, gen_loss = 0.43393437124111434, disc_loss = 0.04717634169025008
Trained batch 88 in epoch 9, gen_loss = 0.434088729405671, disc_loss = 0.04676766882472661
Trained batch 89 in epoch 9, gen_loss = 0.43428550726837584, disc_loss = 0.046426245492572585
Trained batch 90 in epoch 9, gen_loss = 0.4334592910913321, disc_loss = 0.04629704966670373
Trained batch 91 in epoch 9, gen_loss = 0.43361512603967084, disc_loss = 0.04687138691888717
Trained batch 92 in epoch 9, gen_loss = 0.4346781251251057, disc_loss = 0.05037120029190054
Trained batch 93 in epoch 9, gen_loss = 0.43599785388784207, disc_loss = 0.05003935653973925
Trained batch 94 in epoch 9, gen_loss = 0.4353009534509558, disc_loss = 0.0503448580489739
Trained batch 95 in epoch 9, gen_loss = 0.4352329798663656, disc_loss = 0.04992208818536407
Trained batch 96 in epoch 9, gen_loss = 0.4346901691451515, disc_loss = 0.04972778743171354
Trained batch 97 in epoch 9, gen_loss = 0.43483560334663, disc_loss = 0.05046624133876544
Trained batch 98 in epoch 9, gen_loss = 0.4345615524234194, disc_loss = 0.05118849187280343
Trained batch 99 in epoch 9, gen_loss = 0.43442419737577437, disc_loss = 0.050862300083972516
Trained batch 100 in epoch 9, gen_loss = 0.4346454777930043, disc_loss = 0.05137821160127769
Trained batch 101 in epoch 9, gen_loss = 0.43386367986015245, disc_loss = 0.0522696884102462
Trained batch 102 in epoch 9, gen_loss = 0.4337555589606461, disc_loss = 0.0523329816116653
Trained batch 103 in epoch 9, gen_loss = 0.433884191684998, disc_loss = 0.0519153301183206
Trained batch 104 in epoch 9, gen_loss = 0.43347928892998466, disc_loss = 0.05235489353626257
Trained batch 105 in epoch 9, gen_loss = 0.4345984658542669, disc_loss = 0.052334470169197
Trained batch 106 in epoch 9, gen_loss = 0.43448099939622614, disc_loss = 0.05212266351940615
Trained batch 107 in epoch 9, gen_loss = 0.43400442793413446, disc_loss = 0.05190768301987124
Trained batch 108 in epoch 9, gen_loss = 0.4345104358065019, disc_loss = 0.05166428517806557
Trained batch 109 in epoch 9, gen_loss = 0.4345123610713265, disc_loss = 0.0517265437213196
Trained batch 110 in epoch 9, gen_loss = 0.4343966224172094, disc_loss = 0.052003381845146954
Trained batch 111 in epoch 9, gen_loss = 0.4345851093530655, disc_loss = 0.05216758261251796
Trained batch 112 in epoch 9, gen_loss = 0.4348330679720482, disc_loss = 0.051753623950896804
Trained batch 113 in epoch 9, gen_loss = 0.4355300641373584, disc_loss = 0.0514828312545688
Trained batch 114 in epoch 9, gen_loss = 0.4357876243798629, disc_loss = 0.051762643922120335
Trained batch 115 in epoch 9, gen_loss = 0.43580120622084056, disc_loss = 0.051895960920554554
Trained batch 116 in epoch 9, gen_loss = 0.4354197515381707, disc_loss = 0.0517349447378427
Trained batch 117 in epoch 9, gen_loss = 0.4358365131636797, disc_loss = 0.05145997959346968
Trained batch 118 in epoch 9, gen_loss = 0.43579791098081766, disc_loss = 0.05116709676657279
Trained batch 119 in epoch 9, gen_loss = 0.43574894095460576, disc_loss = 0.05084265532204881
Trained batch 120 in epoch 9, gen_loss = 0.4357885819328718, disc_loss = 0.05059731323348959
Trained batch 121 in epoch 9, gen_loss = 0.4354749258424415, disc_loss = 0.05036692012513637
Trained batch 122 in epoch 9, gen_loss = 0.435451469770292, disc_loss = 0.050519507919718334
Trained batch 123 in epoch 9, gen_loss = 0.4356816379774001, disc_loss = 0.05093653538760038
Trained batch 124 in epoch 9, gen_loss = 0.4355735394954681, disc_loss = 0.05064290250465274
Trained batch 125 in epoch 9, gen_loss = 0.4354543004717146, disc_loss = 0.05154417373520869
Trained batch 126 in epoch 9, gen_loss = 0.43578459897379235, disc_loss = 0.051199003735073204
Trained batch 127 in epoch 9, gen_loss = 0.43649781960994005, disc_loss = 0.05149433043334284
Trained batch 128 in epoch 9, gen_loss = 0.43632910163827643, disc_loss = 0.05138622556791403
Trained batch 129 in epoch 9, gen_loss = 0.436775141954422, disc_loss = 0.05106038484507455
Trained batch 130 in epoch 9, gen_loss = 0.4365598190831774, disc_loss = 0.05086542596642411
Trained batch 131 in epoch 9, gen_loss = 0.43693797154860065, disc_loss = 0.05057754241649739
Trained batch 132 in epoch 9, gen_loss = 0.43717190466429057, disc_loss = 0.0505788511792688
Trained batch 133 in epoch 9, gen_loss = 0.43668511665579096, disc_loss = 0.05216583115771524
Trained batch 134 in epoch 9, gen_loss = 0.43694821574069836, disc_loss = 0.051988675234908306
Trained batch 135 in epoch 9, gen_loss = 0.43717047024299116, disc_loss = 0.051920886956127905
Trained batch 136 in epoch 9, gen_loss = 0.4376102381379065, disc_loss = 0.05264089292894206
Trained batch 137 in epoch 9, gen_loss = 0.4367202410231466, disc_loss = 0.054950708263567176
Trained batch 138 in epoch 9, gen_loss = 0.43705946614416386, disc_loss = 0.054907856961350435
Trained batch 139 in epoch 9, gen_loss = 0.43726925530603955, disc_loss = 0.05536967253512037
Trained batch 140 in epoch 9, gen_loss = 0.4368499236326691, disc_loss = 0.05510816203615238
Trained batch 141 in epoch 9, gen_loss = 0.4365630781566593, disc_loss = 0.05510850933800176
Trained batch 142 in epoch 9, gen_loss = 0.43691112111498426, disc_loss = 0.05531398369442229
Trained batch 143 in epoch 9, gen_loss = 0.43676225033899146, disc_loss = 0.05508211632453216
Trained batch 144 in epoch 9, gen_loss = 0.43642952956002334, disc_loss = 0.055001305965385563
Trained batch 145 in epoch 9, gen_loss = 0.43603199536669746, disc_loss = 0.05484329089713729
Trained batch 146 in epoch 9, gen_loss = 0.43613480913395786, disc_loss = 0.05512378498797818
Trained batch 147 in epoch 9, gen_loss = 0.436299825439582, disc_loss = 0.05567699486729563
Trained batch 148 in epoch 9, gen_loss = 0.4363709010133807, disc_loss = 0.055705782122935026
Trained batch 149 in epoch 9, gen_loss = 0.4361218663056691, disc_loss = 0.05577898400214811
Trained batch 150 in epoch 9, gen_loss = 0.4363474911017134, disc_loss = 0.05572299264211035
Trained batch 151 in epoch 9, gen_loss = 0.43650893259205314, disc_loss = 0.05566989983076622
Trained batch 152 in epoch 9, gen_loss = 0.4366031376754536, disc_loss = 0.05587687294358035
Trained batch 153 in epoch 9, gen_loss = 0.43670966621343194, disc_loss = 0.055567219003720525
Trained batch 154 in epoch 9, gen_loss = 0.43642187579985586, disc_loss = 0.055582852706673645
Trained batch 155 in epoch 9, gen_loss = 0.43599204298777455, disc_loss = 0.05590514227067335
Trained batch 156 in epoch 9, gen_loss = 0.43608407457922677, disc_loss = 0.05583616848857065
Trained batch 157 in epoch 9, gen_loss = 0.4354534377402897, disc_loss = 0.0556158809480552
Trained batch 158 in epoch 9, gen_loss = 0.4349248283689127, disc_loss = 0.05543710083741718
Trained batch 159 in epoch 9, gen_loss = 0.4351173618808389, disc_loss = 0.05552002348413225
Trained batch 160 in epoch 9, gen_loss = 0.4347605107363707, disc_loss = 0.05550920015478634
Trained batch 161 in epoch 9, gen_loss = 0.43466010340202, disc_loss = 0.05526760613465291
Trained batch 162 in epoch 9, gen_loss = 0.43471277985104756, disc_loss = 0.055057275146131686
Trained batch 163 in epoch 9, gen_loss = 0.4346737423684539, disc_loss = 0.055266562982734926
Trained batch 164 in epoch 9, gen_loss = 0.4342325430927855, disc_loss = 0.05553357307375832
Trained batch 165 in epoch 9, gen_loss = 0.4344118438571332, disc_loss = 0.05525975723481591
Trained batch 166 in epoch 9, gen_loss = 0.43468754359348094, disc_loss = 0.05497759825711746
Trained batch 167 in epoch 9, gen_loss = 0.4348922533293565, disc_loss = 0.05546877528485354
Trained batch 168 in epoch 9, gen_loss = 0.43456269086465327, disc_loss = 0.055546309774157386
Trained batch 169 in epoch 9, gen_loss = 0.43481683976509994, disc_loss = 0.05540105432874578
Trained batch 170 in epoch 9, gen_loss = 0.43479451833412663, disc_loss = 0.05564482684100145
Trained batch 171 in epoch 9, gen_loss = 0.43486383176127147, disc_loss = 0.0556931403806693
Trained batch 172 in epoch 9, gen_loss = 0.434990201899082, disc_loss = 0.055421142130982495
Trained batch 173 in epoch 9, gen_loss = 0.4347350820042621, disc_loss = 0.055165946406001844
Trained batch 174 in epoch 9, gen_loss = 0.43474085807800295, disc_loss = 0.05519946716459734
Trained batch 175 in epoch 9, gen_loss = 0.43506686321713706, disc_loss = 0.05522517376018434
Trained batch 176 in epoch 9, gen_loss = 0.43502635454053934, disc_loss = 0.05532411181520523
Trained batch 177 in epoch 9, gen_loss = 0.43479182646515663, disc_loss = 0.0551263030613197
Trained batch 178 in epoch 9, gen_loss = 0.43474847944089157, disc_loss = 0.055219836811425796
Trained batch 179 in epoch 9, gen_loss = 0.43437743451860217, disc_loss = 0.05572474895614303
Trained batch 180 in epoch 9, gen_loss = 0.43449985256511203, disc_loss = 0.05580097760809637
Trained batch 181 in epoch 9, gen_loss = 0.4346367071618091, disc_loss = 0.055775363476701326
Trained batch 182 in epoch 9, gen_loss = 0.4346711261024892, disc_loss = 0.05622623969490329
Trained batch 183 in epoch 9, gen_loss = 0.4344961743639863, disc_loss = 0.056261112900835505
Trained batch 184 in epoch 9, gen_loss = 0.4343579221416164, disc_loss = 0.05628347580849721
Trained batch 185 in epoch 9, gen_loss = 0.43471508897760863, disc_loss = 0.05655035094898795
Trained batch 186 in epoch 9, gen_loss = 0.43501816108265023, disc_loss = 0.056399394332227064
Trained batch 187 in epoch 9, gen_loss = 0.4349760538403024, disc_loss = 0.05686939968182606
Trained batch 188 in epoch 9, gen_loss = 0.434826263517299, disc_loss = 0.058129917857330786
Trained batch 189 in epoch 9, gen_loss = 0.43462721736807575, disc_loss = 0.05884061205494953
Trained batch 190 in epoch 9, gen_loss = 0.4340164160541215, disc_loss = 0.05884557120570259
Trained batch 191 in epoch 9, gen_loss = 0.43433065510665375, disc_loss = 0.060164771050040144
Trained batch 192 in epoch 9, gen_loss = 0.4341423468268597, disc_loss = 0.05998569055957421
Trained batch 193 in epoch 9, gen_loss = 0.4340135962078252, disc_loss = 0.06015220070113764
Trained batch 194 in epoch 9, gen_loss = 0.4340084899694492, disc_loss = 0.06002450547873592
Trained batch 195 in epoch 9, gen_loss = 0.43361096981228614, disc_loss = 0.05981622395647348
Trained batch 196 in epoch 9, gen_loss = 0.43309558784296065, disc_loss = 0.0595789226930267
Trained batch 197 in epoch 9, gen_loss = 0.4328970398866769, disc_loss = 0.059384507369344135
Trained batch 198 in epoch 9, gen_loss = 0.4330826099194474, disc_loss = 0.05922179634275673
Trained batch 199 in epoch 9, gen_loss = 0.4331614950299263, disc_loss = 0.059065510935615746
Trained batch 200 in epoch 9, gen_loss = 0.4329763391421209, disc_loss = 0.05894295401194721
Trained batch 201 in epoch 9, gen_loss = 0.4328786469627135, disc_loss = 0.058700678780177
Trained batch 202 in epoch 9, gen_loss = 0.4329793748303587, disc_loss = 0.0584410664194213
Trained batch 203 in epoch 9, gen_loss = 0.43278810776331844, disc_loss = 0.058286910997612365
Trained batch 204 in epoch 9, gen_loss = 0.43286026338251626, disc_loss = 0.05803287963087602
Trained batch 205 in epoch 9, gen_loss = 0.4325775624189562, disc_loss = 0.05816350077749095
Trained batch 206 in epoch 9, gen_loss = 0.43243775059635514, disc_loss = 0.058829928543598614
Trained batch 207 in epoch 9, gen_loss = 0.4323156113521411, disc_loss = 0.05882680285139941
Trained batch 208 in epoch 9, gen_loss = 0.43276279351928015, disc_loss = 0.058805297380625204
Trained batch 209 in epoch 9, gen_loss = 0.432845110978399, disc_loss = 0.058895875493596705
Trained batch 210 in epoch 9, gen_loss = 0.4329679745350969, disc_loss = 0.05871717841695482
Trained batch 211 in epoch 9, gen_loss = 0.433572345606561, disc_loss = 0.05897848376398027
Trained batch 212 in epoch 9, gen_loss = 0.43345284895717817, disc_loss = 0.058836758256990446
Trained batch 213 in epoch 9, gen_loss = 0.43303042190654256, disc_loss = 0.05943935564458022
Trained batch 214 in epoch 9, gen_loss = 0.4330627747746401, disc_loss = 0.05950900231119852
Trained batch 215 in epoch 9, gen_loss = 0.4330225884914398, disc_loss = 0.05941519377261607
Trained batch 216 in epoch 9, gen_loss = 0.43328614993029474, disc_loss = 0.059168464317488643
Trained batch 217 in epoch 9, gen_loss = 0.43337934033586345, disc_loss = 0.05898454015297012
Trained batch 218 in epoch 9, gen_loss = 0.433092585029123, disc_loss = 0.058852659987039084
Trained batch 219 in epoch 9, gen_loss = 0.4326996753161604, disc_loss = 0.05865430397785861
Trained batch 220 in epoch 9, gen_loss = 0.4323433179121751, disc_loss = 0.058476677857659656
Trained batch 221 in epoch 9, gen_loss = 0.43275501948219164, disc_loss = 0.05830348915890329
Trained batch 222 in epoch 9, gen_loss = 0.43293270401890505, disc_loss = 0.05808375979827993
Trained batch 223 in epoch 9, gen_loss = 0.43288311269134283, disc_loss = 0.05797860349204192
Trained batch 224 in epoch 9, gen_loss = 0.4333321260081397, disc_loss = 0.058837600981609686
Trained batch 225 in epoch 9, gen_loss = 0.4330492222731092, disc_loss = 0.05869460239619083
Trained batch 226 in epoch 9, gen_loss = 0.4328925635846176, disc_loss = 0.05932810510578463
Trained batch 227 in epoch 9, gen_loss = 0.4328053729575977, disc_loss = 0.059396289242023045
Trained batch 228 in epoch 9, gen_loss = 0.43281724046932035, disc_loss = 0.05933204343884077
Trained batch 229 in epoch 9, gen_loss = 0.4325786308101986, disc_loss = 0.05938712528744793
Trained batch 230 in epoch 9, gen_loss = 0.4323621919918886, disc_loss = 0.059642247970566734
Trained batch 231 in epoch 9, gen_loss = 0.4324035122990608, disc_loss = 0.06093161439338442
Trained batch 232 in epoch 9, gen_loss = 0.43228702151212567, disc_loss = 0.062116615780001674
Trained batch 233 in epoch 9, gen_loss = 0.43249163566491544, disc_loss = 0.06240695353764563
Trained batch 234 in epoch 9, gen_loss = 0.43259521240883686, disc_loss = 0.06228606261986684
Trained batch 235 in epoch 9, gen_loss = 0.43250197260561635, disc_loss = 0.06210620261105251
Trained batch 236 in epoch 9, gen_loss = 0.43249793017463845, disc_loss = 0.06194445953158198
Trained batch 237 in epoch 9, gen_loss = 0.43229059349088106, disc_loss = 0.06172287360248508
Trained batch 238 in epoch 9, gen_loss = 0.43218856638445513, disc_loss = 0.06151227210550939
Trained batch 239 in epoch 9, gen_loss = 0.4319599135468403, disc_loss = 0.06130985766067169
Trained batch 240 in epoch 9, gen_loss = 0.4321013006431928, disc_loss = 0.061102168756262766
Trained batch 241 in epoch 9, gen_loss = 0.4320424361662431, disc_loss = 0.060982185598724516
Trained batch 242 in epoch 9, gen_loss = 0.431849636045503, disc_loss = 0.06083458832775553
Trained batch 243 in epoch 9, gen_loss = 0.4320599811731792, disc_loss = 0.060963023322267974
Trained batch 244 in epoch 9, gen_loss = 0.4316863078243878, disc_loss = 0.06167093094780433
Trained batch 245 in epoch 9, gen_loss = 0.4318992084846264, disc_loss = 0.06206340396330064
Trained batch 246 in epoch 9, gen_loss = 0.43190535685794074, disc_loss = 0.06185392536004244
Trained batch 247 in epoch 9, gen_loss = 0.4317314117666214, disc_loss = 0.06199223648629061
Trained batch 248 in epoch 9, gen_loss = 0.4317389336455778, disc_loss = 0.06197456832803098
Trained batch 249 in epoch 9, gen_loss = 0.4317765779495239, disc_loss = 0.06262480643205345
Trained batch 250 in epoch 9, gen_loss = 0.43183521754238235, disc_loss = 0.06288412993818343
Trained batch 251 in epoch 9, gen_loss = 0.4321669607408463, disc_loss = 0.0629070816277009
Trained batch 252 in epoch 9, gen_loss = 0.43225110013023194, disc_loss = 0.06327847152646528
Trained batch 253 in epoch 9, gen_loss = 0.43223575309036283, disc_loss = 0.0635891651760376
Trained batch 254 in epoch 9, gen_loss = 0.43252847533600003, disc_loss = 0.06389459897307496
Trained batch 255 in epoch 9, gen_loss = 0.4325123092858121, disc_loss = 0.06373151198022242
Trained batch 256 in epoch 9, gen_loss = 0.4329155545522267, disc_loss = 0.06374113300655776
Trained batch 257 in epoch 9, gen_loss = 0.43283185270405555, disc_loss = 0.06428213034713165
Trained batch 258 in epoch 9, gen_loss = 0.43232995409763, disc_loss = 0.06554795414547375
Trained batch 259 in epoch 9, gen_loss = 0.4321566953108861, disc_loss = 0.0653664939947283
Trained batch 260 in epoch 9, gen_loss = 0.4323278724918877, disc_loss = 0.06523325473919396
Trained batch 261 in epoch 9, gen_loss = 0.4320984081230091, disc_loss = 0.0651542445243059
Trained batch 262 in epoch 9, gen_loss = 0.4321378203172647, disc_loss = 0.06513391612026798
Trained batch 263 in epoch 9, gen_loss = 0.43218150994542875, disc_loss = 0.06496128127169372
Trained batch 264 in epoch 9, gen_loss = 0.43225225491343805, disc_loss = 0.06513109874015428
Trained batch 265 in epoch 9, gen_loss = 0.4321703745010204, disc_loss = 0.06511463539121687
Trained batch 266 in epoch 9, gen_loss = 0.4319068891055575, disc_loss = 0.06503033628757024
Trained batch 267 in epoch 9, gen_loss = 0.4317646941809512, disc_loss = 0.06507703555407308
Trained batch 268 in epoch 9, gen_loss = 0.4316488708262107, disc_loss = 0.06486752854147752
Trained batch 269 in epoch 9, gen_loss = 0.4314280856538702, disc_loss = 0.06477243340643192
Trained batch 270 in epoch 9, gen_loss = 0.4311445434594946, disc_loss = 0.0645745904666004
Trained batch 271 in epoch 9, gen_loss = 0.4313209680292536, disc_loss = 0.06452136563294676
Trained batch 272 in epoch 9, gen_loss = 0.4315150206560617, disc_loss = 0.06434136913447971
Trained batch 273 in epoch 9, gen_loss = 0.43151334004245534, disc_loss = 0.0644424272493806
Trained batch 274 in epoch 9, gen_loss = 0.4314751433242451, disc_loss = 0.06453406147489493
Trained batch 275 in epoch 9, gen_loss = 0.43162590837565024, disc_loss = 0.06435649953883789
Trained batch 276 in epoch 9, gen_loss = 0.4316592514514923, disc_loss = 0.06414522524983605
Trained batch 277 in epoch 9, gen_loss = 0.43177856472756365, disc_loss = 0.06395328585091951
Trained batch 278 in epoch 9, gen_loss = 0.43196524289773786, disc_loss = 0.0639329140748842
Trained batch 279 in epoch 9, gen_loss = 0.4318576967077596, disc_loss = 0.06382685400977997
Trained batch 280 in epoch 9, gen_loss = 0.43166913754999425, disc_loss = 0.06377145823164183
Trained batch 281 in epoch 9, gen_loss = 0.4316868881384532, disc_loss = 0.06385301117098342
Trained batch 282 in epoch 9, gen_loss = 0.4315680391796907, disc_loss = 0.06399746526315703
Trained batch 283 in epoch 9, gen_loss = 0.43110597207092904, disc_loss = 0.06459250482304257
Trained batch 284 in epoch 9, gen_loss = 0.43082942868533886, disc_loss = 0.06482127546904641
Trained batch 285 in epoch 9, gen_loss = 0.43084305795756256, disc_loss = 0.06507551136192169
Trained batch 286 in epoch 9, gen_loss = 0.43078975083520604, disc_loss = 0.06530527539635629
Trained batch 287 in epoch 9, gen_loss = 0.43100833685861695, disc_loss = 0.06544890360964928
Trained batch 288 in epoch 9, gen_loss = 0.43065712072445034, disc_loss = 0.06563007896186004
Trained batch 289 in epoch 9, gen_loss = 0.4306344267623178, disc_loss = 0.06584396467801056
Trained batch 290 in epoch 9, gen_loss = 0.43066469142117453, disc_loss = 0.06572277678330381
Trained batch 291 in epoch 9, gen_loss = 0.4306558585942608, disc_loss = 0.06580570603765497
Trained batch 292 in epoch 9, gen_loss = 0.43031508157684534, disc_loss = 0.06595336478807465
Trained batch 293 in epoch 9, gen_loss = 0.4303053104553093, disc_loss = 0.06583500599178176
Trained batch 294 in epoch 9, gen_loss = 0.43002584263429805, disc_loss = 0.06597203474839107
Trained batch 295 in epoch 9, gen_loss = 0.4299656065130556, disc_loss = 0.06617543659003049
Trained batch 296 in epoch 9, gen_loss = 0.42977944056594414, disc_loss = 0.06665057138467728
Trained batch 297 in epoch 9, gen_loss = 0.4298342343344784, disc_loss = 0.06666376070594478
Trained batch 298 in epoch 9, gen_loss = 0.4297116403795006, disc_loss = 0.06651483882486471
Trained batch 299 in epoch 9, gen_loss = 0.429802504380544, disc_loss = 0.06673445098257313
Trained batch 300 in epoch 9, gen_loss = 0.4299554814927998, disc_loss = 0.06724019781949364
Trained batch 301 in epoch 9, gen_loss = 0.42996287977458625, disc_loss = 0.06710133796699641
Trained batch 302 in epoch 9, gen_loss = 0.43002044495576286, disc_loss = 0.06695404334805242
Trained batch 303 in epoch 9, gen_loss = 0.42971351007489783, disc_loss = 0.06691105458670982
Trained batch 304 in epoch 9, gen_loss = 0.4294440853791159, disc_loss = 0.06671062485146963
Trained batch 305 in epoch 9, gen_loss = 0.4294663327776529, disc_loss = 0.06664456937955145
Trained batch 306 in epoch 9, gen_loss = 0.42934003588819347, disc_loss = 0.0665237064327717
Trained batch 307 in epoch 9, gen_loss = 0.42935444908095644, disc_loss = 0.06646343455619674
Trained batch 308 in epoch 9, gen_loss = 0.4293471281582484, disc_loss = 0.06633212741820027
Trained batch 309 in epoch 9, gen_loss = 0.4293556663297838, disc_loss = 0.06640793737775136
Trained batch 310 in epoch 9, gen_loss = 0.42941210651321043, disc_loss = 0.06703209454325473
Trained batch 311 in epoch 9, gen_loss = 0.4296034103593765, disc_loss = 0.06689377886822256
Trained batch 312 in epoch 9, gen_loss = 0.4298030536014813, disc_loss = 0.06675793771027995
Trained batch 313 in epoch 9, gen_loss = 0.4297791473614942, disc_loss = 0.06657327340981051
Trained batch 314 in epoch 9, gen_loss = 0.42964880788137044, disc_loss = 0.06646524915649067
Trained batch 315 in epoch 9, gen_loss = 0.42947562963147706, disc_loss = 0.06633781401375663
Trained batch 316 in epoch 9, gen_loss = 0.4298505529244239, disc_loss = 0.06648189927178086
Trained batch 317 in epoch 9, gen_loss = 0.42965825848609396, disc_loss = 0.06636974073319737
Trained batch 318 in epoch 9, gen_loss = 0.42959725352290284, disc_loss = 0.0663074897120482
Trained batch 319 in epoch 9, gen_loss = 0.42976016867905853, disc_loss = 0.06622531631292077
Trained batch 320 in epoch 9, gen_loss = 0.429991740118306, disc_loss = 0.06607714097662554
Trained batch 321 in epoch 9, gen_loss = 0.4299211507628423, disc_loss = 0.06591318742811726
Trained batch 322 in epoch 9, gen_loss = 0.42994775823764386, disc_loss = 0.06573250768821537
Trained batch 323 in epoch 9, gen_loss = 0.429804388663651, disc_loss = 0.06566122983852517
Trained batch 324 in epoch 9, gen_loss = 0.42987298561976506, disc_loss = 0.06558055045656287
Trained batch 325 in epoch 9, gen_loss = 0.4301016242957554, disc_loss = 0.06578569815985492
Trained batch 326 in epoch 9, gen_loss = 0.4301281627894177, disc_loss = 0.06566642387841318
Trained batch 327 in epoch 9, gen_loss = 0.43012526467805956, disc_loss = 0.06557926210921212
Trained batch 328 in epoch 9, gen_loss = 0.43013172843535985, disc_loss = 0.06540738844587311
Trained batch 329 in epoch 9, gen_loss = 0.4299484763181571, disc_loss = 0.06535415655199552
Trained batch 330 in epoch 9, gen_loss = 0.43022269631800697, disc_loss = 0.06544202535899969
Trained batch 331 in epoch 9, gen_loss = 0.43045150973351604, disc_loss = 0.06528715050852218
Trained batch 332 in epoch 9, gen_loss = 0.43040953232003404, disc_loss = 0.06518085055785987
Trained batch 333 in epoch 9, gen_loss = 0.4303908655029571, disc_loss = 0.06504004178596605
Trained batch 334 in epoch 9, gen_loss = 0.4304214288939291, disc_loss = 0.0648703612706888
Trained batch 335 in epoch 9, gen_loss = 0.4303738780851875, disc_loss = 0.06480184975606833
Trained batch 336 in epoch 9, gen_loss = 0.4304764864175893, disc_loss = 0.06473417942569722
Trained batch 337 in epoch 9, gen_loss = 0.4304944846404375, disc_loss = 0.06488254895439294
Trained batch 338 in epoch 9, gen_loss = 0.4306890632198975, disc_loss = 0.06475227276566589
Trained batch 339 in epoch 9, gen_loss = 0.43081917455967733, disc_loss = 0.0647189882625004
Trained batch 340 in epoch 9, gen_loss = 0.4309336566680338, disc_loss = 0.06459656280610175
Trained batch 341 in epoch 9, gen_loss = 0.4309278981901749, disc_loss = 0.06495666322407274
Trained batch 342 in epoch 9, gen_loss = 0.43082971675402915, disc_loss = 0.06481173412287852
Trained batch 343 in epoch 9, gen_loss = 0.4308596264657586, disc_loss = 0.06492483966068777
Trained batch 344 in epoch 9, gen_loss = 0.4308679267116215, disc_loss = 0.0650930802391815
Trained batch 345 in epoch 9, gen_loss = 0.4310179806685861, disc_loss = 0.0662246840384202
Trained batch 346 in epoch 9, gen_loss = 0.4311499945196707, disc_loss = 0.0661345859144087
Trained batch 347 in epoch 9, gen_loss = 0.43101621128019246, disc_loss = 0.06610442622398807
Trained batch 348 in epoch 9, gen_loss = 0.4307827547320664, disc_loss = 0.06598868907794869
Trained batch 349 in epoch 9, gen_loss = 0.43116952989782603, disc_loss = 0.06600687794786479
Trained batch 350 in epoch 9, gen_loss = 0.4311537235720545, disc_loss = 0.06594344070764986
Trained batch 351 in epoch 9, gen_loss = 0.43111642060632055, disc_loss = 0.0659486073934452
Trained batch 352 in epoch 9, gen_loss = 0.4312013071927403, disc_loss = 0.0658876856369502
Trained batch 353 in epoch 9, gen_loss = 0.4314058000421793, disc_loss = 0.06590156854225039
Trained batch 354 in epoch 9, gen_loss = 0.4310811718584786, disc_loss = 0.06583929909130846
Trained batch 355 in epoch 9, gen_loss = 0.4310273857933752, disc_loss = 0.06617698604319495
Trained batch 356 in epoch 9, gen_loss = 0.43141038177394064, disc_loss = 0.06732756721054096
Trained batch 357 in epoch 9, gen_loss = 0.4313259125588326, disc_loss = 0.06723342403410491
Trained batch 358 in epoch 9, gen_loss = 0.43120270461093085, disc_loss = 0.06716810144395839
Trained batch 359 in epoch 9, gen_loss = 0.4310062137742837, disc_loss = 0.06719905142543009
Trained batch 360 in epoch 9, gen_loss = 0.4308253876720439, disc_loss = 0.06711061427194284
Trained batch 361 in epoch 9, gen_loss = 0.4307618547868992, disc_loss = 0.06697361312101682
Trained batch 362 in epoch 9, gen_loss = 0.4308038165910842, disc_loss = 0.0668398307382383
Trained batch 363 in epoch 9, gen_loss = 0.43089159553522594, disc_loss = 0.06667251268191939
Trained batch 364 in epoch 9, gen_loss = 0.4309670867985242, disc_loss = 0.06651469812894316
Trained batch 365 in epoch 9, gen_loss = 0.4308135485062834, disc_loss = 0.06642010538136495
Trained batch 366 in epoch 9, gen_loss = 0.4310158192299367, disc_loss = 0.06636363821997426
Trained batch 367 in epoch 9, gen_loss = 0.43093243597642233, disc_loss = 0.06621300953354323
Trained batch 368 in epoch 9, gen_loss = 0.43092618272879585, disc_loss = 0.06609562469323274
Trained batch 369 in epoch 9, gen_loss = 0.43081641076384364, disc_loss = 0.06595373272367225
Trained batch 370 in epoch 9, gen_loss = 0.43076563612470087, disc_loss = 0.06593068742200812
Trained batch 371 in epoch 9, gen_loss = 0.4309661462903023, disc_loss = 0.06607496216567733
Trained batch 372 in epoch 9, gen_loss = 0.4309795616299473, disc_loss = 0.06647802025314431
Trained batch 373 in epoch 9, gen_loss = 0.430935927492412, disc_loss = 0.06634923560609593
Trained batch 374 in epoch 9, gen_loss = 0.43081651139259336, disc_loss = 0.06625956468656659
Trained batch 375 in epoch 9, gen_loss = 0.430811899456572, disc_loss = 0.06614978825351461
Trained batch 376 in epoch 9, gen_loss = 0.4309574199608213, disc_loss = 0.06624507787328619
Trained batch 377 in epoch 9, gen_loss = 0.430934434845334, disc_loss = 0.0662567443817992
Trained batch 378 in epoch 9, gen_loss = 0.43101275328910443, disc_loss = 0.06616407782109675
Trained batch 379 in epoch 9, gen_loss = 0.43100215000541586, disc_loss = 0.06606766962764883
Trained batch 380 in epoch 9, gen_loss = 0.4311256159947613, disc_loss = 0.06594719256584843
Trained batch 381 in epoch 9, gen_loss = 0.431176124676984, disc_loss = 0.06581172774331302
Trained batch 382 in epoch 9, gen_loss = 0.43131963655780564, disc_loss = 0.06566971204761542
Trained batch 383 in epoch 9, gen_loss = 0.43131610999504727, disc_loss = 0.06552232673978627
Trained batch 384 in epoch 9, gen_loss = 0.4313199922635958, disc_loss = 0.0653690777610165
Trained batch 385 in epoch 9, gen_loss = 0.43134330429252565, disc_loss = 0.06523713724895193
Trained batch 386 in epoch 9, gen_loss = 0.43132298098978145, disc_loss = 0.0651744482304795
Trained batch 387 in epoch 9, gen_loss = 0.4311964844459111, disc_loss = 0.06512363917151101
Trained batch 388 in epoch 9, gen_loss = 0.4312016245332046, disc_loss = 0.06499477816927594
Trained batch 389 in epoch 9, gen_loss = 0.43146929664489553, disc_loss = 0.06512964152110119
Trained batch 390 in epoch 9, gen_loss = 0.43156145044299954, disc_loss = 0.06509309596575015
Trained batch 391 in epoch 9, gen_loss = 0.4317864682145265, disc_loss = 0.06494858737070379
Trained batch 392 in epoch 9, gen_loss = 0.43187157305445684, disc_loss = 0.06482045700223808
Trained batch 393 in epoch 9, gen_loss = 0.43183976328615004, disc_loss = 0.06467616884156041
Trained batch 394 in epoch 9, gen_loss = 0.4319974067090433, disc_loss = 0.06454962337436744
Trained batch 395 in epoch 9, gen_loss = 0.4321853109832966, disc_loss = 0.06487618021859853
Trained batch 396 in epoch 9, gen_loss = 0.43213237953426253, disc_loss = 0.06488654638760223
Trained batch 397 in epoch 9, gen_loss = 0.432140823884226, disc_loss = 0.06476172667357079
Trained batch 398 in epoch 9, gen_loss = 0.43223874961821956, disc_loss = 0.06478151076947126
Trained batch 399 in epoch 9, gen_loss = 0.43239593610167504, disc_loss = 0.06475089940358884
Trained batch 400 in epoch 9, gen_loss = 0.4324755928760158, disc_loss = 0.06465172699938279
Trained batch 401 in epoch 9, gen_loss = 0.432500209233061, disc_loss = 0.06452856181926135
Trained batch 402 in epoch 9, gen_loss = 0.43256934974388805, disc_loss = 0.06439791515437197
Trained batch 403 in epoch 9, gen_loss = 0.4324591659230761, disc_loss = 0.06428249882612525
Trained batch 404 in epoch 9, gen_loss = 0.4325354035989738, disc_loss = 0.06417517220647431
Trained batch 405 in epoch 9, gen_loss = 0.432535344890773, disc_loss = 0.06404572674486181
Trained batch 406 in epoch 9, gen_loss = 0.43248710585460615, disc_loss = 0.06408751207342056
Trained batch 407 in epoch 9, gen_loss = 0.4323747259582959, disc_loss = 0.06398381034537748
Trained batch 408 in epoch 9, gen_loss = 0.4323760965488359, disc_loss = 0.06388080008168566
Trained batch 409 in epoch 9, gen_loss = 0.4323216356155349, disc_loss = 0.06377422576202307
Trained batch 410 in epoch 9, gen_loss = 0.43232641015609685, disc_loss = 0.06371084087779813
Trained batch 411 in epoch 9, gen_loss = 0.43244969606110195, disc_loss = 0.0636289297406408
Trained batch 412 in epoch 9, gen_loss = 0.43247927173286604, disc_loss = 0.06352488538385628
Trained batch 413 in epoch 9, gen_loss = 0.43242904104760305, disc_loss = 0.0634022856992782
Trained batch 414 in epoch 9, gen_loss = 0.4322767533451678, disc_loss = 0.06331480546596359
Trained batch 415 in epoch 9, gen_loss = 0.43210489052132917, disc_loss = 0.06329541549404474
Trained batch 416 in epoch 9, gen_loss = 0.432337354341571, disc_loss = 0.06367334283830271
Trained batch 417 in epoch 9, gen_loss = 0.4323891061915165, disc_loss = 0.06355275751679744
Trained batch 418 in epoch 9, gen_loss = 0.4323123169258272, disc_loss = 0.06349128584859799
Trained batch 419 in epoch 9, gen_loss = 0.4323489032330967, disc_loss = 0.06339579135556483
Trained batch 420 in epoch 9, gen_loss = 0.43237056153120734, disc_loss = 0.06326535367904643
Trained batch 421 in epoch 9, gen_loss = 0.43244139906636914, disc_loss = 0.06317763405596016
Trained batch 422 in epoch 9, gen_loss = 0.4325083747118641, disc_loss = 0.06307430291794963
Trained batch 423 in epoch 9, gen_loss = 0.4325077454998808, disc_loss = 0.06304101913372266
Trained batch 424 in epoch 9, gen_loss = 0.4325791152084575, disc_loss = 0.06292381350060597
Trained batch 425 in epoch 9, gen_loss = 0.4323765310882962, disc_loss = 0.06306543526843085
Trained batch 426 in epoch 9, gen_loss = 0.4325178454017192, disc_loss = 0.06390692102035782
Trained batch 427 in epoch 9, gen_loss = 0.43235739362295544, disc_loss = 0.06388348815679794
Trained batch 428 in epoch 9, gen_loss = 0.43245051179454597, disc_loss = 0.06382929785871805
Trained batch 429 in epoch 9, gen_loss = 0.4323106733865516, disc_loss = 0.06376343468572337
Trained batch 430 in epoch 9, gen_loss = 0.4322212128932404, disc_loss = 0.06367199841061318
Trained batch 431 in epoch 9, gen_loss = 0.43210971176072405, disc_loss = 0.06365855282099263
Trained batch 432 in epoch 9, gen_loss = 0.43188489467662694, disc_loss = 0.06366549290213347
Trained batch 433 in epoch 9, gen_loss = 0.43201747454256506, disc_loss = 0.06363992347416343
Trained batch 434 in epoch 9, gen_loss = 0.432280685846833, disc_loss = 0.06355567693003807
Trained batch 435 in epoch 9, gen_loss = 0.43221184057653494, disc_loss = 0.06357087994981216
Trained batch 436 in epoch 9, gen_loss = 0.4321872231889371, disc_loss = 0.06360387510899242
Trained batch 437 in epoch 9, gen_loss = 0.4322281726146942, disc_loss = 0.06352837054063162
Trained batch 438 in epoch 9, gen_loss = 0.43223682378582096, disc_loss = 0.06356035169863178
Trained batch 439 in epoch 9, gen_loss = 0.43219261806119574, disc_loss = 0.06353041687451133
Trained batch 440 in epoch 9, gen_loss = 0.4322204108681538, disc_loss = 0.06340432164202235
Trained batch 441 in epoch 9, gen_loss = 0.43237266315324274, disc_loss = 0.0632765082867892
Trained batch 442 in epoch 9, gen_loss = 0.4323816416495002, disc_loss = 0.06317188477135235
Trained batch 443 in epoch 9, gen_loss = 0.43228853399957623, disc_loss = 0.06316535472597189
Trained batch 444 in epoch 9, gen_loss = 0.4321323556846447, disc_loss = 0.06325001851289293
Trained batch 445 in epoch 9, gen_loss = 0.4321466499246289, disc_loss = 0.0638219574581197
Trained batch 446 in epoch 9, gen_loss = 0.43227778978529124, disc_loss = 0.06380917950193721
Trained batch 447 in epoch 9, gen_loss = 0.4322722480366273, disc_loss = 0.063716551595592
Trained batch 448 in epoch 9, gen_loss = 0.43221239483436125, disc_loss = 0.06381371546690176
Trained batch 449 in epoch 9, gen_loss = 0.43203371127446494, disc_loss = 0.06386119379661977
Trained batch 450 in epoch 9, gen_loss = 0.432171861639044, disc_loss = 0.06375608010787492
Trained batch 451 in epoch 9, gen_loss = 0.43221827411809854, disc_loss = 0.06364415885068773
Trained batch 452 in epoch 9, gen_loss = 0.4322385841252788, disc_loss = 0.06354082973106512
Trained batch 453 in epoch 9, gen_loss = 0.43208355866864917, disc_loss = 0.0634778101635186
Trained batch 454 in epoch 9, gen_loss = 0.4320381834611788, disc_loss = 0.06373697244511037
Trained batch 455 in epoch 9, gen_loss = 0.432399906021984, disc_loss = 0.06397173550743773
Trained batch 456 in epoch 9, gen_loss = 0.4324337988113679, disc_loss = 0.06386349185449387
Trained batch 457 in epoch 9, gen_loss = 0.43242857328668954, disc_loss = 0.06373732705299609
Trained batch 458 in epoch 9, gen_loss = 0.432396249443877, disc_loss = 0.06395271448783722
Trained batch 459 in epoch 9, gen_loss = 0.43251705104890076, disc_loss = 0.0638852898426273
Trained batch 460 in epoch 9, gen_loss = 0.43240983321971854, disc_loss = 0.06379337164264277
Trained batch 461 in epoch 9, gen_loss = 0.4323939984236961, disc_loss = 0.06366941612314643
Trained batch 462 in epoch 9, gen_loss = 0.43243732018553155, disc_loss = 0.06356031482548455
Trained batch 463 in epoch 9, gen_loss = 0.43233843584512843, disc_loss = 0.06345595870917695
Trained batch 464 in epoch 9, gen_loss = 0.43221399341860123, disc_loss = 0.06333481293391957
Trained batch 465 in epoch 9, gen_loss = 0.43224409734230695, disc_loss = 0.0632163230179861
Trained batch 466 in epoch 9, gen_loss = 0.4321728892448883, disc_loss = 0.06309726328949984
Trained batch 467 in epoch 9, gen_loss = 0.43217763737735587, disc_loss = 0.06301026693823883
Trained batch 468 in epoch 9, gen_loss = 0.43210398286644586, disc_loss = 0.06288671740062678
Trained batch 469 in epoch 9, gen_loss = 0.43204449808343925, disc_loss = 0.06277191930727914
Trained batch 470 in epoch 9, gen_loss = 0.43193920706487765, disc_loss = 0.06267243167069086
Trained batch 471 in epoch 9, gen_loss = 0.4317589145848307, disc_loss = 0.06255448556611694
Trained batch 472 in epoch 9, gen_loss = 0.4316278984002281, disc_loss = 0.06244516958941333
Trained batch 473 in epoch 9, gen_loss = 0.43160539368788403, disc_loss = 0.06245054155568502
Trained batch 474 in epoch 9, gen_loss = 0.4316862474617205, disc_loss = 0.06272551965066477
Trained batch 475 in epoch 9, gen_loss = 0.43153194294256325, disc_loss = 0.06273083207530103
Trained batch 476 in epoch 9, gen_loss = 0.43159608539795224, disc_loss = 0.06265462633804174
Trained batch 477 in epoch 9, gen_loss = 0.43171542714579836, disc_loss = 0.06259920074269332
Trained batch 478 in epoch 9, gen_loss = 0.4317871391275482, disc_loss = 0.06249030138461195
Trained batch 479 in epoch 9, gen_loss = 0.4317590334142248, disc_loss = 0.0625133718548265
Trained batch 480 in epoch 9, gen_loss = 0.4317995544035073, disc_loss = 0.06239868993938682
Trained batch 481 in epoch 9, gen_loss = 0.4319155733120392, disc_loss = 0.062467478423406414
Trained batch 482 in epoch 9, gen_loss = 0.4318242375401483, disc_loss = 0.06239037190160982
Trained batch 483 in epoch 9, gen_loss = 0.4315724622858457, disc_loss = 0.06253233307891733
Trained batch 484 in epoch 9, gen_loss = 0.43165684102736795, disc_loss = 0.0626402053857203
Trained batch 485 in epoch 9, gen_loss = 0.43178355963632403, disc_loss = 0.06256261724622253
Trained batch 486 in epoch 9, gen_loss = 0.4317977771132389, disc_loss = 0.062463251614725136
Trained batch 487 in epoch 9, gen_loss = 0.43186687629242415, disc_loss = 0.06237725829266653
Trained batch 488 in epoch 9, gen_loss = 0.43178413451814945, disc_loss = 0.06237325786588169
Trained batch 489 in epoch 9, gen_loss = 0.43152698983951493, disc_loss = 0.06282574505241094
Trained batch 490 in epoch 9, gen_loss = 0.43162937975221155, disc_loss = 0.06272939391066217
Trained batch 491 in epoch 9, gen_loss = 0.4315869690683799, disc_loss = 0.0628436186295987
Trained batch 492 in epoch 9, gen_loss = 0.431552895063319, disc_loss = 0.06278672822208935
Trained batch 493 in epoch 9, gen_loss = 0.4314776236711726, disc_loss = 0.06277538743529937
Trained batch 494 in epoch 9, gen_loss = 0.4312338552089653, disc_loss = 0.06291569716231239
Trained batch 495 in epoch 9, gen_loss = 0.4312812506912216, disc_loss = 0.06284875527396047
Trained batch 496 in epoch 9, gen_loss = 0.4313328911960725, disc_loss = 0.06277485478808073
Trained batch 497 in epoch 9, gen_loss = 0.431233473511106, disc_loss = 0.06271717516260304
Trained batch 498 in epoch 9, gen_loss = 0.43111455882479527, disc_loss = 0.0627237968062814
Trained batch 499 in epoch 9, gen_loss = 0.43118805277347566, disc_loss = 0.06282413609232754
Trained batch 500 in epoch 9, gen_loss = 0.4312198064522353, disc_loss = 0.06274705204997442
Trained batch 501 in epoch 9, gen_loss = 0.43111457518372404, disc_loss = 0.06273042787871957
Trained batch 502 in epoch 9, gen_loss = 0.43114990819519605, disc_loss = 0.06265599450844508
Trained batch 503 in epoch 9, gen_loss = 0.431287770529115, disc_loss = 0.06264598428046271
Trained batch 504 in epoch 9, gen_loss = 0.4313757069630198, disc_loss = 0.06260176377629142
Trained batch 505 in epoch 9, gen_loss = 0.43146446559268964, disc_loss = 0.06253385757972217
Trained batch 506 in epoch 9, gen_loss = 0.4311932146666788, disc_loss = 0.06256197422974297
Trained batch 507 in epoch 9, gen_loss = 0.43136428625095546, disc_loss = 0.06248425134167984
Trained batch 508 in epoch 9, gen_loss = 0.43131462319192343, disc_loss = 0.062415716213618785
Trained batch 509 in epoch 9, gen_loss = 0.43128376088890374, disc_loss = 0.062310439789229455
Trained batch 510 in epoch 9, gen_loss = 0.4311121560472798, disc_loss = 0.062268008715828514
Trained batch 511 in epoch 9, gen_loss = 0.4310490072821267, disc_loss = 0.062182684027902724
Trained batch 512 in epoch 9, gen_loss = 0.43112040611735564, disc_loss = 0.062105047760701956
Trained batch 513 in epoch 9, gen_loss = 0.43113990516514167, disc_loss = 0.062025377942713025
Trained batch 514 in epoch 9, gen_loss = 0.43101742695836187, disc_loss = 0.06214724116804964
Trained batch 515 in epoch 9, gen_loss = 0.4311348078555839, disc_loss = 0.06224472689633655
Trained batch 516 in epoch 9, gen_loss = 0.43124472161095656, disc_loss = 0.06215209100031559
Trained batch 517 in epoch 9, gen_loss = 0.4310921515737261, disc_loss = 0.06211680580653308
Trained batch 518 in epoch 9, gen_loss = 0.4310899183929311, disc_loss = 0.06203777310465371
Trained batch 519 in epoch 9, gen_loss = 0.43119519845797466, disc_loss = 0.0619426854304038
Trained batch 520 in epoch 9, gen_loss = 0.4311988239324939, disc_loss = 0.06189363263100529
Trained batch 521 in epoch 9, gen_loss = 0.43109714048575626, disc_loss = 0.06184792759028974
Trained batch 522 in epoch 9, gen_loss = 0.4310701173760467, disc_loss = 0.06177483417403601
Trained batch 523 in epoch 9, gen_loss = 0.4309617032986561, disc_loss = 0.061679044524243255
Trained batch 524 in epoch 9, gen_loss = 0.43090359988666715, disc_loss = 0.06157064322914396
Trained batch 525 in epoch 9, gen_loss = 0.43106627254658325, disc_loss = 0.061463059921228386
Trained batch 526 in epoch 9, gen_loss = 0.4311583497945, disc_loss = 0.061357133736413334
Trained batch 527 in epoch 9, gen_loss = 0.4310552862783273, disc_loss = 0.0612803397613761
Trained batch 528 in epoch 9, gen_loss = 0.4311892938974449, disc_loss = 0.06117580599452603
Trained batch 529 in epoch 9, gen_loss = 0.43110926173767955, disc_loss = 0.06109904199926499
Trained batch 530 in epoch 9, gen_loss = 0.43093828388302113, disc_loss = 0.06138303881623342
Trained batch 531 in epoch 9, gen_loss = 0.43073112192682755, disc_loss = 0.06182517923670296
Trained batch 532 in epoch 9, gen_loss = 0.4306926441572844, disc_loss = 0.06178673758043944
Trained batch 533 in epoch 9, gen_loss = 0.4308577599038792, disc_loss = 0.06179650732113767
Trained batch 534 in epoch 9, gen_loss = 0.4308654619154529, disc_loss = 0.06173566719168954
Trained batch 535 in epoch 9, gen_loss = 0.4307745809652912, disc_loss = 0.06170123942116442
Trained batch 536 in epoch 9, gen_loss = 0.4308771048733198, disc_loss = 0.061621385337732856
Trained batch 537 in epoch 9, gen_loss = 0.4309096324731869, disc_loss = 0.0615313720125982
Trained batch 538 in epoch 9, gen_loss = 0.43087961086536825, disc_loss = 0.06147337183511793
Trained batch 539 in epoch 9, gen_loss = 0.43085197811877285, disc_loss = 0.0615022121730295
Trained batch 540 in epoch 9, gen_loss = 0.4308995406751051, disc_loss = 0.0617077250606871
Trained batch 541 in epoch 9, gen_loss = 0.4308004857099364, disc_loss = 0.06163337162517121
Trained batch 542 in epoch 9, gen_loss = 0.4306596299671117, disc_loss = 0.061624791793024394
Trained batch 543 in epoch 9, gen_loss = 0.4306530887261033, disc_loss = 0.06156831057759358
Trained batch 544 in epoch 9, gen_loss = 0.4305330297268859, disc_loss = 0.06159284221213482
Trained batch 545 in epoch 9, gen_loss = 0.43049021458232795, disc_loss = 0.061527880803330534
Trained batch 546 in epoch 9, gen_loss = 0.430480861522162, disc_loss = 0.06143243051299202
Trained batch 547 in epoch 9, gen_loss = 0.43048130791552747, disc_loss = 0.0613394477005273
Trained batch 548 in epoch 9, gen_loss = 0.4304886481475309, disc_loss = 0.06124473226176938
Trained batch 549 in epoch 9, gen_loss = 0.4304836916923523, disc_loss = 0.06122629811902615
Trained batch 550 in epoch 9, gen_loss = 0.4305302274097332, disc_loss = 0.06113521171017075
Trained batch 551 in epoch 9, gen_loss = 0.43057655958809715, disc_loss = 0.06105333145630235
Trained batch 552 in epoch 9, gen_loss = 0.43065227220545627, disc_loss = 0.06097714066805207
Trained batch 553 in epoch 9, gen_loss = 0.43060066914085016, disc_loss = 0.06097810833197127
Trained batch 554 in epoch 9, gen_loss = 0.4306900610257913, disc_loss = 0.06095009043493921
Trained batch 555 in epoch 9, gen_loss = 0.43057653709924476, disc_loss = 0.06095490871389269
Trained batch 556 in epoch 9, gen_loss = 0.4306336376461563, disc_loss = 0.06089568160945814
Trained batch 557 in epoch 9, gen_loss = 0.4306235971416624, disc_loss = 0.06080568789531173
Trained batch 558 in epoch 9, gen_loss = 0.43066142230213006, disc_loss = 0.060763677393047937
Trained batch 559 in epoch 9, gen_loss = 0.43065814338624475, disc_loss = 0.06076074411643536
Trained batch 560 in epoch 9, gen_loss = 0.43066380161015105, disc_loss = 0.06076432865547969
Trained batch 561 in epoch 9, gen_loss = 0.43074337735082757, disc_loss = 0.06077023622168898
Trained batch 562 in epoch 9, gen_loss = 0.430874975970541, disc_loss = 0.060769631533154005
Trained batch 563 in epoch 9, gen_loss = 0.4308676317545539, disc_loss = 0.06074612196089026
Trained batch 564 in epoch 9, gen_loss = 0.43082001931899416, disc_loss = 0.06081359090481316
Trained batch 565 in epoch 9, gen_loss = 0.43087672128904836, disc_loss = 0.0611116612805613
Trained batch 566 in epoch 9, gen_loss = 0.4309515821134813, disc_loss = 0.06101877092937339
Trained batch 567 in epoch 9, gen_loss = 0.43085123063393044, disc_loss = 0.06093560395726252
Trained batch 568 in epoch 9, gen_loss = 0.4308929730907266, disc_loss = 0.06083980668254314
Trained batch 569 in epoch 9, gen_loss = 0.43082198913682973, disc_loss = 0.06076776592567432
Trained batch 570 in epoch 9, gen_loss = 0.4306984700379981, disc_loss = 0.06076302280936605
Trained batch 571 in epoch 9, gen_loss = 0.43056474600013317, disc_loss = 0.06067154141081093
Trained batch 572 in epoch 9, gen_loss = 0.43062506348258744, disc_loss = 0.06060397582141647
Trained batch 573 in epoch 9, gen_loss = 0.43063201295789527, disc_loss = 0.06053873985269162
Trained batch 574 in epoch 9, gen_loss = 0.43060842094214064, disc_loss = 0.060578222071509
Trained batch 575 in epoch 9, gen_loss = 0.430539276295652, disc_loss = 0.06048922965176947
Trained batch 576 in epoch 9, gen_loss = 0.43049851225195146, disc_loss = 0.06040321514284822
Trained batch 577 in epoch 9, gen_loss = 0.4305939389244495, disc_loss = 0.06032744246038727
Trained batch 578 in epoch 9, gen_loss = 0.43051901392780234, disc_loss = 0.06027166380760918
Trained batch 579 in epoch 9, gen_loss = 0.43052341172407416, disc_loss = 0.060308863531701784
Trained batch 580 in epoch 9, gen_loss = 0.43062203583947145, disc_loss = 0.06022988485730223
Trained batch 581 in epoch 9, gen_loss = 0.43065989396416443, disc_loss = 0.06013913525434857
Trained batch 582 in epoch 9, gen_loss = 0.4305540479170111, disc_loss = 0.06012926835208927
Trained batch 583 in epoch 9, gen_loss = 0.4305652687708809, disc_loss = 0.060216732098312714
Trained batch 584 in epoch 9, gen_loss = 0.43047495316236445, disc_loss = 0.06014702885101239
Trained batch 585 in epoch 9, gen_loss = 0.4304018831293738, disc_loss = 0.06008827274843237
Trained batch 586 in epoch 9, gen_loss = 0.4304912457880413, disc_loss = 0.06000010043801502
Trained batch 587 in epoch 9, gen_loss = 0.4306609115633024, disc_loss = 0.05993233618586242
Trained batch 588 in epoch 9, gen_loss = 0.4307939250319437, disc_loss = 0.059946747835099394
Trained batch 589 in epoch 9, gen_loss = 0.4309332687975997, disc_loss = 0.05992288632413088
Trained batch 590 in epoch 9, gen_loss = 0.43105373850530376, disc_loss = 0.05987757774047844
Trained batch 591 in epoch 9, gen_loss = 0.43103565421660206, disc_loss = 0.05982720144596454
Trained batch 592 in epoch 9, gen_loss = 0.43086509786005966, disc_loss = 0.06020166959871128
Trained batch 593 in epoch 9, gen_loss = 0.43074767120960183, disc_loss = 0.0605406116706755
Trained batch 594 in epoch 9, gen_loss = 0.4308586427644521, disc_loss = 0.06054976094169777
Trained batch 595 in epoch 9, gen_loss = 0.4308376588777408, disc_loss = 0.060618772602721346
Testing Epoch 9
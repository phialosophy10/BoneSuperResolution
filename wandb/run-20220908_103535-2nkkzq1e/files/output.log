/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 1.7246273756027222, disc_loss = 0.5912789106369019
Trained batch 1 in epoch 0, gen_loss = 1.570762574672699, disc_loss = 0.5508291125297546
Trained batch 2 in epoch 0, gen_loss = 1.5790916681289673, disc_loss = 0.6245667338371277
Trained batch 3 in epoch 0, gen_loss = 1.5810210406780243, disc_loss = 0.6013409346342087
Trained batch 4 in epoch 0, gen_loss = 1.5648244142532348, disc_loss = 0.5762080669403076
Trained batch 5 in epoch 0, gen_loss = 1.555915613969167, disc_loss = 0.560198093454043
Trained batch 6 in epoch 0, gen_loss = 1.5175538403647286, disc_loss = 0.517997281891959
Trained batch 7 in epoch 0, gen_loss = 1.5228395015001297, disc_loss = 0.4908275753259659
Trained batch 8 in epoch 0, gen_loss = 1.5058865282270644, disc_loss = 0.4594913836982515
Trained batch 9 in epoch 0, gen_loss = 1.5023322701454163, disc_loss = 0.4398787096142769
Trained batch 10 in epoch 0, gen_loss = 1.4915988120165737, disc_loss = 0.41818020154129376
Trained batch 11 in epoch 0, gen_loss = 1.4752654731273651, disc_loss = 0.4049781945844491
Trained batch 12 in epoch 0, gen_loss = 1.4580598335999708, disc_loss = 0.39172687094945174
Trained batch 13 in epoch 0, gen_loss = 1.4531532611165727, disc_loss = 0.3771625565631049
Trained batch 14 in epoch 0, gen_loss = 1.4582809368769327, disc_loss = 0.3631709059079488
Trained batch 15 in epoch 0, gen_loss = 1.4721450805664062, disc_loss = 0.3485934603959322
Trained batch 16 in epoch 0, gen_loss = 1.480024485027089, disc_loss = 0.3350989397834329
Trained batch 17 in epoch 0, gen_loss = 1.482304208808475, disc_loss = 0.3232543029718929
Trained batch 18 in epoch 0, gen_loss = 1.4740095703225387, disc_loss = 0.31301596368614
Trained batch 19 in epoch 0, gen_loss = 1.4778963267803191, disc_loss = 0.30415102019906043
Trained batch 20 in epoch 0, gen_loss = 1.4874336208615984, disc_loss = 0.29802019113586065
Trained batch 21 in epoch 0, gen_loss = 1.4970090497623791, disc_loss = 0.2908346964554353
Trained batch 22 in epoch 0, gen_loss = 1.5014888203662375, disc_loss = 0.2828845754265785
Trained batch 23 in epoch 0, gen_loss = 1.5015237232049305, disc_loss = 0.2748120467488964
Trained batch 24 in epoch 0, gen_loss = 1.5186516380310058, disc_loss = 0.26700502723455427
Trained batch 25 in epoch 0, gen_loss = 1.5242664172099187, disc_loss = 0.26024613787348455
Trained batch 26 in epoch 0, gen_loss = 1.5260416048544425, disc_loss = 0.25298704814027856
Trained batch 27 in epoch 0, gen_loss = 1.5263059607573919, disc_loss = 0.24646789208054543
Trained batch 28 in epoch 0, gen_loss = 1.5305760687795178, disc_loss = 0.24025663682099047
Trained batch 29 in epoch 0, gen_loss = 1.5329726139704387, disc_loss = 0.23541154836614928
Trained batch 30 in epoch 0, gen_loss = 1.5398193020974436, disc_loss = 0.23036150658322918
Trained batch 31 in epoch 0, gen_loss = 1.5470651686191559, disc_loss = 0.22590619348920882
Trained batch 32 in epoch 0, gen_loss = 1.5489907264709473, disc_loss = 0.22127530272259857
Trained batch 33 in epoch 0, gen_loss = 1.554674176608815, disc_loss = 0.21680515325244734
Trained batch 34 in epoch 0, gen_loss = 1.56068389075143, disc_loss = 0.21219032662255424
Trained batch 35 in epoch 0, gen_loss = 1.5637498729758792, disc_loss = 0.20797180425789621
Trained batch 36 in epoch 0, gen_loss = 1.5630838484377474, disc_loss = 0.2037322466840615
Trained batch 37 in epoch 0, gen_loss = 1.5700838785422475, disc_loss = 0.19959426524215623
Trained batch 38 in epoch 0, gen_loss = 1.575963359612685, disc_loss = 0.19597090513278276
Trained batch 39 in epoch 0, gen_loss = 1.576699748635292, disc_loss = 0.193058205768466
Trained batch 40 in epoch 0, gen_loss = 1.5730129771116304, disc_loss = 0.1904675106449825
Trained batch 41 in epoch 0, gen_loss = 1.5758510373887562, disc_loss = 0.18783450800748097
Trained batch 42 in epoch 0, gen_loss = 1.5849619022635526, disc_loss = 0.1847468676955201
Trained batch 43 in epoch 0, gen_loss = 1.5897159711881117, disc_loss = 0.1816124738278714
Trained batch 44 in epoch 0, gen_loss = 1.5890583170784844, disc_loss = 0.17870198123984868
Trained batch 45 in epoch 0, gen_loss = 1.5890282159266265, disc_loss = 0.17583508692357852
Trained batch 46 in epoch 0, gen_loss = 1.5917767590664802, disc_loss = 0.1730949491103913
Trained batch 47 in epoch 0, gen_loss = 1.590728926161925, disc_loss = 0.17080338741652668
Trained batch 48 in epoch 0, gen_loss = 1.5943268513192936, disc_loss = 0.16831115374759753
Trained batch 49 in epoch 0, gen_loss = 1.5983550310134889, disc_loss = 0.16595615908503533
Trained batch 50 in epoch 0, gen_loss = 1.603771543970295, disc_loss = 0.16354433366773174
Trained batch 51 in epoch 0, gen_loss = 1.6069124203461866, disc_loss = 0.16104313802833742
Trained batch 52 in epoch 0, gen_loss = 1.609482711216189, disc_loss = 0.15886421789819338
Trained batch 53 in epoch 0, gen_loss = 1.613840103149414, disc_loss = 0.15691081910497612
Trained batch 54 in epoch 0, gen_loss = 1.620121151750738, disc_loss = 0.1552183631468903
Trained batch 55 in epoch 0, gen_loss = 1.6227962034089225, disc_loss = 0.15327623839090979
Trained batch 56 in epoch 0, gen_loss = 1.632619481337698, disc_loss = 0.15154285781216204
Trained batch 57 in epoch 0, gen_loss = 1.6346295290979846, disc_loss = 0.15000911789207622
Trained batch 58 in epoch 0, gen_loss = 1.6401822162886797, disc_loss = 0.1481683966466936
Trained batch 59 in epoch 0, gen_loss = 1.6442902445793153, disc_loss = 0.1464140374213457
Trained batch 60 in epoch 0, gen_loss = 1.648543541548682, disc_loss = 0.14467005834716265
Trained batch 61 in epoch 0, gen_loss = 1.6514878715238264, disc_loss = 0.1432149698056521
Trained batch 62 in epoch 0, gen_loss = 1.6540715618739052, disc_loss = 0.1415364079413906
Trained batch 63 in epoch 0, gen_loss = 1.657124375924468, disc_loss = 0.13993538916110992
Trained batch 64 in epoch 0, gen_loss = 1.6624698730615468, disc_loss = 0.13876230132121306
Trained batch 65 in epoch 0, gen_loss = 1.6663783824805058, disc_loss = 0.13766700582522334
Trained batch 66 in epoch 0, gen_loss = 1.6692562637044424, disc_loss = 0.13638784814236768
Trained batch 67 in epoch 0, gen_loss = 1.6715469605782454, disc_loss = 0.13478204325827606
Trained batch 68 in epoch 0, gen_loss = 1.6740635961726091, disc_loss = 0.1333919020936541
Trained batch 69 in epoch 0, gen_loss = 1.6750894103731429, disc_loss = 0.13206109343362707
Trained batch 70 in epoch 0, gen_loss = 1.6765284403948717, disc_loss = 0.1306097096383152
Trained batch 71 in epoch 0, gen_loss = 1.6775384578439925, disc_loss = 0.12911915165993074
Trained batch 72 in epoch 0, gen_loss = 1.676094463426773, disc_loss = 0.12858449522252768
Trained batch 73 in epoch 0, gen_loss = 1.6761523098558992, disc_loss = 0.1282225954723922
Trained batch 74 in epoch 0, gen_loss = 1.6791222858428956, disc_loss = 0.12712442410488922
Trained batch 75 in epoch 0, gen_loss = 1.684992448279732, disc_loss = 0.12602145972318554
Trained batch 76 in epoch 0, gen_loss = 1.6847152802851293, disc_loss = 0.12502176423448247
Trained batch 77 in epoch 0, gen_loss = 1.6836618276742787, disc_loss = 0.12410311594318885
Trained batch 78 in epoch 0, gen_loss = 1.68540946139565, disc_loss = 0.12306185318982299
Trained batch 79 in epoch 0, gen_loss = 1.6834366127848626, disc_loss = 0.1217723353067413
Trained batch 80 in epoch 0, gen_loss = 1.680246631304423, disc_loss = 0.12060662839607691
Trained batch 81 in epoch 0, gen_loss = 1.6813365526315642, disc_loss = 0.11943166144192219
Trained batch 82 in epoch 0, gen_loss = 1.6830775924475796, disc_loss = 0.11818651464509677
Trained batch 83 in epoch 0, gen_loss = 1.6830259476389204, disc_loss = 0.11699967352407319
Trained batch 84 in epoch 0, gen_loss = 1.6833481087404139, disc_loss = 0.11582856901428279
Trained batch 85 in epoch 0, gen_loss = 1.6820908784866333, disc_loss = 0.11466413898783367
Trained batch 86 in epoch 0, gen_loss = 1.6805577812523678, disc_loss = 0.11371752343558032
Trained batch 87 in epoch 0, gen_loss = 1.6771109158342534, disc_loss = 0.11266152810474689
Trained batch 88 in epoch 0, gen_loss = 1.6750252943360404, disc_loss = 0.1116452348742927
Trained batch 89 in epoch 0, gen_loss = 1.6738171418507894, disc_loss = 0.11060720361355278
Trained batch 90 in epoch 0, gen_loss = 1.6734207134980421, disc_loss = 0.10960909820438086
Trained batch 91 in epoch 0, gen_loss = 1.6744051122147103, disc_loss = 0.1085877740026816
Trained batch 92 in epoch 0, gen_loss = 1.673634438104527, disc_loss = 0.10759952027470834
Trained batch 93 in epoch 0, gen_loss = 1.6724954120656277, disc_loss = 0.10663483854621014
Trained batch 94 in epoch 0, gen_loss = 1.672865141065497, disc_loss = 0.1056670860044266
Trained batch 95 in epoch 0, gen_loss = 1.6702950013180573, disc_loss = 0.10536446909342582
Trained batch 96 in epoch 0, gen_loss = 1.6675489796805627, disc_loss = 0.10572070242433819
Trained batch 97 in epoch 0, gen_loss = 1.6702395543760182, disc_loss = 0.1056594415852914
Trained batch 98 in epoch 0, gen_loss = 1.6708699777872875, disc_loss = 0.10562534793985612
Trained batch 99 in epoch 0, gen_loss = 1.670040088891983, disc_loss = 0.10533791882917284
Trained batch 100 in epoch 0, gen_loss = 1.668424387969593, disc_loss = 0.10460148867920484
Trained batch 101 in epoch 0, gen_loss = 1.6661514476233839, disc_loss = 0.10376471925672948
Trained batch 102 in epoch 0, gen_loss = 1.6656202725993776, disc_loss = 0.10289875803135552
Trained batch 103 in epoch 0, gen_loss = 1.6677603950867286, disc_loss = 0.1020400618794016
Trained batch 104 in epoch 0, gen_loss = 1.6651806309109642, disc_loss = 0.10122480567189909
Trained batch 105 in epoch 0, gen_loss = 1.6641708061380207, disc_loss = 0.10038459349318214
Trained batch 106 in epoch 0, gen_loss = 1.6637781123134578, disc_loss = 0.09965645606307505
Trained batch 107 in epoch 0, gen_loss = 1.6619110935264163, disc_loss = 0.09894485955333544
Trained batch 108 in epoch 0, gen_loss = 1.660292181399984, disc_loss = 0.09815502094976399
Trained batch 109 in epoch 0, gen_loss = 1.6573769135908647, disc_loss = 0.09739531141451814
Trained batch 110 in epoch 0, gen_loss = 1.6533501062307272, disc_loss = 0.09662670140397979
Trained batch 111 in epoch 0, gen_loss = 1.6510072275996208, disc_loss = 0.09584939742593893
Trained batch 112 in epoch 0, gen_loss = 1.6524868507300858, disc_loss = 0.09518560140797522
Trained batch 113 in epoch 0, gen_loss = 1.6495243028590554, disc_loss = 0.09445632144547346
Trained batch 114 in epoch 0, gen_loss = 1.64931422005529, disc_loss = 0.09372272048469471
Trained batch 115 in epoch 0, gen_loss = 1.6463934768890511, disc_loss = 0.09298616146733021
Trained batch 116 in epoch 0, gen_loss = 1.6438267709862473, disc_loss = 0.09229512004834464
Trained batch 117 in epoch 0, gen_loss = 1.6434371178433047, disc_loss = 0.09165315437367406
Trained batch 118 in epoch 0, gen_loss = 1.6432025502709782, disc_loss = 0.09096515524600234
Trained batch 119 in epoch 0, gen_loss = 1.641150137782097, disc_loss = 0.09046775929940244
Trained batch 120 in epoch 0, gen_loss = 1.6387616494470392, disc_loss = 0.08981145436544556
Trained batch 121 in epoch 0, gen_loss = 1.637213764620609, disc_loss = 0.08919687556927322
Trained batch 122 in epoch 0, gen_loss = 1.6354784006025733, disc_loss = 0.08856996696260644
Trained batch 123 in epoch 0, gen_loss = 1.635404530071443, disc_loss = 0.08794097508484076
Trained batch 124 in epoch 0, gen_loss = 1.6331550407409667, disc_loss = 0.08731030309945345
Trained batch 125 in epoch 0, gen_loss = 1.6328833207251534, disc_loss = 0.08667229359880799
Trained batch 126 in epoch 0, gen_loss = 1.633705740838539, disc_loss = 0.08605770392739397
Trained batch 127 in epoch 0, gen_loss = 1.6333642331883311, disc_loss = 0.0854381305143761
Trained batch 128 in epoch 0, gen_loss = 1.6329063158626704, disc_loss = 0.0848566670974269
Trained batch 129 in epoch 0, gen_loss = 1.6309903108156645, disc_loss = 0.08427044576248871
Trained batch 130 in epoch 0, gen_loss = 1.6281334735055006, disc_loss = 0.08368088210442366
Trained batch 131 in epoch 0, gen_loss = 1.626265074267532, disc_loss = 0.08310284528697869
Trained batch 132 in epoch 0, gen_loss = 1.6249845951123345, disc_loss = 0.08253362144630655
Trained batch 133 in epoch 0, gen_loss = 1.6238061385368234, disc_loss = 0.08197532328360005
Trained batch 134 in epoch 0, gen_loss = 1.6208349298547815, disc_loss = 0.08142565843752689
Trained batch 135 in epoch 0, gen_loss = 1.6196315779405481, disc_loss = 0.08089590878294342
Trained batch 136 in epoch 0, gen_loss = 1.6178740323895084, disc_loss = 0.08035859989383033
Trained batch 137 in epoch 0, gen_loss = 1.6172713784204014, disc_loss = 0.07983991485156551
Trained batch 138 in epoch 0, gen_loss = 1.615340414664728, disc_loss = 0.07931566899374341
Trained batch 139 in epoch 0, gen_loss = 1.613484560591834, disc_loss = 0.07886746789528323
Trained batch 140 in epoch 0, gen_loss = 1.6119626041845228, disc_loss = 0.07837213377356
Trained batch 141 in epoch 0, gen_loss = 1.6106975531913865, disc_loss = 0.07788188601712841
Trained batch 142 in epoch 0, gen_loss = 1.6101287244916795, disc_loss = 0.07738811817423968
Trained batch 143 in epoch 0, gen_loss = 1.610216538111369, disc_loss = 0.0769077866344661
Trained batch 144 in epoch 0, gen_loss = 1.6092391836232152, disc_loss = 0.07643561403363429
Trained batch 145 in epoch 0, gen_loss = 1.6070634306293645, disc_loss = 0.07595970026498074
Trained batch 146 in epoch 0, gen_loss = 1.605658163018778, disc_loss = 0.07550050327427635
Trained batch 147 in epoch 0, gen_loss = 1.6035175629564233, disc_loss = 0.07504124304506223
Trained batch 148 in epoch 0, gen_loss = 1.60210357016365, disc_loss = 0.07459789467662972
Trained batch 149 in epoch 0, gen_loss = 1.6002334944407146, disc_loss = 0.07414949879671137
Trained batch 150 in epoch 0, gen_loss = 1.599618283328631, disc_loss = 0.07371455398295691
Trained batch 151 in epoch 0, gen_loss = 1.5977619455048913, disc_loss = 0.07328831237789832
Trained batch 152 in epoch 0, gen_loss = 1.5966640274509105, disc_loss = 0.07286171376510384
Trained batch 153 in epoch 0, gen_loss = 1.5952207051314318, disc_loss = 0.0724343611834595
Trained batch 154 in epoch 0, gen_loss = 1.5949486217191142, disc_loss = 0.0720069150350267
Trained batch 155 in epoch 0, gen_loss = 1.5933435322382512, disc_loss = 0.07158940603049138
Trained batch 156 in epoch 0, gen_loss = 1.591984154312474, disc_loss = 0.07118204664913522
Trained batch 157 in epoch 0, gen_loss = 1.591721699962133, disc_loss = 0.07077318839610944
Trained batch 158 in epoch 0, gen_loss = 1.5906493993675184, disc_loss = 0.07037111804029851
Trained batch 159 in epoch 0, gen_loss = 1.5892584651708603, disc_loss = 0.06998240055982023
Trained batch 160 in epoch 0, gen_loss = 1.5871345300852142, disc_loss = 0.0695875350628858
Trained batch 161 in epoch 0, gen_loss = 1.5859346831286396, disc_loss = 0.06919733973875365
Trained batch 162 in epoch 0, gen_loss = 1.5845119667930838, disc_loss = 0.06905279368836365
Trained batch 163 in epoch 0, gen_loss = 1.581849529975798, disc_loss = 0.06877137210345032
Trained batch 164 in epoch 0, gen_loss = 1.5799652475299257, disc_loss = 0.0684677101869249
Trained batch 165 in epoch 0, gen_loss = 1.579638370548386, disc_loss = 0.068106460421492
Trained batch 166 in epoch 0, gen_loss = 1.5796780300711444, disc_loss = 0.06776179992008263
Trained batch 167 in epoch 0, gen_loss = 1.5786299542302178, disc_loss = 0.0674343819513784
Trained batch 168 in epoch 0, gen_loss = 1.5765130230660975, disc_loss = 0.06707326837776768
Trained batch 169 in epoch 0, gen_loss = 1.576371461503646, disc_loss = 0.06671590042464873
Trained batch 170 in epoch 0, gen_loss = 1.5754811185145239, disc_loss = 0.06635928435839321
Trained batch 171 in epoch 0, gen_loss = 1.574084303406782, disc_loss = 0.06604075866892155
Trained batch 172 in epoch 0, gen_loss = 1.5742735504414993, disc_loss = 0.06571373109022058
Trained batch 173 in epoch 0, gen_loss = 1.5732563096901466, disc_loss = 0.0653819731013828
Trained batch 174 in epoch 0, gen_loss = 1.5719092866352626, disc_loss = 0.06503986722656659
Trained batch 175 in epoch 0, gen_loss = 1.5706903500990435, disc_loss = 0.06470212714471431
Trained batch 176 in epoch 0, gen_loss = 1.5697510626356481, disc_loss = 0.06436424061003546
Trained batch 177 in epoch 0, gen_loss = 1.5691142383586154, disc_loss = 0.06403364654986209
Trained batch 178 in epoch 0, gen_loss = 1.5680581084842788, disc_loss = 0.06370428962861942
Trained batch 179 in epoch 0, gen_loss = 1.566940325498581, disc_loss = 0.06339296119856752
Trained batch 180 in epoch 0, gen_loss = 1.565670787958809, disc_loss = 0.06308989734414615
Trained batch 181 in epoch 0, gen_loss = 1.5643829316883298, disc_loss = 0.06277325786240809
Trained batch 182 in epoch 0, gen_loss = 1.5631155166469637, disc_loss = 0.06247033884423108
Trained batch 183 in epoch 0, gen_loss = 1.5625065001456633, disc_loss = 0.06218172472891519
Trained batch 184 in epoch 0, gen_loss = 1.5617854427646947, disc_loss = 0.06189390844036196
Trained batch 185 in epoch 0, gen_loss = 1.5606462545292352, disc_loss = 0.061598125151709045
Trained batch 186 in epoch 0, gen_loss = 1.5593965487046675, disc_loss = 0.06129524266138115
Trained batch 187 in epoch 0, gen_loss = 1.5576052348664466, disc_loss = 0.0610023913508717
Trained batch 188 in epoch 0, gen_loss = 1.5561782771317416, disc_loss = 0.06070970378264233
Trained batch 189 in epoch 0, gen_loss = 1.5548140839526527, disc_loss = 0.060415125231405624
Trained batch 190 in epoch 0, gen_loss = 1.55448101702785, disc_loss = 0.06012683206467026
Trained batch 191 in epoch 0, gen_loss = 1.5530035234987736, disc_loss = 0.05984608163998928
Trained batch 192 in epoch 0, gen_loss = 1.5531323623163096, disc_loss = 0.05956115754601097
Trained batch 193 in epoch 0, gen_loss = 1.5525753375181217, disc_loss = 0.05927695655600004
Trained batch 194 in epoch 0, gen_loss = 1.5522325381254538, disc_loss = 0.05900398198610697
Trained batch 195 in epoch 0, gen_loss = 1.5510027177479802, disc_loss = 0.0587241560534327
Trained batch 196 in epoch 0, gen_loss = 1.5496973495192938, disc_loss = 0.058451641506992925
Trained batch 197 in epoch 0, gen_loss = 1.5483132600784302, disc_loss = 0.05819103950540526
Trained batch 198 in epoch 0, gen_loss = 1.5481132322819389, disc_loss = 0.057924024896443486
Trained batch 199 in epoch 0, gen_loss = 1.5471464377641677, disc_loss = 0.057662253947928545
Trained batch 200 in epoch 0, gen_loss = 1.5474169076378665, disc_loss = 0.057399948586278886
Trained batch 201 in epoch 0, gen_loss = 1.5469155063723574, disc_loss = 0.05714493535578915
Trained batch 202 in epoch 0, gen_loss = 1.547337429276828, disc_loss = 0.05689261016880937
Trained batch 203 in epoch 0, gen_loss = 1.547561266258651, disc_loss = 0.05663612158969045
Trained batch 204 in epoch 0, gen_loss = 1.5473401278984256, disc_loss = 0.0563879045226225
Trained batch 205 in epoch 0, gen_loss = 1.5462684666068809, disc_loss = 0.05614540990876052
Trained batch 206 in epoch 0, gen_loss = 1.5452243538870327, disc_loss = 0.05589348222646448
Trained batch 207 in epoch 0, gen_loss = 1.5441559065993016, disc_loss = 0.05564618017524481
Trained batch 208 in epoch 0, gen_loss = 1.5432750876440386, disc_loss = 0.05540595463428058
Trained batch 209 in epoch 0, gen_loss = 1.54234889348348, disc_loss = 0.05517232724953265
Trained batch 210 in epoch 0, gen_loss = 1.5415331136558859, disc_loss = 0.05495877930303038
Trained batch 211 in epoch 0, gen_loss = 1.5408821049726233, disc_loss = 0.05472947762980354
Trained batch 212 in epoch 0, gen_loss = 1.540465687362241, disc_loss = 0.054491842694650516
Trained batch 213 in epoch 0, gen_loss = 1.540009224526236, disc_loss = 0.05425580302209846
Trained batch 214 in epoch 0, gen_loss = 1.538702522322189, disc_loss = 0.05402971319854259
Trained batch 215 in epoch 0, gen_loss = 1.5374851072276081, disc_loss = 0.053803335349247965
Trained batch 216 in epoch 0, gen_loss = 1.5360299947624383, disc_loss = 0.05357615829097785
Trained batch 217 in epoch 0, gen_loss = 1.5357919811108791, disc_loss = 0.05335663469644998
Trained batch 218 in epoch 0, gen_loss = 1.534282712631574, disc_loss = 0.05313692618901395
Trained batch 219 in epoch 0, gen_loss = 1.533237781307914, disc_loss = 0.05292108977975493
Trained batch 220 in epoch 0, gen_loss = 1.532964070458218, disc_loss = 0.05270496556299372
Trained batch 221 in epoch 0, gen_loss = 1.5328572983140345, disc_loss = 0.05249115753801422
Trained batch 222 in epoch 0, gen_loss = 1.531738788557694, disc_loss = 0.05229057864423824
Trained batch 223 in epoch 0, gen_loss = 1.5310114473104477, disc_loss = 0.052107884211831594
Trained batch 224 in epoch 0, gen_loss = 1.5294893789291382, disc_loss = 0.051950020074016515
Trained batch 225 in epoch 0, gen_loss = 1.529859637264657, disc_loss = 0.051765262371802755
Trained batch 226 in epoch 0, gen_loss = 1.5283863182109882, disc_loss = 0.051565813230933205
Trained batch 227 in epoch 0, gen_loss = 1.5277944829380303, disc_loss = 0.05135903517887192
Trained batch 228 in epoch 0, gen_loss = 1.5268131895356825, disc_loss = 0.0511558518387117
Trained batch 229 in epoch 0, gen_loss = 1.526383346060048, disc_loss = 0.05095449875351851
Trained batch 230 in epoch 0, gen_loss = 1.5258850194675067, disc_loss = 0.05075567597684599
Trained batch 231 in epoch 0, gen_loss = 1.5247170298263943, disc_loss = 0.05056166315676067
Trained batch 232 in epoch 0, gen_loss = 1.5235259461300568, disc_loss = 0.05037015569975895
Trained batch 233 in epoch 0, gen_loss = 1.5233875895157838, disc_loss = 0.05017832422063837
Trained batch 234 in epoch 0, gen_loss = 1.5238877012374554, disc_loss = 0.049983565911571395
Trained batch 235 in epoch 0, gen_loss = 1.5231049353793515, disc_loss = 0.04979058954335939
Trained batch 236 in epoch 0, gen_loss = 1.522563463524927, disc_loss = 0.04959806651152073
Trained batch 237 in epoch 0, gen_loss = 1.5231918432131535, disc_loss = 0.04940578577640865
Trained batch 238 in epoch 0, gen_loss = 1.522417379223652, disc_loss = 0.04922523701594651
Trained batch 239 in epoch 0, gen_loss = 1.521345088382562, disc_loss = 0.049035772687057035
Trained batch 240 in epoch 0, gen_loss = 1.5209445488403448, disc_loss = 0.048850458718187086
Trained batch 241 in epoch 0, gen_loss = 1.5202871590606437, disc_loss = 0.04866193457841411
Trained batch 242 in epoch 0, gen_loss = 1.5202207163037587, disc_loss = 0.048480485294803734
Trained batch 243 in epoch 0, gen_loss = 1.5198906738249982, disc_loss = 0.048301718412463356
Trained batch 244 in epoch 0, gen_loss = 1.5187085667435003, disc_loss = 0.04812782717849679
Trained batch 245 in epoch 0, gen_loss = 1.5182006582012022, disc_loss = 0.047950568678031665
Trained batch 246 in epoch 0, gen_loss = 1.5189363763399935, disc_loss = 0.04777920512418425
Trained batch 247 in epoch 0, gen_loss = 1.518341431694646, disc_loss = 0.04760405421726436
Trained batch 248 in epoch 0, gen_loss = 1.5179759517730957, disc_loss = 0.04742830152526109
Trained batch 249 in epoch 0, gen_loss = 1.51716268825531, disc_loss = 0.047252507167868316
Trained batch 250 in epoch 0, gen_loss = 1.5163765229076978, disc_loss = 0.04708913016036539
Trained batch 251 in epoch 0, gen_loss = 1.5155370509813701, disc_loss = 0.04692483928501754
Trained batch 252 in epoch 0, gen_loss = 1.5153030632984026, disc_loss = 0.04675582936125634
Trained batch 253 in epoch 0, gen_loss = 1.5151536689968559, disc_loss = 0.04659710004907395
Trained batch 254 in epoch 0, gen_loss = 1.5142621694826612, disc_loss = 0.046431097506052434
Trained batch 255 in epoch 0, gen_loss = 1.5136202927678823, disc_loss = 0.0462639290099105
Trained batch 256 in epoch 0, gen_loss = 1.5144148401713093, disc_loss = 0.046101204979374776
Trained batch 257 in epoch 0, gen_loss = 1.5133466179980788, disc_loss = 0.04593654660067644
Trained batch 258 in epoch 0, gen_loss = 1.5135941841427423, disc_loss = 0.045772016451165486
Trained batch 259 in epoch 0, gen_loss = 1.513543929045017, disc_loss = 0.04561447463750553
Trained batch 260 in epoch 0, gen_loss = 1.5130499199432432, disc_loss = 0.045458279658908245
Trained batch 261 in epoch 0, gen_loss = 1.5120398820811556, disc_loss = 0.045333475800487036
Trained batch 262 in epoch 0, gen_loss = 1.5116600985762738, disc_loss = 0.04518529074620668
Trained batch 263 in epoch 0, gen_loss = 1.5104486138531656, disc_loss = 0.04503946054275289
Trained batch 264 in epoch 0, gen_loss = 1.5105295968505572, disc_loss = 0.04489663148931456
Trained batch 265 in epoch 0, gen_loss = 1.5103510515134138, disc_loss = 0.04474990425064208
Trained batch 266 in epoch 0, gen_loss = 1.5094509151544464, disc_loss = 0.04460403579897648
Trained batch 267 in epoch 0, gen_loss = 1.5088315027863233, disc_loss = 0.04445421851219248
Trained batch 268 in epoch 0, gen_loss = 1.5078668895707255, disc_loss = 0.04431606501126212
Trained batch 269 in epoch 0, gen_loss = 1.5066720512178209, disc_loss = 0.04417368472484803
Trained batch 270 in epoch 0, gen_loss = 1.505551429252343, disc_loss = 0.044027125426805216
Trained batch 271 in epoch 0, gen_loss = 1.5055007185129559, disc_loss = 0.043875380057964805
Trained batch 272 in epoch 0, gen_loss = 1.5044841115727967, disc_loss = 0.04372392336397872
Trained batch 273 in epoch 0, gen_loss = 1.505226942309498, disc_loss = 0.04357646237871861
Trained batch 274 in epoch 0, gen_loss = 1.504569672237743, disc_loss = 0.04343583102338016
Trained batch 275 in epoch 0, gen_loss = 1.5036198786203412, disc_loss = 0.043302175896815905
Trained batch 276 in epoch 0, gen_loss = 1.5029071952461766, disc_loss = 0.043175634054722606
Trained batch 277 in epoch 0, gen_loss = 1.502934939998517, disc_loss = 0.04305578006863621
Trained batch 278 in epoch 0, gen_loss = 1.5030406175121185, disc_loss = 0.04293571157951749
Trained batch 279 in epoch 0, gen_loss = 1.5030747647796359, disc_loss = 0.04280669661820866
Trained batch 280 in epoch 0, gen_loss = 1.5026721114365655, disc_loss = 0.04266695627690793
Trained batch 281 in epoch 0, gen_loss = 1.502189813776219, disc_loss = 0.04253150350975652
Trained batch 282 in epoch 0, gen_loss = 1.5020982983255555, disc_loss = 0.042392736916222966
Trained batch 283 in epoch 0, gen_loss = 1.5015089537056399, disc_loss = 0.0422557271880911
Trained batch 284 in epoch 0, gen_loss = 1.5008505310928613, disc_loss = 0.04212311158659296
Trained batch 285 in epoch 0, gen_loss = 1.4999002480840349, disc_loss = 0.04199127621632851
Trained batch 286 in epoch 0, gen_loss = 1.4995547591186151, disc_loss = 0.0418610213436381
Trained batch 287 in epoch 0, gen_loss = 1.4985229898658063, disc_loss = 0.0417286261225753
Trained batch 288 in epoch 0, gen_loss = 1.4984537738417258, disc_loss = 0.04159780469026971
Trained batch 289 in epoch 0, gen_loss = 1.4974845561487922, disc_loss = 0.04148766363184128
Trained batch 290 in epoch 0, gen_loss = 1.4977232856848806, disc_loss = 0.0413626476880675
Trained batch 291 in epoch 0, gen_loss = 1.4975725861444866, disc_loss = 0.04123455164906224
Trained batch 292 in epoch 0, gen_loss = 1.4966977326129485, disc_loss = 0.041112679334153954
Trained batch 293 in epoch 0, gen_loss = 1.4967521526375596, disc_loss = 0.04098783607743554
Trained batch 294 in epoch 0, gen_loss = 1.496092507798793, disc_loss = 0.04086027641038773
Trained batch 295 in epoch 0, gen_loss = 1.4958416674588177, disc_loss = 0.040735416501332576
Trained batch 296 in epoch 0, gen_loss = 1.4958139702125832, disc_loss = 0.040609133113896856
Trained batch 297 in epoch 0, gen_loss = 1.4951437479697618, disc_loss = 0.040492853933426505
Trained batch 298 in epoch 0, gen_loss = 1.4957518003457366, disc_loss = 0.040374197010542685
Trained batch 299 in epoch 0, gen_loss = 1.4949248218536377, disc_loss = 0.040252619448583576
Trained batch 300 in epoch 0, gen_loss = 1.4945064204871852, disc_loss = 0.04013126805591771
Trained batch 301 in epoch 0, gen_loss = 1.494419178425871, disc_loss = 0.040014627001044765
Trained batch 302 in epoch 0, gen_loss = 1.4935967615335295, disc_loss = 0.03989413843748372
Trained batch 303 in epoch 0, gen_loss = 1.493355673394705, disc_loss = 0.039771846036034585
Trained batch 304 in epoch 0, gen_loss = 1.4931802186809602, disc_loss = 0.039652415158868325
Trained batch 305 in epoch 0, gen_loss = 1.4931869483461566, disc_loss = 0.03953380310250556
Trained batch 306 in epoch 0, gen_loss = 1.4925709916248384, disc_loss = 0.03941728695711358
Trained batch 307 in epoch 0, gen_loss = 1.4918944224134667, disc_loss = 0.03929890719901577
Trained batch 308 in epoch 0, gen_loss = 1.4918694766208191, disc_loss = 0.039183593377724146
Trained batch 309 in epoch 0, gen_loss = 1.4914894146303976, disc_loss = 0.03907249252792568
Trained batch 310 in epoch 0, gen_loss = 1.4918620229917323, disc_loss = 0.03895716483246571
Trained batch 311 in epoch 0, gen_loss = 1.4914161883867705, disc_loss = 0.03885261005519006
Trained batch 312 in epoch 0, gen_loss = 1.4909843914805891, disc_loss = 0.038743067659235325
Trained batch 313 in epoch 0, gen_loss = 1.490686022931603, disc_loss = 0.038629043617457816
Trained batch 314 in epoch 0, gen_loss = 1.4897572543885973, disc_loss = 0.038524436955118466
Trained batch 315 in epoch 0, gen_loss = 1.48922038644175, disc_loss = 0.038414274906014574
Trained batch 316 in epoch 0, gen_loss = 1.4899071018778562, disc_loss = 0.03830720322303568
Trained batch 317 in epoch 0, gen_loss = 1.4899087836907345, disc_loss = 0.03820325700938116
Trained batch 318 in epoch 0, gen_loss = 1.4898654704557317, disc_loss = 0.03809810503602005
Trained batch 319 in epoch 0, gen_loss = 1.4898612577468158, disc_loss = 0.03799497649961268
Trained batch 320 in epoch 0, gen_loss = 1.4892621393144316, disc_loss = 0.03788424461769561
Trained batch 321 in epoch 0, gen_loss = 1.4897152285398163, disc_loss = 0.03777602813799536
Trained batch 322 in epoch 0, gen_loss = 1.4890183321093626, disc_loss = 0.03766905919262338
Trained batch 323 in epoch 0, gen_loss = 1.4881362778904996, disc_loss = 0.03756039322319406
Trained batch 324 in epoch 0, gen_loss = 1.4870169665263249, disc_loss = 0.037453252170234916
Trained batch 325 in epoch 0, gen_loss = 1.4861956948151618, disc_loss = 0.037354563047218084
Trained batch 326 in epoch 0, gen_loss = 1.4852817842355197, disc_loss = 0.03727204334816756
Trained batch 327 in epoch 0, gen_loss = 1.4845702055750825, disc_loss = 0.037188479629992624
Trained batch 328 in epoch 0, gen_loss = 1.4837987067851615, disc_loss = 0.03709654143012177
Trained batch 329 in epoch 0, gen_loss = 1.4833629897146514, disc_loss = 0.03699815442192961
Trained batch 330 in epoch 0, gen_loss = 1.4837171880140045, disc_loss = 0.03689633806593424
Trained batch 331 in epoch 0, gen_loss = 1.4835005707769509, disc_loss = 0.03679484740623374
Trained batch 332 in epoch 0, gen_loss = 1.4831953138202518, disc_loss = 0.03669354711469073
Trained batch 333 in epoch 0, gen_loss = 1.4828167750449952, disc_loss = 0.03659361940432161
Trained batch 334 in epoch 0, gen_loss = 1.4823421659754283, disc_loss = 0.036494878683684034
Trained batch 335 in epoch 0, gen_loss = 1.4821428546593303, disc_loss = 0.03639806069051182
Trained batch 336 in epoch 0, gen_loss = 1.4819359397322205, disc_loss = 0.03630979618510834
Trained batch 337 in epoch 0, gen_loss = 1.4816687519733722, disc_loss = 0.03621883928836406
Trained batch 338 in epoch 0, gen_loss = 1.4809472328793687, disc_loss = 0.03612472756098198
Trained batch 339 in epoch 0, gen_loss = 1.4805473530993742, disc_loss = 0.0360322796369848
Trained batch 340 in epoch 0, gen_loss = 1.4798826150530595, disc_loss = 0.03593432234908806
Trained batch 341 in epoch 0, gen_loss = 1.4794210205998337, disc_loss = 0.03584377902453732
Trained batch 342 in epoch 0, gen_loss = 1.4786031430386246, disc_loss = 0.03575113713510508
Trained batch 343 in epoch 0, gen_loss = 1.4780664759319881, disc_loss = 0.03565532728341993
Trained batch 344 in epoch 0, gen_loss = 1.4773095963657765, disc_loss = 0.03556314211244276
Trained batch 345 in epoch 0, gen_loss = 1.4764781587385718, disc_loss = 0.035468787650007084
Trained batch 346 in epoch 0, gen_loss = 1.4759537950372834, disc_loss = 0.035375977155111024
Trained batch 347 in epoch 0, gen_loss = 1.476147460183878, disc_loss = 0.035282647140837946
Trained batch 348 in epoch 0, gen_loss = 1.4753923638160726, disc_loss = 0.03519530100934741
Trained batch 349 in epoch 0, gen_loss = 1.4753211304119656, disc_loss = 0.03511024746245572
Trained batch 350 in epoch 0, gen_loss = 1.474552247938607, disc_loss = 0.03502682827418389
Trained batch 351 in epoch 0, gen_loss = 1.4737525158985094, disc_loss = 0.03493606362661177
Trained batch 352 in epoch 0, gen_loss = 1.4737054112950398, disc_loss = 0.03484610752228953
Trained batch 353 in epoch 0, gen_loss = 1.473582180879884, disc_loss = 0.03475714601526342
Trained batch 354 in epoch 0, gen_loss = 1.4725491550606742, disc_loss = 0.03466625956385593
Trained batch 355 in epoch 0, gen_loss = 1.4720831118272932, disc_loss = 0.03458549306673008
Trained batch 356 in epoch 0, gen_loss = 1.4714050646923504, disc_loss = 0.03450858373526244
Trained batch 357 in epoch 0, gen_loss = 1.4713494338136812, disc_loss = 0.034436355393728524
Trained batch 358 in epoch 0, gen_loss = 1.4712782978679477, disc_loss = 0.03435690297283398
Trained batch 359 in epoch 0, gen_loss = 1.4715563429726495, disc_loss = 0.03427635788231985
Trained batch 360 in epoch 0, gen_loss = 1.4713175481706444, disc_loss = 0.03419257840980102
Trained batch 361 in epoch 0, gen_loss = 1.4710292177305695, disc_loss = 0.034104667259869034
Trained batch 362 in epoch 0, gen_loss = 1.470911701520284, disc_loss = 0.034016991286864376
Trained batch 363 in epoch 0, gen_loss = 1.4700490010308696, disc_loss = 0.033929209115500514
Trained batch 364 in epoch 0, gen_loss = 1.4695380586467377, disc_loss = 0.03384364585341146
Trained batch 365 in epoch 0, gen_loss = 1.4688238081384877, disc_loss = 0.03375659388734303
Trained batch 366 in epoch 0, gen_loss = 1.467860938417814, disc_loss = 0.03367261110858266
Trained batch 367 in epoch 0, gen_loss = 1.468290464385696, disc_loss = 0.0335869441111319
Trained batch 368 in epoch 0, gen_loss = 1.4680673174741792, disc_loss = 0.0335057449828692
Trained batch 369 in epoch 0, gen_loss = 1.467384534590953, disc_loss = 0.03342568875869384
Trained batch 370 in epoch 0, gen_loss = 1.4681067180762073, disc_loss = 0.033342887298517795
Trained batch 371 in epoch 0, gen_loss = 1.4678829815438998, disc_loss = 0.03326113527310231
Trained batch 372 in epoch 0, gen_loss = 1.4677316285969424, disc_loss = 0.03317950230875819
Trained batch 373 in epoch 0, gen_loss = 1.467243645917923, disc_loss = 0.033098541693214106
Trained batch 374 in epoch 0, gen_loss = 1.4667759838104248, disc_loss = 0.03302301183839639
Trained batch 375 in epoch 0, gen_loss = 1.4665343016386032, disc_loss = 0.032941568524581674
Trained batch 376 in epoch 0, gen_loss = 1.4667606556130974, disc_loss = 0.03286339854265734
Trained batch 377 in epoch 0, gen_loss = 1.4662629813744277, disc_loss = 0.032786097062786144
Trained batch 378 in epoch 0, gen_loss = 1.4656275369246592, disc_loss = 0.032707845062965965
Trained batch 379 in epoch 0, gen_loss = 1.4657061994075775, disc_loss = 0.032629512031072457
Trained batch 380 in epoch 0, gen_loss = 1.465685850366207, disc_loss = 0.03255118596981087
Trained batch 381 in epoch 0, gen_loss = 1.4655750484366692, disc_loss = 0.032471688536205454
Trained batch 382 in epoch 0, gen_loss = 1.46522842281481, disc_loss = 0.03239408074258085
Trained batch 383 in epoch 0, gen_loss = 1.4651372671748202, disc_loss = 0.032317759989382466
Trained batch 384 in epoch 0, gen_loss = 1.4646249223065066, disc_loss = 0.032243684024320214
Trained batch 385 in epoch 0, gen_loss = 1.4639336145603594, disc_loss = 0.032174783752184036
Trained batch 386 in epoch 0, gen_loss = 1.4633836379654956, disc_loss = 0.032103542900868046
Trained batch 387 in epoch 0, gen_loss = 1.4626884758472443, disc_loss = 0.032033246941264415
Trained batch 388 in epoch 0, gen_loss = 1.4625082760666208, disc_loss = 0.03195991578145589
Trained batch 389 in epoch 0, gen_loss = 1.461778600093646, disc_loss = 0.03188540730565691
Trained batch 390 in epoch 0, gen_loss = 1.461667094389191, disc_loss = 0.03181620984685981
Trained batch 391 in epoch 0, gen_loss = 1.4610651491247877, disc_loss = 0.031753169312688276
Trained batch 392 in epoch 0, gen_loss = 1.4606848445557457, disc_loss = 0.0316847189378145
Trained batch 393 in epoch 0, gen_loss = 1.4604353756468913, disc_loss = 0.031614341007824516
Trained batch 394 in epoch 0, gen_loss = 1.4600793452202518, disc_loss = 0.031542460473631566
Trained batch 395 in epoch 0, gen_loss = 1.4595065381791856, disc_loss = 0.03147587796021723
Trained batch 396 in epoch 0, gen_loss = 1.4587358629673495, disc_loss = 0.03140344987189402
Trained batch 397 in epoch 0, gen_loss = 1.4591046469894486, disc_loss = 0.03133494385527494
Trained batch 398 in epoch 0, gen_loss = 1.4604553035028596, disc_loss = 0.03126647925228441
Trained batch 399 in epoch 0, gen_loss = 1.4602115851640702, disc_loss = 0.0311948646674864
Trained batch 400 in epoch 0, gen_loss = 1.4596253859431965, disc_loss = 0.031124405728355793
Trained batch 401 in epoch 0, gen_loss = 1.4602677558191972, disc_loss = 0.031051917857054936
Trained batch 402 in epoch 0, gen_loss = 1.4597624232692104, disc_loss = 0.030980361771721292
Trained batch 403 in epoch 0, gen_loss = 1.460008314635494, disc_loss = 0.03090967320823249
Trained batch 404 in epoch 0, gen_loss = 1.4598025213053196, disc_loss = 0.030838883690030117
Trained batch 405 in epoch 0, gen_loss = 1.4591509353351124, disc_loss = 0.030772572433750325
Trained batch 406 in epoch 0, gen_loss = 1.4585235801317182, disc_loss = 0.030708323183631942
Trained batch 407 in epoch 0, gen_loss = 1.458588491175689, disc_loss = 0.030647294119904366
Trained batch 408 in epoch 0, gen_loss = 1.4584519994288028, disc_loss = 0.030584269148595904
Trained batch 409 in epoch 0, gen_loss = 1.4582239706341813, disc_loss = 0.03051700424686892
Trained batch 410 in epoch 0, gen_loss = 1.457631603934759, disc_loss = 0.03045087246566449
Trained batch 411 in epoch 0, gen_loss = 1.4574645598536555, disc_loss = 0.0303832179300478
Trained batch 412 in epoch 0, gen_loss = 1.4571118545301314, disc_loss = 0.030319022742544298
Trained batch 413 in epoch 0, gen_loss = 1.4565134563883722, disc_loss = 0.030254906724468053
Trained batch 414 in epoch 0, gen_loss = 1.4560254349766006, disc_loss = 0.030187717691086323
Trained batch 415 in epoch 0, gen_loss = 1.4558982545366654, disc_loss = 0.030121934544205524
Trained batch 416 in epoch 0, gen_loss = 1.4550790255018275, disc_loss = 0.030059329475269472
Trained batch 417 in epoch 0, gen_loss = 1.4543404259750148, disc_loss = 0.0299961752097822
Trained batch 418 in epoch 0, gen_loss = 1.4540069845809573, disc_loss = 0.02993087189467646
Trained batch 419 in epoch 0, gen_loss = 1.4535096824169158, disc_loss = 0.029864921202395287
Trained batch 420 in epoch 0, gen_loss = 1.453273869466895, disc_loss = 0.029802766481454256
Trained batch 421 in epoch 0, gen_loss = 1.4528126795709981, disc_loss = 0.029741862219409637
Trained batch 422 in epoch 0, gen_loss = 1.4532292128736528, disc_loss = 0.029680299266609176
Trained batch 423 in epoch 0, gen_loss = 1.4526371514459826, disc_loss = 0.029617948364795907
Trained batch 424 in epoch 0, gen_loss = 1.452356675933389, disc_loss = 0.029552762758753754
Trained batch 425 in epoch 0, gen_loss = 1.4523378697359506, disc_loss = 0.02948934981651919
Trained batch 426 in epoch 0, gen_loss = 1.4519640184956357, disc_loss = 0.029425855976282958
Trained batch 427 in epoch 0, gen_loss = 1.4512638101510913, disc_loss = 0.0293631407282115
Trained batch 428 in epoch 0, gen_loss = 1.450759144373985, disc_loss = 0.02931018522886303
Trained batch 429 in epoch 0, gen_loss = 1.4513371470362642, disc_loss = 0.029252570549156084
Trained batch 430 in epoch 0, gen_loss = 1.4508774407778429, disc_loss = 0.029190777554641327
Trained batch 431 in epoch 0, gen_loss = 1.4503523486631889, disc_loss = 0.029131393938398645
Trained batch 432 in epoch 0, gen_loss = 1.4497767395015126, disc_loss = 0.029071663221877764
Trained batch 433 in epoch 0, gen_loss = 1.4493714952798482, disc_loss = 0.02901252661724382
Trained batch 434 in epoch 0, gen_loss = 1.4496257091390676, disc_loss = 0.028952849801394277
Trained batch 435 in epoch 0, gen_loss = 1.448939688708804, disc_loss = 0.028895605441477627
Trained batch 436 in epoch 0, gen_loss = 1.4487575027980848, disc_loss = 0.028839760563854188
Trained batch 437 in epoch 0, gen_loss = 1.4481456924791205, disc_loss = 0.02878330507555968
Trained batch 438 in epoch 0, gen_loss = 1.4491348532717971, disc_loss = 0.028726345517381957
Trained batch 439 in epoch 0, gen_loss = 1.4489430449225686, disc_loss = 0.02866806817685508
Trained batch 440 in epoch 0, gen_loss = 1.4488482318497569, disc_loss = 0.028609504402655254
Trained batch 441 in epoch 0, gen_loss = 1.4486360706355237, disc_loss = 0.028550656256371293
Trained batch 442 in epoch 0, gen_loss = 1.4480385322872187, disc_loss = 0.028492988310607138
Trained batch 443 in epoch 0, gen_loss = 1.447796973827723, disc_loss = 0.028436566729765588
Trained batch 444 in epoch 0, gen_loss = 1.447487613324369, disc_loss = 0.028378696636600274
Trained batch 445 in epoch 0, gen_loss = 1.446904524292112, disc_loss = 0.028321507069983858
Trained batch 446 in epoch 0, gen_loss = 1.4465062676926854, disc_loss = 0.028265706991664315
Trained batch 447 in epoch 0, gen_loss = 1.4461380842008762, disc_loss = 0.028207081514535406
Trained batch 448 in epoch 0, gen_loss = 1.4456815791289366, disc_loss = 0.028151673744982297
Trained batch 449 in epoch 0, gen_loss = 1.4452542016241285, disc_loss = 0.028095985723969836
Trained batch 450 in epoch 0, gen_loss = 1.445192970880648, disc_loss = 0.028038443800809477
Trained batch 451 in epoch 0, gen_loss = 1.44451513358977, disc_loss = 0.027980621253290684
Trained batch 452 in epoch 0, gen_loss = 1.4440275999094476, disc_loss = 0.027924136338070872
Trained batch 453 in epoch 0, gen_loss = 1.4439267550270989, disc_loss = 0.027867253011016644
Trained batch 454 in epoch 0, gen_loss = 1.4435724289862664, disc_loss = 0.027812713726198524
Trained batch 455 in epoch 0, gen_loss = 1.4432030701846408, disc_loss = 0.02775931583994207
Trained batch 456 in epoch 0, gen_loss = 1.4425483469890035, disc_loss = 0.02770312189524973
Trained batch 457 in epoch 0, gen_loss = 1.4420990329642482, disc_loss = 0.027648210552201798
Trained batch 458 in epoch 0, gen_loss = 1.4418280701232111, disc_loss = 0.02759460157086801
Trained batch 459 in epoch 0, gen_loss = 1.441938317599504, disc_loss = 0.027549667728042394
Trained batch 460 in epoch 0, gen_loss = 1.4413775733132683, disc_loss = 0.027499997490105864
Trained batch 461 in epoch 0, gen_loss = 1.4412258030016185, disc_loss = 0.027446932294678136
Trained batch 462 in epoch 0, gen_loss = 1.4410233010998554, disc_loss = 0.027405126155333966
Trained batch 463 in epoch 0, gen_loss = 1.4405381335266705, disc_loss = 0.027355751093198016
Trained batch 464 in epoch 0, gen_loss = 1.4403887156517274, disc_loss = 0.027302701247765893
Trained batch 465 in epoch 0, gen_loss = 1.43991532883419, disc_loss = 0.027254453627642467
Trained batch 466 in epoch 0, gen_loss = 1.4394846432214121, disc_loss = 0.0272010850555082
Trained batch 467 in epoch 0, gen_loss = 1.4391105185207138, disc_loss = 0.027154910085876033
Trained batch 468 in epoch 0, gen_loss = 1.4386127452606332, disc_loss = 0.02710301247162264
Trained batch 469 in epoch 0, gen_loss = 1.4385266009797442, disc_loss = 0.027051136236727
Trained batch 470 in epoch 0, gen_loss = 1.4379119824958202, disc_loss = 0.02699779464557743
Trained batch 471 in epoch 0, gen_loss = 1.4379628280461845, disc_loss = 0.02694733316395471
Trained batch 472 in epoch 0, gen_loss = 1.438533813202356, disc_loss = 0.0268976997633821
Trained batch 473 in epoch 0, gen_loss = 1.4386580749906066, disc_loss = 0.026844852593902277
Trained batch 474 in epoch 0, gen_loss = 1.4381816871542679, disc_loss = 0.02679306765748678
Trained batch 475 in epoch 0, gen_loss = 1.437838552128367, disc_loss = 0.02674377913574078
Trained batch 476 in epoch 0, gen_loss = 1.4372198784126426, disc_loss = 0.026693813417612552
Trained batch 477 in epoch 0, gen_loss = 1.4374113110318842, disc_loss = 0.02664397622699261
Trained batch 478 in epoch 0, gen_loss = 1.4369199791133778, disc_loss = 0.026592997264647797
Trained batch 479 in epoch 0, gen_loss = 1.4368504198888938, disc_loss = 0.026541795265560116
Trained batch 480 in epoch 0, gen_loss = 1.436399911644553, disc_loss = 0.026492033971099883
Trained batch 481 in epoch 0, gen_loss = 1.4360932183463544, disc_loss = 0.026441583786926837
Trained batch 482 in epoch 0, gen_loss = 1.4356475241682791, disc_loss = 0.02639142279084155
Trained batch 483 in epoch 0, gen_loss = 1.4351930633064145, disc_loss = 0.026339652441771055
Trained batch 484 in epoch 0, gen_loss = 1.434644813881707, disc_loss = 0.02629159793483343
Trained batch 485 in epoch 0, gen_loss = 1.4341238548235637, disc_loss = 0.026242530713798746
Trained batch 486 in epoch 0, gen_loss = 1.4338463752911077, disc_loss = 0.026193623251025422
Trained batch 487 in epoch 0, gen_loss = 1.4339923570390607, disc_loss = 0.026145333055641547
Trained batch 488 in epoch 0, gen_loss = 1.4339917754346851, disc_loss = 0.026098822973666672
Trained batch 489 in epoch 0, gen_loss = 1.4340554237365724, disc_loss = 0.02605163016028664
Trained batch 490 in epoch 0, gen_loss = 1.4335566239541515, disc_loss = 0.02601774951396605
Trained batch 491 in epoch 0, gen_loss = 1.433166880190857, disc_loss = 0.025984268634328317
Trained batch 492 in epoch 0, gen_loss = 1.4327240222366056, disc_loss = 0.02595060331247271
Trained batch 493 in epoch 0, gen_loss = 1.4330124768168337, disc_loss = 0.025910355728298713
Trained batch 494 in epoch 0, gen_loss = 1.4331587369995888, disc_loss = 0.025863973819180344
Trained batch 495 in epoch 0, gen_loss = 1.4326048055964131, disc_loss = 0.025818832302907286
Trained batch 496 in epoch 0, gen_loss = 1.432050305353084, disc_loss = 0.02577638742068906
Trained batch 497 in epoch 0, gen_loss = 1.4316992577778767, disc_loss = 0.02573072929080224
Trained batch 498 in epoch 0, gen_loss = 1.4310591304469442, disc_loss = 0.025684854447541157
Trained batch 499 in epoch 0, gen_loss = 1.4305210247039795, disc_loss = 0.025641082666581497
Trained batch 500 in epoch 0, gen_loss = 1.4300983475591846, disc_loss = 0.02559526081354043
Trained batch 501 in epoch 0, gen_loss = 1.4299773730604772, disc_loss = 0.025548229961279423
Trained batch 502 in epoch 0, gen_loss = 1.4299503962988882, disc_loss = 0.02550164888919355
Trained batch 503 in epoch 0, gen_loss = 1.4298261910203904, disc_loss = 0.025456135611868432
Trained batch 504 in epoch 0, gen_loss = 1.4298878993138229, disc_loss = 0.025413100851819585
Trained batch 505 in epoch 0, gen_loss = 1.4298612091381089, disc_loss = 0.025368271558683573
Trained batch 506 in epoch 0, gen_loss = 1.429449358870527, disc_loss = 0.025322262842724323
Trained batch 507 in epoch 0, gen_loss = 1.4293417346289778, disc_loss = 0.025276185088519622
Trained batch 508 in epoch 0, gen_loss = 1.428972413591411, disc_loss = 0.025230969906618092
Trained batch 509 in epoch 0, gen_loss = 1.428728390674965, disc_loss = 0.025189060179571458
Trained batch 510 in epoch 0, gen_loss = 1.4283878215371746, disc_loss = 0.025144551542119184
Trained batch 511 in epoch 0, gen_loss = 1.4281334187835455, disc_loss = 0.025103047490119934
Trained batch 512 in epoch 0, gen_loss = 1.427660376937301, disc_loss = 0.02506023597200973
Trained batch 513 in epoch 0, gen_loss = 1.4272536034713923, disc_loss = 0.025018268934331456
Trained batch 514 in epoch 0, gen_loss = 1.4268139927132615, disc_loss = 0.024981472816643785
Trained batch 515 in epoch 0, gen_loss = 1.4263412365617678, disc_loss = 0.02497392803856511
Trained batch 516 in epoch 0, gen_loss = 1.4253667528440228, disc_loss = 0.025062476389283023
Trained batch 517 in epoch 0, gen_loss = 1.4255378204883296, disc_loss = 0.025076112309003314
Trained batch 518 in epoch 0, gen_loss = 1.4254098747047614, disc_loss = 0.025179856980797298
Trained batch 519 in epoch 0, gen_loss = 1.425470733642578, disc_loss = 0.025297647891924357
Trained batch 520 in epoch 0, gen_loss = 1.4256053822054287, disc_loss = 0.02538433588590766
Trained batch 521 in epoch 0, gen_loss = 1.4253418692227067, disc_loss = 0.025370551028799166
Trained batch 522 in epoch 0, gen_loss = 1.4249726492861716, disc_loss = 0.025350408993632913
Trained batch 523 in epoch 0, gen_loss = 1.4244413346279667, disc_loss = 0.025319083847944405
Trained batch 524 in epoch 0, gen_loss = 1.424205901736305, disc_loss = 0.025286421580683616
Trained batch 525 in epoch 0, gen_loss = 1.4237423523297328, disc_loss = 0.025248202242969957
Trained batch 526 in epoch 0, gen_loss = 1.4232777920348367, disc_loss = 0.02521284600362832
Trained batch 527 in epoch 0, gen_loss = 1.4228376439123442, disc_loss = 0.025180344210556625
Trained batch 528 in epoch 0, gen_loss = 1.4223355124713342, disc_loss = 0.025139996658707836
Trained batch 529 in epoch 0, gen_loss = 1.4221179165930118, disc_loss = 0.025104448701834904
Trained batch 530 in epoch 0, gen_loss = 1.4217597273109996, disc_loss = 0.025064675981028045
Trained batch 531 in epoch 0, gen_loss = 1.4212717467680909, disc_loss = 0.02502321805306045
Trained batch 532 in epoch 0, gen_loss = 1.4206011881300478, disc_loss = 0.02498350022220897
Trained batch 533 in epoch 0, gen_loss = 1.4214221745841065, disc_loss = 0.024951073637560064
Trained batch 534 in epoch 0, gen_loss = 1.4214071042069765, disc_loss = 0.024910335804588186
Trained batch 535 in epoch 0, gen_loss = 1.4209608150951898, disc_loss = 0.02489005558587152
Trained batch 536 in epoch 0, gen_loss = 1.4207048183046906, disc_loss = 0.024867360271579365
Trained batch 537 in epoch 0, gen_loss = 1.4204642783753492, disc_loss = 0.024827455032398738
Trained batch 538 in epoch 0, gen_loss = 1.42062842646866, disc_loss = 0.02478965166273677
Trained batch 539 in epoch 0, gen_loss = 1.420529435299061, disc_loss = 0.02475066728355294
Trained batch 540 in epoch 0, gen_loss = 1.4203689512615945, disc_loss = 0.024711113210505842
Trained batch 541 in epoch 0, gen_loss = 1.420229605203185, disc_loss = 0.02467032184487559
Trained batch 542 in epoch 0, gen_loss = 1.419851943713306, disc_loss = 0.024628893279300703
Trained batch 543 in epoch 0, gen_loss = 1.419366341741646, disc_loss = 0.02458974975589252
Trained batch 544 in epoch 0, gen_loss = 1.4187450513927216, disc_loss = 0.024549001550148112
Trained batch 545 in epoch 0, gen_loss = 1.4185467072022266, disc_loss = 0.024507903383069095
Trained batch 546 in epoch 0, gen_loss = 1.4185504041598527, disc_loss = 0.024467941325913834
Trained batch 547 in epoch 0, gen_loss = 1.4183050609418075, disc_loss = 0.024428349176513535
Trained batch 548 in epoch 0, gen_loss = 1.4180765957563084, disc_loss = 0.024388622108741726
Trained batch 549 in epoch 0, gen_loss = 1.4181464925679295, disc_loss = 0.024349259076724677
Trained batch 550 in epoch 0, gen_loss = 1.417860288369028, disc_loss = 0.02430922625173972
Trained batch 551 in epoch 0, gen_loss = 1.4176693690427835, disc_loss = 0.024272359516201675
Trained batch 552 in epoch 0, gen_loss = 1.4179108308840402, disc_loss = 0.0242345548499288
Trained batch 553 in epoch 0, gen_loss = 1.417579869500997, disc_loss = 0.024195925718415463
Trained batch 554 in epoch 0, gen_loss = 1.4172745309434496, disc_loss = 0.024157165774135844
Trained batch 555 in epoch 0, gen_loss = 1.4167222783719893, disc_loss = 0.024120595120228558
Trained batch 556 in epoch 0, gen_loss = 1.4161782735554063, disc_loss = 0.024084702986033376
Trained batch 557 in epoch 0, gen_loss = 1.4157238416774298, disc_loss = 0.024046573895580507
Trained batch 558 in epoch 0, gen_loss = 1.4154602001306196, disc_loss = 0.024007580480463336
Trained batch 559 in epoch 0, gen_loss = 1.41534708908626, disc_loss = 0.023969347306826552
Trained batch 560 in epoch 0, gen_loss = 1.4149788184599443, disc_loss = 0.023929764295649282
Trained batch 561 in epoch 0, gen_loss = 1.4149129530713227, disc_loss = 0.023890134658054632
Trained batch 562 in epoch 0, gen_loss = 1.414598152650186, disc_loss = 0.02385039057923385
Trained batch 563 in epoch 0, gen_loss = 1.4143344182917412, disc_loss = 0.023821605873915058
Trained batch 564 in epoch 0, gen_loss = 1.414193732759594, disc_loss = 0.023795362834744486
Trained batch 565 in epoch 0, gen_loss = 1.4138060736571942, disc_loss = 0.02375889873188055
Trained batch 566 in epoch 0, gen_loss = 1.4134024270207373, disc_loss = 0.0237210951174726
Trained batch 567 in epoch 0, gen_loss = 1.41335640658795, disc_loss = 0.02368274577778541
Trained batch 568 in epoch 0, gen_loss = 1.41311378135413, disc_loss = 0.023643745280481444
Trained batch 569 in epoch 0, gen_loss = 1.4129987131085313, disc_loss = 0.023608224183370018
Trained batch 570 in epoch 0, gen_loss = 1.4127798794447437, disc_loss = 0.02356964784866809
Trained batch 571 in epoch 0, gen_loss = 1.4126649963689017, disc_loss = 0.023531573186742493
Trained batch 572 in epoch 0, gen_loss = 1.4133562852366848, disc_loss = 0.023496853107225678
Trained batch 573 in epoch 0, gen_loss = 1.4130167448146833, disc_loss = 0.023467129862215046
Trained batch 574 in epoch 0, gen_loss = 1.4127323903208193, disc_loss = 0.023436058981587057
Trained batch 575 in epoch 0, gen_loss = 1.4125524662021134, disc_loss = 0.023399376217437547
Trained batch 576 in epoch 0, gen_loss = 1.4120499244802334, disc_loss = 0.0233714026027719
Trained batch 577 in epoch 0, gen_loss = 1.4115464344981632, disc_loss = 0.023350376991078156
Trained batch 578 in epoch 0, gen_loss = 1.41140424237556, disc_loss = 0.0233196431114652
Trained batch 579 in epoch 0, gen_loss = 1.4111862351154458, disc_loss = 0.023287534288227045
Trained batch 580 in epoch 0, gen_loss = 1.4109332124460585, disc_loss = 0.023250378637050442
Trained batch 581 in epoch 0, gen_loss = 1.4105163990836782, disc_loss = 0.02321506602348779
Trained batch 582 in epoch 0, gen_loss = 1.4101222876210155, disc_loss = 0.023178592776539407
Trained batch 583 in epoch 0, gen_loss = 1.409980415277285, disc_loss = 0.02314244942960476
Trained batch 584 in epoch 0, gen_loss = 1.4095047724552643, disc_loss = 0.023106778868569586
Trained batch 585 in epoch 0, gen_loss = 1.4090547702011396, disc_loss = 0.023070447699368675
Trained batch 586 in epoch 0, gen_loss = 1.4092140386620413, disc_loss = 0.02303608925755293
Trained batch 587 in epoch 0, gen_loss = 1.4087561950797127, disc_loss = 0.023001165107663937
Trained batch 588 in epoch 0, gen_loss = 1.4083039922503744, disc_loss = 0.022968567323361812
Trained batch 589 in epoch 0, gen_loss = 1.408357843302064, disc_loss = 0.0229327315551434
Trained batch 590 in epoch 0, gen_loss = 1.4080932935078938, disc_loss = 0.022896167677992643
Trained batch 591 in epoch 0, gen_loss = 1.4076567511703517, disc_loss = 0.022860957740655018
Trained batch 592 in epoch 0, gen_loss = 1.4072854516880107, disc_loss = 0.0228251359772179
Trained batch 593 in epoch 0, gen_loss = 1.4066964173156404, disc_loss = 0.022790122537141484
Trained batch 594 in epoch 0, gen_loss = 1.4063283753996136, disc_loss = 0.022754648876838198
Trained batch 595 in epoch 0, gen_loss = 1.406272197329758, disc_loss = 0.022720038704495977
Trained batch 596 in epoch 0, gen_loss = 1.4057691963873118, disc_loss = 0.02269208344936658
Trained batch 597 in epoch 0, gen_loss = 1.4053419708806933, disc_loss = 0.022658652924608603
Trained batch 598 in epoch 0, gen_loss = 1.4050703026814533, disc_loss = 0.022623832792724688
Trained batch 599 in epoch 0, gen_loss = 1.4047932547330857, disc_loss = 0.02259202070417814
Trained batch 600 in epoch 0, gen_loss = 1.4045907639822428, disc_loss = 0.02256195488255688
Trained batch 601 in epoch 0, gen_loss = 1.404395611777258, disc_loss = 0.022528326434340093
Trained batch 602 in epoch 0, gen_loss = 1.4040698358668617, disc_loss = 0.022499149299194266
Trained batch 603 in epoch 0, gen_loss = 1.4043213713248044, disc_loss = 0.022467167236971737
Trained batch 604 in epoch 0, gen_loss = 1.4040461548103773, disc_loss = 0.022433114711633954
Trained batch 605 in epoch 0, gen_loss = 1.4036039273337562, disc_loss = 0.022398822714010617
Trained batch 606 in epoch 0, gen_loss = 1.403476538532452, disc_loss = 0.022365108460128073
Trained batch 607 in epoch 0, gen_loss = 1.4032610411706723, disc_loss = 0.022330591698080656
Trained batch 608 in epoch 0, gen_loss = 1.4029983284046692, disc_loss = 0.022297088502201273
Trained batch 609 in epoch 0, gen_loss = 1.402677309513092, disc_loss = 0.022263787607051676
Trained batch 610 in epoch 0, gen_loss = 1.4023878504133458, disc_loss = 0.02222985761665393
Trained batch 611 in epoch 0, gen_loss = 1.402201862506617, disc_loss = 0.02219608799441036
Trained batch 612 in epoch 0, gen_loss = 1.4019314087623485, disc_loss = 0.02216208960745502
Trained batch 613 in epoch 0, gen_loss = 1.4018404957525894, disc_loss = 0.022127857323506913
Trained batch 614 in epoch 0, gen_loss = 1.401624076347041, disc_loss = 0.0220952634996833
Trained batch 615 in epoch 0, gen_loss = 1.4018330775298082, disc_loss = 0.022062393306382606
Trained batch 616 in epoch 0, gen_loss = 1.4018246969102461, disc_loss = 0.022031124253308994
Trained batch 617 in epoch 0, gen_loss = 1.4016438477633455, disc_loss = 0.021998041810303577
Trained batch 618 in epoch 0, gen_loss = 1.4016422231671113, disc_loss = 0.021965919243230488
Trained batch 619 in epoch 0, gen_loss = 1.4015223433894495, disc_loss = 0.021934035567814605
Trained batch 620 in epoch 0, gen_loss = 1.401373301535221, disc_loss = 0.021901442062510133
Trained batch 621 in epoch 0, gen_loss = 1.401296001921896, disc_loss = 0.02186809660896054
Trained batch 622 in epoch 0, gen_loss = 1.4009006496034502, disc_loss = 0.02183593212522979
Trained batch 623 in epoch 0, gen_loss = 1.4005921242328792, disc_loss = 0.021803533946625136
Trained batch 624 in epoch 0, gen_loss = 1.4006225538253785, disc_loss = 0.02177090744804591
Trained batch 625 in epoch 0, gen_loss = 1.400415579922283, disc_loss = 0.021740088248796488
Trained batch 626 in epoch 0, gen_loss = 1.4002993066915486, disc_loss = 0.021708115452954
Trained batch 627 in epoch 0, gen_loss = 1.4002863504704397, disc_loss = 0.021677137666550956
Trained batch 628 in epoch 0, gen_loss = 1.4003089287322732, disc_loss = 0.021644671406672412
Trained batch 629 in epoch 0, gen_loss = 1.4003572959748525, disc_loss = 0.021613412342655163
Trained batch 630 in epoch 0, gen_loss = 1.4004995766230128, disc_loss = 0.021582342392400426
Trained batch 631 in epoch 0, gen_loss = 1.4005761768998979, disc_loss = 0.021550881203162318
Trained batch 632 in epoch 0, gen_loss = 1.400360015707935, disc_loss = 0.021519178700431782
Trained batch 633 in epoch 0, gen_loss = 1.400088273952436, disc_loss = 0.021487628141703078
Trained batch 634 in epoch 0, gen_loss = 1.3998027944189357, disc_loss = 0.02145661892237391
Trained batch 635 in epoch 0, gen_loss = 1.3996147627725541, disc_loss = 0.0214259953050634
Trained batch 636 in epoch 0, gen_loss = 1.3992829674641416, disc_loss = 0.02139432467425204
Trained batch 637 in epoch 0, gen_loss = 1.398951347345095, disc_loss = 0.02136264594058655
Trained batch 638 in epoch 0, gen_loss = 1.3988911239940423, disc_loss = 0.021331027623102745
Trained batch 639 in epoch 0, gen_loss = 1.3985406447201967, disc_loss = 0.021300610428806977
Trained batch 640 in epoch 0, gen_loss = 1.3987640170336886, disc_loss = 0.021270527439003057
Trained batch 641 in epoch 0, gen_loss = 1.3985654713580171, disc_loss = 0.021239509398401992
Trained batch 642 in epoch 0, gen_loss = 1.398577279658933, disc_loss = 0.02120807870837221
Trained batch 643 in epoch 0, gen_loss = 1.3984164891776092, disc_loss = 0.021177678340424128
Trained batch 644 in epoch 0, gen_loss = 1.3982398885165075, disc_loss = 0.02114647539592413
Trained batch 645 in epoch 0, gen_loss = 1.3978608842973739, disc_loss = 0.021116800795110295
Trained batch 646 in epoch 0, gen_loss = 1.3975376425054749, disc_loss = 0.02108654906808426
Trained batch 647 in epoch 0, gen_loss = 1.3970996490967127, disc_loss = 0.02105601268362708
Trained batch 648 in epoch 0, gen_loss = 1.3971592580959866, disc_loss = 0.021025919023964366
Trained batch 649 in epoch 0, gen_loss = 1.3970616111388574, disc_loss = 0.020995810736114017
Trained batch 650 in epoch 0, gen_loss = 1.3970506898086008, disc_loss = 0.02096588456804382
Trained batch 651 in epoch 0, gen_loss = 1.3967562507997993, disc_loss = 0.020935712844287645
Trained batch 652 in epoch 0, gen_loss = 1.396595256799578, disc_loss = 0.020905999272810737
Trained batch 653 in epoch 0, gen_loss = 1.3966714787191572, disc_loss = 0.020876045639282064
Trained batch 654 in epoch 0, gen_loss = 1.3962988043559417, disc_loss = 0.020847112764711028
Trained batch 655 in epoch 0, gen_loss = 1.396398966087074, disc_loss = 0.020818438227629153
Trained batch 656 in epoch 0, gen_loss = 1.3962375691310818, disc_loss = 0.020788725106190193
Trained batch 657 in epoch 0, gen_loss = 1.3961314113306782, disc_loss = 0.0207617844675744
Trained batch 658 in epoch 0, gen_loss = 1.395987616685164, disc_loss = 0.02073462009013027
Trained batch 659 in epoch 0, gen_loss = 1.395696936231671, disc_loss = 0.020706012946990968
Trained batch 660 in epoch 0, gen_loss = 1.395237420943429, disc_loss = 0.02068150871286786
Trained batch 661 in epoch 0, gen_loss = 1.395466061517191, disc_loss = 0.020655606812487983
Trained batch 662 in epoch 0, gen_loss = 1.3951273539846658, disc_loss = 0.020626306561205315
Trained batch 663 in epoch 0, gen_loss = 1.3947310661336025, disc_loss = 0.020597709599687403
Trained batch 664 in epoch 0, gen_loss = 1.3949450932051006, disc_loss = 0.020568606959956985
Trained batch 665 in epoch 0, gen_loss = 1.3948455094933152, disc_loss = 0.020540539387301694
Trained batch 666 in epoch 0, gen_loss = 1.3944465436678062, disc_loss = 0.020512045744032984
Trained batch 667 in epoch 0, gen_loss = 1.3947756518860777, disc_loss = 0.020483195008626377
Trained batch 668 in epoch 0, gen_loss = 1.39452607143442, disc_loss = 0.02045393968836275
Trained batch 669 in epoch 0, gen_loss = 1.3944493201241563, disc_loss = 0.02042477887155099
Trained batch 670 in epoch 0, gen_loss = 1.394347224612172, disc_loss = 0.020395577779638647
Trained batch 671 in epoch 0, gen_loss = 1.3948133204664503, disc_loss = 0.02036700728673341
Trained batch 672 in epoch 0, gen_loss = 1.3952507172084314, disc_loss = 0.020338792827400348
Trained batch 673 in epoch 0, gen_loss = 1.3953843424511239, disc_loss = 0.020310872278362098
Trained batch 674 in epoch 0, gen_loss = 1.3954323291778565, disc_loss = 0.02028282710859828
Trained batch 675 in epoch 0, gen_loss = 1.3952928326539034, disc_loss = 0.020255193995575686
Trained batch 676 in epoch 0, gen_loss = 1.3949563471570148, disc_loss = 0.020227661001667285
Trained batch 677 in epoch 0, gen_loss = 1.3947226151955867, disc_loss = 0.020200687102340905
Trained batch 678 in epoch 0, gen_loss = 1.394392284799219, disc_loss = 0.020174608796897354
Trained batch 679 in epoch 0, gen_loss = 1.3940226079786524, disc_loss = 0.02014696067207671
Trained batch 680 in epoch 0, gen_loss = 1.3938911214974132, disc_loss = 0.02012003824416009
Trained batch 681 in epoch 0, gen_loss = 1.3939077873383798, disc_loss = 0.020093411722106456
Trained batch 682 in epoch 0, gen_loss = 1.3936501449931245, disc_loss = 0.020065586797066038
Trained batch 683 in epoch 0, gen_loss = 1.3933944803232339, disc_loss = 0.020038915206375258
Trained batch 684 in epoch 0, gen_loss = 1.3930035032495094, disc_loss = 0.02001373058985443
Trained batch 685 in epoch 0, gen_loss = 1.392616704323549, disc_loss = 0.019986484575566617
Trained batch 686 in epoch 0, gen_loss = 1.392364563379746, disc_loss = 0.019959472277655172
Trained batch 687 in epoch 0, gen_loss = 1.392079161696656, disc_loss = 0.01993220253043123
Trained batch 688 in epoch 0, gen_loss = 1.3920549540111393, disc_loss = 0.019904508195355865
Trained batch 689 in epoch 0, gen_loss = 1.3920508942742278, disc_loss = 0.019876918617882294
Trained batch 690 in epoch 0, gen_loss = 1.392108569959483, disc_loss = 0.019850359045830993
Trained batch 691 in epoch 0, gen_loss = 1.3919927496786062, disc_loss = 0.019823429763106484
Trained batch 692 in epoch 0, gen_loss = 1.3918427394066022, disc_loss = 0.019798156715547167
Trained batch 693 in epoch 0, gen_loss = 1.39159081528441, disc_loss = 0.01977168594918788
Trained batch 694 in epoch 0, gen_loss = 1.3913960458563386, disc_loss = 0.01974505444397319
Trained batch 695 in epoch 0, gen_loss = 1.391618987780878, disc_loss = 0.019718318530903653
Trained batch 696 in epoch 0, gen_loss = 1.3914416185239467, disc_loss = 0.019692614503953754
Trained batch 697 in epoch 0, gen_loss = 1.3912681833037674, disc_loss = 0.019667247003814965
Trained batch 698 in epoch 0, gen_loss = 1.3911081953280644, disc_loss = 0.019642723177060704
Trained batch 699 in epoch 0, gen_loss = 1.3911829735551562, disc_loss = 0.019617562716843426
Trained batch 700 in epoch 0, gen_loss = 1.3914365756528695, disc_loss = 0.019591132919327323
Trained batch 701 in epoch 0, gen_loss = 1.3910794793031154, disc_loss = 0.019566365094550956
Trained batch 702 in epoch 0, gen_loss = 1.3908173676744464, disc_loss = 0.019540484318430872
Trained batch 703 in epoch 0, gen_loss = 1.3907253100452097, disc_loss = 0.019514658590279312
Trained batch 704 in epoch 0, gen_loss = 1.3903990623798776, disc_loss = 0.019489416631899695
Trained batch 705 in epoch 0, gen_loss = 1.3901493377118206, disc_loss = 0.019463056499084388
Trained batch 706 in epoch 0, gen_loss = 1.3900144798246434, disc_loss = 0.019436960805588186
Trained batch 707 in epoch 0, gen_loss = 1.3897301059658245, disc_loss = 0.019411328168109712
Trained batch 708 in epoch 0, gen_loss = 1.3894611074154402, disc_loss = 0.019385757464954922
Trained batch 709 in epoch 0, gen_loss = 1.3891207661427243, disc_loss = 0.019360203344479833
Trained batch 710 in epoch 0, gen_loss = 1.3887331110180345, disc_loss = 0.01933456087057936
Trained batch 711 in epoch 0, gen_loss = 1.388764892568749, disc_loss = 0.019309482515954383
Trained batch 712 in epoch 0, gen_loss = 1.3885846102889758, disc_loss = 0.01928414536220757
Trained batch 713 in epoch 0, gen_loss = 1.3884530807075715, disc_loss = 0.019258978726415365
Trained batch 714 in epoch 0, gen_loss = 1.3882996842577742, disc_loss = 0.01923327330993228
Trained batch 715 in epoch 0, gen_loss = 1.388025642107319, disc_loss = 0.019208251152564148
Trained batch 716 in epoch 0, gen_loss = 1.3877757175863206, disc_loss = 0.019183175588878082
Trained batch 717 in epoch 0, gen_loss = 1.387372751089856, disc_loss = 0.019158247192464846
Trained batch 718 in epoch 0, gen_loss = 1.387011301202469, disc_loss = 0.019133548571171836
Trained batch 719 in epoch 0, gen_loss = 1.3868573963642121, disc_loss = 0.019108585226462714
Trained batch 720 in epoch 0, gen_loss = 1.3866342747591736, disc_loss = 0.01908376004994781
Trained batch 721 in epoch 0, gen_loss = 1.3862938061975707, disc_loss = 0.019059109045473158
Trained batch 722 in epoch 0, gen_loss = 1.3859573925844038, disc_loss = 0.019035424288496874
Trained batch 723 in epoch 0, gen_loss = 1.38607162220702, disc_loss = 0.019011464878033655
Trained batch 724 in epoch 0, gen_loss = 1.3862118226084217, disc_loss = 0.01898736668806844
Trained batch 725 in epoch 0, gen_loss = 1.3860419845778096, disc_loss = 0.018962687607094537
Trained batch 726 in epoch 0, gen_loss = 1.3856671623875383, disc_loss = 0.01894067063057498
Trained batch 727 in epoch 0, gen_loss = 1.3857819677054226, disc_loss = 0.018916616087653392
Trained batch 728 in epoch 0, gen_loss = 1.3857154458638572, disc_loss = 0.01889669029506828
Trained batch 729 in epoch 0, gen_loss = 1.3858935308783022, disc_loss = 0.018874772498304382
Trained batch 730 in epoch 0, gen_loss = 1.3857509925166493, disc_loss = 0.018850766784761854
Trained batch 731 in epoch 0, gen_loss = 1.3857068792392648, disc_loss = 0.018826301023236836
Trained batch 732 in epoch 0, gen_loss = 1.3853383836772237, disc_loss = 0.018803028997458202
Trained batch 733 in epoch 0, gen_loss = 1.385395094711709, disc_loss = 0.018783081280085327
Trained batch 734 in epoch 0, gen_loss = 1.3851320811680385, disc_loss = 0.018763402573523574
Trained batch 735 in epoch 0, gen_loss = 1.3849087890399538, disc_loss = 0.018740532809676115
Trained batch 736 in epoch 0, gen_loss = 1.3847269528271224, disc_loss = 0.018716713387059148
Trained batch 737 in epoch 0, gen_loss = 1.3843601875834994, disc_loss = 0.018693102459482556
Trained batch 738 in epoch 0, gen_loss = 1.3845186880380116, disc_loss = 0.018671571826707214
Trained batch 739 in epoch 0, gen_loss = 1.3841042320470551, disc_loss = 0.018649571683301867
Trained batch 740 in epoch 0, gen_loss = 1.384264104762058, disc_loss = 0.018627629624321483
Trained batch 741 in epoch 0, gen_loss = 1.3841556410262528, disc_loss = 0.018605077916453782
Trained batch 742 in epoch 0, gen_loss = 1.384105210990957, disc_loss = 0.018582219247453034
Trained batch 743 in epoch 0, gen_loss = 1.3838856539098165, disc_loss = 0.01856077099622663
Trained batch 744 in epoch 0, gen_loss = 1.3841901766373808, disc_loss = 0.018539557113599708
Trained batch 745 in epoch 0, gen_loss = 1.3839006994428966, disc_loss = 0.01851692365219657
Trained batch 746 in epoch 0, gen_loss = 1.3836539171466546, disc_loss = 0.018494269855344143
Trained batch 747 in epoch 0, gen_loss = 1.3832961008510487, disc_loss = 0.01847196700964073
Trained batch 748 in epoch 0, gen_loss = 1.3830033295622497, disc_loss = 0.018452641110586247
Trained batch 749 in epoch 0, gen_loss = 1.3830275533994039, disc_loss = 0.018433727789980668
Trained batch 750 in epoch 0, gen_loss = 1.3830221410438954, disc_loss = 0.018413024922564983
Trained batch 751 in epoch 0, gen_loss = 1.3828387323846207, disc_loss = 0.018390873768750798
Trained batch 752 in epoch 0, gen_loss = 1.3827751873340581, disc_loss = 0.018369089259183503
Trained batch 753 in epoch 0, gen_loss = 1.382695169916836, disc_loss = 0.018346992206904267
Trained batch 754 in epoch 0, gen_loss = 1.3824629171005147, disc_loss = 0.01832594161695918
Trained batch 755 in epoch 0, gen_loss = 1.3822397763136203, disc_loss = 0.018304606126750715
Trained batch 756 in epoch 0, gen_loss = 1.382065646714547, disc_loss = 0.018282249789036652
Trained batch 757 in epoch 0, gen_loss = 1.382043292465814, disc_loss = 0.01825926345966555
Trained batch 758 in epoch 0, gen_loss = 1.3817624907562698, disc_loss = 0.018236526525830937
Trained batch 759 in epoch 0, gen_loss = 1.3818958379720387, disc_loss = 0.01821396731538698
Trained batch 760 in epoch 0, gen_loss = 1.381629292191093, disc_loss = 0.018193288902665212
Trained batch 761 in epoch 0, gen_loss = 1.3813336712168895, disc_loss = 0.0181714837728716
Trained batch 762 in epoch 0, gen_loss = 1.3815421472214464, disc_loss = 0.018150193381170847
Trained batch 763 in epoch 0, gen_loss = 1.3813081010786026, disc_loss = 0.018129943188886933
Trained batch 764 in epoch 0, gen_loss = 1.3810149802101983, disc_loss = 0.018108389198207876
Trained batch 765 in epoch 0, gen_loss = 1.3811381516817656, disc_loss = 0.018086955221503602
Trained batch 766 in epoch 0, gen_loss = 1.3810413235014078, disc_loss = 0.018064812352125578
Trained batch 767 in epoch 0, gen_loss = 1.3809594026145835, disc_loss = 0.018042857219673653
Trained batch 768 in epoch 0, gen_loss = 1.3810917376231775, disc_loss = 0.018021097468510175
Trained batch 769 in epoch 0, gen_loss = 1.3811861638898972, disc_loss = 0.01799908627154209
Trained batch 770 in epoch 0, gen_loss = 1.381347600278842, disc_loss = 0.017978065477318134
Trained batch 771 in epoch 0, gen_loss = 1.3810322130282309, disc_loss = 0.017957584981153928
Trained batch 772 in epoch 0, gen_loss = 1.3807802834146852, disc_loss = 0.017936376298604267
Trained batch 773 in epoch 0, gen_loss = 1.3804792795686451, disc_loss = 0.01791448716810623
Trained batch 774 in epoch 0, gen_loss = 1.3803600095933484, disc_loss = 0.017892574464842197
Trained batch 775 in epoch 0, gen_loss = 1.3800391883579726, disc_loss = 0.017870750186272377
Trained batch 776 in epoch 0, gen_loss = 1.3800224242216526, disc_loss = 0.01784955555581496
Trained batch 777 in epoch 0, gen_loss = 1.3798182231295077, disc_loss = 0.01782895720942104
Trained batch 778 in epoch 0, gen_loss = 1.3795591603500699, disc_loss = 0.017807648113399112
Trained batch 779 in epoch 0, gen_loss = 1.379494060919835, disc_loss = 0.017786621345051875
Trained batch 780 in epoch 0, gen_loss = 1.3791804959313054, disc_loss = 0.01776566347998666
Trained batch 781 in epoch 0, gen_loss = 1.3792523138053583, disc_loss = 0.017743997140284365
Trained batch 782 in epoch 0, gen_loss = 1.378886891964295, disc_loss = 0.01772310772497685
Trained batch 783 in epoch 0, gen_loss = 1.3788533574160264, disc_loss = 0.0177034720399373
Trained batch 784 in epoch 0, gen_loss = 1.3786789971552078, disc_loss = 0.017683293815082306
Trained batch 785 in epoch 0, gen_loss = 1.3784110884326712, disc_loss = 0.017663114190764568
Trained batch 786 in epoch 0, gen_loss = 1.3783973282749802, disc_loss = 0.017642887973737236
Trained batch 787 in epoch 0, gen_loss = 1.3781170114345358, disc_loss = 0.01762233978808978
Trained batch 788 in epoch 0, gen_loss = 1.3778520015709301, disc_loss = 0.017601356548667357
Trained batch 789 in epoch 0, gen_loss = 1.3776010513305663, disc_loss = 0.0175808734402703
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 1.25070321559906, disc_loss = 0.0012818507384508848
Trained batch 1 in epoch 1, gen_loss = 1.2526813745498657, disc_loss = 0.0011015444761142135
Trained batch 2 in epoch 1, gen_loss = 1.238817850748698, disc_loss = 0.0010805420267085235
Trained batch 3 in epoch 1, gen_loss = 1.2265197038650513, disc_loss = 0.0011886206339113414
Trained batch 4 in epoch 1, gen_loss = 1.2244052171707154, disc_loss = 0.0012482792371883988
Trained batch 5 in epoch 1, gen_loss = 1.2367454171180725, disc_loss = 0.0012669252270522218
Trained batch 6 in epoch 1, gen_loss = 1.2393487351281303, disc_loss = 0.001218949885307146
Trained batch 7 in epoch 1, gen_loss = 1.2220386266708374, disc_loss = 0.0011791513315984048
Trained batch 8 in epoch 1, gen_loss = 1.2549409866333008, disc_loss = 0.0012575424237487216
Trained batch 9 in epoch 1, gen_loss = 1.247189998626709, disc_loss = 0.001390071545029059
Trained batch 10 in epoch 1, gen_loss = 1.2329073710875078, disc_loss = 0.0014429310050962324
Trained batch 11 in epoch 1, gen_loss = 1.227899561325709, disc_loss = 0.0014661924942629412
Trained batch 12 in epoch 1, gen_loss = 1.2403815342829778, disc_loss = 0.0015062191299735927
Trained batch 13 in epoch 1, gen_loss = 1.2771512099674769, disc_loss = 0.001468773794061105
Trained batch 14 in epoch 1, gen_loss = 1.2805271704991659, disc_loss = 0.0014456563590404888
Trained batch 15 in epoch 1, gen_loss = 1.2924505397677422, disc_loss = 0.0014236399474611972
Trained batch 16 in epoch 1, gen_loss = 1.2980603891260483, disc_loss = 0.001401776629363132
Trained batch 17 in epoch 1, gen_loss = 1.2971840964423285, disc_loss = 0.0013756792274458955
Trained batch 18 in epoch 1, gen_loss = 1.2943563586787175, disc_loss = 0.0013357689144629006
Trained batch 19 in epoch 1, gen_loss = 1.3040809452533721, disc_loss = 0.0013226814015069976
Trained batch 20 in epoch 1, gen_loss = 1.3042911404655093, disc_loss = 0.001347727710492022
Trained batch 21 in epoch 1, gen_loss = 1.3082431608980352, disc_loss = 0.0013485173827079548
Trained batch 22 in epoch 1, gen_loss = 1.3034140908199807, disc_loss = 0.0013410630306917365
Trained batch 23 in epoch 1, gen_loss = 1.3075923472642899, disc_loss = 0.0013421352559817024
Trained batch 24 in epoch 1, gen_loss = 1.302099242210388, disc_loss = 0.0013385445787571372
Trained batch 25 in epoch 1, gen_loss = 1.2996618014115553, disc_loss = 0.001346053759334609
Trained batch 26 in epoch 1, gen_loss = 1.2926291580553408, disc_loss = 0.0013866584674731173
Trained batch 27 in epoch 1, gen_loss = 1.3067110989774977, disc_loss = 0.0013772583604025254
Trained batch 28 in epoch 1, gen_loss = 1.3010915723340264, disc_loss = 0.001440425445566532
Trained batch 29 in epoch 1, gen_loss = 1.304559083779653, disc_loss = 0.0014599700555360565
Trained batch 30 in epoch 1, gen_loss = 1.2991700556970411, disc_loss = 0.0014667468194309021
Trained batch 31 in epoch 1, gen_loss = 1.300423253327608, disc_loss = 0.001504272493548342
Trained batch 32 in epoch 1, gen_loss = 1.3015161210840398, disc_loss = 0.001554705225509789
Trained batch 33 in epoch 1, gen_loss = 1.299293931792764, disc_loss = 0.0015719830664559541
Trained batch 34 in epoch 1, gen_loss = 1.301380171094622, disc_loss = 0.0015662327292375266
Trained batch 35 in epoch 1, gen_loss = 1.299242188533147, disc_loss = 0.0015488106065378007
Trained batch 36 in epoch 1, gen_loss = 1.2940048237104673, disc_loss = 0.0015455321440271833
Trained batch 37 in epoch 1, gen_loss = 1.298205134115721, disc_loss = 0.0015629961271770298
Trained batch 38 in epoch 1, gen_loss = 1.301615195396619, disc_loss = 0.0015563286739425398
Trained batch 39 in epoch 1, gen_loss = 1.3012529134750366, disc_loss = 0.0015383327234303578
Trained batch 40 in epoch 1, gen_loss = 1.2979992075664242, disc_loss = 0.0015259695228007509
Trained batch 41 in epoch 1, gen_loss = 1.3053551742008753, disc_loss = 0.0015246797813146952
Trained batch 42 in epoch 1, gen_loss = 1.3094552284063294, disc_loss = 0.001522105146567662
Trained batch 43 in epoch 1, gen_loss = 1.3065542361953042, disc_loss = 0.0015074639708142388
Trained batch 44 in epoch 1, gen_loss = 1.3085046185387506, disc_loss = 0.0014969167144348223
Trained batch 45 in epoch 1, gen_loss = 1.307918501936871, disc_loss = 0.0014797961288739157
Trained batch 46 in epoch 1, gen_loss = 1.3046419366877129, disc_loss = 0.0014657831436241085
Trained batch 47 in epoch 1, gen_loss = 1.300239620109399, disc_loss = 0.0014581063502798013
Trained batch 48 in epoch 1, gen_loss = 1.2961250300310097, disc_loss = 0.0014792030774608102
Trained batch 49 in epoch 1, gen_loss = 1.291102695465088, disc_loss = 0.0014919482229743153
Trained batch 50 in epoch 1, gen_loss = 1.2866410788367777, disc_loss = 0.001500638314824113
Trained batch 51 in epoch 1, gen_loss = 1.2848383325796862, disc_loss = 0.0014937371362555916
Trained batch 52 in epoch 1, gen_loss = 1.2884721935919996, disc_loss = 0.0014859018528851557
Trained batch 53 in epoch 1, gen_loss = 1.2879623108439975, disc_loss = 0.0014879145256364373
Trained batch 54 in epoch 1, gen_loss = 1.2862072424455122, disc_loss = 0.0014751786355521868
Trained batch 55 in epoch 1, gen_loss = 1.2833229175635747, disc_loss = 0.0014980668690571161
Trained batch 56 in epoch 1, gen_loss = 1.2796139006029095, disc_loss = 0.001519553378641017
Trained batch 57 in epoch 1, gen_loss = 1.278348129371117, disc_loss = 0.0015372099376941934
Trained batch 58 in epoch 1, gen_loss = 1.2788433786165916, disc_loss = 0.0015499090363460955
Trained batch 59 in epoch 1, gen_loss = 1.2842555443445842, disc_loss = 0.0015410309880583859
Trained batch 60 in epoch 1, gen_loss = 1.2824821433082956, disc_loss = 0.0015381053424073903
Trained batch 61 in epoch 1, gen_loss = 1.2811528905745475, disc_loss = 0.001562169278904255
Trained batch 62 in epoch 1, gen_loss = 1.2838273388998849, disc_loss = 0.0015777770960186091
Trained batch 63 in epoch 1, gen_loss = 1.283797224983573, disc_loss = 0.0015742228997623897
Trained batch 64 in epoch 1, gen_loss = 1.2836919509447537, disc_loss = 0.0015874514920422092
Trained batch 65 in epoch 1, gen_loss = 1.2925212907068657, disc_loss = 0.0015850174672915741
Trained batch 66 in epoch 1, gen_loss = 1.2933477803842346, disc_loss = 0.0015753938550643846
Trained batch 67 in epoch 1, gen_loss = 1.2912537858766668, disc_loss = 0.0015746863629080027
Trained batch 68 in epoch 1, gen_loss = 1.2893632667652075, disc_loss = 0.0015672772145911079
Trained batch 69 in epoch 1, gen_loss = 1.2881274308477129, disc_loss = 0.0015609597097084459
Trained batch 70 in epoch 1, gen_loss = 1.290662642935632, disc_loss = 0.0015941495969432446
Trained batch 71 in epoch 1, gen_loss = 1.289124960700671, disc_loss = 0.0015952134619712727
Trained batch 72 in epoch 1, gen_loss = 1.2902562242664704, disc_loss = 0.0015901142487315181
Trained batch 73 in epoch 1, gen_loss = 1.2929356500909135, disc_loss = 0.0015827659619783328
Trained batch 74 in epoch 1, gen_loss = 1.2906237840652466, disc_loss = 0.001590627603388081
Trained batch 75 in epoch 1, gen_loss = 1.2892153906194788, disc_loss = 0.0015950409831834566
Trained batch 76 in epoch 1, gen_loss = 1.28808471289548, disc_loss = 0.0015893376820914254
Trained batch 77 in epoch 1, gen_loss = 1.2868517224605267, disc_loss = 0.0015871180512476712
Trained batch 78 in epoch 1, gen_loss = 1.2856451363503179, disc_loss = 0.0015797698185071821
Trained batch 79 in epoch 1, gen_loss = 1.284457428753376, disc_loss = 0.0015705044650530908
Trained batch 80 in epoch 1, gen_loss = 1.283110753989514, disc_loss = 0.001563307877348299
Trained batch 81 in epoch 1, gen_loss = 1.2817138796899377, disc_loss = 0.0015572350942132222
Trained batch 82 in epoch 1, gen_loss = 1.2811383454196423, disc_loss = 0.0015524958578746271
Trained batch 83 in epoch 1, gen_loss = 1.279973532472338, disc_loss = 0.0015467744053152966
Trained batch 84 in epoch 1, gen_loss = 1.2782111799015718, disc_loss = 0.001537831813124392
Trained batch 85 in epoch 1, gen_loss = 1.276993029339369, disc_loss = 0.0015267148826455393
Trained batch 86 in epoch 1, gen_loss = 1.2778779240860336, disc_loss = 0.0015184879664267446
Trained batch 87 in epoch 1, gen_loss = 1.2790936339985242, disc_loss = 0.001513121149566194
Trained batch 88 in epoch 1, gen_loss = 1.2770834156636441, disc_loss = 0.0015068057573955046
Trained batch 89 in epoch 1, gen_loss = 1.277262936698066, disc_loss = 0.0015054611540916893
Trained batch 90 in epoch 1, gen_loss = 1.2765230176213023, disc_loss = 0.0015036332610339582
Trained batch 91 in epoch 1, gen_loss = 1.2756532028965328, disc_loss = 0.0014993551898363005
Trained batch 92 in epoch 1, gen_loss = 1.2775912400214904, disc_loss = 0.0014966587818938718
Trained batch 93 in epoch 1, gen_loss = 1.2782946102162625, disc_loss = 0.0014898955909921688
Trained batch 94 in epoch 1, gen_loss = 1.2774450590735988, disc_loss = 0.0014844106295832287
Trained batch 95 in epoch 1, gen_loss = 1.2774162131051223, disc_loss = 0.0014762936158755717
Trained batch 96 in epoch 1, gen_loss = 1.276089969369554, disc_loss = 0.0014777600077537762
Trained batch 97 in epoch 1, gen_loss = 1.2755357647428707, disc_loss = 0.0014896024207403998
Trained batch 98 in epoch 1, gen_loss = 1.2739974597487786, disc_loss = 0.0015034302310651224
Trained batch 99 in epoch 1, gen_loss = 1.2738559031486512, disc_loss = 0.0015115615696413443
Trained batch 100 in epoch 1, gen_loss = 1.2732491682071496, disc_loss = 0.0015170281507434452
Trained batch 101 in epoch 1, gen_loss = 1.2732734890545117, disc_loss = 0.0015154085241888156
Trained batch 102 in epoch 1, gen_loss = 1.2735854595610239, disc_loss = 0.0015125903046635677
Trained batch 103 in epoch 1, gen_loss = 1.276762184042197, disc_loss = 0.0015100917119595509
Trained batch 104 in epoch 1, gen_loss = 1.2759277672994704, disc_loss = 0.0015064876365830145
Trained batch 105 in epoch 1, gen_loss = 1.2750618109163248, disc_loss = 0.0015039993631258115
Trained batch 106 in epoch 1, gen_loss = 1.2750810629853577, disc_loss = 0.0015010849325743582
Trained batch 107 in epoch 1, gen_loss = 1.277853688708058, disc_loss = 0.0014996359138792657
Trained batch 108 in epoch 1, gen_loss = 1.2761081205595524, disc_loss = 0.0014980538879572456
Trained batch 109 in epoch 1, gen_loss = 1.2754856152967973, disc_loss = 0.0014950806100387127
Trained batch 110 in epoch 1, gen_loss = 1.2771507072019148, disc_loss = 0.0014899691083334252
Trained batch 111 in epoch 1, gen_loss = 1.2771613661731993, disc_loss = 0.0014839833903741756
Trained batch 112 in epoch 1, gen_loss = 1.2753637828658113, disc_loss = 0.0014795795221095988
Trained batch 113 in epoch 1, gen_loss = 1.2762366888815897, disc_loss = 0.001482097455504628
Trained batch 114 in epoch 1, gen_loss = 1.2767999721610028, disc_loss = 0.0014818980226941083
Trained batch 115 in epoch 1, gen_loss = 1.2806651335338066, disc_loss = 0.0014814445036383152
Trained batch 116 in epoch 1, gen_loss = 1.2798036296143491, disc_loss = 0.0014854491694281117
Trained batch 117 in epoch 1, gen_loss = 1.2788864667132749, disc_loss = 0.0014965001037896815
Trained batch 118 in epoch 1, gen_loss = 1.279223963993938, disc_loss = 0.0015016369934452056
Trained batch 119 in epoch 1, gen_loss = 1.2783333321412405, disc_loss = 0.0014982478198362515
Trained batch 120 in epoch 1, gen_loss = 1.2773721099885043, disc_loss = 0.0014925369384798629
Trained batch 121 in epoch 1, gen_loss = 1.2773273450429323, disc_loss = 0.0014866147854472281
Trained batch 122 in epoch 1, gen_loss = 1.2783574951373464, disc_loss = 0.0014816021113240017
Trained batch 123 in epoch 1, gen_loss = 1.2777422791527164, disc_loss = 0.0014842537873905272
Trained batch 124 in epoch 1, gen_loss = 1.2765200881958008, disc_loss = 0.001483854543417692
Trained batch 125 in epoch 1, gen_loss = 1.277192679662553, disc_loss = 0.0014809827109621395
Trained batch 126 in epoch 1, gen_loss = 1.276415318015992, disc_loss = 0.00148509754285979
Trained batch 127 in epoch 1, gen_loss = 1.2754713725298643, disc_loss = 0.0014868884773022728
Trained batch 128 in epoch 1, gen_loss = 1.2741829406383425, disc_loss = 0.0014808619784754376
Trained batch 129 in epoch 1, gen_loss = 1.2731336052601154, disc_loss = 0.001481684293741217
Trained batch 130 in epoch 1, gen_loss = 1.2722932719092332, disc_loss = 0.001478229540058959
Trained batch 131 in epoch 1, gen_loss = 1.2726187751148685, disc_loss = 0.0014746309845411981
Trained batch 132 in epoch 1, gen_loss = 1.2709787546243883, disc_loss = 0.0014748839517929276
Trained batch 133 in epoch 1, gen_loss = 1.2701742106409215, disc_loss = 0.001478131285368173
Trained batch 134 in epoch 1, gen_loss = 1.2697138883449413, disc_loss = 0.0014813380419380134
Trained batch 135 in epoch 1, gen_loss = 1.2681599408388138, disc_loss = 0.001479923280010767
Trained batch 136 in epoch 1, gen_loss = 1.269245600178294, disc_loss = 0.0014756520671334906
Trained batch 137 in epoch 1, gen_loss = 1.2685906826585964, disc_loss = 0.001478957895533708
Trained batch 138 in epoch 1, gen_loss = 1.269660615234924, disc_loss = 0.0014821800483698897
Trained batch 139 in epoch 1, gen_loss = 1.2706410033362252, disc_loss = 0.001483185658331162
Trained batch 140 in epoch 1, gen_loss = 1.2700654023082545, disc_loss = 0.0014815893385836736
Trained batch 141 in epoch 1, gen_loss = 1.26916366395816, disc_loss = 0.0014839984097806606
Trained batch 142 in epoch 1, gen_loss = 1.2680754961667362, disc_loss = 0.001481823809607723
Trained batch 143 in epoch 1, gen_loss = 1.2701591708593898, disc_loss = 0.0014836027185083367
Trained batch 144 in epoch 1, gen_loss = 1.2689841804833248, disc_loss = 0.0014992222872337905
Trained batch 145 in epoch 1, gen_loss = 1.270719199147943, disc_loss = 0.0015067111976661606
Trained batch 146 in epoch 1, gen_loss = 1.2700002412406766, disc_loss = 0.0015098888808734664
Trained batch 147 in epoch 1, gen_loss = 1.270473114542059, disc_loss = 0.0015108311813123324
Trained batch 148 in epoch 1, gen_loss = 1.2703363343373242, disc_loss = 0.0015221218603519385
Trained batch 149 in epoch 1, gen_loss = 1.2700286205609639, disc_loss = 0.0015248291613534093
Trained batch 150 in epoch 1, gen_loss = 1.2704724010252795, disc_loss = 0.0015233235945616732
Trained batch 151 in epoch 1, gen_loss = 1.271013560263734, disc_loss = 0.0015243738927988727
Trained batch 152 in epoch 1, gen_loss = 1.2721054265701692, disc_loss = 0.0015272399938659244
Trained batch 153 in epoch 1, gen_loss = 1.2716473364210747, disc_loss = 0.001539100033333888
Trained batch 154 in epoch 1, gen_loss = 1.2717450995599069, disc_loss = 0.001542374849950354
Trained batch 155 in epoch 1, gen_loss = 1.27069336328751, disc_loss = 0.0015410045206618423
Trained batch 156 in epoch 1, gen_loss = 1.2692706471036195, disc_loss = 0.0016905130020633435
Trained batch 157 in epoch 1, gen_loss = 1.2661462871334221, disc_loss = 0.005068396835564341
Trained batch 158 in epoch 1, gen_loss = 1.270108309931725, disc_loss = 0.0067876258662919395
Trained batch 159 in epoch 1, gen_loss = 1.270031987130642, disc_loss = 0.008477722101088148
Trained batch 160 in epoch 1, gen_loss = 1.2668208994480394, disc_loss = 0.009424847560813245
Trained batch 161 in epoch 1, gen_loss = 1.264198691756637, disc_loss = 0.010082223985838577
Trained batch 162 in epoch 1, gen_loss = 1.2628182399492323, disc_loss = 0.010221557101760448
Trained batch 163 in epoch 1, gen_loss = 1.2637223405082052, disc_loss = 0.010283239860167137
Trained batch 164 in epoch 1, gen_loss = 1.2646254994652488, disc_loss = 0.01046876240606335
Trained batch 165 in epoch 1, gen_loss = 1.2649716720523605, disc_loss = 0.010969534576646086
Trained batch 166 in epoch 1, gen_loss = 1.2654355179050012, disc_loss = 0.011243110214510632
Trained batch 167 in epoch 1, gen_loss = 1.2647321969270706, disc_loss = 0.011258728368418468
Trained batch 168 in epoch 1, gen_loss = 1.2643076400079671, disc_loss = 0.01128048925748723
Trained batch 169 in epoch 1, gen_loss = 1.2645114351721372, disc_loss = 0.011253090598620475
Trained batch 170 in epoch 1, gen_loss = 1.2647062240288272, disc_loss = 0.0112337519629853
Trained batch 171 in epoch 1, gen_loss = 1.263925052659456, disc_loss = 0.011192399649718387
Trained batch 172 in epoch 1, gen_loss = 1.2637645667688007, disc_loss = 0.011184374848919022
Trained batch 173 in epoch 1, gen_loss = 1.2635134972375015, disc_loss = 0.01114007268213378
Trained batch 174 in epoch 1, gen_loss = 1.2625118357794625, disc_loss = 0.011109157046303154
Trained batch 175 in epoch 1, gen_loss = 1.261560196903619, disc_loss = 0.011058667752711865
Trained batch 176 in epoch 1, gen_loss = 1.2611096477777946, disc_loss = 0.01100763221834339
Trained batch 177 in epoch 1, gen_loss = 1.2629792241567976, disc_loss = 0.01095881050170054
Trained batch 178 in epoch 1, gen_loss = 1.2630061523874379, disc_loss = 0.010912485427207538
Trained batch 179 in epoch 1, gen_loss = 1.2623510989877913, disc_loss = 0.010870245075784624
Trained batch 180 in epoch 1, gen_loss = 1.2622332520247823, disc_loss = 0.010829364001051167
Trained batch 181 in epoch 1, gen_loss = 1.2616165352391673, disc_loss = 0.01078078413003503
Trained batch 182 in epoch 1, gen_loss = 1.2629533875835397, disc_loss = 0.010738103730665123
Trained batch 183 in epoch 1, gen_loss = 1.2630503190600353, disc_loss = 0.010697112767957151
Trained batch 184 in epoch 1, gen_loss = 1.2624267352593912, disc_loss = 0.010658254928735865
Trained batch 185 in epoch 1, gen_loss = 1.2623853510425938, disc_loss = 0.010631949441777843
Trained batch 186 in epoch 1, gen_loss = 1.2640102043508845, disc_loss = 0.01058859351703668
Trained batch 187 in epoch 1, gen_loss = 1.266038715839386, disc_loss = 0.010549246804154616
Trained batch 188 in epoch 1, gen_loss = 1.2659927101993056, disc_loss = 0.010511142541728323
Trained batch 189 in epoch 1, gen_loss = 1.2658135326285112, disc_loss = 0.010467227673354118
Trained batch 190 in epoch 1, gen_loss = 1.2655416421241161, disc_loss = 0.010420887992493029
Trained batch 191 in epoch 1, gen_loss = 1.2649682387709618, disc_loss = 0.01038990459649843
Trained batch 192 in epoch 1, gen_loss = 1.2641459493439433, disc_loss = 0.01034442555953126
Trained batch 193 in epoch 1, gen_loss = 1.2629278732329299, disc_loss = 0.010309989137464616
Trained batch 194 in epoch 1, gen_loss = 1.2646410220708602, disc_loss = 0.010285313912810614
Trained batch 195 in epoch 1, gen_loss = 1.264507928673102, disc_loss = 0.010248922864664155
Trained batch 196 in epoch 1, gen_loss = 1.2638210663335578, disc_loss = 0.010206170069871632
Trained batch 197 in epoch 1, gen_loss = 1.2651915598397303, disc_loss = 0.010178689522118393
Trained batch 198 in epoch 1, gen_loss = 1.2660260236442988, disc_loss = 0.010137954885350662
Trained batch 199 in epoch 1, gen_loss = 1.2652877426147462, disc_loss = 0.010101401244173757
Trained batch 200 in epoch 1, gen_loss = 1.2659999861646054, disc_loss = 0.010060575536442967
Trained batch 201 in epoch 1, gen_loss = 1.2669203127964888, disc_loss = 0.010020566604556608
Trained batch 202 in epoch 1, gen_loss = 1.2664664754726616, disc_loss = 0.009992018663737317
Trained batch 203 in epoch 1, gen_loss = 1.2666654814692104, disc_loss = 0.009956112346616482
Trained batch 204 in epoch 1, gen_loss = 1.2670916167701163, disc_loss = 0.009914312026713315
Trained batch 205 in epoch 1, gen_loss = 1.2673158049583435, disc_loss = 0.009875855931912739
Trained batch 206 in epoch 1, gen_loss = 1.2675801601962766, disc_loss = 0.00983606625161615
Trained batch 207 in epoch 1, gen_loss = 1.2666783819978054, disc_loss = 0.009796099389719669
Trained batch 208 in epoch 1, gen_loss = 1.2659127210315906, disc_loss = 0.009759282706078124
Trained batch 209 in epoch 1, gen_loss = 1.2662294433230445, disc_loss = 0.009723103598004119
Trained batch 210 in epoch 1, gen_loss = 1.2654509781661192, disc_loss = 0.00972320114856065
Trained batch 211 in epoch 1, gen_loss = 1.2650302322405689, disc_loss = 0.009696041398027138
Trained batch 212 in epoch 1, gen_loss = 1.2648857333850412, disc_loss = 0.009665682810760964
Trained batch 213 in epoch 1, gen_loss = 1.2663778233750957, disc_loss = 0.009637406955921378
Trained batch 214 in epoch 1, gen_loss = 1.2660530844400095, disc_loss = 0.009603534708730876
Trained batch 215 in epoch 1, gen_loss = 1.265580544869105, disc_loss = 0.009575149304712087
Trained batch 216 in epoch 1, gen_loss = 1.2650544747778898, disc_loss = 0.009537804311179999
Trained batch 217 in epoch 1, gen_loss = 1.2661311188969044, disc_loss = 0.009507968280050015
Trained batch 218 in epoch 1, gen_loss = 1.2664223228959732, disc_loss = 0.009484583449754098
Trained batch 219 in epoch 1, gen_loss = 1.2669262983582237, disc_loss = 0.00944754163395952
Trained batch 220 in epoch 1, gen_loss = 1.2678448630673853, disc_loss = 0.009415788778285096
Trained batch 221 in epoch 1, gen_loss = 1.2687319989676948, disc_loss = 0.009392608435371437
Trained batch 222 in epoch 1, gen_loss = 1.2678756938386926, disc_loss = 0.009357704643698853
Trained batch 223 in epoch 1, gen_loss = 1.2676138601132803, disc_loss = 0.009327209765095696
Trained batch 224 in epoch 1, gen_loss = 1.267689544359843, disc_loss = 0.00929368470226311
Trained batch 225 in epoch 1, gen_loss = 1.2677813462451495, disc_loss = 0.009257990588223875
Trained batch 226 in epoch 1, gen_loss = 1.2694652154057036, disc_loss = 0.009222195181679719
Trained batch 227 in epoch 1, gen_loss = 1.2686842930944342, disc_loss = 0.009194710249542831
Trained batch 228 in epoch 1, gen_loss = 1.2681542900451928, disc_loss = 0.00916277007281162
Trained batch 229 in epoch 1, gen_loss = 1.26783687290938, disc_loss = 0.009132321378337624
Trained batch 230 in epoch 1, gen_loss = 1.267681257033245, disc_loss = 0.009104030832720848
Trained batch 231 in epoch 1, gen_loss = 1.2678816673056832, disc_loss = 0.00907316617667675
Trained batch 232 in epoch 1, gen_loss = 1.2685980771232572, disc_loss = 0.009041037917129152
Trained batch 233 in epoch 1, gen_loss = 1.2696421885082865, disc_loss = 0.009014974827838376
Trained batch 234 in epoch 1, gen_loss = 1.2694188589745379, disc_loss = 0.008984925851542898
Trained batch 235 in epoch 1, gen_loss = 1.2690068256046811, disc_loss = 0.0089542828327621
Trained batch 236 in epoch 1, gen_loss = 1.269514586352095, disc_loss = 0.008921912279400488
Trained batch 237 in epoch 1, gen_loss = 1.2694054020553076, disc_loss = 0.008904565089996591
Trained batch 238 in epoch 1, gen_loss = 1.2687983044021798, disc_loss = 0.008877502662269983
Trained batch 239 in epoch 1, gen_loss = 1.2690566226840019, disc_loss = 0.008845875464127554
Trained batch 240 in epoch 1, gen_loss = 1.2682310916576147, disc_loss = 0.008820542862302628
Trained batch 241 in epoch 1, gen_loss = 1.2686532898382707, disc_loss = 0.00879154727103435
Trained batch 242 in epoch 1, gen_loss = 1.268211629165053, disc_loss = 0.008765421823575448
Trained batch 243 in epoch 1, gen_loss = 1.2677629419037553, disc_loss = 0.008734661464094658
Trained batch 244 in epoch 1, gen_loss = 1.2673295687656014, disc_loss = 0.008703248687943786
Trained batch 245 in epoch 1, gen_loss = 1.2665417717724312, disc_loss = 0.008671340017486743
Trained batch 246 in epoch 1, gen_loss = 1.265688323781558, disc_loss = 0.008644073204512553
Trained batch 247 in epoch 1, gen_loss = 1.2661368894961573, disc_loss = 0.008616992695146285
Trained batch 248 in epoch 1, gen_loss = 1.2658562478291462, disc_loss = 0.00858758365100504
Trained batch 249 in epoch 1, gen_loss = 1.265385066986084, disc_loss = 0.0085592187482398
Trained batch 250 in epoch 1, gen_loss = 1.2664268373018241, disc_loss = 0.008528834989199794
Trained batch 251 in epoch 1, gen_loss = 1.2670628210854908, disc_loss = 0.008499086986245987
Trained batch 252 in epoch 1, gen_loss = 1.2666687871156475, disc_loss = 0.008470580626229421
Trained batch 253 in epoch 1, gen_loss = 1.2663690142744168, disc_loss = 0.00844339451749853
Trained batch 254 in epoch 1, gen_loss = 1.265748446595435, disc_loss = 0.00841460332899884
Trained batch 255 in epoch 1, gen_loss = 1.2654088577255607, disc_loss = 0.008389566088453648
Trained batch 256 in epoch 1, gen_loss = 1.2671617311262435, disc_loss = 0.008366856957080952
Trained batch 257 in epoch 1, gen_loss = 1.2677800017733907, disc_loss = 0.008338509957520869
Trained batch 258 in epoch 1, gen_loss = 1.2671931609223708, disc_loss = 0.008336291484612051
Trained batch 259 in epoch 1, gen_loss = 1.2666358177478496, disc_loss = 0.008341050529270432
Trained batch 260 in epoch 1, gen_loss = 1.2663826549646955, disc_loss = 0.008334004972977527
Trained batch 261 in epoch 1, gen_loss = 1.2662312898017067, disc_loss = 0.008316354002076635
Trained batch 262 in epoch 1, gen_loss = 1.2660682641054741, disc_loss = 0.008297243582911633
Trained batch 263 in epoch 1, gen_loss = 1.2657593867995522, disc_loss = 0.008275344480793909
Trained batch 264 in epoch 1, gen_loss = 1.2655126715606113, disc_loss = 0.008251388776687168
Trained batch 265 in epoch 1, gen_loss = 1.2650723963751829, disc_loss = 0.008225466129746414
Trained batch 266 in epoch 1, gen_loss = 1.2652142677414284, disc_loss = 0.008200566843108445
Trained batch 267 in epoch 1, gen_loss = 1.2646560139620482, disc_loss = 0.00817408951311268
Trained batch 268 in epoch 1, gen_loss = 1.2645645846221527, disc_loss = 0.00814991955083646
Trained batch 269 in epoch 1, gen_loss = 1.2638767820817454, disc_loss = 0.008123569379138105
Trained batch 270 in epoch 1, gen_loss = 1.2639495719402918, disc_loss = 0.008098730114005108
Trained batch 271 in epoch 1, gen_loss = 1.2639765011913635, disc_loss = 0.008072895553649526
Trained batch 272 in epoch 1, gen_loss = 1.2635567397861691, disc_loss = 0.008046251445566902
Trained batch 273 in epoch 1, gen_loss = 1.2643774834862591, disc_loss = 0.008021049776129819
Trained batch 274 in epoch 1, gen_loss = 1.2638752950321543, disc_loss = 0.00799577844858339
Trained batch 275 in epoch 1, gen_loss = 1.2642104128996532, disc_loss = 0.007969311830559003
Trained batch 276 in epoch 1, gen_loss = 1.2637227726326952, disc_loss = 0.007945368591559856
Trained batch 277 in epoch 1, gen_loss = 1.2648927286374483, disc_loss = 0.007919718175975726
Trained batch 278 in epoch 1, gen_loss = 1.264410193675735, disc_loss = 0.00789789230217256
Trained batch 279 in epoch 1, gen_loss = 1.2642047094447273, disc_loss = 0.007875299843310911
Trained batch 280 in epoch 1, gen_loss = 1.2640953237900105, disc_loss = 0.007850621717160043
Trained batch 281 in epoch 1, gen_loss = 1.2640765829289213, disc_loss = 0.007826029298065812
Trained batch 282 in epoch 1, gen_loss = 1.2645086639761502, disc_loss = 0.007801911693894018
Trained batch 283 in epoch 1, gen_loss = 1.2655346972841612, disc_loss = 0.007778757429496437
Trained batch 284 in epoch 1, gen_loss = 1.2660219410009552, disc_loss = 0.007754189662202343
Trained batch 285 in epoch 1, gen_loss = 1.266780258058668, disc_loss = 0.0077307602120775054
Trained batch 286 in epoch 1, gen_loss = 1.2666544033675244, disc_loss = 0.007707943124347772
Trained batch 287 in epoch 1, gen_loss = 1.2664944512976541, disc_loss = 0.0076855577412465615
Trained batch 288 in epoch 1, gen_loss = 1.2663222167731156, disc_loss = 0.007662893458435499
Trained batch 289 in epoch 1, gen_loss = 1.266318548136744, disc_loss = 0.007639034554675414
Trained batch 290 in epoch 1, gen_loss = 1.2661881967098851, disc_loss = 0.0076152240132186496
Trained batch 291 in epoch 1, gen_loss = 1.2659452880082065, disc_loss = 0.007591531790987499
Trained batch 292 in epoch 1, gen_loss = 1.2652598944947175, disc_loss = 0.00757063983314998
Trained batch 293 in epoch 1, gen_loss = 1.2648671926284323, disc_loss = 0.007550490501362095
Trained batch 294 in epoch 1, gen_loss = 1.2643527131969645, disc_loss = 0.007532146278674067
Trained batch 295 in epoch 1, gen_loss = 1.2637308501713984, disc_loss = 0.007509982904003984
Trained batch 296 in epoch 1, gen_loss = 1.2636102016526038, disc_loss = 0.007491282612298575
Trained batch 297 in epoch 1, gen_loss = 1.2637112900714746, disc_loss = 0.007470387324375169
Trained batch 298 in epoch 1, gen_loss = 1.2635152551242739, disc_loss = 0.007449560863725891
Trained batch 299 in epoch 1, gen_loss = 1.263883019288381, disc_loss = 0.007427910442541664
Trained batch 300 in epoch 1, gen_loss = 1.263780528128741, disc_loss = 0.007406665793112619
Trained batch 301 in epoch 1, gen_loss = 1.2635598624778899, disc_loss = 0.007387471088094156
Trained batch 302 in epoch 1, gen_loss = 1.2642723144871173, disc_loss = 0.007365910940351758
Trained batch 303 in epoch 1, gen_loss = 1.264491159664957, disc_loss = 0.007345460593473706
Trained batch 304 in epoch 1, gen_loss = 1.2642514717383462, disc_loss = 0.007327568845166901
Trained batch 305 in epoch 1, gen_loss = 1.2636753905053233, disc_loss = 0.007307166583285198
Trained batch 306 in epoch 1, gen_loss = 1.263979289741392, disc_loss = 0.007285668666350143
Trained batch 307 in epoch 1, gen_loss = 1.2634147243066267, disc_loss = 0.007265706576086436
Trained batch 308 in epoch 1, gen_loss = 1.2633353714804048, disc_loss = 0.007245487137170189
Trained batch 309 in epoch 1, gen_loss = 1.2630851207240936, disc_loss = 0.00722470375645395
Trained batch 310 in epoch 1, gen_loss = 1.263154622059543, disc_loss = 0.007205434215226633
Trained batch 311 in epoch 1, gen_loss = 1.2636827333615377, disc_loss = 0.007184760725627152
Trained batch 312 in epoch 1, gen_loss = 1.2634285947385306, disc_loss = 0.007163979093575428
Trained batch 313 in epoch 1, gen_loss = 1.263264768062883, disc_loss = 0.007145578776312707
Trained batch 314 in epoch 1, gen_loss = 1.263635659974719, disc_loss = 0.007125227035222841
Trained batch 315 in epoch 1, gen_loss = 1.2632862680320498, disc_loss = 0.007108095243663079
Trained batch 316 in epoch 1, gen_loss = 1.2630533186795208, disc_loss = 0.007090006553390201
Trained batch 317 in epoch 1, gen_loss = 1.262471077577123, disc_loss = 0.007071337013749944
Trained batch 318 in epoch 1, gen_loss = 1.2621354440162922, disc_loss = 0.007051571531602266
Trained batch 319 in epoch 1, gen_loss = 1.2632033467292785, disc_loss = 0.007033601047987758
Trained batch 320 in epoch 1, gen_loss = 1.2628904844741584, disc_loss = 0.007020433267797532
Trained batch 321 in epoch 1, gen_loss = 1.2627073096932833, disc_loss = 0.0070097207549817695
Trained batch 322 in epoch 1, gen_loss = 1.2624324541711955, disc_loss = 0.006990800501206377
Trained batch 323 in epoch 1, gen_loss = 1.2631632339807204, disc_loss = 0.006972661826660408
Trained batch 324 in epoch 1, gen_loss = 1.26320741213285, disc_loss = 0.006953558076280527
Trained batch 325 in epoch 1, gen_loss = 1.2632851479974991, disc_loss = 0.00693425160430606
Trained batch 326 in epoch 1, gen_loss = 1.263423163591904, disc_loss = 0.006914798916169422
Trained batch 327 in epoch 1, gen_loss = 1.263320639002614, disc_loss = 0.006895118959907516
Trained batch 328 in epoch 1, gen_loss = 1.2629340778368223, disc_loss = 0.006878656484232649
Trained batch 329 in epoch 1, gen_loss = 1.2629199197798064, disc_loss = 0.006860037624684275
Trained batch 330 in epoch 1, gen_loss = 1.2632274213514298, disc_loss = 0.006841642433637472
Trained batch 331 in epoch 1, gen_loss = 1.2632661996835686, disc_loss = 0.006823036199486787
Trained batch 332 in epoch 1, gen_loss = 1.263241403095715, disc_loss = 0.006808563609353712
Trained batch 333 in epoch 1, gen_loss = 1.263382684327885, disc_loss = 0.0067911775202196215
Trained batch 334 in epoch 1, gen_loss = 1.2628858235344957, disc_loss = 0.006774159239469541
Trained batch 335 in epoch 1, gen_loss = 1.2622784326473873, disc_loss = 0.006756188101852396
Trained batch 336 in epoch 1, gen_loss = 1.2625276702801622, disc_loss = 0.00674153784646111
Trained batch 337 in epoch 1, gen_loss = 1.2625688691816386, disc_loss = 0.006731955446051461
Trained batch 338 in epoch 1, gen_loss = 1.2621585858606659, disc_loss = 0.006716991382480014
Trained batch 339 in epoch 1, gen_loss = 1.2615255299736472, disc_loss = 0.0067010161414680835
Trained batch 340 in epoch 1, gen_loss = 1.2615232299849435, disc_loss = 0.00668445305072271
Trained batch 341 in epoch 1, gen_loss = 1.2609673341115315, disc_loss = 0.006672807021746657
Trained batch 342 in epoch 1, gen_loss = 1.2610742270772728, disc_loss = 0.006657812744633596
Trained batch 343 in epoch 1, gen_loss = 1.2615225970052009, disc_loss = 0.006642957145147172
Trained batch 344 in epoch 1, gen_loss = 1.2611911023872486, disc_loss = 0.006627656449142007
Trained batch 345 in epoch 1, gen_loss = 1.2607633295775837, disc_loss = 0.0066100346728468935
Trained batch 346 in epoch 1, gen_loss = 1.2602999258453633, disc_loss = 0.006602636649745036
Trained batch 347 in epoch 1, gen_loss = 1.2602863373427555, disc_loss = 0.0065911254020449275
Trained batch 348 in epoch 1, gen_loss = 1.2599065228656232, disc_loss = 0.006574773878865825
Trained batch 349 in epoch 1, gen_loss = 1.259643575804574, disc_loss = 0.006558757904567756
Trained batch 350 in epoch 1, gen_loss = 1.2593031112964337, disc_loss = 0.006542088771607074
Trained batch 351 in epoch 1, gen_loss = 1.2591414847834543, disc_loss = 0.006524916292701991
Trained batch 352 in epoch 1, gen_loss = 1.2584701263195395, disc_loss = 0.006507951825202202
Trained batch 353 in epoch 1, gen_loss = 1.2585282130429973, disc_loss = 0.006491402558647596
Trained batch 354 in epoch 1, gen_loss = 1.2586995803134542, disc_loss = 0.006474679203713837
Trained batch 355 in epoch 1, gen_loss = 1.2591178792246271, disc_loss = 0.006461296506795713
Trained batch 356 in epoch 1, gen_loss = 1.2587886721480126, disc_loss = 0.006444740497930424
Trained batch 357 in epoch 1, gen_loss = 1.2590636937311908, disc_loss = 0.006430604681844157
Trained batch 358 in epoch 1, gen_loss = 1.2587204534031222, disc_loss = 0.006414733171994178
Trained batch 359 in epoch 1, gen_loss = 1.258570017748409, disc_loss = 0.006398695805061531
Trained batch 360 in epoch 1, gen_loss = 1.2581960385525985, disc_loss = 0.006382969732333744
Trained batch 361 in epoch 1, gen_loss = 1.2577440182148423, disc_loss = 0.006366779626966505
Trained batch 362 in epoch 1, gen_loss = 1.2576509497382424, disc_loss = 0.006352818462232477
Trained batch 363 in epoch 1, gen_loss = 1.2570849532609458, disc_loss = 0.006337227504735603
Trained batch 364 in epoch 1, gen_loss = 1.2564102868511253, disc_loss = 0.00632192420921518
Trained batch 365 in epoch 1, gen_loss = 1.2564621424414422, disc_loss = 0.006308326016188488
Trained batch 366 in epoch 1, gen_loss = 1.2568551051844044, disc_loss = 0.006293563295377174
Trained batch 367 in epoch 1, gen_loss = 1.2564128682665203, disc_loss = 0.006279566498367627
Trained batch 368 in epoch 1, gen_loss = 1.2562070416241158, disc_loss = 0.006264638584526761
Trained batch 369 in epoch 1, gen_loss = 1.2565105792638418, disc_loss = 0.006250547604223185
Trained batch 370 in epoch 1, gen_loss = 1.25618388132265, disc_loss = 0.006235426325634037
Trained batch 371 in epoch 1, gen_loss = 1.2565913181151114, disc_loss = 0.006221778817166279
Trained batch 372 in epoch 1, gen_loss = 1.2566267104954247, disc_loss = 0.0062078825863990834
Trained batch 373 in epoch 1, gen_loss = 1.2563105729174486, disc_loss = 0.006192947526753103
Trained batch 374 in epoch 1, gen_loss = 1.25625688457489, disc_loss = 0.006178231641262149
Trained batch 375 in epoch 1, gen_loss = 1.25598998240968, disc_loss = 0.006163352646136116
Trained batch 376 in epoch 1, gen_loss = 1.2558037320878208, disc_loss = 0.006149394709023397
Trained batch 377 in epoch 1, gen_loss = 1.255610548945331, disc_loss = 0.006134707518935169
Trained batch 378 in epoch 1, gen_loss = 1.2551873145443153, disc_loss = 0.006121649953065499
Trained batch 379 in epoch 1, gen_loss = 1.2559963872558193, disc_loss = 0.006109065599019615
Trained batch 380 in epoch 1, gen_loss = 1.2558166067118406, disc_loss = 0.006095139401353128
Trained batch 381 in epoch 1, gen_loss = 1.2561986658585633, disc_loss = 0.006081151156073695
Trained batch 382 in epoch 1, gen_loss = 1.2560182078388902, disc_loss = 0.006066706288024156
Trained batch 383 in epoch 1, gen_loss = 1.256322927152117, disc_loss = 0.006056446201228027
Trained batch 384 in epoch 1, gen_loss = 1.2562140619599973, disc_loss = 0.006045381954868094
Trained batch 385 in epoch 1, gen_loss = 1.255742554837558, disc_loss = 0.006032648053815844
Trained batch 386 in epoch 1, gen_loss = 1.255502214111407, disc_loss = 0.006018886312337602
Trained batch 387 in epoch 1, gen_loss = 1.2562955283012587, disc_loss = 0.006005477087680831
Trained batch 388 in epoch 1, gen_loss = 1.2564271431042786, disc_loss = 0.005991511619760557
Trained batch 389 in epoch 1, gen_loss = 1.2567946602136661, disc_loss = 0.005977301752024617
Trained batch 390 in epoch 1, gen_loss = 1.2565607622151485, disc_loss = 0.005963696887025305
Trained batch 391 in epoch 1, gen_loss = 1.2561714089646632, disc_loss = 0.005950757453579821
Trained batch 392 in epoch 1, gen_loss = 1.2562508822700753, disc_loss = 0.005938548490517055
Trained batch 393 in epoch 1, gen_loss = 1.2560532307866865, disc_loss = 0.0059250333234295485
Trained batch 394 in epoch 1, gen_loss = 1.2555077664459808, disc_loss = 0.005912078441860437
Trained batch 395 in epoch 1, gen_loss = 1.256042305568252, disc_loss = 0.00589986047976488
Trained batch 396 in epoch 1, gen_loss = 1.2556757035123312, disc_loss = 0.005886543397214006
Trained batch 397 in epoch 1, gen_loss = 1.2555581382171592, disc_loss = 0.005873363082699042
Trained batch 398 in epoch 1, gen_loss = 1.2554694034700704, disc_loss = 0.005859826386040824
Trained batch 399 in epoch 1, gen_loss = 1.2554922556877137, disc_loss = 0.005847282430986525
Trained batch 400 in epoch 1, gen_loss = 1.2552314589445728, disc_loss = 0.0058346006988363106
Trained batch 401 in epoch 1, gen_loss = 1.2555510591511703, disc_loss = 0.00582148933507194
Trained batch 402 in epoch 1, gen_loss = 1.2553521681660162, disc_loss = 0.005808840893228046
Trained batch 403 in epoch 1, gen_loss = 1.2553783312882527, disc_loss = 0.005795951438984156
Trained batch 404 in epoch 1, gen_loss = 1.2554013178672319, disc_loss = 0.0057831526902808955
Trained batch 405 in epoch 1, gen_loss = 1.2558954748614082, disc_loss = 0.005771066617347378
Trained batch 406 in epoch 1, gen_loss = 1.2558127003161268, disc_loss = 0.005758435449163093
Trained batch 407 in epoch 1, gen_loss = 1.2559484287219889, disc_loss = 0.005745376387708615
Trained batch 408 in epoch 1, gen_loss = 1.2556666686657296, disc_loss = 0.005732802744407758
Trained batch 409 in epoch 1, gen_loss = 1.2554096774357122, disc_loss = 0.005721517688830428
Trained batch 410 in epoch 1, gen_loss = 1.2559299930168764, disc_loss = 0.005708963454090888
Trained batch 411 in epoch 1, gen_loss = 1.2558134033263308, disc_loss = 0.005696761955547224
Trained batch 412 in epoch 1, gen_loss = 1.2555351978930087, disc_loss = 0.005691913959102877
Trained batch 413 in epoch 1, gen_loss = 1.2557487254557402, disc_loss = 0.005687345377411941
Trained batch 414 in epoch 1, gen_loss = 1.255791271451008, disc_loss = 0.005676503313343456
Trained batch 415 in epoch 1, gen_loss = 1.2558449664368079, disc_loss = 0.005666431126813292
Trained batch 416 in epoch 1, gen_loss = 1.2556770336713723, disc_loss = 0.00565471834182344
Trained batch 417 in epoch 1, gen_loss = 1.2554492328725932, disc_loss = 0.005644091953839282
Trained batch 418 in epoch 1, gen_loss = 1.2559243654009835, disc_loss = 0.005633098029613224
Trained batch 419 in epoch 1, gen_loss = 1.2558984319368998, disc_loss = 0.005621312469329929
Trained batch 420 in epoch 1, gen_loss = 1.255972990797138, disc_loss = 0.005609589664339068
Trained batch 421 in epoch 1, gen_loss = 1.2557653581361634, disc_loss = 0.005597960191265176
Trained batch 422 in epoch 1, gen_loss = 1.2553715139416093, disc_loss = 0.005587623205355723
Trained batch 423 in epoch 1, gen_loss = 1.2552540217930417, disc_loss = 0.00557628809000785
Trained batch 424 in epoch 1, gen_loss = 1.2553087930118336, disc_loss = 0.0055646904331275865
Trained batch 425 in epoch 1, gen_loss = 1.255172248177685, disc_loss = 0.005552686893948498
Trained batch 426 in epoch 1, gen_loss = 1.255085339032515, disc_loss = 0.005541380513099566
Trained batch 427 in epoch 1, gen_loss = 1.2550973544053943, disc_loss = 0.005531002400186192
Trained batch 428 in epoch 1, gen_loss = 1.2548358351478488, disc_loss = 0.005520333367587655
Trained batch 429 in epoch 1, gen_loss = 1.2552242389945096, disc_loss = 0.005508974848753708
Trained batch 430 in epoch 1, gen_loss = 1.2548732724377838, disc_loss = 0.005498098132925501
Trained batch 431 in epoch 1, gen_loss = 1.2552407988243632, disc_loss = 0.005487737139817371
Trained batch 432 in epoch 1, gen_loss = 1.2558453969536973, disc_loss = 0.0054781362735644825
Trained batch 433 in epoch 1, gen_loss = 1.2553205679638595, disc_loss = 0.005467385289013549
Trained batch 434 in epoch 1, gen_loss = 1.2555134638972667, disc_loss = 0.0054560139673580045
Trained batch 435 in epoch 1, gen_loss = 1.2552554484354246, disc_loss = 0.005445758227115805
Trained batch 436 in epoch 1, gen_loss = 1.2547691408502155, disc_loss = 0.005435529195205937
Trained batch 437 in epoch 1, gen_loss = 1.2546157608293507, disc_loss = 0.005424295758459607
Trained batch 438 in epoch 1, gen_loss = 1.2553367685348407, disc_loss = 0.005412966041660768
Trained batch 439 in epoch 1, gen_loss = 1.255726205218922, disc_loss = 0.005401970099178884
Trained batch 440 in epoch 1, gen_loss = 1.2555116990796562, disc_loss = 0.005391141281543984
Trained batch 441 in epoch 1, gen_loss = 1.2552267631254586, disc_loss = 0.005380573121810277
Trained batch 442 in epoch 1, gen_loss = 1.2557836426569162, disc_loss = 0.0053699494904652445
Trained batch 443 in epoch 1, gen_loss = 1.2555279723695807, disc_loss = 0.005359587304754002
Trained batch 444 in epoch 1, gen_loss = 1.2552401231915764, disc_loss = 0.005348428931568614
Trained batch 445 in epoch 1, gen_loss = 1.2553811129433157, disc_loss = 0.005339157163069454
Trained batch 446 in epoch 1, gen_loss = 1.2550515907189457, disc_loss = 0.005328824792069776
Trained batch 447 in epoch 1, gen_loss = 1.254858966118523, disc_loss = 0.005318268659850999
Trained batch 448 in epoch 1, gen_loss = 1.2544682671073284, disc_loss = 0.005307684087283693
Trained batch 449 in epoch 1, gen_loss = 1.2545961684650846, disc_loss = 0.005297642246975253
Trained batch 450 in epoch 1, gen_loss = 1.255549977729696, disc_loss = 0.005287431774040408
Trained batch 451 in epoch 1, gen_loss = 1.2553061196761848, disc_loss = 0.0052783817342076595
Trained batch 452 in epoch 1, gen_loss = 1.255024144981081, disc_loss = 0.005268728812189185
Trained batch 453 in epoch 1, gen_loss = 1.2548695322175383, disc_loss = 0.005258993844277049
Trained batch 454 in epoch 1, gen_loss = 1.2545737926776592, disc_loss = 0.005249772906676958
Trained batch 455 in epoch 1, gen_loss = 1.2548904066023074, disc_loss = 0.00523994431977483
Trained batch 456 in epoch 1, gen_loss = 1.2547380911182262, disc_loss = 0.0052301007014988665
Trained batch 457 in epoch 1, gen_loss = 1.254650626640653, disc_loss = 0.005220072539792677
Trained batch 458 in epoch 1, gen_loss = 1.2551457367691339, disc_loss = 0.005209598518184677
Trained batch 459 in epoch 1, gen_loss = 1.2551897852317146, disc_loss = 0.005200610881666248
Trained batch 460 in epoch 1, gen_loss = 1.2551383506708704, disc_loss = 0.0051906669949011676
Trained batch 461 in epoch 1, gen_loss = 1.2552266920799817, disc_loss = 0.005180600039923999
Trained batch 462 in epoch 1, gen_loss = 1.255366417810675, disc_loss = 0.005170983475075781
Trained batch 463 in epoch 1, gen_loss = 1.2552818835809314, disc_loss = 0.005161422523589612
Trained batch 464 in epoch 1, gen_loss = 1.2553386544668546, disc_loss = 0.0051517835690549785
Trained batch 465 in epoch 1, gen_loss = 1.2548977435914233, disc_loss = 0.005142624965741982
Trained batch 466 in epoch 1, gen_loss = 1.2546579472768487, disc_loss = 0.0051348752443622836
Trained batch 467 in epoch 1, gen_loss = 1.2543046487192822, disc_loss = 0.005126137672361329
Trained batch 468 in epoch 1, gen_loss = 1.2545829652977396, disc_loss = 0.005116721555374182
Trained batch 469 in epoch 1, gen_loss = 1.2543406730002544, disc_loss = 0.005107042796543225
Trained batch 470 in epoch 1, gen_loss = 1.254112513961306, disc_loss = 0.005097447301190932
Trained batch 471 in epoch 1, gen_loss = 1.2542721267979025, disc_loss = 0.005087687454745766
Trained batch 472 in epoch 1, gen_loss = 1.2548423168775142, disc_loss = 0.005078500722747604
Trained batch 473 in epoch 1, gen_loss = 1.254983747810251, disc_loss = 0.005070880361693176
Trained batch 474 in epoch 1, gen_loss = 1.2548712931181256, disc_loss = 0.005062377173208485
Trained batch 475 in epoch 1, gen_loss = 1.2553179935246956, disc_loss = 0.005054561239804196
Trained batch 476 in epoch 1, gen_loss = 1.2555183224708029, disc_loss = 0.005047436679110119
Trained batch 477 in epoch 1, gen_loss = 1.2553738395539287, disc_loss = 0.0050390421887314156
Trained batch 478 in epoch 1, gen_loss = 1.2552991771996644, disc_loss = 0.0050295116068768105
Trained batch 479 in epoch 1, gen_loss = 1.2551009776691595, disc_loss = 0.005020227081210275
Trained batch 480 in epoch 1, gen_loss = 1.2551698858177835, disc_loss = 0.005011411337157723
Trained batch 481 in epoch 1, gen_loss = 1.2549127360102548, disc_loss = 0.005003805125312864
Trained batch 482 in epoch 1, gen_loss = 1.254660333412281, disc_loss = 0.004995152838822207
Trained batch 483 in epoch 1, gen_loss = 1.2543883737453745, disc_loss = 0.004985843112111123
Trained batch 484 in epoch 1, gen_loss = 1.2554260966704063, disc_loss = 0.004976801754133872
Trained batch 485 in epoch 1, gen_loss = 1.2554282833028723, disc_loss = 0.004967926169382485
Trained batch 486 in epoch 1, gen_loss = 1.2558294845557556, disc_loss = 0.004958599000247444
Trained batch 487 in epoch 1, gen_loss = 1.2554681621125487, disc_loss = 0.004950003286004906
Trained batch 488 in epoch 1, gen_loss = 1.255084997062059, disc_loss = 0.004941841300195064
Trained batch 489 in epoch 1, gen_loss = 1.255730278151376, disc_loss = 0.004933369760781679
Trained batch 490 in epoch 1, gen_loss = 1.2554034154915275, disc_loss = 0.004924535849382968
Trained batch 491 in epoch 1, gen_loss = 1.254946488432768, disc_loss = 0.004916985906216664
Trained batch 492 in epoch 1, gen_loss = 1.2545981247574998, disc_loss = 0.004910459311827299
Trained batch 493 in epoch 1, gen_loss = 1.2546593858162884, disc_loss = 0.004901977435865738
Trained batch 494 in epoch 1, gen_loss = 1.2552667848991625, disc_loss = 0.00489378677083725
Trained batch 495 in epoch 1, gen_loss = 1.2549348641787805, disc_loss = 0.004886401458098853
Trained batch 496 in epoch 1, gen_loss = 1.2553290272622522, disc_loss = 0.00487810705007959
Trained batch 497 in epoch 1, gen_loss = 1.2551302203691628, disc_loss = 0.004869573841939295
Trained batch 498 in epoch 1, gen_loss = 1.2550412299398908, disc_loss = 0.004860874686300576
Trained batch 499 in epoch 1, gen_loss = 1.2554879665374756, disc_loss = 0.004852088445273694
Trained batch 500 in epoch 1, gen_loss = 1.255207639016553, disc_loss = 0.004845021027844388
Trained batch 501 in epoch 1, gen_loss = 1.2550200724981695, disc_loss = 0.004837967084516192
Trained batch 502 in epoch 1, gen_loss = 1.254547083117142, disc_loss = 0.004829665131635027
Trained batch 503 in epoch 1, gen_loss = 1.2542333394762069, disc_loss = 0.00482076129328417
Trained batch 504 in epoch 1, gen_loss = 1.2537074096132033, disc_loss = 0.004812132206913729
Trained batch 505 in epoch 1, gen_loss = 1.2536905657632549, disc_loss = 0.004804005061900666
Trained batch 506 in epoch 1, gen_loss = 1.2536780695473184, disc_loss = 0.0047956033544022504
Trained batch 507 in epoch 1, gen_loss = 1.2531774049903464, disc_loss = 0.0047875054098237635
Trained batch 508 in epoch 1, gen_loss = 1.2533029747618205, disc_loss = 0.004779295057933394
Trained batch 509 in epoch 1, gen_loss = 1.253087448723176, disc_loss = 0.00477094768778211
Trained batch 510 in epoch 1, gen_loss = 1.2535561226352088, disc_loss = 0.004763089914506834
Trained batch 511 in epoch 1, gen_loss = 1.2533282932126895, disc_loss = 0.004754773548313551
Trained batch 512 in epoch 1, gen_loss = 1.2532295024650604, disc_loss = 0.004746612897163192
Trained batch 513 in epoch 1, gen_loss = 1.2533494773309983, disc_loss = 0.004738147215542188
Trained batch 514 in epoch 1, gen_loss = 1.2530324330607665, disc_loss = 0.004730396444210782
Trained batch 515 in epoch 1, gen_loss = 1.2531200368968092, disc_loss = 0.00472231317340178
Trained batch 516 in epoch 1, gen_loss = 1.252882611013704, disc_loss = 0.00471428403932812
Trained batch 517 in epoch 1, gen_loss = 1.2528454317319346, disc_loss = 0.004706142697958401
Trained batch 518 in epoch 1, gen_loss = 1.2525874586463663, disc_loss = 0.004698035513534909
Trained batch 519 in epoch 1, gen_loss = 1.252636894927575, disc_loss = 0.004690726048283978
Trained batch 520 in epoch 1, gen_loss = 1.2525801819940445, disc_loss = 0.004682804114797962
Trained batch 521 in epoch 1, gen_loss = 1.252454043690729, disc_loss = 0.004674587301810458
Trained batch 522 in epoch 1, gen_loss = 1.2523188179583211, disc_loss = 0.004666798417583325
Trained batch 523 in epoch 1, gen_loss = 1.252496291094154, disc_loss = 0.004659301596518183
Trained batch 524 in epoch 1, gen_loss = 1.252262326081594, disc_loss = 0.004652932274787288
Trained batch 525 in epoch 1, gen_loss = 1.2517727000405128, disc_loss = 0.004645749151663759
Trained batch 526 in epoch 1, gen_loss = 1.2516546501606647, disc_loss = 0.004638011432268287
Trained batch 527 in epoch 1, gen_loss = 1.2516435873553609, disc_loss = 0.004630317335988476
Trained batch 528 in epoch 1, gen_loss = 1.2515310286799541, disc_loss = 0.004622313430053508
Trained batch 529 in epoch 1, gen_loss = 1.2511183051568158, disc_loss = 0.004615210077257493
Trained batch 530 in epoch 1, gen_loss = 1.2507600572149633, disc_loss = 0.004608523692063577
Trained batch 531 in epoch 1, gen_loss = 1.250915390544368, disc_loss = 0.004601908187218679
Trained batch 532 in epoch 1, gen_loss = 1.2509142503729458, disc_loss = 0.00459447041878828
Trained batch 533 in epoch 1, gen_loss = 1.2508524344878251, disc_loss = 0.004587236389028142
Trained batch 534 in epoch 1, gen_loss = 1.251024617992829, disc_loss = 0.004581192485981612
Trained batch 535 in epoch 1, gen_loss = 1.2508590387097045, disc_loss = 0.0045745555323278425
Trained batch 536 in epoch 1, gen_loss = 1.250670378545587, disc_loss = 0.004567573687767963
Trained batch 537 in epoch 1, gen_loss = 1.2506173380467085, disc_loss = 0.004559975107761747
Trained batch 538 in epoch 1, gen_loss = 1.250197768543116, disc_loss = 0.0045524931801435515
Trained batch 539 in epoch 1, gen_loss = 1.2504408471010349, disc_loss = 0.004545166135681534
Trained batch 540 in epoch 1, gen_loss = 1.2502931886371536, disc_loss = 0.004538677055950323
Trained batch 541 in epoch 1, gen_loss = 1.2502007210606578, disc_loss = 0.004531781634024166
Trained batch 542 in epoch 1, gen_loss = 1.249997444903653, disc_loss = 0.004524472669059836
Trained batch 543 in epoch 1, gen_loss = 1.2496425729683216, disc_loss = 0.004517035480228728
Trained batch 544 in epoch 1, gen_loss = 1.249297601914187, disc_loss = 0.00450963138110312
Trained batch 545 in epoch 1, gen_loss = 1.2497687620339377, disc_loss = 0.004502223295435964
Trained batch 546 in epoch 1, gen_loss = 1.2499724812873756, disc_loss = 0.0044946817261289455
Trained batch 547 in epoch 1, gen_loss = 1.2497176420297065, disc_loss = 0.004487128343040559
Trained batch 548 in epoch 1, gen_loss = 1.2494750996756423, disc_loss = 0.004479881693466562
Trained batch 549 in epoch 1, gen_loss = 1.2491253554821014, disc_loss = 0.0044723601816010405
Trained batch 550 in epoch 1, gen_loss = 1.249348974163, disc_loss = 0.004465270477212702
Trained batch 551 in epoch 1, gen_loss = 1.2493569091826244, disc_loss = 0.004457959866356206
Trained batch 552 in epoch 1, gen_loss = 1.2488896858627498, disc_loss = 0.004451012389379037
Trained batch 553 in epoch 1, gen_loss = 1.2490316370118826, disc_loss = 0.004443969524281422
Trained batch 554 in epoch 1, gen_loss = 1.248729227577244, disc_loss = 0.00443753905726496
Trained batch 555 in epoch 1, gen_loss = 1.2485171971346836, disc_loss = 0.0044310261820369274
Trained batch 556 in epoch 1, gen_loss = 1.2485231840631905, disc_loss = 0.0044248320607057166
Trained batch 557 in epoch 1, gen_loss = 1.2485479378144801, disc_loss = 0.004418080082721507
Trained batch 558 in epoch 1, gen_loss = 1.2483163414146479, disc_loss = 0.004411658483423286
Trained batch 559 in epoch 1, gen_loss = 1.2480104719953877, disc_loss = 0.00440606823093341
Trained batch 560 in epoch 1, gen_loss = 1.2477154524568568, disc_loss = 0.004400298747988567
Trained batch 561 in epoch 1, gen_loss = 1.2479086241476052, disc_loss = 0.0043944875173000586
Trained batch 562 in epoch 1, gen_loss = 1.2478272026639636, disc_loss = 0.004388116808673515
Trained batch 563 in epoch 1, gen_loss = 1.2480541100950107, disc_loss = 0.004381366608687511
Trained batch 564 in epoch 1, gen_loss = 1.2480916034858838, disc_loss = 0.004374512517412679
Trained batch 565 in epoch 1, gen_loss = 1.2478605766810293, disc_loss = 0.004367520401508106
Trained batch 566 in epoch 1, gen_loss = 1.2479632406428167, disc_loss = 0.004360626795938126
Trained batch 567 in epoch 1, gen_loss = 1.2476626994534277, disc_loss = 0.004354081391412224
Trained batch 568 in epoch 1, gen_loss = 1.2475181888193154, disc_loss = 0.00434741521707772
Trained batch 569 in epoch 1, gen_loss = 1.2474884249662097, disc_loss = 0.004341066273372506
Trained batch 570 in epoch 1, gen_loss = 1.248229197883773, disc_loss = 0.004334764478998519
Trained batch 571 in epoch 1, gen_loss = 1.2479989613061184, disc_loss = 0.004330514663929311
Trained batch 572 in epoch 1, gen_loss = 1.247766606158611, disc_loss = 0.0043266815938243245
Trained batch 573 in epoch 1, gen_loss = 1.2482902155312927, disc_loss = 0.004320917357331651
Trained batch 574 in epoch 1, gen_loss = 1.2480829523957293, disc_loss = 0.004315497163106161
Trained batch 575 in epoch 1, gen_loss = 1.2480898833730154, disc_loss = 0.004309310764003587
Trained batch 576 in epoch 1, gen_loss = 1.2481265120737681, disc_loss = 0.004302941768987434
Trained batch 577 in epoch 1, gen_loss = 1.2478253456754256, disc_loss = 0.0042967284473394785
Trained batch 578 in epoch 1, gen_loss = 1.2480033276818165, disc_loss = 0.004290112521708903
Trained batch 579 in epoch 1, gen_loss = 1.2479174721857598, disc_loss = 0.004283774131457402
Trained batch 580 in epoch 1, gen_loss = 1.2477281597313086, disc_loss = 0.0042770588805573625
Trained batch 581 in epoch 1, gen_loss = 1.2478707585342972, disc_loss = 0.004270493884509289
Trained batch 582 in epoch 1, gen_loss = 1.2480474220745355, disc_loss = 0.004263867981287397
Trained batch 583 in epoch 1, gen_loss = 1.2478297025169411, disc_loss = 0.0042574821346122865
Trained batch 584 in epoch 1, gen_loss = 1.2477107030713661, disc_loss = 0.004250914178356831
Trained batch 585 in epoch 1, gen_loss = 1.247366865238639, disc_loss = 0.004244463024043109
Trained batch 586 in epoch 1, gen_loss = 1.2469757719178014, disc_loss = 0.004239461532116866
Trained batch 587 in epoch 1, gen_loss = 1.24685180339278, disc_loss = 0.004233906404354822
Trained batch 588 in epoch 1, gen_loss = 1.2467380973600573, disc_loss = 0.004227732774117291
Trained batch 589 in epoch 1, gen_loss = 1.2464082074367393, disc_loss = 0.0042215876306418995
Trained batch 590 in epoch 1, gen_loss = 1.2464850387597448, disc_loss = 0.00421565135954895
Trained batch 591 in epoch 1, gen_loss = 1.246213853661273, disc_loss = 0.004209845221978596
Trained batch 592 in epoch 1, gen_loss = 1.2462890545192093, disc_loss = 0.004203763624001844
Trained batch 593 in epoch 1, gen_loss = 1.2464177053584795, disc_loss = 0.004197245014383401
Trained batch 594 in epoch 1, gen_loss = 1.2464745366272807, disc_loss = 0.004190893674185186
Trained batch 595 in epoch 1, gen_loss = 1.2464031300088703, disc_loss = 0.004184926734585237
Trained batch 596 in epoch 1, gen_loss = 1.2466726030536632, disc_loss = 0.00417885455265649
Trained batch 597 in epoch 1, gen_loss = 1.2465914221710983, disc_loss = 0.004173504936255368
Trained batch 598 in epoch 1, gen_loss = 1.2465489642050906, disc_loss = 0.004168056191665467
Trained batch 599 in epoch 1, gen_loss = 1.2463649645447732, disc_loss = 0.004161843261584484
Trained batch 600 in epoch 1, gen_loss = 1.2466310029616967, disc_loss = 0.0041559286306716015
Trained batch 601 in epoch 1, gen_loss = 1.2469313112010196, disc_loss = 0.004150253830228521
Trained batch 602 in epoch 1, gen_loss = 1.2470890308296305, disc_loss = 0.004144356486419985
Trained batch 603 in epoch 1, gen_loss = 1.2471303792781387, disc_loss = 0.004138261539378166
Trained batch 604 in epoch 1, gen_loss = 1.246854703386953, disc_loss = 0.0041323378883217545
Trained batch 605 in epoch 1, gen_loss = 1.2470113624243846, disc_loss = 0.004126175396402194
Trained batch 606 in epoch 1, gen_loss = 1.2472009728532254, disc_loss = 0.004120100999102948
Trained batch 607 in epoch 1, gen_loss = 1.2470278550723666, disc_loss = 0.004114218007855111
Trained batch 608 in epoch 1, gen_loss = 1.2468480514775355, disc_loss = 0.004108431225941533
Trained batch 609 in epoch 1, gen_loss = 1.2465151393022693, disc_loss = 0.004103113530054841
Trained batch 610 in epoch 1, gen_loss = 1.2468287399474611, disc_loss = 0.0040973286300100414
Trained batch 611 in epoch 1, gen_loss = 1.2465562330546722, disc_loss = 0.004091347527933335
Trained batch 612 in epoch 1, gen_loss = 1.2468485282840387, disc_loss = 0.004085316387455998
Trained batch 613 in epoch 1, gen_loss = 1.2470374191816933, disc_loss = 0.004079328028083982
Trained batch 614 in epoch 1, gen_loss = 1.246899021834862, disc_loss = 0.004073557700503739
Trained batch 615 in epoch 1, gen_loss = 1.2467831807670655, disc_loss = 0.004068158765481452
Trained batch 616 in epoch 1, gen_loss = 1.2468158334155524, disc_loss = 0.004063603870221225
Trained batch 617 in epoch 1, gen_loss = 1.2466495176927943, disc_loss = 0.004058422568697983
Trained batch 618 in epoch 1, gen_loss = 1.246588802780589, disc_loss = 0.00405265281905205
Trained batch 619 in epoch 1, gen_loss = 1.246381479982407, disc_loss = 0.004047328825089931
Trained batch 620 in epoch 1, gen_loss = 1.2463360584300498, disc_loss = 0.00404205084948961
Trained batch 621 in epoch 1, gen_loss = 1.2466364206800125, disc_loss = 0.004036648731721397
Trained batch 622 in epoch 1, gen_loss = 1.2464206632986115, disc_loss = 0.0040312456552882535
Trained batch 623 in epoch 1, gen_loss = 1.2462178798249135, disc_loss = 0.004025537621484359
Trained batch 624 in epoch 1, gen_loss = 1.2460431408882142, disc_loss = 0.00402027926305309
Trained batch 625 in epoch 1, gen_loss = 1.2456886072318776, disc_loss = 0.0040148509147103885
Trained batch 626 in epoch 1, gen_loss = 1.2457911929255276, disc_loss = 0.00400963535348913
Trained batch 627 in epoch 1, gen_loss = 1.2457202968134242, disc_loss = 0.004004316798939257
Trained batch 628 in epoch 1, gen_loss = 1.245371851803578, disc_loss = 0.0039986536229386135
Trained batch 629 in epoch 1, gen_loss = 1.2452437967535048, disc_loss = 0.003993374762579887
Trained batch 630 in epoch 1, gen_loss = 1.2451487011652551, disc_loss = 0.003987883216064577
Trained batch 631 in epoch 1, gen_loss = 1.2449176418064516, disc_loss = 0.003982336108043755
Trained batch 632 in epoch 1, gen_loss = 1.2449979184174802, disc_loss = 0.003978049298152504
Trained batch 633 in epoch 1, gen_loss = 1.244879527892976, disc_loss = 0.003972946536177857
Trained batch 634 in epoch 1, gen_loss = 1.2449148160266126, disc_loss = 0.003968253272849568
Trained batch 635 in epoch 1, gen_loss = 1.244807983813046, disc_loss = 0.003963845308083725
Trained batch 636 in epoch 1, gen_loss = 1.2447976445665165, disc_loss = 0.003958775822802051
Trained batch 637 in epoch 1, gen_loss = 1.2454600299600525, disc_loss = 0.003953261424498676
Trained batch 638 in epoch 1, gen_loss = 1.245426164080093, disc_loss = 0.003948575252051653
Trained batch 639 in epoch 1, gen_loss = 1.2451327866874635, disc_loss = 0.003943815753382296
Trained batch 640 in epoch 1, gen_loss = 1.2448519365091963, disc_loss = 0.003939340358780546
Trained batch 641 in epoch 1, gen_loss = 1.2446187104205848, disc_loss = 0.003934507695473861
Trained batch 642 in epoch 1, gen_loss = 1.2445301296736924, disc_loss = 0.003928956373322764
Trained batch 643 in epoch 1, gen_loss = 1.2442736767278695, disc_loss = 0.0039235818832414945
Trained batch 644 in epoch 1, gen_loss = 1.2439499634180882, disc_loss = 0.003918716148067223
Trained batch 645 in epoch 1, gen_loss = 1.2435655288467466, disc_loss = 0.003913553922655906
Trained batch 646 in epoch 1, gen_loss = 1.243234179027298, disc_loss = 0.00390922903223431
Trained batch 647 in epoch 1, gen_loss = 1.2432604543404815, disc_loss = 0.00390474254783368
Trained batch 648 in epoch 1, gen_loss = 1.2430756827715916, disc_loss = 0.0038994592814925104
Trained batch 649 in epoch 1, gen_loss = 1.2430831227852748, disc_loss = 0.0038941784118875287
Trained batch 650 in epoch 1, gen_loss = 1.243163373338462, disc_loss = 0.003889255027072833
Trained batch 651 in epoch 1, gen_loss = 1.2430161220347222, disc_loss = 0.0038845643009761907
Trained batch 652 in epoch 1, gen_loss = 1.2428704891781712, disc_loss = 0.003879299345262246
Trained batch 653 in epoch 1, gen_loss = 1.2426831112542283, disc_loss = 0.0038743258682820115
Trained batch 654 in epoch 1, gen_loss = 1.2426315814484166, disc_loss = 0.0038690485797808257
Trained batch 655 in epoch 1, gen_loss = 1.2423439828179232, disc_loss = 0.0038637081403377544
Trained batch 656 in epoch 1, gen_loss = 1.242315432706017, disc_loss = 0.0038585168039468733
Trained batch 657 in epoch 1, gen_loss = 1.2420150475480274, disc_loss = 0.0038535388557758396
Trained batch 658 in epoch 1, gen_loss = 1.2421827389546338, disc_loss = 0.003848832616637629
Trained batch 659 in epoch 1, gen_loss = 1.2420637955268223, disc_loss = 0.003843894339815685
Trained batch 660 in epoch 1, gen_loss = 1.2419224799851607, disc_loss = 0.0038390575748559726
Trained batch 661 in epoch 1, gen_loss = 1.2416438495464555, disc_loss = 0.00383400153592046
Trained batch 662 in epoch 1, gen_loss = 1.241568810889444, disc_loss = 0.0038296222136472526
Trained batch 663 in epoch 1, gen_loss = 1.2412313800080712, disc_loss = 0.0038251408911590657
Trained batch 664 in epoch 1, gen_loss = 1.241436841523737, disc_loss = 0.003820422903592593
Trained batch 665 in epoch 1, gen_loss = 1.2410722340012457, disc_loss = 0.0038158524237494836
Trained batch 666 in epoch 1, gen_loss = 1.2409956575869798, disc_loss = 0.0038112719894793146
Trained batch 667 in epoch 1, gen_loss = 1.2408873366560051, disc_loss = 0.003807384218054428
Trained batch 668 in epoch 1, gen_loss = 1.241144264849134, disc_loss = 0.0038024797166074016
Trained batch 669 in epoch 1, gen_loss = 1.2409282825776, disc_loss = 0.0037985694164639587
Trained batch 670 in epoch 1, gen_loss = 1.2410176311093541, disc_loss = 0.0037949103411826987
Trained batch 671 in epoch 1, gen_loss = 1.2408853418947685, disc_loss = 0.0037900962186194235
Trained batch 672 in epoch 1, gen_loss = 1.2413216552089616, disc_loss = 0.0037852977749332508
Trained batch 673 in epoch 1, gen_loss = 1.2413018500592659, disc_loss = 0.003780108453786741
Trained batch 674 in epoch 1, gen_loss = 1.2411397323785005, disc_loss = 0.0037754003497495973
Trained batch 675 in epoch 1, gen_loss = 1.2411008943643795, disc_loss = 0.0037705839453843703
Trained batch 676 in epoch 1, gen_loss = 1.2412394379407299, disc_loss = 0.0037662818196657465
Trained batch 677 in epoch 1, gen_loss = 1.2411751354162672, disc_loss = 0.0037619314712106873
Trained batch 678 in epoch 1, gen_loss = 1.2409658352124322, disc_loss = 0.0037573149349075497
Trained batch 679 in epoch 1, gen_loss = 1.2410806779475774, disc_loss = 0.00375270906053415
Trained batch 680 in epoch 1, gen_loss = 1.2410269166054355, disc_loss = 0.0037481631607907207
Trained batch 681 in epoch 1, gen_loss = 1.240721042642146, disc_loss = 0.0037436244958606096
Trained batch 682 in epoch 1, gen_loss = 1.2404319259991234, disc_loss = 0.0037391055091543293
Trained batch 683 in epoch 1, gen_loss = 1.240480544187172, disc_loss = 0.0037341749258829574
Trained batch 684 in epoch 1, gen_loss = 1.240809455840257, disc_loss = 0.003729470765190947
Trained batch 685 in epoch 1, gen_loss = 1.2407274075047963, disc_loss = 0.003724651236976999
Trained batch 686 in epoch 1, gen_loss = 1.2405809027832841, disc_loss = 0.003720073907173834
Trained batch 687 in epoch 1, gen_loss = 1.2404919861880845, disc_loss = 0.003715192274983057
Trained batch 688 in epoch 1, gen_loss = 1.2404555574556912, disc_loss = 0.003710327719061815
Trained batch 689 in epoch 1, gen_loss = 1.2404050351053044, disc_loss = 0.003705475146399703
Trained batch 690 in epoch 1, gen_loss = 1.2404050588090236, disc_loss = 0.0037010983492695225
Trained batch 691 in epoch 1, gen_loss = 1.2402615094977307, disc_loss = 0.003696534168355388
Trained batch 692 in epoch 1, gen_loss = 1.240019178579724, disc_loss = 0.003691914580472776
Trained batch 693 in epoch 1, gen_loss = 1.239885779296287, disc_loss = 0.0036872283382621738
Trained batch 694 in epoch 1, gen_loss = 1.239608541066698, disc_loss = 0.003682647453346323
Trained batch 695 in epoch 1, gen_loss = 1.2399014608784653, disc_loss = 0.003677929194671525
Trained batch 696 in epoch 1, gen_loss = 1.239794226168218, disc_loss = 0.0036731582768648927
Trained batch 697 in epoch 1, gen_loss = 1.2395314230105938, disc_loss = 0.003668648915806983
Trained batch 698 in epoch 1, gen_loss = 1.2395036751790791, disc_loss = 0.003664306226137823
Trained batch 699 in epoch 1, gen_loss = 1.2396896703754152, disc_loss = 0.0036596707369400453
Trained batch 700 in epoch 1, gen_loss = 1.2394421492595646, disc_loss = 0.0036550661635826927
Trained batch 701 in epoch 1, gen_loss = 1.2397005677732647, disc_loss = 0.0036507242678782696
Trained batch 702 in epoch 1, gen_loss = 1.2398098809790306, disc_loss = 0.003646069155376044
Trained batch 703 in epoch 1, gen_loss = 1.2398264969445087, disc_loss = 0.0036414974721000444
Trained batch 704 in epoch 1, gen_loss = 1.2400338092594283, disc_loss = 0.003636785427683053
Trained batch 705 in epoch 1, gen_loss = 1.240116889770578, disc_loss = 0.0036320047888861277
Trained batch 706 in epoch 1, gen_loss = 1.2400172912585516, disc_loss = 0.0036276935452702053
Trained batch 707 in epoch 1, gen_loss = 1.239747229184808, disc_loss = 0.0036244770163561
Trained batch 708 in epoch 1, gen_loss = 1.2395895938947272, disc_loss = 0.003620994515629677
Trained batch 709 in epoch 1, gen_loss = 1.2395985100470799, disc_loss = 0.0036167371119569303
Trained batch 710 in epoch 1, gen_loss = 1.239722992716627, disc_loss = 0.0036121929473238415
Trained batch 711 in epoch 1, gen_loss = 1.239510335363029, disc_loss = 0.0036078521481020575
Trained batch 712 in epoch 1, gen_loss = 1.2400744209617252, disc_loss = 0.0036039347206059513
Trained batch 713 in epoch 1, gen_loss = 1.2402409379388772, disc_loss = 0.003600665976711437
Trained batch 714 in epoch 1, gen_loss = 1.240223831146747, disc_loss = 0.003596794337011431
Trained batch 715 in epoch 1, gen_loss = 1.239955191755428, disc_loss = 0.003592765685034312
Trained batch 716 in epoch 1, gen_loss = 1.2401807274113472, disc_loss = 0.0035886379271210527
Trained batch 717 in epoch 1, gen_loss = 1.240182557726969, disc_loss = 0.0035842095684045457
Trained batch 718 in epoch 1, gen_loss = 1.2401819248192831, disc_loss = 0.003579674996230013
Trained batch 719 in epoch 1, gen_loss = 1.2399891428649426, disc_loss = 0.003575528923304066
Trained batch 720 in epoch 1, gen_loss = 1.2397910195316257, disc_loss = 0.0035712508563111806
Trained batch 721 in epoch 1, gen_loss = 1.2396126712293176, disc_loss = 0.003566866037859891
Trained batch 722 in epoch 1, gen_loss = 1.2392193008920134, disc_loss = 0.0035635915464985045
Trained batch 723 in epoch 1, gen_loss = 1.239460513489681, disc_loss = 0.0035600552807072594
Trained batch 724 in epoch 1, gen_loss = 1.239492812896597, disc_loss = 0.003556529664201662
Trained batch 725 in epoch 1, gen_loss = 1.2395469249936832, disc_loss = 0.0035523416607312927
Trained batch 726 in epoch 1, gen_loss = 1.2394675033620497, disc_loss = 0.003548092675624938
Trained batch 727 in epoch 1, gen_loss = 1.2393285860563372, disc_loss = 0.00354426160521433
Trained batch 728 in epoch 1, gen_loss = 1.239177945137678, disc_loss = 0.0035402764586124325
Trained batch 729 in epoch 1, gen_loss = 1.2387917222225502, disc_loss = 0.0035365649974627472
Trained batch 730 in epoch 1, gen_loss = 1.239031460396079, disc_loss = 0.0035324038452517865
Trained batch 731 in epoch 1, gen_loss = 1.238695456437726, disc_loss = 0.003528356041415414
Trained batch 732 in epoch 1, gen_loss = 1.2386778218196488, disc_loss = 0.0035242238531850334
Trained batch 733 in epoch 1, gen_loss = 1.2386560197259815, disc_loss = 0.0035201179706069643
Trained batch 734 in epoch 1, gen_loss = 1.238716985173777, disc_loss = 0.0035158341472927277
Trained batch 735 in epoch 1, gen_loss = 1.2385669532839372, disc_loss = 0.0035116155024455943
Trained batch 736 in epoch 1, gen_loss = 1.238516403263589, disc_loss = 0.0035072808299091074
Trained batch 737 in epoch 1, gen_loss = 1.2388308601489235, disc_loss = 0.003503104190439614
Trained batch 738 in epoch 1, gen_loss = 1.2391620289650274, disc_loss = 0.0034990752666337346
Trained batch 739 in epoch 1, gen_loss = 1.2390618015785475, disc_loss = 0.00349492715365675
Trained batch 740 in epoch 1, gen_loss = 1.2391690783976865, disc_loss = 0.003491207861394009
Trained batch 741 in epoch 1, gen_loss = 1.2389256466591776, disc_loss = 0.0034873473860503545
Trained batch 742 in epoch 1, gen_loss = 1.2394614400164115, disc_loss = 0.0034842586016246716
Trained batch 743 in epoch 1, gen_loss = 1.239562255160142, disc_loss = 0.0034802929610211115
Trained batch 744 in epoch 1, gen_loss = 1.2396467259266233, disc_loss = 0.0034765704735354114
Trained batch 745 in epoch 1, gen_loss = 1.2396689480015803, disc_loss = 0.0034734428359395964
Trained batch 746 in epoch 1, gen_loss = 1.239512967217559, disc_loss = 0.0034697973751852606
Trained batch 747 in epoch 1, gen_loss = 1.2395782638839221, disc_loss = 0.00346605004612786
Trained batch 748 in epoch 1, gen_loss = 1.239444334214138, disc_loss = 0.0034622811964195154
Trained batch 749 in epoch 1, gen_loss = 1.2399195350805918, disc_loss = 0.0034590625646912184
Trained batch 750 in epoch 1, gen_loss = 1.2400528115534115, disc_loss = 0.0034579073974367273
Trained batch 751 in epoch 1, gen_loss = 1.2401352646027475, disc_loss = 0.0034575833014582227
Trained batch 752 in epoch 1, gen_loss = 1.2402654524501735, disc_loss = 0.0034545407716539203
Trained batch 753 in epoch 1, gen_loss = 1.2406888492701857, disc_loss = 0.0034513922945293043
Trained batch 754 in epoch 1, gen_loss = 1.2406315322743346, disc_loss = 0.0034476569715335297
Trained batch 755 in epoch 1, gen_loss = 1.240890269478162, disc_loss = 0.003444085744150764
Trained batch 756 in epoch 1, gen_loss = 1.2406223901354339, disc_loss = 0.0034404795298453106
Trained batch 757 in epoch 1, gen_loss = 1.2405671114814627, disc_loss = 0.0034369282956381937
Trained batch 758 in epoch 1, gen_loss = 1.2403369030776545, disc_loss = 0.0034336538823018996
Trained batch 759 in epoch 1, gen_loss = 1.2406327375455906, disc_loss = 0.003430087566735701
Trained batch 760 in epoch 1, gen_loss = 1.2404232134016993, disc_loss = 0.0034268582968298915
Trained batch 761 in epoch 1, gen_loss = 1.2403438835162817, disc_loss = 0.003423333297469262
Trained batch 762 in epoch 1, gen_loss = 1.2404543210607055, disc_loss = 0.0034196227360568663
Trained batch 763 in epoch 1, gen_loss = 1.2403392840898473, disc_loss = 0.003415920361804871
Trained batch 764 in epoch 1, gen_loss = 1.2401566168062048, disc_loss = 0.003411962991516453
Trained batch 765 in epoch 1, gen_loss = 1.2398888839909676, disc_loss = 0.003408204373619677
Trained batch 766 in epoch 1, gen_loss = 1.2396086100804604, disc_loss = 0.003404672984704691
Trained batch 767 in epoch 1, gen_loss = 1.2400738156866282, disc_loss = 0.0034009196917850204
Trained batch 768 in epoch 1, gen_loss = 1.239985436162341, disc_loss = 0.0033973203177965925
Trained batch 769 in epoch 1, gen_loss = 1.239700117281505, disc_loss = 0.003393564537143359
Trained batch 770 in epoch 1, gen_loss = 1.2397382753368482, disc_loss = 0.003389682978276591
Trained batch 771 in epoch 1, gen_loss = 1.2396236757694747, disc_loss = 0.0033855948202594585
Trained batch 772 in epoch 1, gen_loss = 1.2399615090229532, disc_loss = 0.003381984183908305
Trained batch 773 in epoch 1, gen_loss = 1.239891908350533, disc_loss = 0.0033787235761314296
Trained batch 774 in epoch 1, gen_loss = 1.2403198576742602, disc_loss = 0.0033755149460405172
Trained batch 775 in epoch 1, gen_loss = 1.2401866690860581, disc_loss = 0.003371880589595056
Trained batch 776 in epoch 1, gen_loss = 1.240223877755218, disc_loss = 0.0033679666941569867
Trained batch 777 in epoch 1, gen_loss = 1.240069231444582, disc_loss = 0.003364140670172718
Trained batch 778 in epoch 1, gen_loss = 1.2404709078840175, disc_loss = 0.003360636613771244
Trained batch 779 in epoch 1, gen_loss = 1.2404117999168542, disc_loss = 0.003357189986201821
Trained batch 780 in epoch 1, gen_loss = 1.2406203715505124, disc_loss = 0.003353509949878718
Trained batch 781 in epoch 1, gen_loss = 1.2409476184326669, disc_loss = 0.0033495758814105106
Trained batch 782 in epoch 1, gen_loss = 1.2408225628455785, disc_loss = 0.003345725551432107
Trained batch 783 in epoch 1, gen_loss = 1.2406079642170547, disc_loss = 0.0033422861555367006
Trained batch 784 in epoch 1, gen_loss = 1.240815953767983, disc_loss = 0.003339039092341432
Trained batch 785 in epoch 1, gen_loss = 1.2408038624218705, disc_loss = 0.0033357102133349382
Trained batch 786 in epoch 1, gen_loss = 1.2407418258459777, disc_loss = 0.003332471946527882
Trained batch 787 in epoch 1, gen_loss = 1.2408674239053339, disc_loss = 0.003329153989739675
Trained batch 788 in epoch 1, gen_loss = 1.2411944756640831, disc_loss = 0.0033255194609325806
Trained batch 789 in epoch 1, gen_loss = 1.241206693573843, disc_loss = 0.003321785043944941
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 1.2084767818450928, disc_loss = 0.000767066259868443
Trained batch 1 in epoch 2, gen_loss = 1.240587830543518, disc_loss = 0.0007190819596871734
Trained batch 2 in epoch 2, gen_loss = 1.2771742343902588, disc_loss = 0.000662588009921213
Trained batch 3 in epoch 2, gen_loss = 1.284043937921524, disc_loss = 0.0006718069198541343
Trained batch 4 in epoch 2, gen_loss = 1.2687529802322388, disc_loss = 0.0007417228538542986
Trained batch 5 in epoch 2, gen_loss = 1.2820807695388794, disc_loss = 0.0007377704217409095
Trained batch 6 in epoch 2, gen_loss = 1.2592457021985735, disc_loss = 0.0007227309646883181
Trained batch 7 in epoch 2, gen_loss = 1.2221014350652695, disc_loss = 0.0007617551309522241
Trained batch 8 in epoch 2, gen_loss = 1.218762172593011, disc_loss = 0.0007778481813147664
Trained batch 9 in epoch 2, gen_loss = 1.2136050939559937, disc_loss = 0.0007609871739987284
Trained batch 10 in epoch 2, gen_loss = 1.2270407676696777, disc_loss = 0.000741932154844769
Trained batch 11 in epoch 2, gen_loss = 1.2117552558581035, disc_loss = 0.0007377940249474099
Trained batch 12 in epoch 2, gen_loss = 1.2011287212371826, disc_loss = 0.0007878838805481791
Trained batch 13 in epoch 2, gen_loss = 1.197755319731576, disc_loss = 0.0008114855736494064
Trained batch 14 in epoch 2, gen_loss = 1.1931734561920166, disc_loss = 0.0008345861919224262
Trained batch 15 in epoch 2, gen_loss = 1.2007204741239548, disc_loss = 0.0008755754824960604
Trained batch 16 in epoch 2, gen_loss = 1.1954600951250862, disc_loss = 0.0009363340350854047
Trained batch 17 in epoch 2, gen_loss = 1.1957212090492249, disc_loss = 0.0009821384964096877
Trained batch 18 in epoch 2, gen_loss = 1.2007331157985486, disc_loss = 0.0009792912935249899
Trained batch 19 in epoch 2, gen_loss = 1.2010799646377563, disc_loss = 0.0009523622997221537
Trained batch 20 in epoch 2, gen_loss = 1.201735598700387, disc_loss = 0.0009243626665833983
Trained batch 21 in epoch 2, gen_loss = 1.200208848172968, disc_loss = 0.000899320666741749
Trained batch 22 in epoch 2, gen_loss = 1.1974106871563455, disc_loss = 0.0008759860837649878
Trained batch 23 in epoch 2, gen_loss = 1.1990450322628021, disc_loss = 0.0008688632939689948
Trained batch 24 in epoch 2, gen_loss = 1.1974115657806397, disc_loss = 0.000863501135027036
Trained batch 25 in epoch 2, gen_loss = 1.1998426501567547, disc_loss = 0.0008465566262692356
Trained batch 26 in epoch 2, gen_loss = 1.200919676710058, disc_loss = 0.0008372322201332146
Trained batch 27 in epoch 2, gen_loss = 1.2029982592378343, disc_loss = 0.0008217746965653662
Trained batch 28 in epoch 2, gen_loss = 1.1959037842421696, disc_loss = 0.0008255824354348768
Trained batch 29 in epoch 2, gen_loss = 1.1902135074138642, disc_loss = 0.0008305709479221453
Trained batch 30 in epoch 2, gen_loss = 1.1885386570807426, disc_loss = 0.0008205350924042925
Trained batch 31 in epoch 2, gen_loss = 1.1863981541246176, disc_loss = 0.0008091348754533101
Trained batch 32 in epoch 2, gen_loss = 1.1894067146561362, disc_loss = 0.0007954462454301503
Trained batch 33 in epoch 2, gen_loss = 1.1917481930816876, disc_loss = 0.000779843915712691
Trained batch 34 in epoch 2, gen_loss = 1.1937682100704738, disc_loss = 0.000766164918396888
Trained batch 35 in epoch 2, gen_loss = 1.187499451968405, disc_loss = 0.0008702954146428965
Trained batch 36 in epoch 2, gen_loss = 1.1864570588678927, disc_loss = 0.0009830655880914245
Trained batch 37 in epoch 2, gen_loss = 1.1820100467456014, disc_loss = 0.0010258406791284582
Trained batch 38 in epoch 2, gen_loss = 1.1836260205660112, disc_loss = 0.0010340845813819517
Trained batch 39 in epoch 2, gen_loss = 1.1823661610484124, disc_loss = 0.001039160723303212
Trained batch 40 in epoch 2, gen_loss = 1.1791792977146986, disc_loss = 0.0010411182763452483
Trained batch 41 in epoch 2, gen_loss = 1.1798233262130193, disc_loss = 0.0010421058388947997
Trained batch 42 in epoch 2, gen_loss = 1.177236217398976, disc_loss = 0.001035901189234844
Trained batch 43 in epoch 2, gen_loss = 1.1770666959610852, disc_loss = 0.0010501373875409956
Trained batch 44 in epoch 2, gen_loss = 1.176387576262156, disc_loss = 0.0010664652974810452
Trained batch 45 in epoch 2, gen_loss = 1.1747417462908702, disc_loss = 0.0010671821193840435
Trained batch 46 in epoch 2, gen_loss = 1.1810974808449441, disc_loss = 0.00106090671776675
Trained batch 47 in epoch 2, gen_loss = 1.1793747209012508, disc_loss = 0.001051980603733682
Trained batch 48 in epoch 2, gen_loss = 1.1782767541554509, disc_loss = 0.0010483673237957896
Trained batch 49 in epoch 2, gen_loss = 1.1775453245639802, disc_loss = 0.0010411884932545945
Trained batch 50 in epoch 2, gen_loss = 1.1743007419156093, disc_loss = 0.0010335064046860982
Trained batch 51 in epoch 2, gen_loss = 1.1742414041207387, disc_loss = 0.0010288162946101064
Trained batch 52 in epoch 2, gen_loss = 1.1715551063699543, disc_loss = 0.001024737599951584
Trained batch 53 in epoch 2, gen_loss = 1.1692323872336634, disc_loss = 0.001017755920959947
Trained batch 54 in epoch 2, gen_loss = 1.1736193125898189, disc_loss = 0.0010208922919859602
Trained batch 55 in epoch 2, gen_loss = 1.1736072589244162, disc_loss = 0.0010226746625059085
Trained batch 56 in epoch 2, gen_loss = 1.1768783487771686, disc_loss = 0.0010143450186628719
Trained batch 57 in epoch 2, gen_loss = 1.1766355417925736, disc_loss = 0.001006588882240788
Trained batch 58 in epoch 2, gen_loss = 1.1782106555114358, disc_loss = 0.0009969348207281871
Trained batch 59 in epoch 2, gen_loss = 1.1808117121458053, disc_loss = 0.0009925457401550376
Trained batch 60 in epoch 2, gen_loss = 1.1810171574842734, disc_loss = 0.000990151625687684
Trained batch 61 in epoch 2, gen_loss = 1.186518564339607, disc_loss = 0.000987994424048661
Trained batch 62 in epoch 2, gen_loss = 1.1869585958738176, disc_loss = 0.0009830171174909329
Trained batch 63 in epoch 2, gen_loss = 1.1910879453644156, disc_loss = 0.000976675058609544
Trained batch 64 in epoch 2, gen_loss = 1.1926141399603623, disc_loss = 0.000982227584329219
Trained batch 65 in epoch 2, gen_loss = 1.192471958471067, disc_loss = 0.000985840350922169
Trained batch 66 in epoch 2, gen_loss = 1.1920262192612263, disc_loss = 0.0009944790660633026
Trained batch 67 in epoch 2, gen_loss = 1.1978586517712648, disc_loss = 0.0009947806534268346
Trained batch 68 in epoch 2, gen_loss = 1.1983792704084646, disc_loss = 0.0009886421793835589
Trained batch 69 in epoch 2, gen_loss = 1.1984734662941523, disc_loss = 0.000993347733830368
Trained batch 70 in epoch 2, gen_loss = 1.199448074253512, disc_loss = 0.0009890240588402506
Trained batch 71 in epoch 2, gen_loss = 1.198242173426681, disc_loss = 0.0009882814269480554
Trained batch 72 in epoch 2, gen_loss = 1.1999055481936833, disc_loss = 0.0009960091193621239
Trained batch 73 in epoch 2, gen_loss = 1.1990579197535645, disc_loss = 0.0009989238865642078
Trained batch 74 in epoch 2, gen_loss = 1.199272464911143, disc_loss = 0.0009986711056747784
Trained batch 75 in epoch 2, gen_loss = 1.1976308124630075, disc_loss = 0.000998076319918159
Trained batch 76 in epoch 2, gen_loss = 1.197140565940312, disc_loss = 0.0009968981071974017
Trained batch 77 in epoch 2, gen_loss = 1.199085071300849, disc_loss = 0.0009923765830582199
Trained batch 78 in epoch 2, gen_loss = 1.1983322938786278, disc_loss = 0.0009868459829830718
Trained batch 79 in epoch 2, gen_loss = 1.1979089610278606, disc_loss = 0.000981085980674834
Trained batch 80 in epoch 2, gen_loss = 1.1976899092580064, disc_loss = 0.0009758034322186615
Trained batch 81 in epoch 2, gen_loss = 1.1963979725430651, disc_loss = 0.0009766770303164178
Trained batch 82 in epoch 2, gen_loss = 1.1958536419523769, disc_loss = 0.0009800014215807643
Trained batch 83 in epoch 2, gen_loss = 1.195094183087349, disc_loss = 0.0009788427030019062
Trained batch 84 in epoch 2, gen_loss = 1.19348967145471, disc_loss = 0.0009781272023888852
Trained batch 85 in epoch 2, gen_loss = 1.194950057323589, disc_loss = 0.0009749124248290088
Trained batch 86 in epoch 2, gen_loss = 1.1950959618064179, disc_loss = 0.0009694329818212909
Trained batch 87 in epoch 2, gen_loss = 1.1953245868737048, disc_loss = 0.0009664093228242233
Trained batch 88 in epoch 2, gen_loss = 1.1980803113305167, disc_loss = 0.0009640667713744294
Trained batch 89 in epoch 2, gen_loss = 1.199820124440723, disc_loss = 0.0009613019495090056
Trained batch 90 in epoch 2, gen_loss = 1.199280008509919, disc_loss = 0.0009573633065523969
Trained batch 91 in epoch 2, gen_loss = 1.2023740883754648, disc_loss = 0.0009533167679404395
Trained batch 92 in epoch 2, gen_loss = 1.2020419855271616, disc_loss = 0.0009483777106143735
Trained batch 93 in epoch 2, gen_loss = 1.2056985770134216, disc_loss = 0.0009431727617567881
Trained batch 94 in epoch 2, gen_loss = 1.208953915771685, disc_loss = 0.0009376766739143549
Trained batch 95 in epoch 2, gen_loss = 1.211224519337217, disc_loss = 0.0009316986155075332
Trained batch 96 in epoch 2, gen_loss = 1.2115212893977607, disc_loss = 0.0009260933291762299
Trained batch 97 in epoch 2, gen_loss = 1.2128033181842492, disc_loss = 0.0009216637200941997
Trained batch 98 in epoch 2, gen_loss = 1.2146788251520408, disc_loss = 0.0009275422845449713
Trained batch 99 in epoch 2, gen_loss = 1.2128996294736862, disc_loss = 0.0009540091129019856
Trained batch 100 in epoch 2, gen_loss = 1.2139330754185667, disc_loss = 0.0009856624159925054
Trained batch 101 in epoch 2, gen_loss = 1.2167153422738992, disc_loss = 0.001005012859298172
Trained batch 102 in epoch 2, gen_loss = 1.217193432803293, disc_loss = 0.0010085118046138906
Trained batch 103 in epoch 2, gen_loss = 1.2170496772115047, disc_loss = 0.0010055199880018616
Trained batch 104 in epoch 2, gen_loss = 1.216591927551088, disc_loss = 0.0010027067741334792
Trained batch 105 in epoch 2, gen_loss = 1.2156496525935407, disc_loss = 0.001002432007500726
Trained batch 106 in epoch 2, gen_loss = 1.2146459834597936, disc_loss = 0.000998054467855352
Trained batch 107 in epoch 2, gen_loss = 1.2147159957223468, disc_loss = 0.0009946584986108872
Trained batch 108 in epoch 2, gen_loss = 1.2184169057312362, disc_loss = 0.0009921351260796121
Trained batch 109 in epoch 2, gen_loss = 1.2191367447376251, disc_loss = 0.0009875605131541801
Trained batch 110 in epoch 2, gen_loss = 1.2189320782283406, disc_loss = 0.0009845398615013707
Trained batch 111 in epoch 2, gen_loss = 1.2185503569032465, disc_loss = 0.000980557301123294
Trained batch 112 in epoch 2, gen_loss = 1.2185029461320522, disc_loss = 0.0009789071483661182
Trained batch 113 in epoch 2, gen_loss = 1.2201189247139714, disc_loss = 0.0009766221781702417
Trained batch 114 in epoch 2, gen_loss = 1.2197195908297662, disc_loss = 0.0009737995615148026
Trained batch 115 in epoch 2, gen_loss = 1.2208559939573551, disc_loss = 0.0009730761757337263
Trained batch 116 in epoch 2, gen_loss = 1.2213738000291026, disc_loss = 0.0009694906975476978
Trained batch 117 in epoch 2, gen_loss = 1.2206382988873175, disc_loss = 0.0009650429917925622
Trained batch 118 in epoch 2, gen_loss = 1.2209950830756116, disc_loss = 0.0009599609096033671
Trained batch 119 in epoch 2, gen_loss = 1.2213454857468604, disc_loss = 0.0009572244981730667
Trained batch 120 in epoch 2, gen_loss = 1.2211058607771377, disc_loss = 0.0009543891156223133
Trained batch 121 in epoch 2, gen_loss = 1.2231431237009704, disc_loss = 0.000949986915716703
Trained batch 122 in epoch 2, gen_loss = 1.222490837418936, disc_loss = 0.0009465842709850096
Trained batch 123 in epoch 2, gen_loss = 1.2218780935772005, disc_loss = 0.000944866944571972
Trained batch 124 in epoch 2, gen_loss = 1.2228181338310242, disc_loss = 0.0009413810775149614
Trained batch 125 in epoch 2, gen_loss = 1.2267266327426547, disc_loss = 0.0009367797800454325
Trained batch 126 in epoch 2, gen_loss = 1.2260715290317385, disc_loss = 0.0009331214058352267
Trained batch 127 in epoch 2, gen_loss = 1.2254133536480367, disc_loss = 0.0009314561507380859
Trained batch 128 in epoch 2, gen_loss = 1.2253151027731193, disc_loss = 0.0009271536778673068
Trained batch 129 in epoch 2, gen_loss = 1.22658388202007, disc_loss = 0.0009234960504377691
Trained batch 130 in epoch 2, gen_loss = 1.2267878487819934, disc_loss = 0.0009215614067049313
Trained batch 131 in epoch 2, gen_loss = 1.2263507359858714, disc_loss = 0.0009181369711189869
Trained batch 132 in epoch 2, gen_loss = 1.2258066391586362, disc_loss = 0.0009177231885881436
Trained batch 133 in epoch 2, gen_loss = 1.2261368316500934, disc_loss = 0.0009212810031412892
Trained batch 134 in epoch 2, gen_loss = 1.2257640498655813, disc_loss = 0.0009255076092409177
Trained batch 135 in epoch 2, gen_loss = 1.2252085309694796, disc_loss = 0.0009245373724244179
Trained batch 136 in epoch 2, gen_loss = 1.2243581335910045, disc_loss = 0.0009250305888300803
Trained batch 137 in epoch 2, gen_loss = 1.2244403815787772, disc_loss = 0.0009241285284667316
Trained batch 138 in epoch 2, gen_loss = 1.223149419259682, disc_loss = 0.0009207337960289296
Trained batch 139 in epoch 2, gen_loss = 1.223841980099678, disc_loss = 0.0009187021132675
Trained batch 140 in epoch 2, gen_loss = 1.223132719807591, disc_loss = 0.0009175479069025197
Trained batch 141 in epoch 2, gen_loss = 1.2250474981019195, disc_loss = 0.0009186351116382661
Trained batch 142 in epoch 2, gen_loss = 1.224280457813423, disc_loss = 0.0009221682633139792
Trained batch 143 in epoch 2, gen_loss = 1.2270244124035041, disc_loss = 0.0009256590963357465
Trained batch 144 in epoch 2, gen_loss = 1.2270557350125806, disc_loss = 0.0009296348248206978
Trained batch 145 in epoch 2, gen_loss = 1.2263932828217337, disc_loss = 0.0009295930541742414
Trained batch 146 in epoch 2, gen_loss = 1.225231448403832, disc_loss = 0.0009266743323604139
Trained batch 147 in epoch 2, gen_loss = 1.2263388371950872, disc_loss = 0.0009246038670598127
Trained batch 148 in epoch 2, gen_loss = 1.2252001390361147, disc_loss = 0.0009228022721824205
Trained batch 149 in epoch 2, gen_loss = 1.2249381188551585, disc_loss = 0.0009262888636051988
Trained batch 150 in epoch 2, gen_loss = 1.2259695873355234, disc_loss = 0.0009318563448410136
Trained batch 151 in epoch 2, gen_loss = 1.2263509737033593, disc_loss = 0.0009317367893297495
Trained batch 152 in epoch 2, gen_loss = 1.225637098932578, disc_loss = 0.0009291855086879866
Trained batch 153 in epoch 2, gen_loss = 1.2258923731066964, disc_loss = 0.0009258477907029114
Trained batch 154 in epoch 2, gen_loss = 1.226064460123739, disc_loss = 0.0009228697936651447
Trained batch 155 in epoch 2, gen_loss = 1.2264312975681746, disc_loss = 0.0009216138871404558
Trained batch 156 in epoch 2, gen_loss = 1.2258463828427018, disc_loss = 0.0009199449926715605
Trained batch 157 in epoch 2, gen_loss = 1.2262903976289532, disc_loss = 0.0009181316167593616
Trained batch 158 in epoch 2, gen_loss = 1.2259645788174756, disc_loss = 0.0009161920097082526
Trained batch 159 in epoch 2, gen_loss = 1.225352930650115, disc_loss = 0.0009130192378506763
Trained batch 160 in epoch 2, gen_loss = 1.2246790009996165, disc_loss = 0.0009098876804917449
Trained batch 161 in epoch 2, gen_loss = 1.2237409047874404, disc_loss = 0.0009081634868189324
Trained batch 162 in epoch 2, gen_loss = 1.2225554709785555, disc_loss = 0.0009094759824748602
Trained batch 163 in epoch 2, gen_loss = 1.2221262603998184, disc_loss = 0.0009160492180210607
Trained batch 164 in epoch 2, gen_loss = 1.2218377268675602, disc_loss = 0.0009182918294699807
Trained batch 165 in epoch 2, gen_loss = 1.2222447571266128, disc_loss = 0.0009175347857154816
Trained batch 166 in epoch 2, gen_loss = 1.221974264004987, disc_loss = 0.0009162707845429461
Trained batch 167 in epoch 2, gen_loss = 1.2210441930663019, disc_loss = 0.0009144847600033419
Trained batch 168 in epoch 2, gen_loss = 1.2223511916645886, disc_loss = 0.0009117497624788081
Trained batch 169 in epoch 2, gen_loss = 1.2221108061425827, disc_loss = 0.0009103226110763738
Trained batch 170 in epoch 2, gen_loss = 1.2227975781898053, disc_loss = 0.0009074246169446439
Trained batch 171 in epoch 2, gen_loss = 1.2217920301265495, disc_loss = 0.0009052461180037299
Trained batch 172 in epoch 2, gen_loss = 1.2219817869236014, disc_loss = 0.0009036525766664007
Trained batch 173 in epoch 2, gen_loss = 1.2213445233887639, disc_loss = 0.0009010027463135749
Trained batch 174 in epoch 2, gen_loss = 1.2216811210768563, disc_loss = 0.000897734228554847
Trained batch 175 in epoch 2, gen_loss = 1.2212650413540276, disc_loss = 0.000894862267159624
Trained batch 176 in epoch 2, gen_loss = 1.2205216005697088, disc_loss = 0.000891478911619686
Trained batch 177 in epoch 2, gen_loss = 1.2209153520257285, disc_loss = 0.0008888603026227858
Trained batch 178 in epoch 2, gen_loss = 1.2206915287332163, disc_loss = 0.0008880125962564587
Trained batch 179 in epoch 2, gen_loss = 1.2219216601716147, disc_loss = 0.0008884633284954664
Trained batch 180 in epoch 2, gen_loss = 1.2218676420206522, disc_loss = 0.0008889439122465784
Trained batch 181 in epoch 2, gen_loss = 1.220881204356204, disc_loss = 0.0008893247355085255
Trained batch 182 in epoch 2, gen_loss = 1.2211899519618092, disc_loss = 0.0008870998028184852
Trained batch 183 in epoch 2, gen_loss = 1.221142583243225, disc_loss = 0.0008879048652053588
Trained batch 184 in epoch 2, gen_loss = 1.221409723243198, disc_loss = 0.0008882034587283695
Trained batch 185 in epoch 2, gen_loss = 1.2210137155107272, disc_loss = 0.0008859101739857266
Trained batch 186 in epoch 2, gen_loss = 1.2204926297626393, disc_loss = 0.0008825805775303254
Trained batch 187 in epoch 2, gen_loss = 1.2208890727859862, disc_loss = 0.0008796067011141357
Trained batch 188 in epoch 2, gen_loss = 1.2205979978596722, disc_loss = 0.0008777958521417406
Trained batch 189 in epoch 2, gen_loss = 1.2204742183810786, disc_loss = 0.0008769259304053297
Trained batch 190 in epoch 2, gen_loss = 1.219957002482489, disc_loss = 0.0008751039182357685
Trained batch 191 in epoch 2, gen_loss = 1.2193968448167045, disc_loss = 0.0008729576068920627
Trained batch 192 in epoch 2, gen_loss = 1.2188679100318276, disc_loss = 0.0008700134020318022
Trained batch 193 in epoch 2, gen_loss = 1.2183760665741163, disc_loss = 0.0008669768848045988
Trained batch 194 in epoch 2, gen_loss = 1.2189004430404076, disc_loss = 0.0008643743307449115
Trained batch 195 in epoch 2, gen_loss = 1.2191617412834752, disc_loss = 0.0008616857195025956
Trained batch 196 in epoch 2, gen_loss = 1.2186123813469398, disc_loss = 0.0008605055284667477
Trained batch 197 in epoch 2, gen_loss = 1.2189907964431879, disc_loss = 0.0008586967152877325
Trained batch 198 in epoch 2, gen_loss = 1.218156436879431, disc_loss = 0.0008556346494433044
Trained batch 199 in epoch 2, gen_loss = 1.21808963149786, disc_loss = 0.0008542526513338089
Trained batch 200 in epoch 2, gen_loss = 1.2190020982898884, disc_loss = 0.0008536678158553012
Trained batch 201 in epoch 2, gen_loss = 1.2187246305517632, disc_loss = 0.0008512464874092084
Trained batch 202 in epoch 2, gen_loss = 1.2186265893170398, disc_loss = 0.0008501112828113763
Trained batch 203 in epoch 2, gen_loss = 1.2180291867139292, disc_loss = 0.0008493925837968823
Trained batch 204 in epoch 2, gen_loss = 1.2178848257878931, disc_loss = 0.00084717138500021
Trained batch 205 in epoch 2, gen_loss = 1.2174521027838143, disc_loss = 0.0008449345212248922
Trained batch 206 in epoch 2, gen_loss = 1.2174219362401733, disc_loss = 0.0008421759815675157
Trained batch 207 in epoch 2, gen_loss = 1.2165986955738985, disc_loss = 0.0008420891524740279
Trained batch 208 in epoch 2, gen_loss = 1.2164562641148362, disc_loss = 0.0008446335420458083
Trained batch 209 in epoch 2, gen_loss = 1.2151745855808258, disc_loss = 0.0008454919277158167
Trained batch 210 in epoch 2, gen_loss = 1.215100809578647, disc_loss = 0.0008436142907243981
Trained batch 211 in epoch 2, gen_loss = 1.2150055139132265, disc_loss = 0.0008411991397876574
Trained batch 212 in epoch 2, gen_loss = 1.2156241967084822, disc_loss = 0.0008394785886444589
Trained batch 213 in epoch 2, gen_loss = 1.2154387544805758, disc_loss = 0.0008389073872566658
Trained batch 214 in epoch 2, gen_loss = 1.2148535880931588, disc_loss = 0.0008378355998036906
Trained batch 215 in epoch 2, gen_loss = 1.2151830624099131, disc_loss = 0.0008371692880852303
Trained batch 216 in epoch 2, gen_loss = 1.2153451868465968, disc_loss = 0.0008353411587768487
Trained batch 217 in epoch 2, gen_loss = 1.214132402741581, disc_loss = 0.000834402451350422
Trained batch 218 in epoch 2, gen_loss = 1.2131776692660432, disc_loss = 0.0008766623026506389
Trained batch 219 in epoch 2, gen_loss = 1.214208933711052, disc_loss = 0.0009075878467146223
Trained batch 220 in epoch 2, gen_loss = 1.2143759163796093, disc_loss = 0.0009213644378803822
Trained batch 221 in epoch 2, gen_loss = 1.2141295373439789, disc_loss = 0.0009310005618383068
Trained batch 222 in epoch 2, gen_loss = 1.213351712900427, disc_loss = 0.0009341936858920088
Trained batch 223 in epoch 2, gen_loss = 1.2129936572164297, disc_loss = 0.0009379512774622916
Trained batch 224 in epoch 2, gen_loss = 1.2128639584117467, disc_loss = 0.000943259066876231
Trained batch 225 in epoch 2, gen_loss = 1.2124037059534967, disc_loss = 0.0009494860144280541
Trained batch 226 in epoch 2, gen_loss = 1.212205442825603, disc_loss = 0.0009610181660770894
Trained batch 227 in epoch 2, gen_loss = 1.2120940666972546, disc_loss = 0.0009734150114941018
Trained batch 228 in epoch 2, gen_loss = 1.2117141971942118, disc_loss = 0.0009798555446567023
Trained batch 229 in epoch 2, gen_loss = 1.2112153149169425, disc_loss = 0.000985446553955705
Trained batch 230 in epoch 2, gen_loss = 1.210619142303219, disc_loss = 0.0009888185245373984
Trained batch 231 in epoch 2, gen_loss = 1.2098280183714012, disc_loss = 0.0009907264083549622
Trained batch 232 in epoch 2, gen_loss = 1.2095791221688235, disc_loss = 0.0009931089648079574
Trained batch 233 in epoch 2, gen_loss = 1.2087471997126555, disc_loss = 0.0009941822031073065
Trained batch 234 in epoch 2, gen_loss = 1.2089350018095464, disc_loss = 0.0009950175062763168
Trained batch 235 in epoch 2, gen_loss = 1.210324610441418, disc_loss = 0.0009990026753827913
Trained batch 236 in epoch 2, gen_loss = 1.2113815538490875, disc_loss = 0.0010053557072390844
Trained batch 237 in epoch 2, gen_loss = 1.211387196759216, disc_loss = 0.0010082859661138593
Trained batch 238 in epoch 2, gen_loss = 1.2113679375608595, disc_loss = 0.00101062413059062
Trained batch 239 in epoch 2, gen_loss = 1.2120690194269022, disc_loss = 0.0010156419747848608
Trained batch 240 in epoch 2, gen_loss = 1.2146012973488614, disc_loss = 0.0010291373982003415
Trained batch 241 in epoch 2, gen_loss = 1.21713029870317, disc_loss = 0.0010430390545126621
Trained batch 242 in epoch 2, gen_loss = 1.2175613806080916, disc_loss = 0.0010460835248912175
Trained batch 243 in epoch 2, gen_loss = 1.21755244130971, disc_loss = 0.0010493865839470956
Trained batch 244 in epoch 2, gen_loss = 1.2178562410023748, disc_loss = 0.0010523420752605842
Trained batch 245 in epoch 2, gen_loss = 1.2179421310017748, disc_loss = 0.0010558890913020653
Trained batch 246 in epoch 2, gen_loss = 1.2176457443218, disc_loss = 0.0010572412664679666
Trained batch 247 in epoch 2, gen_loss = 1.2179619359873957, disc_loss = 0.0010565546022741228
Trained batch 248 in epoch 2, gen_loss = 1.217236340045929, disc_loss = 0.0010569245117598672
Trained batch 249 in epoch 2, gen_loss = 1.2167542421817779, disc_loss = 0.0010581162500893698
Trained batch 250 in epoch 2, gen_loss = 1.2165489659841318, disc_loss = 0.0010561706952563305
Trained batch 251 in epoch 2, gen_loss = 1.2177733464373484, disc_loss = 0.0010538374988264257
Trained batch 252 in epoch 2, gen_loss = 1.21803003738049, disc_loss = 0.0010510802266911305
Trained batch 253 in epoch 2, gen_loss = 1.2190394535308748, disc_loss = 0.0010482955429066839
Trained batch 254 in epoch 2, gen_loss = 1.2187890531970005, disc_loss = 0.0010463162006892482
Trained batch 255 in epoch 2, gen_loss = 1.2187114984262735, disc_loss = 0.0010455206430606268
Trained batch 256 in epoch 2, gen_loss = 1.2179509793274133, disc_loss = 0.0010449049333228226
Trained batch 257 in epoch 2, gen_loss = 1.2177069572977317, disc_loss = 0.0010434330842419809
Trained batch 258 in epoch 2, gen_loss = 1.2167210924119103, disc_loss = 0.001041872998718424
Trained batch 259 in epoch 2, gen_loss = 1.2168915496422694, disc_loss = 0.0010413272081328054
Trained batch 260 in epoch 2, gen_loss = 1.2171105155542892, disc_loss = 0.0010404046258034535
Trained batch 261 in epoch 2, gen_loss = 1.2167466219144922, disc_loss = 0.001038413637789599
Trained batch 262 in epoch 2, gen_loss = 1.216322999490078, disc_loss = 0.0010366442549341632
Trained batch 263 in epoch 2, gen_loss = 1.2156858891248703, disc_loss = 0.0010344586642697157
Trained batch 264 in epoch 2, gen_loss = 1.2159990405136685, disc_loss = 0.0010328472744594417
Trained batch 265 in epoch 2, gen_loss = 1.2155367265966601, disc_loss = 0.0010310912602607342
Trained batch 266 in epoch 2, gen_loss = 1.215372022171592, disc_loss = 0.0010290160970954218
Trained batch 267 in epoch 2, gen_loss = 1.215184129885773, disc_loss = 0.0010273155750647716
Trained batch 268 in epoch 2, gen_loss = 1.2146853492162484, disc_loss = 0.0010250458353394678
Trained batch 269 in epoch 2, gen_loss = 1.2141451191019128, disc_loss = 0.0010227354120514872
Trained batch 270 in epoch 2, gen_loss = 1.2133807757683785, disc_loss = 0.0010207922496863837
Trained batch 271 in epoch 2, gen_loss = 1.2127355429179527, disc_loss = 0.0010190248867729679
Trained batch 272 in epoch 2, gen_loss = 1.2128596816744124, disc_loss = 0.0010179457989872704
Trained batch 273 in epoch 2, gen_loss = 1.2123900456150083, disc_loss = 0.0010169062794893164
Trained batch 274 in epoch 2, gen_loss = 1.212076648798856, disc_loss = 0.0010153800274499438
Trained batch 275 in epoch 2, gen_loss = 1.2114913502465123, disc_loss = 0.0010161981736546031
Trained batch 276 in epoch 2, gen_loss = 1.211923356951359, disc_loss = 0.0010195648438878868
Trained batch 277 in epoch 2, gen_loss = 1.2118798884556448, disc_loss = 0.0010239615636080397
Trained batch 278 in epoch 2, gen_loss = 1.2129465478295494, disc_loss = 0.0010341813338847036
Trained batch 279 in epoch 2, gen_loss = 1.213038734453065, disc_loss = 0.0010514873370993882
Trained batch 280 in epoch 2, gen_loss = 1.2128732556550104, disc_loss = 0.0010591685760342035
Trained batch 281 in epoch 2, gen_loss = 1.2126464344930987, disc_loss = 0.0010592146439755217
Trained batch 282 in epoch 2, gen_loss = 1.2117633598432103, disc_loss = 0.0010590999623326183
Trained batch 283 in epoch 2, gen_loss = 1.2111542625746257, disc_loss = 0.0010581891758295275
Trained batch 284 in epoch 2, gen_loss = 1.2112866441408794, disc_loss = 0.0010570724509051887
Trained batch 285 in epoch 2, gen_loss = 1.210842970159504, disc_loss = 0.001062293102031808
Trained batch 286 in epoch 2, gen_loss = 1.2107151848513906, disc_loss = 0.0010693873542860697
Trained batch 287 in epoch 2, gen_loss = 1.2113545948846474, disc_loss = 0.001067853356289561
Trained batch 288 in epoch 2, gen_loss = 1.2116358814355, disc_loss = 0.0010687935947131199
Trained batch 289 in epoch 2, gen_loss = 1.2123212121683975, disc_loss = 0.0010781885909542826
Trained batch 290 in epoch 2, gen_loss = 1.2121545455300111, disc_loss = 0.0010884280468151613
Trained batch 291 in epoch 2, gen_loss = 1.2113235141724756, disc_loss = 0.0010895637509473663
Trained batch 292 in epoch 2, gen_loss = 1.2119671881402312, disc_loss = 0.001090750515217807
Trained batch 293 in epoch 2, gen_loss = 1.2128262878680716, disc_loss = 0.0010909538521656297
Trained batch 294 in epoch 2, gen_loss = 1.212339584908243, disc_loss = 0.0010897294572807092
Trained batch 295 in epoch 2, gen_loss = 1.212335378535696, disc_loss = 0.0010882793427004504
Trained batch 296 in epoch 2, gen_loss = 1.2124657299783494, disc_loss = 0.00108619475335836
Trained batch 297 in epoch 2, gen_loss = 1.212031171425877, disc_loss = 0.001085653654205919
Trained batch 298 in epoch 2, gen_loss = 1.2121625905451567, disc_loss = 0.001088989305194704
Trained batch 299 in epoch 2, gen_loss = 1.2134886846939723, disc_loss = 0.0010900160515060027
Trained batch 300 in epoch 2, gen_loss = 1.213621437549591, disc_loss = 0.001088242759723897
Trained batch 301 in epoch 2, gen_loss = 1.213523264949685, disc_loss = 0.0010865134320419208
Trained batch 302 in epoch 2, gen_loss = 1.2148566255868465, disc_loss = 0.001084986963484547
Trained batch 303 in epoch 2, gen_loss = 1.2146274504300796, disc_loss = 0.0010832442174815743
Trained batch 304 in epoch 2, gen_loss = 1.2148132560683078, disc_loss = 0.0010817500804627283
Trained batch 305 in epoch 2, gen_loss = 1.2145890018908807, disc_loss = 0.0010797211530753808
Trained batch 306 in epoch 2, gen_loss = 1.215291424566449, disc_loss = 0.0010778480439776015
Trained batch 307 in epoch 2, gen_loss = 1.2157270062666434, disc_loss = 0.0010755032956919197
Trained batch 308 in epoch 2, gen_loss = 1.2163594068061188, disc_loss = 0.0010727995362933003
Trained batch 309 in epoch 2, gen_loss = 1.2163714664597665, disc_loss = 0.001070447756548322
Trained batch 310 in epoch 2, gen_loss = 1.2169845382117, disc_loss = 0.0010683726986504827
Trained batch 311 in epoch 2, gen_loss = 1.216560080456428, disc_loss = 0.0010686791710889875
Trained batch 312 in epoch 2, gen_loss = 1.2164446635368151, disc_loss = 0.0010686237554693708
Trained batch 313 in epoch 2, gen_loss = 1.2160856034725336, disc_loss = 0.001069033394232511
Trained batch 314 in epoch 2, gen_loss = 1.2170516224134535, disc_loss = 0.0010684188486756905
Trained batch 315 in epoch 2, gen_loss = 1.2170809792189659, disc_loss = 0.0010680023466953065
Trained batch 316 in epoch 2, gen_loss = 1.2168458130457425, disc_loss = 0.0010672623424920068
Trained batch 317 in epoch 2, gen_loss = 1.2174969032500524, disc_loss = 0.0010650190060743007
Trained batch 318 in epoch 2, gen_loss = 1.2173616290092468, disc_loss = 0.0010675135679684615
Trained batch 319 in epoch 2, gen_loss = 1.2169326992705465, disc_loss = 0.0010706535221288505
Trained batch 320 in epoch 2, gen_loss = 1.2170416434234548, disc_loss = 0.0010697764316044249
Trained batch 321 in epoch 2, gen_loss = 1.2165059615736422, disc_loss = 0.0010681441746997757
Trained batch 322 in epoch 2, gen_loss = 1.2167205199737667, disc_loss = 0.0010658923924710291
Trained batch 323 in epoch 2, gen_loss = 1.2160485591049548, disc_loss = 0.0010648087552032881
Trained batch 324 in epoch 2, gen_loss = 1.2158955726256737, disc_loss = 0.0010630817748964406
Trained batch 325 in epoch 2, gen_loss = 1.2161352808124448, disc_loss = 0.0010623508034791067
Trained batch 326 in epoch 2, gen_loss = 1.215709110101064, disc_loss = 0.0010607384367054187
Trained batch 327 in epoch 2, gen_loss = 1.2152476250761892, disc_loss = 0.0010584926458250266
Trained batch 328 in epoch 2, gen_loss = 1.215667761386709, disc_loss = 0.0010568145774892252
Trained batch 329 in epoch 2, gen_loss = 1.2153381699865515, disc_loss = 0.0010544181504166883
Trained batch 330 in epoch 2, gen_loss = 1.2150512117993795, disc_loss = 0.0010519171627083642
Trained batch 331 in epoch 2, gen_loss = 1.2151635427431888, disc_loss = 0.0010494436147897672
Trained batch 332 in epoch 2, gen_loss = 1.2147067604480204, disc_loss = 0.001047614792308717
Trained batch 333 in epoch 2, gen_loss = 1.2138926056687704, disc_loss = 0.0010478245435996416
Trained batch 334 in epoch 2, gen_loss = 1.2135822198284205, disc_loss = 0.001049302696987097
Trained batch 335 in epoch 2, gen_loss = 1.2141084342840172, disc_loss = 0.0010512004110274748
Trained batch 336 in epoch 2, gen_loss = 1.2137107974697645, disc_loss = 0.0010531001367802436
Trained batch 337 in epoch 2, gen_loss = 1.213823953852851, disc_loss = 0.0010533180258639112
Trained batch 338 in epoch 2, gen_loss = 1.213403018702448, disc_loss = 0.0010524054733036321
Trained batch 339 in epoch 2, gen_loss = 1.2131330456803826, disc_loss = 0.001052094268037335
Trained batch 340 in epoch 2, gen_loss = 1.2131147274523537, disc_loss = 0.001051994814889784
Trained batch 341 in epoch 2, gen_loss = 1.2130597333113353, disc_loss = 0.0010510761544723825
Trained batch 342 in epoch 2, gen_loss = 1.213070113005513, disc_loss = 0.0010494792015283605
Trained batch 343 in epoch 2, gen_loss = 1.2124923670361207, disc_loss = 0.0010492631522221166
Trained batch 344 in epoch 2, gen_loss = 1.2121650103209676, disc_loss = 0.0010502174403855874
Trained batch 345 in epoch 2, gen_loss = 1.2116555004795162, disc_loss = 0.00105067257546669
Trained batch 346 in epoch 2, gen_loss = 1.211710909773362, disc_loss = 0.0010501627163808547
Trained batch 347 in epoch 2, gen_loss = 1.2111515003716808, disc_loss = 0.0010488024230674445
Trained batch 348 in epoch 2, gen_loss = 1.2105070470397314, disc_loss = 0.0010503381969377847
Trained batch 349 in epoch 2, gen_loss = 1.2101097554819924, disc_loss = 0.0010527916836352753
Trained batch 350 in epoch 2, gen_loss = 1.2108702603568378, disc_loss = 0.0010529368831590348
Trained batch 351 in epoch 2, gen_loss = 1.2106829141689972, disc_loss = 0.0010520702349326298
Trained batch 352 in epoch 2, gen_loss = 1.210293034487338, disc_loss = 0.0010511807534413639
Trained batch 353 in epoch 2, gen_loss = 1.2097373387571109, disc_loss = 0.0010507152044861498
Trained batch 354 in epoch 2, gen_loss = 1.210327116368522, disc_loss = 0.0010513420013422278
Trained batch 355 in epoch 2, gen_loss = 1.210127965955252, disc_loss = 0.0010513706666448813
Trained batch 356 in epoch 2, gen_loss = 1.2107544367720766, disc_loss = 0.0010508047739638626
Trained batch 357 in epoch 2, gen_loss = 1.2105490690170053, disc_loss = 0.0010500805065173698
Trained batch 358 in epoch 2, gen_loss = 1.2109188440782446, disc_loss = 0.0010489114133114498
Trained batch 359 in epoch 2, gen_loss = 1.2111088251074156, disc_loss = 0.0010473550939221038
Trained batch 360 in epoch 2, gen_loss = 1.2112984038125776, disc_loss = 0.0010451995861172222
Trained batch 361 in epoch 2, gen_loss = 1.2109360031330783, disc_loss = 0.0010434328067085567
Trained batch 362 in epoch 2, gen_loss = 1.211338353715324, disc_loss = 0.0010420394280140311
Trained batch 363 in epoch 2, gen_loss = 1.21092696586153, disc_loss = 0.0010403816835765451
Trained batch 364 in epoch 2, gen_loss = 1.2104577967565353, disc_loss = 0.0010392521217797105
Trained batch 365 in epoch 2, gen_loss = 1.2101643269505005, disc_loss = 0.0010389618634734853
Trained batch 366 in epoch 2, gen_loss = 1.2098919255532101, disc_loss = 0.0010386623955415486
Trained batch 367 in epoch 2, gen_loss = 1.2095995158281014, disc_loss = 0.001037403057600149
Trained batch 368 in epoch 2, gen_loss = 1.2092315105564873, disc_loss = 0.0010353131646443118
Trained batch 369 in epoch 2, gen_loss = 1.2087127023452038, disc_loss = 0.0010336359287140186
Trained batch 370 in epoch 2, gen_loss = 1.20867848476631, disc_loss = 0.0010322150127112493
Trained batch 371 in epoch 2, gen_loss = 1.2086949523097725, disc_loss = 0.0010312150860103898
Trained batch 372 in epoch 2, gen_loss = 1.2091853457225872, disc_loss = 0.0010302544797891776
Trained batch 373 in epoch 2, gen_loss = 1.2092387177408699, disc_loss = 0.001030769284654603
Trained batch 374 in epoch 2, gen_loss = 1.209017235914866, disc_loss = 0.0010317002499941736
Trained batch 375 in epoch 2, gen_loss = 1.209034911020005, disc_loss = 0.0010300523159032231
Trained batch 376 in epoch 2, gen_loss = 1.2087932519950664, disc_loss = 0.0010295073663573761
Trained batch 377 in epoch 2, gen_loss = 1.2085815663375552, disc_loss = 0.0010291253076127125
Trained batch 378 in epoch 2, gen_loss = 1.208442559185632, disc_loss = 0.0010274703797022997
Trained batch 379 in epoch 2, gen_loss = 1.2080935423311434, disc_loss = 0.0010258704180351312
Trained batch 380 in epoch 2, gen_loss = 1.2080642490249294, disc_loss = 0.0010246569368672946
Trained batch 381 in epoch 2, gen_loss = 1.2075803206541151, disc_loss = 0.0010231806196001753
Trained batch 382 in epoch 2, gen_loss = 1.2079292758326619, disc_loss = 0.0010225561361725858
Trained batch 383 in epoch 2, gen_loss = 1.207830498771121, disc_loss = 0.001023205830582204
Trained batch 384 in epoch 2, gen_loss = 1.2082754678540415, disc_loss = 0.0010237817979091173
Trained batch 385 in epoch 2, gen_loss = 1.2080059442186604, disc_loss = 0.0010227305331168494
Trained batch 386 in epoch 2, gen_loss = 1.2078885938154018, disc_loss = 0.0010212473601381984
Trained batch 387 in epoch 2, gen_loss = 1.20760071692393, disc_loss = 0.001019567174395335
Trained batch 388 in epoch 2, gen_loss = 1.2088390798679047, disc_loss = 0.0010198214202688332
Trained batch 389 in epoch 2, gen_loss = 1.2086251391814304, disc_loss = 0.001023014209782466
Trained batch 390 in epoch 2, gen_loss = 1.2084482864040853, disc_loss = 0.001027951987050569
Trained batch 391 in epoch 2, gen_loss = 1.208155298567548, disc_loss = 0.0010307865895625508
Trained batch 392 in epoch 2, gen_loss = 1.2077571488822083, disc_loss = 0.0010315094575044194
Trained batch 393 in epoch 2, gen_loss = 1.2074302681509008, disc_loss = 0.001031428595312261
Trained batch 394 in epoch 2, gen_loss = 1.2073595356337632, disc_loss = 0.0010300946034361384
Trained batch 395 in epoch 2, gen_loss = 1.2074335664510727, disc_loss = 0.0010286392244237541
Trained batch 396 in epoch 2, gen_loss = 1.2074264430579371, disc_loss = 0.001028391890643019
Trained batch 397 in epoch 2, gen_loss = 1.2068711053486445, disc_loss = 0.0010278291319351849
Trained batch 398 in epoch 2, gen_loss = 1.2063754320443423, disc_loss = 0.0010265791747849761
Trained batch 399 in epoch 2, gen_loss = 1.205808998197317, disc_loss = 0.00102596408163663
Trained batch 400 in epoch 2, gen_loss = 1.2059503943842842, disc_loss = 0.0010255462255739976
Trained batch 401 in epoch 2, gen_loss = 1.2066308839700708, disc_loss = 0.0010249646146265113
Trained batch 402 in epoch 2, gen_loss = 1.2064534450878872, disc_loss = 0.0010247822289375897
Trained batch 403 in epoch 2, gen_loss = 1.2065296466692839, disc_loss = 0.0010256778715653253
Trained batch 404 in epoch 2, gen_loss = 1.206476366519928, disc_loss = 0.0010257136884409888
Trained batch 405 in epoch 2, gen_loss = 1.2062556715728028, disc_loss = 0.001026037640025463
Trained batch 406 in epoch 2, gen_loss = 1.2061246227866602, disc_loss = 0.0010247281895543125
Trained batch 407 in epoch 2, gen_loss = 1.2062229626611167, disc_loss = 0.0010234737255457587
Trained batch 408 in epoch 2, gen_loss = 1.206359650657346, disc_loss = 0.0010224095186216343
Trained batch 409 in epoch 2, gen_loss = 1.2065328419208527, disc_loss = 0.0010211628836170748
Trained batch 410 in epoch 2, gen_loss = 1.206485244914563, disc_loss = 0.0010194824573724393
Trained batch 411 in epoch 2, gen_loss = 1.2063810549025398, disc_loss = 0.0010179149375316343
Trained batch 412 in epoch 2, gen_loss = 1.206392909510661, disc_loss = 0.0010165251527499118
Trained batch 413 in epoch 2, gen_loss = 1.2062071813765356, disc_loss = 0.0010151322086055983
Trained batch 414 in epoch 2, gen_loss = 1.2058758803160794, disc_loss = 0.001013452708945576
Trained batch 415 in epoch 2, gen_loss = 1.2058576077509384, disc_loss = 0.0010123535398284171
Trained batch 416 in epoch 2, gen_loss = 1.2060820423155951, disc_loss = 0.001012965291822262
Trained batch 417 in epoch 2, gen_loss = 1.206142736536464, disc_loss = 0.0010145391722189698
Trained batch 418 in epoch 2, gen_loss = 1.2057741338427141, disc_loss = 0.0010152956492240877
Trained batch 419 in epoch 2, gen_loss = 1.2058330582720893, disc_loss = 0.0010151024038870153
Trained batch 420 in epoch 2, gen_loss = 1.205847730687565, disc_loss = 0.0010149658167062244
Trained batch 421 in epoch 2, gen_loss = 1.2058851076245873, disc_loss = 0.0010147579083267723
Trained batch 422 in epoch 2, gen_loss = 1.205992736855861, disc_loss = 0.0010143687995921283
Trained batch 423 in epoch 2, gen_loss = 1.2055662897116732, disc_loss = 0.0010145472561422172
Trained batch 424 in epoch 2, gen_loss = 1.2059273227523355, disc_loss = 0.0010140228738515255
Trained batch 425 in epoch 2, gen_loss = 1.2055192328115025, disc_loss = 0.00101372277533019
Trained batch 426 in epoch 2, gen_loss = 1.2062097080139143, disc_loss = 0.0010133980252928334
Trained batch 427 in epoch 2, gen_loss = 1.2060395650495992, disc_loss = 0.0010129184661776907
Trained batch 428 in epoch 2, gen_loss = 1.2065269073128422, disc_loss = 0.0010125158290326646
Trained batch 429 in epoch 2, gen_loss = 1.2067880202171415, disc_loss = 0.0010117627462361354
Trained batch 430 in epoch 2, gen_loss = 1.206545912610959, disc_loss = 0.0010110130167583526
Trained batch 431 in epoch 2, gen_loss = 1.2065662999671918, disc_loss = 0.0010110700781364426
Trained batch 432 in epoch 2, gen_loss = 1.2061787690907098, disc_loss = 0.0010106917570170883
Trained batch 433 in epoch 2, gen_loss = 1.2063030288790777, disc_loss = 0.0010093120243942176
Trained batch 434 in epoch 2, gen_loss = 1.206016767024994, disc_loss = 0.0010079972664745333
Trained batch 435 in epoch 2, gen_loss = 1.2061915106456214, disc_loss = 0.0010068914728210343
Trained batch 436 in epoch 2, gen_loss = 1.2061491736831054, disc_loss = 0.0010063229179999725
Trained batch 437 in epoch 2, gen_loss = 1.206831368545419, disc_loss = 0.0010050768834022066
Trained batch 438 in epoch 2, gen_loss = 1.2067466264162086, disc_loss = 0.0010042772334013855
Trained batch 439 in epoch 2, gen_loss = 1.2066115982153198, disc_loss = 0.0010036793487167663
Trained batch 440 in epoch 2, gen_loss = 1.2065614763300976, disc_loss = 0.0010023912454637446
Trained batch 441 in epoch 2, gen_loss = 1.2069974308369926, disc_loss = 0.0010010391807344814
Trained batch 442 in epoch 2, gen_loss = 1.2070971973593563, disc_loss = 0.0009994611999968122
Trained batch 443 in epoch 2, gen_loss = 1.2068838156289883, disc_loss = 0.0009978718123281258
Trained batch 444 in epoch 2, gen_loss = 1.2071648245447137, disc_loss = 0.0009968367691695942
Trained batch 445 in epoch 2, gen_loss = 1.2072827651629, disc_loss = 0.0009956572969880523
Trained batch 446 in epoch 2, gen_loss = 1.2070820322239426, disc_loss = 0.000994352974042909
Trained batch 447 in epoch 2, gen_loss = 1.207211656895067, disc_loss = 0.0009932871032885618
Trained batch 448 in epoch 2, gen_loss = 1.2069292430888305, disc_loss = 0.0009922744899563997
Trained batch 449 in epoch 2, gen_loss = 1.2063495185640123, disc_loss = 0.0009915902206234428
Trained batch 450 in epoch 2, gen_loss = 1.2064772431972022, disc_loss = 0.0009925240828751684
Trained batch 451 in epoch 2, gen_loss = 1.2061301316835185, disc_loss = 0.0009935087218764238
Trained batch 452 in epoch 2, gen_loss = 1.205714790500026, disc_loss = 0.0009934682291485245
Trained batch 453 in epoch 2, gen_loss = 1.2054511232523142, disc_loss = 0.0009926490386048463
Trained batch 454 in epoch 2, gen_loss = 1.2054051684809255, disc_loss = 0.000991321582242253
Trained batch 455 in epoch 2, gen_loss = 1.2052919637215764, disc_loss = 0.0009898186959106713
Trained batch 456 in epoch 2, gen_loss = 1.2049676226839194, disc_loss = 0.0009886462705544067
Trained batch 457 in epoch 2, gen_loss = 1.2052123950037894, disc_loss = 0.0009877418831812307
Trained batch 458 in epoch 2, gen_loss = 1.2055121704384133, disc_loss = 0.0009866999419130109
Trained batch 459 in epoch 2, gen_loss = 1.2058498063813086, disc_loss = 0.0009863456855426825
Trained batch 460 in epoch 2, gen_loss = 1.2061713054743868, disc_loss = 0.0009864390766603666
Trained batch 461 in epoch 2, gen_loss = 1.2066783345106877, disc_loss = 0.0009864284067305845
Trained batch 462 in epoch 2, gen_loss = 1.2064287757770547, disc_loss = 0.0009863485489644062
Trained batch 463 in epoch 2, gen_loss = 1.2065557788672119, disc_loss = 0.0009862149190980587
Trained batch 464 in epoch 2, gen_loss = 1.2066034334962086, disc_loss = 0.0009855562853576835
Trained batch 465 in epoch 2, gen_loss = 1.2065967684651648, disc_loss = 0.0009845732932344735
Trained batch 466 in epoch 2, gen_loss = 1.206198130736259, disc_loss = 0.0009834995478709733
Trained batch 467 in epoch 2, gen_loss = 1.2057677252679808, disc_loss = 0.000982315158215252
Trained batch 468 in epoch 2, gen_loss = 1.2059516073035788, disc_loss = 0.0009811101203311735
Trained batch 469 in epoch 2, gen_loss = 1.2056252994435899, disc_loss = 0.0009804177924029609
Trained batch 470 in epoch 2, gen_loss = 1.2054242999184157, disc_loss = 0.000979633247870319
Trained batch 471 in epoch 2, gen_loss = 1.205034310787411, disc_loss = 0.0009789547644470725
Trained batch 472 in epoch 2, gen_loss = 1.205008984872201, disc_loss = 0.000978822169513353
Trained batch 473 in epoch 2, gen_loss = 1.2049820023246958, disc_loss = 0.0009800907049302547
Trained batch 474 in epoch 2, gen_loss = 1.205351393850226, disc_loss = 0.0009813730451768558
Trained batch 475 in epoch 2, gen_loss = 1.205289838444285, disc_loss = 0.000981892368236768
Trained batch 476 in epoch 2, gen_loss = 1.2059197728239015, disc_loss = 0.000982114325586972
Trained batch 477 in epoch 2, gen_loss = 1.206091211680089, disc_loss = 0.0009823429368282415
Trained batch 478 in epoch 2, gen_loss = 1.205873961986231, disc_loss = 0.0009813958120100698
Trained batch 479 in epoch 2, gen_loss = 1.2062190162638824, disc_loss = 0.0009804060429208525
Trained batch 480 in epoch 2, gen_loss = 1.206085783528191, disc_loss = 0.0009803551917444535
Trained batch 481 in epoch 2, gen_loss = 1.2062916315442793, disc_loss = 0.0009811340191901983
Trained batch 482 in epoch 2, gen_loss = 1.2060966469486307, disc_loss = 0.000982375887938916
Trained batch 483 in epoch 2, gen_loss = 1.2062353986846515, disc_loss = 0.0009835975852935414
Trained batch 484 in epoch 2, gen_loss = 1.205998556392709, disc_loss = 0.0009843507089133652
Trained batch 485 in epoch 2, gen_loss = 1.2061173430195562, disc_loss = 0.0009850040534482463
Trained batch 486 in epoch 2, gen_loss = 1.2062744394220122, disc_loss = 0.000984346736829682
Trained batch 487 in epoch 2, gen_loss = 1.2060794204962058, disc_loss = 0.0009833843874044671
Trained batch 488 in epoch 2, gen_loss = 1.2058370052427358, disc_loss = 0.0009829176375347214
Trained batch 489 in epoch 2, gen_loss = 1.2055440126633157, disc_loss = 0.00098318971529584
Trained batch 490 in epoch 2, gen_loss = 1.2052438698572443, disc_loss = 0.0009826862044839185
Trained batch 491 in epoch 2, gen_loss = 1.205267779468521, disc_loss = 0.0009816976737825397
Trained batch 492 in epoch 2, gen_loss = 1.2052732154757209, disc_loss = 0.0009804394085037675
Trained batch 493 in epoch 2, gen_loss = 1.2050760195322847, disc_loss = 0.000978972668618601
Trained batch 494 in epoch 2, gen_loss = 1.2053263919522064, disc_loss = 0.0009779859558241724
Trained batch 495 in epoch 2, gen_loss = 1.2053503978156275, disc_loss = 0.0009775947335935685
Trained batch 496 in epoch 2, gen_loss = 1.2054952694856425, disc_loss = 0.0009773203169564403
Trained batch 497 in epoch 2, gen_loss = 1.2054271638154026, disc_loss = 0.0009766680822098986
Trained batch 498 in epoch 2, gen_loss = 1.2053231808370006, disc_loss = 0.0009761820389223817
Trained batch 499 in epoch 2, gen_loss = 1.2049842178821564, disc_loss = 0.0009757684840005822
Trained batch 500 in epoch 2, gen_loss = 1.2046983458562763, disc_loss = 0.0009754859842243836
Trained batch 501 in epoch 2, gen_loss = 1.2049376036066457, disc_loss = 0.0009747124060805687
Trained batch 502 in epoch 2, gen_loss = 1.2048727195732163, disc_loss = 0.0009732989185382325
Trained batch 503 in epoch 2, gen_loss = 1.204796604693882, disc_loss = 0.0009723584504201195
Trained batch 504 in epoch 2, gen_loss = 1.2051220093623247, disc_loss = 0.0009717133883986217
Trained batch 505 in epoch 2, gen_loss = 1.205096215598668, disc_loss = 0.0009707276850410557
Trained batch 506 in epoch 2, gen_loss = 1.2046841112584523, disc_loss = 0.0009698195878234443
Trained batch 507 in epoch 2, gen_loss = 1.204501647179521, disc_loss = 0.000968513915092523
Trained batch 508 in epoch 2, gen_loss = 1.2043380418788707, disc_loss = 0.0009677846502505374
Trained batch 509 in epoch 2, gen_loss = 1.2043331176626917, disc_loss = 0.0009672019321371016
Trained batch 510 in epoch 2, gen_loss = 1.2041698176333582, disc_loss = 0.0009658414086348827
Trained batch 511 in epoch 2, gen_loss = 1.2041333944071084, disc_loss = 0.0009647738826288332
Trained batch 512 in epoch 2, gen_loss = 1.2038977134529842, disc_loss = 0.0009636967585895929
Trained batch 513 in epoch 2, gen_loss = 1.2041043156779694, disc_loss = 0.0009623335653228381
Trained batch 514 in epoch 2, gen_loss = 1.2045208924025008, disc_loss = 0.0009613993050399444
Trained batch 515 in epoch 2, gen_loss = 1.2046979011953338, disc_loss = 0.0009609085425681276
Trained batch 516 in epoch 2, gen_loss = 1.2049232546088775, disc_loss = 0.0009596184369719747
Trained batch 517 in epoch 2, gen_loss = 1.2048193464868318, disc_loss = 0.0009585934834178127
Trained batch 518 in epoch 2, gen_loss = 1.2043451550838344, disc_loss = 0.000958263158682924
Trained batch 519 in epoch 2, gen_loss = 1.2041932094555634, disc_loss = 0.0009578110046277288
Trained batch 520 in epoch 2, gen_loss = 1.2042172707888994, disc_loss = 0.0009572373128530968
Trained batch 521 in epoch 2, gen_loss = 1.2040977631035437, disc_loss = 0.0009573538089282561
Trained batch 522 in epoch 2, gen_loss = 1.2039959638114186, disc_loss = 0.0009570649886137875
Trained batch 523 in epoch 2, gen_loss = 1.2037632012640247, disc_loss = 0.0009562556008352429
Trained batch 524 in epoch 2, gen_loss = 1.2039174379621234, disc_loss = 0.0009559010159379492
Trained batch 525 in epoch 2, gen_loss = 1.204025230253604, disc_loss = 0.0009562210272267256
Trained batch 526 in epoch 2, gen_loss = 1.2042350205796042, disc_loss = 0.0009570097575822149
Trained batch 527 in epoch 2, gen_loss = 1.20420208731384, disc_loss = 0.0009579886897854246
Trained batch 528 in epoch 2, gen_loss = 1.2039468696302187, disc_loss = 0.0009579374991328278
Trained batch 529 in epoch 2, gen_loss = 1.2040718170831788, disc_loss = 0.0009570545360406439
Trained batch 530 in epoch 2, gen_loss = 1.20389486998039, disc_loss = 0.000956486668597763
Trained batch 531 in epoch 2, gen_loss = 1.2034521665340079, disc_loss = 0.0009569973517773862
Trained batch 532 in epoch 2, gen_loss = 1.2032402619635634, disc_loss = 0.0009575083585456887
Trained batch 533 in epoch 2, gen_loss = 1.203630686252751, disc_loss = 0.0009580032243450043
Trained batch 534 in epoch 2, gen_loss = 1.2036087557534192, disc_loss = 0.0009580437936624251
Trained batch 535 in epoch 2, gen_loss = 1.2035187900955997, disc_loss = 0.000957918035897249
Trained batch 536 in epoch 2, gen_loss = 1.2035183227262019, disc_loss = 0.0009580101381343038
Trained batch 537 in epoch 2, gen_loss = 1.2035183986323474, disc_loss = 0.0009577077810525319
Trained batch 538 in epoch 2, gen_loss = 1.2036085279178088, disc_loss = 0.0009567438420586474
Trained batch 539 in epoch 2, gen_loss = 1.203461433781518, disc_loss = 0.0009556804348701714
Trained batch 540 in epoch 2, gen_loss = 1.203703116356996, disc_loss = 0.0009544897142818367
Trained batch 541 in epoch 2, gen_loss = 1.203594117586903, disc_loss = 0.0009532151862977217
Trained batch 542 in epoch 2, gen_loss = 1.2033740459884728, disc_loss = 0.0009518938790728093
Trained batch 543 in epoch 2, gen_loss = 1.203255340895232, disc_loss = 0.0009509414259061005
Trained batch 544 in epoch 2, gen_loss = 1.2034761710998114, disc_loss = 0.0009503310192226851
Trained batch 545 in epoch 2, gen_loss = 1.20336605712171, disc_loss = 0.0009497499008447226
Trained batch 546 in epoch 2, gen_loss = 1.2038969714637213, disc_loss = 0.0009487544474684866
Trained batch 547 in epoch 2, gen_loss = 1.2037210762500763, disc_loss = 0.0009477246009080202
Trained batch 548 in epoch 2, gen_loss = 1.2034780234369857, disc_loss = 0.0009469613707488664
Trained batch 549 in epoch 2, gen_loss = 1.20325388063084, disc_loss = 0.0009465305006597191
Trained batch 550 in epoch 2, gen_loss = 1.2031713507785555, disc_loss = 0.0009462468385461468
Trained batch 551 in epoch 2, gen_loss = 1.2028435224640197, disc_loss = 0.0009461602720599014
Trained batch 552 in epoch 2, gen_loss = 1.2030245246766489, disc_loss = 0.0009464500298273917
Trained batch 553 in epoch 2, gen_loss = 1.2026263808945887, disc_loss = 0.0009463508297152992
Trained batch 554 in epoch 2, gen_loss = 1.2023667468680992, disc_loss = 0.0009463132227989132
Trained batch 555 in epoch 2, gen_loss = 1.202231321832259, disc_loss = 0.0009456118475603904
Trained batch 556 in epoch 2, gen_loss = 1.202097291364276, disc_loss = 0.0009447139399619422
Trained batch 557 in epoch 2, gen_loss = 1.2022972444479612, disc_loss = 0.0009439047488574219
Trained batch 558 in epoch 2, gen_loss = 1.2021018473534764, disc_loss = 0.000943082059728988
Trained batch 559 in epoch 2, gen_loss = 1.2022029570170811, disc_loss = 0.0009419397373546547
Trained batch 560 in epoch 2, gen_loss = 1.2019275713731898, disc_loss = 0.0009417346288651766
Trained batch 561 in epoch 2, gen_loss = 1.2016587197992725, disc_loss = 0.0009411886729340622
Trained batch 562 in epoch 2, gen_loss = 1.2015085161049879, disc_loss = 0.0009401177161486512
Trained batch 563 in epoch 2, gen_loss = 1.2011640921552131, disc_loss = 0.0009393201257388689
Trained batch 564 in epoch 2, gen_loss = 1.2011590421727274, disc_loss = 0.0009387203075498573
Trained batch 565 in epoch 2, gen_loss = 1.200966081855154, disc_loss = 0.0009381886977968119
Trained batch 566 in epoch 2, gen_loss = 1.200852702534388, disc_loss = 0.0009374306682473446
Trained batch 567 in epoch 2, gen_loss = 1.200455427064862, disc_loss = 0.0009380919652524516
Trained batch 568 in epoch 2, gen_loss = 1.2007871624246005, disc_loss = 0.0009394722289642277
Trained batch 569 in epoch 2, gen_loss = 1.2006911421031283, disc_loss = 0.0009399817835257731
Trained batch 570 in epoch 2, gen_loss = 1.2007290633255046, disc_loss = 0.000939650359596558
Trained batch 571 in epoch 2, gen_loss = 1.2006203677062388, disc_loss = 0.0009394780349762218
Trained batch 572 in epoch 2, gen_loss = 1.2002402644923011, disc_loss = 0.0009392845227702457
Trained batch 573 in epoch 2, gen_loss = 1.200088187273371, disc_loss = 0.0009387058592973381
Trained batch 574 in epoch 2, gen_loss = 1.199919832582059, disc_loss = 0.0009380003393364504
Trained batch 575 in epoch 2, gen_loss = 1.2001653738940756, disc_loss = 0.0009370384046229043
Trained batch 576 in epoch 2, gen_loss = 1.199787092167542, disc_loss = 0.0009363852435258093
Trained batch 577 in epoch 2, gen_loss = 1.1996082104613623, disc_loss = 0.0009353799932953744
Trained batch 578 in epoch 2, gen_loss = 1.200031608909317, disc_loss = 0.0009348490536824151
Trained batch 579 in epoch 2, gen_loss = 1.2004533864300826, disc_loss = 0.0009340902412077412
Trained batch 580 in epoch 2, gen_loss = 1.2004386976540806, disc_loss = 0.0009332852932606886
Trained batch 581 in epoch 2, gen_loss = 1.2000953372811125, disc_loss = 0.0009325363917701919
Trained batch 582 in epoch 2, gen_loss = 1.1999485619481187, disc_loss = 0.000931956272234415
Trained batch 583 in epoch 2, gen_loss = 1.1997662974547034, disc_loss = 0.0009313449672222367
Trained batch 584 in epoch 2, gen_loss = 1.1995396214672642, disc_loss = 0.0009304703289392189
Trained batch 585 in epoch 2, gen_loss = 1.1995256950017128, disc_loss = 0.0009298878483996335
Trained batch 586 in epoch 2, gen_loss = 1.1993973671476115, disc_loss = 0.0009301415981436894
Trained batch 587 in epoch 2, gen_loss = 1.1998398991263644, disc_loss = 0.0009306556512827377
Trained batch 588 in epoch 2, gen_loss = 1.2003503280908425, disc_loss = 0.0009303733962726366
Trained batch 589 in epoch 2, gen_loss = 1.200446672560805, disc_loss = 0.0009297328092003936
Trained batch 590 in epoch 2, gen_loss = 1.2004062808709701, disc_loss = 0.0009293580804884515
Trained batch 591 in epoch 2, gen_loss = 1.1999944615605715, disc_loss = 0.0009300289237561063
Trained batch 592 in epoch 2, gen_loss = 1.2000255755590146, disc_loss = 0.0009299894156500628
Trained batch 593 in epoch 2, gen_loss = 1.2001561337849909, disc_loss = 0.0009293493028179043
Trained batch 594 in epoch 2, gen_loss = 1.2001976323728802, disc_loss = 0.0009284562645030028
Trained batch 595 in epoch 2, gen_loss = 1.2002476949819783, disc_loss = 0.0009276225820403302
Trained batch 596 in epoch 2, gen_loss = 1.1999991011978992, disc_loss = 0.0009269961840890417
Trained batch 597 in epoch 2, gen_loss = 1.1997525004240184, disc_loss = 0.0009263145420906666
Trained batch 598 in epoch 2, gen_loss = 1.199788965446523, disc_loss = 0.0009258558069653529
Trained batch 599 in epoch 2, gen_loss = 1.2001607968409855, disc_loss = 0.000926259256132956
Trained batch 600 in epoch 2, gen_loss = 1.2000771459446176, disc_loss = 0.0009275597031363836
Trained batch 601 in epoch 2, gen_loss = 1.199822564457738, disc_loss = 0.0009279289680546261
Trained batch 602 in epoch 2, gen_loss = 1.1996600817685104, disc_loss = 0.0009277138954501871
Trained batch 603 in epoch 2, gen_loss = 1.199680898363227, disc_loss = 0.0009290031982845602
Trained batch 604 in epoch 2, gen_loss = 1.1995706696155644, disc_loss = 0.0009328591680127265
Trained batch 605 in epoch 2, gen_loss = 1.2002361241740362, disc_loss = 0.0009360246256277389
Trained batch 606 in epoch 2, gen_loss = 1.2000913568933478, disc_loss = 0.0009394210301162414
Trained batch 607 in epoch 2, gen_loss = 1.19990893884709, disc_loss = 0.0009423247378148709
Trained batch 608 in epoch 2, gen_loss = 1.1999257503471938, disc_loss = 0.0009437291023198344
Trained batch 609 in epoch 2, gen_loss = 1.200251464570155, disc_loss = 0.0009439829164890756
Trained batch 610 in epoch 2, gen_loss = 1.2001601785372595, disc_loss = 0.0009440200740289333
Trained batch 611 in epoch 2, gen_loss = 1.2000238712317024, disc_loss = 0.0009445406432705627
Trained batch 612 in epoch 2, gen_loss = 1.2000442212401945, disc_loss = 0.0009442770891715765
Trained batch 613 in epoch 2, gen_loss = 1.2002401814010322, disc_loss = 0.0009442010571810808
Trained batch 614 in epoch 2, gen_loss = 1.2000990867614747, disc_loss = 0.0009447465639852926
Trained batch 615 in epoch 2, gen_loss = 1.1999849173929784, disc_loss = 0.0009446366169537545
Trained batch 616 in epoch 2, gen_loss = 1.20003100384383, disc_loss = 0.0009440854360176646
Trained batch 617 in epoch 2, gen_loss = 1.1998277167672093, disc_loss = 0.0009442985214275672
Trained batch 618 in epoch 2, gen_loss = 1.200000154952818, disc_loss = 0.0009436034667512526
Trained batch 619 in epoch 2, gen_loss = 1.1998250478698362, disc_loss = 0.0009431435607820599
Trained batch 620 in epoch 2, gen_loss = 1.2001523366872815, disc_loss = 0.0009434515903812598
Trained batch 621 in epoch 2, gen_loss = 1.2002113532406724, disc_loss = 0.0009432393564618794
Trained batch 622 in epoch 2, gen_loss = 1.2003352686069175, disc_loss = 0.0009425903495679943
Trained batch 623 in epoch 2, gen_loss = 1.2003154515838013, disc_loss = 0.0009416737288213484
Trained batch 624 in epoch 2, gen_loss = 1.200434776878357, disc_loss = 0.0009406557431910187
Trained batch 625 in epoch 2, gen_loss = 1.200576571610789, disc_loss = 0.0009403078556570341
Trained batch 626 in epoch 2, gen_loss = 1.2005455033820973, disc_loss = 0.0009402121715503856
Trained batch 627 in epoch 2, gen_loss = 1.2002030248474922, disc_loss = 0.000939266777912134
Trained batch 628 in epoch 2, gen_loss = 1.2000047510492782, disc_loss = 0.000938836668052789
Trained batch 629 in epoch 2, gen_loss = 1.1997846484184265, disc_loss = 0.0009392971729597314
Trained batch 630 in epoch 2, gen_loss = 1.1999057705164333, disc_loss = 0.0009400760642863167
Trained batch 631 in epoch 2, gen_loss = 1.2003044337034225, disc_loss = 0.0009409356650935421
Trained batch 632 in epoch 2, gen_loss = 1.2004542514611194, disc_loss = 0.0009416080927156283
Trained batch 633 in epoch 2, gen_loss = 1.2002654955590184, disc_loss = 0.0009429908515198732
Trained batch 634 in epoch 2, gen_loss = 1.2000306831570122, disc_loss = 0.0009444420664538226
Trained batch 635 in epoch 2, gen_loss = 1.199584681657875, disc_loss = 0.0009447935309774337
Trained batch 636 in epoch 2, gen_loss = 1.19946328062839, disc_loss = 0.0009446101639367892
Trained batch 637 in epoch 2, gen_loss = 1.1993124712970937, disc_loss = 0.0009438576575731392
Trained batch 638 in epoch 2, gen_loss = 1.19906506627938, disc_loss = 0.0009432792586055096
Trained batch 639 in epoch 2, gen_loss = 1.1991331476718188, disc_loss = 0.0009434553614937613
Trained batch 640 in epoch 2, gen_loss = 1.1989090022356388, disc_loss = 0.0009430772905051273
Trained batch 641 in epoch 2, gen_loss = 1.1991534849564978, disc_loss = 0.0009423544398484305
Trained batch 642 in epoch 2, gen_loss = 1.1994332961309382, disc_loss = 0.0009425273272831682
Trained batch 643 in epoch 2, gen_loss = 1.1993806954496395, disc_loss = 0.0009423538760292222
Trained batch 644 in epoch 2, gen_loss = 1.1997698268225028, disc_loss = 0.0009421444257049886
Trained batch 645 in epoch 2, gen_loss = 1.1996831133638741, disc_loss = 0.0009417949272672885
Trained batch 646 in epoch 2, gen_loss = 1.1999206049180657, disc_loss = 0.0009411767023828578
Trained batch 647 in epoch 2, gen_loss = 1.200064660406407, disc_loss = 0.000940373494184898
Trained batch 648 in epoch 2, gen_loss = 1.2001142371417195, disc_loss = 0.0009397994601332765
Trained batch 649 in epoch 2, gen_loss = 1.2002556710976822, disc_loss = 0.0009396257713580361
Trained batch 650 in epoch 2, gen_loss = 1.2000535790638258, disc_loss = 0.0009395462829553838
Trained batch 651 in epoch 2, gen_loss = 1.200023880765482, disc_loss = 0.0009399613248044339
Trained batch 652 in epoch 2, gen_loss = 1.2000763018317464, disc_loss = 0.0009400843188757074
Trained batch 653 in epoch 2, gen_loss = 1.2004296621051402, disc_loss = 0.0009397685472441934
Trained batch 654 in epoch 2, gen_loss = 1.2003880979450605, disc_loss = 0.0009389522115305379
Trained batch 655 in epoch 2, gen_loss = 1.2003300155444843, disc_loss = 0.0009380194139627814
Trained batch 656 in epoch 2, gen_loss = 1.2000977080343702, disc_loss = 0.0009370857726214127
Trained batch 657 in epoch 2, gen_loss = 1.2005518470129344, disc_loss = 0.0009364413187200753
Trained batch 658 in epoch 2, gen_loss = 1.2003448762010913, disc_loss = 0.0009361852944562881
Trained batch 659 in epoch 2, gen_loss = 1.2003295441468558, disc_loss = 0.0009359473053006116
Trained batch 660 in epoch 2, gen_loss = 1.200366661696499, disc_loss = 0.0009354121853426978
Trained batch 661 in epoch 2, gen_loss = 1.200582600792369, disc_loss = 0.0009347424934564716
Trained batch 662 in epoch 2, gen_loss = 1.2007402052167315, disc_loss = 0.0009347235295446772
Trained batch 663 in epoch 2, gen_loss = 1.200598917991282, disc_loss = 0.0009352597656957132
Trained batch 664 in epoch 2, gen_loss = 1.2003922847876871, disc_loss = 0.0009359372641429081
Trained batch 665 in epoch 2, gen_loss = 1.2002072633207739, disc_loss = 0.0009359806938084295
Trained batch 666 in epoch 2, gen_loss = 1.2000635840903515, disc_loss = 0.0009360220296360061
Trained batch 667 in epoch 2, gen_loss = 1.1997016787885906, disc_loss = 0.0009369306554034921
Trained batch 668 in epoch 2, gen_loss = 1.1998995442739695, disc_loss = 0.0009376759320164798
Trained batch 669 in epoch 2, gen_loss = 1.1998226290318503, disc_loss = 0.0009376082751802655
Trained batch 670 in epoch 2, gen_loss = 1.199714388826032, disc_loss = 0.0009375568539155411
Trained batch 671 in epoch 2, gen_loss = 1.1998634836858226, disc_loss = 0.0009375290160928021
Trained batch 672 in epoch 2, gen_loss = 1.1997932007904393, disc_loss = 0.000937372161422124
Trained batch 673 in epoch 2, gen_loss = 1.1997510921707493, disc_loss = 0.000937166056203316
Trained batch 674 in epoch 2, gen_loss = 1.199651116265191, disc_loss = 0.0009370213526266592
Trained batch 675 in epoch 2, gen_loss = 1.1998782866805262, disc_loss = 0.0009364992657059131
Trained batch 676 in epoch 2, gen_loss = 1.1997093442976035, disc_loss = 0.0009356651064304242
Trained batch 677 in epoch 2, gen_loss = 1.199690771665545, disc_loss = 0.0009351110712221239
Trained batch 678 in epoch 2, gen_loss = 1.199503364197811, disc_loss = 0.0009349115133396623
Trained batch 679 in epoch 2, gen_loss = 1.199192213310915, disc_loss = 0.0009352006200488712
Trained batch 680 in epoch 2, gen_loss = 1.1991477364485483, disc_loss = 0.0009369628382374898
Trained batch 681 in epoch 2, gen_loss = 1.1992164932388014, disc_loss = 0.0009396138398387794
Trained batch 682 in epoch 2, gen_loss = 1.1994035071195654, disc_loss = 0.0009406915870781491
Trained batch 683 in epoch 2, gen_loss = 1.1992394437915401, disc_loss = 0.0009407655257501568
Trained batch 684 in epoch 2, gen_loss = 1.1990088471530997, disc_loss = 0.0009404061130166434
Trained batch 685 in epoch 2, gen_loss = 1.1993136313844353, disc_loss = 0.0009398142506474352
Trained batch 686 in epoch 2, gen_loss = 1.1989263414121958, disc_loss = 0.000939120718747719
Trained batch 687 in epoch 2, gen_loss = 1.198963962495327, disc_loss = 0.0009384228375237462
Trained batch 688 in epoch 2, gen_loss = 1.1989193189299852, disc_loss = 0.0009379762659340702
Trained batch 689 in epoch 2, gen_loss = 1.198899777903073, disc_loss = 0.0009382250600248116
Trained batch 690 in epoch 2, gen_loss = 1.19909395081262, disc_loss = 0.000938225220934341
Trained batch 691 in epoch 2, gen_loss = 1.1993379544660536, disc_loss = 0.000937800988061367
Trained batch 692 in epoch 2, gen_loss = 1.1990648822866994, disc_loss = 0.0009373583286025656
Trained batch 693 in epoch 2, gen_loss = 1.1988697728780917, disc_loss = 0.0009368705554105079
Trained batch 694 in epoch 2, gen_loss = 1.1993353226201997, disc_loss = 0.0009359920907869479
Trained batch 695 in epoch 2, gen_loss = 1.1993748004409088, disc_loss = 0.0009353349367762118
Trained batch 696 in epoch 2, gen_loss = 1.199276179973159, disc_loss = 0.0009345913105367027
Trained batch 697 in epoch 2, gen_loss = 1.1991269532110767, disc_loss = 0.0009338894210916605
Trained batch 698 in epoch 2, gen_loss = 1.199257750197371, disc_loss = 0.000934454564010799
Trained batch 699 in epoch 2, gen_loss = 1.1991053542069026, disc_loss = 0.0009352953230180512
Trained batch 700 in epoch 2, gen_loss = 1.1988840081042127, disc_loss = 0.000935374643594178
Trained batch 701 in epoch 2, gen_loss = 1.1987118955351348, disc_loss = 0.0009349021667026201
Trained batch 702 in epoch 2, gen_loss = 1.1987536814948743, disc_loss = 0.0009342966391191623
Trained batch 703 in epoch 2, gen_loss = 1.198630058968609, disc_loss = 0.0009340698643014052
Trained batch 704 in epoch 2, gen_loss = 1.1985670799904682, disc_loss = 0.0009356089001141673
Trained batch 705 in epoch 2, gen_loss = 1.1985588203746267, disc_loss = 0.0009386433322175878
Trained batch 706 in epoch 2, gen_loss = 1.198372511243213, disc_loss = 0.000942077224784698
Trained batch 707 in epoch 2, gen_loss = 1.1981480049211426, disc_loss = 0.0009443230871824774
Trained batch 708 in epoch 2, gen_loss = 1.1979527730699655, disc_loss = 0.0009465221756407847
Trained batch 709 in epoch 2, gen_loss = 1.197781251182019, disc_loss = 0.0009481394514654645
Trained batch 710 in epoch 2, gen_loss = 1.1976338256092849, disc_loss = 0.0009487950796560736
Trained batch 711 in epoch 2, gen_loss = 1.197687150219853, disc_loss = 0.0009486256324665836
Trained batch 712 in epoch 2, gen_loss = 1.1977578209292503, disc_loss = 0.0009483864269598791
Trained batch 713 in epoch 2, gen_loss = 1.1977031945514411, disc_loss = 0.0009476397993924821
Trained batch 714 in epoch 2, gen_loss = 1.1974340815644164, disc_loss = 0.0009479796185021426
Trained batch 715 in epoch 2, gen_loss = 1.197290583196299, disc_loss = 0.000948207911237939
Trained batch 716 in epoch 2, gen_loss = 1.1971689337965834, disc_loss = 0.000947571326533626
Trained batch 717 in epoch 2, gen_loss = 1.1971898756319435, disc_loss = 0.0009476869182387486
Trained batch 718 in epoch 2, gen_loss = 1.1970307400893103, disc_loss = 0.0009475764869492091
Trained batch 719 in epoch 2, gen_loss = 1.1971623955501451, disc_loss = 0.000947265412671388
Trained batch 720 in epoch 2, gen_loss = 1.1971233570625315, disc_loss = 0.0009469367186222406
Trained batch 721 in epoch 2, gen_loss = 1.1975529317710538, disc_loss = 0.0009464277353600813
Trained batch 722 in epoch 2, gen_loss = 1.1974123607532612, disc_loss = 0.0009458574647873506
Trained batch 723 in epoch 2, gen_loss = 1.1973415815698507, disc_loss = 0.0009449292743708475
Trained batch 724 in epoch 2, gen_loss = 1.1970178528489737, disc_loss = 0.0009440908446940112
Trained batch 725 in epoch 2, gen_loss = 1.19726963181141, disc_loss = 0.0009432359674423369
Trained batch 726 in epoch 2, gen_loss = 1.1977394191238215, disc_loss = 0.0009424727425450636
Trained batch 727 in epoch 2, gen_loss = 1.1976351163217, disc_loss = 0.0009417618093721103
Trained batch 728 in epoch 2, gen_loss = 1.197727990085042, disc_loss = 0.000941368541592446
Trained batch 729 in epoch 2, gen_loss = 1.1978898675474403, disc_loss = 0.0009411178561555834
Trained batch 730 in epoch 2, gen_loss = 1.1976671404779855, disc_loss = 0.000940408137578851
Trained batch 731 in epoch 2, gen_loss = 1.1979043646588352, disc_loss = 0.0009397337708718912
Trained batch 732 in epoch 2, gen_loss = 1.197558702258101, disc_loss = 0.0009388754412399715
Trained batch 733 in epoch 2, gen_loss = 1.1976208962926422, disc_loss = 0.000938088985855313
Trained batch 734 in epoch 2, gen_loss = 1.1976322018370336, disc_loss = 0.0009375101123258573
Trained batch 735 in epoch 2, gen_loss = 1.1980880553955617, disc_loss = 0.000937070863864906
Trained batch 736 in epoch 2, gen_loss = 1.1978172929995419, disc_loss = 0.0009373480948023094
Trained batch 737 in epoch 2, gen_loss = 1.1976611879944479, disc_loss = 0.0009392139325669252
Trained batch 738 in epoch 2, gen_loss = 1.1974139533765584, disc_loss = 0.0009412204411797004
Trained batch 739 in epoch 2, gen_loss = 1.1975028011444453, disc_loss = 0.000942372192386412
Trained batch 740 in epoch 2, gen_loss = 1.1975819778989363, disc_loss = 0.0009424775879228093
Trained batch 741 in epoch 2, gen_loss = 1.1978229069806174, disc_loss = 0.0009416956427843483
Trained batch 742 in epoch 2, gen_loss = 1.197426200314133, disc_loss = 0.0009435004961124119
Trained batch 743 in epoch 2, gen_loss = 1.1974711672112506, disc_loss = 0.0009472662038783172
Trained batch 744 in epoch 2, gen_loss = 1.1974818036860269, disc_loss = 0.0009499873386245946
Trained batch 745 in epoch 2, gen_loss = 1.197290339594552, disc_loss = 0.0009520368879328884
Trained batch 746 in epoch 2, gen_loss = 1.1971907057915347, disc_loss = 0.0009526551239519135
Trained batch 747 in epoch 2, gen_loss = 1.1975321636639815, disc_loss = 0.0009521386688226525
Trained batch 748 in epoch 2, gen_loss = 1.1974713421154404, disc_loss = 0.0009517669582923499
Trained batch 749 in epoch 2, gen_loss = 1.1973212818304697, disc_loss = 0.0009531981701341768
Trained batch 750 in epoch 2, gen_loss = 1.1972620214984198, disc_loss = 0.0009554559698194444
Trained batch 751 in epoch 2, gen_loss = 1.197324286829284, disc_loss = 0.000956620501962421
Trained batch 752 in epoch 2, gen_loss = 1.1973804796676077, disc_loss = 0.0009567974131260003
Trained batch 753 in epoch 2, gen_loss = 1.197312152591245, disc_loss = 0.0009564506678980348
Trained batch 754 in epoch 2, gen_loss = 1.1976106717097048, disc_loss = 0.0009559970890289012
Trained batch 755 in epoch 2, gen_loss = 1.1976200311429916, disc_loss = 0.0009558179179236056
Trained batch 756 in epoch 2, gen_loss = 1.197576265590194, disc_loss = 0.0009557270450158294
Trained batch 757 in epoch 2, gen_loss = 1.1975695920965603, disc_loss = 0.0009554052495982468
Trained batch 758 in epoch 2, gen_loss = 1.1975830382666255, disc_loss = 0.0009548233391604189
Trained batch 759 in epoch 2, gen_loss = 1.197395084327773, disc_loss = 0.0009543852931145873
Trained batch 760 in epoch 2, gen_loss = 1.1976005387995465, disc_loss = 0.0009538344462168417
Trained batch 761 in epoch 2, gen_loss = 1.1972654076229556, disc_loss = 0.0009538989519917961
Trained batch 762 in epoch 2, gen_loss = 1.1973894905606541, disc_loss = 0.0009541982524878153
Trained batch 763 in epoch 2, gen_loss = 1.1971496144670466, disc_loss = 0.0009545455490182891
Trained batch 764 in epoch 2, gen_loss = 1.1973622880729975, disc_loss = 0.0009544452862339277
Trained batch 765 in epoch 2, gen_loss = 1.1974608587689561, disc_loss = 0.0009541639458757701
Trained batch 766 in epoch 2, gen_loss = 1.1973238884237007, disc_loss = 0.0009539742380953752
Trained batch 767 in epoch 2, gen_loss = 1.1971715416293591, disc_loss = 0.0009533113420350977
Trained batch 768 in epoch 2, gen_loss = 1.1971647268929004, disc_loss = 0.0009526378223148716
Trained batch 769 in epoch 2, gen_loss = 1.1970774753527207, disc_loss = 0.0009517892981598202
Trained batch 770 in epoch 2, gen_loss = 1.1969572028142779, disc_loss = 0.0009510405014369313
Trained batch 771 in epoch 2, gen_loss = 1.1968420012781658, disc_loss = 0.0009503518893212138
Trained batch 772 in epoch 2, gen_loss = 1.196756970913259, disc_loss = 0.0009495841962647387
Trained batch 773 in epoch 2, gen_loss = 1.1967654503131098, disc_loss = 0.0009492355674756113
Trained batch 774 in epoch 2, gen_loss = 1.1967221817662639, disc_loss = 0.0009487163216521543
Trained batch 775 in epoch 2, gen_loss = 1.19664673791411, disc_loss = 0.0009478032175841869
Trained batch 776 in epoch 2, gen_loss = 1.1963613380029547, disc_loss = 0.0009471186732582956
Trained batch 777 in epoch 2, gen_loss = 1.1961545125990722, disc_loss = 0.0009466484881652302
Trained batch 778 in epoch 2, gen_loss = 1.1962956497696766, disc_loss = 0.0009459072762428674
Trained batch 779 in epoch 2, gen_loss = 1.1961614914429493, disc_loss = 0.000945466628036229
Trained batch 780 in epoch 2, gen_loss = 1.1961101026449557, disc_loss = 0.0009458068133578975
Trained batch 781 in epoch 2, gen_loss = 1.1959219875238132, disc_loss = 0.0009472929462476376
Trained batch 782 in epoch 2, gen_loss = 1.1955731915331436, disc_loss = 0.0009493603464045013
Trained batch 783 in epoch 2, gen_loss = 1.1955396102703348, disc_loss = 0.0009504786410022406
Trained batch 784 in epoch 2, gen_loss = 1.195407290215705, disc_loss = 0.0009506966714238581
Trained batch 785 in epoch 2, gen_loss = 1.195382885805523, disc_loss = 0.0009506088104070894
Trained batch 786 in epoch 2, gen_loss = 1.195453167113143, disc_loss = 0.0009499396028089145
Trained batch 787 in epoch 2, gen_loss = 1.195381514312047, disc_loss = 0.0009493078473196921
Trained batch 789 in epoch 2, gen_loss = 1.194972960405712, disc_loss = 0.0009488613874676543
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 1.2650833129882812, disc_loss = 0.0019308817572891712
Trained batch 1 in epoch 3, gen_loss = 1.2302916646003723, disc_loss = 0.001842237077653408
Trained batch 2 in epoch 3, gen_loss = 1.210349400838216, disc_loss = 0.0015670110005885363
Trained batch 3 in epoch 3, gen_loss = 1.2217467427253723, disc_loss = 0.00133581088448409
Trained batch 4 in epoch 3, gen_loss = 1.1972097396850585, disc_loss = 0.0011716421111486852
Trained batch 5 in epoch 3, gen_loss = 1.202383538087209, disc_loss = 0.0010355203121434897
Trained batch 6 in epoch 3, gen_loss = 1.1845693247658866, disc_loss = 0.0009255105812501695
Trained batch 7 in epoch 3, gen_loss = 1.1867316514253616, disc_loss = 0.0008388159840251319
Trained batch 8 in epoch 3, gen_loss = 1.1950096156862047, disc_loss = 0.0007784561409304539
Trained batch 9 in epoch 3, gen_loss = 1.1905647277832032, disc_loss = 0.0007376632711384445
Trained batch 10 in epoch 3, gen_loss = 1.1841211210597644, disc_loss = 0.0007127640234433453
Trained batch 11 in epoch 3, gen_loss = 1.187994619210561, disc_loss = 0.0006865292258832293
Trained batch 12 in epoch 3, gen_loss = 1.195249392436101, disc_loss = 0.0006557152485654044
Trained batch 13 in epoch 3, gen_loss = 1.1944459336144584, disc_loss = 0.0006387660458650706
Trained batch 14 in epoch 3, gen_loss = 1.1873040676116944, disc_loss = 0.0006189592454272012
Trained batch 15 in epoch 3, gen_loss = 1.1765723526477814, disc_loss = 0.0005992324186081532
Trained batch 16 in epoch 3, gen_loss = 1.1820866640876322, disc_loss = 0.000582377499941846
Trained batch 17 in epoch 3, gen_loss = 1.1702821453412373, disc_loss = 0.0005854842133380265
Trained batch 18 in epoch 3, gen_loss = 1.164386040286014, disc_loss = 0.0005991648910199537
Trained batch 19 in epoch 3, gen_loss = 1.1618097305297852, disc_loss = 0.000594997599546332
Trained batch 20 in epoch 3, gen_loss = 1.1564024062383742, disc_loss = 0.0006089523764482389
Trained batch 21 in epoch 3, gen_loss = 1.1516708894209429, disc_loss = 0.0006138351891422644
Trained batch 22 in epoch 3, gen_loss = 1.1503165390180505, disc_loss = 0.0006060544844291618
Trained batch 23 in epoch 3, gen_loss = 1.1431535581747692, disc_loss = 0.0006139535095523266
Trained batch 24 in epoch 3, gen_loss = 1.1416462802886962, disc_loss = 0.0006346328032668679
Trained batch 25 in epoch 3, gen_loss = 1.1461717302982624, disc_loss = 0.000652882672371701
Trained batch 26 in epoch 3, gen_loss = 1.162772293444033, disc_loss = 0.0006474808636725087
Trained batch 27 in epoch 3, gen_loss = 1.159935440335955, disc_loss = 0.0006547445674576531
Trained batch 28 in epoch 3, gen_loss = 1.1579493654185329, disc_loss = 0.0006778556702995737
Trained batch 29 in epoch 3, gen_loss = 1.1532676259676615, disc_loss = 0.0007088238615930701
Trained batch 30 in epoch 3, gen_loss = 1.1528580496388097, disc_loss = 0.0007479983361272682
Trained batch 31 in epoch 3, gen_loss = 1.152215264737606, disc_loss = 0.0007609903632328496
Trained batch 32 in epoch 3, gen_loss = 1.1521222013415713, disc_loss = 0.0007615588018035686
Trained batch 33 in epoch 3, gen_loss = 1.151529024629032, disc_loss = 0.0007518813988152781
Trained batch 34 in epoch 3, gen_loss = 1.1572586127689906, disc_loss = 0.0007390950498769858
Trained batch 35 in epoch 3, gen_loss = 1.1579691502783034, disc_loss = 0.000725727979443036
Trained batch 36 in epoch 3, gen_loss = 1.1578281441250362, disc_loss = 0.0007174074251796245
Trained batch 37 in epoch 3, gen_loss = 1.1547214231993024, disc_loss = 0.0007117204544269235
Trained batch 38 in epoch 3, gen_loss = 1.1601944305957892, disc_loss = 0.0007043506178515366
Trained batch 39 in epoch 3, gen_loss = 1.1617820709943771, disc_loss = 0.0006992063390498515
Trained batch 40 in epoch 3, gen_loss = 1.1631117245046103, disc_loss = 0.000701090668061203
Trained batch 41 in epoch 3, gen_loss = 1.1634555600938343, disc_loss = 0.000718023606515046
Trained batch 42 in epoch 3, gen_loss = 1.1714809772580168, disc_loss = 0.0007510943680752589
Trained batch 43 in epoch 3, gen_loss = 1.1703494624658064, disc_loss = 0.0008060954443697648
Trained batch 44 in epoch 3, gen_loss = 1.1696049107445612, disc_loss = 0.0008469549842023601
Trained batch 45 in epoch 3, gen_loss = 1.1715242344400156, disc_loss = 0.0008536137383603289
Trained batch 46 in epoch 3, gen_loss = 1.1683634950759563, disc_loss = 0.000871249817019487
Trained batch 47 in epoch 3, gen_loss = 1.1691321978966396, disc_loss = 0.0008898502280014023
Trained batch 48 in epoch 3, gen_loss = 1.1764667155791302, disc_loss = 0.0008966322823152022
Trained batch 49 in epoch 3, gen_loss = 1.1755368280410767, disc_loss = 0.0008937297394732013
Trained batch 50 in epoch 3, gen_loss = 1.1731622312583176, disc_loss = 0.0008910332535913982
Trained batch 51 in epoch 3, gen_loss = 1.1703103322249193, disc_loss = 0.0008954717078058121
Trained batch 52 in epoch 3, gen_loss = 1.1696777276273043, disc_loss = 0.0008928876865505821
Trained batch 53 in epoch 3, gen_loss = 1.1673380533854167, disc_loss = 0.0008861596369469124
Trained batch 54 in epoch 3, gen_loss = 1.168653509833596, disc_loss = 0.000878455897856673
Trained batch 55 in epoch 3, gen_loss = 1.1685897005455834, disc_loss = 0.0008693496955467188
Trained batch 56 in epoch 3, gen_loss = 1.165764856756779, disc_loss = 0.000860910836133387
Trained batch 57 in epoch 3, gen_loss = 1.163895202094111, disc_loss = 0.0008520649390792923
Trained batch 58 in epoch 3, gen_loss = 1.1612159539077243, disc_loss = 0.0008417129303502329
Trained batch 59 in epoch 3, gen_loss = 1.1603780229886373, disc_loss = 0.000833167625629964
Trained batch 60 in epoch 3, gen_loss = 1.1591795213886948, disc_loss = 0.0008244896746530641
Trained batch 61 in epoch 3, gen_loss = 1.1590890288352966, disc_loss = 0.0008196513724303054
Trained batch 62 in epoch 3, gen_loss = 1.160027645883106, disc_loss = 0.0008181815122490719
Trained batch 63 in epoch 3, gen_loss = 1.1601149532943964, disc_loss = 0.0008175787470463547
Trained batch 64 in epoch 3, gen_loss = 1.1591672585560726, disc_loss = 0.0008139698936317402
Trained batch 65 in epoch 3, gen_loss = 1.1613870371471753, disc_loss = 0.0008057459860786118
Trained batch 66 in epoch 3, gen_loss = 1.161758348123351, disc_loss = 0.000796750932845023
Trained batch 67 in epoch 3, gen_loss = 1.1592322885990143, disc_loss = 0.0007894241541233735
Trained batch 68 in epoch 3, gen_loss = 1.1574833220329837, disc_loss = 0.000782671594567111
Trained batch 69 in epoch 3, gen_loss = 1.1565806593213763, disc_loss = 0.000776881624395693
Trained batch 70 in epoch 3, gen_loss = 1.1552954492434648, disc_loss = 0.0007718248554328325
Trained batch 71 in epoch 3, gen_loss = 1.1583035671048694, disc_loss = 0.0007651719396461784
Trained batch 72 in epoch 3, gen_loss = 1.1595046797843829, disc_loss = 0.0007571887259996713
Trained batch 73 in epoch 3, gen_loss = 1.158658799287435, disc_loss = 0.0007512102908819814
Trained batch 74 in epoch 3, gen_loss = 1.1603458627065022, disc_loss = 0.0007474752849278351
Trained batch 75 in epoch 3, gen_loss = 1.1584366967803554, disc_loss = 0.0007517276367013293
Trained batch 76 in epoch 3, gen_loss = 1.1608954621599865, disc_loss = 0.0007532324336541744
Trained batch 77 in epoch 3, gen_loss = 1.159212554112459, disc_loss = 0.0007524921645362598
Trained batch 78 in epoch 3, gen_loss = 1.1609703996513463, disc_loss = 0.0007518985385334567
Trained batch 79 in epoch 3, gen_loss = 1.160759949684143, disc_loss = 0.0007490712712751701
Trained batch 80 in epoch 3, gen_loss = 1.1581203157519118, disc_loss = 0.0007508701061324021
Trained batch 81 in epoch 3, gen_loss = 1.1573543941102378, disc_loss = 0.00074964220828672
Trained batch 82 in epoch 3, gen_loss = 1.1566458681979812, disc_loss = 0.0007447735515159432
Trained batch 83 in epoch 3, gen_loss = 1.1570036226794833, disc_loss = 0.0007392456966391322
Trained batch 84 in epoch 3, gen_loss = 1.1565631123150095, disc_loss = 0.0007345093585386434
Trained batch 85 in epoch 3, gen_loss = 1.1570056413495264, disc_loss = 0.0007309583743335679
Trained batch 86 in epoch 3, gen_loss = 1.1584782545593963, disc_loss = 0.0007294009117832428
Trained batch 87 in epoch 3, gen_loss = 1.158170778643001, disc_loss = 0.0007261134447947949
Trained batch 88 in epoch 3, gen_loss = 1.1587353368823448, disc_loss = 0.000722487185678832
Trained batch 89 in epoch 3, gen_loss = 1.1589404503504435, disc_loss = 0.000727564567932859
Trained batch 90 in epoch 3, gen_loss = 1.1574803341876019, disc_loss = 0.000736195189177294
Trained batch 91 in epoch 3, gen_loss = 1.1590043746906777, disc_loss = 0.0007350991078925764
Trained batch 92 in epoch 3, gen_loss = 1.160874879488381, disc_loss = 0.0007306719743346255
Trained batch 93 in epoch 3, gen_loss = 1.1621557474136353, disc_loss = 0.0007264149335629128
Trained batch 94 in epoch 3, gen_loss = 1.1609848198137784, disc_loss = 0.0007219084599790604
Trained batch 95 in epoch 3, gen_loss = 1.1594931793709595, disc_loss = 0.0007218555577613491
Trained batch 96 in epoch 3, gen_loss = 1.1594836072823436, disc_loss = 0.0007283874222115834
Trained batch 97 in epoch 3, gen_loss = 1.1593164679955463, disc_loss = 0.0007294619322887488
Trained batch 98 in epoch 3, gen_loss = 1.1617851931639391, disc_loss = 0.0007268340412687246
Trained batch 99 in epoch 3, gen_loss = 1.1635811734199524, disc_loss = 0.000729043273604475
Trained batch 100 in epoch 3, gen_loss = 1.1637387252090001, disc_loss = 0.0007334605768774774
Trained batch 101 in epoch 3, gen_loss = 1.163607076102612, disc_loss = 0.0007395260441162641
Trained batch 102 in epoch 3, gen_loss = 1.1616514255699601, disc_loss = 0.0007444897997735556
Trained batch 103 in epoch 3, gen_loss = 1.1615161901483169, disc_loss = 0.000743130425689742
Trained batch 104 in epoch 3, gen_loss = 1.1607539750280835, disc_loss = 0.0007385829180878188
Trained batch 105 in epoch 3, gen_loss = 1.1605237671789133, disc_loss = 0.00073532662892556
Trained batch 106 in epoch 3, gen_loss = 1.1644169075466761, disc_loss = 0.0007308720900442138
Trained batch 107 in epoch 3, gen_loss = 1.1644089370965958, disc_loss = 0.0007269839291068449
Trained batch 108 in epoch 3, gen_loss = 1.1667237932528924, disc_loss = 0.0007226821772087741
Trained batch 109 in epoch 3, gen_loss = 1.1666435626420109, disc_loss = 0.000718393524452536
Trained batch 110 in epoch 3, gen_loss = 1.1679785289205946, disc_loss = 0.0007137379045063328
Trained batch 111 in epoch 3, gen_loss = 1.1682760348277432, disc_loss = 0.0007103546913640457
Trained batch 112 in epoch 3, gen_loss = 1.1685468923729079, disc_loss = 0.0007086289147444614
Trained batch 113 in epoch 3, gen_loss = 1.1702222264649575, disc_loss = 0.0007077881004589839
Trained batch 114 in epoch 3, gen_loss = 1.1691602898680646, disc_loss = 0.0007085638425727983
Trained batch 115 in epoch 3, gen_loss = 1.1696605934151287, disc_loss = 0.0007082823276818842
Trained batch 116 in epoch 3, gen_loss = 1.1691680958128383, disc_loss = 0.000712168582692209
Trained batch 117 in epoch 3, gen_loss = 1.1702317368176023, disc_loss = 0.0007239105679357219
Trained batch 118 in epoch 3, gen_loss = 1.1695493104077186, disc_loss = 0.0007403142357239218
Trained batch 119 in epoch 3, gen_loss = 1.1680884485443432, disc_loss = 0.0007542636503785616
Trained batch 120 in epoch 3, gen_loss = 1.167824564393887, disc_loss = 0.0007625667361228934
Trained batch 121 in epoch 3, gen_loss = 1.1683703157745424, disc_loss = 0.0007632916024361249
Trained batch 122 in epoch 3, gen_loss = 1.16805088471591, disc_loss = 0.0007618057293811722
Trained batch 123 in epoch 3, gen_loss = 1.1676812099833642, disc_loss = 0.0007592202550327901
Trained batch 124 in epoch 3, gen_loss = 1.169061767101288, disc_loss = 0.0007570061715086922
Trained batch 125 in epoch 3, gen_loss = 1.169829229986857, disc_loss = 0.0007542329009978972
Trained batch 126 in epoch 3, gen_loss = 1.1704144604562774, disc_loss = 0.0007504905326755747
Trained batch 127 in epoch 3, gen_loss = 1.171617419924587, disc_loss = 0.0007486647224368426
Trained batch 128 in epoch 3, gen_loss = 1.171391555043154, disc_loss = 0.0007509585031598821
Trained batch 129 in epoch 3, gen_loss = 1.1722026875385871, disc_loss = 0.000756348422929967
Trained batch 130 in epoch 3, gen_loss = 1.1717773098072022, disc_loss = 0.0007585076947797815
Trained batch 131 in epoch 3, gen_loss = 1.1714068177071484, disc_loss = 0.0007606267169070303
Trained batch 132 in epoch 3, gen_loss = 1.170633071795442, disc_loss = 0.0007591217970064162
Trained batch 133 in epoch 3, gen_loss = 1.171662808799032, disc_loss = 0.0007566595620539998
Trained batch 134 in epoch 3, gen_loss = 1.1724289721912808, disc_loss = 0.0007546226380832701
Trained batch 135 in epoch 3, gen_loss = 1.1723731655408354, disc_loss = 0.0007525262422217673
Trained batch 136 in epoch 3, gen_loss = 1.1719606605759503, disc_loss = 0.0007491445585866085
Trained batch 137 in epoch 3, gen_loss = 1.17176236320233, disc_loss = 0.0007457257056755581
Trained batch 138 in epoch 3, gen_loss = 1.1720414080208155, disc_loss = 0.0007426506342833674
Trained batch 139 in epoch 3, gen_loss = 1.172846617443221, disc_loss = 0.0007411436185066122
Trained batch 140 in epoch 3, gen_loss = 1.1733114064162504, disc_loss = 0.0007406348615004648
Trained batch 141 in epoch 3, gen_loss = 1.1728096952740574, disc_loss = 0.0007409598647811922
Trained batch 142 in epoch 3, gen_loss = 1.1722912875922409, disc_loss = 0.0007400780632706046
Trained batch 143 in epoch 3, gen_loss = 1.1724849074251122, disc_loss = 0.0007368814532229509
Trained batch 144 in epoch 3, gen_loss = 1.172075980696185, disc_loss = 0.0007335947524427019
Trained batch 145 in epoch 3, gen_loss = 1.1712107107247391, disc_loss = 0.0007317903293543878
Trained batch 146 in epoch 3, gen_loss = 1.1700223550504567, disc_loss = 0.0007298496441137945
Trained batch 147 in epoch 3, gen_loss = 1.1698266126819559, disc_loss = 0.0007273228067198353
Trained batch 148 in epoch 3, gen_loss = 1.1689160466194153, disc_loss = 0.0007268676295799935
Trained batch 149 in epoch 3, gen_loss = 1.168988198041916, disc_loss = 0.0007279412602656521
Trained batch 150 in epoch 3, gen_loss = 1.1687197760240922, disc_loss = 0.0007283727873374233
Trained batch 151 in epoch 3, gen_loss = 1.1689088372023482, disc_loss = 0.0007277325543040398
Trained batch 152 in epoch 3, gen_loss = 1.1677073220801508, disc_loss = 0.0007280943122216092
Trained batch 153 in epoch 3, gen_loss = 1.1691703444177455, disc_loss = 0.000729722529026081
Trained batch 154 in epoch 3, gen_loss = 1.1683730283091145, disc_loss = 0.0007299754087955902
Trained batch 155 in epoch 3, gen_loss = 1.168362205227216, disc_loss = 0.0007308057910659744
Trained batch 156 in epoch 3, gen_loss = 1.1687513768293296, disc_loss = 0.0007351445100695832
Trained batch 157 in epoch 3, gen_loss = 1.1681889895396897, disc_loss = 0.0007401067196042277
Trained batch 158 in epoch 3, gen_loss = 1.1671398656923067, disc_loss = 0.000739680725693814
Trained batch 159 in epoch 3, gen_loss = 1.1666954863816499, disc_loss = 0.0007375480115115352
Trained batch 160 in epoch 3, gen_loss = 1.1672079315096695, disc_loss = 0.0007359110984353996
Trained batch 161 in epoch 3, gen_loss = 1.1668931602695842, disc_loss = 0.0007343339622574054
Trained batch 162 in epoch 3, gen_loss = 1.167905740577019, disc_loss = 0.0007316721475610304
Trained batch 163 in epoch 3, gen_loss = 1.1676767937293866, disc_loss = 0.0007288626993391606
Trained batch 164 in epoch 3, gen_loss = 1.1665704528490701, disc_loss = 0.0007263238420956909
Trained batch 165 in epoch 3, gen_loss = 1.1657076668308441, disc_loss = 0.0007240183013091594
Trained batch 166 in epoch 3, gen_loss = 1.1674075151631933, disc_loss = 0.0007212533880252402
Trained batch 167 in epoch 3, gen_loss = 1.166199739135447, disc_loss = 0.0007225245986947335
Trained batch 168 in epoch 3, gen_loss = 1.1653329222159978, disc_loss = 0.0007307154629152191
Trained batch 169 in epoch 3, gen_loss = 1.166129888857112, disc_loss = 0.000733605662261492
Trained batch 170 in epoch 3, gen_loss = 1.165782496594546, disc_loss = 0.0007343774463822085
Trained batch 171 in epoch 3, gen_loss = 1.165732823485552, disc_loss = 0.0007399052186418314
Trained batch 172 in epoch 3, gen_loss = 1.1674919958748569, disc_loss = 0.0007478577246172139
Trained batch 173 in epoch 3, gen_loss = 1.1688389781562762, disc_loss = 0.0007526576521521402
Trained batch 174 in epoch 3, gen_loss = 1.1679900908470153, disc_loss = 0.0007555647409753874
Trained batch 175 in epoch 3, gen_loss = 1.1674564369022846, disc_loss = 0.0007613760657146817
Trained batch 176 in epoch 3, gen_loss = 1.1674039959907532, disc_loss = 0.0007679515631210406
Trained batch 177 in epoch 3, gen_loss = 1.1676309888952234, disc_loss = 0.0007719143951577239
Trained batch 178 in epoch 3, gen_loss = 1.1667753581228204, disc_loss = 0.0007729122389007787
Trained batch 179 in epoch 3, gen_loss = 1.1667793376578226, disc_loss = 0.0007730255119289116
Trained batch 180 in epoch 3, gen_loss = 1.1659152570350395, disc_loss = 0.0007710941334464716
Trained batch 181 in epoch 3, gen_loss = 1.164800490651812, disc_loss = 0.0007687297589395062
Trained batch 182 in epoch 3, gen_loss = 1.1637573470183409, disc_loss = 0.0007663219073778425
Trained batch 183 in epoch 3, gen_loss = 1.1643104190411775, disc_loss = 0.0007637179502995897
Trained batch 184 in epoch 3, gen_loss = 1.1638554805033916, disc_loss = 0.0007628706391630191
Trained batch 185 in epoch 3, gen_loss = 1.163539139173364, disc_loss = 0.0007628577477980895
Trained batch 186 in epoch 3, gen_loss = 1.16298397212105, disc_loss = 0.0007622841824833453
Trained batch 187 in epoch 3, gen_loss = 1.1636868188989924, disc_loss = 0.0007639206845116395
Trained batch 188 in epoch 3, gen_loss = 1.1634086692144001, disc_loss = 0.0007632110630828523
Trained batch 189 in epoch 3, gen_loss = 1.163166194213064, disc_loss = 0.000761830139565159
Trained batch 190 in epoch 3, gen_loss = 1.1636861412937105, disc_loss = 0.0007604206044437773
Trained batch 191 in epoch 3, gen_loss = 1.1638554818928242, disc_loss = 0.0007589383756112511
Trained batch 192 in epoch 3, gen_loss = 1.163412307210537, disc_loss = 0.0007565755034716066
Trained batch 193 in epoch 3, gen_loss = 1.1631923920100498, disc_loss = 0.0007544250231861501
Trained batch 194 in epoch 3, gen_loss = 1.1637051765735333, disc_loss = 0.0007521892020938536
Trained batch 195 in epoch 3, gen_loss = 1.1644287109375, disc_loss = 0.0007507482357828032
Trained batch 196 in epoch 3, gen_loss = 1.164633972390654, disc_loss = 0.0007486916013472113
Trained batch 197 in epoch 3, gen_loss = 1.16502366944997, disc_loss = 0.000746762787237072
Trained batch 198 in epoch 3, gen_loss = 1.1650759706545115, disc_loss = 0.0007442634327637837
Trained batch 199 in epoch 3, gen_loss = 1.164537754058838, disc_loss = 0.0007429877593676793
Trained batch 200 in epoch 3, gen_loss = 1.16508451030029, disc_loss = 0.0007440824999470514
Trained batch 201 in epoch 3, gen_loss = 1.1661810048735968, disc_loss = 0.0007438041151779022
Trained batch 202 in epoch 3, gen_loss = 1.1656430818764447, disc_loss = 0.0007460742777820191
Trained batch 203 in epoch 3, gen_loss = 1.1653505686451406, disc_loss = 0.00074635857384362
Trained batch 204 in epoch 3, gen_loss = 1.1655797417570906, disc_loss = 0.000744483949085584
Trained batch 205 in epoch 3, gen_loss = 1.1653652717766252, disc_loss = 0.0007426932251936467
Trained batch 206 in epoch 3, gen_loss = 1.1659001227162311, disc_loss = 0.0007409639572887794
Trained batch 207 in epoch 3, gen_loss = 1.1661310258966227, disc_loss = 0.0007391644378283393
Trained batch 208 in epoch 3, gen_loss = 1.166787141818179, disc_loss = 0.0007375196244486309
Trained batch 209 in epoch 3, gen_loss = 1.1674799896421886, disc_loss = 0.0007352350956699367
Trained batch 210 in epoch 3, gen_loss = 1.1676110198712462, disc_loss = 0.0007327373190733308
Trained batch 211 in epoch 3, gen_loss = 1.167309118329354, disc_loss = 0.0007304780619446285
Trained batch 212 in epoch 3, gen_loss = 1.1668645915850786, disc_loss = 0.000728491646390159
Trained batch 213 in epoch 3, gen_loss = 1.1679228443965735, disc_loss = 0.0007272233186799937
Trained batch 214 in epoch 3, gen_loss = 1.1673892359400904, disc_loss = 0.0007258525415361577
Trained batch 215 in epoch 3, gen_loss = 1.1685889401921519, disc_loss = 0.0007238722218634966
Trained batch 216 in epoch 3, gen_loss = 1.16963534860567, disc_loss = 0.0007214786463780844
Trained batch 217 in epoch 3, gen_loss = 1.1692921666924012, disc_loss = 0.0007191861591434295
Trained batch 218 in epoch 3, gen_loss = 1.1689470500162202, disc_loss = 0.0007168542419360381
Trained batch 219 in epoch 3, gen_loss = 1.1689124345779418, disc_loss = 0.0007154424942035059
Trained batch 220 in epoch 3, gen_loss = 1.1695002711196831, disc_loss = 0.0007135690944753924
Trained batch 221 in epoch 3, gen_loss = 1.1697292338620435, disc_loss = 0.0007114724671942191
Trained batch 222 in epoch 3, gen_loss = 1.1708973699621021, disc_loss = 0.0007124237704191006
Trained batch 223 in epoch 3, gen_loss = 1.1712432147136755, disc_loss = 0.0007157257639067081
Trained batch 224 in epoch 3, gen_loss = 1.1713891479704115, disc_loss = 0.000718299189530727
Trained batch 225 in epoch 3, gen_loss = 1.1709476667167866, disc_loss = 0.0007195651226788264
Trained batch 226 in epoch 3, gen_loss = 1.1699168994563267, disc_loss = 0.0007204219079904652
Trained batch 227 in epoch 3, gen_loss = 1.169428858056403, disc_loss = 0.0007204810660863458
Trained batch 228 in epoch 3, gen_loss = 1.1694348209810048, disc_loss = 0.0007199721960411874
Trained batch 229 in epoch 3, gen_loss = 1.170236368023831, disc_loss = 0.0007187290013383102
Trained batch 230 in epoch 3, gen_loss = 1.1705885441788346, disc_loss = 0.0007173682044429535
Trained batch 231 in epoch 3, gen_loss = 1.170911109909929, disc_loss = 0.0007159723846316097
Trained batch 232 in epoch 3, gen_loss = 1.1701937624824916, disc_loss = 0.0007146390278867642
Trained batch 233 in epoch 3, gen_loss = 1.170435760011021, disc_loss = 0.0007134490803383593
Trained batch 234 in epoch 3, gen_loss = 1.1698867942424531, disc_loss = 0.0007122354273575338
Trained batch 235 in epoch 3, gen_loss = 1.1701966698391963, disc_loss = 0.0007116499639824585
Trained batch 236 in epoch 3, gen_loss = 1.1702697249404488, disc_loss = 0.000711697321861613
Trained batch 237 in epoch 3, gen_loss = 1.1710066457255548, disc_loss = 0.0007118523249768519
Trained batch 238 in epoch 3, gen_loss = 1.1712024463769282, disc_loss = 0.0007118946699976968
Trained batch 239 in epoch 3, gen_loss = 1.1706969492137431, disc_loss = 0.0007123605817469069
Trained batch 240 in epoch 3, gen_loss = 1.170911904934531, disc_loss = 0.0007130599886718055
Trained batch 241 in epoch 3, gen_loss = 1.1699701151079382, disc_loss = 0.000713284788744655
Trained batch 242 in epoch 3, gen_loss = 1.170311551280473, disc_loss = 0.0007125631537922724
Trained batch 243 in epoch 3, gen_loss = 1.171026636098252, disc_loss = 0.0007118727663793356
Trained batch 244 in epoch 3, gen_loss = 1.1716920499898948, disc_loss = 0.0007110344304237515
Trained batch 245 in epoch 3, gen_loss = 1.1721155679807431, disc_loss = 0.0007101279765990283
Trained batch 246 in epoch 3, gen_loss = 1.1717590564175655, disc_loss = 0.0007089974426076209
Trained batch 247 in epoch 3, gen_loss = 1.1713633097467884, disc_loss = 0.0007079288355476644
Trained batch 248 in epoch 3, gen_loss = 1.1720370291227318, disc_loss = 0.0007064580554086491
Trained batch 249 in epoch 3, gen_loss = 1.1717835915088655, disc_loss = 0.0007055818618973717
Trained batch 250 in epoch 3, gen_loss = 1.1717841200144643, disc_loss = 0.0007041524222586304
Trained batch 251 in epoch 3, gen_loss = 1.172517416259599, disc_loss = 0.0007024300889858591
Trained batch 252 in epoch 3, gen_loss = 1.1725857156538682, disc_loss = 0.0007038250148642381
Trained batch 253 in epoch 3, gen_loss = 1.1727328809696858, disc_loss = 0.0007052601362747236
Trained batch 254 in epoch 3, gen_loss = 1.1726193579972959, disc_loss = 0.000706139704504726
Trained batch 255 in epoch 3, gen_loss = 1.1728062953334302, disc_loss = 0.0007075070088831126
Trained batch 256 in epoch 3, gen_loss = 1.1717673660716195, disc_loss = 0.0007102194800248174
Trained batch 257 in epoch 3, gen_loss = 1.172064410623654, disc_loss = 0.0007130016050258175
Trained batch 258 in epoch 3, gen_loss = 1.1718347809029361, disc_loss = 0.0007164338239536955
Trained batch 259 in epoch 3, gen_loss = 1.1719483384719263, disc_loss = 0.0007210747155253417
Trained batch 260 in epoch 3, gen_loss = 1.172097724516273, disc_loss = 0.0007248273720586551
Trained batch 261 in epoch 3, gen_loss = 1.1725340135224902, disc_loss = 0.0007269868497445269
Trained batch 262 in epoch 3, gen_loss = 1.17242158456447, disc_loss = 0.0007270700497439436
Trained batch 263 in epoch 3, gen_loss = 1.171898458491672, disc_loss = 0.0007260059754833381
Trained batch 264 in epoch 3, gen_loss = 1.1717911873223648, disc_loss = 0.000724859783680723
Trained batch 265 in epoch 3, gen_loss = 1.1716185135948927, disc_loss = 0.0007235343879634948
Trained batch 266 in epoch 3, gen_loss = 1.1710541761769784, disc_loss = 0.0007214013519583529
Trained batch 267 in epoch 3, gen_loss = 1.1703256324156006, disc_loss = 0.0007196707474441379
Trained batch 268 in epoch 3, gen_loss = 1.170066760375154, disc_loss = 0.0007181439656274372
Trained batch 269 in epoch 3, gen_loss = 1.1698636960100244, disc_loss = 0.0007162700379181101
Trained batch 270 in epoch 3, gen_loss = 1.1702815118311076, disc_loss = 0.0007147939465046479
Trained batch 271 in epoch 3, gen_loss = 1.170456336263348, disc_loss = 0.0007135003064938835
Trained batch 272 in epoch 3, gen_loss = 1.1703700307524685, disc_loss = 0.000711942251495362
Trained batch 273 in epoch 3, gen_loss = 1.1698510285711636, disc_loss = 0.0007101993603240121
Trained batch 274 in epoch 3, gen_loss = 1.170072439367121, disc_loss = 0.0007107757378517735
Trained batch 275 in epoch 3, gen_loss = 1.1703520909599636, disc_loss = 0.0007125246321147247
Trained batch 276 in epoch 3, gen_loss = 1.1706435775068262, disc_loss = 0.0007148300102026797
Trained batch 277 in epoch 3, gen_loss = 1.1702661908787788, disc_loss = 0.0007167712427996495
Trained batch 278 in epoch 3, gen_loss = 1.1706524566082972, disc_loss = 0.0007180596349112469
Trained batch 279 in epoch 3, gen_loss = 1.1704742367778505, disc_loss = 0.0007180515790553597
Trained batch 280 in epoch 3, gen_loss = 1.170374469400725, disc_loss = 0.0007177244519605218
Trained batch 281 in epoch 3, gen_loss = 1.1699284040336069, disc_loss = 0.0007173955487066728
Trained batch 282 in epoch 3, gen_loss = 1.1692434797859865, disc_loss = 0.0007170669202484658
Trained batch 283 in epoch 3, gen_loss = 1.1687086329493723, disc_loss = 0.0007179840901865736
Trained batch 284 in epoch 3, gen_loss = 1.1700365756687365, disc_loss = 0.0007177892287584479
Trained batch 285 in epoch 3, gen_loss = 1.170298430886302, disc_loss = 0.000717077445932029
Trained batch 286 in epoch 3, gen_loss = 1.16962077144131, disc_loss = 0.0007161194511234131
Trained batch 287 in epoch 3, gen_loss = 1.1697226783467665, disc_loss = 0.0007151948642684955
Trained batch 288 in epoch 3, gen_loss = 1.1692644910416388, disc_loss = 0.0007144076329036406
Trained batch 289 in epoch 3, gen_loss = 1.1687825022072627, disc_loss = 0.0007138758648391652
Trained batch 290 in epoch 3, gen_loss = 1.169018040407974, disc_loss = 0.0007130311030628083
Trained batch 291 in epoch 3, gen_loss = 1.169221382435054, disc_loss = 0.0007120977349324974
Trained batch 292 in epoch 3, gen_loss = 1.1687745291218417, disc_loss = 0.0007112823240876153
Trained batch 293 in epoch 3, gen_loss = 1.1686491816222262, disc_loss = 0.0007099868650219505
Trained batch 294 in epoch 3, gen_loss = 1.1681744935148852, disc_loss = 0.0007095505103125568
Trained batch 295 in epoch 3, gen_loss = 1.1689488928060274, disc_loss = 0.0007090522362272463
Trained batch 296 in epoch 3, gen_loss = 1.1688188699760822, disc_loss = 0.0007076342598482596
Trained batch 297 in epoch 3, gen_loss = 1.1691037388455947, disc_loss = 0.0007069721078557188
Trained batch 298 in epoch 3, gen_loss = 1.1685654810041088, disc_loss = 0.0007086495022903847
Trained batch 299 in epoch 3, gen_loss = 1.1688763074080148, disc_loss = 0.0007118896170383474
Trained batch 300 in epoch 3, gen_loss = 1.168447029154958, disc_loss = 0.0007147564084452431
Trained batch 301 in epoch 3, gen_loss = 1.1687303501249149, disc_loss = 0.0007169857345670246
Trained batch 302 in epoch 3, gen_loss = 1.1683628850250747, disc_loss = 0.0007181958324316637
Trained batch 303 in epoch 3, gen_loss = 1.1683085082392943, disc_loss = 0.000718443230222252
Trained batch 304 in epoch 3, gen_loss = 1.168677077527906, disc_loss = 0.000719573286211225
Trained batch 305 in epoch 3, gen_loss = 1.1687322145973156, disc_loss = 0.0007183425906178956
Trained batch 306 in epoch 3, gen_loss = 1.168853422329558, disc_loss = 0.0007165685140680224
Trained batch 307 in epoch 3, gen_loss = 1.1690275897453357, disc_loss = 0.0007150061641628522
Trained batch 308 in epoch 3, gen_loss = 1.1694274843703583, disc_loss = 0.0007145326977055429
Trained batch 309 in epoch 3, gen_loss = 1.1698247774954764, disc_loss = 0.000713791893072231
Trained batch 310 in epoch 3, gen_loss = 1.1701015356652607, disc_loss = 0.0007123800590795306
Trained batch 311 in epoch 3, gen_loss = 1.1699091169314506, disc_loss = 0.0007114327448410526
Trained batch 312 in epoch 3, gen_loss = 1.1694217547060202, disc_loss = 0.0007111925492565276
Trained batch 313 in epoch 3, gen_loss = 1.1697961103384662, disc_loss = 0.0007105643814559403
Trained batch 314 in epoch 3, gen_loss = 1.1699849087094503, disc_loss = 0.000710026142584707
Trained batch 315 in epoch 3, gen_loss = 1.1697268561471867, disc_loss = 0.0007099490564392402
Trained batch 316 in epoch 3, gen_loss = 1.1693902008164945, disc_loss = 0.0007094525891757932
Trained batch 317 in epoch 3, gen_loss = 1.16884723361933, disc_loss = 0.0007085655767850596
Trained batch 318 in epoch 3, gen_loss = 1.1682167886566592, disc_loss = 0.0007101165916355397
Trained batch 319 in epoch 3, gen_loss = 1.1687595643103124, disc_loss = 0.0007127782260340609
Trained batch 320 in epoch 3, gen_loss = 1.1690685667352885, disc_loss = 0.0007140366327452018
Trained batch 321 in epoch 3, gen_loss = 1.1691170101580413, disc_loss = 0.0007139573302405585
Trained batch 322 in epoch 3, gen_loss = 1.1689066407112145, disc_loss = 0.0007126769786660961
Trained batch 323 in epoch 3, gen_loss = 1.169020962935907, disc_loss = 0.0007115442014854821
Trained batch 324 in epoch 3, gen_loss = 1.1689515344913188, disc_loss = 0.0007109821194227642
Trained batch 325 in epoch 3, gen_loss = 1.1696307542133917, disc_loss = 0.0007111731241475019
Trained batch 326 in epoch 3, gen_loss = 1.1697617455724547, disc_loss = 0.0007119107417301602
Trained batch 327 in epoch 3, gen_loss = 1.1696763027731965, disc_loss = 0.0007123285622805181
Trained batch 328 in epoch 3, gen_loss = 1.1694280876577081, disc_loss = 0.0007111248799538137
Trained batch 329 in epoch 3, gen_loss = 1.1698235240849582, disc_loss = 0.0007102181584217981
Trained batch 330 in epoch 3, gen_loss = 1.169913288689812, disc_loss = 0.0007088390869469019
Trained batch 331 in epoch 3, gen_loss = 1.1704072349042778, disc_loss = 0.000707339587597196
Trained batch 332 in epoch 3, gen_loss = 1.1704427945363272, disc_loss = 0.000705905460590684
Trained batch 333 in epoch 3, gen_loss = 1.1704422142691242, disc_loss = 0.0007048626744462328
Trained batch 334 in epoch 3, gen_loss = 1.1702423465785696, disc_loss = 0.0007041803678000735
Trained batch 335 in epoch 3, gen_loss = 1.1707147881388664, disc_loss = 0.000703523867741751
Trained batch 336 in epoch 3, gen_loss = 1.1708642237264253, disc_loss = 0.0007032983871511922
Trained batch 337 in epoch 3, gen_loss = 1.1704430509601118, disc_loss = 0.0007039894622054155
Trained batch 338 in epoch 3, gen_loss = 1.1706884403144364, disc_loss = 0.0007036995800067107
Trained batch 339 in epoch 3, gen_loss = 1.170342996891807, disc_loss = 0.0007026234960529323
Trained batch 340 in epoch 3, gen_loss = 1.1700234504039686, disc_loss = 0.0007037558037493395
Trained batch 341 in epoch 3, gen_loss = 1.1699032246717933, disc_loss = 0.0007066742302349507
Trained batch 342 in epoch 3, gen_loss = 1.1706423940185904, disc_loss = 0.0007092602637616114
Trained batch 343 in epoch 3, gen_loss = 1.1703872694525608, disc_loss = 0.0007093481430232248
Trained batch 344 in epoch 3, gen_loss = 1.1703553455463354, disc_loss = 0.0007086319106958293
Trained batch 345 in epoch 3, gen_loss = 1.1702188804659541, disc_loss = 0.0007073463281334615
Trained batch 346 in epoch 3, gen_loss = 1.1695284118569893, disc_loss = 0.0007062156501267057
Trained batch 347 in epoch 3, gen_loss = 1.1690020117608981, disc_loss = 0.00070584616822026
Trained batch 348 in epoch 3, gen_loss = 1.1687320827754657, disc_loss = 0.0007070893005892917
Trained batch 349 in epoch 3, gen_loss = 1.169112263917923, disc_loss = 0.0007123451474139334
Trained batch 350 in epoch 3, gen_loss = 1.16925275274831, disc_loss = 0.0007190380757956492
Trained batch 351 in epoch 3, gen_loss = 1.1691409605131908, disc_loss = 0.000721089536661814
Trained batch 352 in epoch 3, gen_loss = 1.169228777500455, disc_loss = 0.0007226128539181956
Trained batch 353 in epoch 3, gen_loss = 1.1688809985831632, disc_loss = 0.0007242967538146887
Trained batch 354 in epoch 3, gen_loss = 1.1691956075144485, disc_loss = 0.0007254810810735134
Trained batch 355 in epoch 3, gen_loss = 1.1692687422037125, disc_loss = 0.0007262883732488426
Trained batch 356 in epoch 3, gen_loss = 1.1695186028293534, disc_loss = 0.0007259355671198371
Trained batch 357 in epoch 3, gen_loss = 1.1692238558271077, disc_loss = 0.0007251945300910274
Trained batch 358 in epoch 3, gen_loss = 1.1693093602371747, disc_loss = 0.0007242404542941844
Trained batch 359 in epoch 3, gen_loss = 1.1691594632135498, disc_loss = 0.0007230033391857028
Trained batch 360 in epoch 3, gen_loss = 1.1693362917266064, disc_loss = 0.0007220365433489976
Trained batch 361 in epoch 3, gen_loss = 1.1697533030206986, disc_loss = 0.0007211917752669532
Trained batch 362 in epoch 3, gen_loss = 1.1700159391752616, disc_loss = 0.0007206986525744462
Trained batch 363 in epoch 3, gen_loss = 1.1705131391575048, disc_loss = 0.0007203747716250671
Trained batch 364 in epoch 3, gen_loss = 1.170215650290659, disc_loss = 0.0007197375351496117
Trained batch 365 in epoch 3, gen_loss = 1.170007351806255, disc_loss = 0.0007187552742397316
Trained batch 366 in epoch 3, gen_loss = 1.1701077136746545, disc_loss = 0.0007177830703651066
Trained batch 367 in epoch 3, gen_loss = 1.170484736399806, disc_loss = 0.0007175930700807088
Trained batch 368 in epoch 3, gen_loss = 1.170567424801307, disc_loss = 0.0007186597712015541
Trained batch 369 in epoch 3, gen_loss = 1.17069106955786, disc_loss = 0.0007200784415299249
Trained batch 370 in epoch 3, gen_loss = 1.1711967031589416, disc_loss = 0.0007217945961292326
Trained batch 371 in epoch 3, gen_loss = 1.1716632059504908, disc_loss = 0.0007234529842217628
Trained batch 372 in epoch 3, gen_loss = 1.1720534219498928, disc_loss = 0.0007238688297964877
Trained batch 373 in epoch 3, gen_loss = 1.1716469014710922, disc_loss = 0.000724331356927735
Trained batch 374 in epoch 3, gen_loss = 1.1715123988787333, disc_loss = 0.0007262750131776557
Trained batch 375 in epoch 3, gen_loss = 1.1713425883270325, disc_loss = 0.000728461039390358
Trained batch 376 in epoch 3, gen_loss = 1.1717000123044223, disc_loss = 0.000728274426191109
Trained batch 377 in epoch 3, gen_loss = 1.1725194443155218, disc_loss = 0.0007271939304133103
Trained batch 378 in epoch 3, gen_loss = 1.172693440498966, disc_loss = 0.0007268745255349991
Trained batch 379 in epoch 3, gen_loss = 1.173609054245447, disc_loss = 0.0007263630316485529
Trained batch 380 in epoch 3, gen_loss = 1.1744563224434539, disc_loss = 0.0007251395828721879
Trained batch 381 in epoch 3, gen_loss = 1.1747747567623699, disc_loss = 0.000724016524997908
Trained batch 382 in epoch 3, gen_loss = 1.1743944741727166, disc_loss = 0.0007231299738887838
Trained batch 383 in epoch 3, gen_loss = 1.173977291987588, disc_loss = 0.0007223010283041731
Trained batch 384 in epoch 3, gen_loss = 1.1747735978721023, disc_loss = 0.0007221737260062417
Trained batch 385 in epoch 3, gen_loss = 1.1745749732064459, disc_loss = 0.0007238800214362871
Trained batch 386 in epoch 3, gen_loss = 1.1745978558402346, disc_loss = 0.0007275788731122804
Trained batch 387 in epoch 3, gen_loss = 1.174788055192564, disc_loss = 0.0007310741066530025
Trained batch 388 in epoch 3, gen_loss = 1.174624617577825, disc_loss = 0.0007334593959182026
Trained batch 389 in epoch 3, gen_loss = 1.17468683276421, disc_loss = 0.0007343622056233028
Trained batch 390 in epoch 3, gen_loss = 1.1741920377287414, disc_loss = 0.0007352688236419907
Trained batch 391 in epoch 3, gen_loss = 1.1740673220887476, disc_loss = 0.0007354895182548457
Trained batch 392 in epoch 3, gen_loss = 1.174527408512494, disc_loss = 0.000737989344197188
Trained batch 393 in epoch 3, gen_loss = 1.1745228970111323, disc_loss = 0.0007441938541333787
Trained batch 394 in epoch 3, gen_loss = 1.1744920842255218, disc_loss = 0.0007501251273862192
Trained batch 395 in epoch 3, gen_loss = 1.1741149199731422, disc_loss = 0.0007551559573759659
Trained batch 396 in epoch 3, gen_loss = 1.1739783770491554, disc_loss = 0.0007582007305387534
Trained batch 397 in epoch 3, gen_loss = 1.173881915046941, disc_loss = 0.0007595512647800096
Trained batch 398 in epoch 3, gen_loss = 1.1739947267044755, disc_loss = 0.0007592027833382424
Trained batch 399 in epoch 3, gen_loss = 1.1742569342255593, disc_loss = 0.0007596708847631817
Trained batch 400 in epoch 3, gen_loss = 1.1747929229403375, disc_loss = 0.0007625593320234908
Trained batch 401 in epoch 3, gen_loss = 1.1747081205619507, disc_loss = 0.0007672108751006392
Trained batch 402 in epoch 3, gen_loss = 1.174582048326213, disc_loss = 0.0007696261327374593
Trained batch 403 in epoch 3, gen_loss = 1.1742894555082415, disc_loss = 0.0007697902657659286
Trained batch 404 in epoch 3, gen_loss = 1.1739019305617722, disc_loss = 0.0007693525993360069
Trained batch 405 in epoch 3, gen_loss = 1.1738080444007084, disc_loss = 0.000769368517695722
Trained batch 406 in epoch 3, gen_loss = 1.1736555535904605, disc_loss = 0.000772705657788923
Trained batch 407 in epoch 3, gen_loss = 1.174226359701624, disc_loss = 0.0007766363688978006
Trained batch 408 in epoch 3, gen_loss = 1.1742273735242252, disc_loss = 0.0007804996464734505
Trained batch 409 in epoch 3, gen_loss = 1.1738573865192692, disc_loss = 0.0007830207946315612
Trained batch 410 in epoch 3, gen_loss = 1.1738048916605557, disc_loss = 0.0007827241662926542
Trained batch 411 in epoch 3, gen_loss = 1.1735613783007686, disc_loss = 0.0007821149077253457
Trained batch 412 in epoch 3, gen_loss = 1.1734855720552348, disc_loss = 0.0007821206636876251
Trained batch 413 in epoch 3, gen_loss = 1.1732514607157685, disc_loss = 0.0007813810566645498
Trained batch 414 in epoch 3, gen_loss = 1.1731836554515793, disc_loss = 0.0007807240629616384
Trained batch 415 in epoch 3, gen_loss = 1.1732732619230564, disc_loss = 0.0007794588043977385
Trained batch 416 in epoch 3, gen_loss = 1.1727026649516263, disc_loss = 0.0007787890901816429
Trained batch 417 in epoch 3, gen_loss = 1.1724617926127603, disc_loss = 0.0007778393631674567
Trained batch 418 in epoch 3, gen_loss = 1.1724059615897677, disc_loss = 0.0007768261458861991
Trained batch 419 in epoch 3, gen_loss = 1.1727848677408128, disc_loss = 0.0007761067646719138
Trained batch 420 in epoch 3, gen_loss = 1.1731596562188482, disc_loss = 0.0007756658845441195
Trained batch 421 in epoch 3, gen_loss = 1.1735965036102947, disc_loss = 0.0007747649541717812
Trained batch 422 in epoch 3, gen_loss = 1.1738647631155965, disc_loss = 0.0007736074787949325
Trained batch 423 in epoch 3, gen_loss = 1.1741668896855049, disc_loss = 0.0007731795693922871
Trained batch 424 in epoch 3, gen_loss = 1.1743290772157557, disc_loss = 0.0007735220593167468
Trained batch 425 in epoch 3, gen_loss = 1.1742294310404102, disc_loss = 0.0007729669786569392
Trained batch 426 in epoch 3, gen_loss = 1.1741282671899371, disc_loss = 0.0007719756722593663
Trained batch 427 in epoch 3, gen_loss = 1.1738588297478507, disc_loss = 0.000771926195059074
Trained batch 428 in epoch 3, gen_loss = 1.1735658337186265, disc_loss = 0.000772854425022563
Trained batch 429 in epoch 3, gen_loss = 1.1743112006852794, disc_loss = 0.0007739518803942321
Trained batch 430 in epoch 3, gen_loss = 1.1742390300171004, disc_loss = 0.0007760427238756203
Trained batch 431 in epoch 3, gen_loss = 1.1739285728997655, disc_loss = 0.0007777250284225038
Trained batch 432 in epoch 3, gen_loss = 1.173413482604346, disc_loss = 0.0007787952193865062
Trained batch 433 in epoch 3, gen_loss = 1.173239227264158, disc_loss = 0.0007781575450741832
Trained batch 434 in epoch 3, gen_loss = 1.1731140317588018, disc_loss = 0.0007769527997294355
Trained batch 435 in epoch 3, gen_loss = 1.1730190176482593, disc_loss = 0.0007761254422502793
Trained batch 436 in epoch 3, gen_loss = 1.172901982300887, disc_loss = 0.0007751441739637562
Trained batch 437 in epoch 3, gen_loss = 1.1727699988508877, disc_loss = 0.0007743043748948395
Trained batch 438 in epoch 3, gen_loss = 1.1732085571202167, disc_loss = 0.0007731747674765829
Trained batch 439 in epoch 3, gen_loss = 1.1729585447094657, disc_loss = 0.0007718288908852793
Trained batch 440 in epoch 3, gen_loss = 1.1732109922941039, disc_loss = 0.0007704925306152992
Trained batch 441 in epoch 3, gen_loss = 1.1732171156287732, disc_loss = 0.0007693932986422126
Trained batch 442 in epoch 3, gen_loss = 1.1735979824518243, disc_loss = 0.0007686825768977958
Trained batch 443 in epoch 3, gen_loss = 1.1736087377543922, disc_loss = 0.0007677643408061232
Trained batch 444 in epoch 3, gen_loss = 1.1734671940964259, disc_loss = 0.0007665887922362498
Trained batch 445 in epoch 3, gen_loss = 1.17326363105945, disc_loss = 0.0007655245108131086
Trained batch 446 in epoch 3, gen_loss = 1.172814467475985, disc_loss = 0.0007651913154534829
Trained batch 447 in epoch 3, gen_loss = 1.1729574790224433, disc_loss = 0.0007645591370289497
Trained batch 448 in epoch 3, gen_loss = 1.1735112562211425, disc_loss = 0.0007633822088874981
Trained batch 449 in epoch 3, gen_loss = 1.173428732951482, disc_loss = 0.0007622216488946126
Trained batch 450 in epoch 3, gen_loss = 1.1731896282828302, disc_loss = 0.0007610770312234442
Trained batch 451 in epoch 3, gen_loss = 1.1729353527843425, disc_loss = 0.0007600196334520516
Trained batch 452 in epoch 3, gen_loss = 1.172412837051661, disc_loss = 0.0007589351021616348
Trained batch 453 in epoch 3, gen_loss = 1.172784059583353, disc_loss = 0.0007578923048937205
Trained batch 454 in epoch 3, gen_loss = 1.1728478764439678, disc_loss = 0.0007578258610849913
Trained batch 455 in epoch 3, gen_loss = 1.172576692282108, disc_loss = 0.0007611303828621443
Trained batch 456 in epoch 3, gen_loss = 1.172293064630788, disc_loss = 0.0007645085873222386
Trained batch 457 in epoch 3, gen_loss = 1.1726161486196727, disc_loss = 0.0007656297637757187
Trained batch 458 in epoch 3, gen_loss = 1.172828619256778, disc_loss = 0.0007661477549948622
Trained batch 459 in epoch 3, gen_loss = 1.1726093022719672, disc_loss = 0.0007662263580878853
Trained batch 460 in epoch 3, gen_loss = 1.172684480207861, disc_loss = 0.0007671344596445621
Trained batch 461 in epoch 3, gen_loss = 1.1727687858399891, disc_loss = 0.0007678405559070921
Trained batch 462 in epoch 3, gen_loss = 1.1725892150376322, disc_loss = 0.0007675508325796304
Trained batch 463 in epoch 3, gen_loss = 1.1723472149721508, disc_loss = 0.0007667776544622029
Trained batch 464 in epoch 3, gen_loss = 1.1725272273504606, disc_loss = 0.0007659536707828382
Trained batch 465 in epoch 3, gen_loss = 1.1725315599994086, disc_loss = 0.000764964551327884
Trained batch 466 in epoch 3, gen_loss = 1.1723422695278356, disc_loss = 0.0007643932068749876
Trained batch 467 in epoch 3, gen_loss = 1.1727218920858498, disc_loss = 0.0007645301952095937
Trained batch 468 in epoch 3, gen_loss = 1.172815163506628, disc_loss = 0.0007646400483634407
Trained batch 469 in epoch 3, gen_loss = 1.17273738054519, disc_loss = 0.0007641856626426662
Trained batch 470 in epoch 3, gen_loss = 1.1729290270248542, disc_loss = 0.0007636537227615015
Trained batch 471 in epoch 3, gen_loss = 1.173370897769928, disc_loss = 0.0007631525657693678
Trained batch 472 in epoch 3, gen_loss = 1.173548789911492, disc_loss = 0.0007625693243612726
Trained batch 473 in epoch 3, gen_loss = 1.173046161605336, disc_loss = 0.0007626241905787146
Trained batch 474 in epoch 3, gen_loss = 1.173458846995705, disc_loss = 0.0007646450135354442
Trained batch 475 in epoch 3, gen_loss = 1.1737334903548746, disc_loss = 0.0007693534628612854
Trained batch 476 in epoch 3, gen_loss = 1.1735921138487522, disc_loss = 0.0007729462798637489
Trained batch 477 in epoch 3, gen_loss = 1.1732285333228412, disc_loss = 0.0007740305692518118
Trained batch 478 in epoch 3, gen_loss = 1.1731856233889475, disc_loss = 0.0007748388551797286
Trained batch 479 in epoch 3, gen_loss = 1.1725905717660983, disc_loss = 0.0007772259358110508
Trained batch 480 in epoch 3, gen_loss = 1.172641088090171, disc_loss = 0.0007813559830749772
Trained batch 481 in epoch 3, gen_loss = 1.1727170846521606, disc_loss = 0.0007830571824444663
Trained batch 482 in epoch 3, gen_loss = 1.1724234600985273, disc_loss = 0.0007841204397376014
Trained batch 483 in epoch 3, gen_loss = 1.1719918388965702, disc_loss = 0.0007841556895779704
Trained batch 484 in epoch 3, gen_loss = 1.1718524347875536, disc_loss = 0.0007834331581030598
Trained batch 485 in epoch 3, gen_loss = 1.1723546662938937, disc_loss = 0.0007830943903344906
Trained batch 486 in epoch 3, gen_loss = 1.172533339298726, disc_loss = 0.0007826848740790334
Trained batch 487 in epoch 3, gen_loss = 1.1726441026711074, disc_loss = 0.0007828010614905563
Trained batch 488 in epoch 3, gen_loss = 1.1722575279832617, disc_loss = 0.0007823996086295881
Trained batch 489 in epoch 3, gen_loss = 1.172140688312297, disc_loss = 0.0007835746182981708
Trained batch 490 in epoch 3, gen_loss = 1.1727621657299656, disc_loss = 0.0007852755365511516
Trained batch 491 in epoch 3, gen_loss = 1.1726330208584546, disc_loss = 0.0007863185578534603
Trained batch 492 in epoch 3, gen_loss = 1.1723377264537385, disc_loss = 0.000787269603502351
Trained batch 493 in epoch 3, gen_loss = 1.172487386807739, disc_loss = 0.0007903282317040236
Trained batch 494 in epoch 3, gen_loss = 1.172028932426915, disc_loss = 0.0007940795821445815
Trained batch 495 in epoch 3, gen_loss = 1.171882858199458, disc_loss = 0.0007969923602309615
Trained batch 496 in epoch 3, gen_loss = 1.1722605638580783, disc_loss = 0.0008016002500723481
Trained batch 497 in epoch 3, gen_loss = 1.171903732909735, disc_loss = 0.0008043004132947046
Trained batch 498 in epoch 3, gen_loss = 1.1720328523305232, disc_loss = 0.0008045617064481175
Trained batch 499 in epoch 3, gen_loss = 1.1719825764894485, disc_loss = 0.0008041562150174287
Trained batch 500 in epoch 3, gen_loss = 1.172491910333881, disc_loss = 0.000804654494137782
Trained batch 501 in epoch 3, gen_loss = 1.1724144340273868, disc_loss = 0.0008049147310877771
Trained batch 502 in epoch 3, gen_loss = 1.172356001069958, disc_loss = 0.0008047158127383534
Trained batch 503 in epoch 3, gen_loss = 1.1723694144969894, disc_loss = 0.0008050763149113332
Trained batch 504 in epoch 3, gen_loss = 1.1724733599341741, disc_loss = 0.0008044347858303088
Trained batch 505 in epoch 3, gen_loss = 1.1724880977346022, disc_loss = 0.0008040301625931124
Trained batch 506 in epoch 3, gen_loss = 1.1720998611675917, disc_loss = 0.0008037201576593885
Trained batch 507 in epoch 3, gen_loss = 1.1722331530465855, disc_loss = 0.0008029971436694114
Trained batch 508 in epoch 3, gen_loss = 1.171850358339096, disc_loss = 0.0008026971001155612
Trained batch 509 in epoch 3, gen_loss = 1.171718363902148, disc_loss = 0.000802192305797921
Trained batch 510 in epoch 3, gen_loss = 1.171826626456647, disc_loss = 0.0008013892652903849
Trained batch 511 in epoch 3, gen_loss = 1.1713810109067708, disc_loss = 0.0008029152017741126
Trained batch 512 in epoch 3, gen_loss = 1.1713031820851227, disc_loss = 0.0008052465892303826
Trained batch 513 in epoch 3, gen_loss = 1.171784813533961, disc_loss = 0.0008075451292358031
Trained batch 514 in epoch 3, gen_loss = 1.1717069202256434, disc_loss = 0.0008090132987296245
Trained batch 515 in epoch 3, gen_loss = 1.171681289756021, disc_loss = 0.0008091426209640029
Trained batch 516 in epoch 3, gen_loss = 1.171571309838581, disc_loss = 0.0008089275714232923
Trained batch 517 in epoch 3, gen_loss = 1.1713327940366443, disc_loss = 0.0008086907509864941
Trained batch 518 in epoch 3, gen_loss = 1.1717149313244977, disc_loss = 0.000808994933420672
Trained batch 519 in epoch 3, gen_loss = 1.1717894214850206, disc_loss = 0.0008096471136433628
Trained batch 520 in epoch 3, gen_loss = 1.1718323102610582, disc_loss = 0.000809714649110137
Trained batch 521 in epoch 3, gen_loss = 1.1716427912657288, disc_loss = 0.0008090259217096482
Trained batch 522 in epoch 3, gen_loss = 1.1714238482269228, disc_loss = 0.0008081694956444627
Trained batch 523 in epoch 3, gen_loss = 1.1718231871837879, disc_loss = 0.0008073289117912268
Trained batch 524 in epoch 3, gen_loss = 1.1718320574079242, disc_loss = 0.0008067909759813033
Trained batch 525 in epoch 3, gen_loss = 1.1719925498781096, disc_loss = 0.00080647135014312
Trained batch 526 in epoch 3, gen_loss = 1.1715537643296896, disc_loss = 0.0008059918270055364
Trained batch 527 in epoch 3, gen_loss = 1.171710498518113, disc_loss = 0.0008056107932464907
Trained batch 528 in epoch 3, gen_loss = 1.1715651929716533, disc_loss = 0.0008051294551681224
Trained batch 529 in epoch 3, gen_loss = 1.1720582346871213, disc_loss = 0.0008050022678359693
Trained batch 530 in epoch 3, gen_loss = 1.1717105535913097, disc_loss = 0.0008065454169821517
Trained batch 531 in epoch 3, gen_loss = 1.1719486529665781, disc_loss = 0.0008095691289480941
Trained batch 532 in epoch 3, gen_loss = 1.1719485559338252, disc_loss = 0.0008117145825451324
Trained batch 533 in epoch 3, gen_loss = 1.1719635341051367, disc_loss = 0.000815186788294637
Trained batch 534 in epoch 3, gen_loss = 1.1718453001753193, disc_loss = 0.0008193429064160109
Trained batch 535 in epoch 3, gen_loss = 1.1716141936494344, disc_loss = 0.0008221998170429559
Trained batch 536 in epoch 3, gen_loss = 1.1714608562725217, disc_loss = 0.0008223519143871738
Trained batch 537 in epoch 3, gen_loss = 1.1716902176243664, disc_loss = 0.0008216694269325414
Trained batch 538 in epoch 3, gen_loss = 1.1722344056131224, disc_loss = 0.0008218398229735221
Trained batch 539 in epoch 3, gen_loss = 1.1719817638397216, disc_loss = 0.0008216938947885798
Trained batch 540 in epoch 3, gen_loss = 1.1718134194777765, disc_loss = 0.0008210292670072285
Trained batch 541 in epoch 3, gen_loss = 1.171949165993511, disc_loss = 0.0008203596133849158
Trained batch 542 in epoch 3, gen_loss = 1.1716687231432668, disc_loss = 0.0008195690413464022
Trained batch 543 in epoch 3, gen_loss = 1.1718307860633905, disc_loss = 0.0008191564889945285
Trained batch 544 in epoch 3, gen_loss = 1.1722555543304582, disc_loss = 0.0008192247148536983
Trained batch 545 in epoch 3, gen_loss = 1.1720248045938793, disc_loss = 0.0008198043438164609
Trained batch 546 in epoch 3, gen_loss = 1.1724340255343282, disc_loss = 0.0008200924247692695
Trained batch 547 in epoch 3, gen_loss = 1.1726931640266502, disc_loss = 0.0008193708633709559
Trained batch 548 in epoch 3, gen_loss = 1.1727682551833885, disc_loss = 0.0008182456827267007
Trained batch 549 in epoch 3, gen_loss = 1.1727812170982361, disc_loss = 0.0008174772475930777
Trained batch 550 in epoch 3, gen_loss = 1.173156821792658, disc_loss = 0.0008174167664344685
Trained batch 551 in epoch 3, gen_loss = 1.1734304920486782, disc_loss = 0.0008173504674746453
Trained batch 552 in epoch 3, gen_loss = 1.1736528718234402, disc_loss = 0.0008167427904300971
Trained batch 553 in epoch 3, gen_loss = 1.1740773468671724, disc_loss = 0.0008160715668133564
Trained batch 554 in epoch 3, gen_loss = 1.174205030192126, disc_loss = 0.0008152432119377327
Trained batch 555 in epoch 3, gen_loss = 1.1737866638590106, disc_loss = 0.0008146474642508241
Trained batch 556 in epoch 3, gen_loss = 1.1733927139259968, disc_loss = 0.0008162056477121754
Trained batch 557 in epoch 3, gen_loss = 1.1733960328777204, disc_loss = 0.0008184524047719215
Trained batch 558 in epoch 3, gen_loss = 1.1734053624763898, disc_loss = 0.0008189972754141352
Trained batch 559 in epoch 3, gen_loss = 1.1733167904828277, disc_loss = 0.0008187673397644955
Trained batch 560 in epoch 3, gen_loss = 1.1731929958610399, disc_loss = 0.0008185900393549732
Trained batch 561 in epoch 3, gen_loss = 1.173168400110299, disc_loss = 0.0008181210531061018
Trained batch 562 in epoch 3, gen_loss = 1.1727971273671247, disc_loss = 0.0008173379387465003
Trained batch 563 in epoch 3, gen_loss = 1.1727083186942635, disc_loss = 0.0008162208027026784
Trained batch 564 in epoch 3, gen_loss = 1.1732175659289403, disc_loss = 0.0008152317182847043
Trained batch 565 in epoch 3, gen_loss = 1.173105191110301, disc_loss = 0.0008145206368105839
Trained batch 566 in epoch 3, gen_loss = 1.1730538386936962, disc_loss = 0.0008138220852359594
Trained batch 567 in epoch 3, gen_loss = 1.1725422504922034, disc_loss = 0.000813541660917649
Trained batch 568 in epoch 3, gen_loss = 1.1721920615130863, disc_loss = 0.000813077187587291
Trained batch 569 in epoch 3, gen_loss = 1.1720828510167305, disc_loss = 0.0008123829792582495
Trained batch 570 in epoch 3, gen_loss = 1.1720704159678177, disc_loss = 0.000812657876475388
Trained batch 571 in epoch 3, gen_loss = 1.1721191716777695, disc_loss = 0.0008129796183025351
Trained batch 572 in epoch 3, gen_loss = 1.1723246112543875, disc_loss = 0.0008129020614712458
Trained batch 573 in epoch 3, gen_loss = 1.1723976222480215, disc_loss = 0.0008123716419225621
Trained batch 574 in epoch 3, gen_loss = 1.1721039521175882, disc_loss = 0.0008117388936680863
Trained batch 575 in epoch 3, gen_loss = 1.1719594684739907, disc_loss = 0.0008109351733512287
Trained batch 576 in epoch 3, gen_loss = 1.1717143893448485, disc_loss = 0.0008100956206323346
Trained batch 577 in epoch 3, gen_loss = 1.1712841382282415, disc_loss = 0.0008092304045093974
Trained batch 578 in epoch 3, gen_loss = 1.1710295509386146, disc_loss = 0.0008082505049284898
Trained batch 579 in epoch 3, gen_loss = 1.1709434107459824, disc_loss = 0.0008072523760974632
Trained batch 580 in epoch 3, gen_loss = 1.1711050792117947, disc_loss = 0.0008062147171961515
Trained batch 581 in epoch 3, gen_loss = 1.1714637348127528, disc_loss = 0.0008052859246169531
Trained batch 582 in epoch 3, gen_loss = 1.1715923311575405, disc_loss = 0.0008043770544403863
Trained batch 583 in epoch 3, gen_loss = 1.171544523986235, disc_loss = 0.0008033426830940561
Trained batch 584 in epoch 3, gen_loss = 1.1713021081736965, disc_loss = 0.00080266414821132
Trained batch 585 in epoch 3, gen_loss = 1.1712725865352682, disc_loss = 0.0008026191549742778
Trained batch 586 in epoch 3, gen_loss = 1.1714302866990969, disc_loss = 0.0008022302897128211
Trained batch 587 in epoch 3, gen_loss = 1.1719972155734795, disc_loss = 0.0008017100001959333
Trained batch 588 in epoch 3, gen_loss = 1.1719963300612666, disc_loss = 0.0008010214077251851
Trained batch 589 in epoch 3, gen_loss = 1.1720181217638113, disc_loss = 0.000800056017661996
Trained batch 590 in epoch 3, gen_loss = 1.1721913367761976, disc_loss = 0.0007996592317247297
Trained batch 591 in epoch 3, gen_loss = 1.1724333286889501, disc_loss = 0.0008000716175661797
Trained batch 592 in epoch 3, gen_loss = 1.1724270390217864, disc_loss = 0.000800061380799073
Trained batch 593 in epoch 3, gen_loss = 1.172300709518118, disc_loss = 0.0007991244016587186
Trained batch 594 in epoch 3, gen_loss = 1.1724511682486334, disc_loss = 0.0007982725020499994
Trained batch 595 in epoch 3, gen_loss = 1.1724876644427344, disc_loss = 0.0007973488394318277
Trained batch 596 in epoch 3, gen_loss = 1.1729433285930448, disc_loss = 0.0007965732467490665
Trained batch 597 in epoch 3, gen_loss = 1.1727841738673757, disc_loss = 0.0007966142021484415
Trained batch 598 in epoch 3, gen_loss = 1.1723954045712848, disc_loss = 0.0007965038454975196
Trained batch 599 in epoch 3, gen_loss = 1.1727277027567227, disc_loss = 0.0007959460760321235
Trained batch 600 in epoch 3, gen_loss = 1.1728980139567333, disc_loss = 0.0007958008893256071
Trained batch 601 in epoch 3, gen_loss = 1.1727953197750143, disc_loss = 0.0007953242694139496
Trained batch 602 in epoch 3, gen_loss = 1.1728865095038912, disc_loss = 0.0007948294814274867
Trained batch 603 in epoch 3, gen_loss = 1.172620390325982, disc_loss = 0.0007953108922705218
Trained batch 604 in epoch 3, gen_loss = 1.172744658663253, disc_loss = 0.0007961539457569453
Trained batch 605 in epoch 3, gen_loss = 1.1729185828084598, disc_loss = 0.0007961384081883008
Trained batch 606 in epoch 3, gen_loss = 1.1728257688109132, disc_loss = 0.0007957696783154224
Trained batch 607 in epoch 3, gen_loss = 1.172562147931833, disc_loss = 0.000795627145467542
Trained batch 608 in epoch 3, gen_loss = 1.1723760398737904, disc_loss = 0.0007956361046417621
Trained batch 609 in epoch 3, gen_loss = 1.172473256998375, disc_loss = 0.0007956082977738125
Trained batch 610 in epoch 3, gen_loss = 1.1724846075287427, disc_loss = 0.0007955252330145477
Trained batch 611 in epoch 3, gen_loss = 1.1725713216206606, disc_loss = 0.0007952132186058412
Trained batch 612 in epoch 3, gen_loss = 1.172481033483104, disc_loss = 0.0007945659755226635
Trained batch 613 in epoch 3, gen_loss = 1.1724045751343333, disc_loss = 0.0007940223979233181
Trained batch 614 in epoch 3, gen_loss = 1.1723932588972696, disc_loss = 0.0007932322008707523
Trained batch 615 in epoch 3, gen_loss = 1.1725255847944842, disc_loss = 0.0007922880013683862
Trained batch 616 in epoch 3, gen_loss = 1.1724487642608161, disc_loss = 0.000791328500463277
Trained batch 617 in epoch 3, gen_loss = 1.172525050281321, disc_loss = 0.0007903654161796598
Trained batch 618 in epoch 3, gen_loss = 1.1725846125544177, disc_loss = 0.0007894128890001322
Trained batch 619 in epoch 3, gen_loss = 1.172684042588357, disc_loss = 0.0007884676074853257
Trained batch 620 in epoch 3, gen_loss = 1.1724996936302061, disc_loss = 0.000787734572555204
Trained batch 621 in epoch 3, gen_loss = 1.1723627717356973, disc_loss = 0.0007877648860280525
Trained batch 622 in epoch 3, gen_loss = 1.1722801413811612, disc_loss = 0.00078762565875115
Trained batch 623 in epoch 3, gen_loss = 1.1721253331081989, disc_loss = 0.000787142915914256
Trained batch 624 in epoch 3, gen_loss = 1.1724651009559632, disc_loss = 0.0007884923415724188
Trained batch 625 in epoch 3, gen_loss = 1.1724238754651797, disc_loss = 0.0007901961116745812
Trained batch 626 in epoch 3, gen_loss = 1.172471341238828, disc_loss = 0.0007905358318376847
Trained batch 627 in epoch 3, gen_loss = 1.1725226622668041, disc_loss = 0.0007903466420007164
Trained batch 628 in epoch 3, gen_loss = 1.1721669344530576, disc_loss = 0.0007897528664920396
Trained batch 629 in epoch 3, gen_loss = 1.1720402549183557, disc_loss = 0.0007891641652104371
Trained batch 630 in epoch 3, gen_loss = 1.1720600506016268, disc_loss = 0.0007884502149369308
Trained batch 631 in epoch 3, gen_loss = 1.1720632424082937, disc_loss = 0.0007874552585822648
Trained batch 632 in epoch 3, gen_loss = 1.1722784215616766, disc_loss = 0.0007866416902591785
Trained batch 633 in epoch 3, gen_loss = 1.1724426575263591, disc_loss = 0.0007860544203760026
Trained batch 634 in epoch 3, gen_loss = 1.172454090381232, disc_loss = 0.0007857777473450763
Trained batch 635 in epoch 3, gen_loss = 1.1725166402522873, disc_loss = 0.000785738547605685
Trained batch 636 in epoch 3, gen_loss = 1.172409493657446, disc_loss = 0.0007850564955503445
Trained batch 637 in epoch 3, gen_loss = 1.1725460492705102, disc_loss = 0.0007846596585364055
Trained batch 638 in epoch 3, gen_loss = 1.1724250355796635, disc_loss = 0.0007851189954759457
Trained batch 639 in epoch 3, gen_loss = 1.1721911946311594, disc_loss = 0.0007867763024023589
Trained batch 640 in epoch 3, gen_loss = 1.172175307913615, disc_loss = 0.0007888796935333796
Trained batch 641 in epoch 3, gen_loss = 1.1722564179206563, disc_loss = 0.0007898776328776502
Trained batch 642 in epoch 3, gen_loss = 1.1722129638977408, disc_loss = 0.0007901111675892025
Trained batch 643 in epoch 3, gen_loss = 1.1719153688190886, disc_loss = 0.0007900280887618956
Trained batch 644 in epoch 3, gen_loss = 1.1722090153731117, disc_loss = 0.0007910029214983733
Trained batch 645 in epoch 3, gen_loss = 1.1722183661195147, disc_loss = 0.0007929199557854497
Trained batch 646 in epoch 3, gen_loss = 1.1721293063952345, disc_loss = 0.0007935207299985296
Trained batch 647 in epoch 3, gen_loss = 1.1720523626348118, disc_loss = 0.0007931303412471697
Trained batch 648 in epoch 3, gen_loss = 1.172141706814935, disc_loss = 0.0007924865392246248
Trained batch 649 in epoch 3, gen_loss = 1.1720791127131536, disc_loss = 0.0007927045687280881
Trained batch 650 in epoch 3, gen_loss = 1.1717895811420798, disc_loss = 0.0007928896970945352
Trained batch 651 in epoch 3, gen_loss = 1.1719417528140765, disc_loss = 0.0007933209748600147
Trained batch 652 in epoch 3, gen_loss = 1.1718300834731705, disc_loss = 0.000794642655072651
Trained batch 653 in epoch 3, gen_loss = 1.171922604607515, disc_loss = 0.0007959627933531077
Trained batch 654 in epoch 3, gen_loss = 1.1718390038905253, disc_loss = 0.0007975392136900536
Trained batch 655 in epoch 3, gen_loss = 1.1716198036220016, disc_loss = 0.0007978110505330445
Trained batch 656 in epoch 3, gen_loss = 1.1716951400359108, disc_loss = 0.0007977196994582063
Trained batch 657 in epoch 3, gen_loss = 1.1717758231249986, disc_loss = 0.0007974121432629695
Trained batch 658 in epoch 3, gen_loss = 1.1718019062542953, disc_loss = 0.0007968647377682095
Trained batch 659 in epoch 3, gen_loss = 1.171716092752688, disc_loss = 0.0007962763792337765
Trained batch 660 in epoch 3, gen_loss = 1.1718708069349741, disc_loss = 0.0007958180340568418
Trained batch 661 in epoch 3, gen_loss = 1.1720997419242052, disc_loss = 0.0007959807648522543
Trained batch 662 in epoch 3, gen_loss = 1.1720758696307245, disc_loss = 0.0007975461504644775
Trained batch 663 in epoch 3, gen_loss = 1.1720018785402, disc_loss = 0.0007995798140578393
Trained batch 664 in epoch 3, gen_loss = 1.1715202241015614, disc_loss = 0.000802070225888331
Trained batch 665 in epoch 3, gen_loss = 1.1715363970210961, disc_loss = 0.0008036817099137634
Trained batch 666 in epoch 3, gen_loss = 1.1715511241774152, disc_loss = 0.0008045481602997119
Trained batch 667 in epoch 3, gen_loss = 1.17164522114985, disc_loss = 0.0008052187836446665
Trained batch 668 in epoch 3, gen_loss = 1.1713344311322154, disc_loss = 0.0008051939244171179
Trained batch 669 in epoch 3, gen_loss = 1.1713365271909912, disc_loss = 0.0008048747531955006
Trained batch 670 in epoch 3, gen_loss = 1.1710346513462493, disc_loss = 0.0008047346359943962
Trained batch 671 in epoch 3, gen_loss = 1.1708588196585576, disc_loss = 0.000804384493546552
Trained batch 672 in epoch 3, gen_loss = 1.170628809911181, disc_loss = 0.0008037795912855641
Trained batch 673 in epoch 3, gen_loss = 1.1704460011922286, disc_loss = 0.0008045132475326843
Trained batch 674 in epoch 3, gen_loss = 1.1703448939323424, disc_loss = 0.0008058995030458189
Trained batch 675 in epoch 3, gen_loss = 1.170288174021879, disc_loss = 0.0008058935999591317
Trained batch 676 in epoch 3, gen_loss = 1.1705433920003816, disc_loss = 0.0008056765842059574
Trained batch 677 in epoch 3, gen_loss = 1.1705706526572022, disc_loss = 0.0008058877695564065
Trained batch 678 in epoch 3, gen_loss = 1.170464657806683, disc_loss = 0.0008059077262580093
Trained batch 679 in epoch 3, gen_loss = 1.1707651691401706, disc_loss = 0.0008058250654464834
Trained batch 680 in epoch 3, gen_loss = 1.170650678496704, disc_loss = 0.0008057999250184329
Trained batch 681 in epoch 3, gen_loss = 1.1706637331991951, disc_loss = 0.0008057155150935857
Trained batch 682 in epoch 3, gen_loss = 1.170569441416253, disc_loss = 0.0008054663003868891
Trained batch 683 in epoch 3, gen_loss = 1.1702849501580523, disc_loss = 0.000805120832500884
Trained batch 684 in epoch 3, gen_loss = 1.1703706914491028, disc_loss = 0.0008050890699331479
Trained batch 685 in epoch 3, gen_loss = 1.1705879271030426, disc_loss = 0.0008053999344031557
Trained batch 686 in epoch 3, gen_loss = 1.1703731304866951, disc_loss = 0.0008054985083131936
Trained batch 687 in epoch 3, gen_loss = 1.1700637583122697, disc_loss = 0.0008051070447880532
Trained batch 688 in epoch 3, gen_loss = 1.1701245010331685, disc_loss = 0.0008048198216865772
Trained batch 689 in epoch 3, gen_loss = 1.1701818155205768, disc_loss = 0.0008048171677333101
Trained batch 690 in epoch 3, gen_loss = 1.170295577663416, disc_loss = 0.0008046019421138986
Trained batch 691 in epoch 3, gen_loss = 1.1703501695153342, disc_loss = 0.0008042645321454385
Trained batch 692 in epoch 3, gen_loss = 1.1703931930949334, disc_loss = 0.0008039196876659156
Trained batch 693 in epoch 3, gen_loss = 1.1701724206336293, disc_loss = 0.0008035075533494316
Trained batch 694 in epoch 3, gen_loss = 1.1700307225151885, disc_loss = 0.0008028568317209163
Trained batch 695 in epoch 3, gen_loss = 1.1698823704801757, disc_loss = 0.0008031427024779359
Trained batch 696 in epoch 3, gen_loss = 1.1697160958217583, disc_loss = 0.0008037700086472612
Trained batch 697 in epoch 3, gen_loss = 1.1693645969332118, disc_loss = 0.0008040949541983331
Trained batch 698 in epoch 3, gen_loss = 1.1689616899633613, disc_loss = 0.0008050527555024643
Trained batch 699 in epoch 3, gen_loss = 1.1688816781554903, disc_loss = 0.0008057720010401681
Trained batch 700 in epoch 3, gen_loss = 1.1692581398680955, disc_loss = 0.000806119797745329
Trained batch 701 in epoch 3, gen_loss = 1.169198204564233, disc_loss = 0.0008057010101527241
Trained batch 702 in epoch 3, gen_loss = 1.1693931388142778, disc_loss = 0.0008056747551065515
Trained batch 703 in epoch 3, gen_loss = 1.1695251931351693, disc_loss = 0.0008062365897620276
Trained batch 704 in epoch 3, gen_loss = 1.1695388147171508, disc_loss = 0.0008064572051240145
Trained batch 705 in epoch 3, gen_loss = 1.1698814666811534, disc_loss = 0.0008063845610326531
Trained batch 706 in epoch 3, gen_loss = 1.1698250285806886, disc_loss = 0.0008062865099997445
Trained batch 707 in epoch 3, gen_loss = 1.16993551377186, disc_loss = 0.0008066472645762171
Trained batch 708 in epoch 3, gen_loss = 1.1703522798036488, disc_loss = 0.0008075647970677284
Trained batch 709 in epoch 3, gen_loss = 1.1700937955312325, disc_loss = 0.0008088418241577144
Trained batch 710 in epoch 3, gen_loss = 1.1701848180820502, disc_loss = 0.0008086390602900142
Trained batch 711 in epoch 3, gen_loss = 1.170315626883105, disc_loss = 0.0008079443655690973
Trained batch 712 in epoch 3, gen_loss = 1.1702578326094202, disc_loss = 0.0008074098613947828
Trained batch 713 in epoch 3, gen_loss = 1.1702536392111738, disc_loss = 0.0008069551482187526
Trained batch 714 in epoch 3, gen_loss = 1.1699704387804846, disc_loss = 0.0008070819303751565
Trained batch 715 in epoch 3, gen_loss = 1.1699259651606309, disc_loss = 0.0008075983326474996
Trained batch 716 in epoch 3, gen_loss = 1.1696411934025284, disc_loss = 0.0008079761685836006
Trained batch 717 in epoch 3, gen_loss = 1.1695444516650813, disc_loss = 0.0008083429813552336
Trained batch 718 in epoch 3, gen_loss = 1.1693370845453797, disc_loss = 0.0008086883703406035
Trained batch 719 in epoch 3, gen_loss = 1.1693448287745316, disc_loss = 0.0008086773198253165
Trained batch 720 in epoch 3, gen_loss = 1.1695855618680564, disc_loss = 0.0008083890421812045
Trained batch 721 in epoch 3, gen_loss = 1.1693586770682454, disc_loss = 0.0008080140727835287
Trained batch 722 in epoch 3, gen_loss = 1.1695262023027506, disc_loss = 0.0008090718839005831
Trained batch 723 in epoch 3, gen_loss = 1.1693176180124283, disc_loss = 0.0008110712651865691
Trained batch 724 in epoch 3, gen_loss = 1.1690510229406685, disc_loss = 0.000812394965504264
Trained batch 725 in epoch 3, gen_loss = 1.1688980342763844, disc_loss = 0.0008127106029409453
Trained batch 726 in epoch 3, gen_loss = 1.168894939196323, disc_loss = 0.0008122766741290125
Trained batch 727 in epoch 3, gen_loss = 1.1690434794668312, disc_loss = 0.000811542184357557
Trained batch 728 in epoch 3, gen_loss = 1.169124822802995, disc_loss = 0.000810800511559244
Trained batch 729 in epoch 3, gen_loss = 1.1693586013904989, disc_loss = 0.0008103856245176994
Trained batch 730 in epoch 3, gen_loss = 1.1697081478284583, disc_loss = 0.000810426946381609
Trained batch 731 in epoch 3, gen_loss = 1.1696868397987605, disc_loss = 0.0008102999035557834
Trained batch 732 in epoch 3, gen_loss = 1.1698429873175056, disc_loss = 0.0008097171946158722
Trained batch 733 in epoch 3, gen_loss = 1.1696668242076438, disc_loss = 0.000809066855568789
Trained batch 734 in epoch 3, gen_loss = 1.1698692713465009, disc_loss = 0.0008091709015852943
Trained batch 735 in epoch 3, gen_loss = 1.1701350996837667, disc_loss = 0.0008100030446139103
Trained batch 736 in epoch 3, gen_loss = 1.1701104211516102, disc_loss = 0.0008113992072229894
Trained batch 737 in epoch 3, gen_loss = 1.1701123069133863, disc_loss = 0.0008123382136634574
Trained batch 738 in epoch 3, gen_loss = 1.1700752627543087, disc_loss = 0.0008136756331893
Trained batch 739 in epoch 3, gen_loss = 1.1701445204986107, disc_loss = 0.0008158124725309176
Trained batch 740 in epoch 3, gen_loss = 1.1699297670249835, disc_loss = 0.0008166459237895252
Trained batch 741 in epoch 3, gen_loss = 1.1699704729482492, disc_loss = 0.0008173132276995925
Trained batch 742 in epoch 3, gen_loss = 1.1698775171912694, disc_loss = 0.0008179049988742291
Trained batch 743 in epoch 3, gen_loss = 1.1698012303120346, disc_loss = 0.0008173606300808525
Trained batch 744 in epoch 3, gen_loss = 1.1695493308489755, disc_loss = 0.0008169204527559072
Trained batch 745 in epoch 3, gen_loss = 1.169521262834283, disc_loss = 0.0008164450212415487
Trained batch 746 in epoch 3, gen_loss = 1.1698899790145945, disc_loss = 0.0008159754513401334
Trained batch 747 in epoch 3, gen_loss = 1.1699020860188785, disc_loss = 0.0008155963229380279
Trained batch 748 in epoch 3, gen_loss = 1.169857782658652, disc_loss = 0.0008147986359527156
Trained batch 749 in epoch 3, gen_loss = 1.1696512733300526, disc_loss = 0.0008143422346135291
Trained batch 750 in epoch 3, gen_loss = 1.1696933216642287, disc_loss = 0.0008148742782842733
Trained batch 751 in epoch 3, gen_loss = 1.1695354066472103, disc_loss = 0.0008155836162296373
Trained batch 752 in epoch 3, gen_loss = 1.1693171238202655, disc_loss = 0.0008160616848056587
Trained batch 753 in epoch 3, gen_loss = 1.1692142217007493, disc_loss = 0.0008171925471797005
Trained batch 754 in epoch 3, gen_loss = 1.169066731266628, disc_loss = 0.0008181195652354447
Trained batch 755 in epoch 3, gen_loss = 1.1691550083419002, disc_loss = 0.0008184216676839496
Trained batch 756 in epoch 3, gen_loss = 1.1692098841327028, disc_loss = 0.0008180828584068057
Trained batch 757 in epoch 3, gen_loss = 1.1690785998876616, disc_loss = 0.0008173102487345831
Trained batch 758 in epoch 3, gen_loss = 1.1688924037577764, disc_loss = 0.0008172542068621693
Trained batch 759 in epoch 3, gen_loss = 1.1687090849405841, disc_loss = 0.0008187517943664907
Trained batch 760 in epoch 3, gen_loss = 1.1688838450730081, disc_loss = 0.0008197623801164625
Trained batch 761 in epoch 3, gen_loss = 1.1687344970509137, disc_loss = 0.0008199221779095202
Trained batch 762 in epoch 3, gen_loss = 1.168613394856609, disc_loss = 0.0008193421076904179
Trained batch 763 in epoch 3, gen_loss = 1.1686164325600519, disc_loss = 0.000818825719514051
Trained batch 764 in epoch 3, gen_loss = 1.1685929338137309, disc_loss = 0.0008183281044087683
Trained batch 765 in epoch 3, gen_loss = 1.168429891138724, disc_loss = 0.0008177942629317223
Trained batch 766 in epoch 3, gen_loss = 1.1682296334686926, disc_loss = 0.0008174124528947462
Trained batch 767 in epoch 3, gen_loss = 1.1682146844298888, disc_loss = 0.0008171120684702752
Trained batch 768 in epoch 3, gen_loss = 1.1681699676073418, disc_loss = 0.0008183519456586141
Trained batch 769 in epoch 3, gen_loss = 1.167904229365386, disc_loss = 0.0008202522924863854
Trained batch 770 in epoch 3, gen_loss = 1.1677350890466367, disc_loss = 0.0008222475246399165
Trained batch 771 in epoch 3, gen_loss = 1.167620021212904, disc_loss = 0.0008225858585607114
Trained batch 772 in epoch 3, gen_loss = 1.1676567713471002, disc_loss = 0.0008223393825170455
Trained batch 773 in epoch 3, gen_loss = 1.1677607036838236, disc_loss = 0.0008217619804180232
Trained batch 774 in epoch 3, gen_loss = 1.1678604260567695, disc_loss = 0.0008215098999883799
Trained batch 775 in epoch 3, gen_loss = 1.1677316853526942, disc_loss = 0.0008211174957715539
Trained batch 776 in epoch 3, gen_loss = 1.167591537671353, disc_loss = 0.0008204507870092315
Trained batch 777 in epoch 3, gen_loss = 1.1680112103416864, disc_loss = 0.0008196729886034925
Trained batch 778 in epoch 3, gen_loss = 1.1679579476336919, disc_loss = 0.0008188983856750275
Trained batch 779 in epoch 3, gen_loss = 1.1676430827532058, disc_loss = 0.0008183020906028851
Trained batch 780 in epoch 3, gen_loss = 1.1675259125217432, disc_loss = 0.0008179120018742275
Trained batch 781 in epoch 3, gen_loss = 1.1673978364376156, disc_loss = 0.00081740099393874
Trained batch 782 in epoch 3, gen_loss = 1.1676565541161432, disc_loss = 0.0008166784296723054
Trained batch 783 in epoch 3, gen_loss = 1.1674454099669749, disc_loss = 0.0008164710017289119
Trained batch 784 in epoch 3, gen_loss = 1.167540459723989, disc_loss = 0.0008165340385493187
Trained batch 785 in epoch 3, gen_loss = 1.1674980572768447, disc_loss = 0.0008159437043046988
Trained batch 786 in epoch 3, gen_loss = 1.1674535994002597, disc_loss = 0.0008152134382315963
Trained batch 787 in epoch 3, gen_loss = 1.1672860580652498, disc_loss = 0.0008146843997172735
Trained batch 788 in epoch 3, gen_loss = 1.1675585104938695, disc_loss = 0.0008144822476527044
Trained batch 789 in epoch 3, gen_loss = 1.167738066443914, disc_loss = 0.0008139824190602897
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 1.0515224933624268, disc_loss = 0.0003039023431483656
Trained batch 1 in epoch 4, gen_loss = 1.0687945485115051, disc_loss = 0.0003683237446239218
Trained batch 2 in epoch 4, gen_loss = 1.1585973103841145, disc_loss = 0.0003278843651060015
Trained batch 3 in epoch 4, gen_loss = 1.232206642627716, disc_loss = 0.00032356946758227423
Trained batch 4 in epoch 4, gen_loss = 1.2692418098449707, disc_loss = 0.0003911115985829383
Trained batch 5 in epoch 4, gen_loss = 1.2302520672480266, disc_loss = 0.0004330528851520891
Trained batch 6 in epoch 4, gen_loss = 1.221503598349435, disc_loss = 0.0005056325005300875
Trained batch 7 in epoch 4, gen_loss = 1.254957601428032, disc_loss = 0.0005743951733165886
Trained batch 8 in epoch 4, gen_loss = 1.2461563613679674, disc_loss = 0.0005673023050702694
Trained batch 9 in epoch 4, gen_loss = 1.2408777594566345, disc_loss = 0.0005439198779640719
Trained batch 10 in epoch 4, gen_loss = 1.2302402691407637, disc_loss = 0.0005455275875812566
Trained batch 11 in epoch 4, gen_loss = 1.2283816039562225, disc_loss = 0.0005631060266750865
Trained batch 12 in epoch 4, gen_loss = 1.2334272036185632, disc_loss = 0.0005503370663903367
Trained batch 13 in epoch 4, gen_loss = 1.2504354289599828, disc_loss = 0.0005696482195552173
Trained batch 14 in epoch 4, gen_loss = 1.2371930678685505, disc_loss = 0.0005950495426077396
Trained batch 15 in epoch 4, gen_loss = 1.2430559918284416, disc_loss = 0.0006180323525768472
Trained batch 16 in epoch 4, gen_loss = 1.2365215876523186, disc_loss = 0.0006496887363027781
Trained batch 17 in epoch 4, gen_loss = 1.2458918028407626, disc_loss = 0.000695476597886429
Trained batch 18 in epoch 4, gen_loss = 1.238231332678544, disc_loss = 0.0007451001331087594
Trained batch 19 in epoch 4, gen_loss = 1.227047872543335, disc_loss = 0.0007734611441264861
Trained batch 20 in epoch 4, gen_loss = 1.235866938318525, disc_loss = 0.0007938032989234974
Trained batch 21 in epoch 4, gen_loss = 1.2379937117749995, disc_loss = 0.0008130905480356887
Trained batch 22 in epoch 4, gen_loss = 1.2380580435628477, disc_loss = 0.0008141537356372598
Trained batch 23 in epoch 4, gen_loss = 1.2465942750374477, disc_loss = 0.0008382518171856645
Trained batch 24 in epoch 4, gen_loss = 1.2490612220764161, disc_loss = 0.0008340511808637529
Trained batch 25 in epoch 4, gen_loss = 1.2412777313819299, disc_loss = 0.000824102801673759
Trained batch 26 in epoch 4, gen_loss = 1.2385987793957745, disc_loss = 0.0008209036130682324
Trained batch 27 in epoch 4, gen_loss = 1.2342623429639, disc_loss = 0.0008112012697633223
Trained batch 28 in epoch 4, gen_loss = 1.2324452276887565, disc_loss = 0.0007985526603518118
Trained batch 29 in epoch 4, gen_loss = 1.2296689391136169, disc_loss = 0.0007894625712651759
Trained batch 30 in epoch 4, gen_loss = 1.2330145835876465, disc_loss = 0.0007760162172358363
Trained batch 31 in epoch 4, gen_loss = 1.2302818484604359, disc_loss = 0.0007600542430736823
Trained batch 32 in epoch 4, gen_loss = 1.2305257573272244, disc_loss = 0.0007465008344628255
Trained batch 33 in epoch 4, gen_loss = 1.224983415182899, disc_loss = 0.0007313155314049629
Trained batch 34 in epoch 4, gen_loss = 1.2274685076304845, disc_loss = 0.0007169943211400616
Trained batch 35 in epoch 4, gen_loss = 1.2278517650233374, disc_loss = 0.0007055891223394105
Trained batch 36 in epoch 4, gen_loss = 1.2305376175287608, disc_loss = 0.0006941341200365207
Trained batch 37 in epoch 4, gen_loss = 1.2287171263443797, disc_loss = 0.000682680870675923
Trained batch 38 in epoch 4, gen_loss = 1.2245399340605125, disc_loss = 0.0006726225539564323
Trained batch 39 in epoch 4, gen_loss = 1.221976375579834, disc_loss = 0.0006654775053902995
Trained batch 40 in epoch 4, gen_loss = 1.2180862804738486, disc_loss = 0.0006605479674606879
Trained batch 41 in epoch 4, gen_loss = 1.2196181161063058, disc_loss = 0.000666818476886311
Trained batch 42 in epoch 4, gen_loss = 1.2157950373583062, disc_loss = 0.0006936529203220596
Trained batch 43 in epoch 4, gen_loss = 1.2112638706510717, disc_loss = 0.0007338539852009325
Trained batch 44 in epoch 4, gen_loss = 1.2107635047700671, disc_loss = 0.0007722469829281585
Trained batch 45 in epoch 4, gen_loss = 1.208979536657748, disc_loss = 0.0007911310891833399
Trained batch 46 in epoch 4, gen_loss = 1.2095311829384336, disc_loss = 0.0008001792339974658
Trained batch 47 in epoch 4, gen_loss = 1.2070193315545719, disc_loss = 0.0008006672705960227
Trained batch 48 in epoch 4, gen_loss = 1.2062067669265124, disc_loss = 0.0007971569626088425
Trained batch 49 in epoch 4, gen_loss = 1.2036742424964906, disc_loss = 0.0007950058841379359
Trained batch 50 in epoch 4, gen_loss = 1.2081761827655868, disc_loss = 0.0007946969691307886
Trained batch 51 in epoch 4, gen_loss = 1.2047582108240862, disc_loss = 0.0007908083974213626
Trained batch 52 in epoch 4, gen_loss = 1.2004853734430276, disc_loss = 0.000793720565336528
Trained batch 53 in epoch 4, gen_loss = 1.2011156744427152, disc_loss = 0.0008055114675597805
Trained batch 54 in epoch 4, gen_loss = 1.2003259030255404, disc_loss = 0.0008087446114090694
Trained batch 55 in epoch 4, gen_loss = 1.1980477975947517, disc_loss = 0.0008096276511163783
Trained batch 56 in epoch 4, gen_loss = 1.201576034228007, disc_loss = 0.0008102724151971767
Trained batch 57 in epoch 4, gen_loss = 1.2005223631858826, disc_loss = 0.000806308201421855
Trained batch 58 in epoch 4, gen_loss = 1.2021333827810772, disc_loss = 0.0008108947545455737
Trained batch 59 in epoch 4, gen_loss = 1.2052014688650767, disc_loss = 0.0008184378311852925
Trained batch 60 in epoch 4, gen_loss = 1.2049937658622616, disc_loss = 0.0008168393258409972
Trained batch 61 in epoch 4, gen_loss = 1.2033460505547062, disc_loss = 0.0008112457327379454
Trained batch 62 in epoch 4, gen_loss = 1.2002742763549563, disc_loss = 0.0008022704897152763
Trained batch 63 in epoch 4, gen_loss = 1.1994791459292173, disc_loss = 0.0007963150665091234
Trained batch 64 in epoch 4, gen_loss = 1.1994980390255268, disc_loss = 0.0007964042570585242
Trained batch 65 in epoch 4, gen_loss = 1.1966576702667004, disc_loss = 0.0007997996642988062
Trained batch 66 in epoch 4, gen_loss = 1.1952001087701143, disc_loss = 0.0008016961805675345
Trained batch 67 in epoch 4, gen_loss = 1.194899253985461, disc_loss = 0.0007967175047002349
Trained batch 68 in epoch 4, gen_loss = 1.199713933295098, disc_loss = 0.0007895563768756076
Trained batch 69 in epoch 4, gen_loss = 1.1982117686952864, disc_loss = 0.0007886810540055324
Trained batch 70 in epoch 4, gen_loss = 1.1997990473895006, disc_loss = 0.0007963341748519001
Trained batch 71 in epoch 4, gen_loss = 1.1986114184061687, disc_loss = 0.0008027606329253305
Trained batch 72 in epoch 4, gen_loss = 1.1970231026819307, disc_loss = 0.0008030513214578929
Trained batch 73 in epoch 4, gen_loss = 1.1970497820828412, disc_loss = 0.0007987249110875702
Trained batch 74 in epoch 4, gen_loss = 1.1973643143971762, disc_loss = 0.0007932020685014625
Trained batch 75 in epoch 4, gen_loss = 1.1969987248119556, disc_loss = 0.0007875238117872198
Trained batch 76 in epoch 4, gen_loss = 1.1974985011212238, disc_loss = 0.0007832196224390154
Trained batch 77 in epoch 4, gen_loss = 1.1984695073885796, disc_loss = 0.0007815955908975014
Trained batch 78 in epoch 4, gen_loss = 1.2006074325947822, disc_loss = 0.0007825075472628439
Trained batch 79 in epoch 4, gen_loss = 1.2010485857725144, disc_loss = 0.0007787560225551715
Trained batch 80 in epoch 4, gen_loss = 1.2029340237747004, disc_loss = 0.0007737981508353748
Trained batch 81 in epoch 4, gen_loss = 1.199523687362671, disc_loss = 0.000769696529548638
Trained batch 82 in epoch 4, gen_loss = 1.2010078387088086, disc_loss = 0.0007634866714101644
Trained batch 83 in epoch 4, gen_loss = 1.2002540273325784, disc_loss = 0.0007574651511580063
Trained batch 84 in epoch 4, gen_loss = 1.199788956081166, disc_loss = 0.0007564866069622118
Trained batch 85 in epoch 4, gen_loss = 1.199853382831396, disc_loss = 0.000758031688070163
Trained batch 86 in epoch 4, gen_loss = 1.197663684000914, disc_loss = 0.0007556248439513361
Trained batch 87 in epoch 4, gen_loss = 1.1959762302311985, disc_loss = 0.0007533417715008413
Trained batch 88 in epoch 4, gen_loss = 1.194344132134084, disc_loss = 0.0007575580185106589
Trained batch 89 in epoch 4, gen_loss = 1.192425262928009, disc_loss = 0.0007633840170456097
Trained batch 90 in epoch 4, gen_loss = 1.1915446048254494, disc_loss = 0.0007649883733432904
Trained batch 91 in epoch 4, gen_loss = 1.1919173559416896, disc_loss = 0.0007623919559789457
Trained batch 92 in epoch 4, gen_loss = 1.193760597577659, disc_loss = 0.0007571348984931065
Trained batch 93 in epoch 4, gen_loss = 1.1947462419246107, disc_loss = 0.0007532152196793678
Trained batch 94 in epoch 4, gen_loss = 1.1961725310275428, disc_loss = 0.000754621033985658
Trained batch 95 in epoch 4, gen_loss = 1.1955859611431758, disc_loss = 0.0007593571059866614
Trained batch 96 in epoch 4, gen_loss = 1.194350272109828, disc_loss = 0.0007628186809297497
Trained batch 97 in epoch 4, gen_loss = 1.1955165996843455, disc_loss = 0.0007620390040719197
Trained batch 98 in epoch 4, gen_loss = 1.1937606154066143, disc_loss = 0.0007592295320008439
Trained batch 99 in epoch 4, gen_loss = 1.1943463122844695, disc_loss = 0.0007568445685319602
Trained batch 100 in epoch 4, gen_loss = 1.1949105534223046, disc_loss = 0.0007515611720045494
Trained batch 101 in epoch 4, gen_loss = 1.1955015612583535, disc_loss = 0.000750567719817399
Trained batch 102 in epoch 4, gen_loss = 1.1958746493441388, disc_loss = 0.000749122512185476
Trained batch 103 in epoch 4, gen_loss = 1.1939664735243871, disc_loss = 0.000745875912588627
Trained batch 104 in epoch 4, gen_loss = 1.1938716933840796, disc_loss = 0.0007427711560878725
Trained batch 105 in epoch 4, gen_loss = 1.1930441901368916, disc_loss = 0.0007390094438308568
Trained batch 106 in epoch 4, gen_loss = 1.1922933943917817, disc_loss = 0.0007357881809737115
Trained batch 107 in epoch 4, gen_loss = 1.1922161159691986, disc_loss = 0.0007339013167506049
Trained batch 108 in epoch 4, gen_loss = 1.1912807127751341, disc_loss = 0.0007310823522456879
Trained batch 109 in epoch 4, gen_loss = 1.19121967012232, disc_loss = 0.0007278300065081567
Trained batch 110 in epoch 4, gen_loss = 1.192468929935146, disc_loss = 0.0007294648303860077
Trained batch 111 in epoch 4, gen_loss = 1.1920620277523994, disc_loss = 0.0007345503451818201
Trained batch 112 in epoch 4, gen_loss = 1.1908885324950766, disc_loss = 0.0007344519130193291
Trained batch 113 in epoch 4, gen_loss = 1.192071142949556, disc_loss = 0.0007329193911956329
Trained batch 114 in epoch 4, gen_loss = 1.1926301292751147, disc_loss = 0.0007297063798076756
Trained batch 115 in epoch 4, gen_loss = 1.190934622082217, disc_loss = 0.0007299079970207772
Trained batch 116 in epoch 4, gen_loss = 1.1897101493982167, disc_loss = 0.0007413466262997279
Trained batch 117 in epoch 4, gen_loss = 1.1891695947970373, disc_loss = 0.0007537127362950941
Trained batch 118 in epoch 4, gen_loss = 1.1884084449094885, disc_loss = 0.0007633813113921142
Trained batch 119 in epoch 4, gen_loss = 1.1914833505948386, disc_loss = 0.0007692987375776284
Trained batch 120 in epoch 4, gen_loss = 1.192814633865987, disc_loss = 0.0007733344951883143
Trained batch 121 in epoch 4, gen_loss = 1.1909049944799455, disc_loss = 0.0007776107661021476
Trained batch 122 in epoch 4, gen_loss = 1.1898274605836325, disc_loss = 0.0007801275549842635
Trained batch 123 in epoch 4, gen_loss = 1.1901477661824995, disc_loss = 0.0007784335865571554
Trained batch 124 in epoch 4, gen_loss = 1.1902721586227416, disc_loss = 0.0007763826842419803
Trained batch 125 in epoch 4, gen_loss = 1.1885106043210105, disc_loss = 0.0007796199915612796
Trained batch 126 in epoch 4, gen_loss = 1.187166988380312, disc_loss = 0.0007964098375972625
Trained batch 127 in epoch 4, gen_loss = 1.187868951819837, disc_loss = 0.000815710951883375
Trained batch 128 in epoch 4, gen_loss = 1.1884739288063937, disc_loss = 0.0008252931622492308
Trained batch 129 in epoch 4, gen_loss = 1.1905272841453551, disc_loss = 0.0008311588017162509
Trained batch 130 in epoch 4, gen_loss = 1.1911979768112415, disc_loss = 0.000836785190884479
Trained batch 131 in epoch 4, gen_loss = 1.190879559878147, disc_loss = 0.0008354571618838236
Trained batch 132 in epoch 4, gen_loss = 1.190655883989836, disc_loss = 0.0008347974595599773
Trained batch 133 in epoch 4, gen_loss = 1.1900988247857165, disc_loss = 0.0008435151969784621
Trained batch 134 in epoch 4, gen_loss = 1.1903347227308485, disc_loss = 0.0008451492874883115
Trained batch 135 in epoch 4, gen_loss = 1.1900705905521618, disc_loss = 0.0008435000700581655
Trained batch 136 in epoch 4, gen_loss = 1.1904153005920188, disc_loss = 0.0008465150047440327
Trained batch 137 in epoch 4, gen_loss = 1.1905802730200947, disc_loss = 0.0008491607803844618
Trained batch 138 in epoch 4, gen_loss = 1.1897717774343148, disc_loss = 0.0008486018582287399
Trained batch 139 in epoch 4, gen_loss = 1.1893182805606297, disc_loss = 0.0008472195464751816
Trained batch 140 in epoch 4, gen_loss = 1.1902991812279884, disc_loss = 0.0008451599323897497
Trained batch 141 in epoch 4, gen_loss = 1.190854591383061, disc_loss = 0.0008438836539682316
Trained batch 142 in epoch 4, gen_loss = 1.190079934113509, disc_loss = 0.0008400581260960731
Trained batch 143 in epoch 4, gen_loss = 1.1895569322837725, disc_loss = 0.000836270678822378
Trained batch 144 in epoch 4, gen_loss = 1.1903543348970085, disc_loss = 0.0008322542930696288
Trained batch 145 in epoch 4, gen_loss = 1.1901040558945644, disc_loss = 0.0008278179069349465
Trained batch 146 in epoch 4, gen_loss = 1.1896015786800256, disc_loss = 0.0008236933920293299
Trained batch 147 in epoch 4, gen_loss = 1.189725147711264, disc_loss = 0.0008201394229144097
Trained batch 148 in epoch 4, gen_loss = 1.1892868512428847, disc_loss = 0.0008165675473060371
Trained batch 149 in epoch 4, gen_loss = 1.1893549060821533, disc_loss = 0.0008131406047808317
Trained batch 150 in epoch 4, gen_loss = 1.1882486738116536, disc_loss = 0.0008104550369840966
Trained batch 151 in epoch 4, gen_loss = 1.1896537667826603, disc_loss = 0.0008082135754145719
Trained batch 152 in epoch 4, gen_loss = 1.1917323310390797, disc_loss = 0.0008064082410343271
Trained batch 153 in epoch 4, gen_loss = 1.1914980899203906, disc_loss = 0.0008046732184155118
Trained batch 154 in epoch 4, gen_loss = 1.191608731208309, disc_loss = 0.0008020257189561943
Trained batch 155 in epoch 4, gen_loss = 1.192200209085758, disc_loss = 0.0008013964572269171
Trained batch 156 in epoch 4, gen_loss = 1.1930952170851883, disc_loss = 0.0008007423928308533
Trained batch 157 in epoch 4, gen_loss = 1.1927550088001202, disc_loss = 0.0007999022762973416
Trained batch 158 in epoch 4, gen_loss = 1.1949932282825686, disc_loss = 0.0007981333800894648
Trained batch 159 in epoch 4, gen_loss = 1.1943426311016083, disc_loss = 0.0007972943224558548
Trained batch 160 in epoch 4, gen_loss = 1.1945130484444755, disc_loss = 0.0008003812366250544
Trained batch 161 in epoch 4, gen_loss = 1.1930402009575456, disc_loss = 0.0008011385283747653
Trained batch 162 in epoch 4, gen_loss = 1.1930534744555235, disc_loss = 0.0008005897168668581
Trained batch 163 in epoch 4, gen_loss = 1.1933967914523147, disc_loss = 0.000798334897742124
Trained batch 164 in epoch 4, gen_loss = 1.1925576679634324, disc_loss = 0.0007947504009776325
Trained batch 165 in epoch 4, gen_loss = 1.1936466083469162, disc_loss = 0.0007913849809724579
Trained batch 166 in epoch 4, gen_loss = 1.1932760034492629, disc_loss = 0.0007878620321980906
Trained batch 167 in epoch 4, gen_loss = 1.1938757669358027, disc_loss = 0.0007847029603345575
Trained batch 168 in epoch 4, gen_loss = 1.1929922329603568, disc_loss = 0.0007814046954866995
Trained batch 169 in epoch 4, gen_loss = 1.191195260777193, disc_loss = 0.000778549704580869
Trained batch 170 in epoch 4, gen_loss = 1.1901855803372567, disc_loss = 0.0007767247635025629
Trained batch 171 in epoch 4, gen_loss = 1.1902854969335157, disc_loss = 0.0007738945405858537
Trained batch 172 in epoch 4, gen_loss = 1.1893829513836458, disc_loss = 0.0007714782558035676
Trained batch 173 in epoch 4, gen_loss = 1.1889617354020305, disc_loss = 0.0007687067386698267
Trained batch 174 in epoch 4, gen_loss = 1.1902296141215734, disc_loss = 0.0007664028790480058
Trained batch 175 in epoch 4, gen_loss = 1.1893261887810447, disc_loss = 0.0007653528190613459
Trained batch 176 in epoch 4, gen_loss = 1.1891167594888117, disc_loss = 0.0007657688465410065
Trained batch 177 in epoch 4, gen_loss = 1.189696003881733, disc_loss = 0.0007653049378246435
Trained batch 178 in epoch 4, gen_loss = 1.189603051659781, disc_loss = 0.0007642308566634746
Trained batch 179 in epoch 4, gen_loss = 1.1881023546059926, disc_loss = 0.0007634995776041049
Trained batch 180 in epoch 4, gen_loss = 1.1905265947731818, disc_loss = 0.000767064515487754
Trained batch 181 in epoch 4, gen_loss = 1.1908724491412823, disc_loss = 0.0007784473817702127
Trained batch 182 in epoch 4, gen_loss = 1.1899112560709968, disc_loss = 0.0007933965212852526
Trained batch 183 in epoch 4, gen_loss = 1.1896376609802246, disc_loss = 0.0007997884258656995
Trained batch 184 in epoch 4, gen_loss = 1.1887167092916129, disc_loss = 0.0008066164498764871
Trained batch 185 in epoch 4, gen_loss = 1.1890796897231892, disc_loss = 0.0008152758467770983
Trained batch 186 in epoch 4, gen_loss = 1.1890082671680553, disc_loss = 0.0008203751639616153
Trained batch 187 in epoch 4, gen_loss = 1.187934107285865, disc_loss = 0.0008229763757782999
Trained batch 188 in epoch 4, gen_loss = 1.1876355406468508, disc_loss = 0.0008276140534598627
Trained batch 189 in epoch 4, gen_loss = 1.1870248446339056, disc_loss = 0.0008326924166268375
Trained batch 190 in epoch 4, gen_loss = 1.1858826033107897, disc_loss = 0.00083351977459333
Trained batch 191 in epoch 4, gen_loss = 1.1858192135890324, disc_loss = 0.000831219477807584
Trained batch 192 in epoch 4, gen_loss = 1.184780128261586, disc_loss = 0.0008302476086534337
Trained batch 193 in epoch 4, gen_loss = 1.1850136364858175, disc_loss = 0.0008295507344432876
Trained batch 194 in epoch 4, gen_loss = 1.1841017179000073, disc_loss = 0.0008321979618183552
Trained batch 195 in epoch 4, gen_loss = 1.1841481358421093, disc_loss = 0.0008366558839934071
Trained batch 196 in epoch 4, gen_loss = 1.1838252381019785, disc_loss = 0.0008386778247071109
Trained batch 197 in epoch 4, gen_loss = 1.1832696163293086, disc_loss = 0.0008384563280016683
Trained batch 198 in epoch 4, gen_loss = 1.182434024523251, disc_loss = 0.0008372180866593514
Trained batch 199 in epoch 4, gen_loss = 1.1815987122058869, disc_loss = 0.0008363472042401554
Trained batch 200 in epoch 4, gen_loss = 1.181255162651859, disc_loss = 0.0008374347389282993
Trained batch 201 in epoch 4, gen_loss = 1.1810193404112712, disc_loss = 0.0008359398476872824
Trained batch 202 in epoch 4, gen_loss = 1.1808842543897957, disc_loss = 0.0008337784517961302
Trained batch 203 in epoch 4, gen_loss = 1.1810773435760946, disc_loss = 0.0008350453493168222
Trained batch 204 in epoch 4, gen_loss = 1.181260418310398, disc_loss = 0.0008369507325568986
Trained batch 205 in epoch 4, gen_loss = 1.1809312730159574, disc_loss = 0.0008364257802401253
Trained batch 206 in epoch 4, gen_loss = 1.1809727995867891, disc_loss = 0.0008353368058752332
Trained batch 207 in epoch 4, gen_loss = 1.1815563904551358, disc_loss = 0.0008358282923207019
Trained batch 208 in epoch 4, gen_loss = 1.181775399372338, disc_loss = 0.0008359066067674558
Trained batch 209 in epoch 4, gen_loss = 1.1833951336996895, disc_loss = 0.0008355430915669006
Trained batch 210 in epoch 4, gen_loss = 1.1832586803707466, disc_loss = 0.000834171404861801
Trained batch 211 in epoch 4, gen_loss = 1.1835148300764695, disc_loss = 0.0008318273998980349
Trained batch 212 in epoch 4, gen_loss = 1.1846296395494345, disc_loss = 0.0008292244056577493
Trained batch 213 in epoch 4, gen_loss = 1.184597709468592, disc_loss = 0.0008264703957758905
Trained batch 214 in epoch 4, gen_loss = 1.1858995775843775, disc_loss = 0.000823832104635035
Trained batch 215 in epoch 4, gen_loss = 1.186239989267455, disc_loss = 0.000822903964136559
Trained batch 216 in epoch 4, gen_loss = 1.1860071673371275, disc_loss = 0.0008226060400387564
Trained batch 217 in epoch 4, gen_loss = 1.1862495454079514, disc_loss = 0.0008224682691384218
Trained batch 218 in epoch 4, gen_loss = 1.1855088837070553, disc_loss = 0.0008239685465421179
Trained batch 219 in epoch 4, gen_loss = 1.1860706296834078, disc_loss = 0.0008242148089100903
Trained batch 220 in epoch 4, gen_loss = 1.1855906679619492, disc_loss = 0.0008222433022403567
Trained batch 221 in epoch 4, gen_loss = 1.185872896297558, disc_loss = 0.0008196137756500435
Trained batch 222 in epoch 4, gen_loss = 1.1860620547837741, disc_loss = 0.000816982317725802
Trained batch 223 in epoch 4, gen_loss = 1.1868197806179523, disc_loss = 0.0008141657125893939
Trained batch 224 in epoch 4, gen_loss = 1.1880873250961304, disc_loss = 0.0008132077533001494
Trained batch 225 in epoch 4, gen_loss = 1.187490579301277, disc_loss = 0.0008156865768096476
Trained batch 226 in epoch 4, gen_loss = 1.1868411832969095, disc_loss = 0.000818813401405158
Trained batch 227 in epoch 4, gen_loss = 1.1862402526955855, disc_loss = 0.0008186948489629574
Trained batch 228 in epoch 4, gen_loss = 1.1882248705651561, disc_loss = 0.0008183292795850095
Trained batch 229 in epoch 4, gen_loss = 1.1893555651540342, disc_loss = 0.0008172224854680952
Trained batch 230 in epoch 4, gen_loss = 1.1896179584197668, disc_loss = 0.0008151565558852595
Trained batch 231 in epoch 4, gen_loss = 1.1895904001490822, disc_loss = 0.0008123752786873253
Trained batch 232 in epoch 4, gen_loss = 1.1897365929231112, disc_loss = 0.0008095470821692772
Trained batch 233 in epoch 4, gen_loss = 1.188707890164139, disc_loss = 0.000807432435790244
Trained batch 234 in epoch 4, gen_loss = 1.188603019207082, disc_loss = 0.0008056260881935583
Trained batch 235 in epoch 4, gen_loss = 1.1886514814223272, disc_loss = 0.0008032486207489224
Trained batch 236 in epoch 4, gen_loss = 1.1887024993131936, disc_loss = 0.0008018064701424731
Trained batch 237 in epoch 4, gen_loss = 1.1886525760177804, disc_loss = 0.0008008282370190332
Trained batch 238 in epoch 4, gen_loss = 1.1888054175356941, disc_loss = 0.0007992671868641116
Trained batch 239 in epoch 4, gen_loss = 1.1878661888341109, disc_loss = 0.0007970126970273365
Trained batch 240 in epoch 4, gen_loss = 1.1882319393494316, disc_loss = 0.0007946165923427218
Trained batch 241 in epoch 4, gen_loss = 1.1879501192530324, disc_loss = 0.0007923822058653382
Trained batch 242 in epoch 4, gen_loss = 1.187170727753345, disc_loss = 0.0007917168710683568
Trained batch 243 in epoch 4, gen_loss = 1.1866352968528622, disc_loss = 0.0007922136733884786
Trained batch 244 in epoch 4, gen_loss = 1.1856706619262696, disc_loss = 0.0007918344537385416
Trained batch 245 in epoch 4, gen_loss = 1.1863602012153562, disc_loss = 0.0007925940801983896
Trained batch 246 in epoch 4, gen_loss = 1.1858543379586717, disc_loss = 0.0007944917812969853
Trained batch 247 in epoch 4, gen_loss = 1.1854818770962376, disc_loss = 0.0007956889544842734
Trained batch 248 in epoch 4, gen_loss = 1.1848055947736564, disc_loss = 0.0007958731641637603
Trained batch 249 in epoch 4, gen_loss = 1.1842245144844055, disc_loss = 0.0007946523183491081
Trained batch 250 in epoch 4, gen_loss = 1.1838744346839023, disc_loss = 0.0007932239945605027
Trained batch 251 in epoch 4, gen_loss = 1.1837872635750544, disc_loss = 0.00079209149280648
Trained batch 252 in epoch 4, gen_loss = 1.1838258462461086, disc_loss = 0.0007923839335640885
Trained batch 253 in epoch 4, gen_loss = 1.1837694813886026, disc_loss = 0.0007928128233481947
Trained batch 254 in epoch 4, gen_loss = 1.1831258577458998, disc_loss = 0.0007917305193247967
Trained batch 255 in epoch 4, gen_loss = 1.1832646615803242, disc_loss = 0.0007896695132103559
Trained batch 256 in epoch 4, gen_loss = 1.183452938317325, disc_loss = 0.0007874248045404235
Trained batch 257 in epoch 4, gen_loss = 1.182893314564875, disc_loss = 0.000785500466911115
Trained batch 258 in epoch 4, gen_loss = 1.1828403182931848, disc_loss = 0.0007837236140635311
Trained batch 259 in epoch 4, gen_loss = 1.1827763231901023, disc_loss = 0.0007817909790901467
Trained batch 260 in epoch 4, gen_loss = 1.1833538401629276, disc_loss = 0.0007799597236486616
Trained batch 261 in epoch 4, gen_loss = 1.184356250835739, disc_loss = 0.0007788348286048303
Trained batch 262 in epoch 4, gen_loss = 1.1845131740823898, disc_loss = 0.0007778717380436668
Trained batch 263 in epoch 4, gen_loss = 1.1838771000956043, disc_loss = 0.0007769404036287486
Trained batch 264 in epoch 4, gen_loss = 1.1832535910156539, disc_loss = 0.0007776977040778564
Trained batch 265 in epoch 4, gen_loss = 1.183121162697785, disc_loss = 0.0007790761724721879
Trained batch 266 in epoch 4, gen_loss = 1.1827231975976893, disc_loss = 0.000778526361497147
Trained batch 267 in epoch 4, gen_loss = 1.1823836631739317, disc_loss = 0.0007765889090682213
Trained batch 268 in epoch 4, gen_loss = 1.182105928991807, disc_loss = 0.0007747243987058798
Trained batch 269 in epoch 4, gen_loss = 1.1816615771364283, disc_loss = 0.000772823692575373
Trained batch 270 in epoch 4, gen_loss = 1.1807924201127789, disc_loss = 0.000771348003699269
Trained batch 271 in epoch 4, gen_loss = 1.181370079079095, disc_loss = 0.0007700030023175606
Trained batch 272 in epoch 4, gen_loss = 1.1804928277438378, disc_loss = 0.0007684448293210673
Trained batch 273 in epoch 4, gen_loss = 1.1805688677913082, disc_loss = 0.0007676775275133075
Trained batch 274 in epoch 4, gen_loss = 1.1802503806894475, disc_loss = 0.0007676498084964061
Trained batch 275 in epoch 4, gen_loss = 1.180255999599678, disc_loss = 0.0007673272445664633
Trained batch 276 in epoch 4, gen_loss = 1.1793591804022394, disc_loss = 0.000768075636079508
Trained batch 277 in epoch 4, gen_loss = 1.1790872066141032, disc_loss = 0.0007698260679658462
Trained batch 278 in epoch 4, gen_loss = 1.178783710712173, disc_loss = 0.0007698492654624285
Trained batch 279 in epoch 4, gen_loss = 1.1785448406423842, disc_loss = 0.0007687116101026602
Trained batch 280 in epoch 4, gen_loss = 1.1792827076759202, disc_loss = 0.0007668253541029195
Trained batch 281 in epoch 4, gen_loss = 1.1791845154254994, disc_loss = 0.0007650997288028069
Trained batch 282 in epoch 4, gen_loss = 1.178375650210431, disc_loss = 0.0007652046193669849
Trained batch 283 in epoch 4, gen_loss = 1.1782437999483566, disc_loss = 0.0007660514339976812
Trained batch 284 in epoch 4, gen_loss = 1.1776425323988262, disc_loss = 0.0007651163956452684
Trained batch 285 in epoch 4, gen_loss = 1.177439890124581, disc_loss = 0.000767531592363876
Trained batch 286 in epoch 4, gen_loss = 1.1772592877677093, disc_loss = 0.0007727966695181856
Trained batch 287 in epoch 4, gen_loss = 1.177004351798031, disc_loss = 0.0007783135637914205
Trained batch 288 in epoch 4, gen_loss = 1.1766647607809944, disc_loss = 0.0007835237107321839
Trained batch 289 in epoch 4, gen_loss = 1.1772069445971785, disc_loss = 0.0007877246951403353
Trained batch 290 in epoch 4, gen_loss = 1.1768363792052383, disc_loss = 0.0007915908545359675
Trained batch 291 in epoch 4, gen_loss = 1.1770041335935462, disc_loss = 0.0007935978037868116
Trained batch 292 in epoch 4, gen_loss = 1.176513484720484, disc_loss = 0.0007950117563830416
Trained batch 293 in epoch 4, gen_loss = 1.1775944151845918, disc_loss = 0.0007968572627469505
Trained batch 294 in epoch 4, gen_loss = 1.176744391554493, disc_loss = 0.000800414271435653
Trained batch 295 in epoch 4, gen_loss = 1.1762947895236917, disc_loss = 0.0008025424972033392
Trained batch 296 in epoch 4, gen_loss = 1.1766545856841888, disc_loss = 0.0008038186366467576
Trained batch 297 in epoch 4, gen_loss = 1.1760119621785694, disc_loss = 0.000803594852601578
Trained batch 298 in epoch 4, gen_loss = 1.1753330934406523, disc_loss = 0.0008028645412396814
Trained batch 299 in epoch 4, gen_loss = 1.1750162758429845, disc_loss = 0.0008018327792524361
Trained batch 300 in epoch 4, gen_loss = 1.1749976035764447, disc_loss = 0.0008011225993285556
Trained batch 301 in epoch 4, gen_loss = 1.175670333058629, disc_loss = 0.0007998997081319388
Trained batch 302 in epoch 4, gen_loss = 1.1751675682492775, disc_loss = 0.0008011054503693009
Trained batch 303 in epoch 4, gen_loss = 1.1752878974534964, disc_loss = 0.0008048627646770145
Trained batch 304 in epoch 4, gen_loss = 1.1753432189831967, disc_loss = 0.0008051521886239348
Trained batch 305 in epoch 4, gen_loss = 1.1750366670243881, disc_loss = 0.0008042690434890307
Trained batch 306 in epoch 4, gen_loss = 1.1758233807762593, disc_loss = 0.0008074401231089771
Trained batch 307 in epoch 4, gen_loss = 1.1757607241342594, disc_loss = 0.0008124679240266575
Trained batch 308 in epoch 4, gen_loss = 1.1754152911766447, disc_loss = 0.0008171878938380821
Trained batch 309 in epoch 4, gen_loss = 1.174797620504133, disc_loss = 0.0008197790838875658
Trained batch 310 in epoch 4, gen_loss = 1.1743177438088934, disc_loss = 0.0008211709579364531
Trained batch 311 in epoch 4, gen_loss = 1.1746585542956989, disc_loss = 0.0008213731540681926
Trained batch 312 in epoch 4, gen_loss = 1.174917017499479, disc_loss = 0.0008211450593824239
Trained batch 313 in epoch 4, gen_loss = 1.1747632601838203, disc_loss = 0.0008212603536133423
Trained batch 314 in epoch 4, gen_loss = 1.1743548474614582, disc_loss = 0.0008212628721680847
Trained batch 315 in epoch 4, gen_loss = 1.1742326290924339, disc_loss = 0.0008212808403370702
Trained batch 316 in epoch 4, gen_loss = 1.1739622063065176, disc_loss = 0.0008204943761750997
Trained batch 317 in epoch 4, gen_loss = 1.1747038913597851, disc_loss = 0.0008196472654334393
Trained batch 318 in epoch 4, gen_loss = 1.1743602649918918, disc_loss = 0.000818772779665975
Trained batch 319 in epoch 4, gen_loss = 1.174085962958634, disc_loss = 0.0008181285827049579
Trained batch 320 in epoch 4, gen_loss = 1.1735833123836934, disc_loss = 0.0008172325209121153
Trained batch 321 in epoch 4, gen_loss = 1.1736835283892495, disc_loss = 0.0008158379273058164
Trained batch 322 in epoch 4, gen_loss = 1.1737760491784512, disc_loss = 0.0008141875631772789
Trained batch 323 in epoch 4, gen_loss = 1.173698815114704, disc_loss = 0.000812584657529599
Trained batch 324 in epoch 4, gen_loss = 1.1738476028809182, disc_loss = 0.000810877275115882
Trained batch 325 in epoch 4, gen_loss = 1.1739763590090113, disc_loss = 0.0008093352994504471
Trained batch 326 in epoch 4, gen_loss = 1.1740538095115522, disc_loss = 0.0008074139948508528
Trained batch 327 in epoch 4, gen_loss = 1.1740352535029737, disc_loss = 0.0008054947000168684
Trained batch 328 in epoch 4, gen_loss = 1.173227875066021, disc_loss = 0.0008037488554260413
Trained batch 329 in epoch 4, gen_loss = 1.1729988618330522, disc_loss = 0.000802647238367971
Trained batch 330 in epoch 4, gen_loss = 1.1727140061444747, disc_loss = 0.0008017827059090239
Trained batch 331 in epoch 4, gen_loss = 1.1729235702968506, disc_loss = 0.0008011546284163719
Trained batch 332 in epoch 4, gen_loss = 1.1724301913121082, disc_loss = 0.0008003999626469538
Trained batch 333 in epoch 4, gen_loss = 1.1729324859773327, disc_loss = 0.0008007124088834246
Trained batch 334 in epoch 4, gen_loss = 1.172863528265882, disc_loss = 0.0008008854005854132
Trained batch 335 in epoch 4, gen_loss = 1.173049589707738, disc_loss = 0.0008000132266239408
Trained batch 336 in epoch 4, gen_loss = 1.1729465609841956, disc_loss = 0.0007990737690401018
Trained batch 337 in epoch 4, gen_loss = 1.172195603332576, disc_loss = 0.0007985108257333346
Trained batch 338 in epoch 4, gen_loss = 1.1724167638472047, disc_loss = 0.0007978409766885768
Trained batch 339 in epoch 4, gen_loss = 1.1724817915874368, disc_loss = 0.0007967284690547625
Trained batch 340 in epoch 4, gen_loss = 1.1721243349687795, disc_loss = 0.0007957932053651399
Trained batch 341 in epoch 4, gen_loss = 1.17223133695753, disc_loss = 0.0007958652618258092
Trained batch 342 in epoch 4, gen_loss = 1.171840783979733, disc_loss = 0.0007960438267931983
Trained batch 343 in epoch 4, gen_loss = 1.1712593117425607, disc_loss = 0.0007961095612107635
Trained batch 344 in epoch 4, gen_loss = 1.1707631093868311, disc_loss = 0.0007972540537172091
Trained batch 345 in epoch 4, gen_loss = 1.1706479870515063, disc_loss = 0.000801808035322142
Trained batch 346 in epoch 4, gen_loss = 1.1702356651124761, disc_loss = 0.0008060334510168581
Trained batch 347 in epoch 4, gen_loss = 1.1700450288153244, disc_loss = 0.0008064565489144899
Trained batch 348 in epoch 4, gen_loss = 1.1695905722314786, disc_loss = 0.0008088525660358701
Trained batch 349 in epoch 4, gen_loss = 1.1701797424043927, disc_loss = 0.0008126621042278462
Trained batch 350 in epoch 4, gen_loss = 1.1699091831163804, disc_loss = 0.000814092964510383
Trained batch 351 in epoch 4, gen_loss = 1.1696396188979798, disc_loss = 0.0008135053803925985
Trained batch 352 in epoch 4, gen_loss = 1.1696299192925688, disc_loss = 0.0008125725891025573
Trained batch 353 in epoch 4, gen_loss = 1.170158536757453, disc_loss = 0.0008120439576851941
Trained batch 354 in epoch 4, gen_loss = 1.169900517060723, disc_loss = 0.0008119506878666842
Trained batch 355 in epoch 4, gen_loss = 1.1698232333311873, disc_loss = 0.0008115806678811014
Trained batch 356 in epoch 4, gen_loss = 1.1695693173662287, disc_loss = 0.0008106895353800306
Trained batch 357 in epoch 4, gen_loss = 1.1692073148722089, disc_loss = 0.0008100028164904595
Trained batch 358 in epoch 4, gen_loss = 1.1692995042189913, disc_loss = 0.0008093077034532537
Trained batch 359 in epoch 4, gen_loss = 1.1700946354203754, disc_loss = 0.0008087831821790638
Trained batch 360 in epoch 4, gen_loss = 1.1698285912542792, disc_loss = 0.0008085859289497313
Trained batch 361 in epoch 4, gen_loss = 1.170185441470278, disc_loss = 0.0008078015160017508
Trained batch 362 in epoch 4, gen_loss = 1.1694711870398402, disc_loss = 0.0008083264627744066
Trained batch 363 in epoch 4, gen_loss = 1.1691901883581182, disc_loss = 0.0008097777673546072
Trained batch 364 in epoch 4, gen_loss = 1.1689889251369319, disc_loss = 0.0008104682639273113
Trained batch 365 in epoch 4, gen_loss = 1.16946361918267, disc_loss = 0.0008095183127936322
Trained batch 366 in epoch 4, gen_loss = 1.1695719002378084, disc_loss = 0.0008090763382628884
Trained batch 367 in epoch 4, gen_loss = 1.1694303838455158, disc_loss = 0.0008084902015663987
Trained batch 368 in epoch 4, gen_loss = 1.1692172905940028, disc_loss = 0.0008073923319040578
Trained batch 369 in epoch 4, gen_loss = 1.1692361251727954, disc_loss = 0.0008063581894856651
Trained batch 370 in epoch 4, gen_loss = 1.1688754912013957, disc_loss = 0.0008050265971124373
Trained batch 371 in epoch 4, gen_loss = 1.168355780904011, disc_loss = 0.0008034403671376577
Trained batch 372 in epoch 4, gen_loss = 1.168779665279644, disc_loss = 0.0008018424549316688
Trained batch 373 in epoch 4, gen_loss = 1.1685450312925532, disc_loss = 0.0008003267696215074
Trained batch 374 in epoch 4, gen_loss = 1.1682208735148112, disc_loss = 0.0007988905482537423
Trained batch 375 in epoch 4, gen_loss = 1.1677643651974963, disc_loss = 0.0007978471408507099
Trained batch 376 in epoch 4, gen_loss = 1.167768842187421, disc_loss = 0.000797507842449627
Trained batch 377 in epoch 4, gen_loss = 1.1672729665324801, disc_loss = 0.000797903004649684
Trained batch 378 in epoch 4, gen_loss = 1.1671932176109354, disc_loss = 0.0007975504635406246
Trained batch 379 in epoch 4, gen_loss = 1.1669842683955243, disc_loss = 0.0007971639124949242
Trained batch 380 in epoch 4, gen_loss = 1.1666382293062887, disc_loss = 0.0007959180239974852
Trained batch 381 in epoch 4, gen_loss = 1.1665038208998935, disc_loss = 0.0007944335420164937
Trained batch 382 in epoch 4, gen_loss = 1.1665443199110406, disc_loss = 0.000793553264623182
Trained batch 383 in epoch 4, gen_loss = 1.16643412799264, disc_loss = 0.0007935056290383121
Trained batch 384 in epoch 4, gen_loss = 1.1658816103811387, disc_loss = 0.0007942237923006443
Trained batch 385 in epoch 4, gen_loss = 1.1656114704559504, disc_loss = 0.000797838402864972
Trained batch 386 in epoch 4, gen_loss = 1.165085619580222, disc_loss = 0.0008040025786049086
Trained batch 387 in epoch 4, gen_loss = 1.1650412846164606, disc_loss = 0.0008111000920648293
Trained batch 388 in epoch 4, gen_loss = 1.1651782384261986, disc_loss = 0.0008158125840714034
Trained batch 389 in epoch 4, gen_loss = 1.1653991902485872, disc_loss = 0.0008177926045997689
Trained batch 390 in epoch 4, gen_loss = 1.1656347005568501, disc_loss = 0.0008196268450109112
Trained batch 391 in epoch 4, gen_loss = 1.1655207296111145, disc_loss = 0.0008198645971751087
Trained batch 392 in epoch 4, gen_loss = 1.1649146771612968, disc_loss = 0.0008228925895360571
Trained batch 393 in epoch 4, gen_loss = 1.1652770045445051, disc_loss = 0.0008316826975613662
Trained batch 394 in epoch 4, gen_loss = 1.1653573268576514, disc_loss = 0.0008382711021665814
Trained batch 395 in epoch 4, gen_loss = 1.1654367630529885, disc_loss = 0.0008448921559987627
Trained batch 396 in epoch 4, gen_loss = 1.1655348560371688, disc_loss = 0.0008504518238248149
Trained batch 397 in epoch 4, gen_loss = 1.16506427885899, disc_loss = 0.0008523782222922517
Trained batch 398 in epoch 4, gen_loss = 1.1645022077966751, disc_loss = 0.0008530823204883451
Trained batch 399 in epoch 4, gen_loss = 1.164655334353447, disc_loss = 0.0008589892894087825
Trained batch 400 in epoch 4, gen_loss = 1.1640206758220892, disc_loss = 0.0008669703250386267
Trained batch 401 in epoch 4, gen_loss = 1.1634709196007667, disc_loss = 0.0008713772396767855
Trained batch 402 in epoch 4, gen_loss = 1.1640200459631738, disc_loss = 0.000873280400681834
Trained batch 403 in epoch 4, gen_loss = 1.1636478568952862, disc_loss = 0.0008745785152233012
Trained batch 404 in epoch 4, gen_loss = 1.1630096425244838, disc_loss = 0.0008805688906081573
Trained batch 405 in epoch 4, gen_loss = 1.1628845811183817, disc_loss = 0.0008839122803934524
Trained batch 406 in epoch 4, gen_loss = 1.1630630515131377, disc_loss = 0.000884479556618263
Trained batch 407 in epoch 4, gen_loss = 1.1632035022564964, disc_loss = 0.0008848155496297313
Trained batch 408 in epoch 4, gen_loss = 1.163052598392468, disc_loss = 0.0008850073825265111
Trained batch 409 in epoch 4, gen_loss = 1.1627251013023097, disc_loss = 0.0008845072807516993
Trained batch 410 in epoch 4, gen_loss = 1.162581662917079, disc_loss = 0.0008842352777153
Trained batch 411 in epoch 4, gen_loss = 1.162142855883802, disc_loss = 0.0008833119864699892
Trained batch 412 in epoch 4, gen_loss = 1.161947133321739, disc_loss = 0.0008830061351787975
Trained batch 413 in epoch 4, gen_loss = 1.1613642528725132, disc_loss = 0.0008827224344291819
Trained batch 414 in epoch 4, gen_loss = 1.1616518134094147, disc_loss = 0.0008828015603876886
Trained batch 415 in epoch 4, gen_loss = 1.161039882984299, disc_loss = 0.0008835147322175684
Trained batch 416 in epoch 4, gen_loss = 1.160936163340827, disc_loss = 0.0008870754777610177
Trained batch 417 in epoch 4, gen_loss = 1.1609062377060428, disc_loss = 0.0008903603548792293
Trained batch 418 in epoch 4, gen_loss = 1.1609551245102165, disc_loss = 0.0008909660554046439
Trained batch 419 in epoch 4, gen_loss = 1.1606636485883168, disc_loss = 0.0008909950070249449
Trained batch 420 in epoch 4, gen_loss = 1.1606142278804914, disc_loss = 0.0008908336985725777
Trained batch 421 in epoch 4, gen_loss = 1.1601785564027127, disc_loss = 0.0008917259477504851
Trained batch 422 in epoch 4, gen_loss = 1.1605838211715644, disc_loss = 0.0008934066075243796
Trained batch 423 in epoch 4, gen_loss = 1.1605559633869045, disc_loss = 0.0008946457664418596
Trained batch 424 in epoch 4, gen_loss = 1.1602002756735859, disc_loss = 0.0008941174599835101
Trained batch 425 in epoch 4, gen_loss = 1.1604640650357438, disc_loss = 0.0008948957468295566
Trained batch 426 in epoch 4, gen_loss = 1.1599280676462054, disc_loss = 0.0008944980846499846
Trained batch 427 in epoch 4, gen_loss = 1.1596668767873373, disc_loss = 0.0008936363656430671
Trained batch 428 in epoch 4, gen_loss = 1.1594944415670452, disc_loss = 0.0008935771705061718
Trained batch 429 in epoch 4, gen_loss = 1.1596608590248019, disc_loss = 0.0008934497512432985
Trained batch 430 in epoch 4, gen_loss = 1.1594656190020303, disc_loss = 0.0008928717473001066
Trained batch 431 in epoch 4, gen_loss = 1.1596288163628843, disc_loss = 0.0008920399196978435
Trained batch 432 in epoch 4, gen_loss = 1.1593644287239322, disc_loss = 0.0008909634746531536
Trained batch 433 in epoch 4, gen_loss = 1.1592462717937435, disc_loss = 0.0008897478432042636
Trained batch 434 in epoch 4, gen_loss = 1.1589377634826747, disc_loss = 0.0008887050942994184
Trained batch 435 in epoch 4, gen_loss = 1.1590269406180862, disc_loss = 0.0008876771177352116
Trained batch 436 in epoch 4, gen_loss = 1.1589092614994443, disc_loss = 0.0008865405659024013
Trained batch 437 in epoch 4, gen_loss = 1.158754549478287, disc_loss = 0.0008850866270471645
Trained batch 438 in epoch 4, gen_loss = 1.1587727130952892, disc_loss = 0.0008835097979584492
Trained batch 439 in epoch 4, gen_loss = 1.158987972004847, disc_loss = 0.0008819089933571046
Trained batch 440 in epoch 4, gen_loss = 1.1587788997864237, disc_loss = 0.000880489495255279
Trained batch 441 in epoch 4, gen_loss = 1.1583952211956092, disc_loss = 0.0008791046027382266
Trained batch 442 in epoch 4, gen_loss = 1.1587752990475089, disc_loss = 0.0008784717449938887
Trained batch 443 in epoch 4, gen_loss = 1.1590268811932556, disc_loss = 0.00087938938042236
Trained batch 444 in epoch 4, gen_loss = 1.159015057729871, disc_loss = 0.0008794731520354392
Trained batch 445 in epoch 4, gen_loss = 1.1591149382794383, disc_loss = 0.0008789402959153636
Trained batch 446 in epoch 4, gen_loss = 1.1595238328513415, disc_loss = 0.0008789388930320353
Trained batch 447 in epoch 4, gen_loss = 1.159345534896212, disc_loss = 0.0008786159827585445
Trained batch 448 in epoch 4, gen_loss = 1.1591837561475673, disc_loss = 0.000877358690717046
Trained batch 449 in epoch 4, gen_loss = 1.1588299877113766, disc_loss = 0.000876359501562547
Trained batch 450 in epoch 4, gen_loss = 1.1587189286616848, disc_loss = 0.000874812820845773
Trained batch 451 in epoch 4, gen_loss = 1.1586160497591558, disc_loss = 0.0008733231206056229
Trained batch 452 in epoch 4, gen_loss = 1.1590454563926125, disc_loss = 0.0008717649931753174
Trained batch 453 in epoch 4, gen_loss = 1.1588625410317324, disc_loss = 0.0008701331768464913
Trained batch 454 in epoch 4, gen_loss = 1.1590847650727072, disc_loss = 0.0008685470251033881
Trained batch 455 in epoch 4, gen_loss = 1.1586786735998957, disc_loss = 0.0008672128821847748
Trained batch 456 in epoch 4, gen_loss = 1.158486508436224, disc_loss = 0.0008668085736990856
Trained batch 457 in epoch 4, gen_loss = 1.1582829939225876, disc_loss = 0.0008674789465126057
Trained batch 458 in epoch 4, gen_loss = 1.1581514881586976, disc_loss = 0.0008688398260493359
Trained batch 459 in epoch 4, gen_loss = 1.1581666254478953, disc_loss = 0.0008692079598246062
Trained batch 460 in epoch 4, gen_loss = 1.15843694872039, disc_loss = 0.0008683218402280968
Trained batch 461 in epoch 4, gen_loss = 1.157984277773729, disc_loss = 0.0008672927148454698
Trained batch 462 in epoch 4, gen_loss = 1.157965493124968, disc_loss = 0.0008666641660965979
Trained batch 463 in epoch 4, gen_loss = 1.1576682857141412, disc_loss = 0.0008659266903374247
Trained batch 464 in epoch 4, gen_loss = 1.1577860923223597, disc_loss = 0.0008647565312448248
Trained batch 465 in epoch 4, gen_loss = 1.1576966373449744, disc_loss = 0.0008641845953741707
Trained batch 466 in epoch 4, gen_loss = 1.1573784449626343, disc_loss = 0.0008643646177968382
Trained batch 467 in epoch 4, gen_loss = 1.1574998106966672, disc_loss = 0.0008632863667653276
Trained batch 468 in epoch 4, gen_loss = 1.1576359334276682, disc_loss = 0.0008627595200609448
Trained batch 469 in epoch 4, gen_loss = 1.1575163578733485, disc_loss = 0.0008620150993513736
Trained batch 470 in epoch 4, gen_loss = 1.157259987038412, disc_loss = 0.0008616714045378694
Trained batch 471 in epoch 4, gen_loss = 1.1570586123961513, disc_loss = 0.0008612441294752574
Trained batch 472 in epoch 4, gen_loss = 1.157104000102642, disc_loss = 0.0008602753999898009
Trained batch 473 in epoch 4, gen_loss = 1.1571110714588486, disc_loss = 0.0008599235692070326
Trained batch 474 in epoch 4, gen_loss = 1.156851115854163, disc_loss = 0.000858994582729218
Trained batch 475 in epoch 4, gen_loss = 1.1565680903296511, disc_loss = 0.0008579939116499809
Trained batch 476 in epoch 4, gen_loss = 1.1565263939853485, disc_loss = 0.0008579529539376412
Trained batch 477 in epoch 4, gen_loss = 1.156014428103818, disc_loss = 0.0008571575067949065
Trained batch 478 in epoch 4, gen_loss = 1.1556846092538695, disc_loss = 0.0008560749519876902
Trained batch 479 in epoch 4, gen_loss = 1.1557013362646102, disc_loss = 0.000855024016588383
Trained batch 480 in epoch 4, gen_loss = 1.1554911758696462, disc_loss = 0.0008539666884347386
Trained batch 481 in epoch 4, gen_loss = 1.1556738884617184, disc_loss = 0.0008530716365396482
Trained batch 482 in epoch 4, gen_loss = 1.1552824988868666, disc_loss = 0.0008519737026557773
Trained batch 483 in epoch 4, gen_loss = 1.1550933477307155, disc_loss = 0.0008512075171081449
Trained batch 484 in epoch 4, gen_loss = 1.1546089747517378, disc_loss = 0.0008506011260438173
Trained batch 485 in epoch 4, gen_loss = 1.1549618563043729, disc_loss = 0.0008500564658133803
Trained batch 486 in epoch 4, gen_loss = 1.1549281983404924, disc_loss = 0.0008493793545146444
Trained batch 487 in epoch 4, gen_loss = 1.1549484390215796, disc_loss = 0.0008484522864431502
Trained batch 488 in epoch 4, gen_loss = 1.1546453135145223, disc_loss = 0.0008480509441105005
Trained batch 489 in epoch 4, gen_loss = 1.1544414184531386, disc_loss = 0.0008481300380722411
Trained batch 490 in epoch 4, gen_loss = 1.1544082315293447, disc_loss = 0.00084828062791732
Trained batch 491 in epoch 4, gen_loss = 1.1540904171098538, disc_loss = 0.0008479396454025461
Trained batch 492 in epoch 4, gen_loss = 1.1541518761226661, disc_loss = 0.000847070504999559
Trained batch 493 in epoch 4, gen_loss = 1.1535881960440262, disc_loss = 0.0008460853550124061
Trained batch 494 in epoch 4, gen_loss = 1.153646142073352, disc_loss = 0.0008451940330695549
Trained batch 495 in epoch 4, gen_loss = 1.1535495558092672, disc_loss = 0.0008442910674338852
Trained batch 496 in epoch 4, gen_loss = 1.1535190720433441, disc_loss = 0.0008432480692348145
Trained batch 497 in epoch 4, gen_loss = 1.153548857533788, disc_loss = 0.0008419391446493016
Trained batch 498 in epoch 4, gen_loss = 1.1533032201812836, disc_loss = 0.0008407210410812418
Trained batch 499 in epoch 4, gen_loss = 1.1530086417198182, disc_loss = 0.0008399186946335249
Trained batch 500 in epoch 4, gen_loss = 1.1529125560543494, disc_loss = 0.0008396890597997007
Trained batch 501 in epoch 4, gen_loss = 1.1525948072572154, disc_loss = 0.0008399615297209939
Trained batch 502 in epoch 4, gen_loss = 1.1527798743418622, disc_loss = 0.0008395126456404975
Trained batch 503 in epoch 4, gen_loss = 1.15303099971442, disc_loss = 0.0008385008188760987
Trained batch 504 in epoch 4, gen_loss = 1.1531148149235413, disc_loss = 0.0008374766765927693
Trained batch 505 in epoch 4, gen_loss = 1.1531142346237018, disc_loss = 0.0008365130667982387
Trained batch 506 in epoch 4, gen_loss = 1.1528065064719912, disc_loss = 0.0008354035703372578
Trained batch 507 in epoch 4, gen_loss = 1.1523528808918524, disc_loss = 0.0008341577482984061
Trained batch 508 in epoch 4, gen_loss = 1.1522565671409277, disc_loss = 0.0008330213555035571
Trained batch 509 in epoch 4, gen_loss = 1.1526918323600994, disc_loss = 0.0008320485928504472
Trained batch 510 in epoch 4, gen_loss = 1.1524226932609618, disc_loss = 0.000831380880472192
Trained batch 511 in epoch 4, gen_loss = 1.1526457915315405, disc_loss = 0.00083095260035293
Trained batch 512 in epoch 4, gen_loss = 1.153099249794237, disc_loss = 0.0008300400022101873
Trained batch 513 in epoch 4, gen_loss = 1.1534114522924683, disc_loss = 0.0008294635422263704
Trained batch 514 in epoch 4, gen_loss = 1.1534246026890949, disc_loss = 0.0008289847844246396
Trained batch 515 in epoch 4, gen_loss = 1.1533004238392957, disc_loss = 0.0008283008740596246
Trained batch 516 in epoch 4, gen_loss = 1.153163706426233, disc_loss = 0.0008275123506212946
Trained batch 517 in epoch 4, gen_loss = 1.1531954574538934, disc_loss = 0.0008267722234773111
Trained batch 518 in epoch 4, gen_loss = 1.152966642540544, disc_loss = 0.0008269234669835779
Trained batch 519 in epoch 4, gen_loss = 1.1527436851308897, disc_loss = 0.0008276727427493404
Trained batch 520 in epoch 4, gen_loss = 1.153195475776914, disc_loss = 0.0008279092511510291
Trained batch 521 in epoch 4, gen_loss = 1.153587738558707, disc_loss = 0.0008279297962662999
Trained batch 522 in epoch 4, gen_loss = 1.1534806331530583, disc_loss = 0.0008281018932153654
Trained batch 523 in epoch 4, gen_loss = 1.1532025463480986, disc_loss = 0.0008281962383698
Trained batch 524 in epoch 4, gen_loss = 1.1531239576566787, disc_loss = 0.0008289825328392908
Trained batch 525 in epoch 4, gen_loss = 1.153390709778202, disc_loss = 0.0008305176172019054
Trained batch 526 in epoch 4, gen_loss = 1.1534954129631652, disc_loss = 0.0008318216879390431
Trained batch 527 in epoch 4, gen_loss = 1.1535835188220849, disc_loss = 0.0008319524720883982
Trained batch 528 in epoch 4, gen_loss = 1.154228009776492, disc_loss = 0.0008318925420047244
Trained batch 529 in epoch 4, gen_loss = 1.1547333880415502, disc_loss = 0.000831514258867894
Trained batch 530 in epoch 4, gen_loss = 1.1551021778650876, disc_loss = 0.0008311853003887663
Trained batch 531 in epoch 4, gen_loss = 1.1550550511232893, disc_loss = 0.0008308252471941611
Trained batch 532 in epoch 4, gen_loss = 1.1549367436101243, disc_loss = 0.0008303991905891897
Trained batch 533 in epoch 4, gen_loss = 1.1551342846525743, disc_loss = 0.0008321645806056503
Trained batch 534 in epoch 4, gen_loss = 1.1553539910049082, disc_loss = 0.0008348173103632545
Trained batch 535 in epoch 4, gen_loss = 1.1553372216980848, disc_loss = 0.0008358453295257467
Trained batch 536 in epoch 4, gen_loss = 1.155331628837621, disc_loss = 0.000835718815400286
Trained batch 537 in epoch 4, gen_loss = 1.1554315625291776, disc_loss = 0.0008354288026624269
Trained batch 538 in epoch 4, gen_loss = 1.1559376197975952, disc_loss = 0.0008347447150711277
Trained batch 539 in epoch 4, gen_loss = 1.1558616802648263, disc_loss = 0.0008337683051649947
Trained batch 540 in epoch 4, gen_loss = 1.1556263662971102, disc_loss = 0.0008327578250226236
Trained batch 541 in epoch 4, gen_loss = 1.1553252160109277, disc_loss = 0.0008318345165801599
Trained batch 542 in epoch 4, gen_loss = 1.1552208397489445, disc_loss = 0.0008313071112027117
Trained batch 543 in epoch 4, gen_loss = 1.1551257210838444, disc_loss = 0.0008312451815233062
Trained batch 544 in epoch 4, gen_loss = 1.155485166431567, disc_loss = 0.0008317588358837684
Trained batch 545 in epoch 4, gen_loss = 1.1556675070589715, disc_loss = 0.0008322642544967177
Trained batch 546 in epoch 4, gen_loss = 1.155808213097086, disc_loss = 0.0008324154252171519
Trained batch 547 in epoch 4, gen_loss = 1.155991426458324, disc_loss = 0.0008334820852651054
Trained batch 548 in epoch 4, gen_loss = 1.1557680790758742, disc_loss = 0.0008359397813740979
Trained batch 549 in epoch 4, gen_loss = 1.1558959511193363, disc_loss = 0.0008403219444814815
Trained batch 550 in epoch 4, gen_loss = 1.1560422972845295, disc_loss = 0.0008459758334262837
Trained batch 551 in epoch 4, gen_loss = 1.155937458186046, disc_loss = 0.0008486314303466487
Trained batch 552 in epoch 4, gen_loss = 1.1561684868219317, disc_loss = 0.0008495897100196316
Trained batch 553 in epoch 4, gen_loss = 1.156498894902343, disc_loss = 0.0008492051875767204
Trained batch 554 in epoch 4, gen_loss = 1.1571782409607827, disc_loss = 0.0008485664172267944
Trained batch 555 in epoch 4, gen_loss = 1.1578075775354029, disc_loss = 0.0008479839166186217
Trained batch 556 in epoch 4, gen_loss = 1.1575643653501515, disc_loss = 0.0008482676783638891
Trained batch 557 in epoch 4, gen_loss = 1.1574947860719482, disc_loss = 0.0008493964292501653
Trained batch 558 in epoch 4, gen_loss = 1.157490293007204, disc_loss = 0.0008497228420329945
Trained batch 559 in epoch 4, gen_loss = 1.1575123947645938, disc_loss = 0.0008493052207476077
Trained batch 560 in epoch 4, gen_loss = 1.1578724132502143, disc_loss = 0.0008483053874355158
Trained batch 561 in epoch 4, gen_loss = 1.157526457967283, disc_loss = 0.0008471502251689011
Trained batch 562 in epoch 4, gen_loss = 1.157356067089162, disc_loss = 0.0008459908284834581
Trained batch 563 in epoch 4, gen_loss = 1.1578835989777922, disc_loss = 0.0008457807388954634
Trained batch 564 in epoch 4, gen_loss = 1.1580110470805547, disc_loss = 0.000846677823780327
Trained batch 565 in epoch 4, gen_loss = 1.158120223679728, disc_loss = 0.0008463621712193081
Trained batch 566 in epoch 4, gen_loss = 1.1581160844528695, disc_loss = 0.0008454557984414045
Trained batch 567 in epoch 4, gen_loss = 1.1581164589020567, disc_loss = 0.0008448178984290793
Trained batch 568 in epoch 4, gen_loss = 1.1580972477715128, disc_loss = 0.0008443487522542978
Trained batch 569 in epoch 4, gen_loss = 1.158035124289362, disc_loss = 0.0008436917134084772
Trained batch 570 in epoch 4, gen_loss = 1.1587630116793404, disc_loss = 0.0008427148632411218
Trained batch 571 in epoch 4, gen_loss = 1.1585008073728402, disc_loss = 0.0008416962683421862
Trained batch 572 in epoch 4, gen_loss = 1.158458141028153, disc_loss = 0.0008405963447601998
Trained batch 573 in epoch 4, gen_loss = 1.1582441684053335, disc_loss = 0.0008400674702330713
Trained batch 574 in epoch 4, gen_loss = 1.1585165787779768, disc_loss = 0.0008401661053674457
Trained batch 575 in epoch 4, gen_loss = 1.1585796745494008, disc_loss = 0.000839831297955445
Trained batch 576 in epoch 4, gen_loss = 1.1587484586383483, disc_loss = 0.0008388480842765178
Trained batch 577 in epoch 4, gen_loss = 1.1586306655076961, disc_loss = 0.0008377038783751908
Trained batch 578 in epoch 4, gen_loss = 1.1586548679850879, disc_loss = 0.0008366597238393253
Trained batch 579 in epoch 4, gen_loss = 1.1585983388382812, disc_loss = 0.0008360583097814454
Trained batch 580 in epoch 4, gen_loss = 1.1584981830723315, disc_loss = 0.000835432075158406
Trained batch 581 in epoch 4, gen_loss = 1.1586813026482297, disc_loss = 0.0008346031441835725
Trained batch 582 in epoch 4, gen_loss = 1.1586302239735375, disc_loss = 0.0008336558911967767
Trained batch 583 in epoch 4, gen_loss = 1.1583031645580515, disc_loss = 0.0008324591991828901
Trained batch 584 in epoch 4, gen_loss = 1.1585922113850586, disc_loss = 0.0008313346297965727
Trained batch 585 in epoch 4, gen_loss = 1.158652672893765, disc_loss = 0.0008303205529694706
Trained batch 586 in epoch 4, gen_loss = 1.1588528898546195, disc_loss = 0.0008294000806716498
Trained batch 587 in epoch 4, gen_loss = 1.1588418085356147, disc_loss = 0.0008286955495090556
Trained batch 588 in epoch 4, gen_loss = 1.1588689006852375, disc_loss = 0.0008280925627480417
Trained batch 589 in epoch 4, gen_loss = 1.158941679788848, disc_loss = 0.0008271347161360732
Trained batch 590 in epoch 4, gen_loss = 1.1586998298688589, disc_loss = 0.0008263680226314898
Trained batch 591 in epoch 4, gen_loss = 1.1587123209358872, disc_loss = 0.0008275097249458446
Trained batch 592 in epoch 4, gen_loss = 1.1587163194838102, disc_loss = 0.0008287264895635229
Trained batch 593 in epoch 4, gen_loss = 1.1590147326490292, disc_loss = 0.0008280803267430492
Trained batch 594 in epoch 4, gen_loss = 1.1588407267041567, disc_loss = 0.0008273555655296532
Trained batch 595 in epoch 4, gen_loss = 1.1587259722436034, disc_loss = 0.0008264247599499685
Trained batch 596 in epoch 4, gen_loss = 1.158485132146321, disc_loss = 0.0008257215056411214
Trained batch 597 in epoch 4, gen_loss = 1.1586496264838853, disc_loss = 0.000825049903123666
Trained batch 598 in epoch 4, gen_loss = 1.1584017926544101, disc_loss = 0.0008241735183381598
Trained batch 599 in epoch 4, gen_loss = 1.158117341498534, disc_loss = 0.0008238480190387539
Trained batch 600 in epoch 4, gen_loss = 1.1581010750050156, disc_loss = 0.0008240730680450534
Trained batch 601 in epoch 4, gen_loss = 1.1576545517706, disc_loss = 0.0008282927622733579
Trained batch 602 in epoch 4, gen_loss = 1.157873282780497, disc_loss = 0.0008369610454664361
Trained batch 603 in epoch 4, gen_loss = 1.158195478829327, disc_loss = 0.0008462695589677248
Trained batch 604 in epoch 4, gen_loss = 1.1581765626087661, disc_loss = 0.0008585553385138373
Trained batch 605 in epoch 4, gen_loss = 1.1580154516122523, disc_loss = 0.0008747190707076953
Trained batch 606 in epoch 4, gen_loss = 1.157679556327361, disc_loss = 0.000892922728677446
Trained batch 607 in epoch 4, gen_loss = 1.157854656737886, disc_loss = 0.0009062047021248681
Trained batch 608 in epoch 4, gen_loss = 1.1577350955291335, disc_loss = 0.0009134841343983993
Trained batch 609 in epoch 4, gen_loss = 1.1578764359482, disc_loss = 0.0009167456518253693
Trained batch 610 in epoch 4, gen_loss = 1.1578757960940733, disc_loss = 0.000919487668366519
Trained batch 611 in epoch 4, gen_loss = 1.157642245974416, disc_loss = 0.00092169651576661
Trained batch 612 in epoch 4, gen_loss = 1.1573460467682382, disc_loss = 0.0009219076751598778
Trained batch 613 in epoch 4, gen_loss = 1.1573902461738461, disc_loss = 0.000922493484713621
Trained batch 614 in epoch 4, gen_loss = 1.1573180559204845, disc_loss = 0.0009233702958241575
Trained batch 615 in epoch 4, gen_loss = 1.1574003740951613, disc_loss = 0.0009235753773931979
Trained batch 616 in epoch 4, gen_loss = 1.1570585921672407, disc_loss = 0.0009233897138072625
Trained batch 617 in epoch 4, gen_loss = 1.1569328526077147, disc_loss = 0.0009233351781748426
Trained batch 618 in epoch 4, gen_loss = 1.1571638767091446, disc_loss = 0.0009231208311835822
Trained batch 619 in epoch 4, gen_loss = 1.156807403122225, disc_loss = 0.0009235342523043659
Trained batch 620 in epoch 4, gen_loss = 1.1565131702476845, disc_loss = 0.0009259389536580875
Trained batch 621 in epoch 4, gen_loss = 1.1564454234106365, disc_loss = 0.0009287764938311259
Trained batch 622 in epoch 4, gen_loss = 1.1565732949235465, disc_loss = 0.0009294826068859741
Trained batch 623 in epoch 4, gen_loss = 1.1565162423902597, disc_loss = 0.0009293472927684212
Trained batch 624 in epoch 4, gen_loss = 1.1568852345466614, disc_loss = 0.0009291135552106425
Trained batch 625 in epoch 4, gen_loss = 1.1567098314579303, disc_loss = 0.0009284314672087361
Trained batch 626 in epoch 4, gen_loss = 1.1568936625736181, disc_loss = 0.0009275761504103897
Trained batch 627 in epoch 4, gen_loss = 1.1569684974517032, disc_loss = 0.0009266148030709336
Trained batch 628 in epoch 4, gen_loss = 1.156717150408437, disc_loss = 0.000925549101947869
Trained batch 629 in epoch 4, gen_loss = 1.1570569173684195, disc_loss = 0.0009248384640650041
Trained batch 630 in epoch 4, gen_loss = 1.1574359026083667, disc_loss = 0.0009242253935987738
Trained batch 631 in epoch 4, gen_loss = 1.157467417607579, disc_loss = 0.0009235297775721617
Trained batch 632 in epoch 4, gen_loss = 1.1575637081223076, disc_loss = 0.0009225641373270169
Trained batch 633 in epoch 4, gen_loss = 1.1578173775590181, disc_loss = 0.0009237652453228505
Trained batch 634 in epoch 4, gen_loss = 1.1576900796627436, disc_loss = 0.0009265558853952624
Trained batch 635 in epoch 4, gen_loss = 1.1573782562272354, disc_loss = 0.0009284303261162259
Trained batch 636 in epoch 4, gen_loss = 1.1573826758603287, disc_loss = 0.0009282556379309328
Trained batch 637 in epoch 4, gen_loss = 1.157280455468964, disc_loss = 0.000927870994369714
Trained batch 638 in epoch 4, gen_loss = 1.157184533576637, disc_loss = 0.0009273912341391131
Trained batch 639 in epoch 4, gen_loss = 1.1573346951045096, disc_loss = 0.0009267125263477283
Trained batch 640 in epoch 4, gen_loss = 1.1572872806636851, disc_loss = 0.0009272972394666139
Trained batch 641 in epoch 4, gen_loss = 1.1571449244690832, disc_loss = 0.0009271773841564624
Trained batch 642 in epoch 4, gen_loss = 1.1570945124418517, disc_loss = 0.0009262996143797227
Trained batch 643 in epoch 4, gen_loss = 1.1575797282575822, disc_loss = 0.0009254321784458213
Trained batch 644 in epoch 4, gen_loss = 1.157531757595003, disc_loss = 0.0009248037994234613
Trained batch 645 in epoch 4, gen_loss = 1.157855456919862, disc_loss = 0.0009240316005285625
Trained batch 646 in epoch 4, gen_loss = 1.1574702788910136, disc_loss = 0.0009242315216206224
Trained batch 647 in epoch 4, gen_loss = 1.1574544684938441, disc_loss = 0.0009261317480217887
Trained batch 648 in epoch 4, gen_loss = 1.1571852718185753, disc_loss = 0.0009272961543152935
Trained batch 649 in epoch 4, gen_loss = 1.1571032808377193, disc_loss = 0.0009280920374574354
Trained batch 650 in epoch 4, gen_loss = 1.157080121304033, disc_loss = 0.0009281801565426162
Trained batch 651 in epoch 4, gen_loss = 1.1568060882983764, disc_loss = 0.0009278234066393446
Trained batch 652 in epoch 4, gen_loss = 1.1564477622782836, disc_loss = 0.0009273695121464001
Trained batch 653 in epoch 4, gen_loss = 1.1563096326243258, disc_loss = 0.0009269122067820751
Trained batch 654 in epoch 4, gen_loss = 1.1561654579548435, disc_loss = 0.0009260394578694742
Trained batch 655 in epoch 4, gen_loss = 1.1561003426407896, disc_loss = 0.0009253073025453287
Trained batch 656 in epoch 4, gen_loss = 1.1557589641444759, disc_loss = 0.0009247968188418597
Trained batch 657 in epoch 4, gen_loss = 1.1555483979838235, disc_loss = 0.0009252880314903936
Trained batch 658 in epoch 4, gen_loss = 1.1553883844695432, disc_loss = 0.000928034796127774
Trained batch 659 in epoch 4, gen_loss = 1.1553878190842541, disc_loss = 0.0009312973474813837
Trained batch 660 in epoch 4, gen_loss = 1.1551781044244405, disc_loss = 0.0009364823803667377
Trained batch 661 in epoch 4, gen_loss = 1.1552524358664396, disc_loss = 0.0009392540764689286
Trained batch 662 in epoch 4, gen_loss = 1.1550639464125194, disc_loss = 0.0009395353978548583
Trained batch 663 in epoch 4, gen_loss = 1.1552594272666667, disc_loss = 0.0009401806617527008
Trained batch 664 in epoch 4, gen_loss = 1.1553958067320342, disc_loss = 0.0009411952686557351
Trained batch 665 in epoch 4, gen_loss = 1.1553706559869978, disc_loss = 0.000941104731132177
Trained batch 666 in epoch 4, gen_loss = 1.1551652591803978, disc_loss = 0.0009406688424814115
Trained batch 667 in epoch 4, gen_loss = 1.1549461698996093, disc_loss = 0.0009411373521397545
Trained batch 668 in epoch 4, gen_loss = 1.1546727419790488, disc_loss = 0.0009437265555276528
Trained batch 669 in epoch 4, gen_loss = 1.1544202881962506, disc_loss = 0.0009451601050278074
Trained batch 670 in epoch 4, gen_loss = 1.1542322240359026, disc_loss = 0.0009453523713543986
Trained batch 671 in epoch 4, gen_loss = 1.1541823605518966, disc_loss = 0.0009452486975273392
Trained batch 672 in epoch 4, gen_loss = 1.1542821675317603, disc_loss = 0.00094439275543303
Trained batch 673 in epoch 4, gen_loss = 1.154199879937073, disc_loss = 0.0009434456310332725
Trained batch 674 in epoch 4, gen_loss = 1.1539390700834768, disc_loss = 0.0009428291060504745
Trained batch 675 in epoch 4, gen_loss = 1.1536085108328147, disc_loss = 0.000942042059541133
Trained batch 676 in epoch 4, gen_loss = 1.1535250686296157, disc_loss = 0.000941192644530119
Trained batch 677 in epoch 4, gen_loss = 1.1536661551765284, disc_loss = 0.0009402491660401635
Trained batch 678 in epoch 4, gen_loss = 1.1537825457301862, disc_loss = 0.0009395023241451569
Trained batch 679 in epoch 4, gen_loss = 1.1537760657422682, disc_loss = 0.0009385496716704973
Trained batch 680 in epoch 4, gen_loss = 1.1535489837503643, disc_loss = 0.0009378713436440802
Trained batch 681 in epoch 4, gen_loss = 1.1533510071441224, disc_loss = 0.0009369824812540994
Trained batch 682 in epoch 4, gen_loss = 1.153552474773122, disc_loss = 0.0009360246574511278
Trained batch 683 in epoch 4, gen_loss = 1.1534736173891882, disc_loss = 0.0009356407036217494
Trained batch 684 in epoch 4, gen_loss = 1.1535185034257651, disc_loss = 0.0009358295098237734
Trained batch 685 in epoch 4, gen_loss = 1.1533393679137827, disc_loss = 0.0009365103595254402
Trained batch 686 in epoch 4, gen_loss = 1.153329099283121, disc_loss = 0.0009366759091059527
Trained batch 687 in epoch 4, gen_loss = 1.1531402971162352, disc_loss = 0.0009360316371385125
Trained batch 688 in epoch 4, gen_loss = 1.152838383340351, disc_loss = 0.0009352076981452879
Trained batch 689 in epoch 4, gen_loss = 1.1527663960836936, disc_loss = 0.0009344162681583733
Trained batch 690 in epoch 4, gen_loss = 1.152837636070555, disc_loss = 0.0009341813366266786
Trained batch 691 in epoch 4, gen_loss = 1.1529325788593017, disc_loss = 0.0009339334622334697
Trained batch 692 in epoch 4, gen_loss = 1.1528163529921747, disc_loss = 0.0009333087764651827
Trained batch 693 in epoch 4, gen_loss = 1.153177355053789, disc_loss = 0.0009331048125700062
Trained batch 694 in epoch 4, gen_loss = 1.1534277472564642, disc_loss = 0.000933029144150607
Trained batch 695 in epoch 4, gen_loss = 1.1534433783642177, disc_loss = 0.0009331815248954406
Trained batch 696 in epoch 4, gen_loss = 1.1533270303795977, disc_loss = 0.0009324339358862609
Trained batch 697 in epoch 4, gen_loss = 1.1531284916879112, disc_loss = 0.0009313611592480347
Trained batch 698 in epoch 4, gen_loss = 1.1531200056765043, disc_loss = 0.00093036164376483
Trained batch 699 in epoch 4, gen_loss = 1.153073473913329, disc_loss = 0.0009297191026312898
Trained batch 700 in epoch 4, gen_loss = 1.1528732449283954, disc_loss = 0.0009292120074070445
Trained batch 701 in epoch 4, gen_loss = 1.1527183846360938, disc_loss = 0.0009283400397123225
Trained batch 702 in epoch 4, gen_loss = 1.1527211848397343, disc_loss = 0.0009273088191346772
Trained batch 703 in epoch 4, gen_loss = 1.1529950481754812, disc_loss = 0.0009263819206559922
Trained batch 704 in epoch 4, gen_loss = 1.1529746509612875, disc_loss = 0.0009253309016464384
Trained batch 705 in epoch 4, gen_loss = 1.1530337206196177, disc_loss = 0.000924424702038945
Trained batch 706 in epoch 4, gen_loss = 1.1533041152960846, disc_loss = 0.0009234184266283418
Trained batch 707 in epoch 4, gen_loss = 1.1531270393038873, disc_loss = 0.0009226890718715665
Trained batch 708 in epoch 4, gen_loss = 1.1531049108135347, disc_loss = 0.000922033489162591
Trained batch 709 in epoch 4, gen_loss = 1.153173593819981, disc_loss = 0.000921188139407502
Trained batch 710 in epoch 4, gen_loss = 1.1529575774941263, disc_loss = 0.0009208147570149614
Trained batch 711 in epoch 4, gen_loss = 1.1528969252209984, disc_loss = 0.0009205589703924488
Trained batch 712 in epoch 4, gen_loss = 1.1527747460033582, disc_loss = 0.0009201225331317644
Trained batch 713 in epoch 4, gen_loss = 1.1530729078945994, disc_loss = 0.0009193739786787162
Trained batch 714 in epoch 4, gen_loss = 1.1530244251231214, disc_loss = 0.0009186698885803873
Trained batch 715 in epoch 4, gen_loss = 1.1530840537568043, disc_loss = 0.000918089402234702
Trained batch 716 in epoch 4, gen_loss = 1.1538317131198101, disc_loss = 0.000917200414990588
Trained batch 717 in epoch 4, gen_loss = 1.1537003348630783, disc_loss = 0.000916261074663734
Trained batch 718 in epoch 4, gen_loss = 1.1538644562344558, disc_loss = 0.0009154131677635118
Trained batch 719 in epoch 4, gen_loss = 1.1536282408568594, disc_loss = 0.0009145963479871474
Trained batch 720 in epoch 4, gen_loss = 1.1535240332395789, disc_loss = 0.0009141321307814831
Trained batch 721 in epoch 4, gen_loss = 1.1534871767762624, disc_loss = 0.000914463029851572
Trained batch 722 in epoch 4, gen_loss = 1.153742239353238, disc_loss = 0.0009158961279662313
Trained batch 723 in epoch 4, gen_loss = 1.1538452728347883, disc_loss = 0.0009177437636056447
Trained batch 724 in epoch 4, gen_loss = 1.1540342556197067, disc_loss = 0.0009193723100831668
Trained batch 725 in epoch 4, gen_loss = 1.1539461236683133, disc_loss = 0.000920362593328706
Trained batch 726 in epoch 4, gen_loss = 1.154426292015401, disc_loss = 0.0009204994232097239
Trained batch 727 in epoch 4, gen_loss = 1.1544271321087094, disc_loss = 0.0009200424583968425
Trained batch 728 in epoch 4, gen_loss = 1.1541188885809135, disc_loss = 0.0009195466630211271
Trained batch 729 in epoch 4, gen_loss = 1.1541351121582397, disc_loss = 0.0009189907734502387
Trained batch 730 in epoch 4, gen_loss = 1.1541078386652486, disc_loss = 0.0009183979563118199
Trained batch 731 in epoch 4, gen_loss = 1.1540827882257316, disc_loss = 0.0009179739655272863
Trained batch 732 in epoch 4, gen_loss = 1.1539438953991639, disc_loss = 0.0009175380800677893
Trained batch 733 in epoch 4, gen_loss = 1.1536611801759424, disc_loss = 0.0009168268300971011
Trained batch 734 in epoch 4, gen_loss = 1.153595558396813, disc_loss = 0.0009162356789131985
Trained batch 735 in epoch 4, gen_loss = 1.1534874927576468, disc_loss = 0.0009154809085094198
Trained batch 736 in epoch 4, gen_loss = 1.1538146081578942, disc_loss = 0.0009150452836191729
Trained batch 737 in epoch 4, gen_loss = 1.1541122344289692, disc_loss = 0.0009149471330986457
Trained batch 738 in epoch 4, gen_loss = 1.1540280252251476, disc_loss = 0.0009146502162884361
Trained batch 739 in epoch 4, gen_loss = 1.1537948035710566, disc_loss = 0.0009137918384088128
Trained batch 740 in epoch 4, gen_loss = 1.1534446046741706, disc_loss = 0.0009136052983897825
Trained batch 741 in epoch 4, gen_loss = 1.1534949703357933, disc_loss = 0.0009141778137620835
Trained batch 742 in epoch 4, gen_loss = 1.153595471927648, disc_loss = 0.0009146228934118642
Trained batch 743 in epoch 4, gen_loss = 1.1537332464289922, disc_loss = 0.0009144828224135938
Trained batch 744 in epoch 4, gen_loss = 1.153913010686836, disc_loss = 0.0009137873899976054
Trained batch 745 in epoch 4, gen_loss = 1.15381749785298, disc_loss = 0.0009128437484213495
Trained batch 746 in epoch 4, gen_loss = 1.1534374411326336, disc_loss = 0.0009120295990616584
Trained batch 747 in epoch 4, gen_loss = 1.1535443234889902, disc_loss = 0.00091135384724491
Trained batch 748 in epoch 4, gen_loss = 1.1537214059218546, disc_loss = 0.0009107482796188292
Trained batch 749 in epoch 4, gen_loss = 1.1536384765307108, disc_loss = 0.0009098901876908106
Trained batch 750 in epoch 4, gen_loss = 1.1536933680507695, disc_loss = 0.000909089105308072
Trained batch 751 in epoch 4, gen_loss = 1.1535160173761083, disc_loss = 0.0009081982424059459
Trained batch 752 in epoch 4, gen_loss = 1.15365999295892, disc_loss = 0.0009077191148962823
Trained batch 753 in epoch 4, gen_loss = 1.1537320602793908, disc_loss = 0.0009069953922101109
Trained batch 754 in epoch 4, gen_loss = 1.1537946113687478, disc_loss = 0.0009060923636325061
Trained batch 755 in epoch 4, gen_loss = 1.1538170770047202, disc_loss = 0.000905229055841494
Trained batch 756 in epoch 4, gen_loss = 1.153639501435596, disc_loss = 0.0009044029149514422
Trained batch 757 in epoch 4, gen_loss = 1.1535171308114849, disc_loss = 0.0009034621889393047
Trained batch 758 in epoch 4, gen_loss = 1.1534032769825147, disc_loss = 0.0009026938957296869
Trained batch 759 in epoch 4, gen_loss = 1.1532747017709832, disc_loss = 0.0009022701167659282
Trained batch 760 in epoch 4, gen_loss = 1.1537071605862832, disc_loss = 0.0009020950696876262
Trained batch 761 in epoch 4, gen_loss = 1.1536728863328147, disc_loss = 0.0009019111090893075
Trained batch 762 in epoch 4, gen_loss = 1.1534695781542776, disc_loss = 0.000901471995235162
Trained batch 763 in epoch 4, gen_loss = 1.153314561900044, disc_loss = 0.0009007922518126488
Trained batch 764 in epoch 4, gen_loss = 1.1530011234719768, disc_loss = 0.0009000721143511447
Trained batch 765 in epoch 4, gen_loss = 1.1528002062603326, disc_loss = 0.0009000134996028177
Trained batch 766 in epoch 4, gen_loss = 1.1529466115822227, disc_loss = 0.0008997611473704538
Trained batch 767 in epoch 4, gen_loss = 1.152805363914619, disc_loss = 0.0008991703368981993
Trained batch 768 in epoch 4, gen_loss = 1.152610519152469, disc_loss = 0.0008984297069532297
Trained batch 769 in epoch 4, gen_loss = 1.1524473286294319, disc_loss = 0.0008975030560660261
Trained batch 770 in epoch 4, gen_loss = 1.152461115642899, disc_loss = 0.0008965260292025616
Trained batch 771 in epoch 4, gen_loss = 1.1524556277638272, disc_loss = 0.000895635567960924
Trained batch 772 in epoch 4, gen_loss = 1.1527408568084934, disc_loss = 0.000895272611576689
Trained batch 773 in epoch 4, gen_loss = 1.1529861802586598, disc_loss = 0.0008951436524023423
Trained batch 774 in epoch 4, gen_loss = 1.1532419447745046, disc_loss = 0.0008945060468226251
Trained batch 775 in epoch 4, gen_loss = 1.1533042499699544, disc_loss = 0.0008936815625442175
Trained batch 776 in epoch 4, gen_loss = 1.1533094388330918, disc_loss = 0.0008927986082819289
Trained batch 777 in epoch 4, gen_loss = 1.1530926544745967, disc_loss = 0.0008919539471659067
Trained batch 778 in epoch 4, gen_loss = 1.1530376045327437, disc_loss = 0.000891222973034056
Trained batch 779 in epoch 4, gen_loss = 1.1528884556048955, disc_loss = 0.0008906661204841489
Trained batch 780 in epoch 4, gen_loss = 1.1526515178582732, disc_loss = 0.0008901268754392342
Trained batch 781 in epoch 4, gen_loss = 1.1526684587264, disc_loss = 0.0008893483782486628
Trained batch 782 in epoch 4, gen_loss = 1.152696636597011, disc_loss = 0.0008885170810940374
Trained batch 783 in epoch 4, gen_loss = 1.1527957694262874, disc_loss = 0.0008875980539618912
Trained batch 784 in epoch 4, gen_loss = 1.1529724695120647, disc_loss = 0.0008869081549309372
Trained batch 785 in epoch 4, gen_loss = 1.1530248181510518, disc_loss = 0.0008865672340621027
Trained batch 786 in epoch 4, gen_loss = 1.153235340057819, disc_loss = 0.000885935629197465
Trained batch 787 in epoch 4, gen_loss = 1.1533190928739945, disc_loss = 0.0008850469913447115
Trained batch 788 in epoch 4, gen_loss = 1.1532121221375555, disc_loss = 0.0008841159219230338
Trained batch 789 in epoch 4, gen_loss = 1.1532823076731042, disc_loss = 0.0008832106823388994
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 1.0710561275482178, disc_loss = 0.00023653946118429303
Trained batch 1 in epoch 5, gen_loss = 1.2472688555717468, disc_loss = 0.0003439377906033769
Trained batch 2 in epoch 5, gen_loss = 1.1970426241556804, disc_loss = 0.00040511948949036497
Trained batch 3 in epoch 5, gen_loss = 1.1438945829868317, disc_loss = 0.0004112624592380598
Trained batch 4 in epoch 5, gen_loss = 1.1455685377120972, disc_loss = 0.00038983061676844954
Trained batch 5 in epoch 5, gen_loss = 1.138057013352712, disc_loss = 0.00036519136241016287
Trained batch 6 in epoch 5, gen_loss = 1.1121564592633928, disc_loss = 0.00038062383620334525
Trained batch 7 in epoch 5, gen_loss = 1.087346151471138, disc_loss = 0.0004312857781769708
Trained batch 8 in epoch 5, gen_loss = 1.0952202081680298, disc_loss = 0.00044066045666113496
Trained batch 9 in epoch 5, gen_loss = 1.100018322467804, disc_loss = 0.00043633596797008065
Trained batch 10 in epoch 5, gen_loss = 1.1043989875099876, disc_loss = 0.00042544613560577005
Trained batch 11 in epoch 5, gen_loss = 1.108548899491628, disc_loss = 0.0004456768001546152
Trained batch 12 in epoch 5, gen_loss = 1.1055677578999445, disc_loss = 0.00046513060134692263
Trained batch 13 in epoch 5, gen_loss = 1.1233814529010229, disc_loss = 0.00046173179414056776
Trained batch 14 in epoch 5, gen_loss = 1.1410259405771892, disc_loss = 0.0004886807893247654
Trained batch 15 in epoch 5, gen_loss = 1.1475141420960426, disc_loss = 0.0005153617112227948
Trained batch 16 in epoch 5, gen_loss = 1.1588670436073751, disc_loss = 0.0005230845400707467
Trained batch 17 in epoch 5, gen_loss = 1.1645719210306804, disc_loss = 0.0005496497534396541
Trained batch 18 in epoch 5, gen_loss = 1.164874741905614, disc_loss = 0.000592830270761624
Trained batch 19 in epoch 5, gen_loss = 1.1525484502315522, disc_loss = 0.0006146463318145833
Trained batch 20 in epoch 5, gen_loss = 1.1468956527255831, disc_loss = 0.0006239368522074074
Trained batch 21 in epoch 5, gen_loss = 1.1491182012991472, disc_loss = 0.0006286923241780394
Trained batch 22 in epoch 5, gen_loss = 1.1537323464518008, disc_loss = 0.0006394853509213451
Trained batch 23 in epoch 5, gen_loss = 1.1723015109697978, disc_loss = 0.0006543690239292724
Trained batch 24 in epoch 5, gen_loss = 1.1767155838012695, disc_loss = 0.0006535776692908257
Trained batch 25 in epoch 5, gen_loss = 1.174527039894691, disc_loss = 0.000650454674122067
Trained batch 26 in epoch 5, gen_loss = 1.1765491211855854, disc_loss = 0.0006499420926923415
Trained batch 27 in epoch 5, gen_loss = 1.1756793473448073, disc_loss = 0.000648334546505274
Trained batch 28 in epoch 5, gen_loss = 1.1744834760139728, disc_loss = 0.0006440813875965903
Trained batch 29 in epoch 5, gen_loss = 1.1668948570887248, disc_loss = 0.000643444262095727
Trained batch 30 in epoch 5, gen_loss = 1.1760985889742452, disc_loss = 0.0006459174581968616
Trained batch 31 in epoch 5, gen_loss = 1.1721787340939045, disc_loss = 0.0006723360793330357
Trained batch 32 in epoch 5, gen_loss = 1.1666159196333452, disc_loss = 0.0007129097860094837
Trained batch 33 in epoch 5, gen_loss = 1.1705510335810043, disc_loss = 0.0007245796946603257
Trained batch 34 in epoch 5, gen_loss = 1.1715599196297781, disc_loss = 0.0007176794785274459
Trained batch 35 in epoch 5, gen_loss = 1.1737982001569536, disc_loss = 0.0007041757190664713
Trained batch 36 in epoch 5, gen_loss = 1.1765685242575568, disc_loss = 0.0006908907171974361
Trained batch 37 in epoch 5, gen_loss = 1.1797433777859336, disc_loss = 0.0006795461725376203
Trained batch 38 in epoch 5, gen_loss = 1.1807800806485689, disc_loss = 0.0006725888550788976
Trained batch 39 in epoch 5, gen_loss = 1.1761816009879111, disc_loss = 0.0006682970943074906
Trained batch 40 in epoch 5, gen_loss = 1.1757151688017495, disc_loss = 0.0006642960861648955
Trained batch 41 in epoch 5, gen_loss = 1.1767165845348722, disc_loss = 0.0006578992238029882
Trained batch 42 in epoch 5, gen_loss = 1.1747312171514643, disc_loss = 0.0006489329324997311
Trained batch 43 in epoch 5, gen_loss = 1.1708286499435252, disc_loss = 0.0006406677722142459
Trained batch 44 in epoch 5, gen_loss = 1.1677496605449253, disc_loss = 0.0006369176977184704
Trained batch 45 in epoch 5, gen_loss = 1.1607405374879423, disc_loss = 0.0006416448674787281
Trained batch 46 in epoch 5, gen_loss = 1.1597950598026843, disc_loss = 0.0006405170966667976
Trained batch 47 in epoch 5, gen_loss = 1.1549386121332645, disc_loss = 0.0006453746400438831
Trained batch 48 in epoch 5, gen_loss = 1.1572419319834029, disc_loss = 0.0006668317040822906
Trained batch 49 in epoch 5, gen_loss = 1.1570979177951812, disc_loss = 0.0006918094385764561
Trained batch 50 in epoch 5, gen_loss = 1.1578757073365005, disc_loss = 0.0007061564541015518
Trained batch 51 in epoch 5, gen_loss = 1.154571566444177, disc_loss = 0.0007109836226915761
Trained batch 52 in epoch 5, gen_loss = 1.1620874596091937, disc_loss = 0.0007139082099113368
Trained batch 53 in epoch 5, gen_loss = 1.159220184440966, disc_loss = 0.000715494555522498
Trained batch 54 in epoch 5, gen_loss = 1.1561775164170698, disc_loss = 0.0007139070528368889
Trained batch 55 in epoch 5, gen_loss = 1.1553564199379511, disc_loss = 0.0007091355559428589
Trained batch 56 in epoch 5, gen_loss = 1.1532159792749506, disc_loss = 0.0007020231592162561
Trained batch 57 in epoch 5, gen_loss = 1.1548923541759621, disc_loss = 0.0006977857337915339
Trained batch 58 in epoch 5, gen_loss = 1.1532419616893186, disc_loss = 0.0006951595919494817
Trained batch 59 in epoch 5, gen_loss = 1.1598141312599182, disc_loss = 0.000689541427467096
Trained batch 60 in epoch 5, gen_loss = 1.156470687662969, disc_loss = 0.0006848953014953428
Trained batch 61 in epoch 5, gen_loss = 1.1538294688347848, disc_loss = 0.0006807046398358991
Trained batch 62 in epoch 5, gen_loss = 1.1545791379989139, disc_loss = 0.0006747977493519318
Trained batch 63 in epoch 5, gen_loss = 1.1552703026682138, disc_loss = 0.0006677537878658768
Trained batch 64 in epoch 5, gen_loss = 1.1521163747860834, disc_loss = 0.0006604775911770188
Trained batch 65 in epoch 5, gen_loss = 1.1545399382258907, disc_loss = 0.0006535011138608256
Trained batch 66 in epoch 5, gen_loss = 1.1523643563042825, disc_loss = 0.0006486404938675436
Trained batch 67 in epoch 5, gen_loss = 1.1515100940185434, disc_loss = 0.0006436027630543857
Trained batch 68 in epoch 5, gen_loss = 1.15260573660118, disc_loss = 0.0006389736712056523
Trained batch 69 in epoch 5, gen_loss = 1.1528324782848358, disc_loss = 0.0006378879178165724
Trained batch 70 in epoch 5, gen_loss = 1.1539032199013401, disc_loss = 0.0006360404148720809
Trained batch 71 in epoch 5, gen_loss = 1.1552542621890705, disc_loss = 0.0006323036009740059
Trained batch 72 in epoch 5, gen_loss = 1.152882885443021, disc_loss = 0.0006256138250847309
Trained batch 73 in epoch 5, gen_loss = 1.1516179176601204, disc_loss = 0.0006202446150112066
Trained batch 74 in epoch 5, gen_loss = 1.1517821256319682, disc_loss = 0.0006145118190518891
Trained batch 75 in epoch 5, gen_loss = 1.152423162993632, disc_loss = 0.0006093108233088922
Trained batch 76 in epoch 5, gen_loss = 1.1542361130962124, disc_loss = 0.0006045468985753182
Trained batch 77 in epoch 5, gen_loss = 1.1521961780694814, disc_loss = 0.000599890178142605
Trained batch 78 in epoch 5, gen_loss = 1.1483572585673272, disc_loss = 0.0005944920046169523
Trained batch 79 in epoch 5, gen_loss = 1.1479373633861543, disc_loss = 0.0005896673816096154
Trained batch 80 in epoch 5, gen_loss = 1.1451869599613143, disc_loss = 0.0005863582020852554
Trained batch 81 in epoch 5, gen_loss = 1.146349261446697, disc_loss = 0.0005854513656231575
Trained batch 82 in epoch 5, gen_loss = 1.1456355933683464, disc_loss = 0.0005854525004095588
Trained batch 83 in epoch 5, gen_loss = 1.1448021332422893, disc_loss = 0.0005836608427108288
Trained batch 84 in epoch 5, gen_loss = 1.1456246880924001, disc_loss = 0.0005816493571996141
Trained batch 85 in epoch 5, gen_loss = 1.1480683781379877, disc_loss = 0.0005773387911599563
Trained batch 86 in epoch 5, gen_loss = 1.147595206896464, disc_loss = 0.0005723922563604368
Trained batch 87 in epoch 5, gen_loss = 1.1468405710025267, disc_loss = 0.0005673260731617285
Trained batch 88 in epoch 5, gen_loss = 1.147431444585993, disc_loss = 0.0005624682186014448
Trained batch 89 in epoch 5, gen_loss = 1.147214444478353, disc_loss = 0.0005576640241391335
Trained batch 90 in epoch 5, gen_loss = 1.1461108936058295, disc_loss = 0.0005544231578344376
Trained batch 91 in epoch 5, gen_loss = 1.1456227769022402, disc_loss = 0.0005539694675067237
Trained batch 92 in epoch 5, gen_loss = 1.1477049948066793, disc_loss = 0.0005549186836272198
Trained batch 93 in epoch 5, gen_loss = 1.1481127536043207, disc_loss = 0.0005564091054034082
Trained batch 94 in epoch 5, gen_loss = 1.147074542547527, disc_loss = 0.0005530633240644085
Trained batch 95 in epoch 5, gen_loss = 1.1487880821029346, disc_loss = 0.0005533659229210267
Trained batch 96 in epoch 5, gen_loss = 1.1483035407115503, disc_loss = 0.0005537979022753377
Trained batch 97 in epoch 5, gen_loss = 1.1492530594066697, disc_loss = 0.0005538455425638097
Trained batch 98 in epoch 5, gen_loss = 1.1491966295723963, disc_loss = 0.000551710460003409
Trained batch 99 in epoch 5, gen_loss = 1.148090192079544, disc_loss = 0.0005494366091443226
Trained batch 100 in epoch 5, gen_loss = 1.1474114148923666, disc_loss = 0.0005468672854908843
Trained batch 101 in epoch 5, gen_loss = 1.1464298916798012, disc_loss = 0.0005435069819499154
Trained batch 102 in epoch 5, gen_loss = 1.1481720104958246, disc_loss = 0.0005435318050587333
Trained batch 103 in epoch 5, gen_loss = 1.148068448671928, disc_loss = 0.0005475323110798714
Trained batch 104 in epoch 5, gen_loss = 1.1484692936851866, disc_loss = 0.0005475326251360543
Trained batch 105 in epoch 5, gen_loss = 1.1465598491002928, disc_loss = 0.0005460221270694538
Trained batch 106 in epoch 5, gen_loss = 1.1446397020438006, disc_loss = 0.0005444234875455133
Trained batch 107 in epoch 5, gen_loss = 1.1430312003250476, disc_loss = 0.0005461819198023511
Trained batch 108 in epoch 5, gen_loss = 1.1438352618742427, disc_loss = 0.0005503302431236012
Trained batch 109 in epoch 5, gen_loss = 1.14331596493721, disc_loss = 0.0005528246183530428
Trained batch 110 in epoch 5, gen_loss = 1.1418391815176956, disc_loss = 0.0005525229182797022
Trained batch 111 in epoch 5, gen_loss = 1.1409416917179311, disc_loss = 0.0005502185822479078
Trained batch 112 in epoch 5, gen_loss = 1.1400601035725755, disc_loss = 0.0005494130004467277
Trained batch 113 in epoch 5, gen_loss = 1.1406666871748472, disc_loss = 0.0005488929893002485
Trained batch 114 in epoch 5, gen_loss = 1.1395307618638744, disc_loss = 0.0005484772369052972
Trained batch 115 in epoch 5, gen_loss = 1.139450959604362, disc_loss = 0.000550137458801679
Trained batch 116 in epoch 5, gen_loss = 1.1404320516137996, disc_loss = 0.0005518725283919539
Trained batch 117 in epoch 5, gen_loss = 1.1417309909553852, disc_loss = 0.0005531403199341385
Trained batch 118 in epoch 5, gen_loss = 1.1418162198627697, disc_loss = 0.0005533416087087635
Trained batch 119 in epoch 5, gen_loss = 1.1416076059142748, disc_loss = 0.0005533936868838889
Trained batch 120 in epoch 5, gen_loss = 1.14165764554473, disc_loss = 0.0005543835509004656
Trained batch 121 in epoch 5, gen_loss = 1.1406971709650071, disc_loss = 0.0005544174426057773
Trained batch 122 in epoch 5, gen_loss = 1.1404710790006125, disc_loss = 0.0005542527598175561
Trained batch 123 in epoch 5, gen_loss = 1.1401496072930675, disc_loss = 0.0005533645402934898
Trained batch 124 in epoch 5, gen_loss = 1.138201325416565, disc_loss = 0.0005538863848196342
Trained batch 125 in epoch 5, gen_loss = 1.1398699387671456, disc_loss = 0.0005553420430967688
Trained batch 126 in epoch 5, gen_loss = 1.1405619026169063, disc_loss = 0.0005632929182400575
Trained batch 127 in epoch 5, gen_loss = 1.1395909367129207, disc_loss = 0.00057173756897555
Trained batch 128 in epoch 5, gen_loss = 1.1390810003576353, disc_loss = 0.00057827149233113
Trained batch 129 in epoch 5, gen_loss = 1.1394864559173583, disc_loss = 0.0005840088653852805
Trained batch 130 in epoch 5, gen_loss = 1.1394230555032046, disc_loss = 0.0005877459083394083
Trained batch 131 in epoch 5, gen_loss = 1.1411704168175205, disc_loss = 0.000590279144627416
Trained batch 132 in epoch 5, gen_loss = 1.1399337761384203, disc_loss = 0.0005926848613504754
Trained batch 133 in epoch 5, gen_loss = 1.1405342096713051, disc_loss = 0.0005943703395879216
Trained batch 134 in epoch 5, gen_loss = 1.1411938305254337, disc_loss = 0.0005945175425882486
Trained batch 135 in epoch 5, gen_loss = 1.1406352782950682, disc_loss = 0.0005991006718806388
Trained batch 136 in epoch 5, gen_loss = 1.1410548138792498, disc_loss = 0.0006083324395441349
Trained batch 137 in epoch 5, gen_loss = 1.140752192856609, disc_loss = 0.0006140162574635157
Trained batch 138 in epoch 5, gen_loss = 1.1417090738420006, disc_loss = 0.0006146174810513546
Trained batch 139 in epoch 5, gen_loss = 1.1414532320840018, disc_loss = 0.0006146984970005828
Trained batch 140 in epoch 5, gen_loss = 1.141011562753231, disc_loss = 0.0006219259301631494
Trained batch 141 in epoch 5, gen_loss = 1.140274919254679, disc_loss = 0.0006353107284513485
Trained batch 142 in epoch 5, gen_loss = 1.1412354874444175, disc_loss = 0.0006431111260162589
Trained batch 143 in epoch 5, gen_loss = 1.1415008414122794, disc_loss = 0.0006449166928885259
Trained batch 144 in epoch 5, gen_loss = 1.1414643131453415, disc_loss = 0.0006444066840199883
Trained batch 145 in epoch 5, gen_loss = 1.1407467567757383, disc_loss = 0.0006423314226183671
Trained batch 146 in epoch 5, gen_loss = 1.141544440165669, disc_loss = 0.0006395677734383375
Trained batch 147 in epoch 5, gen_loss = 1.1442750313797512, disc_loss = 0.0006363447805720294
Trained batch 148 in epoch 5, gen_loss = 1.1441818835751323, disc_loss = 0.0006383415544991563
Trained batch 149 in epoch 5, gen_loss = 1.1450920804341633, disc_loss = 0.0006487377111140328
Trained batch 150 in epoch 5, gen_loss = 1.1455831496131341, disc_loss = 0.0006591753558285029
Trained batch 151 in epoch 5, gen_loss = 1.1462513427985341, disc_loss = 0.0006624431598059968
Trained batch 152 in epoch 5, gen_loss = 1.1452374384294148, disc_loss = 0.0006648954307451978
Trained batch 153 in epoch 5, gen_loss = 1.1447842171439877, disc_loss = 0.0006662566374870948
Trained batch 154 in epoch 5, gen_loss = 1.1447411479488496, disc_loss = 0.0006667912857899923
Trained batch 155 in epoch 5, gen_loss = 1.1454401295154522, disc_loss = 0.0006671608428475268
Trained batch 156 in epoch 5, gen_loss = 1.1460214059823637, disc_loss = 0.0006675081438597019
Trained batch 157 in epoch 5, gen_loss = 1.1457451698900778, disc_loss = 0.000667966125202159
Trained batch 158 in epoch 5, gen_loss = 1.1456172537503753, disc_loss = 0.000667714894476124
Trained batch 159 in epoch 5, gen_loss = 1.144510319456458, disc_loss = 0.0006664341300165688
Trained batch 160 in epoch 5, gen_loss = 1.1442941268038305, disc_loss = 0.0006655216203844869
Trained batch 161 in epoch 5, gen_loss = 1.1438645091321733, disc_loss = 0.0006629428839746483
Trained batch 162 in epoch 5, gen_loss = 1.1437124617260659, disc_loss = 0.000660345338619217
Trained batch 163 in epoch 5, gen_loss = 1.1439944472981662, disc_loss = 0.0006574701310899222
Trained batch 164 in epoch 5, gen_loss = 1.143235805901614, disc_loss = 0.0006555083846306485
Trained batch 165 in epoch 5, gen_loss = 1.1435772866369731, disc_loss = 0.0006536192764564563
Trained batch 166 in epoch 5, gen_loss = 1.1437635753682986, disc_loss = 0.0006514377991353792
Trained batch 167 in epoch 5, gen_loss = 1.144728189068181, disc_loss = 0.000648569208351546
Trained batch 168 in epoch 5, gen_loss = 1.1443864308165375, disc_loss = 0.0006460669932138869
Trained batch 169 in epoch 5, gen_loss = 1.1426272283582126, disc_loss = 0.0006441913083750371
Trained batch 170 in epoch 5, gen_loss = 1.142606614974507, disc_loss = 0.0006411348419602313
Trained batch 171 in epoch 5, gen_loss = 1.141822101418362, disc_loss = 0.0006394524386218278
Trained batch 172 in epoch 5, gen_loss = 1.1421755149185313, disc_loss = 0.0006385894931433588
Trained batch 173 in epoch 5, gen_loss = 1.1421697088356675, disc_loss = 0.0006363459860845121
Trained batch 174 in epoch 5, gen_loss = 1.1429699444770813, disc_loss = 0.0006336772593619701
Trained batch 175 in epoch 5, gen_loss = 1.142795880748467, disc_loss = 0.0006313670252728281
Trained batch 176 in epoch 5, gen_loss = 1.1436832506777876, disc_loss = 0.0006298589937229073
Trained batch 177 in epoch 5, gen_loss = 1.1428233957692477, disc_loss = 0.000628507313859097
Trained batch 178 in epoch 5, gen_loss = 1.1428470195338714, disc_loss = 0.0006269318918328779
Trained batch 179 in epoch 5, gen_loss = 1.1430915895435545, disc_loss = 0.0006248643931030529
Trained batch 180 in epoch 5, gen_loss = 1.1425562118957056, disc_loss = 0.0006222625937810019
Trained batch 181 in epoch 5, gen_loss = 1.1412226125434204, disc_loss = 0.0006199463723233138
Trained batch 182 in epoch 5, gen_loss = 1.1413779121930483, disc_loss = 0.0006193233631399226
Trained batch 183 in epoch 5, gen_loss = 1.1410632269537968, disc_loss = 0.0006192393491247734
Trained batch 184 in epoch 5, gen_loss = 1.1407056763365462, disc_loss = 0.0006184127056307311
Trained batch 185 in epoch 5, gen_loss = 1.1411091569931275, disc_loss = 0.0006163891518544231
Trained batch 186 in epoch 5, gen_loss = 1.1419668165757695, disc_loss = 0.000614046085497332
Trained batch 187 in epoch 5, gen_loss = 1.1417471170425415, disc_loss = 0.0006121320414596529
Trained batch 188 in epoch 5, gen_loss = 1.1412123284011921, disc_loss = 0.0006101320410457134
Trained batch 189 in epoch 5, gen_loss = 1.141197669506073, disc_loss = 0.0006077884737399137
Trained batch 190 in epoch 5, gen_loss = 1.1402797493010914, disc_loss = 0.0006058120678214927
Trained batch 191 in epoch 5, gen_loss = 1.1405976644406717, disc_loss = 0.0006035140885387591
Trained batch 192 in epoch 5, gen_loss = 1.1403278816549272, disc_loss = 0.0006011691977920788
Trained batch 193 in epoch 5, gen_loss = 1.1398927913498633, disc_loss = 0.0005994077854637973
Trained batch 194 in epoch 5, gen_loss = 1.1396233564768081, disc_loss = 0.0005981833779608282
Trained batch 195 in epoch 5, gen_loss = 1.1396997516252556, disc_loss = 0.0005968827850405692
Trained batch 196 in epoch 5, gen_loss = 1.1384951526743508, disc_loss = 0.0005964609933706819
Trained batch 197 in epoch 5, gen_loss = 1.139354597739499, disc_loss = 0.0005951131050721296
Trained batch 198 in epoch 5, gen_loss = 1.1396360034918664, disc_loss = 0.0005931508257249768
Trained batch 199 in epoch 5, gen_loss = 1.140887579023838, disc_loss = 0.0005911562042820151
Trained batch 200 in epoch 5, gen_loss = 1.141398780084961, disc_loss = 0.0005900372763147546
Trained batch 201 in epoch 5, gen_loss = 1.1408083276583416, disc_loss = 0.0005886162604054893
Trained batch 202 in epoch 5, gen_loss = 1.1399387629161328, disc_loss = 0.0005868117374398407
Trained batch 203 in epoch 5, gen_loss = 1.1400607926588433, disc_loss = 0.0005847917297668412
Trained batch 204 in epoch 5, gen_loss = 1.13989670887226, disc_loss = 0.000583320779892014
Trained batch 205 in epoch 5, gen_loss = 1.139312784937979, disc_loss = 0.0005836529482127217
Trained batch 206 in epoch 5, gen_loss = 1.1388752555501633, disc_loss = 0.0005838234496152744
Trained batch 207 in epoch 5, gen_loss = 1.1392610683464086, disc_loss = 0.0005829180942363074
Trained batch 208 in epoch 5, gen_loss = 1.1384891553928977, disc_loss = 0.0005819175052125136
Trained batch 209 in epoch 5, gen_loss = 1.139310194480987, disc_loss = 0.000582319142059922
Trained batch 210 in epoch 5, gen_loss = 1.1395042623388825, disc_loss = 0.000583747810011308
Trained batch 211 in epoch 5, gen_loss = 1.1397169876211095, disc_loss = 0.0005841237411656931
Trained batch 212 in epoch 5, gen_loss = 1.139894341359116, disc_loss = 0.0005832714324955339
Trained batch 213 in epoch 5, gen_loss = 1.1408174881868274, disc_loss = 0.0005824731733385043
Trained batch 214 in epoch 5, gen_loss = 1.1405699172685313, disc_loss = 0.0005817163500428568
Trained batch 215 in epoch 5, gen_loss = 1.139998923573229, disc_loss = 0.0005806704363109289
Trained batch 216 in epoch 5, gen_loss = 1.139219881477444, disc_loss = 0.0005796371124191789
Trained batch 217 in epoch 5, gen_loss = 1.138973639372292, disc_loss = 0.0005787149178296213
Trained batch 218 in epoch 5, gen_loss = 1.139512500534319, disc_loss = 0.000578150364096419
Trained batch 219 in epoch 5, gen_loss = 1.1402910983020609, disc_loss = 0.0005777462257604136
Trained batch 220 in epoch 5, gen_loss = 1.141215272888339, disc_loss = 0.0005767260828833475
Trained batch 221 in epoch 5, gen_loss = 1.1418616172966656, disc_loss = 0.0005753211005392111
Trained batch 222 in epoch 5, gen_loss = 1.1422128001136096, disc_loss = 0.0005749735999562686
Trained batch 223 in epoch 5, gen_loss = 1.1416687318789107, disc_loss = 0.0005752380107943671
Trained batch 224 in epoch 5, gen_loss = 1.1406508662965562, disc_loss = 0.0005756750344880857
Trained batch 225 in epoch 5, gen_loss = 1.1399598675491536, disc_loss = 0.0005769884069638215
Trained batch 226 in epoch 5, gen_loss = 1.1404212098814843, disc_loss = 0.000576986575768163
Trained batch 227 in epoch 5, gen_loss = 1.1397599196224881, disc_loss = 0.0005773606567744169
Trained batch 228 in epoch 5, gen_loss = 1.1390544025137956, disc_loss = 0.0005818640633842574
Trained batch 229 in epoch 5, gen_loss = 1.1384107486061428, disc_loss = 0.0005834670905998159
Trained batch 230 in epoch 5, gen_loss = 1.138800276822342, disc_loss = 0.0005839744511776547
Trained batch 231 in epoch 5, gen_loss = 1.1389689512293915, disc_loss = 0.0005835090713499712
Trained batch 232 in epoch 5, gen_loss = 1.1388683349789468, disc_loss = 0.0005821839478399001
Trained batch 233 in epoch 5, gen_loss = 1.1387874417834811, disc_loss = 0.0005805086529861965
Trained batch 234 in epoch 5, gen_loss = 1.1388960336117033, disc_loss = 0.0005796027356483775
Trained batch 235 in epoch 5, gen_loss = 1.1388514153027938, disc_loss = 0.0005803152146392553
Trained batch 236 in epoch 5, gen_loss = 1.1403545810200495, disc_loss = 0.0005819416367746045
Trained batch 237 in epoch 5, gen_loss = 1.1395715284748238, disc_loss = 0.0005857084479201056
Trained batch 238 in epoch 5, gen_loss = 1.139448041197645, disc_loss = 0.0005871941700880221
Trained batch 239 in epoch 5, gen_loss = 1.1388743241628012, disc_loss = 0.0005880232593881374
Trained batch 240 in epoch 5, gen_loss = 1.1397484110598741, disc_loss = 0.0005895143470022136
Trained batch 241 in epoch 5, gen_loss = 1.1397289077112498, disc_loss = 0.0005901125140936972
Trained batch 242 in epoch 5, gen_loss = 1.139367386146828, disc_loss = 0.0005899184014144691
Trained batch 243 in epoch 5, gen_loss = 1.139656700560304, disc_loss = 0.0005891847222450391
Trained batch 244 in epoch 5, gen_loss = 1.1396507010167958, disc_loss = 0.0005880542045128912
Trained batch 245 in epoch 5, gen_loss = 1.1395455526142586, disc_loss = 0.0005873584115938795
Trained batch 246 in epoch 5, gen_loss = 1.1389652867066233, disc_loss = 0.000586276577045879
Trained batch 247 in epoch 5, gen_loss = 1.1386518113074764, disc_loss = 0.0005845787125273942
Trained batch 248 in epoch 5, gen_loss = 1.1391577083901707, disc_loss = 0.0005827824101303181
Trained batch 249 in epoch 5, gen_loss = 1.1383367228507995, disc_loss = 0.0005813761934696231
Trained batch 250 in epoch 5, gen_loss = 1.1374954436404772, disc_loss = 0.0005799720692088869
Trained batch 251 in epoch 5, gen_loss = 1.1372704742446778, disc_loss = 0.0005785542059403803
Trained batch 252 in epoch 5, gen_loss = 1.1371866544715972, disc_loss = 0.0005769181994340757
Trained batch 253 in epoch 5, gen_loss = 1.1370831831233708, disc_loss = 0.0005755122031365231
Trained batch 254 in epoch 5, gen_loss = 1.136477434868906, disc_loss = 0.0005740317968850244
Trained batch 255 in epoch 5, gen_loss = 1.136426292359829, disc_loss = 0.0005729836862826687
Trained batch 256 in epoch 5, gen_loss = 1.1354568658635773, disc_loss = 0.0005736901538466024
Trained batch 257 in epoch 5, gen_loss = 1.1348212499951207, disc_loss = 0.0005754905903940685
Trained batch 258 in epoch 5, gen_loss = 1.1349983689407583, disc_loss = 0.0005764478661556383
Trained batch 259 in epoch 5, gen_loss = 1.1348115095725426, disc_loss = 0.0005782799238659208
Trained batch 260 in epoch 5, gen_loss = 1.1355350364670442, disc_loss = 0.0005807424528322225
Trained batch 261 in epoch 5, gen_loss = 1.1346984446503734, disc_loss = 0.0005826778834690571
Trained batch 262 in epoch 5, gen_loss = 1.1341617581055645, disc_loss = 0.0005836999905594455
Trained batch 263 in epoch 5, gen_loss = 1.1339451961896636, disc_loss = 0.000583083209951865
Trained batch 264 in epoch 5, gen_loss = 1.1338787175574392, disc_loss = 0.0005825667052017964
Trained batch 265 in epoch 5, gen_loss = 1.1340609674615072, disc_loss = 0.0005822436549187431
Trained batch 266 in epoch 5, gen_loss = 1.1340061531084753, disc_loss = 0.0005818702804989859
Trained batch 267 in epoch 5, gen_loss = 1.1346392509207797, disc_loss = 0.0005817781972171957
Trained batch 268 in epoch 5, gen_loss = 1.134192988553455, disc_loss = 0.0005813570440559454
Trained batch 269 in epoch 5, gen_loss = 1.1340155246081176, disc_loss = 0.0005808124192332832
Trained batch 270 in epoch 5, gen_loss = 1.1339546197894754, disc_loss = 0.0005798078592034569
Trained batch 271 in epoch 5, gen_loss = 1.1336469437707872, disc_loss = 0.0005786621190429072
Trained batch 272 in epoch 5, gen_loss = 1.1331152865738223, disc_loss = 0.0005774029981054539
Trained batch 273 in epoch 5, gen_loss = 1.133046970097688, disc_loss = 0.000578169659922795
Trained batch 274 in epoch 5, gen_loss = 1.1325508323582736, disc_loss = 0.0005796228746872988
Trained batch 275 in epoch 5, gen_loss = 1.1320580464342367, disc_loss = 0.0005791891019897236
Trained batch 276 in epoch 5, gen_loss = 1.1320924281213258, disc_loss = 0.0005781727519955079
Trained batch 277 in epoch 5, gen_loss = 1.1318187254795926, disc_loss = 0.0005770723742218068
Trained batch 278 in epoch 5, gen_loss = 1.1316275241981697, disc_loss = 0.0005758692147462682
Trained batch 279 in epoch 5, gen_loss = 1.131861589210374, disc_loss = 0.0005748506048413609
Trained batch 280 in epoch 5, gen_loss = 1.132024593200548, disc_loss = 0.0005737635129335622
Trained batch 281 in epoch 5, gen_loss = 1.1329345255033345, disc_loss = 0.0005729039643070882
Trained batch 282 in epoch 5, gen_loss = 1.1325330068702832, disc_loss = 0.0005717198710237438
Trained batch 283 in epoch 5, gen_loss = 1.1327489014242735, disc_loss = 0.0005704942096074351
Trained batch 284 in epoch 5, gen_loss = 1.1332385493997943, disc_loss = 0.0005692969758233072
Trained batch 285 in epoch 5, gen_loss = 1.1327227654156986, disc_loss = 0.0005681671212511577
Trained batch 286 in epoch 5, gen_loss = 1.1328259262058378, disc_loss = 0.0005686114461212711
Trained batch 287 in epoch 5, gen_loss = 1.1334504650698767, disc_loss = 0.0005703090652231266
Trained batch 288 in epoch 5, gen_loss = 1.134030614344719, disc_loss = 0.000571925623863444
Trained batch 289 in epoch 5, gen_loss = 1.1354094727285977, disc_loss = 0.0005716259382285804
Trained batch 290 in epoch 5, gen_loss = 1.1352388383596623, disc_loss = 0.0005746832448431879
Trained batch 291 in epoch 5, gen_loss = 1.1347916432439464, disc_loss = 0.0005786490741204582
Trained batch 292 in epoch 5, gen_loss = 1.134672924113355, disc_loss = 0.0005787007415851137
Trained batch 293 in epoch 5, gen_loss = 1.1350013747507213, disc_loss = 0.0005787163509321669
Trained batch 294 in epoch 5, gen_loss = 1.1349289623357481, disc_loss = 0.0005797723615768966
Trained batch 295 in epoch 5, gen_loss = 1.135647196221996, disc_loss = 0.0005791679054340961
Trained batch 296 in epoch 5, gen_loss = 1.1359028479065558, disc_loss = 0.0005782148740769784
Trained batch 297 in epoch 5, gen_loss = 1.1363229943601878, disc_loss = 0.0005784649554991253
Trained batch 298 in epoch 5, gen_loss = 1.1374709159634184, disc_loss = 0.000579991138513538
Trained batch 299 in epoch 5, gen_loss = 1.1373337487379709, disc_loss = 0.0005814553274103673
Trained batch 300 in epoch 5, gen_loss = 1.137304582073047, disc_loss = 0.0005826856659373741
Trained batch 301 in epoch 5, gen_loss = 1.136959851577582, disc_loss = 0.0005826079422276119
Trained batch 302 in epoch 5, gen_loss = 1.13700272226491, disc_loss = 0.0005825310012603428
Trained batch 303 in epoch 5, gen_loss = 1.1367497232399488, disc_loss = 0.0005821392352883873
Trained batch 304 in epoch 5, gen_loss = 1.1362047498343422, disc_loss = 0.000581222308439882
Trained batch 305 in epoch 5, gen_loss = 1.1364285850446987, disc_loss = 0.0005805877859244242
Trained batch 306 in epoch 5, gen_loss = 1.1372560916972083, disc_loss = 0.0005798043685967894
Trained batch 307 in epoch 5, gen_loss = 1.137444130592532, disc_loss = 0.0005788916685607499
Trained batch 308 in epoch 5, gen_loss = 1.1376697706558943, disc_loss = 0.0005784078187662972
Trained batch 309 in epoch 5, gen_loss = 1.1383380799524245, disc_loss = 0.000578786756147653
Trained batch 310 in epoch 5, gen_loss = 1.1382808909538857, disc_loss = 0.0005789758695146875
Trained batch 311 in epoch 5, gen_loss = 1.1392439812039719, disc_loss = 0.0005780261691399621
Trained batch 312 in epoch 5, gen_loss = 1.1393153250407868, disc_loss = 0.0005787583954843169
Trained batch 313 in epoch 5, gen_loss = 1.1393789863510497, disc_loss = 0.0005794364466043827
Trained batch 314 in epoch 5, gen_loss = 1.139170099250854, disc_loss = 0.0005792404168113579
Trained batch 315 in epoch 5, gen_loss = 1.1393697757886936, disc_loss = 0.0005795462893038809
Trained batch 316 in epoch 5, gen_loss = 1.1390360449014778, disc_loss = 0.0005788960167394483
Trained batch 317 in epoch 5, gen_loss = 1.1384332483669497, disc_loss = 0.0005781572053248119
Trained batch 318 in epoch 5, gen_loss = 1.137778762365957, disc_loss = 0.0005776106036108696
Trained batch 319 in epoch 5, gen_loss = 1.1376486774533987, disc_loss = 0.0005770808031002161
Trained batch 320 in epoch 5, gen_loss = 1.137072174348564, disc_loss = 0.0005761109477420761
Trained batch 321 in epoch 5, gen_loss = 1.1363826912382375, disc_loss = 0.0005753351547326878
Trained batch 322 in epoch 5, gen_loss = 1.1367796116938162, disc_loss = 0.0005744193936617044
Trained batch 323 in epoch 5, gen_loss = 1.1369338042942094, disc_loss = 0.0005732866035863098
Trained batch 324 in epoch 5, gen_loss = 1.1365003094306358, disc_loss = 0.0005723626354413752
Trained batch 325 in epoch 5, gen_loss = 1.1374097813857844, disc_loss = 0.0005731066709026863
Trained batch 326 in epoch 5, gen_loss = 1.1372887738254092, disc_loss = 0.0005786948531304645
Trained batch 327 in epoch 5, gen_loss = 1.1376522670431835, disc_loss = 0.0005853909946736389
Trained batch 328 in epoch 5, gen_loss = 1.137743373047617, disc_loss = 0.0005893822400722764
Trained batch 329 in epoch 5, gen_loss = 1.1381786797985887, disc_loss = 0.0005921628754577162
Trained batch 330 in epoch 5, gen_loss = 1.1380083766228484, disc_loss = 0.0005944449838742915
Trained batch 331 in epoch 5, gen_loss = 1.1382849238005028, disc_loss = 0.0005968376804212969
Trained batch 332 in epoch 5, gen_loss = 1.1390471630268268, disc_loss = 0.0005975032486180584
Trained batch 333 in epoch 5, gen_loss = 1.1388151924053351, disc_loss = 0.0005977160483938544
Trained batch 334 in epoch 5, gen_loss = 1.1390298427040897, disc_loss = 0.0005986785045051739
Trained batch 335 in epoch 5, gen_loss = 1.1387965590471314, disc_loss = 0.0005989146149788992
Trained batch 336 in epoch 5, gen_loss = 1.1393332757298953, disc_loss = 0.0005983811571842781
Trained batch 337 in epoch 5, gen_loss = 1.1397842242872926, disc_loss = 0.0005982501162400334
Trained batch 338 in epoch 5, gen_loss = 1.1397174294367651, disc_loss = 0.0005992393352214596
Trained batch 339 in epoch 5, gen_loss = 1.1399261730558732, disc_loss = 0.0006006391532162739
Trained batch 340 in epoch 5, gen_loss = 1.1397906527840846, disc_loss = 0.000600866564218183
Trained batch 341 in epoch 5, gen_loss = 1.1394630792545297, disc_loss = 0.0006008719268167454
Trained batch 342 in epoch 5, gen_loss = 1.138737050159332, disc_loss = 0.0006007979146560245
Trained batch 343 in epoch 5, gen_loss = 1.1385683978712835, disc_loss = 0.0006028253325661522
Trained batch 344 in epoch 5, gen_loss = 1.1386860332627227, disc_loss = 0.0006063088234573049
Trained batch 345 in epoch 5, gen_loss = 1.138037308964426, disc_loss = 0.0006073715068819472
Trained batch 346 in epoch 5, gen_loss = 1.138745632398369, disc_loss = 0.0006086435047995167
Trained batch 347 in epoch 5, gen_loss = 1.138374493896276, disc_loss = 0.0006119183789001679
Trained batch 348 in epoch 5, gen_loss = 1.1382913153970822, disc_loss = 0.0006190820591566607
Trained batch 349 in epoch 5, gen_loss = 1.1383848852770668, disc_loss = 0.0006274599202567645
Trained batch 350 in epoch 5, gen_loss = 1.1379350102864778, disc_loss = 0.0006318249987586576
Trained batch 351 in epoch 5, gen_loss = 1.137852797623385, disc_loss = 0.0006343084688234575
Trained batch 352 in epoch 5, gen_loss = 1.1376269000447843, disc_loss = 0.0006358172139474428
Trained batch 353 in epoch 5, gen_loss = 1.1374245681668405, disc_loss = 0.0006368570364964007
Trained batch 354 in epoch 5, gen_loss = 1.1376285856878254, disc_loss = 0.000636101531132918
Trained batch 355 in epoch 5, gen_loss = 1.13774836749843, disc_loss = 0.0006351540930328166
Trained batch 356 in epoch 5, gen_loss = 1.1373803403531135, disc_loss = 0.0006361963740458349
Trained batch 357 in epoch 5, gen_loss = 1.1371150877555656, disc_loss = 0.0006388819567505049
Trained batch 358 in epoch 5, gen_loss = 1.1369389008346706, disc_loss = 0.0006399942901623331
Trained batch 359 in epoch 5, gen_loss = 1.136794589459896, disc_loss = 0.0006423164941427079
Trained batch 360 in epoch 5, gen_loss = 1.1367601461687906, disc_loss = 0.0006471844796158071
Trained batch 361 in epoch 5, gen_loss = 1.1368163150647728, disc_loss = 0.0006557345520040903
Trained batch 362 in epoch 5, gen_loss = 1.1367443292594153, disc_loss = 0.0006619705555416303
Trained batch 363 in epoch 5, gen_loss = 1.136654256300612, disc_loss = 0.0006670866047528221
Trained batch 364 in epoch 5, gen_loss = 1.1364988958998903, disc_loss = 0.0006701550589777108
Trained batch 365 in epoch 5, gen_loss = 1.1363018443349933, disc_loss = 0.0006710250678532973
Trained batch 366 in epoch 5, gen_loss = 1.1361135015370736, disc_loss = 0.0006706866531305164
Trained batch 367 in epoch 5, gen_loss = 1.135620877470659, disc_loss = 0.0006701805283504971
Trained batch 368 in epoch 5, gen_loss = 1.135646658861217, disc_loss = 0.0006694234601405908
Trained batch 369 in epoch 5, gen_loss = 1.135955664596042, disc_loss = 0.0006684791931301997
Trained batch 370 in epoch 5, gen_loss = 1.1355651053135607, disc_loss = 0.0006671318502299992
Trained batch 371 in epoch 5, gen_loss = 1.1352040858999375, disc_loss = 0.0006659075502039907
Trained batch 372 in epoch 5, gen_loss = 1.134721273231762, disc_loss = 0.0006644732750343326
Trained batch 373 in epoch 5, gen_loss = 1.1349436632770906, disc_loss = 0.0006634237706067631
Trained batch 374 in epoch 5, gen_loss = 1.1350679176648457, disc_loss = 0.0006624055744032376
Trained batch 375 in epoch 5, gen_loss = 1.1345828911091418, disc_loss = 0.0006619327536332383
Trained batch 376 in epoch 5, gen_loss = 1.1347259134449441, disc_loss = 0.0006611802120884789
Trained batch 377 in epoch 5, gen_loss = 1.1343012545159255, disc_loss = 0.000660493233024479
Trained batch 378 in epoch 5, gen_loss = 1.1343612313899643, disc_loss = 0.0006609076314329632
Trained batch 379 in epoch 5, gen_loss = 1.1345696469670847, disc_loss = 0.0006617354744728226
Trained batch 380 in epoch 5, gen_loss = 1.1343263880474361, disc_loss = 0.000661074754977116
Trained batch 381 in epoch 5, gen_loss = 1.1337833449790615, disc_loss = 0.0006599472664427366
Trained batch 382 in epoch 5, gen_loss = 1.1337506707281109, disc_loss = 0.0006586834541547803
Trained batch 383 in epoch 5, gen_loss = 1.1333525747371216, disc_loss = 0.0006590079792090364
Trained batch 384 in epoch 5, gen_loss = 1.1337687639447003, disc_loss = 0.0006600120318970377
Trained batch 385 in epoch 5, gen_loss = 1.1338169434218828, disc_loss = 0.0006592238488418009
Trained batch 386 in epoch 5, gen_loss = 1.133911468107879, disc_loss = 0.000659128504469708
Trained batch 387 in epoch 5, gen_loss = 1.1338968825401718, disc_loss = 0.0006592348385423713
Trained batch 388 in epoch 5, gen_loss = 1.1340756298337313, disc_loss = 0.0006584537057554682
Trained batch 389 in epoch 5, gen_loss = 1.1339455211773897, disc_loss = 0.0006573751328314523
Trained batch 390 in epoch 5, gen_loss = 1.1341654740636, disc_loss = 0.0006562179741662536
Trained batch 391 in epoch 5, gen_loss = 1.133638515916406, disc_loss = 0.0006551579872022409
Trained batch 392 in epoch 5, gen_loss = 1.1336355465665724, disc_loss = 0.0006543563858778619
Trained batch 393 in epoch 5, gen_loss = 1.1336524996358126, disc_loss = 0.000653330127330855
Trained batch 394 in epoch 5, gen_loss = 1.1341987001745006, disc_loss = 0.000652065693420694
Trained batch 395 in epoch 5, gen_loss = 1.134084113770061, disc_loss = 0.0006507093787535489
Trained batch 396 in epoch 5, gen_loss = 1.134068607233033, disc_loss = 0.0006496930723336598
Trained batch 397 in epoch 5, gen_loss = 1.133928323061622, disc_loss = 0.0006493779933887379
Trained batch 398 in epoch 5, gen_loss = 1.1337455124185796, disc_loss = 0.0006500797397001906
Trained batch 399 in epoch 5, gen_loss = 1.1339097858965397, disc_loss = 0.0006508020107867196
Trained batch 400 in epoch 5, gen_loss = 1.1336486733465123, disc_loss = 0.000651077195790659
Trained batch 401 in epoch 5, gen_loss = 1.133663264821418, disc_loss = 0.0006505686688249634
Trained batch 402 in epoch 5, gen_loss = 1.1333031996012326, disc_loss = 0.0006494948456454422
Trained batch 403 in epoch 5, gen_loss = 1.1329365312167914, disc_loss = 0.0006484086179355445
Trained batch 404 in epoch 5, gen_loss = 1.1326027783346764, disc_loss = 0.0006476585708708031
Trained batch 405 in epoch 5, gen_loss = 1.1325488661603975, disc_loss = 0.0006470844608942606
Trained batch 406 in epoch 5, gen_loss = 1.132546248102071, disc_loss = 0.0006476689635773695
Trained batch 407 in epoch 5, gen_loss = 1.1322382912039757, disc_loss = 0.000647592669017339
Trained batch 408 in epoch 5, gen_loss = 1.1322142076667188, disc_loss = 0.0006465045252785287
Trained batch 409 in epoch 5, gen_loss = 1.1320277698156311, disc_loss = 0.0006454859493604134
Trained batch 410 in epoch 5, gen_loss = 1.1322970148130636, disc_loss = 0.0006447174769263701
Trained batch 411 in epoch 5, gen_loss = 1.1324255340597005, disc_loss = 0.0006438489202356296
Trained batch 412 in epoch 5, gen_loss = 1.1322449152752505, disc_loss = 0.0006429733491525817
Trained batch 413 in epoch 5, gen_loss = 1.132183935187289, disc_loss = 0.0006427554743589972
Trained batch 414 in epoch 5, gen_loss = 1.1322871930627938, disc_loss = 0.0006419838400184547
Trained batch 415 in epoch 5, gen_loss = 1.1322605178619807, disc_loss = 0.0006417922945029903
Trained batch 416 in epoch 5, gen_loss = 1.131895624619308, disc_loss = 0.0006419581151944284
Trained batch 417 in epoch 5, gen_loss = 1.131706563907377, disc_loss = 0.0006415249222321948
Trained batch 418 in epoch 5, gen_loss = 1.1317957447650608, disc_loss = 0.0006407838817871996
Trained batch 419 in epoch 5, gen_loss = 1.1320290589616413, disc_loss = 0.0006396700611471065
Trained batch 420 in epoch 5, gen_loss = 1.1324082246302425, disc_loss = 0.0006385852191199033
Trained batch 421 in epoch 5, gen_loss = 1.1320032507039925, disc_loss = 0.000638161857211874
Trained batch 422 in epoch 5, gen_loss = 1.1322914574726817, disc_loss = 0.0006386428562556581
Trained batch 423 in epoch 5, gen_loss = 1.1328406757060088, disc_loss = 0.0006383757546537485
Trained batch 424 in epoch 5, gen_loss = 1.1325289924004498, disc_loss = 0.0006385668495889096
Trained batch 425 in epoch 5, gen_loss = 1.1321760409035033, disc_loss = 0.0006395624756502608
Trained batch 426 in epoch 5, gen_loss = 1.1320242517446746, disc_loss = 0.0006397718395187194
Trained batch 427 in epoch 5, gen_loss = 1.1320016249039462, disc_loss = 0.00063965661711251
Trained batch 428 in epoch 5, gen_loss = 1.1320947048825263, disc_loss = 0.0006393273841342205
Trained batch 429 in epoch 5, gen_loss = 1.1323402780433034, disc_loss = 0.0006394576017344154
Trained batch 430 in epoch 5, gen_loss = 1.1322422573848556, disc_loss = 0.0006400502652573786
Trained batch 431 in epoch 5, gen_loss = 1.1324151234218367, disc_loss = 0.000639710765729736
Trained batch 432 in epoch 5, gen_loss = 1.1325601830768806, disc_loss = 0.000638993225540583
Trained batch 433 in epoch 5, gen_loss = 1.1328266533563762, disc_loss = 0.000638053815316705
Trained batch 434 in epoch 5, gen_loss = 1.1328145762969708, disc_loss = 0.0006371017893369513
Trained batch 435 in epoch 5, gen_loss = 1.1327144308101147, disc_loss = 0.0006363424894382853
Trained batch 436 in epoch 5, gen_loss = 1.1326041885862634, disc_loss = 0.0006357090962859983
Trained batch 437 in epoch 5, gen_loss = 1.1327575786745168, disc_loss = 0.0006350400393427941
Trained batch 438 in epoch 5, gen_loss = 1.1330775425754538, disc_loss = 0.000635009636141992
Trained batch 439 in epoch 5, gen_loss = 1.1331718562678856, disc_loss = 0.0006360522651944352
Trained batch 440 in epoch 5, gen_loss = 1.1331069597851933, disc_loss = 0.000637413904637356
Trained batch 441 in epoch 5, gen_loss = 1.1338447023570808, disc_loss = 0.0006379634556091892
Trained batch 442 in epoch 5, gen_loss = 1.1340556172969378, disc_loss = 0.0006380810390639646
Trained batch 443 in epoch 5, gen_loss = 1.1345466690825987, disc_loss = 0.0006380081865679565
Trained batch 444 in epoch 5, gen_loss = 1.1342633122808479, disc_loss = 0.000637741595326159
Trained batch 445 in epoch 5, gen_loss = 1.1344302920749905, disc_loss = 0.0006373298606723589
Trained batch 446 in epoch 5, gen_loss = 1.1344695932646458, disc_loss = 0.0006371887119604646
Trained batch 447 in epoch 5, gen_loss = 1.1344705164166433, disc_loss = 0.0006381797838262823
Trained batch 448 in epoch 5, gen_loss = 1.134795474183055, disc_loss = 0.0006388250341299789
Trained batch 449 in epoch 5, gen_loss = 1.1347503091229332, disc_loss = 0.0006387745351659962
Trained batch 450 in epoch 5, gen_loss = 1.1345865902245176, disc_loss = 0.0006388438153240681
Trained batch 451 in epoch 5, gen_loss = 1.1346432826424067, disc_loss = 0.0006382457186432918
Trained batch 452 in epoch 5, gen_loss = 1.1349828268255355, disc_loss = 0.0006379830747612528
Trained batch 453 in epoch 5, gen_loss = 1.1346247355055703, disc_loss = 0.0006385221151688386
Trained batch 454 in epoch 5, gen_loss = 1.1350071187857742, disc_loss = 0.0006419828281850441
Trained batch 455 in epoch 5, gen_loss = 1.135160744582352, disc_loss = 0.0006447796339144636
Trained batch 456 in epoch 5, gen_loss = 1.1353485162983317, disc_loss = 0.000645940256237788
Trained batch 457 in epoch 5, gen_loss = 1.1355560183785367, disc_loss = 0.0006457831803099232
Trained batch 458 in epoch 5, gen_loss = 1.1356723707226106, disc_loss = 0.0006450714065626361
Trained batch 459 in epoch 5, gen_loss = 1.135753552162129, disc_loss = 0.0006441098799215346
Trained batch 460 in epoch 5, gen_loss = 1.1357335750813597, disc_loss = 0.0006435039590709841
Trained batch 461 in epoch 5, gen_loss = 1.1354814603989258, disc_loss = 0.0006426130457366998
Trained batch 462 in epoch 5, gen_loss = 1.1351602309208453, disc_loss = 0.0006420192646026635
Trained batch 463 in epoch 5, gen_loss = 1.135103505490155, disc_loss = 0.0006432225891957983
Trained batch 464 in epoch 5, gen_loss = 1.13544662896023, disc_loss = 0.0006453108157016217
Trained batch 465 in epoch 5, gen_loss = 1.1363077291603252, disc_loss = 0.0006467316323034905
Trained batch 466 in epoch 5, gen_loss = 1.1367249274407005, disc_loss = 0.0006469985155704804
Trained batch 467 in epoch 5, gen_loss = 1.1366924689366267, disc_loss = 0.0006461990943091969
Trained batch 468 in epoch 5, gen_loss = 1.1365483706948092, disc_loss = 0.0006455915235007789
Trained batch 469 in epoch 5, gen_loss = 1.1364083589391505, disc_loss = 0.0006455900210099532
Trained batch 470 in epoch 5, gen_loss = 1.1366557680117857, disc_loss = 0.0006453970951031135
Trained batch 471 in epoch 5, gen_loss = 1.1368340955952467, disc_loss = 0.0006451027232179837
Trained batch 472 in epoch 5, gen_loss = 1.1368394840595335, disc_loss = 0.0006457479086967409
Trained batch 473 in epoch 5, gen_loss = 1.1369180895608186, disc_loss = 0.0006460816676670465
Trained batch 474 in epoch 5, gen_loss = 1.136978056807267, disc_loss = 0.0006453875455956318
Trained batch 475 in epoch 5, gen_loss = 1.137046599838914, disc_loss = 0.0006444761810820361
Trained batch 476 in epoch 5, gen_loss = 1.1372398337977987, disc_loss = 0.0006436707423384881
Trained batch 477 in epoch 5, gen_loss = 1.1372498605540606, disc_loss = 0.0006430300519968262
Trained batch 478 in epoch 5, gen_loss = 1.1373049110360833, disc_loss = 0.0006423289167606282
Trained batch 479 in epoch 5, gen_loss = 1.1376052464048068, disc_loss = 0.0006413804893478906
Trained batch 480 in epoch 5, gen_loss = 1.1377338059478888, disc_loss = 0.000640400912754989
Trained batch 481 in epoch 5, gen_loss = 1.1379011995564852, disc_loss = 0.0006397488560572004
Trained batch 482 in epoch 5, gen_loss = 1.1382535631859032, disc_loss = 0.0006403888508968641
Trained batch 483 in epoch 5, gen_loss = 1.1384356179513222, disc_loss = 0.0006411919385446852
Trained batch 484 in epoch 5, gen_loss = 1.1381008280921228, disc_loss = 0.0006404220057560189
Trained batch 485 in epoch 5, gen_loss = 1.1380916895199213, disc_loss = 0.0006400281316078548
Trained batch 486 in epoch 5, gen_loss = 1.1376306752404637, disc_loss = 0.000640620490824383
Trained batch 487 in epoch 5, gen_loss = 1.137659079349432, disc_loss = 0.0006421792597512783
Trained batch 488 in epoch 5, gen_loss = 1.1374020894612271, disc_loss = 0.0006440325079134385
Trained batch 489 in epoch 5, gen_loss = 1.1375561367492286, disc_loss = 0.0006442621482740517
Trained batch 490 in epoch 5, gen_loss = 1.1374538548123811, disc_loss = 0.0006444693123708364
Trained batch 491 in epoch 5, gen_loss = 1.1374166495189435, disc_loss = 0.0006437574542715306
Trained batch 492 in epoch 5, gen_loss = 1.137577421887651, disc_loss = 0.0006429936579673251
Trained batch 493 in epoch 5, gen_loss = 1.137343787109321, disc_loss = 0.0006420908347083263
Trained batch 494 in epoch 5, gen_loss = 1.1369031933823017, disc_loss = 0.00064154563470499
Trained batch 495 in epoch 5, gen_loss = 1.1374730255094267, disc_loss = 0.0006410787812074564
Trained batch 496 in epoch 5, gen_loss = 1.1377567576930316, disc_loss = 0.0006402544818384764
Trained batch 497 in epoch 5, gen_loss = 1.1376530265951732, disc_loss = 0.0006393339372956265
Trained batch 498 in epoch 5, gen_loss = 1.1374106862263116, disc_loss = 0.0006386765476245291
Trained batch 499 in epoch 5, gen_loss = 1.1374785619974137, disc_loss = 0.0006381064205779694
Trained batch 500 in epoch 5, gen_loss = 1.1377812132626, disc_loss = 0.0006372942943871858
Trained batch 501 in epoch 5, gen_loss = 1.1378754784623941, disc_loss = 0.0006367681553854933
Trained batch 502 in epoch 5, gen_loss = 1.1377106631252447, disc_loss = 0.0006371371429351068
Trained batch 503 in epoch 5, gen_loss = 1.138111548646102, disc_loss = 0.0006368937644895466
Trained batch 504 in epoch 5, gen_loss = 1.1381983333294934, disc_loss = 0.0006361221514543113
Trained batch 505 in epoch 5, gen_loss = 1.1379642457123331, disc_loss = 0.0006365732531941666
Trained batch 506 in epoch 5, gen_loss = 1.1382933463570635, disc_loss = 0.0006374489490819463
Trained batch 507 in epoch 5, gen_loss = 1.138476615228991, disc_loss = 0.0006369358990751629
Trained batch 508 in epoch 5, gen_loss = 1.138292149968138, disc_loss = 0.000636710336793
Trained batch 509 in epoch 5, gen_loss = 1.1384572046644548, disc_loss = 0.0006366556891247028
Trained batch 510 in epoch 5, gen_loss = 1.1382374657343513, disc_loss = 0.0006362826505267205
Trained batch 511 in epoch 5, gen_loss = 1.138273781281896, disc_loss = 0.0006354382722406626
Trained batch 512 in epoch 5, gen_loss = 1.1383940612363537, disc_loss = 0.0006357603722871926
Trained batch 513 in epoch 5, gen_loss = 1.1381054157644859, disc_loss = 0.0006358711108867014
Trained batch 514 in epoch 5, gen_loss = 1.1378918354951062, disc_loss = 0.0006355530149484216
Trained batch 515 in epoch 5, gen_loss = 1.1378529114547626, disc_loss = 0.0006351104824462646
Trained batch 516 in epoch 5, gen_loss = 1.1376353837765854, disc_loss = 0.0006344462911520924
Trained batch 517 in epoch 5, gen_loss = 1.1375301557388084, disc_loss = 0.0006335827727729282
Trained batch 518 in epoch 5, gen_loss = 1.1374404959825652, disc_loss = 0.0006328018251869304
Trained batch 519 in epoch 5, gen_loss = 1.1377073486263936, disc_loss = 0.000632314060931094
Trained batch 520 in epoch 5, gen_loss = 1.1374372444088765, disc_loss = 0.0006321330328879523
Trained batch 521 in epoch 5, gen_loss = 1.1377098993094945, disc_loss = 0.000634044074159922
Trained batch 522 in epoch 5, gen_loss = 1.137957478002654, disc_loss = 0.00063839913771023
Trained batch 523 in epoch 5, gen_loss = 1.1375657909244072, disc_loss = 0.0006484179312091335
Trained batch 524 in epoch 5, gen_loss = 1.1372680350712367, disc_loss = 0.0006628430154662401
Trained batch 525 in epoch 5, gen_loss = 1.137059037676329, disc_loss = 0.0006771894390278712
Trained batch 526 in epoch 5, gen_loss = 1.1369685848478575, disc_loss = 0.000685277680245244
Trained batch 527 in epoch 5, gen_loss = 1.13703862193859, disc_loss = 0.0006896174069852075
Trained batch 528 in epoch 5, gen_loss = 1.1372200672027069, disc_loss = 0.0006909722620524494
Trained batch 529 in epoch 5, gen_loss = 1.1370191686558273, disc_loss = 0.000690458155619332
Trained batch 530 in epoch 5, gen_loss = 1.1371305453575264, disc_loss = 0.0006909382107743043
Trained batch 531 in epoch 5, gen_loss = 1.1372391041508294, disc_loss = 0.0006926743019568292
Trained batch 532 in epoch 5, gen_loss = 1.1374256836764136, disc_loss = 0.0006936884908473877
Trained batch 533 in epoch 5, gen_loss = 1.1373269886113284, disc_loss = 0.000694689115689028
Trained batch 534 in epoch 5, gen_loss = 1.1372111599021983, disc_loss = 0.0006947313326576324
Trained batch 535 in epoch 5, gen_loss = 1.1369356514135402, disc_loss = 0.0006953779609748788
Trained batch 536 in epoch 5, gen_loss = 1.1369897672139955, disc_loss = 0.0006966058269326941
Trained batch 537 in epoch 5, gen_loss = 1.1367587490374271, disc_loss = 0.0006990894364958221
Trained batch 538 in epoch 5, gen_loss = 1.1366650566099306, disc_loss = 0.0007025125807545153
Trained batch 539 in epoch 5, gen_loss = 1.1371251807168679, disc_loss = 0.0007035922530728082
Trained batch 540 in epoch 5, gen_loss = 1.1370034366570647, disc_loss = 0.0007037140848416346
Trained batch 541 in epoch 5, gen_loss = 1.1368816016564949, disc_loss = 0.0007035410707400651
Trained batch 542 in epoch 5, gen_loss = 1.1370828962896848, disc_loss = 0.0007042899330336991
Trained batch 543 in epoch 5, gen_loss = 1.1369908838806784, disc_loss = 0.0007051948433560456
Trained batch 544 in epoch 5, gen_loss = 1.1367684557897235, disc_loss = 0.0007058009834225299
Trained batch 545 in epoch 5, gen_loss = 1.1368052506403172, disc_loss = 0.0007061349497101655
Trained batch 546 in epoch 5, gen_loss = 1.136624615959537, disc_loss = 0.0007059822620703094
Trained batch 547 in epoch 5, gen_loss = 1.1365283582984966, disc_loss = 0.0007056382753041634
Trained batch 548 in epoch 5, gen_loss = 1.1363394962851032, disc_loss = 0.0007055069095979297
Trained batch 549 in epoch 5, gen_loss = 1.1368265677582134, disc_loss = 0.0007059284223412926
Trained batch 550 in epoch 5, gen_loss = 1.1368433460998881, disc_loss = 0.0007067059226732992
Trained batch 551 in epoch 5, gen_loss = 1.1365052172239276, disc_loss = 0.0007065316514353322
Trained batch 552 in epoch 5, gen_loss = 1.1365884898152963, disc_loss = 0.000706945165990099
Trained batch 553 in epoch 5, gen_loss = 1.1366333948576064, disc_loss = 0.0007072352172364733
Trained batch 554 in epoch 5, gen_loss = 1.1371053433633065, disc_loss = 0.0007067041213074615
Trained batch 555 in epoch 5, gen_loss = 1.1371479130906166, disc_loss = 0.0007062125370545454
Trained batch 556 in epoch 5, gen_loss = 1.1368384108723173, disc_loss = 0.000706158471019952
Trained batch 557 in epoch 5, gen_loss = 1.13701509147562, disc_loss = 0.0007069745073599847
Trained batch 558 in epoch 5, gen_loss = 1.1372914958298739, disc_loss = 0.0007079936843969374
Trained batch 559 in epoch 5, gen_loss = 1.1376395112701825, disc_loss = 0.0007092057827581551
Trained batch 560 in epoch 5, gen_loss = 1.1378765029703233, disc_loss = 0.0007096248511918082
Trained batch 561 in epoch 5, gen_loss = 1.137865582819087, disc_loss = 0.0007087937908353171
Trained batch 562 in epoch 5, gen_loss = 1.1379417797176707, disc_loss = 0.0007081009417281819
Trained batch 563 in epoch 5, gen_loss = 1.137649580307886, disc_loss = 0.0007081004130552483
Trained batch 564 in epoch 5, gen_loss = 1.1375689000155018, disc_loss = 0.000708287349022282
Trained batch 565 in epoch 5, gen_loss = 1.1373902900480128, disc_loss = 0.0007078172105784913
Trained batch 566 in epoch 5, gen_loss = 1.137270800651066, disc_loss = 0.0007072053616147857
Trained batch 567 in epoch 5, gen_loss = 1.1372057317008435, disc_loss = 0.0007065733545049893
Trained batch 568 in epoch 5, gen_loss = 1.1370675471629326, disc_loss = 0.0007061125601249827
Trained batch 569 in epoch 5, gen_loss = 1.1368641439237093, disc_loss = 0.0007059994799579216
Trained batch 570 in epoch 5, gen_loss = 1.1366265705295704, disc_loss = 0.0007061338812726894
Trained batch 571 in epoch 5, gen_loss = 1.1361596205017783, disc_loss = 0.00070606030396982
Trained batch 572 in epoch 5, gen_loss = 1.136543150347565, disc_loss = 0.0007053278274850409
Trained batch 573 in epoch 5, gen_loss = 1.136740110892452, disc_loss = 0.0007047456570431259
Trained batch 574 in epoch 5, gen_loss = 1.136697248375934, disc_loss = 0.0007046360182879573
Trained batch 575 in epoch 5, gen_loss = 1.1365008528033893, disc_loss = 0.0007045930105454722
Trained batch 576 in epoch 5, gen_loss = 1.136176619517328, disc_loss = 0.0007040531244278244
Trained batch 577 in epoch 5, gen_loss = 1.1362338425997631, disc_loss = 0.000703431517105295
Trained batch 578 in epoch 5, gen_loss = 1.1359279550007175, disc_loss = 0.0007036490017923788
Trained batch 579 in epoch 5, gen_loss = 1.1360427662216384, disc_loss = 0.0007036207017492792
Trained batch 580 in epoch 5, gen_loss = 1.1358711544084468, disc_loss = 0.000703089024096955
Trained batch 581 in epoch 5, gen_loss = 1.1359358924565857, disc_loss = 0.0007033846602607935
Trained batch 582 in epoch 5, gen_loss = 1.135877905435873, disc_loss = 0.0007044656407770958
Trained batch 583 in epoch 5, gen_loss = 1.1358709954848027, disc_loss = 0.0007056932762717312
Trained batch 584 in epoch 5, gen_loss = 1.1363200871353476, disc_loss = 0.0007058503552495192
Trained batch 585 in epoch 5, gen_loss = 1.136272882743907, disc_loss = 0.0007053061660896485
Trained batch 586 in epoch 5, gen_loss = 1.1361222095546366, disc_loss = 0.0007047537213280238
Trained batch 587 in epoch 5, gen_loss = 1.1361777467184326, disc_loss = 0.0007040809706719846
Trained batch 588 in epoch 5, gen_loss = 1.136198340024932, disc_loss = 0.0007036741002121266
Trained batch 589 in epoch 5, gen_loss = 1.1362335503101348, disc_loss = 0.0007032458312312236
Trained batch 590 in epoch 5, gen_loss = 1.1360954065411628, disc_loss = 0.0007025089533782884
Trained batch 591 in epoch 5, gen_loss = 1.1364619154986497, disc_loss = 0.000702744171035561
Trained batch 592 in epoch 5, gen_loss = 1.1367236417019346, disc_loss = 0.0007036748794429664
Trained batch 593 in epoch 5, gen_loss = 1.1365045053188247, disc_loss = 0.0007037403741957281
Trained batch 594 in epoch 5, gen_loss = 1.136446185172105, disc_loss = 0.0007032317678275823
Trained batch 595 in epoch 5, gen_loss = 1.1365258684694366, disc_loss = 0.0007023839604009128
Trained batch 596 in epoch 5, gen_loss = 1.136501033601649, disc_loss = 0.0007016158887133287
Trained batch 597 in epoch 5, gen_loss = 1.1364327414976714, disc_loss = 0.0007008658792369182
Trained batch 598 in epoch 5, gen_loss = 1.1364109385789734, disc_loss = 0.0007002873202925392
Trained batch 599 in epoch 5, gen_loss = 1.1364163820942244, disc_loss = 0.0006994564148772042
Trained batch 600 in epoch 5, gen_loss = 1.1364825713059272, disc_loss = 0.0006990403126473515
Trained batch 601 in epoch 5, gen_loss = 1.136439674023378, disc_loss = 0.0006985007963171136
Trained batch 602 in epoch 5, gen_loss = 1.1362910631481886, disc_loss = 0.0006988561095571019
Trained batch 603 in epoch 5, gen_loss = 1.1364385245848965, disc_loss = 0.0006997519855415264
Trained batch 604 in epoch 5, gen_loss = 1.1364888170533929, disc_loss = 0.0006998218126471871
Trained batch 605 in epoch 5, gen_loss = 1.1361136689241176, disc_loss = 0.0006998565596245573
Trained batch 606 in epoch 5, gen_loss = 1.1358355487001788, disc_loss = 0.0006995190272899421
Trained batch 607 in epoch 5, gen_loss = 1.1357043308058852, disc_loss = 0.0006998111109025654
Trained batch 608 in epoch 5, gen_loss = 1.1359239946836712, disc_loss = 0.0006997144992473995
Trained batch 609 in epoch 5, gen_loss = 1.136219969049829, disc_loss = 0.00069932028504287
Trained batch 610 in epoch 5, gen_loss = 1.1360085801680233, disc_loss = 0.0007000339912736877
Trained batch 611 in epoch 5, gen_loss = 1.135921227678754, disc_loss = 0.0007025451621754411
Trained batch 612 in epoch 5, gen_loss = 1.1362459254109256, disc_loss = 0.0007044616730566187
Trained batch 613 in epoch 5, gen_loss = 1.1363645647364253, disc_loss = 0.0007049226491592206
Trained batch 614 in epoch 5, gen_loss = 1.1364599223059368, disc_loss = 0.0007058315387003244
Trained batch 615 in epoch 5, gen_loss = 1.136370002352572, disc_loss = 0.0007065149862659405
Trained batch 616 in epoch 5, gen_loss = 1.1363821706856863, disc_loss = 0.0007063306497698242
Trained batch 617 in epoch 5, gen_loss = 1.1361593956121734, disc_loss = 0.0007062015402647682
Trained batch 618 in epoch 5, gen_loss = 1.1356803690096866, disc_loss = 0.0007058527589187339
Trained batch 619 in epoch 5, gen_loss = 1.1357761549372827, disc_loss = 0.0007059890468935332
Trained batch 620 in epoch 5, gen_loss = 1.1358447381071806, disc_loss = 0.0007057829428953081
Trained batch 621 in epoch 5, gen_loss = 1.1358591190680047, disc_loss = 0.0007054753715907586
Trained batch 622 in epoch 5, gen_loss = 1.1355106244117834, disc_loss = 0.0007058806383098815
Trained batch 623 in epoch 5, gen_loss = 1.1357485538300796, disc_loss = 0.0007094772615975951
Trained batch 624 in epoch 5, gen_loss = 1.1355510899543761, disc_loss = 0.0007125022015534342
Trained batch 625 in epoch 5, gen_loss = 1.1355895461937109, disc_loss = 0.0007136739204085756
Trained batch 626 in epoch 5, gen_loss = 1.135652900407569, disc_loss = 0.0007137038143042719
Trained batch 627 in epoch 5, gen_loss = 1.1358281128155958, disc_loss = 0.000713584338152443
Trained batch 628 in epoch 5, gen_loss = 1.1359130994125086, disc_loss = 0.0007135833531954224
Trained batch 629 in epoch 5, gen_loss = 1.1360240129251329, disc_loss = 0.0007136214505104969
Trained batch 630 in epoch 5, gen_loss = 1.1368756081714115, disc_loss = 0.0007130913733908384
Trained batch 631 in epoch 5, gen_loss = 1.1369841433589971, disc_loss = 0.000712473421244104
Trained batch 632 in epoch 5, gen_loss = 1.1368896453678137, disc_loss = 0.0007117937264635153
Trained batch 633 in epoch 5, gen_loss = 1.1368496219630497, disc_loss = 0.0007108789248474982
Trained batch 634 in epoch 5, gen_loss = 1.1367501265420688, disc_loss = 0.000710197915983071
Trained batch 635 in epoch 5, gen_loss = 1.1370343103911142, disc_loss = 0.0007096167435337286
Trained batch 636 in epoch 5, gen_loss = 1.1370612202297012, disc_loss = 0.0007088840617454688
Trained batch 637 in epoch 5, gen_loss = 1.1374063147085962, disc_loss = 0.00070819808752276
Trained batch 638 in epoch 5, gen_loss = 1.1373122569540857, disc_loss = 0.0007077882927004394
Trained batch 639 in epoch 5, gen_loss = 1.1373256343416869, disc_loss = 0.0007084779706929111
Trained batch 640 in epoch 5, gen_loss = 1.1373114791377659, disc_loss = 0.0007089125778883486
Trained batch 641 in epoch 5, gen_loss = 1.1375986457428084, disc_loss = 0.0007087891251196929
Trained batch 642 in epoch 5, gen_loss = 1.1376633496714603, disc_loss = 0.0007085274897000143
Trained batch 643 in epoch 5, gen_loss = 1.1376462651890997, disc_loss = 0.0007080894843197966
Trained batch 644 in epoch 5, gen_loss = 1.137605555759844, disc_loss = 0.0007075261625609281
Trained batch 645 in epoch 5, gen_loss = 1.1378546035142136, disc_loss = 0.0007069212642311617
Trained batch 646 in epoch 5, gen_loss = 1.137599694305078, disc_loss = 0.0007064254935384603
Trained batch 647 in epoch 5, gen_loss = 1.1377773533264797, disc_loss = 0.000705841164789838
Trained batch 648 in epoch 5, gen_loss = 1.1376123505490954, disc_loss = 0.0007051143784758323
Trained batch 649 in epoch 5, gen_loss = 1.1375437949253964, disc_loss = 0.0007053474971326068
Trained batch 650 in epoch 5, gen_loss = 1.137576467796771, disc_loss = 0.0007060117715667109
Trained batch 651 in epoch 5, gen_loss = 1.1374925863157752, disc_loss = 0.0007061374954828576
Trained batch 652 in epoch 5, gen_loss = 1.1374807355962522, disc_loss = 0.0007057327808880719
Trained batch 653 in epoch 5, gen_loss = 1.1374194968366478, disc_loss = 0.0007050962189841867
Trained batch 654 in epoch 5, gen_loss = 1.137450011085918, disc_loss = 0.0007041843779090053
Trained batch 655 in epoch 5, gen_loss = 1.137304647666652, disc_loss = 0.0007034226847037378
Trained batch 656 in epoch 5, gen_loss = 1.1369103526234445, disc_loss = 0.0007028190455047904
Trained batch 657 in epoch 5, gen_loss = 1.1370361069596646, disc_loss = 0.0007025222689455437
Trained batch 658 in epoch 5, gen_loss = 1.1370816586231063, disc_loss = 0.0007023754543257377
Trained batch 659 in epoch 5, gen_loss = 1.1374445643388864, disc_loss = 0.0007023431538872308
Trained batch 660 in epoch 5, gen_loss = 1.1372940811735779, disc_loss = 0.0007022664484739833
Trained batch 661 in epoch 5, gen_loss = 1.1373052367450969, disc_loss = 0.0007031160336250883
Trained batch 662 in epoch 5, gen_loss = 1.1371294127869929, disc_loss = 0.000704161954399614
Trained batch 663 in epoch 5, gen_loss = 1.1370746964611202, disc_loss = 0.0007042566355365519
Trained batch 664 in epoch 5, gen_loss = 1.1370452014127173, disc_loss = 0.000703886181467976
Trained batch 665 in epoch 5, gen_loss = 1.1370053123962414, disc_loss = 0.0007035588260824644
Trained batch 666 in epoch 5, gen_loss = 1.1371024081195849, disc_loss = 0.000703333150914827
Trained batch 667 in epoch 5, gen_loss = 1.1368674767053055, disc_loss = 0.0007032996312729752
Trained batch 668 in epoch 5, gen_loss = 1.1366813385076766, disc_loss = 0.0007032700531969128
Trained batch 669 in epoch 5, gen_loss = 1.1367795758282961, disc_loss = 0.0007030097842859383
Trained batch 670 in epoch 5, gen_loss = 1.1369882371670799, disc_loss = 0.0007030879851828305
Trained batch 671 in epoch 5, gen_loss = 1.1369755717792682, disc_loss = 0.0007031915860179218
Trained batch 672 in epoch 5, gen_loss = 1.1371488297499306, disc_loss = 0.0007030674596548905
Trained batch 673 in epoch 5, gen_loss = 1.137068988219213, disc_loss = 0.0007029935494856357
Trained batch 674 in epoch 5, gen_loss = 1.13693609935266, disc_loss = 0.0007032263791619766
Trained batch 675 in epoch 5, gen_loss = 1.136719037178, disc_loss = 0.0007038870232662644
Trained batch 676 in epoch 5, gen_loss = 1.1366400531158842, disc_loss = 0.0007036737960531477
Trained batch 677 in epoch 5, gen_loss = 1.136721991244319, disc_loss = 0.0007035048716893189
Trained batch 678 in epoch 5, gen_loss = 1.1367367733385145, disc_loss = 0.0007030649745644143
Trained batch 679 in epoch 5, gen_loss = 1.1371073082089425, disc_loss = 0.0007025077519595952
Trained batch 680 in epoch 5, gen_loss = 1.1371985461218241, disc_loss = 0.0007033148392755949
Trained batch 681 in epoch 5, gen_loss = 1.137241823320165, disc_loss = 0.0007045633489705754
Trained batch 682 in epoch 5, gen_loss = 1.1372619234625452, disc_loss = 0.0007045364945153345
Trained batch 683 in epoch 5, gen_loss = 1.137414965626092, disc_loss = 0.0007044667601367535
Trained batch 684 in epoch 5, gen_loss = 1.1372920209473938, disc_loss = 0.0007046575193211817
Trained batch 685 in epoch 5, gen_loss = 1.1373146827123604, disc_loss = 0.0007042929588011996
Trained batch 686 in epoch 5, gen_loss = 1.1373689987600457, disc_loss = 0.0007038807323245871
Trained batch 687 in epoch 5, gen_loss = 1.137539593892735, disc_loss = 0.0007033223368506337
Trained batch 688 in epoch 5, gen_loss = 1.1376907139454249, disc_loss = 0.0007026691041435338
Trained batch 689 in epoch 5, gen_loss = 1.137876813567203, disc_loss = 0.0007020795407394568
Trained batch 690 in epoch 5, gen_loss = 1.137836373059346, disc_loss = 0.0007014893212772814
Trained batch 691 in epoch 5, gen_loss = 1.1379058591030926, disc_loss = 0.000700806924162131
Trained batch 692 in epoch 5, gen_loss = 1.1382381476537147, disc_loss = 0.0007003356060409626
Trained batch 693 in epoch 5, gen_loss = 1.1386179248091124, disc_loss = 0.0006998573033667843
Trained batch 694 in epoch 5, gen_loss = 1.1387599537698485, disc_loss = 0.0006992496509044666
Trained batch 695 in epoch 5, gen_loss = 1.1393526445688873, disc_loss = 0.0006989369310382433
Trained batch 696 in epoch 5, gen_loss = 1.1393671725880639, disc_loss = 0.0006985523180275824
Trained batch 697 in epoch 5, gen_loss = 1.1391066634723312, disc_loss = 0.000698471047503895
Trained batch 698 in epoch 5, gen_loss = 1.138963065007555, disc_loss = 0.0007003052752213193
Trained batch 699 in epoch 5, gen_loss = 1.138845312680517, disc_loss = 0.0007035016892976793
Trained batch 700 in epoch 5, gen_loss = 1.1387638243901066, disc_loss = 0.000705839953728727
Trained batch 701 in epoch 5, gen_loss = 1.1385850808729134, disc_loss = 0.000706258396657205
Trained batch 702 in epoch 5, gen_loss = 1.1384474279022487, disc_loss = 0.0007081368213928812
Trained batch 703 in epoch 5, gen_loss = 1.1383693298663606, disc_loss = 0.0007105631487072308
Trained batch 704 in epoch 5, gen_loss = 1.1388680499496189, disc_loss = 0.0007105150421031136
Trained batch 705 in epoch 5, gen_loss = 1.1388862785637885, disc_loss = 0.0007106525325988058
Trained batch 706 in epoch 5, gen_loss = 1.1388362102326444, disc_loss = 0.0007104241450401511
Trained batch 707 in epoch 5, gen_loss = 1.1385067516969423, disc_loss = 0.0007110216585283909
Trained batch 708 in epoch 5, gen_loss = 1.1383903118215597, disc_loss = 0.000713139202735388
Trained batch 709 in epoch 5, gen_loss = 1.1385378144996268, disc_loss = 0.0007140887783951795
Trained batch 710 in epoch 5, gen_loss = 1.1384377572606887, disc_loss = 0.0007142239747504781
Trained batch 711 in epoch 5, gen_loss = 1.138428300535411, disc_loss = 0.0007137356737116483
Trained batch 712 in epoch 5, gen_loss = 1.1384005296614863, disc_loss = 0.0007134445224608443
Trained batch 713 in epoch 5, gen_loss = 1.1385631266595269, disc_loss = 0.0007144172936537713
Trained batch 714 in epoch 5, gen_loss = 1.1388332622868198, disc_loss = 0.0007175374962145241
Trained batch 715 in epoch 5, gen_loss = 1.1386989405867773, disc_loss = 0.0007190652655105252
Trained batch 716 in epoch 5, gen_loss = 1.1384759244393439, disc_loss = 0.0007190153683776703
Trained batch 717 in epoch 5, gen_loss = 1.138325546362274, disc_loss = 0.0007208943546410458
Trained batch 718 in epoch 5, gen_loss = 1.1384791456608514, disc_loss = 0.00072554037010042
Trained batch 719 in epoch 5, gen_loss = 1.1388028130763106, disc_loss = 0.0007303463573609608
Trained batch 720 in epoch 5, gen_loss = 1.138650511653678, disc_loss = 0.0007318141011617452
Trained batch 721 in epoch 5, gen_loss = 1.138571667456561, disc_loss = 0.0007331175394656158
Trained batch 722 in epoch 5, gen_loss = 1.1385082012225318, disc_loss = 0.0007338846618980092
Trained batch 723 in epoch 5, gen_loss = 1.138536392242869, disc_loss = 0.0007341685007440147
Trained batch 724 in epoch 5, gen_loss = 1.138518573251264, disc_loss = 0.0007348872543360781
Trained batch 725 in epoch 5, gen_loss = 1.1385198221554769, disc_loss = 0.0007348269418272583
Trained batch 726 in epoch 5, gen_loss = 1.138875235143685, disc_loss = 0.0007346323997559259
Trained batch 727 in epoch 5, gen_loss = 1.1387519827419585, disc_loss = 0.0007350306362211116
Trained batch 728 in epoch 5, gen_loss = 1.1387087014313424, disc_loss = 0.0007352466877139159
Trained batch 729 in epoch 5, gen_loss = 1.1387164936490255, disc_loss = 0.000734825886360191
Trained batch 730 in epoch 5, gen_loss = 1.1385160166816086, disc_loss = 0.0007343942618950509
Trained batch 731 in epoch 5, gen_loss = 1.138473128930467, disc_loss = 0.0007342244094476878
Trained batch 732 in epoch 5, gen_loss = 1.1386533122596116, disc_loss = 0.0007335036782748581
Trained batch 733 in epoch 5, gen_loss = 1.1388694285859204, disc_loss = 0.0007332102051423482
Trained batch 734 in epoch 5, gen_loss = 1.1386390840926137, disc_loss = 0.0007325507500082203
Trained batch 735 in epoch 5, gen_loss = 1.1388052710858376, disc_loss = 0.0007323673294392748
Trained batch 736 in epoch 5, gen_loss = 1.1389294992955439, disc_loss = 0.0007323611199443849
Trained batch 737 in epoch 5, gen_loss = 1.1390442351500194, disc_loss = 0.0007318491618187472
Trained batch 738 in epoch 5, gen_loss = 1.1390523470948288, disc_loss = 0.0007311988216544425
Trained batch 739 in epoch 5, gen_loss = 1.1389472815636041, disc_loss = 0.0007305887575352539
Trained batch 740 in epoch 5, gen_loss = 1.138749600824235, disc_loss = 0.000729925247502649
Trained batch 741 in epoch 5, gen_loss = 1.138967653892111, disc_loss = 0.0007291801972667726
Trained batch 742 in epoch 5, gen_loss = 1.1389186050978515, disc_loss = 0.000728502584129953
Trained batch 743 in epoch 5, gen_loss = 1.1387327690759013, disc_loss = 0.0007280784950751851
Trained batch 744 in epoch 5, gen_loss = 1.138803278439797, disc_loss = 0.0007279376646241285
Trained batch 745 in epoch 5, gen_loss = 1.1386210908039645, disc_loss = 0.0007277771032505217
Trained batch 746 in epoch 5, gen_loss = 1.1383570942534023, disc_loss = 0.0007271139399856678
Trained batch 747 in epoch 5, gen_loss = 1.1381113720450171, disc_loss = 0.0007264562293986434
Trained batch 748 in epoch 5, gen_loss = 1.1378256383343277, disc_loss = 0.0007257911963433397
Trained batch 749 in epoch 5, gen_loss = 1.138052323659261, disc_loss = 0.0007257092707053137
Trained batch 750 in epoch 5, gen_loss = 1.1378076954306997, disc_loss = 0.0007269856476477011
Trained batch 751 in epoch 5, gen_loss = 1.1379368015109224, disc_loss = 0.0007287616746636675
Trained batch 752 in epoch 5, gen_loss = 1.1378286810985125, disc_loss = 0.0007290975894331549
Trained batch 753 in epoch 5, gen_loss = 1.1380311849895144, disc_loss = 0.000728581664424954
Trained batch 754 in epoch 5, gen_loss = 1.1378932884986828, disc_loss = 0.000727925162464812
Trained batch 755 in epoch 5, gen_loss = 1.1379835786958221, disc_loss = 0.0007272078354612594
Trained batch 756 in epoch 5, gen_loss = 1.138057293948598, disc_loss = 0.0007264262203005963
Trained batch 757 in epoch 5, gen_loss = 1.1380707731662136, disc_loss = 0.0007256768470461723
Trained batch 758 in epoch 5, gen_loss = 1.1380459575942068, disc_loss = 0.0007249354204043012
Trained batch 759 in epoch 5, gen_loss = 1.1380094405851866, disc_loss = 0.0007241935263377137
Trained batch 760 in epoch 5, gen_loss = 1.138083919745707, disc_loss = 0.0007236682418918937
Trained batch 761 in epoch 5, gen_loss = 1.138179966314571, disc_loss = 0.0007234275098463821
Trained batch 762 in epoch 5, gen_loss = 1.138259007608906, disc_loss = 0.000723179675664461
Trained batch 763 in epoch 5, gen_loss = 1.1381257076538045, disc_loss = 0.0007226382834504356
Trained batch 764 in epoch 5, gen_loss = 1.1382455077825808, disc_loss = 0.0007222162529002887
Trained batch 765 in epoch 5, gen_loss = 1.1382428644220137, disc_loss = 0.0007216300753678691
Trained batch 766 in epoch 5, gen_loss = 1.138311539976973, disc_loss = 0.0007209952994781902
Trained batch 767 in epoch 5, gen_loss = 1.1386336601960163, disc_loss = 0.0007204706074048772
Trained batch 768 in epoch 5, gen_loss = 1.1384847525347348, disc_loss = 0.0007205217266907935
Trained batch 769 in epoch 5, gen_loss = 1.138585455541487, disc_loss = 0.0007207151694191535
Trained batch 770 in epoch 5, gen_loss = 1.1385366862540733, disc_loss = 0.0007204991111635434
Trained batch 771 in epoch 5, gen_loss = 1.13830031500888, disc_loss = 0.0007201724490559469
Trained batch 772 in epoch 5, gen_loss = 1.1382891409301512, disc_loss = 0.0007199064619231664
Trained batch 773 in epoch 5, gen_loss = 1.1383288788395027, disc_loss = 0.0007200624201877237
Trained batch 774 in epoch 5, gen_loss = 1.138100187470836, disc_loss = 0.0007205864265673764
Trained batch 775 in epoch 5, gen_loss = 1.1380106114695983, disc_loss = 0.0007213949360373159
Trained batch 776 in epoch 5, gen_loss = 1.137946634295671, disc_loss = 0.000722374898743962
Trained batch 777 in epoch 5, gen_loss = 1.138144492107063, disc_loss = 0.0007229206413334381
Trained batch 778 in epoch 5, gen_loss = 1.1386187671084764, disc_loss = 0.0007230148799064365
Trained batch 779 in epoch 5, gen_loss = 1.13857158827476, disc_loss = 0.0007231509311308261
Trained batch 780 in epoch 5, gen_loss = 1.1387700795669409, disc_loss = 0.0007230697077883541
Trained batch 781 in epoch 5, gen_loss = 1.1389139066724216, disc_loss = 0.000722817371996409
Trained batch 782 in epoch 5, gen_loss = 1.1387000646475478, disc_loss = 0.000723041351961173
Trained batch 783 in epoch 5, gen_loss = 1.1387917842639952, disc_loss = 0.00072366711684685
Trained batch 784 in epoch 5, gen_loss = 1.1387148075802311, disc_loss = 0.0007242622885928685
Trained batch 785 in epoch 5, gen_loss = 1.1388199631949418, disc_loss = 0.0007243616378600424
Trained batch 786 in epoch 5, gen_loss = 1.1388779153817794, disc_loss = 0.0007240452296924487
Trained batch 787 in epoch 5, gen_loss = 1.13904632991038, disc_loss = 0.0007234992286972501
Trained batch 788 in epoch 5, gen_loss = 1.1389113289170694, disc_loss = 0.0007230376640338562
Trained batch 789 in epoch 5, gen_loss = 1.1387681026247483, disc_loss = 0.0007228489248472549
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 1.082632064819336, disc_loss = 0.0003152566496282816
Trained batch 1 in epoch 6, gen_loss = 1.2313909530639648, disc_loss = 0.00026361108029959723
Trained batch 2 in epoch 6, gen_loss = 1.173761208852132, disc_loss = 0.00022557595608911166
Trained batch 3 in epoch 6, gen_loss = 1.1831479966640472, disc_loss = 0.00021814652427565306
Trained batch 4 in epoch 6, gen_loss = 1.1572238683700562, disc_loss = 0.00026597878895699977
Trained batch 5 in epoch 6, gen_loss = 1.1569097240765889, disc_loss = 0.0003386986015054087
Trained batch 6 in epoch 6, gen_loss = 1.142141887119838, disc_loss = 0.0003454788072433855
Trained batch 7 in epoch 6, gen_loss = 1.1325433850288391, disc_loss = 0.00032300083694281057
Trained batch 8 in epoch 6, gen_loss = 1.1514045264985826, disc_loss = 0.00031380681321024895
Trained batch 9 in epoch 6, gen_loss = 1.153444266319275, disc_loss = 0.0003063460171688348
Trained batch 10 in epoch 6, gen_loss = 1.1365791071544995, disc_loss = 0.00030343260467899114
Trained batch 11 in epoch 6, gen_loss = 1.1490070670843124, disc_loss = 0.00030555269040632993
Trained batch 12 in epoch 6, gen_loss = 1.138528021482321, disc_loss = 0.00030551186109033343
Trained batch 13 in epoch 6, gen_loss = 1.1475610264710017, disc_loss = 0.00029707091744057834
Trained batch 14 in epoch 6, gen_loss = 1.1441145857175192, disc_loss = 0.0002841445355443284
Trained batch 15 in epoch 6, gen_loss = 1.1392837651073933, disc_loss = 0.00027257419969828334
Trained batch 16 in epoch 6, gen_loss = 1.1420847983921276, disc_loss = 0.00026409121603458463
Trained batch 17 in epoch 6, gen_loss = 1.134459803501765, disc_loss = 0.0002581052483745023
Trained batch 18 in epoch 6, gen_loss = 1.1366897288121676, disc_loss = 0.00026135941994940177
Trained batch 19 in epoch 6, gen_loss = 1.1556072980165482, disc_loss = 0.0002663046419911552
Trained batch 20 in epoch 6, gen_loss = 1.1639157278197152, disc_loss = 0.00028427081928211485
Trained batch 21 in epoch 6, gen_loss = 1.166420354084535, disc_loss = 0.00031414055278715256
Trained batch 22 in epoch 6, gen_loss = 1.1672247725984324, disc_loss = 0.00032393900366277313
Trained batch 23 in epoch 6, gen_loss = 1.1722846254706383, disc_loss = 0.00032419449477553525
Trained batch 24 in epoch 6, gen_loss = 1.1737348008155823, disc_loss = 0.00033977176586631687
Trained batch 25 in epoch 6, gen_loss = 1.1643591133447795, disc_loss = 0.0003574504388290314
Trained batch 26 in epoch 6, gen_loss = 1.1666997913961057, disc_loss = 0.00035968577193906876
Trained batch 27 in epoch 6, gen_loss = 1.1722204919372285, disc_loss = 0.0003586580304337466
Trained batch 28 in epoch 6, gen_loss = 1.1698640030005882, disc_loss = 0.0003548043329421238
Trained batch 29 in epoch 6, gen_loss = 1.172646301984787, disc_loss = 0.00034714799791496866
Trained batch 30 in epoch 6, gen_loss = 1.1681873702233838, disc_loss = 0.00034673616896578743
Trained batch 31 in epoch 6, gen_loss = 1.164160368964076, disc_loss = 0.00035279126086606993
Trained batch 32 in epoch 6, gen_loss = 1.1568702910885666, disc_loss = 0.00035489989827372926
Trained batch 33 in epoch 6, gen_loss = 1.150256386574577, disc_loss = 0.00035297828307032916
Trained batch 34 in epoch 6, gen_loss = 1.1505524345806666, disc_loss = 0.00036092549021954514
Trained batch 35 in epoch 6, gen_loss = 1.154211214847035, disc_loss = 0.00037495943858327035
Trained batch 36 in epoch 6, gen_loss = 1.1519693861136566, disc_loss = 0.0003844980316431689
Trained batch 37 in epoch 6, gen_loss = 1.1466673879246962, disc_loss = 0.0003854249612471138
Trained batch 38 in epoch 6, gen_loss = 1.1475731057998462, disc_loss = 0.00038621596393521683
Trained batch 39 in epoch 6, gen_loss = 1.1483680054545402, disc_loss = 0.000386997192617855
Trained batch 40 in epoch 6, gen_loss = 1.1504736804380649, disc_loss = 0.0003861930734540404
Trained batch 41 in epoch 6, gen_loss = 1.1489888216767992, disc_loss = 0.0003830147605705341
Trained batch 42 in epoch 6, gen_loss = 1.1460684856703116, disc_loss = 0.0003799906621151062
Trained batch 43 in epoch 6, gen_loss = 1.1421042694286867, disc_loss = 0.0003866216234614099
Trained batch 44 in epoch 6, gen_loss = 1.1395615061124167, disc_loss = 0.00040011654847249805
Trained batch 45 in epoch 6, gen_loss = 1.135588140591331, disc_loss = 0.00041390575105375
Trained batch 46 in epoch 6, gen_loss = 1.1341864225712228, disc_loss = 0.00043308854807772615
Trained batch 47 in epoch 6, gen_loss = 1.1320121089617412, disc_loss = 0.0004468964425541344
Trained batch 48 in epoch 6, gen_loss = 1.1304766596580038, disc_loss = 0.0004522771926772572
Trained batch 49 in epoch 6, gen_loss = 1.1283902597427369, disc_loss = 0.00045806864654878153
Trained batch 50 in epoch 6, gen_loss = 1.12472193848853, disc_loss = 0.00047315550681577956
Trained batch 51 in epoch 6, gen_loss = 1.122922732279851, disc_loss = 0.0004978962547633833
Trained batch 52 in epoch 6, gen_loss = 1.1283214946962752, disc_loss = 0.0005188410904561609
Trained batch 53 in epoch 6, gen_loss = 1.1284905363012243, disc_loss = 0.0005293735704509783
Trained batch 54 in epoch 6, gen_loss = 1.1264087438583374, disc_loss = 0.0005292925869897854
Trained batch 55 in epoch 6, gen_loss = 1.1263455982719148, disc_loss = 0.0005292958254098526
Trained batch 56 in epoch 6, gen_loss = 1.122889190389399, disc_loss = 0.0005358120249359656
Trained batch 57 in epoch 6, gen_loss = 1.125023550000684, disc_loss = 0.0005371955733702133
Trained batch 58 in epoch 6, gen_loss = 1.1264378054667328, disc_loss = 0.0005452060942257896
Trained batch 59 in epoch 6, gen_loss = 1.1277681529521941, disc_loss = 0.0005580145373338989
Trained batch 60 in epoch 6, gen_loss = 1.1269553157149768, disc_loss = 0.0005673080614527504
Trained batch 61 in epoch 6, gen_loss = 1.1255283721031681, disc_loss = 0.0005755555985454139
Trained batch 62 in epoch 6, gen_loss = 1.1273769802517362, disc_loss = 0.0005777070036856458
Trained batch 63 in epoch 6, gen_loss = 1.1292236037552357, disc_loss = 0.0005749451677274919
Trained batch 64 in epoch 6, gen_loss = 1.1269221324187058, disc_loss = 0.0005723408416647894
Trained batch 65 in epoch 6, gen_loss = 1.125400317437721, disc_loss = 0.0005698343648515274
Trained batch 66 in epoch 6, gen_loss = 1.1273353437879192, disc_loss = 0.0005707693546437032
Trained batch 67 in epoch 6, gen_loss = 1.126961401280235, disc_loss = 0.0005759538195407539
Trained batch 68 in epoch 6, gen_loss = 1.1261527071828428, disc_loss = 0.0005767813981156391
Trained batch 69 in epoch 6, gen_loss = 1.1254232832363673, disc_loss = 0.0005766193663086077
Trained batch 70 in epoch 6, gen_loss = 1.1240891621146403, disc_loss = 0.0005778868419928214
Trained batch 71 in epoch 6, gen_loss = 1.1256973577870264, disc_loss = 0.0005770514275759019
Trained batch 72 in epoch 6, gen_loss = 1.1262425788461345, disc_loss = 0.0005838249127096688
Trained batch 73 in epoch 6, gen_loss = 1.1256030105255745, disc_loss = 0.0005883330585847206
Trained batch 74 in epoch 6, gen_loss = 1.1244899050394694, disc_loss = 0.0005871397029841318
Trained batch 75 in epoch 6, gen_loss = 1.1222892544771497, disc_loss = 0.0005866787708471652
Trained batch 76 in epoch 6, gen_loss = 1.121616495120061, disc_loss = 0.0005857886498198276
Trained batch 77 in epoch 6, gen_loss = 1.1220622383631194, disc_loss = 0.0005873160252798324
Trained batch 78 in epoch 6, gen_loss = 1.122800903984263, disc_loss = 0.0005868488251853475
Trained batch 79 in epoch 6, gen_loss = 1.1218679264187812, disc_loss = 0.0005818673502290039
Trained batch 80 in epoch 6, gen_loss = 1.12377271976, disc_loss = 0.0005795075171871433
Trained batch 81 in epoch 6, gen_loss = 1.1246184561310746, disc_loss = 0.0005755129963423625
Trained batch 82 in epoch 6, gen_loss = 1.1239213368978844, disc_loss = 0.0005718603972499876
Trained batch 83 in epoch 6, gen_loss = 1.1211964615753718, disc_loss = 0.0005682902256445405
Trained batch 84 in epoch 6, gen_loss = 1.1245894389994004, disc_loss = 0.000564357647775015
Trained batch 85 in epoch 6, gen_loss = 1.127283746419951, disc_loss = 0.0005597102299784744
Trained batch 86 in epoch 6, gen_loss = 1.1264505317841453, disc_loss = 0.0005555404015634766
Trained batch 87 in epoch 6, gen_loss = 1.1251284331083298, disc_loss = 0.0005515451795707287
Trained batch 88 in epoch 6, gen_loss = 1.125610478808371, disc_loss = 0.0005481380601727477
Trained batch 89 in epoch 6, gen_loss = 1.1247706810633342, disc_loss = 0.0005441423693102681
Trained batch 90 in epoch 6, gen_loss = 1.1244122169829986, disc_loss = 0.0005411214686438932
Trained batch 91 in epoch 6, gen_loss = 1.1232276558876038, disc_loss = 0.0005380344506272155
Trained batch 92 in epoch 6, gen_loss = 1.1231991514082877, disc_loss = 0.0005358726240604395
Trained batch 93 in epoch 6, gen_loss = 1.1232097288395495, disc_loss = 0.0005339209205208425
Trained batch 94 in epoch 6, gen_loss = 1.1220702409744263, disc_loss = 0.000530496561336086
Trained batch 95 in epoch 6, gen_loss = 1.1203318710128467, disc_loss = 0.000526924815858365
Trained batch 96 in epoch 6, gen_loss = 1.1200409488579661, disc_loss = 0.000523917631128534
Trained batch 97 in epoch 6, gen_loss = 1.1211789457165464, disc_loss = 0.0005211110686531708
Trained batch 98 in epoch 6, gen_loss = 1.1199644454801925, disc_loss = 0.0005173260331944083
Trained batch 99 in epoch 6, gen_loss = 1.1222765946388245, disc_loss = 0.000514198657911038
Trained batch 100 in epoch 6, gen_loss = 1.1239564501413024, disc_loss = 0.0005109299570471878
Trained batch 101 in epoch 6, gen_loss = 1.1240311849351023, disc_loss = 0.0005072204816422206
Trained batch 102 in epoch 6, gen_loss = 1.123185184395429, disc_loss = 0.0005039262069102141
Trained batch 103 in epoch 6, gen_loss = 1.121664601449783, disc_loss = 0.0005008695106181011
Trained batch 104 in epoch 6, gen_loss = 1.1219448254221962, disc_loss = 0.0004991154088028929
Trained batch 105 in epoch 6, gen_loss = 1.121717098186601, disc_loss = 0.0004963591863139849
Trained batch 106 in epoch 6, gen_loss = 1.1206946612518525, disc_loss = 0.0004940502190250886
Trained batch 107 in epoch 6, gen_loss = 1.1199442473826584, disc_loss = 0.0004920506963336029
Trained batch 108 in epoch 6, gen_loss = 1.1217043066243513, disc_loss = 0.0004940830709662613
Trained batch 109 in epoch 6, gen_loss = 1.1221517210656946, disc_loss = 0.000503348277230874
Trained batch 110 in epoch 6, gen_loss = 1.122061462552698, disc_loss = 0.0005050381517870486
Trained batch 111 in epoch 6, gen_loss = 1.1216404645570688, disc_loss = 0.0005061966752951516
Trained batch 112 in epoch 6, gen_loss = 1.1198954977820406, disc_loss = 0.0005064253759440612
Trained batch 113 in epoch 6, gen_loss = 1.120522318701995, disc_loss = 0.0005101019521948489
Trained batch 114 in epoch 6, gen_loss = 1.1211740136146546, disc_loss = 0.0005177520368622778
Trained batch 115 in epoch 6, gen_loss = 1.1225588604294021, disc_loss = 0.0005198341598864725
Trained batch 116 in epoch 6, gen_loss = 1.1207568049430847, disc_loss = 0.0005206063099486085
Trained batch 117 in epoch 6, gen_loss = 1.121666006617627, disc_loss = 0.0005221806213277456
Trained batch 118 in epoch 6, gen_loss = 1.1208155971615255, disc_loss = 0.0005273025321721358
Trained batch 119 in epoch 6, gen_loss = 1.1237887913982074, disc_loss = 0.0005309720524868074
Trained batch 120 in epoch 6, gen_loss = 1.1227784811957808, disc_loss = 0.0005312913006281265
Trained batch 121 in epoch 6, gen_loss = 1.1242458405064755, disc_loss = 0.0005302554933730223
Trained batch 122 in epoch 6, gen_loss = 1.1236950667893015, disc_loss = 0.0005297366506278106
Trained batch 123 in epoch 6, gen_loss = 1.124122197108884, disc_loss = 0.0005291405953269737
Trained batch 124 in epoch 6, gen_loss = 1.1254415669441222, disc_loss = 0.0005270674616331234
Trained batch 125 in epoch 6, gen_loss = 1.1265912514830392, disc_loss = 0.00052446378963179
Trained batch 126 in epoch 6, gen_loss = 1.1275042422174468, disc_loss = 0.0005225796256155714
Trained batch 127 in epoch 6, gen_loss = 1.128992562647909, disc_loss = 0.0005197577689841637
Trained batch 128 in epoch 6, gen_loss = 1.1275854318640952, disc_loss = 0.0005209060136974219
Trained batch 129 in epoch 6, gen_loss = 1.1289233395686515, disc_loss = 0.0005267836848641029
Trained batch 130 in epoch 6, gen_loss = 1.1287078716372716, disc_loss = 0.0005303547565002378
Trained batch 131 in epoch 6, gen_loss = 1.1282154461651137, disc_loss = 0.0005361894301048861
Trained batch 132 in epoch 6, gen_loss = 1.1267812507493156, disc_loss = 0.0005408621116767154
Trained batch 133 in epoch 6, gen_loss = 1.1275171650879419, disc_loss = 0.0005419627619332134
Trained batch 134 in epoch 6, gen_loss = 1.1266908711857266, disc_loss = 0.0005420123240953588
Trained batch 135 in epoch 6, gen_loss = 1.127246549462571, disc_loss = 0.0005406609877408139
Trained batch 136 in epoch 6, gen_loss = 1.1273510121080996, disc_loss = 0.0005384818437283207
Trained batch 137 in epoch 6, gen_loss = 1.126700527858043, disc_loss = 0.0005364209731772502
Trained batch 138 in epoch 6, gen_loss = 1.1269613903203457, disc_loss = 0.0005342372800533412
Trained batch 139 in epoch 6, gen_loss = 1.126168650814465, disc_loss = 0.0005320720577271589
Trained batch 140 in epoch 6, gen_loss = 1.1260068378549941, disc_loss = 0.000529637698336762
Trained batch 141 in epoch 6, gen_loss = 1.125179924175773, disc_loss = 0.0005282251761560525
Trained batch 142 in epoch 6, gen_loss = 1.12414733888386, disc_loss = 0.0005266265662784291
Trained batch 143 in epoch 6, gen_loss = 1.1243457583089669, disc_loss = 0.0005240970084640947
Trained batch 144 in epoch 6, gen_loss = 1.124001815812341, disc_loss = 0.0005220878289225672
Trained batch 145 in epoch 6, gen_loss = 1.1223976673328713, disc_loss = 0.0005234502308144017
Trained batch 146 in epoch 6, gen_loss = 1.1226309793336051, disc_loss = 0.0005226229140487481
Trained batch 147 in epoch 6, gen_loss = 1.1232457938226494, disc_loss = 0.0005201523264396521
Trained batch 148 in epoch 6, gen_loss = 1.1234787402537045, disc_loss = 0.0005181575973944788
Trained batch 149 in epoch 6, gen_loss = 1.124564720392227, disc_loss = 0.0005164368059680176
Trained batch 150 in epoch 6, gen_loss = 1.1241914566778979, disc_loss = 0.0005152699598674014
Trained batch 151 in epoch 6, gen_loss = 1.1229721484215636, disc_loss = 0.0005145845081738356
Trained batch 152 in epoch 6, gen_loss = 1.1238254593088737, disc_loss = 0.0005161188820755913
Trained batch 153 in epoch 6, gen_loss = 1.1248708665370941, disc_loss = 0.0005176413824892143
Trained batch 154 in epoch 6, gen_loss = 1.1247065440300972, disc_loss = 0.0005193062465555305
Trained batch 155 in epoch 6, gen_loss = 1.1255588176158757, disc_loss = 0.0005204998534538437
Trained batch 156 in epoch 6, gen_loss = 1.1263932600902145, disc_loss = 0.0005209360589239165
Trained batch 157 in epoch 6, gen_loss = 1.1274634226213527, disc_loss = 0.0005198900805767095
Trained batch 158 in epoch 6, gen_loss = 1.1266837633630764, disc_loss = 0.0005183552034710294
Trained batch 159 in epoch 6, gen_loss = 1.1253842052072287, disc_loss = 0.0005172332220354292
Trained batch 160 in epoch 6, gen_loss = 1.1257974668319182, disc_loss = 0.0005199564309025716
Trained batch 161 in epoch 6, gen_loss = 1.125138567921556, disc_loss = 0.000533938300734771
Trained batch 162 in epoch 6, gen_loss = 1.12451176811581, disc_loss = 0.0005458834790160445
Trained batch 163 in epoch 6, gen_loss = 1.1242271999760372, disc_loss = 0.0005488796975064693
Trained batch 164 in epoch 6, gen_loss = 1.124985286322507, disc_loss = 0.000551349760975096
Trained batch 165 in epoch 6, gen_loss = 1.1264995167772454, disc_loss = 0.0005557534423571203
Trained batch 166 in epoch 6, gen_loss = 1.128717698379905, disc_loss = 0.0005578149306486098
Trained batch 167 in epoch 6, gen_loss = 1.129057095519134, disc_loss = 0.0005580828655227032
Trained batch 168 in epoch 6, gen_loss = 1.1303842995293747, disc_loss = 0.0005585817135725799
Trained batch 169 in epoch 6, gen_loss = 1.1302843777572407, disc_loss = 0.0005576462870949934
Trained batch 170 in epoch 6, gen_loss = 1.1299223171340094, disc_loss = 0.0005558243582851651
Trained batch 171 in epoch 6, gen_loss = 1.1290221082609753, disc_loss = 0.0005539913718801176
Trained batch 172 in epoch 6, gen_loss = 1.1292018842145888, disc_loss = 0.0005527002185299142
Trained batch 173 in epoch 6, gen_loss = 1.128085975674377, disc_loss = 0.000555631105574624
Trained batch 174 in epoch 6, gen_loss = 1.1284200593403408, disc_loss = 0.0005592938563287525
Trained batch 175 in epoch 6, gen_loss = 1.1296501450917937, disc_loss = 0.0005638708678154878
Trained batch 176 in epoch 6, gen_loss = 1.1302608029317047, disc_loss = 0.000570145165064309
Trained batch 177 in epoch 6, gen_loss = 1.1305560262015697, disc_loss = 0.0005748500839677597
Trained batch 178 in epoch 6, gen_loss = 1.130459145460715, disc_loss = 0.000580603924502525
Trained batch 179 in epoch 6, gen_loss = 1.1295375843842825, disc_loss = 0.0005873839310273373
Trained batch 180 in epoch 6, gen_loss = 1.129885379780722, disc_loss = 0.0005898299214246205
Trained batch 181 in epoch 6, gen_loss = 1.129391909300626, disc_loss = 0.0005915379318809085
Trained batch 182 in epoch 6, gen_loss = 1.1301256496398175, disc_loss = 0.0005928432443109213
Trained batch 183 in epoch 6, gen_loss = 1.1290221930198048, disc_loss = 0.0005961928897665094
Trained batch 184 in epoch 6, gen_loss = 1.128208849236772, disc_loss = 0.000606428030516474
Trained batch 185 in epoch 6, gen_loss = 1.128037468720508, disc_loss = 0.0006237133717951766
Trained batch 186 in epoch 6, gen_loss = 1.128896075774004, disc_loss = 0.0006342351921108168
Trained batch 187 in epoch 6, gen_loss = 1.1284842237513115, disc_loss = 0.000639007313866193
Trained batch 188 in epoch 6, gen_loss = 1.1281328636502463, disc_loss = 0.0006494674836710421
Trained batch 189 in epoch 6, gen_loss = 1.129065265781001, disc_loss = 0.0006573922733782399
Trained batch 190 in epoch 6, gen_loss = 1.1278562895290514, disc_loss = 0.0006609569168533808
Trained batch 191 in epoch 6, gen_loss = 1.12842408567667, disc_loss = 0.0006664041372914653
Trained batch 192 in epoch 6, gen_loss = 1.1289894370835063, disc_loss = 0.0006712512720112056
Trained batch 193 in epoch 6, gen_loss = 1.129831056004947, disc_loss = 0.0006769263110100772
Trained batch 194 in epoch 6, gen_loss = 1.1294491242139768, disc_loss = 0.0006800596343311601
Trained batch 195 in epoch 6, gen_loss = 1.1293062312262399, disc_loss = 0.0006801272061331511
Trained batch 196 in epoch 6, gen_loss = 1.1299618258694102, disc_loss = 0.0006780424998124097
Trained batch 197 in epoch 6, gen_loss = 1.130494520519719, disc_loss = 0.000681390713990285
Trained batch 198 in epoch 6, gen_loss = 1.1302017848096302, disc_loss = 0.0006956101507656323
Trained batch 199 in epoch 6, gen_loss = 1.1302761751413346, disc_loss = 0.0007011581524420762
Trained batch 200 in epoch 6, gen_loss = 1.1298998232504622, disc_loss = 0.0007020712197226569
Trained batch 201 in epoch 6, gen_loss = 1.1299157779995759, disc_loss = 0.0007004206803469402
Trained batch 202 in epoch 6, gen_loss = 1.1304688594611407, disc_loss = 0.0007014979884054814
Trained batch 203 in epoch 6, gen_loss = 1.1305799203760483, disc_loss = 0.0007078304695503047
Trained batch 204 in epoch 6, gen_loss = 1.1303447467524832, disc_loss = 0.000712826482244631
Trained batch 205 in epoch 6, gen_loss = 1.1294757981323502, disc_loss = 0.000714201188476155
Trained batch 206 in epoch 6, gen_loss = 1.1291929480534244, disc_loss = 0.0007146545024313131
Trained batch 207 in epoch 6, gen_loss = 1.1281137560995727, disc_loss = 0.0007134354248661951
Trained batch 208 in epoch 6, gen_loss = 1.127583284982654, disc_loss = 0.0007192680549403457
Trained batch 209 in epoch 6, gen_loss = 1.1286791372866858, disc_loss = 0.0007268953808566689
Trained batch 210 in epoch 6, gen_loss = 1.1288526072321345, disc_loss = 0.000731460591273325
Trained batch 211 in epoch 6, gen_loss = 1.1289890355096672, disc_loss = 0.0007342599434058735
Trained batch 212 in epoch 6, gen_loss = 1.1296452325834354, disc_loss = 0.0007361011556267712
Trained batch 213 in epoch 6, gen_loss = 1.1293152662638193, disc_loss = 0.0007372790606606481
Trained batch 214 in epoch 6, gen_loss = 1.1293391441189966, disc_loss = 0.0007364073021711002
Trained batch 215 in epoch 6, gen_loss = 1.1297992592056592, disc_loss = 0.0007347685406313287
Trained batch 216 in epoch 6, gen_loss = 1.13018783199073, disc_loss = 0.0007332623137557055
Trained batch 217 in epoch 6, gen_loss = 1.1296506138569717, disc_loss = 0.0007311698719362489
Trained batch 218 in epoch 6, gen_loss = 1.12964470337515, disc_loss = 0.0007292208977157386
Trained batch 219 in epoch 6, gen_loss = 1.130426312847571, disc_loss = 0.0007267565916250036
Trained batch 220 in epoch 6, gen_loss = 1.129706904629237, disc_loss = 0.0007276821326321134
Trained batch 221 in epoch 6, gen_loss = 1.1309601033593084, disc_loss = 0.0007351225777948695
Trained batch 222 in epoch 6, gen_loss = 1.1320311753204586, disc_loss = 0.0007384907733022565
Trained batch 223 in epoch 6, gen_loss = 1.131908943876624, disc_loss = 0.0007382743413992492
Trained batch 224 in epoch 6, gen_loss = 1.1313167905807495, disc_loss = 0.0007388822918033434
Trained batch 225 in epoch 6, gen_loss = 1.1313837117853418, disc_loss = 0.0007388189847609935
Trained batch 226 in epoch 6, gen_loss = 1.1310959523995017, disc_loss = 0.0007378824736250129
Trained batch 227 in epoch 6, gen_loss = 1.130950443577348, disc_loss = 0.0007364757748610716
Trained batch 228 in epoch 6, gen_loss = 1.130779569846574, disc_loss = 0.0007346055389577156
Trained batch 229 in epoch 6, gen_loss = 1.13082398901815, disc_loss = 0.0007328455614776391
Trained batch 230 in epoch 6, gen_loss = 1.1303139176719632, disc_loss = 0.0007301884493500788
Trained batch 231 in epoch 6, gen_loss = 1.129892462286456, disc_loss = 0.0007294419491354975
Trained batch 232 in epoch 6, gen_loss = 1.1303532962635352, disc_loss = 0.0007296121115469007
Trained batch 233 in epoch 6, gen_loss = 1.130344900310549, disc_loss = 0.0007280645206778083
Trained batch 234 in epoch 6, gen_loss = 1.1303411088091262, disc_loss = 0.0007257927781617407
Trained batch 235 in epoch 6, gen_loss = 1.1303149027339483, disc_loss = 0.0007240312281313799
Trained batch 236 in epoch 6, gen_loss = 1.130433757596881, disc_loss = 0.0007219319413860627
Trained batch 237 in epoch 6, gen_loss = 1.1302173999177307, disc_loss = 0.0007196485445291261
Trained batch 238 in epoch 6, gen_loss = 1.1299449010872942, disc_loss = 0.0007176152615874683
Trained batch 239 in epoch 6, gen_loss = 1.1301991949478785, disc_loss = 0.0007182319345702126
Trained batch 240 in epoch 6, gen_loss = 1.1304557808207278, disc_loss = 0.0007213493285295399
Trained batch 241 in epoch 6, gen_loss = 1.1307539880768327, disc_loss = 0.0007216784276449687
Trained batch 242 in epoch 6, gen_loss = 1.1306832739355142, disc_loss = 0.000722815911459244
Trained batch 243 in epoch 6, gen_loss = 1.1305095885620742, disc_loss = 0.0007229880954925692
Trained batch 244 in epoch 6, gen_loss = 1.1301214310587668, disc_loss = 0.0007211600051662999
Trained batch 245 in epoch 6, gen_loss = 1.1302878289687923, disc_loss = 0.0007189118648641194
Trained batch 246 in epoch 6, gen_loss = 1.1299349890064132, disc_loss = 0.0007182334246962739
Trained batch 247 in epoch 6, gen_loss = 1.1304541667622905, disc_loss = 0.000717935385681255
Trained batch 248 in epoch 6, gen_loss = 1.1302026941115597, disc_loss = 0.0007171784735943498
Trained batch 249 in epoch 6, gen_loss = 1.129671581506729, disc_loss = 0.0007168588773638476
Trained batch 250 in epoch 6, gen_loss = 1.1288778926746779, disc_loss = 0.0007162381980052882
Trained batch 251 in epoch 6, gen_loss = 1.1284461071093876, disc_loss = 0.0007150670858425743
Trained batch 252 in epoch 6, gen_loss = 1.1285596475770823, disc_loss = 0.0007131705154642268
Trained batch 253 in epoch 6, gen_loss = 1.1295264159131237, disc_loss = 0.0007114020895749591
Trained batch 254 in epoch 6, gen_loss = 1.1299564261062474, disc_loss = 0.0007104212779713813
Trained batch 255 in epoch 6, gen_loss = 1.1289951305370778, disc_loss = 0.0009780233118306114
Trained batch 256 in epoch 6, gen_loss = 1.1273221007117038, disc_loss = 0.004199820997890815
Trained batch 257 in epoch 6, gen_loss = 1.1267631204091302, disc_loss = 0.0061850086060231246
Trained batch 258 in epoch 6, gen_loss = 1.1271375323354507, disc_loss = 0.009553998165387925
Trained batch 259 in epoch 6, gen_loss = 1.1271960742198504, disc_loss = 0.014271517473697223
Trained batch 260 in epoch 6, gen_loss = 1.1274578792838759, disc_loss = 0.015823040003757845
Trained batch 261 in epoch 6, gen_loss = 1.1253451550279865, disc_loss = 0.017319664731971655
Trained batch 262 in epoch 6, gen_loss = 1.1237140859941113, disc_loss = 0.018525624827975574
Trained batch 263 in epoch 6, gen_loss = 1.1220632893117992, disc_loss = 0.01951174745935339
Trained batch 264 in epoch 6, gen_loss = 1.1208239604841987, disc_loss = 0.020553443260696268
Trained batch 265 in epoch 6, gen_loss = 1.1196537237418325, disc_loss = 0.02150413800429538
Trained batch 266 in epoch 6, gen_loss = 1.1175547222073159, disc_loss = 0.0225063346162356
Trained batch 267 in epoch 6, gen_loss = 1.116235848238219, disc_loss = 0.023396873682968226
Trained batch 268 in epoch 6, gen_loss = 1.114372226385379, disc_loss = 0.024306402915259297
Trained batch 269 in epoch 6, gen_loss = 1.1123911382975402, disc_loss = 0.02519297382103913
Trained batch 270 in epoch 6, gen_loss = 1.1112370348064662, disc_loss = 0.02606403742747951
Trained batch 271 in epoch 6, gen_loss = 1.1089266990037525, disc_loss = 0.026908949814964323
Trained batch 272 in epoch 6, gen_loss = 1.1068182100743165, disc_loss = 0.027722655720116472
Trained batch 273 in epoch 6, gen_loss = 1.105217093533843, disc_loss = 0.02854352947765852
Trained batch 274 in epoch 6, gen_loss = 1.1035243407162754, disc_loss = 0.029335348148570948
Trained batch 275 in epoch 6, gen_loss = 1.1022997135701387, disc_loss = 0.03007870003128356
Trained batch 276 in epoch 6, gen_loss = 1.1012212223094293, disc_loss = 0.03081258999936376
Trained batch 277 in epoch 6, gen_loss = 1.0999214428363087, disc_loss = 0.03150629716147581
Trained batch 278 in epoch 6, gen_loss = 1.0983212639354036, disc_loss = 0.03220364630629044
Trained batch 279 in epoch 6, gen_loss = 1.0965848007372447, disc_loss = 0.032828598020127435
Trained batch 280 in epoch 6, gen_loss = 1.095858705637718, disc_loss = 0.033452403267303414
Trained batch 281 in epoch 6, gen_loss = 1.0952394014977394, disc_loss = 0.03407552297001994
Trained batch 282 in epoch 6, gen_loss = 1.0947592410097695, disc_loss = 0.03495373592971451
Trained batch 283 in epoch 6, gen_loss = 1.0960576206865444, disc_loss = 0.036461774813675144
Trained batch 284 in epoch 6, gen_loss = 1.0951609316625093, disc_loss = 0.03751726200476824
Trained batch 285 in epoch 6, gen_loss = 1.0945646012579644, disc_loss = 0.038251993412120794
Trained batch 286 in epoch 6, gen_loss = 1.0942713009771154, disc_loss = 0.03899744503777162
Trained batch 287 in epoch 6, gen_loss = 1.093283933897813, disc_loss = 0.03960095286763337
Trained batch 288 in epoch 6, gen_loss = 1.0916700899394738, disc_loss = 0.040139789789407326
Trained batch 289 in epoch 6, gen_loss = 1.0919325573691006, disc_loss = 0.04056390932696402
Trained batch 290 in epoch 6, gen_loss = 1.0916015089991986, disc_loss = 0.04086746646961356
Trained batch 291 in epoch 6, gen_loss = 1.091497690302052, disc_loss = 0.04134019564052112
Trained batch 292 in epoch 6, gen_loss = 1.0917711856015306, disc_loss = 0.04207229113599914
Trained batch 293 in epoch 6, gen_loss = 1.090689910917866, disc_loss = 0.04248285483929537
Trained batch 294 in epoch 6, gen_loss = 1.0900794633364272, disc_loss = 0.0429657864649494
Trained batch 295 in epoch 6, gen_loss = 1.0893265921119097, disc_loss = 0.04349599429059634
Trained batch 296 in epoch 6, gen_loss = 1.0895246891461638, disc_loss = 0.04406309898233536
Trained batch 297 in epoch 6, gen_loss = 1.0889006791098805, disc_loss = 0.04441386444037354
Trained batch 298 in epoch 6, gen_loss = 1.0896609469401, disc_loss = 0.0446207423949796
Trained batch 299 in epoch 6, gen_loss = 1.0889746735493342, disc_loss = 0.04486474010130526
Trained batch 300 in epoch 6, gen_loss = 1.0885929829654504, disc_loss = 0.04514558274465504
Trained batch 301 in epoch 6, gen_loss = 1.0887345981518954, disc_loss = 0.04520617756307482
Trained batch 302 in epoch 6, gen_loss = 1.0895841780668831, disc_loss = 0.04519818711183214
Trained batch 303 in epoch 6, gen_loss = 1.0893658029013558, disc_loss = 0.045275297680386996
Trained batch 304 in epoch 6, gen_loss = 1.091570939587765, disc_loss = 0.045227337057285245
Trained batch 305 in epoch 6, gen_loss = 1.0910164863845102, disc_loss = 0.04522796274965847
Trained batch 306 in epoch 6, gen_loss = 1.09141453566691, disc_loss = 0.045152510989282746
Trained batch 307 in epoch 6, gen_loss = 1.0919216671934375, disc_loss = 0.045157618121868234
Trained batch 308 in epoch 6, gen_loss = 1.0919636007651543, disc_loss = 0.04517834761652709
Trained batch 309 in epoch 6, gen_loss = 1.0918469177138421, disc_loss = 0.045201428020969145
Trained batch 310 in epoch 6, gen_loss = 1.092116470697225, disc_loss = 0.04524595621296027
Trained batch 311 in epoch 6, gen_loss = 1.0917820160587628, disc_loss = 0.045303542097989966
Trained batch 312 in epoch 6, gen_loss = 1.0919141657055376, disc_loss = 0.04522513534795897
Trained batch 313 in epoch 6, gen_loss = 1.0920197472071191, disc_loss = 0.04517903778921041
Trained batch 314 in epoch 6, gen_loss = 1.0920253047867428, disc_loss = 0.04511277999344101
Trained batch 315 in epoch 6, gen_loss = 1.0928564530007447, disc_loss = 0.04502918792540289
Trained batch 316 in epoch 6, gen_loss = 1.0930878952474625, disc_loss = 0.044925553015831156
Trained batch 317 in epoch 6, gen_loss = 1.093953236656369, disc_loss = 0.04482166933850074
Trained batch 318 in epoch 6, gen_loss = 1.0948494465373526, disc_loss = 0.04471777950246657
Trained batch 319 in epoch 6, gen_loss = 1.0948914630338549, disc_loss = 0.04463826543913001
Trained batch 320 in epoch 6, gen_loss = 1.0950947793844705, disc_loss = 0.04452237121679155
Trained batch 321 in epoch 6, gen_loss = 1.0956945969081073, disc_loss = 0.044410233193228815
Trained batch 322 in epoch 6, gen_loss = 1.0965624883448006, disc_loss = 0.04429766279832231
Trained batch 323 in epoch 6, gen_loss = 1.0968038117812005, disc_loss = 0.04419093624009865
Trained batch 324 in epoch 6, gen_loss = 1.0973103466400733, disc_loss = 0.04408384938766875
Trained batch 325 in epoch 6, gen_loss = 1.0977522590043354, disc_loss = 0.04397308403751338
Trained batch 326 in epoch 6, gen_loss = 1.0975011516054836, disc_loss = 0.04387387993719428
Trained batch 327 in epoch 6, gen_loss = 1.0980501820038004, disc_loss = 0.04376337754869072
Trained batch 328 in epoch 6, gen_loss = 1.0984506659594713, disc_loss = 0.04365971880740862
Trained batch 329 in epoch 6, gen_loss = 1.0983883805347212, disc_loss = 0.04355485205735683
Trained batch 330 in epoch 6, gen_loss = 1.0984164881562177, disc_loss = 0.043463258211724455
Trained batch 331 in epoch 6, gen_loss = 1.0983276692140533, disc_loss = 0.04335750201379958
Trained batch 332 in epoch 6, gen_loss = 1.0983215672475797, disc_loss = 0.04324423416850053
Trained batch 333 in epoch 6, gen_loss = 1.0985692816223214, disc_loss = 0.04313051717015228
Trained batch 334 in epoch 6, gen_loss = 1.098222098599619, disc_loss = 0.043043598479573064
Trained batch 335 in epoch 6, gen_loss = 1.0984841845929623, disc_loss = 0.04294851961395536
Trained batch 336 in epoch 6, gen_loss = 1.098996500410029, disc_loss = 0.04283762099718359
Trained batch 337 in epoch 6, gen_loss = 1.0993077054884306, disc_loss = 0.04273124315235444
Trained batch 338 in epoch 6, gen_loss = 1.0993017002192922, disc_loss = 0.04262719186445527
Trained batch 339 in epoch 6, gen_loss = 1.0991042282651453, disc_loss = 0.04253407785887676
Trained batch 340 in epoch 6, gen_loss = 1.0990926703749515, disc_loss = 0.04248651454219293
Trained batch 341 in epoch 6, gen_loss = 1.0995824331777138, disc_loss = 0.04241484935825254
Trained batch 342 in epoch 6, gen_loss = 1.0998217703302122, disc_loss = 0.04232115245127827
Trained batch 343 in epoch 6, gen_loss = 1.0997762335247772, disc_loss = 0.042230177406477304
Trained batch 344 in epoch 6, gen_loss = 1.1001543264458145, disc_loss = 0.04212688490640004
Trained batch 345 in epoch 6, gen_loss = 1.100219156528484, disc_loss = 0.042022518600693684
Trained batch 346 in epoch 6, gen_loss = 1.1006029708584721, disc_loss = 0.04192896494051017
Trained batch 347 in epoch 6, gen_loss = 1.1011573793901794, disc_loss = 0.04183346253856812
Trained batch 348 in epoch 6, gen_loss = 1.1015221671251991, disc_loss = 0.04173654613236781
Trained batch 349 in epoch 6, gen_loss = 1.1017847451141902, disc_loss = 0.04163407043926002
Trained batch 350 in epoch 6, gen_loss = 1.103073209948689, disc_loss = 0.04152593608491472
Trained batch 351 in epoch 6, gen_loss = 1.1039337615736506, disc_loss = 0.04141623469899969
Trained batch 352 in epoch 6, gen_loss = 1.1035328612111446, disc_loss = 0.04132022620771966
Trained batch 353 in epoch 6, gen_loss = 1.1029318092906542, disc_loss = 0.041227610234303845
Trained batch 354 in epoch 6, gen_loss = 1.103643780694881, disc_loss = 0.04112850967112151
Trained batch 355 in epoch 6, gen_loss = 1.1038789126310455, disc_loss = 0.041043532908670285
Trained batch 356 in epoch 6, gen_loss = 1.1042562946885908, disc_loss = 0.04096657616458947
Trained batch 357 in epoch 6, gen_loss = 1.1049889342744923, disc_loss = 0.040876848015451495
Trained batch 358 in epoch 6, gen_loss = 1.105097738813225, disc_loss = 0.040786484309304656
Trained batch 359 in epoch 6, gen_loss = 1.1053715470764371, disc_loss = 0.04069052096171314
Trained batch 360 in epoch 6, gen_loss = 1.105250329191995, disc_loss = 0.04059467571980621
Trained batch 361 in epoch 6, gen_loss = 1.10621500114051, disc_loss = 0.04049078647782676
Trained batch 362 in epoch 6, gen_loss = 1.1064062561870607, disc_loss = 0.04038738299868908
Trained batch 363 in epoch 6, gen_loss = 1.106962990629804, disc_loss = 0.040289860251765015
Trained batch 364 in epoch 6, gen_loss = 1.106902543812582, disc_loss = 0.04020124829208003
Trained batch 365 in epoch 6, gen_loss = 1.1068979185787056, disc_loss = 0.040103146505838384
Trained batch 366 in epoch 6, gen_loss = 1.107525424346612, disc_loss = 0.040001114477381736
Trained batch 367 in epoch 6, gen_loss = 1.1077080184350843, disc_loss = 0.039898146737018775
Trained batch 368 in epoch 6, gen_loss = 1.1077422840485405, disc_loss = 0.039797035825553474
Trained batch 369 in epoch 6, gen_loss = 1.1083634025341755, disc_loss = 0.03969798683842905
Trained batch 370 in epoch 6, gen_loss = 1.1089573337061387, disc_loss = 0.03960553046561526
Trained batch 371 in epoch 6, gen_loss = 1.1098347799752348, disc_loss = 0.03951964062432898
Trained batch 372 in epoch 6, gen_loss = 1.1100374930026384, disc_loss = 0.03944025968922656
Trained batch 373 in epoch 6, gen_loss = 1.1105269212773776, disc_loss = 0.03934147702641695
Trained batch 374 in epoch 6, gen_loss = 1.1107772331237793, disc_loss = 0.039243160531914324
Trained batch 375 in epoch 6, gen_loss = 1.1105989376281171, disc_loss = 0.03914803738972934
Trained batch 376 in epoch 6, gen_loss = 1.110838900194244, disc_loss = 0.03905938592138722
Trained batch 377 in epoch 6, gen_loss = 1.1103994453710222, disc_loss = 0.03896957935947323
Trained batch 378 in epoch 6, gen_loss = 1.1107912074607407, disc_loss = 0.03887302692128959
Trained batch 379 in epoch 6, gen_loss = 1.1109157159140235, disc_loss = 0.03878249646213111
Trained batch 380 in epoch 6, gen_loss = 1.1109884572154267, disc_loss = 0.038690005010234535
Trained batch 381 in epoch 6, gen_loss = 1.1110117543118163, disc_loss = 0.03859303590112243
Trained batch 382 in epoch 6, gen_loss = 1.111000790764084, disc_loss = 0.038502341383509914
Trained batch 383 in epoch 6, gen_loss = 1.11134282949691, disc_loss = 0.03840595179377715
Trained batch 384 in epoch 6, gen_loss = 1.112039164598886, disc_loss = 0.03831459132917815
Trained batch 385 in epoch 6, gen_loss = 1.1119154965012803, disc_loss = 0.03823003992401748
Trained batch 386 in epoch 6, gen_loss = 1.1126167905115034, disc_loss = 0.03813638979934492
Trained batch 387 in epoch 6, gen_loss = 1.1130744840988178, disc_loss = 0.038043043039766584
Trained batch 388 in epoch 6, gen_loss = 1.113509136331112, disc_loss = 0.037948958620372626
Trained batch 389 in epoch 6, gen_loss = 1.113746210703483, disc_loss = 0.03785696332318669
Trained batch 390 in epoch 6, gen_loss = 1.1139801675096497, disc_loss = 0.03776439300700984
Trained batch 391 in epoch 6, gen_loss = 1.113580631814441, disc_loss = 0.037676380346798696
Trained batch 392 in epoch 6, gen_loss = 1.1141992678472408, disc_loss = 0.037585086210297734
Trained batch 393 in epoch 6, gen_loss = 1.114046955017874, disc_loss = 0.03749414136240523
Trained batch 394 in epoch 6, gen_loss = 1.1142750771739816, disc_loss = 0.0374033805640684
Trained batch 395 in epoch 6, gen_loss = 1.1142310236740594, disc_loss = 0.03731272380535283
Trained batch 396 in epoch 6, gen_loss = 1.114555801942907, disc_loss = 0.0372234914271753
Trained batch 397 in epoch 6, gen_loss = 1.1150070855665446, disc_loss = 0.037134425505236275
Trained batch 398 in epoch 6, gen_loss = 1.1151370095429862, disc_loss = 0.03704635352240207
Trained batch 399 in epoch 6, gen_loss = 1.1156391246616841, disc_loss = 0.036961314476266126
Trained batch 400 in epoch 6, gen_loss = 1.1152750577712593, disc_loss = 0.03688027950861544
Trained batch 401 in epoch 6, gen_loss = 1.115984151612467, disc_loss = 0.03680742325194847
Trained batch 402 in epoch 6, gen_loss = 1.115667654326181, disc_loss = 0.036724951535993554
Trained batch 403 in epoch 6, gen_loss = 1.115752390705713, disc_loss = 0.03664535827568999
Trained batch 404 in epoch 6, gen_loss = 1.1159771374714227, disc_loss = 0.03656091102243352
Trained batch 405 in epoch 6, gen_loss = 1.1158290235279815, disc_loss = 0.03648737494052337
Trained batch 406 in epoch 6, gen_loss = 1.1162790171344392, disc_loss = 0.03640941111319078
Trained batch 407 in epoch 6, gen_loss = 1.1166819103208243, disc_loss = 0.036323815267518086
Trained batch 408 in epoch 6, gen_loss = 1.1167480884379455, disc_loss = 0.03624300590509871
Trained batch 409 in epoch 6, gen_loss = 1.1166085984648728, disc_loss = 0.036161968010962546
Trained batch 410 in epoch 6, gen_loss = 1.1168976769830188, disc_loss = 0.03607912232692242
Trained batch 411 in epoch 6, gen_loss = 1.1167789755515682, disc_loss = 0.035996588069130524
Trained batch 412 in epoch 6, gen_loss = 1.116888295074352, disc_loss = 0.035916987701189354
Trained batch 413 in epoch 6, gen_loss = 1.1166772905755158, disc_loss = 0.03584371818345058
Trained batch 414 in epoch 6, gen_loss = 1.1169179244213794, disc_loss = 0.03576580550784949
Trained batch 415 in epoch 6, gen_loss = 1.1165731870211089, disc_loss = 0.035688782673350246
Trained batch 416 in epoch 6, gen_loss = 1.116941865399587, disc_loss = 0.03561321519514782
Trained batch 417 in epoch 6, gen_loss = 1.1175370823823665, disc_loss = 0.035532491662119414
Trained batch 418 in epoch 6, gen_loss = 1.1180392682979101, disc_loss = 0.035451681791636776
Trained batch 419 in epoch 6, gen_loss = 1.1180303079741343, disc_loss = 0.03537143942395189
Trained batch 420 in epoch 6, gen_loss = 1.1179622663738042, disc_loss = 0.03529023699912244
Trained batch 421 in epoch 6, gen_loss = 1.117467047196429, disc_loss = 0.035215903260637935
Trained batch 422 in epoch 6, gen_loss = 1.1172382856937164, disc_loss = 0.03513787425432151
Trained batch 423 in epoch 6, gen_loss = 1.117064966064579, disc_loss = 0.035063403640499084
Trained batch 424 in epoch 6, gen_loss = 1.1172668950697955, disc_loss = 0.03498862620283891
Trained batch 425 in epoch 6, gen_loss = 1.1175719320494244, disc_loss = 0.03491091793473739
Trained batch 426 in epoch 6, gen_loss = 1.1180913110527557, disc_loss = 0.03483385566749271
Trained batch 427 in epoch 6, gen_loss = 1.1177400315754882, disc_loss = 0.03475930079089564
Trained batch 428 in epoch 6, gen_loss = 1.1184790761042864, disc_loss = 0.03468203789690965
Trained batch 429 in epoch 6, gen_loss = 1.1184479312841282, disc_loss = 0.034607335688802816
Trained batch 430 in epoch 6, gen_loss = 1.1185666628337514, disc_loss = 0.03453009925693749
Trained batch 431 in epoch 6, gen_loss = 1.1188582406827696, disc_loss = 0.034452748086399275
Trained batch 432 in epoch 6, gen_loss = 1.1191356233030765, disc_loss = 0.034374865482065385
Trained batch 433 in epoch 6, gen_loss = 1.119353122288181, disc_loss = 0.034296746524439106
Trained batch 434 in epoch 6, gen_loss = 1.1194439179595859, disc_loss = 0.03422088800899714
Trained batch 435 in epoch 6, gen_loss = 1.1193761627335068, disc_loss = 0.03414417292720544
Trained batch 436 in epoch 6, gen_loss = 1.1190742623887837, disc_loss = 0.034068599826859676
Trained batch 437 in epoch 6, gen_loss = 1.119197656166608, disc_loss = 0.033992467696943134
Trained batch 438 in epoch 6, gen_loss = 1.119108194234974, disc_loss = 0.03391682429155025
Trained batch 439 in epoch 6, gen_loss = 1.1189838074825027, disc_loss = 0.03384148439527053
Trained batch 440 in epoch 6, gen_loss = 1.119036076696011, disc_loss = 0.0337684609015152
Trained batch 441 in epoch 6, gen_loss = 1.1195868958984565, disc_loss = 0.033696421807048065
Trained batch 442 in epoch 6, gen_loss = 1.1198595930437472, disc_loss = 0.03362259396047236
Trained batch 443 in epoch 6, gen_loss = 1.119565637664752, disc_loss = 0.03355494666697973
Trained batch 444 in epoch 6, gen_loss = 1.1191872255186017, disc_loss = 0.03348281396429638
Trained batch 445 in epoch 6, gen_loss = 1.118842990542741, disc_loss = 0.03341332124694626
Trained batch 446 in epoch 6, gen_loss = 1.1188350514544203, disc_loss = 0.03334458768245036
Trained batch 447 in epoch 6, gen_loss = 1.1190531507932715, disc_loss = 0.0332748829880042
Trained batch 448 in epoch 6, gen_loss = 1.1196077696995639, disc_loss = 0.033204205095052244
Trained batch 449 in epoch 6, gen_loss = 1.1192311027314927, disc_loss = 0.03313592566220905
Trained batch 450 in epoch 6, gen_loss = 1.118998622154185, disc_loss = 0.03306840941820181
Trained batch 451 in epoch 6, gen_loss = 1.1192663649542143, disc_loss = 0.03300186320698593
Trained batch 452 in epoch 6, gen_loss = 1.119714363784453, disc_loss = 0.03293421801488225
Trained batch 453 in epoch 6, gen_loss = 1.119651136681897, disc_loss = 0.03286581021101952
Trained batch 454 in epoch 6, gen_loss = 1.1193169541411347, disc_loss = 0.032798600377394065
Trained batch 455 in epoch 6, gen_loss = 1.1197061959588737, disc_loss = 0.0327297262749613
Trained batch 456 in epoch 6, gen_loss = 1.1200812888093277, disc_loss = 0.0326614236393127
Trained batch 457 in epoch 6, gen_loss = 1.1202741845726447, disc_loss = 0.03259235171325834
Trained batch 458 in epoch 6, gen_loss = 1.1199652413657029, disc_loss = 0.03253054890742265
Trained batch 459 in epoch 6, gen_loss = 1.1200922507306803, disc_loss = 0.03246684612460503
Trained batch 460 in epoch 6, gen_loss = 1.1203495962242243, disc_loss = 0.03240171585798881
Trained batch 461 in epoch 6, gen_loss = 1.120874053730077, disc_loss = 0.03233893280886343
Trained batch 462 in epoch 6, gen_loss = 1.12112399131124, disc_loss = 0.03227558371992306
Trained batch 463 in epoch 6, gen_loss = 1.1214833113140072, disc_loss = 0.03221404997464498
Trained batch 464 in epoch 6, gen_loss = 1.1213541830739668, disc_loss = 0.0321509231444447
Trained batch 465 in epoch 6, gen_loss = 1.121568476949127, disc_loss = 0.03208626121951279
Trained batch 466 in epoch 6, gen_loss = 1.1216943358456042, disc_loss = 0.03202039319031901
Trained batch 467 in epoch 6, gen_loss = 1.1218169359569876, disc_loss = 0.03195353385185588
Trained batch 468 in epoch 6, gen_loss = 1.1221361615256207, disc_loss = 0.031891193041482496
Trained batch 469 in epoch 6, gen_loss = 1.1221610223993341, disc_loss = 0.031826560860769106
Trained batch 470 in epoch 6, gen_loss = 1.1219321213456983, disc_loss = 0.031761427717097376
Trained batch 471 in epoch 6, gen_loss = 1.121765789844222, disc_loss = 0.031697796832474014
Trained batch 472 in epoch 6, gen_loss = 1.1216969575740823, disc_loss = 0.03163340739749486
Trained batch 473 in epoch 6, gen_loss = 1.1213674077504798, disc_loss = 0.031570239411000796
Trained batch 474 in epoch 6, gen_loss = 1.1212786754808928, disc_loss = 0.031507451377830495
Trained batch 475 in epoch 6, gen_loss = 1.1212567368976207, disc_loss = 0.031443455232232846
Trained batch 476 in epoch 6, gen_loss = 1.1217655393312562, disc_loss = 0.03138123211527204
Trained batch 477 in epoch 6, gen_loss = 1.1213530187327492, disc_loss = 0.03132198477413485
Trained batch 478 in epoch 6, gen_loss = 1.1214152161413045, disc_loss = 0.03125997695802759
Trained batch 479 in epoch 6, gen_loss = 1.1211679769059022, disc_loss = 0.031197122542819974
Trained batch 480 in epoch 6, gen_loss = 1.1213687157680488, disc_loss = 0.031134521936401295
Trained batch 481 in epoch 6, gen_loss = 1.1216509359506155, disc_loss = 0.031072665215732556
Trained batch 482 in epoch 6, gen_loss = 1.1219188683274863, disc_loss = 0.03101108863331967
Trained batch 483 in epoch 6, gen_loss = 1.1217105196527213, disc_loss = 0.0309489200688043
Trained batch 484 in epoch 6, gen_loss = 1.121746232829143, disc_loss = 0.030889019713489237
Trained batch 485 in epoch 6, gen_loss = 1.1216327204625793, disc_loss = 0.03082823849332204
Trained batch 486 in epoch 6, gen_loss = 1.1217783332115816, disc_loss = 0.03076887200507314
Trained batch 487 in epoch 6, gen_loss = 1.121869061081136, disc_loss = 0.030711917835642602
Trained batch 488 in epoch 6, gen_loss = 1.1218065072178598, disc_loss = 0.03065180418703594
Trained batch 489 in epoch 6, gen_loss = 1.1218834762670555, disc_loss = 0.030590467006060156
Trained batch 490 in epoch 6, gen_loss = 1.1218359086761165, disc_loss = 0.03052954227253574
Trained batch 491 in epoch 6, gen_loss = 1.1214260716990727, disc_loss = 0.030473641802107123
Trained batch 492 in epoch 6, gen_loss = 1.1213521126801296, disc_loss = 0.030414436110547432
Trained batch 493 in epoch 6, gen_loss = 1.121594950858398, disc_loss = 0.03035783128198017
Trained batch 494 in epoch 6, gen_loss = 1.1215575761265224, disc_loss = 0.030298291814952708
Trained batch 495 in epoch 6, gen_loss = 1.1211972194573572, disc_loss = 0.03024059107236744
Trained batch 496 in epoch 6, gen_loss = 1.1212157151348874, disc_loss = 0.030183511787143718
Trained batch 497 in epoch 6, gen_loss = 1.1211904255022485, disc_loss = 0.03012631240120075
Trained batch 498 in epoch 6, gen_loss = 1.1216438243049898, disc_loss = 0.030068370892069856
Trained batch 499 in epoch 6, gen_loss = 1.121738722205162, disc_loss = 0.03000999147274706
Trained batch 500 in epoch 6, gen_loss = 1.1221395372868537, disc_loss = 0.02995255390038245
Trained batch 501 in epoch 6, gen_loss = 1.122220593738366, disc_loss = 0.029895934084890316
Trained batch 502 in epoch 6, gen_loss = 1.1221541025292565, disc_loss = 0.029838864485962686
Trained batch 503 in epoch 6, gen_loss = 1.1221690477123336, disc_loss = 0.02978473621790308
Trained batch 504 in epoch 6, gen_loss = 1.121989365497438, disc_loss = 0.029730248635581182
Trained batch 505 in epoch 6, gen_loss = 1.1222360033998375, disc_loss = 0.029673673426881392
Trained batch 506 in epoch 6, gen_loss = 1.1222428536038898, disc_loss = 0.029616987094058883
Trained batch 507 in epoch 6, gen_loss = 1.1230470649604722, disc_loss = 0.02956222615419421
Trained batch 508 in epoch 6, gen_loss = 1.1232328706499635, disc_loss = 0.029506636412892823
Trained batch 509 in epoch 6, gen_loss = 1.1234866725463493, disc_loss = 0.029452496272550015
Trained batch 510 in epoch 6, gen_loss = 1.1235282793203678, disc_loss = 0.029396810827827708
Trained batch 511 in epoch 6, gen_loss = 1.1238827795023099, disc_loss = 0.02934027467749445
Trained batch 512 in epoch 6, gen_loss = 1.123616641144074, disc_loss = 0.02928917997949391
Trained batch 513 in epoch 6, gen_loss = 1.123596864103807, disc_loss = 0.02923742998513411
Trained batch 514 in epoch 6, gen_loss = 1.1236064675942208, disc_loss = 0.029183520086703583
Trained batch 515 in epoch 6, gen_loss = 1.1235765598772107, disc_loss = 0.02912897852324967
Trained batch 516 in epoch 6, gen_loss = 1.1236269122396723, disc_loss = 0.029074890383946953
Trained batch 517 in epoch 6, gen_loss = 1.1237865059302121, disc_loss = 0.029020421612873725
Trained batch 518 in epoch 6, gen_loss = 1.1238522918927187, disc_loss = 0.028966049088417174
Trained batch 519 in epoch 6, gen_loss = 1.1238796191719862, disc_loss = 0.02891124702900225
Trained batch 520 in epoch 6, gen_loss = 1.1240750913885413, disc_loss = 0.028856923079764226
Trained batch 521 in epoch 6, gen_loss = 1.1243193632569806, disc_loss = 0.028802528698998124
Trained batch 522 in epoch 6, gen_loss = 1.1241820999358854, disc_loss = 0.028750736716162323
Trained batch 523 in epoch 6, gen_loss = 1.123952535386304, disc_loss = 0.028701254200584763
Trained batch 524 in epoch 6, gen_loss = 1.1235045853115264, disc_loss = 0.02865061136776127
Trained batch 525 in epoch 6, gen_loss = 1.1239855971626456, disc_loss = 0.028598479392467232
Trained batch 526 in epoch 6, gen_loss = 1.124103388478679, disc_loss = 0.028547602874578432
Trained batch 527 in epoch 6, gen_loss = 1.1241956707654577, disc_loss = 0.02849593589575527
Trained batch 528 in epoch 6, gen_loss = 1.124324795879804, disc_loss = 0.028444467033349248
Trained batch 529 in epoch 6, gen_loss = 1.1242673106913297, disc_loss = 0.028392635443385685
Trained batch 530 in epoch 6, gen_loss = 1.1244494796023754, disc_loss = 0.028340717376335967
Trained batch 531 in epoch 6, gen_loss = 1.1244821875615227, disc_loss = 0.02828930876507672
Trained batch 532 in epoch 6, gen_loss = 1.1242830243387991, disc_loss = 0.028238693121743697
Trained batch 533 in epoch 6, gen_loss = 1.1241087033954007, disc_loss = 0.02818916913150879
Trained batch 534 in epoch 6, gen_loss = 1.1240650431018009, disc_loss = 0.02813782719975483
Trained batch 535 in epoch 6, gen_loss = 1.1244842318901376, disc_loss = 0.028086697004160235
Trained batch 536 in epoch 6, gen_loss = 1.1244509923835484, disc_loss = 0.02803627349597736
Trained batch 537 in epoch 6, gen_loss = 1.1244217179521752, disc_loss = 0.027985698267854606
Trained batch 538 in epoch 6, gen_loss = 1.1246293117473651, disc_loss = 0.02793483639482125
Trained batch 539 in epoch 6, gen_loss = 1.124515888426039, disc_loss = 0.02788502053292716
Trained batch 540 in epoch 6, gen_loss = 1.1244397500526442, disc_loss = 0.0278351850953966
Trained batch 541 in epoch 6, gen_loss = 1.1242405679832965, disc_loss = 0.027785579196511527
Trained batch 542 in epoch 6, gen_loss = 1.1244429231348618, disc_loss = 0.027737078178691886
Trained batch 543 in epoch 6, gen_loss = 1.1240833980195664, disc_loss = 0.027690920503533455
Trained batch 544 in epoch 6, gen_loss = 1.12424854422928, disc_loss = 0.02764458568971508
Trained batch 545 in epoch 6, gen_loss = 1.1240824860530896, disc_loss = 0.02759815119411325
Trained batch 546 in epoch 6, gen_loss = 1.124123722151385, disc_loss = 0.027549407880161518
Trained batch 547 in epoch 6, gen_loss = 1.123858226911865, disc_loss = 0.027501326337552617
Trained batch 548 in epoch 6, gen_loss = 1.123924604096265, disc_loss = 0.02745313115463495
Trained batch 549 in epoch 6, gen_loss = 1.1242892950231378, disc_loss = 0.027404655609954552
Trained batch 550 in epoch 6, gen_loss = 1.1244352367958443, disc_loss = 0.027356014839610057
Trained batch 551 in epoch 6, gen_loss = 1.1245364091102628, disc_loss = 0.027307933267853725
Trained batch 552 in epoch 6, gen_loss = 1.124659178485491, disc_loss = 0.027260154574369203
Trained batch 553 in epoch 6, gen_loss = 1.1249124018293857, disc_loss = 0.027212325888742093
Trained batch 554 in epoch 6, gen_loss = 1.1248561315708332, disc_loss = 0.027164216704290624
Trained batch 555 in epoch 6, gen_loss = 1.1249149450295264, disc_loss = 0.02711645262280013
Trained batch 556 in epoch 6, gen_loss = 1.124711436900031, disc_loss = 0.027068695134904525
Trained batch 557 in epoch 6, gen_loss = 1.124928188366702, disc_loss = 0.027021330104838606
Trained batch 558 in epoch 6, gen_loss = 1.1247180126647403, disc_loss = 0.02697461452420244
Trained batch 559 in epoch 6, gen_loss = 1.1247591120856149, disc_loss = 0.026930030955801546
Trained batch 560 in epoch 6, gen_loss = 1.124334164906738, disc_loss = 0.02688832224942833
Trained batch 561 in epoch 6, gen_loss = 1.1242707781095946, disc_loss = 0.026843647329980118
Trained batch 562 in epoch 6, gen_loss = 1.1247215969736157, disc_loss = 0.026799067578562902
Trained batch 563 in epoch 6, gen_loss = 1.1248308331408399, disc_loss = 0.026754509670147898
Trained batch 564 in epoch 6, gen_loss = 1.1246919895695373, disc_loss = 0.026711933398184024
Trained batch 565 in epoch 6, gen_loss = 1.124550285482575, disc_loss = 0.026668353555141435
Trained batch 566 in epoch 6, gen_loss = 1.1242817213505873, disc_loss = 0.026625154623853654
Trained batch 567 in epoch 6, gen_loss = 1.1243555287660008, disc_loss = 0.026581960068795808
Trained batch 568 in epoch 6, gen_loss = 1.124468215949087, disc_loss = 0.026538114115959077
Trained batch 569 in epoch 6, gen_loss = 1.124163843351498, disc_loss = 0.026494524068453883
Trained batch 570 in epoch 6, gen_loss = 1.1242240923089863, disc_loss = 0.026452990689319694
Trained batch 571 in epoch 6, gen_loss = 1.124705490428251, disc_loss = 0.026411020704294238
Trained batch 572 in epoch 6, gen_loss = 1.124697743181991, disc_loss = 0.026366597013183838
Trained batch 573 in epoch 6, gen_loss = 1.1250642348041933, disc_loss = 0.026322597328011975
Trained batch 574 in epoch 6, gen_loss = 1.1250000734951184, disc_loss = 0.02627983526482358
Trained batch 575 in epoch 6, gen_loss = 1.1249543007256255, disc_loss = 0.02623554685723977
Trained batch 576 in epoch 6, gen_loss = 1.1252249385289963, disc_loss = 0.026191547661843693
Trained batch 577 in epoch 6, gen_loss = 1.1254223497474896, disc_loss = 0.02614753894041569
Trained batch 578 in epoch 6, gen_loss = 1.1252995738711382, disc_loss = 0.026104370928033187
Trained batch 579 in epoch 6, gen_loss = 1.1254579294344476, disc_loss = 0.026061177344584803
Trained batch 580 in epoch 6, gen_loss = 1.1254785127565905, disc_loss = 0.026018178975627866
Trained batch 581 in epoch 6, gen_loss = 1.1253345968182553, disc_loss = 0.025974902967200595
Trained batch 582 in epoch 6, gen_loss = 1.1252973097061825, disc_loss = 0.025931184031953377
Trained batch 583 in epoch 6, gen_loss = 1.1251052549644693, disc_loss = 0.025888131320879103
Trained batch 584 in epoch 6, gen_loss = 1.125319053678431, disc_loss = 0.025844864615945158
Trained batch 585 in epoch 6, gen_loss = 1.1252451527851026, disc_loss = 0.025802040394391518
Trained batch 586 in epoch 6, gen_loss = 1.1254699503339738, disc_loss = 0.025759954883689137
Trained batch 587 in epoch 6, gen_loss = 1.1256340288994264, disc_loss = 0.025717047621199737
Trained batch 588 in epoch 6, gen_loss = 1.1255853472622221, disc_loss = 0.025674728318870108
Trained batch 589 in epoch 6, gen_loss = 1.125448004775128, disc_loss = 0.025633197678073004
Trained batch 590 in epoch 6, gen_loss = 1.1255293238384874, disc_loss = 0.025591639817162757
Trained batch 591 in epoch 6, gen_loss = 1.1254991896047786, disc_loss = 0.025551729361981218
Trained batch 592 in epoch 6, gen_loss = 1.1256952755165743, disc_loss = 0.025511116139187016
Trained batch 593 in epoch 6, gen_loss = 1.1256864499363433, disc_loss = 0.02546948044568836
Trained batch 594 in epoch 6, gen_loss = 1.1254374071329583, disc_loss = 0.02542991016852276
Trained batch 595 in epoch 6, gen_loss = 1.125230439157294, disc_loss = 0.0253886815908789
Trained batch 596 in epoch 6, gen_loss = 1.125268399815264, disc_loss = 0.0253487399860941
Trained batch 597 in epoch 6, gen_loss = 1.1250451116458229, disc_loss = 0.02530895473420093
Trained batch 598 in epoch 6, gen_loss = 1.1248015497682091, disc_loss = 0.02526940034505107
Trained batch 599 in epoch 6, gen_loss = 1.125145241220792, disc_loss = 0.025230742088303185
Trained batch 600 in epoch 6, gen_loss = 1.1247998956039225, disc_loss = 0.025191380093340508
Trained batch 601 in epoch 6, gen_loss = 1.1248704208884128, disc_loss = 0.0251529103193131
Trained batch 602 in epoch 6, gen_loss = 1.125282795077335, disc_loss = 0.02511268594391962
Trained batch 603 in epoch 6, gen_loss = 1.1250312130972249, disc_loss = 0.02507493092822031
Trained batch 604 in epoch 6, gen_loss = 1.1247235891247584, disc_loss = 0.02503564276472494
Trained batch 605 in epoch 6, gen_loss = 1.1245127625197862, disc_loss = 0.024995467979546923
Trained batch 606 in epoch 6, gen_loss = 1.1246066435165027, disc_loss = 0.024956544816067357
Trained batch 607 in epoch 6, gen_loss = 1.1243371951736902, disc_loss = 0.024917517997544946
Trained batch 608 in epoch 6, gen_loss = 1.1245943012300188, disc_loss = 0.024877863365459375
Trained batch 609 in epoch 6, gen_loss = 1.1247021256900225, disc_loss = 0.02483852900077778
Trained batch 610 in epoch 6, gen_loss = 1.1246259784152193, disc_loss = 0.024798940084037716
Trained batch 611 in epoch 6, gen_loss = 1.1245234090518328, disc_loss = 0.024759893424999103
Trained batch 612 in epoch 6, gen_loss = 1.1249717662618366, disc_loss = 0.02472084581602559
Trained batch 613 in epoch 6, gen_loss = 1.1250577209826789, disc_loss = 0.024683319389247407
Trained batch 614 in epoch 6, gen_loss = 1.12480946062057, disc_loss = 0.024644533485186956
Trained batch 615 in epoch 6, gen_loss = 1.1250235675410791, disc_loss = 0.024605638481687068
Trained batch 616 in epoch 6, gen_loss = 1.1253791708420702, disc_loss = 0.02456729971494809
Trained batch 617 in epoch 6, gen_loss = 1.1251531115048912, disc_loss = 0.02452882427304166
Trained batch 618 in epoch 6, gen_loss = 1.1252763630500324, disc_loss = 0.024490119521736988
Trained batch 619 in epoch 6, gen_loss = 1.1255820531037546, disc_loss = 0.024451418159444602
Trained batch 620 in epoch 6, gen_loss = 1.1253224821482304, disc_loss = 0.024421582368182166
Trained batch 621 in epoch 6, gen_loss = 1.1250996730526928, disc_loss = 0.024389462230366882
Trained batch 622 in epoch 6, gen_loss = 1.12529079001367, disc_loss = 0.024354716759571866
Trained batch 623 in epoch 6, gen_loss = 1.1254754793376496, disc_loss = 0.024318800229488822
Trained batch 624 in epoch 6, gen_loss = 1.1252190167427063, disc_loss = 0.024288844160025472
Trained batch 625 in epoch 6, gen_loss = 1.125211195157359, disc_loss = 0.024257007420258565
Trained batch 626 in epoch 6, gen_loss = 1.125131112441682, disc_loss = 0.024225062334965644
Trained batch 627 in epoch 6, gen_loss = 1.1251173409496902, disc_loss = 0.024189000077666414
Trained batch 628 in epoch 6, gen_loss = 1.1250127128463103, disc_loss = 0.024156183874660148
Trained batch 629 in epoch 6, gen_loss = 1.12514268793757, disc_loss = 0.024121007646675616
Trained batch 630 in epoch 6, gen_loss = 1.1249324814453368, disc_loss = 0.024089504095720457
Trained batch 631 in epoch 6, gen_loss = 1.124755584363696, disc_loss = 0.024053411015463294
Trained batch 632 in epoch 6, gen_loss = 1.1249372081545668, disc_loss = 0.024018005481595155
Trained batch 633 in epoch 6, gen_loss = 1.124964925957027, disc_loss = 0.023982824178958185
Trained batch 634 in epoch 6, gen_loss = 1.1250531215367354, disc_loss = 0.023947761397417836
Trained batch 635 in epoch 6, gen_loss = 1.1252185640470036, disc_loss = 0.023911025623734452
Trained batch 636 in epoch 6, gen_loss = 1.1252603177185898, disc_loss = 0.023874468227800073
Trained batch 637 in epoch 6, gen_loss = 1.1255386253135704, disc_loss = 0.02383802506883056
Trained batch 638 in epoch 6, gen_loss = 1.1255981448297396, disc_loss = 0.023801901250516434
Trained batch 639 in epoch 6, gen_loss = 1.1256962509825825, disc_loss = 0.023765385043623154
Trained batch 640 in epoch 6, gen_loss = 1.1260545590366478, disc_loss = 0.023730421953907874
Trained batch 641 in epoch 6, gen_loss = 1.1260699328975143, disc_loss = 0.023694896719320457
Trained batch 642 in epoch 6, gen_loss = 1.1261701111103848, disc_loss = 0.023659256835173274
Trained batch 643 in epoch 6, gen_loss = 1.1264775106625526, disc_loss = 0.02362324066291068
Trained batch 644 in epoch 6, gen_loss = 1.1263760036276294, disc_loss = 0.023587305327395044
Trained batch 645 in epoch 6, gen_loss = 1.126611238478138, disc_loss = 0.023551380937688264
Trained batch 646 in epoch 6, gen_loss = 1.1264104971192903, disc_loss = 0.023515979738107044
Trained batch 647 in epoch 6, gen_loss = 1.1263605311145017, disc_loss = 0.02348022622919854
Trained batch 648 in epoch 6, gen_loss = 1.1266804010548466, disc_loss = 0.023445455078535606
Trained batch 649 in epoch 6, gen_loss = 1.126589074593324, disc_loss = 0.023410250342198055
Trained batch 650 in epoch 6, gen_loss = 1.1262659811387596, disc_loss = 0.023375396025772568
Trained batch 651 in epoch 6, gen_loss = 1.1263914441952676, disc_loss = 0.023340856639414
Trained batch 652 in epoch 6, gen_loss = 1.1263468414316864, disc_loss = 0.023306006851146026
Trained batch 653 in epoch 6, gen_loss = 1.1264320525372065, disc_loss = 0.02327082283854823
Trained batch 654 in epoch 6, gen_loss = 1.1262353668686087, disc_loss = 0.02323616781721437
Trained batch 655 in epoch 6, gen_loss = 1.1262448859832637, disc_loss = 0.023202625720098628
Trained batch 656 in epoch 6, gen_loss = 1.1260322447599704, disc_loss = 0.02316882652813302
Trained batch 657 in epoch 6, gen_loss = 1.1264020154722556, disc_loss = 0.02313493582677076
Trained batch 658 in epoch 6, gen_loss = 1.1266412880605197, disc_loss = 0.023100908428349914
Trained batch 659 in epoch 6, gen_loss = 1.126596718394395, disc_loss = 0.023067007744876637
Trained batch 660 in epoch 6, gen_loss = 1.126601256959918, disc_loss = 0.023033021081433333
Trained batch 661 in epoch 6, gen_loss = 1.126711056221648, disc_loss = 0.022998750273500457
Trained batch 662 in epoch 6, gen_loss = 1.1269481645090726, disc_loss = 0.022965088055458473
Trained batch 663 in epoch 6, gen_loss = 1.127124395984483, disc_loss = 0.022931204768534063
Trained batch 664 in epoch 6, gen_loss = 1.1272614151911629, disc_loss = 0.022897788058496796
Trained batch 665 in epoch 6, gen_loss = 1.1281544083768542, disc_loss = 0.02286496918356176
Trained batch 666 in epoch 6, gen_loss = 1.1281577501518616, disc_loss = 0.022832624863726635
Trained batch 667 in epoch 6, gen_loss = 1.1282380647109653, disc_loss = 0.022799719238387053
Trained batch 668 in epoch 6, gen_loss = 1.1288229600374653, disc_loss = 0.0227674405588604
Trained batch 669 in epoch 6, gen_loss = 1.1288750875352034, disc_loss = 0.0227348402920835
Trained batch 670 in epoch 6, gen_loss = 1.128849690877201, disc_loss = 0.02270209404384471
Trained batch 671 in epoch 6, gen_loss = 1.1287194729028713, disc_loss = 0.022669456488670005
Trained batch 672 in epoch 6, gen_loss = 1.1284263563545816, disc_loss = 0.02263693339257758
Trained batch 673 in epoch 6, gen_loss = 1.1289886592580587, disc_loss = 0.02260496163522389
Trained batch 674 in epoch 6, gen_loss = 1.1287945522202385, disc_loss = 0.022572661934461426
Trained batch 675 in epoch 6, gen_loss = 1.1287670291563463, disc_loss = 0.022540266162063772
Trained batch 676 in epoch 6, gen_loss = 1.129018534145468, disc_loss = 0.022507800764900422
Trained batch 677 in epoch 6, gen_loss = 1.128810039136262, disc_loss = 0.022479711759362524
Trained batch 678 in epoch 6, gen_loss = 1.128971590560385, disc_loss = 0.02245084051546133
Trained batch 679 in epoch 6, gen_loss = 1.128754459935076, disc_loss = 0.022418972005396106
Trained batch 680 in epoch 6, gen_loss = 1.1287469042905451, disc_loss = 0.022386874907151143
Trained batch 681 in epoch 6, gen_loss = 1.1287609060838426, disc_loss = 0.02235571444228104
Trained batch 682 in epoch 6, gen_loss = 1.1284824538195988, disc_loss = 0.02232500285847959
Trained batch 683 in epoch 6, gen_loss = 1.128685586633738, disc_loss = 0.02229357709288786
Trained batch 684 in epoch 6, gen_loss = 1.1287671304967282, disc_loss = 0.022261687248329595
Trained batch 685 in epoch 6, gen_loss = 1.1290123092537372, disc_loss = 0.022230031463285244
Trained batch 686 in epoch 6, gen_loss = 1.1290893018505979, disc_loss = 0.02219861358087237
Trained batch 687 in epoch 6, gen_loss = 1.1290382557483607, disc_loss = 0.02216860637518462
Trained batch 688 in epoch 6, gen_loss = 1.128792647959013, disc_loss = 0.02214001054727161
Trained batch 689 in epoch 6, gen_loss = 1.1289070334123528, disc_loss = 0.022112350791101798
Trained batch 690 in epoch 6, gen_loss = 1.1290661761626148, disc_loss = 0.02208313465221135
Trained batch 691 in epoch 6, gen_loss = 1.129182576874777, disc_loss = 0.02205285601497847
Trained batch 692 in epoch 6, gen_loss = 1.1293137924151675, disc_loss = 0.022021579542507642
Trained batch 693 in epoch 6, gen_loss = 1.129274742489933, disc_loss = 0.021990910339819973
Trained batch 694 in epoch 6, gen_loss = 1.1291721291679273, disc_loss = 0.021960028460391263
Trained batch 695 in epoch 6, gen_loss = 1.1293390085813644, disc_loss = 0.02192937136943987
Trained batch 696 in epoch 6, gen_loss = 1.1294239440470548, disc_loss = 0.021898508970516716
Trained batch 697 in epoch 6, gen_loss = 1.129227018202615, disc_loss = 0.021867870479365753
Trained batch 698 in epoch 6, gen_loss = 1.12893285388087, disc_loss = 0.02183889883324677
Trained batch 699 in epoch 6, gen_loss = 1.1292394218274526, disc_loss = 0.021809224694349854
Trained batch 700 in epoch 6, gen_loss = 1.129164887137828, disc_loss = 0.02178072172378616
Trained batch 701 in epoch 6, gen_loss = 1.1293628714193307, disc_loss = 0.02175171467476381
Trained batch 702 in epoch 6, gen_loss = 1.1293873158661094, disc_loss = 0.021722018365695817
Trained batch 703 in epoch 6, gen_loss = 1.1293590350753882, disc_loss = 0.02169211410160766
Trained batch 704 in epoch 6, gen_loss = 1.1291939580694157, disc_loss = 0.02166342470238228
Trained batch 705 in epoch 6, gen_loss = 1.1291556990686962, disc_loss = 0.02163381563837727
Trained batch 706 in epoch 6, gen_loss = 1.1291335597739698, disc_loss = 0.021603997085716288
Trained batch 707 in epoch 6, gen_loss = 1.1289087029668572, disc_loss = 0.021575339567121352
Trained batch 708 in epoch 6, gen_loss = 1.1288258804925237, disc_loss = 0.02154659750759173
Trained batch 709 in epoch 6, gen_loss = 1.1290775410726037, disc_loss = 0.021517602466553053
Trained batch 710 in epoch 6, gen_loss = 1.1289809044403365, disc_loss = 0.021488071709385246
Trained batch 711 in epoch 6, gen_loss = 1.1291229899847106, disc_loss = 0.021459068707760678
Trained batch 712 in epoch 6, gen_loss = 1.1291702476657959, disc_loss = 0.021429994893663182
Trained batch 713 in epoch 6, gen_loss = 1.1293723497237145, disc_loss = 0.021400592938699045
Trained batch 714 in epoch 6, gen_loss = 1.1296562574126503, disc_loss = 0.02137167248515684
Trained batch 715 in epoch 6, gen_loss = 1.1296710013177809, disc_loss = 0.021342706179685547
Trained batch 716 in epoch 6, gen_loss = 1.1295528020320078, disc_loss = 0.02131335923237415
Trained batch 717 in epoch 6, gen_loss = 1.129598414748492, disc_loss = 0.021284302371852977
Trained batch 718 in epoch 6, gen_loss = 1.1297199755119516, disc_loss = 0.021255496710631396
Trained batch 719 in epoch 6, gen_loss = 1.1295063049428993, disc_loss = 0.021227388633380743
Trained batch 720 in epoch 6, gen_loss = 1.1292318809214312, disc_loss = 0.02119898580191468
Trained batch 721 in epoch 6, gen_loss = 1.1293321695189067, disc_loss = 0.021170804658909106
Trained batch 722 in epoch 6, gen_loss = 1.1296323495781768, disc_loss = 0.021142736248499962
Trained batch 723 in epoch 6, gen_loss = 1.129889620848782, disc_loss = 0.021114046423010915
Trained batch 724 in epoch 6, gen_loss = 1.1298755418021103, disc_loss = 0.02108556281156027
Trained batch 725 in epoch 6, gen_loss = 1.1296200996095485, disc_loss = 0.02105812874652749
Trained batch 726 in epoch 6, gen_loss = 1.1300085618210627, disc_loss = 0.02102995404988318
Trained batch 727 in epoch 6, gen_loss = 1.130313675564069, disc_loss = 0.021002789532098838
Trained batch 728 in epoch 6, gen_loss = 1.1303928576215632, disc_loss = 0.020974594479394724
Trained batch 729 in epoch 6, gen_loss = 1.1305275947263795, disc_loss = 0.020947042232080704
Trained batch 730 in epoch 6, gen_loss = 1.1303999796611666, disc_loss = 0.02091904609720629
Trained batch 731 in epoch 6, gen_loss = 1.1301035683988874, disc_loss = 0.02089119997865174
Trained batch 732 in epoch 6, gen_loss = 1.1300399420531353, disc_loss = 0.020863316742377975
Trained batch 733 in epoch 6, gen_loss = 1.1297988688588467, disc_loss = 0.020835957129113424
Trained batch 734 in epoch 6, gen_loss = 1.1297484792008692, disc_loss = 0.020808214899720734
Trained batch 735 in epoch 6, gen_loss = 1.1299458453836648, disc_loss = 0.020781297691141648
Trained batch 736 in epoch 6, gen_loss = 1.1300721665088649, disc_loss = 0.02075366463177587
Trained batch 737 in epoch 6, gen_loss = 1.1297950562907428, disc_loss = 0.02072637833013137
Trained batch 738 in epoch 6, gen_loss = 1.129786628428267, disc_loss = 0.020698961244394083
Trained batch 739 in epoch 6, gen_loss = 1.1294180912745966, disc_loss = 0.020671787651834264
Trained batch 740 in epoch 6, gen_loss = 1.1292998315351694, disc_loss = 0.02064520631920238
Trained batch 741 in epoch 6, gen_loss = 1.1293453009462742, disc_loss = 0.020618749134774954
Trained batch 742 in epoch 6, gen_loss = 1.1293357091668799, disc_loss = 0.02059184073943989
Trained batch 743 in epoch 6, gen_loss = 1.1292401014636921, disc_loss = 0.02056534337996083
Trained batch 744 in epoch 6, gen_loss = 1.12916688863063, disc_loss = 0.020538320401579924
Trained batch 745 in epoch 6, gen_loss = 1.1291638033479532, disc_loss = 0.020512006124212757
Trained batch 746 in epoch 6, gen_loss = 1.1291545068563387, disc_loss = 0.020485506083188162
Trained batch 747 in epoch 6, gen_loss = 1.1291473593144494, disc_loss = 0.02045861969064113
Trained batch 748 in epoch 6, gen_loss = 1.1290779829184427, disc_loss = 0.02043202286367595
Trained batch 749 in epoch 6, gen_loss = 1.1291802027225495, disc_loss = 0.020405663446047887
Trained batch 750 in epoch 6, gen_loss = 1.1294949515840502, disc_loss = 0.020379555591133056
Trained batch 751 in epoch 6, gen_loss = 1.1293357535404094, disc_loss = 0.020352959851761818
Trained batch 752 in epoch 6, gen_loss = 1.1291828241797874, disc_loss = 0.020326591212296494
Trained batch 753 in epoch 6, gen_loss = 1.1291831318358212, disc_loss = 0.020300183102830275
Trained batch 754 in epoch 6, gen_loss = 1.12963030804072, disc_loss = 0.020274144425340205
Trained batch 755 in epoch 6, gen_loss = 1.1298605002581128, disc_loss = 0.020248232353758545
Trained batch 756 in epoch 6, gen_loss = 1.1297771468502684, disc_loss = 0.020222115331157395
Trained batch 757 in epoch 6, gen_loss = 1.1298903136423206, disc_loss = 0.02019633317562175
Trained batch 758 in epoch 6, gen_loss = 1.1299038312651895, disc_loss = 0.020170264178493973
Trained batch 759 in epoch 6, gen_loss = 1.129661616447725, disc_loss = 0.02014473543591808
Trained batch 760 in epoch 6, gen_loss = 1.1295217514508031, disc_loss = 0.020119562572909384
Trained batch 761 in epoch 6, gen_loss = 1.1293402918054676, disc_loss = 0.020095284572249662
Trained batch 762 in epoch 6, gen_loss = 1.1293825846980783, disc_loss = 0.020070917793521142
Trained batch 763 in epoch 6, gen_loss = 1.1298357263909584, disc_loss = 0.020045960037298218
Trained batch 764 in epoch 6, gen_loss = 1.1296024246932634, disc_loss = 0.020022440102669254
Trained batch 765 in epoch 6, gen_loss = 1.129339385826345, disc_loss = 0.019998372933260386
Trained batch 766 in epoch 6, gen_loss = 1.1294358419315134, disc_loss = 0.019973457900107478
Trained batch 767 in epoch 6, gen_loss = 1.1297242479243625, disc_loss = 0.019947942076811387
Trained batch 768 in epoch 6, gen_loss = 1.1294682745970737, disc_loss = 0.019923013808912014
Trained batch 769 in epoch 6, gen_loss = 1.1293653767604332, disc_loss = 0.01989806315153134
Trained batch 770 in epoch 6, gen_loss = 1.1293432529334428, disc_loss = 0.019873027083661086
Trained batch 771 in epoch 6, gen_loss = 1.129362377400843, disc_loss = 0.019848338571829716
Trained batch 772 in epoch 6, gen_loss = 1.1293218341712656, disc_loss = 0.019823472876240512
Trained batch 773 in epoch 6, gen_loss = 1.1295151588066603, disc_loss = 0.019798345805301248
Trained batch 774 in epoch 6, gen_loss = 1.1295816065419104, disc_loss = 0.01977349041434448
Trained batch 775 in epoch 6, gen_loss = 1.129528509817787, disc_loss = 0.0197484066965791
Trained batch 776 in epoch 6, gen_loss = 1.1295813304423672, disc_loss = 0.019723411164504726
Trained batch 777 in epoch 6, gen_loss = 1.1297208333536408, disc_loss = 0.019698473378203935
Trained batch 778 in epoch 6, gen_loss = 1.1297777830712756, disc_loss = 0.019673954514180688
Trained batch 779 in epoch 6, gen_loss = 1.1299751869378947, disc_loss = 0.01964923927607276
Trained batch 780 in epoch 6, gen_loss = 1.1297971454381026, disc_loss = 0.019624734888480135
Trained batch 781 in epoch 6, gen_loss = 1.1298796667162414, disc_loss = 0.01960041082065451
Trained batch 782 in epoch 6, gen_loss = 1.1298317064270662, disc_loss = 0.019575992767982074
Trained batch 783 in epoch 6, gen_loss = 1.1298683008977346, disc_loss = 0.019551554139636617
Trained batch 784 in epoch 6, gen_loss = 1.1298008320437876, disc_loss = 0.019527062222020105
Trained batch 785 in epoch 6, gen_loss = 1.1300714959321738, disc_loss = 0.019502551553233775
Trained batch 786 in epoch 6, gen_loss = 1.1300139260564706, disc_loss = 0.019478055338302123
Trained batch 787 in epoch 6, gen_loss = 1.1298770815285328, disc_loss = 0.01945397751800842
Trained batch 788 in epoch 6, gen_loss = 1.1298866126927132, disc_loss = 0.019429957784062146
Trained batch 789 in epoch 6, gen_loss = 1.1297501737558389, disc_loss = 0.019405771274798582
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 1.1503043174743652, disc_loss = 0.0003836925025098026
Trained batch 1 in epoch 7, gen_loss = 1.1073777675628662, disc_loss = 0.0005763479566667229
Trained batch 2 in epoch 7, gen_loss = 1.1161590814590454, disc_loss = 0.0005906059911164144
Trained batch 3 in epoch 7, gen_loss = 1.1679401695728302, disc_loss = 0.0005645310593536124
Trained batch 4 in epoch 7, gen_loss = 1.1466222047805785, disc_loss = 0.0005655455985106528
Trained batch 5 in epoch 7, gen_loss = 1.1345518032709758, disc_loss = 0.0005679286647743235
Trained batch 6 in epoch 7, gen_loss = 1.135495935167585, disc_loss = 0.0005566993744910828
Trained batch 7 in epoch 7, gen_loss = 1.1530755013227463, disc_loss = 0.0005203475666348822
Trained batch 8 in epoch 7, gen_loss = 1.158751130104065, disc_loss = 0.0005153627264209919
Trained batch 9 in epoch 7, gen_loss = 1.1833521604537964, disc_loss = 0.0005342199117876589
Trained batch 10 in epoch 7, gen_loss = 1.161053104834123, disc_loss = 0.0005834737729111856
Trained batch 11 in epoch 7, gen_loss = 1.1427916089693706, disc_loss = 0.0005699422326870263
Trained batch 12 in epoch 7, gen_loss = 1.1640006945683405, disc_loss = 0.0005709988494905141
Trained batch 13 in epoch 7, gen_loss = 1.1568448458399092, disc_loss = 0.000572852707201881
Trained batch 14 in epoch 7, gen_loss = 1.1708764632542927, disc_loss = 0.0006029987707734108
Trained batch 15 in epoch 7, gen_loss = 1.1669636815786362, disc_loss = 0.0006225847828318365
Trained batch 16 in epoch 7, gen_loss = 1.1548804675831514, disc_loss = 0.0006394756423747715
Trained batch 17 in epoch 7, gen_loss = 1.1535240742895339, disc_loss = 0.0006670279738803705
Trained batch 18 in epoch 7, gen_loss = 1.1593140677401894, disc_loss = 0.0006791562497566797
Trained batch 19 in epoch 7, gen_loss = 1.1555699706077576, disc_loss = 0.0006678331672446802
Trained batch 20 in epoch 7, gen_loss = 1.1445378774688357, disc_loss = 0.000665502597777439
Trained batch 21 in epoch 7, gen_loss = 1.141524756496603, disc_loss = 0.0006620812848929993
Trained batch 22 in epoch 7, gen_loss = 1.1372490058774534, disc_loss = 0.0006877338923716351
Trained batch 23 in epoch 7, gen_loss = 1.1331753060221672, disc_loss = 0.0007004523674064936
Trained batch 24 in epoch 7, gen_loss = 1.1278145575523377, disc_loss = 0.0007163820252753794
Trained batch 25 in epoch 7, gen_loss = 1.1278835328725667, disc_loss = 0.0007149343996738585
Trained batch 26 in epoch 7, gen_loss = 1.1234122271890994, disc_loss = 0.0007008273646028505
Trained batch 27 in epoch 7, gen_loss = 1.1205676602465766, disc_loss = 0.0006926043643034063
Trained batch 28 in epoch 7, gen_loss = 1.1153455273858432, disc_loss = 0.0006922722125731023
Trained batch 29 in epoch 7, gen_loss = 1.1196895162264506, disc_loss = 0.0006926991792473321
Trained batch 30 in epoch 7, gen_loss = 1.12700585011513, disc_loss = 0.0006913850619082129
Trained batch 31 in epoch 7, gen_loss = 1.1224687658250332, disc_loss = 0.0007002640058999532
Trained batch 32 in epoch 7, gen_loss = 1.1290636676730532, disc_loss = 0.0007021330432811131
Trained batch 33 in epoch 7, gen_loss = 1.1312639047117794, disc_loss = 0.0007054333528846174
Trained batch 34 in epoch 7, gen_loss = 1.1307692459651402, disc_loss = 0.0006994333209669484
Trained batch 35 in epoch 7, gen_loss = 1.1316743029488459, disc_loss = 0.0006873165766592138
Trained batch 36 in epoch 7, gen_loss = 1.135249460065687, disc_loss = 0.0006835090926206494
Trained batch 37 in epoch 7, gen_loss = 1.1315969542453164, disc_loss = 0.0006805394468277594
Trained batch 38 in epoch 7, gen_loss = 1.130416677548335, disc_loss = 0.0006778126915331739
Trained batch 39 in epoch 7, gen_loss = 1.1385495960712433, disc_loss = 0.0006680645157757681
Trained batch 40 in epoch 7, gen_loss = 1.141602725517459, disc_loss = 0.0006602574920667926
Trained batch 41 in epoch 7, gen_loss = 1.1402246838524228, disc_loss = 0.0006523621296288357
Trained batch 42 in epoch 7, gen_loss = 1.1402275534563286, disc_loss = 0.0006463061896326064
Trained batch 43 in epoch 7, gen_loss = 1.1353920820084484, disc_loss = 0.000643437361842106
Trained batch 44 in epoch 7, gen_loss = 1.1333582149611579, disc_loss = 0.0006410569806272785
Trained batch 45 in epoch 7, gen_loss = 1.13195972468542, disc_loss = 0.0006346046879037243
Trained batch 46 in epoch 7, gen_loss = 1.1300770488191159, disc_loss = 0.0006265308852852422
Trained batch 47 in epoch 7, gen_loss = 1.13074067607522, disc_loss = 0.0006196437855881717
Trained batch 48 in epoch 7, gen_loss = 1.1293364021242882, disc_loss = 0.0006126778774029974
Trained batch 49 in epoch 7, gen_loss = 1.1301844704151154, disc_loss = 0.0006061346735805273
Trained batch 50 in epoch 7, gen_loss = 1.130609459736768, disc_loss = 0.000598287184759244
Trained batch 51 in epoch 7, gen_loss = 1.1301244990183756, disc_loss = 0.0005910883746065127
Trained batch 52 in epoch 7, gen_loss = 1.1285971864214484, disc_loss = 0.0005839988149983703
Trained batch 53 in epoch 7, gen_loss = 1.1298151623319697, disc_loss = 0.0005793105164128873
Trained batch 54 in epoch 7, gen_loss = 1.1291312727061185, disc_loss = 0.0005725084528834983
Trained batch 55 in epoch 7, gen_loss = 1.1312543483717101, disc_loss = 0.0005689741587307903
Trained batch 56 in epoch 7, gen_loss = 1.1316174153696026, disc_loss = 0.0005656256470134842
Trained batch 57 in epoch 7, gen_loss = 1.13010314723541, disc_loss = 0.000565666785154588
Trained batch 58 in epoch 7, gen_loss = 1.1330279081554737, disc_loss = 0.0005634723480798746
Trained batch 59 in epoch 7, gen_loss = 1.1341564724842708, disc_loss = 0.0005623010768128248
Trained batch 60 in epoch 7, gen_loss = 1.132021480896434, disc_loss = 0.0005598692566950302
Trained batch 61 in epoch 7, gen_loss = 1.132590087190751, disc_loss = 0.0005565910110054838
Trained batch 62 in epoch 7, gen_loss = 1.1336866040078422, disc_loss = 0.0005507517420309817
Trained batch 63 in epoch 7, gen_loss = 1.13181038107723, disc_loss = 0.0005455473315123527
Trained batch 64 in epoch 7, gen_loss = 1.1360795507064232, disc_loss = 0.0005436262433739522
Trained batch 65 in epoch 7, gen_loss = 1.132286371606769, disc_loss = 0.0005442134680572163
Trained batch 66 in epoch 7, gen_loss = 1.1291684641766904, disc_loss = 0.0005434693420243296
Trained batch 67 in epoch 7, gen_loss = 1.1289951853892382, disc_loss = 0.0005424307579660843
Trained batch 68 in epoch 7, gen_loss = 1.1289113621780837, disc_loss = 0.0005396245856452193
Trained batch 69 in epoch 7, gen_loss = 1.128561382634299, disc_loss = 0.0005394537180628894
Trained batch 70 in epoch 7, gen_loss = 1.1285927245314693, disc_loss = 0.0005450933662564559
Trained batch 71 in epoch 7, gen_loss = 1.1292462531063292, disc_loss = 0.000545679254880977
Trained batch 72 in epoch 7, gen_loss = 1.1271222241937298, disc_loss = 0.0005452605741806583
Trained batch 73 in epoch 7, gen_loss = 1.1258441644745905, disc_loss = 0.000543969904380926
Trained batch 74 in epoch 7, gen_loss = 1.1261969137191772, disc_loss = 0.0005408619709002475
Trained batch 75 in epoch 7, gen_loss = 1.1285098053907092, disc_loss = 0.0005382780229985272
Trained batch 76 in epoch 7, gen_loss = 1.130013950459369, disc_loss = 0.00053669893721046
Trained batch 77 in epoch 7, gen_loss = 1.1328384891534462, disc_loss = 0.0005321218277691888
Trained batch 78 in epoch 7, gen_loss = 1.1316925543773024, disc_loss = 0.0005312484370019947
Trained batch 79 in epoch 7, gen_loss = 1.1345690712332726, disc_loss = 0.0005308664276526542
Trained batch 80 in epoch 7, gen_loss = 1.133518797379953, disc_loss = 0.0005295637561680956
Trained batch 81 in epoch 7, gen_loss = 1.1348875353975993, disc_loss = 0.0005294272541948707
Trained batch 82 in epoch 7, gen_loss = 1.1369154438915023, disc_loss = 0.0005274011065527033
Trained batch 83 in epoch 7, gen_loss = 1.1378463322208041, disc_loss = 0.0005291281042792391
Trained batch 84 in epoch 7, gen_loss = 1.1365537012324614, disc_loss = 0.0005301367159357623
Trained batch 85 in epoch 7, gen_loss = 1.1398200157076814, disc_loss = 0.0005314655836839446
Trained batch 86 in epoch 7, gen_loss = 1.1395133034936313, disc_loss = 0.0005290748139350921
Trained batch 87 in epoch 7, gen_loss = 1.1374609727751126, disc_loss = 0.0020192776970692316
Trained batch 88 in epoch 7, gen_loss = 1.131373955292648, disc_loss = 0.009418565578486644
Trained batch 89 in epoch 7, gen_loss = 1.1333165440294477, disc_loss = 0.013548748699637752
Trained batch 90 in epoch 7, gen_loss = 1.1306489227892278, disc_loss = 0.018061643126062475
Trained batch 91 in epoch 7, gen_loss = 1.1267289422128512, disc_loss = 0.021552305190277326
Trained batch 92 in epoch 7, gen_loss = 1.1241071647213352, disc_loss = 0.0240806392519184
Trained batch 93 in epoch 7, gen_loss = 1.1213978224612298, disc_loss = 0.02646169970753266
Trained batch 94 in epoch 7, gen_loss = 1.1204830771998355, disc_loss = 0.028466795156954935
Trained batch 95 in epoch 7, gen_loss = 1.1153161910672982, disc_loss = 0.030609409487321198
Trained batch 96 in epoch 7, gen_loss = 1.112212929529013, disc_loss = 0.032445233668075855
Trained batch 97 in epoch 7, gen_loss = 1.1119001313131682, disc_loss = 0.03398783551291468
Trained batch 98 in epoch 7, gen_loss = 1.1102330130760116, disc_loss = 0.03696081178460383
Trained batch 99 in epoch 7, gen_loss = 1.1082488119602203, disc_loss = 0.04120632515056059
Trained batch 100 in epoch 7, gen_loss = 1.1040566056081564, disc_loss = 0.044189340856829934
Trained batch 101 in epoch 7, gen_loss = 1.0995055174126345, disc_loss = 0.047093636125746165
Trained batch 102 in epoch 7, gen_loss = 1.098310487362945, disc_loss = 0.04905532619427636
Trained batch 103 in epoch 7, gen_loss = 1.0947598941051042, disc_loss = 0.05056656955051809
Trained batch 104 in epoch 7, gen_loss = 1.094232660248166, disc_loss = 0.05189048066690919
Trained batch 105 in epoch 7, gen_loss = 1.0903023391399744, disc_loss = 0.05268526007640966
Trained batch 106 in epoch 7, gen_loss = 1.0875153535994413, disc_loss = 0.053193771678553985
Trained batch 107 in epoch 7, gen_loss = 1.0854444862515837, disc_loss = 0.05370317538122267
Trained batch 108 in epoch 7, gen_loss = 1.0870278926070678, disc_loss = 0.05419371516973532
Trained batch 109 in epoch 7, gen_loss = 1.0870775293220174, disc_loss = 0.05460573760580949
Trained batch 110 in epoch 7, gen_loss = 1.0862997335356634, disc_loss = 0.05511315952910966
Trained batch 111 in epoch 7, gen_loss = 1.0860927365720272, disc_loss = 0.05576969357831071
Trained batch 112 in epoch 7, gen_loss = 1.084603833413757, disc_loss = 0.05661905306984827
Trained batch 113 in epoch 7, gen_loss = 1.0829736062309199, disc_loss = 0.05661700372461622
Trained batch 114 in epoch 7, gen_loss = 1.0821374665135923, disc_loss = 0.05650393088834117
Trained batch 115 in epoch 7, gen_loss = 1.0811034168662697, disc_loss = 0.0563555437617871
Trained batch 116 in epoch 7, gen_loss = 1.0846971675880954, disc_loss = 0.05665682473331372
Trained batch 117 in epoch 7, gen_loss = 1.086654926255598, disc_loss = 0.0574176684081144
Trained batch 118 in epoch 7, gen_loss = 1.0857870303282218, disc_loss = 0.05793565474724507
Trained batch 119 in epoch 7, gen_loss = 1.0910065020124118, disc_loss = 0.06007241868064739
Trained batch 120 in epoch 7, gen_loss = 1.0917155107190786, disc_loss = 0.06298691835369884
Trained batch 121 in epoch 7, gen_loss = 1.0900239099244602, disc_loss = 0.06373874220775715
Trained batch 122 in epoch 7, gen_loss = 1.0909117969070994, disc_loss = 0.06416070776824968
Trained batch 123 in epoch 7, gen_loss = 1.0892164784093057, disc_loss = 0.06486839717516917
Trained batch 124 in epoch 7, gen_loss = 1.0875832471847535, disc_loss = 0.0653425222095102
Trained batch 125 in epoch 7, gen_loss = 1.085461936299763, disc_loss = 0.06552274886422628
Trained batch 126 in epoch 7, gen_loss = 1.0843208080201636, disc_loss = 0.06583912096235638
Trained batch 127 in epoch 7, gen_loss = 1.08397336024791, disc_loss = 0.06625527074174897
Trained batch 128 in epoch 7, gen_loss = 1.0834885373596073, disc_loss = 0.06634479599947095
Trained batch 129 in epoch 7, gen_loss = 1.0823798729823186, disc_loss = 0.06618546769560243
Trained batch 130 in epoch 7, gen_loss = 1.0829139247195412, disc_loss = 0.0660203515342259
Trained batch 131 in epoch 7, gen_loss = 1.0843231009714531, disc_loss = 0.0658021630546445
Trained batch 132 in epoch 7, gen_loss = 1.0839989785861253, disc_loss = 0.06552271254157606
Trained batch 133 in epoch 7, gen_loss = 1.0841855335591444, disc_loss = 0.06526764163073263
Trained batch 134 in epoch 7, gen_loss = 1.0844972054163615, disc_loss = 0.06501124178887241
Trained batch 135 in epoch 7, gen_loss = 1.0845515351085102, disc_loss = 0.06490439503035947
Trained batch 136 in epoch 7, gen_loss = 1.0850634026701433, disc_loss = 0.06463272405115303
Trained batch 137 in epoch 7, gen_loss = 1.085885174896406, disc_loss = 0.06617095184249236
Trained batch 138 in epoch 7, gen_loss = 1.084919679936745, disc_loss = 0.06703496464903352
Trained batch 139 in epoch 7, gen_loss = 1.0840651818684168, disc_loss = 0.06705534248446514
Trained batch 140 in epoch 7, gen_loss = 1.084824672827484, disc_loss = 0.06739698786863145
Trained batch 141 in epoch 7, gen_loss = 1.0828850370057872, disc_loss = 0.06731376451158136
Trained batch 142 in epoch 7, gen_loss = 1.0857480672689586, disc_loss = 0.06727511886917575
Trained batch 143 in epoch 7, gen_loss = 1.0831995432575543, disc_loss = 0.06778034865823833
Trained batch 144 in epoch 7, gen_loss = 1.0842708628753135, disc_loss = 0.06866802725266537
Trained batch 145 in epoch 7, gen_loss = 1.0834905603160596, disc_loss = 0.06882675724863138
Trained batch 146 in epoch 7, gen_loss = 1.0871828697165664, disc_loss = 0.06893465123582809
Trained batch 147 in epoch 7, gen_loss = 1.0890598796509408, disc_loss = 0.06903192776450384
Trained batch 148 in epoch 7, gen_loss = 1.0892366370898765, disc_loss = 0.06868409184620235
Trained batch 149 in epoch 7, gen_loss = 1.0893688495953877, disc_loss = 0.06843169108498842
Trained batch 150 in epoch 7, gen_loss = 1.0899978828745962, disc_loss = 0.0681604846544095
Trained batch 151 in epoch 7, gen_loss = 1.0891368600882982, disc_loss = 0.0678792992824272
Trained batch 152 in epoch 7, gen_loss = 1.0872014702535142, disc_loss = 0.06781555112493924
Trained batch 153 in epoch 7, gen_loss = 1.0918925331010447, disc_loss = 0.06753312981862865
Trained batch 154 in epoch 7, gen_loss = 1.0937073042315821, disc_loss = 0.06715462555538022
Trained batch 155 in epoch 7, gen_loss = 1.0951753858572397, disc_loss = 0.06678514111972152
Trained batch 156 in epoch 7, gen_loss = 1.095203177564463, disc_loss = 0.06649302042113131
Trained batch 157 in epoch 7, gen_loss = 1.09620279715031, disc_loss = 0.06624835321555927
Trained batch 158 in epoch 7, gen_loss = 1.0939863294175587, disc_loss = 0.06676984411875173
Trained batch 159 in epoch 7, gen_loss = 1.098943230137229, disc_loss = 0.06695577546342975
Trained batch 160 in epoch 7, gen_loss = 1.0989237849756797, disc_loss = 0.06685728864217906
Trained batch 161 in epoch 7, gen_loss = 1.1001657258581232, disc_loss = 0.06664072075875958
Trained batch 162 in epoch 7, gen_loss = 1.1014456408886821, disc_loss = 0.0663182756854964
Trained batch 163 in epoch 7, gen_loss = 1.1018015157158783, disc_loss = 0.06604330221662388
Trained batch 164 in epoch 7, gen_loss = 1.1014129367741672, disc_loss = 0.06578493598481697
Trained batch 165 in epoch 7, gen_loss = 1.1019949600639114, disc_loss = 0.06544990245538977
Trained batch 166 in epoch 7, gen_loss = 1.1072407600408543, disc_loss = 0.06530781675124551
Trained batch 167 in epoch 7, gen_loss = 1.107495172747544, disc_loss = 0.06522192012579624
Trained batch 168 in epoch 7, gen_loss = 1.1096329473884854, disc_loss = 0.06499950369935725
Trained batch 169 in epoch 7, gen_loss = 1.1110899367753198, disc_loss = 0.06468096046078511
Trained batch 170 in epoch 7, gen_loss = 1.1111379119387843, disc_loss = 0.06435367513900045
Trained batch 171 in epoch 7, gen_loss = 1.1114970851083135, disc_loss = 0.0640632658858437
Trained batch 172 in epoch 7, gen_loss = 1.1114775180127578, disc_loss = 0.06382440338368835
Trained batch 173 in epoch 7, gen_loss = 1.1123088307079227, disc_loss = 0.06357850357970415
Trained batch 174 in epoch 7, gen_loss = 1.1154986596107483, disc_loss = 0.06338109421809869
Trained batch 175 in epoch 7, gen_loss = 1.1173976507376542, disc_loss = 0.06314911396872379
Trained batch 176 in epoch 7, gen_loss = 1.12017940094242, disc_loss = 0.06290489701306878
Trained batch 177 in epoch 7, gen_loss = 1.1196020168534826, disc_loss = 0.0626784368310898
Trained batch 178 in epoch 7, gen_loss = 1.1205058454135277, disc_loss = 0.06237484457351101
Trained batch 179 in epoch 7, gen_loss = 1.121198304163085, disc_loss = 0.06212903117217745
Trained batch 180 in epoch 7, gen_loss = 1.1218365526331064, disc_loss = 0.06189058866037972
Trained batch 181 in epoch 7, gen_loss = 1.1233317193749186, disc_loss = 0.061642014215557046
Trained batch 182 in epoch 7, gen_loss = 1.1232149643324763, disc_loss = 0.061441175098902456
Trained batch 183 in epoch 7, gen_loss = 1.1218688478288443, disc_loss = 0.061210300569655374
Trained batch 184 in epoch 7, gen_loss = 1.1220578847704707, disc_loss = 0.060950698767713196
Trained batch 185 in epoch 7, gen_loss = 1.1243926514220495, disc_loss = 0.06075261254239107
Trained batch 186 in epoch 7, gen_loss = 1.1243043720403456, disc_loss = 0.060503696324303746
Trained batch 187 in epoch 7, gen_loss = 1.1258287826117048, disc_loss = 0.06027108286086351
Trained batch 188 in epoch 7, gen_loss = 1.1258881871031705, disc_loss = 0.06005271971496758
Trained batch 189 in epoch 7, gen_loss = 1.1276685529633572, disc_loss = 0.05987058015123598
Trained batch 190 in epoch 7, gen_loss = 1.1286531221804195, disc_loss = 0.05992425931251915
Trained batch 191 in epoch 7, gen_loss = 1.1287076904748876, disc_loss = 0.05987518591064145
Trained batch 192 in epoch 7, gen_loss = 1.1299297102374735, disc_loss = 0.05968131366127938
Trained batch 193 in epoch 7, gen_loss = 1.1320810351789612, disc_loss = 0.05949784463785166
Trained batch 194 in epoch 7, gen_loss = 1.1331407415561188, disc_loss = 0.05937977794151849
Trained batch 195 in epoch 7, gen_loss = 1.1347218049424035, disc_loss = 0.059156769514796606
Trained batch 196 in epoch 7, gen_loss = 1.1349335167613732, disc_loss = 0.05888676332182199
Trained batch 197 in epoch 7, gen_loss = 1.1366559835997494, disc_loss = 0.058660257855815946
Trained batch 198 in epoch 7, gen_loss = 1.1361482499831885, disc_loss = 0.05847549237587007
Trained batch 199 in epoch 7, gen_loss = 1.1373738947510719, disc_loss = 0.05823743380955421
Trained batch 200 in epoch 7, gen_loss = 1.1371689901423099, disc_loss = 0.057972499399923196
Trained batch 201 in epoch 7, gen_loss = 1.1389961688235255, disc_loss = 0.05773442947089045
Trained batch 202 in epoch 7, gen_loss = 1.1401486141341073, disc_loss = 0.05749501231392579
Trained batch 203 in epoch 7, gen_loss = 1.1398879707443947, disc_loss = 0.05724884361352808
Trained batch 204 in epoch 7, gen_loss = 1.1413703083992004, disc_loss = 0.056994604613495675
Trained batch 205 in epoch 7, gen_loss = 1.1419705554698278, disc_loss = 0.05674458417060414
Trained batch 206 in epoch 7, gen_loss = 1.142906759960064, disc_loss = 0.05651616205569303
Trained batch 207 in epoch 7, gen_loss = 1.1431266765754957, disc_loss = 0.056313768896730974
Trained batch 208 in epoch 7, gen_loss = 1.1431525081538698, disc_loss = 0.05611472172132341
Trained batch 209 in epoch 7, gen_loss = 1.1452388647056762, disc_loss = 0.05595535762674574
Trained batch 210 in epoch 7, gen_loss = 1.1459583165521305, disc_loss = 0.055737017807263825
Trained batch 211 in epoch 7, gen_loss = 1.1456622000572816, disc_loss = 0.05557318650216813
Trained batch 212 in epoch 7, gen_loss = 1.1461192187568952, disc_loss = 0.05538959545739205
Trained batch 213 in epoch 7, gen_loss = 1.1475568633770274, disc_loss = 0.05518625339245093
Trained batch 214 in epoch 7, gen_loss = 1.1481024384498597, disc_loss = 0.05496435357409334
Trained batch 215 in epoch 7, gen_loss = 1.147585938098254, disc_loss = 0.05475430356670619
Trained batch 216 in epoch 7, gen_loss = 1.1480950273676402, disc_loss = 0.05454262594632324
Trained batch 217 in epoch 7, gen_loss = 1.1481478681804937, disc_loss = 0.054384857549656766
Trained batch 218 in epoch 7, gen_loss = 1.1489062165016453, disc_loss = 0.054167235921855725
Trained batch 219 in epoch 7, gen_loss = 1.1500137218020179, disc_loss = 0.05395467210963199
Trained batch 220 in epoch 7, gen_loss = 1.1505526355488807, disc_loss = 0.05375449370268345
Trained batch 221 in epoch 7, gen_loss = 1.1507439100527548, disc_loss = 0.05355773815729966
Trained batch 222 in epoch 7, gen_loss = 1.151760062027405, disc_loss = 0.05333922886406593
Trained batch 223 in epoch 7, gen_loss = 1.1515473848474878, disc_loss = 0.053763302337236904
Trained batch 224 in epoch 7, gen_loss = 1.1508268046379089, disc_loss = 0.05393524169404473
Trained batch 225 in epoch 7, gen_loss = 1.1522890400570052, disc_loss = 0.054338032687783436
Trained batch 226 in epoch 7, gen_loss = 1.1521755669610616, disc_loss = 0.054352868113478045
Trained batch 227 in epoch 7, gen_loss = 1.1517394260879148, disc_loss = 0.05445337035231652
Trained batch 228 in epoch 7, gen_loss = 1.151917741027982, disc_loss = 0.05438899009195705
Trained batch 229 in epoch 7, gen_loss = 1.1525236562542294, disc_loss = 0.05421668565933309
Trained batch 230 in epoch 7, gen_loss = 1.1530901846431552, disc_loss = 0.05402872105758008
Trained batch 231 in epoch 7, gen_loss = 1.1541922074453583, disc_loss = 0.0538528653269168
Trained batch 232 in epoch 7, gen_loss = 1.1557977621647422, disc_loss = 0.05364334986289332
Trained batch 233 in epoch 7, gen_loss = 1.1565809996209593, disc_loss = 0.05344133363324257
Trained batch 234 in epoch 7, gen_loss = 1.155825890632386, disc_loss = 0.0533017434903044
Trained batch 235 in epoch 7, gen_loss = 1.1562685524508105, disc_loss = 0.05313881837577417
Trained batch 236 in epoch 7, gen_loss = 1.1568126464694863, disc_loss = 0.05294120942541095
Trained batch 237 in epoch 7, gen_loss = 1.1579514463909535, disc_loss = 0.05279015754095177
Trained batch 238 in epoch 7, gen_loss = 1.1588260182276928, disc_loss = 0.05260040069867907
Trained batch 239 in epoch 7, gen_loss = 1.1604654284814993, disc_loss = 0.0524449332083653
Trained batch 240 in epoch 7, gen_loss = 1.1604762633806442, disc_loss = 0.05231898942000051
Trained batch 241 in epoch 7, gen_loss = 1.1608130993429295, disc_loss = 0.05215757007014068
Trained batch 242 in epoch 7, gen_loss = 1.1608870777573606, disc_loss = 0.051981464163457725
Trained batch 243 in epoch 7, gen_loss = 1.1604148513469539, disc_loss = 0.0518062237705501
Trained batch 244 in epoch 7, gen_loss = 1.1621498485000765, disc_loss = 0.051650552646428045
Trained batch 245 in epoch 7, gen_loss = 1.161631899393671, disc_loss = 0.05147270078115862
Trained batch 246 in epoch 7, gen_loss = 1.1610543715809039, disc_loss = 0.051311388148960135
Trained batch 247 in epoch 7, gen_loss = 1.1618068475396401, disc_loss = 0.05121043216035281
Trained batch 248 in epoch 7, gen_loss = 1.1620327255812035, disc_loss = 0.05104992132966807
Trained batch 249 in epoch 7, gen_loss = 1.1629455382823943, disc_loss = 0.050871438507921994
Trained batch 250 in epoch 7, gen_loss = 1.1640912790697409, disc_loss = 0.05068470414753899
Trained batch 251 in epoch 7, gen_loss = 1.1643293436084474, disc_loss = 0.05050349634950094
Trained batch 252 in epoch 7, gen_loss = 1.1641493562181948, disc_loss = 0.05031892983426925
Trained batch 253 in epoch 7, gen_loss = 1.1644884645938873, disc_loss = 0.050139503599342515
Trained batch 254 in epoch 7, gen_loss = 1.164285110726076, disc_loss = 0.04996452766342783
Trained batch 255 in epoch 7, gen_loss = 1.1643381442409009, disc_loss = 0.04978207121257583
Trained batch 256 in epoch 7, gen_loss = 1.1640918962222593, disc_loss = 0.049607234986151064
Trained batch 257 in epoch 7, gen_loss = 1.163376350966535, disc_loss = 0.04943332059918939
Trained batch 258 in epoch 7, gen_loss = 1.1633078446719638, disc_loss = 0.049275353835881275
Trained batch 259 in epoch 7, gen_loss = 1.1629091778626808, disc_loss = 0.04910753433538887
Trained batch 260 in epoch 7, gen_loss = 1.1633768458476013, disc_loss = 0.048936674222385804
Trained batch 261 in epoch 7, gen_loss = 1.1634162648488546, disc_loss = 0.04876706290382266
Trained batch 262 in epoch 7, gen_loss = 1.1630477943801154, disc_loss = 0.0486199162703914
Trained batch 263 in epoch 7, gen_loss = 1.1631849735523716, disc_loss = 0.04844651402902056
Trained batch 264 in epoch 7, gen_loss = 1.1633280288498358, disc_loss = 0.048279649102708926
Trained batch 265 in epoch 7, gen_loss = 1.1641810238361359, disc_loss = 0.048112107137099076
Trained batch 266 in epoch 7, gen_loss = 1.1642987100819078, disc_loss = 0.047962174573843455
Trained batch 267 in epoch 7, gen_loss = 1.1653303835374207, disc_loss = 0.047788809711259525
Trained batch 268 in epoch 7, gen_loss = 1.164867455409805, disc_loss = 0.047619929754427984
Trained batch 269 in epoch 7, gen_loss = 1.1647233532534704, disc_loss = 0.047449993013180106
Trained batch 270 in epoch 7, gen_loss = 1.1647776275103383, disc_loss = 0.04728739423981466
Trained batch 271 in epoch 7, gen_loss = 1.1644990113289917, disc_loss = 0.04712585140719859
Trained batch 272 in epoch 7, gen_loss = 1.1653125214052724, disc_loss = 0.04697328852020518
Trained batch 273 in epoch 7, gen_loss = 1.1652410132606534, disc_loss = 0.04682091481339554
Trained batch 274 in epoch 7, gen_loss = 1.1649957958134738, disc_loss = 0.04666507931807163
Trained batch 275 in epoch 7, gen_loss = 1.1653108145447746, disc_loss = 0.04650914022552214
Trained batch 276 in epoch 7, gen_loss = 1.1657425520222109, disc_loss = 0.04635210082965436
Trained batch 277 in epoch 7, gen_loss = 1.16646758879689, disc_loss = 0.04622168839522202
Trained batch 278 in epoch 7, gen_loss = 1.1665519478073256, disc_loss = 0.046091394080433286
Trained batch 279 in epoch 7, gen_loss = 1.1671882146171162, disc_loss = 0.045951651452924125
Trained batch 280 in epoch 7, gen_loss = 1.1668850024399808, disc_loss = 0.04580587933040506
Trained batch 281 in epoch 7, gen_loss = 1.1675432373023202, disc_loss = 0.04565950325757912
Trained batch 282 in epoch 7, gen_loss = 1.1676908152263492, disc_loss = 0.04551441173271569
Trained batch 283 in epoch 7, gen_loss = 1.1679478969792245, disc_loss = 0.04537130568814333
Trained batch 284 in epoch 7, gen_loss = 1.1686617075351247, disc_loss = 0.045222427887564295
Trained batch 285 in epoch 7, gen_loss = 1.1695342907955597, disc_loss = 0.04507162602141278
Trained batch 286 in epoch 7, gen_loss = 1.169124078459856, disc_loss = 0.04493025850256392
Trained batch 287 in epoch 7, gen_loss = 1.169528889366322, disc_loss = 0.04479238975707429
Trained batch 288 in epoch 7, gen_loss = 1.1694808264092178, disc_loss = 0.04464409881711302
Trained batch 289 in epoch 7, gen_loss = 1.1694032588909413, disc_loss = 0.04449774011255017
Trained batch 290 in epoch 7, gen_loss = 1.1705611389117552, disc_loss = 0.04435687253685329
Trained batch 291 in epoch 7, gen_loss = 1.1701008765256569, disc_loss = 0.044219806357781236
Trained batch 292 in epoch 7, gen_loss = 1.1695142009966202, disc_loss = 0.044080532247712356
Trained batch 293 in epoch 7, gen_loss = 1.1702080330475657, disc_loss = 0.04393677622733992
Trained batch 294 in epoch 7, gen_loss = 1.170504981986547, disc_loss = 0.04379927082089865
Trained batch 295 in epoch 7, gen_loss = 1.1705124557421014, disc_loss = 0.04367706548883517
Trained batch 296 in epoch 7, gen_loss = 1.1707416441705492, disc_loss = 0.04353674304920879
Trained batch 297 in epoch 7, gen_loss = 1.1719393076112605, disc_loss = 0.04341313466250009
Trained batch 298 in epoch 7, gen_loss = 1.1719120069092333, disc_loss = 0.043274448489159796
Trained batch 299 in epoch 7, gen_loss = 1.1718664501110714, disc_loss = 0.043138117706403134
Trained batch 300 in epoch 7, gen_loss = 1.1719408183794877, disc_loss = 0.04300695575272473
Trained batch 301 in epoch 7, gen_loss = 1.1719120166554355, disc_loss = 0.04287346081179104
Trained batch 302 in epoch 7, gen_loss = 1.172305182851974, disc_loss = 0.042743827529073304
Trained batch 303 in epoch 7, gen_loss = 1.1718311958799237, disc_loss = 0.04263876705341605
Trained batch 304 in epoch 7, gen_loss = 1.1723348506161424, disc_loss = 0.04251414458878094
Trained batch 305 in epoch 7, gen_loss = 1.172241666932511, disc_loss = 0.042387753704508
Trained batch 306 in epoch 7, gen_loss = 1.1727004022085705, disc_loss = 0.0422746417277981
Trained batch 307 in epoch 7, gen_loss = 1.1720241641069387, disc_loss = 0.04214993793465947
Trained batch 308 in epoch 7, gen_loss = 1.1725495239677552, disc_loss = 0.04202412550102522
Trained batch 309 in epoch 7, gen_loss = 1.1724147412084764, disc_loss = 0.041896438974917176
Trained batch 310 in epoch 7, gen_loss = 1.1721013857237397, disc_loss = 0.0417668311463645
Trained batch 311 in epoch 7, gen_loss = 1.1720404900037324, disc_loss = 0.04163954552085414
Trained batch 312 in epoch 7, gen_loss = 1.171644415718298, disc_loss = 0.04151772299652009
Trained batch 313 in epoch 7, gen_loss = 1.172135094928134, disc_loss = 0.04139452738424906
Trained batch 314 in epoch 7, gen_loss = 1.17237942824288, disc_loss = 0.04126874437067835
Trained batch 315 in epoch 7, gen_loss = 1.1726432770867892, disc_loss = 0.04114384225811338
Trained batch 316 in epoch 7, gen_loss = 1.172319442691863, disc_loss = 0.041031004079508854
Trained batch 317 in epoch 7, gen_loss = 1.1724989084327746, disc_loss = 0.040906192434280994
Trained batch 318 in epoch 7, gen_loss = 1.1724233847800467, disc_loss = 0.040782747817587776
Trained batch 319 in epoch 7, gen_loss = 1.1723171014338731, disc_loss = 0.04066158920286398
Trained batch 320 in epoch 7, gen_loss = 1.1722987968230916, disc_loss = 0.0405406042417755
Trained batch 321 in epoch 7, gen_loss = 1.1717560259821993, disc_loss = 0.04041952057994659
Trained batch 322 in epoch 7, gen_loss = 1.17147431709449, disc_loss = 0.04030023026135938
Trained batch 323 in epoch 7, gen_loss = 1.1722293295610098, disc_loss = 0.040181600158878915
Trained batch 324 in epoch 7, gen_loss = 1.1723518101985637, disc_loss = 0.040061645791507686
Trained batch 325 in epoch 7, gen_loss = 1.1723418054770838, disc_loss = 0.039942523863443685
Trained batch 326 in epoch 7, gen_loss = 1.1723782230590096, disc_loss = 0.039824670260780654
Trained batch 327 in epoch 7, gen_loss = 1.1721413678875783, disc_loss = 0.039707596721510946
Trained batch 328 in epoch 7, gen_loss = 1.1728101064731284, disc_loss = 0.03959936485095034
Trained batch 329 in epoch 7, gen_loss = 1.1729926652980573, disc_loss = 0.0394861595391183
Trained batch 330 in epoch 7, gen_loss = 1.1731130963365837, disc_loss = 0.03937427246038523
Trained batch 331 in epoch 7, gen_loss = 1.1733485490801823, disc_loss = 0.03926802547795821
Trained batch 332 in epoch 7, gen_loss = 1.1732018675890055, disc_loss = 0.03915730884820279
Trained batch 333 in epoch 7, gen_loss = 1.1729775326337644, disc_loss = 0.03904665053946184
Trained batch 334 in epoch 7, gen_loss = 1.1727534075281514, disc_loss = 0.03893421066389767
Trained batch 335 in epoch 7, gen_loss = 1.1724466810978593, disc_loss = 0.03882315726306323
Trained batch 336 in epoch 7, gen_loss = 1.1730106593239555, disc_loss = 0.0387279421864188
Trained batch 337 in epoch 7, gen_loss = 1.1734159093284042, disc_loss = 0.03862182121722513
Trained batch 338 in epoch 7, gen_loss = 1.1732998374289116, disc_loss = 0.0385172571660676
Trained batch 339 in epoch 7, gen_loss = 1.1734146870234434, disc_loss = 0.03841258659787641
Trained batch 340 in epoch 7, gen_loss = 1.1732984653665872, disc_loss = 0.03830726409591789
Trained batch 341 in epoch 7, gen_loss = 1.173078240184059, disc_loss = 0.038203827693325886
Trained batch 342 in epoch 7, gen_loss = 1.1726789024411415, disc_loss = 0.03810411671810558
Trained batch 343 in epoch 7, gen_loss = 1.1729684969366982, disc_loss = 0.038000105638909806
Trained batch 344 in epoch 7, gen_loss = 1.173491474683734, disc_loss = 0.03789302607883524
Trained batch 345 in epoch 7, gen_loss = 1.1735443653743391, disc_loss = 0.037793908485230274
Trained batch 346 in epoch 7, gen_loss = 1.1735008537597547, disc_loss = 0.03768939147294051
Trained batch 347 in epoch 7, gen_loss = 1.1733815712832856, disc_loss = 0.03758705004844975
Trained batch 348 in epoch 7, gen_loss = 1.174340228808985, disc_loss = 0.037487897815457666
Trained batch 349 in epoch 7, gen_loss = 1.174589172261102, disc_loss = 0.03738494441012985
Trained batch 350 in epoch 7, gen_loss = 1.1742342189166621, disc_loss = 0.037285576081978015
Trained batch 351 in epoch 7, gen_loss = 1.1741641808978536, disc_loss = 0.03718299958993818
Trained batch 352 in epoch 7, gen_loss = 1.1745427875613357, disc_loss = 0.03708210418287074
Trained batch 353 in epoch 7, gen_loss = 1.1743018133828869, disc_loss = 0.036982949854382496
Trained batch 354 in epoch 7, gen_loss = 1.1741959006014004, disc_loss = 0.03688113298693436
Trained batch 355 in epoch 7, gen_loss = 1.1747470305541927, disc_loss = 0.036783374500332734
Trained batch 356 in epoch 7, gen_loss = 1.1751195821775442, disc_loss = 0.0366864599067723
Trained batch 357 in epoch 7, gen_loss = 1.1747846987993358, disc_loss = 0.03659082958494266
Trained batch 358 in epoch 7, gen_loss = 1.1745514552573308, disc_loss = 0.03649153881125842
Trained batch 359 in epoch 7, gen_loss = 1.1747331654032072, disc_loss = 0.03639472092731416
Trained batch 360 in epoch 7, gen_loss = 1.1745041726038397, disc_loss = 0.03629833090759509
Trained batch 361 in epoch 7, gen_loss = 1.175362869685526, disc_loss = 0.0362008869146622
Trained batch 362 in epoch 7, gen_loss = 1.175005698828001, disc_loss = 0.03610378292487991
Trained batch 363 in epoch 7, gen_loss = 1.1750235781892315, disc_loss = 0.036011055596415875
Trained batch 364 in epoch 7, gen_loss = 1.175446772412078, disc_loss = 0.03591510730616952
Trained batch 365 in epoch 7, gen_loss = 1.1756077087967773, disc_loss = 0.03582810948009964
Trained batch 366 in epoch 7, gen_loss = 1.1752722947084286, disc_loss = 0.03573872804025072
Trained batch 367 in epoch 7, gen_loss = 1.1746638954981514, disc_loss = 0.03566192997222179
Trained batch 368 in epoch 7, gen_loss = 1.174830899005983, disc_loss = 0.03557939480593918
Trained batch 369 in epoch 7, gen_loss = 1.1744687170595736, disc_loss = 0.03548915030031993
Trained batch 370 in epoch 7, gen_loss = 1.1746900884931621, disc_loss = 0.03540200663534698
Trained batch 371 in epoch 7, gen_loss = 1.1752374829143606, disc_loss = 0.035311338700158824
Trained batch 372 in epoch 7, gen_loss = 1.1753000005001037, disc_loss = 0.03521969619153402
Trained batch 373 in epoch 7, gen_loss = 1.174962324254653, disc_loss = 0.03513038383527873
Trained batch 374 in epoch 7, gen_loss = 1.1748280674616496, disc_loss = 0.035042291878412166
Trained batch 375 in epoch 7, gen_loss = 1.1744016697432131, disc_loss = 0.03495317879423965
Trained batch 376 in epoch 7, gen_loss = 1.1741125735427087, disc_loss = 0.034863554951623674
Trained batch 377 in epoch 7, gen_loss = 1.174204840231194, disc_loss = 0.03477770411015227
Trained batch 378 in epoch 7, gen_loss = 1.1744515905279598, disc_loss = 0.034691971748217074
Trained batch 379 in epoch 7, gen_loss = 1.1741428616799807, disc_loss = 0.03460349958714735
Trained batch 380 in epoch 7, gen_loss = 1.1740921138152676, disc_loss = 0.034516772100386596
Trained batch 381 in epoch 7, gen_loss = 1.173681347470009, disc_loss = 0.03443159865665235
Trained batch 382 in epoch 7, gen_loss = 1.1743070472313903, disc_loss = 0.03434595339852519
Trained batch 383 in epoch 7, gen_loss = 1.1744436202570796, disc_loss = 0.034258956688214916
Trained batch 384 in epoch 7, gen_loss = 1.174516429219927, disc_loss = 0.034174258536326566
Trained batch 385 in epoch 7, gen_loss = 1.1739195089574923, disc_loss = 0.03416961897993967
Trained batch 386 in epoch 7, gen_loss = 1.1735526860838406, disc_loss = 0.034135208625042
Trained batch 387 in epoch 7, gen_loss = 1.173185143734991, disc_loss = 0.034061321572096986
Trained batch 388 in epoch 7, gen_loss = 1.1736790868800833, disc_loss = 0.03398696958864884
Trained batch 389 in epoch 7, gen_loss = 1.1745879128957406, disc_loss = 0.03391048453661661
Trained batch 390 in epoch 7, gen_loss = 1.1751561864562656, disc_loss = 0.03384214902848667
Trained batch 391 in epoch 7, gen_loss = 1.1749867625078376, disc_loss = 0.03376167104683451
Trained batch 392 in epoch 7, gen_loss = 1.1746566266807283, disc_loss = 0.033683226268315505
Trained batch 393 in epoch 7, gen_loss = 1.1744322282106139, disc_loss = 0.03360402129391364
Trained batch 394 in epoch 7, gen_loss = 1.1744263101227677, disc_loss = 0.03352778619435274
Trained batch 395 in epoch 7, gen_loss = 1.1743530355619662, disc_loss = 0.03344835030815136
Trained batch 396 in epoch 7, gen_loss = 1.1741347896962682, disc_loss = 0.033373058546464704
Trained batch 397 in epoch 7, gen_loss = 1.174377424782844, disc_loss = 0.03329324903538165
Trained batch 398 in epoch 7, gen_loss = 1.1743573692806981, disc_loss = 0.03321347355286481
Trained batch 399 in epoch 7, gen_loss = 1.1749629299342632, disc_loss = 0.033142566985770824
Trained batch 400 in epoch 7, gen_loss = 1.1749691248237344, disc_loss = 0.03306364126493597
Trained batch 401 in epoch 7, gen_loss = 1.1750102800812887, disc_loss = 0.032990431579713715
Trained batch 402 in epoch 7, gen_loss = 1.1748586483392172, disc_loss = 0.032912455939268344
Trained batch 403 in epoch 7, gen_loss = 1.1750141557785545, disc_loss = 0.03283426475277203
Trained batch 404 in epoch 7, gen_loss = 1.1752937336026887, disc_loss = 0.03275704429769474
Trained batch 405 in epoch 7, gen_loss = 1.1754434356842134, disc_loss = 0.03268646121554403
Trained batch 406 in epoch 7, gen_loss = 1.1749157286100365, disc_loss = 0.032616576009815566
Trained batch 407 in epoch 7, gen_loss = 1.175023831719277, disc_loss = 0.032545753833284265
Trained batch 408 in epoch 7, gen_loss = 1.175773155281188, disc_loss = 0.032469453453342484
Trained batch 409 in epoch 7, gen_loss = 1.1759994464676555, disc_loss = 0.0323938022326485
Trained batch 410 in epoch 7, gen_loss = 1.1763603874366648, disc_loss = 0.0323178043775657
Trained batch 411 in epoch 7, gen_loss = 1.1759947001644708, disc_loss = 0.03224265951314575
Trained batch 412 in epoch 7, gen_loss = 1.1758154981361464, disc_loss = 0.032167850134834496
Trained batch 413 in epoch 7, gen_loss = 1.175566288728069, disc_loss = 0.03209289712401148
Trained batch 414 in epoch 7, gen_loss = 1.1751151023140873, disc_loss = 0.032018125559769975
Trained batch 415 in epoch 7, gen_loss = 1.1750104090628715, disc_loss = 0.03194341067431266
Trained batch 416 in epoch 7, gen_loss = 1.1751100475267826, disc_loss = 0.031868450921916626
Trained batch 417 in epoch 7, gen_loss = 1.1747828289937745, disc_loss = 0.03179587960300597
Trained batch 418 in epoch 7, gen_loss = 1.1755181071581875, disc_loss = 0.03172311666802234
Trained batch 419 in epoch 7, gen_loss = 1.1754446243955976, disc_loss = 0.031651205447131014
Trained batch 420 in epoch 7, gen_loss = 1.1751672517941854, disc_loss = 0.03157953893964349
Trained batch 421 in epoch 7, gen_loss = 1.1754343765324327, disc_loss = 0.03150845330219023
Trained batch 422 in epoch 7, gen_loss = 1.1757670983355095, disc_loss = 0.03143595304600476
Trained batch 423 in epoch 7, gen_loss = 1.17597483421834, disc_loss = 0.03136648459182635
Trained batch 424 in epoch 7, gen_loss = 1.1763086847697988, disc_loss = 0.031301116953905236
Trained batch 425 in epoch 7, gen_loss = 1.176237059730879, disc_loss = 0.03123004619043622
Trained batch 426 in epoch 7, gen_loss = 1.1766937151725734, disc_loss = 0.031167085542735062
Trained batch 427 in epoch 7, gen_loss = 1.17678224831541, disc_loss = 0.03109801776620677
Trained batch 428 in epoch 7, gen_loss = 1.176409794317259, disc_loss = 0.03103069323541093
Trained batch 429 in epoch 7, gen_loss = 1.1762770820495694, disc_loss = 0.030963436417352018
Trained batch 430 in epoch 7, gen_loss = 1.176091236332453, disc_loss = 0.030895760300025783
Trained batch 431 in epoch 7, gen_loss = 1.1760197134205588, disc_loss = 0.030829742275306705
Trained batch 432 in epoch 7, gen_loss = 1.1757825534558461, disc_loss = 0.030763551060354454
Trained batch 433 in epoch 7, gen_loss = 1.1759471521124862, disc_loss = 0.030695013299692757
Trained batch 434 in epoch 7, gen_loss = 1.176009467415426, disc_loss = 0.030629772323199772
Trained batch 435 in epoch 7, gen_loss = 1.1762408347578224, disc_loss = 0.030561557857596334
Trained batch 436 in epoch 7, gen_loss = 1.1759748334742792, disc_loss = 0.030494840525157826
Trained batch 437 in epoch 7, gen_loss = 1.175880977960482, disc_loss = 0.030426701191003692
Trained batch 438 in epoch 7, gen_loss = 1.1758137720049378, disc_loss = 0.030361914188746397
Trained batch 439 in epoch 7, gen_loss = 1.1755381273952397, disc_loss = 0.03030186207179213
Trained batch 440 in epoch 7, gen_loss = 1.1754665922145455, disc_loss = 0.030242041789619315
Trained batch 441 in epoch 7, gen_loss = 1.1757231701283433, disc_loss = 0.030178665349284203
Trained batch 442 in epoch 7, gen_loss = 1.1755547947323888, disc_loss = 0.03011508436984452
Trained batch 443 in epoch 7, gen_loss = 1.1758510630141508, disc_loss = 0.03004959063735048
Trained batch 444 in epoch 7, gen_loss = 1.1756434808956104, disc_loss = 0.029985168397431837
Trained batch 445 in epoch 7, gen_loss = 1.175690500324617, disc_loss = 0.029919848476788195
Trained batch 446 in epoch 7, gen_loss = 1.17563857768206, disc_loss = 0.029855677469553307
Trained batch 447 in epoch 7, gen_loss = 1.1762768856382795, disc_loss = 0.02979190356914582
Trained batch 448 in epoch 7, gen_loss = 1.1762302310801296, disc_loss = 0.029727782962977563
Trained batch 449 in epoch 7, gen_loss = 1.1760437511073218, disc_loss = 0.029663691533625955
Trained batch 450 in epoch 7, gen_loss = 1.1762737483777386, disc_loss = 0.029600816419009458
Trained batch 451 in epoch 7, gen_loss = 1.1761139817206205, disc_loss = 0.02953846464747464
Trained batch 452 in epoch 7, gen_loss = 1.1758347327346044, disc_loss = 0.029474756896041465
Trained batch 453 in epoch 7, gen_loss = 1.1759827524292312, disc_loss = 0.029413522771171947
Trained batch 454 in epoch 7, gen_loss = 1.1759846311349136, disc_loss = 0.029353126243094576
Trained batch 455 in epoch 7, gen_loss = 1.1758899656042718, disc_loss = 0.029292735797322455
Trained batch 456 in epoch 7, gen_loss = 1.1761124474475368, disc_loss = 0.02923076508321679
Trained batch 457 in epoch 7, gen_loss = 1.1758920556853432, disc_loss = 0.029171097968622644
Trained batch 458 in epoch 7, gen_loss = 1.176511987232175, disc_loss = 0.029109797510090192
Trained batch 459 in epoch 7, gen_loss = 1.1766109636296396, disc_loss = 0.029048277043772903
Trained batch 460 in epoch 7, gen_loss = 1.1766811796744836, disc_loss = 0.02898665289636984
Trained batch 461 in epoch 7, gen_loss = 1.177043189605077, disc_loss = 0.028925258356214047
Trained batch 462 in epoch 7, gen_loss = 1.1768877365934154, disc_loss = 0.028864904365539512
Trained batch 463 in epoch 7, gen_loss = 1.1769223998075928, disc_loss = 0.028806863266724797
Trained batch 464 in epoch 7, gen_loss = 1.1766273161416412, disc_loss = 0.028750169960536583
Trained batch 465 in epoch 7, gen_loss = 1.176521267885814, disc_loss = 0.02868955456184587
Trained batch 466 in epoch 7, gen_loss = 1.1765259804255956, disc_loss = 0.028629827095126847
Trained batch 467 in epoch 7, gen_loss = 1.1769788844717874, disc_loss = 0.028571603525082707
Trained batch 468 in epoch 7, gen_loss = 1.1770411375234884, disc_loss = 0.028512134776834938
Trained batch 469 in epoch 7, gen_loss = 1.176792036852938, disc_loss = 0.028453968859034926
Trained batch 470 in epoch 7, gen_loss = 1.1766784949160938, disc_loss = 0.0283947799214154
Trained batch 471 in epoch 7, gen_loss = 1.1771234732310651, disc_loss = 0.02833604726346478
Trained batch 472 in epoch 7, gen_loss = 1.1768887828066787, disc_loss = 0.028278462691173494
Trained batch 473 in epoch 7, gen_loss = 1.1765341033160939, disc_loss = 0.02822046706544821
Trained batch 474 in epoch 7, gen_loss = 1.176078614184731, disc_loss = 0.028162779737950155
Trained batch 475 in epoch 7, gen_loss = 1.1757246010443743, disc_loss = 0.028105728602635542
Trained batch 476 in epoch 7, gen_loss = 1.1764262097436677, disc_loss = 0.02804881750373658
Trained batch 477 in epoch 7, gen_loss = 1.1767422319954908, disc_loss = 0.027991726869087914
Trained batch 478 in epoch 7, gen_loss = 1.1766974868754505, disc_loss = 0.027936086911923935
Trained batch 479 in epoch 7, gen_loss = 1.1768263173600038, disc_loss = 0.02788072956148729
Trained batch 480 in epoch 7, gen_loss = 1.1764695956652478, disc_loss = 0.02782452703074101
Trained batch 481 in epoch 7, gen_loss = 1.1765216356491153, disc_loss = 0.027769495498319446
Trained batch 482 in epoch 7, gen_loss = 1.176479484723962, disc_loss = 0.02771324591612825
Trained batch 483 in epoch 7, gen_loss = 1.1760767307902171, disc_loss = 0.027658134491533072
Trained batch 484 in epoch 7, gen_loss = 1.1767038137642378, disc_loss = 0.027602689318867765
Trained batch 485 in epoch 7, gen_loss = 1.1764295639569868, disc_loss = 0.02754788499885074
Trained batch 486 in epoch 7, gen_loss = 1.1763816519929153, disc_loss = 0.02749495341220691
Trained batch 487 in epoch 7, gen_loss = 1.1759878940513877, disc_loss = 0.027441771057831337
Trained batch 488 in epoch 7, gen_loss = 1.1759774281447164, disc_loss = 0.02738898826533536
Trained batch 489 in epoch 7, gen_loss = 1.1764931784600627, disc_loss = 0.027338462713298064
Trained batch 490 in epoch 7, gen_loss = 1.1774347366237834, disc_loss = 0.02728455629324931
Trained batch 491 in epoch 7, gen_loss = 1.1773213476427202, disc_loss = 0.027231518425496024
Trained batch 492 in epoch 7, gen_loss = 1.1774269790968594, disc_loss = 0.027179164083959803
Trained batch 493 in epoch 7, gen_loss = 1.1775899813001456, disc_loss = 0.02712822518370827
Trained batch 494 in epoch 7, gen_loss = 1.1774507716448621, disc_loss = 0.02707498382689958
Trained batch 495 in epoch 7, gen_loss = 1.178440002303931, disc_loss = 0.027024421624387725
Trained batch 496 in epoch 7, gen_loss = 1.178285551382982, disc_loss = 0.026971834139491786
Trained batch 497 in epoch 7, gen_loss = 1.1780468276944984, disc_loss = 0.026919996958968406
Trained batch 498 in epoch 7, gen_loss = 1.17797460047181, disc_loss = 0.026868952039530304
Trained batch 499 in epoch 7, gen_loss = 1.1780114191770554, disc_loss = 0.026817586495541036
Trained batch 500 in epoch 7, gen_loss = 1.1780113963309877, disc_loss = 0.02676549335935166
Trained batch 501 in epoch 7, gen_loss = 1.1780858328380432, disc_loss = 0.026718680890865133
Trained batch 502 in epoch 7, gen_loss = 1.1783138863135048, disc_loss = 0.02666694265753253
Trained batch 503 in epoch 7, gen_loss = 1.178669034133828, disc_loss = 0.026616870879753684
Trained batch 504 in epoch 7, gen_loss = 1.1783599939676794, disc_loss = 0.02656519360987857
Trained batch 505 in epoch 7, gen_loss = 1.1787370779061976, disc_loss = 0.02651564615940594
Trained batch 506 in epoch 7, gen_loss = 1.1787139858014486, disc_loss = 0.026465392678413958
Trained batch 507 in epoch 7, gen_loss = 1.1789308435569599, disc_loss = 0.026416130471648282
Trained batch 508 in epoch 7, gen_loss = 1.1785815976457652, disc_loss = 0.02636633998136199
Trained batch 509 in epoch 7, gen_loss = 1.1787448954348472, disc_loss = 0.026317102239951127
Trained batch 510 in epoch 7, gen_loss = 1.1784471421559028, disc_loss = 0.026267685436045865
Trained batch 511 in epoch 7, gen_loss = 1.1786193089792505, disc_loss = 0.026217970907396193
Trained batch 512 in epoch 7, gen_loss = 1.1788539037137469, disc_loss = 0.02617044963492226
Trained batch 513 in epoch 7, gen_loss = 1.1784349277557566, disc_loss = 0.026121875521131693
Trained batch 514 in epoch 7, gen_loss = 1.1784855251173372, disc_loss = 0.026073011216929055
Trained batch 515 in epoch 7, gen_loss = 1.1787356975697731, disc_loss = 0.026026010078665902
Trained batch 516 in epoch 7, gen_loss = 1.1787558363991963, disc_loss = 0.025976822053116515
Trained batch 517 in epoch 7, gen_loss = 1.1785869038012957, disc_loss = 0.025928075142941008
Trained batch 518 in epoch 7, gen_loss = 1.1784179273827686, disc_loss = 0.025878988202292962
Trained batch 519 in epoch 7, gen_loss = 1.1785956844687462, disc_loss = 0.025831504346737907
Trained batch 520 in epoch 7, gen_loss = 1.1787452385430144, disc_loss = 0.02578389096593765
Trained batch 521 in epoch 7, gen_loss = 1.1786661631074444, disc_loss = 0.025735195123617736
Trained batch 522 in epoch 7, gen_loss = 1.1784289091768503, disc_loss = 0.02568744873165253
Trained batch 523 in epoch 7, gen_loss = 1.1788701202350718, disc_loss = 0.025640671197487173
Trained batch 524 in epoch 7, gen_loss = 1.178716345173972, disc_loss = 0.025596708331223843
Trained batch 525 in epoch 7, gen_loss = 1.1782968639194284, disc_loss = 0.0255513787062103
Trained batch 526 in epoch 7, gen_loss = 1.1783925515424594, disc_loss = 0.025505939258478556
Trained batch 527 in epoch 7, gen_loss = 1.1784248700873419, disc_loss = 0.025459313415205652
Trained batch 528 in epoch 7, gen_loss = 1.1787910773533279, disc_loss = 0.025413534340538026
Trained batch 529 in epoch 7, gen_loss = 1.1784506142139435, disc_loss = 0.025367976758213943
Trained batch 530 in epoch 7, gen_loss = 1.1783103454584456, disc_loss = 0.025321804191081886
Trained batch 531 in epoch 7, gen_loss = 1.1781043933522433, disc_loss = 0.025275773844886062
Trained batch 532 in epoch 7, gen_loss = 1.178123777959405, disc_loss = 0.025229924874269713
Trained batch 533 in epoch 7, gen_loss = 1.1779889048038796, disc_loss = 0.02518446864051202
Trained batch 534 in epoch 7, gen_loss = 1.1777748331845364, disc_loss = 0.025138555134692292
Trained batch 535 in epoch 7, gen_loss = 1.177969688021425, disc_loss = 0.02509387434550792
Trained batch 536 in epoch 7, gen_loss = 1.1777801519221656, disc_loss = 0.025050124904070156
Trained batch 537 in epoch 7, gen_loss = 1.1780408739378905, disc_loss = 0.025004618672481358
Trained batch 538 in epoch 7, gen_loss = 1.1780058292599467, disc_loss = 0.02495959945491097
Trained batch 539 in epoch 7, gen_loss = 1.1780803191441076, disc_loss = 0.024914359032441602
Trained batch 540 in epoch 7, gen_loss = 1.1780813157888965, disc_loss = 0.02486943537391965
Trained batch 541 in epoch 7, gen_loss = 1.1782471611271046, disc_loss = 0.024825031510900063
Trained batch 542 in epoch 7, gen_loss = 1.17790492342761, disc_loss = 0.024780470118238324
Trained batch 543 in epoch 7, gen_loss = 1.1780227241928087, disc_loss = 0.024736073963407868
Trained batch 544 in epoch 7, gen_loss = 1.1779298825001498, disc_loss = 0.02469243428038664
Trained batch 545 in epoch 7, gen_loss = 1.178071875602771, disc_loss = 0.024649071133017092
Trained batch 546 in epoch 7, gen_loss = 1.178157906972512, disc_loss = 0.02460508920962946
Trained batch 547 in epoch 7, gen_loss = 1.178333884499369, disc_loss = 0.0245611445476827
Trained batch 548 in epoch 7, gen_loss = 1.1785080555575358, disc_loss = 0.024517537134464997
Trained batch 549 in epoch 7, gen_loss = 1.1788495881990952, disc_loss = 0.02447543470988008
Trained batch 550 in epoch 7, gen_loss = 1.17867445069519, disc_loss = 0.024432109406810783
Trained batch 551 in epoch 7, gen_loss = 1.1783798011964646, disc_loss = 0.02438935823838751
Trained batch 552 in epoch 7, gen_loss = 1.178234408712301, disc_loss = 0.024351264112812146
Trained batch 553 in epoch 7, gen_loss = 1.1783090998764933, disc_loss = 0.024308248682085018
Trained batch 554 in epoch 7, gen_loss = 1.1782926970773988, disc_loss = 0.024265454130756946
Trained batch 555 in epoch 7, gen_loss = 1.1784637007567522, disc_loss = 0.024223374395948256
Trained batch 556 in epoch 7, gen_loss = 1.178506765909212, disc_loss = 0.024181239637101063
Trained batch 557 in epoch 7, gen_loss = 1.1787229019040275, disc_loss = 0.024142860239619927
Trained batch 558 in epoch 7, gen_loss = 1.1786707570386488, disc_loss = 0.024101870916423525
Trained batch 559 in epoch 7, gen_loss = 1.1784241509224687, disc_loss = 0.024060130387338827
Trained batch 560 in epoch 7, gen_loss = 1.1782465048014799, disc_loss = 0.024018763391097257
Trained batch 561 in epoch 7, gen_loss = 1.1780438080589117, disc_loss = 0.023977504137771295
Trained batch 562 in epoch 7, gen_loss = 1.1783509109414068, disc_loss = 0.02393744169755303
Trained batch 563 in epoch 7, gen_loss = 1.1782805569839816, disc_loss = 0.023899838224588812
Trained batch 564 in epoch 7, gen_loss = 1.1779800306379267, disc_loss = 0.0238591769383087
Trained batch 565 in epoch 7, gen_loss = 1.1777207117409252, disc_loss = 0.023819312709393952
Trained batch 566 in epoch 7, gen_loss = 1.1777610243733387, disc_loss = 0.023779004273640082
Trained batch 567 in epoch 7, gen_loss = 1.1776468246965341, disc_loss = 0.023738701394494726
Trained batch 568 in epoch 7, gen_loss = 1.1772157897639148, disc_loss = 0.023698478721760244
Trained batch 569 in epoch 7, gen_loss = 1.1773924897637285, disc_loss = 0.023657790367060602
Trained batch 570 in epoch 7, gen_loss = 1.177551383625605, disc_loss = 0.02361702073802568
Trained batch 571 in epoch 7, gen_loss = 1.1775595840665845, disc_loss = 0.02357665657442734
Trained batch 572 in epoch 7, gen_loss = 1.177504171979781, disc_loss = 0.02353643786660306
Trained batch 573 in epoch 7, gen_loss = 1.1773834561844736, disc_loss = 0.023496677311508875
Trained batch 574 in epoch 7, gen_loss = 1.1778194042910701, disc_loss = 0.023456696784933624
Trained batch 575 in epoch 7, gen_loss = 1.1778805598409638, disc_loss = 0.023417500227878918
Trained batch 576 in epoch 7, gen_loss = 1.1779240469998669, disc_loss = 0.023377648814810532
Trained batch 577 in epoch 7, gen_loss = 1.1777155377666844, disc_loss = 0.023338077933677377
Trained batch 578 in epoch 7, gen_loss = 1.177484353280438, disc_loss = 0.023299200645493526
Trained batch 579 in epoch 7, gen_loss = 1.1775195605795958, disc_loss = 0.023260456227279944
Trained batch 580 in epoch 7, gen_loss = 1.177119331392692, disc_loss = 0.023221699046968882
Trained batch 581 in epoch 7, gen_loss = 1.1766537161627175, disc_loss = 0.023184302431083992
Trained batch 582 in epoch 7, gen_loss = 1.1767371727303821, disc_loss = 0.02314596332074103
Trained batch 583 in epoch 7, gen_loss = 1.1764224287990022, disc_loss = 0.02310749905712963
Trained batch 584 in epoch 7, gen_loss = 1.1762694138746994, disc_loss = 0.023069989673980378
Trained batch 585 in epoch 7, gen_loss = 1.176340173942644, disc_loss = 0.023031861643480145
Trained batch 586 in epoch 7, gen_loss = 1.176007369510969, disc_loss = 0.02299406680316558
Trained batch 587 in epoch 7, gen_loss = 1.1760764468689353, disc_loss = 0.022955630829850398
Trained batch 588 in epoch 7, gen_loss = 1.1759941822806521, disc_loss = 0.022918579706173874
Trained batch 589 in epoch 7, gen_loss = 1.1755648555391927, disc_loss = 0.022881358902915223
Trained batch 590 in epoch 7, gen_loss = 1.1757060943924635, disc_loss = 0.02284780536322656
Trained batch 591 in epoch 7, gen_loss = 1.1760049284108587, disc_loss = 0.022810819785484677
Trained batch 592 in epoch 7, gen_loss = 1.1758363143388577, disc_loss = 0.022775413054597137
Trained batch 593 in epoch 7, gen_loss = 1.1756123072571225, disc_loss = 0.022739034731821817
Trained batch 594 in epoch 7, gen_loss = 1.1755323677503762, disc_loss = 0.02270271589548108
Trained batch 595 in epoch 7, gen_loss = 1.1754385465943573, disc_loss = 0.0226665517541751
Trained batch 596 in epoch 7, gen_loss = 1.1754262913611266, disc_loss = 0.02262993278682904
Trained batch 597 in epoch 7, gen_loss = 1.1751876418606493, disc_loss = 0.022592871172963346
Trained batch 598 in epoch 7, gen_loss = 1.1750398853386383, disc_loss = 0.022556849149268008
Trained batch 599 in epoch 7, gen_loss = 1.1749593515197436, disc_loss = 0.022520652155217247
Trained batch 600 in epoch 7, gen_loss = 1.1755018963194925, disc_loss = 0.02248421532809719
Trained batch 601 in epoch 7, gen_loss = 1.1754758982761357, disc_loss = 0.022447788037446348
Trained batch 602 in epoch 7, gen_loss = 1.1755191436652126, disc_loss = 0.022411465611340473
Trained batch 603 in epoch 7, gen_loss = 1.1754429138062017, disc_loss = 0.022375194230853174
Trained batch 604 in epoch 7, gen_loss = 1.1753819913903545, disc_loss = 0.022339317537863425
Trained batch 605 in epoch 7, gen_loss = 1.1755841412756702, disc_loss = 0.022303513964048737
Trained batch 606 in epoch 7, gen_loss = 1.175434315126064, disc_loss = 0.022267776471505147
Trained batch 607 in epoch 7, gen_loss = 1.1754323862689107, disc_loss = 0.022237125960217735
Trained batch 608 in epoch 7, gen_loss = 1.1752357000396365, disc_loss = 0.022201783423295186
Trained batch 609 in epoch 7, gen_loss = 1.175334941266013, disc_loss = 0.022166194609122076
Trained batch 610 in epoch 7, gen_loss = 1.175457297975225, disc_loss = 0.02213077208950564
Trained batch 611 in epoch 7, gen_loss = 1.1753418105684854, disc_loss = 0.02209521748172728
Trained batch 612 in epoch 7, gen_loss = 1.1755987727622612, disc_loss = 0.022060320312104097
Trained batch 613 in epoch 7, gen_loss = 1.1752773693213634, disc_loss = 0.022026219960197456
Trained batch 614 in epoch 7, gen_loss = 1.1751159225052934, disc_loss = 0.02199213516546368
Trained batch 615 in epoch 7, gen_loss = 1.1749157397584482, disc_loss = 0.021957683338603765
Trained batch 616 in epoch 7, gen_loss = 1.1749249276504332, disc_loss = 0.021923036319358394
Trained batch 617 in epoch 7, gen_loss = 1.1751080866191765, disc_loss = 0.021889740217934456
Trained batch 618 in epoch 7, gen_loss = 1.175022752778018, disc_loss = 0.02185569826078335
Trained batch 619 in epoch 7, gen_loss = 1.1752104287185976, disc_loss = 0.021822182304740343
Trained batch 620 in epoch 7, gen_loss = 1.1751821141887977, disc_loss = 0.021788115667714623
Trained batch 621 in epoch 7, gen_loss = 1.174857828778086, disc_loss = 0.02175787314671538
Trained batch 622 in epoch 7, gen_loss = 1.174730840885046, disc_loss = 0.021723965337529128
Trained batch 623 in epoch 7, gen_loss = 1.174552587744517, disc_loss = 0.021690321926330514
Trained batch 624 in epoch 7, gen_loss = 1.1746152194976807, disc_loss = 0.021657909366488457
Trained batch 625 in epoch 7, gen_loss = 1.1744100291508075, disc_loss = 0.02162560781563659
Trained batch 626 in epoch 7, gen_loss = 1.174379736422732, disc_loss = 0.021591925903325947
Trained batch 627 in epoch 7, gen_loss = 1.174501440517462, disc_loss = 0.02155909479160461
Trained batch 628 in epoch 7, gen_loss = 1.1742834212859599, disc_loss = 0.02152592652893384
Trained batch 629 in epoch 7, gen_loss = 1.1741903511304703, disc_loss = 0.021492583515484713
Trained batch 630 in epoch 7, gen_loss = 1.174133983164695, disc_loss = 0.021459283308670658
Trained batch 631 in epoch 7, gen_loss = 1.174269264446029, disc_loss = 0.021428087586242282
Trained batch 632 in epoch 7, gen_loss = 1.1740712716492807, disc_loss = 0.021395714185255803
Trained batch 633 in epoch 7, gen_loss = 1.1741357667589036, disc_loss = 0.02136366551568253
Trained batch 634 in epoch 7, gen_loss = 1.173966680173799, disc_loss = 0.021330935895116632
Trained batch 635 in epoch 7, gen_loss = 1.1741875631254424, disc_loss = 0.021299906208530603
Trained batch 636 in epoch 7, gen_loss = 1.174270397452769, disc_loss = 0.02126743619758241
Trained batch 637 in epoch 7, gen_loss = 1.1743717145022927, disc_loss = 0.02123458379492577
Trained batch 638 in epoch 7, gen_loss = 1.1743984220546548, disc_loss = 0.021202272497012217
Trained batch 639 in epoch 7, gen_loss = 1.1744128476828337, disc_loss = 0.021170379221575785
Trained batch 640 in epoch 7, gen_loss = 1.1745552644714736, disc_loss = 0.021138599767778637
Trained batch 641 in epoch 7, gen_loss = 1.174492016759617, disc_loss = 0.021106570010950045
Trained batch 642 in epoch 7, gen_loss = 1.1745412388633978, disc_loss = 0.021074827631233365
Trained batch 643 in epoch 7, gen_loss = 1.1741841494666865, disc_loss = 0.021043889188059092
Trained batch 644 in epoch 7, gen_loss = 1.17409349097762, disc_loss = 0.021012783465345658
Trained batch 645 in epoch 7, gen_loss = 1.1741057846568317, disc_loss = 0.020980905900172667
Trained batch 646 in epoch 7, gen_loss = 1.174248281181135, disc_loss = 0.020949612843537403
Trained batch 647 in epoch 7, gen_loss = 1.1742852734930722, disc_loss = 0.02091852175987169
Trained batch 648 in epoch 7, gen_loss = 1.1743306913434632, disc_loss = 0.02088742044219605
Trained batch 649 in epoch 7, gen_loss = 1.1743823216511653, disc_loss = 0.020856374084474875
Trained batch 650 in epoch 7, gen_loss = 1.1744929220636136, disc_loss = 0.02082510034319624
Trained batch 651 in epoch 7, gen_loss = 1.1742491109605215, disc_loss = 0.020795140777129975
Trained batch 652 in epoch 7, gen_loss = 1.1739405468448563, disc_loss = 0.020764696298448432
Trained batch 653 in epoch 7, gen_loss = 1.1737235788176184, disc_loss = 0.02073380137375942
Trained batch 654 in epoch 7, gen_loss = 1.1739039801459277, disc_loss = 0.020704190581477114
Trained batch 655 in epoch 7, gen_loss = 1.1736876379425933, disc_loss = 0.02067359301735251
Trained batch 656 in epoch 7, gen_loss = 1.173934414325058, disc_loss = 0.020645225796817705
Trained batch 657 in epoch 7, gen_loss = 1.1740337476179592, disc_loss = 0.020615188809938654
Trained batch 658 in epoch 7, gen_loss = 1.1747858061233312, disc_loss = 0.020585609681606477
Trained batch 659 in epoch 7, gen_loss = 1.1745797975496812, disc_loss = 0.020555622321615265
Trained batch 660 in epoch 7, gen_loss = 1.1742163160745387, disc_loss = 0.020527248562772583
Trained batch 661 in epoch 7, gen_loss = 1.1742150580054684, disc_loss = 0.02049732005874819
Trained batch 662 in epoch 7, gen_loss = 1.1742905340583076, disc_loss = 0.020468602075968796
Trained batch 663 in epoch 7, gen_loss = 1.1740211962935436, disc_loss = 0.02044021986078307
Trained batch 664 in epoch 7, gen_loss = 1.1743431500026158, disc_loss = 0.020410475891242785
Trained batch 665 in epoch 7, gen_loss = 1.1741615506979797, disc_loss = 0.02038244543559171
Trained batch 666 in epoch 7, gen_loss = 1.1739438093048165, disc_loss = 0.020352924988275907
Trained batch 667 in epoch 7, gen_loss = 1.1738496374584244, disc_loss = 0.020323315424495027
Trained batch 668 in epoch 7, gen_loss = 1.173726713532646, disc_loss = 0.020293898531018238
Trained batch 669 in epoch 7, gen_loss = 1.1735780235546738, disc_loss = 0.020264430597221213
Trained batch 670 in epoch 7, gen_loss = 1.1734667291584384, disc_loss = 0.020234987867731345
Trained batch 671 in epoch 7, gen_loss = 1.1734843325047266, disc_loss = 0.020205707925968108
Trained batch 672 in epoch 7, gen_loss = 1.1735642175972019, disc_loss = 0.020176249599618074
Trained batch 673 in epoch 7, gen_loss = 1.1737746541507166, disc_loss = 0.020148455728878658
Trained batch 674 in epoch 7, gen_loss = 1.1736749267578126, disc_loss = 0.0201203424055388
Trained batch 675 in epoch 7, gen_loss = 1.1733960306503364, disc_loss = 0.020092363462026697
Trained batch 676 in epoch 7, gen_loss = 1.1731940937535272, disc_loss = 0.020063720517690353
Trained batch 677 in epoch 7, gen_loss = 1.173315356790492, disc_loss = 0.020034925899906894
Trained batch 678 in epoch 7, gen_loss = 1.1733686046150893, disc_loss = 0.020006067523263348
Trained batch 679 in epoch 7, gen_loss = 1.1734899184283087, disc_loss = 0.019977468180406827
Trained batch 680 in epoch 7, gen_loss = 1.1735373066735513, disc_loss = 0.019948739680899552
Trained batch 681 in epoch 7, gen_loss = 1.1737659550831814, disc_loss = 0.019920091841056125
Trained batch 682 in epoch 7, gen_loss = 1.1735278191713079, disc_loss = 0.01989159744396011
Trained batch 683 in epoch 7, gen_loss = 1.1736664165530288, disc_loss = 0.019863219871429104
Trained batch 684 in epoch 7, gen_loss = 1.1737333899866926, disc_loss = 0.019835177859942342
Trained batch 685 in epoch 7, gen_loss = 1.1737428743707194, disc_loss = 0.019806997952994662
Trained batch 686 in epoch 7, gen_loss = 1.173841922390756, disc_loss = 0.019778737147119075
Trained batch 687 in epoch 7, gen_loss = 1.1737128582804701, disc_loss = 0.019750989489440082
Trained batch 688 in epoch 7, gen_loss = 1.173565745180681, disc_loss = 0.019723095242589635
Trained batch 689 in epoch 7, gen_loss = 1.1732478270496147, disc_loss = 0.01969544298962042
Trained batch 690 in epoch 7, gen_loss = 1.1730245954738512, disc_loss = 0.019668050342244156
Trained batch 691 in epoch 7, gen_loss = 1.1731473902574163, disc_loss = 0.019640352717527416
Trained batch 692 in epoch 7, gen_loss = 1.1732395637086976, disc_loss = 0.019612997645998716
Trained batch 693 in epoch 7, gen_loss = 1.1729751217262203, disc_loss = 0.019587553646388634
Trained batch 694 in epoch 7, gen_loss = 1.1726989797550997, disc_loss = 0.01956533237072311
Trained batch 695 in epoch 7, gen_loss = 1.1727611676029774, disc_loss = 0.01953951823565274
Trained batch 696 in epoch 7, gen_loss = 1.1728306435786156, disc_loss = 0.019513463225667306
Trained batch 697 in epoch 7, gen_loss = 1.1728245433217133, disc_loss = 0.019487217197262742
Trained batch 698 in epoch 7, gen_loss = 1.1727307920633296, disc_loss = 0.019460801636728222
Trained batch 699 in epoch 7, gen_loss = 1.1724830407755715, disc_loss = 0.019433848906108844
Trained batch 700 in epoch 7, gen_loss = 1.1723503029125393, disc_loss = 0.01940834321900033
Trained batch 701 in epoch 7, gen_loss = 1.1725476316237382, disc_loss = 0.019382007942605296
Trained batch 702 in epoch 7, gen_loss = 1.1728034099169171, disc_loss = 0.019356310264085543
Trained batch 703 in epoch 7, gen_loss = 1.1729564121501013, disc_loss = 0.019329703405839446
Trained batch 704 in epoch 7, gen_loss = 1.1727590932913705, disc_loss = 0.019303327059317116
Trained batch 705 in epoch 7, gen_loss = 1.1726694152645618, disc_loss = 0.019277090850571783
Trained batch 706 in epoch 7, gen_loss = 1.1725200396110178, disc_loss = 0.01925158072791564
Trained batch 707 in epoch 7, gen_loss = 1.1725937974991771, disc_loss = 0.01922521610258576
Trained batch 708 in epoch 7, gen_loss = 1.1724961748916776, disc_loss = 0.019199488964572166
Trained batch 709 in epoch 7, gen_loss = 1.1724153102283748, disc_loss = 0.0191735790382487
Trained batch 710 in epoch 7, gen_loss = 1.172243750548061, disc_loss = 0.019147218462957707
Trained batch 711 in epoch 7, gen_loss = 1.1723251508527928, disc_loss = 0.019121089201720412
Trained batch 712 in epoch 7, gen_loss = 1.1723348091227141, disc_loss = 0.019094995390302155
Trained batch 713 in epoch 7, gen_loss = 1.1724114210999645, disc_loss = 0.019069037696401097
Trained batch 714 in epoch 7, gen_loss = 1.1725826858640551, disc_loss = 0.019043648280032383
Trained batch 715 in epoch 7, gen_loss = 1.1724946418954008, disc_loss = 0.019018579323803058
Trained batch 716 in epoch 7, gen_loss = 1.1726851898922248, disc_loss = 0.018993172341055915
Trained batch 717 in epoch 7, gen_loss = 1.172545497131879, disc_loss = 0.0189672225323317
Trained batch 718 in epoch 7, gen_loss = 1.1723863854693437, disc_loss = 0.018941259232111034
Trained batch 719 in epoch 7, gen_loss = 1.172316050860617, disc_loss = 0.018915806546566376
Trained batch 720 in epoch 7, gen_loss = 1.1725158547561476, disc_loss = 0.018891082287159904
Trained batch 721 in epoch 7, gen_loss = 1.172403515706102, disc_loss = 0.018866249985070294
Trained batch 722 in epoch 7, gen_loss = 1.1728261649855933, disc_loss = 0.018841445376495295
Trained batch 723 in epoch 7, gen_loss = 1.1726699789255364, disc_loss = 0.01881705135743305
Trained batch 724 in epoch 7, gen_loss = 1.172885368445824, disc_loss = 0.01879168453377447
Trained batch 725 in epoch 7, gen_loss = 1.1726236106114611, disc_loss = 0.018766568263222337
Trained batch 726 in epoch 7, gen_loss = 1.172774917239828, disc_loss = 0.018741352413012356
Trained batch 727 in epoch 7, gen_loss = 1.1728172124578402, disc_loss = 0.01871626155116246
Trained batch 728 in epoch 7, gen_loss = 1.1726431020002797, disc_loss = 0.01869099338514033
Trained batch 729 in epoch 7, gen_loss = 1.1726311104754878, disc_loss = 0.01866717471610372
Trained batch 730 in epoch 7, gen_loss = 1.17269105697624, disc_loss = 0.018642842784274253
Trained batch 731 in epoch 7, gen_loss = 1.1726690870328027, disc_loss = 0.018618113341419374
Trained batch 732 in epoch 7, gen_loss = 1.1725602391471968, disc_loss = 0.018593114266003068
Trained batch 733 in epoch 7, gen_loss = 1.1724218330688632, disc_loss = 0.01856879966848337
Trained batch 734 in epoch 7, gen_loss = 1.1722083639125436, disc_loss = 0.01854409084569815
Trained batch 735 in epoch 7, gen_loss = 1.1721462250241768, disc_loss = 0.018519604247083644
Trained batch 736 in epoch 7, gen_loss = 1.1719116057437342, disc_loss = 0.018495641718981878
Trained batch 737 in epoch 7, gen_loss = 1.1716893241819004, disc_loss = 0.01847250833922838
Trained batch 738 in epoch 7, gen_loss = 1.1714907682151692, disc_loss = 0.018448298257231807
Trained batch 739 in epoch 7, gen_loss = 1.1714874443975656, disc_loss = 0.018424899707866104
Trained batch 740 in epoch 7, gen_loss = 1.1714567891177539, disc_loss = 0.01840121671133241
Trained batch 741 in epoch 7, gen_loss = 1.1717958422201984, disc_loss = 0.018377030573313368
Trained batch 742 in epoch 7, gen_loss = 1.171687996804634, disc_loss = 0.018352858640108143
Trained batch 743 in epoch 7, gen_loss = 1.1716220363654115, disc_loss = 0.018329275170887536
Trained batch 744 in epoch 7, gen_loss = 1.1717984584353913, disc_loss = 0.018305270404526775
Trained batch 745 in epoch 7, gen_loss = 1.172245863056055, disc_loss = 0.01828143465101417
Trained batch 746 in epoch 7, gen_loss = 1.171988422931278, disc_loss = 0.018257967877676126
Trained batch 747 in epoch 7, gen_loss = 1.1719060514699966, disc_loss = 0.018234148303284632
Trained batch 748 in epoch 7, gen_loss = 1.1717472509325586, disc_loss = 0.018210676457211923
Trained batch 749 in epoch 7, gen_loss = 1.1718280091285707, disc_loss = 0.018187066865231222
Trained batch 750 in epoch 7, gen_loss = 1.1718178416060385, disc_loss = 0.018163672207046136
Trained batch 751 in epoch 7, gen_loss = 1.1717506639183837, disc_loss = 0.018139914356884508
Trained batch 752 in epoch 7, gen_loss = 1.1715935023815667, disc_loss = 0.018116569138513283
Trained batch 753 in epoch 7, gen_loss = 1.1712312797968836, disc_loss = 0.018093381598102365
Trained batch 754 in epoch 7, gen_loss = 1.1710017516913003, disc_loss = 0.01807061195969489
Trained batch 755 in epoch 7, gen_loss = 1.171214968123764, disc_loss = 0.018048044761974504
Trained batch 756 in epoch 7, gen_loss = 1.17126227275541, disc_loss = 0.018024876137173955
Trained batch 757 in epoch 7, gen_loss = 1.1711188988824004, disc_loss = 0.01800306019628031
Trained batch 758 in epoch 7, gen_loss = 1.1709998714122847, disc_loss = 0.017981788318176914
Trained batch 759 in epoch 7, gen_loss = 1.1706579346405832, disc_loss = 0.017960640343057763
Trained batch 760 in epoch 7, gen_loss = 1.1706112225328262, disc_loss = 0.01793874661833918
Trained batch 761 in epoch 7, gen_loss = 1.1704683249078085, disc_loss = 0.017916965842657364
Trained batch 762 in epoch 7, gen_loss = 1.1701608715019876, disc_loss = 0.017894263903793194
Trained batch 763 in epoch 7, gen_loss = 1.1702463480190457, disc_loss = 0.017872654911335155
Trained batch 764 in epoch 7, gen_loss = 1.170308997272666, disc_loss = 0.01785047675883915
Trained batch 765 in epoch 7, gen_loss = 1.1704431053241302, disc_loss = 0.017828711648324235
Trained batch 766 in epoch 7, gen_loss = 1.1703484207586017, disc_loss = 0.017806866714046937
Trained batch 767 in epoch 7, gen_loss = 1.1702649450550477, disc_loss = 0.017784211748486694
Trained batch 768 in epoch 7, gen_loss = 1.1703082395933075, disc_loss = 0.017761790381524388
Trained batch 769 in epoch 7, gen_loss = 1.1702860914267503, disc_loss = 0.01774012422050779
Trained batch 770 in epoch 7, gen_loss = 1.1703400056804356, disc_loss = 0.01771897755400338
Trained batch 771 in epoch 7, gen_loss = 1.1702814891239521, disc_loss = 0.017697940823367803
Trained batch 772 in epoch 7, gen_loss = 1.1699940054876221, disc_loss = 0.017676079749705916
Trained batch 773 in epoch 7, gen_loss = 1.1700427697764502, disc_loss = 0.017653782385467907
Trained batch 774 in epoch 7, gen_loss = 1.1700770394263729, disc_loss = 0.01763261461919624
Trained batch 775 in epoch 7, gen_loss = 1.1699092745320083, disc_loss = 0.017610516662767323
Trained batch 776 in epoch 7, gen_loss = 1.170258623522681, disc_loss = 0.017588795156182453
Trained batch 777 in epoch 7, gen_loss = 1.1702752573784336, disc_loss = 0.017568035508396168
Trained batch 778 in epoch 7, gen_loss = 1.1700426264353987, disc_loss = 0.017546644241365858
Trained batch 779 in epoch 7, gen_loss = 1.1699742269057494, disc_loss = 0.017525811978274037
Trained batch 780 in epoch 7, gen_loss = 1.1697813515931788, disc_loss = 0.017504609113124767
Trained batch 781 in epoch 7, gen_loss = 1.1697595527257456, disc_loss = 0.01748276975899375
Trained batch 782 in epoch 7, gen_loss = 1.169783370324326, disc_loss = 0.017461430040169697
Trained batch 783 in epoch 7, gen_loss = 1.1697027699223586, disc_loss = 0.01743985379653168
Trained batch 784 in epoch 7, gen_loss = 1.1697378502529898, disc_loss = 0.017418361721622644
Trained batch 785 in epoch 7, gen_loss = 1.169608877284533, disc_loss = 0.01739665328988002
Trained batch 786 in epoch 7, gen_loss = 1.1694773860474554, disc_loss = 0.01737525348418145
Trained batch 787 in epoch 7, gen_loss = 1.1696001028802794, disc_loss = 0.017353722874620614
Trained batch 788 in epoch 7, gen_loss = 1.1696537756496812, disc_loss = 0.01733213586870555
Trained batch 789 in epoch 7, gen_loss = 1.1695845206327076, disc_loss = 0.017310740504321007
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 1.144534945487976, disc_loss = 0.0004979372606612742
Trained batch 1 in epoch 8, gen_loss = 1.1262039542198181, disc_loss = 0.00045398971997201443
Trained batch 2 in epoch 8, gen_loss = 1.1425370772679646, disc_loss = 0.0004233720828779042
Trained batch 3 in epoch 8, gen_loss = 1.1600632965564728, disc_loss = 0.00045257690362632275
Trained batch 4 in epoch 8, gen_loss = 1.2020568370819091, disc_loss = 0.000507502444088459
Trained batch 5 in epoch 8, gen_loss = 1.17392232020696, disc_loss = 0.0005471681749137739
Trained batch 6 in epoch 8, gen_loss = 1.177973917552403, disc_loss = 0.0005050422665330448
Trained batch 7 in epoch 8, gen_loss = 1.1864226907491684, disc_loss = 0.0005261451697151642
Trained batch 8 in epoch 8, gen_loss = 1.1933346456951566, disc_loss = 0.0005594396465716676
Trained batch 9 in epoch 8, gen_loss = 1.1832355856895447, disc_loss = 0.0005352258420316502
Trained batch 10 in epoch 8, gen_loss = 1.1856889074498957, disc_loss = 0.0005312876336657527
Trained batch 11 in epoch 8, gen_loss = 1.1928681929906209, disc_loss = 0.0005274475309609746
Trained batch 12 in epoch 8, gen_loss = 1.2059534879831166, disc_loss = 0.0005241335423376698
Trained batch 13 in epoch 8, gen_loss = 1.2181896311896188, disc_loss = 0.0005143388615189386
Trained batch 14 in epoch 8, gen_loss = 1.2262573957443237, disc_loss = 0.0005588665488176047
Trained batch 15 in epoch 8, gen_loss = 1.2278191819787025, disc_loss = 0.0006204990677360911
Trained batch 16 in epoch 8, gen_loss = 1.241830264820772, disc_loss = 0.0006125097484875689
Trained batch 17 in epoch 8, gen_loss = 1.2276518179310694, disc_loss = 0.0006447386533384108
Trained batch 18 in epoch 8, gen_loss = 1.2296064119589956, disc_loss = 0.000637521817177338
Trained batch 19 in epoch 8, gen_loss = 1.2142673403024673, disc_loss = 0.0006428491062251851
Trained batch 20 in epoch 8, gen_loss = 1.2186355732736134, disc_loss = 0.0006576736840153379
Trained batch 21 in epoch 8, gen_loss = 1.213521645827727, disc_loss = 0.0006642289517913014
Trained batch 22 in epoch 8, gen_loss = 1.2098213719285054, disc_loss = 0.0006517045979347566
Trained batch 23 in epoch 8, gen_loss = 1.2094943051536877, disc_loss = 0.0006427074913517572
Trained batch 24 in epoch 8, gen_loss = 1.2100901770591737, disc_loss = 0.0006363594823051244
Trained batch 25 in epoch 8, gen_loss = 1.224767994422179, disc_loss = 0.000640476759424648
Trained batch 26 in epoch 8, gen_loss = 1.2202596465746562, disc_loss = 0.00064083044007593
Trained batch 27 in epoch 8, gen_loss = 1.2165233045816422, disc_loss = 0.0006337980895685698
Trained batch 28 in epoch 8, gen_loss = 1.215774953365326, disc_loss = 0.0006261373827924374
Trained batch 29 in epoch 8, gen_loss = 1.2115517596403758, disc_loss = 0.0006254095943101372
Trained batch 30 in epoch 8, gen_loss = 1.2083568630679962, disc_loss = 0.0006160066310962241
Trained batch 31 in epoch 8, gen_loss = 1.2233916204422712, disc_loss = 0.000652662120955938
Trained batch 32 in epoch 8, gen_loss = 1.2192941091277383, disc_loss = 0.0006533368591176854
Trained batch 33 in epoch 8, gen_loss = 1.2123090291724485, disc_loss = 0.0006618770019164966
Trained batch 34 in epoch 8, gen_loss = 1.2084737147603717, disc_loss = 0.0006543175533546933
Trained batch 35 in epoch 8, gen_loss = 1.208378627896309, disc_loss = 0.000681723288532036
Trained batch 36 in epoch 8, gen_loss = 1.2075554760726723, disc_loss = 0.0006861717194771847
Trained batch 37 in epoch 8, gen_loss = 1.2050829670931165, disc_loss = 0.0006879758102035052
Trained batch 38 in epoch 8, gen_loss = 1.2073604617363367, disc_loss = 0.0007144415763039619
Trained batch 39 in epoch 8, gen_loss = 1.2036937728524209, disc_loss = 0.0007199975982075558
Trained batch 40 in epoch 8, gen_loss = 1.2041711589185202, disc_loss = 0.0007248169929924898
Trained batch 41 in epoch 8, gen_loss = 1.2044473049186526, disc_loss = 0.0007283767876547895
Trained batch 42 in epoch 8, gen_loss = 1.2016011628993721, disc_loss = 0.0007217169325084014
Trained batch 43 in epoch 8, gen_loss = 1.207127038728107, disc_loss = 0.0007275234820554033
Trained batch 44 in epoch 8, gen_loss = 1.2032770964834425, disc_loss = 0.0007315914457043012
Trained batch 45 in epoch 8, gen_loss = 1.2043547954248346, disc_loss = 0.0007274965527872353
Trained batch 46 in epoch 8, gen_loss = 1.197276847159609, disc_loss = 0.0007525961697497901
Trained batch 47 in epoch 8, gen_loss = 1.192112859338522, disc_loss = 0.0007526413877106582
Trained batch 48 in epoch 8, gen_loss = 1.1955203584262304, disc_loss = 0.0007567232075546469
Trained batch 49 in epoch 8, gen_loss = 1.1924022924900055, disc_loss = 0.000755967078730464
Trained batch 50 in epoch 8, gen_loss = 1.1901391358936535, disc_loss = 0.0007689395832701348
Trained batch 51 in epoch 8, gen_loss = 1.1898013525284254, disc_loss = 0.0007716765394434333
Trained batch 52 in epoch 8, gen_loss = 1.1898534736543331, disc_loss = 0.0007753680671020498
Trained batch 53 in epoch 8, gen_loss = 1.1852469631919154, disc_loss = 0.0007708334230334947
Trained batch 54 in epoch 8, gen_loss = 1.1838743610815567, disc_loss = 0.0007699932754886422
Trained batch 55 in epoch 8, gen_loss = 1.180623855973993, disc_loss = 0.000766126619834852
Trained batch 56 in epoch 8, gen_loss = 1.1768661507389002, disc_loss = 0.0007623728566901072
Trained batch 57 in epoch 8, gen_loss = 1.177228985161617, disc_loss = 0.0007589020202305682
Trained batch 58 in epoch 8, gen_loss = 1.178028922970012, disc_loss = 0.0007544780303960887
Trained batch 59 in epoch 8, gen_loss = 1.177155045668284, disc_loss = 0.0007477025831273446
Trained batch 60 in epoch 8, gen_loss = 1.1746299364527717, disc_loss = 0.0007418683385590977
Trained batch 61 in epoch 8, gen_loss = 1.1746113415687316, disc_loss = 0.0007362380058639833
Trained batch 62 in epoch 8, gen_loss = 1.1751420289751082, disc_loss = 0.0007370526861724636
Trained batch 63 in epoch 8, gen_loss = 1.1732828076928854, disc_loss = 0.0007303559318643238
Trained batch 64 in epoch 8, gen_loss = 1.1755352020263672, disc_loss = 0.0007235140705373712
Trained batch 65 in epoch 8, gen_loss = 1.173778530323144, disc_loss = 0.0007197605009423569
Trained batch 66 in epoch 8, gen_loss = 1.1736248251217514, disc_loss = 0.0007133250513093185
Trained batch 67 in epoch 8, gen_loss = 1.17358480832156, disc_loss = 0.000707269567903816
Trained batch 68 in epoch 8, gen_loss = 1.170538670774819, disc_loss = 0.0007016649271489755
Trained batch 69 in epoch 8, gen_loss = 1.1710245319775172, disc_loss = 0.0006969100567013291
Trained batch 70 in epoch 8, gen_loss = 1.1682995263959322, disc_loss = 0.0006962170415315252
Trained batch 71 in epoch 8, gen_loss = 1.1657126305831804, disc_loss = 0.0007052888641838864
Trained batch 72 in epoch 8, gen_loss = 1.1680962149411032, disc_loss = 0.0007100593006040595
Trained batch 73 in epoch 8, gen_loss = 1.167882348234589, disc_loss = 0.0007137374710952359
Trained batch 74 in epoch 8, gen_loss = 1.1652644737561544, disc_loss = 0.0007167812968449047
Trained batch 75 in epoch 8, gen_loss = 1.162360195266573, disc_loss = 0.000735632337301994
Trained batch 76 in epoch 8, gen_loss = 1.16146375064726, disc_loss = 0.0007609669999793995
Trained batch 77 in epoch 8, gen_loss = 1.1624492628452106, disc_loss = 0.0007800419955926302
Trained batch 78 in epoch 8, gen_loss = 1.1621063336541382, disc_loss = 0.0007751814323282931
Trained batch 79 in epoch 8, gen_loss = 1.162982565909624, disc_loss = 0.0007727938751486363
Trained batch 80 in epoch 8, gen_loss = 1.1647154762421126, disc_loss = 0.0007813147885040783
Trained batch 81 in epoch 8, gen_loss = 1.1672589611716386, disc_loss = 0.0007793835081052171
Trained batch 82 in epoch 8, gen_loss = 1.1665513781179864, disc_loss = 0.0007751176904477403
Trained batch 83 in epoch 8, gen_loss = 1.1680088248990832, disc_loss = 0.0007755366702137204
Trained batch 84 in epoch 8, gen_loss = 1.1667557555086472, disc_loss = 0.0007709059343837639
Trained batch 85 in epoch 8, gen_loss = 1.1661973588688428, disc_loss = 0.0007694903016631859
Trained batch 86 in epoch 8, gen_loss = 1.1657354975568837, disc_loss = 0.0007649490244461801
Trained batch 87 in epoch 8, gen_loss = 1.1631196703423152, disc_loss = 0.0007627389462537725
Trained batch 88 in epoch 8, gen_loss = 1.1629908774675948, disc_loss = 0.0007624919362774307
Trained batch 89 in epoch 8, gen_loss = 1.1619056853983136, disc_loss = 0.0007607743085827678
Trained batch 90 in epoch 8, gen_loss = 1.1624899126671173, disc_loss = 0.000758113828871481
Trained batch 91 in epoch 8, gen_loss = 1.1632254674382831, disc_loss = 0.000754465795699102
Trained batch 92 in epoch 8, gen_loss = 1.162793916399761, disc_loss = 0.0007527653529729334
Trained batch 93 in epoch 8, gen_loss = 1.1603322124227564, disc_loss = 0.0007480350812213456
Trained batch 94 in epoch 8, gen_loss = 1.1585601260787561, disc_loss = 0.0007465537649726398
Trained batch 95 in epoch 8, gen_loss = 1.1565320113052924, disc_loss = 0.0007535797000552217
Trained batch 96 in epoch 8, gen_loss = 1.1584815112585873, disc_loss = 0.0007520918308315587
Trained batch 97 in epoch 8, gen_loss = 1.1581827736630732, disc_loss = 0.0007518748687437678
Trained batch 98 in epoch 8, gen_loss = 1.1571751622238544, disc_loss = 0.000750609812317322
Trained batch 99 in epoch 8, gen_loss = 1.1574360531568528, disc_loss = 0.0007557854708284139
Trained batch 100 in epoch 8, gen_loss = 1.1572193385350822, disc_loss = 0.0007607283158283127
Trained batch 101 in epoch 8, gen_loss = 1.1563860312396406, disc_loss = 0.0007573137825637983
Trained batch 102 in epoch 8, gen_loss = 1.1573965011291134, disc_loss = 0.0007531629554312496
Trained batch 103 in epoch 8, gen_loss = 1.1578118497362504, disc_loss = 0.0007530552533213408
Trained batch 104 in epoch 8, gen_loss = 1.1590324350765773, disc_loss = 0.0007571716199717706
Trained batch 105 in epoch 8, gen_loss = 1.1597170756672912, disc_loss = 0.0007542336998256978
Trained batch 106 in epoch 8, gen_loss = 1.1591386455241766, disc_loss = 0.0007606847872674709
Trained batch 107 in epoch 8, gen_loss = 1.1585585171425785, disc_loss = 0.0007575671495740406
Trained batch 108 in epoch 8, gen_loss = 1.1576452031048066, disc_loss = 0.0007550120065330503
Trained batch 109 in epoch 8, gen_loss = 1.1562231827865947, disc_loss = 0.0007600770363668827
Trained batch 110 in epoch 8, gen_loss = 1.1561887956954338, disc_loss = 0.0007578562032683072
Trained batch 111 in epoch 8, gen_loss = 1.1568606022213186, disc_loss = 0.0007624741483596154
Trained batch 112 in epoch 8, gen_loss = 1.1555465960924605, disc_loss = 0.0007621067920205208
Trained batch 113 in epoch 8, gen_loss = 1.1539016496716885, disc_loss = 0.0007611318795713025
Trained batch 114 in epoch 8, gen_loss = 1.1530731185622838, disc_loss = 0.00075873420573771
Trained batch 115 in epoch 8, gen_loss = 1.1526288498064567, disc_loss = 0.0007593221952416131
Trained batch 116 in epoch 8, gen_loss = 1.1512542886611743, disc_loss = 0.0007584975414479581
Trained batch 117 in epoch 8, gen_loss = 1.1514508304959636, disc_loss = 0.000754736508173726
Trained batch 118 in epoch 8, gen_loss = 1.1500829297955297, disc_loss = 0.0007543629976948176
Trained batch 119 in epoch 8, gen_loss = 1.151105778415998, disc_loss = 0.000758039072631315
Trained batch 120 in epoch 8, gen_loss = 1.1504142609509556, disc_loss = 0.0007583718250932804
Trained batch 121 in epoch 8, gen_loss = 1.1501870819779694, disc_loss = 0.0007609584262369384
Trained batch 122 in epoch 8, gen_loss = 1.1510735934342795, disc_loss = 0.0007652982502013476
Trained batch 123 in epoch 8, gen_loss = 1.152876655901632, disc_loss = 0.0007624232147786495
Trained batch 124 in epoch 8, gen_loss = 1.1541429805755614, disc_loss = 0.0007685014286544174
Trained batch 125 in epoch 8, gen_loss = 1.1545885072814093, disc_loss = 0.0007659853281294335
Trained batch 126 in epoch 8, gen_loss = 1.1556063402356125, disc_loss = 0.0007776225649836055
Trained batch 127 in epoch 8, gen_loss = 1.1543276752345264, disc_loss = 0.000777880631858352
Trained batch 128 in epoch 8, gen_loss = 1.1538003595300423, disc_loss = 0.0007772512078310486
Trained batch 129 in epoch 8, gen_loss = 1.1529599350232345, disc_loss = 0.0007780145385857815
Trained batch 130 in epoch 8, gen_loss = 1.1517141702520939, disc_loss = 0.0007765156766559702
Trained batch 131 in epoch 8, gen_loss = 1.1515947182973225, disc_loss = 0.0007761837952068273
Trained batch 132 in epoch 8, gen_loss = 1.1522199345710582, disc_loss = 0.000775047656913687
Trained batch 133 in epoch 8, gen_loss = 1.1521044275653896, disc_loss = 0.000773821531928756
Trained batch 134 in epoch 8, gen_loss = 1.1521462202072144, disc_loss = 0.0007710356396812669
Trained batch 135 in epoch 8, gen_loss = 1.152150249656509, disc_loss = 0.0007681016742186758
Trained batch 136 in epoch 8, gen_loss = 1.1519717674185759, disc_loss = 0.0007679964805337988
Trained batch 137 in epoch 8, gen_loss = 1.1516031182330588, disc_loss = 0.0007644247032104707
Trained batch 138 in epoch 8, gen_loss = 1.1514190692695783, disc_loss = 0.0007628197637269367
Trained batch 139 in epoch 8, gen_loss = 1.1502268935952868, disc_loss = 0.0007603162427715558
Trained batch 140 in epoch 8, gen_loss = 1.1507177547360143, disc_loss = 0.0007578094462213496
Trained batch 141 in epoch 8, gen_loss = 1.1502267667945003, disc_loss = 0.0007580771177767737
Trained batch 142 in epoch 8, gen_loss = 1.1493226481484367, disc_loss = 0.0007579976241381096
Trained batch 143 in epoch 8, gen_loss = 1.148665698038207, disc_loss = 0.0007552045760045681
Trained batch 144 in epoch 8, gen_loss = 1.1483174611782205, disc_loss = 0.0007520910430747758
Trained batch 145 in epoch 8, gen_loss = 1.1485236074826488, disc_loss = 0.0007501152738345123
Trained batch 146 in epoch 8, gen_loss = 1.1474975229931526, disc_loss = 0.0007490505871036705
Trained batch 147 in epoch 8, gen_loss = 1.1476556090889751, disc_loss = 0.0007459431765931407
Trained batch 148 in epoch 8, gen_loss = 1.1474567671750215, disc_loss = 0.0007463844589523396
Trained batch 149 in epoch 8, gen_loss = 1.1479141143957774, disc_loss = 0.0007446842584370945
Trained batch 150 in epoch 8, gen_loss = 1.1473662494034167, disc_loss = 0.0007454787829308
Trained batch 151 in epoch 8, gen_loss = 1.1472805522774394, disc_loss = 0.0007438867076799445
Trained batch 152 in epoch 8, gen_loss = 1.1482002302712084, disc_loss = 0.0007403557463868649
Trained batch 153 in epoch 8, gen_loss = 1.1483601451694192, disc_loss = 0.0007387778493832773
Trained batch 154 in epoch 8, gen_loss = 1.147182511514233, disc_loss = 0.0007359269473160947
Trained batch 155 in epoch 8, gen_loss = 1.1468790089472747, disc_loss = 0.0007336461110240541
Trained batch 156 in epoch 8, gen_loss = 1.1468569359202294, disc_loss = 0.0007332009432027651
Trained batch 157 in epoch 8, gen_loss = 1.1475891591627387, disc_loss = 0.0007312801775973455
Trained batch 158 in epoch 8, gen_loss = 1.147139938372486, disc_loss = 0.0007292983355000615
Trained batch 159 in epoch 8, gen_loss = 1.1478519923985004, disc_loss = 0.0007299221193534322
Trained batch 160 in epoch 8, gen_loss = 1.1470031834537198, disc_loss = 0.0007272938766042406
Trained batch 161 in epoch 8, gen_loss = 1.1475259352613378, disc_loss = 0.0007253807148735189
Trained batch 162 in epoch 8, gen_loss = 1.1471209526062012, disc_loss = 0.0007253302664044628
Trained batch 163 in epoch 8, gen_loss = 1.1472358289288311, disc_loss = 0.0007244789679733491
Trained batch 164 in epoch 8, gen_loss = 1.1485019597140225, disc_loss = 0.0007225468753004503
Trained batch 165 in epoch 8, gen_loss = 1.1476867062499725, disc_loss = 0.0007216352743239714
Trained batch 166 in epoch 8, gen_loss = 1.1464564075726948, disc_loss = 0.0007190532460571741
Trained batch 167 in epoch 8, gen_loss = 1.1471116191574506, disc_loss = 0.0007177462468375563
Trained batch 168 in epoch 8, gen_loss = 1.1470259643165317, disc_loss = 0.0007186101351040774
Trained batch 169 in epoch 8, gen_loss = 1.1477903264410356, disc_loss = 0.0007238730224986178
Trained batch 170 in epoch 8, gen_loss = 1.1470737551387988, disc_loss = 0.0007243118416014187
Trained batch 171 in epoch 8, gen_loss = 1.146100675990415, disc_loss = 0.0007230981920106704
Trained batch 172 in epoch 8, gen_loss = 1.146618445140089, disc_loss = 0.0007212425442816248
Trained batch 173 in epoch 8, gen_loss = 1.1460920150937706, disc_loss = 0.0007253529717369626
Trained batch 174 in epoch 8, gen_loss = 1.146025709765298, disc_loss = 0.0007239170705101319
Trained batch 175 in epoch 8, gen_loss = 1.1466503173790195, disc_loss = 0.0007256793151927096
Trained batch 176 in epoch 8, gen_loss = 1.1463997407821611, disc_loss = 0.0007258212962713997
Trained batch 177 in epoch 8, gen_loss = 1.1459263646870517, disc_loss = 0.0007257285198259554
Trained batch 178 in epoch 8, gen_loss = 1.145305018518224, disc_loss = 0.0007235163277439127
Trained batch 179 in epoch 8, gen_loss = 1.1441021571556726, disc_loss = 0.0007221734321016508
Trained batch 180 in epoch 8, gen_loss = 1.1435675163295387, disc_loss = 0.0007237220385294531
Trained batch 181 in epoch 8, gen_loss = 1.1430180770355267, disc_loss = 0.0007216718807755099
Trained batch 182 in epoch 8, gen_loss = 1.1427848342337894, disc_loss = 0.0007189734183033023
Trained batch 183 in epoch 8, gen_loss = 1.142320954605289, disc_loss = 0.0007175781687217988
Trained batch 184 in epoch 8, gen_loss = 1.143057887296419, disc_loss = 0.0007166110342557265
Trained batch 185 in epoch 8, gen_loss = 1.1428772964144265, disc_loss = 0.0007147104940965511
Trained batch 186 in epoch 8, gen_loss = 1.1439213921679532, disc_loss = 0.0007136927484621837
Trained batch 187 in epoch 8, gen_loss = 1.1435876086037209, disc_loss = 0.000712600493453136
Trained batch 188 in epoch 8, gen_loss = 1.1434812567852162, disc_loss = 0.0007105650099686707
Trained batch 189 in epoch 8, gen_loss = 1.143680123592678, disc_loss = 0.0007084078293318223
Trained batch 190 in epoch 8, gen_loss = 1.1435567262285042, disc_loss = 0.0007077330160832413
Trained batch 191 in epoch 8, gen_loss = 1.1429368347550433, disc_loss = 0.0007062958081102503
Trained batch 192 in epoch 8, gen_loss = 1.1435572134398426, disc_loss = 0.0007048685450789669
Trained batch 193 in epoch 8, gen_loss = 1.143399214928912, disc_loss = 0.0007058311250485652
Trained batch 194 in epoch 8, gen_loss = 1.1427372862131169, disc_loss = 0.0007063577263556326
Trained batch 195 in epoch 8, gen_loss = 1.142124739532568, disc_loss = 0.0007061734927725522
Trained batch 196 in epoch 8, gen_loss = 1.1421324822503298, disc_loss = 0.0007056103817477992
Trained batch 197 in epoch 8, gen_loss = 1.1420889885136576, disc_loss = 0.0007064403715305915
Trained batch 198 in epoch 8, gen_loss = 1.1412317648005845, disc_loss = 0.0007043588889269018
Trained batch 199 in epoch 8, gen_loss = 1.1399711737036704, disc_loss = 0.0007027820583607536
Trained batch 200 in epoch 8, gen_loss = 1.1400676156157878, disc_loss = 0.0007009313889809268
Trained batch 201 in epoch 8, gen_loss = 1.1388676252105447, disc_loss = 0.0007002485783754544
Trained batch 202 in epoch 8, gen_loss = 1.1392008016262147, disc_loss = 0.0006981240573976868
Trained batch 203 in epoch 8, gen_loss = 1.1396034427133261, disc_loss = 0.0006971224373795421
Trained batch 204 in epoch 8, gen_loss = 1.1389274070902569, disc_loss = 0.0006954578296622125
Trained batch 205 in epoch 8, gen_loss = 1.1383499922682938, disc_loss = 0.0006953230810360712
Trained batch 206 in epoch 8, gen_loss = 1.1388929336543245, disc_loss = 0.0006946132882219258
Trained batch 207 in epoch 8, gen_loss = 1.1390079675385585, disc_loss = 0.0006930215299339929
Trained batch 208 in epoch 8, gen_loss = 1.1379991034001256, disc_loss = 0.000692756243582601
Trained batch 209 in epoch 8, gen_loss = 1.1387055550302778, disc_loss = 0.0006911191213432522
Trained batch 210 in epoch 8, gen_loss = 1.1383307369964382, disc_loss = 0.0006906488050719927
Trained batch 211 in epoch 8, gen_loss = 1.1386692372133147, disc_loss = 0.0006890247997669679
Trained batch 212 in epoch 8, gen_loss = 1.1396139261308411, disc_loss = 0.0006876163915107945
Trained batch 213 in epoch 8, gen_loss = 1.1391852821145103, disc_loss = 0.0006888748170257433
Trained batch 214 in epoch 8, gen_loss = 1.1391444267228592, disc_loss = 0.0006893735247674983
Trained batch 215 in epoch 8, gen_loss = 1.1392046671222757, disc_loss = 0.0006888193584691853
Trained batch 216 in epoch 8, gen_loss = 1.1394825283832815, disc_loss = 0.0006867920190432808
Trained batch 217 in epoch 8, gen_loss = 1.1397401898279103, disc_loss = 0.000686394788325901
Trained batch 218 in epoch 8, gen_loss = 1.1392870564438982, disc_loss = 0.0006868340212960205
Trained batch 219 in epoch 8, gen_loss = 1.138153780590404, disc_loss = 0.000685608919990376
Trained batch 220 in epoch 8, gen_loss = 1.1368766923295965, disc_loss = 0.0006840346407143155
Trained batch 221 in epoch 8, gen_loss = 1.1360661226349908, disc_loss = 0.0006827205207947692
Trained batch 222 in epoch 8, gen_loss = 1.136695747418254, disc_loss = 0.0006825063319411129
Trained batch 223 in epoch 8, gen_loss = 1.1364634420190538, disc_loss = 0.0006812716752132733
Trained batch 224 in epoch 8, gen_loss = 1.136671961678399, disc_loss = 0.0006797241044437719
Trained batch 225 in epoch 8, gen_loss = 1.1365816461301483, disc_loss = 0.0006785730449369474
Trained batch 226 in epoch 8, gen_loss = 1.1369510684244433, disc_loss = 0.0006765078665793254
Trained batch 227 in epoch 8, gen_loss = 1.1362267991429882, disc_loss = 0.0006748413787838153
Trained batch 228 in epoch 8, gen_loss = 1.1368035059828945, disc_loss = 0.0006740638536582071
Trained batch 229 in epoch 8, gen_loss = 1.1375079722508141, disc_loss = 0.0006738727210018702
Trained batch 230 in epoch 8, gen_loss = 1.1368474632630616, disc_loss = 0.0006727436397404075
Trained batch 231 in epoch 8, gen_loss = 1.1367280177515129, disc_loss = 0.0006716977735903066
Trained batch 232 in epoch 8, gen_loss = 1.1369884671571429, disc_loss = 0.0006700923839731885
Trained batch 233 in epoch 8, gen_loss = 1.1374061242637472, disc_loss = 0.0006692625336452491
Trained batch 234 in epoch 8, gen_loss = 1.1367837847547329, disc_loss = 0.0006680438755714196
Trained batch 235 in epoch 8, gen_loss = 1.1373972390162743, disc_loss = 0.0006661091771339839
Trained batch 236 in epoch 8, gen_loss = 1.1370606223742168, disc_loss = 0.0006665281550113882
Trained batch 237 in epoch 8, gen_loss = 1.1365100358213698, disc_loss = 0.0006658478482027671
Trained batch 238 in epoch 8, gen_loss = 1.1360698716411033, disc_loss = 0.0006649479116303418
Trained batch 239 in epoch 8, gen_loss = 1.135416849454244, disc_loss = 0.0006643928578948058
Trained batch 240 in epoch 8, gen_loss = 1.1352958199394194, disc_loss = 0.0006643158541383662
Trained batch 241 in epoch 8, gen_loss = 1.135124078959473, disc_loss = 0.0006628624743960937
Trained batch 242 in epoch 8, gen_loss = 1.1351646960026933, disc_loss = 0.0006612018042976045
Trained batch 243 in epoch 8, gen_loss = 1.1352412529656144, disc_loss = 0.0006609037919275341
Trained batch 244 in epoch 8, gen_loss = 1.1355468453193198, disc_loss = 0.0006613836531071183
Trained batch 245 in epoch 8, gen_loss = 1.1352779530897372, disc_loss = 0.0006618281162430994
Trained batch 246 in epoch 8, gen_loss = 1.1361278425826717, disc_loss = 0.0006607913800754663
Trained batch 247 in epoch 8, gen_loss = 1.1352046247451537, disc_loss = 0.0006629062823307204
Trained batch 248 in epoch 8, gen_loss = 1.1346883122700764, disc_loss = 0.0006635029285717905
Trained batch 249 in epoch 8, gen_loss = 1.1346629815101623, disc_loss = 0.000662771861650981
Trained batch 250 in epoch 8, gen_loss = 1.1343051803064537, disc_loss = 0.0006614463843045333
Trained batch 251 in epoch 8, gen_loss = 1.1338053525440277, disc_loss = 0.000659922049043604
Trained batch 252 in epoch 8, gen_loss = 1.1332710587931245, disc_loss = 0.0006593497852627336
Trained batch 253 in epoch 8, gen_loss = 1.1335122775374435, disc_loss = 0.0006590262672994066
Trained batch 254 in epoch 8, gen_loss = 1.1329884760520037, disc_loss = 0.0006579107745304046
Trained batch 255 in epoch 8, gen_loss = 1.1327111336868256, disc_loss = 0.0006581020505791457
Trained batch 256 in epoch 8, gen_loss = 1.132716042290402, disc_loss = 0.0006587164084008507
Trained batch 257 in epoch 8, gen_loss = 1.1331115727738816, disc_loss = 0.0006583643892857557
Trained batch 258 in epoch 8, gen_loss = 1.1326820848070978, disc_loss = 0.0006567584286654246
Trained batch 259 in epoch 8, gen_loss = 1.1327672561773887, disc_loss = 0.000656773289553642
Trained batch 260 in epoch 8, gen_loss = 1.1334308680446668, disc_loss = 0.0006563126249372659
Trained batch 261 in epoch 8, gen_loss = 1.1329883862542742, disc_loss = 0.0006549685127288458
Trained batch 262 in epoch 8, gen_loss = 1.133202287407429, disc_loss = 0.0006557335912651903
Trained batch 263 in epoch 8, gen_loss = 1.1338332622791782, disc_loss = 0.0006602154459291011
Trained batch 264 in epoch 8, gen_loss = 1.1338477217926168, disc_loss = 0.000660108357672316
Trained batch 265 in epoch 8, gen_loss = 1.1334838443680813, disc_loss = 0.0006589972405542122
Trained batch 266 in epoch 8, gen_loss = 1.1330944109945262, disc_loss = 0.0006579749896810198
Trained batch 267 in epoch 8, gen_loss = 1.132869645063557, disc_loss = 0.0006571766169335165
Trained batch 268 in epoch 8, gen_loss = 1.1324573314322859, disc_loss = 0.0006564326918005362
Trained batch 269 in epoch 8, gen_loss = 1.1315158832956242, disc_loss = 0.000659776660743066
Trained batch 270 in epoch 8, gen_loss = 1.1310754884652985, disc_loss = 0.0006600490904832431
Trained batch 271 in epoch 8, gen_loss = 1.130767024396097, disc_loss = 0.0006598395782074315
Trained batch 272 in epoch 8, gen_loss = 1.1312282057035536, disc_loss = 0.0006605846290954221
Trained batch 273 in epoch 8, gen_loss = 1.1316759536301133, disc_loss = 0.0006598196685803632
Trained batch 274 in epoch 8, gen_loss = 1.131539769822901, disc_loss = 0.000660725025756454
Trained batch 275 in epoch 8, gen_loss = 1.132312727795131, disc_loss = 0.0006599788610111464
Trained batch 276 in epoch 8, gen_loss = 1.1322645252362056, disc_loss = 0.00065902975147896
Trained batch 277 in epoch 8, gen_loss = 1.1324109162786882, disc_loss = 0.0006583104605858529
Trained batch 278 in epoch 8, gen_loss = 1.1318794576497915, disc_loss = 0.000656925041982103
Trained batch 279 in epoch 8, gen_loss = 1.132370620753084, disc_loss = 0.0006615071111549956
Trained batch 280 in epoch 8, gen_loss = 1.1327888378044888, disc_loss = 0.0006613105619815095
Trained batch 281 in epoch 8, gen_loss = 1.1322266436214987, disc_loss = 0.0006619781584533408
Trained batch 282 in epoch 8, gen_loss = 1.1327596669062288, disc_loss = 0.0006616900488034931
Trained batch 283 in epoch 8, gen_loss = 1.1335131175501245, disc_loss = 0.000660530939057935
Trained batch 284 in epoch 8, gen_loss = 1.1342222266029893, disc_loss = 0.000659397681010887
Trained batch 285 in epoch 8, gen_loss = 1.1340524414619366, disc_loss = 0.00065818970782399
Trained batch 286 in epoch 8, gen_loss = 1.1349116985390826, disc_loss = 0.0006575419064343481
Trained batch 287 in epoch 8, gen_loss = 1.1352022354387574, disc_loss = 0.0006575425107560781
Trained batch 288 in epoch 8, gen_loss = 1.135018538232493, disc_loss = 0.0006573568556456147
Trained batch 289 in epoch 8, gen_loss = 1.1348302510277979, disc_loss = 0.0006569530960405245
Trained batch 290 in epoch 8, gen_loss = 1.1348210386803879, disc_loss = 0.0006556736108930173
Trained batch 291 in epoch 8, gen_loss = 1.135075739597621, disc_loss = 0.0006546613730191993
Trained batch 292 in epoch 8, gen_loss = 1.135310387652075, disc_loss = 0.0006532646803449166
Trained batch 293 in epoch 8, gen_loss = 1.1348800945038697, disc_loss = 0.0006519177644260126
Trained batch 294 in epoch 8, gen_loss = 1.1350526658155151, disc_loss = 0.0006508069442411474
Trained batch 295 in epoch 8, gen_loss = 1.134836061782128, disc_loss = 0.0006498363328392844
Trained batch 296 in epoch 8, gen_loss = 1.1352836204698993, disc_loss = 0.0006503394741395658
Trained batch 297 in epoch 8, gen_loss = 1.1355509023938404, disc_loss = 0.0006495877757009069
Trained batch 298 in epoch 8, gen_loss = 1.1358740236049512, disc_loss = 0.0006499725818730591
Trained batch 299 in epoch 8, gen_loss = 1.1362379239002864, disc_loss = 0.0006497313887424146
Trained batch 300 in epoch 8, gen_loss = 1.1355581992488366, disc_loss = 0.0006550086367847491
Trained batch 301 in epoch 8, gen_loss = 1.1363239280435422, disc_loss = 0.0006595848886441094
Trained batch 302 in epoch 8, gen_loss = 1.1359310185555185, disc_loss = 0.0006663040724804274
Trained batch 303 in epoch 8, gen_loss = 1.1361712566331814, disc_loss = 0.0006671201354995566
Trained batch 304 in epoch 8, gen_loss = 1.135969597003499, disc_loss = 0.00066762470094426
Trained batch 305 in epoch 8, gen_loss = 1.1356485450969023, disc_loss = 0.0006681636869496502
Trained batch 306 in epoch 8, gen_loss = 1.1355886641853408, disc_loss = 0.0006710508349503266
Trained batch 307 in epoch 8, gen_loss = 1.135736330763086, disc_loss = 0.0006724782323981817
Trained batch 308 in epoch 8, gen_loss = 1.1359994272583898, disc_loss = 0.0006867409312666596
Trained batch 309 in epoch 8, gen_loss = 1.1353569949826887, disc_loss = 0.0006966061445118319
Trained batch 310 in epoch 8, gen_loss = 1.1360009536865823, disc_loss = 0.000709696267649136
Trained batch 311 in epoch 8, gen_loss = 1.136147616765438, disc_loss = 0.0007117946476612885
Trained batch 312 in epoch 8, gen_loss = 1.1359809640878307, disc_loss = 0.0007126716688236656
Trained batch 313 in epoch 8, gen_loss = 1.135802632684161, disc_loss = 0.0007138486347638759
Trained batch 314 in epoch 8, gen_loss = 1.1358865450298976, disc_loss = 0.0007146420267721017
Trained batch 315 in epoch 8, gen_loss = 1.136582294974146, disc_loss = 0.0007150284455988933
Trained batch 316 in epoch 8, gen_loss = 1.1365146783624163, disc_loss = 0.0007141503883299509
Trained batch 317 in epoch 8, gen_loss = 1.136319785747888, disc_loss = 0.0007150609673325956
Trained batch 318 in epoch 8, gen_loss = 1.1362164454026655, disc_loss = 0.000715835936123733
Trained batch 319 in epoch 8, gen_loss = 1.1365547332912684, disc_loss = 0.0007199030138508533
Trained batch 320 in epoch 8, gen_loss = 1.137504667136528, disc_loss = 0.0007269382638192367
Trained batch 321 in epoch 8, gen_loss = 1.1375584976273294, disc_loss = 0.0007281548581129484
Trained batch 322 in epoch 8, gen_loss = 1.1372618313544305, disc_loss = 0.0007317944355208092
Trained batch 323 in epoch 8, gen_loss = 1.1377415693836448, disc_loss = 0.0007339733809787481
Trained batch 324 in epoch 8, gen_loss = 1.1386687586857722, disc_loss = 0.0007394776681366449
Trained batch 325 in epoch 8, gen_loss = 1.1384649492480272, disc_loss = 0.0007462615279003726
Trained batch 326 in epoch 8, gen_loss = 1.1393431457904502, disc_loss = 0.0007503203293294375
Trained batch 327 in epoch 8, gen_loss = 1.1387807372503165, disc_loss = 0.0007511240580309433
Trained batch 328 in epoch 8, gen_loss = 1.138880126563249, disc_loss = 0.0007532302700308659
Trained batch 329 in epoch 8, gen_loss = 1.1385650528199744, disc_loss = 0.0007559960057154637
Trained batch 330 in epoch 8, gen_loss = 1.1386227501483122, disc_loss = 0.0007568427115000694
Trained batch 331 in epoch 8, gen_loss = 1.1390702492860427, disc_loss = 0.0007607256690340386
Trained batch 332 in epoch 8, gen_loss = 1.139821307616191, disc_loss = 0.0007625818670330172
Trained batch 333 in epoch 8, gen_loss = 1.1395146091898045, disc_loss = 0.0007618527159214711
Trained batch 335 in epoch 8, gen_loss = 1.1398259463409584, disc_loss = 0.0007636169618871506
Trained batch 336 in epoch 8, gen_loss = 1.140100233102057, disc_loss = 0.0007654378344014685
Trained batch 337 in epoch 8, gen_loss = 1.1407257969210134, disc_loss = 0.000777483230991256
Trained batch 338 in epoch 8, gen_loss = 1.1407729796955368, disc_loss = 0.0007831433212390077
Trained batch 339 in epoch 8, gen_loss = 1.140790070681011, disc_loss = 0.0007848800454453072
Trained batch 340 in epoch 8, gen_loss = 1.1404588038970298, disc_loss = 0.0007872230686039782
Trained batch 341 in epoch 8, gen_loss = 1.1405216962621922, disc_loss = 0.0007915701281431823
Trained batch 342 in epoch 8, gen_loss = 1.1401756614359753, disc_loss = 0.0007909185191312311
Trained batch 343 in epoch 8, gen_loss = 1.1398179695703263, disc_loss = 0.0007916330952105264
Trained batch 344 in epoch 8, gen_loss = 1.139444777412691, disc_loss = 0.0007918002019784804
Trained batch 345 in epoch 8, gen_loss = 1.1398836096931744, disc_loss = 0.0007938094032696862
Trained batch 346 in epoch 8, gen_loss = 1.1398524370591991, disc_loss = 0.0007951748114540872
Trained batch 347 in epoch 8, gen_loss = 1.1398237472635575, disc_loss = 0.0007954243270830177
Trained batch 348 in epoch 8, gen_loss = 1.1393237388919624, disc_loss = 0.0007974918195203928
Trained batch 349 in epoch 8, gen_loss = 1.1392666014603205, disc_loss = 0.0007964589564029926
Trained batch 350 in epoch 8, gen_loss = 1.138722617402036, disc_loss = 0.0007955660558295068
Trained batch 351 in epoch 8, gen_loss = 1.1384308954531497, disc_loss = 0.0007951403200753372
Trained batch 352 in epoch 8, gen_loss = 1.1386038017678193, disc_loss = 0.0007951437768054118
Trained batch 353 in epoch 8, gen_loss = 1.1393352036422255, disc_loss = 0.0007972579142262917
Trained batch 354 in epoch 8, gen_loss = 1.1394848010909389, disc_loss = 0.0007986150780351648
Trained batch 355 in epoch 8, gen_loss = 1.1396570453483068, disc_loss = 0.0007986255989768386
Trained batch 356 in epoch 8, gen_loss = 1.139809957739352, disc_loss = 0.0007975523469967022
Trained batch 357 in epoch 8, gen_loss = 1.1398176900501358, disc_loss = 0.0008003991606122393
Trained batch 358 in epoch 8, gen_loss = 1.139881000877423, disc_loss = 0.0008062239333242697
Trained batch 359 in epoch 8, gen_loss = 1.1402427266041437, disc_loss = 0.0008058128380475359
Trained batch 360 in epoch 8, gen_loss = 1.1405864002962192, disc_loss = 0.0008088692024974488
Trained batch 361 in epoch 8, gen_loss = 1.140493577685804, disc_loss = 0.0008103731580371891
Trained batch 362 in epoch 8, gen_loss = 1.1403282450578758, disc_loss = 0.0008114589857368554
Trained batch 363 in epoch 8, gen_loss = 1.1402994708700493, disc_loss = 0.0008112403423753107
Trained batch 364 in epoch 8, gen_loss = 1.1402137351362673, disc_loss = 0.0008112549606378969
Trained batch 365 in epoch 8, gen_loss = 1.1403150597556693, disc_loss = 0.0008111680570615791
Trained batch 366 in epoch 8, gen_loss = 1.1410724772419527, disc_loss = 0.000812394948763778
Trained batch 367 in epoch 8, gen_loss = 1.1409761970457823, disc_loss = 0.0008138083350153781
Trained batch 368 in epoch 8, gen_loss = 1.1415110732804792, disc_loss = 0.0008189470043751666
Trained batch 369 in epoch 8, gen_loss = 1.1419829722997306, disc_loss = 0.0008213325156641469
Trained batch 370 in epoch 8, gen_loss = 1.1420143881255405, disc_loss = 0.000822557177679548
Trained batch 371 in epoch 8, gen_loss = 1.1423341994003584, disc_loss = 0.0008216147340448593
Trained batch 372 in epoch 8, gen_loss = 1.1426024900364813, disc_loss = 0.0008205419778324484
Trained batch 373 in epoch 8, gen_loss = 1.1428002115876916, disc_loss = 0.0008203061169914822
Trained batch 374 in epoch 8, gen_loss = 1.143211038907369, disc_loss = 0.0008206335323241849
Trained batch 375 in epoch 8, gen_loss = 1.1436040984823348, disc_loss = 0.0008223809435297339
Trained batch 376 in epoch 8, gen_loss = 1.1439967557036907, disc_loss = 0.0008245345703153241
Trained batch 377 in epoch 8, gen_loss = 1.1435864853165136, disc_loss = 0.0008261374223462389
Trained batch 378 in epoch 8, gen_loss = 1.1437705807132268, disc_loss = 0.0008266271547522485
Trained batch 379 in epoch 8, gen_loss = 1.1436078929587414, disc_loss = 0.0008272241419610126
Trained batch 380 in epoch 8, gen_loss = 1.1430606627714603, disc_loss = 0.0008277492712281175
Trained batch 381 in epoch 8, gen_loss = 1.1425667194483793, disc_loss = 0.0008274182587062345
Trained batch 382 in epoch 8, gen_loss = 1.1422798224279838, disc_loss = 0.0008267825717099167
Trained batch 383 in epoch 8, gen_loss = 1.1421568354902167, disc_loss = 0.0008267598395832465
Trained batch 384 in epoch 8, gen_loss = 1.1416986197620242, disc_loss = 0.0008280050438865051
Trained batch 385 in epoch 8, gen_loss = 1.141946808198573, disc_loss = 0.0008268434799534457
Trained batch 386 in epoch 8, gen_loss = 1.1421808674353962, disc_loss = 0.0008278672551214021
Trained batch 387 in epoch 8, gen_loss = 1.1428715674225818, disc_loss = 0.0008267426976427608
Trained batch 388 in epoch 8, gen_loss = 1.1429132990788065, disc_loss = 0.0008255397105035265
Trained batch 389 in epoch 8, gen_loss = 1.1436686923870674, disc_loss = 0.0008244476607218624
Trained batch 390 in epoch 8, gen_loss = 1.1433424874949638, disc_loss = 0.0008240915959804555
Trained batch 391 in epoch 8, gen_loss = 1.1432474807513004, disc_loss = 0.0008228819897340145
Trained batch 392 in epoch 8, gen_loss = 1.1431908196468692, disc_loss = 0.0008220767113409756
Trained batch 393 in epoch 8, gen_loss = 1.1434584745598324, disc_loss = 0.0008208624587062188
Trained batch 394 in epoch 8, gen_loss = 1.1430624658548378, disc_loss = 0.0008198897224626964
Trained batch 395 in epoch 8, gen_loss = 1.143521221147643, disc_loss = 0.0008196512575559977
Trained batch 396 in epoch 8, gen_loss = 1.143508783065402, disc_loss = 0.0008190187303905354
Trained batch 397 in epoch 8, gen_loss = 1.1436729007330373, disc_loss = 0.0008179369818678959
Trained batch 398 in epoch 8, gen_loss = 1.1441408340494734, disc_loss = 0.0008196745015024897
Trained batch 399 in epoch 8, gen_loss = 1.1435960920155048, disc_loss = 0.0008202266551961656
Trained batch 400 in epoch 8, gen_loss = 1.1431941997975186, disc_loss = 0.0008232157404227949
Trained batch 401 in epoch 8, gen_loss = 1.143047069435689, disc_loss = 0.0008246242742005513
Trained batch 402 in epoch 8, gen_loss = 1.1436938576899451, disc_loss = 0.0008248780022384529
Trained batch 403 in epoch 8, gen_loss = 1.1445105193865182, disc_loss = 0.0008255615025023368
Trained batch 404 in epoch 8, gen_loss = 1.1449042855957408, disc_loss = 0.0008247835432282752
Trained batch 405 in epoch 8, gen_loss = 1.1446798003365841, disc_loss = 0.0008238473344534599
Trained batch 406 in epoch 8, gen_loss = 1.1446653124155517, disc_loss = 0.0008236478564514794
Trained batch 407 in epoch 8, gen_loss = 1.1452863263148887, disc_loss = 0.0008225439871917022
Trained batch 408 in epoch 8, gen_loss = 1.1453796085926606, disc_loss = 0.0008241236952764225
Trained batch 409 in epoch 8, gen_loss = 1.1451736618832844, disc_loss = 0.0008239454690582778
Trained batch 410 in epoch 8, gen_loss = 1.1450132528940837, disc_loss = 0.000823664089915209
Trained batch 411 in epoch 8, gen_loss = 1.144897681995503, disc_loss = 0.0008238677162331194
Trained batch 412 in epoch 8, gen_loss = 1.1446090471946586, disc_loss = 0.0008227689331651104
Trained batch 413 in epoch 8, gen_loss = 1.1445689094815277, disc_loss = 0.000822246587508502
Trained batch 414 in epoch 8, gen_loss = 1.1445432918617524, disc_loss = 0.0008216830551854323
Trained batch 415 in epoch 8, gen_loss = 1.1444120243764841, disc_loss = 0.0008212215387594859
Trained batch 416 in epoch 8, gen_loss = 1.1438867479777164, disc_loss = 0.000822882964825749
Trained batch 417 in epoch 8, gen_loss = 1.1440026643173546, disc_loss = 0.0008288565906835275
Trained batch 418 in epoch 8, gen_loss = 1.144135651838808, disc_loss = 0.00082849719132928
Trained batch 419 in epoch 8, gen_loss = 1.144493586960293, disc_loss = 0.0008334517429743538
Trained batch 420 in epoch 8, gen_loss = 1.1447175412733028, disc_loss = 0.0008350365863357518
Trained batch 421 in epoch 8, gen_loss = 1.1446144544117824, disc_loss = 0.0008358056254942032
Trained batch 422 in epoch 8, gen_loss = 1.1446175617529146, disc_loss = 0.000835649123765973
Trained batch 423 in epoch 8, gen_loss = 1.1447691939911753, disc_loss = 0.0008350588596960802
Trained batch 424 in epoch 8, gen_loss = 1.1448082592908073, disc_loss = 0.0008360040743205258
Trained batch 425 in epoch 8, gen_loss = 1.1451006305049842, disc_loss = 0.0008375479359733937
Trained batch 426 in epoch 8, gen_loss = 1.14548352339787, disc_loss = 0.0008374715650719166
Trained batch 427 in epoch 8, gen_loss = 1.1453254874621597, disc_loss = 0.0008362321980448797
Trained batch 428 in epoch 8, gen_loss = 1.1452741923032108, disc_loss = 0.0008370542047639748
Trained batch 429 in epoch 8, gen_loss = 1.1450410244076752, disc_loss = 0.0008382967502003276
Trained batch 430 in epoch 8, gen_loss = 1.1451303107002773, disc_loss = 0.0008391498597074093
Trained batch 431 in epoch 8, gen_loss = 1.1453119403234235, disc_loss = 0.0008381840777507966
Trained batch 432 in epoch 8, gen_loss = 1.1456835740708313, disc_loss = 0.000837472074274748
Trained batch 433 in epoch 8, gen_loss = 1.1456604023133554, disc_loss = 0.0008367168549973999
Trained batch 434 in epoch 8, gen_loss = 1.1453653146480691, disc_loss = 0.0008359017699619691
Trained batch 435 in epoch 8, gen_loss = 1.1452405912066819, disc_loss = 0.0008353196061670208
Trained batch 436 in epoch 8, gen_loss = 1.144872694321028, disc_loss = 0.0008345772917845949
Trained batch 437 in epoch 8, gen_loss = 1.1449945843927392, disc_loss = 0.0008349820829159261
Trained batch 438 in epoch 8, gen_loss = 1.1450808925346252, disc_loss = 0.0008372272578134903
Trained batch 439 in epoch 8, gen_loss = 1.1452485165812754, disc_loss = 0.0008375310678357809
Trained batch 440 in epoch 8, gen_loss = 1.145376727153925, disc_loss = 0.0008369706742821342
Trained batch 441 in epoch 8, gen_loss = 1.1449238763136023, disc_loss = 0.0008382561050457627
Trained batch 442 in epoch 8, gen_loss = 1.144613153509308, disc_loss = 0.0008394633416264081
Trained batch 443 in epoch 8, gen_loss = 1.1446458171079825, disc_loss = 0.0008395598029433582
Trained batch 444 in epoch 8, gen_loss = 1.1444554269983527, disc_loss = 0.0008398137116161164
Trained batch 445 in epoch 8, gen_loss = 1.1445216795788753, disc_loss = 0.0008387284022139911
Trained batch 446 in epoch 8, gen_loss = 1.1445945346648794, disc_loss = 0.0008384075958044237
Trained batch 447 in epoch 8, gen_loss = 1.1443128529936075, disc_loss = 0.0008380998312661957
Trained batch 448 in epoch 8, gen_loss = 1.1440279945764351, disc_loss = 0.000838059686328635
Trained batch 449 in epoch 8, gen_loss = 1.1435581347677444, disc_loss = 0.0008376985053635305
Trained batch 450 in epoch 8, gen_loss = 1.1431553957203275, disc_loss = 0.0008386849637913565
Trained batch 451 in epoch 8, gen_loss = 1.1432569732444475, disc_loss = 0.0008395280010598522
Trained batch 452 in epoch 8, gen_loss = 1.1432684013911956, disc_loss = 0.0008395607999544467
Trained batch 453 in epoch 8, gen_loss = 1.1431773537318612, disc_loss = 0.0008404783033745339
Trained batch 454 in epoch 8, gen_loss = 1.1428834575873155, disc_loss = 0.0008394817005494958
Trained batch 455 in epoch 8, gen_loss = 1.1426185809990816, disc_loss = 0.0008384758494733097
Trained batch 456 in epoch 8, gen_loss = 1.1423619102596976, disc_loss = 0.0008383556995112898
Trained batch 457 in epoch 8, gen_loss = 1.1421233182650987, disc_loss = 0.0008384409332881768
Trained batch 458 in epoch 8, gen_loss = 1.142208269348851, disc_loss = 0.000837330108616006
Trained batch 459 in epoch 8, gen_loss = 1.1422178736199504, disc_loss = 0.0008360810776534693
Trained batch 460 in epoch 8, gen_loss = 1.1421656589187408, disc_loss = 0.0008351139090662325
Trained batch 461 in epoch 8, gen_loss = 1.1424197945501897, disc_loss = 0.0008339870157167799
Trained batch 462 in epoch 8, gen_loss = 1.142152902760722, disc_loss = 0.0008329010141619178
Trained batch 463 in epoch 8, gen_loss = 1.142657024207814, disc_loss = 0.00083264126994342
Trained batch 464 in epoch 8, gen_loss = 1.1431435370957979, disc_loss = 0.0008316889605534974
Trained batch 465 in epoch 8, gen_loss = 1.1429791385267938, disc_loss = 0.0008302780496288298
Trained batch 466 in epoch 8, gen_loss = 1.1431062552096758, disc_loss = 0.0008296971835048442
Trained batch 467 in epoch 8, gen_loss = 1.1430065594931953, disc_loss = 0.0008291165199146693
Trained batch 468 in epoch 8, gen_loss = 1.1429540166722687, disc_loss = 0.0008284968399961016
Trained batch 469 in epoch 8, gen_loss = 1.1430168353496715, disc_loss = 0.0008276708216029913
Trained batch 470 in epoch 8, gen_loss = 1.1433338591247608, disc_loss = 0.0008268805692563597
Trained batch 471 in epoch 8, gen_loss = 1.143593089939174, disc_loss = 0.0008257151505134415
Trained batch 472 in epoch 8, gen_loss = 1.1434230823345466, disc_loss = 0.000824685316731224
Trained batch 473 in epoch 8, gen_loss = 1.1433086562508772, disc_loss = 0.0008238191564222562
Trained batch 474 in epoch 8, gen_loss = 1.1438317001493354, disc_loss = 0.0008266315352490269
Trained batch 475 in epoch 8, gen_loss = 1.143965456540845, disc_loss = 0.0008257749286713079
Trained batch 476 in epoch 8, gen_loss = 1.1439029659365207, disc_loss = 0.0008249685342279136
Trained batch 477 in epoch 8, gen_loss = 1.1439747165685916, disc_loss = 0.0008239815147763126
Trained batch 478 in epoch 8, gen_loss = 1.1440504457109408, disc_loss = 0.0008241973998655015
Trained batch 479 in epoch 8, gen_loss = 1.1448452717314164, disc_loss = 0.0008233120453951415
Trained batch 480 in epoch 8, gen_loss = 1.145103744682304, disc_loss = 0.0008257380040486396
Trained batch 481 in epoch 8, gen_loss = 1.1458245729757048, disc_loss = 0.0008284678951744377
Trained batch 482 in epoch 8, gen_loss = 1.1462650399030365, disc_loss = 0.0008312613343218376
Trained batch 483 in epoch 8, gen_loss = 1.145897440427591, disc_loss = 0.0008333886527140771
Trained batch 484 in epoch 8, gen_loss = 1.145585964389683, disc_loss = 0.0008329866018347903
Trained batch 485 in epoch 8, gen_loss = 1.145745575428009, disc_loss = 0.0008352954672896706
Trained batch 486 in epoch 8, gen_loss = 1.1461064717608067, disc_loss = 0.0008354532240518967
Trained batch 487 in epoch 8, gen_loss = 1.146079631369622, disc_loss = 0.0008354880399744362
Trained batch 488 in epoch 8, gen_loss = 1.14655002470153, disc_loss = 0.0008358619432250735
Trained batch 489 in epoch 8, gen_loss = 1.1472044268432928, disc_loss = 0.0008353400246088146
Trained batch 490 in epoch 8, gen_loss = 1.1469067886259308, disc_loss = 0.0008353450086134697
Trained batch 491 in epoch 8, gen_loss = 1.146609582067505, disc_loss = 0.0008351211595808996
Trained batch 492 in epoch 8, gen_loss = 1.146232435475982, disc_loss = 0.0008385287682548483
Trained batch 493 in epoch 8, gen_loss = 1.1461029851484879, disc_loss = 0.0008388398732916501
Trained batch 494 in epoch 8, gen_loss = 1.1462858508331608, disc_loss = 0.0008383291116163059
Trained batch 495 in epoch 8, gen_loss = 1.1464414517244985, disc_loss = 0.0008375713033244885
Trained batch 496 in epoch 8, gen_loss = 1.1465515142955052, disc_loss = 0.0008375459254374521
Trained batch 497 in epoch 8, gen_loss = 1.1463821975581616, disc_loss = 0.000837016306853999
Trained batch 498 in epoch 8, gen_loss = 1.146848753602328, disc_loss = 0.0008362410819267142
Trained batch 499 in epoch 8, gen_loss = 1.1464838036298752, disc_loss = 0.0008357578947325238
Trained batch 500 in epoch 8, gen_loss = 1.146880581826269, disc_loss = 0.0008352014806959035
Trained batch 501 in epoch 8, gen_loss = 1.1468162449945016, disc_loss = 0.0008358928313839669
Trained batch 502 in epoch 8, gen_loss = 1.146634188963926, disc_loss = 0.0008377261906163305
Trained batch 503 in epoch 8, gen_loss = 1.1465565357652923, disc_loss = 0.0008384200917221495
Trained batch 504 in epoch 8, gen_loss = 1.146092924033061, disc_loss = 0.0008377188933658238
Trained batch 505 in epoch 8, gen_loss = 1.146497330646741, disc_loss = 0.0008371074318958505
Trained batch 506 in epoch 8, gen_loss = 1.1468834105798245, disc_loss = 0.0008362112331472308
Trained batch 507 in epoch 8, gen_loss = 1.147190463589871, disc_loss = 0.0008359687904942795
Trained batch 508 in epoch 8, gen_loss = 1.147498735276093, disc_loss = 0.0008350209487841807
Trained batch 509 in epoch 8, gen_loss = 1.1477209589060615, disc_loss = 0.0008342090438293549
Trained batch 510 in epoch 8, gen_loss = 1.1474671636775515, disc_loss = 0.0008338407856875159
Trained batch 511 in epoch 8, gen_loss = 1.1475663089659065, disc_loss = 0.0008328072768790662
Trained batch 512 in epoch 8, gen_loss = 1.1473536089382208, disc_loss = 0.0008323806358209028
Trained batch 513 in epoch 8, gen_loss = 1.147571699164721, disc_loss = 0.0008324551640000513
Trained batch 514 in epoch 8, gen_loss = 1.1473401426111611, disc_loss = 0.0008318080095510966
Trained batch 515 in epoch 8, gen_loss = 1.147004548315854, disc_loss = 0.0008311103548301392
Trained batch 516 in epoch 8, gen_loss = 1.1472298804980412, disc_loss = 0.0008303534448492689
Trained batch 517 in epoch 8, gen_loss = 1.147160058891451, disc_loss = 0.0008298320364041621
Trained batch 518 in epoch 8, gen_loss = 1.1469694214060127, disc_loss = 0.0008302656211396804
Trained batch 519 in epoch 8, gen_loss = 1.1466450804701218, disc_loss = 0.0008299742926073333
Trained batch 520 in epoch 8, gen_loss = 1.146487688949607, disc_loss = 0.0008289799080346488
Trained batch 521 in epoch 8, gen_loss = 1.1466309819870069, disc_loss = 0.0008287347832666103
Trained batch 522 in epoch 8, gen_loss = 1.1467858884576174, disc_loss = 0.0008282024524865555
Trained batch 523 in epoch 8, gen_loss = 1.1467251371563847, disc_loss = 0.0008275716536445543
Trained batch 524 in epoch 8, gen_loss = 1.1468723831857954, disc_loss = 0.0008266252196127815
Trained batch 525 in epoch 8, gen_loss = 1.1467901240510179, disc_loss = 0.0008256664528301651
Trained batch 526 in epoch 8, gen_loss = 1.1467351826363767, disc_loss = 0.0008246465939016698
Trained batch 527 in epoch 8, gen_loss = 1.1468870480629532, disc_loss = 0.0008238595619883254
Trained batch 528 in epoch 8, gen_loss = 1.1471393877932616, disc_loss = 0.0008245892163092316
Trained batch 529 in epoch 8, gen_loss = 1.1470638708123622, disc_loss = 0.0008240928054668606
Trained batch 530 in epoch 8, gen_loss = 1.1476175265348114, disc_loss = 0.0008243754585146406
Trained batch 531 in epoch 8, gen_loss = 1.1478296270720045, disc_loss = 0.0008238501855215107
Trained batch 532 in epoch 8, gen_loss = 1.1477480716374309, disc_loss = 0.0008229836024886511
Trained batch 533 in epoch 8, gen_loss = 1.147852309969034, disc_loss = 0.0008235238780802087
Trained batch 534 in epoch 8, gen_loss = 1.1477308668822885, disc_loss = 0.0008242468889824454
Trained batch 535 in epoch 8, gen_loss = 1.1474489028106873, disc_loss = 0.0008269407953775954
Trained batch 536 in epoch 8, gen_loss = 1.1476737086555366, disc_loss = 0.0008289384512248964
Trained batch 537 in epoch 8, gen_loss = 1.1483008042808802, disc_loss = 0.000829346821226654
Trained batch 538 in epoch 8, gen_loss = 1.14823438075124, disc_loss = 0.000829342379960869
Trained batch 539 in epoch 8, gen_loss = 1.1482499693278914, disc_loss = 0.0008295131692580913
Trained batch 540 in epoch 8, gen_loss = 1.1486479730350474, disc_loss = 0.0008291828271467239
Trained batch 541 in epoch 8, gen_loss = 1.1483297758216788, disc_loss = 0.0008281365589400225
Trained batch 542 in epoch 8, gen_loss = 1.1484037294133154, disc_loss = 0.0008270401428505078
Trained batch 543 in epoch 8, gen_loss = 1.1483605093158342, disc_loss = 0.0008261487366647035
Trained batch 544 in epoch 8, gen_loss = 1.1483132195035253, disc_loss = 0.0008257101081662017
Trained batch 545 in epoch 8, gen_loss = 1.1480932806656037, disc_loss = 0.0008257930495370275
Trained batch 546 in epoch 8, gen_loss = 1.1479855245166548, disc_loss = 0.0008253183715357028
Trained batch 547 in epoch 8, gen_loss = 1.1479689582203427, disc_loss = 0.0008252131004680125
Trained batch 548 in epoch 8, gen_loss = 1.148127179653918, disc_loss = 0.0008247303081980019
Trained batch 549 in epoch 8, gen_loss = 1.1476711747863075, disc_loss = 0.0008260545541997999
Trained batch 550 in epoch 8, gen_loss = 1.1477303660716422, disc_loss = 0.0008281873233367886
Trained batch 551 in epoch 8, gen_loss = 1.1477276017700417, disc_loss = 0.0008281139748430797
Trained batch 552 in epoch 8, gen_loss = 1.1477102181363925, disc_loss = 0.0008271775321250152
Trained batch 553 in epoch 8, gen_loss = 1.1476617646991991, disc_loss = 0.0008273073036050498
Trained batch 554 in epoch 8, gen_loss = 1.1478951965366397, disc_loss = 0.0008268827269365592
Trained batch 555 in epoch 8, gen_loss = 1.147733389902458, disc_loss = 0.0008269146371845545
Trained batch 556 in epoch 8, gen_loss = 1.1475132295002415, disc_loss = 0.0008275520594253855
Trained batch 557 in epoch 8, gen_loss = 1.1473348683353821, disc_loss = 0.0008266805447921771
Trained batch 558 in epoch 8, gen_loss = 1.1472476189806124, disc_loss = 0.0008258890396622151
Trained batch 559 in epoch 8, gen_loss = 1.1473153371896063, disc_loss = 0.0008259983249964924
Trained batch 560 in epoch 8, gen_loss = 1.1473630738980842, disc_loss = 0.0008251327527819762
Trained batch 561 in epoch 8, gen_loss = 1.1470099797876705, disc_loss = 0.0008246912297815933
Trained batch 562 in epoch 8, gen_loss = 1.1467497793438168, disc_loss = 0.0008241528580850238
Trained batch 563 in epoch 8, gen_loss = 1.1467722030818885, disc_loss = 0.0008232368137530573
Trained batch 564 in epoch 8, gen_loss = 1.1464456589876022, disc_loss = 0.0008224961664156774
Trained batch 565 in epoch 8, gen_loss = 1.1463752140425962, disc_loss = 0.0008219435631894826
Trained batch 566 in epoch 8, gen_loss = 1.1464234291981557, disc_loss = 0.0008214145125385959
Trained batch 567 in epoch 8, gen_loss = 1.1463499407113438, disc_loss = 0.0008210977317042268
Trained batch 568 in epoch 8, gen_loss = 1.1464416065199303, disc_loss = 0.0008204543916222121
Trained batch 569 in epoch 8, gen_loss = 1.1465056245787102, disc_loss = 0.000819676274662478
Trained batch 570 in epoch 8, gen_loss = 1.1463216808339134, disc_loss = 0.0008194235479907702
Trained batch 571 in epoch 8, gen_loss = 1.1465589324911158, disc_loss = 0.0008186575937511438
Trained batch 572 in epoch 8, gen_loss = 1.1463961208053908, disc_loss = 0.0008181885965079082
Trained batch 573 in epoch 8, gen_loss = 1.1465077427206138, disc_loss = 0.0008177177598034697
Trained batch 574 in epoch 8, gen_loss = 1.146319721678029, disc_loss = 0.000816868599301771
Trained batch 575 in epoch 8, gen_loss = 1.146520488171114, disc_loss = 0.0008174189529705069
Trained batch 576 in epoch 8, gen_loss = 1.1462232481875494, disc_loss = 0.0008168482596734199
Trained batch 577 in epoch 8, gen_loss = 1.1459136531014755, disc_loss = 0.0008170397929640996
Trained batch 578 in epoch 8, gen_loss = 1.1462691907026195, disc_loss = 0.0008178339621280553
Trained batch 579 in epoch 8, gen_loss = 1.1459404731618947, disc_loss = 0.0008173966866612819
Trained batch 580 in epoch 8, gen_loss = 1.145642734230488, disc_loss = 0.0008201406490804689
Trained batch 581 in epoch 8, gen_loss = 1.1456366033898187, disc_loss = 0.0008206279795133602
Trained batch 582 in epoch 8, gen_loss = 1.1456198496025176, disc_loss = 0.0008207131820166959
Trained batch 583 in epoch 8, gen_loss = 1.1451931167138767, disc_loss = 0.0008219417395095711
Trained batch 584 in epoch 8, gen_loss = 1.1450918961793948, disc_loss = 0.0008249009398218149
Trained batch 585 in epoch 8, gen_loss = 1.1451559174589736, disc_loss = 0.0008283680485269061
Trained batch 586 in epoch 8, gen_loss = 1.1453175961057414, disc_loss = 0.0008302783261146873
Trained batch 587 in epoch 8, gen_loss = 1.1452695064398708, disc_loss = 0.0008307904633455815
Trained batch 588 in epoch 8, gen_loss = 1.1450311411014031, disc_loss = 0.0008314438286776605
Trained batch 589 in epoch 8, gen_loss = 1.1447806357327155, disc_loss = 0.0008311014081809228
Trained batch 590 in epoch 8, gen_loss = 1.145197963855795, disc_loss = 0.000830331740644012
Trained batch 591 in epoch 8, gen_loss = 1.1448753420766946, disc_loss = 0.0008296009623705145
Trained batch 592 in epoch 8, gen_loss = 1.1451510403047727, disc_loss = 0.0008295306535029366
Trained batch 593 in epoch 8, gen_loss = 1.1452245002844519, disc_loss = 0.0008286308178812209
Trained batch 594 in epoch 8, gen_loss = 1.145110972288276, disc_loss = 0.0008278704413208922
Trained batch 595 in epoch 8, gen_loss = 1.1451123777851961, disc_loss = 0.0008273121650153364
Trained batch 596 in epoch 8, gen_loss = 1.14516524803299, disc_loss = 0.0008267617109836153
Trained batch 597 in epoch 8, gen_loss = 1.1453152513224942, disc_loss = 0.0008267462347500979
Trained batch 598 in epoch 8, gen_loss = 1.1451001001120809, disc_loss = 0.0008261751058299206
Trained batch 599 in epoch 8, gen_loss = 1.1452422747015953, disc_loss = 0.0008257727762975265
Trained batch 600 in epoch 8, gen_loss = 1.1455672599511615, disc_loss = 0.0008249887219357448
Trained batch 601 in epoch 8, gen_loss = 1.1451844414603274, disc_loss = 0.0008243677391789767
Trained batch 602 in epoch 8, gen_loss = 1.1455930558405507, disc_loss = 0.000824120257684581
Trained batch 603 in epoch 8, gen_loss = 1.145611723132481, disc_loss = 0.0008234248030352535
Trained batch 604 in epoch 8, gen_loss = 1.1457645644826338, disc_loss = 0.0008226667475994399
Trained batch 605 in epoch 8, gen_loss = 1.1459102022765886, disc_loss = 0.0008216785297155835
Trained batch 606 in epoch 8, gen_loss = 1.1460314641478033, disc_loss = 0.0008207309134883723
Trained batch 607 in epoch 8, gen_loss = 1.1457982427979772, disc_loss = 0.0008198662569970781
Trained batch 608 in epoch 8, gen_loss = 1.146019891760815, disc_loss = 0.0008189336458211138
Trained batch 609 in epoch 8, gen_loss = 1.1461462747855264, disc_loss = 0.0008182614854227782
Trained batch 610 in epoch 8, gen_loss = 1.1462213226308995, disc_loss = 0.0008175171362601964
Trained batch 611 in epoch 8, gen_loss = 1.1465007497204676, disc_loss = 0.0008167187476704153
Trained batch 612 in epoch 8, gen_loss = 1.146362596584961, disc_loss = 0.0008160119639256844
Trained batch 613 in epoch 8, gen_loss = 1.146595512811058, disc_loss = 0.000815156474861192
Trained batch 614 in epoch 8, gen_loss = 1.1463547878149078, disc_loss = 0.0008147193450192974
Trained batch 615 in epoch 8, gen_loss = 1.1463985573742297, disc_loss = 0.0008139984396644626
Trained batch 616 in epoch 8, gen_loss = 1.1463412478252206, disc_loss = 0.000812946835443539
Trained batch 617 in epoch 8, gen_loss = 1.1464760971879495, disc_loss = 0.0008120889686495231
Trained batch 618 in epoch 8, gen_loss = 1.146259252493524, disc_loss = 0.0008115877854321468
Trained batch 619 in epoch 8, gen_loss = 1.1462128922823938, disc_loss = 0.0008110281332318987
Trained batch 620 in epoch 8, gen_loss = 1.1463013460286766, disc_loss = 0.00081060286447756
Trained batch 621 in epoch 8, gen_loss = 1.1460783342648166, disc_loss = 0.0008103190454041624
Trained batch 622 in epoch 8, gen_loss = 1.1460934472696356, disc_loss = 0.0008100048115618608
Trained batch 623 in epoch 8, gen_loss = 1.1459173112152479, disc_loss = 0.0008098189009848657
Trained batch 624 in epoch 8, gen_loss = 1.1458073441505432, disc_loss = 0.0008105101244291291
Trained batch 625 in epoch 8, gen_loss = 1.1457692326638644, disc_loss = 0.0008110177707432519
Trained batch 626 in epoch 8, gen_loss = 1.1460208412752957, disc_loss = 0.0008109993049702229
Trained batch 627 in epoch 8, gen_loss = 1.1462348366429091, disc_loss = 0.0008102980168036906
Trained batch 628 in epoch 8, gen_loss = 1.1464852544764836, disc_loss = 0.0008093624359149625
Trained batch 629 in epoch 8, gen_loss = 1.1468017743693457, disc_loss = 0.0008086226416967943
Trained batch 630 in epoch 8, gen_loss = 1.1465971006077555, disc_loss = 0.0008086506487875837
Trained batch 631 in epoch 8, gen_loss = 1.1464275020775916, disc_loss = 0.0008084319107195059
Trained batch 632 in epoch 8, gen_loss = 1.1461719644578148, disc_loss = 0.0008077992708744087
Trained batch 633 in epoch 8, gen_loss = 1.1464282807303527, disc_loss = 0.0008072025413771471
Trained batch 634 in epoch 8, gen_loss = 1.1464468027663044, disc_loss = 0.0008067111295646086
Trained batch 635 in epoch 8, gen_loss = 1.1468171183980487, disc_loss = 0.0008067120171696425
Trained batch 636 in epoch 8, gen_loss = 1.146828953381423, disc_loss = 0.0008071287921613398
Trained batch 637 in epoch 8, gen_loss = 1.146556909088057, disc_loss = 0.0008073387224638475
Trained batch 638 in epoch 8, gen_loss = 1.1465933971188624, disc_loss = 0.0008065646537023936
Trained batch 639 in epoch 8, gen_loss = 1.1468166167847813, disc_loss = 0.0008061224152470459
Trained batch 640 in epoch 8, gen_loss = 1.1466495911714254, disc_loss = 0.0008058125370350273
Trained batch 641 in epoch 8, gen_loss = 1.146498902843006, disc_loss = 0.0008052909986623359
Trained batch 642 in epoch 8, gen_loss = 1.1466715168063044, disc_loss = 0.0008052160351601984
Trained batch 643 in epoch 8, gen_loss = 1.1468081806572328, disc_loss = 0.0008051413469447144
Trained batch 644 in epoch 8, gen_loss = 1.1470548575238664, disc_loss = 0.0008048073393825167
Trained batch 645 in epoch 8, gen_loss = 1.1470078258507024, disc_loss = 0.0008040440609455527
Trained batch 646 in epoch 8, gen_loss = 1.1471140597482001, disc_loss = 0.0008031624451236817
Trained batch 647 in epoch 8, gen_loss = 1.1473063930501173, disc_loss = 0.0008025114175661993
Trained batch 648 in epoch 8, gen_loss = 1.1472902510125758, disc_loss = 0.0008016618440931846
Trained batch 649 in epoch 8, gen_loss = 1.1472001918462607, disc_loss = 0.0008011279453281671
Trained batch 650 in epoch 8, gen_loss = 1.1471526264778114, disc_loss = 0.0008013547472943682
Trained batch 651 in epoch 8, gen_loss = 1.1468123637276924, disc_loss = 0.0008007409969036556
Trained batch 652 in epoch 8, gen_loss = 1.1467564351525825, disc_loss = 0.0008003139032657468
Trained batch 653 in epoch 8, gen_loss = 1.1464292075291322, disc_loss = 0.0008007446572083812
Trained batch 654 in epoch 8, gen_loss = 1.1465091920080985, disc_loss = 0.0008005767810302395
Trained batch 655 in epoch 8, gen_loss = 1.1463426131664254, disc_loss = 0.0007996750726794367
Trained batch 656 in epoch 8, gen_loss = 1.146402869594696, disc_loss = 0.0007989997197432681
Trained batch 657 in epoch 8, gen_loss = 1.1463979761651222, disc_loss = 0.0007983582564882614
Trained batch 658 in epoch 8, gen_loss = 1.1466465426866128, disc_loss = 0.0007976578056876942
Trained batch 659 in epoch 8, gen_loss = 1.1462583512970896, disc_loss = 0.0007972870704455118
Trained batch 660 in epoch 8, gen_loss = 1.1463692431731232, disc_loss = 0.0007966220679908847
Trained batch 661 in epoch 8, gen_loss = 1.1464789679043244, disc_loss = 0.000795776370431478
Trained batch 662 in epoch 8, gen_loss = 1.146209282123485, disc_loss = 0.0007950135735262165
Trained batch 663 in epoch 8, gen_loss = 1.1461273552962097, disc_loss = 0.0007943104566991854
Trained batch 664 in epoch 8, gen_loss = 1.1460449232194656, disc_loss = 0.0007936270431575149
Trained batch 665 in epoch 8, gen_loss = 1.14604554367853, disc_loss = 0.0007931943497120252
Trained batch 666 in epoch 8, gen_loss = 1.146249452720339, disc_loss = 0.0007925689543712244
Trained batch 667 in epoch 8, gen_loss = 1.1461915847605575, disc_loss = 0.0007920873507675729
Trained batch 668 in epoch 8, gen_loss = 1.1459629872454655, disc_loss = 0.0007913377311876634
Trained batch 669 in epoch 8, gen_loss = 1.1462141892803248, disc_loss = 0.0007910924905228234
Trained batch 670 in epoch 8, gen_loss = 1.1461691993181822, disc_loss = 0.0007918669850467989
Trained batch 671 in epoch 8, gen_loss = 1.1462940451289927, disc_loss = 0.0007917577078539276
Trained batch 672 in epoch 8, gen_loss = 1.1461846886913984, disc_loss = 0.0007913478299306656
Trained batch 673 in epoch 8, gen_loss = 1.146184343435644, disc_loss = 0.0007911098195654092
Trained batch 674 in epoch 8, gen_loss = 1.146083207130432, disc_loss = 0.0007903659571160528
Trained batch 675 in epoch 8, gen_loss = 1.1458900703128272, disc_loss = 0.0007896618057600672
Trained batch 676 in epoch 8, gen_loss = 1.145958948170593, disc_loss = 0.0007888654403106833
Trained batch 677 in epoch 8, gen_loss = 1.146261702244964, disc_loss = 0.0007882101946913192
Trained batch 678 in epoch 8, gen_loss = 1.146482565266043, disc_loss = 0.0007873469112757785
Trained batch 679 in epoch 8, gen_loss = 1.1466146442820044, disc_loss = 0.0007870092845063054
Trained batch 680 in epoch 8, gen_loss = 1.1462740281955086, disc_loss = 0.0007861302772161814
Trained batch 681 in epoch 8, gen_loss = 1.146344109189825, disc_loss = 0.00078538890584161
Trained batch 682 in epoch 8, gen_loss = 1.1462824222458579, disc_loss = 0.0007847861470482455
Trained batch 683 in epoch 8, gen_loss = 1.1461784877972296, disc_loss = 0.0007841794997988451
Trained batch 684 in epoch 8, gen_loss = 1.145928780788923, disc_loss = 0.0007836613540467976
Trained batch 685 in epoch 8, gen_loss = 1.1460321529092317, disc_loss = 0.0007831202025527648
Trained batch 686 in epoch 8, gen_loss = 1.1460051565191112, disc_loss = 0.0007824954506085394
Trained batch 687 in epoch 8, gen_loss = 1.1459086626594843, disc_loss = 0.00078169565446398
Trained batch 688 in epoch 8, gen_loss = 1.1463264447511194, disc_loss = 0.0007809891404287689
Trained batch 689 in epoch 8, gen_loss = 1.1463235624458479, disc_loss = 0.0007809151295341376
Trained batch 690 in epoch 8, gen_loss = 1.1465944164741229, disc_loss = 0.0007803486685604517
Trained batch 691 in epoch 8, gen_loss = 1.1464528278636106, disc_loss = 0.0007798548750527206
Trained batch 692 in epoch 8, gen_loss = 1.146700803937678, disc_loss = 0.0007798185812964199
Trained batch 693 in epoch 8, gen_loss = 1.1463486898357655, disc_loss = 0.0007801228113345311
Trained batch 694 in epoch 8, gen_loss = 1.145931904007205, disc_loss = 0.0007856160085087159
Trained batch 695 in epoch 8, gen_loss = 1.1461902568223832, disc_loss = 0.0007930548067163507
Trained batch 696 in epoch 8, gen_loss = 1.14619559973179, disc_loss = 0.0008003094994238881
Trained batch 697 in epoch 8, gen_loss = 1.1462373589205537, disc_loss = 0.0008078357682839893
Trained batch 698 in epoch 8, gen_loss = 1.1464015652181765, disc_loss = 0.000811564691538139
Trained batch 699 in epoch 8, gen_loss = 1.1464585545233317, disc_loss = 0.0008131971650332811
Trained batch 700 in epoch 8, gen_loss = 1.1467092240417904, disc_loss = 0.0008140420123707894
Trained batch 701 in epoch 8, gen_loss = 1.1467535241886422, disc_loss = 0.0008138818803359091
Trained batch 702 in epoch 8, gen_loss = 1.1467857850055776, disc_loss = 0.0008135757761635482
Trained batch 703 in epoch 8, gen_loss = 1.1470433853735977, disc_loss = 0.0008143276250559046
Trained batch 704 in epoch 8, gen_loss = 1.146817559637922, disc_loss = 0.000814252904412363
Trained batch 705 in epoch 8, gen_loss = 1.146614313885443, disc_loss = 0.0008136465762012702
Trained batch 706 in epoch 8, gen_loss = 1.1463524162179173, disc_loss = 0.000813650010721567
Trained batch 707 in epoch 8, gen_loss = 1.1462611441558364, disc_loss = 0.0008144818066849865
Trained batch 708 in epoch 8, gen_loss = 1.1461957324879462, disc_loss = 0.0008145252024344062
Trained batch 709 in epoch 8, gen_loss = 1.1460297989173673, disc_loss = 0.0008139240067873583
Trained batch 710 in epoch 8, gen_loss = 1.1459967977722318, disc_loss = 0.0008136199134326332
Trained batch 711 in epoch 8, gen_loss = 1.1458716243505478, disc_loss = 0.0008134346827840121
Trained batch 712 in epoch 8, gen_loss = 1.1460919244760885, disc_loss = 0.0008135450301049564
Trained batch 713 in epoch 8, gen_loss = 1.145820699486078, disc_loss = 0.000813327900839856
Trained batch 714 in epoch 8, gen_loss = 1.1456336718339186, disc_loss = 0.0008125868880953575
Trained batch 715 in epoch 8, gen_loss = 1.1454472595086977, disc_loss = 0.0008127037005919467
Trained batch 716 in epoch 8, gen_loss = 1.1454924303451177, disc_loss = 0.0008141491438122206
Trained batch 717 in epoch 8, gen_loss = 1.1456533124187862, disc_loss = 0.0008141840530228983
Trained batch 718 in epoch 8, gen_loss = 1.1459918542763785, disc_loss = 0.0008142960046086737
Trained batch 719 in epoch 8, gen_loss = 1.1460242749916183, disc_loss = 0.0008137481854040136
Trained batch 720 in epoch 8, gen_loss = 1.1458909013896312, disc_loss = 0.0008136840490083405
Trained batch 721 in epoch 8, gen_loss = 1.1458016742959907, disc_loss = 0.0008141567105715359
Trained batch 722 in epoch 8, gen_loss = 1.1456017302939177, disc_loss = 0.0008147982519191147
Trained batch 723 in epoch 8, gen_loss = 1.145593858884843, disc_loss = 0.0008144112351810037
Trained batch 724 in epoch 8, gen_loss = 1.1453378101875042, disc_loss = 0.0008138038011885986
Trained batch 725 in epoch 8, gen_loss = 1.1453362639285316, disc_loss = 0.0008132038491474369
Trained batch 726 in epoch 8, gen_loss = 1.1454596917927675, disc_loss = 0.0008125707278826544
Trained batch 727 in epoch 8, gen_loss = 1.145435707090975, disc_loss = 0.0008121858913859847
Trained batch 728 in epoch 8, gen_loss = 1.1452006024751806, disc_loss = 0.0008125085204519365
Trained batch 729 in epoch 8, gen_loss = 1.1450581246859406, disc_loss = 0.0008129563410040821
Trained batch 730 in epoch 8, gen_loss = 1.145217356375239, disc_loss = 0.0008132785475927835
Trained batch 731 in epoch 8, gen_loss = 1.1453188431393253, disc_loss = 0.0008127880840722275
Trained batch 732 in epoch 8, gen_loss = 1.1450300722460467, disc_loss = 0.00081252974727954
Trained batch 733 in epoch 8, gen_loss = 1.1451142016158766, disc_loss = 0.0008124542021602126
Trained batch 734 in epoch 8, gen_loss = 1.1450499357820367, disc_loss = 0.0008126234671942016
Trained batch 735 in epoch 8, gen_loss = 1.1452374204021434, disc_loss = 0.0008128023041535926
Trained batch 736 in epoch 8, gen_loss = 1.145247405872578, disc_loss = 0.0008125003103886792
Trained batch 737 in epoch 8, gen_loss = 1.1456519680294563, disc_loss = 0.000812543509697616
Trained batch 738 in epoch 8, gen_loss = 1.1456970034497356, disc_loss = 0.0008125905550980728
Trained batch 739 in epoch 8, gen_loss = 1.1459649914019816, disc_loss = 0.0008124555059751131
Trained batch 740 in epoch 8, gen_loss = 1.1457230501007616, disc_loss = 0.0008119009883909997
Trained batch 741 in epoch 8, gen_loss = 1.1459184139565317, disc_loss = 0.0008112873033925733
Trained batch 742 in epoch 8, gen_loss = 1.1460817060752961, disc_loss = 0.0008112460167893343
Trained batch 743 in epoch 8, gen_loss = 1.145854303433049, disc_loss = 0.0008107518580839506
Trained batch 744 in epoch 8, gen_loss = 1.1458873190335779, disc_loss = 0.0008105172409836965
Trained batch 745 in epoch 8, gen_loss = 1.1460070183385793, disc_loss = 0.0008097302717562133
Trained batch 746 in epoch 8, gen_loss = 1.1460514548951524, disc_loss = 0.0008089420787696795
Trained batch 747 in epoch 8, gen_loss = 1.14610933285346, disc_loss = 0.0008082760540221601
Trained batch 748 in epoch 8, gen_loss = 1.146118311761059, disc_loss = 0.0008074605549495725
Trained batch 749 in epoch 8, gen_loss = 1.1460596459706625, disc_loss = 0.00080685607753306
Trained batch 750 in epoch 8, gen_loss = 1.1461715561730883, disc_loss = 0.0008067608435324192
Trained batch 751 in epoch 8, gen_loss = 1.1458563413074676, disc_loss = 0.0008064807901625519
Trained batch 752 in epoch 8, gen_loss = 1.145697636908269, disc_loss = 0.0008061132727524484
Trained batch 753 in epoch 8, gen_loss = 1.145602472106721, disc_loss = 0.0008057984546441721
Trained batch 754 in epoch 8, gen_loss = 1.1454775694979737, disc_loss = 0.0008053712513481285
Trained batch 755 in epoch 8, gen_loss = 1.146075201412988, disc_loss = 0.0008049145696902458
Trained batch 756 in epoch 8, gen_loss = 1.1459530434488778, disc_loss = 0.0008043656395365332
Trained batch 757 in epoch 8, gen_loss = 1.1460941949746224, disc_loss = 0.0008035004101126912
Trained batch 758 in epoch 8, gen_loss = 1.1460230950467358, disc_loss = 0.0008028691574679295
Trained batch 759 in epoch 8, gen_loss = 1.1460025671281313, disc_loss = 0.000802623989396747
Trained batch 760 in epoch 8, gen_loss = 1.1460209735589648, disc_loss = 0.000802121664538616
Trained batch 761 in epoch 8, gen_loss = 1.1460086894160493, disc_loss = 0.0008014914054483765
Trained batch 762 in epoch 8, gen_loss = 1.1459795169405356, disc_loss = 0.000800881671198512
Trained batch 763 in epoch 8, gen_loss = 1.145671861333997, disc_loss = 0.0008003049453253265
Trained batch 764 in epoch 8, gen_loss = 1.1457215351216934, disc_loss = 0.0007999060695855482
Trained batch 765 in epoch 8, gen_loss = 1.1455754488317524, disc_loss = 0.0008002371304720462
Trained batch 766 in epoch 8, gen_loss = 1.14555761633827, disc_loss = 0.000799623972283539
Trained batch 767 in epoch 8, gen_loss = 1.1458850308942299, disc_loss = 0.000798850520917919
Trained batch 768 in epoch 8, gen_loss = 1.1458307668973629, disc_loss = 0.0007981756471089294
Trained batch 769 in epoch 8, gen_loss = 1.1458880946233676, disc_loss = 0.0007976091143489186
Trained batch 770 in epoch 8, gen_loss = 1.145583774483776, disc_loss = 0.0007973249120664651
Trained batch 771 in epoch 8, gen_loss = 1.1455286098885413, disc_loss = 0.0007973080090980873
Trained batch 772 in epoch 8, gen_loss = 1.145441296029677, disc_loss = 0.0007968943225987013
Trained batch 773 in epoch 8, gen_loss = 1.145655920185168, disc_loss = 0.00079654758571312
Trained batch 774 in epoch 8, gen_loss = 1.1457414537860502, disc_loss = 0.0007963922554289081
Trained batch 775 in epoch 8, gen_loss = 1.1458001494714893, disc_loss = 0.0007959050744267591
Trained batch 776 in epoch 8, gen_loss = 1.1461167643889496, disc_loss = 0.0007951841564728259
Trained batch 777 in epoch 8, gen_loss = 1.1460294496737287, disc_loss = 0.0007944430304389833
Trained batch 778 in epoch 8, gen_loss = 1.1459828815656081, disc_loss = 0.0007938744197622007
Trained batch 779 in epoch 8, gen_loss = 1.1458848120310368, disc_loss = 0.0007933037816166269
Trained batch 780 in epoch 8, gen_loss = 1.145712261926502, disc_loss = 0.0007926664464707843
Trained batch 781 in epoch 8, gen_loss = 1.1458914272315668, disc_loss = 0.0007923436713801837
Trained batch 782 in epoch 8, gen_loss = 1.1457129155082264, disc_loss = 0.0007917629712652879
Trained batch 783 in epoch 8, gen_loss = 1.145797084332729, disc_loss = 0.000791284267803831
Trained batch 784 in epoch 8, gen_loss = 1.1457595144867139, disc_loss = 0.0007907272125394113
Trained batch 785 in epoch 8, gen_loss = 1.1456375619534014, disc_loss = 0.0007900812982650576
Trained batch 786 in epoch 8, gen_loss = 1.1454734322076527, disc_loss = 0.0007894310035828319
Trained batch 787 in epoch 8, gen_loss = 1.1453591108624706, disc_loss = 0.0007888443526218889
Trained batch 788 in epoch 8, gen_loss = 1.1451620139247716, disc_loss = 0.0007886135881816548
Trained batch 789 in epoch 8, gen_loss = 1.1451958851723731, disc_loss = 0.0007885096401832349
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.938174843788147, disc_loss = 0.0006312259938567877
Trained batch 1 in epoch 9, gen_loss = 1.22752046585083, disc_loss = 0.0009415392414666712
Trained batch 2 in epoch 9, gen_loss = 1.2014468510945637, disc_loss = 0.0010766696262483795
Trained batch 3 in epoch 9, gen_loss = 1.1857875883579254, disc_loss = 0.0009621811332181096
Trained batch 4 in epoch 9, gen_loss = 1.1318005323410034, disc_loss = 0.0009385362267494201
Trained batch 5 in epoch 9, gen_loss = 1.1097410122553508, disc_loss = 0.0009301878938761851
Trained batch 6 in epoch 9, gen_loss = 1.1087304864610945, disc_loss = 0.0008497555058316461
Trained batch 7 in epoch 9, gen_loss = 1.0885930061340332, disc_loss = 0.0007839404497644864
Trained batch 8 in epoch 9, gen_loss = 1.1125030252668593, disc_loss = 0.0007487154992607733
Trained batch 9 in epoch 9, gen_loss = 1.1310243368148805, disc_loss = 0.000735245511168614
Trained batch 10 in epoch 9, gen_loss = 1.1299171772870151, disc_loss = 0.0007399695618501441
Trained batch 11 in epoch 9, gen_loss = 1.140594591697057, disc_loss = 0.0007057467785974344
Trained batch 12 in epoch 9, gen_loss = 1.1218711687968328, disc_loss = 0.000682173527401084
Trained batch 13 in epoch 9, gen_loss = 1.1303489463669913, disc_loss = 0.0006517543869059799
Trained batch 14 in epoch 9, gen_loss = 1.140445065498352, disc_loss = 0.0006366175211345156
Trained batch 15 in epoch 9, gen_loss = 1.1371558085083961, disc_loss = 0.0006325649228529073
Trained batch 16 in epoch 9, gen_loss = 1.1589447820887846, disc_loss = 0.0006163149630404351
Trained batch 17 in epoch 9, gen_loss = 1.1541552013821073, disc_loss = 0.0005990732768421165
Trained batch 18 in epoch 9, gen_loss = 1.1535241603851318, disc_loss = 0.0005880345844688188
Trained batch 19 in epoch 9, gen_loss = 1.1476828455924988, disc_loss = 0.0005783729444374331
Trained batch 20 in epoch 9, gen_loss = 1.136908111118135, disc_loss = 0.0005758260640071793
Trained batch 21 in epoch 9, gen_loss = 1.1257044781338086, disc_loss = 0.0005771277395648543
Trained batch 22 in epoch 9, gen_loss = 1.1219849171845808, disc_loss = 0.00057169412510753
Trained batch 23 in epoch 9, gen_loss = 1.1206248104572296, disc_loss = 0.0005634744411509018
Trained batch 24 in epoch 9, gen_loss = 1.116165599822998, disc_loss = 0.0005559663486201316
Trained batch 25 in epoch 9, gen_loss = 1.1202598535097563, disc_loss = 0.0005546103739806523
Trained batch 26 in epoch 9, gen_loss = 1.1246683685867875, disc_loss = 0.0005500700219137663
Trained batch 27 in epoch 9, gen_loss = 1.1275136641093664, disc_loss = 0.0005369334778931391
Trained batch 28 in epoch 9, gen_loss = 1.1361637690971638, disc_loss = 0.0005342751612951016
Trained batch 29 in epoch 9, gen_loss = 1.1309848884741465, disc_loss = 0.0005286638392135501
Trained batch 30 in epoch 9, gen_loss = 1.1280497870137614, disc_loss = 0.0005185522201035412
Trained batch 31 in epoch 9, gen_loss = 1.121927848085761, disc_loss = 0.004368351987977803
Trained batch 32 in epoch 9, gen_loss = 1.1131902553818442, disc_loss = 0.021028417738500248
Trained batch 33 in epoch 9, gen_loss = 1.104895730228985, disc_loss = 0.027478813013123514
Trained batch 34 in epoch 9, gen_loss = 1.1015255945069449, disc_loss = 0.03444865833984555
Trained batch 35 in epoch 9, gen_loss = 1.0965532147222095, disc_loss = 0.04000291537199195
Trained batch 36 in epoch 9, gen_loss = 1.094230914438093, disc_loss = 0.04352401296145635
Trained batch 37 in epoch 9, gen_loss = 1.0915913189712323, disc_loss = 0.045028765132117676
Trained batch 38 in epoch 9, gen_loss = 1.089066268541874, disc_loss = 0.04513454970751459
Trained batch 39 in epoch 9, gen_loss = 1.0877151951193809, disc_loss = 0.045050542415265224
Trained batch 40 in epoch 9, gen_loss = 1.0905020455034768, disc_loss = 0.04515123184239378
Trained batch 41 in epoch 9, gen_loss = 1.0866984597274236, disc_loss = 0.04493015746023351
Trained batch 42 in epoch 9, gen_loss = 1.0923202439796094, disc_loss = 0.044707821279379736
Trained batch 43 in epoch 9, gen_loss = 1.091223875230009, disc_loss = 0.044227349643981805
Trained batch 44 in epoch 9, gen_loss = 1.0952216506004333, disc_loss = 0.04355213015870605
Trained batch 45 in epoch 9, gen_loss = 1.1017312498196312, disc_loss = 0.042925892304755624
Trained batch 46 in epoch 9, gen_loss = 1.1037049559836691, disc_loss = 0.04258810402639705
Trained batch 47 in epoch 9, gen_loss = 1.115977653612693, disc_loss = 0.0423846094909095
Trained batch 48 in epoch 9, gen_loss = 1.1168112669672285, disc_loss = 0.04256499565161327
Trained batch 49 in epoch 9, gen_loss = 1.1174232947826386, disc_loss = 0.041924103189376186
Trained batch 50 in epoch 9, gen_loss = 1.1158551620502097, disc_loss = 0.041382609837455675
Trained batch 51 in epoch 9, gen_loss = 1.1197728801232119, disc_loss = 0.04097723755638491
Trained batch 52 in epoch 9, gen_loss = 1.1204345237534001, disc_loss = 0.04046695413043775
Trained batch 53 in epoch 9, gen_loss = 1.1283224412688502, disc_loss = 0.03990163875547565
Trained batch 54 in epoch 9, gen_loss = 1.126364156332883, disc_loss = 0.039434285570380534
Trained batch 55 in epoch 9, gen_loss = 1.1276221882019724, disc_loss = 0.038911060952419314
Trained batch 56 in epoch 9, gen_loss = 1.1307790561726219, disc_loss = 0.03832017336900575
Trained batch 57 in epoch 9, gen_loss = 1.1319479911491788, disc_loss = 0.03777956075269873
Trained batch 58 in epoch 9, gen_loss = 1.129121865256358, disc_loss = 0.037334206630969105
Trained batch 59 in epoch 9, gen_loss = 1.1304122706254323, disc_loss = 0.03696869873141016
Trained batch 60 in epoch 9, gen_loss = 1.1325520902383523, disc_loss = 0.03643211603907059
Trained batch 61 in epoch 9, gen_loss = 1.1354076150924928, disc_loss = 0.035905517865396704
Trained batch 62 in epoch 9, gen_loss = 1.144054269033765, disc_loss = 0.03541218823732971
Trained batch 63 in epoch 9, gen_loss = 1.1474378891289234, disc_loss = 0.03490597741847523
Trained batch 64 in epoch 9, gen_loss = 1.145384377699632, disc_loss = 0.03451877289603894
Trained batch 65 in epoch 9, gen_loss = 1.1454744013873013, disc_loss = 0.034090201506676916
Trained batch 66 in epoch 9, gen_loss = 1.1474997321171547, disc_loss = 0.033641698688994956
Trained batch 67 in epoch 9, gen_loss = 1.1468176806674284, disc_loss = 0.03322426777766155
Trained batch 68 in epoch 9, gen_loss = 1.1466255239818408, disc_loss = 0.03277521822947428
Trained batch 69 in epoch 9, gen_loss = 1.1493239419800894, disc_loss = 0.03235674217950353
Trained batch 70 in epoch 9, gen_loss = 1.1475147092846079, disc_loss = 0.03198794415425575
Trained batch 71 in epoch 9, gen_loss = 1.1497704552279577, disc_loss = 0.03165467079128979
Trained batch 72 in epoch 9, gen_loss = 1.1494289359001264, disc_loss = 0.03128451363012922
Trained batch 73 in epoch 9, gen_loss = 1.1498664681975905, disc_loss = 0.03090909315545326
Trained batch 74 in epoch 9, gen_loss = 1.1497464116414389, disc_loss = 0.030524569472375637
Trained batch 75 in epoch 9, gen_loss = 1.1507463314031299, disc_loss = 0.03015782336871397
Trained batch 76 in epoch 9, gen_loss = 1.1487704554161469, disc_loss = 0.02988293408544722
Trained batch 77 in epoch 9, gen_loss = 1.149703052563545, disc_loss = 0.029529929915159486
Trained batch 78 in epoch 9, gen_loss = 1.1465475280073625, disc_loss = 0.02920182746182243
Trained batch 79 in epoch 9, gen_loss = 1.1491036869585514, disc_loss = 0.02887272705156647
Trained batch 80 in epoch 9, gen_loss = 1.1508012369826988, disc_loss = 0.02859136830321168
Trained batch 81 in epoch 9, gen_loss = 1.1515914819589474, disc_loss = 0.028313832904464882
Trained batch 82 in epoch 9, gen_loss = 1.1500126705112228, disc_loss = 0.02803815998514295
Trained batch 83 in epoch 9, gen_loss = 1.1490095988625573, disc_loss = 0.027761692044372295
Trained batch 84 in epoch 9, gen_loss = 1.150807213082033, disc_loss = 0.02749368533225018
Trained batch 85 in epoch 9, gen_loss = 1.1515125278816667, disc_loss = 0.02724022888422803
Trained batch 86 in epoch 9, gen_loss = 1.1516725352440758, disc_loss = 0.026968731958721497
Trained batch 87 in epoch 9, gen_loss = 1.1491983905434608, disc_loss = 0.026740621163216103
Trained batch 88 in epoch 9, gen_loss = 1.149981988280007, disc_loss = 0.026469848154366454
Trained batch 89 in epoch 9, gen_loss = 1.1514430661996207, disc_loss = 0.02622951283022606
Trained batch 90 in epoch 9, gen_loss = 1.1505788767730796, disc_loss = 0.025962430437845126
Trained batch 91 in epoch 9, gen_loss = 1.1495861547148747, disc_loss = 0.025710386331965034
Trained batch 92 in epoch 9, gen_loss = 1.1494005822366284, disc_loss = 0.025471111545802384
Trained batch 93 in epoch 9, gen_loss = 1.1478356776085306, disc_loss = 0.02524260778947327
Trained batch 94 in epoch 9, gen_loss = 1.1488370537757873, disc_loss = 0.025034449030461377
Trained batch 95 in epoch 9, gen_loss = 1.1481531156847875, disc_loss = 0.02485623845768714
Trained batch 96 in epoch 9, gen_loss = 1.1503110466544162, disc_loss = 0.024636989873749942
Trained batch 97 in epoch 9, gen_loss = 1.1504897189383605, disc_loss = 0.024544985614757396
Trained batch 98 in epoch 9, gen_loss = 1.154568647495424, disc_loss = 0.02447903941936951
Trained batch 99 in epoch 9, gen_loss = 1.153586785197258, disc_loss = 0.024322062648425343
Trained batch 100 in epoch 9, gen_loss = 1.1564730683175644, disc_loss = 0.0241209862325548
Trained batch 101 in epoch 9, gen_loss = 1.1579078546926087, disc_loss = 0.023922321940464078
Trained batch 102 in epoch 9, gen_loss = 1.1555842328997492, disc_loss = 0.023740413961807736
Trained batch 103 in epoch 9, gen_loss = 1.1534348227656805, disc_loss = 0.023534791088772742
Trained batch 104 in epoch 9, gen_loss = 1.153318685009366, disc_loss = 0.023336218964097846
Trained batch 105 in epoch 9, gen_loss = 1.152604028301419, disc_loss = 0.023141371305067673
Trained batch 106 in epoch 9, gen_loss = 1.1515217646260127, disc_loss = 0.022959483860584984
Trained batch 107 in epoch 9, gen_loss = 1.1502575029929478, disc_loss = 0.022776400454016833
Trained batch 108 in epoch 9, gen_loss = 1.149074470778124, disc_loss = 0.022582348216369903
Trained batch 109 in epoch 9, gen_loss = 1.1488581316037612, disc_loss = 0.022411966711462644
Trained batch 110 in epoch 9, gen_loss = 1.1470522622804384, disc_loss = 0.022265110616121225
Trained batch 111 in epoch 9, gen_loss = 1.1463371408837182, disc_loss = 0.022110744639576296
Trained batch 112 in epoch 9, gen_loss = 1.147388496230134, disc_loss = 0.021932185432035064
Trained batch 113 in epoch 9, gen_loss = 1.1468989650408428, disc_loss = 0.021764297931089492
Trained batch 114 in epoch 9, gen_loss = 1.1477672151897265, disc_loss = 0.02163023003402328
Trained batch 115 in epoch 9, gen_loss = 1.14857335645577, disc_loss = 0.02146278450025671
Trained batch 116 in epoch 9, gen_loss = 1.1487804213140764, disc_loss = 0.021319585842623685
Trained batch 117 in epoch 9, gen_loss = 1.1495847671718922, disc_loss = 0.0211635552589896
Trained batch 118 in epoch 9, gen_loss = 1.1508097277969873, disc_loss = 0.021008594329674345
Trained batch 119 in epoch 9, gen_loss = 1.1514786372582118, disc_loss = 0.0208543881427128
Trained batch 120 in epoch 9, gen_loss = 1.1530208203418195, disc_loss = 0.02069903219581489
Trained batch 121 in epoch 9, gen_loss = 1.154606454685086, disc_loss = 0.020546854288769564
Trained batch 122 in epoch 9, gen_loss = 1.1554250678395837, disc_loss = 0.020391771341986362
Trained batch 123 in epoch 9, gen_loss = 1.1539151110956747, disc_loss = 0.020260968492713742
Trained batch 124 in epoch 9, gen_loss = 1.1531794166564941, disc_loss = 0.020124661992536857
Trained batch 125 in epoch 9, gen_loss = 1.1537909829427326, disc_loss = 0.019985808204861344
Trained batch 126 in epoch 9, gen_loss = 1.1529533130916085, disc_loss = 0.01985672865118868
Trained batch 127 in epoch 9, gen_loss = 1.1517400541342795, disc_loss = 0.01971843522846939
Trained batch 128 in epoch 9, gen_loss = 1.1507762268532153, disc_loss = 0.0195903001010667
Trained batch 129 in epoch 9, gen_loss = 1.1495703568825355, disc_loss = 0.01944556800903788
Trained batch 130 in epoch 9, gen_loss = 1.1525701830405315, disc_loss = 0.019317903898288462
Trained batch 131 in epoch 9, gen_loss = 1.1530619119152878, disc_loss = 0.019201214680365272
Trained batch 132 in epoch 9, gen_loss = 1.1538699094514202, disc_loss = 0.01906652621950261
Trained batch 133 in epoch 9, gen_loss = 1.1540474340097229, disc_loss = 0.018936525204317965
Trained batch 134 in epoch 9, gen_loss = 1.152787372359523, disc_loss = 0.01882487923463082
Trained batch 135 in epoch 9, gen_loss = 1.1517326617065597, disc_loss = 0.018697574837621207
Trained batch 136 in epoch 9, gen_loss = 1.151723932610811, disc_loss = 0.01856599281474873
Trained batch 137 in epoch 9, gen_loss = 1.1517124741837599, disc_loss = 0.01843872323123556
Trained batch 138 in epoch 9, gen_loss = 1.150986717330466, disc_loss = 0.01831133406975293
Trained batch 139 in epoch 9, gen_loss = 1.151180836558342, disc_loss = 0.018184041055792476
Trained batch 140 in epoch 9, gen_loss = 1.1521195524127772, disc_loss = 0.018091349842906963
Trained batch 141 in epoch 9, gen_loss = 1.1510588438578055, disc_loss = 0.01800600531806966
Trained batch 142 in epoch 9, gen_loss = 1.1515509886341495, disc_loss = 0.017899524446754307
Trained batch 143 in epoch 9, gen_loss = 1.152595071742932, disc_loss = 0.01779147442741507
Trained batch 144 in epoch 9, gen_loss = 1.1528061172057842, disc_loss = 0.017689466577802047
Trained batch 145 in epoch 9, gen_loss = 1.1523657967783, disc_loss = 0.017580190543699307
Trained batch 146 in epoch 9, gen_loss = 1.1520821241294446, disc_loss = 0.017471212523294054
Trained batch 147 in epoch 9, gen_loss = 1.1520674885124773, disc_loss = 0.017375193492429192
Trained batch 148 in epoch 9, gen_loss = 1.152099572172101, disc_loss = 0.01727604786666179
Trained batch 149 in epoch 9, gen_loss = 1.1518538518746695, disc_loss = 0.01717794311407488
Trained batch 150 in epoch 9, gen_loss = 1.1513761885908267, disc_loss = 0.017078490772273774
Trained batch 151 in epoch 9, gen_loss = 1.1513793950802402, disc_loss = 0.01697501280413187
Trained batch 152 in epoch 9, gen_loss = 1.150863980545717, disc_loss = 0.016872659374486496
Trained batch 153 in epoch 9, gen_loss = 1.1497711875996033, disc_loss = 0.016773277052486157
Trained batch 154 in epoch 9, gen_loss = 1.1491886888780902, disc_loss = 0.01667127056336481
Trained batch 155 in epoch 9, gen_loss = 1.1485934834449718, disc_loss = 0.016571709512507554
Trained batch 156 in epoch 9, gen_loss = 1.1488297422220752, disc_loss = 0.016470995066712676
Trained batch 157 in epoch 9, gen_loss = 1.1484053002882608, disc_loss = 0.016372734306290264
Trained batch 158 in epoch 9, gen_loss = 1.1495829576966148, disc_loss = 0.01627695451929152
Trained batch 159 in epoch 9, gen_loss = 1.149020779505372, disc_loss = 0.01618208367635816
Trained batch 160 in epoch 9, gen_loss = 1.1486572119760217, disc_loss = 0.01608986167438901
Trained batch 161 in epoch 9, gen_loss = 1.1507031928609919, disc_loss = 0.016005166981442557
Trained batch 162 in epoch 9, gen_loss = 1.149667859808799, disc_loss = 0.015920996134407943
Trained batch 163 in epoch 9, gen_loss = 1.1492582777651346, disc_loss = 0.015837015129630056
Trained batch 164 in epoch 9, gen_loss = 1.148468633854028, disc_loss = 0.01576363097181346
Trained batch 165 in epoch 9, gen_loss = 1.147977633648608, disc_loss = 0.015681327939004053
Trained batch 166 in epoch 9, gen_loss = 1.147394360182528, disc_loss = 0.01559531098230976
Trained batch 167 in epoch 9, gen_loss = 1.146631392694655, disc_loss = 0.01551009031754802
Trained batch 168 in epoch 9, gen_loss = 1.1475678386067498, disc_loss = 0.015425284877908554
Trained batch 169 in epoch 9, gen_loss = 1.1480714187902563, disc_loss = 0.015343767597497551
Trained batch 170 in epoch 9, gen_loss = 1.1476155798337613, disc_loss = 0.015259026544480393
Trained batch 171 in epoch 9, gen_loss = 1.147895341002664, disc_loss = 0.01518349496929955
Trained batch 172 in epoch 9, gen_loss = 1.1466923331938728, disc_loss = 0.015102103718783911
Trained batch 173 in epoch 9, gen_loss = 1.1479451389148319, disc_loss = 0.01502599020173436
Trained batch 174 in epoch 9, gen_loss = 1.1489535093307495, disc_loss = 0.014946940507506952
Trained batch 175 in epoch 9, gen_loss = 1.1481756926937536, disc_loss = 0.01487475427198991
Trained batch 176 in epoch 9, gen_loss = 1.1476555995348483, disc_loss = 0.014799516754110455
Trained batch 177 in epoch 9, gen_loss = 1.1469545967123482, disc_loss = 0.014724786791805273
Trained batch 178 in epoch 9, gen_loss = 1.146012569938958, disc_loss = 0.01465846409623813
Trained batch 179 in epoch 9, gen_loss = 1.1461553944481744, disc_loss = 0.01459488347253581
Trained batch 180 in epoch 9, gen_loss = 1.1463873926447241, disc_loss = 0.014524861300159606
Trained batch 181 in epoch 9, gen_loss = 1.1470530026561612, disc_loss = 0.014449797945377253
Trained batch 182 in epoch 9, gen_loss = 1.1468344816093237, disc_loss = 0.014382279533835616
Trained batch 183 in epoch 9, gen_loss = 1.145481931126636, disc_loss = 0.014320328335483993
Trained batch 184 in epoch 9, gen_loss = 1.1465961984685948, disc_loss = 0.014265876696161875
Trained batch 185 in epoch 9, gen_loss = 1.1470280956196528, disc_loss = 0.014202680215784047
Trained batch 186 in epoch 9, gen_loss = 1.1463373714589817, disc_loss = 0.014133890640497318
Trained batch 187 in epoch 9, gen_loss = 1.1471913101825308, disc_loss = 0.014067108120411348
Trained batch 188 in epoch 9, gen_loss = 1.1472683325015678, disc_loss = 0.014003225086502012
Trained batch 189 in epoch 9, gen_loss = 1.1482382655143737, disc_loss = 0.013942969050472848
Trained batch 190 in epoch 9, gen_loss = 1.148035189868268, disc_loss = 0.01388754584769845
Trained batch 191 in epoch 9, gen_loss = 1.1475191346059244, disc_loss = 0.01382143409970619
Trained batch 192 in epoch 9, gen_loss = 1.1466972238041577, disc_loss = 0.013755599116282827
Trained batch 193 in epoch 9, gen_loss = 1.1472272071027265, disc_loss = 0.013695827339501023
Trained batch 194 in epoch 9, gen_loss = 1.1467864057956598, disc_loss = 0.013640115645158893
Trained batch 195 in epoch 9, gen_loss = 1.1479350483539152, disc_loss = 0.013581795414656695
Trained batch 196 in epoch 9, gen_loss = 1.1472885775082002, disc_loss = 0.013520171936586035
Trained batch 197 in epoch 9, gen_loss = 1.1484599254950127, disc_loss = 0.013457588121651277
Trained batch 198 in epoch 9, gen_loss = 1.148154175760758, disc_loss = 0.013400527513346134
Trained batch 199 in epoch 9, gen_loss = 1.148584427535534, disc_loss = 0.013337959088530624
Trained batch 200 in epoch 9, gen_loss = 1.1478957266949896, disc_loss = 0.013284528514617052
Trained batch 201 in epoch 9, gen_loss = 1.1479666153393169, disc_loss = 0.013223814243931407
Trained batch 202 in epoch 9, gen_loss = 1.147000824582988, disc_loss = 0.013170811770457471
Trained batch 203 in epoch 9, gen_loss = 1.1467288671170963, disc_loss = 0.013114757807474519
Trained batch 204 in epoch 9, gen_loss = 1.1463298515575688, disc_loss = 0.013061548275560731
Trained batch 205 in epoch 9, gen_loss = 1.146993875792883, disc_loss = 0.01300459928164661
Trained batch 206 in epoch 9, gen_loss = 1.1468147059569611, disc_loss = 0.012948905389023728
Trained batch 207 in epoch 9, gen_loss = 1.1455854120162816, disc_loss = 0.012894692462605935
Trained batch 208 in epoch 9, gen_loss = 1.1446076115352686, disc_loss = 0.012838923101203124
Trained batch 209 in epoch 9, gen_loss = 1.1437128762404123, disc_loss = 0.012788781973428004
Trained batch 210 in epoch 9, gen_loss = 1.1433386528661467, disc_loss = 0.01273677959473764
Trained batch 211 in epoch 9, gen_loss = 1.1427898117393818, disc_loss = 0.012688307573866178
Trained batch 212 in epoch 9, gen_loss = 1.1428363885678037, disc_loss = 0.012639974837629736
Trained batch 213 in epoch 9, gen_loss = 1.1440379655806818, disc_loss = 0.012593400776826899
Trained batch 214 in epoch 9, gen_loss = 1.1446627619654632, disc_loss = 0.012542567510553094
Trained batch 215 in epoch 9, gen_loss = 1.1448648094579026, disc_loss = 0.012493271976348263
Trained batch 216 in epoch 9, gen_loss = 1.146779741285034, disc_loss = 0.012442023408183966
Trained batch 217 in epoch 9, gen_loss = 1.1473433443712533, disc_loss = 0.012397281366956864
Trained batch 218 in epoch 9, gen_loss = 1.1473050327061518, disc_loss = 0.012353304139530865
Trained batch 219 in epoch 9, gen_loss = 1.1478711326013913, disc_loss = 0.01230450351206607
Trained batch 220 in epoch 9, gen_loss = 1.14755646324805, disc_loss = 0.012251638946554316
Trained batch 221 in epoch 9, gen_loss = 1.1464057629172866, disc_loss = 0.012208271016674075
Trained batch 222 in epoch 9, gen_loss = 1.1453237565643584, disc_loss = 0.01216578710996003
Trained batch 223 in epoch 9, gen_loss = 1.1442799932722534, disc_loss = 0.012122255381135412
Trained batch 224 in epoch 9, gen_loss = 1.1440119979116652, disc_loss = 0.012080399963306263
Trained batch 225 in epoch 9, gen_loss = 1.1441697960933752, disc_loss = 0.012033267719470237
Trained batch 226 in epoch 9, gen_loss = 1.1438309833866909, disc_loss = 0.0119948592940848
Trained batch 227 in epoch 9, gen_loss = 1.1441104487891782, disc_loss = 0.011946522945404388
Trained batch 228 in epoch 9, gen_loss = 1.143653292062501, disc_loss = 0.011901264555887503
Trained batch 229 in epoch 9, gen_loss = 1.145537036139032, disc_loss = 0.011857706000750035
Trained batch 230 in epoch 9, gen_loss = 1.1454674462219336, disc_loss = 0.011820702764303402
Trained batch 231 in epoch 9, gen_loss = 1.1457738575750385, disc_loss = 0.011803028803115012
Trained batch 232 in epoch 9, gen_loss = 1.148011687231678, disc_loss = 0.01179826586487775
Trained batch 233 in epoch 9, gen_loss = 1.1494375097955394, disc_loss = 0.011769528798365958
Trained batch 234 in epoch 9, gen_loss = 1.1504436297619596, disc_loss = 0.011735479614048444
Trained batch 235 in epoch 9, gen_loss = 1.1512457432888321, disc_loss = 0.011698794132024563
Trained batch 236 in epoch 9, gen_loss = 1.1511381746344425, disc_loss = 0.011658183873836383
Trained batch 237 in epoch 9, gen_loss = 1.1515762723293625, disc_loss = 0.01161530585639167
Trained batch 238 in epoch 9, gen_loss = 1.1517947600476413, disc_loss = 0.011570260179191088
Trained batch 239 in epoch 9, gen_loss = 1.152075619250536, disc_loss = 0.011528105935940402
Trained batch 240 in epoch 9, gen_loss = 1.152919963929663, disc_loss = 0.011491057724924758
Trained batch 241 in epoch 9, gen_loss = 1.1531792265817153, disc_loss = 0.011458560972679445
Trained batch 242 in epoch 9, gen_loss = 1.1533577164995328, disc_loss = 0.011420692558761556
Trained batch 243 in epoch 9, gen_loss = 1.1542881060330594, disc_loss = 0.011382933183249705
Trained batch 244 in epoch 9, gen_loss = 1.1547845803961463, disc_loss = 0.011341068203850859
Trained batch 245 in epoch 9, gen_loss = 1.1560038141603393, disc_loss = 0.01130005751882691
Trained batch 246 in epoch 9, gen_loss = 1.1572655137733892, disc_loss = 0.01125983341169536
Trained batch 247 in epoch 9, gen_loss = 1.1578945375738605, disc_loss = 0.011221802362166683
Trained batch 248 in epoch 9, gen_loss = 1.159459291452385, disc_loss = 0.011184221555419961
Trained batch 249 in epoch 9, gen_loss = 1.160039585828781, disc_loss = 0.011145883879740722
Trained batch 250 in epoch 9, gen_loss = 1.1609771524767476, disc_loss = 0.011105159558824252
Trained batch 251 in epoch 9, gen_loss = 1.1608938350090905, disc_loss = 0.0110862365077732
Trained batch 252 in epoch 9, gen_loss = 1.1615845414960808, disc_loss = 0.011054946806879067
Trained batch 253 in epoch 9, gen_loss = 1.163154200540753, disc_loss = 0.011029369938100218
Trained batch 254 in epoch 9, gen_loss = 1.1629776751293857, disc_loss = 0.01100449630335503
Trained batch 255 in epoch 9, gen_loss = 1.1640496861655265, disc_loss = 0.010979380109006343
Trained batch 256 in epoch 9, gen_loss = 1.1641146531364797, disc_loss = 0.010964022535882375
Trained batch 257 in epoch 9, gen_loss = 1.164451580870059, disc_loss = 0.010948004893793422
Trained batch 258 in epoch 9, gen_loss = 1.1648566214274256, disc_loss = 0.010911913497061523
Trained batch 259 in epoch 9, gen_loss = 1.1653733558379686, disc_loss = 0.010877730671535784
Trained batch 260 in epoch 9, gen_loss = 1.1661249360362231, disc_loss = 0.010838778456561516
Trained batch 261 in epoch 9, gen_loss = 1.1666174592407605, disc_loss = 0.010803583539193248
Trained batch 262 in epoch 9, gen_loss = 1.168280974767054, disc_loss = 0.010770125284382875
Trained batch 263 in epoch 9, gen_loss = 1.1683446126002255, disc_loss = 0.010740357694444494
Trained batch 264 in epoch 9, gen_loss = 1.1700524606794682, disc_loss = 0.010726087376857528
Trained batch 265 in epoch 9, gen_loss = 1.170361238986926, disc_loss = 0.010715659128224541
Trained batch 266 in epoch 9, gen_loss = 1.1700835038213695, disc_loss = 0.01067943963619413
Trained batch 267 in epoch 9, gen_loss = 1.170509814993659, disc_loss = 0.010650416474625184
Trained batch 268 in epoch 9, gen_loss = 1.1706618524838557, disc_loss = 0.010615665713895535
Trained batch 269 in epoch 9, gen_loss = 1.1714029318756527, disc_loss = 0.010581706271881961
Trained batch 270 in epoch 9, gen_loss = 1.171671293538435, disc_loss = 0.010552322358727228
Trained batch 271 in epoch 9, gen_loss = 1.171857140300905, disc_loss = 0.010521331359354114
Trained batch 272 in epoch 9, gen_loss = 1.1725106678166233, disc_loss = 0.010486367070853826
Trained batch 273 in epoch 9, gen_loss = 1.172199700653118, disc_loss = 0.010452585559220216
Trained batch 274 in epoch 9, gen_loss = 1.1733454485373063, disc_loss = 0.010418907411248339
Trained batch 275 in epoch 9, gen_loss = 1.1740299331537192, disc_loss = 0.010384635210515547
Trained batch 276 in epoch 9, gen_loss = 1.1739474494104352, disc_loss = 0.01034983961423943
Trained batch 277 in epoch 9, gen_loss = 1.173826217436962, disc_loss = 0.010314867086687607
Trained batch 278 in epoch 9, gen_loss = 1.1742226853165576, disc_loss = 0.010281942130836715
Trained batch 279 in epoch 9, gen_loss = 1.174562683062894, disc_loss = 0.010247505592061706
Trained batch 280 in epoch 9, gen_loss = 1.1740778729160486, disc_loss = 0.01021517289699274
Trained batch 281 in epoch 9, gen_loss = 1.1743006839397105, disc_loss = 0.010181217740355093
Trained batch 282 in epoch 9, gen_loss = 1.1737975233856444, disc_loss = 0.010148927599315898
Trained batch 283 in epoch 9, gen_loss = 1.174199010494729, disc_loss = 0.010116199746258183
Trained batch 284 in epoch 9, gen_loss = 1.1753670523041173, disc_loss = 0.01008274229682508
Trained batch 285 in epoch 9, gen_loss = 1.1762163853728689, disc_loss = 0.010051468274392468
Trained batch 286 in epoch 9, gen_loss = 1.1782459321753074, disc_loss = 0.010024603510917187
Trained batch 287 in epoch 9, gen_loss = 1.1787478358795245, disc_loss = 0.009997419487768234
Trained batch 288 in epoch 9, gen_loss = 1.1782016785087057, disc_loss = 0.009966154487631976
Trained batch 289 in epoch 9, gen_loss = 1.1786245027492785, disc_loss = 0.009944917787376245
Trained batch 290 in epoch 9, gen_loss = 1.1794338547896683, disc_loss = 0.009915218860870292
Trained batch 291 in epoch 9, gen_loss = 1.1804665488331285, disc_loss = 0.009886022231661976
Trained batch 292 in epoch 9, gen_loss = 1.1811598280997813, disc_loss = 0.009855177682493067
Trained batch 293 in epoch 9, gen_loss = 1.1819970990930284, disc_loss = 0.009824785931438974
Trained batch 294 in epoch 9, gen_loss = 1.1816008400108855, disc_loss = 0.009795393717921165
Trained batch 295 in epoch 9, gen_loss = 1.1810999619396958, disc_loss = 0.009766322780558619
Trained batch 296 in epoch 9, gen_loss = 1.1811420967683246, disc_loss = 0.00974228626765038
Trained batch 297 in epoch 9, gen_loss = 1.1804883434068436, disc_loss = 0.00971467733852356
Trained batch 298 in epoch 9, gen_loss = 1.1804734657839389, disc_loss = 0.00968594315399908
Trained batch 299 in epoch 9, gen_loss = 1.180957604845365, disc_loss = 0.009657924762868787
Trained batch 300 in epoch 9, gen_loss = 1.1808840359168196, disc_loss = 0.009629401972109724
Trained batch 301 in epoch 9, gen_loss = 1.1803029051284917, disc_loss = 0.00961243901804586
Trained batch 302 in epoch 9, gen_loss = 1.1804231662954827, disc_loss = 0.009584863634150715
Trained batch 303 in epoch 9, gen_loss = 1.1803664841542119, disc_loss = 0.0095635827273279
Trained batch 304 in epoch 9, gen_loss = 1.1804537016837324, disc_loss = 0.0095342674411902
Trained batch 305 in epoch 9, gen_loss = 1.1809935645729888, disc_loss = 0.009506851862039374
Trained batch 306 in epoch 9, gen_loss = 1.1812601906857196, disc_loss = 0.009486238641003814
Trained batch 307 in epoch 9, gen_loss = 1.1811091963733946, disc_loss = 0.009463313779987957
Trained batch 308 in epoch 9, gen_loss = 1.1816318249239506, disc_loss = 0.009443220647498755
Trained batch 309 in epoch 9, gen_loss = 1.1815205733622274, disc_loss = 0.0094206821080485
Trained batch 310 in epoch 9, gen_loss = 1.181648185207146, disc_loss = 0.009394658286700181
Trained batch 311 in epoch 9, gen_loss = 1.1815501514535685, disc_loss = 0.009366714115085181
Trained batch 312 in epoch 9, gen_loss = 1.1818535002275778, disc_loss = 0.009339096603640608
Trained batch 313 in epoch 9, gen_loss = 1.1816975339582771, disc_loss = 0.009315947089533346
Trained batch 314 in epoch 9, gen_loss = 1.182011323694199, disc_loss = 0.009295554010711226
Trained batch 315 in epoch 9, gen_loss = 1.1818194146020502, disc_loss = 0.009270068510311001
Trained batch 316 in epoch 9, gen_loss = 1.1818525529810306, disc_loss = 0.00924353702983537
Trained batch 317 in epoch 9, gen_loss = 1.1820458280590345, disc_loss = 0.009217722468724644
Trained batch 318 in epoch 9, gen_loss = 1.1828721501984192, disc_loss = 0.00919286492541593
Trained batch 319 in epoch 9, gen_loss = 1.1826609285548328, disc_loss = 0.009169498957180621
Trained batch 320 in epoch 9, gen_loss = 1.1829032001094284, disc_loss = 0.009145597615652801
Trained batch 321 in epoch 9, gen_loss = 1.1834490056733908, disc_loss = 0.009124360517551689
Trained batch 322 in epoch 9, gen_loss = 1.1840311427234496, disc_loss = 0.009098967222908465
Trained batch 323 in epoch 9, gen_loss = 1.1842945602572994, disc_loss = 0.009075830008868375
Trained batch 324 in epoch 9, gen_loss = 1.1837257390755873, disc_loss = 0.009055468911000598
Trained batch 325 in epoch 9, gen_loss = 1.1841628439952991, disc_loss = 0.009035285878223024
Trained batch 326 in epoch 9, gen_loss = 1.1842771806848158, disc_loss = 0.009011806452640443
Trained batch 327 in epoch 9, gen_loss = 1.1845411700082988, disc_loss = 0.00898627011648808
Trained batch 328 in epoch 9, gen_loss = 1.1839802422784382, disc_loss = 0.008962749840679655
Trained batch 329 in epoch 9, gen_loss = 1.1840076278556477, disc_loss = 0.008937515197480522
Trained batch 330 in epoch 9, gen_loss = 1.184219870142346, disc_loss = 0.00891324264896693
Trained batch 331 in epoch 9, gen_loss = 1.1849260953176453, disc_loss = 0.008888827875015994
Trained batch 332 in epoch 9, gen_loss = 1.185040592968285, disc_loss = 0.008864538962152219
Trained batch 333 in epoch 9, gen_loss = 1.1849603397760562, disc_loss = 0.00883912122649807
Trained batch 334 in epoch 9, gen_loss = 1.1844583655471232, disc_loss = 0.008814791096252765
Trained batch 335 in epoch 9, gen_loss = 1.1844119885492892, disc_loss = 0.008792077863420542
Trained batch 336 in epoch 9, gen_loss = 1.1849653531606543, disc_loss = 0.008767990073557386
Trained batch 337 in epoch 9, gen_loss = 1.185188980673897, disc_loss = 0.008743849903370595
Trained batch 338 in epoch 9, gen_loss = 1.1843527159859648, disc_loss = 0.008747364364919503
Trained batch 339 in epoch 9, gen_loss = 1.184275449900066, disc_loss = 0.008736597565225298
Trained batch 340 in epoch 9, gen_loss = 1.1839490490924578, disc_loss = 0.008714691333044621
Trained batch 341 in epoch 9, gen_loss = 1.18417614158134, disc_loss = 0.008694869158833766
Trained batch 342 in epoch 9, gen_loss = 1.1835966297905924, disc_loss = 0.008676417723570274
Trained batch 343 in epoch 9, gen_loss = 1.1839678141959877, disc_loss = 0.008654679348817512
Trained batch 344 in epoch 9, gen_loss = 1.1837528923283454, disc_loss = 0.008632852442552456
Trained batch 345 in epoch 9, gen_loss = 1.1833968369257932, disc_loss = 0.008612008547061123
Trained batch 346 in epoch 9, gen_loss = 1.1836837832453615, disc_loss = 0.008591401771597312
Trained batch 347 in epoch 9, gen_loss = 1.1838078228221542, disc_loss = 0.008570676880982977
Trained batch 348 in epoch 9, gen_loss = 1.1849900238151878, disc_loss = 0.00855902251248771
Trained batch 349 in epoch 9, gen_loss = 1.185774792603084, disc_loss = 0.008541696433593253
Trained batch 350 in epoch 9, gen_loss = 1.1858483512177427, disc_loss = 0.008520182939607815
Trained batch 351 in epoch 9, gen_loss = 1.1859782141717998, disc_loss = 0.008500687455290807
Trained batch 352 in epoch 9, gen_loss = 1.1867528633760662, disc_loss = 0.008482277894701951
Trained batch 353 in epoch 9, gen_loss = 1.1867477055323326, disc_loss = 0.008462933078358912
Trained batch 354 in epoch 9, gen_loss = 1.188402881420834, disc_loss = 0.008446085427536852
Trained batch 355 in epoch 9, gen_loss = 1.1882211545879922, disc_loss = 0.008431138394330497
Trained batch 356 in epoch 9, gen_loss = 1.1884494806204189, disc_loss = 0.008415143333681329
Trained batch 357 in epoch 9, gen_loss = 1.1889690084164368, disc_loss = 0.008395051637709313
Trained batch 358 in epoch 9, gen_loss = 1.1887849821685748, disc_loss = 0.008375147992597821
Trained batch 359 in epoch 9, gen_loss = 1.189289434419738, disc_loss = 0.008355301202148743
Trained batch 360 in epoch 9, gen_loss = 1.1896022201575072, disc_loss = 0.008337480113522339
Trained batch 361 in epoch 9, gen_loss = 1.1897673893370022, disc_loss = 0.008321128014519487
Trained batch 362 in epoch 9, gen_loss = 1.1897346181974595, disc_loss = 0.008300625132323056
Trained batch 363 in epoch 9, gen_loss = 1.19002399962027, disc_loss = 0.008282517253534464
Trained batch 364 in epoch 9, gen_loss = 1.1900814075992532, disc_loss = 0.008266721093430733
Trained batch 365 in epoch 9, gen_loss = 1.1903488649045184, disc_loss = 0.008246602885195442
Trained batch 366 in epoch 9, gen_loss = 1.1901421891246244, disc_loss = 0.00822893879463584
Trained batch 367 in epoch 9, gen_loss = 1.1896972494280857, disc_loss = 0.008211982909968989
Trained batch 368 in epoch 9, gen_loss = 1.1898211754434478, disc_loss = 0.008195233136541046
Trained batch 369 in epoch 9, gen_loss = 1.1900858125171145, disc_loss = 0.008176794610020856
Trained batch 370 in epoch 9, gen_loss = 1.1905016478181207, disc_loss = 0.008157764326368716
Trained batch 371 in epoch 9, gen_loss = 1.1904111969214615, disc_loss = 0.008138175426074179
Trained batch 372 in epoch 9, gen_loss = 1.1908676934306168, disc_loss = 0.008122684443497471
Trained batch 373 in epoch 9, gen_loss = 1.1905336517063692, disc_loss = 0.008108059514670652
Trained batch 374 in epoch 9, gen_loss = 1.1905168110529583, disc_loss = 0.008089010802020008
Trained batch 375 in epoch 9, gen_loss = 1.1904949327098562, disc_loss = 0.008070335000121168
Trained batch 376 in epoch 9, gen_loss = 1.1907087289370024, disc_loss = 0.00805347257925862
Trained batch 377 in epoch 9, gen_loss = 1.1903246146030526, disc_loss = 0.008035575322022726
Trained batch 378 in epoch 9, gen_loss = 1.1904506453738048, disc_loss = 0.00801732865588231
Trained batch 379 in epoch 9, gen_loss = 1.1911496460437774, disc_loss = 0.00800007117634921
Trained batch 380 in epoch 9, gen_loss = 1.191162370634204, disc_loss = 0.007983968906294618
Trained batch 381 in epoch 9, gen_loss = 1.191349695802359, disc_loss = 0.007965097293066938
Trained batch 382 in epoch 9, gen_loss = 1.1913780973100787, disc_loss = 0.007946211424234928
Trained batch 383 in epoch 9, gen_loss = 1.1911349799484015, disc_loss = 0.007929424287112852
Trained batch 384 in epoch 9, gen_loss = 1.191503888291198, disc_loss = 0.007911267422227334
Trained batch 385 in epoch 9, gen_loss = 1.1918444182588646, disc_loss = 0.007894498660181494
Trained batch 386 in epoch 9, gen_loss = 1.1917757002266187, disc_loss = 0.007875791361669165
Trained batch 387 in epoch 9, gen_loss = 1.1924240042253869, disc_loss = 0.007858658746588788
Trained batch 388 in epoch 9, gen_loss = 1.1918895741048385, disc_loss = 0.007841637705594593
Trained batch 389 in epoch 9, gen_loss = 1.1920091103284787, disc_loss = 0.007823970066368556
Trained batch 390 in epoch 9, gen_loss = 1.1921586246441698, disc_loss = 0.007809764405702363
Trained batch 391 in epoch 9, gen_loss = 1.191922588311896, disc_loss = 0.007794136555888571
Trained batch 392 in epoch 9, gen_loss = 1.192041621256724, disc_loss = 0.007777399050161294
Trained batch 393 in epoch 9, gen_loss = 1.1918773439329893, disc_loss = 0.007759802203213555
Trained batch 394 in epoch 9, gen_loss = 1.1914607011819187, disc_loss = 0.00774205240201429
Trained batch 395 in epoch 9, gen_loss = 1.1913332460504589, disc_loss = 0.007724410438815466
Trained batch 396 in epoch 9, gen_loss = 1.191302363157873, disc_loss = 0.007707565305540479
Trained batch 397 in epoch 9, gen_loss = 1.1909846067428589, disc_loss = 0.007689751204744978
Trained batch 398 in epoch 9, gen_loss = 1.191336985518759, disc_loss = 0.007675995136203272
Trained batch 399 in epoch 9, gen_loss = 1.191549859046936, disc_loss = 0.007660417321967543
Trained batch 400 in epoch 9, gen_loss = 1.1916386126877363, disc_loss = 0.00764251602536353
Trained batch 401 in epoch 9, gen_loss = 1.1911877651712788, disc_loss = 0.0076251668430284475
Trained batch 402 in epoch 9, gen_loss = 1.191013618083509, disc_loss = 0.0076080967464037105
Trained batch 403 in epoch 9, gen_loss = 1.1909733370389088, disc_loss = 0.007591721621883161
Trained batch 404 in epoch 9, gen_loss = 1.1905298645113722, disc_loss = 0.007575509178000905
Trained batch 405 in epoch 9, gen_loss = 1.1905662120856675, disc_loss = 0.007558440952518785
Trained batch 406 in epoch 9, gen_loss = 1.1904609469875365, disc_loss = 0.00754190018637671
Trained batch 407 in epoch 9, gen_loss = 1.1904248726718567, disc_loss = 0.007524818424166833
Trained batch 408 in epoch 9, gen_loss = 1.191005784025402, disc_loss = 0.007509349245839345
Trained batch 409 in epoch 9, gen_loss = 1.1913635210293094, disc_loss = 0.007492213189479804
Trained batch 410 in epoch 9, gen_loss = 1.1909608785833465, disc_loss = 0.007475824002757183
Trained batch 411 in epoch 9, gen_loss = 1.1906267453744575, disc_loss = 0.007459625484293566
Trained batch 412 in epoch 9, gen_loss = 1.190004782295689, disc_loss = 0.007442890655784361
Trained batch 413 in epoch 9, gen_loss = 1.1900113665539285, disc_loss = 0.007426095305976305
Trained batch 414 in epoch 9, gen_loss = 1.1903981949909623, disc_loss = 0.0074101610916403
Trained batch 415 in epoch 9, gen_loss = 1.190635007734482, disc_loss = 0.007393835041581882
Trained batch 416 in epoch 9, gen_loss = 1.1904081898055774, disc_loss = 0.007377477683312856
Trained batch 417 in epoch 9, gen_loss = 1.1905088966543025, disc_loss = 0.007362008821617469
Trained batch 418 in epoch 9, gen_loss = 1.1908139232234909, disc_loss = 0.007345427480873014
Trained batch 419 in epoch 9, gen_loss = 1.1914247456051055, disc_loss = 0.00733140953206679
Trained batch 420 in epoch 9, gen_loss = 1.1915399586503126, disc_loss = 0.0073150943597223425
Trained batch 421 in epoch 9, gen_loss = 1.1911163050416522, disc_loss = 0.007301732241060205
Trained batch 422 in epoch 9, gen_loss = 1.1907572236185096, disc_loss = 0.007285286143384148
Trained batch 423 in epoch 9, gen_loss = 1.1906307286249016, disc_loss = 0.00726950680267314
Trained batch 424 in epoch 9, gen_loss = 1.190742085681242, disc_loss = 0.007253759812413003
Trained batch 425 in epoch 9, gen_loss = 1.1904470685502173, disc_loss = 0.007237821615310911
Trained batch 426 in epoch 9, gen_loss = 1.1906810809075135, disc_loss = 0.007222336645928414
Trained batch 427 in epoch 9, gen_loss = 1.1904209437214326, disc_loss = 0.007206383008383667
Trained batch 428 in epoch 9, gen_loss = 1.190426493858124, disc_loss = 0.0071904120401268725
Trained batch 429 in epoch 9, gen_loss = 1.1897731151691704, disc_loss = 0.007174860370659464
Trained batch 430 in epoch 9, gen_loss = 1.1899526116466301, disc_loss = 0.007159051429785533
Trained batch 431 in epoch 9, gen_loss = 1.1897013052194207, disc_loss = 0.007143801732025976
Trained batch 432 in epoch 9, gen_loss = 1.18968765702589, disc_loss = 0.007128503205919828
Trained batch 433 in epoch 9, gen_loss = 1.189257701970465, disc_loss = 0.00711290907440117
Trained batch 434 in epoch 9, gen_loss = 1.188832746429005, disc_loss = 0.007097592318749012
Trained batch 435 in epoch 9, gen_loss = 1.1887082370049362, disc_loss = 0.0070820518622069124
Trained batch 436 in epoch 9, gen_loss = 1.188937275033248, disc_loss = 0.007066442836110653
Trained batch 437 in epoch 9, gen_loss = 1.1885181943031207, disc_loss = 0.007051375284262073
Trained batch 438 in epoch 9, gen_loss = 1.1880511255905133, disc_loss = 0.007036062364600671
Trained batch 439 in epoch 9, gen_loss = 1.1882792582566089, disc_loss = 0.007023528412008256
Trained batch 440 in epoch 9, gen_loss = 1.1885820620454628, disc_loss = 0.007008817540721909
Trained batch 441 in epoch 9, gen_loss = 1.1878489299057835, disc_loss = 0.0069939521125152206
Trained batch 442 in epoch 9, gen_loss = 1.1881994902414876, disc_loss = 0.006979308476286328
Trained batch 443 in epoch 9, gen_loss = 1.187966385403195, disc_loss = 0.006964231275511289
Trained batch 444 in epoch 9, gen_loss = 1.1877598722329301, disc_loss = 0.006949698284407032
Trained batch 445 in epoch 9, gen_loss = 1.187480664306692, disc_loss = 0.006935484767977604
Trained batch 446 in epoch 9, gen_loss = 1.187159015828331, disc_loss = 0.0069216619104681375
Trained batch 447 in epoch 9, gen_loss = 1.187275965032833, disc_loss = 0.006907067275733425
Trained batch 448 in epoch 9, gen_loss = 1.1870364633063166, disc_loss = 0.006892517912276774
Trained batch 449 in epoch 9, gen_loss = 1.1864664469824897, disc_loss = 0.006878081824591694
Trained batch 450 in epoch 9, gen_loss = 1.185992153150808, disc_loss = 0.006863784836205094
Trained batch 451 in epoch 9, gen_loss = 1.1861547057607533, disc_loss = 0.006850846605058615
Trained batch 452 in epoch 9, gen_loss = 1.1861467419344331, disc_loss = 0.006837598254318734
Trained batch 453 in epoch 9, gen_loss = 1.1858265641502346, disc_loss = 0.006823968422860174
Trained batch 454 in epoch 9, gen_loss = 1.1850849777787595, disc_loss = 0.006809989734204834
Trained batch 455 in epoch 9, gen_loss = 1.184878461455044, disc_loss = 0.0067963794398677065
Trained batch 456 in epoch 9, gen_loss = 1.1845666097081724, disc_loss = 0.006783029949241593
Trained batch 457 in epoch 9, gen_loss = 1.1842133111308235, disc_loss = 0.006769254583027621
Trained batch 458 in epoch 9, gen_loss = 1.1841316537399957, disc_loss = 0.00675528374546733
Trained batch 459 in epoch 9, gen_loss = 1.1838516792525415, disc_loss = 0.00674215841319655
Trained batch 460 in epoch 9, gen_loss = 1.184532236121999, disc_loss = 0.006729397178807351
Trained batch 461 in epoch 9, gen_loss = 1.1843664762261625, disc_loss = 0.006715821717725664
Trained batch 462 in epoch 9, gen_loss = 1.1840145770725885, disc_loss = 0.006702029796595812
Trained batch 463 in epoch 9, gen_loss = 1.1840832767815426, disc_loss = 0.006688213917092573
Trained batch 464 in epoch 9, gen_loss = 1.1838517178771317, disc_loss = 0.006674535226099373
Trained batch 465 in epoch 9, gen_loss = 1.1834652620835366, disc_loss = 0.006661670198856429
Trained batch 466 in epoch 9, gen_loss = 1.1828463394075186, disc_loss = 0.006648277727315179
Trained batch 467 in epoch 9, gen_loss = 1.1830138375616481, disc_loss = 0.00663559937270798
Trained batch 468 in epoch 9, gen_loss = 1.1829539176497632, disc_loss = 0.006622981513725784
Trained batch 469 in epoch 9, gen_loss = 1.1827978486710407, disc_loss = 0.006609676157909525
Trained batch 470 in epoch 9, gen_loss = 1.1825504571262693, disc_loss = 0.006596722390026649
Trained batch 471 in epoch 9, gen_loss = 1.1824761765488123, disc_loss = 0.006584597824936066
Trained batch 472 in epoch 9, gen_loss = 1.1824516448611688, disc_loss = 0.0065716561977259315
Trained batch 473 in epoch 9, gen_loss = 1.1826220532006855, disc_loss = 0.006558972007333682
Trained batch 474 in epoch 9, gen_loss = 1.1821382700769525, disc_loss = 0.006546910232496693
Trained batch 475 in epoch 9, gen_loss = 1.1817114728839457, disc_loss = 0.006534197507499514
Trained batch 476 in epoch 9, gen_loss = 1.1814166619842656, disc_loss = 0.0065219958078026365
Trained batch 477 in epoch 9, gen_loss = 1.1817494219317097, disc_loss = 0.0065090299625252665
Trained batch 478 in epoch 9, gen_loss = 1.1813991801474935, disc_loss = 0.006496657302230305
Trained batch 479 in epoch 9, gen_loss = 1.1809182579318682, disc_loss = 0.006484024414688368
Trained batch 480 in epoch 9, gen_loss = 1.1809738698471608, disc_loss = 0.006471600834962287
Trained batch 481 in epoch 9, gen_loss = 1.180859931771686, disc_loss = 0.00645920289848222
Trained batch 482 in epoch 9, gen_loss = 1.1808664142221645, disc_loss = 0.006446510769379099
Trained batch 483 in epoch 9, gen_loss = 1.180556331784272, disc_loss = 0.006433946493311212
Trained batch 484 in epoch 9, gen_loss = 1.1801249565537444, disc_loss = 0.006421501439523201
Trained batch 485 in epoch 9, gen_loss = 1.1795620000902027, disc_loss = 0.006409402773751486
Trained batch 486 in epoch 9, gen_loss = 1.1791457297620833, disc_loss = 0.006397023460936773
Trained batch 487 in epoch 9, gen_loss = 1.178883071072766, disc_loss = 0.006384844729747455
Trained batch 488 in epoch 9, gen_loss = 1.1785001896154172, disc_loss = 0.006373346398978785
Trained batch 489 in epoch 9, gen_loss = 1.1789676162661338, disc_loss = 0.006361912644458745
Trained batch 490 in epoch 9, gen_loss = 1.1789700266300054, disc_loss = 0.006349795647207344
Trained batch 491 in epoch 9, gen_loss = 1.1790148942935756, disc_loss = 0.006337732202998113
Trained batch 492 in epoch 9, gen_loss = 1.1791087710591408, disc_loss = 0.006326765400186582
Trained batch 493 in epoch 9, gen_loss = 1.178612980282741, disc_loss = 0.006315512677512286
Trained batch 494 in epoch 9, gen_loss = 1.1787315782874521, disc_loss = 0.006303637446671009
Trained batch 495 in epoch 9, gen_loss = 1.1785464003201453, disc_loss = 0.0062917821840880695
Trained batch 496 in epoch 9, gen_loss = 1.1783600054996115, disc_loss = 0.006281541023891554
Trained batch 497 in epoch 9, gen_loss = 1.178185236023133, disc_loss = 0.006270908973021732
Trained batch 498 in epoch 9, gen_loss = 1.1781685194653835, disc_loss = 0.006259398041703628
Trained batch 499 in epoch 9, gen_loss = 1.177757993221283, disc_loss = 0.00624791837844532
Trained batch 500 in epoch 9, gen_loss = 1.1775023056837375, disc_loss = 0.00623608212462606
Trained batch 501 in epoch 9, gen_loss = 1.177001448029066, disc_loss = 0.0062251573394189975
Trained batch 502 in epoch 9, gen_loss = 1.1769074609218013, disc_loss = 0.006213503196570748
Trained batch 503 in epoch 9, gen_loss = 1.1766879182486307, disc_loss = 0.0062017987656295265
Trained batch 504 in epoch 9, gen_loss = 1.1765660529089446, disc_loss = 0.006190217895223529
Trained batch 505 in epoch 9, gen_loss = 1.1763664858614502, disc_loss = 0.006178410710518896
Trained batch 506 in epoch 9, gen_loss = 1.1762005147143935, disc_loss = 0.006166921358675415
Trained batch 507 in epoch 9, gen_loss = 1.1761017373697025, disc_loss = 0.006156771884065609
Trained batch 508 in epoch 9, gen_loss = 1.175676054008349, disc_loss = 0.006145843138247235
Trained batch 509 in epoch 9, gen_loss = 1.175610327720642, disc_loss = 0.006135193193297121
Trained batch 510 in epoch 9, gen_loss = 1.1756671548122997, disc_loss = 0.006124701263274133
Trained batch 511 in epoch 9, gen_loss = 1.1754917702637613, disc_loss = 0.006113236765656893
Trained batch 512 in epoch 9, gen_loss = 1.175333799674497, disc_loss = 0.006102234933690529
Trained batch 513 in epoch 9, gen_loss = 1.1749200374467828, disc_loss = 0.0060911203039482106
Trained batch 514 in epoch 9, gen_loss = 1.1745812651023124, disc_loss = 0.006081899036585525
Trained batch 515 in epoch 9, gen_loss = 1.174518342974574, disc_loss = 0.006071260141081523
Trained batch 516 in epoch 9, gen_loss = 1.1745096446236514, disc_loss = 0.006062201451130997
Trained batch 517 in epoch 9, gen_loss = 1.1744737757448984, disc_loss = 0.006051486954731241
Trained batch 518 in epoch 9, gen_loss = 1.1745545911191746, disc_loss = 0.006041210095634996
Trained batch 519 in epoch 9, gen_loss = 1.174410466162058, disc_loss = 0.00603076847317145
Trained batch 520 in epoch 9, gen_loss = 1.17420118703952, disc_loss = 0.006020162541588193
Trained batch 521 in epoch 9, gen_loss = 1.1738878507952124, disc_loss = 0.0060091900124733776
Trained batch 522 in epoch 9, gen_loss = 1.1737115662366893, disc_loss = 0.005998118589681183
Trained batch 523 in epoch 9, gen_loss = 1.173526362494658, disc_loss = 0.005987486271118792
Trained batch 524 in epoch 9, gen_loss = 1.173358517714909, disc_loss = 0.005977233250215206
Trained batch 525 in epoch 9, gen_loss = 1.172888100940465, disc_loss = 0.005967003671519242
Trained batch 526 in epoch 9, gen_loss = 1.1732060272508147, disc_loss = 0.005956682766068893
Trained batch 527 in epoch 9, gen_loss = 1.1727781597186218, disc_loss = 0.005946696413185705
Trained batch 528 in epoch 9, gen_loss = 1.1728047757833802, disc_loss = 0.005936414613892432
Trained batch 529 in epoch 9, gen_loss = 1.1725458020309232, disc_loss = 0.005926206629813368
Trained batch 530 in epoch 9, gen_loss = 1.1724662611264518, disc_loss = 0.0059165817596305076
Trained batch 531 in epoch 9, gen_loss = 1.1723686262853164, disc_loss = 0.005906728421426746
Trained batch 532 in epoch 9, gen_loss = 1.172284485810693, disc_loss = 0.005896966457906429
Trained batch 533 in epoch 9, gen_loss = 1.1721272536654597, disc_loss = 0.0058869710350683835
Trained batch 534 in epoch 9, gen_loss = 1.171962238137967, disc_loss = 0.005876384648357335
Trained batch 535 in epoch 9, gen_loss = 1.1721813955636167, disc_loss = 0.005866015963345408
Trained batch 536 in epoch 9, gen_loss = 1.172344458280773, disc_loss = 0.005856171469028529
Trained batch 537 in epoch 9, gen_loss = 1.1722177042172301, disc_loss = 0.005845951774864298
Trained batch 538 in epoch 9, gen_loss = 1.172004118810558, disc_loss = 0.005836279411657225
Trained batch 539 in epoch 9, gen_loss = 1.1721741926890832, disc_loss = 0.0058261740339932856
Trained batch 540 in epoch 9, gen_loss = 1.1726138877119463, disc_loss = 0.005816074151211365
Trained batch 541 in epoch 9, gen_loss = 1.173229978423277, disc_loss = 0.005805974133201872
Trained batch 542 in epoch 9, gen_loss = 1.1728693969122392, disc_loss = 0.0057973030337791125
Trained batch 543 in epoch 9, gen_loss = 1.1729589358848684, disc_loss = 0.0057882849982621234
Trained batch 544 in epoch 9, gen_loss = 1.1726407313565594, disc_loss = 0.0057786096140545785
Trained batch 545 in epoch 9, gen_loss = 1.1722269360617403, disc_loss = 0.005769218411126034
Trained batch 546 in epoch 9, gen_loss = 1.1726037668135745, disc_loss = 0.0057596448922557055
Trained batch 547 in epoch 9, gen_loss = 1.1722173467822319, disc_loss = 0.005750908130668545
Trained batch 548 in epoch 9, gen_loss = 1.1719451266559746, disc_loss = 0.005741026953650716
Trained batch 549 in epoch 9, gen_loss = 1.1717571799321609, disc_loss = 0.005732318284519186
Trained batch 550 in epoch 9, gen_loss = 1.1715685930745354, disc_loss = 0.005723454498161077
Trained batch 551 in epoch 9, gen_loss = 1.1713813518484433, disc_loss = 0.00571400581701301
Trained batch 552 in epoch 9, gen_loss = 1.1711734846961865, disc_loss = 0.0057048692402074525
Trained batch 553 in epoch 9, gen_loss = 1.171076547475498, disc_loss = 0.005696328174884327
Trained batch 554 in epoch 9, gen_loss = 1.1711409346477406, disc_loss = 0.005686935154838605
Trained batch 555 in epoch 9, gen_loss = 1.1708328260792245, disc_loss = 0.005677450590077268
Trained batch 556 in epoch 9, gen_loss = 1.170862053198275, disc_loss = 0.005668114905167852
Trained batch 557 in epoch 9, gen_loss = 1.1707768534246739, disc_loss = 0.00565965102572832
Trained batch 558 in epoch 9, gen_loss = 1.1708114757094272, disc_loss = 0.005651464783990579
Trained batch 559 in epoch 9, gen_loss = 1.1709278717637062, disc_loss = 0.005643134066797627
Trained batch 560 in epoch 9, gen_loss = 1.1708514641525487, disc_loss = 0.005633850810209326
Trained batch 561 in epoch 9, gen_loss = 1.171025662447634, disc_loss = 0.00562427974250325
Trained batch 562 in epoch 9, gen_loss = 1.1712736031090176, disc_loss = 0.005615534962204138
Trained batch 563 in epoch 9, gen_loss = 1.1714659937730072, disc_loss = 0.005607014539036883
Trained batch 564 in epoch 9, gen_loss = 1.171680127624917, disc_loss = 0.005598116455861343
Trained batch 565 in epoch 9, gen_loss = 1.1713823164309713, disc_loss = 0.005588985207174286
Trained batch 566 in epoch 9, gen_loss = 1.1712952736614033, disc_loss = 0.005580061108189696
Trained batch 567 in epoch 9, gen_loss = 1.1713787762212082, disc_loss = 0.005570702779614678
Trained batch 568 in epoch 9, gen_loss = 1.1714773758434034, disc_loss = 0.005561566446897179
Trained batch 569 in epoch 9, gen_loss = 1.1717389200863084, disc_loss = 0.005552168559995806
Trained batch 570 in epoch 9, gen_loss = 1.1717660911446486, disc_loss = 0.005542952862913572
Trained batch 571 in epoch 9, gen_loss = 1.1713491426064417, disc_loss = 0.00553427740455877
Trained batch 572 in epoch 9, gen_loss = 1.1714789087235615, disc_loss = 0.00552524390320999
Trained batch 573 in epoch 9, gen_loss = 1.1717133727638565, disc_loss = 0.005516901840295607
Trained batch 574 in epoch 9, gen_loss = 1.1713282462824945, disc_loss = 0.005508357575517553
Trained batch 575 in epoch 9, gen_loss = 1.171611584516035, disc_loss = 0.005501261044577809
Trained batch 576 in epoch 9, gen_loss = 1.171612031331715, disc_loss = 0.005493061939781803
Trained batch 577 in epoch 9, gen_loss = 1.171402278655953, disc_loss = 0.005484553368930918
Trained batch 578 in epoch 9, gen_loss = 1.171437926037118, disc_loss = 0.005475482577196642
Trained batch 579 in epoch 9, gen_loss = 1.1712678857918444, disc_loss = 0.005466476037640703
Trained batch 580 in epoch 9, gen_loss = 1.1710293957780848, disc_loss = 0.005457612630356545
Trained batch 581 in epoch 9, gen_loss = 1.1708314715791814, disc_loss = 0.005448870251336875
Trained batch 582 in epoch 9, gen_loss = 1.17095265134939, disc_loss = 0.005440105545471501
Trained batch 583 in epoch 9, gen_loss = 1.1706462437159395, disc_loss = 0.005431193591741173
Trained batch 584 in epoch 9, gen_loss = 1.1705718763873108, disc_loss = 0.005422326722321634
Trained batch 585 in epoch 9, gen_loss = 1.1701826072797026, disc_loss = 0.00541385575132079
Trained batch 586 in epoch 9, gen_loss = 1.1699813366748608, disc_loss = 0.0054050665690378785
Trained batch 587 in epoch 9, gen_loss = 1.1700242161750793, disc_loss = 0.005396443379412921
Trained batch 588 in epoch 9, gen_loss = 1.1700340952654646, disc_loss = 0.00538772094068995
Trained batch 589 in epoch 9, gen_loss = 1.1700594437324394, disc_loss = 0.005379002878044819
Trained batch 590 in epoch 9, gen_loss = 1.1704518599356895, disc_loss = 0.005370736475932481
Trained batch 591 in epoch 9, gen_loss = 1.1704880254896912, disc_loss = 0.005362551391143014
Trained batch 592 in epoch 9, gen_loss = 1.1706877410110295, disc_loss = 0.005353984961893392
Trained batch 593 in epoch 9, gen_loss = 1.1707048109083464, disc_loss = 0.005345441078143359
Trained batch 594 in epoch 9, gen_loss = 1.170716272682703, disc_loss = 0.005336730164733026
Trained batch 595 in epoch 9, gen_loss = 1.1703491217938045, disc_loss = 0.00532959601991781
Trained batch 596 in epoch 9, gen_loss = 1.170097446621363, disc_loss = 0.005323428603471647
Trained batch 597 in epoch 9, gen_loss = 1.1701266248289957, disc_loss = 0.005315048017660366
Trained batch 598 in epoch 9, gen_loss = 1.1697652414565491, disc_loss = 0.005306568981338959
Trained batch 599 in epoch 9, gen_loss = 1.170243536134561, disc_loss = 0.005299380325426076
Trained batch 600 in epoch 9, gen_loss = 1.1704686998130875, disc_loss = 0.005292518245709631
Trained batch 601 in epoch 9, gen_loss = 1.1704906238075903, disc_loss = 0.005285880552780578
Trained batch 602 in epoch 9, gen_loss = 1.1704632244497588, disc_loss = 0.005278634642827893
Trained batch 603 in epoch 9, gen_loss = 1.170185660388296, disc_loss = 0.005270792119921415
Trained batch 604 in epoch 9, gen_loss = 1.1698712611986586, disc_loss = 0.005262504784368202
Trained batch 605 in epoch 9, gen_loss = 1.1696175278806844, disc_loss = 0.0052547583134090695
Trained batch 606 in epoch 9, gen_loss = 1.1697676341851815, disc_loss = 0.005247348955207384
Trained batch 607 in epoch 9, gen_loss = 1.16951385561965, disc_loss = 0.0052399993914581215
Trained batch 608 in epoch 9, gen_loss = 1.1694611834579305, disc_loss = 0.005232240805924834
Trained batch 609 in epoch 9, gen_loss = 1.1695714607590535, disc_loss = 0.005224142427872065
Trained batch 610 in epoch 9, gen_loss = 1.169475713552703, disc_loss = 0.005215964948599579
Trained batch 611 in epoch 9, gen_loss = 1.169367665656252, disc_loss = 0.005208081170470298
Trained batch 612 in epoch 9, gen_loss = 1.1691117594914957, disc_loss = 0.005199910306465184
Trained batch 613 in epoch 9, gen_loss = 1.1690940265740943, disc_loss = 0.005191955140451309
Trained batch 614 in epoch 9, gen_loss = 1.1686148541729624, disc_loss = 0.005185106720839726
Trained batch 615 in epoch 9, gen_loss = 1.1685687867658479, disc_loss = 0.005177408508206536
Trained batch 616 in epoch 9, gen_loss = 1.1685843748829934, disc_loss = 0.0051704298487315
Trained batch 617 in epoch 9, gen_loss = 1.1683161203722352, disc_loss = 0.005163235409116722
Trained batch 618 in epoch 9, gen_loss = 1.1681544323344992, disc_loss = 0.0051553751802676006
Trained batch 619 in epoch 9, gen_loss = 1.1679920774313712, disc_loss = 0.005148410559547389
Trained batch 620 in epoch 9, gen_loss = 1.168250405750029, disc_loss = 0.00514219864285641
Trained batch 621 in epoch 9, gen_loss = 1.1682196990661682, disc_loss = 0.005135211145190501
Trained batch 622 in epoch 9, gen_loss = 1.1684382994140514, disc_loss = 0.005127455675135476
Trained batch 623 in epoch 9, gen_loss = 1.1679320832093556, disc_loss = 0.005120077014791418
Trained batch 624 in epoch 9, gen_loss = 1.1680459888458252, disc_loss = 0.005113042408274487
Trained batch 625 in epoch 9, gen_loss = 1.167830055894943, disc_loss = 0.00510535255046978
Trained batch 626 in epoch 9, gen_loss = 1.1679286525200048, disc_loss = 0.005097537178381315
Trained batch 627 in epoch 9, gen_loss = 1.167560474887775, disc_loss = 0.005090054454931479
Trained batch 628 in epoch 9, gen_loss = 1.1674801327276305, disc_loss = 0.0050824054019727016
Trained batch 629 in epoch 9, gen_loss = 1.1676807131086078, disc_loss = 0.005075340758499113
Trained batch 630 in epoch 9, gen_loss = 1.1675329589994887, disc_loss = 0.005068977756747495
Trained batch 631 in epoch 9, gen_loss = 1.1677451567559303, disc_loss = 0.00506298604518576
Trained batch 632 in epoch 9, gen_loss = 1.167692994242784, disc_loss = 0.005056449207720033
Trained batch 633 in epoch 9, gen_loss = 1.1680599710542696, disc_loss = 0.005049175726050035
Trained batch 634 in epoch 9, gen_loss = 1.1681412933379647, disc_loss = 0.005042725807151163
Trained batch 635 in epoch 9, gen_loss = 1.1682431345465798, disc_loss = 0.005035513074158503
Trained batch 636 in epoch 9, gen_loss = 1.168459640754448, disc_loss = 0.005028038501232904
Trained batch 637 in epoch 9, gen_loss = 1.1685340471775927, disc_loss = 0.005020766037884519
Trained batch 638 in epoch 9, gen_loss = 1.1682224751265022, disc_loss = 0.00501328942067892
Trained batch 639 in epoch 9, gen_loss = 1.1685265811160206, disc_loss = 0.005005770503180429
Trained batch 640 in epoch 9, gen_loss = 1.1684281768367368, disc_loss = 0.004998430036275877
Trained batch 641 in epoch 9, gen_loss = 1.168375817229072, disc_loss = 0.004991292333765488
Trained batch 642 in epoch 9, gen_loss = 1.168219818112268, disc_loss = 0.004984187393395475
Trained batch 643 in epoch 9, gen_loss = 1.1684423694329231, disc_loss = 0.004976732391917027
Trained batch 644 in epoch 9, gen_loss = 1.168264317142871, disc_loss = 0.004969538609310443
Trained batch 645 in epoch 9, gen_loss = 1.168303417347533, disc_loss = 0.004962173297646457
Trained batch 646 in epoch 9, gen_loss = 1.1681174432291683, disc_loss = 0.004954882848203014
Trained batch 647 in epoch 9, gen_loss = 1.16806601870943, disc_loss = 0.004947635244712324
Trained batch 648 in epoch 9, gen_loss = 1.1680215531027371, disc_loss = 0.004940467109500635
Trained batch 649 in epoch 9, gen_loss = 1.1681206037448002, disc_loss = 0.0049331448856257615
Trained batch 650 in epoch 9, gen_loss = 1.1680524666005383, disc_loss = 0.004925885311787098
Trained batch 651 in epoch 9, gen_loss = 1.168169797381009, disc_loss = 0.004918933285138158
Trained batch 652 in epoch 9, gen_loss = 1.1682666319252704, disc_loss = 0.00491213619407369
Trained batch 653 in epoch 9, gen_loss = 1.1681312785600668, disc_loss = 0.004905116393046442
Trained batch 654 in epoch 9, gen_loss = 1.1678334816721558, disc_loss = 0.004897951534442703
Trained batch 655 in epoch 9, gen_loss = 1.167788945320176, disc_loss = 0.00489093522593044
Trained batch 656 in epoch 9, gen_loss = 1.1675488092402164, disc_loss = 0.00488386523529435
Trained batch 657 in epoch 9, gen_loss = 1.1673100244672827, disc_loss = 0.004876778158257499
Trained batch 658 in epoch 9, gen_loss = 1.1671889036305938, disc_loss = 0.0048697423246187085
Trained batch 659 in epoch 9, gen_loss = 1.1669313671914014, disc_loss = 0.004862834348067268
Trained batch 660 in epoch 9, gen_loss = 1.1666676046808622, disc_loss = 0.004856002821578044
Trained batch 661 in epoch 9, gen_loss = 1.166785895734395, disc_loss = 0.0048491312949919966
Trained batch 662 in epoch 9, gen_loss = 1.1667155443633124, disc_loss = 0.004842152410091307
Trained batch 663 in epoch 9, gen_loss = 1.1665815588041961, disc_loss = 0.004835153657698258
Trained batch 664 in epoch 9, gen_loss = 1.1663552562993271, disc_loss = 0.004828257075794517
Trained batch 665 in epoch 9, gen_loss = 1.166192562998952, disc_loss = 0.004821621398696698
Trained batch 666 in epoch 9, gen_loss = 1.1660281867459081, disc_loss = 0.004814950808751113
Trained batch 667 in epoch 9, gen_loss = 1.1660616072173604, disc_loss = 0.004808295197364202
Trained batch 668 in epoch 9, gen_loss = 1.1663639970424464, disc_loss = 0.004801941936672422
Trained batch 669 in epoch 9, gen_loss = 1.166553373212245, disc_loss = 0.00479529881220026
Trained batch 670 in epoch 9, gen_loss = 1.166351266927051, disc_loss = 0.0047887390802233394
Trained batch 671 in epoch 9, gen_loss = 1.1662531492433377, disc_loss = 0.004781902116476323
Trained batch 672 in epoch 9, gen_loss = 1.166312084952577, disc_loss = 0.004775136903945127
Trained batch 673 in epoch 9, gen_loss = 1.16627484922593, disc_loss = 0.004768308968616073
Trained batch 674 in epoch 9, gen_loss = 1.1662332548035517, disc_loss = 0.004761500223863145
Trained batch 675 in epoch 9, gen_loss = 1.1660557194398, disc_loss = 0.004754660845235281
Trained batch 676 in epoch 9, gen_loss = 1.1658880322335214, disc_loss = 0.004747892464671877
Trained batch 677 in epoch 9, gen_loss = 1.1660727549970678, disc_loss = 0.004741369009907887
Trained batch 678 in epoch 9, gen_loss = 1.1657829094178898, disc_loss = 0.004734893961860496
Trained batch 679 in epoch 9, gen_loss = 1.1656123505795704, disc_loss = 0.004728497390961445
Trained batch 680 in epoch 9, gen_loss = 1.1657802264770922, disc_loss = 0.004721959839868509
Trained batch 681 in epoch 9, gen_loss = 1.165684612178383, disc_loss = 0.004715270814309176
Trained batch 682 in epoch 9, gen_loss = 1.1658517814310891, disc_loss = 0.004709469797339401
Trained batch 683 in epoch 9, gen_loss = 1.165628377718535, disc_loss = 0.0047034900228069805
Trained batch 684 in epoch 9, gen_loss = 1.1655889807826412, disc_loss = 0.004697472933636482
Trained batch 685 in epoch 9, gen_loss = 1.1653565746180865, disc_loss = 0.004691086490181208
Trained batch 686 in epoch 9, gen_loss = 1.1652433276176453, disc_loss = 0.0046852065413674135
Trained batch 687 in epoch 9, gen_loss = 1.1651822338097317, disc_loss = 0.004679810216276924
Trained batch 688 in epoch 9, gen_loss = 1.164985525504252, disc_loss = 0.004675165767257145
Trained batch 689 in epoch 9, gen_loss = 1.1648212677326755, disc_loss = 0.004670174534038634
Trained batch 690 in epoch 9, gen_loss = 1.1649669168136916, disc_loss = 0.00466505104370362
Trained batch 691 in epoch 9, gen_loss = 1.165422956981411, disc_loss = 0.004659040008993406
Trained batch 692 in epoch 9, gen_loss = 1.1654729319341255, disc_loss = 0.004653289074634745
Trained batch 693 in epoch 9, gen_loss = 1.1651628655555957, disc_loss = 0.00464720335238065
Trained batch 694 in epoch 9, gen_loss = 1.16510304452704, disc_loss = 0.004641451217839662
Trained batch 695 in epoch 9, gen_loss = 1.165058887467302, disc_loss = 0.004635462026271853
Trained batch 696 in epoch 9, gen_loss = 1.1647834658964806, disc_loss = 0.004629129863499799
Trained batch 697 in epoch 9, gen_loss = 1.1647387171713874, disc_loss = 0.004622808263058718
Trained batch 698 in epoch 9, gen_loss = 1.1646555274170698, disc_loss = 0.004616666568885524
Trained batch 699 in epoch 9, gen_loss = 1.1643148400102343, disc_loss = 0.004610623809276149
Trained batch 700 in epoch 9, gen_loss = 1.1641820880043694, disc_loss = 0.004604858003016003
Trained batch 701 in epoch 9, gen_loss = 1.164049920363304, disc_loss = 0.00459865312381552
Trained batch 702 in epoch 9, gen_loss = 1.1642002406534055, disc_loss = 0.004592392157851341
Trained batch 703 in epoch 9, gen_loss = 1.1642455760050903, disc_loss = 0.004586186894006129
Trained batch 704 in epoch 9, gen_loss = 1.1643625142726493, disc_loss = 0.004580047736807185
Trained batch 705 in epoch 9, gen_loss = 1.1641064195896342, disc_loss = 0.004573975009870915
Trained batch 706 in epoch 9, gen_loss = 1.1640718656854212, disc_loss = 0.004567763262277349
Trained batch 707 in epoch 9, gen_loss = 1.1639065021007073, disc_loss = 0.004561614273540218
Trained batch 708 in epoch 9, gen_loss = 1.1636990844278645, disc_loss = 0.004555372827302478
Trained batch 709 in epoch 9, gen_loss = 1.1635487270187324, disc_loss = 0.004549173169529958
Trained batch 710 in epoch 9, gen_loss = 1.163215789362348, disc_loss = 0.0045432544693399255
Trained batch 711 in epoch 9, gen_loss = 1.163406450343266, disc_loss = 0.004538022098376735
Trained batch 712 in epoch 9, gen_loss = 1.1633073774494262, disc_loss = 0.004532265290340375
Trained batch 713 in epoch 9, gen_loss = 1.1634820010982643, disc_loss = 0.004526561407613012
Trained batch 714 in epoch 9, gen_loss = 1.1635694487945183, disc_loss = 0.0045208165609323375
Trained batch 715 in epoch 9, gen_loss = 1.1633043203440459, disc_loss = 0.00451489885196359
Trained batch 716 in epoch 9, gen_loss = 1.1632943779354814, disc_loss = 0.0045092392751717785
Trained batch 717 in epoch 9, gen_loss = 1.1633755024263122, disc_loss = 0.004503342319235483
Trained batch 718 in epoch 9, gen_loss = 1.1632598579675995, disc_loss = 0.004497490309317103
Trained batch 719 in epoch 9, gen_loss = 1.1632348122696081, disc_loss = 0.004491459908119093
Trained batch 720 in epoch 9, gen_loss = 1.163596273873947, disc_loss = 0.0044859176205022935
Trained batch 721 in epoch 9, gen_loss = 1.1636814104387965, disc_loss = 0.004480338974828752
Trained batch 722 in epoch 9, gen_loss = 1.1635635900794223, disc_loss = 0.004475430217197997
Trained batch 723 in epoch 9, gen_loss = 1.1635715945814196, disc_loss = 0.0044715395173153104
Trained batch 724 in epoch 9, gen_loss = 1.163279917240143, disc_loss = 0.004468813031301673
Trained batch 725 in epoch 9, gen_loss = 1.163036319753027, disc_loss = 0.0044649297087042805
Trained batch 726 in epoch 9, gen_loss = 1.1633230555172307, disc_loss = 0.004460159796315721
Trained batch 727 in epoch 9, gen_loss = 1.163247441279364, disc_loss = 0.004454870650398924
Trained batch 728 in epoch 9, gen_loss = 1.1635249636464322, disc_loss = 0.0044498067355263765
Trained batch 729 in epoch 9, gen_loss = 1.1633957275789077, disc_loss = 0.004445703375178759
Trained batch 730 in epoch 9, gen_loss = 1.1633635482938116, disc_loss = 0.0044412328617993825
Trained batch 731 in epoch 9, gen_loss = 1.1631631330877055, disc_loss = 0.004436006957679081
Trained batch 732 in epoch 9, gen_loss = 1.1631243509452633, disc_loss = 0.004430721510115294
Trained batch 733 in epoch 9, gen_loss = 1.1631229993270593, disc_loss = 0.004424982601605427
Trained batch 734 in epoch 9, gen_loss = 1.162888075137625, disc_loss = 0.0044196652688029015
Trained batch 735 in epoch 9, gen_loss = 1.162669197777691, disc_loss = 0.004414440938727121
Trained batch 736 in epoch 9, gen_loss = 1.1627890474113713, disc_loss = 0.004409647834034866
Trained batch 737 in epoch 9, gen_loss = 1.1630980865903664, disc_loss = 0.004404695228980173
Trained batch 738 in epoch 9, gen_loss = 1.1630032456937436, disc_loss = 0.00439915572090203
Trained batch 739 in epoch 9, gen_loss = 1.1627778267538225, disc_loss = 0.004393611459188931
Trained batch 740 in epoch 9, gen_loss = 1.1627250227690065, disc_loss = 0.004388285661658257
Trained batch 741 in epoch 9, gen_loss = 1.1626268699162732, disc_loss = 0.004383527926733213
Trained batch 742 in epoch 9, gen_loss = 1.1623736294249667, disc_loss = 0.0043791905832448715
Trained batch 743 in epoch 9, gen_loss = 1.1622912188371022, disc_loss = 0.004374145321469436
Trained batch 744 in epoch 9, gen_loss = 1.1624102773282352, disc_loss = 0.004368760102762897
Trained batch 745 in epoch 9, gen_loss = 1.1623351348628947, disc_loss = 0.004363636311921403
Trained batch 746 in epoch 9, gen_loss = 1.1622665702418948, disc_loss = 0.004358318352877316
Trained batch 747 in epoch 9, gen_loss = 1.162295393924662, disc_loss = 0.004352911242589238
Trained batch 748 in epoch 9, gen_loss = 1.1619697185320275, disc_loss = 0.004347480839630962
Trained batch 749 in epoch 9, gen_loss = 1.1616469728151957, disc_loss = 0.004342120976303704
Trained batch 750 in epoch 9, gen_loss = 1.1617519490410897, disc_loss = 0.0043372731355807
Trained batch 751 in epoch 9, gen_loss = 1.161693772737016, disc_loss = 0.004332378726603372
Trained batch 752 in epoch 9, gen_loss = 1.1614176534403209, disc_loss = 0.0043280993947795755
Trained batch 753 in epoch 9, gen_loss = 1.1611242577315009, disc_loss = 0.004323164997778311
Trained batch 754 in epoch 9, gen_loss = 1.1609298586055932, disc_loss = 0.00431819454684317
Trained batch 755 in epoch 9, gen_loss = 1.1609403522557051, disc_loss = 0.004313109333298314
Trained batch 756 in epoch 9, gen_loss = 1.1607157867524867, disc_loss = 0.004307964395395205
Trained batch 757 in epoch 9, gen_loss = 1.1605180295916535, disc_loss = 0.0043027287806088775
Trained batch 758 in epoch 9, gen_loss = 1.1607808276755693, disc_loss = 0.004297517367161023
Trained batch 759 in epoch 9, gen_loss = 1.1609270392279876, disc_loss = 0.0042924602314949305
Trained batch 760 in epoch 9, gen_loss = 1.1609434251246409, disc_loss = 0.00428792372533015
Trained batch 761 in epoch 9, gen_loss = 1.1613598655215085, disc_loss = 0.004283133803570724
Trained batch 762 in epoch 9, gen_loss = 1.1613575429466418, disc_loss = 0.004278188886517307
Trained batch 763 in epoch 9, gen_loss = 1.1613091597070244, disc_loss = 0.004273034182658446
Trained batch 764 in epoch 9, gen_loss = 1.1609217081973755, disc_loss = 0.004267780972512293
Trained batch 765 in epoch 9, gen_loss = 1.1605508066811077, disc_loss = 0.004263500352646954
Trained batch 766 in epoch 9, gen_loss = 1.1605996306125934, disc_loss = 0.004258304743108072
Trained batch 767 in epoch 9, gen_loss = 1.1603315003061045, disc_loss = 0.004254041989914488
Trained batch 768 in epoch 9, gen_loss = 1.1604301528750842, disc_loss = 0.00424957492806457
Trained batch 769 in epoch 9, gen_loss = 1.160121421922337, disc_loss = 0.004244802535213712
Trained batch 770 in epoch 9, gen_loss = 1.1601766838792387, disc_loss = 0.004239546413554981
Trained batch 771 in epoch 9, gen_loss = 1.1603238974056096, disc_loss = 0.0042343136027611855
Trained batch 772 in epoch 9, gen_loss = 1.1599838848564326, disc_loss = 0.004229366729459316
Trained batch 773 in epoch 9, gen_loss = 1.1601427815835297, disc_loss = 0.0042251514827822655
Trained batch 774 in epoch 9, gen_loss = 1.1599529850098396, disc_loss = 0.004220805559363667
Trained batch 775 in epoch 9, gen_loss = 1.1599755676597665, disc_loss = 0.004216216186288181
Trained batch 776 in epoch 9, gen_loss = 1.1599037318156034, disc_loss = 0.004211238436540979
Trained batch 777 in epoch 9, gen_loss = 1.160087545534026, disc_loss = 0.0042060754045465205
Trained batch 778 in epoch 9, gen_loss = 1.1599279300086152, disc_loss = 0.0042011698998079845
Trained batch 779 in epoch 9, gen_loss = 1.1597406019767125, disc_loss = 0.004196459568181756
Trained batch 780 in epoch 9, gen_loss = 1.1594964170425406, disc_loss = 0.0041917778641982996
Trained batch 781 in epoch 9, gen_loss = 1.1595401728092252, disc_loss = 0.004186794246316773
Trained batch 782 in epoch 9, gen_loss = 1.159372705685529, disc_loss = 0.004181699695249681
Trained batch 783 in epoch 9, gen_loss = 1.1593943220772305, disc_loss = 0.004176525477713748
Trained batch 784 in epoch 9, gen_loss = 1.1592775454946385, disc_loss = 0.004171540333139028
Trained batch 785 in epoch 9, gen_loss = 1.1590313191783943, disc_loss = 0.004166502069150016
Trained batch 786 in epoch 9, gen_loss = 1.158682910505365, disc_loss = 0.004161981036896188
Trained batch 787 in epoch 9, gen_loss = 1.158798883484705, disc_loss = 0.004157401887726702
Trained batch 788 in epoch 9, gen_loss = 1.1588229381388433, disc_loss = 0.004152847305684603
Trained batch 789 in epoch 9, gen_loss = 1.1586696580240998, disc_loss = 0.00414801684859919
Testing Epoch 9
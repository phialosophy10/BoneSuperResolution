/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 0.5994430780410767, disc_loss = 0.7027992010116577
Trained batch 1 in epoch 0, gen_loss = 0.680517852306366, disc_loss = 1.7043644785881042
Trained batch 2 in epoch 0, gen_loss = 0.6151916086673737, disc_loss = 1.3438788255055745
Trained batch 3 in epoch 0, gen_loss = 0.5715794712305069, disc_loss = 1.1226345226168633
Trained batch 4 in epoch 0, gen_loss = 0.5532003521919251, disc_loss = 0.9718905091285706
Trained batch 5 in epoch 0, gen_loss = 0.5405304233233134, disc_loss = 0.8628200242916743
Trained batch 6 in epoch 0, gen_loss = 0.5369868193353925, disc_loss = 0.7765652111598423
Trained batch 7 in epoch 0, gen_loss = 0.526802271604538, disc_loss = 0.7013491857796907
Trained batch 8 in epoch 0, gen_loss = 0.520640105009079, disc_loss = 0.6512012100882001
Trained batch 9 in epoch 0, gen_loss = 0.517699733376503, disc_loss = 0.6133451476693154
Trained batch 10 in epoch 0, gen_loss = 0.5184754051945426, disc_loss = 0.5781603821299293
Trained batch 11 in epoch 0, gen_loss = 0.5163955762982368, disc_loss = 0.5712009010215601
Trained batch 12 in epoch 0, gen_loss = 0.5179110559133383, disc_loss = 0.5481584656697053
Trained batch 13 in epoch 0, gen_loss = 0.5166006812027523, disc_loss = 0.5216142545853343
Trained batch 14 in epoch 0, gen_loss = 0.5160733660062155, disc_loss = 0.49611350198586784
Trained batch 15 in epoch 0, gen_loss = 0.5137807615101337, disc_loss = 0.47206627298146486
Trained batch 16 in epoch 0, gen_loss = 0.509757893926957, disc_loss = 0.44977639527881846
Trained batch 17 in epoch 0, gen_loss = 0.5089314695861604, disc_loss = 0.42985276463958955
Trained batch 18 in epoch 0, gen_loss = 0.5061861355053751, disc_loss = 0.4116539084597638
Trained batch 19 in epoch 0, gen_loss = 0.5056829169392586, disc_loss = 0.3975460551679134
Trained batch 20 in epoch 0, gen_loss = 0.5079377307778313, disc_loss = 0.3926758886802764
Trained batch 21 in epoch 0, gen_loss = 0.5050977915525436, disc_loss = 0.3882797881960869
Trained batch 22 in epoch 0, gen_loss = 0.5070469884768777, disc_loss = 0.37633115960204083
Trained batch 23 in epoch 0, gen_loss = 0.5059713584681352, disc_loss = 0.36512692521015805
Trained batch 24 in epoch 0, gen_loss = 0.5067489898204803, disc_loss = 0.353259542286396
Trained batch 25 in epoch 0, gen_loss = 0.5072644341450471, disc_loss = 0.34127846259910327
Trained batch 26 in epoch 0, gen_loss = 0.5069757004578909, disc_loss = 0.3299611971058227
Trained batch 27 in epoch 0, gen_loss = 0.5065676676375526, disc_loss = 0.3196880498102733
Trained batch 28 in epoch 0, gen_loss = 0.5063091495941425, disc_loss = 0.3098332168984002
Trained batch 29 in epoch 0, gen_loss = 0.506758572657903, disc_loss = 0.30072820944090684
Trained batch 30 in epoch 0, gen_loss = 0.5060290059735698, disc_loss = 0.29233262844143376
Trained batch 31 in epoch 0, gen_loss = 0.5059886947274208, disc_loss = 0.28432802099268883
Trained batch 32 in epoch 0, gen_loss = 0.505220092607267, disc_loss = 0.2769433586209109
Trained batch 33 in epoch 0, gen_loss = 0.5051192457185072, disc_loss = 0.2697986563777222
Trained batch 34 in epoch 0, gen_loss = 0.50652214884758, disc_loss = 0.2631325479064669
Trained batch 35 in epoch 0, gen_loss = 0.5077387169003487, disc_loss = 0.2570562631719642
Trained batch 36 in epoch 0, gen_loss = 0.508014011221963, disc_loss = 0.25159032028671857
Trained batch 37 in epoch 0, gen_loss = 0.5088032382099252, disc_loss = 0.24630470368030824
Trained batch 38 in epoch 0, gen_loss = 0.5075539159469116, disc_loss = 0.24106719535894883
Trained batch 39 in epoch 0, gen_loss = 0.5080596290528774, disc_loss = 0.23607806907966733
Trained batch 40 in epoch 0, gen_loss = 0.5094040566828193, disc_loss = 0.23112830256180064
Trained batch 41 in epoch 0, gen_loss = 0.5106984909091677, disc_loss = 0.22634399593586013
Trained batch 42 in epoch 0, gen_loss = 0.510563651489657, disc_loss = 0.22167638091500416
Trained batch 43 in epoch 0, gen_loss = 0.5117828080599959, disc_loss = 0.21714606991207058
Trained batch 44 in epoch 0, gen_loss = 0.5105533460776012, disc_loss = 0.21296952333715227
Trained batch 45 in epoch 0, gen_loss = 0.509973151528317, disc_loss = 0.20955176246554955
Trained batch 46 in epoch 0, gen_loss = 0.5095483280242757, disc_loss = 0.20638337271644713
Trained batch 47 in epoch 0, gen_loss = 0.5113404095172882, disc_loss = 0.20308781314330795
Trained batch 48 in epoch 0, gen_loss = 0.5112900369021357, disc_loss = 0.19938466431839125
Trained batch 49 in epoch 0, gen_loss = 0.5096833217144012, disc_loss = 0.19601845998317002
Trained batch 50 in epoch 0, gen_loss = 0.509948752674402, disc_loss = 0.1928107508038189
Trained batch 51 in epoch 0, gen_loss = 0.509420687189469, disc_loss = 0.18948422246970809
Trained batch 52 in epoch 0, gen_loss = 0.5096546074129501, disc_loss = 0.18634445318635903
Trained batch 53 in epoch 0, gen_loss = 0.5086398632438095, disc_loss = 0.18364267899758285
Trained batch 54 in epoch 0, gen_loss = 0.5074557309800928, disc_loss = 0.18117757825688882
Trained batch 55 in epoch 0, gen_loss = 0.508403980838401, disc_loss = 0.17852679919451475
Trained batch 56 in epoch 0, gen_loss = 0.5081526454080615, disc_loss = 0.17589854913061126
Trained batch 57 in epoch 0, gen_loss = 0.5074978172779083, disc_loss = 0.17376492268823343
Trained batch 58 in epoch 0, gen_loss = 0.5087947976791253, disc_loss = 0.17207427392319097
Trained batch 59 in epoch 0, gen_loss = 0.5081235582629839, disc_loss = 0.17092466559261082
Trained batch 60 in epoch 0, gen_loss = 0.5082520974464104, disc_loss = 0.1713815962315583
Trained batch 61 in epoch 0, gen_loss = 0.5079086081635568, disc_loss = 0.17327506702032783
Trained batch 62 in epoch 0, gen_loss = 0.5077608038508703, disc_loss = 0.17162113524382078
Trained batch 63 in epoch 0, gen_loss = 0.5084552634507418, disc_loss = 0.17021689499961212
Trained batch 64 in epoch 0, gen_loss = 0.5084364249156071, disc_loss = 0.1684521052126701
Trained batch 65 in epoch 0, gen_loss = 0.5091201663017273, disc_loss = 0.16620900199720354
Trained batch 66 in epoch 0, gen_loss = 0.508727870325544, disc_loss = 0.16406419345024806
Trained batch 67 in epoch 0, gen_loss = 0.5079796813866672, disc_loss = 0.16199841128443093
Trained batch 68 in epoch 0, gen_loss = 0.5077650650687839, disc_loss = 0.15993943365047808
Trained batch 69 in epoch 0, gen_loss = 0.5075811747993741, disc_loss = 0.1578828895996724
Trained batch 70 in epoch 0, gen_loss = 0.5073523630558605, disc_loss = 0.15588806354453866
Trained batch 71 in epoch 0, gen_loss = 0.5065978119770685, disc_loss = 0.15394694872924852
Trained batch 72 in epoch 0, gen_loss = 0.5061818479675136, disc_loss = 0.15201130635679178
Trained batch 73 in epoch 0, gen_loss = 0.5063559102850992, disc_loss = 0.15013036180942044
Trained batch 74 in epoch 0, gen_loss = 0.5059074135621389, disc_loss = 0.14828420234223208
Trained batch 75 in epoch 0, gen_loss = 0.5051018630987719, disc_loss = 0.14650061048910415
Trained batch 76 in epoch 0, gen_loss = 0.5053141670567649, disc_loss = 0.14477875491289735
Trained batch 77 in epoch 0, gen_loss = 0.50541069989021, disc_loss = 0.1430620972234278
Trained batch 78 in epoch 0, gen_loss = 0.5043100967437406, disc_loss = 0.14141788844113487
Trained batch 79 in epoch 0, gen_loss = 0.5048624891787767, disc_loss = 0.13982387079158798
Trained batch 80 in epoch 0, gen_loss = 0.5043475127514497, disc_loss = 0.13826318299052892
Trained batch 81 in epoch 0, gen_loss = 0.5049027073674086, disc_loss = 0.13675263060665713
Trained batch 82 in epoch 0, gen_loss = 0.5050320266241051, disc_loss = 0.13526140974767237
Trained batch 83 in epoch 0, gen_loss = 0.5049515724891708, disc_loss = 0.13381238920348032
Trained batch 84 in epoch 0, gen_loss = 0.5041297060601851, disc_loss = 0.13243454300305424
Trained batch 85 in epoch 0, gen_loss = 0.5041258206894231, disc_loss = 0.1310922897659069
Trained batch 86 in epoch 0, gen_loss = 0.5041539740973505, disc_loss = 0.12978521216361003
Trained batch 87 in epoch 0, gen_loss = 0.5036768882789395, disc_loss = 0.1284834585491229
Trained batch 88 in epoch 0, gen_loss = 0.5034316624148508, disc_loss = 0.12718157116532997
Trained batch 89 in epoch 0, gen_loss = 0.5033014135228263, disc_loss = 0.12589880859272348
Trained batch 90 in epoch 0, gen_loss = 0.5026948677969503, disc_loss = 0.12463710566593723
Trained batch 91 in epoch 0, gen_loss = 0.5025919821599255, disc_loss = 0.12342325724539874
Trained batch 92 in epoch 0, gen_loss = 0.5027759911552552, disc_loss = 0.12220368825740391
Trained batch 93 in epoch 0, gen_loss = 0.5025911264597102, disc_loss = 0.12099319924303192
Trained batch 94 in epoch 0, gen_loss = 0.5016896087872355, disc_loss = 0.11981892142640917
Trained batch 95 in epoch 0, gen_loss = 0.5010411522040764, disc_loss = 0.11867220239946619
Trained batch 96 in epoch 0, gen_loss = 0.5007489378919306, disc_loss = 0.1175346586315595
Trained batch 97 in epoch 0, gen_loss = 0.5010939094485068, disc_loss = 0.11643149941323364
Trained batch 98 in epoch 0, gen_loss = 0.5011123256249861, disc_loss = 0.11534375913742215
Trained batch 99 in epoch 0, gen_loss = 0.5005941513180733, disc_loss = 0.11427317441441119
Trained batch 100 in epoch 0, gen_loss = 0.5004495523943759, disc_loss = 0.11323281513102869
Trained batch 101 in epoch 0, gen_loss = 0.5000172973263497, disc_loss = 0.11223561675561701
Trained batch 102 in epoch 0, gen_loss = 0.4996380820436385, disc_loss = 0.11137713127525396
Trained batch 103 in epoch 0, gen_loss = 0.49982179844608676, disc_loss = 0.11052096415705119
Trained batch 104 in epoch 0, gen_loss = 0.4999220374084654, disc_loss = 0.10962006047900234
Trained batch 105 in epoch 0, gen_loss = 0.5000171399903748, disc_loss = 0.10883007320698421
Trained batch 106 in epoch 0, gen_loss = 0.5003936115269348, disc_loss = 0.1079459676049023
Trained batch 107 in epoch 0, gen_loss = 0.5005843642133253, disc_loss = 0.10708396757642429
Trained batch 108 in epoch 0, gen_loss = 0.5003134627407844, disc_loss = 0.1063785086291919
Trained batch 109 in epoch 0, gen_loss = 0.5007357665083625, disc_loss = 0.10558948530392213
Trained batch 110 in epoch 0, gen_loss = 0.5016170356187735, disc_loss = 0.10568520467023591
Trained batch 111 in epoch 0, gen_loss = 0.5026911233684846, disc_loss = 0.11250905546226672
Trained batch 112 in epoch 0, gen_loss = 0.5022789131751103, disc_loss = 0.11387542087947373
Trained batch 113 in epoch 0, gen_loss = 0.501624726412589, disc_loss = 0.11728524861105702
Trained batch 114 in epoch 0, gen_loss = 0.5014880411002947, disc_loss = 0.12162165810232577
Trained batch 115 in epoch 0, gen_loss = 0.5006074440376512, disc_loss = 0.12239821075365462
Trained batch 116 in epoch 0, gen_loss = 0.5003186945731823, disc_loss = 0.12223316633548492
Trained batch 117 in epoch 0, gen_loss = 0.49930955469608307, disc_loss = 0.12160636730870958
Trained batch 118 in epoch 0, gen_loss = 0.4986548248459311, disc_loss = 0.12097441329926002
Trained batch 119 in epoch 0, gen_loss = 0.4980777350564798, disc_loss = 0.12022797896837195
Trained batch 120 in epoch 0, gen_loss = 0.498168553941506, disc_loss = 0.11941838329119131
Trained batch 121 in epoch 0, gen_loss = 0.4977586765269764, disc_loss = 0.11854735206904225
Trained batch 122 in epoch 0, gen_loss = 0.49739786837159133, disc_loss = 0.11769797793036796
Trained batch 123 in epoch 0, gen_loss = 0.49738831673899003, disc_loss = 0.11685899852384482
Trained batch 124 in epoch 0, gen_loss = 0.4975000925064087, disc_loss = 0.11601791481673718
Trained batch 125 in epoch 0, gen_loss = 0.49759431254296077, disc_loss = 0.11518635626675354
Trained batch 126 in epoch 0, gen_loss = 0.49740376294128535, disc_loss = 0.11437840594022762
Trained batch 127 in epoch 0, gen_loss = 0.4971506749279797, disc_loss = 0.11361567529093008
Trained batch 128 in epoch 0, gen_loss = 0.4969908784526263, disc_loss = 0.11284000232324813
Trained batch 129 in epoch 0, gen_loss = 0.49672262370586395, disc_loss = 0.1121006990209795
Trained batch 130 in epoch 0, gen_loss = 0.49624976925267517, disc_loss = 0.11146201862320873
Trained batch 131 in epoch 0, gen_loss = 0.4955881330551523, disc_loss = 0.11180968738556134
Trained batch 132 in epoch 0, gen_loss = 0.4963547992975192, disc_loss = 0.11482512702311116
Trained batch 133 in epoch 0, gen_loss = 0.49630434054936934, disc_loss = 0.11432423952049506
Trained batch 134 in epoch 0, gen_loss = 0.49582783734356917, disc_loss = 0.1141665503727617
Trained batch 135 in epoch 0, gen_loss = 0.49623190962216435, disc_loss = 0.11353589655311011
Trained batch 136 in epoch 0, gen_loss = 0.496110149761186, disc_loss = 0.11300409536971881
Trained batch 137 in epoch 0, gen_loss = 0.4960747061000354, disc_loss = 0.1123858773338514
Trained batch 138 in epoch 0, gen_loss = 0.4957451837525951, disc_loss = 0.1116729276991791
Trained batch 139 in epoch 0, gen_loss = 0.49540335131543023, disc_loss = 0.11099408146526132
Trained batch 140 in epoch 0, gen_loss = 0.49497699589594035, disc_loss = 0.11040676558218526
Trained batch 141 in epoch 0, gen_loss = 0.49492187965923634, disc_loss = 0.109936749077284
Trained batch 142 in epoch 0, gen_loss = 0.49510404384219564, disc_loss = 0.10926598033678907
Trained batch 143 in epoch 0, gen_loss = 0.4946747167656819, disc_loss = 0.10891071535621046
Trained batch 144 in epoch 0, gen_loss = 0.4948766245924193, disc_loss = 0.10904661267353542
Trained batch 145 in epoch 0, gen_loss = 0.49499613434484563, disc_loss = 0.10913329621879002
Trained batch 146 in epoch 0, gen_loss = 0.49455914935287165, disc_loss = 0.11004346446292539
Trained batch 147 in epoch 0, gen_loss = 0.4951537311882586, disc_loss = 0.11187283371927569
Trained batch 148 in epoch 0, gen_loss = 0.49470416991502647, disc_loss = 0.11142531386732855
Trained batch 149 in epoch 0, gen_loss = 0.49437292098999025, disc_loss = 0.11223476369554798
Trained batch 150 in epoch 0, gen_loss = 0.49466923846314287, disc_loss = 0.11173404550290858
Trained batch 151 in epoch 0, gen_loss = 0.4949924079211135, disc_loss = 0.11143361879390125
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.509294331073761, disc_loss = 0.027244802564382553
Trained batch 1 in epoch 1, gen_loss = 0.46471792459487915, disc_loss = 0.04697536863386631
Trained batch 2 in epoch 1, gen_loss = 0.45449768503506977, disc_loss = 0.07439947252472241
Trained batch 3 in epoch 1, gen_loss = 0.4359048381447792, disc_loss = 0.16359272692352533
Trained batch 4 in epoch 1, gen_loss = 0.46472588181495667, disc_loss = 0.194960368424654
Trained batch 5 in epoch 1, gen_loss = 0.4667000472545624, disc_loss = 0.21687328877548376
Trained batch 6 in epoch 1, gen_loss = 0.4650729426315853, disc_loss = 0.22620456612535886
Trained batch 7 in epoch 1, gen_loss = 0.459649208933115, disc_loss = 0.2158694681711495
Trained batch 8 in epoch 1, gen_loss = 0.45696191324128044, disc_loss = 0.20394942040244737
Trained batch 9 in epoch 1, gen_loss = 0.4590499341487885, disc_loss = 0.19476650841534138
Trained batch 10 in epoch 1, gen_loss = 0.46251639994707977, disc_loss = 0.20947968316349116
Trained batch 11 in epoch 1, gen_loss = 0.46261128534873325, disc_loss = 0.19893692961583534
Trained batch 12 in epoch 1, gen_loss = 0.46077767931498015, disc_loss = 0.19298056197854188
Trained batch 13 in epoch 1, gen_loss = 0.46263487637043, disc_loss = 0.19602599287671701
Trained batch 14 in epoch 1, gen_loss = 0.45801132122675575, disc_loss = 0.1972316361963749
Trained batch 15 in epoch 1, gen_loss = 0.46076725050807, disc_loss = 0.20376151404343545
Trained batch 16 in epoch 1, gen_loss = 0.4611322143498589, disc_loss = 0.20111668438595884
Trained batch 17 in epoch 1, gen_loss = 0.45750003059705097, disc_loss = 0.19786613827778232
Trained batch 18 in epoch 1, gen_loss = 0.4568700539438348, disc_loss = 0.1920504889598018
Trained batch 19 in epoch 1, gen_loss = 0.4551692321896553, disc_loss = 0.18660841714590787
Trained batch 20 in epoch 1, gen_loss = 0.4540899126302628, disc_loss = 0.18167272121423766
Trained batch 21 in epoch 1, gen_loss = 0.45519088208675385, disc_loss = 0.17870690893720498
Trained batch 22 in epoch 1, gen_loss = 0.45265893573346344, disc_loss = 0.18346044566968214
Trained batch 23 in epoch 1, gen_loss = 0.45540476342042285, disc_loss = 0.1876527420245111
Trained batch 24 in epoch 1, gen_loss = 0.45616371870040895, disc_loss = 0.1835595865547657
Trained batch 25 in epoch 1, gen_loss = 0.4546256810426712, disc_loss = 0.1810052917840389
Trained batch 26 in epoch 1, gen_loss = 0.4567020171218448, disc_loss = 0.17649579503469998
Trained batch 27 in epoch 1, gen_loss = 0.4578530660697392, disc_loss = 0.17171724127339466
Trained batch 28 in epoch 1, gen_loss = 0.45805946198003045, disc_loss = 0.16735720493156334
Trained batch 29 in epoch 1, gen_loss = 0.45867694516976676, disc_loss = 0.16706443689763545
Trained batch 30 in epoch 1, gen_loss = 0.4600671847020426, disc_loss = 0.17959725724593287
Trained batch 31 in epoch 1, gen_loss = 0.4612498814240098, disc_loss = 0.1807803144911304
Trained batch 32 in epoch 1, gen_loss = 0.45857079462571576, disc_loss = 0.18196882634903444
Trained batch 33 in epoch 1, gen_loss = 0.4571848108487971, disc_loss = 0.18075775234576533
Trained batch 34 in epoch 1, gen_loss = 0.4565826279776437, disc_loss = 0.1797712752861636
Trained batch 35 in epoch 1, gen_loss = 0.4574868554870288, disc_loss = 0.17706554103642702
Trained batch 36 in epoch 1, gen_loss = 0.458244245600056, disc_loss = 0.17403458532046628
Trained batch 37 in epoch 1, gen_loss = 0.45740508484212977, disc_loss = 0.1711461323460466
Trained batch 38 in epoch 1, gen_loss = 0.4571020442705888, disc_loss = 0.16893253217522913
Trained batch 39 in epoch 1, gen_loss = 0.45775219798088074, disc_loss = 0.1709143220447004
Trained batch 40 in epoch 1, gen_loss = 0.4575499092660299, disc_loss = 0.1742235661098143
Trained batch 41 in epoch 1, gen_loss = 0.4580327903940564, disc_loss = 0.17959222614410378
Trained batch 42 in epoch 1, gen_loss = 0.4556112303290256, disc_loss = 0.1809995010668455
Trained batch 43 in epoch 1, gen_loss = 0.4546199637380513, disc_loss = 0.1817806406285275
Trained batch 44 in epoch 1, gen_loss = 0.45434942576620313, disc_loss = 0.18178534565700424
Trained batch 45 in epoch 1, gen_loss = 0.4524152602838433, disc_loss = 0.18127523937627024
Trained batch 46 in epoch 1, gen_loss = 0.45229573262498735, disc_loss = 0.18046242212678523
Trained batch 47 in epoch 1, gen_loss = 0.45137975737452507, disc_loss = 0.17933909152634442
Trained batch 48 in epoch 1, gen_loss = 0.4504441132350844, disc_loss = 0.17766406820440778
Trained batch 49 in epoch 1, gen_loss = 0.44821315705776216, disc_loss = 0.17832622818648816
Trained batch 50 in epoch 1, gen_loss = 0.4501955199475382, disc_loss = 0.17890812946008702
Trained batch 51 in epoch 1, gen_loss = 0.4487309725238727, disc_loss = 0.1825681712048558
Trained batch 52 in epoch 1, gen_loss = 0.44879321613401735, disc_loss = 0.18732883394607958
Trained batch 53 in epoch 1, gen_loss = 0.4473279184765286, disc_loss = 0.18801669824730466
Trained batch 54 in epoch 1, gen_loss = 0.4464292509989305, disc_loss = 0.18966575529087673
Trained batch 55 in epoch 1, gen_loss = 0.4461037026984351, disc_loss = 0.19084968943414943
Trained batch 56 in epoch 1, gen_loss = 0.4453963161560527, disc_loss = 0.19256128128944783
Trained batch 57 in epoch 1, gen_loss = 0.4452027663074691, disc_loss = 0.19309224824196305
Trained batch 58 in epoch 1, gen_loss = 0.4446804311315892, disc_loss = 0.19330501171239353
Trained batch 59 in epoch 1, gen_loss = 0.44464279115200045, disc_loss = 0.19303652712454397
Trained batch 60 in epoch 1, gen_loss = 0.4437219764365525, disc_loss = 0.1930111242977322
Trained batch 61 in epoch 1, gen_loss = 0.4435119499121943, disc_loss = 0.1931425433365568
Trained batch 62 in epoch 1, gen_loss = 0.4430434557180556, disc_loss = 0.1931704111870319
Trained batch 63 in epoch 1, gen_loss = 0.4433904644101858, disc_loss = 0.19320393115049228
Trained batch 64 in epoch 1, gen_loss = 0.4430790130908673, disc_loss = 0.19381816839942564
Trained batch 65 in epoch 1, gen_loss = 0.44316379590467975, disc_loss = 0.19449074334944738
Trained batch 66 in epoch 1, gen_loss = 0.4429693204253467, disc_loss = 0.19500210697748768
Trained batch 67 in epoch 1, gen_loss = 0.44224684203372283, disc_loss = 0.19552947378114743
Trained batch 68 in epoch 1, gen_loss = 0.44206292257792706, disc_loss = 0.19783427290942357
Trained batch 69 in epoch 1, gen_loss = 0.4429548088993345, disc_loss = 0.20074855871498584
Trained batch 70 in epoch 1, gen_loss = 0.4427381481083346, disc_loss = 0.2021918722336561
Trained batch 71 in epoch 1, gen_loss = 0.4421379139853848, disc_loss = 0.2036996704733206
Trained batch 72 in epoch 1, gen_loss = 0.44196454466205753, disc_loss = 0.20829001900880303
Trained batch 73 in epoch 1, gen_loss = 0.44163586682564504, disc_loss = 0.21227970049792044
Trained batch 74 in epoch 1, gen_loss = 0.4410615408420563, disc_loss = 0.2129504717886448
Trained batch 75 in epoch 1, gen_loss = 0.43981690195045975, disc_loss = 0.213522342621888
Trained batch 76 in epoch 1, gen_loss = 0.4389556243822172, disc_loss = 0.21365307363403307
Trained batch 77 in epoch 1, gen_loss = 0.43821024130552244, disc_loss = 0.21378179157200533
Trained batch 78 in epoch 1, gen_loss = 0.43785731588737875, disc_loss = 0.21374444300426712
Trained batch 79 in epoch 1, gen_loss = 0.4368447303771973, disc_loss = 0.21386808599345386
Trained batch 80 in epoch 1, gen_loss = 0.4362915415822724, disc_loss = 0.21383000813700534
Trained batch 81 in epoch 1, gen_loss = 0.4357437560471093, disc_loss = 0.2139095494569075
Trained batch 82 in epoch 1, gen_loss = 0.4348255622099681, disc_loss = 0.21384766513863243
Trained batch 83 in epoch 1, gen_loss = 0.43431701617581503, disc_loss = 0.2140019177237437
Trained batch 84 in epoch 1, gen_loss = 0.43500890381195967, disc_loss = 0.21327115398119478
Trained batch 85 in epoch 1, gen_loss = 0.4356484298789224, disc_loss = 0.21260671174630177
Trained batch 86 in epoch 1, gen_loss = 0.434861845668705, disc_loss = 0.21214827514071574
Trained batch 87 in epoch 1, gen_loss = 0.4344959841533141, disc_loss = 0.2120753167281774
Trained batch 88 in epoch 1, gen_loss = 0.43473009848862554, disc_loss = 0.2124554593157902
Trained batch 89 in epoch 1, gen_loss = 0.435329920384619, disc_loss = 0.211697766971257
Trained batch 90 in epoch 1, gen_loss = 0.4353786795348911, disc_loss = 0.21137319140873112
Trained batch 91 in epoch 1, gen_loss = 0.43544641461061395, disc_loss = 0.21103041469240966
Trained batch 92 in epoch 1, gen_loss = 0.4352760289305, disc_loss = 0.21216327284452735
Trained batch 93 in epoch 1, gen_loss = 0.4350544975159016, disc_loss = 0.211694917265088
Trained batch 94 in epoch 1, gen_loss = 0.4358402032601206, disc_loss = 0.21135369268687149
Trained batch 95 in epoch 1, gen_loss = 0.4354920558010538, disc_loss = 0.21180930403837314
Trained batch 96 in epoch 1, gen_loss = 0.43578327500943054, disc_loss = 0.21061665169203403
Trained batch 97 in epoch 1, gen_loss = 0.43547408586862135, disc_loss = 0.20958599930971253
Trained batch 98 in epoch 1, gen_loss = 0.4351858680296426, disc_loss = 0.20880271054127
Trained batch 99 in epoch 1, gen_loss = 0.43561544597148893, disc_loss = 0.20839410912245512
Trained batch 100 in epoch 1, gen_loss = 0.4348950273919814, disc_loss = 0.20881615693468858
Trained batch 101 in epoch 1, gen_loss = 0.4353695219638301, disc_loss = 0.20842974176447765
Trained batch 102 in epoch 1, gen_loss = 0.43597333523833637, disc_loss = 0.20752955752524357
Trained batch 103 in epoch 1, gen_loss = 0.4361623835105162, disc_loss = 0.20650255311137208
Trained batch 104 in epoch 1, gen_loss = 0.4359777740069798, disc_loss = 0.20644975180427233
Trained batch 105 in epoch 1, gen_loss = 0.43676960468292236, disc_loss = 0.20855106627744324
Trained batch 106 in epoch 1, gen_loss = 0.43662103704202954, disc_loss = 0.20780745124287694
Trained batch 107 in epoch 1, gen_loss = 0.4364199011966034, disc_loss = 0.20680586528033018
Trained batch 108 in epoch 1, gen_loss = 0.4360906238402795, disc_loss = 0.20656536851044094
Trained batch 109 in epoch 1, gen_loss = 0.43590212166309356, disc_loss = 0.20641899207098918
Trained batch 110 in epoch 1, gen_loss = 0.43553729610400155, disc_loss = 0.20513157979459376
Trained batch 111 in epoch 1, gen_loss = 0.43498071070228306, disc_loss = 0.20584820307392096
Trained batch 112 in epoch 1, gen_loss = 0.43483379140364387, disc_loss = 0.20547630331289451
Trained batch 113 in epoch 1, gen_loss = 0.4352302287231412, disc_loss = 0.20562195166814745
Trained batch 114 in epoch 1, gen_loss = 0.4349336730397266, disc_loss = 0.20520959098054015
Trained batch 115 in epoch 1, gen_loss = 0.4351934803457096, disc_loss = 0.20439214448862034
Trained batch 116 in epoch 1, gen_loss = 0.43538325362735325, disc_loss = 0.20335540535230923
Trained batch 117 in epoch 1, gen_loss = 0.43574065525653, disc_loss = 0.20237250787095498
Trained batch 118 in epoch 1, gen_loss = 0.43530950175613914, disc_loss = 0.201650482359804
Trained batch 119 in epoch 1, gen_loss = 0.43494040071964263, disc_loss = 0.2008561534496645
Trained batch 120 in epoch 1, gen_loss = 0.43552695374843503, disc_loss = 0.2026022234546744
Trained batch 121 in epoch 1, gen_loss = 0.43583791837340496, disc_loss = 0.20143008726786393
Trained batch 122 in epoch 1, gen_loss = 0.43537598921031484, disc_loss = 0.20214339200316406
Trained batch 123 in epoch 1, gen_loss = 0.4354134223634197, disc_loss = 0.20351473272087112
Trained batch 124 in epoch 1, gen_loss = 0.43553676557540894, disc_loss = 0.203619617164135
Trained batch 125 in epoch 1, gen_loss = 0.4354818243355978, disc_loss = 0.20423665826046278
Trained batch 126 in epoch 1, gen_loss = 0.4346519225225674, disc_loss = 0.20415835147063563
Trained batch 127 in epoch 1, gen_loss = 0.43409056426025927, disc_loss = 0.20430938439676538
Trained batch 128 in epoch 1, gen_loss = 0.4337207545605741, disc_loss = 0.2043070603133172
Trained batch 129 in epoch 1, gen_loss = 0.4331882843604455, disc_loss = 0.20421872202020425
Trained batch 130 in epoch 1, gen_loss = 0.4328084829199405, disc_loss = 0.20415847737143059
Trained batch 131 in epoch 1, gen_loss = 0.43222198183789395, disc_loss = 0.20399697830505442
Trained batch 132 in epoch 1, gen_loss = 0.43195212962932156, disc_loss = 0.20378589859806506
Trained batch 133 in epoch 1, gen_loss = 0.43187964852176497, disc_loss = 0.20318991707554504
Trained batch 134 in epoch 1, gen_loss = 0.43139769236246744, disc_loss = 0.20405806948741276
Trained batch 135 in epoch 1, gen_loss = 0.4314019772059777, disc_loss = 0.20469862885554047
Trained batch 136 in epoch 1, gen_loss = 0.43110766354268487, disc_loss = 0.20467321525742538
Trained batch 137 in epoch 1, gen_loss = 0.43122066276660864, disc_loss = 0.2038015120163344
Trained batch 138 in epoch 1, gen_loss = 0.4305492270764687, disc_loss = 0.20349525306507837
Trained batch 139 in epoch 1, gen_loss = 0.43071928662913184, disc_loss = 0.20290729366242885
Trained batch 140 in epoch 1, gen_loss = 0.4308723232424851, disc_loss = 0.20189384096269067
Trained batch 141 in epoch 1, gen_loss = 0.43048512075148837, disc_loss = 0.20231724965950132
Trained batch 142 in epoch 1, gen_loss = 0.430713365544806, disc_loss = 0.20284739204428412
Trained batch 143 in epoch 1, gen_loss = 0.43071096390485764, disc_loss = 0.20221291259965962
Trained batch 144 in epoch 1, gen_loss = 0.4304034052223995, disc_loss = 0.2014062526924857
Trained batch 145 in epoch 1, gen_loss = 0.4300655932867364, disc_loss = 0.20127153161862124
Trained batch 146 in epoch 1, gen_loss = 0.4300365488545424, disc_loss = 0.20235073049457705
Trained batch 147 in epoch 1, gen_loss = 0.43032733673179474, disc_loss = 0.20157582473915978
Trained batch 148 in epoch 1, gen_loss = 0.42986030486606114, disc_loss = 0.20137882082654326
Trained batch 149 in epoch 1, gen_loss = 0.42955363015333814, disc_loss = 0.20158798118432364
Trained batch 150 in epoch 1, gen_loss = 0.4297608154893711, disc_loss = 0.20149258450167068
Trained batch 151 in epoch 1, gen_loss = 0.42949585224452774, disc_loss = 0.20157106838336117
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.3635346293449402, disc_loss = 0.20075055956840515
Trained batch 1 in epoch 2, gen_loss = 0.3854866921901703, disc_loss = 0.22543968260288239
Trained batch 2 in epoch 2, gen_loss = 0.3792881766955058, disc_loss = 0.24146980047225952
Trained batch 3 in epoch 2, gen_loss = 0.39317481219768524, disc_loss = 0.24615853279829025
Trained batch 4 in epoch 2, gen_loss = 0.3925511300563812, disc_loss = 0.22296047508716582
Trained batch 5 in epoch 2, gen_loss = 0.38472213347752887, disc_loss = 0.24969249218702316
Trained batch 6 in epoch 2, gen_loss = 0.3834990007536752, disc_loss = 0.2425078238759722
Trained batch 7 in epoch 2, gen_loss = 0.39111632853746414, disc_loss = 0.23460092023015022
Trained batch 8 in epoch 2, gen_loss = 0.3911019232538011, disc_loss = 0.22407274279329512
Trained batch 9 in epoch 2, gen_loss = 0.3856008589267731, disc_loss = 0.22062191367149353
Trained batch 10 in epoch 2, gen_loss = 0.3836504437706687, disc_loss = 0.22293915802782233
Trained batch 11 in epoch 2, gen_loss = 0.3861166735490163, disc_loss = 0.21676094084978104
Trained batch 12 in epoch 2, gen_loss = 0.3868447267092191, disc_loss = 0.20893487219627088
Trained batch 13 in epoch 2, gen_loss = 0.3891957998275757, disc_loss = 0.20205758405583246
Trained batch 14 in epoch 2, gen_loss = 0.3877551356951396, disc_loss = 0.19697065353393556
Trained batch 15 in epoch 2, gen_loss = 0.3935693632811308, disc_loss = 0.19008775148540735
Trained batch 16 in epoch 2, gen_loss = 0.39553438915925865, disc_loss = 0.1862375639817294
Trained batch 17 in epoch 2, gen_loss = 0.3967934283945296, disc_loss = 0.18722387651602426
Trained batch 18 in epoch 2, gen_loss = 0.3938985043450406, disc_loss = 0.19346323295643456
Trained batch 19 in epoch 2, gen_loss = 0.3934712141752243, disc_loss = 0.1934272490441799
Trained batch 20 in epoch 2, gen_loss = 0.3943647728079841, disc_loss = 0.18774056576547168
Trained batch 21 in epoch 2, gen_loss = 0.39230087399482727, disc_loss = 0.19176115637475794
Trained batch 22 in epoch 2, gen_loss = 0.39139493781587353, disc_loss = 0.19100111269432565
Trained batch 23 in epoch 2, gen_loss = 0.3954493763546149, disc_loss = 0.18919550441205502
Trained batch 24 in epoch 2, gen_loss = 0.39394343018531797, disc_loss = 0.18391068413853645
Trained batch 25 in epoch 2, gen_loss = 0.39206575888853806, disc_loss = 0.1929552023513959
Trained batch 26 in epoch 2, gen_loss = 0.39392288746657195, disc_loss = 0.19462530328719704
Trained batch 27 in epoch 2, gen_loss = 0.39625604982886997, disc_loss = 0.19490178634545632
Trained batch 28 in epoch 2, gen_loss = 0.397774750816411, disc_loss = 0.192792779027388
Trained batch 29 in epoch 2, gen_loss = 0.3966530273358027, disc_loss = 0.19070934218664964
Trained batch 30 in epoch 2, gen_loss = 0.39614790485751245, disc_loss = 0.19062929876869725
Trained batch 31 in epoch 2, gen_loss = 0.39600361976772547, disc_loss = 0.1904943158151582
Trained batch 32 in epoch 2, gen_loss = 0.3982177701863376, disc_loss = 0.1875888512215831
Trained batch 33 in epoch 2, gen_loss = 0.3998258411884308, disc_loss = 0.18414231203496456
Trained batch 34 in epoch 2, gen_loss = 0.3994747757911682, disc_loss = 0.1828401428248201
Trained batch 35 in epoch 2, gen_loss = 0.39917802893453175, disc_loss = 0.18187498042566907
Trained batch 36 in epoch 2, gen_loss = 0.3990813123213278, disc_loss = 0.18014067119440516
Trained batch 37 in epoch 2, gen_loss = 0.3991507291793823, disc_loss = 0.18047891625840412
Trained batch 38 in epoch 2, gen_loss = 0.399743799215708, disc_loss = 0.17869484071166086
Trained batch 39 in epoch 2, gen_loss = 0.40009900480508803, disc_loss = 0.17699736123904586
Trained batch 40 in epoch 2, gen_loss = 0.39965697832223845, disc_loss = 0.17618618569359545
Trained batch 41 in epoch 2, gen_loss = 0.4018025320200693, disc_loss = 0.17405660885075727
Trained batch 42 in epoch 2, gen_loss = 0.4021466429843459, disc_loss = 0.1728933657151322
Trained batch 43 in epoch 2, gen_loss = 0.4020812890746377, disc_loss = 0.17350212509997867
Trained batch 44 in epoch 2, gen_loss = 0.4019513295756446, disc_loss = 0.18602922053800688
Trained batch 45 in epoch 2, gen_loss = 0.40189174789449444, disc_loss = 0.1911920719658551
Trained batch 46 in epoch 2, gen_loss = 0.402915081445207, disc_loss = 0.20146427216364982
Trained batch 47 in epoch 2, gen_loss = 0.4022795483469963, disc_loss = 0.20855044410564005
Trained batch 48 in epoch 2, gen_loss = 0.4019549245737037, disc_loss = 0.2094940527209214
Trained batch 49 in epoch 2, gen_loss = 0.4016882359981537, disc_loss = 0.21052988909184933
Trained batch 50 in epoch 2, gen_loss = 0.40421907340779023, disc_loss = 0.2084638729837595
Trained batch 51 in epoch 2, gen_loss = 0.4027248586599643, disc_loss = 0.20869492961523625
Trained batch 52 in epoch 2, gen_loss = 0.40139865031782185, disc_loss = 0.2084844373166561
Trained batch 53 in epoch 2, gen_loss = 0.4013669325245751, disc_loss = 0.2076547589428999
Trained batch 54 in epoch 2, gen_loss = 0.40180027105591515, disc_loss = 0.20707529072057118
Trained batch 55 in epoch 2, gen_loss = 0.4017406313547066, disc_loss = 0.2067108238781137
Trained batch 56 in epoch 2, gen_loss = 0.4019188436499813, disc_loss = 0.20548114330883613
Trained batch 57 in epoch 2, gen_loss = 0.4018475957985582, disc_loss = 0.20581602221675988
Trained batch 58 in epoch 2, gen_loss = 0.40162822705204204, disc_loss = 0.2057655879880412
Trained batch 59 in epoch 2, gen_loss = 0.4018136923511823, disc_loss = 0.2056263140713175
Trained batch 60 in epoch 2, gen_loss = 0.40144709729757466, disc_loss = 0.2055880998368146
Trained batch 61 in epoch 2, gen_loss = 0.402046273312261, disc_loss = 0.20693109154460892
Trained batch 62 in epoch 2, gen_loss = 0.4012062085999383, disc_loss = 0.20888824542126957
Trained batch 63 in epoch 2, gen_loss = 0.4011614085175097, disc_loss = 0.20855819730786607
Trained batch 64 in epoch 2, gen_loss = 0.4005747643800882, disc_loss = 0.20806923984335018
Trained batch 65 in epoch 2, gen_loss = 0.40069788604071643, disc_loss = 0.2076986962082711
Trained batch 66 in epoch 2, gen_loss = 0.40096445670768394, disc_loss = 0.20788694022973972
Trained batch 67 in epoch 2, gen_loss = 0.40106624671641516, disc_loss = 0.20780201689066255
Trained batch 68 in epoch 2, gen_loss = 0.400119849305222, disc_loss = 0.21049665146763774
Trained batch 69 in epoch 2, gen_loss = 0.3999382563999721, disc_loss = 0.20926262475550175
Trained batch 70 in epoch 2, gen_loss = 0.40077960952906544, disc_loss = 0.2081135044949995
Trained batch 71 in epoch 2, gen_loss = 0.4009634645448791, disc_loss = 0.20762782455939385
Trained batch 72 in epoch 2, gen_loss = 0.4005918617117895, disc_loss = 0.2074891893728955
Trained batch 73 in epoch 2, gen_loss = 0.40081900881754384, disc_loss = 0.20779001949405349
Trained batch 74 in epoch 2, gen_loss = 0.4008102202415466, disc_loss = 0.20849398290117582
Trained batch 75 in epoch 2, gen_loss = 0.40082039644843653, disc_loss = 0.2094234933488463
Trained batch 76 in epoch 2, gen_loss = 0.4006327266816969, disc_loss = 0.20948922242243567
Trained batch 77 in epoch 2, gen_loss = 0.4006503988534976, disc_loss = 0.20919534482826024
Trained batch 78 in epoch 2, gen_loss = 0.40099683894386773, disc_loss = 0.20726344644834724
Trained batch 79 in epoch 2, gen_loss = 0.4013929158449173, disc_loss = 0.20512139736674725
Trained batch 80 in epoch 2, gen_loss = 0.40113611574526187, disc_loss = 0.20307189216952265
Trained batch 81 in epoch 2, gen_loss = 0.4014413727492821, disc_loss = 0.2014355286047226
Trained batch 82 in epoch 2, gen_loss = 0.4033381306981466, disc_loss = 0.20059329962514968
Trained batch 83 in epoch 2, gen_loss = 0.40398359050353366, disc_loss = 0.19877595348017557
Trained batch 84 in epoch 2, gen_loss = 0.40416949531611274, disc_loss = 0.19916382291737725
Trained batch 85 in epoch 2, gen_loss = 0.40482609874980396, disc_loss = 0.19796051240937654
Trained batch 86 in epoch 2, gen_loss = 0.4059039864731931, disc_loss = 0.19724503673356156
Trained batch 87 in epoch 2, gen_loss = 0.40642514757134696, disc_loss = 0.1963991163806482
Trained batch 88 in epoch 2, gen_loss = 0.4067284538504783, disc_loss = 0.19455814600158272
Trained batch 89 in epoch 2, gen_loss = 0.4068027403619554, disc_loss = 0.19579870539406935
Trained batch 90 in epoch 2, gen_loss = 0.4078738401224325, disc_loss = 0.19812235666009095
Trained batch 91 in epoch 2, gen_loss = 0.4076767492553462, disc_loss = 0.19863434690658166
Trained batch 92 in epoch 2, gen_loss = 0.4076492225611082, disc_loss = 0.197997002551953
Trained batch 93 in epoch 2, gen_loss = 0.4082990542371222, disc_loss = 0.19652127954078483
Trained batch 94 in epoch 2, gen_loss = 0.4082283691356057, disc_loss = 0.19486443757226593
Trained batch 95 in epoch 2, gen_loss = 0.4077612118174632, disc_loss = 0.19322522077709436
Trained batch 96 in epoch 2, gen_loss = 0.4083300911888634, disc_loss = 0.19148332049551697
Trained batch 97 in epoch 2, gen_loss = 0.4079351872205734, disc_loss = 0.19037980669919324
Trained batch 98 in epoch 2, gen_loss = 0.40963108581726, disc_loss = 0.18918432603881816
Trained batch 99 in epoch 2, gen_loss = 0.4113125225901604, disc_loss = 0.1893537526577711
Trained batch 100 in epoch 2, gen_loss = 0.41271127539105934, disc_loss = 0.1879612024836611
Trained batch 101 in epoch 2, gen_loss = 0.4133656267441955, disc_loss = 0.18634842506007238
Trained batch 102 in epoch 2, gen_loss = 0.413293958288952, disc_loss = 0.1847068212600877
Trained batch 103 in epoch 2, gen_loss = 0.4135840715697178, disc_loss = 0.18351179581636992
Trained batch 104 in epoch 2, gen_loss = 0.4157875188759395, disc_loss = 0.18208273384897483
Trained batch 105 in epoch 2, gen_loss = 0.417269304394722, disc_loss = 0.18060408369198722
Trained batch 106 in epoch 2, gen_loss = 0.41802623645167486, disc_loss = 0.17897720228462854
Trained batch 107 in epoch 2, gen_loss = 0.4177629343337483, disc_loss = 0.17770023468916338
Trained batch 108 in epoch 2, gen_loss = 0.4185581538108511, disc_loss = 0.17631595832116287
Trained batch 109 in epoch 2, gen_loss = 0.419341444698247, disc_loss = 0.17478743713687767
Trained batch 110 in epoch 2, gen_loss = 0.4185586313943605, disc_loss = 0.17469465574836945
Trained batch 111 in epoch 2, gen_loss = 0.41929145795958384, disc_loss = 0.17519675943601346
Trained batch 112 in epoch 2, gen_loss = 0.4185358262167568, disc_loss = 0.1754066171701503
Trained batch 113 in epoch 2, gen_loss = 0.4192479480254023, disc_loss = 0.174809118798166
Trained batch 114 in epoch 2, gen_loss = 0.41965656772903775, disc_loss = 0.17363642016830652
Trained batch 115 in epoch 2, gen_loss = 0.4193111634973822, disc_loss = 0.17258918551920815
Trained batch 116 in epoch 2, gen_loss = 0.4186673910699339, disc_loss = 0.17465833934326458
Trained batch 117 in epoch 2, gen_loss = 0.4189491357843755, disc_loss = 0.17693889731446566
Trained batch 118 in epoch 2, gen_loss = 0.41898158017326803, disc_loss = 0.17626372571377194
Trained batch 119 in epoch 2, gen_loss = 0.41852126518885296, disc_loss = 0.17600330092633765
Trained batch 120 in epoch 2, gen_loss = 0.4182451020094974, disc_loss = 0.17712186883426895
Trained batch 121 in epoch 2, gen_loss = 0.41796601258340427, disc_loss = 0.17866384937259994
Trained batch 122 in epoch 2, gen_loss = 0.4176459079835473, disc_loss = 0.1790089056319822
Trained batch 123 in epoch 2, gen_loss = 0.41716792242180917, disc_loss = 0.1787838934950771
Trained batch 124 in epoch 2, gen_loss = 0.4165427281856537, disc_loss = 0.17887857249379158
Trained batch 125 in epoch 2, gen_loss = 0.41614571095459046, disc_loss = 0.17929524056140392
Trained batch 126 in epoch 2, gen_loss = 0.4160858702471876, disc_loss = 0.17966984379596598
Trained batch 127 in epoch 2, gen_loss = 0.41607081703841686, disc_loss = 0.17902908314135857
Trained batch 128 in epoch 2, gen_loss = 0.4154887885548348, disc_loss = 0.17998833876363066
Trained batch 129 in epoch 2, gen_loss = 0.4150871093456562, disc_loss = 0.18013503932609007
Trained batch 130 in epoch 2, gen_loss = 0.4150991862966814, disc_loss = 0.17970806016153051
Trained batch 131 in epoch 2, gen_loss = 0.4150394971172015, disc_loss = 0.17877917273929625
Trained batch 132 in epoch 2, gen_loss = 0.41479736342465967, disc_loss = 0.17800810064812353
Trained batch 133 in epoch 2, gen_loss = 0.41430078113256996, disc_loss = 0.17895874853676824
Trained batch 134 in epoch 2, gen_loss = 0.41447047414603055, disc_loss = 0.17934016038974127
Trained batch 135 in epoch 2, gen_loss = 0.4149189069867134, disc_loss = 0.17920003146590555
Trained batch 136 in epoch 2, gen_loss = 0.4150329932679225, disc_loss = 0.17801924992053614
Trained batch 137 in epoch 2, gen_loss = 0.4151574429394542, disc_loss = 0.17699519883625317
Trained batch 138 in epoch 2, gen_loss = 0.414516348418572, disc_loss = 0.17707078870412685
Trained batch 139 in epoch 2, gen_loss = 0.4148532373564584, disc_loss = 0.17622322907139149
Trained batch 140 in epoch 2, gen_loss = 0.41488893234983404, disc_loss = 0.17622068977472208
Trained batch 141 in epoch 2, gen_loss = 0.41469315701807047, disc_loss = 0.17517515908087222
Trained batch 142 in epoch 2, gen_loss = 0.41439591692044186, disc_loss = 0.17521168089673653
Trained batch 143 in epoch 2, gen_loss = 0.4142902060929272, disc_loss = 0.17448704256417435
Trained batch 144 in epoch 2, gen_loss = 0.4143290700583622, disc_loss = 0.17492843045499817
Trained batch 145 in epoch 2, gen_loss = 0.4144960256063775, disc_loss = 0.17500492635706108
Trained batch 146 in epoch 2, gen_loss = 0.41466292394261783, disc_loss = 0.1743769612366042
Trained batch 147 in epoch 2, gen_loss = 0.4148335654187847, disc_loss = 0.17348808131961002
Trained batch 148 in epoch 2, gen_loss = 0.4147071118322795, disc_loss = 0.17448657272296064
Trained batch 149 in epoch 2, gen_loss = 0.4152674408753713, disc_loss = 0.17515829246491194
Trained batch 150 in epoch 2, gen_loss = 0.4150295579275548, disc_loss = 0.17474571384785587
Trained batch 151 in epoch 2, gen_loss = 0.4151446480107935, disc_loss = 0.17383058992900738
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.38907551765441895, disc_loss = 0.10992466658353806
Trained batch 1 in epoch 3, gen_loss = 0.4131449908018112, disc_loss = 0.08985433354973793
Trained batch 2 in epoch 3, gen_loss = 0.43013861775398254, disc_loss = 0.09384210407733917
Trained batch 3 in epoch 3, gen_loss = 0.42264217138290405, disc_loss = 0.08823814988136292
Trained batch 4 in epoch 3, gen_loss = 0.42332274913787843, disc_loss = 0.0739462397992611
Trained batch 5 in epoch 3, gen_loss = 0.41366690397262573, disc_loss = 0.06975947072108586
Trained batch 6 in epoch 3, gen_loss = 0.41075313091278076, disc_loss = 0.0827477787222181
Trained batch 7 in epoch 3, gen_loss = 0.4034559018909931, disc_loss = 0.1058298908174038
Trained batch 8 in epoch 3, gen_loss = 0.4120324088467492, disc_loss = 0.10941376123163435
Trained batch 9 in epoch 3, gen_loss = 0.41774760782718656, disc_loss = 0.10564901977777481
Trained batch 10 in epoch 3, gen_loss = 0.4222523109479384, disc_loss = 0.09968196058815176
Trained batch 11 in epoch 3, gen_loss = 0.4241279984513919, disc_loss = 0.09533989429473877
Trained batch 12 in epoch 3, gen_loss = 0.4243482809800368, disc_loss = 0.08871222316072537
Trained batch 13 in epoch 3, gen_loss = 0.42391072639397215, disc_loss = 0.08483330825609821
Trained batch 14 in epoch 3, gen_loss = 0.4273882210254669, disc_loss = 0.08183738936980565
Trained batch 15 in epoch 3, gen_loss = 0.42689535208046436, disc_loss = 0.09031738853082061
Trained batch 16 in epoch 3, gen_loss = 0.42667895906111775, disc_loss = 0.09709536985439413
Trained batch 17 in epoch 3, gen_loss = 0.42445629835128784, disc_loss = 0.10265637147757742
Trained batch 18 in epoch 3, gen_loss = 0.42432840560611923, disc_loss = 0.10481771473821841
Trained batch 19 in epoch 3, gen_loss = 0.42962433099746705, disc_loss = 0.11001482792198658
Trained batch 20 in epoch 3, gen_loss = 0.42683439879190355, disc_loss = 0.1096682498852412
Trained batch 21 in epoch 3, gen_loss = 0.42518833821470087, disc_loss = 0.10850002752109007
Trained batch 22 in epoch 3, gen_loss = 0.42706991926483484, disc_loss = 0.11090718987195389
Trained batch 23 in epoch 3, gen_loss = 0.42330482974648476, disc_loss = 0.12213287316262722
Trained batch 24 in epoch 3, gen_loss = 0.42189002156257627, disc_loss = 0.12373588502407074
Trained batch 25 in epoch 3, gen_loss = 0.4226955565122458, disc_loss = 0.12708489138346452
Trained batch 26 in epoch 3, gen_loss = 0.4232317165092186, disc_loss = 0.12530611979740638
Trained batch 27 in epoch 3, gen_loss = 0.4216834796326501, disc_loss = 0.12187565730086394
Trained batch 28 in epoch 3, gen_loss = 0.42111393501018657, disc_loss = 0.11882725203859396
Trained batch 29 in epoch 3, gen_loss = 0.4192520081996918, disc_loss = 0.12031625906626384
Trained batch 30 in epoch 3, gen_loss = 0.4221007593216435, disc_loss = 0.12048121181226545
Trained batch 31 in epoch 3, gen_loss = 0.4220898449420929, disc_loss = 0.11864914232864976
Trained batch 32 in epoch 3, gen_loss = 0.42113101753321563, disc_loss = 0.11734604474269983
Trained batch 33 in epoch 3, gen_loss = 0.41879187787280364, disc_loss = 0.12475750814465915
Trained batch 34 in epoch 3, gen_loss = 0.4203107638018472, disc_loss = 0.13147561294691903
Trained batch 35 in epoch 3, gen_loss = 0.4204152383738094, disc_loss = 0.13036857545375824
Trained batch 36 in epoch 3, gen_loss = 0.41890995405815745, disc_loss = 0.12907595751253334
Trained batch 37 in epoch 3, gen_loss = 0.417741101823355, disc_loss = 0.13439133547638593
Trained batch 38 in epoch 3, gen_loss = 0.4174215296904246, disc_loss = 0.13861438498283044
Trained batch 39 in epoch 3, gen_loss = 0.4170711226761341, disc_loss = 0.1404157506301999
Trained batch 40 in epoch 3, gen_loss = 0.41763681100635996, disc_loss = 0.14192399037320438
Trained batch 41 in epoch 3, gen_loss = 0.418496331288701, disc_loss = 0.13953410426066035
Trained batch 42 in epoch 3, gen_loss = 0.4175216257572174, disc_loss = 0.14424282017835352
Trained batch 43 in epoch 3, gen_loss = 0.4183006225661798, disc_loss = 0.14320943470705638
Trained batch 44 in epoch 3, gen_loss = 0.41879424651463826, disc_loss = 0.142937985724873
Trained batch 45 in epoch 3, gen_loss = 0.41638832636501477, disc_loss = 0.14526450148095255
Trained batch 46 in epoch 3, gen_loss = 0.41568165763895565, disc_loss = 0.14578770037661207
Trained batch 47 in epoch 3, gen_loss = 0.41546441552539665, disc_loss = 0.14754733288039765
Trained batch 48 in epoch 3, gen_loss = 0.41588394252621397, disc_loss = 0.14703546722932737
Trained batch 49 in epoch 3, gen_loss = 0.4146661788225174, disc_loss = 0.14843233779072762
Trained batch 50 in epoch 3, gen_loss = 0.41441140572230023, disc_loss = 0.15032092540287503
Trained batch 51 in epoch 3, gen_loss = 0.4135312936626948, disc_loss = 0.14992205354456717
Trained batch 52 in epoch 3, gen_loss = 0.4139015657721825, disc_loss = 0.14812224780051214
Trained batch 53 in epoch 3, gen_loss = 0.41315629416041905, disc_loss = 0.1491489825701272
Trained batch 54 in epoch 3, gen_loss = 0.4140329734845595, disc_loss = 0.15001041252504696
Trained batch 55 in epoch 3, gen_loss = 0.4136989728680679, disc_loss = 0.1523788402389203
Trained batch 56 in epoch 3, gen_loss = 0.41268744855596307, disc_loss = 0.15440300642921215
Trained batch 57 in epoch 3, gen_loss = 0.41286089040082075, disc_loss = 0.15429427975724483
Trained batch 58 in epoch 3, gen_loss = 0.4120278525150428, disc_loss = 0.15412333847607596
Trained batch 59 in epoch 3, gen_loss = 0.4107059399286906, disc_loss = 0.15629068203270435
Trained batch 60 in epoch 3, gen_loss = 0.41040847340568165, disc_loss = 0.15679997877507915
Trained batch 61 in epoch 3, gen_loss = 0.41139922122801503, disc_loss = 0.15598022144648335
Trained batch 62 in epoch 3, gen_loss = 0.41176570833675447, disc_loss = 0.1541616100640524
Trained batch 63 in epoch 3, gen_loss = 0.41185461776331067, disc_loss = 0.15332583151757717
Trained batch 64 in epoch 3, gen_loss = 0.41171225217672497, disc_loss = 0.15193681510595175
Trained batch 65 in epoch 3, gen_loss = 0.41190802509134467, disc_loss = 0.15201248160817407
Trained batch 66 in epoch 3, gen_loss = 0.41186280837699546, disc_loss = 0.15221675207365803
Trained batch 67 in epoch 3, gen_loss = 0.41305843083297505, disc_loss = 0.15166279553052256
Trained batch 68 in epoch 3, gen_loss = 0.4130996171978937, disc_loss = 0.14975090702806693
Trained batch 69 in epoch 3, gen_loss = 0.4130873680114746, disc_loss = 0.15101926443832261
Trained batch 70 in epoch 3, gen_loss = 0.4134613917747014, disc_loss = 0.14965580246398147
Trained batch 71 in epoch 3, gen_loss = 0.4141726146141688, disc_loss = 0.14921118205206263
Trained batch 72 in epoch 3, gen_loss = 0.4150516774556408, disc_loss = 0.14733744347595598
Trained batch 73 in epoch 3, gen_loss = 0.4151428712380899, disc_loss = 0.14558906683295564
Trained batch 74 in epoch 3, gen_loss = 0.41461185852686566, disc_loss = 0.14530465176949897
Trained batch 75 in epoch 3, gen_loss = 0.4157608974921076, disc_loss = 0.14392569368264
Trained batch 76 in epoch 3, gen_loss = 0.41630904666789165, disc_loss = 0.14269860409345334
Trained batch 77 in epoch 3, gen_loss = 0.4179483480178393, disc_loss = 0.14098555300957882
Trained batch 78 in epoch 3, gen_loss = 0.4176904264884659, disc_loss = 0.13954396982076048
Trained batch 79 in epoch 3, gen_loss = 0.4165535241365433, disc_loss = 0.14059888424817474
Trained batch 80 in epoch 3, gen_loss = 0.416968857800519, disc_loss = 0.14393970998073066
Trained batch 81 in epoch 3, gen_loss = 0.41689908758896155, disc_loss = 0.1435852377198455
Trained batch 82 in epoch 3, gen_loss = 0.4162067232361759, disc_loss = 0.1437005163002086
Trained batch 83 in epoch 3, gen_loss = 0.41576145873183296, disc_loss = 0.1456110129088518
Trained batch 84 in epoch 3, gen_loss = 0.41582347610417536, disc_loss = 0.14758836269816933
Trained batch 85 in epoch 3, gen_loss = 0.41546572848807933, disc_loss = 0.14819813859757297
Trained batch 86 in epoch 3, gen_loss = 0.4156600558894804, disc_loss = 0.14702495609292354
Trained batch 87 in epoch 3, gen_loss = 0.4147862321273847, disc_loss = 0.14596056851389055
Trained batch 88 in epoch 3, gen_loss = 0.41411853071009175, disc_loss = 0.14473622583187698
Trained batch 89 in epoch 3, gen_loss = 0.4139576749669181, disc_loss = 0.14327976810228493
Trained batch 90 in epoch 3, gen_loss = 0.4141147487111144, disc_loss = 0.14180181739381054
Trained batch 91 in epoch 3, gen_loss = 0.41367795026820636, disc_loss = 0.14044730501937802
Trained batch 92 in epoch 3, gen_loss = 0.4135809928499242, disc_loss = 0.1408114871410753
Trained batch 93 in epoch 3, gen_loss = 0.41345662259040994, disc_loss = 0.14074204330074977
Trained batch 94 in epoch 3, gen_loss = 0.4134895280787819, disc_loss = 0.13998580064232413
Trained batch 95 in epoch 3, gen_loss = 0.413233006062607, disc_loss = 0.13976606291059093
Trained batch 96 in epoch 3, gen_loss = 0.4128587236723949, disc_loss = 0.14022976266623466
Trained batch 97 in epoch 3, gen_loss = 0.4133828480024727, disc_loss = 0.13991065854586812
Trained batch 98 in epoch 3, gen_loss = 0.41321121532507615, disc_loss = 0.14000307579496593
Trained batch 99 in epoch 3, gen_loss = 0.4125016701221466, disc_loss = 0.14175580113194883
Trained batch 100 in epoch 3, gen_loss = 0.4120257048323603, disc_loss = 0.1422106841911036
Trained batch 101 in epoch 3, gen_loss = 0.41229526435627656, disc_loss = 0.14186039040157317
Trained batch 102 in epoch 3, gen_loss = 0.41170468752823985, disc_loss = 0.14451574699645772
Trained batch 103 in epoch 3, gen_loss = 0.411514477374462, disc_loss = 0.14498963707592338
Trained batch 104 in epoch 3, gen_loss = 0.4117090557302747, disc_loss = 0.1453012490467656
Trained batch 105 in epoch 3, gen_loss = 0.4121881939892499, disc_loss = 0.14581908045758335
Trained batch 106 in epoch 3, gen_loss = 0.41164768159946546, disc_loss = 0.14764222070122154
Trained batch 107 in epoch 3, gen_loss = 0.41099895426520594, disc_loss = 0.14806660829560347
Trained batch 108 in epoch 3, gen_loss = 0.4109237456540449, disc_loss = 0.14856715499500342
Trained batch 109 in epoch 3, gen_loss = 0.41136820018291476, disc_loss = 0.1479240188459781
Trained batch 110 in epoch 3, gen_loss = 0.41127490379788856, disc_loss = 0.146979979491113
Trained batch 111 in epoch 3, gen_loss = 0.41098860491599354, disc_loss = 0.1470198005221651
Trained batch 112 in epoch 3, gen_loss = 0.4106857594663063, disc_loss = 0.14780945435528997
Trained batch 113 in epoch 3, gen_loss = 0.4110163583567268, disc_loss = 0.14897863729448432
Trained batch 114 in epoch 3, gen_loss = 0.41130851092545884, disc_loss = 0.14881680846700202
Trained batch 115 in epoch 3, gen_loss = 0.41127061175888985, disc_loss = 0.14789269831641738
Trained batch 116 in epoch 3, gen_loss = 0.41127764363574165, disc_loss = 0.14705673722215953
Trained batch 117 in epoch 3, gen_loss = 0.41130388667017725, disc_loss = 0.14597102406955623
Trained batch 118 in epoch 3, gen_loss = 0.41118642462401833, disc_loss = 0.14570461821687572
Trained batch 119 in epoch 3, gen_loss = 0.4117715758581956, disc_loss = 0.14496580102325726
Trained batch 120 in epoch 3, gen_loss = 0.4114978197684958, disc_loss = 0.14438914151261906
Trained batch 121 in epoch 3, gen_loss = 0.4122093234394417, disc_loss = 0.1433092272443483
Trained batch 122 in epoch 3, gen_loss = 0.4120859452864019, disc_loss = 0.14252882539408235
Trained batch 123 in epoch 3, gen_loss = 0.41258915369549104, disc_loss = 0.14164575006842853
Trained batch 124 in epoch 3, gen_loss = 0.412494277715683, disc_loss = 0.1418815890327096
Trained batch 125 in epoch 3, gen_loss = 0.4142389233623232, disc_loss = 0.14223936694629846
Trained batch 126 in epoch 3, gen_loss = 0.41508999795425594, disc_loss = 0.14131929047083056
Trained batch 127 in epoch 3, gen_loss = 0.4151862196158618, disc_loss = 0.14028659354517004
Trained batch 128 in epoch 3, gen_loss = 0.41516467767168386, disc_loss = 0.13940091698986384
Trained batch 129 in epoch 3, gen_loss = 0.41493047865537497, disc_loss = 0.13890536062849257
Trained batch 130 in epoch 3, gen_loss = 0.41613784022913636, disc_loss = 0.13827189725631747
Trained batch 131 in epoch 3, gen_loss = 0.416459026436011, disc_loss = 0.13749701737877773
Trained batch 132 in epoch 3, gen_loss = 0.41604007141930716, disc_loss = 0.13676672627014996
Trained batch 133 in epoch 3, gen_loss = 0.4154997881668717, disc_loss = 0.13666439392089622
Trained batch 134 in epoch 3, gen_loss = 0.4157639757350639, disc_loss = 0.1363016502379819
Trained batch 135 in epoch 3, gen_loss = 0.4159214301582645, disc_loss = 0.13643640857052935
Trained batch 136 in epoch 3, gen_loss = 0.4155743998767686, disc_loss = 0.13578009667269286
Trained batch 137 in epoch 3, gen_loss = 0.4153512871783713, disc_loss = 0.13767655017664251
Trained batch 138 in epoch 3, gen_loss = 0.41546839690036913, disc_loss = 0.1398033653754446
Trained batch 139 in epoch 3, gen_loss = 0.4151341983250209, disc_loss = 0.1402494057680347
Trained batch 140 in epoch 3, gen_loss = 0.4148354116061055, disc_loss = 0.14069368861325032
Trained batch 141 in epoch 3, gen_loss = 0.41440463800665356, disc_loss = 0.14145840396842277
Trained batch 142 in epoch 3, gen_loss = 0.4142642850642438, disc_loss = 0.14221159516592752
Trained batch 143 in epoch 3, gen_loss = 0.4140668252689971, disc_loss = 0.1426928069946977
Trained batch 144 in epoch 3, gen_loss = 0.41416751434063087, disc_loss = 0.14272452229955074
Trained batch 145 in epoch 3, gen_loss = 0.4144083910608945, disc_loss = 0.14205886336196571
Trained batch 146 in epoch 3, gen_loss = 0.41443794580543936, disc_loss = 0.1411706550604328
Trained batch 147 in epoch 3, gen_loss = 0.4145281026894982, disc_loss = 0.14037603704334312
Trained batch 148 in epoch 3, gen_loss = 0.41437898386244804, disc_loss = 0.13959611387885856
Trained batch 149 in epoch 3, gen_loss = 0.4140330457687378, disc_loss = 0.14078101004784305
Trained batch 150 in epoch 3, gen_loss = 0.41410934767186247, disc_loss = 0.14234779731352007
Trained batch 151 in epoch 3, gen_loss = 0.4138818604773597, disc_loss = 0.1429749394485139
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.3544401228427887, disc_loss = 0.19390805065631866
Trained batch 1 in epoch 4, gen_loss = 0.3700580298900604, disc_loss = 0.1615288034081459
Trained batch 2 in epoch 4, gen_loss = 0.3782389561335246, disc_loss = 0.1323726773262024
Trained batch 3 in epoch 4, gen_loss = 0.3842209130525589, disc_loss = 0.12087898701429367
Trained batch 4 in epoch 4, gen_loss = 0.37794668674468995, disc_loss = 0.1462600290775299
Trained batch 5 in epoch 4, gen_loss = 0.37863608201344806, disc_loss = 0.15333041548728943
Trained batch 6 in epoch 4, gen_loss = 0.388153748852866, disc_loss = 0.14472348349434988
Trained batch 7 in epoch 4, gen_loss = 0.3862670958042145, disc_loss = 0.1690945290029049
Trained batch 8 in epoch 4, gen_loss = 0.3861427903175354, disc_loss = 0.16347463925679526
Trained batch 9 in epoch 4, gen_loss = 0.38377671837806704, disc_loss = 0.1589917793869972
Trained batch 10 in epoch 4, gen_loss = 0.38154980540275574, disc_loss = 0.16013293916528876
Trained batch 11 in epoch 4, gen_loss = 0.38248734424511593, disc_loss = 0.15644951288898787
Trained batch 12 in epoch 4, gen_loss = 0.38834329751821667, disc_loss = 0.15175916713017684
Trained batch 13 in epoch 4, gen_loss = 0.3917362072638103, disc_loss = 0.15569107128041132
Trained batch 14 in epoch 4, gen_loss = 0.3939906140168508, disc_loss = 0.16249300340811412
Trained batch 15 in epoch 4, gen_loss = 0.3967159055173397, disc_loss = 0.15615539602003992
Trained batch 16 in epoch 4, gen_loss = 0.3964322244419771, disc_loss = 0.1545454471865121
Trained batch 17 in epoch 4, gen_loss = 0.3956983702050315, disc_loss = 0.16120081953704357
Trained batch 18 in epoch 4, gen_loss = 0.39859581307361003, disc_loss = 0.1749904357681149
Trained batch 19 in epoch 4, gen_loss = 0.398403400182724, disc_loss = 0.1698849393054843
Trained batch 20 in epoch 4, gen_loss = 0.3977801828157334, disc_loss = 0.16874507548553602
Trained batch 21 in epoch 4, gen_loss = 0.3967030481858687, disc_loss = 0.16321034814146432
Trained batch 22 in epoch 4, gen_loss = 0.3961819008640621, disc_loss = 0.16147996825368507
Trained batch 23 in epoch 4, gen_loss = 0.3969212348262469, disc_loss = 0.15805016659821072
Trained batch 24 in epoch 4, gen_loss = 0.39626609683036806, disc_loss = 0.15462925478816034
Trained batch 25 in epoch 4, gen_loss = 0.39783523174432606, disc_loss = 0.15032618263593087
Trained batch 26 in epoch 4, gen_loss = 0.39950110846095616, disc_loss = 0.14524955533582856
Trained batch 27 in epoch 4, gen_loss = 0.3999924010464123, disc_loss = 0.1408271116670221
Trained batch 28 in epoch 4, gen_loss = 0.40257254859496805, disc_loss = 0.1363438637284883
Trained batch 29 in epoch 4, gen_loss = 0.40448775788148245, disc_loss = 0.13214675933122635
Trained batch 30 in epoch 4, gen_loss = 0.405901062873102, disc_loss = 0.12824211762316765
Trained batch 31 in epoch 4, gen_loss = 0.4054704708978534, disc_loss = 0.12602256622631103
Trained batch 32 in epoch 4, gen_loss = 0.4078955478740461, disc_loss = 0.12438117249897032
Trained batch 33 in epoch 4, gen_loss = 0.40709122051210966, disc_loss = 0.13052909130997517
Trained batch 34 in epoch 4, gen_loss = 0.40751573869160246, disc_loss = 0.13359376245311327
Trained batch 35 in epoch 4, gen_loss = 0.4070432641439968, disc_loss = 0.1364451436739829
Trained batch 36 in epoch 4, gen_loss = 0.4072851570876869, disc_loss = 0.13745913120943146
Trained batch 37 in epoch 4, gen_loss = 0.4069301642869648, disc_loss = 0.1379692508397918
Trained batch 38 in epoch 4, gen_loss = 0.40646891104869354, disc_loss = 0.13810240926268774
Trained batch 39 in epoch 4, gen_loss = 0.4072976142168045, disc_loss = 0.1357845683582127
Trained batch 40 in epoch 4, gen_loss = 0.40636520414817623, disc_loss = 0.13737143439854063
Trained batch 41 in epoch 4, gen_loss = 0.40744449269203914, disc_loss = 0.1434447237600883
Trained batch 42 in epoch 4, gen_loss = 0.40935234413590543, disc_loss = 0.141081074036138
Trained batch 43 in epoch 4, gen_loss = 0.4085475741462274, disc_loss = 0.14126552107997917
Trained batch 44 in epoch 4, gen_loss = 0.4079500264591641, disc_loss = 0.14113909378647804
Trained batch 45 in epoch 4, gen_loss = 0.4083751686241316, disc_loss = 0.14220152285111987
Trained batch 46 in epoch 4, gen_loss = 0.40814470420492455, disc_loss = 0.14205115470797458
Trained batch 47 in epoch 4, gen_loss = 0.4077633072932561, disc_loss = 0.14310244137110809
Trained batch 48 in epoch 4, gen_loss = 0.4070419717808159, disc_loss = 0.14249481907000347
Trained batch 49 in epoch 4, gen_loss = 0.4062392431497574, disc_loss = 0.14073754467070101
Trained batch 50 in epoch 4, gen_loss = 0.4062129311701831, disc_loss = 0.13931567170748524
Trained batch 51 in epoch 4, gen_loss = 0.4053299811023932, disc_loss = 0.13878991075146657
Trained batch 52 in epoch 4, gen_loss = 0.40519653288823254, disc_loss = 0.13907771114751977
Trained batch 53 in epoch 4, gen_loss = 0.40645631816652084, disc_loss = 0.1381533421162102
Trained batch 54 in epoch 4, gen_loss = 0.40693727189844303, disc_loss = 0.13660221038894219
Trained batch 55 in epoch 4, gen_loss = 0.40772683758820805, disc_loss = 0.13555519968005164
Trained batch 56 in epoch 4, gen_loss = 0.4069944112970118, disc_loss = 0.13751953964432082
Trained batch 57 in epoch 4, gen_loss = 0.4075457751750946, disc_loss = 0.1398237205656438
Trained batch 58 in epoch 4, gen_loss = 0.40733270574424224, disc_loss = 0.13909212607195823
Trained batch 59 in epoch 4, gen_loss = 0.40657276958227156, disc_loss = 0.141581548191607
Trained batch 60 in epoch 4, gen_loss = 0.40637159396390443, disc_loss = 0.14116142952784164
Trained batch 61 in epoch 4, gen_loss = 0.4058112175233902, disc_loss = 0.14113558870890447
Trained batch 62 in epoch 4, gen_loss = 0.4051596091853248, disc_loss = 0.14134352210731732
Trained batch 63 in epoch 4, gen_loss = 0.4051851858384907, disc_loss = 0.14210025471402332
Trained batch 64 in epoch 4, gen_loss = 0.4046710321536431, disc_loss = 0.1424384657580119
Trained batch 65 in epoch 4, gen_loss = 0.40499042064854596, disc_loss = 0.14340925956088485
Trained batch 66 in epoch 4, gen_loss = 0.4046597827726336, disc_loss = 0.1448102559505114
Trained batch 67 in epoch 4, gen_loss = 0.40477701977771874, disc_loss = 0.14528740871259394
Trained batch 68 in epoch 4, gen_loss = 0.403827845186427, disc_loss = 0.14693788185283757
Trained batch 69 in epoch 4, gen_loss = 0.4051888772419521, disc_loss = 0.14673267895621914
Trained batch 70 in epoch 4, gen_loss = 0.4042154307096777, disc_loss = 0.1480958490619357
Trained batch 71 in epoch 4, gen_loss = 0.4038187861442566, disc_loss = 0.14921441379313669
Trained batch 72 in epoch 4, gen_loss = 0.40358084685181916, disc_loss = 0.15055352852564968
Trained batch 73 in epoch 4, gen_loss = 0.4034096361012072, disc_loss = 0.15176711890947175
Trained batch 74 in epoch 4, gen_loss = 0.4026128280162811, disc_loss = 0.15277686233321824
Trained batch 75 in epoch 4, gen_loss = 0.40222248827156265, disc_loss = 0.1546271286022506
Trained batch 76 in epoch 4, gen_loss = 0.40231524852963235, disc_loss = 0.15472325058532999
Trained batch 77 in epoch 4, gen_loss = 0.40293735686020976, disc_loss = 0.1536968969859374
Trained batch 78 in epoch 4, gen_loss = 0.4019718505913698, disc_loss = 0.15308520221446134
Trained batch 79 in epoch 4, gen_loss = 0.40064033344388006, disc_loss = 0.15475215413607657
Trained batch 80 in epoch 4, gen_loss = 0.40120324823591447, disc_loss = 0.1567650664091846
Trained batch 81 in epoch 4, gen_loss = 0.40124837581704303, disc_loss = 0.15698010224576403
Trained batch 82 in epoch 4, gen_loss = 0.40084641058760956, disc_loss = 0.15752329906246748
Trained batch 83 in epoch 4, gen_loss = 0.40005553513765335, disc_loss = 0.15854510935466914
Trained batch 84 in epoch 4, gen_loss = 0.399260453266256, disc_loss = 0.159960168117986
Trained batch 85 in epoch 4, gen_loss = 0.39909763426281686, disc_loss = 0.16109225418158743
Trained batch 86 in epoch 4, gen_loss = 0.39903603819594985, disc_loss = 0.16206006778553986
Trained batch 87 in epoch 4, gen_loss = 0.39914911782199686, disc_loss = 0.1616971444084563
Trained batch 88 in epoch 4, gen_loss = 0.39884083793404396, disc_loss = 0.16123064552967467
Trained batch 89 in epoch 4, gen_loss = 0.39837435086568196, disc_loss = 0.16164331738319662
Trained batch 90 in epoch 4, gen_loss = 0.398242738875714, disc_loss = 0.16243346923818955
Trained batch 91 in epoch 4, gen_loss = 0.39910243743139767, disc_loss = 0.1627865024315922
Trained batch 92 in epoch 4, gen_loss = 0.39897902390008333, disc_loss = 0.16191428959850343
Trained batch 93 in epoch 4, gen_loss = 0.398964505246345, disc_loss = 0.16046050385116262
Trained batch 94 in epoch 4, gen_loss = 0.3993169354765039, disc_loss = 0.15895326537521262
Trained batch 95 in epoch 4, gen_loss = 0.39879648853093386, disc_loss = 0.1582489349724104
Trained batch 96 in epoch 4, gen_loss = 0.39906993754131276, disc_loss = 0.15734474668183276
Trained batch 97 in epoch 4, gen_loss = 0.3997921843309792, disc_loss = 0.15627251546449808
Trained batch 98 in epoch 4, gen_loss = 0.3993164337042606, disc_loss = 0.15745727985043717
Trained batch 99 in epoch 4, gen_loss = 0.39937433540821077, disc_loss = 0.15924233209341765
Trained batch 100 in epoch 4, gen_loss = 0.4004000555170645, disc_loss = 0.1578869974554175
Trained batch 101 in epoch 4, gen_loss = 0.4003078218768625, disc_loss = 0.15676961517801472
Trained batch 102 in epoch 4, gen_loss = 0.39993378693617665, disc_loss = 0.15794760422799195
Trained batch 103 in epoch 4, gen_loss = 0.40033979857197177, disc_loss = 0.1589038045360492
Trained batch 104 in epoch 4, gen_loss = 0.4002018965425945, disc_loss = 0.158358894998119
Trained batch 105 in epoch 4, gen_loss = 0.39972150775621523, disc_loss = 0.15822274652573298
Trained batch 106 in epoch 4, gen_loss = 0.39956078044722015, disc_loss = 0.15872649186961005
Trained batch 107 in epoch 4, gen_loss = 0.39959699053455283, disc_loss = 0.1588293826552453
Trained batch 108 in epoch 4, gen_loss = 0.3997529753304403, disc_loss = 0.15895373989409262
Trained batch 109 in epoch 4, gen_loss = 0.39923993782563644, disc_loss = 0.1598989450796084
Trained batch 110 in epoch 4, gen_loss = 0.3995445120979, disc_loss = 0.16052925257800935
Trained batch 111 in epoch 4, gen_loss = 0.3996152420129095, disc_loss = 0.16098101630008646
Trained batch 112 in epoch 4, gen_loss = 0.3991153648996775, disc_loss = 0.16144658183365795
Trained batch 113 in epoch 4, gen_loss = 0.39901701896859887, disc_loss = 0.1619776316771382
Trained batch 114 in epoch 4, gen_loss = 0.398832426900449, disc_loss = 0.1625230949210084
Trained batch 115 in epoch 4, gen_loss = 0.3984567926361643, disc_loss = 0.16310255659808373
Trained batch 116 in epoch 4, gen_loss = 0.3980585267910591, disc_loss = 0.16359339406092963
Trained batch 117 in epoch 4, gen_loss = 0.3979280669305284, disc_loss = 0.16400988368412195
Trained batch 118 in epoch 4, gen_loss = 0.3973798734300277, disc_loss = 0.16440099509072906
Trained batch 119 in epoch 4, gen_loss = 0.397092263152202, disc_loss = 0.1651322487120827
Trained batch 120 in epoch 4, gen_loss = 0.39703750511831487, disc_loss = 0.16570999017678018
Trained batch 121 in epoch 4, gen_loss = 0.39669695911837405, disc_loss = 0.1660201658845925
Trained batch 122 in epoch 4, gen_loss = 0.3967415908487832, disc_loss = 0.16623067389416502
Trained batch 123 in epoch 4, gen_loss = 0.3961796964849195, disc_loss = 0.16617159707651985
Trained batch 124 in epoch 4, gen_loss = 0.39593527173995974, disc_loss = 0.16611756509542466
Trained batch 125 in epoch 4, gen_loss = 0.3959958392476279, disc_loss = 0.16673928741661329
Trained batch 126 in epoch 4, gen_loss = 0.39597316051092674, disc_loss = 0.16797958238153007
Trained batch 127 in epoch 4, gen_loss = 0.3961402317509055, disc_loss = 0.16911116690607741
Trained batch 128 in epoch 4, gen_loss = 0.3954320355903271, disc_loss = 0.1690921368178471
Trained batch 129 in epoch 4, gen_loss = 0.39512802614615516, disc_loss = 0.1690577183205348
Trained batch 130 in epoch 4, gen_loss = 0.39508870562524284, disc_loss = 0.16817440246125215
Trained batch 131 in epoch 4, gen_loss = 0.3949240039695393, disc_loss = 0.16706338983424235
Trained batch 132 in epoch 4, gen_loss = 0.39470031566189645, disc_loss = 0.16612576319366917
Trained batch 133 in epoch 4, gen_loss = 0.39462305738854764, disc_loss = 0.16590251496979105
Trained batch 134 in epoch 4, gen_loss = 0.39513148930337694, disc_loss = 0.16859754722703385
Trained batch 135 in epoch 4, gen_loss = 0.3951544998323216, disc_loss = 0.16778083963264875
Trained batch 136 in epoch 4, gen_loss = 0.3949693817726887, disc_loss = 0.16896103209659566
Trained batch 137 in epoch 4, gen_loss = 0.3950359048186869, disc_loss = 0.16866876386052024
Trained batch 138 in epoch 4, gen_loss = 0.39525987218609815, disc_loss = 0.16977393312259115
Trained batch 139 in epoch 4, gen_loss = 0.39519415838377814, disc_loss = 0.16992342159418122
Trained batch 140 in epoch 4, gen_loss = 0.39488947877647185, disc_loss = 0.1700439444274133
Trained batch 141 in epoch 4, gen_loss = 0.3947729073779684, disc_loss = 0.17015360827019937
Trained batch 142 in epoch 4, gen_loss = 0.3948917786975007, disc_loss = 0.17046269468337924
Trained batch 143 in epoch 4, gen_loss = 0.39492669825752574, disc_loss = 0.17078135044883108
Trained batch 144 in epoch 4, gen_loss = 0.3948757286729484, disc_loss = 0.17097354424667768
Trained batch 145 in epoch 4, gen_loss = 0.3943853929434737, disc_loss = 0.17124165733638283
Trained batch 146 in epoch 4, gen_loss = 0.39417556698630457, disc_loss = 0.17150643312049155
Trained batch 147 in epoch 4, gen_loss = 0.3938974067568779, disc_loss = 0.1716915661645298
Trained batch 148 in epoch 4, gen_loss = 0.39356033574014704, disc_loss = 0.17213561697144236
Trained batch 149 in epoch 4, gen_loss = 0.39362034380435945, disc_loss = 0.17219286726166805
Trained batch 150 in epoch 4, gen_loss = 0.3937839915026103, disc_loss = 0.17209157008455683
Trained batch 151 in epoch 4, gen_loss = 0.39381531018175575, disc_loss = 0.17187675575137532
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.3348146080970764, disc_loss = 0.2272447645664215
Trained batch 1 in epoch 5, gen_loss = 0.34396809339523315, disc_loss = 0.20614591985940933
Trained batch 2 in epoch 5, gen_loss = 0.3515383005142212, disc_loss = 0.20158928632736206
Trained batch 3 in epoch 5, gen_loss = 0.3623438850045204, disc_loss = 0.19659822061657906
Trained batch 4 in epoch 5, gen_loss = 0.3706317603588104, disc_loss = 0.20140520930290223
Trained batch 5 in epoch 5, gen_loss = 0.3759763439496358, disc_loss = 0.20500370115041733
Trained batch 6 in epoch 5, gen_loss = 0.3876775119985853, disc_loss = 0.2228935637644359
Trained batch 7 in epoch 5, gen_loss = 0.3841901235282421, disc_loss = 0.21719938702881336
Trained batch 8 in epoch 5, gen_loss = 0.38186753789583844, disc_loss = 0.20771331753995684
Trained batch 9 in epoch 5, gen_loss = 0.3827370285987854, disc_loss = 0.21062994748353958
Trained batch 10 in epoch 5, gen_loss = 0.38705420765009796, disc_loss = 0.21952119063247333
Trained batch 11 in epoch 5, gen_loss = 0.3838621949156125, disc_loss = 0.2196064628660679
Trained batch 12 in epoch 5, gen_loss = 0.3841735262137193, disc_loss = 0.22234099071759444
Trained batch 13 in epoch 5, gen_loss = 0.3801600805350712, disc_loss = 0.21928984033209936
Trained batch 14 in epoch 5, gen_loss = 0.37628345092137655, disc_loss = 0.21804310778776806
Trained batch 15 in epoch 5, gen_loss = 0.375675518065691, disc_loss = 0.21712372545152903
Trained batch 16 in epoch 5, gen_loss = 0.3762877338072833, disc_loss = 0.21409641556880055
Trained batch 17 in epoch 5, gen_loss = 0.37404852443271214, disc_loss = 0.21152676310804155
Trained batch 18 in epoch 5, gen_loss = 0.37289906489221675, disc_loss = 0.2122872691405447
Trained batch 19 in epoch 5, gen_loss = 0.37286418229341506, disc_loss = 0.2110512986779213
Trained batch 20 in epoch 5, gen_loss = 0.3719910851546696, disc_loss = 0.20882579542341687
Trained batch 21 in epoch 5, gen_loss = 0.37368250435048883, disc_loss = 0.20682114294984125
Trained batch 22 in epoch 5, gen_loss = 0.373618369517119, disc_loss = 0.20557968448037686
Trained batch 23 in epoch 5, gen_loss = 0.3720683803160985, disc_loss = 0.20441204495728016
Trained batch 24 in epoch 5, gen_loss = 0.37188750624656675, disc_loss = 0.2031481981277466
Trained batch 25 in epoch 5, gen_loss = 0.37083009573129505, disc_loss = 0.20111366189443147
Trained batch 26 in epoch 5, gen_loss = 0.3705017301771376, disc_loss = 0.2007851004600525
Trained batch 27 in epoch 5, gen_loss = 0.3729535000664847, disc_loss = 0.20072065400225775
Trained batch 28 in epoch 5, gen_loss = 0.3727740213788789, disc_loss = 0.19861159345199322
Trained batch 29 in epoch 5, gen_loss = 0.3740481545527776, disc_loss = 0.19379103978474935
Trained batch 30 in epoch 5, gen_loss = 0.3736591137224628, disc_loss = 0.19474906065771658
Trained batch 31 in epoch 5, gen_loss = 0.3743457980453968, disc_loss = 0.194819460157305
Trained batch 32 in epoch 5, gen_loss = 0.37504183342962555, disc_loss = 0.19359134589180801
Trained batch 33 in epoch 5, gen_loss = 0.37577664413872885, disc_loss = 0.19173838242011912
Trained batch 34 in epoch 5, gen_loss = 0.37678021107401166, disc_loss = 0.1933717544589724
Trained batch 35 in epoch 5, gen_loss = 0.3760143957204289, disc_loss = 0.19403670190109146
Trained batch 36 in epoch 5, gen_loss = 0.37574919011141805, disc_loss = 0.19662926930028038
Trained batch 37 in epoch 5, gen_loss = 0.3764195967661707, disc_loss = 0.20164366105669423
Trained batch 38 in epoch 5, gen_loss = 0.3759693931310605, disc_loss = 0.20470526547004014
Trained batch 39 in epoch 5, gen_loss = 0.37645059898495675, disc_loss = 0.2063951414078474
Trained batch 40 in epoch 5, gen_loss = 0.3769351978127549, disc_loss = 0.20721234126788815
Trained batch 41 in epoch 5, gen_loss = 0.37716354713553474, disc_loss = 0.20717347661654154
Trained batch 42 in epoch 5, gen_loss = 0.3767781909122023, disc_loss = 0.20686799357103747
Trained batch 43 in epoch 5, gen_loss = 0.3761425980112769, disc_loss = 0.20688915252685547
Trained batch 44 in epoch 5, gen_loss = 0.37571246226628624, disc_loss = 0.20765154096815322
Trained batch 45 in epoch 5, gen_loss = 0.37624935611434607, disc_loss = 0.2089694233044334
Trained batch 46 in epoch 5, gen_loss = 0.374163270630735, disc_loss = 0.2108648108675125
Trained batch 47 in epoch 5, gen_loss = 0.37361055177946884, disc_loss = 0.21235720937450728
Trained batch 48 in epoch 5, gen_loss = 0.37384170476271184, disc_loss = 0.21310208160050062
Trained batch 49 in epoch 5, gen_loss = 0.3733767706155777, disc_loss = 0.2135038447380066
Trained batch 50 in epoch 5, gen_loss = 0.3733243761109371, disc_loss = 0.21371665889141606
Trained batch 51 in epoch 5, gen_loss = 0.3734702748747972, disc_loss = 0.21352246747567102
Trained batch 52 in epoch 5, gen_loss = 0.37316253725087867, disc_loss = 0.21320894529234688
Trained batch 53 in epoch 5, gen_loss = 0.3725686294061166, disc_loss = 0.21321187085575527
Trained batch 54 in epoch 5, gen_loss = 0.37238258394328033, disc_loss = 0.21234157952395352
Trained batch 55 in epoch 5, gen_loss = 0.3717697619327477, disc_loss = 0.21221396406846388
Trained batch 56 in epoch 5, gen_loss = 0.37133214557380007, disc_loss = 0.21216476983145663
Trained batch 57 in epoch 5, gen_loss = 0.3716520718459425, disc_loss = 0.2113637171428779
Trained batch 58 in epoch 5, gen_loss = 0.37248697826417826, disc_loss = 0.21261728693873194
Trained batch 59 in epoch 5, gen_loss = 0.37204735626777014, disc_loss = 0.21245011662443478
Trained batch 60 in epoch 5, gen_loss = 0.37165723325776273, disc_loss = 0.21260712185844047
Trained batch 61 in epoch 5, gen_loss = 0.37168849091376027, disc_loss = 0.21243210545470637
Trained batch 62 in epoch 5, gen_loss = 0.3727048838895465, disc_loss = 0.2126890482410552
Trained batch 63 in epoch 5, gen_loss = 0.3730695201084018, disc_loss = 0.2127829750534147
Trained batch 64 in epoch 5, gen_loss = 0.37325432667365444, disc_loss = 0.21324523572738355
Trained batch 65 in epoch 5, gen_loss = 0.37306013658191217, disc_loss = 0.21413853877421582
Trained batch 66 in epoch 5, gen_loss = 0.37307380428954734, disc_loss = 0.21507235360679341
Trained batch 67 in epoch 5, gen_loss = 0.37290410741287117, disc_loss = 0.21564901203793638
Trained batch 68 in epoch 5, gen_loss = 0.3732073613698932, disc_loss = 0.21511994064718054
Trained batch 69 in epoch 5, gen_loss = 0.3741896948644093, disc_loss = 0.21487166179077966
Trained batch 70 in epoch 5, gen_loss = 0.3736744821071625, disc_loss = 0.21552387068808918
Trained batch 71 in epoch 5, gen_loss = 0.37316467323236996, disc_loss = 0.21634006520940197
Trained batch 72 in epoch 5, gen_loss = 0.37254508799069547, disc_loss = 0.21728074326090616
Trained batch 73 in epoch 5, gen_loss = 0.3726801191632812, disc_loss = 0.21668987721204758
Trained batch 74 in epoch 5, gen_loss = 0.3729654443264008, disc_loss = 0.2157815980911255
Trained batch 75 in epoch 5, gen_loss = 0.3731786447920297, disc_loss = 0.2152083598469433
Trained batch 76 in epoch 5, gen_loss = 0.37319604065511136, disc_loss = 0.21541151075394122
Trained batch 77 in epoch 5, gen_loss = 0.3730235237341661, disc_loss = 0.21538309657420868
Trained batch 78 in epoch 5, gen_loss = 0.37309082776685304, disc_loss = 0.21531671455389337
Trained batch 79 in epoch 5, gen_loss = 0.373289730027318, disc_loss = 0.2153183551505208
Trained batch 80 in epoch 5, gen_loss = 0.37296900521090004, disc_loss = 0.21538199410762315
Trained batch 81 in epoch 5, gen_loss = 0.3729644621290812, disc_loss = 0.21795277715456196
Trained batch 82 in epoch 5, gen_loss = 0.3730732141489006, disc_loss = 0.21781211445130497
Trained batch 83 in epoch 5, gen_loss = 0.37360309135346187, disc_loss = 0.21734443182746568
Trained batch 84 in epoch 5, gen_loss = 0.37377405131564423, disc_loss = 0.21701381925274343
Trained batch 85 in epoch 5, gen_loss = 0.37382102428480635, disc_loss = 0.2162485755113668
Trained batch 86 in epoch 5, gen_loss = 0.3736767433155542, disc_loss = 0.2150819075518641
Trained batch 87 in epoch 5, gen_loss = 0.3738277791575952, disc_loss = 0.21494942564855923
Trained batch 88 in epoch 5, gen_loss = 0.37408815776364185, disc_loss = 0.21467804456694742
Trained batch 89 in epoch 5, gen_loss = 0.3739156888590919, disc_loss = 0.21469727158546448
Trained batch 90 in epoch 5, gen_loss = 0.37405394361569333, disc_loss = 0.2145467202414523
Trained batch 91 in epoch 5, gen_loss = 0.3745677539187929, disc_loss = 0.21494760477672453
Trained batch 92 in epoch 5, gen_loss = 0.37488301306642513, disc_loss = 0.21407337278448124
Trained batch 93 in epoch 5, gen_loss = 0.37492518190373764, disc_loss = 0.21355251175291995
Trained batch 94 in epoch 5, gen_loss = 0.37465703456025373, disc_loss = 0.21392477358642378
Trained batch 95 in epoch 5, gen_loss = 0.3746686792001128, disc_loss = 0.21468415902927518
Trained batch 96 in epoch 5, gen_loss = 0.37422758371559617, disc_loss = 0.21501965359928682
Trained batch 97 in epoch 5, gen_loss = 0.37400518570627483, disc_loss = 0.21471809306923223
Trained batch 98 in epoch 5, gen_loss = 0.3738186251033436, disc_loss = 0.21434990038173368
Trained batch 99 in epoch 5, gen_loss = 0.37389837980270385, disc_loss = 0.21390863880515099
Trained batch 100 in epoch 5, gen_loss = 0.37394522086228477, disc_loss = 0.21351038347376455
Trained batch 101 in epoch 5, gen_loss = 0.3737315144024643, disc_loss = 0.21398388170728497
Trained batch 102 in epoch 5, gen_loss = 0.37333154678344727, disc_loss = 0.21393282610235861
Trained batch 103 in epoch 5, gen_loss = 0.373332431110052, disc_loss = 0.2137191817164421
Trained batch 104 in epoch 5, gen_loss = 0.37355642318725585, disc_loss = 0.21334015897342137
Trained batch 105 in epoch 5, gen_loss = 0.3736475905719793, disc_loss = 0.21242347549436227
Trained batch 106 in epoch 5, gen_loss = 0.373653424120395, disc_loss = 0.21327204702892036
Trained batch 107 in epoch 5, gen_loss = 0.37410816329496877, disc_loss = 0.2128594936458049
Trained batch 108 in epoch 5, gen_loss = 0.37396696866105456, disc_loss = 0.21191524283601604
Trained batch 109 in epoch 5, gen_loss = 0.37364625930786133, disc_loss = 0.21098027161576532
Trained batch 110 in epoch 5, gen_loss = 0.3738862547251555, disc_loss = 0.21042632371992678
Trained batch 111 in epoch 5, gen_loss = 0.3743213481668915, disc_loss = 0.2120952024789793
Trained batch 112 in epoch 5, gen_loss = 0.37377659488568266, disc_loss = 0.2132460853431077
Trained batch 113 in epoch 5, gen_loss = 0.3739386119863443, disc_loss = 0.21275960366454041
Trained batch 114 in epoch 5, gen_loss = 0.3740989661735037, disc_loss = 0.21280874078688414
Trained batch 115 in epoch 5, gen_loss = 0.3740626845894189, disc_loss = 0.21231386682082867
Trained batch 116 in epoch 5, gen_loss = 0.37395601343904805, disc_loss = 0.21170730888843536
Trained batch 117 in epoch 5, gen_loss = 0.37397576818021677, disc_loss = 0.212091564500736
Trained batch 118 in epoch 5, gen_loss = 0.37394610973967224, disc_loss = 0.2118841097885821
Trained batch 119 in epoch 5, gen_loss = 0.37406270106633505, disc_loss = 0.21137058747311432
Trained batch 120 in epoch 5, gen_loss = 0.3744717422595694, disc_loss = 0.21121301545091897
Trained batch 121 in epoch 5, gen_loss = 0.37491048945755256, disc_loss = 0.20997788906708115
Trained batch 122 in epoch 5, gen_loss = 0.37502688508692794, disc_loss = 0.20893968123851753
Trained batch 123 in epoch 5, gen_loss = 0.37520965717492566, disc_loss = 0.20802889809372924
Trained batch 124 in epoch 5, gen_loss = 0.37530265045166017, disc_loss = 0.20867139264941215
Trained batch 125 in epoch 5, gen_loss = 0.3757214286024608, disc_loss = 0.20965333469212055
Trained batch 126 in epoch 5, gen_loss = 0.37564139197191854, disc_loss = 0.20909136542537082
Trained batch 127 in epoch 5, gen_loss = 0.375901042483747, disc_loss = 0.20860441200784408
Trained batch 128 in epoch 5, gen_loss = 0.3756699885508811, disc_loss = 0.2078608457836532
Trained batch 129 in epoch 5, gen_loss = 0.37546480687764977, disc_loss = 0.2073425739717025
Trained batch 130 in epoch 5, gen_loss = 0.3755506304384188, disc_loss = 0.2070168981058452
Trained batch 131 in epoch 5, gen_loss = 0.3755404104789098, disc_loss = 0.20712737363734932
Trained batch 132 in epoch 5, gen_loss = 0.37553420886957556, disc_loss = 0.20635507208176126
Trained batch 133 in epoch 5, gen_loss = 0.3757307938675382, disc_loss = 0.2055128573426115
Trained batch 134 in epoch 5, gen_loss = 0.3758861541748047, disc_loss = 0.2043361735012796
Trained batch 135 in epoch 5, gen_loss = 0.3759458205279182, disc_loss = 0.20414758983122952
Trained batch 136 in epoch 5, gen_loss = 0.3764694006773677, disc_loss = 0.20493584833223455
Trained batch 137 in epoch 5, gen_loss = 0.37635073972784955, disc_loss = 0.20556967073808546
Trained batch 138 in epoch 5, gen_loss = 0.3761852568002056, disc_loss = 0.20519033422787414
Trained batch 139 in epoch 5, gen_loss = 0.37623002784592763, disc_loss = 0.20506307104868549
Trained batch 140 in epoch 5, gen_loss = 0.3760700690830853, disc_loss = 0.2048965556718779
Trained batch 141 in epoch 5, gen_loss = 0.37612682350084814, disc_loss = 0.20480385658816552
Trained batch 142 in epoch 5, gen_loss = 0.3767314795013908, disc_loss = 0.20477789155878387
Trained batch 143 in epoch 5, gen_loss = 0.37724409583542085, disc_loss = 0.20400897822239333
Trained batch 144 in epoch 5, gen_loss = 0.3772663932422112, disc_loss = 0.20380418665450195
Trained batch 145 in epoch 5, gen_loss = 0.3771323767835147, disc_loss = 0.20342520762183894
Trained batch 146 in epoch 5, gen_loss = 0.37713107730255646, disc_loss = 0.20346555585155682
Trained batch 147 in epoch 5, gen_loss = 0.3773077766637544, disc_loss = 0.2031078182060171
Trained batch 148 in epoch 5, gen_loss = 0.3771852312872074, disc_loss = 0.20291707474713358
Trained batch 149 in epoch 5, gen_loss = 0.37711708148320516, disc_loss = 0.20320166781544685
Trained batch 150 in epoch 5, gen_loss = 0.377508500948647, disc_loss = 0.20313171287443463
Trained batch 151 in epoch 5, gen_loss = 0.3774410474457239, disc_loss = 0.20317204066209102
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.3652031719684601, disc_loss = 0.19740022718906403
Trained batch 1 in epoch 6, gen_loss = 0.38098181784152985, disc_loss = 0.19359543174505234
Trained batch 2 in epoch 6, gen_loss = 0.37494797507921857, disc_loss = 0.19255264103412628
Trained batch 3 in epoch 6, gen_loss = 0.38168099522590637, disc_loss = 0.19297998771071434
Trained batch 4 in epoch 6, gen_loss = 0.3845302820205688, disc_loss = 0.19520476162433625
Trained batch 5 in epoch 6, gen_loss = 0.3953419029712677, disc_loss = 0.19683647404114404
Trained batch 6 in epoch 6, gen_loss = 0.38764685818127226, disc_loss = 0.20202972207750594
Trained batch 7 in epoch 6, gen_loss = 0.38756341114640236, disc_loss = 0.20538392663002014
Trained batch 8 in epoch 6, gen_loss = 0.38567132751146954, disc_loss = 0.19733687904145983
Trained batch 9 in epoch 6, gen_loss = 0.3856919676065445, disc_loss = 0.19186557531356813
Trained batch 10 in epoch 6, gen_loss = 0.3869250172918493, disc_loss = 0.19537610763853247
Trained batch 11 in epoch 6, gen_loss = 0.38558590163787204, disc_loss = 0.1964709535241127
Trained batch 12 in epoch 6, gen_loss = 0.38495214168842024, disc_loss = 0.19565899670124054
Trained batch 13 in epoch 6, gen_loss = 0.3853451630898884, disc_loss = 0.1938707988177027
Trained batch 14 in epoch 6, gen_loss = 0.3840724229812622, disc_loss = 0.18658941288789113
Trained batch 15 in epoch 6, gen_loss = 0.3840206954628229, disc_loss = 0.1794549892656505
Trained batch 16 in epoch 6, gen_loss = 0.38610617378178763, disc_loss = 0.1777749644482837
Trained batch 17 in epoch 6, gen_loss = 0.38818883564737106, disc_loss = 0.18435760877198643
Trained batch 18 in epoch 6, gen_loss = 0.39081658501374095, disc_loss = 0.20060586654826215
Trained batch 19 in epoch 6, gen_loss = 0.388237239420414, disc_loss = 0.20293699912726879
Trained batch 20 in epoch 6, gen_loss = 0.3873812442734128, disc_loss = 0.20697315498476937
Trained batch 21 in epoch 6, gen_loss = 0.38621601462364197, disc_loss = 0.21174162050539796
Trained batch 22 in epoch 6, gen_loss = 0.38425213098526, disc_loss = 0.209780302060687
Trained batch 23 in epoch 6, gen_loss = 0.3830060971279939, disc_loss = 0.20947774716963372
Trained batch 24 in epoch 6, gen_loss = 0.38208054423332216, disc_loss = 0.20748510211706161
Trained batch 25 in epoch 6, gen_loss = 0.3827590506810408, disc_loss = 0.2084189702111941
Trained batch 26 in epoch 6, gen_loss = 0.3800531504330812, disc_loss = 0.20979685501919854
Trained batch 27 in epoch 6, gen_loss = 0.37998611267123905, disc_loss = 0.20779331108289106
Trained batch 28 in epoch 6, gen_loss = 0.37907159225694065, disc_loss = 0.20727070112680568
Trained batch 29 in epoch 6, gen_loss = 0.3779226988554001, disc_loss = 0.20491744950413704
Trained batch 30 in epoch 6, gen_loss = 0.3777348726026474, disc_loss = 0.20258017869726305
Trained batch 31 in epoch 6, gen_loss = 0.3766973093152046, disc_loss = 0.200617442606017
Trained batch 32 in epoch 6, gen_loss = 0.3761388731725288, disc_loss = 0.19960590768041034
Trained batch 33 in epoch 6, gen_loss = 0.3761899033013512, disc_loss = 0.19980902728788993
Trained batch 34 in epoch 6, gen_loss = 0.3762771112578256, disc_loss = 0.20035546060119355
Trained batch 35 in epoch 6, gen_loss = 0.37527912937932545, disc_loss = 0.2025517016235325
Trained batch 36 in epoch 6, gen_loss = 0.37433997843716593, disc_loss = 0.2019734473244564
Trained batch 37 in epoch 6, gen_loss = 0.37440673614803116, disc_loss = 0.20102407606808761
Trained batch 38 in epoch 6, gen_loss = 0.3747895359992981, disc_loss = 0.2005527097827349
Trained batch 39 in epoch 6, gen_loss = 0.37470479160547254, disc_loss = 0.1984339075163007
Trained batch 40 in epoch 6, gen_loss = 0.37342813247587625, disc_loss = 0.1977094515431218
Trained batch 41 in epoch 6, gen_loss = 0.3751348427363804, disc_loss = 0.19667090777130353
Trained batch 42 in epoch 6, gen_loss = 0.3765474904415219, disc_loss = 0.1959928369452787
Trained batch 43 in epoch 6, gen_loss = 0.37605293840169907, disc_loss = 0.19865451058880848
Trained batch 44 in epoch 6, gen_loss = 0.376657106479009, disc_loss = 0.19729146146112017
Trained batch 45 in epoch 6, gen_loss = 0.37938665890175366, disc_loss = 0.19649877415403075
Trained batch 46 in epoch 6, gen_loss = 0.3780331484814908, disc_loss = 0.19579480192128648
Trained batch 47 in epoch 6, gen_loss = 0.3773300554603338, disc_loss = 0.19519643376891813
Trained batch 48 in epoch 6, gen_loss = 0.3773360459171996, disc_loss = 0.19456609186469292
Trained batch 49 in epoch 6, gen_loss = 0.37777788162231446, disc_loss = 0.1935468728840351
Trained batch 50 in epoch 6, gen_loss = 0.37671547777512493, disc_loss = 0.19313058330147875
Trained batch 51 in epoch 6, gen_loss = 0.37626404487169707, disc_loss = 0.1936231961903664
Trained batch 52 in epoch 6, gen_loss = 0.37780971459622653, disc_loss = 0.1947813097317264
Trained batch 53 in epoch 6, gen_loss = 0.37681839532322353, disc_loss = 0.1927905084082374
Trained batch 54 in epoch 6, gen_loss = 0.37637475728988645, disc_loss = 0.1941175570542162
Trained batch 55 in epoch 6, gen_loss = 0.37714888208678793, disc_loss = 0.19352348827357804
Trained batch 56 in epoch 6, gen_loss = 0.37707819855004027, disc_loss = 0.19371126840511957
Trained batch 57 in epoch 6, gen_loss = 0.3770709027504099, disc_loss = 0.1938171274960041
Trained batch 58 in epoch 6, gen_loss = 0.37682437745191283, disc_loss = 0.1927745353619931
Trained batch 59 in epoch 6, gen_loss = 0.3769007494052251, disc_loss = 0.1919749797632297
Trained batch 60 in epoch 6, gen_loss = 0.37636063773123946, disc_loss = 0.19161181457218576
Trained batch 61 in epoch 6, gen_loss = 0.37659519430129756, disc_loss = 0.19080111780954945
Trained batch 62 in epoch 6, gen_loss = 0.37747736109627616, disc_loss = 0.19149681369936655
Trained batch 63 in epoch 6, gen_loss = 0.37800431810319424, disc_loss = 0.19151593500282615
Trained batch 64 in epoch 6, gen_loss = 0.3784909147482652, disc_loss = 0.1924130713710418
Trained batch 65 in epoch 6, gen_loss = 0.3786263596830946, disc_loss = 0.1932824905397314
Trained batch 66 in epoch 6, gen_loss = 0.37847263555028543, disc_loss = 0.19565776446417196
Trained batch 67 in epoch 6, gen_loss = 0.3789326627464855, disc_loss = 0.19855631329119205
Trained batch 68 in epoch 6, gen_loss = 0.3785055245178333, disc_loss = 0.20022207854882532
Trained batch 69 in epoch 6, gen_loss = 0.3788800890956606, disc_loss = 0.20053598039916584
Trained batch 70 in epoch 6, gen_loss = 0.37974021594289326, disc_loss = 0.19989011961389597
Trained batch 71 in epoch 6, gen_loss = 0.3798527812792195, disc_loss = 0.19806099631306198
Trained batch 72 in epoch 6, gen_loss = 0.37931733874425494, disc_loss = 0.19792067851514034
Trained batch 73 in epoch 6, gen_loss = 0.37979451264884023, disc_loss = 0.19693933457538887
Trained batch 74 in epoch 6, gen_loss = 0.38007033546765645, disc_loss = 0.1960679383079211
Trained batch 75 in epoch 6, gen_loss = 0.3799139790629086, disc_loss = 0.19556113028604732
Trained batch 76 in epoch 6, gen_loss = 0.3794034038271223, disc_loss = 0.19518653206623993
Trained batch 77 in epoch 6, gen_loss = 0.37903125775166047, disc_loss = 0.1944438321277117
Trained batch 78 in epoch 6, gen_loss = 0.3787029102633271, disc_loss = 0.19561139871425268
Trained batch 79 in epoch 6, gen_loss = 0.37860965728759766, disc_loss = 0.1966087887994945
Trained batch 80 in epoch 6, gen_loss = 0.37930481301413643, disc_loss = 0.19782026783551698
Trained batch 81 in epoch 6, gen_loss = 0.3787407166347271, disc_loss = 0.19751804294746098
Trained batch 82 in epoch 6, gen_loss = 0.3789667067039444, disc_loss = 0.19859577903905548
Trained batch 83 in epoch 6, gen_loss = 0.37950056188163306, disc_loss = 0.19886658899486065
Trained batch 84 in epoch 6, gen_loss = 0.3794282983331119, disc_loss = 0.1988299374194706
Trained batch 85 in epoch 6, gen_loss = 0.38002940249997513, disc_loss = 0.1979395706466464
Trained batch 86 in epoch 6, gen_loss = 0.3796215499269551, disc_loss = 0.19799156238635382
Trained batch 87 in epoch 6, gen_loss = 0.37966504896228964, disc_loss = 0.19817943100563504
Trained batch 88 in epoch 6, gen_loss = 0.3792902910977267, disc_loss = 0.19756832576534722
Trained batch 89 in epoch 6, gen_loss = 0.37931689984268613, disc_loss = 0.19751767375402982
Trained batch 90 in epoch 6, gen_loss = 0.37906305901296844, disc_loss = 0.19690165193853798
Trained batch 91 in epoch 6, gen_loss = 0.3791812512537707, disc_loss = 0.19617511842237867
Trained batch 92 in epoch 6, gen_loss = 0.37898953467287044, disc_loss = 0.19526417665584114
Trained batch 93 in epoch 6, gen_loss = 0.37845404699761814, disc_loss = 0.19550884134591895
Trained batch 94 in epoch 6, gen_loss = 0.37883523075204145, disc_loss = 0.19599959740513248
Trained batch 95 in epoch 6, gen_loss = 0.3788327140112718, disc_loss = 0.19550308166071773
Trained batch 96 in epoch 6, gen_loss = 0.37912417809987803, disc_loss = 0.19481138654590882
Trained batch 97 in epoch 6, gen_loss = 0.37921450910519583, disc_loss = 0.1936403443010486
Trained batch 98 in epoch 6, gen_loss = 0.37903772249366297, disc_loss = 0.1929622306065126
Trained batch 99 in epoch 6, gen_loss = 0.37853511214256286, disc_loss = 0.1924943022429943
Trained batch 100 in epoch 6, gen_loss = 0.3785083733572818, disc_loss = 0.19304938304542316
Trained batch 101 in epoch 6, gen_loss = 0.37919600483249216, disc_loss = 0.19202827859450788
Trained batch 102 in epoch 6, gen_loss = 0.3791845938534413, disc_loss = 0.19083009710879
Trained batch 103 in epoch 6, gen_loss = 0.3788414394053129, disc_loss = 0.19028461144234127
Trained batch 104 in epoch 6, gen_loss = 0.3793372787180401, disc_loss = 0.18974220447597048
Trained batch 105 in epoch 6, gen_loss = 0.3798456256682018, disc_loss = 0.1886608658955907
Trained batch 106 in epoch 6, gen_loss = 0.3795871392031696, disc_loss = 0.189981733178981
Trained batch 107 in epoch 6, gen_loss = 0.3801405098703172, disc_loss = 0.1908962229197776
Trained batch 108 in epoch 6, gen_loss = 0.3804074468415812, disc_loss = 0.19001354242956967
Trained batch 109 in epoch 6, gen_loss = 0.38037164075808094, disc_loss = 0.19066223779862576
Trained batch 110 in epoch 6, gen_loss = 0.38059672391092453, disc_loss = 0.1902542296159375
Trained batch 111 in epoch 6, gen_loss = 0.3807753952486174, disc_loss = 0.18972350783380015
Trained batch 112 in epoch 6, gen_loss = 0.3803814831560692, disc_loss = 0.18917799094873192
Trained batch 113 in epoch 6, gen_loss = 0.38056365021488125, disc_loss = 0.1884188503680522
Trained batch 114 in epoch 6, gen_loss = 0.38044496722843335, disc_loss = 0.18764551767836446
Trained batch 115 in epoch 6, gen_loss = 0.38072297028426466, disc_loss = 0.18760517939668278
Trained batch 116 in epoch 6, gen_loss = 0.3804691591833392, disc_loss = 0.1879005361443911
Trained batch 117 in epoch 6, gen_loss = 0.3803197499048912, disc_loss = 0.18781546989487388
Trained batch 118 in epoch 6, gen_loss = 0.3804350963660649, disc_loss = 0.18764358552313654
Trained batch 119 in epoch 6, gen_loss = 0.38076830382148424, disc_loss = 0.1876302528505524
Trained batch 120 in epoch 6, gen_loss = 0.38106601987003297, disc_loss = 0.18703220396741363
Trained batch 121 in epoch 6, gen_loss = 0.38084683897065336, disc_loss = 0.18667231445185473
Trained batch 122 in epoch 6, gen_loss = 0.3812786146877258, disc_loss = 0.18645520962593032
Trained batch 123 in epoch 6, gen_loss = 0.3814102529037383, disc_loss = 0.18547456381061384
Trained batch 124 in epoch 6, gen_loss = 0.38113717079162596, disc_loss = 0.18518706983327865
Trained batch 125 in epoch 6, gen_loss = 0.3814749734269248, disc_loss = 0.1844298518484547
Trained batch 126 in epoch 6, gen_loss = 0.3819887161724211, disc_loss = 0.18419586198301766
Trained batch 127 in epoch 6, gen_loss = 0.38295128499157727, disc_loss = 0.18300053788698278
Trained batch 128 in epoch 6, gen_loss = 0.38281462820925455, disc_loss = 0.1819867211314597
Trained batch 129 in epoch 6, gen_loss = 0.38293905326953304, disc_loss = 0.18269579516580473
Trained batch 130 in epoch 6, gen_loss = 0.38393696824102913, disc_loss = 0.18421280284533065
Trained batch 131 in epoch 6, gen_loss = 0.3847000939827977, disc_loss = 0.18304604174795025
Trained batch 132 in epoch 6, gen_loss = 0.38429619293463857, disc_loss = 0.18447643962401644
Trained batch 133 in epoch 6, gen_loss = 0.38444573999340853, disc_loss = 0.18393654488861116
Trained batch 134 in epoch 6, gen_loss = 0.3844931874010298, disc_loss = 0.18378328119439108
Trained batch 135 in epoch 6, gen_loss = 0.38467996918103275, disc_loss = 0.18426154018379748
Trained batch 136 in epoch 6, gen_loss = 0.3843334682666472, disc_loss = 0.18423952033104252
Trained batch 137 in epoch 6, gen_loss = 0.3847259293863739, disc_loss = 0.18396024536881325
Trained batch 138 in epoch 6, gen_loss = 0.3855107102891524, disc_loss = 0.18327543741132288
Trained batch 139 in epoch 6, gen_loss = 0.38587122708559035, disc_loss = 0.18219221650755832
Trained batch 140 in epoch 6, gen_loss = 0.3859383093972578, disc_loss = 0.1811689767880854
Trained batch 141 in epoch 6, gen_loss = 0.3859244792813986, disc_loss = 0.18059417685415124
Trained batch 142 in epoch 6, gen_loss = 0.3856569739071639, disc_loss = 0.18111192050774197
Trained batch 143 in epoch 6, gen_loss = 0.3857853870011038, disc_loss = 0.18123920744336727
Trained batch 144 in epoch 6, gen_loss = 0.38567610691333637, disc_loss = 0.1805838038823728
Trained batch 145 in epoch 6, gen_loss = 0.3856829388500893, disc_loss = 0.17977405552535433
Trained batch 146 in epoch 6, gen_loss = 0.3855223481346961, disc_loss = 0.17916605422640738
Trained batch 147 in epoch 6, gen_loss = 0.3854249824543257, disc_loss = 0.17916954136327715
Trained batch 148 in epoch 6, gen_loss = 0.3855563642194607, disc_loss = 0.1795301078224942
Trained batch 149 in epoch 6, gen_loss = 0.3861640508969625, disc_loss = 0.17851927967121203
Trained batch 150 in epoch 6, gen_loss = 0.3858737436351397, disc_loss = 0.17850709554819477
Trained batch 151 in epoch 6, gen_loss = 0.3861658333947784, disc_loss = 0.1787610430589044
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.48327693343162537, disc_loss = 0.10395114868879318
Trained batch 1 in epoch 7, gen_loss = 0.46381185948848724, disc_loss = 0.06255913898348808
Trained batch 2 in epoch 7, gen_loss = 0.4349385201931, disc_loss = 0.0687428464492162
Trained batch 3 in epoch 7, gen_loss = 0.444094218313694, disc_loss = 0.05607719346880913
Trained batch 4 in epoch 7, gen_loss = 0.44222235679626465, disc_loss = 0.06419999450445175
Trained batch 5 in epoch 7, gen_loss = 0.4289521723985672, disc_loss = 0.08590652172764142
Trained batch 6 in epoch 7, gen_loss = 0.4315306075981685, disc_loss = 0.09084209054708481
Trained batch 7 in epoch 7, gen_loss = 0.44531485065817833, disc_loss = 0.09137925785034895
Trained batch 8 in epoch 7, gen_loss = 0.4486806293328603, disc_loss = 0.08291178941726685
Trained batch 9 in epoch 7, gen_loss = 0.43868834972381593, disc_loss = 0.10603237748146058
Trained batch 10 in epoch 7, gen_loss = 0.44021468270908704, disc_loss = 0.10768830234354193
Trained batch 11 in epoch 7, gen_loss = 0.4385051305095355, disc_loss = 0.10342486730466287
Trained batch 12 in epoch 7, gen_loss = 0.4481127697687883, disc_loss = 0.09681817803245324
Trained batch 13 in epoch 7, gen_loss = 0.4499681762286595, disc_loss = 0.09043750289960631
Trained batch 14 in epoch 7, gen_loss = 0.4498044828573863, disc_loss = 0.08550825929269194
Trained batch 15 in epoch 7, gen_loss = 0.44387974217534065, disc_loss = 0.08366465629660524
Trained batch 16 in epoch 7, gen_loss = 0.4474835430874544, disc_loss = 0.08229064648313557
Trained batch 17 in epoch 7, gen_loss = 0.44784408973322976, disc_loss = 0.07855431018914613
Trained batch 18 in epoch 7, gen_loss = 0.44601555403910187, disc_loss = 0.07529183043363064
Trained batch 19 in epoch 7, gen_loss = 0.44399032145738604, disc_loss = 0.07279292845632881
Trained batch 20 in epoch 7, gen_loss = 0.4433786159469968, disc_loss = 0.07307831036104333
Trained batch 21 in epoch 7, gen_loss = 0.4431181793863123, disc_loss = 0.0752498139838942
Trained batch 22 in epoch 7, gen_loss = 0.4425981122514476, disc_loss = 0.07920424103655893
Trained batch 23 in epoch 7, gen_loss = 0.4422892878452937, disc_loss = 0.07767288741888478
Trained batch 24 in epoch 7, gen_loss = 0.4415067172050476, disc_loss = 0.0758909629099071
Trained batch 25 in epoch 7, gen_loss = 0.4391896105729617, disc_loss = 0.07461337843694939
Trained batch 26 in epoch 7, gen_loss = 0.43637756285844026, disc_loss = 0.07450114451003848
Trained batch 27 in epoch 7, gen_loss = 0.4379659305725779, disc_loss = 0.07412711329691644
Trained batch 28 in epoch 7, gen_loss = 0.4401879546971157, disc_loss = 0.07318963044612058
Trained batch 29 in epoch 7, gen_loss = 0.4394213249286016, disc_loss = 0.07134751440025866
Trained batch 30 in epoch 7, gen_loss = 0.4377641552878964, disc_loss = 0.06994333308971216
Trained batch 31 in epoch 7, gen_loss = 0.4388167252764106, disc_loss = 0.06808048368839081
Trained batch 32 in epoch 7, gen_loss = 0.4369465338461327, disc_loss = 0.06959927622511079
Trained batch 33 in epoch 7, gen_loss = 0.43805935190004464, disc_loss = 0.07054215646348894
Trained batch 34 in epoch 7, gen_loss = 0.43963304247174945, disc_loss = 0.07187986904755235
Trained batch 35 in epoch 7, gen_loss = 0.4397728708055284, disc_loss = 0.07025147057397084
Trained batch 36 in epoch 7, gen_loss = 0.43928596619013194, disc_loss = 0.06984770634035403
Trained batch 37 in epoch 7, gen_loss = 0.4392410014805041, disc_loss = 0.0688213145629944
Trained batch 38 in epoch 7, gen_loss = 0.4384445196542984, disc_loss = 0.06783762429721463
Trained batch 39 in epoch 7, gen_loss = 0.4369734197854996, disc_loss = 0.06705810566199943
Trained batch 40 in epoch 7, gen_loss = 0.437268763053708, disc_loss = 0.06605786601899237
Trained batch 41 in epoch 7, gen_loss = 0.4407478031657991, disc_loss = 0.06671067707551022
Trained batch 42 in epoch 7, gen_loss = 0.44316003627555317, disc_loss = 0.06651634418643838
Trained batch 43 in epoch 7, gen_loss = 0.44364453513513913, disc_loss = 0.06592770402362062
Trained batch 44 in epoch 7, gen_loss = 0.4439344121350182, disc_loss = 0.06473460237806042
Trained batch 45 in epoch 7, gen_loss = 0.4431120487658874, disc_loss = 0.06359111941824465
Trained batch 46 in epoch 7, gen_loss = 0.4416918545327288, disc_loss = 0.06272478420485525
Trained batch 47 in epoch 7, gen_loss = 0.4404860542466243, disc_loss = 0.06355653721645164
Trained batch 48 in epoch 7, gen_loss = 0.44130872767798757, disc_loss = 0.06358511748780706
Trained batch 49 in epoch 7, gen_loss = 0.4426869469881058, disc_loss = 0.0636546930950135
Trained batch 50 in epoch 7, gen_loss = 0.4415995320853065, disc_loss = 0.0630945137008002
Trained batch 51 in epoch 7, gen_loss = 0.44205095733587557, disc_loss = 0.06208606219241539
Trained batch 52 in epoch 7, gen_loss = 0.44209036231040955, disc_loss = 0.06110782479375319
Trained batch 53 in epoch 7, gen_loss = 0.4424212663261979, disc_loss = 0.060279725714483194
Trained batch 54 in epoch 7, gen_loss = 0.4423307700590654, disc_loss = 0.05958060023628853
Trained batch 55 in epoch 7, gen_loss = 0.44170428280319485, disc_loss = 0.05906043026230431
Trained batch 56 in epoch 7, gen_loss = 0.4414885211409184, disc_loss = 0.05838925996795297
Trained batch 57 in epoch 7, gen_loss = 0.44243223451334857, disc_loss = 0.05753600588550085
Trained batch 58 in epoch 7, gen_loss = 0.4408486157150592, disc_loss = 0.05954363403084167
Trained batch 59 in epoch 7, gen_loss = 0.44152923276027045, disc_loss = 0.06848526513980081
Trained batch 60 in epoch 7, gen_loss = 0.44088354560195425, disc_loss = 0.0695319475346535
Trained batch 61 in epoch 7, gen_loss = 0.43920059598261313, disc_loss = 0.07074950146488845
Trained batch 62 in epoch 7, gen_loss = 0.4379370321357061, disc_loss = 0.0716148647184055
Trained batch 63 in epoch 7, gen_loss = 0.43719027237966657, disc_loss = 0.07404256743757287
Trained batch 64 in epoch 7, gen_loss = 0.43644813069930444, disc_loss = 0.07678827406265415
Trained batch 65 in epoch 7, gen_loss = 0.4354640444119771, disc_loss = 0.08029182112041974
Trained batch 66 in epoch 7, gen_loss = 0.43510386481213925, disc_loss = 0.08229286938822314
Trained batch 67 in epoch 7, gen_loss = 0.43454127627260547, disc_loss = 0.0842395555570393
Trained batch 68 in epoch 7, gen_loss = 0.43352667274682416, disc_loss = 0.0875074335751866
Trained batch 69 in epoch 7, gen_loss = 0.43361554145812986, disc_loss = 0.08876176213712565
Trained batch 70 in epoch 7, gen_loss = 0.43226957531042504, disc_loss = 0.09027055486328375
Trained batch 71 in epoch 7, gen_loss = 0.4322024683157603, disc_loss = 0.09076513446375935
Trained batch 72 in epoch 7, gen_loss = 0.43130553340258665, disc_loss = 0.09066212415210392
Trained batch 73 in epoch 7, gen_loss = 0.4308247082942241, disc_loss = 0.089864851988701
Trained batch 74 in epoch 7, gen_loss = 0.4301627735296885, disc_loss = 0.08912626060967645
Trained batch 75 in epoch 7, gen_loss = 0.42908895054930135, disc_loss = 0.09064462636965082
Trained batch 76 in epoch 7, gen_loss = 0.4297389577735554, disc_loss = 0.09368276957108022
Trained batch 77 in epoch 7, gen_loss = 0.42920354581796205, disc_loss = 0.09327479870392917
Trained batch 78 in epoch 7, gen_loss = 0.4279664713370649, disc_loss = 0.09352428869851216
Trained batch 79 in epoch 7, gen_loss = 0.4272575929760933, disc_loss = 0.09423830768209882
Trained batch 80 in epoch 7, gen_loss = 0.4267469114727444, disc_loss = 0.09515519898361814
Trained batch 81 in epoch 7, gen_loss = 0.42603855016754894, disc_loss = 0.09613651235406173
Trained batch 82 in epoch 7, gen_loss = 0.42547079561704615, disc_loss = 0.0958757988311889
Trained batch 83 in epoch 7, gen_loss = 0.4242820991646676, disc_loss = 0.09583709360699036
Trained batch 84 in epoch 7, gen_loss = 0.4234365691156948, disc_loss = 0.0979069552713019
Trained batch 85 in epoch 7, gen_loss = 0.42389862308668536, disc_loss = 0.10059465440315042
Trained batch 86 in epoch 7, gen_loss = 0.4233955819716399, disc_loss = 0.10095726560009108
Trained batch 87 in epoch 7, gen_loss = 0.4225209785456007, disc_loss = 0.10128672292392532
Trained batch 88 in epoch 7, gen_loss = 0.421715079733495, disc_loss = 0.10199996718634548
Trained batch 89 in epoch 7, gen_loss = 0.421064332458708, disc_loss = 0.10285018192500704
Trained batch 90 in epoch 7, gen_loss = 0.42034738338910616, disc_loss = 0.10306586593819353
Trained batch 91 in epoch 7, gen_loss = 0.419836548683436, disc_loss = 0.10431157285853734
Trained batch 92 in epoch 7, gen_loss = 0.41915845806880664, disc_loss = 0.10519639128738995
Trained batch 93 in epoch 7, gen_loss = 0.41934774625808635, disc_loss = 0.10539137776643831
Trained batch 94 in epoch 7, gen_loss = 0.41775697469711304, disc_loss = 0.10582214843383746
Trained batch 95 in epoch 7, gen_loss = 0.4169431310147047, disc_loss = 0.10622279484232422
Trained batch 96 in epoch 7, gen_loss = 0.41715197495578493, disc_loss = 0.1093165980335133
Trained batch 97 in epoch 7, gen_loss = 0.41642182335561634, disc_loss = 0.10976744867500146
Trained batch 98 in epoch 7, gen_loss = 0.41548830692214195, disc_loss = 0.11033348858149515
Trained batch 99 in epoch 7, gen_loss = 0.4150271585583687, disc_loss = 0.11065946115646512
Trained batch 100 in epoch 7, gen_loss = 0.4150282646169757, disc_loss = 0.11094347821401045
Trained batch 101 in epoch 7, gen_loss = 0.4145364369831833, disc_loss = 0.11087483473067336
Trained batch 102 in epoch 7, gen_loss = 0.4146763306219601, disc_loss = 0.11138259914694625
Trained batch 103 in epoch 7, gen_loss = 0.41430799261881757, disc_loss = 0.11207634252227414
Trained batch 104 in epoch 7, gen_loss = 0.41457284688949586, disc_loss = 0.11285076253559617
Trained batch 105 in epoch 7, gen_loss = 0.4143349933174421, disc_loss = 0.11338259334640824
Trained batch 106 in epoch 7, gen_loss = 0.4137323891448083, disc_loss = 0.11386516786432851
Trained batch 107 in epoch 7, gen_loss = 0.4131184943296291, disc_loss = 0.11481992968064905
Trained batch 108 in epoch 7, gen_loss = 0.41281479870507476, disc_loss = 0.1151235262060179
Trained batch 109 in epoch 7, gen_loss = 0.41270311962474476, disc_loss = 0.11554485476914454
Trained batch 110 in epoch 7, gen_loss = 0.41295709856995594, disc_loss = 0.11543726986945346
Trained batch 111 in epoch 7, gen_loss = 0.4123987622026886, disc_loss = 0.11520469999023979
Trained batch 112 in epoch 7, gen_loss = 0.4119735188716281, disc_loss = 0.11534730297620449
Trained batch 113 in epoch 7, gen_loss = 0.4117983621463441, disc_loss = 0.11490158402164907
Trained batch 114 in epoch 7, gen_loss = 0.4117310630238574, disc_loss = 0.11524546358977324
Trained batch 115 in epoch 7, gen_loss = 0.4112049361755108, disc_loss = 0.11491963747840632
Trained batch 116 in epoch 7, gen_loss = 0.41079970863130355, disc_loss = 0.11510040890027443
Trained batch 117 in epoch 7, gen_loss = 0.4106061837430728, disc_loss = 0.1160174569596489
Trained batch 118 in epoch 7, gen_loss = 0.4100267919672637, disc_loss = 0.11550217408671223
Trained batch 119 in epoch 7, gen_loss = 0.4094327968855699, disc_loss = 0.11712321979381765
Trained batch 120 in epoch 7, gen_loss = 0.4092491389798724, disc_loss = 0.11952669258529613
Trained batch 121 in epoch 7, gen_loss = 0.40928916120138326, disc_loss = 0.12015761879700251
Trained batch 122 in epoch 7, gen_loss = 0.40930105297546077, disc_loss = 0.12035915175664837
Trained batch 123 in epoch 7, gen_loss = 0.40928865103952344, disc_loss = 0.12070312956723594
Trained batch 124 in epoch 7, gen_loss = 0.40978412914276124, disc_loss = 0.12167320005968213
Trained batch 125 in epoch 7, gen_loss = 0.4095342629958713, disc_loss = 0.12228997056520292
Trained batch 126 in epoch 7, gen_loss = 0.4094130056580221, disc_loss = 0.1224193568781429
Trained batch 127 in epoch 7, gen_loss = 0.4087251015007496, disc_loss = 0.12244923510661465
Trained batch 128 in epoch 7, gen_loss = 0.40831980594368866, disc_loss = 0.12230774759163343
Trained batch 129 in epoch 7, gen_loss = 0.4082640331525069, disc_loss = 0.12219333401164756
Trained batch 130 in epoch 7, gen_loss = 0.4082836690749831, disc_loss = 0.12313332635098855
Trained batch 131 in epoch 7, gen_loss = 0.4084728786891157, disc_loss = 0.12391335882994374
Trained batch 132 in epoch 7, gen_loss = 0.4080114411680322, disc_loss = 0.1241223415941056
Trained batch 133 in epoch 7, gen_loss = 0.4076994568554323, disc_loss = 0.12460296138523341
Trained batch 134 in epoch 7, gen_loss = 0.4072296343467854, disc_loss = 0.1248019793967682
Trained batch 135 in epoch 7, gen_loss = 0.40717720963499127, disc_loss = 0.1246640517766697
Trained batch 136 in epoch 7, gen_loss = 0.40690838964316095, disc_loss = 0.12469027750533972
Trained batch 137 in epoch 7, gen_loss = 0.40658932276394055, disc_loss = 0.12464570598609313
Trained batch 138 in epoch 7, gen_loss = 0.40658761292910406, disc_loss = 0.12420019935213512
Trained batch 139 in epoch 7, gen_loss = 0.4069073298147747, disc_loss = 0.12418314057867974
Trained batch 140 in epoch 7, gen_loss = 0.4067228296969799, disc_loss = 0.12455840185879076
Trained batch 141 in epoch 7, gen_loss = 0.406953172364705, disc_loss = 0.12508638873761913
Trained batch 142 in epoch 7, gen_loss = 0.40669452018671104, disc_loss = 0.12539203245179742
Trained batch 143 in epoch 7, gen_loss = 0.40638753585517406, disc_loss = 0.12548164349734886
Trained batch 144 in epoch 7, gen_loss = 0.4062454661418652, disc_loss = 0.1256716559576834
Trained batch 145 in epoch 7, gen_loss = 0.405674084204517, disc_loss = 0.12573228765291813
Trained batch 146 in epoch 7, gen_loss = 0.4054629650651192, disc_loss = 0.1258663746883117
Trained batch 147 in epoch 7, gen_loss = 0.4050963160556716, disc_loss = 0.1259672074811533
Trained batch 148 in epoch 7, gen_loss = 0.40538535442128276, disc_loss = 0.1262395158816354
Trained batch 149 in epoch 7, gen_loss = 0.40501200596491493, disc_loss = 0.1263901532596598
Trained batch 150 in epoch 7, gen_loss = 0.4047011040299144, disc_loss = 0.12834107470297754
Trained batch 151 in epoch 7, gen_loss = 0.40515133660090596, disc_loss = 0.1303064722083754
Testing Epoch 7

Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.3818155527114868, disc_loss = 0.1931636482477188
Trained batch 1 in epoch 8, gen_loss = 0.3869834691286087, disc_loss = 0.18531465530395508
Trained batch 2 in epoch 8, gen_loss = 0.3971950113773346, disc_loss = 0.19468903541564941
Trained batch 3 in epoch 8, gen_loss = 0.3954475149512291, disc_loss = 0.17925912886857986
Trained batch 4 in epoch 8, gen_loss = 0.3821978509426117, disc_loss = 0.1917245090007782
Trained batch 5 in epoch 8, gen_loss = 0.37738744417826336, disc_loss = 0.19263832022746405
Trained batch 6 in epoch 8, gen_loss = 0.3798321655818394, disc_loss = 0.20506452023983002
Trained batch 7 in epoch 8, gen_loss = 0.3799385018646717, disc_loss = 0.21074084006249905
Trained batch 8 in epoch 8, gen_loss = 0.3833060926861233, disc_loss = 0.2001944449212816
Trained batch 9 in epoch 8, gen_loss = 0.3857963621616364, disc_loss = 0.18875661343336106
Trained batch 10 in epoch 8, gen_loss = 0.3859214891086925, disc_loss = 0.18311864814975046
Trained batch 11 in epoch 8, gen_loss = 0.3864179775118828, disc_loss = 0.18038858224948248
Trained batch 12 in epoch 8, gen_loss = 0.38579607009887695, disc_loss = 0.18305286650474256
Trained batch 13 in epoch 8, gen_loss = 0.38389882019587923, disc_loss = 0.17984904455287115
Trained batch 14 in epoch 8, gen_loss = 0.38356155157089233, disc_loss = 0.1924352655808131
Trained batch 15 in epoch 8, gen_loss = 0.38184158504009247, disc_loss = 0.20215184893459082
Trained batch 16 in epoch 8, gen_loss = 0.3825572851826163, disc_loss = 0.20246202016578002
Trained batch 17 in epoch 8, gen_loss = 0.38363692661126453, disc_loss = 0.1993827149271965
Trained batch 18 in epoch 8, gen_loss = 0.38417320972994756, disc_loss = 0.1992114954873135
Trained batch 19 in epoch 8, gen_loss = 0.38351830691099165, disc_loss = 0.19811159744858742
Trained batch 20 in epoch 8, gen_loss = 0.3846670091152191, disc_loss = 0.19666367982115066
Trained batch 21 in epoch 8, gen_loss = 0.3867633437568491, disc_loss = 0.1977217529307712
Trained batch 22 in epoch 8, gen_loss = 0.3860185392524885, disc_loss = 0.1969944452461989
Trained batch 23 in epoch 8, gen_loss = 0.3850194364786148, disc_loss = 0.1930586996798714
Trained batch 24 in epoch 8, gen_loss = 0.38553438663482664, disc_loss = 0.19147301346063614
Trained batch 25 in epoch 8, gen_loss = 0.38637065772826856, disc_loss = 0.18985801104169625
Trained batch 26 in epoch 8, gen_loss = 0.38584397788401004, disc_loss = 0.18823334823052087
Trained batch 27 in epoch 8, gen_loss = 0.3854484717760767, disc_loss = 0.18700340203940868
Trained batch 28 in epoch 8, gen_loss = 0.38326873244910403, disc_loss = 0.18536446089374609
Trained batch 29 in epoch 8, gen_loss = 0.3825968265533447, disc_loss = 0.18397588655352592
Trained batch 30 in epoch 8, gen_loss = 0.38332994330313896, disc_loss = 0.18478964293195355
Trained batch 31 in epoch 8, gen_loss = 0.38278694823384285, disc_loss = 0.1850162234622985
Trained batch 32 in epoch 8, gen_loss = 0.3822441805492748, disc_loss = 0.18197736618193713
Trained batch 33 in epoch 8, gen_loss = 0.38351201222223397, disc_loss = 0.18315441972192595
Trained batch 34 in epoch 8, gen_loss = 0.3831681728363037, disc_loss = 0.1827293261885643
Trained batch 35 in epoch 8, gen_loss = 0.38356558316283756, disc_loss = 0.18014989648428228
Trained batch 36 in epoch 8, gen_loss = 0.38252778874861226, disc_loss = 0.18064347332393801
Trained batch 37 in epoch 8, gen_loss = 0.38301559106299754, disc_loss = 0.18061971566394755
Trained batch 38 in epoch 8, gen_loss = 0.3825690020353366, disc_loss = 0.17928319577223215
Trained batch 39 in epoch 8, gen_loss = 0.3820331409573555, disc_loss = 0.18118865508586168
Trained batch 40 in epoch 8, gen_loss = 0.38384872456876246, disc_loss = 0.1810375170373335
Trained batch 41 in epoch 8, gen_loss = 0.3830610116322835, disc_loss = 0.17980657571128436
Trained batch 42 in epoch 8, gen_loss = 0.38229963391326194, disc_loss = 0.18029109665820764
Trained batch 43 in epoch 8, gen_loss = 0.38365570252591913, disc_loss = 0.17984760264781388
Trained batch 44 in epoch 8, gen_loss = 0.38486116462283665, disc_loss = 0.17836015390025245
Trained batch 45 in epoch 8, gen_loss = 0.3839879314536634, disc_loss = 0.1794282703295998
Trained batch 46 in epoch 8, gen_loss = 0.38332531617042864, disc_loss = 0.17901933637071163
Trained batch 47 in epoch 8, gen_loss = 0.38237337830166024, disc_loss = 0.17998405763258538
Trained batch 48 in epoch 8, gen_loss = 0.38217776709673357, disc_loss = 0.18018938753069663
Trained batch 49 in epoch 8, gen_loss = 0.382409525513649, disc_loss = 0.17877208605408668
Trained batch 50 in epoch 8, gen_loss = 0.38276580209825556, disc_loss = 0.178590914636266
Trained batch 51 in epoch 8, gen_loss = 0.38312021184426087, disc_loss = 0.17731610212761623
Trained batch 52 in epoch 8, gen_loss = 0.3840862439488465, disc_loss = 0.17701018123694187
Trained batch 53 in epoch 8, gen_loss = 0.3853786681537275, disc_loss = 0.1751236711387281
Trained batch 54 in epoch 8, gen_loss = 0.3860420974818143, disc_loss = 0.17313443097201262
Trained batch 55 in epoch 8, gen_loss = 0.38604587582605226, disc_loss = 0.17264677557562078
Trained batch 56 in epoch 8, gen_loss = 0.386843681858297, disc_loss = 0.17038118453663692
Trained batch 57 in epoch 8, gen_loss = 0.3876153538967001, disc_loss = 0.16801268543148862
Trained batch 58 in epoch 8, gen_loss = 0.3883044376211651, disc_loss = 0.1662508150783636
Trained batch 59 in epoch 8, gen_loss = 0.38928991357485454, disc_loss = 0.16512084466715654
Trained batch 60 in epoch 8, gen_loss = 0.39043494326169376, disc_loss = 0.16283531465613452
Trained batch 61 in epoch 8, gen_loss = 0.39143211610855594, disc_loss = 0.16133997352012702
Trained batch 62 in epoch 8, gen_loss = 0.3925909267531501, disc_loss = 0.15925045332147014
Trained batch 63 in epoch 8, gen_loss = 0.3929116344079375, disc_loss = 0.15720898503786884
Trained batch 64 in epoch 8, gen_loss = 0.39301071212841915, disc_loss = 0.155309638982782
Trained batch 65 in epoch 8, gen_loss = 0.39319211063962994, disc_loss = 0.15346438688875147
Trained batch 66 in epoch 8, gen_loss = 0.39382331762740863, disc_loss = 0.151548783809169
Trained batch 67 in epoch 8, gen_loss = 0.39478523766293244, disc_loss = 0.1501114904497038
Trained batch 68 in epoch 8, gen_loss = 0.3961442320243172, disc_loss = 0.14825012129933937
Trained batch 69 in epoch 8, gen_loss = 0.39579721220902037, disc_loss = 0.1468597138034446
Trained batch 70 in epoch 8, gen_loss = 0.3956891953105658, disc_loss = 0.14611933123267873
Trained batch 71 in epoch 8, gen_loss = 0.39684595581558013, disc_loss = 0.14652812217051783
Trained batch 72 in epoch 8, gen_loss = 0.3962484773707716, disc_loss = 0.14814890803743716
Trained batch 73 in epoch 8, gen_loss = 0.3964368990949682, disc_loss = 0.15113874328498905
Trained batch 74 in epoch 8, gen_loss = 0.3966008464495341, disc_loss = 0.15016038164496423
Trained batch 75 in epoch 8, gen_loss = 0.3965390661829396, disc_loss = 0.149505089821392
Trained batch 76 in epoch 8, gen_loss = 0.396432651327802, disc_loss = 0.1482027910843298
Trained batch 77 in epoch 8, gen_loss = 0.3957795481651257, disc_loss = 0.14699554954392788
Trained batch 78 in epoch 8, gen_loss = 0.3959832795058625, disc_loss = 0.1456246974441824
Trained batch 79 in epoch 8, gen_loss = 0.3953539490699768, disc_loss = 0.1461119341198355
Trained batch 80 in epoch 8, gen_loss = 0.3953457607163323, disc_loss = 0.14635090497724804
Trained batch 81 in epoch 8, gen_loss = 0.3949865571609357, disc_loss = 0.14682157451241482
Trained batch 82 in epoch 8, gen_loss = 0.3954257699380438, disc_loss = 0.14647412654685688
Trained batch 83 in epoch 8, gen_loss = 0.39650998051677433, disc_loss = 0.1451130574569106
Trained batch 84 in epoch 8, gen_loss = 0.39636492378571453, disc_loss = 0.14383999906918582
Trained batch 85 in epoch 8, gen_loss = 0.3961052513399789, disc_loss = 0.1431356614758802
Trained batch 86 in epoch 8, gen_loss = 0.39669440052975186, disc_loss = 0.1424556677711421
Trained batch 87 in epoch 8, gen_loss = 0.39616130089217966, disc_loss = 0.14321914281357417
Trained batch 88 in epoch 8, gen_loss = 0.3965149779668015, disc_loss = 0.14413332286175717
Trained batch 89 in epoch 8, gen_loss = 0.3970103293657303, disc_loss = 0.14306924839814503
Trained batch 90 in epoch 8, gen_loss = 0.3980024073805128, disc_loss = 0.1418573347094295
Trained batch 91 in epoch 8, gen_loss = 0.3975038985195367, disc_loss = 0.14069974649211633
Trained batch 92 in epoch 8, gen_loss = 0.3976975993443561, disc_loss = 0.13946564575677278
Trained batch 93 in epoch 8, gen_loss = 0.3973070316492243, disc_loss = 0.13866781863443395
Trained batch 94 in epoch 8, gen_loss = 0.3982694845450552, disc_loss = 0.13766262562651382
Trained batch 95 in epoch 8, gen_loss = 0.39868726426114637, disc_loss = 0.13667851449766508
Trained batch 96 in epoch 8, gen_loss = 0.3986097223979911, disc_loss = 0.13576466805234397
Trained batch 97 in epoch 8, gen_loss = 0.3979039104009161, disc_loss = 0.13498367620061855
Trained batch 98 in epoch 8, gen_loss = 0.3992421274835413, disc_loss = 0.13523403148759494
Trained batch 99 in epoch 8, gen_loss = 0.39997238278388975, disc_loss = 0.13396229095757006
Trained batch 100 in epoch 8, gen_loss = 0.4000132653382745, disc_loss = 0.13468887538898108
Trained batch 101 in epoch 8, gen_loss = 0.4008019028925428, disc_loss = 0.13458399620710634
Trained batch 102 in epoch 8, gen_loss = 0.40132702727919645, disc_loss = 0.13354369719485634
Trained batch 103 in epoch 8, gen_loss = 0.4014613794592711, disc_loss = 0.13327051072309798
Trained batch 104 in epoch 8, gen_loss = 0.40171468768801005, disc_loss = 0.13328047809856278
Trained batch 105 in epoch 8, gen_loss = 0.4015787974843439, disc_loss = 0.1323785527064553
Trained batch 106 in epoch 8, gen_loss = 0.40138061024318233, disc_loss = 0.13203726844670616
Trained batch 107 in epoch 8, gen_loss = 0.4019651826885011, disc_loss = 0.1313050924282935
Trained batch 108 in epoch 8, gen_loss = 0.4021729012148096, disc_loss = 0.13053771009275672
Trained batch 109 in epoch 8, gen_loss = 0.40176791657101024, disc_loss = 0.13020800985395908
Trained batch 110 in epoch 8, gen_loss = 0.40232356523608304, disc_loss = 0.1297045049702262
Trained batch 111 in epoch 8, gen_loss = 0.402240658977202, disc_loss = 0.12881522648967803
Trained batch 112 in epoch 8, gen_loss = 0.40257271069341, disc_loss = 0.12806703179942824
Trained batch 113 in epoch 8, gen_loss = 0.4027220081341894, disc_loss = 0.12716214813030602
Trained batch 114 in epoch 8, gen_loss = 0.40283144997513815, disc_loss = 0.12632961729946343
Trained batch 115 in epoch 8, gen_loss = 0.40271694752676734, disc_loss = 0.12564263043218646
Trained batch 116 in epoch 8, gen_loss = 0.4024603922142942, disc_loss = 0.1260294846744619
Trained batch 117 in epoch 8, gen_loss = 0.4029983191166894, disc_loss = 0.12571616123540927
Trained batch 118 in epoch 8, gen_loss = 0.4033976948561789, disc_loss = 0.12473804010626148
Trained batch 119 in epoch 8, gen_loss = 0.40379949783285457, disc_loss = 0.12396845272742212
Trained batch 120 in epoch 8, gen_loss = 0.4035915776717761, disc_loss = 0.12342397469934846
Trained batch 121 in epoch 8, gen_loss = 0.4035782161794725, disc_loss = 0.12260093709423406
Trained batch 122 in epoch 8, gen_loss = 0.4031450898666692, disc_loss = 0.12329909676398204
Trained batch 123 in epoch 8, gen_loss = 0.40392020152461144, disc_loss = 0.12568289917262812
Trained batch 124 in epoch 8, gen_loss = 0.403657874584198, disc_loss = 0.1253972222059965
Trained batch 125 in epoch 8, gen_loss = 0.40331424370644586, disc_loss = 0.12565050065694822
Trained batch 126 in epoch 8, gen_loss = 0.402767810061222, disc_loss = 0.1254430115662926
Trained batch 127 in epoch 8, gen_loss = 0.4032103142235428, disc_loss = 0.12479372970119584
Trained batch 128 in epoch 8, gen_loss = 0.40310367225676547, disc_loss = 0.12427706336385982
Trained batch 129 in epoch 8, gen_loss = 0.4029344698557487, disc_loss = 0.12427106833515258
Trained batch 130 in epoch 8, gen_loss = 0.4025542815677992, disc_loss = 0.12395865699091485
Trained batch 131 in epoch 8, gen_loss = 0.4026891017953555, disc_loss = 0.12576423942421874
Trained batch 132 in epoch 8, gen_loss = 0.4024392612894675, disc_loss = 0.12719634686477652
Trained batch 133 in epoch 8, gen_loss = 0.40272912027230906, disc_loss = 0.1277438113743912
Trained batch 134 in epoch 8, gen_loss = 0.4025237476384198, disc_loss = 0.12776772309508588
Trained batch 135 in epoch 8, gen_loss = 0.4020940565011081, disc_loss = 0.12872809759231613
Trained batch 136 in epoch 8, gen_loss = 0.4024995478400349, disc_loss = 0.1286467097454915
Trained batch 137 in epoch 8, gen_loss = 0.4027422999126324, disc_loss = 0.12883167715230281
Trained batch 138 in epoch 8, gen_loss = 0.4024212943564216, disc_loss = 0.1295872446578398
Trained batch 139 in epoch 8, gen_loss = 0.40248139117445264, disc_loss = 0.12977359636819788
Trained batch 140 in epoch 8, gen_loss = 0.4024574067575712, disc_loss = 0.13000802718208615
Trained batch 141 in epoch 8, gen_loss = 0.4022895055757442, disc_loss = 0.12993085548334138
Trained batch 142 in epoch 8, gen_loss = 0.4025451961930815, disc_loss = 0.12964634124476176
Trained batch 143 in epoch 8, gen_loss = 0.4024699384139644, disc_loss = 0.12928032208906692
Trained batch 144 in epoch 8, gen_loss = 0.4023842215538025, disc_loss = 0.12943997122347356
Trained batch 145 in epoch 8, gen_loss = 0.4025894658614511, disc_loss = 0.12962911927383647
Trained batch 146 in epoch 8, gen_loss = 0.4025826125728841, disc_loss = 0.12949765844866126
Trained batch 147 in epoch 8, gen_loss = 0.40304574068333654, disc_loss = 0.12913953524233923
Trained batch 148 in epoch 8, gen_loss = 0.4029319352351579, disc_loss = 0.12881941169550354
Trained batch 149 in epoch 8, gen_loss = 0.4025530767440796, disc_loss = 0.1286937360589703
Trained batch 150 in epoch 8, gen_loss = 0.4024629551448569, disc_loss = 0.1283688106210224
Trained batch 151 in epoch 8, gen_loss = 0.40234860895495667, disc_loss = 0.12832864997663387
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.4044944643974304, disc_loss = 0.4190451204776764
Trained batch 1 in epoch 9, gen_loss = 0.3967384994029999, disc_loss = 0.36311502754688263
Trained batch 2 in epoch 9, gen_loss = 0.3850141763687134, disc_loss = 0.31515245139598846
Trained batch 3 in epoch 9, gen_loss = 0.3777979016304016, disc_loss = 0.2674419991672039
Trained batch 4 in epoch 9, gen_loss = 0.37171908020973204, disc_loss = 0.2321387842297554
Trained batch 5 in epoch 9, gen_loss = 0.37082742154598236, disc_loss = 0.21190758173664412
Trained batch 6 in epoch 9, gen_loss = 0.3737290288720812, disc_loss = 0.22376641311815806
Trained batch 7 in epoch 9, gen_loss = 0.36719539761543274, disc_loss = 0.22303655464202166
Trained batch 8 in epoch 9, gen_loss = 0.3629630274242825, disc_loss = 0.2140362055765258
Trained batch 9 in epoch 9, gen_loss = 0.3635861724615097, disc_loss = 0.20450117513537408
Trained batch 10 in epoch 9, gen_loss = 0.3630959283221852, disc_loss = 0.20046482370658356
Trained batch 11 in epoch 9, gen_loss = 0.3711029216647148, disc_loss = 0.19722624806066355
Trained batch 12 in epoch 9, gen_loss = 0.36718130340942967, disc_loss = 0.19486396645124143
Trained batch 13 in epoch 9, gen_loss = 0.36621943967682974, disc_loss = 0.1920276725930827
Trained batch 14 in epoch 9, gen_loss = 0.36878819863001505, disc_loss = 0.18655722786982853
Trained batch 15 in epoch 9, gen_loss = 0.3738945070654154, disc_loss = 0.17874669842422009
Trained batch 16 in epoch 9, gen_loss = 0.3795458691961625, disc_loss = 0.1724170420099707
Trained batch 17 in epoch 9, gen_loss = 0.3828351812230216, disc_loss = 0.16413161769095394
Trained batch 18 in epoch 9, gen_loss = 0.3835090304675855, disc_loss = 0.15866859070956707
Trained batch 19 in epoch 9, gen_loss = 0.3828736662864685, disc_loss = 0.1523545897565782
Trained batch 20 in epoch 9, gen_loss = 0.38789420468466623, disc_loss = 0.15052694073390394
Trained batch 21 in epoch 9, gen_loss = 0.38731003891338, disc_loss = 0.14536810251460833
Trained batch 22 in epoch 9, gen_loss = 0.3866836998773658, disc_loss = 0.14152583536570487
Trained batch 23 in epoch 9, gen_loss = 0.38675108303626377, disc_loss = 0.13866764050908387
Trained batch 24 in epoch 9, gen_loss = 0.38968356370925905, disc_loss = 0.14050373367965222
Trained batch 25 in epoch 9, gen_loss = 0.39165911307701695, disc_loss = 0.13638557773083448
Trained batch 26 in epoch 9, gen_loss = 0.39081581543993066, disc_loss = 0.1345354055778848
Trained batch 27 in epoch 9, gen_loss = 0.39317585847207476, disc_loss = 0.13093068856479867
Trained batch 28 in epoch 9, gen_loss = 0.3938191245342123, disc_loss = 0.1279844282644576
Trained batch 29 in epoch 9, gen_loss = 0.39182842274506885, disc_loss = 0.13099787042786679
Trained batch 30 in epoch 9, gen_loss = 0.39396542791397343, disc_loss = 0.1343929244265441
Trained batch 31 in epoch 9, gen_loss = 0.393438964150846, disc_loss = 0.13719410501653329
Trained batch 32 in epoch 9, gen_loss = 0.39417181231758813, disc_loss = 0.13680004537331336
Trained batch 33 in epoch 9, gen_loss = 0.3954526343766381, disc_loss = 0.13729085691054077
Trained batch 34 in epoch 9, gen_loss = 0.39589262860161917, disc_loss = 0.13792951154921737
Trained batch 35 in epoch 9, gen_loss = 0.39723643991682267, disc_loss = 0.13585505391367608
Trained batch 36 in epoch 9, gen_loss = 0.39808883940851364, disc_loss = 0.1353207992238773
Trained batch 37 in epoch 9, gen_loss = 0.3980765640735626, disc_loss = 0.1369836609320421
Trained batch 38 in epoch 9, gen_loss = 0.39809475953762347, disc_loss = 0.13629687830614737
Trained batch 39 in epoch 9, gen_loss = 0.4000749871134758, disc_loss = 0.1379072018433362
Trained batch 40 in epoch 9, gen_loss = 0.39977190116556677, disc_loss = 0.1386052806657262
Trained batch 41 in epoch 9, gen_loss = 0.4002966753074101, disc_loss = 0.13845282016942898
Trained batch 42 in epoch 9, gen_loss = 0.39969594603361086, disc_loss = 0.1359249768821999
Trained batch 43 in epoch 9, gen_loss = 0.3984834003177556, disc_loss = 0.13682753825560212
Trained batch 44 in epoch 9, gen_loss = 0.39922626747025386, disc_loss = 0.13530812507702245
Trained batch 45 in epoch 9, gen_loss = 0.39934172060178674, disc_loss = 0.13585799134781826
Trained batch 46 in epoch 9, gen_loss = 0.39916412437215765, disc_loss = 0.13829007915201338
Trained batch 47 in epoch 9, gen_loss = 0.4000759453823169, disc_loss = 0.13852087637254348
Trained batch 48 in epoch 9, gen_loss = 0.40051331994484884, disc_loss = 0.13734915194918915
Trained batch 49 in epoch 9, gen_loss = 0.39969080567359927, disc_loss = 0.1380092767998576
Trained batch 50 in epoch 9, gen_loss = 0.4000556755299662, disc_loss = 0.1382747711431162
Trained batch 51 in epoch 9, gen_loss = 0.4005153735096638, disc_loss = 0.13686999417125031
Trained batch 52 in epoch 9, gen_loss = 0.4001709723247672, disc_loss = 0.13613600575558418
Trained batch 53 in epoch 9, gen_loss = 0.4006408315013956, disc_loss = 0.13659290717569766
Trained batch 54 in epoch 9, gen_loss = 0.39942870194261726, disc_loss = 0.13759177107025278
Trained batch 55 in epoch 9, gen_loss = 0.39877403154969215, disc_loss = 0.1363323584664613
Trained batch 56 in epoch 9, gen_loss = 0.39942615858295505, disc_loss = 0.13598027573735044
Trained batch 57 in epoch 9, gen_loss = 0.3998823731110014, disc_loss = 0.1352850680143155
Trained batch 58 in epoch 9, gen_loss = 0.4013939520060006, disc_loss = 0.1355607977799945
Trained batch 59 in epoch 9, gen_loss = 0.4013804912567139, disc_loss = 0.1358613847134014
Trained batch 60 in epoch 9, gen_loss = 0.4017124312822936, disc_loss = 0.13625643667993975
Trained batch 61 in epoch 9, gen_loss = 0.40199953221505685, disc_loss = 0.13560913920763037
Trained batch 62 in epoch 9, gen_loss = 0.40236476867917986, disc_loss = 0.1344175273996024
Trained batch 63 in epoch 9, gen_loss = 0.40257104439660907, disc_loss = 0.13492917493567802
Trained batch 64 in epoch 9, gen_loss = 0.4037209634597485, disc_loss = 0.13660006675009545
Trained batch 65 in epoch 9, gen_loss = 0.4028746670845783, disc_loss = 0.13602316393658068
Trained batch 66 in epoch 9, gen_loss = 0.4026991760552819, disc_loss = 0.13581714092461922
Trained batch 67 in epoch 9, gen_loss = 0.4031358001863255, disc_loss = 0.13568854323752663
Trained batch 68 in epoch 9, gen_loss = 0.40262411772340967, disc_loss = 0.13619606080802454
Trained batch 69 in epoch 9, gen_loss = 0.4029215591294425, disc_loss = 0.13594025088740247
Trained batch 70 in epoch 9, gen_loss = 0.40345349446148937, disc_loss = 0.1357775953086749
Trained batch 71 in epoch 9, gen_loss = 0.40323138278391624, disc_loss = 0.13476695919719836
Trained batch 72 in epoch 9, gen_loss = 0.4041752231447664, disc_loss = 0.13373770812296704
Trained batch 73 in epoch 9, gen_loss = 0.4040487541540249, disc_loss = 0.13372952100896351
Trained batch 74 in epoch 9, gen_loss = 0.40379151264826457, disc_loss = 0.13306273999313514
Trained batch 75 in epoch 9, gen_loss = 0.40366942004153605, disc_loss = 0.13284195962018872
Trained batch 76 in epoch 9, gen_loss = 0.40430400820521567, disc_loss = 0.13194243147872486
Trained batch 77 in epoch 9, gen_loss = 0.4050489847476666, disc_loss = 0.13045432991706407
Trained batch 78 in epoch 9, gen_loss = 0.404068821593176, disc_loss = 0.13104289374019526
Trained batch 79 in epoch 9, gen_loss = 0.40394333712756636, disc_loss = 0.13015959290787577
Trained batch 80 in epoch 9, gen_loss = 0.404473399306521, disc_loss = 0.13158371741021122
Trained batch 81 in epoch 9, gen_loss = 0.4036546171438403, disc_loss = 0.1343054774149162
Trained batch 82 in epoch 9, gen_loss = 0.40397121676479475, disc_loss = 0.13392152592360254
Trained batch 83 in epoch 9, gen_loss = 0.4043234856355758, disc_loss = 0.1331505762147052
Trained batch 84 in epoch 9, gen_loss = 0.4042024181169622, disc_loss = 0.132998048294993
Trained batch 85 in epoch 9, gen_loss = 0.40396412028822787, disc_loss = 0.13501597984239114
Trained batch 86 in epoch 9, gen_loss = 0.4037844829860775, disc_loss = 0.1382792723076097
Trained batch 87 in epoch 9, gen_loss = 0.40317715399644594, disc_loss = 0.1382443829524246
Trained batch 88 in epoch 9, gen_loss = 0.4028303418936354, disc_loss = 0.13836378687888048
Trained batch 89 in epoch 9, gen_loss = 0.4028418782684538, disc_loss = 0.13885189981924162
Trained batch 90 in epoch 9, gen_loss = 0.4030835061937898, disc_loss = 0.13931990709606107
Trained batch 91 in epoch 9, gen_loss = 0.40357084766678186, disc_loss = 0.13938691280782223
Trained batch 92 in epoch 9, gen_loss = 0.4034187521344872, disc_loss = 0.13934075535945994
Trained batch 93 in epoch 9, gen_loss = 0.40376585309809826, disc_loss = 0.13956882971081327
Trained batch 94 in epoch 9, gen_loss = 0.4036609825335051, disc_loss = 0.1396428232914523
Trained batch 95 in epoch 9, gen_loss = 0.4029975238566597, disc_loss = 0.14037619368173182
Trained batch 96 in epoch 9, gen_loss = 0.4035220988017997, disc_loss = 0.14181438357252435
Trained batch 97 in epoch 9, gen_loss = 0.40317234640218774, disc_loss = 0.14176163875630923
Trained batch 98 in epoch 9, gen_loss = 0.4024928696829863, disc_loss = 0.14112086601630605
Trained batch 99 in epoch 9, gen_loss = 0.4026166823506355, disc_loss = 0.14098152585327625
Trained batch 100 in epoch 9, gen_loss = 0.40271416719597164, disc_loss = 0.14025001648333993
Trained batch 101 in epoch 9, gen_loss = 0.4022754036328372, disc_loss = 0.140201593657919
Trained batch 102 in epoch 9, gen_loss = 0.40255198403469566, disc_loss = 0.13935484035501203
Trained batch 103 in epoch 9, gen_loss = 0.4035139230008309, disc_loss = 0.13850773466177857
Trained batch 104 in epoch 9, gen_loss = 0.40393722511473157, disc_loss = 0.1374432809473503
Trained batch 105 in epoch 9, gen_loss = 0.4035797895125623, disc_loss = 0.13629575277555664
Trained batch 106 in epoch 9, gen_loss = 0.4030038817463634, disc_loss = 0.13616224044115743
Trained batch 107 in epoch 9, gen_loss = 0.4032208392465556, disc_loss = 0.13864596029398618
Trained batch 108 in epoch 9, gen_loss = 0.40363964356413673, disc_loss = 0.13771229708960298
Trained batch 109 in epoch 9, gen_loss = 0.40351616794412787, disc_loss = 0.1368468456647613
Trained batch 110 in epoch 9, gen_loss = 0.40355641186774316, disc_loss = 0.13627042534115077
Trained batch 111 in epoch 9, gen_loss = 0.4037486229624067, disc_loss = 0.13577870938128658
Trained batch 112 in epoch 9, gen_loss = 0.4037511617736479, disc_loss = 0.13485876942234756
Trained batch 113 in epoch 9, gen_loss = 0.40338975661679316, disc_loss = 0.13434174633993393
Trained batch 114 in epoch 9, gen_loss = 0.4032020991263182, disc_loss = 0.13410407009979952
Trained batch 115 in epoch 9, gen_loss = 0.40322363248159143, disc_loss = 0.1336624723505871
Trained batch 116 in epoch 9, gen_loss = 0.40389294451118535, disc_loss = 0.13282033352133554
Trained batch 117 in epoch 9, gen_loss = 0.4037162110967151, disc_loss = 0.13216062101645995
Trained batch 118 in epoch 9, gen_loss = 0.4036338449526234, disc_loss = 0.13198555821255475
Trained batch 119 in epoch 9, gen_loss = 0.40409337331851325, disc_loss = 0.1320456461670498
Trained batch 120 in epoch 9, gen_loss = 0.4035563099482828, disc_loss = 0.13177339686465658
Trained batch 121 in epoch 9, gen_loss = 0.4034296169144208, disc_loss = 0.13100570953283153
Trained batch 122 in epoch 9, gen_loss = 0.403154930932735, disc_loss = 0.1305262820749748
Trained batch 123 in epoch 9, gen_loss = 0.4030243759193728, disc_loss = 0.13039562346473818
Trained batch 124 in epoch 9, gen_loss = 0.4027857985496521, disc_loss = 0.13049706959724428
Trained batch 125 in epoch 9, gen_loss = 0.4033345142527232, disc_loss = 0.13164168052257053
Trained batch 126 in epoch 9, gen_loss = 0.40290922677423074, disc_loss = 0.13290569327009005
Trained batch 127 in epoch 9, gen_loss = 0.40322928968816996, disc_loss = 0.13361802778672427
Trained batch 128 in epoch 9, gen_loss = 0.403130548406941, disc_loss = 0.13291522496661476
Trained batch 129 in epoch 9, gen_loss = 0.4033880041195796, disc_loss = 0.13311430473740285
Trained batch 130 in epoch 9, gen_loss = 0.40387113085229887, disc_loss = 0.13443943977583456
Trained batch 131 in epoch 9, gen_loss = 0.40350032913865463, disc_loss = 0.1348757573939634
Trained batch 132 in epoch 9, gen_loss = 0.4030934094934535, disc_loss = 0.13533370247236767
Trained batch 133 in epoch 9, gen_loss = 0.40327022213544417, disc_loss = 0.13520564889507508
Trained batch 134 in epoch 9, gen_loss = 0.4036405976171847, disc_loss = 0.134953459876555
Trained batch 135 in epoch 9, gen_loss = 0.40347320192000447, disc_loss = 0.1347273839637637
Trained batch 136 in epoch 9, gen_loss = 0.40320468275216376, disc_loss = 0.1342339562999941
Trained batch 137 in epoch 9, gen_loss = 0.40289037210353906, disc_loss = 0.13438693201844243
Trained batch 138 in epoch 9, gen_loss = 0.40285011954444777, disc_loss = 0.13477161971570775
Trained batch 139 in epoch 9, gen_loss = 0.402649943956307, disc_loss = 0.13477925173938274
Trained batch 140 in epoch 9, gen_loss = 0.4029538109370157, disc_loss = 0.13424681919686338
Trained batch 141 in epoch 9, gen_loss = 0.40317397050454584, disc_loss = 0.13387693291608715
Trained batch 142 in epoch 9, gen_loss = 0.40328960235302264, disc_loss = 0.1341099113330141
Trained batch 143 in epoch 9, gen_loss = 0.4027567004991902, disc_loss = 0.13439213779444495
Trained batch 144 in epoch 9, gen_loss = 0.40308192701175294, disc_loss = 0.13450063821570626
Trained batch 145 in epoch 9, gen_loss = 0.4026891297265275, disc_loss = 0.13439155349584475
Trained batch 146 in epoch 9, gen_loss = 0.40245101099111596, disc_loss = 0.1341609131215381
Trained batch 147 in epoch 9, gen_loss = 0.4022506179439055, disc_loss = 0.13452070332258134
Trained batch 148 in epoch 9, gen_loss = 0.4021068113362229, disc_loss = 0.1345557401944327
Trained batch 149 in epoch 9, gen_loss = 0.4018561659256617, disc_loss = 0.13485627805193265
Trained batch 150 in epoch 9, gen_loss = 0.4015303285706122, disc_loss = 0.1354594449235114
Trained batch 151 in epoch 9, gen_loss = 0.4015338362047547, disc_loss = 0.1360576417003023
Testing Epoch 9
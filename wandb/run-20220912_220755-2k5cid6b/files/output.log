/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 1.2999496459960938, disc_loss = 0.8684319853782654
Trained batch 1 in epoch 0, gen_loss = 1.282596468925476, disc_loss = 0.8840837776660919
Trained batch 2 in epoch 0, gen_loss = 1.2383827368418376, disc_loss = 0.8324616948763529
Trained batch 3 in epoch 0, gen_loss = 1.1516036987304688, disc_loss = 0.7179975733160973
Trained batch 4 in epoch 0, gen_loss = 1.068580651283264, disc_loss = 0.6367772281169891
Trained batch 5 in epoch 0, gen_loss = 1.0013155341148376, disc_loss = 0.5818714648485184
Trained batch 6 in epoch 0, gen_loss = 0.9562175955091204, disc_loss = 0.5315039902925491
Trained batch 7 in epoch 0, gen_loss = 0.9409501552581787, disc_loss = 0.4916356950998306
Trained batch 8 in epoch 0, gen_loss = 0.9327037599351671, disc_loss = 0.46126215159893036
Trained batch 9 in epoch 0, gen_loss = 0.9236485481262207, disc_loss = 0.4303103253245354
Trained batch 10 in epoch 0, gen_loss = 0.9073280854658647, disc_loss = 0.4076609408313578
Trained batch 11 in epoch 0, gen_loss = 0.9001996914545695, disc_loss = 0.3897877025107543
Trained batch 12 in epoch 0, gen_loss = 0.9060388299135061, disc_loss = 0.37313081094851863
Trained batch 13 in epoch 0, gen_loss = 0.9002194021429334, disc_loss = 0.355690204671451
Trained batch 14 in epoch 0, gen_loss = 0.8998465180397034, disc_loss = 0.33946509261926017
Trained batch 15 in epoch 0, gen_loss = 0.8984427005052567, disc_loss = 0.32593453116714954
Trained batch 16 in epoch 0, gen_loss = 0.8945827378946192, disc_loss = 0.31408220748690996
Trained batch 17 in epoch 0, gen_loss = 0.8943090736865997, disc_loss = 0.3054585030509366
Trained batch 18 in epoch 0, gen_loss = 0.8921706237291035, disc_loss = 0.2961881297983621
Trained batch 19 in epoch 0, gen_loss = 0.8909050643444061, disc_loss = 0.28895724304020404
Trained batch 20 in epoch 0, gen_loss = 0.8977662608737037, disc_loss = 0.2819633310039838
Trained batch 21 in epoch 0, gen_loss = 0.8983959284695712, disc_loss = 0.27389527213844383
Trained batch 22 in epoch 0, gen_loss = 0.9004207331201305, disc_loss = 0.26571338591368304
Trained batch 23 in epoch 0, gen_loss = 0.8979533414045969, disc_loss = 0.2597995937491457
Trained batch 24 in epoch 0, gen_loss = 0.9008441996574402, disc_loss = 0.2543018189072609
Trained batch 25 in epoch 0, gen_loss = 0.9058268964290619, disc_loss = 0.2487275247963575
Trained batch 26 in epoch 0, gen_loss = 0.9081703490681119, disc_loss = 0.2431401695918154
Trained batch 27 in epoch 0, gen_loss = 0.9156287887266704, disc_loss = 0.23685316262500627
Trained batch 28 in epoch 0, gen_loss = 0.9245073117058853, disc_loss = 0.23067991576831917
Trained batch 29 in epoch 0, gen_loss = 0.9304726580778758, disc_loss = 0.22513104267418385
Trained batch 30 in epoch 0, gen_loss = 0.9348817621507952, disc_loss = 0.21976081341985734
Trained batch 31 in epoch 0, gen_loss = 0.9375570844858885, disc_loss = 0.21505591308232397
Trained batch 32 in epoch 0, gen_loss = 0.9467917373686126, disc_loss = 0.2108903812865416
Trained batch 33 in epoch 0, gen_loss = 0.9507479544948129, disc_loss = 0.2064888375427793
Trained batch 34 in epoch 0, gen_loss = 0.9572714958872114, disc_loss = 0.20208581568939346
Trained batch 35 in epoch 0, gen_loss = 0.9641459402110841, disc_loss = 0.19784833708157143
Trained batch 36 in epoch 0, gen_loss = 0.9691807563240463, disc_loss = 0.19377488934913198
Trained batch 37 in epoch 0, gen_loss = 0.9754508592580494, disc_loss = 0.19027471856067055
Trained batch 38 in epoch 0, gen_loss = 0.9803449175296686, disc_loss = 0.1873080245195291
Trained batch 39 in epoch 0, gen_loss = 0.985163040459156, disc_loss = 0.18498088493943216
Trained batch 40 in epoch 0, gen_loss = 0.9897556115941304, disc_loss = 0.18203026092633967
Trained batch 41 in epoch 0, gen_loss = 0.9962024163632166, disc_loss = 0.17883147902431942
Trained batch 42 in epoch 0, gen_loss = 1.0009070343749469, disc_loss = 0.17607673916012742
Trained batch 43 in epoch 0, gen_loss = 1.0034703707153148, disc_loss = 0.17367690412158315
Trained batch 44 in epoch 0, gen_loss = 1.0096483614709642, disc_loss = 0.17096119282974137
Trained batch 45 in epoch 0, gen_loss = 1.014169385899668, disc_loss = 0.16816233997435673
Trained batch 46 in epoch 0, gen_loss = 1.0154063409947334, disc_loss = 0.16562945942612403
Trained batch 47 in epoch 0, gen_loss = 1.0171218626201153, disc_loss = 0.16303270814629892
Trained batch 48 in epoch 0, gen_loss = 1.0184954708936262, disc_loss = 0.160708022588978
Trained batch 49 in epoch 0, gen_loss = 1.019374622106552, disc_loss = 0.15846445210278035
Trained batch 50 in epoch 0, gen_loss = 1.0144723595357408, disc_loss = 0.15945774937669435
Trained batch 51 in epoch 0, gen_loss = 1.023003345498672, disc_loss = 0.1635527264756652
Trained batch 52 in epoch 0, gen_loss = 1.0208131985844306, disc_loss = 0.16240950751135935
Trained batch 53 in epoch 0, gen_loss = 1.017185691330168, disc_loss = 0.1618054882381801
Trained batch 54 in epoch 0, gen_loss = 1.0173562515865673, disc_loss = 0.16073203608393669
Trained batch 55 in epoch 0, gen_loss = 1.0196357465216093, disc_loss = 0.16012579714879394
Trained batch 56 in epoch 0, gen_loss = 1.0234077823789496, disc_loss = 0.1588787605757253
Trained batch 57 in epoch 0, gen_loss = 1.020486322970226, disc_loss = 0.15712654288729716
Trained batch 58 in epoch 0, gen_loss = 1.0175001510119035, disc_loss = 0.15541460011470115
Trained batch 59 in epoch 0, gen_loss = 1.0180088569720587, disc_loss = 0.15355086661875247
Trained batch 60 in epoch 0, gen_loss = 1.0210569774518248, disc_loss = 0.15215974349956043
Trained batch 61 in epoch 0, gen_loss = 1.01754397634537, disc_loss = 0.15094572918549662
Trained batch 62 in epoch 0, gen_loss = 1.0176693588968306, disc_loss = 0.14926705332029433
Trained batch 63 in epoch 0, gen_loss = 1.0183573393151164, disc_loss = 0.1478097732178867
Trained batch 64 in epoch 0, gen_loss = 1.0176846788479732, disc_loss = 0.14643552211614755
Trained batch 65 in epoch 0, gen_loss = 1.0180574375571627, disc_loss = 0.14566013013774698
Trained batch 66 in epoch 0, gen_loss = 1.0152500850051196, disc_loss = 0.14543814289925702
Trained batch 67 in epoch 0, gen_loss = 1.0166893426109762, disc_loss = 0.1440790605676525
Trained batch 68 in epoch 0, gen_loss = 1.0191869735717773, disc_loss = 0.14288753751611363
Trained batch 69 in epoch 0, gen_loss = 1.0187458464077541, disc_loss = 0.14142891610307354
Trained batch 70 in epoch 0, gen_loss = 1.020099485424203, disc_loss = 0.1400399681862811
Trained batch 71 in epoch 0, gen_loss = 1.020099585254987, disc_loss = 0.13859811782216033
Trained batch 72 in epoch 0, gen_loss = 1.0197754175695655, disc_loss = 0.13719598545807682
Trained batch 73 in epoch 0, gen_loss = 1.0210754073954917, disc_loss = 0.1357446829159115
Trained batch 74 in epoch 0, gen_loss = 1.0201235858599345, disc_loss = 0.13439631693065165
Trained batch 75 in epoch 0, gen_loss = 1.0204052101624639, disc_loss = 0.1331195895265984
Trained batch 76 in epoch 0, gen_loss = 1.0206761971696632, disc_loss = 0.1320537608600669
Trained batch 77 in epoch 0, gen_loss = 1.0220331710118513, disc_loss = 0.13117223617453605
Trained batch 78 in epoch 0, gen_loss = 1.0220573137078104, disc_loss = 0.13006070202004305
Trained batch 79 in epoch 0, gen_loss = 1.0192527897655963, disc_loss = 0.12967736928258092
Trained batch 80 in epoch 0, gen_loss = 1.0231899810426028, disc_loss = 0.12936063103929715
Trained batch 81 in epoch 0, gen_loss = 1.0238632828724095, disc_loss = 0.12854415026107213
Trained batch 82 in epoch 0, gen_loss = 1.0224197377641517, disc_loss = 0.1278353463858366
Trained batch 83 in epoch 0, gen_loss = 1.0199159291528521, disc_loss = 0.12698615663906648
Trained batch 84 in epoch 0, gen_loss = 1.0194476877941805, disc_loss = 0.12598335083354922
Trained batch 85 in epoch 0, gen_loss = 1.0220061034657235, disc_loss = 0.12505909850344407
Trained batch 86 in epoch 0, gen_loss = 1.0211489419827515, disc_loss = 0.1250750269826459
Trained batch 87 in epoch 0, gen_loss = 1.024669117548249, disc_loss = 0.12999914432029155
Trained batch 88 in epoch 0, gen_loss = 1.0238825531488054, disc_loss = 0.12940876074972446
Trained batch 89 in epoch 0, gen_loss = 1.0204713920752206, disc_loss = 0.12998938119659822
Trained batch 90 in epoch 0, gen_loss = 1.0191877497421515, disc_loss = 0.12978301432679643
Trained batch 91 in epoch 0, gen_loss = 1.0191695178332536, disc_loss = 0.12907803088993483
Trained batch 92 in epoch 0, gen_loss = 1.0178974860457963, disc_loss = 0.1282752998053066
Trained batch 93 in epoch 0, gen_loss = 1.0163421041153846, disc_loss = 0.12761804673503688
Trained batch 94 in epoch 0, gen_loss = 1.0159662453751814, disc_loss = 0.12676926566974112
Trained batch 95 in epoch 0, gen_loss = 1.0168785409380992, disc_loss = 0.12593325113023943
Trained batch 96 in epoch 0, gen_loss = 1.0161879572671713, disc_loss = 0.12514165644869976
Trained batch 97 in epoch 0, gen_loss = 1.015725579797005, disc_loss = 0.12431400826162829
Trained batch 98 in epoch 0, gen_loss = 1.01476331070216, disc_loss = 0.12365948470930259
Trained batch 99 in epoch 0, gen_loss = 1.0176493644714355, disc_loss = 0.12300736689940095
Trained batch 100 in epoch 0, gen_loss = 1.0158900040211063, disc_loss = 0.12251688866405794
Trained batch 101 in epoch 0, gen_loss = 1.0178522122841256, disc_loss = 0.12221960002081651
Trained batch 102 in epoch 0, gen_loss = 1.014889486206388, disc_loss = 0.12241825962312591
Trained batch 103 in epoch 0, gen_loss = 1.01716410024808, disc_loss = 0.1223201119305136
Trained batch 104 in epoch 0, gen_loss = 1.0180932482083638, disc_loss = 0.12147381350043274
Trained batch 105 in epoch 0, gen_loss = 1.0160333025005628, disc_loss = 0.12128603488277152
Trained batch 106 in epoch 0, gen_loss = 1.018084809601864, disc_loss = 0.12207434836461722
Trained batch 107 in epoch 0, gen_loss = 1.015000041436266, disc_loss = 0.12428404199373391
Trained batch 108 in epoch 0, gen_loss = 1.013239340497813, disc_loss = 0.12452096719328963
Trained batch 109 in epoch 0, gen_loss = 1.0131922326304696, disc_loss = 0.1250430284745314
Trained batch 110 in epoch 0, gen_loss = 1.0122007233602506, disc_loss = 0.12524819295215714
Trained batch 111 in epoch 0, gen_loss = 1.013133712645088, disc_loss = 0.12927861433542734
Trained batch 112 in epoch 0, gen_loss = 1.0123080131226936, disc_loss = 0.13037351988651583
Trained batch 113 in epoch 0, gen_loss = 1.009258338233881, disc_loss = 0.13140944955184272
Trained batch 114 in epoch 0, gen_loss = 1.0080371390218321, disc_loss = 0.13147641901412735
Trained batch 115 in epoch 0, gen_loss = 1.007222255242282, disc_loss = 0.13256791608151178
Trained batch 116 in epoch 0, gen_loss = 1.00675141505706, disc_loss = 0.13256227525954062
Trained batch 117 in epoch 0, gen_loss = 1.0036639318627827, disc_loss = 0.13264939657775526
Trained batch 118 in epoch 0, gen_loss = 1.0033348247784526, disc_loss = 0.13235018072070695
Trained batch 119 in epoch 0, gen_loss = 1.0021837428212166, disc_loss = 0.13182120939406256
Trained batch 120 in epoch 0, gen_loss = 0.9992328448729082, disc_loss = 0.13284186681747928
Trained batch 121 in epoch 0, gen_loss = 0.9992347701651151, disc_loss = 0.13253004575667324
Trained batch 122 in epoch 0, gen_loss = 0.9989619860804178, disc_loss = 0.13240067292822572
Trained batch 123 in epoch 0, gen_loss = 0.9963683490791628, disc_loss = 0.133488254035793
Trained batch 124 in epoch 0, gen_loss = 0.9960601754188537, disc_loss = 0.13353682442009449
Trained batch 125 in epoch 0, gen_loss = 0.9969301058186425, disc_loss = 0.13479101345948283
Trained batch 126 in epoch 0, gen_loss = 0.9946901915580268, disc_loss = 0.1357162455903498
Trained batch 127 in epoch 0, gen_loss = 0.9932411671616137, disc_loss = 0.13618383528955746
Trained batch 128 in epoch 0, gen_loss = 0.9927085388538449, disc_loss = 0.13651602127582066
Trained batch 129 in epoch 0, gen_loss = 0.9908795237541199, disc_loss = 0.13728019556460472
Trained batch 130 in epoch 0, gen_loss = 0.9895729741067377, disc_loss = 0.13791360821262116
Trained batch 131 in epoch 0, gen_loss = 0.9877454354004427, disc_loss = 0.1381580234279461
Trained batch 132 in epoch 0, gen_loss = 0.9876397547865272, disc_loss = 0.13828959619920506
Trained batch 133 in epoch 0, gen_loss = 0.9875506113714246, disc_loss = 0.1383490707697486
Trained batch 134 in epoch 0, gen_loss = 0.986503913225951, disc_loss = 0.13910472620692518
Trained batch 135 in epoch 0, gen_loss = 0.9865498433218283, disc_loss = 0.13920641850734897
Trained batch 136 in epoch 0, gen_loss = 0.9848171611771966, disc_loss = 0.13919539136445
Trained batch 137 in epoch 0, gen_loss = 0.9837690030319103, disc_loss = 0.13911542033209748
Trained batch 138 in epoch 0, gen_loss = 0.9836072124165597, disc_loss = 0.1390332743230698
Trained batch 139 in epoch 0, gen_loss = 0.9842837631702424, disc_loss = 0.13950334080894078
Trained batch 140 in epoch 0, gen_loss = 0.9814170882211509, disc_loss = 0.14179145144496827
Trained batch 141 in epoch 0, gen_loss = 0.9800226163696235, disc_loss = 0.14230920013669932
Trained batch 142 in epoch 0, gen_loss = 0.9792185292377339, disc_loss = 0.14290187696737428
Trained batch 143 in epoch 0, gen_loss = 0.977537791348166, disc_loss = 0.14360247175985327
Trained batch 144 in epoch 0, gen_loss = 0.9756945433287785, disc_loss = 0.1441217096329763
Trained batch 145 in epoch 0, gen_loss = 0.9734059335434273, disc_loss = 0.14445384975828945
Trained batch 146 in epoch 0, gen_loss = 0.9712559815977706, disc_loss = 0.14476462424460318
Trained batch 147 in epoch 0, gen_loss = 0.9703433557942107, disc_loss = 0.14497707760263537
Trained batch 148 in epoch 0, gen_loss = 0.97066884752888, disc_loss = 0.1450108492359419
Trained batch 149 in epoch 0, gen_loss = 0.9700424873828888, disc_loss = 0.14516055172930162
Trained batch 150 in epoch 0, gen_loss = 0.9684729662952044, disc_loss = 0.14552918635308743
Trained batch 151 in epoch 0, gen_loss = 0.9692679024056384, disc_loss = 0.14580901826143658
Trained batch 152 in epoch 0, gen_loss = 0.9679869689972572, disc_loss = 0.14578675285127818
Trained batch 153 in epoch 0, gen_loss = 0.9678119208131518, disc_loss = 0.1455576043551812
Trained batch 154 in epoch 0, gen_loss = 0.9692783705649838, disc_loss = 0.1468305275445023
Trained batch 155 in epoch 0, gen_loss = 0.9673094256566122, disc_loss = 0.14804781602026942
Trained batch 156 in epoch 0, gen_loss = 0.9662746316308428, disc_loss = 0.14809686743956843
Trained batch 157 in epoch 0, gen_loss = 0.9661386922190461, disc_loss = 0.14808294008474185
Trained batch 158 in epoch 0, gen_loss = 0.9647534774534358, disc_loss = 0.1482304823028404
Trained batch 159 in epoch 0, gen_loss = 0.963836332783103, disc_loss = 0.14849890145706013
Trained batch 160 in epoch 0, gen_loss = 0.9623651615581157, disc_loss = 0.14916497701489778
Trained batch 161 in epoch 0, gen_loss = 0.962883049323235, disc_loss = 0.1491222370668878
Trained batch 162 in epoch 0, gen_loss = 0.9623919005042936, disc_loss = 0.14911950495025497
Trained batch 163 in epoch 0, gen_loss = 0.9614698941387781, disc_loss = 0.14926609398070267
Trained batch 164 in epoch 0, gen_loss = 0.9608832857825539, disc_loss = 0.14900190036630992
Trained batch 165 in epoch 0, gen_loss = 0.9608578753758625, disc_loss = 0.14877735227570835
Trained batch 166 in epoch 0, gen_loss = 0.9611718247750562, disc_loss = 0.14863412962211464
Trained batch 167 in epoch 0, gen_loss = 0.9592916731323514, disc_loss = 0.1489725640331883
Trained batch 168 in epoch 0, gen_loss = 0.9595751550776013, disc_loss = 0.15080246528797953
Trained batch 169 in epoch 0, gen_loss = 0.9588992206489338, disc_loss = 0.15098920294686274
Trained batch 170 in epoch 0, gen_loss = 0.9572272861910145, disc_loss = 0.15169672978421053
Trained batch 171 in epoch 0, gen_loss = 0.9565357631722162, disc_loss = 0.15187807568500555
Trained batch 172 in epoch 0, gen_loss = 0.9563656883432686, disc_loss = 0.15171630806531866
Trained batch 173 in epoch 0, gen_loss = 0.9559329813239218, disc_loss = 0.1515648464040681
Trained batch 174 in epoch 0, gen_loss = 0.9562625581877572, disc_loss = 0.1523823451676539
Trained batch 175 in epoch 0, gen_loss = 0.9545425803146579, disc_loss = 0.15314128585371442
Trained batch 176 in epoch 0, gen_loss = 0.9540975467633392, disc_loss = 0.153166960577591
Trained batch 177 in epoch 0, gen_loss = 0.9529798985197303, disc_loss = 0.15298307256961471
Trained batch 178 in epoch 0, gen_loss = 0.9519216831169981, disc_loss = 0.15291697766069925
Trained batch 179 in epoch 0, gen_loss = 0.9510315428177516, disc_loss = 0.15286449728947546
Trained batch 180 in epoch 0, gen_loss = 0.9517836896754102, disc_loss = 0.15287350823083964
Trained batch 181 in epoch 0, gen_loss = 0.9505250119900965, disc_loss = 0.15305352961173752
Trained batch 182 in epoch 0, gen_loss = 0.950519384582186, disc_loss = 0.15289990649726548
Trained batch 183 in epoch 0, gen_loss = 0.951351316726726, disc_loss = 0.1529495943357925
Trained batch 184 in epoch 0, gen_loss = 0.9495224317988834, disc_loss = 0.15349095662099285
Trained batch 185 in epoch 0, gen_loss = 0.9491613270134054, disc_loss = 0.15370075377605616
Trained batch 186 in epoch 0, gen_loss = 0.9476634273554552, disc_loss = 0.15389835656207193
Trained batch 187 in epoch 0, gen_loss = 0.9476001319733072, disc_loss = 0.15392199686748234
Trained batch 188 in epoch 0, gen_loss = 0.9467506560068282, disc_loss = 0.15378360565574395
Trained batch 189 in epoch 0, gen_loss = 0.9470242751272101, disc_loss = 0.15337966873653625
Trained batch 190 in epoch 0, gen_loss = 0.9482268825251394, disc_loss = 0.15522773607746157
Trained batch 191 in epoch 0, gen_loss = 0.9475977119679252, disc_loss = 0.1556930391913435
Trained batch 192 in epoch 0, gen_loss = 0.9477280041714407, disc_loss = 0.15528864954921556
Trained batch 193 in epoch 0, gen_loss = 0.9477686568633797, disc_loss = 0.155319595815057
Trained batch 194 in epoch 0, gen_loss = 0.9459079543749491, disc_loss = 0.15623374372147597
Trained batch 195 in epoch 0, gen_loss = 0.945045851018964, disc_loss = 0.15623573264183135
Trained batch 196 in epoch 0, gen_loss = 0.9452121272910065, disc_loss = 0.15637935332121886
Trained batch 197 in epoch 0, gen_loss = 0.9445465776053342, disc_loss = 0.15671560097711557
Trained batch 198 in epoch 0, gen_loss = 0.9436631966475866, disc_loss = 0.1568152707294753
Trained batch 199 in epoch 0, gen_loss = 0.9440244796872139, disc_loss = 0.1564520959276706
Trained batch 200 in epoch 0, gen_loss = 0.9432488315141023, disc_loss = 0.15652192207006968
Trained batch 201 in epoch 0, gen_loss = 0.9446618577631394, disc_loss = 0.15743937030766564
Trained batch 202 in epoch 0, gen_loss = 0.9438224261617426, disc_loss = 0.15756169443243537
Trained batch 203 in epoch 0, gen_loss = 0.9419068808064741, disc_loss = 0.1578746076180216
Trained batch 204 in epoch 0, gen_loss = 0.941781540905557, disc_loss = 0.1579640803268043
Trained batch 205 in epoch 0, gen_loss = 0.9410680465906569, disc_loss = 0.15793822551128064
Trained batch 206 in epoch 0, gen_loss = 0.9401980756561538, disc_loss = 0.15782865987199804
Trained batch 207 in epoch 0, gen_loss = 0.9390306174755096, disc_loss = 0.15861303378075647
Trained batch 208 in epoch 0, gen_loss = 0.9392989674253327, disc_loss = 0.15960505495124172
Trained batch 209 in epoch 0, gen_loss = 0.9387077359926133, disc_loss = 0.15989747250541336
Trained batch 210 in epoch 0, gen_loss = 0.9373576129782256, disc_loss = 0.16011403639628707
Trained batch 211 in epoch 0, gen_loss = 0.9368021530362795, disc_loss = 0.16007970573099436
Trained batch 212 in epoch 0, gen_loss = 0.9362725640686465, disc_loss = 0.16015243555633396
Trained batch 213 in epoch 0, gen_loss = 0.935693722740512, disc_loss = 0.160098759971002
Trained batch 214 in epoch 0, gen_loss = 0.9348344292751578, disc_loss = 0.1602368343448223
Trained batch 215 in epoch 0, gen_loss = 0.9345338223157106, disc_loss = 0.16010818269138258
Trained batch 216 in epoch 0, gen_loss = 0.9336758775095786, disc_loss = 0.16033112340980135
Trained batch 217 in epoch 0, gen_loss = 0.9326373204725598, disc_loss = 0.16084661817502813
Trained batch 218 in epoch 0, gen_loss = 0.932587984490068, disc_loss = 0.1611938848496164
Trained batch 219 in epoch 0, gen_loss = 0.9320253513076089, disc_loss = 0.1613030186854303
Trained batch 220 in epoch 0, gen_loss = 0.9309785258176639, disc_loss = 0.161371315606107
Trained batch 221 in epoch 0, gen_loss = 0.9298621646992795, disc_loss = 0.16138831201336673
Trained batch 222 in epoch 0, gen_loss = 0.9287800056517391, disc_loss = 0.1613553074593635
Trained batch 223 in epoch 0, gen_loss = 0.9280711745045015, disc_loss = 0.16128085265102396
Trained batch 224 in epoch 0, gen_loss = 0.9281817317008972, disc_loss = 0.16112351772685846
Trained batch 225 in epoch 0, gen_loss = 0.9273085741870171, disc_loss = 0.1611400418461556
Trained batch 226 in epoch 0, gen_loss = 0.9266965735851406, disc_loss = 0.1612824991033597
Trained batch 227 in epoch 0, gen_loss = 0.9264774976069468, disc_loss = 0.16120211705728843
Trained batch 228 in epoch 0, gen_loss = 0.9271460323875127, disc_loss = 0.1614752701162381
Trained batch 229 in epoch 0, gen_loss = 0.9259422698746557, disc_loss = 0.1619960264424267
Trained batch 230 in epoch 0, gen_loss = 0.9260570866204959, disc_loss = 0.16267648433613313
Trained batch 231 in epoch 0, gen_loss = 0.9250570964710466, disc_loss = 0.16283192592351858
Trained batch 232 in epoch 0, gen_loss = 0.9239344381979095, disc_loss = 0.16319408581907913
Trained batch 233 in epoch 0, gen_loss = 0.9233784344461229, disc_loss = 0.1633069762068554
Trained batch 234 in epoch 0, gen_loss = 0.9228372464788721, disc_loss = 0.16342330407747563
Trained batch 235 in epoch 0, gen_loss = 0.9220734316918809, disc_loss = 0.1635614880834217
Trained batch 236 in epoch 0, gen_loss = 0.9210299758971492, disc_loss = 0.16369295306503773
Trained batch 237 in epoch 0, gen_loss = 0.9206239911688476, disc_loss = 0.1635551371009034
Trained batch 238 in epoch 0, gen_loss = 0.9204583983541034, disc_loss = 0.16354538753597556
Trained batch 239 in epoch 0, gen_loss = 0.9196292797724406, disc_loss = 0.1634257403279965
Trained batch 240 in epoch 0, gen_loss = 0.9190966773824573, disc_loss = 0.16323523125244127
Trained batch 241 in epoch 0, gen_loss = 0.9189344481988386, disc_loss = 0.16338835017032122
Trained batch 242 in epoch 0, gen_loss = 0.9180810117917787, disc_loss = 0.1640278992660865
Trained batch 243 in epoch 0, gen_loss = 0.9172059451458884, disc_loss = 0.1641506312155455
Trained batch 244 in epoch 0, gen_loss = 0.9172897932480792, disc_loss = 0.16431558960098394
Trained batch 245 in epoch 0, gen_loss = 0.9161820329301725, disc_loss = 0.16441113920503758
Trained batch 246 in epoch 0, gen_loss = 0.9155009041430979, disc_loss = 0.16455681490059565
Trained batch 247 in epoch 0, gen_loss = 0.9156377317924653, disc_loss = 0.16478677323058008
Trained batch 248 in epoch 0, gen_loss = 0.9146014418467939, disc_loss = 0.1651666604924992
Trained batch 249 in epoch 0, gen_loss = 0.9136233577728271, disc_loss = 0.1652774930074811
Trained batch 250 in epoch 0, gen_loss = 0.9132424450490579, disc_loss = 0.16521489430975866
Trained batch 251 in epoch 0, gen_loss = 0.9132621941112337, disc_loss = 0.16506226739979216
Trained batch 252 in epoch 0, gen_loss = 0.9131748181557938, disc_loss = 0.1650912165715407
Trained batch 253 in epoch 0, gen_loss = 0.9126600871874592, disc_loss = 0.1650933050807184
Trained batch 254 in epoch 0, gen_loss = 0.9126027915991989, disc_loss = 0.1648265241773105
Trained batch 255 in epoch 0, gen_loss = 0.9130478743463755, disc_loss = 0.1648508374710218
Trained batch 256 in epoch 0, gen_loss = 0.9120061787185966, disc_loss = 0.16528203228945165
Trained batch 257 in epoch 0, gen_loss = 0.9119127589140752, disc_loss = 0.16500242023418346
Trained batch 258 in epoch 0, gen_loss = 0.9128413662947282, disc_loss = 0.1652597498839081
Trained batch 259 in epoch 0, gen_loss = 0.9123451347534474, disc_loss = 0.16545709936807934
Trained batch 260 in epoch 0, gen_loss = 0.9114870255477584, disc_loss = 0.16545656492569666
Trained batch 261 in epoch 0, gen_loss = 0.9114826990447882, disc_loss = 0.16580848996563038
Trained batch 262 in epoch 0, gen_loss = 0.9101991855146314, disc_loss = 0.16612323221286668
Trained batch 263 in epoch 0, gen_loss = 0.9094227387598066, disc_loss = 0.16632524412830896
Trained batch 264 in epoch 0, gen_loss = 0.9087846164433462, disc_loss = 0.16646058579801387
Trained batch 265 in epoch 0, gen_loss = 0.9084148265813526, disc_loss = 0.1665682897209785
Trained batch 266 in epoch 0, gen_loss = 0.9078944573241673, disc_loss = 0.16667405209654057
Trained batch 267 in epoch 0, gen_loss = 0.9073783524000822, disc_loss = 0.16683674746179092
Trained batch 268 in epoch 0, gen_loss = 0.9068169682442477, disc_loss = 0.16698523356707345
Trained batch 269 in epoch 0, gen_loss = 0.9061054393097207, disc_loss = 0.16698751933182832
Trained batch 270 in epoch 0, gen_loss = 0.905903435941112, disc_loss = 0.16684389513714507
Trained batch 271 in epoch 0, gen_loss = 0.9056859393330181, disc_loss = 0.1666421612847925
Trained batch 272 in epoch 0, gen_loss = 0.9054967392058599, disc_loss = 0.16653585300913878
Trained batch 273 in epoch 0, gen_loss = 0.9052716578445296, disc_loss = 0.16646805952853747
Trained batch 274 in epoch 0, gen_loss = 0.9048244389620694, disc_loss = 0.1665726117992943
Trained batch 275 in epoch 0, gen_loss = 0.9054578940073649, disc_loss = 0.16685094282813911
Trained batch 276 in epoch 0, gen_loss = 0.9047287803694659, disc_loss = 0.16699836436080803
Trained batch 277 in epoch 0, gen_loss = 0.9040154480248046, disc_loss = 0.16702650399650815
Trained batch 278 in epoch 0, gen_loss = 0.9038448709740861, disc_loss = 0.16737538958669348
Trained batch 279 in epoch 0, gen_loss = 0.9031905255147389, disc_loss = 0.16757255785300262
Trained batch 280 in epoch 0, gen_loss = 0.9028025509199638, disc_loss = 0.16737979778430004
Trained batch 281 in epoch 0, gen_loss = 0.9033638648952999, disc_loss = 0.16793534329412044
Trained batch 282 in epoch 0, gen_loss = 0.9026775246374178, disc_loss = 0.16816540273702818
Trained batch 283 in epoch 0, gen_loss = 0.9019181493302466, disc_loss = 0.1683285987253865
Trained batch 284 in epoch 0, gen_loss = 0.9019700111004344, disc_loss = 0.16827446562809903
Trained batch 285 in epoch 0, gen_loss = 0.9021097181977092, disc_loss = 0.16848314470787357
Trained batch 286 in epoch 0, gen_loss = 0.9015467563572661, disc_loss = 0.16842387129231404
Trained batch 287 in epoch 0, gen_loss = 0.9006064436915848, disc_loss = 0.16842319413424572
Trained batch 288 in epoch 0, gen_loss = 0.9000198597726525, disc_loss = 0.16846305808007306
Trained batch 289 in epoch 0, gen_loss = 0.8999740082642128, disc_loss = 0.16831918107666846
Trained batch 290 in epoch 0, gen_loss = 0.899569517558383, disc_loss = 0.16825186259583713
Trained batch 291 in epoch 0, gen_loss = 0.8996492318094593, disc_loss = 0.16824664446614582
Trained batch 292 in epoch 0, gen_loss = 0.8991238895943547, disc_loss = 0.16835165756783185
Trained batch 293 in epoch 0, gen_loss = 0.8982856810903873, disc_loss = 0.1689152689270523
Trained batch 294 in epoch 0, gen_loss = 0.8983973686977968, disc_loss = 0.1687692990305565
Trained batch 295 in epoch 0, gen_loss = 0.8993376902229077, disc_loss = 0.1691798081030012
Trained batch 296 in epoch 0, gen_loss = 0.8983496339232834, disc_loss = 0.1693343139921475
Trained batch 297 in epoch 0, gen_loss = 0.897315263748169, disc_loss = 0.16941772446961412
Trained batch 298 in epoch 0, gen_loss = 0.896830267132724, disc_loss = 0.16944706734631174
Trained batch 299 in epoch 0, gen_loss = 0.8961231185992559, disc_loss = 0.169632330990086
Trained batch 300 in epoch 0, gen_loss = 0.8953623282552954, disc_loss = 0.16991025769458062
Trained batch 301 in epoch 0, gen_loss = 0.8943522880408937, disc_loss = 0.17016629539800204
Trained batch 302 in epoch 0, gen_loss = 0.8936375552671577, disc_loss = 0.1701002402335602
Trained batch 303 in epoch 0, gen_loss = 0.8936987980023811, disc_loss = 0.17005904838075175
Trained batch 304 in epoch 0, gen_loss = 0.8932510774643695, disc_loss = 0.17004374681559742
Trained batch 305 in epoch 0, gen_loss = 0.8928168735472984, disc_loss = 0.1700017761524304
Trained batch 306 in epoch 0, gen_loss = 0.8925478916603113, disc_loss = 0.16997599781942874
Trained batch 307 in epoch 0, gen_loss = 0.8922158319067646, disc_loss = 0.16990853537043388
Trained batch 308 in epoch 0, gen_loss = 0.8918122788077419, disc_loss = 0.1698848604251748
Trained batch 309 in epoch 0, gen_loss = 0.8917910466271062, disc_loss = 0.1697188691566548
Trained batch 310 in epoch 0, gen_loss = 0.8909768232195324, disc_loss = 0.16983631970151253
Trained batch 311 in epoch 0, gen_loss = 0.8909788162280352, disc_loss = 0.16973107167853949
Trained batch 312 in epoch 0, gen_loss = 0.8907741807139339, disc_loss = 0.16962786464574048
Trained batch 313 in epoch 0, gen_loss = 0.8899816164545192, disc_loss = 0.16988513806751768
Trained batch 314 in epoch 0, gen_loss = 0.8906255506333851, disc_loss = 0.1699087408622579
Trained batch 315 in epoch 0, gen_loss = 0.8901182605495935, disc_loss = 0.1698173651695723
Trained batch 316 in epoch 0, gen_loss = 0.889049557857333, disc_loss = 0.16988695197230447
Trained batch 317 in epoch 0, gen_loss = 0.8888337301008357, disc_loss = 0.16980810794370166
Trained batch 318 in epoch 0, gen_loss = 0.8890325438266263, disc_loss = 0.17001483029449435
Trained batch 319 in epoch 0, gen_loss = 0.8884586660191417, disc_loss = 0.16995317841065116
Trained batch 320 in epoch 0, gen_loss = 0.888018390657003, disc_loss = 0.16976249021277806
Trained batch 321 in epoch 0, gen_loss = 0.8878483026294235, disc_loss = 0.17005514495236718
Trained batch 322 in epoch 0, gen_loss = 0.8871913941652044, disc_loss = 0.17023261254163166
Trained batch 323 in epoch 0, gen_loss = 0.8868491145563714, disc_loss = 0.1700948318409055
Trained batch 324 in epoch 0, gen_loss = 0.8865820662791912, disc_loss = 0.17016476262647373
Trained batch 325 in epoch 0, gen_loss = 0.8862253061832825, disc_loss = 0.1700017590567104
Trained batch 326 in epoch 0, gen_loss = 0.8858941939263534, disc_loss = 0.1698313758791131
Trained batch 327 in epoch 0, gen_loss = 0.8855921978630671, disc_loss = 0.16979469841050848
Trained batch 328 in epoch 0, gen_loss = 0.8848635632216387, disc_loss = 0.16968586950882772
Trained batch 329 in epoch 0, gen_loss = 0.8840622992226572, disc_loss = 0.16977992699566213
Trained batch 330 in epoch 0, gen_loss = 0.8843002863160793, disc_loss = 0.16987106483711037
Trained batch 331 in epoch 0, gen_loss = 0.8838949020368507, disc_loss = 0.16979983418125166
Trained batch 332 in epoch 0, gen_loss = 0.8835781182612743, disc_loss = 0.169698068648353
Trained batch 333 in epoch 0, gen_loss = 0.8833382458030107, disc_loss = 0.16953955104987242
Trained batch 334 in epoch 0, gen_loss = 0.8834691065460888, disc_loss = 0.16928280519126956
Trained batch 335 in epoch 0, gen_loss = 0.8834191892473471, disc_loss = 0.1691820233716585
Trained batch 336 in epoch 0, gen_loss = 0.883010473378688, disc_loss = 0.16905979757426579
Trained batch 337 in epoch 0, gen_loss = 0.8837981883590743, disc_loss = 0.16918768758538383
Trained batch 338 in epoch 0, gen_loss = 0.8827911388557569, disc_loss = 0.16912531152169788
Trained batch 339 in epoch 0, gen_loss = 0.882552216684117, disc_loss = 0.16904163223088664
Trained batch 340 in epoch 0, gen_loss = 0.8817167053124771, disc_loss = 0.16909018738462953
Trained batch 341 in epoch 0, gen_loss = 0.8816509035944241, disc_loss = 0.16898364454442472
Trained batch 342 in epoch 0, gen_loss = 0.8827035147316602, disc_loss = 0.17026027488052498
Trained batch 343 in epoch 0, gen_loss = 0.8829555929053662, disc_loss = 0.17039319256125668
Trained batch 344 in epoch 0, gen_loss = 0.8825114645819733, disc_loss = 0.1705415630524141
Trained batch 345 in epoch 0, gen_loss = 0.8819794511863951, disc_loss = 0.17053706907920238
Trained batch 346 in epoch 0, gen_loss = 0.881435253091092, disc_loss = 0.17048679659899957
Trained batch 347 in epoch 0, gen_loss = 0.8811272365608435, disc_loss = 0.17036676182593594
Trained batch 348 in epoch 0, gen_loss = 0.8806120073556217, disc_loss = 0.17023263750517778
Trained batch 349 in epoch 0, gen_loss = 0.8799220040866307, disc_loss = 0.17026960171226943
Trained batch 350 in epoch 0, gen_loss = 0.8798521205230996, disc_loss = 0.17024184243907448
Trained batch 351 in epoch 0, gen_loss = 0.8800593338568102, disc_loss = 0.17036021300274032
Trained batch 352 in epoch 0, gen_loss = 0.8795358567332411, disc_loss = 0.17036470760810307
Trained batch 353 in epoch 0, gen_loss = 0.8793267287776969, disc_loss = 0.1702244646142179
Trained batch 354 in epoch 0, gen_loss = 0.8793412347914468, disc_loss = 0.17004436846874968
Trained batch 355 in epoch 0, gen_loss = 0.8794109156627333, disc_loss = 0.17012767460762282
Trained batch 356 in epoch 0, gen_loss = 0.8788298600528086, disc_loss = 0.17034321038850717
Trained batch 357 in epoch 0, gen_loss = 0.8785898943520125, disc_loss = 0.17030152137906357
Trained batch 358 in epoch 0, gen_loss = 0.878115581768801, disc_loss = 0.17011467550562118
Trained batch 359 in epoch 0, gen_loss = 0.8778719734814432, disc_loss = 0.16993138552643358
Trained batch 360 in epoch 0, gen_loss = 0.8781833024566523, disc_loss = 0.1696907040247709
Trained batch 361 in epoch 0, gen_loss = 0.8773675501675896, disc_loss = 0.16950371201299336
Trained batch 362 in epoch 0, gen_loss = 0.8776138669531536, disc_loss = 0.16926310415130838
Trained batch 363 in epoch 0, gen_loss = 0.8776630610227585, disc_loss = 0.16899623861536384
Trained batch 364 in epoch 0, gen_loss = 0.8782961651070477, disc_loss = 0.1692697842694717
Trained batch 365 in epoch 0, gen_loss = 0.8778166648794393, disc_loss = 0.16937650862796222
Trained batch 366 in epoch 0, gen_loss = 0.8780966573255263, disc_loss = 0.16941274849225943
Trained batch 367 in epoch 0, gen_loss = 0.8779343342327554, disc_loss = 0.1692807333311066
Trained batch 368 in epoch 0, gen_loss = 0.8778754217514824, disc_loss = 0.1690239902525171
Trained batch 369 in epoch 0, gen_loss = 0.8779591360607663, disc_loss = 0.16883708158558286
Trained batch 370 in epoch 0, gen_loss = 0.8779155150899347, disc_loss = 0.16856051325255808
Trained batch 371 in epoch 0, gen_loss = 0.878252609442639, disc_loss = 0.16828100283640207
Trained batch 372 in epoch 0, gen_loss = 0.8781370312854369, disc_loss = 0.16802135689668457
Trained batch 373 in epoch 0, gen_loss = 0.8786185394952641, disc_loss = 0.16828136915530273
Trained batch 374 in epoch 0, gen_loss = 0.8781643446286519, disc_loss = 0.1683745021869739
Trained batch 375 in epoch 0, gen_loss = 0.8786077066621882, disc_loss = 0.1686648713038402
Trained batch 376 in epoch 0, gen_loss = 0.8780522499856013, disc_loss = 0.16870177326234803
Trained batch 377 in epoch 0, gen_loss = 0.8776816389863453, disc_loss = 0.16870736315471943
Trained batch 378 in epoch 0, gen_loss = 0.8777402552891532, disc_loss = 0.16877366441712374
Trained batch 379 in epoch 0, gen_loss = 0.8773309524122037, disc_loss = 0.16874846455788142
Trained batch 380 in epoch 0, gen_loss = 0.8771439632718644, disc_loss = 0.16854347605893774
Trained batch 381 in epoch 0, gen_loss = 0.8768797744631143, disc_loss = 0.16831095489863482
Trained batch 382 in epoch 0, gen_loss = 0.876493647266617, disc_loss = 0.16822401627256262
Trained batch 383 in epoch 0, gen_loss = 0.8767627209114531, disc_loss = 0.16838987874507438
Trained batch 384 in epoch 0, gen_loss = 0.8764920999477436, disc_loss = 0.1684416524823997
Trained batch 385 in epoch 0, gen_loss = 0.8763493222276164, disc_loss = 0.1687115270287339
Trained batch 386 in epoch 0, gen_loss = 0.8758178724491011, disc_loss = 0.16868843404378847
Trained batch 387 in epoch 0, gen_loss = 0.8755982952941325, disc_loss = 0.16872956128022873
Trained batch 388 in epoch 0, gen_loss = 0.8753077173294322, disc_loss = 0.16866969756284073
Trained batch 389 in epoch 0, gen_loss = 0.87497795239473, disc_loss = 0.16854909441123406
Trained batch 390 in epoch 0, gen_loss = 0.8745786477537716, disc_loss = 0.1683924532235812
Trained batch 391 in epoch 0, gen_loss = 0.8747887400035955, disc_loss = 0.1681141574648494
Trained batch 392 in epoch 0, gen_loss = 0.8747184396396763, disc_loss = 0.16805568841255197
Trained batch 393 in epoch 0, gen_loss = 0.8741913937070043, disc_loss = 0.16831805533847682
Trained batch 394 in epoch 0, gen_loss = 0.8746249911151355, disc_loss = 0.16886019815655448
Trained batch 395 in epoch 0, gen_loss = 0.8744390856738042, disc_loss = 0.16864990384195638
Trained batch 396 in epoch 0, gen_loss = 0.8743056111431843, disc_loss = 0.16844566760852145
Trained batch 397 in epoch 0, gen_loss = 0.874255751994387, disc_loss = 0.16825089225049444
Trained batch 398 in epoch 0, gen_loss = 0.873843927281841, disc_loss = 0.1680884060956407
Trained batch 399 in epoch 0, gen_loss = 0.873995423913002, disc_loss = 0.16814173046033828
Trained batch 400 in epoch 0, gen_loss = 0.8734170987719015, disc_loss = 0.16814707189408176
Trained batch 401 in epoch 0, gen_loss = 0.8734578740834004, disc_loss = 0.16789308879339132
Trained batch 402 in epoch 0, gen_loss = 0.8734566616657058, disc_loss = 0.16768566006447927
Trained batch 403 in epoch 0, gen_loss = 0.873399762676494, disc_loss = 0.16760971123758373
Trained batch 404 in epoch 0, gen_loss = 0.8727609682966162, disc_loss = 0.16767325231598484
Trained batch 405 in epoch 0, gen_loss = 0.8733242070440002, disc_loss = 0.16779443646868314
Trained batch 406 in epoch 0, gen_loss = 0.8728120835173042, disc_loss = 0.16769263341894752
Trained batch 407 in epoch 0, gen_loss = 0.8725690054250699, disc_loss = 0.16753649733065828
Trained batch 408 in epoch 0, gen_loss = 0.872153722423796, disc_loss = 0.167364596386957
Trained batch 409 in epoch 0, gen_loss = 0.8717982164243373, disc_loss = 0.1672070927509084
Trained batch 410 in epoch 0, gen_loss = 0.8721159586361145, disc_loss = 0.1669719577189127
Trained batch 411 in epoch 0, gen_loss = 0.8720803252122935, disc_loss = 0.16668655879307284
Trained batch 412 in epoch 0, gen_loss = 0.8716257008166926, disc_loss = 0.16651617333780044
Trained batch 413 in epoch 0, gen_loss = 0.8713773680481933, disc_loss = 0.16642223633735795
Trained batch 414 in epoch 0, gen_loss = 0.8723865461636738, disc_loss = 0.16688873743167124
Trained batch 415 in epoch 0, gen_loss = 0.8723477725512706, disc_loss = 0.16669353404386827
Trained batch 416 in epoch 0, gen_loss = 0.8719043452962697, disc_loss = 0.16659717528457693
Trained batch 417 in epoch 0, gen_loss = 0.8714517677229557, disc_loss = 0.16650507309023985
Trained batch 418 in epoch 0, gen_loss = 0.8713682013650498, disc_loss = 0.1663537223763355
Trained batch 419 in epoch 0, gen_loss = 0.8712242935385023, disc_loss = 0.166125523835598
Trained batch 420 in epoch 0, gen_loss = 0.8710380549102384, disc_loss = 0.1658976726862215
Trained batch 421 in epoch 0, gen_loss = 0.8715145246112516, disc_loss = 0.16579291576263605
Trained batch 422 in epoch 0, gen_loss = 0.8708785238277263, disc_loss = 0.16580288748457217
Trained batch 423 in epoch 0, gen_loss = 0.8714057031386303, disc_loss = 0.16614560641014492
Trained batch 424 in epoch 0, gen_loss = 0.871115215105169, disc_loss = 0.16595992967048112
Trained batch 425 in epoch 0, gen_loss = 0.8703564581736712, disc_loss = 0.16624193910089596
Trained batch 426 in epoch 0, gen_loss = 0.8706119405302007, disc_loss = 0.16669080926833862
Trained batch 427 in epoch 0, gen_loss = 0.8708027998142154, disc_loss = 0.16683744056428843
Trained batch 428 in epoch 0, gen_loss = 0.8705226433027041, disc_loss = 0.16678974871677812
Trained batch 429 in epoch 0, gen_loss = 0.8699662911337476, disc_loss = 0.1667511917694017
Trained batch 430 in epoch 0, gen_loss = 0.8694885323329757, disc_loss = 0.16680965313726814
Trained batch 431 in epoch 0, gen_loss = 0.8692242165130598, disc_loss = 0.16667314120827037
Trained batch 432 in epoch 0, gen_loss = 0.8690418113737128, disc_loss = 0.16649754306271364
Trained batch 433 in epoch 0, gen_loss = 0.8688695183547411, disc_loss = 0.16661229536091815
Trained batch 434 in epoch 0, gen_loss = 0.868336948170059, disc_loss = 0.16655743686032706
Trained batch 435 in epoch 0, gen_loss = 0.8681537753671681, disc_loss = 0.16648217142397248
Trained batch 436 in epoch 0, gen_loss = 0.8679933921696119, disc_loss = 0.16633234139386932
Trained batch 437 in epoch 0, gen_loss = 0.868068323559957, disc_loss = 0.16623708117991415
Trained batch 438 in epoch 0, gen_loss = 0.8675538638186617, disc_loss = 0.1663418141212781
Trained batch 439 in epoch 0, gen_loss = 0.8679968806830319, disc_loss = 0.166284172156487
Trained batch 440 in epoch 0, gen_loss = 0.8679594823292324, disc_loss = 0.16612812120239345
Trained batch 441 in epoch 0, gen_loss = 0.8675963420134324, disc_loss = 0.1661478931724823
Trained batch 442 in epoch 0, gen_loss = 0.867777985590037, disc_loss = 0.16613571336135505
Trained batch 443 in epoch 0, gen_loss = 0.867655327593958, disc_loss = 0.16599360736389016
Trained batch 444 in epoch 0, gen_loss = 0.8678902020615138, disc_loss = 0.16586675349664823
Trained batch 445 in epoch 0, gen_loss = 0.8675340066576218, disc_loss = 0.16575133398325587
Trained batch 446 in epoch 0, gen_loss = 0.8672387690618801, disc_loss = 0.16556059096166884
Trained batch 447 in epoch 0, gen_loss = 0.8671304961400372, disc_loss = 0.16534239365137182
Trained batch 448 in epoch 0, gen_loss = 0.8672482222650524, disc_loss = 0.16506023745245418
Trained batch 449 in epoch 0, gen_loss = 0.867134327756034, disc_loss = 0.16481774209688108
Trained batch 450 in epoch 0, gen_loss = 0.867152231759877, disc_loss = 0.16457659295634128
Trained batch 451 in epoch 0, gen_loss = 0.8672998662279771, disc_loss = 0.16427510078023888
Trained batch 452 in epoch 0, gen_loss = 0.8675079965433538, disc_loss = 0.1642869659730338
Trained batch 453 in epoch 0, gen_loss = 0.8669395465157631, disc_loss = 0.1651406592857667
Trained batch 454 in epoch 0, gen_loss = 0.8666943311691284, disc_loss = 0.16516343055108745
Trained batch 455 in epoch 0, gen_loss = 0.867191957538588, disc_loss = 0.16549943375662624
Trained batch 456 in epoch 0, gen_loss = 0.8668567034817368, disc_loss = 0.16556280735203552
Trained batch 457 in epoch 0, gen_loss = 0.8662101873664356, disc_loss = 0.16560457107981089
Trained batch 458 in epoch 0, gen_loss = 0.8660179087019694, disc_loss = 0.16553605045547023
Trained batch 459 in epoch 0, gen_loss = 0.8659331227126329, disc_loss = 0.16558654115170887
Trained batch 460 in epoch 0, gen_loss = 0.8664378371259396, disc_loss = 0.16568833551977694
Trained batch 461 in epoch 0, gen_loss = 0.8661907917751378, disc_loss = 0.16554693754730157
Trained batch 462 in epoch 0, gen_loss = 0.8660406918299121, disc_loss = 0.16535122207814493
Trained batch 463 in epoch 0, gen_loss = 0.8660711107839798, disc_loss = 0.16513051967345307
Trained batch 464 in epoch 0, gen_loss = 0.8661228927232886, disc_loss = 0.16491188244713892
Trained batch 465 in epoch 0, gen_loss = 0.86551626864421, disc_loss = 0.16485526992703584
Trained batch 466 in epoch 0, gen_loss = 0.865688323208811, disc_loss = 0.1646393852894707
Trained batch 467 in epoch 0, gen_loss = 0.8661065104170742, disc_loss = 0.16439019170247465
Trained batch 468 in epoch 0, gen_loss = 0.8656676142200478, disc_loss = 0.16435592888054182
Trained batch 469 in epoch 0, gen_loss = 0.8660311771200059, disc_loss = 0.16446495215864257
Trained batch 470 in epoch 0, gen_loss = 0.8657707963020179, disc_loss = 0.1644086524678074
Trained batch 471 in epoch 0, gen_loss = 0.8662777192006677, disc_loss = 0.16442551736530484
Trained batch 472 in epoch 0, gen_loss = 0.8659063556229589, disc_loss = 0.16431467332355443
Trained batch 473 in epoch 0, gen_loss = 0.8654938287372831, disc_loss = 0.16418620363616615
Trained batch 474 in epoch 0, gen_loss = 0.8651553914421483, disc_loss = 0.16409143063190737
Trained batch 475 in epoch 0, gen_loss = 0.8653356023445851, disc_loss = 0.16404852303558914
Trained batch 476 in epoch 0, gen_loss = 0.8649383928290952, disc_loss = 0.1638777278621429
Trained batch 477 in epoch 0, gen_loss = 0.864730801168346, disc_loss = 0.1637552020619292
Trained batch 478 in epoch 0, gen_loss = 0.8648789119372039, disc_loss = 0.16433375574150638
Trained batch 479 in epoch 0, gen_loss = 0.86448083880047, disc_loss = 0.16434713687049224
Trained batch 480 in epoch 0, gen_loss = 0.8645494921043856, disc_loss = 0.16433449276566134
Trained batch 481 in epoch 0, gen_loss = 0.8644016023988051, disc_loss = 0.164160451434429
Trained batch 482 in epoch 0, gen_loss = 0.8637442850424883, disc_loss = 0.164192894890164
Trained batch 483 in epoch 0, gen_loss = 0.8638632031511669, disc_loss = 0.16434526306092123
Trained batch 484 in epoch 0, gen_loss = 0.8635377262056488, disc_loss = 0.16422480017177224
Trained batch 485 in epoch 0, gen_loss = 0.8630704513057269, disc_loss = 0.1643229177635577
Trained batch 486 in epoch 0, gen_loss = 0.8632617945299011, disc_loss = 0.16453236406879382
Trained batch 487 in epoch 0, gen_loss = 0.8631268557710726, disc_loss = 0.16460986051815332
Trained batch 488 in epoch 0, gen_loss = 0.862695274786959, disc_loss = 0.16466697655496298
Trained batch 489 in epoch 0, gen_loss = 0.8625825316322093, disc_loss = 0.16465291196518406
Trained batch 490 in epoch 0, gen_loss = 0.8623757344156564, disc_loss = 0.16456113972316083
Trained batch 491 in epoch 0, gen_loss = 0.8623795069572402, disc_loss = 0.1644275302741283
Trained batch 492 in epoch 0, gen_loss = 0.861980080846357, disc_loss = 0.16435815661042386
Trained batch 493 in epoch 0, gen_loss = 0.862053903973537, disc_loss = 0.16434187105355355
Trained batch 494 in epoch 0, gen_loss = 0.8618684325555358, disc_loss = 0.164282939541671
Trained batch 495 in epoch 0, gen_loss = 0.8618727825101344, disc_loss = 0.16418167293417238
Trained batch 496 in epoch 0, gen_loss = 0.8619206508160597, disc_loss = 0.1639198427101676
Trained batch 497 in epoch 0, gen_loss = 0.8614041796889171, disc_loss = 0.16384858549404216
Trained batch 498 in epoch 0, gen_loss = 0.8619382621530063, disc_loss = 0.16380403978835964
Trained batch 499 in epoch 0, gen_loss = 0.8613595772981644, disc_loss = 0.1639356235973537
Trained batch 500 in epoch 0, gen_loss = 0.8617984390782263, disc_loss = 0.16391129400246515
Trained batch 501 in epoch 0, gen_loss = 0.8612774953661687, disc_loss = 0.1640902864320048
Trained batch 502 in epoch 0, gen_loss = 0.8613898641546488, disc_loss = 0.1642190114100636
Trained batch 503 in epoch 0, gen_loss = 0.861039128331911, disc_loss = 0.1641103211782932
Trained batch 504 in epoch 0, gen_loss = 0.8605442030595081, disc_loss = 0.16411262486166883
Trained batch 505 in epoch 0, gen_loss = 0.8602438504281251, disc_loss = 0.16416102372065716
Trained batch 506 in epoch 0, gen_loss = 0.8599381986454394, disc_loss = 0.16409504884960502
Trained batch 507 in epoch 0, gen_loss = 0.8599638380403594, disc_loss = 0.1639749287612971
Trained batch 508 in epoch 0, gen_loss = 0.8600087032336852, disc_loss = 0.16380169072457404
Trained batch 509 in epoch 0, gen_loss = 0.8600019267961091, disc_loss = 0.16358790343225588
Trained batch 510 in epoch 0, gen_loss = 0.8596747837187959, disc_loss = 0.16357155285279928
Trained batch 511 in epoch 0, gen_loss = 0.8595253492239863, disc_loss = 0.16343417361713364
Trained batch 512 in epoch 0, gen_loss = 0.859656709792786, disc_loss = 0.16324434118240083
Trained batch 513 in epoch 0, gen_loss = 0.8595108885013639, disc_loss = 0.1630413895617837
Trained batch 514 in epoch 0, gen_loss = 0.8598484906178077, disc_loss = 0.1629757694068175
Trained batch 515 in epoch 0, gen_loss = 0.8594325928725013, disc_loss = 0.16300454563569539
Trained batch 516 in epoch 0, gen_loss = 0.8597427136201693, disc_loss = 0.16298538848138064
Trained batch 517 in epoch 0, gen_loss = 0.8591185053343018, disc_loss = 0.16341286855587972
Trained batch 518 in epoch 0, gen_loss = 0.8597497283149087, disc_loss = 0.16372774668784384
Trained batch 519 in epoch 0, gen_loss = 0.8598429248883174, disc_loss = 0.1636798150658321
Trained batch 520 in epoch 0, gen_loss = 0.8590373943154047, disc_loss = 0.1638350768583235
Trained batch 521 in epoch 0, gen_loss = 0.8585458236293317, disc_loss = 0.1639236972642299
Trained batch 522 in epoch 0, gen_loss = 0.8584506981801349, disc_loss = 0.16391042853219445
Trained batch 523 in epoch 0, gen_loss = 0.8583587306260153, disc_loss = 0.16396733755530177
Trained batch 524 in epoch 0, gen_loss = 0.8580517873877571, disc_loss = 0.16397387165044036
Trained batch 525 in epoch 0, gen_loss = 0.8577152418659667, disc_loss = 0.16400984502946356
Trained batch 526 in epoch 0, gen_loss = 0.8574313672376086, disc_loss = 0.16401157100849292
Trained batch 527 in epoch 0, gen_loss = 0.8575237795823452, disc_loss = 0.16408069791258173
Trained batch 528 in epoch 0, gen_loss = 0.8571074584143373, disc_loss = 0.1640784791820385
Trained batch 529 in epoch 0, gen_loss = 0.8570169414551753, disc_loss = 0.1642069619324691
Trained batch 530 in epoch 0, gen_loss = 0.8565523841623532, disc_loss = 0.1642613242960863
Trained batch 531 in epoch 0, gen_loss = 0.8562494836243472, disc_loss = 0.16426806917582126
Trained batch 532 in epoch 0, gen_loss = 0.8558172613214596, disc_loss = 0.1642532947300243
Trained batch 533 in epoch 0, gen_loss = 0.8557277103599984, disc_loss = 0.164086138833077
Trained batch 534 in epoch 0, gen_loss = 0.8551615689959482, disc_loss = 0.164045601703714
Trained batch 535 in epoch 0, gen_loss = 0.8551420332002106, disc_loss = 0.1639659234996774
Trained batch 536 in epoch 0, gen_loss = 0.8550103309545215, disc_loss = 0.1638321768547958
Trained batch 537 in epoch 0, gen_loss = 0.8547837271677073, disc_loss = 0.1638280150747155
Trained batch 538 in epoch 0, gen_loss = 0.855342776578521, disc_loss = 0.16408872888777715
Trained batch 539 in epoch 0, gen_loss = 0.8549559211841335, disc_loss = 0.16416400162917044
Trained batch 540 in epoch 0, gen_loss = 0.8546905681187917, disc_loss = 0.1641379509382845
Trained batch 541 in epoch 0, gen_loss = 0.8547168871683388, disc_loss = 0.16425718025843924
Trained batch 542 in epoch 0, gen_loss = 0.8543034117415026, disc_loss = 0.16418967594634432
Trained batch 543 in epoch 0, gen_loss = 0.8540620739736101, disc_loss = 0.1641170320833814
Trained batch 544 in epoch 0, gen_loss = 0.854019424401292, disc_loss = 0.1641069788964243
Trained batch 545 in epoch 0, gen_loss = 0.8536093079454297, disc_loss = 0.16413804197909085
Trained batch 546 in epoch 0, gen_loss = 0.853651169830528, disc_loss = 0.1642741046035475
Trained batch 547 in epoch 0, gen_loss = 0.8530221324223671, disc_loss = 0.16434797758481254
Trained batch 548 in epoch 0, gen_loss = 0.8530625688465132, disc_loss = 0.16442441589831763
Trained batch 549 in epoch 0, gen_loss = 0.8529993943192742, disc_loss = 0.1644034664976326
Trained batch 550 in epoch 0, gen_loss = 0.8525156740592742, disc_loss = 0.1645824323136177
Trained batch 551 in epoch 0, gen_loss = 0.8523883413037529, disc_loss = 0.16461445447529896
Trained batch 552 in epoch 0, gen_loss = 0.8524378899747597, disc_loss = 0.16454650135289803
Trained batch 553 in epoch 0, gen_loss = 0.852056568764177, disc_loss = 0.16477254683669615
Trained batch 554 in epoch 0, gen_loss = 0.8519128230777947, disc_loss = 0.16479817762769558
Trained batch 555 in epoch 0, gen_loss = 0.8516370744692335, disc_loss = 0.16477681661239094
Trained batch 556 in epoch 0, gen_loss = 0.8512287258138777, disc_loss = 0.16474940037585567
Trained batch 557 in epoch 0, gen_loss = 0.8511449073484721, disc_loss = 0.16463755823898807
Trained batch 558 in epoch 0, gen_loss = 0.8507812265739885, disc_loss = 0.1646088593887675
Trained batch 559 in epoch 0, gen_loss = 0.8505015594086477, disc_loss = 0.16458781387856497
Trained batch 560 in epoch 0, gen_loss = 0.8503215246553302, disc_loss = 0.16446811470423897
Trained batch 561 in epoch 0, gen_loss = 0.850475900484998, disc_loss = 0.16434065069260864
Trained batch 562 in epoch 0, gen_loss = 0.8503680960217336, disc_loss = 0.16418260130468842
Trained batch 563 in epoch 0, gen_loss = 0.8499719672274928, disc_loss = 0.16414709572501957
Trained batch 564 in epoch 0, gen_loss = 0.8504851537995634, disc_loss = 0.16421697438752228
Trained batch 565 in epoch 0, gen_loss = 0.8501590892093341, disc_loss = 0.16420598529187086
Trained batch 566 in epoch 0, gen_loss = 0.8499677246945665, disc_loss = 0.1640655160758388
Trained batch 567 in epoch 0, gen_loss = 0.8504227377264433, disc_loss = 0.16416277088106832
Trained batch 568 in epoch 0, gen_loss = 0.8498846007042903, disc_loss = 0.16422459990872965
Trained batch 569 in epoch 0, gen_loss = 0.850021280688152, disc_loss = 0.16406635801193484
Trained batch 570 in epoch 0, gen_loss = 0.8499343859230784, disc_loss = 0.16395704421800303
Trained batch 571 in epoch 0, gen_loss = 0.8500057930400321, disc_loss = 0.16420734196679887
Trained batch 572 in epoch 0, gen_loss = 0.8495671445890663, disc_loss = 0.1642189896771161
Trained batch 573 in epoch 0, gen_loss = 0.8493731664136727, disc_loss = 0.16418930220674036
Trained batch 574 in epoch 0, gen_loss = 0.8489289197196132, disc_loss = 0.1640661080084417
Trained batch 575 in epoch 0, gen_loss = 0.8486071794500781, disc_loss = 0.1640373722540163
Trained batch 576 in epoch 0, gen_loss = 0.8484439926812719, disc_loss = 0.16396584447983337
Trained batch 577 in epoch 0, gen_loss = 0.8479934094995776, disc_loss = 0.1640660671749278
Trained batch 578 in epoch 0, gen_loss = 0.8481428104875824, disc_loss = 0.16426373441383527
Trained batch 579 in epoch 0, gen_loss = 0.847873645147373, disc_loss = 0.16419641732334578
Trained batch 580 in epoch 0, gen_loss = 0.8481393200497619, disc_loss = 0.16404691594692905
Trained batch 581 in epoch 0, gen_loss = 0.8479643526048595, disc_loss = 0.1639325791662655
Trained batch 582 in epoch 0, gen_loss = 0.8475034500170326, disc_loss = 0.1642090965343534
Trained batch 583 in epoch 0, gen_loss = 0.8475206107003231, disc_loss = 0.16410245515138216
Trained batch 584 in epoch 0, gen_loss = 0.847840394372614, disc_loss = 0.16409825693784105
Trained batch 585 in epoch 0, gen_loss = 0.8477996881199371, disc_loss = 0.16396856622980216
Trained batch 586 in epoch 0, gen_loss = 0.8474015958569119, disc_loss = 0.1641447094238952
Trained batch 587 in epoch 0, gen_loss = 0.8479038489615025, disc_loss = 0.16446225405639026
Trained batch 588 in epoch 0, gen_loss = 0.8479217539315312, disc_loss = 0.1643877059240242
Trained batch 589 in epoch 0, gen_loss = 0.8475486309346506, disc_loss = 0.1644184906572356
Trained batch 590 in epoch 0, gen_loss = 0.8473519307203503, disc_loss = 0.16436395762321207
Trained batch 591 in epoch 0, gen_loss = 0.847194400238427, disc_loss = 0.16431048011243646
Trained batch 592 in epoch 0, gen_loss = 0.8468620757529949, disc_loss = 0.16428530326468044
Trained batch 593 in epoch 0, gen_loss = 0.8468352127255816, disc_loss = 0.16425295795944303
Trained batch 594 in epoch 0, gen_loss = 0.8465500784020464, disc_loss = 0.16417560082461152
Trained batch 595 in epoch 0, gen_loss = 0.8461914872063087, disc_loss = 0.16415638612558278
Trained batch 596 in epoch 0, gen_loss = 0.8466038965000778, disc_loss = 0.1640990058075593
Trained batch 597 in epoch 0, gen_loss = 0.8463675801869619, disc_loss = 0.16402163470855424
Trained batch 598 in epoch 0, gen_loss = 0.8463187491853965, disc_loss = 0.16387508814230883
Trained batch 599 in epoch 0, gen_loss = 0.8462039764225483, disc_loss = 0.16370256032484273
Trained batch 600 in epoch 0, gen_loss = 0.8461773579509405, disc_loss = 0.1635877232279585
Trained batch 601 in epoch 0, gen_loss = 0.8458840718796087, disc_loss = 0.16355767995552267
Trained batch 602 in epoch 0, gen_loss = 0.8458755732472263, disc_loss = 0.16356987802382825
Trained batch 603 in epoch 0, gen_loss = 0.8454076836736787, disc_loss = 0.16359884761557575
Trained batch 604 in epoch 0, gen_loss = 0.8453142433619696, disc_loss = 0.16352603208612312
Trained batch 605 in epoch 0, gen_loss = 0.8451519684724682, disc_loss = 0.1634474327578747
Trained batch 606 in epoch 0, gen_loss = 0.8449926364068341, disc_loss = 0.16342488993910528
Trained batch 607 in epoch 0, gen_loss = 0.8452772078055301, disc_loss = 0.16367848562750673
Trained batch 608 in epoch 0, gen_loss = 0.8452206099855488, disc_loss = 0.16354529463880266
Trained batch 609 in epoch 0, gen_loss = 0.8447728222999417, disc_loss = 0.16360569227120428
Trained batch 610 in epoch 0, gen_loss = 0.8447665588262624, disc_loss = 0.16360217856880394
Trained batch 611 in epoch 0, gen_loss = 0.8444506580046579, disc_loss = 0.1636384589920198
Trained batch 612 in epoch 0, gen_loss = 0.8439592207139313, disc_loss = 0.16374058719742648
Trained batch 613 in epoch 0, gen_loss = 0.8439134617096438, disc_loss = 0.16367845414115376
Trained batch 614 in epoch 0, gen_loss = 0.8438148957442462, disc_loss = 0.16374112069303912
Trained batch 615 in epoch 0, gen_loss = 0.8435772614335859, disc_loss = 0.16372773953253864
Trained batch 616 in epoch 0, gen_loss = 0.8433270655826, disc_loss = 0.1637192090016275
Trained batch 617 in epoch 0, gen_loss = 0.8434385320225966, disc_loss = 0.16365719624888453
Trained batch 618 in epoch 0, gen_loss = 0.8436828470865628, disc_loss = 0.16349724715993844
Trained batch 619 in epoch 0, gen_loss = 0.8432077583286071, disc_loss = 0.16352909657683584
Trained batch 620 in epoch 0, gen_loss = 0.843309367576467, disc_loss = 0.1634779707911078
Trained batch 621 in epoch 0, gen_loss = 0.8430941325771081, disc_loss = 0.1634811217899635
Trained batch 622 in epoch 0, gen_loss = 0.8428875224643879, disc_loss = 0.16343559002739946
Trained batch 623 in epoch 0, gen_loss = 0.8432954390748189, disc_loss = 0.16342462903449836
Trained batch 624 in epoch 0, gen_loss = 0.8428272299289703, disc_loss = 0.16355879140794277
Trained batch 625 in epoch 0, gen_loss = 0.8431698764189364, disc_loss = 0.16350995785833453
Trained batch 626 in epoch 0, gen_loss = 0.8430939195543955, disc_loss = 0.16347774189185393
Trained batch 627 in epoch 0, gen_loss = 0.8427944804547699, disc_loss = 0.16350980345930927
Trained batch 628 in epoch 0, gen_loss = 0.8428198818845855, disc_loss = 0.16346474990118384
Trained batch 629 in epoch 0, gen_loss = 0.8424297482721389, disc_loss = 0.16344004316876332
Trained batch 630 in epoch 0, gen_loss = 0.8421557776618117, disc_loss = 0.16343589687628432
Trained batch 631 in epoch 0, gen_loss = 0.8422284931227376, disc_loss = 0.16351169089291576
Trained batch 632 in epoch 0, gen_loss = 0.8420353654719077, disc_loss = 0.16340584913783635
Trained batch 633 in epoch 0, gen_loss = 0.842121696575583, disc_loss = 0.16325218087996501
Trained batch 634 in epoch 0, gen_loss = 0.841808419293306, disc_loss = 0.1631512554230418
Trained batch 635 in epoch 0, gen_loss = 0.8417621145739496, disc_loss = 0.16311247038520263
Trained batch 636 in epoch 0, gen_loss = 0.8416538654447911, disc_loss = 0.16290953707131242
Trained batch 637 in epoch 0, gen_loss = 0.8412807853337739, disc_loss = 0.16290326340293343
Trained batch 638 in epoch 0, gen_loss = 0.8418074231099262, disc_loss = 0.16314731940265645
Trained batch 639 in epoch 0, gen_loss = 0.8414748494978994, disc_loss = 0.16320455738750753
Trained batch 640 in epoch 0, gen_loss = 0.8413713544188721, disc_loss = 0.16311107223414686
Trained batch 641 in epoch 0, gen_loss = 0.8411188078725078, disc_loss = 0.1631951141388756
Trained batch 642 in epoch 0, gen_loss = 0.8413880039614801, disc_loss = 0.1632987307254254
Trained batch 643 in epoch 0, gen_loss = 0.8409784592179038, disc_loss = 0.16329213035992862
Trained batch 644 in epoch 0, gen_loss = 0.8406336383764134, disc_loss = 0.16340793693192707
Trained batch 645 in epoch 0, gen_loss = 0.8407789421247625, disc_loss = 0.16350922492208772
Trained batch 646 in epoch 0, gen_loss = 0.840732125032814, disc_loss = 0.1635259310275869
Trained batch 647 in epoch 0, gen_loss = 0.8404098245556708, disc_loss = 0.16355561824618942
Trained batch 648 in epoch 0, gen_loss = 0.840267228189345, disc_loss = 0.16354191542900123
Trained batch 649 in epoch 0, gen_loss = 0.8398811299525775, disc_loss = 0.1636369637428568
Trained batch 650 in epoch 0, gen_loss = 0.8396826526994163, disc_loss = 0.16367723023413056
Trained batch 651 in epoch 0, gen_loss = 0.8393483059080832, disc_loss = 0.16365486366011522
Trained batch 652 in epoch 0, gen_loss = 0.8390441855920584, disc_loss = 0.16365097495934045
Trained batch 653 in epoch 0, gen_loss = 0.8388625812184191, disc_loss = 0.16362874048964238
Trained batch 654 in epoch 0, gen_loss = 0.8387002044506655, disc_loss = 0.16355736713771146
Trained batch 655 in epoch 0, gen_loss = 0.8385705083336045, disc_loss = 0.16350082154442533
Trained batch 656 in epoch 0, gen_loss = 0.8384316479688003, disc_loss = 0.1634347877086706
Trained batch 657 in epoch 0, gen_loss = 0.8382140128536427, disc_loss = 0.16343328212656782
Trained batch 658 in epoch 0, gen_loss = 0.8380555858290069, disc_loss = 0.1634779187719223
Trained batch 659 in epoch 0, gen_loss = 0.8376916512846947, disc_loss = 0.16349203788364927
Trained batch 660 in epoch 0, gen_loss = 0.8378056694898591, disc_loss = 0.16363825517989775
Trained batch 661 in epoch 0, gen_loss = 0.8375028609959381, disc_loss = 0.1636656544669292
Trained batch 662 in epoch 0, gen_loss = 0.837162281368293, disc_loss = 0.16367070121496782
Trained batch 663 in epoch 0, gen_loss = 0.837065299366971, disc_loss = 0.1636980725873082
Trained batch 664 in epoch 0, gen_loss = 0.8367955737096027, disc_loss = 0.16373659736175733
Trained batch 665 in epoch 0, gen_loss = 0.8366024957315342, disc_loss = 0.16376716431856783
Trained batch 666 in epoch 0, gen_loss = 0.8363329888373122, disc_loss = 0.16371703863624243
Trained batch 667 in epoch 0, gen_loss = 0.836117994241015, disc_loss = 0.16362549505938223
Trained batch 668 in epoch 0, gen_loss = 0.8363024300613032, disc_loss = 0.16345466689801091
Trained batch 669 in epoch 0, gen_loss = 0.836219760686604, disc_loss = 0.16332780366012856
Trained batch 670 in epoch 0, gen_loss = 0.8360270149395114, disc_loss = 0.16324122810539207
Trained batch 671 in epoch 0, gen_loss = 0.8356895706217203, disc_loss = 0.16331789428312776
Trained batch 672 in epoch 0, gen_loss = 0.8361968668662066, disc_loss = 0.16353655940566605
Trained batch 673 in epoch 0, gen_loss = 0.8358244755766866, disc_loss = 0.16361721619156683
Trained batch 674 in epoch 0, gen_loss = 0.8355400165363595, disc_loss = 0.16370602290663455
Trained batch 675 in epoch 0, gen_loss = 0.8355256969318587, disc_loss = 0.16382943334873523
Trained batch 676 in epoch 0, gen_loss = 0.8352911706072893, disc_loss = 0.16377444821444273
Trained batch 677 in epoch 0, gen_loss = 0.8351941085406812, disc_loss = 0.16369003261601592
Trained batch 678 in epoch 0, gen_loss = 0.835254716285023, disc_loss = 0.16357759716310188
Trained batch 679 in epoch 0, gen_loss = 0.8352429753278985, disc_loss = 0.1634033151272246
Trained batch 680 in epoch 0, gen_loss = 0.8349190042319977, disc_loss = 0.1634226457876387
Trained batch 681 in epoch 0, gen_loss = 0.8354876949028536, disc_loss = 0.16340556892339697
Trained batch 682 in epoch 0, gen_loss = 0.8358768785418738, disc_loss = 0.16322087737326654
Trained batch 683 in epoch 0, gen_loss = 0.8356365710932608, disc_loss = 0.16326078892091822
Trained batch 684 in epoch 0, gen_loss = 0.8355905353152839, disc_loss = 0.16315829926544298
Trained batch 685 in epoch 0, gen_loss = 0.8355973862958719, disc_loss = 0.16310396941199506
Trained batch 686 in epoch 0, gen_loss = 0.8352817171612508, disc_loss = 0.16306482950358325
Trained batch 687 in epoch 0, gen_loss = 0.8353495671911988, disc_loss = 0.16307469447370793
Trained batch 688 in epoch 0, gen_loss = 0.8350962251208517, disc_loss = 0.16296660913903327
Trained batch 689 in epoch 0, gen_loss = 0.8346720633731373, disc_loss = 0.16307072262347178
Trained batch 690 in epoch 0, gen_loss = 0.8350391350416992, disc_loss = 0.16338934242326428
Trained batch 691 in epoch 0, gen_loss = 0.8347492065129941, disc_loss = 0.16336162193177667
Trained batch 692 in epoch 0, gen_loss = 0.8346331565497069, disc_loss = 0.1633275141442278
Trained batch 693 in epoch 0, gen_loss = 0.8343329277179427, disc_loss = 0.16327446171750853
Trained batch 694 in epoch 0, gen_loss = 0.8345299598553197, disc_loss = 0.16331264688331876
Trained batch 695 in epoch 0, gen_loss = 0.8340973724322073, disc_loss = 0.16341073141733034
Trained batch 696 in epoch 0, gen_loss = 0.834146079365458, disc_loss = 0.16335543234120398
Trained batch 697 in epoch 0, gen_loss = 0.8339754573168249, disc_loss = 0.1633141315422077
Trained batch 698 in epoch 0, gen_loss = 0.833738853619334, disc_loss = 0.1632733319956644
Trained batch 699 in epoch 0, gen_loss = 0.8333995823775019, disc_loss = 0.16320122318342328
Trained batch 700 in epoch 0, gen_loss = 0.8333342619952394, disc_loss = 0.1630953497594799
Trained batch 701 in epoch 0, gen_loss = 0.8336657216491183, disc_loss = 0.16309917550215608
Trained batch 702 in epoch 0, gen_loss = 0.8333818222770989, disc_loss = 0.16316069825519283
Trained batch 703 in epoch 0, gen_loss = 0.8335785552943972, disc_loss = 0.16320890501215632
Trained batch 704 in epoch 0, gen_loss = 0.8335421442562807, disc_loss = 0.16307826256445537
Trained batch 705 in epoch 0, gen_loss = 0.8333137974607371, disc_loss = 0.16300734269456468
Trained batch 706 in epoch 0, gen_loss = 0.8331410530348647, disc_loss = 0.16285139242453234
Trained batch 707 in epoch 0, gen_loss = 0.8329752955985608, disc_loss = 0.1627767237697828
Trained batch 708 in epoch 0, gen_loss = 0.8328620264745398, disc_loss = 0.16264976882894638
Trained batch 709 in epoch 0, gen_loss = 0.8326859035542313, disc_loss = 0.16254101201734492
Trained batch 710 in epoch 0, gen_loss = 0.8325961766615195, disc_loss = 0.16250724106786035
Trained batch 711 in epoch 0, gen_loss = 0.8329741896621967, disc_loss = 0.16235643552794132
Trained batch 712 in epoch 0, gen_loss = 0.8327970304545982, disc_loss = 0.16220652008740047
Trained batch 713 in epoch 0, gen_loss = 0.8326392963069493, disc_loss = 0.16217082731310978
Trained batch 714 in epoch 0, gen_loss = 0.8333284864475677, disc_loss = 0.16268677753949914
Trained batch 715 in epoch 0, gen_loss = 0.8333155167752138, disc_loss = 0.16271238764435803
Trained batch 716 in epoch 0, gen_loss = 0.8330004966325507, disc_loss = 0.1626849724070755
Trained batch 717 in epoch 0, gen_loss = 0.8327176873481373, disc_loss = 0.16270074377765148
Trained batch 718 in epoch 0, gen_loss = 0.8325693499975643, disc_loss = 0.16273696425012074
Trained batch 719 in epoch 0, gen_loss = 0.8324634343799617, disc_loss = 0.16271780854246268
Trained batch 720 in epoch 0, gen_loss = 0.8323968074771468, disc_loss = 0.16262452274137248
Trained batch 721 in epoch 0, gen_loss = 0.832086260752995, disc_loss = 0.1626109227698059
Trained batch 722 in epoch 0, gen_loss = 0.8316825398683219, disc_loss = 0.16272329373921512
Trained batch 723 in epoch 0, gen_loss = 0.8314249195693606, disc_loss = 0.16270584943164038
Trained batch 724 in epoch 0, gen_loss = 0.8313638507497721, disc_loss = 0.1626696807634214
Trained batch 725 in epoch 0, gen_loss = 0.831603092061915, disc_loss = 0.16256299440187116
Trained batch 726 in epoch 0, gen_loss = 0.8312477623170147, disc_loss = 0.1628123027601752
Trained batch 727 in epoch 0, gen_loss = 0.8312750858674337, disc_loss = 0.1627545961470517
Trained batch 728 in epoch 0, gen_loss = 0.8311982003177308, disc_loss = 0.16262993974603498
Trained batch 729 in epoch 0, gen_loss = 0.8317272988492496, disc_loss = 0.16248750368975204
Trained batch 730 in epoch 0, gen_loss = 0.8320341787406749, disc_loss = 0.16230010981486775
Trained batch 731 in epoch 0, gen_loss = 0.8316786740728415, disc_loss = 0.1623101281790989
Trained batch 732 in epoch 0, gen_loss = 0.8318758476398489, disc_loss = 0.16218397378321803
Trained batch 733 in epoch 0, gen_loss = 0.831656721737794, disc_loss = 0.1620761276595802
Trained batch 734 in epoch 0, gen_loss = 0.8314915922628779, disc_loss = 0.16202474262083874
Trained batch 735 in epoch 0, gen_loss = 0.8315430456448508, disc_loss = 0.16191604256923514
Trained batch 736 in epoch 0, gen_loss = 0.8314201792593403, disc_loss = 0.16177532479439938
Trained batch 737 in epoch 0, gen_loss = 0.8312235964426826, disc_loss = 0.1616565876824625
Trained batch 738 in epoch 0, gen_loss = 0.831742600473564, disc_loss = 0.16168946152016098
Trained batch 739 in epoch 0, gen_loss = 0.8314536360872758, disc_loss = 0.16175826293844225
Trained batch 740 in epoch 0, gen_loss = 0.8317109633151658, disc_loss = 0.16163476721689043
Trained batch 741 in epoch 0, gen_loss = 0.8317438950837461, disc_loss = 0.16154080546257713
Trained batch 742 in epoch 0, gen_loss = 0.8318070316459096, disc_loss = 0.16155398717528638
Trained batch 743 in epoch 0, gen_loss = 0.8319130676488081, disc_loss = 0.16142979801271953
Trained batch 744 in epoch 0, gen_loss = 0.8320001836191088, disc_loss = 0.16126187380978324
Trained batch 745 in epoch 0, gen_loss = 0.8320388182318562, disc_loss = 0.1610968344377968
Trained batch 746 in epoch 0, gen_loss = 0.8319278116446422, disc_loss = 0.16098749342622606
Trained batch 747 in epoch 0, gen_loss = 0.8318578255447474, disc_loss = 0.16082441072940906
Trained batch 748 in epoch 0, gen_loss = 0.8316511639526912, disc_loss = 0.16084486243373483
Trained batch 749 in epoch 0, gen_loss = 0.8319591799974442, disc_loss = 0.16134032969921827
Trained batch 750 in epoch 0, gen_loss = 0.8319483391851306, disc_loss = 0.16130147984725102
Trained batch 751 in epoch 0, gen_loss = 0.8315210116908271, disc_loss = 0.1613506546090456
Trained batch 752 in epoch 0, gen_loss = 0.8315081349011278, disc_loss = 0.16129651845025905
Trained batch 753 in epoch 0, gen_loss = 0.831477288818802, disc_loss = 0.16130952571891743
Trained batch 754 in epoch 0, gen_loss = 0.831229535909678, disc_loss = 0.16119708860206683
Trained batch 755 in epoch 0, gen_loss = 0.8309039171962511, disc_loss = 0.16122230953689684
Trained batch 756 in epoch 0, gen_loss = 0.8309226257719169, disc_loss = 0.16125286884527146
Trained batch 757 in epoch 0, gen_loss = 0.8307162315282469, disc_loss = 0.16132959858379217
Trained batch 758 in epoch 0, gen_loss = 0.8306043108382872, disc_loss = 0.16131375711632104
Trained batch 759 in epoch 0, gen_loss = 0.830482965982274, disc_loss = 0.1613800459320804
Trained batch 760 in epoch 0, gen_loss = 0.8301543598497744, disc_loss = 0.16159137879080981
Trained batch 761 in epoch 0, gen_loss = 0.8301292591755158, disc_loss = 0.1616873575638481
Trained batch 762 in epoch 0, gen_loss = 0.8300556562753055, disc_loss = 0.16166913489106832
Trained batch 763 in epoch 0, gen_loss = 0.8296860140889727, disc_loss = 0.16171190629503568
Trained batch 764 in epoch 0, gen_loss = 0.8295575351107354, disc_loss = 0.1617573014783119
Trained batch 765 in epoch 0, gen_loss = 0.8294858935996695, disc_loss = 0.16172847341668278
Trained batch 766 in epoch 0, gen_loss = 0.8292558757780117, disc_loss = 0.16163063734390978
Trained batch 767 in epoch 0, gen_loss = 0.8291275229227418, disc_loss = 0.16157438902155263
Trained batch 768 in epoch 0, gen_loss = 0.828892006636906, disc_loss = 0.16156811056166925
Trained batch 769 in epoch 0, gen_loss = 0.8287576667287133, disc_loss = 0.1614988661939641
Trained batch 770 in epoch 0, gen_loss = 0.8283919871781122, disc_loss = 0.1614809520518463
Trained batch 771 in epoch 0, gen_loss = 0.82829567423293, disc_loss = 0.16142291711025675
Trained batch 772 in epoch 0, gen_loss = 0.8284032689877346, disc_loss = 0.16126644788948485
Trained batch 773 in epoch 0, gen_loss = 0.8281546431841468, disc_loss = 0.16118026765674662
Trained batch 774 in epoch 0, gen_loss = 0.8281701591322499, disc_loss = 0.16106873973963723
Trained batch 775 in epoch 0, gen_loss = 0.8281649692540931, disc_loss = 0.16102604333973808
Trained batch 776 in epoch 0, gen_loss = 0.8281921809934741, disc_loss = 0.16101214362780636
Trained batch 777 in epoch 0, gen_loss = 0.8278863803509882, disc_loss = 0.16097077219998393
Trained batch 778 in epoch 0, gen_loss = 0.8277764811212811, disc_loss = 0.16084280484075036
Trained batch 779 in epoch 0, gen_loss = 0.827607147472027, disc_loss = 0.16077146558091043
Trained batch 780 in epoch 0, gen_loss = 0.8278775368930436, disc_loss = 0.160596149917525
Trained batch 781 in epoch 0, gen_loss = 0.8279924488357265, disc_loss = 0.1604113824132001
Trained batch 782 in epoch 0, gen_loss = 0.827948403503094, disc_loss = 0.16029113731888214
Trained batch 783 in epoch 0, gen_loss = 0.8280315524233239, disc_loss = 0.16016373670260822
Trained batch 784 in epoch 0, gen_loss = 0.82828405985407, disc_loss = 0.16003035678035893
Trained batch 785 in epoch 0, gen_loss = 0.8281582074083444, disc_loss = 0.15993496954782319
Trained batch 786 in epoch 0, gen_loss = 0.8281046970448015, disc_loss = 0.15980395694586344
Trained batch 787 in epoch 0, gen_loss = 0.8282444757329026, disc_loss = 0.15965163911962268
Trained batch 788 in epoch 0, gen_loss = 0.828153145215055, disc_loss = 0.15953541673597124
Trained batch 789 in epoch 0, gen_loss = 0.8279928265870372, disc_loss = 0.15958439137173605
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.9570021629333496, disc_loss = 0.12790817022323608
Trained batch 1 in epoch 1, gen_loss = 1.08392995595932, disc_loss = 0.08939318731427193
Trained batch 2 in epoch 1, gen_loss = 1.0723158915837605, disc_loss = 0.07228292648990949
Trained batch 3 in epoch 1, gen_loss = 1.0282487571239471, disc_loss = 0.0615944555029273
Trained batch 4 in epoch 1, gen_loss = 0.9888579487800598, disc_loss = 0.05259893238544464
Trained batch 5 in epoch 1, gen_loss = 0.9833318491776785, disc_loss = 0.04657761100679636
Trained batch 6 in epoch 1, gen_loss = 0.9657489316804069, disc_loss = 0.043851577543786595
Trained batch 7 in epoch 1, gen_loss = 0.9463253244757652, disc_loss = 0.04043689160607755
Trained batch 8 in epoch 1, gen_loss = 0.9261961049503751, disc_loss = 0.03953647344476647
Trained batch 9 in epoch 1, gen_loss = 0.920580142736435, disc_loss = 0.03821434024721384
Trained batch 10 in epoch 1, gen_loss = 0.9452322125434875, disc_loss = 0.038186408071355385
Trained batch 11 in epoch 1, gen_loss = 0.9452971468369166, disc_loss = 0.03649301594123244
Trained batch 12 in epoch 1, gen_loss = 0.9376452106695908, disc_loss = 0.03570691524789883
Trained batch 13 in epoch 1, gen_loss = 0.938421219587326, disc_loss = 0.03467458965522902
Trained batch 14 in epoch 1, gen_loss = 0.9197522044181824, disc_loss = 0.03895575106143952
Trained batch 15 in epoch 1, gen_loss = 0.9368507750332355, disc_loss = 0.06934480648487806
Trained batch 16 in epoch 1, gen_loss = 0.9314949968281914, disc_loss = 0.075138319941128
Trained batch 17 in epoch 1, gen_loss = 0.9076911509037018, disc_loss = 0.10124468472268847
Trained batch 18 in epoch 1, gen_loss = 0.9082141581334566, disc_loss = 0.1032591030785912
Trained batch 19 in epoch 1, gen_loss = 0.9084265857934952, disc_loss = 0.104994398355484
Trained batch 20 in epoch 1, gen_loss = 0.8972818283807664, disc_loss = 0.10522142407440004
Trained batch 21 in epoch 1, gen_loss = 0.8820166262713346, disc_loss = 0.10893755744804036
Trained batch 22 in epoch 1, gen_loss = 0.874821108320485, disc_loss = 0.11029929311379143
Trained batch 23 in epoch 1, gen_loss = 0.8705119490623474, disc_loss = 0.11069109632323186
Trained batch 24 in epoch 1, gen_loss = 0.8616862559318542, disc_loss = 0.11031739622354507
Trained batch 25 in epoch 1, gen_loss = 0.8551614078191611, disc_loss = 0.10970559028478769
Trained batch 26 in epoch 1, gen_loss = 0.8547155018205996, disc_loss = 0.1085134791555228
Trained batch 27 in epoch 1, gen_loss = 0.845878358398165, disc_loss = 0.1086843761482409
Trained batch 28 in epoch 1, gen_loss = 0.8343854484886959, disc_loss = 0.11234149105589965
Trained batch 29 in epoch 1, gen_loss = 0.8375174403190613, disc_loss = 0.11548315112789471
Trained batch 30 in epoch 1, gen_loss = 0.8274976880319657, disc_loss = 0.1167091931546888
Trained batch 31 in epoch 1, gen_loss = 0.822815665975213, disc_loss = 0.11780726094730198
Trained batch 32 in epoch 1, gen_loss = 0.8159186388507034, disc_loss = 0.11966561932455409
Trained batch 33 in epoch 1, gen_loss = 0.8128005634335911, disc_loss = 0.11896327598130002
Trained batch 34 in epoch 1, gen_loss = 0.8139461091586522, disc_loss = 0.11796693525144032
Trained batch 35 in epoch 1, gen_loss = 0.8148935851123598, disc_loss = 0.11569426426043113
Trained batch 36 in epoch 1, gen_loss = 0.8091637492179871, disc_loss = 0.11780285080139702
Trained batch 37 in epoch 1, gen_loss = 0.8081533548079038, disc_loss = 0.11807979966856931
Trained batch 38 in epoch 1, gen_loss = 0.8083142821605389, disc_loss = 0.11784830527045788
Trained batch 39 in epoch 1, gen_loss = 0.8040348425507545, disc_loss = 0.12002112669870257
Trained batch 40 in epoch 1, gen_loss = 0.8046240297759452, disc_loss = 0.120845288310836
Trained batch 41 in epoch 1, gen_loss = 0.8109483789829981, disc_loss = 0.1207102309202864
Trained batch 42 in epoch 1, gen_loss = 0.8128835503445115, disc_loss = 0.11833956586413605
Trained batch 43 in epoch 1, gen_loss = 0.8093561543659731, disc_loss = 0.11797531499442729
Trained batch 44 in epoch 1, gen_loss = 0.8069834497239855, disc_loss = 0.11673538196418021
Trained batch 45 in epoch 1, gen_loss = 0.8102468044861503, disc_loss = 0.11651292467570823
Trained batch 46 in epoch 1, gen_loss = 0.8073032967587734, disc_loss = 0.11585529869858255
Trained batch 47 in epoch 1, gen_loss = 0.8036127140124639, disc_loss = 0.11634980382708211
Trained batch 48 in epoch 1, gen_loss = 0.8011903835802662, disc_loss = 0.11590458156198871
Trained batch 49 in epoch 1, gen_loss = 0.8090983128547669, disc_loss = 0.1171553162485361
Trained batch 50 in epoch 1, gen_loss = 0.8108064041418188, disc_loss = 0.11549319392618011
Trained batch 51 in epoch 1, gen_loss = 0.8075791677603354, disc_loss = 0.11642707404322349
Trained batch 52 in epoch 1, gen_loss = 0.8092864425677173, disc_loss = 0.11519491243756043
Trained batch 53 in epoch 1, gen_loss = 0.8131572637293074, disc_loss = 0.11368355023916121
Trained batch 54 in epoch 1, gen_loss = 0.8067660992795771, disc_loss = 0.117038297991861
Trained batch 55 in epoch 1, gen_loss = 0.8065547528011459, disc_loss = 0.11774907986234341
Trained batch 56 in epoch 1, gen_loss = 0.805742877617217, disc_loss = 0.11803373936236951
Trained batch 57 in epoch 1, gen_loss = 0.8036690148813971, disc_loss = 0.11842443800434985
Trained batch 58 in epoch 1, gen_loss = 0.8040295354390549, disc_loss = 0.11934987297755177
Trained batch 59 in epoch 1, gen_loss = 0.8067657858133316, disc_loss = 0.11949913607289393
Trained batch 60 in epoch 1, gen_loss = 0.8100901715091018, disc_loss = 0.11786530637105957
Trained batch 61 in epoch 1, gen_loss = 0.805616085567782, disc_loss = 0.12094052658686714
Trained batch 62 in epoch 1, gen_loss = 0.8048907679224772, disc_loss = 0.12124901956745557
Trained batch 63 in epoch 1, gen_loss = 0.8094232128933072, disc_loss = 0.12221030629007146
Trained batch 64 in epoch 1, gen_loss = 0.8069243403581473, disc_loss = 0.12285337900886169
Trained batch 65 in epoch 1, gen_loss = 0.803968757390976, disc_loss = 0.12354786959335659
Trained batch 66 in epoch 1, gen_loss = 0.8055421825665147, disc_loss = 0.1260535187129654
Trained batch 67 in epoch 1, gen_loss = 0.8037076907999375, disc_loss = 0.12629320883356474
Trained batch 68 in epoch 1, gen_loss = 0.8011018711587657, disc_loss = 0.12635886901314708
Trained batch 69 in epoch 1, gen_loss = 0.8014883381979806, disc_loss = 0.12738140283950738
Trained batch 70 in epoch 1, gen_loss = 0.7990848380075374, disc_loss = 0.12780952952067617
Trained batch 71 in epoch 1, gen_loss = 0.798409041431215, disc_loss = 0.12767625491445264
Trained batch 72 in epoch 1, gen_loss = 0.7985424432035995, disc_loss = 0.12784454772529535
Trained batch 73 in epoch 1, gen_loss = 0.7975918272057095, disc_loss = 0.12672177802872014
Trained batch 74 in epoch 1, gen_loss = 0.7959691596031189, disc_loss = 0.12616688678661983
Trained batch 75 in epoch 1, gen_loss = 0.796125380616439, disc_loss = 0.12515097204595804
Trained batch 76 in epoch 1, gen_loss = 0.7974966145181036, disc_loss = 0.12447177584875714
Trained batch 77 in epoch 1, gen_loss = 0.7977893016277215, disc_loss = 0.12336354707487118
Trained batch 78 in epoch 1, gen_loss = 0.7965815323817579, disc_loss = 0.12328713967264453
Trained batch 79 in epoch 1, gen_loss = 0.8035237357020378, disc_loss = 0.12598400735296308
Trained batch 80 in epoch 1, gen_loss = 0.8073926722561872, disc_loss = 0.12469063975192883
Trained batch 81 in epoch 1, gen_loss = 0.8083792154381915, disc_loss = 0.12365492147098227
Trained batch 82 in epoch 1, gen_loss = 0.8077893652111651, disc_loss = 0.12275026442415743
Trained batch 83 in epoch 1, gen_loss = 0.8068145761887232, disc_loss = 0.1216016203342449
Trained batch 84 in epoch 1, gen_loss = 0.807514422080096, disc_loss = 0.12036655486068305
Trained batch 85 in epoch 1, gen_loss = 0.8054483740828758, disc_loss = 0.11971094166903301
Trained batch 86 in epoch 1, gen_loss = 0.8060373554284546, disc_loss = 0.11886734817305515
Trained batch 87 in epoch 1, gen_loss = 0.8072662610899318, disc_loss = 0.11828708549199457
Trained batch 88 in epoch 1, gen_loss = 0.8073564138305321, disc_loss = 0.11779722071179513
Trained batch 89 in epoch 1, gen_loss = 0.8079482793807984, disc_loss = 0.11695664920326736
Trained batch 90 in epoch 1, gen_loss = 0.8053179049229884, disc_loss = 0.11715516593348194
Trained batch 91 in epoch 1, gen_loss = 0.8018970557528994, disc_loss = 0.11900631676468512
Trained batch 92 in epoch 1, gen_loss = 0.8059660968601062, disc_loss = 0.12164829861653108
Trained batch 93 in epoch 1, gen_loss = 0.8032652535971175, disc_loss = 0.12186477775190105
Trained batch 94 in epoch 1, gen_loss = 0.8020196622923801, disc_loss = 0.12216512449085712
Trained batch 95 in epoch 1, gen_loss = 0.8002108531072736, disc_loss = 0.12351157281470175
Trained batch 96 in epoch 1, gen_loss = 0.8020122816267702, disc_loss = 0.12350780315236333
Trained batch 97 in epoch 1, gen_loss = 0.8003345098422499, disc_loss = 0.12348486169488454
Trained batch 98 in epoch 1, gen_loss = 0.7994333249751968, disc_loss = 0.123836350768353
Trained batch 99 in epoch 1, gen_loss = 0.7989629909396172, disc_loss = 0.1242380397580564
Trained batch 100 in epoch 1, gen_loss = 0.7972919442275963, disc_loss = 0.1240281333390734
Trained batch 101 in epoch 1, gen_loss = 0.7975497499984854, disc_loss = 0.12435413522682354
Trained batch 102 in epoch 1, gen_loss = 0.8002517718134574, disc_loss = 0.12360438688215121
Trained batch 103 in epoch 1, gen_loss = 0.7990998594233623, disc_loss = 0.12325526184688967
Trained batch 104 in epoch 1, gen_loss = 0.800570312284288, disc_loss = 0.12260349834603923
Trained batch 105 in epoch 1, gen_loss = 0.7997231272593984, disc_loss = 0.12224056861662078
Trained batch 106 in epoch 1, gen_loss = 0.8011073801562051, disc_loss = 0.12221451474475527
Trained batch 107 in epoch 1, gen_loss = 0.8001261334176417, disc_loss = 0.12205031295134514
Trained batch 108 in epoch 1, gen_loss = 0.7994398247758183, disc_loss = 0.12154542287350248
Trained batch 109 in epoch 1, gen_loss = 0.8024946199222045, disc_loss = 0.12131558922542766
Trained batch 110 in epoch 1, gen_loss = 0.803076828653748, disc_loss = 0.12050046236464032
Trained batch 111 in epoch 1, gen_loss = 0.8031000678560564, disc_loss = 0.11963669797738216
Trained batch 112 in epoch 1, gen_loss = 0.802381253611725, disc_loss = 0.11927152565161211
Trained batch 113 in epoch 1, gen_loss = 0.8014067963027117, disc_loss = 0.1195789854156605
Trained batch 114 in epoch 1, gen_loss = 0.8018587705881699, disc_loss = 0.11930447909171167
Trained batch 115 in epoch 1, gen_loss = 0.8044092174747894, disc_loss = 0.11845804717199042
Trained batch 116 in epoch 1, gen_loss = 0.8051204179596697, disc_loss = 0.11769464564247009
Trained batch 117 in epoch 1, gen_loss = 0.805671928545176, disc_loss = 0.11687060677588491
Trained batch 118 in epoch 1, gen_loss = 0.8041500241315666, disc_loss = 0.11682657695555386
Trained batch 119 in epoch 1, gen_loss = 0.8063237297038237, disc_loss = 0.11810934008099139
Trained batch 120 in epoch 1, gen_loss = 0.8083192344046821, disc_loss = 0.11730477637188001
Trained batch 121 in epoch 1, gen_loss = 0.8083380898002719, disc_loss = 0.11662675347179174
Trained batch 122 in epoch 1, gen_loss = 0.8090232060692175, disc_loss = 0.11614466175376399
Trained batch 123 in epoch 1, gen_loss = 0.8120369913597261, disc_loss = 0.11570963003642616
Trained batch 124 in epoch 1, gen_loss = 0.8118106071949005, disc_loss = 0.11503650496900082
Trained batch 125 in epoch 1, gen_loss = 0.811342917974033, disc_loss = 0.11437475919309589
Trained batch 126 in epoch 1, gen_loss = 0.8140020025527384, disc_loss = 0.11376834304372627
Trained batch 127 in epoch 1, gen_loss = 0.815028251381591, disc_loss = 0.1130060791329015
Trained batch 128 in epoch 1, gen_loss = 0.8153287729089574, disc_loss = 0.11241193982057793
Trained batch 129 in epoch 1, gen_loss = 0.8158336962644871, disc_loss = 0.11173581290416992
Trained batch 130 in epoch 1, gen_loss = 0.8170959687869968, disc_loss = 0.11110818526842667
Trained batch 131 in epoch 1, gen_loss = 0.8175971930225691, disc_loss = 0.1104168043697648
Trained batch 132 in epoch 1, gen_loss = 0.8177113378406468, disc_loss = 0.10972229091632635
Trained batch 133 in epoch 1, gen_loss = 0.8186893398637203, disc_loss = 0.10899423232385472
Trained batch 134 in epoch 1, gen_loss = 0.8184529991061599, disc_loss = 0.10834758107860883
Trained batch 135 in epoch 1, gen_loss = 0.8195490940090489, disc_loss = 0.10768026342232
Trained batch 136 in epoch 1, gen_loss = 0.818411723323112, disc_loss = 0.10729738807536825
Trained batch 137 in epoch 1, gen_loss = 0.8210847824811935, disc_loss = 0.10681726355645535
Trained batch 138 in epoch 1, gen_loss = 0.8222374202107354, disc_loss = 0.1061587716392476
Trained batch 139 in epoch 1, gen_loss = 0.8227058493665287, disc_loss = 0.10550255430862307
Trained batch 140 in epoch 1, gen_loss = 0.8213565588420164, disc_loss = 0.10636159520041436
Trained batch 141 in epoch 1, gen_loss = 0.8234203728571744, disc_loss = 0.1082334570507978
Trained batch 142 in epoch 1, gen_loss = 0.8234690008880375, disc_loss = 0.10831411007036279
Trained batch 143 in epoch 1, gen_loss = 0.8204766439480914, disc_loss = 0.10939286133119215
Trained batch 144 in epoch 1, gen_loss = 0.819450065390817, disc_loss = 0.10932076970307991
Trained batch 145 in epoch 1, gen_loss = 0.8200153714581712, disc_loss = 0.10981254041041821
Trained batch 146 in epoch 1, gen_loss = 0.8197837769985199, disc_loss = 0.10948127509430558
Trained batch 147 in epoch 1, gen_loss = 0.8204777291094935, disc_loss = 0.10911788551036168
Trained batch 148 in epoch 1, gen_loss = 0.8200144009702157, disc_loss = 0.10861133167757683
Trained batch 149 in epoch 1, gen_loss = 0.8206181099017461, disc_loss = 0.10797154144694408
Trained batch 150 in epoch 1, gen_loss = 0.8189584006931608, disc_loss = 0.10852508529379273
Trained batch 151 in epoch 1, gen_loss = 0.8198458495500841, disc_loss = 0.1092473075014392
Trained batch 152 in epoch 1, gen_loss = 0.8204136259025998, disc_loss = 0.10878581425868998
Trained batch 153 in epoch 1, gen_loss = 0.8188673031407517, disc_loss = 0.10891741121115235
Trained batch 154 in epoch 1, gen_loss = 0.8185321067610095, disc_loss = 0.10928815943339179
Trained batch 155 in epoch 1, gen_loss = 0.817546705978039, disc_loss = 0.10918408559444241
Trained batch 156 in epoch 1, gen_loss = 0.816675232284388, disc_loss = 0.10917757488312615
Trained batch 157 in epoch 1, gen_loss = 0.8169093522467191, disc_loss = 0.10886473377247023
Trained batch 158 in epoch 1, gen_loss = 0.8171253528609965, disc_loss = 0.10861702196581184
Trained batch 159 in epoch 1, gen_loss = 0.8188082681968808, disc_loss = 0.1081026324420236
Trained batch 160 in epoch 1, gen_loss = 0.8201389684810402, disc_loss = 0.10751890714471199
Trained batch 161 in epoch 1, gen_loss = 0.8204224192433887, disc_loss = 0.10696062305942178
Trained batch 162 in epoch 1, gen_loss = 0.820906407811159, disc_loss = 0.10645327937040776
Trained batch 163 in epoch 1, gen_loss = 0.8211969771399731, disc_loss = 0.10586112653609456
Trained batch 164 in epoch 1, gen_loss = 0.8211762390353463, disc_loss = 0.10555674169551242
Trained batch 165 in epoch 1, gen_loss = 0.8207299671618336, disc_loss = 0.10525790364088783
Trained batch 166 in epoch 1, gen_loss = 0.8209182918071747, disc_loss = 0.10495578131811348
Trained batch 167 in epoch 1, gen_loss = 0.8231729384334314, disc_loss = 0.10464945508699332
Trained batch 168 in epoch 1, gen_loss = 0.8237824381808557, disc_loss = 0.1040802166890904
Trained batch 169 in epoch 1, gen_loss = 0.8227401254808202, disc_loss = 0.10440797753741636
Trained batch 170 in epoch 1, gen_loss = 0.8246075212955475, disc_loss = 0.10507386304677753
Trained batch 171 in epoch 1, gen_loss = 0.8230834324346032, disc_loss = 0.10530671347907289
Trained batch 172 in epoch 1, gen_loss = 0.8219025960202851, disc_loss = 0.10554650159434259
Trained batch 173 in epoch 1, gen_loss = 0.8223612892559204, disc_loss = 0.10600874350866539
Trained batch 174 in epoch 1, gen_loss = 0.8211941468715668, disc_loss = 0.10609012489340135
Trained batch 175 in epoch 1, gen_loss = 0.819805723530325, disc_loss = 0.10682486586632546
Trained batch 176 in epoch 1, gen_loss = 0.8201451949817312, disc_loss = 0.10805109408973469
Trained batch 177 in epoch 1, gen_loss = 0.8201947096693382, disc_loss = 0.1080210021843485
Trained batch 178 in epoch 1, gen_loss = 0.8194091151879487, disc_loss = 0.10780404987302739
Trained batch 179 in epoch 1, gen_loss = 0.8173985552456644, disc_loss = 0.10853993740036255
Trained batch 180 in epoch 1, gen_loss = 0.8169212194766787, disc_loss = 0.10873709813027915
Trained batch 181 in epoch 1, gen_loss = 0.8169385622163395, disc_loss = 0.1089965249616448
Trained batch 182 in epoch 1, gen_loss = 0.8162002265453339, disc_loss = 0.10923997402862935
Trained batch 183 in epoch 1, gen_loss = 0.8150355360754158, disc_loss = 0.1093617219771461
Trained batch 184 in epoch 1, gen_loss = 0.813940499763231, disc_loss = 0.10934537758396284
Trained batch 185 in epoch 1, gen_loss = 0.8139951701766701, disc_loss = 0.10923961121889372
Trained batch 186 in epoch 1, gen_loss = 0.814313240070394, disc_loss = 0.10899332696123716
Trained batch 187 in epoch 1, gen_loss = 0.8131891465250481, disc_loss = 0.10944811029339883
Trained batch 188 in epoch 1, gen_loss = 0.8144159432126101, disc_loss = 0.11031172732531867
Trained batch 189 in epoch 1, gen_loss = 0.8137395587406661, disc_loss = 0.11044808952137827
Trained batch 190 in epoch 1, gen_loss = 0.813056541206949, disc_loss = 0.1102877086496556
Trained batch 191 in epoch 1, gen_loss = 0.8111755625965694, disc_loss = 0.11121446146959595
Trained batch 192 in epoch 1, gen_loss = 0.8113640977619844, disc_loss = 0.11163693292481448
Trained batch 193 in epoch 1, gen_loss = 0.8113041113025135, disc_loss = 0.11187841901171607
Trained batch 194 in epoch 1, gen_loss = 0.8100657840569814, disc_loss = 0.11229492254459705
Trained batch 195 in epoch 1, gen_loss = 0.8099181194390569, disc_loss = 0.11227453979473485
Trained batch 196 in epoch 1, gen_loss = 0.8093077472321273, disc_loss = 0.11238088273930216
Trained batch 197 in epoch 1, gen_loss = 0.8086642154840508, disc_loss = 0.11226521865605857
Trained batch 198 in epoch 1, gen_loss = 0.8092609390841058, disc_loss = 0.11239365593591077
Trained batch 199 in epoch 1, gen_loss = 0.8081159110367299, disc_loss = 0.1128436827333644
Trained batch 200 in epoch 1, gen_loss = 0.80736167499082, disc_loss = 0.11291155734780564
Trained batch 201 in epoch 1, gen_loss = 0.807763315515943, disc_loss = 0.11322214901170666
Trained batch 202 in epoch 1, gen_loss = 0.8072587438111235, disc_loss = 0.11315217133831655
Trained batch 203 in epoch 1, gen_loss = 0.8061294939880278, disc_loss = 0.11335447047581422
Trained batch 204 in epoch 1, gen_loss = 0.8060776185698626, disc_loss = 0.11322776185030617
Trained batch 205 in epoch 1, gen_loss = 0.8060808449404911, disc_loss = 0.11354850359640799
Trained batch 206 in epoch 1, gen_loss = 0.8059934926205787, disc_loss = 0.11339834250131811
Trained batch 207 in epoch 1, gen_loss = 0.8047872788917559, disc_loss = 0.1135222319056853
Trained batch 208 in epoch 1, gen_loss = 0.8047878988907098, disc_loss = 0.11357919205621812
Trained batch 209 in epoch 1, gen_loss = 0.8047988382123765, disc_loss = 0.11330385045370175
Trained batch 210 in epoch 1, gen_loss = 0.8038018785099282, disc_loss = 0.1131805843271986
Trained batch 211 in epoch 1, gen_loss = 0.8030238012379071, disc_loss = 0.11325298510228266
Trained batch 212 in epoch 1, gen_loss = 0.8038015571278585, disc_loss = 0.1135832901055894
Trained batch 213 in epoch 1, gen_loss = 0.8032337425746651, disc_loss = 0.11361300507038136
Trained batch 214 in epoch 1, gen_loss = 0.802125165490217, disc_loss = 0.11408845581720735
Trained batch 215 in epoch 1, gen_loss = 0.8013550223851645, disc_loss = 0.11421746878315592
Trained batch 216 in epoch 1, gen_loss = 0.8016151902587733, disc_loss = 0.11425969743251388
Trained batch 217 in epoch 1, gen_loss = 0.8015661273800999, disc_loss = 0.11455403976227849
Trained batch 218 in epoch 1, gen_loss = 0.8019765690309272, disc_loss = 0.11424240395511802
Trained batch 219 in epoch 1, gen_loss = 0.8013415579091419, disc_loss = 0.11401811743747782
Trained batch 220 in epoch 1, gen_loss = 0.800173785756616, disc_loss = 0.11444367785681023
Trained batch 221 in epoch 1, gen_loss = 0.8005657908884255, disc_loss = 0.11475839298470197
Trained batch 222 in epoch 1, gen_loss = 0.8005256477760092, disc_loss = 0.11457791072922036
Trained batch 223 in epoch 1, gen_loss = 0.8002721375918814, disc_loss = 0.1144515347176431
Trained batch 224 in epoch 1, gen_loss = 0.7993174787362417, disc_loss = 0.11462036543836196
Trained batch 225 in epoch 1, gen_loss = 0.7996460382653549, disc_loss = 0.11513682165125434
Trained batch 226 in epoch 1, gen_loss = 0.799497961341547, disc_loss = 0.11487259689948238
Trained batch 227 in epoch 1, gen_loss = 0.7985894066984194, disc_loss = 0.1148956415790803
Trained batch 228 in epoch 1, gen_loss = 0.7995508408182053, disc_loss = 0.11498420874641062
Trained batch 229 in epoch 1, gen_loss = 0.7991572580907655, disc_loss = 0.11470085102659852
Trained batch 230 in epoch 1, gen_loss = 0.798807083141236, disc_loss = 0.11441506387754566
Trained batch 231 in epoch 1, gen_loss = 0.7984891429800411, disc_loss = 0.11414268839670795
Trained batch 232 in epoch 1, gen_loss = 0.7980383687009116, disc_loss = 0.11399997315517439
Trained batch 233 in epoch 1, gen_loss = 0.7996564411964172, disc_loss = 0.11392575806866471
Trained batch 234 in epoch 1, gen_loss = 0.7993314133045522, disc_loss = 0.11410820895132233
Trained batch 235 in epoch 1, gen_loss = 0.7997257809265185, disc_loss = 0.11432170803595523
Trained batch 236 in epoch 1, gen_loss = 0.7987287936079854, disc_loss = 0.11480900285694795
Trained batch 237 in epoch 1, gen_loss = 0.7992929577076134, disc_loss = 0.11491963309979364
Trained batch 238 in epoch 1, gen_loss = 0.8005081291727442, disc_loss = 0.11478092669895129
Trained batch 239 in epoch 1, gen_loss = 0.8004082050174475, disc_loss = 0.1145837427310956
Trained batch 240 in epoch 1, gen_loss = 0.8004113323213649, disc_loss = 0.11431257023680878
Trained batch 241 in epoch 1, gen_loss = 0.8002937491521362, disc_loss = 0.1141981431590932
Trained batch 242 in epoch 1, gen_loss = 0.7999775116580995, disc_loss = 0.11412359684046526
Trained batch 243 in epoch 1, gen_loss = 0.8006543234967795, disc_loss = 0.11422734697288299
Trained batch 244 in epoch 1, gen_loss = 0.800494305576597, disc_loss = 0.11386545699241818
Trained batch 245 in epoch 1, gen_loss = 0.8000587572654089, disc_loss = 0.11363586465775119
Trained batch 246 in epoch 1, gen_loss = 0.7995214354895387, disc_loss = 0.11365841012749715
Trained batch 247 in epoch 1, gen_loss = 0.8001548846162134, disc_loss = 0.11372577642736535
Trained batch 248 in epoch 1, gen_loss = 0.8013369813262219, disc_loss = 0.11346329452776646
Trained batch 249 in epoch 1, gen_loss = 0.8015550705194473, disc_loss = 0.11315973592177034
Trained batch 250 in epoch 1, gen_loss = 0.8012201858469215, disc_loss = 0.11300922859371065
Trained batch 251 in epoch 1, gen_loss = 0.8015398523873754, disc_loss = 0.1127615473639693
Trained batch 252 in epoch 1, gen_loss = 0.802618627845063, disc_loss = 0.1126032030401317
Trained batch 253 in epoch 1, gen_loss = 0.8019145749450669, disc_loss = 0.11257828847233822
Trained batch 254 in epoch 1, gen_loss = 0.8025481540782778, disc_loss = 0.11234579933989866
Trained batch 255 in epoch 1, gen_loss = 0.8024080231552944, disc_loss = 0.11208320365767577
Trained batch 256 in epoch 1, gen_loss = 0.8033074171858539, disc_loss = 0.11180466165990798
Trained batch 257 in epoch 1, gen_loss = 0.8035895236471827, disc_loss = 0.11142420244598111
Trained batch 258 in epoch 1, gen_loss = 0.8024321979767567, disc_loss = 0.11165343082607022
Trained batch 259 in epoch 1, gen_loss = 0.8020558940676542, disc_loss = 0.11234081492114525
Trained batch 260 in epoch 1, gen_loss = 0.8021983434642411, disc_loss = 0.11200425506951252
Trained batch 261 in epoch 1, gen_loss = 0.8013145551654218, disc_loss = 0.11195396508253713
Trained batch 262 in epoch 1, gen_loss = 0.8020618883149252, disc_loss = 0.11192764697362714
Trained batch 263 in epoch 1, gen_loss = 0.8016096025028012, disc_loss = 0.11172763249752196
Trained batch 264 in epoch 1, gen_loss = 0.800690325363627, disc_loss = 0.11160249409248243
Trained batch 265 in epoch 1, gen_loss = 0.8000124826243049, disc_loss = 0.11170473720010062
Trained batch 266 in epoch 1, gen_loss = 0.8003968566321256, disc_loss = 0.11181101936860924
Trained batch 267 in epoch 1, gen_loss = 0.800834849588017, disc_loss = 0.11158144467079373
Trained batch 268 in epoch 1, gen_loss = 0.7996589353093427, disc_loss = 0.11195994646298842
Trained batch 269 in epoch 1, gen_loss = 0.799445175241541, disc_loss = 0.11186343452168836
Trained batch 270 in epoch 1, gen_loss = 0.8004979449444591, disc_loss = 0.1119277820238548
Trained batch 271 in epoch 1, gen_loss = 0.8007476402117926, disc_loss = 0.11163741825422381
Trained batch 272 in epoch 1, gen_loss = 0.800928675866389, disc_loss = 0.11133839941887191
Trained batch 273 in epoch 1, gen_loss = 0.8013042239812169, disc_loss = 0.11102952580409546
Trained batch 274 in epoch 1, gen_loss = 0.8018492492762479, disc_loss = 0.11075245162980123
Trained batch 275 in epoch 1, gen_loss = 0.8026546889889068, disc_loss = 0.11053548706695437
Trained batch 276 in epoch 1, gen_loss = 0.8017999521231393, disc_loss = 0.11079535105464046
Trained batch 277 in epoch 1, gen_loss = 0.8030419681998465, disc_loss = 0.11090741592640285
Trained batch 278 in epoch 1, gen_loss = 0.8030594649280699, disc_loss = 0.11072556450829497
Trained batch 279 in epoch 1, gen_loss = 0.8022032388619014, disc_loss = 0.11061844549674009
Trained batch 280 in epoch 1, gen_loss = 0.8013579993909788, disc_loss = 0.11068424964953359
Trained batch 281 in epoch 1, gen_loss = 0.8018869019991962, disc_loss = 0.11089662922850103
Trained batch 282 in epoch 1, gen_loss = 0.801587815419524, disc_loss = 0.11103442490969656
Trained batch 283 in epoch 1, gen_loss = 0.8010103459089575, disc_loss = 0.11138841269118055
Trained batch 284 in epoch 1, gen_loss = 0.8008797085076048, disc_loss = 0.11141900117590763
Trained batch 285 in epoch 1, gen_loss = 0.8014455725263049, disc_loss = 0.11125613223448709
Trained batch 286 in epoch 1, gen_loss = 0.8018270967729416, disc_loss = 0.11107333423083045
Trained batch 287 in epoch 1, gen_loss = 0.8007174495400654, disc_loss = 0.11156891750094171
Trained batch 288 in epoch 1, gen_loss = 0.8016683144759141, disc_loss = 0.11144607122923057
Trained batch 289 in epoch 1, gen_loss = 0.8017383769668381, disc_loss = 0.11158558020432448
Trained batch 290 in epoch 1, gen_loss = 0.8007641468465942, disc_loss = 0.11200664889489867
Trained batch 291 in epoch 1, gen_loss = 0.8008088509309782, disc_loss = 0.11204451583453441
Trained batch 292 in epoch 1, gen_loss = 0.8015155392498693, disc_loss = 0.11250857775554111
Trained batch 293 in epoch 1, gen_loss = 0.800756335968063, disc_loss = 0.11259468128511897
Trained batch 294 in epoch 1, gen_loss = 0.8000110047348475, disc_loss = 0.1127544391521458
Trained batch 295 in epoch 1, gen_loss = 0.8000138811767101, disc_loss = 0.1127180339630089
Trained batch 296 in epoch 1, gen_loss = 0.7996402488212393, disc_loss = 0.11309415927965834
Trained batch 297 in epoch 1, gen_loss = 0.7996152934412029, disc_loss = 0.1132750895011845
Trained batch 298 in epoch 1, gen_loss = 0.799072270907686, disc_loss = 0.11326871110269657
Trained batch 299 in epoch 1, gen_loss = 0.7988597308595975, disc_loss = 0.11329354212308923
Trained batch 300 in epoch 1, gen_loss = 0.798350450703472, disc_loss = 0.1134399278182227
Trained batch 301 in epoch 1, gen_loss = 0.7982213656041796, disc_loss = 0.11347630615685357
Trained batch 302 in epoch 1, gen_loss = 0.7995706439608394, disc_loss = 0.1133971863023617
Trained batch 303 in epoch 1, gen_loss = 0.7991423776471301, disc_loss = 0.1133748822612688
Trained batch 304 in epoch 1, gen_loss = 0.7996130975543475, disc_loss = 0.11315837691186881
Trained batch 305 in epoch 1, gen_loss = 0.7997295302308463, disc_loss = 0.11288513220676215
Trained batch 306 in epoch 1, gen_loss = 0.7993508991861188, disc_loss = 0.11270673284822838
Trained batch 307 in epoch 1, gen_loss = 0.7992168110492942, disc_loss = 0.11261748068349121
Trained batch 308 in epoch 1, gen_loss = 0.7991567893514355, disc_loss = 0.11257124075539482
Trained batch 309 in epoch 1, gen_loss = 0.7988575794043079, disc_loss = 0.11246258931895417
Trained batch 310 in epoch 1, gen_loss = 0.7993500668711218, disc_loss = 0.11221807384773658
Trained batch 311 in epoch 1, gen_loss = 0.7992455012714251, disc_loss = 0.1119691389433753
Trained batch 312 in epoch 1, gen_loss = 0.798740452566086, disc_loss = 0.11195393020328813
Trained batch 313 in epoch 1, gen_loss = 0.7988316852385831, disc_loss = 0.11187059811322363
Trained batch 314 in epoch 1, gen_loss = 0.799926974943706, disc_loss = 0.11183708617020222
Trained batch 315 in epoch 1, gen_loss = 0.7995056003520761, disc_loss = 0.11165866123135143
Trained batch 316 in epoch 1, gen_loss = 0.798524731247207, disc_loss = 0.11208257003325957
Trained batch 317 in epoch 1, gen_loss = 0.7987771280719049, disc_loss = 0.11197618528052508
Trained batch 318 in epoch 1, gen_loss = 0.7987916666699054, disc_loss = 0.11230655656222452
Trained batch 319 in epoch 1, gen_loss = 0.7978280865587294, disc_loss = 0.11291564620914869
Trained batch 320 in epoch 1, gen_loss = 0.7972286474481921, disc_loss = 0.11299163745455096
Trained batch 321 in epoch 1, gen_loss = 0.7972567711742768, disc_loss = 0.11335288124124271
Trained batch 322 in epoch 1, gen_loss = 0.7971378770590567, disc_loss = 0.11333976761544637
Trained batch 323 in epoch 1, gen_loss = 0.7969015217673632, disc_loss = 0.11348823418288871
Trained batch 324 in epoch 1, gen_loss = 0.7964982926845551, disc_loss = 0.11338249288499355
Trained batch 325 in epoch 1, gen_loss = 0.7974468015271462, disc_loss = 0.11330508399023417
Trained batch 326 in epoch 1, gen_loss = 0.7967306782893084, disc_loss = 0.11351946164321279
Trained batch 327 in epoch 1, gen_loss = 0.796387381215648, disc_loss = 0.11346112268340842
Trained batch 328 in epoch 1, gen_loss = 0.796135614255279, disc_loss = 0.11355431173506297
Trained batch 329 in epoch 1, gen_loss = 0.7960841979944344, disc_loss = 0.11341247725102938
Trained batch 330 in epoch 1, gen_loss = 0.7958136673600292, disc_loss = 0.11344999700131914
Trained batch 331 in epoch 1, gen_loss = 0.7953600044171494, disc_loss = 0.11371049073423786
Trained batch 332 in epoch 1, gen_loss = 0.7954122265716931, disc_loss = 0.11398734299426859
Trained batch 333 in epoch 1, gen_loss = 0.7963052400036487, disc_loss = 0.11393042691163495
Trained batch 334 in epoch 1, gen_loss = 0.7956526657538627, disc_loss = 0.11412091350266293
Trained batch 335 in epoch 1, gen_loss = 0.7953064297104165, disc_loss = 0.11427997258336593
Trained batch 336 in epoch 1, gen_loss = 0.7953746691125083, disc_loss = 0.11450435191901395
Trained batch 337 in epoch 1, gen_loss = 0.7951234851539488, disc_loss = 0.11509488806811839
Trained batch 338 in epoch 1, gen_loss = 0.795393467740675, disc_loss = 0.11662908985793238
Trained batch 339 in epoch 1, gen_loss = 0.7959461272639387, disc_loss = 0.1176199602017946
Trained batch 340 in epoch 1, gen_loss = 0.7957077728163812, disc_loss = 0.11781283895706327
Trained batch 341 in epoch 1, gen_loss = 0.7956304824665973, disc_loss = 0.1180973053577612
Trained batch 342 in epoch 1, gen_loss = 0.7952383394317794, disc_loss = 0.1182294302611848
Trained batch 343 in epoch 1, gen_loss = 0.7947932364808958, disc_loss = 0.1183788783924091
Trained batch 344 in epoch 1, gen_loss = 0.7945438613926155, disc_loss = 0.11862495620937451
Trained batch 345 in epoch 1, gen_loss = 0.793954718233533, disc_loss = 0.11873301740391234
Trained batch 346 in epoch 1, gen_loss = 0.7937155155524053, disc_loss = 0.11882689957552582
Trained batch 347 in epoch 1, gen_loss = 0.7931461739300312, disc_loss = 0.11900691758177576
Trained batch 348 in epoch 1, gen_loss = 0.7930417953213853, disc_loss = 0.11916119737128986
Trained batch 349 in epoch 1, gen_loss = 0.7923686554602214, disc_loss = 0.11927154597959348
Trained batch 350 in epoch 1, gen_loss = 0.7922397020705405, disc_loss = 0.1191796198052134
Trained batch 351 in epoch 1, gen_loss = 0.7919971076771617, disc_loss = 0.11929014532043683
Trained batch 352 in epoch 1, gen_loss = 0.791688582968104, disc_loss = 0.11953735359477423
Trained batch 353 in epoch 1, gen_loss = 0.7916710626775936, disc_loss = 0.11961501912019179
Trained batch 354 in epoch 1, gen_loss = 0.7915966038133057, disc_loss = 0.11965273681136085
Trained batch 355 in epoch 1, gen_loss = 0.7916197101219317, disc_loss = 0.11951498301657901
Trained batch 356 in epoch 1, gen_loss = 0.7911116685353073, disc_loss = 0.1196019406526947
Trained batch 357 in epoch 1, gen_loss = 0.7908017055115886, disc_loss = 0.11966987503120187
Trained batch 358 in epoch 1, gen_loss = 0.7907110395371748, disc_loss = 0.11990738308840641
Trained batch 359 in epoch 1, gen_loss = 0.7904632913569609, disc_loss = 0.1199117506078134
Trained batch 360 in epoch 1, gen_loss = 0.789861255487907, disc_loss = 0.12003522215106646
Trained batch 361 in epoch 1, gen_loss = 0.7900538148965625, disc_loss = 0.12053870186930038
Trained batch 362 in epoch 1, gen_loss = 0.7898022139203779, disc_loss = 0.12038850356868312
Trained batch 363 in epoch 1, gen_loss = 0.789549066388345, disc_loss = 0.12039404611645656
Trained batch 364 in epoch 1, gen_loss = 0.7891017516181894, disc_loss = 0.12039380791558794
Trained batch 365 in epoch 1, gen_loss = 0.7891311291299883, disc_loss = 0.12046399345631645
Trained batch 366 in epoch 1, gen_loss = 0.78891958730747, disc_loss = 0.12063424349622928
Trained batch 367 in epoch 1, gen_loss = 0.7879872650070034, disc_loss = 0.12091891969169449
Trained batch 368 in epoch 1, gen_loss = 0.7875065904484209, disc_loss = 0.12088233882152452
Trained batch 369 in epoch 1, gen_loss = 0.7871147527082546, disc_loss = 0.1208392232203403
Trained batch 370 in epoch 1, gen_loss = 0.786701682362595, disc_loss = 0.12096677226016946
Trained batch 371 in epoch 1, gen_loss = 0.787131165865288, disc_loss = 0.12123099413590245
Trained batch 372 in epoch 1, gen_loss = 0.786793454322994, disc_loss = 0.12119562979338157
Trained batch 373 in epoch 1, gen_loss = 0.786325752974194, disc_loss = 0.12132202674022173
Trained batch 374 in epoch 1, gen_loss = 0.7859984559218088, disc_loss = 0.12127899332344531
Trained batch 375 in epoch 1, gen_loss = 0.785987091429056, disc_loss = 0.12127521405729683
Trained batch 376 in epoch 1, gen_loss = 0.7860264695133391, disc_loss = 0.12125685433078982
Trained batch 377 in epoch 1, gen_loss = 0.785610913836136, disc_loss = 0.1214925416710752
Trained batch 378 in epoch 1, gen_loss = 0.7858784430731569, disc_loss = 0.12163216588738568
Trained batch 379 in epoch 1, gen_loss = 0.7855679890827129, disc_loss = 0.12164382492927345
Trained batch 380 in epoch 1, gen_loss = 0.7858354550177656, disc_loss = 0.12163732337259402
Trained batch 381 in epoch 1, gen_loss = 0.7852987888127722, disc_loss = 0.12164930450725149
Trained batch 382 in epoch 1, gen_loss = 0.7852024063273447, disc_loss = 0.12163514742632603
Trained batch 383 in epoch 1, gen_loss = 0.7856947934099784, disc_loss = 0.1216082034467642
Trained batch 384 in epoch 1, gen_loss = 0.7853246505384321, disc_loss = 0.1219265875249327
Trained batch 385 in epoch 1, gen_loss = 0.7854943969552381, disc_loss = 0.12211245434947428
Trained batch 386 in epoch 1, gen_loss = 0.7849862787304615, disc_loss = 0.12219322168145531
Trained batch 387 in epoch 1, gen_loss = 0.784947726453088, disc_loss = 0.12222966653074033
Trained batch 388 in epoch 1, gen_loss = 0.7852777404313223, disc_loss = 0.12203182317891127
Trained batch 389 in epoch 1, gen_loss = 0.7850253154834111, disc_loss = 0.12183959567680573
Trained batch 390 in epoch 1, gen_loss = 0.7847149750918073, disc_loss = 0.12179960835906094
Trained batch 391 in epoch 1, gen_loss = 0.784785695145933, disc_loss = 0.12178778199345938
Trained batch 392 in epoch 1, gen_loss = 0.784080321021359, disc_loss = 0.12203271360475447
Trained batch 393 in epoch 1, gen_loss = 0.7840923725197158, disc_loss = 0.12188229671570704
Trained batch 394 in epoch 1, gen_loss = 0.7838588949245743, disc_loss = 0.1218880341730163
Trained batch 395 in epoch 1, gen_loss = 0.7840202157997122, disc_loss = 0.12179449527533819
Trained batch 396 in epoch 1, gen_loss = 0.7837139721631403, disc_loss = 0.12177722350757579
Trained batch 397 in epoch 1, gen_loss = 0.7835922000845473, disc_loss = 0.12165784638786885
Trained batch 398 in epoch 1, gen_loss = 0.7835404352287302, disc_loss = 0.12153252975590396
Trained batch 399 in epoch 1, gen_loss = 0.7832794120162725, disc_loss = 0.12149895097594708
Trained batch 400 in epoch 1, gen_loss = 0.7833440154419278, disc_loss = 0.12154001149434847
Trained batch 401 in epoch 1, gen_loss = 0.7840694037094638, disc_loss = 0.12162373844645362
Trained batch 402 in epoch 1, gen_loss = 0.7834655638811902, disc_loss = 0.12178446832702267
Trained batch 403 in epoch 1, gen_loss = 0.7830628113138793, disc_loss = 0.12183814174449532
Trained batch 404 in epoch 1, gen_loss = 0.7832146512873379, disc_loss = 0.12204659613838166
Trained batch 405 in epoch 1, gen_loss = 0.7830742428015018, disc_loss = 0.12186725015105138
Trained batch 406 in epoch 1, gen_loss = 0.7826633770430703, disc_loss = 0.12192019266911601
Trained batch 407 in epoch 1, gen_loss = 0.7826591630046275, disc_loss = 0.12184001711270243
Trained batch 408 in epoch 1, gen_loss = 0.7819809178414147, disc_loss = 0.12187379286658648
Trained batch 409 in epoch 1, gen_loss = 0.7816514527652322, disc_loss = 0.12174040145899465
Trained batch 410 in epoch 1, gen_loss = 0.7821392117480582, disc_loss = 0.12179828387596746
Trained batch 411 in epoch 1, gen_loss = 0.7820478202503862, disc_loss = 0.12166531334712523
Trained batch 412 in epoch 1, gen_loss = 0.7817379225397225, disc_loss = 0.1217828574240857
Trained batch 413 in epoch 1, gen_loss = 0.7821685450808438, disc_loss = 0.12201468197961793
Trained batch 414 in epoch 1, gen_loss = 0.7823363031967576, disc_loss = 0.12183629189539387
Trained batch 415 in epoch 1, gen_loss = 0.7817967488931922, disc_loss = 0.12239990513682222
Trained batch 416 in epoch 1, gen_loss = 0.7815610934361565, disc_loss = 0.12236553124583167
Trained batch 417 in epoch 1, gen_loss = 0.7816050094708301, disc_loss = 0.12232773003734328
Trained batch 418 in epoch 1, gen_loss = 0.7816392992020791, disc_loss = 0.12224022120788587
Trained batch 419 in epoch 1, gen_loss = 0.7813161890421595, disc_loss = 0.12235496669919008
Trained batch 420 in epoch 1, gen_loss = 0.7812622116608744, disc_loss = 0.12237029851385504
Trained batch 421 in epoch 1, gen_loss = 0.7813725308360646, disc_loss = 0.1224241362072492
Trained batch 422 in epoch 1, gen_loss = 0.7811052721020177, disc_loss = 0.12242719354482266
Trained batch 423 in epoch 1, gen_loss = 0.7812404818832874, disc_loss = 0.12241450977898291
Trained batch 424 in epoch 1, gen_loss = 0.7808653731205885, disc_loss = 0.12248312476365006
Trained batch 425 in epoch 1, gen_loss = 0.7809884045185618, disc_loss = 0.12230690659194345
Trained batch 426 in epoch 1, gen_loss = 0.7815944964908046, disc_loss = 0.12221372891348335
Trained batch 427 in epoch 1, gen_loss = 0.7812890294138516, disc_loss = 0.12206800914343412
Trained batch 428 in epoch 1, gen_loss = 0.7816889236718069, disc_loss = 0.12189156109237032
Trained batch 429 in epoch 1, gen_loss = 0.7814075459574544, disc_loss = 0.12191519741142212
Trained batch 430 in epoch 1, gen_loss = 0.7817358289544931, disc_loss = 0.12180437806673919
Trained batch 431 in epoch 1, gen_loss = 0.781967929047015, disc_loss = 0.12159729990849479
Trained batch 432 in epoch 1, gen_loss = 0.7816567354196764, disc_loss = 0.12143277552830567
Trained batch 433 in epoch 1, gen_loss = 0.7822743856824488, disc_loss = 0.12131645257932387
Trained batch 434 in epoch 1, gen_loss = 0.7821491638134266, disc_loss = 0.12116291382960205
Trained batch 435 in epoch 1, gen_loss = 0.7826488665347799, disc_loss = 0.12094093854496375
Trained batch 436 in epoch 1, gen_loss = 0.7835564558102283, disc_loss = 0.12072101751133561
Trained batch 437 in epoch 1, gen_loss = 0.784320307036513, disc_loss = 0.12052682496301115
Trained batch 438 in epoch 1, gen_loss = 0.7848964374945213, disc_loss = 0.12029692442379128
Trained batch 439 in epoch 1, gen_loss = 0.7852233138274063, disc_loss = 0.1200655110434375
Trained batch 440 in epoch 1, gen_loss = 0.7857671288811431, disc_loss = 0.1198365225027951
Trained batch 441 in epoch 1, gen_loss = 0.7864927589488785, disc_loss = 0.11960051483706449
Trained batch 442 in epoch 1, gen_loss = 0.7872928956157736, disc_loss = 0.11936335681473025
Trained batch 443 in epoch 1, gen_loss = 0.7879849207159635, disc_loss = 0.11912643727594735
Trained batch 444 in epoch 1, gen_loss = 0.7885569349433599, disc_loss = 0.11890368091382003
Trained batch 445 in epoch 1, gen_loss = 0.7894063553868922, disc_loss = 0.11869935909987765
Trained batch 446 in epoch 1, gen_loss = 0.789830977418012, disc_loss = 0.11845409112171972
Trained batch 447 in epoch 1, gen_loss = 0.790301197008895, disc_loss = 0.11820959235774353
Trained batch 448 in epoch 1, gen_loss = 0.7908301820070016, disc_loss = 0.1180369541264722
Trained batch 449 in epoch 1, gen_loss = 0.7914347049262789, disc_loss = 0.11785765349037118
Trained batch 450 in epoch 1, gen_loss = 0.7919185906318233, disc_loss = 0.11762800523205898
Trained batch 451 in epoch 1, gen_loss = 0.792213939657781, disc_loss = 0.1174359600537712
Trained batch 452 in epoch 1, gen_loss = 0.7929426141527315, disc_loss = 0.11722827516496181
Trained batch 453 in epoch 1, gen_loss = 0.7935543167302261, disc_loss = 0.11700633411513157
Trained batch 454 in epoch 1, gen_loss = 0.7941656932071015, disc_loss = 0.11677193028627189
Trained batch 455 in epoch 1, gen_loss = 0.7945517159736993, disc_loss = 0.11653345135824852
Trained batch 456 in epoch 1, gen_loss = 0.7951771158488626, disc_loss = 0.11630441788054138
Trained batch 457 in epoch 1, gen_loss = 0.7958028347080972, disc_loss = 0.11607373870225973
Trained batch 458 in epoch 1, gen_loss = 0.7963477642577718, disc_loss = 0.11585821389080653
Trained batch 459 in epoch 1, gen_loss = 0.7967155524570009, disc_loss = 0.11562106733149646
Trained batch 460 in epoch 1, gen_loss = 0.7972894780935796, disc_loss = 0.1153904902243708
Trained batch 461 in epoch 1, gen_loss = 0.7976276864866158, disc_loss = 0.11516008087941869
Trained batch 462 in epoch 1, gen_loss = 0.7979699745935189, disc_loss = 0.11492513119269235
Trained batch 463 in epoch 1, gen_loss = 0.7984162676308689, disc_loss = 0.11469777929696962
Trained batch 464 in epoch 1, gen_loss = 0.7983149003597998, disc_loss = 0.11456556074341298
Trained batch 465 in epoch 1, gen_loss = 0.7987929437421423, disc_loss = 0.11436756889439735
Trained batch 466 in epoch 1, gen_loss = 0.8000261919529076, disc_loss = 0.11434683926918043
Trained batch 467 in epoch 1, gen_loss = 0.8000317471277001, disc_loss = 0.11418777588520072
Trained batch 468 in epoch 1, gen_loss = 0.8006496318240663, disc_loss = 0.11397718173612569
Trained batch 469 in epoch 1, gen_loss = 0.8008587830244227, disc_loss = 0.11376365711218975
Trained batch 470 in epoch 1, gen_loss = 0.8011108729869697, disc_loss = 0.11357112842139387
Trained batch 471 in epoch 1, gen_loss = 0.8011488364535874, disc_loss = 0.11340688634170536
Trained batch 472 in epoch 1, gen_loss = 0.8012962329337259, disc_loss = 0.11320606852540979
Trained batch 473 in epoch 1, gen_loss = 0.801751098112215, disc_loss = 0.11306679511603895
Trained batch 474 in epoch 1, gen_loss = 0.801134565441232, disc_loss = 0.11299603649169991
Trained batch 475 in epoch 1, gen_loss = 0.8013516435978794, disc_loss = 0.11287891622456651
Trained batch 476 in epoch 1, gen_loss = 0.8013746585361112, disc_loss = 0.11271083371643469
Trained batch 477 in epoch 1, gen_loss = 0.8024792513463288, disc_loss = 0.1125787087125805
Trained batch 478 in epoch 1, gen_loss = 0.8033967029948822, disc_loss = 0.11242991797373258
Trained batch 479 in epoch 1, gen_loss = 0.8038927859937152, disc_loss = 0.11226983409045109
Trained batch 480 in epoch 1, gen_loss = 0.804310001541324, disc_loss = 0.11206109611813188
Trained batch 481 in epoch 1, gen_loss = 0.8043512748361128, disc_loss = 0.11188109593052432
Trained batch 482 in epoch 1, gen_loss = 0.8045185492769285, disc_loss = 0.11168208705862949
Trained batch 483 in epoch 1, gen_loss = 0.8047778918600279, disc_loss = 0.11149436941135613
Trained batch 484 in epoch 1, gen_loss = 0.8051068015319784, disc_loss = 0.11129759719748933
Trained batch 485 in epoch 1, gen_loss = 0.8048933572116702, disc_loss = 0.11118257576848836
Trained batch 486 in epoch 1, gen_loss = 0.8053457481782784, disc_loss = 0.11110111311349628
Trained batch 487 in epoch 1, gen_loss = 0.8050074433816261, disc_loss = 0.11114898271244172
Trained batch 488 in epoch 1, gen_loss = 0.8051454984946729, disc_loss = 0.11134166103561079
Trained batch 489 in epoch 1, gen_loss = 0.8046716991127754, disc_loss = 0.11158854556079878
Trained batch 490 in epoch 1, gen_loss = 0.8044433929405485, disc_loss = 0.11171623939162693
Trained batch 491 in epoch 1, gen_loss = 0.8044729359387383, disc_loss = 0.1117833287528966
Trained batch 492 in epoch 1, gen_loss = 0.8040849200731359, disc_loss = 0.11185297465828412
Trained batch 493 in epoch 1, gen_loss = 0.8035887773582328, disc_loss = 0.1120358754301949
Trained batch 494 in epoch 1, gen_loss = 0.8034992207782438, disc_loss = 0.1122257503812587
Trained batch 495 in epoch 1, gen_loss = 0.8033524563596133, disc_loss = 0.11226633508715989
Trained batch 496 in epoch 1, gen_loss = 0.8030049940589927, disc_loss = 0.11223941355460217
Trained batch 497 in epoch 1, gen_loss = 0.8032309020977901, disc_loss = 0.11214593146276851
Trained batch 498 in epoch 1, gen_loss = 0.803073140626441, disc_loss = 0.11208059131737075
Trained batch 499 in epoch 1, gen_loss = 0.8028600173592567, disc_loss = 0.11209763540979475
Trained batch 500 in epoch 1, gen_loss = 0.802836800942164, disc_loss = 0.11204129330230181
Trained batch 501 in epoch 1, gen_loss = 0.8034869132645102, disc_loss = 0.11195472158042648
Trained batch 502 in epoch 1, gen_loss = 0.803152381248076, disc_loss = 0.11189278682404999
Trained batch 503 in epoch 1, gen_loss = 0.8029554919709289, disc_loss = 0.11197347596697953
Trained batch 504 in epoch 1, gen_loss = 0.8038109248817558, disc_loss = 0.11233574654261518
Trained batch 505 in epoch 1, gen_loss = 0.8035483047542836, disc_loss = 0.11231507435201744
Trained batch 506 in epoch 1, gen_loss = 0.8029151206773649, disc_loss = 0.11236140394171873
Trained batch 507 in epoch 1, gen_loss = 0.8029992092899451, disc_loss = 0.11228154685373938
Trained batch 508 in epoch 1, gen_loss = 0.8032485999035226, disc_loss = 0.11234642220441479
Trained batch 509 in epoch 1, gen_loss = 0.803588830665046, disc_loss = 0.11219086327736139
Trained batch 510 in epoch 1, gen_loss = 0.8033864686517099, disc_loss = 0.11211594234178765
Trained batch 511 in epoch 1, gen_loss = 0.8031609202153049, disc_loss = 0.11204490507134324
Trained batch 512 in epoch 1, gen_loss = 0.8029828136078796, disc_loss = 0.11216888176531442
Trained batch 513 in epoch 1, gen_loss = 0.8026739533425306, disc_loss = 0.11221097069719974
Trained batch 514 in epoch 1, gen_loss = 0.8027294046091802, disc_loss = 0.11242080784303327
Trained batch 515 in epoch 1, gen_loss = 0.8023463878636212, disc_loss = 0.11243578132382746
Trained batch 516 in epoch 1, gen_loss = 0.8021096588910434, disc_loss = 0.11250142187395311
Trained batch 517 in epoch 1, gen_loss = 0.8021615273588872, disc_loss = 0.112511308460126
Trained batch 518 in epoch 1, gen_loss = 0.8028326454305006, disc_loss = 0.11246110360283469
Trained batch 519 in epoch 1, gen_loss = 0.8025916125338811, disc_loss = 0.11248847242498483
Trained batch 520 in epoch 1, gen_loss = 0.8022998088037671, disc_loss = 0.11249162243042791
Trained batch 521 in epoch 1, gen_loss = 0.8026850556390952, disc_loss = 0.11245759401623859
Trained batch 522 in epoch 1, gen_loss = 0.8023804195410434, disc_loss = 0.11246149104362778
Trained batch 523 in epoch 1, gen_loss = 0.8027891718590533, disc_loss = 0.1123734798117093
Trained batch 524 in epoch 1, gen_loss = 0.8030393572648367, disc_loss = 0.11219545965304686
Trained batch 525 in epoch 1, gen_loss = 0.8025123810700138, disc_loss = 0.11264842764842731
Trained batch 526 in epoch 1, gen_loss = 0.8025292714022142, disc_loss = 0.11281338819626019
Trained batch 527 in epoch 1, gen_loss = 0.8024792564524845, disc_loss = 0.11276903716674441
Trained batch 528 in epoch 1, gen_loss = 0.8022456384899486, disc_loss = 0.11273138366537504
Trained batch 529 in epoch 1, gen_loss = 0.8020212945510756, disc_loss = 0.11280993423424661
Trained batch 530 in epoch 1, gen_loss = 0.8022023803657956, disc_loss = 0.11283313165104855
Trained batch 531 in epoch 1, gen_loss = 0.8025651486184364, disc_loss = 0.11284084632709146
Trained batch 532 in epoch 1, gen_loss = 0.8020132218136349, disc_loss = 0.11304740574801476
Trained batch 533 in epoch 1, gen_loss = 0.8018218132105659, disc_loss = 0.11307251135895398
Trained batch 534 in epoch 1, gen_loss = 0.8020423245764224, disc_loss = 0.11318431603069479
Trained batch 535 in epoch 1, gen_loss = 0.8018983466300502, disc_loss = 0.1131680265630234
Trained batch 536 in epoch 1, gen_loss = 0.8015913684163901, disc_loss = 0.11320415994471539
Trained batch 537 in epoch 1, gen_loss = 0.8015547599158765, disc_loss = 0.11325300654455271
Trained batch 538 in epoch 1, gen_loss = 0.8011113241010782, disc_loss = 0.11335638774289354
Trained batch 539 in epoch 1, gen_loss = 0.8009098215787499, disc_loss = 0.11336750096244806
Trained batch 540 in epoch 1, gen_loss = 0.8010150318114903, disc_loss = 0.1133726388551708
Trained batch 541 in epoch 1, gen_loss = 0.8009125060810814, disc_loss = 0.11337952607833673
Trained batch 542 in epoch 1, gen_loss = 0.8012847885571791, disc_loss = 0.11325880988633079
Trained batch 543 in epoch 1, gen_loss = 0.8008135196150226, disc_loss = 0.1132829438215327
Trained batch 544 in epoch 1, gen_loss = 0.8008881577111165, disc_loss = 0.11317983200568535
Trained batch 545 in epoch 1, gen_loss = 0.8011264088717136, disc_loss = 0.11303219108351066
Trained batch 546 in epoch 1, gen_loss = 0.8008155517103032, disc_loss = 0.11306506149399297
Trained batch 547 in epoch 1, gen_loss = 0.8008900674698997, disc_loss = 0.11302248201499537
Trained batch 548 in epoch 1, gen_loss = 0.8007570505685059, disc_loss = 0.11307291231136803
Trained batch 549 in epoch 1, gen_loss = 0.801086987636306, disc_loss = 0.11320217645219104
Trained batch 550 in epoch 1, gen_loss = 0.8009128580833303, disc_loss = 0.11312315091676672
Trained batch 551 in epoch 1, gen_loss = 0.800725877231014, disc_loss = 0.11299962928920201
Trained batch 552 in epoch 1, gen_loss = 0.8004137856943051, disc_loss = 0.11307354468707446
Trained batch 553 in epoch 1, gen_loss = 0.8007940729064632, disc_loss = 0.11324153434979436
Trained batch 554 in epoch 1, gen_loss = 0.8007780364504805, disc_loss = 0.11307908148832015
Trained batch 555 in epoch 1, gen_loss = 0.8004435092317972, disc_loss = 0.11309502186612126
Trained batch 556 in epoch 1, gen_loss = 0.8004672556741019, disc_loss = 0.1130861565997386
Trained batch 557 in epoch 1, gen_loss = 0.8003338361192348, disc_loss = 0.11304285330447539
Trained batch 558 in epoch 1, gen_loss = 0.8006477772336527, disc_loss = 0.11308688923553271
Trained batch 559 in epoch 1, gen_loss = 0.8003261481544801, disc_loss = 0.11321765414489034
Trained batch 560 in epoch 1, gen_loss = 0.8002596658500121, disc_loss = 0.11316853016531908
Trained batch 561 in epoch 1, gen_loss = 0.7998040970216018, disc_loss = 0.11320572029517506
Trained batch 562 in epoch 1, gen_loss = 0.8000137842463769, disc_loss = 0.11320638058369659
Trained batch 563 in epoch 1, gen_loss = 0.7997752582878931, disc_loss = 0.1131655522845091
Trained batch 564 in epoch 1, gen_loss = 0.8000276953245686, disc_loss = 0.1130880604794793
Trained batch 565 in epoch 1, gen_loss = 0.799538125471597, disc_loss = 0.11316840898150138
Trained batch 566 in epoch 1, gen_loss = 0.7994615430869754, disc_loss = 0.11314448415888129
Trained batch 567 in epoch 1, gen_loss = 0.7994632183141271, disc_loss = 0.11311438263797292
Trained batch 568 in epoch 1, gen_loss = 0.7994528702461866, disc_loss = 0.11302824263331629
Trained batch 569 in epoch 1, gen_loss = 0.7992207156461582, disc_loss = 0.1129873105823144
Trained batch 570 in epoch 1, gen_loss = 0.7994227866053373, disc_loss = 0.11303759868551966
Trained batch 571 in epoch 1, gen_loss = 0.7997899807312272, disc_loss = 0.11290270906719997
Trained batch 572 in epoch 1, gen_loss = 0.7995544829605762, disc_loss = 0.11287559629913686
Trained batch 573 in epoch 1, gen_loss = 0.7994656789697421, disc_loss = 0.11285006358671142
Trained batch 574 in epoch 1, gen_loss = 0.7995271374350009, disc_loss = 0.11274307913673312
Trained batch 575 in epoch 1, gen_loss = 0.7998712384141982, disc_loss = 0.1126747767678656
Trained batch 576 in epoch 1, gen_loss = 0.7994676371277721, disc_loss = 0.1128450865999342
Trained batch 577 in epoch 1, gen_loss = 0.7997529035930403, disc_loss = 0.11276154871627199
Trained batch 578 in epoch 1, gen_loss = 0.799721773578713, disc_loss = 0.11279042352663292
Trained batch 579 in epoch 1, gen_loss = 0.7995510376219092, disc_loss = 0.1128113622351646
Trained batch 580 in epoch 1, gen_loss = 0.7997103845909007, disc_loss = 0.11282337784507471
Trained batch 581 in epoch 1, gen_loss = 0.80015862013671, disc_loss = 0.11275934126416919
Trained batch 582 in epoch 1, gen_loss = 0.7997879342497111, disc_loss = 0.11289261031566798
Trained batch 583 in epoch 1, gen_loss = 0.7997152049553721, disc_loss = 0.1127654613268383
Trained batch 584 in epoch 1, gen_loss = 0.8005243724737412, disc_loss = 0.11289860009430693
Trained batch 585 in epoch 1, gen_loss = 0.800273231119426, disc_loss = 0.11283938964882885
Trained batch 586 in epoch 1, gen_loss = 0.8001246477209121, disc_loss = 0.11270520193153259
Trained batch 587 in epoch 1, gen_loss = 0.8002635550235404, disc_loss = 0.11262714959677866
Trained batch 588 in epoch 1, gen_loss = 0.8009265085938426, disc_loss = 0.11249751452726577
Trained batch 589 in epoch 1, gen_loss = 0.8011424461158655, disc_loss = 0.11234549873950496
Trained batch 590 in epoch 1, gen_loss = 0.8009035179356835, disc_loss = 0.11245704528224826
Trained batch 591 in epoch 1, gen_loss = 0.8012365756707417, disc_loss = 0.11248389522252428
Trained batch 592 in epoch 1, gen_loss = 0.8011461335028605, disc_loss = 0.11241201391996436
Trained batch 593 in epoch 1, gen_loss = 0.8011773303401992, disc_loss = 0.11233816538178534
Trained batch 594 in epoch 1, gen_loss = 0.800824830361775, disc_loss = 0.11248561676294237
Trained batch 595 in epoch 1, gen_loss = 0.8012260713133236, disc_loss = 0.11278781326309521
Trained batch 596 in epoch 1, gen_loss = 0.8011025725996475, disc_loss = 0.11274356790857275
Trained batch 597 in epoch 1, gen_loss = 0.8009803602627688, disc_loss = 0.11275354735662282
Trained batch 598 in epoch 1, gen_loss = 0.8006781813795857, disc_loss = 0.1127875363710764
Trained batch 599 in epoch 1, gen_loss = 0.8004613090058168, disc_loss = 0.11278532798324402
Trained batch 600 in epoch 1, gen_loss = 0.8002765912085326, disc_loss = 0.1127376844277435
Trained batch 601 in epoch 1, gen_loss = 0.7998169317494991, disc_loss = 0.11303911917762478
Trained batch 602 in epoch 1, gen_loss = 0.8003523997703001, disc_loss = 0.11317889595243641
Trained batch 603 in epoch 1, gen_loss = 0.8002797163381482, disc_loss = 0.11313880336338296
Trained batch 604 in epoch 1, gen_loss = 0.7999757159347377, disc_loss = 0.113184215340086
Trained batch 605 in epoch 1, gen_loss = 0.8002634783684224, disc_loss = 0.11317836901667856
Trained batch 606 in epoch 1, gen_loss = 0.7998803009016706, disc_loss = 0.11323789255754928
Trained batch 607 in epoch 1, gen_loss = 0.7996855567846644, disc_loss = 0.11333614727711967
Trained batch 608 in epoch 1, gen_loss = 0.7997264341865659, disc_loss = 0.11338914972645871
Trained batch 609 in epoch 1, gen_loss = 0.7998099751648355, disc_loss = 0.113351295512078
Trained batch 610 in epoch 1, gen_loss = 0.7992852733587867, disc_loss = 0.11355306280307387
Trained batch 611 in epoch 1, gen_loss = 0.7993727796315367, disc_loss = 0.11363030564925615
Trained batch 612 in epoch 1, gen_loss = 0.7990470051668208, disc_loss = 0.1135986404938602
Trained batch 613 in epoch 1, gen_loss = 0.7987465391038684, disc_loss = 0.11357129745243014
Trained batch 614 in epoch 1, gen_loss = 0.7988665211006878, disc_loss = 0.11349439890146619
Trained batch 615 in epoch 1, gen_loss = 0.7984186893256454, disc_loss = 0.11353513801866513
Trained batch 616 in epoch 1, gen_loss = 0.7982427967135678, disc_loss = 0.11351331341724898
Trained batch 617 in epoch 1, gen_loss = 0.7980444302547325, disc_loss = 0.1135135741872731
Trained batch 618 in epoch 1, gen_loss = 0.7980687497409364, disc_loss = 0.11346096805671474
Trained batch 619 in epoch 1, gen_loss = 0.798290111028379, disc_loss = 0.11333140065337742
Trained batch 620 in epoch 1, gen_loss = 0.7982047762175881, disc_loss = 0.11327513237971207
Trained batch 621 in epoch 1, gen_loss = 0.7983372937348878, disc_loss = 0.1131608455712904
Trained batch 622 in epoch 1, gen_loss = 0.7981760528171808, disc_loss = 0.11317156716496542
Trained batch 623 in epoch 1, gen_loss = 0.7982432794016905, disc_loss = 0.1130861369795942
Trained batch 624 in epoch 1, gen_loss = 0.7982508506298065, disc_loss = 0.11305890667662025
Trained batch 625 in epoch 1, gen_loss = 0.7977604003855214, disc_loss = 0.11326745309801504
Trained batch 626 in epoch 1, gen_loss = 0.7984380733928802, disc_loss = 0.11339628444746898
Trained batch 627 in epoch 1, gen_loss = 0.7987096300645239, disc_loss = 0.11325220420146895
Trained batch 628 in epoch 1, gen_loss = 0.7987917985275553, disc_loss = 0.11311390318068275
Trained batch 629 in epoch 1, gen_loss = 0.7985310707300428, disc_loss = 0.113108170158895
Trained batch 630 in epoch 1, gen_loss = 0.7985084833792764, disc_loss = 0.11297019689953436
Trained batch 631 in epoch 1, gen_loss = 0.7989466950957533, disc_loss = 0.11301299273787963
Trained batch 632 in epoch 1, gen_loss = 0.7986205426908406, disc_loss = 0.11304783655954363
Trained batch 633 in epoch 1, gen_loss = 0.7985298694214235, disc_loss = 0.11296462961208158
Trained batch 634 in epoch 1, gen_loss = 0.7985216317683693, disc_loss = 0.11295409645137237
Trained batch 635 in epoch 1, gen_loss = 0.7985845867474124, disc_loss = 0.1128303920872123
Trained batch 636 in epoch 1, gen_loss = 0.7991619203210438, disc_loss = 0.11270519220482213
Trained batch 637 in epoch 1, gen_loss = 0.7994683617054482, disc_loss = 0.11255733722742052
Trained batch 638 in epoch 1, gen_loss = 0.7992750632464419, disc_loss = 0.11250487798008724
Trained batch 639 in epoch 1, gen_loss = 0.7995384759735316, disc_loss = 0.1124160150262469
Trained batch 640 in epoch 1, gen_loss = 0.7995272052362445, disc_loss = 0.11233982138913967
Trained batch 641 in epoch 1, gen_loss = 0.7995635025504965, disc_loss = 0.11228885573213136
Trained batch 642 in epoch 1, gen_loss = 0.7997312435002571, disc_loss = 0.11223587488413761
Trained batch 643 in epoch 1, gen_loss = 0.7996997822608266, disc_loss = 0.11214487863956193
Trained batch 644 in epoch 1, gen_loss = 0.7994675428830376, disc_loss = 0.11216983668896001
Trained batch 645 in epoch 1, gen_loss = 0.7996585962849874, disc_loss = 0.1121678107119693
Trained batch 646 in epoch 1, gen_loss = 0.7993719866600066, disc_loss = 0.11211103113034201
Trained batch 647 in epoch 1, gen_loss = 0.7994830905011406, disc_loss = 0.11212294730056008
Trained batch 648 in epoch 1, gen_loss = 0.799337261309058, disc_loss = 0.11209161617134472
Trained batch 649 in epoch 1, gen_loss = 0.7992571546939703, disc_loss = 0.11205050487572757
Trained batch 650 in epoch 1, gen_loss = 0.7996447995053275, disc_loss = 0.11195051199334535
Trained batch 651 in epoch 1, gen_loss = 0.7996194112611694, disc_loss = 0.1118306612411651
Trained batch 652 in epoch 1, gen_loss = 0.799862237062425, disc_loss = 0.11169535669770554
Trained batch 653 in epoch 1, gen_loss = 0.7995026063755017, disc_loss = 0.1118358643148778
Trained batch 654 in epoch 1, gen_loss = 0.8002665013302374, disc_loss = 0.11208480725861118
Trained batch 655 in epoch 1, gen_loss = 0.8001788179958012, disc_loss = 0.11201700003371892
Trained batch 656 in epoch 1, gen_loss = 0.800036354560286, disc_loss = 0.1120842885604494
Trained batch 657 in epoch 1, gen_loss = 0.8001578046648699, disc_loss = 0.11212742272806905
Trained batch 658 in epoch 1, gen_loss = 0.7999802506295611, disc_loss = 0.11221335315794227
Trained batch 659 in epoch 1, gen_loss = 0.7999170251416438, disc_loss = 0.1122385794092252
Trained batch 660 in epoch 1, gen_loss = 0.7998706840440833, disc_loss = 0.11221960151663865
Trained batch 661 in epoch 1, gen_loss = 0.8002716658068567, disc_loss = 0.11233368638292338
Trained batch 662 in epoch 1, gen_loss = 0.7998819980955771, disc_loss = 0.11258034136913278
Trained batch 663 in epoch 1, gen_loss = 0.7999975304736431, disc_loss = 0.1125636919736806
Trained batch 664 in epoch 1, gen_loss = 0.7998247069971902, disc_loss = 0.11256894448744063
Trained batch 665 in epoch 1, gen_loss = 0.8000515006236486, disc_loss = 0.11254169419058249
Trained batch 666 in epoch 1, gen_loss = 0.7998664821016377, disc_loss = 0.1124903326972794
Trained batch 667 in epoch 1, gen_loss = 0.7997119954513933, disc_loss = 0.11248895774308235
Trained batch 668 in epoch 1, gen_loss = 0.7998463283828912, disc_loss = 0.112431996324488
Trained batch 669 in epoch 1, gen_loss = 0.7995838778677271, disc_loss = 0.1124595333467613
Trained batch 670 in epoch 1, gen_loss = 0.7992216444139865, disc_loss = 0.11242293551683581
Trained batch 671 in epoch 1, gen_loss = 0.7997629393690399, disc_loss = 0.11244311531481799
Trained batch 672 in epoch 1, gen_loss = 0.7995989079549798, disc_loss = 0.11242622218646917
Trained batch 673 in epoch 1, gen_loss = 0.799561749358913, disc_loss = 0.11239509318419111
Trained batch 674 in epoch 1, gen_loss = 0.7995799829783263, disc_loss = 0.11239899496996292
Trained batch 675 in epoch 1, gen_loss = 0.7994688451730994, disc_loss = 0.11234841143819861
Trained batch 676 in epoch 1, gen_loss = 0.799348269334748, disc_loss = 0.11243143040161344
Trained batch 677 in epoch 1, gen_loss = 0.7995016824970554, disc_loss = 0.11233007786094945
Trained batch 678 in epoch 1, gen_loss = 0.7990816232469893, disc_loss = 0.11235700783817665
Trained batch 679 in epoch 1, gen_loss = 0.7991033764008213, disc_loss = 0.11228806332835709
Trained batch 680 in epoch 1, gen_loss = 0.7988410856842819, disc_loss = 0.11237334369417833
Trained batch 681 in epoch 1, gen_loss = 0.7992261796315744, disc_loss = 0.11245485329850306
Trained batch 682 in epoch 1, gen_loss = 0.7989688378214661, disc_loss = 0.11244590614484637
Trained batch 683 in epoch 1, gen_loss = 0.7990365763418159, disc_loss = 0.11234978722797827
Trained batch 684 in epoch 1, gen_loss = 0.7989260159704807, disc_loss = 0.11227104923463542
Trained batch 685 in epoch 1, gen_loss = 0.7990813458191758, disc_loss = 0.11217301410253624
Trained batch 686 in epoch 1, gen_loss = 0.7990298662904048, disc_loss = 0.11207740546951106
Trained batch 687 in epoch 1, gen_loss = 0.7987937625324311, disc_loss = 0.11213901909921037
Trained batch 688 in epoch 1, gen_loss = 0.7991430435454032, disc_loss = 0.11232377413771127
Trained batch 689 in epoch 1, gen_loss = 0.7991115119578182, disc_loss = 0.11224070066329686
Trained batch 690 in epoch 1, gen_loss = 0.7988594701855987, disc_loss = 0.11220189860203827
Trained batch 691 in epoch 1, gen_loss = 0.7991760347706045, disc_loss = 0.11221215951679048
Trained batch 692 in epoch 1, gen_loss = 0.7989067658459469, disc_loss = 0.11222082920692335
Trained batch 693 in epoch 1, gen_loss = 0.7989801756329084, disc_loss = 0.11212537381516216
Trained batch 694 in epoch 1, gen_loss = 0.7991098656499986, disc_loss = 0.11207101230020468
Trained batch 695 in epoch 1, gen_loss = 0.7988261794992562, disc_loss = 0.11213603948347335
Trained batch 696 in epoch 1, gen_loss = 0.7987145627160668, disc_loss = 0.11202024222368981
Trained batch 697 in epoch 1, gen_loss = 0.798737232229088, disc_loss = 0.11200235404786694
Trained batch 698 in epoch 1, gen_loss = 0.7986543499604827, disc_loss = 0.11202723579481244
Trained batch 699 in epoch 1, gen_loss = 0.7983960780501366, disc_loss = 0.11213927523033428
Trained batch 700 in epoch 1, gen_loss = 0.7983005406087883, disc_loss = 0.11204424284906067
Trained batch 701 in epoch 1, gen_loss = 0.7985153215648102, disc_loss = 0.11213706539044332
Trained batch 702 in epoch 1, gen_loss = 0.7983128156719642, disc_loss = 0.11209466459049418
Trained batch 703 in epoch 1, gen_loss = 0.7979825180108574, disc_loss = 0.11213544016606068
Trained batch 704 in epoch 1, gen_loss = 0.7981819258936753, disc_loss = 0.11210258935135624
Trained batch 705 in epoch 1, gen_loss = 0.7982532862816586, disc_loss = 0.1120935609905846
Trained batch 706 in epoch 1, gen_loss = 0.7979521029319251, disc_loss = 0.11221094960821042
Trained batch 707 in epoch 1, gen_loss = 0.7979825508207251, disc_loss = 0.11230326551446786
Trained batch 708 in epoch 1, gen_loss = 0.7979914256396515, disc_loss = 0.11232639523617115
Trained batch 709 in epoch 1, gen_loss = 0.7977305605797701, disc_loss = 0.11233388632732692
Trained batch 710 in epoch 1, gen_loss = 0.7976084924532224, disc_loss = 0.11225514034459003
Trained batch 711 in epoch 1, gen_loss = 0.7976021284049146, disc_loss = 0.11219363167994457
Trained batch 712 in epoch 1, gen_loss = 0.7976746684120547, disc_loss = 0.11222779577556177
Trained batch 713 in epoch 1, gen_loss = 0.7976031191125303, disc_loss = 0.11219936431025569
Trained batch 714 in epoch 1, gen_loss = 0.7977842712318981, disc_loss = 0.11208398042481159
Trained batch 715 in epoch 1, gen_loss = 0.7975473887177819, disc_loss = 0.11203497403116595
Trained batch 716 in epoch 1, gen_loss = 0.7977270100322894, disc_loss = 0.11206561711914266
Trained batch 717 in epoch 1, gen_loss = 0.7977019768820499, disc_loss = 0.11199371253586475
Trained batch 718 in epoch 1, gen_loss = 0.7977467791510225, disc_loss = 0.1119079516108649
Trained batch 719 in epoch 1, gen_loss = 0.7976036505152782, disc_loss = 0.11185793315202722
Trained batch 720 in epoch 1, gen_loss = 0.7974385700592882, disc_loss = 0.1118294979166627
Trained batch 721 in epoch 1, gen_loss = 0.7979847544035423, disc_loss = 0.11197949968048802
Trained batch 722 in epoch 1, gen_loss = 0.7973823587759237, disc_loss = 0.11240313423122504
Trained batch 723 in epoch 1, gen_loss = 0.7971406525505181, disc_loss = 0.1124329126243176
Trained batch 724 in epoch 1, gen_loss = 0.7970762614546151, disc_loss = 0.11254816981674783
Trained batch 725 in epoch 1, gen_loss = 0.7970827368008532, disc_loss = 0.1125154206086689
Trained batch 726 in epoch 1, gen_loss = 0.7972025516272575, disc_loss = 0.11248252146712093
Trained batch 727 in epoch 1, gen_loss = 0.7972790038028916, disc_loss = 0.11238938161097774
Trained batch 728 in epoch 1, gen_loss = 0.79718522598714, disc_loss = 0.11237221777845373
Trained batch 729 in epoch 1, gen_loss = 0.7973419719362912, disc_loss = 0.11231686204914258
Trained batch 730 in epoch 1, gen_loss = 0.7974836828770618, disc_loss = 0.11231608019642297
Trained batch 731 in epoch 1, gen_loss = 0.7972590560958686, disc_loss = 0.11231339269360945
Trained batch 732 in epoch 1, gen_loss = 0.7971600626695693, disc_loss = 0.11225231986373439
Trained batch 733 in epoch 1, gen_loss = 0.7973806499947644, disc_loss = 0.11249308308842783
Trained batch 734 in epoch 1, gen_loss = 0.7973406989558214, disc_loss = 0.11245179950215277
Trained batch 735 in epoch 1, gen_loss = 0.797055315307301, disc_loss = 0.11248582248694931
Trained batch 736 in epoch 1, gen_loss = 0.7969980167889692, disc_loss = 0.11246246474970693
Trained batch 737 in epoch 1, gen_loss = 0.7973741611975641, disc_loss = 0.11255259459982134
Trained batch 738 in epoch 1, gen_loss = 0.7970912234708969, disc_loss = 0.11254033635285997
Trained batch 739 in epoch 1, gen_loss = 0.7968525271963429, disc_loss = 0.11256021892941381
Trained batch 740 in epoch 1, gen_loss = 0.796696147053187, disc_loss = 0.11260497277884086
Trained batch 741 in epoch 1, gen_loss = 0.7964623992173177, disc_loss = 0.11262474630236365
Trained batch 742 in epoch 1, gen_loss = 0.7966049897558436, disc_loss = 0.11260338251392481
Trained batch 743 in epoch 1, gen_loss = 0.7965037183415505, disc_loss = 0.11260226882070364
Trained batch 744 in epoch 1, gen_loss = 0.7962570108823328, disc_loss = 0.11259758294866289
Trained batch 745 in epoch 1, gen_loss = 0.7962740131581437, disc_loss = 0.1126103503098986
Trained batch 746 in epoch 1, gen_loss = 0.796211692623026, disc_loss = 0.11256603332525655
Trained batch 747 in epoch 1, gen_loss = 0.7964966229417108, disc_loss = 0.1124680361549873
Trained batch 748 in epoch 1, gen_loss = 0.7966554602570782, disc_loss = 0.11240971997039559
Trained batch 749 in epoch 1, gen_loss = 0.7965448192755381, disc_loss = 0.11241462315556904
Trained batch 750 in epoch 1, gen_loss = 0.7969231022182063, disc_loss = 0.1123265163016849
Trained batch 751 in epoch 1, gen_loss = 0.796678327975121, disc_loss = 0.11228637776691763
Trained batch 752 in epoch 1, gen_loss = 0.7969949785298402, disc_loss = 0.11225675418416402
Trained batch 753 in epoch 1, gen_loss = 0.7969791090773019, disc_loss = 0.11220463923554107
Trained batch 754 in epoch 1, gen_loss = 0.7968377735441095, disc_loss = 0.11221305849277322
Trained batch 755 in epoch 1, gen_loss = 0.797039639776346, disc_loss = 0.11211632966204355
Trained batch 756 in epoch 1, gen_loss = 0.7969662047912769, disc_loss = 0.11205631448694134
Trained batch 757 in epoch 1, gen_loss = 0.7968353224146649, disc_loss = 0.1119862135473914
Trained batch 758 in epoch 1, gen_loss = 0.7969448741559769, disc_loss = 0.11191731459634165
Trained batch 759 in epoch 1, gen_loss = 0.7970298121634283, disc_loss = 0.11180106864592648
Trained batch 760 in epoch 1, gen_loss = 0.796939149870979, disc_loss = 0.11175265791183447
Trained batch 761 in epoch 1, gen_loss = 0.7970104247253398, disc_loss = 0.11176578794835805
Trained batch 762 in epoch 1, gen_loss = 0.7967593719106202, disc_loss = 0.111770452459759
Trained batch 763 in epoch 1, gen_loss = 0.7965971004432408, disc_loss = 0.11171770849111563
Trained batch 764 in epoch 1, gen_loss = 0.797015570737178, disc_loss = 0.11184884676393243
Trained batch 765 in epoch 1, gen_loss = 0.7969528611739684, disc_loss = 0.11180409945136631
Trained batch 766 in epoch 1, gen_loss = 0.7964629868174159, disc_loss = 0.11188704984243157
Trained batch 767 in epoch 1, gen_loss = 0.7970138092059642, disc_loss = 0.11200139559453721
Trained batch 768 in epoch 1, gen_loss = 0.7968218655207997, disc_loss = 0.11198513662704158
Trained batch 769 in epoch 1, gen_loss = 0.7965469664567477, disc_loss = 0.1120734031656878
Trained batch 770 in epoch 1, gen_loss = 0.7966193994350161, disc_loss = 0.11206886683918062
Trained batch 771 in epoch 1, gen_loss = 0.796233129779292, disc_loss = 0.11217767731202138
Trained batch 772 in epoch 1, gen_loss = 0.7963959302507427, disc_loss = 0.11216913276854397
Trained batch 773 in epoch 1, gen_loss = 0.7965157734331234, disc_loss = 0.1121293305718997
Trained batch 774 in epoch 1, gen_loss = 0.7963949079667368, disc_loss = 0.11213618446201566
Trained batch 775 in epoch 1, gen_loss = 0.7962126815595578, disc_loss = 0.11208835695858219
Trained batch 776 in epoch 1, gen_loss = 0.7962813460228526, disc_loss = 0.11201019748084085
Trained batch 777 in epoch 1, gen_loss = 0.7968773094118408, disc_loss = 0.1120558156599566
Trained batch 778 in epoch 1, gen_loss = 0.7970234125049185, disc_loss = 0.11194650295569498
Trained batch 779 in epoch 1, gen_loss = 0.7968107205170851, disc_loss = 0.11192757716963593
Trained batch 780 in epoch 1, gen_loss = 0.7970203843525827, disc_loss = 0.11181674808652525
Trained batch 781 in epoch 1, gen_loss = 0.7971236016744238, disc_loss = 0.1116974521041288
Trained batch 782 in epoch 1, gen_loss = 0.7970877616341543, disc_loss = 0.111641609924102
Trained batch 783 in epoch 1, gen_loss = 0.7971884886525116, disc_loss = 0.11151556324924114
Trained batch 784 in epoch 1, gen_loss = 0.7970859245889506, disc_loss = 0.1114683014779666
Trained batch 785 in epoch 1, gen_loss = 0.7971303623747886, disc_loss = 0.11140078327229896
Trained batch 786 in epoch 1, gen_loss = 0.7970411159486298, disc_loss = 0.1113414667289955
Trained batch 787 in epoch 1, gen_loss = 0.7976431141650011, disc_loss = 0.11132801780039871
Trained batch 788 in epoch 1, gen_loss = 0.798131849980324, disc_loss = 0.11122972432922935
Trained batch 789 in epoch 1, gen_loss = 0.798250560141817, disc_loss = 0.11111078783339243
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.7757542133331299, disc_loss = 0.043647002428770065
Trained batch 1 in epoch 2, gen_loss = 0.7859649658203125, disc_loss = 0.03691379353404045
Trained batch 2 in epoch 2, gen_loss = 0.7804588079452515, disc_loss = 0.0376737043261528
Trained batch 3 in epoch 2, gen_loss = 0.8499307930469513, disc_loss = 0.039022766053676605
Trained batch 4 in epoch 2, gen_loss = 0.8269119739532471, disc_loss = 0.0395301878452301
Trained batch 5 in epoch 2, gen_loss = 0.7923522492249807, disc_loss = 0.04162399905423323
Trained batch 6 in epoch 2, gen_loss = 0.8257214937891278, disc_loss = 0.05196493385093553
Trained batch 7 in epoch 2, gen_loss = 0.8175997287034988, disc_loss = 0.063619629945606
Trained batch 8 in epoch 2, gen_loss = 0.8372590674294366, disc_loss = 0.0666070824695958
Trained batch 9 in epoch 2, gen_loss = 0.8094360649585723, disc_loss = 0.07371751330792904
Trained batch 10 in epoch 2, gen_loss = 0.8083289048888467, disc_loss = 0.06998485529964621
Trained batch 11 in epoch 2, gen_loss = 0.8189297666152319, disc_loss = 0.07072581723332405
Trained batch 12 in epoch 2, gen_loss = 0.8175361294012803, disc_loss = 0.0695426595898775
Trained batch 13 in epoch 2, gen_loss = 0.8125187626906804, disc_loss = 0.06597455737314054
Trained batch 14 in epoch 2, gen_loss = 0.8129256685574849, disc_loss = 0.06318007285396258
Trained batch 15 in epoch 2, gen_loss = 0.8216936029493809, disc_loss = 0.06015584582928568
Trained batch 16 in epoch 2, gen_loss = 0.835577063700732, disc_loss = 0.057364944368600845
Trained batch 17 in epoch 2, gen_loss = 0.8452242977089353, disc_loss = 0.05491417625712024
Trained batch 18 in epoch 2, gen_loss = 0.8606494006357694, disc_loss = 0.05297776517507277
Trained batch 19 in epoch 2, gen_loss = 0.8555387318134308, disc_loss = 0.0542907995171845
Trained batch 20 in epoch 2, gen_loss = 0.859565964766911, disc_loss = 0.05231459962115401
Trained batch 21 in epoch 2, gen_loss = 0.8636936735023152, disc_loss = 0.05168502329086715
Trained batch 22 in epoch 2, gen_loss = 0.8541919589042664, disc_loss = 0.052737522951286774
Trained batch 23 in epoch 2, gen_loss = 0.8598635221521059, disc_loss = 0.05539414620337387
Trained batch 24 in epoch 2, gen_loss = 0.8745385670661926, disc_loss = 0.055512607619166376
Trained batch 25 in epoch 2, gen_loss = 0.8777208351171933, disc_loss = 0.05486472488309328
Trained batch 26 in epoch 2, gen_loss = 0.8728632860713534, disc_loss = 0.055064728069636554
Trained batch 27 in epoch 2, gen_loss = 0.8738160814557757, disc_loss = 0.05361738531584186
Trained batch 28 in epoch 2, gen_loss = 0.877904094498733, disc_loss = 0.05215107874366744
Trained batch 29 in epoch 2, gen_loss = 0.8846377889315288, disc_loss = 0.051174314506351945
Trained batch 30 in epoch 2, gen_loss = 0.8833904266357422, disc_loss = 0.050629904854201505
Trained batch 31 in epoch 2, gen_loss = 0.8803952522575855, disc_loss = 0.049698859569616616
Trained batch 32 in epoch 2, gen_loss = 0.8793521830529878, disc_loss = 0.04849144116495595
Trained batch 33 in epoch 2, gen_loss = 0.8789190649986267, disc_loss = 0.04743556787862497
Trained batch 34 in epoch 2, gen_loss = 0.8828266995293753, disc_loss = 0.046486470928149566
Trained batch 35 in epoch 2, gen_loss = 0.8833538492520651, disc_loss = 0.046029620984983116
Trained batch 36 in epoch 2, gen_loss = 0.8827134741319193, disc_loss = 0.045214114182100106
Trained batch 37 in epoch 2, gen_loss = 0.8802713108690161, disc_loss = 0.04454916502398096
Trained batch 38 in epoch 2, gen_loss = 0.8765814686432863, disc_loss = 0.04523584822145028
Trained batch 39 in epoch 2, gen_loss = 0.8848304197192192, disc_loss = 0.04531820297706872
Trained batch 40 in epoch 2, gen_loss = 0.8894690435107161, disc_loss = 0.044510511249848984
Trained batch 41 in epoch 2, gen_loss = 0.8906541381563459, disc_loss = 0.04374202673456499
Trained batch 42 in epoch 2, gen_loss = 0.8893659114837646, disc_loss = 0.04299419680826886
Trained batch 43 in epoch 2, gen_loss = 0.8919101601297205, disc_loss = 0.042266972616992214
Trained batch 44 in epoch 2, gen_loss = 0.8900475025177002, disc_loss = 0.04185826070606709
Trained batch 45 in epoch 2, gen_loss = 0.8905616752479387, disc_loss = 0.04110015365902497
Trained batch 46 in epoch 2, gen_loss = 0.8910552605669549, disc_loss = 0.04037142412221812
Trained batch 47 in epoch 2, gen_loss = 0.8937291167676449, disc_loss = 0.03970092001448696
Trained batch 48 in epoch 2, gen_loss = 0.8945114150339243, disc_loss = 0.03934251948506856
Trained batch 49 in epoch 2, gen_loss = 0.8930629503726959, disc_loss = 0.03876912152394652
Trained batch 50 in epoch 2, gen_loss = 0.8938242559339485, disc_loss = 0.03814380634210858
Trained batch 51 in epoch 2, gen_loss = 0.8952186233722247, disc_loss = 0.037590837535949856
Trained batch 52 in epoch 2, gen_loss = 0.8960352742447043, disc_loss = 0.03705777681239371
Trained batch 53 in epoch 2, gen_loss = 0.8952581562377788, disc_loss = 0.036556755778966124
Trained batch 54 in epoch 2, gen_loss = 0.895769832350991, disc_loss = 0.03601608432152054
Trained batch 55 in epoch 2, gen_loss = 0.8933749433074679, disc_loss = 0.03565542446449399
Trained batch 56 in epoch 2, gen_loss = 0.8941747222030372, disc_loss = 0.03527730618391121
Trained batch 57 in epoch 2, gen_loss = 0.8923821099873247, disc_loss = 0.03489676204606377
Trained batch 58 in epoch 2, gen_loss = 0.8926325329279495, disc_loss = 0.034886468296586454
Trained batch 59 in epoch 2, gen_loss = 0.8972549478212992, disc_loss = 0.034777179826051
Trained batch 60 in epoch 2, gen_loss = 0.8939508209463025, disc_loss = 0.03525377587094659
Trained batch 61 in epoch 2, gen_loss = 0.8975443311275975, disc_loss = 0.03577161120671418
Trained batch 62 in epoch 2, gen_loss = 0.8967161036673046, disc_loss = 0.03565095347307977
Trained batch 63 in epoch 2, gen_loss = 0.8978063063696027, disc_loss = 0.035338795598363504
Trained batch 64 in epoch 2, gen_loss = 0.8966108872340276, disc_loss = 0.03529451303184032
Trained batch 65 in epoch 2, gen_loss = 0.9031574364864465, disc_loss = 0.03573094757104462
Trained batch 66 in epoch 2, gen_loss = 0.9055435871010395, disc_loss = 0.03573004053488596
Trained batch 67 in epoch 2, gen_loss = 0.9008746173451928, disc_loss = 0.040094081723295594
Trained batch 68 in epoch 2, gen_loss = 0.8999223199443541, disc_loss = 0.04023104973569296
Trained batch 69 in epoch 2, gen_loss = 0.9016454432691846, disc_loss = 0.04148407538554498
Trained batch 70 in epoch 2, gen_loss = 0.8999166765683134, disc_loss = 0.04178845685657481
Trained batch 71 in epoch 2, gen_loss = 0.8958051792449422, disc_loss = 0.04251841137496134
Trained batch 72 in epoch 2, gen_loss = 0.8976920736979132, disc_loss = 0.042375949734490215
Trained batch 73 in epoch 2, gen_loss = 0.8977385960720681, disc_loss = 0.04257145370482593
Trained batch 74 in epoch 2, gen_loss = 0.8993673253059388, disc_loss = 0.04214802914609512
Trained batch 75 in epoch 2, gen_loss = 0.8971539900491112, disc_loss = 0.042094998294487596
Trained batch 76 in epoch 2, gen_loss = 0.8970266100648162, disc_loss = 0.04259581190183178
Trained batch 77 in epoch 2, gen_loss = 0.8930695698811457, disc_loss = 0.04423013352191983
Trained batch 78 in epoch 2, gen_loss = 0.8948323756833619, disc_loss = 0.04600911770204577
Trained batch 79 in epoch 2, gen_loss = 0.8975816547870636, disc_loss = 0.04695063134422526
Trained batch 80 in epoch 2, gen_loss = 0.8939990011262305, disc_loss = 0.0494430839072591
Trained batch 81 in epoch 2, gen_loss = 0.8887582341345345, disc_loss = 0.050897377236496386
Trained batch 82 in epoch 2, gen_loss = 0.8901359094194619, disc_loss = 0.05394920126635985
Trained batch 83 in epoch 2, gen_loss = 0.8891195945796513, disc_loss = 0.054370521024490394
Trained batch 84 in epoch 2, gen_loss = 0.890973851961248, disc_loss = 0.05418368112295866
Trained batch 85 in epoch 2, gen_loss = 0.8907459641611853, disc_loss = 0.054077984667708016
Trained batch 86 in epoch 2, gen_loss = 0.8890009515586941, disc_loss = 0.05389380192748089
Trained batch 87 in epoch 2, gen_loss = 0.8877858302809976, disc_loss = 0.05371133452916348
Trained batch 88 in epoch 2, gen_loss = 0.8859220354744558, disc_loss = 0.0542218822755673
Trained batch 89 in epoch 2, gen_loss = 0.8863203134801653, disc_loss = 0.053949358883417314
Trained batch 90 in epoch 2, gen_loss = 0.8829843696657118, disc_loss = 0.05445564643653867
Trained batch 91 in epoch 2, gen_loss = 0.8844411787779435, disc_loss = 0.05479029200606696
Trained batch 92 in epoch 2, gen_loss = 0.8812196254730225, disc_loss = 0.05663058809655648
Trained batch 93 in epoch 2, gen_loss = 0.8815928989268363, disc_loss = 0.05747359649258408
Trained batch 94 in epoch 2, gen_loss = 0.8798848710562054, disc_loss = 0.058601582118947254
Trained batch 95 in epoch 2, gen_loss = 0.878591800108552, disc_loss = 0.058298727934015915
Trained batch 96 in epoch 2, gen_loss = 0.8762866375372582, disc_loss = 0.05897133725397673
Trained batch 97 in epoch 2, gen_loss = 0.8784308512600101, disc_loss = 0.06090980947815946
Trained batch 98 in epoch 2, gen_loss = 0.8761817548010085, disc_loss = 0.06163087544605286
Trained batch 99 in epoch 2, gen_loss = 0.8714211988449097, disc_loss = 0.06349148479290306
Trained batch 100 in epoch 2, gen_loss = 0.8726052630065692, disc_loss = 0.06594159783297542
Trained batch 101 in epoch 2, gen_loss = 0.8692790871741725, disc_loss = 0.0673140748769191
Trained batch 102 in epoch 2, gen_loss = 0.8686073416645087, disc_loss = 0.06805157542988224
Trained batch 103 in epoch 2, gen_loss = 0.8665045408102182, disc_loss = 0.06875632184808357
Trained batch 104 in epoch 2, gen_loss = 0.8667906420571464, disc_loss = 0.06896122357852402
Trained batch 105 in epoch 2, gen_loss = 0.8636789355637893, disc_loss = 0.0697444795876882
Trained batch 106 in epoch 2, gen_loss = 0.8613819173563306, disc_loss = 0.0700864639115807
Trained batch 107 in epoch 2, gen_loss = 0.8606480172386876, disc_loss = 0.07020722540888798
Trained batch 108 in epoch 2, gen_loss = 0.8590293455561366, disc_loss = 0.07015328974796271
Trained batch 109 in epoch 2, gen_loss = 0.8586744194680994, disc_loss = 0.0710306288589808
Trained batch 110 in epoch 2, gen_loss = 0.8554301678060411, disc_loss = 0.0731822788329409
Trained batch 111 in epoch 2, gen_loss = 0.8541391494550875, disc_loss = 0.07348051019445327
Trained batch 112 in epoch 2, gen_loss = 0.8549456588462391, disc_loss = 0.0746486335086216
Trained batch 113 in epoch 2, gen_loss = 0.8527357376981199, disc_loss = 0.07499909444238272
Trained batch 114 in epoch 2, gen_loss = 0.8503264590449955, disc_loss = 0.07523604778006025
Trained batch 115 in epoch 2, gen_loss = 0.8488555661049383, disc_loss = 0.07544509466769624
Trained batch 116 in epoch 2, gen_loss = 0.8498735873617678, disc_loss = 0.07551360592787337
Trained batch 117 in epoch 2, gen_loss = 0.8516780903278771, disc_loss = 0.0750076476468752
Trained batch 118 in epoch 2, gen_loss = 0.8518654110551882, disc_loss = 0.07450923604593307
Trained batch 119 in epoch 2, gen_loss = 0.8491930745542049, disc_loss = 0.075553649966605
Trained batch 120 in epoch 2, gen_loss = 0.8486576644349689, disc_loss = 0.07562579872656214
Trained batch 121 in epoch 2, gen_loss = 0.8476665252056278, disc_loss = 0.07615081494918367
Trained batch 122 in epoch 2, gen_loss = 0.8465559843594466, disc_loss = 0.07600607146789146
Trained batch 123 in epoch 2, gen_loss = 0.8448042756607456, disc_loss = 0.07609797070073264
Trained batch 124 in epoch 2, gen_loss = 0.8436067659854889, disc_loss = 0.07620679687708616
Trained batch 125 in epoch 2, gen_loss = 0.8444611129779664, disc_loss = 0.07678010467705983
Trained batch 126 in epoch 2, gen_loss = 0.8423746601333768, disc_loss = 0.07705715561916274
Trained batch 127 in epoch 2, gen_loss = 0.8413508755620569, disc_loss = 0.07700135517370654
Trained batch 128 in epoch 2, gen_loss = 0.8416078060634377, disc_loss = 0.07866757096679405
Trained batch 129 in epoch 2, gen_loss = 0.8399891598866536, disc_loss = 0.0790398003318562
Trained batch 130 in epoch 2, gen_loss = 0.8412897552697713, disc_loss = 0.07880097985239203
Trained batch 131 in epoch 2, gen_loss = 0.8422651550535, disc_loss = 0.07869547881383562
Trained batch 132 in epoch 2, gen_loss = 0.8433519931215989, disc_loss = 0.07824474569634163
Trained batch 133 in epoch 2, gen_loss = 0.8436238714563313, disc_loss = 0.0777750370342896
Trained batch 134 in epoch 2, gen_loss = 0.8425162180706307, disc_loss = 0.07801643762461564
Trained batch 135 in epoch 2, gen_loss = 0.8414823011878658, disc_loss = 0.07865820702521459
Trained batch 136 in epoch 2, gen_loss = 0.842002794907911, disc_loss = 0.07844832167709179
Trained batch 137 in epoch 2, gen_loss = 0.8396497543739236, disc_loss = 0.0791425360299215
Trained batch 138 in epoch 2, gen_loss = 0.8391593516730577, disc_loss = 0.07955616324630788
Trained batch 139 in epoch 2, gen_loss = 0.838929320020335, disc_loss = 0.07954617475957743
Trained batch 140 in epoch 2, gen_loss = 0.841210146110954, disc_loss = 0.07925116702095203
Trained batch 141 in epoch 2, gen_loss = 0.8411456604658718, disc_loss = 0.07885331258466335
Trained batch 142 in epoch 2, gen_loss = 0.8391190823558328, disc_loss = 0.0791681929576126
Trained batch 143 in epoch 2, gen_loss = 0.8407974398384491, disc_loss = 0.07944420494216804
Trained batch 144 in epoch 2, gen_loss = 0.8414557060291027, disc_loss = 0.079102279727572
Trained batch 145 in epoch 2, gen_loss = 0.8400251993986025, disc_loss = 0.07901994646080349
Trained batch 146 in epoch 2, gen_loss = 0.838775462642008, disc_loss = 0.07879729043743035
Trained batch 147 in epoch 2, gen_loss = 0.8380356598142031, disc_loss = 0.07864395759974581
Trained batch 148 in epoch 2, gen_loss = 0.8389661042082229, disc_loss = 0.07878336529778754
Trained batch 149 in epoch 2, gen_loss = 0.8398794684807459, disc_loss = 0.07846154622112711
Trained batch 150 in epoch 2, gen_loss = 0.8378827048848007, disc_loss = 0.07861736976227027
Trained batch 151 in epoch 2, gen_loss = 0.8367671748917354, disc_loss = 0.07867426167266738
Trained batch 152 in epoch 2, gen_loss = 0.8382313253443225, disc_loss = 0.07910756471572943
Trained batch 153 in epoch 2, gen_loss = 0.8365811753969687, disc_loss = 0.0798734979667737
Trained batch 154 in epoch 2, gen_loss = 0.8362424329403908, disc_loss = 0.08014941356715656
Trained batch 155 in epoch 2, gen_loss = 0.8364514358914815, disc_loss = 0.08003293371233994
Trained batch 156 in epoch 2, gen_loss = 0.835719397303405, disc_loss = 0.0801115650268402
Trained batch 157 in epoch 2, gen_loss = 0.8359569358297542, disc_loss = 0.0802142289231378
Trained batch 158 in epoch 2, gen_loss = 0.8377663603743667, disc_loss = 0.07989067262706329
Trained batch 159 in epoch 2, gen_loss = 0.837799664773047, disc_loss = 0.07955048137228005
Trained batch 160 in epoch 2, gen_loss = 0.8379296599337773, disc_loss = 0.07924606067400357
Trained batch 161 in epoch 2, gen_loss = 0.8382346742315057, disc_loss = 0.07889199658745417
Trained batch 162 in epoch 2, gen_loss = 0.8375441517932284, disc_loss = 0.0789443903254128
Trained batch 163 in epoch 2, gen_loss = 0.8402164514835287, disc_loss = 0.07921373659585852
Trained batch 164 in epoch 2, gen_loss = 0.839893636378375, disc_loss = 0.07888748577485481
Trained batch 165 in epoch 2, gen_loss = 0.8401359928300581, disc_loss = 0.07850281610882964
Trained batch 166 in epoch 2, gen_loss = 0.840185821234823, disc_loss = 0.0786371414387922
Trained batch 167 in epoch 2, gen_loss = 0.8377556784876755, disc_loss = 0.07966813528799407
Trained batch 168 in epoch 2, gen_loss = 0.8377497913922078, disc_loss = 0.07938389519240553
Trained batch 169 in epoch 2, gen_loss = 0.8377735549912734, disc_loss = 0.07972738746663227
Trained batch 170 in epoch 2, gen_loss = 0.8369426645382106, disc_loss = 0.08004384330468393
Trained batch 171 in epoch 2, gen_loss = 0.8358439978125484, disc_loss = 0.07996896571523054
Trained batch 172 in epoch 2, gen_loss = 0.8349829300635123, disc_loss = 0.08030218182594617
Trained batch 173 in epoch 2, gen_loss = 0.8340734289637928, disc_loss = 0.08032045671288138
Trained batch 174 in epoch 2, gen_loss = 0.8329168808460236, disc_loss = 0.08042615327984094
Trained batch 175 in epoch 2, gen_loss = 0.8332724677906795, disc_loss = 0.08089481158160859
Trained batch 176 in epoch 2, gen_loss = 0.8326502060149349, disc_loss = 0.08114827655276842
Trained batch 177 in epoch 2, gen_loss = 0.8325020317616088, disc_loss = 0.08101335295026055
Trained batch 178 in epoch 2, gen_loss = 0.8334529275001761, disc_loss = 0.0809904975587679
Trained batch 179 in epoch 2, gen_loss = 0.8318533604343732, disc_loss = 0.08127956234643029
Trained batch 180 in epoch 2, gen_loss = 0.8313759036814969, disc_loss = 0.08105478750140463
Trained batch 181 in epoch 2, gen_loss = 0.8332874963244239, disc_loss = 0.08158572203899314
Trained batch 182 in epoch 2, gen_loss = 0.8317058768754448, disc_loss = 0.08223367329239031
Trained batch 183 in epoch 2, gen_loss = 0.8302970714867115, disc_loss = 0.08268973860464504
Trained batch 184 in epoch 2, gen_loss = 0.8303654301810909, disc_loss = 0.08296356464459284
Trained batch 185 in epoch 2, gen_loss = 0.83182832742891, disc_loss = 0.08365030039442323
Trained batch 186 in epoch 2, gen_loss = 0.8301088460945191, disc_loss = 0.08431364665116696
Trained batch 187 in epoch 2, gen_loss = 0.828854889787258, disc_loss = 0.08477213072709422
Trained batch 188 in epoch 2, gen_loss = 0.8291811436887772, disc_loss = 0.08515029141886367
Trained batch 189 in epoch 2, gen_loss = 0.8287490651795738, disc_loss = 0.08541786056502085
Trained batch 190 in epoch 2, gen_loss = 0.8280128872519388, disc_loss = 0.08586578427555518
Trained batch 191 in epoch 2, gen_loss = 0.8277780970868965, disc_loss = 0.08611704880119457
Trained batch 192 in epoch 2, gen_loss = 0.8287083224002562, disc_loss = 0.08598473075043815
Trained batch 193 in epoch 2, gen_loss = 0.8275557705729278, disc_loss = 0.08648679706450436
Trained batch 194 in epoch 2, gen_loss = 0.8268648011562152, disc_loss = 0.08641391986360153
Trained batch 195 in epoch 2, gen_loss = 0.8270534682942896, disc_loss = 0.08657001329072732
Trained batch 196 in epoch 2, gen_loss = 0.8271258462806643, disc_loss = 0.08650912939651212
Trained batch 197 in epoch 2, gen_loss = 0.8251411235994763, disc_loss = 0.08746225678013882
Trained batch 198 in epoch 2, gen_loss = 0.824949953574032, disc_loss = 0.08797028254081107
Trained batch 199 in epoch 2, gen_loss = 0.8243950916826726, disc_loss = 0.08806923584546894
Trained batch 200 in epoch 2, gen_loss = 0.8237443719040695, disc_loss = 0.08843621390579796
Trained batch 201 in epoch 2, gen_loss = 0.8229703296824257, disc_loss = 0.08870355269899315
Trained batch 202 in epoch 2, gen_loss = 0.8235183797152759, disc_loss = 0.08892110850331672
Trained batch 203 in epoch 2, gen_loss = 0.8231985027007028, disc_loss = 0.08899210047835082
Trained batch 204 in epoch 2, gen_loss = 0.8230360055842051, disc_loss = 0.08889410151850159
Trained batch 205 in epoch 2, gen_loss = 0.8220471961116328, disc_loss = 0.08900158506483563
Trained batch 206 in epoch 2, gen_loss = 0.8235442242472644, disc_loss = 0.08906320563027105
Trained batch 207 in epoch 2, gen_loss = 0.822557217369859, disc_loss = 0.08910089460326932
Trained batch 208 in epoch 2, gen_loss = 0.8225278370973597, disc_loss = 0.08930521769867987
Trained batch 209 in epoch 2, gen_loss = 0.8224456856648127, disc_loss = 0.08916489391011141
Trained batch 210 in epoch 2, gen_loss = 0.8216319834169054, disc_loss = 0.08926223851828637
Trained batch 211 in epoch 2, gen_loss = 0.8217439976222111, disc_loss = 0.08923154645423703
Trained batch 212 in epoch 2, gen_loss = 0.8203762701139764, disc_loss = 0.08963172898098756
Trained batch 213 in epoch 2, gen_loss = 0.8203450946885849, disc_loss = 0.0897704979935748
Trained batch 214 in epoch 2, gen_loss = 0.8196632200895354, disc_loss = 0.08980846936532924
Trained batch 215 in epoch 2, gen_loss = 0.8185213634537326, disc_loss = 0.0901898816012329
Trained batch 216 in epoch 2, gen_loss = 0.8188323234358141, disc_loss = 0.08994954836035517
Trained batch 217 in epoch 2, gen_loss = 0.8189563331527447, disc_loss = 0.08986657527659875
Trained batch 218 in epoch 2, gen_loss = 0.8181683974995461, disc_loss = 0.08996809166367059
Trained batch 219 in epoch 2, gen_loss = 0.8180931385267864, disc_loss = 0.09012858432040295
Trained batch 220 in epoch 2, gen_loss = 0.8174704600513251, disc_loss = 0.09003857443555853
Trained batch 221 in epoch 2, gen_loss = 0.8173747437225806, disc_loss = 0.08981513340647022
Trained batch 222 in epoch 2, gen_loss = 0.8179520492863762, disc_loss = 0.08957982729418797
Trained batch 223 in epoch 2, gen_loss = 0.8183983991454754, disc_loss = 0.08930291343131103
Trained batch 224 in epoch 2, gen_loss = 0.8177528727054596, disc_loss = 0.08931520125518243
Trained batch 225 in epoch 2, gen_loss = 0.8187839653903404, disc_loss = 0.08930670431674978
Trained batch 226 in epoch 2, gen_loss = 0.8193240870725741, disc_loss = 0.08897766609171545
Trained batch 227 in epoch 2, gen_loss = 0.8185524133998051, disc_loss = 0.08887670856181598
Trained batch 228 in epoch 2, gen_loss = 0.817811479604921, disc_loss = 0.08899160504227252
Trained batch 229 in epoch 2, gen_loss = 0.8184192772792733, disc_loss = 0.0886906345617836
Trained batch 230 in epoch 2, gen_loss = 0.8192608811896601, disc_loss = 0.08840157290380367
Trained batch 231 in epoch 2, gen_loss = 0.819654777774523, disc_loss = 0.08807248731770007
Trained batch 232 in epoch 2, gen_loss = 0.8191831095280053, disc_loss = 0.08801267229324375
Trained batch 233 in epoch 2, gen_loss = 0.8202357173730166, disc_loss = 0.08824895602913621
Trained batch 234 in epoch 2, gen_loss = 0.8184688366473989, disc_loss = 0.08836243004003104
Trained batch 235 in epoch 2, gen_loss = 0.8193092468684002, disc_loss = 0.08810899778805925
Trained batch 236 in epoch 2, gen_loss = 0.819608117080439, disc_loss = 0.08788330179839572
Trained batch 237 in epoch 2, gen_loss = 0.8199462606375959, disc_loss = 0.08758382987184059
Trained batch 238 in epoch 2, gen_loss = 0.82031190707095, disc_loss = 0.08740018519756061
Trained batch 239 in epoch 2, gen_loss = 0.8209957576046387, disc_loss = 0.08711916980876898
Trained batch 240 in epoch 2, gen_loss = 0.8211412376635302, disc_loss = 0.0868910566490159
Trained batch 241 in epoch 2, gen_loss = 0.8222132365811955, disc_loss = 0.08662139300703386
Trained batch 242 in epoch 2, gen_loss = 0.8212914448461415, disc_loss = 0.086855054909647
Trained batch 243 in epoch 2, gen_loss = 0.8218070076870136, disc_loss = 0.08715322396534754
Trained batch 244 in epoch 2, gen_loss = 0.8217995243413108, disc_loss = 0.08699842180144422
Trained batch 245 in epoch 2, gen_loss = 0.8219369929738161, disc_loss = 0.08688855370718652
Trained batch 246 in epoch 2, gen_loss = 0.8209073747459211, disc_loss = 0.08721632724213094
Trained batch 247 in epoch 2, gen_loss = 0.8216406771492574, disc_loss = 0.08730027589931964
Trained batch 248 in epoch 2, gen_loss = 0.8224667580012816, disc_loss = 0.0873787761834192
Trained batch 249 in epoch 2, gen_loss = 0.8217177263498306, disc_loss = 0.0874595201574266
Trained batch 250 in epoch 2, gen_loss = 0.8208034730764974, disc_loss = 0.08765205040024927
Trained batch 251 in epoch 2, gen_loss = 0.8211150638877399, disc_loss = 0.08792757833864362
Trained batch 252 in epoch 2, gen_loss = 0.8206753849747623, disc_loss = 0.08808415509362819
Trained batch 253 in epoch 2, gen_loss = 0.8199581371282968, disc_loss = 0.08816908554753333
Trained batch 254 in epoch 2, gen_loss = 0.8196352971535102, disc_loss = 0.08819663576854794
Trained batch 255 in epoch 2, gen_loss = 0.8192770449677482, disc_loss = 0.0880745663853304
Trained batch 256 in epoch 2, gen_loss = 0.8190841761776445, disc_loss = 0.08807972473262697
Trained batch 257 in epoch 2, gen_loss = 0.8193202216264813, disc_loss = 0.08819742364693405
Trained batch 258 in epoch 2, gen_loss = 0.8190605349292166, disc_loss = 0.08826141320816223
Trained batch 259 in epoch 2, gen_loss = 0.8185125003640469, disc_loss = 0.0885182987862768
Trained batch 260 in epoch 2, gen_loss = 0.8174140653162624, disc_loss = 0.08902428601422414
Trained batch 261 in epoch 2, gen_loss = 0.8180782450291947, disc_loss = 0.08940391000431344
Trained batch 262 in epoch 2, gen_loss = 0.8177727337345877, disc_loss = 0.08934415675373925
Trained batch 263 in epoch 2, gen_loss = 0.8173652023754336, disc_loss = 0.08932337263302709
Trained batch 264 in epoch 2, gen_loss = 0.8174906243693154, disc_loss = 0.08948535719218681
Trained batch 265 in epoch 2, gen_loss = 0.8167061260096112, disc_loss = 0.08961388303135011
Trained batch 266 in epoch 2, gen_loss = 0.8169974121038387, disc_loss = 0.08944191250336192
Trained batch 267 in epoch 2, gen_loss = 0.8172427712758975, disc_loss = 0.08943630660077863
Trained batch 268 in epoch 2, gen_loss = 0.8163219981698742, disc_loss = 0.08965089623245054
Trained batch 269 in epoch 2, gen_loss = 0.8164516726025829, disc_loss = 0.08957666323899671
Trained batch 270 in epoch 2, gen_loss = 0.8163247622027169, disc_loss = 0.08958748719445343
Trained batch 271 in epoch 2, gen_loss = 0.8163527580087676, disc_loss = 0.08934236913987928
Trained batch 272 in epoch 2, gen_loss = 0.8155863587454562, disc_loss = 0.08952442989531127
Trained batch 273 in epoch 2, gen_loss = 0.8158374830101528, disc_loss = 0.08965917871449225
Trained batch 274 in epoch 2, gen_loss = 0.8168867324699055, disc_loss = 0.08940743641758507
Trained batch 275 in epoch 2, gen_loss = 0.8163629134280094, disc_loss = 0.08937234574915383
Trained batch 276 in epoch 2, gen_loss = 0.8161585467601942, disc_loss = 0.08940417960030615
Trained batch 277 in epoch 2, gen_loss = 0.8172315409500822, disc_loss = 0.08983050070019613
Trained batch 278 in epoch 2, gen_loss = 0.8165905726639601, disc_loss = 0.08978942814066099
Trained batch 279 in epoch 2, gen_loss = 0.8161060511001519, disc_loss = 0.08965438570095492
Trained batch 280 in epoch 2, gen_loss = 0.8155529430116198, disc_loss = 0.08970101180675297
Trained batch 281 in epoch 2, gen_loss = 0.8171830400296137, disc_loss = 0.09023849584545332
Trained batch 282 in epoch 2, gen_loss = 0.8165682599527676, disc_loss = 0.09037233323398516
Trained batch 283 in epoch 2, gen_loss = 0.8157885358996795, disc_loss = 0.09049895335264294
Trained batch 284 in epoch 2, gen_loss = 0.8160742018306465, disc_loss = 0.09058401762720263
Trained batch 285 in epoch 2, gen_loss = 0.8157073850189889, disc_loss = 0.09062500444234356
Trained batch 286 in epoch 2, gen_loss = 0.816071399724442, disc_loss = 0.09069331037367366
Trained batch 287 in epoch 2, gen_loss = 0.815368079373406, disc_loss = 0.09086881836992688
Trained batch 288 in epoch 2, gen_loss = 0.8154022572981032, disc_loss = 0.09083285177880608
Trained batch 289 in epoch 2, gen_loss = 0.8146475412722292, disc_loss = 0.0910966303617019
Trained batch 290 in epoch 2, gen_loss = 0.8150177302024618, disc_loss = 0.09104724820139994
Trained batch 291 in epoch 2, gen_loss = 0.8162674896725236, disc_loss = 0.09108785741758367
Trained batch 292 in epoch 2, gen_loss = 0.8151902653048063, disc_loss = 0.09151072106276457
Trained batch 293 in epoch 2, gen_loss = 0.8150906957128421, disc_loss = 0.0914950126268882
Trained batch 294 in epoch 2, gen_loss = 0.8151315639584752, disc_loss = 0.09141766851041781
Trained batch 295 in epoch 2, gen_loss = 0.8153652547783142, disc_loss = 0.09138941961479045
Trained batch 296 in epoch 2, gen_loss = 0.8147933110845611, disc_loss = 0.09130439493704826
Trained batch 297 in epoch 2, gen_loss = 0.8146946291195466, disc_loss = 0.09129844926260161
Trained batch 298 in epoch 2, gen_loss = 0.8143888840507902, disc_loss = 0.09125178843350415
Trained batch 299 in epoch 2, gen_loss = 0.8147768834233284, disc_loss = 0.09114323180479308
Trained batch 300 in epoch 2, gen_loss = 0.8140457435897814, disc_loss = 0.09107818941205145
Trained batch 301 in epoch 2, gen_loss = 0.8139076780601843, disc_loss = 0.09109447325660003
Trained batch 302 in epoch 2, gen_loss = 0.8137694395611389, disc_loss = 0.09108412523043923
Trained batch 303 in epoch 2, gen_loss = 0.8134755353982511, disc_loss = 0.09096432877030518
Trained batch 304 in epoch 2, gen_loss = 0.8138902190278788, disc_loss = 0.0907774322620425
Trained batch 305 in epoch 2, gen_loss = 0.8146930406101389, disc_loss = 0.09054961077735023
Trained batch 306 in epoch 2, gen_loss = 0.8137215541900175, disc_loss = 0.09122549184576793
Trained batch 307 in epoch 2, gen_loss = 0.8152365822877202, disc_loss = 0.09161782678664214
Trained batch 308 in epoch 2, gen_loss = 0.8149086832035707, disc_loss = 0.09157607010279369
Trained batch 309 in epoch 2, gen_loss = 0.8140339165925979, disc_loss = 0.09167034787336184
Trained batch 310 in epoch 2, gen_loss = 0.8141884965720284, disc_loss = 0.09167144093303148
Trained batch 311 in epoch 2, gen_loss = 0.8137072383020169, disc_loss = 0.09169041702392487
Trained batch 312 in epoch 2, gen_loss = 0.8134155830445762, disc_loss = 0.09167267413387378
Trained batch 313 in epoch 2, gen_loss = 0.8128684296919282, disc_loss = 0.09167356559247443
Trained batch 314 in epoch 2, gen_loss = 0.813063262095527, disc_loss = 0.09154793834461579
Trained batch 315 in epoch 2, gen_loss = 0.8129968557365334, disc_loss = 0.09142217691103587
Trained batch 316 in epoch 2, gen_loss = 0.8128891926646609, disc_loss = 0.0914373188206121
Trained batch 317 in epoch 2, gen_loss = 0.8130019838517567, disc_loss = 0.09128551276798987
Trained batch 318 in epoch 2, gen_loss = 0.8123817532600653, disc_loss = 0.09126877322571124
Trained batch 319 in epoch 2, gen_loss = 0.8131652547977865, disc_loss = 0.09150684243359138
Trained batch 320 in epoch 2, gen_loss = 0.812868347141973, disc_loss = 0.09161991387245903
Trained batch 321 in epoch 2, gen_loss = 0.8122657197787895, disc_loss = 0.09179495613131186
Trained batch 322 in epoch 2, gen_loss = 0.8135536755017083, disc_loss = 0.0920901631175226
Trained batch 323 in epoch 2, gen_loss = 0.8132165790891942, disc_loss = 0.09200519415618921
Trained batch 324 in epoch 2, gen_loss = 0.812252528484051, disc_loss = 0.09233201870838037
Trained batch 325 in epoch 2, gen_loss = 0.8126654871768015, disc_loss = 0.09231364629031416
Trained batch 326 in epoch 2, gen_loss = 0.8127438834318692, disc_loss = 0.09245678661989236
Trained batch 327 in epoch 2, gen_loss = 0.8119423196810048, disc_loss = 0.09259705720526143
Trained batch 328 in epoch 2, gen_loss = 0.8115262244247738, disc_loss = 0.09259802322993253
Trained batch 329 in epoch 2, gen_loss = 0.8119065983728929, disc_loss = 0.0926917184285368
Trained batch 330 in epoch 2, gen_loss = 0.8114407820643975, disc_loss = 0.09275673170295456
Trained batch 331 in epoch 2, gen_loss = 0.8113595591970237, disc_loss = 0.09286355041247983
Trained batch 332 in epoch 2, gen_loss = 0.8106871839758154, disc_loss = 0.09301579806550934
Trained batch 333 in epoch 2, gen_loss = 0.810866979246368, disc_loss = 0.09313655196560804
Trained batch 334 in epoch 2, gen_loss = 0.8109298857290353, disc_loss = 0.09319320047802444
Trained batch 335 in epoch 2, gen_loss = 0.8113871521893001, disc_loss = 0.0932148975525273
Trained batch 336 in epoch 2, gen_loss = 0.8106559090515273, disc_loss = 0.09330467838042303
Trained batch 337 in epoch 2, gen_loss = 0.8103739739169736, disc_loss = 0.0932718237018841
Trained batch 338 in epoch 2, gen_loss = 0.8105813444188211, disc_loss = 0.0931216564859129
Trained batch 339 in epoch 2, gen_loss = 0.8105648121413063, disc_loss = 0.09302841488765005
Trained batch 340 in epoch 2, gen_loss = 0.8105340605257544, disc_loss = 0.09293634210961743
Trained batch 341 in epoch 2, gen_loss = 0.8109054141923001, disc_loss = 0.09292826339961928
Trained batch 342 in epoch 2, gen_loss = 0.8099843717177477, disc_loss = 0.09379015350578565
Trained batch 343 in epoch 2, gen_loss = 0.8100529526208722, disc_loss = 0.09376440951221644
Trained batch 344 in epoch 2, gen_loss = 0.8105405959530153, disc_loss = 0.09373912861219783
Trained batch 345 in epoch 2, gen_loss = 0.8101189043480537, disc_loss = 0.09377163325872466
Trained batch 346 in epoch 2, gen_loss = 0.8098258851928052, disc_loss = 0.09383459833936406
Trained batch 347 in epoch 2, gen_loss = 0.8099759520812967, disc_loss = 0.09385662087260735
Trained batch 348 in epoch 2, gen_loss = 0.8099452699494567, disc_loss = 0.09366510913341725
Trained batch 349 in epoch 2, gen_loss = 0.8103264447620937, disc_loss = 0.09349046724449311
Trained batch 350 in epoch 2, gen_loss = 0.8110116434912397, disc_loss = 0.09341679539191841
Trained batch 351 in epoch 2, gen_loss = 0.8108454075726595, disc_loss = 0.09327349656483751
Trained batch 352 in epoch 2, gen_loss = 0.8104335491785585, disc_loss = 0.09325669420139057
Trained batch 353 in epoch 2, gen_loss = 0.8104347977261085, disc_loss = 0.09342686664891867
Trained batch 354 in epoch 2, gen_loss = 0.8105984647509078, disc_loss = 0.09326494707870231
Trained batch 355 in epoch 2, gen_loss = 0.8101968221115262, disc_loss = 0.09339379818764713
Trained batch 356 in epoch 2, gen_loss = 0.8102838587360222, disc_loss = 0.09328726344384483
Trained batch 357 in epoch 2, gen_loss = 0.8103929526646044, disc_loss = 0.09317620625386441
Trained batch 358 in epoch 2, gen_loss = 0.8103089472045474, disc_loss = 0.0930106595475071
Trained batch 359 in epoch 2, gen_loss = 0.8103856046994528, disc_loss = 0.09284053327153541
Trained batch 360 in epoch 2, gen_loss = 0.8099872493017414, disc_loss = 0.0928378216225726
Trained batch 361 in epoch 2, gen_loss = 0.8119403026709899, disc_loss = 0.09338115761056542
Trained batch 362 in epoch 2, gen_loss = 0.8119757748503987, disc_loss = 0.09321705405100071
Trained batch 363 in epoch 2, gen_loss = 0.8112808472507602, disc_loss = 0.09415923217874389
Trained batch 364 in epoch 2, gen_loss = 0.8119504311313368, disc_loss = 0.09449340092043762
Trained batch 365 in epoch 2, gen_loss = 0.8119025715713293, disc_loss = 0.0947203201679462
Trained batch 366 in epoch 2, gen_loss = 0.8117844567961524, disc_loss = 0.09490620183735599
Trained batch 367 in epoch 2, gen_loss = 0.8120494967569476, disc_loss = 0.09512563895322787
Trained batch 368 in epoch 2, gen_loss = 0.8123075840918998, disc_loss = 0.09514883499047379
Trained batch 369 in epoch 2, gen_loss = 0.8119799765380653, disc_loss = 0.09518659609445446
Trained batch 370 in epoch 2, gen_loss = 0.8118052819989762, disc_loss = 0.09509323272512689
Trained batch 371 in epoch 2, gen_loss = 0.8120454230936625, disc_loss = 0.09522465544612578
Trained batch 372 in epoch 2, gen_loss = 0.8113001778362264, disc_loss = 0.09535917272446702
Trained batch 373 in epoch 2, gen_loss = 0.810360373899261, disc_loss = 0.09566959762886007
Trained batch 374 in epoch 2, gen_loss = 0.8106128408908844, disc_loss = 0.09603678123404583
Trained batch 375 in epoch 2, gen_loss = 0.8108014362131027, disc_loss = 0.09596619517492884
Trained batch 376 in epoch 2, gen_loss = 0.8102537086060572, disc_loss = 0.09615295252142676
Trained batch 377 in epoch 2, gen_loss = 0.8103972934383564, disc_loss = 0.09612540108590294
Trained batch 378 in epoch 2, gen_loss = 0.8102565411684696, disc_loss = 0.09623674124646392
Trained batch 379 in epoch 2, gen_loss = 0.8098027876333187, disc_loss = 0.09624511105694661
Trained batch 380 in epoch 2, gen_loss = 0.8095216723721171, disc_loss = 0.09615828449106983
Trained batch 381 in epoch 2, gen_loss = 0.8094667293794492, disc_loss = 0.09618031586817812
Trained batch 382 in epoch 2, gen_loss = 0.809629469331811, disc_loss = 0.09615829842062983
Trained batch 383 in epoch 2, gen_loss = 0.809220400871709, disc_loss = 0.09619879303742589
Trained batch 384 in epoch 2, gen_loss = 0.8095027339148831, disc_loss = 0.0960505214918937
Trained batch 385 in epoch 2, gen_loss = 0.809891204219408, disc_loss = 0.095902152024113
Trained batch 386 in epoch 2, gen_loss = 0.80938863561751, disc_loss = 0.09592003613296482
Trained batch 387 in epoch 2, gen_loss = 0.8095599908343295, disc_loss = 0.09575043734614305
Trained batch 388 in epoch 2, gen_loss = 0.8099505897506037, disc_loss = 0.0957502505998187
Trained batch 389 in epoch 2, gen_loss = 0.8100162841570683, disc_loss = 0.0956164175668397
Trained batch 390 in epoch 2, gen_loss = 0.8093976063649063, disc_loss = 0.09562745526232912
Trained batch 391 in epoch 2, gen_loss = 0.8091545142233372, disc_loss = 0.09555584349793059
Trained batch 392 in epoch 2, gen_loss = 0.8093710280101718, disc_loss = 0.09550514909896156
Trained batch 393 in epoch 2, gen_loss = 0.8091302050400506, disc_loss = 0.09544706758499373
Trained batch 394 in epoch 2, gen_loss = 0.8093389667287657, disc_loss = 0.09528113707098403
Trained batch 395 in epoch 2, gen_loss = 0.8092064101136092, disc_loss = 0.09528379738471951
Trained batch 396 in epoch 2, gen_loss = 0.8091889541005007, disc_loss = 0.09518879853536184
Trained batch 397 in epoch 2, gen_loss = 0.8103510919378032, disc_loss = 0.09506931173470078
Trained batch 398 in epoch 2, gen_loss = 0.811031593938818, disc_loss = 0.09489550908565297
Trained batch 399 in epoch 2, gen_loss = 0.8109702702611685, disc_loss = 0.09476153645897284
Trained batch 400 in epoch 2, gen_loss = 0.8106471480722737, disc_loss = 0.0946780938929193
Trained batch 401 in epoch 2, gen_loss = 0.810955733728053, disc_loss = 0.0945543550274599
Trained batch 402 in epoch 2, gen_loss = 0.8113158609228158, disc_loss = 0.09441533500083697
Trained batch 403 in epoch 2, gen_loss = 0.8109954178775891, disc_loss = 0.09435068746097386
Trained batch 404 in epoch 2, gen_loss = 0.8110081121509458, disc_loss = 0.09436248254122925
Trained batch 405 in epoch 2, gen_loss = 0.8108167867795587, disc_loss = 0.09436773442952283
Trained batch 406 in epoch 2, gen_loss = 0.811357263191912, disc_loss = 0.0942207222200326
Trained batch 407 in epoch 2, gen_loss = 0.8109382223703113, disc_loss = 0.0943821530136298
Trained batch 408 in epoch 2, gen_loss = 0.8111445856414972, disc_loss = 0.09433629284760844
Trained batch 409 in epoch 2, gen_loss = 0.8113552389348425, disc_loss = 0.09419911384991393
Trained batch 410 in epoch 2, gen_loss = 0.811120921315358, disc_loss = 0.09405986650409562
Trained batch 411 in epoch 2, gen_loss = 0.8112095263831823, disc_loss = 0.09389918070801904
Trained batch 412 in epoch 2, gen_loss = 0.8111012610482823, disc_loss = 0.09381910478673677
Trained batch 413 in epoch 2, gen_loss = 0.8110816963196953, disc_loss = 0.09385974811623998
Trained batch 414 in epoch 2, gen_loss = 0.8110241349203041, disc_loss = 0.09371927626745169
Trained batch 415 in epoch 2, gen_loss = 0.8109457242804078, disc_loss = 0.09368739207499087
Trained batch 416 in epoch 2, gen_loss = 0.8117806544835618, disc_loss = 0.09355342868108044
Trained batch 417 in epoch 2, gen_loss = 0.8120435803558268, disc_loss = 0.09338237951023941
Trained batch 418 in epoch 2, gen_loss = 0.8116602605311, disc_loss = 0.09341650991200476
Trained batch 419 in epoch 2, gen_loss = 0.8123161132136981, disc_loss = 0.09370998218433843
Trained batch 420 in epoch 2, gen_loss = 0.8124203073865162, disc_loss = 0.0935445904196406
Trained batch 421 in epoch 2, gen_loss = 0.8118000921056169, disc_loss = 0.09363648703904442
Trained batch 422 in epoch 2, gen_loss = 0.8118603327454686, disc_loss = 0.0936646268683228
Trained batch 423 in epoch 2, gen_loss = 0.8111783363768514, disc_loss = 0.09404206686029386
Trained batch 424 in epoch 2, gen_loss = 0.8114132092279547, disc_loss = 0.0943511815873139
Trained batch 425 in epoch 2, gen_loss = 0.8111563471141555, disc_loss = 0.09435477617367262
Trained batch 426 in epoch 2, gen_loss = 0.810724522037305, disc_loss = 0.09442984219204277
Trained batch 427 in epoch 2, gen_loss = 0.8110350900303538, disc_loss = 0.09444818357397393
Trained batch 428 in epoch 2, gen_loss = 0.8107688233152136, disc_loss = 0.09449006405839205
Trained batch 429 in epoch 2, gen_loss = 0.8103173908106116, disc_loss = 0.09458372285156402
Trained batch 430 in epoch 2, gen_loss = 0.8105546052798871, disc_loss = 0.0944586635184779
Trained batch 431 in epoch 2, gen_loss = 0.8106653993190439, disc_loss = 0.09465392562345153
Trained batch 432 in epoch 2, gen_loss = 0.8105782708862913, disc_loss = 0.09451729683614149
Trained batch 433 in epoch 2, gen_loss = 0.8101436359129743, disc_loss = 0.09445496770222822
Trained batch 434 in epoch 2, gen_loss = 0.8102260492998978, disc_loss = 0.09432317671719297
Trained batch 435 in epoch 2, gen_loss = 0.8108825133344449, disc_loss = 0.09439907536346363
Trained batch 436 in epoch 2, gen_loss = 0.8102467474048143, disc_loss = 0.09462641764994821
Trained batch 437 in epoch 2, gen_loss = 0.8101801464682845, disc_loss = 0.0945474803341408
Trained batch 438 in epoch 2, gen_loss = 0.8105461860164694, disc_loss = 0.0946001560068721
Trained batch 439 in epoch 2, gen_loss = 0.8101246818222783, disc_loss = 0.09479929695371539
Trained batch 440 in epoch 2, gen_loss = 0.8107851092912712, disc_loss = 0.09549952011825749
Trained batch 441 in epoch 2, gen_loss = 0.8102485149829096, disc_loss = 0.09577375595411497
Trained batch 442 in epoch 2, gen_loss = 0.8097523643927435, disc_loss = 0.09581132232091699
Trained batch 443 in epoch 2, gen_loss = 0.8099538409360895, disc_loss = 0.09612967029239076
Trained batch 444 in epoch 2, gen_loss = 0.8099608176879669, disc_loss = 0.09611440947844406
Trained batch 445 in epoch 2, gen_loss = 0.8093635073023526, disc_loss = 0.0962250736592162
Trained batch 446 in epoch 2, gen_loss = 0.8096230294747108, disc_loss = 0.09627736110440237
Trained batch 447 in epoch 2, gen_loss = 0.8091769442627472, disc_loss = 0.0964058037477246
Trained batch 448 in epoch 2, gen_loss = 0.8091158834358632, disc_loss = 0.09639279792222188
Trained batch 449 in epoch 2, gen_loss = 0.8094376783238517, disc_loss = 0.09636484650067158
Trained batch 450 in epoch 2, gen_loss = 0.8089460768218579, disc_loss = 0.09647736462770637
Trained batch 451 in epoch 2, gen_loss = 0.8090094345728908, disc_loss = 0.096489968954841
Trained batch 452 in epoch 2, gen_loss = 0.8089137655615017, disc_loss = 0.09636523478991346
Trained batch 453 in epoch 2, gen_loss = 0.8090767135047703, disc_loss = 0.0962936467417241
Trained batch 454 in epoch 2, gen_loss = 0.8086861043840974, disc_loss = 0.09640859825393329
Trained batch 455 in epoch 2, gen_loss = 0.8085885408023993, disc_loss = 0.09627684637732607
Trained batch 456 in epoch 2, gen_loss = 0.8087404335745054, disc_loss = 0.09617956411256506
Trained batch 457 in epoch 2, gen_loss = 0.8082286497521088, disc_loss = 0.09620335579170605
Trained batch 458 in epoch 2, gen_loss = 0.8085531132023839, disc_loss = 0.09618242209765061
Trained batch 459 in epoch 2, gen_loss = 0.8083370129051416, disc_loss = 0.09611245712629803
Trained batch 460 in epoch 2, gen_loss = 0.8085304742392129, disc_loss = 0.09599411051009263
Trained batch 461 in epoch 2, gen_loss = 0.8086025052385413, disc_loss = 0.09585247743769965
Trained batch 462 in epoch 2, gen_loss = 0.8087681514526804, disc_loss = 0.09579625985027969
Trained batch 463 in epoch 2, gen_loss = 0.8084313222688848, disc_loss = 0.09586747236557883
Trained batch 464 in epoch 2, gen_loss = 0.8090183330479489, disc_loss = 0.09593518865244684
Trained batch 465 in epoch 2, gen_loss = 0.8091298552158053, disc_loss = 0.09583574928575127
Trained batch 466 in epoch 2, gen_loss = 0.808516737799573, disc_loss = 0.09617061844610109
Trained batch 467 in epoch 2, gen_loss = 0.8083204162808565, disc_loss = 0.09622238914116135
Trained batch 468 in epoch 2, gen_loss = 0.8088083289452453, disc_loss = 0.09638914342191238
Trained batch 469 in epoch 2, gen_loss = 0.8082377022251169, disc_loss = 0.0966241022710629
Trained batch 470 in epoch 2, gen_loss = 0.8084031018861539, disc_loss = 0.09658442972516622
Trained batch 471 in epoch 2, gen_loss = 0.8079320083103948, disc_loss = 0.09662513545580145
Trained batch 472 in epoch 2, gen_loss = 0.8078031589692541, disc_loss = 0.09667931869035354
Trained batch 473 in epoch 2, gen_loss = 0.8079312964959486, disc_loss = 0.09670875378872586
Trained batch 474 in epoch 2, gen_loss = 0.8075201932380074, disc_loss = 0.09686379815598851
Trained batch 475 in epoch 2, gen_loss = 0.8076492543606197, disc_loss = 0.09674743556871447
Trained batch 476 in epoch 2, gen_loss = 0.8080429986462903, disc_loss = 0.0966921563063059
Trained batch 477 in epoch 2, gen_loss = 0.8079986094056811, disc_loss = 0.09654843677263941
Trained batch 478 in epoch 2, gen_loss = 0.8075939332891356, disc_loss = 0.09663389876119341
Trained batch 479 in epoch 2, gen_loss = 0.8083708515390754, disc_loss = 0.09662233935086988
Trained batch 480 in epoch 2, gen_loss = 0.8089194613162296, disc_loss = 0.09651573836656284
Trained batch 481 in epoch 2, gen_loss = 0.8087712153483229, disc_loss = 0.096493252744334
Trained batch 482 in epoch 2, gen_loss = 0.8086452526705605, disc_loss = 0.09643947452838932
Trained batch 483 in epoch 2, gen_loss = 0.8088453583850348, disc_loss = 0.09632581744289165
Trained batch 484 in epoch 2, gen_loss = 0.8085055534987106, disc_loss = 0.09627915591039915
Trained batch 485 in epoch 2, gen_loss = 0.808693027238787, disc_loss = 0.09622394949113453
Trained batch 486 in epoch 2, gen_loss = 0.8082727746429874, disc_loss = 0.09626060315203189
Trained batch 487 in epoch 2, gen_loss = 0.8088955624548139, disc_loss = 0.0961530768927034
Trained batch 488 in epoch 2, gen_loss = 0.8090083976342878, disc_loss = 0.09599252756883091
Trained batch 489 in epoch 2, gen_loss = 0.8085418318607369, disc_loss = 0.09596951862569061
Trained batch 490 in epoch 2, gen_loss = 0.8089531729881729, disc_loss = 0.09588084008939216
Trained batch 491 in epoch 2, gen_loss = 0.809174034108476, disc_loss = 0.09574917432988381
Trained batch 492 in epoch 2, gen_loss = 0.8094809754745955, disc_loss = 0.09561039028126316
Trained batch 493 in epoch 2, gen_loss = 0.80923249358349, disc_loss = 0.0956761024209863
Trained batch 494 in epoch 2, gen_loss = 0.8099843559241054, disc_loss = 0.09571139103347304
Trained batch 495 in epoch 2, gen_loss = 0.8100205160557262, disc_loss = 0.09571533723576595
Trained batch 496 in epoch 2, gen_loss = 0.8096809860326395, disc_loss = 0.09577501535048367
Trained batch 497 in epoch 2, gen_loss = 0.8097379765955799, disc_loss = 0.09578969585241742
Trained batch 498 in epoch 2, gen_loss = 0.8098227033514775, disc_loss = 0.09571462672368021
Trained batch 499 in epoch 2, gen_loss = 0.8094948515295982, disc_loss = 0.09575505660288036
Trained batch 500 in epoch 2, gen_loss = 0.8101122126488867, disc_loss = 0.09592920453836044
Trained batch 501 in epoch 2, gen_loss = 0.8100472360374443, disc_loss = 0.09585544043795699
Trained batch 502 in epoch 2, gen_loss = 0.8099059651552091, disc_loss = 0.09581548366399396
Trained batch 503 in epoch 2, gen_loss = 0.8103969258566698, disc_loss = 0.09570494762599646
Trained batch 504 in epoch 2, gen_loss = 0.8111753157459863, disc_loss = 0.09557664046746374
Trained batch 505 in epoch 2, gen_loss = 0.8107669607334929, disc_loss = 0.09558735856153218
Trained batch 506 in epoch 2, gen_loss = 0.8107906111481157, disc_loss = 0.09549816939391975
Trained batch 507 in epoch 2, gen_loss = 0.8112160354031352, disc_loss = 0.09560334549549468
Trained batch 508 in epoch 2, gen_loss = 0.8110279464885621, disc_loss = 0.095691971603437
Trained batch 509 in epoch 2, gen_loss = 0.810986658580163, disc_loss = 0.09561880896160123
Trained batch 510 in epoch 2, gen_loss = 0.8111083074208575, disc_loss = 0.09550806239006746
Trained batch 511 in epoch 2, gen_loss = 0.8119135448359884, disc_loss = 0.0955658070215577
Trained batch 512 in epoch 2, gen_loss = 0.8114450401381442, disc_loss = 0.09561003050921198
Trained batch 513 in epoch 2, gen_loss = 0.8118033683369595, disc_loss = 0.09550569169332024
Trained batch 514 in epoch 2, gen_loss = 0.8114226712185202, disc_loss = 0.09546778017419924
Trained batch 515 in epoch 2, gen_loss = 0.8117852100683737, disc_loss = 0.09540136623947137
Trained batch 516 in epoch 2, gen_loss = 0.811881092404028, disc_loss = 0.09531288920961162
Trained batch 517 in epoch 2, gen_loss = 0.8118405593523188, disc_loss = 0.09516483380434078
Trained batch 518 in epoch 2, gen_loss = 0.8113923700443811, disc_loss = 0.09523507133521039
Trained batch 519 in epoch 2, gen_loss = 0.8119901178547969, disc_loss = 0.09531632821397999
Trained batch 520 in epoch 2, gen_loss = 0.811926772464031, disc_loss = 0.09523315947045234
Trained batch 521 in epoch 2, gen_loss = 0.8121399367335199, disc_loss = 0.0950861917148519
Trained batch 522 in epoch 2, gen_loss = 0.8115971192689061, disc_loss = 0.09516583866908092
Trained batch 523 in epoch 2, gen_loss = 0.8118332694391258, disc_loss = 0.09539040908366726
Trained batch 524 in epoch 2, gen_loss = 0.8113543182895298, disc_loss = 0.09547468732687689
Trained batch 525 in epoch 2, gen_loss = 0.8109609974767772, disc_loss = 0.0955252437569031
Trained batch 526 in epoch 2, gen_loss = 0.8110241647350268, disc_loss = 0.09553872705728833
Trained batch 527 in epoch 2, gen_loss = 0.811160345928687, disc_loss = 0.0955829423742905
Trained batch 528 in epoch 2, gen_loss = 0.8107760270849743, disc_loss = 0.09571699356741231
Trained batch 529 in epoch 2, gen_loss = 0.8105094903482581, disc_loss = 0.09579196966797957
Trained batch 530 in epoch 2, gen_loss = 0.8103124751321789, disc_loss = 0.09584991732987587
Trained batch 531 in epoch 2, gen_loss = 0.8102377843027725, disc_loss = 0.0957409393241895
Trained batch 532 in epoch 2, gen_loss = 0.8101394491280668, disc_loss = 0.09575265557391614
Trained batch 533 in epoch 2, gen_loss = 0.8108122571465675, disc_loss = 0.09577984667874956
Trained batch 534 in epoch 2, gen_loss = 0.8102655693192349, disc_loss = 0.0960326280357821
Trained batch 535 in epoch 2, gen_loss = 0.8100904065615205, disc_loss = 0.09594136229959498
Trained batch 536 in epoch 2, gen_loss = 0.8105838402578507, disc_loss = 0.09598896497933392
Trained batch 537 in epoch 2, gen_loss = 0.8101429083422658, disc_loss = 0.09606850102412269
Trained batch 538 in epoch 2, gen_loss = 0.8096454162876328, disc_loss = 0.0960902327512683
Trained batch 539 in epoch 2, gen_loss = 0.8099678615177119, disc_loss = 0.09611705212715875
Trained batch 540 in epoch 2, gen_loss = 0.8097432289348292, disc_loss = 0.0960758777349058
Trained batch 541 in epoch 2, gen_loss = 0.8095015856502681, disc_loss = 0.0961558402522821
Trained batch 542 in epoch 2, gen_loss = 0.8096537922078514, disc_loss = 0.09631838450040223
Trained batch 543 in epoch 2, gen_loss = 0.809321118354359, disc_loss = 0.09641034117221887
Trained batch 544 in epoch 2, gen_loss = 0.8092692971776385, disc_loss = 0.09640207633273591
Trained batch 545 in epoch 2, gen_loss = 0.8095510850350062, disc_loss = 0.09632054547994183
Trained batch 546 in epoch 2, gen_loss = 0.8098803399576784, disc_loss = 0.09618616426428286
Trained batch 547 in epoch 2, gen_loss = 0.809984912239287, disc_loss = 0.09605673909438842
Trained batch 548 in epoch 2, gen_loss = 0.8099471956545755, disc_loss = 0.09596761387479381
Trained batch 549 in epoch 2, gen_loss = 0.8102345359867269, disc_loss = 0.09586342228576542
Trained batch 550 in epoch 2, gen_loss = 0.8103929982535852, disc_loss = 0.09581772210465207
Trained batch 551 in epoch 2, gen_loss = 0.8100657980835092, disc_loss = 0.0958183458213276
Trained batch 552 in epoch 2, gen_loss = 0.8095533821401717, disc_loss = 0.09589203321299167
Trained batch 553 in epoch 2, gen_loss = 0.8096589380976095, disc_loss = 0.09581767473981753
Trained batch 554 in epoch 2, gen_loss = 0.8097034660008576, disc_loss = 0.0959329933146233
Trained batch 555 in epoch 2, gen_loss = 0.8096807431295622, disc_loss = 0.09584581919798373
Trained batch 556 in epoch 2, gen_loss = 0.8093280987529823, disc_loss = 0.09589335454303496
Trained batch 557 in epoch 2, gen_loss = 0.809144627930443, disc_loss = 0.0958283630860669
Trained batch 558 in epoch 2, gen_loss = 0.8099290314322081, disc_loss = 0.09604889556452338
Trained batch 559 in epoch 2, gen_loss = 0.8096104296722583, disc_loss = 0.09594357226742431
Trained batch 560 in epoch 2, gen_loss = 0.8089559732167692, disc_loss = 0.09604933013419045
Trained batch 561 in epoch 2, gen_loss = 0.8084995510633306, disc_loss = 0.09617701957824232
Trained batch 562 in epoch 2, gen_loss = 0.8086612708932764, disc_loss = 0.09620816164135562
Trained batch 563 in epoch 2, gen_loss = 0.8083563636697776, disc_loss = 0.09635690560214327
Trained batch 564 in epoch 2, gen_loss = 0.8081965049283695, disc_loss = 0.09641814730501017
Trained batch 565 in epoch 2, gen_loss = 0.8078445941209793, disc_loss = 0.0964677446265129
Trained batch 566 in epoch 2, gen_loss = 0.80740798565656, disc_loss = 0.09653623002816182
Trained batch 567 in epoch 2, gen_loss = 0.8076517948697151, disc_loss = 0.0966836597367098
Trained batch 568 in epoch 2, gen_loss = 0.8076725484302467, disc_loss = 0.09656180396695704
Trained batch 569 in epoch 2, gen_loss = 0.8075586904036371, disc_loss = 0.09648760208010412
Trained batch 570 in epoch 2, gen_loss = 0.8073882209544841, disc_loss = 0.09652263227354363
Trained batch 571 in epoch 2, gen_loss = 0.8072921917676092, disc_loss = 0.09664316187365228
Trained batch 572 in epoch 2, gen_loss = 0.807105284450774, disc_loss = 0.09664982464814634
Trained batch 573 in epoch 2, gen_loss = 0.8068722114226544, disc_loss = 0.09664427934097652
Trained batch 574 in epoch 2, gen_loss = 0.8072296467553014, disc_loss = 0.09669438119653774
Trained batch 575 in epoch 2, gen_loss = 0.8071077550347481, disc_loss = 0.09667735591938253
Trained batch 576 in epoch 2, gen_loss = 0.8068779749824848, disc_loss = 0.09658614338006004
Trained batch 577 in epoch 2, gen_loss = 0.806915614173899, disc_loss = 0.09650895433745324
Trained batch 578 in epoch 2, gen_loss = 0.8071299140214508, disc_loss = 0.0964268452965611
Trained batch 579 in epoch 2, gen_loss = 0.80700265205112, disc_loss = 0.09634268187981998
Trained batch 580 in epoch 2, gen_loss = 0.8068206007119505, disc_loss = 0.09635137722197529
Trained batch 581 in epoch 2, gen_loss = 0.8069924397259644, disc_loss = 0.09649161144905433
Trained batch 582 in epoch 2, gen_loss = 0.8068076757071971, disc_loss = 0.09659309079950455
Trained batch 583 in epoch 2, gen_loss = 0.8071964916403163, disc_loss = 0.0966993446369362
Trained batch 584 in epoch 2, gen_loss = 0.8073387262658176, disc_loss = 0.09657815252390937
Trained batch 585 in epoch 2, gen_loss = 0.8074768289872811, disc_loss = 0.09645952300387896
Trained batch 586 in epoch 2, gen_loss = 0.8075628514691959, disc_loss = 0.0964169338094848
Trained batch 587 in epoch 2, gen_loss = 0.8074506239927545, disc_loss = 0.09641604640736517
Trained batch 588 in epoch 2, gen_loss = 0.8071728284472318, disc_loss = 0.09649162162221804
Trained batch 589 in epoch 2, gen_loss = 0.8075919910507687, disc_loss = 0.0967117924890402
Trained batch 590 in epoch 2, gen_loss = 0.8074137004196341, disc_loss = 0.09663539079322074
Trained batch 591 in epoch 2, gen_loss = 0.8078032900654787, disc_loss = 0.09654463954251008
Trained batch 592 in epoch 2, gen_loss = 0.8085416408152042, disc_loss = 0.09645339758818558
Trained batch 593 in epoch 2, gen_loss = 0.8085654008167761, disc_loss = 0.09639900371037198
Trained batch 594 in epoch 2, gen_loss = 0.8084219503302534, disc_loss = 0.09641182777166617
Trained batch 595 in epoch 2, gen_loss = 0.8094596558269238, disc_loss = 0.0965801956860236
Trained batch 596 in epoch 2, gen_loss = 0.8097944806269066, disc_loss = 0.09645195838400916
Trained batch 597 in epoch 2, gen_loss = 0.8097108988757915, disc_loss = 0.09639771087219733
Trained batch 598 in epoch 2, gen_loss = 0.8099701311532563, disc_loss = 0.09630361798441718
Trained batch 599 in epoch 2, gen_loss = 0.8099918161332608, disc_loss = 0.09617798378225416
Trained batch 600 in epoch 2, gen_loss = 0.8102401492500464, disc_loss = 0.09605979269987186
Trained batch 601 in epoch 2, gen_loss = 0.810047663475984, disc_loss = 0.09600571372338951
Trained batch 602 in epoch 2, gen_loss = 0.8103860187194438, disc_loss = 0.09597733876456323
Trained batch 603 in epoch 2, gen_loss = 0.8109377705004831, disc_loss = 0.09591722042016093
Trained batch 604 in epoch 2, gen_loss = 0.8106683188726094, disc_loss = 0.09594269397491512
Trained batch 605 in epoch 2, gen_loss = 0.8109377495231408, disc_loss = 0.09585314129844996
Trained batch 606 in epoch 2, gen_loss = 0.8111020172938483, disc_loss = 0.09579270598332856
Trained batch 607 in epoch 2, gen_loss = 0.8114120682309333, disc_loss = 0.09576945245958325
Trained batch 608 in epoch 2, gen_loss = 0.811807562418172, disc_loss = 0.09566339214098424
Trained batch 609 in epoch 2, gen_loss = 0.8111393033969597, disc_loss = 0.09594646364786341
Trained batch 610 in epoch 2, gen_loss = 0.8114066670744782, disc_loss = 0.09582546181251247
Trained batch 611 in epoch 2, gen_loss = 0.8118447206086583, disc_loss = 0.09584051834303715
Trained batch 612 in epoch 2, gen_loss = 0.8117429656364011, disc_loss = 0.09576852518615434
Trained batch 613 in epoch 2, gen_loss = 0.8114491252149744, disc_loss = 0.09575641301918641
Trained batch 614 in epoch 2, gen_loss = 0.8126573938179792, disc_loss = 0.09596275416907014
Trained batch 615 in epoch 2, gen_loss = 0.8127193769754527, disc_loss = 0.09585237744197782
Trained batch 616 in epoch 2, gen_loss = 0.8127342945076464, disc_loss = 0.09576824450385386
Trained batch 617 in epoch 2, gen_loss = 0.8123399371757476, disc_loss = 0.09585136460128292
Trained batch 618 in epoch 2, gen_loss = 0.8130460021857876, disc_loss = 0.09658351906925824
Trained batch 619 in epoch 2, gen_loss = 0.8130958737384888, disc_loss = 0.09653019566659725
Trained batch 620 in epoch 2, gen_loss = 0.8130512715057858, disc_loss = 0.09647428071435284
Trained batch 621 in epoch 2, gen_loss = 0.812722054660512, disc_loss = 0.09644007142423577
Trained batch 622 in epoch 2, gen_loss = 0.8127433466777373, disc_loss = 0.09641172179435029
Trained batch 623 in epoch 2, gen_loss = 0.8127266695388616, disc_loss = 0.09632669501334955
Trained batch 624 in epoch 2, gen_loss = 0.8127326313495636, disc_loss = 0.096279047511518
Trained batch 625 in epoch 2, gen_loss = 0.8123120765049998, disc_loss = 0.09644945498895102
Trained batch 626 in epoch 2, gen_loss = 0.8124147893614366, disc_loss = 0.09636273727480447
Trained batch 627 in epoch 2, gen_loss = 0.8127176843725952, disc_loss = 0.0963075561315462
Trained batch 628 in epoch 2, gen_loss = 0.8126974846391875, disc_loss = 0.09622265032932328
Trained batch 629 in epoch 2, gen_loss = 0.8122838165551897, disc_loss = 0.0963488502087929
Trained batch 630 in epoch 2, gen_loss = 0.812246976818789, disc_loss = 0.09631937144031946
Trained batch 631 in epoch 2, gen_loss = 0.8120285184417344, disc_loss = 0.09632996381761483
Trained batch 632 in epoch 2, gen_loss = 0.8118234016413184, disc_loss = 0.0962906628773558
Trained batch 633 in epoch 2, gen_loss = 0.8115484837195851, disc_loss = 0.09629970897512058
Trained batch 634 in epoch 2, gen_loss = 0.8117485812799199, disc_loss = 0.09620793674023836
Trained batch 635 in epoch 2, gen_loss = 0.8113928229647612, disc_loss = 0.09621093948020266
Trained batch 636 in epoch 2, gen_loss = 0.8117223334742865, disc_loss = 0.09612282265410459
Trained batch 637 in epoch 2, gen_loss = 0.8117596797154615, disc_loss = 0.09605533205013617
Trained batch 638 in epoch 2, gen_loss = 0.8114830662666912, disc_loss = 0.09601221366964735
Trained batch 639 in epoch 2, gen_loss = 0.8116326723713427, disc_loss = 0.09590010972315213
Trained batch 640 in epoch 2, gen_loss = 0.8117621322038951, disc_loss = 0.09589898476868217
Trained batch 641 in epoch 2, gen_loss = 0.8120316858882102, disc_loss = 0.09579067740363077
Trained batch 642 in epoch 2, gen_loss = 0.8115992193366655, disc_loss = 0.09583349000303361
Trained batch 643 in epoch 2, gen_loss = 0.8115206341843427, disc_loss = 0.09579388566332528
Trained batch 644 in epoch 2, gen_loss = 0.81165668202001, disc_loss = 0.09590431581605081
Trained batch 645 in epoch 2, gen_loss = 0.811230898318645, disc_loss = 0.09593049840909362
Trained batch 646 in epoch 2, gen_loss = 0.8109286672088794, disc_loss = 0.09597851988216041
Trained batch 647 in epoch 2, gen_loss = 0.811429924297112, disc_loss = 0.0959393107432895
Trained batch 648 in epoch 2, gen_loss = 0.8114658616632453, disc_loss = 0.09587149651368107
Trained batch 649 in epoch 2, gen_loss = 0.8116206553807626, disc_loss = 0.09576509901967187
Trained batch 650 in epoch 2, gen_loss = 0.8117501021072429, disc_loss = 0.09566259322782403
Trained batch 651 in epoch 2, gen_loss = 0.811917685977886, disc_loss = 0.09554184200613548
Trained batch 652 in epoch 2, gen_loss = 0.8117843852200151, disc_loss = 0.09543713448771703
Trained batch 653 in epoch 2, gen_loss = 0.8120144083868108, disc_loss = 0.09542136476019153
Trained batch 654 in epoch 2, gen_loss = 0.8121853453967407, disc_loss = 0.09529889565359317
Trained batch 655 in epoch 2, gen_loss = 0.8123193374585088, disc_loss = 0.0952026224851313
Trained batch 656 in epoch 2, gen_loss = 0.8124647530155821, disc_loss = 0.09507866798442204
Trained batch 657 in epoch 2, gen_loss = 0.812783060963393, disc_loss = 0.09496366963396273
Trained batch 658 in epoch 2, gen_loss = 0.8133343714593213, disc_loss = 0.09502865120129764
Trained batch 659 in epoch 2, gen_loss = 0.8131589879140709, disc_loss = 0.09495379379950464
Trained batch 660 in epoch 2, gen_loss = 0.8129140896533874, disc_loss = 0.09498478486181523
Trained batch 661 in epoch 2, gen_loss = 0.8131738802547541, disc_loss = 0.09490384882192192
Trained batch 662 in epoch 2, gen_loss = 0.8134199287826659, disc_loss = 0.09477593648201066
Trained batch 663 in epoch 2, gen_loss = 0.8133269629654396, disc_loss = 0.09468910350122052
Trained batch 664 in epoch 2, gen_loss = 0.8137194065671218, disc_loss = 0.09470480059350568
Trained batch 665 in epoch 2, gen_loss = 0.8135994575671606, disc_loss = 0.09464816859428275
Trained batch 666 in epoch 2, gen_loss = 0.813820708772053, disc_loss = 0.0946622257940527
Trained batch 667 in epoch 2, gen_loss = 0.8138943820031818, disc_loss = 0.0945814698056212
Trained batch 668 in epoch 2, gen_loss = 0.8138746141229153, disc_loss = 0.09453267263462949
Trained batch 669 in epoch 2, gen_loss = 0.8139711134914142, disc_loss = 0.09452852974993302
Trained batch 670 in epoch 2, gen_loss = 0.8137373621790669, disc_loss = 0.09458239133512787
Trained batch 671 in epoch 2, gen_loss = 0.8140140507104141, disc_loss = 0.0945571360657812
Trained batch 672 in epoch 2, gen_loss = 0.8141992719619802, disc_loss = 0.09447485490952567
Trained batch 673 in epoch 2, gen_loss = 0.813922847281224, disc_loss = 0.09470601595567887
Trained batch 674 in epoch 2, gen_loss = 0.8142097371154361, disc_loss = 0.09466521493952583
Trained batch 675 in epoch 2, gen_loss = 0.814283720708105, disc_loss = 0.09456370499938418
Trained batch 676 in epoch 2, gen_loss = 0.8144303610000864, disc_loss = 0.09449958329280203
Trained batch 677 in epoch 2, gen_loss = 0.8140899116574487, disc_loss = 0.09450743714578252
Trained batch 678 in epoch 2, gen_loss = 0.8145979031459573, disc_loss = 0.09449755329232723
Trained batch 679 in epoch 2, gen_loss = 0.8143496833741665, disc_loss = 0.09450754943057238
Trained batch 680 in epoch 2, gen_loss = 0.8143324462940339, disc_loss = 0.09441228408815008
Trained batch 681 in epoch 2, gen_loss = 0.8147826031768077, disc_loss = 0.09433981817614429
Trained batch 682 in epoch 2, gen_loss = 0.8147633958438829, disc_loss = 0.09424627696519845
Trained batch 683 in epoch 2, gen_loss = 0.8143104960085356, disc_loss = 0.0944091589966168
Trained batch 684 in epoch 2, gen_loss = 0.8146968205044739, disc_loss = 0.09447868980712047
Trained batch 685 in epoch 2, gen_loss = 0.8146850123958059, disc_loss = 0.0944592413470779
Trained batch 686 in epoch 2, gen_loss = 0.814312479164576, disc_loss = 0.09462432512197388
Trained batch 687 in epoch 2, gen_loss = 0.8145739840300277, disc_loss = 0.09470552111688871
Trained batch 688 in epoch 2, gen_loss = 0.8142918902402, disc_loss = 0.09468190774121504
Trained batch 689 in epoch 2, gen_loss = 0.8142201833534932, disc_loss = 0.0946582907770315
Trained batch 690 in epoch 2, gen_loss = 0.814435323007545, disc_loss = 0.09491523401474772
Trained batch 691 in epoch 2, gen_loss = 0.8143873911114098, disc_loss = 0.09487153701564954
Trained batch 692 in epoch 2, gen_loss = 0.8143098705688768, disc_loss = 0.09493062299949051
Trained batch 693 in epoch 2, gen_loss = 0.8145891820061791, disc_loss = 0.09483707693381294
Trained batch 694 in epoch 2, gen_loss = 0.8146083409408871, disc_loss = 0.09479582748583538
Trained batch 695 in epoch 2, gen_loss = 0.8144632601446804, disc_loss = 0.09472886543993934
Trained batch 696 in epoch 2, gen_loss = 0.814689337651391, disc_loss = 0.09467303610060744
Trained batch 697 in epoch 2, gen_loss = 0.8152321563836155, disc_loss = 0.09460684845362788
Trained batch 698 in epoch 2, gen_loss = 0.8151526254560474, disc_loss = 0.09456661658412184
Trained batch 699 in epoch 2, gen_loss = 0.8149132288779531, disc_loss = 0.09457183028305216
Trained batch 700 in epoch 2, gen_loss = 0.8151172569151782, disc_loss = 0.09457572583991306
Trained batch 701 in epoch 2, gen_loss = 0.8152073375095329, disc_loss = 0.0945152659592699
Trained batch 702 in epoch 2, gen_loss = 0.8156349870507442, disc_loss = 0.09447349854221682
Trained batch 703 in epoch 2, gen_loss = 0.8152319373647597, disc_loss = 0.09457914550677576
Trained batch 704 in epoch 2, gen_loss = 0.8153043536852438, disc_loss = 0.09449236071041078
Trained batch 705 in epoch 2, gen_loss = 0.815868753844888, disc_loss = 0.09455411798233647
Trained batch 706 in epoch 2, gen_loss = 0.8158326789294139, disc_loss = 0.09446566688263054
Trained batch 707 in epoch 2, gen_loss = 0.8157133782903353, disc_loss = 0.09444409578717655
Trained batch 708 in epoch 2, gen_loss = 0.8158760769831277, disc_loss = 0.09438699390739202
Trained batch 709 in epoch 2, gen_loss = 0.8160531613608482, disc_loss = 0.09428645697566615
Trained batch 710 in epoch 2, gen_loss = 0.8158812307858769, disc_loss = 0.09420538571978881
Trained batch 711 in epoch 2, gen_loss = 0.815905373124929, disc_loss = 0.09414406953604494
Trained batch 712 in epoch 2, gen_loss = 0.8160770031797268, disc_loss = 0.0941168869953984
Trained batch 713 in epoch 2, gen_loss = 0.8160836790539637, disc_loss = 0.09406515650049437
Trained batch 714 in epoch 2, gen_loss = 0.815794024142352, disc_loss = 0.09404066759259343
Trained batch 715 in epoch 2, gen_loss = 0.8159264994150434, disc_loss = 0.09393365325681949
Trained batch 716 in epoch 2, gen_loss = 0.8160497507540252, disc_loss = 0.09384448816311368
Trained batch 717 in epoch 2, gen_loss = 0.8165596597789058, disc_loss = 0.09382367911709674
Trained batch 718 in epoch 2, gen_loss = 0.8165952229615876, disc_loss = 0.09373150489866858
Trained batch 719 in epoch 2, gen_loss = 0.8164533264521096, disc_loss = 0.09370813935400091
Trained batch 720 in epoch 2, gen_loss = 0.8165401390207293, disc_loss = 0.09363146158950546
Trained batch 721 in epoch 2, gen_loss = 0.8165916184226562, disc_loss = 0.09353535341800621
Trained batch 722 in epoch 2, gen_loss = 0.8167099807189873, disc_loss = 0.09342600561467156
Trained batch 723 in epoch 2, gen_loss = 0.8167047450802603, disc_loss = 0.09339843825848763
Trained batch 724 in epoch 2, gen_loss = 0.8167767317130648, disc_loss = 0.09340747714684955
Trained batch 725 in epoch 2, gen_loss = 0.816745102364498, disc_loss = 0.09331679099031594
Trained batch 726 in epoch 2, gen_loss = 0.8166365163936248, disc_loss = 0.0932629584787001
Trained batch 727 in epoch 2, gen_loss = 0.8166392535216861, disc_loss = 0.09331478913452804
Trained batch 728 in epoch 2, gen_loss = 0.8169106298595136, disc_loss = 0.09347382044887224
Trained batch 729 in epoch 2, gen_loss = 0.8165198673532433, disc_loss = 0.0937596165983338
Trained batch 730 in epoch 2, gen_loss = 0.8166078417555578, disc_loss = 0.09376111389271578
Trained batch 731 in epoch 2, gen_loss = 0.8165100940345414, disc_loss = 0.09370789472446293
Trained batch 732 in epoch 2, gen_loss = 0.816392943649305, disc_loss = 0.09365188878405671
Trained batch 733 in epoch 2, gen_loss = 0.8161929404459467, disc_loss = 0.09368481946987295
Trained batch 734 in epoch 2, gen_loss = 0.8166379210494813, disc_loss = 0.09368441600707315
Trained batch 735 in epoch 2, gen_loss = 0.8166936200678997, disc_loss = 0.0936181361232783
Trained batch 736 in epoch 2, gen_loss = 0.8162277078046243, disc_loss = 0.0937950489208547
Trained batch 737 in epoch 2, gen_loss = 0.8165257388983316, disc_loss = 0.09377860214414838
Trained batch 738 in epoch 2, gen_loss = 0.8163836481445375, disc_loss = 0.0937916707355877
Trained batch 739 in epoch 2, gen_loss = 0.8165573426195093, disc_loss = 0.09371359295564125
Trained batch 740 in epoch 2, gen_loss = 0.8164526853162428, disc_loss = 0.09367756766371439
Trained batch 741 in epoch 2, gen_loss = 0.8164146810850365, disc_loss = 0.09358380643670972
Trained batch 742 in epoch 2, gen_loss = 0.8166750484969703, disc_loss = 0.09353985917825919
Trained batch 743 in epoch 2, gen_loss = 0.8164440278084047, disc_loss = 0.09349341813339701
Trained batch 744 in epoch 2, gen_loss = 0.8162919905361713, disc_loss = 0.09353469396822604
Trained batch 745 in epoch 2, gen_loss = 0.8165979976628485, disc_loss = 0.09351301105972629
Trained batch 746 in epoch 2, gen_loss = 0.8164639271087596, disc_loss = 0.09351509672476145
Trained batch 747 in epoch 2, gen_loss = 0.8160528136606522, disc_loss = 0.09363271981940909
Trained batch 748 in epoch 2, gen_loss = 0.8159503623226456, disc_loss = 0.0936281555487671
Trained batch 749 in epoch 2, gen_loss = 0.8159192708333334, disc_loss = 0.09361306003356973
Trained batch 750 in epoch 2, gen_loss = 0.8158807094182854, disc_loss = 0.09357704392469397
Trained batch 751 in epoch 2, gen_loss = 0.8157289020241575, disc_loss = 0.09353333983713999
Trained batch 752 in epoch 2, gen_loss = 0.8156334498963983, disc_loss = 0.09363281286159557
Trained batch 753 in epoch 2, gen_loss = 0.8154025038294198, disc_loss = 0.093608897719137
Trained batch 754 in epoch 2, gen_loss = 0.8156586675454449, disc_loss = 0.0935677551337524
Trained batch 755 in epoch 2, gen_loss = 0.8155600711624459, disc_loss = 0.09353412893383946
Trained batch 756 in epoch 2, gen_loss = 0.8157832944566381, disc_loss = 0.09349702930144346
Trained batch 757 in epoch 2, gen_loss = 0.8155369724793295, disc_loss = 0.09349091165873534
Trained batch 758 in epoch 2, gen_loss = 0.8154265875087582, disc_loss = 0.09342492134856338
Trained batch 759 in epoch 2, gen_loss = 0.8155754210133301, disc_loss = 0.09341045141244601
Trained batch 760 in epoch 2, gen_loss = 0.8155389562072954, disc_loss = 0.0933604434428739
Trained batch 761 in epoch 2, gen_loss = 0.8152911325921537, disc_loss = 0.09335867095166656
Trained batch 762 in epoch 2, gen_loss = 0.8157631876740512, disc_loss = 0.09331076947769558
Trained batch 763 in epoch 2, gen_loss = 0.8157016997718062, disc_loss = 0.09324925407128536
Trained batch 764 in epoch 2, gen_loss = 0.8159404602705264, disc_loss = 0.09314401796562415
Trained batch 765 in epoch 2, gen_loss = 0.8161817413241683, disc_loss = 0.09310059903150633
Trained batch 766 in epoch 2, gen_loss = 0.8158033457542181, disc_loss = 0.09320771873040996
Trained batch 767 in epoch 2, gen_loss = 0.8158521191993108, disc_loss = 0.09313440974923044
Trained batch 768 in epoch 2, gen_loss = 0.8160954144128122, disc_loss = 0.09310704255682478
Trained batch 769 in epoch 2, gen_loss = 0.8159944474697113, disc_loss = 0.09305420798648681
Trained batch 770 in epoch 2, gen_loss = 0.8159432244981155, disc_loss = 0.09298104880892233
Trained batch 771 in epoch 2, gen_loss = 0.8160259142286419, disc_loss = 0.09298370818250422
Trained batch 772 in epoch 2, gen_loss = 0.8159574388995053, disc_loss = 0.09291908129649706
Trained batch 773 in epoch 2, gen_loss = 0.815550400844224, disc_loss = 0.09307388451253605
Trained batch 774 in epoch 2, gen_loss = 0.8160382231589287, disc_loss = 0.09339895469647261
Trained batch 775 in epoch 2, gen_loss = 0.8162141198042742, disc_loss = 0.0933508795995707
Trained batch 776 in epoch 2, gen_loss = 0.8159412646539116, disc_loss = 0.09346932149881754
Trained batch 777 in epoch 2, gen_loss = 0.8163028740178037, disc_loss = 0.09351865412992998
Trained batch 778 in epoch 2, gen_loss = 0.8164239810428203, disc_loss = 0.09344836919471641
Trained batch 779 in epoch 2, gen_loss = 0.8162425621197774, disc_loss = 0.09347936796764723
Trained batch 780 in epoch 2, gen_loss = 0.8161948482755205, disc_loss = 0.09348215373702795
Trained batch 781 in epoch 2, gen_loss = 0.8163754165629902, disc_loss = 0.09344639988435084
Trained batch 782 in epoch 2, gen_loss = 0.8163063134117906, disc_loss = 0.09335293336908213
Trained batch 783 in epoch 2, gen_loss = 0.8162650082032291, disc_loss = 0.09326480132437368
Trained batch 784 in epoch 2, gen_loss = 0.8162150991950066, disc_loss = 0.09321654293875975
Trained batch 785 in epoch 2, gen_loss = 0.8161633334693714, disc_loss = 0.0931488311939586
Trained batch 786 in epoch 2, gen_loss = 0.8160742174412728, disc_loss = 0.09310540450994857
Trained batch 787 in epoch 2, gen_loss = 0.8163108264431735, disc_loss = 0.09315516996471598
Trained batch 788 in epoch 2, gen_loss = 0.8162696145484354, disc_loss = 0.09308623607625716
Trained batch 789 in epoch 2, gen_loss = 0.8161432358283031, disc_loss = 0.09305339299165938
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.9328683614730835, disc_loss = 0.010134292766451836
Trained batch 1 in epoch 3, gen_loss = 0.9531323909759521, disc_loss = 0.010402943938970566
Trained batch 2 in epoch 3, gen_loss = 0.8714640935262045, disc_loss = 0.01872778683900833
Trained batch 3 in epoch 3, gen_loss = 0.881814569234848, disc_loss = 0.021020646207034588
Trained batch 4 in epoch 3, gen_loss = 0.8821280002593994, disc_loss = 0.027298982441425323
Trained batch 5 in epoch 3, gen_loss = 0.8600298762321472, disc_loss = 0.029736035813887913
Trained batch 6 in epoch 3, gen_loss = 0.8901492868150983, disc_loss = 0.03169805184006691
Trained batch 7 in epoch 3, gen_loss = 0.8796211779117584, disc_loss = 0.032011575531214476
Trained batch 8 in epoch 3, gen_loss = 0.8541120092074076, disc_loss = 0.038565137734015785
Trained batch 9 in epoch 3, gen_loss = 0.8725604593753815, disc_loss = 0.039994674175977706
Trained batch 10 in epoch 3, gen_loss = 0.8484497016126459, disc_loss = 0.04442317512902347
Trained batch 11 in epoch 3, gen_loss = 0.8644057065248489, disc_loss = 0.04674327000975609
Trained batch 12 in epoch 3, gen_loss = 0.8592496239222013, disc_loss = 0.047321570034210496
Trained batch 13 in epoch 3, gen_loss = 0.8777588052409036, disc_loss = 0.04839746042021683
Trained batch 14 in epoch 3, gen_loss = 0.8548815329869588, disc_loss = 0.06335681503017744
Trained batch 15 in epoch 3, gen_loss = 0.8701570481061935, disc_loss = 0.07377787702716887
Trained batch 16 in epoch 3, gen_loss = 0.8719169953290153, disc_loss = 0.07189911647754557
Trained batch 17 in epoch 3, gen_loss = 0.8572707408004336, disc_loss = 0.07713537787397702
Trained batch 18 in epoch 3, gen_loss = 0.8620308574877287, disc_loss = 0.07777619401091024
Trained batch 19 in epoch 3, gen_loss = 0.8685892730951309, disc_loss = 0.07599297780543565
Trained batch 20 in epoch 3, gen_loss = 0.8646806308201381, disc_loss = 0.07431905202212788
Trained batch 21 in epoch 3, gen_loss = 0.8597365753217177, disc_loss = 0.07389867221089927
Trained batch 22 in epoch 3, gen_loss = 0.8621805387994518, disc_loss = 0.07218677113237588
Trained batch 23 in epoch 3, gen_loss = 0.8553477078676224, disc_loss = 0.07092375416929524
Trained batch 24 in epoch 3, gen_loss = 0.8481444954872132, disc_loss = 0.06993030324578285
Trained batch 25 in epoch 3, gen_loss = 0.8500448442422427, disc_loss = 0.07144968455227521
Trained batch 26 in epoch 3, gen_loss = 0.8455658555030823, disc_loss = 0.07396300868303687
Trained batch 27 in epoch 3, gen_loss = 0.8367052503994533, disc_loss = 0.07570421921887568
Trained batch 28 in epoch 3, gen_loss = 0.8361125136243885, disc_loss = 0.07528493078104381
Trained batch 29 in epoch 3, gen_loss = 0.8350780308246613, disc_loss = 0.07657212230066458
Trained batch 30 in epoch 3, gen_loss = 0.8270650102246192, disc_loss = 0.0773957007594647
Trained batch 31 in epoch 3, gen_loss = 0.8286289870738983, disc_loss = 0.0756311675067991
Trained batch 32 in epoch 3, gen_loss = 0.8311423496766523, disc_loss = 0.0753772875124758
Trained batch 33 in epoch 3, gen_loss = 0.8376570799771477, disc_loss = 0.07485783100128174
Trained batch 34 in epoch 3, gen_loss = 0.8300886120115007, disc_loss = 0.07674556374549865
Trained batch 35 in epoch 3, gen_loss = 0.8278551929526858, disc_loss = 0.07742027524444792
Trained batch 36 in epoch 3, gen_loss = 0.8227558812579593, disc_loss = 0.07863936150396192
Trained batch 37 in epoch 3, gen_loss = 0.8252316854502025, disc_loss = 0.07740641267676103
Trained batch 38 in epoch 3, gen_loss = 0.8263325293858846, disc_loss = 0.07697403106169823
Trained batch 39 in epoch 3, gen_loss = 0.8230976432561874, disc_loss = 0.07597501194104553
Trained batch 40 in epoch 3, gen_loss = 0.8246288881069277, disc_loss = 0.07466437122443827
Trained batch 41 in epoch 3, gen_loss = 0.8326131531170436, disc_loss = 0.07568389372456641
Trained batch 42 in epoch 3, gen_loss = 0.8303537701451501, disc_loss = 0.07586347190446632
Trained batch 43 in epoch 3, gen_loss = 0.828647487542846, disc_loss = 0.07514417484741319
Trained batch 44 in epoch 3, gen_loss = 0.834069303671519, disc_loss = 0.07802577523721589
Trained batch 45 in epoch 3, gen_loss = 0.8325640714686849, disc_loss = 0.07771115531416042
Trained batch 46 in epoch 3, gen_loss = 0.8363384870772667, disc_loss = 0.0775692547730943
Trained batch 47 in epoch 3, gen_loss = 0.8326394719382127, disc_loss = 0.0793961468928804
Trained batch 48 in epoch 3, gen_loss = 0.8289973480360848, disc_loss = 0.0798845041011061
Trained batch 49 in epoch 3, gen_loss = 0.8379268157482147, disc_loss = 0.0818372418731451
Trained batch 50 in epoch 3, gen_loss = 0.837170422077179, disc_loss = 0.0811191724942011
Trained batch 51 in epoch 3, gen_loss = 0.8342002825095103, disc_loss = 0.08094710462655012
Trained batch 52 in epoch 3, gen_loss = 0.8319627923785515, disc_loss = 0.08062670710233022
Trained batch 53 in epoch 3, gen_loss = 0.8295670560112706, disc_loss = 0.08009414202361195
Trained batch 54 in epoch 3, gen_loss = 0.8265941522338174, disc_loss = 0.07963701561093331
Trained batch 55 in epoch 3, gen_loss = 0.8258769703762872, disc_loss = 0.07962549630818623
Trained batch 56 in epoch 3, gen_loss = 0.8275291177264431, disc_loss = 0.08051078459411337
Trained batch 57 in epoch 3, gen_loss = 0.8313934320005877, disc_loss = 0.07958794141124034
Trained batch 58 in epoch 3, gen_loss = 0.8273370518522748, disc_loss = 0.08051046539666289
Trained batch 59 in epoch 3, gen_loss = 0.831715942422549, disc_loss = 0.08338454129795234
Trained batch 60 in epoch 3, gen_loss = 0.8289207522986365, disc_loss = 0.08386840598016489
Trained batch 61 in epoch 3, gen_loss = 0.8269648465418047, disc_loss = 0.08390799345028016
Trained batch 62 in epoch 3, gen_loss = 0.8294851240657625, disc_loss = 0.08492575928805367
Trained batch 63 in epoch 3, gen_loss = 0.825580389238894, disc_loss = 0.08641235588584095
Trained batch 64 in epoch 3, gen_loss = 0.8262588427616999, disc_loss = 0.08583104690680136
Trained batch 65 in epoch 3, gen_loss = 0.8283452725771702, disc_loss = 0.08551179922439835
Trained batch 66 in epoch 3, gen_loss = 0.8293631192463548, disc_loss = 0.08473132350551549
Trained batch 67 in epoch 3, gen_loss = 0.8283029268769657, disc_loss = 0.08415815464275725
Trained batch 68 in epoch 3, gen_loss = 0.82601073945778, disc_loss = 0.08371116458505824
Trained batch 69 in epoch 3, gen_loss = 0.825588402577809, disc_loss = 0.08353793248534203
Trained batch 70 in epoch 3, gen_loss = 0.825332803625456, disc_loss = 0.08494699641432561
Trained batch 71 in epoch 3, gen_loss = 0.8270240268773503, disc_loss = 0.08400235079332358
Trained batch 72 in epoch 3, gen_loss = 0.8232742172397979, disc_loss = 0.08469579136636976
Trained batch 73 in epoch 3, gen_loss = 0.8225847579337455, disc_loss = 0.08414782556025563
Trained batch 74 in epoch 3, gen_loss = 0.8240811014175415, disc_loss = 0.0840463586896658
Trained batch 75 in epoch 3, gen_loss = 0.825096480156246, disc_loss = 0.08367019766745598
Trained batch 76 in epoch 3, gen_loss = 0.8217046431132725, disc_loss = 0.0855039024556225
Trained batch 77 in epoch 3, gen_loss = 0.8228579453932934, disc_loss = 0.08477406311207093
Trained batch 78 in epoch 3, gen_loss = 0.8225154288207428, disc_loss = 0.08412945136144946
Trained batch 79 in epoch 3, gen_loss = 0.8264421209692955, disc_loss = 0.08459851283114403
Trained batch 80 in epoch 3, gen_loss = 0.8252201786747685, disc_loss = 0.08486734815861707
Trained batch 81 in epoch 3, gen_loss = 0.8227596377454153, disc_loss = 0.08600046419788425
Trained batch 82 in epoch 3, gen_loss = 0.8223799617893724, disc_loss = 0.0861043471124876
Trained batch 83 in epoch 3, gen_loss = 0.8237840987387157, disc_loss = 0.08564257978772123
Trained batch 84 in epoch 3, gen_loss = 0.8231945612851311, disc_loss = 0.08520821168580477
Trained batch 85 in epoch 3, gen_loss = 0.8206973055074381, disc_loss = 0.08582442420599766
Trained batch 86 in epoch 3, gen_loss = 0.8232930891815273, disc_loss = 0.08649795110626467
Trained batch 87 in epoch 3, gen_loss = 0.8218163692138412, disc_loss = 0.08669530788690528
Trained batch 88 in epoch 3, gen_loss = 0.820340713088432, disc_loss = 0.08674107996349255
Trained batch 89 in epoch 3, gen_loss = 0.8210644278261396, disc_loss = 0.0870065934335192
Trained batch 90 in epoch 3, gen_loss = 0.821220283979898, disc_loss = 0.0869139501886381
Trained batch 91 in epoch 3, gen_loss = 0.8227504485327265, disc_loss = 0.08613581969605191
Trained batch 92 in epoch 3, gen_loss = 0.82029749308863, disc_loss = 0.0862835543730887
Trained batch 93 in epoch 3, gen_loss = 0.8203888497454055, disc_loss = 0.08604041825821425
Trained batch 94 in epoch 3, gen_loss = 0.8238391524867008, disc_loss = 0.08536077945640212
Trained batch 95 in epoch 3, gen_loss = 0.8223001180837551, disc_loss = 0.08576184980726491
Trained batch 96 in epoch 3, gen_loss = 0.8250182602823395, disc_loss = 0.08572669369504624
Trained batch 97 in epoch 3, gen_loss = 0.8236470946243831, disc_loss = 0.08519856301041281
Trained batch 98 in epoch 3, gen_loss = 0.824176757022588, disc_loss = 0.08456735000616372
Trained batch 99 in epoch 3, gen_loss = 0.8252359247207641, disc_loss = 0.08397519536316395
Trained batch 100 in epoch 3, gen_loss = 0.8255956715876513, disc_loss = 0.08347805419770798
Trained batch 101 in epoch 3, gen_loss = 0.8268995121413586, disc_loss = 0.08277357632622999
Trained batch 102 in epoch 3, gen_loss = 0.8281919238636795, disc_loss = 0.08255248809757743
Trained batch 103 in epoch 3, gen_loss = 0.8262323244259908, disc_loss = 0.08327251468570186
Trained batch 104 in epoch 3, gen_loss = 0.8264870132718768, disc_loss = 0.0834773087430568
Trained batch 105 in epoch 3, gen_loss = 0.827631487598959, disc_loss = 0.08330968763890131
Trained batch 106 in epoch 3, gen_loss = 0.8265650968685329, disc_loss = 0.08282143918571071
Trained batch 107 in epoch 3, gen_loss = 0.8260139955414666, disc_loss = 0.08232290497808545
Trained batch 108 in epoch 3, gen_loss = 0.8246682040188291, disc_loss = 0.08204274026489039
Trained batch 109 in epoch 3, gen_loss = 0.8270125410773538, disc_loss = 0.08259894925762307
Trained batch 110 in epoch 3, gen_loss = 0.8270959918563431, disc_loss = 0.0821238111134048
Trained batch 111 in epoch 3, gen_loss = 0.8243798815778324, disc_loss = 0.08322392264381051
Trained batch 112 in epoch 3, gen_loss = 0.8245306015014648, disc_loss = 0.08318985174451254
Trained batch 113 in epoch 3, gen_loss = 0.8284477005925095, disc_loss = 0.08439551274243154
Trained batch 114 in epoch 3, gen_loss = 0.8289307874181996, disc_loss = 0.08398448844318805
Trained batch 115 in epoch 3, gen_loss = 0.8264017171900848, disc_loss = 0.0843767100495511
Trained batch 116 in epoch 3, gen_loss = 0.8281486355341398, disc_loss = 0.08429810958795059
Trained batch 117 in epoch 3, gen_loss = 0.8298402565010523, disc_loss = 0.08443989200612247
Trained batch 118 in epoch 3, gen_loss = 0.8294551172176329, disc_loss = 0.08409961669885811
Trained batch 119 in epoch 3, gen_loss = 0.8296556572119395, disc_loss = 0.0838483319307367
Trained batch 120 in epoch 3, gen_loss = 0.8294650567464592, disc_loss = 0.08359240937577792
Trained batch 121 in epoch 3, gen_loss = 0.8280029761009529, disc_loss = 0.08392229535784877
Trained batch 122 in epoch 3, gen_loss = 0.8316769973049319, disc_loss = 0.08587047899883937
Trained batch 123 in epoch 3, gen_loss = 0.8314191694221189, disc_loss = 0.08543081218076329
Trained batch 124 in epoch 3, gen_loss = 0.8292563953399659, disc_loss = 0.08576776334643364
Trained batch 125 in epoch 3, gen_loss = 0.8295737727293893, disc_loss = 0.08528370463422366
Trained batch 126 in epoch 3, gen_loss = 0.8317272489465127, disc_loss = 0.08507645652284772
Trained batch 127 in epoch 3, gen_loss = 0.8322594044730067, disc_loss = 0.0845360444218386
Trained batch 128 in epoch 3, gen_loss = 0.830241319745086, disc_loss = 0.0851628234277862
Trained batch 129 in epoch 3, gen_loss = 0.8297417833254888, disc_loss = 0.08503923843113276
Trained batch 130 in epoch 3, gen_loss = 0.8300658373432305, disc_loss = 0.08480338743738546
Trained batch 131 in epoch 3, gen_loss = 0.8314058934197281, disc_loss = 0.08466260600835085
Trained batch 132 in epoch 3, gen_loss = 0.8306282445004112, disc_loss = 0.08468379357591607
Trained batch 133 in epoch 3, gen_loss = 0.8290624805350801, disc_loss = 0.08524601225421499
Trained batch 134 in epoch 3, gen_loss = 0.8290011238168787, disc_loss = 0.08486445504758093
Trained batch 135 in epoch 3, gen_loss = 0.8289936013958034, disc_loss = 0.08519086518379695
Trained batch 136 in epoch 3, gen_loss = 0.8312548194488469, disc_loss = 0.08492209264723054
Trained batch 137 in epoch 3, gen_loss = 0.8300704195879508, disc_loss = 0.08493435207376446
Trained batch 138 in epoch 3, gen_loss = 0.8287780636506115, disc_loss = 0.08497271625150879
Trained batch 139 in epoch 3, gen_loss = 0.8300659545830318, disc_loss = 0.08455137243228299
Trained batch 140 in epoch 3, gen_loss = 0.8325215062351091, disc_loss = 0.08431407095904046
Trained batch 141 in epoch 3, gen_loss = 0.8313645090855343, disc_loss = 0.08440575418128095
Trained batch 142 in epoch 3, gen_loss = 0.8291736461899497, disc_loss = 0.08587749224234294
Trained batch 143 in epoch 3, gen_loss = 0.8296137530770566, disc_loss = 0.08582666588740216
Trained batch 144 in epoch 3, gen_loss = 0.8309659657807186, disc_loss = 0.08600407206806643
Trained batch 145 in epoch 3, gen_loss = 0.8302695061246009, disc_loss = 0.08567213223711269
Trained batch 146 in epoch 3, gen_loss = 0.8290470834492015, disc_loss = 0.08561474700667421
Trained batch 147 in epoch 3, gen_loss = 0.8296975046396255, disc_loss = 0.0851540403767816
Trained batch 148 in epoch 3, gen_loss = 0.8302843718720763, disc_loss = 0.08476623497753336
Trained batch 149 in epoch 3, gen_loss = 0.8286391770839692, disc_loss = 0.08506750151515007
Trained batch 150 in epoch 3, gen_loss = 0.8307723971392145, disc_loss = 0.0848221695975752
Trained batch 151 in epoch 3, gen_loss = 0.8311196228391245, disc_loss = 0.08435699646361172
Trained batch 152 in epoch 3, gen_loss = 0.8317712568769268, disc_loss = 0.08392814045248467
Trained batch 153 in epoch 3, gen_loss = 0.8310884214066839, disc_loss = 0.08360316304417399
Trained batch 154 in epoch 3, gen_loss = 0.8309277257611675, disc_loss = 0.08328179498353312
Trained batch 155 in epoch 3, gen_loss = 0.8333430542395666, disc_loss = 0.08313358971514763
Trained batch 156 in epoch 3, gen_loss = 0.8329471277583177, disc_loss = 0.08293574811167019
Trained batch 157 in epoch 3, gen_loss = 0.831689096704314, disc_loss = 0.08278042816002912
Trained batch 158 in epoch 3, gen_loss = 0.8329960310234213, disc_loss = 0.08237817797973845
Trained batch 159 in epoch 3, gen_loss = 0.8323439333587885, disc_loss = 0.08228677975712344
Trained batch 160 in epoch 3, gen_loss = 0.831736299562158, disc_loss = 0.08227417602996279
Trained batch 161 in epoch 3, gen_loss = 0.8325390061478556, disc_loss = 0.08213004974625361
Trained batch 162 in epoch 3, gen_loss = 0.8330411428322821, disc_loss = 0.08188652470022258
Trained batch 163 in epoch 3, gen_loss = 0.8336104292695116, disc_loss = 0.0814665479233443
Trained batch 164 in epoch 3, gen_loss = 0.8341085426735155, disc_loss = 0.08109305543317036
Trained batch 165 in epoch 3, gen_loss = 0.8336462299507784, disc_loss = 0.0808852148825774
Trained batch 166 in epoch 3, gen_loss = 0.8350929278813436, disc_loss = 0.08061242466625161
Trained batch 167 in epoch 3, gen_loss = 0.8370623631136758, disc_loss = 0.08063884280688528
Trained batch 168 in epoch 3, gen_loss = 0.834953063514811, disc_loss = 0.08229543671518917
Trained batch 169 in epoch 3, gen_loss = 0.8347616032642476, disc_loss = 0.08210057442569557
Trained batch 170 in epoch 3, gen_loss = 0.8365227951292407, disc_loss = 0.08230702611154805
Trained batch 171 in epoch 3, gen_loss = 0.835531399173792, disc_loss = 0.08244429049515274
Trained batch 172 in epoch 3, gen_loss = 0.8359187949944094, disc_loss = 0.08209958331756337
Trained batch 173 in epoch 3, gen_loss = 0.8370873905803965, disc_loss = 0.0820678370126962
Trained batch 174 in epoch 3, gen_loss = 0.8361518030507223, disc_loss = 0.08197948021015951
Trained batch 175 in epoch 3, gen_loss = 0.8367435886439952, disc_loss = 0.08175157143374566
Trained batch 176 in epoch 3, gen_loss = 0.8357450424951348, disc_loss = 0.08173160727982973
Trained batch 177 in epoch 3, gen_loss = 0.837188959958848, disc_loss = 0.0816495586134326
Trained batch 178 in epoch 3, gen_loss = 0.8378953908741807, disc_loss = 0.08145715813958944
Trained batch 179 in epoch 3, gen_loss = 0.8383576480878724, disc_loss = 0.08120941862774392
Trained batch 180 in epoch 3, gen_loss = 0.837749570608139, disc_loss = 0.08135354267278923
Trained batch 181 in epoch 3, gen_loss = 0.8366531387462721, disc_loss = 0.08146040746942163
Trained batch 182 in epoch 3, gen_loss = 0.8363227073937818, disc_loss = 0.08157092621397288
Trained batch 183 in epoch 3, gen_loss = 0.8356811315145182, disc_loss = 0.08154861498927779
Trained batch 184 in epoch 3, gen_loss = 0.8362882519090498, disc_loss = 0.08129934376055324
Trained batch 185 in epoch 3, gen_loss = 0.8357899594371037, disc_loss = 0.08135270525110505
Trained batch 186 in epoch 3, gen_loss = 0.8344798268162631, disc_loss = 0.08143711968120884
Trained batch 187 in epoch 3, gen_loss = 0.8355374908510674, disc_loss = 0.08118310280917014
Trained batch 188 in epoch 3, gen_loss = 0.8356981581796414, disc_loss = 0.08091257630339849
Trained batch 189 in epoch 3, gen_loss = 0.837287363409996, disc_loss = 0.08066835946060325
Trained batch 190 in epoch 3, gen_loss = 0.8364902542835755, disc_loss = 0.08051172095346044
Trained batch 191 in epoch 3, gen_loss = 0.8363110350134472, disc_loss = 0.08069556925814443
Trained batch 192 in epoch 3, gen_loss = 0.8357756157922004, disc_loss = 0.08078811149272122
Trained batch 193 in epoch 3, gen_loss = 0.8360197736123174, disc_loss = 0.08066536967652206
Trained batch 194 in epoch 3, gen_loss = 0.8359422706640683, disc_loss = 0.08050450451003435
Trained batch 195 in epoch 3, gen_loss = 0.8358593113264259, disc_loss = 0.08021840082044351
Trained batch 196 in epoch 3, gen_loss = 0.8367983482513331, disc_loss = 0.07993978461921972
Trained batch 197 in epoch 3, gen_loss = 0.8378013605722273, disc_loss = 0.0796359725851528
Trained batch 198 in epoch 3, gen_loss = 0.8365252184208913, disc_loss = 0.07970735205608846
Trained batch 199 in epoch 3, gen_loss = 0.8377863608300686, disc_loss = 0.07959760441910475
Trained batch 200 in epoch 3, gen_loss = 0.8375654681701565, disc_loss = 0.07944660049524918
Trained batch 201 in epoch 3, gen_loss = 0.8377786404130483, disc_loss = 0.07933594394788736
Trained batch 202 in epoch 3, gen_loss = 0.838309336325218, disc_loss = 0.07916792522051505
Trained batch 203 in epoch 3, gen_loss = 0.8390305335907375, disc_loss = 0.07903598471289026
Trained batch 204 in epoch 3, gen_loss = 0.8386614588702598, disc_loss = 0.0791372073814273
Trained batch 205 in epoch 3, gen_loss = 0.8391544493367371, disc_loss = 0.07886759634355753
Trained batch 206 in epoch 3, gen_loss = 0.8400393112558098, disc_loss = 0.07912615979549245
Trained batch 207 in epoch 3, gen_loss = 0.8394151824311569, disc_loss = 0.0792768835582627
Trained batch 208 in epoch 3, gen_loss = 0.8402657595832953, disc_loss = 0.07907003766308988
Trained batch 209 in epoch 3, gen_loss = 0.8393989663748515, disc_loss = 0.07923339459424218
Trained batch 210 in epoch 3, gen_loss = 0.8409522086805642, disc_loss = 0.07992038260968799
Trained batch 211 in epoch 3, gen_loss = 0.8406438485912557, disc_loss = 0.0797629304502581
Trained batch 212 in epoch 3, gen_loss = 0.8397004110432567, disc_loss = 0.0798643909071183
Trained batch 213 in epoch 3, gen_loss = 0.8399868088069363, disc_loss = 0.08008948453728144
Trained batch 214 in epoch 3, gen_loss = 0.8394788319288298, disc_loss = 0.08007408835773551
Trained batch 215 in epoch 3, gen_loss = 0.8401572763643883, disc_loss = 0.0805663482794814
Trained batch 216 in epoch 3, gen_loss = 0.8391338832642076, disc_loss = 0.08070857484271313
Trained batch 217 in epoch 3, gen_loss = 0.838747698642792, disc_loss = 0.0806295546156209
Trained batch 218 in epoch 3, gen_loss = 0.8392377649540226, disc_loss = 0.08055985332402872
Trained batch 219 in epoch 3, gen_loss = 0.8392622296105732, disc_loss = 0.08057369208386676
Trained batch 220 in epoch 3, gen_loss = 0.8375032678988185, disc_loss = 0.08120962375210286
Trained batch 221 in epoch 3, gen_loss = 0.8389452338755667, disc_loss = 0.08162223552311729
Trained batch 222 in epoch 3, gen_loss = 0.8381498068437448, disc_loss = 0.08163592835362049
Trained batch 223 in epoch 3, gen_loss = 0.8372076148433345, disc_loss = 0.08191965335364719
Trained batch 224 in epoch 3, gen_loss = 0.838287574450175, disc_loss = 0.08309124576962656
Trained batch 225 in epoch 3, gen_loss = 0.8373266202686107, disc_loss = 0.08323792867214147
Trained batch 226 in epoch 3, gen_loss = 0.8371099325528754, disc_loss = 0.08312142183716996
Trained batch 227 in epoch 3, gen_loss = 0.8379092051794654, disc_loss = 0.08295720787473808
Trained batch 228 in epoch 3, gen_loss = 0.8370444136936072, disc_loss = 0.08299378668035352
Trained batch 229 in epoch 3, gen_loss = 0.8366986992566482, disc_loss = 0.08295874493196606
Trained batch 230 in epoch 3, gen_loss = 0.835469109155399, disc_loss = 0.083005647295965
Trained batch 231 in epoch 3, gen_loss = 0.8358194278231983, disc_loss = 0.08310503818913652
Trained batch 232 in epoch 3, gen_loss = 0.8350209652610091, disc_loss = 0.08322114952692018
Trained batch 233 in epoch 3, gen_loss = 0.8349269944378453, disc_loss = 0.08324208111764911
Trained batch 234 in epoch 3, gen_loss = 0.8349376719048682, disc_loss = 0.08299593933005917
Trained batch 235 in epoch 3, gen_loss = 0.8342655169761787, disc_loss = 0.08281343761373754
Trained batch 236 in epoch 3, gen_loss = 0.8343560974809188, disc_loss = 0.08277823181453511
Trained batch 237 in epoch 3, gen_loss = 0.8344896468294769, disc_loss = 0.08280496978193146
Trained batch 238 in epoch 3, gen_loss = 0.8333656032215102, disc_loss = 0.08327849492602143
Trained batch 239 in epoch 3, gen_loss = 0.8330324709415435, disc_loss = 0.08344794741133228
Trained batch 240 in epoch 3, gen_loss = 0.8339553215691657, disc_loss = 0.08331904709880159
Trained batch 241 in epoch 3, gen_loss = 0.8337583741373267, disc_loss = 0.08318683786379281
Trained batch 242 in epoch 3, gen_loss = 0.8335573293054055, disc_loss = 0.08307896538756389
Trained batch 243 in epoch 3, gen_loss = 0.8337551152608433, disc_loss = 0.0828816617999348
Trained batch 244 in epoch 3, gen_loss = 0.8343427881902578, disc_loss = 0.08277220555334067
Trained batch 245 in epoch 3, gen_loss = 0.8339973135692317, disc_loss = 0.08258033525274415
Trained batch 246 in epoch 3, gen_loss = 0.8335411514830493, disc_loss = 0.08243518243902005
Trained batch 247 in epoch 3, gen_loss = 0.8334778614582554, disc_loss = 0.0824266889906158
Trained batch 248 in epoch 3, gen_loss = 0.8336891484069058, disc_loss = 0.08226935274854123
Trained batch 249 in epoch 3, gen_loss = 0.833387597322464, disc_loss = 0.08210400491580368
Trained batch 250 in epoch 3, gen_loss = 0.8325390761117061, disc_loss = 0.08209390842923486
Trained batch 251 in epoch 3, gen_loss = 0.8320669529456941, disc_loss = 0.08207750651201913
Trained batch 252 in epoch 3, gen_loss = 0.8330374298830748, disc_loss = 0.08211651176081698
Trained batch 253 in epoch 3, gen_loss = 0.8323380681942767, disc_loss = 0.08246756963593167
Trained batch 254 in epoch 3, gen_loss = 0.832468277800317, disc_loss = 0.082282619875874
Trained batch 255 in epoch 3, gen_loss = 0.8319570894818753, disc_loss = 0.08215558383017196
Trained batch 256 in epoch 3, gen_loss = 0.8334665606921748, disc_loss = 0.08262465058931001
Trained batch 257 in epoch 3, gen_loss = 0.8331905986911566, disc_loss = 0.0827343657345677
Trained batch 258 in epoch 3, gen_loss = 0.8326783525437462, disc_loss = 0.08268075965301756
Trained batch 259 in epoch 3, gen_loss = 0.8331299227017622, disc_loss = 0.08264466406276019
Trained batch 260 in epoch 3, gen_loss = 0.8323243125645137, disc_loss = 0.08290596343077349
Trained batch 261 in epoch 3, gen_loss = 0.8307556542958922, disc_loss = 0.08371334275202329
Trained batch 262 in epoch 3, gen_loss = 0.8320707142806325, disc_loss = 0.08407404137414104
Trained batch 263 in epoch 3, gen_loss = 0.8311369844684096, disc_loss = 0.08412476865729938
Trained batch 264 in epoch 3, gen_loss = 0.8316952800975655, disc_loss = 0.0840176296367679
Trained batch 265 in epoch 3, gen_loss = 0.8314746760560158, disc_loss = 0.08407888541530285
Trained batch 266 in epoch 3, gen_loss = 0.8307197760330157, disc_loss = 0.08415974321869317
Trained batch 267 in epoch 3, gen_loss = 0.8316711522082785, disc_loss = 0.08395166198528413
Trained batch 268 in epoch 3, gen_loss = 0.8312465554054785, disc_loss = 0.0838464882785669
Trained batch 269 in epoch 3, gen_loss = 0.8316205930930597, disc_loss = 0.08367305051328408
Trained batch 270 in epoch 3, gen_loss = 0.8309875206533833, disc_loss = 0.08355231821963158
Trained batch 271 in epoch 3, gen_loss = 0.8308566877728, disc_loss = 0.08341234974111156
Trained batch 272 in epoch 3, gen_loss = 0.8306654732087593, disc_loss = 0.08319490637302726
Trained batch 273 in epoch 3, gen_loss = 0.830775976507333, disc_loss = 0.08302812257536897
Trained batch 274 in epoch 3, gen_loss = 0.8324648344516754, disc_loss = 0.08379308343949643
Trained batch 275 in epoch 3, gen_loss = 0.8316958074768385, disc_loss = 0.08433539729119967
Trained batch 276 in epoch 3, gen_loss = 0.8324696650789103, disc_loss = 0.08432277631929097
Trained batch 277 in epoch 3, gen_loss = 0.8322635712169058, disc_loss = 0.08418456929662138
Trained batch 278 in epoch 3, gen_loss = 0.832289021822714, disc_loss = 0.08396897523406906
Trained batch 279 in epoch 3, gen_loss = 0.8319931182478155, disc_loss = 0.08377198768180928
Trained batch 280 in epoch 3, gen_loss = 0.8324245240976802, disc_loss = 0.08374393365123836
Trained batch 281 in epoch 3, gen_loss = 0.8321988938759405, disc_loss = 0.08384772239200083
Trained batch 282 in epoch 3, gen_loss = 0.8327692743956832, disc_loss = 0.083638722323829
Trained batch 283 in epoch 3, gen_loss = 0.8334313946920382, disc_loss = 0.08365617574743507
Trained batch 284 in epoch 3, gen_loss = 0.8332235778632917, disc_loss = 0.08349403654339543
Trained batch 285 in epoch 3, gen_loss = 0.8328350472908753, disc_loss = 0.08335545118833027
Trained batch 286 in epoch 3, gen_loss = 0.832993318914121, disc_loss = 0.08319926198623841
Trained batch 287 in epoch 3, gen_loss = 0.8338134434695045, disc_loss = 0.08295480745275402
Trained batch 288 in epoch 3, gen_loss = 0.8345630330816685, disc_loss = 0.08308671552778116
Trained batch 289 in epoch 3, gen_loss = 0.8336888616455013, disc_loss = 0.08343981241100822
Trained batch 290 in epoch 3, gen_loss = 0.8337995263514241, disc_loss = 0.08331332291729261
Trained batch 291 in epoch 3, gen_loss = 0.8344994623162975, disc_loss = 0.08316490725193122
Trained batch 292 in epoch 3, gen_loss = 0.8347029192659229, disc_loss = 0.08294315849758252
Trained batch 293 in epoch 3, gen_loss = 0.8346699473201012, disc_loss = 0.08294715423162291
Trained batch 294 in epoch 3, gen_loss = 0.8362841894060878, disc_loss = 0.08348039408861581
Trained batch 295 in epoch 3, gen_loss = 0.8366697256428164, disc_loss = 0.08324097014170743
Trained batch 296 in epoch 3, gen_loss = 0.8360087643769454, disc_loss = 0.0832423718320049
Trained batch 297 in epoch 3, gen_loss = 0.835338602630084, disc_loss = 0.08353296537639811
Trained batch 298 in epoch 3, gen_loss = 0.8358023658045957, disc_loss = 0.083382736147073
Trained batch 299 in epoch 3, gen_loss = 0.8369651870926221, disc_loss = 0.08356468773446978
Trained batch 300 in epoch 3, gen_loss = 0.8371998603359805, disc_loss = 0.08377600767250572
Trained batch 301 in epoch 3, gen_loss = 0.8372846578328025, disc_loss = 0.08422378269610124
Trained batch 302 in epoch 3, gen_loss = 0.8376582246212283, disc_loss = 0.08437496730166398
Trained batch 303 in epoch 3, gen_loss = 0.8382735569030046, disc_loss = 0.08430658831371386
Trained batch 304 in epoch 3, gen_loss = 0.8388374136119593, disc_loss = 0.08453736580358666
Trained batch 305 in epoch 3, gen_loss = 0.8385019998729618, disc_loss = 0.0843657397153769
Trained batch 306 in epoch 3, gen_loss = 0.838257291709173, disc_loss = 0.08438867532287145
Trained batch 307 in epoch 3, gen_loss = 0.837834922814524, disc_loss = 0.08433105327588107
Trained batch 308 in epoch 3, gen_loss = 0.8375836480589747, disc_loss = 0.08426952449164826
Trained batch 309 in epoch 3, gen_loss = 0.8373884332756842, disc_loss = 0.08408079139227348
Trained batch 310 in epoch 3, gen_loss = 0.8376757915571955, disc_loss = 0.08407225272052253
Trained batch 311 in epoch 3, gen_loss = 0.8375590983300637, disc_loss = 0.08399524037332202
Trained batch 312 in epoch 3, gen_loss = 0.8373483911680337, disc_loss = 0.08379559436985574
Trained batch 313 in epoch 3, gen_loss = 0.836902334906493, disc_loss = 0.08377625464882915
Trained batch 314 in epoch 3, gen_loss = 0.8378764558406103, disc_loss = 0.08399457239974585
Trained batch 315 in epoch 3, gen_loss = 0.8377778836632077, disc_loss = 0.08402529596115309
Trained batch 316 in epoch 3, gen_loss = 0.8381482017717151, disc_loss = 0.08406973892546697
Trained batch 317 in epoch 3, gen_loss = 0.838031697291998, disc_loss = 0.0838838071363199
Trained batch 318 in epoch 3, gen_loss = 0.8378483745558508, disc_loss = 0.08380014047925842
Trained batch 319 in epoch 3, gen_loss = 0.8378148431889713, disc_loss = 0.08371561565727462
Trained batch 320 in epoch 3, gen_loss = 0.8384261059798184, disc_loss = 0.08358950139171331
Trained batch 321 in epoch 3, gen_loss = 0.837966048476859, disc_loss = 0.0835342476786525
Trained batch 322 in epoch 3, gen_loss = 0.8376213230031193, disc_loss = 0.08340450451527678
Trained batch 323 in epoch 3, gen_loss = 0.8382534759096157, disc_loss = 0.08327557078999594
Trained batch 324 in epoch 3, gen_loss = 0.8376933856193836, disc_loss = 0.08337521618661972
Trained batch 325 in epoch 3, gen_loss = 0.8371417245433375, disc_loss = 0.08335171024275063
Trained batch 326 in epoch 3, gen_loss = 0.8366070859111413, disc_loss = 0.0832427808821247
Trained batch 327 in epoch 3, gen_loss = 0.8373973185151089, disc_loss = 0.083232901800174
Trained batch 328 in epoch 3, gen_loss = 0.8374636127050162, disc_loss = 0.083059653535055
Trained batch 329 in epoch 3, gen_loss = 0.8374349611275124, disc_loss = 0.08294494202586286
Trained batch 330 in epoch 3, gen_loss = 0.8379243391698221, disc_loss = 0.08280178755690594
Trained batch 331 in epoch 3, gen_loss = 0.8377948170864439, disc_loss = 0.08259838500273335
Trained batch 332 in epoch 3, gen_loss = 0.8371837046948282, disc_loss = 0.0826232861503735
Trained batch 333 in epoch 3, gen_loss = 0.8378401403120178, disc_loss = 0.082441821593992
Trained batch 334 in epoch 3, gen_loss = 0.8383531667403321, disc_loss = 0.08228373918960344
Trained batch 335 in epoch 3, gen_loss = 0.8377400795441299, disc_loss = 0.08229733258485794
Trained batch 336 in epoch 3, gen_loss = 0.8378867327459488, disc_loss = 0.08224205873928721
Trained batch 337 in epoch 3, gen_loss = 0.8376095149467683, disc_loss = 0.08207581611625718
Trained batch 338 in epoch 3, gen_loss = 0.8378276008244461, disc_loss = 0.08194842904388552
Trained batch 339 in epoch 3, gen_loss = 0.8379191131276242, disc_loss = 0.08182007956921178
Trained batch 340 in epoch 3, gen_loss = 0.8383264848388885, disc_loss = 0.08161233187464675
Trained batch 341 in epoch 3, gen_loss = 0.8387299257586573, disc_loss = 0.08144739360619359
Trained batch 342 in epoch 3, gen_loss = 0.8384934833202695, disc_loss = 0.08129169983088796
Trained batch 343 in epoch 3, gen_loss = 0.8384055213699507, disc_loss = 0.08113826164802493
Trained batch 344 in epoch 3, gen_loss = 0.8396868618502134, disc_loss = 0.08112607018455215
Trained batch 345 in epoch 3, gen_loss = 0.8389305125254427, disc_loss = 0.08145109774017265
Trained batch 346 in epoch 3, gen_loss = 0.8387726188908393, disc_loss = 0.08141046095779031
Trained batch 347 in epoch 3, gen_loss = 0.839338137243671, disc_loss = 0.0812318138457064
Trained batch 348 in epoch 3, gen_loss = 0.8399198254234128, disc_loss = 0.08104139823135639
Trained batch 349 in epoch 3, gen_loss = 0.8401943555048533, disc_loss = 0.08088945434561798
Trained batch 350 in epoch 3, gen_loss = 0.839601302163893, disc_loss = 0.08085592353233585
Trained batch 351 in epoch 3, gen_loss = 0.8396647271954201, disc_loss = 0.08070642433912409
Trained batch 352 in epoch 3, gen_loss = 0.8394901071155375, disc_loss = 0.08062556523713613
Trained batch 353 in epoch 3, gen_loss = 0.8390403138210545, disc_loss = 0.08068166787362537
Trained batch 354 in epoch 3, gen_loss = 0.8389206756168688, disc_loss = 0.0805683384741276
Trained batch 355 in epoch 3, gen_loss = 0.8389527182398218, disc_loss = 0.08038384798820015
Trained batch 356 in epoch 3, gen_loss = 0.8389093180497488, disc_loss = 0.08026704319207524
Trained batch 357 in epoch 3, gen_loss = 0.8386383358826185, disc_loss = 0.08011383824206514
Trained batch 358 in epoch 3, gen_loss = 0.8375760164931624, disc_loss = 0.08051677972524528
Trained batch 359 in epoch 3, gen_loss = 0.8388037639359633, disc_loss = 0.0807093712889279
Trained batch 360 in epoch 3, gen_loss = 0.8398204045447616, disc_loss = 0.08058353000348872
Trained batch 361 in epoch 3, gen_loss = 0.8398598792309261, disc_loss = 0.08052596420780318
Trained batch 362 in epoch 3, gen_loss = 0.8397734093764597, disc_loss = 0.08039578067564686
Trained batch 363 in epoch 3, gen_loss = 0.8402284692440715, disc_loss = 0.08026965515902983
Trained batch 364 in epoch 3, gen_loss = 0.839723121058451, disc_loss = 0.08032203405227971
Trained batch 365 in epoch 3, gen_loss = 0.8392534426164105, disc_loss = 0.08025017499547106
Trained batch 366 in epoch 3, gen_loss = 0.8389981644842215, disc_loss = 0.08026524727316497
Trained batch 367 in epoch 3, gen_loss = 0.838934467619528, disc_loss = 0.08016393215992772
Trained batch 368 in epoch 3, gen_loss = 0.8387421859796778, disc_loss = 0.08005255007192613
Trained batch 369 in epoch 3, gen_loss = 0.8382033089528212, disc_loss = 0.08013991267244155
Trained batch 370 in epoch 3, gen_loss = 0.8384724583105257, disc_loss = 0.08015395677585727
Trained batch 371 in epoch 3, gen_loss = 0.8384408277048859, disc_loss = 0.08008776395581663
Trained batch 372 in epoch 3, gen_loss = 0.838686711906428, disc_loss = 0.07993668318543853
Trained batch 373 in epoch 3, gen_loss = 0.8382420405187708, disc_loss = 0.07983658742408621
Trained batch 374 in epoch 3, gen_loss = 0.8377542472680409, disc_loss = 0.07996423936635255
Trained batch 375 in epoch 3, gen_loss = 0.8385878714950795, disc_loss = 0.08017656096861639
Trained batch 376 in epoch 3, gen_loss = 0.8389346557681693, disc_loss = 0.08000767243586342
Trained batch 377 in epoch 3, gen_loss = 0.8384435877755836, disc_loss = 0.07998598225799108
Trained batch 378 in epoch 3, gen_loss = 0.8386080528469387, disc_loss = 0.07984887593054756
Trained batch 379 in epoch 3, gen_loss = 0.8392776629642437, disc_loss = 0.08033921638944823
Trained batch 380 in epoch 3, gen_loss = 0.8382576872983317, disc_loss = 0.08071072754301033
Trained batch 381 in epoch 3, gen_loss = 0.8378133876785558, disc_loss = 0.08071401932505959
Trained batch 382 in epoch 3, gen_loss = 0.8376614231976143, disc_loss = 0.08060639290085583
Trained batch 383 in epoch 3, gen_loss = 0.8377972807114323, disc_loss = 0.0807751506290515
Trained batch 384 in epoch 3, gen_loss = 0.8377113831507695, disc_loss = 0.08074236327129138
Trained batch 385 in epoch 3, gen_loss = 0.8374245106556255, disc_loss = 0.08098288081885542
Trained batch 386 in epoch 3, gen_loss = 0.8372249447714143, disc_loss = 0.08114242065428379
Trained batch 387 in epoch 3, gen_loss = 0.8372068007275001, disc_loss = 0.08103484500766031
Trained batch 388 in epoch 3, gen_loss = 0.8371526548366007, disc_loss = 0.08104591008160829
Trained batch 389 in epoch 3, gen_loss = 0.837053702886288, disc_loss = 0.08096748342833075
Trained batch 390 in epoch 3, gen_loss = 0.8380206928533667, disc_loss = 0.081043487359934
Trained batch 391 in epoch 3, gen_loss = 0.8373250442804122, disc_loss = 0.08131493967054981
Trained batch 392 in epoch 3, gen_loss = 0.8374393832592564, disc_loss = 0.08128313819519967
Trained batch 393 in epoch 3, gen_loss = 0.8376572769002866, disc_loss = 0.08141866841396024
Trained batch 394 in epoch 3, gen_loss = 0.8374465521377853, disc_loss = 0.08133558452459454
Trained batch 395 in epoch 3, gen_loss = 0.8374525618673575, disc_loss = 0.0811986300619225
Trained batch 396 in epoch 3, gen_loss = 0.8378488693189261, disc_loss = 0.08128937087737267
Trained batch 397 in epoch 3, gen_loss = 0.8371055542524136, disc_loss = 0.08164077469068182
Trained batch 398 in epoch 3, gen_loss = 0.8371894488059787, disc_loss = 0.08161716271229182
Trained batch 399 in epoch 3, gen_loss = 0.8371192565560341, disc_loss = 0.0815342735289596
Trained batch 400 in epoch 3, gen_loss = 0.8369833667973925, disc_loss = 0.08143425320142746
Trained batch 401 in epoch 3, gen_loss = 0.8375800836145582, disc_loss = 0.08143261084055055
Trained batch 402 in epoch 3, gen_loss = 0.8370254745258587, disc_loss = 0.08146402518734078
Trained batch 403 in epoch 3, gen_loss = 0.8382184424317709, disc_loss = 0.0815257403681442
Trained batch 404 in epoch 3, gen_loss = 0.8378517225936607, disc_loss = 0.08148102325927696
Trained batch 405 in epoch 3, gen_loss = 0.8375148758512413, disc_loss = 0.08141052531849208
Trained batch 406 in epoch 3, gen_loss = 0.8378653416469584, disc_loss = 0.08130409398072694
Trained batch 407 in epoch 3, gen_loss = 0.8376657154922392, disc_loss = 0.08122281391200993
Trained batch 408 in epoch 3, gen_loss = 0.8376967407088991, disc_loss = 0.08113681002859309
Trained batch 409 in epoch 3, gen_loss = 0.8373167394137964, disc_loss = 0.08125195318560412
Trained batch 410 in epoch 3, gen_loss = 0.8377353415582012, disc_loss = 0.0811661371163607
Trained batch 411 in epoch 3, gen_loss = 0.8380433410695456, disc_loss = 0.08104223579177362
Trained batch 412 in epoch 3, gen_loss = 0.8374723678062383, disc_loss = 0.08116797668313648
Trained batch 413 in epoch 3, gen_loss = 0.8375486337044389, disc_loss = 0.08106727705782522
Trained batch 414 in epoch 3, gen_loss = 0.8377462973077613, disc_loss = 0.08128628172653626
Trained batch 415 in epoch 3, gen_loss = 0.8372244556935934, disc_loss = 0.08140958299582753
Trained batch 416 in epoch 3, gen_loss = 0.83746578367494, disc_loss = 0.08130708519297895
Trained batch 417 in epoch 3, gen_loss = 0.8376958604064284, disc_loss = 0.08126868560919137
Trained batch 418 in epoch 3, gen_loss = 0.8377285128846089, disc_loss = 0.08119198507662675
Trained batch 419 in epoch 3, gen_loss = 0.8375487557479313, disc_loss = 0.08111261884415788
Trained batch 420 in epoch 3, gen_loss = 0.8377272742944205, disc_loss = 0.08097805359097741
Trained batch 421 in epoch 3, gen_loss = 0.838371305386602, disc_loss = 0.08097365783015487
Trained batch 422 in epoch 3, gen_loss = 0.8375073379658639, disc_loss = 0.08109399935463994
Trained batch 423 in epoch 3, gen_loss = 0.8373146283457864, disc_loss = 0.08112661907985315
Trained batch 424 in epoch 3, gen_loss = 0.8370945757978103, disc_loss = 0.08116024724043468
Trained batch 425 in epoch 3, gen_loss = 0.837586049882459, disc_loss = 0.08103504114316452
Trained batch 426 in epoch 3, gen_loss = 0.8381257332180926, disc_loss = 0.08101765853538237
Trained batch 427 in epoch 3, gen_loss = 0.8375654355666348, disc_loss = 0.08113399715702459
Trained batch 428 in epoch 3, gen_loss = 0.8377576300870011, disc_loss = 0.08100414427435829
Trained batch 429 in epoch 3, gen_loss = 0.837675881940265, disc_loss = 0.08095649306034279
Trained batch 430 in epoch 3, gen_loss = 0.8378639824152546, disc_loss = 0.08083846965662081
Trained batch 431 in epoch 3, gen_loss = 0.8380333574281799, disc_loss = 0.08075294880998424
Trained batch 432 in epoch 3, gen_loss = 0.8380960300392697, disc_loss = 0.08065992285116784
Trained batch 433 in epoch 3, gen_loss = 0.83763546575599, disc_loss = 0.08062847608631726
Trained batch 434 in epoch 3, gen_loss = 0.8380354908691056, disc_loss = 0.08079388533215756
Trained batch 435 in epoch 3, gen_loss = 0.8375060168701575, disc_loss = 0.08082193885758998
Trained batch 436 in epoch 3, gen_loss = 0.8376489816323025, disc_loss = 0.08070727072238444
Trained batch 437 in epoch 3, gen_loss = 0.8377018561374107, disc_loss = 0.08056716523324586
Trained batch 438 in epoch 3, gen_loss = 0.8378373797227691, disc_loss = 0.08054639221909446
Trained batch 439 in epoch 3, gen_loss = 0.8370826390656558, disc_loss = 0.08072169520680539
Trained batch 440 in epoch 3, gen_loss = 0.8370293570754209, disc_loss = 0.08059907329317326
Trained batch 441 in epoch 3, gen_loss = 0.8371804602005902, disc_loss = 0.0805502973172426
Trained batch 442 in epoch 3, gen_loss = 0.8371243437848834, disc_loss = 0.08043685612851086
Trained batch 443 in epoch 3, gen_loss = 0.8369336462504154, disc_loss = 0.08036604734464876
Trained batch 444 in epoch 3, gen_loss = 0.837347429923797, disc_loss = 0.08029079158696231
Trained batch 445 in epoch 3, gen_loss = 0.8370027203998224, disc_loss = 0.08024541192767398
Trained batch 446 in epoch 3, gen_loss = 0.836708813839044, disc_loss = 0.0802771894727944
Trained batch 447 in epoch 3, gen_loss = 0.8374314626146641, disc_loss = 0.08020254222252074
Trained batch 448 in epoch 3, gen_loss = 0.8382832774340708, disc_loss = 0.08014120602304062
Trained batch 449 in epoch 3, gen_loss = 0.8380309364530776, disc_loss = 0.08008566629762451
Trained batch 450 in epoch 3, gen_loss = 0.8380487014079041, disc_loss = 0.07997497674408152
Trained batch 451 in epoch 3, gen_loss = 0.8382658711840622, disc_loss = 0.07985178861082985
Trained batch 452 in epoch 3, gen_loss = 0.8378555418113472, disc_loss = 0.07988492054268553
Trained batch 453 in epoch 3, gen_loss = 0.8383623360274647, disc_loss = 0.07999053907822735
Trained batch 454 in epoch 3, gen_loss = 0.8382774994923519, disc_loss = 0.07992707496856923
Trained batch 455 in epoch 3, gen_loss = 0.8381704684150847, disc_loss = 0.07987570930313188
Trained batch 456 in epoch 3, gen_loss = 0.83792391425932, disc_loss = 0.0799564035707184
Trained batch 457 in epoch 3, gen_loss = 0.8381906497946994, disc_loss = 0.080233498165327
Trained batch 458 in epoch 3, gen_loss = 0.8386781885733012, disc_loss = 0.08017586869003011
Trained batch 459 in epoch 3, gen_loss = 0.8381748268137807, disc_loss = 0.080253870876344
Trained batch 460 in epoch 3, gen_loss = 0.8375974191502221, disc_loss = 0.08028332513520683
Trained batch 461 in epoch 3, gen_loss = 0.8374923817265085, disc_loss = 0.08032694747026413
Trained batch 462 in epoch 3, gen_loss = 0.8374403513018565, disc_loss = 0.08039013307026666
Trained batch 463 in epoch 3, gen_loss = 0.837135968922541, disc_loss = 0.08035507710883394
Trained batch 464 in epoch 3, gen_loss = 0.8369809810833264, disc_loss = 0.08025713278761794
Trained batch 465 in epoch 3, gen_loss = 0.8369178320461077, disc_loss = 0.08012681249169384
Trained batch 466 in epoch 3, gen_loss = 0.8370584051665197, disc_loss = 0.08001415679785692
Trained batch 467 in epoch 3, gen_loss = 0.8372209093764297, disc_loss = 0.07996408777653725
Trained batch 468 in epoch 3, gen_loss = 0.837560246366936, disc_loss = 0.07993773054252111
Trained batch 469 in epoch 3, gen_loss = 0.8372471187977081, disc_loss = 0.08000019924477376
Trained batch 470 in epoch 3, gen_loss = 0.8371970973703259, disc_loss = 0.07990560559812941
Trained batch 471 in epoch 3, gen_loss = 0.8372125003044888, disc_loss = 0.07977533920754884
Trained batch 472 in epoch 3, gen_loss = 0.8376110261640891, disc_loss = 0.07965238652060135
Trained batch 473 in epoch 3, gen_loss = 0.8372208981574336, disc_loss = 0.07960673429284103
Trained batch 474 in epoch 3, gen_loss = 0.837036393692619, disc_loss = 0.07949919598471178
Trained batch 475 in epoch 3, gen_loss = 0.8378221065807743, disc_loss = 0.07942512799484827
Trained batch 476 in epoch 3, gen_loss = 0.8373051543155806, disc_loss = 0.0795095463027588
Trained batch 477 in epoch 3, gen_loss = 0.8376551461269666, disc_loss = 0.07955722492694792
Trained batch 478 in epoch 3, gen_loss = 0.8376432096037337, disc_loss = 0.07954503610411305
Trained batch 479 in epoch 3, gen_loss = 0.837513142451644, disc_loss = 0.07943323075499696
Trained batch 480 in epoch 3, gen_loss = 0.8377939959573647, disc_loss = 0.07931129189630247
Trained batch 481 in epoch 3, gen_loss = 0.8378530776599631, disc_loss = 0.07918797791027367
Trained batch 482 in epoch 3, gen_loss = 0.8382436065446763, disc_loss = 0.07905269151757902
Trained batch 483 in epoch 3, gen_loss = 0.8384691628296513, disc_loss = 0.0789952971299048
Trained batch 484 in epoch 3, gen_loss = 0.8380543429826953, disc_loss = 0.07903807560922867
Trained batch 485 in epoch 3, gen_loss = 0.8384851507934523, disc_loss = 0.07892860685869929
Trained batch 486 in epoch 3, gen_loss = 0.8384653125455492, disc_loss = 0.07890153331089253
Trained batch 487 in epoch 3, gen_loss = 0.8384146459522794, disc_loss = 0.07877746894077749
Trained batch 488 in epoch 3, gen_loss = 0.8381666609358446, disc_loss = 0.07875011994832924
Trained batch 489 in epoch 3, gen_loss = 0.8383332557824194, disc_loss = 0.07877389295406792
Trained batch 490 in epoch 3, gen_loss = 0.8383208440423254, disc_loss = 0.07870132455037046
Trained batch 491 in epoch 3, gen_loss = 0.8378738439906903, disc_loss = 0.07883654294225077
Trained batch 492 in epoch 3, gen_loss = 0.8378266412878134, disc_loss = 0.07886300789301887
Trained batch 493 in epoch 3, gen_loss = 0.8381612325004237, disc_loss = 0.07876486731466917
Trained batch 494 in epoch 3, gen_loss = 0.8377246638741156, disc_loss = 0.07882108612155372
Trained batch 495 in epoch 3, gen_loss = 0.83751164617077, disc_loss = 0.07881479826568055
Trained batch 496 in epoch 3, gen_loss = 0.8382291654705761, disc_loss = 0.07898284035212018
Trained batch 497 in epoch 3, gen_loss = 0.8387324743002773, disc_loss = 0.07886629182299278
Trained batch 498 in epoch 3, gen_loss = 0.8381846418122729, disc_loss = 0.07893721595264687
Trained batch 499 in epoch 3, gen_loss = 0.8379807339906693, disc_loss = 0.07890155457146465
Trained batch 500 in epoch 3, gen_loss = 0.8382523836727865, disc_loss = 0.07909806520527529
Trained batch 501 in epoch 3, gen_loss = 0.8377993402490578, disc_loss = 0.07916271602141252
Trained batch 502 in epoch 3, gen_loss = 0.837308780810468, disc_loss = 0.0791888967708168
Trained batch 503 in epoch 3, gen_loss = 0.8374284758927331, disc_loss = 0.07913186541011942
Trained batch 504 in epoch 3, gen_loss = 0.8372886654173973, disc_loss = 0.07906593235744404
Trained batch 505 in epoch 3, gen_loss = 0.8373041913914586, disc_loss = 0.0789996095520735
Trained batch 506 in epoch 3, gen_loss = 0.8375040748885868, disc_loss = 0.07888351397908475
Trained batch 507 in epoch 3, gen_loss = 0.8379595716168561, disc_loss = 0.07877895410363306
Trained batch 508 in epoch 3, gen_loss = 0.8375844070157275, disc_loss = 0.07883534933054319
Trained batch 509 in epoch 3, gen_loss = 0.8379326177578347, disc_loss = 0.0788814509890097
Trained batch 510 in epoch 3, gen_loss = 0.8373788627859664, disc_loss = 0.07904013311727348
Trained batch 511 in epoch 3, gen_loss = 0.8375613476382568, disc_loss = 0.07892895517397847
Trained batch 512 in epoch 3, gen_loss = 0.8375644717532524, disc_loss = 0.07890226122456627
Trained batch 513 in epoch 3, gen_loss = 0.8373005204627486, disc_loss = 0.07888782699683007
Trained batch 514 in epoch 3, gen_loss = 0.8373844172190694, disc_loss = 0.07880717534571886
Trained batch 515 in epoch 3, gen_loss = 0.8370982780475025, disc_loss = 0.07880332833336479
Trained batch 516 in epoch 3, gen_loss = 0.837003297916464, disc_loss = 0.07879040230108818
Trained batch 517 in epoch 3, gen_loss = 0.8374124558275731, disc_loss = 0.07875949408837439
Trained batch 518 in epoch 3, gen_loss = 0.8374052719573755, disc_loss = 0.07873620325250835
Trained batch 519 in epoch 3, gen_loss = 0.837187311397149, disc_loss = 0.07885918135647303
Trained batch 520 in epoch 3, gen_loss = 0.8371190523689401, disc_loss = 0.07886296647802825
Trained batch 521 in epoch 3, gen_loss = 0.8373734517115743, disc_loss = 0.0787952258108876
Trained batch 522 in epoch 3, gen_loss = 0.8372484311091056, disc_loss = 0.07872821864837613
Trained batch 523 in epoch 3, gen_loss = 0.8377015727166911, disc_loss = 0.0788520296577023
Trained batch 524 in epoch 3, gen_loss = 0.8371858104070028, disc_loss = 0.07896090236270711
Trained batch 525 in epoch 3, gen_loss = 0.8370390458478674, disc_loss = 0.07887460577333551
Trained batch 526 in epoch 3, gen_loss = 0.8370481529317273, disc_loss = 0.07906269523680945
Trained batch 527 in epoch 3, gen_loss = 0.8364390208188331, disc_loss = 0.07943917376123312
Trained batch 528 in epoch 3, gen_loss = 0.8370123334327583, disc_loss = 0.07958811577691191
Trained batch 529 in epoch 3, gen_loss = 0.8367090186982785, disc_loss = 0.07959413051710658
Trained batch 530 in epoch 3, gen_loss = 0.8368508060324215, disc_loss = 0.07958811677101361
Trained batch 531 in epoch 3, gen_loss = 0.8369144820853284, disc_loss = 0.07948594749555048
Trained batch 532 in epoch 3, gen_loss = 0.8365473225013847, disc_loss = 0.0795438692417506
Trained batch 533 in epoch 3, gen_loss = 0.8369758342312517, disc_loss = 0.07972958395676163
Trained batch 534 in epoch 3, gen_loss = 0.8366606261128577, disc_loss = 0.07964376289676005
Trained batch 535 in epoch 3, gen_loss = 0.8363135882945203, disc_loss = 0.07982403132195737
Trained batch 536 in epoch 3, gen_loss = 0.8371947916082386, disc_loss = 0.07991698720566998
Trained batch 537 in epoch 3, gen_loss = 0.8375516020897152, disc_loss = 0.07999255680427177
Trained batch 538 in epoch 3, gen_loss = 0.8374545017951937, disc_loss = 0.0801653303326918
Trained batch 539 in epoch 3, gen_loss = 0.8368209665572202, disc_loss = 0.08034748515562602
Trained batch 540 in epoch 3, gen_loss = 0.8370830487191346, disc_loss = 0.08040330048595416
Trained batch 541 in epoch 3, gen_loss = 0.8373296066183885, disc_loss = 0.0803986932735244
Trained batch 542 in epoch 3, gen_loss = 0.8372758808056953, disc_loss = 0.08032071574472756
Trained batch 543 in epoch 3, gen_loss = 0.8371898322640097, disc_loss = 0.08027682314209147
Trained batch 544 in epoch 3, gen_loss = 0.8370664580152669, disc_loss = 0.08019198465477162
Trained batch 545 in epoch 3, gen_loss = 0.8376367951269115, disc_loss = 0.08019064431464225
Trained batch 546 in epoch 3, gen_loss = 0.8380244511572926, disc_loss = 0.08011233324944374
Trained batch 547 in epoch 3, gen_loss = 0.8379252922795984, disc_loss = 0.08003455425449477
Trained batch 548 in epoch 3, gen_loss = 0.8378421950861404, disc_loss = 0.07996672259402786
Trained batch 549 in epoch 3, gen_loss = 0.8380706185644323, disc_loss = 0.07995926818217744
Trained batch 550 in epoch 3, gen_loss = 0.8379842455071244, disc_loss = 0.07989647516477076
Trained batch 551 in epoch 3, gen_loss = 0.8376764577368031, disc_loss = 0.07992781083052303
Trained batch 552 in epoch 3, gen_loss = 0.8375365583202506, disc_loss = 0.07990177032145357
Trained batch 553 in epoch 3, gen_loss = 0.8373840753567348, disc_loss = 0.07980264939320701
Trained batch 554 in epoch 3, gen_loss = 0.8375251451054135, disc_loss = 0.0797023808919229
Trained batch 555 in epoch 3, gen_loss = 0.8377407303602575, disc_loss = 0.07969401428549677
Trained batch 556 in epoch 3, gen_loss = 0.838254257314295, disc_loss = 0.07961942175406582
Trained batch 557 in epoch 3, gen_loss = 0.8379378107286268, disc_loss = 0.07964939727050696
Trained batch 558 in epoch 3, gen_loss = 0.8386014371523917, disc_loss = 0.07960741254059542
Trained batch 559 in epoch 3, gen_loss = 0.8388228088617324, disc_loss = 0.0795272978970648
Trained batch 560 in epoch 3, gen_loss = 0.8388002751770292, disc_loss = 0.07946276882706532
Trained batch 561 in epoch 3, gen_loss = 0.8389079365017575, disc_loss = 0.07936192454863009
Trained batch 562 in epoch 3, gen_loss = 0.8397092662526702, disc_loss = 0.07935133066729744
Trained batch 563 in epoch 3, gen_loss = 0.8398868489138623, disc_loss = 0.07927059388640238
Trained batch 564 in epoch 3, gen_loss = 0.8401894218098801, disc_loss = 0.07918813229761029
Trained batch 565 in epoch 3, gen_loss = 0.839968556544806, disc_loss = 0.07922590923966188
Trained batch 566 in epoch 3, gen_loss = 0.8397660475138844, disc_loss = 0.07915711588007801
Trained batch 567 in epoch 3, gen_loss = 0.8399803093831304, disc_loss = 0.07903991141323735
Trained batch 568 in epoch 3, gen_loss = 0.8404976162005393, disc_loss = 0.07900438110895704
Trained batch 569 in epoch 3, gen_loss = 0.8406101117008611, disc_loss = 0.07888353976274007
Trained batch 570 in epoch 3, gen_loss = 0.8401420259433954, disc_loss = 0.0788449637555956
Trained batch 571 in epoch 3, gen_loss = 0.8402698003537171, disc_loss = 0.07872265381119832
Trained batch 572 in epoch 3, gen_loss = 0.840612410770869, disc_loss = 0.07870985127263824
Trained batch 573 in epoch 3, gen_loss = 0.8402293831213842, disc_loss = 0.0786891071375732
Trained batch 574 in epoch 3, gen_loss = 0.8396115277124487, disc_loss = 0.07880403583950323
Trained batch 575 in epoch 3, gen_loss = 0.8400644721049402, disc_loss = 0.07882112020646066
Trained batch 576 in epoch 3, gen_loss = 0.8400101055305587, disc_loss = 0.07890507634858274
Trained batch 577 in epoch 3, gen_loss = 0.8398279031049009, disc_loss = 0.07882565804386582
Trained batch 578 in epoch 3, gen_loss = 0.8392714494662376, disc_loss = 0.07907692149172124
Trained batch 579 in epoch 3, gen_loss = 0.8391178504146378, disc_loss = 0.07907563752880127
Trained batch 580 in epoch 3, gen_loss = 0.8395525811050927, disc_loss = 0.07904234314225166
Trained batch 581 in epoch 3, gen_loss = 0.8397222174606782, disc_loss = 0.07893800598335583
Trained batch 582 in epoch 3, gen_loss = 0.8392960894373637, disc_loss = 0.0790495196050656
Trained batch 583 in epoch 3, gen_loss = 0.8393850118330081, disc_loss = 0.07896868005388556
Trained batch 584 in epoch 3, gen_loss = 0.839753825440366, disc_loss = 0.07893618752017745
Trained batch 585 in epoch 3, gen_loss = 0.8393605867140123, disc_loss = 0.07899710129622256
Trained batch 586 in epoch 3, gen_loss = 0.8400355832337114, disc_loss = 0.07901795165775125
Trained batch 587 in epoch 3, gen_loss = 0.8400189305852059, disc_loss = 0.07893451758292916
Trained batch 588 in epoch 3, gen_loss = 0.8399265127190103, disc_loss = 0.07887283170118245
Trained batch 589 in epoch 3, gen_loss = 0.8402085287086034, disc_loss = 0.0787525828154284
Trained batch 590 in epoch 3, gen_loss = 0.8401545124812376, disc_loss = 0.07869630886081058
Trained batch 591 in epoch 3, gen_loss = 0.8403613843225144, disc_loss = 0.0785918530136523
Trained batch 592 in epoch 3, gen_loss = 0.8404417912433361, disc_loss = 0.07853360220783627
Trained batch 593 in epoch 3, gen_loss = 0.8406980869545279, disc_loss = 0.07843924057121178
Trained batch 594 in epoch 3, gen_loss = 0.8405717070363149, disc_loss = 0.078373423905871
Trained batch 595 in epoch 3, gen_loss = 0.8403197990967923, disc_loss = 0.0782996073987135
Trained batch 596 in epoch 3, gen_loss = 0.8404713545612355, disc_loss = 0.07822478324692803
Trained batch 597 in epoch 3, gen_loss = 0.8408112049501476, disc_loss = 0.07819218332271861
Trained batch 598 in epoch 3, gen_loss = 0.8403480009164953, disc_loss = 0.07820627392302322
Trained batch 599 in epoch 3, gen_loss = 0.8403045069177946, disc_loss = 0.07822433340518425
Trained batch 600 in epoch 3, gen_loss = 0.8399759992188502, disc_loss = 0.0782602824280023
Trained batch 601 in epoch 3, gen_loss = 0.8408068627416098, disc_loss = 0.07840293098049257
Trained batch 602 in epoch 3, gen_loss = 0.8406377823198613, disc_loss = 0.07842466920138542
Trained batch 603 in epoch 3, gen_loss = 0.8407167789359756, disc_loss = 0.0783565378121859
Trained batch 604 in epoch 3, gen_loss = 0.8408465213026882, disc_loss = 0.07825083190436698
Trained batch 605 in epoch 3, gen_loss = 0.840825480694818, disc_loss = 0.07818296878435725
Trained batch 606 in epoch 3, gen_loss = 0.841049511900058, disc_loss = 0.07819028251192224
Trained batch 607 in epoch 3, gen_loss = 0.8410697151955805, disc_loss = 0.07813374319812283
Trained batch 608 in epoch 3, gen_loss = 0.8413776278691535, disc_loss = 0.07804438463230243
Trained batch 609 in epoch 3, gen_loss = 0.8409440206699684, disc_loss = 0.07819028282996084
Trained batch 610 in epoch 3, gen_loss = 0.8413103576962959, disc_loss = 0.07809065142722645
Trained batch 611 in epoch 3, gen_loss = 0.8416198850457185, disc_loss = 0.07801690149833174
Trained batch 612 in epoch 3, gen_loss = 0.8415145858465944, disc_loss = 0.07795015076512614
Trained batch 613 in epoch 3, gen_loss = 0.8413245426521239, disc_loss = 0.07793488490003911
Trained batch 614 in epoch 3, gen_loss = 0.8418499048163252, disc_loss = 0.07817418103416761
Trained batch 615 in epoch 3, gen_loss = 0.8413252236394139, disc_loss = 0.07844371153283622
Trained batch 616 in epoch 3, gen_loss = 0.8413233613079139, disc_loss = 0.07838442319675049
Trained batch 617 in epoch 3, gen_loss = 0.8412571353626869, disc_loss = 0.07836119858939863
Trained batch 618 in epoch 3, gen_loss = 0.8412355958741393, disc_loss = 0.07837436821835299
Trained batch 619 in epoch 3, gen_loss = 0.8414230498575395, disc_loss = 0.07844655740285111
Trained batch 620 in epoch 3, gen_loss = 0.8411628926433803, disc_loss = 0.07865188411780409
Trained batch 621 in epoch 3, gen_loss = 0.8413832340018159, disc_loss = 0.07859186906595131
Trained batch 622 in epoch 3, gen_loss = 0.8416548688951312, disc_loss = 0.07857076667643856
Trained batch 623 in epoch 3, gen_loss = 0.8414506837725639, disc_loss = 0.07862568476523918
Trained batch 624 in epoch 3, gen_loss = 0.8414519132614136, disc_loss = 0.07860891258120536
Trained batch 625 in epoch 3, gen_loss = 0.8411979624828972, disc_loss = 0.07865137551515437
Trained batch 626 in epoch 3, gen_loss = 0.8415150097682715, disc_loss = 0.07865315038217692
Trained batch 627 in epoch 3, gen_loss = 0.8409507778609634, disc_loss = 0.07884329367001915
Trained batch 628 in epoch 3, gen_loss = 0.8409371049112281, disc_loss = 0.07882729985874105
Trained batch 629 in epoch 3, gen_loss = 0.8411843922403124, disc_loss = 0.07892682910083779
Trained batch 630 in epoch 3, gen_loss = 0.8408947731537978, disc_loss = 0.07893013541487809
Trained batch 631 in epoch 3, gen_loss = 0.8408251474552517, disc_loss = 0.07895453079143845
Trained batch 632 in epoch 3, gen_loss = 0.8405825541859366, disc_loss = 0.07891556724764724
Trained batch 633 in epoch 3, gen_loss = 0.8404445443243634, disc_loss = 0.07891779724943337
Trained batch 634 in epoch 3, gen_loss = 0.8407521501300842, disc_loss = 0.07884370856515066
Trained batch 635 in epoch 3, gen_loss = 0.8405702915394081, disc_loss = 0.0787760545236041
Trained batch 636 in epoch 3, gen_loss = 0.8406479424172706, disc_loss = 0.07867631300979731
Trained batch 637 in epoch 3, gen_loss = 0.8406124879200256, disc_loss = 0.07860384726762584
Trained batch 638 in epoch 3, gen_loss = 0.840862513148169, disc_loss = 0.07851113638431068
Trained batch 639 in epoch 3, gen_loss = 0.8408160134218633, disc_loss = 0.07848571255453862
Trained batch 640 in epoch 3, gen_loss = 0.8405654801407396, disc_loss = 0.07844266260562932
Trained batch 641 in epoch 3, gen_loss = 0.8406531009532953, disc_loss = 0.07835960859937646
Trained batch 642 in epoch 3, gen_loss = 0.8407924378270495, disc_loss = 0.07861270323905567
Trained batch 643 in epoch 3, gen_loss = 0.8404975238238802, disc_loss = 0.07862887345832882
Trained batch 644 in epoch 3, gen_loss = 0.840891719511313, disc_loss = 0.07861359795743181
Trained batch 645 in epoch 3, gen_loss = 0.8405816436921111, disc_loss = 0.07869940836432364
Trained batch 646 in epoch 3, gen_loss = 0.8405239701823805, disc_loss = 0.07876696084644731
Trained batch 647 in epoch 3, gen_loss = 0.8401423862870828, disc_loss = 0.07892209489795345
Trained batch 648 in epoch 3, gen_loss = 0.840300327181265, disc_loss = 0.07891223802932973
Trained batch 649 in epoch 3, gen_loss = 0.8405883298470423, disc_loss = 0.07896306576064
Trained batch 650 in epoch 3, gen_loss = 0.8400488109907247, disc_loss = 0.07912697194976741
Trained batch 651 in epoch 3, gen_loss = 0.83990372045457, disc_loss = 0.07905984059136155
Trained batch 652 in epoch 3, gen_loss = 0.840148242974902, disc_loss = 0.07902013181293722
Trained batch 653 in epoch 3, gen_loss = 0.8402149109938822, disc_loss = 0.07893436643599734
Trained batch 654 in epoch 3, gen_loss = 0.8403994931064489, disc_loss = 0.07882805347215129
Trained batch 655 in epoch 3, gen_loss = 0.8402286692999485, disc_loss = 0.07876988209602309
Trained batch 656 in epoch 3, gen_loss = 0.8406576355026193, disc_loss = 0.07874406343453551
Trained batch 657 in epoch 3, gen_loss = 0.8405497352674739, disc_loss = 0.07865590587722585
Trained batch 658 in epoch 3, gen_loss = 0.8401468000480727, disc_loss = 0.07872194998328078
Trained batch 659 in epoch 3, gen_loss = 0.8402520903583729, disc_loss = 0.07869895209247867
Trained batch 660 in epoch 3, gen_loss = 0.8404866601713847, disc_loss = 0.07868159003555775
Trained batch 661 in epoch 3, gen_loss = 0.8402377973420382, disc_loss = 0.07875619132319336
Trained batch 662 in epoch 3, gen_loss = 0.8399291516339258, disc_loss = 0.07882744520284561
Trained batch 663 in epoch 3, gen_loss = 0.8395757314760283, disc_loss = 0.07877666962961385
Trained batch 664 in epoch 3, gen_loss = 0.8397159764193054, disc_loss = 0.07873260901778713
Trained batch 665 in epoch 3, gen_loss = 0.840244589401437, disc_loss = 0.0787973772516256
Trained batch 666 in epoch 3, gen_loss = 0.8399160329637856, disc_loss = 0.0789670625497689
Trained batch 667 in epoch 3, gen_loss = 0.8399578487712466, disc_loss = 0.07893156937552159
Trained batch 668 in epoch 3, gen_loss = 0.8400352753598593, disc_loss = 0.07912391276336839
Trained batch 669 in epoch 3, gen_loss = 0.8395740942723715, disc_loss = 0.07930065038989284
Trained batch 670 in epoch 3, gen_loss = 0.8394679674537278, disc_loss = 0.07927811636843464
Trained batch 671 in epoch 3, gen_loss = 0.8390765953365535, disc_loss = 0.07931138287087725
Trained batch 672 in epoch 3, gen_loss = 0.8393915015290786, disc_loss = 0.07934313776998339
Trained batch 673 in epoch 3, gen_loss = 0.8395196696859439, disc_loss = 0.0795042498357793
Trained batch 674 in epoch 3, gen_loss = 0.8394138984768479, disc_loss = 0.07944521999745457
Trained batch 675 in epoch 3, gen_loss = 0.8390545939817231, disc_loss = 0.0795492520473192
Trained batch 676 in epoch 3, gen_loss = 0.8385027794049092, disc_loss = 0.07975847942911451
Trained batch 677 in epoch 3, gen_loss = 0.8386148045548295, disc_loss = 0.07987161799111461
Trained batch 678 in epoch 3, gen_loss = 0.8388306040300361, disc_loss = 0.08014795448307349
Trained batch 679 in epoch 3, gen_loss = 0.8384300213526277, disc_loss = 0.08028165753656889
Trained batch 680 in epoch 3, gen_loss = 0.8380888149951873, disc_loss = 0.08027917770026101
Trained batch 681 in epoch 3, gen_loss = 0.8378592606338937, disc_loss = 0.08032406549463786
Trained batch 682 in epoch 3, gen_loss = 0.8378369426832017, disc_loss = 0.08044361585742994
Trained batch 683 in epoch 3, gen_loss = 0.8374559450567814, disc_loss = 0.08051207223471407
Trained batch 684 in epoch 3, gen_loss = 0.8373318325864137, disc_loss = 0.08068232462082031
Trained batch 685 in epoch 3, gen_loss = 0.8371331589215003, disc_loss = 0.08074867401445833
Trained batch 686 in epoch 3, gen_loss = 0.837329109509786, disc_loss = 0.08066916974394256
Trained batch 687 in epoch 3, gen_loss = 0.8372632043306217, disc_loss = 0.08061309342900681
Trained batch 688 in epoch 3, gen_loss = 0.8369657674098742, disc_loss = 0.08062203365806571
Trained batch 689 in epoch 3, gen_loss = 0.8367036086061727, disc_loss = 0.0805855796172999
Trained batch 690 in epoch 3, gen_loss = 0.8365293422932217, disc_loss = 0.08056341437285958
Trained batch 691 in epoch 3, gen_loss = 0.836451829082704, disc_loss = 0.08050170075686681
Trained batch 692 in epoch 3, gen_loss = 0.8366756809050214, disc_loss = 0.08040857889715039
Trained batch 693 in epoch 3, gen_loss = 0.8370663274605611, disc_loss = 0.08035126486283214
Trained batch 694 in epoch 3, gen_loss = 0.8369847416020125, disc_loss = 0.0803172311497678
Trained batch 695 in epoch 3, gen_loss = 0.8366158418785566, disc_loss = 0.08033048979745343
Trained batch 696 in epoch 3, gen_loss = 0.8370301141116335, disc_loss = 0.0803458476799889
Trained batch 697 in epoch 3, gen_loss = 0.8370472374652381, disc_loss = 0.08029376052554836
Trained batch 698 in epoch 3, gen_loss = 0.836907698616961, disc_loss = 0.08022588600693684
Trained batch 699 in epoch 3, gen_loss = 0.8368394641365324, disc_loss = 0.08014077434316277
Trained batch 700 in epoch 3, gen_loss = 0.8365890591188776, disc_loss = 0.0800936432813059
Trained batch 701 in epoch 3, gen_loss = 0.8367324687986293, disc_loss = 0.08000863336843897
Trained batch 702 in epoch 3, gen_loss = 0.8370341153266928, disc_loss = 0.07995673682100828
Trained batch 703 in epoch 3, gen_loss = 0.8366788077930157, disc_loss = 0.08000207439181395
Trained batch 704 in epoch 3, gen_loss = 0.8371407925659883, disc_loss = 0.07999015485088454
Trained batch 705 in epoch 3, gen_loss = 0.8367675984378576, disc_loss = 0.08008158967563772
Trained batch 706 in epoch 3, gen_loss = 0.8365261445962725, disc_loss = 0.08010946598583688
Trained batch 707 in epoch 3, gen_loss = 0.8369487055109046, disc_loss = 0.08010734717419508
Trained batch 708 in epoch 3, gen_loss = 0.836760586004163, disc_loss = 0.08008975499639306
Trained batch 709 in epoch 3, gen_loss = 0.8365866259789803, disc_loss = 0.08008508478409387
Trained batch 710 in epoch 3, gen_loss = 0.8369232615673424, disc_loss = 0.08010202578927814
Trained batch 711 in epoch 3, gen_loss = 0.8369852123635538, disc_loss = 0.08004377865797599
Trained batch 712 in epoch 3, gen_loss = 0.8368269840430411, disc_loss = 0.07999742141079685
Trained batch 713 in epoch 3, gen_loss = 0.8366051217755016, disc_loss = 0.08000100193498265
Trained batch 714 in epoch 3, gen_loss = 0.8369793746854876, disc_loss = 0.08011163204543657
Trained batch 715 in epoch 3, gen_loss = 0.8367680908914384, disc_loss = 0.08005967227138537
Trained batch 716 in epoch 3, gen_loss = 0.8365596854537102, disc_loss = 0.08000930497160433
Trained batch 717 in epoch 3, gen_loss = 0.836515697513118, disc_loss = 0.07995156200555954
Trained batch 718 in epoch 3, gen_loss = 0.8367214366192612, disc_loss = 0.0798858389781687
Trained batch 719 in epoch 3, gen_loss = 0.8364169922967751, disc_loss = 0.07989307032742848
Trained batch 720 in epoch 3, gen_loss = 0.8363094419943642, disc_loss = 0.07988144078352663
Trained batch 721 in epoch 3, gen_loss = 0.8363007816416405, disc_loss = 0.0797905031684528
Trained batch 722 in epoch 3, gen_loss = 0.8364019676692588, disc_loss = 0.07976256593814529
Trained batch 723 in epoch 3, gen_loss = 0.836548625928921, disc_loss = 0.0796923253386801
Trained batch 724 in epoch 3, gen_loss = 0.8359051222636782, disc_loss = 0.08006812449673127
Trained batch 725 in epoch 3, gen_loss = 0.8355315399071401, disc_loss = 0.08010628618833611
Trained batch 726 in epoch 3, gen_loss = 0.8360985638022914, disc_loss = 0.0802552166357739
Trained batch 727 in epoch 3, gen_loss = 0.836141896198739, disc_loss = 0.08016952182995257
Trained batch 728 in epoch 3, gen_loss = 0.8359570396126379, disc_loss = 0.08015881036759567
Trained batch 729 in epoch 3, gen_loss = 0.8359213928653769, disc_loss = 0.08013637867590336
Trained batch 730 in epoch 3, gen_loss = 0.8360782943248096, disc_loss = 0.08016888256580983
Trained batch 731 in epoch 3, gen_loss = 0.8359198933416377, disc_loss = 0.080200554808103
Trained batch 732 in epoch 3, gen_loss = 0.8359723323689314, disc_loss = 0.08031537929120364
Trained batch 733 in epoch 3, gen_loss = 0.8359152785926164, disc_loss = 0.08024211671731209
Trained batch 734 in epoch 3, gen_loss = 0.8354982827796417, disc_loss = 0.08047403812053658
Trained batch 735 in epoch 3, gen_loss = 0.8357447266740643, disc_loss = 0.080587786311061
Trained batch 736 in epoch 3, gen_loss = 0.8357553451323283, disc_loss = 0.08057508947456626
Trained batch 737 in epoch 3, gen_loss = 0.8357074696843217, disc_loss = 0.08062827955870851
Trained batch 738 in epoch 3, gen_loss = 0.8354913554430331, disc_loss = 0.08061836867849059
Trained batch 739 in epoch 3, gen_loss = 0.8355747666713353, disc_loss = 0.08057943316478584
Trained batch 740 in epoch 3, gen_loss = 0.8356899372157458, disc_loss = 0.08059219727179541
Trained batch 741 in epoch 3, gen_loss = 0.8356528070095093, disc_loss = 0.08052070329412617
Trained batch 742 in epoch 3, gen_loss = 0.8352850532788447, disc_loss = 0.08054671893811322
Trained batch 743 in epoch 3, gen_loss = 0.8354253770523173, disc_loss = 0.08061062827986736
Trained batch 744 in epoch 3, gen_loss = 0.8356263107901452, disc_loss = 0.08055713296736647
Trained batch 745 in epoch 3, gen_loss = 0.8352550658879268, disc_loss = 0.08078327075885385
Trained batch 746 in epoch 3, gen_loss = 0.8353707505517216, disc_loss = 0.08079339906952308
Trained batch 747 in epoch 3, gen_loss = 0.8358189118577835, disc_loss = 0.08081785499810536
Trained batch 748 in epoch 3, gen_loss = 0.8354942883763995, disc_loss = 0.08085622536006057
Trained batch 749 in epoch 3, gen_loss = 0.8356716565291087, disc_loss = 0.08078193964560827
Trained batch 750 in epoch 3, gen_loss = 0.8358230791618916, disc_loss = 0.08070992074470307
Trained batch 751 in epoch 3, gen_loss = 0.8359929360449314, disc_loss = 0.08062586787236022
Trained batch 752 in epoch 3, gen_loss = 0.835712818193879, disc_loss = 0.08065214624027332
Trained batch 753 in epoch 3, gen_loss = 0.8359611372732674, disc_loss = 0.08056052488618251
Trained batch 754 in epoch 3, gen_loss = 0.835650808921713, disc_loss = 0.08057702166947307
Trained batch 755 in epoch 3, gen_loss = 0.8355645043824715, disc_loss = 0.08051903077731372
Trained batch 756 in epoch 3, gen_loss = 0.8357039054602267, disc_loss = 0.08047442320276597
Trained batch 757 in epoch 3, gen_loss = 0.8357836050534311, disc_loss = 0.0804239330434862
Trained batch 758 in epoch 3, gen_loss = 0.8355358287750968, disc_loss = 0.08039619517911407
Trained batch 759 in epoch 3, gen_loss = 0.8358122477405949, disc_loss = 0.08049646469421293
Trained batch 760 in epoch 3, gen_loss = 0.8355321385230717, disc_loss = 0.08050875063696766
Trained batch 761 in epoch 3, gen_loss = 0.8355603592758729, disc_loss = 0.08043624505674432
Trained batch 762 in epoch 3, gen_loss = 0.8356432542107208, disc_loss = 0.08034530014097495
Trained batch 763 in epoch 3, gen_loss = 0.835639867873092, disc_loss = 0.08028691347946866
Trained batch 764 in epoch 3, gen_loss = 0.8354773411563798, disc_loss = 0.08030473462433792
Trained batch 765 in epoch 3, gen_loss = 0.8354862494972917, disc_loss = 0.08026970849632634
Trained batch 766 in epoch 3, gen_loss = 0.8354645424280825, disc_loss = 0.08019474690908752
Trained batch 767 in epoch 3, gen_loss = 0.8352673632713655, disc_loss = 0.08027697234380564
Trained batch 768 in epoch 3, gen_loss = 0.8355641084467637, disc_loss = 0.08023128772980409
Trained batch 769 in epoch 3, gen_loss = 0.835922838341106, disc_loss = 0.08016952640171368
Trained batch 770 in epoch 3, gen_loss = 0.8360075599643197, disc_loss = 0.08008298240650334
Trained batch 771 in epoch 3, gen_loss = 0.8356275940651721, disc_loss = 0.08026594363172283
Trained batch 772 in epoch 3, gen_loss = 0.8357316140678228, disc_loss = 0.080277679957941
Trained batch 773 in epoch 3, gen_loss = 0.8359101768919972, disc_loss = 0.08029800783890932
Trained batch 774 in epoch 3, gen_loss = 0.8356738641185145, disc_loss = 0.08025958402022239
Trained batch 775 in epoch 3, gen_loss = 0.8354195795722843, disc_loss = 0.08032005090631314
Trained batch 776 in epoch 3, gen_loss = 0.8355831101134017, disc_loss = 0.08023368876710285
Trained batch 777 in epoch 3, gen_loss = 0.8357479783747067, disc_loss = 0.08017542129645847
Trained batch 778 in epoch 3, gen_loss = 0.8359538455982722, disc_loss = 0.08017425109729151
Trained batch 779 in epoch 3, gen_loss = 0.8357002328603695, disc_loss = 0.0802281755548066
Trained batch 780 in epoch 3, gen_loss = 0.8356204158060071, disc_loss = 0.08017569637014298
Trained batch 781 in epoch 3, gen_loss = 0.8362773917520138, disc_loss = 0.08025902343670958
Trained batch 782 in epoch 3, gen_loss = 0.8362490069668259, disc_loss = 0.08019410742453917
Trained batch 783 in epoch 3, gen_loss = 0.8358609320557847, disc_loss = 0.08044909428073359
Trained batch 784 in epoch 3, gen_loss = 0.8357325540226735, disc_loss = 0.08043330141645708
Trained batch 785 in epoch 3, gen_loss = 0.8361786205046656, disc_loss = 0.08082730515265207
Trained batch 786 in epoch 3, gen_loss = 0.8359403211855373, disc_loss = 0.08087182283316285
Trained batch 787 in epoch 3, gen_loss = 0.8357241047820464, disc_loss = 0.08091588496812029
Trained batch 788 in epoch 3, gen_loss = 0.8356166703317253, disc_loss = 0.08101353635456701
Trained batch 789 in epoch 3, gen_loss = 0.8357461933093735, disc_loss = 0.0813057081679566
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.7692896127700806, disc_loss = 0.15932242572307587
Trained batch 1 in epoch 4, gen_loss = 0.6841276586055756, disc_loss = 0.12953979521989822
Trained batch 2 in epoch 4, gen_loss = 0.6794742941856384, disc_loss = 0.10974625746409099
Trained batch 3 in epoch 4, gen_loss = 0.7672336846590042, disc_loss = 0.09392906352877617
Trained batch 4 in epoch 4, gen_loss = 0.7949486374855042, disc_loss = 0.08254907578229904
Trained batch 5 in epoch 4, gen_loss = 0.7828351060549418, disc_loss = 0.07661975175142288
Trained batch 6 in epoch 4, gen_loss = 0.7789558683122907, disc_loss = 0.06910590667809759
Trained batch 7 in epoch 4, gen_loss = 0.8057541772723198, disc_loss = 0.08833217667415738
Trained batch 8 in epoch 4, gen_loss = 0.7899529602792528, disc_loss = 0.08895866697033246
Trained batch 9 in epoch 4, gen_loss = 0.7775392591953277, disc_loss = 0.08608168475329876
Trained batch 10 in epoch 4, gen_loss = 0.7843879515474493, disc_loss = 0.08392134274948727
Trained batch 11 in epoch 4, gen_loss = 0.8046427418788274, disc_loss = 0.08019568709035714
Trained batch 12 in epoch 4, gen_loss = 0.8069385244296148, disc_loss = 0.07842331780837132
Trained batch 13 in epoch 4, gen_loss = 0.7984290506158557, disc_loss = 0.08046259518180575
Trained batch 14 in epoch 4, gen_loss = 0.7930831432342529, disc_loss = 0.07828252042333285
Trained batch 15 in epoch 4, gen_loss = 0.7966762594878674, disc_loss = 0.07528973533771932
Trained batch 16 in epoch 4, gen_loss = 0.8049599984112907, disc_loss = 0.07269924900987569
Trained batch 17 in epoch 4, gen_loss = 0.8063198162449731, disc_loss = 0.069944494507379
Trained batch 18 in epoch 4, gen_loss = 0.8176345166407133, disc_loss = 0.07171792831075818
Trained batch 19 in epoch 4, gen_loss = 0.8127942234277725, disc_loss = 0.07199807483702898
Trained batch 20 in epoch 4, gen_loss = 0.804077168305715, disc_loss = 0.0742692934970061
Trained batch 21 in epoch 4, gen_loss = 0.8167112984440543, disc_loss = 0.07299734431911599
Trained batch 22 in epoch 4, gen_loss = 0.836044500703397, disc_loss = 0.07593024084749429
Trained batch 23 in epoch 4, gen_loss = 0.8447311595082283, disc_loss = 0.07347360835410655
Trained batch 24 in epoch 4, gen_loss = 0.8418710160255433, disc_loss = 0.07232423596084119
Trained batch 25 in epoch 4, gen_loss = 0.8362277310628158, disc_loss = 0.07173310872167349
Trained batch 26 in epoch 4, gen_loss = 0.838452489287765, disc_loss = 0.06957025336170639
Trained batch 27 in epoch 4, gen_loss = 0.8375883400440216, disc_loss = 0.07178814715838858
Trained batch 28 in epoch 4, gen_loss = 0.830084872656855, disc_loss = 0.07154962478269791
Trained batch 29 in epoch 4, gen_loss = 0.8337688187758128, disc_loss = 0.06997587885707617
Trained batch 30 in epoch 4, gen_loss = 0.8345149274795286, disc_loss = 0.07047178578232566
Trained batch 31 in epoch 4, gen_loss = 0.8364712614566088, disc_loss = 0.06965759576996788
Trained batch 32 in epoch 4, gen_loss = 0.831049028671149, disc_loss = 0.07019806850814458
Trained batch 33 in epoch 4, gen_loss = 0.833709131268894, disc_loss = 0.06878564632771646
Trained batch 34 in epoch 4, gen_loss = 0.8359766517366681, disc_loss = 0.06925278066524437
Trained batch 35 in epoch 4, gen_loss = 0.8385233829418818, disc_loss = 0.06834558557925953
Trained batch 36 in epoch 4, gen_loss = 0.8369795857249079, disc_loss = 0.06720140989165048
Trained batch 37 in epoch 4, gen_loss = 0.833669651495783, disc_loss = 0.06746409058962997
Trained batch 38 in epoch 4, gen_loss = 0.8462850298636999, disc_loss = 0.06776949600913586
Trained batch 39 in epoch 4, gen_loss = 0.8503541693091392, disc_loss = 0.06653726566582918
Trained batch 40 in epoch 4, gen_loss = 0.8435655105404738, disc_loss = 0.06773454768628609
Trained batch 41 in epoch 4, gen_loss = 0.8471305270989736, disc_loss = 0.06687222092988945
Trained batch 42 in epoch 4, gen_loss = 0.8493185251258141, disc_loss = 0.06657076947564303
Trained batch 43 in epoch 4, gen_loss = 0.8510805598714135, disc_loss = 0.06605560781264846
Trained batch 44 in epoch 4, gen_loss = 0.850817867120107, disc_loss = 0.06486112974170181
Trained batch 45 in epoch 4, gen_loss = 0.8489387722119041, disc_loss = 0.0645299872342983
Trained batch 46 in epoch 4, gen_loss = 0.8457744096187835, disc_loss = 0.06488567283575206
Trained batch 47 in epoch 4, gen_loss = 0.8516560991605123, disc_loss = 0.06428935326403007
Trained batch 48 in epoch 4, gen_loss = 0.8544583174647117, disc_loss = 0.06411817884642859
Trained batch 49 in epoch 4, gen_loss = 0.8550682532787323, disc_loss = 0.06338513093069195
Trained batch 50 in epoch 4, gen_loss = 0.8538231744485743, disc_loss = 0.063074198149729
Trained batch 51 in epoch 4, gen_loss = 0.8527547659782263, disc_loss = 0.06251526632919334
Trained batch 52 in epoch 4, gen_loss = 0.8566476702690125, disc_loss = 0.061619125956774885
Trained batch 53 in epoch 4, gen_loss = 0.8572518538545679, disc_loss = 0.06172215864407243
Trained batch 54 in epoch 4, gen_loss = 0.8521636724472046, disc_loss = 0.06292510447515683
Trained batch 55 in epoch 4, gen_loss = 0.8530644242252622, disc_loss = 0.06220018652467323
Trained batch 56 in epoch 4, gen_loss = 0.8556899459738481, disc_loss = 0.062033032720679775
Trained batch 57 in epoch 4, gen_loss = 0.8579963229853531, disc_loss = 0.06181122203646549
Trained batch 58 in epoch 4, gen_loss = 0.855796777595908, disc_loss = 0.06210462643244004
Trained batch 59 in epoch 4, gen_loss = 0.8543822924296062, disc_loss = 0.061659067015474044
Trained batch 60 in epoch 4, gen_loss = 0.8545591010422003, disc_loss = 0.0641677500680089
Trained batch 61 in epoch 4, gen_loss = 0.8492730240668019, disc_loss = 0.06522782304654678
Trained batch 62 in epoch 4, gen_loss = 0.8473311293692816, disc_loss = 0.06483582940898718
Trained batch 63 in epoch 4, gen_loss = 0.8520000902935863, disc_loss = 0.06590093906561378
Trained batch 64 in epoch 4, gen_loss = 0.8477328364665692, disc_loss = 0.06684402687331804
Trained batch 65 in epoch 4, gen_loss = 0.8482739771857406, disc_loss = 0.066299887501042
Trained batch 66 in epoch 4, gen_loss = 0.848459835372754, disc_loss = 0.06562473937702268
Trained batch 67 in epoch 4, gen_loss = 0.8464098318534738, disc_loss = 0.06592122532482095
Trained batch 68 in epoch 4, gen_loss = 0.8482556818188101, disc_loss = 0.06521976502963166
Trained batch 69 in epoch 4, gen_loss = 0.8504636824131012, disc_loss = 0.06572570642456413
Trained batch 70 in epoch 4, gen_loss = 0.8464876270629991, disc_loss = 0.06634661724502353
Trained batch 71 in epoch 4, gen_loss = 0.8488247220714887, disc_loss = 0.06680820386908534
Trained batch 72 in epoch 4, gen_loss = 0.8468843151445258, disc_loss = 0.06676020699055636
Trained batch 73 in epoch 4, gen_loss = 0.8429561643987089, disc_loss = 0.0686200391123625
Trained batch 74 in epoch 4, gen_loss = 0.8453285455703735, disc_loss = 0.06930359116444985
Trained batch 75 in epoch 4, gen_loss = 0.843049420337928, disc_loss = 0.06922164276291273
Trained batch 76 in epoch 4, gen_loss = 0.8442369227285509, disc_loss = 0.06894434297868571
Trained batch 77 in epoch 4, gen_loss = 0.8455506028273166, disc_loss = 0.06846754812898162
Trained batch 78 in epoch 4, gen_loss = 0.8410609590856335, disc_loss = 0.06942038451427524
Trained batch 79 in epoch 4, gen_loss = 0.8432244412600994, disc_loss = 0.0690948101808317
Trained batch 80 in epoch 4, gen_loss = 0.8403396451914752, disc_loss = 0.06923528246719528
Trained batch 81 in epoch 4, gen_loss = 0.8406283746405345, disc_loss = 0.06923363922254705
Trained batch 82 in epoch 4, gen_loss = 0.8381592767784395, disc_loss = 0.06921459690678909
Trained batch 83 in epoch 4, gen_loss = 0.8382482855092912, disc_loss = 0.06869069443616484
Trained batch 84 in epoch 4, gen_loss = 0.8413243391934563, disc_loss = 0.07042486361940117
Trained batch 85 in epoch 4, gen_loss = 0.84152584921482, disc_loss = 0.07013231374020147
Trained batch 86 in epoch 4, gen_loss = 0.838053325126911, disc_loss = 0.07117198627099566
Trained batch 87 in epoch 4, gen_loss = 0.8356944959272038, disc_loss = 0.07171897002792155
Trained batch 88 in epoch 4, gen_loss = 0.8348365941744172, disc_loss = 0.07149590205484896
Trained batch 89 in epoch 4, gen_loss = 0.8401519589953952, disc_loss = 0.07416211471168531
Trained batch 90 in epoch 4, gen_loss = 0.8365528544226846, disc_loss = 0.07554454074988326
Trained batch 91 in epoch 4, gen_loss = 0.8352239792761595, disc_loss = 0.07562055540999965
Trained batch 92 in epoch 4, gen_loss = 0.833776234298624, disc_loss = 0.07562349565447338
Trained batch 93 in epoch 4, gen_loss = 0.8335499750806931, disc_loss = 0.07518299352972115
Trained batch 94 in epoch 4, gen_loss = 0.8334936587434066, disc_loss = 0.07484914206556584
Trained batch 95 in epoch 4, gen_loss = 0.8346827036390702, disc_loss = 0.07484125587507151
Trained batch 96 in epoch 4, gen_loss = 0.8331599555064723, disc_loss = 0.07460433814060136
Trained batch 97 in epoch 4, gen_loss = 0.8338445753467326, disc_loss = 0.07416125026778603
Trained batch 98 in epoch 4, gen_loss = 0.8324946436015043, disc_loss = 0.07426668610423803
Trained batch 99 in epoch 4, gen_loss = 0.833903757929802, disc_loss = 0.0737934344727546
Trained batch 100 in epoch 4, gen_loss = 0.8343033820095629, disc_loss = 0.07369467207590247
Trained batch 101 in epoch 4, gen_loss = 0.8347050600192126, disc_loss = 0.07391939053823258
Trained batch 102 in epoch 4, gen_loss = 0.831388023582477, disc_loss = 0.07605271595665841
Trained batch 103 in epoch 4, gen_loss = 0.8332450060317149, disc_loss = 0.07618915093525384
Trained batch 104 in epoch 4, gen_loss = 0.8349644788673946, disc_loss = 0.07645882840844848
Trained batch 105 in epoch 4, gen_loss = 0.8330213475339817, disc_loss = 0.07645575235650506
Trained batch 106 in epoch 4, gen_loss = 0.8312749965725658, disc_loss = 0.07722866393312394
Trained batch 107 in epoch 4, gen_loss = 0.8346579773006616, disc_loss = 0.07904484948246843
Trained batch 108 in epoch 4, gen_loss = 0.8377401153428838, disc_loss = 0.07869456774221921
Trained batch 109 in epoch 4, gen_loss = 0.8396917649290778, disc_loss = 0.07821833927353675
Trained batch 110 in epoch 4, gen_loss = 0.8377813812311705, disc_loss = 0.07841039592450536
Trained batch 111 in epoch 4, gen_loss = 0.8361706853445087, disc_loss = 0.07849382412054443
Trained batch 112 in epoch 4, gen_loss = 0.8392587037740555, disc_loss = 0.0789632161881412
Trained batch 113 in epoch 4, gen_loss = 0.8381122463105017, disc_loss = 0.07900193636714105
Trained batch 114 in epoch 4, gen_loss = 0.8360898196697235, disc_loss = 0.07944540267243333
Trained batch 115 in epoch 4, gen_loss = 0.8378610243571216, disc_loss = 0.08007668706203072
Trained batch 116 in epoch 4, gen_loss = 0.8365867517442784, disc_loss = 0.08003904921217607
Trained batch 117 in epoch 4, gen_loss = 0.836934044957161, disc_loss = 0.07951442435604789
Trained batch 118 in epoch 4, gen_loss = 0.8362628148884332, disc_loss = 0.07973197170634981
Trained batch 119 in epoch 4, gen_loss = 0.8352122681836287, disc_loss = 0.07975980495878805
Trained batch 120 in epoch 4, gen_loss = 0.838632552830641, disc_loss = 0.07989186755851034
Trained batch 121 in epoch 4, gen_loss = 0.8379493363079478, disc_loss = 0.07945032646024569
Trained batch 122 in epoch 4, gen_loss = 0.8380114123588656, disc_loss = 0.07891786888211481
Trained batch 123 in epoch 4, gen_loss = 0.8380384168797924, disc_loss = 0.07843683402414524
Trained batch 124 in epoch 4, gen_loss = 0.8364676868915558, disc_loss = 0.07831891507655382
Trained batch 125 in epoch 4, gen_loss = 0.8375836622620386, disc_loss = 0.07829464884060952
Trained batch 126 in epoch 4, gen_loss = 0.8366023266878654, disc_loss = 0.07800682112721243
Trained batch 127 in epoch 4, gen_loss = 0.8387402195949107, disc_loss = 0.07806102542235749
Trained batch 128 in epoch 4, gen_loss = 0.8384466450805812, disc_loss = 0.07776946592498427
Trained batch 129 in epoch 4, gen_loss = 0.8387811144957176, disc_loss = 0.07760317836386653
Trained batch 130 in epoch 4, gen_loss = 0.8390169159601663, disc_loss = 0.07759325474301595
Trained batch 131 in epoch 4, gen_loss = 0.8378860085751071, disc_loss = 0.07760351287398601
Trained batch 132 in epoch 4, gen_loss = 0.837878020410251, disc_loss = 0.0773905334798129
Trained batch 133 in epoch 4, gen_loss = 0.8391227679910944, disc_loss = 0.07743857067717767
Trained batch 134 in epoch 4, gen_loss = 0.8388851410812802, disc_loss = 0.07752588436145473
Trained batch 135 in epoch 4, gen_loss = 0.8390944703098606, disc_loss = 0.07736503021271132
Trained batch 136 in epoch 4, gen_loss = 0.839504025060765, disc_loss = 0.07803234975295563
Trained batch 137 in epoch 4, gen_loss = 0.8387205114831096, disc_loss = 0.07794290916670275
Trained batch 138 in epoch 4, gen_loss = 0.8392643626216504, disc_loss = 0.07762747612386513
Trained batch 139 in epoch 4, gen_loss = 0.838988131923335, disc_loss = 0.077276168357847
Trained batch 140 in epoch 4, gen_loss = 0.8380943357099032, disc_loss = 0.07757996077523797
Trained batch 141 in epoch 4, gen_loss = 0.8365788591999404, disc_loss = 0.07771115363772277
Trained batch 142 in epoch 4, gen_loss = 0.8381468780807682, disc_loss = 0.07744238842799739
Trained batch 143 in epoch 4, gen_loss = 0.8383855974922577, disc_loss = 0.07752587179937917
Trained batch 144 in epoch 4, gen_loss = 0.8380597519463506, disc_loss = 0.0773665828116495
Trained batch 145 in epoch 4, gen_loss = 0.8367136277972835, disc_loss = 0.07768361838789631
Trained batch 146 in epoch 4, gen_loss = 0.8371710949609069, disc_loss = 0.07768353233810793
Trained batch 147 in epoch 4, gen_loss = 0.8368993959314114, disc_loss = 0.07740515308781855
Trained batch 148 in epoch 4, gen_loss = 0.8375793281417565, disc_loss = 0.07736942261432442
Trained batch 149 in epoch 4, gen_loss = 0.8377691306670507, disc_loss = 0.07693991316482425
Trained batch 150 in epoch 4, gen_loss = 0.8377313181659244, disc_loss = 0.07650840015378811
Trained batch 151 in epoch 4, gen_loss = 0.8366886787116528, disc_loss = 0.07654352534537841
Trained batch 152 in epoch 4, gen_loss = 0.8373604925239787, disc_loss = 0.07648793875172831
Trained batch 153 in epoch 4, gen_loss = 0.8365739729110296, disc_loss = 0.07681012830346243
Trained batch 154 in epoch 4, gen_loss = 0.8373572009225045, disc_loss = 0.07657289917791082
Trained batch 155 in epoch 4, gen_loss = 0.8362539018958043, disc_loss = 0.07673597005673517
Trained batch 156 in epoch 4, gen_loss = 0.836803240191405, disc_loss = 0.07716417857772036
Trained batch 157 in epoch 4, gen_loss = 0.8363672353421585, disc_loss = 0.07720790901869724
Trained batch 158 in epoch 4, gen_loss = 0.8368670110057734, disc_loss = 0.07721673855968055
Trained batch 159 in epoch 4, gen_loss = 0.8370270831510425, disc_loss = 0.07719657890847884
Trained batch 160 in epoch 4, gen_loss = 0.835832357961939, disc_loss = 0.07737102035016562
Trained batch 161 in epoch 4, gen_loss = 0.8353901224003898, disc_loss = 0.07767141917950393
Trained batch 162 in epoch 4, gen_loss = 0.8344986557594838, disc_loss = 0.07802652109962849
Trained batch 163 in epoch 4, gen_loss = 0.8352362602585699, disc_loss = 0.07771548198922197
Trained batch 164 in epoch 4, gen_loss = 0.8345770852132277, disc_loss = 0.07758038881037271
Trained batch 165 in epoch 4, gen_loss = 0.8368467625724264, disc_loss = 0.07811578423211193
Trained batch 166 in epoch 4, gen_loss = 0.8348657547713754, disc_loss = 0.07870525984417
Trained batch 167 in epoch 4, gen_loss = 0.8350089148041748, disc_loss = 0.07887124994747519
Trained batch 168 in epoch 4, gen_loss = 0.8342640814343854, disc_loss = 0.07917826624377769
Trained batch 169 in epoch 4, gen_loss = 0.8328094785704332, disc_loss = 0.07989464741309776
Trained batch 170 in epoch 4, gen_loss = 0.8327907241924465, disc_loss = 0.07988180809964736
Trained batch 171 in epoch 4, gen_loss = 0.8329264176792877, disc_loss = 0.07969999356130354
Trained batch 172 in epoch 4, gen_loss = 0.8317630041196856, disc_loss = 0.0799051693269197
Trained batch 173 in epoch 4, gen_loss = 0.8298102630966011, disc_loss = 0.08020348276878739
Trained batch 174 in epoch 4, gen_loss = 0.8303701659611293, disc_loss = 0.07992547975586993
Trained batch 175 in epoch 4, gen_loss = 0.8310265351425518, disc_loss = 0.0797646989442662
Trained batch 176 in epoch 4, gen_loss = 0.831128126820602, disc_loss = 0.07946661714001396
Trained batch 177 in epoch 4, gen_loss = 0.8312199346804887, disc_loss = 0.07920589697222864
Trained batch 178 in epoch 4, gen_loss = 0.8302862950543451, disc_loss = 0.07945237988762183
Trained batch 179 in epoch 4, gen_loss = 0.8304224809010824, disc_loss = 0.07913847894200848
Trained batch 180 in epoch 4, gen_loss = 0.8300176503249953, disc_loss = 0.07899940268584213
Trained batch 181 in epoch 4, gen_loss = 0.8312512708234263, disc_loss = 0.07875248948930876
Trained batch 182 in epoch 4, gen_loss = 0.8309365188489195, disc_loss = 0.07850012958273699
Trained batch 183 in epoch 4, gen_loss = 0.8296358802396319, disc_loss = 0.07849727240492306
Trained batch 184 in epoch 4, gen_loss = 0.8306881766061525, disc_loss = 0.07836808710786942
Trained batch 185 in epoch 4, gen_loss = 0.832958004487458, disc_loss = 0.07817780606508735
Trained batch 186 in epoch 4, gen_loss = 0.832130226540693, disc_loss = 0.07852912637937993
Trained batch 187 in epoch 4, gen_loss = 0.8324512341555129, disc_loss = 0.0782507706800119
Trained batch 188 in epoch 4, gen_loss = 0.8321300653553514, disc_loss = 0.07820044919631626
Trained batch 189 in epoch 4, gen_loss = 0.8313816926981273, disc_loss = 0.07842950841019812
Trained batch 190 in epoch 4, gen_loss = 0.833028153911311, disc_loss = 0.07890815826630249
Trained batch 191 in epoch 4, gen_loss = 0.8327410199368993, disc_loss = 0.07869227430880225
Trained batch 192 in epoch 4, gen_loss = 0.8326091133251091, disc_loss = 0.07846442720529484
Trained batch 193 in epoch 4, gen_loss = 0.8316869806383074, disc_loss = 0.07854906660168595
Trained batch 194 in epoch 4, gen_loss = 0.8322143637217008, disc_loss = 0.07841147947101257
Trained batch 195 in epoch 4, gen_loss = 0.8325794454740019, disc_loss = 0.07808463601870652
Trained batch 196 in epoch 4, gen_loss = 0.8318958058575083, disc_loss = 0.07790976075862113
Trained batch 197 in epoch 4, gen_loss = 0.8323401357188369, disc_loss = 0.07781275137412277
Trained batch 198 in epoch 4, gen_loss = 0.8310647502017381, disc_loss = 0.07803638591594882
Trained batch 199 in epoch 4, gen_loss = 0.8334071969985962, disc_loss = 0.07808623054530471
Trained batch 200 in epoch 4, gen_loss = 0.8337014551779524, disc_loss = 0.07775974968235143
Trained batch 201 in epoch 4, gen_loss = 0.8343340748607522, disc_loss = 0.07763063431357836
Trained batch 202 in epoch 4, gen_loss = 0.8332961046049747, disc_loss = 0.07776565467617635
Trained batch 203 in epoch 4, gen_loss = 0.8335309875946418, disc_loss = 0.07755835726400655
Trained batch 204 in epoch 4, gen_loss = 0.835124532769366, disc_loss = 0.07765979228495824
Trained batch 205 in epoch 4, gen_loss = 0.8336709471582209, disc_loss = 0.07772291082328239
Trained batch 206 in epoch 4, gen_loss = 0.8334836476091025, disc_loss = 0.0776303287928447
Trained batch 207 in epoch 4, gen_loss = 0.8350993922123542, disc_loss = 0.07805509927521388
Trained batch 208 in epoch 4, gen_loss = 0.8351873447450154, disc_loss = 0.07790729609812704
Trained batch 209 in epoch 4, gen_loss = 0.8347656689939045, disc_loss = 0.0777588905101376
Trained batch 210 in epoch 4, gen_loss = 0.8348806472186229, disc_loss = 0.07763169121032501
Trained batch 211 in epoch 4, gen_loss = 0.8353071252130112, disc_loss = 0.07752342029685541
Trained batch 212 in epoch 4, gen_loss = 0.8354719961193245, disc_loss = 0.0773060999049897
Trained batch 213 in epoch 4, gen_loss = 0.8356953580802846, disc_loss = 0.07710652323613797
Trained batch 214 in epoch 4, gen_loss = 0.8355569368184999, disc_loss = 0.07726835063117188
Trained batch 215 in epoch 4, gen_loss = 0.8354212213997487, disc_loss = 0.07697496026392198
Trained batch 216 in epoch 4, gen_loss = 0.8345735493343547, disc_loss = 0.07684053296506542
Trained batch 217 in epoch 4, gen_loss = 0.8352258197211344, disc_loss = 0.07659028954547617
Trained batch 218 in epoch 4, gen_loss = 0.8364129569976841, disc_loss = 0.0763655499295761
Trained batch 219 in epoch 4, gen_loss = 0.8365131830627268, disc_loss = 0.07625776991163465
Trained batch 220 in epoch 4, gen_loss = 0.8361737649904657, disc_loss = 0.07605347524890128
Trained batch 221 in epoch 4, gen_loss = 0.8350970567883672, disc_loss = 0.07598518119151662
Trained batch 222 in epoch 4, gen_loss = 0.835675064758335, disc_loss = 0.07570383480161161
Trained batch 223 in epoch 4, gen_loss = 0.835316754345383, disc_loss = 0.07594541187115413
Trained batch 224 in epoch 4, gen_loss = 0.8367083999845717, disc_loss = 0.07595595879273283
Trained batch 225 in epoch 4, gen_loss = 0.8363973740982799, disc_loss = 0.07578585512392157
Trained batch 226 in epoch 4, gen_loss = 0.8360888569365514, disc_loss = 0.07582889167009339
Trained batch 227 in epoch 4, gen_loss = 0.8362083453358266, disc_loss = 0.07573652814403829
Trained batch 228 in epoch 4, gen_loss = 0.8380077142902858, disc_loss = 0.07568104768082434
Trained batch 229 in epoch 4, gen_loss = 0.8374673317308011, disc_loss = 0.07581479502031985
Trained batch 230 in epoch 4, gen_loss = 0.8380118992937592, disc_loss = 0.07559102633766411
Trained batch 231 in epoch 4, gen_loss = 0.838807063626832, disc_loss = 0.07534581079581303
Trained batch 232 in epoch 4, gen_loss = 0.8394907562006185, disc_loss = 0.07508772064416065
Trained batch 233 in epoch 4, gen_loss = 0.8384430128285009, disc_loss = 0.07555770074439228
Trained batch 234 in epoch 4, gen_loss = 0.8388854924668657, disc_loss = 0.07533988363327498
Trained batch 235 in epoch 4, gen_loss = 0.8393705936811738, disc_loss = 0.07535381356680418
Trained batch 236 in epoch 4, gen_loss = 0.838468137169689, disc_loss = 0.07559721568355707
Trained batch 237 in epoch 4, gen_loss = 0.8383833475473548, disc_loss = 0.07544423510250048
Trained batch 238 in epoch 4, gen_loss = 0.8392837361810597, disc_loss = 0.07562102987255637
Trained batch 239 in epoch 4, gen_loss = 0.8388648559649785, disc_loss = 0.07565341615506137
Trained batch 240 in epoch 4, gen_loss = 0.837876496967933, disc_loss = 0.07575532115794935
Trained batch 241 in epoch 4, gen_loss = 0.8369518811545096, disc_loss = 0.07599734898641212
Trained batch 242 in epoch 4, gen_loss = 0.8384543703907311, disc_loss = 0.07623827980578314
Trained batch 243 in epoch 4, gen_loss = 0.8387180745113091, disc_loss = 0.0765064620893815
Trained batch 244 in epoch 4, gen_loss = 0.8374496063407586, disc_loss = 0.07746060900010017
Trained batch 245 in epoch 4, gen_loss = 0.8367687572793263, disc_loss = 0.07758667724721921
Trained batch 246 in epoch 4, gen_loss = 0.8367427493396559, disc_loss = 0.07747053135156269
Trained batch 247 in epoch 4, gen_loss = 0.8378478641952237, disc_loss = 0.07821955532211089
Trained batch 248 in epoch 4, gen_loss = 0.8377898680158409, disc_loss = 0.07826783942305539
Trained batch 249 in epoch 4, gen_loss = 0.8367398722171784, disc_loss = 0.07895278603211045
Trained batch 250 in epoch 4, gen_loss = 0.837445160544726, disc_loss = 0.0788955906688039
Trained batch 251 in epoch 4, gen_loss = 0.838123146740217, disc_loss = 0.07890295364805275
Trained batch 252 in epoch 4, gen_loss = 0.8382136536681134, disc_loss = 0.07885004297679239
Trained batch 253 in epoch 4, gen_loss = 0.8377841314462227, disc_loss = 0.07885868771471025
Trained batch 254 in epoch 4, gen_loss = 0.8373520615054112, disc_loss = 0.07890358707849301
Trained batch 255 in epoch 4, gen_loss = 0.8375415012706071, disc_loss = 0.07868451570902835
Trained batch 256 in epoch 4, gen_loss = 0.8366693933186364, disc_loss = 0.07903864456101498
Trained batch 257 in epoch 4, gen_loss = 0.8371134030726529, disc_loss = 0.07887433675413792
Trained batch 258 in epoch 4, gen_loss = 0.8355891824228884, disc_loss = 0.07933529289115696
Trained batch 259 in epoch 4, gen_loss = 0.836103998697721, disc_loss = 0.07926075356439329
Trained batch 260 in epoch 4, gen_loss = 0.8355954278017826, disc_loss = 0.07916571420770838
Trained batch 261 in epoch 4, gen_loss = 0.8353187446375839, disc_loss = 0.07899933528396806
Trained batch 262 in epoch 4, gen_loss = 0.8350481395485737, disc_loss = 0.07900269854700498
Trained batch 263 in epoch 4, gen_loss = 0.8352067039319964, disc_loss = 0.0788239660129572
Trained batch 264 in epoch 4, gen_loss = 0.8348655282326465, disc_loss = 0.07882446256940658
Trained batch 265 in epoch 4, gen_loss = 0.8350011706352234, disc_loss = 0.07928640796992004
Trained batch 266 in epoch 4, gen_loss = 0.8340883839889413, disc_loss = 0.07925717776452892
Trained batch 267 in epoch 4, gen_loss = 0.8333399064505278, disc_loss = 0.07937187827609257
Trained batch 268 in epoch 4, gen_loss = 0.8338485072093382, disc_loss = 0.07933239974981679
Trained batch 269 in epoch 4, gen_loss = 0.8331555053039833, disc_loss = 0.07929378001157332
Trained batch 270 in epoch 4, gen_loss = 0.8337143771762777, disc_loss = 0.07908301093577788
Trained batch 271 in epoch 4, gen_loss = 0.834251452675637, disc_loss = 0.07892053328824285
Trained batch 272 in epoch 4, gen_loss = 0.8343695967625349, disc_loss = 0.07872558824868102
Trained batch 273 in epoch 4, gen_loss = 0.8339685917335705, disc_loss = 0.07856391242834447
Trained batch 274 in epoch 4, gen_loss = 0.8336332013390281, disc_loss = 0.07853238144042816
Trained batch 275 in epoch 4, gen_loss = 0.8329979047395181, disc_loss = 0.07854466542831041
Trained batch 276 in epoch 4, gen_loss = 0.833759918539963, disc_loss = 0.07838509167588252
Trained batch 277 in epoch 4, gen_loss = 0.8339871997884709, disc_loss = 0.0784021792899844
Trained batch 278 in epoch 4, gen_loss = 0.8336619783900545, disc_loss = 0.07839016584632752
Trained batch 279 in epoch 4, gen_loss = 0.8333876005240849, disc_loss = 0.07824176571531487
Trained batch 280 in epoch 4, gen_loss = 0.8333126930155363, disc_loss = 0.07822087030937346
Trained batch 281 in epoch 4, gen_loss = 0.8340849559357826, disc_loss = 0.07831092443356806
Trained batch 282 in epoch 4, gen_loss = 0.8340428330451777, disc_loss = 0.0781677250286347
Trained batch 283 in epoch 4, gen_loss = 0.833657550979668, disc_loss = 0.07815622593748422
Trained batch 284 in epoch 4, gen_loss = 0.8341756042681242, disc_loss = 0.07820051765036687
Trained batch 285 in epoch 4, gen_loss = 0.8353582887382774, disc_loss = 0.07831923312253573
Trained batch 286 in epoch 4, gen_loss = 0.8343468271066088, disc_loss = 0.07884103820727366
Trained batch 287 in epoch 4, gen_loss = 0.8336527945680751, disc_loss = 0.07884007746987562
Trained batch 288 in epoch 4, gen_loss = 0.8338049163455369, disc_loss = 0.07881364649464619
Trained batch 289 in epoch 4, gen_loss = 0.8342724417818004, disc_loss = 0.07882225380182781
Trained batch 290 in epoch 4, gen_loss = 0.8342968528623024, disc_loss = 0.07867580068800151
Trained batch 291 in epoch 4, gen_loss = 0.8338374926211083, disc_loss = 0.07852836558276353
Trained batch 292 in epoch 4, gen_loss = 0.8337073106407712, disc_loss = 0.07837244100652559
Trained batch 293 in epoch 4, gen_loss = 0.8336789741808054, disc_loss = 0.07833180541400703
Trained batch 294 in epoch 4, gen_loss = 0.8326136140500084, disc_loss = 0.07841487176148063
Trained batch 295 in epoch 4, gen_loss = 0.833410694792464, disc_loss = 0.07824937645912271
Trained batch 296 in epoch 4, gen_loss = 0.833921031719105, disc_loss = 0.07803830309059183
Trained batch 297 in epoch 4, gen_loss = 0.8337308890467522, disc_loss = 0.07792706494125844
Trained batch 298 in epoch 4, gen_loss = 0.8343055038946529, disc_loss = 0.07773232672762213
Trained batch 299 in epoch 4, gen_loss = 0.8344524822632472, disc_loss = 0.0775750201785316
Trained batch 300 in epoch 4, gen_loss = 0.8346626376392834, disc_loss = 0.07736987007651912
Trained batch 301 in epoch 4, gen_loss = 0.8344866078815713, disc_loss = 0.07729807827584692
Trained batch 302 in epoch 4, gen_loss = 0.8351190642948592, disc_loss = 0.07754162377785437
Trained batch 303 in epoch 4, gen_loss = 0.8342027136761891, disc_loss = 0.07780094935840584
Trained batch 304 in epoch 4, gen_loss = 0.8340203042890205, disc_loss = 0.07772039539928807
Trained batch 305 in epoch 4, gen_loss = 0.8360247425004548, disc_loss = 0.07781396992200243
Trained batch 306 in epoch 4, gen_loss = 0.8362230848800087, disc_loss = 0.07774288023758304
Trained batch 307 in epoch 4, gen_loss = 0.8354502914400844, disc_loss = 0.07806043804308714
Trained batch 308 in epoch 4, gen_loss = 0.8354025679884605, disc_loss = 0.0779425014129879
Trained batch 309 in epoch 4, gen_loss = 0.8371097439719785, disc_loss = 0.0782931927080837
Trained batch 310 in epoch 4, gen_loss = 0.8364979433093424, disc_loss = 0.07838015872505988
Trained batch 311 in epoch 4, gen_loss = 0.8362915204503597, disc_loss = 0.07826255647262606
Trained batch 312 in epoch 4, gen_loss = 0.8365794477371362, disc_loss = 0.0780806239997855
Trained batch 313 in epoch 4, gen_loss = 0.8372081518173218, disc_loss = 0.07787920181360689
Trained batch 314 in epoch 4, gen_loss = 0.8370309163653661, disc_loss = 0.07776202292491992
Trained batch 315 in epoch 4, gen_loss = 0.8370037339156187, disc_loss = 0.07762933496822001
Trained batch 316 in epoch 4, gen_loss = 0.8370303278465753, disc_loss = 0.07746210947268486
Trained batch 317 in epoch 4, gen_loss = 0.8369548684396084, disc_loss = 0.077425016725799
Trained batch 318 in epoch 4, gen_loss = 0.8362590414603303, disc_loss = 0.07739493196252091
Trained batch 319 in epoch 4, gen_loss = 0.8369563229382038, disc_loss = 0.07747809925640467
Trained batch 320 in epoch 4, gen_loss = 0.8372529655973487, disc_loss = 0.07729281731982747
Trained batch 321 in epoch 4, gen_loss = 0.8372162784108464, disc_loss = 0.07709741432462698
Trained batch 322 in epoch 4, gen_loss = 0.8361930164390304, disc_loss = 0.07757983647067757
Trained batch 323 in epoch 4, gen_loss = 0.836592290872409, disc_loss = 0.07765881337489887
Trained batch 324 in epoch 4, gen_loss = 0.8367085852989784, disc_loss = 0.07755854189109344
Trained batch 325 in epoch 4, gen_loss = 0.8366511595761118, disc_loss = 0.07739143050418584
Trained batch 326 in epoch 4, gen_loss = 0.8366000608566704, disc_loss = 0.07728013929139128
Trained batch 327 in epoch 4, gen_loss = 0.8365269630420499, disc_loss = 0.0772086826420003
Trained batch 328 in epoch 4, gen_loss = 0.8364057493789581, disc_loss = 0.07706868836208952
Trained batch 329 in epoch 4, gen_loss = 0.8371298804427638, disc_loss = 0.0769043945368718
Trained batch 330 in epoch 4, gen_loss = 0.8378744658386599, disc_loss = 0.07675127868802256
Trained batch 331 in epoch 4, gen_loss = 0.8381446831556688, disc_loss = 0.07657046279735324
Trained batch 332 in epoch 4, gen_loss = 0.8386836386657692, disc_loss = 0.07637766173931661
Trained batch 333 in epoch 4, gen_loss = 0.8387797173268781, disc_loss = 0.07632059517210561
Trained batch 334 in epoch 4, gen_loss = 0.8390924886091432, disc_loss = 0.07635491119225078
Trained batch 335 in epoch 4, gen_loss = 0.8393012608091036, disc_loss = 0.07633388836568754
Trained batch 336 in epoch 4, gen_loss = 0.8389548003142948, disc_loss = 0.07644200002503766
Trained batch 337 in epoch 4, gen_loss = 0.8389276615261326, disc_loss = 0.0763920405080553
Trained batch 338 in epoch 4, gen_loss = 0.8390055071991102, disc_loss = 0.07646165209325102
Trained batch 339 in epoch 4, gen_loss = 0.8390383744941038, disc_loss = 0.0763678334571202
Trained batch 340 in epoch 4, gen_loss = 0.8382325252829409, disc_loss = 0.07648887836218667
Trained batch 341 in epoch 4, gen_loss = 0.8384034061989589, disc_loss = 0.07641708538513521
Trained batch 342 in epoch 4, gen_loss = 0.8389165523100872, disc_loss = 0.07640078059145122
Trained batch 343 in epoch 4, gen_loss = 0.8383810672649118, disc_loss = 0.0763686902869796
Trained batch 344 in epoch 4, gen_loss = 0.8381288728852203, disc_loss = 0.07634161625705335
Trained batch 345 in epoch 4, gen_loss = 0.8376399661075173, disc_loss = 0.07639306815168848
Trained batch 346 in epoch 4, gen_loss = 0.8382648834234012, disc_loss = 0.07649418616382894
Trained batch 347 in epoch 4, gen_loss = 0.838273289217346, disc_loss = 0.07639388637563706
Trained batch 348 in epoch 4, gen_loss = 0.8386758487340714, disc_loss = 0.07624482813112458
Trained batch 349 in epoch 4, gen_loss = 0.8389131695883615, disc_loss = 0.07613185134583286
Trained batch 350 in epoch 4, gen_loss = 0.8383546116684917, disc_loss = 0.0760676151014164
Trained batch 351 in epoch 4, gen_loss = 0.8383894776078787, disc_loss = 0.07616621810699474
Trained batch 352 in epoch 4, gen_loss = 0.8385827504203948, disc_loss = 0.07600892828276154
Trained batch 353 in epoch 4, gen_loss = 0.8393616423768512, disc_loss = 0.07587606078119012
Trained batch 354 in epoch 4, gen_loss = 0.8384598894858024, disc_loss = 0.0760724098880736
Trained batch 355 in epoch 4, gen_loss = 0.8387047616618403, disc_loss = 0.07593496337669033
Trained batch 356 in epoch 4, gen_loss = 0.8398220650956076, disc_loss = 0.07594386886033107
Trained batch 357 in epoch 4, gen_loss = 0.839753627943593, disc_loss = 0.07598413107916713
Trained batch 358 in epoch 4, gen_loss = 0.839803587593408, disc_loss = 0.07591994578138118
Trained batch 359 in epoch 4, gen_loss = 0.8404371081127061, disc_loss = 0.07667934151832015
Trained batch 360 in epoch 4, gen_loss = 0.840097234519895, disc_loss = 0.07662321117621462
Trained batch 361 in epoch 4, gen_loss = 0.8396164493336862, disc_loss = 0.07664870899119183
Trained batch 362 in epoch 4, gen_loss = 0.8398759125349607, disc_loss = 0.07676910699573512
Trained batch 363 in epoch 4, gen_loss = 0.8398830625382099, disc_loss = 0.07671371227447557
Trained batch 364 in epoch 4, gen_loss = 0.8399962252133513, disc_loss = 0.07668857507356634
Trained batch 365 in epoch 4, gen_loss = 0.8408713376587206, disc_loss = 0.07674995354056115
Trained batch 366 in epoch 4, gen_loss = 0.8408117557416495, disc_loss = 0.07665937593110332
Trained batch 367 in epoch 4, gen_loss = 0.8407798723682113, disc_loss = 0.07651285003901095
Trained batch 368 in epoch 4, gen_loss = 0.8402875676387693, disc_loss = 0.07647220852726763
Trained batch 369 in epoch 4, gen_loss = 0.8410290581149024, disc_loss = 0.07652141364996096
Trained batch 370 in epoch 4, gen_loss = 0.8407499454413463, disc_loss = 0.07651035603878874
Trained batch 371 in epoch 4, gen_loss = 0.8405663359870192, disc_loss = 0.07639898011030288
Trained batch 372 in epoch 4, gen_loss = 0.8406391396279629, disc_loss = 0.07626803891718308
Trained batch 373 in epoch 4, gen_loss = 0.8407590733492438, disc_loss = 0.07623774957977594
Trained batch 374 in epoch 4, gen_loss = 0.8404497281710307, disc_loss = 0.0762239689156413
Trained batch 375 in epoch 4, gen_loss = 0.8400793253107274, disc_loss = 0.07619121743296768
Trained batch 376 in epoch 4, gen_loss = 0.8407793810260075, disc_loss = 0.07608892148316143
Trained batch 377 in epoch 4, gen_loss = 0.8402100533404678, disc_loss = 0.07601485933822694
Trained batch 378 in epoch 4, gen_loss = 0.8401605537195633, disc_loss = 0.07588929695010893
Trained batch 379 in epoch 4, gen_loss = 0.8413904160261154, disc_loss = 0.07601820771876526
Trained batch 380 in epoch 4, gen_loss = 0.841182009910974, disc_loss = 0.0759283532938502
Trained batch 381 in epoch 4, gen_loss = 0.8403156800731939, disc_loss = 0.07624400691104886
Trained batch 382 in epoch 4, gen_loss = 0.8405673002760964, disc_loss = 0.07626137646357711
Trained batch 383 in epoch 4, gen_loss = 0.8403250249102712, disc_loss = 0.0762456667459143
Trained batch 384 in epoch 4, gen_loss = 0.8402445474228302, disc_loss = 0.07615905449810353
Trained batch 385 in epoch 4, gen_loss = 0.8404347899664252, disc_loss = 0.07602320602067163
Trained batch 386 in epoch 4, gen_loss = 0.8397733980371046, disc_loss = 0.0761647113365451
Trained batch 387 in epoch 4, gen_loss = 0.840150478881659, disc_loss = 0.07645214643070147
Trained batch 388 in epoch 4, gen_loss = 0.8395913928210889, disc_loss = 0.07644233508107365
Trained batch 389 in epoch 4, gen_loss = 0.8396134171730433, disc_loss = 0.07635394905287868
Trained batch 390 in epoch 4, gen_loss = 0.8395458923276428, disc_loss = 0.07626163260415768
Trained batch 391 in epoch 4, gen_loss = 0.8399556346085607, disc_loss = 0.07627371928835174
Trained batch 392 in epoch 4, gen_loss = 0.8394365043737203, disc_loss = 0.07640407776872393
Trained batch 393 in epoch 4, gen_loss = 0.8392634921267553, disc_loss = 0.07637953325434763
Trained batch 394 in epoch 4, gen_loss = 0.839562905136543, disc_loss = 0.07641273378807155
Trained batch 395 in epoch 4, gen_loss = 0.8391229927238791, disc_loss = 0.07637966537349528
Trained batch 396 in epoch 4, gen_loss = 0.8393227992490196, disc_loss = 0.07629974536663414
Trained batch 397 in epoch 4, gen_loss = 0.8388634166825357, disc_loss = 0.07625400938851824
Trained batch 398 in epoch 4, gen_loss = 0.83839180789197, disc_loss = 0.0762706706253695
Trained batch 399 in epoch 4, gen_loss = 0.8383908547461033, disc_loss = 0.07613908388884738
Trained batch 400 in epoch 4, gen_loss = 0.8384219956516922, disc_loss = 0.07607969521147726
Trained batch 401 in epoch 4, gen_loss = 0.8382382145271966, disc_loss = 0.07595785858517337
Trained batch 402 in epoch 4, gen_loss = 0.8379574064581329, disc_loss = 0.07585485044071826
Trained batch 403 in epoch 4, gen_loss = 0.838060336832953, disc_loss = 0.075830412394653
Trained batch 404 in epoch 4, gen_loss = 0.8383931014272902, disc_loss = 0.07577094486512152
Trained batch 405 in epoch 4, gen_loss = 0.8382159387830443, disc_loss = 0.07575590327941799
Trained batch 406 in epoch 4, gen_loss = 0.8382681511543892, disc_loss = 0.07561136737090583
Trained batch 407 in epoch 4, gen_loss = 0.8390144997952032, disc_loss = 0.07551455405294238
Trained batch 408 in epoch 4, gen_loss = 0.8395997720126126, disc_loss = 0.07539042134821633
Trained batch 409 in epoch 4, gen_loss = 0.8393575653797243, disc_loss = 0.07534554934401701
Trained batch 410 in epoch 4, gen_loss = 0.8393756908221837, disc_loss = 0.07524243850315357
Trained batch 411 in epoch 4, gen_loss = 0.8392810072135, disc_loss = 0.07521099500692657
Trained batch 412 in epoch 4, gen_loss = 0.8390516850907924, disc_loss = 0.07509219086532803
Trained batch 413 in epoch 4, gen_loss = 0.8392447224561719, disc_loss = 0.07551620788377336
Trained batch 414 in epoch 4, gen_loss = 0.8390545560652951, disc_loss = 0.07542015340358738
Trained batch 415 in epoch 4, gen_loss = 0.838596990905129, disc_loss = 0.07539473260224511
Trained batch 416 in epoch 4, gen_loss = 0.8388250801774809, disc_loss = 0.07529205873796194
Trained batch 417 in epoch 4, gen_loss = 0.8390442545048928, disc_loss = 0.07526303102534139
Trained batch 418 in epoch 4, gen_loss = 0.8385344473445046, disc_loss = 0.07536215550512929
Trained batch 419 in epoch 4, gen_loss = 0.8383782366911571, disc_loss = 0.07522922038721541
Trained batch 420 in epoch 4, gen_loss = 0.8383594408737509, disc_loss = 0.07525467902041458
Trained batch 421 in epoch 4, gen_loss = 0.8381087757399862, disc_loss = 0.07514137518040448
Trained batch 422 in epoch 4, gen_loss = 0.838409503864622, disc_loss = 0.07520932965993388
Trained batch 423 in epoch 4, gen_loss = 0.8383636608157518, disc_loss = 0.07521042901855665
Trained batch 424 in epoch 4, gen_loss = 0.8384767320576836, disc_loss = 0.07507924117367057
Trained batch 425 in epoch 4, gen_loss = 0.8382775096546317, disc_loss = 0.07499189602928193
Trained batch 426 in epoch 4, gen_loss = 0.8390264942439435, disc_loss = 0.07516257082541807
Trained batch 427 in epoch 4, gen_loss = 0.838675853665744, disc_loss = 0.07515874619717562
Trained batch 428 in epoch 4, gen_loss = 0.8383474882110293, disc_loss = 0.07517481454385397
Trained batch 429 in epoch 4, gen_loss = 0.8378865146359732, disc_loss = 0.07530564506170015
Trained batch 430 in epoch 4, gen_loss = 0.8378401353021785, disc_loss = 0.07535772272569329
Trained batch 431 in epoch 4, gen_loss = 0.8373009281025993, disc_loss = 0.07539763482485863
Trained batch 432 in epoch 4, gen_loss = 0.837643049330414, disc_loss = 0.07582755735914028
Trained batch 433 in epoch 4, gen_loss = 0.8372561983798507, disc_loss = 0.07574514514865345
Trained batch 434 in epoch 4, gen_loss = 0.8369364242444093, disc_loss = 0.07571683401648684
Trained batch 435 in epoch 4, gen_loss = 0.83649043479097, disc_loss = 0.07578829302315797
Trained batch 436 in epoch 4, gen_loss = 0.8366916542467864, disc_loss = 0.07599106279907224
Trained batch 437 in epoch 4, gen_loss = 0.836480539955505, disc_loss = 0.07591786311905338
Trained batch 438 in epoch 4, gen_loss = 0.8358562144711783, disc_loss = 0.0759844365328177
Trained batch 439 in epoch 4, gen_loss = 0.8355235430327329, disc_loss = 0.07603042770642787
Trained batch 440 in epoch 4, gen_loss = 0.836078857618665, disc_loss = 0.07607964157441509
Trained batch 441 in epoch 4, gen_loss = 0.836139936792365, disc_loss = 0.07600894002918138
Trained batch 442 in epoch 4, gen_loss = 0.836431461047911, disc_loss = 0.07589823451801361
Trained batch 443 in epoch 4, gen_loss = 0.8360950084956916, disc_loss = 0.07583753929288874
Trained batch 444 in epoch 4, gen_loss = 0.8361289511905627, disc_loss = 0.07579219049324146
Trained batch 445 in epoch 4, gen_loss = 0.8365109079087262, disc_loss = 0.07566052208959455
Trained batch 446 in epoch 4, gen_loss = 0.8363260585456354, disc_loss = 0.07574245853503746
Trained batch 447 in epoch 4, gen_loss = 0.8357175913240228, disc_loss = 0.0759618308573928
Trained batch 448 in epoch 4, gen_loss = 0.8366883207270192, disc_loss = 0.0761065456190692
Trained batch 449 in epoch 4, gen_loss = 0.836100250085195, disc_loss = 0.07627767109001676
Trained batch 450 in epoch 4, gen_loss = 0.8363263281908903, disc_loss = 0.0763861030121303
Trained batch 451 in epoch 4, gen_loss = 0.8365014029287658, disc_loss = 0.07643002604414602
Trained batch 452 in epoch 4, gen_loss = 0.8363313339403923, disc_loss = 0.07651508656879331
Trained batch 453 in epoch 4, gen_loss = 0.836063414286937, disc_loss = 0.07651105260328771
Trained batch 454 in epoch 4, gen_loss = 0.835990190243983, disc_loss = 0.0764896181729305
Trained batch 455 in epoch 4, gen_loss = 0.8357571758199156, disc_loss = 0.07643469287237774
Trained batch 456 in epoch 4, gen_loss = 0.8357586602413419, disc_loss = 0.0763556220644119
Trained batch 457 in epoch 4, gen_loss = 0.8359014372377938, disc_loss = 0.07630756335316723
Trained batch 458 in epoch 4, gen_loss = 0.83533445136999, disc_loss = 0.0764413194260144
Trained batch 459 in epoch 4, gen_loss = 0.8355462748071422, disc_loss = 0.07668261496228693
Trained batch 460 in epoch 4, gen_loss = 0.835807219891124, disc_loss = 0.07655214290225519
Trained batch 461 in epoch 4, gen_loss = 0.8351375660596988, disc_loss = 0.07661930719809808
Trained batch 462 in epoch 4, gen_loss = 0.8349708543997861, disc_loss = 0.07657289132274703
Trained batch 463 in epoch 4, gen_loss = 0.835518482044853, disc_loss = 0.07659209513803944
Trained batch 464 in epoch 4, gen_loss = 0.8359387752830342, disc_loss = 0.07647892214878592
Trained batch 465 in epoch 4, gen_loss = 0.8362551395473562, disc_loss = 0.07634718794287722
Trained batch 466 in epoch 4, gen_loss = 0.8363300066688587, disc_loss = 0.07631856253933025
Trained batch 467 in epoch 4, gen_loss = 0.8370549240682879, disc_loss = 0.07632358671309283
Trained batch 468 in epoch 4, gen_loss = 0.8369431602421091, disc_loss = 0.07624638155063014
Trained batch 469 in epoch 4, gen_loss = 0.836671991551176, disc_loss = 0.07621518975678594
Trained batch 470 in epoch 4, gen_loss = 0.8370938751601363, disc_loss = 0.07609016955444578
Trained batch 471 in epoch 4, gen_loss = 0.8370660376750817, disc_loss = 0.07598787033338479
Trained batch 472 in epoch 4, gen_loss = 0.8372791442256146, disc_loss = 0.07587920353958584
Trained batch 473 in epoch 4, gen_loss = 0.8374492635455313, disc_loss = 0.07577794120069357
Trained batch 474 in epoch 4, gen_loss = 0.837686029358914, disc_loss = 0.07565940953202938
Trained batch 475 in epoch 4, gen_loss = 0.8380952371018273, disc_loss = 0.07553997911520678
Trained batch 476 in epoch 4, gen_loss = 0.8378713355874116, disc_loss = 0.0754646089502007
Trained batch 477 in epoch 4, gen_loss = 0.8378762410774391, disc_loss = 0.07545449487498677
Trained batch 478 in epoch 4, gen_loss = 0.8380797410807679, disc_loss = 0.07536159546964166
Trained batch 479 in epoch 4, gen_loss = 0.8381159064670404, disc_loss = 0.07528069835195007
Trained batch 480 in epoch 4, gen_loss = 0.8382439408877288, disc_loss = 0.0751584387033899
Trained batch 481 in epoch 4, gen_loss = 0.8378978435923944, disc_loss = 0.07512179393653615
Trained batch 482 in epoch 4, gen_loss = 0.8384500157018626, disc_loss = 0.07529144185955788
Trained batch 483 in epoch 4, gen_loss = 0.8386336409848584, disc_loss = 0.07521816283995517
Trained batch 484 in epoch 4, gen_loss = 0.8378288261669198, disc_loss = 0.07559594029042217
Trained batch 485 in epoch 4, gen_loss = 0.8382925224402313, disc_loss = 0.0755642824921251
Trained batch 486 in epoch 4, gen_loss = 0.8383928392946842, disc_loss = 0.07544041367809937
Trained batch 487 in epoch 4, gen_loss = 0.8383661105495984, disc_loss = 0.07540845142898807
Trained batch 488 in epoch 4, gen_loss = 0.8385002710580338, disc_loss = 0.07537692092960903
Trained batch 489 in epoch 4, gen_loss = 0.8384965105932586, disc_loss = 0.07526936665063305
Trained batch 490 in epoch 4, gen_loss = 0.8383177329469358, disc_loss = 0.07517981813943617
Trained batch 491 in epoch 4, gen_loss = 0.8381918688130573, disc_loss = 0.07511380906368235
Trained batch 492 in epoch 4, gen_loss = 0.8379495355468735, disc_loss = 0.07511556927779686
Trained batch 493 in epoch 4, gen_loss = 0.8385003451634998, disc_loss = 0.07512514491712577
Trained batch 494 in epoch 4, gen_loss = 0.8387864661939216, disc_loss = 0.0749972783894551
Trained batch 495 in epoch 4, gen_loss = 0.83876721368682, disc_loss = 0.07490143544536325
Trained batch 496 in epoch 4, gen_loss = 0.8389614405526482, disc_loss = 0.07482088660405316
Trained batch 497 in epoch 4, gen_loss = 0.8392796537962305, disc_loss = 0.0747070559506196
Trained batch 498 in epoch 4, gen_loss = 0.8390282419974914, disc_loss = 0.07466413037392323
Trained batch 499 in epoch 4, gen_loss = 0.8389772540330886, disc_loss = 0.07461146995425225
Trained batch 500 in epoch 4, gen_loss = 0.8389521376815384, disc_loss = 0.07450491747263067
Trained batch 501 in epoch 4, gen_loss = 0.8388615726712215, disc_loss = 0.07440976413760883
Trained batch 502 in epoch 4, gen_loss = 0.838363384750207, disc_loss = 0.074400663401776
Trained batch 503 in epoch 4, gen_loss = 0.8386681161466099, disc_loss = 0.07427460762176899
Trained batch 504 in epoch 4, gen_loss = 0.8388722894215348, disc_loss = 0.07424647288562933
Trained batch 505 in epoch 4, gen_loss = 0.8390085508700887, disc_loss = 0.07415239242174232
Trained batch 506 in epoch 4, gen_loss = 0.8397282764051087, disc_loss = 0.07410799613667017
Trained batch 507 in epoch 4, gen_loss = 0.8406336342725228, disc_loss = 0.07409049475411554
Trained batch 508 in epoch 4, gen_loss = 0.8407654854778223, disc_loss = 0.0739989785938606
Trained batch 509 in epoch 4, gen_loss = 0.840256014992209, disc_loss = 0.07411596824177633
Trained batch 510 in epoch 4, gen_loss = 0.8408477458002049, disc_loss = 0.07419497855991825
Trained batch 511 in epoch 4, gen_loss = 0.8408528408035636, disc_loss = 0.07409920507234347
Trained batch 512 in epoch 4, gen_loss = 0.8405018440696463, disc_loss = 0.0741269943444149
Trained batch 513 in epoch 4, gen_loss = 0.840588631565005, disc_loss = 0.07410337138333963
Trained batch 514 in epoch 4, gen_loss = 0.8407491327489464, disc_loss = 0.07413825789303745
Trained batch 515 in epoch 4, gen_loss = 0.8402635477078978, disc_loss = 0.07422217543511254
Trained batch 516 in epoch 4, gen_loss = 0.8399084023626907, disc_loss = 0.07425028108946648
Trained batch 517 in epoch 4, gen_loss = 0.8404068015947305, disc_loss = 0.07439467699435974
Trained batch 518 in epoch 4, gen_loss = 0.8404313556720756, disc_loss = 0.07437262068429032
Trained batch 519 in epoch 4, gen_loss = 0.8402022485549633, disc_loss = 0.07436317910547727
Trained batch 520 in epoch 4, gen_loss = 0.8404214784874797, disc_loss = 0.07439600740829322
Trained batch 521 in epoch 4, gen_loss = 0.8406119252986834, disc_loss = 0.07429581168518042
Trained batch 522 in epoch 4, gen_loss = 0.8402704636407856, disc_loss = 0.07431786346568034
Trained batch 523 in epoch 4, gen_loss = 0.8406239925450041, disc_loss = 0.0742871869899304
Trained batch 524 in epoch 4, gen_loss = 0.8405478159586589, disc_loss = 0.07437536355462812
Trained batch 525 in epoch 4, gen_loss = 0.8402236749917382, disc_loss = 0.07437472648302469
Trained batch 526 in epoch 4, gen_loss = 0.8401073226440111, disc_loss = 0.07428400698285798
Trained batch 527 in epoch 4, gen_loss = 0.8403227338285157, disc_loss = 0.07422149239044468
Trained batch 528 in epoch 4, gen_loss = 0.8401553455057126, disc_loss = 0.0741787048387702
Trained batch 529 in epoch 4, gen_loss = 0.8402977329380107, disc_loss = 0.07406613103658805
Trained batch 530 in epoch 4, gen_loss = 0.8407300760068014, disc_loss = 0.0742234896023086
Trained batch 531 in epoch 4, gen_loss = 0.8399356875316542, disc_loss = 0.07476288765927959
Trained batch 532 in epoch 4, gen_loss = 0.8399779277156486, disc_loss = 0.0747400075284586
Trained batch 533 in epoch 4, gen_loss = 0.8399132846781378, disc_loss = 0.07478951839451095
Trained batch 534 in epoch 4, gen_loss = 0.8395099159156051, disc_loss = 0.0747841632759599
Trained batch 535 in epoch 4, gen_loss = 0.8397706520757569, disc_loss = 0.07467726446556122
Trained batch 536 in epoch 4, gen_loss = 0.839578466319949, disc_loss = 0.07470803507525661
Trained batch 537 in epoch 4, gen_loss = 0.8394078663844602, disc_loss = 0.07462366648039133
Trained batch 538 in epoch 4, gen_loss = 0.8394858962640249, disc_loss = 0.07457341075959531
Trained batch 539 in epoch 4, gen_loss = 0.839528925716877, disc_loss = 0.07445771205928867
Trained batch 540 in epoch 4, gen_loss = 0.8391097378047689, disc_loss = 0.0744754768057611
Trained batch 541 in epoch 4, gen_loss = 0.8397459360836177, disc_loss = 0.07451065438816744
Trained batch 542 in epoch 4, gen_loss = 0.8395924049517067, disc_loss = 0.07442118179286328
Trained batch 543 in epoch 4, gen_loss = 0.8395394651657518, disc_loss = 0.07432004790376488
Trained batch 544 in epoch 4, gen_loss = 0.8395032220477358, disc_loss = 0.07422921696011353
Trained batch 545 in epoch 4, gen_loss = 0.8395023300643369, disc_loss = 0.07419792657731708
Trained batch 546 in epoch 4, gen_loss = 0.8392778228035357, disc_loss = 0.07413285030341508
Trained batch 547 in epoch 4, gen_loss = 0.8392821214821217, disc_loss = 0.07406771835789465
Trained batch 548 in epoch 4, gen_loss = 0.8397156166791482, disc_loss = 0.07442367999884003
Trained batch 549 in epoch 4, gen_loss = 0.8393060055104169, disc_loss = 0.07447625371712176
Trained batch 550 in epoch 4, gen_loss = 0.8395028946728542, disc_loss = 0.07436546739765498
Trained batch 551 in epoch 4, gen_loss = 0.8393289051086142, disc_loss = 0.07430388176125353
Trained batch 552 in epoch 4, gen_loss = 0.839665188011166, disc_loss = 0.07423101318073855
Trained batch 553 in epoch 4, gen_loss = 0.8399052038412231, disc_loss = 0.07422052037024648
Trained batch 554 in epoch 4, gen_loss = 0.8396502092614904, disc_loss = 0.07418055756873376
Trained batch 555 in epoch 4, gen_loss = 0.8401008453622139, disc_loss = 0.07411028618636213
Trained batch 556 in epoch 4, gen_loss = 0.8395723792017041, disc_loss = 0.07424663376109926
Trained batch 557 in epoch 4, gen_loss = 0.8398105578503728, disc_loss = 0.07421068298066281
Trained batch 558 in epoch 4, gen_loss = 0.840235616898494, disc_loss = 0.07414655990845295
Trained batch 559 in epoch 4, gen_loss = 0.8402587176965816, disc_loss = 0.07407601692248136
Trained batch 560 in epoch 4, gen_loss = 0.840576860515829, disc_loss = 0.07396574997062565
Trained batch 561 in epoch 4, gen_loss = 0.8404468511665419, disc_loss = 0.07389012568388333
Trained batch 562 in epoch 4, gen_loss = 0.8407274913936059, disc_loss = 0.07380188351123201
Trained batch 563 in epoch 4, gen_loss = 0.8405542941697945, disc_loss = 0.07376541092938987
Trained batch 564 in epoch 4, gen_loss = 0.840599833600289, disc_loss = 0.07370767183931529
Trained batch 565 in epoch 4, gen_loss = 0.8406325096902915, disc_loss = 0.07360722537583576
Trained batch 566 in epoch 4, gen_loss = 0.8413660188305735, disc_loss = 0.07357612846507913
Trained batch 567 in epoch 4, gen_loss = 0.8414346350645515, disc_loss = 0.07349517676179153
Trained batch 568 in epoch 4, gen_loss = 0.8413413171713717, disc_loss = 0.0734285019658938
Trained batch 569 in epoch 4, gen_loss = 0.8412322150510654, disc_loss = 0.0733702945441269
Trained batch 570 in epoch 4, gen_loss = 0.8410436790273402, disc_loss = 0.07334682335277885
Trained batch 571 in epoch 4, gen_loss = 0.840634956486992, disc_loss = 0.07335339031032437
Trained batch 572 in epoch 4, gen_loss = 0.8407534967854385, disc_loss = 0.073275783273146
Trained batch 573 in epoch 4, gen_loss = 0.8409913609563682, disc_loss = 0.07322950564480617
Trained batch 574 in epoch 4, gen_loss = 0.8409129266635231, disc_loss = 0.07316657621575438
Trained batch 575 in epoch 4, gen_loss = 0.8405817930793597, disc_loss = 0.0732231274079014
Trained batch 576 in epoch 4, gen_loss = 0.8407032516118352, disc_loss = 0.07312592352374071
Trained batch 577 in epoch 4, gen_loss = 0.8409876503230791, disc_loss = 0.07302608857556507
Trained batch 578 in epoch 4, gen_loss = 0.8415015004768273, disc_loss = 0.07297294809191852
Trained batch 579 in epoch 4, gen_loss = 0.841128063150521, disc_loss = 0.07306160227684626
Trained batch 580 in epoch 4, gen_loss = 0.8419834216880306, disc_loss = 0.07329703243882131
Trained batch 581 in epoch 4, gen_loss = 0.841827944945224, disc_loss = 0.07323243838648513
Trained batch 582 in epoch 4, gen_loss = 0.8413041866357289, disc_loss = 0.07330081197489086
Trained batch 583 in epoch 4, gen_loss = 0.8412191547861655, disc_loss = 0.07323878166291302
Trained batch 584 in epoch 4, gen_loss = 0.8420585011315141, disc_loss = 0.0735215259126873
Trained batch 585 in epoch 4, gen_loss = 0.8422843156312513, disc_loss = 0.07343282325530215
Trained batch 586 in epoch 4, gen_loss = 0.8416785466305442, disc_loss = 0.0735481768414962
Trained batch 587 in epoch 4, gen_loss = 0.8415751101917961, disc_loss = 0.07349519206046247
Trained batch 588 in epoch 4, gen_loss = 0.8416606175170892, disc_loss = 0.07343208390099892
Trained batch 589 in epoch 4, gen_loss = 0.841546194381633, disc_loss = 0.07343723420369423
Trained batch 590 in epoch 4, gen_loss = 0.8418411120848002, disc_loss = 0.07346979482020621
Trained batch 591 in epoch 4, gen_loss = 0.8411777642228313, disc_loss = 0.07379840749844506
Trained batch 592 in epoch 4, gen_loss = 0.8414447169380285, disc_loss = 0.07384758398665546
Trained batch 593 in epoch 4, gen_loss = 0.8416379346490308, disc_loss = 0.07376587802939343
Trained batch 594 in epoch 4, gen_loss = 0.8415889895763717, disc_loss = 0.07368020734929738
Trained batch 595 in epoch 4, gen_loss = 0.8416034756790871, disc_loss = 0.07359344999449666
Trained batch 596 in epoch 4, gen_loss = 0.8413125317999266, disc_loss = 0.07360636773308617
Trained batch 597 in epoch 4, gen_loss = 0.841409148131326, disc_loss = 0.07353945601930885
Trained batch 598 in epoch 4, gen_loss = 0.8415555400223486, disc_loss = 0.07350626266646962
Trained batch 599 in epoch 4, gen_loss = 0.841592507114013, disc_loss = 0.07342199930300315
Trained batch 600 in epoch 4, gen_loss = 0.8415461528221898, disc_loss = 0.0733639279166593
Trained batch 601 in epoch 4, gen_loss = 0.8413307227664611, disc_loss = 0.0733701617045458
Trained batch 602 in epoch 4, gen_loss = 0.8418410651225158, disc_loss = 0.07361468355206906
Trained batch 603 in epoch 4, gen_loss = 0.842130893755038, disc_loss = 0.07352733765019487
Trained batch 604 in epoch 4, gen_loss = 0.841958701364265, disc_loss = 0.07344815501989412
Trained batch 605 in epoch 4, gen_loss = 0.8417300874545629, disc_loss = 0.0734193863119721
Trained batch 606 in epoch 4, gen_loss = 0.8416256955172713, disc_loss = 0.07342422723500104
Trained batch 607 in epoch 4, gen_loss = 0.8417464051101553, disc_loss = 0.0734459338403356
Trained batch 608 in epoch 4, gen_loss = 0.841211304435589, disc_loss = 0.07377687083749936
Trained batch 609 in epoch 4, gen_loss = 0.8415214717876716, disc_loss = 0.0737532662624707
Trained batch 610 in epoch 4, gen_loss = 0.8416404608521251, disc_loss = 0.07373232473108655
Trained batch 611 in epoch 4, gen_loss = 0.841678131006512, disc_loss = 0.07365086828693261
Trained batch 612 in epoch 4, gen_loss = 0.8416586311664705, disc_loss = 0.07357867522131754
Trained batch 613 in epoch 4, gen_loss = 0.8412463756745335, disc_loss = 0.07363770471988944
Trained batch 614 in epoch 4, gen_loss = 0.8410904152121971, disc_loss = 0.07363769455048128
Trained batch 615 in epoch 4, gen_loss = 0.8412358660686325, disc_loss = 0.07364404471833016
Trained batch 616 in epoch 4, gen_loss = 0.8411065537597218, disc_loss = 0.07360808432367864
Trained batch 617 in epoch 4, gen_loss = 0.8407982155246642, disc_loss = 0.07362143486183631
Trained batch 618 in epoch 4, gen_loss = 0.8410359062073882, disc_loss = 0.07374565486881961
Trained batch 619 in epoch 4, gen_loss = 0.8409275838924992, disc_loss = 0.07372960917531482
Trained batch 620 in epoch 4, gen_loss = 0.8406840563300343, disc_loss = 0.07376192499929964
Trained batch 621 in epoch 4, gen_loss = 0.8408181974454708, disc_loss = 0.07367771368928948
Trained batch 622 in epoch 4, gen_loss = 0.8416336052012099, disc_loss = 0.07373860163575287
Trained batch 623 in epoch 4, gen_loss = 0.8420050184791669, disc_loss = 0.0736826094171892
Trained batch 624 in epoch 4, gen_loss = 0.841639567899704, disc_loss = 0.07370435806214809
Trained batch 625 in epoch 4, gen_loss = 0.8414306082188512, disc_loss = 0.0736473646318427
Trained batch 626 in epoch 4, gen_loss = 0.8411570968525262, disc_loss = 0.07368077568567255
Trained batch 627 in epoch 4, gen_loss = 0.8415315290260467, disc_loss = 0.07386955438822412
Trained batch 628 in epoch 4, gen_loss = 0.8413673610395392, disc_loss = 0.07389332909901021
Trained batch 629 in epoch 4, gen_loss = 0.8413281040059195, disc_loss = 0.07381352274013417
Trained batch 630 in epoch 4, gen_loss = 0.841311875169893, disc_loss = 0.07378882798181756
Trained batch 631 in epoch 4, gen_loss = 0.8409023138258276, disc_loss = 0.07379409074606492
Trained batch 632 in epoch 4, gen_loss = 0.8405827932165697, disc_loss = 0.07383946153095454
Trained batch 633 in epoch 4, gen_loss = 0.8409264340103613, disc_loss = 0.07420047825313987
Trained batch 634 in epoch 4, gen_loss = 0.840627032049059, disc_loss = 0.07424747135754176
Trained batch 635 in epoch 4, gen_loss = 0.8403577350501744, disc_loss = 0.07427064118813137
Trained batch 636 in epoch 4, gen_loss = 0.8402824545486756, disc_loss = 0.0742426886072666
Trained batch 637 in epoch 4, gen_loss = 0.8401040838897041, disc_loss = 0.07418775174556574
Trained batch 638 in epoch 4, gen_loss = 0.839746010835182, disc_loss = 0.07424315358096725
Trained batch 639 in epoch 4, gen_loss = 0.8391482142265886, disc_loss = 0.0745052460610168
Trained batch 640 in epoch 4, gen_loss = 0.8397162739367642, disc_loss = 0.07466201138117477
Trained batch 641 in epoch 4, gen_loss = 0.8394663665803422, disc_loss = 0.07475259088014609
Trained batch 642 in epoch 4, gen_loss = 0.8392541511896795, disc_loss = 0.07479667446024217
Trained batch 643 in epoch 4, gen_loss = 0.8391410730177571, disc_loss = 0.07478513950713395
Trained batch 644 in epoch 4, gen_loss = 0.8398573664269706, disc_loss = 0.0749769008003695
Trained batch 645 in epoch 4, gen_loss = 0.8395392351752096, disc_loss = 0.07502006556285147
Trained batch 646 in epoch 4, gen_loss = 0.8394887988589462, disc_loss = 0.07496522702391863
Trained batch 647 in epoch 4, gen_loss = 0.839525191642252, disc_loss = 0.07492589524855124
Trained batch 648 in epoch 4, gen_loss = 0.8394426162970268, disc_loss = 0.0749675098244095
Trained batch 649 in epoch 4, gen_loss = 0.8393696531424155, disc_loss = 0.07494039347825142
Trained batch 650 in epoch 4, gen_loss = 0.8392142067948062, disc_loss = 0.07495382144623729
Trained batch 651 in epoch 4, gen_loss = 0.8394525094540572, disc_loss = 0.07497165968321676
Trained batch 652 in epoch 4, gen_loss = 0.8394629443677607, disc_loss = 0.07489289879901577
Trained batch 653 in epoch 4, gen_loss = 0.8395085731686438, disc_loss = 0.0748250010973042
Trained batch 654 in epoch 4, gen_loss = 0.8392197231755002, disc_loss = 0.07484198837960494
Trained batch 655 in epoch 4, gen_loss = 0.8397609449287013, disc_loss = 0.07491045469906545
Trained batch 656 in epoch 4, gen_loss = 0.8398438078355571, disc_loss = 0.07481566672830005
Trained batch 657 in epoch 4, gen_loss = 0.8399859336643596, disc_loss = 0.07474185650641704
Trained batch 658 in epoch 4, gen_loss = 0.8402336091933735, disc_loss = 0.07465058739533102
Trained batch 659 in epoch 4, gen_loss = 0.8402042870720228, disc_loss = 0.0745954637472151
Trained batch 660 in epoch 4, gen_loss = 0.840191450990094, disc_loss = 0.07451742314050219
Trained batch 661 in epoch 4, gen_loss = 0.8403695097412588, disc_loss = 0.07450114089567945
Trained batch 662 in epoch 4, gen_loss = 0.840030015638691, disc_loss = 0.07456980643689992
Trained batch 663 in epoch 4, gen_loss = 0.8401415500206402, disc_loss = 0.07453254080960998
Trained batch 664 in epoch 4, gen_loss = 0.8400949328913725, disc_loss = 0.07447368686640621
Trained batch 665 in epoch 4, gen_loss = 0.84035657919026, disc_loss = 0.07462336027060633
Trained batch 666 in epoch 4, gen_loss = 0.840208941805309, disc_loss = 0.0746203602572297
Trained batch 667 in epoch 4, gen_loss = 0.8397968720622405, disc_loss = 0.0747235746089436
Trained batch 668 in epoch 4, gen_loss = 0.8397849003919393, disc_loss = 0.07498782979232581
Trained batch 669 in epoch 4, gen_loss = 0.8392435754857847, disc_loss = 0.07520168493988354
Trained batch 670 in epoch 4, gen_loss = 0.8394301242782177, disc_loss = 0.07535448629581182
Trained batch 671 in epoch 4, gen_loss = 0.8398106418816107, disc_loss = 0.07645078561368532
Trained batch 672 in epoch 4, gen_loss = 0.840310415178316, disc_loss = 0.07752670690051956
Trained batch 673 in epoch 4, gen_loss = 0.8407720047483105, disc_loss = 0.07863506178706
Trained batch 674 in epoch 4, gen_loss = 0.8410290023574123, disc_loss = 0.07906207132394667
Trained batch 675 in epoch 4, gen_loss = 0.8405282813504603, disc_loss = 0.07954020149311458
Trained batch 676 in epoch 4, gen_loss = 0.840461245359663, disc_loss = 0.0796839094017818
Trained batch 677 in epoch 4, gen_loss = 0.8403449844909628, disc_loss = 0.07994227785243485
Trained batch 678 in epoch 4, gen_loss = 0.8400022264169488, disc_loss = 0.08008563094148316
Trained batch 679 in epoch 4, gen_loss = 0.8394731997567064, disc_loss = 0.08036556451252716
Trained batch 680 in epoch 4, gen_loss = 0.8391833645831821, disc_loss = 0.08052007352082652
Trained batch 681 in epoch 4, gen_loss = 0.8390371449007666, disc_loss = 0.08062223879527573
Trained batch 682 in epoch 4, gen_loss = 0.838720578574855, disc_loss = 0.08074606943324666
Trained batch 683 in epoch 4, gen_loss = 0.8384308591049318, disc_loss = 0.08081822039842693
Trained batch 684 in epoch 4, gen_loss = 0.83804124663346, disc_loss = 0.08090768564410888
Trained batch 685 in epoch 4, gen_loss = 0.8378551601494714, disc_loss = 0.08105424847236614
Trained batch 686 in epoch 4, gen_loss = 0.8376666173837765, disc_loss = 0.08112085450391843
Trained batch 687 in epoch 4, gen_loss = 0.8372537750144338, disc_loss = 0.08127070000925816
Trained batch 688 in epoch 4, gen_loss = 0.8368615478666497, disc_loss = 0.0813262300546915
Trained batch 689 in epoch 4, gen_loss = 0.8366193825783936, disc_loss = 0.08142838032403286
Trained batch 690 in epoch 4, gen_loss = 0.8362090536723433, disc_loss = 0.08149019208522419
Trained batch 691 in epoch 4, gen_loss = 0.8360508463286251, disc_loss = 0.08145795989447849
Trained batch 692 in epoch 4, gen_loss = 0.8358326973165097, disc_loss = 0.08154103986402869
Trained batch 693 in epoch 4, gen_loss = 0.8355246807209696, disc_loss = 0.08166205327721683
Trained batch 694 in epoch 4, gen_loss = 0.835172338537175, disc_loss = 0.08175111270154552
Trained batch 695 in epoch 4, gen_loss = 0.8350383748096981, disc_loss = 0.08179470176016376
Trained batch 696 in epoch 4, gen_loss = 0.8347219416879684, disc_loss = 0.08190607319891965
Trained batch 697 in epoch 4, gen_loss = 0.8346563993518196, disc_loss = 0.0818998746461846
Trained batch 698 in epoch 4, gen_loss = 0.8344619862511434, disc_loss = 0.08198205703264569
Trained batch 699 in epoch 4, gen_loss = 0.8341235382216318, disc_loss = 0.08202744504969035
Trained batch 700 in epoch 4, gen_loss = 0.8339064864391267, disc_loss = 0.08201803194462573
Trained batch 701 in epoch 4, gen_loss = 0.8338101046886879, disc_loss = 0.08215601975496253
Trained batch 702 in epoch 4, gen_loss = 0.8336750050187959, disc_loss = 0.08214648119617747
Trained batch 703 in epoch 4, gen_loss = 0.8336178198118102, disc_loss = 0.08210966517270374
Trained batch 704 in epoch 4, gen_loss = 0.833312160748962, disc_loss = 0.0821304968406334
Trained batch 705 in epoch 4, gen_loss = 0.8332869123466967, disc_loss = 0.08206585411868841
Trained batch 706 in epoch 4, gen_loss = 0.833289312001165, disc_loss = 0.08200966556526225
Trained batch 707 in epoch 4, gen_loss = 0.8330920767144295, disc_loss = 0.08196217632236874
Trained batch 708 in epoch 4, gen_loss = 0.8330682996970474, disc_loss = 0.08189916647235077
Trained batch 709 in epoch 4, gen_loss = 0.833052099086869, disc_loss = 0.08192748973854411
Trained batch 710 in epoch 4, gen_loss = 0.8330072226571299, disc_loss = 0.08220099573679866
Trained batch 711 in epoch 4, gen_loss = 0.8325811787770035, disc_loss = 0.08250008080562765
Trained batch 712 in epoch 4, gen_loss = 0.8327014569146102, disc_loss = 0.08244336654822673
Trained batch 713 in epoch 4, gen_loss = 0.8329628055670014, disc_loss = 0.08246335166269074
Trained batch 714 in epoch 4, gen_loss = 0.8324611239499979, disc_loss = 0.08274201759352134
Trained batch 715 in epoch 4, gen_loss = 0.8322734865229889, disc_loss = 0.08280389951854195
Trained batch 716 in epoch 4, gen_loss = 0.8319399054246633, disc_loss = 0.08283496352180195
Trained batch 717 in epoch 4, gen_loss = 0.8320734119016812, disc_loss = 0.08276629631866735
Trained batch 718 in epoch 4, gen_loss = 0.832302423113742, disc_loss = 0.08274983867785281
Trained batch 719 in epoch 4, gen_loss = 0.8321067213184303, disc_loss = 0.08275612422213373
Trained batch 720 in epoch 4, gen_loss = 0.8320345004785408, disc_loss = 0.08274861470887879
Trained batch 721 in epoch 4, gen_loss = 0.8322300673191567, disc_loss = 0.08277337370992449
Trained batch 722 in epoch 4, gen_loss = 0.8322748846862655, disc_loss = 0.0826987843434964
Trained batch 723 in epoch 4, gen_loss = 0.832130275790204, disc_loss = 0.08270955146213181
Trained batch 724 in epoch 4, gen_loss = 0.8320411654998516, disc_loss = 0.08266007644092215
Trained batch 725 in epoch 4, gen_loss = 0.8319374553592409, disc_loss = 0.0826990180430785
Trained batch 726 in epoch 4, gen_loss = 0.8319450202801533, disc_loss = 0.08262011157464047
Trained batch 727 in epoch 4, gen_loss = 0.8319549093043411, disc_loss = 0.08260202448518313
Trained batch 728 in epoch 4, gen_loss = 0.8318135855292751, disc_loss = 0.08258459631951502
Trained batch 729 in epoch 4, gen_loss = 0.8319069213246646, disc_loss = 0.0824865616245629
Trained batch 730 in epoch 4, gen_loss = 0.8322667861115264, disc_loss = 0.08242537447145634
Trained batch 731 in epoch 4, gen_loss = 0.8319676660123418, disc_loss = 0.0824485166924573
Trained batch 732 in epoch 4, gen_loss = 0.83228811804627, disc_loss = 0.08238276323407766
Trained batch 733 in epoch 4, gen_loss = 0.8326143874134615, disc_loss = 0.08230235546380688
Trained batch 734 in epoch 4, gen_loss = 0.8323107085260404, disc_loss = 0.08225722041259817
Trained batch 735 in epoch 4, gen_loss = 0.8324804365958857, disc_loss = 0.08219866330593663
Trained batch 736 in epoch 4, gen_loss = 0.832270497706399, disc_loss = 0.08214302799756686
Trained batch 737 in epoch 4, gen_loss = 0.832536336852283, disc_loss = 0.08208444170391334
Trained batch 738 in epoch 4, gen_loss = 0.832335908616186, disc_loss = 0.08206688890962059
Trained batch 739 in epoch 4, gen_loss = 0.8326382263286694, disc_loss = 0.0821491933855656
Trained batch 740 in epoch 4, gen_loss = 0.8328720792906809, disc_loss = 0.08205633926960701
Trained batch 741 in epoch 4, gen_loss = 0.8324895685895113, disc_loss = 0.08214777364393049
Trained batch 742 in epoch 4, gen_loss = 0.8328286990182396, disc_loss = 0.082080758092762
Trained batch 743 in epoch 4, gen_loss = 0.8328253084453203, disc_loss = 0.08208028135711067
Trained batch 744 in epoch 4, gen_loss = 0.8325097924910936, disc_loss = 0.08222770399645271
Trained batch 745 in epoch 4, gen_loss = 0.8330345432656061, disc_loss = 0.08226613331606097
Trained batch 746 in epoch 4, gen_loss = 0.8329151845680502, disc_loss = 0.08226815146086126
Trained batch 747 in epoch 4, gen_loss = 0.8329705484410658, disc_loss = 0.08222059345490394
Trained batch 748 in epoch 4, gen_loss = 0.8329997580742168, disc_loss = 0.082146312481909
Trained batch 749 in epoch 4, gen_loss = 0.8329861729939778, disc_loss = 0.08206517245868841
Trained batch 750 in epoch 4, gen_loss = 0.8329690307497819, disc_loss = 0.08202365879589486
Trained batch 751 in epoch 4, gen_loss = 0.8327430370957294, disc_loss = 0.08202226750770623
Trained batch 752 in epoch 4, gen_loss = 0.8328067865346374, disc_loss = 0.0819636519063279
Trained batch 753 in epoch 4, gen_loss = 0.8327399452738168, disc_loss = 0.08202596147611381
Trained batch 754 in epoch 4, gen_loss = 0.8325701899875868, disc_loss = 0.08202976409271853
Trained batch 755 in epoch 4, gen_loss = 0.8322668599861639, disc_loss = 0.08200920485058631
Trained batch 756 in epoch 4, gen_loss = 0.8328547204501405, disc_loss = 0.08220230863285663
Trained batch 757 in epoch 4, gen_loss = 0.8327457505354466, disc_loss = 0.0821732935350693
Trained batch 758 in epoch 4, gen_loss = 0.8326841445936672, disc_loss = 0.08213873373955606
Trained batch 759 in epoch 4, gen_loss = 0.832560799859072, disc_loss = 0.08210627410168711
Trained batch 760 in epoch 4, gen_loss = 0.8325697226687268, disc_loss = 0.08202838647067938
Trained batch 761 in epoch 4, gen_loss = 0.8327767473506177, disc_loss = 0.08194506971845085
Trained batch 762 in epoch 4, gen_loss = 0.8327408336093197, disc_loss = 0.08187341379053002
Trained batch 763 in epoch 4, gen_loss = 0.8331252160964836, disc_loss = 0.08192060479689486
Trained batch 764 in epoch 4, gen_loss = 0.8327545509618871, disc_loss = 0.0820349375163418
Trained batch 765 in epoch 4, gen_loss = 0.8330366221638323, disc_loss = 0.0820594718315038
Trained batch 766 in epoch 4, gen_loss = 0.8327602770524355, disc_loss = 0.08206398590350089
Trained batch 767 in epoch 4, gen_loss = 0.8327992421109229, disc_loss = 0.0819893680648723
Trained batch 768 in epoch 4, gen_loss = 0.8328934499439244, disc_loss = 0.0819176141371265
Trained batch 769 in epoch 4, gen_loss = 0.8327974807906461, disc_loss = 0.08196092819335399
Trained batch 770 in epoch 4, gen_loss = 0.8324055483059815, disc_loss = 0.08198962547609778
Trained batch 771 in epoch 4, gen_loss = 0.8322159324439696, disc_loss = 0.08197577637885672
Trained batch 772 in epoch 4, gen_loss = 0.8323134761424145, disc_loss = 0.08197663350929572
Trained batch 773 in epoch 4, gen_loss = 0.8318633256956588, disc_loss = 0.08206610414813194
Trained batch 774 in epoch 4, gen_loss = 0.831649571541817, disc_loss = 0.08203593900126796
Trained batch 775 in epoch 4, gen_loss = 0.8318840426575277, disc_loss = 0.08211723985822544
Trained batch 776 in epoch 4, gen_loss = 0.831516115898638, disc_loss = 0.08230975007535254
Trained batch 777 in epoch 4, gen_loss = 0.831540624172951, disc_loss = 0.08229815384377857
Trained batch 778 in epoch 4, gen_loss = 0.8314872846982905, disc_loss = 0.0823621464001352
Trained batch 779 in epoch 4, gen_loss = 0.8311892770803891, disc_loss = 0.08238674018245477
Trained batch 780 in epoch 4, gen_loss = 0.8312554487650892, disc_loss = 0.08236413055055425
Trained batch 781 in epoch 4, gen_loss = 0.8309487685218186, disc_loss = 0.08239118022191555
Trained batch 782 in epoch 4, gen_loss = 0.8310604091652813, disc_loss = 0.08253355408955655
Trained batch 783 in epoch 4, gen_loss = 0.8308306594892424, disc_loss = 0.08255089352819689
Trained batch 784 in epoch 4, gen_loss = 0.8311790633353459, disc_loss = 0.08254049368155231
Trained batch 785 in epoch 4, gen_loss = 0.8307351522697444, disc_loss = 0.08277488813638384
Trained batch 786 in epoch 4, gen_loss = 0.8308942623559523, disc_loss = 0.08271152020125559
Trained batch 787 in epoch 4, gen_loss = 0.830858922057648, disc_loss = 0.08271143287136622
Trained batch 788 in epoch 4, gen_loss = 0.8305670188784751, disc_loss = 0.08273019444749836
Trained batch 789 in epoch 4, gen_loss = 0.8306304962951926, disc_loss = 0.08273652045504201
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.9140913486480713, disc_loss = 0.04545168578624725
Trained batch 1 in epoch 5, gen_loss = 0.7769446969032288, disc_loss = 0.04121115803718567
Trained batch 2 in epoch 5, gen_loss = 0.7658100922902426, disc_loss = 0.05402533710002899
Trained batch 3 in epoch 5, gen_loss = 0.791402742266655, disc_loss = 0.04732837900519371
Trained batch 4 in epoch 5, gen_loss = 0.8498225808143616, disc_loss = 0.04759097248315811
Trained batch 5 in epoch 5, gen_loss = 0.8360607922077179, disc_loss = 0.05239367733399073
Trained batch 6 in epoch 5, gen_loss = 0.8259884800229754, disc_loss = 0.05296936152236802
Trained batch 7 in epoch 5, gen_loss = 0.8309819102287292, disc_loss = 0.05577187007293105
Trained batch 8 in epoch 5, gen_loss = 0.8387448125415378, disc_loss = 0.058885802411370806
Trained batch 9 in epoch 5, gen_loss = 0.8316863715648651, disc_loss = 0.05463727284222841
Trained batch 10 in epoch 5, gen_loss = 0.8168548399751837, disc_loss = 0.058338693089105866
Trained batch 11 in epoch 5, gen_loss = 0.8184781422217687, disc_loss = 0.05846795393154025
Trained batch 12 in epoch 5, gen_loss = 0.8471154020382807, disc_loss = 0.061777084636000484
Trained batch 13 in epoch 5, gen_loss = 0.8305348839078631, disc_loss = 0.06392241176217794
Trained batch 14 in epoch 5, gen_loss = 0.8370254357655843, disc_loss = 0.06139811016619205
Trained batch 15 in epoch 5, gen_loss = 0.849442258477211, disc_loss = 0.05877362168394029
Trained batch 16 in epoch 5, gen_loss = 0.8409392062355491, disc_loss = 0.058344099670648575
Trained batch 17 in epoch 5, gen_loss = 0.8566385308901469, disc_loss = 0.06047255897687541
Trained batch 18 in epoch 5, gen_loss = 0.8568192281221089, disc_loss = 0.05843998442747091
Trained batch 19 in epoch 5, gen_loss = 0.8393930673599244, disc_loss = 0.06394153563305735
Trained batch 20 in epoch 5, gen_loss = 0.8392893246241978, disc_loss = 0.06218938219050566
Trained batch 21 in epoch 5, gen_loss = 0.8463460288264535, disc_loss = 0.06142415317960761
Trained batch 22 in epoch 5, gen_loss = 0.8488583279692609, disc_loss = 0.05989870882552603
Trained batch 23 in epoch 5, gen_loss = 0.8401102498173714, disc_loss = 0.06377356064816316
Trained batch 24 in epoch 5, gen_loss = 0.8535954356193542, disc_loss = 0.06574129521846771
Trained batch 25 in epoch 5, gen_loss = 0.8497754656351529, disc_loss = 0.06469982174726632
Trained batch 26 in epoch 5, gen_loss = 0.8467251018241599, disc_loss = 0.06671624575500135
Trained batch 27 in epoch 5, gen_loss = 0.8458717209952218, disc_loss = 0.0679609083703586
Trained batch 28 in epoch 5, gen_loss = 0.8368798042165821, disc_loss = 0.07355346710517488
Trained batch 29 in epoch 5, gen_loss = 0.8472022970517477, disc_loss = 0.07549853175878525
Trained batch 30 in epoch 5, gen_loss = 0.8460173876054825, disc_loss = 0.0736531448220053
Trained batch 31 in epoch 5, gen_loss = 0.8460130989551544, disc_loss = 0.07359717052895576
Trained batch 32 in epoch 5, gen_loss = 0.8493299195260713, disc_loss = 0.07286876191695531
Trained batch 33 in epoch 5, gen_loss = 0.8412738144397736, disc_loss = 0.07356307085822611
Trained batch 34 in epoch 5, gen_loss = 0.838278305530548, disc_loss = 0.073055576639516
Trained batch 35 in epoch 5, gen_loss = 0.8494223836395476, disc_loss = 0.07243986179431279
Trained batch 36 in epoch 5, gen_loss = 0.8448842200073036, disc_loss = 0.07297180109732859
Trained batch 37 in epoch 5, gen_loss = 0.8466202710804186, disc_loss = 0.0718765568576361
Trained batch 38 in epoch 5, gen_loss = 0.8520522301013653, disc_loss = 0.07077774052054454
Trained batch 39 in epoch 5, gen_loss = 0.851056382060051, disc_loss = 0.07130575189366936
Trained batch 40 in epoch 5, gen_loss = 0.8534601854114998, disc_loss = 0.07002962816779207
Trained batch 41 in epoch 5, gen_loss = 0.8541392584641775, disc_loss = 0.06899215232226111
Trained batch 42 in epoch 5, gen_loss = 0.8529830574989319, disc_loss = 0.06815988938649033
Trained batch 43 in epoch 5, gen_loss = 0.8560966442931782, disc_loss = 0.06775194249877875
Trained batch 44 in epoch 5, gen_loss = 0.855867518319024, disc_loss = 0.0670158481846253
Trained batch 45 in epoch 5, gen_loss = 0.8552004228467527, disc_loss = 0.06640559900552034
Trained batch 46 in epoch 5, gen_loss = 0.8555195914938095, disc_loss = 0.06593374341250734
Trained batch 47 in epoch 5, gen_loss = 0.8524068556725979, disc_loss = 0.06598553732813646
Trained batch 48 in epoch 5, gen_loss = 0.8461468548190837, disc_loss = 0.06693146229550546
Trained batch 49 in epoch 5, gen_loss = 0.8368808031082153, disc_loss = 0.07018017400056124
Trained batch 50 in epoch 5, gen_loss = 0.8356429291706459, disc_loss = 0.06994347789270036
Trained batch 51 in epoch 5, gen_loss = 0.8443659773239722, disc_loss = 0.07036266694418512
Trained batch 52 in epoch 5, gen_loss = 0.8372245290369358, disc_loss = 0.07360723491687819
Trained batch 53 in epoch 5, gen_loss = 0.8413533772583361, disc_loss = 0.07329843665852591
Trained batch 54 in epoch 5, gen_loss = 0.843007618188858, disc_loss = 0.07221582680940627
Trained batch 55 in epoch 5, gen_loss = 0.8410133788628238, disc_loss = 0.07185779006353446
Trained batch 56 in epoch 5, gen_loss = 0.8419590879950607, disc_loss = 0.07147558340639398
Trained batch 57 in epoch 5, gen_loss = 0.8378509873973912, disc_loss = 0.07156507227698276
Trained batch 58 in epoch 5, gen_loss = 0.8420436478267281, disc_loss = 0.07081575341270131
Trained batch 59 in epoch 5, gen_loss = 0.8436009719967842, disc_loss = 0.07128022614245613
Trained batch 60 in epoch 5, gen_loss = 0.8400930679235302, disc_loss = 0.07377266325056553
Trained batch 61 in epoch 5, gen_loss = 0.8442279893544412, disc_loss = 0.07308199253654288
Trained batch 62 in epoch 5, gen_loss = 0.8464568318828704, disc_loss = 0.07218527820493494
Trained batch 63 in epoch 5, gen_loss = 0.8463854673318565, disc_loss = 0.07150309145799838
Trained batch 64 in epoch 5, gen_loss = 0.8500227740177742, disc_loss = 0.07130246669627154
Trained batch 65 in epoch 5, gen_loss = 0.8490899417436484, disc_loss = 0.07078613140479181
Trained batch 66 in epoch 5, gen_loss = 0.845360332015735, disc_loss = 0.07164215221445062
Trained batch 67 in epoch 5, gen_loss = 0.8480396020938369, disc_loss = 0.07242271427393836
Trained batch 68 in epoch 5, gen_loss = 0.8458702732687411, disc_loss = 0.0720620322432639
Trained batch 69 in epoch 5, gen_loss = 0.8464851434741701, disc_loss = 0.07197974428002324
Trained batch 70 in epoch 5, gen_loss = 0.8436989267946968, disc_loss = 0.07228136395799442
Trained batch 71 in epoch 5, gen_loss = 0.8456075990365611, disc_loss = 0.07182057178579271
Trained batch 72 in epoch 5, gen_loss = 0.8513409572921388, disc_loss = 0.07160481384457791
Trained batch 73 in epoch 5, gen_loss = 0.8501567353267927, disc_loss = 0.07218675821314792
Trained batch 74 in epoch 5, gen_loss = 0.8500336436430613, disc_loss = 0.07178413910170396
Trained batch 75 in epoch 5, gen_loss = 0.8479259880749803, disc_loss = 0.07129814385093357
Trained batch 76 in epoch 5, gen_loss = 0.8523741763133508, disc_loss = 0.07313297135005524
Trained batch 77 in epoch 5, gen_loss = 0.850201108898872, disc_loss = 0.07306047937331292
Trained batch 78 in epoch 5, gen_loss = 0.8467596161969101, disc_loss = 0.07435815967619419
Trained batch 79 in epoch 5, gen_loss = 0.847481295093894, disc_loss = 0.0736705070361495
Trained batch 80 in epoch 5, gen_loss = 0.8483215949417632, disc_loss = 0.0748748928308487
Trained batch 81 in epoch 5, gen_loss = 0.846717415422928, disc_loss = 0.07454542602162535
Trained batch 82 in epoch 5, gen_loss = 0.8457288853375309, disc_loss = 0.07433737563081534
Trained batch 83 in epoch 5, gen_loss = 0.8450697153097108, disc_loss = 0.07362818328796752
Trained batch 84 in epoch 5, gen_loss = 0.8440557301044465, disc_loss = 0.07335180281935369
Trained batch 85 in epoch 5, gen_loss = 0.8429969240759694, disc_loss = 0.07318662645208628
Trained batch 86 in epoch 5, gen_loss = 0.8434878741872722, disc_loss = 0.07251218882999544
Trained batch 87 in epoch 5, gen_loss = 0.8428168164735491, disc_loss = 0.07202771328262646
Trained batch 88 in epoch 5, gen_loss = 0.8426216107405974, disc_loss = 0.07203980054957478
Trained batch 89 in epoch 5, gen_loss = 0.8424690302875307, disc_loss = 0.07164632236171099
Trained batch 90 in epoch 5, gen_loss = 0.8434093041079385, disc_loss = 0.07106346515222238
Trained batch 91 in epoch 5, gen_loss = 0.8416198741482652, disc_loss = 0.07086739321644216
Trained batch 92 in epoch 5, gen_loss = 0.8466728954545913, disc_loss = 0.07232560799206778
Trained batch 93 in epoch 5, gen_loss = 0.846728543334819, disc_loss = 0.07178172644505158
Trained batch 94 in epoch 5, gen_loss = 0.8446050785089794, disc_loss = 0.0718682559011014
Trained batch 95 in epoch 5, gen_loss = 0.8461362679178516, disc_loss = 0.07143228366233718
Trained batch 96 in epoch 5, gen_loss = 0.8491640481137738, disc_loss = 0.07166673816241247
Trained batch 97 in epoch 5, gen_loss = 0.8451703126941409, disc_loss = 0.07370235213097565
Trained batch 98 in epoch 5, gen_loss = 0.8438610973382237, disc_loss = 0.07321992575783622
Trained batch 99 in epoch 5, gen_loss = 0.8435847130417824, disc_loss = 0.0736771725025028
Trained batch 100 in epoch 5, gen_loss = 0.8440761250434535, disc_loss = 0.0732877604054785
Trained batch 101 in epoch 5, gen_loss = 0.8410007430642259, disc_loss = 0.07457749500834182
Trained batch 102 in epoch 5, gen_loss = 0.8424901189734635, disc_loss = 0.07444706742733138
Trained batch 103 in epoch 5, gen_loss = 0.841648330195592, disc_loss = 0.07455786083860752
Trained batch 104 in epoch 5, gen_loss = 0.840255997578303, disc_loss = 0.07448594154169162
Trained batch 105 in epoch 5, gen_loss = 0.8379488219067736, disc_loss = 0.07465352865709167
Trained batch 106 in epoch 5, gen_loss = 0.8384873758409624, disc_loss = 0.07508906341706202
Trained batch 107 in epoch 5, gen_loss = 0.8394960300238045, disc_loss = 0.07471356226165814
Trained batch 108 in epoch 5, gen_loss = 0.8377502957068452, disc_loss = 0.07526667117901625
Trained batch 109 in epoch 5, gen_loss = 0.8384259546344931, disc_loss = 0.07530423662709919
Trained batch 110 in epoch 5, gen_loss = 0.8381198964140437, disc_loss = 0.07499969853843386
Trained batch 111 in epoch 5, gen_loss = 0.8375126280422721, disc_loss = 0.07595856543464054
Trained batch 112 in epoch 5, gen_loss = 0.836178776173465, disc_loss = 0.07558370726924818
Trained batch 113 in epoch 5, gen_loss = 0.8347645514366919, disc_loss = 0.07541957888915612
Trained batch 114 in epoch 5, gen_loss = 0.8370911191339078, disc_loss = 0.07541383413354988
Trained batch 115 in epoch 5, gen_loss = 0.8379054231376484, disc_loss = 0.07499161477457604
Trained batch 116 in epoch 5, gen_loss = 0.8357032840577965, disc_loss = 0.07541071177006532
Trained batch 117 in epoch 5, gen_loss = 0.8376459395986492, disc_loss = 0.07535400676493675
Trained batch 118 in epoch 5, gen_loss = 0.8363265242396283, disc_loss = 0.07616870962239865
Trained batch 119 in epoch 5, gen_loss = 0.835517231374979, disc_loss = 0.07589205151889473
Trained batch 120 in epoch 5, gen_loss = 0.8349831944162195, disc_loss = 0.0756977337743502
Trained batch 121 in epoch 5, gen_loss = 0.8350253459371504, disc_loss = 0.07782515388012665
Trained batch 122 in epoch 5, gen_loss = 0.8337590842227626, disc_loss = 0.07763071502823897
Trained batch 123 in epoch 5, gen_loss = 0.831941035726378, disc_loss = 0.07753740178210841
Trained batch 124 in epoch 5, gen_loss = 0.8316399939060212, disc_loss = 0.07756515901535749
Trained batch 125 in epoch 5, gen_loss = 0.8331590874327554, disc_loss = 0.07775880703111253
Trained batch 126 in epoch 5, gen_loss = 0.8317990967138545, disc_loss = 0.07763431901038867
Trained batch 127 in epoch 5, gen_loss = 0.8317790988367051, disc_loss = 0.07749163058906561
Trained batch 128 in epoch 5, gen_loss = 0.8310499909774277, disc_loss = 0.07777721281055101
Trained batch 129 in epoch 5, gen_loss = 0.8305130378558085, disc_loss = 0.07780333404214336
Trained batch 130 in epoch 5, gen_loss = 0.8318935639530648, disc_loss = 0.0775970859197146
Trained batch 131 in epoch 5, gen_loss = 0.8327652638157209, disc_loss = 0.07790234023846235
Trained batch 132 in epoch 5, gen_loss = 0.8315544202363581, disc_loss = 0.0778858510889393
Trained batch 133 in epoch 5, gen_loss = 0.8303971150472983, disc_loss = 0.07807583277767051
Trained batch 134 in epoch 5, gen_loss = 0.8321730774861795, disc_loss = 0.07785761761306613
Trained batch 135 in epoch 5, gen_loss = 0.8329206220805645, disc_loss = 0.07742581613060526
Trained batch 136 in epoch 5, gen_loss = 0.8333520569505483, disc_loss = 0.07699382727299511
Trained batch 137 in epoch 5, gen_loss = 0.8314052450916042, disc_loss = 0.07755525904856082
Trained batch 138 in epoch 5, gen_loss = 0.8319078548777875, disc_loss = 0.07745033479128167
Trained batch 139 in epoch 5, gen_loss = 0.8330593609384128, disc_loss = 0.07718954470141658
Trained batch 140 in epoch 5, gen_loss = 0.8323871161498076, disc_loss = 0.07705921099144727
Trained batch 141 in epoch 5, gen_loss = 0.8314202262062422, disc_loss = 0.07692962762256952
Trained batch 142 in epoch 5, gen_loss = 0.8329773876633677, disc_loss = 0.07668273096865082
Trained batch 143 in epoch 5, gen_loss = 0.8319792807516124, disc_loss = 0.07655174787699555
Trained batch 144 in epoch 5, gen_loss = 0.8310633369560899, disc_loss = 0.07660763228376363
Trained batch 145 in epoch 5, gen_loss = 0.8299180969391784, disc_loss = 0.07634476812760511
Trained batch 146 in epoch 5, gen_loss = 0.8290766694513308, disc_loss = 0.076257763728246
Trained batch 147 in epoch 5, gen_loss = 0.8324907822786151, disc_loss = 0.07687613514654741
Trained batch 148 in epoch 5, gen_loss = 0.8322361209648568, disc_loss = 0.0765466938020299
Trained batch 149 in epoch 5, gen_loss = 0.832408726811409, disc_loss = 0.07617500377818942
Trained batch 150 in epoch 5, gen_loss = 0.8313642888274414, disc_loss = 0.07625347270402096
Trained batch 151 in epoch 5, gen_loss = 0.8318855203688145, disc_loss = 0.07595089350606461
Trained batch 152 in epoch 5, gen_loss = 0.8317852337765538, disc_loss = 0.0761570473524188
Trained batch 153 in epoch 5, gen_loss = 0.8305563491273236, disc_loss = 0.07645168676125733
Trained batch 154 in epoch 5, gen_loss = 0.830610082803234, disc_loss = 0.07601983938366175
Trained batch 155 in epoch 5, gen_loss = 0.8320954753420292, disc_loss = 0.07601308518757996
Trained batch 156 in epoch 5, gen_loss = 0.8319823948820685, disc_loss = 0.07567389789304346
Trained batch 157 in epoch 5, gen_loss = 0.8307007123020631, disc_loss = 0.07577101891577433
Trained batch 158 in epoch 5, gen_loss = 0.8302769115510976, disc_loss = 0.07564036928281281
Trained batch 159 in epoch 5, gen_loss = 0.829518079943955, disc_loss = 0.07616826878511347
Trained batch 160 in epoch 5, gen_loss = 0.8300691023006203, disc_loss = 0.07584583319098868
Trained batch 161 in epoch 5, gen_loss = 0.8326914915700018, disc_loss = 0.07563051875151786
Trained batch 162 in epoch 5, gen_loss = 0.8329364600722775, disc_loss = 0.07540233073858944
Trained batch 163 in epoch 5, gen_loss = 0.831802830281781, disc_loss = 0.07546280880413223
Trained batch 164 in epoch 5, gen_loss = 0.832456318356774, disc_loss = 0.07515183641490611
Trained batch 165 in epoch 5, gen_loss = 0.833721006311566, disc_loss = 0.07538963934541287
Trained batch 166 in epoch 5, gen_loss = 0.831987493230911, disc_loss = 0.07593935129684425
Trained batch 167 in epoch 5, gen_loss = 0.8329643559242997, disc_loss = 0.0757774588197381
Trained batch 168 in epoch 5, gen_loss = 0.832229371783296, disc_loss = 0.07572159219048256
Trained batch 169 in epoch 5, gen_loss = 0.8325715431395699, disc_loss = 0.07585106701864039
Trained batch 170 in epoch 5, gen_loss = 0.8311851866412581, disc_loss = 0.07618578962916345
Trained batch 171 in epoch 5, gen_loss = 0.8316532607341922, disc_loss = 0.07603210751725317
Trained batch 172 in epoch 5, gen_loss = 0.8321233400375168, disc_loss = 0.07596348074797778
Trained batch 173 in epoch 5, gen_loss = 0.8327480182908047, disc_loss = 0.07559448628333108
Trained batch 174 in epoch 5, gen_loss = 0.8327407297066279, disc_loss = 0.07545495214206832
Trained batch 175 in epoch 5, gen_loss = 0.8315257631580938, disc_loss = 0.07571723432788117
Trained batch 176 in epoch 5, gen_loss = 0.8305213655118888, disc_loss = 0.07568491795389666
Trained batch 177 in epoch 5, gen_loss = 0.8316544456763214, disc_loss = 0.07560077500058694
Trained batch 178 in epoch 5, gen_loss = 0.8323561201215456, disc_loss = 0.07569155719276913
Trained batch 179 in epoch 5, gen_loss = 0.8315610277983877, disc_loss = 0.076109144402047
Trained batch 180 in epoch 5, gen_loss = 0.8317412897038855, disc_loss = 0.07588294677395188
Trained batch 181 in epoch 5, gen_loss = 0.8327873612825687, disc_loss = 0.0758288801330459
Trained batch 182 in epoch 5, gen_loss = 0.831789086262385, disc_loss = 0.07593125733928602
Trained batch 183 in epoch 5, gen_loss = 0.8322909041915251, disc_loss = 0.07630751858991773
Trained batch 184 in epoch 5, gen_loss = 0.8326738726448368, disc_loss = 0.0759701620586015
Trained batch 185 in epoch 5, gen_loss = 0.83258214961457, disc_loss = 0.07581524495836547
Trained batch 186 in epoch 5, gen_loss = 0.8323821165663673, disc_loss = 0.07569457045731379
Trained batch 187 in epoch 5, gen_loss = 0.8331950337011763, disc_loss = 0.07589764652298168
Trained batch 188 in epoch 5, gen_loss = 0.8336820358006412, disc_loss = 0.0756180821449826
Trained batch 189 in epoch 5, gen_loss = 0.832651516167741, disc_loss = 0.07562912264348645
Trained batch 190 in epoch 5, gen_loss = 0.832752598049753, disc_loss = 0.07547695992309697
Trained batch 191 in epoch 5, gen_loss = 0.8337289139938852, disc_loss = 0.07629261091157484
Trained batch 192 in epoch 5, gen_loss = 0.8323710525282924, disc_loss = 0.07720031117335194
Trained batch 193 in epoch 5, gen_loss = 0.8335677340780336, disc_loss = 0.0776113755904983
Trained batch 194 in epoch 5, gen_loss = 0.832259899072158, disc_loss = 0.07847161517502406
Trained batch 195 in epoch 5, gen_loss = 0.8314957924339236, disc_loss = 0.07850083392303513
Trained batch 196 in epoch 5, gen_loss = 0.831264042460979, disc_loss = 0.07866430935936833
Trained batch 197 in epoch 5, gen_loss = 0.829876421527429, disc_loss = 0.07907080337066542
Trained batch 198 in epoch 5, gen_loss = 0.829766048109112, disc_loss = 0.07906333771744865
Trained batch 199 in epoch 5, gen_loss = 0.8302172677218914, disc_loss = 0.07893867381848395
Trained batch 200 in epoch 5, gen_loss = 0.8296546388917895, disc_loss = 0.07891162300473126
Trained batch 201 in epoch 5, gen_loss = 0.8294972469015877, disc_loss = 0.07879245260011146
Trained batch 202 in epoch 5, gen_loss = 0.829821856004264, disc_loss = 0.07858551378944531
Trained batch 203 in epoch 5, gen_loss = 0.8296182925502459, disc_loss = 0.0785123300921245
Trained batch 204 in epoch 5, gen_loss = 0.8291520861590781, disc_loss = 0.07830856198036089
Trained batch 205 in epoch 5, gen_loss = 0.8292560442848113, disc_loss = 0.07849422331393055
Trained batch 206 in epoch 5, gen_loss = 0.8289143133566576, disc_loss = 0.07843538988291641
Trained batch 207 in epoch 5, gen_loss = 0.8292077388614416, disc_loss = 0.07870223443919364
Trained batch 208 in epoch 5, gen_loss = 0.8294054157140722, disc_loss = 0.07838750603880608
Trained batch 209 in epoch 5, gen_loss = 0.8284883165643329, disc_loss = 0.07847717101020472
Trained batch 210 in epoch 5, gen_loss = 0.8287425926793808, disc_loss = 0.07819496393556843
Trained batch 211 in epoch 5, gen_loss = 0.8301765984802876, disc_loss = 0.0787588715166697
Trained batch 212 in epoch 5, gen_loss = 0.829121150181327, disc_loss = 0.07900181288520496
Trained batch 213 in epoch 5, gen_loss = 0.8297831938367024, disc_loss = 0.07871189700422164
Trained batch 214 in epoch 5, gen_loss = 0.828923710141071, disc_loss = 0.0787013544679381
Trained batch 215 in epoch 5, gen_loss = 0.8307591760876002, disc_loss = 0.07889608746497995
Trained batch 216 in epoch 5, gen_loss = 0.8302028911179661, disc_loss = 0.07876760372677431
Trained batch 217 in epoch 5, gen_loss = 0.8294002316687086, disc_loss = 0.07883593642554425
Trained batch 218 in epoch 5, gen_loss = 0.8293361774046127, disc_loss = 0.07943182153686813
Trained batch 219 in epoch 5, gen_loss = 0.8282512460242618, disc_loss = 0.07956337187947198
Trained batch 220 in epoch 5, gen_loss = 0.8274498353986179, disc_loss = 0.07951573526056913
Trained batch 221 in epoch 5, gen_loss = 0.8285149487557711, disc_loss = 0.07939436524133156
Trained batch 222 in epoch 5, gen_loss = 0.8296199145605746, disc_loss = 0.07953140439440584
Trained batch 223 in epoch 5, gen_loss = 0.8282904275027769, disc_loss = 0.08050094723668215
Trained batch 224 in epoch 5, gen_loss = 0.8283508921994104, disc_loss = 0.0804467153797547
Trained batch 225 in epoch 5, gen_loss = 0.8296295479599354, disc_loss = 0.08071047795392507
Trained batch 226 in epoch 5, gen_loss = 0.8287818732503227, disc_loss = 0.08080412062615287
Trained batch 227 in epoch 5, gen_loss = 0.8284535440698004, disc_loss = 0.08061135106867082
Trained batch 228 in epoch 5, gen_loss = 0.828736132539516, disc_loss = 0.08032444594061922
Trained batch 229 in epoch 5, gen_loss = 0.8293654367975567, disc_loss = 0.0804525127188991
Trained batch 230 in epoch 5, gen_loss = 0.8287587706402783, disc_loss = 0.08038542854692383
Trained batch 231 in epoch 5, gen_loss = 0.8294214705197975, disc_loss = 0.08017174716123604
Trained batch 232 in epoch 5, gen_loss = 0.8297387214433481, disc_loss = 0.08009511315115915
Trained batch 233 in epoch 5, gen_loss = 0.8296590708514564, disc_loss = 0.07984260472461072
Trained batch 234 in epoch 5, gen_loss = 0.8296846738521089, disc_loss = 0.07963410352376547
Trained batch 235 in epoch 5, gen_loss = 0.8299179906814785, disc_loss = 0.0794649374931735
Trained batch 236 in epoch 5, gen_loss = 0.8302694552809881, disc_loss = 0.07926375963941279
Trained batch 237 in epoch 5, gen_loss = 0.8299829317491596, disc_loss = 0.07927300055910434
Trained batch 238 in epoch 5, gen_loss = 0.8311121292942238, disc_loss = 0.07903237845436924
Trained batch 239 in epoch 5, gen_loss = 0.8319436360150576, disc_loss = 0.07878423394092048
Trained batch 240 in epoch 5, gen_loss = 0.832124355052022, disc_loss = 0.07854915643304092
Trained batch 241 in epoch 5, gen_loss = 0.8317821066487919, disc_loss = 0.0784400074188559
Trained batch 242 in epoch 5, gen_loss = 0.8311206427375966, disc_loss = 0.07825494597094908
Trained batch 243 in epoch 5, gen_loss = 0.8318987900360686, disc_loss = 0.07804610255388085
Trained batch 244 in epoch 5, gen_loss = 0.8338039915172422, disc_loss = 0.07807716491955276
Trained batch 245 in epoch 5, gen_loss = 0.8349200575574627, disc_loss = 0.07785180092569653
Trained batch 246 in epoch 5, gen_loss = 0.8338862183364296, disc_loss = 0.07818485412987983
Trained batch 247 in epoch 5, gen_loss = 0.8350548401715294, disc_loss = 0.07791350926122358
Trained batch 248 in epoch 5, gen_loss = 0.8357295553128882, disc_loss = 0.07844452703573618
Trained batch 249 in epoch 5, gen_loss = 0.8348092876672745, disc_loss = 0.07871517121791839
Trained batch 250 in epoch 5, gen_loss = 0.8357715479643696, disc_loss = 0.07859484536714288
Trained batch 251 in epoch 5, gen_loss = 0.8363652970819246, disc_loss = 0.07839621568749112
Trained batch 252 in epoch 5, gen_loss = 0.8356126131040776, disc_loss = 0.078350984715956
Trained batch 253 in epoch 5, gen_loss = 0.8349567767907315, disc_loss = 0.07840161718516134
Trained batch 254 in epoch 5, gen_loss = 0.8348082571637396, disc_loss = 0.07826264854885784
Trained batch 255 in epoch 5, gen_loss = 0.8360316875623539, disc_loss = 0.07827048862964148
Trained batch 256 in epoch 5, gen_loss = 0.8355036731591948, disc_loss = 0.07818533965034939
Trained batch 257 in epoch 5, gen_loss = 0.8349459059247675, disc_loss = 0.07800560682116783
Trained batch 258 in epoch 5, gen_loss = 0.8348466271829421, disc_loss = 0.07788571195396447
Trained batch 259 in epoch 5, gen_loss = 0.8343591468838545, disc_loss = 0.07781524997061262
Trained batch 260 in epoch 5, gen_loss = 0.8354420030482428, disc_loss = 0.07822374452148133
Trained batch 261 in epoch 5, gen_loss = 0.835292182464636, disc_loss = 0.07804592119401875
Trained batch 262 in epoch 5, gen_loss = 0.8341408520370381, disc_loss = 0.0781160751463909
Trained batch 263 in epoch 5, gen_loss = 0.8351200187973904, disc_loss = 0.07787419548681514
Trained batch 264 in epoch 5, gen_loss = 0.8343331414573597, disc_loss = 0.07788091791828848
Trained batch 265 in epoch 5, gen_loss = 0.8343546786030432, disc_loss = 0.07785986667092805
Trained batch 266 in epoch 5, gen_loss = 0.8347834992721286, disc_loss = 0.07782057104178805
Trained batch 267 in epoch 5, gen_loss = 0.8342764280847649, disc_loss = 0.07779475997215998
Trained batch 268 in epoch 5, gen_loss = 0.8337411176981093, disc_loss = 0.07767930321506186
Trained batch 269 in epoch 5, gen_loss = 0.8335633923610052, disc_loss = 0.07752662249323394
Trained batch 270 in epoch 5, gen_loss = 0.8334956029464398, disc_loss = 0.07745845030951984
Trained batch 271 in epoch 5, gen_loss = 0.833443805027534, disc_loss = 0.07730714566594757
Trained batch 272 in epoch 5, gen_loss = 0.8330359025534256, disc_loss = 0.07716620730529557
Trained batch 273 in epoch 5, gen_loss = 0.8338868682184358, disc_loss = 0.07705277758548512
Trained batch 274 in epoch 5, gen_loss = 0.8331541391936216, disc_loss = 0.07720578415149992
Trained batch 275 in epoch 5, gen_loss = 0.8318842825466308, disc_loss = 0.0779755629963525
Trained batch 276 in epoch 5, gen_loss = 0.8320833919065523, disc_loss = 0.07777580893211847
Trained batch 277 in epoch 5, gen_loss = 0.832127326791235, disc_loss = 0.07785579347781998
Trained batch 278 in epoch 5, gen_loss = 0.831471933152086, disc_loss = 0.077836763153794
Trained batch 279 in epoch 5, gen_loss = 0.8317196549049446, disc_loss = 0.07768752226339919
Trained batch 280 in epoch 5, gen_loss = 0.831790308617188, disc_loss = 0.0775371887770836
Trained batch 281 in epoch 5, gen_loss = 0.8320888383380065, disc_loss = 0.07737579164986914
Trained batch 282 in epoch 5, gen_loss = 0.8328538573883447, disc_loss = 0.07722199134291692
Trained batch 283 in epoch 5, gen_loss = 0.83289346885933, disc_loss = 0.07708769540866496
Trained batch 284 in epoch 5, gen_loss = 0.8326268977240512, disc_loss = 0.07690892618214874
Trained batch 285 in epoch 5, gen_loss = 0.8332561182600635, disc_loss = 0.0767633484324792
Trained batch 286 in epoch 5, gen_loss = 0.8326997826531374, disc_loss = 0.07661676840395877
Trained batch 287 in epoch 5, gen_loss = 0.8335592658776376, disc_loss = 0.07642861817859942
Trained batch 288 in epoch 5, gen_loss = 0.8332201092919677, disc_loss = 0.07634453240872255
Trained batch 289 in epoch 5, gen_loss = 0.8339964105137463, disc_loss = 0.07625905303605672
Trained batch 290 in epoch 5, gen_loss = 0.8332085649377292, disc_loss = 0.07624645528617184
Trained batch 291 in epoch 5, gen_loss = 0.8328218646857837, disc_loss = 0.0763215258054129
Trained batch 292 in epoch 5, gen_loss = 0.8325589249361904, disc_loss = 0.07636690017713214
Trained batch 293 in epoch 5, gen_loss = 0.832147614586921, disc_loss = 0.0763786000763478
Trained batch 294 in epoch 5, gen_loss = 0.8322833882550061, disc_loss = 0.07664951863935439
Trained batch 295 in epoch 5, gen_loss = 0.8322353480836829, disc_loss = 0.07661984850828713
Trained batch 296 in epoch 5, gen_loss = 0.8308986679271415, disc_loss = 0.07765291355274341
Trained batch 297 in epoch 5, gen_loss = 0.8307637825308231, disc_loss = 0.07826478789316728
Trained batch 298 in epoch 5, gen_loss = 0.8321819996156022, disc_loss = 0.0798492206378924
Trained batch 299 in epoch 5, gen_loss = 0.8314563752214114, disc_loss = 0.0804746264219284
Trained batch 300 in epoch 5, gen_loss = 0.8307215037734009, disc_loss = 0.08106313769603489
Trained batch 301 in epoch 5, gen_loss = 0.8309090582542862, disc_loss = 0.08162742547246794
Trained batch 302 in epoch 5, gen_loss = 0.8305884126586096, disc_loss = 0.08220519356601702
Trained batch 303 in epoch 5, gen_loss = 0.8302408628361789, disc_loss = 0.08236552917055394
Trained batch 304 in epoch 5, gen_loss = 0.8301318206748024, disc_loss = 0.08259475113915615
Trained batch 305 in epoch 5, gen_loss = 0.8298037269341401, disc_loss = 0.08265197764035144
Trained batch 306 in epoch 5, gen_loss = 0.8296838597870805, disc_loss = 0.08254763337173757
Trained batch 307 in epoch 5, gen_loss = 0.8289417232592384, disc_loss = 0.08262356507362097
Trained batch 308 in epoch 5, gen_loss = 0.8290205540973392, disc_loss = 0.0828624472962421
Trained batch 309 in epoch 5, gen_loss = 0.8280116787841243, disc_loss = 0.08332551483425402
Trained batch 310 in epoch 5, gen_loss = 0.8290145879198118, disc_loss = 0.08359332125142839
Trained batch 311 in epoch 5, gen_loss = 0.8292597959247919, disc_loss = 0.08339513389345928
Trained batch 312 in epoch 5, gen_loss = 0.8294901778332342, disc_loss = 0.08318845227884408
Trained batch 313 in epoch 5, gen_loss = 0.8291721673338277, disc_loss = 0.08311376370679421
Trained batch 314 in epoch 5, gen_loss = 0.8295079063801538, disc_loss = 0.08298073141347795
Trained batch 315 in epoch 5, gen_loss = 0.8305005041670196, disc_loss = 0.08285840818823516
Trained batch 316 in epoch 5, gen_loss = 0.8306121646605832, disc_loss = 0.0826660990950061
Trained batch 317 in epoch 5, gen_loss = 0.8302584894985523, disc_loss = 0.08260493664621557
Trained batch 318 in epoch 5, gen_loss = 0.8299120843036795, disc_loss = 0.08258931196315161
Trained batch 319 in epoch 5, gen_loss = 0.8300343330018223, disc_loss = 0.08247681900393218
Trained batch 320 in epoch 5, gen_loss = 0.8301257090962193, disc_loss = 0.08235307794493678
Trained batch 321 in epoch 5, gen_loss = 0.8297097200747603, disc_loss = 0.08224544974957934
Trained batch 322 in epoch 5, gen_loss = 0.8301637813956376, disc_loss = 0.08203064036143269
Trained batch 323 in epoch 5, gen_loss = 0.8297496703855786, disc_loss = 0.08202642027035724
Trained batch 324 in epoch 5, gen_loss = 0.8303587547632364, disc_loss = 0.08183977535137764
Trained batch 325 in epoch 5, gen_loss = 0.8302239648586401, disc_loss = 0.08193517748289313
Trained batch 326 in epoch 5, gen_loss = 0.8294814694729784, disc_loss = 0.08200607496664064
Trained batch 327 in epoch 5, gen_loss = 0.8286577682124405, disc_loss = 0.08198687863513464
Trained batch 328 in epoch 5, gen_loss = 0.829590561995028, disc_loss = 0.08197143954708946
Trained batch 329 in epoch 5, gen_loss = 0.8296391742699074, disc_loss = 0.08188480856743725
Trained batch 330 in epoch 5, gen_loss = 0.829565676587586, disc_loss = 0.0818049161275708
Trained batch 331 in epoch 5, gen_loss = 0.8285413308136435, disc_loss = 0.08228965076696441
Trained batch 332 in epoch 5, gen_loss = 0.83010718727613, disc_loss = 0.08247881984567498
Trained batch 333 in epoch 5, gen_loss = 0.8294704104076602, disc_loss = 0.08259433284848036
Trained batch 334 in epoch 5, gen_loss = 0.8294631805882525, disc_loss = 0.08249757721352934
Trained batch 335 in epoch 5, gen_loss = 0.8295471110336837, disc_loss = 0.082369124915983
Trained batch 336 in epoch 5, gen_loss = 0.8292353622814315, disc_loss = 0.08243822463365266
Trained batch 337 in epoch 5, gen_loss = 0.8288967802503405, disc_loss = 0.0823133084923029
Trained batch 338 in epoch 5, gen_loss = 0.8288964892031521, disc_loss = 0.08213953743070627
Trained batch 339 in epoch 5, gen_loss = 0.8291457552243682, disc_loss = 0.08223822161774424
Trained batch 340 in epoch 5, gen_loss = 0.8287664138851277, disc_loss = 0.08219190351555775
Trained batch 341 in epoch 5, gen_loss = 0.8279085696963538, disc_loss = 0.08251544688310888
Trained batch 342 in epoch 5, gen_loss = 0.8282525847847886, disc_loss = 0.08262844593332043
Trained batch 343 in epoch 5, gen_loss = 0.8279445205143717, disc_loss = 0.08255709212836485
Trained batch 344 in epoch 5, gen_loss = 0.8276039025921752, disc_loss = 0.08248896355862202
Trained batch 345 in epoch 5, gen_loss = 0.8281655469209472, disc_loss = 0.08264466886532444
Trained batch 346 in epoch 5, gen_loss = 0.8285702218755178, disc_loss = 0.0824507393361598
Trained batch 347 in epoch 5, gen_loss = 0.8287070440663689, disc_loss = 0.0824861241793581
Trained batch 348 in epoch 5, gen_loss = 0.8280994004882167, disc_loss = 0.0825358918763932
Trained batch 349 in epoch 5, gen_loss = 0.8280671123947416, disc_loss = 0.08234511251428298
Trained batch 350 in epoch 5, gen_loss = 0.8276227319512273, disc_loss = 0.0823092389045193
Trained batch 351 in epoch 5, gen_loss = 0.8283575513315472, disc_loss = 0.08242227443472737
Trained batch 352 in epoch 5, gen_loss = 0.8274997417886264, disc_loss = 0.08257946622671386
Trained batch 353 in epoch 5, gen_loss = 0.8279046263903548, disc_loss = 0.08283925723116108
Trained batch 354 in epoch 5, gen_loss = 0.827395309780685, disc_loss = 0.08282881055394528
Trained batch 355 in epoch 5, gen_loss = 0.8267706531319725, disc_loss = 0.08288227410442876
Trained batch 356 in epoch 5, gen_loss = 0.8264883760811568, disc_loss = 0.08294020056286279
Trained batch 357 in epoch 5, gen_loss = 0.8266547426331643, disc_loss = 0.0828068352372037
Trained batch 358 in epoch 5, gen_loss = 0.8271208466095512, disc_loss = 0.08275263024426602
Trained batch 359 in epoch 5, gen_loss = 0.8271613229480055, disc_loss = 0.08262551774063873
Trained batch 360 in epoch 5, gen_loss = 0.8271294781871119, disc_loss = 0.08270059903139387
Trained batch 361 in epoch 5, gen_loss = 0.8261305037782996, disc_loss = 0.08291583876151241
Trained batch 362 in epoch 5, gen_loss = 0.8260484951915164, disc_loss = 0.08299586705904526
Trained batch 363 in epoch 5, gen_loss = 0.8253543877994621, disc_loss = 0.08317287368085849
Trained batch 364 in epoch 5, gen_loss = 0.8263152406640248, disc_loss = 0.08317856147170884
Trained batch 365 in epoch 5, gen_loss = 0.8267363808194145, disc_loss = 0.08302675263416734
Trained batch 366 in epoch 5, gen_loss = 0.8262130829229017, disc_loss = 0.08317344213965316
Trained batch 367 in epoch 5, gen_loss = 0.8256229947766532, disc_loss = 0.08340103509734668
Trained batch 368 in epoch 5, gen_loss = 0.8265129213087604, disc_loss = 0.08359734021975257
Trained batch 369 in epoch 5, gen_loss = 0.8256143775340673, disc_loss = 0.08383310403473473
Trained batch 370 in epoch 5, gen_loss = 0.8256656830362232, disc_loss = 0.08372367977232464
Trained batch 371 in epoch 5, gen_loss = 0.8255992543793493, disc_loss = 0.08368259468566507
Trained batch 372 in epoch 5, gen_loss = 0.8256316564517749, disc_loss = 0.08353574411199495
Trained batch 373 in epoch 5, gen_loss = 0.8260395851205377, disc_loss = 0.08391188014358442
Trained batch 374 in epoch 5, gen_loss = 0.8250982032616934, disc_loss = 0.08428411250313123
Trained batch 375 in epoch 5, gen_loss = 0.8256013167506837, disc_loss = 0.08409824918341288
Trained batch 376 in epoch 5, gen_loss = 0.825271860278886, disc_loss = 0.08399633482711226
Trained batch 377 in epoch 5, gen_loss = 0.8254161597717375, disc_loss = 0.0839438919204647
Trained batch 378 in epoch 5, gen_loss = 0.8249024508968192, disc_loss = 0.08389152121044557
Trained batch 379 in epoch 5, gen_loss = 0.8245867209214913, disc_loss = 0.0839414314464911
Trained batch 380 in epoch 5, gen_loss = 0.8252449975082568, disc_loss = 0.0839908501069768
Trained batch 381 in epoch 5, gen_loss = 0.8244134759559681, disc_loss = 0.08411619545531054
Trained batch 382 in epoch 5, gen_loss = 0.8243709171565332, disc_loss = 0.08403707327267676
Trained batch 383 in epoch 5, gen_loss = 0.8244427655978749, disc_loss = 0.08421622036742822
Trained batch 384 in epoch 5, gen_loss = 0.8239465876833185, disc_loss = 0.08432908904339587
Trained batch 385 in epoch 5, gen_loss = 0.8236763779209068, disc_loss = 0.08430606854954069
Trained batch 386 in epoch 5, gen_loss = 0.823351079718395, disc_loss = 0.08417413557472925
Trained batch 387 in epoch 5, gen_loss = 0.8245443209391279, disc_loss = 0.08427442916064072
Trained batch 388 in epoch 5, gen_loss = 0.8241839912219648, disc_loss = 0.08423576956485568
Trained batch 389 in epoch 5, gen_loss = 0.8240717529486388, disc_loss = 0.08408591912056392
Trained batch 390 in epoch 5, gen_loss = 0.8243202703535709, disc_loss = 0.08390353008618821
Trained batch 391 in epoch 5, gen_loss = 0.8246348938923709, disc_loss = 0.08377462895634603
Trained batch 392 in epoch 5, gen_loss = 0.824865168211721, disc_loss = 0.08362618610784221
Trained batch 393 in epoch 5, gen_loss = 0.8252841628293701, disc_loss = 0.0835181179853525
Trained batch 394 in epoch 5, gen_loss = 0.8252376778970791, disc_loss = 0.0833983136859687
Trained batch 395 in epoch 5, gen_loss = 0.8248813330675616, disc_loss = 0.0833060260123639
Trained batch 396 in epoch 5, gen_loss = 0.8250465161103746, disc_loss = 0.0832876876461078
Trained batch 397 in epoch 5, gen_loss = 0.8263059000124284, disc_loss = 0.08325947841498346
Trained batch 398 in epoch 5, gen_loss = 0.8257021096565371, disc_loss = 0.08328932807325645
Trained batch 399 in epoch 5, gen_loss = 0.825249157473445, disc_loss = 0.08320982952369377
Trained batch 400 in epoch 5, gen_loss = 0.8246311621921616, disc_loss = 0.08321156412911163
Trained batch 401 in epoch 5, gen_loss = 0.8246129830530033, disc_loss = 0.08325689642537218
Trained batch 402 in epoch 5, gen_loss = 0.8247008238625586, disc_loss = 0.0832261673935109
Trained batch 403 in epoch 5, gen_loss = 0.8242619843913777, disc_loss = 0.08332707584227002
Trained batch 404 in epoch 5, gen_loss = 0.824169624366878, disc_loss = 0.08322571900293783
Trained batch 405 in epoch 5, gen_loss = 0.8249700633909902, disc_loss = 0.08345387099549322
Trained batch 406 in epoch 5, gen_loss = 0.82447651160437, disc_loss = 0.08353791184293184
Trained batch 407 in epoch 5, gen_loss = 0.8249793666981015, disc_loss = 0.08347160319624213
Trained batch 408 in epoch 5, gen_loss = 0.8250344794216249, disc_loss = 0.0833304899979228
Trained batch 409 in epoch 5, gen_loss = 0.8249132437676918, disc_loss = 0.08326045254972286
Trained batch 410 in epoch 5, gen_loss = 0.825215306377759, disc_loss = 0.0832471709059429
Trained batch 411 in epoch 5, gen_loss = 0.8251059064732015, disc_loss = 0.08318820180036851
Trained batch 412 in epoch 5, gen_loss = 0.8246625500931867, disc_loss = 0.08314131247443451
Trained batch 413 in epoch 5, gen_loss = 0.8244286548832188, disc_loss = 0.0831618002741845
Trained batch 414 in epoch 5, gen_loss = 0.8249897302633309, disc_loss = 0.08326599680740072
Trained batch 415 in epoch 5, gen_loss = 0.8246251399843738, disc_loss = 0.08328224509247005
Trained batch 416 in epoch 5, gen_loss = 0.8246678817901109, disc_loss = 0.08314631745549772
Trained batch 417 in epoch 5, gen_loss = 0.8261996243131218, disc_loss = 0.08355909242165502
Trained batch 418 in epoch 5, gen_loss = 0.8261518746543329, disc_loss = 0.08342295742609265
Trained batch 419 in epoch 5, gen_loss = 0.825451908154147, disc_loss = 0.08382214697831798
Trained batch 420 in epoch 5, gen_loss = 0.8253223712682157, disc_loss = 0.08372810996865362
Trained batch 421 in epoch 5, gen_loss = 0.8255306680761807, disc_loss = 0.08398095755595096
Trained batch 422 in epoch 5, gen_loss = 0.8260414815259036, disc_loss = 0.08385100164813987
Trained batch 423 in epoch 5, gen_loss = 0.8256917763852848, disc_loss = 0.08392810219029
Trained batch 424 in epoch 5, gen_loss = 0.825859595677432, disc_loss = 0.08384535688030369
Trained batch 425 in epoch 5, gen_loss = 0.8256386621317393, disc_loss = 0.08375108149558516
Trained batch 426 in epoch 5, gen_loss = 0.8256765890875243, disc_loss = 0.08371862942086798
Trained batch 427 in epoch 5, gen_loss = 0.8260044670689886, disc_loss = 0.08355216577727452
Trained batch 428 in epoch 5, gen_loss = 0.825727052830316, disc_loss = 0.08348743086311715
Trained batch 429 in epoch 5, gen_loss = 0.8257285038399141, disc_loss = 0.08335088858121009
Trained batch 430 in epoch 5, gen_loss = 0.8267206341512242, disc_loss = 0.08341267330922066
Trained batch 431 in epoch 5, gen_loss = 0.8268531768548267, disc_loss = 0.08328274331547113
Trained batch 432 in epoch 5, gen_loss = 0.8270621874453564, disc_loss = 0.08312837348274422
Trained batch 433 in epoch 5, gen_loss = 0.8277013921929944, disc_loss = 0.0830062350262523
Trained batch 434 in epoch 5, gen_loss = 0.82793490934646, disc_loss = 0.08288561943062078
Trained batch 435 in epoch 5, gen_loss = 0.827405180337779, disc_loss = 0.0829390392643015
Trained batch 436 in epoch 5, gen_loss = 0.8279492772553005, disc_loss = 0.08285625689626763
Trained batch 437 in epoch 5, gen_loss = 0.827930380424408, disc_loss = 0.08270577464006058
Trained batch 438 in epoch 5, gen_loss = 0.8280672059651116, disc_loss = 0.0825545619812567
Trained batch 439 in epoch 5, gen_loss = 0.8283885166726329, disc_loss = 0.0824017202862623
Trained batch 440 in epoch 5, gen_loss = 0.8281938601918772, disc_loss = 0.08230680639933702
Trained batch 441 in epoch 5, gen_loss = 0.8284824492569962, disc_loss = 0.0821407321688816
Trained batch 442 in epoch 5, gen_loss = 0.8281068459455908, disc_loss = 0.08207622283132028
Trained batch 443 in epoch 5, gen_loss = 0.8280179953655681, disc_loss = 0.08194081880873791
Trained batch 444 in epoch 5, gen_loss = 0.8272831348220954, disc_loss = 0.08206998347147797
Trained batch 445 in epoch 5, gen_loss = 0.8280581550614181, disc_loss = 0.08207482835820838
Trained batch 446 in epoch 5, gen_loss = 0.8279307963997459, disc_loss = 0.08195065542372147
Trained batch 447 in epoch 5, gen_loss = 0.827298968564719, disc_loss = 0.08199043868392307
Trained batch 448 in epoch 5, gen_loss = 0.8273334821109517, disc_loss = 0.08191435171378349
Trained batch 449 in epoch 5, gen_loss = 0.8267189483510123, disc_loss = 0.08206190098904902
Trained batch 450 in epoch 5, gen_loss = 0.8269542383645432, disc_loss = 0.08213573092483231
Trained batch 451 in epoch 5, gen_loss = 0.8272303049411394, disc_loss = 0.08219462194257474
Trained batch 452 in epoch 5, gen_loss = 0.827033397838243, disc_loss = 0.08212680145522484
Trained batch 453 in epoch 5, gen_loss = 0.8266153565981315, disc_loss = 0.08221993698340549
Trained batch 454 in epoch 5, gen_loss = 0.8265953774635608, disc_loss = 0.08213660708413674
Trained batch 455 in epoch 5, gen_loss = 0.8269496422195644, disc_loss = 0.08205952347877125
Trained batch 456 in epoch 5, gen_loss = 0.8270591661105793, disc_loss = 0.08192586856007707
Trained batch 457 in epoch 5, gen_loss = 0.8270510936798487, disc_loss = 0.08180397831505433
Trained batch 458 in epoch 5, gen_loss = 0.8271381562182067, disc_loss = 0.08170622010555013
Trained batch 459 in epoch 5, gen_loss = 0.8270601817447206, disc_loss = 0.08159726730588338
Trained batch 460 in epoch 5, gen_loss = 0.8270610320723237, disc_loss = 0.08146592029602694
Trained batch 461 in epoch 5, gen_loss = 0.8267554398867991, disc_loss = 0.08135372255948974
Trained batch 462 in epoch 5, gen_loss = 0.8268356601955051, disc_loss = 0.08121970448779751
Trained batch 463 in epoch 5, gen_loss = 0.8270344598668402, disc_loss = 0.08108710005060481
Trained batch 464 in epoch 5, gen_loss = 0.8263783168408179, disc_loss = 0.08120894712866635
Trained batch 465 in epoch 5, gen_loss = 0.8270152577642719, disc_loss = 0.08147604119576227
Trained batch 466 in epoch 5, gen_loss = 0.826838176625699, disc_loss = 0.08141204403270619
Trained batch 467 in epoch 5, gen_loss = 0.8267722150836235, disc_loss = 0.08138894743055232
Trained batch 468 in epoch 5, gen_loss = 0.8266852459292422, disc_loss = 0.08130368037121509
Trained batch 469 in epoch 5, gen_loss = 0.8269351254752342, disc_loss = 0.0813215995048906
Trained batch 470 in epoch 5, gen_loss = 0.8262389275045658, disc_loss = 0.08136461144847096
Trained batch 471 in epoch 5, gen_loss = 0.8260038113063675, disc_loss = 0.08142793643825008
Trained batch 472 in epoch 5, gen_loss = 0.8269785475655288, disc_loss = 0.08211347162644783
Trained batch 473 in epoch 5, gen_loss = 0.8269033104432786, disc_loss = 0.08199202743622196
Trained batch 474 in epoch 5, gen_loss = 0.8264032073397386, disc_loss = 0.08195776258252169
Trained batch 475 in epoch 5, gen_loss = 0.8261557532583966, disc_loss = 0.08187706432375713
Trained batch 476 in epoch 5, gen_loss = 0.8260913965462139, disc_loss = 0.08197247084284853
Trained batch 477 in epoch 5, gen_loss = 0.8261420473019947, disc_loss = 0.08193630683450145
Trained batch 478 in epoch 5, gen_loss = 0.8255271807717381, disc_loss = 0.08234233086022678
Trained batch 479 in epoch 5, gen_loss = 0.8262007301673293, disc_loss = 0.08232501742507642
Trained batch 480 in epoch 5, gen_loss = 0.8263979563470194, disc_loss = 0.0823328041523819
Trained batch 481 in epoch 5, gen_loss = 0.8261083226604581, disc_loss = 0.08228413992913061
Trained batch 482 in epoch 5, gen_loss = 0.8258222461857411, disc_loss = 0.08242507593987768
Trained batch 483 in epoch 5, gen_loss = 0.8257353760856242, disc_loss = 0.08251759641195748
Trained batch 484 in epoch 5, gen_loss = 0.8257525944832674, disc_loss = 0.08246052525937557
Trained batch 485 in epoch 5, gen_loss = 0.8262104641630816, disc_loss = 0.08232541018215472
Trained batch 486 in epoch 5, gen_loss = 0.8263305593932189, disc_loss = 0.08218042743516593
Trained batch 487 in epoch 5, gen_loss = 0.8262764074396892, disc_loss = 0.08208858858236708
Trained batch 488 in epoch 5, gen_loss = 0.8257595389045334, disc_loss = 0.08226951985507594
Trained batch 489 in epoch 5, gen_loss = 0.8261956135229188, disc_loss = 0.08229604018091852
Trained batch 490 in epoch 5, gen_loss = 0.8261906463963923, disc_loss = 0.08223621031865022
Trained batch 491 in epoch 5, gen_loss = 0.8255477762682651, disc_loss = 0.08231367917950984
Trained batch 492 in epoch 5, gen_loss = 0.8250491478259375, disc_loss = 0.08234176872974416
Trained batch 493 in epoch 5, gen_loss = 0.8249007231190137, disc_loss = 0.08228898760089688
Trained batch 494 in epoch 5, gen_loss = 0.8246084060933855, disc_loss = 0.08219732312353874
Trained batch 495 in epoch 5, gen_loss = 0.824519818288184, disc_loss = 0.08212584119492901
Trained batch 496 in epoch 5, gen_loss = 0.8243389066676019, disc_loss = 0.08205999115995419
Trained batch 497 in epoch 5, gen_loss = 0.8235307421430527, disc_loss = 0.08218417454129422
Trained batch 498 in epoch 5, gen_loss = 0.8237779915093898, disc_loss = 0.08214679016789538
Trained batch 499 in epoch 5, gen_loss = 0.823904555618763, disc_loss = 0.08226021680049599
Trained batch 500 in epoch 5, gen_loss = 0.8234863084352421, disc_loss = 0.08239909134872124
Trained batch 501 in epoch 5, gen_loss = 0.8237963714803832, disc_loss = 0.08227450906139505
Trained batch 502 in epoch 5, gen_loss = 0.8235299745444986, disc_loss = 0.08222870388907004
Trained batch 503 in epoch 5, gen_loss = 0.8241780387858549, disc_loss = 0.08222264531327204
Trained batch 504 in epoch 5, gen_loss = 0.8239275901034326, disc_loss = 0.08219298995699328
Trained batch 505 in epoch 5, gen_loss = 0.8236417840474208, disc_loss = 0.0821113615230521
Trained batch 506 in epoch 5, gen_loss = 0.8239524071150748, disc_loss = 0.08211754642507793
Trained batch 507 in epoch 5, gen_loss = 0.8233507893334223, disc_loss = 0.08250217709697666
Trained batch 508 in epoch 5, gen_loss = 0.823405944586737, disc_loss = 0.08261658351736652
Trained batch 509 in epoch 5, gen_loss = 0.8232235266297472, disc_loss = 0.08262133371340585
Trained batch 510 in epoch 5, gen_loss = 0.8227821719739769, disc_loss = 0.082673657731082
Trained batch 511 in epoch 5, gen_loss = 0.8235224562813528, disc_loss = 0.08258838985238981
Trained batch 512 in epoch 5, gen_loss = 0.8231136835457986, disc_loss = 0.08272717005916332
Trained batch 513 in epoch 5, gen_loss = 0.823165280055907, disc_loss = 0.08268168524581693
Trained batch 514 in epoch 5, gen_loss = 0.823452787318276, disc_loss = 0.08253965361351237
Trained batch 515 in epoch 5, gen_loss = 0.8228244753193485, disc_loss = 0.08271947971819503
Trained batch 516 in epoch 5, gen_loss = 0.8237155066583327, disc_loss = 0.08283926530180921
Trained batch 517 in epoch 5, gen_loss = 0.8237759877701063, disc_loss = 0.08277793566095841
Trained batch 518 in epoch 5, gen_loss = 0.8236580217160241, disc_loss = 0.08273005286888407
Trained batch 519 in epoch 5, gen_loss = 0.8233439088440858, disc_loss = 0.0827711074344384
Trained batch 520 in epoch 5, gen_loss = 0.8228836913598476, disc_loss = 0.08277659220603115
Trained batch 521 in epoch 5, gen_loss = 0.8227589430137613, disc_loss = 0.08271703735828914
Trained batch 522 in epoch 5, gen_loss = 0.823186599330738, disc_loss = 0.08268167810197599
Trained batch 523 in epoch 5, gen_loss = 0.8229588129706965, disc_loss = 0.08266586515490847
Trained batch 524 in epoch 5, gen_loss = 0.822878601040159, disc_loss = 0.08263229888996908
Trained batch 525 in epoch 5, gen_loss = 0.8234066904837641, disc_loss = 0.08258324608865403
Trained batch 526 in epoch 5, gen_loss = 0.8230675163146893, disc_loss = 0.08254167926188495
Trained batch 527 in epoch 5, gen_loss = 0.8233272420298873, disc_loss = 0.08240959148811684
Trained batch 528 in epoch 5, gen_loss = 0.8229775468771309, disc_loss = 0.08241581450971741
Trained batch 529 in epoch 5, gen_loss = 0.8234910017476892, disc_loss = 0.08241031704435371
Trained batch 530 in epoch 5, gen_loss = 0.8233029149234182, disc_loss = 0.08239415703646544
Trained batch 531 in epoch 5, gen_loss = 0.823555809606735, disc_loss = 0.0822778985261413
Trained batch 532 in epoch 5, gen_loss = 0.823732636267875, disc_loss = 0.08215371225777084
Trained batch 533 in epoch 5, gen_loss = 0.8244376549225175, disc_loss = 0.08233244899897539
Trained batch 534 in epoch 5, gen_loss = 0.8239967727772544, disc_loss = 0.08230937123298646
Trained batch 535 in epoch 5, gen_loss = 0.8234846431261568, disc_loss = 0.08240566013464287
Trained batch 536 in epoch 5, gen_loss = 0.8235278261107439, disc_loss = 0.08234243787256255
Trained batch 537 in epoch 5, gen_loss = 0.8233622150239448, disc_loss = 0.08227493580721568
Trained batch 538 in epoch 5, gen_loss = 0.8234693134317592, disc_loss = 0.08220176355211765
Trained batch 539 in epoch 5, gen_loss = 0.8236971394331367, disc_loss = 0.08230150179868495
Trained batch 540 in epoch 5, gen_loss = 0.8233537377028721, disc_loss = 0.08239138187658104
Trained batch 541 in epoch 5, gen_loss = 0.8231959279722834, disc_loss = 0.0823263564246717
Trained batch 542 in epoch 5, gen_loss = 0.8232890025577053, disc_loss = 0.082354001639133
Trained batch 543 in epoch 5, gen_loss = 0.8233710637535242, disc_loss = 0.0822519130717196
Trained batch 544 in epoch 5, gen_loss = 0.8229331274098213, disc_loss = 0.0822944543572194
Trained batch 545 in epoch 5, gen_loss = 0.8230233842527473, disc_loss = 0.08220022042783406
Trained batch 546 in epoch 5, gen_loss = 0.8227232920731226, disc_loss = 0.08220813780941301
Trained batch 547 in epoch 5, gen_loss = 0.8227756931072604, disc_loss = 0.08209969964639767
Trained batch 548 in epoch 5, gen_loss = 0.822393674288074, disc_loss = 0.08206757575354941
Trained batch 549 in epoch 5, gen_loss = 0.822304744774645, disc_loss = 0.08201782013204965
Trained batch 550 in epoch 5, gen_loss = 0.8230044829326186, disc_loss = 0.08195000272345629
Trained batch 551 in epoch 5, gen_loss = 0.8228549750494785, disc_loss = 0.0818821750311316
Trained batch 552 in epoch 5, gen_loss = 0.8225558602249429, disc_loss = 0.08183269530777258
Trained batch 553 in epoch 5, gen_loss = 0.8225631645547784, disc_loss = 0.08192993323268227
Trained batch 554 in epoch 5, gen_loss = 0.8228919592526582, disc_loss = 0.08180590443447366
Trained batch 555 in epoch 5, gen_loss = 0.8228397565029508, disc_loss = 0.08171546375780976
Trained batch 556 in epoch 5, gen_loss = 0.822596180214274, disc_loss = 0.08168822228306606
Trained batch 557 in epoch 5, gen_loss = 0.8224772128900747, disc_loss = 0.08172041313609235
Trained batch 558 in epoch 5, gen_loss = 0.8229735206299477, disc_loss = 0.08199497321304033
Trained batch 559 in epoch 5, gen_loss = 0.8228670762585742, disc_loss = 0.08196568255911447
Trained batch 560 in epoch 5, gen_loss = 0.8225086280900101, disc_loss = 0.08204811982438633
Trained batch 561 in epoch 5, gen_loss = 0.8226724033147839, disc_loss = 0.08197977949013384
Trained batch 562 in epoch 5, gen_loss = 0.8227901076021246, disc_loss = 0.08198619048652069
Trained batch 563 in epoch 5, gen_loss = 0.8228052809623116, disc_loss = 0.08191153898848393
Trained batch 564 in epoch 5, gen_loss = 0.8228075245312885, disc_loss = 0.08193329902678992
Trained batch 565 in epoch 5, gen_loss = 0.8226092315078203, disc_loss = 0.08188244313751956
Trained batch 566 in epoch 5, gen_loss = 0.8223105367844697, disc_loss = 0.0818286373639706
Trained batch 567 in epoch 5, gen_loss = 0.8231278262822561, disc_loss = 0.0818191958020743
Trained batch 568 in epoch 5, gen_loss = 0.8226773458645926, disc_loss = 0.08186302331778726
Trained batch 569 in epoch 5, gen_loss = 0.8226161843329145, disc_loss = 0.08179413938012563
Trained batch 570 in epoch 5, gen_loss = 0.8228729717472597, disc_loss = 0.08172276326750394
Trained batch 571 in epoch 5, gen_loss = 0.8230183623158015, disc_loss = 0.08162035732171856
Trained batch 572 in epoch 5, gen_loss = 0.823637763087038, disc_loss = 0.08169185665694519
Trained batch 573 in epoch 5, gen_loss = 0.8231259309767845, disc_loss = 0.08183103345840755
Trained batch 574 in epoch 5, gen_loss = 0.8231216511000757, disc_loss = 0.08174202541618243
Trained batch 575 in epoch 5, gen_loss = 0.8232858257057766, disc_loss = 0.08167512602004637
Trained batch 576 in epoch 5, gen_loss = 0.8234829587064542, disc_loss = 0.08160048669956275
Trained batch 577 in epoch 5, gen_loss = 0.8237171080801313, disc_loss = 0.08152305225561338
Trained batch 578 in epoch 5, gen_loss = 0.8238487981246955, disc_loss = 0.08145005351482587
Trained batch 579 in epoch 5, gen_loss = 0.8236957629692966, disc_loss = 0.08147498925762443
Trained batch 580 in epoch 5, gen_loss = 0.824409858854215, disc_loss = 0.08143071657473064
Trained batch 581 in epoch 5, gen_loss = 0.8251098033386407, disc_loss = 0.08139906553839593
Trained batch 582 in epoch 5, gen_loss = 0.8252238768758332, disc_loss = 0.08129229044819676
Trained batch 583 in epoch 5, gen_loss = 0.8251438175060161, disc_loss = 0.08121165076640677
Trained batch 584 in epoch 5, gen_loss = 0.8250078905851413, disc_loss = 0.08118047482119156
Trained batch 585 in epoch 5, gen_loss = 0.8249341999609723, disc_loss = 0.08120466270023137
Trained batch 586 in epoch 5, gen_loss = 0.8254169580579007, disc_loss = 0.08126249500380565
Trained batch 587 in epoch 5, gen_loss = 0.8253837432078763, disc_loss = 0.08119071948145624
Trained batch 588 in epoch 5, gen_loss = 0.8252318548528772, disc_loss = 0.08114411121831988
Trained batch 589 in epoch 5, gen_loss = 0.8255190311347024, disc_loss = 0.08114669583422147
Trained batch 590 in epoch 5, gen_loss = 0.8253796712295255, disc_loss = 0.08106951175695648
Trained batch 591 in epoch 5, gen_loss = 0.8252073692006839, disc_loss = 0.08109004729792375
Trained batch 592 in epoch 5, gen_loss = 0.8256963228596402, disc_loss = 0.08100240005095431
Trained batch 593 in epoch 5, gen_loss = 0.8267144163951328, disc_loss = 0.08104662303358116
Trained batch 594 in epoch 5, gen_loss = 0.8265386401605206, disc_loss = 0.08100924315009297
Trained batch 595 in epoch 5, gen_loss = 0.8262609831938807, disc_loss = 0.08098090812251371
Trained batch 596 in epoch 5, gen_loss = 0.826132858867821, disc_loss = 0.08088536013285919
Trained batch 597 in epoch 5, gen_loss = 0.8261701020608379, disc_loss = 0.08080634746987087
Trained batch 598 in epoch 5, gen_loss = 0.8262762188015875, disc_loss = 0.08071526213982866
Trained batch 599 in epoch 5, gen_loss = 0.8262240572273731, disc_loss = 0.08061442926526069
Trained batch 600 in epoch 5, gen_loss = 0.8267144924293144, disc_loss = 0.08050726827376595
Trained batch 601 in epoch 5, gen_loss = 0.8266567995282899, disc_loss = 0.08042015006883299
Trained batch 602 in epoch 5, gen_loss = 0.8265681482765014, disc_loss = 0.08034017661997236
Trained batch 603 in epoch 5, gen_loss = 0.8269821930898736, disc_loss = 0.08029292022735374
Trained batch 604 in epoch 5, gen_loss = 0.8270906071524975, disc_loss = 0.08018617108156366
Trained batch 605 in epoch 5, gen_loss = 0.8268559748681859, disc_loss = 0.0801201614861687
Trained batch 606 in epoch 5, gen_loss = 0.8267684845496245, disc_loss = 0.08003477403921684
Trained batch 607 in epoch 5, gen_loss = 0.8271673657490235, disc_loss = 0.07995980861290407
Trained batch 608 in epoch 5, gen_loss = 0.8271211253109041, disc_loss = 0.07987030169181832
Trained batch 609 in epoch 5, gen_loss = 0.8276136654810827, disc_loss = 0.07977460087200658
Trained batch 610 in epoch 5, gen_loss = 0.8280250901773987, disc_loss = 0.07969170356391884
Trained batch 611 in epoch 5, gen_loss = 0.8284885426070175, disc_loss = 0.07963042281981972
Trained batch 612 in epoch 5, gen_loss = 0.8284752379136606, disc_loss = 0.07959138600195213
Trained batch 613 in epoch 5, gen_loss = 0.8288656355212488, disc_loss = 0.07949731814756941
Trained batch 614 in epoch 5, gen_loss = 0.829122953153238, disc_loss = 0.07941482494759365
Trained batch 615 in epoch 5, gen_loss = 0.8291675499217077, disc_loss = 0.07931515575664772
Trained batch 616 in epoch 5, gen_loss = 0.8292432752478645, disc_loss = 0.07923521582683249
Trained batch 617 in epoch 5, gen_loss = 0.8291147761649684, disc_loss = 0.07915125132921155
Trained batch 618 in epoch 5, gen_loss = 0.8297285262814246, disc_loss = 0.07922836569151412
Trained batch 619 in epoch 5, gen_loss = 0.829392430618886, disc_loss = 0.07927534055385378
Trained batch 620 in epoch 5, gen_loss = 0.8291919267407938, disc_loss = 0.07927086841668964
Trained batch 621 in epoch 5, gen_loss = 0.8292634173317355, disc_loss = 0.07916373409588381
Trained batch 622 in epoch 5, gen_loss = 0.8297944287522838, disc_loss = 0.07946326417241538
Trained batch 623 in epoch 5, gen_loss = 0.8298352242757877, disc_loss = 0.07936507500917053
Trained batch 624 in epoch 5, gen_loss = 0.8296302119731903, disc_loss = 0.07934107830971479
Trained batch 625 in epoch 5, gen_loss = 0.8293750070440121, disc_loss = 0.07927500972369561
Trained batch 626 in epoch 5, gen_loss = 0.8296741535694026, disc_loss = 0.07925358784653876
Trained batch 627 in epoch 5, gen_loss = 0.8295770486354068, disc_loss = 0.07917328949893118
Trained batch 628 in epoch 5, gen_loss = 0.8292448801626651, disc_loss = 0.07922319922039496
Trained batch 629 in epoch 5, gen_loss = 0.8290004444027704, disc_loss = 0.07923644751399046
Trained batch 630 in epoch 5, gen_loss = 0.8292483759663184, disc_loss = 0.07943484721861768
Trained batch 631 in epoch 5, gen_loss = 0.829140785138441, disc_loss = 0.07937098481203135
Trained batch 632 in epoch 5, gen_loss = 0.8290548385319552, disc_loss = 0.07931873384027449
Trained batch 633 in epoch 5, gen_loss = 0.8286984886750814, disc_loss = 0.07937576986514384
Trained batch 634 in epoch 5, gen_loss = 0.8289272026283534, disc_loss = 0.07940192460045806
Trained batch 635 in epoch 5, gen_loss = 0.8292575766736606, disc_loss = 0.07934833977389026
Trained batch 636 in epoch 5, gen_loss = 0.8290179647400017, disc_loss = 0.07936306290615064
Trained batch 637 in epoch 5, gen_loss = 0.8288984298238934, disc_loss = 0.07939647682168781
Trained batch 638 in epoch 5, gen_loss = 0.8293471533647725, disc_loss = 0.07972518936330117
Trained batch 639 in epoch 5, gen_loss = 0.8290267878677696, disc_loss = 0.07985633876960492
Trained batch 640 in epoch 5, gen_loss = 0.8285784749735536, disc_loss = 0.07994369000004671
Trained batch 641 in epoch 5, gen_loss = 0.8289556336644283, disc_loss = 0.0799462480624308
Trained batch 642 in epoch 5, gen_loss = 0.828804154650049, disc_loss = 0.07991911821837883
Trained batch 643 in epoch 5, gen_loss = 0.8290815753688724, disc_loss = 0.08008202057626816
Trained batch 644 in epoch 5, gen_loss = 0.8287283385908881, disc_loss = 0.08012548455058835
Trained batch 645 in epoch 5, gen_loss = 0.8283846116748756, disc_loss = 0.08010574484290123
Trained batch 646 in epoch 5, gen_loss = 0.8288150128938684, disc_loss = 0.08035248998045876
Trained batch 647 in epoch 5, gen_loss = 0.8284021954937482, disc_loss = 0.08029871343571784
Trained batch 648 in epoch 5, gen_loss = 0.828293195077561, disc_loss = 0.08024022221215103
Trained batch 649 in epoch 5, gen_loss = 0.8279943532668628, disc_loss = 0.0802591659859396
Trained batch 650 in epoch 5, gen_loss = 0.8279698673755892, disc_loss = 0.08025188400008117
Trained batch 651 in epoch 5, gen_loss = 0.8276882119979595, disc_loss = 0.08023222338585355
Trained batch 652 in epoch 5, gen_loss = 0.8278852258944401, disc_loss = 0.08021982102462334
Trained batch 653 in epoch 5, gen_loss = 0.8274240132409862, disc_loss = 0.08035987621708703
Trained batch 654 in epoch 5, gen_loss = 0.8276229335606553, disc_loss = 0.08030794015907831
Trained batch 655 in epoch 5, gen_loss = 0.8277925844872143, disc_loss = 0.08025410056267525
Trained batch 656 in epoch 5, gen_loss = 0.8278097588812743, disc_loss = 0.08023490499750438
Trained batch 657 in epoch 5, gen_loss = 0.8274377342143682, disc_loss = 0.0802763109236933
Trained batch 658 in epoch 5, gen_loss = 0.82747341455024, disc_loss = 0.0803087889873995
Trained batch 659 in epoch 5, gen_loss = 0.8270661199183175, disc_loss = 0.0803366157071044
Trained batch 660 in epoch 5, gen_loss = 0.8270540622016486, disc_loss = 0.08026256800436171
Trained batch 661 in epoch 5, gen_loss = 0.8273973701313543, disc_loss = 0.08020322706150819
Trained batch 662 in epoch 5, gen_loss = 0.8274912271834067, disc_loss = 0.0801052690917685
Trained batch 663 in epoch 5, gen_loss = 0.8277377257774393, disc_loss = 0.08000542775234096
Trained batch 664 in epoch 5, gen_loss = 0.8278668682826192, disc_loss = 0.0799123539596348
Trained batch 665 in epoch 5, gen_loss = 0.8278948968505716, disc_loss = 0.07982952278331146
Trained batch 666 in epoch 5, gen_loss = 0.8278043214259655, disc_loss = 0.07974899917382976
Trained batch 667 in epoch 5, gen_loss = 0.8282208527901216, disc_loss = 0.08019665654046004
Trained batch 668 in epoch 5, gen_loss = 0.827998663589737, disc_loss = 0.08016748487760045
Trained batch 669 in epoch 5, gen_loss = 0.8276735227054625, disc_loss = 0.08043505028724225
Trained batch 670 in epoch 5, gen_loss = 0.8273619279687344, disc_loss = 0.08046034697704184
Trained batch 671 in epoch 5, gen_loss = 0.8276544381376534, disc_loss = 0.08048036225262054
Trained batch 672 in epoch 5, gen_loss = 0.827716841164528, disc_loss = 0.08042382153600765
Trained batch 673 in epoch 5, gen_loss = 0.8274156028067676, disc_loss = 0.08038969876006997
Trained batch 674 in epoch 5, gen_loss = 0.8274939963994202, disc_loss = 0.08029761865183159
Trained batch 675 in epoch 5, gen_loss = 0.8273640591100123, disc_loss = 0.08025507287800136
Trained batch 676 in epoch 5, gen_loss = 0.8276202550578857, disc_loss = 0.08018420583828513
Trained batch 677 in epoch 5, gen_loss = 0.8278382158121177, disc_loss = 0.08013867269816828
Trained batch 678 in epoch 5, gen_loss = 0.8275320705064794, disc_loss = 0.08020815153953254
Trained batch 679 in epoch 5, gen_loss = 0.8280356319073369, disc_loss = 0.08014629179721369
Trained batch 680 in epoch 5, gen_loss = 0.8281738309520632, disc_loss = 0.08005886936831054
Trained batch 681 in epoch 5, gen_loss = 0.8281313196217909, disc_loss = 0.08001479739732931
Trained batch 682 in epoch 5, gen_loss = 0.8282096465806835, disc_loss = 0.07991584653162982
Trained batch 683 in epoch 5, gen_loss = 0.8282799108596574, disc_loss = 0.0798385002805541
Trained batch 684 in epoch 5, gen_loss = 0.8283784960743285, disc_loss = 0.07975958605725182
Trained batch 685 in epoch 5, gen_loss = 0.8284377824547687, disc_loss = 0.07987882292886474
Trained batch 686 in epoch 5, gen_loss = 0.8284281393759809, disc_loss = 0.07984185399246312
Trained batch 687 in epoch 5, gen_loss = 0.8281805131064598, disc_loss = 0.07988338633088482
Trained batch 688 in epoch 5, gen_loss = 0.8283457841253765, disc_loss = 0.07979251737794224
Trained batch 689 in epoch 5, gen_loss = 0.8290634679189627, disc_loss = 0.07980704252891567
Trained batch 690 in epoch 5, gen_loss = 0.8292860260661881, disc_loss = 0.07972928041028865
Trained batch 691 in epoch 5, gen_loss = 0.8288723060247526, disc_loss = 0.07985085559432863
Trained batch 692 in epoch 5, gen_loss = 0.8294580676424899, disc_loss = 0.07982658266263219
Trained batch 693 in epoch 5, gen_loss = 0.8298164907123582, disc_loss = 0.07985096355438533
Trained batch 694 in epoch 5, gen_loss = 0.8297224941442338, disc_loss = 0.0798463520212032
Trained batch 695 in epoch 5, gen_loss = 0.8295975164349737, disc_loss = 0.07983248546350233
Trained batch 696 in epoch 5, gen_loss = 0.8296754532513694, disc_loss = 0.0797537980611881
Trained batch 697 in epoch 5, gen_loss = 0.8301371523421952, disc_loss = 0.07979493995829563
Trained batch 698 in epoch 5, gen_loss = 0.8299505143973961, disc_loss = 0.0798855599999236
Trained batch 699 in epoch 5, gen_loss = 0.8298073625990323, disc_loss = 0.07988927159857537
Trained batch 700 in epoch 5, gen_loss = 0.829935585253589, disc_loss = 0.08014291588525246
Trained batch 701 in epoch 5, gen_loss = 0.8297148125718462, disc_loss = 0.08014494922420705
Trained batch 702 in epoch 5, gen_loss = 0.8297340574423925, disc_loss = 0.08011862112985524
Trained batch 703 in epoch 5, gen_loss = 0.8295678075995635, disc_loss = 0.08013765924393242
Trained batch 704 in epoch 5, gen_loss = 0.8295973789184652, disc_loss = 0.08008707600995793
Trained batch 705 in epoch 5, gen_loss = 0.8299108211362666, disc_loss = 0.08000753665205736
Trained batch 706 in epoch 5, gen_loss = 0.8298393267468988, disc_loss = 0.07992926659260098
Trained batch 707 in epoch 5, gen_loss = 0.8297089217493763, disc_loss = 0.07997981046252794
Trained batch 708 in epoch 5, gen_loss = 0.8294300172577792, disc_loss = 0.08000622118976919
Trained batch 709 in epoch 5, gen_loss = 0.8295474197243301, disc_loss = 0.07991909004721633
Trained batch 710 in epoch 5, gen_loss = 0.829450065283165, disc_loss = 0.07984953918448438
Trained batch 711 in epoch 5, gen_loss = 0.8297910354194347, disc_loss = 0.0801601788811281
Trained batch 712 in epoch 5, gen_loss = 0.829398731738956, disc_loss = 0.08022467136712219
Trained batch 713 in epoch 5, gen_loss = 0.8291303936590334, disc_loss = 0.08028050290723265
Trained batch 714 in epoch 5, gen_loss = 0.8292481574562046, disc_loss = 0.08033697590414253
Trained batch 715 in epoch 5, gen_loss = 0.8291165942336594, disc_loss = 0.08032125580988242
Trained batch 716 in epoch 5, gen_loss = 0.8292409635903613, disc_loss = 0.080399479211738
Trained batch 717 in epoch 5, gen_loss = 0.8291477143017363, disc_loss = 0.08036230667299671
Trained batch 718 in epoch 5, gen_loss = 0.8287564121881016, disc_loss = 0.08045547621218443
Trained batch 719 in epoch 5, gen_loss = 0.829370100175341, disc_loss = 0.08081846627173946
Trained batch 720 in epoch 5, gen_loss = 0.8289722056643477, disc_loss = 0.08091715516473441
Trained batch 721 in epoch 5, gen_loss = 0.8292356907413276, disc_loss = 0.08094337969435343
Trained batch 722 in epoch 5, gen_loss = 0.8290562757070629, disc_loss = 0.08088717088077532
Trained batch 723 in epoch 5, gen_loss = 0.8287093315417595, disc_loss = 0.08085685624555783
Trained batch 724 in epoch 5, gen_loss = 0.8287004935741424, disc_loss = 0.08084795507762967
Trained batch 725 in epoch 5, gen_loss = 0.8286848517735143, disc_loss = 0.08076492140387742
Trained batch 726 in epoch 5, gen_loss = 0.8284466815535927, disc_loss = 0.08073043096246918
Trained batch 727 in epoch 5, gen_loss = 0.8282508371541133, disc_loss = 0.08073556128055226
Trained batch 728 in epoch 5, gen_loss = 0.8283643646904143, disc_loss = 0.08066341577452928
Trained batch 729 in epoch 5, gen_loss = 0.828322623812989, disc_loss = 0.08061915126897089
Trained batch 730 in epoch 5, gen_loss = 0.8280212463742241, disc_loss = 0.08072471599414353
Trained batch 731 in epoch 5, gen_loss = 0.8281664356915026, disc_loss = 0.0808417858884166
Trained batch 732 in epoch 5, gen_loss = 0.8281620874655361, disc_loss = 0.08079048270667112
Trained batch 733 in epoch 5, gen_loss = 0.828152942600627, disc_loss = 0.08071393787236605
Trained batch 734 in epoch 5, gen_loss = 0.827966539592159, disc_loss = 0.08067077822653818
Trained batch 735 in epoch 5, gen_loss = 0.8279786659404635, disc_loss = 0.08068152108740911
Trained batch 736 in epoch 5, gen_loss = 0.8278784123091394, disc_loss = 0.0806172084596559
Trained batch 737 in epoch 5, gen_loss = 0.8280982409470127, disc_loss = 0.08052434392026082
Trained batch 738 in epoch 5, gen_loss = 0.8279527547152987, disc_loss = 0.08048634889317584
Trained batch 739 in epoch 5, gen_loss = 0.827834704800232, disc_loss = 0.08044464350929735
Trained batch 740 in epoch 5, gen_loss = 0.8282235730917026, disc_loss = 0.08057346405504164
Trained batch 741 in epoch 5, gen_loss = 0.8280552031617923, disc_loss = 0.08060128644806637
Trained batch 742 in epoch 5, gen_loss = 0.8281449927054697, disc_loss = 0.0805332208538621
Trained batch 743 in epoch 5, gen_loss = 0.8283286510055424, disc_loss = 0.08045634314022278
Trained batch 744 in epoch 5, gen_loss = 0.827995824213796, disc_loss = 0.08048993658224408
Trained batch 745 in epoch 5, gen_loss = 0.8281318240526854, disc_loss = 0.08043030950168382
Trained batch 746 in epoch 5, gen_loss = 0.8284147598417887, disc_loss = 0.08035721778096644
Trained batch 747 in epoch 5, gen_loss = 0.8281560389195534, disc_loss = 0.08029606254188652
Trained batch 748 in epoch 5, gen_loss = 0.8279325881294001, disc_loss = 0.08032964447635078
Trained batch 749 in epoch 5, gen_loss = 0.8281859364906947, disc_loss = 0.08024956574166814
Trained batch 750 in epoch 5, gen_loss = 0.8287926788891997, disc_loss = 0.08032810257576634
Trained batch 751 in epoch 5, gen_loss = 0.8289588652947482, disc_loss = 0.08025569445825123
Trained batch 752 in epoch 5, gen_loss = 0.8284849926215877, disc_loss = 0.08075970693171064
Trained batch 753 in epoch 5, gen_loss = 0.828637908679737, disc_loss = 0.08075134553860093
Trained batch 754 in epoch 5, gen_loss = 0.8287294422159132, disc_loss = 0.08075967524694094
Trained batch 755 in epoch 5, gen_loss = 0.828569606064804, disc_loss = 0.08073727635632234
Trained batch 756 in epoch 5, gen_loss = 0.8284144785397907, disc_loss = 0.08073388133444079
Trained batch 757 in epoch 5, gen_loss = 0.8286760214686708, disc_loss = 0.0807611055089785
Trained batch 758 in epoch 5, gen_loss = 0.8283520707264248, disc_loss = 0.08081052402139927
Trained batch 759 in epoch 5, gen_loss = 0.8286266317100901, disc_loss = 0.08082356361647773
Trained batch 760 in epoch 5, gen_loss = 0.8287415627816034, disc_loss = 0.08073776308936648
Trained batch 761 in epoch 5, gen_loss = 0.828795489246451, disc_loss = 0.0806520941980144
Trained batch 762 in epoch 5, gen_loss = 0.8288778449807849, disc_loss = 0.08057536020127966
Trained batch 763 in epoch 5, gen_loss = 0.8288042141582953, disc_loss = 0.08051578371775829
Trained batch 764 in epoch 5, gen_loss = 0.8288006772013271, disc_loss = 0.08043891529315243
Trained batch 765 in epoch 5, gen_loss = 0.8292210992649393, disc_loss = 0.08042056096824708
Trained batch 766 in epoch 5, gen_loss = 0.8292869051634255, disc_loss = 0.08035423923186676
Trained batch 767 in epoch 5, gen_loss = 0.8291560943471268, disc_loss = 0.08031169971097067
Trained batch 768 in epoch 5, gen_loss = 0.8289852919364626, disc_loss = 0.08028210951826778
Trained batch 769 in epoch 5, gen_loss = 0.8290438282412368, disc_loss = 0.08030269408550161
Trained batch 770 in epoch 5, gen_loss = 0.8288859243754747, disc_loss = 0.08030615908718255
Trained batch 771 in epoch 5, gen_loss = 0.8287385670863903, disc_loss = 0.08030021088704506
Trained batch 772 in epoch 5, gen_loss = 0.8290132354718439, disc_loss = 0.0802498847128098
Trained batch 773 in epoch 5, gen_loss = 0.8292195630242967, disc_loss = 0.0802322332939802
Trained batch 774 in epoch 5, gen_loss = 0.8289350282376813, disc_loss = 0.08024043009526306
Trained batch 775 in epoch 5, gen_loss = 0.8288574171511783, disc_loss = 0.08023407008167663
Trained batch 776 in epoch 5, gen_loss = 0.8287409807494248, disc_loss = 0.08018181225503082
Trained batch 777 in epoch 5, gen_loss = 0.8288762788922743, disc_loss = 0.0800908869946409
Trained batch 778 in epoch 5, gen_loss = 0.8291503136286533, disc_loss = 0.08009473561752822
Trained batch 779 in epoch 5, gen_loss = 0.8289813286600969, disc_loss = 0.08004839236203294
Trained batch 780 in epoch 5, gen_loss = 0.8290067104081338, disc_loss = 0.0800037180907099
Trained batch 781 in epoch 5, gen_loss = 0.8292095515200549, disc_loss = 0.08001878923114837
Trained batch 782 in epoch 5, gen_loss = 0.8292576342935306, disc_loss = 0.07993538128890068
Trained batch 783 in epoch 5, gen_loss = 0.8295111925702314, disc_loss = 0.07984970001579851
Trained batch 784 in epoch 5, gen_loss = 0.8295962438841534, disc_loss = 0.07976845050598405
Trained batch 785 in epoch 5, gen_loss = 0.8291963428713893, disc_loss = 0.07993149093373586
Trained batch 786 in epoch 5, gen_loss = 0.8296237071026993, disc_loss = 0.07991354570285035
Trained batch 787 in epoch 5, gen_loss = 0.8298203382017043, disc_loss = 0.07983104938281899
Trained batch 788 in epoch 5, gen_loss = 0.8297679689824959, disc_loss = 0.07975528750176741
Trained batch 789 in epoch 5, gen_loss = 0.8298154782268066, disc_loss = 0.07967154552947871
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.7199273705482483, disc_loss = 0.06696756184101105
Trained batch 1 in epoch 6, gen_loss = 0.6392324268817902, disc_loss = 0.09522990137338638
Trained batch 2 in epoch 6, gen_loss = 0.7776617010434469, disc_loss = 0.08156933262944221
Trained batch 3 in epoch 6, gen_loss = 0.8977268785238266, disc_loss = 0.07201581727713346
Trained batch 4 in epoch 6, gen_loss = 0.8605626463890076, disc_loss = 0.06749376356601715
Trained batch 5 in epoch 6, gen_loss = 0.8682615458965302, disc_loss = 0.058943948398033776
Trained batch 6 in epoch 6, gen_loss = 0.8733000755310059, disc_loss = 0.05270087080342429
Trained batch 7 in epoch 6, gen_loss = 0.8746811300516129, disc_loss = 0.05470381863415241
Trained batch 8 in epoch 6, gen_loss = 0.8717374934090508, disc_loss = 0.05393913139899572
Trained batch 9 in epoch 6, gen_loss = 0.8542242586612702, disc_loss = 0.052814599499106406
Trained batch 10 in epoch 6, gen_loss = 0.8615448420697992, disc_loss = 0.05148914287036115
Trained batch 11 in epoch 6, gen_loss = 0.8610584785540899, disc_loss = 0.0495451632887125
Trained batch 12 in epoch 6, gen_loss = 0.8667861177371099, disc_loss = 0.04728395649446891
Trained batch 13 in epoch 6, gen_loss = 0.8896871081420353, disc_loss = 0.047683302712227614
Trained batch 14 in epoch 6, gen_loss = 0.8813156962394715, disc_loss = 0.04674877288440863
Trained batch 15 in epoch 6, gen_loss = 0.8724842332303524, disc_loss = 0.04760246316436678
Trained batch 16 in epoch 6, gen_loss = 0.8766469990505892, disc_loss = 0.04537096318295773
Trained batch 17 in epoch 6, gen_loss = 0.8720667660236359, disc_loss = 0.04613343672826886
Trained batch 18 in epoch 6, gen_loss = 0.8732066625042966, disc_loss = 0.047241532145754286
Trained batch 19 in epoch 6, gen_loss = 0.8776817142963409, disc_loss = 0.04562379168346524
Trained batch 20 in epoch 6, gen_loss = 0.8684271517254057, disc_loss = 0.04730210107352052
Trained batch 21 in epoch 6, gen_loss = 0.8687333952296864, disc_loss = 0.0460788006470962
Trained batch 22 in epoch 6, gen_loss = 0.8696818196255228, disc_loss = 0.04454157185619292
Trained batch 23 in epoch 6, gen_loss = 0.8754084557294846, disc_loss = 0.050875643035396934
Trained batch 24 in epoch 6, gen_loss = 0.870483705997467, disc_loss = 0.05146605171263218
Trained batch 25 in epoch 6, gen_loss = 0.8638224853919103, disc_loss = 0.053151581508035846
Trained batch 26 in epoch 6, gen_loss = 0.8781803647677103, disc_loss = 0.06617781775141204
Trained batch 27 in epoch 6, gen_loss = 0.8659110622746604, disc_loss = 0.06824393390810915
Trained batch 28 in epoch 6, gen_loss = 0.869167500528796, disc_loss = 0.06875148987204864
Trained batch 29 in epoch 6, gen_loss = 0.8547050366799037, disc_loss = 0.07277072078237931
Trained batch 30 in epoch 6, gen_loss = 0.854467862075375, disc_loss = 0.07261580523223646
Trained batch 31 in epoch 6, gen_loss = 0.8515731645748019, disc_loss = 0.07203421223675832
Trained batch 32 in epoch 6, gen_loss = 0.8466518132975607, disc_loss = 0.07109475796195594
Trained batch 33 in epoch 6, gen_loss = 0.8405755188535241, disc_loss = 0.07104823458939791
Trained batch 34 in epoch 6, gen_loss = 0.8392185049397605, disc_loss = 0.07262440520737852
Trained batch 35 in epoch 6, gen_loss = 0.8397289655274816, disc_loss = 0.07213978288281295
Trained batch 36 in epoch 6, gen_loss = 0.8305923882368449, disc_loss = 0.07614718563854694
Trained batch 37 in epoch 6, gen_loss = 0.8370138602821451, disc_loss = 0.07524448716522832
Trained batch 38 in epoch 6, gen_loss = 0.8394608321862344, disc_loss = 0.07799453044740054
Trained batch 39 in epoch 6, gen_loss = 0.8332145728170872, disc_loss = 0.0792204957921058
Trained batch 40 in epoch 6, gen_loss = 0.8315140743081163, disc_loss = 0.07789951322100512
Trained batch 41 in epoch 6, gen_loss = 0.8319179323457536, disc_loss = 0.07679359211275975
Trained batch 42 in epoch 6, gen_loss = 0.8296352950639503, disc_loss = 0.07594510743957619
Trained batch 43 in epoch 6, gen_loss = 0.8281617997722193, disc_loss = 0.07714920495213433
Trained batch 44 in epoch 6, gen_loss = 0.8257119410567814, disc_loss = 0.07696789987385273
Trained batch 45 in epoch 6, gen_loss = 0.8236392678126044, disc_loss = 0.07631562225034703
Trained batch 46 in epoch 6, gen_loss = 0.8230575443582332, disc_loss = 0.07555164757402653
Trained batch 47 in epoch 6, gen_loss = 0.825975771372517, disc_loss = 0.07805280430087198
Trained batch 48 in epoch 6, gen_loss = 0.826892359524357, disc_loss = 0.07704038009503666
Trained batch 49 in epoch 6, gen_loss = 0.8252799254655838, disc_loss = 0.07658653784543276
Trained batch 50 in epoch 6, gen_loss = 0.8280304781362122, disc_loss = 0.07542944363519258
Trained batch 51 in epoch 6, gen_loss = 0.8317019841991938, disc_loss = 0.07421739030486116
Trained batch 52 in epoch 6, gen_loss = 0.8309529046967344, disc_loss = 0.07338965603343721
Trained batch 53 in epoch 6, gen_loss = 0.8321765986857591, disc_loss = 0.07238903120849971
Trained batch 54 in epoch 6, gen_loss = 0.8292770499532873, disc_loss = 0.07234961827370254
Trained batch 55 in epoch 6, gen_loss = 0.8317717851272651, disc_loss = 0.07208298801976655
Trained batch 56 in epoch 6, gen_loss = 0.8336761818643201, disc_loss = 0.07112720814582549
Trained batch 57 in epoch 6, gen_loss = 0.8318935966697233, disc_loss = 0.070676999455639
Trained batch 58 in epoch 6, gen_loss = 0.8345346405344495, disc_loss = 0.06971706640985557
Trained batch 59 in epoch 6, gen_loss = 0.8313893372813861, disc_loss = 0.0700902454710255
Trained batch 60 in epoch 6, gen_loss = 0.8339287506752326, disc_loss = 0.06933127232201275
Trained batch 61 in epoch 6, gen_loss = 0.8395866939137059, disc_loss = 0.06911682420139832
Trained batch 62 in epoch 6, gen_loss = 0.8454995453357697, disc_loss = 0.06828341424642574
Trained batch 63 in epoch 6, gen_loss = 0.845063750166446, disc_loss = 0.06751272625115234
Trained batch 64 in epoch 6, gen_loss = 0.8405373605398031, disc_loss = 0.06977726640896155
Trained batch 65 in epoch 6, gen_loss = 0.8355501036752354, disc_loss = 0.06982770603093685
Trained batch 66 in epoch 6, gen_loss = 0.8378790870531282, disc_loss = 0.07158663842493473
Trained batch 67 in epoch 6, gen_loss = 0.8348933725672609, disc_loss = 0.07221630792243078
Trained batch 68 in epoch 6, gen_loss = 0.8319179247254911, disc_loss = 0.0723871228730549
Trained batch 69 in epoch 6, gen_loss = 0.8353477013962609, disc_loss = 0.07530897117352911
Trained batch 70 in epoch 6, gen_loss = 0.8344461250473076, disc_loss = 0.07508491101661618
Trained batch 71 in epoch 6, gen_loss = 0.8294604830443859, disc_loss = 0.07735699638983028
Trained batch 72 in epoch 6, gen_loss = 0.8331894429579173, disc_loss = 0.0778497802093625
Trained batch 73 in epoch 6, gen_loss = 0.8341091029547356, disc_loss = 0.0772522453948654
Trained batch 74 in epoch 6, gen_loss = 0.8319557694594065, disc_loss = 0.0775049493337671
Trained batch 75 in epoch 6, gen_loss = 0.8324570714643127, disc_loss = 0.0771213159773891
Trained batch 76 in epoch 6, gen_loss = 0.8304931904588427, disc_loss = 0.0773654595235145
Trained batch 77 in epoch 6, gen_loss = 0.8279039175846638, disc_loss = 0.07766311583467402
Trained batch 78 in epoch 6, gen_loss = 0.829505679350865, disc_loss = 0.07705585126871173
Trained batch 79 in epoch 6, gen_loss = 0.8333621624857187, disc_loss = 0.07700930448481813
Trained batch 80 in epoch 6, gen_loss = 0.8281619887293121, disc_loss = 0.08026585448533297
Trained batch 81 in epoch 6, gen_loss = 0.8298181244512883, disc_loss = 0.07988581162445792
Trained batch 82 in epoch 6, gen_loss = 0.8297377831964607, disc_loss = 0.0793228028790958
Trained batch 83 in epoch 6, gen_loss = 0.829526852284159, disc_loss = 0.07994401504817818
Trained batch 84 in epoch 6, gen_loss = 0.8282639244023491, disc_loss = 0.079952150550397
Trained batch 85 in epoch 6, gen_loss = 0.8290744416935499, disc_loss = 0.08019406535814322
Trained batch 86 in epoch 6, gen_loss = 0.8281345552411573, disc_loss = 0.07989008460279512
Trained batch 87 in epoch 6, gen_loss = 0.831581749022007, disc_loss = 0.07968145427929069
Trained batch 88 in epoch 6, gen_loss = 0.8288445633448912, disc_loss = 0.07943876925855875
Trained batch 89 in epoch 6, gen_loss = 0.8283524466885461, disc_loss = 0.07911387397390272
Trained batch 90 in epoch 6, gen_loss = 0.8308165184744112, disc_loss = 0.07855022517493465
Trained batch 91 in epoch 6, gen_loss = 0.8296438941489095, disc_loss = 0.0784409876163725
Trained batch 92 in epoch 6, gen_loss = 0.8290864242020474, disc_loss = 0.07823944831847825
Trained batch 93 in epoch 6, gen_loss = 0.8289214055588905, disc_loss = 0.07769794241980986
Trained batch 94 in epoch 6, gen_loss = 0.8299437209179527, disc_loss = 0.07745163333847334
Trained batch 95 in epoch 6, gen_loss = 0.8292316508789858, disc_loss = 0.0771777842019219
Trained batch 96 in epoch 6, gen_loss = 0.8302810831168264, disc_loss = 0.07746625894238961
Trained batch 97 in epoch 6, gen_loss = 0.8303937948479945, disc_loss = 0.07686542783274639
Trained batch 98 in epoch 6, gen_loss = 0.830117080548797, disc_loss = 0.07630129680601937
Trained batch 99 in epoch 6, gen_loss = 0.830147129893303, disc_loss = 0.0764986330550164
Trained batch 100 in epoch 6, gen_loss = 0.8296034406907488, disc_loss = 0.07638951165066792
Trained batch 101 in epoch 6, gen_loss = 0.8315258189743641, disc_loss = 0.07613522598666012
Trained batch 102 in epoch 6, gen_loss = 0.8320669821165141, disc_loss = 0.07572573111437768
Trained batch 103 in epoch 6, gen_loss = 0.832936762044063, disc_loss = 0.07542230940173165
Trained batch 104 in epoch 6, gen_loss = 0.8347091646421523, disc_loss = 0.07483938528845707
Trained batch 105 in epoch 6, gen_loss = 0.8333624994979715, disc_loss = 0.0746612430128427
Trained batch 106 in epoch 6, gen_loss = 0.8334794150334652, disc_loss = 0.075355304953442
Trained batch 107 in epoch 6, gen_loss = 0.8326396936619723, disc_loss = 0.07501658453192148
Trained batch 108 in epoch 6, gen_loss = 0.8342565041069591, disc_loss = 0.07446209161004069
Trained batch 109 in epoch 6, gen_loss = 0.8336462481455369, disc_loss = 0.07427922356027093
Trained batch 110 in epoch 6, gen_loss = 0.832545775014001, disc_loss = 0.07410765023952401
Trained batch 111 in epoch 6, gen_loss = 0.8317982767309461, disc_loss = 0.07379196518533197
Trained batch 112 in epoch 6, gen_loss = 0.8331457450326565, disc_loss = 0.07329115578987166
Trained batch 113 in epoch 6, gen_loss = 0.8344071936189082, disc_loss = 0.07301397981906407
Trained batch 114 in epoch 6, gen_loss = 0.8346508969431338, disc_loss = 0.07261991080544565
Trained batch 115 in epoch 6, gen_loss = 0.8367454265726024, disc_loss = 0.0723651624525544
Trained batch 116 in epoch 6, gen_loss = 0.8385551790905814, disc_loss = 0.0718629591119213
Trained batch 117 in epoch 6, gen_loss = 0.8388970544782736, disc_loss = 0.07172315218091263
Trained batch 118 in epoch 6, gen_loss = 0.8397513342504742, disc_loss = 0.07119858325185145
Trained batch 119 in epoch 6, gen_loss = 0.8401061023275057, disc_loss = 0.07083990795072168
Trained batch 120 in epoch 6, gen_loss = 0.8399306983987161, disc_loss = 0.07054750434284614
Trained batch 121 in epoch 6, gen_loss = 0.8392063100807002, disc_loss = 0.07117309944215612
Trained batch 122 in epoch 6, gen_loss = 0.8388534420874061, disc_loss = 0.07083063137270813
Trained batch 123 in epoch 6, gen_loss = 0.8378136931888519, disc_loss = 0.07079508144318336
Trained batch 124 in epoch 6, gen_loss = 0.8399164156913758, disc_loss = 0.07044897047430276
Trained batch 125 in epoch 6, gen_loss = 0.8434036851875366, disc_loss = 0.07082234782033733
Trained batch 126 in epoch 6, gen_loss = 0.8433892966255429, disc_loss = 0.07053854856933431
Trained batch 127 in epoch 6, gen_loss = 0.84255251288414, disc_loss = 0.07050245727441506
Trained batch 128 in epoch 6, gen_loss = 0.8426678647366606, disc_loss = 0.07051954638617214
Trained batch 129 in epoch 6, gen_loss = 0.8439795186886421, disc_loss = 0.07006335783606539
Trained batch 130 in epoch 6, gen_loss = 0.8449635287277572, disc_loss = 0.06970219621932461
Trained batch 131 in epoch 6, gen_loss = 0.8430702555360217, disc_loss = 0.07003633492400474
Trained batch 132 in epoch 6, gen_loss = 0.8428361855055156, disc_loss = 0.06981339737688913
Trained batch 133 in epoch 6, gen_loss = 0.8438703551221249, disc_loss = 0.070082581150276
Trained batch 134 in epoch 6, gen_loss = 0.8422346962822809, disc_loss = 0.07030913427610089
Trained batch 135 in epoch 6, gen_loss = 0.8425992302158299, disc_loss = 0.07066695124376565
Trained batch 136 in epoch 6, gen_loss = 0.8421525572338243, disc_loss = 0.07049145139617859
Trained batch 137 in epoch 6, gen_loss = 0.8414333488630212, disc_loss = 0.07021045842059497
Trained batch 138 in epoch 6, gen_loss = 0.8432214242948902, disc_loss = 0.07008599597799907
Trained batch 139 in epoch 6, gen_loss = 0.8424089763845716, disc_loss = 0.06995417907434914
Trained batch 140 in epoch 6, gen_loss = 0.8407890069569256, disc_loss = 0.07022788027526004
Trained batch 141 in epoch 6, gen_loss = 0.8418638681022215, disc_loss = 0.07005626304914624
Trained batch 142 in epoch 6, gen_loss = 0.8431397968238884, disc_loss = 0.07135025839731618
Trained batch 143 in epoch 6, gen_loss = 0.8407946928507752, disc_loss = 0.07191203333463313
Trained batch 144 in epoch 6, gen_loss = 0.8403798567837683, disc_loss = 0.0716247263203921
Trained batch 145 in epoch 6, gen_loss = 0.8399265865757041, disc_loss = 0.07138493588857658
Trained batch 146 in epoch 6, gen_loss = 0.8408463804089293, disc_loss = 0.07215550119298048
Trained batch 147 in epoch 6, gen_loss = 0.8384289612641206, disc_loss = 0.0730374696400218
Trained batch 148 in epoch 6, gen_loss = 0.8380692293179915, disc_loss = 0.07289301314634965
Trained batch 149 in epoch 6, gen_loss = 0.8371458180745442, disc_loss = 0.07283998877430956
Trained batch 150 in epoch 6, gen_loss = 0.8382891787598464, disc_loss = 0.07324647193540208
Trained batch 151 in epoch 6, gen_loss = 0.8365024245883289, disc_loss = 0.07388323849973906
Trained batch 152 in epoch 6, gen_loss = 0.8367494555080638, disc_loss = 0.07424431445770989
Trained batch 153 in epoch 6, gen_loss = 0.8369794565361816, disc_loss = 0.07387153256999014
Trained batch 154 in epoch 6, gen_loss = 0.8376692333529072, disc_loss = 0.07354468921379696
Trained batch 155 in epoch 6, gen_loss = 0.8372729653731371, disc_loss = 0.07336482799086624
Trained batch 156 in epoch 6, gen_loss = 0.8367003859228389, disc_loss = 0.07323463111048102
Trained batch 157 in epoch 6, gen_loss = 0.8384543894966946, disc_loss = 0.07428334070416757
Trained batch 158 in epoch 6, gen_loss = 0.838240090031294, disc_loss = 0.07393469044692674
Trained batch 159 in epoch 6, gen_loss = 0.8369577955454588, disc_loss = 0.07392842533881776
Trained batch 160 in epoch 6, gen_loss = 0.8367172146435851, disc_loss = 0.07365895581564733
Trained batch 161 in epoch 6, gen_loss = 0.8381684179659243, disc_loss = 0.07344263100444719
Trained batch 162 in epoch 6, gen_loss = 0.8387468109832951, disc_loss = 0.0731021398678422
Trained batch 163 in epoch 6, gen_loss = 0.8391078885008649, disc_loss = 0.07276971169701982
Trained batch 164 in epoch 6, gen_loss = 0.8385610793576096, disc_loss = 0.07253154515655655
Trained batch 165 in epoch 6, gen_loss = 0.8388431772410151, disc_loss = 0.07227989285623274
Trained batch 166 in epoch 6, gen_loss = 0.8383391884986512, disc_loss = 0.07228305716692152
Trained batch 167 in epoch 6, gen_loss = 0.8388764365088373, disc_loss = 0.07196321661606253
Trained batch 168 in epoch 6, gen_loss = 0.837203582715706, disc_loss = 0.07235030269459683
Trained batch 169 in epoch 6, gen_loss = 0.8376815918613882, disc_loss = 0.0723185084267136
Trained batch 170 in epoch 6, gen_loss = 0.8370098095191153, disc_loss = 0.07221290226807894
Trained batch 171 in epoch 6, gen_loss = 0.8379415096931679, disc_loss = 0.07197246087043611
Trained batch 172 in epoch 6, gen_loss = 0.8372573001536331, disc_loss = 0.07184125129348798
Trained batch 173 in epoch 6, gen_loss = 0.8389415278516966, disc_loss = 0.07197206287013216
Trained batch 174 in epoch 6, gen_loss = 0.8378942050252642, disc_loss = 0.072045241376119
Trained batch 175 in epoch 6, gen_loss = 0.8367980786345222, disc_loss = 0.07256590621016751
Trained batch 176 in epoch 6, gen_loss = 0.838614137159229, disc_loss = 0.07310371003560932
Trained batch 177 in epoch 6, gen_loss = 0.8393135569738538, disc_loss = 0.07278642869878853
Trained batch 178 in epoch 6, gen_loss = 0.8384269868861364, disc_loss = 0.07301090195171493
Trained batch 179 in epoch 6, gen_loss = 0.8388244642151726, disc_loss = 0.07357520001112587
Trained batch 180 in epoch 6, gen_loss = 0.8373164844117771, disc_loss = 0.07410469086768713
Trained batch 181 in epoch 6, gen_loss = 0.8378191200586466, disc_loss = 0.07405015543246499
Trained batch 182 in epoch 6, gen_loss = 0.838947243703519, disc_loss = 0.07405848690700498
Trained batch 183 in epoch 6, gen_loss = 0.8387968734554623, disc_loss = 0.07386764523107558
Trained batch 184 in epoch 6, gen_loss = 0.8388500229732411, disc_loss = 0.07363086418827643
Trained batch 185 in epoch 6, gen_loss = 0.838527032444554, disc_loss = 0.07342547253875803
Trained batch 186 in epoch 6, gen_loss = 0.839330452967455, disc_loss = 0.07332762228673632
Trained batch 187 in epoch 6, gen_loss = 0.838483768257689, disc_loss = 0.0731749406946387
Trained batch 188 in epoch 6, gen_loss = 0.8384158532455485, disc_loss = 0.07316753177080677
Trained batch 189 in epoch 6, gen_loss = 0.8384637496973338, disc_loss = 0.07305533679594335
Trained batch 190 in epoch 6, gen_loss = 0.8387955782925272, disc_loss = 0.07308697623946749
Trained batch 191 in epoch 6, gen_loss = 0.8373926458880305, disc_loss = 0.07363906162693941
Trained batch 192 in epoch 6, gen_loss = 0.8362453820791886, disc_loss = 0.07382155153321324
Trained batch 193 in epoch 6, gen_loss = 0.8398577500249922, disc_loss = 0.0757082010350507
Trained batch 194 in epoch 6, gen_loss = 0.8386974496719165, disc_loss = 0.0758670432588611
Trained batch 195 in epoch 6, gen_loss = 0.8378094285726547, disc_loss = 0.07608228185860326
Trained batch 196 in epoch 6, gen_loss = 0.8385700050949445, disc_loss = 0.07586905034495338
Trained batch 197 in epoch 6, gen_loss = 0.8380597953242485, disc_loss = 0.0759151431901211
Trained batch 198 in epoch 6, gen_loss = 0.8371939985596355, disc_loss = 0.07584771953392119
Trained batch 199 in epoch 6, gen_loss = 0.8367334142327308, disc_loss = 0.07567758092191071
Trained batch 200 in epoch 6, gen_loss = 0.8381101174734125, disc_loss = 0.0758984312924802
Trained batch 201 in epoch 6, gen_loss = 0.8376156826420585, disc_loss = 0.07580433075436123
Trained batch 202 in epoch 6, gen_loss = 0.8368480572559563, disc_loss = 0.07597742113628851
Trained batch 203 in epoch 6, gen_loss = 0.8362004838737787, disc_loss = 0.07580746724452897
Trained batch 204 in epoch 6, gen_loss = 0.836323375818206, disc_loss = 0.07554950726377528
Trained batch 205 in epoch 6, gen_loss = 0.8355821521536818, disc_loss = 0.07573551761926813
Trained batch 206 in epoch 6, gen_loss = 0.8347207376922386, disc_loss = 0.07597505021840334
Trained batch 207 in epoch 6, gen_loss = 0.8343421005858824, disc_loss = 0.07577491545816883
Trained batch 208 in epoch 6, gen_loss = 0.8336233816078406, disc_loss = 0.07570450830955112
Trained batch 209 in epoch 6, gen_loss = 0.8339161566325597, disc_loss = 0.0753930128711675
Trained batch 210 in epoch 6, gen_loss = 0.8346888047259001, disc_loss = 0.07538113216494356
Trained batch 211 in epoch 6, gen_loss = 0.8338386332089046, disc_loss = 0.07530933358038794
Trained batch 212 in epoch 6, gen_loss = 0.8329517287267766, disc_loss = 0.07539267907522514
Trained batch 213 in epoch 6, gen_loss = 0.8345404189323711, disc_loss = 0.07582295595050276
Trained batch 214 in epoch 6, gen_loss = 0.8340888733087584, disc_loss = 0.07572098661560651
Trained batch 215 in epoch 6, gen_loss = 0.8345535380972756, disc_loss = 0.07548805324929869
Trained batch 216 in epoch 6, gen_loss = 0.8347918866416826, disc_loss = 0.07552452439073182
Trained batch 217 in epoch 6, gen_loss = 0.8336632218929606, disc_loss = 0.07569264315085811
Trained batch 218 in epoch 6, gen_loss = 0.8337884504501134, disc_loss = 0.07557424421945255
Trained batch 219 in epoch 6, gen_loss = 0.8332141079685905, disc_loss = 0.07563091403466057
Trained batch 220 in epoch 6, gen_loss = 0.8338931558898132, disc_loss = 0.07553743136566284
Trained batch 221 in epoch 6, gen_loss = 0.832741214885368, disc_loss = 0.07557736240277016
Trained batch 222 in epoch 6, gen_loss = 0.8320147755969266, disc_loss = 0.07556850570483727
Trained batch 223 in epoch 6, gen_loss = 0.8317421323486737, disc_loss = 0.07544457064692064
Trained batch 224 in epoch 6, gen_loss = 0.8329902760187785, disc_loss = 0.07561315228955613
Trained batch 225 in epoch 6, gen_loss = 0.8338133481751501, disc_loss = 0.07536096599332132
Trained batch 226 in epoch 6, gen_loss = 0.8333536901137902, disc_loss = 0.0752081442583303
Trained batch 227 in epoch 6, gen_loss = 0.8329088358502639, disc_loss = 0.07558095712100335
Trained batch 228 in epoch 6, gen_loss = 0.831829092648352, disc_loss = 0.07603606414537893
Trained batch 229 in epoch 6, gen_loss = 0.8313227396944295, disc_loss = 0.07660802630707622
Trained batch 230 in epoch 6, gen_loss = 0.8300595007417522, disc_loss = 0.07673383425534158
Trained batch 231 in epoch 6, gen_loss = 0.8311533118630278, disc_loss = 0.07676771349386023
Trained batch 232 in epoch 6, gen_loss = 0.8310151465972606, disc_loss = 0.07664917085255804
Trained batch 233 in epoch 6, gen_loss = 0.8297976782688727, disc_loss = 0.0769641998813002
Trained batch 234 in epoch 6, gen_loss = 0.8297376767117927, disc_loss = 0.07680316683539051
Trained batch 235 in epoch 6, gen_loss = 0.8310680503057222, disc_loss = 0.07708725777170541
Trained batch 236 in epoch 6, gen_loss = 0.8314646537796857, disc_loss = 0.07688880819072828
Trained batch 237 in epoch 6, gen_loss = 0.8313927570310962, disc_loss = 0.07673548580296025
Trained batch 238 in epoch 6, gen_loss = 0.8313850393853925, disc_loss = 0.07656479419976722
Trained batch 239 in epoch 6, gen_loss = 0.8313500329852104, disc_loss = 0.07644051723570253
Trained batch 240 in epoch 6, gen_loss = 0.8319420500414995, disc_loss = 0.07637766473907281
Trained batch 241 in epoch 6, gen_loss = 0.8304635493223332, disc_loss = 0.07688817376086166
Trained batch 242 in epoch 6, gen_loss = 0.8313558278260408, disc_loss = 0.07705700134191616
Trained batch 243 in epoch 6, gen_loss = 0.8306940622994157, disc_loss = 0.07697343493842321
Trained batch 244 in epoch 6, gen_loss = 0.8311179355699189, disc_loss = 0.07674484175002697
Trained batch 245 in epoch 6, gen_loss = 0.8302920262018839, disc_loss = 0.07669467156056345
Trained batch 246 in epoch 6, gen_loss = 0.831300886053788, disc_loss = 0.07679157433767429
Trained batch 247 in epoch 6, gen_loss = 0.8305223490441999, disc_loss = 0.07693262285207428
Trained batch 248 in epoch 6, gen_loss = 0.830885444778994, disc_loss = 0.07691041812166033
Trained batch 249 in epoch 6, gen_loss = 0.8300282034873963, disc_loss = 0.07713554696366191
Trained batch 250 in epoch 6, gen_loss = 0.8305712396880071, disc_loss = 0.07728362378415715
Trained batch 251 in epoch 6, gen_loss = 0.829845999677976, disc_loss = 0.07734588552488103
Trained batch 252 in epoch 6, gen_loss = 0.8296612392772328, disc_loss = 0.07735669166365042
Trained batch 253 in epoch 6, gen_loss = 0.8293212323676883, disc_loss = 0.07719141703583007
Trained batch 254 in epoch 6, gen_loss = 0.8298099459386339, disc_loss = 0.07694024229970048
Trained batch 255 in epoch 6, gen_loss = 0.8292313928250223, disc_loss = 0.07691083199097193
Trained batch 256 in epoch 6, gen_loss = 0.8304385380522287, disc_loss = 0.07717430083885615
Trained batch 257 in epoch 6, gen_loss = 0.8305254622485286, disc_loss = 0.07694394418305552
Trained batch 258 in epoch 6, gen_loss = 0.8305588608542924, disc_loss = 0.07670596213543852
Trained batch 259 in epoch 6, gen_loss = 0.8308959092085179, disc_loss = 0.0764917318816655
Trained batch 260 in epoch 6, gen_loss = 0.8304327317581323, disc_loss = 0.07651399300430127
Trained batch 261 in epoch 6, gen_loss = 0.8308264419777702, disc_loss = 0.07642506043433801
Trained batch 262 in epoch 6, gen_loss = 0.8302223693735246, disc_loss = 0.07637051068345517
Trained batch 263 in epoch 6, gen_loss = 0.8305936153187896, disc_loss = 0.07615570238946627
Trained batch 264 in epoch 6, gen_loss = 0.8302403584966119, disc_loss = 0.0760671876546628
Trained batch 265 in epoch 6, gen_loss = 0.8300076319759053, disc_loss = 0.075938506545569
Trained batch 266 in epoch 6, gen_loss = 0.8301205364952373, disc_loss = 0.0758379806523745
Trained batch 267 in epoch 6, gen_loss = 0.8299191881026795, disc_loss = 0.0756622944548448
Trained batch 268 in epoch 6, gen_loss = 0.8295195446138488, disc_loss = 0.07554408230344492
Trained batch 269 in epoch 6, gen_loss = 0.8296232141830303, disc_loss = 0.07538898795222243
Trained batch 270 in epoch 6, gen_loss = 0.8304230689562555, disc_loss = 0.0756579288195585
Trained batch 271 in epoch 6, gen_loss = 0.8296052813529968, disc_loss = 0.07593701159074794
Trained batch 272 in epoch 6, gen_loss = 0.8301978220433106, disc_loss = 0.07596106042287179
Trained batch 273 in epoch 6, gen_loss = 0.8286277186261476, disc_loss = 0.07622081390412076
Trained batch 274 in epoch 6, gen_loss = 0.8287482406876304, disc_loss = 0.07624264810234309
Trained batch 275 in epoch 6, gen_loss = 0.8284428113180659, disc_loss = 0.07634403282250075
Trained batch 276 in epoch 6, gen_loss = 0.828059185928386, disc_loss = 0.07623246294321889
Trained batch 277 in epoch 6, gen_loss = 0.8270426356106353, disc_loss = 0.07639343788338115
Trained batch 278 in epoch 6, gen_loss = 0.8272915785885199, disc_loss = 0.07653762003253331
Trained batch 279 in epoch 6, gen_loss = 0.8274935724479812, disc_loss = 0.07644234734387802
Trained batch 280 in epoch 6, gen_loss = 0.8265087759367512, disc_loss = 0.07684242140395679
Trained batch 281 in epoch 6, gen_loss = 0.8278071485089917, disc_loss = 0.0769069177191044
Trained batch 282 in epoch 6, gen_loss = 0.8277563086246854, disc_loss = 0.07672144722377769
Trained batch 283 in epoch 6, gen_loss = 0.8271797368643989, disc_loss = 0.07680773868514093
Trained batch 284 in epoch 6, gen_loss = 0.828939484085953, disc_loss = 0.0770987977812949
Trained batch 285 in epoch 6, gen_loss = 0.8285368924791162, disc_loss = 0.07749264043514857
Trained batch 286 in epoch 6, gen_loss = 0.829234174942721, disc_loss = 0.0781593921623527
Trained batch 287 in epoch 6, gen_loss = 0.8297204296622012, disc_loss = 0.0789336524612736
Trained batch 288 in epoch 6, gen_loss = 0.8289441489018371, disc_loss = 0.07917410410798854
Trained batch 289 in epoch 6, gen_loss = 0.8292045511048416, disc_loss = 0.07913193949016517
Trained batch 290 in epoch 6, gen_loss = 0.8291231004642867, disc_loss = 0.07901262944801055
Trained batch 291 in epoch 6, gen_loss = 0.8281024408667055, disc_loss = 0.07915079817877546
Trained batch 292 in epoch 6, gen_loss = 0.8285056490946955, disc_loss = 0.0790644487900081
Trained batch 293 in epoch 6, gen_loss = 0.8284991156487238, disc_loss = 0.07897708766149725
Trained batch 294 in epoch 6, gen_loss = 0.828316215337333, disc_loss = 0.07915571810267234
Trained batch 295 in epoch 6, gen_loss = 0.8275302521683074, disc_loss = 0.0793106407776626
Trained batch 296 in epoch 6, gen_loss = 0.8272616518065584, disc_loss = 0.07931120782425809
Trained batch 297 in epoch 6, gen_loss = 0.8271883760122645, disc_loss = 0.07929833851842172
Trained batch 298 in epoch 6, gen_loss = 0.826968032380809, disc_loss = 0.07920172779095114
Trained batch 299 in epoch 6, gen_loss = 0.8263012955586115, disc_loss = 0.07923378222621977
Trained batch 300 in epoch 6, gen_loss = 0.8272758720325077, disc_loss = 0.07957799399451065
Trained batch 301 in epoch 6, gen_loss = 0.8268679145550886, disc_loss = 0.07953370597817941
Trained batch 302 in epoch 6, gen_loss = 0.8258621114315373, disc_loss = 0.0796367702944198
Trained batch 303 in epoch 6, gen_loss = 0.825901672048004, disc_loss = 0.07953478360095208
Trained batch 304 in epoch 6, gen_loss = 0.8267066433781484, disc_loss = 0.07947115582704055
Trained batch 305 in epoch 6, gen_loss = 0.8267092439863417, disc_loss = 0.07931532873619908
Trained batch 306 in epoch 6, gen_loss = 0.826147772007734, disc_loss = 0.07923407360899234
Trained batch 307 in epoch 6, gen_loss = 0.8252653158330298, disc_loss = 0.07970956672744994
Trained batch 308 in epoch 6, gen_loss = 0.8264244652103067, disc_loss = 0.08030996554528143
Trained batch 309 in epoch 6, gen_loss = 0.8265656373193188, disc_loss = 0.08020877134836009
Trained batch 310 in epoch 6, gen_loss = 0.8268138643629681, disc_loss = 0.08006803179608951
Trained batch 311 in epoch 6, gen_loss = 0.826056745954049, disc_loss = 0.08019740359845738
Trained batch 312 in epoch 6, gen_loss = 0.8266060971223508, disc_loss = 0.08004573653764523
Trained batch 313 in epoch 6, gen_loss = 0.8275137519001201, disc_loss = 0.08043414676728047
Trained batch 314 in epoch 6, gen_loss = 0.8266270317728557, disc_loss = 0.08078501134342145
Trained batch 315 in epoch 6, gen_loss = 0.8256705635333363, disc_loss = 0.08093945507278454
Trained batch 316 in epoch 6, gen_loss = 0.8260139792875537, disc_loss = 0.08127098212941118
Trained batch 317 in epoch 6, gen_loss = 0.8256294181886709, disc_loss = 0.08136659595564757
Trained batch 318 in epoch 6, gen_loss = 0.8249846668826375, disc_loss = 0.0815044348347103
Trained batch 319 in epoch 6, gen_loss = 0.824853958748281, disc_loss = 0.08140604027721565
Trained batch 320 in epoch 6, gen_loss = 0.8248744224462182, disc_loss = 0.08128849806618003
Trained batch 321 in epoch 6, gen_loss = 0.8249230410741724, disc_loss = 0.08124426097221533
Trained batch 322 in epoch 6, gen_loss = 0.8246276064922935, disc_loss = 0.0812282088665355
Trained batch 323 in epoch 6, gen_loss = 0.8244412729033718, disc_loss = 0.08114155025198412
Trained batch 324 in epoch 6, gen_loss = 0.824750286432413, disc_loss = 0.08122731460688205
Trained batch 325 in epoch 6, gen_loss = 0.8246487706351134, disc_loss = 0.08121763283752499
Trained batch 326 in epoch 6, gen_loss = 0.8246797780742704, disc_loss = 0.08103059502517868
Trained batch 327 in epoch 6, gen_loss = 0.8253793002265256, disc_loss = 0.080850953619541
Trained batch 328 in epoch 6, gen_loss = 0.8253398671700962, disc_loss = 0.0807061618828076
Trained batch 329 in epoch 6, gen_loss = 0.8255458136399587, disc_loss = 0.08050264980587545
Trained batch 330 in epoch 6, gen_loss = 0.8252028574396116, disc_loss = 0.08038925248116614
Trained batch 331 in epoch 6, gen_loss = 0.8254140531083187, disc_loss = 0.08019826513243816
Trained batch 332 in epoch 6, gen_loss = 0.8262482622006276, disc_loss = 0.08037545464026767
Trained batch 333 in epoch 6, gen_loss = 0.82606570984789, disc_loss = 0.08021866638090706
Trained batch 334 in epoch 6, gen_loss = 0.8254379777765986, disc_loss = 0.08047948947537746
Trained batch 335 in epoch 6, gen_loss = 0.8265187939008077, disc_loss = 0.08065571854101672
Trained batch 336 in epoch 6, gen_loss = 0.8266696779593515, disc_loss = 0.08049627786739909
Trained batch 337 in epoch 6, gen_loss = 0.8272157680000779, disc_loss = 0.08029725561579744
Trained batch 338 in epoch 6, gen_loss = 0.8270598811737556, disc_loss = 0.08018061758505296
Trained batch 339 in epoch 6, gen_loss = 0.82775159443126, disc_loss = 0.07999999986358863
Trained batch 340 in epoch 6, gen_loss = 0.8277269671739371, disc_loss = 0.07983968711985259
Trained batch 341 in epoch 6, gen_loss = 0.828033539286831, disc_loss = 0.07969334893941618
Trained batch 342 in epoch 6, gen_loss = 0.8278146290570585, disc_loss = 0.07959913707042314
Trained batch 343 in epoch 6, gen_loss = 0.8275326045100079, disc_loss = 0.07954080503834628
Trained batch 344 in epoch 6, gen_loss = 0.8278549532959427, disc_loss = 0.07934446490599194
Trained batch 345 in epoch 6, gen_loss = 0.8285539925442955, disc_loss = 0.07925687690744597
Trained batch 346 in epoch 6, gen_loss = 0.8283701152554163, disc_loss = 0.0790772672973423
Trained batch 347 in epoch 6, gen_loss = 0.8278539987473652, disc_loss = 0.07909152659202187
Trained batch 348 in epoch 6, gen_loss = 0.8281222839751694, disc_loss = 0.07889842177156818
Trained batch 349 in epoch 6, gen_loss = 0.8278185413564955, disc_loss = 0.0788320858483868
Trained batch 350 in epoch 6, gen_loss = 0.827960169892705, disc_loss = 0.07878216013492767
Trained batch 351 in epoch 6, gen_loss = 0.8272342754697258, disc_loss = 0.07903284510989166
Trained batch 352 in epoch 6, gen_loss = 0.8277644420480593, disc_loss = 0.07898676776651704
Trained batch 353 in epoch 6, gen_loss = 0.8278938914086186, disc_loss = 0.07880941225152652
Trained batch 354 in epoch 6, gen_loss = 0.8278663598315816, disc_loss = 0.078636708176157
Trained batch 355 in epoch 6, gen_loss = 0.8274090872721725, disc_loss = 0.07852092478685918
Trained batch 356 in epoch 6, gen_loss = 0.8284486064723894, disc_loss = 0.07885322927729506
Trained batch 357 in epoch 6, gen_loss = 0.8278084890136506, disc_loss = 0.07908293077534886
Trained batch 358 in epoch 6, gen_loss = 0.8269375041334742, disc_loss = 0.07925869164661528
Trained batch 359 in epoch 6, gen_loss = 0.8272506399287118, disc_loss = 0.07943090222413755
Trained batch 360 in epoch 6, gen_loss = 0.8272288217108665, disc_loss = 0.07940970205668349
Trained batch 361 in epoch 6, gen_loss = 0.827604267972609, disc_loss = 0.07923836240195026
Trained batch 362 in epoch 6, gen_loss = 0.8269911654724562, disc_loss = 0.07934853791441389
Trained batch 363 in epoch 6, gen_loss = 0.8262153484009125, disc_loss = 0.07967231213626871
Trained batch 364 in epoch 6, gen_loss = 0.8262795836958167, disc_loss = 0.07982424623907021
Trained batch 365 in epoch 6, gen_loss = 0.8260305390331915, disc_loss = 0.07976198027195419
Trained batch 366 in epoch 6, gen_loss = 0.8265818607579785, disc_loss = 0.07961343112338223
Trained batch 367 in epoch 6, gen_loss = 0.8272011804839839, disc_loss = 0.07942656094825867
Trained batch 368 in epoch 6, gen_loss = 0.8274529432539695, disc_loss = 0.0792489129630975
Trained batch 369 in epoch 6, gen_loss = 0.8274669740651105, disc_loss = 0.07907751787806282
Trained batch 370 in epoch 6, gen_loss = 0.8281251230651157, disc_loss = 0.07899663650814816
Trained batch 371 in epoch 6, gen_loss = 0.8279424816049555, disc_loss = 0.0788814965360147
Trained batch 372 in epoch 6, gen_loss = 0.82806685974387, disc_loss = 0.07874904765969706
Trained batch 373 in epoch 6, gen_loss = 0.8285272175615485, disc_loss = 0.07858591658974634
Trained batch 374 in epoch 6, gen_loss = 0.8286193075180054, disc_loss = 0.07840965744356314
Trained batch 375 in epoch 6, gen_loss = 0.8293867082671916, disc_loss = 0.07824536258889798
Trained batch 376 in epoch 6, gen_loss = 0.8292199436486242, disc_loss = 0.07813929054461202
Trained batch 377 in epoch 6, gen_loss = 0.8298244019034048, disc_loss = 0.07812717566315933
Trained batch 378 in epoch 6, gen_loss = 0.8290100627650057, disc_loss = 0.07817397582637131
Trained batch 379 in epoch 6, gen_loss = 0.8294686805260809, disc_loss = 0.07800064018535378
Trained batch 380 in epoch 6, gen_loss = 0.8301015937422204, disc_loss = 0.07792544427750696
Trained batch 381 in epoch 6, gen_loss = 0.8298035225006922, disc_loss = 0.07785030881781618
Trained batch 382 in epoch 6, gen_loss = 0.8297334845632548, disc_loss = 0.07781571329038775
Trained batch 383 in epoch 6, gen_loss = 0.8297482610990604, disc_loss = 0.07766935829567956
Trained batch 384 in epoch 6, gen_loss = 0.8296675195941677, disc_loss = 0.07757681225753063
Trained batch 385 in epoch 6, gen_loss = 0.8286375139352571, disc_loss = 0.07775055424797643
Trained batch 386 in epoch 6, gen_loss = 0.830058210733941, disc_loss = 0.07785067459669455
Trained batch 387 in epoch 6, gen_loss = 0.8302584327373308, disc_loss = 0.07776220330786075
Trained batch 388 in epoch 6, gen_loss = 0.8300990477625693, disc_loss = 0.07767371995886907
Trained batch 389 in epoch 6, gen_loss = 0.8299290184791271, disc_loss = 0.07753459654318598
Trained batch 390 in epoch 6, gen_loss = 0.82991085561645, disc_loss = 0.07736292132474196
Trained batch 391 in epoch 6, gen_loss = 0.8296006784147146, disc_loss = 0.07726001019865199
Trained batch 392 in epoch 6, gen_loss = 0.8302674742448725, disc_loss = 0.0772088700194509
Trained batch 393 in epoch 6, gen_loss = 0.830072451666527, disc_loss = 0.07712377449686682
Trained batch 394 in epoch 6, gen_loss = 0.8304213549517379, disc_loss = 0.07695585217892746
Trained batch 395 in epoch 6, gen_loss = 0.8301468667658892, disc_loss = 0.07689500142199297
Trained batch 396 in epoch 6, gen_loss = 0.8303897496434843, disc_loss = 0.07690375781751775
Trained batch 397 in epoch 6, gen_loss = 0.8300021936246498, disc_loss = 0.07682394861809946
Trained batch 398 in epoch 6, gen_loss = 0.8300453745631646, disc_loss = 0.07670973590750219
Trained batch 399 in epoch 6, gen_loss = 0.8297449746727943, disc_loss = 0.07669144729385152
Trained batch 400 in epoch 6, gen_loss = 0.8300980932991998, disc_loss = 0.07690698939823822
Trained batch 401 in epoch 6, gen_loss = 0.8299390427508757, disc_loss = 0.07688369915417548
Trained batch 402 in epoch 6, gen_loss = 0.8297627401115285, disc_loss = 0.07685063343273277
Trained batch 403 in epoch 6, gen_loss = 0.8305348302468215, disc_loss = 0.07712406200578086
Trained batch 404 in epoch 6, gen_loss = 0.8303621786612051, disc_loss = 0.07717157140788104
Trained batch 405 in epoch 6, gen_loss = 0.8297638063653937, disc_loss = 0.07720315704360751
Trained batch 406 in epoch 6, gen_loss = 0.8301956851300795, disc_loss = 0.07716690810484221
Trained batch 407 in epoch 6, gen_loss = 0.830891543013208, disc_loss = 0.07701618311351494
Trained batch 408 in epoch 6, gen_loss = 0.8305449746640212, disc_loss = 0.07707701507992222
Trained batch 409 in epoch 6, gen_loss = 0.8308861383577673, disc_loss = 0.07707260753732266
Trained batch 410 in epoch 6, gen_loss = 0.8305937048872601, disc_loss = 0.07714345722420735
Trained batch 411 in epoch 6, gen_loss = 0.8312118776793619, disc_loss = 0.07727680421542847
Trained batch 412 in epoch 6, gen_loss = 0.8314790740140126, disc_loss = 0.0771217011614335
Trained batch 413 in epoch 6, gen_loss = 0.8309585820649557, disc_loss = 0.07712690462695732
Trained batch 414 in epoch 6, gen_loss = 0.830950777932822, disc_loss = 0.07726802896618484
Trained batch 415 in epoch 6, gen_loss = 0.8309196301091176, disc_loss = 0.07720410903297867
Trained batch 416 in epoch 6, gen_loss = 0.8311973291335346, disc_loss = 0.07739252835396025
Trained batch 417 in epoch 6, gen_loss = 0.8310543280183984, disc_loss = 0.07725523511821217
Trained batch 418 in epoch 6, gen_loss = 0.830075723672539, disc_loss = 0.0777658647290811
Trained batch 419 in epoch 6, gen_loss = 0.8299832468231519, disc_loss = 0.07765423834456929
Trained batch 420 in epoch 6, gen_loss = 0.8308495848733852, disc_loss = 0.07771616653625515
Trained batch 421 in epoch 6, gen_loss = 0.8307622376635176, disc_loss = 0.07763772233393731
Trained batch 422 in epoch 6, gen_loss = 0.8313775834039594, disc_loss = 0.077547050499518
Trained batch 423 in epoch 6, gen_loss = 0.8317062425304134, disc_loss = 0.07739570278911588
Trained batch 424 in epoch 6, gen_loss = 0.831265375403797, disc_loss = 0.07734893194673692
Trained batch 425 in epoch 6, gen_loss = 0.8307906725736851, disc_loss = 0.07744043174160409
Trained batch 426 in epoch 6, gen_loss = 0.8315599573998597, disc_loss = 0.07773700618867782
Trained batch 427 in epoch 6, gen_loss = 0.8315384364991545, disc_loss = 0.07769013163807724
Trained batch 428 in epoch 6, gen_loss = 0.8311419600234443, disc_loss = 0.07772658314416944
Trained batch 429 in epoch 6, gen_loss = 0.8312469437371853, disc_loss = 0.07780512062572809
Trained batch 430 in epoch 6, gen_loss = 0.8313905537958212, disc_loss = 0.07768091321501475
Trained batch 431 in epoch 6, gen_loss = 0.8318499435015299, disc_loss = 0.07753410851755352
Trained batch 432 in epoch 6, gen_loss = 0.8320827658264521, disc_loss = 0.07743403491914685
Trained batch 433 in epoch 6, gen_loss = 0.8317021246192642, disc_loss = 0.07740761508761737
Trained batch 434 in epoch 6, gen_loss = 0.8317556997140249, disc_loss = 0.07751147566341805
Trained batch 435 in epoch 6, gen_loss = 0.8321012342605022, disc_loss = 0.07738018887749779
Trained batch 436 in epoch 6, gen_loss = 0.832055092471688, disc_loss = 0.07732801927888694
Trained batch 437 in epoch 6, gen_loss = 0.8313659347219554, disc_loss = 0.07752876981378418
Trained batch 438 in epoch 6, gen_loss = 0.8319122057433552, disc_loss = 0.07753910033503263
Trained batch 439 in epoch 6, gen_loss = 0.8321846619925716, disc_loss = 0.07759772507812489
Trained batch 440 in epoch 6, gen_loss = 0.832216242611273, disc_loss = 0.07748588565272403
Trained batch 441 in epoch 6, gen_loss = 0.8321356129457508, disc_loss = 0.07749389493374398
Trained batch 442 in epoch 6, gen_loss = 0.8315792535147871, disc_loss = 0.0775867231888171
Trained batch 443 in epoch 6, gen_loss = 0.8314933400299098, disc_loss = 0.07751823631576724
Trained batch 444 in epoch 6, gen_loss = 0.8313696859257944, disc_loss = 0.07746070558519176
Trained batch 445 in epoch 6, gen_loss = 0.8313411833058558, disc_loss = 0.07736580993879938
Trained batch 446 in epoch 6, gen_loss = 0.8313666857462335, disc_loss = 0.0772927809856682
Trained batch 447 in epoch 6, gen_loss = 0.8311881383747927, disc_loss = 0.07724271300165649
Trained batch 448 in epoch 6, gen_loss = 0.8312512833318094, disc_loss = 0.07720164894510086
Trained batch 449 in epoch 6, gen_loss = 0.8313157786925633, disc_loss = 0.0770844314288762
Trained batch 450 in epoch 6, gen_loss = 0.8324542445380513, disc_loss = 0.07742166087576528
Trained batch 451 in epoch 6, gen_loss = 0.831776745881127, disc_loss = 0.07790642486786288
Trained batch 452 in epoch 6, gen_loss = 0.8314029536894615, disc_loss = 0.07785735497658221
Trained batch 453 in epoch 6, gen_loss = 0.8316512763631502, disc_loss = 0.07786661647014025
Trained batch 454 in epoch 6, gen_loss = 0.8324628331504025, disc_loss = 0.07778718795340794
Trained batch 455 in epoch 6, gen_loss = 0.8322364969603848, disc_loss = 0.07766883997164928
Trained batch 456 in epoch 6, gen_loss = 0.832052874421656, disc_loss = 0.0776313888418531
Trained batch 457 in epoch 6, gen_loss = 0.8321151321501711, disc_loss = 0.07753356129305201
Trained batch 458 in epoch 6, gen_loss = 0.8320193788714398, disc_loss = 0.07751412858094915
Trained batch 459 in epoch 6, gen_loss = 0.8329154817306477, disc_loss = 0.07770407584941258
Trained batch 460 in epoch 6, gen_loss = 0.832981562342923, disc_loss = 0.0775693353111987
Trained batch 461 in epoch 6, gen_loss = 0.832738606122149, disc_loss = 0.07747444773326705
Trained batch 462 in epoch 6, gen_loss = 0.8325833279808448, disc_loss = 0.07735612076057471
Trained batch 463 in epoch 6, gen_loss = 0.8326336884678438, disc_loss = 0.07743285729646168
Trained batch 464 in epoch 6, gen_loss = 0.8334495628392825, disc_loss = 0.07744986451761697
Trained batch 465 in epoch 6, gen_loss = 0.8331993130783155, disc_loss = 0.07763914557677482
Trained batch 466 in epoch 6, gen_loss = 0.8328278891151927, disc_loss = 0.07774233934519378
Trained batch 467 in epoch 6, gen_loss = 0.8329138369259671, disc_loss = 0.07763359470404366
Trained batch 468 in epoch 6, gen_loss = 0.8334358575374587, disc_loss = 0.07784173700378648
Trained batch 469 in epoch 6, gen_loss = 0.833737346656779, disc_loss = 0.07796229476782869
Trained batch 470 in epoch 6, gen_loss = 0.8330847283710593, disc_loss = 0.07841322956223144
Trained batch 471 in epoch 6, gen_loss = 0.8328749747725867, disc_loss = 0.07844786870814228
Trained batch 472 in epoch 6, gen_loss = 0.8329303741581092, disc_loss = 0.07852412630305734
Trained batch 473 in epoch 6, gen_loss = 0.8328459199345062, disc_loss = 0.0784951852956779
Trained batch 474 in epoch 6, gen_loss = 0.8324672412244897, disc_loss = 0.07847483728277056
Trained batch 475 in epoch 6, gen_loss = 0.8325876901004495, disc_loss = 0.07837237222041904
Trained batch 476 in epoch 6, gen_loss = 0.8328454533837876, disc_loss = 0.07829131649912528
Trained batch 477 in epoch 6, gen_loss = 0.8327243709040486, disc_loss = 0.07816260052400653
Trained batch 478 in epoch 6, gen_loss = 0.8330940425644837, disc_loss = 0.07802318750894269
Trained batch 479 in epoch 6, gen_loss = 0.8331606710329652, disc_loss = 0.07789218101340036
Trained batch 480 in epoch 6, gen_loss = 0.833029151272625, disc_loss = 0.07778951490836183
Trained batch 481 in epoch 6, gen_loss = 0.8330973358940782, disc_loss = 0.0777607935391892
Trained batch 482 in epoch 6, gen_loss = 0.8327428586858153, disc_loss = 0.07774179247564657
Trained batch 483 in epoch 6, gen_loss = 0.8329611440951173, disc_loss = 0.07766450769922212
Trained batch 484 in epoch 6, gen_loss = 0.832629847342206, disc_loss = 0.0776306683101605
Trained batch 485 in epoch 6, gen_loss = 0.8329083071446713, disc_loss = 0.07766930187128698
Trained batch 486 in epoch 6, gen_loss = 0.8325105687064067, disc_loss = 0.07767317847977918
Trained batch 487 in epoch 6, gen_loss = 0.8326702090438272, disc_loss = 0.07765385203185629
Trained batch 488 in epoch 6, gen_loss = 0.8327249036854274, disc_loss = 0.07763434318798938
Trained batch 489 in epoch 6, gen_loss = 0.8326869166019012, disc_loss = 0.07766593338883652
Trained batch 490 in epoch 6, gen_loss = 0.8322548960352624, disc_loss = 0.07760639545600671
Trained batch 491 in epoch 6, gen_loss = 0.8327052052306935, disc_loss = 0.07774493012698443
Trained batch 492 in epoch 6, gen_loss = 0.8321336800984388, disc_loss = 0.07795093511561835
Trained batch 493 in epoch 6, gen_loss = 0.8323185369674011, disc_loss = 0.07782328821650823
Trained batch 494 in epoch 6, gen_loss = 0.8322366072071923, disc_loss = 0.07773100680888
Trained batch 495 in epoch 6, gen_loss = 0.8330217023650485, disc_loss = 0.07770087904739945
Trained batch 496 in epoch 6, gen_loss = 0.8331043365855572, disc_loss = 0.07761661144501907
Trained batch 497 in epoch 6, gen_loss = 0.8329685448283651, disc_loss = 0.07755067586771636
Trained batch 498 in epoch 6, gen_loss = 0.8329188710821416, disc_loss = 0.07746270333859091
Trained batch 499 in epoch 6, gen_loss = 0.8325915755629539, disc_loss = 0.07744059815071523
Trained batch 500 in epoch 6, gen_loss = 0.8327207181625024, disc_loss = 0.07756849111219545
Trained batch 501 in epoch 6, gen_loss = 0.8329642381207402, disc_loss = 0.0774638624138299
Trained batch 502 in epoch 6, gen_loss = 0.8331080684012494, disc_loss = 0.07735467937480563
Trained batch 503 in epoch 6, gen_loss = 0.8325657386273618, disc_loss = 0.07746691129443842
Trained batch 504 in epoch 6, gen_loss = 0.8329533003934539, disc_loss = 0.07736303377527706
Trained batch 505 in epoch 6, gen_loss = 0.8333168235338724, disc_loss = 0.07729509267256607
Trained batch 506 in epoch 6, gen_loss = 0.8333534842294584, disc_loss = 0.07716906493386397
Trained batch 507 in epoch 6, gen_loss = 0.8332916036482871, disc_loss = 0.07711472633060097
Trained batch 508 in epoch 6, gen_loss = 0.8329577092922975, disc_loss = 0.07717812879007376
Trained batch 509 in epoch 6, gen_loss = 0.8332099358825122, disc_loss = 0.0770911346774037
Trained batch 510 in epoch 6, gen_loss = 0.833079162934055, disc_loss = 0.07721706259806153
Trained batch 511 in epoch 6, gen_loss = 0.8327649258426391, disc_loss = 0.07717932432751695
Trained batch 512 in epoch 6, gen_loss = 0.832612568349169, disc_loss = 0.07712625803110021
Trained batch 513 in epoch 6, gen_loss = 0.8325402214253459, disc_loss = 0.07722521700320135
Trained batch 514 in epoch 6, gen_loss = 0.832670001555415, disc_loss = 0.077186716132734
Trained batch 515 in epoch 6, gen_loss = 0.8321356712732204, disc_loss = 0.07723927550747009
Trained batch 516 in epoch 6, gen_loss = 0.8318182189067973, disc_loss = 0.0773134878143034
Trained batch 517 in epoch 6, gen_loss = 0.8319721627534586, disc_loss = 0.07721048744726193
Trained batch 518 in epoch 6, gen_loss = 0.8325804387558402, disc_loss = 0.07724706037777525
Trained batch 519 in epoch 6, gen_loss = 0.8325106513614838, disc_loss = 0.07717050409410149
Trained batch 520 in epoch 6, gen_loss = 0.8331383844826821, disc_loss = 0.07708189837212698
Trained batch 521 in epoch 6, gen_loss = 0.832719736001044, disc_loss = 0.07707302010229207
Trained batch 522 in epoch 6, gen_loss = 0.8325541530580867, disc_loss = 0.0773269462935185
Trained batch 523 in epoch 6, gen_loss = 0.8330140580771533, disc_loss = 0.0772386651702993
Trained batch 524 in epoch 6, gen_loss = 0.8325248662063054, disc_loss = 0.07740635735825414
Trained batch 525 in epoch 6, gen_loss = 0.8324636948992544, disc_loss = 0.07733833642690638
Trained batch 526 in epoch 6, gen_loss = 0.8326977645762731, disc_loss = 0.07731508395936786
Trained batch 527 in epoch 6, gen_loss = 0.8323267763198325, disc_loss = 0.07727228733181785
Trained batch 528 in epoch 6, gen_loss = 0.8320539261871114, disc_loss = 0.07722326457000465
Trained batch 529 in epoch 6, gen_loss = 0.8318359482400822, disc_loss = 0.07718851681763553
Trained batch 530 in epoch 6, gen_loss = 0.831776494079615, disc_loss = 0.07715986991255577
Trained batch 531 in epoch 6, gen_loss = 0.832098891804541, disc_loss = 0.07704975789489883
Trained batch 532 in epoch 6, gen_loss = 0.83192959472565, disc_loss = 0.07704365399000401
Trained batch 533 in epoch 6, gen_loss = 0.8319405878192923, disc_loss = 0.07696997369587254
Trained batch 534 in epoch 6, gen_loss = 0.8320272781581523, disc_loss = 0.07695722463845371
Trained batch 535 in epoch 6, gen_loss = 0.8318728924131216, disc_loss = 0.07684270560623271
Trained batch 536 in epoch 6, gen_loss = 0.8318361032275514, disc_loss = 0.07674711705939896
Trained batch 537 in epoch 6, gen_loss = 0.8319842941145028, disc_loss = 0.07664753796643539
Trained batch 538 in epoch 6, gen_loss = 0.8320232591624604, disc_loss = 0.07670863422846805
Trained batch 539 in epoch 6, gen_loss = 0.831878272637173, disc_loss = 0.07669934409118637
Trained batch 540 in epoch 6, gen_loss = 0.8325415891001273, disc_loss = 0.07668584167385774
Trained batch 541 in epoch 6, gen_loss = 0.8323551635790575, disc_loss = 0.07659780750106127
Trained batch 542 in epoch 6, gen_loss = 0.8324303365214754, disc_loss = 0.076519924583013
Trained batch 543 in epoch 6, gen_loss = 0.8326481584569111, disc_loss = 0.07640139483127688
Trained batch 544 in epoch 6, gen_loss = 0.8326471164139039, disc_loss = 0.0762968709658182
Trained batch 545 in epoch 6, gen_loss = 0.8328148870568572, disc_loss = 0.07618288450018117
Trained batch 546 in epoch 6, gen_loss = 0.8331850960551058, disc_loss = 0.07611653215372748
Trained batch 547 in epoch 6, gen_loss = 0.8334218126035084, disc_loss = 0.07602592839954597
Trained batch 548 in epoch 6, gen_loss = 0.8334294780681694, disc_loss = 0.07592099445799064
Trained batch 549 in epoch 6, gen_loss = 0.8331067192012613, disc_loss = 0.07593539104712281
Trained batch 550 in epoch 6, gen_loss = 0.8334963198906713, disc_loss = 0.0758874463830177
Trained batch 551 in epoch 6, gen_loss = 0.8337465916098892, disc_loss = 0.07582434559193696
Trained batch 552 in epoch 6, gen_loss = 0.8333236992790298, disc_loss = 0.07586660916002545
Trained batch 553 in epoch 6, gen_loss = 0.8334725196288381, disc_loss = 0.07576421735176164
Trained batch 554 in epoch 6, gen_loss = 0.8334800370641657, disc_loss = 0.07574626056494208
Trained batch 555 in epoch 6, gen_loss = 0.8332574666082431, disc_loss = 0.07591245489081086
Trained batch 556 in epoch 6, gen_loss = 0.8330235846701816, disc_loss = 0.07596321205509897
Trained batch 557 in epoch 6, gen_loss = 0.833222922298216, disc_loss = 0.07585152878516144
Trained batch 558 in epoch 6, gen_loss = 0.833048989766399, disc_loss = 0.07586102546500925
Trained batch 559 in epoch 6, gen_loss = 0.8328961277114494, disc_loss = 0.07579630688165448
Trained batch 560 in epoch 6, gen_loss = 0.8330954998041007, disc_loss = 0.0757277372347958
Trained batch 561 in epoch 6, gen_loss = 0.8332088233843393, disc_loss = 0.07561478606554484
Trained batch 562 in epoch 6, gen_loss = 0.8329695740029824, disc_loss = 0.07559182619771938
Trained batch 563 in epoch 6, gen_loss = 0.8334925913958685, disc_loss = 0.07559760062004182
Trained batch 564 in epoch 6, gen_loss = 0.8330887770758266, disc_loss = 0.07568134369279167
Trained batch 565 in epoch 6, gen_loss = 0.8328796591965133, disc_loss = 0.07559718809488752
Trained batch 566 in epoch 6, gen_loss = 0.8337364142639087, disc_loss = 0.07584429750912142
Trained batch 567 in epoch 6, gen_loss = 0.8332497782375611, disc_loss = 0.07587544312274319
Trained batch 568 in epoch 6, gen_loss = 0.833162312086521, disc_loss = 0.07581826489785382
Trained batch 569 in epoch 6, gen_loss = 0.8330148073142035, disc_loss = 0.0758288547053541
Trained batch 570 in epoch 6, gen_loss = 0.8331642338252527, disc_loss = 0.07589492129223933
Trained batch 571 in epoch 6, gen_loss = 0.8327789124804776, disc_loss = 0.07603312232140842
Trained batch 572 in epoch 6, gen_loss = 0.8334734832533159, disc_loss = 0.07599693831108367
Trained batch 573 in epoch 6, gen_loss = 0.8337326784478662, disc_loss = 0.07590418001507061
Trained batch 574 in epoch 6, gen_loss = 0.8335040819644928, disc_loss = 0.07583318707249735
Trained batch 575 in epoch 6, gen_loss = 0.8333974189331962, disc_loss = 0.07587129049190683
Trained batch 576 in epoch 6, gen_loss = 0.8332055689867076, disc_loss = 0.07586912079464056
Trained batch 577 in epoch 6, gen_loss = 0.8335958494962705, disc_loss = 0.07602639534513894
Trained batch 578 in epoch 6, gen_loss = 0.8332064426109993, disc_loss = 0.07610288858960587
Trained batch 579 in epoch 6, gen_loss = 0.8333432060377352, disc_loss = 0.07614203561257957
Trained batch 580 in epoch 6, gen_loss = 0.8328648190592735, disc_loss = 0.07620111281747918
Trained batch 581 in epoch 6, gen_loss = 0.8328587526001062, disc_loss = 0.07625990078858134
Trained batch 582 in epoch 6, gen_loss = 0.8331716527354043, disc_loss = 0.0762060025393784
Trained batch 583 in epoch 6, gen_loss = 0.8328308714681292, disc_loss = 0.07626638700069273
Trained batch 584 in epoch 6, gen_loss = 0.8331020671587724, disc_loss = 0.07617098354280759
Trained batch 585 in epoch 6, gen_loss = 0.8333189138068274, disc_loss = 0.07611217435748148
Trained batch 586 in epoch 6, gen_loss = 0.8334230404391606, disc_loss = 0.0760294599966281
Trained batch 587 in epoch 6, gen_loss = 0.833523631957518, disc_loss = 0.0759930167439058
Trained batch 588 in epoch 6, gen_loss = 0.8335664081553247, disc_loss = 0.07590640522381496
Trained batch 589 in epoch 6, gen_loss = 0.8334660963991941, disc_loss = 0.07581594042574703
Trained batch 590 in epoch 6, gen_loss = 0.833096638296663, disc_loss = 0.07588711580617728
Trained batch 591 in epoch 6, gen_loss = 0.8339376751132108, disc_loss = 0.07604739148440343
Trained batch 592 in epoch 6, gen_loss = 0.8339391859848222, disc_loss = 0.07597841827346492
Trained batch 593 in epoch 6, gen_loss = 0.8337700426678867, disc_loss = 0.07599347331702258
Trained batch 594 in epoch 6, gen_loss = 0.8333332758490779, disc_loss = 0.07608719454186053
Trained batch 595 in epoch 6, gen_loss = 0.833843284355314, disc_loss = 0.0761089064540254
Trained batch 596 in epoch 6, gen_loss = 0.8339017996536428, disc_loss = 0.07600898770350258
Trained batch 597 in epoch 6, gen_loss = 0.8345325329530997, disc_loss = 0.07594722065059188
Trained batch 598 in epoch 6, gen_loss = 0.8341922496813964, disc_loss = 0.07596984054607173
Trained batch 599 in epoch 6, gen_loss = 0.8346750843028228, disc_loss = 0.0759146936594819
Trained batch 600 in epoch 6, gen_loss = 0.8346426359528115, disc_loss = 0.07580735792596507
Trained batch 601 in epoch 6, gen_loss = 0.8343680079692226, disc_loss = 0.07576255620676912
Trained batch 602 in epoch 6, gen_loss = 0.8348768693001116, disc_loss = 0.075680501953657
Trained batch 603 in epoch 6, gen_loss = 0.8350744711740917, disc_loss = 0.07559186525470177
Trained batch 604 in epoch 6, gen_loss = 0.8348343550173705, disc_loss = 0.07560011949544111
Trained batch 605 in epoch 6, gen_loss = 0.8346731503902882, disc_loss = 0.07553283998699668
Trained batch 606 in epoch 6, gen_loss = 0.8345011235559988, disc_loss = 0.07546310936894016
Trained batch 607 in epoch 6, gen_loss = 0.8352559534832835, disc_loss = 0.07542912782120861
Trained batch 608 in epoch 6, gen_loss = 0.835194592650105, disc_loss = 0.07538548693648113
Trained batch 609 in epoch 6, gen_loss = 0.835161951965973, disc_loss = 0.07548192218556755
Trained batch 610 in epoch 6, gen_loss = 0.8346399969730752, disc_loss = 0.0756143156603686
Trained batch 611 in epoch 6, gen_loss = 0.8343542799158813, disc_loss = 0.07563737297150629
Trained batch 612 in epoch 6, gen_loss = 0.8351171691985543, disc_loss = 0.07568132602055154
Trained batch 613 in epoch 6, gen_loss = 0.8354491213342654, disc_loss = 0.0756448238833234
Trained batch 614 in epoch 6, gen_loss = 0.8351423521836598, disc_loss = 0.07567001797440576
Trained batch 615 in epoch 6, gen_loss = 0.8348962338036531, disc_loss = 0.07572899776353657
Trained batch 616 in epoch 6, gen_loss = 0.8355151160319775, disc_loss = 0.07587788564966602
Trained batch 617 in epoch 6, gen_loss = 0.8351612914245106, disc_loss = 0.07592425846817231
Trained batch 618 in epoch 6, gen_loss = 0.8356076595952707, disc_loss = 0.07588493972655644
Trained batch 619 in epoch 6, gen_loss = 0.8355539966494806, disc_loss = 0.07579607691375478
Trained batch 620 in epoch 6, gen_loss = 0.8355916309951776, disc_loss = 0.07570516423062809
Trained batch 621 in epoch 6, gen_loss = 0.8358311667990455, disc_loss = 0.07559990282155502
Trained batch 622 in epoch 6, gen_loss = 0.8356159042871975, disc_loss = 0.0755515146169387
Trained batch 623 in epoch 6, gen_loss = 0.8356991992451441, disc_loss = 0.07547220579670885
Trained batch 624 in epoch 6, gen_loss = 0.8356404824733734, disc_loss = 0.07540756362974643
Trained batch 625 in epoch 6, gen_loss = 0.8355844829695674, disc_loss = 0.0753196006515822
Trained batch 626 in epoch 6, gen_loss = 0.835547498871455, disc_loss = 0.07525250045924285
Trained batch 627 in epoch 6, gen_loss = 0.8355626420705182, disc_loss = 0.07516908032855221
Trained batch 628 in epoch 6, gen_loss = 0.8359305186283039, disc_loss = 0.07508310980336749
Trained batch 629 in epoch 6, gen_loss = 0.8356868929806209, disc_loss = 0.07507779386840642
Trained batch 630 in epoch 6, gen_loss = 0.8362771533842888, disc_loss = 0.07516158875461709
Trained batch 631 in epoch 6, gen_loss = 0.8359980988257294, disc_loss = 0.07522198229238297
Trained batch 632 in epoch 6, gen_loss = 0.8359608974596147, disc_loss = 0.07523243678042203
Trained batch 633 in epoch 6, gen_loss = 0.8355812940405747, disc_loss = 0.075309774797257
Trained batch 634 in epoch 6, gen_loss = 0.8356522213286303, disc_loss = 0.07526149879114365
Trained batch 635 in epoch 6, gen_loss = 0.8354271379000736, disc_loss = 0.07524045731040573
Trained batch 636 in epoch 6, gen_loss = 0.8356256681952035, disc_loss = 0.07515190500514567
Trained batch 637 in epoch 6, gen_loss = 0.8358390580243825, disc_loss = 0.07509906706473203
Trained batch 638 in epoch 6, gen_loss = 0.8359854802932352, disc_loss = 0.07500181494627574
Trained batch 639 in epoch 6, gen_loss = 0.8359152957331389, disc_loss = 0.07496658811578527
Trained batch 640 in epoch 6, gen_loss = 0.8357498679722714, disc_loss = 0.07492027448580343
Trained batch 641 in epoch 6, gen_loss = 0.8361129594090572, disc_loss = 0.07496777625400515
Trained batch 642 in epoch 6, gen_loss = 0.8363263308074945, disc_loss = 0.07488962728675008
Trained batch 643 in epoch 6, gen_loss = 0.8361424916186688, disc_loss = 0.07487616138474912
Trained batch 644 in epoch 6, gen_loss = 0.8363228363122127, disc_loss = 0.07491161504457164
Trained batch 645 in epoch 6, gen_loss = 0.8363730091336342, disc_loss = 0.0749129484819923
Trained batch 646 in epoch 6, gen_loss = 0.8364850448032803, disc_loss = 0.07484505043711968
Trained batch 647 in epoch 6, gen_loss = 0.8365698713855243, disc_loss = 0.07477924531544156
Trained batch 648 in epoch 6, gen_loss = 0.8362142783008482, disc_loss = 0.07485240512170208
Trained batch 649 in epoch 6, gen_loss = 0.8367238753117048, disc_loss = 0.07478584292129828
Trained batch 650 in epoch 6, gen_loss = 0.8367585181365914, disc_loss = 0.07471875769991754
Trained batch 651 in epoch 6, gen_loss = 0.8369821056357922, disc_loss = 0.07461800608795388
Trained batch 652 in epoch 6, gen_loss = 0.8368723663126345, disc_loss = 0.07460007979427599
Trained batch 653 in epoch 6, gen_loss = 0.8366891353046493, disc_loss = 0.07456663567344986
Trained batch 654 in epoch 6, gen_loss = 0.8368487071899967, disc_loss = 0.07449893894256981
Trained batch 655 in epoch 6, gen_loss = 0.8366197893259729, disc_loss = 0.07444778528552866
Trained batch 656 in epoch 6, gen_loss = 0.836890900198546, disc_loss = 0.07434640271104362
Trained batch 657 in epoch 6, gen_loss = 0.8372054685665844, disc_loss = 0.07425797961958001
Trained batch 658 in epoch 6, gen_loss = 0.837476086589382, disc_loss = 0.074165890981162
Trained batch 659 in epoch 6, gen_loss = 0.837309643490748, disc_loss = 0.07420209995188722
Trained batch 660 in epoch 6, gen_loss = 0.8372148776288834, disc_loss = 0.0742273667387653
Trained batch 661 in epoch 6, gen_loss = 0.8371142524876983, disc_loss = 0.0741528026278488
Trained batch 662 in epoch 6, gen_loss = 0.8373494241302369, disc_loss = 0.07406573092107005
Trained batch 663 in epoch 6, gen_loss = 0.8375937050455305, disc_loss = 0.07409841068094619
Trained batch 664 in epoch 6, gen_loss = 0.8373878074319739, disc_loss = 0.07419147441177663
Trained batch 665 in epoch 6, gen_loss = 0.8371145972707966, disc_loss = 0.07420130818103393
Trained batch 666 in epoch 6, gen_loss = 0.8375394693289561, disc_loss = 0.07412297580659255
Trained batch 667 in epoch 6, gen_loss = 0.8372612090078656, disc_loss = 0.07408441227726906
Trained batch 668 in epoch 6, gen_loss = 0.8372899383440146, disc_loss = 0.07407170279516723
Trained batch 669 in epoch 6, gen_loss = 0.837284620795677, disc_loss = 0.0740472437772177
Trained batch 670 in epoch 6, gen_loss = 0.8375364259085251, disc_loss = 0.07395581937021674
Trained batch 671 in epoch 6, gen_loss = 0.837236384328987, disc_loss = 0.07396764594679033
Trained batch 672 in epoch 6, gen_loss = 0.8372782544519359, disc_loss = 0.07397116692307755
Trained batch 673 in epoch 6, gen_loss = 0.8371163959053928, disc_loss = 0.07397882788903591
Trained batch 674 in epoch 6, gen_loss = 0.8374273125772123, disc_loss = 0.07396626212392692
Trained batch 675 in epoch 6, gen_loss = 0.8377779163640632, disc_loss = 0.07388900968069817
Trained batch 676 in epoch 6, gen_loss = 0.8377462301948045, disc_loss = 0.07386304392854916
Trained batch 677 in epoch 6, gen_loss = 0.837925300177923, disc_loss = 0.07379108966413368
Trained batch 678 in epoch 6, gen_loss = 0.8382944179827756, disc_loss = 0.07374198924179501
Trained batch 679 in epoch 6, gen_loss = 0.8384808035896105, disc_loss = 0.07366849689278751
Trained batch 680 in epoch 6, gen_loss = 0.8384823740053807, disc_loss = 0.07360043502364871
Trained batch 681 in epoch 6, gen_loss = 0.838366904260476, disc_loss = 0.07354437120537385
Trained batch 682 in epoch 6, gen_loss = 0.8383730481955527, disc_loss = 0.07355064949863434
Trained batch 683 in epoch 6, gen_loss = 0.8385180102889997, disc_loss = 0.07346737369682574
Trained batch 684 in epoch 6, gen_loss = 0.8385028881313157, disc_loss = 0.07343759437900607
Trained batch 685 in epoch 6, gen_loss = 0.8386409269216805, disc_loss = 0.07336745036049114
Trained batch 686 in epoch 6, gen_loss = 0.8385802824511105, disc_loss = 0.07334004748840389
Trained batch 687 in epoch 6, gen_loss = 0.8387376104243273, disc_loss = 0.0732834938558923
Trained batch 688 in epoch 6, gen_loss = 0.8386499685801685, disc_loss = 0.0732488186154055
Trained batch 689 in epoch 6, gen_loss = 0.8385217972855638, disc_loss = 0.0732136790100755
Trained batch 690 in epoch 6, gen_loss = 0.8392133763229795, disc_loss = 0.07325868543733434
Trained batch 691 in epoch 6, gen_loss = 0.838852230567119, disc_loss = 0.07323416818950777
Trained batch 692 in epoch 6, gen_loss = 0.8390223810081014, disc_loss = 0.07315260493485486
Trained batch 693 in epoch 6, gen_loss = 0.8390886868197224, disc_loss = 0.07308460531423475
Trained batch 694 in epoch 6, gen_loss = 0.8390349013771085, disc_loss = 0.07310434115527989
Trained batch 695 in epoch 6, gen_loss = 0.8389673555462525, disc_loss = 0.07307023911378292
Trained batch 696 in epoch 6, gen_loss = 0.8388176984133645, disc_loss = 0.07302079753685674
Trained batch 697 in epoch 6, gen_loss = 0.839136612150594, disc_loss = 0.07307475397395327
Trained batch 698 in epoch 6, gen_loss = 0.8389671328497547, disc_loss = 0.07302190168748726
Trained batch 699 in epoch 6, gen_loss = 0.8387499445251057, disc_loss = 0.07308659987125013
Trained batch 700 in epoch 6, gen_loss = 0.8388325990776873, disc_loss = 0.07322409741989684
Trained batch 701 in epoch 6, gen_loss = 0.8389225360589829, disc_loss = 0.07314105522805597
Trained batch 702 in epoch 6, gen_loss = 0.8388329761720145, disc_loss = 0.07308889316477062
Trained batch 703 in epoch 6, gen_loss = 0.8389463977126236, disc_loss = 0.07305457720675887
Trained batch 704 in epoch 6, gen_loss = 0.8389421299416968, disc_loss = 0.0730049762835211
Trained batch 705 in epoch 6, gen_loss = 0.8387411750494251, disc_loss = 0.07299914933799136
Trained batch 706 in epoch 6, gen_loss = 0.8391259291974624, disc_loss = 0.07308059179288622
Trained batch 707 in epoch 6, gen_loss = 0.8391776981074258, disc_loss = 0.07302292307844059
Trained batch 708 in epoch 6, gen_loss = 0.8389392584688404, disc_loss = 0.07307274626864826
Trained batch 709 in epoch 6, gen_loss = 0.8394644338899935, disc_loss = 0.07300962126407196
Trained batch 710 in epoch 6, gen_loss = 0.8392147022376751, disc_loss = 0.07302339890193713
Trained batch 711 in epoch 6, gen_loss = 0.8393069895382008, disc_loss = 0.07303279342804773
Trained batch 712 in epoch 6, gen_loss = 0.8393379713592823, disc_loss = 0.07297228818150632
Trained batch 713 in epoch 6, gen_loss = 0.8391142850246082, disc_loss = 0.07293306395061919
Trained batch 714 in epoch 6, gen_loss = 0.8392201637471473, disc_loss = 0.07287154273370972
Trained batch 715 in epoch 6, gen_loss = 0.8390930536822234, disc_loss = 0.07282443216211011
Trained batch 716 in epoch 6, gen_loss = 0.8389075470353103, disc_loss = 0.0728050173900637
Trained batch 717 in epoch 6, gen_loss = 0.8397440259088048, disc_loss = 0.07278693307704788
Trained batch 718 in epoch 6, gen_loss = 0.8394818507829197, disc_loss = 0.07279801505626865
Trained batch 719 in epoch 6, gen_loss = 0.8397598579112027, disc_loss = 0.0727734765671711
Trained batch 720 in epoch 6, gen_loss = 0.8398461678735757, disc_loss = 0.072693559281714
Trained batch 721 in epoch 6, gen_loss = 0.8397653067788919, disc_loss = 0.07265428846464635
Trained batch 722 in epoch 6, gen_loss = 0.8395883169329182, disc_loss = 0.07259618122140937
Trained batch 723 in epoch 6, gen_loss = 0.840107030919573, disc_loss = 0.07287369918680199
Trained batch 724 in epoch 6, gen_loss = 0.8402040541172028, disc_loss = 0.07280176327017875
Trained batch 725 in epoch 6, gen_loss = 0.8400678411741888, disc_loss = 0.07276476529547457
Trained batch 726 in epoch 6, gen_loss = 0.8399492229605311, disc_loss = 0.07274530752032914
Trained batch 727 in epoch 6, gen_loss = 0.8402919298918038, disc_loss = 0.07286162821673225
Trained batch 728 in epoch 6, gen_loss = 0.8399916250764587, disc_loss = 0.07295493750778041
Trained batch 729 in epoch 6, gen_loss = 0.8401162078527555, disc_loss = 0.07288666822092786
Trained batch 730 in epoch 6, gen_loss = 0.8404159702044668, disc_loss = 0.07304047202378022
Trained batch 731 in epoch 6, gen_loss = 0.8402433650659733, disc_loss = 0.0729838003508767
Trained batch 732 in epoch 6, gen_loss = 0.8399019362900462, disc_loss = 0.07303949859562504
Trained batch 733 in epoch 6, gen_loss = 0.8400378225203756, disc_loss = 0.07298378151909979
Trained batch 734 in epoch 6, gen_loss = 0.8400640595121448, disc_loss = 0.07294437928239302
Trained batch 735 in epoch 6, gen_loss = 0.8401336156074768, disc_loss = 0.07292653973411728
Trained batch 736 in epoch 6, gen_loss = 0.8396636032103845, disc_loss = 0.07314582133546896
Trained batch 737 in epoch 6, gen_loss = 0.8399627826966567, disc_loss = 0.0733915661779664
Trained batch 738 in epoch 6, gen_loss = 0.8396651056445177, disc_loss = 0.07346553740460875
Trained batch 739 in epoch 6, gen_loss = 0.8396303941671913, disc_loss = 0.07349491734435228
Trained batch 740 in epoch 6, gen_loss = 0.8395073579953589, disc_loss = 0.07345534197347649
Trained batch 741 in epoch 6, gen_loss = 0.8394569901202246, disc_loss = 0.0733915017302728
Trained batch 742 in epoch 6, gen_loss = 0.8392386014897922, disc_loss = 0.0733873083808962
Trained batch 743 in epoch 6, gen_loss = 0.8394578182969683, disc_loss = 0.07333483378357825
Trained batch 744 in epoch 6, gen_loss = 0.8395373944068115, disc_loss = 0.07329465263466907
Trained batch 745 in epoch 6, gen_loss = 0.8393216636081803, disc_loss = 0.07335353060063704
Trained batch 746 in epoch 6, gen_loss = 0.8395199886207759, disc_loss = 0.07340763396193264
Trained batch 747 in epoch 6, gen_loss = 0.8394226797203966, disc_loss = 0.07336939686167249
Trained batch 748 in epoch 6, gen_loss = 0.8391419098039813, disc_loss = 0.07336809312196098
Trained batch 749 in epoch 6, gen_loss = 0.8394670954942703, disc_loss = 0.07338709309821327
Trained batch 750 in epoch 6, gen_loss = 0.839037570710506, disc_loss = 0.07347660773767334
Trained batch 751 in epoch 6, gen_loss = 0.8391986383481863, disc_loss = 0.0734823470888164
Trained batch 752 in epoch 6, gen_loss = 0.8388865303945732, disc_loss = 0.07347225465231723
Trained batch 753 in epoch 6, gen_loss = 0.838785879610388, disc_loss = 0.0734810417021479
Trained batch 754 in epoch 6, gen_loss = 0.83854434612571, disc_loss = 0.07345768823257542
Trained batch 755 in epoch 6, gen_loss = 0.8385807149230488, disc_loss = 0.0734059876434643
Trained batch 756 in epoch 6, gen_loss = 0.8387124016782567, disc_loss = 0.0734583175110002
Trained batch 757 in epoch 6, gen_loss = 0.8384773376985087, disc_loss = 0.07345454902621601
Trained batch 758 in epoch 6, gen_loss = 0.8382391695998246, disc_loss = 0.07344947141449167
Trained batch 759 in epoch 6, gen_loss = 0.8382989022684725, disc_loss = 0.07343920806153237
Trained batch 760 in epoch 6, gen_loss = 0.838315152659836, disc_loss = 0.07342621882454677
Trained batch 761 in epoch 6, gen_loss = 0.8380320395619225, disc_loss = 0.0735405035710495
Trained batch 762 in epoch 6, gen_loss = 0.8383432913810835, disc_loss = 0.07354634488184557
Trained batch 763 in epoch 6, gen_loss = 0.8380677467943486, disc_loss = 0.0736558663558839
Trained batch 764 in epoch 6, gen_loss = 0.8381031289209727, disc_loss = 0.07376120980293338
Trained batch 765 in epoch 6, gen_loss = 0.837995684061287, disc_loss = 0.07374299851224293
Trained batch 766 in epoch 6, gen_loss = 0.8379308319076254, disc_loss = 0.07374066055777836
Trained batch 767 in epoch 6, gen_loss = 0.8379901583539322, disc_loss = 0.07377267430638312
Trained batch 768 in epoch 6, gen_loss = 0.8379611812037826, disc_loss = 0.07373041887398232
Trained batch 769 in epoch 6, gen_loss = 0.8382818514263475, disc_loss = 0.07365369017465742
Trained batch 770 in epoch 6, gen_loss = 0.8380444975601251, disc_loss = 0.07359276746850263
Trained batch 771 in epoch 6, gen_loss = 0.8381247379542015, disc_loss = 0.07352680580357543
Trained batch 772 in epoch 6, gen_loss = 0.8382301955528432, disc_loss = 0.073602977563009
Trained batch 773 in epoch 6, gen_loss = 0.837777628570564, disc_loss = 0.07381404761720728
Trained batch 774 in epoch 6, gen_loss = 0.8377878205622397, disc_loss = 0.07375860286936645
Trained batch 775 in epoch 6, gen_loss = 0.8385362145442938, disc_loss = 0.07385913109450035
Trained batch 776 in epoch 6, gen_loss = 0.8383570504081141, disc_loss = 0.07385368797295228
Trained batch 777 in epoch 6, gen_loss = 0.838100408948479, disc_loss = 0.0738744855963728
Trained batch 778 in epoch 6, gen_loss = 0.8378914568252833, disc_loss = 0.07383927866094417
Trained batch 779 in epoch 6, gen_loss = 0.8375748740938994, disc_loss = 0.07381684030883778
Trained batch 780 in epoch 6, gen_loss = 0.8377778909804726, disc_loss = 0.07396681991819573
Trained batch 781 in epoch 6, gen_loss = 0.837671613868545, disc_loss = 0.07394915539175843
Trained batch 782 in epoch 6, gen_loss = 0.8376064501122344, disc_loss = 0.07391011841133674
Trained batch 783 in epoch 6, gen_loss = 0.8375879409437885, disc_loss = 0.07386659896975308
Trained batch 784 in epoch 6, gen_loss = 0.8380068949453391, disc_loss = 0.07403100085130353
Trained batch 785 in epoch 6, gen_loss = 0.8377571800965389, disc_loss = 0.07407006499672703
Trained batch 786 in epoch 6, gen_loss = 0.8375733879121467, disc_loss = 0.07411882540345988
Trained batch 787 in epoch 6, gen_loss = 0.8373357929327161, disc_loss = 0.07413675149708873
Trained batch 788 in epoch 6, gen_loss = 0.8375960690062612, disc_loss = 0.07430329081851456
Trained batch 789 in epoch 6, gen_loss = 0.8373908558601065, disc_loss = 0.0743610056671255
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.6033110022544861, disc_loss = 0.2755374610424042
Trained batch 1 in epoch 7, gen_loss = 0.930751234292984, disc_loss = 0.2564510703086853
Trained batch 2 in epoch 7, gen_loss = 0.9015915393829346, disc_loss = 0.1931285709142685
Trained batch 3 in epoch 7, gen_loss = 0.8154897540807724, disc_loss = 0.18879197165369987
Trained batch 4 in epoch 7, gen_loss = 0.8082079887390137, disc_loss = 0.1728219911456108
Trained batch 5 in epoch 7, gen_loss = 0.7994171182314554, disc_loss = 0.1570336806277434
Trained batch 6 in epoch 7, gen_loss = 0.7834826878138951, disc_loss = 0.1495952531695366
Trained batch 7 in epoch 7, gen_loss = 0.7779963910579681, disc_loss = 0.14255200792104006
Trained batch 8 in epoch 7, gen_loss = 0.7886041800181071, disc_loss = 0.1309364934762319
Trained batch 9 in epoch 7, gen_loss = 0.7707831740379334, disc_loss = 0.1296992003917694
Trained batch 10 in epoch 7, gen_loss = 0.7921362248334017, disc_loss = 0.12131979011676529
Trained batch 11 in epoch 7, gen_loss = 0.8154691755771637, disc_loss = 0.11242154597615202
Trained batch 12 in epoch 7, gen_loss = 0.8242305929844196, disc_loss = 0.10518483717281085
Trained batch 13 in epoch 7, gen_loss = 0.8256837981087821, disc_loss = 0.09957032624099936
Trained batch 14 in epoch 7, gen_loss = 0.8180598775545757, disc_loss = 0.09751938258608182
Trained batch 15 in epoch 7, gen_loss = 0.8195451200008392, disc_loss = 0.09334352042060345
Trained batch 16 in epoch 7, gen_loss = 0.827587415190304, disc_loss = 0.08950581598807783
Trained batch 17 in epoch 7, gen_loss = 0.8148821824126773, disc_loss = 0.09147778132723437
Trained batch 18 in epoch 7, gen_loss = 0.8207181692123413, disc_loss = 0.08925824788840193
Trained batch 19 in epoch 7, gen_loss = 0.8299676537513733, disc_loss = 0.08542488645762206
Trained batch 20 in epoch 7, gen_loss = 0.8414447761717296, disc_loss = 0.08186328207098302
Trained batch 21 in epoch 7, gen_loss = 0.8465794595805082, disc_loss = 0.07892029376869852
Trained batch 22 in epoch 7, gen_loss = 0.8401938054872595, disc_loss = 0.07881896311174268
Trained batch 23 in epoch 7, gen_loss = 0.8322719683249792, disc_loss = 0.07795601664111018
Trained batch 24 in epoch 7, gen_loss = 0.8498792600631714, disc_loss = 0.08553343251347542
Trained batch 25 in epoch 7, gen_loss = 0.8479203811058631, disc_loss = 0.08377493000947513
Trained batch 26 in epoch 7, gen_loss = 0.8420149132057473, disc_loss = 0.08216269383275951
Trained batch 27 in epoch 7, gen_loss = 0.8401713967323303, disc_loss = 0.08015651947685651
Trained batch 28 in epoch 7, gen_loss = 0.8374361786349066, disc_loss = 0.08019550761272168
Trained batch 29 in epoch 7, gen_loss = 0.8320198674996694, disc_loss = 0.07922711397210756
Trained batch 30 in epoch 7, gen_loss = 0.8422301027082628, disc_loss = 0.0784722785315206
Trained batch 31 in epoch 7, gen_loss = 0.8394371755421162, disc_loss = 0.07790175173431635
Trained batch 32 in epoch 7, gen_loss = 0.8342314868262319, disc_loss = 0.07848175208676945
Trained batch 33 in epoch 7, gen_loss = 0.835293792626437, disc_loss = 0.08054327373118962
Trained batch 34 in epoch 7, gen_loss = 0.8360890712056841, disc_loss = 0.07873820236751011
Trained batch 35 in epoch 7, gen_loss = 0.8366743673880895, disc_loss = 0.07745080803417498
Trained batch 36 in epoch 7, gen_loss = 0.8335360079198271, disc_loss = 0.07621786813880946
Trained batch 37 in epoch 7, gen_loss = 0.8340045464666266, disc_loss = 0.07572473987544838
Trained batch 38 in epoch 7, gen_loss = 0.8369785975187253, disc_loss = 0.07404053089423822
Trained batch 39 in epoch 7, gen_loss = 0.839326274394989, disc_loss = 0.07316001581493765
Trained batch 40 in epoch 7, gen_loss = 0.8339587769857267, disc_loss = 0.0731157816991937
Trained batch 41 in epoch 7, gen_loss = 0.8385958444504511, disc_loss = 0.0717076790918197
Trained batch 42 in epoch 7, gen_loss = 0.8437239014825155, disc_loss = 0.07101915694426658
Trained batch 43 in epoch 7, gen_loss = 0.8381073501977053, disc_loss = 0.07093977779996666
Trained batch 44 in epoch 7, gen_loss = 0.8347022612889607, disc_loss = 0.07165464878910117
Trained batch 45 in epoch 7, gen_loss = 0.847605288028717, disc_loss = 0.08245220703437277
Trained batch 46 in epoch 7, gen_loss = 0.8441801426258493, disc_loss = 0.08267936447357878
Trained batch 47 in epoch 7, gen_loss = 0.8403694964945316, disc_loss = 0.0828564272960648
Trained batch 48 in epoch 7, gen_loss = 0.8387229393939583, disc_loss = 0.08198960798279363
Trained batch 49 in epoch 7, gen_loss = 0.8347910940647125, disc_loss = 0.08197943229228258
Trained batch 50 in epoch 7, gen_loss = 0.8367088495516309, disc_loss = 0.08424812369048595
Trained batch 51 in epoch 7, gen_loss = 0.8319218525519738, disc_loss = 0.08436959269098364
Trained batch 52 in epoch 7, gen_loss = 0.8313347326134736, disc_loss = 0.08360426616415663
Trained batch 53 in epoch 7, gen_loss = 0.8332745057565195, disc_loss = 0.08651130463652036
Trained batch 54 in epoch 7, gen_loss = 0.8281343481757424, disc_loss = 0.08860102251849392
Trained batch 55 in epoch 7, gen_loss = 0.8265894619481904, disc_loss = 0.0893225867766887
Trained batch 56 in epoch 7, gen_loss = 0.8225788223116022, disc_loss = 0.09094677221748912
Trained batch 57 in epoch 7, gen_loss = 0.8221301970810726, disc_loss = 0.09108301942589982
Trained batch 58 in epoch 7, gen_loss = 0.8184686586008234, disc_loss = 0.0912888590246439
Trained batch 59 in epoch 7, gen_loss = 0.8140562027692795, disc_loss = 0.0922570399629573
Trained batch 60 in epoch 7, gen_loss = 0.815551115841162, disc_loss = 0.09170450541938914
Trained batch 61 in epoch 7, gen_loss = 0.8192572622529922, disc_loss = 0.09060789257167809
Trained batch 62 in epoch 7, gen_loss = 0.8185239585619124, disc_loss = 0.08999684154396019
Trained batch 63 in epoch 7, gen_loss = 0.818607079796493, disc_loss = 0.08897386936587282
Trained batch 64 in epoch 7, gen_loss = 0.8180880739138676, disc_loss = 0.08832981795645677
Trained batch 65 in epoch 7, gen_loss = 0.817165142658985, disc_loss = 0.08955926541239023
Trained batch 66 in epoch 7, gen_loss = 0.8158138456629284, disc_loss = 0.08889013720648502
Trained batch 67 in epoch 7, gen_loss = 0.8141588112887215, disc_loss = 0.08841705472920747
Trained batch 68 in epoch 7, gen_loss = 0.8143738499586133, disc_loss = 0.08767921534245429
Trained batch 69 in epoch 7, gen_loss = 0.8153230845928192, disc_loss = 0.08744295689144305
Trained batch 70 in epoch 7, gen_loss = 0.8147173918468852, disc_loss = 0.08675679420186601
Trained batch 71 in epoch 7, gen_loss = 0.8156043920252058, disc_loss = 0.0858546891508417
Trained batch 72 in epoch 7, gen_loss = 0.816756450150111, disc_loss = 0.08492820806903383
Trained batch 73 in epoch 7, gen_loss = 0.8166198214969119, disc_loss = 0.08433312464606117
Trained batch 74 in epoch 7, gen_loss = 0.8152347620328267, disc_loss = 0.08460669731100401
Trained batch 75 in epoch 7, gen_loss = 0.8196181474547637, disc_loss = 0.08568402198388388
Trained batch 76 in epoch 7, gen_loss = 0.818361704225664, disc_loss = 0.08510467705207986
Trained batch 77 in epoch 7, gen_loss = 0.8160771582371149, disc_loss = 0.08509294034387821
Trained batch 78 in epoch 7, gen_loss = 0.8167944527879546, disc_loss = 0.08544946617529361
Trained batch 79 in epoch 7, gen_loss = 0.8176964364945889, disc_loss = 0.08466429659165442
Trained batch 80 in epoch 7, gen_loss = 0.8193472336839747, disc_loss = 0.08387927717908665
Trained batch 81 in epoch 7, gen_loss = 0.8196133978483153, disc_loss = 0.08305948143597783
Trained batch 82 in epoch 7, gen_loss = 0.8201775414397917, disc_loss = 0.08314787369804928
Trained batch 83 in epoch 7, gen_loss = 0.8175576059591203, disc_loss = 0.08303327155521228
Trained batch 84 in epoch 7, gen_loss = 0.821742039568284, disc_loss = 0.08269621271859197
Trained batch 85 in epoch 7, gen_loss = 0.8208617547223734, disc_loss = 0.08204999187051557
Trained batch 86 in epoch 7, gen_loss = 0.8204458273690323, disc_loss = 0.08202840458473255
Trained batch 87 in epoch 7, gen_loss = 0.8175247033888643, disc_loss = 0.0822360586925325
Trained batch 88 in epoch 7, gen_loss = 0.8200869473178735, disc_loss = 0.08167422288672978
Trained batch 89 in epoch 7, gen_loss = 0.8181047300497691, disc_loss = 0.08207311069385873
Trained batch 90 in epoch 7, gen_loss = 0.8189388579064674, disc_loss = 0.08138238888356712
Trained batch 91 in epoch 7, gen_loss = 0.8183929635130841, disc_loss = 0.08116512522911248
Trained batch 92 in epoch 7, gen_loss = 0.8207273662731212, disc_loss = 0.08076883700265679
Trained batch 93 in epoch 7, gen_loss = 0.8245527592111142, disc_loss = 0.08062313885447826
Trained batch 94 in epoch 7, gen_loss = 0.8249818525816265, disc_loss = 0.08001412090502287
Trained batch 95 in epoch 7, gen_loss = 0.8227663437525431, disc_loss = 0.08036649102965991
Trained batch 96 in epoch 7, gen_loss = 0.8241476041754496, disc_loss = 0.0798876106585424
Trained batch 97 in epoch 7, gen_loss = 0.8257628898231351, disc_loss = 0.0792649602137354
Trained batch 98 in epoch 7, gen_loss = 0.8241593663138572, disc_loss = 0.08037297271493107
Trained batch 99 in epoch 7, gen_loss = 0.8232869356870651, disc_loss = 0.08018646648153663
Trained batch 100 in epoch 7, gen_loss = 0.8268959752403864, disc_loss = 0.07968522226530136
Trained batch 101 in epoch 7, gen_loss = 0.8291928972683701, disc_loss = 0.0793836137425958
Trained batch 102 in epoch 7, gen_loss = 0.8292479011618975, disc_loss = 0.07885124064186244
Trained batch 103 in epoch 7, gen_loss = 0.8279761414115245, disc_loss = 0.07880959401910122
Trained batch 104 in epoch 7, gen_loss = 0.8311744604791914, disc_loss = 0.07839338843311583
Trained batch 105 in epoch 7, gen_loss = 0.8302489209849879, disc_loss = 0.0780429130174079
Trained batch 106 in epoch 7, gen_loss = 0.8309455369120446, disc_loss = 0.07742009828929032
Trained batch 107 in epoch 7, gen_loss = 0.8327317221297158, disc_loss = 0.07754566680846943
Trained batch 108 in epoch 7, gen_loss = 0.8310364282459294, disc_loss = 0.07794640707108405
Trained batch 109 in epoch 7, gen_loss = 0.8315668198195371, disc_loss = 0.07767933612181381
Trained batch 110 in epoch 7, gen_loss = 0.8330989780726733, disc_loss = 0.07732184447750852
Trained batch 111 in epoch 7, gen_loss = 0.8339481167495251, disc_loss = 0.07709177618380636
Trained batch 112 in epoch 7, gen_loss = 0.8320984107203189, disc_loss = 0.0771405445823891
Trained batch 113 in epoch 7, gen_loss = 0.8308393123902773, disc_loss = 0.07680286507922829
Trained batch 114 in epoch 7, gen_loss = 0.8330052463904671, disc_loss = 0.07638781373591527
Trained batch 115 in epoch 7, gen_loss = 0.8333131994666725, disc_loss = 0.07641985477751186
Trained batch 116 in epoch 7, gen_loss = 0.8333007464042077, disc_loss = 0.07613124193735102
Trained batch 117 in epoch 7, gen_loss = 0.8305915907277899, disc_loss = 0.07674326291465658
Trained batch 118 in epoch 7, gen_loss = 0.831544424305443, disc_loss = 0.07628324986318079
Trained batch 119 in epoch 7, gen_loss = 0.8327077110608418, disc_loss = 0.07626678460898499
Trained batch 120 in epoch 7, gen_loss = 0.834700967654709, disc_loss = 0.07637844365551945
Trained batch 121 in epoch 7, gen_loss = 0.8335079892736966, disc_loss = 0.07600780629904055
Trained batch 122 in epoch 7, gen_loss = 0.8325857447414864, disc_loss = 0.07561278752074009
Trained batch 123 in epoch 7, gen_loss = 0.8301299521999974, disc_loss = 0.07691774862788377
Trained batch 124 in epoch 7, gen_loss = 0.8323959474563598, disc_loss = 0.07706478962302207
Trained batch 125 in epoch 7, gen_loss = 0.8318826849498446, disc_loss = 0.07672718773403811
Trained batch 126 in epoch 7, gen_loss = 0.8326343626487912, disc_loss = 0.07693390246099374
Trained batch 127 in epoch 7, gen_loss = 0.8308967826887965, disc_loss = 0.07718540154746734
Trained batch 128 in epoch 7, gen_loss = 0.8314991671909657, disc_loss = 0.07683310342967048
Trained batch 129 in epoch 7, gen_loss = 0.8303990478699024, disc_loss = 0.07777303345501423
Trained batch 130 in epoch 7, gen_loss = 0.829926643207783, disc_loss = 0.07749937281353783
Trained batch 131 in epoch 7, gen_loss = 0.829730922074029, disc_loss = 0.07711939824124177
Trained batch 132 in epoch 7, gen_loss = 0.8298133427935436, disc_loss = 0.0767973428382013
Trained batch 133 in epoch 7, gen_loss = 0.8304624099340012, disc_loss = 0.07665599343269619
Trained batch 134 in epoch 7, gen_loss = 0.8291672998004489, disc_loss = 0.0766017406626984
Trained batch 135 in epoch 7, gen_loss = 0.8307055979967117, disc_loss = 0.07689621387159123
Trained batch 136 in epoch 7, gen_loss = 0.8296280777367362, disc_loss = 0.0770120805632459
Trained batch 137 in epoch 7, gen_loss = 0.8279159846513168, disc_loss = 0.07734988716201506
Trained batch 138 in epoch 7, gen_loss = 0.8294907851184873, disc_loss = 0.07705599868254696
Trained batch 139 in epoch 7, gen_loss = 0.8314525135925838, disc_loss = 0.07694657210792814
Trained batch 140 in epoch 7, gen_loss = 0.829785239611957, disc_loss = 0.07680644483325329
Trained batch 141 in epoch 7, gen_loss = 0.8307085771795729, disc_loss = 0.07645582005014302
Trained batch 142 in epoch 7, gen_loss = 0.8320154280929298, disc_loss = 0.07609258756249934
Trained batch 143 in epoch 7, gen_loss = 0.8307852161427339, disc_loss = 0.07605838829961915
Trained batch 144 in epoch 7, gen_loss = 0.8293584761948422, disc_loss = 0.0758046967459136
Trained batch 145 in epoch 7, gen_loss = 0.8303433966963258, disc_loss = 0.07539478597575672
Trained batch 146 in epoch 7, gen_loss = 0.8310458124900351, disc_loss = 0.07510032393291693
Trained batch 147 in epoch 7, gen_loss = 0.8304197530488711, disc_loss = 0.07486416137701757
Trained batch 148 in epoch 7, gen_loss = 0.8299753661923761, disc_loss = 0.0748669322105062
Trained batch 149 in epoch 7, gen_loss = 0.8292044333616893, disc_loss = 0.07467639048894247
Trained batch 150 in epoch 7, gen_loss = 0.8306743431564988, disc_loss = 0.07426124954263107
Trained batch 151 in epoch 7, gen_loss = 0.8297811295641097, disc_loss = 0.07463201375580147
Trained batch 152 in epoch 7, gen_loss = 0.8313151111010633, disc_loss = 0.07525206707856234
Trained batch 153 in epoch 7, gen_loss = 0.8323280954515779, disc_loss = 0.0754242515215626
Trained batch 154 in epoch 7, gen_loss = 0.8309322107222772, disc_loss = 0.07609024874625668
Trained batch 155 in epoch 7, gen_loss = 0.8285102372368177, disc_loss = 0.07644397106308204
Trained batch 156 in epoch 7, gen_loss = 0.8313613744678011, disc_loss = 0.07752370454703167
Trained batch 157 in epoch 7, gen_loss = 0.8324486592525169, disc_loss = 0.0774010896824206
Trained batch 158 in epoch 7, gen_loss = 0.830090249859312, disc_loss = 0.0783462828763251
Trained batch 159 in epoch 7, gen_loss = 0.8299054197967053, disc_loss = 0.07833849920425565
Trained batch 160 in epoch 7, gen_loss = 0.8321090655297226, disc_loss = 0.07867963595882706
Trained batch 161 in epoch 7, gen_loss = 0.8323133161038528, disc_loss = 0.07849691644954829
Trained batch 162 in epoch 7, gen_loss = 0.8305595550069048, disc_loss = 0.07939298718344946
Trained batch 163 in epoch 7, gen_loss = 0.8309550147231032, disc_loss = 0.07919870001241201
Trained batch 164 in epoch 7, gen_loss = 0.8326090198574644, disc_loss = 0.07891522934942534
Trained batch 165 in epoch 7, gen_loss = 0.8329569790736738, disc_loss = 0.07856768738837486
Trained batch 166 in epoch 7, gen_loss = 0.8307921827553275, disc_loss = 0.078962046686493
Trained batch 167 in epoch 7, gen_loss = 0.8328976891934872, disc_loss = 0.07887813272619885
Trained batch 168 in epoch 7, gen_loss = 0.8335332494868329, disc_loss = 0.0786759519960577
Trained batch 169 in epoch 7, gen_loss = 0.8333594467710046, disc_loss = 0.07839910483316463
Trained batch 170 in epoch 7, gen_loss = 0.8331438994895645, disc_loss = 0.07811075349866647
Trained batch 171 in epoch 7, gen_loss = 0.832980528993662, disc_loss = 0.07793660857173246
Trained batch 172 in epoch 7, gen_loss = 0.8321104540645732, disc_loss = 0.07781029485079939
Trained batch 173 in epoch 7, gen_loss = 0.8304838896140285, disc_loss = 0.07835219917155203
Trained batch 174 in epoch 7, gen_loss = 0.8311771540982382, disc_loss = 0.07808656387031078
Trained batch 175 in epoch 7, gen_loss = 0.832741183144125, disc_loss = 0.07771501903401011
Trained batch 176 in epoch 7, gen_loss = 0.8327089122122964, disc_loss = 0.07752512100200026
Trained batch 177 in epoch 7, gen_loss = 0.8321721793225642, disc_loss = 0.07747548190207126
Trained batch 178 in epoch 7, gen_loss = 0.8326745311308174, disc_loss = 0.07744159349162319
Trained batch 179 in epoch 7, gen_loss = 0.8325490585631794, disc_loss = 0.0770835440657619
Trained batch 180 in epoch 7, gen_loss = 0.8320865971936705, disc_loss = 0.07691382061566601
Trained batch 181 in epoch 7, gen_loss = 0.8338790023392373, disc_loss = 0.07664270934925138
Trained batch 182 in epoch 7, gen_loss = 0.8347691735608982, disc_loss = 0.07649186954329737
Trained batch 183 in epoch 7, gen_loss = 0.8335800515892713, disc_loss = 0.07662651109326955
Trained batch 184 in epoch 7, gen_loss = 0.8344177067279815, disc_loss = 0.076836751446732
Trained batch 185 in epoch 7, gen_loss = 0.8334309489175837, disc_loss = 0.07675483164387525
Trained batch 186 in epoch 7, gen_loss = 0.832983959645511, disc_loss = 0.07647430876339661
Trained batch 187 in epoch 7, gen_loss = 0.8341428483737275, disc_loss = 0.07647429140621519
Trained batch 188 in epoch 7, gen_loss = 0.834122177311983, disc_loss = 0.07627149304207513
Trained batch 189 in epoch 7, gen_loss = 0.8328112324601725, disc_loss = 0.07655965050094221
Trained batch 190 in epoch 7, gen_loss = 0.833877725594955, disc_loss = 0.07649164868723504
Trained batch 191 in epoch 7, gen_loss = 0.8348171461063126, disc_loss = 0.07630955825152341
Trained batch 192 in epoch 7, gen_loss = 0.8357751689117807, disc_loss = 0.07598146821319131
Trained batch 193 in epoch 7, gen_loss = 0.8359221556444758, disc_loss = 0.07576657353525924
Trained batch 194 in epoch 7, gen_loss = 0.8360561671929482, disc_loss = 0.07550532539876607
Trained batch 195 in epoch 7, gen_loss = 0.8361886117835434, disc_loss = 0.07555956360218781
Trained batch 196 in epoch 7, gen_loss = 0.834798820581533, disc_loss = 0.07607663476716746
Trained batch 197 in epoch 7, gen_loss = 0.8373762879407767, disc_loss = 0.07647707445942091
Trained batch 198 in epoch 7, gen_loss = 0.8375265560857016, disc_loss = 0.07615449210750548
Trained batch 199 in epoch 7, gen_loss = 0.8374960087239742, disc_loss = 0.07583896400872618
Trained batch 200 in epoch 7, gen_loss = 0.8373151428960449, disc_loss = 0.07556421185996551
Trained batch 201 in epoch 7, gen_loss = 0.8363667562751487, disc_loss = 0.07554894105282307
Trained batch 202 in epoch 7, gen_loss = 0.8367759460592504, disc_loss = 0.07580666921647458
Trained batch 203 in epoch 7, gen_loss = 0.8350760340690613, disc_loss = 0.07605385110603974
Trained batch 204 in epoch 7, gen_loss = 0.8338049336177547, disc_loss = 0.07635914118642487
Trained batch 205 in epoch 7, gen_loss = 0.8344902818642773, disc_loss = 0.07662188531650067
Trained batch 206 in epoch 7, gen_loss = 0.8351569596120125, disc_loss = 0.07649199990780602
Trained batch 207 in epoch 7, gen_loss = 0.8349172444297717, disc_loss = 0.07634975931768377
Trained batch 208 in epoch 7, gen_loss = 0.8342986660140553, disc_loss = 0.07618009964333909
Trained batch 209 in epoch 7, gen_loss = 0.8345413236390977, disc_loss = 0.07590121023268218
Trained batch 210 in epoch 7, gen_loss = 0.8347634884983443, disc_loss = 0.07585981007559463
Trained batch 211 in epoch 7, gen_loss = 0.8343486577834723, disc_loss = 0.07566475565545261
Trained batch 212 in epoch 7, gen_loss = 0.8338512579600016, disc_loss = 0.0755022580171345
Trained batch 213 in epoch 7, gen_loss = 0.8329283004609224, disc_loss = 0.07566897487093772
Trained batch 214 in epoch 7, gen_loss = 0.8331220028012298, disc_loss = 0.07559926823041467
Trained batch 215 in epoch 7, gen_loss = 0.832647912480213, disc_loss = 0.07542351553544265
Trained batch 216 in epoch 7, gen_loss = 0.8321851426005913, disc_loss = 0.07550026898268043
Trained batch 217 in epoch 7, gen_loss = 0.8330918413783432, disc_loss = 0.07549513438545646
Trained batch 218 in epoch 7, gen_loss = 0.8320599299043281, disc_loss = 0.07568394878802642
Trained batch 219 in epoch 7, gen_loss = 0.8314288865436207, disc_loss = 0.07575247280553661
Trained batch 220 in epoch 7, gen_loss = 0.8321270538131575, disc_loss = 0.07609621937306624
Trained batch 221 in epoch 7, gen_loss = 0.8335448100760177, disc_loss = 0.07596303899730514
Trained batch 222 in epoch 7, gen_loss = 0.8326816361046693, disc_loss = 0.07593300034429862
Trained batch 223 in epoch 7, gen_loss = 0.8329008085919278, disc_loss = 0.07578521193188083
Trained batch 224 in epoch 7, gen_loss = 0.8325410087903341, disc_loss = 0.07563388171709245
Trained batch 225 in epoch 7, gen_loss = 0.8326870495766665, disc_loss = 0.07543091956872196
Trained batch 226 in epoch 7, gen_loss = 0.8325519564393333, disc_loss = 0.07525919905826778
Trained batch 227 in epoch 7, gen_loss = 0.832533580430767, disc_loss = 0.07534454429211716
Trained batch 228 in epoch 7, gen_loss = 0.8319742726446759, disc_loss = 0.0752297403599953
Trained batch 229 in epoch 7, gen_loss = 0.8338081323582193, disc_loss = 0.07528228662179216
Trained batch 230 in epoch 7, gen_loss = 0.8340106709694965, disc_loss = 0.07510313621895524
Trained batch 231 in epoch 7, gen_loss = 0.833007062817442, disc_loss = 0.07525780040305108
Trained batch 232 in epoch 7, gen_loss = 0.8339670543506933, disc_loss = 0.07500467965451305
Trained batch 233 in epoch 7, gen_loss = 0.8347857839021927, disc_loss = 0.07478404049482992
Trained batch 234 in epoch 7, gen_loss = 0.8340641186592427, disc_loss = 0.07467319681210087
Trained batch 235 in epoch 7, gen_loss = 0.8345257422681582, disc_loss = 0.07449343909067496
Trained batch 236 in epoch 7, gen_loss = 0.8344170265056916, disc_loss = 0.07445715070320962
Trained batch 237 in epoch 7, gen_loss = 0.834240170336571, disc_loss = 0.07433101564191845
Trained batch 238 in epoch 7, gen_loss = 0.8337221818987794, disc_loss = 0.07424766588644378
Trained batch 239 in epoch 7, gen_loss = 0.8335793527464072, disc_loss = 0.0740648035852549
Trained batch 240 in epoch 7, gen_loss = 0.8346831949419995, disc_loss = 0.073987166335443
Trained batch 241 in epoch 7, gen_loss = 0.834835252978585, disc_loss = 0.0739185626556989
Trained batch 242 in epoch 7, gen_loss = 0.8347622413694122, disc_loss = 0.07382571730578755
Trained batch 243 in epoch 7, gen_loss = 0.8347050281333142, disc_loss = 0.07363538756645972
Trained batch 244 in epoch 7, gen_loss = 0.8359201049318119, disc_loss = 0.07418391717863934
Trained batch 245 in epoch 7, gen_loss = 0.8341213680379759, disc_loss = 0.07495917998844893
Trained batch 246 in epoch 7, gen_loss = 0.835188345629194, disc_loss = 0.0747908899590735
Trained batch 247 in epoch 7, gen_loss = 0.8346408473387841, disc_loss = 0.0747570623606143
Trained batch 248 in epoch 7, gen_loss = 0.8346663500410486, disc_loss = 0.07461929847542421
Trained batch 249 in epoch 7, gen_loss = 0.8361454889774322, disc_loss = 0.07492362582311034
Trained batch 250 in epoch 7, gen_loss = 0.8355738750966897, disc_loss = 0.07494290279543614
Trained batch 251 in epoch 7, gen_loss = 0.8354327844248878, disc_loss = 0.07493096087054009
Trained batch 252 in epoch 7, gen_loss = 0.8357509859936981, disc_loss = 0.0758649847569614
Trained batch 253 in epoch 7, gen_loss = 0.8348128483520718, disc_loss = 0.0759865279588115
Trained batch 254 in epoch 7, gen_loss = 0.8343116021623799, disc_loss = 0.07592470940640744
Trained batch 255 in epoch 7, gen_loss = 0.8344048296567053, disc_loss = 0.07610427942927345
Trained batch 256 in epoch 7, gen_loss = 0.8339285087492679, disc_loss = 0.07593531187275852
Trained batch 257 in epoch 7, gen_loss = 0.8342925058316815, disc_loss = 0.07603959369206036
Trained batch 258 in epoch 7, gen_loss = 0.8333570685625997, disc_loss = 0.07608188610725306
Trained batch 259 in epoch 7, gen_loss = 0.8337987950214973, disc_loss = 0.07587268620084685
Trained batch 260 in epoch 7, gen_loss = 0.834046785173745, disc_loss = 0.07564701314416082
Trained batch 261 in epoch 7, gen_loss = 0.8343545596563179, disc_loss = 0.07553232086196769
Trained batch 262 in epoch 7, gen_loss = 0.8344884986206605, disc_loss = 0.07564338336666841
Trained batch 263 in epoch 7, gen_loss = 0.8333561759103428, disc_loss = 0.07573002125630438
Trained batch 264 in epoch 7, gen_loss = 0.8338724631183553, disc_loss = 0.07551823393002434
Trained batch 265 in epoch 7, gen_loss = 0.8336472697275922, disc_loss = 0.0755265124275216
Trained batch 266 in epoch 7, gen_loss = 0.8343466844005085, disc_loss = 0.07556359698361113
Trained batch 267 in epoch 7, gen_loss = 0.8344056788665145, disc_loss = 0.07541317436774608
Trained batch 268 in epoch 7, gen_loss = 0.8338299271785636, disc_loss = 0.07535598962654301
Trained batch 269 in epoch 7, gen_loss = 0.8345712851594995, disc_loss = 0.07533979750824747
Trained batch 270 in epoch 7, gen_loss = 0.8346516965060217, disc_loss = 0.07526240052098608
Trained batch 271 in epoch 7, gen_loss = 0.8343141396694324, disc_loss = 0.07528061559081406
Trained batch 272 in epoch 7, gen_loss = 0.8340621385382209, disc_loss = 0.07530500911408182
Trained batch 273 in epoch 7, gen_loss = 0.8352860845353481, disc_loss = 0.07625541966204552
Trained batch 274 in epoch 7, gen_loss = 0.8354805185578086, disc_loss = 0.07618332651189783
Trained batch 275 in epoch 7, gen_loss = 0.8352412201356196, disc_loss = 0.0762476943993428
Trained batch 276 in epoch 7, gen_loss = 0.834556753454656, disc_loss = 0.0766582319257438
Trained batch 277 in epoch 7, gen_loss = 0.8341995046721945, disc_loss = 0.07681784816019291
Trained batch 278 in epoch 7, gen_loss = 0.834773940638402, disc_loss = 0.07709489431312327
Trained batch 279 in epoch 7, gen_loss = 0.835003679565021, disc_loss = 0.0773314868199772
Trained batch 280 in epoch 7, gen_loss = 0.83515072505245, disc_loss = 0.07724654029895721
Trained batch 281 in epoch 7, gen_loss = 0.8354444478420501, disc_loss = 0.0770687205314055
Trained batch 282 in epoch 7, gen_loss = 0.835088857913607, disc_loss = 0.07698875300046518
Trained batch 283 in epoch 7, gen_loss = 0.8353869696738014, disc_loss = 0.07695753628742212
Trained batch 284 in epoch 7, gen_loss = 0.834788333533103, disc_loss = 0.07698914152815153
Trained batch 285 in epoch 7, gen_loss = 0.8356028317988335, disc_loss = 0.0770882620814849
Trained batch 286 in epoch 7, gen_loss = 0.8349343903804075, disc_loss = 0.07713505205493874
Trained batch 287 in epoch 7, gen_loss = 0.8348182195590602, disc_loss = 0.07693547484167437
Trained batch 288 in epoch 7, gen_loss = 0.8343819546864519, disc_loss = 0.07691666267644678
Trained batch 289 in epoch 7, gen_loss = 0.8349315460385948, disc_loss = 0.07669852049378999
Trained batch 290 in epoch 7, gen_loss = 0.8347179580390248, disc_loss = 0.0765900438510624
Trained batch 291 in epoch 7, gen_loss = 0.8344831909627131, disc_loss = 0.0764838815188316
Trained batch 292 in epoch 7, gen_loss = 0.8340426593917222, disc_loss = 0.07640079589109271
Trained batch 293 in epoch 7, gen_loss = 0.8354384084137119, disc_loss = 0.0765177663003861
Trained batch 294 in epoch 7, gen_loss = 0.835318732059608, disc_loss = 0.07631633552896269
Trained batch 295 in epoch 7, gen_loss = 0.8345475680119282, disc_loss = 0.07648359640262316
Trained batch 296 in epoch 7, gen_loss = 0.8346135427654793, disc_loss = 0.07629558328313357
Trained batch 297 in epoch 7, gen_loss = 0.8357592217074145, disc_loss = 0.07673753332659203
Trained batch 298 in epoch 7, gen_loss = 0.8358995762955783, disc_loss = 0.07656822735786338
Trained batch 299 in epoch 7, gen_loss = 0.8349032626549403, disc_loss = 0.07692095916407804
Trained batch 300 in epoch 7, gen_loss = 0.8353249094018904, disc_loss = 0.07674012681240358
Trained batch 301 in epoch 7, gen_loss = 0.8354930177034922, disc_loss = 0.0768800754476314
Trained batch 302 in epoch 7, gen_loss = 0.8343057450484914, disc_loss = 0.07713167302052279
Trained batch 303 in epoch 7, gen_loss = 0.8340550973815354, disc_loss = 0.07704486348972607
Trained batch 304 in epoch 7, gen_loss = 0.8334324011060058, disc_loss = 0.07698628107604921
Trained batch 305 in epoch 7, gen_loss = 0.8344863913222855, disc_loss = 0.07687429536219223
Trained batch 306 in epoch 7, gen_loss = 0.8347457230867703, disc_loss = 0.07683819889451957
Trained batch 307 in epoch 7, gen_loss = 0.8334973341265282, disc_loss = 0.07756984105950536
Trained batch 308 in epoch 7, gen_loss = 0.8336443105368938, disc_loss = 0.07740741593516084
Trained batch 309 in epoch 7, gen_loss = 0.8341070537605594, disc_loss = 0.07728718083291765
Trained batch 310 in epoch 7, gen_loss = 0.8331359863472905, disc_loss = 0.07759795145362232
Trained batch 311 in epoch 7, gen_loss = 0.8336353488266468, disc_loss = 0.0783154933552186
Trained batch 312 in epoch 7, gen_loss = 0.8334809117995131, disc_loss = 0.0782001872157184
Trained batch 313 in epoch 7, gen_loss = 0.8334940978486067, disc_loss = 0.07810325213785099
Trained batch 314 in epoch 7, gen_loss = 0.8330378580661048, disc_loss = 0.07797607089141531
Trained batch 315 in epoch 7, gen_loss = 0.8332724240195902, disc_loss = 0.07841167863328717
Trained batch 316 in epoch 7, gen_loss = 0.8324126372766043, disc_loss = 0.07870710686095976
Trained batch 317 in epoch 7, gen_loss = 0.832091618540152, disc_loss = 0.0785867467130177
Trained batch 318 in epoch 7, gen_loss = 0.83280682591809, disc_loss = 0.07860313349207834
Trained batch 319 in epoch 7, gen_loss = 0.8336207116954029, disc_loss = 0.07845938290993218
Trained batch 320 in epoch 7, gen_loss = 0.8328551676971518, disc_loss = 0.0785525834965418
Trained batch 321 in epoch 7, gen_loss = 0.8327339435030955, disc_loss = 0.07840505661442876
Trained batch 322 in epoch 7, gen_loss = 0.8326245796385195, disc_loss = 0.0787511952134893
Trained batch 323 in epoch 7, gen_loss = 0.8323350146780779, disc_loss = 0.07870946312035768
Trained batch 324 in epoch 7, gen_loss = 0.8321346443433028, disc_loss = 0.0785698777007369
Trained batch 325 in epoch 7, gen_loss = 0.8319816482396214, disc_loss = 0.07849501391324254
Trained batch 326 in epoch 7, gen_loss = 0.8332241769048416, disc_loss = 0.0787048280404294
Trained batch 327 in epoch 7, gen_loss = 0.8329120168416966, disc_loss = 0.07856533468825878
Trained batch 328 in epoch 7, gen_loss = 0.8323120323539143, disc_loss = 0.07903084423008026
Trained batch 329 in epoch 7, gen_loss = 0.8322964152603438, disc_loss = 0.07891139816210577
Trained batch 330 in epoch 7, gen_loss = 0.8327499207593163, disc_loss = 0.07899407834501154
Trained batch 331 in epoch 7, gen_loss = 0.834070378847151, disc_loss = 0.07911987922782729
Trained batch 332 in epoch 7, gen_loss = 0.8336293143374068, disc_loss = 0.07901154773158801
Trained batch 333 in epoch 7, gen_loss = 0.833189453818127, disc_loss = 0.07893609556977353
Trained batch 334 in epoch 7, gen_loss = 0.8324952418234811, disc_loss = 0.07906855596368437
Trained batch 335 in epoch 7, gen_loss = 0.8328605518631992, disc_loss = 0.0790817290128741
Trained batch 336 in epoch 7, gen_loss = 0.8337258359621823, disc_loss = 0.07926754649308475
Trained batch 337 in epoch 7, gen_loss = 0.8335003839618356, disc_loss = 0.07914399876143541
Trained batch 338 in epoch 7, gen_loss = 0.8330339864116151, disc_loss = 0.079101243556359
Trained batch 339 in epoch 7, gen_loss = 0.8328848932595814, disc_loss = 0.07922306012855294
Trained batch 340 in epoch 7, gen_loss = 0.8329639872672621, disc_loss = 0.07906814355162843
Trained batch 341 in epoch 7, gen_loss = 0.8334768844103952, disc_loss = 0.0791337510641686
Trained batch 342 in epoch 7, gen_loss = 0.8335231640769858, disc_loss = 0.0789697093009384
Trained batch 343 in epoch 7, gen_loss = 0.83317456766963, disc_loss = 0.07884708671494885
Trained batch 344 in epoch 7, gen_loss = 0.8329751910506815, disc_loss = 0.07873546671986148
Trained batch 345 in epoch 7, gen_loss = 0.833163397591238, disc_loss = 0.07855128697684907
Trained batch 346 in epoch 7, gen_loss = 0.8332931235303797, disc_loss = 0.07856121625461393
Trained batch 347 in epoch 7, gen_loss = 0.8341816460777973, disc_loss = 0.07848727820312669
Trained batch 348 in epoch 7, gen_loss = 0.8342768296300511, disc_loss = 0.07831629295766696
Trained batch 349 in epoch 7, gen_loss = 0.8338136803252356, disc_loss = 0.07838734835918461
Trained batch 350 in epoch 7, gen_loss = 0.8335087568501801, disc_loss = 0.07836925752588317
Trained batch 351 in epoch 7, gen_loss = 0.8341404122554443, disc_loss = 0.07866901111132889
Trained batch 352 in epoch 7, gen_loss = 0.8343756959559897, disc_loss = 0.07869141251798561
Trained batch 353 in epoch 7, gen_loss = 0.8337561522668364, disc_loss = 0.07871891729175876
Trained batch 354 in epoch 7, gen_loss = 0.8328898665770679, disc_loss = 0.07878422473203128
Trained batch 355 in epoch 7, gen_loss = 0.8337142099992613, disc_loss = 0.0788407826199709
Trained batch 356 in epoch 7, gen_loss = 0.8349396161505488, disc_loss = 0.07877572490742393
Trained batch 357 in epoch 7, gen_loss = 0.8345250478170437, disc_loss = 0.07863413071644872
Trained batch 358 in epoch 7, gen_loss = 0.8343115680563085, disc_loss = 0.07852698394037722
Trained batch 359 in epoch 7, gen_loss = 0.8343218579060502, disc_loss = 0.07833835329446527
Trained batch 360 in epoch 7, gen_loss = 0.833762081458628, disc_loss = 0.07830640630296062
Trained batch 361 in epoch 7, gen_loss = 0.8342387048085091, disc_loss = 0.07820918517012293
Trained batch 362 in epoch 7, gen_loss = 0.8344162880717558, disc_loss = 0.07805287411061856
Trained batch 363 in epoch 7, gen_loss = 0.8344832240388944, disc_loss = 0.07789165143353435
Trained batch 364 in epoch 7, gen_loss = 0.8346474454011003, disc_loss = 0.07771783147568571
Trained batch 365 in epoch 7, gen_loss = 0.8348549588944743, disc_loss = 0.07767531002968386
Trained batch 366 in epoch 7, gen_loss = 0.8341041170771181, disc_loss = 0.0778397028144114
Trained batch 367 in epoch 7, gen_loss = 0.8344998830200537, disc_loss = 0.07784758380654713
Trained batch 368 in epoch 7, gen_loss = 0.8340354241168273, disc_loss = 0.07783194001370329
Trained batch 369 in epoch 7, gen_loss = 0.8341921190152297, disc_loss = 0.07788931282388198
Trained batch 370 in epoch 7, gen_loss = 0.8344026350107476, disc_loss = 0.07775927975653317
Trained batch 371 in epoch 7, gen_loss = 0.8344075057295061, disc_loss = 0.07760699458360192
Trained batch 372 in epoch 7, gen_loss = 0.8343637407465211, disc_loss = 0.077522933208471
Trained batch 373 in epoch 7, gen_loss = 0.8350036494075296, disc_loss = 0.07734681819042659
Trained batch 374 in epoch 7, gen_loss = 0.8362984818617503, disc_loss = 0.07726837702343861
Trained batch 375 in epoch 7, gen_loss = 0.8364002324957797, disc_loss = 0.07714439314502747
Trained batch 376 in epoch 7, gen_loss = 0.8368259803527862, disc_loss = 0.07697266199692727
Trained batch 377 in epoch 7, gen_loss = 0.8374571793136143, disc_loss = 0.07681564572538255
Trained batch 378 in epoch 7, gen_loss = 0.8374446046226572, disc_loss = 0.07680344237334102
Trained batch 379 in epoch 7, gen_loss = 0.8374090708400074, disc_loss = 0.07674291568906291
Trained batch 380 in epoch 7, gen_loss = 0.837107701486177, disc_loss = 0.07662711957142031
Trained batch 381 in epoch 7, gen_loss = 0.837200957365061, disc_loss = 0.07656264154689084
Trained batch 382 in epoch 7, gen_loss = 0.8367736478854098, disc_loss = 0.07649974844737012
Trained batch 383 in epoch 7, gen_loss = 0.8372586688492447, disc_loss = 0.076456732909719
Trained batch 384 in epoch 7, gen_loss = 0.8372754672130981, disc_loss = 0.07628923955724223
Trained batch 385 in epoch 7, gen_loss = 0.836805687126718, disc_loss = 0.07630951352504328
Trained batch 386 in epoch 7, gen_loss = 0.8362982467933526, disc_loss = 0.07644771599001432
Trained batch 387 in epoch 7, gen_loss = 0.8370878509793085, disc_loss = 0.07673572243152897
Trained batch 388 in epoch 7, gen_loss = 0.8367689385971864, disc_loss = 0.0767336179906919
Trained batch 389 in epoch 7, gen_loss = 0.8368351168357409, disc_loss = 0.07662054405619319
Trained batch 390 in epoch 7, gen_loss = 0.8376127529479659, disc_loss = 0.07711410589392304
Trained batch 391 in epoch 7, gen_loss = 0.8368607030383178, disc_loss = 0.07734860911518715
Trained batch 392 in epoch 7, gen_loss = 0.8367368067038878, disc_loss = 0.07739248667291482
Trained batch 393 in epoch 7, gen_loss = 0.8370405443882579, disc_loss = 0.07735578723601656
Trained batch 394 in epoch 7, gen_loss = 0.8367008136043066, disc_loss = 0.0772632954264932
Trained batch 395 in epoch 7, gen_loss = 0.8365440250496672, disc_loss = 0.07720318472605538
Trained batch 396 in epoch 7, gen_loss = 0.8362505978691187, disc_loss = 0.07721627678403101
Trained batch 397 in epoch 7, gen_loss = 0.8365251493064603, disc_loss = 0.07705675569320818
Trained batch 398 in epoch 7, gen_loss = 0.8366991274787071, disc_loss = 0.07692836894231257
Trained batch 399 in epoch 7, gen_loss = 0.8360016069561244, disc_loss = 0.07689768041251227
Trained batch 400 in epoch 7, gen_loss = 0.8358178959968976, disc_loss = 0.07678782522557605
Trained batch 401 in epoch 7, gen_loss = 0.835319201225665, disc_loss = 0.07686025036535972
Trained batch 402 in epoch 7, gen_loss = 0.836157306622039, disc_loss = 0.07693194552433329
Trained batch 403 in epoch 7, gen_loss = 0.8364985280550352, disc_loss = 0.07685385886718067
Trained batch 404 in epoch 7, gen_loss = 0.8362066000332067, disc_loss = 0.07672549216881579
Trained batch 405 in epoch 7, gen_loss = 0.835829595259845, disc_loss = 0.07680341319910484
Trained batch 406 in epoch 7, gen_loss = 0.836436963418192, disc_loss = 0.07667781810072555
Trained batch 407 in epoch 7, gen_loss = 0.835973243137785, disc_loss = 0.07672901409815121
Trained batch 408 in epoch 7, gen_loss = 0.8361228646888127, disc_loss = 0.0765810901171603
Trained batch 409 in epoch 7, gen_loss = 0.8363874047994614, disc_loss = 0.07648489632666475
Trained batch 410 in epoch 7, gen_loss = 0.8357250828957615, disc_loss = 0.07671188486291326
Trained batch 411 in epoch 7, gen_loss = 0.8358017089731485, disc_loss = 0.07656468746017267
Trained batch 412 in epoch 7, gen_loss = 0.8359225771184695, disc_loss = 0.07647002703277958
Trained batch 413 in epoch 7, gen_loss = 0.8360179375479186, disc_loss = 0.07639434762020114
Trained batch 414 in epoch 7, gen_loss = 0.8356497894568615, disc_loss = 0.07635839117623597
Trained batch 415 in epoch 7, gen_loss = 0.835327802440868, disc_loss = 0.07630310706624116
Trained batch 416 in epoch 7, gen_loss = 0.8355761637075914, disc_loss = 0.07639757830792551
Trained batch 417 in epoch 7, gen_loss = 0.8363793939352036, disc_loss = 0.07628485029474186
Trained batch 418 in epoch 7, gen_loss = 0.8360870256486542, disc_loss = 0.07618874219203976
Trained batch 419 in epoch 7, gen_loss = 0.8358593999629929, disc_loss = 0.07609660044711615
Trained batch 420 in epoch 7, gen_loss = 0.8357974393492357, disc_loss = 0.07603412703998086
Trained batch 421 in epoch 7, gen_loss = 0.8359443301696913, disc_loss = 0.07596502075483802
Trained batch 422 in epoch 7, gen_loss = 0.8365868560388579, disc_loss = 0.0758657923461451
Trained batch 423 in epoch 7, gen_loss = 0.8362903629412066, disc_loss = 0.07585630717221648
Trained batch 424 in epoch 7, gen_loss = 0.8363632592734168, disc_loss = 0.07573771927944001
Trained batch 425 in epoch 7, gen_loss = 0.8370373056668071, disc_loss = 0.07571877233745276
Trained batch 426 in epoch 7, gen_loss = 0.8366655618720088, disc_loss = 0.07558173782887936
Trained batch 427 in epoch 7, gen_loss = 0.8365153807485215, disc_loss = 0.07546186376859164
Trained batch 428 in epoch 7, gen_loss = 0.8363345666226252, disc_loss = 0.07552981059911437
Trained batch 429 in epoch 7, gen_loss = 0.8359227175629416, disc_loss = 0.07560158146025484
Trained batch 430 in epoch 7, gen_loss = 0.8364124995788123, disc_loss = 0.07579500225789655
Trained batch 431 in epoch 7, gen_loss = 0.8368925386694847, disc_loss = 0.07566330246670448
Trained batch 432 in epoch 7, gen_loss = 0.8364439336174355, disc_loss = 0.0756831152545284
Trained batch 433 in epoch 7, gen_loss = 0.8367670657035942, disc_loss = 0.07553256864869787
Trained batch 434 in epoch 7, gen_loss = 0.8372029932751053, disc_loss = 0.07539101459685413
Trained batch 435 in epoch 7, gen_loss = 0.8377375600671549, disc_loss = 0.07528410177814578
Trained batch 436 in epoch 7, gen_loss = 0.8375827074732879, disc_loss = 0.0751645722697133
Trained batch 437 in epoch 7, gen_loss = 0.8374199322233461, disc_loss = 0.07518472799342381
Trained batch 438 in epoch 7, gen_loss = 0.8382222733220641, disc_loss = 0.07552089297333583
Trained batch 439 in epoch 7, gen_loss = 0.8376632277938453, disc_loss = 0.07566291322000325
Trained batch 440 in epoch 7, gen_loss = 0.8379699681756718, disc_loss = 0.075705451383984
Trained batch 441 in epoch 7, gen_loss = 0.8379251892884932, disc_loss = 0.07561576295205776
Trained batch 442 in epoch 7, gen_loss = 0.8376571653793412, disc_loss = 0.07556611697691962
Trained batch 443 in epoch 7, gen_loss = 0.8388472178632075, disc_loss = 0.07571969132215993
Trained batch 444 in epoch 7, gen_loss = 0.8389922346291917, disc_loss = 0.07558381154170532
Trained batch 445 in epoch 7, gen_loss = 0.8387509729429211, disc_loss = 0.07548950115770035
Trained batch 446 in epoch 7, gen_loss = 0.8385533544441197, disc_loss = 0.07541889926706184
Trained batch 447 in epoch 7, gen_loss = 0.8386309204756149, disc_loss = 0.07531853534289569
Trained batch 448 in epoch 7, gen_loss = 0.8400038344690157, disc_loss = 0.07553283530256331
Trained batch 449 in epoch 7, gen_loss = 0.8400922003719542, disc_loss = 0.07543082088852922
Trained batch 450 in epoch 7, gen_loss = 0.8398902336271797, disc_loss = 0.07537541707601819
Trained batch 451 in epoch 7, gen_loss = 0.8391640384772182, disc_loss = 0.0757981678120693
Trained batch 452 in epoch 7, gen_loss = 0.839699424721021, disc_loss = 0.07580670958413654
Trained batch 453 in epoch 7, gen_loss = 0.8404392485182716, disc_loss = 0.07572239066888517
Trained batch 454 in epoch 7, gen_loss = 0.8403373991395091, disc_loss = 0.07559773672044605
Trained batch 455 in epoch 7, gen_loss = 0.840293340842452, disc_loss = 0.0755268712834406
Trained batch 456 in epoch 7, gen_loss = 0.8401387590156864, disc_loss = 0.07548966283830498
Trained batch 457 in epoch 7, gen_loss = 0.8400892293218962, disc_loss = 0.07536976645989384
Trained batch 458 in epoch 7, gen_loss = 0.8400961963829132, disc_loss = 0.07528234859786458
Trained batch 459 in epoch 7, gen_loss = 0.839703248311644, disc_loss = 0.07521048656907743
Trained batch 460 in epoch 7, gen_loss = 0.8401313613526474, disc_loss = 0.07523769795401689
Trained batch 461 in epoch 7, gen_loss = 0.8399969617396722, disc_loss = 0.07515882973829324
Trained batch 462 in epoch 7, gen_loss = 0.8394290781046865, disc_loss = 0.07528010167414825
Trained batch 463 in epoch 7, gen_loss = 0.8400466810141144, disc_loss = 0.07551082142363784
Trained batch 464 in epoch 7, gen_loss = 0.8402805298246363, disc_loss = 0.07537211433493643
Trained batch 465 in epoch 7, gen_loss = 0.839610266135486, disc_loss = 0.0756198448936411
Trained batch 466 in epoch 7, gen_loss = 0.8400456786028068, disc_loss = 0.07553726170467297
Trained batch 467 in epoch 7, gen_loss = 0.8403367579110668, disc_loss = 0.07551436031308885
Trained batch 468 in epoch 7, gen_loss = 0.84044376663816, disc_loss = 0.07537926736273873
Trained batch 469 in epoch 7, gen_loss = 0.8400182172973105, disc_loss = 0.07535306011980518
Trained batch 470 in epoch 7, gen_loss = 0.8394840312231878, disc_loss = 0.07541035558245364
Trained batch 471 in epoch 7, gen_loss = 0.8401069079794116, disc_loss = 0.07544434892597719
Trained batch 472 in epoch 7, gen_loss = 0.840175497040436, disc_loss = 0.07542943572881484
Trained batch 473 in epoch 7, gen_loss = 0.8394332840598585, disc_loss = 0.07571904901572295
Trained batch 474 in epoch 7, gen_loss = 0.8396646852869737, disc_loss = 0.07561565803461953
Trained batch 475 in epoch 7, gen_loss = 0.840313460834387, disc_loss = 0.07555545033386149
Trained batch 476 in epoch 7, gen_loss = 0.8406929196926533, disc_loss = 0.0754327141998074
Trained batch 477 in epoch 7, gen_loss = 0.8403610127615629, disc_loss = 0.07549620362848168
Trained batch 478 in epoch 7, gen_loss = 0.8400888795768044, disc_loss = 0.07549947197694869
Trained batch 479 in epoch 7, gen_loss = 0.8405143051718672, disc_loss = 0.0755059704883024
Trained batch 480 in epoch 7, gen_loss = 0.8400687628005498, disc_loss = 0.07555383836498132
Trained batch 481 in epoch 7, gen_loss = 0.8399781413469077, disc_loss = 0.07550201482328883
Trained batch 482 in epoch 7, gen_loss = 0.8395104318795491, disc_loss = 0.07569383792039278
Trained batch 483 in epoch 7, gen_loss = 0.8398751300597979, disc_loss = 0.07582066008774949
Trained batch 484 in epoch 7, gen_loss = 0.8397157221110826, disc_loss = 0.07574872980566369
Trained batch 485 in epoch 7, gen_loss = 0.8391410515264228, disc_loss = 0.07578593372164194
Trained batch 486 in epoch 7, gen_loss = 0.8394205195091099, disc_loss = 0.0756608001405882
Trained batch 487 in epoch 7, gen_loss = 0.8393000683701429, disc_loss = 0.07563323005041504
Trained batch 488 in epoch 7, gen_loss = 0.8393597354796279, disc_loss = 0.07565586813982644
Trained batch 489 in epoch 7, gen_loss = 0.8393459554229464, disc_loss = 0.07565893563917096
Trained batch 490 in epoch 7, gen_loss = 0.8391085929273345, disc_loss = 0.07553539609312708
Trained batch 491 in epoch 7, gen_loss = 0.838785657856038, disc_loss = 0.07556352260658836
Trained batch 492 in epoch 7, gen_loss = 0.8391244230720141, disc_loss = 0.07547563441951606
Trained batch 493 in epoch 7, gen_loss = 0.8391235081652398, disc_loss = 0.07539749011842285
Trained batch 494 in epoch 7, gen_loss = 0.839266131562416, disc_loss = 0.07535812614504436
Trained batch 495 in epoch 7, gen_loss = 0.838767287651858, disc_loss = 0.0754856632237563
Trained batch 496 in epoch 7, gen_loss = 0.8387804728758407, disc_loss = 0.07553754726488525
Trained batch 497 in epoch 7, gen_loss = 0.8389803783362171, disc_loss = 0.07544617817725942
Trained batch 498 in epoch 7, gen_loss = 0.838917325816317, disc_loss = 0.07533524974337023
Trained batch 499 in epoch 7, gen_loss = 0.838906055867672, disc_loss = 0.07533069100044668
Trained batch 500 in epoch 7, gen_loss = 0.838953403358212, disc_loss = 0.07522858879501056
Trained batch 501 in epoch 7, gen_loss = 0.8389747353545223, disc_loss = 0.07512853974550665
Trained batch 502 in epoch 7, gen_loss = 0.8383383231300483, disc_loss = 0.07534798763684973
Trained batch 503 in epoch 7, gen_loss = 0.839079773319619, disc_loss = 0.07555953037947238
Trained batch 504 in epoch 7, gen_loss = 0.8393595288885702, disc_loss = 0.07544923033196442
Trained batch 505 in epoch 7, gen_loss = 0.8387784332979338, disc_loss = 0.07555815975987923
Trained batch 506 in epoch 7, gen_loss = 0.8391017948499563, disc_loss = 0.07545543649955791
Trained batch 507 in epoch 7, gen_loss = 0.8396219683327074, disc_loss = 0.07557551699001196
Trained batch 508 in epoch 7, gen_loss = 0.8390287581853173, disc_loss = 0.07564507803764406
Trained batch 509 in epoch 7, gen_loss = 0.8387755208740048, disc_loss = 0.07558789512361674
Trained batch 510 in epoch 7, gen_loss = 0.8389792420742797, disc_loss = 0.07575202016469726
Trained batch 511 in epoch 7, gen_loss = 0.8385899979039095, disc_loss = 0.07584224240235926
Trained batch 512 in epoch 7, gen_loss = 0.8384718878111179, disc_loss = 0.07579224698107552
Trained batch 513 in epoch 7, gen_loss = 0.8383441564521901, disc_loss = 0.07567199050894566
Trained batch 514 in epoch 7, gen_loss = 0.8387077631880936, disc_loss = 0.07582521922705532
Trained batch 515 in epoch 7, gen_loss = 0.8385129840683567, disc_loss = 0.07575011603685833
Trained batch 516 in epoch 7, gen_loss = 0.8379389659233204, disc_loss = 0.07605626894705127
Trained batch 517 in epoch 7, gen_loss = 0.8383131639952826, disc_loss = 0.07599138877890342
Trained batch 518 in epoch 7, gen_loss = 0.8382007217246443, disc_loss = 0.07596864835009237
Trained batch 519 in epoch 7, gen_loss = 0.8386678013090904, disc_loss = 0.07586554892611905
Trained batch 520 in epoch 7, gen_loss = 0.8389980553322242, disc_loss = 0.07575569101457347
Trained batch 521 in epoch 7, gen_loss = 0.8383475145846034, disc_loss = 0.07583328003734635
Trained batch 522 in epoch 7, gen_loss = 0.8384112050154925, disc_loss = 0.07574245805031198
Trained batch 523 in epoch 7, gen_loss = 0.8387208777757091, disc_loss = 0.07589021886570933
Trained batch 524 in epoch 7, gen_loss = 0.838594245456514, disc_loss = 0.0757971832812542
Trained batch 525 in epoch 7, gen_loss = 0.8385883552719885, disc_loss = 0.07574149292181936
Trained batch 526 in epoch 7, gen_loss = 0.8385281232547941, disc_loss = 0.0756652400452481
Trained batch 527 in epoch 7, gen_loss = 0.8389222791249101, disc_loss = 0.0758145027670473
Trained batch 528 in epoch 7, gen_loss = 0.8387454718858398, disc_loss = 0.07577847374078513
Trained batch 529 in epoch 7, gen_loss = 0.838436783709616, disc_loss = 0.07573701194048209
Trained batch 530 in epoch 7, gen_loss = 0.8384682114065928, disc_loss = 0.07562609934712815
Trained batch 531 in epoch 7, gen_loss = 0.8391475826501846, disc_loss = 0.07565188045347375
Trained batch 532 in epoch 7, gen_loss = 0.8392201209157761, disc_loss = 0.07555284867094617
Trained batch 533 in epoch 7, gen_loss = 0.8384881645775912, disc_loss = 0.07567295217398233
Trained batch 534 in epoch 7, gen_loss = 0.8388744208300225, disc_loss = 0.07557615070803979
Trained batch 535 in epoch 7, gen_loss = 0.8392076037490546, disc_loss = 0.0756920202854159
Trained batch 536 in epoch 7, gen_loss = 0.8390805877786774, disc_loss = 0.07563173869239719
Trained batch 537 in epoch 7, gen_loss = 0.8386732342074795, disc_loss = 0.07562898574258481
Trained batch 538 in epoch 7, gen_loss = 0.8380775021489343, disc_loss = 0.07580868972911187
Trained batch 539 in epoch 7, gen_loss = 0.8385295776305375, disc_loss = 0.07587775442990716
Trained batch 540 in epoch 7, gen_loss = 0.8387294914056986, disc_loss = 0.07592265163126527
Trained batch 541 in epoch 7, gen_loss = 0.838324662834076, disc_loss = 0.07603255938223093
Trained batch 542 in epoch 7, gen_loss = 0.8381809572488563, disc_loss = 0.0759511857892131
Trained batch 543 in epoch 7, gen_loss = 0.8382331469260594, disc_loss = 0.07585953883587054
Trained batch 544 in epoch 7, gen_loss = 0.8383684968729631, disc_loss = 0.07605628957202949
Trained batch 545 in epoch 7, gen_loss = 0.8382571148566711, disc_loss = 0.0759619634765654
Trained batch 546 in epoch 7, gen_loss = 0.8377074189552224, disc_loss = 0.07595109646898138
Trained batch 547 in epoch 7, gen_loss = 0.8378037946285123, disc_loss = 0.07589111642497354
Trained batch 548 in epoch 7, gen_loss = 0.8375833980155556, disc_loss = 0.0758378542162383
Trained batch 549 in epoch 7, gen_loss = 0.8375382294438102, disc_loss = 0.07597161841155453
Trained batch 550 in epoch 7, gen_loss = 0.837828469471144, disc_loss = 0.07587366193674924
Trained batch 551 in epoch 7, gen_loss = 0.8377198035950246, disc_loss = 0.07585830316521174
Trained batch 552 in epoch 7, gen_loss = 0.8373682523722243, disc_loss = 0.07590897635440552
Trained batch 553 in epoch 7, gen_loss = 0.83743128417201, disc_loss = 0.07599479798731874
Trained batch 554 in epoch 7, gen_loss = 0.8375891179651828, disc_loss = 0.07591444409141938
Trained batch 555 in epoch 7, gen_loss = 0.8374434807103315, disc_loss = 0.07589482070657043
Trained batch 556 in epoch 7, gen_loss = 0.8372775336570328, disc_loss = 0.07590611909868955
Trained batch 557 in epoch 7, gen_loss = 0.8374782126650588, disc_loss = 0.07592601860008841
Trained batch 558 in epoch 7, gen_loss = 0.8379214501978033, disc_loss = 0.07585538244824556
Trained batch 559 in epoch 7, gen_loss = 0.8373898395470211, disc_loss = 0.07597774470258238
Trained batch 560 in epoch 7, gen_loss = 0.8370158686144892, disc_loss = 0.07595224533256628
Trained batch 561 in epoch 7, gen_loss = 0.836963019231036, disc_loss = 0.07595729697462555
Trained batch 562 in epoch 7, gen_loss = 0.8367061154457011, disc_loss = 0.07601412124501716
Trained batch 563 in epoch 7, gen_loss = 0.8360397396146828, disc_loss = 0.07619551898984252
Trained batch 564 in epoch 7, gen_loss = 0.8364701691981965, disc_loss = 0.07639601214302588
Trained batch 565 in epoch 7, gen_loss = 0.8360259085367088, disc_loss = 0.07650079467093618
Trained batch 566 in epoch 7, gen_loss = 0.8366561460537044, disc_loss = 0.0764375449465407
Trained batch 567 in epoch 7, gen_loss = 0.8361810540229502, disc_loss = 0.07648100934325862
Trained batch 568 in epoch 7, gen_loss = 0.8363335554754797, disc_loss = 0.07647856421316916
Trained batch 569 in epoch 7, gen_loss = 0.8361955876935993, disc_loss = 0.07644258635118603
Trained batch 570 in epoch 7, gen_loss = 0.836182409222197, disc_loss = 0.07641066456353862
Trained batch 571 in epoch 7, gen_loss = 0.8360423367548656, disc_loss = 0.0764332790582252
Trained batch 572 in epoch 7, gen_loss = 0.8357914439670703, disc_loss = 0.0764172344987019
Trained batch 573 in epoch 7, gen_loss = 0.8360020959626507, disc_loss = 0.07634142088745996
Trained batch 574 in epoch 7, gen_loss = 0.8361973871355471, disc_loss = 0.07628104358425607
Trained batch 575 in epoch 7, gen_loss = 0.8360408395528793, disc_loss = 0.07626360425395735
Trained batch 576 in epoch 7, gen_loss = 0.8361641751211686, disc_loss = 0.07616986990446287
Trained batch 577 in epoch 7, gen_loss = 0.8362299049189347, disc_loss = 0.07607478219016768
Trained batch 578 in epoch 7, gen_loss = 0.8363943989412772, disc_loss = 0.07597860002114931
Trained batch 579 in epoch 7, gen_loss = 0.8364382338934931, disc_loss = 0.07593708608524295
Trained batch 580 in epoch 7, gen_loss = 0.8367678591798792, disc_loss = 0.07591027446995247
Trained batch 581 in epoch 7, gen_loss = 0.8366171155393738, disc_loss = 0.0759014203181151
Trained batch 582 in epoch 7, gen_loss = 0.8362550488058126, disc_loss = 0.07592855967536544
Trained batch 583 in epoch 7, gen_loss = 0.8365296799026124, disc_loss = 0.07598497389260782
Trained batch 584 in epoch 7, gen_loss = 0.8366042705682608, disc_loss = 0.07597694608231641
Trained batch 585 in epoch 7, gen_loss = 0.8361893212835944, disc_loss = 0.07597373354601525
Trained batch 586 in epoch 7, gen_loss = 0.8357382269490516, disc_loss = 0.07622830229422659
Trained batch 587 in epoch 7, gen_loss = 0.8362098873472538, disc_loss = 0.07631273663818178
Trained batch 588 in epoch 7, gen_loss = 0.8365358735588087, disc_loss = 0.07622238937512368
Trained batch 589 in epoch 7, gen_loss = 0.8363090369660976, disc_loss = 0.0762352170028045
Trained batch 590 in epoch 7, gen_loss = 0.8362166268369672, disc_loss = 0.07615046705042096
Trained batch 591 in epoch 7, gen_loss = 0.83673753569255, disc_loss = 0.0761135706215518
Trained batch 592 in epoch 7, gen_loss = 0.836750336883442, disc_loss = 0.07602379045293715
Trained batch 593 in epoch 7, gen_loss = 0.8367997442030345, disc_loss = 0.07593721855801816
Trained batch 594 in epoch 7, gen_loss = 0.8370089030065456, disc_loss = 0.07592591026782239
Trained batch 595 in epoch 7, gen_loss = 0.8369554953287112, disc_loss = 0.07582869751522656
Trained batch 596 in epoch 7, gen_loss = 0.8368053338435827, disc_loss = 0.07581505094072977
Trained batch 597 in epoch 7, gen_loss = 0.8370470707631829, disc_loss = 0.07584425548627274
Trained batch 598 in epoch 7, gen_loss = 0.837220265391673, disc_loss = 0.07573618122589508
Trained batch 599 in epoch 7, gen_loss = 0.8373702826102575, disc_loss = 0.07564455440578362
Trained batch 600 in epoch 7, gen_loss = 0.8376587877257692, disc_loss = 0.07555099450262533
Trained batch 601 in epoch 7, gen_loss = 0.8379855415353743, disc_loss = 0.07544017067191461
Trained batch 602 in epoch 7, gen_loss = 0.8377964026101589, disc_loss = 0.07544428877575728
Trained batch 603 in epoch 7, gen_loss = 0.8378315826520225, disc_loss = 0.07536361841269035
Trained batch 604 in epoch 7, gen_loss = 0.8378119273619218, disc_loss = 0.07532206049481453
Trained batch 605 in epoch 7, gen_loss = 0.8380427778554042, disc_loss = 0.07521777964126405
Trained batch 606 in epoch 7, gen_loss = 0.8380003381993075, disc_loss = 0.07513294264496208
Trained batch 607 in epoch 7, gen_loss = 0.8378143030169763, disc_loss = 0.07506989128734476
Trained batch 608 in epoch 7, gen_loss = 0.8382908806620756, disc_loss = 0.07496834438208533
Trained batch 609 in epoch 7, gen_loss = 0.8384250406359063, disc_loss = 0.07487616958096624
Trained batch 610 in epoch 7, gen_loss = 0.8385869764072025, disc_loss = 0.0747715068444512
Trained batch 611 in epoch 7, gen_loss = 0.8384541841893415, disc_loss = 0.07475439103752424
Trained batch 612 in epoch 7, gen_loss = 0.8388551428889761, disc_loss = 0.07466476229376495
Trained batch 613 in epoch 7, gen_loss = 0.8388949962702947, disc_loss = 0.0745688939075735
Trained batch 614 in epoch 7, gen_loss = 0.8392098399681773, disc_loss = 0.07446495037889335
Trained batch 615 in epoch 7, gen_loss = 0.8391731778135547, disc_loss = 0.07442213614416829
Trained batch 616 in epoch 7, gen_loss = 0.8391413296447581, disc_loss = 0.07434198333213114
Trained batch 617 in epoch 7, gen_loss = 0.8391882531272555, disc_loss = 0.07425205181217165
Trained batch 618 in epoch 7, gen_loss = 0.8393824293078052, disc_loss = 0.07416335550048095
Trained batch 619 in epoch 7, gen_loss = 0.8396148300939991, disc_loss = 0.07405885295912383
Trained batch 620 in epoch 7, gen_loss = 0.8397927335111032, disc_loss = 0.07396348232730335
Trained batch 621 in epoch 7, gen_loss = 0.8405884949915662, disc_loss = 0.07394361483244603
Trained batch 622 in epoch 7, gen_loss = 0.8405406585091764, disc_loss = 0.07398711797148946
Trained batch 623 in epoch 7, gen_loss = 0.8402929851450981, disc_loss = 0.07403119816295564
Trained batch 624 in epoch 7, gen_loss = 0.8401225420951843, disc_loss = 0.07397361776679755
Trained batch 625 in epoch 7, gen_loss = 0.8405467836430278, disc_loss = 0.07388801365858688
Trained batch 626 in epoch 7, gen_loss = 0.8408765014278832, disc_loss = 0.07411961145906976
Trained batch 627 in epoch 7, gen_loss = 0.8402368315276066, disc_loss = 0.07435601418333686
Trained batch 628 in epoch 7, gen_loss = 0.8404098236503965, disc_loss = 0.07427960170939304
Trained batch 629 in epoch 7, gen_loss = 0.8403969724026937, disc_loss = 0.07421229988898313
Trained batch 630 in epoch 7, gen_loss = 0.8402703617907553, disc_loss = 0.07420403806554676
Trained batch 631 in epoch 7, gen_loss = 0.8403586144500141, disc_loss = 0.07411680856418996
Trained batch 632 in epoch 7, gen_loss = 0.8405025970502675, disc_loss = 0.07410903741262771
Trained batch 633 in epoch 7, gen_loss = 0.8402225921394697, disc_loss = 0.0740958979420881
Trained batch 634 in epoch 7, gen_loss = 0.8401890876724964, disc_loss = 0.07402010232826152
Trained batch 635 in epoch 7, gen_loss = 0.8404064559899036, disc_loss = 0.07395656356652437
Trained batch 636 in epoch 7, gen_loss = 0.8405848011678579, disc_loss = 0.07385321282540423
Trained batch 637 in epoch 7, gen_loss = 0.8405656010192764, disc_loss = 0.07375331801073305
Trained batch 638 in epoch 7, gen_loss = 0.840463356699369, disc_loss = 0.07367007108186611
Trained batch 639 in epoch 7, gen_loss = 0.8404531204141676, disc_loss = 0.07364246119104792
Trained batch 640 in epoch 7, gen_loss = 0.8402343628559024, disc_loss = 0.07361791372682766
Trained batch 641 in epoch 7, gen_loss = 0.8397092825712816, disc_loss = 0.07363705137727138
Trained batch 642 in epoch 7, gen_loss = 0.8401507585082046, disc_loss = 0.07394255107068812
Trained batch 643 in epoch 7, gen_loss = 0.8399017590173283, disc_loss = 0.0738947944374327
Trained batch 644 in epoch 7, gen_loss = 0.8394172418025113, disc_loss = 0.07400606756004714
Trained batch 645 in epoch 7, gen_loss = 0.8394576906235225, disc_loss = 0.07395034947435461
Trained batch 646 in epoch 7, gen_loss = 0.8393901919102558, disc_loss = 0.07397891850235197
Trained batch 647 in epoch 7, gen_loss = 0.8396414659089513, disc_loss = 0.07394575118662122
Trained batch 648 in epoch 7, gen_loss = 0.8393377512923007, disc_loss = 0.07389253570492994
Trained batch 649 in epoch 7, gen_loss = 0.8398430612454048, disc_loss = 0.07383580065977115
Trained batch 650 in epoch 7, gen_loss = 0.8396946251300806, disc_loss = 0.07376622927365123
Trained batch 651 in epoch 7, gen_loss = 0.8393557664989694, disc_loss = 0.07377678363018332
Trained batch 652 in epoch 7, gen_loss = 0.8398011816040846, disc_loss = 0.07376978356123062
Trained batch 653 in epoch 7, gen_loss = 0.840137234612707, disc_loss = 0.07372385978026583
Trained batch 654 in epoch 7, gen_loss = 0.8398947470970736, disc_loss = 0.07368660240739812
Trained batch 655 in epoch 7, gen_loss = 0.8394973903167539, disc_loss = 0.07366436622503054
Trained batch 656 in epoch 7, gen_loss = 0.8397547418486945, disc_loss = 0.07361938028427654
Trained batch 657 in epoch 7, gen_loss = 0.8400340323027868, disc_loss = 0.0735442900101691
Trained batch 658 in epoch 7, gen_loss = 0.8397723007636294, disc_loss = 0.07364697077443007
Trained batch 659 in epoch 7, gen_loss = 0.8398814513827815, disc_loss = 0.07358557118780233
Trained batch 660 in epoch 7, gen_loss = 0.8400541167035586, disc_loss = 0.0734994700389848
Trained batch 661 in epoch 7, gen_loss = 0.8400591055432115, disc_loss = 0.07343184827542737
Trained batch 662 in epoch 7, gen_loss = 0.8405542217228748, disc_loss = 0.07347466585368233
Trained batch 663 in epoch 7, gen_loss = 0.8404866578169616, disc_loss = 0.07340925133012864
Trained batch 664 in epoch 7, gen_loss = 0.8405031770691835, disc_loss = 0.07336584181713879
Trained batch 665 in epoch 7, gen_loss = 0.840928909119901, disc_loss = 0.07371660870116752
Trained batch 666 in epoch 7, gen_loss = 0.840772813853474, disc_loss = 0.07368544891275566
Trained batch 667 in epoch 7, gen_loss = 0.8407081016701853, disc_loss = 0.0736508190542638
Trained batch 668 in epoch 7, gen_loss = 0.8411573361388236, disc_loss = 0.07359164652535734
Trained batch 669 in epoch 7, gen_loss = 0.8411402735247541, disc_loss = 0.07351892513792906
Trained batch 670 in epoch 7, gen_loss = 0.8410505967772665, disc_loss = 0.07344178280802846
Trained batch 671 in epoch 7, gen_loss = 0.8408774792083672, disc_loss = 0.07345598473191439
Trained batch 672 in epoch 7, gen_loss = 0.8409311236456635, disc_loss = 0.07341004407135729
Trained batch 673 in epoch 7, gen_loss = 0.8408511046662882, disc_loss = 0.0733711337477234
Trained batch 674 in epoch 7, gen_loss = 0.8409406239015085, disc_loss = 0.07328158899313873
Trained batch 675 in epoch 7, gen_loss = 0.8408717198308403, disc_loss = 0.07326521219950191
Trained batch 676 in epoch 7, gen_loss = 0.8412551956479624, disc_loss = 0.0731869808520621
Trained batch 677 in epoch 7, gen_loss = 0.8409111370555068, disc_loss = 0.07325088196217047
Trained batch 678 in epoch 7, gen_loss = 0.8408723786934135, disc_loss = 0.07318250647031418
Trained batch 679 in epoch 7, gen_loss = 0.8411123712273205, disc_loss = 0.07339922922444256
Trained batch 680 in epoch 7, gen_loss = 0.8408535690909791, disc_loss = 0.0733822519848569
Trained batch 681 in epoch 7, gen_loss = 0.8405223352468608, disc_loss = 0.07335747451496875
Trained batch 682 in epoch 7, gen_loss = 0.8405286425378278, disc_loss = 0.07338537613685361
Trained batch 683 in epoch 7, gen_loss = 0.8405337223009757, disc_loss = 0.07333310209595931
Trained batch 684 in epoch 7, gen_loss = 0.8410366389873254, disc_loss = 0.07364510597701926
Trained batch 685 in epoch 7, gen_loss = 0.8406756821770015, disc_loss = 0.07367760001385786
Trained batch 686 in epoch 7, gen_loss = 0.8402798391846069, disc_loss = 0.0736877069262221
Trained batch 687 in epoch 7, gen_loss = 0.8398831295239371, disc_loss = 0.07370067692935726
Trained batch 688 in epoch 7, gen_loss = 0.8401911574455062, disc_loss = 0.07367933926230677
Trained batch 689 in epoch 7, gen_loss = 0.8402495690877887, disc_loss = 0.07361850835976826
Trained batch 690 in epoch 7, gen_loss = 0.840011913334754, disc_loss = 0.07357669745972205
Trained batch 691 in epoch 7, gen_loss = 0.8395860012556087, disc_loss = 0.07376010574109723
Trained batch 692 in epoch 7, gen_loss = 0.8403221043673429, disc_loss = 0.07395449648698602
Trained batch 693 in epoch 7, gen_loss = 0.8400565232942016, disc_loss = 0.07390608952276044
Trained batch 694 in epoch 7, gen_loss = 0.8402555268445461, disc_loss = 0.07383095290538647
Trained batch 695 in epoch 7, gen_loss = 0.8402184814043429, disc_loss = 0.07375859954640612
Trained batch 696 in epoch 7, gen_loss = 0.8400567233819017, disc_loss = 0.07378786876583886
Trained batch 697 in epoch 7, gen_loss = 0.8400205367786495, disc_loss = 0.0737615587792885
Trained batch 698 in epoch 7, gen_loss = 0.8401141222113362, disc_loss = 0.07375121514748606
Trained batch 699 in epoch 7, gen_loss = 0.8399281808308192, disc_loss = 0.07373669832412685
Trained batch 700 in epoch 7, gen_loss = 0.8400842743831423, disc_loss = 0.07384032854403817
Trained batch 701 in epoch 7, gen_loss = 0.8396928004729443, disc_loss = 0.07390471194947718
Trained batch 702 in epoch 7, gen_loss = 0.8399163652449889, disc_loss = 0.0738369239014633
Trained batch 703 in epoch 7, gen_loss = 0.840100853449919, disc_loss = 0.07375146296478553
Trained batch 704 in epoch 7, gen_loss = 0.8402813609610212, disc_loss = 0.07366292109144917
Trained batch 705 in epoch 7, gen_loss = 0.8402210577858068, disc_loss = 0.0735792258448329
Trained batch 706 in epoch 7, gen_loss = 0.8406742795184782, disc_loss = 0.0736641776543822
Trained batch 707 in epoch 7, gen_loss = 0.8402617203313753, disc_loss = 0.07378163758802128
Trained batch 708 in epoch 7, gen_loss = 0.8400971006775441, disc_loss = 0.07379268140010588
Trained batch 709 in epoch 7, gen_loss = 0.8403842524743416, disc_loss = 0.0737967634888392
Trained batch 710 in epoch 7, gen_loss = 0.8405427612500519, disc_loss = 0.07384533803705676
Trained batch 711 in epoch 7, gen_loss = 0.8401968503433667, disc_loss = 0.07393135627198001
Trained batch 712 in epoch 7, gen_loss = 0.8404310484420702, disc_loss = 0.0738636955545711
Trained batch 713 in epoch 7, gen_loss = 0.8403725322722053, disc_loss = 0.07383362285229338
Trained batch 714 in epoch 7, gen_loss = 0.8404182314872741, disc_loss = 0.07377298162742095
Trained batch 715 in epoch 7, gen_loss = 0.8402193871290324, disc_loss = 0.07377587293155033
Trained batch 716 in epoch 7, gen_loss = 0.8402821912093807, disc_loss = 0.07376132801569987
Trained batch 717 in epoch 7, gen_loss = 0.8404001459935914, disc_loss = 0.07368736555358825
Trained batch 718 in epoch 7, gen_loss = 0.8404497296985897, disc_loss = 0.0736297174811529
Trained batch 719 in epoch 7, gen_loss = 0.8401813406911162, disc_loss = 0.07367322513212761
Trained batch 720 in epoch 7, gen_loss = 0.8406646753481787, disc_loss = 0.07374989529671186
Trained batch 721 in epoch 7, gen_loss = 0.8406314139881292, disc_loss = 0.07368513761433951
Trained batch 722 in epoch 7, gen_loss = 0.8404650491962459, disc_loss = 0.07365730948189729
Trained batch 723 in epoch 7, gen_loss = 0.840494680799832, disc_loss = 0.07364131296465164
Trained batch 724 in epoch 7, gen_loss = 0.8406981217450109, disc_loss = 0.07357206362331736
Trained batch 725 in epoch 7, gen_loss = 0.8409331673268773, disc_loss = 0.07349567599953781
Trained batch 726 in epoch 7, gen_loss = 0.8408491900895287, disc_loss = 0.0734734356408475
Trained batch 727 in epoch 7, gen_loss = 0.8408616388237083, disc_loss = 0.07341991005987339
Trained batch 728 in epoch 7, gen_loss = 0.840574909711898, disc_loss = 0.07347178650542133
Trained batch 729 in epoch 7, gen_loss = 0.8405324557872668, disc_loss = 0.0734521759112608
Trained batch 730 in epoch 7, gen_loss = 0.8408396191049046, disc_loss = 0.07345137323435044
Trained batch 731 in epoch 7, gen_loss = 0.8410005576786448, disc_loss = 0.07336262154107903
Trained batch 732 in epoch 7, gen_loss = 0.8405923010707714, disc_loss = 0.07350512953426837
Trained batch 733 in epoch 7, gen_loss = 0.8409524356961575, disc_loss = 0.07346652634061203
Trained batch 734 in epoch 7, gen_loss = 0.8409463451022193, disc_loss = 0.07340448078426982
Trained batch 735 in epoch 7, gen_loss = 0.8405656212859828, disc_loss = 0.07342827595826036
Trained batch 736 in epoch 7, gen_loss = 0.8405238960135419, disc_loss = 0.07341260502299388
Trained batch 737 in epoch 7, gen_loss = 0.8402913425996051, disc_loss = 0.0734484772763258
Trained batch 738 in epoch 7, gen_loss = 0.8403832289782203, disc_loss = 0.07353822975539186
Trained batch 739 in epoch 7, gen_loss = 0.8404111105848003, disc_loss = 0.07346737673631995
Trained batch 740 in epoch 7, gen_loss = 0.8404757515621571, disc_loss = 0.07338755110381787
Trained batch 741 in epoch 7, gen_loss = 0.8403885721196382, disc_loss = 0.07334441658626549
Trained batch 742 in epoch 7, gen_loss = 0.8403369682473738, disc_loss = 0.07331276968407319
Trained batch 743 in epoch 7, gen_loss = 0.8404498882992293, disc_loss = 0.07323850929782155
Trained batch 744 in epoch 7, gen_loss = 0.8406554483727321, disc_loss = 0.07316624996371117
Trained batch 745 in epoch 7, gen_loss = 0.8410321482864206, disc_loss = 0.07308372227230356
Trained batch 746 in epoch 7, gen_loss = 0.8408598812867998, disc_loss = 0.07302305437973544
Trained batch 747 in epoch 7, gen_loss = 0.8406845744759004, disc_loss = 0.07298109025500196
Trained batch 748 in epoch 7, gen_loss = 0.8410827616187377, disc_loss = 0.07294631456938859
Trained batch 749 in epoch 7, gen_loss = 0.841322248061498, disc_loss = 0.07294830055038135
Trained batch 750 in epoch 7, gen_loss = 0.841097402032936, disc_loss = 0.07304397647017327
Trained batch 751 in epoch 7, gen_loss = 0.8408253806385588, disc_loss = 0.07306167175200709
Trained batch 752 in epoch 7, gen_loss = 0.841003772667838, disc_loss = 0.07303682854708289
Trained batch 753 in epoch 7, gen_loss = 0.8409908519025191, disc_loss = 0.07300486197245531
Trained batch 754 in epoch 7, gen_loss = 0.8409642285858558, disc_loss = 0.07296481666383364
Trained batch 755 in epoch 7, gen_loss = 0.8410580396336853, disc_loss = 0.07290795986742649
Trained batch 756 in epoch 7, gen_loss = 0.8408635947631876, disc_loss = 0.07288675544392244
Trained batch 757 in epoch 7, gen_loss = 0.8408837607793883, disc_loss = 0.07282254693041848
Trained batch 758 in epoch 7, gen_loss = 0.8413795650555054, disc_loss = 0.07283549185974796
Trained batch 759 in epoch 7, gen_loss = 0.8412668976344561, disc_loss = 0.07278632058418895
Trained batch 760 in epoch 7, gen_loss = 0.8412047535298531, disc_loss = 0.07276761715401958
Trained batch 761 in epoch 7, gen_loss = 0.8410472244102498, disc_loss = 0.07270003187658358
Trained batch 762 in epoch 7, gen_loss = 0.8411799049002471, disc_loss = 0.07266472352041252
Trained batch 763 in epoch 7, gen_loss = 0.8413865766756198, disc_loss = 0.07278802056421393
Trained batch 764 in epoch 7, gen_loss = 0.8408851946880614, disc_loss = 0.0731168386374229
Trained batch 765 in epoch 7, gen_loss = 0.8407376446705263, disc_loss = 0.07314128160000082
Trained batch 766 in epoch 7, gen_loss = 0.8407482470651649, disc_loss = 0.07317084250570975
Trained batch 767 in epoch 7, gen_loss = 0.8408493610719839, disc_loss = 0.07316496495574636
Trained batch 768 in epoch 7, gen_loss = 0.8404632758722194, disc_loss = 0.07323642083539376
Trained batch 769 in epoch 7, gen_loss = 0.8403744452185445, disc_loss = 0.07321792488506475
Trained batch 770 in epoch 7, gen_loss = 0.840511361680606, disc_loss = 0.0733240657641846
Trained batch 771 in epoch 7, gen_loss = 0.840226371902876, disc_loss = 0.07333820401763283
Trained batch 772 in epoch 7, gen_loss = 0.8403045400919303, disc_loss = 0.07329315738210317
Trained batch 773 in epoch 7, gen_loss = 0.8403325351941802, disc_loss = 0.07330519512286097
Trained batch 774 in epoch 7, gen_loss = 0.8401107514289118, disc_loss = 0.07329303997899256
Trained batch 775 in epoch 7, gen_loss = 0.8399178770553205, disc_loss = 0.0732659406302324
Trained batch 776 in epoch 7, gen_loss = 0.8403121276711866, disc_loss = 0.07327917303309861
Trained batch 777 in epoch 7, gen_loss = 0.8400538665623162, disc_loss = 0.07334708562958746
Trained batch 778 in epoch 7, gen_loss = 0.840301178156641, disc_loss = 0.07333203378122716
Trained batch 779 in epoch 7, gen_loss = 0.8403255067574672, disc_loss = 0.0732603253892217
Trained batch 780 in epoch 7, gen_loss = 0.8405802679580855, disc_loss = 0.0733367236576755
Trained batch 781 in epoch 7, gen_loss = 0.8401217701871072, disc_loss = 0.0734519190809992
Trained batch 782 in epoch 7, gen_loss = 0.839986997583969, disc_loss = 0.07344272737968166
Trained batch 783 in epoch 7, gen_loss = 0.8402911440222239, disc_loss = 0.07338696464002893
Trained batch 784 in epoch 7, gen_loss = 0.840553143259826, disc_loss = 0.07343191299943408
Trained batch 785 in epoch 7, gen_loss = 0.8403278878551099, disc_loss = 0.0734526124230702
Trained batch 786 in epoch 7, gen_loss = 0.840074070564825, disc_loss = 0.0734326540903109
Trained batch 787 in epoch 7, gen_loss = 0.8400057622699568, disc_loss = 0.07337674317021055
Trained batch 788 in epoch 7, gen_loss = 0.8403542477292857, disc_loss = 0.07332387768648121
Trained batch 789 in epoch 7, gen_loss = 0.8403160911194886, disc_loss = 0.07341747617797006
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.4645264446735382, disc_loss = 0.15463687479496002
Trained batch 1 in epoch 8, gen_loss = 0.6149822622537613, disc_loss = 0.10424481891095638
Trained batch 2 in epoch 8, gen_loss = 0.7333702544371287, disc_loss = 0.10081695641080539
Trained batch 3 in epoch 8, gen_loss = 0.7614283487200737, disc_loss = 0.10263667162507772
Trained batch 4 in epoch 8, gen_loss = 0.7275796353816986, disc_loss = 0.11216872557997704
Trained batch 5 in epoch 8, gen_loss = 0.7637772113084793, disc_loss = 0.09778290459265311
Trained batch 6 in epoch 8, gen_loss = 0.7857158141476768, disc_loss = 0.09667319139199597
Trained batch 7 in epoch 8, gen_loss = 0.7603253237903118, disc_loss = 0.09950801800005138
Trained batch 8 in epoch 8, gen_loss = 0.7665223975976309, disc_loss = 0.09301619417965412
Trained batch 9 in epoch 8, gen_loss = 0.7628035694360733, disc_loss = 0.08750947285443544
Trained batch 10 in epoch 8, gen_loss = 0.7519679638472471, disc_loss = 0.08697855218567631
Trained batch 11 in epoch 8, gen_loss = 0.7587346062064171, disc_loss = 0.08707491075620055
Trained batch 12 in epoch 8, gen_loss = 0.7678849261540633, disc_loss = 0.08337263204157352
Trained batch 13 in epoch 8, gen_loss = 0.7486166421856199, disc_loss = 0.09011213388293982
Trained batch 14 in epoch 8, gen_loss = 0.7623656173547109, disc_loss = 0.09002027375002702
Trained batch 15 in epoch 8, gen_loss = 0.7870183195918798, disc_loss = 0.087777373730205
Trained batch 16 in epoch 8, gen_loss = 0.7781822523650002, disc_loss = 0.08988451333168675
Trained batch 17 in epoch 8, gen_loss = 0.7716583030091392, disc_loss = 0.0885653958345453
Trained batch 18 in epoch 8, gen_loss = 0.7901055389329007, disc_loss = 0.09680937299210775
Trained batch 19 in epoch 8, gen_loss = 0.780570949614048, disc_loss = 0.09723911499604583
Trained batch 20 in epoch 8, gen_loss = 0.7786987324555715, disc_loss = 0.09658417025847095
Trained batch 21 in epoch 8, gen_loss = 0.7817224304784428, disc_loss = 0.09318857148967007
Trained batch 22 in epoch 8, gen_loss = 0.8007246242917102, disc_loss = 0.09666582277935484
Trained batch 23 in epoch 8, gen_loss = 0.7926992413898309, disc_loss = 0.09613002200300495
Trained batch 24 in epoch 8, gen_loss = 0.7904396069049835, disc_loss = 0.09371643260121346
Trained batch 25 in epoch 8, gen_loss = 0.7803996285566916, disc_loss = 0.09591135053107372
Trained batch 26 in epoch 8, gen_loss = 0.7932335789556857, disc_loss = 0.09676662680727464
Trained batch 27 in epoch 8, gen_loss = 0.8031190069658416, disc_loss = 0.09741908271930047
Trained batch 28 in epoch 8, gen_loss = 0.7965393816602642, disc_loss = 0.09855763729790161
Trained batch 29 in epoch 8, gen_loss = 0.7961668342351913, disc_loss = 0.09634099888304869
Trained batch 30 in epoch 8, gen_loss = 0.789286010688351, disc_loss = 0.09729035427012751
Trained batch 31 in epoch 8, gen_loss = 0.7909457618370652, disc_loss = 0.09607382665853947
Trained batch 32 in epoch 8, gen_loss = 0.793352568691427, disc_loss = 0.0951725658819531
Trained batch 33 in epoch 8, gen_loss = 0.7941823312464882, disc_loss = 0.09343848059720852
Trained batch 34 in epoch 8, gen_loss = 0.7886084718363625, disc_loss = 0.09548145905137062
Trained batch 35 in epoch 8, gen_loss = 0.8043514117598534, disc_loss = 0.09645953805496295
Trained batch 36 in epoch 8, gen_loss = 0.7992911346860834, disc_loss = 0.09586555359734071
Trained batch 37 in epoch 8, gen_loss = 0.7962877962150072, disc_loss = 0.0969353336840868
Trained batch 38 in epoch 8, gen_loss = 0.8071902738167689, disc_loss = 0.09591989687237984
Trained batch 39 in epoch 8, gen_loss = 0.8089871846139431, disc_loss = 0.09408623040653766
Trained batch 40 in epoch 8, gen_loss = 0.81378231615555, disc_loss = 0.09211768805072075
Trained batch 41 in epoch 8, gen_loss = 0.8139479749259495, disc_loss = 0.09163136793566602
Trained batch 42 in epoch 8, gen_loss = 0.8116102391897246, disc_loss = 0.09128101356327534
Trained batch 43 in epoch 8, gen_loss = 0.8091700490225445, disc_loss = 0.08989983132447708
Trained batch 44 in epoch 8, gen_loss = 0.812608516878552, disc_loss = 0.08813123580896193
Trained batch 45 in epoch 8, gen_loss = 0.8122722862855248, disc_loss = 0.0866939996207214
Trained batch 46 in epoch 8, gen_loss = 0.8194981756362509, disc_loss = 0.08529475408586416
Trained batch 47 in epoch 8, gen_loss = 0.825932156915466, disc_loss = 0.08550994453253224
Trained batch 48 in epoch 8, gen_loss = 0.8206396899661239, disc_loss = 0.08764219388593825
Trained batch 49 in epoch 8, gen_loss = 0.8205897659063339, disc_loss = 0.0867691114358604
Trained batch 50 in epoch 8, gen_loss = 0.8255509576376747, disc_loss = 0.08721950896741713
Trained batch 51 in epoch 8, gen_loss = 0.8258353443099902, disc_loss = 0.0859957961544681
Trained batch 52 in epoch 8, gen_loss = 0.8266364262913758, disc_loss = 0.08492379658416195
Trained batch 53 in epoch 8, gen_loss = 0.8265173484881719, disc_loss = 0.0842254527637528
Trained batch 54 in epoch 8, gen_loss = 0.8343583524227143, disc_loss = 0.08364711933853951
Trained batch 55 in epoch 8, gen_loss = 0.8373989446886948, disc_loss = 0.08238884232871767
Trained batch 56 in epoch 8, gen_loss = 0.8376871394483667, disc_loss = 0.082081795898838
Trained batch 57 in epoch 8, gen_loss = 0.8346690479023703, disc_loss = 0.08127110282858384
Trained batch 58 in epoch 8, gen_loss = 0.83094360919322, disc_loss = 0.08084203957943088
Trained batch 59 in epoch 8, gen_loss = 0.8323250080148379, disc_loss = 0.0796368148488303
Trained batch 60 in epoch 8, gen_loss = 0.8378222833891384, disc_loss = 0.07941337787836301
Trained batch 61 in epoch 8, gen_loss = 0.8365728715735097, disc_loss = 0.07865685095349627
Trained batch 62 in epoch 8, gen_loss = 0.8359207875198789, disc_loss = 0.07828025635154474
Trained batch 63 in epoch 8, gen_loss = 0.8334717317484319, disc_loss = 0.07807576571940444
Trained batch 64 in epoch 8, gen_loss = 0.8347110716196207, disc_loss = 0.07722761461941095
Trained batch 65 in epoch 8, gen_loss = 0.836805515668609, disc_loss = 0.07947783389439185
Trained batch 66 in epoch 8, gen_loss = 0.8376429503533378, disc_loss = 0.07864810768236864
Trained batch 67 in epoch 8, gen_loss = 0.8350004891262335, disc_loss = 0.07921018240535084
Trained batch 68 in epoch 8, gen_loss = 0.8323677264261937, disc_loss = 0.07909738939201487
Trained batch 69 in epoch 8, gen_loss = 0.836152691926275, disc_loss = 0.07873369410101856
Trained batch 70 in epoch 8, gen_loss = 0.8353128949521293, disc_loss = 0.07793916491660434
Trained batch 71 in epoch 8, gen_loss = 0.835704809675614, disc_loss = 0.07727565898353027
Trained batch 72 in epoch 8, gen_loss = 0.8338173607440844, disc_loss = 0.07663812281640425
Trained batch 73 in epoch 8, gen_loss = 0.8410380623630576, disc_loss = 0.07664674930777904
Trained batch 74 in epoch 8, gen_loss = 0.8435375638802847, disc_loss = 0.07585552719732126
Trained batch 75 in epoch 8, gen_loss = 0.8419723130370441, disc_loss = 0.07533127454256541
Trained batch 76 in epoch 8, gen_loss = 0.8400195322253488, disc_loss = 0.07504816055781656
Trained batch 77 in epoch 8, gen_loss = 0.8418099914605801, disc_loss = 0.07441237227370341
Trained batch 78 in epoch 8, gen_loss = 0.8409307323679139, disc_loss = 0.07466942743881594
Trained batch 79 in epoch 8, gen_loss = 0.83592498190701, disc_loss = 0.0762051233323291
Trained batch 80 in epoch 8, gen_loss = 0.838160432783174, disc_loss = 0.07641624992736328
Trained batch 81 in epoch 8, gen_loss = 0.8421337172025587, disc_loss = 0.07579434497236479
Trained batch 82 in epoch 8, gen_loss = 0.8408742952777679, disc_loss = 0.07538003799875817
Trained batch 83 in epoch 8, gen_loss = 0.8431555909060297, disc_loss = 0.07482443916212235
Trained batch 84 in epoch 8, gen_loss = 0.8430408067563001, disc_loss = 0.07415629758992616
Trained batch 85 in epoch 8, gen_loss = 0.842429826079413, disc_loss = 0.07392968638085348
Trained batch 86 in epoch 8, gen_loss = 0.842752420696719, disc_loss = 0.07328585590953114
Trained batch 87 in epoch 8, gen_loss = 0.8464942977509715, disc_loss = 0.07458643627945673
Trained batch 88 in epoch 8, gen_loss = 0.8446861281153861, disc_loss = 0.07441130678138036
Trained batch 89 in epoch 8, gen_loss = 0.8429772486289342, disc_loss = 0.07545431136257119
Trained batch 90 in epoch 8, gen_loss = 0.8423898740784153, disc_loss = 0.07507232138580018
Trained batch 91 in epoch 8, gen_loss = 0.8420734266224115, disc_loss = 0.07502491023067547
Trained batch 92 in epoch 8, gen_loss = 0.8435365644193464, disc_loss = 0.07452444575967328
Trained batch 93 in epoch 8, gen_loss = 0.8425541073083878, disc_loss = 0.07437200130934411
Trained batch 94 in epoch 8, gen_loss = 0.843620848341992, disc_loss = 0.07391247961081956
Trained batch 95 in epoch 8, gen_loss = 0.8454379634931684, disc_loss = 0.07353316767451663
Trained batch 96 in epoch 8, gen_loss = 0.8482176295875274, disc_loss = 0.07305321462221981
Trained batch 97 in epoch 8, gen_loss = 0.8474458708446853, disc_loss = 0.07273893430829048
Trained batch 98 in epoch 8, gen_loss = 0.8478106582405591, disc_loss = 0.07243747113630025
Trained batch 99 in epoch 8, gen_loss = 0.8502879139780998, disc_loss = 0.07197190254926682
Trained batch 100 in epoch 8, gen_loss = 0.8496423555482732, disc_loss = 0.07177830907968011
Trained batch 101 in epoch 8, gen_loss = 0.8481418732918945, disc_loss = 0.07128074547896783
Trained batch 102 in epoch 8, gen_loss = 0.8474912374343687, disc_loss = 0.07233534407919472
Trained batch 103 in epoch 8, gen_loss = 0.8480075554778943, disc_loss = 0.07181204710370646
Trained batch 104 in epoch 8, gen_loss = 0.8454941604818617, disc_loss = 0.07202943426867327
Trained batch 105 in epoch 8, gen_loss = 0.8477402860825917, disc_loss = 0.07200685078453906
Trained batch 106 in epoch 8, gen_loss = 0.8489382481463602, disc_loss = 0.07157877879652465
Trained batch 107 in epoch 8, gen_loss = 0.8475102746376285, disc_loss = 0.07172277092036826
Trained batch 108 in epoch 8, gen_loss = 0.8438928212047717, disc_loss = 0.07176305659525438
Trained batch 109 in epoch 8, gen_loss = 0.8438958739692515, disc_loss = 0.07130709519101815
Trained batch 110 in epoch 8, gen_loss = 0.8467033712176589, disc_loss = 0.07166923285537474
Trained batch 111 in epoch 8, gen_loss = 0.8466018313275916, disc_loss = 0.07133040389245641
Trained batch 112 in epoch 8, gen_loss = 0.846048941918179, disc_loss = 0.07120578164086405
Trained batch 113 in epoch 8, gen_loss = 0.8463952946558333, disc_loss = 0.07081391624779555
Trained batch 114 in epoch 8, gen_loss = 0.8490197210208229, disc_loss = 0.07032748991218599
Trained batch 115 in epoch 8, gen_loss = 0.8522200129669288, disc_loss = 0.07094223783672626
Trained batch 116 in epoch 8, gen_loss = 0.8515151272981595, disc_loss = 0.0707071674350872
Trained batch 117 in epoch 8, gen_loss = 0.8512515534283751, disc_loss = 0.07052212633918654
Trained batch 118 in epoch 8, gen_loss = 0.8514915782363475, disc_loss = 0.07007970725882705
Trained batch 119 in epoch 8, gen_loss = 0.8519937279323737, disc_loss = 0.0695564069901593
Trained batch 120 in epoch 8, gen_loss = 0.8537053916572539, disc_loss = 0.06966759287174945
Trained batch 121 in epoch 8, gen_loss = 0.8529704684605364, disc_loss = 0.06932410826433266
Trained batch 122 in epoch 8, gen_loss = 0.8538863137970126, disc_loss = 0.06883595841066019
Trained batch 123 in epoch 8, gen_loss = 0.85384972994366, disc_loss = 0.06844765890855342
Trained batch 124 in epoch 8, gen_loss = 0.8557386214733124, disc_loss = 0.06806555556878448
Trained batch 125 in epoch 8, gen_loss = 0.8529615106563719, disc_loss = 0.06829899241630402
Trained batch 126 in epoch 8, gen_loss = 0.8558456257102997, disc_loss = 0.06823007565534372
Trained batch 127 in epoch 8, gen_loss = 0.8574943447019905, disc_loss = 0.06782169898724533
Trained batch 128 in epoch 8, gen_loss = 0.8583229084809622, disc_loss = 0.06827850769411108
Trained batch 129 in epoch 8, gen_loss = 0.8578751254540223, disc_loss = 0.06802544066180977
Trained batch 130 in epoch 8, gen_loss = 0.8556098194067715, disc_loss = 0.06856730898472531
Trained batch 131 in epoch 8, gen_loss = 0.8552181244348035, disc_loss = 0.06827711753871743
Trained batch 132 in epoch 8, gen_loss = 0.8562115424109581, disc_loss = 0.06785475974202268
Trained batch 133 in epoch 8, gen_loss = 0.8587303982296987, disc_loss = 0.06753713717169837
Trained batch 134 in epoch 8, gen_loss = 0.8583830416202545, disc_loss = 0.0676414191895337
Trained batch 135 in epoch 8, gen_loss = 0.8576710519983488, disc_loss = 0.0675711810540901
Trained batch 136 in epoch 8, gen_loss = 0.8566858231151191, disc_loss = 0.06741925877226639
Trained batch 137 in epoch 8, gen_loss = 0.8583884621443956, disc_loss = 0.06725981671268633
Trained batch 138 in epoch 8, gen_loss = 0.8574038951945819, disc_loss = 0.06713430488669722
Trained batch 139 in epoch 8, gen_loss = 0.8570140998278345, disc_loss = 0.06691378939431161
Trained batch 140 in epoch 8, gen_loss = 0.858383833727938, disc_loss = 0.06664766088881074
Trained batch 141 in epoch 8, gen_loss = 0.8591701214162397, disc_loss = 0.06625965064798127
Trained batch 142 in epoch 8, gen_loss = 0.8595166075062919, disc_loss = 0.06662455362990707
Trained batch 143 in epoch 8, gen_loss = 0.8596753873344924, disc_loss = 0.06626636171778147
Trained batch 144 in epoch 8, gen_loss = 0.8588215094188164, disc_loss = 0.06632772945188757
Trained batch 145 in epoch 8, gen_loss = 0.8595373408026892, disc_loss = 0.06603511322404526
Trained batch 146 in epoch 8, gen_loss = 0.8606552532335527, disc_loss = 0.06582438704069882
Trained batch 147 in epoch 8, gen_loss = 0.8611240997105032, disc_loss = 0.0655090887558873
Trained batch 148 in epoch 8, gen_loss = 0.860981816213403, disc_loss = 0.06522099304031706
Trained batch 149 in epoch 8, gen_loss = 0.8608679610490799, disc_loss = 0.06497853990954658
Trained batch 150 in epoch 8, gen_loss = 0.8605706326614152, disc_loss = 0.06500308138213509
Trained batch 151 in epoch 8, gen_loss = 0.8604076683129135, disc_loss = 0.06470797879094455
Trained batch 152 in epoch 8, gen_loss = 0.8618792527251773, disc_loss = 0.06452517286003902
Trained batch 153 in epoch 8, gen_loss = 0.8619537986331172, disc_loss = 0.06439592211821733
Trained batch 154 in epoch 8, gen_loss = 0.8619143353354546, disc_loss = 0.06425625476685744
Trained batch 155 in epoch 8, gen_loss = 0.8612744848315532, disc_loss = 0.06409587483339681
Trained batch 156 in epoch 8, gen_loss = 0.8600932433726681, disc_loss = 0.06414640710576419
Trained batch 157 in epoch 8, gen_loss = 0.8609686608933196, disc_loss = 0.06394414463717066
Trained batch 158 in epoch 8, gen_loss = 0.8615840600346619, disc_loss = 0.06369507145546612
Trained batch 159 in epoch 8, gen_loss = 0.8605773588642478, disc_loss = 0.06363415679952596
Trained batch 160 in epoch 8, gen_loss = 0.8636781863914513, disc_loss = 0.06373998517263102
Trained batch 161 in epoch 8, gen_loss = 0.8650894052820441, disc_loss = 0.06354573641811716
Trained batch 162 in epoch 8, gen_loss = 0.8649637327969439, disc_loss = 0.06325322937254617
Trained batch 163 in epoch 8, gen_loss = 0.8639928155192514, disc_loss = 0.06303953513696153
Trained batch 164 in epoch 8, gen_loss = 0.8643415763522639, disc_loss = 0.06284038092884602
Trained batch 165 in epoch 8, gen_loss = 0.8655433448323284, disc_loss = 0.06257423147256205
Trained batch 166 in epoch 8, gen_loss = 0.8663920494253764, disc_loss = 0.06224954389537612
Trained batch 167 in epoch 8, gen_loss = 0.8669978594850927, disc_loss = 0.06218763270382104
Trained batch 168 in epoch 8, gen_loss = 0.8654348668614789, disc_loss = 0.06228215086753287
Trained batch 169 in epoch 8, gen_loss = 0.866040317977176, disc_loss = 0.06199645377312075
Trained batch 170 in epoch 8, gen_loss = 0.8658117803565243, disc_loss = 0.06173945677178035
Trained batch 171 in epoch 8, gen_loss = 0.8658527712835822, disc_loss = 0.06174095264408564
Trained batch 172 in epoch 8, gen_loss = 0.8646078249278096, disc_loss = 0.06188615083403756
Trained batch 173 in epoch 8, gen_loss = 0.866346532072144, disc_loss = 0.061669441060452114
Trained batch 174 in epoch 8, gen_loss = 0.8675611293315888, disc_loss = 0.06156280569998281
Trained batch 175 in epoch 8, gen_loss = 0.865909006954594, disc_loss = 0.06176772723450664
Trained batch 176 in epoch 8, gen_loss = 0.8647780413344756, disc_loss = 0.06182876626282173
Trained batch 177 in epoch 8, gen_loss = 0.8659163460637747, disc_loss = 0.06207893760822546
Trained batch 178 in epoch 8, gen_loss = 0.8653740068720706, disc_loss = 0.061945810989481945
Trained batch 179 in epoch 8, gen_loss = 0.8636726347936524, disc_loss = 0.06287871648091822
Trained batch 180 in epoch 8, gen_loss = 0.8655213593448723, disc_loss = 0.06279663674955292
Trained batch 181 in epoch 8, gen_loss = 0.86583129799628, disc_loss = 0.06324504184086326
Trained batch 182 in epoch 8, gen_loss = 0.8650922581472033, disc_loss = 0.06352087659150606
Trained batch 183 in epoch 8, gen_loss = 0.8642949172012184, disc_loss = 0.06360274787394977
Trained batch 184 in epoch 8, gen_loss = 0.8653136461167722, disc_loss = 0.06340688877059399
Trained batch 185 in epoch 8, gen_loss = 0.8655966323229575, disc_loss = 0.06342530902725474
Trained batch 186 in epoch 8, gen_loss = 0.8661298367747648, disc_loss = 0.06320521099253852
Trained batch 187 in epoch 8, gen_loss = 0.8647039166473328, disc_loss = 0.06379244959308825
Trained batch 188 in epoch 8, gen_loss = 0.8645515635846153, disc_loss = 0.06401451778839584
Trained batch 189 in epoch 8, gen_loss = 0.8660515689536145, disc_loss = 0.0642666926828066
Trained batch 190 in epoch 8, gen_loss = 0.8663513072186115, disc_loss = 0.06401947237482948
Trained batch 191 in epoch 8, gen_loss = 0.8644299207565685, disc_loss = 0.06497474568944502
Trained batch 192 in epoch 8, gen_loss = 0.8639948558004409, disc_loss = 0.06502468655503553
Trained batch 193 in epoch 8, gen_loss = 0.865557126624068, disc_loss = 0.06533310769039408
Trained batch 194 in epoch 8, gen_loss = 0.8643426370926393, disc_loss = 0.065396850491659
Trained batch 195 in epoch 8, gen_loss = 0.8637633890825875, disc_loss = 0.06528589503164878
Trained batch 196 in epoch 8, gen_loss = 0.8659302263998138, disc_loss = 0.06578702545077138
Trained batch 197 in epoch 8, gen_loss = 0.864501483663164, disc_loss = 0.06596196632164371
Trained batch 198 in epoch 8, gen_loss = 0.864503913339059, disc_loss = 0.06584710608372212
Trained batch 199 in epoch 8, gen_loss = 0.8634755943715572, disc_loss = 0.06570835589664056
Trained batch 200 in epoch 8, gen_loss = 0.8632157722219306, disc_loss = 0.0656403941009657
Trained batch 201 in epoch 8, gen_loss = 0.8627793094014177, disc_loss = 0.06545711989459203
Trained batch 202 in epoch 8, gen_loss = 0.8632909530782934, disc_loss = 0.06541044643295589
Trained batch 203 in epoch 8, gen_loss = 0.8635926131232112, disc_loss = 0.06513689269594775
Trained batch 204 in epoch 8, gen_loss = 0.8637162797334718, disc_loss = 0.06486604434279043
Trained batch 205 in epoch 8, gen_loss = 0.862799898368641, disc_loss = 0.065055117759293
Trained batch 206 in epoch 8, gen_loss = 0.8636755509940899, disc_loss = 0.06487766373227688
Trained batch 207 in epoch 8, gen_loss = 0.8649981782700007, disc_loss = 0.0651073953060684
Trained batch 208 in epoch 8, gen_loss = 0.8650782819855156, disc_loss = 0.06484258499076706
Trained batch 209 in epoch 8, gen_loss = 0.8641364470833823, disc_loss = 0.06484149264925647
Trained batch 210 in epoch 8, gen_loss = 0.8640137087394841, disc_loss = 0.06463700785164796
Trained batch 211 in epoch 8, gen_loss = 0.8649393973766633, disc_loss = 0.06440865343111514
Trained batch 212 in epoch 8, gen_loss = 0.8647139784595776, disc_loss = 0.06436139316967046
Trained batch 213 in epoch 8, gen_loss = 0.8649766897765275, disc_loss = 0.06410635217249602
Trained batch 214 in epoch 8, gen_loss = 0.8642641396023506, disc_loss = 0.06408830390550023
Trained batch 215 in epoch 8, gen_loss = 0.8636995800943287, disc_loss = 0.06396542980844432
Trained batch 216 in epoch 8, gen_loss = 0.8643717934733711, disc_loss = 0.06379561139751345
Trained batch 217 in epoch 8, gen_loss = 0.865314747078703, disc_loss = 0.06357560180119076
Trained batch 218 in epoch 8, gen_loss = 0.8659662747219817, disc_loss = 0.06359526705311518
Trained batch 219 in epoch 8, gen_loss = 0.8654380349950357, disc_loss = 0.06372226848986677
Trained batch 220 in epoch 8, gen_loss = 0.8645665377243612, disc_loss = 0.0636997665194331
Trained batch 221 in epoch 8, gen_loss = 0.8653867745453173, disc_loss = 0.06347530266177748
Trained batch 222 in epoch 8, gen_loss = 0.8655378862614055, disc_loss = 0.06332413233073236
Trained batch 223 in epoch 8, gen_loss = 0.8658667338479843, disc_loss = 0.06309235487424303
Trained batch 224 in epoch 8, gen_loss = 0.864987225400077, disc_loss = 0.0630864714148144
Trained batch 225 in epoch 8, gen_loss = 0.8655622014693455, disc_loss = 0.06292284124909975
Trained batch 226 in epoch 8, gen_loss = 0.8653985659719039, disc_loss = 0.06280341324096932
Trained batch 227 in epoch 8, gen_loss = 0.8650472100105202, disc_loss = 0.06270203495749452
Trained batch 228 in epoch 8, gen_loss = 0.8645151649239803, disc_loss = 0.06261928358184393
Trained batch 229 in epoch 8, gen_loss = 0.8665083090896192, disc_loss = 0.0637230046235187
Trained batch 230 in epoch 8, gen_loss = 0.8663766031915491, disc_loss = 0.06368233803538727
Trained batch 231 in epoch 8, gen_loss = 0.8656060961556846, disc_loss = 0.0635639177133522
Trained batch 232 in epoch 8, gen_loss = 0.8648547539127743, disc_loss = 0.06369998956562815
Trained batch 233 in epoch 8, gen_loss = 0.8652002463738123, disc_loss = 0.06397758909644416
Trained batch 234 in epoch 8, gen_loss = 0.8637729100724484, disc_loss = 0.06409651806498778
Trained batch 235 in epoch 8, gen_loss = 0.8638902757379968, disc_loss = 0.06387291641677019
Trained batch 236 in epoch 8, gen_loss = 0.8637869132973474, disc_loss = 0.06368117057816577
Trained batch 237 in epoch 8, gen_loss = 0.8639651668422362, disc_loss = 0.06356855918371565
Trained batch 238 in epoch 8, gen_loss = 0.8643606603145599, disc_loss = 0.06406020399409046
Trained batch 239 in epoch 8, gen_loss = 0.8630133607735236, disc_loss = 0.0647920822550077
Trained batch 240 in epoch 8, gen_loss = 0.8624092863555766, disc_loss = 0.06474488585437667
Trained batch 241 in epoch 8, gen_loss = 0.8631905045144814, disc_loss = 0.06551473983178639
Trained batch 242 in epoch 8, gen_loss = 0.8622573406853303, disc_loss = 0.06577180689124107
Trained batch 243 in epoch 8, gen_loss = 0.860942791597765, disc_loss = 0.06592627848139734
Trained batch 244 in epoch 8, gen_loss = 0.8613274222734023, disc_loss = 0.065973947468993
Trained batch 245 in epoch 8, gen_loss = 0.861599197353774, disc_loss = 0.06579219773828196
Trained batch 246 in epoch 8, gen_loss = 0.8612808666007239, disc_loss = 0.06574263578838846
Trained batch 247 in epoch 8, gen_loss = 0.8613481950615683, disc_loss = 0.06579019040462651
Trained batch 248 in epoch 8, gen_loss = 0.860581303815765, disc_loss = 0.06572528077050085
Trained batch 249 in epoch 8, gen_loss = 0.8595855392217636, disc_loss = 0.0657606051992625
Trained batch 250 in epoch 8, gen_loss = 0.8601566993620291, disc_loss = 0.06577394725903275
Trained batch 251 in epoch 8, gen_loss = 0.8596422836657555, disc_loss = 0.06575401291243792
Trained batch 252 in epoch 8, gen_loss = 0.8596437141122554, disc_loss = 0.06574290488541068
Trained batch 253 in epoch 8, gen_loss = 0.8585889178702212, disc_loss = 0.06593354860152023
Trained batch 254 in epoch 8, gen_loss = 0.8593199121017082, disc_loss = 0.06609110664028456
Trained batch 255 in epoch 8, gen_loss = 0.8589395241579041, disc_loss = 0.06591391805523017
Trained batch 256 in epoch 8, gen_loss = 0.8584065774767315, disc_loss = 0.06583682219189835
Trained batch 257 in epoch 8, gen_loss = 0.85850169157335, disc_loss = 0.06570119076307372
Trained batch 258 in epoch 8, gen_loss = 0.8592376445481216, disc_loss = 0.0657338203491938
Trained batch 259 in epoch 8, gen_loss = 0.8589268389802712, disc_loss = 0.06563757927909207
Trained batch 260 in epoch 8, gen_loss = 0.8581076117082574, disc_loss = 0.06568505852465371
Trained batch 261 in epoch 8, gen_loss = 0.8583410003485571, disc_loss = 0.06616756013409725
Trained batch 262 in epoch 8, gen_loss = 0.857778714070302, disc_loss = 0.06603788781889888
Trained batch 263 in epoch 8, gen_loss = 0.8578095213707649, disc_loss = 0.06591331169086818
Trained batch 264 in epoch 8, gen_loss = 0.8572151866723906, disc_loss = 0.06590231179593588
Trained batch 265 in epoch 8, gen_loss = 0.8566039559760488, disc_loss = 0.06603364462095936
Trained batch 266 in epoch 8, gen_loss = 0.85761226216952, disc_loss = 0.06621681639840932
Trained batch 267 in epoch 8, gen_loss = 0.8574067820141564, disc_loss = 0.0661512852295427
Trained batch 268 in epoch 8, gen_loss = 0.8570928969126208, disc_loss = 0.06600923336813828
Trained batch 269 in epoch 8, gen_loss = 0.8568001236076708, disc_loss = 0.06592956545969678
Trained batch 270 in epoch 8, gen_loss = 0.8565741090097111, disc_loss = 0.06593763764184725
Trained batch 271 in epoch 8, gen_loss = 0.8574150229859001, disc_loss = 0.0659564388830297
Trained batch 272 in epoch 8, gen_loss = 0.8572217724917136, disc_loss = 0.06581400762458806
Trained batch 273 in epoch 8, gen_loss = 0.8565279529260023, disc_loss = 0.06586406512328688
Trained batch 274 in epoch 8, gen_loss = 0.8566753551093015, disc_loss = 0.06575293966823004
Trained batch 275 in epoch 8, gen_loss = 0.8559510207910469, disc_loss = 0.06568425130335263
Trained batch 276 in epoch 8, gen_loss = 0.8567653116551547, disc_loss = 0.06559174789438556
Trained batch 277 in epoch 8, gen_loss = 0.8559496781165651, disc_loss = 0.0656275958703871
Trained batch 278 in epoch 8, gen_loss = 0.8556438687668052, disc_loss = 0.06546928436331798
Trained batch 279 in epoch 8, gen_loss = 0.8552535962845598, disc_loss = 0.065820898533067
Trained batch 280 in epoch 8, gen_loss = 0.8545576776261856, disc_loss = 0.06590872127198187
Trained batch 281 in epoch 8, gen_loss = 0.8541632268234347, disc_loss = 0.06579506137500787
Trained batch 282 in epoch 8, gen_loss = 0.8547419725584899, disc_loss = 0.06597576571246708
Trained batch 283 in epoch 8, gen_loss = 0.8541054279661514, disc_loss = 0.06594027659337653
Trained batch 284 in epoch 8, gen_loss = 0.8541585795712052, disc_loss = 0.06581386916437432
Trained batch 285 in epoch 8, gen_loss = 0.854418190313386, disc_loss = 0.06574606811269544
Trained batch 286 in epoch 8, gen_loss = 0.8549205132270109, disc_loss = 0.06567233093959061
Trained batch 287 in epoch 8, gen_loss = 0.8554617548361421, disc_loss = 0.0654831839217675
Trained batch 288 in epoch 8, gen_loss = 0.8542625962862919, disc_loss = 0.06593487807307843
Trained batch 289 in epoch 8, gen_loss = 0.8542110670229485, disc_loss = 0.06599717691123229
Trained batch 290 in epoch 8, gen_loss = 0.8551402482175335, disc_loss = 0.06638188456437995
Trained batch 291 in epoch 8, gen_loss = 0.8546716855609253, disc_loss = 0.06638151737510495
Trained batch 292 in epoch 8, gen_loss = 0.8539370248545559, disc_loss = 0.06652814931627173
Trained batch 293 in epoch 8, gen_loss = 0.85363097042859, disc_loss = 0.06670332272841158
Trained batch 294 in epoch 8, gen_loss = 0.8535055632308378, disc_loss = 0.06664396624033482
Trained batch 295 in epoch 8, gen_loss = 0.8537137217416957, disc_loss = 0.06650329032453482
Trained batch 296 in epoch 8, gen_loss = 0.8533246148917009, disc_loss = 0.06645939195440825
Trained batch 297 in epoch 8, gen_loss = 0.85332151517372, disc_loss = 0.06650559298987907
Trained batch 298 in epoch 8, gen_loss = 0.8532972233151911, disc_loss = 0.06642284021124144
Trained batch 299 in epoch 8, gen_loss = 0.853771635790666, disc_loss = 0.06629614375376452
Trained batch 300 in epoch 8, gen_loss = 0.8535110224719064, disc_loss = 0.06624942705920121
Trained batch 301 in epoch 8, gen_loss = 0.8540570770470511, disc_loss = 0.06627844145601702
Trained batch 302 in epoch 8, gen_loss = 0.854559987980147, disc_loss = 0.0661200090317615
Trained batch 303 in epoch 8, gen_loss = 0.8537177344490039, disc_loss = 0.06613828296816025
Trained batch 304 in epoch 8, gen_loss = 0.8544434855218793, disc_loss = 0.06605579357014084
Trained batch 305 in epoch 8, gen_loss = 0.8546807776673947, disc_loss = 0.06592582971971556
Trained batch 306 in epoch 8, gen_loss = 0.8540935932813327, disc_loss = 0.06590328809535222
Trained batch 307 in epoch 8, gen_loss = 0.8547193687651065, disc_loss = 0.06577594805502804
Trained batch 308 in epoch 8, gen_loss = 0.8549944707297971, disc_loss = 0.06559666766842351
Trained batch 309 in epoch 8, gen_loss = 0.8549653475323031, disc_loss = 0.06550301593247682
Trained batch 310 in epoch 8, gen_loss = 0.8554850681610046, disc_loss = 0.06537176674483434
Trained batch 311 in epoch 8, gen_loss = 0.8552286167366382, disc_loss = 0.06520855759168999
Trained batch 312 in epoch 8, gen_loss = 0.8544168225682962, disc_loss = 0.06521881350759452
Trained batch 313 in epoch 8, gen_loss = 0.8541641342601959, disc_loss = 0.06523197908755274
Trained batch 314 in epoch 8, gen_loss = 0.8541745856640831, disc_loss = 0.06516702066781739
Trained batch 315 in epoch 8, gen_loss = 0.8544725878517839, disc_loss = 0.06499713165773952
Trained batch 316 in epoch 8, gen_loss = 0.8545579822845639, disc_loss = 0.06487326374959071
Trained batch 317 in epoch 8, gen_loss = 0.855222224720619, disc_loss = 0.0647584659401796
Trained batch 318 in epoch 8, gen_loss = 0.8552774933625165, disc_loss = 0.06458720840005712
Trained batch 319 in epoch 8, gen_loss = 0.8555889555253089, disc_loss = 0.06442269362596562
Trained batch 320 in epoch 8, gen_loss = 0.8558834816250845, disc_loss = 0.06425284579065497
Trained batch 321 in epoch 8, gen_loss = 0.8557790154070588, disc_loss = 0.06417116441659815
Trained batch 322 in epoch 8, gen_loss = 0.8564379727323727, disc_loss = 0.06419855436806109
Trained batch 323 in epoch 8, gen_loss = 0.856223634087745, disc_loss = 0.06411459839494646
Trained batch 324 in epoch 8, gen_loss = 0.8560741086189564, disc_loss = 0.06406657603927529
Trained batch 325 in epoch 8, gen_loss = 0.8555204324378558, disc_loss = 0.06421454268953324
Trained batch 326 in epoch 8, gen_loss = 0.8557942598055627, disc_loss = 0.06417945127461436
Trained batch 327 in epoch 8, gen_loss = 0.8555856313465572, disc_loss = 0.06404932601258113
Trained batch 328 in epoch 8, gen_loss = 0.8555570488461608, disc_loss = 0.06401670374695245
Trained batch 329 in epoch 8, gen_loss = 0.8545329833572561, disc_loss = 0.06416710327718068
Trained batch 330 in epoch 8, gen_loss = 0.8550344279705577, disc_loss = 0.0640559529089383
Trained batch 331 in epoch 8, gen_loss = 0.8548271457653448, disc_loss = 0.06400837088761155
Trained batch 332 in epoch 8, gen_loss = 0.8551379111973015, disc_loss = 0.06386333258050653
Trained batch 333 in epoch 8, gen_loss = 0.8546298834199677, disc_loss = 0.0638507559022749
Trained batch 334 in epoch 8, gen_loss = 0.855575971372092, disc_loss = 0.06412371378530984
Trained batch 335 in epoch 8, gen_loss = 0.8552198153698728, disc_loss = 0.06406160954446975
Trained batch 336 in epoch 8, gen_loss = 0.8544636408546912, disc_loss = 0.06448840560358382
Trained batch 337 in epoch 8, gen_loss = 0.8538026704767047, disc_loss = 0.06468685738847056
Trained batch 338 in epoch 8, gen_loss = 0.854663635161774, disc_loss = 0.06498990474257806
Trained batch 339 in epoch 8, gen_loss = 0.8544560389483676, disc_loss = 0.06502883070942891
Trained batch 340 in epoch 8, gen_loss = 0.853958416631844, disc_loss = 0.06514803764118084
Trained batch 341 in epoch 8, gen_loss = 0.8536189025082783, disc_loss = 0.0651744203301615
Trained batch 342 in epoch 8, gen_loss = 0.853980413418122, disc_loss = 0.06583470836384955
Trained batch 343 in epoch 8, gen_loss = 0.8535788713326288, disc_loss = 0.06581963848208922
Trained batch 344 in epoch 8, gen_loss = 0.8529557386170263, disc_loss = 0.06590836696407718
Trained batch 345 in epoch 8, gen_loss = 0.8530300825489738, disc_loss = 0.06584443261098612
Trained batch 346 in epoch 8, gen_loss = 0.853192857689404, disc_loss = 0.06577139528554136
Trained batch 347 in epoch 8, gen_loss = 0.8531481321344431, disc_loss = 0.0658655791829779
Trained batch 348 in epoch 8, gen_loss = 0.8521476537416179, disc_loss = 0.06611607845386966
Trained batch 349 in epoch 8, gen_loss = 0.8526506077391761, disc_loss = 0.06610171883633094
Trained batch 350 in epoch 8, gen_loss = 0.8529265450785982, disc_loss = 0.06599540585397273
Trained batch 351 in epoch 8, gen_loss = 0.8525373005223545, disc_loss = 0.06602938749843319
Trained batch 352 in epoch 8, gen_loss = 0.8518709115705139, disc_loss = 0.06611992874005994
Trained batch 353 in epoch 8, gen_loss = 0.851659889190884, disc_loss = 0.06615790631490533
Trained batch 354 in epoch 8, gen_loss = 0.8525575385127269, disc_loss = 0.06649568210369054
Trained batch 355 in epoch 8, gen_loss = 0.8519760366068797, disc_loss = 0.06650882667804325
Trained batch 356 in epoch 8, gen_loss = 0.8516561663618275, disc_loss = 0.06649980518095591
Trained batch 357 in epoch 8, gen_loss = 0.851684207606582, disc_loss = 0.06643953504607955
Trained batch 358 in epoch 8, gen_loss = 0.851847036220237, disc_loss = 0.0663058959754459
Trained batch 359 in epoch 8, gen_loss = 0.8521439730293221, disc_loss = 0.06616196682443842
Trained batch 360 in epoch 8, gen_loss = 0.8520160519680489, disc_loss = 0.06603867864917314
Trained batch 361 in epoch 8, gen_loss = 0.8523744352120721, disc_loss = 0.06588471764878714
Trained batch 362 in epoch 8, gen_loss = 0.8525059470296235, disc_loss = 0.06582179870430802
Trained batch 363 in epoch 8, gen_loss = 0.8517471343115136, disc_loss = 0.06591884001378216
Trained batch 364 in epoch 8, gen_loss = 0.8519552768909768, disc_loss = 0.06580956130837129
Trained batch 365 in epoch 8, gen_loss = 0.8523434858993103, disc_loss = 0.06572181816579255
Trained batch 366 in epoch 8, gen_loss = 0.8532619485250935, disc_loss = 0.065951280596562
Trained batch 367 in epoch 8, gen_loss = 0.8526645421819843, disc_loss = 0.06610596752548388
Trained batch 368 in epoch 8, gen_loss = 0.8522879808414273, disc_loss = 0.06600865082270126
Trained batch 369 in epoch 8, gen_loss = 0.8519949860669471, disc_loss = 0.06606599387108676
Trained batch 370 in epoch 8, gen_loss = 0.8526830772023317, disc_loss = 0.0660745787956423
Trained batch 371 in epoch 8, gen_loss = 0.8529979295788273, disc_loss = 0.06592827443639317
Trained batch 372 in epoch 8, gen_loss = 0.8533303076875753, disc_loss = 0.06580383545436944
Trained batch 373 in epoch 8, gen_loss = 0.8532341050113587, disc_loss = 0.06570196856575256
Trained batch 374 in epoch 8, gen_loss = 0.8531512785752614, disc_loss = 0.0655912576528887
Trained batch 375 in epoch 8, gen_loss = 0.8526995411103077, disc_loss = 0.065675821255625
Trained batch 376 in epoch 8, gen_loss = 0.8543533916024377, disc_loss = 0.06643061693733068
Trained batch 377 in epoch 8, gen_loss = 0.8542167341740674, disc_loss = 0.06639309249271358
Trained batch 378 in epoch 8, gen_loss = 0.8538441795629688, disc_loss = 0.06639080604852858
Trained batch 379 in epoch 8, gen_loss = 0.853315485386472, disc_loss = 0.0663949270793972
Trained batch 380 in epoch 8, gen_loss = 0.8539326953606343, disc_loss = 0.06648672599066782
Trained batch 381 in epoch 8, gen_loss = 0.8539214395571754, disc_loss = 0.06641406328076038
Trained batch 382 in epoch 8, gen_loss = 0.8531888773951767, disc_loss = 0.06644743681075561
Trained batch 383 in epoch 8, gen_loss = 0.8536749718866, disc_loss = 0.06632090866454139
Trained batch 384 in epoch 8, gen_loss = 0.8538163269495035, disc_loss = 0.06647474729129439
Trained batch 385 in epoch 8, gen_loss = 0.8534318326822834, disc_loss = 0.06653258414972825
Trained batch 386 in epoch 8, gen_loss = 0.8528178937213365, disc_loss = 0.06668520060509867
Trained batch 387 in epoch 8, gen_loss = 0.8536032239340016, disc_loss = 0.06673285868330907
Trained batch 388 in epoch 8, gen_loss = 0.8540171888156538, disc_loss = 0.06675852900418838
Trained batch 389 in epoch 8, gen_loss = 0.854210926248477, disc_loss = 0.06661895002620534
Trained batch 390 in epoch 8, gen_loss = 0.8532628941413997, disc_loss = 0.06714214915362046
Trained batch 391 in epoch 8, gen_loss = 0.8543359924639974, disc_loss = 0.06741290608995917
Trained batch 392 in epoch 8, gen_loss = 0.853905580729322, disc_loss = 0.06736822933570005
Trained batch 393 in epoch 8, gen_loss = 0.8539210813602215, disc_loss = 0.0673564951878684
Trained batch 394 in epoch 8, gen_loss = 0.8530959233453003, disc_loss = 0.06761157960760632
Trained batch 395 in epoch 8, gen_loss = 0.8527454344010112, disc_loss = 0.06754284770806518
Trained batch 396 in epoch 8, gen_loss = 0.8530321422992485, disc_loss = 0.06744619904283049
Trained batch 397 in epoch 8, gen_loss = 0.8532008149815564, disc_loss = 0.06741529072859516
Trained batch 398 in epoch 8, gen_loss = 0.8536169727643331, disc_loss = 0.06726644884323454
Trained batch 399 in epoch 8, gen_loss = 0.8533242361247539, disc_loss = 0.0671978220960591
Trained batch 400 in epoch 8, gen_loss = 0.8532744388925168, disc_loss = 0.06716876509169725
Trained batch 401 in epoch 8, gen_loss = 0.8535512636846571, disc_loss = 0.06709276674088295
Trained batch 402 in epoch 8, gen_loss = 0.8533650654421255, disc_loss = 0.06704312018130354
Trained batch 403 in epoch 8, gen_loss = 0.8530465972305524, disc_loss = 0.06698910885209236
Trained batch 404 in epoch 8, gen_loss = 0.8532585458990968, disc_loss = 0.06686268331666971
Trained batch 405 in epoch 8, gen_loss = 0.8532087306670955, disc_loss = 0.06676625780729127
Trained batch 406 in epoch 8, gen_loss = 0.8528449639348492, disc_loss = 0.06670768962742839
Trained batch 407 in epoch 8, gen_loss = 0.8527923747897148, disc_loss = 0.06675835071683989
Trained batch 408 in epoch 8, gen_loss = 0.8531373823767477, disc_loss = 0.0666182661567949
Trained batch 409 in epoch 8, gen_loss = 0.8534195801106895, disc_loss = 0.06670870829441744
Trained batch 410 in epoch 8, gen_loss = 0.8529338691646455, disc_loss = 0.06670262073019378
Trained batch 411 in epoch 8, gen_loss = 0.8523833039894845, disc_loss = 0.06674691663435615
Trained batch 412 in epoch 8, gen_loss = 0.852606682165483, disc_loss = 0.06684258319865957
Trained batch 413 in epoch 8, gen_loss = 0.8527975890083589, disc_loss = 0.0668246070055768
Trained batch 414 in epoch 8, gen_loss = 0.8530621768480324, disc_loss = 0.06668791742546551
Trained batch 415 in epoch 8, gen_loss = 0.8526614352774161, disc_loss = 0.06673533107991367
Trained batch 416 in epoch 8, gen_loss = 0.8525042602484175, disc_loss = 0.06668073519934817
Trained batch 417 in epoch 8, gen_loss = 0.8526830564845692, disc_loss = 0.06655888870674849
Trained batch 418 in epoch 8, gen_loss = 0.8525368047784792, disc_loss = 0.06649450316629539
Trained batch 419 in epoch 8, gen_loss = 0.8526673812241782, disc_loss = 0.0664095579857184
Trained batch 420 in epoch 8, gen_loss = 0.8525375551112757, disc_loss = 0.06637392383214803
Trained batch 421 in epoch 8, gen_loss = 0.8524797714152043, disc_loss = 0.06626216213933912
Trained batch 422 in epoch 8, gen_loss = 0.8527430660899368, disc_loss = 0.06612669005351533
Trained batch 423 in epoch 8, gen_loss = 0.8525410471659787, disc_loss = 0.06608705317386303
Trained batch 424 in epoch 8, gen_loss = 0.8526612461314482, disc_loss = 0.06598748701788923
Trained batch 425 in epoch 8, gen_loss = 0.8532002016971928, disc_loss = 0.06590921381387876
Trained batch 426 in epoch 8, gen_loss = 0.8529172183758202, disc_loss = 0.06589093515911168
Trained batch 427 in epoch 8, gen_loss = 0.8531279973337583, disc_loss = 0.06595109110136699
Trained batch 428 in epoch 8, gen_loss = 0.8529631658033892, disc_loss = 0.06586738251527394
Trained batch 429 in epoch 8, gen_loss = 0.8532189509203267, disc_loss = 0.06576045560433941
Trained batch 430 in epoch 8, gen_loss = 0.8527770768462091, disc_loss = 0.0656876320228966
Trained batch 431 in epoch 8, gen_loss = 0.8531175207484651, disc_loss = 0.06559462380849894
Trained batch 432 in epoch 8, gen_loss = 0.8533758669747491, disc_loss = 0.0654748592936535
Trained batch 433 in epoch 8, gen_loss = 0.8528226611251655, disc_loss = 0.06562227965976339
Trained batch 434 in epoch 8, gen_loss = 0.8533820223534244, disc_loss = 0.06572230822117678
Trained batch 435 in epoch 8, gen_loss = 0.8534418863987704, disc_loss = 0.0656101884557481
Trained batch 436 in epoch 8, gen_loss = 0.8532610564264608, disc_loss = 0.065551991861109
Trained batch 437 in epoch 8, gen_loss = 0.8532116434889842, disc_loss = 0.06549793616528346
Trained batch 438 in epoch 8, gen_loss = 0.8534353488127029, disc_loss = 0.06564741646489107
Trained batch 439 in epoch 8, gen_loss = 0.8528639051047239, disc_loss = 0.06579465898579326
Trained batch 440 in epoch 8, gen_loss = 0.8526532905442374, disc_loss = 0.06572181237608093
Trained batch 441 in epoch 8, gen_loss = 0.853074857417275, disc_loss = 0.06562256731611268
Trained batch 442 in epoch 8, gen_loss = 0.8529639868381061, disc_loss = 0.06559094918984289
Trained batch 443 in epoch 8, gen_loss = 0.8533147262023376, disc_loss = 0.06563706982457121
Trained batch 444 in epoch 8, gen_loss = 0.8527896921286422, disc_loss = 0.06579147427750939
Trained batch 445 in epoch 8, gen_loss = 0.8521728095986918, disc_loss = 0.06578840593799047
Trained batch 446 in epoch 8, gen_loss = 0.8529380573255637, disc_loss = 0.06614136056957862
Trained batch 447 in epoch 8, gen_loss = 0.8527878705146057, disc_loss = 0.06607857531447994
Trained batch 448 in epoch 8, gen_loss = 0.8526396431476874, disc_loss = 0.06611119693908467
Trained batch 449 in epoch 8, gen_loss = 0.8522226618395912, disc_loss = 0.0661350938377695
Trained batch 450 in epoch 8, gen_loss = 0.8517745935467553, disc_loss = 0.06623892616914243
Trained batch 451 in epoch 8, gen_loss = 0.8515981520171714, disc_loss = 0.06639998315821147
Trained batch 452 in epoch 8, gen_loss = 0.8512610758903537, disc_loss = 0.06638381276875899
Trained batch 453 in epoch 8, gen_loss = 0.8520567376445568, disc_loss = 0.06631714616294966
Trained batch 454 in epoch 8, gen_loss = 0.8517955465631171, disc_loss = 0.06629322237836627
Trained batch 455 in epoch 8, gen_loss = 0.8511020611775549, disc_loss = 0.06638924288461312
Trained batch 456 in epoch 8, gen_loss = 0.8512281680263628, disc_loss = 0.06647825446000212
Trained batch 457 in epoch 8, gen_loss = 0.8510681638030506, disc_loss = 0.06638749892514313
Trained batch 458 in epoch 8, gen_loss = 0.8509001470858755, disc_loss = 0.06633304067925917
Trained batch 459 in epoch 8, gen_loss = 0.8506107431391011, disc_loss = 0.06630115749861074
Trained batch 460 in epoch 8, gen_loss = 0.8512139061785055, disc_loss = 0.06630413249890581
Trained batch 461 in epoch 8, gen_loss = 0.8512974358224249, disc_loss = 0.06621523625499597
Trained batch 462 in epoch 8, gen_loss = 0.8507995412365149, disc_loss = 0.06629529835044791
Trained batch 463 in epoch 8, gen_loss = 0.8519293128930289, disc_loss = 0.06658369708898605
Trained batch 464 in epoch 8, gen_loss = 0.8518918947506976, disc_loss = 0.06655808808882871
Trained batch 465 in epoch 8, gen_loss = 0.8513999111918421, disc_loss = 0.06686249141813187
Trained batch 466 in epoch 8, gen_loss = 0.8515502998098827, disc_loss = 0.06692230884819361
Trained batch 467 in epoch 8, gen_loss = 0.8512040063356742, disc_loss = 0.06684523223377924
Trained batch 468 in epoch 8, gen_loss = 0.8511761964511261, disc_loss = 0.06681165571258997
Trained batch 469 in epoch 8, gen_loss = 0.8509262281529447, disc_loss = 0.06684793115276447
Trained batch 470 in epoch 8, gen_loss = 0.8508646052860657, disc_loss = 0.06681236920031994
Trained batch 471 in epoch 8, gen_loss = 0.8516267280457384, disc_loss = 0.0667755850067883
Trained batch 472 in epoch 8, gen_loss = 0.8514495388649986, disc_loss = 0.06669072232191425
Trained batch 473 in epoch 8, gen_loss = 0.8514127257252544, disc_loss = 0.06659234666760681
Trained batch 474 in epoch 8, gen_loss = 0.8517858920599285, disc_loss = 0.06648526524144568
Trained batch 475 in epoch 8, gen_loss = 0.8524765168167964, disc_loss = 0.06644717622607038
Trained batch 476 in epoch 8, gen_loss = 0.8526075762272881, disc_loss = 0.06633272229262337
Trained batch 477 in epoch 8, gen_loss = 0.8528408863305048, disc_loss = 0.06623093329397299
Trained batch 478 in epoch 8, gen_loss = 0.853145683856996, disc_loss = 0.06611792855878557
Trained batch 479 in epoch 8, gen_loss = 0.8531971385081609, disc_loss = 0.06602925797051284
Trained batch 480 in epoch 8, gen_loss = 0.8535144671085223, disc_loss = 0.06595832406758116
Trained batch 481 in epoch 8, gen_loss = 0.8535519404282709, disc_loss = 0.06586386117585684
Trained batch 482 in epoch 8, gen_loss = 0.8532109148260476, disc_loss = 0.06577254668568448
Trained batch 483 in epoch 8, gen_loss = 0.8533806979409919, disc_loss = 0.06565547632611518
Trained batch 484 in epoch 8, gen_loss = 0.8534379304069833, disc_loss = 0.06554009821169923
Trained batch 485 in epoch 8, gen_loss = 0.8533563758610698, disc_loss = 0.065520136832708
Trained batch 486 in epoch 8, gen_loss = 0.8532087068538157, disc_loss = 0.06545967813409115
Trained batch 487 in epoch 8, gen_loss = 0.853136806947286, disc_loss = 0.06540341900955489
Trained batch 488 in epoch 8, gen_loss = 0.8528027711226652, disc_loss = 0.06541996042135577
Trained batch 489 in epoch 8, gen_loss = 0.8530263965227166, disc_loss = 0.06530871784827691
Trained batch 490 in epoch 8, gen_loss = 0.8528821265624643, disc_loss = 0.06519944550917159
Trained batch 491 in epoch 8, gen_loss = 0.853340444889495, disc_loss = 0.0650851405954473
Trained batch 492 in epoch 8, gen_loss = 0.8528758883476257, disc_loss = 0.06511625126249801
Trained batch 493 in epoch 8, gen_loss = 0.8537534194195319, disc_loss = 0.06515773402447793
Trained batch 494 in epoch 8, gen_loss = 0.8542519758446048, disc_loss = 0.06506041740020267
Trained batch 495 in epoch 8, gen_loss = 0.8541456636401915, disc_loss = 0.0650107694814177
Trained batch 496 in epoch 8, gen_loss = 0.8536830345389829, disc_loss = 0.06507134048635481
Trained batch 497 in epoch 8, gen_loss = 0.8545636085860701, disc_loss = 0.06549157526243074
Trained batch 498 in epoch 8, gen_loss = 0.8543649164134849, disc_loss = 0.06547141008037992
Trained batch 499 in epoch 8, gen_loss = 0.8540023897886276, disc_loss = 0.0654337232420221
Trained batch 500 in epoch 8, gen_loss = 0.854046012708051, disc_loss = 0.06533425598091143
Trained batch 501 in epoch 8, gen_loss = 0.8541529996699071, disc_loss = 0.06524230541004632
Trained batch 502 in epoch 8, gen_loss = 0.8542919131680938, disc_loss = 0.0651455915266385
Trained batch 503 in epoch 8, gen_loss = 0.8544373152747987, disc_loss = 0.06512853368425682
Trained batch 504 in epoch 8, gen_loss = 0.8538349084334799, disc_loss = 0.06545035002273646
Trained batch 505 in epoch 8, gen_loss = 0.8535098115446068, disc_loss = 0.06544768617105608
Trained batch 506 in epoch 8, gen_loss = 0.8541379386386457, disc_loss = 0.06556925710742555
Trained batch 507 in epoch 8, gen_loss = 0.8536268221581076, disc_loss = 0.06568606514355359
Trained batch 508 in epoch 8, gen_loss = 0.8541930984186049, disc_loss = 0.0656535628065101
Trained batch 509 in epoch 8, gen_loss = 0.8538958405747133, disc_loss = 0.06567839890736721
Trained batch 510 in epoch 8, gen_loss = 0.8539733369989638, disc_loss = 0.06571236679716849
Trained batch 511 in epoch 8, gen_loss = 0.8538626169320196, disc_loss = 0.06569253209181625
Trained batch 512 in epoch 8, gen_loss = 0.85425837625537, disc_loss = 0.0658646966457788
Trained batch 513 in epoch 8, gen_loss = 0.8535213741810869, disc_loss = 0.0661744813222786
Trained batch 514 in epoch 8, gen_loss = 0.8544222574789547, disc_loss = 0.06621756664775674
Trained batch 515 in epoch 8, gen_loss = 0.8541225368200347, disc_loss = 0.06623873325126145
Trained batch 516 in epoch 8, gen_loss = 0.8542005128048836, disc_loss = 0.06617396426922147
Trained batch 517 in epoch 8, gen_loss = 0.8542601721627372, disc_loss = 0.06618358108258184
Trained batch 518 in epoch 8, gen_loss = 0.8541048880027668, disc_loss = 0.0661361459938734
Trained batch 519 in epoch 8, gen_loss = 0.8539651946379588, disc_loss = 0.06608104255641452
Trained batch 520 in epoch 8, gen_loss = 0.8545582795554983, disc_loss = 0.06601684917776261
Trained batch 521 in epoch 8, gen_loss = 0.85482016479832, disc_loss = 0.06615995265761127
Trained batch 522 in epoch 8, gen_loss = 0.8540941549760661, disc_loss = 0.06665692235971757
Trained batch 523 in epoch 8, gen_loss = 0.8537854482881896, disc_loss = 0.06666098900213979
Trained batch 524 in epoch 8, gen_loss = 0.8536777827853248, disc_loss = 0.06674257675540589
Trained batch 525 in epoch 8, gen_loss = 0.8539043195800636, disc_loss = 0.06678679440712322
Trained batch 526 in epoch 8, gen_loss = 0.8538274580658727, disc_loss = 0.06672105331422737
Trained batch 527 in epoch 8, gen_loss = 0.8535418115330465, disc_loss = 0.06674122316216005
Trained batch 528 in epoch 8, gen_loss = 0.8530284885197371, disc_loss = 0.06679355333134926
Trained batch 529 in epoch 8, gen_loss = 0.8531955527809431, disc_loss = 0.06675154712701321
Trained batch 530 in epoch 8, gen_loss = 0.8537001892671747, disc_loss = 0.06678739710396994
Trained batch 531 in epoch 8, gen_loss = 0.8535041113321046, disc_loss = 0.06669135509790587
Trained batch 532 in epoch 8, gen_loss = 0.853110608419379, disc_loss = 0.06668624408127247
Trained batch 533 in epoch 8, gen_loss = 0.852965411287122, disc_loss = 0.0666329542058084
Trained batch 534 in epoch 8, gen_loss = 0.8526825207416142, disc_loss = 0.06665649693024076
Trained batch 535 in epoch 8, gen_loss = 0.853044584838312, disc_loss = 0.06655484144384764
Trained batch 536 in epoch 8, gen_loss = 0.8530794134575117, disc_loss = 0.06652402856735794
Trained batch 537 in epoch 8, gen_loss = 0.8533904154726121, disc_loss = 0.0665225734748985
Trained batch 538 in epoch 8, gen_loss = 0.8529957363689543, disc_loss = 0.06662830295462804
Trained batch 539 in epoch 8, gen_loss = 0.8531480877487748, disc_loss = 0.06658925275852973
Trained batch 540 in epoch 8, gen_loss = 0.8534069019412818, disc_loss = 0.0665039370798759
Trained batch 541 in epoch 8, gen_loss = 0.8533391305881233, disc_loss = 0.06646950505553603
Trained batch 542 in epoch 8, gen_loss = 0.8534398188687601, disc_loss = 0.06641718554250471
Trained batch 543 in epoch 8, gen_loss = 0.8533894303528702, disc_loss = 0.0665074773654958
Trained batch 544 in epoch 8, gen_loss = 0.8532309632782542, disc_loss = 0.06641391151490698
Trained batch 545 in epoch 8, gen_loss = 0.8534272000903175, disc_loss = 0.06631386078699686
Trained batch 546 in epoch 8, gen_loss = 0.8530025453846459, disc_loss = 0.06651467755624184
Trained batch 547 in epoch 8, gen_loss = 0.8529136702962166, disc_loss = 0.06642590476672444
Trained batch 548 in epoch 8, gen_loss = 0.852508044199431, disc_loss = 0.06644744789634979
Trained batch 549 in epoch 8, gen_loss = 0.8531703985821117, disc_loss = 0.06640592241744427
Trained batch 550 in epoch 8, gen_loss = 0.8529126980560012, disc_loss = 0.06638377724289758
Trained batch 551 in epoch 8, gen_loss = 0.8529775026051895, disc_loss = 0.06641414446293957
Trained batch 552 in epoch 8, gen_loss = 0.8527102116865879, disc_loss = 0.06645478540526241
Trained batch 553 in epoch 8, gen_loss = 0.8525535602001507, disc_loss = 0.06640277131769927
Trained batch 554 in epoch 8, gen_loss = 0.8527318446485845, disc_loss = 0.06631097776882418
Trained batch 555 in epoch 8, gen_loss = 0.853042958344487, disc_loss = 0.06637374616626704
Trained batch 556 in epoch 8, gen_loss = 0.8530607118640811, disc_loss = 0.06632661942603264
Trained batch 557 in epoch 8, gen_loss = 0.8527811329851869, disc_loss = 0.06639126775115328
Trained batch 558 in epoch 8, gen_loss = 0.852613589418169, disc_loss = 0.06638789194351152
Trained batch 559 in epoch 8, gen_loss = 0.8531278925282615, disc_loss = 0.06653559193364345
Trained batch 560 in epoch 8, gen_loss = 0.8528570216182294, disc_loss = 0.06648601935645183
Trained batch 561 in epoch 8, gen_loss = 0.8531735992304371, disc_loss = 0.06638951489645524
Trained batch 562 in epoch 8, gen_loss = 0.8530244511778783, disc_loss = 0.06640635842464031
Trained batch 563 in epoch 8, gen_loss = 0.8528006922268698, disc_loss = 0.06636070756073248
Trained batch 564 in epoch 8, gen_loss = 0.8534605203476627, disc_loss = 0.0664275005599896
Trained batch 565 in epoch 8, gen_loss = 0.8536310657174343, disc_loss = 0.06635101113958751
Trained batch 566 in epoch 8, gen_loss = 0.8536895515637003, disc_loss = 0.06626034529413206
Trained batch 567 in epoch 8, gen_loss = 0.8538495060843481, disc_loss = 0.06620371169951732
Trained batch 568 in epoch 8, gen_loss = 0.8537423887236048, disc_loss = 0.06622491310872727
Trained batch 569 in epoch 8, gen_loss = 0.8538268756448177, disc_loss = 0.0661639334544082
Trained batch 570 in epoch 8, gen_loss = 0.8545275183358668, disc_loss = 0.06623542991967549
Trained batch 571 in epoch 8, gen_loss = 0.8540415647146585, disc_loss = 0.06636459614277225
Trained batch 572 in epoch 8, gen_loss = 0.8537444527444623, disc_loss = 0.06638693932466612
Trained batch 573 in epoch 8, gen_loss = 0.8539850518678539, disc_loss = 0.06650668661149044
Trained batch 574 in epoch 8, gen_loss = 0.853879002177197, disc_loss = 0.06646806713760547
Trained batch 575 in epoch 8, gen_loss = 0.8534262796036072, disc_loss = 0.06659456403980989
Trained batch 576 in epoch 8, gen_loss = 0.8534591507870362, disc_loss = 0.06672446137339368
Trained batch 577 in epoch 8, gen_loss = 0.8536116062151107, disc_loss = 0.06663987656111046
Trained batch 578 in epoch 8, gen_loss = 0.8531507590274119, disc_loss = 0.06664065244030175
Trained batch 579 in epoch 8, gen_loss = 0.8531629719610871, disc_loss = 0.06656458525003159
Trained batch 580 in epoch 8, gen_loss = 0.8532259050827223, disc_loss = 0.06656256149540593
Trained batch 581 in epoch 8, gen_loss = 0.853128782150262, disc_loss = 0.06649915142148041
Trained batch 582 in epoch 8, gen_loss = 0.852631467591019, disc_loss = 0.06661915677275324
Trained batch 583 in epoch 8, gen_loss = 0.8527229384404339, disc_loss = 0.06653542043274421
Trained batch 584 in epoch 8, gen_loss = 0.8527945313698206, disc_loss = 0.06645356828474208
Trained batch 585 in epoch 8, gen_loss = 0.8528411057825381, disc_loss = 0.06638202994327623
Trained batch 586 in epoch 8, gen_loss = 0.852958816584371, disc_loss = 0.06632344827160645
Trained batch 587 in epoch 8, gen_loss = 0.8527687148374765, disc_loss = 0.06627586020273948
Trained batch 588 in epoch 8, gen_loss = 0.8529883039220282, disc_loss = 0.0662602140988794
Trained batch 589 in epoch 8, gen_loss = 0.853101197137671, disc_loss = 0.06620052916281935
Trained batch 590 in epoch 8, gen_loss = 0.8527108916978142, disc_loss = 0.0662826927585209
Trained batch 591 in epoch 8, gen_loss = 0.8522906486649771, disc_loss = 0.06628851671593038
Trained batch 592 in epoch 8, gen_loss = 0.8529871999714869, disc_loss = 0.06638648304193082
Trained batch 593 in epoch 8, gen_loss = 0.8531477009808576, disc_loss = 0.06636411544666171
Trained batch 594 in epoch 8, gen_loss = 0.8530984063108428, disc_loss = 0.06629976761456924
Trained batch 595 in epoch 8, gen_loss = 0.8525994516059057, disc_loss = 0.06645676472158665
Trained batch 596 in epoch 8, gen_loss = 0.8527117634139069, disc_loss = 0.06640745602451402
Trained batch 597 in epoch 8, gen_loss = 0.8529992306910231, disc_loss = 0.06643075571102666
Trained batch 598 in epoch 8, gen_loss = 0.8526623961523498, disc_loss = 0.06650052670286798
Trained batch 599 in epoch 8, gen_loss = 0.852200335363547, disc_loss = 0.06672024442891901
Trained batch 600 in epoch 8, gen_loss = 0.8524241273891112, disc_loss = 0.066663238448486
Trained batch 601 in epoch 8, gen_loss = 0.8527142139170257, disc_loss = 0.06659662166372114
Trained batch 602 in epoch 8, gen_loss = 0.8528847108235209, disc_loss = 0.06661237111302776
Trained batch 603 in epoch 8, gen_loss = 0.852488339934128, disc_loss = 0.06665341871627144
Trained batch 604 in epoch 8, gen_loss = 0.8520334561009052, disc_loss = 0.06674881164708044
Trained batch 605 in epoch 8, gen_loss = 0.8522836015169376, disc_loss = 0.06720281572837272
Trained batch 606 in epoch 8, gen_loss = 0.8527504551351758, disc_loss = 0.0672813647417459
Trained batch 607 in epoch 8, gen_loss = 0.8523993009799405, disc_loss = 0.06735608627250737
Trained batch 608 in epoch 8, gen_loss = 0.8523363430903267, disc_loss = 0.06730098875961305
Trained batch 609 in epoch 8, gen_loss = 0.8524347958017569, disc_loss = 0.06723995696768531
Trained batch 610 in epoch 8, gen_loss = 0.8523549274610029, disc_loss = 0.06726514191462761
Trained batch 611 in epoch 8, gen_loss = 0.8526177719917173, disc_loss = 0.06720299688335264
Trained batch 612 in epoch 8, gen_loss = 0.8525148356913742, disc_loss = 0.06716991276183996
Trained batch 613 in epoch 8, gen_loss = 0.8523308655143949, disc_loss = 0.06712744402068178
Trained batch 614 in epoch 8, gen_loss = 0.852374299464187, disc_loss = 0.06705461803263402
Trained batch 615 in epoch 8, gen_loss = 0.8521541686027081, disc_loss = 0.06698640305080221
Trained batch 616 in epoch 8, gen_loss = 0.852274061794992, disc_loss = 0.06690057799917445
Trained batch 617 in epoch 8, gen_loss = 0.852180474495039, disc_loss = 0.06687404269512297
Trained batch 618 in epoch 8, gen_loss = 0.8520765596329685, disc_loss = 0.0668264678965273
Trained batch 619 in epoch 8, gen_loss = 0.85170968434503, disc_loss = 0.06692004899509371
Trained batch 620 in epoch 8, gen_loss = 0.8517955512816203, disc_loss = 0.06683580745116548
Trained batch 621 in epoch 8, gen_loss = 0.8525772895843653, disc_loss = 0.06745018321089447
Trained batch 622 in epoch 8, gen_loss = 0.8523162161366323, disc_loss = 0.06743065464903823
Trained batch 623 in epoch 8, gen_loss = 0.8523279342513818, disc_loss = 0.06738452358807151
Trained batch 624 in epoch 8, gen_loss = 0.8521860897064208, disc_loss = 0.06736019140854478
Trained batch 625 in epoch 8, gen_loss = 0.8521317633957909, disc_loss = 0.06733037632318756
Trained batch 626 in epoch 8, gen_loss = 0.8520267741721973, disc_loss = 0.06726976769918389
Trained batch 627 in epoch 8, gen_loss = 0.8520135263538664, disc_loss = 0.06723178758888036
Trained batch 628 in epoch 8, gen_loss = 0.8516924977302551, disc_loss = 0.0672525894111511
Trained batch 629 in epoch 8, gen_loss = 0.8520306533291226, disc_loss = 0.06778673726607055
Trained batch 630 in epoch 8, gen_loss = 0.8518019271350322, disc_loss = 0.06780420750949277
Trained batch 631 in epoch 8, gen_loss = 0.8512923596780512, disc_loss = 0.06790277649003046
Trained batch 632 in epoch 8, gen_loss = 0.8515407259430365, disc_loss = 0.06810255258713406
Trained batch 633 in epoch 8, gen_loss = 0.8515869787062756, disc_loss = 0.06802589502494065
Trained batch 634 in epoch 8, gen_loss = 0.8513582884796023, disc_loss = 0.06800612143541532
Trained batch 635 in epoch 8, gen_loss = 0.8511907797564501, disc_loss = 0.06795867373537179
Trained batch 636 in epoch 8, gen_loss = 0.851053961405013, disc_loss = 0.06810345179423269
Trained batch 637 in epoch 8, gen_loss = 0.8508626938239908, disc_loss = 0.06807306087517463
Trained batch 638 in epoch 8, gen_loss = 0.850607542271532, disc_loss = 0.06809888385798846
Trained batch 639 in epoch 8, gen_loss = 0.8509356123395264, disc_loss = 0.06806370881167823
Trained batch 640 in epoch 8, gen_loss = 0.8506223817883342, disc_loss = 0.0681143312252965
Trained batch 641 in epoch 8, gen_loss = 0.8507998045359817, disc_loss = 0.06802554993246133
Trained batch 642 in epoch 8, gen_loss = 0.8511246841395068, disc_loss = 0.06815956473353421
Trained batch 643 in epoch 8, gen_loss = 0.8510520808074785, disc_loss = 0.06811677746153696
Trained batch 644 in epoch 8, gen_loss = 0.8507284327070842, disc_loss = 0.06813220398558319
Trained batch 645 in epoch 8, gen_loss = 0.8506901579744676, disc_loss = 0.06814979327678242
Trained batch 646 in epoch 8, gen_loss = 0.8507266346785533, disc_loss = 0.06813213875275421
Trained batch 647 in epoch 8, gen_loss = 0.8508485625555486, disc_loss = 0.06823543632865803
Trained batch 648 in epoch 8, gen_loss = 0.8501610233805764, disc_loss = 0.06851705163789021
Trained batch 649 in epoch 8, gen_loss = 0.8504991657458819, disc_loss = 0.0687670113153469
Trained batch 650 in epoch 8, gen_loss = 0.8506272932809252, disc_loss = 0.06876453238907063
Trained batch 651 in epoch 8, gen_loss = 0.8502783730077598, disc_loss = 0.06877919699085384
Trained batch 652 in epoch 8, gen_loss = 0.8498305610365379, disc_loss = 0.06888848090270508
Trained batch 653 in epoch 8, gen_loss = 0.8497496543036324, disc_loss = 0.06885882315015142
Trained batch 654 in epoch 8, gen_loss = 0.8499134164275104, disc_loss = 0.06877148611158246
Trained batch 655 in epoch 8, gen_loss = 0.8501148271578841, disc_loss = 0.06874562804118685
Trained batch 656 in epoch 8, gen_loss = 0.8500622552188746, disc_loss = 0.06867031179456383
Trained batch 657 in epoch 8, gen_loss = 0.8499746497912972, disc_loss = 0.06865217304777207
Trained batch 658 in epoch 8, gen_loss = 0.8499334024460435, disc_loss = 0.0685733290741076
Trained batch 659 in epoch 8, gen_loss = 0.8502850542917396, disc_loss = 0.06857739672502221
Trained batch 660 in epoch 8, gen_loss = 0.8497653848374666, disc_loss = 0.0687371357484987
Trained batch 661 in epoch 8, gen_loss = 0.8500082900246825, disc_loss = 0.06874893499000893
Trained batch 662 in epoch 8, gen_loss = 0.8501076648407931, disc_loss = 0.06869686838466994
Trained batch 663 in epoch 8, gen_loss = 0.8498966705098928, disc_loss = 0.06865948464101494
Trained batch 664 in epoch 8, gen_loss = 0.8499673539982703, disc_loss = 0.06866951378314455
Trained batch 665 in epoch 8, gen_loss = 0.8497856730544889, disc_loss = 0.06875379558851209
Trained batch 666 in epoch 8, gen_loss = 0.8495995064099868, disc_loss = 0.0688863662574189
Trained batch 667 in epoch 8, gen_loss = 0.8494611564064454, disc_loss = 0.06886208198705275
Trained batch 668 in epoch 8, gen_loss = 0.8494443899223801, disc_loss = 0.06896985422121013
Trained batch 669 in epoch 8, gen_loss = 0.8492574419993073, disc_loss = 0.06895955252433335
Trained batch 670 in epoch 8, gen_loss = 0.8487922205033139, disc_loss = 0.0691390749804076
Trained batch 671 in epoch 8, gen_loss = 0.8486490001724589, disc_loss = 0.06908118443416675
Trained batch 672 in epoch 8, gen_loss = 0.8490655663551937, disc_loss = 0.06914972315956168
Trained batch 673 in epoch 8, gen_loss = 0.848774600055522, disc_loss = 0.06914815006194532
Trained batch 674 in epoch 8, gen_loss = 0.849403536717097, disc_loss = 0.06913177157648735
Trained batch 675 in epoch 8, gen_loss = 0.8493841601282182, disc_loss = 0.06905918477926977
Trained batch 676 in epoch 8, gen_loss = 0.8492245366425423, disc_loss = 0.0690444359931396
Trained batch 677 in epoch 8, gen_loss = 0.8492421861683022, disc_loss = 0.06895969452811707
Trained batch 678 in epoch 8, gen_loss = 0.8492522330540445, disc_loss = 0.06889282996438455
Trained batch 679 in epoch 8, gen_loss = 0.849038021573249, disc_loss = 0.06883939935154665
Trained batch 680 in epoch 8, gen_loss = 0.8493000160842565, disc_loss = 0.06880867351516644
Trained batch 681 in epoch 8, gen_loss = 0.8488766376661065, disc_loss = 0.06890740826155149
Trained batch 682 in epoch 8, gen_loss = 0.8487252816012454, disc_loss = 0.06899638975170028
Trained batch 683 in epoch 8, gen_loss = 0.848719203376282, disc_loss = 0.06892304603563218
Trained batch 684 in epoch 8, gen_loss = 0.8483898172848416, disc_loss = 0.06898896550270218
Trained batch 685 in epoch 8, gen_loss = 0.8488028608588366, disc_loss = 0.06891830078918085
Trained batch 686 in epoch 8, gen_loss = 0.8489416940503766, disc_loss = 0.06884753494964048
Trained batch 687 in epoch 8, gen_loss = 0.8489947803751674, disc_loss = 0.0687908464711062
Trained batch 688 in epoch 8, gen_loss = 0.8486425914248811, disc_loss = 0.06882609966507043
Trained batch 689 in epoch 8, gen_loss = 0.8490349803713785, disc_loss = 0.06877013695075353
Trained batch 690 in epoch 8, gen_loss = 0.8493612143393018, disc_loss = 0.0686825783202201
Trained batch 691 in epoch 8, gen_loss = 0.8491852639641376, disc_loss = 0.06870002821935718
Trained batch 692 in epoch 8, gen_loss = 0.8492725378421134, disc_loss = 0.06864063565862535
Trained batch 693 in epoch 8, gen_loss = 0.8494443027275783, disc_loss = 0.06862578780916372
Trained batch 694 in epoch 8, gen_loss = 0.8491790174151496, disc_loss = 0.06859141820237684
Trained batch 695 in epoch 8, gen_loss = 0.8493856198914435, disc_loss = 0.06852901350886122
Trained batch 696 in epoch 8, gen_loss = 0.8493696264334697, disc_loss = 0.06849281821423979
Trained batch 697 in epoch 8, gen_loss = 0.8494150715007481, disc_loss = 0.06844177329979495
Trained batch 698 in epoch 8, gen_loss = 0.849776991575061, disc_loss = 0.06842584572985598
Trained batch 699 in epoch 8, gen_loss = 0.849554715028831, disc_loss = 0.0684198634718944
Trained batch 700 in epoch 8, gen_loss = 0.8496599129790416, disc_loss = 0.06834786869093946
Trained batch 701 in epoch 8, gen_loss = 0.8493996715528673, disc_loss = 0.06832246160986395
Trained batch 702 in epoch 8, gen_loss = 0.8493148684925579, disc_loss = 0.0685911049839814
Trained batch 703 in epoch 8, gen_loss = 0.8490279457870532, disc_loss = 0.06855158686878647
Trained batch 704 in epoch 8, gen_loss = 0.8491172894095698, disc_loss = 0.06848227015980486
Trained batch 705 in epoch 8, gen_loss = 0.8488841077508061, disc_loss = 0.06845074977459276
Trained batch 706 in epoch 8, gen_loss = 0.8493120815747193, disc_loss = 0.06848910921931667
Trained batch 707 in epoch 8, gen_loss = 0.8489998267953005, disc_loss = 0.06844669014233885
Trained batch 708 in epoch 8, gen_loss = 0.8487961132956829, disc_loss = 0.06844788338865544
Trained batch 709 in epoch 8, gen_loss = 0.848777628238772, disc_loss = 0.0683792848212146
Trained batch 710 in epoch 8, gen_loss = 0.8491603177559527, disc_loss = 0.06835107976025817
Trained batch 711 in epoch 8, gen_loss = 0.8491905977468143, disc_loss = 0.06828672371038204
Trained batch 712 in epoch 8, gen_loss = 0.8491727079866979, disc_loss = 0.06821505110619425
Trained batch 713 in epoch 8, gen_loss = 0.8490490221760186, disc_loss = 0.06818636639515872
Trained batch 714 in epoch 8, gen_loss = 0.8490048849916124, disc_loss = 0.06813104384207538
Trained batch 715 in epoch 8, gen_loss = 0.8492941821004425, disc_loss = 0.06805734747341788
Trained batch 716 in epoch 8, gen_loss = 0.8494390208102669, disc_loss = 0.067974033708992
Trained batch 717 in epoch 8, gen_loss = 0.8493887815717868, disc_loss = 0.06794071376445628
Trained batch 718 in epoch 8, gen_loss = 0.849389168955852, disc_loss = 0.06788941630212815
Trained batch 719 in epoch 8, gen_loss = 0.8493139914754364, disc_loss = 0.06786339551456169
Trained batch 720 in epoch 8, gen_loss = 0.84947400305539, disc_loss = 0.06802442152603386
Trained batch 721 in epoch 8, gen_loss = 0.8497385830512668, disc_loss = 0.06795985953317352
Trained batch 722 in epoch 8, gen_loss = 0.8494331733237328, disc_loss = 0.06798101576137901
Trained batch 723 in epoch 8, gen_loss = 0.8495652033890808, disc_loss = 0.0679037033635557
Trained batch 724 in epoch 8, gen_loss = 0.850170195883718, disc_loss = 0.0679026123129859
Trained batch 725 in epoch 8, gen_loss = 0.850011228653025, disc_loss = 0.0678680997371376
Trained batch 726 in epoch 8, gen_loss = 0.8500426658000054, disc_loss = 0.06780408732426524
Trained batch 727 in epoch 8, gen_loss = 0.8503366832795379, disc_loss = 0.06774644114289453
Trained batch 728 in epoch 8, gen_loss = 0.850493315111626, disc_loss = 0.06768645801414086
Trained batch 729 in epoch 8, gen_loss = 0.8503688566897013, disc_loss = 0.06764233948165321
Trained batch 730 in epoch 8, gen_loss = 0.8503517068606558, disc_loss = 0.0675904072289866
Trained batch 731 in epoch 8, gen_loss = 0.8500602427320402, disc_loss = 0.06763751388214467
Trained batch 732 in epoch 8, gen_loss = 0.849930916403358, disc_loss = 0.06758103878167426
Trained batch 733 in epoch 8, gen_loss = 0.8499899719732659, disc_loss = 0.06750095375351689
Trained batch 734 in epoch 8, gen_loss = 0.8503158172377113, disc_loss = 0.06743151009348887
Trained batch 735 in epoch 8, gen_loss = 0.8507377698450632, disc_loss = 0.06736593264339837
Trained batch 736 in epoch 8, gen_loss = 0.8505229326002957, disc_loss = 0.06737072133045932
Trained batch 737 in epoch 8, gen_loss = 0.8505717774797584, disc_loss = 0.0672970029297045
Trained batch 738 in epoch 8, gen_loss = 0.8505101607600795, disc_loss = 0.06730028833495769
Trained batch 739 in epoch 8, gen_loss = 0.8502733063456175, disc_loss = 0.06731093220626684
Trained batch 740 in epoch 8, gen_loss = 0.8504097912556086, disc_loss = 0.06724000652854842
Trained batch 741 in epoch 8, gen_loss = 0.8502067075665749, disc_loss = 0.0672093434039644
Trained batch 742 in epoch 8, gen_loss = 0.8501287322105341, disc_loss = 0.06721410233575054
Trained batch 743 in epoch 8, gen_loss = 0.8503360425031954, disc_loss = 0.06715052911413393
Trained batch 744 in epoch 8, gen_loss = 0.8504435150015274, disc_loss = 0.06708345900808504
Trained batch 745 in epoch 8, gen_loss = 0.8502147562462268, disc_loss = 0.06707063600503348
Trained batch 746 in epoch 8, gen_loss = 0.8500887708092629, disc_loss = 0.06706863513635285
Trained batch 747 in epoch 8, gen_loss = 0.8501254058378266, disc_loss = 0.0671690374489545
Trained batch 748 in epoch 8, gen_loss = 0.8501464340572205, disc_loss = 0.0670914645480845
Trained batch 749 in epoch 8, gen_loss = 0.8499269669453303, disc_loss = 0.0671036818716675
Trained batch 750 in epoch 8, gen_loss = 0.8503373725992068, disc_loss = 0.06705705272331437
Trained batch 751 in epoch 8, gen_loss = 0.8499028855102494, disc_loss = 0.067207781998614
Trained batch 752 in epoch 8, gen_loss = 0.8500014316750713, disc_loss = 0.06725000407470076
Trained batch 753 in epoch 8, gen_loss = 0.8499737607626447, disc_loss = 0.06720373561094449
Trained batch 754 in epoch 8, gen_loss = 0.8497079632534886, disc_loss = 0.06721075180091507
Trained batch 755 in epoch 8, gen_loss = 0.8498837266255308, disc_loss = 0.06713865973023334
Trained batch 756 in epoch 8, gen_loss = 0.8497227056731951, disc_loss = 0.0671061941759619
Trained batch 757 in epoch 8, gen_loss = 0.8497098860844459, disc_loss = 0.06708622662569236
Trained batch 758 in epoch 8, gen_loss = 0.8496393967758525, disc_loss = 0.0670496058154591
Trained batch 759 in epoch 8, gen_loss = 0.8499645851552486, disc_loss = 0.06703142130833217
Trained batch 760 in epoch 8, gen_loss = 0.8496709987227457, disc_loss = 0.06705395894188743
Trained batch 761 in epoch 8, gen_loss = 0.8496305966392903, disc_loss = 0.06706233055873473
Trained batch 762 in epoch 8, gen_loss = 0.8500256213807498, disc_loss = 0.06701223713041894
Trained batch 763 in epoch 8, gen_loss = 0.8499244365314539, disc_loss = 0.06696628674033406
Trained batch 764 in epoch 8, gen_loss = 0.8504879210899079, disc_loss = 0.06695376117622444
Trained batch 765 in epoch 8, gen_loss = 0.850173792274129, disc_loss = 0.06696951298065017
Trained batch 766 in epoch 8, gen_loss = 0.8505552340750588, disc_loss = 0.06702298005785419
Trained batch 767 in epoch 8, gen_loss = 0.8503297960463291, disc_loss = 0.0670746464087036
Trained batch 768 in epoch 8, gen_loss = 0.8508388339233026, disc_loss = 0.06713063116954404
Trained batch 769 in epoch 8, gen_loss = 0.8505977469992329, disc_loss = 0.06722475397884362
Trained batch 770 in epoch 8, gen_loss = 0.8504875037534073, disc_loss = 0.06716879497520171
Trained batch 771 in epoch 8, gen_loss = 0.8505052008082212, disc_loss = 0.06717530891499507
Trained batch 772 in epoch 8, gen_loss = 0.8506062593296614, disc_loss = 0.06712322860153784
Trained batch 773 in epoch 8, gen_loss = 0.8507599261919041, disc_loss = 0.06710801657363868
Trained batch 774 in epoch 8, gen_loss = 0.85069216624383, disc_loss = 0.06707233499314996
Trained batch 775 in epoch 8, gen_loss = 0.8503871578915217, disc_loss = 0.06709066454078715
Trained batch 776 in epoch 8, gen_loss = 0.8507188236774779, disc_loss = 0.06711505144592399
Trained batch 777 in epoch 8, gen_loss = 0.8508428621338082, disc_loss = 0.06704555767597895
Trained batch 778 in epoch 8, gen_loss = 0.851124911888267, disc_loss = 0.06697932402848412
Trained batch 779 in epoch 8, gen_loss = 0.8509230463550641, disc_loss = 0.06695510339744103
Trained batch 780 in epoch 8, gen_loss = 0.8511767158053444, disc_loss = 0.0669046156245514
Trained batch 781 in epoch 8, gen_loss = 0.851377096284381, disc_loss = 0.06690429943694692
Trained batch 782 in epoch 8, gen_loss = 0.8513289293795253, disc_loss = 0.0668551680241803
Trained batch 783 in epoch 8, gen_loss = 0.8511628826738012, disc_loss = 0.06683999031000505
Trained batch 784 in epoch 8, gen_loss = 0.8513599424984805, disc_loss = 0.06676931642648426
Trained batch 785 in epoch 8, gen_loss = 0.851458700596528, disc_loss = 0.06682135752857243
Trained batch 786 in epoch 8, gen_loss = 0.8512055631135289, disc_loss = 0.06678614942380612
Trained batch 787 in epoch 8, gen_loss = 0.8509100295489814, disc_loss = 0.06684540021103254
Trained batch 788 in epoch 8, gen_loss = 0.8512340810891189, disc_loss = 0.06684698954788809
Trained batch 789 in epoch 8, gen_loss = 0.8514423434870153, disc_loss = 0.06685583957329487
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.5098560452461243, disc_loss = 0.1835414171218872
Trained batch 1 in epoch 9, gen_loss = 0.7437886595726013, disc_loss = 0.1127546913921833
Trained batch 2 in epoch 9, gen_loss = 0.8187728524208069, disc_loss = 0.07832188531756401
Trained batch 3 in epoch 9, gen_loss = 0.8112751692533493, disc_loss = 0.06800624541938305
Trained batch 4 in epoch 9, gen_loss = 0.8637779831886292, disc_loss = 0.06853185147047043
Trained batch 5 in epoch 9, gen_loss = 0.8258460958798727, disc_loss = 0.06391018691162269
Trained batch 6 in epoch 9, gen_loss = 0.8468211122921535, disc_loss = 0.056755930850548406
Trained batch 7 in epoch 9, gen_loss = 0.824394054710865, disc_loss = 0.0584657039726153
Trained batch 8 in epoch 9, gen_loss = 0.8513410025172763, disc_loss = 0.061870910744700164
Trained batch 9 in epoch 9, gen_loss = 0.8337657749652863, disc_loss = 0.05959896380081773
Trained batch 10 in epoch 9, gen_loss = 0.8263879093256864, disc_loss = 0.05924357956444675
Trained batch 11 in epoch 9, gen_loss = 0.8207258929808935, disc_loss = 0.05984320002608001
Trained batch 12 in epoch 9, gen_loss = 0.8114711183768052, disc_loss = 0.06270665911814341
Trained batch 13 in epoch 9, gen_loss = 0.8385059876101357, disc_loss = 0.06649652609069433
Trained batch 14 in epoch 9, gen_loss = 0.8322876890500387, disc_loss = 0.06660845981289944
Trained batch 15 in epoch 9, gen_loss = 0.8398411758244038, disc_loss = 0.07086778996745124
Trained batch 16 in epoch 9, gen_loss = 0.8285332006566665, disc_loss = 0.07077362218543011
Trained batch 17 in epoch 9, gen_loss = 0.8471031586329142, disc_loss = 0.06806916396857964
Trained batch 18 in epoch 9, gen_loss = 0.8341326619449415, disc_loss = 0.06944612163658205
Trained batch 19 in epoch 9, gen_loss = 0.8546398609876633, disc_loss = 0.07526643523015082
Trained batch 20 in epoch 9, gen_loss = 0.8616148034731547, disc_loss = 0.07252985119287457
Trained batch 21 in epoch 9, gen_loss = 0.8568658070130781, disc_loss = 0.07047672633251006
Trained batch 22 in epoch 9, gen_loss = 0.8448595015898995, disc_loss = 0.07224266324192286
Trained batch 23 in epoch 9, gen_loss = 0.8555575956900915, disc_loss = 0.07132802558286737
Trained batch 24 in epoch 9, gen_loss = 0.8556223225593567, disc_loss = 0.07116219904273749
Trained batch 25 in epoch 9, gen_loss = 0.8546075568749354, disc_loss = 0.06916303076566412
Trained batch 26 in epoch 9, gen_loss = 0.8463454003687259, disc_loss = 0.06835232899282817
Trained batch 27 in epoch 9, gen_loss = 0.8455673179456166, disc_loss = 0.06650926907812911
Trained batch 28 in epoch 9, gen_loss = 0.8500639878470322, disc_loss = 0.06465686141545403
Trained batch 29 in epoch 9, gen_loss = 0.8598952353000641, disc_loss = 0.06381140789017081
Trained batch 30 in epoch 9, gen_loss = 0.8671354843724158, disc_loss = 0.062229344831599344
Trained batch 31 in epoch 9, gen_loss = 0.8745896834880114, disc_loss = 0.06057153761503287
Trained batch 32 in epoch 9, gen_loss = 0.8779060967040785, disc_loss = 0.06020026047234282
Trained batch 33 in epoch 9, gen_loss = 0.8779688775539398, disc_loss = 0.058750549139564526
Trained batch 34 in epoch 9, gen_loss = 0.8804065108299255, disc_loss = 0.05771644575787442
Trained batch 35 in epoch 9, gen_loss = 0.8777121090226703, disc_loss = 0.0572199611665888
Trained batch 36 in epoch 9, gen_loss = 0.883850862851014, disc_loss = 0.057025033401677735
Trained batch 37 in epoch 9, gen_loss = 0.888066020451094, disc_loss = 0.055990555103083976
Trained batch 38 in epoch 9, gen_loss = 0.8863314099800892, disc_loss = 0.05522754427809746
Trained batch 39 in epoch 9, gen_loss = 0.8870550081133842, disc_loss = 0.05419088576454669
Trained batch 40 in epoch 9, gen_loss = 0.885973655596012, disc_loss = 0.05340714836720287
Trained batch 41 in epoch 9, gen_loss = 0.8838818257763272, disc_loss = 0.052614272017741485
Trained batch 42 in epoch 9, gen_loss = 0.890790136747582, disc_loss = 0.05204047516074985
Trained batch 43 in epoch 9, gen_loss = 0.8915134058757261, disc_loss = 0.051080070922828534
Trained batch 44 in epoch 9, gen_loss = 0.8924791322814094, disc_loss = 0.05056712141053544
Trained batch 45 in epoch 9, gen_loss = 0.8930107134839763, disc_loss = 0.049700425492356655
Trained batch 46 in epoch 9, gen_loss = 0.8926301738049122, disc_loss = 0.04880162342352436
Trained batch 47 in epoch 9, gen_loss = 0.892112468679746, disc_loss = 0.04877783526899293
Trained batch 48 in epoch 9, gen_loss = 0.8967761117584852, disc_loss = 0.048305256919441174
Trained batch 49 in epoch 9, gen_loss = 0.8909413170814514, disc_loss = 0.05038686512038112
Trained batch 50 in epoch 9, gen_loss = 0.8937986084059173, disc_loss = 0.052346005141004626
Trained batch 51 in epoch 9, gen_loss = 0.8949954154399725, disc_loss = 0.051818679785355926
Trained batch 52 in epoch 9, gen_loss = 0.8934535732809102, disc_loss = 0.051290644069184675
Trained batch 53 in epoch 9, gen_loss = 0.896766620653647, disc_loss = 0.05089534517308628
Trained batch 54 in epoch 9, gen_loss = 0.8974859920415011, disc_loss = 0.050262615745040505
Trained batch 55 in epoch 9, gen_loss = 0.8939128454242434, disc_loss = 0.0506493790973244
Trained batch 56 in epoch 9, gen_loss = 0.9008671526323285, disc_loss = 0.05040197896264624
Trained batch 57 in epoch 9, gen_loss = 0.9002180490000494, disc_loss = 0.04976880926125009
Trained batch 58 in epoch 9, gen_loss = 0.8997752030017012, disc_loss = 0.049308617488812594
Trained batch 59 in epoch 9, gen_loss = 0.8965251276890437, disc_loss = 0.04904099454482396
Trained batch 60 in epoch 9, gen_loss = 0.8937451585394437, disc_loss = 0.04942629254255138
Trained batch 61 in epoch 9, gen_loss = 0.8978689543662532, disc_loss = 0.05086127884926334
Trained batch 62 in epoch 9, gen_loss = 0.9012507976047577, disc_loss = 0.050610914530735164
Trained batch 63 in epoch 9, gen_loss = 0.8956701653078198, disc_loss = 0.050834516587201506
Trained batch 64 in epoch 9, gen_loss = 0.8926434122599088, disc_loss = 0.0514405373770457
Trained batch 65 in epoch 9, gen_loss = 0.8938398406361089, disc_loss = 0.05091542558688106
Trained batch 66 in epoch 9, gen_loss = 0.8969217939163322, disc_loss = 0.051506431578700225
Trained batch 67 in epoch 9, gen_loss = 0.8943671899683335, disc_loss = 0.05120774876216755
Trained batch 68 in epoch 9, gen_loss = 0.8931832132132157, disc_loss = 0.05181598266505677
Trained batch 69 in epoch 9, gen_loss = 0.887207237311772, disc_loss = 0.05347892995923757
Trained batch 70 in epoch 9, gen_loss = 0.8838870088819047, disc_loss = 0.05401202818562447
Trained batch 71 in epoch 9, gen_loss = 0.8871317240926955, disc_loss = 0.053926158153141536
Trained batch 72 in epoch 9, gen_loss = 0.8878235082103781, disc_loss = 0.05348524402775993
Trained batch 73 in epoch 9, gen_loss = 0.8881332761532551, disc_loss = 0.05299844907445682
Trained batch 74 in epoch 9, gen_loss = 0.883607779343923, disc_loss = 0.05397940032184124
Trained batch 75 in epoch 9, gen_loss = 0.8819210545012826, disc_loss = 0.054623716094188
Trained batch 76 in epoch 9, gen_loss = 0.8818935689988074, disc_loss = 0.05436339676863961
Trained batch 77 in epoch 9, gen_loss = 0.8789488191788013, disc_loss = 0.05436609019167148
Trained batch 78 in epoch 9, gen_loss = 0.878073846992058, disc_loss = 0.05425033772576459
Trained batch 79 in epoch 9, gen_loss = 0.8837037958204746, disc_loss = 0.05685038424562663
Trained batch 80 in epoch 9, gen_loss = 0.8810064873577635, disc_loss = 0.05737285801198012
Trained batch 81 in epoch 9, gen_loss = 0.8777204301299119, disc_loss = 0.059662920922586106
Trained batch 82 in epoch 9, gen_loss = 0.8794955158808145, disc_loss = 0.05919661581606032
Trained batch 83 in epoch 9, gen_loss = 0.8799313654502233, disc_loss = 0.05897709135232227
Trained batch 84 in epoch 9, gen_loss = 0.8794432969654308, disc_loss = 0.05861533106688191
Trained batch 85 in epoch 9, gen_loss = 0.8776805698871613, disc_loss = 0.05849389725386403
Trained batch 86 in epoch 9, gen_loss = 0.8783598487404571, disc_loss = 0.05860742329266565
Trained batch 87 in epoch 9, gen_loss = 0.8751286098902876, disc_loss = 0.05888609547930008
Trained batch 88 in epoch 9, gen_loss = 0.8732414319274131, disc_loss = 0.05918538003239069
Trained batch 89 in epoch 9, gen_loss = 0.872617648045222, disc_loss = 0.058713241728643575
Trained batch 90 in epoch 9, gen_loss = 0.8761536740994715, disc_loss = 0.05955404483273134
Trained batch 91 in epoch 9, gen_loss = 0.8729852567548337, disc_loss = 0.05963122356764
Trained batch 92 in epoch 9, gen_loss = 0.8737905730483353, disc_loss = 0.059116973191179256
Trained batch 93 in epoch 9, gen_loss = 0.8732854926839788, disc_loss = 0.058854924078951494
Trained batch 94 in epoch 9, gen_loss = 0.87114350293812, disc_loss = 0.05922198985752306
Trained batch 95 in epoch 9, gen_loss = 0.8679945108791193, disc_loss = 0.05936737389614185
Trained batch 96 in epoch 9, gen_loss = 0.8699162080115879, disc_loss = 0.05927710511635259
Trained batch 97 in epoch 9, gen_loss = 0.8665098858122923, disc_loss = 0.06095824299418196
Trained batch 98 in epoch 9, gen_loss = 0.8710140802643516, disc_loss = 0.06321007449819584
Trained batch 99 in epoch 9, gen_loss = 0.8710520201921463, disc_loss = 0.062713732291013
Trained batch 100 in epoch 9, gen_loss = 0.8689730869661464, disc_loss = 0.06291314017138269
Trained batch 101 in epoch 9, gen_loss = 0.8688992863776637, disc_loss = 0.06248330768636044
Trained batch 102 in epoch 9, gen_loss = 0.8684291891681338, disc_loss = 0.06246390897165803
Trained batch 103 in epoch 9, gen_loss = 0.8686723290727689, disc_loss = 0.06205085433947925
Trained batch 104 in epoch 9, gen_loss = 0.8694009014538356, disc_loss = 0.062181437707373076
Trained batch 105 in epoch 9, gen_loss = 0.8691296740522925, disc_loss = 0.061780807773037905
Trained batch 106 in epoch 9, gen_loss = 0.8677379650490307, disc_loss = 0.061552878103662875
Trained batch 107 in epoch 9, gen_loss = 0.8672255553581096, disc_loss = 0.06107577298664384
Trained batch 108 in epoch 9, gen_loss = 0.8674194872926134, disc_loss = 0.06108374093924094
Trained batch 109 in epoch 9, gen_loss = 0.8675301470539787, disc_loss = 0.06151137927716428
Trained batch 110 in epoch 9, gen_loss = 0.8665274596429086, disc_loss = 0.061338443074140464
Trained batch 111 in epoch 9, gen_loss = 0.8633745312690735, disc_loss = 0.06296837037163121
Trained batch 112 in epoch 9, gen_loss = 0.8659392574192148, disc_loss = 0.06313337570270605
Trained batch 113 in epoch 9, gen_loss = 0.8652136728428957, disc_loss = 0.06279114728564755
Trained batch 114 in epoch 9, gen_loss = 0.8667053207107213, disc_loss = 0.062404147632744
Trained batch 115 in epoch 9, gen_loss = 0.8647103001331461, disc_loss = 0.06245183116146203
Trained batch 116 in epoch 9, gen_loss = 0.8652791416543162, disc_loss = 0.06211300633656673
Trained batch 117 in epoch 9, gen_loss = 0.8643210105976816, disc_loss = 0.0618923012861761
Trained batch 118 in epoch 9, gen_loss = 0.8659427236108219, disc_loss = 0.06306560531634242
Trained batch 119 in epoch 9, gen_loss = 0.8630867848793665, disc_loss = 0.06369332801550627
Trained batch 120 in epoch 9, gen_loss = 0.8626018703476457, disc_loss = 0.06383241583739431
Trained batch 121 in epoch 9, gen_loss = 0.863558783882954, disc_loss = 0.06407823163222094
Trained batch 122 in epoch 9, gen_loss = 0.8626377456556491, disc_loss = 0.06422126917092781
Trained batch 123 in epoch 9, gen_loss = 0.8612910461041235, disc_loss = 0.06429296341394225
Trained batch 124 in epoch 9, gen_loss = 0.863028169631958, disc_loss = 0.06461968302726745
Trained batch 125 in epoch 9, gen_loss = 0.862144528873383, disc_loss = 0.06477986116494451
Trained batch 126 in epoch 9, gen_loss = 0.8601276104844461, disc_loss = 0.06475075744972454
Trained batch 127 in epoch 9, gen_loss = 0.8614548090845346, disc_loss = 0.06444316646957304
Trained batch 128 in epoch 9, gen_loss = 0.86281222336052, disc_loss = 0.06413827172314474
Trained batch 129 in epoch 9, gen_loss = 0.8617652292434986, disc_loss = 0.06420697357792121
Trained batch 130 in epoch 9, gen_loss = 0.8633431846858891, disc_loss = 0.06384175535262997
Trained batch 131 in epoch 9, gen_loss = 0.8638999258930032, disc_loss = 0.0635273919694803
Trained batch 132 in epoch 9, gen_loss = 0.8648879156076819, disc_loss = 0.06322825862500901
Trained batch 133 in epoch 9, gen_loss = 0.866051117430872, disc_loss = 0.06289687812495143
Trained batch 134 in epoch 9, gen_loss = 0.867023730719531, disc_loss = 0.06327447144797554
Trained batch 135 in epoch 9, gen_loss = 0.865661617149325, disc_loss = 0.06322782320956535
Trained batch 136 in epoch 9, gen_loss = 0.8644287773292431, disc_loss = 0.06310425632137016
Trained batch 137 in epoch 9, gen_loss = 0.8654087522755498, disc_loss = 0.06292262105136245
Trained batch 138 in epoch 9, gen_loss = 0.8672867644605019, disc_loss = 0.06261981091053366
Trained batch 139 in epoch 9, gen_loss = 0.8672262557915279, disc_loss = 0.06245385730373008
Trained batch 140 in epoch 9, gen_loss = 0.8662000996001223, disc_loss = 0.062336465436304715
Trained batch 141 in epoch 9, gen_loss = 0.8652746030982111, disc_loss = 0.062189506917772155
Trained batch 142 in epoch 9, gen_loss = 0.8653594338810527, disc_loss = 0.06283045033891718
Trained batch 143 in epoch 9, gen_loss = 0.8640321588350667, disc_loss = 0.06298518517158097
Trained batch 144 in epoch 9, gen_loss = 0.8631355166435242, disc_loss = 0.06290677888640042
Trained batch 145 in epoch 9, gen_loss = 0.8627231770182309, disc_loss = 0.06303797060087936
Trained batch 146 in epoch 9, gen_loss = 0.863993859209982, disc_loss = 0.06316513750626117
Trained batch 147 in epoch 9, gen_loss = 0.8628584718382036, disc_loss = 0.06301027173931534
Trained batch 148 in epoch 9, gen_loss = 0.8623180293396815, disc_loss = 0.0628247777337596
Trained batch 149 in epoch 9, gen_loss = 0.8617881727218628, disc_loss = 0.0626982675989469
Trained batch 150 in epoch 9, gen_loss = 0.8606896191243304, disc_loss = 0.062496424905511716
Trained batch 151 in epoch 9, gen_loss = 0.8613865924508948, disc_loss = 0.06221539154648781
Trained batch 152 in epoch 9, gen_loss = 0.8604200151231554, disc_loss = 0.06207932069215899
Trained batch 153 in epoch 9, gen_loss = 0.8608541840856726, disc_loss = 0.06198819852494574
Trained batch 154 in epoch 9, gen_loss = 0.8610239344258462, disc_loss = 0.06176179426331674
Trained batch 155 in epoch 9, gen_loss = 0.862703141493675, disc_loss = 0.06152785165856282
Trained batch 156 in epoch 9, gen_loss = 0.8630380045836139, disc_loss = 0.06119346025453252
Trained batch 157 in epoch 9, gen_loss = 0.8642259987094735, disc_loss = 0.060868330842143374
Trained batch 158 in epoch 9, gen_loss = 0.8642376323915878, disc_loss = 0.06063660841036893
Trained batch 159 in epoch 9, gen_loss = 0.8654033847153186, disc_loss = 0.060714085842482744
Trained batch 160 in epoch 9, gen_loss = 0.8636573982534942, disc_loss = 0.061081437613838205
Trained batch 161 in epoch 9, gen_loss = 0.8643463835304166, disc_loss = 0.060889665612284045
Trained batch 162 in epoch 9, gen_loss = 0.864673931174483, disc_loss = 0.06061931181859019
Trained batch 163 in epoch 9, gen_loss = 0.8664391731343618, disc_loss = 0.060359843631797444
Trained batch 164 in epoch 9, gen_loss = 0.866508935437058, disc_loss = 0.060896909428816856
Trained batch 165 in epoch 9, gen_loss = 0.8641710459108812, disc_loss = 0.06205443626112608
Trained batch 166 in epoch 9, gen_loss = 0.866340934694884, disc_loss = 0.06188405652023004
Trained batch 167 in epoch 9, gen_loss = 0.8662673176399299, disc_loss = 0.06171539309434593
Trained batch 168 in epoch 9, gen_loss = 0.8656289039631567, disc_loss = 0.061870871067664326
Trained batch 169 in epoch 9, gen_loss = 0.8669625203399097, disc_loss = 0.06162622957764303
Trained batch 170 in epoch 9, gen_loss = 0.8671351589306057, disc_loss = 0.06134663118125751
Trained batch 171 in epoch 9, gen_loss = 0.8666126307013423, disc_loss = 0.0611890385382224
Trained batch 172 in epoch 9, gen_loss = 0.8658297142886013, disc_loss = 0.060969666755526744
Trained batch 173 in epoch 9, gen_loss = 0.865204816748356, disc_loss = 0.06081645009803704
Trained batch 174 in epoch 9, gen_loss = 0.8649213778972625, disc_loss = 0.06090175159275532
Trained batch 175 in epoch 9, gen_loss = 0.8660055251622741, disc_loss = 0.06064856215380132
Trained batch 176 in epoch 9, gen_loss = 0.8669833828837185, disc_loss = 0.060462303954245004
Trained batch 177 in epoch 9, gen_loss = 0.864512896102466, disc_loss = 0.06123034374558189
Trained batch 178 in epoch 9, gen_loss = 0.8659538981301824, disc_loss = 0.06103047588059689
Trained batch 179 in epoch 9, gen_loss = 0.8662677783105108, disc_loss = 0.06117713692494565
Trained batch 180 in epoch 9, gen_loss = 0.8662331570248577, disc_loss = 0.06094449212085147
Trained batch 181 in epoch 9, gen_loss = 0.8651761008160455, disc_loss = 0.06085349477131616
Trained batch 182 in epoch 9, gen_loss = 0.8655894182093157, disc_loss = 0.06063895542276362
Trained batch 183 in epoch 9, gen_loss = 0.8680092402450417, disc_loss = 0.060949589976150055
Trained batch 184 in epoch 9, gen_loss = 0.8678714608823931, disc_loss = 0.06075642490507783
Trained batch 185 in epoch 9, gen_loss = 0.8678974212818248, disc_loss = 0.06052000735515869
Trained batch 186 in epoch 9, gen_loss = 0.8671541846690969, disc_loss = 0.06070603353573995
Trained batch 187 in epoch 9, gen_loss = 0.8675732721990728, disc_loss = 0.060607949202444326
Trained batch 188 in epoch 9, gen_loss = 0.8692754420338484, disc_loss = 0.06067955274154585
Trained batch 189 in epoch 9, gen_loss = 0.8683617245209845, disc_loss = 0.06095935071965582
Trained batch 190 in epoch 9, gen_loss = 0.8691301300575596, disc_loss = 0.06091062955714333
Trained batch 191 in epoch 9, gen_loss = 0.8711325108694533, disc_loss = 0.06082445496576838
Trained batch 192 in epoch 9, gen_loss = 0.8702615714134948, disc_loss = 0.0611319792953952
Trained batch 193 in epoch 9, gen_loss = 0.8697473859971332, disc_loss = 0.06101086627231123
Trained batch 194 in epoch 9, gen_loss = 0.8701811370177147, disc_loss = 0.0608590683589379
Trained batch 195 in epoch 9, gen_loss = 0.8723611656804474, disc_loss = 0.06107290223126813
Trained batch 196 in epoch 9, gen_loss = 0.8722318436591153, disc_loss = 0.060903495139806405
Trained batch 197 in epoch 9, gen_loss = 0.8712215015683511, disc_loss = 0.0612099597682104
Trained batch 198 in epoch 9, gen_loss = 0.8719238541533599, disc_loss = 0.061736990711721944
Trained batch 199 in epoch 9, gen_loss = 0.8734017534554005, disc_loss = 0.0618869577627629
Trained batch 200 in epoch 9, gen_loss = 0.8727795162900763, disc_loss = 0.061970746589463145
Trained batch 201 in epoch 9, gen_loss = 0.8720306749686156, disc_loss = 0.06185191772915054
Trained batch 202 in epoch 9, gen_loss = 0.872522432081805, disc_loss = 0.06164619516526244
Trained batch 203 in epoch 9, gen_loss = 0.8746698082369917, disc_loss = 0.06203616898981672
Trained batch 204 in epoch 9, gen_loss = 0.8734198469941209, disc_loss = 0.06250507009283798
Trained batch 205 in epoch 9, gen_loss = 0.8727707392671733, disc_loss = 0.06239641326687579
Trained batch 206 in epoch 9, gen_loss = 0.8736115992069244, disc_loss = 0.06245165025806369
Trained batch 207 in epoch 9, gen_loss = 0.8736412919198091, disc_loss = 0.06226892126365923
Trained batch 208 in epoch 9, gen_loss = 0.8723723744376425, disc_loss = 0.06245126922806484
Trained batch 209 in epoch 9, gen_loss = 0.8732755517675763, disc_loss = 0.06255062224254722
Trained batch 210 in epoch 9, gen_loss = 0.8718669836837534, disc_loss = 0.06274876777100337
Trained batch 211 in epoch 9, gen_loss = 0.8713592371007182, disc_loss = 0.06279780815865071
Trained batch 212 in epoch 9, gen_loss = 0.8716996750081649, disc_loss = 0.0631163363200678
Trained batch 213 in epoch 9, gen_loss = 0.8700736929601598, disc_loss = 0.06382202734805156
Trained batch 214 in epoch 9, gen_loss = 0.869792293809181, disc_loss = 0.06386875657494678
Trained batch 215 in epoch 9, gen_loss = 0.8696565218269825, disc_loss = 0.06376354618825847
Trained batch 216 in epoch 9, gen_loss = 0.8694195987716797, disc_loss = 0.06378295191902719
Trained batch 217 in epoch 9, gen_loss = 0.8700606668487602, disc_loss = 0.0638824440709768
Trained batch 218 in epoch 9, gen_loss = 0.869812547752302, disc_loss = 0.06400454144703743
Trained batch 219 in epoch 9, gen_loss = 0.8692768374627287, disc_loss = 0.06412814880975268
Trained batch 220 in epoch 9, gen_loss = 0.8687830493191249, disc_loss = 0.06405489482154134
Trained batch 221 in epoch 9, gen_loss = 0.8695077067828393, disc_loss = 0.06390891346644174
Trained batch 222 in epoch 9, gen_loss = 0.8690334386087853, disc_loss = 0.06383216937360742
Trained batch 223 in epoch 9, gen_loss = 0.869478192047349, disc_loss = 0.06390477425884455
Trained batch 224 in epoch 9, gen_loss = 0.8689097909132639, disc_loss = 0.06391423697272937
Trained batch 225 in epoch 9, gen_loss = 0.868136206691244, disc_loss = 0.06398360874602753
Trained batch 226 in epoch 9, gen_loss = 0.8695691431408937, disc_loss = 0.06452522241399677
Trained batch 227 in epoch 9, gen_loss = 0.8686997672183472, disc_loss = 0.06448364100958172
Trained batch 228 in epoch 9, gen_loss = 0.8683572899566467, disc_loss = 0.06438363735527451
Trained batch 229 in epoch 9, gen_loss = 0.8671848876320798, disc_loss = 0.06439286319781905
Trained batch 230 in epoch 9, gen_loss = 0.8674658244048362, disc_loss = 0.06418661463570285
Trained batch 231 in epoch 9, gen_loss = 0.8680639319635671, disc_loss = 0.06449464650760436
Trained batch 232 in epoch 9, gen_loss = 0.8668984155542349, disc_loss = 0.06452199516122434
Trained batch 233 in epoch 9, gen_loss = 0.8663434795080087, disc_loss = 0.06443406942372139
Trained batch 234 in epoch 9, gen_loss = 0.8668444972088997, disc_loss = 0.06426059129707357
Trained batch 235 in epoch 9, gen_loss = 0.8669001021880215, disc_loss = 0.06412579468056812
Trained batch 236 in epoch 9, gen_loss = 0.8662264242705413, disc_loss = 0.064083053828669
Trained batch 237 in epoch 9, gen_loss = 0.8670292047141981, disc_loss = 0.0640475750282532
Trained batch 238 in epoch 9, gen_loss = 0.8676925040937368, disc_loss = 0.06384098933518681
Trained batch 239 in epoch 9, gen_loss = 0.8670284943034251, disc_loss = 0.06382292204846939
Trained batch 240 in epoch 9, gen_loss = 0.8669029710451103, disc_loss = 0.06362712840043411
Trained batch 241 in epoch 9, gen_loss = 0.8682802027660953, disc_loss = 0.06384388159591058
Trained batch 242 in epoch 9, gen_loss = 0.8684182052994952, disc_loss = 0.06374416864427274
Trained batch 243 in epoch 9, gen_loss = 0.8682043323995637, disc_loss = 0.06369805660434678
Trained batch 244 in epoch 9, gen_loss = 0.8678646366206967, disc_loss = 0.06360087847071035
Trained batch 245 in epoch 9, gen_loss = 0.867940990057418, disc_loss = 0.06371665366630001
Trained batch 246 in epoch 9, gen_loss = 0.8685316799381967, disc_loss = 0.06349434708490183
Trained batch 247 in epoch 9, gen_loss = 0.8674240875388345, disc_loss = 0.06372513972418083
Trained batch 248 in epoch 9, gen_loss = 0.8676259588285622, disc_loss = 0.0636236802020286
Trained batch 249 in epoch 9, gen_loss = 0.8690095928907394, disc_loss = 0.06359633483365178
Trained batch 250 in epoch 9, gen_loss = 0.8679855614306917, disc_loss = 0.06351033116197324
Trained batch 251 in epoch 9, gen_loss = 0.8681567433098006, disc_loss = 0.06331515217214705
Trained batch 252 in epoch 9, gen_loss = 0.8680280747385364, disc_loss = 0.0631302386897767
Trained batch 253 in epoch 9, gen_loss = 0.8677627077018182, disc_loss = 0.06296839874868435
Trained batch 254 in epoch 9, gen_loss = 0.8674205916769364, disc_loss = 0.06286141859623147
Trained batch 255 in epoch 9, gen_loss = 0.8682223461801186, disc_loss = 0.06268765549248201
Trained batch 256 in epoch 9, gen_loss = 0.8684479609305756, disc_loss = 0.0625971851595007
Trained batch 257 in epoch 9, gen_loss = 0.8674645034610763, disc_loss = 0.06254508202289079
Trained batch 258 in epoch 9, gen_loss = 0.8671619605603825, disc_loss = 0.06251454811082958
Trained batch 259 in epoch 9, gen_loss = 0.868778666968529, disc_loss = 0.06294443788221822
Trained batch 260 in epoch 9, gen_loss = 0.8689979695040604, disc_loss = 0.06282965972006206
Trained batch 261 in epoch 9, gen_loss = 0.8682440991392573, disc_loss = 0.06305386827377077
Trained batch 262 in epoch 9, gen_loss = 0.868433688643314, disc_loss = 0.06288123535551839
Trained batch 263 in epoch 9, gen_loss = 0.8689711560128313, disc_loss = 0.06268712576958492
Trained batch 264 in epoch 9, gen_loss = 0.868797485221107, disc_loss = 0.06256775039968626
Trained batch 265 in epoch 9, gen_loss = 0.8689625589247036, disc_loss = 0.06243288051337004
Trained batch 266 in epoch 9, gen_loss = 0.8695560898003953, disc_loss = 0.062372300418072874
Trained batch 267 in epoch 9, gen_loss = 0.8694502336542997, disc_loss = 0.06233391077466198
Trained batch 268 in epoch 9, gen_loss = 0.8694651491358377, disc_loss = 0.06219648882109658
Trained batch 269 in epoch 9, gen_loss = 0.8679920016615479, disc_loss = 0.06279968199216657
Trained batch 270 in epoch 9, gen_loss = 0.8689799349466373, disc_loss = 0.06284742875925069
Trained batch 271 in epoch 9, gen_loss = 0.8690716401838204, disc_loss = 0.06269050653859534
Trained batch 272 in epoch 9, gen_loss = 0.8685483968519903, disc_loss = 0.06261262606024305
Trained batch 273 in epoch 9, gen_loss = 0.8691754603255404, disc_loss = 0.062445397060500445
Trained batch 274 in epoch 9, gen_loss = 0.8693461722677405, disc_loss = 0.0622474962269718
Trained batch 275 in epoch 9, gen_loss = 0.8700828445346459, disc_loss = 0.062190394801344126
Trained batch 276 in epoch 9, gen_loss = 0.8690925544995263, disc_loss = 0.06243265488114383
Trained batch 277 in epoch 9, gen_loss = 0.8690941390588129, disc_loss = 0.06227012473768253
Trained batch 278 in epoch 9, gen_loss = 0.8701846810011026, disc_loss = 0.0625862578751259
Trained batch 279 in epoch 9, gen_loss = 0.8699189561818327, disc_loss = 0.06247827175871602
Trained batch 280 in epoch 9, gen_loss = 0.8697160742248928, disc_loss = 0.06244538239869571
Trained batch 281 in epoch 9, gen_loss = 0.8700401094999719, disc_loss = 0.062262828739241084
Trained batch 282 in epoch 9, gen_loss = 0.8697311291635669, disc_loss = 0.06217884398049053
Trained batch 283 in epoch 9, gen_loss = 0.8697669116753928, disc_loss = 0.06203720687796742
Trained batch 284 in epoch 9, gen_loss = 0.8699571832230216, disc_loss = 0.06193595372401831
Trained batch 285 in epoch 9, gen_loss = 0.869946176876555, disc_loss = 0.061782683493322006
Trained batch 286 in epoch 9, gen_loss = 0.8697378657213072, disc_loss = 0.06167999241591954
Trained batch 287 in epoch 9, gen_loss = 0.8703278266928263, disc_loss = 0.06166529191735511
Trained batch 288 in epoch 9, gen_loss = 0.8696507134033322, disc_loss = 0.06163551506931188
Trained batch 289 in epoch 9, gen_loss = 0.8695748424735562, disc_loss = 0.061473295786257445
Trained batch 290 in epoch 9, gen_loss = 0.8699953112610427, disc_loss = 0.06133877750985401
Trained batch 291 in epoch 9, gen_loss = 0.8695543603333709, disc_loss = 0.06130013061202552
Trained batch 292 in epoch 9, gen_loss = 0.8693406070255175, disc_loss = 0.061215437274845796
Trained batch 293 in epoch 9, gen_loss = 0.870381836278909, disc_loss = 0.061574202829173634
Trained batch 294 in epoch 9, gen_loss = 0.8699334794181889, disc_loss = 0.06161299952763622
Trained batch 295 in epoch 9, gen_loss = 0.868959327505247, disc_loss = 0.061911044478718494
Trained batch 296 in epoch 9, gen_loss = 0.8698237035611663, disc_loss = 0.062140584832389746
Trained batch 297 in epoch 9, gen_loss = 0.8695466463397813, disc_loss = 0.062054532223799884
Trained batch 298 in epoch 9, gen_loss = 0.8692529222438965, disc_loss = 0.06234859516937597
Trained batch 299 in epoch 9, gen_loss = 0.8687043171127637, disc_loss = 0.06250373382121324
Trained batch 300 in epoch 9, gen_loss = 0.8685510793199571, disc_loss = 0.06240674495647516
Trained batch 301 in epoch 9, gen_loss = 0.8688131518513951, disc_loss = 0.06230092929392461
Trained batch 302 in epoch 9, gen_loss = 0.8683183115504363, disc_loss = 0.062257635490138935
Trained batch 303 in epoch 9, gen_loss = 0.8684443173635947, disc_loss = 0.062137625835786914
Trained batch 304 in epoch 9, gen_loss = 0.867966756371201, disc_loss = 0.06213326973871129
Trained batch 305 in epoch 9, gen_loss = 0.8684920911111084, disc_loss = 0.06201019955592023
Trained batch 306 in epoch 9, gen_loss = 0.8683267681334617, disc_loss = 0.06186702251070291
Trained batch 307 in epoch 9, gen_loss = 0.867757918482477, disc_loss = 0.06181944502130538
Trained batch 308 in epoch 9, gen_loss = 0.8682640259512806, disc_loss = 0.06170180470088925
Trained batch 309 in epoch 9, gen_loss = 0.868829493080416, disc_loss = 0.061602736018117395
Trained batch 310 in epoch 9, gen_loss = 0.8686202730971517, disc_loss = 0.06154930418495005
Trained batch 311 in epoch 9, gen_loss = 0.868550051194735, disc_loss = 0.06139161471181955
Trained batch 312 in epoch 9, gen_loss = 0.8681151787884319, disc_loss = 0.06128508169144487
Trained batch 313 in epoch 9, gen_loss = 0.8686050454712217, disc_loss = 0.061655172330748506
Trained batch 314 in epoch 9, gen_loss = 0.8675988115015484, disc_loss = 0.061824067031580304
Trained batch 315 in epoch 9, gen_loss = 0.8674038619368891, disc_loss = 0.06192742703081686
Trained batch 316 in epoch 9, gen_loss = 0.8676497363705741, disc_loss = 0.062277207944295386
Trained batch 317 in epoch 9, gen_loss = 0.8668327473057141, disc_loss = 0.06244812692579983
Trained batch 318 in epoch 9, gen_loss = 0.8664129915469119, disc_loss = 0.062448203189993355
Trained batch 319 in epoch 9, gen_loss = 0.8672316054813564, disc_loss = 0.06269577876664698
Trained batch 320 in epoch 9, gen_loss = 0.867043837858509, disc_loss = 0.06258384714547162
Trained batch 321 in epoch 9, gen_loss = 0.8661690425613652, disc_loss = 0.06291669272233426
Trained batch 322 in epoch 9, gen_loss = 0.866317806321401, disc_loss = 0.06294290399057761
Trained batch 323 in epoch 9, gen_loss = 0.8664468971115572, disc_loss = 0.06287585668564763
Trained batch 324 in epoch 9, gen_loss = 0.8666634626571948, disc_loss = 0.06274670952214645
Trained batch 325 in epoch 9, gen_loss = 0.8660647857225746, disc_loss = 0.06283932593451139
Trained batch 326 in epoch 9, gen_loss = 0.8662300291229096, disc_loss = 0.0628722276629749
Trained batch 327 in epoch 9, gen_loss = 0.8661601502539181, disc_loss = 0.06287318311926977
Trained batch 328 in epoch 9, gen_loss = 0.8654300000711053, disc_loss = 0.06285622038264224
Trained batch 329 in epoch 9, gen_loss = 0.8650746503562639, disc_loss = 0.0629306942619609
Trained batch 330 in epoch 9, gen_loss = 0.8653887642654408, disc_loss = 0.06290339593553292
Trained batch 331 in epoch 9, gen_loss = 0.8660591566957623, disc_loss = 0.06292591298402972
Trained batch 332 in epoch 9, gen_loss = 0.8653644322454035, disc_loss = 0.06293669994640816
Trained batch 333 in epoch 9, gen_loss = 0.8657954505639162, disc_loss = 0.06278077467807575
Trained batch 334 in epoch 9, gen_loss = 0.8657442159617125, disc_loss = 0.06270315894551241
Trained batch 335 in epoch 9, gen_loss = 0.8659300547802732, disc_loss = 0.06256359143160461
Trained batch 336 in epoch 9, gen_loss = 0.8651998480809548, disc_loss = 0.06255165982206604
Trained batch 337 in epoch 9, gen_loss = 0.8651270782630119, disc_loss = 0.062433761880683475
Trained batch 338 in epoch 9, gen_loss = 0.8649577668107014, disc_loss = 0.06250035816633244
Trained batch 339 in epoch 9, gen_loss = 0.8643679712625111, disc_loss = 0.06252206562853911
Trained batch 340 in epoch 9, gen_loss = 0.8635684595254859, disc_loss = 0.0627467267739633
Trained batch 341 in epoch 9, gen_loss = 0.8639381269091054, disc_loss = 0.0628927694796993
Trained batch 342 in epoch 9, gen_loss = 0.8631940443209934, disc_loss = 0.06324887211616463
Trained batch 343 in epoch 9, gen_loss = 0.8641901750030906, disc_loss = 0.06346695139181129
Trained batch 344 in epoch 9, gen_loss = 0.8634533979754517, disc_loss = 0.0635720911341301
Trained batch 345 in epoch 9, gen_loss = 0.8633743907847157, disc_loss = 0.0634815484349955
Trained batch 346 in epoch 9, gen_loss = 0.8631648107804895, disc_loss = 0.06343597357271384
Trained batch 347 in epoch 9, gen_loss = 0.863295671669231, disc_loss = 0.06343015336870463
Trained batch 348 in epoch 9, gen_loss = 0.8629232423865693, disc_loss = 0.0633698878302786
Trained batch 349 in epoch 9, gen_loss = 0.8618707188538143, disc_loss = 0.06375186440135751
Trained batch 350 in epoch 9, gen_loss = 0.8626642371514583, disc_loss = 0.06411939210913799
Trained batch 351 in epoch 9, gen_loss = 0.8632700617679141, disc_loss = 0.06456502489957282
Trained batch 352 in epoch 9, gen_loss = 0.8624819495184901, disc_loss = 0.06481333086451795
Trained batch 353 in epoch 9, gen_loss = 0.8624424265939638, disc_loss = 0.06480627882657415
Trained batch 354 in epoch 9, gen_loss = 0.8620556608052321, disc_loss = 0.06471441105847628
Trained batch 355 in epoch 9, gen_loss = 0.8614486445871632, disc_loss = 0.06485942398522342
Trained batch 356 in epoch 9, gen_loss = 0.8612318281032124, disc_loss = 0.06534681453549561
Trained batch 357 in epoch 9, gen_loss = 0.861138710596042, disc_loss = 0.06530626108817882
Trained batch 358 in epoch 9, gen_loss = 0.8603163359889081, disc_loss = 0.06543120514591093
Trained batch 359 in epoch 9, gen_loss = 0.8599555411272579, disc_loss = 0.06547676725313067
Trained batch 360 in epoch 9, gen_loss = 0.8599436611680112, disc_loss = 0.06537304713888677
Trained batch 361 in epoch 9, gen_loss = 0.859926739285664, disc_loss = 0.06525936226221574
Trained batch 362 in epoch 9, gen_loss = 0.8600220294366526, disc_loss = 0.06526982268580228
Trained batch 363 in epoch 9, gen_loss = 0.860316956272492, disc_loss = 0.06512767724580244
Trained batch 364 in epoch 9, gen_loss = 0.8600611743861681, disc_loss = 0.06504551657309679
Trained batch 365 in epoch 9, gen_loss = 0.8601030230196447, disc_loss = 0.06493503878483436
Trained batch 366 in epoch 9, gen_loss = 0.8599977969148828, disc_loss = 0.0648181470801257
Trained batch 367 in epoch 9, gen_loss = 0.8599676650179469, disc_loss = 0.06513840817269342
Trained batch 368 in epoch 9, gen_loss = 0.8601482345805904, disc_loss = 0.06500558180325641
Trained batch 369 in epoch 9, gen_loss = 0.8601884961128234, disc_loss = 0.06486835062403132
Trained batch 370 in epoch 9, gen_loss = 0.8605965764696064, disc_loss = 0.06477837720910976
Trained batch 371 in epoch 9, gen_loss = 0.8599157112260019, disc_loss = 0.06483693661729015
Trained batch 372 in epoch 9, gen_loss = 0.8593959765204155, disc_loss = 0.06485676504272078
Trained batch 373 in epoch 9, gen_loss = 0.8599209398190606, disc_loss = 0.06482588533152711
Trained batch 374 in epoch 9, gen_loss = 0.8594894793828328, disc_loss = 0.06483521329859893
Trained batch 375 in epoch 9, gen_loss = 0.8586052486554105, disc_loss = 0.06490230399302821
Trained batch 376 in epoch 9, gen_loss = 0.8592142889607174, disc_loss = 0.06504151042778075
Trained batch 377 in epoch 9, gen_loss = 0.85863766200328, disc_loss = 0.06511267623001779
Trained batch 378 in epoch 9, gen_loss = 0.8592796154261264, disc_loss = 0.06500284199290823
Trained batch 379 in epoch 9, gen_loss = 0.8589178601377889, disc_loss = 0.06503447320214227
Trained batch 380 in epoch 9, gen_loss = 0.8590263935524648, disc_loss = 0.06491399368667226
Trained batch 381 in epoch 9, gen_loss = 0.8594439837945069, disc_loss = 0.06486215346848777
Trained batch 382 in epoch 9, gen_loss = 0.8594708349312565, disc_loss = 0.06473924528914395
Trained batch 383 in epoch 9, gen_loss = 0.8587343227118254, disc_loss = 0.06475075392518193
Trained batch 384 in epoch 9, gen_loss = 0.858695463700728, disc_loss = 0.06462586706431656
Trained batch 385 in epoch 9, gen_loss = 0.858425237971884, disc_loss = 0.06465952764771918
Trained batch 386 in epoch 9, gen_loss = 0.8585214664153659, disc_loss = 0.06516904796375014
Trained batch 387 in epoch 9, gen_loss = 0.8579094863122272, disc_loss = 0.06524797884708981
Trained batch 388 in epoch 9, gen_loss = 0.8574357118582051, disc_loss = 0.06523090780528315
Trained batch 389 in epoch 9, gen_loss = 0.8575196816371038, disc_loss = 0.0652339037746573
Trained batch 390 in epoch 9, gen_loss = 0.8572493806824355, disc_loss = 0.06526189382709659
Trained batch 391 in epoch 9, gen_loss = 0.8576104534523827, disc_loss = 0.06512414238282613
Trained batch 392 in epoch 9, gen_loss = 0.8580176050729728, disc_loss = 0.06515539132305077
Trained batch 393 in epoch 9, gen_loss = 0.8577540043344353, disc_loss = 0.0651668837379078
Trained batch 394 in epoch 9, gen_loss = 0.8573368028749393, disc_loss = 0.06513592632888239
Trained batch 395 in epoch 9, gen_loss = 0.857802017319082, disc_loss = 0.0650407963037265
Trained batch 396 in epoch 9, gen_loss = 0.857882161734987, disc_loss = 0.0649686609852299
Trained batch 397 in epoch 9, gen_loss = 0.8577465985588093, disc_loss = 0.06488231101059284
Trained batch 398 in epoch 9, gen_loss = 0.8575746656061712, disc_loss = 0.06480178436297074
Trained batch 399 in epoch 9, gen_loss = 0.8569192044436932, disc_loss = 0.06481239756103604
Trained batch 400 in epoch 9, gen_loss = 0.8573142785086596, disc_loss = 0.06467998099102269
Trained batch 401 in epoch 9, gen_loss = 0.8580111091706291, disc_loss = 0.06465906457771635
Trained batch 402 in epoch 9, gen_loss = 0.8581243485729985, disc_loss = 0.06464024234526136
Trained batch 403 in epoch 9, gen_loss = 0.8577774867858037, disc_loss = 0.06466166603858445
Trained batch 404 in epoch 9, gen_loss = 0.8574251043943711, disc_loss = 0.06472469782341778
Trained batch 405 in epoch 9, gen_loss = 0.8577703422513502, disc_loss = 0.06470341799468757
Trained batch 406 in epoch 9, gen_loss = 0.8576322446877013, disc_loss = 0.06487594236201019
Trained batch 407 in epoch 9, gen_loss = 0.8571493822862121, disc_loss = 0.06482032153928909
Trained batch 408 in epoch 9, gen_loss = 0.8565804712055365, disc_loss = 0.06505276270729915
Trained batch 409 in epoch 9, gen_loss = 0.8567086312828994, disc_loss = 0.06504229148849845
Trained batch 410 in epoch 9, gen_loss = 0.8570957302757133, disc_loss = 0.06500597954149881
Trained batch 411 in epoch 9, gen_loss = 0.8566147800788139, disc_loss = 0.06507132990620307
Trained batch 412 in epoch 9, gen_loss = 0.8567209572826691, disc_loss = 0.064965566536795
Trained batch 413 in epoch 9, gen_loss = 0.857443176317906, disc_loss = 0.06507234405141306
Trained batch 414 in epoch 9, gen_loss = 0.857110935090536, disc_loss = 0.06506211397024882
Trained batch 415 in epoch 9, gen_loss = 0.85671309596644, disc_loss = 0.06509084188459943
Trained batch 416 in epoch 9, gen_loss = 0.8571607293270761, disc_loss = 0.06528655364796769
Trained batch 417 in epoch 9, gen_loss = 0.8568279255520214, disc_loss = 0.06529800524560815
Trained batch 418 in epoch 9, gen_loss = 0.8570507651012667, disc_loss = 0.06520642623136394
Trained batch 419 in epoch 9, gen_loss = 0.8571478985604786, disc_loss = 0.06509280785962585
Trained batch 420 in epoch 9, gen_loss = 0.8574509571113949, disc_loss = 0.06497376062851974
Trained batch 421 in epoch 9, gen_loss = 0.8576193636910046, disc_loss = 0.0648663693540222
Trained batch 422 in epoch 9, gen_loss = 0.8574433294312046, disc_loss = 0.06477261968969805
Trained batch 423 in epoch 9, gen_loss = 0.8573619838593141, disc_loss = 0.06467172751457975
Trained batch 424 in epoch 9, gen_loss = 0.8577309681387508, disc_loss = 0.06466599441845627
Trained batch 425 in epoch 9, gen_loss = 0.8575051148452669, disc_loss = 0.06463259273370457
Trained batch 426 in epoch 9, gen_loss = 0.8566996889315388, disc_loss = 0.06475105637627757
Trained batch 427 in epoch 9, gen_loss = 0.8567700445930534, disc_loss = 0.06464952953969276
Trained batch 428 in epoch 9, gen_loss = 0.8574485799649378, disc_loss = 0.06474653050728958
Trained batch 429 in epoch 9, gen_loss = 0.8575227946736091, disc_loss = 0.06484401934065445
Trained batch 430 in epoch 9, gen_loss = 0.8566611399506748, disc_loss = 0.06521419569927758
Trained batch 431 in epoch 9, gen_loss = 0.8567424366871516, disc_loss = 0.0651385451222908
Trained batch 432 in epoch 9, gen_loss = 0.8571384440393426, disc_loss = 0.06504963013380077
Trained batch 433 in epoch 9, gen_loss = 0.8565965270117131, disc_loss = 0.06505232939736978
Trained batch 434 in epoch 9, gen_loss = 0.8563974827185444, disc_loss = 0.06499372982987385
Trained batch 435 in epoch 9, gen_loss = 0.8565874827017478, disc_loss = 0.06487621121117076
Trained batch 436 in epoch 9, gen_loss = 0.856514907537936, disc_loss = 0.06480907806721718
Trained batch 437 in epoch 9, gen_loss = 0.8565763866520364, disc_loss = 0.06469954138400552
Trained batch 438 in epoch 9, gen_loss = 0.8568945675070031, disc_loss = 0.06459796719108804
Trained batch 439 in epoch 9, gen_loss = 0.8576470375061035, disc_loss = 0.06451451307035644
Trained batch 440 in epoch 9, gen_loss = 0.8573589889911297, disc_loss = 0.06448518520520996
Trained batch 441 in epoch 9, gen_loss = 0.8574895726609554, disc_loss = 0.06437543528660188
Trained batch 442 in epoch 9, gen_loss = 0.857754461248626, disc_loss = 0.0642791518806974
Trained batch 443 in epoch 9, gen_loss = 0.8575983498547528, disc_loss = 0.06421725054036591
Trained batch 444 in epoch 9, gen_loss = 0.8578912246093321, disc_loss = 0.0641064372562458
Trained batch 445 in epoch 9, gen_loss = 0.8575108901267628, disc_loss = 0.06417576877834617
Trained batch 446 in epoch 9, gen_loss = 0.8579635044072298, disc_loss = 0.06408413117272276
Trained batch 447 in epoch 9, gen_loss = 0.8586611965937274, disc_loss = 0.06432823849484391
Trained batch 448 in epoch 9, gen_loss = 0.8582687202699997, disc_loss = 0.0642696732389668
Trained batch 449 in epoch 9, gen_loss = 0.8576380655500624, disc_loss = 0.06442560290503833
Trained batch 450 in epoch 9, gen_loss = 0.8578120729082704, disc_loss = 0.06434722478705936
Trained batch 451 in epoch 9, gen_loss = 0.8581135904630729, disc_loss = 0.06427047789236942
Trained batch 452 in epoch 9, gen_loss = 0.8578238333297881, disc_loss = 0.06418494576543043
Trained batch 453 in epoch 9, gen_loss = 0.8584391512797267, disc_loss = 0.0641090132907394
Trained batch 454 in epoch 9, gen_loss = 0.8584802062956841, disc_loss = 0.06404835997906687
Trained batch 455 in epoch 9, gen_loss = 0.8589289069437144, disc_loss = 0.06395824741482277
Trained batch 456 in epoch 9, gen_loss = 0.8593163802013355, disc_loss = 0.06386844761857123
Trained batch 457 in epoch 9, gen_loss = 0.8588285751998684, disc_loss = 0.06385167307671827
Trained batch 458 in epoch 9, gen_loss = 0.8591032948888725, disc_loss = 0.06373922644925663
Trained batch 459 in epoch 9, gen_loss = 0.8588157699159954, disc_loss = 0.06369379730895161
Trained batch 460 in epoch 9, gen_loss = 0.859674390510468, disc_loss = 0.06362996195844998
Trained batch 461 in epoch 9, gen_loss = 0.8592954026414202, disc_loss = 0.06359695250095872
Trained batch 462 in epoch 9, gen_loss = 0.8592461938476974, disc_loss = 0.06350527926635793
Trained batch 463 in epoch 9, gen_loss = 0.8593604398955559, disc_loss = 0.0633902567486953
Trained batch 464 in epoch 9, gen_loss = 0.8597035627211294, disc_loss = 0.06329946952962107
Trained batch 465 in epoch 9, gen_loss = 0.8591095606912359, disc_loss = 0.06338487471985459
Trained batch 466 in epoch 9, gen_loss = 0.8591948175838724, disc_loss = 0.0632690058989207
Trained batch 467 in epoch 9, gen_loss = 0.8595354768455538, disc_loss = 0.06315588632311958
Trained batch 468 in epoch 9, gen_loss = 0.8597791886278815, disc_loss = 0.06305204839237145
Trained batch 469 in epoch 9, gen_loss = 0.859647539828686, disc_loss = 0.06295678047859606
Trained batch 470 in epoch 9, gen_loss = 0.8594194312763822, disc_loss = 0.06292940608785347
Trained batch 471 in epoch 9, gen_loss = 0.8594076659972385, disc_loss = 0.06281575140685348
Trained batch 472 in epoch 9, gen_loss = 0.8599156621394651, disc_loss = 0.06304499018645941
Trained batch 473 in epoch 9, gen_loss = 0.8600540330892876, disc_loss = 0.06294272305986172
Trained batch 474 in epoch 9, gen_loss = 0.859516579853861, disc_loss = 0.06301453612744808
Trained batch 475 in epoch 9, gen_loss = 0.8595788282256166, disc_loss = 0.06296062875272972
Trained batch 476 in epoch 9, gen_loss = 0.8599435027290441, disc_loss = 0.06287750917676235
Trained batch 477 in epoch 9, gen_loss = 0.8598604071339803, disc_loss = 0.06277249343147712
Trained batch 478 in epoch 9, gen_loss = 0.8595830699844997, disc_loss = 0.06272430585343429
Trained batch 479 in epoch 9, gen_loss = 0.8600319392979145, disc_loss = 0.06264843731187283
Trained batch 480 in epoch 9, gen_loss = 0.8599472975284791, disc_loss = 0.06254265559236993
Trained batch 481 in epoch 9, gen_loss = 0.8602119874657437, disc_loss = 0.06242903552300208
Trained batch 482 in epoch 9, gen_loss = 0.8603437736661291, disc_loss = 0.06231562732420013
Trained batch 483 in epoch 9, gen_loss = 0.8601931754715186, disc_loss = 0.06227845986554599
Trained batch 484 in epoch 9, gen_loss = 0.860183179009821, disc_loss = 0.06221815593559871
Trained batch 485 in epoch 9, gen_loss = 0.8607285868974379, disc_loss = 0.06229781522032318
Trained batch 486 in epoch 9, gen_loss = 0.860694726879347, disc_loss = 0.06234024351967587
Trained batch 487 in epoch 9, gen_loss = 0.8601918506329177, disc_loss = 0.06269585439023088
Trained batch 488 in epoch 9, gen_loss = 0.8603556797304523, disc_loss = 0.06277813564448909
Trained batch 489 in epoch 9, gen_loss = 0.860630502262894, disc_loss = 0.06283538905732637
Trained batch 490 in epoch 9, gen_loss = 0.8603320534506058, disc_loss = 0.06284325359040177
Trained batch 491 in epoch 9, gen_loss = 0.8606541827926791, disc_loss = 0.06279895827268833
Trained batch 492 in epoch 9, gen_loss = 0.8604126601625408, disc_loss = 0.06280914201489961
Trained batch 493 in epoch 9, gen_loss = 0.8606087307215702, disc_loss = 0.06272271759751505
Trained batch 494 in epoch 9, gen_loss = 0.8604989131291707, disc_loss = 0.06264949197213006
Trained batch 495 in epoch 9, gen_loss = 0.8613471537828445, disc_loss = 0.06280805395949902
Trained batch 496 in epoch 9, gen_loss = 0.8609850624917259, disc_loss = 0.06289804046336464
Trained batch 497 in epoch 9, gen_loss = 0.8616367686225708, disc_loss = 0.06288225691574793
Trained batch 498 in epoch 9, gen_loss = 0.861197744438309, disc_loss = 0.06293022017534039
Trained batch 499 in epoch 9, gen_loss = 0.8610780854225158, disc_loss = 0.06284358283970505
Trained batch 500 in epoch 9, gen_loss = 0.8607985407054544, disc_loss = 0.06304882374683213
Trained batch 501 in epoch 9, gen_loss = 0.860167858847584, disc_loss = 0.06312561265296819
Trained batch 502 in epoch 9, gen_loss = 0.8602408001247505, disc_loss = 0.06308033662546374
Trained batch 503 in epoch 9, gen_loss = 0.8601270664542441, disc_loss = 0.0630217296790169
Trained batch 504 in epoch 9, gen_loss = 0.8598382936845912, disc_loss = 0.06296360281083992
Trained batch 505 in epoch 9, gen_loss = 0.8598477280893816, disc_loss = 0.06313007048942267
Trained batch 506 in epoch 9, gen_loss = 0.8593659218716668, disc_loss = 0.0632917501070928
Trained batch 507 in epoch 9, gen_loss = 0.8588723966221171, disc_loss = 0.06337022125137985
Trained batch 508 in epoch 9, gen_loss = 0.859269213699873, disc_loss = 0.0634904317859714
Trained batch 509 in epoch 9, gen_loss = 0.8587651487659006, disc_loss = 0.06354439893426994
Trained batch 510 in epoch 9, gen_loss = 0.8596105621052348, disc_loss = 0.06362494722158155
Trained batch 511 in epoch 9, gen_loss = 0.8595944457920268, disc_loss = 0.06360999340631679
Trained batch 512 in epoch 9, gen_loss = 0.8592453931274935, disc_loss = 0.06361478959350006
Trained batch 513 in epoch 9, gen_loss = 0.858861078432098, disc_loss = 0.06359046694808114
Trained batch 514 in epoch 9, gen_loss = 0.8591192760513824, disc_loss = 0.06353560995075454
Trained batch 515 in epoch 9, gen_loss = 0.8596396336490794, disc_loss = 0.06355800031406386
Trained batch 516 in epoch 9, gen_loss = 0.8592958084849832, disc_loss = 0.06356892052486654
Trained batch 517 in epoch 9, gen_loss = 0.8595004750264658, disc_loss = 0.06371686957923976
Trained batch 518 in epoch 9, gen_loss = 0.8593946714851438, disc_loss = 0.06373805412843192
Trained batch 519 in epoch 9, gen_loss = 0.8594157552489867, disc_loss = 0.0637309078207741
Trained batch 520 in epoch 9, gen_loss = 0.8594774642741154, disc_loss = 0.06372899494282258
Trained batch 521 in epoch 9, gen_loss = 0.8597991163931588, disc_loss = 0.06364694476873396
Trained batch 522 in epoch 9, gen_loss = 0.8592068322757918, disc_loss = 0.06368187802931005
Trained batch 523 in epoch 9, gen_loss = 0.8591010426064484, disc_loss = 0.06365931332768972
Trained batch 524 in epoch 9, gen_loss = 0.8592618942260742, disc_loss = 0.063746108399438
Trained batch 525 in epoch 9, gen_loss = 0.85900551035377, disc_loss = 0.06378444655401767
Trained batch 526 in epoch 9, gen_loss = 0.8583837111941778, disc_loss = 0.06395992475598909
Trained batch 527 in epoch 9, gen_loss = 0.8589781473080317, disc_loss = 0.0640364573628176
Trained batch 528 in epoch 9, gen_loss = 0.8593637391164307, disc_loss = 0.06397637032018182
Trained batch 529 in epoch 9, gen_loss = 0.8595216256267619, disc_loss = 0.06391621497811152
Trained batch 530 in epoch 9, gen_loss = 0.8594652535551686, disc_loss = 0.06395226791448429
Trained batch 531 in epoch 9, gen_loss = 0.859489330447706, disc_loss = 0.06386421063540265
Trained batch 532 in epoch 9, gen_loss = 0.8595602591757926, disc_loss = 0.06378969898985569
Trained batch 533 in epoch 9, gen_loss = 0.8594147923510619, disc_loss = 0.06380763363305912
Trained batch 534 in epoch 9, gen_loss = 0.8594021061870539, disc_loss = 0.0637361192405572
Trained batch 535 in epoch 9, gen_loss = 0.8599033987344201, disc_loss = 0.06369229035761291
Trained batch 536 in epoch 9, gen_loss = 0.8600149512068963, disc_loss = 0.06360309677254027
Trained batch 537 in epoch 9, gen_loss = 0.860389908228665, disc_loss = 0.06351169568251085
Trained batch 538 in epoch 9, gen_loss = 0.8605333909475295, disc_loss = 0.06342971713086919
Trained batch 539 in epoch 9, gen_loss = 0.8605278589107372, disc_loss = 0.06334366820907841
Trained batch 540 in epoch 9, gen_loss = 0.8609874949217283, disc_loss = 0.06332965922075394
Trained batch 541 in epoch 9, gen_loss = 0.8610577508532253, disc_loss = 0.06328644390850297
Trained batch 542 in epoch 9, gen_loss = 0.8606332878601046, disc_loss = 0.06333389188528307
Trained batch 543 in epoch 9, gen_loss = 0.8605434316046098, disc_loss = 0.06325021383150563
Trained batch 544 in epoch 9, gen_loss = 0.8602363947334639, disc_loss = 0.0632010828917248
Trained batch 545 in epoch 9, gen_loss = 0.8608351452446683, disc_loss = 0.06335284633667723
Trained batch 546 in epoch 9, gen_loss = 0.8603748919976912, disc_loss = 0.0634003361862432
Trained batch 547 in epoch 9, gen_loss = 0.8601702386445372, disc_loss = 0.0633323672507978
Trained batch 548 in epoch 9, gen_loss = 0.860434211668421, disc_loss = 0.06346524507909986
Trained batch 549 in epoch 9, gen_loss = 0.8596728880838914, disc_loss = 0.06368849296207454
Trained batch 550 in epoch 9, gen_loss = 0.8597001078557189, disc_loss = 0.06361015817191039
Trained batch 551 in epoch 9, gen_loss = 0.8599475229132003, disc_loss = 0.06354941155818844
Trained batch 552 in epoch 9, gen_loss = 0.8604115732755195, disc_loss = 0.06352893898438723
Trained batch 553 in epoch 9, gen_loss = 0.8600857903380686, disc_loss = 0.06350609016712311
Trained batch 554 in epoch 9, gen_loss = 0.8603828327075855, disc_loss = 0.06343556330497335
Trained batch 555 in epoch 9, gen_loss = 0.8606078265596637, disc_loss = 0.06336432372524718
Trained batch 556 in epoch 9, gen_loss = 0.8610931899217986, disc_loss = 0.06336594241983934
Trained batch 557 in epoch 9, gen_loss = 0.8611462113036904, disc_loss = 0.06328380740194257
Trained batch 558 in epoch 9, gen_loss = 0.8609948434428794, disc_loss = 0.06334368740033512
Trained batch 559 in epoch 9, gen_loss = 0.8614411991621767, disc_loss = 0.06326938284577668
Trained batch 560 in epoch 9, gen_loss = 0.8614899320610917, disc_loss = 0.06319693561042401
Trained batch 561 in epoch 9, gen_loss = 0.8617966687339905, disc_loss = 0.06315475869410112
Trained batch 562 in epoch 9, gen_loss = 0.8617029431446408, disc_loss = 0.06311174144068497
Trained batch 563 in epoch 9, gen_loss = 0.8613046931882277, disc_loss = 0.06324846431669112
Trained batch 564 in epoch 9, gen_loss = 0.861524683711803, disc_loss = 0.06332656621883533
Trained batch 565 in epoch 9, gen_loss = 0.8611738929268328, disc_loss = 0.06372161832960592
Trained batch 566 in epoch 9, gen_loss = 0.8613656591065556, disc_loss = 0.06368036370484628
Trained batch 567 in epoch 9, gen_loss = 0.860947471479295, disc_loss = 0.06377515242136621
Trained batch 568 in epoch 9, gen_loss = 0.8607303897190597, disc_loss = 0.06382852703126668
Trained batch 569 in epoch 9, gen_loss = 0.8608046772187217, disc_loss = 0.06400656059073905
Trained batch 570 in epoch 9, gen_loss = 0.8605478301566035, disc_loss = 0.0639624408602832
Trained batch 571 in epoch 9, gen_loss = 0.8601840965814523, disc_loss = 0.06399765485080311
Trained batch 572 in epoch 9, gen_loss = 0.8602385044513988, disc_loss = 0.06399560218553399
Trained batch 573 in epoch 9, gen_loss = 0.8605091573884678, disc_loss = 0.06390613387987823
Trained batch 574 in epoch 9, gen_loss = 0.8602242696803549, disc_loss = 0.06393854789516848
Trained batch 575 in epoch 9, gen_loss = 0.8603057284942932, disc_loss = 0.06386076838518623
Trained batch 576 in epoch 9, gen_loss = 0.8610173169413721, disc_loss = 0.06421265619172613
Trained batch 577 in epoch 9, gen_loss = 0.8608854640932644, disc_loss = 0.06413748183377913
Trained batch 578 in epoch 9, gen_loss = 0.8603906696324521, disc_loss = 0.0643697323990159
Trained batch 579 in epoch 9, gen_loss = 0.8604397110897919, disc_loss = 0.06433783475197209
Trained batch 580 in epoch 9, gen_loss = 0.8611223725361586, disc_loss = 0.06440939028184739
Trained batch 581 in epoch 9, gen_loss = 0.8608970582690026, disc_loss = 0.06445339123424002
Trained batch 582 in epoch 9, gen_loss = 0.8609449972828297, disc_loss = 0.06456712221624537
Trained batch 583 in epoch 9, gen_loss = 0.8604644745180051, disc_loss = 0.06472931486914853
Trained batch 584 in epoch 9, gen_loss = 0.8603070244829879, disc_loss = 0.0646907976653395
Trained batch 585 in epoch 9, gen_loss = 0.8609800230927842, disc_loss = 0.06535559705515796
Trained batch 586 in epoch 9, gen_loss = 0.8608058806781671, disc_loss = 0.06532284467412854
Trained batch 587 in epoch 9, gen_loss = 0.8606862007152467, disc_loss = 0.06527291167746013
Trained batch 588 in epoch 9, gen_loss = 0.8608812180763594, disc_loss = 0.06518602090475034
Trained batch 589 in epoch 9, gen_loss = 0.8611599198842452, disc_loss = 0.06520604169296132
Trained batch 590 in epoch 9, gen_loss = 0.8608893221606659, disc_loss = 0.06518608179217592
Trained batch 591 in epoch 9, gen_loss = 0.8605962159061754, disc_loss = 0.06520188665347854
Trained batch 592 in epoch 9, gen_loss = 0.8607156888831526, disc_loss = 0.06513073369248143
Trained batch 593 in epoch 9, gen_loss = 0.8603348621615657, disc_loss = 0.06526794680707809
Trained batch 594 in epoch 9, gen_loss = 0.8601663502324529, disc_loss = 0.0652293956932463
Trained batch 595 in epoch 9, gen_loss = 0.8600814129482179, disc_loss = 0.06525600048785267
Trained batch 596 in epoch 9, gen_loss = 0.8602018195580398, disc_loss = 0.0651660941960836
Trained batch 597 in epoch 9, gen_loss = 0.8597737221813521, disc_loss = 0.06522179735173475
Trained batch 598 in epoch 9, gen_loss = 0.8599077321850199, disc_loss = 0.06518326200411122
Trained batch 599 in epoch 9, gen_loss = 0.8598079415162404, disc_loss = 0.06510321722133085
Trained batch 600 in epoch 9, gen_loss = 0.8594838976860046, disc_loss = 0.06510587610047118
Trained batch 601 in epoch 9, gen_loss = 0.8595607636180826, disc_loss = 0.06503914437176307
Trained batch 602 in epoch 9, gen_loss = 0.8594201265480585, disc_loss = 0.06501441372397848
Trained batch 603 in epoch 9, gen_loss = 0.8593348961397512, disc_loss = 0.06497417774671281
Trained batch 604 in epoch 9, gen_loss = 0.8597606270766456, disc_loss = 0.06500017917060778
Trained batch 605 in epoch 9, gen_loss = 0.8594734361856291, disc_loss = 0.0649734042567991
Trained batch 606 in epoch 9, gen_loss = 0.8595322111293158, disc_loss = 0.06489086738684793
Trained batch 607 in epoch 9, gen_loss = 0.8593532533237809, disc_loss = 0.06486496138983823
Trained batch 608 in epoch 9, gen_loss = 0.8600082060777886, disc_loss = 0.06513469306177082
Trained batch 609 in epoch 9, gen_loss = 0.8597007819863617, disc_loss = 0.06517205950040676
Trained batch 610 in epoch 9, gen_loss = 0.8594895345684744, disc_loss = 0.06511452377875947
Trained batch 611 in epoch 9, gen_loss = 0.8592746499317144, disc_loss = 0.06527973892505043
Trained batch 612 in epoch 9, gen_loss = 0.8592608644950642, disc_loss = 0.06524401775152586
Trained batch 613 in epoch 9, gen_loss = 0.8593468768006427, disc_loss = 0.06518215836171388
Trained batch 614 in epoch 9, gen_loss = 0.859220999624671, disc_loss = 0.06518951805490182
Trained batch 615 in epoch 9, gen_loss = 0.8591513630825204, disc_loss = 0.06512948583022317
Trained batch 616 in epoch 9, gen_loss = 0.8593459036593692, disc_loss = 0.06506573057671589
Trained batch 617 in epoch 9, gen_loss = 0.8597529189100543, disc_loss = 0.06517858989160014
Trained batch 618 in epoch 9, gen_loss = 0.8593355060008886, disc_loss = 0.06522800924063861
Trained batch 619 in epoch 9, gen_loss = 0.8588809616142704, disc_loss = 0.06532813950156373
Trained batch 620 in epoch 9, gen_loss = 0.859040140049853, disc_loss = 0.06547823366176656
Trained batch 621 in epoch 9, gen_loss = 0.8590867435050548, disc_loss = 0.0653992776221437
Trained batch 622 in epoch 9, gen_loss = 0.858742090519129, disc_loss = 0.0654819316191847
Trained batch 623 in epoch 9, gen_loss = 0.858817130804826, disc_loss = 0.06542561744945721
Trained batch 624 in epoch 9, gen_loss = 0.8588042150497437, disc_loss = 0.06537422157153487
Trained batch 625 in epoch 9, gen_loss = 0.8589615027744549, disc_loss = 0.06532378840117385
Trained batch 626 in epoch 9, gen_loss = 0.8587777192512768, disc_loss = 0.0652821577240251
Trained batch 627 in epoch 9, gen_loss = 0.8587761631437169, disc_loss = 0.06531322354993599
Trained batch 628 in epoch 9, gen_loss = 0.8587817393349919, disc_loss = 0.06528226248490578
Trained batch 629 in epoch 9, gen_loss = 0.8586291726619478, disc_loss = 0.06526566440136068
Trained batch 630 in epoch 9, gen_loss = 0.8583540875824809, disc_loss = 0.06535357580684042
Trained batch 631 in epoch 9, gen_loss = 0.8588454292356213, disc_loss = 0.06543675536817364
Trained batch 632 in epoch 9, gen_loss = 0.8587933079137998, disc_loss = 0.0653662795979253
Trained batch 633 in epoch 9, gen_loss = 0.8585986762956866, disc_loss = 0.06531175120134342
Trained batch 634 in epoch 9, gen_loss = 0.858409862912546, disc_loss = 0.06529998126857746
Trained batch 635 in epoch 9, gen_loss = 0.8585780759652456, disc_loss = 0.06550273786477581
Trained batch 636 in epoch 9, gen_loss = 0.8588296682157173, disc_loss = 0.0654244040156564
Trained batch 637 in epoch 9, gen_loss = 0.8588581453296458, disc_loss = 0.06536539529631247
Trained batch 638 in epoch 9, gen_loss = 0.858533695829866, disc_loss = 0.06537292546815646
Trained batch 639 in epoch 9, gen_loss = 0.858553031180054, disc_loss = 0.06533365144350682
Trained batch 640 in epoch 9, gen_loss = 0.8588997275334624, disc_loss = 0.06525423165698435
Trained batch 641 in epoch 9, gen_loss = 0.8586552394699085, disc_loss = 0.06526519955321566
Trained batch 642 in epoch 9, gen_loss = 0.8588536795153403, disc_loss = 0.06523016037877133
Trained batch 643 in epoch 9, gen_loss = 0.8588346706599183, disc_loss = 0.06518315352710623
Trained batch 644 in epoch 9, gen_loss = 0.8586546410885892, disc_loss = 0.0651385078488221
Trained batch 645 in epoch 9, gen_loss = 0.8584634878502542, disc_loss = 0.06510667401458203
Trained batch 646 in epoch 9, gen_loss = 0.8584403323795549, disc_loss = 0.0652738010641792
Trained batch 647 in epoch 9, gen_loss = 0.8585758846667078, disc_loss = 0.06518912791018662
Trained batch 648 in epoch 9, gen_loss = 0.8588229536275467, disc_loss = 0.06511083177760106
Trained batch 649 in epoch 9, gen_loss = 0.8582503931338971, disc_loss = 0.0654360737845015
Trained batch 650 in epoch 9, gen_loss = 0.8587495910773446, disc_loss = 0.06545127858658151
Trained batch 651 in epoch 9, gen_loss = 0.8589420976814317, disc_loss = 0.06560115606675461
Trained batch 652 in epoch 9, gen_loss = 0.8585048541540756, disc_loss = 0.0657382101229867
Trained batch 653 in epoch 9, gen_loss = 0.8582648317748254, disc_loss = 0.06569592345047412
Trained batch 654 in epoch 9, gen_loss = 0.8585105599337862, disc_loss = 0.06572064088714373
Trained batch 655 in epoch 9, gen_loss = 0.8587771201642548, disc_loss = 0.0656569884747846
Trained batch 656 in epoch 9, gen_loss = 0.8583479643412376, disc_loss = 0.06575915473903128
Trained batch 657 in epoch 9, gen_loss = 0.8582900268872096, disc_loss = 0.06579653278069633
Trained batch 658 in epoch 9, gen_loss = 0.8581172085857536, disc_loss = 0.06577701775261027
Trained batch 659 in epoch 9, gen_loss = 0.8578842799771916, disc_loss = 0.0657560321777551
Trained batch 660 in epoch 9, gen_loss = 0.8580763816112108, disc_loss = 0.06573543175364564
Trained batch 661 in epoch 9, gen_loss = 0.858514008745326, disc_loss = 0.06568341798661136
Trained batch 662 in epoch 9, gen_loss = 0.8580937810792822, disc_loss = 0.06579521554276392
Trained batch 663 in epoch 9, gen_loss = 0.8580104030938034, disc_loss = 0.06577502929041701
Trained batch 664 in epoch 9, gen_loss = 0.8579749780489986, disc_loss = 0.06573444805072999
Trained batch 665 in epoch 9, gen_loss = 0.8583117448710822, disc_loss = 0.065713767372715
Trained batch 666 in epoch 9, gen_loss = 0.8578996240109696, disc_loss = 0.06584325010191532
Trained batch 667 in epoch 9, gen_loss = 0.8580448807713514, disc_loss = 0.06589789082600127
Trained batch 668 in epoch 9, gen_loss = 0.8579604415437387, disc_loss = 0.06598727394700028
Trained batch 669 in epoch 9, gen_loss = 0.8579135002484962, disc_loss = 0.06592247592799588
Trained batch 670 in epoch 9, gen_loss = 0.857729692839297, disc_loss = 0.06584507624386919
Trained batch 671 in epoch 9, gen_loss = 0.8571075320776019, disc_loss = 0.06609997219735912
Trained batch 672 in epoch 9, gen_loss = 0.8571969604598466, disc_loss = 0.06604641449484105
Trained batch 673 in epoch 9, gen_loss = 0.857619996505958, disc_loss = 0.06648366616897904
Trained batch 674 in epoch 9, gen_loss = 0.8577413019427547, disc_loss = 0.06644086450269376
Trained batch 675 in epoch 9, gen_loss = 0.8573440977278546, disc_loss = 0.06653525635046256
Trained batch 676 in epoch 9, gen_loss = 0.857365525895771, disc_loss = 0.06648761351995908
Trained batch 677 in epoch 9, gen_loss = 0.8571111871957076, disc_loss = 0.06649316309890806
Trained batch 678 in epoch 9, gen_loss = 0.8572445153663366, disc_loss = 0.06643189298844895
Trained batch 679 in epoch 9, gen_loss = 0.8570740790051572, disc_loss = 0.06640264029162662
Trained batch 680 in epoch 9, gen_loss = 0.8568702721735805, disc_loss = 0.06640231365299676
Trained batch 681 in epoch 9, gen_loss = 0.8570515057208601, disc_loss = 0.06633835099842345
Trained batch 682 in epoch 9, gen_loss = 0.856842699197515, disc_loss = 0.06629772540686399
Trained batch 683 in epoch 9, gen_loss = 0.8567959998260465, disc_loss = 0.06623389977044072
Trained batch 684 in epoch 9, gen_loss = 0.8567796572281496, disc_loss = 0.06620031984006293
Trained batch 685 in epoch 9, gen_loss = 0.8569420711639671, disc_loss = 0.06614699640376466
Trained batch 686 in epoch 9, gen_loss = 0.8569747016072446, disc_loss = 0.06607335262214752
Trained batch 687 in epoch 9, gen_loss = 0.8568395666431549, disc_loss = 0.06601360144004291
Trained batch 688 in epoch 9, gen_loss = 0.8563497226539302, disc_loss = 0.06611171053825231
Trained batch 689 in epoch 9, gen_loss = 0.8561817425748576, disc_loss = 0.0660716690386281
Trained batch 690 in epoch 9, gen_loss = 0.8561519963178897, disc_loss = 0.06616967590256188
Trained batch 691 in epoch 9, gen_loss = 0.8559282372108085, disc_loss = 0.06619152190322541
Trained batch 692 in epoch 9, gen_loss = 0.8555614827859281, disc_loss = 0.06625414794999004
Trained batch 693 in epoch 9, gen_loss = 0.8559850311760256, disc_loss = 0.06646423258077923
Trained batch 694 in epoch 9, gen_loss = 0.8559161668201145, disc_loss = 0.06640103879257393
Trained batch 695 in epoch 9, gen_loss = 0.8556370430294125, disc_loss = 0.0663671408553779
Trained batch 696 in epoch 9, gen_loss = 0.8552391146826779, disc_loss = 0.06645094044439741
Trained batch 697 in epoch 9, gen_loss = 0.8549343011099151, disc_loss = 0.06642295084133168
Trained batch 698 in epoch 9, gen_loss = 0.8548635795222161, disc_loss = 0.06637118727125985
Trained batch 699 in epoch 9, gen_loss = 0.854762738772801, disc_loss = 0.06633915962052665
Trained batch 700 in epoch 9, gen_loss = 0.855082858135969, disc_loss = 0.0662709750844891
Trained batch 701 in epoch 9, gen_loss = 0.8554173273238701, disc_loss = 0.0663394100607195
Trained batch 702 in epoch 9, gen_loss = 0.8549814774505106, disc_loss = 0.06665292738805688
Trained batch 703 in epoch 9, gen_loss = 0.8552876354449175, disc_loss = 0.06660908442559461
Trained batch 704 in epoch 9, gen_loss = 0.8551294063845425, disc_loss = 0.06669298948270949
Trained batch 705 in epoch 9, gen_loss = 0.8550589796335096, disc_loss = 0.0666744747052692
Trained batch 706 in epoch 9, gen_loss = 0.854950910663335, disc_loss = 0.06664539649595191
Trained batch 707 in epoch 9, gen_loss = 0.8546872616319333, disc_loss = 0.06662718705388344
Trained batch 708 in epoch 9, gen_loss = 0.8550963513605685, disc_loss = 0.06658844200484403
Trained batch 709 in epoch 9, gen_loss = 0.8548762420533409, disc_loss = 0.06654907489575865
Trained batch 710 in epoch 9, gen_loss = 0.8551097006737431, disc_loss = 0.06653161633447986
Trained batch 711 in epoch 9, gen_loss = 0.854922066076418, disc_loss = 0.06654392160263352
Trained batch 712 in epoch 9, gen_loss = 0.8550628348453516, disc_loss = 0.06666649590072654
Trained batch 713 in epoch 9, gen_loss = 0.854871529407528, disc_loss = 0.06667620354170288
Trained batch 714 in epoch 9, gen_loss = 0.8549268100645159, disc_loss = 0.06661241745602313
Trained batch 715 in epoch 9, gen_loss = 0.8553181522052381, disc_loss = 0.06661105268522993
Trained batch 716 in epoch 9, gen_loss = 0.8552906549791578, disc_loss = 0.06655227154106255
Trained batch 717 in epoch 9, gen_loss = 0.8549198330610908, disc_loss = 0.06658085997211215
Trained batch 718 in epoch 9, gen_loss = 0.854755341260589, disc_loss = 0.06653372846188876
Trained batch 719 in epoch 9, gen_loss = 0.8549270791312059, disc_loss = 0.06661339496559877
Trained batch 720 in epoch 9, gen_loss = 0.8548834432179984, disc_loss = 0.06662327979320606
Trained batch 721 in epoch 9, gen_loss = 0.8545066411310286, disc_loss = 0.06685631482996088
Trained batch 722 in epoch 9, gen_loss = 0.8545130261247089, disc_loss = 0.06680812015498307
Trained batch 723 in epoch 9, gen_loss = 0.8550221726545313, disc_loss = 0.06690859230356136
Trained batch 724 in epoch 9, gen_loss = 0.8550422748203935, disc_loss = 0.06684236047275621
Trained batch 725 in epoch 9, gen_loss = 0.854614001003507, disc_loss = 0.06697438441450418
Trained batch 726 in epoch 9, gen_loss = 0.8545924459559717, disc_loss = 0.06697084797428411
Trained batch 727 in epoch 9, gen_loss = 0.8545799777730481, disc_loss = 0.06691206352731499
Trained batch 728 in epoch 9, gen_loss = 0.8545082653827955, disc_loss = 0.06705727318521533
Trained batch 729 in epoch 9, gen_loss = 0.8542573428317292, disc_loss = 0.0670774546662371
Trained batch 730 in epoch 9, gen_loss = 0.8541968104451202, disc_loss = 0.06702427391954041
Trained batch 731 in epoch 9, gen_loss = 0.8547089947540252, disc_loss = 0.06699337854235855
Trained batch 732 in epoch 9, gen_loss = 0.8547403188714552, disc_loss = 0.06694758721242315
Trained batch 733 in epoch 9, gen_loss = 0.8548283890417551, disc_loss = 0.06688165740485555
Trained batch 734 in epoch 9, gen_loss = 0.8546817925511574, disc_loss = 0.0668486518791693
Trained batch 735 in epoch 9, gen_loss = 0.8543661502392396, disc_loss = 0.06685097812884994
Trained batch 736 in epoch 9, gen_loss = 0.8546470269419283, disc_loss = 0.06682901096238351
Trained batch 737 in epoch 9, gen_loss = 0.8545470468720123, disc_loss = 0.06676476381827641
Trained batch 738 in epoch 9, gen_loss = 0.8542947578817324, disc_loss = 0.06678561125951284
Trained batch 739 in epoch 9, gen_loss = 0.8540198274560877, disc_loss = 0.06683592889646722
Trained batch 740 in epoch 9, gen_loss = 0.8540152150448839, disc_loss = 0.06677876351471593
Trained batch 741 in epoch 9, gen_loss = 0.854315657178668, disc_loss = 0.06683036819479436
Trained batch 742 in epoch 9, gen_loss = 0.8541624291748571, disc_loss = 0.06681909331861347
Trained batch 743 in epoch 9, gen_loss = 0.8541051050027212, disc_loss = 0.06678030785531186
Trained batch 744 in epoch 9, gen_loss = 0.8543590854478362, disc_loss = 0.06687939696501466
Trained batch 745 in epoch 9, gen_loss = 0.8540797545187595, disc_loss = 0.06691367896685711
Trained batch 746 in epoch 9, gen_loss = 0.8537102878652264, disc_loss = 0.06696588464687209
Trained batch 747 in epoch 9, gen_loss = 0.8539696260888309, disc_loss = 0.06704124381434531
Trained batch 748 in epoch 9, gen_loss = 0.8539779819697341, disc_loss = 0.0669743456736018
Trained batch 749 in epoch 9, gen_loss = 0.8541029794216156, disc_loss = 0.06690087879635394
Trained batch 750 in epoch 9, gen_loss = 0.8540380994743418, disc_loss = 0.06686060636002972
Trained batch 751 in epoch 9, gen_loss = 0.8541948784221994, disc_loss = 0.0668349200903012
Trained batch 752 in epoch 9, gen_loss = 0.8540254475111031, disc_loss = 0.0668142168401712
Trained batch 753 in epoch 9, gen_loss = 0.8542683892920415, disc_loss = 0.06694157743660994
Trained batch 754 in epoch 9, gen_loss = 0.854141747872561, disc_loss = 0.06697355065655136
Trained batch 755 in epoch 9, gen_loss = 0.8541850291547322, disc_loss = 0.06700943170852033
Trained batch 756 in epoch 9, gen_loss = 0.854183664095134, disc_loss = 0.0669861189631039
Trained batch 757 in epoch 9, gen_loss = 0.854024420312967, disc_loss = 0.06702044851878919
Trained batch 758 in epoch 9, gen_loss = 0.8544143053539814, disc_loss = 0.06696768004842328
Trained batch 759 in epoch 9, gen_loss = 0.8543920214238919, disc_loss = 0.06696237220710731
Trained batch 760 in epoch 9, gen_loss = 0.8542010342401212, disc_loss = 0.06698641854518249
Trained batch 761 in epoch 9, gen_loss = 0.8543518872398717, disc_loss = 0.06693444616073288
Trained batch 762 in epoch 9, gen_loss = 0.8544020323109658, disc_loss = 0.06687496419871522
Trained batch 763 in epoch 9, gen_loss = 0.854132474248946, disc_loss = 0.06691245005175919
Trained batch 764 in epoch 9, gen_loss = 0.8540996159603393, disc_loss = 0.06687841519068172
Trained batch 765 in epoch 9, gen_loss = 0.8549299275128088, disc_loss = 0.06703757767458556
Trained batch 766 in epoch 9, gen_loss = 0.8546951456672987, disc_loss = 0.06717751112449646
Trained batch 767 in epoch 9, gen_loss = 0.8547087783614794, disc_loss = 0.0671313128204929
Trained batch 768 in epoch 9, gen_loss = 0.8550574950030938, disc_loss = 0.06709205961310255
Trained batch 769 in epoch 9, gen_loss = 0.8549644799975605, disc_loss = 0.06704353286594443
Trained batch 770 in epoch 9, gen_loss = 0.8548288733424225, disc_loss = 0.06702575949473662
Trained batch 771 in epoch 9, gen_loss = 0.8547643330430738, disc_loss = 0.06696849519452032
Trained batch 772 in epoch 9, gen_loss = 0.8550931286225806, disc_loss = 0.06701000978842493
Trained batch 773 in epoch 9, gen_loss = 0.8549406560816506, disc_loss = 0.066983742008313
Trained batch 774 in epoch 9, gen_loss = 0.8550941598030829, disc_loss = 0.06691308914713802
Trained batch 775 in epoch 9, gen_loss = 0.8553179706802073, disc_loss = 0.06689338058235661
Trained batch 776 in epoch 9, gen_loss = 0.855303243627266, disc_loss = 0.06683874326641821
Trained batch 777 in epoch 9, gen_loss = 0.855126218884647, disc_loss = 0.06683890505066586
Trained batch 778 in epoch 9, gen_loss = 0.8551425572690364, disc_loss = 0.06678929387033464
Trained batch 779 in epoch 9, gen_loss = 0.8551044759077904, disc_loss = 0.06673846745636697
Trained batch 780 in epoch 9, gen_loss = 0.8551992647321215, disc_loss = 0.06670056756945963
Trained batch 781 in epoch 9, gen_loss = 0.8553041763927626, disc_loss = 0.06664818402706071
Trained batch 782 in epoch 9, gen_loss = 0.8552613327634137, disc_loss = 0.06659717658311033
Trained batch 783 in epoch 9, gen_loss = 0.8556536815452332, disc_loss = 0.06656580629618364
Trained batch 784 in epoch 9, gen_loss = 0.8553851478418727, disc_loss = 0.06658428140803223
Trained batch 785 in epoch 9, gen_loss = 0.8552504253144786, disc_loss = 0.06654787885733707
Trained batch 786 in epoch 9, gen_loss = 0.8554877474468575, disc_loss = 0.06651200285758894
Trained batch 787 in epoch 9, gen_loss = 0.8554860143189503, disc_loss = 0.06649669832585446
Trained batch 788 in epoch 9, gen_loss = 0.855022478126301, disc_loss = 0.06656909514754462
Trained batch 789 in epoch 9, gen_loss = 0.8548419385393964, disc_loss = 0.06656687756516982
Testing Epoch 9
Training Epoch 10
Trained batch 0 in epoch 10, gen_loss = 0.683048665523529, disc_loss = 0.049946073442697525
Trained batch 1 in epoch 10, gen_loss = 0.8360711336135864, disc_loss = 0.10309425182640553
Trained batch 2 in epoch 10, gen_loss = 0.8318396011988322, disc_loss = 0.07703100206951301
Trained batch 3 in epoch 10, gen_loss = 0.8743360936641693, disc_loss = 0.06068891636095941
Trained batch 4 in epoch 10, gen_loss = 0.8433509588241577, disc_loss = 0.06956518720835447
Trained batch 5 in epoch 10, gen_loss = 0.839555581410726, disc_loss = 0.06751135410740972
Trained batch 6 in epoch 10, gen_loss = 0.8508979593004499, disc_loss = 0.061594239968274324
Trained batch 7 in epoch 10, gen_loss = 0.8298372030258179, disc_loss = 0.06447598116938025
Trained batch 8 in epoch 10, gen_loss = 0.7986700269911025, disc_loss = 0.06704718340188265
Trained batch 9 in epoch 10, gen_loss = 0.8141346275806427, disc_loss = 0.06602830151095987
Trained batch 10 in epoch 10, gen_loss = 0.8306350057775324, disc_loss = 0.06301095277409662
Trained batch 11 in epoch 10, gen_loss = 0.837136427561442, disc_loss = 0.059272624629860125
Trained batch 12 in epoch 10, gen_loss = 0.8179276952376733, disc_loss = 0.06359671980429155
Trained batch 13 in epoch 10, gen_loss = 0.8284505903720856, disc_loss = 0.06085027255383985
Trained batch 14 in epoch 10, gen_loss = 0.8343788266181946, disc_loss = 0.058925118607779346
Trained batch 15 in epoch 10, gen_loss = 0.8312029913067818, disc_loss = 0.05919581517810002
Trained batch 16 in epoch 10, gen_loss = 0.8249670898213106, disc_loss = 0.0578745845157434
Trained batch 17 in epoch 10, gen_loss = 0.8384582731458876, disc_loss = 0.05660089979776078
Trained batch 18 in epoch 10, gen_loss = 0.8418479499063993, disc_loss = 0.06668982659711649
Trained batch 19 in epoch 10, gen_loss = 0.8383036345243454, disc_loss = 0.06709264148958027
Trained batch 20 in epoch 10, gen_loss = 0.8214440984385354, disc_loss = 0.08351280509183805
Trained batch 21 in epoch 10, gen_loss = 0.8276296948844736, disc_loss = 0.08186407628553835
Trained batch 22 in epoch 10, gen_loss = 0.8288336616495381, disc_loss = 0.08280164039815249
Trained batch 23 in epoch 10, gen_loss = 0.82626548781991, disc_loss = 0.08262966204589854
Trained batch 24 in epoch 10, gen_loss = 0.8210686242580414, disc_loss = 0.08110506955534219
Trained batch 25 in epoch 10, gen_loss = 0.8174119924123471, disc_loss = 0.0796560224217291
Trained batch 26 in epoch 10, gen_loss = 0.8223692918265307, disc_loss = 0.07913081737718096
Trained batch 27 in epoch 10, gen_loss = 0.8201747164130211, disc_loss = 0.07880146325831967
Trained batch 28 in epoch 10, gen_loss = 0.8109519820788811, disc_loss = 0.08071526220261023
Trained batch 29 in epoch 10, gen_loss = 0.8075148989756902, disc_loss = 0.07940123879040281
Trained batch 30 in epoch 10, gen_loss = 0.8216991511083418, disc_loss = 0.08429343376549021
Trained batch 31 in epoch 10, gen_loss = 0.8255686545744538, disc_loss = 0.08278031545341946
Trained batch 32 in epoch 10, gen_loss = 0.8204930090542996, disc_loss = 0.08416404724685532
Trained batch 33 in epoch 10, gen_loss = 0.8148855821174734, disc_loss = 0.08436533274567302
Trained batch 34 in epoch 10, gen_loss = 0.828809187241963, disc_loss = 0.0852570200871144
Trained batch 35 in epoch 10, gen_loss = 0.8263494811124272, disc_loss = 0.0848578054509643
Trained batch 36 in epoch 10, gen_loss = 0.8251603527649028, disc_loss = 0.08456314649634264
Trained batch 37 in epoch 10, gen_loss = 0.8150971524025264, disc_loss = 0.08786582664929722
Trained batch 38 in epoch 10, gen_loss = 0.8154631356398264, disc_loss = 0.08961781393736601
Trained batch 39 in epoch 10, gen_loss = 0.8193586073815823, disc_loss = 0.0879643930355087
Trained batch 40 in epoch 10, gen_loss = 0.8164250654418294, disc_loss = 0.08827711880297923
Trained batch 41 in epoch 10, gen_loss = 0.819799345873651, disc_loss = 0.08684281421647895
Trained batch 42 in epoch 10, gen_loss = 0.8142261415026909, disc_loss = 0.08712990047020275
Trained batch 43 in epoch 10, gen_loss = 0.8180481866002083, disc_loss = 0.08799331891350448
Trained batch 44 in epoch 10, gen_loss = 0.8175047165817685, disc_loss = 0.086717789599465
Trained batch 45 in epoch 10, gen_loss = 0.816368092013442, disc_loss = 0.08629664800980169
Trained batch 46 in epoch 10, gen_loss = 0.8205878373156202, disc_loss = 0.08518733280374015
Trained batch 47 in epoch 10, gen_loss = 0.8184441023816665, disc_loss = 0.08457241733170424
Trained batch 48 in epoch 10, gen_loss = 0.8204122605372448, disc_loss = 0.08354021728570972
Trained batch 49 in epoch 10, gen_loss = 0.8188660174608231, disc_loss = 0.08242246186360717
Trained batch 50 in epoch 10, gen_loss = 0.8169062751180985, disc_loss = 0.08162322346413252
Trained batch 51 in epoch 10, gen_loss = 0.8223379076673434, disc_loss = 0.08200454036705196
Trained batch 52 in epoch 10, gen_loss = 0.8209549644083347, disc_loss = 0.08127532728930127
Trained batch 53 in epoch 10, gen_loss = 0.818983288274871, disc_loss = 0.08054256078752654
Trained batch 54 in epoch 10, gen_loss = 0.8207720176740126, disc_loss = 0.07932829140600833
Trained batch 55 in epoch 10, gen_loss = 0.8234229242163045, disc_loss = 0.07817881146911532
Trained batch 56 in epoch 10, gen_loss = 0.8269084258037701, disc_loss = 0.0770378237132702
Trained batch 57 in epoch 10, gen_loss = 0.8281000302783375, disc_loss = 0.07595416381634001
Trained batch 58 in epoch 10, gen_loss = 0.830498839333906, disc_loss = 0.07531768372440237
Trained batch 59 in epoch 10, gen_loss = 0.8298764124512672, disc_loss = 0.07448358763940632
Trained batch 60 in epoch 10, gen_loss = 0.8274174532929405, disc_loss = 0.07442206661903956
Trained batch 61 in epoch 10, gen_loss = 0.8277474627379449, disc_loss = 0.07340715499594808
Trained batch 62 in epoch 10, gen_loss = 0.8360121822546399, disc_loss = 0.07692259560442632
Trained batch 63 in epoch 10, gen_loss = 0.831312797497958, disc_loss = 0.07724977597536054
Trained batch 64 in epoch 10, gen_loss = 0.8356577281768506, disc_loss = 0.07642385293371402
Trained batch 65 in epoch 10, gen_loss = 0.8366152720920967, disc_loss = 0.07546947316520593
Trained batch 66 in epoch 10, gen_loss = 0.8340956057185558, disc_loss = 0.07516117245236885
Trained batch 67 in epoch 10, gen_loss = 0.833662718972739, disc_loss = 0.07434099771575454
Trained batch 68 in epoch 10, gen_loss = 0.8352174365866012, disc_loss = 0.07350137760943692
Trained batch 69 in epoch 10, gen_loss = 0.8355337555919374, disc_loss = 0.07269986347694482
Trained batch 70 in epoch 10, gen_loss = 0.8391965950878573, disc_loss = 0.07207533731584398
Trained batch 71 in epoch 10, gen_loss = 0.8440878776212534, disc_loss = 0.07126162533596572
Trained batch 72 in epoch 10, gen_loss = 0.841282551010994, disc_loss = 0.07163293405805957
Trained batch 73 in epoch 10, gen_loss = 0.8417544844182762, disc_loss = 0.07086901610868203
Trained batch 74 in epoch 10, gen_loss = 0.8422908373673756, disc_loss = 0.07009694783637921
Trained batch 75 in epoch 10, gen_loss = 0.84274693735336, disc_loss = 0.06947387432630517
Trained batch 76 in epoch 10, gen_loss = 0.8419802959089155, disc_loss = 0.07022054562369337
Trained batch 77 in epoch 10, gen_loss = 0.842599616982998, disc_loss = 0.0694704049338515
Trained batch 78 in epoch 10, gen_loss = 0.8384684856179394, disc_loss = 0.07009594456021544
Trained batch 79 in epoch 10, gen_loss = 0.839976342394948, disc_loss = 0.06939918163698167
Trained batch 80 in epoch 10, gen_loss = 0.8431826083012569, disc_loss = 0.06905184683884368
Trained batch 81 in epoch 10, gen_loss = 0.845882847905159, disc_loss = 0.06856597891849715
Trained batch 82 in epoch 10, gen_loss = 0.8446021169783121, disc_loss = 0.06816178156309817
Trained batch 83 in epoch 10, gen_loss = 0.8465868976144564, disc_loss = 0.06753301820052522
Trained batch 84 in epoch 10, gen_loss = 0.8454954550546758, disc_loss = 0.06746598065775984
Trained batch 85 in epoch 10, gen_loss = 0.8488098670576893, disc_loss = 0.06837147634563058
Trained batch 86 in epoch 10, gen_loss = 0.8484988907972971, disc_loss = 0.06781865243168397
Trained batch 87 in epoch 10, gen_loss = 0.8475563184104182, disc_loss = 0.06755686731247063
Trained batch 88 in epoch 10, gen_loss = 0.8507055884666657, disc_loss = 0.06719796692303727
Trained batch 89 in epoch 10, gen_loss = 0.8497477925486034, disc_loss = 0.066982159908447
Trained batch 90 in epoch 10, gen_loss = 0.8510145934728476, disc_loss = 0.06636130218240587
Trained batch 91 in epoch 10, gen_loss = 0.8534939849506253, disc_loss = 0.06598211215485049
Trained batch 92 in epoch 10, gen_loss = 0.856417021764222, disc_loss = 0.06552410932878654
Trained batch 93 in epoch 10, gen_loss = 0.8561541574432495, disc_loss = 0.06516899249734397
Trained batch 94 in epoch 10, gen_loss = 0.8542777968080421, disc_loss = 0.06524034395421806
Trained batch 95 in epoch 10, gen_loss = 0.8529977068925897, disc_loss = 0.06509196597229068
Trained batch 96 in epoch 10, gen_loss = 0.8571672749888036, disc_loss = 0.0659072968494339
Trained batch 97 in epoch 10, gen_loss = 0.8604325934940454, disc_loss = 0.065835450699895
Trained batch 98 in epoch 10, gen_loss = 0.858054060827602, disc_loss = 0.06635436086416846
Trained batch 99 in epoch 10, gen_loss = 0.8578749820590019, disc_loss = 0.06635103972628713
Trained batch 100 in epoch 10, gen_loss = 0.8587480892639349, disc_loss = 0.06583310023761622
Trained batch 101 in epoch 10, gen_loss = 0.8566433626647089, disc_loss = 0.06640772603671341
Trained batch 102 in epoch 10, gen_loss = 0.854893864647856, disc_loss = 0.06691520171041049
Trained batch 103 in epoch 10, gen_loss = 0.853837636514352, disc_loss = 0.0671523255833353
Trained batch 104 in epoch 10, gen_loss = 0.8588620410079048, disc_loss = 0.06739892911698137
Trained batch 105 in epoch 10, gen_loss = 0.8573324452593641, disc_loss = 0.06734078670939747
Trained batch 106 in epoch 10, gen_loss = 0.8551173346621967, disc_loss = 0.06768810608049977
Trained batch 107 in epoch 10, gen_loss = 0.8550641826457448, disc_loss = 0.06844936392304522
Trained batch 108 in epoch 10, gen_loss = 0.8526333042787849, disc_loss = 0.06852920406386939
Trained batch 109 in epoch 10, gen_loss = 0.853574647415768, disc_loss = 0.06803264485841448
Trained batch 110 in epoch 10, gen_loss = 0.8561577461324297, disc_loss = 0.06763134363132554
Trained batch 111 in epoch 10, gen_loss = 0.855331917692508, disc_loss = 0.06743053855773594
Trained batch 112 in epoch 10, gen_loss = 0.8556569252921417, disc_loss = 0.06745373006019972
Trained batch 113 in epoch 10, gen_loss = 0.8552086695767286, disc_loss = 0.06726904040235177
Trained batch 114 in epoch 10, gen_loss = 0.8554370125998622, disc_loss = 0.06702085163282312
Trained batch 115 in epoch 10, gen_loss = 0.8549525899619892, disc_loss = 0.06667616683989763
Trained batch 116 in epoch 10, gen_loss = 0.8556821679967082, disc_loss = 0.06629496830332483
Trained batch 117 in epoch 10, gen_loss = 0.8531718660714263, disc_loss = 0.06723171919268572
Trained batch 118 in epoch 10, gen_loss = 0.8569250269597318, disc_loss = 0.06945226364964698
Trained batch 119 in epoch 10, gen_loss = 0.8584489983816942, disc_loss = 0.06898043639957904
Trained batch 120 in epoch 10, gen_loss = 0.8561156069444231, disc_loss = 0.06981772245946995
Trained batch 121 in epoch 10, gen_loss = 0.8568094893068564, disc_loss = 0.06970458157116273
Trained batch 122 in epoch 10, gen_loss = 0.8565675051716285, disc_loss = 0.07003119209311842
Trained batch 123 in epoch 10, gen_loss = 0.8543035678805844, disc_loss = 0.07003908583353605
Trained batch 124 in epoch 10, gen_loss = 0.8546883151531219, disc_loss = 0.06980334389209747
Trained batch 125 in epoch 10, gen_loss = 0.8539990714145085, disc_loss = 0.0694816540335379
Trained batch 126 in epoch 10, gen_loss = 0.8520617961414217, disc_loss = 0.06938054465402768
Trained batch 127 in epoch 10, gen_loss = 0.8514395279344171, disc_loss = 0.06910491193411872
Trained batch 128 in epoch 10, gen_loss = 0.8536516915458118, disc_loss = 0.06925006418727166
Trained batch 129 in epoch 10, gen_loss = 0.8529967108598122, disc_loss = 0.06891697639456162
Trained batch 130 in epoch 10, gen_loss = 0.8506760426605021, disc_loss = 0.06936039195488428
Trained batch 131 in epoch 10, gen_loss = 0.8522332005880096, disc_loss = 0.06933653648152496
Trained batch 132 in epoch 10, gen_loss = 0.8531050751531931, disc_loss = 0.06896045984686318
Trained batch 133 in epoch 10, gen_loss = 0.8511971090711764, disc_loss = 0.06963469256271622
Trained batch 134 in epoch 10, gen_loss = 0.8528373521787149, disc_loss = 0.07002497934908779
Trained batch 135 in epoch 10, gen_loss = 0.8524921613142771, disc_loss = 0.06976876359925989
Trained batch 136 in epoch 10, gen_loss = 0.8512057668536249, disc_loss = 0.06990478401255869
Trained batch 137 in epoch 10, gen_loss = 0.8506706480098807, disc_loss = 0.06954929412113152
Trained batch 138 in epoch 10, gen_loss = 0.8516271648218305, disc_loss = 0.06935113637621025
Trained batch 139 in epoch 10, gen_loss = 0.8509971033249583, disc_loss = 0.06940512876691562
Trained batch 140 in epoch 10, gen_loss = 0.8508977985128443, disc_loss = 0.06915190645513382
Trained batch 141 in epoch 10, gen_loss = 0.8502391159114703, disc_loss = 0.06907228707060428
Trained batch 142 in epoch 10, gen_loss = 0.853944161763558, disc_loss = 0.06935642645336114
Trained batch 143 in epoch 10, gen_loss = 0.8515291079464886, disc_loss = 0.0706502492668935
Trained batch 144 in epoch 10, gen_loss = 0.8517876721661667, disc_loss = 0.07047311757402173
Trained batch 145 in epoch 10, gen_loss = 0.8522419674347524, disc_loss = 0.07037207388561474
Trained batch 146 in epoch 10, gen_loss = 0.8515529849496829, disc_loss = 0.07018346723397167
Trained batch 147 in epoch 10, gen_loss = 0.8505133895857914, disc_loss = 0.07025802214755802
Trained batch 148 in epoch 10, gen_loss = 0.8514310863594081, disc_loss = 0.0705760879779622
Trained batch 149 in epoch 10, gen_loss = 0.8496155522267024, disc_loss = 0.0712564363454779
Trained batch 150 in epoch 10, gen_loss = 0.8494806639011333, disc_loss = 0.07139032974296453
Trained batch 151 in epoch 10, gen_loss = 0.8519572562685138, disc_loss = 0.07140235023229922
Trained batch 152 in epoch 10, gen_loss = 0.8518221614017986, disc_loss = 0.07123921995410343
Trained batch 153 in epoch 10, gen_loss = 0.8517738462655575, disc_loss = 0.07096317438287782
Trained batch 154 in epoch 10, gen_loss = 0.8513029108124395, disc_loss = 0.0706797540067665
Trained batch 155 in epoch 10, gen_loss = 0.8518483984546784, disc_loss = 0.07119964042869516
Trained batch 156 in epoch 10, gen_loss = 0.850530180391992, disc_loss = 0.07126149472300035
Trained batch 157 in epoch 10, gen_loss = 0.8503878642863865, disc_loss = 0.07106406582354367
Trained batch 158 in epoch 10, gen_loss = 0.8515177738366637, disc_loss = 0.07116471967841469
Trained batch 159 in epoch 10, gen_loss = 0.8533702543005347, disc_loss = 0.07086032432271168
Trained batch 160 in epoch 10, gen_loss = 0.8525875760531574, disc_loss = 0.07063991825171509
Trained batch 161 in epoch 10, gen_loss = 0.8528101843448332, disc_loss = 0.0704532441234699
Trained batch 162 in epoch 10, gen_loss = 0.8523163830210094, disc_loss = 0.0701736229946094
Trained batch 163 in epoch 10, gen_loss = 0.8540358330781866, disc_loss = 0.0703254244744596
Trained batch 164 in epoch 10, gen_loss = 0.8536874863234434, disc_loss = 0.07015696049413898
Trained batch 165 in epoch 10, gen_loss = 0.8542922026062586, disc_loss = 0.0698177765673363
Trained batch 166 in epoch 10, gen_loss = 0.8553636004467924, disc_loss = 0.06949076656542139
Trained batch 167 in epoch 10, gen_loss = 0.8550517628235477, disc_loss = 0.0694178969244517
Trained batch 168 in epoch 10, gen_loss = 0.8537974207711643, disc_loss = 0.06953727685400014
Trained batch 169 in epoch 10, gen_loss = 0.857196049655185, disc_loss = 0.06979985830976683
Trained batch 170 in epoch 10, gen_loss = 0.85772048991326, disc_loss = 0.0694454327356397
Trained batch 171 in epoch 10, gen_loss = 0.8571525734177855, disc_loss = 0.06921589627948611
Trained batch 172 in epoch 10, gen_loss = 0.8565319258009079, disc_loss = 0.06940338784301212
Trained batch 173 in epoch 10, gen_loss = 0.8561599163830965, disc_loss = 0.0691878401470938
Trained batch 174 in epoch 10, gen_loss = 0.8573001730442047, disc_loss = 0.06887059310185058
Trained batch 175 in epoch 10, gen_loss = 0.8578240422701294, disc_loss = 0.06870431533951143
Trained batch 176 in epoch 10, gen_loss = 0.857437139682177, disc_loss = 0.06862987292204369
Trained batch 177 in epoch 10, gen_loss = 0.8582007421201534, disc_loss = 0.06832975187349354
Trained batch 178 in epoch 10, gen_loss = 0.8584748101967007, disc_loss = 0.06801894215044862
Trained batch 179 in epoch 10, gen_loss = 0.8598989223440489, disc_loss = 0.06773283709771931
Trained batch 180 in epoch 10, gen_loss = 0.8601436866910418, disc_loss = 0.06742384160729897
Trained batch 181 in epoch 10, gen_loss = 0.8599527656704515, disc_loss = 0.06710524382683766
Trained batch 182 in epoch 10, gen_loss = 0.8606526426604537, disc_loss = 0.06678083345874167
Trained batch 183 in epoch 10, gen_loss = 0.8611454676998698, disc_loss = 0.06656541935745222
Trained batch 184 in epoch 10, gen_loss = 0.8608125710809553, disc_loss = 0.0663697855219849
Trained batch 185 in epoch 10, gen_loss = 0.8593681731852152, disc_loss = 0.06641273432090798
Trained batch 186 in epoch 10, gen_loss = 0.8609768389699294, disc_loss = 0.06637641902325704
Trained batch 187 in epoch 10, gen_loss = 0.8614552330146444, disc_loss = 0.06608462788689723
Trained batch 188 in epoch 10, gen_loss = 0.8625955977452495, disc_loss = 0.06578655092774954
Trained batch 189 in epoch 10, gen_loss = 0.8634779495628256, disc_loss = 0.06550127696490994
Trained batch 190 in epoch 10, gen_loss = 0.8631170924109314, disc_loss = 0.06535053182227528
Trained batch 191 in epoch 10, gen_loss = 0.8629221045412123, disc_loss = 0.06511887230105155
Trained batch 192 in epoch 10, gen_loss = 0.8635105906064029, disc_loss = 0.06485011186112935
Trained batch 193 in epoch 10, gen_loss = 0.8637919952881705, disc_loss = 0.06461790502407425
Trained batch 194 in epoch 10, gen_loss = 0.8642755671953544, disc_loss = 0.06443812396998207
Trained batch 195 in epoch 10, gen_loss = 0.8630126780089067, disc_loss = 0.06434878186864436
Trained batch 196 in epoch 10, gen_loss = 0.863615075797599, disc_loss = 0.06413465374040649
Trained batch 197 in epoch 10, gen_loss = 0.8641455972736533, disc_loss = 0.0639493284309565
Trained batch 198 in epoch 10, gen_loss = 0.8642171341270658, disc_loss = 0.06376907887199341
Trained batch 199 in epoch 10, gen_loss = 0.8621408277750016, disc_loss = 0.06427241212455556
Trained batch 200 in epoch 10, gen_loss = 0.8634750593954058, disc_loss = 0.06446208892649605
Trained batch 201 in epoch 10, gen_loss = 0.8646574215133591, disc_loss = 0.06430284930439205
Trained batch 202 in epoch 10, gen_loss = 0.8644800256625772, disc_loss = 0.06406853423944761
Trained batch 203 in epoch 10, gen_loss = 0.8656977006033355, disc_loss = 0.06396749972447972
Trained batch 204 in epoch 10, gen_loss = 0.864236099836303, disc_loss = 0.06457097645530976
Trained batch 205 in epoch 10, gen_loss = 0.8651480498244462, disc_loss = 0.06440778672288272
Trained batch 206 in epoch 10, gen_loss = 0.8665757867449148, disc_loss = 0.06477188195466348
Trained batch 207 in epoch 10, gen_loss = 0.8649674126735101, disc_loss = 0.06546477195045625
Trained batch 208 in epoch 10, gen_loss = 0.8656109254896356, disc_loss = 0.06536179694289154
Trained batch 209 in epoch 10, gen_loss = 0.8669031532037825, disc_loss = 0.06550481960487863
Trained batch 210 in epoch 10, gen_loss = 0.8661979010319822, disc_loss = 0.06553102400092081
Trained batch 211 in epoch 10, gen_loss = 0.8657220020046774, disc_loss = 0.06533131378325019
Trained batch 212 in epoch 10, gen_loss = 0.865656919042829, disc_loss = 0.06510001248483296
Trained batch 213 in epoch 10, gen_loss = 0.8662432412677836, disc_loss = 0.06528179732882461
Trained batch 214 in epoch 10, gen_loss = 0.8663879020269527, disc_loss = 0.06503036919504751
Trained batch 215 in epoch 10, gen_loss = 0.8652979336954929, disc_loss = 0.06511163273265723
Trained batch 216 in epoch 10, gen_loss = 0.865046166604565, disc_loss = 0.06542793626806909
Trained batch 217 in epoch 10, gen_loss = 0.8650596065258761, disc_loss = 0.06519379153411937
Trained batch 218 in epoch 10, gen_loss = 0.8648342909333913, disc_loss = 0.06506673223870597
Trained batch 219 in epoch 10, gen_loss = 0.8645491938699376, disc_loss = 0.06491267770232463
Trained batch 220 in epoch 10, gen_loss = 0.866447248879601, disc_loss = 0.06486143048102568
Trained batch 221 in epoch 10, gen_loss = 0.8679980283921903, disc_loss = 0.06466696265589882
Trained batch 222 in epoch 10, gen_loss = 0.8685585487583828, disc_loss = 0.06443009406303143
Trained batch 223 in epoch 10, gen_loss = 0.8683896879000323, disc_loss = 0.06425193486211356
Trained batch 224 in epoch 10, gen_loss = 0.8680965961350335, disc_loss = 0.0640794707607064
Trained batch 225 in epoch 10, gen_loss = 0.8679861249649419, disc_loss = 0.06387392625385747
Trained batch 226 in epoch 10, gen_loss = 0.8684007966570917, disc_loss = 0.06365955617927048
Trained batch 227 in epoch 10, gen_loss = 0.8684168863191939, disc_loss = 0.06343456567060855
Trained batch 228 in epoch 10, gen_loss = 0.8685946664955939, disc_loss = 0.06329185702110027
Trained batch 229 in epoch 10, gen_loss = 0.8681065758933192, disc_loss = 0.06318204107532359
Trained batch 230 in epoch 10, gen_loss = 0.8678700567839982, disc_loss = 0.06316491843148808
Trained batch 231 in epoch 10, gen_loss = 0.8670318825491543, disc_loss = 0.06332418638289553
Trained batch 232 in epoch 10, gen_loss = 0.8674493831114708, disc_loss = 0.06311514906289431
Trained batch 233 in epoch 10, gen_loss = 0.8667002903600024, disc_loss = 0.0632105646077862
Trained batch 234 in epoch 10, gen_loss = 0.866767040973014, disc_loss = 0.06316749071306053
Trained batch 235 in epoch 10, gen_loss = 0.8660617437908205, disc_loss = 0.06309514841404192
Trained batch 236 in epoch 10, gen_loss = 0.8666754390116985, disc_loss = 0.06294031970729494
Trained batch 237 in epoch 10, gen_loss = 0.8665974618507033, disc_loss = 0.06275490668070104
Trained batch 238 in epoch 10, gen_loss = 0.8668273490343134, disc_loss = 0.06256232148613079
Trained batch 239 in epoch 10, gen_loss = 0.8667488080759843, disc_loss = 0.06237440334904629
Trained batch 240 in epoch 10, gen_loss = 0.8663858118393609, disc_loss = 0.06225029359614144
Trained batch 241 in epoch 10, gen_loss = 0.8682003048333254, disc_loss = 0.06218379145403477
Trained batch 242 in epoch 10, gen_loss = 0.8682322455531776, disc_loss = 0.06217097062349258
Trained batch 243 in epoch 10, gen_loss = 0.8677481024480257, disc_loss = 0.06243365744060119
Trained batch 244 in epoch 10, gen_loss = 0.8678821967572582, disc_loss = 0.06249628213557358
Trained batch 245 in epoch 10, gen_loss = 0.8687208512934242, disc_loss = 0.06231545334931735
Trained batch 246 in epoch 10, gen_loss = 0.869528009823942, disc_loss = 0.06212403670307777
Trained batch 247 in epoch 10, gen_loss = 0.8700621589537589, disc_loss = 0.06193250994340727
Trained batch 248 in epoch 10, gen_loss = 0.8702285847510679, disc_loss = 0.06176139919057369
Trained batch 249 in epoch 10, gen_loss = 0.8703260831832885, disc_loss = 0.061626174887642264
Trained batch 250 in epoch 10, gen_loss = 0.8693603414938269, disc_loss = 0.06178393053722037
Trained batch 251 in epoch 10, gen_loss = 0.8704079238195268, disc_loss = 0.06178696532475038
Trained batch 252 in epoch 10, gen_loss = 0.8713893329673134, disc_loss = 0.061594437533555174
Trained batch 253 in epoch 10, gen_loss = 0.8712661918692701, disc_loss = 0.06144939054089679
Trained batch 254 in epoch 10, gen_loss = 0.8713660583776586, disc_loss = 0.06126825441880261
Trained batch 255 in epoch 10, gen_loss = 0.8712200182490051, disc_loss = 0.06120804175407102
Trained batch 256 in epoch 10, gen_loss = 0.8702469530736426, disc_loss = 0.06128413780095918
Trained batch 257 in epoch 10, gen_loss = 0.8713128626808639, disc_loss = 0.06119019558920359
Trained batch 258 in epoch 10, gen_loss = 0.8713161544910268, disc_loss = 0.0611312741244708
Trained batch 259 in epoch 10, gen_loss = 0.8711083879837623, disc_loss = 0.06108153448619235
Trained batch 260 in epoch 10, gen_loss = 0.8708353056304756, disc_loss = 0.060961397227356606
Trained batch 261 in epoch 10, gen_loss = 0.8715315966205742, disc_loss = 0.06083905199037879
Trained batch 262 in epoch 10, gen_loss = 0.8723104131539058, disc_loss = 0.06073995282831018
Trained batch 263 in epoch 10, gen_loss = 0.8714603047930833, disc_loss = 0.06087692468391844
Trained batch 264 in epoch 10, gen_loss = 0.8718137914279722, disc_loss = 0.060723126691959374
Trained batch 265 in epoch 10, gen_loss = 0.871958471330485, disc_loss = 0.060524669747197425
Trained batch 266 in epoch 10, gen_loss = 0.8727422684765933, disc_loss = 0.06036743021322491
Trained batch 267 in epoch 10, gen_loss = 0.873118450392538, disc_loss = 0.06022571279396261
Trained batch 268 in epoch 10, gen_loss = 0.8727708868820871, disc_loss = 0.06015473459310636
Trained batch 269 in epoch 10, gen_loss = 0.8727008709201106, disc_loss = 0.06004610200136624
Trained batch 270 in epoch 10, gen_loss = 0.8741187521452394, disc_loss = 0.0599131673571011
Trained batch 271 in epoch 10, gen_loss = 0.8746566373635741, disc_loss = 0.059834214247530326
Trained batch 272 in epoch 10, gen_loss = 0.8747951351242624, disc_loss = 0.05970390798564959
Trained batch 273 in epoch 10, gen_loss = 0.8736495205955784, disc_loss = 0.05983616726942034
Trained batch 274 in epoch 10, gen_loss = 0.8744533972306685, disc_loss = 0.05968824436549436
Trained batch 275 in epoch 10, gen_loss = 0.8752934319385584, disc_loss = 0.059699892199706235
Trained batch 276 in epoch 10, gen_loss = 0.8754704119066039, disc_loss = 0.05955071475471131
Trained batch 277 in epoch 10, gen_loss = 0.8745378513130353, disc_loss = 0.05968903184519987
Trained batch 278 in epoch 10, gen_loss = 0.875166246967931, disc_loss = 0.05952327144849631
Trained batch 279 in epoch 10, gen_loss = 0.8758306997162956, disc_loss = 0.059395121508610565
Trained batch 280 in epoch 10, gen_loss = 0.8762355457421299, disc_loss = 0.05922557563550797
Trained batch 281 in epoch 10, gen_loss = 0.8758224880864435, disc_loss = 0.05912408567733851
Trained batch 282 in epoch 10, gen_loss = 0.8757443666036896, disc_loss = 0.058999146181800445
Trained batch 283 in epoch 10, gen_loss = 0.8759585965267369, disc_loss = 0.05891606388252858
Trained batch 284 in epoch 10, gen_loss = 0.8765187374332495, disc_loss = 0.05879232564026065
Trained batch 285 in epoch 10, gen_loss = 0.8760376641383538, disc_loss = 0.058737208084952267
Trained batch 286 in epoch 10, gen_loss = 0.8767504071109387, disc_loss = 0.05857723614343731
Trained batch 287 in epoch 10, gen_loss = 0.8770534607271353, disc_loss = 0.058496510601900004
Trained batch 288 in epoch 10, gen_loss = 0.8771838098248809, disc_loss = 0.05831685672098429
Trained batch 289 in epoch 10, gen_loss = 0.8774139772201407, disc_loss = 0.05815232886675874
Trained batch 290 in epoch 10, gen_loss = 0.8769058511429226, disc_loss = 0.05801473998167005
Trained batch 291 in epoch 10, gen_loss = 0.8775688595559499, disc_loss = 0.05784163188846297
Trained batch 292 in epoch 10, gen_loss = 0.8784484674092445, disc_loss = 0.057864178682489914
Trained batch 293 in epoch 10, gen_loss = 0.8783268348700335, disc_loss = 0.05785302170172182
Trained batch 294 in epoch 10, gen_loss = 0.8779369051173582, disc_loss = 0.05779866284327739
Trained batch 295 in epoch 10, gen_loss = 0.8776213921405174, disc_loss = 0.05774980727929269
Trained batch 296 in epoch 10, gen_loss = 0.8780246680031721, disc_loss = 0.05758630077476905
Trained batch 297 in epoch 10, gen_loss = 0.8777244583072278, disc_loss = 0.05751914508021968
Trained batch 298 in epoch 10, gen_loss = 0.8774044075139789, disc_loss = 0.0574266650358894
Trained batch 299 in epoch 10, gen_loss = 0.8776164680719376, disc_loss = 0.05772334937782337
Trained batch 300 in epoch 10, gen_loss = 0.8765946454384003, disc_loss = 0.05789303863297319
Trained batch 301 in epoch 10, gen_loss = 0.8768679693045206, disc_loss = 0.057738184427768485
Trained batch 302 in epoch 10, gen_loss = 0.8772471021897722, disc_loss = 0.057634315455006586
Trained batch 303 in epoch 10, gen_loss = 0.8769998213178233, disc_loss = 0.05748473440364346
Trained batch 304 in epoch 10, gen_loss = 0.8773319637189146, disc_loss = 0.05732155108946513
Trained batch 305 in epoch 10, gen_loss = 0.876955836426978, disc_loss = 0.057356316975190065
Trained batch 306 in epoch 10, gen_loss = 0.8760848973395382, disc_loss = 0.05752515032165456
Trained batch 307 in epoch 10, gen_loss = 0.8760242069309409, disc_loss = 0.057563365148319924
Trained batch 308 in epoch 10, gen_loss = 0.8760234150300134, disc_loss = 0.0574043482002534
Trained batch 309 in epoch 10, gen_loss = 0.8760796560395149, disc_loss = 0.05724652401291795
Trained batch 310 in epoch 10, gen_loss = 0.876836226875759, disc_loss = 0.057120215526551395
Trained batch 311 in epoch 10, gen_loss = 0.8767971184391242, disc_loss = 0.05706072911076868
Trained batch 312 in epoch 10, gen_loss = 0.8766970183140934, disc_loss = 0.05698800748273635
Trained batch 313 in epoch 10, gen_loss = 0.8771596662937455, disc_loss = 0.0569601150386771
Trained batch 314 in epoch 10, gen_loss = 0.8770499081838699, disc_loss = 0.056839868126230104
Trained batch 315 in epoch 10, gen_loss = 0.8766109083272233, disc_loss = 0.05684152204997225
Trained batch 316 in epoch 10, gen_loss = 0.876609316007572, disc_loss = 0.05677745197032951
Trained batch 317 in epoch 10, gen_loss = 0.8773137357249949, disc_loss = 0.056898424432630525
Trained batch 318 in epoch 10, gen_loss = 0.8767234113149135, disc_loss = 0.057062792362569364
Trained batch 319 in epoch 10, gen_loss = 0.8765604548156262, disc_loss = 0.05700760680047097
Trained batch 320 in epoch 10, gen_loss = 0.8774236964288159, disc_loss = 0.05735539453034507
Trained batch 321 in epoch 10, gen_loss = 0.8771434119029075, disc_loss = 0.057310704507731965
Trained batch 322 in epoch 10, gen_loss = 0.8776804939512128, disc_loss = 0.05716650583132548
Trained batch 323 in epoch 10, gen_loss = 0.8767629534374048, disc_loss = 0.05731913813729023
Trained batch 324 in epoch 10, gen_loss = 0.8777993125181932, disc_loss = 0.05756013240521917
Trained batch 325 in epoch 10, gen_loss = 0.8782116156414242, disc_loss = 0.05743274599616559
Trained batch 326 in epoch 10, gen_loss = 0.8772872476767327, disc_loss = 0.05757876100098367
Trained batch 327 in epoch 10, gen_loss = 0.878455717934341, disc_loss = 0.05761859356567672
Trained batch 328 in epoch 10, gen_loss = 0.8782895024424265, disc_loss = 0.05756215963620228
Trained batch 329 in epoch 10, gen_loss = 0.8776694494666475, disc_loss = 0.057674023188707055
Trained batch 330 in epoch 10, gen_loss = 0.8779520446440244, disc_loss = 0.057874100531797486
Trained batch 331 in epoch 10, gen_loss = 0.877321444541575, disc_loss = 0.057911365861017035
Trained batch 332 in epoch 10, gen_loss = 0.8783897037978645, disc_loss = 0.05780020762967678
Trained batch 333 in epoch 10, gen_loss = 0.8789160599608621, disc_loss = 0.05781057622690802
Trained batch 334 in epoch 10, gen_loss = 0.8781390852002955, disc_loss = 0.05779386296896125
Trained batch 335 in epoch 10, gen_loss = 0.8773504250815937, disc_loss = 0.05789684695662886
Trained batch 336 in epoch 10, gen_loss = 0.8772623758287741, disc_loss = 0.057997099863149736
Trained batch 337 in epoch 10, gen_loss = 0.8772010910793169, disc_loss = 0.05786270762452051
Trained batch 338 in epoch 10, gen_loss = 0.8768510113423553, disc_loss = 0.05778534874831021
Trained batch 339 in epoch 10, gen_loss = 0.8772432409665164, disc_loss = 0.05765545660876395
Trained batch 340 in epoch 10, gen_loss = 0.8764824507173555, disc_loss = 0.05761444624486076
Trained batch 341 in epoch 10, gen_loss = 0.8764464879593654, disc_loss = 0.05767262869852197
Trained batch 342 in epoch 10, gen_loss = 0.8760060162307918, disc_loss = 0.0575752505671461
Trained batch 343 in epoch 10, gen_loss = 0.8757292756507563, disc_loss = 0.057544425613149396
Trained batch 344 in epoch 10, gen_loss = 0.8749753221221592, disc_loss = 0.05756634755222046
Trained batch 345 in epoch 10, gen_loss = 0.8750904726155232, disc_loss = 0.05748184299973954
Trained batch 346 in epoch 10, gen_loss = 0.87501571587252, disc_loss = 0.057823998903216905
Trained batch 347 in epoch 10, gen_loss = 0.874594630352382, disc_loss = 0.057854771048055385
Trained batch 348 in epoch 10, gen_loss = 0.8744585003415629, disc_loss = 0.05779410761121906
Trained batch 349 in epoch 10, gen_loss = 0.8746578792163304, disc_loss = 0.05769741272420755
Trained batch 350 in epoch 10, gen_loss = 0.874361627801531, disc_loss = 0.05772889311162707
Trained batch 351 in epoch 10, gen_loss = 0.8733299460939385, disc_loss = 0.0586436425285435
Trained batch 352 in epoch 10, gen_loss = 0.8740617406604648, disc_loss = 0.058704284989346274
Trained batch 353 in epoch 10, gen_loss = 0.8744645221421947, disc_loss = 0.058568010168507864
Trained batch 354 in epoch 10, gen_loss = 0.8740831568207539, disc_loss = 0.058533142747121375
Trained batch 355 in epoch 10, gen_loss = 0.8735291207774302, disc_loss = 0.05857885765890183
Trained batch 356 in epoch 10, gen_loss = 0.8737313331676131, disc_loss = 0.05868400381721493
Trained batch 357 in epoch 10, gen_loss = 0.8730987455258822, disc_loss = 0.058755187628603434
Trained batch 358 in epoch 10, gen_loss = 0.8734138828798257, disc_loss = 0.05885651498944771
Trained batch 359 in epoch 10, gen_loss = 0.8727467641234398, disc_loss = 0.058942129513404024
Trained batch 360 in epoch 10, gen_loss = 0.873039768178047, disc_loss = 0.05895925766125404
Trained batch 361 in epoch 10, gen_loss = 0.8732081980995052, disc_loss = 0.05883451881406839
Trained batch 362 in epoch 10, gen_loss = 0.873378172722073, disc_loss = 0.058709064971901904
Trained batch 363 in epoch 10, gen_loss = 0.8728485529894358, disc_loss = 0.05873009912122123
Trained batch 364 in epoch 10, gen_loss = 0.8728055210962687, disc_loss = 0.05860996592968498
Trained batch 365 in epoch 10, gen_loss = 0.8729596817102588, disc_loss = 0.05855327737364979
Trained batch 366 in epoch 10, gen_loss = 0.8725032949317704, disc_loss = 0.05850116123524
Trained batch 367 in epoch 10, gen_loss = 0.8722818161806335, disc_loss = 0.058437760449875066
Trained batch 368 in epoch 10, gen_loss = 0.8728439987190371, disc_loss = 0.05835751920236845
Trained batch 369 in epoch 10, gen_loss = 0.873712921625859, disc_loss = 0.058341576376728516
Trained batch 370 in epoch 10, gen_loss = 0.873394826351793, disc_loss = 0.05828437174612661
Trained batch 371 in epoch 10, gen_loss = 0.8726537410290011, disc_loss = 0.0584107437283702
Trained batch 372 in epoch 10, gen_loss = 0.8733810179994189, disc_loss = 0.05830313622497082
Trained batch 373 in epoch 10, gen_loss = 0.8739966103099884, disc_loss = 0.058261746267992305
Trained batch 374 in epoch 10, gen_loss = 0.8741462475458781, disc_loss = 0.05822373248760899
Trained batch 375 in epoch 10, gen_loss = 0.8738668713163822, disc_loss = 0.058154211217349275
Trained batch 376 in epoch 10, gen_loss = 0.8738847800211818, disc_loss = 0.058049437623293156
Trained batch 377 in epoch 10, gen_loss = 0.8738848284754173, disc_loss = 0.05797538458537212
Trained batch 378 in epoch 10, gen_loss = 0.8733851198785223, disc_loss = 0.057982643684102005
Trained batch 379 in epoch 10, gen_loss = 0.8742536300107052, disc_loss = 0.058225515618381136
Trained batch 380 in epoch 10, gen_loss = 0.8741777741064237, disc_loss = 0.05830864693964599
Trained batch 381 in epoch 10, gen_loss = 0.8734102005733869, disc_loss = 0.05844067543847438
Trained batch 382 in epoch 10, gen_loss = 0.8729255963554582, disc_loss = 0.05850673540478314
Trained batch 383 in epoch 10, gen_loss = 0.873019887910535, disc_loss = 0.0584428186181564
Trained batch 384 in epoch 10, gen_loss = 0.8728436477772601, disc_loss = 0.05839883231908664
Trained batch 385 in epoch 10, gen_loss = 0.8729928174475932, disc_loss = 0.05827236016898614
Trained batch 386 in epoch 10, gen_loss = 0.8732722119767536, disc_loss = 0.0582330897895653
Trained batch 387 in epoch 10, gen_loss = 0.8725889455719092, disc_loss = 0.05836967523473786
Trained batch 388 in epoch 10, gen_loss = 0.8728557359283565, disc_loss = 0.05860226391275966
Trained batch 389 in epoch 10, gen_loss = 0.8722481507521409, disc_loss = 0.058671028001042895
Trained batch 390 in epoch 10, gen_loss = 0.8723281949682309, disc_loss = 0.058582135484508614
Trained batch 391 in epoch 10, gen_loss = 0.8721101360053433, disc_loss = 0.05864072796931414
Trained batch 392 in epoch 10, gen_loss = 0.8719055196104463, disc_loss = 0.05857569412103174
Trained batch 393 in epoch 10, gen_loss = 0.8712943488268683, disc_loss = 0.05856325582903692
Trained batch 394 in epoch 10, gen_loss = 0.8713314293306085, disc_loss = 0.058499129565692025
Trained batch 395 in epoch 10, gen_loss = 0.8713859977445217, disc_loss = 0.0584106375569139
Trained batch 396 in epoch 10, gen_loss = 0.8712091175675092, disc_loss = 0.058406393802595755
Trained batch 397 in epoch 10, gen_loss = 0.8713461659361968, disc_loss = 0.058285908283310095
Trained batch 398 in epoch 10, gen_loss = 0.8706540522121248, disc_loss = 0.05846328393469814
Trained batch 399 in epoch 10, gen_loss = 0.871023225337267, disc_loss = 0.05855421936721541
Trained batch 400 in epoch 10, gen_loss = 0.8711210394143464, disc_loss = 0.05863901375075268
Trained batch 401 in epoch 10, gen_loss = 0.8704718545598177, disc_loss = 0.05869796522429667
Trained batch 402 in epoch 10, gen_loss = 0.8700301206437293, disc_loss = 0.05879309851671604
Trained batch 403 in epoch 10, gen_loss = 0.8701692574685163, disc_loss = 0.05874072777517693
Trained batch 404 in epoch 10, gen_loss = 0.8705842439039254, disc_loss = 0.058892340522351455
Trained batch 405 in epoch 10, gen_loss = 0.870722453582463, disc_loss = 0.0587846630268955
Trained batch 406 in epoch 10, gen_loss = 0.8703292950951204, disc_loss = 0.05881451464919442
Trained batch 407 in epoch 10, gen_loss = 0.8698075298292964, disc_loss = 0.058785551530080755
Trained batch 408 in epoch 10, gen_loss = 0.8707061882123971, disc_loss = 0.05885865039381137
Trained batch 409 in epoch 10, gen_loss = 0.8709463871106868, disc_loss = 0.058866305405092315
Trained batch 410 in epoch 10, gen_loss = 0.8705517198627593, disc_loss = 0.058824920398013215
Trained batch 411 in epoch 10, gen_loss = 0.870755884253863, disc_loss = 0.05875528010752197
Trained batch 412 in epoch 10, gen_loss = 0.8711590027982329, disc_loss = 0.05864807616662207
Trained batch 413 in epoch 10, gen_loss = 0.8715811599279948, disc_loss = 0.058658631254158516
Trained batch 414 in epoch 10, gen_loss = 0.871642301743289, disc_loss = 0.058546556672642386
Trained batch 415 in epoch 10, gen_loss = 0.8712789803170241, disc_loss = 0.05864033344439052
Trained batch 416 in epoch 10, gen_loss = 0.8719253520027911, disc_loss = 0.05857695947899271
Trained batch 417 in epoch 10, gen_loss = 0.8717312467725653, disc_loss = 0.05854900330683867
Trained batch 418 in epoch 10, gen_loss = 0.8715863842383774, disc_loss = 0.05858836498729404
Trained batch 419 in epoch 10, gen_loss = 0.8719465931256613, disc_loss = 0.05862819704648462
Trained batch 420 in epoch 10, gen_loss = 0.8714244563902359, disc_loss = 0.05869482607733361
Trained batch 421 in epoch 10, gen_loss = 0.8716522867645697, disc_loss = 0.05859372404324535
Trained batch 422 in epoch 10, gen_loss = 0.8720375200817208, disc_loss = 0.05853356844272209
Trained batch 423 in epoch 10, gen_loss = 0.8720929241686497, disc_loss = 0.058436265080191965
Trained batch 424 in epoch 10, gen_loss = 0.8714020486438976, disc_loss = 0.05857502292732106
Trained batch 425 in epoch 10, gen_loss = 0.8713230976196522, disc_loss = 0.058495662639687106
Trained batch 426 in epoch 10, gen_loss = 0.8712838523840178, disc_loss = 0.05862318548707584
Trained batch 427 in epoch 10, gen_loss = 0.8710529897536072, disc_loss = 0.058564724719421674
Trained batch 428 in epoch 10, gen_loss = 0.8711269182480854, disc_loss = 0.058500885178654136
Trained batch 429 in epoch 10, gen_loss = 0.8711936132852421, disc_loss = 0.058534625117385455
Trained batch 430 in epoch 10, gen_loss = 0.8719220875034199, disc_loss = 0.058678804839509616
Trained batch 431 in epoch 10, gen_loss = 0.871382183222859, disc_loss = 0.058876005429300236
Trained batch 432 in epoch 10, gen_loss = 0.870639705768083, disc_loss = 0.058882960784044674
Trained batch 433 in epoch 10, gen_loss = 0.8703291913331379, disc_loss = 0.059490558494972534
Trained batch 434 in epoch 10, gen_loss = 0.8701692604470527, disc_loss = 0.059426511940813956
Trained batch 435 in epoch 10, gen_loss = 0.8704144813872259, disc_loss = 0.059372352552600205
Trained batch 436 in epoch 10, gen_loss = 0.8701938738539235, disc_loss = 0.05933764879218808
Trained batch 437 in epoch 10, gen_loss = 0.8702984393731644, disc_loss = 0.0592723323434132
Trained batch 438 in epoch 10, gen_loss = 0.8702543922328732, disc_loss = 0.05922484721729621
Trained batch 439 in epoch 10, gen_loss = 0.8703670719807798, disc_loss = 0.059177933316889475
Trained batch 440 in epoch 10, gen_loss = 0.8701576509443271, disc_loss = 0.059128591048482664
Trained batch 441 in epoch 10, gen_loss = 0.8703097823788138, disc_loss = 0.059071807541602135
Trained batch 442 in epoch 10, gen_loss = 0.8700365624632308, disc_loss = 0.05911337704193814
Trained batch 443 in epoch 10, gen_loss = 0.8699211126512235, disc_loss = 0.05904575059849031
Trained batch 444 in epoch 10, gen_loss = 0.8703352132540071, disc_loss = 0.05895343505034453
Trained batch 445 in epoch 10, gen_loss = 0.8698203675950055, disc_loss = 0.05894840401054398
Trained batch 446 in epoch 10, gen_loss = 0.8703280580657173, disc_loss = 0.059075840060251204
Trained batch 447 in epoch 10, gen_loss = 0.8708104312952075, disc_loss = 0.05906839543292465
Trained batch 448 in epoch 10, gen_loss = 0.8700726011017118, disc_loss = 0.059277404830863654
Trained batch 449 in epoch 10, gen_loss = 0.8697181419531504, disc_loss = 0.0592435074194024
Trained batch 450 in epoch 10, gen_loss = 0.8697951985832857, disc_loss = 0.05915253476122035
Trained batch 451 in epoch 10, gen_loss = 0.8700245817941902, disc_loss = 0.059090864388230954
Trained batch 452 in epoch 10, gen_loss = 0.8703863693125727, disc_loss = 0.058989234319034856
Trained batch 453 in epoch 10, gen_loss = 0.8699767921727134, disc_loss = 0.05895609623703302
Trained batch 454 in epoch 10, gen_loss = 0.8703001188707876, disc_loss = 0.059037131432361986
Trained batch 455 in epoch 10, gen_loss = 0.8699192636107144, disc_loss = 0.059022943563800175
Trained batch 456 in epoch 10, gen_loss = 0.8692788784300473, disc_loss = 0.059026014729233814
Trained batch 457 in epoch 10, gen_loss = 0.8695945030476849, disc_loss = 0.05914190606067697
Trained batch 458 in epoch 10, gen_loss = 0.8688311882008655, disc_loss = 0.05933210116654862
Trained batch 459 in epoch 10, gen_loss = 0.8694318941105967, disc_loss = 0.059316948599829944
Trained batch 460 in epoch 10, gen_loss = 0.8696868811408764, disc_loss = 0.059234521657818374
Trained batch 461 in epoch 10, gen_loss = 0.8692322108910714, disc_loss = 0.059346840758223364
Trained batch 462 in epoch 10, gen_loss = 0.8696257981831775, disc_loss = 0.05949479219710885
Trained batch 463 in epoch 10, gen_loss = 0.8690032353945847, disc_loss = 0.05953215742343234
Trained batch 464 in epoch 10, gen_loss = 0.8682622823663937, disc_loss = 0.05965944045193253
Trained batch 465 in epoch 10, gen_loss = 0.8686346466705012, disc_loss = 0.059665209223024644
Trained batch 466 in epoch 10, gen_loss = 0.8688315715983798, disc_loss = 0.05958545405509417
Trained batch 467 in epoch 10, gen_loss = 0.868817094172168, disc_loss = 0.05948062424058429
Trained batch 468 in epoch 10, gen_loss = 0.8685998168072975, disc_loss = 0.05942457415429609
Trained batch 469 in epoch 10, gen_loss = 0.8682076258862272, disc_loss = 0.05941159899465423
Trained batch 470 in epoch 10, gen_loss = 0.8683809312792088, disc_loss = 0.05931714720996354
Trained batch 471 in epoch 10, gen_loss = 0.8684038120811268, disc_loss = 0.05923884965072907
Trained batch 472 in epoch 10, gen_loss = 0.8684044758814838, disc_loss = 0.05915687731851137
Trained batch 473 in epoch 10, gen_loss = 0.8685330147481669, disc_loss = 0.05906735241652824
Trained batch 474 in epoch 10, gen_loss = 0.868352430745175, disc_loss = 0.059252285083853884
Trained batch 475 in epoch 10, gen_loss = 0.8677643044155186, disc_loss = 0.05937162147024881
Trained batch 476 in epoch 10, gen_loss = 0.8685521349716986, disc_loss = 0.05941609971604039
Trained batch 477 in epoch 10, gen_loss = 0.8680039029490498, disc_loss = 0.059481875936863125
Trained batch 478 in epoch 10, gen_loss = 0.8679758913830576, disc_loss = 0.059566608508601626
Trained batch 479 in epoch 10, gen_loss = 0.867805865034461, disc_loss = 0.05950370134960394
Trained batch 480 in epoch 10, gen_loss = 0.8674522772152558, disc_loss = 0.059461314902058075
Trained batch 481 in epoch 10, gen_loss = 0.8672627499984014, disc_loss = 0.05941130971841329
Trained batch 482 in epoch 10, gen_loss = 0.8677157543707585, disc_loss = 0.05931159708452243
Trained batch 483 in epoch 10, gen_loss = 0.8680639912274258, disc_loss = 0.059390360361527006
Trained batch 484 in epoch 10, gen_loss = 0.8670289008887773, disc_loss = 0.06022814507164138
Trained batch 485 in epoch 10, gen_loss = 0.8669375447334086, disc_loss = 0.06024542099359319
Trained batch 486 in epoch 10, gen_loss = 0.8672091995176593, disc_loss = 0.06029272834756995
Trained batch 487 in epoch 10, gen_loss = 0.8668055021371998, disc_loss = 0.06037928377274332
Trained batch 488 in epoch 10, gen_loss = 0.8665476897255288, disc_loss = 0.060399774937168645
Trained batch 489 in epoch 10, gen_loss = 0.8663174000321602, disc_loss = 0.06038881618890683
Trained batch 490 in epoch 10, gen_loss = 0.8663159180318751, disc_loss = 0.06032080618596338
Trained batch 491 in epoch 10, gen_loss = 0.866343045501205, disc_loss = 0.06023878785043319
Trained batch 492 in epoch 10, gen_loss = 0.8665289268290537, disc_loss = 0.06019907000306503
Trained batch 493 in epoch 10, gen_loss = 0.8663192118710352, disc_loss = 0.06022238517123527
Trained batch 494 in epoch 10, gen_loss = 0.8663240760263771, disc_loss = 0.060125439061849105
Trained batch 495 in epoch 10, gen_loss = 0.8666842308255934, disc_loss = 0.06017201737549546
Trained batch 496 in epoch 10, gen_loss = 0.866375386115291, disc_loss = 0.06020709528668336
Trained batch 497 in epoch 10, gen_loss = 0.8662960850091345, disc_loss = 0.06014745296577523
Trained batch 498 in epoch 10, gen_loss = 0.8663462449410158, disc_loss = 0.060065130231890806
Trained batch 499 in epoch 10, gen_loss = 0.8665077934265136, disc_loss = 0.059976576511748134
Trained batch 500 in epoch 10, gen_loss = 0.8664938280444421, disc_loss = 0.05989530709797067
Trained batch 501 in epoch 10, gen_loss = 0.8667307234855287, disc_loss = 0.059795514976353464
Trained batch 502 in epoch 10, gen_loss = 0.8669037991916209, disc_loss = 0.059697399918493585
Trained batch 503 in epoch 10, gen_loss = 0.8671959087489143, disc_loss = 0.05959496048504546
Trained batch 504 in epoch 10, gen_loss = 0.867467488628803, disc_loss = 0.05971400284918375
Trained batch 505 in epoch 10, gen_loss = 0.8671636151466445, disc_loss = 0.059836329694417684
Trained batch 506 in epoch 10, gen_loss = 0.8670336919188264, disc_loss = 0.05977003892913049
Trained batch 507 in epoch 10, gen_loss = 0.8678621097108511, disc_loss = 0.05975736641805384
Trained batch 508 in epoch 10, gen_loss = 0.867748726444769, disc_loss = 0.059684199624107544
Trained batch 509 in epoch 10, gen_loss = 0.867435259328169, disc_loss = 0.059747142309103815
Trained batch 510 in epoch 10, gen_loss = 0.8675181374624518, disc_loss = 0.059698868325115007
Trained batch 511 in epoch 10, gen_loss = 0.8673002449795604, disc_loss = 0.05962606721823249
Trained batch 512 in epoch 10, gen_loss = 0.8676557931286549, disc_loss = 0.05953329339438276
Trained batch 513 in epoch 10, gen_loss = 0.8678685941584843, disc_loss = 0.059441306832126894
Trained batch 514 in epoch 10, gen_loss = 0.8674949104346118, disc_loss = 0.05942789035966819
Trained batch 515 in epoch 10, gen_loss = 0.8684126069379408, disc_loss = 0.059703027992870285
Trained batch 516 in epoch 10, gen_loss = 0.8679085820048644, disc_loss = 0.059694789822899684
Trained batch 517 in epoch 10, gen_loss = 0.8677872284729048, disc_loss = 0.05969550425787259
Trained batch 518 in epoch 10, gen_loss = 0.8677183209356775, disc_loss = 0.0596723092517139
Trained batch 519 in epoch 10, gen_loss = 0.8680025782722693, disc_loss = 0.059578379445100346
Trained batch 520 in epoch 10, gen_loss = 0.867920420906594, disc_loss = 0.05954993011487108
Trained batch 521 in epoch 10, gen_loss = 0.8676975536163739, disc_loss = 0.05951542794165626
Trained batch 522 in epoch 10, gen_loss = 0.8678588434113599, disc_loss = 0.059428251726841325
Trained batch 523 in epoch 10, gen_loss = 0.8683131783063175, disc_loss = 0.059348102739855704
Trained batch 524 in epoch 10, gen_loss = 0.8686390656516666, disc_loss = 0.05925548207635681
Trained batch 525 in epoch 10, gen_loss = 0.8684475868373769, disc_loss = 0.0592310576967031
Trained batch 526 in epoch 10, gen_loss = 0.8687034144121057, disc_loss = 0.05916279293260974
Trained batch 527 in epoch 10, gen_loss = 0.8689458907553644, disc_loss = 0.0590687118105548
Trained batch 528 in epoch 10, gen_loss = 0.8689997615345484, disc_loss = 0.058996740578091046
Trained batch 529 in epoch 10, gen_loss = 0.8693095317426718, disc_loss = 0.05891623893875699
Trained batch 530 in epoch 10, gen_loss = 0.8689722948604159, disc_loss = 0.05891770260976786
Trained batch 531 in epoch 10, gen_loss = 0.86907951477775, disc_loss = 0.05893968051751109
Trained batch 532 in epoch 10, gen_loss = 0.8689885767942074, disc_loss = 0.05893819565722268
Trained batch 533 in epoch 10, gen_loss = 0.8693421275428171, disc_loss = 0.05897175440170596
Trained batch 534 in epoch 10, gen_loss = 0.8693863732792507, disc_loss = 0.059203556156499644
Trained batch 535 in epoch 10, gen_loss = 0.8687186826076081, disc_loss = 0.059634939340853704
Trained batch 536 in epoch 10, gen_loss = 0.868956822034811, disc_loss = 0.05954810800516434
Trained batch 537 in epoch 10, gen_loss = 0.8692635955863726, disc_loss = 0.05951370639972333
Trained batch 538 in epoch 10, gen_loss = 0.8692805196447142, disc_loss = 0.05955511025120271
Trained batch 539 in epoch 10, gen_loss = 0.8692590954127135, disc_loss = 0.059497990021999514
Trained batch 540 in epoch 10, gen_loss = 0.8688141180274668, disc_loss = 0.05960103991060981
Trained batch 541 in epoch 10, gen_loss = 0.8691668479644944, disc_loss = 0.0596312597519426
Trained batch 542 in epoch 10, gen_loss = 0.8689865233928898, disc_loss = 0.059561156063181096
Trained batch 543 in epoch 10, gen_loss = 0.8690747652641114, disc_loss = 0.05947470546936315
Trained batch 544 in epoch 10, gen_loss = 0.8691688817575437, disc_loss = 0.05939279400717912
Trained batch 545 in epoch 10, gen_loss = 0.8693248725636101, disc_loss = 0.059312356527615
Trained batch 546 in epoch 10, gen_loss = 0.8692116703586125, disc_loss = 0.05923969857820346
Trained batch 547 in epoch 10, gen_loss = 0.8693122381929064, disc_loss = 0.059198286874648044
Trained batch 548 in epoch 10, gen_loss = 0.8690582849288899, disc_loss = 0.05915017497347488
Trained batch 549 in epoch 10, gen_loss = 0.869086976593191, disc_loss = 0.059090702250091866
Trained batch 550 in epoch 10, gen_loss = 0.8687661172257577, disc_loss = 0.0590891832808631
Trained batch 551 in epoch 10, gen_loss = 0.8691977476296218, disc_loss = 0.059014964262462236
Trained batch 552 in epoch 10, gen_loss = 0.8686906652252239, disc_loss = 0.05904505856648411
Trained batch 553 in epoch 10, gen_loss = 0.8689893577718563, disc_loss = 0.05898679601993506
Trained batch 554 in epoch 10, gen_loss = 0.8692488950652045, disc_loss = 0.05896645140087416
Trained batch 555 in epoch 10, gen_loss = 0.8690938962449273, disc_loss = 0.05894392503763837
Trained batch 556 in epoch 10, gen_loss = 0.8691313153323408, disc_loss = 0.05889039303475399
Trained batch 557 in epoch 10, gen_loss = 0.8689209057225121, disc_loss = 0.05884196204767566
Trained batch 558 in epoch 10, gen_loss = 0.8685437145514651, disc_loss = 0.058912530728850734
Trained batch 559 in epoch 10, gen_loss = 0.8694930362914289, disc_loss = 0.05911089075546313
Trained batch 560 in epoch 10, gen_loss = 0.8689714426875327, disc_loss = 0.05929990487385694
Trained batch 561 in epoch 10, gen_loss = 0.8693386130697787, disc_loss = 0.05956238211344702
Trained batch 562 in epoch 10, gen_loss = 0.8691460025458734, disc_loss = 0.05953359733654937
Trained batch 563 in epoch 10, gen_loss = 0.8688994035230461, disc_loss = 0.05950977032465847
Trained batch 564 in epoch 10, gen_loss = 0.8687682973600067, disc_loss = 0.059502125011377895
Trained batch 565 in epoch 10, gen_loss = 0.8693329395969849, disc_loss = 0.05948969312489375
Trained batch 566 in epoch 10, gen_loss = 0.8693935075344442, disc_loss = 0.05955575978238878
Trained batch 567 in epoch 10, gen_loss = 0.8689175310059333, disc_loss = 0.059691567092799436
Trained batch 568 in epoch 10, gen_loss = 0.8689378457035876, disc_loss = 0.059637306183609316
Trained batch 569 in epoch 10, gen_loss = 0.8689349164042557, disc_loss = 0.059567143863655234
Trained batch 570 in epoch 10, gen_loss = 0.8691680865613466, disc_loss = 0.05948037348260317
Trained batch 571 in epoch 10, gen_loss = 0.8691117489462966, disc_loss = 0.059466860173237546
Trained batch 572 in epoch 10, gen_loss = 0.8693077854461071, disc_loss = 0.05939413977130259
Trained batch 573 in epoch 10, gen_loss = 0.8698396586167272, disc_loss = 0.05934313563419058
Trained batch 574 in epoch 10, gen_loss = 0.8692320563482202, disc_loss = 0.0596068849325504
Trained batch 575 in epoch 10, gen_loss = 0.8699313074143397, disc_loss = 0.05968989999140225
Trained batch 576 in epoch 10, gen_loss = 0.8701465571980336, disc_loss = 0.059667661476983616
Trained batch 577 in epoch 10, gen_loss = 0.8699995619615469, disc_loss = 0.059623299476732484
Trained batch 578 in epoch 10, gen_loss = 0.869629445265406, disc_loss = 0.05966114616407554
Trained batch 579 in epoch 10, gen_loss = 0.8695722504936415, disc_loss = 0.05963901388057476
Trained batch 580 in epoch 10, gen_loss = 0.8698023308369871, disc_loss = 0.05961583354774856
Trained batch 581 in epoch 10, gen_loss = 0.8698762588689417, disc_loss = 0.05954139196166698
Trained batch 582 in epoch 10, gen_loss = 0.8696016820585339, disc_loss = 0.05952108486940506
Trained batch 583 in epoch 10, gen_loss = 0.8696016394724585, disc_loss = 0.05945477925945864
Trained batch 584 in epoch 10, gen_loss = 0.8698355588138613, disc_loss = 0.0594158693551062
Trained batch 585 in epoch 10, gen_loss = 0.8698760676912887, disc_loss = 0.05942863733634836
Trained batch 586 in epoch 10, gen_loss = 0.8698894948122652, disc_loss = 0.05935018408640559
Trained batch 587 in epoch 10, gen_loss = 0.8693977538622967, disc_loss = 0.05947765451301599
Trained batch 588 in epoch 10, gen_loss = 0.8693325239247903, disc_loss = 0.05943400331761795
Trained batch 589 in epoch 10, gen_loss = 0.8699380473565247, disc_loss = 0.0596316847879187
Trained batch 590 in epoch 10, gen_loss = 0.8696468758905801, disc_loss = 0.059679755212206476
Trained batch 591 in epoch 10, gen_loss = 0.8697321198477939, disc_loss = 0.05962482254521141
Trained batch 592 in epoch 10, gen_loss = 0.8697022564495595, disc_loss = 0.05966073264482527
Trained batch 593 in epoch 10, gen_loss = 0.8696320702130546, disc_loss = 0.059601386958068416
Trained batch 594 in epoch 10, gen_loss = 0.8692800643063393, disc_loss = 0.059683095074470054
Trained batch 595 in epoch 10, gen_loss = 0.869261160992936, disc_loss = 0.05961261480193485
Trained batch 596 in epoch 10, gen_loss = 0.8695684915012251, disc_loss = 0.059637330265768757
Trained batch 597 in epoch 10, gen_loss = 0.8699029048150997, disc_loss = 0.05956188523690263
Trained batch 598 in epoch 10, gen_loss = 0.869486579512913, disc_loss = 0.059571580856397924
Trained batch 599 in epoch 10, gen_loss = 0.8695166488488515, disc_loss = 0.05950440743394817
Trained batch 600 in epoch 10, gen_loss = 0.8696232375606721, disc_loss = 0.05945041551705629
Trained batch 601 in epoch 10, gen_loss = 0.8698984253842174, disc_loss = 0.0595270798168767
Trained batch 602 in epoch 10, gen_loss = 0.8697994435406838, disc_loss = 0.059477079691362275
Trained batch 603 in epoch 10, gen_loss = 0.8692826979010311, disc_loss = 0.059498864960770385
Trained batch 604 in epoch 10, gen_loss = 0.8689269941700392, disc_loss = 0.05948954637832016
Trained batch 605 in epoch 10, gen_loss = 0.8690980988563878, disc_loss = 0.059429684015322885
Trained batch 606 in epoch 10, gen_loss = 0.8693235286770779, disc_loss = 0.05947641017608946
Trained batch 607 in epoch 10, gen_loss = 0.8691844465701204, disc_loss = 0.05943775844934862
Trained batch 608 in epoch 10, gen_loss = 0.86887054509913, disc_loss = 0.059632526059927075
Trained batch 609 in epoch 10, gen_loss = 0.8689803674572804, disc_loss = 0.05975767563433066
Trained batch 610 in epoch 10, gen_loss = 0.8685428362626296, disc_loss = 0.059794463852112546
Trained batch 611 in epoch 10, gen_loss = 0.8690242027145585, disc_loss = 0.05994755654288395
Trained batch 612 in epoch 10, gen_loss = 0.8688726238480984, disc_loss = 0.05995284618967825
Trained batch 613 in epoch 10, gen_loss = 0.8688698459525839, disc_loss = 0.0598855236255494
Trained batch 614 in epoch 10, gen_loss = 0.869155870608198, disc_loss = 0.059845625355506575
Trained batch 615 in epoch 10, gen_loss = 0.8692721039443821, disc_loss = 0.059864193353009736
Trained batch 616 in epoch 10, gen_loss = 0.8688541794711999, disc_loss = 0.059958244036170665
Trained batch 617 in epoch 10, gen_loss = 0.8686001738684077, disc_loss = 0.05997539559472654
Trained batch 618 in epoch 10, gen_loss = 0.8692614910868335, disc_loss = 0.060112939651766624
Trained batch 619 in epoch 10, gen_loss = 0.8692851678017647, disc_loss = 0.06005193852864566
Trained batch 620 in epoch 10, gen_loss = 0.8689708537909527, disc_loss = 0.06003815355379248
Trained batch 621 in epoch 10, gen_loss = 0.8688609256046761, disc_loss = 0.060095029782018715
Trained batch 622 in epoch 10, gen_loss = 0.8690701625511696, disc_loss = 0.06004902774043513
Trained batch 623 in epoch 10, gen_loss = 0.8689551273217568, disc_loss = 0.060012893665444635
Trained batch 624 in epoch 10, gen_loss = 0.8690291416168213, disc_loss = 0.05994183293357491
Trained batch 625 in epoch 10, gen_loss = 0.8692788704515646, disc_loss = 0.05992028373442352
Trained batch 626 in epoch 10, gen_loss = 0.8690545181528423, disc_loss = 0.05996724999208223
Trained batch 627 in epoch 10, gen_loss = 0.8693786847173788, disc_loss = 0.05990787729351028
Trained batch 628 in epoch 10, gen_loss = 0.8690952898398492, disc_loss = 0.05996882331310305
Trained batch 629 in epoch 10, gen_loss = 0.8694351943712386, disc_loss = 0.05998436484323253
Trained batch 630 in epoch 10, gen_loss = 0.8694166156644867, disc_loss = 0.059929691872776455
Trained batch 631 in epoch 10, gen_loss = 0.8694559748791442, disc_loss = 0.05989408880675542
Trained batch 632 in epoch 10, gen_loss = 0.8693689693583508, disc_loss = 0.05984080413144559
Trained batch 633 in epoch 10, gen_loss = 0.86942768773822, disc_loss = 0.05979687394794629
Trained batch 634 in epoch 10, gen_loss = 0.8693196597061758, disc_loss = 0.059805801555543665
Trained batch 635 in epoch 10, gen_loss = 0.8688590590309047, disc_loss = 0.059867708619432115
Trained batch 636 in epoch 10, gen_loss = 0.8693795679502622, disc_loss = 0.05981485118206409
Trained batch 637 in epoch 10, gen_loss = 0.869445066840671, disc_loss = 0.05975437029498428
Trained batch 638 in epoch 10, gen_loss = 0.8689237602626401, disc_loss = 0.05980314909668526
Trained batch 639 in epoch 10, gen_loss = 0.8692534704692662, disc_loss = 0.0597648131843016
Trained batch 640 in epoch 10, gen_loss = 0.8692567537243764, disc_loss = 0.05971334119183527
Trained batch 641 in epoch 10, gen_loss = 0.8692421089637317, disc_loss = 0.05964654517023479
Trained batch 642 in epoch 10, gen_loss = 0.8692465066724394, disc_loss = 0.05958465542745651
Trained batch 643 in epoch 10, gen_loss = 0.8690821425700039, disc_loss = 0.05953338939583751
Trained batch 644 in epoch 10, gen_loss = 0.8688801401345305, disc_loss = 0.05947743006584834
Trained batch 645 in epoch 10, gen_loss = 0.8692284458931017, disc_loss = 0.05950283493641937
Trained batch 646 in epoch 10, gen_loss = 0.8693387197011037, disc_loss = 0.0594326025242104
Trained batch 647 in epoch 10, gen_loss = 0.8687409141825305, disc_loss = 0.05956751178665501
Trained batch 648 in epoch 10, gen_loss = 0.8691245945190612, disc_loss = 0.05959764573341365
Trained batch 649 in epoch 10, gen_loss = 0.8687399388735111, disc_loss = 0.059618854572136816
Trained batch 650 in epoch 10, gen_loss = 0.8685692062117903, disc_loss = 0.059603421035410116
Trained batch 651 in epoch 10, gen_loss = 0.8690017412868014, disc_loss = 0.05978476119933342
Trained batch 652 in epoch 10, gen_loss = 0.8688639338951198, disc_loss = 0.05977733729686731
Trained batch 653 in epoch 10, gen_loss = 0.868534422203306, disc_loss = 0.05983234250231643
Trained batch 654 in epoch 10, gen_loss = 0.8684133026891082, disc_loss = 0.05986557540106978
Trained batch 655 in epoch 10, gen_loss = 0.8684635130097953, disc_loss = 0.05988253071327784
Trained batch 656 in epoch 10, gen_loss = 0.8683449378750278, disc_loss = 0.05988384565321482
Trained batch 657 in epoch 10, gen_loss = 0.8679565568553641, disc_loss = 0.05990527178257092
Trained batch 658 in epoch 10, gen_loss = 0.868017523033666, disc_loss = 0.05989437026631692
Trained batch 659 in epoch 10, gen_loss = 0.8680409813017557, disc_loss = 0.059873498951536465
Trained batch 660 in epoch 10, gen_loss = 0.8674010676352952, disc_loss = 0.06013060371080095
Trained batch 661 in epoch 10, gen_loss = 0.8676389903730496, disc_loss = 0.0600706661588532
Trained batch 662 in epoch 10, gen_loss = 0.8678913567310724, disc_loss = 0.060683024047732036
Trained batch 663 in epoch 10, gen_loss = 0.8674553003925157, disc_loss = 0.060741056747740156
Trained batch 664 in epoch 10, gen_loss = 0.867363858357408, disc_loss = 0.060729927645954196
Trained batch 665 in epoch 10, gen_loss = 0.86711829055, disc_loss = 0.060718044082776784
Trained batch 666 in epoch 10, gen_loss = 0.8670278288524548, disc_loss = 0.06067501737162292
Trained batch 667 in epoch 10, gen_loss = 0.8671386375309464, disc_loss = 0.06072006210988711
Trained batch 668 in epoch 10, gen_loss = 0.8668140147566261, disc_loss = 0.06076038699327051
Trained batch 669 in epoch 10, gen_loss = 0.8665110155272839, disc_loss = 0.06078366626457158
Trained batch 670 in epoch 10, gen_loss = 0.8660703438671442, disc_loss = 0.06086271919446113
Trained batch 671 in epoch 10, gen_loss = 0.8663030388720688, disc_loss = 0.06103356229487829
Trained batch 672 in epoch 10, gen_loss = 0.8659200359683866, disc_loss = 0.06113807976946102
Trained batch 673 in epoch 10, gen_loss = 0.8660950759309689, disc_loss = 0.061078204127382324
Trained batch 674 in epoch 10, gen_loss = 0.8662893975664068, disc_loss = 0.06108943366687055
Trained batch 675 in epoch 10, gen_loss = 0.8664012666372858, disc_loss = 0.06104021451157689
Trained batch 676 in epoch 10, gen_loss = 0.866023507084769, disc_loss = 0.061075836530799926
Trained batch 677 in epoch 10, gen_loss = 0.8658706795940708, disc_loss = 0.06102584882716272
Trained batch 678 in epoch 10, gen_loss = 0.8661149333344995, disc_loss = 0.06109182582756666
Trained batch 679 in epoch 10, gen_loss = 0.8663061713909401, disc_loss = 0.06103044459116919
Trained batch 680 in epoch 10, gen_loss = 0.8660839680970678, disc_loss = 0.06105697971239423
Trained batch 681 in epoch 10, gen_loss = 0.8659459741846207, disc_loss = 0.06104215136264885
Trained batch 682 in epoch 10, gen_loss = 0.8663998035438588, disc_loss = 0.06110017752209419
Trained batch 683 in epoch 10, gen_loss = 0.86671985864465, disc_loss = 0.061148363476679034
Trained batch 684 in epoch 10, gen_loss = 0.866428944794801, disc_loss = 0.06118301664458683
Trained batch 685 in epoch 10, gen_loss = 0.8661516388286307, disc_loss = 0.061182306689120634
Trained batch 686 in epoch 10, gen_loss = 0.8662283052263302, disc_loss = 0.06111034225968012
Trained batch 687 in epoch 10, gen_loss = 0.8660967834727016, disc_loss = 0.0613848494229091
Trained batch 688 in epoch 10, gen_loss = 0.865684356978393, disc_loss = 0.06146218620054154
Trained batch 689 in epoch 10, gen_loss = 0.8659446157838987, disc_loss = 0.061526921563579334
Trained batch 690 in epoch 10, gen_loss = 0.8654297048983457, disc_loss = 0.06160057806133599
Trained batch 691 in epoch 10, gen_loss = 0.8653659934684031, disc_loss = 0.061582468029493846
Trained batch 692 in epoch 10, gen_loss = 0.865304075063221, disc_loss = 0.06155577557252836
Trained batch 693 in epoch 10, gen_loss = 0.8649247456610375, disc_loss = 0.06174085670827166
Trained batch 694 in epoch 10, gen_loss = 0.8647252761631561, disc_loss = 0.06174624545580085
Trained batch 695 in epoch 10, gen_loss = 0.8648400741318861, disc_loss = 0.061679529242255005
Trained batch 696 in epoch 10, gen_loss = 0.864960559086615, disc_loss = 0.06170175375464978
Trained batch 697 in epoch 10, gen_loss = 0.8646628108185137, disc_loss = 0.061774249139901004
Trained batch 698 in epoch 10, gen_loss = 0.8645619542387252, disc_loss = 0.06179211141797414
Trained batch 699 in epoch 10, gen_loss = 0.8647727189319474, disc_loss = 0.06176693744624832
Trained batch 700 in epoch 10, gen_loss = 0.8652070047766948, disc_loss = 0.06170199614499142
Trained batch 701 in epoch 10, gen_loss = 0.8655110651526357, disc_loss = 0.061631464377507314
Trained batch 702 in epoch 10, gen_loss = 0.8650866842286855, disc_loss = 0.06173107462205194
Trained batch 703 in epoch 10, gen_loss = 0.8647160762497648, disc_loss = 0.06181932297543178
Trained batch 704 in epoch 10, gen_loss = 0.8652540019640685, disc_loss = 0.06198034436237199
Trained batch 705 in epoch 10, gen_loss = 0.8654986389044662, disc_loss = 0.06193886276416312
Trained batch 706 in epoch 10, gen_loss = 0.8651519802621601, disc_loss = 0.06194459833665797
Trained batch 707 in epoch 10, gen_loss = 0.8650630195177881, disc_loss = 0.061952910751057
Trained batch 708 in epoch 10, gen_loss = 0.865233055585194, disc_loss = 0.06231469742110464
Trained batch 709 in epoch 10, gen_loss = 0.8651991781634344, disc_loss = 0.06231661710927499
Trained batch 710 in epoch 10, gen_loss = 0.8652955536349414, disc_loss = 0.06225294904500435
Trained batch 711 in epoch 10, gen_loss = 0.8650701861786708, disc_loss = 0.06223885384008937
Trained batch 712 in epoch 10, gen_loss = 0.8652685339370583, disc_loss = 0.062352408676540155
Trained batch 713 in epoch 10, gen_loss = 0.8650477811151526, disc_loss = 0.06233339456917003
Trained batch 714 in epoch 10, gen_loss = 0.8645934048649314, disc_loss = 0.062492097577509974
Trained batch 715 in epoch 10, gen_loss = 0.8648254718610694, disc_loss = 0.06243118996193435
Trained batch 716 in epoch 10, gen_loss = 0.8651465262744882, disc_loss = 0.062415559033797
Trained batch 717 in epoch 10, gen_loss = 0.8647920696433208, disc_loss = 0.06240809282539594
Trained batch 718 in epoch 10, gen_loss = 0.8649407102517856, disc_loss = 0.06250225796308549
Trained batch 719 in epoch 10, gen_loss = 0.8647246068964402, disc_loss = 0.06253745820981244
Trained batch 720 in epoch 10, gen_loss = 0.8645019201812401, disc_loss = 0.06250883324908793
Trained batch 721 in epoch 10, gen_loss = 0.8647784118094273, disc_loss = 0.06248487325945038
Trained batch 722 in epoch 10, gen_loss = 0.8648123966625287, disc_loss = 0.06246558581652792
Trained batch 723 in epoch 10, gen_loss = 0.8646372004684822, disc_loss = 0.06248006456884046
Trained batch 724 in epoch 10, gen_loss = 0.8646082144359063, disc_loss = 0.062468267902089605
Trained batch 725 in epoch 10, gen_loss = 0.8646489427355696, disc_loss = 0.06241209910138312
Trained batch 726 in epoch 10, gen_loss = 0.8647129125329455, disc_loss = 0.062385293058769206
Trained batch 727 in epoch 10, gen_loss = 0.8647250690712378, disc_loss = 0.06233149837218942
Trained batch 728 in epoch 10, gen_loss = 0.8649041957243644, disc_loss = 0.06226146836357577
Trained batch 729 in epoch 10, gen_loss = 0.864769673714899, disc_loss = 0.06229013002426555
Trained batch 730 in epoch 10, gen_loss = 0.8647088391754761, disc_loss = 0.062229145620854014
Trained batch 731 in epoch 10, gen_loss = 0.8644194117253595, disc_loss = 0.06230228822970956
Trained batch 732 in epoch 10, gen_loss = 0.8645488547026542, disc_loss = 0.062311551054001955
Trained batch 733 in epoch 10, gen_loss = 0.8641620961700538, disc_loss = 0.0623200852290679
Trained batch 734 in epoch 10, gen_loss = 0.8642919823831442, disc_loss = 0.06233316783786935
Trained batch 735 in epoch 10, gen_loss = 0.8639267071190736, disc_loss = 0.06238149574378242
Trained batch 736 in epoch 10, gen_loss = 0.8636229868417193, disc_loss = 0.06239974610141025
Trained batch 737 in epoch 10, gen_loss = 0.8636191061276407, disc_loss = 0.06235947971974265
Trained batch 738 in epoch 10, gen_loss = 0.8640429807854602, disc_loss = 0.06234935462583204
Trained batch 739 in epoch 10, gen_loss = 0.863993776931956, disc_loss = 0.06230368304280313
Trained batch 740 in epoch 10, gen_loss = 0.863956393942981, disc_loss = 0.06225987902293221
Trained batch 741 in epoch 10, gen_loss = 0.863748117317408, disc_loss = 0.06234252565751239
Trained batch 742 in epoch 10, gen_loss = 0.8638198807695191, disc_loss = 0.062357859743049575
Trained batch 743 in epoch 10, gen_loss = 0.86381555216447, disc_loss = 0.062302225218680236
Trained batch 744 in epoch 10, gen_loss = 0.8640796264946061, disc_loss = 0.06226457365844774
Trained batch 745 in epoch 10, gen_loss = 0.8640196543516486, disc_loss = 0.06222333294594156
Trained batch 746 in epoch 10, gen_loss = 0.8639246346241978, disc_loss = 0.062170049833280935
Trained batch 747 in epoch 10, gen_loss = 0.8640524143761492, disc_loss = 0.06219766616888524
Trained batch 748 in epoch 10, gen_loss = 0.8638342234973755, disc_loss = 0.062206027287621805
Trained batch 749 in epoch 10, gen_loss = 0.8639500444332758, disc_loss = 0.06215318788277606
Trained batch 750 in epoch 10, gen_loss = 0.8637647390286234, disc_loss = 0.062120883785728886
Trained batch 751 in epoch 10, gen_loss = 0.8635564710786368, disc_loss = 0.06208104099966883
Trained batch 752 in epoch 10, gen_loss = 0.8636477384988371, disc_loss = 0.062092413670033375
Trained batch 753 in epoch 10, gen_loss = 0.8634904446352065, disc_loss = 0.062050848857768924
Trained batch 754 in epoch 10, gen_loss = 0.8632494927636835, disc_loss = 0.062056981061048656
Trained batch 755 in epoch 10, gen_loss = 0.8632908359012276, disc_loss = 0.06208274623307661
Trained batch 756 in epoch 10, gen_loss = 0.863454683493119, disc_loss = 0.06216143083892753
Trained batch 757 in epoch 10, gen_loss = 0.8632246281430715, disc_loss = 0.06222184369460947
Trained batch 758 in epoch 10, gen_loss = 0.8631350493478209, disc_loss = 0.06219736368325447
Trained batch 759 in epoch 10, gen_loss = 0.8631042814960606, disc_loss = 0.06215323929760703
Trained batch 760 in epoch 10, gen_loss = 0.8632171353357067, disc_loss = 0.06208538677868936
Trained batch 761 in epoch 10, gen_loss = 0.8634137352072974, disc_loss = 0.0620605460486651
Trained batch 762 in epoch 10, gen_loss = 0.8634758828742476, disc_loss = 0.062000224573676856
Trained batch 763 in epoch 10, gen_loss = 0.8636498237077478, disc_loss = 0.061934449682524186
Trained batch 764 in epoch 10, gen_loss = 0.86326957228137, disc_loss = 0.06201095044113744
Trained batch 765 in epoch 10, gen_loss = 0.8634592761181042, disc_loss = 0.06196291572000958
Trained batch 766 in epoch 10, gen_loss = 0.8638635879622911, disc_loss = 0.06208725437228088
Trained batch 767 in epoch 10, gen_loss = 0.8635135841323063, disc_loss = 0.06227540254318834
Trained batch 768 in epoch 10, gen_loss = 0.8635584165975548, disc_loss = 0.062230023195160494
Trained batch 769 in epoch 10, gen_loss = 0.8637280540419864, disc_loss = 0.06226622579534623
Trained batch 770 in epoch 10, gen_loss = 0.863499091486368, disc_loss = 0.062318778853505924
Trained batch 771 in epoch 10, gen_loss = 0.863189905302821, disc_loss = 0.06232602899312645
Trained batch 772 in epoch 10, gen_loss = 0.8630900205261186, disc_loss = 0.062423662654212154
Trained batch 773 in epoch 10, gen_loss = 0.8628760623608449, disc_loss = 0.06245815527904538
Trained batch 774 in epoch 10, gen_loss = 0.8628739253551729, disc_loss = 0.062408710864162255
Trained batch 775 in epoch 10, gen_loss = 0.862836530720143, disc_loss = 0.06241380676960803
Trained batch 776 in epoch 10, gen_loss = 0.8628757930093444, disc_loss = 0.06238521140924579
Trained batch 777 in epoch 10, gen_loss = 0.8626223183919348, disc_loss = 0.06242919141716374
Trained batch 778 in epoch 10, gen_loss = 0.8624860960727173, disc_loss = 0.06245409747207865
Trained batch 779 in epoch 10, gen_loss = 0.8624617460828561, disc_loss = 0.06240622558547423
Trained batch 780 in epoch 10, gen_loss = 0.8627132765385924, disc_loss = 0.0623547996170151
Trained batch 781 in epoch 10, gen_loss = 0.8627731684604873, disc_loss = 0.06234796165579173
Trained batch 782 in epoch 10, gen_loss = 0.8624508085150372, disc_loss = 0.062363794779388346
Trained batch 783 in epoch 10, gen_loss = 0.862359184277605, disc_loss = 0.06243427050696705
Trained batch 784 in epoch 10, gen_loss = 0.8623534459596987, disc_loss = 0.062390863453482936
Trained batch 785 in epoch 10, gen_loss = 0.8617969589833995, disc_loss = 0.06267359615279879
Trained batch 786 in epoch 10, gen_loss = 0.8624016363860085, disc_loss = 0.06304314961122039
Trained batch 787 in epoch 10, gen_loss = 0.8626518233627232, disc_loss = 0.06300641368864209
Trained batch 788 in epoch 10, gen_loss = 0.8623085753999282, disc_loss = 0.06312943274905983
Trained batch 789 in epoch 10, gen_loss = 0.8623609547373615, disc_loss = 0.06306575961187011
Testing Epoch 10
Training Epoch 11
Trained batch 0 in epoch 11, gen_loss = 0.9386551380157471, disc_loss = 0.02986243925988674
Trained batch 1 in epoch 11, gen_loss = 0.8731167018413544, disc_loss = 0.11124780308455229
Trained batch 2 in epoch 11, gen_loss = 0.7890132466952006, disc_loss = 0.11728908307850361
Trained batch 3 in epoch 11, gen_loss = 0.7754558175802231, disc_loss = 0.09826517151668668
Trained batch 4 in epoch 11, gen_loss = 0.7794152855873108, disc_loss = 0.09145640470087528
Trained batch 5 in epoch 11, gen_loss = 0.8293537398179373, disc_loss = 0.08972993524124225
Trained batch 6 in epoch 11, gen_loss = 0.8078573346138, disc_loss = 0.08759532682597637
Trained batch 7 in epoch 11, gen_loss = 0.8001615181565285, disc_loss = 0.08858028170652688
Trained batch 8 in epoch 11, gen_loss = 0.8474550180964999, disc_loss = 0.10485104823278056
Trained batch 9 in epoch 11, gen_loss = 0.8270448327064515, disc_loss = 0.10897070858627558
Trained batch 10 in epoch 11, gen_loss = 0.8225280154835094, disc_loss = 0.10269969786432656
Trained batch 11 in epoch 11, gen_loss = 0.8167944351832072, disc_loss = 0.1030425070784986
Trained batch 12 in epoch 11, gen_loss = 0.7986761469107407, disc_loss = 0.10458796600309703
Trained batch 13 in epoch 11, gen_loss = 0.8082776750837054, disc_loss = 0.09835177380591631
Trained batch 14 in epoch 11, gen_loss = 0.8009737253189086, disc_loss = 0.09507057604690393
Trained batch 15 in epoch 11, gen_loss = 0.8310942426323891, disc_loss = 0.09543944976758212
Trained batch 16 in epoch 11, gen_loss = 0.8329681648927576, disc_loss = 0.09155777918503565
Trained batch 17 in epoch 11, gen_loss = 0.8303201794624329, disc_loss = 0.09094917225754923
Trained batch 18 in epoch 11, gen_loss = 0.8226667266142996, disc_loss = 0.09323333703765743
Trained batch 19 in epoch 11, gen_loss = 0.8264866977930069, disc_loss = 0.09040234973654152
Trained batch 20 in epoch 11, gen_loss = 0.8253694063141233, disc_loss = 0.08782146791262287
Trained batch 21 in epoch 11, gen_loss = 0.8222152075984261, disc_loss = 0.08588862071999094
Trained batch 22 in epoch 11, gen_loss = 0.837243896463643, disc_loss = 0.08603074101974136
Trained batch 23 in epoch 11, gen_loss = 0.8378175422549248, disc_loss = 0.08303191458495955
Trained batch 24 in epoch 11, gen_loss = 0.841954710483551, disc_loss = 0.08046976901590824
Trained batch 25 in epoch 11, gen_loss = 0.8267017476833783, disc_loss = 0.08557084410522993
Trained batch 26 in epoch 11, gen_loss = 0.8325443146405397, disc_loss = 0.08482461401985751
Trained batch 27 in epoch 11, gen_loss = 0.8386647924780846, disc_loss = 0.08534092569191541
Trained batch 28 in epoch 11, gen_loss = 0.8516307462906015, disc_loss = 0.08875256423549406
Trained batch 29 in epoch 11, gen_loss = 0.8374909410874048, disc_loss = 0.09874302602062622
Trained batch 30 in epoch 11, gen_loss = 0.8323946085668379, disc_loss = 0.09781540022982706
Trained batch 31 in epoch 11, gen_loss = 0.8388907248154283, disc_loss = 0.0980882112053223
Trained batch 32 in epoch 11, gen_loss = 0.8303446002078779, disc_loss = 0.0994784523253188
Trained batch 33 in epoch 11, gen_loss = 0.832042388179723, disc_loss = 0.09732360201066032
Trained batch 34 in epoch 11, gen_loss = 0.8280809325831276, disc_loss = 0.096805821412376
Trained batch 35 in epoch 11, gen_loss = 0.8241161944137679, disc_loss = 0.09702081652358174
Trained batch 36 in epoch 11, gen_loss = 0.822816802843197, disc_loss = 0.09623979157894044
Trained batch 37 in epoch 11, gen_loss = 0.8337250940109554, disc_loss = 0.104123979855917
Trained batch 38 in epoch 11, gen_loss = 0.8311066176646795, disc_loss = 0.10257875255476205
Trained batch 39 in epoch 11, gen_loss = 0.8259998627007008, disc_loss = 0.10276889582164586
Trained batch 40 in epoch 11, gen_loss = 0.8264639762843528, disc_loss = 0.1009144341436828
Trained batch 41 in epoch 11, gen_loss = 0.824251033720516, disc_loss = 0.09995333894732453
Trained batch 42 in epoch 11, gen_loss = 0.8234460499397543, disc_loss = 0.09874828549665074
Trained batch 43 in epoch 11, gen_loss = 0.8234721212224527, disc_loss = 0.09734428123655645
Trained batch 44 in epoch 11, gen_loss = 0.8256661501195696, disc_loss = 0.09615188398294978
Trained batch 45 in epoch 11, gen_loss = 0.8181728526302006, disc_loss = 0.09960369854841543
Trained batch 46 in epoch 11, gen_loss = 0.82660344686914, disc_loss = 0.1022688847114431
Trained batch 47 in epoch 11, gen_loss = 0.8233796544373035, disc_loss = 0.1009182264873137
Trained batch 48 in epoch 11, gen_loss = 0.8233133177368008, disc_loss = 0.0996333511964399
Trained batch 49 in epoch 11, gen_loss = 0.8226832497119904, disc_loss = 0.09839014887809754
Trained batch 50 in epoch 11, gen_loss = 0.8290292503787022, disc_loss = 0.09979291640075982
Trained batch 51 in epoch 11, gen_loss = 0.8251555905892298, disc_loss = 0.0996852210507943
Trained batch 52 in epoch 11, gen_loss = 0.8248179971047167, disc_loss = 0.09836411869750833
Trained batch 53 in epoch 11, gen_loss = 0.8240950151726052, disc_loss = 0.09888425469398499
Trained batch 54 in epoch 11, gen_loss = 0.8222040544856678, disc_loss = 0.0979743284935301
Trained batch 55 in epoch 11, gen_loss = 0.817866678748812, disc_loss = 0.09820553627131241
Trained batch 56 in epoch 11, gen_loss = 0.8192157117944014, disc_loss = 0.09675810257332366
Trained batch 57 in epoch 11, gen_loss = 0.8244371948571041, disc_loss = 0.09543076668191573
Trained batch 58 in epoch 11, gen_loss = 0.8244401186199511, disc_loss = 0.09430593703636679
Trained batch 59 in epoch 11, gen_loss = 0.8248004823923111, disc_loss = 0.09295098558068275
Trained batch 60 in epoch 11, gen_loss = 0.8265551211404019, disc_loss = 0.092723405629885
Trained batch 61 in epoch 11, gen_loss = 0.8219160235697224, disc_loss = 0.09287518611358057
Trained batch 62 in epoch 11, gen_loss = 0.8200013874069093, disc_loss = 0.09310619757762031
Trained batch 63 in epoch 11, gen_loss = 0.8221459910273552, disc_loss = 0.09274947352241725
Trained batch 64 in epoch 11, gen_loss = 0.824106098138369, disc_loss = 0.09148769188099183
Trained batch 65 in epoch 11, gen_loss = 0.8243958543647419, disc_loss = 0.09039431631169988
Trained batch 66 in epoch 11, gen_loss = 0.8269599871848946, disc_loss = 0.08946231545519027
Trained batch 67 in epoch 11, gen_loss = 0.8281984969097025, disc_loss = 0.08832179849474307
Trained batch 68 in epoch 11, gen_loss = 0.8291388672331105, disc_loss = 0.08720322200299604
Trained batch 69 in epoch 11, gen_loss = 0.8279200187751226, disc_loss = 0.086339654866606
Trained batch 70 in epoch 11, gen_loss = 0.8304554030928814, disc_loss = 0.08551640261594258
Trained batch 71 in epoch 11, gen_loss = 0.8288848631911807, disc_loss = 0.08489458691070063
Trained batch 72 in epoch 11, gen_loss = 0.8283498711781959, disc_loss = 0.08439721767981984
Trained batch 73 in epoch 11, gen_loss = 0.8310642629056364, disc_loss = 0.08339612491781244
Trained batch 74 in epoch 11, gen_loss = 0.8297245756785074, disc_loss = 0.08320048832645019
Trained batch 75 in epoch 11, gen_loss = 0.8292779475450516, disc_loss = 0.08280339076085702
Trained batch 76 in epoch 11, gen_loss = 0.8338140396328716, disc_loss = 0.082119486197926
Trained batch 77 in epoch 11, gen_loss = 0.8326826485303732, disc_loss = 0.0817253579481099
Trained batch 78 in epoch 11, gen_loss = 0.834346981742714, disc_loss = 0.08088780358386567
Trained batch 79 in epoch 11, gen_loss = 0.8347797594964504, disc_loss = 0.08024138667387888
Trained batch 80 in epoch 11, gen_loss = 0.8360701343159617, disc_loss = 0.07954284892543967
Trained batch 81 in epoch 11, gen_loss = 0.836944811227845, disc_loss = 0.07874496464004241
Trained batch 82 in epoch 11, gen_loss = 0.8380041948284012, disc_loss = 0.07862195274960923
Trained batch 83 in epoch 11, gen_loss = 0.8353289138703119, disc_loss = 0.0800861252493979
Trained batch 84 in epoch 11, gen_loss = 0.8388428141089047, disc_loss = 0.07998751604600865
Trained batch 85 in epoch 11, gen_loss = 0.8386214625003726, disc_loss = 0.07972771484881293
Trained batch 86 in epoch 11, gen_loss = 0.8414104574028103, disc_loss = 0.07952158214074784
Trained batch 87 in epoch 11, gen_loss = 0.8399006419561126, disc_loss = 0.07971346269319342
Trained batch 88 in epoch 11, gen_loss = 0.8365652273210247, disc_loss = 0.07988719919466236
Trained batch 89 in epoch 11, gen_loss = 0.8431037061744266, disc_loss = 0.08249695227584905
Trained batch 90 in epoch 11, gen_loss = 0.8438318581371517, disc_loss = 0.08176547453667109
Trained batch 91 in epoch 11, gen_loss = 0.843914168684379, disc_loss = 0.08122739326411291
Trained batch 92 in epoch 11, gen_loss = 0.8440253651270302, disc_loss = 0.08050511341782347
Trained batch 93 in epoch 11, gen_loss = 0.8444429921342972, disc_loss = 0.07993514377108597
Trained batch 94 in epoch 11, gen_loss = 0.8441417079222829, disc_loss = 0.07934970127320604
Trained batch 95 in epoch 11, gen_loss = 0.8454319847126802, disc_loss = 0.07881692177033983
Trained batch 96 in epoch 11, gen_loss = 0.8461858243057409, disc_loss = 0.0781228087900072
Trained batch 97 in epoch 11, gen_loss = 0.8489499457028448, disc_loss = 0.07747699108392912
Trained batch 98 in epoch 11, gen_loss = 0.8497745304396658, disc_loss = 0.0767573132508933
Trained batch 99 in epoch 11, gen_loss = 0.8485013771057129, disc_loss = 0.07632812909781933
Trained batch 100 in epoch 11, gen_loss = 0.8483591988535211, disc_loss = 0.07610579192785934
Trained batch 101 in epoch 11, gen_loss = 0.8483031953082365, disc_loss = 0.0761064752278959
Trained batch 102 in epoch 11, gen_loss = 0.8493117979429301, disc_loss = 0.07554265983330394
Trained batch 103 in epoch 11, gen_loss = 0.8464479652734903, disc_loss = 0.0760927635531586
Trained batch 104 in epoch 11, gen_loss = 0.8497156097775413, disc_loss = 0.0759990288742951
Trained batch 105 in epoch 11, gen_loss = 0.8481064973012457, disc_loss = 0.07616691133183129
Trained batch 106 in epoch 11, gen_loss = 0.8493663607356704, disc_loss = 0.07568100570030858
Trained batch 107 in epoch 11, gen_loss = 0.8497168167873665, disc_loss = 0.07545847506089895
Trained batch 108 in epoch 11, gen_loss = 0.8500274321354857, disc_loss = 0.075053410809658
Trained batch 109 in epoch 11, gen_loss = 0.8484429825435985, disc_loss = 0.0750703448091041
Trained batch 110 in epoch 11, gen_loss = 0.8510226290505212, disc_loss = 0.07559288724384329
Trained batch 111 in epoch 11, gen_loss = 0.8491619937121868, disc_loss = 0.07579590694513172
Trained batch 112 in epoch 11, gen_loss = 0.8487543474256465, disc_loss = 0.075395606342802
Trained batch 113 in epoch 11, gen_loss = 0.8513568895950652, disc_loss = 0.07508984755463245
Trained batch 114 in epoch 11, gen_loss = 0.8499970638233683, disc_loss = 0.07509756507756918
Trained batch 115 in epoch 11, gen_loss = 0.849487137691728, disc_loss = 0.0748672903322711
Trained batch 116 in epoch 11, gen_loss = 0.8515930731072385, disc_loss = 0.07454806758870935
Trained batch 117 in epoch 11, gen_loss = 0.8520695152929274, disc_loss = 0.07418726739805129
Trained batch 118 in epoch 11, gen_loss = 0.853606142917601, disc_loss = 0.07373339294635949
Trained batch 119 in epoch 11, gen_loss = 0.855887284874916, disc_loss = 0.0734871116777261
Trained batch 120 in epoch 11, gen_loss = 0.8538265464719662, disc_loss = 0.07413747389454486
Trained batch 121 in epoch 11, gen_loss = 0.8534620194161524, disc_loss = 0.07370576372400658
Trained batch 122 in epoch 11, gen_loss = 0.8545461927003007, disc_loss = 0.07380314141027326
Trained batch 123 in epoch 11, gen_loss = 0.8559889625157079, disc_loss = 0.07370293488906275
Trained batch 124 in epoch 11, gen_loss = 0.8548944087028504, disc_loss = 0.07356348782777786
Trained batch 125 in epoch 11, gen_loss = 0.853330878038255, disc_loss = 0.07371647354392778
Trained batch 126 in epoch 11, gen_loss = 0.8539262775361068, disc_loss = 0.07323546560965186
Trained batch 127 in epoch 11, gen_loss = 0.8555534519255161, disc_loss = 0.07286425870552193
Trained batch 128 in epoch 11, gen_loss = 0.8555401291034018, disc_loss = 0.07295035425024901
Trained batch 129 in epoch 11, gen_loss = 0.853175446161857, disc_loss = 0.0736730445892765
Trained batch 130 in epoch 11, gen_loss = 0.853587894494297, disc_loss = 0.07321109068899892
Trained batch 131 in epoch 11, gen_loss = 0.85402481935241, disc_loss = 0.0729356047796142
Trained batch 132 in epoch 11, gen_loss = 0.8540314220844355, disc_loss = 0.07300568498755083
Trained batch 133 in epoch 11, gen_loss = 0.8538950036710767, disc_loss = 0.07282698741738698
Trained batch 134 in epoch 11, gen_loss = 0.8511213293781987, disc_loss = 0.07340931150786302
Trained batch 135 in epoch 11, gen_loss = 0.853155650636729, disc_loss = 0.0730015156475608
Trained batch 136 in epoch 11, gen_loss = 0.853640022939139, disc_loss = 0.072644368908538
Trained batch 137 in epoch 11, gen_loss = 0.851546021907226, disc_loss = 0.07272087081429968
Trained batch 138 in epoch 11, gen_loss = 0.8543897888643278, disc_loss = 0.07347169283295063
Trained batch 139 in epoch 11, gen_loss = 0.8540104512657438, disc_loss = 0.07334002693449812
Trained batch 140 in epoch 11, gen_loss = 0.8540887016776606, disc_loss = 0.07310629124152111
Trained batch 141 in epoch 11, gen_loss = 0.8542179469491394, disc_loss = 0.07274836976684525
Trained batch 142 in epoch 11, gen_loss = 0.8544355830946169, disc_loss = 0.0729322282180607
Trained batch 143 in epoch 11, gen_loss = 0.8534828747312228, disc_loss = 0.07284519514198312
Trained batch 144 in epoch 11, gen_loss = 0.8527094331280939, disc_loss = 0.07264287634270972
Trained batch 145 in epoch 11, gen_loss = 0.853111061331344, disc_loss = 0.07245899130245798
Trained batch 146 in epoch 11, gen_loss = 0.854079743631843, disc_loss = 0.07283838311856498
Trained batch 147 in epoch 11, gen_loss = 0.8523444009793771, disc_loss = 0.07293509018003337
Trained batch 148 in epoch 11, gen_loss = 0.8524362368871702, disc_loss = 0.0726117829310914
Trained batch 149 in epoch 11, gen_loss = 0.8514273794492085, disc_loss = 0.0724730299723645
Trained batch 150 in epoch 11, gen_loss = 0.8517150523646778, disc_loss = 0.07248747623248013
Trained batch 151 in epoch 11, gen_loss = 0.8522147959784457, disc_loss = 0.07215667204122599
Trained batch 152 in epoch 11, gen_loss = 0.8489510360496496, disc_loss = 0.07380219789380146
Trained batch 153 in epoch 11, gen_loss = 0.8490958343465607, disc_loss = 0.07395867090793205
Trained batch 154 in epoch 11, gen_loss = 0.8478025788261044, disc_loss = 0.07468461564351474
Trained batch 155 in epoch 11, gen_loss = 0.8466825330486665, disc_loss = 0.07479078214591703
Trained batch 156 in epoch 11, gen_loss = 0.8469499750122144, disc_loss = 0.07445568218234049
Trained batch 157 in epoch 11, gen_loss = 0.846730429726311, disc_loss = 0.07416675302871986
Trained batch 158 in epoch 11, gen_loss = 0.8476689542239567, disc_loss = 0.07382506665732688
Trained batch 159 in epoch 11, gen_loss = 0.84684186745435, disc_loss = 0.07389325666590593
Trained batch 160 in epoch 11, gen_loss = 0.8487260972861177, disc_loss = 0.07495721692786268
Trained batch 161 in epoch 11, gen_loss = 0.8478409892614976, disc_loss = 0.07477814446053939
Trained batch 162 in epoch 11, gen_loss = 0.8470305337862003, disc_loss = 0.07443419274262672
Trained batch 163 in epoch 11, gen_loss = 0.8462189030719967, disc_loss = 0.0741728008781537
Trained batch 164 in epoch 11, gen_loss = 0.8468466753309424, disc_loss = 0.07432709030919905
Trained batch 165 in epoch 11, gen_loss = 0.8454915495162987, disc_loss = 0.07452353428353567
Trained batch 166 in epoch 11, gen_loss = 0.8453473450537927, disc_loss = 0.07475526132871826
Trained batch 167 in epoch 11, gen_loss = 0.8446738271131402, disc_loss = 0.07483551085239187
Trained batch 168 in epoch 11, gen_loss = 0.8450841245919289, disc_loss = 0.07536940516341896
Trained batch 169 in epoch 11, gen_loss = 0.8453833234660766, disc_loss = 0.0751017303315594
Trained batch 170 in epoch 11, gen_loss = 0.8447134914802529, disc_loss = 0.07496782054046267
Trained batch 171 in epoch 11, gen_loss = 0.8444179755657218, disc_loss = 0.07470492629312672
Trained batch 172 in epoch 11, gen_loss = 0.8444432838459235, disc_loss = 0.07451108524931131
Trained batch 173 in epoch 11, gen_loss = 0.8458459656471493, disc_loss = 0.07431276243758099
Trained batch 174 in epoch 11, gen_loss = 0.8442015400954656, disc_loss = 0.07457376870193652
Trained batch 175 in epoch 11, gen_loss = 0.8454975409602578, disc_loss = 0.07438685952960937
Trained batch 176 in epoch 11, gen_loss = 0.8456453723085802, disc_loss = 0.07523240852511703
Trained batch 177 in epoch 11, gen_loss = 0.8441781567388706, disc_loss = 0.076274931477906
Trained batch 178 in epoch 11, gen_loss = 0.8438823394602237, disc_loss = 0.07601764372045268
Trained batch 179 in epoch 11, gen_loss = 0.8447973541087574, disc_loss = 0.07631286182440818
Trained batch 180 in epoch 11, gen_loss = 0.8442637582839523, disc_loss = 0.07630002900484682
Trained batch 181 in epoch 11, gen_loss = 0.8431372614679756, disc_loss = 0.07651788359098546
Trained batch 182 in epoch 11, gen_loss = 0.8428491147163787, disc_loss = 0.07670354707258158
Trained batch 183 in epoch 11, gen_loss = 0.8450965325793495, disc_loss = 0.07699143897195387
Trained batch 184 in epoch 11, gen_loss = 0.8436295562499279, disc_loss = 0.077439194379022
Trained batch 185 in epoch 11, gen_loss = 0.8420953457393954, disc_loss = 0.07753303481305959
Trained batch 186 in epoch 11, gen_loss = 0.8438882950474235, disc_loss = 0.07800684441478654
Trained batch 187 in epoch 11, gen_loss = 0.8460021369317745, disc_loss = 0.07832365937313025
Trained batch 188 in epoch 11, gen_loss = 0.8449274107577309, disc_loss = 0.0783216920410278
Trained batch 189 in epoch 11, gen_loss = 0.8430496851080342, disc_loss = 0.0788573334336673
Trained batch 190 in epoch 11, gen_loss = 0.8414386153533197, disc_loss = 0.07939526714209019
Trained batch 191 in epoch 11, gen_loss = 0.8433690864282349, disc_loss = 0.07958349684971229
Trained batch 192 in epoch 11, gen_loss = 0.8436407479288665, disc_loss = 0.07941029630504896
Trained batch 193 in epoch 11, gen_loss = 0.8421349889531577, disc_loss = 0.07987065763529583
Trained batch 194 in epoch 11, gen_loss = 0.8433903995232704, disc_loss = 0.07972320863165153
Trained batch 195 in epoch 11, gen_loss = 0.8440657423771157, disc_loss = 0.08076032337124403
Trained batch 196 in epoch 11, gen_loss = 0.8442670447269672, disc_loss = 0.08051124122939285
Trained batch 197 in epoch 11, gen_loss = 0.8424147415642786, disc_loss = 0.08065190544878745
Trained batch 198 in epoch 11, gen_loss = 0.8431529983803255, disc_loss = 0.0805118190143351
Trained batch 199 in epoch 11, gen_loss = 0.8429152980446816, disc_loss = 0.0803901017876342
Trained batch 200 in epoch 11, gen_loss = 0.8415676100337091, disc_loss = 0.08062559918996262
Trained batch 201 in epoch 11, gen_loss = 0.8414808859919557, disc_loss = 0.08122250316480156
Trained batch 202 in epoch 11, gen_loss = 0.8408068201224792, disc_loss = 0.08109588556340322
Trained batch 203 in epoch 11, gen_loss = 0.8403741620919284, disc_loss = 0.08089738224596515
Trained batch 204 in epoch 11, gen_loss = 0.8394432617396843, disc_loss = 0.08084771217460313
Trained batch 205 in epoch 11, gen_loss = 0.8396672143519504, disc_loss = 0.08063702276699895
Trained batch 206 in epoch 11, gen_loss = 0.8399028069731118, disc_loss = 0.08062672322157069
Trained batch 207 in epoch 11, gen_loss = 0.8388049017924529, disc_loss = 0.08088581402374145
Trained batch 208 in epoch 11, gen_loss = 0.8404357319243216, disc_loss = 0.08111400462455298
Trained batch 209 in epoch 11, gen_loss = 0.8400646039417812, disc_loss = 0.08110063972306393
Trained batch 210 in epoch 11, gen_loss = 0.8394807204251041, disc_loss = 0.08115470432786721
Trained batch 211 in epoch 11, gen_loss = 0.8397632772630116, disc_loss = 0.08088843713795661
Trained batch 212 in epoch 11, gen_loss = 0.8396003067213604, disc_loss = 0.0809769547137786
Trained batch 213 in epoch 11, gen_loss = 0.8385706126132858, disc_loss = 0.08091063863188724
Trained batch 214 in epoch 11, gen_loss = 0.8380304780117301, disc_loss = 0.08112822392912106
Trained batch 215 in epoch 11, gen_loss = 0.8394123371000644, disc_loss = 0.0814048650941846
Trained batch 216 in epoch 11, gen_loss = 0.8396079894584445, disc_loss = 0.08115969922324892
Trained batch 217 in epoch 11, gen_loss = 0.8401273885451326, disc_loss = 0.08096443630601151
Trained batch 218 in epoch 11, gen_loss = 0.8386170570164511, disc_loss = 0.08162907243506413
Trained batch 219 in epoch 11, gen_loss = 0.8384349679405039, disc_loss = 0.08146141697652638
Trained batch 220 in epoch 11, gen_loss = 0.8403427166636713, disc_loss = 0.08237938870722217
Trained batch 221 in epoch 11, gen_loss = 0.8404738690939035, disc_loss = 0.0822239145762413
Trained batch 222 in epoch 11, gen_loss = 0.8398859086592636, disc_loss = 0.08220353022201045
Trained batch 223 in epoch 11, gen_loss = 0.8392439136015517, disc_loss = 0.08215659033157863
Trained batch 224 in epoch 11, gen_loss = 0.8403845461209615, disc_loss = 0.08269563537091017
Trained batch 225 in epoch 11, gen_loss = 0.8391925547502738, disc_loss = 0.08282532946379707
Trained batch 226 in epoch 11, gen_loss = 0.8393247531899272, disc_loss = 0.08281602330981766
Trained batch 227 in epoch 11, gen_loss = 0.839162215590477, disc_loss = 0.08290487623838871
Trained batch 228 in epoch 11, gen_loss = 0.8387644059272833, disc_loss = 0.08275466491610593
Trained batch 229 in epoch 11, gen_loss = 0.8397672349992006, disc_loss = 0.08251441202490874
Trained batch 230 in epoch 11, gen_loss = 0.8399437072473172, disc_loss = 0.08274075205466061
Trained batch 231 in epoch 11, gen_loss = 0.8394507272490139, disc_loss = 0.08293683258896886
Trained batch 232 in epoch 11, gen_loss = 0.8385929726224088, disc_loss = 0.08278700828056607
Trained batch 233 in epoch 11, gen_loss = 0.839179852579394, disc_loss = 0.08249880847497246
Trained batch 234 in epoch 11, gen_loss = 0.8398066383727053, disc_loss = 0.08219181870288671
Trained batch 235 in epoch 11, gen_loss = 0.8409622730845112, disc_loss = 0.08217713710757256
Trained batch 236 in epoch 11, gen_loss = 0.8407892758333231, disc_loss = 0.08196886982925959
Trained batch 237 in epoch 11, gen_loss = 0.8413012120403162, disc_loss = 0.0817260597832501
Trained batch 238 in epoch 11, gen_loss = 0.841382210474134, disc_loss = 0.0815143801201774
Trained batch 239 in epoch 11, gen_loss = 0.8413136405249436, disc_loss = 0.08128948321488376
Trained batch 240 in epoch 11, gen_loss = 0.8415148767692914, disc_loss = 0.08101211650938538
Trained batch 241 in epoch 11, gen_loss = 0.8411780090864039, disc_loss = 0.08101731112750232
Trained batch 242 in epoch 11, gen_loss = 0.8414920794129862, disc_loss = 0.08073014439823328
Trained batch 243 in epoch 11, gen_loss = 0.842479373099374, disc_loss = 0.08044044857798907
Trained batch 244 in epoch 11, gen_loss = 0.8415023141977739, disc_loss = 0.08068003388007684
Trained batch 245 in epoch 11, gen_loss = 0.8425851202592617, disc_loss = 0.08082712018801792
Trained batch 246 in epoch 11, gen_loss = 0.8421393432597882, disc_loss = 0.08068182334107787
Trained batch 247 in epoch 11, gen_loss = 0.8427389290544295, disc_loss = 0.08045418319037004
Trained batch 248 in epoch 11, gen_loss = 0.8429874897481926, disc_loss = 0.08041813106736145
Trained batch 249 in epoch 11, gen_loss = 0.842154596567154, disc_loss = 0.08057422630861402
Trained batch 250 in epoch 11, gen_loss = 0.8418550332228976, disc_loss = 0.08050989052763143
Trained batch 251 in epoch 11, gen_loss = 0.8418081466640744, disc_loss = 0.08048529241840163
Trained batch 252 in epoch 11, gen_loss = 0.8427808084506763, disc_loss = 0.08022920410756183
Trained batch 253 in epoch 11, gen_loss = 0.8422185236544121, disc_loss = 0.08004519494807744
Trained batch 254 in epoch 11, gen_loss = 0.8425862810190986, disc_loss = 0.07982872168296108
Trained batch 255 in epoch 11, gen_loss = 0.8419892394449562, disc_loss = 0.07972643658649758
Trained batch 256 in epoch 11, gen_loss = 0.8429392008002167, disc_loss = 0.08032730888894211
Trained batch 257 in epoch 11, gen_loss = 0.8429977170718733, disc_loss = 0.08027526251466353
Trained batch 258 in epoch 11, gen_loss = 0.8423184846819137, disc_loss = 0.08014796979538377
Trained batch 259 in epoch 11, gen_loss = 0.8414482978674082, disc_loss = 0.08029778645947003
Trained batch 260 in epoch 11, gen_loss = 0.842122553408831, disc_loss = 0.08015425436526993
Trained batch 261 in epoch 11, gen_loss = 0.8429909252938423, disc_loss = 0.07997034588572748
Trained batch 262 in epoch 11, gen_loss = 0.8433236776649272, disc_loss = 0.0797200935853808
Trained batch 263 in epoch 11, gen_loss = 0.8436164679852399, disc_loss = 0.07949378780639646
Trained batch 264 in epoch 11, gen_loss = 0.8429425203575278, disc_loss = 0.07931571582086244
Trained batch 265 in epoch 11, gen_loss = 0.8428790768734494, disc_loss = 0.0791007456285669
Trained batch 266 in epoch 11, gen_loss = 0.8420686987455418, disc_loss = 0.07900680903317442
Trained batch 267 in epoch 11, gen_loss = 0.8429577788755075, disc_loss = 0.07878457151228256
Trained batch 268 in epoch 11, gen_loss = 0.8426636304553999, disc_loss = 0.07877557547105178
Trained batch 269 in epoch 11, gen_loss = 0.8421844603838744, disc_loss = 0.07861413604890306
Trained batch 270 in epoch 11, gen_loss = 0.8430207327723063, disc_loss = 0.07842474086794356
Trained batch 271 in epoch 11, gen_loss = 0.8432346702936817, disc_loss = 0.07883543942657792
Trained batch 272 in epoch 11, gen_loss = 0.8428340126306583, disc_loss = 0.07871381272203647
Trained batch 273 in epoch 11, gen_loss = 0.8417089986105035, disc_loss = 0.07898603482715731
Trained batch 274 in epoch 11, gen_loss = 0.8418802053278143, disc_loss = 0.07883767975663597
Trained batch 275 in epoch 11, gen_loss = 0.8420667112737462, disc_loss = 0.07864905062023604
Trained batch 276 in epoch 11, gen_loss = 0.8419461779646065, disc_loss = 0.07857582573896603
Trained batch 277 in epoch 11, gen_loss = 0.8411057831572114, disc_loss = 0.07864141344635499
Trained batch 278 in epoch 11, gen_loss = 0.84198257572762, disc_loss = 0.07859217053392775
Trained batch 279 in epoch 11, gen_loss = 0.8428079817976271, disc_loss = 0.07836097558028995
Trained batch 280 in epoch 11, gen_loss = 0.8420667230446568, disc_loss = 0.07844217004274347
Trained batch 281 in epoch 11, gen_loss = 0.8428335508978959, disc_loss = 0.07854312824098565
Trained batch 282 in epoch 11, gen_loss = 0.8421673880027798, disc_loss = 0.0786054267781678
Trained batch 283 in epoch 11, gen_loss = 0.8424437742837718, disc_loss = 0.07842937725084559
Trained batch 284 in epoch 11, gen_loss = 0.8423921739845945, disc_loss = 0.07821258616944154
Trained batch 285 in epoch 11, gen_loss = 0.8424605081131408, disc_loss = 0.07804723461060882
Trained batch 286 in epoch 11, gen_loss = 0.8424246358954532, disc_loss = 0.07781226884002573
Trained batch 287 in epoch 11, gen_loss = 0.8430178266846471, disc_loss = 0.07758447668553951
Trained batch 288 in epoch 11, gen_loss = 0.8431517820044785, disc_loss = 0.07735964416439249
Trained batch 289 in epoch 11, gen_loss = 0.8433036711709253, disc_loss = 0.07713252165643819
Trained batch 290 in epoch 11, gen_loss = 0.8428793977626001, disc_loss = 0.0772689588694382
Trained batch 291 in epoch 11, gen_loss = 0.8424401626194993, disc_loss = 0.0771734520556941
Trained batch 292 in epoch 11, gen_loss = 0.8429360206623533, disc_loss = 0.07709357355730831
Trained batch 293 in epoch 11, gen_loss = 0.8435628126267674, disc_loss = 0.0769087797265221
Trained batch 294 in epoch 11, gen_loss = 0.8431372923366094, disc_loss = 0.0768598941644117
Trained batch 295 in epoch 11, gen_loss = 0.8421428491537636, disc_loss = 0.07693317776382272
Trained batch 296 in epoch 11, gen_loss = 0.8415352047894539, disc_loss = 0.07688716482621953
Trained batch 297 in epoch 11, gen_loss = 0.8423622276558972, disc_loss = 0.07666464472789593
Trained batch 298 in epoch 11, gen_loss = 0.8413629567742746, disc_loss = 0.07692727299849425
Trained batch 299 in epoch 11, gen_loss = 0.8430801697572072, disc_loss = 0.07701831803036233
Trained batch 300 in epoch 11, gen_loss = 0.8440732809396281, disc_loss = 0.07731563278916369
Trained batch 301 in epoch 11, gen_loss = 0.843343351060981, disc_loss = 0.07730763030873723
Trained batch 302 in epoch 11, gen_loss = 0.8422512547804577, disc_loss = 0.07814859011496353
Trained batch 303 in epoch 11, gen_loss = 0.842665911112961, disc_loss = 0.07808360054562065
Trained batch 304 in epoch 11, gen_loss = 0.843106505519054, disc_loss = 0.0783728958550291
Trained batch 305 in epoch 11, gen_loss = 0.8427527500133888, disc_loss = 0.0783069122345278
Trained batch 306 in epoch 11, gen_loss = 0.8422053431066706, disc_loss = 0.0783539848123049
Trained batch 307 in epoch 11, gen_loss = 0.8421098258975265, disc_loss = 0.07815830850695538
Trained batch 308 in epoch 11, gen_loss = 0.841801951425361, disc_loss = 0.07798614156128036
Trained batch 309 in epoch 11, gen_loss = 0.8410165934793411, disc_loss = 0.07803131700944035
Trained batch 310 in epoch 11, gen_loss = 0.8410323116557008, disc_loss = 0.07783581800100026
Trained batch 311 in epoch 11, gen_loss = 0.8419125888210076, disc_loss = 0.07793185415450865
Trained batch 312 in epoch 11, gen_loss = 0.8418217046192279, disc_loss = 0.07774793240911188
Trained batch 313 in epoch 11, gen_loss = 0.8414940547411609, disc_loss = 0.07762455907917232
Trained batch 314 in epoch 11, gen_loss = 0.840970403996725, disc_loss = 0.07757982163143064
Trained batch 315 in epoch 11, gen_loss = 0.8415032227205325, disc_loss = 0.07744286026322295
Trained batch 316 in epoch 11, gen_loss = 0.8404545780236037, disc_loss = 0.07773756135654657
Trained batch 317 in epoch 11, gen_loss = 0.8394741607162187, disc_loss = 0.07775795395023324
Trained batch 318 in epoch 11, gen_loss = 0.8382740186112801, disc_loss = 0.07809140312202205
Trained batch 319 in epoch 11, gen_loss = 0.839378806296736, disc_loss = 0.07828339492843953
Trained batch 320 in epoch 11, gen_loss = 0.8404250242442728, disc_loss = 0.07816191656787726
Trained batch 321 in epoch 11, gen_loss = 0.8400252327230406, disc_loss = 0.078331915797631
Trained batch 322 in epoch 11, gen_loss = 0.8391550723059628, disc_loss = 0.0786492063205447
Trained batch 323 in epoch 11, gen_loss = 0.8388071673703782, disc_loss = 0.07848987960325624
Trained batch 324 in epoch 11, gen_loss = 0.8386330310197977, disc_loss = 0.07833322967760838
Trained batch 325 in epoch 11, gen_loss = 0.8390415507408738, disc_loss = 0.0782417494695108
Trained batch 326 in epoch 11, gen_loss = 0.8387542418930509, disc_loss = 0.07807012321854677
Trained batch 327 in epoch 11, gen_loss = 0.838766475003667, disc_loss = 0.07795710350875175
Trained batch 328 in epoch 11, gen_loss = 0.8382492493894688, disc_loss = 0.0778674998980208
Trained batch 329 in epoch 11, gen_loss = 0.8381521957390237, disc_loss = 0.07767013611667084
Trained batch 330 in epoch 11, gen_loss = 0.8381655292748684, disc_loss = 0.07751373291083152
Trained batch 331 in epoch 11, gen_loss = 0.8389252518494446, disc_loss = 0.0776091550297317
Trained batch 332 in epoch 11, gen_loss = 0.8390475691438796, disc_loss = 0.07743056255529772
Trained batch 333 in epoch 11, gen_loss = 0.8382508293418827, disc_loss = 0.07746496232795323
Trained batch 334 in epoch 11, gen_loss = 0.8385663245151292, disc_loss = 0.0772984223134482
Trained batch 335 in epoch 11, gen_loss = 0.8390242623253947, disc_loss = 0.07713090018591001
Trained batch 336 in epoch 11, gen_loss = 0.8388685156931156, disc_loss = 0.07702824717680495
Trained batch 337 in epoch 11, gen_loss = 0.839269187411613, disc_loss = 0.07689847109409478
Trained batch 338 in epoch 11, gen_loss = 0.8403080829301063, disc_loss = 0.07678346208414849
Trained batch 339 in epoch 11, gen_loss = 0.8398906454443932, disc_loss = 0.07685219413217376
Trained batch 340 in epoch 11, gen_loss = 0.8397711262849769, disc_loss = 0.07679256204723263
Trained batch 341 in epoch 11, gen_loss = 0.8399491279620176, disc_loss = 0.07698417905914157
Trained batch 342 in epoch 11, gen_loss = 0.8401733655102399, disc_loss = 0.07686152629575993
Trained batch 343 in epoch 11, gen_loss = 0.839829744381267, disc_loss = 0.07682642716437925
Trained batch 344 in epoch 11, gen_loss = 0.8396789826344753, disc_loss = 0.07680997283778329
Trained batch 345 in epoch 11, gen_loss = 0.83910978538108, disc_loss = 0.07689122227962651
Trained batch 346 in epoch 11, gen_loss = 0.8403742194003949, disc_loss = 0.07680996517068371
Trained batch 347 in epoch 11, gen_loss = 0.8410675759459364, disc_loss = 0.07676301304593511
Trained batch 348 in epoch 11, gen_loss = 0.840467381699379, disc_loss = 0.07675123632082283
Trained batch 349 in epoch 11, gen_loss = 0.8402955793482917, disc_loss = 0.07663262017071247
Trained batch 350 in epoch 11, gen_loss = 0.8410837455862268, disc_loss = 0.07665119958017287
Trained batch 351 in epoch 11, gen_loss = 0.8411393940279429, disc_loss = 0.07649241733385927
Trained batch 352 in epoch 11, gen_loss = 0.8413158656010884, disc_loss = 0.07637264360555002
Trained batch 353 in epoch 11, gen_loss = 0.8412188617354732, disc_loss = 0.07624464805137976
Trained batch 354 in epoch 11, gen_loss = 0.8419115710426385, disc_loss = 0.07615648998131215
Trained batch 355 in epoch 11, gen_loss = 0.8424576633934224, disc_loss = 0.0759789305712944
Trained batch 356 in epoch 11, gen_loss = 0.8435073248645505, disc_loss = 0.07586070489534895
Trained batch 357 in epoch 11, gen_loss = 0.8430766925298968, disc_loss = 0.07577677404341501
Trained batch 358 in epoch 11, gen_loss = 0.8427383639852316, disc_loss = 0.0756086676607225
Trained batch 359 in epoch 11, gen_loss = 0.8425778346757095, disc_loss = 0.07559377250985967
Trained batch 360 in epoch 11, gen_loss = 0.843052420011848, disc_loss = 0.07560227704015135
Trained batch 361 in epoch 11, gen_loss = 0.8433996927178367, disc_loss = 0.07572838711392814
Trained batch 362 in epoch 11, gen_loss = 0.8428273275699826, disc_loss = 0.07582412871529577
Trained batch 363 in epoch 11, gen_loss = 0.8426560154491729, disc_loss = 0.075652660126542
Trained batch 364 in epoch 11, gen_loss = 0.8433122841462697, disc_loss = 0.0754818463009106
Trained batch 365 in epoch 11, gen_loss = 0.8432218677522055, disc_loss = 0.07538136294813919
Trained batch 366 in epoch 11, gen_loss = 0.8428220426516572, disc_loss = 0.07531045910671394
Trained batch 367 in epoch 11, gen_loss = 0.8429433710711158, disc_loss = 0.07523999617779223
Trained batch 368 in epoch 11, gen_loss = 0.8439006677003411, disc_loss = 0.0753959110789102
Trained batch 369 in epoch 11, gen_loss = 0.8440013037340061, disc_loss = 0.07525220356277518
Trained batch 370 in epoch 11, gen_loss = 0.8429710335647963, disc_loss = 0.07569267755409456
Trained batch 371 in epoch 11, gen_loss = 0.8435277462165843, disc_loss = 0.0756774023375524
Trained batch 372 in epoch 11, gen_loss = 0.843329790370394, disc_loss = 0.07558585218985343
Trained batch 373 in epoch 11, gen_loss = 0.8437714671546762, disc_loss = 0.07564712241092786
Trained batch 374 in epoch 11, gen_loss = 0.8436763266722361, disc_loss = 0.07557230434815089
Trained batch 375 in epoch 11, gen_loss = 0.8434690543787277, disc_loss = 0.0755544772490542
Trained batch 376 in epoch 11, gen_loss = 0.8444711452928083, disc_loss = 0.0756096137534402
Trained batch 377 in epoch 11, gen_loss = 0.8440399954400996, disc_loss = 0.07567794887082917
Trained batch 378 in epoch 11, gen_loss = 0.8435728096238542, disc_loss = 0.07569697695860447
Trained batch 379 in epoch 11, gen_loss = 0.8439660733467654, disc_loss = 0.07554605988001353
Trained batch 380 in epoch 11, gen_loss = 0.8444437316552861, disc_loss = 0.07606641279919724
Trained batch 381 in epoch 11, gen_loss = 0.8439992553120508, disc_loss = 0.0760219351227605
Trained batch 382 in epoch 11, gen_loss = 0.843317624405221, disc_loss = 0.07635529484726275
Trained batch 383 in epoch 11, gen_loss = 0.8440361872781068, disc_loss = 0.07630012581648771
Trained batch 384 in epoch 11, gen_loss = 0.8443424882052781, disc_loss = 0.0763301146640019
Trained batch 385 in epoch 11, gen_loss = 0.8441973754006964, disc_loss = 0.07619491695315418
Trained batch 386 in epoch 11, gen_loss = 0.8443847696756516, disc_loss = 0.07603774044316175
Trained batch 387 in epoch 11, gen_loss = 0.8444825085936133, disc_loss = 0.07588701065120854
Trained batch 388 in epoch 11, gen_loss = 0.8446957785396773, disc_loss = 0.07571465254145983
Trained batch 389 in epoch 11, gen_loss = 0.8443969065562272, disc_loss = 0.07562398230656982
Trained batch 390 in epoch 11, gen_loss = 0.8447834182425839, disc_loss = 0.07558052381143317
Trained batch 391 in epoch 11, gen_loss = 0.8443502224981785, disc_loss = 0.07562939266018494
Trained batch 392 in epoch 11, gen_loss = 0.8441225979619353, disc_loss = 0.07550686585264275
Trained batch 393 in epoch 11, gen_loss = 0.8449941187491877, disc_loss = 0.0753984064085948
Trained batch 394 in epoch 11, gen_loss = 0.845442509726633, disc_loss = 0.07527613722589574
Trained batch 395 in epoch 11, gen_loss = 0.8450181954587349, disc_loss = 0.07524523003299655
Trained batch 396 in epoch 11, gen_loss = 0.8451602165434763, disc_loss = 0.0751164475765539
Trained batch 397 in epoch 11, gen_loss = 0.8454366439401205, disc_loss = 0.07500022205865788
Trained batch 398 in epoch 11, gen_loss = 0.8455515316405093, disc_loss = 0.07486286855309754
Trained batch 399 in epoch 11, gen_loss = 0.8449001645296812, disc_loss = 0.07489686998305842
Trained batch 400 in epoch 11, gen_loss = 0.8445436956727891, disc_loss = 0.07487924713548505
Trained batch 401 in epoch 11, gen_loss = 0.8446601767889896, disc_loss = 0.07486537296037694
Trained batch 402 in epoch 11, gen_loss = 0.843499628545037, disc_loss = 0.07567274848475276
Trained batch 403 in epoch 11, gen_loss = 0.8441012844000713, disc_loss = 0.07556783674183384
Trained batch 404 in epoch 11, gen_loss = 0.8450424933139189, disc_loss = 0.07560382583581003
Trained batch 405 in epoch 11, gen_loss = 0.8456554081052395, disc_loss = 0.0754528107428969
Trained batch 406 in epoch 11, gen_loss = 0.8451348856567458, disc_loss = 0.07549554670883997
Trained batch 407 in epoch 11, gen_loss = 0.844945610007819, disc_loss = 0.07540796690976576
Trained batch 408 in epoch 11, gen_loss = 0.8451161610468093, disc_loss = 0.0753116060371686
Trained batch 409 in epoch 11, gen_loss = 0.8450485193147892, disc_loss = 0.07517784189932593
Trained batch 410 in epoch 11, gen_loss = 0.845338460302701, disc_loss = 0.07503976644562907
Trained batch 411 in epoch 11, gen_loss = 0.8449932510413013, disc_loss = 0.07494271199164677
Trained batch 412 in epoch 11, gen_loss = 0.8449579419581711, disc_loss = 0.07498083718021831
Trained batch 413 in epoch 11, gen_loss = 0.8447734975584463, disc_loss = 0.07486068149398706
Trained batch 414 in epoch 11, gen_loss = 0.8444983603006386, disc_loss = 0.07488430161926761
Trained batch 415 in epoch 11, gen_loss = 0.8446226886545236, disc_loss = 0.07474361067019905
Trained batch 416 in epoch 11, gen_loss = 0.844540594435996, disc_loss = 0.07470667135970985
Trained batch 417 in epoch 11, gen_loss = 0.84541732714507, disc_loss = 0.0746036067974874
Trained batch 418 in epoch 11, gen_loss = 0.845337813680098, disc_loss = 0.07450654912242101
Trained batch 419 in epoch 11, gen_loss = 0.8454455020881835, disc_loss = 0.07437234232867403
Trained batch 420 in epoch 11, gen_loss = 0.8453718967505702, disc_loss = 0.0742990895508481
Trained batch 421 in epoch 11, gen_loss = 0.8453475734068884, disc_loss = 0.07415433814837398
Trained batch 422 in epoch 11, gen_loss = 0.8460041893289444, disc_loss = 0.07413295627159923
Trained batch 423 in epoch 11, gen_loss = 0.8458403443109315, disc_loss = 0.07403568923253706
Trained batch 424 in epoch 11, gen_loss = 0.8454306286924026, disc_loss = 0.07402381206040873
Trained batch 425 in epoch 11, gen_loss = 0.8454111091127978, disc_loss = 0.07389257426981426
Trained batch 426 in epoch 11, gen_loss = 0.8458598948474232, disc_loss = 0.07376450518543115
Trained batch 427 in epoch 11, gen_loss = 0.8455904768170598, disc_loss = 0.07366522243376995
Trained batch 428 in epoch 11, gen_loss = 0.8449830503174753, disc_loss = 0.07391492090033831
Trained batch 429 in epoch 11, gen_loss = 0.8459594244180724, disc_loss = 0.07387268969702512
Trained batch 430 in epoch 11, gen_loss = 0.8470406391227882, disc_loss = 0.07387962415511883
Trained batch 431 in epoch 11, gen_loss = 0.8468332627305278, disc_loss = 0.0738573524329156
Trained batch 432 in epoch 11, gen_loss = 0.8465127482425258, disc_loss = 0.07382081147266109
Trained batch 433 in epoch 11, gen_loss = 0.8463622633762623, disc_loss = 0.07373562608180302
Trained batch 434 in epoch 11, gen_loss = 0.8461760008472136, disc_loss = 0.07368387263268232
Trained batch 435 in epoch 11, gen_loss = 0.8459744223760902, disc_loss = 0.07362318539846723
Trained batch 436 in epoch 11, gen_loss = 0.845545440571259, disc_loss = 0.07362385815567841
Trained batch 437 in epoch 11, gen_loss = 0.8453803628547006, disc_loss = 0.07357014318689976
Trained batch 438 in epoch 11, gen_loss = 0.8457165136424175, disc_loss = 0.07342533697427202
Trained batch 439 in epoch 11, gen_loss = 0.8459988539869135, disc_loss = 0.07332758028271862
Trained batch 440 in epoch 11, gen_loss = 0.8461814941732791, disc_loss = 0.07318222873090278
Trained batch 441 in epoch 11, gen_loss = 0.8461376300494595, disc_loss = 0.07308114334999909
Trained batch 442 in epoch 11, gen_loss = 0.8457112206024188, disc_loss = 0.07305077067944253
Trained batch 443 in epoch 11, gen_loss = 0.8460909414130289, disc_loss = 0.07314327691245388
Trained batch 444 in epoch 11, gen_loss = 0.8464214848668388, disc_loss = 0.07302585720304358
Trained batch 445 in epoch 11, gen_loss = 0.8465948789109029, disc_loss = 0.07309043419760372
Trained batch 446 in epoch 11, gen_loss = 0.8459658001359944, disc_loss = 0.07333360251322622
Trained batch 447 in epoch 11, gen_loss = 0.8461260340575661, disc_loss = 0.07320538552552794
Trained batch 448 in epoch 11, gen_loss = 0.8467204278720779, disc_loss = 0.07348118284572007
Trained batch 449 in epoch 11, gen_loss = 0.8471818823284573, disc_loss = 0.07336228858886494
Trained batch 450 in epoch 11, gen_loss = 0.8468248672337331, disc_loss = 0.07341476853424786
Trained batch 451 in epoch 11, gen_loss = 0.8466385988007604, disc_loss = 0.07331165548339816
Trained batch 452 in epoch 11, gen_loss = 0.8471341567323697, disc_loss = 0.07339587990836
Trained batch 453 in epoch 11, gen_loss = 0.8469448286531255, disc_loss = 0.07329914836409925
Trained batch 454 in epoch 11, gen_loss = 0.8464578335101788, disc_loss = 0.07332988865468856
Trained batch 455 in epoch 11, gen_loss = 0.8467298638925218, disc_loss = 0.07328162939704366
Trained batch 456 in epoch 11, gen_loss = 0.8467734609964901, disc_loss = 0.07314831654070439
Trained batch 457 in epoch 11, gen_loss = 0.8466719123473855, disc_loss = 0.07309928651712022
Trained batch 458 in epoch 11, gen_loss = 0.8470904172635546, disc_loss = 0.0730276848362
Trained batch 459 in epoch 11, gen_loss = 0.847460918582004, disc_loss = 0.072987414813479
Trained batch 460 in epoch 11, gen_loss = 0.8477497151254831, disc_loss = 0.07285508139911481
Trained batch 461 in epoch 11, gen_loss = 0.8475606802738074, disc_loss = 0.07282387640012743
Trained batch 462 in epoch 11, gen_loss = 0.8477245569229126, disc_loss = 0.07295742518918238
Trained batch 463 in epoch 11, gen_loss = 0.8472426003166313, disc_loss = 0.07298286760763811
Trained batch 464 in epoch 11, gen_loss = 0.8465043738324155, disc_loss = 0.07303487844965471
Trained batch 465 in epoch 11, gen_loss = 0.8471435529735467, disc_loss = 0.07294045437662962
Trained batch 466 in epoch 11, gen_loss = 0.8476347756079484, disc_loss = 0.07288021346398607
Trained batch 467 in epoch 11, gen_loss = 0.8481979236388818, disc_loss = 0.07279693449322039
Trained batch 468 in epoch 11, gen_loss = 0.847824492815461, disc_loss = 0.07285082898835447
Trained batch 469 in epoch 11, gen_loss = 0.847700319772071, disc_loss = 0.07276239299433346
Trained batch 470 in epoch 11, gen_loss = 0.8477923096871427, disc_loss = 0.07264966716804006
Trained batch 471 in epoch 11, gen_loss = 0.8478935160121676, disc_loss = 0.07253327994741562
Trained batch 472 in epoch 11, gen_loss = 0.848245165186755, disc_loss = 0.0724549302713154
Trained batch 473 in epoch 11, gen_loss = 0.8487865961302182, disc_loss = 0.07234441008583843
Trained batch 474 in epoch 11, gen_loss = 0.8490150683804563, disc_loss = 0.07222234075006685
Trained batch 475 in epoch 11, gen_loss = 0.8486888800598994, disc_loss = 0.07214877752884596
Trained batch 476 in epoch 11, gen_loss = 0.8484512477550866, disc_loss = 0.07212280214957471
Trained batch 477 in epoch 11, gen_loss = 0.848146599705748, disc_loss = 0.07225607528846134
Trained batch 478 in epoch 11, gen_loss = 0.8484998495942118, disc_loss = 0.07212892123196656
Trained batch 479 in epoch 11, gen_loss = 0.8482825619479021, disc_loss = 0.07205835883311616
Trained batch 480 in epoch 11, gen_loss = 0.8479034085283657, disc_loss = 0.07207017786715668
Trained batch 481 in epoch 11, gen_loss = 0.8487739738587027, disc_loss = 0.07201821580954298
Trained batch 482 in epoch 11, gen_loss = 0.8492357703716364, disc_loss = 0.07189032086219414
Trained batch 483 in epoch 11, gen_loss = 0.8493232826802356, disc_loss = 0.07197242706806269
Trained batch 484 in epoch 11, gen_loss = 0.8487691703530931, disc_loss = 0.072227975812539
Trained batch 485 in epoch 11, gen_loss = 0.8489053687195719, disc_loss = 0.07210779427301614
Trained batch 486 in epoch 11, gen_loss = 0.8497861512387802, disc_loss = 0.07218530120469584
Trained batch 487 in epoch 11, gen_loss = 0.8497207897608398, disc_loss = 0.07212495766809118
Trained batch 488 in epoch 11, gen_loss = 0.8494968821422211, disc_loss = 0.07204110258790247
Trained batch 489 in epoch 11, gen_loss = 0.8498496941157749, disc_loss = 0.07190877902416551
Trained batch 490 in epoch 11, gen_loss = 0.8498837824023183, disc_loss = 0.07190929662034128
Trained batch 491 in epoch 11, gen_loss = 0.849922919297606, disc_loss = 0.07179187383593583
Trained batch 492 in epoch 11, gen_loss = 0.8497103811761186, disc_loss = 0.07171861197172265
Trained batch 493 in epoch 11, gen_loss = 0.8494920357760147, disc_loss = 0.07167122009312094
Trained batch 494 in epoch 11, gen_loss = 0.8501161323653327, disc_loss = 0.07163948295543893
Trained batch 495 in epoch 11, gen_loss = 0.85050830978059, disc_loss = 0.07151110042750294
Trained batch 496 in epoch 11, gen_loss = 0.8503736513001579, disc_loss = 0.071397947325508
Trained batch 497 in epoch 11, gen_loss = 0.8500142816798275, disc_loss = 0.07140102023707635
Trained batch 498 in epoch 11, gen_loss = 0.8504617523573682, disc_loss = 0.07127457460899929
Trained batch 499 in epoch 11, gen_loss = 0.8508372153043747, disc_loss = 0.07124727481044829
Trained batch 500 in epoch 11, gen_loss = 0.8510492532077187, disc_loss = 0.07113142266958773
Trained batch 501 in epoch 11, gen_loss = 0.8509243802720332, disc_loss = 0.07101962757315412
Trained batch 502 in epoch 11, gen_loss = 0.850542627319427, disc_loss = 0.07100666153279854
Trained batch 503 in epoch 11, gen_loss = 0.8506330316738476, disc_loss = 0.07091195127808504
Trained batch 504 in epoch 11, gen_loss = 0.8510268568992615, disc_loss = 0.0709657197135805
Trained batch 505 in epoch 11, gen_loss = 0.8510972380402531, disc_loss = 0.07085530721240128
Trained batch 506 in epoch 11, gen_loss = 0.8505994122644384, disc_loss = 0.07087001399205047
Trained batch 507 in epoch 11, gen_loss = 0.8507472782388447, disc_loss = 0.07075240560917287
Trained batch 508 in epoch 11, gen_loss = 0.8505555225027568, disc_loss = 0.07069080827614999
Trained batch 509 in epoch 11, gen_loss = 0.8511721807367661, disc_loss = 0.07074169896031711
Trained batch 510 in epoch 11, gen_loss = 0.8510236014591971, disc_loss = 0.07067648260517014
Trained batch 511 in epoch 11, gen_loss = 0.8507176858838648, disc_loss = 0.07072712599256192
Trained batch 512 in epoch 11, gen_loss = 0.8505989069129989, disc_loss = 0.07069295947939215
Trained batch 513 in epoch 11, gen_loss = 0.850511321181917, disc_loss = 0.07063985373534928
Trained batch 514 in epoch 11, gen_loss = 0.8499138761492608, disc_loss = 0.07075931419374294
Trained batch 515 in epoch 11, gen_loss = 0.8506620534399684, disc_loss = 0.07096269242682082
Trained batch 516 in epoch 11, gen_loss = 0.8507121649194271, disc_loss = 0.07086879111163505
Trained batch 517 in epoch 11, gen_loss = 0.8504282425959598, disc_loss = 0.07079634543968559
Trained batch 518 in epoch 11, gen_loss = 0.8501308126256645, disc_loss = 0.07080565211013218
Trained batch 519 in epoch 11, gen_loss = 0.850272315969834, disc_loss = 0.07073825017119256
Trained batch 520 in epoch 11, gen_loss = 0.8502643096927489, disc_loss = 0.07073015942383064
Trained batch 521 in epoch 11, gen_loss = 0.8499704766090802, disc_loss = 0.07076767748899729
Trained batch 522 in epoch 11, gen_loss = 0.8499490815868341, disc_loss = 0.07074782679331121
Trained batch 523 in epoch 11, gen_loss = 0.8503560078053074, disc_loss = 0.07069166068997206
Trained batch 524 in epoch 11, gen_loss = 0.8510293456486293, disc_loss = 0.07067635379022076
Trained batch 525 in epoch 11, gen_loss = 0.85099960801266, disc_loss = 0.07062893845636695
Trained batch 526 in epoch 11, gen_loss = 0.8506522297406784, disc_loss = 0.07073588270969704
Trained batch 527 in epoch 11, gen_loss = 0.8515698030365236, disc_loss = 0.07087947699509448
Trained batch 528 in epoch 11, gen_loss = 0.8511835888788696, disc_loss = 0.0708589050425868
Trained batch 529 in epoch 11, gen_loss = 0.8509465667436708, disc_loss = 0.07081875144240429
Trained batch 530 in epoch 11, gen_loss = 0.8512266539808945, disc_loss = 0.07072575964566791
Trained batch 531 in epoch 11, gen_loss = 0.8507757817668126, disc_loss = 0.0707427642826355
Trained batch 532 in epoch 11, gen_loss = 0.8505981116089096, disc_loss = 0.07067384643176147
Trained batch 533 in epoch 11, gen_loss = 0.850659746802255, disc_loss = 0.07058972462467598
Trained batch 534 in epoch 11, gen_loss = 0.8509124125275657, disc_loss = 0.07047533272791688
Trained batch 535 in epoch 11, gen_loss = 0.8506737718386437, disc_loss = 0.07041718666580742
Trained batch 536 in epoch 11, gen_loss = 0.8507348014877717, disc_loss = 0.07034178188823344
Trained batch 537 in epoch 11, gen_loss = 0.8509098723475375, disc_loss = 0.07027330227736314
Trained batch 538 in epoch 11, gen_loss = 0.8511408303133411, disc_loss = 0.0701833506234004
Trained batch 539 in epoch 11, gen_loss = 0.850566272272004, disc_loss = 0.07029266885516268
Trained batch 540 in epoch 11, gen_loss = 0.8510471643008939, disc_loss = 0.07039480647778004
Trained batch 541 in epoch 11, gen_loss = 0.8511500894143572, disc_loss = 0.07041285978458355
Trained batch 542 in epoch 11, gen_loss = 0.8503064884775032, disc_loss = 0.07090081504681602
Trained batch 543 in epoch 11, gen_loss = 0.8506239581962719, disc_loss = 0.07081289966385264
Trained batch 544 in epoch 11, gen_loss = 0.8509483616833293, disc_loss = 0.07075591711071107
Trained batch 545 in epoch 11, gen_loss = 0.8513121209192626, disc_loss = 0.07071174267379246
Trained batch 546 in epoch 11, gen_loss = 0.8511640593491263, disc_loss = 0.07073854067630153
Trained batch 547 in epoch 11, gen_loss = 0.8508693053230753, disc_loss = 0.07089536721022786
Trained batch 548 in epoch 11, gen_loss = 0.8510339605895114, disc_loss = 0.07084364550890493
Trained batch 549 in epoch 11, gen_loss = 0.8509512137824838, disc_loss = 0.07091297160156748
Trained batch 550 in epoch 11, gen_loss = 0.8504458472754691, disc_loss = 0.07099964051505724
Trained batch 551 in epoch 11, gen_loss = 0.8506384813159272, disc_loss = 0.07089511306106072
Trained batch 552 in epoch 11, gen_loss = 0.8508101356288192, disc_loss = 0.07122350537688026
Trained batch 553 in epoch 11, gen_loss = 0.850302240747407, disc_loss = 0.07135765586344237
Trained batch 554 in epoch 11, gen_loss = 0.8499655843318046, disc_loss = 0.07132284246250853
Trained batch 555 in epoch 11, gen_loss = 0.8504800197782276, disc_loss = 0.07148783726001279
Trained batch 556 in epoch 11, gen_loss = 0.8498775073506032, disc_loss = 0.07164226062729608
Trained batch 557 in epoch 11, gen_loss = 0.8494151630388793, disc_loss = 0.07171125948682801
Trained batch 558 in epoch 11, gen_loss = 0.8497054174355829, disc_loss = 0.07173362515253649
Trained batch 559 in epoch 11, gen_loss = 0.8498179840722254, disc_loss = 0.07163238600561661
Trained batch 560 in epoch 11, gen_loss = 0.849735828591328, disc_loss = 0.07157807366892616
Trained batch 561 in epoch 11, gen_loss = 0.8496312270491149, disc_loss = 0.07149527308753165
Trained batch 562 in epoch 11, gen_loss = 0.8498967889676509, disc_loss = 0.0716230796441621
Trained batch 563 in epoch 11, gen_loss = 0.8495910067824607, disc_loss = 0.07172408310947477
Trained batch 564 in epoch 11, gen_loss = 0.8495728533352371, disc_loss = 0.07169151589670013
Trained batch 565 in epoch 11, gen_loss = 0.8492621386114363, disc_loss = 0.07173738845824774
Trained batch 566 in epoch 11, gen_loss = 0.8494966123154555, disc_loss = 0.07189256558605392
Trained batch 567 in epoch 11, gen_loss = 0.8489643680062932, disc_loss = 0.07201316020071087
Trained batch 568 in epoch 11, gen_loss = 0.8488096055854603, disc_loss = 0.07197865484338024
Trained batch 569 in epoch 11, gen_loss = 0.8484509214497449, disc_loss = 0.07207397046711361
Trained batch 570 in epoch 11, gen_loss = 0.8483246299201678, disc_loss = 0.07253538447247913
Trained batch 571 in epoch 11, gen_loss = 0.8479316451853806, disc_loss = 0.07257633639981488
Trained batch 572 in epoch 11, gen_loss = 0.8479011348508831, disc_loss = 0.07259774077391125
Trained batch 573 in epoch 11, gen_loss = 0.8477786981374129, disc_loss = 0.0725983705709101
Trained batch 574 in epoch 11, gen_loss = 0.8474794305407483, disc_loss = 0.07263647319829983
Trained batch 575 in epoch 11, gen_loss = 0.8472410039458838, disc_loss = 0.07261101624721454
Trained batch 576 in epoch 11, gen_loss = 0.847379681917369, disc_loss = 0.07258778658777837
Trained batch 577 in epoch 11, gen_loss = 0.8471756127363258, disc_loss = 0.07258857423794104
Trained batch 578 in epoch 11, gen_loss = 0.8472959693128786, disc_loss = 0.07249715399891396
Trained batch 579 in epoch 11, gen_loss = 0.8469440648781842, disc_loss = 0.07258102749313773
Trained batch 580 in epoch 11, gen_loss = 0.8469339208533144, disc_loss = 0.07248478575502226
Trained batch 581 in epoch 11, gen_loss = 0.8473159563807687, disc_loss = 0.07245010178843417
Trained batch 582 in epoch 11, gen_loss = 0.8478387783874165, disc_loss = 0.0723919753036358
Trained batch 583 in epoch 11, gen_loss = 0.8475775354835269, disc_loss = 0.07246388617124766
Trained batch 584 in epoch 11, gen_loss = 0.8475432053080991, disc_loss = 0.07237391344820841
Trained batch 585 in epoch 11, gen_loss = 0.8475918336024464, disc_loss = 0.07237326966935559
Trained batch 586 in epoch 11, gen_loss = 0.8475301274347549, disc_loss = 0.07230057031728543
Trained batch 587 in epoch 11, gen_loss = 0.8474145359834846, disc_loss = 0.07221676698778154
Trained batch 588 in epoch 11, gen_loss = 0.8476102385031145, disc_loss = 0.07212302336984762
Trained batch 589 in epoch 11, gen_loss = 0.8480467311911664, disc_loss = 0.07203228764109693
Trained batch 590 in epoch 11, gen_loss = 0.8478283619416749, disc_loss = 0.07197792420255149
Trained batch 591 in epoch 11, gen_loss = 0.8476260780180628, disc_loss = 0.07190656143467168
Trained batch 592 in epoch 11, gen_loss = 0.8480016236864093, disc_loss = 0.07181102232175171
Trained batch 593 in epoch 11, gen_loss = 0.8482885995396862, disc_loss = 0.07180506749837487
Trained batch 594 in epoch 11, gen_loss = 0.8485689666591772, disc_loss = 0.07178582626731456
Trained batch 595 in epoch 11, gen_loss = 0.8482611246857067, disc_loss = 0.07186411366166684
Trained batch 596 in epoch 11, gen_loss = 0.8480059031765266, disc_loss = 0.07193486197809477
Trained batch 597 in epoch 11, gen_loss = 0.8485504928540226, disc_loss = 0.07189786908867765
Trained batch 598 in epoch 11, gen_loss = 0.8487828677902636, disc_loss = 0.07191430493716605
Trained batch 599 in epoch 11, gen_loss = 0.8487288838128249, disc_loss = 0.07185942970837156
Trained batch 600 in epoch 11, gen_loss = 0.8485118507247995, disc_loss = 0.07186947400354704
Trained batch 601 in epoch 11, gen_loss = 0.8478873682972601, disc_loss = 0.07201382277094051
Trained batch 602 in epoch 11, gen_loss = 0.8484902882061985, disc_loss = 0.07207263335832712
Trained batch 603 in epoch 11, gen_loss = 0.8485530875376518, disc_loss = 0.07217039058712736
Trained batch 604 in epoch 11, gen_loss = 0.8482281131192673, disc_loss = 0.07225087094774917
Trained batch 605 in epoch 11, gen_loss = 0.8480678647264789, disc_loss = 0.07220176878468235
Trained batch 606 in epoch 11, gen_loss = 0.8481466909609674, disc_loss = 0.07213998091893495
Trained batch 607 in epoch 11, gen_loss = 0.8484640356741453, disc_loss = 0.07207996945975251
Trained batch 608 in epoch 11, gen_loss = 0.8485083417547943, disc_loss = 0.07198954709424761
Trained batch 609 in epoch 11, gen_loss = 0.8482917471010177, disc_loss = 0.07198859834890874
Trained batch 610 in epoch 11, gen_loss = 0.8481221762889731, disc_loss = 0.07196629795500377
Trained batch 611 in epoch 11, gen_loss = 0.8487019575888815, disc_loss = 0.0720602354960017
Trained batch 612 in epoch 11, gen_loss = 0.8484096229562557, disc_loss = 0.0720694944153116
Trained batch 613 in epoch 11, gen_loss = 0.8480852112319648, disc_loss = 0.07214173528362758
Trained batch 614 in epoch 11, gen_loss = 0.8483008383735409, disc_loss = 0.07213116340884348
Trained batch 615 in epoch 11, gen_loss = 0.8480265381467806, disc_loss = 0.07217285723437543
Trained batch 616 in epoch 11, gen_loss = 0.8472778470145246, disc_loss = 0.07255812276100417
Trained batch 617 in epoch 11, gen_loss = 0.8480686367426103, disc_loss = 0.07345908272010801
Trained batch 618 in epoch 11, gen_loss = 0.8480149221054379, disc_loss = 0.07347716948977387
Trained batch 619 in epoch 11, gen_loss = 0.847613552549193, disc_loss = 0.07358722717411095
Trained batch 620 in epoch 11, gen_loss = 0.8472137928680905, disc_loss = 0.07365116394828292
Trained batch 621 in epoch 11, gen_loss = 0.8471665140421061, disc_loss = 0.07390421851151817
Trained batch 622 in epoch 11, gen_loss = 0.8473989563137532, disc_loss = 0.07393459849549909
Trained batch 623 in epoch 11, gen_loss = 0.8466993661549611, disc_loss = 0.0741794948072101
Trained batch 624 in epoch 11, gen_loss = 0.8464712903499604, disc_loss = 0.0742210740506649
Trained batch 625 in epoch 11, gen_loss = 0.8468452899124675, disc_loss = 0.0743539517287153
Trained batch 626 in epoch 11, gen_loss = 0.846965475848607, disc_loss = 0.07427718606517551
Trained batch 627 in epoch 11, gen_loss = 0.8467927780595554, disc_loss = 0.07421057752873393
Trained batch 628 in epoch 11, gen_loss = 0.8466401630346271, disc_loss = 0.0741445647081766
Trained batch 629 in epoch 11, gen_loss = 0.8466587741696645, disc_loss = 0.07415408392451585
Trained batch 630 in epoch 11, gen_loss = 0.8463703368904095, disc_loss = 0.07413286080203135
Trained batch 631 in epoch 11, gen_loss = 0.845891887675735, disc_loss = 0.07423386289856007
Trained batch 632 in epoch 11, gen_loss = 0.8462296171116791, disc_loss = 0.07433437890009763
Trained batch 633 in epoch 11, gen_loss = 0.8459111236341368, disc_loss = 0.07437583219777053
Trained batch 634 in epoch 11, gen_loss = 0.8458065786230282, disc_loss = 0.07428675140804193
Trained batch 635 in epoch 11, gen_loss = 0.845373679397616, disc_loss = 0.07433733972574368
Trained batch 636 in epoch 11, gen_loss = 0.8453352996374786, disc_loss = 0.07475624607182933
Trained batch 637 in epoch 11, gen_loss = 0.8450394327457422, disc_loss = 0.07479665024924241
Trained batch 638 in epoch 11, gen_loss = 0.8446907913647533, disc_loss = 0.0748484047517437
Trained batch 639 in epoch 11, gen_loss = 0.8447808732744306, disc_loss = 0.07488623462268151
Trained batch 640 in epoch 11, gen_loss = 0.8442118661173048, disc_loss = 0.07497317036512118
Trained batch 641 in epoch 11, gen_loss = 0.8444298735567343, disc_loss = 0.07505468474672033
Trained batch 642 in epoch 11, gen_loss = 0.8441200190995751, disc_loss = 0.07504664311072504
Trained batch 643 in epoch 11, gen_loss = 0.8439402016145843, disc_loss = 0.07504020174907416
Trained batch 644 in epoch 11, gen_loss = 0.8442006690095561, disc_loss = 0.07502501202068587
Trained batch 645 in epoch 11, gen_loss = 0.8439507833667584, disc_loss = 0.0751369668361111
Trained batch 646 in epoch 11, gen_loss = 0.8437691404148822, disc_loss = 0.0751631738102694
Trained batch 647 in epoch 11, gen_loss = 0.8433802439198818, disc_loss = 0.0751810641211952
Trained batch 648 in epoch 11, gen_loss = 0.8436353190562391, disc_loss = 0.07512469288931789
Trained batch 649 in epoch 11, gen_loss = 0.8433070784807205, disc_loss = 0.07510174977091642
Trained batch 650 in epoch 11, gen_loss = 0.8435833117654247, disc_loss = 0.0750802681765615
Trained batch 651 in epoch 11, gen_loss = 0.8433788166912787, disc_loss = 0.07512855560638787
Trained batch 652 in epoch 11, gen_loss = 0.8434164882345185, disc_loss = 0.07512070064020741
Trained batch 653 in epoch 11, gen_loss = 0.8433496320922076, disc_loss = 0.07506450373873069
Trained batch 654 in epoch 11, gen_loss = 0.8429896221361087, disc_loss = 0.07507189461065612
Trained batch 655 in epoch 11, gen_loss = 0.8428164850920439, disc_loss = 0.07511299747473947
Trained batch 656 in epoch 11, gen_loss = 0.8433510334978002, disc_loss = 0.07515530694202383
Trained batch 657 in epoch 11, gen_loss = 0.8431101270631454, disc_loss = 0.07512025740620394
Trained batch 658 in epoch 11, gen_loss = 0.8429003195534708, disc_loss = 0.07517431908723798
Trained batch 659 in epoch 11, gen_loss = 0.8429409044710072, disc_loss = 0.07513398992631472
Trained batch 660 in epoch 11, gen_loss = 0.8433920297878773, disc_loss = 0.0752391265522063
Trained batch 661 in epoch 11, gen_loss = 0.8432696347780458, disc_loss = 0.07518754673283266
Trained batch 662 in epoch 11, gen_loss = 0.8432357408791825, disc_loss = 0.0751008704939624
Trained batch 663 in epoch 11, gen_loss = 0.8434009524623314, disc_loss = 0.07499949940261487
Trained batch 664 in epoch 11, gen_loss = 0.8431583712423655, disc_loss = 0.07498881035813487
Trained batch 665 in epoch 11, gen_loss = 0.8430737036395002, disc_loss = 0.07492211760740515
Trained batch 666 in epoch 11, gen_loss = 0.8434227629490699, disc_loss = 0.07483704140859432
Trained batch 667 in epoch 11, gen_loss = 0.8432182412215335, disc_loss = 0.07485206054473396
Trained batch 668 in epoch 11, gen_loss = 0.8435340337065481, disc_loss = 0.07475674361608622
Trained batch 669 in epoch 11, gen_loss = 0.8432189966760465, disc_loss = 0.07477681298615105
Trained batch 670 in epoch 11, gen_loss = 0.8433355948875274, disc_loss = 0.07469220760787786
Trained batch 671 in epoch 11, gen_loss = 0.8436373448708937, disc_loss = 0.0745972385047935
Trained batch 672 in epoch 11, gen_loss = 0.8437483248260719, disc_loss = 0.07457322074601325
Trained batch 673 in epoch 11, gen_loss = 0.8437233805567999, disc_loss = 0.07460983778220168
Trained batch 674 in epoch 11, gen_loss = 0.843383960503119, disc_loss = 0.074577210476553
Trained batch 675 in epoch 11, gen_loss = 0.8432100741027375, disc_loss = 0.07458983312950597
Trained batch 676 in epoch 11, gen_loss = 0.8437707728350003, disc_loss = 0.07453593838151043
Trained batch 677 in epoch 11, gen_loss = 0.8443032922910026, disc_loss = 0.07450619003952516
Trained batch 678 in epoch 11, gen_loss = 0.8443838153829982, disc_loss = 0.07443539851478168
Trained batch 679 in epoch 11, gen_loss = 0.8442666566985495, disc_loss = 0.07442389741430387
Trained batch 680 in epoch 11, gen_loss = 0.8440965734827011, disc_loss = 0.07436860467631386
Trained batch 681 in epoch 11, gen_loss = 0.8443885977404558, disc_loss = 0.07427343430374463
Trained batch 682 in epoch 11, gen_loss = 0.8446773977003893, disc_loss = 0.07417999543958667
Trained batch 683 in epoch 11, gen_loss = 0.8449633949768474, disc_loss = 0.07410141614902961
Trained batch 684 in epoch 11, gen_loss = 0.8450206184474222, disc_loss = 0.07400766210834475
Trained batch 685 in epoch 11, gen_loss = 0.8452456126494589, disc_loss = 0.07399254506209502
Trained batch 686 in epoch 11, gen_loss = 0.845030803737682, disc_loss = 0.0739690999688887
Trained batch 687 in epoch 11, gen_loss = 0.8449959594236557, disc_loss = 0.07389606805897296
Trained batch 688 in epoch 11, gen_loss = 0.8451491101646285, disc_loss = 0.07389061593860172
Trained batch 689 in epoch 11, gen_loss = 0.8450172670941422, disc_loss = 0.07385624883345504
Trained batch 690 in epoch 11, gen_loss = 0.8451537448055665, disc_loss = 0.07376517625808629
Trained batch 691 in epoch 11, gen_loss = 0.8453223565324194, disc_loss = 0.07367117410778698
Trained batch 692 in epoch 11, gen_loss = 0.8449590592759341, disc_loss = 0.07368801691815322
Trained batch 693 in epoch 11, gen_loss = 0.8454343301676193, disc_loss = 0.07363572390481658
Trained batch 694 in epoch 11, gen_loss = 0.8458627100042302, disc_loss = 0.0735984352866201
Trained batch 695 in epoch 11, gen_loss = 0.8460926853291605, disc_loss = 0.0735323739508381
Trained batch 696 in epoch 11, gen_loss = 0.845821062281963, disc_loss = 0.07359803415209568
Trained batch 697 in epoch 11, gen_loss = 0.8459703704091402, disc_loss = 0.07352099205663476
Trained batch 698 in epoch 11, gen_loss = 0.8459687026188267, disc_loss = 0.07343364195186693
Trained batch 699 in epoch 11, gen_loss = 0.8465265571645328, disc_loss = 0.07354075700576816
Trained batch 700 in epoch 11, gen_loss = 0.8464416578815939, disc_loss = 0.07350006847829689
Trained batch 701 in epoch 11, gen_loss = 0.8465621439564941, disc_loss = 0.07347992076366036
Trained batch 702 in epoch 11, gen_loss = 0.8464240635696211, disc_loss = 0.07345587801543273
Trained batch 703 in epoch 11, gen_loss = 0.8468608117493038, disc_loss = 0.07343067970677195
Trained batch 704 in epoch 11, gen_loss = 0.8468224200373846, disc_loss = 0.07336074552426101
Trained batch 705 in epoch 11, gen_loss = 0.8466692939611737, disc_loss = 0.0732949354419374
Trained batch 706 in epoch 11, gen_loss = 0.8469220923821019, disc_loss = 0.07328107203271297
Trained batch 707 in epoch 11, gen_loss = 0.8469865392409476, disc_loss = 0.07319726572124718
Trained batch 708 in epoch 11, gen_loss = 0.8466414140461194, disc_loss = 0.07319478949397928
Trained batch 709 in epoch 11, gen_loss = 0.846847336351032, disc_loss = 0.07313662798104571
Trained batch 710 in epoch 11, gen_loss = 0.8470024495436672, disc_loss = 0.07305502517963595
Trained batch 711 in epoch 11, gen_loss = 0.8470722603077969, disc_loss = 0.07298333263757188
Trained batch 712 in epoch 11, gen_loss = 0.8469623555057012, disc_loss = 0.07296594251652587
Trained batch 713 in epoch 11, gen_loss = 0.8472278442452935, disc_loss = 0.07288456687453289
Trained batch 714 in epoch 11, gen_loss = 0.8476411318028724, disc_loss = 0.07291165780067652
Trained batch 715 in epoch 11, gen_loss = 0.847760597961908, disc_loss = 0.07285484314282221
Trained batch 716 in epoch 11, gen_loss = 0.8474516111687137, disc_loss = 0.07304386331763435
Trained batch 717 in epoch 11, gen_loss = 0.8476035836098254, disc_loss = 0.07297146314506038
Trained batch 718 in epoch 11, gen_loss = 0.8478567923972272, disc_loss = 0.0730045773075979
Trained batch 719 in epoch 11, gen_loss = 0.8477248162445095, disc_loss = 0.07297596460492868
Trained batch 720 in epoch 11, gen_loss = 0.8481205779950596, disc_loss = 0.07290521809565169
Trained batch 721 in epoch 11, gen_loss = 0.848204214363217, disc_loss = 0.07283316727165247
Trained batch 722 in epoch 11, gen_loss = 0.8481031992211217, disc_loss = 0.07276658995533014
Trained batch 723 in epoch 11, gen_loss = 0.8482528285673969, disc_loss = 0.07269272660368344
Trained batch 724 in epoch 11, gen_loss = 0.8483611378587526, disc_loss = 0.07260807800524194
Trained batch 725 in epoch 11, gen_loss = 0.8486039039599337, disc_loss = 0.07252452578446918
Trained batch 726 in epoch 11, gen_loss = 0.8488681039669163, disc_loss = 0.07245379521356488
Trained batch 727 in epoch 11, gen_loss = 0.8487426220633827, disc_loss = 0.07240950087453801
Trained batch 728 in epoch 11, gen_loss = 0.8488056763945293, disc_loss = 0.07237807551937993
Trained batch 729 in epoch 11, gen_loss = 0.8486534671832437, disc_loss = 0.07236780620192829
Trained batch 730 in epoch 11, gen_loss = 0.8481895080098701, disc_loss = 0.07254749505937344
Trained batch 731 in epoch 11, gen_loss = 0.848017865639241, disc_loss = 0.07252416052331365
Trained batch 732 in epoch 11, gen_loss = 0.8482264582408239, disc_loss = 0.07253414410767418
Trained batch 733 in epoch 11, gen_loss = 0.8483100682497025, disc_loss = 0.07249369343351927
Trained batch 734 in epoch 11, gen_loss = 0.8479643588568888, disc_loss = 0.07252720550817697
Trained batch 735 in epoch 11, gen_loss = 0.8479422337740011, disc_loss = 0.072477192288953
Trained batch 736 in epoch 11, gen_loss = 0.8481748177287052, disc_loss = 0.07240323197435249
Trained batch 737 in epoch 11, gen_loss = 0.8482890379864995, disc_loss = 0.07231931641778648
Trained batch 738 in epoch 11, gen_loss = 0.8482990763748773, disc_loss = 0.07226870338027952
Trained batch 739 in epoch 11, gen_loss = 0.8486176325259982, disc_loss = 0.07219735152415327
Trained batch 740 in epoch 11, gen_loss = 0.8484405725188905, disc_loss = 0.07215519732067942
Trained batch 741 in epoch 11, gen_loss = 0.8484316166600769, disc_loss = 0.07207663175762904
Trained batch 742 in epoch 11, gen_loss = 0.8489105084141363, disc_loss = 0.07201002677338521
Trained batch 743 in epoch 11, gen_loss = 0.8492031706677329, disc_loss = 0.07199352539785367
Trained batch 744 in epoch 11, gen_loss = 0.8488384032009432, disc_loss = 0.07207689478043341
Trained batch 745 in epoch 11, gen_loss = 0.8491522015818962, disc_loss = 0.07199993817979625
Trained batch 746 in epoch 11, gen_loss = 0.8492276028217561, disc_loss = 0.07195709521571796
Trained batch 747 in epoch 11, gen_loss = 0.8491783399871964, disc_loss = 0.07195449071154397
Trained batch 748 in epoch 11, gen_loss = 0.8493018384689641, disc_loss = 0.07199653789639791
Trained batch 749 in epoch 11, gen_loss = 0.8491921037435531, disc_loss = 0.07196662231783073
Trained batch 750 in epoch 11, gen_loss = 0.8496280420080482, disc_loss = 0.07190646294172054
Trained batch 751 in epoch 11, gen_loss = 0.8497785988085448, disc_loss = 0.07184344772843922
Trained batch 752 in epoch 11, gen_loss = 0.8494857121036348, disc_loss = 0.07182420887656579
Trained batch 753 in epoch 11, gen_loss = 0.8494177751974339, disc_loss = 0.07185793672478326
Trained batch 754 in epoch 11, gen_loss = 0.8495383643551379, disc_loss = 0.07178377388476931
Trained batch 755 in epoch 11, gen_loss = 0.8492462052002786, disc_loss = 0.0717913748957611
Trained batch 756 in epoch 11, gen_loss = 0.8495152952885219, disc_loss = 0.07175546331156434
Trained batch 757 in epoch 11, gen_loss = 0.849798010529503, disc_loss = 0.0716817531228498
Trained batch 758 in epoch 11, gen_loss = 0.8501599528023063, disc_loss = 0.07161823380124978
Trained batch 759 in epoch 11, gen_loss = 0.850146697657673, disc_loss = 0.07157153038945245
Trained batch 760 in epoch 11, gen_loss = 0.8499057455460752, disc_loss = 0.07154095541739668
Trained batch 761 in epoch 11, gen_loss = 0.8502327979314984, disc_loss = 0.07151479328056098
Trained batch 762 in epoch 11, gen_loss = 0.8500339384550817, disc_loss = 0.07150536330555948
Trained batch 763 in epoch 11, gen_loss = 0.8499230301270935, disc_loss = 0.07153001564423217
Trained batch 764 in epoch 11, gen_loss = 0.8498537545500238, disc_loss = 0.07149093172762519
Trained batch 765 in epoch 11, gen_loss = 0.8498763590272973, disc_loss = 0.07144561401925806
Trained batch 766 in epoch 11, gen_loss = 0.849584735007143, disc_loss = 0.07155694407222712
Trained batch 767 in epoch 11, gen_loss = 0.8499092693673447, disc_loss = 0.07156928403370937
Trained batch 768 in epoch 11, gen_loss = 0.8498109724416224, disc_loss = 0.07152760637044829
Trained batch 769 in epoch 11, gen_loss = 0.849889248261204, disc_loss = 0.0714868202297525
Trained batch 770 in epoch 11, gen_loss = 0.849689094511606, disc_loss = 0.07154213806950087
Trained batch 771 in epoch 11, gen_loss = 0.8500661850361626, disc_loss = 0.0715263624762431
Trained batch 772 in epoch 11, gen_loss = 0.8502872246588649, disc_loss = 0.07145171388405415
Trained batch 773 in epoch 11, gen_loss = 0.850269466369035, disc_loss = 0.07140055851341834
Trained batch 774 in epoch 11, gen_loss = 0.8503493966979365, disc_loss = 0.07133010998127921
Trained batch 775 in epoch 11, gen_loss = 0.8506722012054675, disc_loss = 0.07125070274653893
Trained batch 776 in epoch 11, gen_loss = 0.8503083858634207, disc_loss = 0.0712635523377123
Trained batch 777 in epoch 11, gen_loss = 0.8501699246983295, disc_loss = 0.07132583022701786
Trained batch 778 in epoch 11, gen_loss = 0.8500967837191057, disc_loss = 0.07127598520793949
Trained batch 779 in epoch 11, gen_loss = 0.8496624280626958, disc_loss = 0.0714171758805139
Trained batch 780 in epoch 11, gen_loss = 0.8501935292526641, disc_loss = 0.0715481221995456
Trained batch 781 in epoch 11, gen_loss = 0.8501523375282507, disc_loss = 0.07153835701887183
Trained batch 782 in epoch 11, gen_loss = 0.8499246768339384, disc_loss = 0.07153540563984925
Trained batch 783 in epoch 11, gen_loss = 0.8501715822411435, disc_loss = 0.07150968479952413
Trained batch 784 in epoch 11, gen_loss = 0.8501252297003558, disc_loss = 0.07146754984500682
Trained batch 785 in epoch 11, gen_loss = 0.850161247922264, disc_loss = 0.07139645016019922
Trained batch 786 in epoch 11, gen_loss = 0.8501519177208408, disc_loss = 0.07145388200618753
Trained batch 787 in epoch 11, gen_loss = 0.8499849414840568, disc_loss = 0.07140974265163963
Trained batch 788 in epoch 11, gen_loss = 0.8498546703611187, disc_loss = 0.07134669537671354
Trained batch 789 in epoch 11, gen_loss = 0.8503841707600823, disc_loss = 0.07137003880630755
Testing Epoch 11
Training Epoch 12
Trained batch 0 in epoch 12, gen_loss = 0.9304404258728027, disc_loss = 0.019612308591604233
Trained batch 1 in epoch 12, gen_loss = 0.8226852118968964, disc_loss = 0.04415481723845005
Trained batch 2 in epoch 12, gen_loss = 0.7426368196805319, disc_loss = 0.06370454902450244
Trained batch 3 in epoch 12, gen_loss = 0.864904597401619, disc_loss = 0.07767743896692991
Trained batch 4 in epoch 12, gen_loss = 0.8755538821220398, disc_loss = 0.0688989594578743
Trained batch 5 in epoch 12, gen_loss = 0.8656026124954224, disc_loss = 0.06444126864274342
Trained batch 6 in epoch 12, gen_loss = 0.8444642680031913, disc_loss = 0.06065103092363903
Trained batch 7 in epoch 12, gen_loss = 0.8306252434849739, disc_loss = 0.057173957116901875
Trained batch 8 in epoch 12, gen_loss = 0.8019574019643996, disc_loss = 0.06223811705907186
Trained batch 9 in epoch 12, gen_loss = 0.8606887638568879, disc_loss = 0.0694613665342331
Trained batch 10 in epoch 12, gen_loss = 0.8567602417685769, disc_loss = 0.06561834331263196
Trained batch 11 in epoch 12, gen_loss = 0.8661510099967321, disc_loss = 0.06506285878519218
Trained batch 12 in epoch 12, gen_loss = 0.8498689348881061, disc_loss = 0.06772667685380349
Trained batch 13 in epoch 12, gen_loss = 0.8404172956943512, disc_loss = 0.06459671817719936
Trained batch 14 in epoch 12, gen_loss = 0.8694724361101787, disc_loss = 0.06651202365756034
Trained batch 15 in epoch 12, gen_loss = 0.8753265589475632, disc_loss = 0.06312512280419469
Trained batch 16 in epoch 12, gen_loss = 0.8621499748790965, disc_loss = 0.06236673453274895
Trained batch 17 in epoch 12, gen_loss = 0.870272159576416, disc_loss = 0.06139902108245426
Trained batch 18 in epoch 12, gen_loss = 0.8590379137741891, disc_loss = 0.06082897790168461
Trained batch 19 in epoch 12, gen_loss = 0.8605881005525589, disc_loss = 0.060724100656807424
Trained batch 20 in epoch 12, gen_loss = 0.868473884605226, disc_loss = 0.07154120167806036
Trained batch 21 in epoch 12, gen_loss = 0.8572118824178522, disc_loss = 0.07431843622841618
Trained batch 22 in epoch 12, gen_loss = 0.8485388082006703, disc_loss = 0.0738116413678812
Trained batch 23 in epoch 12, gen_loss = 0.8486591031153997, disc_loss = 0.07203075468229751
Trained batch 24 in epoch 12, gen_loss = 0.8541478109359741, disc_loss = 0.07435588590800762
Trained batch 25 in epoch 12, gen_loss = 0.8574117284554702, disc_loss = 0.07199056776097187
Trained batch 26 in epoch 12, gen_loss = 0.8493073141133344, disc_loss = 0.0724691294685558
Trained batch 27 in epoch 12, gen_loss = 0.844675172652517, disc_loss = 0.07234489052955594
Trained batch 28 in epoch 12, gen_loss = 0.8488234425413197, disc_loss = 0.07037335457601424
Trained batch 29 in epoch 12, gen_loss = 0.8483534514904022, disc_loss = 0.06883181293184558
Trained batch 30 in epoch 12, gen_loss = 0.8498774055511721, disc_loss = 0.07058488178036866
Trained batch 31 in epoch 12, gen_loss = 0.8428296558558941, disc_loss = 0.0711658600193914
Trained batch 32 in epoch 12, gen_loss = 0.8453619082768759, disc_loss = 0.06969371988353404
Trained batch 33 in epoch 12, gen_loss = 0.8409361401024986, disc_loss = 0.06887732673545971
Trained batch 34 in epoch 12, gen_loss = 0.8395226631845747, disc_loss = 0.06788987120879549
Trained batch 35 in epoch 12, gen_loss = 0.836012010773023, disc_loss = 0.06715379083632594
Trained batch 36 in epoch 12, gen_loss = 0.835951212290171, disc_loss = 0.0695135594169433
Trained batch 37 in epoch 12, gen_loss = 0.8288531585743553, disc_loss = 0.07099088171104852
Trained batch 38 in epoch 12, gen_loss = 0.8280430451417581, disc_loss = 0.07174730460899763
Trained batch 39 in epoch 12, gen_loss = 0.8337167501449585, disc_loss = 0.07055810044985264
Trained batch 40 in epoch 12, gen_loss = 0.8311576552507354, disc_loss = 0.06977122583676403
Trained batch 41 in epoch 12, gen_loss = 0.8319514706021264, disc_loss = 0.06843052948603318
Trained batch 42 in epoch 12, gen_loss = 0.8292795364246812, disc_loss = 0.06887253029488546
Trained batch 43 in epoch 12, gen_loss = 0.827526874162934, disc_loss = 0.06820134905336256
Trained batch 44 in epoch 12, gen_loss = 0.8226778242323134, disc_loss = 0.06937906197789642
Trained batch 45 in epoch 12, gen_loss = 0.8305389259172522, disc_loss = 0.07351449636094597
Trained batch 46 in epoch 12, gen_loss = 0.8262579111342735, disc_loss = 0.07351379431387846
Trained batch 47 in epoch 12, gen_loss = 0.8307522957523664, disc_loss = 0.0723406540734383
Trained batch 48 in epoch 12, gen_loss = 0.8329160773024267, disc_loss = 0.07122200265602797
Trained batch 49 in epoch 12, gen_loss = 0.8280333924293518, disc_loss = 0.07120498726144434
Trained batch 50 in epoch 12, gen_loss = 0.8238582260468427, disc_loss = 0.07204846769352169
Trained batch 51 in epoch 12, gen_loss = 0.8205107163924438, disc_loss = 0.07185751488074087
Trained batch 52 in epoch 12, gen_loss = 0.8204233162807968, disc_loss = 0.07097494864028017
Trained batch 53 in epoch 12, gen_loss = 0.8228002289930979, disc_loss = 0.07050010680945383
Trained batch 54 in epoch 12, gen_loss = 0.819185733795166, disc_loss = 0.07061859459023584
Trained batch 55 in epoch 12, gen_loss = 0.8180736154317856, disc_loss = 0.06999378786089697
Trained batch 56 in epoch 12, gen_loss = 0.8207191061555293, disc_loss = 0.06903889724625308
Trained batch 57 in epoch 12, gen_loss = 0.8194658273252947, disc_loss = 0.0687199904390707
Trained batch 58 in epoch 12, gen_loss = 0.8221634373826495, disc_loss = 0.06777216628256996
Trained batch 59 in epoch 12, gen_loss = 0.819648364186287, disc_loss = 0.06759830969385802
Trained batch 60 in epoch 12, gen_loss = 0.8215840077791058, disc_loss = 0.06676787292187819
Trained batch 61 in epoch 12, gen_loss = 0.8262025463965631, disc_loss = 0.0658870447997845
Trained batch 62 in epoch 12, gen_loss = 0.8293296893437704, disc_loss = 0.06502831987445316
Trained batch 63 in epoch 12, gen_loss = 0.8290578201413155, disc_loss = 0.06479563529137522
Trained batch 64 in epoch 12, gen_loss = 0.8302018404006958, disc_loss = 0.06407679405349952
Trained batch 65 in epoch 12, gen_loss = 0.8337209622065226, disc_loss = 0.06407637515980186
Trained batch 66 in epoch 12, gen_loss = 0.8324534626149419, disc_loss = 0.0640300815341188
Trained batch 67 in epoch 12, gen_loss = 0.8317472645465065, disc_loss = 0.06354771280551658
Trained batch 68 in epoch 12, gen_loss = 0.8344942685486614, disc_loss = 0.06448129694099011
Trained batch 69 in epoch 12, gen_loss = 0.8340482924665723, disc_loss = 0.06389499862811394
Trained batch 70 in epoch 12, gen_loss = 0.8330143849614641, disc_loss = 0.06391418979726207
Trained batch 71 in epoch 12, gen_loss = 0.836323914428552, disc_loss = 0.0634193308910148
Trained batch 72 in epoch 12, gen_loss = 0.8358364880901493, disc_loss = 0.06355905504769659
Trained batch 73 in epoch 12, gen_loss = 0.8370980008228405, disc_loss = 0.06354855456565683
Trained batch 74 in epoch 12, gen_loss = 0.8389313594500224, disc_loss = 0.06377863677839438
Trained batch 75 in epoch 12, gen_loss = 0.8415872870307219, disc_loss = 0.06387243579190813
Trained batch 76 in epoch 12, gen_loss = 0.8393457082958965, disc_loss = 0.06447786356431323
Trained batch 77 in epoch 12, gen_loss = 0.8438735275696485, disc_loss = 0.06500631754692549
Trained batch 78 in epoch 12, gen_loss = 0.8456763617600067, disc_loss = 0.06437417165718123
Trained batch 79 in epoch 12, gen_loss = 0.8447295688092709, disc_loss = 0.0639125968213193
Trained batch 80 in epoch 12, gen_loss = 0.8452597510667494, disc_loss = 0.0634711217250169
Trained batch 81 in epoch 12, gen_loss = 0.846057942727717, disc_loss = 0.06363025142970245
Trained batch 82 in epoch 12, gen_loss = 0.8452308407749038, disc_loss = 0.06325728700956307
Trained batch 83 in epoch 12, gen_loss = 0.8440817424229213, disc_loss = 0.06287988287485427
Trained batch 84 in epoch 12, gen_loss = 0.8480237063239603, disc_loss = 0.06243579224409426
Trained batch 85 in epoch 12, gen_loss = 0.8504390564075736, disc_loss = 0.062028127538343504
Trained batch 86 in epoch 12, gen_loss = 0.8505645510794102, disc_loss = 0.062170223696906675
Trained batch 87 in epoch 12, gen_loss = 0.8507536006244746, disc_loss = 0.06177953589411283
Trained batch 88 in epoch 12, gen_loss = 0.8480877494544126, disc_loss = 0.06237973139903853
Trained batch 89 in epoch 12, gen_loss = 0.8476815594567193, disc_loss = 0.061999516489191185
Trained batch 90 in epoch 12, gen_loss = 0.8502997513655778, disc_loss = 0.06243424032620349
Trained batch 91 in epoch 12, gen_loss = 0.8497608304023743, disc_loss = 0.06199918653937462
Trained batch 92 in epoch 12, gen_loss = 0.8517221276478101, disc_loss = 0.061487320119575146
Trained batch 93 in epoch 12, gen_loss = 0.8489372540027538, disc_loss = 0.06204740178989286
Trained batch 94 in epoch 12, gen_loss = 0.8518082744196842, disc_loss = 0.06355113307700345
Trained batch 95 in epoch 12, gen_loss = 0.8520337287336588, disc_loss = 0.06308038966380991
Trained batch 96 in epoch 12, gen_loss = 0.8531455065786224, disc_loss = 0.06254843529313803
Trained batch 97 in epoch 12, gen_loss = 0.8507568659831066, disc_loss = 0.06268809286269303
Trained batch 98 in epoch 12, gen_loss = 0.8519968775787738, disc_loss = 0.06230577396586387
Trained batch 99 in epoch 12, gen_loss = 0.8535242921113968, disc_loss = 0.06191836568526923
Trained batch 100 in epoch 12, gen_loss = 0.8528620942984477, disc_loss = 0.06155064579394489
Trained batch 101 in epoch 12, gen_loss = 0.8536224780129451, disc_loss = 0.06106372728176853
Trained batch 102 in epoch 12, gen_loss = 0.8531884863538649, disc_loss = 0.060740940571192975
Trained batch 103 in epoch 12, gen_loss = 0.8528659057158691, disc_loss = 0.06040596327063842
Trained batch 104 in epoch 12, gen_loss = 0.8538157678785778, disc_loss = 0.059921754089494544
Trained batch 105 in epoch 12, gen_loss = 0.8543626947223015, disc_loss = 0.05949071392346666
Trained batch 106 in epoch 12, gen_loss = 0.8539503812789917, disc_loss = 0.059112572137301214
Trained batch 107 in epoch 12, gen_loss = 0.8552997294399474, disc_loss = 0.05864186520274314
Trained batch 108 in epoch 12, gen_loss = 0.8558828967426895, disc_loss = 0.05817759373661028
Trained batch 109 in epoch 12, gen_loss = 0.8602149567820809, disc_loss = 0.05812442629513415
Trained batch 110 in epoch 12, gen_loss = 0.8597302270365191, disc_loss = 0.057759723063927515
Trained batch 111 in epoch 12, gen_loss = 0.8573076602603708, disc_loss = 0.05806586590395974
Trained batch 112 in epoch 12, gen_loss = 0.8598861151036963, disc_loss = 0.057815828072154414
Trained batch 113 in epoch 12, gen_loss = 0.861301309706872, disc_loss = 0.05745285082804529
Trained batch 114 in epoch 12, gen_loss = 0.8623067907665087, disc_loss = 0.05704202193604863
Trained batch 115 in epoch 12, gen_loss = 0.8636829863334524, disc_loss = 0.057694878766377425
Trained batch 116 in epoch 12, gen_loss = 0.8638758470869472, disc_loss = 0.057516333463991806
Trained batch 117 in epoch 12, gen_loss = 0.8630759094731283, disc_loss = 0.057550666869570645
Trained batch 118 in epoch 12, gen_loss = 0.8603658876499208, disc_loss = 0.05773149936326912
Trained batch 119 in epoch 12, gen_loss = 0.8613834713896116, disc_loss = 0.05744360798659424
Trained batch 120 in epoch 12, gen_loss = 0.8624677288630778, disc_loss = 0.05752176842228933
Trained batch 121 in epoch 12, gen_loss = 0.8611603882469114, disc_loss = 0.057911307673107405
Trained batch 122 in epoch 12, gen_loss = 0.8607320863056959, disc_loss = 0.05754473775897811
Trained batch 123 in epoch 12, gen_loss = 0.8594208167445275, disc_loss = 0.05747717836000506
Trained batch 124 in epoch 12, gen_loss = 0.859785979270935, disc_loss = 0.05715184194594622
Trained batch 125 in epoch 12, gen_loss = 0.8630689108182513, disc_loss = 0.05704980492148371
Trained batch 126 in epoch 12, gen_loss = 0.863959975129976, disc_loss = 0.05679091512716896
Trained batch 127 in epoch 12, gen_loss = 0.8625698229297996, disc_loss = 0.056771258015942294
Trained batch 128 in epoch 12, gen_loss = 0.8627617992171945, disc_loss = 0.056476272693149344
Trained batch 129 in epoch 12, gen_loss = 0.8628260594147902, disc_loss = 0.056260714672792415
Trained batch 130 in epoch 12, gen_loss = 0.8653250322997115, disc_loss = 0.056979086840141364
Trained batch 131 in epoch 12, gen_loss = 0.8644405531160759, disc_loss = 0.056814406201186954
Trained batch 132 in epoch 12, gen_loss = 0.8641614707789027, disc_loss = 0.05663472343292227
Trained batch 133 in epoch 12, gen_loss = 0.8642865543934837, disc_loss = 0.056386951461378766
Trained batch 134 in epoch 12, gen_loss = 0.8628224739321956, disc_loss = 0.056311334386743885
Trained batch 135 in epoch 12, gen_loss = 0.8656699653057491, disc_loss = 0.05676977532943163
Trained batch 136 in epoch 12, gen_loss = 0.8659812420824148, disc_loss = 0.056774495502621154
Trained batch 137 in epoch 12, gen_loss = 0.8654138329236404, disc_loss = 0.05702821747737302
Trained batch 138 in epoch 12, gen_loss = 0.8637220254904933, disc_loss = 0.057468484196034696
Trained batch 139 in epoch 12, gen_loss = 0.8623698596443449, disc_loss = 0.058214439657915916
Trained batch 140 in epoch 12, gen_loss = 0.8649352700152295, disc_loss = 0.05833030813736907
Trained batch 141 in epoch 12, gen_loss = 0.86433205512208, disc_loss = 0.05812059125771195
Trained batch 142 in epoch 12, gen_loss = 0.8649333577889663, disc_loss = 0.057780654951148515
Trained batch 143 in epoch 12, gen_loss = 0.8625261075794697, disc_loss = 0.05796491980112882
Trained batch 144 in epoch 12, gen_loss = 0.8618700689282911, disc_loss = 0.05795372533772526
Trained batch 145 in epoch 12, gen_loss = 0.8615006559515652, disc_loss = 0.05793803643869006
Trained batch 146 in epoch 12, gen_loss = 0.8626647984900442, disc_loss = 0.058200991370392086
Trained batch 147 in epoch 12, gen_loss = 0.8609067572129739, disc_loss = 0.058676535106339564
Trained batch 148 in epoch 12, gen_loss = 0.8608972730252566, disc_loss = 0.058441033493102396
Trained batch 149 in epoch 12, gen_loss = 0.8607057170073191, disc_loss = 0.05825377693399787
Trained batch 150 in epoch 12, gen_loss = 0.8607528371526706, disc_loss = 0.058009416043807736
Trained batch 151 in epoch 12, gen_loss = 0.8614227085521347, disc_loss = 0.0576987956944657
Trained batch 152 in epoch 12, gen_loss = 0.8615331490055408, disc_loss = 0.05761202553810637
Trained batch 153 in epoch 12, gen_loss = 0.8618769897268964, disc_loss = 0.05732644505968148
Trained batch 154 in epoch 12, gen_loss = 0.8611861936507686, disc_loss = 0.057245144938989995
Trained batch 155 in epoch 12, gen_loss = 0.8635072455956385, disc_loss = 0.057346765590736114
Trained batch 156 in epoch 12, gen_loss = 0.8619586935468541, disc_loss = 0.05760993335728243
Trained batch 157 in epoch 12, gen_loss = 0.8624962617324877, disc_loss = 0.05755034086141217
Trained batch 158 in epoch 12, gen_loss = 0.8631684532705343, disc_loss = 0.05724688779281558
Trained batch 159 in epoch 12, gen_loss = 0.8629344154149294, disc_loss = 0.057157153176376596
Trained batch 160 in epoch 12, gen_loss = 0.8616389846949843, disc_loss = 0.05757894344419611
Trained batch 161 in epoch 12, gen_loss = 0.8613698335341465, disc_loss = 0.05731778080218736
Trained batch 162 in epoch 12, gen_loss = 0.861638230780151, disc_loss = 0.05793515829357999
Trained batch 163 in epoch 12, gen_loss = 0.859296780170464, disc_loss = 0.058687784902115424
Trained batch 164 in epoch 12, gen_loss = 0.8609919392701352, disc_loss = 0.05891817630917737
Trained batch 165 in epoch 12, gen_loss = 0.8605340234486454, disc_loss = 0.05914581740970712
Trained batch 166 in epoch 12, gen_loss = 0.8609107729203687, disc_loss = 0.059860286721123195
Trained batch 167 in epoch 12, gen_loss = 0.8617018638622194, disc_loss = 0.060996346652419084
Trained batch 168 in epoch 12, gen_loss = 0.8609555321332265, disc_loss = 0.06148340992805873
Trained batch 169 in epoch 12, gen_loss = 0.8607988164705389, disc_loss = 0.061549313486937214
Trained batch 170 in epoch 12, gen_loss = 0.8606639051297952, disc_loss = 0.06144298306987648
Trained batch 171 in epoch 12, gen_loss = 0.8595503443895385, disc_loss = 0.06148719561264612
Trained batch 172 in epoch 12, gen_loss = 0.8600071379215042, disc_loss = 0.061302118886240646
Trained batch 173 in epoch 12, gen_loss = 0.8606781709468228, disc_loss = 0.06107468579778041
Trained batch 174 in epoch 12, gen_loss = 0.8590059614181519, disc_loss = 0.06164911408509527
Trained batch 175 in epoch 12, gen_loss = 0.8601191741499034, disc_loss = 0.06150258662687107
Trained batch 176 in epoch 12, gen_loss = 0.8627430483446283, disc_loss = 0.06170259045679017
Trained batch 177 in epoch 12, gen_loss = 0.8623299471447977, disc_loss = 0.061523032364215746
Trained batch 178 in epoch 12, gen_loss = 0.8613698615708165, disc_loss = 0.06145964608678604
Trained batch 179 in epoch 12, gen_loss = 0.8597564829720391, disc_loss = 0.061771247080630726
Trained batch 180 in epoch 12, gen_loss = 0.8599753689370762, disc_loss = 0.06157904819106858
Trained batch 181 in epoch 12, gen_loss = 0.8612895594848381, disc_loss = 0.0624963161075017
Trained batch 182 in epoch 12, gen_loss = 0.8593930045112235, disc_loss = 0.06320191631755216
Trained batch 183 in epoch 12, gen_loss = 0.8585852987092474, disc_loss = 0.06322491939341568
Trained batch 184 in epoch 12, gen_loss = 0.8589602496172931, disc_loss = 0.06419020062564193
Trained batch 185 in epoch 12, gen_loss = 0.8587596647201046, disc_loss = 0.0644270317148297
Trained batch 186 in epoch 12, gen_loss = 0.8584548458058566, disc_loss = 0.06438206894233583
Trained batch 187 in epoch 12, gen_loss = 0.857456145451424, disc_loss = 0.06445789908831741
Trained batch 188 in epoch 12, gen_loss = 0.8569163698998709, disc_loss = 0.06435659022203513
Trained batch 189 in epoch 12, gen_loss = 0.8575690768266979, disc_loss = 0.06413989239617397
Trained batch 190 in epoch 12, gen_loss = 0.8579969946002461, disc_loss = 0.06389750716768947
Trained batch 191 in epoch 12, gen_loss = 0.8589753002549211, disc_loss = 0.06362556047194327
Trained batch 192 in epoch 12, gen_loss = 0.8587505919328008, disc_loss = 0.06349175886632247
Trained batch 193 in epoch 12, gen_loss = 0.8595013916492462, disc_loss = 0.06347465753248058
Trained batch 194 in epoch 12, gen_loss = 0.8594435966931857, disc_loss = 0.0634018511344225
Trained batch 195 in epoch 12, gen_loss = 0.8599072366344686, disc_loss = 0.06318655452329894
Trained batch 196 in epoch 12, gen_loss = 0.8603829048611791, disc_loss = 0.06294452062415593
Trained batch 197 in epoch 12, gen_loss = 0.8596565253806837, disc_loss = 0.06304270815518168
Trained batch 198 in epoch 12, gen_loss = 0.8601120656459176, disc_loss = 0.06278171321030837
Trained batch 199 in epoch 12, gen_loss = 0.8624813222885132, disc_loss = 0.06280551495030523
Trained batch 200 in epoch 12, gen_loss = 0.8634294170645339, disc_loss = 0.06263197795372104
Trained batch 201 in epoch 12, gen_loss = 0.8630846614884858, disc_loss = 0.062423058407436505
Trained batch 202 in epoch 12, gen_loss = 0.8624248672001468, disc_loss = 0.06230108801440652
Trained batch 203 in epoch 12, gen_loss = 0.8614473205571082, disc_loss = 0.062170906065433636
Trained batch 204 in epoch 12, gen_loss = 0.861675177260143, disc_loss = 0.06196410221661009
Trained batch 205 in epoch 12, gen_loss = 0.86311185967575, disc_loss = 0.061912297388737644
Trained batch 206 in epoch 12, gen_loss = 0.8624339860994459, disc_loss = 0.06189032987767947
Trained batch 207 in epoch 12, gen_loss = 0.8618805846915796, disc_loss = 0.06178105821331533
Trained batch 208 in epoch 12, gen_loss = 0.86320178274903, disc_loss = 0.061594715315189084
Trained batch 209 in epoch 12, gen_loss = 0.862670667114712, disc_loss = 0.061581772104615254
Trained batch 210 in epoch 12, gen_loss = 0.8625866911987558, disc_loss = 0.0613557386445985
Trained batch 211 in epoch 12, gen_loss = 0.8628471842351949, disc_loss = 0.06122694014712184
Trained batch 212 in epoch 12, gen_loss = 0.8631915816678687, disc_loss = 0.06105695442327171
Trained batch 213 in epoch 12, gen_loss = 0.862170959744498, disc_loss = 0.06121127740436486
Trained batch 214 in epoch 12, gen_loss = 0.8621715778528258, disc_loss = 0.06118089585716641
Trained batch 215 in epoch 12, gen_loss = 0.8630227556935063, disc_loss = 0.06093270469163717
Trained batch 216 in epoch 12, gen_loss = 0.8628289205138036, disc_loss = 0.06076543698782608
Trained batch 217 in epoch 12, gen_loss = 0.8637770840881067, disc_loss = 0.06055596606259089
Trained batch 218 in epoch 12, gen_loss = 0.8646838153333969, disc_loss = 0.0606009915139373
Trained batch 219 in epoch 12, gen_loss = 0.864682878147472, disc_loss = 0.06052527113140307
Trained batch 220 in epoch 12, gen_loss = 0.864233486253212, disc_loss = 0.0604190409765052
Trained batch 221 in epoch 12, gen_loss = 0.8654689676052815, disc_loss = 0.0603791651198523
Trained batch 222 in epoch 12, gen_loss = 0.864589368281343, disc_loss = 0.06045944922323852
Trained batch 223 in epoch 12, gen_loss = 0.8662611501557487, disc_loss = 0.06028989910763422
Trained batch 224 in epoch 12, gen_loss = 0.8658867152531942, disc_loss = 0.060205052118334504
Trained batch 225 in epoch 12, gen_loss = 0.8674155141400025, disc_loss = 0.060017362191646766
Trained batch 226 in epoch 12, gen_loss = 0.8671414090673304, disc_loss = 0.05998100887261955
Trained batch 227 in epoch 12, gen_loss = 0.8670077203658589, disc_loss = 0.05982260653144566
Trained batch 228 in epoch 12, gen_loss = 0.8674816530864832, disc_loss = 0.059615632498791385
Trained batch 229 in epoch 12, gen_loss = 0.8681487941223642, disc_loss = 0.05951593868515414
Trained batch 230 in epoch 12, gen_loss = 0.8676830697885324, disc_loss = 0.05990783393270138
Trained batch 231 in epoch 12, gen_loss = 0.8688425634955538, disc_loss = 0.059934058872950745
Trained batch 232 in epoch 12, gen_loss = 0.8698577028999002, disc_loss = 0.05975051763439511
Trained batch 233 in epoch 12, gen_loss = 0.8693631426391438, disc_loss = 0.05970899046311139
Trained batch 234 in epoch 12, gen_loss = 0.8688143040271515, disc_loss = 0.059536238565565426
Trained batch 235 in epoch 12, gen_loss = 0.8700752520965318, disc_loss = 0.05962732950051836
Trained batch 236 in epoch 12, gen_loss = 0.8692750998690159, disc_loss = 0.05964905446010174
Trained batch 237 in epoch 12, gen_loss = 0.8698708492667735, disc_loss = 0.059449082647426786
Trained batch 238 in epoch 12, gen_loss = 0.8701323123656556, disc_loss = 0.059349253633406374
Trained batch 239 in epoch 12, gen_loss = 0.8700276220838229, disc_loss = 0.05920945686132958
Trained batch 240 in epoch 12, gen_loss = 0.8699397902271065, disc_loss = 0.05973197019724678
Trained batch 241 in epoch 12, gen_loss = 0.8700569700603643, disc_loss = 0.05954079522389518
Trained batch 242 in epoch 12, gen_loss = 0.8701384518862751, disc_loss = 0.059332321118180154
Trained batch 243 in epoch 12, gen_loss = 0.8694023900344724, disc_loss = 0.059405651645826514
Trained batch 244 in epoch 12, gen_loss = 0.869788650347262, disc_loss = 0.05935930515430411
Trained batch 245 in epoch 12, gen_loss = 0.8709409690000177, disc_loss = 0.05926256199798933
Trained batch 246 in epoch 12, gen_loss = 0.8707874335258113, disc_loss = 0.05909644426242543
Trained batch 247 in epoch 12, gen_loss = 0.8719235262082469, disc_loss = 0.05899752344515535
Trained batch 248 in epoch 12, gen_loss = 0.8722399683841261, disc_loss = 0.05885014380795889
Trained batch 249 in epoch 12, gen_loss = 0.8716602582931519, disc_loss = 0.05888177341222763
Trained batch 250 in epoch 12, gen_loss = 0.8714847958895314, disc_loss = 0.058729202772279186
Trained batch 251 in epoch 12, gen_loss = 0.8716002120858147, disc_loss = 0.05854773888778356
Trained batch 252 in epoch 12, gen_loss = 0.8721912788308185, disc_loss = 0.05837810811818588
Trained batch 253 in epoch 12, gen_loss = 0.8721964868504232, disc_loss = 0.05871204809674362
Trained batch 254 in epoch 12, gen_loss = 0.8713422955251208, disc_loss = 0.05872671011762292
Trained batch 255 in epoch 12, gen_loss = 0.8708634756039828, disc_loss = 0.0586474370866199
Trained batch 256 in epoch 12, gen_loss = 0.8712904195841185, disc_loss = 0.05853907987910254
Trained batch 257 in epoch 12, gen_loss = 0.8706228009952132, disc_loss = 0.05846976405803778
Trained batch 258 in epoch 12, gen_loss = 0.8706665414180534, disc_loss = 0.058299223791707204
Trained batch 259 in epoch 12, gen_loss = 0.8715361253573344, disc_loss = 0.058390651603874105
Trained batch 260 in epoch 12, gen_loss = 0.871859769483179, disc_loss = 0.05821123522959678
Trained batch 261 in epoch 12, gen_loss = 0.871288186948718, disc_loss = 0.058225964622586286
Trained batch 262 in epoch 12, gen_loss = 0.8717615237254154, disc_loss = 0.05804795149302981
Trained batch 263 in epoch 12, gen_loss = 0.8714829419146884, disc_loss = 0.058122324341005
Trained batch 264 in epoch 12, gen_loss = 0.8717738428205813, disc_loss = 0.0579775334248003
Trained batch 265 in epoch 12, gen_loss = 0.8721159535243099, disc_loss = 0.05779853175723351
Trained batch 266 in epoch 12, gen_loss = 0.8718985091434436, disc_loss = 0.0576396808725841
Trained batch 267 in epoch 12, gen_loss = 0.8721644882835559, disc_loss = 0.057458186330996565
Trained batch 268 in epoch 12, gen_loss = 0.8723195859933874, disc_loss = 0.05776645426316443
Trained batch 269 in epoch 12, gen_loss = 0.8714417965323836, disc_loss = 0.05816064687031838
Trained batch 270 in epoch 12, gen_loss = 0.8713295140829473, disc_loss = 0.05799847996941462
Trained batch 271 in epoch 12, gen_loss = 0.8707727511577746, disc_loss = 0.05792961326112751
Trained batch 272 in epoch 12, gen_loss = 0.8718892093543168, disc_loss = 0.05801432286713259
Trained batch 273 in epoch 12, gen_loss = 0.8711038586432046, disc_loss = 0.05812581564999954
Trained batch 274 in epoch 12, gen_loss = 0.8708734934980219, disc_loss = 0.0581905523924665
Trained batch 275 in epoch 12, gen_loss = 0.8722390418035396, disc_loss = 0.05857888648650893
Trained batch 276 in epoch 12, gen_loss = 0.8715007541842409, disc_loss = 0.0586567870391674
Trained batch 277 in epoch 12, gen_loss = 0.8699380926948657, disc_loss = 0.059648639720147674
Trained batch 278 in epoch 12, gen_loss = 0.8703151067525255, disc_loss = 0.05987361230049616
Trained batch 279 in epoch 12, gen_loss = 0.8710922583937645, disc_loss = 0.060170963369975135
Trained batch 280 in epoch 12, gen_loss = 0.8710253245041464, disc_loss = 0.06015169174075657
Trained batch 281 in epoch 12, gen_loss = 0.8706924545426741, disc_loss = 0.060159356052597576
Trained batch 282 in epoch 12, gen_loss = 0.869889938999823, disc_loss = 0.06046691738635091
Trained batch 283 in epoch 12, gen_loss = 0.8706650043457327, disc_loss = 0.06084869682959373
Trained batch 284 in epoch 12, gen_loss = 0.8708234751433657, disc_loss = 0.0608578998954934
Trained batch 285 in epoch 12, gen_loss = 0.8694809687721146, disc_loss = 0.06149821130923562
Trained batch 286 in epoch 12, gen_loss = 0.8698344006355632, disc_loss = 0.061478449690450986
Trained batch 287 in epoch 12, gen_loss = 0.8699628772834936, disc_loss = 0.06157036843877803
Trained batch 288 in epoch 12, gen_loss = 0.8689009281178247, disc_loss = 0.061815224139980175
Trained batch 289 in epoch 12, gen_loss = 0.8690822247801155, disc_loss = 0.06173957530087952
Trained batch 290 in epoch 12, gen_loss = 0.8692229127965841, disc_loss = 0.0616473815087037
Trained batch 291 in epoch 12, gen_loss = 0.8695002522778837, disc_loss = 0.061799197767108474
Trained batch 292 in epoch 12, gen_loss = 0.8687689941084019, disc_loss = 0.06211791702771858
Trained batch 293 in epoch 12, gen_loss = 0.8688551173323676, disc_loss = 0.061976049706770654
Trained batch 294 in epoch 12, gen_loss = 0.8692966412689727, disc_loss = 0.06188481951732252
Trained batch 295 in epoch 12, gen_loss = 0.8697583304869162, disc_loss = 0.06178407873517859
Trained batch 296 in epoch 12, gen_loss = 0.8698218531078763, disc_loss = 0.06162644333209253
Trained batch 297 in epoch 12, gen_loss = 0.8697343158641918, disc_loss = 0.06158995223325371
Trained batch 298 in epoch 12, gen_loss = 0.8693732942227137, disc_loss = 0.06149284576492565
Trained batch 299 in epoch 12, gen_loss = 0.8694384266932805, disc_loss = 0.06139129516979058
Trained batch 300 in epoch 12, gen_loss = 0.8686326284741246, disc_loss = 0.06147365858685535
Trained batch 301 in epoch 12, gen_loss = 0.8679254870146316, disc_loss = 0.061548217612978635
Trained batch 302 in epoch 12, gen_loss = 0.8681121637718906, disc_loss = 0.06139008692241345
Trained batch 303 in epoch 12, gen_loss = 0.8687893809064439, disc_loss = 0.061357083497568965
Trained batch 304 in epoch 12, gen_loss = 0.8686684927002328, disc_loss = 0.06124848515772428
Trained batch 305 in epoch 12, gen_loss = 0.8694286367862053, disc_loss = 0.06110928546077286
Trained batch 306 in epoch 12, gen_loss = 0.8695011228225907, disc_loss = 0.060957015743812834
Trained batch 307 in epoch 12, gen_loss = 0.8691505048569147, disc_loss = 0.06092793596666548
Trained batch 308 in epoch 12, gen_loss = 0.8697736948053428, disc_loss = 0.06098011703287706
Trained batch 309 in epoch 12, gen_loss = 0.8695136399038377, disc_loss = 0.06085217702653139
Trained batch 310 in epoch 12, gen_loss = 0.870108349338605, disc_loss = 0.06086110965112206
Trained batch 311 in epoch 12, gen_loss = 0.8698279613103622, disc_loss = 0.06071712573966346
Trained batch 312 in epoch 12, gen_loss = 0.8701543895581278, disc_loss = 0.06062969720711152
Trained batch 313 in epoch 12, gen_loss = 0.870662320950988, disc_loss = 0.06048599651949421
Trained batch 314 in epoch 12, gen_loss = 0.869708250060914, disc_loss = 0.06066207963795889
Trained batch 315 in epoch 12, gen_loss = 0.869852517035943, disc_loss = 0.06050586273386792
Trained batch 316 in epoch 12, gen_loss = 0.869901856413399, disc_loss = 0.06037127250975897
Trained batch 317 in epoch 12, gen_loss = 0.8695745552485844, disc_loss = 0.06025597024064675
Trained batch 318 in epoch 12, gen_loss = 0.8694205046821164, disc_loss = 0.060096836316057695
Trained batch 319 in epoch 12, gen_loss = 0.8689951060339809, disc_loss = 0.06006305277987849
Trained batch 320 in epoch 12, gen_loss = 0.8689786730525649, disc_loss = 0.05994891149290718
Trained batch 321 in epoch 12, gen_loss = 0.8696251674468473, disc_loss = 0.05985058153117573
Trained batch 322 in epoch 12, gen_loss = 0.8695660873832348, disc_loss = 0.05971476405386124
Trained batch 323 in epoch 12, gen_loss = 0.8689119859978005, disc_loss = 0.059740537153786896
Trained batch 324 in epoch 12, gen_loss = 0.8685834140043992, disc_loss = 0.0596122882887721
Trained batch 325 in epoch 12, gen_loss = 0.867796702984652, disc_loss = 0.059631706629679794
Trained batch 326 in epoch 12, gen_loss = 0.8675448734096796, disc_loss = 0.05960766745258453
Trained batch 327 in epoch 12, gen_loss = 0.8678388326633267, disc_loss = 0.05988979496050444
Trained batch 328 in epoch 12, gen_loss = 0.8686038614406412, disc_loss = 0.0597609285304838
Trained batch 329 in epoch 12, gen_loss = 0.8676931128357396, disc_loss = 0.0600072485620551
Trained batch 330 in epoch 12, gen_loss = 0.8670829408478521, disc_loss = 0.060099438049484415
Trained batch 331 in epoch 12, gen_loss = 0.8683310427579535, disc_loss = 0.06056337237234665
Trained batch 332 in epoch 12, gen_loss = 0.8682918602281863, disc_loss = 0.06045666922935405
Trained batch 333 in epoch 12, gen_loss = 0.8680219835863856, disc_loss = 0.060335800288702376
Trained batch 334 in epoch 12, gen_loss = 0.868572266422101, disc_loss = 0.06036438020363228
Trained batch 335 in epoch 12, gen_loss = 0.8676404310833841, disc_loss = 0.06066163118451923
Trained batch 336 in epoch 12, gen_loss = 0.8683001991549302, disc_loss = 0.06069761878625664
Trained batch 337 in epoch 12, gen_loss = 0.868123857403648, disc_loss = 0.06059883144469215
Trained batch 338 in epoch 12, gen_loss = 0.8688497116080428, disc_loss = 0.060499696986843175
Trained batch 339 in epoch 12, gen_loss = 0.8682915401809356, disc_loss = 0.06052155637949267
Trained batch 340 in epoch 12, gen_loss = 0.8677591989117284, disc_loss = 0.06040762270093401
Trained batch 341 in epoch 12, gen_loss = 0.8681339285178491, disc_loss = 0.06026449821050665
Trained batch 342 in epoch 12, gen_loss = 0.8684620829434854, disc_loss = 0.06013212041554663
Trained batch 343 in epoch 12, gen_loss = 0.8680862540075945, disc_loss = 0.06021735656107668
Trained batch 344 in epoch 12, gen_loss = 0.8676964951598126, disc_loss = 0.060113655497738415
Trained batch 345 in epoch 12, gen_loss = 0.8677486844490029, disc_loss = 0.06002172117385303
Trained batch 346 in epoch 12, gen_loss = 0.8676030019174735, disc_loss = 0.05994839063692591
Trained batch 347 in epoch 12, gen_loss = 0.8678236160127596, disc_loss = 0.05980277743094183
Trained batch 348 in epoch 12, gen_loss = 0.8682324993917798, disc_loss = 0.059749655412205824
Trained batch 349 in epoch 12, gen_loss = 0.868685074363436, disc_loss = 0.05960112742281386
Trained batch 350 in epoch 12, gen_loss = 0.8682166631744798, disc_loss = 0.059639786746872966
Trained batch 351 in epoch 12, gen_loss = 0.868687745014375, disc_loss = 0.059576949668222696
Trained batch 352 in epoch 12, gen_loss = 0.8681711939509125, disc_loss = 0.05955460643601569
Trained batch 353 in epoch 12, gen_loss = 0.869057196850157, disc_loss = 0.05986028586877352
Trained batch 354 in epoch 12, gen_loss = 0.8693369778109269, disc_loss = 0.05973646811563784
Trained batch 355 in epoch 12, gen_loss = 0.8684139231617531, disc_loss = 0.059965195142130334
Trained batch 356 in epoch 12, gen_loss = 0.8684470596767607, disc_loss = 0.0601838115754039
Trained batch 357 in epoch 12, gen_loss = 0.8688749924052361, disc_loss = 0.06005789253954365
Trained batch 358 in epoch 12, gen_loss = 0.8681019909866673, disc_loss = 0.06014784773899901
Trained batch 359 in epoch 12, gen_loss = 0.8687249458498425, disc_loss = 0.06002383917673594
Trained batch 360 in epoch 12, gen_loss = 0.8692947319009627, disc_loss = 0.060317465994207814
Trained batch 361 in epoch 12, gen_loss = 0.8685316695363482, disc_loss = 0.06053664908327615
Trained batch 362 in epoch 12, gen_loss = 0.8684916668686985, disc_loss = 0.060409114914163745
Trained batch 363 in epoch 12, gen_loss = 0.8683932697052484, disc_loss = 0.060524272885951365
Trained batch 364 in epoch 12, gen_loss = 0.8682904160186036, disc_loss = 0.060475851738289614
Trained batch 365 in epoch 12, gen_loss = 0.8676608625005503, disc_loss = 0.0607914814694983
Trained batch 366 in epoch 12, gen_loss = 0.8689786263967405, disc_loss = 0.06123244315791845
Trained batch 367 in epoch 12, gen_loss = 0.868867926299572, disc_loss = 0.061171756885216935
Trained batch 368 in epoch 12, gen_loss = 0.8682737150166416, disc_loss = 0.06139141429205574
Trained batch 369 in epoch 12, gen_loss = 0.8683078308363219, disc_loss = 0.061772404037214616
Trained batch 370 in epoch 12, gen_loss = 0.86806493403134, disc_loss = 0.06178082629154635
Trained batch 371 in epoch 12, gen_loss = 0.8678167161121163, disc_loss = 0.06175228923318848
Trained batch 372 in epoch 12, gen_loss = 0.8682571588828161, disc_loss = 0.06173322748282959
Trained batch 373 in epoch 12, gen_loss = 0.868098287340154, disc_loss = 0.06164356840047288
Trained batch 374 in epoch 12, gen_loss = 0.8673707501093546, disc_loss = 0.061651524196068445
Trained batch 375 in epoch 12, gen_loss = 0.8676705655265362, disc_loss = 0.06188651349672929
Trained batch 376 in epoch 12, gen_loss = 0.8671856296473536, disc_loss = 0.062014895908791445
Trained batch 377 in epoch 12, gen_loss = 0.8671727282975716, disc_loss = 0.06195772792059909
Trained batch 378 in epoch 12, gen_loss = 0.868224458046513, disc_loss = 0.062117170257429966
Trained batch 379 in epoch 12, gen_loss = 0.8684252902081139, disc_loss = 0.0619927404497407
Trained batch 380 in epoch 12, gen_loss = 0.868313619783857, disc_loss = 0.0619543607143827
Trained batch 381 in epoch 12, gen_loss = 0.8679377282165108, disc_loss = 0.061943761316854605
Trained batch 382 in epoch 12, gen_loss = 0.8675789160765804, disc_loss = 0.061865038503515817
Trained batch 383 in epoch 12, gen_loss = 0.8676495205921432, disc_loss = 0.061746366094060555
Trained batch 384 in epoch 12, gen_loss = 0.8678040204110083, disc_loss = 0.061698202019581545
Trained batch 385 in epoch 12, gen_loss = 0.8680249287365632, disc_loss = 0.06157013751962102
Trained batch 386 in epoch 12, gen_loss = 0.8682321226874063, disc_loss = 0.0614337780000281
Trained batch 387 in epoch 12, gen_loss = 0.8679573376154163, disc_loss = 0.06133369342712013
Trained batch 388 in epoch 12, gen_loss = 0.8677397702837358, disc_loss = 0.06125053767938464
Trained batch 389 in epoch 12, gen_loss = 0.8680571063970908, disc_loss = 0.06117556666095669
Trained batch 390 in epoch 12, gen_loss = 0.8679798073171044, disc_loss = 0.06119451059928864
Trained batch 391 in epoch 12, gen_loss = 0.8676521811558275, disc_loss = 0.06123780854264921
Trained batch 392 in epoch 12, gen_loss = 0.8677741880635269, disc_loss = 0.06114622480627007
Trained batch 393 in epoch 12, gen_loss = 0.8671548753825541, disc_loss = 0.061205252024066174
Trained batch 394 in epoch 12, gen_loss = 0.8680310976656177, disc_loss = 0.06114434828345157
Trained batch 395 in epoch 12, gen_loss = 0.8682962189419101, disc_loss = 0.06117101700628421
Trained batch 396 in epoch 12, gen_loss = 0.8675257604128167, disc_loss = 0.061380442787872004
Trained batch 397 in epoch 12, gen_loss = 0.8681900821738506, disc_loss = 0.061336012587569017
Trained batch 398 in epoch 12, gen_loss = 0.867886405540887, disc_loss = 0.06131849623049486
Trained batch 399 in epoch 12, gen_loss = 0.8683294916152954, disc_loss = 0.06141150197247043
Trained batch 400 in epoch 12, gen_loss = 0.8678946310742538, disc_loss = 0.061438913712570646
Trained batch 401 in epoch 12, gen_loss = 0.8671054353761436, disc_loss = 0.06180455878756903
Trained batch 402 in epoch 12, gen_loss = 0.8673214335595408, disc_loss = 0.061863510157663386
Trained batch 403 in epoch 12, gen_loss = 0.8675999428966258, disc_loss = 0.061921783125876345
Trained batch 404 in epoch 12, gen_loss = 0.8679381959232283, disc_loss = 0.061808966755591055
Trained batch 405 in epoch 12, gen_loss = 0.8671902241965233, disc_loss = 0.06203508132316282
Trained batch 406 in epoch 12, gen_loss = 0.8678197354005068, disc_loss = 0.0619238027387484
Trained batch 407 in epoch 12, gen_loss = 0.8681347522081113, disc_loss = 0.062041545156663394
Trained batch 408 in epoch 12, gen_loss = 0.8679294743572878, disc_loss = 0.061985768767160276
Trained batch 409 in epoch 12, gen_loss = 0.8681423124743671, disc_loss = 0.061875833750407144
Trained batch 410 in epoch 12, gen_loss = 0.8683785214621366, disc_loss = 0.061791706782677314
Trained batch 411 in epoch 12, gen_loss = 0.868467216786829, disc_loss = 0.061684170093622454
Trained batch 412 in epoch 12, gen_loss = 0.8689777055895068, disc_loss = 0.061569512537601644
Trained batch 413 in epoch 12, gen_loss = 0.8691765385261481, disc_loss = 0.061442616798325585
Trained batch 414 in epoch 12, gen_loss = 0.8694201052907001, disc_loss = 0.06136185087218701
Trained batch 415 in epoch 12, gen_loss = 0.8696606546067275, disc_loss = 0.061267521646536455
Trained batch 416 in epoch 12, gen_loss = 0.8698341227549728, disc_loss = 0.061140728518098805
Trained batch 417 in epoch 12, gen_loss = 0.8698790665163377, disc_loss = 0.06102550205770149
Trained batch 418 in epoch 12, gen_loss = 0.8695745422618202, disc_loss = 0.06101057565102003
Trained batch 419 in epoch 12, gen_loss = 0.8691899004436675, disc_loss = 0.06104665581757824
Trained batch 420 in epoch 12, gen_loss = 0.8695139579138677, disc_loss = 0.06115458757481637
Trained batch 421 in epoch 12, gen_loss = 0.87019369839492, disc_loss = 0.0610454425930765
Trained batch 422 in epoch 12, gen_loss = 0.869748006193914, disc_loss = 0.06104404514932886
Trained batch 423 in epoch 12, gen_loss = 0.8696375986877477, disc_loss = 0.06092476488732434
Trained batch 424 in epoch 12, gen_loss = 0.8698107314109802, disc_loss = 0.0608066326379776
Trained batch 425 in epoch 12, gen_loss = 0.8699512673375752, disc_loss = 0.060884610762898354
Trained batch 426 in epoch 12, gen_loss = 0.8700074613513098, disc_loss = 0.06080722925743956
Trained batch 427 in epoch 12, gen_loss = 0.8698443230067459, disc_loss = 0.060701015135534456
Trained batch 428 in epoch 12, gen_loss = 0.8699679456668578, disc_loss = 0.060610261439651876
Trained batch 429 in epoch 12, gen_loss = 0.8693729155285413, disc_loss = 0.060676871716629624
Trained batch 430 in epoch 12, gen_loss = 0.8704394617932578, disc_loss = 0.060677411194605506
Trained batch 431 in epoch 12, gen_loss = 0.8709579572357513, disc_loss = 0.060627556380091444
Trained batch 432 in epoch 12, gen_loss = 0.8712558371916104, disc_loss = 0.06051377804549819
Trained batch 433 in epoch 12, gen_loss = 0.8708879906460986, disc_loss = 0.06045169636074986
Trained batch 434 in epoch 12, gen_loss = 0.8708264054923222, disc_loss = 0.06038982430151824
Trained batch 435 in epoch 12, gen_loss = 0.870902249435766, disc_loss = 0.06028604604850669
Trained batch 436 in epoch 12, gen_loss = 0.870924375013574, disc_loss = 0.06020632046072379
Trained batch 437 in epoch 12, gen_loss = 0.8712131454520029, disc_loss = 0.06008510179732624
Trained batch 438 in epoch 12, gen_loss = 0.8718339728874607, disc_loss = 0.05999210884620633
Trained batch 439 in epoch 12, gen_loss = 0.8718191919001665, disc_loss = 0.05988875547508624
Trained batch 440 in epoch 12, gen_loss = 0.8719836046365924, disc_loss = 0.05988543762354488
Trained batch 441 in epoch 12, gen_loss = 0.8719961686371678, disc_loss = 0.05979832572803508
Trained batch 442 in epoch 12, gen_loss = 0.871868447444778, disc_loss = 0.059761903650268206
Trained batch 443 in epoch 12, gen_loss = 0.8724732376165218, disc_loss = 0.05970540782017214
Trained batch 444 in epoch 12, gen_loss = 0.8727474038520556, disc_loss = 0.059590055291237454
Trained batch 445 in epoch 12, gen_loss = 0.8733644766123305, disc_loss = 0.059509089533991345
Trained batch 446 in epoch 12, gen_loss = 0.8733587614375207, disc_loss = 0.05940255412927743
Trained batch 447 in epoch 12, gen_loss = 0.8730654809623957, disc_loss = 0.059331084819859825
Trained batch 448 in epoch 12, gen_loss = 0.873281101607002, disc_loss = 0.05922982097086901
Trained batch 449 in epoch 12, gen_loss = 0.8731500245465172, disc_loss = 0.059129592925310136
Trained batch 450 in epoch 12, gen_loss = 0.87340790469472, disc_loss = 0.059015066792440916
Trained batch 451 in epoch 12, gen_loss = 0.8730224821947318, disc_loss = 0.05892856362836221
Trained batch 452 in epoch 12, gen_loss = 0.8730310856901258, disc_loss = 0.05882417554730677
Trained batch 453 in epoch 12, gen_loss = 0.8728885128109466, disc_loss = 0.05876981656760437
Trained batch 454 in epoch 12, gen_loss = 0.8733529931896336, disc_loss = 0.05868140949693682
Trained batch 455 in epoch 12, gen_loss = 0.8736476508671778, disc_loss = 0.058671086636502626
Trained batch 456 in epoch 12, gen_loss = 0.8728549569127857, disc_loss = 0.05883394664508052
Trained batch 457 in epoch 12, gen_loss = 0.8733241196282566, disc_loss = 0.05873814015750932
Trained batch 458 in epoch 12, gen_loss = 0.8733636201856443, disc_loss = 0.058668123468886536
Trained batch 459 in epoch 12, gen_loss = 0.8732303108858026, disc_loss = 0.0586239309940973
Trained batch 460 in epoch 12, gen_loss = 0.8736094898360411, disc_loss = 0.05852883743675761
Trained batch 461 in epoch 12, gen_loss = 0.8730302533029994, disc_loss = 0.05854013300746744
Trained batch 462 in epoch 12, gen_loss = 0.8731180367665466, disc_loss = 0.05862875284172482
Trained batch 463 in epoch 12, gen_loss = 0.8737804876833126, disc_loss = 0.05854855029610917
Trained batch 464 in epoch 12, gen_loss = 0.873271260851173, disc_loss = 0.058657511281630687
Trained batch 465 in epoch 12, gen_loss = 0.8731413176642978, disc_loss = 0.058912008311279726
Trained batch 466 in epoch 12, gen_loss = 0.8724783033579269, disc_loss = 0.059080027392816106
Trained batch 467 in epoch 12, gen_loss = 0.871996138849829, disc_loss = 0.05911057991469199
Trained batch 468 in epoch 12, gen_loss = 0.8727914562611692, disc_loss = 0.05927653901223371
Trained batch 469 in epoch 12, gen_loss = 0.8726923797992949, disc_loss = 0.05920217086937516
Trained batch 470 in epoch 12, gen_loss = 0.8723107702919379, disc_loss = 0.05918984617958846
Trained batch 471 in epoch 12, gen_loss = 0.8726886225453878, disc_loss = 0.05915271062838008
Trained batch 472 in epoch 12, gen_loss = 0.8722586004224943, disc_loss = 0.05912162805956653
Trained batch 473 in epoch 12, gen_loss = 0.8724984545496446, disc_loss = 0.059040476283144974
Trained batch 474 in epoch 12, gen_loss = 0.8722504777657358, disc_loss = 0.05903291677369883
Trained batch 475 in epoch 12, gen_loss = 0.8723337180724665, disc_loss = 0.059037445036757015
Trained batch 476 in epoch 12, gen_loss = 0.8722959935540173, disc_loss = 0.058953177135055046
Trained batch 477 in epoch 12, gen_loss = 0.8722247736972745, disc_loss = 0.05885617731715782
Trained batch 478 in epoch 12, gen_loss = 0.8724684295923077, disc_loss = 0.058836317570619516
Trained batch 479 in epoch 12, gen_loss = 0.8721016044418017, disc_loss = 0.05878157051241336
Trained batch 480 in epoch 12, gen_loss = 0.8719679833449842, disc_loss = 0.05877648080794021
Trained batch 481 in epoch 12, gen_loss = 0.8728522408552685, disc_loss = 0.05882704218354896
Trained batch 482 in epoch 12, gen_loss = 0.8728538551685973, disc_loss = 0.058745507098826935
Trained batch 483 in epoch 12, gen_loss = 0.8728277436957872, disc_loss = 0.058916693570646494
Trained batch 484 in epoch 12, gen_loss = 0.8722870347426109, disc_loss = 0.05889771337400085
Trained batch 485 in epoch 12, gen_loss = 0.8719056133380152, disc_loss = 0.05896635159827125
Trained batch 486 in epoch 12, gen_loss = 0.8723219652685051, disc_loss = 0.058935999137863855
Trained batch 487 in epoch 12, gen_loss = 0.8719769428010846, disc_loss = 0.05890801730832909
Trained batch 488 in epoch 12, gen_loss = 0.872679169192636, disc_loss = 0.05948540542640386
Trained batch 489 in epoch 12, gen_loss = 0.8722852120594102, disc_loss = 0.05949044403410992
Trained batch 490 in epoch 12, gen_loss = 0.872038699216124, disc_loss = 0.05951001594704244
Trained batch 491 in epoch 12, gen_loss = 0.872290315666819, disc_loss = 0.059515859751878834
Trained batch 492 in epoch 12, gen_loss = 0.8719136505774987, disc_loss = 0.059598483706297424
Trained batch 493 in epoch 12, gen_loss = 0.8714792806851236, disc_loss = 0.05961362669349984
Trained batch 494 in epoch 12, gen_loss = 0.871279339958923, disc_loss = 0.05979042488404296
Trained batch 495 in epoch 12, gen_loss = 0.8713210632483805, disc_loss = 0.05975603903531127
Trained batch 496 in epoch 12, gen_loss = 0.8709016949597979, disc_loss = 0.05976867060583662
Trained batch 497 in epoch 12, gen_loss = 0.8705610668802836, disc_loss = 0.05975912637956231
Trained batch 498 in epoch 12, gen_loss = 0.8701577910440479, disc_loss = 0.059836757171503406
Trained batch 499 in epoch 12, gen_loss = 0.8706251168251038, disc_loss = 0.06019110729731619
Trained batch 500 in epoch 12, gen_loss = 0.870419302029524, disc_loss = 0.06013339278501962
Trained batch 501 in epoch 12, gen_loss = 0.8697833027022769, disc_loss = 0.06029042871149472
Trained batch 502 in epoch 12, gen_loss = 0.87010357820727, disc_loss = 0.06020396665131181
Trained batch 503 in epoch 12, gen_loss = 0.8704992473598511, disc_loss = 0.0601270953877016
Trained batch 504 in epoch 12, gen_loss = 0.870462170685872, disc_loss = 0.0600713618413204
Trained batch 505 in epoch 12, gen_loss = 0.8706354053595321, disc_loss = 0.05996897784816359
Trained batch 506 in epoch 12, gen_loss = 0.8708603348017209, disc_loss = 0.060188763334068675
Trained batch 507 in epoch 12, gen_loss = 0.8702916011331588, disc_loss = 0.06016807897405068
Trained batch 508 in epoch 12, gen_loss = 0.8698594203632333, disc_loss = 0.06025893576187036
Trained batch 509 in epoch 12, gen_loss = 0.8695763219805325, disc_loss = 0.06023885962535061
Trained batch 510 in epoch 12, gen_loss = 0.8699128540294744, disc_loss = 0.06017121597723543
Trained batch 511 in epoch 12, gen_loss = 0.8701862042071298, disc_loss = 0.0601874150979711
Trained batch 512 in epoch 12, gen_loss = 0.8697753082706682, disc_loss = 0.06022003350586977
Trained batch 513 in epoch 12, gen_loss = 0.8694129661595311, disc_loss = 0.06021926918244606
Trained batch 514 in epoch 12, gen_loss = 0.8700782246960019, disc_loss = 0.06014565783688455
Trained batch 515 in epoch 12, gen_loss = 0.8703964670268141, disc_loss = 0.060153552152346385
Trained batch 516 in epoch 12, gen_loss = 0.8702194975469283, disc_loss = 0.060089454294418344
Trained batch 517 in epoch 12, gen_loss = 0.8695934066210934, disc_loss = 0.06011490182390142
Trained batch 518 in epoch 12, gen_loss = 0.8692707017437341, disc_loss = 0.0600565265207363
Trained batch 519 in epoch 12, gen_loss = 0.8699487877579836, disc_loss = 0.06038405412199119
Trained batch 520 in epoch 12, gen_loss = 0.8694452545006764, disc_loss = 0.060546060940054124
Trained batch 521 in epoch 12, gen_loss = 0.8692813634415696, disc_loss = 0.06047709969718052
Trained batch 522 in epoch 12, gen_loss = 0.8693644793038159, disc_loss = 0.06045396531082647
Trained batch 523 in epoch 12, gen_loss = 0.8690134120806483, disc_loss = 0.060469262264597846
Trained batch 524 in epoch 12, gen_loss = 0.8688807085582189, disc_loss = 0.060412476919591424
Trained batch 525 in epoch 12, gen_loss = 0.8686025837301755, disc_loss = 0.060345616841426704
Trained batch 526 in epoch 12, gen_loss = 0.8684045710871297, disc_loss = 0.06026366539122766
Trained batch 527 in epoch 12, gen_loss = 0.8684125995319901, disc_loss = 0.060224353944332426
Trained batch 528 in epoch 12, gen_loss = 0.8683221070888137, disc_loss = 0.06025152484620508
Trained batch 529 in epoch 12, gen_loss = 0.8681244706207851, disc_loss = 0.06026695625294211
Trained batch 530 in epoch 12, gen_loss = 0.8678869419852219, disc_loss = 0.060243738729247154
Trained batch 531 in epoch 12, gen_loss = 0.8677623000808228, disc_loss = 0.06023314390926713
Trained batch 532 in epoch 12, gen_loss = 0.8686070113423617, disc_loss = 0.06041607316793074
Trained batch 533 in epoch 12, gen_loss = 0.8683052114333106, disc_loss = 0.06041455409255869
Trained batch 534 in epoch 12, gen_loss = 0.8684823675690411, disc_loss = 0.06031779177034291
Trained batch 535 in epoch 12, gen_loss = 0.8686684421194133, disc_loss = 0.06023803707246961
Trained batch 536 in epoch 12, gen_loss = 0.8686514426876046, disc_loss = 0.06018754825502412
Trained batch 537 in epoch 12, gen_loss = 0.868459029268598, disc_loss = 0.06016128491714154
Trained batch 538 in epoch 12, gen_loss = 0.8680198172691359, disc_loss = 0.060231823213260226
Trained batch 539 in epoch 12, gen_loss = 0.8688803041422809, disc_loss = 0.060805931364841484
Trained batch 540 in epoch 12, gen_loss = 0.8686434471232614, disc_loss = 0.06074281290084013
Trained batch 541 in epoch 12, gen_loss = 0.8685760441961323, disc_loss = 0.060703733171305424
Trained batch 542 in epoch 12, gen_loss = 0.8686127930495401, disc_loss = 0.0607211015429039
Trained batch 543 in epoch 12, gen_loss = 0.8682005992707085, disc_loss = 0.0607543941022253
Trained batch 544 in epoch 12, gen_loss = 0.8683377944001364, disc_loss = 0.06066769595266482
Trained batch 545 in epoch 12, gen_loss = 0.868470596743154, disc_loss = 0.06060934868801535
Trained batch 546 in epoch 12, gen_loss = 0.8687596146759647, disc_loss = 0.06067518525887996
Trained batch 547 in epoch 12, gen_loss = 0.8682384383286873, disc_loss = 0.06079374197666554
Trained batch 548 in epoch 12, gen_loss = 0.8682407731349785, disc_loss = 0.060712027772311085
Trained batch 549 in epoch 12, gen_loss = 0.8682376318628138, disc_loss = 0.0606394926560196
Trained batch 550 in epoch 12, gen_loss = 0.868305060370215, disc_loss = 0.06055851012279031
Trained batch 551 in epoch 12, gen_loss = 0.8681492879986763, disc_loss = 0.06051467046600537
Trained batch 552 in epoch 12, gen_loss = 0.8679712452465975, disc_loss = 0.06049409652866464
Trained batch 553 in epoch 12, gen_loss = 0.8673376206456539, disc_loss = 0.06070733063649184
Trained batch 554 in epoch 12, gen_loss = 0.8668965139904538, disc_loss = 0.06083682701662854
Trained batch 555 in epoch 12, gen_loss = 0.8669727046927103, disc_loss = 0.06080434859308193
Trained batch 556 in epoch 12, gen_loss = 0.8669805968685252, disc_loss = 0.06082132520886469
Trained batch 557 in epoch 12, gen_loss = 0.8667740580428885, disc_loss = 0.060774318620188686
Trained batch 558 in epoch 12, gen_loss = 0.8671551976946045, disc_loss = 0.06069219251678114
Trained batch 559 in epoch 12, gen_loss = 0.8670109127249036, disc_loss = 0.06062748230927225
Trained batch 560 in epoch 12, gen_loss = 0.8669129195697804, disc_loss = 0.06058585846633941
Trained batch 561 in epoch 12, gen_loss = 0.8670124174012832, disc_loss = 0.06049417259894126
Trained batch 562 in epoch 12, gen_loss = 0.8670424002737177, disc_loss = 0.060423638049652055
Trained batch 563 in epoch 12, gen_loss = 0.8672173380429018, disc_loss = 0.06042110293126064
Trained batch 564 in epoch 12, gen_loss = 0.8675530990668102, disc_loss = 0.06033290140990135
Trained batch 565 in epoch 12, gen_loss = 0.8670642733995148, disc_loss = 0.060378364339971076
Trained batch 566 in epoch 12, gen_loss = 0.8668517874031471, disc_loss = 0.06038771358497664
Trained batch 567 in epoch 12, gen_loss = 0.8669100295699818, disc_loss = 0.06029953750860418
Trained batch 568 in epoch 12, gen_loss = 0.8665782279205657, disc_loss = 0.06030390578893346
Trained batch 569 in epoch 12, gen_loss = 0.8671406010786692, disc_loss = 0.06043404827972776
Trained batch 570 in epoch 12, gen_loss = 0.8673382624853304, disc_loss = 0.06034792063924143
Trained batch 571 in epoch 12, gen_loss = 0.8668303697050869, disc_loss = 0.06045855648841683
Trained batch 572 in epoch 12, gen_loss = 0.8662476548973802, disc_loss = 0.06054241340899967
Trained batch 573 in epoch 12, gen_loss = 0.8668387329744545, disc_loss = 0.06084071963584174
Trained batch 574 in epoch 12, gen_loss = 0.8664664234285769, disc_loss = 0.060919780258251274
Trained batch 575 in epoch 12, gen_loss = 0.8661166374675102, disc_loss = 0.06094666082127434
Trained batch 576 in epoch 12, gen_loss = 0.8656728237712404, disc_loss = 0.060998010928492406
Trained batch 577 in epoch 12, gen_loss = 0.8656490846282471, disc_loss = 0.06099324566424924
Trained batch 578 in epoch 12, gen_loss = 0.8654576009831074, disc_loss = 0.06096828696744224
Trained batch 579 in epoch 12, gen_loss = 0.8654148133664296, disc_loss = 0.06089565383334612
Trained batch 580 in epoch 12, gen_loss = 0.8659888260746166, disc_loss = 0.06086044818188566
Trained batch 581 in epoch 12, gen_loss = 0.8659116575603223, disc_loss = 0.060810620886916966
Trained batch 582 in epoch 12, gen_loss = 0.8657268326646468, disc_loss = 0.06075402040283737
Trained batch 583 in epoch 12, gen_loss = 0.8660751489335543, disc_loss = 0.06070061344079265
Trained batch 584 in epoch 12, gen_loss = 0.866642654247773, disc_loss = 0.060689555340979855
Trained batch 585 in epoch 12, gen_loss = 0.8664647338740248, disc_loss = 0.06065102054740687
Trained batch 586 in epoch 12, gen_loss = 0.8661430738041308, disc_loss = 0.060640329406223874
Trained batch 587 in epoch 12, gen_loss = 0.8663834640566184, disc_loss = 0.06057017138164465
Trained batch 588 in epoch 12, gen_loss = 0.8665409177187545, disc_loss = 0.06056623638991791
Trained batch 589 in epoch 12, gen_loss = 0.8664669961242353, disc_loss = 0.06054775455998162
Trained batch 590 in epoch 12, gen_loss = 0.8664146694031666, disc_loss = 0.060522991855031544
Trained batch 591 in epoch 12, gen_loss = 0.8665278442203999, disc_loss = 0.06049674209459005
Trained batch 592 in epoch 12, gen_loss = 0.866474907977183, disc_loss = 0.06055999447985805
Trained batch 593 in epoch 12, gen_loss = 0.8664523586881683, disc_loss = 0.06058644495829187
Trained batch 594 in epoch 12, gen_loss = 0.8659673009599959, disc_loss = 0.06073136071698004
Trained batch 595 in epoch 12, gen_loss = 0.8658343674552521, disc_loss = 0.06084318841563775
Trained batch 596 in epoch 12, gen_loss = 0.8658806778478063, disc_loss = 0.06078595825325903
Trained batch 597 in epoch 12, gen_loss = 0.8658567756713433, disc_loss = 0.060765556854049496
Trained batch 598 in epoch 12, gen_loss = 0.8660982970602326, disc_loss = 0.06069244381556527
Trained batch 599 in epoch 12, gen_loss = 0.8661462781826655, disc_loss = 0.06064044609665871
Trained batch 600 in epoch 12, gen_loss = 0.8660253209996343, disc_loss = 0.06063063591470734
Trained batch 601 in epoch 12, gen_loss = 0.8658006148678916, disc_loss = 0.06064808379821603
Trained batch 602 in epoch 12, gen_loss = 0.8660405651846929, disc_loss = 0.06068701809812739
Trained batch 603 in epoch 12, gen_loss = 0.8661099197651376, disc_loss = 0.06061229132276201
Trained batch 604 in epoch 12, gen_loss = 0.8660580996639472, disc_loss = 0.060559694847661605
Trained batch 605 in epoch 12, gen_loss = 0.8664696186092427, disc_loss = 0.06050713066159204
Trained batch 606 in epoch 12, gen_loss = 0.8668953189150702, disc_loss = 0.060449858532092324
Trained batch 607 in epoch 12, gen_loss = 0.8667848608211467, disc_loss = 0.06039172779511366
Trained batch 608 in epoch 12, gen_loss = 0.8664188591521753, disc_loss = 0.060387346847671004
Trained batch 609 in epoch 12, gen_loss = 0.8667135524945181, disc_loss = 0.060407139003643244
Trained batch 610 in epoch 12, gen_loss = 0.8667016630281988, disc_loss = 0.060400510005616324
Trained batch 611 in epoch 12, gen_loss = 0.8663181185332778, disc_loss = 0.060461813392227184
Trained batch 612 in epoch 12, gen_loss = 0.8663045142642047, disc_loss = 0.06067122129167371
Trained batch 613 in epoch 12, gen_loss = 0.8660592741609008, disc_loss = 0.06074062896534461
Trained batch 614 in epoch 12, gen_loss = 0.8655460679434179, disc_loss = 0.06094790386051182
Trained batch 615 in epoch 12, gen_loss = 0.8654532393851837, disc_loss = 0.061189918757670304
Trained batch 616 in epoch 12, gen_loss = 0.8658393287194992, disc_loss = 0.061145466500274366
Trained batch 617 in epoch 12, gen_loss = 0.8655978440273927, disc_loss = 0.06113432861056818
Trained batch 618 in epoch 12, gen_loss = 0.8654008228482261, disc_loss = 0.06109290791792804
Trained batch 619 in epoch 12, gen_loss = 0.8656955404627708, disc_loss = 0.061057230845213896
Trained batch 620 in epoch 12, gen_loss = 0.8653912251506258, disc_loss = 0.06103244674318559
Trained batch 621 in epoch 12, gen_loss = 0.8650084913160256, disc_loss = 0.06106516832360021
Trained batch 622 in epoch 12, gen_loss = 0.8652218060738394, disc_loss = 0.06112178170793416
Trained batch 623 in epoch 12, gen_loss = 0.8650193297519133, disc_loss = 0.06115969799112719
Trained batch 624 in epoch 12, gen_loss = 0.8649855200767517, disc_loss = 0.06110181972384453
Trained batch 625 in epoch 12, gen_loss = 0.8647825739825495, disc_loss = 0.061059145256876945
Trained batch 626 in epoch 12, gen_loss = 0.865459415235778, disc_loss = 0.061374625229711925
Trained batch 627 in epoch 12, gen_loss = 0.8653115754484371, disc_loss = 0.06137649460464336
Trained batch 628 in epoch 12, gen_loss = 0.864962083830932, disc_loss = 0.06146663390040777
Trained batch 629 in epoch 12, gen_loss = 0.8652136449775999, disc_loss = 0.06157332250168399
Trained batch 630 in epoch 12, gen_loss = 0.8652706088619262, disc_loss = 0.06151422985169665
Trained batch 631 in epoch 12, gen_loss = 0.8653712005743498, disc_loss = 0.061439040949556364
Trained batch 632 in epoch 12, gen_loss = 0.8655587793526491, disc_loss = 0.0613563289147865
Trained batch 633 in epoch 12, gen_loss = 0.8655024312836138, disc_loss = 0.06130066126649641
Trained batch 634 in epoch 12, gen_loss = 0.8658601052179111, disc_loss = 0.06129114424120488
Trained batch 635 in epoch 12, gen_loss = 0.8654695645255862, disc_loss = 0.06128202170080874
Trained batch 636 in epoch 12, gen_loss = 0.8652387405489828, disc_loss = 0.0613516022552103
Trained batch 637 in epoch 12, gen_loss = 0.865770075855584, disc_loss = 0.06146327402518601
Trained batch 638 in epoch 12, gen_loss = 0.8657047472462781, disc_loss = 0.0613860696691186
Trained batch 639 in epoch 12, gen_loss = 0.8653539718128741, disc_loss = 0.06140478903398616
Trained batch 640 in epoch 12, gen_loss = 0.8658088028151978, disc_loss = 0.0613786695269336
Trained batch 641 in epoch 12, gen_loss = 0.865390416246337, disc_loss = 0.06151517941776048
Trained batch 642 in epoch 12, gen_loss = 0.8650644085084669, disc_loss = 0.06158117499654391
Trained batch 643 in epoch 12, gen_loss = 0.8654781985356941, disc_loss = 0.061891999042170666
Trained batch 644 in epoch 12, gen_loss = 0.8650931047838788, disc_loss = 0.0619201650149947
Trained batch 645 in epoch 12, gen_loss = 0.86534691078375, disc_loss = 0.0621045913371393
Trained batch 646 in epoch 12, gen_loss = 0.8655218856043573, disc_loss = 0.062030318576030696
Trained batch 647 in epoch 12, gen_loss = 0.8650866898673552, disc_loss = 0.06213582472525031
Trained batch 648 in epoch 12, gen_loss = 0.8649176944202194, disc_loss = 0.06211371224327659
Trained batch 649 in epoch 12, gen_loss = 0.8654241511454949, disc_loss = 0.0623214891137412
Trained batch 650 in epoch 12, gen_loss = 0.8652156000862473, disc_loss = 0.06229681055706721
Trained batch 651 in epoch 12, gen_loss = 0.8649310226455057, disc_loss = 0.062332405998697216
Trained batch 652 in epoch 12, gen_loss = 0.8651837190844198, disc_loss = 0.062275224276868255
Trained batch 653 in epoch 12, gen_loss = 0.8651755258030848, disc_loss = 0.06222815753960418
Trained batch 654 in epoch 12, gen_loss = 0.8648826055854332, disc_loss = 0.06219180027691235
Trained batch 655 in epoch 12, gen_loss = 0.8647529242060533, disc_loss = 0.062143340943915
Trained batch 656 in epoch 12, gen_loss = 0.864930772073737, disc_loss = 0.06213560437179728
Trained batch 657 in epoch 12, gen_loss = 0.8651940751039511, disc_loss = 0.06210516498913836
Trained batch 658 in epoch 12, gen_loss = 0.8648486523599291, disc_loss = 0.06210082055851026
Trained batch 659 in epoch 12, gen_loss = 0.8649937496943907, disc_loss = 0.0620308514867881
Trained batch 660 in epoch 12, gen_loss = 0.8649373921071166, disc_loss = 0.061967300483604694
Trained batch 661 in epoch 12, gen_loss = 0.8649851427697703, disc_loss = 0.061890562479961046
Trained batch 662 in epoch 12, gen_loss = 0.8649933039692552, disc_loss = 0.061845969640527645
Trained batch 663 in epoch 12, gen_loss = 0.864973970026855, disc_loss = 0.06189518812510847
Trained batch 664 in epoch 12, gen_loss = 0.8648713513424522, disc_loss = 0.06185953113621563
Trained batch 665 in epoch 12, gen_loss = 0.8650343199749967, disc_loss = 0.0617897048181443
Trained batch 666 in epoch 12, gen_loss = 0.865566639707185, disc_loss = 0.061729806587044175
Trained batch 667 in epoch 12, gen_loss = 0.8651108642716607, disc_loss = 0.06175386416168136
Trained batch 668 in epoch 12, gen_loss = 0.8653748834614262, disc_loss = 0.06192715398226663
Trained batch 669 in epoch 12, gen_loss = 0.8650093673770107, disc_loss = 0.06194985467912768
Trained batch 670 in epoch 12, gen_loss = 0.8650623027862628, disc_loss = 0.061911031205468044
Trained batch 671 in epoch 12, gen_loss = 0.8650720662304333, disc_loss = 0.061872256987650566
Trained batch 672 in epoch 12, gen_loss = 0.8652143115274619, disc_loss = 0.06182526568307875
Trained batch 673 in epoch 12, gen_loss = 0.8645814384391824, disc_loss = 0.06192956447396814
Trained batch 674 in epoch 12, gen_loss = 0.8651526319980621, disc_loss = 0.06191086760687607
Trained batch 675 in epoch 12, gen_loss = 0.8652873291859965, disc_loss = 0.0619157037722531
Trained batch 676 in epoch 12, gen_loss = 0.8650646616032064, disc_loss = 0.06189879530042058
Trained batch 677 in epoch 12, gen_loss = 0.8649107604163938, disc_loss = 0.06199335798505792
Trained batch 678 in epoch 12, gen_loss = 0.8651973907568318, disc_loss = 0.0619290591984307
Trained batch 679 in epoch 12, gen_loss = 0.8650131386430825, disc_loss = 0.061904706941534056
Trained batch 680 in epoch 12, gen_loss = 0.8648425023373704, disc_loss = 0.061872844909770464
Trained batch 681 in epoch 12, gen_loss = 0.8647759244326623, disc_loss = 0.06186315954643742
Trained batch 682 in epoch 12, gen_loss = 0.8645983495003657, disc_loss = 0.061813976502490514
Trained batch 683 in epoch 12, gen_loss = 0.864938325221427, disc_loss = 0.06178296544883204
Trained batch 684 in epoch 12, gen_loss = 0.8649549350686317, disc_loss = 0.06172112795748632
Trained batch 685 in epoch 12, gen_loss = 0.8651258164783261, disc_loss = 0.06164523712888838
Trained batch 686 in epoch 12, gen_loss = 0.8652834562148243, disc_loss = 0.06165016763823261
Trained batch 687 in epoch 12, gen_loss = 0.8654588041177322, disc_loss = 0.061596941557539586
Trained batch 688 in epoch 12, gen_loss = 0.8652386009174092, disc_loss = 0.06161131440284723
Trained batch 689 in epoch 12, gen_loss = 0.8652207014785297, disc_loss = 0.06156041981463415
Trained batch 690 in epoch 12, gen_loss = 0.865646339316789, disc_loss = 0.06163386945301389
Trained batch 691 in epoch 12, gen_loss = 0.8661627750090092, disc_loss = 0.06166498075277044
Trained batch 692 in epoch 12, gen_loss = 0.8662175838479405, disc_loss = 0.06162866683136591
Trained batch 693 in epoch 12, gen_loss = 0.8658956227883138, disc_loss = 0.0617137031028482
Trained batch 694 in epoch 12, gen_loss = 0.8655141276850117, disc_loss = 0.061872393147443694
Trained batch 695 in epoch 12, gen_loss = 0.8661605764137602, disc_loss = 0.062327688835539866
Trained batch 696 in epoch 12, gen_loss = 0.8664064329101502, disc_loss = 0.06225769701741176
Trained batch 697 in epoch 12, gen_loss = 0.8666387393771748, disc_loss = 0.06222990783395774
Trained batch 698 in epoch 12, gen_loss = 0.8664995983179035, disc_loss = 0.06220664985168816
Trained batch 699 in epoch 12, gen_loss = 0.8665688426579747, disc_loss = 0.062137904978756396
Trained batch 700 in epoch 12, gen_loss = 0.8665138420551888, disc_loss = 0.06210723970770921
Trained batch 701 in epoch 12, gen_loss = 0.8665686501481934, disc_loss = 0.0621038717682078
Trained batch 702 in epoch 12, gen_loss = 0.8666076775041447, disc_loss = 0.062053348545838216
Trained batch 703 in epoch 12, gen_loss = 0.8666689651171592, disc_loss = 0.06200649516011419
Trained batch 704 in epoch 12, gen_loss = 0.8669229848587766, disc_loss = 0.06193025803576547
Trained batch 705 in epoch 12, gen_loss = 0.867042178261719, disc_loss = 0.06187539170667656
Trained batch 706 in epoch 12, gen_loss = 0.8672835275088207, disc_loss = 0.06181380821094233
Trained batch 707 in epoch 12, gen_loss = 0.8670244381505218, disc_loss = 0.061837291200303256
Trained batch 708 in epoch 12, gen_loss = 0.8672180293056961, disc_loss = 0.061767009394282764
Trained batch 709 in epoch 12, gen_loss = 0.8675396183426951, disc_loss = 0.06171018747665303
Trained batch 710 in epoch 12, gen_loss = 0.8677703384860156, disc_loss = 0.06166973211651906
Trained batch 711 in epoch 12, gen_loss = 0.8678559984467672, disc_loss = 0.06160577626119294
Trained batch 712 in epoch 12, gen_loss = 0.8677160389209362, disc_loss = 0.06155650935633445
Trained batch 713 in epoch 12, gen_loss = 0.8675337524390688, disc_loss = 0.06152436234636091
Trained batch 714 in epoch 12, gen_loss = 0.8675875397412094, disc_loss = 0.061474480905889216
Trained batch 715 in epoch 12, gen_loss = 0.8676709954382321, disc_loss = 0.061439237051367675
Trained batch 716 in epoch 12, gen_loss = 0.8673086166797489, disc_loss = 0.06144347567516516
Trained batch 717 in epoch 12, gen_loss = 0.8672884168482092, disc_loss = 0.061689508563908944
Trained batch 718 in epoch 12, gen_loss = 0.8668929358765545, disc_loss = 0.06187879122011312
Trained batch 719 in epoch 12, gen_loss = 0.8669086231539647, disc_loss = 0.06183585037554925
Trained batch 720 in epoch 12, gen_loss = 0.8669555003285904, disc_loss = 0.061861794254640515
Trained batch 721 in epoch 12, gen_loss = 0.8668307800289666, disc_loss = 0.06192594559584587
Trained batch 722 in epoch 12, gen_loss = 0.8668506504506656, disc_loss = 0.06189631618028648
Trained batch 723 in epoch 12, gen_loss = 0.8664457199076263, disc_loss = 0.06196106651165003
Trained batch 724 in epoch 12, gen_loss = 0.8665736065650809, disc_loss = 0.062003127304387506
Trained batch 725 in epoch 12, gen_loss = 0.8660122580190007, disc_loss = 0.06207733772587308
Trained batch 726 in epoch 12, gen_loss = 0.8664822716578493, disc_loss = 0.06205174960631575
Trained batch 727 in epoch 12, gen_loss = 0.8668496576393698, disc_loss = 0.0620445088460366
Trained batch 728 in epoch 12, gen_loss = 0.8667225748177909, disc_loss = 0.06203284135934052
Trained batch 729 in epoch 12, gen_loss = 0.8665454717939847, disc_loss = 0.062028993624071146
Trained batch 730 in epoch 12, gen_loss = 0.8663719424878523, disc_loss = 0.061997263368713466
Trained batch 731 in epoch 12, gen_loss = 0.8663227315076062, disc_loss = 0.061954328834837494
Trained batch 732 in epoch 12, gen_loss = 0.866320145772554, disc_loss = 0.06195283338991674
Trained batch 733 in epoch 12, gen_loss = 0.8660489745052374, disc_loss = 0.06202254049880912
Trained batch 734 in epoch 12, gen_loss = 0.8663628142301728, disc_loss = 0.062135635462089056
Trained batch 735 in epoch 12, gen_loss = 0.8661662444229359, disc_loss = 0.0621300794870046
Trained batch 736 in epoch 12, gen_loss = 0.8660432894889827, disc_loss = 0.062079267163117756
Trained batch 737 in epoch 12, gen_loss = 0.8659799268979044, disc_loss = 0.062022020415652815
Trained batch 738 in epoch 12, gen_loss = 0.8660956868380106, disc_loss = 0.06195849469322232
Trained batch 739 in epoch 12, gen_loss = 0.866089826540367, disc_loss = 0.061911372138136946
Trained batch 740 in epoch 12, gen_loss = 0.8663989395989098, disc_loss = 0.06185495852167227
Trained batch 741 in epoch 12, gen_loss = 0.8666011374996037, disc_loss = 0.06178834167186101
Trained batch 742 in epoch 12, gen_loss = 0.8661502999620836, disc_loss = 0.06190228233963732
Trained batch 743 in epoch 12, gen_loss = 0.8667020859016527, disc_loss = 0.06218995422660623
Trained batch 744 in epoch 12, gen_loss = 0.8664461805916472, disc_loss = 0.062168912383283946
Trained batch 745 in epoch 12, gen_loss = 0.8663463422743948, disc_loss = 0.062370424559614536
Trained batch 746 in epoch 12, gen_loss = 0.8660080497922349, disc_loss = 0.06238808285774117
Trained batch 747 in epoch 12, gen_loss = 0.8657984516438954, disc_loss = 0.062369351199315116
Trained batch 748 in epoch 12, gen_loss = 0.8659488729466106, disc_loss = 0.0623194244721325
Trained batch 749 in epoch 12, gen_loss = 0.8662472856442134, disc_loss = 0.06227177651350697
Trained batch 750 in epoch 12, gen_loss = 0.8664212714578118, disc_loss = 0.062226272758577617
Trained batch 751 in epoch 12, gen_loss = 0.8663419842165201, disc_loss = 0.06219178852947191
Trained batch 752 in epoch 12, gen_loss = 0.8659553835354004, disc_loss = 0.06221698968242087
Trained batch 753 in epoch 12, gen_loss = 0.8663001389734308, disc_loss = 0.06221284373571963
Trained batch 754 in epoch 12, gen_loss = 0.8663006169511782, disc_loss = 0.062143464101515465
Trained batch 755 in epoch 12, gen_loss = 0.8662414938290283, disc_loss = 0.06208220106628403
Trained batch 756 in epoch 12, gen_loss = 0.866001358317258, disc_loss = 0.062056597367745964
Trained batch 757 in epoch 12, gen_loss = 0.8660689179139276, disc_loss = 0.062004955206557834
Trained batch 758 in epoch 12, gen_loss = 0.8662263138884769, disc_loss = 0.06193289525159027
Trained batch 759 in epoch 12, gen_loss = 0.8660663802764917, disc_loss = 0.06191384533763324
Trained batch 760 in epoch 12, gen_loss = 0.8662149398226618, disc_loss = 0.06187089570551993
Trained batch 761 in epoch 12, gen_loss = 0.8663975057874139, disc_loss = 0.06184688288464243
Trained batch 762 in epoch 12, gen_loss = 0.8662111018228968, disc_loss = 0.06183188541171045
Trained batch 763 in epoch 12, gen_loss = 0.8658147706645322, disc_loss = 0.06185980895729199
Trained batch 764 in epoch 12, gen_loss = 0.8659440567680433, disc_loss = 0.06186345382989232
Trained batch 765 in epoch 12, gen_loss = 0.8660067396515655, disc_loss = 0.061795296710393056
Trained batch 766 in epoch 12, gen_loss = 0.8659048811320065, disc_loss = 0.06175681989824562
Trained batch 767 in epoch 12, gen_loss = 0.8657194263845062, disc_loss = 0.061720517278445186
Trained batch 768 in epoch 12, gen_loss = 0.8654808968266833, disc_loss = 0.06169806223517703
Trained batch 769 in epoch 12, gen_loss = 0.8657856295248131, disc_loss = 0.06176091607103681
Trained batch 770 in epoch 12, gen_loss = 0.865905511201433, disc_loss = 0.06169431102154088
Trained batch 771 in epoch 12, gen_loss = 0.8657745562609613, disc_loss = 0.06166082212141681
Trained batch 772 in epoch 12, gen_loss = 0.8655250257153406, disc_loss = 0.06171141843158477
Trained batch 773 in epoch 12, gen_loss = 0.8657158531190813, disc_loss = 0.06167872192083018
Trained batch 774 in epoch 12, gen_loss = 0.8658693547787205, disc_loss = 0.061613954401785326
Trained batch 775 in epoch 12, gen_loss = 0.8659330764305346, disc_loss = 0.06155282526142588
Trained batch 776 in epoch 12, gen_loss = 0.8660105919055496, disc_loss = 0.061507191583322435
Trained batch 777 in epoch 12, gen_loss = 0.8659955016828135, disc_loss = 0.06145712279578178
Trained batch 778 in epoch 12, gen_loss = 0.8660476622058124, disc_loss = 0.061395341640431554
Trained batch 779 in epoch 12, gen_loss = 0.8661004545979011, disc_loss = 0.061338209683218826
Trained batch 780 in epoch 12, gen_loss = 0.8662155032844763, disc_loss = 0.061282062585848396
Trained batch 781 in epoch 12, gen_loss = 0.8661308124318452, disc_loss = 0.06125519287479503
Trained batch 782 in epoch 12, gen_loss = 0.8665885153782018, disc_loss = 0.061251012491844926
Trained batch 783 in epoch 12, gen_loss = 0.8664574018318434, disc_loss = 0.061236164570615
Trained batch 784 in epoch 12, gen_loss = 0.8664612497114073, disc_loss = 0.06120590854222607
Trained batch 785 in epoch 12, gen_loss = 0.8663781891569836, disc_loss = 0.06118072685963325
Trained batch 786 in epoch 12, gen_loss = 0.8666787910567457, disc_loss = 0.061462434711647154
Trained batch 787 in epoch 12, gen_loss = 0.8664078041911125, disc_loss = 0.061495133651997234
Trained batch 788 in epoch 12, gen_loss = 0.8666760641585738, disc_loss = 0.06148397663775808
Trained batch 789 in epoch 12, gen_loss = 0.8664437074827243, disc_loss = 0.061548056566639794
Testing Epoch 12
Training Epoch 13
Trained batch 0 in epoch 13, gen_loss = 0.9340962767601013, disc_loss = 0.048447638750076294
Trained batch 1 in epoch 13, gen_loss = 0.9667469561100006, disc_loss = 0.06393290311098099
Trained batch 2 in epoch 13, gen_loss = 0.8411264816919962, disc_loss = 0.07998034358024597
Trained batch 3 in epoch 13, gen_loss = 0.856541246175766, disc_loss = 0.07831544801592827
Trained batch 4 in epoch 13, gen_loss = 0.8334925174713135, disc_loss = 0.07598319202661515
Trained batch 5 in epoch 13, gen_loss = 0.8152440985043844, disc_loss = 0.07058077491819859
Trained batch 6 in epoch 13, gen_loss = 0.8351705244609288, disc_loss = 0.06275002126182828
Trained batch 7 in epoch 13, gen_loss = 0.8542602434754372, disc_loss = 0.058742208406329155
Trained batch 8 in epoch 13, gen_loss = 0.8560623923937479, disc_loss = 0.05618213696612252
Trained batch 9 in epoch 13, gen_loss = 0.837212759256363, disc_loss = 0.06008202210068703
Trained batch 10 in epoch 13, gen_loss = 0.8466648730364713, disc_loss = 0.05912446264516224
Trained batch 11 in epoch 13, gen_loss = 0.8518116772174835, disc_loss = 0.05722495851417383
Trained batch 12 in epoch 13, gen_loss = 0.8590618417813227, disc_loss = 0.05384944099932909
Trained batch 13 in epoch 13, gen_loss = 0.8583596135888781, disc_loss = 0.051511241987879784
Trained batch 14 in epoch 13, gen_loss = 0.8425487955411275, disc_loss = 0.05440592473993699
Trained batch 15 in epoch 13, gen_loss = 0.8423884771764278, disc_loss = 0.05262701091123745
Trained batch 16 in epoch 13, gen_loss = 0.8437159096493441, disc_loss = 0.05089573151267627
Trained batch 17 in epoch 13, gen_loss = 0.8644682466983795, disc_loss = 0.04966858676117328
Trained batch 18 in epoch 13, gen_loss = 0.8601789317632976, disc_loss = 0.05358619228201477
Trained batch 19 in epoch 13, gen_loss = 0.8466697424650192, disc_loss = 0.057582988822832706
Trained batch 20 in epoch 13, gen_loss = 0.8534708533968244, disc_loss = 0.06215379019046113
Trained batch 21 in epoch 13, gen_loss = 0.853094604882327, disc_loss = 0.06017156271263957
Trained batch 22 in epoch 13, gen_loss = 0.8517290561095529, disc_loss = 0.05950974466522103
Trained batch 23 in epoch 13, gen_loss = 0.845514602959156, disc_loss = 0.060452096979133785
Trained batch 24 in epoch 13, gen_loss = 0.847695815563202, disc_loss = 0.05914435017853975
Trained batch 25 in epoch 13, gen_loss = 0.8561959931483636, disc_loss = 0.05877305900391478
Trained batch 26 in epoch 13, gen_loss = 0.8591144725128457, disc_loss = 0.05771038753704892
Trained batch 27 in epoch 13, gen_loss = 0.8501458466053009, disc_loss = 0.062012920322428854
Trained batch 28 in epoch 13, gen_loss = 0.845223800889377, disc_loss = 0.061761422564500366
Trained batch 29 in epoch 13, gen_loss = 0.8640498042106628, disc_loss = 0.0627753944757084
Trained batch 30 in epoch 13, gen_loss = 0.8695589765425651, disc_loss = 0.061206860437748895
Trained batch 31 in epoch 13, gen_loss = 0.8661332614719868, disc_loss = 0.06042587597039528
Trained batch 32 in epoch 13, gen_loss = 0.8591180534073801, disc_loss = 0.061478466049514034
Trained batch 33 in epoch 13, gen_loss = 0.8613450229167938, disc_loss = 0.06041932820945101
Trained batch 34 in epoch 13, gen_loss = 0.8652934432029724, disc_loss = 0.061550448542194706
Trained batch 35 in epoch 13, gen_loss = 0.8592394871844186, disc_loss = 0.06178480192708472
Trained batch 36 in epoch 13, gen_loss = 0.8557445664663572, disc_loss = 0.062022648474856
Trained batch 37 in epoch 13, gen_loss = 0.8555803894996643, disc_loss = 0.06114828118466233
Trained batch 38 in epoch 13, gen_loss = 0.8524430929086148, disc_loss = 0.06062872681575708
Trained batch 39 in epoch 13, gen_loss = 0.8575025469064712, disc_loss = 0.060062286187894644
Trained batch 40 in epoch 13, gen_loss = 0.8602599545222956, disc_loss = 0.05921886940827457
Trained batch 41 in epoch 13, gen_loss = 0.857724422500247, disc_loss = 0.058712541236586514
Trained batch 42 in epoch 13, gen_loss = 0.8512057315471561, disc_loss = 0.0595282010170956
Trained batch 43 in epoch 13, gen_loss = 0.8526933003555645, disc_loss = 0.06000386658971282
Trained batch 44 in epoch 13, gen_loss = 0.8555596166186863, disc_loss = 0.059057434337834516
Trained batch 45 in epoch 13, gen_loss = 0.8581180689127549, disc_loss = 0.05794882314765583
Trained batch 46 in epoch 13, gen_loss = 0.8594392297115732, disc_loss = 0.05714124637319053
Trained batch 47 in epoch 13, gen_loss = 0.8596131217976412, disc_loss = 0.057322857804441206
Trained batch 48 in epoch 13, gen_loss = 0.85849102540892, disc_loss = 0.057020281403496555
Trained batch 49 in epoch 13, gen_loss = 0.8533920896053314, disc_loss = 0.058552084621042014
Trained batch 50 in epoch 13, gen_loss = 0.8625409404436747, disc_loss = 0.06280344730133519
Trained batch 51 in epoch 13, gen_loss = 0.8604173350792664, disc_loss = 0.062062421831517264
Trained batch 52 in epoch 13, gen_loss = 0.8592350280509805, disc_loss = 0.0612936596438851
Trained batch 53 in epoch 13, gen_loss = 0.8599168558915457, disc_loss = 0.06055626481840456
Trained batch 54 in epoch 13, gen_loss = 0.8587494644251736, disc_loss = 0.06041083188558167
Trained batch 55 in epoch 13, gen_loss = 0.8608466227139745, disc_loss = 0.05956937169789204
Trained batch 56 in epoch 13, gen_loss = 0.8609773182032401, disc_loss = 0.05875208094846784
Trained batch 57 in epoch 13, gen_loss = 0.8653393274751203, disc_loss = 0.05805667997177305
Trained batch 58 in epoch 13, gen_loss = 0.8628461997387773, disc_loss = 0.05792680565836066
Trained batch 59 in epoch 13, gen_loss = 0.8645962387323379, disc_loss = 0.05710069619429608
Trained batch 60 in epoch 13, gen_loss = 0.8641037403560076, disc_loss = 0.05654863715477166
Trained batch 61 in epoch 13, gen_loss = 0.8626890692018694, disc_loss = 0.0567022196257547
Trained batch 62 in epoch 13, gen_loss = 0.8640490136449299, disc_loss = 0.05598466708842251
Trained batch 63 in epoch 13, gen_loss = 0.8607473904266953, disc_loss = 0.05681835518043954
Trained batch 64 in epoch 13, gen_loss = 0.863659182878641, disc_loss = 0.05818069515606532
Trained batch 65 in epoch 13, gen_loss = 0.8598220357389161, disc_loss = 0.05890244557381128
Trained batch 66 in epoch 13, gen_loss = 0.858061106347326, disc_loss = 0.05882849028584228
Trained batch 67 in epoch 13, gen_loss = 0.8565918312353247, disc_loss = 0.059232188347617495
Trained batch 68 in epoch 13, gen_loss = 0.8560092587401902, disc_loss = 0.05860514740419129
Trained batch 69 in epoch 13, gen_loss = 0.8557880708149501, disc_loss = 0.058311975600996185
Trained batch 70 in epoch 13, gen_loss = 0.8547366605678075, disc_loss = 0.05810150080426058
Trained batch 71 in epoch 13, gen_loss = 0.8576352430714501, disc_loss = 0.05744194664940652
Trained batch 72 in epoch 13, gen_loss = 0.8601307999597837, disc_loss = 0.05739423940085793
Trained batch 73 in epoch 13, gen_loss = 0.8598634189850575, disc_loss = 0.056894716441732
Trained batch 74 in epoch 13, gen_loss = 0.8565822148323059, disc_loss = 0.057784191730121774
Trained batch 75 in epoch 13, gen_loss = 0.8613127838624152, disc_loss = 0.05744193485741945
Trained batch 76 in epoch 13, gen_loss = 0.8662636334245856, disc_loss = 0.05704919211324546
Trained batch 77 in epoch 13, gen_loss = 0.8630387332194891, disc_loss = 0.05692073312373115
Trained batch 78 in epoch 13, gen_loss = 0.8620343593102467, disc_loss = 0.056577323676570306
Trained batch 79 in epoch 13, gen_loss = 0.8645750366151332, disc_loss = 0.056616054789628834
Trained batch 80 in epoch 13, gen_loss = 0.8634864239045131, disc_loss = 0.056699386291941746
Trained batch 81 in epoch 13, gen_loss = 0.8622715022505784, disc_loss = 0.0564844117999622
Trained batch 82 in epoch 13, gen_loss = 0.8613203397716385, disc_loss = 0.05599117583135165
Trained batch 83 in epoch 13, gen_loss = 0.8608773272661936, disc_loss = 0.05603104478324808
Trained batch 84 in epoch 13, gen_loss = 0.8613039717954748, disc_loss = 0.05558575813603752
Trained batch 85 in epoch 13, gen_loss = 0.8618024296538774, disc_loss = 0.05513775211130811
Trained batch 86 in epoch 13, gen_loss = 0.8611819661896805, disc_loss = 0.05507743441039461
Trained batch 87 in epoch 13, gen_loss = 0.8646206259727478, disc_loss = 0.05475396244913678
Trained batch 88 in epoch 13, gen_loss = 0.8637214296319512, disc_loss = 0.05451139620390166
Trained batch 89 in epoch 13, gen_loss = 0.8667087992032368, disc_loss = 0.05404980765241715
Trained batch 90 in epoch 13, gen_loss = 0.866549897979904, disc_loss = 0.053715414592771085
Trained batch 91 in epoch 13, gen_loss = 0.8712781278983407, disc_loss = 0.05467778852249941
Trained batch 92 in epoch 13, gen_loss = 0.8702066720172923, disc_loss = 0.05462506096008965
Trained batch 93 in epoch 13, gen_loss = 0.8686622425596765, disc_loss = 0.05507303111532584
Trained batch 94 in epoch 13, gen_loss = 0.8710239880963375, disc_loss = 0.05654960795256652
Trained batch 95 in epoch 13, gen_loss = 0.8686335807045301, disc_loss = 0.057262499923429765
Trained batch 96 in epoch 13, gen_loss = 0.8654799147979501, disc_loss = 0.057160406104605835
Trained batch 97 in epoch 13, gen_loss = 0.8668309736008547, disc_loss = 0.056682502052613666
Trained batch 98 in epoch 13, gen_loss = 0.8695498193153227, disc_loss = 0.05640816534257898
Trained batch 99 in epoch 13, gen_loss = 0.8674304085969925, disc_loss = 0.05755327682942152
Trained batch 100 in epoch 13, gen_loss = 0.8676603542696132, disc_loss = 0.057355589685168594
Trained batch 101 in epoch 13, gen_loss = 0.8660277122376012, disc_loss = 0.05742273381089463
Trained batch 102 in epoch 13, gen_loss = 0.8651288568394856, disc_loss = 0.057252990570172524
Trained batch 103 in epoch 13, gen_loss = 0.8638420271185728, disc_loss = 0.05790222282163226
Trained batch 104 in epoch 13, gen_loss = 0.866897189617157, disc_loss = 0.0578131510033494
Trained batch 105 in epoch 13, gen_loss = 0.8663244028136415, disc_loss = 0.05768699835072148
Trained batch 106 in epoch 13, gen_loss = 0.8675299019457023, disc_loss = 0.057293562636336434
Trained batch 107 in epoch 13, gen_loss = 0.8665750810393581, disc_loss = 0.05694572487846017
Trained batch 108 in epoch 13, gen_loss = 0.8654655950878738, disc_loss = 0.056757876410260116
Trained batch 109 in epoch 13, gen_loss = 0.8696657462553544, disc_loss = 0.0572067904709415
Trained batch 110 in epoch 13, gen_loss = 0.8687632202028154, disc_loss = 0.0569168593197524
Trained batch 111 in epoch 13, gen_loss = 0.8669706455298832, disc_loss = 0.05732656637805381
Trained batch 112 in epoch 13, gen_loss = 0.8653072841399538, disc_loss = 0.05751001533219772
Trained batch 113 in epoch 13, gen_loss = 0.8714700534678342, disc_loss = 0.05957166734560017
Trained batch 114 in epoch 13, gen_loss = 0.8709023200947306, disc_loss = 0.0597846238023561
Trained batch 115 in epoch 13, gen_loss = 0.8698998412181591, disc_loss = 0.05990472135679989
Trained batch 116 in epoch 13, gen_loss = 0.8687518875823061, disc_loss = 0.06013212844920464
Trained batch 117 in epoch 13, gen_loss = 0.8685129118167748, disc_loss = 0.05980557640540903
Trained batch 118 in epoch 13, gen_loss = 0.8674239962040877, disc_loss = 0.059789221092056824
Trained batch 119 in epoch 13, gen_loss = 0.8687004715204238, disc_loss = 0.05963703805270294
Trained batch 120 in epoch 13, gen_loss = 0.8701135944729009, disc_loss = 0.05927119884362891
Trained batch 121 in epoch 13, gen_loss = 0.87096461946847, disc_loss = 0.05904539054656615
Trained batch 122 in epoch 13, gen_loss = 0.8694658177654918, disc_loss = 0.058853529878263554
Trained batch 123 in epoch 13, gen_loss = 0.87087803934851, disc_loss = 0.05847440697553177
Trained batch 124 in epoch 13, gen_loss = 0.870086477279663, disc_loss = 0.058363310649991035
Trained batch 125 in epoch 13, gen_loss = 0.8696579904783339, disc_loss = 0.058096810125760616
Trained batch 126 in epoch 13, gen_loss = 0.8679925667957997, disc_loss = 0.058109489760882274
Trained batch 127 in epoch 13, gen_loss = 0.8681564047001302, disc_loss = 0.0577858730830485
Trained batch 128 in epoch 13, gen_loss = 0.8668497897857843, disc_loss = 0.05774430247644583
Trained batch 129 in epoch 13, gen_loss = 0.8650631404840029, disc_loss = 0.05765969986812426
Trained batch 130 in epoch 13, gen_loss = 0.8649303508168869, disc_loss = 0.05767060712491738
Trained batch 131 in epoch 13, gen_loss = 0.8665860317873232, disc_loss = 0.05763172681415171
Trained batch 132 in epoch 13, gen_loss = 0.8646899883012126, disc_loss = 0.05770945029431268
Trained batch 133 in epoch 13, gen_loss = 0.863075615754768, disc_loss = 0.05798684462293315
Trained batch 134 in epoch 13, gen_loss = 0.8650000695829039, disc_loss = 0.0583956295279441
Trained batch 135 in epoch 13, gen_loss = 0.8656695274745717, disc_loss = 0.058249804999350625
Trained batch 136 in epoch 13, gen_loss = 0.8652509024543483, disc_loss = 0.05829126821545354
Trained batch 137 in epoch 13, gen_loss = 0.8650246875873511, disc_loss = 0.0581480361710208
Trained batch 138 in epoch 13, gen_loss = 0.8665086159603201, disc_loss = 0.05833037255211271
Trained batch 139 in epoch 13, gen_loss = 0.8665924344744002, disc_loss = 0.05818971282403384
Trained batch 140 in epoch 13, gen_loss = 0.866427443551679, disc_loss = 0.05832446555455103
Trained batch 141 in epoch 13, gen_loss = 0.8652428741186438, disc_loss = 0.05828387097416209
Trained batch 142 in epoch 13, gen_loss = 0.8674886226654053, disc_loss = 0.058338865233989026
Trained batch 143 in epoch 13, gen_loss = 0.8685247533851199, disc_loss = 0.058087574977738164
Trained batch 144 in epoch 13, gen_loss = 0.8674558479210426, disc_loss = 0.05815204108326599
Trained batch 145 in epoch 13, gen_loss = 0.8670555720590565, disc_loss = 0.058195189088072675
Trained batch 146 in epoch 13, gen_loss = 0.8665879753982129, disc_loss = 0.05800902446871307
Trained batch 147 in epoch 13, gen_loss = 0.8669662044660466, disc_loss = 0.05778582521236023
Trained batch 148 in epoch 13, gen_loss = 0.8664203050152567, disc_loss = 0.057606151977541466
Trained batch 149 in epoch 13, gen_loss = 0.8665570410092672, disc_loss = 0.057721777545909084
Trained batch 150 in epoch 13, gen_loss = 0.8663377797366768, disc_loss = 0.05780763804468493
Trained batch 151 in epoch 13, gen_loss = 0.8658277447286405, disc_loss = 0.05772231723868141
Trained batch 152 in epoch 13, gen_loss = 0.8656105504316443, disc_loss = 0.057488527343748444
Trained batch 153 in epoch 13, gen_loss = 0.8687120141921105, disc_loss = 0.058325693954701545
Trained batch 154 in epoch 13, gen_loss = 0.8698453187942505, disc_loss = 0.05804361886074466
Trained batch 155 in epoch 13, gen_loss = 0.8683546961118014, disc_loss = 0.05824767098499414
Trained batch 156 in epoch 13, gen_loss = 0.8672540924351686, disc_loss = 0.05808625519750225
Trained batch 157 in epoch 13, gen_loss = 0.8691795166534714, disc_loss = 0.057872249178965635
Trained batch 158 in epoch 13, gen_loss = 0.8695293387526986, disc_loss = 0.05773450107366409
Trained batch 159 in epoch 13, gen_loss = 0.8685954120010138, disc_loss = 0.05760066678049043
Trained batch 160 in epoch 13, gen_loss = 0.8691636112906178, disc_loss = 0.05732349678295555
Trained batch 161 in epoch 13, gen_loss = 0.8699173033237457, disc_loss = 0.057018191605392426
Trained batch 162 in epoch 13, gen_loss = 0.8693580759083567, disc_loss = 0.056899281795725135
Trained batch 163 in epoch 13, gen_loss = 0.8685828905280043, disc_loss = 0.0567894738065306
Trained batch 164 in epoch 13, gen_loss = 0.8704131046930949, disc_loss = 0.057450880623902335
Trained batch 165 in epoch 13, gen_loss = 0.8709209399769106, disc_loss = 0.057170822369271374
Trained batch 166 in epoch 13, gen_loss = 0.870784721331682, disc_loss = 0.05696005745049187
Trained batch 167 in epoch 13, gen_loss = 0.8693095967173576, disc_loss = 0.05734849451220639
Trained batch 168 in epoch 13, gen_loss = 0.8699213107662088, disc_loss = 0.05741988771082558
Trained batch 169 in epoch 13, gen_loss = 0.8698770999908447, disc_loss = 0.057203325974371506
Trained batch 170 in epoch 13, gen_loss = 0.8717873026753029, disc_loss = 0.0571370602514573
Trained batch 171 in epoch 13, gen_loss = 0.870183278654897, disc_loss = 0.05758847107266098
Trained batch 172 in epoch 13, gen_loss = 0.8707246043089497, disc_loss = 0.05740171292462962
Trained batch 173 in epoch 13, gen_loss = 0.8712897780297817, disc_loss = 0.057339986384814155
Trained batch 174 in epoch 13, gen_loss = 0.8704847260883877, disc_loss = 0.0573631992776479
Trained batch 175 in epoch 13, gen_loss = 0.8718753755092621, disc_loss = 0.0574667702100917
Trained batch 176 in epoch 13, gen_loss = 0.872106142299997, disc_loss = 0.05727747890382669
Trained batch 177 in epoch 13, gen_loss = 0.8715163599909022, disc_loss = 0.05712501863226964
Trained batch 178 in epoch 13, gen_loss = 0.8723473279169818, disc_loss = 0.056977281757947786
Trained batch 179 in epoch 13, gen_loss = 0.872895062300894, disc_loss = 0.05701931208475596
Trained batch 180 in epoch 13, gen_loss = 0.8707568273359899, disc_loss = 0.057704204750036334
Trained batch 181 in epoch 13, gen_loss = 0.8718799028422807, disc_loss = 0.05817915211114418
Trained batch 182 in epoch 13, gen_loss = 0.8704794954732468, disc_loss = 0.05838163684076462
Trained batch 183 in epoch 13, gen_loss = 0.8712516514503438, disc_loss = 0.05846928750954406
Trained batch 184 in epoch 13, gen_loss = 0.8702276374842669, disc_loss = 0.05839851108455175
Trained batch 185 in epoch 13, gen_loss = 0.8702623905033193, disc_loss = 0.05820356648395299
Trained batch 186 in epoch 13, gen_loss = 0.8705758599036517, disc_loss = 0.05793906236316431
Trained batch 187 in epoch 13, gen_loss = 0.8704078581104887, disc_loss = 0.058297072854289346
Trained batch 188 in epoch 13, gen_loss = 0.8690905183080643, disc_loss = 0.058339638625660904
Trained batch 189 in epoch 13, gen_loss = 0.8686361466583453, disc_loss = 0.058187090076114
Trained batch 190 in epoch 13, gen_loss = 0.8692141821247121, disc_loss = 0.05829498739376742
Trained batch 191 in epoch 13, gen_loss = 0.8691077840824922, disc_loss = 0.058121358995170645
Trained batch 192 in epoch 13, gen_loss = 0.8693399521970996, disc_loss = 0.057981286796263465
Trained batch 193 in epoch 13, gen_loss = 0.8683041340297031, disc_loss = 0.058147699792975
Trained batch 194 in epoch 13, gen_loss = 0.8697775235542884, disc_loss = 0.05801963127958469
Trained batch 195 in epoch 13, gen_loss = 0.8694530685945433, disc_loss = 0.058187554932522534
Trained batch 196 in epoch 13, gen_loss = 0.8692822453334247, disc_loss = 0.05803487841323548
Trained batch 197 in epoch 13, gen_loss = 0.8674092060989804, disc_loss = 0.05816078202968294
Trained batch 198 in epoch 13, gen_loss = 0.8680893029998894, disc_loss = 0.05807968144815172
Trained batch 199 in epoch 13, gen_loss = 0.8683552640676498, disc_loss = 0.05795889500528574
Trained batch 200 in epoch 13, gen_loss = 0.8673182577636112, disc_loss = 0.058068249949175324
Trained batch 201 in epoch 13, gen_loss = 0.8674642523326496, disc_loss = 0.05790858694564293
Trained batch 202 in epoch 13, gen_loss = 0.8680254658454745, disc_loss = 0.05790460185868106
Trained batch 203 in epoch 13, gen_loss = 0.8665876204476637, disc_loss = 0.05817831262909606
Trained batch 204 in epoch 13, gen_loss = 0.8675249928381384, disc_loss = 0.05904749056733236
Trained batch 205 in epoch 13, gen_loss = 0.8671626677212206, disc_loss = 0.058907735333280656
Trained batch 206 in epoch 13, gen_loss = 0.8666969292981613, disc_loss = 0.058907632702502655
Trained batch 207 in epoch 13, gen_loss = 0.8670619591497458, disc_loss = 0.058929831792528815
Trained batch 208 in epoch 13, gen_loss = 0.8673297945392189, disc_loss = 0.05880500754100854
Trained batch 209 in epoch 13, gen_loss = 0.8668036724839892, disc_loss = 0.05872355460056237
Trained batch 210 in epoch 13, gen_loss = 0.8659253241891545, disc_loss = 0.05872017782516954
Trained batch 211 in epoch 13, gen_loss = 0.8659988970689054, disc_loss = 0.058819678576909146
Trained batch 212 in epoch 13, gen_loss = 0.8645296180751961, disc_loss = 0.058976119445383265
Trained batch 213 in epoch 13, gen_loss = 0.8660619899491283, disc_loss = 0.05897218645245672
Trained batch 214 in epoch 13, gen_loss = 0.8657546614491662, disc_loss = 0.05886519137163495
Trained batch 215 in epoch 13, gen_loss = 0.8659061397667285, disc_loss = 0.05867909552115533
Trained batch 216 in epoch 13, gen_loss = 0.8661743828228542, disc_loss = 0.05861060517037519
Trained batch 217 in epoch 13, gen_loss = 0.8656797851991216, disc_loss = 0.05851309018534258
Trained batch 218 in epoch 13, gen_loss = 0.8679110051290085, disc_loss = 0.05872460230164332
Trained batch 219 in epoch 13, gen_loss = 0.866943601586602, disc_loss = 0.058748331259597435
Trained batch 220 in epoch 13, gen_loss = 0.8659344480048478, disc_loss = 0.05870799185935728
Trained batch 221 in epoch 13, gen_loss = 0.8662088475785814, disc_loss = 0.05853472327863848
Trained batch 222 in epoch 13, gen_loss = 0.8655490538464533, disc_loss = 0.058609763302343305
Trained batch 223 in epoch 13, gen_loss = 0.8645022639206478, disc_loss = 0.0585275495125513
Trained batch 224 in epoch 13, gen_loss = 0.8646281629138522, disc_loss = 0.058335540522303844
Trained batch 225 in epoch 13, gen_loss = 0.863359256655769, disc_loss = 0.058541175237634274
Trained batch 226 in epoch 13, gen_loss = 0.8643694669664694, disc_loss = 0.058419603817493115
Trained batch 227 in epoch 13, gen_loss = 0.864119670108745, disc_loss = 0.058281494275944534
Trained batch 228 in epoch 13, gen_loss = 0.8646604725887682, disc_loss = 0.058112352106346056
Trained batch 229 in epoch 13, gen_loss = 0.8643177392690078, disc_loss = 0.05816227585968116
Trained batch 230 in epoch 13, gen_loss = 0.8646633382483478, disc_loss = 0.05799840119348847
Trained batch 231 in epoch 13, gen_loss = 0.8643118333199928, disc_loss = 0.05789204024918506
Trained batch 232 in epoch 13, gen_loss = 0.8657489135030002, disc_loss = 0.0577289062979843
Trained batch 233 in epoch 13, gen_loss = 0.8657533083206568, disc_loss = 0.058110414594252646
Trained batch 234 in epoch 13, gen_loss = 0.8647844111665767, disc_loss = 0.05818928470240629
Trained batch 235 in epoch 13, gen_loss = 0.864581318982577, disc_loss = 0.05809402972128305
Trained batch 236 in epoch 13, gen_loss = 0.8650119352441297, disc_loss = 0.05803709431209519
Trained batch 237 in epoch 13, gen_loss = 0.8650033659293872, disc_loss = 0.058030854953656424
Trained batch 238 in epoch 13, gen_loss = 0.8649535096838883, disc_loss = 0.05784094390151516
Trained batch 239 in epoch 13, gen_loss = 0.8642672998209794, disc_loss = 0.05777381680672988
Trained batch 240 in epoch 13, gen_loss = 0.8649297559409715, disc_loss = 0.05831861629293791
Trained batch 241 in epoch 13, gen_loss = 0.8638799399876398, disc_loss = 0.058644044778717694
Trained batch 242 in epoch 13, gen_loss = 0.8632422822983667, disc_loss = 0.058545410744232654
Trained batch 243 in epoch 13, gen_loss = 0.8642685447559982, disc_loss = 0.058756878618608975
Trained batch 244 in epoch 13, gen_loss = 0.8633179066132526, disc_loss = 0.05897995478720689
Trained batch 245 in epoch 13, gen_loss = 0.8638768704926095, disc_loss = 0.058924070101352484
Trained batch 246 in epoch 13, gen_loss = 0.8641618996979255, disc_loss = 0.05878755802039796
Trained batch 247 in epoch 13, gen_loss = 0.863406210657089, disc_loss = 0.058783088994753215
Trained batch 248 in epoch 13, gen_loss = 0.8635548331651343, disc_loss = 0.05864327052705379
Trained batch 249 in epoch 13, gen_loss = 0.8645115778446197, disc_loss = 0.05854160793498159
Trained batch 250 in epoch 13, gen_loss = 0.8649850953147706, disc_loss = 0.05834558874042148
Trained batch 251 in epoch 13, gen_loss = 0.8647862452836264, disc_loss = 0.05818998212704346
Trained batch 252 in epoch 13, gen_loss = 0.8644850407193301, disc_loss = 0.05806920273236842
Trained batch 253 in epoch 13, gen_loss = 0.8644274721934101, disc_loss = 0.05805710879865828
Trained batch 254 in epoch 13, gen_loss = 0.8648891652331633, disc_loss = 0.05785399751701192
Trained batch 255 in epoch 13, gen_loss = 0.86467055673711, disc_loss = 0.05773894611411379
Trained batch 256 in epoch 13, gen_loss = 0.863620222078687, disc_loss = 0.05802385590550153
Trained batch 257 in epoch 13, gen_loss = 0.8656698439934457, disc_loss = 0.058623903080849915
Trained batch 258 in epoch 13, gen_loss = 0.8658382961648772, disc_loss = 0.05844565402917765
Trained batch 259 in epoch 13, gen_loss = 0.8655222425094018, disc_loss = 0.05842515302893634
Trained batch 260 in epoch 13, gen_loss = 0.8657455697826956, disc_loss = 0.058243472200472234
Trained batch 261 in epoch 13, gen_loss = 0.8656373881656705, disc_loss = 0.05807397465527285
Trained batch 262 in epoch 13, gen_loss = 0.8656983518328504, disc_loss = 0.05789599443003252
Trained batch 263 in epoch 13, gen_loss = 0.8656711402264509, disc_loss = 0.05772675514912628
Trained batch 264 in epoch 13, gen_loss = 0.8673553574760006, disc_loss = 0.057748871904639704
Trained batch 265 in epoch 13, gen_loss = 0.8667792344003692, disc_loss = 0.05767423329398708
Trained batch 266 in epoch 13, gen_loss = 0.8665703760550709, disc_loss = 0.05753072357147039
Trained batch 267 in epoch 13, gen_loss = 0.8673638539082968, disc_loss = 0.05735841753489491
Trained batch 268 in epoch 13, gen_loss = 0.8674535305969777, disc_loss = 0.05718699237851073
Trained batch 269 in epoch 13, gen_loss = 0.8680516461531321, disc_loss = 0.057000397787325914
Trained batch 270 in epoch 13, gen_loss = 0.8687089991745474, disc_loss = 0.056819241957883335
Trained batch 271 in epoch 13, gen_loss = 0.8686009638887995, disc_loss = 0.05663962029810885
Trained batch 272 in epoch 13, gen_loss = 0.8685107150357285, disc_loss = 0.056472733115347534
Trained batch 273 in epoch 13, gen_loss = 0.8684016805495659, disc_loss = 0.05628921443691654
Trained batch 274 in epoch 13, gen_loss = 0.8692229921167547, disc_loss = 0.05614439090544527
Trained batch 275 in epoch 13, gen_loss = 0.8693684760643088, disc_loss = 0.055961425495468946
Trained batch 276 in epoch 13, gen_loss = 0.8690766627607793, disc_loss = 0.055794956278566954
Trained batch 277 in epoch 13, gen_loss = 0.8692630207795891, disc_loss = 0.05563914178361406
Trained batch 278 in epoch 13, gen_loss = 0.8688040170618283, disc_loss = 0.05560244148677235
Trained batch 279 in epoch 13, gen_loss = 0.8698817693761417, disc_loss = 0.05546972873520904
Trained batch 280 in epoch 13, gen_loss = 0.8709526191402585, disc_loss = 0.05538327550661362
Trained batch 281 in epoch 13, gen_loss = 0.8710418347771286, disc_loss = 0.05522140780800676
Trained batch 282 in epoch 13, gen_loss = 0.8708048490247963, disc_loss = 0.05507973953587902
Trained batch 283 in epoch 13, gen_loss = 0.8710234540868813, disc_loss = 0.0549755315706265
Trained batch 284 in epoch 13, gen_loss = 0.8708983571905838, disc_loss = 0.05488502168374365
Trained batch 285 in epoch 13, gen_loss = 0.8713061619888652, disc_loss = 0.05472510219291113
Trained batch 286 in epoch 13, gen_loss = 0.8711802720608196, disc_loss = 0.054567515932815315
Trained batch 287 in epoch 13, gen_loss = 0.8710828841560416, disc_loss = 0.054496000473995485
Trained batch 288 in epoch 13, gen_loss = 0.8714941490480231, disc_loss = 0.054360638915603034
Trained batch 289 in epoch 13, gen_loss = 0.8714905960806485, disc_loss = 0.054197325555864595
Trained batch 290 in epoch 13, gen_loss = 0.8711102893672038, disc_loss = 0.05418311531697096
Trained batch 291 in epoch 13, gen_loss = 0.8723576485294186, disc_loss = 0.05427334175528065
Trained batch 292 in epoch 13, gen_loss = 0.8715289949150216, disc_loss = 0.05432926350886657
Trained batch 293 in epoch 13, gen_loss = 0.8711155693547256, disc_loss = 0.0542340731980013
Trained batch 294 in epoch 13, gen_loss = 0.871316446490207, disc_loss = 0.05410090649689911
Trained batch 295 in epoch 13, gen_loss = 0.8713179119938129, disc_loss = 0.05406489924408143
Trained batch 296 in epoch 13, gen_loss = 0.8712741138557794, disc_loss = 0.05401089924359412
Trained batch 297 in epoch 13, gen_loss = 0.8705901597570253, disc_loss = 0.054036815258543064
Trained batch 298 in epoch 13, gen_loss = 0.8715601922277623, disc_loss = 0.0539527490227343
Trained batch 299 in epoch 13, gen_loss = 0.8716384406884511, disc_loss = 0.05380025540944189
Trained batch 300 in epoch 13, gen_loss = 0.8722091548862647, disc_loss = 0.05364773390146337
Trained batch 301 in epoch 13, gen_loss = 0.872902225579647, disc_loss = 0.05349447237426378
Trained batch 302 in epoch 13, gen_loss = 0.8731322013112185, disc_loss = 0.05334069788542026
Trained batch 303 in epoch 13, gen_loss = 0.8735782562902099, disc_loss = 0.053248828923403234
Trained batch 304 in epoch 13, gen_loss = 0.8730538637911687, disc_loss = 0.05319776277012024
Trained batch 305 in epoch 13, gen_loss = 0.8725557701260436, disc_loss = 0.05313766781496359
Trained batch 306 in epoch 13, gen_loss = 0.872218891735574, disc_loss = 0.0530959094695577
Trained batch 307 in epoch 13, gen_loss = 0.8728862395147224, disc_loss = 0.053018576631854684
Trained batch 308 in epoch 13, gen_loss = 0.8734055882904522, disc_loss = 0.052874899632071405
Trained batch 309 in epoch 13, gen_loss = 0.8730680606057567, disc_loss = 0.052808001748616655
Trained batch 310 in epoch 13, gen_loss = 0.8736212926278927, disc_loss = 0.05281602788021806
Trained batch 311 in epoch 13, gen_loss = 0.8737975242428291, disc_loss = 0.05277861532074614
Trained batch 312 in epoch 13, gen_loss = 0.8733845311231887, disc_loss = 0.052814028124673104
Trained batch 313 in epoch 13, gen_loss = 0.872641173517628, disc_loss = 0.05290057134345933
Trained batch 314 in epoch 13, gen_loss = 0.873318684668768, disc_loss = 0.05278830081520099
Trained batch 315 in epoch 13, gen_loss = 0.8733444634494902, disc_loss = 0.05277278216826859
Trained batch 316 in epoch 13, gen_loss = 0.873564561270765, disc_loss = 0.05285231429754465
Trained batch 317 in epoch 13, gen_loss = 0.8735869180106517, disc_loss = 0.05275605654390822
Trained batch 318 in epoch 13, gen_loss = 0.8726274083400595, disc_loss = 0.05312904040840072
Trained batch 319 in epoch 13, gen_loss = 0.8729910161346197, disc_loss = 0.05319873486005235
Trained batch 320 in epoch 13, gen_loss = 0.8734139686804323, disc_loss = 0.053058261344806984
Trained batch 321 in epoch 13, gen_loss = 0.8734674516671933, disc_loss = 0.05292723772133359
Trained batch 322 in epoch 13, gen_loss = 0.8744274639861872, disc_loss = 0.05288179722778937
Trained batch 323 in epoch 13, gen_loss = 0.8742733468979965, disc_loss = 0.05288767162710428
Trained batch 324 in epoch 13, gen_loss = 0.8742709438617413, disc_loss = 0.052795533566520766
Trained batch 325 in epoch 13, gen_loss = 0.8746015714721446, disc_loss = 0.052693868792998644
Trained batch 326 in epoch 13, gen_loss = 0.8753828043602293, disc_loss = 0.052806812478087
Trained batch 327 in epoch 13, gen_loss = 0.8747643948328204, disc_loss = 0.05283246143357601
Trained batch 328 in epoch 13, gen_loss = 0.8749841846593608, disc_loss = 0.05274429478000363
Trained batch 329 in epoch 13, gen_loss = 0.8754841172333919, disc_loss = 0.05264644462502364
Trained batch 330 in epoch 13, gen_loss = 0.8763639275040871, disc_loss = 0.05274149872295086
Trained batch 331 in epoch 13, gen_loss = 0.8761098104787161, disc_loss = 0.052708052457815194
Trained batch 332 in epoch 13, gen_loss = 0.875794980261061, disc_loss = 0.05278378483411428
Trained batch 333 in epoch 13, gen_loss = 0.8770136230006189, disc_loss = 0.05273115206621364
Trained batch 334 in epoch 13, gen_loss = 0.8769804096933621, disc_loss = 0.052748464826327654
Trained batch 335 in epoch 13, gen_loss = 0.8769308286053794, disc_loss = 0.052636952053511606
Trained batch 336 in epoch 13, gen_loss = 0.8765464525901953, disc_loss = 0.05261495074074859
Trained batch 337 in epoch 13, gen_loss = 0.8756648834640458, disc_loss = 0.053096760100183577
Trained batch 338 in epoch 13, gen_loss = 0.876791550346532, disc_loss = 0.05344197458716708
Trained batch 339 in epoch 13, gen_loss = 0.8774799178628361, disc_loss = 0.05340179107699762
Trained batch 340 in epoch 13, gen_loss = 0.8779122437899414, disc_loss = 0.05329774165269304
Trained batch 341 in epoch 13, gen_loss = 0.8778448965814378, disc_loss = 0.053169122763653424
Trained batch 342 in epoch 13, gen_loss = 0.8777335235745845, disc_loss = 0.05307476422084229
Trained batch 343 in epoch 13, gen_loss = 0.8778561185612235, disc_loss = 0.052994207303083046
Trained batch 344 in epoch 13, gen_loss = 0.8788274500681006, disc_loss = 0.05348923774031193
Trained batch 345 in epoch 13, gen_loss = 0.8787203401843936, disc_loss = 0.053427381298337885
Trained batch 346 in epoch 13, gen_loss = 0.8777867770332425, disc_loss = 0.053852676333435504
Trained batch 347 in epoch 13, gen_loss = 0.878676440352681, disc_loss = 0.054389210072635065
Trained batch 348 in epoch 13, gen_loss = 0.8784089040619596, disc_loss = 0.05437193405053933
Trained batch 349 in epoch 13, gen_loss = 0.8775303993906294, disc_loss = 0.05450973406167967
Trained batch 350 in epoch 13, gen_loss = 0.8765922793295988, disc_loss = 0.05462846153301646
Trained batch 351 in epoch 13, gen_loss = 0.8768250727179375, disc_loss = 0.05467429248859513
Trained batch 352 in epoch 13, gen_loss = 0.8771524765336142, disc_loss = 0.05476701772236199
Trained batch 353 in epoch 13, gen_loss = 0.8763099822957637, disc_loss = 0.05501922499651542
Trained batch 354 in epoch 13, gen_loss = 0.8761670832902613, disc_loss = 0.05491586765930266
Trained batch 355 in epoch 13, gen_loss = 0.8760813339037842, disc_loss = 0.05490053434374878
Trained batch 356 in epoch 13, gen_loss = 0.8764119179976755, disc_loss = 0.054795172459417195
Trained batch 357 in epoch 13, gen_loss = 0.8765705918799566, disc_loss = 0.05468998590026405
Trained batch 358 in epoch 13, gen_loss = 0.8760853768391197, disc_loss = 0.05459726812229764
Trained batch 359 in epoch 13, gen_loss = 0.8765103596780035, disc_loss = 0.054700684720753796
Trained batch 360 in epoch 13, gen_loss = 0.8760969647079954, disc_loss = 0.054688655404977686
Trained batch 361 in epoch 13, gen_loss = 0.8755006747351167, disc_loss = 0.054794249230306284
Trained batch 362 in epoch 13, gen_loss = 0.875878224688128, disc_loss = 0.05466712729045839
Trained batch 363 in epoch 13, gen_loss = 0.8765162082163842, disc_loss = 0.05499559727876068
Trained batch 364 in epoch 13, gen_loss = 0.8767729318305237, disc_loss = 0.054896839718296106
Trained batch 365 in epoch 13, gen_loss = 0.8762941901149646, disc_loss = 0.055150615020853576
Trained batch 366 in epoch 13, gen_loss = 0.8758739414916701, disc_loss = 0.055183291963075747
Trained batch 367 in epoch 13, gen_loss = 0.8755721074083577, disc_loss = 0.055205088230254856
Trained batch 368 in epoch 13, gen_loss = 0.8754695863904669, disc_loss = 0.05528467439296769
Trained batch 369 in epoch 13, gen_loss = 0.8752349953393679, disc_loss = 0.05523619262149205
Trained batch 370 in epoch 13, gen_loss = 0.8758332144539311, disc_loss = 0.055186886983017394
Trained batch 371 in epoch 13, gen_loss = 0.8758141464123161, disc_loss = 0.05512023204436866
Trained batch 372 in epoch 13, gen_loss = 0.8760154907249573, disc_loss = 0.05528741353878067
Trained batch 373 in epoch 13, gen_loss = 0.8759623185836057, disc_loss = 0.055241324884050036
Trained batch 374 in epoch 13, gen_loss = 0.8760043611526489, disc_loss = 0.05518723032871882
Trained batch 375 in epoch 13, gen_loss = 0.8761438036218603, disc_loss = 0.055092740462141784
Trained batch 376 in epoch 13, gen_loss = 0.8765492518321273, disc_loss = 0.055011609559310524
Trained batch 377 in epoch 13, gen_loss = 0.8757898794910896, disc_loss = 0.05516078756264751
Trained batch 378 in epoch 13, gen_loss = 0.8759873040747831, disc_loss = 0.05509416729034881
Trained batch 379 in epoch 13, gen_loss = 0.8768962736192503, disc_loss = 0.05531212473288179
Trained batch 380 in epoch 13, gen_loss = 0.8760825184386546, disc_loss = 0.055467496056530105
Trained batch 381 in epoch 13, gen_loss = 0.8759701933848296, disc_loss = 0.055396328899638816
Trained batch 382 in epoch 13, gen_loss = 0.8758615443662937, disc_loss = 0.055328555366233496
Trained batch 383 in epoch 13, gen_loss = 0.875807389151305, disc_loss = 0.05524499965152548
Trained batch 384 in epoch 13, gen_loss = 0.8757506533102556, disc_loss = 0.05516291856281943
Trained batch 385 in epoch 13, gen_loss = 0.875329624185908, disc_loss = 0.05511438446553723
Trained batch 386 in epoch 13, gen_loss = 0.8761230562392439, disc_loss = 0.055060184447609795
Trained batch 387 in epoch 13, gen_loss = 0.8760620831828756, disc_loss = 0.055008352095664466
Trained batch 388 in epoch 13, gen_loss = 0.8765973376737463, disc_loss = 0.05490433774256461
Trained batch 389 in epoch 13, gen_loss = 0.8766639856191781, disc_loss = 0.05482178015682178
Trained batch 390 in epoch 13, gen_loss = 0.8760581175079736, disc_loss = 0.05494038259986874
Trained batch 391 in epoch 13, gen_loss = 0.8759851261061065, disc_loss = 0.054960368643039645
Trained batch 392 in epoch 13, gen_loss = 0.875768929037429, disc_loss = 0.054873234533133704
Trained batch 393 in epoch 13, gen_loss = 0.8760899928620625, disc_loss = 0.054770315077798774
Trained batch 394 in epoch 13, gen_loss = 0.8766386303720595, disc_loss = 0.05483984779566527
Trained batch 395 in epoch 13, gen_loss = 0.8755220151459328, disc_loss = 0.055489980570990784
Trained batch 396 in epoch 13, gen_loss = 0.8754840614063013, disc_loss = 0.0554232406746643
Trained batch 397 in epoch 13, gen_loss = 0.8756822072830631, disc_loss = 0.05535866744844383
Trained batch 398 in epoch 13, gen_loss = 0.8766074509997117, disc_loss = 0.055499107296809666
Trained batch 399 in epoch 13, gen_loss = 0.8760820264369249, disc_loss = 0.05552347302203998
Trained batch 400 in epoch 13, gen_loss = 0.8756290963314418, disc_loss = 0.05560372992560379
Trained batch 401 in epoch 13, gen_loss = 0.8751967720576187, disc_loss = 0.05556333936815757
Trained batch 402 in epoch 13, gen_loss = 0.8752161606813483, disc_loss = 0.05570467830249674
Trained batch 403 in epoch 13, gen_loss = 0.875008205302281, disc_loss = 0.055658076905949726
Trained batch 404 in epoch 13, gen_loss = 0.8748256461855806, disc_loss = 0.05562646253563372
Trained batch 405 in epoch 13, gen_loss = 0.8748903080013585, disc_loss = 0.055516267931685216
Trained batch 406 in epoch 13, gen_loss = 0.8744651936635338, disc_loss = 0.05549307911901641
Trained batch 407 in epoch 13, gen_loss = 0.8744051368067077, disc_loss = 0.0554171645598413
Trained batch 408 in epoch 13, gen_loss = 0.8763313546303141, disc_loss = 0.055676998659367226
Trained batch 409 in epoch 13, gen_loss = 0.8766919286512747, disc_loss = 0.05557866553298947
Trained batch 410 in epoch 13, gen_loss = 0.8759512500316268, disc_loss = 0.055756210979445865
Trained batch 411 in epoch 13, gen_loss = 0.8759501491790836, disc_loss = 0.05568828184419827
Trained batch 412 in epoch 13, gen_loss = 0.8763032971946726, disc_loss = 0.05581462993252725
Trained batch 413 in epoch 13, gen_loss = 0.8752983093693636, disc_loss = 0.05604446485215699
Trained batch 414 in epoch 13, gen_loss = 0.8749672449496855, disc_loss = 0.056044425332851436
Trained batch 415 in epoch 13, gen_loss = 0.8755252435087011, disc_loss = 0.05610987924872181
Trained batch 416 in epoch 13, gen_loss = 0.8757600955111231, disc_loss = 0.05600675385963502
Trained batch 417 in epoch 13, gen_loss = 0.8754003527774765, disc_loss = 0.05602784851637255
Trained batch 418 in epoch 13, gen_loss = 0.8762278110855803, disc_loss = 0.05599897425301675
Trained batch 419 in epoch 13, gen_loss = 0.8758474807654109, disc_loss = 0.056030014345777174
Trained batch 420 in epoch 13, gen_loss = 0.8763742444775733, disc_loss = 0.05592809518635485
Trained batch 421 in epoch 13, gen_loss = 0.8757206072315785, disc_loss = 0.056102368718021996
Trained batch 422 in epoch 13, gen_loss = 0.8750347600056488, disc_loss = 0.05620695844548039
Trained batch 423 in epoch 13, gen_loss = 0.8748444327908866, disc_loss = 0.056143962714452086
Trained batch 424 in epoch 13, gen_loss = 0.8747089824255775, disc_loss = 0.056080813379410434
Trained batch 425 in epoch 13, gen_loss = 0.8750153534429174, disc_loss = 0.05598608307111921
Trained batch 426 in epoch 13, gen_loss = 0.8750325231278528, disc_loss = 0.05596814369804616
Trained batch 427 in epoch 13, gen_loss = 0.8741105102072252, disc_loss = 0.05606451027191061
Trained batch 428 in epoch 13, gen_loss = 0.8742276252983333, disc_loss = 0.05595975877860418
Trained batch 429 in epoch 13, gen_loss = 0.8742973242388216, disc_loss = 0.05584809464554107
Trained batch 430 in epoch 13, gen_loss = 0.8738586072163903, disc_loss = 0.05581604179185048
Trained batch 431 in epoch 13, gen_loss = 0.8739048294309113, disc_loss = 0.05573383995323201
Trained batch 432 in epoch 13, gen_loss = 0.8741978890763694, disc_loss = 0.05562874018999707
Trained batch 433 in epoch 13, gen_loss = 0.8739506425808102, disc_loss = 0.05561506282752766
Trained batch 434 in epoch 13, gen_loss = 0.8745363330704042, disc_loss = 0.055787726361090424
Trained batch 435 in epoch 13, gen_loss = 0.8740551760847416, disc_loss = 0.05594237645823132
Trained batch 436 in epoch 13, gen_loss = 0.8740579913491788, disc_loss = 0.055838426670967445
Trained batch 437 in epoch 13, gen_loss = 0.8737250237840496, disc_loss = 0.05579393691081366
Trained batch 438 in epoch 13, gen_loss = 0.8739398136090037, disc_loss = 0.05573743094471633
Trained batch 439 in epoch 13, gen_loss = 0.873772027885372, disc_loss = 0.05570276155856184
Trained batch 440 in epoch 13, gen_loss = 0.8738217554530319, disc_loss = 0.05571342641255415
Trained batch 441 in epoch 13, gen_loss = 0.8741612041293226, disc_loss = 0.0557185632168269
Trained batch 442 in epoch 13, gen_loss = 0.8737135411788863, disc_loss = 0.055739353331011925
Trained batch 443 in epoch 13, gen_loss = 0.8731068663366206, disc_loss = 0.0558050678317175
Trained batch 444 in epoch 13, gen_loss = 0.8735238595624988, disc_loss = 0.05570354886729731
Trained batch 445 in epoch 13, gen_loss = 0.8740172402874771, disc_loss = 0.05566211650148034
Trained batch 446 in epoch 13, gen_loss = 0.8745140480648484, disc_loss = 0.05555894717332434
Trained batch 447 in epoch 13, gen_loss = 0.8747906881118459, disc_loss = 0.05555891070772694
Trained batch 448 in epoch 13, gen_loss = 0.8743007317815963, disc_loss = 0.05567815984269492
Trained batch 449 in epoch 13, gen_loss = 0.8741335982084274, disc_loss = 0.05560506769145528
Trained batch 450 in epoch 13, gen_loss = 0.8741691866497243, disc_loss = 0.055548439849325004
Trained batch 451 in epoch 13, gen_loss = 0.8744046645222512, disc_loss = 0.05549189110237083
Trained batch 452 in epoch 13, gen_loss = 0.8742968453871494, disc_loss = 0.05543948190027712
Trained batch 453 in epoch 13, gen_loss = 0.8738633464480287, disc_loss = 0.055478634450190786
Trained batch 454 in epoch 13, gen_loss = 0.8741337926178188, disc_loss = 0.05542625802681669
Trained batch 455 in epoch 13, gen_loss = 0.8743936224072649, disc_loss = 0.05535423023454649
Trained batch 456 in epoch 13, gen_loss = 0.8740315257981257, disc_loss = 0.05534759409016475
Trained batch 457 in epoch 13, gen_loss = 0.8739969110254637, disc_loss = 0.0552783303601285
Trained batch 458 in epoch 13, gen_loss = 0.8739343229072546, disc_loss = 0.05548100868414495
Trained batch 459 in epoch 13, gen_loss = 0.8743668757702994, disc_loss = 0.05540483584829971
Trained batch 460 in epoch 13, gen_loss = 0.8740658321116855, disc_loss = 0.055364780247195294
Trained batch 461 in epoch 13, gen_loss = 0.874700063299307, disc_loss = 0.05528878489735
Trained batch 462 in epoch 13, gen_loss = 0.8743820375165465, disc_loss = 0.05525390706256386
Trained batch 463 in epoch 13, gen_loss = 0.8746746053341133, disc_loss = 0.05520809492987484
Trained batch 464 in epoch 13, gen_loss = 0.8746066585022916, disc_loss = 0.055240921690178815
Trained batch 465 in epoch 13, gen_loss = 0.8742486817258622, disc_loss = 0.05533525507393505
Trained batch 466 in epoch 13, gen_loss = 0.8741360096783403, disc_loss = 0.05536222700189153
Trained batch 467 in epoch 13, gen_loss = 0.8740200910430688, disc_loss = 0.05531728538111425
Trained batch 468 in epoch 13, gen_loss = 0.8742085528144958, disc_loss = 0.05535445161966055
Trained batch 469 in epoch 13, gen_loss = 0.8739690948674019, disc_loss = 0.05538016164358309
Trained batch 470 in epoch 13, gen_loss = 0.8735329080412595, disc_loss = 0.055386528022777125
Trained batch 471 in epoch 13, gen_loss = 0.8740876666191271, disc_loss = 0.05538489285785452
Trained batch 472 in epoch 13, gen_loss = 0.8745654834627349, disc_loss = 0.05548486680414599
Trained batch 473 in epoch 13, gen_loss = 0.8745042125258264, disc_loss = 0.05547605363557799
Trained batch 474 in epoch 13, gen_loss = 0.8745202824316527, disc_loss = 0.05543183207315834
Trained batch 475 in epoch 13, gen_loss = 0.8743010383068013, disc_loss = 0.05551832472756818
Trained batch 476 in epoch 13, gen_loss = 0.8738768909837215, disc_loss = 0.05566225399066005
Trained batch 477 in epoch 13, gen_loss = 0.8741345912467485, disc_loss = 0.05592538974205009
Trained batch 478 in epoch 13, gen_loss = 0.8739353924180869, disc_loss = 0.05588816588312885
Trained batch 479 in epoch 13, gen_loss = 0.874131505501767, disc_loss = 0.05580808603165981
Trained batch 480 in epoch 13, gen_loss = 0.8735679296966402, disc_loss = 0.055893798525253474
Trained batch 481 in epoch 13, gen_loss = 0.8735334833009609, disc_loss = 0.05591488712084677
Trained batch 482 in epoch 13, gen_loss = 0.8738931431656792, disc_loss = 0.05584212415899858
Trained batch 483 in epoch 13, gen_loss = 0.8735790291477826, disc_loss = 0.05576785414649004
Trained batch 484 in epoch 13, gen_loss = 0.8740487073500132, disc_loss = 0.05570361470400365
Trained batch 485 in epoch 13, gen_loss = 0.874850436922454, disc_loss = 0.055663681889926334
Trained batch 486 in epoch 13, gen_loss = 0.8747888259451981, disc_loss = 0.055606250559387144
Trained batch 487 in epoch 13, gen_loss = 0.874531264615352, disc_loss = 0.05554637111166156
Trained batch 488 in epoch 13, gen_loss = 0.8745703015225065, disc_loss = 0.05564056542380151
Trained batch 489 in epoch 13, gen_loss = 0.8742669682721702, disc_loss = 0.055584856474353954
Trained batch 490 in epoch 13, gen_loss = 0.8737800833285462, disc_loss = 0.05559727912408332
Trained batch 491 in epoch 13, gen_loss = 0.8739305100426441, disc_loss = 0.05550214395161748
Trained batch 492 in epoch 13, gen_loss = 0.8743349614177224, disc_loss = 0.055466326635565166
Trained batch 493 in epoch 13, gen_loss = 0.874415726374518, disc_loss = 0.05537783908978225
Trained batch 494 in epoch 13, gen_loss = 0.8742205611985139, disc_loss = 0.05531106936472534
Trained batch 495 in epoch 13, gen_loss = 0.8735730560917047, disc_loss = 0.055472046698278356
Trained batch 496 in epoch 13, gen_loss = 0.8743044403597143, disc_loss = 0.05545739852589081
Trained batch 497 in epoch 13, gen_loss = 0.8746431811626656, disc_loss = 0.05539912283308355
Trained batch 498 in epoch 13, gen_loss = 0.8746891022325757, disc_loss = 0.05533500784496685
Trained batch 499 in epoch 13, gen_loss = 0.8748098927140235, disc_loss = 0.05524453622661531
Trained batch 500 in epoch 13, gen_loss = 0.8749126047788266, disc_loss = 0.055159598497856045
Trained batch 501 in epoch 13, gen_loss = 0.8748256606291015, disc_loss = 0.055098164067844825
Trained batch 502 in epoch 13, gen_loss = 0.8748186565417182, disc_loss = 0.05503029828598616
Trained batch 503 in epoch 13, gen_loss = 0.8751204105478431, disc_loss = 0.05495494046241104
Trained batch 504 in epoch 13, gen_loss = 0.8751226055149984, disc_loss = 0.05486464540630874
Trained batch 505 in epoch 13, gen_loss = 0.8753614105843743, disc_loss = 0.05477296496951297
Trained batch 506 in epoch 13, gen_loss = 0.8756585845933158, disc_loss = 0.05469327106248933
Trained batch 507 in epoch 13, gen_loss = 0.8755385240349244, disc_loss = 0.05461032539019434
Trained batch 508 in epoch 13, gen_loss = 0.875556041836036, disc_loss = 0.05452667418245248
Trained batch 509 in epoch 13, gen_loss = 0.8757580848885518, disc_loss = 0.05443423885815576
Trained batch 510 in epoch 13, gen_loss = 0.8758087986952638, disc_loss = 0.054347715572018444
Trained batch 511 in epoch 13, gen_loss = 0.8754708561464213, disc_loss = 0.0543015900766477
Trained batch 512 in epoch 13, gen_loss = 0.8756148431152396, disc_loss = 0.054209341434852655
Trained batch 513 in epoch 13, gen_loss = 0.8761107536025549, disc_loss = 0.054144997269292054
Trained batch 514 in epoch 13, gen_loss = 0.8758668419805545, disc_loss = 0.054094160427746264
Trained batch 515 in epoch 13, gen_loss = 0.875983850380709, disc_loss = 0.05400641914276594
Trained batch 516 in epoch 13, gen_loss = 0.8758595699383166, disc_loss = 0.053994659678488106
Trained batch 517 in epoch 13, gen_loss = 0.8752956479557693, disc_loss = 0.05404406524727186
Trained batch 518 in epoch 13, gen_loss = 0.8756384456203622, disc_loss = 0.053971070478632616
Trained batch 519 in epoch 13, gen_loss = 0.8755962552359471, disc_loss = 0.05388480610608195
Trained batch 520 in epoch 13, gen_loss = 0.8755474009921135, disc_loss = 0.05382846059338431
Trained batch 521 in epoch 13, gen_loss = 0.8754572466986389, disc_loss = 0.05376146237947532
Trained batch 522 in epoch 13, gen_loss = 0.8752789538973376, disc_loss = 0.05368942845555781
Trained batch 523 in epoch 13, gen_loss = 0.875237722831373, disc_loss = 0.05363898655179291
Trained batch 524 in epoch 13, gen_loss = 0.8757718812284015, disc_loss = 0.05360209041230735
Trained batch 525 in epoch 13, gen_loss = 0.8764861046474696, disc_loss = 0.05356993876617161
Trained batch 526 in epoch 13, gen_loss = 0.8762212873523104, disc_loss = 0.05351662918380983
Trained batch 527 in epoch 13, gen_loss = 0.8759365620825327, disc_loss = 0.053469966657840734
Trained batch 528 in epoch 13, gen_loss = 0.875580036741574, disc_loss = 0.05345489433834537
Trained batch 529 in epoch 13, gen_loss = 0.8754713170370966, disc_loss = 0.05347147941554211
Trained batch 530 in epoch 13, gen_loss = 0.8754122217383986, disc_loss = 0.05340687682055877
Trained batch 531 in epoch 13, gen_loss = 0.8753733064111014, disc_loss = 0.05334209534339607
Trained batch 532 in epoch 13, gen_loss = 0.8752296750921246, disc_loss = 0.053286190626978536
Trained batch 533 in epoch 13, gen_loss = 0.8752911373805464, disc_loss = 0.0532150818261733
Trained batch 534 in epoch 13, gen_loss = 0.8755232294586217, disc_loss = 0.05314561890211896
Trained batch 535 in epoch 13, gen_loss = 0.8759650154901084, disc_loss = 0.05310801319159401
Trained batch 536 in epoch 13, gen_loss = 0.8759020998158269, disc_loss = 0.05304205568344289
Trained batch 537 in epoch 13, gen_loss = 0.8759940074389752, disc_loss = 0.05297841497811188
Trained batch 538 in epoch 13, gen_loss = 0.8754716077076482, disc_loss = 0.053004057091316954
Trained batch 539 in epoch 13, gen_loss = 0.875868576599492, disc_loss = 0.0529540052930652
Trained batch 540 in epoch 13, gen_loss = 0.8758586890265594, disc_loss = 0.05287819482943873
Trained batch 541 in epoch 13, gen_loss = 0.8758151399803338, disc_loss = 0.052800850363661334
Trained batch 542 in epoch 13, gen_loss = 0.8764472726190508, disc_loss = 0.05277165327166271
Trained batch 543 in epoch 13, gen_loss = 0.8762249163735438, disc_loss = 0.052732437128297
Trained batch 544 in epoch 13, gen_loss = 0.8759849070955854, disc_loss = 0.05267077706104845
Trained batch 545 in epoch 13, gen_loss = 0.8761552237656527, disc_loss = 0.05259340589067766
Trained batch 546 in epoch 13, gen_loss = 0.8761423150080867, disc_loss = 0.05253689469500586
Trained batch 547 in epoch 13, gen_loss = 0.8764717711040574, disc_loss = 0.052453003800814
Trained batch 548 in epoch 13, gen_loss = 0.8763021981455589, disc_loss = 0.052383264955065345
Trained batch 549 in epoch 13, gen_loss = 0.8763018709421158, disc_loss = 0.052307866108180445
Trained batch 550 in epoch 13, gen_loss = 0.8763823818057073, disc_loss = 0.052241799329490336
Trained batch 551 in epoch 13, gen_loss = 0.8759408201752366, disc_loss = 0.052319780526095594
Trained batch 552 in epoch 13, gen_loss = 0.8764256218997307, disc_loss = 0.05227991408511835
Trained batch 553 in epoch 13, gen_loss = 0.8767047874656395, disc_loss = 0.05228315123074456
Trained batch 554 in epoch 13, gen_loss = 0.8767367697513855, disc_loss = 0.052222537773720046
Trained batch 555 in epoch 13, gen_loss = 0.8764484890823742, disc_loss = 0.052227399989513666
Trained batch 556 in epoch 13, gen_loss = 0.8767270623995543, disc_loss = 0.052179722517521475
Trained batch 557 in epoch 13, gen_loss = 0.8771787287407024, disc_loss = 0.05222159805440588
Trained batch 558 in epoch 13, gen_loss = 0.8771164998918611, disc_loss = 0.05216011855907885
Trained batch 559 in epoch 13, gen_loss = 0.8769696423517807, disc_loss = 0.05214323225580821
Trained batch 560 in epoch 13, gen_loss = 0.8768973811106249, disc_loss = 0.05209403990148675
Trained batch 561 in epoch 13, gen_loss = 0.8769550030235718, disc_loss = 0.052019794522105214
Trained batch 562 in epoch 13, gen_loss = 0.8777450460206129, disc_loss = 0.052015660460509004
Trained batch 563 in epoch 13, gen_loss = 0.878053438948824, disc_loss = 0.052043193648239026
Trained batch 564 in epoch 13, gen_loss = 0.8777287471083414, disc_loss = 0.052134461662179866
Trained batch 565 in epoch 13, gen_loss = 0.8775237445380578, disc_loss = 0.05210277080855105
Trained batch 566 in epoch 13, gen_loss = 0.8773388251320605, disc_loss = 0.05205599215403987
Trained batch 567 in epoch 13, gen_loss = 0.8780212927557213, disc_loss = 0.052160900946162166
Trained batch 568 in epoch 13, gen_loss = 0.8782543135129295, disc_loss = 0.05208448794063161
Trained batch 569 in epoch 13, gen_loss = 0.8779834162247808, disc_loss = 0.05209873894539972
Trained batch 570 in epoch 13, gen_loss = 0.8781774378595335, disc_loss = 0.05202183458911689
Trained batch 571 in epoch 13, gen_loss = 0.8782864840818452, disc_loss = 0.05194542576946396
Trained batch 572 in epoch 13, gen_loss = 0.878356283403816, disc_loss = 0.05187686973123
Trained batch 573 in epoch 13, gen_loss = 0.8781257199597275, disc_loss = 0.05185356986942581
Trained batch 574 in epoch 13, gen_loss = 0.8778329343899437, disc_loss = 0.05184697122920467
Trained batch 575 in epoch 13, gen_loss = 0.8782313872232206, disc_loss = 0.052311681239290114
Trained batch 576 in epoch 13, gen_loss = 0.8781668768495167, disc_loss = 0.052267263079323584
Trained batch 577 in epoch 13, gen_loss = 0.8775791744975483, disc_loss = 0.052448208559027334
Trained batch 578 in epoch 13, gen_loss = 0.8777776875747094, disc_loss = 0.05244129054193644
Trained batch 579 in epoch 13, gen_loss = 0.8779678525081996, disc_loss = 0.052424670077442864
Trained batch 580 in epoch 13, gen_loss = 0.8781417440526867, disc_loss = 0.052353408040956506
Trained batch 581 in epoch 13, gen_loss = 0.8776306844351628, disc_loss = 0.05245921229607589
Trained batch 582 in epoch 13, gen_loss = 0.8778002897523484, disc_loss = 0.05249909900758243
Trained batch 583 in epoch 13, gen_loss = 0.8781609071342096, disc_loss = 0.05243456634542943
Trained batch 584 in epoch 13, gen_loss = 0.8777959868948684, disc_loss = 0.052463499428783984
Trained batch 585 in epoch 13, gen_loss = 0.8779904812370958, disc_loss = 0.05238670657735331
Trained batch 586 in epoch 13, gen_loss = 0.8782179455639353, disc_loss = 0.0523971096284091
Trained batch 587 in epoch 13, gen_loss = 0.8780738956161908, disc_loss = 0.0523429681280894
Trained batch 588 in epoch 13, gen_loss = 0.878545829871312, disc_loss = 0.05228358334806354
Trained batch 589 in epoch 13, gen_loss = 0.8784606373411114, disc_loss = 0.05221842979791306
Trained batch 590 in epoch 13, gen_loss = 0.8786198945114052, disc_loss = 0.052147905151603995
Trained batch 591 in epoch 13, gen_loss = 0.8785834809312144, disc_loss = 0.05210354643861285
Trained batch 592 in epoch 13, gen_loss = 0.8783633004855145, disc_loss = 0.05205069609225098
Trained batch 593 in epoch 13, gen_loss = 0.8786026985456646, disc_loss = 0.05204095584199284
Trained batch 594 in epoch 13, gen_loss = 0.8784990025668585, disc_loss = 0.051999120223296794
Trained batch 595 in epoch 13, gen_loss = 0.8784732728096463, disc_loss = 0.05193985729547055
Trained batch 596 in epoch 13, gen_loss = 0.8790122437816569, disc_loss = 0.05192222996260752
Trained batch 597 in epoch 13, gen_loss = 0.8791683720406083, disc_loss = 0.051856146162892865
Trained batch 598 in epoch 13, gen_loss = 0.8792571021937369, disc_loss = 0.051790085509232864
Trained batch 599 in epoch 13, gen_loss = 0.8791818814973037, disc_loss = 0.051765840803273025
Trained batch 600 in epoch 13, gen_loss = 0.8792602628618231, disc_loss = 0.05169545476651827
Trained batch 601 in epoch 13, gen_loss = 0.879500981531666, disc_loss = 0.05162027789484029
Trained batch 602 in epoch 13, gen_loss = 0.879875610074396, disc_loss = 0.05155524559578492
Trained batch 603 in epoch 13, gen_loss = 0.8797495650830648, disc_loss = 0.05151828138515452
Trained batch 604 in epoch 13, gen_loss = 0.8802695114257907, disc_loss = 0.05147958753153312
Trained batch 605 in epoch 13, gen_loss = 0.8803375667766375, disc_loss = 0.051405614195852586
Trained batch 606 in epoch 13, gen_loss = 0.8801845859558225, disc_loss = 0.0513435080448009
Trained batch 607 in epoch 13, gen_loss = 0.8802476629712864, disc_loss = 0.05127029652526529
Trained batch 608 in epoch 13, gen_loss = 0.8805481888879891, disc_loss = 0.05120616471119629
Trained batch 609 in epoch 13, gen_loss = 0.8806739145126499, disc_loss = 0.05156887388696558
Trained batch 610 in epoch 13, gen_loss = 0.880092470179603, disc_loss = 0.05189428338323721
Trained batch 611 in epoch 13, gen_loss = 0.880053706174972, disc_loss = 0.05183738662809548
Trained batch 612 in epoch 13, gen_loss = 0.8803814559640153, disc_loss = 0.05184253523138399
Trained batch 613 in epoch 13, gen_loss = 0.8800340156504697, disc_loss = 0.05182031094072332
Trained batch 614 in epoch 13, gen_loss = 0.8800833709356262, disc_loss = 0.05178227106684713
Trained batch 615 in epoch 13, gen_loss = 0.8800436651648639, disc_loss = 0.05171927764434246
Trained batch 616 in epoch 13, gen_loss = 0.8798653262650754, disc_loss = 0.05169363763723734
Trained batch 617 in epoch 13, gen_loss = 0.8798816342473416, disc_loss = 0.05163812081323497
Trained batch 618 in epoch 13, gen_loss = 0.880332343171987, disc_loss = 0.051981843572398816
Trained batch 619 in epoch 13, gen_loss = 0.88013984325432, disc_loss = 0.05198310999154684
Trained batch 620 in epoch 13, gen_loss = 0.8800401256184263, disc_loss = 0.05198803399846966
Trained batch 621 in epoch 13, gen_loss = 0.8805420987571551, disc_loss = 0.052055002310705575
Trained batch 622 in epoch 13, gen_loss = 0.8799749698436088, disc_loss = 0.052306173459729884
Trained batch 623 in epoch 13, gen_loss = 0.8796347838659317, disc_loss = 0.05232330868751981
Trained batch 624 in epoch 13, gen_loss = 0.8797272785663605, disc_loss = 0.052358095822483304
Trained batch 625 in epoch 13, gen_loss = 0.8800809151543596, disc_loss = 0.052311737665359063
Trained batch 626 in epoch 13, gen_loss = 0.8801237208326087, disc_loss = 0.052249027841666525
Trained batch 627 in epoch 13, gen_loss = 0.8798705586677145, disc_loss = 0.05226303887431907
Trained batch 628 in epoch 13, gen_loss = 0.8801645209660401, disc_loss = 0.052197891707267075
Trained batch 629 in epoch 13, gen_loss = 0.8804225670439857, disc_loss = 0.05218061157650063
Trained batch 630 in epoch 13, gen_loss = 0.880393987081697, disc_loss = 0.05212881354461594
Trained batch 631 in epoch 13, gen_loss = 0.8805444156161591, disc_loss = 0.052090063789134396
Trained batch 632 in epoch 13, gen_loss = 0.8804142692171943, disc_loss = 0.0520541533087726
Trained batch 633 in epoch 13, gen_loss = 0.8803626026734945, disc_loss = 0.05201713365432145
Trained batch 634 in epoch 13, gen_loss = 0.880457587082555, disc_loss = 0.051950916487312926
Trained batch 635 in epoch 13, gen_loss = 0.8806175503809497, disc_loss = 0.0518858817782335
Trained batch 636 in epoch 13, gen_loss = 0.8808222073868642, disc_loss = 0.051895537857387326
Trained batch 637 in epoch 13, gen_loss = 0.8804261951143839, disc_loss = 0.05190924319824011
Trained batch 638 in epoch 13, gen_loss = 0.8801845769647142, disc_loss = 0.05188511296923102
Trained batch 639 in epoch 13, gen_loss = 0.8806952819693834, disc_loss = 0.05200732447046903
Trained batch 640 in epoch 13, gen_loss = 0.8806445228049238, disc_loss = 0.051978330984392
Trained batch 641 in epoch 13, gen_loss = 0.880769458190303, disc_loss = 0.05195244660563303
Trained batch 642 in epoch 13, gen_loss = 0.8802074529983763, disc_loss = 0.05207915239189614
Trained batch 643 in epoch 13, gen_loss = 0.8801736933936984, disc_loss = 0.052066088440793315
Trained batch 644 in epoch 13, gen_loss = 0.8801623028840205, disc_loss = 0.05211177813755565
Trained batch 645 in epoch 13, gen_loss = 0.8800234178732792, disc_loss = 0.05216144875409918
Trained batch 646 in epoch 13, gen_loss = 0.8799227843236702, disc_loss = 0.05220100655647965
Trained batch 647 in epoch 13, gen_loss = 0.8797961227411841, disc_loss = 0.05217478492219622
Trained batch 648 in epoch 13, gen_loss = 0.8799045265455643, disc_loss = 0.05216953435120602
Trained batch 649 in epoch 13, gen_loss = 0.8797417269761746, disc_loss = 0.05215625504533259
Trained batch 650 in epoch 13, gen_loss = 0.879747264167314, disc_loss = 0.05210692025563707
Trained batch 651 in epoch 13, gen_loss = 0.8796265801312002, disc_loss = 0.05206276539018938
Trained batch 652 in epoch 13, gen_loss = 0.8798682897324585, disc_loss = 0.05214906058090227
Trained batch 653 in epoch 13, gen_loss = 0.8798805729967374, disc_loss = 0.05211962741053455
Trained batch 654 in epoch 13, gen_loss = 0.8793650354592855, disc_loss = 0.052202016920675984
Trained batch 655 in epoch 13, gen_loss = 0.8796829203734311, disc_loss = 0.05216991182249153
Trained batch 656 in epoch 13, gen_loss = 0.8797504212849034, disc_loss = 0.052133841338727616
Trained batch 657 in epoch 13, gen_loss = 0.8795358075287567, disc_loss = 0.05213525423448884
Trained batch 658 in epoch 13, gen_loss = 0.8794215664787611, disc_loss = 0.05211818920680193
Trained batch 659 in epoch 13, gen_loss = 0.8794215480938102, disc_loss = 0.05206997086166997
Trained batch 660 in epoch 13, gen_loss = 0.8794761288815295, disc_loss = 0.05202342629074802
Trained batch 661 in epoch 13, gen_loss = 0.8793591069580925, disc_loss = 0.0519769809629453
Trained batch 662 in epoch 13, gen_loss = 0.8799856348724566, disc_loss = 0.052174554534430644
Trained batch 663 in epoch 13, gen_loss = 0.8795568190335509, disc_loss = 0.05232946662279968
Trained batch 664 in epoch 13, gen_loss = 0.8795616844991097, disc_loss = 0.052271989306533026
Trained batch 665 in epoch 13, gen_loss = 0.879434241770624, disc_loss = 0.052365329926945384
Trained batch 666 in epoch 13, gen_loss = 0.8792228620538468, disc_loss = 0.0524088349102576
Trained batch 667 in epoch 13, gen_loss = 0.8788488311414233, disc_loss = 0.05251286512806811
Trained batch 668 in epoch 13, gen_loss = 0.8786445432446998, disc_loss = 0.05255000329380145
Trained batch 669 in epoch 13, gen_loss = 0.8789587950083747, disc_loss = 0.052652151843032506
Trained batch 670 in epoch 13, gen_loss = 0.8786719893112268, disc_loss = 0.0527656367971616
Trained batch 671 in epoch 13, gen_loss = 0.8786396147860658, disc_loss = 0.05274411724877566
Trained batch 672 in epoch 13, gen_loss = 0.878728120810564, disc_loss = 0.05269363496997802
Trained batch 673 in epoch 13, gen_loss = 0.8791545059542981, disc_loss = 0.05268368455968266
Trained batch 674 in epoch 13, gen_loss = 0.879150096266358, disc_loss = 0.0526490806284602
Trained batch 675 in epoch 13, gen_loss = 0.878744942593504, disc_loss = 0.052752417668606534
Trained batch 676 in epoch 13, gen_loss = 0.8790580286497204, disc_loss = 0.052708560523151954
Trained batch 677 in epoch 13, gen_loss = 0.8784240231489362, disc_loss = 0.05281996451370462
Trained batch 678 in epoch 13, gen_loss = 0.8787504094426516, disc_loss = 0.05284648218750405
Trained batch 679 in epoch 13, gen_loss = 0.8789929904043674, disc_loss = 0.05283100826542496
Trained batch 680 in epoch 13, gen_loss = 0.8787395333140957, disc_loss = 0.05287314498682182
Trained batch 681 in epoch 13, gen_loss = 0.8782620088708016, disc_loss = 0.05302692558875859
Trained batch 682 in epoch 13, gen_loss = 0.8786999707602478, disc_loss = 0.053037313743743986
Trained batch 683 in epoch 13, gen_loss = 0.8792001374545153, disc_loss = 0.053519885934622445
Trained batch 684 in epoch 13, gen_loss = 0.8789672619669977, disc_loss = 0.05353988333108978
Trained batch 685 in epoch 13, gen_loss = 0.8785740720548018, disc_loss = 0.053630338131203034
Trained batch 686 in epoch 13, gen_loss = 0.8784238464013284, disc_loss = 0.053607850412131876
Trained batch 687 in epoch 13, gen_loss = 0.8784228742209285, disc_loss = 0.05360668985007959
Trained batch 688 in epoch 13, gen_loss = 0.8787769641948888, disc_loss = 0.05369720531962758
Trained batch 689 in epoch 13, gen_loss = 0.8783783939869507, disc_loss = 0.05384438854939156
Trained batch 690 in epoch 13, gen_loss = 0.8781207782228501, disc_loss = 0.053940083003332015
Trained batch 691 in epoch 13, gen_loss = 0.877912998845467, disc_loss = 0.053980812007114506
Trained batch 692 in epoch 13, gen_loss = 0.8781882200664256, disc_loss = 0.053959130947202616
Trained batch 693 in epoch 13, gen_loss = 0.8782929096596386, disc_loss = 0.05391928843109833
Trained batch 694 in epoch 13, gen_loss = 0.8784406038068181, disc_loss = 0.05386164085001504
Trained batch 695 in epoch 13, gen_loss = 0.8786875506670311, disc_loss = 0.05380849988566412
Trained batch 696 in epoch 13, gen_loss = 0.8787404517275702, disc_loss = 0.0537682560545097
Trained batch 697 in epoch 13, gen_loss = 0.8786028530929013, disc_loss = 0.05372957260091722
Trained batch 698 in epoch 13, gen_loss = 0.878705740785053, disc_loss = 0.053667870646633094
Trained batch 699 in epoch 13, gen_loss = 0.8786658720885004, disc_loss = 0.05360934560519776
Trained batch 700 in epoch 13, gen_loss = 0.8786927396577707, disc_loss = 0.053547799105645714
Trained batch 701 in epoch 13, gen_loss = 0.8783841425621951, disc_loss = 0.053583721560625054
Trained batch 702 in epoch 13, gen_loss = 0.8784150799595953, disc_loss = 0.05359035709894038
Trained batch 703 in epoch 13, gen_loss = 0.8784328783354298, disc_loss = 0.05354007667615819
Trained batch 704 in epoch 13, gen_loss = 0.8788486625708587, disc_loss = 0.05358542763687512
Trained batch 705 in epoch 13, gen_loss = 0.878456952931523, disc_loss = 0.0537670853042516
Trained batch 706 in epoch 13, gen_loss = 0.8784984203932815, disc_loss = 0.0537470665265038
Trained batch 707 in epoch 13, gen_loss = 0.8787065017442245, disc_loss = 0.05375042267467321
Trained batch 708 in epoch 13, gen_loss = 0.8786146272977418, disc_loss = 0.053709581617150344
Trained batch 709 in epoch 13, gen_loss = 0.8784038747280416, disc_loss = 0.05366994078979421
Trained batch 710 in epoch 13, gen_loss = 0.8780430992528189, disc_loss = 0.05370916865711033
Trained batch 711 in epoch 13, gen_loss = 0.8782813505091694, disc_loss = 0.05412251382393846
Trained batch 712 in epoch 13, gen_loss = 0.8778012975486097, disc_loss = 0.05436382819356352
Trained batch 713 in epoch 13, gen_loss = 0.8778957201569688, disc_loss = 0.05450231787952117
Trained batch 714 in epoch 13, gen_loss = 0.8778368848603922, disc_loss = 0.05450028262811003
Trained batch 715 in epoch 13, gen_loss = 0.8774087109795495, disc_loss = 0.054562490323542844
Trained batch 716 in epoch 13, gen_loss = 0.877326098737025, disc_loss = 0.05452902353663554
Trained batch 717 in epoch 13, gen_loss = 0.8771787276258044, disc_loss = 0.05452791025439241
Trained batch 718 in epoch 13, gen_loss = 0.8770102549743254, disc_loss = 0.054483732345264005
Trained batch 719 in epoch 13, gen_loss = 0.8767930395487282, disc_loss = 0.05453261028807093
Trained batch 720 in epoch 13, gen_loss = 0.877045577218893, disc_loss = 0.05447901795126095
Trained batch 721 in epoch 13, gen_loss = 0.8769343584941035, disc_loss = 0.05445970669633856
Trained batch 722 in epoch 13, gen_loss = 0.8766389683321798, disc_loss = 0.05451565222907425
Trained batch 723 in epoch 13, gen_loss = 0.8768164422054318, disc_loss = 0.054464054846420924
Trained batch 724 in epoch 13, gen_loss = 0.8768129239822257, disc_loss = 0.05466633153565485
Trained batch 725 in epoch 13, gen_loss = 0.8768671068360326, disc_loss = 0.0546229903736298
Trained batch 726 in epoch 13, gen_loss = 0.8765145452101261, disc_loss = 0.054677194652456323
Trained batch 727 in epoch 13, gen_loss = 0.8767300567866027, disc_loss = 0.054631509413241644
Trained batch 728 in epoch 13, gen_loss = 0.8768326781986509, disc_loss = 0.05462504764865517
Trained batch 729 in epoch 13, gen_loss = 0.8769699866232806, disc_loss = 0.054578672767272345
Trained batch 730 in epoch 13, gen_loss = 0.8766559922173314, disc_loss = 0.05459520688519982
Trained batch 731 in epoch 13, gen_loss = 0.8765810922276779, disc_loss = 0.05461810939357479
Trained batch 732 in epoch 13, gen_loss = 0.8761091085524383, disc_loss = 0.054718612414361635
Trained batch 733 in epoch 13, gen_loss = 0.8765135756224313, disc_loss = 0.05478279453915435
Trained batch 734 in epoch 13, gen_loss = 0.8765620637507666, disc_loss = 0.054848314223012756
Trained batch 735 in epoch 13, gen_loss = 0.8762942846135601, disc_loss = 0.054871054932490275
Trained batch 736 in epoch 13, gen_loss = 0.8762232090676332, disc_loss = 0.054842021775632854
Trained batch 737 in epoch 13, gen_loss = 0.875789064500067, disc_loss = 0.0549184112099118
Trained batch 738 in epoch 13, gen_loss = 0.8759745868762226, disc_loss = 0.05499989976879607
Trained batch 739 in epoch 13, gen_loss = 0.8763287787099142, disc_loss = 0.055012996141748455
Trained batch 740 in epoch 13, gen_loss = 0.8763136482029631, disc_loss = 0.05495187619766384
Trained batch 741 in epoch 13, gen_loss = 0.8758404714800919, disc_loss = 0.055029386284854015
Trained batch 742 in epoch 13, gen_loss = 0.8757320851448568, disc_loss = 0.05499213737589815
Trained batch 743 in epoch 13, gen_loss = 0.8761839178060332, disc_loss = 0.05502949284717581
Trained batch 744 in epoch 13, gen_loss = 0.8760913810073929, disc_loss = 0.05506865092359433
Trained batch 745 in epoch 13, gen_loss = 0.8756885653606369, disc_loss = 0.055152650934396856
Trained batch 746 in epoch 13, gen_loss = 0.8754879994644538, disc_loss = 0.05515388762603303
Trained batch 747 in epoch 13, gen_loss = 0.8755364188934392, disc_loss = 0.05511103455353289
Trained batch 748 in epoch 13, gen_loss = 0.8752288525906678, disc_loss = 0.055108442001706254
Trained batch 749 in epoch 13, gen_loss = 0.8751722743113836, disc_loss = 0.055045963793372114
Trained batch 750 in epoch 13, gen_loss = 0.8751548285411296, disc_loss = 0.055001932844276555
Trained batch 751 in epoch 13, gen_loss = 0.875399671613853, disc_loss = 0.05494430769628726
Trained batch 752 in epoch 13, gen_loss = 0.8751249607419904, disc_loss = 0.054945934355471675
Trained batch 753 in epoch 13, gen_loss = 0.875466136424864, disc_loss = 0.05515305762579393
Trained batch 754 in epoch 13, gen_loss = 0.8750747947108667, disc_loss = 0.05542505716485594
Trained batch 755 in epoch 13, gen_loss = 0.8750038190730034, disc_loss = 0.055391836839373265
Trained batch 756 in epoch 13, gen_loss = 0.87487138384557, disc_loss = 0.055429306680329214
Trained batch 757 in epoch 13, gen_loss = 0.8749205755920083, disc_loss = 0.05539063250923672
Trained batch 758 in epoch 13, gen_loss = 0.8748646977312166, disc_loss = 0.05543766006500962
Trained batch 759 in epoch 13, gen_loss = 0.8747604059153482, disc_loss = 0.0554795997088628
Trained batch 760 in epoch 13, gen_loss = 0.8745196528644662, disc_loss = 0.05545753427278177
Trained batch 761 in epoch 13, gen_loss = 0.8744247484942433, disc_loss = 0.05545258613149306
Trained batch 762 in epoch 13, gen_loss = 0.8742321313677421, disc_loss = 0.055536548060830075
Trained batch 763 in epoch 13, gen_loss = 0.8741794649453063, disc_loss = 0.055506842534535646
Trained batch 764 in epoch 13, gen_loss = 0.8747620706854303, disc_loss = 0.055485507014992774
Trained batch 765 in epoch 13, gen_loss = 0.8749943818731657, disc_loss = 0.05548910880959824
Trained batch 766 in epoch 13, gen_loss = 0.8748510858770144, disc_loss = 0.055487161589060294
Trained batch 767 in epoch 13, gen_loss = 0.8744989864450569, disc_loss = 0.05566219056284657
Trained batch 768 in epoch 13, gen_loss = 0.8743032222838953, disc_loss = 0.05568763628415521
Trained batch 769 in epoch 13, gen_loss = 0.8746509872086636, disc_loss = 0.05569612191953732
Trained batch 770 in epoch 13, gen_loss = 0.8747553126125485, disc_loss = 0.05564758567086357
Trained batch 771 in epoch 13, gen_loss = 0.8745806941019438, disc_loss = 0.05565544193154539
Trained batch 772 in epoch 13, gen_loss = 0.8747102554603197, disc_loss = 0.05560738886772796
Trained batch 773 in epoch 13, gen_loss = 0.875076088524912, disc_loss = 0.055557910549678194
Trained batch 774 in epoch 13, gen_loss = 0.8747718111545809, disc_loss = 0.05559844283747577
Trained batch 775 in epoch 13, gen_loss = 0.874661537905022, disc_loss = 0.05558392042522175
Trained batch 776 in epoch 13, gen_loss = 0.874588208577501, disc_loss = 0.05555863418056602
Trained batch 777 in epoch 13, gen_loss = 0.8746142931723043, disc_loss = 0.0555529378990195
Trained batch 778 in epoch 13, gen_loss = 0.8745098033291079, disc_loss = 0.055524363477184736
Trained batch 779 in epoch 13, gen_loss = 0.8741825183614707, disc_loss = 0.05561574884176923
Trained batch 780 in epoch 13, gen_loss = 0.8738964871239876, disc_loss = 0.05564796491901697
Trained batch 781 in epoch 13, gen_loss = 0.8742358383086636, disc_loss = 0.055726254520261344
Trained batch 782 in epoch 13, gen_loss = 0.8742617971976293, disc_loss = 0.055683513710187274
Trained batch 783 in epoch 13, gen_loss = 0.8741328099324387, disc_loss = 0.0556526357511163
Trained batch 784 in epoch 13, gen_loss = 0.8739600894177795, disc_loss = 0.05566135603092184
Trained batch 785 in epoch 13, gen_loss = 0.8740911906532962, disc_loss = 0.05568908352070694
Trained batch 786 in epoch 13, gen_loss = 0.874144412245805, disc_loss = 0.05568969376524851
Trained batch 787 in epoch 13, gen_loss = 0.8742442489199832, disc_loss = 0.0556348707558833
Trained batch 788 in epoch 13, gen_loss = 0.8739113462061936, disc_loss = 0.055829472121568954
Trained batch 789 in epoch 13, gen_loss = 0.8743127194009249, disc_loss = 0.05587379113723866
Testing Epoch 13
Training Epoch 14
Trained batch 0 in epoch 14, gen_loss = 0.8878545761108398, disc_loss = 0.025556646287441254
Trained batch 1 in epoch 14, gen_loss = 0.7732703983783722, disc_loss = 0.06338615342974663
Trained batch 2 in epoch 14, gen_loss = 0.7571512659390768, disc_loss = 0.05756731082995733
Trained batch 3 in epoch 14, gen_loss = 0.8613713830709457, disc_loss = 0.06372646987438202
Trained batch 4 in epoch 14, gen_loss = 0.8769581198692322, disc_loss = 0.0625125840306282
Trained batch 5 in epoch 14, gen_loss = 0.8231070339679718, disc_loss = 0.07890338574846585
Trained batch 6 in epoch 14, gen_loss = 0.8281811560903277, disc_loss = 0.0691579622881753
Trained batch 7 in epoch 14, gen_loss = 0.8351793736219406, disc_loss = 0.06627437705174088
Trained batch 8 in epoch 14, gen_loss = 0.8283982806735568, disc_loss = 0.0648910469479031
Trained batch 9 in epoch 14, gen_loss = 0.8327138900756836, disc_loss = 0.061316877603530884
Trained batch 10 in epoch 14, gen_loss = 0.8219434402205728, disc_loss = 0.0603891827843406
Trained batch 11 in epoch 14, gen_loss = 0.832861120502154, disc_loss = 0.05599671990300218
Trained batch 12 in epoch 14, gen_loss = 0.8281604601786687, disc_loss = 0.052855185591257535
Trained batch 13 in epoch 14, gen_loss = 0.8473854660987854, disc_loss = 0.05397147898163114
Trained batch 14 in epoch 14, gen_loss = 0.8354492584864298, disc_loss = 0.054180845121542615
Trained batch 15 in epoch 14, gen_loss = 0.8428597450256348, disc_loss = 0.051918917801231146
Trained batch 16 in epoch 14, gen_loss = 0.851393089574926, disc_loss = 0.04934023868511705
Trained batch 17 in epoch 14, gen_loss = 0.8547816011640761, disc_loss = 0.047704576411181025
Trained batch 18 in epoch 14, gen_loss = 0.8621971669949984, disc_loss = 0.0465121320203731
Trained batch 19 in epoch 14, gen_loss = 0.8633281648159027, disc_loss = 0.045632658340036866
Trained batch 20 in epoch 14, gen_loss = 0.862637752578372, disc_loss = 0.04547133456383433
Trained batch 21 in epoch 14, gen_loss = 0.8507501699707725, disc_loss = 0.047670933841304344
Trained batch 22 in epoch 14, gen_loss = 0.8599657442258752, disc_loss = 0.04771266359349956
Trained batch 23 in epoch 14, gen_loss = 0.8803906589746475, disc_loss = 0.050583881636460624
Trained batch 24 in epoch 14, gen_loss = 0.883521957397461, disc_loss = 0.049179977551102635
Trained batch 25 in epoch 14, gen_loss = 0.8737861835039579, disc_loss = 0.05390608117270928
Trained batch 26 in epoch 14, gen_loss = 0.8666589414631879, disc_loss = 0.05440860138171249
Trained batch 27 in epoch 14, gen_loss = 0.8695454150438309, disc_loss = 0.0543076335452497
Trained batch 28 in epoch 14, gen_loss = 0.8844647798044928, disc_loss = 0.05664902597922703
Trained batch 29 in epoch 14, gen_loss = 0.8789722561836243, disc_loss = 0.056277852567533655
Trained batch 30 in epoch 14, gen_loss = 0.8707081925484442, disc_loss = 0.0576026558034843
Trained batch 31 in epoch 14, gen_loss = 0.87309380620718, disc_loss = 0.05652839917456731
Trained batch 32 in epoch 14, gen_loss = 0.8832206437082002, disc_loss = 0.060594856682600395
Trained batch 33 in epoch 14, gen_loss = 0.8776733805151546, disc_loss = 0.061728023814366144
Trained batch 34 in epoch 14, gen_loss = 0.874087062903813, disc_loss = 0.06169534948255335
Trained batch 35 in epoch 14, gen_loss = 0.8873235434293747, disc_loss = 0.06483268308349782
Trained batch 36 in epoch 14, gen_loss = 0.883586720840351, disc_loss = 0.06402738397387234
Trained batch 37 in epoch 14, gen_loss = 0.8758758510413923, disc_loss = 0.06477278024938546
Trained batch 38 in epoch 14, gen_loss = 0.8740021189053854, disc_loss = 0.06375915065216713
Trained batch 39 in epoch 14, gen_loss = 0.877598623931408, disc_loss = 0.06251203906722366
Trained batch 40 in epoch 14, gen_loss = 0.8798351825737372, disc_loss = 0.06298996748902448
Trained batch 41 in epoch 14, gen_loss = 0.8770689779803866, disc_loss = 0.0627978252956555
Trained batch 42 in epoch 14, gen_loss = 0.8721236337062924, disc_loss = 0.06276224991090076
Trained batch 43 in epoch 14, gen_loss = 0.8696841123429212, disc_loss = 0.0618778227574446
Trained batch 44 in epoch 14, gen_loss = 0.8696742468410068, disc_loss = 0.060884947329759596
Trained batch 45 in epoch 14, gen_loss = 0.8712494982325513, disc_loss = 0.06027280077662157
Trained batch 46 in epoch 14, gen_loss = 0.8717435433509502, disc_loss = 0.05934153889563489
Trained batch 47 in epoch 14, gen_loss = 0.8688159994781017, disc_loss = 0.059116291774747275
Trained batch 48 in epoch 14, gen_loss = 0.8708083945877698, disc_loss = 0.05997293347454801
Trained batch 49 in epoch 14, gen_loss = 0.8715663707256317, disc_loss = 0.05909502848982811
Trained batch 50 in epoch 14, gen_loss = 0.867000841626934, disc_loss = 0.06103397599037956
Trained batch 51 in epoch 14, gen_loss = 0.8696905282827524, disc_loss = 0.061199565346424394
Trained batch 52 in epoch 14, gen_loss = 0.8629872416550258, disc_loss = 0.06246829370282731
Trained batch 53 in epoch 14, gen_loss = 0.8691674846189993, disc_loss = 0.06450227896372478
Trained batch 54 in epoch 14, gen_loss = 0.8741249929774891, disc_loss = 0.06448869759386236
Trained batch 55 in epoch 14, gen_loss = 0.8727406965834754, disc_loss = 0.06405060299273048
Trained batch 56 in epoch 14, gen_loss = 0.8677851672758136, disc_loss = 0.06559250582205622
Trained batch 57 in epoch 14, gen_loss = 0.8660050188672954, disc_loss = 0.06545095736610479
Trained batch 58 in epoch 14, gen_loss = 0.8713736301761562, disc_loss = 0.06624234265695184
Trained batch 59 in epoch 14, gen_loss = 0.8701254894336065, disc_loss = 0.06552629011372725
Trained batch 60 in epoch 14, gen_loss = 0.8653660006210452, disc_loss = 0.06562076411286338
Trained batch 61 in epoch 14, gen_loss = 0.8672079626590975, disc_loss = 0.06954621523618698
Trained batch 62 in epoch 14, gen_loss = 0.8639302793003264, disc_loss = 0.06899465691475641
Trained batch 63 in epoch 14, gen_loss = 0.8640385419130325, disc_loss = 0.06818222915171646
Trained batch 64 in epoch 14, gen_loss = 0.8613102023418133, disc_loss = 0.06792751914606644
Trained batch 65 in epoch 14, gen_loss = 0.8604331820300131, disc_loss = 0.0674142533574592
Trained batch 66 in epoch 14, gen_loss = 0.8576740159917233, disc_loss = 0.06790968962013721
Trained batch 67 in epoch 14, gen_loss = 0.857837562175358, disc_loss = 0.06717530276407213
Trained batch 68 in epoch 14, gen_loss = 0.8568734319313712, disc_loss = 0.06644798631685367
Trained batch 69 in epoch 14, gen_loss = 0.8555349920477185, disc_loss = 0.06627579256892205
Trained batch 70 in epoch 14, gen_loss = 0.8569374982739838, disc_loss = 0.06576034182708868
Trained batch 71 in epoch 14, gen_loss = 0.8608857086963124, disc_loss = 0.06506556841648287
Trained batch 72 in epoch 14, gen_loss = 0.8576519081037338, disc_loss = 0.0655989672427308
Trained batch 73 in epoch 14, gen_loss = 0.8600233422743307, disc_loss = 0.06504424862764976
Trained batch 74 in epoch 14, gen_loss = 0.8577773729960124, disc_loss = 0.06488901704549789
Trained batch 75 in epoch 14, gen_loss = 0.8601518100813815, disc_loss = 0.06421282753887537
Trained batch 76 in epoch 14, gen_loss = 0.8633704479638632, disc_loss = 0.06451888676345735
Trained batch 77 in epoch 14, gen_loss = 0.8589003009673877, disc_loss = 0.06620918026862618
Trained batch 78 in epoch 14, gen_loss = 0.8596530171889293, disc_loss = 0.0654762362165353
Trained batch 79 in epoch 14, gen_loss = 0.8613475367426873, disc_loss = 0.06476193558191881
Trained batch 80 in epoch 14, gen_loss = 0.8633659989745529, disc_loss = 0.06532394080020396
Trained batch 81 in epoch 14, gen_loss = 0.8636746275715712, disc_loss = 0.06475503696128726
Trained batch 82 in epoch 14, gen_loss = 0.8635267550686756, disc_loss = 0.06445923109864254
Trained batch 83 in epoch 14, gen_loss = 0.8648332868303571, disc_loss = 0.06377339564884703
Trained batch 84 in epoch 14, gen_loss = 0.8628357578726376, disc_loss = 0.06325912723208175
Trained batch 85 in epoch 14, gen_loss = 0.8623904079891914, disc_loss = 0.06278455406860557
Trained batch 86 in epoch 14, gen_loss = 0.8609570134645221, disc_loss = 0.0627106685705226
Trained batch 87 in epoch 14, gen_loss = 0.862813919105313, disc_loss = 0.06252859568816017
Trained batch 88 in epoch 14, gen_loss = 0.8649667668878362, disc_loss = 0.061912072372486755
Trained batch 89 in epoch 14, gen_loss = 0.8636140114731259, disc_loss = 0.061785811134096646
Trained batch 90 in epoch 14, gen_loss = 0.8646664514646425, disc_loss = 0.06122857451971088
Trained batch 91 in epoch 14, gen_loss = 0.8673014161379441, disc_loss = 0.06221007884723013
Trained batch 92 in epoch 14, gen_loss = 0.8655707893833038, disc_loss = 0.0622460498144069
Trained batch 93 in epoch 14, gen_loss = 0.863500030750924, disc_loss = 0.06199189490499966
Trained batch 94 in epoch 14, gen_loss = 0.8632373558847528, disc_loss = 0.06154001218904006
Trained batch 95 in epoch 14, gen_loss = 0.8627379660805067, disc_loss = 0.06104925900581293
Trained batch 96 in epoch 14, gen_loss = 0.8648899351198649, disc_loss = 0.061704966258833704
Trained batch 97 in epoch 14, gen_loss = 0.8623380788734981, disc_loss = 0.06215219280435419
Trained batch 98 in epoch 14, gen_loss = 0.8638019700243016, disc_loss = 0.06165562913461466
Trained batch 99 in epoch 14, gen_loss = 0.8687200576066971, disc_loss = 0.06254934784956276
Trained batch 100 in epoch 14, gen_loss = 0.8662859490602324, disc_loss = 0.06275472853627831
Trained batch 101 in epoch 14, gen_loss = 0.864051971949783, disc_loss = 0.06312947447283887
Trained batch 102 in epoch 14, gen_loss = 0.8650032652234568, disc_loss = 0.06404762958330147
Trained batch 103 in epoch 14, gen_loss = 0.8655924963263365, disc_loss = 0.06358358463666473
Trained batch 104 in epoch 14, gen_loss = 0.8639562975792657, disc_loss = 0.0636150262096808
Trained batch 105 in epoch 14, gen_loss = 0.8683139215100486, disc_loss = 0.06343082267404446
Trained batch 106 in epoch 14, gen_loss = 0.867859936763193, disc_loss = 0.06319775365327841
Trained batch 107 in epoch 14, gen_loss = 0.8672012587388357, disc_loss = 0.06302510125183121
Trained batch 108 in epoch 14, gen_loss = 0.8686345443813079, disc_loss = 0.0625879587092941
Trained batch 109 in epoch 14, gen_loss = 0.869105863571167, disc_loss = 0.062216683942824605
Trained batch 110 in epoch 14, gen_loss = 0.8705265693836384, disc_loss = 0.06199384379192247
Trained batch 111 in epoch 14, gen_loss = 0.8679168123219695, disc_loss = 0.06276754980873582
Trained batch 112 in epoch 14, gen_loss = 0.8705439055915427, disc_loss = 0.06373190338335998
Trained batch 113 in epoch 14, gen_loss = 0.8695484446851831, disc_loss = 0.06386643778042574
Trained batch 114 in epoch 14, gen_loss = 0.868296129807182, disc_loss = 0.06399042229775502
Trained batch 115 in epoch 14, gen_loss = 0.8702570384946363, disc_loss = 0.06374889617817926
Trained batch 116 in epoch 14, gen_loss = 0.8689543161636744, disc_loss = 0.06356032529415992
Trained batch 117 in epoch 14, gen_loss = 0.8701971345028635, disc_loss = 0.06342019187286496
Trained batch 118 in epoch 14, gen_loss = 0.8680220406596401, disc_loss = 0.06358709533017974
Trained batch 119 in epoch 14, gen_loss = 0.8664294506112734, disc_loss = 0.06362626859142134
Trained batch 120 in epoch 14, gen_loss = 0.8701158451639917, disc_loss = 0.06337162777627549
Trained batch 121 in epoch 14, gen_loss = 0.8686981543165738, disc_loss = 0.06310609147166375
Trained batch 122 in epoch 14, gen_loss = 0.8693813095247842, disc_loss = 0.06281427005533038
Trained batch 123 in epoch 14, gen_loss = 0.8689098906132483, disc_loss = 0.06273483279942264
Trained batch 124 in epoch 14, gen_loss = 0.8694041452407837, disc_loss = 0.062349929697811605
Trained batch 125 in epoch 14, gen_loss = 0.8692467950639271, disc_loss = 0.06222929478076006
Trained batch 126 in epoch 14, gen_loss = 0.8682186284403163, disc_loss = 0.06211097480538558
Trained batch 127 in epoch 14, gen_loss = 0.8672803388908505, disc_loss = 0.0618585805859766
Trained batch 128 in epoch 14, gen_loss = 0.8706732720367668, disc_loss = 0.06252739413157683
Trained batch 129 in epoch 14, gen_loss = 0.87059142772968, disc_loss = 0.06216197402144854
Trained batch 130 in epoch 14, gen_loss = 0.869341735621445, disc_loss = 0.062225713117318296
Trained batch 131 in epoch 14, gen_loss = 0.8693893475062919, disc_loss = 0.0618553702352625
Trained batch 132 in epoch 14, gen_loss = 0.8716672134578676, disc_loss = 0.061672042943257135
Trained batch 133 in epoch 14, gen_loss = 0.8711500643794217, disc_loss = 0.06129799977834545
Trained batch 134 in epoch 14, gen_loss = 0.8703330962746232, disc_loss = 0.06097591218573076
Trained batch 135 in epoch 14, gen_loss = 0.8697276553686928, disc_loss = 0.06109374912236543
Trained batch 136 in epoch 14, gen_loss = 0.8690619990773445, disc_loss = 0.06079034813183502
Trained batch 137 in epoch 14, gen_loss = 0.8675701160361802, disc_loss = 0.060771908624556614
Trained batch 138 in epoch 14, gen_loss = 0.8658595977069663, disc_loss = 0.060951294457848124
Trained batch 139 in epoch 14, gen_loss = 0.8664507303919111, disc_loss = 0.061817057231175046
Trained batch 140 in epoch 14, gen_loss = 0.8660043139829703, disc_loss = 0.06167089808335964
Trained batch 141 in epoch 14, gen_loss = 0.8652172726644597, disc_loss = 0.061506466769521505
Trained batch 142 in epoch 14, gen_loss = 0.8644769400149792, disc_loss = 0.06135761166004451
Trained batch 143 in epoch 14, gen_loss = 0.8655212231808238, disc_loss = 0.06120376554059072
Trained batch 144 in epoch 14, gen_loss = 0.86519296169281, disc_loss = 0.06094797131573332
Trained batch 145 in epoch 14, gen_loss = 0.8641117737717825, disc_loss = 0.060712444710813156
Trained batch 146 in epoch 14, gen_loss = 0.8648068073655473, disc_loss = 0.060654218403660524
Trained batch 147 in epoch 14, gen_loss = 0.8640841418826902, disc_loss = 0.060513821606700484
Trained batch 148 in epoch 14, gen_loss = 0.8664256098286417, disc_loss = 0.06033661331506383
Trained batch 149 in epoch 14, gen_loss = 0.8654979153474172, disc_loss = 0.06020507916808129
Trained batch 150 in epoch 14, gen_loss = 0.8660855778795205, disc_loss = 0.05993098874163154
Trained batch 151 in epoch 14, gen_loss = 0.8666880189588195, disc_loss = 0.0596260232238197
Trained batch 152 in epoch 14, gen_loss = 0.8652372648513394, disc_loss = 0.059550887217221696
Trained batch 153 in epoch 14, gen_loss = 0.8640489911104178, disc_loss = 0.05941718413990427
Trained batch 154 in epoch 14, gen_loss = 0.8642892833678953, disc_loss = 0.059134161700644804
Trained batch 155 in epoch 14, gen_loss = 0.8660979404663428, disc_loss = 0.058942519570103824
Trained batch 156 in epoch 14, gen_loss = 0.8664686964575652, disc_loss = 0.05961462462641251
Trained batch 157 in epoch 14, gen_loss = 0.8652452950990652, disc_loss = 0.059681071805520146
Trained batch 158 in epoch 14, gen_loss = 0.8645445756942222, disc_loss = 0.059810150262413535
Trained batch 159 in epoch 14, gen_loss = 0.8639849659055472, disc_loss = 0.05959813749650493
Trained batch 160 in epoch 14, gen_loss = 0.8630802968273992, disc_loss = 0.05945767347718248
Trained batch 161 in epoch 14, gen_loss = 0.8647552850069823, disc_loss = 0.05930427426219354
Trained batch 162 in epoch 14, gen_loss = 0.8649968069755226, disc_loss = 0.05923906244063304
Trained batch 163 in epoch 14, gen_loss = 0.8636089934081566, disc_loss = 0.0596586001650771
Trained batch 164 in epoch 14, gen_loss = 0.8617811506444758, disc_loss = 0.060274360769174314
Trained batch 165 in epoch 14, gen_loss = 0.863457814038518, disc_loss = 0.06220796310443835
Trained batch 166 in epoch 14, gen_loss = 0.8632587569202491, disc_loss = 0.06215157961015573
Trained batch 167 in epoch 14, gen_loss = 0.8635297020276388, disc_loss = 0.06209432101985883
Trained batch 168 in epoch 14, gen_loss = 0.8619856732131461, disc_loss = 0.062348203314743805
Trained batch 169 in epoch 14, gen_loss = 0.8601950494682088, disc_loss = 0.06253498646923725
Trained batch 170 in epoch 14, gen_loss = 0.8600478126988773, disc_loss = 0.06227335764084294
Trained batch 171 in epoch 14, gen_loss = 0.8620383694421413, disc_loss = 0.06305217364976226
Trained batch 172 in epoch 14, gen_loss = 0.8620553915900302, disc_loss = 0.06281585331381745
Trained batch 173 in epoch 14, gen_loss = 0.8605091705404478, disc_loss = 0.06300985396721925
Trained batch 174 in epoch 14, gen_loss = 0.8595995736122132, disc_loss = 0.062841130271554
Trained batch 175 in epoch 14, gen_loss = 0.8601307747038928, disc_loss = 0.06263703925916078
Trained batch 176 in epoch 14, gen_loss = 0.8596094462831142, disc_loss = 0.06336539829055131
Trained batch 177 in epoch 14, gen_loss = 0.859131542484412, disc_loss = 0.06323873993595329
Trained batch 178 in epoch 14, gen_loss = 0.856332756787039, disc_loss = 0.0650022432478613
Trained batch 179 in epoch 14, gen_loss = 0.8566164025002055, disc_loss = 0.06482575288456348
Trained batch 180 in epoch 14, gen_loss = 0.8578579783110328, disc_loss = 0.0647721357376042
Trained batch 181 in epoch 14, gen_loss = 0.8580246864111869, disc_loss = 0.06467376290155309
Trained batch 182 in epoch 14, gen_loss = 0.8579569737442204, disc_loss = 0.06449168583612298
Trained batch 183 in epoch 14, gen_loss = 0.8571930684797142, disc_loss = 0.06443061093475831
Trained batch 184 in epoch 14, gen_loss = 0.8561092797163371, disc_loss = 0.06434483511021008
Trained batch 185 in epoch 14, gen_loss = 0.8571195424564423, disc_loss = 0.06406651553447529
Trained batch 186 in epoch 14, gen_loss = 0.8570467993856113, disc_loss = 0.0638967395864706
Trained batch 187 in epoch 14, gen_loss = 0.8566549640703709, disc_loss = 0.06370164706629325
Trained batch 188 in epoch 14, gen_loss = 0.8567272050986214, disc_loss = 0.06355331779984885
Trained batch 189 in epoch 14, gen_loss = 0.8580565181217695, disc_loss = 0.06345043693129954
Trained batch 190 in epoch 14, gen_loss = 0.8564076924511276, disc_loss = 0.06398588279505987
Trained batch 191 in epoch 14, gen_loss = 0.8570934367987016, disc_loss = 0.06433413201981845
Trained batch 192 in epoch 14, gen_loss = 0.8557902736676172, disc_loss = 0.0646546978812298
Trained batch 193 in epoch 14, gen_loss = 0.8558547058978032, disc_loss = 0.06448530159007336
Trained batch 194 in epoch 14, gen_loss = 0.8553001286127628, disc_loss = 0.06461715842477786
Trained batch 195 in epoch 14, gen_loss = 0.855567679265324, disc_loss = 0.06462832870037884
Trained batch 196 in epoch 14, gen_loss = 0.8568019481177257, disc_loss = 0.06443528396072727
Trained batch 197 in epoch 14, gen_loss = 0.8560739838414722, disc_loss = 0.0645673635481584
Trained batch 198 in epoch 14, gen_loss = 0.855879298855911, disc_loss = 0.06437375539698494
Trained batch 199 in epoch 14, gen_loss = 0.8557306112349033, disc_loss = 0.06434795179404318
Trained batch 200 in epoch 14, gen_loss = 0.857217366570857, disc_loss = 0.06432862662297872
Trained batch 201 in epoch 14, gen_loss = 0.8554824072830748, disc_loss = 0.06469690018693114
Trained batch 202 in epoch 14, gen_loss = 0.8561046171951764, disc_loss = 0.06442155351798082
Trained batch 203 in epoch 14, gen_loss = 0.856194721279191, disc_loss = 0.06431038842499986
Trained batch 204 in epoch 14, gen_loss = 0.8561889408565149, disc_loss = 0.06410909603554302
Trained batch 205 in epoch 14, gen_loss = 0.855683997852131, disc_loss = 0.06400441414070795
Trained batch 206 in epoch 14, gen_loss = 0.8551851434696124, disc_loss = 0.06395452460139125
Trained batch 207 in epoch 14, gen_loss = 0.8560052604342883, disc_loss = 0.06368382521367703
Trained batch 208 in epoch 14, gen_loss = 0.8550582732024946, disc_loss = 0.06377611155109257
Trained batch 209 in epoch 14, gen_loss = 0.8554346020732607, disc_loss = 0.06354779110600552
Trained batch 210 in epoch 14, gen_loss = 0.8562204209266681, disc_loss = 0.06341719679463814
Trained batch 211 in epoch 14, gen_loss = 0.8557987743110027, disc_loss = 0.06332861757749375
Trained batch 212 in epoch 14, gen_loss = 0.8562063842032437, disc_loss = 0.06314393901594088
Trained batch 213 in epoch 14, gen_loss = 0.8570359874273015, disc_loss = 0.06290964228666832
Trained batch 214 in epoch 14, gen_loss = 0.8564076289188031, disc_loss = 0.06283669466542643
Trained batch 215 in epoch 14, gen_loss = 0.8558239328364531, disc_loss = 0.06290400892289148
Trained batch 216 in epoch 14, gen_loss = 0.8568587400671523, disc_loss = 0.06269118227579627
Trained batch 217 in epoch 14, gen_loss = 0.8579700128474367, disc_loss = 0.06271917601927705
Trained batch 218 in epoch 14, gen_loss = 0.85704419533956, disc_loss = 0.0630049914053586
Trained batch 219 in epoch 14, gen_loss = 0.8559657463973219, disc_loss = 0.06310682926665653
Trained batch 220 in epoch 14, gen_loss = 0.8571551610711473, disc_loss = 0.06297562182017041
Trained batch 221 in epoch 14, gen_loss = 0.8575030048419764, disc_loss = 0.06276942735856718
Trained batch 222 in epoch 14, gen_loss = 0.8566229040045374, disc_loss = 0.06294929637101733
Trained batch 223 in epoch 14, gen_loss = 0.8568581354671291, disc_loss = 0.06273209891514853
Trained batch 224 in epoch 14, gen_loss = 0.8561011893219418, disc_loss = 0.06273021683924727
Trained batch 225 in epoch 14, gen_loss = 0.857910628999229, disc_loss = 0.06298942273004657
Trained batch 226 in epoch 14, gen_loss = 0.8573942590127432, disc_loss = 0.06292848642669323
Trained batch 227 in epoch 14, gen_loss = 0.8575735950940534, disc_loss = 0.06275337440239494
Trained batch 228 in epoch 14, gen_loss = 0.8576293372951741, disc_loss = 0.06266358994988636
Trained batch 229 in epoch 14, gen_loss = 0.8572075412325237, disc_loss = 0.06255535495507976
Trained batch 230 in epoch 14, gen_loss = 0.8586312474368455, disc_loss = 0.06243592012851011
Trained batch 231 in epoch 14, gen_loss = 0.8594915875843887, disc_loss = 0.06221160898787965
Trained batch 232 in epoch 14, gen_loss = 0.8603333166996296, disc_loss = 0.062012740814570706
Trained batch 233 in epoch 14, gen_loss = 0.8600635667387236, disc_loss = 0.06184163664937274
Trained batch 234 in epoch 14, gen_loss = 0.8599038764517358, disc_loss = 0.061648993281290886
Trained batch 235 in epoch 14, gen_loss = 0.8598165841678441, disc_loss = 0.0615508354868803
Trained batch 236 in epoch 14, gen_loss = 0.859916185402166, disc_loss = 0.06139455703460466
Trained batch 237 in epoch 14, gen_loss = 0.8596649193713645, disc_loss = 0.06123585401869872
Trained batch 238 in epoch 14, gen_loss = 0.8606921752377035, disc_loss = 0.061049989740282425
Trained batch 239 in epoch 14, gen_loss = 0.8607626799494028, disc_loss = 0.06088295540927599
Trained batch 240 in epoch 14, gen_loss = 0.8606416970120426, disc_loss = 0.06070386663975805
Trained batch 241 in epoch 14, gen_loss = 0.8604982760080622, disc_loss = 0.060552259399132294
Trained batch 242 in epoch 14, gen_loss = 0.861111644241545, disc_loss = 0.060554250737521874
Trained batch 243 in epoch 14, gen_loss = 0.8601440510056058, disc_loss = 0.06082201770460997
Trained batch 244 in epoch 14, gen_loss = 0.860104984288313, disc_loss = 0.06061189178453416
Trained batch 245 in epoch 14, gen_loss = 0.8607791983257465, disc_loss = 0.06043581150441877
Trained batch 246 in epoch 14, gen_loss = 0.8606716328062992, disc_loss = 0.06027641674496143
Trained batch 247 in epoch 14, gen_loss = 0.8614540553141025, disc_loss = 0.06019992167280326
Trained batch 248 in epoch 14, gen_loss = 0.8617050866764712, disc_loss = 0.06002141382679882
Trained batch 249 in epoch 14, gen_loss = 0.860548518538475, disc_loss = 0.060260777413845064
Trained batch 250 in epoch 14, gen_loss = 0.8619139240794923, disc_loss = 0.06018169175284317
Trained batch 251 in epoch 14, gen_loss = 0.8620865208998559, disc_loss = 0.06005382976893868
Trained batch 252 in epoch 14, gen_loss = 0.862023370892634, disc_loss = 0.05988296087492596
Trained batch 253 in epoch 14, gen_loss = 0.8628877437724842, disc_loss = 0.05969914796534838
Trained batch 254 in epoch 14, gen_loss = 0.8626767157339582, disc_loss = 0.05955491210242697
Trained batch 255 in epoch 14, gen_loss = 0.8622133714379743, disc_loss = 0.05942512929686927
Trained batch 256 in epoch 14, gen_loss = 0.8627354471368085, disc_loss = 0.05926934847470503
Trained batch 257 in epoch 14, gen_loss = 0.8637933475795643, disc_loss = 0.059220025362807883
Trained batch 258 in epoch 14, gen_loss = 0.863129649268154, disc_loss = 0.05919987608006217
Trained batch 259 in epoch 14, gen_loss = 0.8627254232764244, disc_loss = 0.05916703131694633
Trained batch 260 in epoch 14, gen_loss = 0.8643845816453298, disc_loss = 0.05930403734546626
Trained batch 261 in epoch 14, gen_loss = 0.8642925302718432, disc_loss = 0.059194281871451905
Trained batch 262 in epoch 14, gen_loss = 0.8638223546766056, disc_loss = 0.05927328856399871
Trained batch 263 in epoch 14, gen_loss = 0.8651413643224672, disc_loss = 0.06007421620994468
Trained batch 264 in epoch 14, gen_loss = 0.8644344915758889, disc_loss = 0.060019615492871346
Trained batch 265 in epoch 14, gen_loss = 0.8638186917493218, disc_loss = 0.059965254084200115
Trained batch 266 in epoch 14, gen_loss = 0.8635845013548819, disc_loss = 0.059881002691047694
Trained batch 267 in epoch 14, gen_loss = 0.8630042470880409, disc_loss = 0.059870494824987075
Trained batch 268 in epoch 14, gen_loss = 0.8637707653320412, disc_loss = 0.05982448296711458
Trained batch 269 in epoch 14, gen_loss = 0.8642509371042252, disc_loss = 0.05973095340930201
Trained batch 270 in epoch 14, gen_loss = 0.8644012097283044, disc_loss = 0.05955953860992215
Trained batch 271 in epoch 14, gen_loss = 0.8640292765682235, disc_loss = 0.05947059577139204
Trained batch 272 in epoch 14, gen_loss = 0.8635900427788605, disc_loss = 0.05934835404785343
Trained batch 273 in epoch 14, gen_loss = 0.8638892583820942, disc_loss = 0.05927110560591856
Trained batch 274 in epoch 14, gen_loss = 0.8635386442054401, disc_loss = 0.0591773858056827
Trained batch 275 in epoch 14, gen_loss = 0.8638841027150983, disc_loss = 0.0589951601392333
Trained batch 276 in epoch 14, gen_loss = 0.8626481377475959, disc_loss = 0.05933610606763767
Trained batch 277 in epoch 14, gen_loss = 0.8641110256635886, disc_loss = 0.05956689283090959
Trained batch 278 in epoch 14, gen_loss = 0.8646193068728225, disc_loss = 0.0594431954472723
Trained batch 279 in epoch 14, gen_loss = 0.8647447774452822, disc_loss = 0.05934963699962412
Trained batch 280 in epoch 14, gen_loss = 0.8651880557214662, disc_loss = 0.05919976110878364
Trained batch 281 in epoch 14, gen_loss = 0.8648173387380357, disc_loss = 0.05907415622409354
Trained batch 282 in epoch 14, gen_loss = 0.8653390610807776, disc_loss = 0.05928274307255189
Trained batch 283 in epoch 14, gen_loss = 0.8655993895421565, disc_loss = 0.059144870260022055
Trained batch 284 in epoch 14, gen_loss = 0.8645563950664119, disc_loss = 0.05932062798947619
Trained batch 285 in epoch 14, gen_loss = 0.8640638607573676, disc_loss = 0.05937943011001273
Trained batch 286 in epoch 14, gen_loss = 0.8655750843913713, disc_loss = 0.05941860520569705
Trained batch 287 in epoch 14, gen_loss = 0.8657506916465031, disc_loss = 0.05928400105848494
Trained batch 288 in epoch 14, gen_loss = 0.8652545804589677, disc_loss = 0.059254850057891495
Trained batch 289 in epoch 14, gen_loss = 0.8653523754456948, disc_loss = 0.0592607645253683
Trained batch 290 in epoch 14, gen_loss = 0.8654884604858779, disc_loss = 0.05909328336132966
Trained batch 291 in epoch 14, gen_loss = 0.8652873748581703, disc_loss = 0.05894124083067864
Trained batch 292 in epoch 14, gen_loss = 0.8641995550625967, disc_loss = 0.05905976447788522
Trained batch 293 in epoch 14, gen_loss = 0.8658351290996383, disc_loss = 0.05935218771856253
Trained batch 294 in epoch 14, gen_loss = 0.8658827132087643, disc_loss = 0.05919601642921314
Trained batch 295 in epoch 14, gen_loss = 0.8652483266149018, disc_loss = 0.059290308590248426
Trained batch 296 in epoch 14, gen_loss = 0.8661409854286849, disc_loss = 0.059183056623069726
Trained batch 297 in epoch 14, gen_loss = 0.8652030842616254, disc_loss = 0.059311760242578365
Trained batch 298 in epoch 14, gen_loss = 0.865531443453154, disc_loss = 0.05959632782496038
Trained batch 299 in epoch 14, gen_loss = 0.8655003302296003, disc_loss = 0.05976082080664734
Trained batch 300 in epoch 14, gen_loss = 0.8650474945374106, disc_loss = 0.05984988659187112
Trained batch 301 in epoch 14, gen_loss = 0.8649865709590596, disc_loss = 0.05972072631675775
Trained batch 302 in epoch 14, gen_loss = 0.8646229439639416, disc_loss = 0.05962353206175094
Trained batch 303 in epoch 14, gen_loss = 0.8648396013794761, disc_loss = 0.059495634218604355
Trained batch 304 in epoch 14, gen_loss = 0.8650580383715082, disc_loss = 0.05938188040048861
Trained batch 305 in epoch 14, gen_loss = 0.8644887416386137, disc_loss = 0.05928889709810903
Trained batch 306 in epoch 14, gen_loss = 0.864215541060662, disc_loss = 0.05915942921300179
Trained batch 307 in epoch 14, gen_loss = 0.864791950718923, disc_loss = 0.05900356069497474
Trained batch 308 in epoch 14, gen_loss = 0.8646191648873697, disc_loss = 0.058901054392837014
Trained batch 309 in epoch 14, gen_loss = 0.8660521842779652, disc_loss = 0.05917125201273349
Trained batch 310 in epoch 14, gen_loss = 0.8660865772000463, disc_loss = 0.059007145566236936
Trained batch 311 in epoch 14, gen_loss = 0.8656039070815612, disc_loss = 0.05900100878296563
Trained batch 312 in epoch 14, gen_loss = 0.865388514610906, disc_loss = 0.05887740348784116
Trained batch 313 in epoch 14, gen_loss = 0.8661924358575966, disc_loss = 0.05934960597378623
Trained batch 314 in epoch 14, gen_loss = 0.8660824320619068, disc_loss = 0.059231077607661956
Trained batch 315 in epoch 14, gen_loss = 0.8657297394886802, disc_loss = 0.05918486764112228
Trained batch 316 in epoch 14, gen_loss = 0.8651012303513307, disc_loss = 0.05928746442830525
Trained batch 317 in epoch 14, gen_loss = 0.8655981587351493, disc_loss = 0.05922113402319029
Trained batch 318 in epoch 14, gen_loss = 0.8656649366254717, disc_loss = 0.059062932212150955
Trained batch 319 in epoch 14, gen_loss = 0.8656027254648506, disc_loss = 0.05939426897093654
Trained batch 320 in epoch 14, gen_loss = 0.8650133844662307, disc_loss = 0.059348186251716076
Trained batch 321 in epoch 14, gen_loss = 0.864503589198456, disc_loss = 0.05940513777899446
Trained batch 322 in epoch 14, gen_loss = 0.8648048972382265, disc_loss = 0.05947755376344126
Trained batch 323 in epoch 14, gen_loss = 0.8652659041094192, disc_loss = 0.059321611283209036
Trained batch 324 in epoch 14, gen_loss = 0.8645826177413647, disc_loss = 0.05924898945654814
Trained batch 325 in epoch 14, gen_loss = 0.864261542452625, disc_loss = 0.05915766070236915
Trained batch 326 in epoch 14, gen_loss = 0.8653558118080874, disc_loss = 0.05905547114630267
Trained batch 327 in epoch 14, gen_loss = 0.8658459841659883, disc_loss = 0.058921882192740534
Trained batch 328 in epoch 14, gen_loss = 0.8657803963926426, disc_loss = 0.05880472495710325
Trained batch 329 in epoch 14, gen_loss = 0.8653422555237106, disc_loss = 0.05879647584180489
Trained batch 330 in epoch 14, gen_loss = 0.8641406752371716, disc_loss = 0.058966301058016694
Trained batch 331 in epoch 14, gen_loss = 0.864894707967718, disc_loss = 0.05885007844239204
Trained batch 332 in epoch 14, gen_loss = 0.8653480982458269, disc_loss = 0.059312334259015484
Trained batch 333 in epoch 14, gen_loss = 0.8660459972605734, disc_loss = 0.05916594122787436
Trained batch 334 in epoch 14, gen_loss = 0.8653039847736927, disc_loss = 0.05927109495917363
Trained batch 335 in epoch 14, gen_loss = 0.8646969946899584, disc_loss = 0.059202752785668486
Trained batch 336 in epoch 14, gen_loss = 0.8649005096637884, disc_loss = 0.05927486706646684
Trained batch 337 in epoch 14, gen_loss = 0.8646887310686902, disc_loss = 0.05918099806704641
Trained batch 338 in epoch 14, gen_loss = 0.8641953965028127, disc_loss = 0.05917448490572363
Trained batch 339 in epoch 14, gen_loss = 0.8640001853599267, disc_loss = 0.059119564376990584
Trained batch 340 in epoch 14, gen_loss = 0.8641899484168749, disc_loss = 0.058970628612158585
Trained batch 341 in epoch 14, gen_loss = 0.8641854969904437, disc_loss = 0.05891357949929454
Trained batch 342 in epoch 14, gen_loss = 0.8650310400102298, disc_loss = 0.05889910949888278
Trained batch 343 in epoch 14, gen_loss = 0.8652617660199486, disc_loss = 0.05875935254423598
Trained batch 344 in epoch 14, gen_loss = 0.8644614032213239, disc_loss = 0.05901653659192548
Trained batch 345 in epoch 14, gen_loss = 0.864624612162568, disc_loss = 0.0588801692326074
Trained batch 346 in epoch 14, gen_loss = 0.8650057941932843, disc_loss = 0.05891586338526835
Trained batch 347 in epoch 14, gen_loss = 0.8653414101264942, disc_loss = 0.05902565793862202
Trained batch 348 in epoch 14, gen_loss = 0.8647748005595112, disc_loss = 0.059086090927799484
Trained batch 349 in epoch 14, gen_loss = 0.8640778072391238, disc_loss = 0.05917230315240366
Trained batch 350 in epoch 14, gen_loss = 0.8645892354667696, disc_loss = 0.05931288144813898
Trained batch 351 in epoch 14, gen_loss = 0.8644862351939082, disc_loss = 0.059229114407736976
Trained batch 352 in epoch 14, gen_loss = 0.8641375248391635, disc_loss = 0.05914498123448479
Trained batch 353 in epoch 14, gen_loss = 0.8637809594303875, disc_loss = 0.05921603689538473
Trained batch 354 in epoch 14, gen_loss = 0.863415020536369, disc_loss = 0.059208735495700805
Trained batch 355 in epoch 14, gen_loss = 0.8633191279983252, disc_loss = 0.05915440891848438
Trained batch 356 in epoch 14, gen_loss = 0.8633382483189848, disc_loss = 0.05903499031110721
Trained batch 357 in epoch 14, gen_loss = 0.8636567054014632, disc_loss = 0.05896016533158761
Trained batch 358 in epoch 14, gen_loss = 0.8634988143417497, disc_loss = 0.05887646467002072
Trained batch 359 in epoch 14, gen_loss = 0.8636012927525574, disc_loss = 0.05877298008805762
Trained batch 360 in epoch 14, gen_loss = 0.8638113075841497, disc_loss = 0.05874317659225078
Trained batch 361 in epoch 14, gen_loss = 0.8641092476759168, disc_loss = 0.05861292440619176
Trained batch 362 in epoch 14, gen_loss = 0.8635751513902806, disc_loss = 0.05858740594094368
Trained batch 363 in epoch 14, gen_loss = 0.8642401540508637, disc_loss = 0.0591590356793009
Trained batch 364 in epoch 14, gen_loss = 0.863592516151193, disc_loss = 0.0592215254469073
Trained batch 365 in epoch 14, gen_loss = 0.863292145191646, disc_loss = 0.05929653832811068
Trained batch 366 in epoch 14, gen_loss = 0.862773618759836, disc_loss = 0.059226914364793805
Trained batch 367 in epoch 14, gen_loss = 0.8630530258397693, disc_loss = 0.059095000655835735
Trained batch 368 in epoch 14, gen_loss = 0.8630201058174537, disc_loss = 0.05908662929807898
Trained batch 369 in epoch 14, gen_loss = 0.8628426800708513, disc_loss = 0.05898890044238116
Trained batch 370 in epoch 14, gen_loss = 0.8620259754580629, disc_loss = 0.05902064491234057
Trained batch 371 in epoch 14, gen_loss = 0.8624823957841884, disc_loss = 0.05891561915757515
Trained batch 372 in epoch 14, gen_loss = 0.8634609798164214, disc_loss = 0.058843947357770265
Trained batch 373 in epoch 14, gen_loss = 0.8632695909968034, disc_loss = 0.05880181525241245
Trained batch 374 in epoch 14, gen_loss = 0.8633939484755199, disc_loss = 0.058668802564342815
Trained batch 375 in epoch 14, gen_loss = 0.8627018059029224, disc_loss = 0.058782934870055696
Trained batch 376 in epoch 14, gen_loss = 0.8629298079709475, disc_loss = 0.05864856796047653
Trained batch 377 in epoch 14, gen_loss = 0.8636241724724492, disc_loss = 0.05879090058927735
Trained batch 378 in epoch 14, gen_loss = 0.8633204202381476, disc_loss = 0.05880579488759855
Trained batch 379 in epoch 14, gen_loss = 0.8632902274790563, disc_loss = 0.05870267572126498
Trained batch 380 in epoch 14, gen_loss = 0.8635553407074585, disc_loss = 0.05859021410062479
Trained batch 381 in epoch 14, gen_loss = 0.8634403152147513, disc_loss = 0.05856279456129795
Trained batch 382 in epoch 14, gen_loss = 0.8633906796924751, disc_loss = 0.05844027516930595
Trained batch 383 in epoch 14, gen_loss = 0.8634950895017633, disc_loss = 0.05832041990167151
Trained batch 384 in epoch 14, gen_loss = 0.8629817935553464, disc_loss = 0.05829196057536385
Trained batch 385 in epoch 14, gen_loss = 0.8627862520322899, disc_loss = 0.05818673801352632
Trained batch 386 in epoch 14, gen_loss = 0.8629131091503518, disc_loss = 0.05830794623848388
Trained batch 387 in epoch 14, gen_loss = 0.8623946638605029, disc_loss = 0.0583070162779738
Trained batch 388 in epoch 14, gen_loss = 0.8626829398781597, disc_loss = 0.05846515298847368
Trained batch 389 in epoch 14, gen_loss = 0.8630753071644367, disc_loss = 0.058361872514853114
Trained batch 390 in epoch 14, gen_loss = 0.8629025410660698, disc_loss = 0.05827682523433205
Trained batch 391 in epoch 14, gen_loss = 0.8624796865089815, disc_loss = 0.05826506983222706
Trained batch 392 in epoch 14, gen_loss = 0.8623204911483153, disc_loss = 0.0582133557069241
Trained batch 393 in epoch 14, gen_loss = 0.8630241940015464, disc_loss = 0.05874955772332431
Trained batch 394 in epoch 14, gen_loss = 0.8633505029768883, disc_loss = 0.05864449728610395
Trained batch 395 in epoch 14, gen_loss = 0.8634475340897386, disc_loss = 0.05853898859479361
Trained batch 396 in epoch 14, gen_loss = 0.8622698703550872, disc_loss = 0.05899709679411551
Trained batch 397 in epoch 14, gen_loss = 0.8622563428165925, disc_loss = 0.05910017268835151
Trained batch 398 in epoch 14, gen_loss = 0.8621571817643063, disc_loss = 0.05926053351570938
Trained batch 399 in epoch 14, gen_loss = 0.8618332632631064, disc_loss = 0.0593241565534845
Trained batch 400 in epoch 14, gen_loss = 0.8616433905395784, disc_loss = 0.059303411015511454
Trained batch 401 in epoch 14, gen_loss = 0.8616438716353468, disc_loss = 0.05936496659872396
Trained batch 402 in epoch 14, gen_loss = 0.8616410775604674, disc_loss = 0.05929044969195024
Trained batch 403 in epoch 14, gen_loss = 0.8616276586262306, disc_loss = 0.05926420568663737
Trained batch 404 in epoch 14, gen_loss = 0.8617021783634469, disc_loss = 0.05947495183367052
Trained batch 405 in epoch 14, gen_loss = 0.8619201709631041, disc_loss = 0.05939850793334798
Trained batch 406 in epoch 14, gen_loss = 0.8615684571518066, disc_loss = 0.059389618369556176
Trained batch 407 in epoch 14, gen_loss = 0.8610281661591109, disc_loss = 0.05936922388169549
Trained batch 408 in epoch 14, gen_loss = 0.8618581432730761, disc_loss = 0.059336575859369745
Trained batch 409 in epoch 14, gen_loss = 0.8620732671603923, disc_loss = 0.05922407573770459
Trained batch 410 in epoch 14, gen_loss = 0.8619343662348977, disc_loss = 0.059161726326439214
Trained batch 411 in epoch 14, gen_loss = 0.8620158948221253, disc_loss = 0.059081227098166655
Trained batch 412 in epoch 14, gen_loss = 0.861612014779167, disc_loss = 0.05911308172052911
Trained batch 413 in epoch 14, gen_loss = 0.8609720965946354, disc_loss = 0.05910873917439854
Trained batch 414 in epoch 14, gen_loss = 0.8610510777996248, disc_loss = 0.05946513192212007
Trained batch 415 in epoch 14, gen_loss = 0.8607531073144995, disc_loss = 0.05949174448435839
Trained batch 416 in epoch 14, gen_loss = 0.8608352561219991, disc_loss = 0.05947631197742564
Trained batch 417 in epoch 14, gen_loss = 0.8603784764925259, disc_loss = 0.059519155926859836
Trained batch 418 in epoch 14, gen_loss = 0.8606460045374095, disc_loss = 0.05942804054723862
Trained batch 419 in epoch 14, gen_loss = 0.8608850417392594, disc_loss = 0.05934842278560003
Trained batch 420 in epoch 14, gen_loss = 0.8606109956805893, disc_loss = 0.059407981409029836
Trained batch 421 in epoch 14, gen_loss = 0.8605523192063327, disc_loss = 0.0595957575039276
Trained batch 422 in epoch 14, gen_loss = 0.8611673844480627, disc_loss = 0.05951574215352817
Trained batch 423 in epoch 14, gen_loss = 0.8612094851175569, disc_loss = 0.059467937125174224
Trained batch 424 in epoch 14, gen_loss = 0.8604627337876488, disc_loss = 0.059797353284323916
Trained batch 425 in epoch 14, gen_loss = 0.8610497962840846, disc_loss = 0.06003158203295559
Trained batch 426 in epoch 14, gen_loss = 0.8611277212722519, disc_loss = 0.060209082387195814
Trained batch 427 in epoch 14, gen_loss = 0.8615855924854768, disc_loss = 0.06030328336354589
Trained batch 428 in epoch 14, gen_loss = 0.8614996312520443, disc_loss = 0.06030922024869002
Trained batch 429 in epoch 14, gen_loss = 0.8617240088623623, disc_loss = 0.06025162425411995
Trained batch 430 in epoch 14, gen_loss = 0.8613683638744177, disc_loss = 0.060219754117028894
Trained batch 431 in epoch 14, gen_loss = 0.8624896184299831, disc_loss = 0.06029859573701052
Trained batch 432 in epoch 14, gen_loss = 0.8632344500985487, disc_loss = 0.06022388064334767
Trained batch 433 in epoch 14, gen_loss = 0.8635505004549906, disc_loss = 0.060146517721155
Trained batch 434 in epoch 14, gen_loss = 0.863563528622704, disc_loss = 0.06005445462276881
Trained batch 435 in epoch 14, gen_loss = 0.8638295564766324, disc_loss = 0.05994275366084291
Trained batch 436 in epoch 14, gen_loss = 0.8632727971202449, disc_loss = 0.059990472665367736
Trained batch 437 in epoch 14, gen_loss = 0.8640340619027342, disc_loss = 0.06020722391942865
Trained batch 438 in epoch 14, gen_loss = 0.8640046131230704, disc_loss = 0.060129636487072854
Trained batch 439 in epoch 14, gen_loss = 0.8637733194638383, disc_loss = 0.06014016237617894
Trained batch 440 in epoch 14, gen_loss = 0.8637670872568273, disc_loss = 0.06005652699104242
Trained batch 441 in epoch 14, gen_loss = 0.8642503955650114, disc_loss = 0.060066502701440545
Trained batch 442 in epoch 14, gen_loss = 0.8637696065294554, disc_loss = 0.06010474484102721
Trained batch 443 in epoch 14, gen_loss = 0.8644691852701677, disc_loss = 0.06002688186394202
Trained batch 444 in epoch 14, gen_loss = 0.8645120936163356, disc_loss = 0.05991293558578813
Trained batch 445 in epoch 14, gen_loss = 0.8646188682371191, disc_loss = 0.05979438539544296
Trained batch 446 in epoch 14, gen_loss = 0.8641886335758021, disc_loss = 0.05985138931163739
Trained batch 447 in epoch 14, gen_loss = 0.8647763357231659, disc_loss = 0.0597443040501925
Trained batch 448 in epoch 14, gen_loss = 0.8646657504722111, disc_loss = 0.059664946269318626
Trained batch 449 in epoch 14, gen_loss = 0.8645605564779706, disc_loss = 0.05958638858464029
Trained batch 450 in epoch 14, gen_loss = 0.864720610121137, disc_loss = 0.05950516703520011
Trained batch 451 in epoch 14, gen_loss = 0.8652553953296316, disc_loss = 0.05941310701726944
Trained batch 452 in epoch 14, gen_loss = 0.865339410423443, disc_loss = 0.05940748900421802
Trained batch 453 in epoch 14, gen_loss = 0.8650111542267946, disc_loss = 0.05944981799760448
Trained batch 454 in epoch 14, gen_loss = 0.8648717221977946, disc_loss = 0.05943252052497733
Trained batch 455 in epoch 14, gen_loss = 0.8656424510766539, disc_loss = 0.059374062364855616
Trained batch 456 in epoch 14, gen_loss = 0.8659605238448087, disc_loss = 0.05929963516083666
Trained batch 457 in epoch 14, gen_loss = 0.8663365236406243, disc_loss = 0.05918859696528146
Trained batch 458 in epoch 14, gen_loss = 0.8658872886290997, disc_loss = 0.05929397955163502
Trained batch 459 in epoch 14, gen_loss = 0.8661634053225102, disc_loss = 0.05919761233355688
Trained batch 460 in epoch 14, gen_loss = 0.8669299145194816, disc_loss = 0.059261262901693
Trained batch 461 in epoch 14, gen_loss = 0.8668793168289837, disc_loss = 0.05919558204129919
Trained batch 462 in epoch 14, gen_loss = 0.8665785253305415, disc_loss = 0.05912319172905923
Trained batch 463 in epoch 14, gen_loss = 0.8667351212352514, disc_loss = 0.05901278069660325
Trained batch 464 in epoch 14, gen_loss = 0.8662277615839435, disc_loss = 0.05897635788686814
Trained batch 465 in epoch 14, gen_loss = 0.8663838722547237, disc_loss = 0.05889444426501514
Trained batch 466 in epoch 14, gen_loss = 0.866442812267667, disc_loss = 0.05905782875686692
Trained batch 467 in epoch 14, gen_loss = 0.8659487810527158, disc_loss = 0.059137442499462865
Trained batch 468 in epoch 14, gen_loss = 0.8662968384050357, disc_loss = 0.05905101396667678
Trained batch 469 in epoch 14, gen_loss = 0.8664995270206574, disc_loss = 0.05896322645564028
Trained batch 470 in epoch 14, gen_loss = 0.8665720073154272, disc_loss = 0.05885967387246351
Trained batch 471 in epoch 14, gen_loss = 0.866891639023009, disc_loss = 0.058758423647890655
Trained batch 472 in epoch 14, gen_loss = 0.8664174803845727, disc_loss = 0.05876695797886959
Trained batch 473 in epoch 14, gen_loss = 0.8666553204949898, disc_loss = 0.058672636354397116
Trained batch 474 in epoch 14, gen_loss = 0.8668982359610106, disc_loss = 0.05902495768509413
Trained batch 475 in epoch 14, gen_loss = 0.8663932825712597, disc_loss = 0.05907356307035735
Trained batch 476 in epoch 14, gen_loss = 0.8658817536051169, disc_loss = 0.059150430688193256
Trained batch 477 in epoch 14, gen_loss = 0.8660374352996818, disc_loss = 0.05942783443935247
Trained batch 478 in epoch 14, gen_loss = 0.8663731305111425, disc_loss = 0.05932363386349539
Trained batch 479 in epoch 14, gen_loss = 0.8665852623060346, disc_loss = 0.059218057186808434
Trained batch 480 in epoch 14, gen_loss = 0.866440645312569, disc_loss = 0.059154153307764294
Trained batch 481 in epoch 14, gen_loss = 0.8661483366088748, disc_loss = 0.05911031750676172
Trained batch 482 in epoch 14, gen_loss = 0.8660719679132505, disc_loss = 0.0590457974452965
Trained batch 483 in epoch 14, gen_loss = 0.8659939085525915, disc_loss = 0.05897702805867249
Trained batch 484 in epoch 14, gen_loss = 0.8660059917218906, disc_loss = 0.05894175516345452
Trained batch 485 in epoch 14, gen_loss = 0.8657127062602298, disc_loss = 0.058924397403841894
Trained batch 486 in epoch 14, gen_loss = 0.8652810742600497, disc_loss = 0.05893676553984809
Trained batch 487 in epoch 14, gen_loss = 0.8651623189082889, disc_loss = 0.05895414246536303
Trained batch 488 in epoch 14, gen_loss = 0.8654433184728056, disc_loss = 0.05887414240763963
Trained batch 489 in epoch 14, gen_loss = 0.8655365156275886, disc_loss = 0.059160882234573366
Trained batch 490 in epoch 14, gen_loss = 0.8651386493942159, disc_loss = 0.05916674394168096
Trained batch 491 in epoch 14, gen_loss = 0.864416085668211, disc_loss = 0.059395001201731405
Trained batch 492 in epoch 14, gen_loss = 0.864489102520759, disc_loss = 0.05945486326004864
Trained batch 493 in epoch 14, gen_loss = 0.8639319533640556, disc_loss = 0.05956066090628686
Trained batch 494 in epoch 14, gen_loss = 0.8636894962402305, disc_loss = 0.05952142531221563
Trained batch 495 in epoch 14, gen_loss = 0.8638996868244102, disc_loss = 0.05955678552028633
Trained batch 496 in epoch 14, gen_loss = 0.8639791252267672, disc_loss = 0.059475864225649974
Trained batch 497 in epoch 14, gen_loss = 0.8644806061044754, disc_loss = 0.05938749901022777
Trained batch 498 in epoch 14, gen_loss = 0.8644289684319544, disc_loss = 0.059350986832487795
Trained batch 499 in epoch 14, gen_loss = 0.8644898553490639, disc_loss = 0.05925223560072482
Trained batch 500 in epoch 14, gen_loss = 0.864356385555096, disc_loss = 0.059192126644719505
Trained batch 501 in epoch 14, gen_loss = 0.8649643529577559, disc_loss = 0.05911627403122792
Trained batch 502 in epoch 14, gen_loss = 0.8653757608316054, disc_loss = 0.059016977414622106
Trained batch 503 in epoch 14, gen_loss = 0.8655772290177761, disc_loss = 0.058995046214910134
Trained batch 504 in epoch 14, gen_loss = 0.8651245418751594, disc_loss = 0.05904487940012523
Trained batch 505 in epoch 14, gen_loss = 0.8647915842858228, disc_loss = 0.059106379046137976
Trained batch 506 in epoch 14, gen_loss = 0.8648209220911625, disc_loss = 0.05905638770907529
Trained batch 507 in epoch 14, gen_loss = 0.8656618359872675, disc_loss = 0.059136347865363155
Trained batch 508 in epoch 14, gen_loss = 0.8656644480987241, disc_loss = 0.05903663782655373
Trained batch 509 in epoch 14, gen_loss = 0.8658183099592434, disc_loss = 0.058975500094832156
Trained batch 510 in epoch 14, gen_loss = 0.8653608065412003, disc_loss = 0.059014539013811755
Trained batch 511 in epoch 14, gen_loss = 0.8655569994007237, disc_loss = 0.05891222957507125
Trained batch 512 in epoch 14, gen_loss = 0.8657491314597064, disc_loss = 0.059038543514544274
Trained batch 513 in epoch 14, gen_loss = 0.8654082537509125, disc_loss = 0.05905699243964736
Trained batch 514 in epoch 14, gen_loss = 0.8652118994773013, disc_loss = 0.059204007247553286
Trained batch 515 in epoch 14, gen_loss = 0.8651336685054062, disc_loss = 0.05917732129884205
Trained batch 516 in epoch 14, gen_loss = 0.8647559036715118, disc_loss = 0.05936150323073569
Trained batch 517 in epoch 14, gen_loss = 0.8647519627938399, disc_loss = 0.0595263854985244
Trained batch 518 in epoch 14, gen_loss = 0.8651940488976091, disc_loss = 0.05959016645617912
Trained batch 519 in epoch 14, gen_loss = 0.8653388219957169, disc_loss = 0.059632619767664714
Trained batch 520 in epoch 14, gen_loss = 0.8658367685415923, disc_loss = 0.05959775693171198
Trained batch 521 in epoch 14, gen_loss = 0.8658655189348821, disc_loss = 0.05952044400133164
Trained batch 522 in epoch 14, gen_loss = 0.8653202099622321, disc_loss = 0.05965989922844657
Trained batch 523 in epoch 14, gen_loss = 0.865405677327218, disc_loss = 0.05960523911204388
Trained batch 524 in epoch 14, gen_loss = 0.8662050139904022, disc_loss = 0.0596393628879672
Trained batch 525 in epoch 14, gen_loss = 0.8664607847031531, disc_loss = 0.05966509226709604
Trained batch 526 in epoch 14, gen_loss = 0.8662946678316344, disc_loss = 0.05961953421287677
Trained batch 527 in epoch 14, gen_loss = 0.8661199310850917, disc_loss = 0.05955745445239837
Trained batch 528 in epoch 14, gen_loss = 0.8664072897911973, disc_loss = 0.059497741933045856
Trained batch 529 in epoch 14, gen_loss = 0.8661370852645838, disc_loss = 0.05950070840640451
Trained batch 530 in epoch 14, gen_loss = 0.8669392105661992, disc_loss = 0.059476004534606206
Trained batch 531 in epoch 14, gen_loss = 0.8669959228849948, disc_loss = 0.05940788490277596
Trained batch 532 in epoch 14, gen_loss = 0.8669218863264481, disc_loss = 0.05931980522807275
Trained batch 533 in epoch 14, gen_loss = 0.8670687767561902, disc_loss = 0.05921983766048616
Trained batch 534 in epoch 14, gen_loss = 0.8676064141999895, disc_loss = 0.05914457959566857
Trained batch 535 in epoch 14, gen_loss = 0.8675465158450959, disc_loss = 0.05905875615487153
Trained batch 536 in epoch 14, gen_loss = 0.8669943720157808, disc_loss = 0.05917048506053716
Trained batch 537 in epoch 14, gen_loss = 0.8678236038157487, disc_loss = 0.05929210853112037
Trained batch 538 in epoch 14, gen_loss = 0.8679518603991047, disc_loss = 0.0592198904183847
Trained batch 539 in epoch 14, gen_loss = 0.8681087326672342, disc_loss = 0.05912985508761334
Trained batch 540 in epoch 14, gen_loss = 0.8678475697137512, disc_loss = 0.05912600161142771
Trained batch 541 in epoch 14, gen_loss = 0.8678159039068926, disc_loss = 0.05910704882447763
Trained batch 542 in epoch 14, gen_loss = 0.8671957130919504, disc_loss = 0.05925368215343323
Trained batch 543 in epoch 14, gen_loss = 0.8670353555832716, disc_loss = 0.05919402060766622
Trained batch 544 in epoch 14, gen_loss = 0.8674682419781291, disc_loss = 0.05913098823159523
Trained batch 545 in epoch 14, gen_loss = 0.8677285018312189, disc_loss = 0.05906759826347041
Trained batch 546 in epoch 14, gen_loss = 0.8676630236222059, disc_loss = 0.05897373437431983
Trained batch 547 in epoch 14, gen_loss = 0.8681861063750991, disc_loss = 0.05890937928912522
Trained batch 548 in epoch 14, gen_loss = 0.8681082227733834, disc_loss = 0.05881876324410321
Trained batch 549 in epoch 14, gen_loss = 0.8681229775060307, disc_loss = 0.05874081530015577
Trained batch 550 in epoch 14, gen_loss = 0.8680029919813852, disc_loss = 0.0586491471051683
Trained batch 551 in epoch 14, gen_loss = 0.8681175072232018, disc_loss = 0.05855616947814849
Trained batch 552 in epoch 14, gen_loss = 0.8679533939788397, disc_loss = 0.058492795512868366
Trained batch 553 in epoch 14, gen_loss = 0.8678337756799877, disc_loss = 0.058445854426028766
Trained batch 554 in epoch 14, gen_loss = 0.867819747892586, disc_loss = 0.05843366078176611
Trained batch 555 in epoch 14, gen_loss = 0.8680260061896105, disc_loss = 0.058345833918073034
Trained batch 556 in epoch 14, gen_loss = 0.8685799891152545, disc_loss = 0.0583093844569845
Trained batch 557 in epoch 14, gen_loss = 0.8688276523864398, disc_loss = 0.05821625442297522
Trained batch 558 in epoch 14, gen_loss = 0.8692893462125645, disc_loss = 0.058141262041428166
Trained batch 559 in epoch 14, gen_loss = 0.8690873540405716, disc_loss = 0.05808380234770344
Trained batch 560 in epoch 14, gen_loss = 0.8687161505222321, disc_loss = 0.05819632098951946
Trained batch 561 in epoch 14, gen_loss = 0.8692259460263405, disc_loss = 0.05814110783584999
Trained batch 562 in epoch 14, gen_loss = 0.8695627180445893, disc_loss = 0.0583739808618321
Trained batch 563 in epoch 14, gen_loss = 0.8692085603978617, disc_loss = 0.05831189693615554
Trained batch 564 in epoch 14, gen_loss = 0.8690481066176322, disc_loss = 0.05826488921451753
Trained batch 565 in epoch 14, gen_loss = 0.868766858857849, disc_loss = 0.05821794789044232
Trained batch 566 in epoch 14, gen_loss = 0.869033243553138, disc_loss = 0.058131005509051856
Trained batch 567 in epoch 14, gen_loss = 0.86894962459173, disc_loss = 0.058239408590811184
Trained batch 568 in epoch 14, gen_loss = 0.8686308198213997, disc_loss = 0.058214259835578805
Trained batch 569 in epoch 14, gen_loss = 0.8687814605340624, disc_loss = 0.05814200322339801
Trained batch 570 in epoch 14, gen_loss = 0.8689446421617384, disc_loss = 0.058058747022711195
Trained batch 571 in epoch 14, gen_loss = 0.8692299600143533, disc_loss = 0.057976287689509354
Trained batch 572 in epoch 14, gen_loss = 0.8689017789422113, disc_loss = 0.05794311977718123
Trained batch 573 in epoch 14, gen_loss = 0.8691497447702528, disc_loss = 0.05785464018077074
Trained batch 574 in epoch 14, gen_loss = 0.869684179606645, disc_loss = 0.05779513012131919
Trained batch 575 in epoch 14, gen_loss = 0.869570128671411, disc_loss = 0.05772416605032049
Trained batch 576 in epoch 14, gen_loss = 0.8698371500551597, disc_loss = 0.057642779566437985
Trained batch 577 in epoch 14, gen_loss = 0.8699100931726113, disc_loss = 0.057601491221352434
Trained batch 578 in epoch 14, gen_loss = 0.8696283356822216, disc_loss = 0.05752836244698736
Trained batch 579 in epoch 14, gen_loss = 0.8700124779138072, disc_loss = 0.05744259603128865
Trained batch 580 in epoch 14, gen_loss = 0.8700742897499039, disc_loss = 0.05736764599593187
Trained batch 581 in epoch 14, gen_loss = 0.8700082233988542, disc_loss = 0.05729340831989173
Trained batch 582 in epoch 14, gen_loss = 0.8703926253175653, disc_loss = 0.057346129074283776
Trained batch 583 in epoch 14, gen_loss = 0.870333465352042, disc_loss = 0.057261592971658566
Trained batch 584 in epoch 14, gen_loss = 0.8701189689656608, disc_loss = 0.057250900090568595
Trained batch 585 in epoch 14, gen_loss = 0.8702676014993784, disc_loss = 0.057167853378140884
Trained batch 586 in epoch 14, gen_loss = 0.8706728347420083, disc_loss = 0.05711326354660817
Trained batch 587 in epoch 14, gen_loss = 0.8709224243046475, disc_loss = 0.05702921220095081
Trained batch 588 in epoch 14, gen_loss = 0.8709543430845685, disc_loss = 0.05695019896554876
Trained batch 589 in epoch 14, gen_loss = 0.870673993836015, disc_loss = 0.05696168651930609
Trained batch 590 in epoch 14, gen_loss = 0.8710306626185145, disc_loss = 0.05707166175154714
Trained batch 591 in epoch 14, gen_loss = 0.8708736847683385, disc_loss = 0.057012421225285714
Trained batch 592 in epoch 14, gen_loss = 0.8706078814314349, disc_loss = 0.056994911360210454
Trained batch 593 in epoch 14, gen_loss = 0.8703845745887018, disc_loss = 0.05700821603369281
Trained batch 594 in epoch 14, gen_loss = 0.8704966472477472, disc_loss = 0.05703983156151381
Trained batch 595 in epoch 14, gen_loss = 0.8710862205632581, disc_loss = 0.056993489198999214
Trained batch 596 in epoch 14, gen_loss = 0.8708313315657515, disc_loss = 0.0569702182074313
Trained batch 597 in epoch 14, gen_loss = 0.8708434712428313, disc_loss = 0.05706806441170964
Trained batch 598 in epoch 14, gen_loss = 0.8705393962052111, disc_loss = 0.05708420538002989
Trained batch 599 in epoch 14, gen_loss = 0.8701897485554219, disc_loss = 0.05712319235162189
Trained batch 600 in epoch 14, gen_loss = 0.8700843423158674, disc_loss = 0.05713831283889723
Trained batch 601 in epoch 14, gen_loss = 0.8701124453168375, disc_loss = 0.057057233531943884
Trained batch 602 in epoch 14, gen_loss = 0.8704131363735073, disc_loss = 0.0570151943506466
Trained batch 603 in epoch 14, gen_loss = 0.869822602052957, disc_loss = 0.05715773659079823
Trained batch 604 in epoch 14, gen_loss = 0.8700665919741323, disc_loss = 0.05710238884087683
Trained batch 605 in epoch 14, gen_loss = 0.8704721629127811, disc_loss = 0.05707276426409386
Trained batch 606 in epoch 14, gen_loss = 0.870689478943729, disc_loss = 0.057031421363660594
Trained batch 607 in epoch 14, gen_loss = 0.8705424466905626, disc_loss = 0.057000327875261735
Trained batch 608 in epoch 14, gen_loss = 0.8704873541207933, disc_loss = 0.05695966960424909
Trained batch 609 in epoch 14, gen_loss = 0.870262106959937, disc_loss = 0.05691271523074781
Trained batch 610 in epoch 14, gen_loss = 0.8705395722057543, disc_loss = 0.05684422827958329
Trained batch 611 in epoch 14, gen_loss = 0.8705824669572263, disc_loss = 0.05676350271667117
Trained batch 612 in epoch 14, gen_loss = 0.8706496413827526, disc_loss = 0.05668259389184987
Trained batch 613 in epoch 14, gen_loss = 0.8704968972877881, disc_loss = 0.05661880259147272
Trained batch 614 in epoch 14, gen_loss = 0.8705779391091044, disc_loss = 0.056553445031821
Trained batch 615 in epoch 14, gen_loss = 0.8706897613773872, disc_loss = 0.05648381990462227
Trained batch 616 in epoch 14, gen_loss = 0.8708615373077423, disc_loss = 0.05640807866105264
Trained batch 617 in epoch 14, gen_loss = 0.8709221679512351, disc_loss = 0.05633579808118539
Trained batch 618 in epoch 14, gen_loss = 0.871290091214542, disc_loss = 0.05633145976309124
Trained batch 619 in epoch 14, gen_loss = 0.8710892925820043, disc_loss = 0.0563283797826678
Trained batch 620 in epoch 14, gen_loss = 0.870497378030261, disc_loss = 0.05642282599193343
Trained batch 621 in epoch 14, gen_loss = 0.8705425490999529, disc_loss = 0.05637554443363472
Trained batch 622 in epoch 14, gen_loss = 0.8711040571547244, disc_loss = 0.056358366916897926
Trained batch 623 in epoch 14, gen_loss = 0.8712918302283074, disc_loss = 0.05628754619661217
Trained batch 624 in epoch 14, gen_loss = 0.8714259151935577, disc_loss = 0.05621063063517213
Trained batch 625 in epoch 14, gen_loss = 0.8713166546612121, disc_loss = 0.05617764328320782
Trained batch 626 in epoch 14, gen_loss = 0.8712910885730999, disc_loss = 0.056194660556094164
Trained batch 627 in epoch 14, gen_loss = 0.8712879154048149, disc_loss = 0.05611934787430652
Trained batch 628 in epoch 14, gen_loss = 0.8709526671798505, disc_loss = 0.05609446053211067
Trained batch 629 in epoch 14, gen_loss = 0.8711625410923882, disc_loss = 0.056060235580015515
Trained batch 630 in epoch 14, gen_loss = 0.871648416607958, disc_loss = 0.055993987978679584
Trained batch 631 in epoch 14, gen_loss = 0.8716897383049319, disc_loss = 0.05592574714904038
Trained batch 632 in epoch 14, gen_loss = 0.871449557667095, disc_loss = 0.055904140762872936
Trained batch 633 in epoch 14, gen_loss = 0.871482527077386, disc_loss = 0.05592960522845035
Trained batch 634 in epoch 14, gen_loss = 0.8716099760194463, disc_loss = 0.05593079241051331
Trained batch 635 in epoch 14, gen_loss = 0.8712676396628596, disc_loss = 0.055960655299530794
Trained batch 636 in epoch 14, gen_loss = 0.8709820466382163, disc_loss = 0.056017840341803744
Trained batch 637 in epoch 14, gen_loss = 0.8711243903842466, disc_loss = 0.05598107795960921
Trained batch 638 in epoch 14, gen_loss = 0.8715965854636567, disc_loss = 0.05595397051928072
Trained batch 639 in epoch 14, gen_loss = 0.8714288503397256, disc_loss = 0.05591905401597615
Trained batch 640 in epoch 14, gen_loss = 0.8712362745157828, disc_loss = 0.055887451461500336
Trained batch 641 in epoch 14, gen_loss = 0.8714725719155553, disc_loss = 0.055815967180653014
Trained batch 642 in epoch 14, gen_loss = 0.8721713499277598, disc_loss = 0.056070117906321125
Trained batch 643 in epoch 14, gen_loss = 0.8718531690306545, disc_loss = 0.05610027205074634
Trained batch 644 in epoch 14, gen_loss = 0.8713286689547606, disc_loss = 0.05613273439149177
Trained batch 645 in epoch 14, gen_loss = 0.8713532214286527, disc_loss = 0.05606975812167967
Trained batch 646 in epoch 14, gen_loss = 0.8715467223151943, disc_loss = 0.05604841608274872
Trained batch 647 in epoch 14, gen_loss = 0.8716501478151775, disc_loss = 0.0559761465195118
Trained batch 648 in epoch 14, gen_loss = 0.871469406069519, disc_loss = 0.055980161266496124
Trained batch 649 in epoch 14, gen_loss = 0.8715929237237343, disc_loss = 0.055923431198327586
Trained batch 650 in epoch 14, gen_loss = 0.8720263113166147, disc_loss = 0.05586453874347969
Trained batch 651 in epoch 14, gen_loss = 0.872105201740572, disc_loss = 0.05581408023528549
Trained batch 652 in epoch 14, gen_loss = 0.8716083006051927, disc_loss = 0.05585847301893564
Trained batch 653 in epoch 14, gen_loss = 0.8715208335480559, disc_loss = 0.05583572684821391
Trained batch 654 in epoch 14, gen_loss = 0.8717976694343654, disc_loss = 0.05581673769678437
Trained batch 655 in epoch 14, gen_loss = 0.8718415442854166, disc_loss = 0.05575018150450821
Trained batch 656 in epoch 14, gen_loss = 0.8723222318940329, disc_loss = 0.055699233927507426
Trained batch 657 in epoch 14, gen_loss = 0.8728593572023067, disc_loss = 0.05564406689179999
Trained batch 658 in epoch 14, gen_loss = 0.8727776375182301, disc_loss = 0.05561765868496574
Trained batch 659 in epoch 14, gen_loss = 0.8725783530961383, disc_loss = 0.05559670543086461
Trained batch 660 in epoch 14, gen_loss = 0.8728391257158387, disc_loss = 0.055535897035602584
Trained batch 661 in epoch 14, gen_loss = 0.8729721264086461, disc_loss = 0.05547688029540472
Trained batch 662 in epoch 14, gen_loss = 0.8732069063240586, disc_loss = 0.05541086970683788
Trained batch 663 in epoch 14, gen_loss = 0.8732028583356415, disc_loss = 0.0553491019246909
Trained batch 664 in epoch 14, gen_loss = 0.8734449093951319, disc_loss = 0.05528192408312868
Trained batch 665 in epoch 14, gen_loss = 0.8736269538019512, disc_loss = 0.0552171756053349
Trained batch 666 in epoch 14, gen_loss = 0.8737905933849816, disc_loss = 0.05517066766981264
Trained batch 667 in epoch 14, gen_loss = 0.8736545030852991, disc_loss = 0.05514439903994364
Trained batch 668 in epoch 14, gen_loss = 0.8740021731197745, disc_loss = 0.05507546828179906
Trained batch 669 in epoch 14, gen_loss = 0.8739223556287253, disc_loss = 0.05501944810888772
Trained batch 670 in epoch 14, gen_loss = 0.8740102475073227, disc_loss = 0.05494945675576031
Trained batch 671 in epoch 14, gen_loss = 0.8740648592245721, disc_loss = 0.054904349430303444
Trained batch 672 in epoch 14, gen_loss = 0.873742260027782, disc_loss = 0.054943577777372916
Trained batch 673 in epoch 14, gen_loss = 0.8736336222830441, disc_loss = 0.05487810365112294
Trained batch 674 in epoch 14, gen_loss = 0.8740102519370891, disc_loss = 0.05482916868602236
Trained batch 675 in epoch 14, gen_loss = 0.8742996038505312, disc_loss = 0.0547660718384039
Trained batch 676 in epoch 14, gen_loss = 0.8743144577063697, disc_loss = 0.054732285334730034
Trained batch 677 in epoch 14, gen_loss = 0.8739912373214345, disc_loss = 0.054783366493479646
Trained batch 678 in epoch 14, gen_loss = 0.874029774070664, disc_loss = 0.054730064480459875
Trained batch 679 in epoch 14, gen_loss = 0.8738178139662042, disc_loss = 0.05470729309668326
Trained batch 680 in epoch 14, gen_loss = 0.8742230747677331, disc_loss = 0.054757179070822073
Trained batch 681 in epoch 14, gen_loss = 0.8742961363970709, disc_loss = 0.05470092221753142
Trained batch 682 in epoch 14, gen_loss = 0.8738531862572381, disc_loss = 0.05476252579417947
Trained batch 683 in epoch 14, gen_loss = 0.8741878524248363, disc_loss = 0.054785362773640246
Trained batch 684 in epoch 14, gen_loss = 0.8743233973527477, disc_loss = 0.054718971673236055
Trained batch 685 in epoch 14, gen_loss = 0.8742782586951993, disc_loss = 0.05468069738844198
Trained batch 686 in epoch 14, gen_loss = 0.8743341315694945, disc_loss = 0.054649313965343276
Trained batch 687 in epoch 14, gen_loss = 0.8741878764487283, disc_loss = 0.05463158658388894
Trained batch 688 in epoch 14, gen_loss = 0.8741117527678673, disc_loss = 0.05459966764316309
Trained batch 689 in epoch 14, gen_loss = 0.8743673724108848, disc_loss = 0.054701846337917706
Trained batch 690 in epoch 14, gen_loss = 0.8740727554268154, disc_loss = 0.054733776059486886
Trained batch 691 in epoch 14, gen_loss = 0.8737027055524678, disc_loss = 0.05480406009874743
Trained batch 692 in epoch 14, gen_loss = 0.8741162817113499, disc_loss = 0.05487310429121143
Trained batch 693 in epoch 14, gen_loss = 0.8743489370480051, disc_loss = 0.05481012208153754
Trained batch 694 in epoch 14, gen_loss = 0.8746581541977341, disc_loss = 0.05476102638895885
Trained batch 695 in epoch 14, gen_loss = 0.8744427808828052, disc_loss = 0.0547175037576924
Trained batch 696 in epoch 14, gen_loss = 0.8743981497958195, disc_loss = 0.054675003903192416
Trained batch 697 in epoch 14, gen_loss = 0.8739295620204385, disc_loss = 0.054740467556434705
Trained batch 698 in epoch 14, gen_loss = 0.8743154574105668, disc_loss = 0.05476221312383704
Trained batch 699 in epoch 14, gen_loss = 0.8745853159683091, disc_loss = 0.0548426729460646
Trained batch 700 in epoch 14, gen_loss = 0.874274243429282, disc_loss = 0.054826962780845104
Trained batch 701 in epoch 14, gen_loss = 0.8740694124219764, disc_loss = 0.054812858435073254
Trained batch 702 in epoch 14, gen_loss = 0.8741793355680632, disc_loss = 0.05474739670846214
Trained batch 703 in epoch 14, gen_loss = 0.8742791569622402, disc_loss = 0.05468186167193132
Trained batch 704 in epoch 14, gen_loss = 0.8746485878812505, disc_loss = 0.05464553600969784
Trained batch 705 in epoch 14, gen_loss = 0.8748197735791166, disc_loss = 0.05457702646145423
Trained batch 706 in epoch 14, gen_loss = 0.8747441887096772, disc_loss = 0.05456553297143698
Trained batch 707 in epoch 14, gen_loss = 0.8744982887206778, disc_loss = 0.054565133509163005
Trained batch 708 in epoch 14, gen_loss = 0.8746041181813846, disc_loss = 0.054498789790618445
Trained batch 709 in epoch 14, gen_loss = 0.8747383687277914, disc_loss = 0.05444260810003419
Trained batch 710 in epoch 14, gen_loss = 0.8749315038260528, disc_loss = 0.05437417867961543
Trained batch 711 in epoch 14, gen_loss = 0.874965949967671, disc_loss = 0.05431622174748983
Trained batch 712 in epoch 14, gen_loss = 0.8747931066351886, disc_loss = 0.054284307244266444
Trained batch 713 in epoch 14, gen_loss = 0.8746910152398572, disc_loss = 0.05422045317405433
Trained batch 714 in epoch 14, gen_loss = 0.8749696601937701, disc_loss = 0.05416296330847211
Trained batch 715 in epoch 14, gen_loss = 0.8749802467626566, disc_loss = 0.05413426929764845
Trained batch 716 in epoch 14, gen_loss = 0.8750049755746184, disc_loss = 0.054079166136167665
Trained batch 717 in epoch 14, gen_loss = 0.8746400901783143, disc_loss = 0.05416097269331242
Trained batch 718 in epoch 14, gen_loss = 0.8748412763541862, disc_loss = 0.054279057404236226
Trained batch 719 in epoch 14, gen_loss = 0.8746630039066077, disc_loss = 0.05423994800787316
Trained batch 720 in epoch 14, gen_loss = 0.8749601637192804, disc_loss = 0.05417583247739693
Trained batch 721 in epoch 14, gen_loss = 0.8752874092629742, disc_loss = 0.054121378747942414
Trained batch 722 in epoch 14, gen_loss = 0.8753546075290004, disc_loss = 0.054055138930348606
Trained batch 723 in epoch 14, gen_loss = 0.8752570849179563, disc_loss = 0.05403457513819989
Trained batch 724 in epoch 14, gen_loss = 0.8752161402126838, disc_loss = 0.053981046279699636
Trained batch 725 in epoch 14, gen_loss = 0.8748931746427021, disc_loss = 0.05399747733052399
Trained batch 726 in epoch 14, gen_loss = 0.8750566884854801, disc_loss = 0.05394722645182516
Trained batch 727 in epoch 14, gen_loss = 0.8753040186897084, disc_loss = 0.054063384870200286
Trained batch 728 in epoch 14, gen_loss = 0.8753675365889514, disc_loss = 0.054024184392241374
Trained batch 729 in epoch 14, gen_loss = 0.8749504221220539, disc_loss = 0.05411661591457382
Trained batch 730 in epoch 14, gen_loss = 0.8752996818393102, disc_loss = 0.054078442854845005
Trained batch 731 in epoch 14, gen_loss = 0.875414290348363, disc_loss = 0.054014882129423646
Trained batch 732 in epoch 14, gen_loss = 0.8753107603624117, disc_loss = 0.05402761889433572
Trained batch 733 in epoch 14, gen_loss = 0.8753321360421116, disc_loss = 0.05398682559008027
Trained batch 734 in epoch 14, gen_loss = 0.8754851702524691, disc_loss = 0.05399189206524467
Trained batch 735 in epoch 14, gen_loss = 0.8755690553023115, disc_loss = 0.05395213383535915
Trained batch 736 in epoch 14, gen_loss = 0.8755496836177691, disc_loss = 0.053900513705118905
Trained batch 737 in epoch 14, gen_loss = 0.8756387652501181, disc_loss = 0.05383768963607326
Trained batch 738 in epoch 14, gen_loss = 0.8757179374220568, disc_loss = 0.05377687286920795
Trained batch 739 in epoch 14, gen_loss = 0.8756667881801322, disc_loss = 0.05371490847508146
Trained batch 740 in epoch 14, gen_loss = 0.8758989889853397, disc_loss = 0.05366069742374112
Trained batch 741 in epoch 14, gen_loss = 0.8758641324354953, disc_loss = 0.053601129176948634
Trained batch 742 in epoch 14, gen_loss = 0.8760431743807299, disc_loss = 0.05354163794142782
Trained batch 743 in epoch 14, gen_loss = 0.876165732701299, disc_loss = 0.05349984094538095
Trained batch 744 in epoch 14, gen_loss = 0.8760606925359509, disc_loss = 0.053470595735406516
Trained batch 745 in epoch 14, gen_loss = 0.8759473411631009, disc_loss = 0.053419144248000615
Trained batch 746 in epoch 14, gen_loss = 0.8760898086520403, disc_loss = 0.053354268486535496
Trained batch 747 in epoch 14, gen_loss = 0.8761075115538536, disc_loss = 0.053297256146318576
Trained batch 748 in epoch 14, gen_loss = 0.876121707887293, disc_loss = 0.05324145572543522
Trained batch 749 in epoch 14, gen_loss = 0.8762578098376592, disc_loss = 0.05318263056067129
Trained batch 750 in epoch 14, gen_loss = 0.8765192689416254, disc_loss = 0.053122062272653876
Trained batch 751 in epoch 14, gen_loss = 0.8770150350842704, disc_loss = 0.05309571073814097
Trained batch 752 in epoch 14, gen_loss = 0.8771741654214315, disc_loss = 0.05304500618999005
Trained batch 753 in epoch 14, gen_loss = 0.8768031543777856, disc_loss = 0.05303563361441524
Trained batch 754 in epoch 14, gen_loss = 0.8770013550654152, disc_loss = 0.05298220356309552
Trained batch 755 in epoch 14, gen_loss = 0.8772830651314171, disc_loss = 0.05292867796148159
Trained batch 756 in epoch 14, gen_loss = 0.877336988715231, disc_loss = 0.05287326885082192
Trained batch 757 in epoch 14, gen_loss = 0.8772086684732135, disc_loss = 0.05284147338246273
Trained batch 758 in epoch 14, gen_loss = 0.877125427931822, disc_loss = 0.05279373771379725
Trained batch 759 in epoch 14, gen_loss = 0.8772549671954231, disc_loss = 0.052741694459569104
Trained batch 760 in epoch 14, gen_loss = 0.8773766834773465, disc_loss = 0.05270070678024564
Trained batch 761 in epoch 14, gen_loss = 0.8774942810845188, disc_loss = 0.05277357626342144
Trained batch 762 in epoch 14, gen_loss = 0.8772299202600906, disc_loss = 0.052734359087566525
Trained batch 763 in epoch 14, gen_loss = 0.8769053542567173, disc_loss = 0.05275513866065431
Trained batch 764 in epoch 14, gen_loss = 0.8771199259493087, disc_loss = 0.05271038184112875
Trained batch 765 in epoch 14, gen_loss = 0.8774812836637697, disc_loss = 0.05266267197102056
Trained batch 766 in epoch 14, gen_loss = 0.8775464220572327, disc_loss = 0.05260360784248256
Trained batch 767 in epoch 14, gen_loss = 0.8775652892654762, disc_loss = 0.05254784303603325
Trained batch 768 in epoch 14, gen_loss = 0.8776723163103096, disc_loss = 0.052490549516271905
Trained batch 769 in epoch 14, gen_loss = 0.8775520539515979, disc_loss = 0.05244758223522116
Trained batch 770 in epoch 14, gen_loss = 0.8776641193144362, disc_loss = 0.05238589634285363
Trained batch 771 in epoch 14, gen_loss = 0.8777879436012994, disc_loss = 0.052328984911790014
Trained batch 772 in epoch 14, gen_loss = 0.8779049127484355, disc_loss = 0.05226903949848546
Trained batch 773 in epoch 14, gen_loss = 0.8781349800276818, disc_loss = 0.05225826985051119
Trained batch 774 in epoch 14, gen_loss = 0.8782111398250826, disc_loss = 0.05220610555621885
Trained batch 775 in epoch 14, gen_loss = 0.8782583800403728, disc_loss = 0.052145215423451255
Trained batch 776 in epoch 14, gen_loss = 0.8780873295499858, disc_loss = 0.05211835858943073
Trained batch 777 in epoch 14, gen_loss = 0.8782491859786001, disc_loss = 0.0520627800504507
Trained batch 778 in epoch 14, gen_loss = 0.8784590830622344, disc_loss = 0.05200573356178935
Trained batch 779 in epoch 14, gen_loss = 0.8786241379685891, disc_loss = 0.05195963209709869
Trained batch 780 in epoch 14, gen_loss = 0.878838766666747, disc_loss = 0.05190119993778735
Trained batch 781 in epoch 14, gen_loss = 0.8788627120463745, disc_loss = 0.0518553563759274
Trained batch 782 in epoch 14, gen_loss = 0.878949383019183, disc_loss = 0.05181354100936084
Trained batch 783 in epoch 14, gen_loss = 0.8790278153075856, disc_loss = 0.051755107587027574
Trained batch 784 in epoch 14, gen_loss = 0.8789644870408782, disc_loss = 0.05170624942999262
Trained batch 785 in epoch 14, gen_loss = 0.8789611890646641, disc_loss = 0.0516512030990363
Trained batch 786 in epoch 14, gen_loss = 0.8791461432828382, disc_loss = 0.051591189801243276
Trained batch 787 in epoch 14, gen_loss = 0.8793036190008149, disc_loss = 0.05156338195077753
Trained batch 788 in epoch 14, gen_loss = 0.8794078814439448, disc_loss = 0.05150414422492016
Trained batch 789 in epoch 14, gen_loss = 0.8795908295278307, disc_loss = 0.05144568537656642
Testing Epoch 14
Training Epoch 15
Trained batch 0 in epoch 15, gen_loss = 0.9983857870101929, disc_loss = 0.006029301788657904
Trained batch 1 in epoch 15, gen_loss = 0.9056370258331299, disc_loss = 0.00810412666760385
Trained batch 2 in epoch 15, gen_loss = 0.885240356127421, disc_loss = 0.006979737741251786
Trained batch 3 in epoch 15, gen_loss = 0.8895324170589447, disc_loss = 0.006770975771360099
Trained batch 4 in epoch 15, gen_loss = 0.8855694532394409, disc_loss = 0.008815921749919653
Trained batch 5 in epoch 15, gen_loss = 0.9148765206336975, disc_loss = 0.010518204343194762
Trained batch 6 in epoch 15, gen_loss = 0.8980322224753243, disc_loss = 0.010452227600451027
Trained batch 7 in epoch 15, gen_loss = 0.9034601226449013, disc_loss = 0.010593172803055495
Trained batch 8 in epoch 15, gen_loss = 0.888152903980679, disc_loss = 0.01356155565008521
Trained batch 9 in epoch 15, gen_loss = 0.8936089217662812, disc_loss = 0.01302077635191381
Trained batch 10 in epoch 15, gen_loss = 0.9191702658479864, disc_loss = 0.01379376831887798
Trained batch 11 in epoch 15, gen_loss = 0.9388134429852167, disc_loss = 0.014365718505966166
Trained batch 12 in epoch 15, gen_loss = 0.9439938022540166, disc_loss = 0.015409955575775642
Trained batch 13 in epoch 15, gen_loss = 0.9338314831256866, disc_loss = 0.015024902931015407
Trained batch 14 in epoch 15, gen_loss = 0.935915736357371, disc_loss = 0.014456958292673032
Trained batch 15 in epoch 15, gen_loss = 0.9259668923914433, disc_loss = 0.0143515155359637
Trained batch 16 in epoch 15, gen_loss = 0.9148585831417757, disc_loss = 0.015039437149158296
Trained batch 17 in epoch 15, gen_loss = 0.9222020672427284, disc_loss = 0.01545238378457725
Trained batch 18 in epoch 15, gen_loss = 0.9261216113441869, disc_loss = 0.015085087672464158
Trained batch 19 in epoch 15, gen_loss = 0.9273090332746505, disc_loss = 0.014633640623651445
Trained batch 20 in epoch 15, gen_loss = 0.9271294275919596, disc_loss = 0.015137318765655869
Trained batch 21 in epoch 15, gen_loss = 0.9305023388429121, disc_loss = 0.016379535431042314
Trained batch 22 in epoch 15, gen_loss = 0.9197540490523629, disc_loss = 0.0188875508332706
Trained batch 23 in epoch 15, gen_loss = 0.9243390709161758, disc_loss = 0.018464463743536424
Trained batch 24 in epoch 15, gen_loss = 0.9347978973388672, disc_loss = 0.020055628102272748
Trained batch 25 in epoch 15, gen_loss = 0.9264419353925265, disc_loss = 0.021265735401986882
Trained batch 26 in epoch 15, gen_loss = 0.9272279960137827, disc_loss = 0.02072793623018596
Trained batch 27 in epoch 15, gen_loss = 0.9274499033178601, disc_loss = 0.022286175533996096
Trained batch 28 in epoch 15, gen_loss = 0.9222542396907148, disc_loss = 0.022928927398832708
Trained batch 29 in epoch 15, gen_loss = 0.928398750225703, disc_loss = 0.022842303399617472
Trained batch 30 in epoch 15, gen_loss = 0.9361042495696775, disc_loss = 0.022650196472363125
Trained batch 31 in epoch 15, gen_loss = 0.9235201068222523, disc_loss = 0.02505122665024828
Trained batch 32 in epoch 15, gen_loss = 0.9192964398499691, disc_loss = 0.02468997455964034
Trained batch 33 in epoch 15, gen_loss = 0.9185252312351676, disc_loss = 0.025053681928993148
Trained batch 34 in epoch 15, gen_loss = 0.9203763195446559, disc_loss = 0.0246584674742605
Trained batch 35 in epoch 15, gen_loss = 0.9126907967858844, disc_loss = 0.026402603382141225
Trained batch 36 in epoch 15, gen_loss = 0.9104689295227463, disc_loss = 0.03118482228318179
Trained batch 37 in epoch 15, gen_loss = 0.906069848098253, disc_loss = 0.03101400762649351
Trained batch 38 in epoch 15, gen_loss = 0.9036331956203167, disc_loss = 0.031163096774178438
Trained batch 39 in epoch 15, gen_loss = 0.9082524433732033, disc_loss = 0.03193971231812611
Trained batch 40 in epoch 15, gen_loss = 0.9103178367382143, disc_loss = 0.03145335511327153
Trained batch 41 in epoch 15, gen_loss = 0.9079707052026477, disc_loss = 0.03150690654070959
Trained batch 42 in epoch 15, gen_loss = 0.8988272270490957, disc_loss = 0.03419238836829399
Trained batch 43 in epoch 15, gen_loss = 0.9010028473355554, disc_loss = 0.033836199531585655
Trained batch 44 in epoch 15, gen_loss = 0.9039121879471673, disc_loss = 0.03624187580620249
Trained batch 45 in epoch 15, gen_loss = 0.9021787811880526, disc_loss = 0.03983834844447025
Trained batch 46 in epoch 15, gen_loss = 0.8926583813860062, disc_loss = 0.04409567731373171
Trained batch 47 in epoch 15, gen_loss = 0.8847483713179827, disc_loss = 0.046472509750553094
Trained batch 48 in epoch 15, gen_loss = 0.8851758040943924, disc_loss = 0.04655615176663411
Trained batch 49 in epoch 15, gen_loss = 0.8840274447202683, disc_loss = 0.04668813963420689
Trained batch 50 in epoch 15, gen_loss = 0.8848152084677827, disc_loss = 0.046343017853431256
Trained batch 51 in epoch 15, gen_loss = 0.8809428919966404, disc_loss = 0.0462679769575166
Trained batch 52 in epoch 15, gen_loss = 0.8768632946149358, disc_loss = 0.04684428263561062
Trained batch 53 in epoch 15, gen_loss = 0.8756206460573055, disc_loss = 0.046148624659205474
Trained batch 54 in epoch 15, gen_loss = 0.8752859077670357, disc_loss = 0.04564903460612351
Trained batch 55 in epoch 15, gen_loss = 0.8817554334444659, disc_loss = 0.04691570785195966
Trained batch 56 in epoch 15, gen_loss = 0.8786697685718536, disc_loss = 0.04676055987447239
Trained batch 57 in epoch 15, gen_loss = 0.8744959774716147, disc_loss = 0.04772991636478952
Trained batch 58 in epoch 15, gen_loss = 0.878753335294077, disc_loss = 0.04924563205627314
Trained batch 59 in epoch 15, gen_loss = 0.8781803076465925, disc_loss = 0.048643717425875366
Trained batch 60 in epoch 15, gen_loss = 0.8773860350006917, disc_loss = 0.04849006248576963
Trained batch 61 in epoch 15, gen_loss = 0.8781689179520453, disc_loss = 0.04806218074724799
Trained batch 62 in epoch 15, gen_loss = 0.8771196873415084, disc_loss = 0.047666186208112374
Trained batch 63 in epoch 15, gen_loss = 0.8762116082943976, disc_loss = 0.047351484310638625
Trained batch 64 in epoch 15, gen_loss = 0.8800840987608983, disc_loss = 0.04697038451782786
Trained batch 65 in epoch 15, gen_loss = 0.8815904815088619, disc_loss = 0.04688695378629773
Trained batch 66 in epoch 15, gen_loss = 0.8791928331353771, disc_loss = 0.04684520747039968
Trained batch 67 in epoch 15, gen_loss = 0.8805350928622133, disc_loss = 0.04635097480187302
Trained batch 68 in epoch 15, gen_loss = 0.8808228982531506, disc_loss = 0.04587044325940635
Trained batch 69 in epoch 15, gen_loss = 0.8803871916873115, disc_loss = 0.0454056026879698
Trained batch 70 in epoch 15, gen_loss = 0.8809230004397917, disc_loss = 0.04533982383821842
Trained batch 71 in epoch 15, gen_loss = 0.8844042830169201, disc_loss = 0.04509950907150698
Trained batch 72 in epoch 15, gen_loss = 0.8799975894085349, disc_loss = 0.04561730904810845
Trained batch 73 in epoch 15, gen_loss = 0.8831631263365617, disc_loss = 0.04567917901393328
Trained batch 74 in epoch 15, gen_loss = 0.884118945201238, disc_loss = 0.045360062761853136
Trained batch 75 in epoch 15, gen_loss = 0.8832869423847449, disc_loss = 0.045456703403033316
Trained batch 76 in epoch 15, gen_loss = 0.8826024350407836, disc_loss = 0.04719630565324968
Trained batch 77 in epoch 15, gen_loss = 0.8824614038070043, disc_loss = 0.04700634503760972
Trained batch 78 in epoch 15, gen_loss = 0.8845457544055166, disc_loss = 0.04689213085943197
Trained batch 79 in epoch 15, gen_loss = 0.8823580902069807, disc_loss = 0.04693226506351493
Trained batch 80 in epoch 15, gen_loss = 0.8801131215360429, disc_loss = 0.047159780868915493
Trained batch 81 in epoch 15, gen_loss = 0.8791304924866048, disc_loss = 0.046728942333152744
Trained batch 82 in epoch 15, gen_loss = 0.8799444490886597, disc_loss = 0.047445785899433386
Trained batch 83 in epoch 15, gen_loss = 0.8783294682701429, disc_loss = 0.04715105061352785
Trained batch 84 in epoch 15, gen_loss = 0.8836997589644264, disc_loss = 0.04724796229754301
Trained batch 85 in epoch 15, gen_loss = 0.8816903257785842, disc_loss = 0.047194155057632296
Trained batch 86 in epoch 15, gen_loss = 0.883304738107769, disc_loss = 0.046881161132377794
Trained batch 87 in epoch 15, gen_loss = 0.881911290301518, disc_loss = 0.046731410225303
Trained batch 88 in epoch 15, gen_loss = 0.8820259346720878, disc_loss = 0.046543635590148444
Trained batch 89 in epoch 15, gen_loss = 0.8814657400051753, disc_loss = 0.04655601505914496
Trained batch 90 in epoch 15, gen_loss = 0.8818491301038763, disc_loss = 0.04613028750703721
Trained batch 91 in epoch 15, gen_loss = 0.8803636208176613, disc_loss = 0.04603882261005271
Trained batch 92 in epoch 15, gen_loss = 0.8785635524539537, disc_loss = 0.04635119748111534
Trained batch 93 in epoch 15, gen_loss = 0.8825553411498983, disc_loss = 0.04647426724810391
Trained batch 94 in epoch 15, gen_loss = 0.8857694961522755, disc_loss = 0.046276890481577106
Trained batch 95 in epoch 15, gen_loss = 0.8878016282493869, disc_loss = 0.04635727284767199
Trained batch 96 in epoch 15, gen_loss = 0.8893374742306385, disc_loss = 0.04603106409944978
Trained batch 97 in epoch 15, gen_loss = 0.8865410433131822, disc_loss = 0.04598853117976414
Trained batch 98 in epoch 15, gen_loss = 0.88514919022117, disc_loss = 0.04587920936238435
Trained batch 99 in epoch 15, gen_loss = 0.8840157601237297, disc_loss = 0.045632527046836915
Trained batch 100 in epoch 15, gen_loss = 0.8830884279000877, disc_loss = 0.04534007415710257
Trained batch 101 in epoch 15, gen_loss = 0.882069988285794, disc_loss = 0.04530938961725755
Trained batch 102 in epoch 15, gen_loss = 0.882955122630573, disc_loss = 0.045315338194695784
Trained batch 103 in epoch 15, gen_loss = 0.8836155616893218, disc_loss = 0.04494545808455978
Trained batch 104 in epoch 15, gen_loss = 0.8861277140322186, disc_loss = 0.045041339835595516
Trained batch 105 in epoch 15, gen_loss = 0.8859061815266339, disc_loss = 0.04495114596771463
Trained batch 106 in epoch 15, gen_loss = 0.8839152452544631, disc_loss = 0.04499046437477119
Trained batch 107 in epoch 15, gen_loss = 0.8845696275432905, disc_loss = 0.04465003050346342
Trained batch 108 in epoch 15, gen_loss = 0.8883752278778532, disc_loss = 0.04549187928472364
Trained batch 109 in epoch 15, gen_loss = 0.8887595688754862, disc_loss = 0.04523066589608789
Trained batch 110 in epoch 15, gen_loss = 0.8868002067278097, disc_loss = 0.04554920740056414
Trained batch 111 in epoch 15, gen_loss = 0.8864742929914168, disc_loss = 0.045623817306477576
Trained batch 112 in epoch 15, gen_loss = 0.8871230786353086, disc_loss = 0.04528587011092928
Trained batch 113 in epoch 15, gen_loss = 0.8877275703768981, disc_loss = 0.044988816526407995
Trained batch 114 in epoch 15, gen_loss = 0.887630857332893, disc_loss = 0.04471010114268764
Trained batch 115 in epoch 15, gen_loss = 0.887101040575011, disc_loss = 0.04444012415579295
Trained batch 116 in epoch 15, gen_loss = 0.8873331223288153, disc_loss = 0.044180072609207824
Trained batch 117 in epoch 15, gen_loss = 0.8871447522256334, disc_loss = 0.044046631876095116
Trained batch 118 in epoch 15, gen_loss = 0.8858056807217478, disc_loss = 0.04440704915093399
Trained batch 119 in epoch 15, gen_loss = 0.8854563298324744, disc_loss = 0.044309354297971976
Trained batch 120 in epoch 15, gen_loss = 0.8862842900201309, disc_loss = 0.044531865526483326
Trained batch 121 in epoch 15, gen_loss = 0.8866437353560181, disc_loss = 0.04430248448243517
Trained batch 122 in epoch 15, gen_loss = 0.8878614459095931, disc_loss = 0.04424096268745578
Trained batch 123 in epoch 15, gen_loss = 0.8864274830106766, disc_loss = 0.04441204499227986
Trained batch 124 in epoch 15, gen_loss = 0.8868119180202484, disc_loss = 0.04412651964649558
Trained batch 125 in epoch 15, gen_loss = 0.8847857101096047, disc_loss = 0.04421064854481272
Trained batch 126 in epoch 15, gen_loss = 0.8857553110817286, disc_loss = 0.04420774004341462
Trained batch 127 in epoch 15, gen_loss = 0.8857003019656986, disc_loss = 0.04409447735451977
Trained batch 128 in epoch 15, gen_loss = 0.886388650929281, disc_loss = 0.04382106322116514
Trained batch 129 in epoch 15, gen_loss = 0.8879563824488567, disc_loss = 0.04361109283322898
Trained batch 130 in epoch 15, gen_loss = 0.8893442870551393, disc_loss = 0.04346462498056411
Trained batch 131 in epoch 15, gen_loss = 0.8900637308304961, disc_loss = 0.04320978710187994
Trained batch 132 in epoch 15, gen_loss = 0.8886113796467171, disc_loss = 0.043303343512930144
Trained batch 133 in epoch 15, gen_loss = 0.8891114915040002, disc_loss = 0.04342325308026551
Trained batch 134 in epoch 15, gen_loss = 0.8874379835746906, disc_loss = 0.04354140271122257
Trained batch 135 in epoch 15, gen_loss = 0.889358221388915, disc_loss = 0.04376559182385202
Trained batch 136 in epoch 15, gen_loss = 0.888262688025941, disc_loss = 0.043820725097898805
Trained batch 137 in epoch 15, gen_loss = 0.8871187829021094, disc_loss = 0.04380137468958138
Trained batch 138 in epoch 15, gen_loss = 0.8866196101089175, disc_loss = 0.04365473640948641
Trained batch 139 in epoch 15, gen_loss = 0.8871512321489198, disc_loss = 0.044035915481591865
Trained batch 140 in epoch 15, gen_loss = 0.8858722589962872, disc_loss = 0.04460508010105778
Trained batch 141 in epoch 15, gen_loss = 0.8852356720558354, disc_loss = 0.04457010537005541
Trained batch 142 in epoch 15, gen_loss = 0.8845298938401096, disc_loss = 0.04455164101925659
Trained batch 143 in epoch 15, gen_loss = 0.8864677024798261, disc_loss = 0.04541791309020482
Trained batch 144 in epoch 15, gen_loss = 0.884004658460617, disc_loss = 0.04608343753257188
Trained batch 145 in epoch 15, gen_loss = 0.8819249294800301, disc_loss = 0.04663091189585218
Trained batch 146 in epoch 15, gen_loss = 0.8834334188172607, disc_loss = 0.04692386517453254
Trained batch 147 in epoch 15, gen_loss = 0.8827698756311391, disc_loss = 0.046939738255271035
Trained batch 148 in epoch 15, gen_loss = 0.8816947122948282, disc_loss = 0.04702005581305231
Trained batch 149 in epoch 15, gen_loss = 0.8795590951045354, disc_loss = 0.04748091485040883
Trained batch 150 in epoch 15, gen_loss = 0.8806049344160699, disc_loss = 0.04780256161959657
Trained batch 151 in epoch 15, gen_loss = 0.8799533053840461, disc_loss = 0.04772061039387297
Trained batch 152 in epoch 15, gen_loss = 0.8777829032707838, disc_loss = 0.048399410980564904
Trained batch 153 in epoch 15, gen_loss = 0.8788448895339842, disc_loss = 0.0484077051711305
Trained batch 154 in epoch 15, gen_loss = 0.8762109819919832, disc_loss = 0.049449336129210646
Trained batch 155 in epoch 15, gen_loss = 0.877600294084121, disc_loss = 0.049777035371591456
Trained batch 156 in epoch 15, gen_loss = 0.8776223889202069, disc_loss = 0.04957008870484628
Trained batch 157 in epoch 15, gen_loss = 0.8777694277748277, disc_loss = 0.049401322235294344
Trained batch 158 in epoch 15, gen_loss = 0.8766902293424187, disc_loss = 0.04953433134821507
Trained batch 159 in epoch 15, gen_loss = 0.875991471670568, disc_loss = 0.049499829692649655
Trained batch 160 in epoch 15, gen_loss = 0.8755117441926684, disc_loss = 0.04955850400157875
Trained batch 161 in epoch 15, gen_loss = 0.8762811004747579, disc_loss = 0.04933190414463572
Trained batch 162 in epoch 15, gen_loss = 0.8764733816582733, disc_loss = 0.049454675173169815
Trained batch 163 in epoch 15, gen_loss = 0.8762020499604505, disc_loss = 0.04939241279995569
Trained batch 164 in epoch 15, gen_loss = 0.8746800164381663, disc_loss = 0.04945047068494288
Trained batch 165 in epoch 15, gen_loss = 0.8754156248038074, disc_loss = 0.049480288454993485
Trained batch 166 in epoch 15, gen_loss = 0.8753962011751301, disc_loss = 0.04935272637765832
Trained batch 167 in epoch 15, gen_loss = 0.8756766462964671, disc_loss = 0.04912131352605121
Trained batch 168 in epoch 15, gen_loss = 0.8757689872084284, disc_loss = 0.04891609360006522
Trained batch 169 in epoch 15, gen_loss = 0.8775581631590338, disc_loss = 0.04875365229706992
Trained batch 170 in epoch 15, gen_loss = 0.8771660883872829, disc_loss = 0.048683662133629034
Trained batch 171 in epoch 15, gen_loss = 0.8782988965164783, disc_loss = 0.048461694619618356
Trained batch 172 in epoch 15, gen_loss = 0.8776678885683159, disc_loss = 0.04850390754004865
Trained batch 173 in epoch 15, gen_loss = 0.8784792414684405, disc_loss = 0.048841380420537005
Trained batch 174 in epoch 15, gen_loss = 0.8775311751025063, disc_loss = 0.04901468147390655
Trained batch 175 in epoch 15, gen_loss = 0.8760712697086009, disc_loss = 0.049091079338474876
Trained batch 176 in epoch 15, gen_loss = 0.8763584115747678, disc_loss = 0.04887307554451843
Trained batch 177 in epoch 15, gen_loss = 0.8779204342137562, disc_loss = 0.04871573266991822
Trained batch 178 in epoch 15, gen_loss = 0.87901578352438, disc_loss = 0.048869453883058696
Trained batch 179 in epoch 15, gen_loss = 0.8779459613892767, disc_loss = 0.048844032375038496
Trained batch 180 in epoch 15, gen_loss = 0.8766152494849421, disc_loss = 0.049019077054394705
Trained batch 181 in epoch 15, gen_loss = 0.8782635964862593, disc_loss = 0.04890726417927378
Trained batch 182 in epoch 15, gen_loss = 0.8775333607457375, disc_loss = 0.04892727481506643
Trained batch 183 in epoch 15, gen_loss = 0.8771759522673876, disc_loss = 0.04874956227444193
Trained batch 184 in epoch 15, gen_loss = 0.8778785169124603, disc_loss = 0.048924094199429495
Trained batch 185 in epoch 15, gen_loss = 0.8767756292576431, disc_loss = 0.0489209343213588
Trained batch 186 in epoch 15, gen_loss = 0.8771142970750676, disc_loss = 0.04874781595124679
Trained batch 187 in epoch 15, gen_loss = 0.877092385387167, disc_loss = 0.04861784118297015
Trained batch 188 in epoch 15, gen_loss = 0.8791395613440761, disc_loss = 0.04893671230674184
Trained batch 189 in epoch 15, gen_loss = 0.8788518414685601, disc_loss = 0.04897740252168947
Trained batch 190 in epoch 15, gen_loss = 0.877667139181916, disc_loss = 0.04907868073336507
Trained batch 191 in epoch 15, gen_loss = 0.8786580536204079, disc_loss = 0.04892490750110786
Trained batch 192 in epoch 15, gen_loss = 0.877492595367481, disc_loss = 0.049364172889720746
Trained batch 193 in epoch 15, gen_loss = 0.8778946788347873, disc_loss = 0.04926766395885689
Trained batch 194 in epoch 15, gen_loss = 0.8781733266818218, disc_loss = 0.049068869423503296
Trained batch 195 in epoch 15, gen_loss = 0.8781888544255373, disc_loss = 0.04896478951975171
Trained batch 196 in epoch 15, gen_loss = 0.8782963391185412, disc_loss = 0.04880167587617705
Trained batch 197 in epoch 15, gen_loss = 0.8794012715419134, disc_loss = 0.04873000044196919
Trained batch 198 in epoch 15, gen_loss = 0.8787102658844473, disc_loss = 0.04874956963733587
Trained batch 199 in epoch 15, gen_loss = 0.8790411798655987, disc_loss = 0.04883138802135363
Trained batch 200 in epoch 15, gen_loss = 0.8767571364765736, disc_loss = 0.0497309171539078
Trained batch 201 in epoch 15, gen_loss = 0.87770645025343, disc_loss = 0.050440613699081066
Trained batch 202 in epoch 15, gen_loss = 0.8768173801194271, disc_loss = 0.05045521854115604
Trained batch 203 in epoch 15, gen_loss = 0.8775603436664039, disc_loss = 0.05024744171475736
Trained batch 204 in epoch 15, gen_loss = 0.876969360578351, disc_loss = 0.050630398451282484
Trained batch 205 in epoch 15, gen_loss = 0.8768120713314964, disc_loss = 0.050553117302309686
Trained batch 206 in epoch 15, gen_loss = 0.8753887019007678, disc_loss = 0.05124117120209595
Trained batch 207 in epoch 15, gen_loss = 0.8757138620488919, disc_loss = 0.05134715067554051
Trained batch 208 in epoch 15, gen_loss = 0.8770801201106259, disc_loss = 0.05206809267089769
Trained batch 209 in epoch 15, gen_loss = 0.8757307922556287, disc_loss = 0.05252996959191348
Trained batch 210 in epoch 15, gen_loss = 0.8760668198926754, disc_loss = 0.052365746236543095
Trained batch 211 in epoch 15, gen_loss = 0.8757620652048093, disc_loss = 0.05233457787533484
Trained batch 212 in epoch 15, gen_loss = 0.8745419238934494, disc_loss = 0.05244226646369122
Trained batch 213 in epoch 15, gen_loss = 0.8749864562371067, disc_loss = 0.05226319484961019
Trained batch 214 in epoch 15, gen_loss = 0.8748208061207172, disc_loss = 0.0521077589565065
Trained batch 215 in epoch 15, gen_loss = 0.8740249139567217, disc_loss = 0.05201732532630019
Trained batch 216 in epoch 15, gen_loss = 0.8735851729245779, disc_loss = 0.05216929178968209
Trained batch 217 in epoch 15, gen_loss = 0.8736284127749434, disc_loss = 0.052082792759676456
Trained batch 218 in epoch 15, gen_loss = 0.8745940073167897, disc_loss = 0.05188521342437085
Trained batch 219 in epoch 15, gen_loss = 0.874862197718837, disc_loss = 0.05169269571885128
Trained batch 220 in epoch 15, gen_loss = 0.8739811463863062, disc_loss = 0.05163835222322949
Trained batch 221 in epoch 15, gen_loss = 0.8741982945719281, disc_loss = 0.0520851419177242
Trained batch 222 in epoch 15, gen_loss = 0.8724388537652824, disc_loss = 0.052877329964391186
Trained batch 223 in epoch 15, gen_loss = 0.8720684537131872, disc_loss = 0.052901867217899835
Trained batch 224 in epoch 15, gen_loss = 0.8714314003785452, disc_loss = 0.05308784336472551
Trained batch 225 in epoch 15, gen_loss = 0.871232612866216, disc_loss = 0.05308235315317535
Trained batch 226 in epoch 15, gen_loss = 0.8724894375265433, disc_loss = 0.05306688119095262
Trained batch 227 in epoch 15, gen_loss = 0.8723904818557856, disc_loss = 0.05297882958486872
Trained batch 228 in epoch 15, gen_loss = 0.8714722674746701, disc_loss = 0.05323392639798824
Trained batch 229 in epoch 15, gen_loss = 0.8730533427518347, disc_loss = 0.05323842829295798
Trained batch 230 in epoch 15, gen_loss = 0.8728265144350209, disc_loss = 0.05313084151765162
Trained batch 231 in epoch 15, gen_loss = 0.873203935422774, disc_loss = 0.05295532548615452
Trained batch 232 in epoch 15, gen_loss = 0.8742592407654284, disc_loss = 0.052794309275008965
Trained batch 233 in epoch 15, gen_loss = 0.8745266230952027, disc_loss = 0.05263559266916898
Trained batch 234 in epoch 15, gen_loss = 0.8736087927158843, disc_loss = 0.0525988622370394
Trained batch 235 in epoch 15, gen_loss = 0.8738238221760524, disc_loss = 0.052437324836550246
Trained batch 236 in epoch 15, gen_loss = 0.8744419502558084, disc_loss = 0.05228426633009742
Trained batch 237 in epoch 15, gen_loss = 0.8741885545123526, disc_loss = 0.05241165956787515
Trained batch 238 in epoch 15, gen_loss = 0.8735974073160643, disc_loss = 0.052395900752333045
Trained batch 239 in epoch 15, gen_loss = 0.8724721303830544, disc_loss = 0.052523324531891076
Trained batch 240 in epoch 15, gen_loss = 0.8734732427290366, disc_loss = 0.052456867801898864
Trained batch 241 in epoch 15, gen_loss = 0.8736615546725013, disc_loss = 0.0522824886759112
Trained batch 242 in epoch 15, gen_loss = 0.8743314126146183, disc_loss = 0.052101923541813595
Trained batch 243 in epoch 15, gen_loss = 0.8739222733945143, disc_loss = 0.05205441986737376
Trained batch 244 in epoch 15, gen_loss = 0.874758697164302, disc_loss = 0.05199463429613685
Trained batch 245 in epoch 15, gen_loss = 0.8749477346011294, disc_loss = 0.05194030141616922
Trained batch 246 in epoch 15, gen_loss = 0.874039332031721, disc_loss = 0.05210183041833854
Trained batch 247 in epoch 15, gen_loss = 0.8741984354151834, disc_loss = 0.05196834111308318
Trained batch 248 in epoch 15, gen_loss = 0.8744435661049732, disc_loss = 0.051805543169065056
Trained batch 249 in epoch 15, gen_loss = 0.8745130430459976, disc_loss = 0.051715923538431526
Trained batch 250 in epoch 15, gen_loss = 0.8749713036881025, disc_loss = 0.05195547066502778
Trained batch 251 in epoch 15, gen_loss = 0.8760853678224578, disc_loss = 0.052045964434491616
Trained batch 252 in epoch 15, gen_loss = 0.8746999281903972, disc_loss = 0.052591464638695296
Trained batch 253 in epoch 15, gen_loss = 0.8742015531917257, disc_loss = 0.05272590312336784
Trained batch 254 in epoch 15, gen_loss = 0.8737545171204735, disc_loss = 0.052795495931059123
Trained batch 255 in epoch 15, gen_loss = 0.8740041001001373, disc_loss = 0.053133587460251874
Trained batch 256 in epoch 15, gen_loss = 0.8729525160928645, disc_loss = 0.05321192798469259
Trained batch 257 in epoch 15, gen_loss = 0.8717335549204849, disc_loss = 0.05386763169112536
Trained batch 258 in epoch 15, gen_loss = 0.8727129402077797, disc_loss = 0.053936540668751164
Trained batch 259 in epoch 15, gen_loss = 0.8725582651220836, disc_loss = 0.05392959277467946
Trained batch 260 in epoch 15, gen_loss = 0.8721532752002336, disc_loss = 0.0539019931289742
Trained batch 261 in epoch 15, gen_loss = 0.8719696820009756, disc_loss = 0.05376046364735954
Trained batch 262 in epoch 15, gen_loss = 0.8720841776055528, disc_loss = 0.053618179363315435
Trained batch 263 in epoch 15, gen_loss = 0.8719765086742964, disc_loss = 0.05356401108226485
Trained batch 264 in epoch 15, gen_loss = 0.87179188762071, disc_loss = 0.05357378155239067
Trained batch 265 in epoch 15, gen_loss = 0.8716103195920026, disc_loss = 0.05348170445566731
Trained batch 266 in epoch 15, gen_loss = 0.8706786307726013, disc_loss = 0.053663372189462294
Trained batch 267 in epoch 15, gen_loss = 0.8717587600225833, disc_loss = 0.053736190775534445
Trained batch 268 in epoch 15, gen_loss = 0.8717282973922318, disc_loss = 0.053611681542141174
Trained batch 269 in epoch 15, gen_loss = 0.8713288570995684, disc_loss = 0.05356573703767801
Trained batch 270 in epoch 15, gen_loss = 0.8705407921018635, disc_loss = 0.05351324493367898
Trained batch 271 in epoch 15, gen_loss = 0.8719595844912178, disc_loss = 0.05414728018941412
Trained batch 272 in epoch 15, gen_loss = 0.8711433926999788, disc_loss = 0.05421829167514657
Trained batch 273 in epoch 15, gen_loss = 0.8719730156399038, disc_loss = 0.05406660052784549
Trained batch 274 in epoch 15, gen_loss = 0.8717575282400305, disc_loss = 0.05396262292665514
Trained batch 275 in epoch 15, gen_loss = 0.8714176011474236, disc_loss = 0.053934790752490684
Trained batch 276 in epoch 15, gen_loss = 0.8714652766174358, disc_loss = 0.05384999709136596
Trained batch 277 in epoch 15, gen_loss = 0.8716652012771839, disc_loss = 0.05368612695103444
Trained batch 278 in epoch 15, gen_loss = 0.8718146860172244, disc_loss = 0.05362955573445526
Trained batch 279 in epoch 15, gen_loss = 0.8714395428342478, disc_loss = 0.053582189263709425
Trained batch 280 in epoch 15, gen_loss = 0.8719100730487036, disc_loss = 0.05348808619150647
Trained batch 281 in epoch 15, gen_loss = 0.8716894776051771, disc_loss = 0.05334477016788161
Trained batch 282 in epoch 15, gen_loss = 0.872482056225989, disc_loss = 0.053463852669806765
Trained batch 283 in epoch 15, gen_loss = 0.8721237681071523, disc_loss = 0.05332364967833995
Trained batch 284 in epoch 15, gen_loss = 0.8718212555375016, disc_loss = 0.05323913357008183
Trained batch 285 in epoch 15, gen_loss = 0.8719022083324153, disc_loss = 0.05312692112992746
Trained batch 286 in epoch 15, gen_loss = 0.8718083163379376, disc_loss = 0.053024763703826513
Trained batch 287 in epoch 15, gen_loss = 0.8733507673152618, disc_loss = 0.05298441410640306
Trained batch 288 in epoch 15, gen_loss = 0.873967937635303, disc_loss = 0.05287049203034761
Trained batch 289 in epoch 15, gen_loss = 0.872640954523251, disc_loss = 0.05306491831413888
Trained batch 290 in epoch 15, gen_loss = 0.8722037577751985, disc_loss = 0.0533222501851055
Trained batch 291 in epoch 15, gen_loss = 0.8721944992877033, disc_loss = 0.05319113183721951
Trained batch 292 in epoch 15, gen_loss = 0.8726051880027654, disc_loss = 0.05303200311583718
Trained batch 293 in epoch 15, gen_loss = 0.8731329705642195, disc_loss = 0.05289928097322229
Trained batch 294 in epoch 15, gen_loss = 0.8725265221070435, disc_loss = 0.052897048758942695
Trained batch 295 in epoch 15, gen_loss = 0.8729399276544919, disc_loss = 0.05288637797442592
Trained batch 296 in epoch 15, gen_loss = 0.8727586661725735, disc_loss = 0.05275990809423705
Trained batch 297 in epoch 15, gen_loss = 0.8733158158575929, disc_loss = 0.05263266462563918
Trained batch 298 in epoch 15, gen_loss = 0.8731573530064778, disc_loss = 0.05248421397726721
Trained batch 299 in epoch 15, gen_loss = 0.8738708640138309, disc_loss = 0.052343092596468827
Trained batch 300 in epoch 15, gen_loss = 0.8734301632622944, disc_loss = 0.05235944724056956
Trained batch 301 in epoch 15, gen_loss = 0.8741033336776771, disc_loss = 0.05232253765520819
Trained batch 302 in epoch 15, gen_loss = 0.8729977376586927, disc_loss = 0.05265815286642008
Trained batch 303 in epoch 15, gen_loss = 0.8723938609228322, disc_loss = 0.05261271837700501
Trained batch 304 in epoch 15, gen_loss = 0.8741646652338935, disc_loss = 0.0527612432700078
Trained batch 305 in epoch 15, gen_loss = 0.8743833756329966, disc_loss = 0.05262836431506169
Trained batch 306 in epoch 15, gen_loss = 0.874323048207193, disc_loss = 0.05250887587781789
Trained batch 307 in epoch 15, gen_loss = 0.873118914083227, disc_loss = 0.05279977378199578
Trained batch 308 in epoch 15, gen_loss = 0.873838679207953, disc_loss = 0.05269873194535139
Trained batch 309 in epoch 15, gen_loss = 0.8744323114233632, disc_loss = 0.05270572164576621
Trained batch 310 in epoch 15, gen_loss = 0.8748394004593325, disc_loss = 0.05261173098530752
Trained batch 311 in epoch 15, gen_loss = 0.874141227071866, disc_loss = 0.052854467438569724
Trained batch 312 in epoch 15, gen_loss = 0.8739025353814085, disc_loss = 0.05307497771325917
Trained batch 313 in epoch 15, gen_loss = 0.8745041729728128, disc_loss = 0.05297463241768823
Trained batch 314 in epoch 15, gen_loss = 0.8740225597979531, disc_loss = 0.052895064437614076
Trained batch 315 in epoch 15, gen_loss = 0.8739983793112296, disc_loss = 0.05280751451301754
Trained batch 316 in epoch 15, gen_loss = 0.8737223899514893, disc_loss = 0.052958715029871706
Trained batch 317 in epoch 15, gen_loss = 0.8731957500648199, disc_loss = 0.052953880952390016
Trained batch 318 in epoch 15, gen_loss = 0.8724253096363761, disc_loss = 0.05305699013074317
Trained batch 319 in epoch 15, gen_loss = 0.8720475123263896, disc_loss = 0.05296400018705753
Trained batch 320 in epoch 15, gen_loss = 0.872778209291886, disc_loss = 0.05311247109177281
Trained batch 321 in epoch 15, gen_loss = 0.8725765585344031, disc_loss = 0.053090084533594685
Trained batch 322 in epoch 15, gen_loss = 0.8727369254034001, disc_loss = 0.05296773582137544
Trained batch 323 in epoch 15, gen_loss = 0.8725200623825744, disc_loss = 0.05290309392507935
Trained batch 324 in epoch 15, gen_loss = 0.8724368701531336, disc_loss = 0.05278568114942083
Trained batch 325 in epoch 15, gen_loss = 0.8729537123002888, disc_loss = 0.05266244044567407
Trained batch 326 in epoch 15, gen_loss = 0.8729645876891752, disc_loss = 0.05276968414590492
Trained batch 327 in epoch 15, gen_loss = 0.8725303276101264, disc_loss = 0.052721649954924586
Trained batch 328 in epoch 15, gen_loss = 0.8720847142684786, disc_loss = 0.052731840898166765
Trained batch 329 in epoch 15, gen_loss = 0.8721658364389882, disc_loss = 0.05288659117579686
Trained batch 330 in epoch 15, gen_loss = 0.8716872193121838, disc_loss = 0.052845628995425845
Trained batch 331 in epoch 15, gen_loss = 0.8712285635880677, disc_loss = 0.05281729130102434
Trained batch 332 in epoch 15, gen_loss = 0.8709412484734624, disc_loss = 0.0527845914223911
Trained batch 333 in epoch 15, gen_loss = 0.8704099959420587, disc_loss = 0.05328228530016711
Trained batch 334 in epoch 15, gen_loss = 0.8696997682550061, disc_loss = 0.05346216497275589
Trained batch 335 in epoch 15, gen_loss = 0.869718659935253, disc_loss = 0.05334438533949045
Trained batch 336 in epoch 15, gen_loss = 0.8705566903073285, disc_loss = 0.05356412537489916
Trained batch 337 in epoch 15, gen_loss = 0.8696870638950337, disc_loss = 0.05368816325325276
Trained batch 338 in epoch 15, gen_loss = 0.8690761231918954, disc_loss = 0.05368312181915901
Trained batch 339 in epoch 15, gen_loss = 0.8705750127925592, disc_loss = 0.054128969807232565
Trained batch 340 in epoch 15, gen_loss = 0.8703253920302013, disc_loss = 0.05411490119168879
Trained batch 341 in epoch 15, gen_loss = 0.8700038845601835, disc_loss = 0.05400960706855165
Trained batch 342 in epoch 15, gen_loss = 0.8698396485505229, disc_loss = 0.05390631351701416
Trained batch 343 in epoch 15, gen_loss = 0.870237820803426, disc_loss = 0.053822297436390935
Trained batch 344 in epoch 15, gen_loss = 0.8696233356344527, disc_loss = 0.0538133574852153
Trained batch 345 in epoch 15, gen_loss = 0.8692312611837607, disc_loss = 0.05377415795487519
Trained batch 346 in epoch 15, gen_loss = 0.8688611509305256, disc_loss = 0.05373260964604594
Trained batch 347 in epoch 15, gen_loss = 0.869132179724074, disc_loss = 0.053597773671492766
Trained batch 348 in epoch 15, gen_loss = 0.8690033567839844, disc_loss = 0.05360339608651861
Trained batch 349 in epoch 15, gen_loss = 0.8690582535096577, disc_loss = 0.05353288487664291
Trained batch 350 in epoch 15, gen_loss = 0.8688739464323745, disc_loss = 0.053478972163804914
Trained batch 351 in epoch 15, gen_loss = 0.8695803485302762, disc_loss = 0.05343200310810723
Trained batch 352 in epoch 15, gen_loss = 0.8699332630161524, disc_loss = 0.053328878576036215
Trained batch 353 in epoch 15, gen_loss = 0.8706872331052177, disc_loss = 0.053306060953665586
Trained batch 354 in epoch 15, gen_loss = 0.8701158244005391, disc_loss = 0.05337995171127185
Trained batch 355 in epoch 15, gen_loss = 0.8694728123170606, disc_loss = 0.05343537792312295
Trained batch 356 in epoch 15, gen_loss = 0.8697656200212591, disc_loss = 0.053493699272807574
Trained batch 357 in epoch 15, gen_loss = 0.8696121777402622, disc_loss = 0.05352075002546417
Trained batch 358 in epoch 15, gen_loss = 0.8699685900490264, disc_loss = 0.05340030322416911
Trained batch 359 in epoch 15, gen_loss = 0.86899937565128, disc_loss = 0.05390293459511465
Trained batch 360 in epoch 15, gen_loss = 0.8684964218793483, disc_loss = 0.053950125552775785
Trained batch 361 in epoch 15, gen_loss = 0.8685165300389022, disc_loss = 0.05396937944241979
Trained batch 362 in epoch 15, gen_loss = 0.869273842776774, disc_loss = 0.05401875348582084
Trained batch 363 in epoch 15, gen_loss = 0.8699700589199643, disc_loss = 0.05401218204585078
Trained batch 364 in epoch 15, gen_loss = 0.8701204199497014, disc_loss = 0.05395704489456464
Trained batch 365 in epoch 15, gen_loss = 0.8689798919555268, disc_loss = 0.054168040289090634
Trained batch 366 in epoch 15, gen_loss = 0.8692540247044056, disc_loss = 0.054160041526487804
Trained batch 367 in epoch 15, gen_loss = 0.8690007369479408, disc_loss = 0.05411002480262971
Trained batch 368 in epoch 15, gen_loss = 0.868561300320354, disc_loss = 0.0541159857498598
Trained batch 369 in epoch 15, gen_loss = 0.8696453917670894, disc_loss = 0.05432941007453042
Trained batch 370 in epoch 15, gen_loss = 0.8694010463686324, disc_loss = 0.05442667911155526
Trained batch 371 in epoch 15, gen_loss = 0.8688746951921011, disc_loss = 0.05461107004153472
Trained batch 372 in epoch 15, gen_loss = 0.8688744598994625, disc_loss = 0.054537405487119994
Trained batch 373 in epoch 15, gen_loss = 0.8683217602936342, disc_loss = 0.05457651480673788
Trained batch 374 in epoch 15, gen_loss = 0.8685975915590922, disc_loss = 0.054574881404638294
Trained batch 375 in epoch 15, gen_loss = 0.869574822168401, disc_loss = 0.054477109241873975
Trained batch 376 in epoch 15, gen_loss = 0.8695882316925797, disc_loss = 0.05436882556018368
Trained batch 377 in epoch 15, gen_loss = 0.8691778771145634, disc_loss = 0.05437533455413012
Trained batch 378 in epoch 15, gen_loss = 0.8690330049607873, disc_loss = 0.05441214235150563
Trained batch 379 in epoch 15, gen_loss = 0.868755579465314, disc_loss = 0.05431679379881212
Trained batch 380 in epoch 15, gen_loss = 0.8689783616015917, disc_loss = 0.05419399290592495
Trained batch 381 in epoch 15, gen_loss = 0.8686238625598828, disc_loss = 0.05412829551767773
Trained batch 382 in epoch 15, gen_loss = 0.868398495816064, disc_loss = 0.05417084139005789
Trained batch 383 in epoch 15, gen_loss = 0.8686420409940183, disc_loss = 0.05420737090268327
Trained batch 384 in epoch 15, gen_loss = 0.8692204080618822, disc_loss = 0.05469017730808103
Trained batch 385 in epoch 15, gen_loss = 0.8683718748660902, disc_loss = 0.055032850136990066
Trained batch 386 in epoch 15, gen_loss = 0.8677531582440516, disc_loss = 0.05507945503741118
Trained batch 387 in epoch 15, gen_loss = 0.867522661065318, disc_loss = 0.05504285938288901
Trained batch 388 in epoch 15, gen_loss = 0.8676591707072712, disc_loss = 0.0550643366768688
Trained batch 389 in epoch 15, gen_loss = 0.8670095972525768, disc_loss = 0.055152590004488446
Trained batch 390 in epoch 15, gen_loss = 0.8673552433243188, disc_loss = 0.05510536187311725
Trained batch 391 in epoch 15, gen_loss = 0.867079750311618, disc_loss = 0.055117080211449336
Trained batch 392 in epoch 15, gen_loss = 0.8674108561972018, disc_loss = 0.05510364148206535
Trained batch 393 in epoch 15, gen_loss = 0.8673427059565704, disc_loss = 0.05499745454629741
Trained batch 394 in epoch 15, gen_loss = 0.8669020260436625, disc_loss = 0.054985114934418024
Trained batch 395 in epoch 15, gen_loss = 0.8672540892254222, disc_loss = 0.05510360189017398
Trained batch 396 in epoch 15, gen_loss = 0.8666538515078931, disc_loss = 0.05513931966858261
Trained batch 397 in epoch 15, gen_loss = 0.866321361843665, disc_loss = 0.05531184792977257
Trained batch 398 in epoch 15, gen_loss = 0.8662917113543155, disc_loss = 0.05527955745778661
Trained batch 399 in epoch 15, gen_loss = 0.8658431349694728, disc_loss = 0.05522624166915193
Trained batch 400 in epoch 15, gen_loss = 0.8665028312557058, disc_loss = 0.05513852533937764
Trained batch 401 in epoch 15, gen_loss = 0.866810125942847, disc_loss = 0.05503535752569265
Trained batch 402 in epoch 15, gen_loss = 0.8662714615057479, disc_loss = 0.055081899478920636
Trained batch 403 in epoch 15, gen_loss = 0.8658212005796999, disc_loss = 0.05507371002937307
Trained batch 404 in epoch 15, gen_loss = 0.8659128791020241, disc_loss = 0.05501448384221689
Trained batch 405 in epoch 15, gen_loss = 0.8669911988556679, disc_loss = 0.05520684449139781
Trained batch 406 in epoch 15, gen_loss = 0.8671889754712435, disc_loss = 0.055101651721233526
Trained batch 407 in epoch 15, gen_loss = 0.8673514406762871, disc_loss = 0.054995079260027294
Trained batch 408 in epoch 15, gen_loss = 0.8672289381983228, disc_loss = 0.05498583282373645
Trained batch 409 in epoch 15, gen_loss = 0.8669063466351207, disc_loss = 0.05496433844290129
Trained batch 410 in epoch 15, gen_loss = 0.8670570679244624, disc_loss = 0.05484726279180887
Trained batch 411 in epoch 15, gen_loss = 0.8664678054527172, disc_loss = 0.0549390438901152
Trained batch 412 in epoch 15, gen_loss = 0.8668990178489223, disc_loss = 0.05482637978409198
Trained batch 413 in epoch 15, gen_loss = 0.866771396951399, disc_loss = 0.054977726448858205
Trained batch 414 in epoch 15, gen_loss = 0.866313823878047, disc_loss = 0.05497938923829471
Trained batch 415 in epoch 15, gen_loss = 0.8665015426679299, disc_loss = 0.0548945701235565
Trained batch 416 in epoch 15, gen_loss = 0.8658545972060242, disc_loss = 0.05489992572450273
Trained batch 417 in epoch 15, gen_loss = 0.8660770258264678, disc_loss = 0.054991317945242854
Trained batch 418 in epoch 15, gen_loss = 0.8662032933109984, disc_loss = 0.05488002002972727
Trained batch 419 in epoch 15, gen_loss = 0.866044604636374, disc_loss = 0.05487516124710618
Trained batch 420 in epoch 15, gen_loss = 0.8670020203975487, disc_loss = 0.054927855992198626
Trained batch 421 in epoch 15, gen_loss = 0.8668490031036721, disc_loss = 0.054836042734057205
Trained batch 422 in epoch 15, gen_loss = 0.8668182314710414, disc_loss = 0.05507149983827139
Trained batch 423 in epoch 15, gen_loss = 0.8661740297135317, disc_loss = 0.05522135741468343
Trained batch 424 in epoch 15, gen_loss = 0.8662325683762045, disc_loss = 0.055131572455386905
Trained batch 425 in epoch 15, gen_loss = 0.8665821447338856, disc_loss = 0.05511076060700899
Trained batch 426 in epoch 15, gen_loss = 0.8664286936474069, disc_loss = 0.05501324463029342
Trained batch 427 in epoch 15, gen_loss = 0.8668238198924287, disc_loss = 0.055050281732708706
Trained batch 428 in epoch 15, gen_loss = 0.8662584008592548, disc_loss = 0.05512398418303935
Trained batch 429 in epoch 15, gen_loss = 0.8663091131421022, disc_loss = 0.05505646953554174
Trained batch 430 in epoch 15, gen_loss = 0.8665220783094243, disc_loss = 0.05495327599930065
Trained batch 431 in epoch 15, gen_loss = 0.8661452127551591, disc_loss = 0.055004520508831506
Trained batch 432 in epoch 15, gen_loss = 0.8664261260979721, disc_loss = 0.05511731985960732
Trained batch 433 in epoch 15, gen_loss = 0.8664201565327183, disc_loss = 0.05502605627393908
Trained batch 434 in epoch 15, gen_loss = 0.8659138634287078, disc_loss = 0.05516130751555507
Trained batch 435 in epoch 15, gen_loss = 0.8659467933648223, disc_loss = 0.055391957781516836
Trained batch 436 in epoch 15, gen_loss = 0.8657774271899558, disc_loss = 0.05544086685830416
Trained batch 437 in epoch 15, gen_loss = 0.8656952583898693, disc_loss = 0.05540014843703099
Trained batch 438 in epoch 15, gen_loss = 0.8654747799480151, disc_loss = 0.05534480464939614
Trained batch 439 in epoch 15, gen_loss = 0.8652008482001045, disc_loss = 0.05533091886794533
Trained batch 440 in epoch 15, gen_loss = 0.8646386559047397, disc_loss = 0.055595101551057735
Trained batch 441 in epoch 15, gen_loss = 0.8650047609169559, disc_loss = 0.056023068594371235
Trained batch 442 in epoch 15, gen_loss = 0.8641590100647902, disc_loss = 0.05632466202576563
Trained batch 443 in epoch 15, gen_loss = 0.8643044766273584, disc_loss = 0.056288545610391545
Trained batch 444 in epoch 15, gen_loss = 0.8639706323655804, disc_loss = 0.05629470796544063
Trained batch 445 in epoch 15, gen_loss = 0.863264441623816, disc_loss = 0.05637470545401722
Trained batch 446 in epoch 15, gen_loss = 0.863628369983144, disc_loss = 0.05633239004181769
Trained batch 447 in epoch 15, gen_loss = 0.864183127214866, disc_loss = 0.05627767538265159
Trained batch 448 in epoch 15, gen_loss = 0.8647089252758663, disc_loss = 0.05664136693325466
Trained batch 449 in epoch 15, gen_loss = 0.8640563829739889, disc_loss = 0.05691295520609452
Trained batch 450 in epoch 15, gen_loss = 0.8633996380406315, disc_loss = 0.05701768919804904
Trained batch 451 in epoch 15, gen_loss = 0.8634219429398005, disc_loss = 0.057076231019151095
Trained batch 452 in epoch 15, gen_loss = 0.8631390018705237, disc_loss = 0.057171051597087
Trained batch 453 in epoch 15, gen_loss = 0.8634162794650914, disc_loss = 0.057130484545340816
Trained batch 454 in epoch 15, gen_loss = 0.8635548233985901, disc_loss = 0.05729994235437486
Trained batch 455 in epoch 15, gen_loss = 0.8632608168480689, disc_loss = 0.05724036481880926
Trained batch 456 in epoch 15, gen_loss = 0.862653885419833, disc_loss = 0.057397846522775665
Trained batch 457 in epoch 15, gen_loss = 0.8625612227677257, disc_loss = 0.05736376697250426
Trained batch 458 in epoch 15, gen_loss = 0.8621486840944145, disc_loss = 0.05736908862724381
Trained batch 459 in epoch 15, gen_loss = 0.8622072295002315, disc_loss = 0.05734258140943459
Trained batch 460 in epoch 15, gen_loss = 0.8622985783471461, disc_loss = 0.057281713725679806
Trained batch 461 in epoch 15, gen_loss = 0.8619179120569518, disc_loss = 0.05735701752637082
Trained batch 462 in epoch 15, gen_loss = 0.862253271349048, disc_loss = 0.0574428330469257
Trained batch 463 in epoch 15, gen_loss = 0.8619843260224523, disc_loss = 0.057527192558186
Trained batch 464 in epoch 15, gen_loss = 0.8624598999177256, disc_loss = 0.05748386340896769
Trained batch 465 in epoch 15, gen_loss = 0.8624134612441574, disc_loss = 0.0576476430702283
Trained batch 466 in epoch 15, gen_loss = 0.8623339033484204, disc_loss = 0.05757458690988654
Trained batch 467 in epoch 15, gen_loss = 0.862278622821865, disc_loss = 0.057512049773174666
Trained batch 468 in epoch 15, gen_loss = 0.8625257196965248, disc_loss = 0.057428623101850755
Trained batch 469 in epoch 15, gen_loss = 0.8628077214068555, disc_loss = 0.057394392934053184
Trained batch 470 in epoch 15, gen_loss = 0.8622870107365262, disc_loss = 0.05750698602863147
Trained batch 471 in epoch 15, gen_loss = 0.8625030391297098, disc_loss = 0.05740623265185188
Trained batch 472 in epoch 15, gen_loss = 0.8623723300768508, disc_loss = 0.057323871754369767
Trained batch 473 in epoch 15, gen_loss = 0.8619064424611345, disc_loss = 0.05747137401343366
Trained batch 474 in epoch 15, gen_loss = 0.8616779284728201, disc_loss = 0.057405423324947295
Trained batch 475 in epoch 15, gen_loss = 0.8619442188940128, disc_loss = 0.05731966164053081
Trained batch 476 in epoch 15, gen_loss = 0.8618692167150149, disc_loss = 0.05724552721156108
Trained batch 477 in epoch 15, gen_loss = 0.8611253814218434, disc_loss = 0.057404292528186324
Trained batch 478 in epoch 15, gen_loss = 0.8617844086350379, disc_loss = 0.05784168407721503
Trained batch 479 in epoch 15, gen_loss = 0.8611629112313192, disc_loss = 0.057878364505207475
Trained batch 480 in epoch 15, gen_loss = 0.8612546625851097, disc_loss = 0.05780129135332676
Trained batch 481 in epoch 15, gen_loss = 0.860537964897037, disc_loss = 0.05796429867995323
Trained batch 482 in epoch 15, gen_loss = 0.8608669549782083, disc_loss = 0.0580598934935348
Trained batch 483 in epoch 15, gen_loss = 0.8612619536228416, disc_loss = 0.057987308086373285
Trained batch 484 in epoch 15, gen_loss = 0.8610084038419822, disc_loss = 0.0579985078337804
Trained batch 485 in epoch 15, gen_loss = 0.8606234087374965, disc_loss = 0.05798469321637457
Trained batch 486 in epoch 15, gen_loss = 0.8602535665891988, disc_loss = 0.05807092041064062
Trained batch 487 in epoch 15, gen_loss = 0.8608042915336421, disc_loss = 0.05841922019818248
Trained batch 488 in epoch 15, gen_loss = 0.8609895920704722, disc_loss = 0.05832224011569758
Trained batch 489 in epoch 15, gen_loss = 0.8605653969609007, disc_loss = 0.05852449031413666
Trained batch 490 in epoch 15, gen_loss = 0.8604761478614419, disc_loss = 0.058438695188566224
Trained batch 491 in epoch 15, gen_loss = 0.860795479479844, disc_loss = 0.058415233160414526
Trained batch 492 in epoch 15, gen_loss = 0.8609238907725042, disc_loss = 0.05846302573518113
Trained batch 493 in epoch 15, gen_loss = 0.8606033630457967, disc_loss = 0.05853069496250557
Trained batch 494 in epoch 15, gen_loss = 0.8609116483216334, disc_loss = 0.05849469294583406
Trained batch 495 in epoch 15, gen_loss = 0.8605393090796086, disc_loss = 0.058517458723790404
Trained batch 496 in epoch 15, gen_loss = 0.8605308661038726, disc_loss = 0.05843906160312849
Trained batch 497 in epoch 15, gen_loss = 0.8606019611339493, disc_loss = 0.05843656703392156
Trained batch 498 in epoch 15, gen_loss = 0.8610656103772486, disc_loss = 0.058355528360161786
Trained batch 499 in epoch 15, gen_loss = 0.8607770299911499, disc_loss = 0.05835273943748325
Trained batch 500 in epoch 15, gen_loss = 0.8606860682873907, disc_loss = 0.05825575872300241
Trained batch 501 in epoch 15, gen_loss = 0.8600694440987956, disc_loss = 0.05831226841472386
Trained batch 502 in epoch 15, gen_loss = 0.8607806781414252, disc_loss = 0.058520515694673626
Trained batch 503 in epoch 15, gen_loss = 0.8602127334664739, disc_loss = 0.058502699720621526
Trained batch 504 in epoch 15, gen_loss = 0.8600027963666632, disc_loss = 0.05850165993030561
Trained batch 505 in epoch 15, gen_loss = 0.8605426258956019, disc_loss = 0.05855517544997157
Trained batch 506 in epoch 15, gen_loss = 0.860488286267606, disc_loss = 0.05846961746653597
Trained batch 507 in epoch 15, gen_loss = 0.8600304566734419, disc_loss = 0.058533101719364114
Trained batch 508 in epoch 15, gen_loss = 0.8603587467918696, disc_loss = 0.05860918221907408
Trained batch 509 in epoch 15, gen_loss = 0.8604326552035761, disc_loss = 0.05852638846354596
Trained batch 510 in epoch 15, gen_loss = 0.8603657691679355, disc_loss = 0.058460388903974495
Trained batch 511 in epoch 15, gen_loss = 0.8599612195976079, disc_loss = 0.05856165356362908
Trained batch 512 in epoch 15, gen_loss = 0.8600195901900471, disc_loss = 0.058697371537566594
Trained batch 513 in epoch 15, gen_loss = 0.8597310557671558, disc_loss = 0.05869872434923592
Trained batch 514 in epoch 15, gen_loss = 0.8601333904034884, disc_loss = 0.058656685404226326
Trained batch 515 in epoch 15, gen_loss = 0.8598660433939261, disc_loss = 0.058768158145934744
Trained batch 516 in epoch 15, gen_loss = 0.8597171943007862, disc_loss = 0.05888394570713088
Trained batch 517 in epoch 15, gen_loss = 0.8594509363174438, disc_loss = 0.0589257567342457
Trained batch 518 in epoch 15, gen_loss = 0.860119116329274, disc_loss = 0.05908166627473196
Trained batch 519 in epoch 15, gen_loss = 0.8599306950202354, disc_loss = 0.05904429261483109
Trained batch 520 in epoch 15, gen_loss = 0.8599713369202934, disc_loss = 0.05902061846210924
Trained batch 521 in epoch 15, gen_loss = 0.8599964189575093, disc_loss = 0.05905720437662783
Trained batch 522 in epoch 15, gen_loss = 0.8596142584005688, disc_loss = 0.05907177113363409
Trained batch 523 in epoch 15, gen_loss = 0.8594279249433343, disc_loss = 0.05902814522709072
Trained batch 524 in epoch 15, gen_loss = 0.8594243112064543, disc_loss = 0.05903673849201628
Trained batch 525 in epoch 15, gen_loss = 0.8595747486493434, disc_loss = 0.05906749135963336
Trained batch 526 in epoch 15, gen_loss = 0.8586747035582106, disc_loss = 0.05948438099806375
Trained batch 527 in epoch 15, gen_loss = 0.8586086000908505, disc_loss = 0.059446898997218035
Trained batch 528 in epoch 15, gen_loss = 0.8585861819903656, disc_loss = 0.05947279100815126
Trained batch 529 in epoch 15, gen_loss = 0.8586550196386733, disc_loss = 0.059442453932473965
Trained batch 530 in epoch 15, gen_loss = 0.859052077861829, disc_loss = 0.059379957201531094
Trained batch 531 in epoch 15, gen_loss = 0.85849467199996, disc_loss = 0.05951498195973638
Trained batch 532 in epoch 15, gen_loss = 0.8581972398409029, disc_loss = 0.05985074790061834
Trained batch 533 in epoch 15, gen_loss = 0.8581688144010551, disc_loss = 0.059810567527751296
Trained batch 534 in epoch 15, gen_loss = 0.8577175672923293, disc_loss = 0.059887258714569784
Trained batch 535 in epoch 15, gen_loss = 0.8579822273841545, disc_loss = 0.05995787336028862
Trained batch 536 in epoch 15, gen_loss = 0.8581649642194894, disc_loss = 0.05987410821121193
Trained batch 537 in epoch 15, gen_loss = 0.8576000340587587, disc_loss = 0.06002287696233386
Trained batch 538 in epoch 15, gen_loss = 0.8577523183955332, disc_loss = 0.05999529485526825
Trained batch 539 in epoch 15, gen_loss = 0.8577561604755896, disc_loss = 0.059910604560368313
Trained batch 540 in epoch 15, gen_loss = 0.8577175849907499, disc_loss = 0.059844194843421745
Trained batch 541 in epoch 15, gen_loss = 0.8579156017171501, disc_loss = 0.05975061959786361
Trained batch 542 in epoch 15, gen_loss = 0.8575049261142316, disc_loss = 0.05978021803217671
Trained batch 543 in epoch 15, gen_loss = 0.8574595906059531, disc_loss = 0.05973004233622786
Trained batch 544 in epoch 15, gen_loss = 0.8582701905058064, disc_loss = 0.059944705312234274
Trained batch 545 in epoch 15, gen_loss = 0.8581912050317059, disc_loss = 0.05992238143298625
Trained batch 546 in epoch 15, gen_loss = 0.8577282008130982, disc_loss = 0.05999600158840881
Trained batch 547 in epoch 15, gen_loss = 0.8574885497563076, disc_loss = 0.059945494442138085
Trained batch 548 in epoch 15, gen_loss = 0.8577875441757925, disc_loss = 0.059983348724125245
Trained batch 549 in epoch 15, gen_loss = 0.8577357827533375, disc_loss = 0.05995576008053666
Trained batch 550 in epoch 15, gen_loss = 0.857934145875505, disc_loss = 0.05994108721137236
Trained batch 551 in epoch 15, gen_loss = 0.8577767364356829, disc_loss = 0.059936597297960165
Trained batch 552 in epoch 15, gen_loss = 0.8582680014115346, disc_loss = 0.05989199211470662
Trained batch 553 in epoch 15, gen_loss = 0.8579796622591328, disc_loss = 0.05985839337712349
Trained batch 554 in epoch 15, gen_loss = 0.858137004976874, disc_loss = 0.05977214991727525
Trained batch 555 in epoch 15, gen_loss = 0.8583215914613052, disc_loss = 0.05968660912258725
Trained batch 556 in epoch 15, gen_loss = 0.8586945610799738, disc_loss = 0.059605652527445575
Trained batch 557 in epoch 15, gen_loss = 0.8585582674617835, disc_loss = 0.059562535733685536
Trained batch 558 in epoch 15, gen_loss = 0.8588167431102882, disc_loss = 0.05946713655417342
Trained batch 559 in epoch 15, gen_loss = 0.8588702539248126, disc_loss = 0.05938470511048633
Trained batch 560 in epoch 15, gen_loss = 0.8582349116789466, disc_loss = 0.05952177873817596
Trained batch 561 in epoch 15, gen_loss = 0.8585360468070278, disc_loss = 0.05987871200711304
Trained batch 562 in epoch 15, gen_loss = 0.8586182578418861, disc_loss = 0.05981934876272167
Trained batch 563 in epoch 15, gen_loss = 0.8583222565287394, disc_loss = 0.0598232858056361
Trained batch 564 in epoch 15, gen_loss = 0.857849945536757, disc_loss = 0.05985217838572849
Trained batch 565 in epoch 15, gen_loss = 0.8583907869384483, disc_loss = 0.05986602196729884
Trained batch 566 in epoch 15, gen_loss = 0.8587087120538877, disc_loss = 0.05977766276493248
Trained batch 567 in epoch 15, gen_loss = 0.858694034982735, disc_loss = 0.05976899041922133
Trained batch 568 in epoch 15, gen_loss = 0.8584526655753594, disc_loss = 0.05976085990310527
Trained batch 569 in epoch 15, gen_loss = 0.858293715799064, disc_loss = 0.05969053052545509
Trained batch 570 in epoch 15, gen_loss = 0.8585229331265398, disc_loss = 0.05960893273050204
Trained batch 571 in epoch 15, gen_loss = 0.8589775829048424, disc_loss = 0.05955989870740999
Trained batch 572 in epoch 15, gen_loss = 0.8593067361422234, disc_loss = 0.059486299866150553
Trained batch 573 in epoch 15, gen_loss = 0.8593955220661097, disc_loss = 0.0594201051729053
Trained batch 574 in epoch 15, gen_loss = 0.8595310666250146, disc_loss = 0.05933039261514078
Trained batch 575 in epoch 15, gen_loss = 0.8594356764935784, disc_loss = 0.059306235511030536
Trained batch 576 in epoch 15, gen_loss = 0.8596354617609722, disc_loss = 0.059226585857964004
Trained batch 577 in epoch 15, gen_loss = 0.859813602325413, disc_loss = 0.0591457707599566
Trained batch 578 in epoch 15, gen_loss = 0.8603885814110026, disc_loss = 0.05910346350698557
Trained batch 579 in epoch 15, gen_loss = 0.860603673499206, disc_loss = 0.05902005135611599
Trained batch 580 in epoch 15, gen_loss = 0.8604566041450697, disc_loss = 0.058990718238216
Trained batch 581 in epoch 15, gen_loss = 0.8604890815785661, disc_loss = 0.058911105426655654
Trained batch 582 in epoch 15, gen_loss = 0.8605881261784667, disc_loss = 0.058827161853637795
Trained batch 583 in epoch 15, gen_loss = 0.8607621079642479, disc_loss = 0.05876348315090681
Trained batch 584 in epoch 15, gen_loss = 0.8605488028281775, disc_loss = 0.058725326935736795
Trained batch 585 in epoch 15, gen_loss = 0.8606116701515054, disc_loss = 0.05866182357177723
Trained batch 586 in epoch 15, gen_loss = 0.8606445280616084, disc_loss = 0.058583160157091724
Trained batch 587 in epoch 15, gen_loss = 0.8609859151702349, disc_loss = 0.05855963058804548
Trained batch 588 in epoch 15, gen_loss = 0.8605588633054788, disc_loss = 0.058554111281805155
Trained batch 589 in epoch 15, gen_loss = 0.8608220796463854, disc_loss = 0.0584779052892542
Trained batch 590 in epoch 15, gen_loss = 0.8614795475240085, disc_loss = 0.05844690709086466
Trained batch 591 in epoch 15, gen_loss = 0.8618163556061886, disc_loss = 0.05839242655988405
Trained batch 592 in epoch 15, gen_loss = 0.861985370340878, disc_loss = 0.0583323682988185
Trained batch 593 in epoch 15, gen_loss = 0.8619314780339649, disc_loss = 0.0583378211085556
Trained batch 594 in epoch 15, gen_loss = 0.8622423355318919, disc_loss = 0.05826349828564444
Trained batch 595 in epoch 15, gen_loss = 0.8626894037795547, disc_loss = 0.05830791134202865
Trained batch 596 in epoch 15, gen_loss = 0.862464181242676, disc_loss = 0.058303093444868
Trained batch 597 in epoch 15, gen_loss = 0.8622637661205088, disc_loss = 0.05830646040039542
Trained batch 598 in epoch 15, gen_loss = 0.8623358768493384, disc_loss = 0.05827085543594918
Trained batch 599 in epoch 15, gen_loss = 0.8623143374919892, disc_loss = 0.05821662741790836
Trained batch 600 in epoch 15, gen_loss = 0.8623490272068144, disc_loss = 0.0583130862856727
Trained batch 601 in epoch 15, gen_loss = 0.8625141697072507, disc_loss = 0.058242851073862956
Trained batch 602 in epoch 15, gen_loss = 0.8619995680614491, disc_loss = 0.058300620822968025
Trained batch 603 in epoch 15, gen_loss = 0.8623380562327555, disc_loss = 0.058242355458691275
Trained batch 604 in epoch 15, gen_loss = 0.8624262219618175, disc_loss = 0.05816585327891156
Trained batch 605 in epoch 15, gen_loss = 0.8627515455873886, disc_loss = 0.058114208267977085
Trained batch 606 in epoch 15, gen_loss = 0.8625646377905982, disc_loss = 0.05811930828861266
Trained batch 607 in epoch 15, gen_loss = 0.8624076439361823, disc_loss = 0.058067914079353945
Trained batch 608 in epoch 15, gen_loss = 0.8626452608061541, disc_loss = 0.058116561874643285
Trained batch 609 in epoch 15, gen_loss = 0.8629774435621793, disc_loss = 0.058038468691749404
Trained batch 610 in epoch 15, gen_loss = 0.8628608677078972, disc_loss = 0.05800122036270907
Trained batch 611 in epoch 15, gen_loss = 0.8633971436350953, disc_loss = 0.057948742925457264
Trained batch 612 in epoch 15, gen_loss = 0.863490267251094, disc_loss = 0.05788191189977293
Trained batch 613 in epoch 15, gen_loss = 0.8637492726602461, disc_loss = 0.05783020130037072
Trained batch 614 in epoch 15, gen_loss = 0.8637617658793442, disc_loss = 0.05776414930502453
Trained batch 615 in epoch 15, gen_loss = 0.8634115537846243, disc_loss = 0.057875836763210446
Trained batch 616 in epoch 15, gen_loss = 0.8636776410779845, disc_loss = 0.057844383897927
Trained batch 617 in epoch 15, gen_loss = 0.8638876659198872, disc_loss = 0.05788813474660432
Trained batch 618 in epoch 15, gen_loss = 0.8633263322956535, disc_loss = 0.05791365603129462
Trained batch 619 in epoch 15, gen_loss = 0.8632070971112098, disc_loss = 0.05789764767377487
Trained batch 620 in epoch 15, gen_loss = 0.8634010562958156, disc_loss = 0.057833305467819965
Trained batch 621 in epoch 15, gen_loss = 0.8635456371345704, disc_loss = 0.057765479528246344
Trained batch 622 in epoch 15, gen_loss = 0.8633578896139827, disc_loss = 0.05782444505648834
Trained batch 623 in epoch 15, gen_loss = 0.8636046981391234, disc_loss = 0.05788274696440054
Trained batch 624 in epoch 15, gen_loss = 0.8633955674171447, disc_loss = 0.0578350794903934
Trained batch 625 in epoch 15, gen_loss = 0.8635120944093211, disc_loss = 0.05775661555642542
Trained batch 626 in epoch 15, gen_loss = 0.8634126585636412, disc_loss = 0.05772872650966143
Trained batch 627 in epoch 15, gen_loss = 0.863617818826323, disc_loss = 0.05777135656651252
Trained batch 628 in epoch 15, gen_loss = 0.8633408410939579, disc_loss = 0.05777174757722475
Trained batch 629 in epoch 15, gen_loss = 0.8637596085904137, disc_loss = 0.05773434711487165
Trained batch 630 in epoch 15, gen_loss = 0.8635644142865757, disc_loss = 0.05772081346704186
Trained batch 631 in epoch 15, gen_loss = 0.8637456761885293, disc_loss = 0.05768340884168526
Trained batch 632 in epoch 15, gen_loss = 0.8636335738085645, disc_loss = 0.05763613437721726
Trained batch 633 in epoch 15, gen_loss = 0.8636410664120683, disc_loss = 0.05758406577429114
Trained batch 634 in epoch 15, gen_loss = 0.8636423667584817, disc_loss = 0.05758221040985833
Trained batch 635 in epoch 15, gen_loss = 0.8636325106680768, disc_loss = 0.0575245868732403
Trained batch 636 in epoch 15, gen_loss = 0.8635951480835535, disc_loss = 0.05746839710202776
Trained batch 637 in epoch 15, gen_loss = 0.8638156189066489, disc_loss = 0.05739901198999705
Trained batch 638 in epoch 15, gen_loss = 0.8636745292815804, disc_loss = 0.05739067810192611
Trained batch 639 in epoch 15, gen_loss = 0.863139043841511, disc_loss = 0.057594662607152715
Trained batch 640 in epoch 15, gen_loss = 0.8638099070272282, disc_loss = 0.05791613922705772
Trained batch 641 in epoch 15, gen_loss = 0.8635365154327261, disc_loss = 0.05793032590285338
Trained batch 642 in epoch 15, gen_loss = 0.863385274936771, disc_loss = 0.05792099603525657
Trained batch 643 in epoch 15, gen_loss = 0.8631873700929724, disc_loss = 0.05794057448941242
Trained batch 644 in epoch 15, gen_loss = 0.8630002241726069, disc_loss = 0.057938968493466
Trained batch 645 in epoch 15, gen_loss = 0.8626347123284827, disc_loss = 0.057963825455915774
Trained batch 646 in epoch 15, gen_loss = 0.8623454380993497, disc_loss = 0.058045452969491346
Trained batch 647 in epoch 15, gen_loss = 0.862397653637109, disc_loss = 0.05805866561045318
Trained batch 648 in epoch 15, gen_loss = 0.8624533016251856, disc_loss = 0.05798805623784523
Trained batch 649 in epoch 15, gen_loss = 0.8625113863211412, disc_loss = 0.05794518543765522
Trained batch 650 in epoch 15, gen_loss = 0.862242231171252, disc_loss = 0.05793495454715304
Trained batch 651 in epoch 15, gen_loss = 0.8626549223815005, disc_loss = 0.05789775752956676
Trained batch 652 in epoch 15, gen_loss = 0.862626088706129, disc_loss = 0.05782227039659484
Trained batch 653 in epoch 15, gen_loss = 0.8622992118928775, disc_loss = 0.05785705350319476
Trained batch 654 in epoch 15, gen_loss = 0.8625990758415397, disc_loss = 0.05785205149880916
Trained batch 655 in epoch 15, gen_loss = 0.8625244192960786, disc_loss = 0.05782911777794475
Trained batch 656 in epoch 15, gen_loss = 0.8625620944677785, disc_loss = 0.05778976646712677
Trained batch 657 in epoch 15, gen_loss = 0.8626201008772053, disc_loss = 0.05777741747902633
Trained batch 658 in epoch 15, gen_loss = 0.8625209198555202, disc_loss = 0.057724352299245656
Trained batch 659 in epoch 15, gen_loss = 0.8623722458427603, disc_loss = 0.05768045951033745
Trained batch 660 in epoch 15, gen_loss = 0.8620827129496749, disc_loss = 0.057706708207574314
Trained batch 661 in epoch 15, gen_loss = 0.861985567203101, disc_loss = 0.05767267972042396
Trained batch 662 in epoch 15, gen_loss = 0.8619929544886133, disc_loss = 0.057808495645704894
Trained batch 663 in epoch 15, gen_loss = 0.8619035718491278, disc_loss = 0.05774695746928835
Trained batch 664 in epoch 15, gen_loss = 0.862200653373747, disc_loss = 0.057692879301852976
Trained batch 665 in epoch 15, gen_loss = 0.8617632870559577, disc_loss = 0.05770301574760035
Trained batch 666 in epoch 15, gen_loss = 0.8618727666863437, disc_loss = 0.057647895205464365
Trained batch 667 in epoch 15, gen_loss = 0.8618202014954505, disc_loss = 0.05762283218268885
Trained batch 668 in epoch 15, gen_loss = 0.8616229019535675, disc_loss = 0.05766177174993004
Trained batch 669 in epoch 15, gen_loss = 0.8617542517718985, disc_loss = 0.05759172546816295
Trained batch 670 in epoch 15, gen_loss = 0.8617284805159988, disc_loss = 0.057527527545513546
Trained batch 671 in epoch 15, gen_loss = 0.8615534363225812, disc_loss = 0.0575584824456157
Trained batch 672 in epoch 15, gen_loss = 0.8620398314711243, disc_loss = 0.05767322899524626
Trained batch 673 in epoch 15, gen_loss = 0.8622289531662486, disc_loss = 0.05760557655153868
Trained batch 674 in epoch 15, gen_loss = 0.861886278435036, disc_loss = 0.05763475917762628
Trained batch 675 in epoch 15, gen_loss = 0.8619442581248706, disc_loss = 0.05758466740406102
Trained batch 676 in epoch 15, gen_loss = 0.8625150528933132, disc_loss = 0.0576209176126785
Trained batch 677 in epoch 15, gen_loss = 0.8625183440415205, disc_loss = 0.05755309549374588
Trained batch 678 in epoch 15, gen_loss = 0.8624137503935767, disc_loss = 0.05752711492180495
Trained batch 679 in epoch 15, gen_loss = 0.862483835132683, disc_loss = 0.05747217647251947
Trained batch 680 in epoch 15, gen_loss = 0.8623804187459567, disc_loss = 0.05744446985896748
Trained batch 681 in epoch 15, gen_loss = 0.8618894288442002, disc_loss = 0.0575139533265431
Trained batch 682 in epoch 15, gen_loss = 0.8624212311616231, disc_loss = 0.057598786835598256
Trained batch 683 in epoch 15, gen_loss = 0.862256539582509, disc_loss = 0.057588151738466965
Trained batch 684 in epoch 15, gen_loss = 0.8620221250248652, disc_loss = 0.057598852774767326
Trained batch 685 in epoch 15, gen_loss = 0.8620950912421368, disc_loss = 0.05755957630435792
Trained batch 686 in epoch 15, gen_loss = 0.8623290333511875, disc_loss = 0.05751030229295033
Trained batch 687 in epoch 15, gen_loss = 0.8624457809640917, disc_loss = 0.057518735980793705
Trained batch 688 in epoch 15, gen_loss = 0.8621786363066022, disc_loss = 0.05748679433004452
Trained batch 689 in epoch 15, gen_loss = 0.8621980719808219, disc_loss = 0.057498738842516925
Trained batch 690 in epoch 15, gen_loss = 0.8625905545679085, disc_loss = 0.05745425487783577
Trained batch 691 in epoch 15, gen_loss = 0.862450761688238, disc_loss = 0.0574110239492514
Trained batch 692 in epoch 15, gen_loss = 0.8622011704018278, disc_loss = 0.05742552528200835
Trained batch 693 in epoch 15, gen_loss = 0.862773745736746, disc_loss = 0.0574344329285014
Trained batch 694 in epoch 15, gen_loss = 0.8633550677368109, disc_loss = 0.05739326556447706
Trained batch 695 in epoch 15, gen_loss = 0.863445418319483, disc_loss = 0.05733355716869085
Trained batch 696 in epoch 15, gen_loss = 0.8635078779765147, disc_loss = 0.05726748194419906
Trained batch 697 in epoch 15, gen_loss = 0.8640292028984573, disc_loss = 0.05723556797126879
Trained batch 698 in epoch 15, gen_loss = 0.864283314760833, disc_loss = 0.057185377615859706
Trained batch 699 in epoch 15, gen_loss = 0.863953395656177, disc_loss = 0.057198924693012874
Trained batch 700 in epoch 15, gen_loss = 0.8644220056105272, disc_loss = 0.05714828808979263
Trained batch 701 in epoch 15, gen_loss = 0.8645504803059787, disc_loss = 0.057247358933489166
Trained batch 702 in epoch 15, gen_loss = 0.8644453666966467, disc_loss = 0.05723852082321243
Trained batch 703 in epoch 15, gen_loss = 0.864697102965279, disc_loss = 0.05718029566328782
Trained batch 704 in epoch 15, gen_loss = 0.8645851802318654, disc_loss = 0.057149688869794
Trained batch 705 in epoch 15, gen_loss = 0.8645172672974152, disc_loss = 0.05709139749120193
Trained batch 706 in epoch 15, gen_loss = 0.864504694601434, disc_loss = 0.05706191093159004
Trained batch 707 in epoch 15, gen_loss = 0.8649302584640051, disc_loss = 0.05703182099321278
Trained batch 708 in epoch 15, gen_loss = 0.8648503694278733, disc_loss = 0.05702021210132579
Trained batch 709 in epoch 15, gen_loss = 0.8646505150156961, disc_loss = 0.057060855634274404
Trained batch 710 in epoch 15, gen_loss = 0.8643564238159298, disc_loss = 0.05710866413001919
Trained batch 711 in epoch 15, gen_loss = 0.864202226229598, disc_loss = 0.057070188210581255
Trained batch 712 in epoch 15, gen_loss = 0.8645684781783426, disc_loss = 0.05706678159197931
Trained batch 713 in epoch 15, gen_loss = 0.8646472230011008, disc_loss = 0.057007006394966434
Trained batch 714 in epoch 15, gen_loss = 0.8644627585277691, disc_loss = 0.05708315698820707
Trained batch 715 in epoch 15, gen_loss = 0.8647007651668687, disc_loss = 0.0570665618746838
Trained batch 716 in epoch 15, gen_loss = 0.8645532779613798, disc_loss = 0.05709379628973505
Trained batch 717 in epoch 15, gen_loss = 0.8648555363453199, disc_loss = 0.05718617010693011
Trained batch 718 in epoch 15, gen_loss = 0.8645628048249512, disc_loss = 0.05723197835073994
Trained batch 719 in epoch 15, gen_loss = 0.8647800487776597, disc_loss = 0.05720886107107314
Trained batch 720 in epoch 15, gen_loss = 0.8648626259560394, disc_loss = 0.05718159256761328
Trained batch 721 in epoch 15, gen_loss = 0.8649189590252007, disc_loss = 0.057133581947891296
Trained batch 722 in epoch 15, gen_loss = 0.8649760210167817, disc_loss = 0.05708785685304846
Trained batch 723 in epoch 15, gen_loss = 0.865379783741677, disc_loss = 0.05704106191798365
Trained batch 724 in epoch 15, gen_loss = 0.8654660310416386, disc_loss = 0.056976834884363003
Trained batch 725 in epoch 15, gen_loss = 0.8655973305058545, disc_loss = 0.05692202389463474
Trained batch 726 in epoch 15, gen_loss = 0.8659513855898725, disc_loss = 0.05686545386292973
Trained batch 727 in epoch 15, gen_loss = 0.8659626550071842, disc_loss = 0.0568085335608275
Trained batch 728 in epoch 15, gen_loss = 0.8657841482116688, disc_loss = 0.05679116854367494
Trained batch 729 in epoch 15, gen_loss = 0.8658426826947356, disc_loss = 0.056759906804495275
Trained batch 730 in epoch 15, gen_loss = 0.8663412456473313, disc_loss = 0.05674297679992833
Trained batch 731 in epoch 15, gen_loss = 0.866506357499159, disc_loss = 0.05668730415146839
Trained batch 732 in epoch 15, gen_loss = 0.8663491570120131, disc_loss = 0.05665996241971525
Trained batch 733 in epoch 15, gen_loss = 0.8660365200984705, disc_loss = 0.0566762325040519
Trained batch 734 in epoch 15, gen_loss = 0.8659748501518145, disc_loss = 0.05664261348076722
Trained batch 735 in epoch 15, gen_loss = 0.8661116558410551, disc_loss = 0.05658032303693725
Trained batch 736 in epoch 15, gen_loss = 0.8663721800335712, disc_loss = 0.056606038848223766
Trained batch 737 in epoch 15, gen_loss = 0.8661463285687816, disc_loss = 0.056648992011475004
Trained batch 738 in epoch 15, gen_loss = 0.8661461161179859, disc_loss = 0.05667600521555672
Trained batch 739 in epoch 15, gen_loss = 0.8661586391764718, disc_loss = 0.05661303720978164
Trained batch 740 in epoch 15, gen_loss = 0.8660494869376323, disc_loss = 0.05659434411300198
Trained batch 741 in epoch 15, gen_loss = 0.8661029444871887, disc_loss = 0.05660712926628475
Trained batch 742 in epoch 15, gen_loss = 0.8662625195842091, disc_loss = 0.05656179464152672
Trained batch 743 in epoch 15, gen_loss = 0.866115444850537, disc_loss = 0.05673794061138285
Trained batch 744 in epoch 15, gen_loss = 0.8660359987476528, disc_loss = 0.05677158820861638
Trained batch 745 in epoch 15, gen_loss = 0.8657850314720706, disc_loss = 0.05684706140571741
Trained batch 746 in epoch 15, gen_loss = 0.866059230194194, disc_loss = 0.05700089110540278
Trained batch 747 in epoch 15, gen_loss = 0.8658088095047894, disc_loss = 0.057044818472580354
Trained batch 748 in epoch 15, gen_loss = 0.8659024170944305, disc_loss = 0.05703332031752482
Trained batch 749 in epoch 15, gen_loss = 0.8657080691655477, disc_loss = 0.05703942498875161
Trained batch 750 in epoch 15, gen_loss = 0.8659356264236288, disc_loss = 0.057193719052130505
Trained batch 751 in epoch 15, gen_loss = 0.8659444616988619, disc_loss = 0.05719887705314211
Trained batch 752 in epoch 15, gen_loss = 0.865592330812933, disc_loss = 0.057294704943306615
Trained batch 753 in epoch 15, gen_loss = 0.8654283842452325, disc_loss = 0.057295854999473816
Trained batch 754 in epoch 15, gen_loss = 0.8655579866952454, disc_loss = 0.05738119558301687
Trained batch 755 in epoch 15, gen_loss = 0.8656257312133829, disc_loss = 0.057327334715482146
Trained batch 756 in epoch 15, gen_loss = 0.8655691310625567, disc_loss = 0.05729272757451415
Trained batch 757 in epoch 15, gen_loss = 0.8658011016241793, disc_loss = 0.05723270031102591
Trained batch 758 in epoch 15, gen_loss = 0.8656590866791244, disc_loss = 0.05721665776797297
Trained batch 759 in epoch 15, gen_loss = 0.865923025655119, disc_loss = 0.05723220872950103
Trained batch 760 in epoch 15, gen_loss = 0.8657816621069839, disc_loss = 0.05736949350917406
Trained batch 761 in epoch 15, gen_loss = 0.8654173495262627, disc_loss = 0.05756994423192493
Trained batch 762 in epoch 15, gen_loss = 0.865776754613004, disc_loss = 0.057514499559837395
Trained batch 763 in epoch 15, gen_loss = 0.8658300855084864, disc_loss = 0.05751755916945032
Trained batch 764 in epoch 15, gen_loss = 0.8657897900911717, disc_loss = 0.05748707988524651
Trained batch 765 in epoch 15, gen_loss = 0.8657489406533403, disc_loss = 0.057429940604505084
Trained batch 766 in epoch 15, gen_loss = 0.8658211290292355, disc_loss = 0.05737760937633054
Trained batch 767 in epoch 15, gen_loss = 0.8663994173208872, disc_loss = 0.0575447514293046
Trained batch 768 in epoch 15, gen_loss = 0.8664384984226003, disc_loss = 0.057497423454048534
Trained batch 769 in epoch 15, gen_loss = 0.8659634440750271, disc_loss = 0.057656060601282234
Trained batch 770 in epoch 15, gen_loss = 0.8662376842146253, disc_loss = 0.0575923354560618
Trained batch 771 in epoch 15, gen_loss = 0.8667240880159517, disc_loss = 0.05758751184773665
Trained batch 772 in epoch 15, gen_loss = 0.8663835599536575, disc_loss = 0.05760667263982001
Trained batch 773 in epoch 15, gen_loss = 0.8665715013979634, disc_loss = 0.057617568837488385
Trained batch 774 in epoch 15, gen_loss = 0.8663975441071295, disc_loss = 0.05759709846648958
Trained batch 775 in epoch 15, gen_loss = 0.8664265169771677, disc_loss = 0.057547855489172
Trained batch 776 in epoch 15, gen_loss = 0.8664410128863469, disc_loss = 0.057493516640135946
Trained batch 777 in epoch 15, gen_loss = 0.8666096349608315, disc_loss = 0.05750975678770642
Trained batch 778 in epoch 15, gen_loss = 0.8662583648928935, disc_loss = 0.057556756782262984
Trained batch 779 in epoch 15, gen_loss = 0.8660830885936053, disc_loss = 0.05754208500222422
Trained batch 780 in epoch 15, gen_loss = 0.8662674375135981, disc_loss = 0.05755399973113829
Trained batch 781 in epoch 15, gen_loss = 0.866044944814404, disc_loss = 0.057513275090247735
Trained batch 782 in epoch 15, gen_loss = 0.8658720863885502, disc_loss = 0.057481590358095566
Trained batch 783 in epoch 15, gen_loss = 0.8661609250976114, disc_loss = 0.05743618687194278
Trained batch 784 in epoch 15, gen_loss = 0.8665111370147414, disc_loss = 0.05748613155417287
Trained batch 785 in epoch 15, gen_loss = 0.8662602597368886, disc_loss = 0.05748992279093741
Trained batch 786 in epoch 15, gen_loss = 0.8660651336328199, disc_loss = 0.05747278481946721
Trained batch 787 in epoch 15, gen_loss = 0.8661645389904226, disc_loss = 0.05741926999278083
Trained batch 788 in epoch 15, gen_loss = 0.8662862250409048, disc_loss = 0.057427509778140276
Trained batch 789 in epoch 15, gen_loss = 0.8660043935232524, disc_loss = 0.057439574202569794
Testing Epoch 15
Training Epoch 16
Trained batch 0 in epoch 16, gen_loss = 0.8895076513290405, disc_loss = 0.017329270020127296
Trained batch 1 in epoch 16, gen_loss = 0.8515711426734924, disc_loss = 0.016126135364174843
Trained batch 2 in epoch 16, gen_loss = 0.9646310408910116, disc_loss = 0.032604136814673744
Trained batch 3 in epoch 16, gen_loss = 0.8749784678220749, disc_loss = 0.04878285061568022
Trained batch 4 in epoch 16, gen_loss = 0.89913409948349, disc_loss = 0.05596775785088539
Trained batch 5 in epoch 16, gen_loss = 0.842505027850469, disc_loss = 0.06099187768995762
Trained batch 6 in epoch 16, gen_loss = 0.8601004566465106, disc_loss = 0.05342462791928223
Trained batch 7 in epoch 16, gen_loss = 0.8921065777540207, disc_loss = 0.058754096971824765
Trained batch 8 in epoch 16, gen_loss = 0.864768816365136, disc_loss = 0.056314843603306346
Trained batch 9 in epoch 16, gen_loss = 0.8574051260948181, disc_loss = 0.0524560296908021
Trained batch 10 in epoch 16, gen_loss = 0.8624533306468617, disc_loss = 0.04851637094874273
Trained batch 11 in epoch 16, gen_loss = 0.8455260495344797, disc_loss = 0.049599055744086705
Trained batch 12 in epoch 16, gen_loss = 0.8733064394730788, disc_loss = 0.059601024294701904
Trained batch 13 in epoch 16, gen_loss = 0.84761152948652, disc_loss = 0.06453027197026781
Trained batch 14 in epoch 16, gen_loss = 0.8567023118336995, disc_loss = 0.06095531353106101
Trained batch 15 in epoch 16, gen_loss = 0.8621255904436111, disc_loss = 0.06356011581374332
Trained batch 16 in epoch 16, gen_loss = 0.8513819470125086, disc_loss = 0.0643130928168402
Trained batch 17 in epoch 16, gen_loss = 0.8596825069851346, disc_loss = 0.061529633744309344
Trained batch 18 in epoch 16, gen_loss = 0.8731967210769653, disc_loss = 0.06628012877741926
Trained batch 19 in epoch 16, gen_loss = 0.868683522939682, disc_loss = 0.06501649026758968
Trained batch 20 in epoch 16, gen_loss = 0.8580142969176883, disc_loss = 0.06806307396895829
Trained batch 21 in epoch 16, gen_loss = 0.8655678006735715, disc_loss = 0.06601476182483813
Trained batch 22 in epoch 16, gen_loss = 0.8627608625785165, disc_loss = 0.06529870811525894
Trained batch 23 in epoch 16, gen_loss = 0.8656812782088915, disc_loss = 0.063756761723198
Trained batch 24 in epoch 16, gen_loss = 0.8659820652008057, disc_loss = 0.06226012174040079
Trained batch 25 in epoch 16, gen_loss = 0.8713429891146146, disc_loss = 0.06095405399369506
Trained batch 26 in epoch 16, gen_loss = 0.8713136116663615, disc_loss = 0.05913922104432627
Trained batch 27 in epoch 16, gen_loss = 0.8671583852597645, disc_loss = 0.058339817682281137
Trained batch 28 in epoch 16, gen_loss = 0.861344273748069, disc_loss = 0.05764936703931669
Trained batch 29 in epoch 16, gen_loss = 0.864922696352005, disc_loss = 0.05620611282065511
Trained batch 30 in epoch 16, gen_loss = 0.8622825472585617, disc_loss = 0.05690051395926745
Trained batch 31 in epoch 16, gen_loss = 0.8583751115947962, disc_loss = 0.05599823870579712
Trained batch 32 in epoch 16, gen_loss = 0.8506868337139939, disc_loss = 0.05573014121954188
Trained batch 33 in epoch 16, gen_loss = 0.8536192862426534, disc_loss = 0.05448227323701277
Trained batch 34 in epoch 16, gen_loss = 0.8663579446928842, disc_loss = 0.05724790173449686
Trained batch 35 in epoch 16, gen_loss = 0.8592898531092538, disc_loss = 0.057532490877848536
Trained batch 36 in epoch 16, gen_loss = 0.8508574753194242, disc_loss = 0.06029684672987944
Trained batch 37 in epoch 16, gen_loss = 0.8598463582365137, disc_loss = 0.06048520882368872
Trained batch 38 in epoch 16, gen_loss = 0.8599043824733832, disc_loss = 0.06115518445865466
Trained batch 39 in epoch 16, gen_loss = 0.8629730015993118, disc_loss = 0.06071324499789625
Trained batch 40 in epoch 16, gen_loss = 0.8606362764428301, disc_loss = 0.06021542758567304
Trained batch 41 in epoch 16, gen_loss = 0.8569276801177433, disc_loss = 0.060800804290920496
Trained batch 42 in epoch 16, gen_loss = 0.8643326495969018, disc_loss = 0.06520477355306231
Trained batch 43 in epoch 16, gen_loss = 0.8630020821636374, disc_loss = 0.06478113471530378
Trained batch 44 in epoch 16, gen_loss = 0.860913966761695, disc_loss = 0.06436600894149806
Trained batch 45 in epoch 16, gen_loss = 0.8594381588956584, disc_loss = 0.06366914107828685
Trained batch 46 in epoch 16, gen_loss = 0.8569437087850368, disc_loss = 0.06335357760891636
Trained batch 47 in epoch 16, gen_loss = 0.8608869463205338, disc_loss = 0.0638479957706295
Trained batch 48 in epoch 16, gen_loss = 0.8638547902204552, disc_loss = 0.0628742784147664
Trained batch 49 in epoch 16, gen_loss = 0.8641346645355225, disc_loss = 0.06190234998241067
Trained batch 50 in epoch 16, gen_loss = 0.8648943071271858, disc_loss = 0.061206539709340126
Trained batch 51 in epoch 16, gen_loss = 0.8621286807151941, disc_loss = 0.060773649342501394
Trained batch 52 in epoch 16, gen_loss = 0.8610112610852944, disc_loss = 0.060422458053338075
Trained batch 53 in epoch 16, gen_loss = 0.8548468318250444, disc_loss = 0.0611891510758411
Trained batch 54 in epoch 16, gen_loss = 0.8629655892198737, disc_loss = 0.06073198530145667
Trained batch 55 in epoch 16, gen_loss = 0.8644376876098769, disc_loss = 0.06485678623097815
Trained batch 56 in epoch 16, gen_loss = 0.8616458585387782, disc_loss = 0.06443599881114144
Trained batch 57 in epoch 16, gen_loss = 0.8594180181108672, disc_loss = 0.06438907430153983
Trained batch 58 in epoch 16, gen_loss = 0.8599627846378392, disc_loss = 0.06370264716383259
Trained batch 59 in epoch 16, gen_loss = 0.8616089234749477, disc_loss = 0.06287712552584708
Trained batch 60 in epoch 16, gen_loss = 0.8593206347012129, disc_loss = 0.06273831297322864
Trained batch 61 in epoch 16, gen_loss = 0.8590014211593135, disc_loss = 0.06338445942909006
Trained batch 62 in epoch 16, gen_loss = 0.8580093270256406, disc_loss = 0.06292690749147109
Trained batch 63 in epoch 16, gen_loss = 0.8587553976103663, disc_loss = 0.062404731594142504
Trained batch 64 in epoch 16, gen_loss = 0.8601090458723215, disc_loss = 0.06155825684276911
Trained batch 65 in epoch 16, gen_loss = 0.8595743278662363, disc_loss = 0.06083513539510243
Trained batch 66 in epoch 16, gen_loss = 0.8575976695587386, disc_loss = 0.060179293739484316
Trained batch 67 in epoch 16, gen_loss = 0.8558951861718122, disc_loss = 0.059507469893159234
Trained batch 68 in epoch 16, gen_loss = 0.8590532523998315, disc_loss = 0.05902541415306969
Trained batch 69 in epoch 16, gen_loss = 0.8620979513440813, disc_loss = 0.05855146702378988
Trained batch 70 in epoch 16, gen_loss = 0.8632208730133486, disc_loss = 0.05790497504279647
Trained batch 71 in epoch 16, gen_loss = 0.8628279765446981, disc_loss = 0.05761587547345294
Trained batch 72 in epoch 16, gen_loss = 0.8636998036136366, disc_loss = 0.056937398707927904
Trained batch 73 in epoch 16, gen_loss = 0.8658254033810383, disc_loss = 0.05626253131777048
Trained batch 74 in epoch 16, gen_loss = 0.8666357580820719, disc_loss = 0.05647295507291953
Trained batch 75 in epoch 16, gen_loss = 0.8647434711456299, disc_loss = 0.056333439939312245
Trained batch 76 in epoch 16, gen_loss = 0.862062593559166, disc_loss = 0.05626061014444023
Trained batch 77 in epoch 16, gen_loss = 0.8627602756023407, disc_loss = 0.05568213443247936
Trained batch 78 in epoch 16, gen_loss = 0.8612238085722621, disc_loss = 0.05524325700877588
Trained batch 79 in epoch 16, gen_loss = 0.8655494756996631, disc_loss = 0.056335572991520165
Trained batch 80 in epoch 16, gen_loss = 0.8615201277497374, disc_loss = 0.05764344159835651
Trained batch 81 in epoch 16, gen_loss = 0.8628016862927413, disc_loss = 0.057227608815925875
Trained batch 82 in epoch 16, gen_loss = 0.8630595472921808, disc_loss = 0.05678295433880335
Trained batch 83 in epoch 16, gen_loss = 0.8660542489517302, disc_loss = 0.056886184871906324
Trained batch 84 in epoch 16, gen_loss = 0.8673608548500958, disc_loss = 0.05632738789872212
Trained batch 85 in epoch 16, gen_loss = 0.8661163976026136, disc_loss = 0.0560631318299403
Trained batch 86 in epoch 16, gen_loss = 0.8668483235370154, disc_loss = 0.05550690679864465
Trained batch 87 in epoch 16, gen_loss = 0.8663562854582613, disc_loss = 0.055129496544726535
Trained batch 88 in epoch 16, gen_loss = 0.8639224941810865, disc_loss = 0.055193985566454995
Trained batch 89 in epoch 16, gen_loss = 0.864702500237359, disc_loss = 0.055037694377824666
Trained batch 90 in epoch 16, gen_loss = 0.8680344833122505, disc_loss = 0.05472418968309904
Trained batch 91 in epoch 16, gen_loss = 0.8643196426008058, disc_loss = 0.0560206808909045
Trained batch 92 in epoch 16, gen_loss = 0.8686994128329779, disc_loss = 0.05780521891911023
Trained batch 93 in epoch 16, gen_loss = 0.8681687313191434, disc_loss = 0.05743774154936855
Trained batch 94 in epoch 16, gen_loss = 0.8690972710910596, disc_loss = 0.05701008326815147
Trained batch 95 in epoch 16, gen_loss = 0.8707973702500263, disc_loss = 0.05668124963510005
Trained batch 96 in epoch 16, gen_loss = 0.8707577930283301, disc_loss = 0.056285891753919036
Trained batch 97 in epoch 16, gen_loss = 0.8695049729882455, disc_loss = 0.056115285773780575
Trained batch 98 in epoch 16, gen_loss = 0.8705328413934419, disc_loss = 0.05579311221442891
Trained batch 99 in epoch 16, gen_loss = 0.8702569556236267, disc_loss = 0.055834531388245526
Trained batch 100 in epoch 16, gen_loss = 0.8689138842101144, disc_loss = 0.05554525404338642
Trained batch 101 in epoch 16, gen_loss = 0.8672431070430606, disc_loss = 0.05545154679110091
Trained batch 102 in epoch 16, gen_loss = 0.8701032220738606, disc_loss = 0.05550508741379797
Trained batch 103 in epoch 16, gen_loss = 0.871849791934857, disc_loss = 0.05535710099278591
Trained batch 104 in epoch 16, gen_loss = 0.8704033357756479, disc_loss = 0.05559901777388794
Trained batch 105 in epoch 16, gen_loss = 0.8708903598335554, disc_loss = 0.055294071179199614
Trained batch 106 in epoch 16, gen_loss = 0.8699642425385591, disc_loss = 0.05522115717894424
Trained batch 107 in epoch 16, gen_loss = 0.8732374757528305, disc_loss = 0.05513733223132375
Trained batch 108 in epoch 16, gen_loss = 0.87270296440212, disc_loss = 0.054868681522923596
Trained batch 109 in epoch 16, gen_loss = 0.8713466768915002, disc_loss = 0.054772687411274425
Trained batch 110 in epoch 16, gen_loss = 0.8709411363343935, disc_loss = 0.0550824095461484
Trained batch 111 in epoch 16, gen_loss = 0.8716728751148496, disc_loss = 0.054756758747056926
Trained batch 112 in epoch 16, gen_loss = 0.8677520118983446, disc_loss = 0.056093338197014765
Trained batch 113 in epoch 16, gen_loss = 0.8703421019671256, disc_loss = 0.057128665360148274
Trained batch 114 in epoch 16, gen_loss = 0.8714394989220993, disc_loss = 0.05699143699248848
Trained batch 115 in epoch 16, gen_loss = 0.8702686721908635, disc_loss = 0.05714397213887423
Trained batch 116 in epoch 16, gen_loss = 0.8683285998482989, disc_loss = 0.057500507439781204
Trained batch 117 in epoch 16, gen_loss = 0.8691486201043856, disc_loss = 0.057754338841285495
Trained batch 118 in epoch 16, gen_loss = 0.8680736377459615, disc_loss = 0.05765522012737494
Trained batch 119 in epoch 16, gen_loss = 0.8683050105969111, disc_loss = 0.057443257898557934
Trained batch 120 in epoch 16, gen_loss = 0.8671389507853295, disc_loss = 0.057394972313503344
Trained batch 121 in epoch 16, gen_loss = 0.8658273889393103, disc_loss = 0.05725125477985158
Trained batch 122 in epoch 16, gen_loss = 0.8668722156586686, disc_loss = 0.05740115286903531
Trained batch 123 in epoch 16, gen_loss = 0.8675517694604012, disc_loss = 0.05705592364838888
Trained batch 124 in epoch 16, gen_loss = 0.8642847769260407, disc_loss = 0.0578704924993217
Trained batch 125 in epoch 16, gen_loss = 0.8642057532828952, disc_loss = 0.057573349152262955
Trained batch 126 in epoch 16, gen_loss = 0.8651934451474919, disc_loss = 0.05735302908258058
Trained batch 127 in epoch 16, gen_loss = 0.8665232111234218, disc_loss = 0.05731368598571862
Trained batch 128 in epoch 16, gen_loss = 0.8646281165208003, disc_loss = 0.05794592373174175
Trained batch 129 in epoch 16, gen_loss = 0.8647902041673661, disc_loss = 0.057558044382872486
Trained batch 130 in epoch 16, gen_loss = 0.8675279464885479, disc_loss = 0.05750197939261908
Trained batch 131 in epoch 16, gen_loss = 0.8664725569613052, disc_loss = 0.057232063157822595
Trained batch 132 in epoch 16, gen_loss = 0.8644707514379257, disc_loss = 0.05757046558831195
Trained batch 133 in epoch 16, gen_loss = 0.8657465494835554, disc_loss = 0.05751263417664971
Trained batch 134 in epoch 16, gen_loss = 0.8646678507328034, disc_loss = 0.057305556859959056
Trained batch 135 in epoch 16, gen_loss = 0.865378491799621, disc_loss = 0.057046042721006364
Trained batch 136 in epoch 16, gen_loss = 0.8661226632386229, disc_loss = 0.05668650142998047
Trained batch 137 in epoch 16, gen_loss = 0.8667403975690621, disc_loss = 0.05669521599454616
Trained batch 138 in epoch 16, gen_loss = 0.8680792950468955, disc_loss = 0.05671828877676627
Trained batch 139 in epoch 16, gen_loss = 0.8666304049747331, disc_loss = 0.05655631276313215
Trained batch 140 in epoch 16, gen_loss = 0.8656286333046906, disc_loss = 0.0565665626852172
Trained batch 141 in epoch 16, gen_loss = 0.8666766749721178, disc_loss = 0.05631026864038702
Trained batch 142 in epoch 16, gen_loss = 0.8674009156810654, disc_loss = 0.05597366732252124
Trained batch 143 in epoch 16, gen_loss = 0.867717764650782, disc_loss = 0.05567465017278058
Trained batch 144 in epoch 16, gen_loss = 0.8678706352053017, disc_loss = 0.05539994533655458
Trained batch 145 in epoch 16, gen_loss = 0.8672566232207704, disc_loss = 0.05529946105057144
Trained batch 146 in epoch 16, gen_loss = 0.8679757533835716, disc_loss = 0.05502058755365663
Trained batch 147 in epoch 16, gen_loss = 0.8675283461406424, disc_loss = 0.05507257728950699
Trained batch 148 in epoch 16, gen_loss = 0.8693301351678452, disc_loss = 0.05491073813051885
Trained batch 149 in epoch 16, gen_loss = 0.8682885442177455, disc_loss = 0.05496637238500019
Trained batch 150 in epoch 16, gen_loss = 0.869811624288559, disc_loss = 0.054937984532251065
Trained batch 151 in epoch 16, gen_loss = 0.8704009324704346, disc_loss = 0.05481225368260455
Trained batch 152 in epoch 16, gen_loss = 0.8689025408691831, disc_loss = 0.05484729580082048
Trained batch 153 in epoch 16, gen_loss = 0.8708021898161281, disc_loss = 0.05466633294588076
Trained batch 154 in epoch 16, gen_loss = 0.8706583894068195, disc_loss = 0.05437968940804562
Trained batch 155 in epoch 16, gen_loss = 0.871537790275537, disc_loss = 0.054431439213192045
Trained batch 156 in epoch 16, gen_loss = 0.8714555260861755, disc_loss = 0.054412904702672724
Trained batch 157 in epoch 16, gen_loss = 0.8701416384192961, disc_loss = 0.054514076540105136
Trained batch 158 in epoch 16, gen_loss = 0.8709140658003729, disc_loss = 0.05455153435761542
Trained batch 159 in epoch 16, gen_loss = 0.8699912840500474, disc_loss = 0.054442634296719916
Trained batch 160 in epoch 16, gen_loss = 0.8704750587851364, disc_loss = 0.05417256384960705
Trained batch 161 in epoch 16, gen_loss = 0.8715910696321063, disc_loss = 0.05390924754851486
Trained batch 162 in epoch 16, gen_loss = 0.870353505472464, disc_loss = 0.05373333608503082
Trained batch 163 in epoch 16, gen_loss = 0.8703036822560357, disc_loss = 0.05370851060114347
Trained batch 164 in epoch 16, gen_loss = 0.869332909042185, disc_loss = 0.053585531125127366
Trained batch 165 in epoch 16, gen_loss = 0.8695290643407638, disc_loss = 0.05336387405250536
Trained batch 166 in epoch 16, gen_loss = 0.8693072412185326, disc_loss = 0.05309275308244689
Trained batch 167 in epoch 16, gen_loss = 0.8708243648565951, disc_loss = 0.05305696667138753
Trained batch 168 in epoch 16, gen_loss = 0.870098352608596, disc_loss = 0.05312234703616719
Trained batch 169 in epoch 16, gen_loss = 0.8691800652181401, disc_loss = 0.05305767114383771
Trained batch 170 in epoch 16, gen_loss = 0.8698224008780474, disc_loss = 0.053089252844648924
Trained batch 171 in epoch 16, gen_loss = 0.8701963908104009, disc_loss = 0.052851793900413745
Trained batch 172 in epoch 16, gen_loss = 0.8702111711047288, disc_loss = 0.052662861724572546
Trained batch 173 in epoch 16, gen_loss = 0.869398892439645, disc_loss = 0.05256365862910518
Trained batch 174 in epoch 16, gen_loss = 0.8690513179983411, disc_loss = 0.05239018292565431
Trained batch 175 in epoch 16, gen_loss = 0.8695742005312984, disc_loss = 0.05254424288498492
Trained batch 176 in epoch 16, gen_loss = 0.8691543871063298, disc_loss = 0.052494710124502915
Trained batch 177 in epoch 16, gen_loss = 0.8688513926240835, disc_loss = 0.052314695025783745
Trained batch 178 in epoch 16, gen_loss = 0.8694787346783963, disc_loss = 0.052201381455274434
Trained batch 179 in epoch 16, gen_loss = 0.8695607733395364, disc_loss = 0.05198693532858872
Trained batch 180 in epoch 16, gen_loss = 0.871288300054508, disc_loss = 0.052128933007360656
Trained batch 181 in epoch 16, gen_loss = 0.8725040147265235, disc_loss = 0.05194779809635992
Trained batch 182 in epoch 16, gen_loss = 0.8709093744311828, disc_loss = 0.052616281635916785
Trained batch 183 in epoch 16, gen_loss = 0.8699076834904111, disc_loss = 0.0528371221988219
Trained batch 184 in epoch 16, gen_loss = 0.8697474581164283, disc_loss = 0.05303024726894659
Trained batch 185 in epoch 16, gen_loss = 0.8697170302752526, disc_loss = 0.05290113126869083
Trained batch 186 in epoch 16, gen_loss = 0.868636888775596, disc_loss = 0.052865057444090355
Trained batch 187 in epoch 16, gen_loss = 0.8681458699259352, disc_loss = 0.05278890930423315
Trained batch 188 in epoch 16, gen_loss = 0.8703426508991806, disc_loss = 0.05308599346046331
Trained batch 189 in epoch 16, gen_loss = 0.8689137557619496, disc_loss = 0.05315909383475388
Trained batch 190 in epoch 16, gen_loss = 0.8705966065379338, disc_loss = 0.05298893695638676
Trained batch 191 in epoch 16, gen_loss = 0.8714802611308793, disc_loss = 0.05298522227046002
Trained batch 192 in epoch 16, gen_loss = 0.8707047767280914, disc_loss = 0.0528963564489751
Trained batch 193 in epoch 16, gen_loss = 0.869387326934903, disc_loss = 0.05307682979727145
Trained batch 194 in epoch 16, gen_loss = 0.8700202484925588, disc_loss = 0.05329541792997565
Trained batch 195 in epoch 16, gen_loss = 0.8696427331591139, disc_loss = 0.05314604954898586
Trained batch 196 in epoch 16, gen_loss = 0.8702858297655425, disc_loss = 0.05292884980181828
Trained batch 197 in epoch 16, gen_loss = 0.8711522105667326, disc_loss = 0.052838900034795654
Trained batch 198 in epoch 16, gen_loss = 0.8704293605370738, disc_loss = 0.05279234578907864
Trained batch 199 in epoch 16, gen_loss = 0.8695442394912243, disc_loss = 0.05280291629256681
Trained batch 200 in epoch 16, gen_loss = 0.8701501344863455, disc_loss = 0.053336665898431744
Trained batch 201 in epoch 16, gen_loss = 0.8683890034951786, disc_loss = 0.053688113764389464
Trained batch 202 in epoch 16, gen_loss = 0.8677308954335199, disc_loss = 0.053627694321548555
Trained batch 203 in epoch 16, gen_loss = 0.8671908158005452, disc_loss = 0.05356018313928051
Trained batch 204 in epoch 16, gen_loss = 0.8689292653304774, disc_loss = 0.05380587678902397
Trained batch 205 in epoch 16, gen_loss = 0.8683791451373146, disc_loss = 0.05376880047435972
Trained batch 206 in epoch 16, gen_loss = 0.867582665981302, disc_loss = 0.05382366556953189
Trained batch 207 in epoch 16, gen_loss = 0.8680593799799681, disc_loss = 0.053622177795310005
Trained batch 208 in epoch 16, gen_loss = 0.8685027812941793, disc_loss = 0.05342805362195133
Trained batch 209 in epoch 16, gen_loss = 0.8682510791789918, disc_loss = 0.05338382632028134
Trained batch 210 in epoch 16, gen_loss = 0.8688188623195576, disc_loss = 0.05337499908140697
Trained batch 211 in epoch 16, gen_loss = 0.8695442177495867, disc_loss = 0.05318060467010891
Trained batch 212 in epoch 16, gen_loss = 0.8685005887853148, disc_loss = 0.05361438216204305
Trained batch 213 in epoch 16, gen_loss = 0.8686007479919451, disc_loss = 0.053466960393919426
Trained batch 214 in epoch 16, gen_loss = 0.8697038491104925, disc_loss = 0.05329555501554941
Trained batch 215 in epoch 16, gen_loss = 0.8698079283866618, disc_loss = 0.05312978470034001
Trained batch 216 in epoch 16, gen_loss = 0.8711960036908427, disc_loss = 0.053258940274934476
Trained batch 217 in epoch 16, gen_loss = 0.8705543144307005, disc_loss = 0.053425183919164426
Trained batch 218 in epoch 16, gen_loss = 0.8688486055152057, disc_loss = 0.054108081927701626
Trained batch 219 in epoch 16, gen_loss = 0.8702424068342556, disc_loss = 0.054883665157566694
Trained batch 220 in epoch 16, gen_loss = 0.8709226887150587, disc_loss = 0.05484741889741019
Trained batch 221 in epoch 16, gen_loss = 0.8696428736050924, disc_loss = 0.05561764918158653
Trained batch 222 in epoch 16, gen_loss = 0.8699901718729814, disc_loss = 0.05548828527657106
Trained batch 223 in epoch 16, gen_loss = 0.8702362874256713, disc_loss = 0.055817826665588655
Trained batch 224 in epoch 16, gen_loss = 0.8693579252560933, disc_loss = 0.05589448228271471
Trained batch 225 in epoch 16, gen_loss = 0.8686435051196444, disc_loss = 0.056287146393885525
Trained batch 226 in epoch 16, gen_loss = 0.8683347069219346, disc_loss = 0.056262598145293635
Trained batch 227 in epoch 16, gen_loss = 0.8673906172053856, disc_loss = 0.05631275721539727
Trained batch 228 in epoch 16, gen_loss = 0.8667342649797165, disc_loss = 0.05622491847081151
Trained batch 229 in epoch 16, gen_loss = 0.8663882532845373, disc_loss = 0.05609343787857696
Trained batch 230 in epoch 16, gen_loss = 0.8668676323188848, disc_loss = 0.05609357847884555
Trained batch 231 in epoch 16, gen_loss = 0.8665276267405214, disc_loss = 0.05590815302827556
Trained batch 232 in epoch 16, gen_loss = 0.8676867331558031, disc_loss = 0.05591179548998567
Trained batch 233 in epoch 16, gen_loss = 0.8669793396933466, disc_loss = 0.05579134168572979
Trained batch 234 in epoch 16, gen_loss = 0.8659438364049221, disc_loss = 0.056123923647039116
Trained batch 235 in epoch 16, gen_loss = 0.866139549320027, disc_loss = 0.05596009406884658
Trained batch 236 in epoch 16, gen_loss = 0.8674719746102764, disc_loss = 0.05637971986328814
Trained batch 237 in epoch 16, gen_loss = 0.8678607660181382, disc_loss = 0.056191843791528286
Trained batch 238 in epoch 16, gen_loss = 0.8665958024467884, disc_loss = 0.05661763182829551
Trained batch 239 in epoch 16, gen_loss = 0.8669763979812463, disc_loss = 0.056537198327714575
Trained batch 240 in epoch 16, gen_loss = 0.8677193255345357, disc_loss = 0.05653874892007204
Trained batch 241 in epoch 16, gen_loss = 0.8670134502501528, disc_loss = 0.056653169659158786
Trained batch 242 in epoch 16, gen_loss = 0.8669401601018238, disc_loss = 0.05652807527815793
Trained batch 243 in epoch 16, gen_loss = 0.8664511239430943, disc_loss = 0.05646078805171992
Trained batch 244 in epoch 16, gen_loss = 0.8670386978558131, disc_loss = 0.05627466708763826
Trained batch 245 in epoch 16, gen_loss = 0.8678907773843626, disc_loss = 0.05638082953344092
Trained batch 246 in epoch 16, gen_loss = 0.8679883902372136, disc_loss = 0.05618692300120286
Trained batch 247 in epoch 16, gen_loss = 0.8672757687107209, disc_loss = 0.05619863981583847
Trained batch 248 in epoch 16, gen_loss = 0.8669688538853902, disc_loss = 0.05606174030449675
Trained batch 249 in epoch 16, gen_loss = 0.8672460527420044, disc_loss = 0.056094645900651816
Trained batch 250 in epoch 16, gen_loss = 0.8676068645074548, disc_loss = 0.05594252862325643
Trained batch 251 in epoch 16, gen_loss = 0.867764746149381, disc_loss = 0.05590512951473809
Trained batch 252 in epoch 16, gen_loss = 0.8668248321227876, disc_loss = 0.05622889253719463
Trained batch 253 in epoch 16, gen_loss = 0.8673034427672859, disc_loss = 0.0561318376310551
Trained batch 254 in epoch 16, gen_loss = 0.8679594021217496, disc_loss = 0.05600057493201366
Trained batch 255 in epoch 16, gen_loss = 0.8681379635818303, disc_loss = 0.055903623635458644
Trained batch 256 in epoch 16, gen_loss = 0.8676117964755701, disc_loss = 0.05591895360072009
Trained batch 257 in epoch 16, gen_loss = 0.8675492325032405, disc_loss = 0.055744185782030456
Trained batch 258 in epoch 16, gen_loss = 0.8687867775386825, disc_loss = 0.055618221377126846
Trained batch 259 in epoch 16, gen_loss = 0.8683478153668918, disc_loss = 0.05551667535641732
Trained batch 260 in epoch 16, gen_loss = 0.8691039514724322, disc_loss = 0.05537431914594838
Trained batch 261 in epoch 16, gen_loss = 0.8692299939748895, disc_loss = 0.05525536778852173
Trained batch 262 in epoch 16, gen_loss = 0.8700277925444193, disc_loss = 0.05508141102935028
Trained batch 263 in epoch 16, gen_loss = 0.8697675956469594, disc_loss = 0.054970596805849876
Trained batch 264 in epoch 16, gen_loss = 0.8696556448936462, disc_loss = 0.054813786337749575
Trained batch 265 in epoch 16, gen_loss = 0.869938380960235, disc_loss = 0.055317149695387126
Trained batch 266 in epoch 16, gen_loss = 0.8688310882571931, disc_loss = 0.05548888641106111
Trained batch 267 in epoch 16, gen_loss = 0.8688776413006569, disc_loss = 0.055317773718261784
Trained batch 268 in epoch 16, gen_loss = 0.8684206002263775, disc_loss = 0.05519039997983322
Trained batch 269 in epoch 16, gen_loss = 0.8686467455493079, disc_loss = 0.0550589968536601
Trained batch 270 in epoch 16, gen_loss = 0.8681221714318899, disc_loss = 0.05500761031025395
Trained batch 271 in epoch 16, gen_loss = 0.8677087726400179, disc_loss = 0.05492862274781253
Trained batch 272 in epoch 16, gen_loss = 0.8686669626078762, disc_loss = 0.05500264331227639
Trained batch 273 in epoch 16, gen_loss = 0.8680124232803819, disc_loss = 0.055076694746508545
Trained batch 274 in epoch 16, gen_loss = 0.868013548634269, disc_loss = 0.05496086882427335
Trained batch 275 in epoch 16, gen_loss = 0.868677033678345, disc_loss = 0.05488556359415415
Trained batch 276 in epoch 16, gen_loss = 0.8683535966632169, disc_loss = 0.054792556082930696
Trained batch 277 in epoch 16, gen_loss = 0.8690869808197021, disc_loss = 0.054640704221527676
Trained batch 278 in epoch 16, gen_loss = 0.8693225695668155, disc_loss = 0.05456118136610982
Trained batch 279 in epoch 16, gen_loss = 0.8685932832104819, disc_loss = 0.05450414778897539
Trained batch 280 in epoch 16, gen_loss = 0.8682593563273284, disc_loss = 0.054467833264535324
Trained batch 281 in epoch 16, gen_loss = 0.8694650376519413, disc_loss = 0.05435878157133488
Trained batch 282 in epoch 16, gen_loss = 0.8703410509618348, disc_loss = 0.05424774863161542
Trained batch 283 in epoch 16, gen_loss = 0.870082459399398, disc_loss = 0.05413559174106102
Trained batch 284 in epoch 16, gen_loss = 0.8702269899217706, disc_loss = 0.05399526664333647
Trained batch 285 in epoch 16, gen_loss = 0.8695542201712415, disc_loss = 0.054151850024733196
Trained batch 286 in epoch 16, gen_loss = 0.8696511188450591, disc_loss = 0.05400911258624458
Trained batch 287 in epoch 16, gen_loss = 0.870215650026997, disc_loss = 0.054114193702439986
Trained batch 288 in epoch 16, gen_loss = 0.871101492210243, disc_loss = 0.05395978045485476
Trained batch 289 in epoch 16, gen_loss = 0.8706466615200043, disc_loss = 0.05392078891685553
Trained batch 290 in epoch 16, gen_loss = 0.870742230071235, disc_loss = 0.053773632613922824
Trained batch 291 in epoch 16, gen_loss = 0.8719374431322698, disc_loss = 0.05377617052418167
Trained batch 292 in epoch 16, gen_loss = 0.8725106366258433, disc_loss = 0.053627844443767246
Trained batch 293 in epoch 16, gen_loss = 0.8729425719400652, disc_loss = 0.053555237612414625
Trained batch 294 in epoch 16, gen_loss = 0.8740798717838223, disc_loss = 0.053434509741363385
Trained batch 295 in epoch 16, gen_loss = 0.8737917131668812, disc_loss = 0.05338639277190826
Trained batch 296 in epoch 16, gen_loss = 0.8735662217092033, disc_loss = 0.05327496134679175
Trained batch 297 in epoch 16, gen_loss = 0.8741574967467545, disc_loss = 0.05313376426828038
Trained batch 298 in epoch 16, gen_loss = 0.8746355564697929, disc_loss = 0.05316358768103962
Trained batch 299 in epoch 16, gen_loss = 0.8747831153869629, disc_loss = 0.05301071462066223
Trained batch 300 in epoch 16, gen_loss = 0.875037112703355, disc_loss = 0.052909499066773544
Trained batch 301 in epoch 16, gen_loss = 0.8745592066783778, disc_loss = 0.05287808369974674
Trained batch 302 in epoch 16, gen_loss = 0.8739076455434164, disc_loss = 0.0528733607261709
Trained batch 303 in epoch 16, gen_loss = 0.8741284071614868, disc_loss = 0.052957193155491133
Trained batch 304 in epoch 16, gen_loss = 0.8744445546728665, disc_loss = 0.05284321162330567
Trained batch 305 in epoch 16, gen_loss = 0.874910332019033, disc_loss = 0.052698144891597576
Trained batch 306 in epoch 16, gen_loss = 0.8758444824902165, disc_loss = 0.05260215059122987
Trained batch 307 in epoch 16, gen_loss = 0.8755888118372335, disc_loss = 0.052516445252959704
Trained batch 308 in epoch 16, gen_loss = 0.8760084885995365, disc_loss = 0.05237617887538469
Trained batch 309 in epoch 16, gen_loss = 0.8764611478774779, disc_loss = 0.05223246234348945
Trained batch 310 in epoch 16, gen_loss = 0.8762321196185048, disc_loss = 0.052198581189408275
Trained batch 311 in epoch 16, gen_loss = 0.8768507226919516, disc_loss = 0.0520636302117521
Trained batch 312 in epoch 16, gen_loss = 0.8778446307197546, disc_loss = 0.05253879358016026
Trained batch 313 in epoch 16, gen_loss = 0.8775802858316215, disc_loss = 0.0524922778969334
Trained batch 314 in epoch 16, gen_loss = 0.8764078278390188, disc_loss = 0.05329011714026805
Trained batch 315 in epoch 16, gen_loss = 0.8762881755828857, disc_loss = 0.05320256241579552
Trained batch 316 in epoch 16, gen_loss = 0.8763683524793631, disc_loss = 0.053472731913196084
Trained batch 317 in epoch 16, gen_loss = 0.876681627342536, disc_loss = 0.0534627706488981
Trained batch 318 in epoch 16, gen_loss = 0.8766855666629947, disc_loss = 0.05335765337092703
Trained batch 319 in epoch 16, gen_loss = 0.8767230682075023, disc_loss = 0.05330014974315418
Trained batch 320 in epoch 16, gen_loss = 0.8764467165106182, disc_loss = 0.053283170786776184
Trained batch 321 in epoch 16, gen_loss = 0.8772087626575683, disc_loss = 0.0531592764645838
Trained batch 322 in epoch 16, gen_loss = 0.8767000316835409, disc_loss = 0.05309955021597145
Trained batch 323 in epoch 16, gen_loss = 0.8770939518272141, disc_loss = 0.053008902612441205
Trained batch 324 in epoch 16, gen_loss = 0.8773294369991009, disc_loss = 0.053012778107076886
Trained batch 325 in epoch 16, gen_loss = 0.876951328267349, disc_loss = 0.052928387760213275
Trained batch 326 in epoch 16, gen_loss = 0.8767085972182248, disc_loss = 0.052876236192050424
Trained batch 327 in epoch 16, gen_loss = 0.8769682096998866, disc_loss = 0.05274905409896746
Trained batch 328 in epoch 16, gen_loss = 0.8772732642646256, disc_loss = 0.05264411005120736
Trained batch 329 in epoch 16, gen_loss = 0.8782976457566926, disc_loss = 0.05261351492284148
Trained batch 330 in epoch 16, gen_loss = 0.8786724978703386, disc_loss = 0.05258098358479736
Trained batch 331 in epoch 16, gen_loss = 0.8787680562720241, disc_loss = 0.05247415307241615
Trained batch 332 in epoch 16, gen_loss = 0.8778599509605775, disc_loss = 0.05275992585021678
Trained batch 333 in epoch 16, gen_loss = 0.8777337579313153, disc_loss = 0.0526292003024771
Trained batch 334 in epoch 16, gen_loss = 0.8782909726029011, disc_loss = 0.0525520590217367
Trained batch 335 in epoch 16, gen_loss = 0.8791112536120982, disc_loss = 0.05269029050915768
Trained batch 336 in epoch 16, gen_loss = 0.8786939440919667, disc_loss = 0.05259661959727414
Trained batch 337 in epoch 16, gen_loss = 0.8777409843086491, disc_loss = 0.05269089572203274
Trained batch 338 in epoch 16, gen_loss = 0.8782396029933716, disc_loss = 0.05262910873164865
Trained batch 339 in epoch 16, gen_loss = 0.8780865222215652, disc_loss = 0.0525220603641013
Trained batch 340 in epoch 16, gen_loss = 0.8779357816816425, disc_loss = 0.0523891046785277
Trained batch 341 in epoch 16, gen_loss = 0.8780635785289675, disc_loss = 0.05234578830783653
Trained batch 342 in epoch 16, gen_loss = 0.8775725559312471, disc_loss = 0.05231558315933793
Trained batch 343 in epoch 16, gen_loss = 0.8774245845717054, disc_loss = 0.0521996145239533
Trained batch 344 in epoch 16, gen_loss = 0.8777795969576075, disc_loss = 0.05236576690568008
Trained batch 345 in epoch 16, gen_loss = 0.8772407296420521, disc_loss = 0.05230856135304522
Trained batch 346 in epoch 16, gen_loss = 0.8775438023918988, disc_loss = 0.05218732966008121
Trained batch 347 in epoch 16, gen_loss = 0.877015870364233, disc_loss = 0.05211937066499443
Trained batch 348 in epoch 16, gen_loss = 0.8776818546319759, disc_loss = 0.052103036718395
Trained batch 349 in epoch 16, gen_loss = 0.8782213716847556, disc_loss = 0.05198836273114596
Trained batch 350 in epoch 16, gen_loss = 0.8788292416480192, disc_loss = 0.05187427692720269
Trained batch 351 in epoch 16, gen_loss = 0.8780614752322435, disc_loss = 0.052235335500551046
Trained batch 352 in epoch 16, gen_loss = 0.8777406235929927, disc_loss = 0.05222879022771424
Trained batch 353 in epoch 16, gen_loss = 0.8786793694657794, disc_loss = 0.052547494125799774
Trained batch 354 in epoch 16, gen_loss = 0.8797984173600103, disc_loss = 0.052522776294237294
Trained batch 355 in epoch 16, gen_loss = 0.8789910915192594, disc_loss = 0.05269867552998947
Trained batch 356 in epoch 16, gen_loss = 0.8787163504365445, disc_loss = 0.05268557347534668
Trained batch 357 in epoch 16, gen_loss = 0.8787294378160765, disc_loss = 0.05258834464787688
Trained batch 358 in epoch 16, gen_loss = 0.8786120921124323, disc_loss = 0.05248098288374774
Trained batch 359 in epoch 16, gen_loss = 0.8789902933769755, disc_loss = 0.052360454581988354
Trained batch 360 in epoch 16, gen_loss = 0.8791750991443518, disc_loss = 0.052239496353755695
Trained batch 361 in epoch 16, gen_loss = 0.8796988473742048, disc_loss = 0.05212730580416009
Trained batch 362 in epoch 16, gen_loss = 0.8797705634894778, disc_loss = 0.05203971634144297
Trained batch 363 in epoch 16, gen_loss = 0.8792809527981412, disc_loss = 0.052069259623249806
Trained batch 364 in epoch 16, gen_loss = 0.8785792515702444, disc_loss = 0.0520990253311314
Trained batch 365 in epoch 16, gen_loss = 0.8786827076653965, disc_loss = 0.05197902770631545
Trained batch 366 in epoch 16, gen_loss = 0.8794215646361785, disc_loss = 0.05189175856850371
Trained batch 367 in epoch 16, gen_loss = 0.8799747949385125, disc_loss = 0.051812630721226174
Trained batch 368 in epoch 16, gen_loss = 0.8804060713385502, disc_loss = 0.051709382007337684
Trained batch 369 in epoch 16, gen_loss = 0.8802383269812609, disc_loss = 0.05163799904639254
Trained batch 370 in epoch 16, gen_loss = 0.8807625650074282, disc_loss = 0.05169253784038548
Trained batch 371 in epoch 16, gen_loss = 0.8801321134131442, disc_loss = 0.05177369859740539
Trained batch 372 in epoch 16, gen_loss = 0.8795700344898746, disc_loss = 0.05172529674557115
Trained batch 373 in epoch 16, gen_loss = 0.879702121816217, disc_loss = 0.05172322091601669
Trained batch 374 in epoch 16, gen_loss = 0.8800428762435913, disc_loss = 0.05161994488040606
Trained batch 375 in epoch 16, gen_loss = 0.8799389984379423, disc_loss = 0.051594701288466126
Trained batch 376 in epoch 16, gen_loss = 0.8796602084402696, disc_loss = 0.051524800567119444
Trained batch 377 in epoch 16, gen_loss = 0.879017734496051, disc_loss = 0.05157400231571898
Trained batch 378 in epoch 16, gen_loss = 0.8788152777425218, disc_loss = 0.0515474786239831
Trained batch 379 in epoch 16, gen_loss = 0.8792413239416323, disc_loss = 0.051431938840419446
Trained batch 380 in epoch 16, gen_loss = 0.879118747129215, disc_loss = 0.051320697932584786
Trained batch 381 in epoch 16, gen_loss = 0.8794615885038026, disc_loss = 0.05142753109633338
Trained batch 382 in epoch 16, gen_loss = 0.8786975441028804, disc_loss = 0.05154524761672781
Trained batch 383 in epoch 16, gen_loss = 0.8779108985327184, disc_loss = 0.05162310385518746
Trained batch 384 in epoch 16, gen_loss = 0.877762741392309, disc_loss = 0.05168740674490472
Trained batch 385 in epoch 16, gen_loss = 0.8783562685232706, disc_loss = 0.05188178624885417
Trained batch 386 in epoch 16, gen_loss = 0.878098850410422, disc_loss = 0.05181572422293768
Trained batch 387 in epoch 16, gen_loss = 0.8776754763015767, disc_loss = 0.051789983162493204
Trained batch 388 in epoch 16, gen_loss = 0.8774755885178142, disc_loss = 0.05170756335798794
Trained batch 389 in epoch 16, gen_loss = 0.8784033617912195, disc_loss = 0.05165778773550231
Trained batch 390 in epoch 16, gen_loss = 0.8783380596534066, disc_loss = 0.05157443504337498
Trained batch 391 in epoch 16, gen_loss = 0.8785346404326205, disc_loss = 0.05174898976407831
Trained batch 392 in epoch 16, gen_loss = 0.8780344905137409, disc_loss = 0.0517241876375679
Trained batch 393 in epoch 16, gen_loss = 0.8779137287345634, disc_loss = 0.05163844071238817
Trained batch 394 in epoch 16, gen_loss = 0.8777178741708587, disc_loss = 0.05162549653220214
Trained batch 395 in epoch 16, gen_loss = 0.8785170586121203, disc_loss = 0.05153270355882029
Trained batch 396 in epoch 16, gen_loss = 0.8786415053855262, disc_loss = 0.051434610410821
Trained batch 397 in epoch 16, gen_loss = 0.8792037125208869, disc_loss = 0.0513427626942963
Trained batch 398 in epoch 16, gen_loss = 0.8791457153203195, disc_loss = 0.051280521287029625
Trained batch 399 in epoch 16, gen_loss = 0.8784494844079017, disc_loss = 0.05146477667731233
Trained batch 400 in epoch 16, gen_loss = 0.8781527702945129, disc_loss = 0.0514202999181005
Trained batch 401 in epoch 16, gen_loss = 0.8783644842567728, disc_loss = 0.05134057289855879
Trained batch 402 in epoch 16, gen_loss = 0.8787696436971943, disc_loss = 0.0515676205041853
Trained batch 403 in epoch 16, gen_loss = 0.8781465762617564, disc_loss = 0.05179013362693794
Trained batch 404 in epoch 16, gen_loss = 0.8777576403853334, disc_loss = 0.05189927504685374
Trained batch 405 in epoch 16, gen_loss = 0.8777029476142282, disc_loss = 0.05190251611764979
Trained batch 406 in epoch 16, gen_loss = 0.8777986480797245, disc_loss = 0.051952525095771585
Trained batch 407 in epoch 16, gen_loss = 0.8772056121744362, disc_loss = 0.051972946554979346
Trained batch 408 in epoch 16, gen_loss = 0.8774414480752641, disc_loss = 0.05197522051582309
Trained batch 409 in epoch 16, gen_loss = 0.877105508054175, disc_loss = 0.052001421118336846
Trained batch 410 in epoch 16, gen_loss = 0.8765660609932131, disc_loss = 0.052013990382036225
Trained batch 411 in epoch 16, gen_loss = 0.8763267630801618, disc_loss = 0.052041498185768365
Trained batch 412 in epoch 16, gen_loss = 0.8767846578835864, disc_loss = 0.052220689526310336
Trained batch 413 in epoch 16, gen_loss = 0.8775789543338444, disc_loss = 0.05218962512590927
Trained batch 414 in epoch 16, gen_loss = 0.8776685831058456, disc_loss = 0.05211457782144468
Trained batch 415 in epoch 16, gen_loss = 0.8770289438275191, disc_loss = 0.05218429289995514
Trained batch 416 in epoch 16, gen_loss = 0.8769569689993092, disc_loss = 0.052113928585324425
Trained batch 417 in epoch 16, gen_loss = 0.8774910014497036, disc_loss = 0.05251606577521627
Trained batch 418 in epoch 16, gen_loss = 0.8774278337460429, disc_loss = 0.05244703182443834
Trained batch 419 in epoch 16, gen_loss = 0.8768401040917351, disc_loss = 0.052636037807955983
Trained batch 420 in epoch 16, gen_loss = 0.8779944628831043, disc_loss = 0.05263972743978445
Trained batch 421 in epoch 16, gen_loss = 0.8782954176455312, disc_loss = 0.05263210535248062
Trained batch 422 in epoch 16, gen_loss = 0.8780037249233705, disc_loss = 0.052552612010724226
Trained batch 423 in epoch 16, gen_loss = 0.876964586101613, disc_loss = 0.05258407988607497
Trained batch 424 in epoch 16, gen_loss = 0.8766677790529588, disc_loss = 0.05250443378025118
Trained batch 425 in epoch 16, gen_loss = 0.8766402723923535, disc_loss = 0.052408976219113515
Trained batch 426 in epoch 16, gen_loss = 0.87650408077575, disc_loss = 0.052343444860555595
Trained batch 427 in epoch 16, gen_loss = 0.8768619684693969, disc_loss = 0.0522464765355461
Trained batch 428 in epoch 16, gen_loss = 0.8769610011494243, disc_loss = 0.052154980038698666
Trained batch 429 in epoch 16, gen_loss = 0.8771868378617043, disc_loss = 0.05215462878844592
Trained batch 430 in epoch 16, gen_loss = 0.8773164602554038, disc_loss = 0.05206097637707251
Trained batch 431 in epoch 16, gen_loss = 0.8764445238091327, disc_loss = 0.052299245945134853
Trained batch 432 in epoch 16, gen_loss = 0.8772391526858746, disc_loss = 0.052243529058622916
Trained batch 433 in epoch 16, gen_loss = 0.8777479040457906, disc_loss = 0.052444785759325055
Trained batch 434 in epoch 16, gen_loss = 0.8774546987708958, disc_loss = 0.052446627286102235
Trained batch 435 in epoch 16, gen_loss = 0.8770753142483737, disc_loss = 0.05246674533775333
Trained batch 436 in epoch 16, gen_loss = 0.8777464603668492, disc_loss = 0.052462321818002776
Trained batch 437 in epoch 16, gen_loss = 0.8774571548041687, disc_loss = 0.05244696130401978
Trained batch 438 in epoch 16, gen_loss = 0.8775106858555439, disc_loss = 0.05236706250837255
Trained batch 439 in epoch 16, gen_loss = 0.877618720992045, disc_loss = 0.052281585785517976
Trained batch 440 in epoch 16, gen_loss = 0.877868331073363, disc_loss = 0.052510456240138295
Trained batch 441 in epoch 16, gen_loss = 0.8776549788621756, disc_loss = 0.052432048763464544
Trained batch 442 in epoch 16, gen_loss = 0.876851259585697, disc_loss = 0.052760586362231195
Trained batch 443 in epoch 16, gen_loss = 0.8769785615506472, disc_loss = 0.05284249426918692
Trained batch 444 in epoch 16, gen_loss = 0.8766168729642804, disc_loss = 0.0528071521467456
Trained batch 445 in epoch 16, gen_loss = 0.877065078693655, disc_loss = 0.05295489736072585
Trained batch 446 in epoch 16, gen_loss = 0.8764333056923527, disc_loss = 0.0531044889010189
Trained batch 447 in epoch 16, gen_loss = 0.8755284427399082, disc_loss = 0.05338801060341731
Trained batch 448 in epoch 16, gen_loss = 0.8757183447579764, disc_loss = 0.05333603567698916
Trained batch 449 in epoch 16, gen_loss = 0.8767058628797532, disc_loss = 0.05365720733275844
Trained batch 450 in epoch 16, gen_loss = 0.8766158287250282, disc_loss = 0.05360350895057662
Trained batch 451 in epoch 16, gen_loss = 0.8766450297120398, disc_loss = 0.05350180791662099
Trained batch 452 in epoch 16, gen_loss = 0.8766725358715647, disc_loss = 0.05340586642880675
Trained batch 453 in epoch 16, gen_loss = 0.876206290682507, disc_loss = 0.053457540372747615
Trained batch 454 in epoch 16, gen_loss = 0.8763690047866696, disc_loss = 0.053576540299128374
Trained batch 455 in epoch 16, gen_loss = 0.876125656133681, disc_loss = 0.053511485211314276
Trained batch 456 in epoch 16, gen_loss = 0.8758914246992157, disc_loss = 0.05352242456349652
Trained batch 457 in epoch 16, gen_loss = 0.8758600930069211, disc_loss = 0.05346064495561262
Trained batch 458 in epoch 16, gen_loss = 0.8763207270558883, disc_loss = 0.05338813214256451
Trained batch 459 in epoch 16, gen_loss = 0.8759199557744939, disc_loss = 0.05348893686541883
Trained batch 460 in epoch 16, gen_loss = 0.8763204407666096, disc_loss = 0.05350278194997775
Trained batch 461 in epoch 16, gen_loss = 0.8763240602238354, disc_loss = 0.05347916948230074
Trained batch 462 in epoch 16, gen_loss = 0.876080225340491, disc_loss = 0.053464944230002344
Trained batch 463 in epoch 16, gen_loss = 0.8758665367575555, disc_loss = 0.053430390567318055
Trained batch 464 in epoch 16, gen_loss = 0.8760452009657378, disc_loss = 0.05340382419025866
Trained batch 465 in epoch 16, gen_loss = 0.8764489613505392, disc_loss = 0.05346520285745643
Trained batch 466 in epoch 16, gen_loss = 0.8761592376538466, disc_loss = 0.05367735716588077
Trained batch 467 in epoch 16, gen_loss = 0.875880632454004, disc_loss = 0.053742530436302796
Trained batch 468 in epoch 16, gen_loss = 0.876409988985387, disc_loss = 0.05415043580248507
Trained batch 469 in epoch 16, gen_loss = 0.8757118314504624, disc_loss = 0.05454061769167001
Trained batch 470 in epoch 16, gen_loss = 0.8751094235609544, disc_loss = 0.05462076556779871
Trained batch 471 in epoch 16, gen_loss = 0.8751086340743607, disc_loss = 0.05455369107579118
Trained batch 472 in epoch 16, gen_loss = 0.8754730530193442, disc_loss = 0.05473105407696036
Trained batch 473 in epoch 16, gen_loss = 0.8755616741215629, disc_loss = 0.05466219554812439
Trained batch 474 in epoch 16, gen_loss = 0.8750336203449651, disc_loss = 0.05468390671732394
Trained batch 475 in epoch 16, gen_loss = 0.8747927346775511, disc_loss = 0.054786744456104305
Trained batch 476 in epoch 16, gen_loss = 0.8747132362434699, disc_loss = 0.054751006920531045
Trained batch 477 in epoch 16, gen_loss = 0.8747655238691234, disc_loss = 0.05494536186576233
Trained batch 478 in epoch 16, gen_loss = 0.8748676227502883, disc_loss = 0.05496301291907101
Trained batch 479 in epoch 16, gen_loss = 0.8745738973841071, disc_loss = 0.055113775064819494
Trained batch 480 in epoch 16, gen_loss = 0.8741560743777024, disc_loss = 0.055137951723774295
Trained batch 481 in epoch 16, gen_loss = 0.8746070187245167, disc_loss = 0.05507498081769655
Trained batch 482 in epoch 16, gen_loss = 0.8748903277621259, disc_loss = 0.055106587772591205
Trained batch 483 in epoch 16, gen_loss = 0.8752113578856484, disc_loss = 0.05501682521325097
Trained batch 484 in epoch 16, gen_loss = 0.8748580165130576, disc_loss = 0.0550954283887194
Trained batch 485 in epoch 16, gen_loss = 0.8747090956679097, disc_loss = 0.05503320380366971
Trained batch 486 in epoch 16, gen_loss = 0.8748141883947032, disc_loss = 0.054941803212153285
Trained batch 487 in epoch 16, gen_loss = 0.8748996716420181, disc_loss = 0.05486376553327303
Trained batch 488 in epoch 16, gen_loss = 0.875103502856198, disc_loss = 0.05485984316126183
Trained batch 489 in epoch 16, gen_loss = 0.8745806958602399, disc_loss = 0.05501184933628811
Trained batch 490 in epoch 16, gen_loss = 0.8746681739623581, disc_loss = 0.05499996448527498
Trained batch 491 in epoch 16, gen_loss = 0.8746454104538856, disc_loss = 0.054948993011120315
Trained batch 492 in epoch 16, gen_loss = 0.8744866020418326, disc_loss = 0.054924208994833926
Trained batch 493 in epoch 16, gen_loss = 0.8746228024423847, disc_loss = 0.05487948263852069
Trained batch 494 in epoch 16, gen_loss = 0.8746224416024757, disc_loss = 0.054831947287488164
Trained batch 495 in epoch 16, gen_loss = 0.8747205648330911, disc_loss = 0.05474289430722204
Trained batch 496 in epoch 16, gen_loss = 0.8740449954926128, disc_loss = 0.05489176864711422
Trained batch 497 in epoch 16, gen_loss = 0.8744676817492788, disc_loss = 0.05540474644024299
Trained batch 498 in epoch 16, gen_loss = 0.8742826384509016, disc_loss = 0.05566174561486305
Trained batch 499 in epoch 16, gen_loss = 0.8741358473896981, disc_loss = 0.05567168381717056
Trained batch 500 in epoch 16, gen_loss = 0.8740016194041855, disc_loss = 0.05569554536608968
Trained batch 501 in epoch 16, gen_loss = 0.8735547612506555, disc_loss = 0.055714610250726104
Trained batch 502 in epoch 16, gen_loss = 0.8738071077742112, disc_loss = 0.05562271132868961
Trained batch 503 in epoch 16, gen_loss = 0.8735902028542663, disc_loss = 0.055619753116468294
Trained batch 504 in epoch 16, gen_loss = 0.8734263718128205, disc_loss = 0.05561561570733343
Trained batch 505 in epoch 16, gen_loss = 0.8731652207878738, disc_loss = 0.055636793120097915
Trained batch 506 in epoch 16, gen_loss = 0.8736777373201984, disc_loss = 0.05565940915961443
Trained batch 507 in epoch 16, gen_loss = 0.873810116758966, disc_loss = 0.05560240611034321
Trained batch 508 in epoch 16, gen_loss = 0.8732759449594382, disc_loss = 0.05563966213672446
Trained batch 509 in epoch 16, gen_loss = 0.8731733630100886, disc_loss = 0.055637748242702845
Trained batch 510 in epoch 16, gen_loss = 0.8732767422955097, disc_loss = 0.05560728055634581
Trained batch 511 in epoch 16, gen_loss = 0.8733167609316297, disc_loss = 0.05552645195075456
Trained batch 512 in epoch 16, gen_loss = 0.8730658998614863, disc_loss = 0.055511752155302616
Trained batch 513 in epoch 16, gen_loss = 0.8732353296377315, disc_loss = 0.05542461178627894
Trained batch 514 in epoch 16, gen_loss = 0.8727141932955066, disc_loss = 0.05553447348382143
Trained batch 515 in epoch 16, gen_loss = 0.8733603951427363, disc_loss = 0.055683243661476374
Trained batch 516 in epoch 16, gen_loss = 0.8735237887680415, disc_loss = 0.05577147074991286
Trained batch 517 in epoch 16, gen_loss = 0.8732322135141918, disc_loss = 0.05579980562304409
Trained batch 518 in epoch 16, gen_loss = 0.8726005918832643, disc_loss = 0.056050586464827405
Trained batch 519 in epoch 16, gen_loss = 0.8725658482657029, disc_loss = 0.05618769061088992
Trained batch 520 in epoch 16, gen_loss = 0.872095535275117, disc_loss = 0.05623785160649961
Trained batch 521 in epoch 16, gen_loss = 0.8722672661716454, disc_loss = 0.05661616222023022
Trained batch 522 in epoch 16, gen_loss = 0.871921519533398, disc_loss = 0.056667203502996644
Trained batch 523 in epoch 16, gen_loss = 0.8715048691129866, disc_loss = 0.05678087121981217
Trained batch 524 in epoch 16, gen_loss = 0.8709925421646663, disc_loss = 0.05691810283189019
Trained batch 525 in epoch 16, gen_loss = 0.8713869025838692, disc_loss = 0.057123238896285344
Trained batch 526 in epoch 16, gen_loss = 0.8710616322011604, disc_loss = 0.057138190100206314
Trained batch 527 in epoch 16, gen_loss = 0.8704526283862916, disc_loss = 0.05715767826415796
Trained batch 528 in epoch 16, gen_loss = 0.8704199332934021, disc_loss = 0.05706940965888941
Trained batch 529 in epoch 16, gen_loss = 0.8702786374204564, disc_loss = 0.057030014481992936
Trained batch 530 in epoch 16, gen_loss = 0.8706343223931875, disc_loss = 0.057009743501146355
Trained batch 531 in epoch 16, gen_loss = 0.8705179017401279, disc_loss = 0.05695428759388318
Trained batch 532 in epoch 16, gen_loss = 0.8704444427763096, disc_loss = 0.056880338728169284
Trained batch 533 in epoch 16, gen_loss = 0.870544379625874, disc_loss = 0.056798507017345075
Trained batch 534 in epoch 16, gen_loss = 0.8709918506234606, disc_loss = 0.056822439708755675
Trained batch 535 in epoch 16, gen_loss = 0.8707539862327611, disc_loss = 0.056827495285525303
Trained batch 536 in epoch 16, gen_loss = 0.8709836637174617, disc_loss = 0.056739378209768675
Trained batch 537 in epoch 16, gen_loss = 0.8710958284627106, disc_loss = 0.05671604697377902
Trained batch 538 in epoch 16, gen_loss = 0.8714936485648819, disc_loss = 0.05666691732052057
Trained batch 539 in epoch 16, gen_loss = 0.8712944425366543, disc_loss = 0.05667607600335032
Trained batch 540 in epoch 16, gen_loss = 0.871307161015195, disc_loss = 0.056595686493465566
Trained batch 541 in epoch 16, gen_loss = 0.8715740230580538, disc_loss = 0.05650976764955781
Trained batch 542 in epoch 16, gen_loss = 0.8714452090074564, disc_loss = 0.05645246729752114
Trained batch 543 in epoch 16, gen_loss = 0.8719499732970315, disc_loss = 0.05636487306208651
Trained batch 544 in epoch 16, gen_loss = 0.8720857661251628, disc_loss = 0.056274360451642254
Trained batch 545 in epoch 16, gen_loss = 0.8717866586350695, disc_loss = 0.05625327064437389
Trained batch 546 in epoch 16, gen_loss = 0.8722152653843219, disc_loss = 0.056169835519440596
Trained batch 547 in epoch 16, gen_loss = 0.8722672465182569, disc_loss = 0.05616166703589941
Trained batch 548 in epoch 16, gen_loss = 0.8725092005534251, disc_loss = 0.05608843808708702
Trained batch 549 in epoch 16, gen_loss = 0.8721847875009884, disc_loss = 0.056045291853052646
Trained batch 550 in epoch 16, gen_loss = 0.8721640964060643, disc_loss = 0.05597912299340276
Trained batch 551 in epoch 16, gen_loss = 0.8723426594574383, disc_loss = 0.05592821891321733
Trained batch 552 in epoch 16, gen_loss = 0.8729531747199744, disc_loss = 0.055903177721018334
Trained batch 553 in epoch 16, gen_loss = 0.8729387035976679, disc_loss = 0.05587906300910624
Trained batch 554 in epoch 16, gen_loss = 0.8726098862317231, disc_loss = 0.05585797000760297
Trained batch 555 in epoch 16, gen_loss = 0.8726335166276787, disc_loss = 0.055850837968470755
Trained batch 556 in epoch 16, gen_loss = 0.873133416289273, disc_loss = 0.055791852242502264
Trained batch 557 in epoch 16, gen_loss = 0.8733069506276893, disc_loss = 0.05570501863445726
Trained batch 558 in epoch 16, gen_loss = 0.873759444849649, disc_loss = 0.0556415968361329
Trained batch 559 in epoch 16, gen_loss = 0.8738137684230294, disc_loss = 0.05562306715957155
Trained batch 560 in epoch 16, gen_loss = 0.8740820099007, disc_loss = 0.05555645900956104
Trained batch 561 in epoch 16, gen_loss = 0.8743145449411827, disc_loss = 0.055482536962825894
Trained batch 562 in epoch 16, gen_loss = 0.8738340563397212, disc_loss = 0.05563317647958125
Trained batch 563 in epoch 16, gen_loss = 0.8742118019689905, disc_loss = 0.05641760067859044
Trained batch 564 in epoch 16, gen_loss = 0.8739714877267855, disc_loss = 0.05641499873563911
Trained batch 565 in epoch 16, gen_loss = 0.8735141261832874, disc_loss = 0.05669830623411906
Trained batch 566 in epoch 16, gen_loss = 0.8736326847442244, disc_loss = 0.05674838617434183
Trained batch 567 in epoch 16, gen_loss = 0.8735606191338787, disc_loss = 0.05674852357118089
Trained batch 568 in epoch 16, gen_loss = 0.8732859375501978, disc_loss = 0.056736084860905034
Trained batch 569 in epoch 16, gen_loss = 0.873259962075635, disc_loss = 0.0566599438645011
Trained batch 570 in epoch 16, gen_loss = 0.8732812858191555, disc_loss = 0.056593972781017396
Trained batch 571 in epoch 16, gen_loss = 0.8732230205323313, disc_loss = 0.05653373939978363
Trained batch 572 in epoch 16, gen_loss = 0.8730233029233223, disc_loss = 0.05648173099825805
Trained batch 573 in epoch 16, gen_loss = 0.8729408762907732, disc_loss = 0.0564342095940098
Trained batch 574 in epoch 16, gen_loss = 0.873386988795322, disc_loss = 0.05636296244986031
Trained batch 575 in epoch 16, gen_loss = 0.8735397656241225, disc_loss = 0.05627708361539084
Trained batch 576 in epoch 16, gen_loss = 0.8734056089635118, disc_loss = 0.0562011046081691
Trained batch 577 in epoch 16, gen_loss = 0.8736324656277792, disc_loss = 0.056137094800247714
Trained batch 578 in epoch 16, gen_loss = 0.8738000075331211, disc_loss = 0.05606072616485142
Trained batch 579 in epoch 16, gen_loss = 0.8733674626412062, disc_loss = 0.05605468675895626
Trained batch 580 in epoch 16, gen_loss = 0.8734119081558747, disc_loss = 0.05597143730135849
Trained batch 581 in epoch 16, gen_loss = 0.873802867490811, disc_loss = 0.05590675140993471
Trained batch 582 in epoch 16, gen_loss = 0.8742549713336788, disc_loss = 0.05587875546798059
Trained batch 583 in epoch 16, gen_loss = 0.8740013096328467, disc_loss = 0.055834980667983376
Trained batch 584 in epoch 16, gen_loss = 0.8738658425644932, disc_loss = 0.05579833491410837
Trained batch 585 in epoch 16, gen_loss = 0.8738851927144535, disc_loss = 0.05573485218824457
Trained batch 586 in epoch 16, gen_loss = 0.8740913071360255, disc_loss = 0.05564967704162611
Trained batch 587 in epoch 16, gen_loss = 0.8743665919316058, disc_loss = 0.05556667411737904
Trained batch 588 in epoch 16, gen_loss = 0.8746073466104238, disc_loss = 0.0554991710507303
Trained batch 589 in epoch 16, gen_loss = 0.8746075608467652, disc_loss = 0.055436332056582986
Trained batch 590 in epoch 16, gen_loss = 0.8745147800183336, disc_loss = 0.05539459920474115
Trained batch 591 in epoch 16, gen_loss = 0.875179898648246, disc_loss = 0.05539179699042359
Trained batch 592 in epoch 16, gen_loss = 0.8749392625151758, disc_loss = 0.05541776131970484
Trained batch 593 in epoch 16, gen_loss = 0.8756043531176217, disc_loss = 0.05541744182883489
Trained batch 594 in epoch 16, gen_loss = 0.8757117617530983, disc_loss = 0.05534487635898991
Trained batch 595 in epoch 16, gen_loss = 0.8755708613351687, disc_loss = 0.05529419756525715
Trained batch 596 in epoch 16, gen_loss = 0.8753856860313384, disc_loss = 0.055293234118215205
Trained batch 597 in epoch 16, gen_loss = 0.875453631265905, disc_loss = 0.05535821155037569
Trained batch 598 in epoch 16, gen_loss = 0.8754001294133659, disc_loss = 0.05531721394540173
Trained batch 599 in epoch 16, gen_loss = 0.8756012194852034, disc_loss = 0.0552443926455453
Trained batch 600 in epoch 16, gen_loss = 0.8751735231543143, disc_loss = 0.055353643138662055
Trained batch 601 in epoch 16, gen_loss = 0.8754415009603944, disc_loss = 0.05534579382553399
Trained batch 602 in epoch 16, gen_loss = 0.8757931840657002, disc_loss = 0.0553115598075895
Trained batch 603 in epoch 16, gen_loss = 0.87550413514802, disc_loss = 0.055309661970911736
Trained batch 604 in epoch 16, gen_loss = 0.8755947342096282, disc_loss = 0.055285052965926236
Trained batch 605 in epoch 16, gen_loss = 0.8753513404146673, disc_loss = 0.05525786754069696
Trained batch 606 in epoch 16, gen_loss = 0.8755302570109705, disc_loss = 0.05528532719635443
Trained batch 607 in epoch 16, gen_loss = 0.8754108985885978, disc_loss = 0.05526274316300834
Trained batch 608 in epoch 16, gen_loss = 0.8754623715807064, disc_loss = 0.05520372250696953
Trained batch 609 in epoch 16, gen_loss = 0.8755007455094916, disc_loss = 0.05518701471174594
Trained batch 610 in epoch 16, gen_loss = 0.8751560271566706, disc_loss = 0.05523235682678545
Trained batch 611 in epoch 16, gen_loss = 0.8752254409825101, disc_loss = 0.0552256561076159
Trained batch 612 in epoch 16, gen_loss = 0.8756587603061079, disc_loss = 0.055192379662265686
Trained batch 613 in epoch 16, gen_loss = 0.8752197119913971, disc_loss = 0.055368672657442504
Trained batch 614 in epoch 16, gen_loss = 0.8757944525257358, disc_loss = 0.05539068141270701
Trained batch 615 in epoch 16, gen_loss = 0.8761300328006218, disc_loss = 0.05535082370435892
Trained batch 616 in epoch 16, gen_loss = 0.8760805464737612, disc_loss = 0.05530898133972041
Trained batch 617 in epoch 16, gen_loss = 0.8755934436633749, disc_loss = 0.05551663010824218
Trained batch 618 in epoch 16, gen_loss = 0.8757701863283487, disc_loss = 0.055608705286484254
Trained batch 619 in epoch 16, gen_loss = 0.8755856369291583, disc_loss = 0.05559127582988191
Trained batch 620 in epoch 16, gen_loss = 0.8753925615174759, disc_loss = 0.05556787999013916
Trained batch 621 in epoch 16, gen_loss = 0.8756239664803748, disc_loss = 0.05553194735396857
Trained batch 622 in epoch 16, gen_loss = 0.875523439523305, disc_loss = 0.05551692345187092
Trained batch 623 in epoch 16, gen_loss = 0.8748655792516775, disc_loss = 0.055761104895888515
Trained batch 624 in epoch 16, gen_loss = 0.8750449524402618, disc_loss = 0.055739166162908076
Trained batch 625 in epoch 16, gen_loss = 0.8755502129991215, disc_loss = 0.055795352095172716
Trained batch 626 in epoch 16, gen_loss = 0.875558086797191, disc_loss = 0.055739314432004895
Trained batch 627 in epoch 16, gen_loss = 0.8754071088828099, disc_loss = 0.05570443569991002
Trained batch 628 in epoch 16, gen_loss = 0.8754291858032511, disc_loss = 0.055648650344763254
Trained batch 629 in epoch 16, gen_loss = 0.8756755122589687, disc_loss = 0.05568331844720339
Trained batch 630 in epoch 16, gen_loss = 0.8754820146859165, disc_loss = 0.055678602200290764
Trained batch 631 in epoch 16, gen_loss = 0.8754563034052336, disc_loss = 0.0556082445877616
Trained batch 632 in epoch 16, gen_loss = 0.875392713205886, disc_loss = 0.05557072313140495
Trained batch 633 in epoch 16, gen_loss = 0.8755683636157671, disc_loss = 0.055506523197651945
Trained batch 634 in epoch 16, gen_loss = 0.8759343117710173, disc_loss = 0.055442794108778004
Trained batch 635 in epoch 16, gen_loss = 0.875938670018559, disc_loss = 0.055454106575299825
Trained batch 636 in epoch 16, gen_loss = 0.8755720555782318, disc_loss = 0.055472405222383454
Trained batch 637 in epoch 16, gen_loss = 0.875934626381599, disc_loss = 0.055401263161501076
Trained batch 638 in epoch 16, gen_loss = 0.876215012187316, disc_loss = 0.05535475846018543
Trained batch 639 in epoch 16, gen_loss = 0.8760167359840125, disc_loss = 0.05533716326899594
Trained batch 640 in epoch 16, gen_loss = 0.875839826050861, disc_loss = 0.055373729598910404
Trained batch 641 in epoch 16, gen_loss = 0.8758463012373707, disc_loss = 0.055344592314213514
Trained batch 642 in epoch 16, gen_loss = 0.8754921060976678, disc_loss = 0.05547043142194279
Trained batch 643 in epoch 16, gen_loss = 0.8759481750937722, disc_loss = 0.05541901640530375
Trained batch 644 in epoch 16, gen_loss = 0.875658512254094, disc_loss = 0.05541437334821437
Trained batch 645 in epoch 16, gen_loss = 0.876170099104521, disc_loss = 0.055589453004381326
Trained batch 646 in epoch 16, gen_loss = 0.8756494450698127, disc_loss = 0.05581521372551205
Trained batch 647 in epoch 16, gen_loss = 0.8757642247702604, disc_loss = 0.055775858506410855
Trained batch 648 in epoch 16, gen_loss = 0.8758426467057185, disc_loss = 0.055722595092041194
Trained batch 649 in epoch 16, gen_loss = 0.8758671129208345, disc_loss = 0.055773437875681196
Trained batch 650 in epoch 16, gen_loss = 0.8756649770220304, disc_loss = 0.055846542627843936
Trained batch 651 in epoch 16, gen_loss = 0.8758409234917969, disc_loss = 0.055776764025934546
Trained batch 652 in epoch 16, gen_loss = 0.8755465331066622, disc_loss = 0.05585655629218401
Trained batch 653 in epoch 16, gen_loss = 0.8752646646277256, disc_loss = 0.05587297019374981
Trained batch 654 in epoch 16, gen_loss = 0.8751643056632908, disc_loss = 0.0558599247319894
Trained batch 655 in epoch 16, gen_loss = 0.8753188583636429, disc_loss = 0.05583376379927802
Trained batch 656 in epoch 16, gen_loss = 0.8753472729451399, disc_loss = 0.05579663356525123
Trained batch 657 in epoch 16, gen_loss = 0.8749009478146544, disc_loss = 0.055933863845990694
Trained batch 658 in epoch 16, gen_loss = 0.8747555640199658, disc_loss = 0.055886060786638436
Trained batch 659 in epoch 16, gen_loss = 0.8749684357733437, disc_loss = 0.056171831574686096
Trained batch 660 in epoch 16, gen_loss = 0.8750156014030531, disc_loss = 0.05617565367618821
Trained batch 661 in epoch 16, gen_loss = 0.8747526434703176, disc_loss = 0.05618709045690217
Trained batch 662 in epoch 16, gen_loss = 0.8743541525230148, disc_loss = 0.05621025666487747
Trained batch 663 in epoch 16, gen_loss = 0.874549486236759, disc_loss = 0.05615032661330314
Trained batch 664 in epoch 16, gen_loss = 0.8745488308874289, disc_loss = 0.05665775062026162
Trained batch 665 in epoch 16, gen_loss = 0.874311891180259, disc_loss = 0.05669987670008887
Trained batch 666 in epoch 16, gen_loss = 0.874007423733664, disc_loss = 0.05672841457261898
Trained batch 667 in epoch 16, gen_loss = 0.8737423135759588, disc_loss = 0.056730484384987616
Trained batch 668 in epoch 16, gen_loss = 0.8738770325889502, disc_loss = 0.05682950958704244
Trained batch 669 in epoch 16, gen_loss = 0.8738950397096463, disc_loss = 0.056755514310867484
Trained batch 670 in epoch 16, gen_loss = 0.8735726184798779, disc_loss = 0.05674025111161339
Trained batch 671 in epoch 16, gen_loss = 0.8733855053516371, disc_loss = 0.05671460883431358
Trained batch 672 in epoch 16, gen_loss = 0.8736135921099211, disc_loss = 0.056680465862985266
Trained batch 673 in epoch 16, gen_loss = 0.8736925354608797, disc_loss = 0.056615826606098284
Trained batch 674 in epoch 16, gen_loss = 0.8735179450335326, disc_loss = 0.056659757474230396
Trained batch 675 in epoch 16, gen_loss = 0.8735009850217745, disc_loss = 0.05665041265055846
Trained batch 676 in epoch 16, gen_loss = 0.8734407927208144, disc_loss = 0.056595589587275084
Trained batch 677 in epoch 16, gen_loss = 0.8734295020500819, disc_loss = 0.056555308578783166
Trained batch 678 in epoch 16, gen_loss = 0.8736233367572301, disc_loss = 0.05648618067624336
Trained batch 679 in epoch 16, gen_loss = 0.8733769804677542, disc_loss = 0.056471665369291955
Trained batch 680 in epoch 16, gen_loss = 0.8733636297055803, disc_loss = 0.05641172166705875
Trained batch 681 in epoch 16, gen_loss = 0.8731339633727003, disc_loss = 0.05636241992859066
Trained batch 682 in epoch 16, gen_loss = 0.873910903625223, disc_loss = 0.056466158846254146
Trained batch 683 in epoch 16, gen_loss = 0.8739223941637758, disc_loss = 0.05639898548398319
Trained batch 684 in epoch 16, gen_loss = 0.873882639799675, disc_loss = 0.056340370932254046
Trained batch 685 in epoch 16, gen_loss = 0.8742688085786108, disc_loss = 0.05629060047192624
Trained batch 686 in epoch 16, gen_loss = 0.8741668366882652, disc_loss = 0.056271926117613585
Trained batch 687 in epoch 16, gen_loss = 0.8739019411854273, disc_loss = 0.05625148161536429
Trained batch 688 in epoch 16, gen_loss = 0.8739109293210316, disc_loss = 0.056188755198307495
Trained batch 689 in epoch 16, gen_loss = 0.8741413136755211, disc_loss = 0.05614053042389561
Trained batch 690 in epoch 16, gen_loss = 0.8741108556473479, disc_loss = 0.056105291917003614
Trained batch 691 in epoch 16, gen_loss = 0.874214388860788, disc_loss = 0.05609912642363911
Trained batch 692 in epoch 16, gen_loss = 0.8741685830239437, disc_loss = 0.05610087016815102
Trained batch 693 in epoch 16, gen_loss = 0.8738250455440637, disc_loss = 0.056147882082802844
Trained batch 694 in epoch 16, gen_loss = 0.874413892819727, disc_loss = 0.05626853923815832
Trained batch 695 in epoch 16, gen_loss = 0.8748956719606087, disc_loss = 0.05624080200053366
Trained batch 696 in epoch 16, gen_loss = 0.8749930964224307, disc_loss = 0.05617252258394165
Trained batch 697 in epoch 16, gen_loss = 0.8747936046994518, disc_loss = 0.056138325568000365
Trained batch 698 in epoch 16, gen_loss = 0.8744566076047431, disc_loss = 0.05613239693624608
Trained batch 699 in epoch 16, gen_loss = 0.8744721981031555, disc_loss = 0.05609135996018137
Trained batch 700 in epoch 16, gen_loss = 0.8745643675497357, disc_loss = 0.05602370806240321
Trained batch 701 in epoch 16, gen_loss = 0.874451870549778, disc_loss = 0.055969388948546514
Trained batch 702 in epoch 16, gen_loss = 0.8748854165989508, disc_loss = 0.05597167377854309
Trained batch 703 in epoch 16, gen_loss = 0.8752565449527041, disc_loss = 0.05592216524845836
Trained batch 704 in epoch 16, gen_loss = 0.875216269704467, disc_loss = 0.05587446787889967
Trained batch 705 in epoch 16, gen_loss = 0.8748875777461373, disc_loss = 0.055898223336121176
Trained batch 706 in epoch 16, gen_loss = 0.8745417544747344, disc_loss = 0.056150005658748635
Trained batch 707 in epoch 16, gen_loss = 0.8745307880690543, disc_loss = 0.056090836265876805
Trained batch 708 in epoch 16, gen_loss = 0.8745613411300105, disc_loss = 0.05603312583553522
Trained batch 709 in epoch 16, gen_loss = 0.87422834890829, disc_loss = 0.05609476553984511
Trained batch 710 in epoch 16, gen_loss = 0.874173625821638, disc_loss = 0.05613363290313008
Trained batch 711 in epoch 16, gen_loss = 0.8748604861621776, disc_loss = 0.05613234317128996
Trained batch 712 in epoch 16, gen_loss = 0.8749792230998651, disc_loss = 0.05607737080150951
Trained batch 713 in epoch 16, gen_loss = 0.8748730943233025, disc_loss = 0.05602563195535783
Trained batch 714 in epoch 16, gen_loss = 0.8747131415597209, disc_loss = 0.055974343843706004
Trained batch 715 in epoch 16, gen_loss = 0.8743767330849637, disc_loss = 0.05595759386404849
Trained batch 716 in epoch 16, gen_loss = 0.8743340675219, disc_loss = 0.05592156595172493
Trained batch 717 in epoch 16, gen_loss = 0.8745460648473591, disc_loss = 0.05591917623996651
Trained batch 718 in epoch 16, gen_loss = 0.8746871784515938, disc_loss = 0.055852932714298885
Trained batch 719 in epoch 16, gen_loss = 0.8744051594287157, disc_loss = 0.05587447385639987
Trained batch 720 in epoch 16, gen_loss = 0.8746190612177247, disc_loss = 0.05582068597926305
Trained batch 721 in epoch 16, gen_loss = 0.8744216877089973, disc_loss = 0.05581743353100654
Trained batch 722 in epoch 16, gen_loss = 0.8749422476746729, disc_loss = 0.055875789661367484
Trained batch 723 in epoch 16, gen_loss = 0.8750993654296543, disc_loss = 0.055817206993503544
Trained batch 724 in epoch 16, gen_loss = 0.8748374124642077, disc_loss = 0.055832019685928165
Trained batch 725 in epoch 16, gen_loss = 0.8745568601142605, disc_loss = 0.05581138594096562
Trained batch 726 in epoch 16, gen_loss = 0.8746236896826444, disc_loss = 0.05599744106672366
Trained batch 727 in epoch 16, gen_loss = 0.874815775429482, disc_loss = 0.055947100345792436
Trained batch 728 in epoch 16, gen_loss = 0.8746484179964444, disc_loss = 0.05592628256820234
Trained batch 729 in epoch 16, gen_loss = 0.8747485381691423, disc_loss = 0.0558640580943288
Trained batch 730 in epoch 16, gen_loss = 0.8750034209070714, disc_loss = 0.055984751497192765
Trained batch 731 in epoch 16, gen_loss = 0.8744347654486615, disc_loss = 0.056210116107943034
Trained batch 732 in epoch 16, gen_loss = 0.8742605729529185, disc_loss = 0.056223477386852974
Trained batch 733 in epoch 16, gen_loss = 0.8740364006575837, disc_loss = 0.0562542041456606
Trained batch 734 in epoch 16, gen_loss = 0.8739232461063229, disc_loss = 0.05629560350991634
Trained batch 735 in epoch 16, gen_loss = 0.8744100596674759, disc_loss = 0.05630510901328702
Trained batch 736 in epoch 16, gen_loss = 0.8739301736594217, disc_loss = 0.05647711580798657
Trained batch 737 in epoch 16, gen_loss = 0.8740511746991294, disc_loss = 0.05644608190697101
Trained batch 738 in epoch 16, gen_loss = 0.8737952123233527, disc_loss = 0.056427523177444774
Trained batch 739 in epoch 16, gen_loss = 0.8738067857719757, disc_loss = 0.05643893280569967
Trained batch 740 in epoch 16, gen_loss = 0.8739576982020045, disc_loss = 0.056393744870165664
Trained batch 741 in epoch 16, gen_loss = 0.8740434103979254, disc_loss = 0.0563697082999682
Trained batch 742 in epoch 16, gen_loss = 0.8740195089281808, disc_loss = 0.05632996853080003
Trained batch 743 in epoch 16, gen_loss = 0.873881598834389, disc_loss = 0.05632181791713842
Trained batch 744 in epoch 16, gen_loss = 0.8742266980193605, disc_loss = 0.05646597922673362
Trained batch 745 in epoch 16, gen_loss = 0.8744834248006503, disc_loss = 0.05640337501724947
Trained batch 746 in epoch 16, gen_loss = 0.8747435109602559, disc_loss = 0.0563414223290172
Trained batch 747 in epoch 16, gen_loss = 0.8749017327784855, disc_loss = 0.05628267134275825
Trained batch 748 in epoch 16, gen_loss = 0.8749793473884802, disc_loss = 0.056224954293391735
Trained batch 749 in epoch 16, gen_loss = 0.8749059890508651, disc_loss = 0.056186589911580084
Trained batch 750 in epoch 16, gen_loss = 0.8749355008297373, disc_loss = 0.05613828326678387
Trained batch 751 in epoch 16, gen_loss = 0.8749164255296297, disc_loss = 0.05610997694237356
Trained batch 752 in epoch 16, gen_loss = 0.8748073398591988, disc_loss = 0.056049161502821826
Trained batch 753 in epoch 16, gen_loss = 0.875180515552073, disc_loss = 0.05600035342014832
Trained batch 754 in epoch 16, gen_loss = 0.8753592729173749, disc_loss = 0.055935472533082134
Trained batch 755 in epoch 16, gen_loss = 0.8751573245282527, disc_loss = 0.055902694841654645
Trained batch 756 in epoch 16, gen_loss = 0.8752687641541268, disc_loss = 0.05584140932384283
Trained batch 757 in epoch 16, gen_loss = 0.8756209089369132, disc_loss = 0.056009367948132605
Trained batch 758 in epoch 16, gen_loss = 0.8755095145997637, disc_loss = 0.055965418552511095
Trained batch 759 in epoch 16, gen_loss = 0.8750886622620256, disc_loss = 0.056057772897551525
Trained batch 760 in epoch 16, gen_loss = 0.8751732116068239, disc_loss = 0.0560515750873878
Trained batch 761 in epoch 16, gen_loss = 0.8752686484983274, disc_loss = 0.056006368403041885
Trained batch 762 in epoch 16, gen_loss = 0.8751719168644901, disc_loss = 0.05598920890036116
Trained batch 763 in epoch 16, gen_loss = 0.875248971604864, disc_loss = 0.055927297037645825
Trained batch 764 in epoch 16, gen_loss = 0.8754695487567802, disc_loss = 0.05587047322233226
Trained batch 765 in epoch 16, gen_loss = 0.8756113685375717, disc_loss = 0.055810013971371725
Trained batch 766 in epoch 16, gen_loss = 0.8753289036753902, disc_loss = 0.05579786376682786
Trained batch 767 in epoch 16, gen_loss = 0.875289367705894, disc_loss = 0.055761032110240194
Trained batch 768 in epoch 16, gen_loss = 0.8755602412245519, disc_loss = 0.05570396020226132
Trained batch 769 in epoch 16, gen_loss = 0.8758780848283272, disc_loss = 0.05565525604496625
Trained batch 770 in epoch 16, gen_loss = 0.8758393797042614, disc_loss = 0.05560293937725258
Trained batch 771 in epoch 16, gen_loss = 0.8758108651777006, disc_loss = 0.055546149697728996
Trained batch 772 in epoch 16, gen_loss = 0.8760797888387529, disc_loss = 0.05549782177645419
Trained batch 773 in epoch 16, gen_loss = 0.8764681489969717, disc_loss = 0.05545157967532386
Trained batch 774 in epoch 16, gen_loss = 0.8765655028050946, disc_loss = 0.05541064469263919
Trained batch 775 in epoch 16, gen_loss = 0.87662446955891, disc_loss = 0.05537982436902725
Trained batch 776 in epoch 16, gen_loss = 0.8768409550036549, disc_loss = 0.05533040445981166
Trained batch 777 in epoch 16, gen_loss = 0.8773223366636237, disc_loss = 0.05538672882678097
Trained batch 778 in epoch 16, gen_loss = 0.8771867301788502, disc_loss = 0.05539887750148295
Trained batch 779 in epoch 16, gen_loss = 0.8771285570966891, disc_loss = 0.05536993142300978
Trained batch 780 in epoch 16, gen_loss = 0.8772537472077124, disc_loss = 0.05530811728797519
Trained batch 781 in epoch 16, gen_loss = 0.8773980049602211, disc_loss = 0.05525365656317995
Trained batch 782 in epoch 16, gen_loss = 0.8773820973066839, disc_loss = 0.055197833909975465
Trained batch 783 in epoch 16, gen_loss = 0.8774362748146666, disc_loss = 0.055153385648142775
Trained batch 784 in epoch 16, gen_loss = 0.8772471037260287, disc_loss = 0.05512106249191959
Trained batch 785 in epoch 16, gen_loss = 0.8773900122967082, disc_loss = 0.05507093557789353
Trained batch 786 in epoch 16, gen_loss = 0.8776451620016498, disc_loss = 0.05506373874445504
Trained batch 787 in epoch 16, gen_loss = 0.8778472136951945, disc_loss = 0.055003852800934144
Trained batch 788 in epoch 16, gen_loss = 0.8776527503824053, disc_loss = 0.05500459987835437
Trained batch 789 in epoch 16, gen_loss = 0.8775948905869375, disc_loss = 0.05496330166919322
Testing Epoch 16
Training Epoch 17
Trained batch 0 in epoch 17, gen_loss = 1.0235764980316162, disc_loss = 0.03385181725025177
Trained batch 1 in epoch 17, gen_loss = 0.9148461222648621, disc_loss = 0.022121425718069077
Trained batch 2 in epoch 17, gen_loss = 0.9467211961746216, disc_loss = 0.02068149670958519
Trained batch 3 in epoch 17, gen_loss = 0.9324233382940292, disc_loss = 0.01988468924537301
Trained batch 4 in epoch 17, gen_loss = 0.8792118906974793, disc_loss = 0.027522686496376993
Trained batch 5 in epoch 17, gen_loss = 0.9166638354460398, disc_loss = 0.030985862327118713
Trained batch 6 in epoch 17, gen_loss = 0.9108213356563023, disc_loss = 0.030910986608692577
Trained batch 7 in epoch 17, gen_loss = 0.942942887544632, disc_loss = 0.028824553824961185
Trained batch 8 in epoch 17, gen_loss = 0.9340053664313422, disc_loss = 0.027881319324175518
Trained batch 9 in epoch 17, gen_loss = 0.922504985332489, disc_loss = 0.027587605826556682
Trained batch 10 in epoch 17, gen_loss = 0.9316104867241599, disc_loss = 0.02588501674207774
Trained batch 11 in epoch 17, gen_loss = 0.9222408632437388, disc_loss = 0.024463869786510866
Trained batch 12 in epoch 17, gen_loss = 0.9096557727226844, disc_loss = 0.025849392351049643
Trained batch 13 in epoch 17, gen_loss = 0.9096116168158395, disc_loss = 0.02580409829637834
Trained batch 14 in epoch 17, gen_loss = 0.897666581471761, disc_loss = 0.027290532613794008
Trained batch 15 in epoch 17, gen_loss = 0.9139934033155441, disc_loss = 0.03024286834988743
Trained batch 16 in epoch 17, gen_loss = 0.921778636820176, disc_loss = 0.029149729155880565
Trained batch 17 in epoch 17, gen_loss = 0.9126912620332506, disc_loss = 0.031112072420203023
Trained batch 18 in epoch 17, gen_loss = 0.924397443470202, disc_loss = 0.03097860970975537
Trained batch 19 in epoch 17, gen_loss = 0.9241509556770324, disc_loss = 0.029996591852977872
Trained batch 20 in epoch 17, gen_loss = 0.9169908761978149, disc_loss = 0.029442903585731983
Trained batch 21 in epoch 17, gen_loss = 0.9185980639674447, disc_loss = 0.028454042441973634
Trained batch 22 in epoch 17, gen_loss = 0.9247574054676554, disc_loss = 0.028568497312295695
Trained batch 23 in epoch 17, gen_loss = 0.9127280587951342, disc_loss = 0.028973944465784978
Trained batch 24 in epoch 17, gen_loss = 0.90214191198349, disc_loss = 0.029630041997879743
Trained batch 25 in epoch 17, gen_loss = 0.8963473324592297, disc_loss = 0.02894002412302563
Trained batch 26 in epoch 17, gen_loss = 0.9035307323491132, disc_loss = 0.02906817334048726
Trained batch 27 in epoch 17, gen_loss = 0.9061118428196225, disc_loss = 0.028822227231492952
Trained batch 28 in epoch 17, gen_loss = 0.9006279049248531, disc_loss = 0.028644255378508364
Trained batch 29 in epoch 17, gen_loss = 0.9015840252240499, disc_loss = 0.027933852622906367
Trained batch 30 in epoch 17, gen_loss = 0.8971989539361769, disc_loss = 0.027664937499550082
Trained batch 31 in epoch 17, gen_loss = 0.8905419632792473, disc_loss = 0.02904387441230938
Trained batch 32 in epoch 17, gen_loss = 0.8999366651881825, disc_loss = 0.03418357732395331
Trained batch 33 in epoch 17, gen_loss = 0.8964478987104753, disc_loss = 0.033616670790840596
Trained batch 34 in epoch 17, gen_loss = 0.9042251978601729, disc_loss = 0.03312046251126698
Trained batch 35 in epoch 17, gen_loss = 0.8988610456387202, disc_loss = 0.035461198124620646
Trained batch 36 in epoch 17, gen_loss = 0.9004300945513958, disc_loss = 0.037245194251472886
Trained batch 37 in epoch 17, gen_loss = 0.8955847495480588, disc_loss = 0.03743428972206617
Trained batch 38 in epoch 17, gen_loss = 0.8901198292389895, disc_loss = 0.03800363953296955
Trained batch 39 in epoch 17, gen_loss = 0.8869805231690406, disc_loss = 0.038014004565775396
Trained batch 40 in epoch 17, gen_loss = 0.8945955023532961, disc_loss = 0.03797712158866045
Trained batch 41 in epoch 17, gen_loss = 0.8961043570722852, disc_loss = 0.037421374515231164
Trained batch 42 in epoch 17, gen_loss = 0.8940969913504845, disc_loss = 0.03781956475401341
Trained batch 43 in epoch 17, gen_loss = 0.8928684253584255, disc_loss = 0.03800203547474335
Trained batch 44 in epoch 17, gen_loss = 0.88909922308392, disc_loss = 0.03808482891569535
Trained batch 45 in epoch 17, gen_loss = 0.8881754784480386, disc_loss = 0.03808766852497407
Trained batch 46 in epoch 17, gen_loss = 0.8844331528278108, disc_loss = 0.037900686204591964
Trained batch 47 in epoch 17, gen_loss = 0.8840121527512869, disc_loss = 0.03828384116059169
Trained batch 48 in epoch 17, gen_loss = 0.8864799810915577, disc_loss = 0.03824394966038514
Trained batch 49 in epoch 17, gen_loss = 0.89177001953125, disc_loss = 0.03784973816946149
Trained batch 50 in epoch 17, gen_loss = 0.8863194958836424, disc_loss = 0.0402571046359691
Trained batch 51 in epoch 17, gen_loss = 0.8899553704720277, disc_loss = 0.0398504518581411
Trained batch 52 in epoch 17, gen_loss = 0.8983861916470077, disc_loss = 0.042577054369140346
Trained batch 53 in epoch 17, gen_loss = 0.8959324834523378, disc_loss = 0.04250362151543851
Trained batch 54 in epoch 17, gen_loss = 0.8887318714098497, disc_loss = 0.04595380745489489
Trained batch 55 in epoch 17, gen_loss = 0.8915460764297417, disc_loss = 0.045927820610813797
Trained batch 56 in epoch 17, gen_loss = 0.8941504218076405, disc_loss = 0.045565202358391205
Trained batch 57 in epoch 17, gen_loss = 0.8926036085548072, disc_loss = 0.04527796613823237
Trained batch 58 in epoch 17, gen_loss = 0.891165106478384, disc_loss = 0.04580965728135938
Trained batch 59 in epoch 17, gen_loss = 0.8945243790745735, disc_loss = 0.04635260280532141
Trained batch 60 in epoch 17, gen_loss = 0.8945381392220981, disc_loss = 0.04612154747191511
Trained batch 61 in epoch 17, gen_loss = 0.892319705697798, disc_loss = 0.046064333644725626
Trained batch 62 in epoch 17, gen_loss = 0.889124236882679, disc_loss = 0.046038918803253816
Trained batch 63 in epoch 17, gen_loss = 0.8860338400118053, disc_loss = 0.04613598914875183
Trained batch 64 in epoch 17, gen_loss = 0.8893311092486749, disc_loss = 0.04578833016925133
Trained batch 65 in epoch 17, gen_loss = 0.888461224509008, disc_loss = 0.045594557992775335
Trained batch 66 in epoch 17, gen_loss = 0.8882572255027827, disc_loss = 0.045195936392158714
Trained batch 67 in epoch 17, gen_loss = 0.8861171853016404, disc_loss = 0.04497934813501642
Trained batch 68 in epoch 17, gen_loss = 0.8819119589052339, disc_loss = 0.04588210000993981
Trained batch 69 in epoch 17, gen_loss = 0.8860523687941687, disc_loss = 0.04583396582997271
Trained batch 70 in epoch 17, gen_loss = 0.8903601190573732, disc_loss = 0.04674275609021875
Trained batch 71 in epoch 17, gen_loss = 0.8868646509945393, disc_loss = 0.04666417786696305
Trained batch 72 in epoch 17, gen_loss = 0.8847024044761919, disc_loss = 0.047355699123278874
Trained batch 73 in epoch 17, gen_loss = 0.8868221990965508, disc_loss = 0.04691418999101262
Trained batch 74 in epoch 17, gen_loss = 0.889647308588028, disc_loss = 0.04788094236205021
Trained batch 75 in epoch 17, gen_loss = 0.8846092071188124, disc_loss = 0.049146098856765186
Trained batch 76 in epoch 17, gen_loss = 0.8857182121122038, disc_loss = 0.048717529246849675
Trained batch 77 in epoch 17, gen_loss = 0.8839808989029664, disc_loss = 0.04863732708140443
Trained batch 78 in epoch 17, gen_loss = 0.8855598633047901, disc_loss = 0.04854056643487155
Trained batch 79 in epoch 17, gen_loss = 0.8889429714530707, disc_loss = 0.04845601961715147
Trained batch 80 in epoch 17, gen_loss = 0.8871193414117083, disc_loss = 0.04879654896802005
Trained batch 81 in epoch 17, gen_loss = 0.8886239961153124, disc_loss = 0.04860331366838115
Trained batch 82 in epoch 17, gen_loss = 0.887315350483699, disc_loss = 0.04847690233040646
Trained batch 83 in epoch 17, gen_loss = 0.8866163644762266, disc_loss = 0.04809417075566238
Trained batch 84 in epoch 17, gen_loss = 0.8905335913686191, disc_loss = 0.04808149207383394
Trained batch 85 in epoch 17, gen_loss = 0.8916030169226402, disc_loss = 0.04762901681973491
Trained batch 86 in epoch 17, gen_loss = 0.8879395137573111, disc_loss = 0.04813164365531384
Trained batch 87 in epoch 17, gen_loss = 0.8907471736046401, disc_loss = 0.04846316952766343
Trained batch 88 in epoch 17, gen_loss = 0.8925335156113914, disc_loss = 0.04826073754536972
Trained batch 89 in epoch 17, gen_loss = 0.893476997812589, disc_loss = 0.04792481975422965
Trained batch 90 in epoch 17, gen_loss = 0.891801567195536, disc_loss = 0.04783696345575563
Trained batch 91 in epoch 17, gen_loss = 0.8928251891680385, disc_loss = 0.04743682212479736
Trained batch 92 in epoch 17, gen_loss = 0.8924698820037227, disc_loss = 0.04700480412531604
Trained batch 93 in epoch 17, gen_loss = 0.8943960390826489, disc_loss = 0.04660917946355457
Trained batch 94 in epoch 17, gen_loss = 0.8944844700788197, disc_loss = 0.04625985311638368
Trained batch 95 in epoch 17, gen_loss = 0.8928799098357558, disc_loss = 0.04607578796761421
Trained batch 96 in epoch 17, gen_loss = 0.8938644709660835, disc_loss = 0.04579568211680528
Trained batch 97 in epoch 17, gen_loss = 0.8955391587651506, disc_loss = 0.045437292224366446
Trained batch 98 in epoch 17, gen_loss = 0.8950760867258515, disc_loss = 0.04529542134453853
Trained batch 99 in epoch 17, gen_loss = 0.8960550978779793, disc_loss = 0.04492832178249955
Trained batch 100 in epoch 17, gen_loss = 0.8957231165749011, disc_loss = 0.04461154308502037
Trained batch 101 in epoch 17, gen_loss = 0.8950783204214245, disc_loss = 0.044261459407268784
Trained batch 102 in epoch 17, gen_loss = 0.8944512099316977, disc_loss = 0.044046436011501884
Trained batch 103 in epoch 17, gen_loss = 0.8953249187996755, disc_loss = 0.04387971017366418
Trained batch 104 in epoch 17, gen_loss = 0.8948434622514816, disc_loss = 0.04359513263972033
Trained batch 105 in epoch 17, gen_loss = 0.8943098223996613, disc_loss = 0.043259764564627746
Trained batch 106 in epoch 17, gen_loss = 0.8933610974628234, disc_loss = 0.04311729969334937
Trained batch 107 in epoch 17, gen_loss = 0.8960376219065102, disc_loss = 0.04299603142189207
Trained batch 108 in epoch 17, gen_loss = 0.8965941096117737, disc_loss = 0.04270778193112907
Trained batch 109 in epoch 17, gen_loss = 0.8959622098640962, disc_loss = 0.04246110841631889
Trained batch 110 in epoch 17, gen_loss = 0.8956047605286848, disc_loss = 0.04240251997032681
Trained batch 111 in epoch 17, gen_loss = 0.8965979641569513, disc_loss = 0.04207109309832698
Trained batch 112 in epoch 17, gen_loss = 0.8985833127414231, disc_loss = 0.043234088342735726
Trained batch 113 in epoch 17, gen_loss = 0.8971584792199888, disc_loss = 0.043010821182019356
Trained batch 114 in epoch 17, gen_loss = 0.8967942084955133, disc_loss = 0.04273677891849176
Trained batch 115 in epoch 17, gen_loss = 0.8954639067423755, disc_loss = 0.04286769850597043
Trained batch 116 in epoch 17, gen_loss = 0.8940253036144452, disc_loss = 0.04270158409594725
Trained batch 117 in epoch 17, gen_loss = 0.8950072367817669, disc_loss = 0.042570687996192
Trained batch 118 in epoch 17, gen_loss = 0.8941588213964671, disc_loss = 0.04251562385279842
Trained batch 119 in epoch 17, gen_loss = 0.8953428658346335, disc_loss = 0.04247986072829614
Trained batch 120 in epoch 17, gen_loss = 0.8937830405294402, disc_loss = 0.04279748622081743
Trained batch 121 in epoch 17, gen_loss = 0.8963175125297953, disc_loss = 0.042958521795627036
Trained batch 122 in epoch 17, gen_loss = 0.8943644027884413, disc_loss = 0.04310938174556184
Trained batch 123 in epoch 17, gen_loss = 0.8928786009069412, disc_loss = 0.04316276285587059
Trained batch 124 in epoch 17, gen_loss = 0.8941286404132843, disc_loss = 0.04289245647192001
Trained batch 125 in epoch 17, gen_loss = 0.8953819078585458, disc_loss = 0.04275409317028428
Trained batch 126 in epoch 17, gen_loss = 0.8927835678960395, disc_loss = 0.042836156930393124
Trained batch 127 in epoch 17, gen_loss = 0.8928650582674891, disc_loss = 0.04263417606125586
Trained batch 128 in epoch 17, gen_loss = 0.893462820801624, disc_loss = 0.04236157656856632
Trained batch 129 in epoch 17, gen_loss = 0.8934208340369738, disc_loss = 0.04210377165402931
Trained batch 130 in epoch 17, gen_loss = 0.8945030831653653, disc_loss = 0.041876211126143016
Trained batch 131 in epoch 17, gen_loss = 0.8944236475861433, disc_loss = 0.04194773371317283
Trained batch 132 in epoch 17, gen_loss = 0.8933023790219673, disc_loss = 0.042007303317042444
Trained batch 133 in epoch 17, gen_loss = 0.8953406074598654, disc_loss = 0.04290954567450307
Trained batch 134 in epoch 17, gen_loss = 0.8945372106852355, disc_loss = 0.043007332103809824
Trained batch 135 in epoch 17, gen_loss = 0.8928449852939915, disc_loss = 0.043576170050073415
Trained batch 136 in epoch 17, gen_loss = 0.8952985469007144, disc_loss = 0.04383470418856201
Trained batch 137 in epoch 17, gen_loss = 0.8966095168953356, disc_loss = 0.04414236795602609
Trained batch 138 in epoch 17, gen_loss = 0.8955991480419104, disc_loss = 0.04420671608339218
Trained batch 139 in epoch 17, gen_loss = 0.8941309462700572, disc_loss = 0.04454874978068152
Trained batch 140 in epoch 17, gen_loss = 0.8941599314517163, disc_loss = 0.04442520503364239
Trained batch 141 in epoch 17, gen_loss = 0.8952411461464116, disc_loss = 0.04461723970393584
Trained batch 142 in epoch 17, gen_loss = 0.8955216426532585, disc_loss = 0.044416754516297494
Trained batch 143 in epoch 17, gen_loss = 0.8959077441444, disc_loss = 0.04435538833301204
Trained batch 144 in epoch 17, gen_loss = 0.8949261601628928, disc_loss = 0.04440537995883617
Trained batch 145 in epoch 17, gen_loss = 0.8957185151234065, disc_loss = 0.04451058502946917
Trained batch 146 in epoch 17, gen_loss = 0.8954117182566195, disc_loss = 0.04442013583785924
Trained batch 147 in epoch 17, gen_loss = 0.8953345456236118, disc_loss = 0.04440086477473881
Trained batch 148 in epoch 17, gen_loss = 0.8959465152865288, disc_loss = 0.044156119718072595
Trained batch 149 in epoch 17, gen_loss = 0.8975032661358515, disc_loss = 0.04446613593958318
Trained batch 150 in epoch 17, gen_loss = 0.8971671602189146, disc_loss = 0.044321141227315
Trained batch 151 in epoch 17, gen_loss = 0.8959459652634043, disc_loss = 0.04441595465055128
Trained batch 152 in epoch 17, gen_loss = 0.897218997766769, disc_loss = 0.04428743170817791
Trained batch 153 in epoch 17, gen_loss = 0.8975447662077941, disc_loss = 0.044057576164192
Trained batch 154 in epoch 17, gen_loss = 0.8970365745405997, disc_loss = 0.04396658177757936
Trained batch 155 in epoch 17, gen_loss = 0.8948880053865604, disc_loss = 0.044098417522409596
Trained batch 156 in epoch 17, gen_loss = 0.8943398494249696, disc_loss = 0.044079764666047634
Trained batch 157 in epoch 17, gen_loss = 0.8965999983911273, disc_loss = 0.04462779439172319
Trained batch 158 in epoch 17, gen_loss = 0.8965620145482837, disc_loss = 0.04461968447368756
Trained batch 159 in epoch 17, gen_loss = 0.8957270501181483, disc_loss = 0.044576000384404325
Trained batch 160 in epoch 17, gen_loss = 0.8965555301734379, disc_loss = 0.044504451950121184
Trained batch 161 in epoch 17, gen_loss = 0.8968128442396353, disc_loss = 0.044298035055283964
Trained batch 162 in epoch 17, gen_loss = 0.8958863281399194, disc_loss = 0.04430401763747349
Trained batch 163 in epoch 17, gen_loss = 0.8958337319696822, disc_loss = 0.044135652252518365
Trained batch 164 in epoch 17, gen_loss = 0.8967501638513623, disc_loss = 0.045375205302667435
Trained batch 165 in epoch 17, gen_loss = 0.8954060858631708, disc_loss = 0.04578755584724965
Trained batch 166 in epoch 17, gen_loss = 0.8947715846721284, disc_loss = 0.04589551526350443
Trained batch 167 in epoch 17, gen_loss = 0.8977773794460864, disc_loss = 0.04618740170207318
Trained batch 168 in epoch 17, gen_loss = 0.8977083293996619, disc_loss = 0.04606888447364671
Trained batch 169 in epoch 17, gen_loss = 0.8974458454286351, disc_loss = 0.0461514435681131
Trained batch 170 in epoch 17, gen_loss = 0.8974727578679024, disc_loss = 0.046027209073283344
Trained batch 171 in epoch 17, gen_loss = 0.8978885292660358, disc_loss = 0.045836933095246384
Trained batch 172 in epoch 17, gen_loss = 0.8970804143847758, disc_loss = 0.04593303115672372
Trained batch 173 in epoch 17, gen_loss = 0.8951698656397304, disc_loss = 0.04624073769115768
Trained batch 174 in epoch 17, gen_loss = 0.8954183454172951, disc_loss = 0.04631577026365059
Trained batch 175 in epoch 17, gen_loss = 0.895136693153869, disc_loss = 0.04612726673473266
Trained batch 176 in epoch 17, gen_loss = 0.8963222161861463, disc_loss = 0.04603320377810442
Trained batch 177 in epoch 17, gen_loss = 0.8972353514995468, disc_loss = 0.045823132956735374
Trained batch 178 in epoch 17, gen_loss = 0.8964251564534683, disc_loss = 0.04571675310723026
Trained batch 179 in epoch 17, gen_loss = 0.8964263745480113, disc_loss = 0.045534146833233535
Trained batch 180 in epoch 17, gen_loss = 0.8973948634461145, disc_loss = 0.045386095894037526
Trained batch 181 in epoch 17, gen_loss = 0.8965924033424356, disc_loss = 0.04530145895953935
Trained batch 182 in epoch 17, gen_loss = 0.8955939035923755, disc_loss = 0.04540490355759941
Trained batch 183 in epoch 17, gen_loss = 0.8954396498915942, disc_loss = 0.04530173098496364
Trained batch 184 in epoch 17, gen_loss = 0.894948825803963, disc_loss = 0.04512330623645638
Trained batch 185 in epoch 17, gen_loss = 0.89731400740403, disc_loss = 0.04548353989989126
Trained batch 186 in epoch 17, gen_loss = 0.8973216352297023, disc_loss = 0.045388186407738666
Trained batch 187 in epoch 17, gen_loss = 0.8963678892939648, disc_loss = 0.04528853222678237
Trained batch 188 in epoch 17, gen_loss = 0.8960125173525836, disc_loss = 0.045094042186127614
Trained batch 189 in epoch 17, gen_loss = 0.8952669744428835, disc_loss = 0.045077251052287846
Trained batch 190 in epoch 17, gen_loss = 0.8944395616728598, disc_loss = 0.04505158024376834
Trained batch 191 in epoch 17, gen_loss = 0.8947028410620987, disc_loss = 0.04521509178205937
Trained batch 192 in epoch 17, gen_loss = 0.8937315488417532, disc_loss = 0.04524106781090093
Trained batch 193 in epoch 17, gen_loss = 0.8936658819618913, disc_loss = 0.04512165632511767
Trained batch 194 in epoch 17, gen_loss = 0.894263289983456, disc_loss = 0.04496684223174667
Trained batch 195 in epoch 17, gen_loss = 0.8946673728677691, disc_loss = 0.04510675663157005
Trained batch 196 in epoch 17, gen_loss = 0.8934224600416755, disc_loss = 0.04515816322125986
Trained batch 197 in epoch 17, gen_loss = 0.8916743965160967, disc_loss = 0.04585931568425337
Trained batch 198 in epoch 17, gen_loss = 0.8936484610315544, disc_loss = 0.04643953256262232
Trained batch 199 in epoch 17, gen_loss = 0.8925689436495304, disc_loss = 0.046477600520011035
Trained batch 200 in epoch 17, gen_loss = 0.8916380169676311, disc_loss = 0.046648170704031315
Trained batch 201 in epoch 17, gen_loss = 0.8923853536938676, disc_loss = 0.04660202732245152
Trained batch 202 in epoch 17, gen_loss = 0.8923876903620847, disc_loss = 0.04663274066265801
Trained batch 203 in epoch 17, gen_loss = 0.8909861809190582, disc_loss = 0.046980026230562986
Trained batch 204 in epoch 17, gen_loss = 0.8908184465838642, disc_loss = 0.047550609414806454
Trained batch 205 in epoch 17, gen_loss = 0.8893447357763364, disc_loss = 0.047753074683375585
Trained batch 206 in epoch 17, gen_loss = 0.889364593990759, disc_loss = 0.04762133306954146
Trained batch 207 in epoch 17, gen_loss = 0.8896849838873515, disc_loss = 0.047588335195681654
Trained batch 208 in epoch 17, gen_loss = 0.8894885118212996, disc_loss = 0.04752575066698154
Trained batch 209 in epoch 17, gen_loss = 0.8893490883566084, disc_loss = 0.047407383877517924
Trained batch 210 in epoch 17, gen_loss = 0.8890090413850631, disc_loss = 0.04729925086986609
Trained batch 211 in epoch 17, gen_loss = 0.8867070552594257, disc_loss = 0.048551569690593994
Trained batch 212 in epoch 17, gen_loss = 0.8890945660956029, disc_loss = 0.050027147265579636
Trained batch 213 in epoch 17, gen_loss = 0.8891394613223655, disc_loss = 0.05036498670396613
Trained batch 214 in epoch 17, gen_loss = 0.8874550438204477, disc_loss = 0.05063818015461398
Trained batch 215 in epoch 17, gen_loss = 0.8867119579679437, disc_loss = 0.050843270855559106
Trained batch 216 in epoch 17, gen_loss = 0.8865940476068154, disc_loss = 0.05080168496619927
Trained batch 217 in epoch 17, gen_loss = 0.8854207925566839, disc_loss = 0.050964653848696057
Trained batch 218 in epoch 17, gen_loss = 0.8845583547468054, disc_loss = 0.05104042499296401
Trained batch 219 in epoch 17, gen_loss = 0.8846802864562381, disc_loss = 0.050893269832754
Trained batch 220 in epoch 17, gen_loss = 0.8841967818693878, disc_loss = 0.05082812077445884
Trained batch 221 in epoch 17, gen_loss = 0.8835148396524223, disc_loss = 0.05073116285734818
Trained batch 222 in epoch 17, gen_loss = 0.8835175308678717, disc_loss = 0.05071344820264677
Trained batch 223 in epoch 17, gen_loss = 0.8835824167888079, disc_loss = 0.05059186862074837
Trained batch 224 in epoch 17, gen_loss = 0.8828322642379337, disc_loss = 0.050585962987194456
Trained batch 225 in epoch 17, gen_loss = 0.8841842285035986, disc_loss = 0.05043743323097912
Trained batch 226 in epoch 17, gen_loss = 0.8846635727892889, disc_loss = 0.05118024030634682
Trained batch 227 in epoch 17, gen_loss = 0.8836551992255345, disc_loss = 0.05124238554772251
Trained batch 228 in epoch 17, gen_loss = 0.8833033076800634, disc_loss = 0.0514022437550583
Trained batch 229 in epoch 17, gen_loss = 0.8838194371565529, disc_loss = 0.051404897753230254
Trained batch 230 in epoch 17, gen_loss = 0.8831136418885482, disc_loss = 0.051423133433558595
Trained batch 231 in epoch 17, gen_loss = 0.8823920456242973, disc_loss = 0.05133544341139174
Trained batch 232 in epoch 17, gen_loss = 0.8826080180800524, disc_loss = 0.05115438712153248
Trained batch 233 in epoch 17, gen_loss = 0.8829177244860902, disc_loss = 0.05102269274071177
Trained batch 234 in epoch 17, gen_loss = 0.8831084488554204, disc_loss = 0.050906391590437354
Trained batch 235 in epoch 17, gen_loss = 0.8819583749114457, disc_loss = 0.05095133522201835
Trained batch 236 in epoch 17, gen_loss = 0.8819586975413536, disc_loss = 0.051524025940175175
Trained batch 237 in epoch 17, gen_loss = 0.8820414659606308, disc_loss = 0.051423894865594864
Trained batch 238 in epoch 17, gen_loss = 0.8808113714391717, disc_loss = 0.05152571882281032
Trained batch 239 in epoch 17, gen_loss = 0.8809747895846765, disc_loss = 0.05136310392796683
Trained batch 240 in epoch 17, gen_loss = 0.8808591945784715, disc_loss = 0.05126177850160052
Trained batch 241 in epoch 17, gen_loss = 0.8800235268744555, disc_loss = 0.05124729508264683
Trained batch 242 in epoch 17, gen_loss = 0.8809928620548405, disc_loss = 0.05112888950494275
Trained batch 243 in epoch 17, gen_loss = 0.8805132323845488, disc_loss = 0.051130410281895494
Trained batch 244 in epoch 17, gen_loss = 0.8804981641623438, disc_loss = 0.05111633627200309
Trained batch 245 in epoch 17, gen_loss = 0.8803603529203229, disc_loss = 0.050990428152774284
Trained batch 246 in epoch 17, gen_loss = 0.8803541116144976, disc_loss = 0.050980308864205355
Trained batch 247 in epoch 17, gen_loss = 0.8799597211182117, disc_loss = 0.05087371749405359
Trained batch 248 in epoch 17, gen_loss = 0.8809700140273236, disc_loss = 0.050844483995757785
Trained batch 249 in epoch 17, gen_loss = 0.8796839789152145, disc_loss = 0.05121808104775846
Trained batch 250 in epoch 17, gen_loss = 0.8792388100785563, disc_loss = 0.0512069796538537
Trained batch 251 in epoch 17, gen_loss = 0.8792591798636649, disc_loss = 0.051098294118197544
Trained batch 252 in epoch 17, gen_loss = 0.879559865464335, disc_loss = 0.050941401752072714
Trained batch 253 in epoch 17, gen_loss = 0.8794578401826498, disc_loss = 0.05080955581717545
Trained batch 254 in epoch 17, gen_loss = 0.8805684654151692, disc_loss = 0.05228742799886009
Trained batch 255 in epoch 17, gen_loss = 0.8801620214944705, disc_loss = 0.05238649130296835
Trained batch 256 in epoch 17, gen_loss = 0.8802719595135418, disc_loss = 0.05221871982223503
Trained batch 257 in epoch 17, gen_loss = 0.8796927902356598, disc_loss = 0.052224307817356416
Trained batch 258 in epoch 17, gen_loss = 0.8789073522256609, disc_loss = 0.05230098165765865
Trained batch 259 in epoch 17, gen_loss = 0.88047770938048, disc_loss = 0.05230101664872983
Trained batch 260 in epoch 17, gen_loss = 0.8803608258793637, disc_loss = 0.052157192849607646
Trained batch 261 in epoch 17, gen_loss = 0.8797134840078936, disc_loss = 0.05209262788345511
Trained batch 262 in epoch 17, gen_loss = 0.879993970289883, disc_loss = 0.051969882084885365
Trained batch 263 in epoch 17, gen_loss = 0.8797026320614598, disc_loss = 0.05188208485240907
Trained batch 264 in epoch 17, gen_loss = 0.8805895426363315, disc_loss = 0.05175063261270242
Trained batch 265 in epoch 17, gen_loss = 0.880214793005384, disc_loss = 0.05169666293637365
Trained batch 266 in epoch 17, gen_loss = 0.8804851726869519, disc_loss = 0.051559072300052265
Trained batch 267 in epoch 17, gen_loss = 0.8810089729837517, disc_loss = 0.05142002571339427
Trained batch 268 in epoch 17, gen_loss = 0.880627454102704, disc_loss = 0.05140895204493935
Trained batch 269 in epoch 17, gen_loss = 0.8811415143586971, disc_loss = 0.051270574377849695
Trained batch 270 in epoch 17, gen_loss = 0.880768620769916, disc_loss = 0.05120856030861335
Trained batch 271 in epoch 17, gen_loss = 0.8810401562163058, disc_loss = 0.05115916344905546
Trained batch 272 in epoch 17, gen_loss = 0.8818714434192294, disc_loss = 0.05111635165739354
Trained batch 273 in epoch 17, gen_loss = 0.8812498175097208, disc_loss = 0.051115155361089716
Trained batch 274 in epoch 17, gen_loss = 0.8817033194411885, disc_loss = 0.050959255839274686
Trained batch 275 in epoch 17, gen_loss = 0.8817453011870384, disc_loss = 0.050827736829650465
Trained batch 276 in epoch 17, gen_loss = 0.882276169121911, disc_loss = 0.05085168298609582
Trained batch 277 in epoch 17, gen_loss = 0.882444914189174, disc_loss = 0.050706366624803746
Trained batch 278 in epoch 17, gen_loss = 0.882407775809688, disc_loss = 0.05062458117235465
Trained batch 279 in epoch 17, gen_loss = 0.8828379864139216, disc_loss = 0.050476340492189464
Trained batch 280 in epoch 17, gen_loss = 0.8831745618390867, disc_loss = 0.05032250949005958
Trained batch 281 in epoch 17, gen_loss = 0.8824640989092225, disc_loss = 0.050369381412520266
Trained batch 282 in epoch 17, gen_loss = 0.8828754520879617, disc_loss = 0.050225182528551605
Trained batch 283 in epoch 17, gen_loss = 0.8829660095589261, disc_loss = 0.05007007464268048
Trained batch 284 in epoch 17, gen_loss = 0.8834431404607338, disc_loss = 0.049966730478039956
Trained batch 285 in epoch 17, gen_loss = 0.8831483989537179, disc_loss = 0.04986761397050394
Trained batch 286 in epoch 17, gen_loss = 0.8839338109260653, disc_loss = 0.049832338162207855
Trained batch 287 in epoch 17, gen_loss = 0.8843418273867832, disc_loss = 0.04974459063830889
Trained batch 288 in epoch 17, gen_loss = 0.8841154427883122, disc_loss = 0.049687708524993546
Trained batch 289 in epoch 17, gen_loss = 0.8840516975213741, disc_loss = 0.049543778868070966
Trained batch 290 in epoch 17, gen_loss = 0.8843681147622898, disc_loss = 0.0494772738799504
Trained batch 291 in epoch 17, gen_loss = 0.8853125020045124, disc_loss = 0.04934531339278368
Trained batch 292 in epoch 17, gen_loss = 0.8850621293225793, disc_loss = 0.04927927110051743
Trained batch 293 in epoch 17, gen_loss = 0.8849830423690834, disc_loss = 0.049139716168295364
Trained batch 294 in epoch 17, gen_loss = 0.885326209209733, disc_loss = 0.049009484450443314
Trained batch 295 in epoch 17, gen_loss = 0.8851451236452605, disc_loss = 0.0488737484540891
Trained batch 296 in epoch 17, gen_loss = 0.8852916328794627, disc_loss = 0.048732847020795146
Trained batch 297 in epoch 17, gen_loss = 0.8859208017187631, disc_loss = 0.04861861323131461
Trained batch 298 in epoch 17, gen_loss = 0.8851605048745771, disc_loss = 0.04863958203554602
Trained batch 299 in epoch 17, gen_loss = 0.8855223986506462, disc_loss = 0.04850786784819017
Trained batch 300 in epoch 17, gen_loss = 0.8860276522628493, disc_loss = 0.048670607840215346
Trained batch 301 in epoch 17, gen_loss = 0.8855439243924539, disc_loss = 0.04859834320578009
Trained batch 302 in epoch 17, gen_loss = 0.8861179518030815, disc_loss = 0.04848367914022638
Trained batch 303 in epoch 17, gen_loss = 0.8857799973338842, disc_loss = 0.04841124922141286
Trained batch 304 in epoch 17, gen_loss = 0.8856706489305027, disc_loss = 0.04828479462379559
Trained batch 305 in epoch 17, gen_loss = 0.8856168939592013, disc_loss = 0.04817204894284943
Trained batch 306 in epoch 17, gen_loss = 0.8851463698603043, disc_loss = 0.04813295187647015
Trained batch 307 in epoch 17, gen_loss = 0.8853939730045083, disc_loss = 0.0487493250213636
Trained batch 308 in epoch 17, gen_loss = 0.8842526611579661, disc_loss = 0.04939841638050949
Trained batch 309 in epoch 17, gen_loss = 0.8838775406922064, disc_loss = 0.04960192859983973
Trained batch 310 in epoch 17, gen_loss = 0.8841049641466601, disc_loss = 0.049837562526573224
Trained batch 311 in epoch 17, gen_loss = 0.8831386032203833, disc_loss = 0.05014059205318634
Trained batch 312 in epoch 17, gen_loss = 0.8826165165954505, disc_loss = 0.05029890757536117
Trained batch 313 in epoch 17, gen_loss = 0.8824761248887725, disc_loss = 0.05032072241038416
Trained batch 314 in epoch 17, gen_loss = 0.8825420202716948, disc_loss = 0.05033376647218589
Trained batch 315 in epoch 17, gen_loss = 0.882334137736242, disc_loss = 0.05032845470859799
Trained batch 316 in epoch 17, gen_loss = 0.8816275118089248, disc_loss = 0.05046802493435116
Trained batch 317 in epoch 17, gen_loss = 0.8817237151681252, disc_loss = 0.05036634388789769
Trained batch 318 in epoch 17, gen_loss = 0.8808575759300243, disc_loss = 0.05036818625428787
Trained batch 319 in epoch 17, gen_loss = 0.8813080481253565, disc_loss = 0.050277110251772686
Trained batch 320 in epoch 17, gen_loss = 0.8808962831801714, disc_loss = 0.05030657887615472
Trained batch 321 in epoch 17, gen_loss = 0.8806373196544114, disc_loss = 0.0502141864655065
Trained batch 322 in epoch 17, gen_loss = 0.8803135814496976, disc_loss = 0.05016090951992585
Trained batch 323 in epoch 17, gen_loss = 0.8799474284420779, disc_loss = 0.050529077906380004
Trained batch 324 in epoch 17, gen_loss = 0.8793365552792183, disc_loss = 0.05047888985476815
Trained batch 325 in epoch 17, gen_loss = 0.8791780392267953, disc_loss = 0.050416577697383023
Trained batch 326 in epoch 17, gen_loss = 0.8798323196190942, disc_loss = 0.05032626955715842
Trained batch 327 in epoch 17, gen_loss = 0.8796330542280907, disc_loss = 0.05023841098058832
Trained batch 328 in epoch 17, gen_loss = 0.8793614031152522, disc_loss = 0.05017499919941134
Trained batch 329 in epoch 17, gen_loss = 0.879765298962593, disc_loss = 0.05020838333434905
Trained batch 330 in epoch 17, gen_loss = 0.8797429260710575, disc_loss = 0.05014080018384714
Trained batch 331 in epoch 17, gen_loss = 0.8799841491034232, disc_loss = 0.050049600021700454
Trained batch 332 in epoch 17, gen_loss = 0.8804888933807522, disc_loss = 0.04995396423822006
Trained batch 333 in epoch 17, gen_loss = 0.881003055476143, disc_loss = 0.04985086144293898
Trained batch 334 in epoch 17, gen_loss = 0.8804663950827585, disc_loss = 0.04982341771055736
Trained batch 335 in epoch 17, gen_loss = 0.8815526129411799, disc_loss = 0.049849268333110514
Trained batch 336 in epoch 17, gen_loss = 0.8815241066037016, disc_loss = 0.04997075204972388
Trained batch 337 in epoch 17, gen_loss = 0.8811834681139895, disc_loss = 0.05000459897254742
Trained batch 338 in epoch 17, gen_loss = 0.8808255556937867, disc_loss = 0.049925682957731955
Trained batch 339 in epoch 17, gen_loss = 0.8816356170703383, disc_loss = 0.04982339757741155
Trained batch 340 in epoch 17, gen_loss = 0.8815422534418246, disc_loss = 0.04978175194049118
Trained batch 341 in epoch 17, gen_loss = 0.8824299306374545, disc_loss = 0.04983846944952874
Trained batch 342 in epoch 17, gen_loss = 0.8826024366363492, disc_loss = 0.04979525188679207
Trained batch 343 in epoch 17, gen_loss = 0.882308153305636, disc_loss = 0.049861613134474514
Trained batch 344 in epoch 17, gen_loss = 0.8829927853052167, disc_loss = 0.04983574686895894
Trained batch 345 in epoch 17, gen_loss = 0.8829253945564259, disc_loss = 0.04988005864326277
Trained batch 346 in epoch 17, gen_loss = 0.8828600987749072, disc_loss = 0.05038312106911275
Trained batch 347 in epoch 17, gen_loss = 0.8827885595717649, disc_loss = 0.050526161810608004
Trained batch 348 in epoch 17, gen_loss = 0.8828684379344001, disc_loss = 0.05043648227510232
Trained batch 349 in epoch 17, gen_loss = 0.8829775821311133, disc_loss = 0.05041169890734766
Trained batch 350 in epoch 17, gen_loss = 0.88294470726255, disc_loss = 0.05036839079032214
Trained batch 351 in epoch 17, gen_loss = 0.8822813541205092, disc_loss = 0.05041494491822298
Trained batch 352 in epoch 17, gen_loss = 0.8824780324194317, disc_loss = 0.050530032108329424
Trained batch 353 in epoch 17, gen_loss = 0.8827731386248001, disc_loss = 0.050420955224699304
Trained batch 354 in epoch 17, gen_loss = 0.8822577751018632, disc_loss = 0.05055201070540598
Trained batch 355 in epoch 17, gen_loss = 0.8833756673704373, disc_loss = 0.05066502661564586
Trained batch 356 in epoch 17, gen_loss = 0.8836748829575813, disc_loss = 0.05055114265442604
Trained batch 357 in epoch 17, gen_loss = 0.882815831949591, disc_loss = 0.05073800834556573
Trained batch 358 in epoch 17, gen_loss = 0.8832031572263553, disc_loss = 0.0506509182972102
Trained batch 359 in epoch 17, gen_loss = 0.8838876486652427, disc_loss = 0.0505629466393859
Trained batch 360 in epoch 17, gen_loss = 0.88317926380773, disc_loss = 0.0507776438944826
Trained batch 361 in epoch 17, gen_loss = 0.8847502276548365, disc_loss = 0.051188208549978076
Trained batch 362 in epoch 17, gen_loss = 0.8847651424979376, disc_loss = 0.05122810599750765
Trained batch 363 in epoch 17, gen_loss = 0.8839847883516616, disc_loss = 0.0514818222561319
Trained batch 364 in epoch 17, gen_loss = 0.8836818560345532, disc_loss = 0.05144665357210253
Trained batch 365 in epoch 17, gen_loss = 0.8840284988365538, disc_loss = 0.051366121417847896
Trained batch 366 in epoch 17, gen_loss = 0.8839651298295574, disc_loss = 0.05137220997114638
Trained batch 367 in epoch 17, gen_loss = 0.8839824440200692, disc_loss = 0.05130294144644564
Trained batch 368 in epoch 17, gen_loss = 0.8834891090709666, disc_loss = 0.05126280970694775
Trained batch 369 in epoch 17, gen_loss = 0.8829445546543276, disc_loss = 0.051218724463487394
Trained batch 370 in epoch 17, gen_loss = 0.8831402909241597, disc_loss = 0.05110187315309265
Trained batch 371 in epoch 17, gen_loss = 0.8830957580157506, disc_loss = 0.05098848797816543
Trained batch 372 in epoch 17, gen_loss = 0.8841440141520616, disc_loss = 0.05106930067043641
Trained batch 373 in epoch 17, gen_loss = 0.8842816822190973, disc_loss = 0.05096100221318317
Trained batch 374 in epoch 17, gen_loss = 0.8839178248246511, disc_loss = 0.05094077879562974
Trained batch 375 in epoch 17, gen_loss = 0.8841935403327993, disc_loss = 0.05103639222339707
Trained batch 376 in epoch 17, gen_loss = 0.8838220524060632, disc_loss = 0.05103304025047614
Trained batch 377 in epoch 17, gen_loss = 0.8838075808589421, disc_loss = 0.05093623554733183
Trained batch 378 in epoch 17, gen_loss = 0.883884263148723, disc_loss = 0.05084245823358129
Trained batch 379 in epoch 17, gen_loss = 0.8839752845858273, disc_loss = 0.05077197552585092
Trained batch 380 in epoch 17, gen_loss = 0.8846704186260543, disc_loss = 0.05078973929004211
Trained batch 381 in epoch 17, gen_loss = 0.8846170157194138, disc_loss = 0.05070393214475227
Trained batch 382 in epoch 17, gen_loss = 0.8845813015266747, disc_loss = 0.050600167664191044
Trained batch 383 in epoch 17, gen_loss = 0.8846074214670807, disc_loss = 0.05050034926898661
Trained batch 384 in epoch 17, gen_loss = 0.8844307273239285, disc_loss = 0.050420820128849964
Trained batch 385 in epoch 17, gen_loss = 0.8839605326325165, disc_loss = 0.05038665514559982
Trained batch 386 in epoch 17, gen_loss = 0.8842887732871744, disc_loss = 0.05039429775913287
Trained batch 387 in epoch 17, gen_loss = 0.8839347595252942, disc_loss = 0.0503485039723845
Trained batch 388 in epoch 17, gen_loss = 0.8844956217051165, disc_loss = 0.05026539640290457
Trained batch 389 in epoch 17, gen_loss = 0.8837488907269943, disc_loss = 0.050577015039296104
Trained batch 390 in epoch 17, gen_loss = 0.8845265563339224, disc_loss = 0.05055315759333084
Trained batch 391 in epoch 17, gen_loss = 0.8849645794502327, disc_loss = 0.05045513104889732
Trained batch 392 in epoch 17, gen_loss = 0.8851418923634002, disc_loss = 0.050530606168665886
Trained batch 393 in epoch 17, gen_loss = 0.8848765559759236, disc_loss = 0.05051847118387935
Trained batch 394 in epoch 17, gen_loss = 0.8842751195913628, disc_loss = 0.05052233170835844
Trained batch 395 in epoch 17, gen_loss = 0.8842563425200154, disc_loss = 0.05047804476914344
Trained batch 396 in epoch 17, gen_loss = 0.8840969984867711, disc_loss = 0.05040250759764155
Trained batch 397 in epoch 17, gen_loss = 0.8845235535397602, disc_loss = 0.050315536052016684
Trained batch 398 in epoch 17, gen_loss = 0.8847521969997195, disc_loss = 0.050290636026200125
Trained batch 399 in epoch 17, gen_loss = 0.8846235551685094, disc_loss = 0.050281973796663805
Trained batch 400 in epoch 17, gen_loss = 0.8842810608650978, disc_loss = 0.05023261814487359
Trained batch 401 in epoch 17, gen_loss = 0.8849944459709955, disc_loss = 0.0501790560436764
Trained batch 402 in epoch 17, gen_loss = 0.8847993046562962, disc_loss = 0.050218672927228675
Trained batch 403 in epoch 17, gen_loss = 0.8845851038499634, disc_loss = 0.050123565600917554
Trained batch 404 in epoch 17, gen_loss = 0.8837468932440251, disc_loss = 0.05029563429293993
Trained batch 405 in epoch 17, gen_loss = 0.8843675437085147, disc_loss = 0.05025745775169817
Trained batch 406 in epoch 17, gen_loss = 0.8846124453831656, disc_loss = 0.05096352701841943
Trained batch 407 in epoch 17, gen_loss = 0.8845064290160057, disc_loss = 0.05091814975386631
Trained batch 408 in epoch 17, gen_loss = 0.8834979974990369, disc_loss = 0.05127001950098316
Trained batch 409 in epoch 17, gen_loss = 0.8840296312803175, disc_loss = 0.05194727136162905
Trained batch 410 in epoch 17, gen_loss = 0.8834913618808246, disc_loss = 0.05202819895647339
Trained batch 411 in epoch 17, gen_loss = 0.8832170556037171, disc_loss = 0.05206417638776842
Trained batch 412 in epoch 17, gen_loss = 0.8826122870601119, disc_loss = 0.05208548384021796
Trained batch 413 in epoch 17, gen_loss = 0.8819402379258243, disc_loss = 0.0521689153643064
Trained batch 414 in epoch 17, gen_loss = 0.8820051929318761, disc_loss = 0.05251104840784367
Trained batch 415 in epoch 17, gen_loss = 0.8816909398167179, disc_loss = 0.052466006717832685
Trained batch 416 in epoch 17, gen_loss = 0.8810503043287949, disc_loss = 0.05244964701670716
Trained batch 417 in epoch 17, gen_loss = 0.880812491027362, disc_loss = 0.052449564000538164
Trained batch 418 in epoch 17, gen_loss = 0.8808095845658341, disc_loss = 0.052352867634891394
Trained batch 419 in epoch 17, gen_loss = 0.8811049612505095, disc_loss = 0.05230333175887132
Trained batch 420 in epoch 17, gen_loss = 0.8806332075822382, disc_loss = 0.05232260219261688
Trained batch 421 in epoch 17, gen_loss = 0.8807232966778967, disc_loss = 0.052278001926247895
Trained batch 422 in epoch 17, gen_loss = 0.8804126925079535, disc_loss = 0.05219141234606328
Trained batch 423 in epoch 17, gen_loss = 0.8808099113685904, disc_loss = 0.05209124053911886
Trained batch 424 in epoch 17, gen_loss = 0.8808001154310563, disc_loss = 0.052004505982074664
Trained batch 425 in epoch 17, gen_loss = 0.881068239819276, disc_loss = 0.05191568390273887
Trained batch 426 in epoch 17, gen_loss = 0.8813104137464206, disc_loss = 0.0518496154231702
Trained batch 427 in epoch 17, gen_loss = 0.8808467117286174, disc_loss = 0.051838739210452504
Trained batch 428 in epoch 17, gen_loss = 0.8809995996507454, disc_loss = 0.05176655063405633
Trained batch 429 in epoch 17, gen_loss = 0.8807753836692765, disc_loss = 0.051678171625014306
Trained batch 430 in epoch 17, gen_loss = 0.881095236733452, disc_loss = 0.05159599162970957
Trained batch 431 in epoch 17, gen_loss = 0.881397334444854, disc_loss = 0.05150375151424669
Trained batch 432 in epoch 17, gen_loss = 0.8812190904765977, disc_loss = 0.051570846151784235
Trained batch 433 in epoch 17, gen_loss = 0.8813336540339729, disc_loss = 0.05150738754309714
Trained batch 434 in epoch 17, gen_loss = 0.8806260957800108, disc_loss = 0.05174161374847266
Trained batch 435 in epoch 17, gen_loss = 0.880688134068196, disc_loss = 0.05164967246733845
Trained batch 436 in epoch 17, gen_loss = 0.8809474444089274, disc_loss = 0.05183815023621003
Trained batch 437 in epoch 17, gen_loss = 0.8808128541871293, disc_loss = 0.05176612718315735
Trained batch 438 in epoch 17, gen_loss = 0.8813383817536956, disc_loss = 0.05168513130663909
Trained batch 439 in epoch 17, gen_loss = 0.8806976721368053, disc_loss = 0.05179227324816483
Trained batch 440 in epoch 17, gen_loss = 0.8814213523924216, disc_loss = 0.05177526811323638
Trained batch 441 in epoch 17, gen_loss = 0.8814176509148395, disc_loss = 0.0516907096539131
Trained batch 442 in epoch 17, gen_loss = 0.8813335193871914, disc_loss = 0.051626588189532946
Trained batch 443 in epoch 17, gen_loss = 0.8817561202355333, disc_loss = 0.05158165957136835
Trained batch 444 in epoch 17, gen_loss = 0.8820334909337291, disc_loss = 0.05148113707415341
Trained batch 445 in epoch 17, gen_loss = 0.881966699198757, disc_loss = 0.05147062408353616
Trained batch 446 in epoch 17, gen_loss = 0.8822981189161339, disc_loss = 0.051386668764563145
Trained batch 447 in epoch 17, gen_loss = 0.8821801683599395, disc_loss = 0.05130235049520187
Trained batch 448 in epoch 17, gen_loss = 0.8823214540370058, disc_loss = 0.05120539166062307
Trained batch 449 in epoch 17, gen_loss = 0.8824558946159151, disc_loss = 0.0511333817936894
Trained batch 450 in epoch 17, gen_loss = 0.8827425478699467, disc_loss = 0.05103871416189024
Trained batch 451 in epoch 17, gen_loss = 0.8824161708486818, disc_loss = 0.050949541104965704
Trained batch 452 in epoch 17, gen_loss = 0.882431652832768, disc_loss = 0.05086089965782517
Trained batch 453 in epoch 17, gen_loss = 0.8828521149667874, disc_loss = 0.050784009433913535
Trained batch 454 in epoch 17, gen_loss = 0.8829083761671087, disc_loss = 0.050696635253440876
Trained batch 455 in epoch 17, gen_loss = 0.8826604662626459, disc_loss = 0.050613853858841026
Trained batch 456 in epoch 17, gen_loss = 0.8825100388386057, disc_loss = 0.05052830759105752
Trained batch 457 in epoch 17, gen_loss = 0.8825563010820655, disc_loss = 0.05045413641222472
Trained batch 458 in epoch 17, gen_loss = 0.8827628069323912, disc_loss = 0.05035758081494885
Trained batch 459 in epoch 17, gen_loss = 0.8831225800125495, disc_loss = 0.05032879739858048
Trained batch 460 in epoch 17, gen_loss = 0.8829550635142337, disc_loss = 0.05023975391243938
Trained batch 461 in epoch 17, gen_loss = 0.8829656104633818, disc_loss = 0.050144350305360894
Trained batch 462 in epoch 17, gen_loss = 0.8828159147797084, disc_loss = 0.05006238695869693
Trained batch 463 in epoch 17, gen_loss = 0.88250831585249, disc_loss = 0.04998819850353074
Trained batch 464 in epoch 17, gen_loss = 0.8826577059043351, disc_loss = 0.04989335009607897
Trained batch 465 in epoch 17, gen_loss = 0.8830411690627045, disc_loss = 0.0498027830052913
Trained batch 466 in epoch 17, gen_loss = 0.8834917801222913, disc_loss = 0.0497314835792882
Trained batch 467 in epoch 17, gen_loss = 0.8833216103351015, disc_loss = 0.04969777534994432
Trained batch 468 in epoch 17, gen_loss = 0.8835792928489287, disc_loss = 0.04960258218294967
Trained batch 469 in epoch 17, gen_loss = 0.8834839903927864, disc_loss = 0.049523792255352785
Trained batch 470 in epoch 17, gen_loss = 0.8836076209626127, disc_loss = 0.04946440647923706
Trained batch 471 in epoch 17, gen_loss = 0.8837742134297298, disc_loss = 0.04937002144090957
Trained batch 472 in epoch 17, gen_loss = 0.8837478284981992, disc_loss = 0.04928636727913679
Trained batch 473 in epoch 17, gen_loss = 0.8837982410494285, disc_loss = 0.04919730940193158
Trained batch 474 in epoch 17, gen_loss = 0.8840553328238036, disc_loss = 0.04911384064017942
Trained batch 475 in epoch 17, gen_loss = 0.8838144536404049, disc_loss = 0.049036268120388964
Trained batch 476 in epoch 17, gen_loss = 0.8836662356333662, disc_loss = 0.04922119524052652
Trained batch 477 in epoch 17, gen_loss = 0.8833819365276951, disc_loss = 0.04928135462631335
Trained batch 478 in epoch 17, gen_loss = 0.8830135857262542, disc_loss = 0.04926279730733196
Trained batch 479 in epoch 17, gen_loss = 0.8830175741886099, disc_loss = 0.04922573968360666
Trained batch 480 in epoch 17, gen_loss = 0.883022236662942, disc_loss = 0.0491453250279561
Trained batch 481 in epoch 17, gen_loss = 0.8826824333286879, disc_loss = 0.04910376637157717
Trained batch 482 in epoch 17, gen_loss = 0.88308596197616, disc_loss = 0.0490486429701511
Trained batch 483 in epoch 17, gen_loss = 0.8834240592338822, disc_loss = 0.04896191935428257
Trained batch 484 in epoch 17, gen_loss = 0.8831423823980941, disc_loss = 0.048929211580837816
Trained batch 485 in epoch 17, gen_loss = 0.8831739969582224, disc_loss = 0.04884292138452975
Trained batch 486 in epoch 17, gen_loss = 0.8836068587503884, disc_loss = 0.04879990232595887
Trained batch 487 in epoch 17, gen_loss = 0.8836391912009872, disc_loss = 0.048726058680541265
Trained batch 488 in epoch 17, gen_loss = 0.8833593205074591, disc_loss = 0.04872012847714537
Trained batch 489 in epoch 17, gen_loss = 0.8832583402492562, disc_loss = 0.04874865716152197
Trained batch 490 in epoch 17, gen_loss = 0.883147201992101, disc_loss = 0.04871053326886352
Trained batch 491 in epoch 17, gen_loss = 0.8834330877516328, disc_loss = 0.04864170259466713
Trained batch 492 in epoch 17, gen_loss = 0.8836362890853843, disc_loss = 0.04857840900107251
Trained batch 493 in epoch 17, gen_loss = 0.8833363640766877, disc_loss = 0.048658256063629925
Trained batch 494 in epoch 17, gen_loss = 0.8840753310256534, disc_loss = 0.04863425767463114
Trained batch 495 in epoch 17, gen_loss = 0.884216737663073, disc_loss = 0.04855607972281324
Trained batch 496 in epoch 17, gen_loss = 0.8840891242147212, disc_loss = 0.04852425831255749
Trained batch 497 in epoch 17, gen_loss = 0.8835197574043848, disc_loss = 0.04862999233387291
Trained batch 498 in epoch 17, gen_loss = 0.8835627599684652, disc_loss = 0.04855594078997124
Trained batch 499 in epoch 17, gen_loss = 0.8837176117300988, disc_loss = 0.04857860322762281
Trained batch 500 in epoch 17, gen_loss = 0.8835234559343722, disc_loss = 0.04856408486038655
Trained batch 501 in epoch 17, gen_loss = 0.8833302307532603, disc_loss = 0.048544988255999774
Trained batch 502 in epoch 17, gen_loss = 0.8837196773018088, disc_loss = 0.04853086764266933
Trained batch 503 in epoch 17, gen_loss = 0.8837125808118828, disc_loss = 0.04847639440355586
Trained batch 504 in epoch 17, gen_loss = 0.883899871134522, disc_loss = 0.048434931996029496
Trained batch 505 in epoch 17, gen_loss = 0.8833942855653084, disc_loss = 0.04857171919995647
Trained batch 506 in epoch 17, gen_loss = 0.8830674492278278, disc_loss = 0.04853974771088897
Trained batch 507 in epoch 17, gen_loss = 0.8834194506364544, disc_loss = 0.0484699019511399
Trained batch 508 in epoch 17, gen_loss = 0.8841936186043827, disc_loss = 0.04851980068334808
Trained batch 509 in epoch 17, gen_loss = 0.8847545357895833, disc_loss = 0.048580277449104425
Trained batch 510 in epoch 17, gen_loss = 0.883919261906245, disc_loss = 0.04892429078194639
Trained batch 511 in epoch 17, gen_loss = 0.8840948332799599, disc_loss = 0.04885505588117667
Trained batch 512 in epoch 17, gen_loss = 0.8840064034592106, disc_loss = 0.0487824993827117
Trained batch 513 in epoch 17, gen_loss = 0.8844272360959405, disc_loss = 0.0490026839235109
Trained batch 514 in epoch 17, gen_loss = 0.8844928349106057, disc_loss = 0.04896940659388032
Trained batch 515 in epoch 17, gen_loss = 0.8842831930910894, disc_loss = 0.04891969912140377
Trained batch 516 in epoch 17, gen_loss = 0.8837119004251417, disc_loss = 0.04909430163492749
Trained batch 517 in epoch 17, gen_loss = 0.8843654221549457, disc_loss = 0.049380289357421656
Trained batch 518 in epoch 17, gen_loss = 0.8838801096859236, disc_loss = 0.049413677932145454
Trained batch 519 in epoch 17, gen_loss = 0.8839245423674583, disc_loss = 0.049350921647587365
Trained batch 520 in epoch 17, gen_loss = 0.8838584648441673, disc_loss = 0.049293167677291465
Trained batch 521 in epoch 17, gen_loss = 0.8839167522059547, disc_loss = 0.04921289324007529
Trained batch 522 in epoch 17, gen_loss = 0.883918655192191, disc_loss = 0.04918491234646729
Trained batch 523 in epoch 17, gen_loss = 0.8832140857254276, disc_loss = 0.04928240341841748
Trained batch 524 in epoch 17, gen_loss = 0.8841248531568618, disc_loss = 0.049330620308894485
Trained batch 525 in epoch 17, gen_loss = 0.8844433729412892, disc_loss = 0.049262349625709446
Trained batch 526 in epoch 17, gen_loss = 0.8841869753044969, disc_loss = 0.04929379034571816
Trained batch 527 in epoch 17, gen_loss = 0.8840888753307589, disc_loss = 0.0492566038870295
Trained batch 528 in epoch 17, gen_loss = 0.8840549018072046, disc_loss = 0.049220288053528176
Trained batch 529 in epoch 17, gen_loss = 0.8838619300779307, disc_loss = 0.04925069347603844
Trained batch 530 in epoch 17, gen_loss = 0.8844552043467592, disc_loss = 0.04944666723147203
Trained batch 531 in epoch 17, gen_loss = 0.8840103355565465, disc_loss = 0.04948020821412731
Trained batch 532 in epoch 17, gen_loss = 0.8842438074705972, disc_loss = 0.049407654316959586
Trained batch 533 in epoch 17, gen_loss = 0.8844843435376771, disc_loss = 0.0493659185871747
Trained batch 534 in epoch 17, gen_loss = 0.8848737616405309, disc_loss = 0.04929385154690837
Trained batch 535 in epoch 17, gen_loss = 0.8847619801092503, disc_loss = 0.049240389756281484
Trained batch 536 in epoch 17, gen_loss = 0.8844566801406818, disc_loss = 0.04926941578590365
Trained batch 537 in epoch 17, gen_loss = 0.8844104236386523, disc_loss = 0.049208875427881195
Trained batch 538 in epoch 17, gen_loss = 0.8847202732744376, disc_loss = 0.04923965423998591
Trained batch 539 in epoch 17, gen_loss = 0.8844627064687235, disc_loss = 0.04931407885505231
Trained batch 540 in epoch 17, gen_loss = 0.8851157131565256, disc_loss = 0.049249237703672455
Trained batch 541 in epoch 17, gen_loss = 0.8850262106784595, disc_loss = 0.049202037845459866
Trained batch 542 in epoch 17, gen_loss = 0.8853044919326599, disc_loss = 0.04912602701901868
Trained batch 543 in epoch 17, gen_loss = 0.8855227583690601, disc_loss = 0.04920478412446648
Trained batch 544 in epoch 17, gen_loss = 0.8854856422188085, disc_loss = 0.04915146660999557
Trained batch 545 in epoch 17, gen_loss = 0.8851766279547206, disc_loss = 0.04922082922046138
Trained batch 546 in epoch 17, gen_loss = 0.8849456709089402, disc_loss = 0.04917257690931614
Trained batch 547 in epoch 17, gen_loss = 0.8849599539798542, disc_loss = 0.049117026647491666
Trained batch 548 in epoch 17, gen_loss = 0.8853271910835919, disc_loss = 0.0490551650539407
Trained batch 549 in epoch 17, gen_loss = 0.8857501342079857, disc_loss = 0.049081348550759935
Trained batch 550 in epoch 17, gen_loss = 0.885274900931412, disc_loss = 0.04907981683322636
Trained batch 551 in epoch 17, gen_loss = 0.8850271531205246, disc_loss = 0.049033235405079104
Trained batch 552 in epoch 17, gen_loss = 0.885396674140668, disc_loss = 0.048974534490770556
Trained batch 553 in epoch 17, gen_loss = 0.8848075567600099, disc_loss = 0.049300958241910976
Trained batch 554 in epoch 17, gen_loss = 0.8854838605399604, disc_loss = 0.04941034203328125
Trained batch 555 in epoch 17, gen_loss = 0.8858288104156796, disc_loss = 0.04941439989488572
Trained batch 556 in epoch 17, gen_loss = 0.8854977810618265, disc_loss = 0.04940304509656674
Trained batch 557 in epoch 17, gen_loss = 0.8856440898979009, disc_loss = 0.049339745623496856
Trained batch 558 in epoch 17, gen_loss = 0.885384560164484, disc_loss = 0.04938415806050777
Trained batch 559 in epoch 17, gen_loss = 0.8855332777968474, disc_loss = 0.04932276392438715
Trained batch 560 in epoch 17, gen_loss = 0.8857177973006073, disc_loss = 0.04932333046982128
Trained batch 561 in epoch 17, gen_loss = 0.8856266419870573, disc_loss = 0.04927262563168923
Trained batch 562 in epoch 17, gen_loss = 0.8856531636753049, disc_loss = 0.049196430287600144
Trained batch 563 in epoch 17, gen_loss = 0.8854942329175083, disc_loss = 0.049173810383047356
Trained batch 564 in epoch 17, gen_loss = 0.8856031362989307, disc_loss = 0.04912954454384415
Trained batch 565 in epoch 17, gen_loss = 0.8858522553747198, disc_loss = 0.0491093687948445
Trained batch 566 in epoch 17, gen_loss = 0.8860340674507975, disc_loss = 0.04903422139923382
Trained batch 567 in epoch 17, gen_loss = 0.8857544203039626, disc_loss = 0.04911585440973974
Trained batch 568 in epoch 17, gen_loss = 0.8862308791735469, disc_loss = 0.049084248914103464
Trained batch 569 in epoch 17, gen_loss = 0.8861989652901365, disc_loss = 0.04904488227656928
Trained batch 570 in epoch 17, gen_loss = 0.8862582660180675, disc_loss = 0.04897784839274978
Trained batch 571 in epoch 17, gen_loss = 0.886715122036167, disc_loss = 0.04893013935168176
Trained batch 572 in epoch 17, gen_loss = 0.886759176200181, disc_loss = 0.04887100013239507
Trained batch 573 in epoch 17, gen_loss = 0.8864853420531709, disc_loss = 0.048861872806385785
Trained batch 574 in epoch 17, gen_loss = 0.8868995035212973, disc_loss = 0.04880251867858612
Trained batch 575 in epoch 17, gen_loss = 0.8863389623454876, disc_loss = 0.048798746606432054
Trained batch 576 in epoch 17, gen_loss = 0.8863469462460827, disc_loss = 0.048737315758836795
Trained batch 577 in epoch 17, gen_loss = 0.8863062245004317, disc_loss = 0.04866883762996115
Trained batch 578 in epoch 17, gen_loss = 0.8862471305644574, disc_loss = 0.04861095791283693
Trained batch 579 in epoch 17, gen_loss = 0.8862453175002131, disc_loss = 0.048537762320985826
Trained batch 580 in epoch 17, gen_loss = 0.8863228879574039, disc_loss = 0.04854527378627924
Trained batch 581 in epoch 17, gen_loss = 0.8863009563631209, disc_loss = 0.04849361233282002
Trained batch 582 in epoch 17, gen_loss = 0.8858740457539698, disc_loss = 0.04859222479940969
Trained batch 583 in epoch 17, gen_loss = 0.8861631107044546, disc_loss = 0.048541672246320146
Trained batch 584 in epoch 17, gen_loss = 0.8861683880162036, disc_loss = 0.0486351177852569
Trained batch 585 in epoch 17, gen_loss = 0.8863170241536541, disc_loss = 0.0485948389260982
Trained batch 586 in epoch 17, gen_loss = 0.8859731444305212, disc_loss = 0.04855900254256046
Trained batch 587 in epoch 17, gen_loss = 0.8862263564349843, disc_loss = 0.04849830888081849
Trained batch 588 in epoch 17, gen_loss = 0.8864025209472216, disc_loss = 0.04844952723745048
Trained batch 589 in epoch 17, gen_loss = 0.8865542219857038, disc_loss = 0.048383984679229934
Trained batch 590 in epoch 17, gen_loss = 0.8864247914901643, disc_loss = 0.04837083631445687
Trained batch 591 in epoch 17, gen_loss = 0.8863600479388559, disc_loss = 0.048313117382349446
Trained batch 592 in epoch 17, gen_loss = 0.8863900269665967, disc_loss = 0.0482411878207042
Trained batch 593 in epoch 17, gen_loss = 0.8868304377653783, disc_loss = 0.04820460097171266
Trained batch 594 in epoch 17, gen_loss = 0.8867416569164821, disc_loss = 0.04815446213279076
Trained batch 595 in epoch 17, gen_loss = 0.8866293969370375, disc_loss = 0.04812067860953085
Trained batch 596 in epoch 17, gen_loss = 0.8863078875957022, disc_loss = 0.04816582901372108
Trained batch 597 in epoch 17, gen_loss = 0.8858272997431931, disc_loss = 0.0482261514541908
Trained batch 598 in epoch 17, gen_loss = 0.8860904374385318, disc_loss = 0.04822779553266046
Trained batch 599 in epoch 17, gen_loss = 0.8862253467241923, disc_loss = 0.04816587440747147
Trained batch 600 in epoch 17, gen_loss = 0.8860419093074894, disc_loss = 0.04812507558313389
Trained batch 601 in epoch 17, gen_loss = 0.8864112988460896, disc_loss = 0.04809935665782231
Trained batch 602 in epoch 17, gen_loss = 0.8860458570530956, disc_loss = 0.04818034928313659
Trained batch 603 in epoch 17, gen_loss = 0.8861243330090252, disc_loss = 0.04821598318957458
Trained batch 604 in epoch 17, gen_loss = 0.8857895342771672, disc_loss = 0.04824780451195422
Trained batch 605 in epoch 17, gen_loss = 0.88625171908451, disc_loss = 0.04830230044726614
Trained batch 606 in epoch 17, gen_loss = 0.8863836221482844, disc_loss = 0.048247509558502544
Trained batch 607 in epoch 17, gen_loss = 0.8863664909609055, disc_loss = 0.048205434324029885
Trained batch 608 in epoch 17, gen_loss = 0.8861117733914669, disc_loss = 0.04819662633240345
Trained batch 609 in epoch 17, gen_loss = 0.8862843656149066, disc_loss = 0.04813107597550041
Trained batch 610 in epoch 17, gen_loss = 0.8867154140909448, disc_loss = 0.04820807425475964
Trained batch 611 in epoch 17, gen_loss = 0.8866537466547848, disc_loss = 0.04814570986443607
Trained batch 612 in epoch 17, gen_loss = 0.8868360818890918, disc_loss = 0.04808170815814305
Trained batch 613 in epoch 17, gen_loss = 0.8871669967322086, disc_loss = 0.04803348267193071
Trained batch 614 in epoch 17, gen_loss = 0.8874748330775315, disc_loss = 0.04796996344017183
Trained batch 615 in epoch 17, gen_loss = 0.8872589285110498, disc_loss = 0.04798112560725807
Trained batch 616 in epoch 17, gen_loss = 0.8874538750470747, disc_loss = 0.04791673542961865
Trained batch 617 in epoch 17, gen_loss = 0.8874675810915752, disc_loss = 0.04785448702995614
Trained batch 618 in epoch 17, gen_loss = 0.8878892149794275, disc_loss = 0.04783306912607807
Trained batch 619 in epoch 17, gen_loss = 0.8876024560582253, disc_loss = 0.04783933810033505
Trained batch 620 in epoch 17, gen_loss = 0.8879373963328375, disc_loss = 0.047912940403203604
Trained batch 621 in epoch 17, gen_loss = 0.8874548523180738, disc_loss = 0.04793825709272979
Trained batch 622 in epoch 17, gen_loss = 0.8875418022203215, disc_loss = 0.04790216094977185
Trained batch 623 in epoch 17, gen_loss = 0.8874878618770685, disc_loss = 0.04788840132487866
Trained batch 624 in epoch 17, gen_loss = 0.8876168511390686, disc_loss = 0.04805752120241523
Trained batch 625 in epoch 17, gen_loss = 0.8874290996847062, disc_loss = 0.0480823958785044
Trained batch 626 in epoch 17, gen_loss = 0.8874042558898195, disc_loss = 0.048059886677169865
Trained batch 627 in epoch 17, gen_loss = 0.8871462845308765, disc_loss = 0.04828118518881713
Trained batch 628 in epoch 17, gen_loss = 0.8865608927365896, disc_loss = 0.04840247193499452
Trained batch 629 in epoch 17, gen_loss = 0.8863631123588198, disc_loss = 0.0483964079628802
Trained batch 630 in epoch 17, gen_loss = 0.8860203350780506, disc_loss = 0.04843484622938485
Trained batch 631 in epoch 17, gen_loss = 0.8866207188443292, disc_loss = 0.04859318128784034
Trained batch 632 in epoch 17, gen_loss = 0.8864917515013455, disc_loss = 0.04887989808041691
Trained batch 633 in epoch 17, gen_loss = 0.8861126235042837, disc_loss = 0.049062161200330225
Trained batch 634 in epoch 17, gen_loss = 0.8856025612260413, disc_loss = 0.04919876416001146
Trained batch 635 in epoch 17, gen_loss = 0.8855823322474582, disc_loss = 0.04917629438806794
Trained batch 636 in epoch 17, gen_loss = 0.8853045128391152, disc_loss = 0.04923655715766633
Trained batch 637 in epoch 17, gen_loss = 0.8848680848238236, disc_loss = 0.049275696180544816
Trained batch 638 in epoch 17, gen_loss = 0.884828333750204, disc_loss = 0.04925937532827678
Trained batch 639 in epoch 17, gen_loss = 0.8852912086993456, disc_loss = 0.04935794423436164
Trained batch 640 in epoch 17, gen_loss = 0.8848946719385347, disc_loss = 0.049509442281326664
Trained batch 641 in epoch 17, gen_loss = 0.8845224412059487, disc_loss = 0.04954456953067808
Trained batch 642 in epoch 17, gen_loss = 0.8844865128560163, disc_loss = 0.049518249618269006
Trained batch 643 in epoch 17, gen_loss = 0.8847502336739013, disc_loss = 0.04952959529693984
Trained batch 644 in epoch 17, gen_loss = 0.8847471838773683, disc_loss = 0.049590975597009875
Trained batch 645 in epoch 17, gen_loss = 0.8842410973904672, disc_loss = 0.04983067664392754
Trained batch 646 in epoch 17, gen_loss = 0.8845979482902809, disc_loss = 0.0497900483002699
Trained batch 647 in epoch 17, gen_loss = 0.884381963055075, disc_loss = 0.049772248665922905
Trained batch 648 in epoch 17, gen_loss = 0.884349570344152, disc_loss = 0.04981196388668267
Trained batch 649 in epoch 17, gen_loss = 0.8844919447715466, disc_loss = 0.04975839487563532
Trained batch 650 in epoch 17, gen_loss = 0.8840977051474166, disc_loss = 0.04978061878206795
Trained batch 651 in epoch 17, gen_loss = 0.8843888889975343, disc_loss = 0.04972695237656975
Trained batch 652 in epoch 17, gen_loss = 0.8843820265752433, disc_loss = 0.04966439080038101
Trained batch 653 in epoch 17, gen_loss = 0.8840256549349619, disc_loss = 0.04966497036560071
Trained batch 654 in epoch 17, gen_loss = 0.8843307770845544, disc_loss = 0.04970483393514998
Trained batch 655 in epoch 17, gen_loss = 0.8843515677968177, disc_loss = 0.04964937152775436
Trained batch 656 in epoch 17, gen_loss = 0.8840403199377307, disc_loss = 0.049740832963110694
Trained batch 657 in epoch 17, gen_loss = 0.8840165284085781, disc_loss = 0.049713305314425325
Trained batch 658 in epoch 17, gen_loss = 0.883812305507602, disc_loss = 0.04967302664879806
Trained batch 659 in epoch 17, gen_loss = 0.8837170012972572, disc_loss = 0.04964424573012035
Trained batch 660 in epoch 17, gen_loss = 0.8835234368803281, disc_loss = 0.04959180138500777
Trained batch 661 in epoch 17, gen_loss = 0.8836136083948648, disc_loss = 0.049625412226876865
Trained batch 662 in epoch 17, gen_loss = 0.8832409068110482, disc_loss = 0.049788646175923615
Trained batch 663 in epoch 17, gen_loss = 0.8827660586460527, disc_loss = 0.04984275450304442
Trained batch 664 in epoch 17, gen_loss = 0.8834680919360397, disc_loss = 0.05004875477389398
Trained batch 665 in epoch 17, gen_loss = 0.8831339565304307, disc_loss = 0.05009314461538496
Trained batch 666 in epoch 17, gen_loss = 0.883121500576454, disc_loss = 0.050034540394709254
Trained batch 667 in epoch 17, gen_loss = 0.8831125488895142, disc_loss = 0.04998512454344863
Trained batch 668 in epoch 17, gen_loss = 0.8834466978751668, disc_loss = 0.04993281666375975
Trained batch 669 in epoch 17, gen_loss = 0.8833681927688086, disc_loss = 0.049872352312833296
Trained batch 670 in epoch 17, gen_loss = 0.8830270130303862, disc_loss = 0.04991059274733311
Trained batch 671 in epoch 17, gen_loss = 0.8832193807299648, disc_loss = 0.04988455375686975
Trained batch 672 in epoch 17, gen_loss = 0.8836101485751182, disc_loss = 0.049867617308866526
Trained batch 673 in epoch 17, gen_loss = 0.8832685591028423, disc_loss = 0.049910990274663274
Trained batch 674 in epoch 17, gen_loss = 0.8831922235312285, disc_loss = 0.04987001395818812
Trained batch 675 in epoch 17, gen_loss = 0.8832001797193606, disc_loss = 0.049898635165506876
Trained batch 676 in epoch 17, gen_loss = 0.8832545604452249, disc_loss = 0.049839729624091916
Trained batch 677 in epoch 17, gen_loss = 0.8832288781801859, disc_loss = 0.049781486438037856
Trained batch 678 in epoch 17, gen_loss = 0.8828879682585838, disc_loss = 0.04985164198270054
Trained batch 679 in epoch 17, gen_loss = 0.8831442333319608, disc_loss = 0.0499502444989048
Trained batch 680 in epoch 17, gen_loss = 0.883262882236167, disc_loss = 0.04989138414136923
Trained batch 681 in epoch 17, gen_loss = 0.883283350824261, disc_loss = 0.049858424578359095
Trained batch 682 in epoch 17, gen_loss = 0.8832483199120964, disc_loss = 0.0498054117792031
Trained batch 683 in epoch 17, gen_loss = 0.8829588158088818, disc_loss = 0.049822664631078595
Trained batch 684 in epoch 17, gen_loss = 0.8833925111450418, disc_loss = 0.050628108408193304
Trained batch 685 in epoch 17, gen_loss = 0.8831123022400603, disc_loss = 0.050655316639523246
Trained batch 686 in epoch 17, gen_loss = 0.8829057371946054, disc_loss = 0.05063702302932024
Trained batch 687 in epoch 17, gen_loss = 0.8825889620496783, disc_loss = 0.050649455290282315
Trained batch 688 in epoch 17, gen_loss = 0.8825313243879809, disc_loss = 0.050603318566805174
Trained batch 689 in epoch 17, gen_loss = 0.8825169648813165, disc_loss = 0.05055769923197079
Trained batch 690 in epoch 17, gen_loss = 0.8826637274104503, disc_loss = 0.0505186262036446
Trained batch 691 in epoch 17, gen_loss = 0.8828027266470683, disc_loss = 0.050474453224219125
Trained batch 692 in epoch 17, gen_loss = 0.8825066824152012, disc_loss = 0.05047083229651678
Trained batch 693 in epoch 17, gen_loss = 0.8825718423818649, disc_loss = 0.050414939375422484
Trained batch 694 in epoch 17, gen_loss = 0.8825522805289399, disc_loss = 0.05038761991752888
Trained batch 695 in epoch 17, gen_loss = 0.8826882511206057, disc_loss = 0.05032743866242276
Trained batch 696 in epoch 17, gen_loss = 0.8828110632458581, disc_loss = 0.050287093065940966
Trained batch 697 in epoch 17, gen_loss = 0.8823573311796161, disc_loss = 0.050341054489622616
Trained batch 698 in epoch 17, gen_loss = 0.8822215370013138, disc_loss = 0.05029031088660992
Trained batch 699 in epoch 17, gen_loss = 0.8826628755671637, disc_loss = 0.050248861566319
Trained batch 700 in epoch 17, gen_loss = 0.882963730758335, disc_loss = 0.050212695188262366
Trained batch 701 in epoch 17, gen_loss = 0.8829217238134128, disc_loss = 0.050213583342417906
Trained batch 702 in epoch 17, gen_loss = 0.8827347589251326, disc_loss = 0.05019948438437891
Trained batch 703 in epoch 17, gen_loss = 0.882162872532552, disc_loss = 0.050448735782331576
Trained batch 704 in epoch 17, gen_loss = 0.88286614164393, disc_loss = 0.050643615507197086
Trained batch 705 in epoch 17, gen_loss = 0.8828817187220112, disc_loss = 0.05068282581266892
Trained batch 706 in epoch 17, gen_loss = 0.882403912773564, disc_loss = 0.050741753806366655
Trained batch 707 in epoch 17, gen_loss = 0.8822484282450488, disc_loss = 0.05071383281439901
Trained batch 708 in epoch 17, gen_loss = 0.8820464737156383, disc_loss = 0.05067732156555159
Trained batch 709 in epoch 17, gen_loss = 0.8821820608327087, disc_loss = 0.05063692550174892
Trained batch 710 in epoch 17, gen_loss = 0.8824290471405587, disc_loss = 0.050593303257806435
Trained batch 711 in epoch 17, gen_loss = 0.8826072577680095, disc_loss = 0.05053993572776593
Trained batch 712 in epoch 17, gen_loss = 0.8823805173015193, disc_loss = 0.05053853749155183
Trained batch 713 in epoch 17, gen_loss = 0.8822009600177199, disc_loss = 0.050504935984251924
Trained batch 714 in epoch 17, gen_loss = 0.8820443848629932, disc_loss = 0.05070545745336197
Trained batch 715 in epoch 17, gen_loss = 0.8814742904385375, disc_loss = 0.05089166128875261
Trained batch 716 in epoch 17, gen_loss = 0.8812875844527821, disc_loss = 0.05090694625717763
Trained batch 717 in epoch 17, gen_loss = 0.8816535001760738, disc_loss = 0.05089799603797537
Trained batch 718 in epoch 17, gen_loss = 0.8817458113393797, disc_loss = 0.050867606504264605
Trained batch 719 in epoch 17, gen_loss = 0.8817900162190199, disc_loss = 0.05082881207021678
Trained batch 720 in epoch 17, gen_loss = 0.8816155713986755, disc_loss = 0.050814153350781176
Trained batch 721 in epoch 17, gen_loss = 0.8813597987150552, disc_loss = 0.05078957046748467
Trained batch 722 in epoch 17, gen_loss = 0.8815853166629665, disc_loss = 0.05078045369021564
Trained batch 723 in epoch 17, gen_loss = 0.8817321040271395, disc_loss = 0.05072210139005821
Trained batch 724 in epoch 17, gen_loss = 0.8818588087065466, disc_loss = 0.05069009038459124
Trained batch 725 in epoch 17, gen_loss = 0.8817057381730434, disc_loss = 0.05067376965418273
Trained batch 726 in epoch 17, gen_loss = 0.8814004629727407, disc_loss = 0.0506781032148805
Trained batch 727 in epoch 17, gen_loss = 0.8817662039546521, disc_loss = 0.05065838058778484
Trained batch 728 in epoch 17, gen_loss = 0.8820707934955838, disc_loss = 0.05068653864423209
Trained batch 729 in epoch 17, gen_loss = 0.8818440388735026, disc_loss = 0.05066670347324075
Trained batch 730 in epoch 17, gen_loss = 0.8814615621530896, disc_loss = 0.05066607653057628
Trained batch 731 in epoch 17, gen_loss = 0.8815644429436799, disc_loss = 0.05076727099128862
Trained batch 732 in epoch 17, gen_loss = 0.8810909395735066, disc_loss = 0.05087525049976669
Trained batch 733 in epoch 17, gen_loss = 0.8811226396615889, disc_loss = 0.05081780582770441
Trained batch 734 in epoch 17, gen_loss = 0.881570260257137, disc_loss = 0.050824842840863936
Trained batch 735 in epoch 17, gen_loss = 0.8814415990415475, disc_loss = 0.05080364869322891
Trained batch 736 in epoch 17, gen_loss = 0.8813098636297876, disc_loss = 0.05075521809156362
Trained batch 737 in epoch 17, gen_loss = 0.8813775090909586, disc_loss = 0.0507140050428922
Trained batch 738 in epoch 17, gen_loss = 0.8811852639599002, disc_loss = 0.05068135989013258
Trained batch 739 in epoch 17, gen_loss = 0.881055863282165, disc_loss = 0.05064185752118057
Trained batch 740 in epoch 17, gen_loss = 0.8813729531932295, disc_loss = 0.05084389091284591
Trained batch 741 in epoch 17, gen_loss = 0.880983840864945, disc_loss = 0.05093707584128326
Trained batch 742 in epoch 17, gen_loss = 0.8810046436728892, disc_loss = 0.050913388724908894
Trained batch 743 in epoch 17, gen_loss = 0.8808981077244846, disc_loss = 0.050899419233187915
Trained batch 744 in epoch 17, gen_loss = 0.8808794211621253, disc_loss = 0.050861953302042795
Trained batch 745 in epoch 17, gen_loss = 0.8809047518322999, disc_loss = 0.050957745708270503
Trained batch 746 in epoch 17, gen_loss = 0.8806056450887856, disc_loss = 0.051042926312615
Trained batch 747 in epoch 17, gen_loss = 0.8807327734196887, disc_loss = 0.050998158355114016
Trained batch 748 in epoch 17, gen_loss = 0.8806196664856655, disc_loss = 0.050962639647412884
Trained batch 749 in epoch 17, gen_loss = 0.8810330281654993, disc_loss = 0.05100589855574071
Trained batch 750 in epoch 17, gen_loss = 0.8807092487177106, disc_loss = 0.05107872839955075
Trained batch 751 in epoch 17, gen_loss = 0.8806898356514409, disc_loss = 0.05105970000434528
Trained batch 752 in epoch 17, gen_loss = 0.8807104214491597, disc_loss = 0.05103820002888877
Trained batch 753 in epoch 17, gen_loss = 0.8806781510696488, disc_loss = 0.050993427822603514
Trained batch 754 in epoch 17, gen_loss = 0.880371045316292, disc_loss = 0.051015715025340684
Trained batch 755 in epoch 17, gen_loss = 0.8806891263556228, disc_loss = 0.05099036935877015
Trained batch 756 in epoch 17, gen_loss = 0.8807047535044041, disc_loss = 0.0513087867456519
Trained batch 757 in epoch 17, gen_loss = 0.8801947327669818, disc_loss = 0.05143335785060669
Trained batch 758 in epoch 17, gen_loss = 0.8800574910577892, disc_loss = 0.05143465728551758
Trained batch 759 in epoch 17, gen_loss = 0.8800285890306297, disc_loss = 0.05141503968288338
Trained batch 760 in epoch 17, gen_loss = 0.8798305600215821, disc_loss = 0.05137386709101664
Trained batch 761 in epoch 17, gen_loss = 0.880224361233511, disc_loss = 0.05140262038026523
Trained batch 762 in epoch 17, gen_loss = 0.8800275771442904, disc_loss = 0.05139056418938159
Trained batch 763 in epoch 17, gen_loss = 0.8800714033514417, disc_loss = 0.05133302186808369
Trained batch 764 in epoch 17, gen_loss = 0.8797095479139315, disc_loss = 0.051381204533542876
Trained batch 765 in epoch 17, gen_loss = 0.8799042975233367, disc_loss = 0.05133826442989314
Trained batch 766 in epoch 17, gen_loss = 0.8796832545562082, disc_loss = 0.05135479341947135
Trained batch 767 in epoch 17, gen_loss = 0.8797879492631182, disc_loss = 0.05134434660249099
Trained batch 768 in epoch 17, gen_loss = 0.879651816559396, disc_loss = 0.05130562869836764
Trained batch 769 in epoch 17, gen_loss = 0.8796988196574248, disc_loss = 0.05126192743962558
Trained batch 770 in epoch 17, gen_loss = 0.8796644189555667, disc_loss = 0.05125452645772877
Trained batch 771 in epoch 17, gen_loss = 0.8793970167714079, disc_loss = 0.051268472563634614
Trained batch 772 in epoch 17, gen_loss = 0.8791624786088876, disc_loss = 0.05129431149612674
Trained batch 773 in epoch 17, gen_loss = 0.8796231140230977, disc_loss = 0.05137735895044832
Trained batch 774 in epoch 17, gen_loss = 0.8799642080260861, disc_loss = 0.051454127537266865
Trained batch 775 in epoch 17, gen_loss = 0.8795743818519656, disc_loss = 0.05162152595225165
Trained batch 776 in epoch 17, gen_loss = 0.8794469562199738, disc_loss = 0.05160828879309226
Trained batch 777 in epoch 17, gen_loss = 0.8795192142455315, disc_loss = 0.05157957040790976
Trained batch 778 in epoch 17, gen_loss = 0.879549270684667, disc_loss = 0.05154904241187065
Trained batch 779 in epoch 17, gen_loss = 0.8793347691496213, disc_loss = 0.051609633089855125
Trained batch 780 in epoch 17, gen_loss = 0.8795844152779646, disc_loss = 0.0517037058596126
Trained batch 781 in epoch 17, gen_loss = 0.8797890453616066, disc_loss = 0.05171200553076747
Trained batch 782 in epoch 17, gen_loss = 0.8795639145191602, disc_loss = 0.05169304607835709
Trained batch 783 in epoch 17, gen_loss = 0.8794412807922583, disc_loss = 0.05167220706388601
Trained batch 784 in epoch 17, gen_loss = 0.8792851011084902, disc_loss = 0.051678986174119694
Trained batch 785 in epoch 17, gen_loss = 0.8793378948179517, disc_loss = 0.051640459692399505
Trained batch 786 in epoch 17, gen_loss = 0.879418128895487, disc_loss = 0.051699016994076016
Trained batch 787 in epoch 17, gen_loss = 0.8796164636608913, disc_loss = 0.05164484963527772
Trained batch 788 in epoch 17, gen_loss = 0.8795436803907798, disc_loss = 0.05164685979643683
Trained batch 789 in epoch 17, gen_loss = 0.8791045599723164, disc_loss = 0.05182077820719326
Testing Epoch 17
Training Epoch 18
Trained batch 0 in epoch 18, gen_loss = 1.356597900390625, disc_loss = 0.13952568173408508
Trained batch 1 in epoch 18, gen_loss = 1.1061972975730896, disc_loss = 0.08736508898437023
Trained batch 2 in epoch 18, gen_loss = 0.9744886159896851, disc_loss = 0.07259407639503479
Trained batch 3 in epoch 18, gen_loss = 0.9889635741710663, disc_loss = 0.0665422584861517
Trained batch 4 in epoch 18, gen_loss = 0.9384454131126404, disc_loss = 0.06501025110483169
Trained batch 5 in epoch 18, gen_loss = 0.9147485991319021, disc_loss = 0.06214210266868273
Trained batch 6 in epoch 18, gen_loss = 0.8715335045542035, disc_loss = 0.06887061893939972
Trained batch 7 in epoch 18, gen_loss = 0.8801658824086189, disc_loss = 0.0634349633473903
Trained batch 8 in epoch 18, gen_loss = 0.8902360532018874, disc_loss = 0.06179867788321442
Trained batch 9 in epoch 18, gen_loss = 0.8824242889881134, disc_loss = 0.06256272364407778
Trained batch 10 in epoch 18, gen_loss = 0.8533179489049044, disc_loss = 0.06946820037608797
Trained batch 11 in epoch 18, gen_loss = 0.8443472931782404, disc_loss = 0.06591149279847741
Trained batch 12 in epoch 18, gen_loss = 0.86385211119285, disc_loss = 0.06703265799352756
Trained batch 13 in epoch 18, gen_loss = 0.8820236708436694, disc_loss = 0.06852100510150194
Trained batch 14 in epoch 18, gen_loss = 0.8722911715507508, disc_loss = 0.07157574035227299
Trained batch 15 in epoch 18, gen_loss = 0.8499306067824364, disc_loss = 0.08179634937550873
Trained batch 16 in epoch 18, gen_loss = 0.8768915218465468, disc_loss = 0.0844253480215283
Trained batch 17 in epoch 18, gen_loss = 0.8682423035303751, disc_loss = 0.08229811893155177
Trained batch 18 in epoch 18, gen_loss = 0.8732586628512332, disc_loss = 0.08402561308129837
Trained batch 19 in epoch 18, gen_loss = 0.868099159002304, disc_loss = 0.08305396093055606
Trained batch 20 in epoch 18, gen_loss = 0.8592867709341503, disc_loss = 0.0858335533134994
Trained batch 21 in epoch 18, gen_loss = 0.8521659726446326, disc_loss = 0.08638016261499036
Trained batch 22 in epoch 18, gen_loss = 0.8574481813803964, disc_loss = 0.0862007720152969
Trained batch 23 in epoch 18, gen_loss = 0.8658380632599195, disc_loss = 0.08808373807308574
Trained batch 24 in epoch 18, gen_loss = 0.852907772064209, disc_loss = 0.08897575877606868
Trained batch 25 in epoch 18, gen_loss = 0.8562544996921833, disc_loss = 0.09154950562291421
Trained batch 26 in epoch 18, gen_loss = 0.8568651234662091, disc_loss = 0.08918622418962142
Trained batch 27 in epoch 18, gen_loss = 0.8448207633835929, disc_loss = 0.09140682812514049
Trained batch 28 in epoch 18, gen_loss = 0.8504161341436978, disc_loss = 0.09344881316968079
Trained batch 29 in epoch 18, gen_loss = 0.8536812464396158, disc_loss = 0.09359008477379878
Trained batch 30 in epoch 18, gen_loss = 0.8439048624807789, disc_loss = 0.09591119478066121
Trained batch 31 in epoch 18, gen_loss = 0.8379292618483305, disc_loss = 0.09549285500543192
Trained batch 32 in epoch 18, gen_loss = 0.8408914063916062, disc_loss = 0.09502173988430788
Trained batch 33 in epoch 18, gen_loss = 0.8472956436521867, disc_loss = 0.093068203121862
Trained batch 34 in epoch 18, gen_loss = 0.8455318910734994, disc_loss = 0.09132148405270916
Trained batch 35 in epoch 18, gen_loss = 0.8419984877109528, disc_loss = 0.08929190867476994
Trained batch 36 in epoch 18, gen_loss = 0.8393867241369711, disc_loss = 0.08786355633590673
Trained batch 37 in epoch 18, gen_loss = 0.8397184563310522, disc_loss = 0.08615142523654197
Trained batch 38 in epoch 18, gen_loss = 0.8379991115667881, disc_loss = 0.08464582880529073
Trained batch 39 in epoch 18, gen_loss = 0.8449348628520965, disc_loss = 0.08473858018405736
Trained batch 40 in epoch 18, gen_loss = 0.8391766722609357, disc_loss = 0.08556067602845227
Trained batch 41 in epoch 18, gen_loss = 0.8411454061667124, disc_loss = 0.08420632473592247
Trained batch 42 in epoch 18, gen_loss = 0.8446554680203282, disc_loss = 0.08247008176823688
Trained batch 43 in epoch 18, gen_loss = 0.8448868475177072, disc_loss = 0.08120917700315741
Trained batch 44 in epoch 18, gen_loss = 0.8465949402915107, disc_loss = 0.08003690571834644
Trained batch 45 in epoch 18, gen_loss = 0.8453256228695745, disc_loss = 0.07923484980331166
Trained batch 46 in epoch 18, gen_loss = 0.8474385281826587, disc_loss = 0.07778681111224789
Trained batch 47 in epoch 18, gen_loss = 0.8547345499197642, disc_loss = 0.07688772237937276
Trained batch 48 in epoch 18, gen_loss = 0.8533109803589023, disc_loss = 0.07595426184410344
Trained batch 49 in epoch 18, gen_loss = 0.8519298374652863, disc_loss = 0.07532250670716166
Trained batch 50 in epoch 18, gen_loss = 0.8532264337820166, disc_loss = 0.07501502654643036
Trained batch 51 in epoch 18, gen_loss = 0.8513321922375605, disc_loss = 0.07409939189584783
Trained batch 52 in epoch 18, gen_loss = 0.8537059729953982, disc_loss = 0.07282133566496789
Trained batch 53 in epoch 18, gen_loss = 0.8571669106130246, disc_loss = 0.07452231808565557
Trained batch 54 in epoch 18, gen_loss = 0.8500787827101621, disc_loss = 0.07739102106372064
Trained batch 55 in epoch 18, gen_loss = 0.8550615592726639, disc_loss = 0.07653332472546026
Trained batch 56 in epoch 18, gen_loss = 0.854432472534347, disc_loss = 0.07593858337618019
Trained batch 57 in epoch 18, gen_loss = 0.8510921181275927, disc_loss = 0.07582994605864174
Trained batch 58 in epoch 18, gen_loss = 0.8527281188358695, disc_loss = 0.07523975638925272
Trained batch 59 in epoch 18, gen_loss = 0.8548082545399666, disc_loss = 0.07461502742177496
Trained batch 60 in epoch 18, gen_loss = 0.8526554005067857, disc_loss = 0.0742630160138866
Trained batch 61 in epoch 18, gen_loss = 0.8522451832409828, disc_loss = 0.07340596346635252
Trained batch 62 in epoch 18, gen_loss = 0.8534087571832869, disc_loss = 0.07247889625085961
Trained batch 63 in epoch 18, gen_loss = 0.8542583924718201, disc_loss = 0.07224978178419406
Trained batch 64 in epoch 18, gen_loss = 0.8515548215462612, disc_loss = 0.07248839561899122
Trained batch 65 in epoch 18, gen_loss = 0.8522902767766606, disc_loss = 0.07184300239367242
Trained batch 66 in epoch 18, gen_loss = 0.8479319308231126, disc_loss = 0.0716682945016716
Trained batch 67 in epoch 18, gen_loss = 0.8534089480252827, disc_loss = 0.07475202060167623
Trained batch 68 in epoch 18, gen_loss = 0.8500411031038865, disc_loss = 0.07479752287727551
Trained batch 69 in epoch 18, gen_loss = 0.8493689158133098, disc_loss = 0.07393645465240947
Trained batch 70 in epoch 18, gen_loss = 0.8501163851207411, disc_loss = 0.07301186048097803
Trained batch 71 in epoch 18, gen_loss = 0.8537044405109353, disc_loss = 0.07409724802063364
Trained batch 72 in epoch 18, gen_loss = 0.8516846793155147, disc_loss = 0.07432476198300719
Trained batch 73 in epoch 18, gen_loss = 0.8472731528249947, disc_loss = 0.07562537835533353
Trained batch 74 in epoch 18, gen_loss = 0.8490758653481801, disc_loss = 0.07869925639902552
Trained batch 75 in epoch 18, gen_loss = 0.8494368991569469, disc_loss = 0.07792917871235036
Trained batch 76 in epoch 18, gen_loss = 0.8490410528399728, disc_loss = 0.07766756272040211
Trained batch 77 in epoch 18, gen_loss = 0.8474616511509969, disc_loss = 0.07834047415198232
Trained batch 78 in epoch 18, gen_loss = 0.8456606378283682, disc_loss = 0.07816925542900645
Trained batch 79 in epoch 18, gen_loss = 0.8413543727248907, disc_loss = 0.07844328071805648
Trained batch 80 in epoch 18, gen_loss = 0.8423793312208152, disc_loss = 0.07789638791992157
Trained batch 81 in epoch 18, gen_loss = 0.8434641430290734, disc_loss = 0.07752374025266164
Trained batch 82 in epoch 18, gen_loss = 0.8431156927562622, disc_loss = 0.07694108408864543
Trained batch 83 in epoch 18, gen_loss = 0.842130527255081, disc_loss = 0.07662449565915656
Trained batch 84 in epoch 18, gen_loss = 0.8429613839177524, disc_loss = 0.07596264583989978
Trained batch 85 in epoch 18, gen_loss = 0.8440381908832595, disc_loss = 0.07571919056110431
Trained batch 86 in epoch 18, gen_loss = 0.8440495479380947, disc_loss = 0.07555447657453432
Trained batch 87 in epoch 18, gen_loss = 0.8409939757124945, disc_loss = 0.07575428233460778
Trained batch 88 in epoch 18, gen_loss = 0.8417260697048702, disc_loss = 0.07504087601254662
Trained batch 89 in epoch 18, gen_loss = 0.8460093110799789, disc_loss = 0.07528908896880845
Trained batch 90 in epoch 18, gen_loss = 0.8471694598486136, disc_loss = 0.07460271266729131
Trained batch 91 in epoch 18, gen_loss = 0.8456878937456919, disc_loss = 0.07420281825445431
Trained batch 92 in epoch 18, gen_loss = 0.8434029699012797, disc_loss = 0.07404507675097995
Trained batch 93 in epoch 18, gen_loss = 0.844763919711113, disc_loss = 0.07348397491559228
Trained batch 94 in epoch 18, gen_loss = 0.8490525248803591, disc_loss = 0.07535555667096847
Trained batch 95 in epoch 18, gen_loss = 0.8483549806599816, disc_loss = 0.07483585487837748
Trained batch 96 in epoch 18, gen_loss = 0.844662355700719, disc_loss = 0.07608816932560396
Trained batch 97 in epoch 18, gen_loss = 0.8439881384980922, disc_loss = 0.07559457704976048
Trained batch 98 in epoch 18, gen_loss = 0.8453425340580217, disc_loss = 0.07674345895742075
Trained batch 99 in epoch 18, gen_loss = 0.844982268512249, disc_loss = 0.07624253074172885
Trained batch 100 in epoch 18, gen_loss = 0.8452737328439656, disc_loss = 0.07581745780137654
Trained batch 101 in epoch 18, gen_loss = 0.845288535251337, disc_loss = 0.07536168723805424
Trained batch 102 in epoch 18, gen_loss = 0.8441877472169191, disc_loss = 0.0750752405932589
Trained batch 103 in epoch 18, gen_loss = 0.8440881294126694, disc_loss = 0.07462162340435988
Trained batch 104 in epoch 18, gen_loss = 0.8453284538927532, disc_loss = 0.07426251004937859
Trained batch 105 in epoch 18, gen_loss = 0.8455997753255772, disc_loss = 0.07439585018217704
Trained batch 106 in epoch 18, gen_loss = 0.8457259666696887, disc_loss = 0.07396176630178485
Trained batch 107 in epoch 18, gen_loss = 0.8456495738139859, disc_loss = 0.07351966535551818
Trained batch 108 in epoch 18, gen_loss = 0.8456215664334253, disc_loss = 0.07304474204317282
Trained batch 109 in epoch 18, gen_loss = 0.8495679543776946, disc_loss = 0.0732521688269282
Trained batch 110 in epoch 18, gen_loss = 0.8482610049011471, disc_loss = 0.07284474458864278
Trained batch 111 in epoch 18, gen_loss = 0.8474817741662264, disc_loss = 0.07279068609516669
Trained batch 112 in epoch 18, gen_loss = 0.8488498026818301, disc_loss = 0.07225695014642798
Trained batch 113 in epoch 18, gen_loss = 0.8483802014798448, disc_loss = 0.07183416837646642
Trained batch 114 in epoch 18, gen_loss = 0.847773791136949, disc_loss = 0.07162576087386063
Trained batch 115 in epoch 18, gen_loss = 0.8512156757301298, disc_loss = 0.07139081449713558
Trained batch 116 in epoch 18, gen_loss = 0.8490472479253752, disc_loss = 0.07191571433686166
Trained batch 117 in epoch 18, gen_loss = 0.851235988534103, disc_loss = 0.07139618034569263
Trained batch 118 in epoch 18, gen_loss = 0.8520456239455888, disc_loss = 0.07086389847178043
Trained batch 119 in epoch 18, gen_loss = 0.8535491195817788, disc_loss = 0.07033487651885177
Trained batch 120 in epoch 18, gen_loss = 0.8540414840229287, disc_loss = 0.06993958357459873
Trained batch 121 in epoch 18, gen_loss = 0.8558250785362526, disc_loss = 0.06963205496688969
Trained batch 122 in epoch 18, gen_loss = 0.8555185724564685, disc_loss = 0.06947228558194952
Trained batch 123 in epoch 18, gen_loss = 0.8549075412654108, disc_loss = 0.06908407236915082
Trained batch 124 in epoch 18, gen_loss = 0.8528233392238617, disc_loss = 0.06895762327685952
Trained batch 125 in epoch 18, gen_loss = 0.8519543539437037, disc_loss = 0.06862499624387258
Trained batch 126 in epoch 18, gen_loss = 0.852465840540533, disc_loss = 0.0683307733980748
Trained batch 127 in epoch 18, gen_loss = 0.8548345209565014, disc_loss = 0.06809345051078708
Trained batch 128 in epoch 18, gen_loss = 0.8584592524887056, disc_loss = 0.06793955142082747
Trained batch 129 in epoch 18, gen_loss = 0.8587548473706612, disc_loss = 0.06772855629499715
Trained batch 130 in epoch 18, gen_loss = 0.8577583807570334, disc_loss = 0.06758403476995935
Trained batch 131 in epoch 18, gen_loss = 0.8589198767687335, disc_loss = 0.06731137179303914
Trained batch 132 in epoch 18, gen_loss = 0.8588506393414691, disc_loss = 0.06687386750236601
Trained batch 133 in epoch 18, gen_loss = 0.8595500550608137, disc_loss = 0.06641300793028256
Trained batch 134 in epoch 18, gen_loss = 0.8592653939017543, disc_loss = 0.06620898211236906
Trained batch 135 in epoch 18, gen_loss = 0.8590340147561887, disc_loss = 0.06588893963421202
Trained batch 136 in epoch 18, gen_loss = 0.8583646801701428, disc_loss = 0.06547587702431491
Trained batch 137 in epoch 18, gen_loss = 0.8609174686497536, disc_loss = 0.06518493548535026
Trained batch 138 in epoch 18, gen_loss = 0.8610793650150299, disc_loss = 0.06478290320474574
Trained batch 139 in epoch 18, gen_loss = 0.8589676799518722, disc_loss = 0.06472756231004106
Trained batch 140 in epoch 18, gen_loss = 0.8598354160785675, disc_loss = 0.06439099005416882
Trained batch 141 in epoch 18, gen_loss = 0.8603933992939936, disc_loss = 0.06420047753359336
Trained batch 142 in epoch 18, gen_loss = 0.8612868954668512, disc_loss = 0.0638359373767528
Trained batch 143 in epoch 18, gen_loss = 0.8608144995652967, disc_loss = 0.06355891612474807
Trained batch 144 in epoch 18, gen_loss = 0.861565474189561, disc_loss = 0.06317428524509586
Trained batch 145 in epoch 18, gen_loss = 0.8620090625465733, disc_loss = 0.06279350665066238
Trained batch 146 in epoch 18, gen_loss = 0.8616344038726521, disc_loss = 0.06251276066197323
Trained batch 147 in epoch 18, gen_loss = 0.8621418035110912, disc_loss = 0.062145797104725765
Trained batch 148 in epoch 18, gen_loss = 0.8638104874415685, disc_loss = 0.06201689337511491
Trained batch 149 in epoch 18, gen_loss = 0.8620176062981287, disc_loss = 0.06198119950480759
Trained batch 150 in epoch 18, gen_loss = 0.8626086058600849, disc_loss = 0.06163759013045801
Trained batch 151 in epoch 18, gen_loss = 0.8628858533736906, disc_loss = 0.06127562803694194
Trained batch 152 in epoch 18, gen_loss = 0.8650189071309333, disc_loss = 0.0613732241867171
Trained batch 153 in epoch 18, gen_loss = 0.8667895106913207, disc_loss = 0.06104811953755652
Trained batch 154 in epoch 18, gen_loss = 0.8642452630304521, disc_loss = 0.06203113905184211
Trained batch 155 in epoch 18, gen_loss = 0.8657949465589646, disc_loss = 0.06324905267236038
Trained batch 156 in epoch 18, gen_loss = 0.8659685225623428, disc_loss = 0.06297684203726565
Trained batch 157 in epoch 18, gen_loss = 0.8655547807111016, disc_loss = 0.06267456674087746
Trained batch 158 in epoch 18, gen_loss = 0.8670763637659684, disc_loss = 0.06239142195386051
Trained batch 159 in epoch 18, gen_loss = 0.8668861476704478, disc_loss = 0.06207499961310532
Trained batch 160 in epoch 18, gen_loss = 0.8656663655864526, disc_loss = 0.061925774830630664
Trained batch 161 in epoch 18, gen_loss = 0.8653546341775377, disc_loss = 0.06163732702613889
Trained batch 162 in epoch 18, gen_loss = 0.8651934048515156, disc_loss = 0.061307627293481236
Trained batch 163 in epoch 18, gen_loss = 0.8656351615379496, disc_loss = 0.06100288872527549
Trained batch 164 in epoch 18, gen_loss = 0.8669504727378036, disc_loss = 0.06069067426759637
Trained batch 165 in epoch 18, gen_loss = 0.8673395717359451, disc_loss = 0.06045620929146836
Trained batch 166 in epoch 18, gen_loss = 0.8667328527230702, disc_loss = 0.06020612702677082
Trained batch 167 in epoch 18, gen_loss = 0.8664006489728179, disc_loss = 0.059904221237437535
Trained batch 168 in epoch 18, gen_loss = 0.8652410371416419, disc_loss = 0.05969779753572577
Trained batch 169 in epoch 18, gen_loss = 0.8658598757842008, disc_loss = 0.05941768160692471
Trained batch 170 in epoch 18, gen_loss = 0.8670045867649435, disc_loss = 0.05911827948194934
Trained batch 171 in epoch 18, gen_loss = 0.8670764775123707, disc_loss = 0.05907998301446178
Trained batch 172 in epoch 18, gen_loss = 0.8677608748047339, disc_loss = 0.05879639972787286
Trained batch 173 in epoch 18, gen_loss = 0.8665741447402143, disc_loss = 0.05886806304373875
Trained batch 174 in epoch 18, gen_loss = 0.8666856982026782, disc_loss = 0.0585729777600084
Trained batch 175 in epoch 18, gen_loss = 0.8665143977850676, disc_loss = 0.05828530457802117
Trained batch 176 in epoch 18, gen_loss = 0.8689703680364426, disc_loss = 0.05894576591876267
Trained batch 177 in epoch 18, gen_loss = 0.8680995968955286, disc_loss = 0.05883980831235982
Trained batch 178 in epoch 18, gen_loss = 0.8663676219612526, disc_loss = 0.05909880750172631
Trained batch 179 in epoch 18, gen_loss = 0.8666704351703326, disc_loss = 0.058903031051158905
Trained batch 180 in epoch 18, gen_loss = 0.8686242355496844, disc_loss = 0.05917002326546453
Trained batch 181 in epoch 18, gen_loss = 0.8671201724600006, disc_loss = 0.05930893016713006
Trained batch 182 in epoch 18, gen_loss = 0.8675250917510257, disc_loss = 0.05944472095354007
Trained batch 183 in epoch 18, gen_loss = 0.8668273028148257, disc_loss = 0.05924373189918697
Trained batch 184 in epoch 18, gen_loss = 0.8659542842491254, disc_loss = 0.0592678037950316
Trained batch 185 in epoch 18, gen_loss = 0.865083302060763, disc_loss = 0.05981410319806747
Trained batch 186 in epoch 18, gen_loss = 0.863835087593864, disc_loss = 0.05989241593064153
Trained batch 187 in epoch 18, gen_loss = 0.864358236339498, disc_loss = 0.05965129418813802
Trained batch 188 in epoch 18, gen_loss = 0.8654259060110364, disc_loss = 0.059739669932732505
Trained batch 189 in epoch 18, gen_loss = 0.8647089482922303, disc_loss = 0.05965431640414815
Trained batch 190 in epoch 18, gen_loss = 0.8639420553339714, disc_loss = 0.059506534554883445
Trained batch 191 in epoch 18, gen_loss = 0.8650276091260215, disc_loss = 0.05951765823798875
Trained batch 192 in epoch 18, gen_loss = 0.8654817081794838, disc_loss = 0.059279601417790734
Trained batch 193 in epoch 18, gen_loss = 0.8649107652533915, disc_loss = 0.05914527062115442
Trained batch 194 in epoch 18, gen_loss = 0.8648904010271414, disc_loss = 0.05897045471251775
Trained batch 195 in epoch 18, gen_loss = 0.8668910585799996, disc_loss = 0.058992178991855104
Trained batch 196 in epoch 18, gen_loss = 0.8673996730201741, disc_loss = 0.05873598432083269
Trained batch 197 in epoch 18, gen_loss = 0.8669941502087044, disc_loss = 0.05854514886088895
Trained batch 198 in epoch 18, gen_loss = 0.8674399941111329, disc_loss = 0.05829904891606701
Trained batch 199 in epoch 18, gen_loss = 0.8665484775602817, disc_loss = 0.0585305953817442
Trained batch 200 in epoch 18, gen_loss = 0.8668450225348496, disc_loss = 0.05826759157211182
Trained batch 201 in epoch 18, gen_loss = 0.8672973650811923, disc_loss = 0.05809931157820738
Trained batch 202 in epoch 18, gen_loss = 0.8679111601390275, disc_loss = 0.05786822331160894
Trained batch 203 in epoch 18, gen_loss = 0.8679642483007675, disc_loss = 0.05766596596268024
Trained batch 204 in epoch 18, gen_loss = 0.8677395400477619, disc_loss = 0.05747996106652952
Trained batch 205 in epoch 18, gen_loss = 0.8681670865676936, disc_loss = 0.05729493001041916
Trained batch 206 in epoch 18, gen_loss = 0.8682962317685574, disc_loss = 0.0571642553721721
Trained batch 207 in epoch 18, gen_loss = 0.8672403551351565, disc_loss = 0.05738149759305928
Trained batch 208 in epoch 18, gen_loss = 0.8668672144412994, disc_loss = 0.057156032321163626
Trained batch 209 in epoch 18, gen_loss = 0.8684449237017404, disc_loss = 0.05711703286727979
Trained batch 210 in epoch 18, gen_loss = 0.8695074705433506, disc_loss = 0.05687544797216123
Trained batch 211 in epoch 18, gen_loss = 0.8682957838447589, disc_loss = 0.05684911143825442
Trained batch 212 in epoch 18, gen_loss = 0.8682595582355356, disc_loss = 0.056721638402783534
Trained batch 213 in epoch 18, gen_loss = 0.8681404622637223, disc_loss = 0.05674652792252252
Trained batch 214 in epoch 18, gen_loss = 0.8679589394913163, disc_loss = 0.05657621125235807
Trained batch 215 in epoch 18, gen_loss = 0.8678678659101328, disc_loss = 0.0564099720256679
Trained batch 216 in epoch 18, gen_loss = 0.8682851564774315, disc_loss = 0.05619307946036076
Trained batch 217 in epoch 18, gen_loss = 0.8677315043473462, disc_loss = 0.05625887343728351
Trained batch 218 in epoch 18, gen_loss = 0.8694244082932059, disc_loss = 0.056194614759352925
Trained batch 219 in epoch 18, gen_loss = 0.8717940567569299, disc_loss = 0.05613066905008798
Trained batch 220 in epoch 18, gen_loss = 0.8715133530791529, disc_loss = 0.05602204992237809
Trained batch 221 in epoch 18, gen_loss = 0.8723785145594193, disc_loss = 0.055857446434832106
Trained batch 222 in epoch 18, gen_loss = 0.8713514247550024, disc_loss = 0.055834186037860375
Trained batch 223 in epoch 18, gen_loss = 0.8717026219570211, disc_loss = 0.055640216975007206
Trained batch 224 in epoch 18, gen_loss = 0.8713946619298722, disc_loss = 0.05594344790611002
Trained batch 225 in epoch 18, gen_loss = 0.8702710261650844, disc_loss = 0.05605572939281706
Trained batch 226 in epoch 18, gen_loss = 0.8697219069571221, disc_loss = 0.056166581538739706
Trained batch 227 in epoch 18, gen_loss = 0.8698934328399206, disc_loss = 0.055989902801484914
Trained batch 228 in epoch 18, gen_loss = 0.8707992360321195, disc_loss = 0.05596506300353848
Trained batch 229 in epoch 18, gen_loss = 0.871011989660885, disc_loss = 0.05596038236728181
Trained batch 230 in epoch 18, gen_loss = 0.8698762336592654, disc_loss = 0.056228380513204126
Trained batch 231 in epoch 18, gen_loss = 0.8708013292273571, disc_loss = 0.05601887024561714
Trained batch 232 in epoch 18, gen_loss = 0.8712335997640831, disc_loss = 0.05585080251105674
Trained batch 233 in epoch 18, gen_loss = 0.8724214998830078, disc_loss = 0.05564420943299674
Trained batch 234 in epoch 18, gen_loss = 0.872709288115197, disc_loss = 0.05551920586285439
Trained batch 235 in epoch 18, gen_loss = 0.8740408154109777, disc_loss = 0.05535734655588108
Trained batch 236 in epoch 18, gen_loss = 0.8745062935955917, disc_loss = 0.05521715802576723
Trained batch 237 in epoch 18, gen_loss = 0.874626132495263, disc_loss = 0.055081434500943716
Trained batch 238 in epoch 18, gen_loss = 0.8745156121303845, disc_loss = 0.05513655557979101
Trained batch 239 in epoch 18, gen_loss = 0.8732905495911837, disc_loss = 0.055450072744861245
Trained batch 240 in epoch 18, gen_loss = 0.8740153034445656, disc_loss = 0.05530189478545763
Trained batch 241 in epoch 18, gen_loss = 0.8753178093797904, disc_loss = 0.055275786606487166
Trained batch 242 in epoch 18, gen_loss = 0.8748035542513608, disc_loss = 0.05521036494415974
Trained batch 243 in epoch 18, gen_loss = 0.8750550784781331, disc_loss = 0.05504747517941306
Trained batch 244 in epoch 18, gen_loss = 0.874906657544934, disc_loss = 0.05488276875064689
Trained batch 245 in epoch 18, gen_loss = 0.8742625377769393, disc_loss = 0.05484858601603929
Trained batch 246 in epoch 18, gen_loss = 0.875927050465997, disc_loss = 0.05513946692033215
Trained batch 247 in epoch 18, gen_loss = 0.8755434175893184, disc_loss = 0.05499980028253049
Trained batch 248 in epoch 18, gen_loss = 0.875418578644833, disc_loss = 0.054868288700988734
Trained batch 249 in epoch 18, gen_loss = 0.8758021153211594, disc_loss = 0.054691353891044854
Trained batch 250 in epoch 18, gen_loss = 0.8758557527901167, disc_loss = 0.05455397747353135
Trained batch 251 in epoch 18, gen_loss = 0.8761139908243739, disc_loss = 0.05439383512185443
Trained batch 252 in epoch 18, gen_loss = 0.8755118652530338, disc_loss = 0.05439883659744687
Trained batch 253 in epoch 18, gen_loss = 0.8764345855928781, disc_loss = 0.054435776597930224
Trained batch 254 in epoch 18, gen_loss = 0.8769542043115578, disc_loss = 0.05438580021408259
Trained batch 255 in epoch 18, gen_loss = 0.8762676814803854, disc_loss = 0.0544475801216322
Trained batch 256 in epoch 18, gen_loss = 0.8753266706772815, disc_loss = 0.05444096655726201
Trained batch 257 in epoch 18, gen_loss = 0.876332005442575, disc_loss = 0.05428597117348235
Trained batch 258 in epoch 18, gen_loss = 0.8772567447318074, disc_loss = 0.05413673954753342
Trained batch 259 in epoch 18, gen_loss = 0.877184357207555, disc_loss = 0.0540301488354229
Trained batch 260 in epoch 18, gen_loss = 0.8767936577970498, disc_loss = 0.05391410185859121
Trained batch 261 in epoch 18, gen_loss = 0.8767463875408391, disc_loss = 0.053843118278807355
Trained batch 262 in epoch 18, gen_loss = 0.8766912560725847, disc_loss = 0.053691512965260806
Trained batch 263 in epoch 18, gen_loss = 0.8762405337483594, disc_loss = 0.05363232324210306
Trained batch 264 in epoch 18, gen_loss = 0.8761355797074876, disc_loss = 0.05355441540057929
Trained batch 265 in epoch 18, gen_loss = 0.8764031351284873, disc_loss = 0.053399795319716954
Trained batch 266 in epoch 18, gen_loss = 0.8760118307022566, disc_loss = 0.053274187496566816
Trained batch 267 in epoch 18, gen_loss = 0.8760444322851166, disc_loss = 0.053212163431236324
Trained batch 268 in epoch 18, gen_loss = 0.8759804725868551, disc_loss = 0.05307867086135876
Trained batch 269 in epoch 18, gen_loss = 0.8756946887131091, disc_loss = 0.0529676503225885
Trained batch 270 in epoch 18, gen_loss = 0.8771715068509218, disc_loss = 0.05348101342474952
Trained batch 271 in epoch 18, gen_loss = 0.876307303962462, disc_loss = 0.053496506260297096
Trained batch 272 in epoch 18, gen_loss = 0.8758051269875341, disc_loss = 0.05343892841835271
Trained batch 273 in epoch 18, gen_loss = 0.8747812142989931, disc_loss = 0.053580754038870984
Trained batch 274 in epoch 18, gen_loss = 0.8754831685803154, disc_loss = 0.05377685792405497
Trained batch 275 in epoch 18, gen_loss = 0.8753681484123935, disc_loss = 0.0536321889595601
Trained batch 276 in epoch 18, gen_loss = 0.8752087220173019, disc_loss = 0.05350557033523971
Trained batch 277 in epoch 18, gen_loss = 0.8748492138634483, disc_loss = 0.05346081406548083
Trained batch 278 in epoch 18, gen_loss = 0.874327372372364, disc_loss = 0.05362112118485367
Trained batch 279 in epoch 18, gen_loss = 0.875356098903077, disc_loss = 0.05369323122847293
Trained batch 280 in epoch 18, gen_loss = 0.8750912734834325, disc_loss = 0.05368326506925435
Trained batch 281 in epoch 18, gen_loss = 0.874618540101863, disc_loss = 0.05362421377885637
Trained batch 282 in epoch 18, gen_loss = 0.8751561444766108, disc_loss = 0.05355754443987309
Trained batch 283 in epoch 18, gen_loss = 0.8743903407118689, disc_loss = 0.05351914254896028
Trained batch 284 in epoch 18, gen_loss = 0.8747783465343609, disc_loss = 0.05336570717525064
Trained batch 285 in epoch 18, gen_loss = 0.8752090990334958, disc_loss = 0.05320902742523622
Trained batch 286 in epoch 18, gen_loss = 0.8751295739557685, disc_loss = 0.05319407717925123
Trained batch 287 in epoch 18, gen_loss = 0.8748070714581344, disc_loss = 0.053093904784570135
Trained batch 288 in epoch 18, gen_loss = 0.8745065652169158, disc_loss = 0.05307318076852284
Trained batch 289 in epoch 18, gen_loss = 0.876676679993498, disc_loss = 0.05409410038384898
Trained batch 290 in epoch 18, gen_loss = 0.8756272265386745, disc_loss = 0.05428175958468742
Trained batch 291 in epoch 18, gen_loss = 0.875398859687864, disc_loss = 0.0541575759623761
Trained batch 292 in epoch 18, gen_loss = 0.8753414594476133, disc_loss = 0.05419357262119498
Trained batch 293 in epoch 18, gen_loss = 0.8751792926974848, disc_loss = 0.0543006002066695
Trained batch 294 in epoch 18, gen_loss = 0.8744029411825083, disc_loss = 0.054389830931263455
Trained batch 295 in epoch 18, gen_loss = 0.8735657828683788, disc_loss = 0.05468298168852925
Trained batch 296 in epoch 18, gen_loss = 0.874258752523448, disc_loss = 0.05526841244964487
Trained batch 297 in epoch 18, gen_loss = 0.8752694720989905, disc_loss = 0.055213061992654064
Trained batch 298 in epoch 18, gen_loss = 0.8748466596754897, disc_loss = 0.05514263068902054
Trained batch 299 in epoch 18, gen_loss = 0.8741368948419889, disc_loss = 0.05507038943469524
Trained batch 300 in epoch 18, gen_loss = 0.8731931355902522, disc_loss = 0.05524322214811743
Trained batch 301 in epoch 18, gen_loss = 0.8736530478229586, disc_loss = 0.05517162251847469
Trained batch 302 in epoch 18, gen_loss = 0.8733906154782072, disc_loss = 0.05516830580954504
Trained batch 303 in epoch 18, gen_loss = 0.8730306677324208, disc_loss = 0.05509285300381874
Trained batch 304 in epoch 18, gen_loss = 0.8724379944996755, disc_loss = 0.05508653278477856
Trained batch 305 in epoch 18, gen_loss = 0.873974844423774, disc_loss = 0.05519485827900615
Trained batch 306 in epoch 18, gen_loss = 0.8735827424044718, disc_loss = 0.05514573292497315
Trained batch 307 in epoch 18, gen_loss = 0.8736632983986433, disc_loss = 0.055029798516785945
Trained batch 308 in epoch 18, gen_loss = 0.8729111929348757, disc_loss = 0.0552926844040167
Trained batch 309 in epoch 18, gen_loss = 0.872971427921326, disc_loss = 0.055249545723199844
Trained batch 310 in epoch 18, gen_loss = 0.873221645688704, disc_loss = 0.05517644895138848
Trained batch 311 in epoch 18, gen_loss = 0.8733756399880617, disc_loss = 0.05503635188767639
Trained batch 312 in epoch 18, gen_loss = 0.8727400869416734, disc_loss = 0.05499990316875541
Trained batch 313 in epoch 18, gen_loss = 0.8730975794754211, disc_loss = 0.05502235701094103
Trained batch 314 in epoch 18, gen_loss = 0.8730862277840811, disc_loss = 0.05488087836179941
Trained batch 315 in epoch 18, gen_loss = 0.8739645451873164, disc_loss = 0.0547523788718766
Trained batch 316 in epoch 18, gen_loss = 0.8732587509914903, disc_loss = 0.054860302649602906
Trained batch 317 in epoch 18, gen_loss = 0.8736100803193806, disc_loss = 0.05478768150831731
Trained batch 318 in epoch 18, gen_loss = 0.8729826173625396, disc_loss = 0.05492642079844931
Trained batch 319 in epoch 18, gen_loss = 0.8745816095732153, disc_loss = 0.05505898424307816
Trained batch 320 in epoch 18, gen_loss = 0.8750499463712686, disc_loss = 0.0552090711578309
Trained batch 321 in epoch 18, gen_loss = 0.8742364651483038, disc_loss = 0.05548538815415239
Trained batch 322 in epoch 18, gen_loss = 0.8739073460131607, disc_loss = 0.055502243472649586
Trained batch 323 in epoch 18, gen_loss = 0.8741297720942969, disc_loss = 0.055356120972399725
Trained batch 324 in epoch 18, gen_loss = 0.8734023544421563, disc_loss = 0.05559456970256108
Trained batch 325 in epoch 18, gen_loss = 0.8738014112038115, disc_loss = 0.05554415544414996
Trained batch 326 in epoch 18, gen_loss = 0.8740231063934641, disc_loss = 0.05592298820409753
Trained batch 327 in epoch 18, gen_loss = 0.8736496683119274, disc_loss = 0.05586094726672078
Trained batch 328 in epoch 18, gen_loss = 0.8733486610161859, disc_loss = 0.05582956326021431
Trained batch 329 in epoch 18, gen_loss = 0.8730508893728256, disc_loss = 0.05578988276309136
Trained batch 330 in epoch 18, gen_loss = 0.8731309311447547, disc_loss = 0.055705371377511324
Trained batch 331 in epoch 18, gen_loss = 0.8723823140005031, disc_loss = 0.05569434329777597
Trained batch 332 in epoch 18, gen_loss = 0.8726836363295535, disc_loss = 0.05575688548005737
Trained batch 333 in epoch 18, gen_loss = 0.8729075685054243, disc_loss = 0.05562853097670271
Trained batch 334 in epoch 18, gen_loss = 0.873298202254879, disc_loss = 0.055495042053621206
Trained batch 335 in epoch 18, gen_loss = 0.8727786261588335, disc_loss = 0.05560211939293714
Trained batch 336 in epoch 18, gen_loss = 0.8729692489704676, disc_loss = 0.055476914328531274
Trained batch 337 in epoch 18, gen_loss = 0.8732627652276902, disc_loss = 0.055754029913943196
Trained batch 338 in epoch 18, gen_loss = 0.8733115508317244, disc_loss = 0.05563014669338335
Trained batch 339 in epoch 18, gen_loss = 0.8725038599442033, disc_loss = 0.05588585141060107
Trained batch 340 in epoch 18, gen_loss = 0.8717225336434204, disc_loss = 0.05595747875787121
Trained batch 341 in epoch 18, gen_loss = 0.8722084737137744, disc_loss = 0.05606441304893696
Trained batch 342 in epoch 18, gen_loss = 0.8731665782434948, disc_loss = 0.05612404084609653
Trained batch 343 in epoch 18, gen_loss = 0.8725935980504336, disc_loss = 0.05611927994137067
Trained batch 344 in epoch 18, gen_loss = 0.8731950950795325, disc_loss = 0.055985859921876935
Trained batch 345 in epoch 18, gen_loss = 0.8734870455685378, disc_loss = 0.05585676095464585
Trained batch 346 in epoch 18, gen_loss = 0.8731645939157744, disc_loss = 0.05574864172443791
Trained batch 347 in epoch 18, gen_loss = 0.8729924394310206, disc_loss = 0.05567956088249968
Trained batch 348 in epoch 18, gen_loss = 0.8727583592293255, disc_loss = 0.0558149911714104
Trained batch 349 in epoch 18, gen_loss = 0.8724890031984874, disc_loss = 0.055703425010932346
Trained batch 350 in epoch 18, gen_loss = 0.8717397009035801, disc_loss = 0.05584715299064193
Trained batch 351 in epoch 18, gen_loss = 0.8723074017431248, disc_loss = 0.05577913955097425
Trained batch 352 in epoch 18, gen_loss = 0.8720029797668836, disc_loss = 0.05578579443108512
Trained batch 353 in epoch 18, gen_loss = 0.8717769945913789, disc_loss = 0.055693605796323487
Trained batch 354 in epoch 18, gen_loss = 0.8716288095628711, disc_loss = 0.05569226385789438
Trained batch 355 in epoch 18, gen_loss = 0.8716991976573226, disc_loss = 0.05558160275712693
Trained batch 356 in epoch 18, gen_loss = 0.8725199533276865, disc_loss = 0.055464228364725074
Trained batch 357 in epoch 18, gen_loss = 0.8723577253478866, disc_loss = 0.05545801853022262
Trained batch 358 in epoch 18, gen_loss = 0.8732251688464439, disc_loss = 0.05548352514157554
Trained batch 359 in epoch 18, gen_loss = 0.8737048317160871, disc_loss = 0.05545432415997816
Trained batch 360 in epoch 18, gen_loss = 0.8734280386955123, disc_loss = 0.05554572642984648
Trained batch 361 in epoch 18, gen_loss = 0.8733867738622328, disc_loss = 0.05547260703488114
Trained batch 362 in epoch 18, gen_loss = 0.87344495463634, disc_loss = 0.05535491325535886
Trained batch 363 in epoch 18, gen_loss = 0.8732391688358653, disc_loss = 0.055356168623113045
Trained batch 364 in epoch 18, gen_loss = 0.8741454415941892, disc_loss = 0.055777635450844895
Trained batch 365 in epoch 18, gen_loss = 0.8735764631645275, disc_loss = 0.05581260809949676
Trained batch 366 in epoch 18, gen_loss = 0.8729426981805131, disc_loss = 0.05575235136746548
Trained batch 367 in epoch 18, gen_loss = 0.8734997346511354, disc_loss = 0.055693599694084536
Trained batch 368 in epoch 18, gen_loss = 0.872992559580945, disc_loss = 0.05574390802502147
Trained batch 369 in epoch 18, gen_loss = 0.8729380904822737, disc_loss = 0.05577403268197904
Trained batch 370 in epoch 18, gen_loss = 0.8723506957212227, disc_loss = 0.05570903054446062
Trained batch 371 in epoch 18, gen_loss = 0.8714275952148182, disc_loss = 0.055854305199357454
Trained batch 372 in epoch 18, gen_loss = 0.8724580900119393, disc_loss = 0.055901365504467775
Trained batch 373 in epoch 18, gen_loss = 0.8722327650390207, disc_loss = 0.05591142607384665
Trained batch 374 in epoch 18, gen_loss = 0.8722366262276967, disc_loss = 0.05593573386967182
Trained batch 375 in epoch 18, gen_loss = 0.871716882874991, disc_loss = 0.05608898709884825
Trained batch 376 in epoch 18, gen_loss = 0.8720734599256389, disc_loss = 0.056009356806978626
Trained batch 377 in epoch 18, gen_loss = 0.8721582466174685, disc_loss = 0.05594376414994556
Trained batch 378 in epoch 18, gen_loss = 0.8721921562676694, disc_loss = 0.05588797780151889
Trained batch 379 in epoch 18, gen_loss = 0.8723281861135834, disc_loss = 0.0557664564296015
Trained batch 380 in epoch 18, gen_loss = 0.8737806376666222, disc_loss = 0.05590366096213812
Trained batch 381 in epoch 18, gen_loss = 0.873875397428168, disc_loss = 0.055811387786631965
Trained batch 382 in epoch 18, gen_loss = 0.873648146191714, disc_loss = 0.0558246760981707
Trained batch 383 in epoch 18, gen_loss = 0.8735905184876174, disc_loss = 0.055709971425433956
Trained batch 384 in epoch 18, gen_loss = 0.873813218652428, disc_loss = 0.05560830052603375
Trained batch 385 in epoch 18, gen_loss = 0.8737918946872721, disc_loss = 0.05561334681287022
Trained batch 386 in epoch 18, gen_loss = 0.873197816832121, disc_loss = 0.055720785512403614
Trained batch 387 in epoch 18, gen_loss = 0.8729111666685527, disc_loss = 0.05564691771551506
Trained batch 388 in epoch 18, gen_loss = 0.8730995732438595, disc_loss = 0.055540231568858525
Trained batch 389 in epoch 18, gen_loss = 0.8729266225527494, disc_loss = 0.0554752310905128
Trained batch 390 in epoch 18, gen_loss = 0.8735094302907929, disc_loss = 0.05548624123882531
Trained batch 391 in epoch 18, gen_loss = 0.873263561984106, disc_loss = 0.0554945691303369
Trained batch 392 in epoch 18, gen_loss = 0.873393030339525, disc_loss = 0.0553841662187954
Trained batch 393 in epoch 18, gen_loss = 0.8728963754655141, disc_loss = 0.055448124896697135
Trained batch 394 in epoch 18, gen_loss = 0.8729319629035418, disc_loss = 0.055400587007686304
Trained batch 395 in epoch 18, gen_loss = 0.8729032662631285, disc_loss = 0.05535058039616831
Trained batch 396 in epoch 18, gen_loss = 0.8732441696021659, disc_loss = 0.0552355809446884
Trained batch 397 in epoch 18, gen_loss = 0.8732236395379407, disc_loss = 0.055239116485188505
Trained batch 398 in epoch 18, gen_loss = 0.8730419192248419, disc_loss = 0.05516430075726189
Trained batch 399 in epoch 18, gen_loss = 0.873399614021182, disc_loss = 0.055046567725948986
Trained batch 400 in epoch 18, gen_loss = 0.8733910039030108, disc_loss = 0.05495684693783447
Trained batch 401 in epoch 18, gen_loss = 0.8734353548703502, disc_loss = 0.054889452652959386
Trained batch 402 in epoch 18, gen_loss = 0.8727376664394776, disc_loss = 0.05513580701320846
Trained batch 403 in epoch 18, gen_loss = 0.8733045915418333, disc_loss = 0.05506374159053263
Trained batch 404 in epoch 18, gen_loss = 0.8744512766231726, disc_loss = 0.05520195964217922
Trained batch 405 in epoch 18, gen_loss = 0.8743728700970194, disc_loss = 0.055132720422164855
Trained batch 406 in epoch 18, gen_loss = 0.8744088933421001, disc_loss = 0.05505997708172558
Trained batch 407 in epoch 18, gen_loss = 0.8744513548034079, disc_loss = 0.05495258643492764
Trained batch 408 in epoch 18, gen_loss = 0.8751687325154657, disc_loss = 0.05496643703148534
Trained batch 409 in epoch 18, gen_loss = 0.8748303920030593, disc_loss = 0.05494510929395513
Trained batch 410 in epoch 18, gen_loss = 0.875047918146254, disc_loss = 0.05490570803628351
Trained batch 411 in epoch 18, gen_loss = 0.8748214494400811, disc_loss = 0.054896305034895544
Trained batch 412 in epoch 18, gen_loss = 0.8742452273212968, disc_loss = 0.05491525793479661
Trained batch 413 in epoch 18, gen_loss = 0.8747431698484697, disc_loss = 0.05482144027516462
Trained batch 414 in epoch 18, gen_loss = 0.8746795541550739, disc_loss = 0.05474080269684992
Trained batch 415 in epoch 18, gen_loss = 0.8747428311035037, disc_loss = 0.054705525090237364
Trained batch 416 in epoch 18, gen_loss = 0.8750995574094694, disc_loss = 0.05463708548112024
Trained batch 417 in epoch 18, gen_loss = 0.8749934291582929, disc_loss = 0.05453809266508909
Trained batch 418 in epoch 18, gen_loss = 0.874800808745523, disc_loss = 0.05456860226118906
Trained batch 419 in epoch 18, gen_loss = 0.8749985045620373, disc_loss = 0.054476364116583555
Trained batch 420 in epoch 18, gen_loss = 0.8754185954210594, disc_loss = 0.054383056943975126
Trained batch 421 in epoch 18, gen_loss = 0.8755428461243191, disc_loss = 0.054392188604285505
Trained batch 422 in epoch 18, gen_loss = 0.8749516966354198, disc_loss = 0.05444459692216159
Trained batch 423 in epoch 18, gen_loss = 0.875327718496885, disc_loss = 0.05433670591501484
Trained batch 424 in epoch 18, gen_loss = 0.8756482178323409, disc_loss = 0.05427200944327256
Trained batch 425 in epoch 18, gen_loss = 0.8754594158818464, disc_loss = 0.05419697333783121
Trained batch 426 in epoch 18, gen_loss = 0.8758028280120823, disc_loss = 0.05409036405096638
Trained batch 427 in epoch 18, gen_loss = 0.8759442815017477, disc_loss = 0.05404302037634373
Trained batch 428 in epoch 18, gen_loss = 0.876204425568903, disc_loss = 0.05397254463267841
Trained batch 429 in epoch 18, gen_loss = 0.8757583060236864, disc_loss = 0.054025618041064156
Trained batch 430 in epoch 18, gen_loss = 0.8760841998450994, disc_loss = 0.0539217983024614
Trained batch 431 in epoch 18, gen_loss = 0.8762460086770631, disc_loss = 0.05382253474090248
Trained batch 432 in epoch 18, gen_loss = 0.8767663241121014, disc_loss = 0.05379829407340522
Trained batch 433 in epoch 18, gen_loss = 0.8767617995151177, disc_loss = 0.053723681675192946
Trained batch 434 in epoch 18, gen_loss = 0.8763900569800673, disc_loss = 0.05372098708289793
Trained batch 435 in epoch 18, gen_loss = 0.8764034506241116, disc_loss = 0.05366792619535956
Trained batch 436 in epoch 18, gen_loss = 0.876605181658568, disc_loss = 0.053570734677959905
Trained batch 437 in epoch 18, gen_loss = 0.8765151723198694, disc_loss = 0.0534947259419653
Trained batch 438 in epoch 18, gen_loss = 0.8766564686776294, disc_loss = 0.05339110848877859
Trained batch 439 in epoch 18, gen_loss = 0.8765386513011022, disc_loss = 0.05332151686518707
Trained batch 440 in epoch 18, gen_loss = 0.8770321869120306, disc_loss = 0.05323059274867819
Trained batch 441 in epoch 18, gen_loss = 0.877712926106755, disc_loss = 0.053174316655524176
Trained batch 442 in epoch 18, gen_loss = 0.8779084520334584, disc_loss = 0.053070355093203334
Trained batch 443 in epoch 18, gen_loss = 0.8771870565172788, disc_loss = 0.05320409940018713
Trained batch 444 in epoch 18, gen_loss = 0.8772837881961565, disc_loss = 0.05310446547365256
Trained batch 445 in epoch 18, gen_loss = 0.8782315753366915, disc_loss = 0.05317067890532415
Trained batch 446 in epoch 18, gen_loss = 0.8784856260889595, disc_loss = 0.053256208308341116
Trained batch 447 in epoch 18, gen_loss = 0.8779235956525164, disc_loss = 0.053465684387317323
Trained batch 448 in epoch 18, gen_loss = 0.8780099884306136, disc_loss = 0.053366475307148255
Trained batch 449 in epoch 18, gen_loss = 0.878040451142523, disc_loss = 0.053260752186179164
Trained batch 450 in epoch 18, gen_loss = 0.8779346143987914, disc_loss = 0.053180354727874045
Trained batch 451 in epoch 18, gen_loss = 0.8777931728853589, disc_loss = 0.053103791549801826
Trained batch 452 in epoch 18, gen_loss = 0.8781988013527514, disc_loss = 0.05302504604686438
Trained batch 453 in epoch 18, gen_loss = 0.8781796529035736, disc_loss = 0.0529342694987547
Trained batch 454 in epoch 18, gen_loss = 0.8784281199450021, disc_loss = 0.052849289365522155
Trained batch 455 in epoch 18, gen_loss = 0.8787981327296349, disc_loss = 0.05286473931189169
Trained batch 456 in epoch 18, gen_loss = 0.8788800163263826, disc_loss = 0.05277181879354384
Trained batch 457 in epoch 18, gen_loss = 0.8786721174243236, disc_loss = 0.052763146250691735
Trained batch 458 in epoch 18, gen_loss = 0.8781519034199725, disc_loss = 0.05283452828936198
Trained batch 459 in epoch 18, gen_loss = 0.8781145114613615, disc_loss = 0.05274012085536252
Trained batch 460 in epoch 18, gen_loss = 0.8787871005090353, disc_loss = 0.052755528531661516
Trained batch 461 in epoch 18, gen_loss = 0.8791612784712861, disc_loss = 0.05266515999322846
Trained batch 462 in epoch 18, gen_loss = 0.8783087413074131, disc_loss = 0.0527804548455881
Trained batch 463 in epoch 18, gen_loss = 0.878605631597597, disc_loss = 0.052717742381681656
Trained batch 464 in epoch 18, gen_loss = 0.8785109160407897, disc_loss = 0.052747479866268814
Trained batch 465 in epoch 18, gen_loss = 0.8787705187761733, disc_loss = 0.05265671287787191
Trained batch 466 in epoch 18, gen_loss = 0.8779789557165967, disc_loss = 0.0528995324947275
Trained batch 467 in epoch 18, gen_loss = 0.8778798759110973, disc_loss = 0.05283611828986651
Trained batch 468 in epoch 18, gen_loss = 0.8782706520577738, disc_loss = 0.05277329867979738
Trained batch 469 in epoch 18, gen_loss = 0.878702245938017, disc_loss = 0.0529349255157595
Trained batch 470 in epoch 18, gen_loss = 0.8784001965052003, disc_loss = 0.052918481943049246
Trained batch 471 in epoch 18, gen_loss = 0.8778046685886585, disc_loss = 0.05309689868541466
Trained batch 472 in epoch 18, gen_loss = 0.8780386256995211, disc_loss = 0.05338384717876135
Trained batch 473 in epoch 18, gen_loss = 0.8777673004926005, disc_loss = 0.05333476716000194
Trained batch 474 in epoch 18, gen_loss = 0.8781260058126952, disc_loss = 0.05355233196757342
Trained batch 475 in epoch 18, gen_loss = 0.8776078471491316, disc_loss = 0.05371738094914736
Trained batch 476 in epoch 18, gen_loss = 0.8774818298826678, disc_loss = 0.05369634946234196
Trained batch 477 in epoch 18, gen_loss = 0.87679671599027, disc_loss = 0.05395579417177698
Trained batch 478 in epoch 18, gen_loss = 0.8771317015734496, disc_loss = 0.05453405447988645
Trained batch 479 in epoch 18, gen_loss = 0.8765820380921165, disc_loss = 0.05458315188298002
Trained batch 480 in epoch 18, gen_loss = 0.8760851731295397, disc_loss = 0.05460376383469531
Trained batch 481 in epoch 18, gen_loss = 0.8757964442503403, disc_loss = 0.05459644490489698
Trained batch 482 in epoch 18, gen_loss = 0.8758626173618664, disc_loss = 0.05465382250801006
Trained batch 483 in epoch 18, gen_loss = 0.8762077410235878, disc_loss = 0.05466060515508548
Trained batch 484 in epoch 18, gen_loss = 0.8755515836563307, disc_loss = 0.05470351820677211
Trained batch 485 in epoch 18, gen_loss = 0.8751217643787832, disc_loss = 0.05473858011894143
Trained batch 486 in epoch 18, gen_loss = 0.8748884271424898, disc_loss = 0.05485177007589864
Trained batch 487 in epoch 18, gen_loss = 0.8747888005292807, disc_loss = 0.05485223620351343
Trained batch 488 in epoch 18, gen_loss = 0.8746572544603991, disc_loss = 0.05477074100988286
Trained batch 489 in epoch 18, gen_loss = 0.8739917608548183, disc_loss = 0.0549491001483129
Trained batch 490 in epoch 18, gen_loss = 0.874318688500923, disc_loss = 0.05495460416416044
Trained batch 491 in epoch 18, gen_loss = 0.8746840628545459, disc_loss = 0.054872074632004386
Trained batch 492 in epoch 18, gen_loss = 0.8741117140946959, disc_loss = 0.05495211763711718
Trained batch 493 in epoch 18, gen_loss = 0.8744784574880291, disc_loss = 0.055047779888864834
Trained batch 494 in epoch 18, gen_loss = 0.874498787612626, disc_loss = 0.05497393434434527
Trained batch 495 in epoch 18, gen_loss = 0.8745028158469547, disc_loss = 0.05491515262720866
Trained batch 496 in epoch 18, gen_loss = 0.8748286886354327, disc_loss = 0.0548570679568159
Trained batch 497 in epoch 18, gen_loss = 0.8751156692164969, disc_loss = 0.05476358019930112
Trained batch 498 in epoch 18, gen_loss = 0.874823213161113, disc_loss = 0.05473576005518377
Trained batch 499 in epoch 18, gen_loss = 0.8749896478056908, disc_loss = 0.054669688472524285
Trained batch 500 in epoch 18, gen_loss = 0.8745752492707647, disc_loss = 0.05468373939194187
Trained batch 501 in epoch 18, gen_loss = 0.874857620473402, disc_loss = 0.05460596471780028
Trained batch 502 in epoch 18, gen_loss = 0.8747729333802673, disc_loss = 0.054520599925464715
Trained batch 503 in epoch 18, gen_loss = 0.8746793895132012, disc_loss = 0.05447307544656926
Trained batch 504 in epoch 18, gen_loss = 0.8746890629282092, disc_loss = 0.054416431361200786
Trained batch 505 in epoch 18, gen_loss = 0.8746489688695184, disc_loss = 0.054353967655023094
Trained batch 506 in epoch 18, gen_loss = 0.8751164993943548, disc_loss = 0.054301524391541116
Trained batch 507 in epoch 18, gen_loss = 0.8747918152316349, disc_loss = 0.05428682855059078
Trained batch 508 in epoch 18, gen_loss = 0.8745188443154858, disc_loss = 0.0542052566496498
Trained batch 509 in epoch 18, gen_loss = 0.8744743440081092, disc_loss = 0.0541407333705209
Trained batch 510 in epoch 18, gen_loss = 0.8746907793262467, disc_loss = 0.05423345801524395
Trained batch 511 in epoch 18, gen_loss = 0.8744688674923964, disc_loss = 0.054219941053816
Trained batch 512 in epoch 18, gen_loss = 0.8738499165859371, disc_loss = 0.05445317769891512
Trained batch 513 in epoch 18, gen_loss = 0.874706787300017, disc_loss = 0.05469770639489771
Trained batch 514 in epoch 18, gen_loss = 0.874847960182764, disc_loss = 0.05462091287543762
Trained batch 515 in epoch 18, gen_loss = 0.8746839493166568, disc_loss = 0.054567323454345264
Trained batch 516 in epoch 18, gen_loss = 0.8743647722603043, disc_loss = 0.05463177131982502
Trained batch 517 in epoch 18, gen_loss = 0.8747409776025757, disc_loss = 0.054601615724516994
Trained batch 518 in epoch 18, gen_loss = 0.8743625601936627, disc_loss = 0.05459318300511738
Trained batch 519 in epoch 18, gen_loss = 0.8748801846343738, disc_loss = 0.05482882301932057
Trained batch 520 in epoch 18, gen_loss = 0.8745282687632914, disc_loss = 0.05483253734032561
Trained batch 521 in epoch 18, gen_loss = 0.8739817624918802, disc_loss = 0.05487914956299681
Trained batch 522 in epoch 18, gen_loss = 0.8740310147547129, disc_loss = 0.054830247944089125
Trained batch 523 in epoch 18, gen_loss = 0.8739801952970847, disc_loss = 0.05476583590738134
Trained batch 524 in epoch 18, gen_loss = 0.8734975918701717, disc_loss = 0.05479685732828719
Trained batch 525 in epoch 18, gen_loss = 0.8740586705874127, disc_loss = 0.0550368518370271
Trained batch 526 in epoch 18, gen_loss = 0.8741715603015002, disc_loss = 0.05499648611526053
Trained batch 527 in epoch 18, gen_loss = 0.8736823030154813, disc_loss = 0.05505945319556772
Trained batch 528 in epoch 18, gen_loss = 0.8736756392710601, disc_loss = 0.05501648660974545
Trained batch 529 in epoch 18, gen_loss = 0.8738385207810492, disc_loss = 0.055232749020083335
Trained batch 530 in epoch 18, gen_loss = 0.8732449124425145, disc_loss = 0.05541116045349455
Trained batch 531 in epoch 18, gen_loss = 0.8734499727536861, disc_loss = 0.05535165937372336
Trained batch 532 in epoch 18, gen_loss = 0.8734446276978749, disc_loss = 0.05551905244917348
Trained batch 533 in epoch 18, gen_loss = 0.8731119604258055, disc_loss = 0.05566721501470673
Trained batch 534 in epoch 18, gen_loss = 0.8727933422984364, disc_loss = 0.05568201469309698
Trained batch 535 in epoch 18, gen_loss = 0.873525258153677, disc_loss = 0.05569611053128463
Trained batch 536 in epoch 18, gen_loss = 0.8735504246401831, disc_loss = 0.055662633929214334
Trained batch 537 in epoch 18, gen_loss = 0.8736612416222193, disc_loss = 0.05559286375298099
Trained batch 538 in epoch 18, gen_loss = 0.8735665090119463, disc_loss = 0.05584370171917336
Trained batch 539 in epoch 18, gen_loss = 0.8730682424373097, disc_loss = 0.05592740586337944
Trained batch 540 in epoch 18, gen_loss = 0.8729480243324131, disc_loss = 0.05586041007948395
Trained batch 541 in epoch 18, gen_loss = 0.8721687140499974, disc_loss = 0.05629108716111726
Trained batch 542 in epoch 18, gen_loss = 0.8718486201038677, disc_loss = 0.05634278801834111
Trained batch 543 in epoch 18, gen_loss = 0.8724019477034316, disc_loss = 0.05638749211828005
Trained batch 544 in epoch 18, gen_loss = 0.8717064084263023, disc_loss = 0.056498258955639986
Trained batch 545 in epoch 18, gen_loss = 0.8715871219888275, disc_loss = 0.056522562313524684
Trained batch 546 in epoch 18, gen_loss = 0.8717133683957827, disc_loss = 0.05670424767853301
Trained batch 547 in epoch 18, gen_loss = 0.8718918276964313, disc_loss = 0.05661797286929005
Trained batch 548 in epoch 18, gen_loss = 0.8713465976801944, disc_loss = 0.05665478140170023
Trained batch 549 in epoch 18, gen_loss = 0.8710148840600794, disc_loss = 0.05668239456686107
Trained batch 550 in epoch 18, gen_loss = 0.8712328202927827, disc_loss = 0.0569188017026266
Trained batch 551 in epoch 18, gen_loss = 0.8712694207611291, disc_loss = 0.056833705959328705
Trained batch 552 in epoch 18, gen_loss = 0.8709781771327013, disc_loss = 0.05687031706299963
Trained batch 553 in epoch 18, gen_loss = 0.8707830989834203, disc_loss = 0.05688510450537885
Trained batch 554 in epoch 18, gen_loss = 0.8714309857772278, disc_loss = 0.05714270260419931
Trained batch 555 in epoch 18, gen_loss = 0.8713674703947931, disc_loss = 0.0570842366223391
Trained batch 556 in epoch 18, gen_loss = 0.8711516069552628, disc_loss = 0.057047840903381046
Trained batch 557 in epoch 18, gen_loss = 0.8707190956052486, disc_loss = 0.05713853347499097
Trained batch 558 in epoch 18, gen_loss = 0.8709925171087808, disc_loss = 0.05734492793732551
Trained batch 559 in epoch 18, gen_loss = 0.8707901812025479, disc_loss = 0.05731706419693572
Trained batch 560 in epoch 18, gen_loss = 0.8704976147296382, disc_loss = 0.057287001846202126
Trained batch 561 in epoch 18, gen_loss = 0.8704540816490336, disc_loss = 0.05723747808910456
Trained batch 562 in epoch 18, gen_loss = 0.8706073566186068, disc_loss = 0.057163778384800065
Trained batch 563 in epoch 18, gen_loss = 0.8708847784404213, disc_loss = 0.05707692165515577
Trained batch 564 in epoch 18, gen_loss = 0.8708735482882609, disc_loss = 0.05701743887358271
Trained batch 565 in epoch 18, gen_loss = 0.8711624956383722, disc_loss = 0.05693354173777329
Trained batch 566 in epoch 18, gen_loss = 0.8711285830805542, disc_loss = 0.05686597741082495
Trained batch 567 in epoch 18, gen_loss = 0.8714981482062542, disc_loss = 0.056839268118418544
Trained batch 568 in epoch 18, gen_loss = 0.8713456756829796, disc_loss = 0.05681486334979063
Trained batch 569 in epoch 18, gen_loss = 0.8712820586405302, disc_loss = 0.05675374612767707
Trained batch 570 in epoch 18, gen_loss = 0.871590529557076, disc_loss = 0.05667487989732712
Trained batch 571 in epoch 18, gen_loss = 0.8715904657240514, disc_loss = 0.05660527873413077
Trained batch 572 in epoch 18, gen_loss = 0.8716732033676294, disc_loss = 0.05660455504084497
Trained batch 573 in epoch 18, gen_loss = 0.8714137833292891, disc_loss = 0.056587494148804644
Trained batch 574 in epoch 18, gen_loss = 0.8715581674161165, disc_loss = 0.056512192058498445
Trained batch 575 in epoch 18, gen_loss = 0.8718099190543095, disc_loss = 0.056488632882570125
Trained batch 576 in epoch 18, gen_loss = 0.8712244084430939, disc_loss = 0.056660129882369445
Trained batch 577 in epoch 18, gen_loss = 0.8711941032879905, disc_loss = 0.05679519377668166
Trained batch 578 in epoch 18, gen_loss = 0.8711055446165213, disc_loss = 0.05677164725425279
Trained batch 579 in epoch 18, gen_loss = 0.8712000859194788, disc_loss = 0.056713776250273504
Trained batch 580 in epoch 18, gen_loss = 0.8705296639526157, disc_loss = 0.0568927074934832
Trained batch 581 in epoch 18, gen_loss = 0.8713123548481473, disc_loss = 0.05704558278270757
Trained batch 582 in epoch 18, gen_loss = 0.871390031296025, disc_loss = 0.056972255070867915
Trained batch 583 in epoch 18, gen_loss = 0.871061126357072, disc_loss = 0.05700626876205206
Trained batch 584 in epoch 18, gen_loss = 0.8711979084544712, disc_loss = 0.05693478281808714
Trained batch 585 in epoch 18, gen_loss = 0.8712711321005642, disc_loss = 0.056863819520742515
Trained batch 586 in epoch 18, gen_loss = 0.8713015442812463, disc_loss = 0.056823241340355025
Trained batch 587 in epoch 18, gen_loss = 0.8712888694539362, disc_loss = 0.056747407864677864
Trained batch 588 in epoch 18, gen_loss = 0.8712138639848382, disc_loss = 0.05669050702606984
Trained batch 589 in epoch 18, gen_loss = 0.8714725676229444, disc_loss = 0.05677661812090773
Trained batch 590 in epoch 18, gen_loss = 0.8712597506502154, disc_loss = 0.05679755265526663
Trained batch 591 in epoch 18, gen_loss = 0.8711159889762466, disc_loss = 0.05677064461318927
Trained batch 592 in epoch 18, gen_loss = 0.8711453883282049, disc_loss = 0.05674629692069897
Trained batch 593 in epoch 18, gen_loss = 0.8710649268394367, disc_loss = 0.05675545910856238
Trained batch 594 in epoch 18, gen_loss = 0.8711807211907971, disc_loss = 0.05668973112870164
Trained batch 595 in epoch 18, gen_loss = 0.8716573436188217, disc_loss = 0.056779710629067365
Trained batch 596 in epoch 18, gen_loss = 0.8713553707603634, disc_loss = 0.05677788218224368
Trained batch 597 in epoch 18, gen_loss = 0.8711214585846483, disc_loss = 0.05677330678011163
Trained batch 598 in epoch 18, gen_loss = 0.8713412091807651, disc_loss = 0.05669492274174507
Trained batch 599 in epoch 18, gen_loss = 0.8716780696312586, disc_loss = 0.056646067183464766
Trained batch 600 in epoch 18, gen_loss = 0.87156101183566, disc_loss = 0.05661478607036707
Trained batch 601 in epoch 18, gen_loss = 0.8720560789702343, disc_loss = 0.056555631310614043
Trained batch 602 in epoch 18, gen_loss = 0.8721828039605819, disc_loss = 0.056554372127401095
Trained batch 603 in epoch 18, gen_loss = 0.8719093857814144, disc_loss = 0.05657852373536158
Trained batch 604 in epoch 18, gen_loss = 0.871878711349708, disc_loss = 0.05653430514099184
Trained batch 605 in epoch 18, gen_loss = 0.8723596034467024, disc_loss = 0.05646249751188476
Trained batch 606 in epoch 18, gen_loss = 0.8723462940833517, disc_loss = 0.056447939333525876
Trained batch 607 in epoch 18, gen_loss = 0.8718654190827357, disc_loss = 0.05646533212367151
Trained batch 608 in epoch 18, gen_loss = 0.8720123625936962, disc_loss = 0.056393289589896575
Trained batch 609 in epoch 18, gen_loss = 0.8724869404659896, disc_loss = 0.05637019438760691
Trained batch 610 in epoch 18, gen_loss = 0.8725920212249318, disc_loss = 0.056297617920243015
Trained batch 611 in epoch 18, gen_loss = 0.872136018829408, disc_loss = 0.05626136648279974
Trained batch 612 in epoch 18, gen_loss = 0.8721879365782559, disc_loss = 0.056355855514281725
Trained batch 613 in epoch 18, gen_loss = 0.8720999728973214, disc_loss = 0.056282606556805316
Trained batch 614 in epoch 18, gen_loss = 0.871684589812426, disc_loss = 0.056271099206817346
Trained batch 615 in epoch 18, gen_loss = 0.8713386238782437, disc_loss = 0.056462868453946886
Trained batch 616 in epoch 18, gen_loss = 0.8713844582752431, disc_loss = 0.05638894871499154
Trained batch 617 in epoch 18, gen_loss = 0.8716862329966042, disc_loss = 0.05631684421329581
Trained batch 618 in epoch 18, gen_loss = 0.8715382961733853, disc_loss = 0.0563301029622627
Trained batch 619 in epoch 18, gen_loss = 0.8716955731953344, disc_loss = 0.05626126193711835
Trained batch 620 in epoch 18, gen_loss = 0.8715281986575963, disc_loss = 0.05622028934374908
Trained batch 621 in epoch 18, gen_loss = 0.8720618680934047, disc_loss = 0.056274270159686494
Trained batch 622 in epoch 18, gen_loss = 0.8720114766881707, disc_loss = 0.05622678642635074
Trained batch 623 in epoch 18, gen_loss = 0.871690208140092, disc_loss = 0.05622429765748958
Trained batch 624 in epoch 18, gen_loss = 0.8722073637008667, disc_loss = 0.05631264216601849
Trained batch 625 in epoch 18, gen_loss = 0.8718849762369649, disc_loss = 0.0562911315794332
Trained batch 626 in epoch 18, gen_loss = 0.8719031665313757, disc_loss = 0.05622337099485563
Trained batch 627 in epoch 18, gen_loss = 0.8716548716376542, disc_loss = 0.056234411223477145
Trained batch 628 in epoch 18, gen_loss = 0.871723376984437, disc_loss = 0.0561602592545255
Trained batch 629 in epoch 18, gen_loss = 0.8719481785146017, disc_loss = 0.0561100148965442
Trained batch 630 in epoch 18, gen_loss = 0.872206368178082, disc_loss = 0.056042391833407944
Trained batch 631 in epoch 18, gen_loss = 0.8721505511976495, disc_loss = 0.056020646936649196
Trained batch 632 in epoch 18, gen_loss = 0.8725360126291971, disc_loss = 0.055954641538950224
Trained batch 633 in epoch 18, gen_loss = 0.8724991762863725, disc_loss = 0.05589465847332912
Trained batch 634 in epoch 18, gen_loss = 0.8723146440475944, disc_loss = 0.055865738645019966
Trained batch 635 in epoch 18, gen_loss = 0.8723529462919295, disc_loss = 0.055851225558164644
Trained batch 636 in epoch 18, gen_loss = 0.8726880544770269, disc_loss = 0.05580122619896566
Trained batch 637 in epoch 18, gen_loss = 0.8729861399223064, disc_loss = 0.05577332728621214
Trained batch 638 in epoch 18, gen_loss = 0.8725581689619683, disc_loss = 0.05582891106284887
Trained batch 639 in epoch 18, gen_loss = 0.8722975062206387, disc_loss = 0.05580636165250326
Trained batch 640 in epoch 18, gen_loss = 0.8726525438743151, disc_loss = 0.0557693951776289
Trained batch 641 in epoch 18, gen_loss = 0.8727407562212781, disc_loss = 0.05574740384882345
Trained batch 642 in epoch 18, gen_loss = 0.872688981088843, disc_loss = 0.05571250234691435
Trained batch 643 in epoch 18, gen_loss = 0.8728778318773885, disc_loss = 0.055640486180377396
Trained batch 644 in epoch 18, gen_loss = 0.8730325878128525, disc_loss = 0.05556845485499894
Trained batch 645 in epoch 18, gen_loss = 0.8726516707393777, disc_loss = 0.05555686022042536
Trained batch 646 in epoch 18, gen_loss = 0.8724116588117903, disc_loss = 0.055564395745084774
Trained batch 647 in epoch 18, gen_loss = 0.8726821665042712, disc_loss = 0.055494731376924906
Trained batch 648 in epoch 18, gen_loss = 0.8729771063397588, disc_loss = 0.055740582366374955
Trained batch 649 in epoch 18, gen_loss = 0.8730297042773321, disc_loss = 0.055679225421582275
Trained batch 650 in epoch 18, gen_loss = 0.8729931049266352, disc_loss = 0.05561201209445611
Trained batch 651 in epoch 18, gen_loss = 0.8725186093636086, disc_loss = 0.055630558350357726
Trained batch 652 in epoch 18, gen_loss = 0.8726240133618505, disc_loss = 0.05555843692529621
Trained batch 653 in epoch 18, gen_loss = 0.8724304543358106, disc_loss = 0.05571249714662358
Trained batch 654 in epoch 18, gen_loss = 0.8723995367989286, disc_loss = 0.05565878602157112
Trained batch 655 in epoch 18, gen_loss = 0.8721405781078629, disc_loss = 0.055763525047861945
Trained batch 656 in epoch 18, gen_loss = 0.8721845838577236, disc_loss = 0.05585948627334389
Trained batch 657 in epoch 18, gen_loss = 0.8719802266015108, disc_loss = 0.05583509093994065
Trained batch 658 in epoch 18, gen_loss = 0.8716820929770405, disc_loss = 0.055836062957511506
Trained batch 659 in epoch 18, gen_loss = 0.87243322215297, disc_loss = 0.05638747621101863
Trained batch 660 in epoch 18, gen_loss = 0.8722127329744117, disc_loss = 0.05635491169639687
Trained batch 661 in epoch 18, gen_loss = 0.8718846719430653, disc_loss = 0.05658813415719843
Trained batch 662 in epoch 18, gen_loss = 0.8719269628798081, disc_loss = 0.056747661125291345
Trained batch 663 in epoch 18, gen_loss = 0.8716975700962974, disc_loss = 0.05691977853449174
Trained batch 664 in epoch 18, gen_loss = 0.8714222790603351, disc_loss = 0.057015478661409894
Trained batch 665 in epoch 18, gen_loss = 0.8712223674262967, disc_loss = 0.057029356139602964
Trained batch 666 in epoch 18, gen_loss = 0.8711953935237123, disc_loss = 0.057068373773364295
Trained batch 667 in epoch 18, gen_loss = 0.8714589722856076, disc_loss = 0.05709045356373765
Trained batch 668 in epoch 18, gen_loss = 0.870995974861453, disc_loss = 0.05715806455377862
Trained batch 669 in epoch 18, gen_loss = 0.8706662597940928, disc_loss = 0.05719829510285783
Trained batch 670 in epoch 18, gen_loss = 0.870998118922181, disc_loss = 0.057315093855166754
Trained batch 671 in epoch 18, gen_loss = 0.8709067485871769, disc_loss = 0.0572799629354406
Trained batch 672 in epoch 18, gen_loss = 0.8709784213890824, disc_loss = 0.057228049684044685
Trained batch 673 in epoch 18, gen_loss = 0.8706046943317889, disc_loss = 0.05734646980006811
Trained batch 674 in epoch 18, gen_loss = 0.8707991316583421, disc_loss = 0.0573895777568773
Trained batch 675 in epoch 18, gen_loss = 0.8706343121077182, disc_loss = 0.05735378981066438
Trained batch 676 in epoch 18, gen_loss = 0.8704158011356168, disc_loss = 0.05730969329781423
Trained batch 677 in epoch 18, gen_loss = 0.8702898454525477, disc_loss = 0.05731908285545301
Trained batch 678 in epoch 18, gen_loss = 0.8701974520451542, disc_loss = 0.05726030760270506
Trained batch 679 in epoch 18, gen_loss = 0.8699102259734097, disc_loss = 0.05724737809094436
Trained batch 680 in epoch 18, gen_loss = 0.8702212393546419, disc_loss = 0.057256802320261535
Trained batch 681 in epoch 18, gen_loss = 0.8700847953470572, disc_loss = 0.057581865668427906
Trained batch 682 in epoch 18, gen_loss = 0.8696482921589171, disc_loss = 0.05774019812922352
Trained batch 683 in epoch 18, gen_loss = 0.8691206239817435, disc_loss = 0.05810159095699153
Trained batch 684 in epoch 18, gen_loss = 0.8694101493724071, disc_loss = 0.05857514969080034
Trained batch 685 in epoch 18, gen_loss = 0.8689964410167393, disc_loss = 0.05877282474266023
Trained batch 686 in epoch 18, gen_loss = 0.8686525878947895, disc_loss = 0.05886153600773784
Trained batch 687 in epoch 18, gen_loss = 0.8686312821715377, disc_loss = 0.058908493989038954
Trained batch 688 in epoch 18, gen_loss = 0.8685681531841073, disc_loss = 0.058951696940577426
Trained batch 689 in epoch 18, gen_loss = 0.8683783097543578, disc_loss = 0.05894393391259339
Trained batch 690 in epoch 18, gen_loss = 0.8682962346352993, disc_loss = 0.05898271193229169
Trained batch 691 in epoch 18, gen_loss = 0.8684911375617705, disc_loss = 0.058960958340910474
Trained batch 692 in epoch 18, gen_loss = 0.8681633807019926, disc_loss = 0.05902997152221323
Trained batch 693 in epoch 18, gen_loss = 0.8681196174463552, disc_loss = 0.05901205924578462
Trained batch 694 in epoch 18, gen_loss = 0.8680892069562733, disc_loss = 0.059109579278625174
Trained batch 695 in epoch 18, gen_loss = 0.8675817912337423, disc_loss = 0.0592389153691287
Trained batch 696 in epoch 18, gen_loss = 0.8676157628788668, disc_loss = 0.059183125813068074
Trained batch 697 in epoch 18, gen_loss = 0.8678718188772229, disc_loss = 0.0591674178150245
Trained batch 698 in epoch 18, gen_loss = 0.8676483312219339, disc_loss = 0.05912764487423013
Trained batch 699 in epoch 18, gen_loss = 0.8674992041928428, disc_loss = 0.05909334875909345
Trained batch 700 in epoch 18, gen_loss = 0.8674600983142172, disc_loss = 0.05907035836639061
Trained batch 701 in epoch 18, gen_loss = 0.8672947293502993, disc_loss = 0.0590922252760611
Trained batch 702 in epoch 18, gen_loss = 0.8673616887665067, disc_loss = 0.05902873326734154
Trained batch 703 in epoch 18, gen_loss = 0.8670018544759263, disc_loss = 0.05906713887816295
Trained batch 704 in epoch 18, gen_loss = 0.8671306531480019, disc_loss = 0.05902598698933919
Trained batch 705 in epoch 18, gen_loss = 0.867989680837977, disc_loss = 0.05905507484888895
Trained batch 706 in epoch 18, gen_loss = 0.8675311020611031, disc_loss = 0.05911345598636962
Trained batch 707 in epoch 18, gen_loss = 0.8675538021965888, disc_loss = 0.0592021962238402
Trained batch 708 in epoch 18, gen_loss = 0.8676869480835198, disc_loss = 0.05914593356620778
Trained batch 709 in epoch 18, gen_loss = 0.8673206734825188, disc_loss = 0.05937868140532937
Trained batch 710 in epoch 18, gen_loss = 0.8670928502552284, disc_loss = 0.059367034987725956
Trained batch 711 in epoch 18, gen_loss = 0.8672709594784158, disc_loss = 0.05932753481065038
Trained batch 712 in epoch 18, gen_loss = 0.8672516217238438, disc_loss = 0.0592874787554542
Trained batch 713 in epoch 18, gen_loss = 0.8677381929897127, disc_loss = 0.05926039677989833
Trained batch 714 in epoch 18, gen_loss = 0.8675709633560448, disc_loss = 0.05924581062908356
Trained batch 715 in epoch 18, gen_loss = 0.8673845486267985, disc_loss = 0.05921035084363552
Trained batch 716 in epoch 18, gen_loss = 0.8674100702277786, disc_loss = 0.059165251398435696
Trained batch 717 in epoch 18, gen_loss = 0.8676583644075314, disc_loss = 0.05953058074319263
Trained batch 718 in epoch 18, gen_loss = 0.8673983339805762, disc_loss = 0.05954524250869459
Trained batch 719 in epoch 18, gen_loss = 0.8674585378004445, disc_loss = 0.05953575163148343
Trained batch 720 in epoch 18, gen_loss = 0.8674956267485175, disc_loss = 0.05950400015744852
Trained batch 721 in epoch 18, gen_loss = 0.867279937392787, disc_loss = 0.059525261124869465
Trained batch 722 in epoch 18, gen_loss = 0.8668047944869574, disc_loss = 0.05960945553696337
Trained batch 723 in epoch 18, gen_loss = 0.867307932172691, disc_loss = 0.0596113455898607
Trained batch 724 in epoch 18, gen_loss = 0.8674551267459475, disc_loss = 0.059623378222358636
Trained batch 725 in epoch 18, gen_loss = 0.8672325963323767, disc_loss = 0.05962955659722329
Trained batch 726 in epoch 18, gen_loss = 0.8670816043548112, disc_loss = 0.05958484964345311
Trained batch 727 in epoch 18, gen_loss = 0.8674321425976333, disc_loss = 0.05953307191401229
Trained batch 728 in epoch 18, gen_loss = 0.8678977612932359, disc_loss = 0.05960947196976638
Trained batch 729 in epoch 18, gen_loss = 0.8674633518473743, disc_loss = 0.05963753866516564
Trained batch 730 in epoch 18, gen_loss = 0.8673808272168673, disc_loss = 0.0596295116436139
Trained batch 731 in epoch 18, gen_loss = 0.8675892980860882, disc_loss = 0.059564097200474536
Trained batch 732 in epoch 18, gen_loss = 0.8676921214608508, disc_loss = 0.05959995797521461
Trained batch 733 in epoch 18, gen_loss = 0.8676172736067863, disc_loss = 0.05963678238913417
Trained batch 734 in epoch 18, gen_loss = 0.8674311892515948, disc_loss = 0.0596551258459079
Trained batch 735 in epoch 18, gen_loss = 0.8670610971748829, disc_loss = 0.05971384431240554
Trained batch 736 in epoch 18, gen_loss = 0.8671796832188176, disc_loss = 0.05991234593068122
Trained batch 737 in epoch 18, gen_loss = 0.8671588710330043, disc_loss = 0.05986936195175539
Trained batch 738 in epoch 18, gen_loss = 0.8675603132609263, disc_loss = 0.05980968678871697
Trained batch 739 in epoch 18, gen_loss = 0.8673362236570668, disc_loss = 0.059847063549819425
Trained batch 740 in epoch 18, gen_loss = 0.8674408305994412, disc_loss = 0.059883747877007634
Trained batch 741 in epoch 18, gen_loss = 0.8673023379877249, disc_loss = 0.059966739627339366
Trained batch 742 in epoch 18, gen_loss = 0.8673464934245093, disc_loss = 0.05992879086170311
Trained batch 743 in epoch 18, gen_loss = 0.8670101807482781, disc_loss = 0.05998683412764622
Trained batch 744 in epoch 18, gen_loss = 0.8670962931325772, disc_loss = 0.05991981224900724
Trained batch 745 in epoch 18, gen_loss = 0.8669539171473271, disc_loss = 0.05995504712266473
Trained batch 746 in epoch 18, gen_loss = 0.8671991015214677, disc_loss = 0.05991061737603811
Trained batch 747 in epoch 18, gen_loss = 0.8670242263034066, disc_loss = 0.05988086189920292
Trained batch 748 in epoch 18, gen_loss = 0.8669932375603588, disc_loss = 0.0598477056742371
Trained batch 749 in epoch 18, gen_loss = 0.8670200141270955, disc_loss = 0.05979370552922288
Trained batch 750 in epoch 18, gen_loss = 0.8671101606320764, disc_loss = 0.05972773606297417
Trained batch 751 in epoch 18, gen_loss = 0.8675039651546073, disc_loss = 0.059701735730917055
Trained batch 752 in epoch 18, gen_loss = 0.8677409835070727, disc_loss = 0.059711111546215785
Trained batch 753 in epoch 18, gen_loss = 0.8674485834429055, disc_loss = 0.05970251781307655
Trained batch 754 in epoch 18, gen_loss = 0.8671237336878745, disc_loss = 0.05977966639133084
Trained batch 755 in epoch 18, gen_loss = 0.8670918729412492, disc_loss = 0.05976332529206519
Trained batch 756 in epoch 18, gen_loss = 0.8671313464405357, disc_loss = 0.05974956887529344
Trained batch 757 in epoch 18, gen_loss = 0.8669645575546023, disc_loss = 0.05975303797193835
Trained batch 758 in epoch 18, gen_loss = 0.8670823845781671, disc_loss = 0.05980504469330053
Trained batch 759 in epoch 18, gen_loss = 0.867367777071501, disc_loss = 0.05973876156893216
Trained batch 760 in epoch 18, gen_loss = 0.8670965860770347, disc_loss = 0.05971970177119727
Trained batch 761 in epoch 18, gen_loss = 0.867401370539127, disc_loss = 0.059666080801231966
Trained batch 762 in epoch 18, gen_loss = 0.8677013414090458, disc_loss = 0.05960231159263209
Trained batch 763 in epoch 18, gen_loss = 0.8679552549467037, disc_loss = 0.059535328802257696
Trained batch 764 in epoch 18, gen_loss = 0.8680460629899517, disc_loss = 0.05947023518261761
Trained batch 765 in epoch 18, gen_loss = 0.8680818330681355, disc_loss = 0.05944787354546528
Trained batch 766 in epoch 18, gen_loss = 0.8684605073276057, disc_loss = 0.059396941206300194
Trained batch 767 in epoch 18, gen_loss = 0.8685277740781506, disc_loss = 0.05933197344711516
Trained batch 768 in epoch 18, gen_loss = 0.8685399980631854, disc_loss = 0.0594461035269212
Trained batch 769 in epoch 18, gen_loss = 0.8686866435911749, disc_loss = 0.059386947867158174
Trained batch 770 in epoch 18, gen_loss = 0.8682663511054834, disc_loss = 0.0595598311082553
Trained batch 771 in epoch 18, gen_loss = 0.8679341805876846, disc_loss = 0.059568472061827395
Trained batch 772 in epoch 18, gen_loss = 0.8681718377061526, disc_loss = 0.05957840677027869
Trained batch 773 in epoch 18, gen_loss = 0.8682820844711875, disc_loss = 0.05959720814297365
Trained batch 774 in epoch 18, gen_loss = 0.8684217408395583, disc_loss = 0.059529681649179225
Trained batch 775 in epoch 18, gen_loss = 0.8682157209853536, disc_loss = 0.05957761022967968
Trained batch 776 in epoch 18, gen_loss = 0.8681155468506242, disc_loss = 0.05955079353823203
Trained batch 777 in epoch 18, gen_loss = 0.868309186096363, disc_loss = 0.05968444795014964
Trained batch 778 in epoch 18, gen_loss = 0.8683642771798012, disc_loss = 0.05965199706590566
Trained batch 779 in epoch 18, gen_loss = 0.8682311135224807, disc_loss = 0.0596502598721343
Trained batch 780 in epoch 18, gen_loss = 0.8678413198333086, disc_loss = 0.05971827235540301
Trained batch 781 in epoch 18, gen_loss = 0.8684447958798664, disc_loss = 0.059688506096534796
Trained batch 782 in epoch 18, gen_loss = 0.8685114226122012, disc_loss = 0.059628970208571865
Trained batch 783 in epoch 18, gen_loss = 0.8685895399931742, disc_loss = 0.0598169047093228
Trained batch 784 in epoch 18, gen_loss = 0.8682643847101054, disc_loss = 0.05988465441379008
Trained batch 785 in epoch 18, gen_loss = 0.8680548915881237, disc_loss = 0.059870025694000586
Trained batch 786 in epoch 18, gen_loss = 0.8683052548459403, disc_loss = 0.05981557936143731
Trained batch 787 in epoch 18, gen_loss = 0.8684158834255287, disc_loss = 0.05993861006927407
Trained batch 788 in epoch 18, gen_loss = 0.8680337204377159, disc_loss = 0.060022512331595515
Trained batch 789 in epoch 18, gen_loss = 0.8677676917631415, disc_loss = 0.060055581759661435
Testing Epoch 18
Training Epoch 19
Trained batch 0 in epoch 19, gen_loss = 0.7798908948898315, disc_loss = 0.03404080867767334
Trained batch 1 in epoch 19, gen_loss = 0.8624982237815857, disc_loss = 0.0356262493878603
Trained batch 2 in epoch 19, gen_loss = 0.9007438023885092, disc_loss = 0.030074213941891987
Trained batch 3 in epoch 19, gen_loss = 0.8794203102588654, disc_loss = 0.03677775897085667
Trained batch 4 in epoch 19, gen_loss = 0.9104530096054078, disc_loss = 0.0314291812479496
Trained batch 5 in epoch 19, gen_loss = 0.8771955569585165, disc_loss = 0.03297764870027701
Trained batch 6 in epoch 19, gen_loss = 0.844572935785566, disc_loss = 0.047312869025128226
Trained batch 7 in epoch 19, gen_loss = 0.8374614864587784, disc_loss = 0.04651637375354767
Trained batch 8 in epoch 19, gen_loss = 0.8386340075069003, disc_loss = 0.04276958594305648
Trained batch 9 in epoch 19, gen_loss = 0.8763599455356598, disc_loss = 0.04335797419771552
Trained batch 10 in epoch 19, gen_loss = 0.8686874942346052, disc_loss = 0.04260133604773066
Trained batch 11 in epoch 19, gen_loss = 0.8760734051465988, disc_loss = 0.039969660341739655
Trained batch 12 in epoch 19, gen_loss = 0.8972003689179053, disc_loss = 0.038277927929392226
Trained batch 13 in epoch 19, gen_loss = 0.8858090596539634, disc_loss = 0.03753661923110485
Trained batch 14 in epoch 19, gen_loss = 0.8912363131841023, disc_loss = 0.036329226568341255
Trained batch 15 in epoch 19, gen_loss = 0.8844964355230331, disc_loss = 0.03582324553281069
Trained batch 16 in epoch 19, gen_loss = 0.885336111573612, disc_loss = 0.03438764503773521
Trained batch 17 in epoch 19, gen_loss = 0.8823999298943414, disc_loss = 0.03471929166052076
Trained batch 18 in epoch 19, gen_loss = 0.8841641764891776, disc_loss = 0.03317182261104647
Trained batch 19 in epoch 19, gen_loss = 0.8873971253633499, disc_loss = 0.03214414780959487
Trained batch 20 in epoch 19, gen_loss = 0.8739070211138044, disc_loss = 0.03382320906079951
Trained batch 21 in epoch 19, gen_loss = 0.8770454688505693, disc_loss = 0.03400450089777058
Trained batch 22 in epoch 19, gen_loss = 0.8688694912454357, disc_loss = 0.035564416371609855
Trained batch 23 in epoch 19, gen_loss = 0.8695319021741549, disc_loss = 0.034796649512524404
Trained batch 24 in epoch 19, gen_loss = 0.8677964091300965, disc_loss = 0.03453497797250748
Trained batch 25 in epoch 19, gen_loss = 0.8598202856687399, disc_loss = 0.03613826288626744
Trained batch 26 in epoch 19, gen_loss = 0.8762873477405972, disc_loss = 0.0370947285382836
Trained batch 27 in epoch 19, gen_loss = 0.8734010245118823, disc_loss = 0.03843824192881584
Trained batch 28 in epoch 19, gen_loss = 0.8715747800366632, disc_loss = 0.037536021257782805
Trained batch 29 in epoch 19, gen_loss = 0.8766611893971761, disc_loss = 0.03695546773572763
Trained batch 30 in epoch 19, gen_loss = 0.8850055548452562, disc_loss = 0.036480655773512775
Trained batch 31 in epoch 19, gen_loss = 0.8911685608327389, disc_loss = 0.03562353545567021
Trained batch 32 in epoch 19, gen_loss = 0.8870102997982141, disc_loss = 0.03631630760024895
Trained batch 33 in epoch 19, gen_loss = 0.8848800291033352, disc_loss = 0.03593577137764763
Trained batch 34 in epoch 19, gen_loss = 0.8972447173936027, disc_loss = 0.038481405377388
Trained batch 35 in epoch 19, gen_loss = 0.9043642464611266, disc_loss = 0.037657931007237896
Trained batch 36 in epoch 19, gen_loss = 0.8990606939470446, disc_loss = 0.038938602457779484
Trained batch 37 in epoch 19, gen_loss = 0.9007481164053867, disc_loss = 0.03849206352606416
Trained batch 38 in epoch 19, gen_loss = 0.9008312057226132, disc_loss = 0.037881104251704156
Trained batch 39 in epoch 19, gen_loss = 0.8932444855570794, disc_loss = 0.039269536011852325
Trained batch 40 in epoch 19, gen_loss = 0.9035030734248277, disc_loss = 0.03901696743489039
Trained batch 41 in epoch 19, gen_loss = 0.9050288938340687, disc_loss = 0.03999451966956258
Trained batch 42 in epoch 19, gen_loss = 0.9029256826223329, disc_loss = 0.03956637126501909
Trained batch 43 in epoch 19, gen_loss = 0.9036714962937615, disc_loss = 0.03935346547090872
Trained batch 44 in epoch 19, gen_loss = 0.9038345641560025, disc_loss = 0.038764388859272005
Trained batch 45 in epoch 19, gen_loss = 0.9029437536778657, disc_loss = 0.03841226491267267
Trained batch 46 in epoch 19, gen_loss = 0.9090260723803906, disc_loss = 0.038704403775169496
Trained batch 47 in epoch 19, gen_loss = 0.9104510582983494, disc_loss = 0.038041728403186426
Trained batch 48 in epoch 19, gen_loss = 0.9063153412877297, disc_loss = 0.03836859679989973
Trained batch 49 in epoch 19, gen_loss = 0.9106649684906006, disc_loss = 0.03790454818867147
Trained batch 50 in epoch 19, gen_loss = 0.9111533702588549, disc_loss = 0.03734493196266247
Trained batch 51 in epoch 19, gen_loss = 0.9133308277680323, disc_loss = 0.03694608194144586
Trained batch 52 in epoch 19, gen_loss = 0.9148798337522542, disc_loss = 0.03705553038326918
Trained batch 53 in epoch 19, gen_loss = 0.9133127784287488, disc_loss = 0.036688649362918956
Trained batch 54 in epoch 19, gen_loss = 0.9074898524717852, disc_loss = 0.03783023813739419
Trained batch 55 in epoch 19, gen_loss = 0.91316961816379, disc_loss = 0.03782327994537939
Trained batch 56 in epoch 19, gen_loss = 0.9133952918805575, disc_loss = 0.03851984116951363
Trained batch 57 in epoch 19, gen_loss = 0.9124683912458091, disc_loss = 0.0382274549759539
Trained batch 58 in epoch 19, gen_loss = 0.9110095268588955, disc_loss = 0.037825808805113624
Trained batch 59 in epoch 19, gen_loss = 0.9143051713705063, disc_loss = 0.037341157401291035
Trained batch 60 in epoch 19, gen_loss = 0.9141773259053465, disc_loss = 0.036849337141411226
Trained batch 61 in epoch 19, gen_loss = 0.9144627182714401, disc_loss = 0.036350890453304016
Trained batch 62 in epoch 19, gen_loss = 0.9099975124238029, disc_loss = 0.036854152464204364
Trained batch 63 in epoch 19, gen_loss = 0.9115946888923645, disc_loss = 0.036729085812112316
Trained batch 64 in epoch 19, gen_loss = 0.9164362540611855, disc_loss = 0.03663349303488548
Trained batch 65 in epoch 19, gen_loss = 0.9200065533320109, disc_loss = 0.03628476124934175
Trained batch 66 in epoch 19, gen_loss = 0.9204244240006404, disc_loss = 0.03637020898732676
Trained batch 67 in epoch 19, gen_loss = 0.9169347461532144, disc_loss = 0.036941206164877206
Trained batch 68 in epoch 19, gen_loss = 0.913790850535683, disc_loss = 0.03754824624005435
Trained batch 69 in epoch 19, gen_loss = 0.9145047741276877, disc_loss = 0.037674048569585596
Trained batch 70 in epoch 19, gen_loss = 0.9154471402436914, disc_loss = 0.03878451466665302
Trained batch 71 in epoch 19, gen_loss = 0.917055698732535, disc_loss = 0.03836865163046039
Trained batch 72 in epoch 19, gen_loss = 0.9136327186675921, disc_loss = 0.039204029175006365
Trained batch 73 in epoch 19, gen_loss = 0.9096865645937018, disc_loss = 0.04094620390065216
Trained batch 74 in epoch 19, gen_loss = 0.9119218627611796, disc_loss = 0.04184383500367403
Trained batch 75 in epoch 19, gen_loss = 0.9106821668775458, disc_loss = 0.04198519845101002
Trained batch 76 in epoch 19, gen_loss = 0.9091493758288297, disc_loss = 0.042155775144793
Trained batch 77 in epoch 19, gen_loss = 0.9090104255920801, disc_loss = 0.0419184578797565
Trained batch 78 in epoch 19, gen_loss = 0.9085717148418668, disc_loss = 0.0415492165786556
Trained batch 79 in epoch 19, gen_loss = 0.9106535173952579, disc_loss = 0.04115234655328095
Trained batch 80 in epoch 19, gen_loss = 0.9093886474032461, disc_loss = 0.040883943208573775
Trained batch 81 in epoch 19, gen_loss = 0.9105194131048714, disc_loss = 0.04140345275220347
Trained batch 82 in epoch 19, gen_loss = 0.9066575600440243, disc_loss = 0.04168728384447385
Trained batch 83 in epoch 19, gen_loss = 0.9085208284003394, disc_loss = 0.04135967748949215
Trained batch 84 in epoch 19, gen_loss = 0.9075487171902376, disc_loss = 0.04105611760169268
Trained batch 85 in epoch 19, gen_loss = 0.9115443998991057, disc_loss = 0.040779387632514846
Trained batch 86 in epoch 19, gen_loss = 0.9093808634527798, disc_loss = 0.041259361934130906
Trained batch 87 in epoch 19, gen_loss = 0.9092708013274453, disc_loss = 0.0408833277919753
Trained batch 88 in epoch 19, gen_loss = 0.9116956759034918, disc_loss = 0.04131100916962945
Trained batch 89 in epoch 19, gen_loss = 0.9094356603092617, disc_loss = 0.04122721432811684
Trained batch 90 in epoch 19, gen_loss = 0.9092937825800298, disc_loss = 0.041092383583168406
Trained batch 91 in epoch 19, gen_loss = 0.9054093334985815, disc_loss = 0.042263009544947876
Trained batch 92 in epoch 19, gen_loss = 0.9079356706270607, disc_loss = 0.04219193980898908
Trained batch 93 in epoch 19, gen_loss = 0.9086797820760849, disc_loss = 0.04205284725399094
Trained batch 94 in epoch 19, gen_loss = 0.9064661239322863, disc_loss = 0.042454733013322477
Trained batch 95 in epoch 19, gen_loss = 0.9055632079641024, disc_loss = 0.04223577284331744
Trained batch 96 in epoch 19, gen_loss = 0.9036100433044827, disc_loss = 0.042338255235982926
Trained batch 97 in epoch 19, gen_loss = 0.9044580009518838, disc_loss = 0.04200631440902243
Trained batch 98 in epoch 19, gen_loss = 0.9020070210851804, disc_loss = 0.0419023669127262
Trained batch 99 in epoch 19, gen_loss = 0.9030508315563202, disc_loss = 0.041672942079603675
Trained batch 100 in epoch 19, gen_loss = 0.9048510341361018, disc_loss = 0.04170190384334857
Trained batch 101 in epoch 19, gen_loss = 0.9028369293493383, disc_loss = 0.04156986987400873
Trained batch 102 in epoch 19, gen_loss = 0.902971877635104, disc_loss = 0.04125106114062291
Trained batch 103 in epoch 19, gen_loss = 0.9013547559197133, disc_loss = 0.041108266038533584
Trained batch 104 in epoch 19, gen_loss = 0.9007079709143866, disc_loss = 0.04086958792592798
Trained batch 105 in epoch 19, gen_loss = 0.9049743655717598, disc_loss = 0.04096042784809504
Trained batch 106 in epoch 19, gen_loss = 0.9067690589717615, disc_loss = 0.04141782180658568
Trained batch 107 in epoch 19, gen_loss = 0.9065587879331024, disc_loss = 0.041378742066660416
Trained batch 108 in epoch 19, gen_loss = 0.9030834567656211, disc_loss = 0.042518719671926365
Trained batch 109 in epoch 19, gen_loss = 0.9041065801273692, disc_loss = 0.04238914818587628
Trained batch 110 in epoch 19, gen_loss = 0.9050518521317491, disc_loss = 0.0421121926592277
Trained batch 111 in epoch 19, gen_loss = 0.9059603725160871, disc_loss = 0.04196743750279503
Trained batch 112 in epoch 19, gen_loss = 0.9062849198822427, disc_loss = 0.04169770167003163
Trained batch 113 in epoch 19, gen_loss = 0.9052422297628302, disc_loss = 0.04148638926511794
Trained batch 114 in epoch 19, gen_loss = 0.9035215237866278, disc_loss = 0.04177716120105723
Trained batch 115 in epoch 19, gen_loss = 0.9033762812614441, disc_loss = 0.041610491767140295
Trained batch 116 in epoch 19, gen_loss = 0.9052098306835207, disc_loss = 0.04135370329340808
Trained batch 117 in epoch 19, gen_loss = 0.9047571117595091, disc_loss = 0.04141809897086883
Trained batch 118 in epoch 19, gen_loss = 0.9044212293224174, disc_loss = 0.04126589123879661
Trained batch 119 in epoch 19, gen_loss = 0.9040328751007716, disc_loss = 0.041277306231980525
Trained batch 120 in epoch 19, gen_loss = 0.9034219142819239, disc_loss = 0.04104098445959081
Trained batch 121 in epoch 19, gen_loss = 0.9039887160551353, disc_loss = 0.04080511405911358
Trained batch 122 in epoch 19, gen_loss = 0.9068933618747121, disc_loss = 0.040629431658341146
Trained batch 123 in epoch 19, gen_loss = 0.9056303472288193, disc_loss = 0.04049747565671081
Trained batch 124 in epoch 19, gen_loss = 0.905168616771698, disc_loss = 0.04028071942180395
Trained batch 125 in epoch 19, gen_loss = 0.9059660571908194, disc_loss = 0.04006215581108653
Trained batch 126 in epoch 19, gen_loss = 0.9063025886618247, disc_loss = 0.039799593110370825
Trained batch 127 in epoch 19, gen_loss = 0.9056838625110686, disc_loss = 0.039745041853166185
Trained batch 128 in epoch 19, gen_loss = 0.9071805648101393, disc_loss = 0.039632059113923895
Trained batch 129 in epoch 19, gen_loss = 0.9077993204960456, disc_loss = 0.0393987268782579
Trained batch 130 in epoch 19, gen_loss = 0.9058856527313931, disc_loss = 0.03958407021660841
Trained batch 131 in epoch 19, gen_loss = 0.9073827862739563, disc_loss = 0.03943240586103815
Trained batch 132 in epoch 19, gen_loss = 0.9072615450486204, disc_loss = 0.03930844942149811
Trained batch 133 in epoch 19, gen_loss = 0.908241682533008, disc_loss = 0.03923316313815651
Trained batch 134 in epoch 19, gen_loss = 0.9091012199719747, disc_loss = 0.039031439591889025
Trained batch 135 in epoch 19, gen_loss = 0.9072554334998131, disc_loss = 0.03903633247896591
Trained batch 136 in epoch 19, gen_loss = 0.9068145416948917, disc_loss = 0.03883386353697002
Trained batch 137 in epoch 19, gen_loss = 0.9075359844643137, disc_loss = 0.03869522046432763
Trained batch 138 in epoch 19, gen_loss = 0.9065044938231543, disc_loss = 0.03856631941262552
Trained batch 139 in epoch 19, gen_loss = 0.9071530657155173, disc_loss = 0.03835537695059819
Trained batch 140 in epoch 19, gen_loss = 0.906505989690199, disc_loss = 0.038136847746551884
Trained batch 141 in epoch 19, gen_loss = 0.9069212746452278, disc_loss = 0.037940138623013465
Trained batch 142 in epoch 19, gen_loss = 0.9076446198916935, disc_loss = 0.03773529944824172
Trained batch 143 in epoch 19, gen_loss = 0.9090427735613452, disc_loss = 0.037544856281278446
Trained batch 144 in epoch 19, gen_loss = 0.9088870229392216, disc_loss = 0.03735517596761728
Trained batch 145 in epoch 19, gen_loss = 0.9097662086356176, disc_loss = 0.037326489760195966
Trained batch 146 in epoch 19, gen_loss = 0.9102801599470126, disc_loss = 0.037128337709625966
Trained batch 147 in epoch 19, gen_loss = 0.9111518428937809, disc_loss = 0.0369469138755891
Trained batch 148 in epoch 19, gen_loss = 0.910805543397097, disc_loss = 0.03673684757652899
Trained batch 149 in epoch 19, gen_loss = 0.9113610017299653, disc_loss = 0.03797906677549084
Trained batch 150 in epoch 19, gen_loss = 0.9089181924497844, disc_loss = 0.039010272817747875
Trained batch 151 in epoch 19, gen_loss = 0.9081024288346893, disc_loss = 0.039026910518786234
Trained batch 152 in epoch 19, gen_loss = 0.9089886873376136, disc_loss = 0.039824506407907974
Trained batch 153 in epoch 19, gen_loss = 0.9064681255198145, disc_loss = 0.040846889360819934
Trained batch 154 in epoch 19, gen_loss = 0.9056284877561753, disc_loss = 0.04106461894247801
Trained batch 155 in epoch 19, gen_loss = 0.9083394717711669, disc_loss = 0.04239211220127077
Trained batch 156 in epoch 19, gen_loss = 0.9085799504996864, disc_loss = 0.042901689441767844
Trained batch 157 in epoch 19, gen_loss = 0.9062336306028729, disc_loss = 0.0444123750446435
Trained batch 158 in epoch 19, gen_loss = 0.9057135015913526, disc_loss = 0.04434944322016442
Trained batch 159 in epoch 19, gen_loss = 0.9069354612380266, disc_loss = 0.04443545984686352
Trained batch 160 in epoch 19, gen_loss = 0.9090326635733895, disc_loss = 0.045209443723054035
Trained batch 161 in epoch 19, gen_loss = 0.9073235734745309, disc_loss = 0.045699509211390474
Trained batch 162 in epoch 19, gen_loss = 0.9062369590156649, disc_loss = 0.045688610895325436
Trained batch 163 in epoch 19, gen_loss = 0.9073160061749016, disc_loss = 0.0456388257273541
Trained batch 164 in epoch 19, gen_loss = 0.905217215870366, disc_loss = 0.04602838125305645
Trained batch 165 in epoch 19, gen_loss = 0.906355232000351, disc_loss = 0.04642879718869745
Trained batch 166 in epoch 19, gen_loss = 0.9058109896625587, disc_loss = 0.046552799714584196
Trained batch 167 in epoch 19, gen_loss = 0.9049624190444038, disc_loss = 0.04642333750546511
Trained batch 168 in epoch 19, gen_loss = 0.9030492256378987, disc_loss = 0.04734423249056177
Trained batch 169 in epoch 19, gen_loss = 0.9039624866317301, disc_loss = 0.04742864556062747
Trained batch 170 in epoch 19, gen_loss = 0.9054360110857333, disc_loss = 0.04727204045422419
Trained batch 171 in epoch 19, gen_loss = 0.9045962992795679, disc_loss = 0.04769718683281437
Trained batch 172 in epoch 19, gen_loss = 0.9039462002026553, disc_loss = 0.047619779992611765
Trained batch 173 in epoch 19, gen_loss = 0.9024369473429932, disc_loss = 0.047808908327514756
Trained batch 174 in epoch 19, gen_loss = 0.9018876031466893, disc_loss = 0.04770340368683849
Trained batch 175 in epoch 19, gen_loss = 0.9014698134904559, disc_loss = 0.047596688197121366
Trained batch 176 in epoch 19, gen_loss = 0.9019740048774891, disc_loss = 0.04740465428722275
Trained batch 177 in epoch 19, gen_loss = 0.901318148615655, disc_loss = 0.04718128955148663
Trained batch 178 in epoch 19, gen_loss = 0.900960719452224, disc_loss = 0.04701542980479878
Trained batch 179 in epoch 19, gen_loss = 0.9004126048750347, disc_loss = 0.046841520756586555
Trained batch 180 in epoch 19, gen_loss = 0.8993539727853807, disc_loss = 0.04679831998546232
Trained batch 181 in epoch 19, gen_loss = 0.8987511904030056, disc_loss = 0.046650661096734165
Trained batch 182 in epoch 19, gen_loss = 0.8994467320337973, disc_loss = 0.04660153397374221
Trained batch 183 in epoch 19, gen_loss = 0.8977332202636678, disc_loss = 0.04699957650407906
Trained batch 184 in epoch 19, gen_loss = 0.8983546704859346, disc_loss = 0.04681507152933124
Trained batch 185 in epoch 19, gen_loss = 0.8981007436911265, disc_loss = 0.046632285843232785
Trained batch 186 in epoch 19, gen_loss = 0.8994342455251969, disc_loss = 0.04652461393880732
Trained batch 187 in epoch 19, gen_loss = 0.9003143123489745, disc_loss = 0.04633387352805585
Trained batch 188 in epoch 19, gen_loss = 0.9000419050297409, disc_loss = 0.04644221327853976
Trained batch 189 in epoch 19, gen_loss = 0.8985861426905581, disc_loss = 0.046693753963336346
Trained batch 190 in epoch 19, gen_loss = 0.8976459487570518, disc_loss = 0.04688234331027766
Trained batch 191 in epoch 19, gen_loss = 0.8973314467196664, disc_loss = 0.046863617882384766
Trained batch 192 in epoch 19, gen_loss = 0.8983117592149448, disc_loss = 0.04768569586277394
Trained batch 193 in epoch 19, gen_loss = 0.8969455216963267, disc_loss = 0.04764014098687654
Trained batch 194 in epoch 19, gen_loss = 0.896259296246064, disc_loss = 0.04758728570901813
Trained batch 195 in epoch 19, gen_loss = 0.8966344479395418, disc_loss = 0.04738299426271067
Trained batch 196 in epoch 19, gen_loss = 0.8955275588834346, disc_loss = 0.04739565662519656
Trained batch 197 in epoch 19, gen_loss = 0.895988706085417, disc_loss = 0.047204271116472706
Trained batch 198 in epoch 19, gen_loss = 0.8966544336410024, disc_loss = 0.047010713287315625
Trained batch 199 in epoch 19, gen_loss = 0.895680575966835, disc_loss = 0.0470426055486314
Trained batch 200 in epoch 19, gen_loss = 0.8960759378784332, disc_loss = 0.04687434501380692
Trained batch 201 in epoch 19, gen_loss = 0.8958253299835885, disc_loss = 0.046826734232928345
Trained batch 202 in epoch 19, gen_loss = 0.8955805921202222, disc_loss = 0.047166460746523045
Trained batch 203 in epoch 19, gen_loss = 0.8950352540203169, disc_loss = 0.04709038843044683
Trained batch 204 in epoch 19, gen_loss = 0.8949264863642251, disc_loss = 0.046959063735586115
Trained batch 205 in epoch 19, gen_loss = 0.8941480957188652, disc_loss = 0.046954937295047836
Trained batch 206 in epoch 19, gen_loss = 0.8947767364806023, disc_loss = 0.04691872801316749
Trained batch 207 in epoch 19, gen_loss = 0.894929396131864, disc_loss = 0.04678208656528463
Trained batch 208 in epoch 19, gen_loss = 0.8948870908700678, disc_loss = 0.04662073881958018
Trained batch 209 in epoch 19, gen_loss = 0.8944223284721374, disc_loss = 0.046702805026212615
Trained batch 210 in epoch 19, gen_loss = 0.8950989788742427, disc_loss = 0.04711640291401489
Trained batch 211 in epoch 19, gen_loss = 0.8945401490859266, disc_loss = 0.04710755452188611
Trained batch 212 in epoch 19, gen_loss = 0.8928348049871239, disc_loss = 0.04763234841108252
Trained batch 213 in epoch 19, gen_loss = 0.8937017165611838, disc_loss = 0.047646027726391066
Trained batch 214 in epoch 19, gen_loss = 0.8928948269333951, disc_loss = 0.04786437556450797
Trained batch 215 in epoch 19, gen_loss = 0.8924557583199607, disc_loss = 0.048098189762741744
Trained batch 216 in epoch 19, gen_loss = 0.8931852903234244, disc_loss = 0.04796573346103048
Trained batch 217 in epoch 19, gen_loss = 0.8927255220916293, disc_loss = 0.04817464053758992
Trained batch 218 in epoch 19, gen_loss = 0.8918912968679106, disc_loss = 0.048208298236046616
Trained batch 219 in epoch 19, gen_loss = 0.8911659804257479, disc_loss = 0.04841899563431401
Trained batch 220 in epoch 19, gen_loss = 0.8912975432106812, disc_loss = 0.04828052482108387
Trained batch 221 in epoch 19, gen_loss = 0.8903422369076325, disc_loss = 0.04833955616220362
Trained batch 222 in epoch 19, gen_loss = 0.8899119274498636, disc_loss = 0.04819593326952893
Trained batch 223 in epoch 19, gen_loss = 0.8896351789257356, disc_loss = 0.04804605012551682
Trained batch 224 in epoch 19, gen_loss = 0.8899761637051901, disc_loss = 0.04787517462132706
Trained batch 225 in epoch 19, gen_loss = 0.8888558626702402, disc_loss = 0.047862111819512415
Trained batch 226 in epoch 19, gen_loss = 0.8884481871705748, disc_loss = 0.04793325790905677
Trained batch 227 in epoch 19, gen_loss = 0.8894071069202925, disc_loss = 0.04781067637489749
Trained batch 228 in epoch 19, gen_loss = 0.8890164723562882, disc_loss = 0.04773311259826914
Trained batch 229 in epoch 19, gen_loss = 0.8887039441129435, disc_loss = 0.047568017351643545
Trained batch 230 in epoch 19, gen_loss = 0.8899004998661223, disc_loss = 0.04774993023677886
Trained batch 231 in epoch 19, gen_loss = 0.8890001791818388, disc_loss = 0.047823469389374526
Trained batch 232 in epoch 19, gen_loss = 0.889657888033871, disc_loss = 0.047667175349519614
Trained batch 233 in epoch 19, gen_loss = 0.8895488837335863, disc_loss = 0.04757782343464593
Trained batch 234 in epoch 19, gen_loss = 0.8899354275236738, disc_loss = 0.0474685888519471
Trained batch 235 in epoch 19, gen_loss = 0.8892023512872599, disc_loss = 0.04746066985880735
Trained batch 236 in epoch 19, gen_loss = 0.8894721156434168, disc_loss = 0.0472966124036424
Trained batch 237 in epoch 19, gen_loss = 0.8889620051163585, disc_loss = 0.04737871824450666
Trained batch 238 in epoch 19, gen_loss = 0.8889551651527692, disc_loss = 0.047251977994804226
Trained batch 239 in epoch 19, gen_loss = 0.8901097739736239, disc_loss = 0.04712510730023496
Trained batch 240 in epoch 19, gen_loss = 0.8901995979404054, disc_loss = 0.04700587060943988
Trained batch 241 in epoch 19, gen_loss = 0.8905328884105052, disc_loss = 0.04684047323405312
Trained batch 242 in epoch 19, gen_loss = 0.8903353111243543, disc_loss = 0.04676730202802231
Trained batch 243 in epoch 19, gen_loss = 0.8905269650162243, disc_loss = 0.04694084208038803
Trained batch 244 in epoch 19, gen_loss = 0.8901394931637511, disc_loss = 0.04684152086360418
Trained batch 245 in epoch 19, gen_loss = 0.8893534005657444, disc_loss = 0.046971561979669015
Trained batch 246 in epoch 19, gen_loss = 0.8902017821667165, disc_loss = 0.04684920674039104
Trained batch 247 in epoch 19, gen_loss = 0.8914303248447757, disc_loss = 0.04681664223279504
Trained batch 248 in epoch 19, gen_loss = 0.8921729654193403, disc_loss = 0.04665751309960662
Trained batch 249 in epoch 19, gen_loss = 0.8934145181179046, disc_loss = 0.046652557408437136
Trained batch 250 in epoch 19, gen_loss = 0.8929491819613483, disc_loss = 0.04664187902673723
Trained batch 251 in epoch 19, gen_loss = 0.8926492122903703, disc_loss = 0.046533787857726334
Trained batch 252 in epoch 19, gen_loss = 0.8919605226384792, disc_loss = 0.04650019192994524
Trained batch 253 in epoch 19, gen_loss = 0.8914700410966798, disc_loss = 0.04646044189117732
Trained batch 254 in epoch 19, gen_loss = 0.8931759392513948, disc_loss = 0.0466066276891997
Trained batch 255 in epoch 19, gen_loss = 0.8933520016726106, disc_loss = 0.04647493807897263
Trained batch 256 in epoch 19, gen_loss = 0.8929039599366689, disc_loss = 0.04637103193124271
Trained batch 257 in epoch 19, gen_loss = 0.8927377568658932, disc_loss = 0.046265800954600755
Trained batch 258 in epoch 19, gen_loss = 0.8925476394104681, disc_loss = 0.04626503579757216
Trained batch 259 in epoch 19, gen_loss = 0.8929912285162852, disc_loss = 0.0461216709164616
Trained batch 260 in epoch 19, gen_loss = 0.8930968048472058, disc_loss = 0.04598019160223247
Trained batch 261 in epoch 19, gen_loss = 0.8921641514046501, disc_loss = 0.04618890654075294
Trained batch 262 in epoch 19, gen_loss = 0.8924666708866453, disc_loss = 0.046096263540122556
Trained batch 263 in epoch 19, gen_loss = 0.8933736074602965, disc_loss = 0.04617764482761479
Trained batch 264 in epoch 19, gen_loss = 0.894019467200873, disc_loss = 0.04605463093919855
Trained batch 265 in epoch 19, gen_loss = 0.8947384866108572, disc_loss = 0.045915730764977354
Trained batch 266 in epoch 19, gen_loss = 0.8940497143438246, disc_loss = 0.04598721199623598
Trained batch 267 in epoch 19, gen_loss = 0.8944091476611237, disc_loss = 0.04583937135253991
Trained batch 268 in epoch 19, gen_loss = 0.8941426775712507, disc_loss = 0.045808172246378925
Trained batch 269 in epoch 19, gen_loss = 0.8954760977515468, disc_loss = 0.045774249468619625
Trained batch 270 in epoch 19, gen_loss = 0.8951258503203022, disc_loss = 0.045717696454788376
Trained batch 271 in epoch 19, gen_loss = 0.8936109198805164, disc_loss = 0.045912730731823316
Trained batch 272 in epoch 19, gen_loss = 0.8940857978530856, disc_loss = 0.04587824408463015
Trained batch 273 in epoch 19, gen_loss = 0.8935485210296882, disc_loss = 0.045859226091921224
Trained batch 274 in epoch 19, gen_loss = 0.894888777516105, disc_loss = 0.04583222653886134
Trained batch 275 in epoch 19, gen_loss = 0.8942072244657986, disc_loss = 0.04583714191592636
Trained batch 276 in epoch 19, gen_loss = 0.8947983463748698, disc_loss = 0.046097182858708424
Trained batch 277 in epoch 19, gen_loss = 0.8953975409054927, disc_loss = 0.04596725754312528
Trained batch 278 in epoch 19, gen_loss = 0.8943916123400453, disc_loss = 0.046122095939840145
Trained batch 279 in epoch 19, gen_loss = 0.8943778140204294, disc_loss = 0.04601088915452627
Trained batch 280 in epoch 19, gen_loss = 0.8948207928192573, disc_loss = 0.046010436074231546
Trained batch 281 in epoch 19, gen_loss = 0.8939307530721029, disc_loss = 0.04626990880004744
Trained batch 282 in epoch 19, gen_loss = 0.8938002712735018, disc_loss = 0.04621420646836659
Trained batch 283 in epoch 19, gen_loss = 0.8937770650840141, disc_loss = 0.046130224624583105
Trained batch 284 in epoch 19, gen_loss = 0.8942286828108001, disc_loss = 0.04601360699488667
Trained batch 285 in epoch 19, gen_loss = 0.8945183024539815, disc_loss = 0.04685393375852569
Trained batch 286 in epoch 19, gen_loss = 0.8936602068279679, disc_loss = 0.04706874654793833
Trained batch 287 in epoch 19, gen_loss = 0.8926307027124696, disc_loss = 0.047282698423562884
Trained batch 288 in epoch 19, gen_loss = 0.8927062052756445, disc_loss = 0.047425258725842905
Trained batch 289 in epoch 19, gen_loss = 0.8923703808208991, disc_loss = 0.0475950595521336
Trained batch 290 in epoch 19, gen_loss = 0.8913460720036038, disc_loss = 0.047665673370482685
Trained batch 291 in epoch 19, gen_loss = 0.890824702912814, disc_loss = 0.047667469856431326
Trained batch 292 in epoch 19, gen_loss = 0.8905040833323482, disc_loss = 0.04761813601491648
Trained batch 293 in epoch 19, gen_loss = 0.8896435667462901, disc_loss = 0.04776837377885015
Trained batch 294 in epoch 19, gen_loss = 0.8896938275482695, disc_loss = 0.04799694219540994
Trained batch 295 in epoch 19, gen_loss = 0.8896803479339626, disc_loss = 0.047879929297188345
Trained batch 296 in epoch 19, gen_loss = 0.889248950513525, disc_loss = 0.048145386225760284
Trained batch 297 in epoch 19, gen_loss = 0.889049619436264, disc_loss = 0.04806085856750157
Trained batch 298 in epoch 19, gen_loss = 0.8884909645370815, disc_loss = 0.0480617461523608
Trained batch 299 in epoch 19, gen_loss = 0.8884240627288819, disc_loss = 0.048029365870170294
Trained batch 300 in epoch 19, gen_loss = 0.8885492791369112, disc_loss = 0.04792510316648406
Trained batch 301 in epoch 19, gen_loss = 0.8887988038805147, disc_loss = 0.04778897471954146
Trained batch 302 in epoch 19, gen_loss = 0.889250641412074, disc_loss = 0.047982688545996306
Trained batch 303 in epoch 19, gen_loss = 0.8893239629503927, disc_loss = 0.04786202482615696
Trained batch 304 in epoch 19, gen_loss = 0.8879271692916996, disc_loss = 0.04830237949022748
Trained batch 305 in epoch 19, gen_loss = 0.8883211930203282, disc_loss = 0.048240862216106524
Trained batch 306 in epoch 19, gen_loss = 0.8881611167802096, disc_loss = 0.04818181854487679
Trained batch 307 in epoch 19, gen_loss = 0.8886530105169718, disc_loss = 0.04805342637322988
Trained batch 308 in epoch 19, gen_loss = 0.8885865196055193, disc_loss = 0.04793010892129494
Trained batch 309 in epoch 19, gen_loss = 0.889012223674405, disc_loss = 0.047804855788126585
Trained batch 310 in epoch 19, gen_loss = 0.8894952968769135, disc_loss = 0.0476817914967536
Trained batch 311 in epoch 19, gen_loss = 0.8896485819266393, disc_loss = 0.04771616468534399
Trained batch 312 in epoch 19, gen_loss = 0.8884602080518826, disc_loss = 0.0482153941180926
Trained batch 313 in epoch 19, gen_loss = 0.8879644141835012, disc_loss = 0.04820229680051991
Trained batch 314 in epoch 19, gen_loss = 0.8878064698643154, disc_loss = 0.04820561460884554
Trained batch 315 in epoch 19, gen_loss = 0.8891891582479959, disc_loss = 0.04823227765339226
Trained batch 316 in epoch 19, gen_loss = 0.8894743977661013, disc_loss = 0.048108874289877125
Trained batch 317 in epoch 19, gen_loss = 0.8896468276122831, disc_loss = 0.04810495839348801
Trained batch 318 in epoch 19, gen_loss = 0.8894466972650031, disc_loss = 0.04813694798162785
Trained batch 319 in epoch 19, gen_loss = 0.8886094911023974, disc_loss = 0.04832964116503717
Trained batch 320 in epoch 19, gen_loss = 0.889957158179298, disc_loss = 0.04863116559006761
Trained batch 321 in epoch 19, gen_loss = 0.8900302833651904, disc_loss = 0.04852063924230358
Trained batch 322 in epoch 19, gen_loss = 0.8906211048456907, disc_loss = 0.048412532783502674
Trained batch 323 in epoch 19, gen_loss = 0.8903019794343431, disc_loss = 0.04836141039117205
Trained batch 324 in epoch 19, gen_loss = 0.8900987164790813, disc_loss = 0.04830471743041506
Trained batch 325 in epoch 19, gen_loss = 0.8900338760548574, disc_loss = 0.048202495109232746
Trained batch 326 in epoch 19, gen_loss = 0.8906704462631763, disc_loss = 0.0481059872687706
Trained batch 327 in epoch 19, gen_loss = 0.8912161746766509, disc_loss = 0.04801067461333487
Trained batch 328 in epoch 19, gen_loss = 0.8917219173219791, disc_loss = 0.047888675926813694
Trained batch 329 in epoch 19, gen_loss = 0.8916659055334148, disc_loss = 0.04780745620444191
Trained batch 330 in epoch 19, gen_loss = 0.8917459688878131, disc_loss = 0.047702040564088756
Trained batch 331 in epoch 19, gen_loss = 0.8917380772441267, disc_loss = 0.04758031941467829
Trained batch 332 in epoch 19, gen_loss = 0.8923514877353702, disc_loss = 0.047465487338557794
Trained batch 333 in epoch 19, gen_loss = 0.8926024729620197, disc_loss = 0.047350029391376024
Trained batch 334 in epoch 19, gen_loss = 0.8930530313235611, disc_loss = 0.04724310651254743
Trained batch 335 in epoch 19, gen_loss = 0.8927275538444519, disc_loss = 0.0471639950798514
Trained batch 336 in epoch 19, gen_loss = 0.8930530827547747, disc_loss = 0.04743187921812608
Trained batch 337 in epoch 19, gen_loss = 0.8925876367021595, disc_loss = 0.04740189768362944
Trained batch 338 in epoch 19, gen_loss = 0.8917421647581028, disc_loss = 0.047591390453586714
Trained batch 339 in epoch 19, gen_loss = 0.8919187505455578, disc_loss = 0.04758244221208288
Trained batch 340 in epoch 19, gen_loss = 0.8922028632457655, disc_loss = 0.04747410627393341
Trained batch 341 in epoch 19, gen_loss = 0.8928359028888725, disc_loss = 0.04740309276024413
Trained batch 342 in epoch 19, gen_loss = 0.8931005199171016, disc_loss = 0.04728615853892037
Trained batch 343 in epoch 19, gen_loss = 0.8926067927549052, disc_loss = 0.04732012134424389
Trained batch 344 in epoch 19, gen_loss = 0.8925684877063917, disc_loss = 0.047222348885691684
Trained batch 345 in epoch 19, gen_loss = 0.8927907892045258, disc_loss = 0.04748806405834036
Trained batch 346 in epoch 19, gen_loss = 0.8929409499814256, disc_loss = 0.0474159033373213
Trained batch 347 in epoch 19, gen_loss = 0.8923406499898296, disc_loss = 0.047459518847366176
Trained batch 348 in epoch 19, gen_loss = 0.8928290132465199, disc_loss = 0.047401919379232604
Trained batch 349 in epoch 19, gen_loss = 0.8927874992574965, disc_loss = 0.047307872027158734
Trained batch 350 in epoch 19, gen_loss = 0.8929715215990007, disc_loss = 0.04729333040211615
Trained batch 351 in epoch 19, gen_loss = 0.8926771825010126, disc_loss = 0.047254511970095336
Trained batch 352 in epoch 19, gen_loss = 0.8922001670507804, disc_loss = 0.04733933372259478
Trained batch 353 in epoch 19, gen_loss = 0.8930570166663262, disc_loss = 0.04726511138980671
Trained batch 354 in epoch 19, gen_loss = 0.8925122182134172, disc_loss = 0.04727213681793549
Trained batch 355 in epoch 19, gen_loss = 0.8922368415286032, disc_loss = 0.04716923631455624
Trained batch 356 in epoch 19, gen_loss = 0.8920475358054751, disc_loss = 0.0470609196412171
Trained batch 357 in epoch 19, gen_loss = 0.8922047535134427, disc_loss = 0.04695529576297329
Trained batch 358 in epoch 19, gen_loss = 0.8919682839786774, disc_loss = 0.04698571326434197
Trained batch 359 in epoch 19, gen_loss = 0.8914371485511462, disc_loss = 0.04694012996688899
Trained batch 360 in epoch 19, gen_loss = 0.8913958100731023, disc_loss = 0.04687591945788619
Trained batch 361 in epoch 19, gen_loss = 0.891372658435811, disc_loss = 0.0467884080839544
Trained batch 362 in epoch 19, gen_loss = 0.8916425056365568, disc_loss = 0.04679223323194695
Trained batch 363 in epoch 19, gen_loss = 0.8915264886486661, disc_loss = 0.04672204597423283
Trained batch 364 in epoch 19, gen_loss = 0.8916115857150456, disc_loss = 0.04697557357841567
Trained batch 365 in epoch 19, gen_loss = 0.8913585599002942, disc_loss = 0.04693645331245221
Trained batch 366 in epoch 19, gen_loss = 0.8910158620868132, disc_loss = 0.0469731668071258
Trained batch 367 in epoch 19, gen_loss = 0.8916772725465505, disc_loss = 0.04694512278681783
Trained batch 368 in epoch 19, gen_loss = 0.892420563109845, disc_loss = 0.04688439928853334
Trained batch 369 in epoch 19, gen_loss = 0.8921374573900893, disc_loss = 0.04689339378949355
Trained batch 370 in epoch 19, gen_loss = 0.8915496375361542, disc_loss = 0.046992855470356434
Trained batch 371 in epoch 19, gen_loss = 0.8921011719972857, disc_loss = 0.04735383421172618
Trained batch 372 in epoch 19, gen_loss = 0.8919927752689126, disc_loss = 0.04737672998492504
Trained batch 373 in epoch 19, gen_loss = 0.8916812642691607, disc_loss = 0.04732887122909573
Trained batch 374 in epoch 19, gen_loss = 0.8909782965977987, disc_loss = 0.04746112987150749
Trained batch 375 in epoch 19, gen_loss = 0.8910579605305449, disc_loss = 0.04739194148111137
Trained batch 376 in epoch 19, gen_loss = 0.8904531490581421, disc_loss = 0.0474012531710675
Trained batch 377 in epoch 19, gen_loss = 0.890487348118787, disc_loss = 0.04733364106397386
Trained batch 378 in epoch 19, gen_loss = 0.8905540401199562, disc_loss = 0.047602944565067036
Trained batch 379 in epoch 19, gen_loss = 0.8906309781890166, disc_loss = 0.04751057387819808
Trained batch 380 in epoch 19, gen_loss = 0.8908637550872142, disc_loss = 0.04741004514666836
Trained batch 381 in epoch 19, gen_loss = 0.890366712789885, disc_loss = 0.04760924855939537
Trained batch 382 in epoch 19, gen_loss = 0.8901933173286697, disc_loss = 0.04756445333595064
Trained batch 383 in epoch 19, gen_loss = 0.8901963423316678, disc_loss = 0.04758854575144748
Trained batch 384 in epoch 19, gen_loss = 0.8903771177514807, disc_loss = 0.047596675118842684
Trained batch 385 in epoch 19, gen_loss = 0.8907009801716385, disc_loss = 0.0475010285974321
Trained batch 386 in epoch 19, gen_loss = 0.8905753388577345, disc_loss = 0.047447107559026674
Trained batch 387 in epoch 19, gen_loss = 0.8905314243945879, disc_loss = 0.04735288160286613
Trained batch 388 in epoch 19, gen_loss = 0.8911379646213011, disc_loss = 0.04728932810856321
Trained batch 389 in epoch 19, gen_loss = 0.891587610122485, disc_loss = 0.04722060406914888
Trained batch 390 in epoch 19, gen_loss = 0.8911784154070003, disc_loss = 0.04732821994673108
Trained batch 391 in epoch 19, gen_loss = 0.8906337171792984, disc_loss = 0.047285368794347256
Trained batch 392 in epoch 19, gen_loss = 0.890354552645113, disc_loss = 0.047225420441450054
Trained batch 393 in epoch 19, gen_loss = 0.8909945385105114, disc_loss = 0.047315785231134916
Trained batch 394 in epoch 19, gen_loss = 0.8903949239585973, disc_loss = 0.04735572858230223
Trained batch 395 in epoch 19, gen_loss = 0.8916207849979401, disc_loss = 0.04738967419329165
Trained batch 396 in epoch 19, gen_loss = 0.8918044925937124, disc_loss = 0.047293676258128144
Trained batch 397 in epoch 19, gen_loss = 0.8924507170765843, disc_loss = 0.04727202521206521
Trained batch 398 in epoch 19, gen_loss = 0.8919905778160668, disc_loss = 0.04732622339023758
Trained batch 399 in epoch 19, gen_loss = 0.8916357882320881, disc_loss = 0.04732539952034131
Trained batch 400 in epoch 19, gen_loss = 0.8912639256724693, disc_loss = 0.04730698865074246
Trained batch 401 in epoch 19, gen_loss = 0.8915940334844352, disc_loss = 0.04720422613726401
Trained batch 402 in epoch 19, gen_loss = 0.8916725977774589, disc_loss = 0.04715310146907349
Trained batch 403 in epoch 19, gen_loss = 0.891481939666342, disc_loss = 0.04710288948176595
Trained batch 404 in epoch 19, gen_loss = 0.8913485460811191, disc_loss = 0.04711945181321583
Trained batch 405 in epoch 19, gen_loss = 0.8909231321565036, disc_loss = 0.04706931692488455
Trained batch 406 in epoch 19, gen_loss = 0.8906867498261922, disc_loss = 0.047032536268325785
Trained batch 407 in epoch 19, gen_loss = 0.8908711527200306, disc_loss = 0.04694496841379898
Trained batch 408 in epoch 19, gen_loss = 0.8908072731897125, disc_loss = 0.04688516276726877
Trained batch 409 in epoch 19, gen_loss = 0.8910322084659483, disc_loss = 0.04682639032466019
Trained batch 410 in epoch 19, gen_loss = 0.8909603712622557, disc_loss = 0.046763686125604054
Trained batch 411 in epoch 19, gen_loss = 0.8906368417936621, disc_loss = 0.04668400510557864
Trained batch 412 in epoch 19, gen_loss = 0.8908489457631515, disc_loss = 0.046635172722216234
Trained batch 413 in epoch 19, gen_loss = 0.8905384074086728, disc_loss = 0.04662584418268955
Trained batch 414 in epoch 19, gen_loss = 0.8901077543396547, disc_loss = 0.046663592093770044
Trained batch 415 in epoch 19, gen_loss = 0.8905839911447122, disc_loss = 0.04662736535940964
Trained batch 416 in epoch 19, gen_loss = 0.8904671598967316, disc_loss = 0.04654650466976692
Trained batch 417 in epoch 19, gen_loss = 0.8909586127580068, disc_loss = 0.046637153600534186
Trained batch 418 in epoch 19, gen_loss = 0.8904898372925552, disc_loss = 0.04677094316425642
Trained batch 419 in epoch 19, gen_loss = 0.8904364707924071, disc_loss = 0.046756308445973054
Trained batch 420 in epoch 19, gen_loss = 0.8907906867546027, disc_loss = 0.04680209229047678
Trained batch 421 in epoch 19, gen_loss = 0.8905002921113471, disc_loss = 0.04678090482561792
Trained batch 422 in epoch 19, gen_loss = 0.8911783131583645, disc_loss = 0.04705439219977839
Trained batch 423 in epoch 19, gen_loss = 0.8904406493002514, disc_loss = 0.047227529079635754
Trained batch 424 in epoch 19, gen_loss = 0.8899671379257651, disc_loss = 0.047275586943416034
Trained batch 425 in epoch 19, gen_loss = 0.8908272381399719, disc_loss = 0.04743452909721735
Trained batch 426 in epoch 19, gen_loss = 0.8906453843697452, disc_loss = 0.04739063548085561
Trained batch 427 in epoch 19, gen_loss = 0.8901619642415893, disc_loss = 0.04760579962422636
Trained batch 428 in epoch 19, gen_loss = 0.8901023668842716, disc_loss = 0.04757671091175857
Trained batch 429 in epoch 19, gen_loss = 0.8904071063496346, disc_loss = 0.0481307115145894
Trained batch 430 in epoch 19, gen_loss = 0.8897957630334487, disc_loss = 0.048166997073836225
Trained batch 431 in epoch 19, gen_loss = 0.8893752633421509, disc_loss = 0.04819716940875406
Trained batch 432 in epoch 19, gen_loss = 0.889785010875235, disc_loss = 0.04870263974055407
Trained batch 433 in epoch 19, gen_loss = 0.8890892546023091, disc_loss = 0.04885628264963902
Trained batch 434 in epoch 19, gen_loss = 0.8887897369505345, disc_loss = 0.04884023281863366
Trained batch 435 in epoch 19, gen_loss = 0.8885603739854393, disc_loss = 0.04884215099138951
Trained batch 436 in epoch 19, gen_loss = 0.8889439505625099, disc_loss = 0.04915292605382627
Trained batch 437 in epoch 19, gen_loss = 0.8882488020478863, disc_loss = 0.049520550185142585
Trained batch 438 in epoch 19, gen_loss = 0.8877200219517145, disc_loss = 0.04968293080772517
Trained batch 439 in epoch 19, gen_loss = 0.8887646542354064, disc_loss = 0.050005797516893255
Trained batch 440 in epoch 19, gen_loss = 0.8889330068683408, disc_loss = 0.049927239663172474
Trained batch 441 in epoch 19, gen_loss = 0.888946786185735, disc_loss = 0.04985439744504059
Trained batch 442 in epoch 19, gen_loss = 0.8886730837768141, disc_loss = 0.049858076342341594
Trained batch 443 in epoch 19, gen_loss = 0.8881527797595875, disc_loss = 0.0499270524628259
Trained batch 444 in epoch 19, gen_loss = 0.8877668284298329, disc_loss = 0.049960530976231175
Trained batch 445 in epoch 19, gen_loss = 0.8876489042701208, disc_loss = 0.04987385115197822
Trained batch 446 in epoch 19, gen_loss = 0.8878120437297778, disc_loss = 0.04982653078133494
Trained batch 447 in epoch 19, gen_loss = 0.887212344179196, disc_loss = 0.05001841283852367
Trained batch 448 in epoch 19, gen_loss = 0.8868740647035611, disc_loss = 0.050015254585043356
Trained batch 449 in epoch 19, gen_loss = 0.8872459828853607, disc_loss = 0.049943331997427676
Trained batch 450 in epoch 19, gen_loss = 0.8872654788245647, disc_loss = 0.04987150463306587
Trained batch 451 in epoch 19, gen_loss = 0.8866495794690816, disc_loss = 0.04994436557429422
Trained batch 452 in epoch 19, gen_loss = 0.8867122775671498, disc_loss = 0.04993646987868066
Trained batch 453 in epoch 19, gen_loss = 0.8870468062188657, disc_loss = 0.04995699267473384
Trained batch 454 in epoch 19, gen_loss = 0.8870408981711, disc_loss = 0.04989088858467537
Trained batch 455 in epoch 19, gen_loss = 0.8868999766153202, disc_loss = 0.04983660235200404
Trained batch 456 in epoch 19, gen_loss = 0.8866527653105671, disc_loss = 0.0497840089719392
Trained batch 457 in epoch 19, gen_loss = 0.8865433540927271, disc_loss = 0.04974773569707657
Trained batch 458 in epoch 19, gen_loss = 0.8858434937098967, disc_loss = 0.04981907576825754
Trained batch 459 in epoch 19, gen_loss = 0.8871382688698561, disc_loss = 0.05003252124575817
Trained batch 460 in epoch 19, gen_loss = 0.8874261427080812, disc_loss = 0.049964068970620765
Trained batch 461 in epoch 19, gen_loss = 0.8876123652829753, disc_loss = 0.04994714135118635
Trained batch 462 in epoch 19, gen_loss = 0.8877589084674679, disc_loss = 0.04989665765596904
Trained batch 463 in epoch 19, gen_loss = 0.8874578793244116, disc_loss = 0.04984173054630258
Trained batch 464 in epoch 19, gen_loss = 0.8876913930780144, disc_loss = 0.04984419858984409
Trained batch 465 in epoch 19, gen_loss = 0.8877400301812545, disc_loss = 0.04975975256876884
Trained batch 466 in epoch 19, gen_loss = 0.8873991963694897, disc_loss = 0.04978032318408535
Trained batch 467 in epoch 19, gen_loss = 0.8870390116149544, disc_loss = 0.049745123053335734
Trained batch 468 in epoch 19, gen_loss = 0.8872135580221473, disc_loss = 0.04972000287444607
Trained batch 469 in epoch 19, gen_loss = 0.886859808576868, disc_loss = 0.04969426172369338
Trained batch 470 in epoch 19, gen_loss = 0.8869970723069145, disc_loss = 0.049602079954623166
Trained batch 471 in epoch 19, gen_loss = 0.8872559583288128, disc_loss = 0.049510143683449824
Trained batch 472 in epoch 19, gen_loss = 0.886904632062287, disc_loss = 0.04954310813938399
Trained batch 473 in epoch 19, gen_loss = 0.8873138608811777, disc_loss = 0.049495020973641536
Trained batch 474 in epoch 19, gen_loss = 0.8874377684844168, disc_loss = 0.04943382921775705
Trained batch 475 in epoch 19, gen_loss = 0.8871118822017637, disc_loss = 0.04941489001023857
Trained batch 476 in epoch 19, gen_loss = 0.8873286350967999, disc_loss = 0.049354705520255386
Trained batch 477 in epoch 19, gen_loss = 0.8872765150529072, disc_loss = 0.04928689503995507
Trained batch 478 in epoch 19, gen_loss = 0.8874819318536428, disc_loss = 0.04920057363084873
Trained batch 479 in epoch 19, gen_loss = 0.8870540517071883, disc_loss = 0.04918996480021936
Trained batch 480 in epoch 19, gen_loss = 0.8876260898217342, disc_loss = 0.04915078411657139
Trained batch 481 in epoch 19, gen_loss = 0.8879883247292388, disc_loss = 0.049086163622323285
Trained batch 482 in epoch 19, gen_loss = 0.8878146525989161, disc_loss = 0.04905279426339929
Trained batch 483 in epoch 19, gen_loss = 0.8878803128792234, disc_loss = 0.04902666307454698
Trained batch 484 in epoch 19, gen_loss = 0.8882297583462037, disc_loss = 0.048971106747606984
Trained batch 485 in epoch 19, gen_loss = 0.8876606499461971, disc_loss = 0.04899415293892408
Trained batch 486 in epoch 19, gen_loss = 0.8876653159423531, disc_loss = 0.04891673859698388
Trained batch 487 in epoch 19, gen_loss = 0.88838180154562, disc_loss = 0.049553200512834385
Trained batch 488 in epoch 19, gen_loss = 0.8878335053204027, disc_loss = 0.0497039800151756
Trained batch 489 in epoch 19, gen_loss = 0.8870536672825716, disc_loss = 0.049958758955175174
Trained batch 490 in epoch 19, gen_loss = 0.8878704282756735, disc_loss = 0.050310716626676306
Trained batch 491 in epoch 19, gen_loss = 0.887257390996305, disc_loss = 0.05033662580748702
Trained batch 492 in epoch 19, gen_loss = 0.886655272745941, disc_loss = 0.050495883954299756
Trained batch 493 in epoch 19, gen_loss = 0.8875471118249392, disc_loss = 0.05062595197010921
Trained batch 494 in epoch 19, gen_loss = 0.8873271468913917, disc_loss = 0.05063090191382651
Trained batch 495 in epoch 19, gen_loss = 0.8878581186215724, disc_loss = 0.050593895862074266
Trained batch 496 in epoch 19, gen_loss = 0.8872678691232708, disc_loss = 0.050847168623936366
Trained batch 497 in epoch 19, gen_loss = 0.8872405975219236, disc_loss = 0.05082040143397498
Trained batch 498 in epoch 19, gen_loss = 0.887151506477463, disc_loss = 0.05075226102457316
Trained batch 499 in epoch 19, gen_loss = 0.8872283782958984, disc_loss = 0.050931495809927584
Trained batch 500 in epoch 19, gen_loss = 0.8865999502098251, disc_loss = 0.05101977731333581
Trained batch 501 in epoch 19, gen_loss = 0.8861571804460776, disc_loss = 0.05103773651347752
Trained batch 502 in epoch 19, gen_loss = 0.8863964130579832, disc_loss = 0.05097197698129278
Trained batch 503 in epoch 19, gen_loss = 0.8867127528739354, disc_loss = 0.050999020653155945
Trained batch 504 in epoch 19, gen_loss = 0.88620631423327, disc_loss = 0.05100778912811881
Trained batch 505 in epoch 19, gen_loss = 0.8860629496602673, disc_loss = 0.05097063564375161
Trained batch 506 in epoch 19, gen_loss = 0.8858485151324752, disc_loss = 0.050902096218479104
Trained batch 507 in epoch 19, gen_loss = 0.8860754030426656, disc_loss = 0.05081988887414043
Trained batch 508 in epoch 19, gen_loss = 0.8862227234250202, disc_loss = 0.05080242342478458
Trained batch 509 in epoch 19, gen_loss = 0.8860859973757875, disc_loss = 0.05074408990970137
Trained batch 510 in epoch 19, gen_loss = 0.8860225783635493, disc_loss = 0.05069127546007328
Trained batch 511 in epoch 19, gen_loss = 0.886315634357743, disc_loss = 0.05109219161204237
Trained batch 512 in epoch 19, gen_loss = 0.8857643440452933, disc_loss = 0.05130112837622447
Trained batch 513 in epoch 19, gen_loss = 0.8856248884581406, disc_loss = 0.051246564583454265
Trained batch 514 in epoch 19, gen_loss = 0.8856523658465413, disc_loss = 0.05126972861985848
Trained batch 515 in epoch 19, gen_loss = 0.8857611556385838, disc_loss = 0.05118834073727503
Trained batch 516 in epoch 19, gen_loss = 0.8856842351835977, disc_loss = 0.05115142515977589
Trained batch 517 in epoch 19, gen_loss = 0.8855260530033627, disc_loss = 0.05108208397158842
Trained batch 518 in epoch 19, gen_loss = 0.8854173421859741, disc_loss = 0.05105013341637533
Trained batch 519 in epoch 19, gen_loss = 0.8851173327519344, disc_loss = 0.0510079049379923
Trained batch 520 in epoch 19, gen_loss = 0.8850988869246046, disc_loss = 0.05093064933350299
Trained batch 521 in epoch 19, gen_loss = 0.8851671925678107, disc_loss = 0.05088475765660405
Trained batch 522 in epoch 19, gen_loss = 0.8854346816671966, disc_loss = 0.050856339253741625
Trained batch 523 in epoch 19, gen_loss = 0.8856746075490048, disc_loss = 0.050773748281973466
Trained batch 524 in epoch 19, gen_loss = 0.8854680013656616, disc_loss = 0.05070311617106199
Trained batch 525 in epoch 19, gen_loss = 0.8854181530811034, disc_loss = 0.050635142675016655
Trained batch 526 in epoch 19, gen_loss = 0.8854010046320124, disc_loss = 0.050601552088569986
Trained batch 527 in epoch 19, gen_loss = 0.8850860823736046, disc_loss = 0.050554941759345995
Trained batch 528 in epoch 19, gen_loss = 0.885209743151818, disc_loss = 0.050478584069709356
Trained batch 529 in epoch 19, gen_loss = 0.8852627719348332, disc_loss = 0.05040491813582913
Trained batch 530 in epoch 19, gen_loss = 0.8854152341346956, disc_loss = 0.050366673420364015
Trained batch 531 in epoch 19, gen_loss = 0.8856865178821678, disc_loss = 0.05029002431591034
Trained batch 532 in epoch 19, gen_loss = 0.8857960949248266, disc_loss = 0.05034572572585398
Trained batch 533 in epoch 19, gen_loss = 0.8853879120019491, disc_loss = 0.05035679071813766
Trained batch 534 in epoch 19, gen_loss = 0.8848669691620586, disc_loss = 0.05042173092505921
Trained batch 535 in epoch 19, gen_loss = 0.8851364417307412, disc_loss = 0.05065822299854802
Trained batch 536 in epoch 19, gen_loss = 0.8852433592247564, disc_loss = 0.050598852365889915
Trained batch 537 in epoch 19, gen_loss = 0.8854198887888827, disc_loss = 0.05054818347380341
Trained batch 538 in epoch 19, gen_loss = 0.8854397085248208, disc_loss = 0.05048876682707629
Trained batch 539 in epoch 19, gen_loss = 0.8853630387120777, disc_loss = 0.05047114052533828
Trained batch 540 in epoch 19, gen_loss = 0.8853778419344791, disc_loss = 0.05042403539239865
Trained batch 541 in epoch 19, gen_loss = 0.8854879364096371, disc_loss = 0.05047782943016983
Trained batch 542 in epoch 19, gen_loss = 0.8858227825296517, disc_loss = 0.050536215780422944
Trained batch 543 in epoch 19, gen_loss = 0.8858840788769371, disc_loss = 0.05049407629549558
Trained batch 544 in epoch 19, gen_loss = 0.8851291693131859, disc_loss = 0.05066437906662532
Trained batch 545 in epoch 19, gen_loss = 0.8846997463113659, disc_loss = 0.05069587018934416
Trained batch 546 in epoch 19, gen_loss = 0.884685780546565, disc_loss = 0.05084561753568582
Trained batch 547 in epoch 19, gen_loss = 0.8849150438922165, disc_loss = 0.05085966490841314
Trained batch 548 in epoch 19, gen_loss = 0.8847859638093382, disc_loss = 0.050802434943887816
Trained batch 549 in epoch 19, gen_loss = 0.8847596755352887, disc_loss = 0.05075640264051882
Trained batch 550 in epoch 19, gen_loss = 0.8847904066316878, disc_loss = 0.050676354275553226
Trained batch 551 in epoch 19, gen_loss = 0.8846044553902702, disc_loss = 0.05065770158999721
Trained batch 552 in epoch 19, gen_loss = 0.884597954062398, disc_loss = 0.05060095899059668
Trained batch 553 in epoch 19, gen_loss = 0.8850476268934429, disc_loss = 0.05072462399967607
Trained batch 554 in epoch 19, gen_loss = 0.885091353590424, disc_loss = 0.05066301198005005
Trained batch 555 in epoch 19, gen_loss = 0.8847599083678328, disc_loss = 0.050733479218081766
Trained batch 556 in epoch 19, gen_loss = 0.8848645935901833, disc_loss = 0.050662362490758915
Trained batch 557 in epoch 19, gen_loss = 0.884636093692113, disc_loss = 0.05062032378225263
Trained batch 558 in epoch 19, gen_loss = 0.8851221938999053, disc_loss = 0.05058881741813476
Trained batch 559 in epoch 19, gen_loss = 0.8851247745433024, disc_loss = 0.050983689300483095
Trained batch 560 in epoch 19, gen_loss = 0.8849969820224027, disc_loss = 0.0509300369266321
Trained batch 561 in epoch 19, gen_loss = 0.8846657584252307, disc_loss = 0.05090993601792356
Trained batch 562 in epoch 19, gen_loss = 0.8843573870180343, disc_loss = 0.05089393847739426
Trained batch 563 in epoch 19, gen_loss = 0.8842543806907133, disc_loss = 0.05086042139603235
Trained batch 564 in epoch 19, gen_loss = 0.8843281224238134, disc_loss = 0.0508195044893145
Trained batch 565 in epoch 19, gen_loss = 0.8840950558442531, disc_loss = 0.051094761629203865
Trained batch 566 in epoch 19, gen_loss = 0.883382708622665, disc_loss = 0.051200084904836234
Trained batch 567 in epoch 19, gen_loss = 0.8830286022013342, disc_loss = 0.05119414561064127
Trained batch 568 in epoch 19, gen_loss = 0.8834604088786616, disc_loss = 0.05117715659890134
Trained batch 569 in epoch 19, gen_loss = 0.883799877187662, disc_loss = 0.05127550671122184
Trained batch 570 in epoch 19, gen_loss = 0.8832414008272509, disc_loss = 0.051428458571022996
Trained batch 571 in epoch 19, gen_loss = 0.8828445674030931, disc_loss = 0.0514468970664588
Trained batch 572 in epoch 19, gen_loss = 0.8823919070536762, disc_loss = 0.051486133310917837
Trained batch 573 in epoch 19, gen_loss = 0.8827199320136878, disc_loss = 0.051672924664488085
Trained batch 574 in epoch 19, gen_loss = 0.8827270736901657, disc_loss = 0.051609875000203434
Trained batch 575 in epoch 19, gen_loss = 0.88271837712576, disc_loss = 0.05159765548321755
Trained batch 576 in epoch 19, gen_loss = 0.8823841934187573, disc_loss = 0.0515877742108855
Trained batch 577 in epoch 19, gen_loss = 0.8826226950929239, disc_loss = 0.051588613969341536
Trained batch 578 in epoch 19, gen_loss = 0.882661897695538, disc_loss = 0.051551049103114324
Trained batch 579 in epoch 19, gen_loss = 0.8828010992757205, disc_loss = 0.05148130068796333
Trained batch 580 in epoch 19, gen_loss = 0.8823190336588533, disc_loss = 0.051565999757472857
Trained batch 581 in epoch 19, gen_loss = 0.8821298367379048, disc_loss = 0.051520806810053714
Trained batch 582 in epoch 19, gen_loss = 0.8824644679679674, disc_loss = 0.051664848518789476
Trained batch 583 in epoch 19, gen_loss = 0.8821758183918588, disc_loss = 0.0516932462972002
Trained batch 584 in epoch 19, gen_loss = 0.8824668514422881, disc_loss = 0.05172032539963595
Trained batch 585 in epoch 19, gen_loss = 0.8821110218865066, disc_loss = 0.05174060221109857
Trained batch 586 in epoch 19, gen_loss = 0.8820668634604758, disc_loss = 0.051712309226895056
Trained batch 587 in epoch 19, gen_loss = 0.8821534150514473, disc_loss = 0.05164479783048764
Trained batch 588 in epoch 19, gen_loss = 0.882406825829038, disc_loss = 0.051783284271240286
Trained batch 589 in epoch 19, gen_loss = 0.882227530519841, disc_loss = 0.05178713514469564
Trained batch 590 in epoch 19, gen_loss = 0.8819918105041517, disc_loss = 0.0517852758640477
Trained batch 591 in epoch 19, gen_loss = 0.8818172471144715, disc_loss = 0.05180942840524949
Trained batch 592 in epoch 19, gen_loss = 0.8818772431167744, disc_loss = 0.05175354919501566
Trained batch 593 in epoch 19, gen_loss = 0.882065932658385, disc_loss = 0.05169558827138133
Trained batch 594 in epoch 19, gen_loss = 0.881872599766034, disc_loss = 0.051653779095367475
Trained batch 595 in epoch 19, gen_loss = 0.8818441403392178, disc_loss = 0.051639668028582913
Trained batch 596 in epoch 19, gen_loss = 0.8812576118026746, disc_loss = 0.051844475467157376
Trained batch 597 in epoch 19, gen_loss = 0.8816348911328459, disc_loss = 0.051827220436976754
Trained batch 598 in epoch 19, gen_loss = 0.8821460037478223, disc_loss = 0.051814355774749944
Trained batch 599 in epoch 19, gen_loss = 0.8820931741595268, disc_loss = 0.051762570096955944
Trained batch 600 in epoch 19, gen_loss = 0.8817101762616099, disc_loss = 0.05177408871868511
Trained batch 601 in epoch 19, gen_loss = 0.8823090571897767, disc_loss = 0.051839774664014925
Trained batch 602 in epoch 19, gen_loss = 0.8822528782175548, disc_loss = 0.05177435741850961
Trained batch 603 in epoch 19, gen_loss = 0.8819109538927773, disc_loss = 0.05175895916393631
Trained batch 604 in epoch 19, gen_loss = 0.8818097008161309, disc_loss = 0.051970667080291785
Trained batch 605 in epoch 19, gen_loss = 0.8814384884173327, disc_loss = 0.05203820914014707
Trained batch 606 in epoch 19, gen_loss = 0.8811607058397825, disc_loss = 0.052086876256504946
Trained batch 607 in epoch 19, gen_loss = 0.8812125827136793, disc_loss = 0.05204397704265399
Trained batch 608 in epoch 19, gen_loss = 0.8817234935823137, disc_loss = 0.05231975703706662
Trained batch 609 in epoch 19, gen_loss = 0.881555305348068, disc_loss = 0.05232574057490488
Trained batch 610 in epoch 19, gen_loss = 0.8812149048046668, disc_loss = 0.05240990330866018
Trained batch 611 in epoch 19, gen_loss = 0.8812598276372049, disc_loss = 0.052367865481547815
Trained batch 612 in epoch 19, gen_loss = 0.8811249861320508, disc_loss = 0.05232359377096056
Trained batch 613 in epoch 19, gen_loss = 0.8811517728656433, disc_loss = 0.05226267003969984
Trained batch 614 in epoch 19, gen_loss = 0.8807936625752023, disc_loss = 0.05226886711363506
Trained batch 615 in epoch 19, gen_loss = 0.8811240691643256, disc_loss = 0.05232668721628097
Trained batch 616 in epoch 19, gen_loss = 0.8807355308455431, disc_loss = 0.05233593878367949
Trained batch 617 in epoch 19, gen_loss = 0.880775371512163, disc_loss = 0.052276390825449506
Trained batch 618 in epoch 19, gen_loss = 0.8804208520733675, disc_loss = 0.052337773036669116
Trained batch 619 in epoch 19, gen_loss = 0.8809615878328201, disc_loss = 0.05253127863886015
Trained batch 620 in epoch 19, gen_loss = 0.8807715952108448, disc_loss = 0.05258827213866819
Trained batch 621 in epoch 19, gen_loss = 0.8806103419069309, disc_loss = 0.05258496460307186
Trained batch 622 in epoch 19, gen_loss = 0.8803814528076453, disc_loss = 0.05255947467821678
Trained batch 623 in epoch 19, gen_loss = 0.8803303198745618, disc_loss = 0.05272482305792017
Trained batch 624 in epoch 19, gen_loss = 0.8800403210639953, disc_loss = 0.05277713663652539
Trained batch 625 in epoch 19, gen_loss = 0.8800501595861234, disc_loss = 0.05277931768247804
Trained batch 626 in epoch 19, gen_loss = 0.879933891018802, disc_loss = 0.052747032604368915
Trained batch 627 in epoch 19, gen_loss = 0.8797113182628231, disc_loss = 0.05279816890648525
Trained batch 628 in epoch 19, gen_loss = 0.880002956416914, disc_loss = 0.052791365006988916
Trained batch 629 in epoch 19, gen_loss = 0.8796498906044733, disc_loss = 0.052777259070278394
Trained batch 630 in epoch 19, gen_loss = 0.8794887596756078, disc_loss = 0.05275330207312093
Trained batch 631 in epoch 19, gen_loss = 0.8793219873045064, disc_loss = 0.052703596888068784
Trained batch 632 in epoch 19, gen_loss = 0.8795727110963674, disc_loss = 0.05266910002862602
Trained batch 633 in epoch 19, gen_loss = 0.8796856942989096, disc_loss = 0.052599682752483695
Trained batch 634 in epoch 19, gen_loss = 0.8795586565348107, disc_loss = 0.05255841210733835
Trained batch 635 in epoch 19, gen_loss = 0.8798526939730974, disc_loss = 0.05252238512170976
Trained batch 636 in epoch 19, gen_loss = 0.8795640659481989, disc_loss = 0.05249921072587324
Trained batch 637 in epoch 19, gen_loss = 0.8799768882485393, disc_loss = 0.05247236177293134
Trained batch 638 in epoch 19, gen_loss = 0.880117160613548, disc_loss = 0.052427971325319185
Trained batch 639 in epoch 19, gen_loss = 0.8793879861012102, disc_loss = 0.052791097871522655
Trained batch 640 in epoch 19, gen_loss = 0.8797168692634928, disc_loss = 0.052993366219446225
Trained batch 641 in epoch 19, gen_loss = 0.8795407651183761, disc_loss = 0.053021942315379454
Trained batch 642 in epoch 19, gen_loss = 0.8793212506300183, disc_loss = 0.05301039044355646
Trained batch 643 in epoch 19, gen_loss = 0.8792326094015784, disc_loss = 0.05296902624407193
Trained batch 644 in epoch 19, gen_loss = 0.879187447802965, disc_loss = 0.05291924774718955
Trained batch 645 in epoch 19, gen_loss = 0.8790177574652267, disc_loss = 0.05290032543844598
Trained batch 646 in epoch 19, gen_loss = 0.8789375709050221, disc_loss = 0.05284669499346264
Trained batch 647 in epoch 19, gen_loss = 0.879093350727617, disc_loss = 0.05284268387527217
Trained batch 648 in epoch 19, gen_loss = 0.8791887747304649, disc_loss = 0.052887246509919224
Trained batch 649 in epoch 19, gen_loss = 0.8787470769882202, disc_loss = 0.053051069302197836
Trained batch 650 in epoch 19, gen_loss = 0.8790478301670878, disc_loss = 0.0530544698915048
Trained batch 651 in epoch 19, gen_loss = 0.8792652030663988, disc_loss = 0.05299056055484214
Trained batch 652 in epoch 19, gen_loss = 0.8794504256197359, disc_loss = 0.052921562603208454
Trained batch 653 in epoch 19, gen_loss = 0.8792404176992014, disc_loss = 0.05287488128502913
Trained batch 654 in epoch 19, gen_loss = 0.8794191577052342, disc_loss = 0.0529481252420779
Trained batch 655 in epoch 19, gen_loss = 0.8794565086321133, disc_loss = 0.05289031891507187
Trained batch 656 in epoch 19, gen_loss = 0.8792731834510327, disc_loss = 0.052891878145385415
Trained batch 657 in epoch 19, gen_loss = 0.8791965793331343, disc_loss = 0.052842567296200474
Trained batch 658 in epoch 19, gen_loss = 0.8793250350380523, disc_loss = 0.05280171579304003
Trained batch 659 in epoch 19, gen_loss = 0.879327626932751, disc_loss = 0.052765815403792216
Trained batch 660 in epoch 19, gen_loss = 0.8793556231233247, disc_loss = 0.05272576303972261
Trained batch 661 in epoch 19, gen_loss = 0.8794618318268179, disc_loss = 0.05271540731093157
Trained batch 662 in epoch 19, gen_loss = 0.8792979550937002, disc_loss = 0.052692634530427274
Trained batch 663 in epoch 19, gen_loss = 0.8792524970619076, disc_loss = 0.05266192717918094
Trained batch 664 in epoch 19, gen_loss = 0.8794094832319962, disc_loss = 0.052599904387208976
Trained batch 665 in epoch 19, gen_loss = 0.8794658691496462, disc_loss = 0.052641451435007
Trained batch 666 in epoch 19, gen_loss = 0.879350631222732, disc_loss = 0.05258622754161348
Trained batch 667 in epoch 19, gen_loss = 0.8794376255866296, disc_loss = 0.052661816726862536
Trained batch 668 in epoch 19, gen_loss = 0.8790004223095106, disc_loss = 0.052760607924212125
Trained batch 669 in epoch 19, gen_loss = 0.879056447477483, disc_loss = 0.052693077332493087
Trained batch 670 in epoch 19, gen_loss = 0.8789110524821389, disc_loss = 0.05265952003273097
Trained batch 671 in epoch 19, gen_loss = 0.8785331406231437, disc_loss = 0.052695840724655205
Trained batch 672 in epoch 19, gen_loss = 0.8790053002547368, disc_loss = 0.053017614495125424
Trained batch 673 in epoch 19, gen_loss = 0.8786648969975707, disc_loss = 0.05304956540620115
Trained batch 674 in epoch 19, gen_loss = 0.878528617841226, disc_loss = 0.053023176160123614
Trained batch 675 in epoch 19, gen_loss = 0.8783758306468027, disc_loss = 0.053129705837404236
Trained batch 676 in epoch 19, gen_loss = 0.878581229041563, disc_loss = 0.0531440565535906
Trained batch 677 in epoch 19, gen_loss = 0.8785327953399107, disc_loss = 0.053107301517771585
Trained batch 678 in epoch 19, gen_loss = 0.8785094341403079, disc_loss = 0.05308610144645985
Trained batch 679 in epoch 19, gen_loss = 0.8781732585500268, disc_loss = 0.05317110148368075
Trained batch 680 in epoch 19, gen_loss = 0.8781155223538347, disc_loss = 0.05316271085056877
Trained batch 681 in epoch 19, gen_loss = 0.8782347395273248, disc_loss = 0.05314382988566265
Trained batch 682 in epoch 19, gen_loss = 0.8784420807923614, disc_loss = 0.05308082281430504
Trained batch 683 in epoch 19, gen_loss = 0.8781075109863838, disc_loss = 0.05310653490477312
Trained batch 684 in epoch 19, gen_loss = 0.8781921747827182, disc_loss = 0.0530502238711954
Trained batch 685 in epoch 19, gen_loss = 0.878095202908224, disc_loss = 0.052997187521232635
Trained batch 686 in epoch 19, gen_loss = 0.8783890875666422, disc_loss = 0.05299503462771401
Trained batch 687 in epoch 19, gen_loss = 0.8785915292452934, disc_loss = 0.05294929561746675
Trained batch 688 in epoch 19, gen_loss = 0.8785132072833522, disc_loss = 0.052888117883359835
Trained batch 689 in epoch 19, gen_loss = 0.8781693559625875, disc_loss = 0.05299667518558925
Trained batch 690 in epoch 19, gen_loss = 0.877894166237021, disc_loss = 0.05300298161324863
Trained batch 691 in epoch 19, gen_loss = 0.8779781388409565, disc_loss = 0.0530145859811455
Trained batch 692 in epoch 19, gen_loss = 0.8780865022458383, disc_loss = 0.05302627159559409
Trained batch 693 in epoch 19, gen_loss = 0.8776816264524927, disc_loss = 0.053031713448153536
Trained batch 694 in epoch 19, gen_loss = 0.8773758835929761, disc_loss = 0.053036252174714055
Trained batch 695 in epoch 19, gen_loss = 0.8777711501923101, disc_loss = 0.05301138357896272
Trained batch 696 in epoch 19, gen_loss = 0.878493334761309, disc_loss = 0.0530643949680661
Trained batch 697 in epoch 19, gen_loss = 0.8782337974853024, disc_loss = 0.053091325950582
Trained batch 698 in epoch 19, gen_loss = 0.8782002603547255, disc_loss = 0.053041644539625434
Trained batch 699 in epoch 19, gen_loss = 0.8781118087257658, disc_loss = 0.05300277933611401
Trained batch 700 in epoch 19, gen_loss = 0.8782587561559745, disc_loss = 0.0529471190524063
Trained batch 701 in epoch 19, gen_loss = 0.8783018819117479, disc_loss = 0.05289807219848971
Trained batch 702 in epoch 19, gen_loss = 0.8783041272699239, disc_loss = 0.052873793230319176
Trained batch 703 in epoch 19, gen_loss = 0.8783300497823141, disc_loss = 0.05281123752171301
Trained batch 704 in epoch 19, gen_loss = 0.8782394775262116, disc_loss = 0.05276096806009399
Trained batch 705 in epoch 19, gen_loss = 0.8782073790392186, disc_loss = 0.05273872901878132
Trained batch 706 in epoch 19, gen_loss = 0.8780483592517643, disc_loss = 0.0526965602460453
Trained batch 707 in epoch 19, gen_loss = 0.8781998160026842, disc_loss = 0.05265434558429666
Trained batch 708 in epoch 19, gen_loss = 0.8785907415980513, disc_loss = 0.05269498449102654
Trained batch 709 in epoch 19, gen_loss = 0.8780954627923563, disc_loss = 0.05289847041335954
Trained batch 710 in epoch 19, gen_loss = 0.8776236438885352, disc_loss = 0.052943892752078434
Trained batch 711 in epoch 19, gen_loss = 0.8774112665586258, disc_loss = 0.05295253202994092
Trained batch 712 in epoch 19, gen_loss = 0.8773143308192785, disc_loss = 0.05308870790555007
Trained batch 713 in epoch 19, gen_loss = 0.8774440098209542, disc_loss = 0.05308012829321314
Trained batch 714 in epoch 19, gen_loss = 0.8770462217864456, disc_loss = 0.053134273556614674
Trained batch 715 in epoch 19, gen_loss = 0.8772452105689981, disc_loss = 0.05309891175900133
Trained batch 716 in epoch 19, gen_loss = 0.8767186623986296, disc_loss = 0.05318320216935757
Trained batch 717 in epoch 19, gen_loss = 0.8766593688626807, disc_loss = 0.05315550828279932
Trained batch 718 in epoch 19, gen_loss = 0.8767386400898574, disc_loss = 0.053145538104933804
Trained batch 719 in epoch 19, gen_loss = 0.8768249945094188, disc_loss = 0.05309322921740305
Trained batch 720 in epoch 19, gen_loss = 0.8766323220134609, disc_loss = 0.05308057898306772
Trained batch 721 in epoch 19, gen_loss = 0.8764983524163343, disc_loss = 0.0530347342840254
Trained batch 722 in epoch 19, gen_loss = 0.8764865160565488, disc_loss = 0.052996826515292146
Trained batch 723 in epoch 19, gen_loss = 0.8764703321111137, disc_loss = 0.053031524963604894
Trained batch 724 in epoch 19, gen_loss = 0.8763907935290501, disc_loss = 0.05299857194182174
Trained batch 725 in epoch 19, gen_loss = 0.8762677870588198, disc_loss = 0.05294506183951149
Trained batch 726 in epoch 19, gen_loss = 0.8764050835346421, disc_loss = 0.05288472485073946
Trained batch 727 in epoch 19, gen_loss = 0.8761969846110422, disc_loss = 0.05283811739978513
Trained batch 728 in epoch 19, gen_loss = 0.8764837872753091, disc_loss = 0.0528178352732288
Trained batch 729 in epoch 19, gen_loss = 0.8769609748908919, disc_loss = 0.05280111474814276
Trained batch 730 in epoch 19, gen_loss = 0.8769536711041155, disc_loss = 0.05276321904751614
Trained batch 731 in epoch 19, gen_loss = 0.8771583553138977, disc_loss = 0.05270428511013832
Trained batch 732 in epoch 19, gen_loss = 0.8770301837631658, disc_loss = 0.0527239465681991
Trained batch 733 in epoch 19, gen_loss = 0.8767674645302406, disc_loss = 0.05277936168938713
Trained batch 734 in epoch 19, gen_loss = 0.8770532319740373, disc_loss = 0.052957061442489524
Trained batch 735 in epoch 19, gen_loss = 0.8776538903703508, disc_loss = 0.05296363580577156
Trained batch 736 in epoch 19, gen_loss = 0.8777441191139506, disc_loss = 0.05291467062431404
Trained batch 737 in epoch 19, gen_loss = 0.877613547008212, disc_loss = 0.05288197535789271
Trained batch 738 in epoch 19, gen_loss = 0.8775508695348835, disc_loss = 0.052839856645210834
Trained batch 739 in epoch 19, gen_loss = 0.8776863957981805, disc_loss = 0.05278938321925297
Trained batch 740 in epoch 19, gen_loss = 0.8775767230714059, disc_loss = 0.05274416489071651
Trained batch 741 in epoch 19, gen_loss = 0.8775010653984836, disc_loss = 0.05269438968569723
Trained batch 742 in epoch 19, gen_loss = 0.8775530998591299, disc_loss = 0.05272548491684256
Trained batch 743 in epoch 19, gen_loss = 0.8772269525435022, disc_loss = 0.05281505921369879
Trained batch 744 in epoch 19, gen_loss = 0.8774103327485538, disc_loss = 0.0528433111127491
Trained batch 745 in epoch 19, gen_loss = 0.8772155604557441, disc_loss = 0.05283125036897952
Trained batch 746 in epoch 19, gen_loss = 0.8774181687768045, disc_loss = 0.05278763122023788
Trained batch 747 in epoch 19, gen_loss = 0.8772200487434545, disc_loss = 0.052787931216382644
Trained batch 748 in epoch 19, gen_loss = 0.8771730704762748, disc_loss = 0.05273613901572608
Trained batch 749 in epoch 19, gen_loss = 0.877580425620079, disc_loss = 0.052712986453125873
Trained batch 750 in epoch 19, gen_loss = 0.8772011497287394, disc_loss = 0.0528100153416415
Trained batch 751 in epoch 19, gen_loss = 0.8775482737716842, disc_loss = 0.052837919308853516
Trained batch 752 in epoch 19, gen_loss = 0.8777517620548309, disc_loss = 0.05298570808082582
Trained batch 753 in epoch 19, gen_loss = 0.8775006620020702, disc_loss = 0.05308709716898653
Trained batch 754 in epoch 19, gen_loss = 0.8774564109495934, disc_loss = 0.0530436629256764
Trained batch 755 in epoch 19, gen_loss = 0.8774799443978482, disc_loss = 0.05300320205081589
Trained batch 756 in epoch 19, gen_loss = 0.877575085885931, disc_loss = 0.05294653663935836
Trained batch 757 in epoch 19, gen_loss = 0.8773653325194734, disc_loss = 0.052946930130732324
Trained batch 758 in epoch 19, gen_loss = 0.8772854678951233, disc_loss = 0.05293840657163789
Trained batch 759 in epoch 19, gen_loss = 0.8777453911539755, disc_loss = 0.052947603081549076
Trained batch 760 in epoch 19, gen_loss = 0.8774054270144674, disc_loss = 0.053102213623792756
Trained batch 761 in epoch 19, gen_loss = 0.8773460271242722, disc_loss = 0.05309748648008297
Trained batch 762 in epoch 19, gen_loss = 0.8777299466717446, disc_loss = 0.053126234940813456
Trained batch 763 in epoch 19, gen_loss = 0.8775463220102625, disc_loss = 0.05312511569537534
Trained batch 764 in epoch 19, gen_loss = 0.8775238240855971, disc_loss = 0.05311016261066292
Trained batch 765 in epoch 19, gen_loss = 0.8774448506748085, disc_loss = 0.05306122943335857
Trained batch 766 in epoch 19, gen_loss = 0.8775715929355273, disc_loss = 0.05301802022433615
Trained batch 767 in epoch 19, gen_loss = 0.877435889832365, disc_loss = 0.05298232992330062
Trained batch 768 in epoch 19, gen_loss = 0.8775727833743523, disc_loss = 0.05292188602660738
Trained batch 769 in epoch 19, gen_loss = 0.8776789556463044, disc_loss = 0.05293247093289317
Trained batch 770 in epoch 19, gen_loss = 0.8778207794933468, disc_loss = 0.052943343030900036
Trained batch 771 in epoch 19, gen_loss = 0.8775841469823388, disc_loss = 0.05298151354995494
Trained batch 772 in epoch 19, gen_loss = 0.8773836727515538, disc_loss = 0.05301655330881958
Trained batch 773 in epoch 19, gen_loss = 0.8772795633521191, disc_loss = 0.05297428542550759
Trained batch 774 in epoch 19, gen_loss = 0.8775949658501533, disc_loss = 0.0529968823132015
Trained batch 775 in epoch 19, gen_loss = 0.8776034081028294, disc_loss = 0.05299083505680343
Trained batch 776 in epoch 19, gen_loss = 0.8772860650773828, disc_loss = 0.05296810361361335
Trained batch 777 in epoch 19, gen_loss = 0.8774719528260145, disc_loss = 0.05291067091580528
Trained batch 778 in epoch 19, gen_loss = 0.8772705328556325, disc_loss = 0.05291248898145017
Trained batch 779 in epoch 19, gen_loss = 0.8773416888637421, disc_loss = 0.05285814800896706
Trained batch 780 in epoch 19, gen_loss = 0.8776567021573246, disc_loss = 0.052836982297225735
Trained batch 781 in epoch 19, gen_loss = 0.8775318266104555, disc_loss = 0.05278926893897221
Trained batch 782 in epoch 19, gen_loss = 0.877610811671078, disc_loss = 0.05274562566216421
Trained batch 783 in epoch 19, gen_loss = 0.8771750839161021, disc_loss = 0.05281626760997638
Trained batch 784 in epoch 19, gen_loss = 0.8776241758446784, disc_loss = 0.05288611803275005
Trained batch 785 in epoch 19, gen_loss = 0.8776177238037871, disc_loss = 0.0528486591405958
Trained batch 786 in epoch 19, gen_loss = 0.8775491736819814, disc_loss = 0.052811423785217686
Trained batch 787 in epoch 19, gen_loss = 0.8776743695291166, disc_loss = 0.05276955430381718
Trained batch 788 in epoch 19, gen_loss = 0.877840400384255, disc_loss = 0.05272358074472658
Trained batch 789 in epoch 19, gen_loss = 0.8775952132819574, disc_loss = 0.05269894281378652
Testing Epoch 19
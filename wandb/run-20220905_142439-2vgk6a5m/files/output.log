
wandb: WARNING Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 0.49965518712997437, disc_loss = 0.5170195698738098
Trained batch 1 in epoch 0, gen_loss = 0.4982908070087433, disc_loss = 0.5649652183055878
Trained batch 2 in epoch 0, gen_loss = 0.4811676541964213, disc_loss = 0.5748871763547262
Trained batch 3 in epoch 0, gen_loss = 0.4531490057706833, disc_loss = 0.5206464976072311
Trained batch 4 in epoch 0, gen_loss = 0.45605300068855287, disc_loss = 0.46366291046142577
Trained batch 5 in epoch 0, gen_loss = 0.45045458773771924, disc_loss = 0.42381155987580615
Trained batch 6 in epoch 0, gen_loss = 0.4504453326974596, disc_loss = 0.3889144403593881
Trained batch 7 in epoch 0, gen_loss = 0.451130997389555, disc_loss = 0.35962681099772453
Trained batch 8 in epoch 0, gen_loss = 0.4607440067662133, disc_loss = 0.33452299071682823
Trained batch 9 in epoch 0, gen_loss = 0.4604633927345276, disc_loss = 0.31274106353521347
Trained batch 10 in epoch 0, gen_loss = 0.46115871451117774, disc_loss = 0.2973561463030902
Trained batch 11 in epoch 0, gen_loss = 0.4672695944706599, disc_loss = 0.2859302485982577
Trained batch 12 in epoch 0, gen_loss = 0.47023080403988177, disc_loss = 0.27704174931232745
Trained batch 13 in epoch 0, gen_loss = 0.46546198640550884, disc_loss = 0.26794308849743437
Trained batch 14 in epoch 0, gen_loss = 0.4688342332839966, disc_loss = 0.25999656518300374
Trained batch 15 in epoch 0, gen_loss = 0.4709884598851204, disc_loss = 0.2504004933871329
Trained batch 16 in epoch 0, gen_loss = 0.4701680576100069, disc_loss = 0.24315239269943797
Trained batch 17 in epoch 0, gen_loss = 0.46785222987333935, disc_loss = 0.24087457069092327
Trained batch 18 in epoch 0, gen_loss = 0.47144884341641474, disc_loss = 0.23538495482582794
Trained batch 19 in epoch 0, gen_loss = 0.4719381913542747, disc_loss = 0.22992778532207012
Trained batch 20 in epoch 0, gen_loss = 0.4741030349617913, disc_loss = 0.22462907433509827
Trained batch 21 in epoch 0, gen_loss = 0.47894540564580396, disc_loss = 0.22188750180331143
Trained batch 22 in epoch 0, gen_loss = 0.47870049010152405, disc_loss = 0.22867114388424417
Trained batch 23 in epoch 0, gen_loss = 0.47541947787006694, disc_loss = 0.22693325703342757
Trained batch 24 in epoch 0, gen_loss = 0.47495720505714417, disc_loss = 0.22748813509941102
Trained batch 25 in epoch 0, gen_loss = 0.47578968566197616, disc_loss = 0.233137112397414
Trained batch 26 in epoch 0, gen_loss = 0.4709709452258216, disc_loss = 0.2368968261612786
Trained batch 27 in epoch 0, gen_loss = 0.4694804602435657, disc_loss = 0.24071414981569564
Trained batch 28 in epoch 0, gen_loss = 0.4683237497148843, disc_loss = 0.24320044188663878
Trained batch 29 in epoch 0, gen_loss = 0.46688668926556903, disc_loss = 0.24295910994211833
Trained batch 30 in epoch 0, gen_loss = 0.4692534996617225, disc_loss = 0.23967397357186965
Trained batch 31 in epoch 0, gen_loss = 0.4694700324907899, disc_loss = 0.23646673234179616
Trained batch 32 in epoch 0, gen_loss = 0.4722472871794845, disc_loss = 0.23238793060635077
Trained batch 33 in epoch 0, gen_loss = 0.47362955791108746, disc_loss = 0.2282845667179893
Trained batch 34 in epoch 0, gen_loss = 0.47540047253881185, disc_loss = 0.22418341828244073
Trained batch 35 in epoch 0, gen_loss = 0.47597664843002957, disc_loss = 0.22049011724690595
Trained batch 36 in epoch 0, gen_loss = 0.4763045496231801, disc_loss = 0.2179770350858972
Trained batch 37 in epoch 0, gen_loss = 0.4769607147103862, disc_loss = 0.21839347344480062
Trained batch 38 in epoch 0, gen_loss = 0.47781685300362414, disc_loss = 0.22222962154027742
Trained batch 39 in epoch 0, gen_loss = 0.4763610281050205, disc_loss = 0.220245891623199
Trained batch 40 in epoch 0, gen_loss = 0.4759487393425732, disc_loss = 0.2188783595111312
Trained batch 41 in epoch 0, gen_loss = 0.4772913001832508, disc_loss = 0.21568867475503967
Trained batch 42 in epoch 0, gen_loss = 0.4792722505192424, disc_loss = 0.21311651447484659
Trained batch 43 in epoch 0, gen_loss = 0.4791100336746736, disc_loss = 0.21141104671088132
Trained batch 44 in epoch 0, gen_loss = 0.4787544409434001, disc_loss = 0.21085832715034486
Trained batch 45 in epoch 0, gen_loss = 0.47869726497194043, disc_loss = 0.21090534394202026
Trained batch 46 in epoch 0, gen_loss = 0.47994407060298516, disc_loss = 0.20935022260280364
Trained batch 47 in epoch 0, gen_loss = 0.4811457519729932, disc_loss = 0.20666285464540124
Trained batch 48 in epoch 0, gen_loss = 0.48059951590031996, disc_loss = 0.20839077279883989
Trained batch 49 in epoch 0, gen_loss = 0.47968757152557373, disc_loss = 0.20986555859446526
Trained batch 50 in epoch 0, gen_loss = 0.48007582040394053, disc_loss = 0.20746898548860176
Trained batch 51 in epoch 0, gen_loss = 0.4829608734983664, disc_loss = 0.20703959508010975
Trained batch 52 in epoch 0, gen_loss = 0.4815216216276277, disc_loss = 0.20605399375254252
Trained batch 53 in epoch 0, gen_loss = 0.48045430967101344, disc_loss = 0.20760928384131855
Trained batch 54 in epoch 0, gen_loss = 0.4807935535907745, disc_loss = 0.20615543438629672
Trained batch 55 in epoch 0, gen_loss = 0.4804656947297709, disc_loss = 0.20554397481360606
Trained batch 56 in epoch 0, gen_loss = 0.479604254689133, disc_loss = 0.2037386721686313
Trained batch 57 in epoch 0, gen_loss = 0.4795350386150952, disc_loss = 0.20223627599148913
Trained batch 58 in epoch 0, gen_loss = 0.47921970638178163, disc_loss = 0.2020245027744164
Trained batch 59 in epoch 0, gen_loss = 0.4806307872136434, disc_loss = 0.2005280522008737
Trained batch 60 in epoch 0, gen_loss = 0.48146709848622804, disc_loss = 0.19882462381339464
Trained batch 61 in epoch 0, gen_loss = 0.4814812853451698, disc_loss = 0.19787199891382648
Trained batch 62 in epoch 0, gen_loss = 0.48296669787830776, disc_loss = 0.19665124054465974
Trained batch 63 in epoch 0, gen_loss = 0.4833372295834124, disc_loss = 0.19535799615550786
Trained batch 64 in epoch 0, gen_loss = 0.4821441173553467, disc_loss = 0.19463933878220044
Trained batch 65 in epoch 0, gen_loss = 0.48223871579675964, disc_loss = 0.20164893420808244
Trained batch 66 in epoch 0, gen_loss = 0.4829066675990375, disc_loss = 0.20126635536773882
Trained batch 67 in epoch 0, gen_loss = 0.4830152830656837, disc_loss = 0.20077130844926133
Trained batch 68 in epoch 0, gen_loss = 0.4833674206249956, disc_loss = 0.20087225681197815
Trained batch 69 in epoch 0, gen_loss = 0.4837072355406625, disc_loss = 0.20174227452703886
Trained batch 70 in epoch 0, gen_loss = 0.48548213612865393, disc_loss = 0.20231148023420656
Trained batch 71 in epoch 0, gen_loss = 0.48576944983667797, disc_loss = 0.20294361468404531
Trained batch 72 in epoch 0, gen_loss = 0.4852686581546313, disc_loss = 0.20183780636281184
Trained batch 73 in epoch 0, gen_loss = 0.48573396173683375, disc_loss = 0.20102910747801936
Trained batch 74 in epoch 0, gen_loss = 0.48549066464106244, disc_loss = 0.20025259027878442
Trained batch 75 in epoch 0, gen_loss = 0.4858588772384744, disc_loss = 0.20082478744811133
Trained batch 76 in epoch 0, gen_loss = 0.4865272060617224, disc_loss = 0.20086778206871703
Trained batch 77 in epoch 0, gen_loss = 0.4872248661823762, disc_loss = 0.2015716386720156
Trained batch 78 in epoch 0, gen_loss = 0.4883165955543518, disc_loss = 0.2012505256865598
Trained batch 79 in epoch 0, gen_loss = 0.4879781287163496, disc_loss = 0.2011566516943276
Trained batch 80 in epoch 0, gen_loss = 0.4887820802353047, disc_loss = 0.20090715173217985
Trained batch 81 in epoch 0, gen_loss = 0.48893889385025674, disc_loss = 0.2016830343480517
Trained batch 82 in epoch 0, gen_loss = 0.48859123293175755, disc_loss = 0.20237689716629234
Trained batch 83 in epoch 0, gen_loss = 0.4888762597526823, disc_loss = 0.20196310936340264
Trained batch 84 in epoch 0, gen_loss = 0.4893439103575314, disc_loss = 0.20165585814153447
Trained batch 85 in epoch 0, gen_loss = 0.48988915044207904, disc_loss = 0.2008615081566711
Trained batch 86 in epoch 0, gen_loss = 0.48908364601518917, disc_loss = 0.20047764334527926
Trained batch 87 in epoch 0, gen_loss = 0.48967016996307805, disc_loss = 0.20018398262221704
Trained batch 88 in epoch 0, gen_loss = 0.48997391174348554, disc_loss = 0.20030010859952885
Trained batch 89 in epoch 0, gen_loss = 0.4909501536024941, disc_loss = 0.20010227635502814
Trained batch 90 in epoch 0, gen_loss = 0.4915993734375461, disc_loss = 0.2026446819469169
Trained batch 91 in epoch 0, gen_loss = 0.4925320164664932, disc_loss = 0.20238028733950594
Trained batch 92 in epoch 0, gen_loss = 0.4924342020224499, disc_loss = 0.2018286025812549
Trained batch 93 in epoch 0, gen_loss = 0.49192021977394185, disc_loss = 0.20135517378753803
Trained batch 94 in epoch 0, gen_loss = 0.49180410504341127, disc_loss = 0.2008317317617567
Trained batch 95 in epoch 0, gen_loss = 0.49217130523175, disc_loss = 0.2005367532838136
Trained batch 96 in epoch 0, gen_loss = 0.492144897733767, disc_loss = 0.20041684890838013
Trained batch 97 in epoch 0, gen_loss = 0.4924691213028772, disc_loss = 0.2003567839915655
Trained batch 98 in epoch 0, gen_loss = 0.49328655155018125, disc_loss = 0.20191925019025803
Trained batch 99 in epoch 0, gen_loss = 0.49411590486764906, disc_loss = 0.20140029273927212
Trained batch 100 in epoch 0, gen_loss = 0.49407312126442937, disc_loss = 0.20139836033086966
Trained batch 101 in epoch 0, gen_loss = 0.494094096270262, disc_loss = 0.20135273835530468
Trained batch 102 in epoch 0, gen_loss = 0.49382569749378463, disc_loss = 0.20099330100330334
Trained batch 103 in epoch 0, gen_loss = 0.4941504302506263, disc_loss = 0.2012017549087222
Trained batch 104 in epoch 0, gen_loss = 0.4931709403083438, disc_loss = 0.20324697714476359
Trained batch 105 in epoch 0, gen_loss = 0.4936538766015251, disc_loss = 0.20304224520640554
Trained batch 106 in epoch 0, gen_loss = 0.49386533231378715, disc_loss = 0.2038262372958326
Trained batch 107 in epoch 0, gen_loss = 0.49462505126440964, disc_loss = 0.204861999730821
Trained batch 108 in epoch 0, gen_loss = 0.49488523903243037, disc_loss = 0.20515674906312872
Trained batch 109 in epoch 0, gen_loss = 0.4947076014497063, disc_loss = 0.20502395230260761
Trained batch 110 in epoch 0, gen_loss = 0.49487853882549043, disc_loss = 0.20497096853481755
Trained batch 111 in epoch 0, gen_loss = 0.49461367247360094, disc_loss = 0.20507918251678348
Trained batch 112 in epoch 0, gen_loss = 0.4955402333124549, disc_loss = 0.2048483994022935
Trained batch 113 in epoch 0, gen_loss = 0.4960040586036548, disc_loss = 0.20461079524013034
Trained batch 114 in epoch 0, gen_loss = 0.4955901195173678, disc_loss = 0.20426692152800768
Trained batch 115 in epoch 0, gen_loss = 0.4952001861971, disc_loss = 0.2040104092066658
Trained batch 116 in epoch 0, gen_loss = 0.4948095967117538, disc_loss = 0.20359476018919903
Trained batch 117 in epoch 0, gen_loss = 0.4946573356450614, disc_loss = 0.20430437153426267
Trained batch 118 in epoch 0, gen_loss = 0.4939213164714204, disc_loss = 0.20637467221803024
Trained batch 119 in epoch 0, gen_loss = 0.49384712626536686, disc_loss = 0.20705567070593436
Trained batch 120 in epoch 0, gen_loss = 0.49457482267017205, disc_loss = 0.20809769599644606
Trained batch 121 in epoch 0, gen_loss = 0.49370966070011013, disc_loss = 0.20858545644117182
Trained batch 122 in epoch 0, gen_loss = 0.4937617698820626, disc_loss = 0.20893393220697962
Trained batch 123 in epoch 0, gen_loss = 0.49364973820986285, disc_loss = 0.20880604997998284
Trained batch 124 in epoch 0, gen_loss = 0.49280298948287965, disc_loss = 0.20902822345495223
Trained batch 125 in epoch 0, gen_loss = 0.4926125234554684, disc_loss = 0.20929616328979295
Trained batch 126 in epoch 0, gen_loss = 0.49189984188305114, disc_loss = 0.20944016626266043
Trained batch 127 in epoch 0, gen_loss = 0.4923466267064214, disc_loss = 0.20935069367988035
Trained batch 128 in epoch 0, gen_loss = 0.49263946677363196, disc_loss = 0.20896208176548167
Trained batch 129 in epoch 0, gen_loss = 0.4924177114780133, disc_loss = 0.20882250603574973
Trained batch 130 in epoch 0, gen_loss = 0.49169138096671067, disc_loss = 0.2091200494470487
Trained batch 131 in epoch 0, gen_loss = 0.49169244052785815, disc_loss = 0.20968973653560335
Trained batch 132 in epoch 0, gen_loss = 0.49171833144991023, disc_loss = 0.20979620925241843
Trained batch 133 in epoch 0, gen_loss = 0.4908968628342472, disc_loss = 0.21030245893704358
Trained batch 134 in epoch 0, gen_loss = 0.49032368063926696, disc_loss = 0.21139485742206926
Trained batch 135 in epoch 0, gen_loss = 0.49064890623969193, disc_loss = 0.21174514112884507
Trained batch 136 in epoch 0, gen_loss = 0.490640790358077, disc_loss = 0.21187880716837235
Trained batch 137 in epoch 0, gen_loss = 0.4903501995663712, disc_loss = 0.2119246574955574
Trained batch 138 in epoch 0, gen_loss = 0.48995218045419925, disc_loss = 0.21196646221893298
Trained batch 139 in epoch 0, gen_loss = 0.48949344967092784, disc_loss = 0.21197590183998857
Trained batch 140 in epoch 0, gen_loss = 0.4894423448870368, disc_loss = 0.21190010840799792
Trained batch 141 in epoch 0, gen_loss = 0.48915128304924765, disc_loss = 0.21192067856310118
Trained batch 142 in epoch 0, gen_loss = 0.4890134932694735, disc_loss = 0.21195454338005373
Trained batch 143 in epoch 0, gen_loss = 0.4885290741092629, disc_loss = 0.21261334848693675
Trained batch 144 in epoch 0, gen_loss = 0.4882248196108588, disc_loss = 0.21325788883299662
Trained batch 145 in epoch 0, gen_loss = 0.4881709769164046, disc_loss = 0.21317566313768085
Trained batch 146 in epoch 0, gen_loss = 0.48769470765477135, disc_loss = 0.21321683295932756
Trained batch 147 in epoch 0, gen_loss = 0.4873606151825673, disc_loss = 0.21336325303324172
Trained batch 148 in epoch 0, gen_loss = 0.4872377780859902, disc_loss = 0.21319217554874867
Trained batch 149 in epoch 0, gen_loss = 0.48659459988276166, disc_loss = 0.21331357444326082
Trained batch 150 in epoch 0, gen_loss = 0.48667447594617375, disc_loss = 0.21330147700396596
Trained batch 151 in epoch 0, gen_loss = 0.48611244872996684, disc_loss = 0.21338747485883927
Trained batch 152 in epoch 0, gen_loss = 0.48601065468943977, disc_loss = 0.2135743451566478
Trained batch 153 in epoch 0, gen_loss = 0.4859915472470321, disc_loss = 0.2135518290489525
Trained batch 154 in epoch 0, gen_loss = 0.4860647007342308, disc_loss = 0.21345769239048804
Trained batch 155 in epoch 0, gen_loss = 0.486436295012633, disc_loss = 0.21331488890334582
Trained batch 156 in epoch 0, gen_loss = 0.4863119768868586, disc_loss = 0.21328701842932185
Trained batch 157 in epoch 0, gen_loss = 0.4855545981775356, disc_loss = 0.21346999322877655
Trained batch 158 in epoch 0, gen_loss = 0.48520144332879744, disc_loss = 0.21394960999301393
Trained batch 159 in epoch 0, gen_loss = 0.48503326810896397, disc_loss = 0.21414745426736773
Trained batch 160 in epoch 0, gen_loss = 0.484809138389848, disc_loss = 0.21426018642157502
Trained batch 161 in epoch 0, gen_loss = 0.4846345990160365, disc_loss = 0.2142518850296368
Trained batch 162 in epoch 0, gen_loss = 0.48409529642824745, disc_loss = 0.21427556410706117
Trained batch 163 in epoch 0, gen_loss = 0.48469189990584444, disc_loss = 0.2142209044952945
Trained batch 164 in epoch 0, gen_loss = 0.4845310243693265, disc_loss = 0.21403077095746995
Trained batch 165 in epoch 0, gen_loss = 0.48419816666338816, disc_loss = 0.21390037575220489
Trained batch 166 in epoch 0, gen_loss = 0.48458272932532304, disc_loss = 0.21393846140471762
Trained batch 167 in epoch 0, gen_loss = 0.4846608911951383, disc_loss = 0.21404938466314757
Trained batch 168 in epoch 0, gen_loss = 0.48450948236256663, disc_loss = 0.21414445627194184
Trained batch 169 in epoch 0, gen_loss = 0.48437401547151454, disc_loss = 0.21402682201827275
Trained batch 170 in epoch 0, gen_loss = 0.48371200638207773, disc_loss = 0.21392581150022863
Trained batch 171 in epoch 0, gen_loss = 0.48391667458900184, disc_loss = 0.21380780944817288
Trained batch 172 in epoch 0, gen_loss = 0.4839871191565012, disc_loss = 0.21371869971125113
Trained batch 173 in epoch 0, gen_loss = 0.4837222871766693, disc_loss = 0.21374110205248856
Trained batch 174 in epoch 0, gen_loss = 0.4834293712888445, disc_loss = 0.2137307726911136
Trained batch 175 in epoch 0, gen_loss = 0.4830554827031764, disc_loss = 0.2137150427072563
Trained batch 176 in epoch 0, gen_loss = 0.4827211542991595, disc_loss = 0.21365198177301278
Trained batch 177 in epoch 0, gen_loss = 0.48275463098890325, disc_loss = 0.21357801828658982
Trained batch 178 in epoch 0, gen_loss = 0.4826506209773058, disc_loss = 0.21370000159107774
Trained batch 179 in epoch 0, gen_loss = 0.4819873775045077, disc_loss = 0.2149438471843799
Trained batch 180 in epoch 0, gen_loss = 0.4820529217548792, disc_loss = 0.214897434232314
Trained batch 181 in epoch 0, gen_loss = 0.48222101569830716, disc_loss = 0.21498108307247635
Trained batch 182 in epoch 0, gen_loss = 0.48200650163035574, disc_loss = 0.21501137230728493
Trained batch 183 in epoch 0, gen_loss = 0.4818717485860638, disc_loss = 0.21484813656981872
Trained batch 184 in epoch 0, gen_loss = 0.4817543118386655, disc_loss = 0.21475891644084777
Trained batch 185 in epoch 0, gen_loss = 0.4822093278810542, disc_loss = 0.21467659538311343
Trained batch 186 in epoch 0, gen_loss = 0.4814348671844299, disc_loss = 0.21480192415376398
Trained batch 187 in epoch 0, gen_loss = 0.4811956781022092, disc_loss = 0.21522008251161018
Trained batch 188 in epoch 0, gen_loss = 0.4811511415022391, disc_loss = 0.21592656081473385
Trained batch 189 in epoch 0, gen_loss = 0.4805875632323717, disc_loss = 0.21627851132499545
Trained batch 190 in epoch 0, gen_loss = 0.4803632652260246, disc_loss = 0.216197498532802
Trained batch 191 in epoch 0, gen_loss = 0.4798096865415573, disc_loss = 0.2164282633069282
Trained batch 192 in epoch 0, gen_loss = 0.4794372968723119, disc_loss = 0.21650417098881666
Trained batch 193 in epoch 0, gen_loss = 0.4792404744735698, disc_loss = 0.21647617032693833
Trained batch 194 in epoch 0, gen_loss = 0.4789933623411717, disc_loss = 0.2162908293879949
Trained batch 195 in epoch 0, gen_loss = 0.4791434148744661, disc_loss = 0.2161167798069667
Trained batch 196 in epoch 0, gen_loss = 0.4786410416443336, disc_loss = 0.21602384303578265
Trained batch 197 in epoch 0, gen_loss = 0.4786086850094073, disc_loss = 0.21589932692321864
Trained batch 198 in epoch 0, gen_loss = 0.47890050237502285, disc_loss = 0.21568314248143727
Trained batch 199 in epoch 0, gen_loss = 0.4789028327167034, disc_loss = 0.21545027825981378
Trained batch 200 in epoch 0, gen_loss = 0.478716265058043, disc_loss = 0.21553455586012324
Trained batch 201 in epoch 0, gen_loss = 0.47827943790667127, disc_loss = 0.21582637716195371
Trained batch 202 in epoch 0, gen_loss = 0.47837643244583616, disc_loss = 0.21574650319485827
Trained batch 203 in epoch 0, gen_loss = 0.4778160822449946, disc_loss = 0.21581323273187758
Trained batch 204 in epoch 0, gen_loss = 0.4775046184295561, disc_loss = 0.21570685305973378
Trained batch 205 in epoch 0, gen_loss = 0.4778276084406862, disc_loss = 0.2155680580118906
Trained batch 206 in epoch 0, gen_loss = 0.4780417785840334, disc_loss = 0.21571424635856049
Trained batch 207 in epoch 0, gen_loss = 0.4780739852442191, disc_loss = 0.21635598893492267
Trained batch 208 in epoch 0, gen_loss = 0.47796430898625314, disc_loss = 0.21612742204557767
Trained batch 209 in epoch 0, gen_loss = 0.47779882990178607, disc_loss = 0.21629251117507617
Trained batch 210 in epoch 0, gen_loss = 0.47767919344359666, disc_loss = 0.21677502541321714
Trained batch 211 in epoch 0, gen_loss = 0.4774115140426834, disc_loss = 0.21679104277688377
Trained batch 212 in epoch 0, gen_loss = 0.47765587123347003, disc_loss = 0.21700086395645365
Trained batch 213 in epoch 0, gen_loss = 0.4773798185252698, disc_loss = 0.21714059315691484
Trained batch 214 in epoch 0, gen_loss = 0.4769644746946734, disc_loss = 0.21709097058967103
Trained batch 215 in epoch 0, gen_loss = 0.47696499084984817, disc_loss = 0.21703129858468417
Trained batch 216 in epoch 0, gen_loss = 0.4767394848682913, disc_loss = 0.21689798435719881
Trained batch 217 in epoch 0, gen_loss = 0.47686276523345106, disc_loss = 0.21678720486410166
Trained batch 218 in epoch 0, gen_loss = 0.47698407712048047, disc_loss = 0.216563502301092
Trained batch 219 in epoch 0, gen_loss = 0.4767540523951704, disc_loss = 0.2163621527566151
Trained batch 220 in epoch 0, gen_loss = 0.4763426432782169, disc_loss = 0.21618824377993112
Trained batch 221 in epoch 0, gen_loss = 0.4759726842512956, disc_loss = 0.21630396898668092
Trained batch 222 in epoch 0, gen_loss = 0.4760345850022919, disc_loss = 0.21712535362473517
Trained batch 223 in epoch 0, gen_loss = 0.47584078101707356, disc_loss = 0.2170988839186196
Trained batch 224 in epoch 0, gen_loss = 0.47568837960561117, disc_loss = 0.21703643802139494
Trained batch 225 in epoch 0, gen_loss = 0.4754337052592134, disc_loss = 0.21696110501621677
Trained batch 226 in epoch 0, gen_loss = 0.47570575478318505, disc_loss = 0.2168577311125621
Trained batch 227 in epoch 0, gen_loss = 0.4759700278702535, disc_loss = 0.2166775847017242
Trained batch 228 in epoch 0, gen_loss = 0.4758899213184956, disc_loss = 0.216735106791211
Trained batch 229 in epoch 0, gen_loss = 0.476234084756478, disc_loss = 0.21672773416275565
Trained batch 230 in epoch 0, gen_loss = 0.47626516906730026, disc_loss = 0.21658479899684072
Trained batch 231 in epoch 0, gen_loss = 0.47589150045452444, disc_loss = 0.21648016536672568
Trained batch 232 in epoch 0, gen_loss = 0.4756074776721103, disc_loss = 0.21641536200890726
Trained batch 233 in epoch 0, gen_loss = 0.47560259266796273, disc_loss = 0.21642937909206775
Trained batch 234 in epoch 0, gen_loss = 0.4759383462845011, disc_loss = 0.2164816584041778
Trained batch 235 in epoch 0, gen_loss = 0.47576717236789606, disc_loss = 0.2170189840371831
Trained batch 236 in epoch 0, gen_loss = 0.47567925863125154, disc_loss = 0.21696617001596885
Trained batch 237 in epoch 0, gen_loss = 0.4755467202733545, disc_loss = 0.21704356669753538
Trained batch 238 in epoch 0, gen_loss = 0.475013629786639, disc_loss = 0.21714677730240084
Trained batch 239 in epoch 0, gen_loss = 0.47466054608424507, disc_loss = 0.21715308542673786
Trained batch 240 in epoch 0, gen_loss = 0.47432632824691995, disc_loss = 0.21706601782582113
Trained batch 241 in epoch 0, gen_loss = 0.47431309558143303, disc_loss = 0.2169323601444398
Trained batch 242 in epoch 0, gen_loss = 0.4741616661165967, disc_loss = 0.21675375254188545
Trained batch 243 in epoch 0, gen_loss = 0.4741137699514139, disc_loss = 0.21645537290538922
Trained batch 244 in epoch 0, gen_loss = 0.47391450538927193, disc_loss = 0.21682970867473253
Trained batch 245 in epoch 0, gen_loss = 0.4741210478350399, disc_loss = 0.21738063044300893
Trained batch 246 in epoch 0, gen_loss = 0.47392529044074083, disc_loss = 0.21775193774869084
Trained batch 247 in epoch 0, gen_loss = 0.47367949831870293, disc_loss = 0.21780099939074246
Trained batch 248 in epoch 0, gen_loss = 0.4740027371180584, disc_loss = 0.21773757115305667
Trained batch 249 in epoch 0, gen_loss = 0.47378556406497957, disc_loss = 0.21768799921870233
Trained batch 250 in epoch 0, gen_loss = 0.47358499960120454, disc_loss = 0.21758408924616665
Trained batch 251 in epoch 0, gen_loss = 0.473759626112287, disc_loss = 0.21754663736219443
Trained batch 252 in epoch 0, gen_loss = 0.4736772130129366, disc_loss = 0.21741552966032104
Trained batch 253 in epoch 0, gen_loss = 0.4737783291443126, disc_loss = 0.21731816680999252
Trained batch 254 in epoch 0, gen_loss = 0.4735817278132719, disc_loss = 0.2172469275547009
Trained batch 255 in epoch 0, gen_loss = 0.4734168533468619, disc_loss = 0.21716510006808676
Trained batch 256 in epoch 0, gen_loss = 0.4733192892853852, disc_loss = 0.2171441294861675
Trained batch 257 in epoch 0, gen_loss = 0.47317261520282244, disc_loss = 0.2172112308096054
Trained batch 258 in epoch 0, gen_loss = 0.47311719699716015, disc_loss = 0.21708726960604716
Trained batch 259 in epoch 0, gen_loss = 0.4731143194895524, disc_loss = 0.21703852859254066
Trained batch 260 in epoch 0, gen_loss = 0.4728335832955737, disc_loss = 0.21703764530776562
Trained batch 261 in epoch 0, gen_loss = 0.4726730248400273, disc_loss = 0.2169305763228704
Trained batch 262 in epoch 0, gen_loss = 0.4726193371607777, disc_loss = 0.21689101829841562
Trained batch 263 in epoch 0, gen_loss = 0.4722217643125491, disc_loss = 0.21699995460045157
Trained batch 264 in epoch 0, gen_loss = 0.47196659805639735, disc_loss = 0.21684954023023822
Trained batch 265 in epoch 0, gen_loss = 0.4716773465611881, disc_loss = 0.21676634170843245
Trained batch 266 in epoch 0, gen_loss = 0.47144302547201233, disc_loss = 0.21721380745315375
Trained batch 267 in epoch 0, gen_loss = 0.47105073951073545, disc_loss = 0.21745994539736813
Trained batch 268 in epoch 0, gen_loss = 0.47095661014872414, disc_loss = 0.2180229832857958
Trained batch 269 in epoch 0, gen_loss = 0.47072541305312404, disc_loss = 0.21862934626362943
Trained batch 270 in epoch 0, gen_loss = 0.4706601554397287, disc_loss = 0.21903977048243103
Trained batch 271 in epoch 0, gen_loss = 0.47072078934048905, disc_loss = 0.21905998247401678
Trained batch 272 in epoch 0, gen_loss = 0.470569603063248, disc_loss = 0.21913748103511202
Trained batch 273 in epoch 0, gen_loss = 0.47031835189265925, disc_loss = 0.21912411711838123
Trained batch 274 in epoch 0, gen_loss = 0.4702845061909069, disc_loss = 0.2190445069562305
Trained batch 275 in epoch 0, gen_loss = 0.4701898641128471, disc_loss = 0.2189988437500121
Trained batch 276 in epoch 0, gen_loss = 0.4705478567293835, disc_loss = 0.21884317983896723
Trained batch 277 in epoch 0, gen_loss = 0.4706009659621355, disc_loss = 0.2187217346144666
Trained batch 278 in epoch 0, gen_loss = 0.47052590233877994, disc_loss = 0.21857365557262975
Trained batch 279 in epoch 0, gen_loss = 0.47044063391430035, disc_loss = 0.2184616000258497
Trained batch 280 in epoch 0, gen_loss = 0.4705148238516363, disc_loss = 0.21833915411895705
Trained batch 281 in epoch 0, gen_loss = 0.4706456083143857, disc_loss = 0.21836032493845792
Trained batch 282 in epoch 0, gen_loss = 0.470507587013312, disc_loss = 0.21840116652814745
Trained batch 283 in epoch 0, gen_loss = 0.4700664988076183, disc_loss = 0.2185989520446935
Trained batch 284 in epoch 0, gen_loss = 0.4700093753505171, disc_loss = 0.21853571228290858
Trained batch 285 in epoch 0, gen_loss = 0.46987925719964757, disc_loss = 0.21900708064228505
Trained batch 286 in epoch 0, gen_loss = 0.4699136756023048, disc_loss = 0.21909574024664816
Trained batch 287 in epoch 0, gen_loss = 0.4698410893066062, disc_loss = 0.21899295254196557
Trained batch 288 in epoch 0, gen_loss = 0.4696702377606428, disc_loss = 0.2188544882570996
Trained batch 289 in epoch 0, gen_loss = 0.46931396681686927, disc_loss = 0.21885208870316375
Trained batch 290 in epoch 0, gen_loss = 0.46930102753065706, disc_loss = 0.21878255312283015
Trained batch 291 in epoch 0, gen_loss = 0.4692688631276562, disc_loss = 0.2187112346546699
Trained batch 292 in epoch 0, gen_loss = 0.46915621389301154, disc_loss = 0.2185433757437374
Trained batch 293 in epoch 0, gen_loss = 0.46898791305467386, disc_loss = 0.21842114746469218
Trained batch 294 in epoch 0, gen_loss = 0.46882534057407055, disc_loss = 0.2183247689725989
Trained batch 295 in epoch 0, gen_loss = 0.46867835521698, disc_loss = 0.21819087100290768
Trained batch 296 in epoch 0, gen_loss = 0.4686465191118645, disc_loss = 0.2181849969607411
Trained batch 297 in epoch 0, gen_loss = 0.46852734184905187, disc_loss = 0.21811217307144362
Trained batch 298 in epoch 0, gen_loss = 0.46821528992126615, disc_loss = 0.2181164418225703
Trained batch 299 in epoch 0, gen_loss = 0.46830465028683343, disc_loss = 0.21800763599574566
Trained batch 300 in epoch 0, gen_loss = 0.46822847807130147, disc_loss = 0.2180322369814315
Trained batch 301 in epoch 0, gen_loss = 0.46842700844963653, disc_loss = 0.21791306441489433
Trained batch 302 in epoch 0, gen_loss = 0.46843210246303296, disc_loss = 0.2177789645767448
Trained batch 303 in epoch 0, gen_loss = 0.4680283280383599, disc_loss = 0.21777668867358252
Trained batch 304 in epoch 0, gen_loss = 0.46799369473926355, disc_loss = 0.21771332208738953
Trained batch 305 in epoch 0, gen_loss = 0.4678765737932492, disc_loss = 0.21774382711528173
Trained batch 306 in epoch 0, gen_loss = 0.46790089989718087, disc_loss = 0.21770583207230615
Trained batch 307 in epoch 0, gen_loss = 0.46758223470155297, disc_loss = 0.21774296735885082
Trained batch 308 in epoch 0, gen_loss = 0.46744803915517613, disc_loss = 0.21769900333051928
Trained batch 309 in epoch 0, gen_loss = 0.46753207502826566, disc_loss = 0.2183782899331662
Trained batch 310 in epoch 0, gen_loss = 0.467498508584461, disc_loss = 0.2185061779771587
Trained batch 311 in epoch 0, gen_loss = 0.4673548083847914, disc_loss = 0.2184859176333516
Trained batch 312 in epoch 0, gen_loss = 0.4671784925955934, disc_loss = 0.21844650812137623
Trained batch 313 in epoch 0, gen_loss = 0.46700439901108953, disc_loss = 0.2183384038033379
Trained batch 314 in epoch 0, gen_loss = 0.46712621166592555, disc_loss = 0.21829148694163278
Trained batch 315 in epoch 0, gen_loss = 0.46702192553991007, disc_loss = 0.21824927239006833
Trained batch 316 in epoch 0, gen_loss = 0.466958884937154, disc_loss = 0.2182488720922816
Trained batch 317 in epoch 0, gen_loss = 0.4670054260289894, disc_loss = 0.21811663436720957
Trained batch 318 in epoch 0, gen_loss = 0.4669850288326837, disc_loss = 0.2180344901722053
Trained batch 319 in epoch 0, gen_loss = 0.46693458370864394, disc_loss = 0.21788132006768138
Trained batch 320 in epoch 0, gen_loss = 0.46666589908510725, disc_loss = 0.2179102137499138
Trained batch 321 in epoch 0, gen_loss = 0.46688929255704703, disc_loss = 0.21786178724828714
Trained batch 322 in epoch 0, gen_loss = 0.4667933832381163, disc_loss = 0.2178143981394384
Trained batch 323 in epoch 0, gen_loss = 0.46685544153054553, disc_loss = 0.21759547323080491
Trained batch 324 in epoch 0, gen_loss = 0.4667913721157954, disc_loss = 0.21771310707697503
Trained batch 325 in epoch 0, gen_loss = 0.4667078732895705, disc_loss = 0.2182141619454498
Trained batch 326 in epoch 0, gen_loss = 0.4667505471531404, disc_loss = 0.21810754698442028
Trained batch 327 in epoch 0, gen_loss = 0.4665389979576192, disc_loss = 0.218026021563607
Trained batch 328 in epoch 0, gen_loss = 0.46631605574425233, disc_loss = 0.21794744250350448
Trained batch 329 in epoch 0, gen_loss = 0.4661600617748318, disc_loss = 0.21784101194052985
Trained batch 330 in epoch 0, gen_loss = 0.46614408628097836, disc_loss = 0.2177074414050471
Trained batch 331 in epoch 0, gen_loss = 0.46617010190903424, disc_loss = 0.21783108957650432
Trained batch 332 in epoch 0, gen_loss = 0.46600450266588916, disc_loss = 0.21767894720082526
Trained batch 333 in epoch 0, gen_loss = 0.466067154250459, disc_loss = 0.21758652601145698
Trained batch 334 in epoch 0, gen_loss = 0.46565158100270515, disc_loss = 0.2177137447159682
Trained batch 335 in epoch 0, gen_loss = 0.4656667561225948, disc_loss = 0.21769976343161293
Trained batch 336 in epoch 0, gen_loss = 0.4654411419739709, disc_loss = 0.2178196081289198
Trained batch 337 in epoch 0, gen_loss = 0.46543006413787075, disc_loss = 0.21808417073103803
Trained batch 338 in epoch 0, gen_loss = 0.4654918528411944, disc_loss = 0.21798818382629603
Trained batch 339 in epoch 0, gen_loss = 0.4655419869457974, disc_loss = 0.21799584839712172
Trained batch 340 in epoch 0, gen_loss = 0.4655213298336152, disc_loss = 0.21795884830074228
Trained batch 341 in epoch 0, gen_loss = 0.46507805977997024, disc_loss = 0.2179067044012379
Trained batch 342 in epoch 0, gen_loss = 0.4651248117925127, disc_loss = 0.21777521054268578
Trained batch 343 in epoch 0, gen_loss = 0.4650831449516984, disc_loss = 0.21757876727903305
Trained batch 344 in epoch 0, gen_loss = 0.4649887968664584, disc_loss = 0.2174741771126139
Trained batch 345 in epoch 0, gen_loss = 0.4649437607368293, disc_loss = 0.21741722659826968
Trained batch 346 in epoch 0, gen_loss = 0.4646388111093889, disc_loss = 0.2173552481130152
Trained batch 347 in epoch 0, gen_loss = 0.46455589544841613, disc_loss = 0.21712000905696688
Trained batch 348 in epoch 0, gen_loss = 0.46445923001855016, disc_loss = 0.2170883049297128
Trained batch 349 in epoch 0, gen_loss = 0.46422576223100936, disc_loss = 0.21694435070667947
Trained batch 350 in epoch 0, gen_loss = 0.4642295168335961, disc_loss = 0.2172308047315334
Trained batch 351 in epoch 0, gen_loss = 0.46460456858304416, disc_loss = 0.21747813731516627
Trained batch 352 in epoch 0, gen_loss = 0.46465762005986977, disc_loss = 0.21767711033648876
Trained batch 353 in epoch 0, gen_loss = 0.46471778273919206, disc_loss = 0.21757784079612985
Trained batch 354 in epoch 0, gen_loss = 0.4648830491892049, disc_loss = 0.2174944139072593
Trained batch 355 in epoch 0, gen_loss = 0.46474622491370426, disc_loss = 0.21738721662609095
Trained batch 356 in epoch 0, gen_loss = 0.46433912722670395, disc_loss = 0.21728201830337027
Trained batch 357 in epoch 0, gen_loss = 0.46424128431514655, disc_loss = 0.2171491301051398
Trained batch 358 in epoch 0, gen_loss = 0.46395515648435415, disc_loss = 0.21712551539903896
Trained batch 359 in epoch 0, gen_loss = 0.4639213436179691, disc_loss = 0.21733865255696905
Trained batch 360 in epoch 0, gen_loss = 0.46406658980324655, disc_loss = 0.21727041910477293
Trained batch 361 in epoch 0, gen_loss = 0.4640016414183938, disc_loss = 0.2171696100733886
Trained batch 362 in epoch 0, gen_loss = 0.4637947435549796, disc_loss = 0.21711787846216485
Trained batch 363 in epoch 0, gen_loss = 0.4637461361158025, disc_loss = 0.21697879179411536
Trained batch 364 in epoch 0, gen_loss = 0.46366213862210104, disc_loss = 0.216896237555432
Trained batch 365 in epoch 0, gen_loss = 0.4637196295248355, disc_loss = 0.21678877167932975
Trained batch 366 in epoch 0, gen_loss = 0.4636792287189889, disc_loss = 0.21664703036442765
Trained batch 367 in epoch 0, gen_loss = 0.46357516604273213, disc_loss = 0.21650150485093828
Trained batch 368 in epoch 0, gen_loss = 0.46327402363947734, disc_loss = 0.21645526343648672
Trained batch 369 in epoch 0, gen_loss = 0.4631867137309667, disc_loss = 0.2163989969403357
Trained batch 370 in epoch 0, gen_loss = 0.4630515029166908, disc_loss = 0.21653597247648754
Trained batch 371 in epoch 0, gen_loss = 0.46285325897637236, disc_loss = 0.21685056318278595
Trained batch 372 in epoch 0, gen_loss = 0.4627964351995381, disc_loss = 0.21665244537528014
Trained batch 373 in epoch 0, gen_loss = 0.4627880395893107, disc_loss = 0.2164814418211659
Trained batch 374 in epoch 0, gen_loss = 0.46262211600939435, disc_loss = 0.21646069608132046
Trained batch 375 in epoch 0, gen_loss = 0.4624366612034909, disc_loss = 0.21633244569393548
Trained batch 376 in epoch 0, gen_loss = 0.4623507005940698, disc_loss = 0.21620714721771386
Trained batch 377 in epoch 0, gen_loss = 0.46218677432764144, disc_loss = 0.21612495043999935
Trained batch 378 in epoch 0, gen_loss = 0.46201596010014373, disc_loss = 0.21595679115415564
Trained batch 379 in epoch 0, gen_loss = 0.4618564475523798, disc_loss = 0.21571316550436773
Trained batch 380 in epoch 0, gen_loss = 0.46179655374191564, disc_loss = 0.2156374197932366
Trained batch 381 in epoch 0, gen_loss = 0.4616520778514952, disc_loss = 0.21548270399033712
Trained batch 382 in epoch 0, gen_loss = 0.4615572770332854, disc_loss = 0.2153425689776946
Trained batch 383 in epoch 0, gen_loss = 0.46147299363898736, disc_loss = 0.2153513922045628
Trained batch 384 in epoch 0, gen_loss = 0.46155897572443083, disc_loss = 0.2151996667121912
Trained batch 385 in epoch 0, gen_loss = 0.4615003303697072, disc_loss = 0.21507186238012166
Trained batch 386 in epoch 0, gen_loss = 0.4613959286410063, disc_loss = 0.2156836376633755
Trained batch 387 in epoch 0, gen_loss = 0.46124091452544497, disc_loss = 0.21559722771503262
Trained batch 388 in epoch 0, gen_loss = 0.46099417175915675, disc_loss = 0.21552375188829967
Trained batch 389 in epoch 0, gen_loss = 0.4609039461765534, disc_loss = 0.21547451920998403
Trained batch 390 in epoch 0, gen_loss = 0.46081384559116706, disc_loss = 0.21532455151495727
Trained batch 391 in epoch 0, gen_loss = 0.46069550643465956, disc_loss = 0.21518973329541635
Trained batch 392 in epoch 0, gen_loss = 0.4606644097175307, disc_loss = 0.21500907235473166
Trained batch 393 in epoch 0, gen_loss = 0.46060655262264505, disc_loss = 0.21485149066157752
Trained batch 394 in epoch 0, gen_loss = 0.4605254456212249, disc_loss = 0.21460345794882957
Trained batch 395 in epoch 0, gen_loss = 0.46062017277334677, disc_loss = 0.21461843770712313
Trained batch 396 in epoch 0, gen_loss = 0.4606338561482033, disc_loss = 0.21450143279296624
Trained batch 397 in epoch 0, gen_loss = 0.460590762933295, disc_loss = 0.21440985933620127
Trained batch 398 in epoch 0, gen_loss = 0.4605714890144224, disc_loss = 0.21421724367410616
Trained batch 399 in epoch 0, gen_loss = 0.4606638579815626, disc_loss = 0.2141371066123247
Trained batch 400 in epoch 0, gen_loss = 0.4608556001709584, disc_loss = 0.2141092749976755
Trained batch 401 in epoch 0, gen_loss = 0.4605964802539171, disc_loss = 0.21415479863016165
Trained batch 402 in epoch 0, gen_loss = 0.46052642347794903, disc_loss = 0.21405389790351576
Trained batch 403 in epoch 0, gen_loss = 0.46037433274311595, disc_loss = 0.21397252144789933
Trained batch 404 in epoch 0, gen_loss = 0.4602693309018641, disc_loss = 0.21383350498882342
Trained batch 405 in epoch 0, gen_loss = 0.46040932679998464, disc_loss = 0.2137348208888411
Trained batch 406 in epoch 0, gen_loss = 0.46052471044901255, disc_loss = 0.21360108757927027
Trained batch 407 in epoch 0, gen_loss = 0.46027683357105537, disc_loss = 0.21347355393364148
Trained batch 408 in epoch 0, gen_loss = 0.460102107967899, disc_loss = 0.21355005147841857
Trained batch 409 in epoch 0, gen_loss = 0.46024798140293216, disc_loss = 0.2138582732255866
Trained batch 410 in epoch 0, gen_loss = 0.46012644980945727, disc_loss = 0.21416060865795525
Trained batch 411 in epoch 0, gen_loss = 0.4602005379726586, disc_loss = 0.21408350201486384
Trained batch 412 in epoch 0, gen_loss = 0.46016558362554405, disc_loss = 0.2140822603973869
Trained batch 413 in epoch 0, gen_loss = 0.4602436037455204, disc_loss = 0.21396680478600488
Trained batch 414 in epoch 0, gen_loss = 0.4601419193198882, disc_loss = 0.21388493927128344
Trained batch 415 in epoch 0, gen_loss = 0.4601458733758101, disc_loss = 0.2137614102102816
Trained batch 416 in epoch 0, gen_loss = 0.4600275391154438, disc_loss = 0.2137502913209174
Trained batch 417 in epoch 0, gen_loss = 0.4601699258579592, disc_loss = 0.21380346542910525
Trained batch 418 in epoch 0, gen_loss = 0.459994743789295, disc_loss = 0.21394697905724827
Trained batch 419 in epoch 0, gen_loss = 0.45990518352815085, disc_loss = 0.21397433348354838
Trained batch 420 in epoch 0, gen_loss = 0.4598100548543726, disc_loss = 0.21387154150603785
Trained batch 421 in epoch 0, gen_loss = 0.45971925083494863, disc_loss = 0.21377984582671622
Trained batch 422 in epoch 0, gen_loss = 0.45957723400835165, disc_loss = 0.2137451723182737
Trained batch 423 in epoch 0, gen_loss = 0.4594572980027154, disc_loss = 0.21368951972503708
Trained batch 424 in epoch 0, gen_loss = 0.4594064577186809, disc_loss = 0.21355035918600418
Trained batch 425 in epoch 0, gen_loss = 0.4592028989898207, disc_loss = 0.21352439496158993
Trained batch 426 in epoch 0, gen_loss = 0.45910515781029604, disc_loss = 0.21344610595033095
Trained batch 427 in epoch 0, gen_loss = 0.45928171478977825, disc_loss = 0.21350439655307296
Trained batch 428 in epoch 0, gen_loss = 0.45923976492492746, disc_loss = 0.21332679181804745
Trained batch 429 in epoch 0, gen_loss = 0.4592531261749046, disc_loss = 0.21317545244860095
Trained batch 430 in epoch 0, gen_loss = 0.459122943560098, disc_loss = 0.21309466580503778
Trained batch 431 in epoch 0, gen_loss = 0.4588347580973749, disc_loss = 0.21293318092271132
Trained batch 432 in epoch 0, gen_loss = 0.4586901753521406, disc_loss = 0.21287769120504896
Trained batch 433 in epoch 0, gen_loss = 0.45877225916781184, disc_loss = 0.21270235373814533
Trained batch 434 in epoch 0, gen_loss = 0.4587701831055784, disc_loss = 0.2124551230634766
Trained batch 435 in epoch 0, gen_loss = 0.458764222578718, disc_loss = 0.21232758703376722
Trained batch 436 in epoch 0, gen_loss = 0.45885988224289237, disc_loss = 0.21279120453776157
Trained batch 437 in epoch 0, gen_loss = 0.4588213873916565, disc_loss = 0.21295635710091895
Trained batch 438 in epoch 0, gen_loss = 0.45894519621527546, disc_loss = 0.21289574914953432
Trained batch 439 in epoch 0, gen_loss = 0.45877630012956533, disc_loss = 0.21284140116450462
Trained batch 440 in epoch 0, gen_loss = 0.45857542645093263, disc_loss = 0.21270336719259383
Trained batch 441 in epoch 0, gen_loss = 0.45847267391185414, disc_loss = 0.2126140699498524
Trained batch 442 in epoch 0, gen_loss = 0.4581677507331624, disc_loss = 0.2124059535310715
Trained batch 443 in epoch 0, gen_loss = 0.4580952987611831, disc_loss = 0.2123055772201435
Trained batch 444 in epoch 0, gen_loss = 0.4578973797599921, disc_loss = 0.21222157227189353
Trained batch 445 in epoch 0, gen_loss = 0.45785814383372064, disc_loss = 0.21215707120473073
Trained batch 446 in epoch 0, gen_loss = 0.4577233553999489, disc_loss = 0.21204855751404558
Trained batch 447 in epoch 0, gen_loss = 0.4576277502014169, disc_loss = 0.21187553840822407
Trained batch 448 in epoch 0, gen_loss = 0.45751076923446826, disc_loss = 0.21179014865831702
Trained batch 449 in epoch 0, gen_loss = 0.4574307052956687, disc_loss = 0.2116814304391543
Trained batch 450 in epoch 0, gen_loss = 0.4574905558594579, disc_loss = 0.21159477221331416
Trained batch 451 in epoch 0, gen_loss = 0.4574481713692699, disc_loss = 0.211440559476614
Trained batch 452 in epoch 0, gen_loss = 0.4576161936024167, disc_loss = 0.21159001589479298
Trained batch 453 in epoch 0, gen_loss = 0.45769884473426753, disc_loss = 0.2118576200194821
Trained batch 454 in epoch 0, gen_loss = 0.4579128288960719, disc_loss = 0.21180115273365607
Trained batch 455 in epoch 0, gen_loss = 0.45775534212589264, disc_loss = 0.2116458355530835
Trained batch 456 in epoch 0, gen_loss = 0.4577288705227933, disc_loss = 0.21146486393080238
Trained batch 457 in epoch 0, gen_loss = 0.4577800726526169, disc_loss = 0.21132745483166265
Trained batch 458 in epoch 0, gen_loss = 0.4577223213150091, disc_loss = 0.2113917659895093
Trained batch 459 in epoch 0, gen_loss = 0.45779791811238163, disc_loss = 0.21137641279593758
Trained batch 460 in epoch 0, gen_loss = 0.45764568848878856, disc_loss = 0.21132614668822342
Trained batch 461 in epoch 0, gen_loss = 0.4574553207272575, disc_loss = 0.21115822028933148
Trained batch 462 in epoch 0, gen_loss = 0.45754843815099083, disc_loss = 0.21097374461253313
Trained batch 463 in epoch 0, gen_loss = 0.457448602043863, disc_loss = 0.21084895919494587
Trained batch 464 in epoch 0, gen_loss = 0.4575023033926564, disc_loss = 0.21092167746636176
Trained batch 465 in epoch 0, gen_loss = 0.4574676026857974, disc_loss = 0.2112418691359876
Trained batch 466 in epoch 0, gen_loss = 0.4572834530785456, disc_loss = 0.21131764569297848
Trained batch 467 in epoch 0, gen_loss = 0.4571552088118007, disc_loss = 0.21123911787429425
Trained batch 468 in epoch 0, gen_loss = 0.45718626249065275, disc_loss = 0.21122829514398758
Trained batch 469 in epoch 0, gen_loss = 0.4571745348103503, disc_loss = 0.2111063002588901
Trained batch 470 in epoch 0, gen_loss = 0.4571672522971078, disc_loss = 0.21095281598927362
Trained batch 471 in epoch 0, gen_loss = 0.4572965810233254, disc_loss = 0.21089890750788026
Trained batch 472 in epoch 0, gen_loss = 0.45725020753656836, disc_loss = 0.21068913521083665
Trained batch 473 in epoch 0, gen_loss = 0.45739958262393243, disc_loss = 0.21084250008317992
Trained batch 474 in epoch 0, gen_loss = 0.4575489624550468, disc_loss = 0.21080768900482277
Trained batch 475 in epoch 0, gen_loss = 0.4574371247607119, disc_loss = 0.21066968808216707
Trained batch 476 in epoch 0, gen_loss = 0.45742298497094047, disc_loss = 0.2105294820116501
Trained batch 477 in epoch 0, gen_loss = 0.457448421412432, disc_loss = 0.21043395689030073
Trained batch 478 in epoch 0, gen_loss = 0.45741788734971606, disc_loss = 0.21049644664272138
Trained batch 479 in epoch 0, gen_loss = 0.4572667934000492, disc_loss = 0.2107078312430531
Trained batch 480 in epoch 0, gen_loss = 0.4572914848704348, disc_loss = 0.2107268476901332
Trained batch 481 in epoch 0, gen_loss = 0.457142803369716, disc_loss = 0.21060260553763122
Trained batch 482 in epoch 0, gen_loss = 0.4570359905437406, disc_loss = 0.2105400626919778
Trained batch 483 in epoch 0, gen_loss = 0.456931269427469, disc_loss = 0.21045814440701127
Trained batch 484 in epoch 0, gen_loss = 0.4570013145196069, disc_loss = 0.21038349677914198
Trained batch 485 in epoch 0, gen_loss = 0.45694527612546837, disc_loss = 0.21025701396075297
Trained batch 486 in epoch 0, gen_loss = 0.4568247607846035, disc_loss = 0.2102774042766197
Trained batch 487 in epoch 0, gen_loss = 0.45687054152615736, disc_loss = 0.21048025989935534
Trained batch 488 in epoch 0, gen_loss = 0.4570192491715671, disc_loss = 0.21040756456508228
Trained batch 489 in epoch 0, gen_loss = 0.4568739178229351, disc_loss = 0.2103240411652594
Trained batch 490 in epoch 0, gen_loss = 0.4567377479280328, disc_loss = 0.21025957748324225
Trained batch 491 in epoch 0, gen_loss = 0.45658889418937326, disc_loss = 0.21029724512340092
Trained batch 492 in epoch 0, gen_loss = 0.4566258578344001, disc_loss = 0.21016140341093767
Trained batch 493 in epoch 0, gen_loss = 0.4565533252380155, disc_loss = 0.2100558027715577
Trained batch 494 in epoch 0, gen_loss = 0.4564608552239158, disc_loss = 0.21023362003492588
Trained batch 495 in epoch 0, gen_loss = 0.45643734919928736, disc_loss = 0.2101796637289226
Trained batch 496 in epoch 0, gen_loss = 0.456670297583344, disc_loss = 0.21014161046661842
Trained batch 497 in epoch 0, gen_loss = 0.45662356182992697, disc_loss = 0.20995946288348202
Trained batch 498 in epoch 0, gen_loss = 0.45659862826009073, disc_loss = 0.2098078628281553
Trained batch 499 in epoch 0, gen_loss = 0.4565381532907486, disc_loss = 0.20986246833205224
Trained batch 500 in epoch 0, gen_loss = 0.4565222155667113, disc_loss = 0.20968756882730358
Trained batch 501 in epoch 0, gen_loss = 0.4565098339699179, disc_loss = 0.20958325958465676
Trained batch 502 in epoch 0, gen_loss = 0.4564816867617916, disc_loss = 0.20951832721294988
Trained batch 503 in epoch 0, gen_loss = 0.45638814095466856, disc_loss = 0.20935891651444966
Trained batch 504 in epoch 0, gen_loss = 0.45624985334896806, disc_loss = 0.2093019463048123
Trained batch 505 in epoch 0, gen_loss = 0.4560078020859142, disc_loss = 0.20917936912167215
Trained batch 506 in epoch 0, gen_loss = 0.45620325695598385, disc_loss = 0.2090608407642244
Trained batch 507 in epoch 0, gen_loss = 0.456046600217425, disc_loss = 0.20886740367126277
Trained batch 508 in epoch 0, gen_loss = 0.4559357637623673, disc_loss = 0.208672216809803
Trained batch 509 in epoch 0, gen_loss = 0.4558169992531047, disc_loss = 0.2087357070223958
Trained batch 510 in epoch 0, gen_loss = 0.4557279179824075, disc_loss = 0.20877988945598006
Trained batch 511 in epoch 0, gen_loss = 0.45574821438640356, disc_loss = 0.20873086378560401
Trained batch 512 in epoch 0, gen_loss = 0.45568544892539753, disc_loss = 0.20857371633861496
Trained batch 513 in epoch 0, gen_loss = 0.45565074896766056, disc_loss = 0.20850316916342376
Trained batch 514 in epoch 0, gen_loss = 0.455500516787316, disc_loss = 0.20839459236385752
Trained batch 515 in epoch 0, gen_loss = 0.4554390032277551, disc_loss = 0.2082694074673246
Trained batch 516 in epoch 0, gen_loss = 0.4552908397389565, disc_loss = 0.2081234829511126
Trained batch 517 in epoch 0, gen_loss = 0.45543630582255284, disc_loss = 0.2080464766119898
Trained batch 518 in epoch 0, gen_loss = 0.4553796487047493, disc_loss = 0.20794039143532916
Trained batch 519 in epoch 0, gen_loss = 0.4553672912602241, disc_loss = 0.2079367298919421
Trained batch 520 in epoch 0, gen_loss = 0.45540150816975994, disc_loss = 0.20805692672729492
Trained batch 521 in epoch 0, gen_loss = 0.45517008160722666, disc_loss = 0.20809013330845083
Trained batch 522 in epoch 0, gen_loss = 0.455291494698643, disc_loss = 0.20795754156650595
Trained batch 523 in epoch 0, gen_loss = 0.45505121429912915, disc_loss = 0.20801199244633886
Trained batch 524 in epoch 0, gen_loss = 0.45490118827138626, disc_loss = 0.20798313612029665
Trained batch 525 in epoch 0, gen_loss = 0.45489049694384004, disc_loss = 0.20790584198422304
Trained batch 526 in epoch 0, gen_loss = 0.45483130454112275, disc_loss = 0.20779597417113904
Trained batch 527 in epoch 0, gen_loss = 0.4548132714787216, disc_loss = 0.20761810554981683
Trained batch 528 in epoch 0, gen_loss = 0.4547041305860184, disc_loss = 0.2075893962174823
Trained batch 529 in epoch 0, gen_loss = 0.4545595203930477, disc_loss = 0.20768240896879503
Trained batch 530 in epoch 0, gen_loss = 0.45447480807645624, disc_loss = 0.20757434893181992
Trained batch 531 in epoch 0, gen_loss = 0.45448416505092964, disc_loss = 0.20760465481955753
Trained batch 532 in epoch 0, gen_loss = 0.4544925467158348, disc_loss = 0.20749585698122827
Trained batch 533 in epoch 0, gen_loss = 0.45444648419873096, disc_loss = 0.2073957234593143
Trained batch 534 in epoch 0, gen_loss = 0.4544982286257164, disc_loss = 0.20728327037296562
Trained batch 535 in epoch 0, gen_loss = 0.4544372346196602, disc_loss = 0.20718548556706354
Trained batch 536 in epoch 0, gen_loss = 0.4545473500780997, disc_loss = 0.2069610755065078
Trained batch 537 in epoch 0, gen_loss = 0.4545895818994834, disc_loss = 0.20675044911169208
Trained batch 538 in epoch 0, gen_loss = 0.4544583453428767, disc_loss = 0.20656423793210613
Trained batch 539 in epoch 0, gen_loss = 0.4543952475543375, disc_loss = 0.20645085454539017
Trained batch 540 in epoch 0, gen_loss = 0.4544145661008556, disc_loss = 0.20646542536573356
Trained batch 541 in epoch 0, gen_loss = 0.4544947373361165, disc_loss = 0.20638583182628745
Trained batch 542 in epoch 0, gen_loss = 0.45435096315257456, disc_loss = 0.20625345340310758
Trained batch 543 in epoch 0, gen_loss = 0.45430689863860607, disc_loss = 0.2061291849514579
Trained batch 544 in epoch 0, gen_loss = 0.454305211611844, disc_loss = 0.20606525332555858
Trained batch 545 in epoch 0, gen_loss = 0.45424184175856386, disc_loss = 0.20616465375755297
Trained batch 546 in epoch 0, gen_loss = 0.4541958969297531, disc_loss = 0.20612347412043996
Trained batch 547 in epoch 0, gen_loss = 0.4540401219125212, disc_loss = 0.20617063204846242
Trained batch 548 in epoch 0, gen_loss = 0.4540830365838466, disc_loss = 0.20611120114452416
Trained batch 549 in epoch 0, gen_loss = 0.4541516437855634, disc_loss = 0.2059679977460341
Trained batch 550 in epoch 0, gen_loss = 0.45418746972257124, disc_loss = 0.20584322901581248
Trained batch 551 in epoch 0, gen_loss = 0.454005790685398, disc_loss = 0.20578313616198907
Trained batch 552 in epoch 0, gen_loss = 0.4540448918480554, disc_loss = 0.2056587763117192
Trained batch 553 in epoch 0, gen_loss = 0.4540667612952876, disc_loss = 0.20558301184581937
Trained batch 554 in epoch 0, gen_loss = 0.4540790368844797, disc_loss = 0.20555102543250933
Trained batch 555 in epoch 0, gen_loss = 0.4539001874036069, disc_loss = 0.2057218905672324
Trained batch 556 in epoch 0, gen_loss = 0.45384332275476236, disc_loss = 0.20561257084995455
Trained batch 557 in epoch 0, gen_loss = 0.4537096074832383, disc_loss = 0.20559195041870132
Trained batch 558 in epoch 0, gen_loss = 0.45360319089804224, disc_loss = 0.20560511610802257
Trained batch 559 in epoch 0, gen_loss = 0.4534909507525819, disc_loss = 0.20550232247582503
Trained batch 560 in epoch 0, gen_loss = 0.4535762667124709, disc_loss = 0.20554131367733558
Trained batch 561 in epoch 0, gen_loss = 0.4534097229034451, disc_loss = 0.2056498103029363
Trained batch 562 in epoch 0, gen_loss = 0.4533186626370804, disc_loss = 0.20559233194134374
Trained batch 563 in epoch 0, gen_loss = 0.45328577919631985, disc_loss = 0.20567419770972947
Trained batch 564 in epoch 0, gen_loss = 0.453244657484831, disc_loss = 0.2057157168609906
Trained batch 565 in epoch 0, gen_loss = 0.45325823138754273, disc_loss = 0.2056146316993784
Trained batch 566 in epoch 0, gen_loss = 0.45334503538183857, disc_loss = 0.20561470065062218
Trained batch 567 in epoch 0, gen_loss = 0.45320602962878387, disc_loss = 0.20557335950434208
Trained batch 568 in epoch 0, gen_loss = 0.45316087712512493, disc_loss = 0.20550411944858638
Trained batch 569 in epoch 0, gen_loss = 0.4533337217151073, disc_loss = 0.20549820251109308
Trained batch 570 in epoch 0, gen_loss = 0.4534004100463019, disc_loss = 0.20539970758604292
Trained batch 571 in epoch 0, gen_loss = 0.45334529652670547, disc_loss = 0.20523887481931205
Trained batch 572 in epoch 0, gen_loss = 0.45358988913149945, disc_loss = 0.20508196344030258
Trained batch 573 in epoch 0, gen_loss = 0.45355720163845437, disc_loss = 0.20491092554731652
Trained batch 574 in epoch 0, gen_loss = 0.45355686659398287, disc_loss = 0.20479244617016418
Trained batch 575 in epoch 0, gen_loss = 0.4534804115796255, disc_loss = 0.2047906420322963
Trained batch 576 in epoch 0, gen_loss = 0.45346191752721365, disc_loss = 0.20481361101415377
Trained batch 577 in epoch 0, gen_loss = 0.45335677833293136, disc_loss = 0.20469031888978703
Trained batch 578 in epoch 0, gen_loss = 0.4533606540662637, disc_loss = 0.20455560949027848
Trained batch 579 in epoch 0, gen_loss = 0.45343032057943017, disc_loss = 0.20452859721564012
Trained batch 580 in epoch 0, gen_loss = 0.4532947846513607, disc_loss = 0.20444601326667913
Trained batch 581 in epoch 0, gen_loss = 0.4533207609583832, disc_loss = 0.20428941201713077
Trained batch 582 in epoch 0, gen_loss = 0.4532396635919247, disc_loss = 0.20407056555433092
Trained batch 583 in epoch 0, gen_loss = 0.4532543676969123, disc_loss = 0.20396929532799818
Trained batch 584 in epoch 0, gen_loss = 0.45317420658902224, disc_loss = 0.20381947183965618
Trained batch 585 in epoch 0, gen_loss = 0.45313429074686135, disc_loss = 0.20380565774572995
Trained batch 586 in epoch 0, gen_loss = 0.4531853283284267, disc_loss = 0.20382762207844798
Trained batch 587 in epoch 0, gen_loss = 0.4532913103395579, disc_loss = 0.20366575966785555
Trained batch 588 in epoch 0, gen_loss = 0.4532595051670722, disc_loss = 0.20344747745879438
Trained batch 589 in epoch 0, gen_loss = 0.4532387446043855, disc_loss = 0.2034052928246684
Trained batch 590 in epoch 0, gen_loss = 0.4532896792122152, disc_loss = 0.20325065120525165
Trained batch 591 in epoch 0, gen_loss = 0.45330033320430163, disc_loss = 0.20315344553642176
Trained batch 592 in epoch 0, gen_loss = 0.45327176060684615, disc_loss = 0.20321702243505801
Trained batch 593 in epoch 0, gen_loss = 0.4532805675709689, disc_loss = 0.20311562365755087
Trained batch 594 in epoch 0, gen_loss = 0.4534301417715409, disc_loss = 0.20297237334131193
Trained batch 595 in epoch 0, gen_loss = 0.45340549670809865, disc_loss = 0.20293253267671438
Trained batch 596 in epoch 0, gen_loss = 0.4534189692593899, disc_loss = 0.20274717319550825
Trained batch 597 in epoch 0, gen_loss = 0.4533964798701647, disc_loss = 0.20262564021010063
Trained batch 598 in epoch 0, gen_loss = 0.4533005254794043, disc_loss = 0.2027649878958032
Trained batch 599 in epoch 0, gen_loss = 0.45333697949846585, disc_loss = 0.20296964819232624
Trained batch 600 in epoch 0, gen_loss = 0.4532709902713382, disc_loss = 0.20296954163993258
Trained batch 601 in epoch 0, gen_loss = 0.45338350529488536, disc_loss = 0.202924741636281
Trained batch 602 in epoch 0, gen_loss = 0.4532649724143457, disc_loss = 0.2029460087097304
Trained batch 603 in epoch 0, gen_loss = 0.45325907171759383, disc_loss = 0.20289252671283603
Trained batch 604 in epoch 0, gen_loss = 0.45319889626227133, disc_loss = 0.20268646468800947
Trained batch 605 in epoch 0, gen_loss = 0.45324603072290764, disc_loss = 0.20256300747591277
Trained batch 606 in epoch 0, gen_loss = 0.45326046328960967, disc_loss = 0.20235867979990002
Trained batch 607 in epoch 0, gen_loss = 0.45332491839010464, disc_loss = 0.20209221509407813
Trained batch 608 in epoch 0, gen_loss = 0.45330992727639835, disc_loss = 0.20198422273367106
Trained batch 609 in epoch 0, gen_loss = 0.4533862595186859, disc_loss = 0.20173904686311228
Trained batch 610 in epoch 0, gen_loss = 0.453404378920257, disc_loss = 0.2015742442331318
Trained batch 611 in epoch 0, gen_loss = 0.4533604955653739, disc_loss = 0.20155564425939243
Trained batch 612 in epoch 0, gen_loss = 0.45355154634688843, disc_loss = 0.201697039595679
Trained batch 613 in epoch 0, gen_loss = 0.4535424106478303, disc_loss = 0.20181001886021624
Trained batch 614 in epoch 0, gen_loss = 0.4535151092017569, disc_loss = 0.2017266708721475
Trained batch 615 in epoch 0, gen_loss = 0.4535933765885118, disc_loss = 0.20168897094108262
Trained batch 616 in epoch 0, gen_loss = 0.4536739811905006, disc_loss = 0.20157155363761625
Trained batch 617 in epoch 0, gen_loss = 0.4536814394988674, disc_loss = 0.20148325755492963
Trained batch 618 in epoch 0, gen_loss = 0.4535341712018785, disc_loss = 0.2015356022160446
Trained batch 619 in epoch 0, gen_loss = 0.4533816439490164, disc_loss = 0.20142514437076545
Trained batch 620 in epoch 0, gen_loss = 0.45338775795822944, disc_loss = 0.20129100424679966
Trained batch 621 in epoch 0, gen_loss = 0.4534505472018404, disc_loss = 0.20122233639887482
Trained batch 622 in epoch 0, gen_loss = 0.45335838767919645, disc_loss = 0.20118127455321974
Trained batch 623 in epoch 0, gen_loss = 0.4534883820093595, disc_loss = 0.2012148380625802
Trained batch 624 in epoch 0, gen_loss = 0.4533919789791107, disc_loss = 0.2012481512129307
Trained batch 625 in epoch 0, gen_loss = 0.45341632641352025, disc_loss = 0.2013257310187188
Trained batch 626 in epoch 0, gen_loss = 0.45333182374446207, disc_loss = 0.20132283272854448
Trained batch 627 in epoch 0, gen_loss = 0.45334695920253254, disc_loss = 0.20124456033134347
Trained batch 628 in epoch 0, gen_loss = 0.45346575051498716, disc_loss = 0.2011277159003745
Trained batch 629 in epoch 0, gen_loss = 0.453361105871579, disc_loss = 0.20104865008994702
Trained batch 630 in epoch 0, gen_loss = 0.4533177157967291, disc_loss = 0.20100009876484917
Trained batch 631 in epoch 0, gen_loss = 0.45340543447793286, disc_loss = 0.2008690652319619
Trained batch 632 in epoch 0, gen_loss = 0.45352329367898275, disc_loss = 0.2010197166123944
Trained batch 633 in epoch 0, gen_loss = 0.4534194855377877, disc_loss = 0.20119207362388775
Trained batch 634 in epoch 0, gen_loss = 0.45346958055270936, disc_loss = 0.20098152093178645
Trained batch 635 in epoch 0, gen_loss = 0.4535847433707999, disc_loss = 0.20096644136539232
Trained batch 636 in epoch 0, gen_loss = 0.4535540192617539, disc_loss = 0.2009909432820005
Trained batch 637 in epoch 0, gen_loss = 0.4535094112811791, disc_loss = 0.20086667276218206
Trained batch 638 in epoch 0, gen_loss = 0.4535646976346328, disc_loss = 0.20076456904434636
Trained batch 639 in epoch 0, gen_loss = 0.4535317319445312, disc_loss = 0.20067266480182297
Trained batch 640 in epoch 0, gen_loss = 0.453430995042908, disc_loss = 0.20059443039125102
Trained batch 641 in epoch 0, gen_loss = 0.4534451612895152, disc_loss = 0.20047940393312141
Trained batch 642 in epoch 0, gen_loss = 0.45342960091623513, disc_loss = 0.20042767597602834
Trained batch 643 in epoch 0, gen_loss = 0.45348411215388257, disc_loss = 0.20035434785582448
Trained batch 644 in epoch 0, gen_loss = 0.45349065656809845, disc_loss = 0.20066327820568122
Trained batch 645 in epoch 0, gen_loss = 0.4533798303397447, disc_loss = 0.2009288719667831
Trained batch 646 in epoch 0, gen_loss = 0.453367702328993, disc_loss = 0.20090281809615387
Trained batch 647 in epoch 0, gen_loss = 0.4532938569692182, disc_loss = 0.20088721490407616
Trained batch 648 in epoch 0, gen_loss = 0.4532181347371617, disc_loss = 0.20099443776421078
Trained batch 649 in epoch 0, gen_loss = 0.4532237441723163, disc_loss = 0.20098766139493537
Trained batch 650 in epoch 0, gen_loss = 0.453063230681163, disc_loss = 0.20092026292476603
Trained batch 651 in epoch 0, gen_loss = 0.45295241452250745, disc_loss = 0.2008492313153996
Trained batch 652 in epoch 0, gen_loss = 0.4529100561580103, disc_loss = 0.20074371964446802
Trained batch 653 in epoch 0, gen_loss = 0.4528776688404404, disc_loss = 0.20064316854587205
Trained batch 654 in epoch 0, gen_loss = 0.4529003446338741, disc_loss = 0.20050014389948992
Trained batch 655 in epoch 0, gen_loss = 0.45291217007651563, disc_loss = 0.2003227211591765
Trained batch 656 in epoch 0, gen_loss = 0.45284391728710366, disc_loss = 0.20022364643996346
Trained batch 657 in epoch 0, gen_loss = 0.4527715849477832, disc_loss = 0.20019275512217932
Trained batch 658 in epoch 0, gen_loss = 0.45278481042439367, disc_loss = 0.20009429615460145
Trained batch 659 in epoch 0, gen_loss = 0.4527127898552201, disc_loss = 0.2000630020248619
Trained batch 660 in epoch 0, gen_loss = 0.4526774697062107, disc_loss = 0.19990802801435364
Trained batch 661 in epoch 0, gen_loss = 0.45262533957504436, disc_loss = 0.19978023368268755
Trained batch 662 in epoch 0, gen_loss = 0.4526483168429379, disc_loss = 0.19966407464662647
Trained batch 663 in epoch 0, gen_loss = 0.4526931977415659, disc_loss = 0.1999014443717897
Trained batch 664 in epoch 0, gen_loss = 0.45259599743929124, disc_loss = 0.1999594897311881
Trained batch 665 in epoch 0, gen_loss = 0.45256528495489295, disc_loss = 0.19985232424472008
Trained batch 666 in epoch 0, gen_loss = 0.4525804296694417, disc_loss = 0.19981164451146768
Trained batch 667 in epoch 0, gen_loss = 0.4525936243687561, disc_loss = 0.19979501846330072
Trained batch 668 in epoch 0, gen_loss = 0.452651237603973, disc_loss = 0.1997575530968885
Trained batch 669 in epoch 0, gen_loss = 0.45265478180415597, disc_loss = 0.19969200281176105
Trained batch 670 in epoch 0, gen_loss = 0.4525899029435415, disc_loss = 0.1995840318523203
Trained batch 671 in epoch 0, gen_loss = 0.4526204073890334, disc_loss = 0.19950732420797326
Trained batch 672 in epoch 0, gen_loss = 0.45263629168670566, disc_loss = 0.1994839795598038
Trained batch 673 in epoch 0, gen_loss = 0.45265272502906245, disc_loss = 0.19935044326241894
Trained batch 674 in epoch 0, gen_loss = 0.4524490584709026, disc_loss = 0.19931803224815262
Trained batch 675 in epoch 0, gen_loss = 0.45246399000022536, disc_loss = 0.19930301847476403
Trained batch 676 in epoch 0, gen_loss = 0.45259746398496137, disc_loss = 0.19932024485185368
Trained batch 677 in epoch 0, gen_loss = 0.45261085622430197, disc_loss = 0.19924809208419997
Trained batch 678 in epoch 0, gen_loss = 0.4527128036840324, disc_loss = 0.1992815056204006
Trained batch 679 in epoch 0, gen_loss = 0.452689825611956, disc_loss = 0.19927790064693374
Trained batch 680 in epoch 0, gen_loss = 0.45267932552423074, disc_loss = 0.1991700636231164
Trained batch 681 in epoch 0, gen_loss = 0.4526088403379463, disc_loss = 0.19908604316981482
Trained batch 682 in epoch 0, gen_loss = 0.45252406317877036, disc_loss = 0.19902365438171046
Trained batch 683 in epoch 0, gen_loss = 0.4525290290166063, disc_loss = 0.1989801262957398
Trained batch 684 in epoch 0, gen_loss = 0.4525864300066537, disc_loss = 0.1988810983941938
Trained batch 685 in epoch 0, gen_loss = 0.45253728516942904, disc_loss = 0.19882099589457838
Trained batch 686 in epoch 0, gen_loss = 0.4525707174943871, disc_loss = 0.198662813568523
Trained batch 687 in epoch 0, gen_loss = 0.45257313202979954, disc_loss = 0.19871825897568013
Trained batch 688 in epoch 0, gen_loss = 0.4526806218530685, disc_loss = 0.1987355846008732
Trained batch 689 in epoch 0, gen_loss = 0.4526377071936925, disc_loss = 0.19857166384117328
Trained batch 690 in epoch 0, gen_loss = 0.45266118637042174, disc_loss = 0.19845317214102026
Trained batch 691 in epoch 0, gen_loss = 0.45249694491052905, disc_loss = 0.1983856065737116
Trained batch 692 in epoch 0, gen_loss = 0.45243620644572147, disc_loss = 0.19827680249428337
Trained batch 693 in epoch 0, gen_loss = 0.4524937580401341, disc_loss = 0.1982297945917941
Trained batch 694 in epoch 0, gen_loss = 0.45246980872085624, disc_loss = 0.19835972880824007
Trained batch 695 in epoch 0, gen_loss = 0.4525105391853842, disc_loss = 0.19829917766003943
Trained batch 696 in epoch 0, gen_loss = 0.4525073395141399, disc_loss = 0.19829134459752948
Trained batch 697 in epoch 0, gen_loss = 0.45270823113043873, disc_loss = 0.1984925669134944
Trained batch 698 in epoch 0, gen_loss = 0.4527707410302114, disc_loss = 0.19847260106978498
Trained batch 699 in epoch 0, gen_loss = 0.45279313130038124, disc_loss = 0.19842750187963248
Trained batch 700 in epoch 0, gen_loss = 0.45281440142898177, disc_loss = 0.19830359224649877
Trained batch 701 in epoch 0, gen_loss = 0.4526890642792411, disc_loss = 0.19816171103541838
Trained batch 702 in epoch 0, gen_loss = 0.45260504435000687, disc_loss = 0.1980242540696861
Trained batch 703 in epoch 0, gen_loss = 0.4526047076267952, disc_loss = 0.19793573044642637
Trained batch 704 in epoch 0, gen_loss = 0.4526964187199342, disc_loss = 0.1980720269923092
Trained batch 705 in epoch 0, gen_loss = 0.45266101937793807, disc_loss = 0.19797350619800874
Trained batch 706 in epoch 0, gen_loss = 0.4527941035920862, disc_loss = 0.19805591676220866
Trained batch 707 in epoch 0, gen_loss = 0.4527811378577335, disc_loss = 0.19811746854292975
Trained batch 708 in epoch 0, gen_loss = 0.45272517981919314, disc_loss = 0.19804661446191865
Trained batch 709 in epoch 0, gen_loss = 0.4526197038066219, disc_loss = 0.19799609968674856
Trained batch 710 in epoch 0, gen_loss = 0.45249589946534896, disc_loss = 0.19802433884743229
Trained batch 711 in epoch 0, gen_loss = 0.4523191823299681, disc_loss = 0.19794107914452305
Trained batch 712 in epoch 0, gen_loss = 0.45234614180147564, disc_loss = 0.19786112340164552
Trained batch 713 in epoch 0, gen_loss = 0.45237747277198387, disc_loss = 0.19779693213727126
Trained batch 714 in epoch 0, gen_loss = 0.45235132008165746, disc_loss = 0.19764933493900133
Trained batch 715 in epoch 0, gen_loss = 0.4522344062947694, disc_loss = 0.1976839987790035
Trained batch 716 in epoch 0, gen_loss = 0.45227978410747427, disc_loss = 0.19786760019270944
Trained batch 717 in epoch 0, gen_loss = 0.45226004499744904, disc_loss = 0.19781723952123215
Trained batch 718 in epoch 0, gen_loss = 0.45211593091736585, disc_loss = 0.1979133361310637
Trained batch 719 in epoch 0, gen_loss = 0.4521740220901039, disc_loss = 0.19796980155321459
Trained batch 720 in epoch 0, gen_loss = 0.4522130338477692, disc_loss = 0.1978811680929588
Trained batch 721 in epoch 0, gen_loss = 0.4521091622493934, disc_loss = 0.1978315036908989
Trained batch 722 in epoch 0, gen_loss = 0.45198723273982977, disc_loss = 0.19785342285638857
Trained batch 723 in epoch 0, gen_loss = 0.4519380833233259, disc_loss = 0.19775648531889883
Trained batch 724 in epoch 0, gen_loss = 0.4518514424356921, disc_loss = 0.197611751099085
Trained batch 725 in epoch 0, gen_loss = 0.451842248727139, disc_loss = 0.19746769436688955
Trained batch 726 in epoch 0, gen_loss = 0.4517396220724717, disc_loss = 0.1973858088654616
Trained batch 727 in epoch 0, gen_loss = 0.4517818424482267, disc_loss = 0.19737303332210734
Trained batch 728 in epoch 0, gen_loss = 0.4517635628274439, disc_loss = 0.19734097840915982
Trained batch 729 in epoch 0, gen_loss = 0.45175922696721066, disc_loss = 0.19722555756875096
Trained batch 730 in epoch 0, gen_loss = 0.45183878472500394, disc_loss = 0.19708090237304873
Trained batch 731 in epoch 0, gen_loss = 0.4519380764638791, disc_loss = 0.19695243864864762
Trained batch 732 in epoch 0, gen_loss = 0.45191335848864234, disc_loss = 0.19686707063980838
Trained batch 733 in epoch 0, gen_loss = 0.4520101881806792, disc_loss = 0.1968646646205752
Trained batch 734 in epoch 0, gen_loss = 0.4519495119853896, disc_loss = 0.1967133983412162
Trained batch 735 in epoch 0, gen_loss = 0.4518892869110341, disc_loss = 0.1967242243649114
Trained batch 736 in epoch 0, gen_loss = 0.45182883019686715, disc_loss = 0.19673127459116999
Trained batch 737 in epoch 0, gen_loss = 0.45177382149993567, disc_loss = 0.1966498636042442
Trained batch 738 in epoch 0, gen_loss = 0.4518101071795204, disc_loss = 0.19649927172411602
Trained batch 739 in epoch 0, gen_loss = 0.45181306765691653, disc_loss = 0.19646624316134162
Trained batch 740 in epoch 0, gen_loss = 0.45184232485600007, disc_loss = 0.19642485563068898
Trained batch 741 in epoch 0, gen_loss = 0.45185744449134785, disc_loss = 0.1963701362588576
Trained batch 742 in epoch 0, gen_loss = 0.4518074487131666, disc_loss = 0.19633173785632424
Trained batch 743 in epoch 0, gen_loss = 0.45183310405381266, disc_loss = 0.19626286641384164
Trained batch 744 in epoch 0, gen_loss = 0.45180700013301517, disc_loss = 0.1962030577929628
Trained batch 745 in epoch 0, gen_loss = 0.45180057049117206, disc_loss = 0.1961767418564724
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.4360893666744232, disc_loss = 0.1808108389377594
Trained batch 1 in epoch 1, gen_loss = 0.4830022305250168, disc_loss = 0.2420194447040558
Trained batch 2 in epoch 1, gen_loss = 0.4449729025363922, disc_loss = 0.24548423290252686
Trained batch 3 in epoch 1, gen_loss = 0.4404871463775635, disc_loss = 0.21636751294136047
Trained batch 4 in epoch 1, gen_loss = 0.4531154274940491, disc_loss = 0.19462099224328994
Trained batch 5 in epoch 1, gen_loss = 0.4573824604352315, disc_loss = 0.18102208897471428
Trained batch 6 in epoch 1, gen_loss = 0.45617023536137175, disc_loss = 0.18375466018915176
Trained batch 7 in epoch 1, gen_loss = 0.44901731982827187, disc_loss = 0.17520821746438742
Trained batch 8 in epoch 1, gen_loss = 0.4469936556286282, disc_loss = 0.16920660187800726
Trained batch 9 in epoch 1, gen_loss = 0.44845091700553896, disc_loss = 0.1678347997367382
Trained batch 10 in epoch 1, gen_loss = 0.4400409189137546, disc_loss = 0.1734229861335321
Trained batch 11 in epoch 1, gen_loss = 0.44338225821654004, disc_loss = 0.18242266463736692
Trained batch 12 in epoch 1, gen_loss = 0.444023086474492, disc_loss = 0.18384492569244826
Trained batch 13 in epoch 1, gen_loss = 0.4400011045592172, disc_loss = 0.1832119742674487
Trained batch 14 in epoch 1, gen_loss = 0.43944066961606343, disc_loss = 0.18380357474088668
Trained batch 15 in epoch 1, gen_loss = 0.4407500885426998, disc_loss = 0.1836797916330397
Trained batch 16 in epoch 1, gen_loss = 0.4467184824102065, disc_loss = 0.18088754178846583
Trained batch 17 in epoch 1, gen_loss = 0.44738197988933986, disc_loss = 0.17685800583826172
Trained batch 18 in epoch 1, gen_loss = 0.4479100280686429, disc_loss = 0.1749271707315194
Trained batch 19 in epoch 1, gen_loss = 0.4488114073872566, disc_loss = 0.17348974831402303
Trained batch 20 in epoch 1, gen_loss = 0.4468106641655877, disc_loss = 0.17153252767665045
Trained batch 21 in epoch 1, gen_loss = 0.4436346563425931, disc_loss = 0.1717775785787539
Trained batch 22 in epoch 1, gen_loss = 0.44317495822906494, disc_loss = 0.1698799168933993
Trained batch 23 in epoch 1, gen_loss = 0.4450110122561455, disc_loss = 0.16907328149924675
Trained batch 24 in epoch 1, gen_loss = 0.44413427233695985, disc_loss = 0.1681299987435341
Trained batch 25 in epoch 1, gen_loss = 0.4432074737090331, disc_loss = 0.1663358429303536
Trained batch 26 in epoch 1, gen_loss = 0.4451394036964134, disc_loss = 0.16422198436878346
Trained batch 27 in epoch 1, gen_loss = 0.448106763618333, disc_loss = 0.16339329097952163
Trained batch 28 in epoch 1, gen_loss = 0.4484130647675744, disc_loss = 0.16223808403672843
Trained batch 29 in epoch 1, gen_loss = 0.4463133951028188, disc_loss = 0.16451418350140254
Trained batch 30 in epoch 1, gen_loss = 0.448087792242727, disc_loss = 0.16563099045907298
Trained batch 31 in epoch 1, gen_loss = 0.4481883915141225, disc_loss = 0.1661141342483461
Trained batch 32 in epoch 1, gen_loss = 0.44750452041625977, disc_loss = 0.1660674142115044
Trained batch 33 in epoch 1, gen_loss = 0.44742561964427724, disc_loss = 0.16463510560638764
Trained batch 34 in epoch 1, gen_loss = 0.4485635655266898, disc_loss = 0.16404961049556732
Trained batch 35 in epoch 1, gen_loss = 0.4484649548927943, disc_loss = 0.16277519861857095
Trained batch 36 in epoch 1, gen_loss = 0.44952142238616943, disc_loss = 0.16534180737830498
Trained batch 37 in epoch 1, gen_loss = 0.4492941200733185, disc_loss = 0.16524622079573179
Trained batch 38 in epoch 1, gen_loss = 0.4497785048607068, disc_loss = 0.16589815952838996
Trained batch 39 in epoch 1, gen_loss = 0.4495096027851105, disc_loss = 0.168003561347723
Trained batch 40 in epoch 1, gen_loss = 0.449821940282496, disc_loss = 0.1683932182992377
Trained batch 41 in epoch 1, gen_loss = 0.4516460413024539, disc_loss = 0.16729634397086643
Trained batch 42 in epoch 1, gen_loss = 0.45108904464300287, disc_loss = 0.16658782404522562
Trained batch 43 in epoch 1, gen_loss = 0.4517709565433589, disc_loss = 0.1660496314818209
Trained batch 44 in epoch 1, gen_loss = 0.4529743558830685, disc_loss = 0.16522228452894422
Trained batch 45 in epoch 1, gen_loss = 0.4523937235707822, disc_loss = 0.16411927763534628
Trained batch 46 in epoch 1, gen_loss = 0.45323762424448705, disc_loss = 0.16335470974445343
Trained batch 47 in epoch 1, gen_loss = 0.45279869933923084, disc_loss = 0.161565317461888
Trained batch 48 in epoch 1, gen_loss = 0.45366028681093334, disc_loss = 0.16021118054584582
Trained batch 49 in epoch 1, gen_loss = 0.4543018943071365, disc_loss = 0.15913099989295007
Trained batch 50 in epoch 1, gen_loss = 0.45478730341967416, disc_loss = 0.15820160464328878
Trained batch 51 in epoch 1, gen_loss = 0.45472092639941436, disc_loss = 0.15957492575622523
Trained batch 52 in epoch 1, gen_loss = 0.4547961118086329, disc_loss = 0.16465229400486317
Trained batch 53 in epoch 1, gen_loss = 0.45680356908727576, disc_loss = 0.16515108956782906
Trained batch 54 in epoch 1, gen_loss = 0.45589503049850466, disc_loss = 0.16610294919122348
Trained batch 55 in epoch 1, gen_loss = 0.45506602099963595, disc_loss = 0.16563728198941266
Trained batch 56 in epoch 1, gen_loss = 0.45398276207739846, disc_loss = 0.16565393421210742
Trained batch 57 in epoch 1, gen_loss = 0.4545700555217677, disc_loss = 0.1648931478888824
Trained batch 58 in epoch 1, gen_loss = 0.454393362089739, disc_loss = 0.16461149981971515
Trained batch 59 in epoch 1, gen_loss = 0.45402413258949914, disc_loss = 0.16400476656854152
Trained batch 60 in epoch 1, gen_loss = 0.45291846160028804, disc_loss = 0.16421180755877104
Trained batch 61 in epoch 1, gen_loss = 0.45203013477786896, disc_loss = 0.16378496094576775
Trained batch 62 in epoch 1, gen_loss = 0.4518089389044141, disc_loss = 0.16347923413628623
Trained batch 63 in epoch 1, gen_loss = 0.45070064486935735, disc_loss = 0.16369540442246944
Trained batch 64 in epoch 1, gen_loss = 0.4525625471885388, disc_loss = 0.16419984961931522
Trained batch 65 in epoch 1, gen_loss = 0.4519737186757001, disc_loss = 0.16359501241734534
Trained batch 66 in epoch 1, gen_loss = 0.4527595919459613, disc_loss = 0.16332063879539718
Trained batch 67 in epoch 1, gen_loss = 0.45194343521314506, disc_loss = 0.16333427061052883
Trained batch 68 in epoch 1, gen_loss = 0.4527495658915976, disc_loss = 0.16267155348390772
Trained batch 69 in epoch 1, gen_loss = 0.45319164863654543, disc_loss = 0.16245803790433067
Trained batch 70 in epoch 1, gen_loss = 0.4517877227823499, disc_loss = 0.1619402331785417
Trained batch 71 in epoch 1, gen_loss = 0.4519832266701592, disc_loss = 0.16330118166903654
Trained batch 72 in epoch 1, gen_loss = 0.4528582667651242, disc_loss = 0.16470424259362154
Trained batch 73 in epoch 1, gen_loss = 0.45306316863846136, disc_loss = 0.16394499367153323
Trained batch 74 in epoch 1, gen_loss = 0.4533724045753479, disc_loss = 0.16352471033732097
Trained batch 75 in epoch 1, gen_loss = 0.4527270888027392, disc_loss = 0.16328871838356318
Trained batch 76 in epoch 1, gen_loss = 0.45307051206563975, disc_loss = 0.16379079106566194
Trained batch 77 in epoch 1, gen_loss = 0.4520164838968179, disc_loss = 0.16329452662895888
Trained batch 78 in epoch 1, gen_loss = 0.45119941800455504, disc_loss = 0.16319469881208637
Trained batch 79 in epoch 1, gen_loss = 0.45168969593942165, disc_loss = 0.16249932255595922
Trained batch 80 in epoch 1, gen_loss = 0.45188163607208814, disc_loss = 0.16140490899115434
Trained batch 81 in epoch 1, gen_loss = 0.45129441451735613, disc_loss = 0.16026442316247197
Trained batch 82 in epoch 1, gen_loss = 0.4516705238675497, disc_loss = 0.15941103772226586
Trained batch 83 in epoch 1, gen_loss = 0.45233273931912016, disc_loss = 0.1592437362387067
Trained batch 84 in epoch 1, gen_loss = 0.4513146723017973, disc_loss = 0.15820611189393435
Trained batch 85 in epoch 1, gen_loss = 0.4516760544028393, disc_loss = 0.15779956672773804
Trained batch 86 in epoch 1, gen_loss = 0.4517138322879528, disc_loss = 0.1566342438260714
Trained batch 87 in epoch 1, gen_loss = 0.45260973850434477, disc_loss = 0.15666885157539087
Trained batch 88 in epoch 1, gen_loss = 0.4532395028666164, disc_loss = 0.15661330948050103
Trained batch 89 in epoch 1, gen_loss = 0.45274321205086177, disc_loss = 0.15802035770482487
Trained batch 90 in epoch 1, gen_loss = 0.45466373025716006, disc_loss = 0.1584379200588216
Trained batch 91 in epoch 1, gen_loss = 0.4547904788152031, disc_loss = 0.15737656536309616
Trained batch 92 in epoch 1, gen_loss = 0.4543622392480091, disc_loss = 0.1583387742760361
Trained batch 93 in epoch 1, gen_loss = 0.4550383636291991, disc_loss = 0.1575140342750448
Trained batch 94 in epoch 1, gen_loss = 0.4561160827937879, disc_loss = 0.15714160948991776
Trained batch 95 in epoch 1, gen_loss = 0.45645422643671435, disc_loss = 0.15732769396466514
Trained batch 96 in epoch 1, gen_loss = 0.45655254942854656, disc_loss = 0.15713217493492304
Trained batch 97 in epoch 1, gen_loss = 0.45639465141053104, disc_loss = 0.15709199992065526
Trained batch 98 in epoch 1, gen_loss = 0.45637229626828973, disc_loss = 0.15632753638607083
Trained batch 99 in epoch 1, gen_loss = 0.45582870274782183, disc_loss = 0.15690331019461154
Trained batch 100 in epoch 1, gen_loss = 0.45541584403207985, disc_loss = 0.15876774364473797
Trained batch 101 in epoch 1, gen_loss = 0.45606907822337805, disc_loss = 0.15843799702969252
Trained batch 102 in epoch 1, gen_loss = 0.45613486818896914, disc_loss = 0.15792911760147335
Trained batch 103 in epoch 1, gen_loss = 0.4553553920525771, disc_loss = 0.1573693728647553
Trained batch 104 in epoch 1, gen_loss = 0.4557590024811881, disc_loss = 0.15655674302861805
Trained batch 105 in epoch 1, gen_loss = 0.45589724295544176, disc_loss = 0.1563437909309594
Trained batch 106 in epoch 1, gen_loss = 0.45613731067871377, disc_loss = 0.15714452847420612
Trained batch 107 in epoch 1, gen_loss = 0.4562019049017518, disc_loss = 0.15678706033914178
Trained batch 108 in epoch 1, gen_loss = 0.4562316312702424, disc_loss = 0.15660255381820398
Trained batch 109 in epoch 1, gen_loss = 0.45687098069624466, disc_loss = 0.15659923418001695
Trained batch 110 in epoch 1, gen_loss = 0.45673010907731615, disc_loss = 0.15602623268559174
Trained batch 111 in epoch 1, gen_loss = 0.4569950361869165, disc_loss = 0.15577489915969117
Trained batch 112 in epoch 1, gen_loss = 0.4570751358977461, disc_loss = 0.1552400999760206
Trained batch 113 in epoch 1, gen_loss = 0.4569261087137356, disc_loss = 0.1548129675027571
Trained batch 114 in epoch 1, gen_loss = 0.45760590641394905, disc_loss = 0.15421984629786534
Trained batch 115 in epoch 1, gen_loss = 0.4574211296336404, disc_loss = 0.15441717753379508
Trained batch 116 in epoch 1, gen_loss = 0.4577249441391382, disc_loss = 0.15499825030565262
Trained batch 117 in epoch 1, gen_loss = 0.4576429891384254, disc_loss = 0.1544400010952505
Trained batch 118 in epoch 1, gen_loss = 0.45695701892636403, disc_loss = 0.15458892567568466
Trained batch 119 in epoch 1, gen_loss = 0.45722495863835017, disc_loss = 0.15371580223242443
Trained batch 120 in epoch 1, gen_loss = 0.4560524875467474, disc_loss = 0.15455179273589584
Trained batch 121 in epoch 1, gen_loss = 0.45699206238887347, disc_loss = 0.15470949951253954
Trained batch 122 in epoch 1, gen_loss = 0.45695525044348184, disc_loss = 0.15431104279388258
Trained batch 123 in epoch 1, gen_loss = 0.457178772216843, disc_loss = 0.1541051096132686
Trained batch 124 in epoch 1, gen_loss = 0.45734351563453673, disc_loss = 0.15370796287059785
Trained batch 125 in epoch 1, gen_loss = 0.4574471248520745, disc_loss = 0.1535936864832091
Trained batch 126 in epoch 1, gen_loss = 0.4577635263833474, disc_loss = 0.15303059068955774
Trained batch 127 in epoch 1, gen_loss = 0.4579678170848638, disc_loss = 0.15307561756344512
Trained batch 128 in epoch 1, gen_loss = 0.45759484610816303, disc_loss = 0.1540810166056766
Trained batch 129 in epoch 1, gen_loss = 0.4564090825044192, disc_loss = 0.15426408963707777
Trained batch 130 in epoch 1, gen_loss = 0.45634888078420216, disc_loss = 0.15414157049119018
Trained batch 131 in epoch 1, gen_loss = 0.455613065849651, disc_loss = 0.15361482847594854
Trained batch 132 in epoch 1, gen_loss = 0.45582872337864755, disc_loss = 0.15346585253351613
Trained batch 133 in epoch 1, gen_loss = 0.455774355290541, disc_loss = 0.15334800013632915
Trained batch 134 in epoch 1, gen_loss = 0.4561079837657787, disc_loss = 0.15373729770934141
Trained batch 135 in epoch 1, gen_loss = 0.4559726474039695, disc_loss = 0.15443412548698046
Trained batch 136 in epoch 1, gen_loss = 0.45590098756943304, disc_loss = 0.15399621508634873
Trained batch 137 in epoch 1, gen_loss = 0.4560222040483917, disc_loss = 0.15357081295139546
Trained batch 138 in epoch 1, gen_loss = 0.4558578495927852, disc_loss = 0.1532350494492826
Trained batch 139 in epoch 1, gen_loss = 0.45615038233143945, disc_loss = 0.15334778161985532
Trained batch 140 in epoch 1, gen_loss = 0.4561813752701942, disc_loss = 0.1532415473926152
Trained batch 141 in epoch 1, gen_loss = 0.45587771165538843, disc_loss = 0.15277623899385961
Trained batch 142 in epoch 1, gen_loss = 0.4554476610847286, disc_loss = 0.1525931617805174
Trained batch 143 in epoch 1, gen_loss = 0.4552741613652971, disc_loss = 0.15237740742870504
Trained batch 144 in epoch 1, gen_loss = 0.45498391718700015, disc_loss = 0.15214583586002217
Trained batch 145 in epoch 1, gen_loss = 0.45481229726582356, disc_loss = 0.15201572012411405
Trained batch 146 in epoch 1, gen_loss = 0.45546860192097777, disc_loss = 0.15254602555920477
Trained batch 147 in epoch 1, gen_loss = 0.4554096182455888, disc_loss = 0.15247781947255135
Trained batch 148 in epoch 1, gen_loss = 0.45498639525183093, disc_loss = 0.15202005197537827
Trained batch 149 in epoch 1, gen_loss = 0.45495538095633187, disc_loss = 0.15236381163199741
Trained batch 150 in epoch 1, gen_loss = 0.45485107571083977, disc_loss = 0.1526721812636647
Trained batch 151 in epoch 1, gen_loss = 0.45506685756539045, disc_loss = 0.15372053867107943
Trained batch 152 in epoch 1, gen_loss = 0.4544347569443821, disc_loss = 0.15382002099277148
Trained batch 153 in epoch 1, gen_loss = 0.4544081705344188, disc_loss = 0.15349086935256984
Trained batch 154 in epoch 1, gen_loss = 0.4547752055429643, disc_loss = 0.15334477405394278
Trained batch 155 in epoch 1, gen_loss = 0.4551393578831966, disc_loss = 0.15303003253080907
Trained batch 156 in epoch 1, gen_loss = 0.45510117073727263, disc_loss = 0.15288025928530724
Trained batch 157 in epoch 1, gen_loss = 0.4548403930060471, disc_loss = 0.15252839505106588
Trained batch 158 in epoch 1, gen_loss = 0.4554914550961189, disc_loss = 0.15215117531190128
Trained batch 159 in epoch 1, gen_loss = 0.45570065788924696, disc_loss = 0.1520928209181875
Trained batch 160 in epoch 1, gen_loss = 0.45565826496722533, disc_loss = 0.15272667407063964
Trained batch 161 in epoch 1, gen_loss = 0.45528239876399806, disc_loss = 0.15259603645514558
Trained batch 162 in epoch 1, gen_loss = 0.45521398281758546, disc_loss = 0.15254459392987876
Trained batch 163 in epoch 1, gen_loss = 0.4554901775426981, disc_loss = 0.1521432316157876
Trained batch 164 in epoch 1, gen_loss = 0.4555021858576572, disc_loss = 0.15159848075021398
Trained batch 165 in epoch 1, gen_loss = 0.45574610868850385, disc_loss = 0.15108681667640986
Trained batch 166 in epoch 1, gen_loss = 0.45625568774645914, disc_loss = 0.1505187800276779
Trained batch 167 in epoch 1, gen_loss = 0.4562224916049412, disc_loss = 0.15028981336702904
Trained batch 168 in epoch 1, gen_loss = 0.455913223458465, disc_loss = 0.14983458653885937
Trained batch 169 in epoch 1, gen_loss = 0.45597971800495596, disc_loss = 0.1494106432532563
Trained batch 170 in epoch 1, gen_loss = 0.4562138287644637, disc_loss = 0.1490078859074771
Trained batch 171 in epoch 1, gen_loss = 0.45648946353169373, disc_loss = 0.1490856419902208
Trained batch 172 in epoch 1, gen_loss = 0.4563313366016212, disc_loss = 0.14878685178095205
Trained batch 173 in epoch 1, gen_loss = 0.4563775901821838, disc_loss = 0.14891099338901453
Trained batch 174 in epoch 1, gen_loss = 0.45709035873413084, disc_loss = 0.1494145860842296
Trained batch 175 in epoch 1, gen_loss = 0.45723317665132607, disc_loss = 0.14891952911222522
Trained batch 176 in epoch 1, gen_loss = 0.4568501924727596, disc_loss = 0.14901288956572106
Trained batch 177 in epoch 1, gen_loss = 0.4565796950894795, disc_loss = 0.14885616051347067
Trained batch 178 in epoch 1, gen_loss = 0.4566444426608485, disc_loss = 0.14855231361349203
Trained batch 179 in epoch 1, gen_loss = 0.4563496780064371, disc_loss = 0.14817216131422256
Trained batch 180 in epoch 1, gen_loss = 0.4560957789750389, disc_loss = 0.1477313613858671
Trained batch 181 in epoch 1, gen_loss = 0.45628595466797167, disc_loss = 0.14758024331960048
Trained batch 182 in epoch 1, gen_loss = 0.45616278899171964, disc_loss = 0.14718548277688157
Trained batch 183 in epoch 1, gen_loss = 0.45590318172522215, disc_loss = 0.1467889935264121
Trained batch 184 in epoch 1, gen_loss = 0.4555399248728881, disc_loss = 0.14626509998295759
Trained batch 185 in epoch 1, gen_loss = 0.45547577177965515, disc_loss = 0.1461986286505576
Trained batch 186 in epoch 1, gen_loss = 0.455511446464508, disc_loss = 0.146988084211069
Trained batch 187 in epoch 1, gen_loss = 0.45505351604933436, disc_loss = 0.14745487803791432
Trained batch 188 in epoch 1, gen_loss = 0.4552889985066873, disc_loss = 0.14741360928331101
Trained batch 189 in epoch 1, gen_loss = 0.4551480613256756, disc_loss = 0.14750433195578425
Trained batch 190 in epoch 1, gen_loss = 0.4548141254180389, disc_loss = 0.14718818274468026
Trained batch 191 in epoch 1, gen_loss = 0.454730327706784, disc_loss = 0.14691490470431745
Trained batch 192 in epoch 1, gen_loss = 0.4551134660762826, disc_loss = 0.14666938044401032
Trained batch 193 in epoch 1, gen_loss = 0.45489030999621166, disc_loss = 0.146337044108467
Trained batch 194 in epoch 1, gen_loss = 0.4546583583721748, disc_loss = 0.1462625740812375
Trained batch 195 in epoch 1, gen_loss = 0.4546842900465946, disc_loss = 0.14641373289026777
Trained batch 196 in epoch 1, gen_loss = 0.4546681224997274, disc_loss = 0.1465056862701014
Trained batch 197 in epoch 1, gen_loss = 0.45447523259755335, disc_loss = 0.14633630720352886
Trained batch 198 in epoch 1, gen_loss = 0.45448239424719883, disc_loss = 0.14598933918092719
Trained batch 199 in epoch 1, gen_loss = 0.4542924135923386, disc_loss = 0.14591190353035927
Trained batch 200 in epoch 1, gen_loss = 0.45456966149866285, disc_loss = 0.14586020420439802
Trained batch 201 in epoch 1, gen_loss = 0.4547720020360286, disc_loss = 0.1459555273303891
Trained batch 202 in epoch 1, gen_loss = 0.4549367680338216, disc_loss = 0.14600780371374686
Trained batch 203 in epoch 1, gen_loss = 0.4547140456589998, disc_loss = 0.14640445868466415
Trained batch 204 in epoch 1, gen_loss = 0.45468526075525983, disc_loss = 0.14590552398344367
Trained batch 205 in epoch 1, gen_loss = 0.45474902837021836, disc_loss = 0.14608311443363578
Trained batch 206 in epoch 1, gen_loss = 0.4545911551961576, disc_loss = 0.1459669828198958
Trained batch 207 in epoch 1, gen_loss = 0.454837007734638, disc_loss = 0.14573530297583112
Trained batch 208 in epoch 1, gen_loss = 0.45495459936452254, disc_loss = 0.1455658128458347
Trained batch 209 in epoch 1, gen_loss = 0.45513558799312226, disc_loss = 0.14616495970459212
Trained batch 210 in epoch 1, gen_loss = 0.4549569200847951, disc_loss = 0.14636109384456517
Trained batch 211 in epoch 1, gen_loss = 0.4546192677797012, disc_loss = 0.14605213993422264
Trained batch 212 in epoch 1, gen_loss = 0.4550088799335587, disc_loss = 0.14580931178700757
Trained batch 213 in epoch 1, gen_loss = 0.45527173801560267, disc_loss = 0.1454859502335018
Trained batch 214 in epoch 1, gen_loss = 0.45521135136138563, disc_loss = 0.1450271555850672
Trained batch 215 in epoch 1, gen_loss = 0.4548638925232269, disc_loss = 0.14486058887646155
Trained batch 216 in epoch 1, gen_loss = 0.45489337298727256, disc_loss = 0.14462915430283216
Trained batch 217 in epoch 1, gen_loss = 0.45489148822946285, disc_loss = 0.14439213733880893
Trained batch 218 in epoch 1, gen_loss = 0.4546236262473886, disc_loss = 0.14426877638792882
Trained batch 219 in epoch 1, gen_loss = 0.4552146762609482, disc_loss = 0.14415378519757227
Trained batch 220 in epoch 1, gen_loss = 0.4552401217939627, disc_loss = 0.14399097155257048
Trained batch 221 in epoch 1, gen_loss = 0.45515802650301307, disc_loss = 0.14392226199443275
Trained batch 222 in epoch 1, gen_loss = 0.4550310978707711, disc_loss = 0.14365271338566538
Trained batch 223 in epoch 1, gen_loss = 0.4551627568102309, disc_loss = 0.14339542585158987
Trained batch 224 in epoch 1, gen_loss = 0.4556853128804101, disc_loss = 0.14329998903804356
Trained batch 225 in epoch 1, gen_loss = 0.45559493960004993, disc_loss = 0.14319030683388753
Trained batch 226 in epoch 1, gen_loss = 0.45558325178297604, disc_loss = 0.14334194998909197
Trained batch 227 in epoch 1, gen_loss = 0.4557222352738966, disc_loss = 0.1430769053598245
Trained batch 228 in epoch 1, gen_loss = 0.4558028533208839, disc_loss = 0.1426799761123272
Trained batch 229 in epoch 1, gen_loss = 0.4559770113748053, disc_loss = 0.14231617649936157
Trained batch 230 in epoch 1, gen_loss = 0.4561701100884062, disc_loss = 0.1423722824718787
Trained batch 231 in epoch 1, gen_loss = 0.4560720048330981, disc_loss = 0.14222832439981145
Trained batch 232 in epoch 1, gen_loss = 0.45601073393494274, disc_loss = 0.14178658000197533
Trained batch 233 in epoch 1, gen_loss = 0.455802894046164, disc_loss = 0.1416716411486905
Trained batch 234 in epoch 1, gen_loss = 0.4561294679946088, disc_loss = 0.14186472450482085
Trained batch 235 in epoch 1, gen_loss = 0.456634698782937, disc_loss = 0.1416579651156977
Trained batch 236 in epoch 1, gen_loss = 0.4568060833945053, disc_loss = 0.14117307464281717
Trained batch 237 in epoch 1, gen_loss = 0.45680702170904947, disc_loss = 0.14081545761089867
Trained batch 238 in epoch 1, gen_loss = 0.45717103822959515, disc_loss = 0.14078110816526113
Trained batch 239 in epoch 1, gen_loss = 0.4571977034211159, disc_loss = 0.1413249499940624
Trained batch 240 in epoch 1, gen_loss = 0.45740877444318717, disc_loss = 0.1411105100822894
Trained batch 241 in epoch 1, gen_loss = 0.4570480234120503, disc_loss = 0.14088592950778067
Trained batch 242 in epoch 1, gen_loss = 0.4569929721669405, disc_loss = 0.14057892025927457
Trained batch 243 in epoch 1, gen_loss = 0.4570113750266247, disc_loss = 0.14043995287635777
Trained batch 244 in epoch 1, gen_loss = 0.45696150332081076, disc_loss = 0.14054401031866365
Trained batch 245 in epoch 1, gen_loss = 0.4568000618762117, disc_loss = 0.14052243405059586
Trained batch 246 in epoch 1, gen_loss = 0.45716527804189366, disc_loss = 0.14027601623764405
Trained batch 247 in epoch 1, gen_loss = 0.457213512351436, disc_loss = 0.1400532402969416
Trained batch 248 in epoch 1, gen_loss = 0.4572870092219617, disc_loss = 0.14019071949593515
Trained batch 249 in epoch 1, gen_loss = 0.4574764482975006, disc_loss = 0.14076332069933414
Trained batch 250 in epoch 1, gen_loss = 0.45748312682269576, disc_loss = 0.14065113074454177
Trained batch 251 in epoch 1, gen_loss = 0.45713282163654057, disc_loss = 0.14177936651108283
Trained batch 252 in epoch 1, gen_loss = 0.4571928675231255, disc_loss = 0.14181906436919695
Trained batch 253 in epoch 1, gen_loss = 0.4569943659887539, disc_loss = 0.14183024755554405
Trained batch 254 in epoch 1, gen_loss = 0.45720928603527594, disc_loss = 0.1416613429638685
Trained batch 255 in epoch 1, gen_loss = 0.45704719820059836, disc_loss = 0.1416788645874476
Trained batch 256 in epoch 1, gen_loss = 0.4570116772957813, disc_loss = 0.14174045267214108
Trained batch 257 in epoch 1, gen_loss = 0.4566395223833794, disc_loss = 0.14162474797042304
Trained batch 258 in epoch 1, gen_loss = 0.4562664151651979, disc_loss = 0.14143122469423822
Trained batch 259 in epoch 1, gen_loss = 0.4561650692270352, disc_loss = 0.14122403936030772
Trained batch 260 in epoch 1, gen_loss = 0.45620337357009505, disc_loss = 0.14146297549208006
Trained batch 261 in epoch 1, gen_loss = 0.45640063979698503, disc_loss = 0.14136744508135865
Trained batch 262 in epoch 1, gen_loss = 0.4564248818635034, disc_loss = 0.1418135256396727
Trained batch 263 in epoch 1, gen_loss = 0.4567383894640388, disc_loss = 0.14160027610363835
Trained batch 264 in epoch 1, gen_loss = 0.45684185151783924, disc_loss = 0.1412678614961651
Trained batch 265 in epoch 1, gen_loss = 0.4567330783247051, disc_loss = 0.14129346170763774
Trained batch 266 in epoch 1, gen_loss = 0.4565276759170861, disc_loss = 0.14115940286927903
Trained batch 267 in epoch 1, gen_loss = 0.456381271690575, disc_loss = 0.1412256667112459
Trained batch 268 in epoch 1, gen_loss = 0.45600654821856756, disc_loss = 0.14133859302530058
Trained batch 269 in epoch 1, gen_loss = 0.4561590916580624, disc_loss = 0.14119596576525106
Trained batch 270 in epoch 1, gen_loss = 0.45625497296287565, disc_loss = 0.1410928447885487
Trained batch 271 in epoch 1, gen_loss = 0.4562244661809767, disc_loss = 0.1408304095350425
Trained batch 272 in epoch 1, gen_loss = 0.45632270262354896, disc_loss = 0.14072142125213102
Trained batch 273 in epoch 1, gen_loss = 0.45651302100533114, disc_loss = 0.140715200358825
Trained batch 274 in epoch 1, gen_loss = 0.4563105460730466, disc_loss = 0.14053973814303225
Trained batch 275 in epoch 1, gen_loss = 0.45645098539366236, disc_loss = 0.14053826065113148
Trained batch 276 in epoch 1, gen_loss = 0.45657278150858, disc_loss = 0.14047201829105077
Trained batch 277 in epoch 1, gen_loss = 0.4566478083888404, disc_loss = 0.14011131304738333
Trained batch 278 in epoch 1, gen_loss = 0.45673122756370077, disc_loss = 0.13994033509151055
Trained batch 279 in epoch 1, gen_loss = 0.45684099197387695, disc_loss = 0.13960227593779564
Trained batch 280 in epoch 1, gen_loss = 0.45699889210195305, disc_loss = 0.13934939826616613
Trained batch 281 in epoch 1, gen_loss = 0.45706259823860007, disc_loss = 0.1389955239410096
Trained batch 282 in epoch 1, gen_loss = 0.45709060411571195, disc_loss = 0.13881003543365972
Trained batch 283 in epoch 1, gen_loss = 0.4573250029918174, disc_loss = 0.13872473967642013
Trained batch 284 in epoch 1, gen_loss = 0.4572299185552095, disc_loss = 0.13861625837652305
Trained batch 285 in epoch 1, gen_loss = 0.4575615220970207, disc_loss = 0.13848837558831367
Trained batch 286 in epoch 1, gen_loss = 0.45735789736804233, disc_loss = 0.1382521309399854
Trained batch 287 in epoch 1, gen_loss = 0.45730193528450197, disc_loss = 0.13859966666334206
Trained batch 288 in epoch 1, gen_loss = 0.45749513304769784, disc_loss = 0.1395687691893132
Trained batch 289 in epoch 1, gen_loss = 0.45756787215841227, disc_loss = 0.139425027884286
Trained batch 290 in epoch 1, gen_loss = 0.45759499451958435, disc_loss = 0.1392862544846289
Trained batch 291 in epoch 1, gen_loss = 0.4578883626485524, disc_loss = 0.1391102822931254
Trained batch 292 in epoch 1, gen_loss = 0.45783965121763964, disc_loss = 0.13882719296898452
Trained batch 293 in epoch 1, gen_loss = 0.458009917821203, disc_loss = 0.13856030254289
Trained batch 294 in epoch 1, gen_loss = 0.45795667545270113, disc_loss = 0.13839711032934107
Trained batch 295 in epoch 1, gen_loss = 0.4579068542130896, disc_loss = 0.13834977760357228
Trained batch 296 in epoch 1, gen_loss = 0.4580008262134963, disc_loss = 0.13811796435753906
Trained batch 297 in epoch 1, gen_loss = 0.4578640560975811, disc_loss = 0.13806628264586798
Trained batch 298 in epoch 1, gen_loss = 0.45756412539195057, disc_loss = 0.1380075699833524
Trained batch 299 in epoch 1, gen_loss = 0.4578459146618843, disc_loss = 0.1379194945221146
Trained batch 300 in epoch 1, gen_loss = 0.4582606333236758, disc_loss = 0.13796649305180853
Trained batch 301 in epoch 1, gen_loss = 0.4581507372342988, disc_loss = 0.1380423412639771
Trained batch 302 in epoch 1, gen_loss = 0.4581424081482903, disc_loss = 0.13822589722452777
Trained batch 303 in epoch 1, gen_loss = 0.4578412015383181, disc_loss = 0.13817057318642342
Trained batch 304 in epoch 1, gen_loss = 0.4579079798987654, disc_loss = 0.13808484598994256
Trained batch 305 in epoch 1, gen_loss = 0.4576399000057208, disc_loss = 0.13800279088805315
Trained batch 306 in epoch 1, gen_loss = 0.4575697431152729, disc_loss = 0.13793905483443497
Trained batch 307 in epoch 1, gen_loss = 0.45771423243470005, disc_loss = 0.13791001729618807
Trained batch 308 in epoch 1, gen_loss = 0.4578943382767798, disc_loss = 0.13782846205491078
Trained batch 309 in epoch 1, gen_loss = 0.4580169431624874, disc_loss = 0.137503119570113
Trained batch 310 in epoch 1, gen_loss = 0.4580756847498118, disc_loss = 0.13732772532527088
Trained batch 311 in epoch 1, gen_loss = 0.4582812698223652, disc_loss = 0.13715027964029175
Trained batch 312 in epoch 1, gen_loss = 0.4582563461587071, disc_loss = 0.13740881900198923
Trained batch 313 in epoch 1, gen_loss = 0.4584843404353804, disc_loss = 0.13714131572918528
Trained batch 314 in epoch 1, gen_loss = 0.45869267043613254, disc_loss = 0.1370765473871004
Trained batch 315 in epoch 1, gen_loss = 0.4587498939112772, disc_loss = 0.13685204807810392
Trained batch 316 in epoch 1, gen_loss = 0.4586543312960243, disc_loss = 0.13677540358026696
Trained batch 317 in epoch 1, gen_loss = 0.45882748357904785, disc_loss = 0.136512798145882
Trained batch 318 in epoch 1, gen_loss = 0.45888786274811316, disc_loss = 0.13648282626766395
Trained batch 319 in epoch 1, gen_loss = 0.4586612183600664, disc_loss = 0.13634955924935638
Trained batch 320 in epoch 1, gen_loss = 0.4585264527537741, disc_loss = 0.13621717255063517
Trained batch 321 in epoch 1, gen_loss = 0.45882953583083536, disc_loss = 0.13622358154436076
Trained batch 322 in epoch 1, gen_loss = 0.4587472556360735, disc_loss = 0.13586884074997238
Trained batch 323 in epoch 1, gen_loss = 0.4585876961549123, disc_loss = 0.13579054250393385
Trained batch 324 in epoch 1, gen_loss = 0.4586336340354039, disc_loss = 0.1355113544372412
Trained batch 325 in epoch 1, gen_loss = 0.45893716510453836, disc_loss = 0.13548145831728275
Trained batch 326 in epoch 1, gen_loss = 0.4588818337756924, disc_loss = 0.13534017481388302
Trained batch 327 in epoch 1, gen_loss = 0.45896976095874137, disc_loss = 0.1350653141328111
Trained batch 328 in epoch 1, gen_loss = 0.45907220162881546, disc_loss = 0.13489343459211223
Trained batch 329 in epoch 1, gen_loss = 0.4591567394408313, disc_loss = 0.13479890286019355
Trained batch 330 in epoch 1, gen_loss = 0.4590767068265068, disc_loss = 0.1345127317322885
Trained batch 331 in epoch 1, gen_loss = 0.4591580412114959, disc_loss = 0.13425328294151878
Trained batch 332 in epoch 1, gen_loss = 0.45924124390155346, disc_loss = 0.1342055350430198
Trained batch 333 in epoch 1, gen_loss = 0.4595049227961523, disc_loss = 0.13398831499417027
Trained batch 334 in epoch 1, gen_loss = 0.4594076007159788, disc_loss = 0.1340099744053919
Trained batch 335 in epoch 1, gen_loss = 0.4596325395007928, disc_loss = 0.13378182223199733
Trained batch 336 in epoch 1, gen_loss = 0.46003728733572125, disc_loss = 0.13408323261300958
Trained batch 337 in epoch 1, gen_loss = 0.45995289404716716, disc_loss = 0.13423270274769272
Trained batch 338 in epoch 1, gen_loss = 0.45967003421797514, disc_loss = 0.13405188393935694
Trained batch 339 in epoch 1, gen_loss = 0.45959525485249125, disc_loss = 0.13405420007731986
Trained batch 340 in epoch 1, gen_loss = 0.4593058263451473, disc_loss = 0.134262105357175
Trained batch 341 in epoch 1, gen_loss = 0.4592212103089394, disc_loss = 0.13410523890011145
Trained batch 342 in epoch 1, gen_loss = 0.45923933395491395, disc_loss = 0.1340003382338553
Trained batch 343 in epoch 1, gen_loss = 0.4590953884776248, disc_loss = 0.13381406620448066
Trained batch 344 in epoch 1, gen_loss = 0.45904780643573706, disc_loss = 0.13367441602159238
Trained batch 345 in epoch 1, gen_loss = 0.4589743099977515, disc_loss = 0.13343041582905144
Trained batch 346 in epoch 1, gen_loss = 0.4590375523917613, disc_loss = 0.13333389331567871
Trained batch 347 in epoch 1, gen_loss = 0.45890578875939053, disc_loss = 0.13337614362652617
Trained batch 348 in epoch 1, gen_loss = 0.4589090399380058, disc_loss = 0.13328822131100562
Trained batch 349 in epoch 1, gen_loss = 0.4588933839968273, disc_loss = 0.13310726456344127
Trained batch 350 in epoch 1, gen_loss = 0.45922963529230865, disc_loss = 0.13334345958723642
Trained batch 351 in epoch 1, gen_loss = 0.45911738962273707, disc_loss = 0.1333288770190186
Trained batch 352 in epoch 1, gen_loss = 0.45928364240751723, disc_loss = 0.13320621650760978
Trained batch 353 in epoch 1, gen_loss = 0.4593259710713295, disc_loss = 0.13316293973159993
Trained batch 354 in epoch 1, gen_loss = 0.45933258508292724, disc_loss = 0.13303031983299995
Trained batch 355 in epoch 1, gen_loss = 0.45927158810114593, disc_loss = 0.13301776189440756
Trained batch 356 in epoch 1, gen_loss = 0.45924395740199153, disc_loss = 0.1327920530085303
Trained batch 357 in epoch 1, gen_loss = 0.45937984582432156, disc_loss = 0.13268234725396394
Trained batch 358 in epoch 1, gen_loss = 0.45928443872829, disc_loss = 0.13238225050768646
Trained batch 359 in epoch 1, gen_loss = 0.4591264809999201, disc_loss = 0.13218108996645445
Trained batch 360 in epoch 1, gen_loss = 0.4592560142526336, disc_loss = 0.13193363670022368
Trained batch 361 in epoch 1, gen_loss = 0.459290310081856, disc_loss = 0.13179985880954653
Trained batch 362 in epoch 1, gen_loss = 0.45942229024306475, disc_loss = 0.13185811944346948
Trained batch 363 in epoch 1, gen_loss = 0.4593329749755807, disc_loss = 0.13200333057953925
Trained batch 364 in epoch 1, gen_loss = 0.45932271480560305, disc_loss = 0.13187103759854624
Trained batch 365 in epoch 1, gen_loss = 0.45952263083614286, disc_loss = 0.13189957838994068
Trained batch 366 in epoch 1, gen_loss = 0.45947498018150434, disc_loss = 0.13176033922473643
Trained batch 367 in epoch 1, gen_loss = 0.4595121223803448, disc_loss = 0.13178478289172862
Trained batch 368 in epoch 1, gen_loss = 0.45931482888495695, disc_loss = 0.1317527021425284
Trained batch 369 in epoch 1, gen_loss = 0.4595157512941876, disc_loss = 0.13163297243315625
Trained batch 370 in epoch 1, gen_loss = 0.45936501435835086, disc_loss = 0.1315771138541541
Trained batch 371 in epoch 1, gen_loss = 0.4593000419197544, disc_loss = 0.13145527416359512
Trained batch 372 in epoch 1, gen_loss = 0.45928120157673913, disc_loss = 0.13125709772369656
Trained batch 373 in epoch 1, gen_loss = 0.45932922062070614, disc_loss = 0.13102649149788734
Trained batch 374 in epoch 1, gen_loss = 0.4595089994271596, disc_loss = 0.1308884571144978
Trained batch 375 in epoch 1, gen_loss = 0.45936603273483034, disc_loss = 0.13070067196113475
Trained batch 376 in epoch 1, gen_loss = 0.4591375529291775, disc_loss = 0.13062148637555795
Trained batch 377 in epoch 1, gen_loss = 0.45903483395854, disc_loss = 0.13052700364853811
Trained batch 378 in epoch 1, gen_loss = 0.4591767923183995, disc_loss = 0.13076841547633067
Trained batch 379 in epoch 1, gen_loss = 0.4591945812890404, disc_loss = 0.1306076894024093
Trained batch 380 in epoch 1, gen_loss = 0.4592027289504454, disc_loss = 0.13045037991007952
Trained batch 381 in epoch 1, gen_loss = 0.4590019796687271, disc_loss = 0.13052789240353863
Trained batch 382 in epoch 1, gen_loss = 0.45900920227987024, disc_loss = 0.13043381442503113
Trained batch 383 in epoch 1, gen_loss = 0.45881404510388774, disc_loss = 0.13042854798550252
Trained batch 384 in epoch 1, gen_loss = 0.4588746261287045, disc_loss = 0.13032021808450098
Trained batch 385 in epoch 1, gen_loss = 0.4588755708901993, disc_loss = 0.13025046085427308
Trained batch 386 in epoch 1, gen_loss = 0.4588199140027512, disc_loss = 0.13005027422821028
Trained batch 387 in epoch 1, gen_loss = 0.4588399497196846, disc_loss = 0.1299567304542
Trained batch 388 in epoch 1, gen_loss = 0.4588333179834263, disc_loss = 0.12992513198453387
Trained batch 389 in epoch 1, gen_loss = 0.4586652382826194, disc_loss = 0.12996624822322375
Trained batch 390 in epoch 1, gen_loss = 0.4588601003827341, disc_loss = 0.12998846950261947
Trained batch 391 in epoch 1, gen_loss = 0.45865749841441916, disc_loss = 0.12990530308012907
Trained batch 392 in epoch 1, gen_loss = 0.4585565335422982, disc_loss = 0.12978837661369308
Trained batch 393 in epoch 1, gen_loss = 0.4586374078910363, disc_loss = 0.1296018298365516
Trained batch 394 in epoch 1, gen_loss = 0.45894302401361586, disc_loss = 0.1299298426631508
Trained batch 395 in epoch 1, gen_loss = 0.45891364475693364, disc_loss = 0.12996667851646893
Trained batch 396 in epoch 1, gen_loss = 0.4588441639312869, disc_loss = 0.12994106758095006
Trained batch 397 in epoch 1, gen_loss = 0.4589439842419409, disc_loss = 0.13030079503698117
Trained batch 398 in epoch 1, gen_loss = 0.4587170792402779, disc_loss = 0.13039989745650524
Trained batch 399 in epoch 1, gen_loss = 0.45874733574688437, disc_loss = 0.13055063942912967
Trained batch 400 in epoch 1, gen_loss = 0.45872823258587847, disc_loss = 0.1304953709439818
Trained batch 401 in epoch 1, gen_loss = 0.45860492612295484, disc_loss = 0.13069431938286594
Trained batch 402 in epoch 1, gen_loss = 0.45862518557839593, disc_loss = 0.1306531295855125
Trained batch 403 in epoch 1, gen_loss = 0.4585839461277027, disc_loss = 0.13050188711097482
Trained batch 404 in epoch 1, gen_loss = 0.45873674301453576, disc_loss = 0.13034402647596083
Trained batch 405 in epoch 1, gen_loss = 0.4584923377031176, disc_loss = 0.130202755446688
Trained batch 406 in epoch 1, gen_loss = 0.45848619989153794, disc_loss = 0.13004042942726787
Trained batch 407 in epoch 1, gen_loss = 0.4584204929278177, disc_loss = 0.12985359868673862
Trained batch 408 in epoch 1, gen_loss = 0.45846635977621475, disc_loss = 0.12975407397706964
Trained batch 409 in epoch 1, gen_loss = 0.4585437986182003, disc_loss = 0.12947514366994545
Trained batch 410 in epoch 1, gen_loss = 0.4585548474695851, disc_loss = 0.12946312355190298
Trained batch 411 in epoch 1, gen_loss = 0.4586488850487089, disc_loss = 0.12928220810531413
Trained batch 412 in epoch 1, gen_loss = 0.45870311468045877, disc_loss = 0.12905198789357272
Trained batch 413 in epoch 1, gen_loss = 0.45860922199804427, disc_loss = 0.1288543284515252
Trained batch 414 in epoch 1, gen_loss = 0.45880561930587493, disc_loss = 0.12865595472864358
Trained batch 415 in epoch 1, gen_loss = 0.45866339488957936, disc_loss = 0.12850613376268974
Trained batch 416 in epoch 1, gen_loss = 0.45855575163873263, disc_loss = 0.12842604653726664
Trained batch 417 in epoch 1, gen_loss = 0.45859824463226007, disc_loss = 0.1282534368300552
Trained batch 418 in epoch 1, gen_loss = 0.4585091815216729, disc_loss = 0.128588376295595
Trained batch 419 in epoch 1, gen_loss = 0.4584847345948219, disc_loss = 0.12863622165861585
Trained batch 420 in epoch 1, gen_loss = 0.45851890923291655, disc_loss = 0.12858787927590754
Trained batch 421 in epoch 1, gen_loss = 0.458680317088326, disc_loss = 0.12860711446799938
Trained batch 422 in epoch 1, gen_loss = 0.4585506649727517, disc_loss = 0.12846312460535808
Trained batch 423 in epoch 1, gen_loss = 0.45858086715891677, disc_loss = 0.12826606390540893
Trained batch 424 in epoch 1, gen_loss = 0.4585168987863204, disc_loss = 0.128146209629143
Trained batch 425 in epoch 1, gen_loss = 0.4587947668184137, disc_loss = 0.12797346245934707
Trained batch 426 in epoch 1, gen_loss = 0.4590016891721819, disc_loss = 0.1278964191744981
Trained batch 427 in epoch 1, gen_loss = 0.4589578577569712, disc_loss = 0.12766608159345028
Trained batch 428 in epoch 1, gen_loss = 0.4589623055813752, disc_loss = 0.12757452357221732
Trained batch 429 in epoch 1, gen_loss = 0.4590454972760622, disc_loss = 0.12738865714866754
Trained batch 430 in epoch 1, gen_loss = 0.4591133538503934, disc_loss = 0.12722162470619114
Trained batch 431 in epoch 1, gen_loss = 0.4589994771888963, disc_loss = 0.1273043615165753
Trained batch 432 in epoch 1, gen_loss = 0.45905519626157115, disc_loss = 0.12734834389120134
Trained batch 433 in epoch 1, gen_loss = 0.45906300183540116, disc_loss = 0.12717596674552573
Trained batch 434 in epoch 1, gen_loss = 0.45933908313170246, disc_loss = 0.1270040173426099
Trained batch 435 in epoch 1, gen_loss = 0.4594387136604808, disc_loss = 0.1269317619425646
Trained batch 436 in epoch 1, gen_loss = 0.4595784260561046, disc_loss = 0.1267132532465308
Trained batch 437 in epoch 1, gen_loss = 0.45981798004614166, disc_loss = 0.12652173830136726
Trained batch 438 in epoch 1, gen_loss = 0.45965145728582674, disc_loss = 0.12650647421276243
Trained batch 439 in epoch 1, gen_loss = 0.45969666235826234, disc_loss = 0.12644906624389643
Trained batch 440 in epoch 1, gen_loss = 0.4598324779345065, disc_loss = 0.126419205628251
Trained batch 441 in epoch 1, gen_loss = 0.45998777988539563, disc_loss = 0.12635493364050243
Trained batch 442 in epoch 1, gen_loss = 0.4600341204999532, disc_loss = 0.1261795059006249
Trained batch 443 in epoch 1, gen_loss = 0.45993299144613853, disc_loss = 0.126121081911061
Trained batch 444 in epoch 1, gen_loss = 0.45992029215512653, disc_loss = 0.12592393710288438
Trained batch 445 in epoch 1, gen_loss = 0.459955272519535, disc_loss = 0.12574515250749518
Trained batch 446 in epoch 1, gen_loss = 0.4600335731602355, disc_loss = 0.1256031257452514
Trained batch 447 in epoch 1, gen_loss = 0.4600472196803561, disc_loss = 0.12567261398154578
Trained batch 448 in epoch 1, gen_loss = 0.4600064305128127, disc_loss = 0.12548157250413253
Trained batch 449 in epoch 1, gen_loss = 0.46024583094649846, disc_loss = 0.1253503037782179
Trained batch 450 in epoch 1, gen_loss = 0.46016600047405437, disc_loss = 0.12519618350508604
Trained batch 451 in epoch 1, gen_loss = 0.46035897362548694, disc_loss = 0.12510411202726243
Trained batch 452 in epoch 1, gen_loss = 0.4603971998159985, disc_loss = 0.1248840092420249
Trained batch 453 in epoch 1, gen_loss = 0.4604461229188852, disc_loss = 0.12467286677103867
Trained batch 454 in epoch 1, gen_loss = 0.46058659992375217, disc_loss = 0.12483357198045149
Trained batch 455 in epoch 1, gen_loss = 0.460557537643533, disc_loss = 0.1251695610362252
Trained batch 456 in epoch 1, gen_loss = 0.4605584868456133, disc_loss = 0.12505460498320586
Trained batch 457 in epoch 1, gen_loss = 0.4606457792515317, disc_loss = 0.12515421343894115
Trained batch 458 in epoch 1, gen_loss = 0.46050508323578015, disc_loss = 0.1249853764053978
Trained batch 459 in epoch 1, gen_loss = 0.4603242130383201, disc_loss = 0.12524276712261465
Trained batch 460 in epoch 1, gen_loss = 0.46029838945498436, disc_loss = 0.12513032335375887
Trained batch 461 in epoch 1, gen_loss = 0.46039533079702616, disc_loss = 0.12500202865037438
Trained batch 462 in epoch 1, gen_loss = 0.46015941311422226, disc_loss = 0.1250713721167127
Trained batch 463 in epoch 1, gen_loss = 0.4602295655500272, disc_loss = 0.12500485859345645
Trained batch 464 in epoch 1, gen_loss = 0.460238794806183, disc_loss = 0.12486996342658356
Trained batch 465 in epoch 1, gen_loss = 0.46013503492901764, disc_loss = 0.12486283858046895
Trained batch 466 in epoch 1, gen_loss = 0.460241088456209, disc_loss = 0.12479230161253722
Trained batch 467 in epoch 1, gen_loss = 0.4601940545134055, disc_loss = 0.12468863870455031
Trained batch 468 in epoch 1, gen_loss = 0.4602469258598173, disc_loss = 0.12461215632159446
Trained batch 469 in epoch 1, gen_loss = 0.4604027482423377, disc_loss = 0.12456522864150874
Trained batch 470 in epoch 1, gen_loss = 0.4604076491925873, disc_loss = 0.12460697084396381
Trained batch 471 in epoch 1, gen_loss = 0.46046762976606015, disc_loss = 0.12457604233917417
Trained batch 472 in epoch 1, gen_loss = 0.4604134840642675, disc_loss = 0.12453837000841696
Trained batch 473 in epoch 1, gen_loss = 0.46026042694783914, disc_loss = 0.12484573699801155
Trained batch 474 in epoch 1, gen_loss = 0.4604376627269544, disc_loss = 0.12477687115339857
Trained batch 475 in epoch 1, gen_loss = 0.46029643294941475, disc_loss = 0.12467169822311076
Trained batch 476 in epoch 1, gen_loss = 0.4603377681233348, disc_loss = 0.12460997772151194
Trained batch 477 in epoch 1, gen_loss = 0.460181202910934, disc_loss = 0.12444914468645925
Trained batch 478 in epoch 1, gen_loss = 0.459874084635418, disc_loss = 0.12446913623595163
Trained batch 479 in epoch 1, gen_loss = 0.459996815957129, disc_loss = 0.12460566913941876
Trained batch 480 in epoch 1, gen_loss = 0.45990745899830937, disc_loss = 0.12451673067889317
Trained batch 481 in epoch 1, gen_loss = 0.4598203175295438, disc_loss = 0.12448267298228884
Trained batch 482 in epoch 1, gen_loss = 0.45968853847333857, disc_loss = 0.12443499007565018
Trained batch 483 in epoch 1, gen_loss = 0.45976491143141895, disc_loss = 0.12428503604759732
Trained batch 484 in epoch 1, gen_loss = 0.4596899958615451, disc_loss = 0.12425753573704626
Trained batch 485 in epoch 1, gen_loss = 0.4596714974062924, disc_loss = 0.12411828446796033
Trained batch 486 in epoch 1, gen_loss = 0.4595776360627317, disc_loss = 0.12390789689086913
Trained batch 487 in epoch 1, gen_loss = 0.4594594704323128, disc_loss = 0.12376726621410764
Trained batch 488 in epoch 1, gen_loss = 0.459557404791163, disc_loss = 0.12361040540374739
Trained batch 489 in epoch 1, gen_loss = 0.45949370563030245, disc_loss = 0.12339882386506212
Trained batch 490 in epoch 1, gen_loss = 0.4594857139767066, disc_loss = 0.12328880862569978
Trained batch 491 in epoch 1, gen_loss = 0.45960331356864637, disc_loss = 0.12313937502193863
Trained batch 492 in epoch 1, gen_loss = 0.4597598809378626, disc_loss = 0.12295387149930122
Trained batch 493 in epoch 1, gen_loss = 0.45978624871385243, disc_loss = 0.12278052217700341
Trained batch 494 in epoch 1, gen_loss = 0.4595807120053455, disc_loss = 0.12262932840697091
Trained batch 495 in epoch 1, gen_loss = 0.45953448158839055, disc_loss = 0.12251010666706509
Trained batch 496 in epoch 1, gen_loss = 0.45977516559288056, disc_loss = 0.12257020241792653
Trained batch 497 in epoch 1, gen_loss = 0.4598435462718029, disc_loss = 0.12235343680309364
Trained batch 498 in epoch 1, gen_loss = 0.45980337172567487, disc_loss = 0.12216269486548308
Trained batch 499 in epoch 1, gen_loss = 0.4598716452717781, disc_loss = 0.12194453846849501
Trained batch 500 in epoch 1, gen_loss = 0.4599252961233942, disc_loss = 0.12179548663836337
Trained batch 501 in epoch 1, gen_loss = 0.4599930863100219, disc_loss = 0.12161618910648256
Trained batch 502 in epoch 1, gen_loss = 0.45996507652711205, disc_loss = 0.1213948256123226
Trained batch 503 in epoch 1, gen_loss = 0.46003288757942973, disc_loss = 0.12121515230105687
Trained batch 504 in epoch 1, gen_loss = 0.45997978649517096, disc_loss = 0.1211207245522649
Trained batch 505 in epoch 1, gen_loss = 0.45992470841869537, disc_loss = 0.1209943757296757
Trained batch 506 in epoch 1, gen_loss = 0.46010780222787423, disc_loss = 0.1210255928951108
Trained batch 507 in epoch 1, gen_loss = 0.45996416172408683, disc_loss = 0.12130086139893144
Trained batch 508 in epoch 1, gen_loss = 0.4601121247985742, disc_loss = 0.12123605381873069
Trained batch 509 in epoch 1, gen_loss = 0.4600064716502732, disc_loss = 0.12115816885751544
Trained batch 510 in epoch 1, gen_loss = 0.4599911333763436, disc_loss = 0.12110327809516873
Trained batch 511 in epoch 1, gen_loss = 0.4601491221692413, disc_loss = 0.12125423170618888
Trained batch 512 in epoch 1, gen_loss = 0.4600445166317343, disc_loss = 0.12139206359137511
Trained batch 513 in epoch 1, gen_loss = 0.460080481340913, disc_loss = 0.12131995558267611
Trained batch 514 in epoch 1, gen_loss = 0.4601534404800934, disc_loss = 0.12163651410345604
Trained batch 515 in epoch 1, gen_loss = 0.46005825184343396, disc_loss = 0.12161050367082447
Trained batch 516 in epoch 1, gen_loss = 0.46002266202950615, disc_loss = 0.12176407766807644
Trained batch 517 in epoch 1, gen_loss = 0.46000708938795626, disc_loss = 0.121570058790859
Trained batch 518 in epoch 1, gen_loss = 0.459976417710556, disc_loss = 0.12141169990037849
Trained batch 519 in epoch 1, gen_loss = 0.45979787202981803, disc_loss = 0.12135965598281473
Trained batch 520 in epoch 1, gen_loss = 0.45965003383823183, disc_loss = 0.12124850858903835
Trained batch 521 in epoch 1, gen_loss = 0.45969777271665374, disc_loss = 0.12110533849853608
Trained batch 522 in epoch 1, gen_loss = 0.459652304364436, disc_loss = 0.12100038729273281
Trained batch 523 in epoch 1, gen_loss = 0.4596566911075861, disc_loss = 0.12093517658272261
Trained batch 524 in epoch 1, gen_loss = 0.4596208052408128, disc_loss = 0.12080471513349386
Trained batch 525 in epoch 1, gen_loss = 0.4596814648620076, disc_loss = 0.12066453683788503
Trained batch 526 in epoch 1, gen_loss = 0.45962741659986, disc_loss = 0.12051122479911265
Trained batch 527 in epoch 1, gen_loss = 0.4595278784858458, disc_loss = 0.12046241530069066
Trained batch 528 in epoch 1, gen_loss = 0.45949693748090126, disc_loss = 0.12043914477567987
Trained batch 529 in epoch 1, gen_loss = 0.459508952217282, disc_loss = 0.12094871516884216
Trained batch 530 in epoch 1, gen_loss = 0.4594848251387673, disc_loss = 0.12086664048846102
Trained batch 531 in epoch 1, gen_loss = 0.45948243510902376, disc_loss = 0.1208173734419524
Trained batch 532 in epoch 1, gen_loss = 0.45942440673736873, disc_loss = 0.12071236745606388
Trained batch 533 in epoch 1, gen_loss = 0.4593274084927884, disc_loss = 0.12072626229075624
Trained batch 534 in epoch 1, gen_loss = 0.4591942625625111, disc_loss = 0.1206612991517253
Trained batch 535 in epoch 1, gen_loss = 0.45916734791513697, disc_loss = 0.1208682438174485
Trained batch 536 in epoch 1, gen_loss = 0.4590888275336509, disc_loss = 0.1210521331778424
Trained batch 537 in epoch 1, gen_loss = 0.45913751384582663, disc_loss = 0.12092027238996
Trained batch 538 in epoch 1, gen_loss = 0.45927325549063747, disc_loss = 0.12090898002973016
Trained batch 539 in epoch 1, gen_loss = 0.4591680661947639, disc_loss = 0.12081042886021788
Trained batch 540 in epoch 1, gen_loss = 0.4590915339601238, disc_loss = 0.12074954247759748
Trained batch 541 in epoch 1, gen_loss = 0.4590938820940102, disc_loss = 0.12065058486618624
Trained batch 542 in epoch 1, gen_loss = 0.45902144189917143, disc_loss = 0.1205403253309168
Trained batch 543 in epoch 1, gen_loss = 0.4588336435091846, disc_loss = 0.12053051813991796
Trained batch 544 in epoch 1, gen_loss = 0.4587764496103339, disc_loss = 0.12051686358663741
Trained batch 545 in epoch 1, gen_loss = 0.4587976814080507, disc_loss = 0.12039633374831779
Trained batch 546 in epoch 1, gen_loss = 0.4587856435252718, disc_loss = 0.12023526250846153
Trained batch 547 in epoch 1, gen_loss = 0.4587768284182479, disc_loss = 0.1201361495998083
Trained batch 548 in epoch 1, gen_loss = 0.4587818027519789, disc_loss = 0.12022311088946293
Trained batch 549 in epoch 1, gen_loss = 0.45878505051136015, disc_loss = 0.12004755080254241
Trained batch 550 in epoch 1, gen_loss = 0.45893240878240166, disc_loss = 0.11999538686031817
Trained batch 551 in epoch 1, gen_loss = 0.45891049747233803, disc_loss = 0.11981964369635165
Trained batch 552 in epoch 1, gen_loss = 0.45890245633789256, disc_loss = 0.11968361666328384
Trained batch 553 in epoch 1, gen_loss = 0.4587968584647678, disc_loss = 0.11951226147147238
Trained batch 554 in epoch 1, gen_loss = 0.4589888641426155, disc_loss = 0.11954521400400915
Trained batch 555 in epoch 1, gen_loss = 0.4590984468194221, disc_loss = 0.11937598010572009
Trained batch 556 in epoch 1, gen_loss = 0.458980347192052, disc_loss = 0.11938972477057089
Trained batch 557 in epoch 1, gen_loss = 0.4589771111913052, disc_loss = 0.11929363963164148
Trained batch 558 in epoch 1, gen_loss = 0.4591727725401761, disc_loss = 0.1195462564146396
Trained batch 559 in epoch 1, gen_loss = 0.45911865676087993, disc_loss = 0.11944152365072763
Trained batch 560 in epoch 1, gen_loss = 0.45907787311948345, disc_loss = 0.11941568109367887
Trained batch 561 in epoch 1, gen_loss = 0.45916839617427135, disc_loss = 0.11944190115299991
Trained batch 562 in epoch 1, gen_loss = 0.4590749293301076, disc_loss = 0.1193079502531865
Trained batch 563 in epoch 1, gen_loss = 0.45915123910134564, disc_loss = 0.11928517710424114
Trained batch 564 in epoch 1, gen_loss = 0.45926475878310413, disc_loss = 0.11922753202209695
Trained batch 565 in epoch 1, gen_loss = 0.4593164683336083, disc_loss = 0.11918120316061925
Trained batch 566 in epoch 1, gen_loss = 0.45922004035961483, disc_loss = 0.1190764439198627
Trained batch 567 in epoch 1, gen_loss = 0.4592698940508802, disc_loss = 0.1189297253190553
Trained batch 568 in epoch 1, gen_loss = 0.45942621616571355, disc_loss = 0.1187503838859276
Trained batch 569 in epoch 1, gen_loss = 0.4595535375569996, disc_loss = 0.11865327710024359
Trained batch 570 in epoch 1, gen_loss = 0.4596620208327699, disc_loss = 0.11847231862821898
Trained batch 571 in epoch 1, gen_loss = 0.459491303802787, disc_loss = 0.11876887281855139
Trained batch 572 in epoch 1, gen_loss = 0.45952202169058837, disc_loss = 0.11868242293524753
Trained batch 573 in epoch 1, gen_loss = 0.4596303319266449, disc_loss = 0.11915819347716011
Trained batch 574 in epoch 1, gen_loss = 0.4596887291514355, disc_loss = 0.11928038354315187
Trained batch 575 in epoch 1, gen_loss = 0.4596161348227825, disc_loss = 0.11963195437339083
Trained batch 576 in epoch 1, gen_loss = 0.45958757586454396, disc_loss = 0.11953831734732956
Trained batch 577 in epoch 1, gen_loss = 0.4596201432514356, disc_loss = 0.11955585615116471
Trained batch 578 in epoch 1, gen_loss = 0.4597023549989921, disc_loss = 0.1194257421792197
Trained batch 579 in epoch 1, gen_loss = 0.45972213298082354, disc_loss = 0.11936018118345788
Trained batch 580 in epoch 1, gen_loss = 0.4596972064902163, disc_loss = 0.11932404924876565
Trained batch 581 in epoch 1, gen_loss = 0.4597357033249439, disc_loss = 0.11922476020932864
Trained batch 582 in epoch 1, gen_loss = 0.459706260348266, disc_loss = 0.11919358871257377
Trained batch 583 in epoch 1, gen_loss = 0.45973896648581714, disc_loss = 0.11918333711338625
Trained batch 584 in epoch 1, gen_loss = 0.45963550087733146, disc_loss = 0.11909174249372166
Trained batch 585 in epoch 1, gen_loss = 0.4597822820875832, disc_loss = 0.11898930433266654
Trained batch 586 in epoch 1, gen_loss = 0.4597648835568046, disc_loss = 0.11902037728895168
Trained batch 587 in epoch 1, gen_loss = 0.45977761616714957, disc_loss = 0.11890525026975492
Trained batch 588 in epoch 1, gen_loss = 0.4597012888393499, disc_loss = 0.11874669147829299
Trained batch 589 in epoch 1, gen_loss = 0.4596435700432729, disc_loss = 0.11865248748464352
Trained batch 590 in epoch 1, gen_loss = 0.45965773205063265, disc_loss = 0.11856804427717593
Trained batch 591 in epoch 1, gen_loss = 0.4596715143101441, disc_loss = 0.11843303678639082
Trained batch 592 in epoch 1, gen_loss = 0.4595886640263247, disc_loss = 0.11827474196314258
Trained batch 593 in epoch 1, gen_loss = 0.4594680660401129, disc_loss = 0.11817182078236331
Trained batch 594 in epoch 1, gen_loss = 0.45956171295222115, disc_loss = 0.11813164049869075
Trained batch 595 in epoch 1, gen_loss = 0.4595463789449442, disc_loss = 0.11810675811728825
Trained batch 596 in epoch 1, gen_loss = 0.45953573618502275, disc_loss = 0.1179918448582691
Trained batch 597 in epoch 1, gen_loss = 0.4596696836394211, disc_loss = 0.1180823681748357
Trained batch 598 in epoch 1, gen_loss = 0.45962588765187334, disc_loss = 0.11798076454288822
Trained batch 599 in epoch 1, gen_loss = 0.4597221967577934, disc_loss = 0.11803870939494421
Trained batch 600 in epoch 1, gen_loss = 0.45964987871055796, disc_loss = 0.1179442884363296
Trained batch 601 in epoch 1, gen_loss = 0.45960740007435363, disc_loss = 0.11799653111013314
Trained batch 602 in epoch 1, gen_loss = 0.4597097160804331, disc_loss = 0.11802843315789405
Trained batch 603 in epoch 1, gen_loss = 0.4597843358453536, disc_loss = 0.11789547277164232
Trained batch 604 in epoch 1, gen_loss = 0.4599278890396938, disc_loss = 0.11790355139927677
Trained batch 605 in epoch 1, gen_loss = 0.4599678618187952, disc_loss = 0.11778442090893589
Trained batch 606 in epoch 1, gen_loss = 0.45992190868300703, disc_loss = 0.11789847796405413
Trained batch 607 in epoch 1, gen_loss = 0.4598775016339986, disc_loss = 0.11786212639938305
Trained batch 608 in epoch 1, gen_loss = 0.4597775126717165, disc_loss = 0.11776482289556066
Trained batch 609 in epoch 1, gen_loss = 0.4600798756372733, disc_loss = 0.11784686254581711
Trained batch 610 in epoch 1, gen_loss = 0.4600363220598811, disc_loss = 0.11770235927723677
Trained batch 611 in epoch 1, gen_loss = 0.46003029782787647, disc_loss = 0.11764153637436334
Trained batch 612 in epoch 1, gen_loss = 0.4601962416634863, disc_loss = 0.1176029370101032
Trained batch 613 in epoch 1, gen_loss = 0.46014572573212925, disc_loss = 0.11752294546527127
Trained batch 614 in epoch 1, gen_loss = 0.4601580332934372, disc_loss = 0.11742975064439745
Trained batch 615 in epoch 1, gen_loss = 0.46020070158622484, disc_loss = 0.11734892960861568
Trained batch 616 in epoch 1, gen_loss = 0.4602036649539366, disc_loss = 0.11727999028337688
Trained batch 617 in epoch 1, gen_loss = 0.46030406875710655, disc_loss = 0.1172357181156458
Trained batch 618 in epoch 1, gen_loss = 0.4601054880075963, disc_loss = 0.11718992563491154
Trained batch 619 in epoch 1, gen_loss = 0.4601528090334708, disc_loss = 0.11703312318141182
Trained batch 620 in epoch 1, gen_loss = 0.4600922038205772, disc_loss = 0.1169580686012592
Trained batch 621 in epoch 1, gen_loss = 0.46009054952495737, disc_loss = 0.11693918716216346
Trained batch 622 in epoch 1, gen_loss = 0.4601898547351647, disc_loss = 0.11685516202544276
Trained batch 623 in epoch 1, gen_loss = 0.4600816495621052, disc_loss = 0.11687470135989432
Trained batch 624 in epoch 1, gen_loss = 0.4601923907756805, disc_loss = 0.11688082560747862
Trained batch 625 in epoch 1, gen_loss = 0.46028510016945606, disc_loss = 0.1169475743490548
Trained batch 626 in epoch 1, gen_loss = 0.4601642480877598, disc_loss = 0.11680170597339218
Trained batch 627 in epoch 1, gen_loss = 0.4602274066608423, disc_loss = 0.11676417341734621
Trained batch 628 in epoch 1, gen_loss = 0.46027443504674637, disc_loss = 0.11676267677376162
Trained batch 629 in epoch 1, gen_loss = 0.46028573456264676, disc_loss = 0.11662761814567069
Trained batch 630 in epoch 1, gen_loss = 0.4603156848868175, disc_loss = 0.11664217865912217
Trained batch 631 in epoch 1, gen_loss = 0.46019609423377844, disc_loss = 0.11694424268878006
Trained batch 632 in epoch 1, gen_loss = 0.4602344355782815, disc_loss = 0.11691977685879427
Trained batch 633 in epoch 1, gen_loss = 0.4602742346021279, disc_loss = 0.11703330064074897
Trained batch 634 in epoch 1, gen_loss = 0.4601786860800165, disc_loss = 0.11714344495892759
Trained batch 635 in epoch 1, gen_loss = 0.460121621219617, disc_loss = 0.11705395299501999
Trained batch 636 in epoch 1, gen_loss = 0.46018358124668596, disc_loss = 0.11698415640484267
Trained batch 637 in epoch 1, gen_loss = 0.4603118157498889, disc_loss = 0.11696045817865706
Trained batch 638 in epoch 1, gen_loss = 0.46027476229764674, disc_loss = 0.11684812165954163
Trained batch 639 in epoch 1, gen_loss = 0.46024315487593415, disc_loss = 0.11678090394852916
Trained batch 640 in epoch 1, gen_loss = 0.4602093002911477, disc_loss = 0.11664305223869785
Trained batch 641 in epoch 1, gen_loss = 0.4604096908435643, disc_loss = 0.11653363689449485
Trained batch 642 in epoch 1, gen_loss = 0.460587307416818, disc_loss = 0.11640730606678809
Trained batch 643 in epoch 1, gen_loss = 0.46069222966336315, disc_loss = 0.1162767919309738
Trained batch 644 in epoch 1, gen_loss = 0.4607320847899415, disc_loss = 0.11625136769874844
Trained batch 645 in epoch 1, gen_loss = 0.4606422111161353, disc_loss = 0.11612823554646258
Trained batch 646 in epoch 1, gen_loss = 0.46054365134681396, disc_loss = 0.11602282150860133
Trained batch 647 in epoch 1, gen_loss = 0.4606101974201055, disc_loss = 0.11599951985803789
Trained batch 648 in epoch 1, gen_loss = 0.4605495632613201, disc_loss = 0.11589771635882062
Trained batch 649 in epoch 1, gen_loss = 0.460496953359017, disc_loss = 0.11574165710176412
Trained batch 650 in epoch 1, gen_loss = 0.4604997239812362, disc_loss = 0.11603097069705229
Trained batch 651 in epoch 1, gen_loss = 0.4604445206332792, disc_loss = 0.11615307852225892
Trained batch 652 in epoch 1, gen_loss = 0.46041737567593455, disc_loss = 0.11606935424527658
Trained batch 653 in epoch 1, gen_loss = 0.4605635280182602, disc_loss = 0.11603306368597148
Trained batch 654 in epoch 1, gen_loss = 0.4606061944979748, disc_loss = 0.11595585920940374
Trained batch 655 in epoch 1, gen_loss = 0.460516641688783, disc_loss = 0.11585490216739566
Trained batch 656 in epoch 1, gen_loss = 0.4605255817804525, disc_loss = 0.11582678016360219
Trained batch 657 in epoch 1, gen_loss = 0.46047483189852406, disc_loss = 0.11573157755312677
Trained batch 658 in epoch 1, gen_loss = 0.46061720987372046, disc_loss = 0.11568688263491994
Trained batch 659 in epoch 1, gen_loss = 0.4606442148035223, disc_loss = 0.11554787136952985
Trained batch 660 in epoch 1, gen_loss = 0.46058539070087556, disc_loss = 0.11554193266198241
Trained batch 661 in epoch 1, gen_loss = 0.460566485711455, disc_loss = 0.11558248169630135
Trained batch 662 in epoch 1, gen_loss = 0.46076824487963775, disc_loss = 0.11564621638905588
Trained batch 663 in epoch 1, gen_loss = 0.4607308941882059, disc_loss = 0.11561134755499212
Trained batch 664 in epoch 1, gen_loss = 0.460697912497628, disc_loss = 0.11550089518042435
Trained batch 665 in epoch 1, gen_loss = 0.46070256699491907, disc_loss = 0.11540004335813694
Trained batch 666 in epoch 1, gen_loss = 0.46071392275404177, disc_loss = 0.11527070978648034
Trained batch 667 in epoch 1, gen_loss = 0.4607264126935405, disc_loss = 0.11531642816882737
Trained batch 668 in epoch 1, gen_loss = 0.4606867858469041, disc_loss = 0.115313583372442
Trained batch 669 in epoch 1, gen_loss = 0.46062558030904227, disc_loss = 0.11520943425095348
Trained batch 670 in epoch 1, gen_loss = 0.46051366287443213, disc_loss = 0.11511043792010331
Trained batch 671 in epoch 1, gen_loss = 0.4603370160662702, disc_loss = 0.11499732488577831
Trained batch 672 in epoch 1, gen_loss = 0.4603379808953046, disc_loss = 0.11491904316129603
Trained batch 673 in epoch 1, gen_loss = 0.4604772124163121, disc_loss = 0.11486965229110212
Trained batch 674 in epoch 1, gen_loss = 0.46054593165715535, disc_loss = 0.11479437439805931
Trained batch 675 in epoch 1, gen_loss = 0.4605341898442725, disc_loss = 0.1146459770430232
Trained batch 676 in epoch 1, gen_loss = 0.4604771104661894, disc_loss = 0.11453472454364974
Trained batch 677 in epoch 1, gen_loss = 0.4604573529818065, disc_loss = 0.114432208274373
Trained batch 678 in epoch 1, gen_loss = 0.46046707749542326, disc_loss = 0.1145303986201252
Trained batch 679 in epoch 1, gen_loss = 0.46047022482928107, disc_loss = 0.11463692215791739
Trained batch 680 in epoch 1, gen_loss = 0.46042335339754864, disc_loss = 0.11451145029174117
Trained batch 681 in epoch 1, gen_loss = 0.4604779213579519, disc_loss = 0.11449395970760946
Trained batch 682 in epoch 1, gen_loss = 0.4603556172041383, disc_loss = 0.11451403696995398
Trained batch 683 in epoch 1, gen_loss = 0.46033260897237654, disc_loss = 0.1144430362279064
Trained batch 684 in epoch 1, gen_loss = 0.4603848170189962, disc_loss = 0.11441532898367975
Trained batch 685 in epoch 1, gen_loss = 0.46029590469928944, disc_loss = 0.114310100257842
Trained batch 686 in epoch 1, gen_loss = 0.460543837045825, disc_loss = 0.1144675234999654
Trained batch 687 in epoch 1, gen_loss = 0.4606019975400941, disc_loss = 0.11437309150676091
Trained batch 688 in epoch 1, gen_loss = 0.46065778721053646, disc_loss = 0.1144068682598726
Trained batch 689 in epoch 1, gen_loss = 0.46067302650299624, disc_loss = 0.11430541460091868
Trained batch 690 in epoch 1, gen_loss = 0.46074257064314206, disc_loss = 0.11420899698734499
Trained batch 691 in epoch 1, gen_loss = 0.46067323044717656, disc_loss = 0.11415780917203021
Trained batch 692 in epoch 1, gen_loss = 0.46065933914239615, disc_loss = 0.11424354634894136
Trained batch 693 in epoch 1, gen_loss = 0.46059148649145615, disc_loss = 0.11414605911193088
Trained batch 694 in epoch 1, gen_loss = 0.46055120898665286, disc_loss = 0.11414353624120248
Trained batch 695 in epoch 1, gen_loss = 0.4605378606196108, disc_loss = 0.1140887303152068
Trained batch 696 in epoch 1, gen_loss = 0.460517984637229, disc_loss = 0.11400221752262056
Trained batch 697 in epoch 1, gen_loss = 0.46052337273485683, disc_loss = 0.11392085559607448
Trained batch 698 in epoch 1, gen_loss = 0.46058128320096386, disc_loss = 0.11386019540537623
Trained batch 699 in epoch 1, gen_loss = 0.46054129804883687, disc_loss = 0.11389601942817015
Trained batch 700 in epoch 1, gen_loss = 0.46050713231492146, disc_loss = 0.11377654345400535
Trained batch 701 in epoch 1, gen_loss = 0.4605552337617956, disc_loss = 0.11369877194646119
Trained batch 702 in epoch 1, gen_loss = 0.46062601706381373, disc_loss = 0.11369783335509756
Trained batch 703 in epoch 1, gen_loss = 0.46057393799789925, disc_loss = 0.11367283677497074
Trained batch 704 in epoch 1, gen_loss = 0.4606505480218441, disc_loss = 0.11355428437154133
Trained batch 705 in epoch 1, gen_loss = 0.4605952745709811, disc_loss = 0.11351591199187946
Trained batch 706 in epoch 1, gen_loss = 0.46056390976298817, disc_loss = 0.11343666485772907
Trained batch 707 in epoch 1, gen_loss = 0.46057028870629724, disc_loss = 0.11341825155357141
Trained batch 708 in epoch 1, gen_loss = 0.46058625722637636, disc_loss = 0.11335522313017729
Trained batch 709 in epoch 1, gen_loss = 0.46056559874977865, disc_loss = 0.11327799098880988
Trained batch 710 in epoch 1, gen_loss = 0.46054674075122626, disc_loss = 0.11327551066241477
Trained batch 711 in epoch 1, gen_loss = 0.4605952081050766, disc_loss = 0.11315253536410504
Trained batch 712 in epoch 1, gen_loss = 0.4606391028886423, disc_loss = 0.1131706979337343
Trained batch 713 in epoch 1, gen_loss = 0.4606774230213726, disc_loss = 0.11306357604297561
Trained batch 714 in epoch 1, gen_loss = 0.4606501407973416, disc_loss = 0.11295676521461952
Trained batch 715 in epoch 1, gen_loss = 0.4606850313324502, disc_loss = 0.11285740409082833
Trained batch 716 in epoch 1, gen_loss = 0.4607166459204595, disc_loss = 0.11274394904610129
Trained batch 717 in epoch 1, gen_loss = 0.460782129037347, disc_loss = 0.1126196334556181
Trained batch 718 in epoch 1, gen_loss = 0.46074939026951955, disc_loss = 0.11250777850225464
Trained batch 719 in epoch 1, gen_loss = 0.46088350146181056, disc_loss = 0.11239560135096932
Trained batch 720 in epoch 1, gen_loss = 0.46096537046227476, disc_loss = 0.11231403493925661
Trained batch 721 in epoch 1, gen_loss = 0.46109193608866506, disc_loss = 0.11220368555001399
Trained batch 722 in epoch 1, gen_loss = 0.4610534163596389, disc_loss = 0.11215458602037791
Trained batch 723 in epoch 1, gen_loss = 0.4610614142694526, disc_loss = 0.11207244883147352
Trained batch 724 in epoch 1, gen_loss = 0.4611730070771842, disc_loss = 0.11196010409115717
Trained batch 725 in epoch 1, gen_loss = 0.4612124448144403, disc_loss = 0.11184342375240666
Trained batch 726 in epoch 1, gen_loss = 0.4612717238220257, disc_loss = 0.11172985819077434
Trained batch 727 in epoch 1, gen_loss = 0.4612336445313234, disc_loss = 0.11159487256708626
Trained batch 728 in epoch 1, gen_loss = 0.46136905291770547, disc_loss = 0.11145986623510167
Trained batch 729 in epoch 1, gen_loss = 0.4614656421419692, disc_loss = 0.11134130265563727
Trained batch 730 in epoch 1, gen_loss = 0.46145401159161253, disc_loss = 0.11120608754751621
Trained batch 731 in epoch 1, gen_loss = 0.46168959100064033, disc_loss = 0.1111795998743323
Trained batch 732 in epoch 1, gen_loss = 0.4616929538253222, disc_loss = 0.11105571727371313
Trained batch 733 in epoch 1, gen_loss = 0.4616332415907519, disc_loss = 0.11103635284877116
Trained batch 734 in epoch 1, gen_loss = 0.4616602297542857, disc_loss = 0.11099467682493787
Trained batch 735 in epoch 1, gen_loss = 0.46165729812143935, disc_loss = 0.11086734146659222
Trained batch 736 in epoch 1, gen_loss = 0.46175752812680587, disc_loss = 0.11073175860187254
Trained batch 737 in epoch 1, gen_loss = 0.46174755882279983, disc_loss = 0.11060232963655295
Trained batch 738 in epoch 1, gen_loss = 0.461683313844975, disc_loss = 0.11057293430948693
Trained batch 739 in epoch 1, gen_loss = 0.4616975333642315, disc_loss = 0.11049198934909057
Trained batch 740 in epoch 1, gen_loss = 0.46157742712983557, disc_loss = 0.11036508195806048
Trained batch 741 in epoch 1, gen_loss = 0.4616229883985057, disc_loss = 0.11033773306014162
Trained batch 742 in epoch 1, gen_loss = 0.461584302409982, disc_loss = 0.11020445601555894
Trained batch 743 in epoch 1, gen_loss = 0.4615296607696882, disc_loss = 0.1100758550330616
Trained batch 744 in epoch 1, gen_loss = 0.4614839361418014, disc_loss = 0.11002430154398184
Trained batch 745 in epoch 1, gen_loss = 0.4616491437837202, disc_loss = 0.10999984238871022
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.43251872062683105, disc_loss = 0.04127122461795807
Trained batch 1 in epoch 2, gen_loss = 0.4082411676645279, disc_loss = 0.03967729210853577
Trained batch 2 in epoch 2, gen_loss = 0.4498024682203929, disc_loss = 0.037732391307751335
Trained batch 3 in epoch 2, gen_loss = 0.44934452325105667, disc_loss = 0.035660818219184875
Trained batch 4 in epoch 2, gen_loss = 0.4734346568584442, disc_loss = 0.04893564283847809
Trained batch 5 in epoch 2, gen_loss = 0.4610410233338674, disc_loss = 0.05333852767944336
Trained batch 6 in epoch 2, gen_loss = 0.46715361731392996, disc_loss = 0.061623449836458476
Trained batch 7 in epoch 2, gen_loss = 0.466717004776001, disc_loss = 0.059107002802193165
Trained batch 8 in epoch 2, gen_loss = 0.47327084011501735, disc_loss = 0.06136655559142431
Trained batch 9 in epoch 2, gen_loss = 0.47971123456954956, disc_loss = 0.05812612883746624
Trained batch 10 in epoch 2, gen_loss = 0.47832162271846423, disc_loss = 0.05795855447649956
Trained batch 11 in epoch 2, gen_loss = 0.4767003233234088, disc_loss = 0.0560627564166983
Trained batch 12 in epoch 2, gen_loss = 0.47567002589886004, disc_loss = 0.05414994075321234
Trained batch 13 in epoch 2, gen_loss = 0.47407891282013487, disc_loss = 0.052995197874094756
Trained batch 14 in epoch 2, gen_loss = 0.4737857441107432, disc_loss = 0.051471126327912016
Trained batch 15 in epoch 2, gen_loss = 0.479556268081069, disc_loss = 0.053929131710901856
Trained batch 16 in epoch 2, gen_loss = 0.4818361980073592, disc_loss = 0.05185735357158324
Trained batch 17 in epoch 2, gen_loss = 0.47981926964388955, disc_loss = 0.05327463439769215
Trained batch 18 in epoch 2, gen_loss = 0.47880587138627706, disc_loss = 0.05248392569391351
Trained batch 19 in epoch 2, gen_loss = 0.47996426224708555, disc_loss = 0.052625136077404024
Trained batch 20 in epoch 2, gen_loss = 0.4829309100196475, disc_loss = 0.0518928553376879
Trained batch 21 in epoch 2, gen_loss = 0.4834426302801479, disc_loss = 0.050098621201786125
Trained batch 22 in epoch 2, gen_loss = 0.4832876506059066, disc_loss = 0.04979523141746935
Trained batch 23 in epoch 2, gen_loss = 0.4818025616308053, disc_loss = 0.04985529432694117
Trained batch 24 in epoch 2, gen_loss = 0.4796493172645569, disc_loss = 0.0483948515355587
Trained batch 25 in epoch 2, gen_loss = 0.48279887667069066, disc_loss = 0.048107027291105345
Trained batch 26 in epoch 2, gen_loss = 0.48268141128398756, disc_loss = 0.04843641155295902
Trained batch 27 in epoch 2, gen_loss = 0.48174175300768446, disc_loss = 0.04843869486025402
Trained batch 28 in epoch 2, gen_loss = 0.48727419561353225, disc_loss = 0.05179617836557586
Trained batch 29 in epoch 2, gen_loss = 0.48620735108852386, disc_loss = 0.05237947305043538
Trained batch 30 in epoch 2, gen_loss = 0.487154955825498, disc_loss = 0.051088156418934945
Trained batch 31 in epoch 2, gen_loss = 0.48751706071197987, disc_loss = 0.05005055107176304
Trained batch 32 in epoch 2, gen_loss = 0.48890075177857373, disc_loss = 0.049333620703581604
Trained batch 33 in epoch 2, gen_loss = 0.48770606956061197, disc_loss = 0.049323696862248814
Trained batch 34 in epoch 2, gen_loss = 0.4862879088946751, disc_loss = 0.049653456040791105
Trained batch 35 in epoch 2, gen_loss = 0.4873044060336219, disc_loss = 0.049098968868040375
Trained batch 36 in epoch 2, gen_loss = 0.4884027081566888, disc_loss = 0.049652048210437234
Trained batch 37 in epoch 2, gen_loss = 0.48887364487898977, disc_loss = 0.04863048634050708
Trained batch 38 in epoch 2, gen_loss = 0.4893125845835759, disc_loss = 0.04805846636494001
Trained batch 39 in epoch 2, gen_loss = 0.48795347809791567, disc_loss = 0.04765639947727322
Trained batch 40 in epoch 2, gen_loss = 0.4888286168982343, disc_loss = 0.04715879379612643
Trained batch 41 in epoch 2, gen_loss = 0.49042803332919166, disc_loss = 0.04625065842022499
Trained batch 42 in epoch 2, gen_loss = 0.48894577178844184, disc_loss = 0.045588948092488354
Trained batch 43 in epoch 2, gen_loss = 0.4886174608360637, disc_loss = 0.04536540831693194
Trained batch 44 in epoch 2, gen_loss = 0.4906898260116577, disc_loss = 0.04458370084563891
Trained batch 45 in epoch 2, gen_loss = 0.48824080954427307, disc_loss = 0.04398618654712387
Trained batch 46 in epoch 2, gen_loss = 0.487678014851631, disc_loss = 0.043541687283110114
Trained batch 47 in epoch 2, gen_loss = 0.4870022727797429, disc_loss = 0.04284361645113677
Trained batch 48 in epoch 2, gen_loss = 0.4883557503320733, disc_loss = 0.042217887957029195
Trained batch 49 in epoch 2, gen_loss = 0.48801795542240145, disc_loss = 0.046579106021672485
Trained batch 50 in epoch 2, gen_loss = 0.4878391863084307, disc_loss = 0.05070281746413778
Trained batch 51 in epoch 2, gen_loss = 0.48776713185585463, disc_loss = 0.050231701927259564
Trained batch 52 in epoch 2, gen_loss = 0.48692499916508514, disc_loss = 0.05013454995416808
Trained batch 53 in epoch 2, gen_loss = 0.48620003682595714, disc_loss = 0.05072689299575157
Trained batch 54 in epoch 2, gen_loss = 0.4859396202997728, disc_loss = 0.05063786968927492
Trained batch 55 in epoch 2, gen_loss = 0.4843841844371387, disc_loss = 0.052665891142428985
Trained batch 56 in epoch 2, gen_loss = 0.4841007041303735, disc_loss = 0.052936798402745476
Trained batch 57 in epoch 2, gen_loss = 0.4839340078419653, disc_loss = 0.056730538879617536
Trained batch 58 in epoch 2, gen_loss = 0.4822180180226342, disc_loss = 0.05847187922730789
Trained batch 59 in epoch 2, gen_loss = 0.4798543617129326, disc_loss = 0.05891620617670317
Trained batch 60 in epoch 2, gen_loss = 0.4798488025782538, disc_loss = 0.05945755493995108
Trained batch 61 in epoch 2, gen_loss = 0.4799386166757153, disc_loss = 0.06087469767719027
Trained batch 62 in epoch 2, gen_loss = 0.47923291817544, disc_loss = 0.06081983933432235
Trained batch 63 in epoch 2, gen_loss = 0.4778424450196326, disc_loss = 0.06140116626920644
Trained batch 64 in epoch 2, gen_loss = 0.4766281361763294, disc_loss = 0.06120647359639406
Trained batch 65 in epoch 2, gen_loss = 0.4760420259201165, disc_loss = 0.06138190656731075
Trained batch 66 in epoch 2, gen_loss = 0.47587482520003815, disc_loss = 0.06119142140525935
Trained batch 67 in epoch 2, gen_loss = 0.47636135974351096, disc_loss = 0.061723085900987774
Trained batch 68 in epoch 2, gen_loss = 0.47693464635075, disc_loss = 0.06129823540053938
Trained batch 69 in epoch 2, gen_loss = 0.4758614310196468, disc_loss = 0.06064569660063301
Trained batch 70 in epoch 2, gen_loss = 0.4746737073005085, disc_loss = 0.060288520424928466
Trained batch 71 in epoch 2, gen_loss = 0.47446781976355445, disc_loss = 0.05979314291228851
Trained batch 72 in epoch 2, gen_loss = 0.47425019047031663, disc_loss = 0.05936128174095121
Trained batch 73 in epoch 2, gen_loss = 0.4750091743630332, disc_loss = 0.0603212916317421
Trained batch 74 in epoch 2, gen_loss = 0.4758846573034922, disc_loss = 0.060056718463699026
Trained batch 75 in epoch 2, gen_loss = 0.4756638756708095, disc_loss = 0.0622403836122861
Trained batch 76 in epoch 2, gen_loss = 0.4748990520254358, disc_loss = 0.06238630421266153
Trained batch 77 in epoch 2, gen_loss = 0.47618066500394773, disc_loss = 0.06586636839291224
Trained batch 78 in epoch 2, gen_loss = 0.47577657842937904, disc_loss = 0.06528876502585562
Trained batch 79 in epoch 2, gen_loss = 0.47522923089563845, disc_loss = 0.06472830998245627
Trained batch 80 in epoch 2, gen_loss = 0.4734154159640088, disc_loss = 0.06422583292019957
Trained batch 81 in epoch 2, gen_loss = 0.47368148369033164, disc_loss = 0.06392081756508206
Trained batch 82 in epoch 2, gen_loss = 0.47287814911589565, disc_loss = 0.063641571742763
Trained batch 83 in epoch 2, gen_loss = 0.47355416949306217, disc_loss = 0.06352516372377674
Trained batch 84 in epoch 2, gen_loss = 0.4744174105279586, disc_loss = 0.0637920311487773
Trained batch 85 in epoch 2, gen_loss = 0.4746412700691888, disc_loss = 0.06341289936803109
Trained batch 86 in epoch 2, gen_loss = 0.4752533363884893, disc_loss = 0.06326032832436178
Trained batch 87 in epoch 2, gen_loss = 0.47558370808308775, disc_loss = 0.06279100831174715
Trained batch 88 in epoch 2, gen_loss = 0.4762979621967573, disc_loss = 0.06241988099776627
Trained batch 89 in epoch 2, gen_loss = 0.4761467847559187, disc_loss = 0.06267835235016214
Trained batch 90 in epoch 2, gen_loss = 0.47688145231414625, disc_loss = 0.062181485653087336
Trained batch 91 in epoch 2, gen_loss = 0.476552027075187, disc_loss = 0.06267770495184738
Trained batch 92 in epoch 2, gen_loss = 0.47700982004083614, disc_loss = 0.06226032277348862
Trained batch 93 in epoch 2, gen_loss = 0.4777961937671012, disc_loss = 0.06288359585673885
Trained batch 94 in epoch 2, gen_loss = 0.47668387419299074, disc_loss = 0.06325308125662177
Trained batch 95 in epoch 2, gen_loss = 0.476819656478862, disc_loss = 0.06355826255943005
Trained batch 96 in epoch 2, gen_loss = 0.47651609163923364, disc_loss = 0.06337301354356033
Trained batch 97 in epoch 2, gen_loss = 0.47643898792412814, disc_loss = 0.0631674704312974
Trained batch 98 in epoch 2, gen_loss = 0.47652528231794183, disc_loss = 0.06289757406244977
Trained batch 99 in epoch 2, gen_loss = 0.47614294111728667, disc_loss = 0.06292087191715837
Trained batch 100 in epoch 2, gen_loss = 0.476569136770645, disc_loss = 0.06248521364045025
Trained batch 101 in epoch 2, gen_loss = 0.4761441756112903, disc_loss = 0.062251212641450705
Trained batch 102 in epoch 2, gen_loss = 0.4749937575418972, disc_loss = 0.06195362735069492
Trained batch 103 in epoch 2, gen_loss = 0.47434798542123574, disc_loss = 0.06265884091576132
Trained batch 104 in epoch 2, gen_loss = 0.47449079070772443, disc_loss = 0.06251352363753887
Trained batch 105 in epoch 2, gen_loss = 0.4743728409960585, disc_loss = 0.06547591868647427
Trained batch 106 in epoch 2, gen_loss = 0.47398562464758615, disc_loss = 0.06622556191390362
Trained batch 107 in epoch 2, gen_loss = 0.4733028930646402, disc_loss = 0.06699106999224534
Trained batch 108 in epoch 2, gen_loss = 0.47334037598119966, disc_loss = 0.06826344725393921
Trained batch 109 in epoch 2, gen_loss = 0.47268396453423933, disc_loss = 0.06898687053471804
Trained batch 110 in epoch 2, gen_loss = 0.4725753562944429, disc_loss = 0.06873567944375782
Trained batch 111 in epoch 2, gen_loss = 0.4726829518164907, disc_loss = 0.06849934724492154
Trained batch 112 in epoch 2, gen_loss = 0.47121673875150427, disc_loss = 0.06838737096868258
Trained batch 113 in epoch 2, gen_loss = 0.47079553363616006, disc_loss = 0.06861572580313996
Trained batch 114 in epoch 2, gen_loss = 0.470973393191462, disc_loss = 0.06851777484559494
Trained batch 115 in epoch 2, gen_loss = 0.4711023995588566, disc_loss = 0.06824287940780151
Trained batch 116 in epoch 2, gen_loss = 0.4702840854978969, disc_loss = 0.06807024450574675
Trained batch 117 in epoch 2, gen_loss = 0.47026009882910774, disc_loss = 0.06772848201315787
Trained batch 118 in epoch 2, gen_loss = 0.4703472078848286, disc_loss = 0.06726793057340033
Trained batch 119 in epoch 2, gen_loss = 0.46996918295820556, disc_loss = 0.06680990729170541
Trained batch 120 in epoch 2, gen_loss = 0.47016278155579055, disc_loss = 0.06655709259212017
Trained batch 121 in epoch 2, gen_loss = 0.4698885219996093, disc_loss = 0.06614534491215085
Trained batch 122 in epoch 2, gen_loss = 0.46979130356292415, disc_loss = 0.06569073941346591
Trained batch 123 in epoch 2, gen_loss = 0.4702036772524157, disc_loss = 0.06523436812623855
Trained batch 124 in epoch 2, gen_loss = 0.470152560710907, disc_loss = 0.06479090318083763
Trained batch 125 in epoch 2, gen_loss = 0.4700214264411775, disc_loss = 0.0644422656013852
Trained batch 126 in epoch 2, gen_loss = 0.47062858375977346, disc_loss = 0.06440550217947622
Trained batch 127 in epoch 2, gen_loss = 0.4710781059693545, disc_loss = 0.06490048870909959
Trained batch 128 in epoch 2, gen_loss = 0.47108794067257137, disc_loss = 0.06474368025859197
Trained batch 129 in epoch 2, gen_loss = 0.4707838597205969, disc_loss = 0.06467944962474016
Trained batch 130 in epoch 2, gen_loss = 0.46997336508663556, disc_loss = 0.06455193929203594
Trained batch 131 in epoch 2, gen_loss = 0.4696482117428924, disc_loss = 0.06447235740382563
Trained batch 132 in epoch 2, gen_loss = 0.4692509797282685, disc_loss = 0.06408700267819309
Trained batch 133 in epoch 2, gen_loss = 0.46960772106896587, disc_loss = 0.06375892017620491
Trained batch 134 in epoch 2, gen_loss = 0.47003455912625347, disc_loss = 0.06361756862175685
Trained batch 135 in epoch 2, gen_loss = 0.46981167420744896, disc_loss = 0.06356174788465176
Trained batch 136 in epoch 2, gen_loss = 0.46968422188375986, disc_loss = 0.06352305634586262
Trained batch 137 in epoch 2, gen_loss = 0.4701940944229347, disc_loss = 0.06372338737887533
Trained batch 138 in epoch 2, gen_loss = 0.46993453511231237, disc_loss = 0.06372628708725138
Trained batch 139 in epoch 2, gen_loss = 0.4699100168687957, disc_loss = 0.06386921075172722
Trained batch 140 in epoch 2, gen_loss = 0.4697222443337136, disc_loss = 0.06363417023911755
Trained batch 141 in epoch 2, gen_loss = 0.4702360206086871, disc_loss = 0.06349550314168904
Trained batch 142 in epoch 2, gen_loss = 0.4707183842058782, disc_loss = 0.06325757347854909
Trained batch 143 in epoch 2, gen_loss = 0.4710487599174182, disc_loss = 0.06301068013352859
Trained batch 144 in epoch 2, gen_loss = 0.47089474982228774, disc_loss = 0.06286589118555702
Trained batch 145 in epoch 2, gen_loss = 0.4706141177105577, disc_loss = 0.0626430862506673
Trained batch 146 in epoch 2, gen_loss = 0.469615119857853, disc_loss = 0.06264816092162513
Trained batch 147 in epoch 2, gen_loss = 0.46888406051171794, disc_loss = 0.06246728839579265
Trained batch 148 in epoch 2, gen_loss = 0.46873173397659457, disc_loss = 0.06211300591169388
Trained batch 149 in epoch 2, gen_loss = 0.46895487447579703, disc_loss = 0.06183839617297053
Trained batch 150 in epoch 2, gen_loss = 0.46895407426436214, disc_loss = 0.06152379902585453
Trained batch 151 in epoch 2, gen_loss = 0.4688980955826609, disc_loss = 0.06124700520089582
Trained batch 152 in epoch 2, gen_loss = 0.46822746419439126, disc_loss = 0.06115898368210575
Trained batch 153 in epoch 2, gen_loss = 0.46851233518742896, disc_loss = 0.06083823279659083
Trained batch 154 in epoch 2, gen_loss = 0.46845326173690055, disc_loss = 0.060595674728674276
Trained batch 155 in epoch 2, gen_loss = 0.46791985573676914, disc_loss = 0.06030341422853944
Trained batch 156 in epoch 2, gen_loss = 0.46791351392010977, disc_loss = 0.060987445140245615
Trained batch 157 in epoch 2, gen_loss = 0.4683669200049171, disc_loss = 0.06083300562363259
Trained batch 158 in epoch 2, gen_loss = 0.4685697448703478, disc_loss = 0.06069794057065961
Trained batch 159 in epoch 2, gen_loss = 0.4683930654078722, disc_loss = 0.06041200796607882
Trained batch 160 in epoch 2, gen_loss = 0.468812844768074, disc_loss = 0.060293768804450955
Trained batch 161 in epoch 2, gen_loss = 0.4688828710788562, disc_loss = 0.060318761608666845
Trained batch 162 in epoch 2, gen_loss = 0.468545133350817, disc_loss = 0.060855126659745816
Trained batch 163 in epoch 2, gen_loss = 0.4684603534093717, disc_loss = 0.06077127474382883
Trained batch 164 in epoch 2, gen_loss = 0.46841420097784564, disc_loss = 0.060577464600404106
Trained batch 165 in epoch 2, gen_loss = 0.4688471036862178, disc_loss = 0.06045457965368966
Trained batch 166 in epoch 2, gen_loss = 0.4698290815967286, disc_loss = 0.060415566324473854
Trained batch 167 in epoch 2, gen_loss = 0.4700486569532326, disc_loss = 0.06030859030960571
Trained batch 168 in epoch 2, gen_loss = 0.47013585295902904, disc_loss = 0.06010643418150893
Trained batch 169 in epoch 2, gen_loss = 0.47055386743124794, disc_loss = 0.05986769648597521
Trained batch 170 in epoch 2, gen_loss = 0.47079531334297003, disc_loss = 0.06002811540724241
Trained batch 171 in epoch 2, gen_loss = 0.47049263691486315, disc_loss = 0.05984103247566625
Trained batch 172 in epoch 2, gen_loss = 0.47052597878985325, disc_loss = 0.05989153141618809
Trained batch 173 in epoch 2, gen_loss = 0.4705903074522128, disc_loss = 0.05968329478483433
Trained batch 174 in epoch 2, gen_loss = 0.47056295428957257, disc_loss = 0.05965882745172296
Trained batch 175 in epoch 2, gen_loss = 0.4707968048751354, disc_loss = 0.05974711334883151
Trained batch 176 in epoch 2, gen_loss = 0.4709278887274575, disc_loss = 0.0596054979405329
Trained batch 177 in epoch 2, gen_loss = 0.47115513347507865, disc_loss = 0.05940436612647236
Trained batch 178 in epoch 2, gen_loss = 0.4712334365152114, disc_loss = 0.05916124466785838
Trained batch 179 in epoch 2, gen_loss = 0.47118865069415833, disc_loss = 0.05939710182655189
Trained batch 180 in epoch 2, gen_loss = 0.4713453813481726, disc_loss = 0.05941123514338422
Trained batch 181 in epoch 2, gen_loss = 0.4716703179445896, disc_loss = 0.059397255070507526
Trained batch 182 in epoch 2, gen_loss = 0.4718635552893571, disc_loss = 0.05921651957342859
Trained batch 183 in epoch 2, gen_loss = 0.4716977200106434, disc_loss = 0.05911030076727595
Trained batch 184 in epoch 2, gen_loss = 0.47229187408009093, disc_loss = 0.0588822206734
Trained batch 185 in epoch 2, gen_loss = 0.4723023397307242, disc_loss = 0.0586798275190015
Trained batch 186 in epoch 2, gen_loss = 0.47207187171925835, disc_loss = 0.05845861702679313
Trained batch 187 in epoch 2, gen_loss = 0.47225064419685525, disc_loss = 0.05818919056501398
Trained batch 188 in epoch 2, gen_loss = 0.472558700533771, disc_loss = 0.05803293076210788
Trained batch 189 in epoch 2, gen_loss = 0.47221690682988415, disc_loss = 0.057799027896927375
Trained batch 190 in epoch 2, gen_loss = 0.4724544506734578, disc_loss = 0.057794278553389596
Trained batch 191 in epoch 2, gen_loss = 0.471750401891768, disc_loss = 0.05798155003139982
Trained batch 192 in epoch 2, gen_loss = 0.47182744617906874, disc_loss = 0.05779529262305155
Trained batch 193 in epoch 2, gen_loss = 0.4717023000889218, disc_loss = 0.05760725894606836
Trained batch 194 in epoch 2, gen_loss = 0.4721211962210826, disc_loss = 0.0574729361380331
Trained batch 195 in epoch 2, gen_loss = 0.47216978760398165, disc_loss = 0.05739320160545485
Trained batch 196 in epoch 2, gen_loss = 0.47213507878598826, disc_loss = 0.0571597592484414
Trained batch 197 in epoch 2, gen_loss = 0.4721916722829896, disc_loss = 0.05698823320415962
Trained batch 198 in epoch 2, gen_loss = 0.4722029369081085, disc_loss = 0.05676478215132901
Trained batch 199 in epoch 2, gen_loss = 0.4724114927649498, disc_loss = 0.05653204976348206
Trained batch 200 in epoch 2, gen_loss = 0.4723224798541757, disc_loss = 0.056600323982481195
Trained batch 201 in epoch 2, gen_loss = 0.47250084549483684, disc_loss = 0.05667709373629255
Trained batch 202 in epoch 2, gen_loss = 0.4722664118400348, disc_loss = 0.056688333515151235
Trained batch 203 in epoch 2, gen_loss = 0.4725827992546792, disc_loss = 0.05870895130404582
Trained batch 204 in epoch 2, gen_loss = 0.47264971195197686, disc_loss = 0.058707435508599366
Trained batch 205 in epoch 2, gen_loss = 0.47242662484206044, disc_loss = 0.058632151999067766
Trained batch 206 in epoch 2, gen_loss = 0.47256766511622256, disc_loss = 0.058675601293337376
Trained batch 207 in epoch 2, gen_loss = 0.4724396485835314, disc_loss = 0.0584945153118147
Trained batch 208 in epoch 2, gen_loss = 0.47250439148200185, disc_loss = 0.05827041969157791
Trained batch 209 in epoch 2, gen_loss = 0.471980554433096, disc_loss = 0.05818941881214934
Trained batch 210 in epoch 2, gen_loss = 0.4718915902042841, disc_loss = 0.058031467383206595
Trained batch 211 in epoch 2, gen_loss = 0.4718138612103912, disc_loss = 0.05782122360674208
Trained batch 212 in epoch 2, gen_loss = 0.4719402069496996, disc_loss = 0.057610734984576
Trained batch 213 in epoch 2, gen_loss = 0.47192419967918753, disc_loss = 0.05741720168990579
Trained batch 214 in epoch 2, gen_loss = 0.47173034035882283, disc_loss = 0.0572207244091429
Trained batch 215 in epoch 2, gen_loss = 0.47124691086786763, disc_loss = 0.05719435636894087
Trained batch 216 in epoch 2, gen_loss = 0.4715037917211858, disc_loss = 0.05804611125548932
Trained batch 217 in epoch 2, gen_loss = 0.47131275911943626, disc_loss = 0.058366408120892055
Trained batch 218 in epoch 2, gen_loss = 0.4712260342351922, disc_loss = 0.05841893972573827
Trained batch 219 in epoch 2, gen_loss = 0.47110601433298804, disc_loss = 0.05855640146923675
Trained batch 220 in epoch 2, gen_loss = 0.47099519207466783, disc_loss = 0.05847782903978795
Trained batch 221 in epoch 2, gen_loss = 0.4709651870233519, disc_loss = 0.0583157075237617
Trained batch 222 in epoch 2, gen_loss = 0.47077783768487086, disc_loss = 0.05820285472308908
Trained batch 223 in epoch 2, gen_loss = 0.4705332226252982, disc_loss = 0.057996037800746435
Trained batch 224 in epoch 2, gen_loss = 0.47043695542547437, disc_loss = 0.057983888373192814
Trained batch 225 in epoch 2, gen_loss = 0.4700552992588651, disc_loss = 0.05785792060732116
Trained batch 226 in epoch 2, gen_loss = 0.47032062361418936, disc_loss = 0.05765480400239516
Trained batch 227 in epoch 2, gen_loss = 0.4701551121839306, disc_loss = 0.05745941288401618
Trained batch 228 in epoch 2, gen_loss = 0.47033999931864345, disc_loss = 0.05736314104137918
Trained batch 229 in epoch 2, gen_loss = 0.4702700066825618, disc_loss = 0.057405353618947705
Trained batch 230 in epoch 2, gen_loss = 0.4701491334995666, disc_loss = 0.05742629493881033
Trained batch 231 in epoch 2, gen_loss = 0.4702294873523301, disc_loss = 0.05725362942481799
Trained batch 232 in epoch 2, gen_loss = 0.47060600281273346, disc_loss = 0.057388777710705226
Trained batch 233 in epoch 2, gen_loss = 0.4704870180441783, disc_loss = 0.05725408494114303
Trained batch 234 in epoch 2, gen_loss = 0.47024792800558374, disc_loss = 0.05742921190970439
Trained batch 235 in epoch 2, gen_loss = 0.4699674255009425, disc_loss = 0.05743333278026558
Trained batch 236 in epoch 2, gen_loss = 0.4693472032054064, disc_loss = 0.057493925194810086
Trained batch 237 in epoch 2, gen_loss = 0.469578624147327, disc_loss = 0.05753642480875201
Trained batch 238 in epoch 2, gen_loss = 0.4692336606430708, disc_loss = 0.05759352717400532
Trained batch 239 in epoch 2, gen_loss = 0.46913350944717724, disc_loss = 0.057456941054745886
Trained batch 240 in epoch 2, gen_loss = 0.4694036015336444, disc_loss = 0.05729268025027209
Trained batch 241 in epoch 2, gen_loss = 0.4692370216708538, disc_loss = 0.05725517540146435
Trained batch 242 in epoch 2, gen_loss = 0.46944554033593383, disc_loss = 0.05715775609959239
Trained batch 243 in epoch 2, gen_loss = 0.4695999065383536, disc_loss = 0.05710240551766741
Trained batch 244 in epoch 2, gen_loss = 0.46949314146625754, disc_loss = 0.05698626890436423
Trained batch 245 in epoch 2, gen_loss = 0.4693365808182616, disc_loss = 0.05683774628858196
Trained batch 246 in epoch 2, gen_loss = 0.4693202498229409, disc_loss = 0.05675690841902545
Trained batch 247 in epoch 2, gen_loss = 0.469026765635898, disc_loss = 0.05675539307318808
Trained batch 248 in epoch 2, gen_loss = 0.4689035724444562, disc_loss = 0.056677921669535246
Trained batch 249 in epoch 2, gen_loss = 0.46898012018203733, disc_loss = 0.056605936890468
Trained batch 250 in epoch 2, gen_loss = 0.4687081958905634, disc_loss = 0.05643412312566937
Trained batch 251 in epoch 2, gen_loss = 0.4689755216240883, disc_loss = 0.05639637040439993
Trained batch 252 in epoch 2, gen_loss = 0.46925958354953723, disc_loss = 0.05624649122084966
Trained batch 253 in epoch 2, gen_loss = 0.4695131378614996, disc_loss = 0.05609185644425452
Trained batch 254 in epoch 2, gen_loss = 0.4697478466174182, disc_loss = 0.05594848530074837
Trained batch 255 in epoch 2, gen_loss = 0.46991928352508694, disc_loss = 0.05581615633673209
Trained batch 256 in epoch 2, gen_loss = 0.46992971866975036, disc_loss = 0.05567565542040574
Trained batch 257 in epoch 2, gen_loss = 0.4699206360319788, disc_loss = 0.055500402943729314
Trained batch 258 in epoch 2, gen_loss = 0.47024614504865697, disc_loss = 0.055331864669329295
Trained batch 259 in epoch 2, gen_loss = 0.4705156996846199, disc_loss = 0.05517466891592798
Trained batch 260 in epoch 2, gen_loss = 0.47037636183230813, disc_loss = 0.05504183927408181
Trained batch 261 in epoch 2, gen_loss = 0.47067695264597886, disc_loss = 0.05541178304879777
Trained batch 262 in epoch 2, gen_loss = 0.4706943710493951, disc_loss = 0.056264492660095144
Trained batch 263 in epoch 2, gen_loss = 0.47035817756797327, disc_loss = 0.05637079188917679
Trained batch 264 in epoch 2, gen_loss = 0.4706810757798969, disc_loss = 0.05626264286385673
Trained batch 265 in epoch 2, gen_loss = 0.47097330546020566, disc_loss = 0.056398932074539755
Trained batch 266 in epoch 2, gen_loss = 0.4709282401349214, disc_loss = 0.056491440700974026
Trained batch 267 in epoch 2, gen_loss = 0.4709239163950308, disc_loss = 0.056502423237022294
Trained batch 268 in epoch 2, gen_loss = 0.47100191067585717, disc_loss = 0.05638147171995288
Trained batch 269 in epoch 2, gen_loss = 0.47125132105968615, disc_loss = 0.056407833942729566
Trained batch 270 in epoch 2, gen_loss = 0.4711738986502714, disc_loss = 0.05698372023798718
Trained batch 271 in epoch 2, gen_loss = 0.47085114053505306, disc_loss = 0.05795230575570125
Trained batch 272 in epoch 2, gen_loss = 0.47063961428600354, disc_loss = 0.0583234818689798
Trained batch 273 in epoch 2, gen_loss = 0.47059980915845745, disc_loss = 0.05829507792470501
Trained batch 274 in epoch 2, gen_loss = 0.4705772795460441, disc_loss = 0.05841944496909326
Trained batch 275 in epoch 2, gen_loss = 0.47059410659299383, disc_loss = 0.05841378558703793
Trained batch 276 in epoch 2, gen_loss = 0.47047261565600923, disc_loss = 0.05834328676557121
Trained batch 277 in epoch 2, gen_loss = 0.4701208125987499, disc_loss = 0.05851793080307007
Trained batch 278 in epoch 2, gen_loss = 0.47030170683792416, disc_loss = 0.05845411507893474
Trained batch 279 in epoch 2, gen_loss = 0.47013128623366357, disc_loss = 0.05841071178770757
Trained batch 280 in epoch 2, gen_loss = 0.4699691103446526, disc_loss = 0.05840490692298449
Trained batch 281 in epoch 2, gen_loss = 0.4699467585441914, disc_loss = 0.05841106130305598
Trained batch 282 in epoch 2, gen_loss = 0.47010965376776437, disc_loss = 0.05842300325586023
Trained batch 283 in epoch 2, gen_loss = 0.46981775802625736, disc_loss = 0.05829853665667363
Trained batch 284 in epoch 2, gen_loss = 0.46992994484148526, disc_loss = 0.05820210229834182
Trained batch 285 in epoch 2, gen_loss = 0.4701643375666825, disc_loss = 0.058044272264908554
Trained batch 286 in epoch 2, gen_loss = 0.47027218362595563, disc_loss = 0.05793114109548905
Trained batch 287 in epoch 2, gen_loss = 0.47042937556074726, disc_loss = 0.05779262247152575
Trained batch 288 in epoch 2, gen_loss = 0.4704646458881537, disc_loss = 0.05772696795573645
Trained batch 289 in epoch 2, gen_loss = 0.47021512748866245, disc_loss = 0.05772202741194131
Trained batch 290 in epoch 2, gen_loss = 0.46996017512177274, disc_loss = 0.057672872632114645
Trained batch 291 in epoch 2, gen_loss = 0.46998296749510177, disc_loss = 0.05756491088876118
Trained batch 292 in epoch 2, gen_loss = 0.4697948234479989, disc_loss = 0.057604448232520054
Trained batch 293 in epoch 2, gen_loss = 0.46969449996542767, disc_loss = 0.057593732950321976
Trained batch 294 in epoch 2, gen_loss = 0.4697372636552584, disc_loss = 0.05746654628665518
Trained batch 295 in epoch 2, gen_loss = 0.4699711485488995, disc_loss = 0.057660672793202604
Trained batch 296 in epoch 2, gen_loss = 0.4698645567853844, disc_loss = 0.05787723376462706
Trained batch 297 in epoch 2, gen_loss = 0.46992622255878963, disc_loss = 0.05799918227216491
Trained batch 298 in epoch 2, gen_loss = 0.4699052932071048, disc_loss = 0.058115969189321215
Trained batch 299 in epoch 2, gen_loss = 0.4695707294344902, disc_loss = 0.05815850971111407
Trained batch 300 in epoch 2, gen_loss = 0.4697273618161084, disc_loss = 0.05816332790907782
Trained batch 301 in epoch 2, gen_loss = 0.47007015475768915, disc_loss = 0.05801447573895042
Trained batch 302 in epoch 2, gen_loss = 0.4700093690318243, disc_loss = 0.05788871623643308
Trained batch 303 in epoch 2, gen_loss = 0.4702593139127681, disc_loss = 0.05795134400403568
Trained batch 304 in epoch 2, gen_loss = 0.47032536932679475, disc_loss = 0.05785267354737295
Trained batch 305 in epoch 2, gen_loss = 0.47028965352017893, disc_loss = 0.05774674178527218
Trained batch 306 in epoch 2, gen_loss = 0.4703892021885912, disc_loss = 0.05759513386789139
Trained batch 307 in epoch 2, gen_loss = 0.47031574560837314, disc_loss = 0.057498890496850884
Trained batch 308 in epoch 2, gen_loss = 0.47040739134677406, disc_loss = 0.057433428503512664
Trained batch 309 in epoch 2, gen_loss = 0.4707276998989044, disc_loss = 0.057357609754187924
Trained batch 310 in epoch 2, gen_loss = 0.47083023631304405, disc_loss = 0.057220369581899744
Trained batch 311 in epoch 2, gen_loss = 0.4706874278684457, disc_loss = 0.057071777868072666
Trained batch 312 in epoch 2, gen_loss = 0.47033262424194777, disc_loss = 0.057108167375916966
Trained batch 313 in epoch 2, gen_loss = 0.4704076569930763, disc_loss = 0.05733949892299997
Trained batch 314 in epoch 2, gen_loss = 0.47013929836333745, disc_loss = 0.05723071043483085
Trained batch 315 in epoch 2, gen_loss = 0.46994902523635307, disc_loss = 0.0571734736028092
Trained batch 316 in epoch 2, gen_loss = 0.46964920027774965, disc_loss = 0.05716984329615905
Trained batch 317 in epoch 2, gen_loss = 0.4694482741303414, disc_loss = 0.057095358799850136
Trained batch 318 in epoch 2, gen_loss = 0.469581778987448, disc_loss = 0.05709659846114187
Trained batch 319 in epoch 2, gen_loss = 0.4699608854018152, disc_loss = 0.056986633311316835
Trained batch 320 in epoch 2, gen_loss = 0.4700547691631911, disc_loss = 0.05686716911327848
Trained batch 321 in epoch 2, gen_loss = 0.47006195718827454, disc_loss = 0.056745696727545085
Trained batch 322 in epoch 2, gen_loss = 0.47016836550582675, disc_loss = 0.056664726459031964
Trained batch 323 in epoch 2, gen_loss = 0.47016082188965364, disc_loss = 0.05661169066594017
Trained batch 324 in epoch 2, gen_loss = 0.47028165138684785, disc_loss = 0.05671775402501225
Trained batch 325 in epoch 2, gen_loss = 0.47005162621202645, disc_loss = 0.05662959890777211
Trained batch 326 in epoch 2, gen_loss = 0.46996299325508445, disc_loss = 0.056651304064415375
Trained batch 327 in epoch 2, gen_loss = 0.4699765596447921, disc_loss = 0.056696621259594925
Trained batch 328 in epoch 2, gen_loss = 0.4701256168649552, disc_loss = 0.056643002891579024
Trained batch 329 in epoch 2, gen_loss = 0.46981917321681976, disc_loss = 0.056895673908575466
Trained batch 330 in epoch 2, gen_loss = 0.47002888905317763, disc_loss = 0.05718453422194386
Trained batch 331 in epoch 2, gen_loss = 0.4705076446554747, disc_loss = 0.05706452055559325
Trained batch 332 in epoch 2, gen_loss = 0.47033716501058404, disc_loss = 0.05735968740366108
Trained batch 333 in epoch 2, gen_loss = 0.47043027867100196, disc_loss = 0.057494810443583455
Trained batch 334 in epoch 2, gen_loss = 0.4703217327594757, disc_loss = 0.05816022560361828
Trained batch 335 in epoch 2, gen_loss = 0.4702650083317643, disc_loss = 0.05839701912814884
Trained batch 336 in epoch 2, gen_loss = 0.4701355189880914, disc_loss = 0.058524811415150986
Trained batch 337 in epoch 2, gen_loss = 0.4703405000401672, disc_loss = 0.05862759364653136
Trained batch 338 in epoch 2, gen_loss = 0.47039181767663424, disc_loss = 0.05858994904042917
Trained batch 339 in epoch 2, gen_loss = 0.47032576106926977, disc_loss = 0.05871973638285828
Trained batch 340 in epoch 2, gen_loss = 0.4701974415534403, disc_loss = 0.058708357912846065
Trained batch 341 in epoch 2, gen_loss = 0.4703548872157147, disc_loss = 0.05862886303006426
Trained batch 342 in epoch 2, gen_loss = 0.4705000035790591, disc_loss = 0.05855976543782969
Trained batch 343 in epoch 2, gen_loss = 0.47039029721257297, disc_loss = 0.05854495522853117
Trained batch 344 in epoch 2, gen_loss = 0.4701432780943055, disc_loss = 0.05848663413789177
Trained batch 345 in epoch 2, gen_loss = 0.4706083477577033, disc_loss = 0.05901210327804993
Trained batch 346 in epoch 2, gen_loss = 0.47069861703372484, disc_loss = 0.05891516641109795
Trained batch 347 in epoch 2, gen_loss = 0.4708559985818534, disc_loss = 0.05904816015725206
Trained batch 348 in epoch 2, gen_loss = 0.4708233793348843, disc_loss = 0.059275306074114194
Trained batch 349 in epoch 2, gen_loss = 0.4708412437779563, disc_loss = 0.05943190080379801
Trained batch 350 in epoch 2, gen_loss = 0.4705084646359468, disc_loss = 0.05949139465150713
Trained batch 351 in epoch 2, gen_loss = 0.47056984588165174, disc_loss = 0.05944871912652161
Trained batch 352 in epoch 2, gen_loss = 0.4708240429841763, disc_loss = 0.060010154777742054
Trained batch 353 in epoch 2, gen_loss = 0.470628733773016, disc_loss = 0.06004188438788014
Trained batch 354 in epoch 2, gen_loss = 0.4705547872563483, disc_loss = 0.060073903660801516
Trained batch 355 in epoch 2, gen_loss = 0.4705328845073668, disc_loss = 0.06005959105651742
Trained batch 356 in epoch 2, gen_loss = 0.47046260715198784, disc_loss = 0.06000481557012314
Trained batch 357 in epoch 2, gen_loss = 0.4705226247370576, disc_loss = 0.05986233398854191
Trained batch 358 in epoch 2, gen_loss = 0.47060810913614576, disc_loss = 0.0597825415917571
Trained batch 359 in epoch 2, gen_loss = 0.47042314070794317, disc_loss = 0.05969934663088578
Trained batch 360 in epoch 2, gen_loss = 0.4704946419043554, disc_loss = 0.0595984805125093
Trained batch 361 in epoch 2, gen_loss = 0.4705393088785983, disc_loss = 0.059467886105046004
Trained batch 362 in epoch 2, gen_loss = 0.47064914749345177, disc_loss = 0.059449686685489805
Trained batch 363 in epoch 2, gen_loss = 0.47048867960552593, disc_loss = 0.059923094614142816
Trained batch 364 in epoch 2, gen_loss = 0.4705980544220911, disc_loss = 0.059996095716902245
Trained batch 365 in epoch 2, gen_loss = 0.4704641127358369, disc_loss = 0.06004254280620056
Trained batch 366 in epoch 2, gen_loss = 0.47045528994269203, disc_loss = 0.06003544557641694
Trained batch 367 in epoch 2, gen_loss = 0.47061969315552193, disc_loss = 0.06029457140222961
Trained batch 368 in epoch 2, gen_loss = 0.4704166477127127, disc_loss = 0.06051477271846437
Trained batch 369 in epoch 2, gen_loss = 0.47025942915194746, disc_loss = 0.06055235905899994
Trained batch 370 in epoch 2, gen_loss = 0.4701327683148037, disc_loss = 0.060978643042650424
Trained batch 371 in epoch 2, gen_loss = 0.4701849790189856, disc_loss = 0.06113680106492573
Trained batch 372 in epoch 2, gen_loss = 0.4699871142172622, disc_loss = 0.061065733900927906
Trained batch 373 in epoch 2, gen_loss = 0.47021759464779, disc_loss = 0.061169533715160054
Trained batch 374 in epoch 2, gen_loss = 0.4701349685986837, disc_loss = 0.06110056814427177
Trained batch 375 in epoch 2, gen_loss = 0.47022246537690465, disc_loss = 0.06104206288743645
Trained batch 376 in epoch 2, gen_loss = 0.47017967171314856, disc_loss = 0.061110015937549604
Trained batch 377 in epoch 2, gen_loss = 0.47012135323393284, disc_loss = 0.061137200750794915
Trained batch 378 in epoch 2, gen_loss = 0.4699756558935372, disc_loss = 0.06102785649819983
Trained batch 379 in epoch 2, gen_loss = 0.47003687267240724, disc_loss = 0.06105990289146767
Trained batch 380 in epoch 2, gen_loss = 0.47001678252157575, disc_loss = 0.06100068155192132
Trained batch 381 in epoch 2, gen_loss = 0.4699028502584128, disc_loss = 0.06100831705350331
Trained batch 382 in epoch 2, gen_loss = 0.4697921159373251, disc_loss = 0.06087672759416481
Trained batch 383 in epoch 2, gen_loss = 0.4698093330177168, disc_loss = 0.06082536959608357
Trained batch 384 in epoch 2, gen_loss = 0.469759840005404, disc_loss = 0.060962703363220024
Trained batch 385 in epoch 2, gen_loss = 0.46997534410323505, disc_loss = 0.060962651912943304
Trained batch 386 in epoch 2, gen_loss = 0.47014952322001297, disc_loss = 0.06089251735235639
Trained batch 387 in epoch 2, gen_loss = 0.4701737001077416, disc_loss = 0.06096152508434523
Trained batch 388 in epoch 2, gen_loss = 0.4700216214270702, disc_loss = 0.06099873796885876
Trained batch 389 in epoch 2, gen_loss = 0.47007255515991114, disc_loss = 0.06088664479529819
Trained batch 390 in epoch 2, gen_loss = 0.46992919573088743, disc_loss = 0.0610169738357234
Trained batch 391 in epoch 2, gen_loss = 0.4700607680240456, disc_loss = 0.06110640299121602
Trained batch 392 in epoch 2, gen_loss = 0.47017018804113375, disc_loss = 0.06098889766981394
Trained batch 393 in epoch 2, gen_loss = 0.47009361168454744, disc_loss = 0.06093822031868101
Trained batch 394 in epoch 2, gen_loss = 0.47002915015703517, disc_loss = 0.06085932754994004
Trained batch 395 in epoch 2, gen_loss = 0.47012588494654856, disc_loss = 0.06080451083129667
Trained batch 396 in epoch 2, gen_loss = 0.4702749008345664, disc_loss = 0.060794139336043926
Trained batch 397 in epoch 2, gen_loss = 0.47020927348628117, disc_loss = 0.06081746240034138
Trained batch 398 in epoch 2, gen_loss = 0.47018983467180925, disc_loss = 0.06071669911209466
Trained batch 399 in epoch 2, gen_loss = 0.4702195628732443, disc_loss = 0.060595849474193525
Trained batch 400 in epoch 2, gen_loss = 0.47034473527696663, disc_loss = 0.06047996646722319
Trained batch 401 in epoch 2, gen_loss = 0.4702216802693125, disc_loss = 0.06051186946989848
Trained batch 402 in epoch 2, gen_loss = 0.47037050201934266, disc_loss = 0.060391969802019836
Trained batch 403 in epoch 2, gen_loss = 0.470268852934979, disc_loss = 0.060433574139583154
Trained batch 404 in epoch 2, gen_loss = 0.4703073689967026, disc_loss = 0.06038104646988673
Trained batch 405 in epoch 2, gen_loss = 0.4705392352759544, disc_loss = 0.060332965526702295
Trained batch 406 in epoch 2, gen_loss = 0.4705546337937254, disc_loss = 0.060436663264751944
Trained batch 407 in epoch 2, gen_loss = 0.4705537792806532, disc_loss = 0.06038901715553092
Trained batch 408 in epoch 2, gen_loss = 0.47063620282851687, disc_loss = 0.0602627534790461
Trained batch 409 in epoch 2, gen_loss = 0.4708783821361821, disc_loss = 0.06025224307483835
Trained batch 410 in epoch 2, gen_loss = 0.4707686520405929, disc_loss = 0.0601602217211975
Trained batch 411 in epoch 2, gen_loss = 0.47065494961819604, disc_loss = 0.06013787178281984
Trained batch 412 in epoch 2, gen_loss = 0.4705245468143112, disc_loss = 0.06004754758212201
Trained batch 413 in epoch 2, gen_loss = 0.4702726737168676, disc_loss = 0.05996049322291381
Trained batch 414 in epoch 2, gen_loss = 0.47045403525053736, disc_loss = 0.05985772395057671
Trained batch 415 in epoch 2, gen_loss = 0.47034120767448956, disc_loss = 0.05974170007595184
Trained batch 416 in epoch 2, gen_loss = 0.47009596385830027, disc_loss = 0.059864849270917744
Trained batch 417 in epoch 2, gen_loss = 0.4699972070147546, disc_loss = 0.059907743011035346
Trained batch 418 in epoch 2, gen_loss = 0.4699675087285782, disc_loss = 0.059862312710752846
Trained batch 419 in epoch 2, gen_loss = 0.4701265662198975, disc_loss = 0.05980011402917582
Trained batch 420 in epoch 2, gen_loss = 0.47021493117486496, disc_loss = 0.059728213202102094
Trained batch 421 in epoch 2, gen_loss = 0.4701113890838849, disc_loss = 0.05964521631064396
Trained batch 422 in epoch 2, gen_loss = 0.4699421467933249, disc_loss = 0.05957639961444
Trained batch 423 in epoch 2, gen_loss = 0.4698238570313409, disc_loss = 0.059659475380475724
Trained batch 424 in epoch 2, gen_loss = 0.46966277529211603, disc_loss = 0.05978776303174741
Trained batch 425 in epoch 2, gen_loss = 0.4695307261927027, disc_loss = 0.05969637375600426
Trained batch 426 in epoch 2, gen_loss = 0.4697246436352473, disc_loss = 0.05982282426561593
Trained batch 427 in epoch 2, gen_loss = 0.4696912292008088, disc_loss = 0.05974412235435725
Trained batch 428 in epoch 2, gen_loss = 0.46983442398218006, disc_loss = 0.05969361090242411
Trained batch 429 in epoch 2, gen_loss = 0.46984191862649693, disc_loss = 0.059650680746579934
Trained batch 430 in epoch 2, gen_loss = 0.4698224611182777, disc_loss = 0.05957195370970186
Trained batch 431 in epoch 2, gen_loss = 0.4698663762322179, disc_loss = 0.05952484464096078
Trained batch 432 in epoch 2, gen_loss = 0.46994464350627696, disc_loss = 0.05942819084580687
Trained batch 433 in epoch 2, gen_loss = 0.46991102280704655, disc_loss = 0.05932771606254928
Trained batch 434 in epoch 2, gen_loss = 0.4698138567222946, disc_loss = 0.05921554771926382
Trained batch 435 in epoch 2, gen_loss = 0.47002422959979523, disc_loss = 0.05931441963611837
Trained batch 436 in epoch 2, gen_loss = 0.4700758743613481, disc_loss = 0.05935981587636832
Trained batch 437 in epoch 2, gen_loss = 0.4700030702842425, disc_loss = 0.059255845322737206
Trained batch 438 in epoch 2, gen_loss = 0.470052933502849, disc_loss = 0.059194751258871615
Trained batch 439 in epoch 2, gen_loss = 0.47004682049155233, disc_loss = 0.05914418750379065
Trained batch 440 in epoch 2, gen_loss = 0.4699824922749785, disc_loss = 0.05904236799655081
Trained batch 441 in epoch 2, gen_loss = 0.4699099675427735, disc_loss = 0.059175157983791575
Trained batch 442 in epoch 2, gen_loss = 0.4699306539837986, disc_loss = 0.059480861473710823
Trained batch 443 in epoch 2, gen_loss = 0.4699868228924167, disc_loss = 0.05947966651827399
Trained batch 444 in epoch 2, gen_loss = 0.4696400306198034, disc_loss = 0.059744639540865514
Trained batch 445 in epoch 2, gen_loss = 0.4696421707424882, disc_loss = 0.05982850620318455
Trained batch 446 in epoch 2, gen_loss = 0.4697342928357306, disc_loss = 0.05979709001883064
Trained batch 447 in epoch 2, gen_loss = 0.469672817670341, disc_loss = 0.059769222942122724
Trained batch 448 in epoch 2, gen_loss = 0.46973274352821315, disc_loss = 0.05980833438650304
Trained batch 449 in epoch 2, gen_loss = 0.4697578086455663, disc_loss = 0.0597694883050604
Trained batch 450 in epoch 2, gen_loss = 0.46987702028450046, disc_loss = 0.05982852730169033
Trained batch 451 in epoch 2, gen_loss = 0.4699155261031294, disc_loss = 0.060011160795873576
Trained batch 452 in epoch 2, gen_loss = 0.46998362325411497, disc_loss = 0.059927113564935804
Trained batch 453 in epoch 2, gen_loss = 0.4698991570703784, disc_loss = 0.06001029114058397
Trained batch 454 in epoch 2, gen_loss = 0.469639503628343, disc_loss = 0.059972996908434474
Trained batch 455 in epoch 2, gen_loss = 0.4696410863676615, disc_loss = 0.06004030657462416
Trained batch 456 in epoch 2, gen_loss = 0.4696815461898528, disc_loss = 0.060010316935561483
Trained batch 457 in epoch 2, gen_loss = 0.4696925925375593, disc_loss = 0.06012425311092759
Trained batch 458 in epoch 2, gen_loss = 0.4695575117155877, disc_loss = 0.06009893801594904
Trained batch 459 in epoch 2, gen_loss = 0.46954504212607506, disc_loss = 0.060269565561421864
Trained batch 460 in epoch 2, gen_loss = 0.46955910098785436, disc_loss = 0.06022560916974365
Trained batch 461 in epoch 2, gen_loss = 0.46963322923813033, disc_loss = 0.060117092625604884
Trained batch 462 in epoch 2, gen_loss = 0.469676454304104, disc_loss = 0.060076405204727956
Trained batch 463 in epoch 2, gen_loss = 0.46963300440331984, disc_loss = 0.060021534623329306
Trained batch 464 in epoch 2, gen_loss = 0.4695069254726492, disc_loss = 0.06011018616557923
Trained batch 465 in epoch 2, gen_loss = 0.46965065144418133, disc_loss = 0.0603513512490597
Trained batch 466 in epoch 2, gen_loss = 0.46970471178183465, disc_loss = 0.06036197334803178
Trained batch 467 in epoch 2, gen_loss = 0.4696197737740655, disc_loss = 0.06042691356498493
Trained batch 468 in epoch 2, gen_loss = 0.46970710863690895, disc_loss = 0.060457294871375314
Trained batch 469 in epoch 2, gen_loss = 0.469834170316128, disc_loss = 0.060638872832258016
Trained batch 470 in epoch 2, gen_loss = 0.4699454146838745, disc_loss = 0.06056269798961699
Trained batch 471 in epoch 2, gen_loss = 0.4698575725621086, disc_loss = 0.06046036732387019
Trained batch 472 in epoch 2, gen_loss = 0.4697608075736693, disc_loss = 0.060443217999028166
Trained batch 473 in epoch 2, gen_loss = 0.4699194393580473, disc_loss = 0.060776694050011563
Trained batch 474 in epoch 2, gen_loss = 0.46979743210892927, disc_loss = 0.06076636267041689
Trained batch 475 in epoch 2, gen_loss = 0.4697863160311675, disc_loss = 0.06073970835706798
Trained batch 476 in epoch 2, gen_loss = 0.4697660672589668, disc_loss = 0.06083782221555741
Trained batch 477 in epoch 2, gen_loss = 0.46975352025929856, disc_loss = 0.06074988818727434
Trained batch 478 in epoch 2, gen_loss = 0.46969409937151785, disc_loss = 0.06075695746661881
Trained batch 479 in epoch 2, gen_loss = 0.4696624205758174, disc_loss = 0.06070441401194936
Trained batch 480 in epoch 2, gen_loss = 0.46957396048270245, disc_loss = 0.060734589521244574
Trained batch 481 in epoch 2, gen_loss = 0.4696530400470085, disc_loss = 0.060747049510270296
Trained batch 482 in epoch 2, gen_loss = 0.46960103289681193, disc_loss = 0.060940699093622264
Trained batch 483 in epoch 2, gen_loss = 0.46973285608547777, disc_loss = 0.060862287421987876
Trained batch 484 in epoch 2, gen_loss = 0.46973559076024085, disc_loss = 0.06075721205375397
Trained batch 485 in epoch 2, gen_loss = 0.46987492122032026, disc_loss = 0.060677481513401424
Trained batch 486 in epoch 2, gen_loss = 0.46982967498610884, disc_loss = 0.06061192462794498
Trained batch 487 in epoch 2, gen_loss = 0.46962790789662817, disc_loss = 0.060539574790784145
Trained batch 488 in epoch 2, gen_loss = 0.4694985392634854, disc_loss = 0.060500618391279855
Trained batch 489 in epoch 2, gen_loss = 0.4694672332734478, disc_loss = 0.060433086860278734
Trained batch 490 in epoch 2, gen_loss = 0.4697379281710219, disc_loss = 0.06038479488855133
Trained batch 491 in epoch 2, gen_loss = 0.46968291409131957, disc_loss = 0.060338105681746045
Trained batch 492 in epoch 2, gen_loss = 0.46963214197216846, disc_loss = 0.06026163155545479
Trained batch 493 in epoch 2, gen_loss = 0.4695630995368185, disc_loss = 0.06016324159900398
Trained batch 494 in epoch 2, gen_loss = 0.4695000262573512, disc_loss = 0.06006400886678485
Trained batch 495 in epoch 2, gen_loss = 0.4696419355008871, disc_loss = 0.05998313455981383
Trained batch 496 in epoch 2, gen_loss = 0.4697029986971581, disc_loss = 0.05993314492619283
Trained batch 497 in epoch 2, gen_loss = 0.46964306806225375, disc_loss = 0.05983387608264375
Trained batch 498 in epoch 2, gen_loss = 0.4695118899216394, disc_loss = 0.05973155680719114
Trained batch 499 in epoch 2, gen_loss = 0.46967972499132155, disc_loss = 0.0596352312406525
Trained batch 500 in epoch 2, gen_loss = 0.4696461735609287, disc_loss = 0.05954916414129966
Trained batch 501 in epoch 2, gen_loss = 0.46956784815427316, disc_loss = 0.05944533983200967
Trained batch 502 in epoch 2, gen_loss = 0.46968082298578373, disc_loss = 0.05960080355116968
Trained batch 503 in epoch 2, gen_loss = 0.4696016140163891, disc_loss = 0.059803629044576416
Trained batch 504 in epoch 2, gen_loss = 0.4695676893290907, disc_loss = 0.05978228612295767
Trained batch 505 in epoch 2, gen_loss = 0.4695922648718235, disc_loss = 0.05993128771315745
Trained batch 506 in epoch 2, gen_loss = 0.46953468580217755, disc_loss = 0.05994239558430877
Trained batch 507 in epoch 2, gen_loss = 0.469341187085223, disc_loss = 0.0599777963118789
Trained batch 508 in epoch 2, gen_loss = 0.46936540343672445, disc_loss = 0.05991358780768683
Trained batch 509 in epoch 2, gen_loss = 0.46940935230722614, disc_loss = 0.05986631441970958
Trained batch 510 in epoch 2, gen_loss = 0.46935956177179594, disc_loss = 0.05989804962529653
Trained batch 511 in epoch 2, gen_loss = 0.46942432306241244, disc_loss = 0.059810269542140304
Trained batch 512 in epoch 2, gen_loss = 0.4695621053842541, disc_loss = 0.05977922906558126
Trained batch 513 in epoch 2, gen_loss = 0.4694887492443337, disc_loss = 0.0596820601943431
Trained batch 514 in epoch 2, gen_loss = 0.4694406965403881, disc_loss = 0.05978397683792033
Trained batch 515 in epoch 2, gen_loss = 0.46945720287256465, disc_loss = 0.05975932847571292
Trained batch 516 in epoch 2, gen_loss = 0.469360501611717, disc_loss = 0.05967678952731581
Trained batch 517 in epoch 2, gen_loss = 0.46937347770197513, disc_loss = 0.059648773142111464
Trained batch 518 in epoch 2, gen_loss = 0.46932746805896647, disc_loss = 0.059805858185827045
Trained batch 519 in epoch 2, gen_loss = 0.46941849738359454, disc_loss = 0.05975659638822365
Trained batch 520 in epoch 2, gen_loss = 0.46954312480113786, disc_loss = 0.05998577772605728
Trained batch 521 in epoch 2, gen_loss = 0.4694390842170094, disc_loss = 0.05999833414102708
Trained batch 522 in epoch 2, gen_loss = 0.46924868607840164, disc_loss = 0.06007549783702847
Trained batch 523 in epoch 2, gen_loss = 0.4691801125766667, disc_loss = 0.060099624127561924
Trained batch 524 in epoch 2, gen_loss = 0.46908142884572346, disc_loss = 0.06003496616546597
Trained batch 525 in epoch 2, gen_loss = 0.46907333774711696, disc_loss = 0.060066393241923685
Trained batch 526 in epoch 2, gen_loss = 0.4688798252500212, disc_loss = 0.059968281478976274
Trained batch 527 in epoch 2, gen_loss = 0.4689836185989958, disc_loss = 0.05991466210583563
Trained batch 528 in epoch 2, gen_loss = 0.4689337269795639, disc_loss = 0.05983921781442848
Trained batch 529 in epoch 2, gen_loss = 0.46891201059773285, disc_loss = 0.059871389760793946
Trained batch 530 in epoch 2, gen_loss = 0.468967046665831, disc_loss = 0.059784357400923235
Trained batch 531 in epoch 2, gen_loss = 0.4690123276602953, disc_loss = 0.05971170466260186
Trained batch 532 in epoch 2, gen_loss = 0.46915428544522225, disc_loss = 0.05974084474530777
Trained batch 533 in epoch 2, gen_loss = 0.4691518045096808, disc_loss = 0.0596981701364371
Trained batch 534 in epoch 2, gen_loss = 0.4691500782409561, disc_loss = 0.05961486188712243
Trained batch 535 in epoch 2, gen_loss = 0.46917563276504404, disc_loss = 0.059528390317460274
Trained batch 536 in epoch 2, gen_loss = 0.4691066242463096, disc_loss = 0.059439520053288016
Trained batch 537 in epoch 2, gen_loss = 0.46925284007224893, disc_loss = 0.05935321361878991
Trained batch 538 in epoch 2, gen_loss = 0.4692031729530978, disc_loss = 0.05933738722429647
Trained batch 539 in epoch 2, gen_loss = 0.4692867093064167, disc_loss = 0.05924756833076201
Trained batch 540 in epoch 2, gen_loss = 0.46928368098414097, disc_loss = 0.05919339421571899
Trained batch 541 in epoch 2, gen_loss = 0.46931783569035057, disc_loss = 0.05911742015896413
Trained batch 542 in epoch 2, gen_loss = 0.4694075286388397, disc_loss = 0.05904857019343264
Trained batch 543 in epoch 2, gen_loss = 0.4696490667650805, disc_loss = 0.05907022193765871
Trained batch 544 in epoch 2, gen_loss = 0.4696551334967307, disc_loss = 0.05901158534229622
Trained batch 545 in epoch 2, gen_loss = 0.4696838377596258, disc_loss = 0.0589227538723021
Trained batch 546 in epoch 2, gen_loss = 0.46982392281893187, disc_loss = 0.05883997479552434
Trained batch 547 in epoch 2, gen_loss = 0.4699724301369521, disc_loss = 0.058777918189383334
Trained batch 548 in epoch 2, gen_loss = 0.4700716345253755, disc_loss = 0.05873444654685335
Trained batch 549 in epoch 2, gen_loss = 0.4701761984825134, disc_loss = 0.05864980469034477
Trained batch 550 in epoch 2, gen_loss = 0.4702501782704611, disc_loss = 0.05861473768719636
Trained batch 551 in epoch 2, gen_loss = 0.47016689316302107, disc_loss = 0.05852786990462978
Trained batch 552 in epoch 2, gen_loss = 0.47011051902288126, disc_loss = 0.05844714134513901
Trained batch 553 in epoch 2, gen_loss = 0.4700220923884251, disc_loss = 0.058361775651977595
Trained batch 554 in epoch 2, gen_loss = 0.4700289086178616, disc_loss = 0.05826876727142581
Trained batch 555 in epoch 2, gen_loss = 0.4702427789247293, disc_loss = 0.05824270440942253
Trained batch 556 in epoch 2, gen_loss = 0.470143439686277, disc_loss = 0.05817562194718332
Trained batch 557 in epoch 2, gen_loss = 0.4700122214987287, disc_loss = 0.05819282547393847
Trained batch 558 in epoch 2, gen_loss = 0.4700013597984007, disc_loss = 0.058285132385390494
Trained batch 559 in epoch 2, gen_loss = 0.470115443904485, disc_loss = 0.05820807034282812
Trained batch 560 in epoch 2, gen_loss = 0.4700290464037455, disc_loss = 0.058129076552104184
Trained batch 561 in epoch 2, gen_loss = 0.4698673500497146, disc_loss = 0.05902979393685204
Trained batch 562 in epoch 2, gen_loss = 0.4698556877580036, disc_loss = 0.059378856405959884
Trained batch 563 in epoch 2, gen_loss = 0.46977256935961703, disc_loss = 0.05946897405549778
Trained batch 564 in epoch 2, gen_loss = 0.46975630120893497, disc_loss = 0.05953722578366246
Trained batch 565 in epoch 2, gen_loss = 0.4698652923107147, disc_loss = 0.05968121126583734
Trained batch 566 in epoch 2, gen_loss = 0.4697816952195748, disc_loss = 0.06004040593008726
Trained batch 567 in epoch 2, gen_loss = 0.46972549759166343, disc_loss = 0.060106592797215135
Trained batch 568 in epoch 2, gen_loss = 0.4698349875389796, disc_loss = 0.06022522973652883
Trained batch 569 in epoch 2, gen_loss = 0.46989006222340096, disc_loss = 0.06020212408089847
Trained batch 570 in epoch 2, gen_loss = 0.4698541528706793, disc_loss = 0.06012404061390671
Trained batch 571 in epoch 2, gen_loss = 0.4697832069717921, disc_loss = 0.06009176046379119
Trained batch 572 in epoch 2, gen_loss = 0.4699301004513812, disc_loss = 0.0604928861019473
Trained batch 573 in epoch 2, gen_loss = 0.4698996159153948, disc_loss = 0.06048088506324937
Trained batch 574 in epoch 2, gen_loss = 0.469839840453604, disc_loss = 0.060507708008846514
Trained batch 575 in epoch 2, gen_loss = 0.4698935134543313, disc_loss = 0.060441391443924256
Trained batch 576 in epoch 2, gen_loss = 0.47002553185722445, disc_loss = 0.060921075237362905
Trained batch 577 in epoch 2, gen_loss = 0.4699353710280983, disc_loss = 0.06111168637581711
Trained batch 578 in epoch 2, gen_loss = 0.4698039042620255, disc_loss = 0.06121957759390584
Trained batch 579 in epoch 2, gen_loss = 0.4697970562967761, disc_loss = 0.06118680618799709
Trained batch 580 in epoch 2, gen_loss = 0.46976848108222685, disc_loss = 0.061188325810081066
Trained batch 581 in epoch 2, gen_loss = 0.46976760572584225, disc_loss = 0.06128633748003861
Trained batch 582 in epoch 2, gen_loss = 0.4697834107111085, disc_loss = 0.061372231658528946
Trained batch 583 in epoch 2, gen_loss = 0.4697543450006067, disc_loss = 0.06141468241957514
Trained batch 584 in epoch 2, gen_loss = 0.4699133123088087, disc_loss = 0.061442835207105195
Trained batch 585 in epoch 2, gen_loss = 0.4699159721770791, disc_loss = 0.06138323501559807
Trained batch 586 in epoch 2, gen_loss = 0.46993641857394164, disc_loss = 0.061331276965900315
Trained batch 587 in epoch 2, gen_loss = 0.4698402305342713, disc_loss = 0.06138661278722187
Trained batch 588 in epoch 2, gen_loss = 0.46981537094140496, disc_loss = 0.06139179200711953
Trained batch 589 in epoch 2, gen_loss = 0.4696942686529483, disc_loss = 0.06138880635943201
Trained batch 590 in epoch 2, gen_loss = 0.4697220338076706, disc_loss = 0.061413980999964646
Trained batch 591 in epoch 2, gen_loss = 0.46972458703896486, disc_loss = 0.061593231334464274
Trained batch 592 in epoch 2, gen_loss = 0.4696728816321889, disc_loss = 0.06153248514175968
Trained batch 593 in epoch 2, gen_loss = 0.46974769796586596, disc_loss = 0.06153264503004124
Trained batch 594 in epoch 2, gen_loss = 0.46959038361781785, disc_loss = 0.06147606848825176
Trained batch 595 in epoch 2, gen_loss = 0.4695005746395796, disc_loss = 0.061511995159902126
Trained batch 596 in epoch 2, gen_loss = 0.4694493497835731, disc_loss = 0.06149203849603832
Trained batch 597 in epoch 2, gen_loss = 0.46939797858928756, disc_loss = 0.06161582037762904
Trained batch 598 in epoch 2, gen_loss = 0.4693331500027136, disc_loss = 0.0615354903113837
Trained batch 599 in epoch 2, gen_loss = 0.46944054240981736, disc_loss = 0.06168838790152222
Trained batch 600 in epoch 2, gen_loss = 0.46935873182363397, disc_loss = 0.06161676911472927
Trained batch 601 in epoch 2, gen_loss = 0.46926866590580674, disc_loss = 0.06163956856268436
Trained batch 602 in epoch 2, gen_loss = 0.4692424262439829, disc_loss = 0.061559772206961516
Trained batch 603 in epoch 2, gen_loss = 0.469160992874215, disc_loss = 0.06148531426527593
Trained batch 604 in epoch 2, gen_loss = 0.4690707490956488, disc_loss = 0.061416358262115764
Trained batch 605 in epoch 2, gen_loss = 0.4690420608906069, disc_loss = 0.061456313905407595
Trained batch 606 in epoch 2, gen_loss = 0.46893723571712925, disc_loss = 0.06150370883054209
Trained batch 607 in epoch 2, gen_loss = 0.46890561106173617, disc_loss = 0.06144475114170315
Trained batch 608 in epoch 2, gen_loss = 0.4688463535019134, disc_loss = 0.06140412064345648
Trained batch 609 in epoch 2, gen_loss = 0.46881449701356104, disc_loss = 0.061442710283655125
Trained batch 610 in epoch 2, gen_loss = 0.4686753237208446, disc_loss = 0.061402800206381544
Trained batch 611 in epoch 2, gen_loss = 0.4686705469111212, disc_loss = 0.061318539146918295
Trained batch 612 in epoch 2, gen_loss = 0.46871830851179935, disc_loss = 0.06122756887266798
Trained batch 613 in epoch 2, gen_loss = 0.46872616707307896, disc_loss = 0.06114011722941449
Trained batch 614 in epoch 2, gen_loss = 0.4686992616188235, disc_loss = 0.061091714161561755
Trained batch 615 in epoch 2, gen_loss = 0.46868726915933867, disc_loss = 0.061049992094638864
Trained batch 616 in epoch 2, gen_loss = 0.4687726236336428, disc_loss = 0.06104897167624202
Trained batch 617 in epoch 2, gen_loss = 0.4687218118254035, disc_loss = 0.06097551221540348
Trained batch 618 in epoch 2, gen_loss = 0.46866509515750004, disc_loss = 0.060902585526732715
Trained batch 619 in epoch 2, gen_loss = 0.4686850716029444, disc_loss = 0.060898144702397045
Trained batch 620 in epoch 2, gen_loss = 0.4686660721970065, disc_loss = 0.06081101039931442
Trained batch 621 in epoch 2, gen_loss = 0.46864314981020533, disc_loss = 0.06089202923867911
Trained batch 622 in epoch 2, gen_loss = 0.4686975135179431, disc_loss = 0.06081126858876423
Trained batch 623 in epoch 2, gen_loss = 0.46864243993201316, disc_loss = 0.0607270547024643
Trained batch 624 in epoch 2, gen_loss = 0.4687404455661774, disc_loss = 0.06079294127970934
Trained batch 625 in epoch 2, gen_loss = 0.46883925000509136, disc_loss = 0.06071160986168554
Trained batch 626 in epoch 2, gen_loss = 0.4688429111879218, disc_loss = 0.06066818792147167
Trained batch 627 in epoch 2, gen_loss = 0.46895850340651857, disc_loss = 0.06058802660762267
Trained batch 628 in epoch 2, gen_loss = 0.46900942357810765, disc_loss = 0.06052157208056964
Trained batch 629 in epoch 2, gen_loss = 0.4690155318332097, disc_loss = 0.06045960797115214
Trained batch 630 in epoch 2, gen_loss = 0.4690773465837427, disc_loss = 0.06038923817354649
Trained batch 631 in epoch 2, gen_loss = 0.4690723121637785, disc_loss = 0.06033637553093884
Trained batch 632 in epoch 2, gen_loss = 0.46910090789222414, disc_loss = 0.06025249959671455
Trained batch 633 in epoch 2, gen_loss = 0.4691293967259043, disc_loss = 0.06017435090513518
Trained batch 634 in epoch 2, gen_loss = 0.46917389499859546, disc_loss = 0.060100171258159744
Trained batch 635 in epoch 2, gen_loss = 0.4692859136083591, disc_loss = 0.06005803602908697
Trained batch 636 in epoch 2, gen_loss = 0.4692744177589237, disc_loss = 0.060000781283466795
Trained batch 637 in epoch 2, gen_loss = 0.46931326174437066, disc_loss = 0.05991723944964383
Trained batch 638 in epoch 2, gen_loss = 0.4692702654848263, disc_loss = 0.0598584632360098
Trained batch 639 in epoch 2, gen_loss = 0.4693394088651985, disc_loss = 0.05993569470956572
Trained batch 640 in epoch 2, gen_loss = 0.4694635802516699, disc_loss = 0.060130890009143095
Trained batch 641 in epoch 2, gen_loss = 0.46948215383978276, disc_loss = 0.060068567049170254
Trained batch 642 in epoch 2, gen_loss = 0.4693447704170577, disc_loss = 0.060147122302545965
Trained batch 643 in epoch 2, gen_loss = 0.4695131142409692, disc_loss = 0.0601929115798174
Trained batch 644 in epoch 2, gen_loss = 0.4695563618988954, disc_loss = 0.06022939139168507
Trained batch 645 in epoch 2, gen_loss = 0.469534740174887, disc_loss = 0.06016127434818668
Trained batch 646 in epoch 2, gen_loss = 0.4695655779086825, disc_loss = 0.060105476983991296
Trained batch 647 in epoch 2, gen_loss = 0.46953125127855644, disc_loss = 0.060123014103558005
Trained batch 648 in epoch 2, gen_loss = 0.4696338402196329, disc_loss = 0.06006858921258241
Trained batch 649 in epoch 2, gen_loss = 0.4696703421152555, disc_loss = 0.060031884104156726
Trained batch 650 in epoch 2, gen_loss = 0.46962048829792097, disc_loss = 0.05996621162137059
Trained batch 651 in epoch 2, gen_loss = 0.46965996431975277, disc_loss = 0.0599839133817554
Trained batch 652 in epoch 2, gen_loss = 0.4697641486139429, disc_loss = 0.059998047697125356
Trained batch 653 in epoch 2, gen_loss = 0.4697981985792837, disc_loss = 0.059917055464147474
Trained batch 654 in epoch 2, gen_loss = 0.46997340012142674, disc_loss = 0.05985609818008224
Trained batch 655 in epoch 2, gen_loss = 0.46989925237508806, disc_loss = 0.05987426281477915
Trained batch 656 in epoch 2, gen_loss = 0.4698878085322939, disc_loss = 0.059823837455169296
Trained batch 657 in epoch 2, gen_loss = 0.4698910202751768, disc_loss = 0.05974460137855137
Trained batch 658 in epoch 2, gen_loss = 0.46996440009209745, disc_loss = 0.05967295774836687
Trained batch 659 in epoch 2, gen_loss = 0.469870030338114, disc_loss = 0.05964010122062808
Trained batch 660 in epoch 2, gen_loss = 0.4698199672616015, disc_loss = 0.059567243331386716
Trained batch 661 in epoch 2, gen_loss = 0.46987216093569, disc_loss = 0.059538062962948196
Trained batch 662 in epoch 2, gen_loss = 0.4698770072305544, disc_loss = 0.059492598429636896
Trained batch 663 in epoch 2, gen_loss = 0.4701195207525449, disc_loss = 0.05957340419079256
Trained batch 664 in epoch 2, gen_loss = 0.4701902161863514, disc_loss = 0.05950051490077399
Trained batch 665 in epoch 2, gen_loss = 0.4701404813621137, disc_loss = 0.05955852145278776
Trained batch 666 in epoch 2, gen_loss = 0.470183372318834, disc_loss = 0.05972600027896475
Trained batch 667 in epoch 2, gen_loss = 0.470100169454863, disc_loss = 0.0596877488636685
Trained batch 668 in epoch 2, gen_loss = 0.4699424052185007, disc_loss = 0.05964135332381066
Trained batch 669 in epoch 2, gen_loss = 0.4698513372175729, disc_loss = 0.05970798338860718
Trained batch 670 in epoch 2, gen_loss = 0.4699360688734694, disc_loss = 0.0597243817736868
Trained batch 671 in epoch 2, gen_loss = 0.47005267569883946, disc_loss = 0.05984383233312872
Trained batch 672 in epoch 2, gen_loss = 0.47007900401174935, disc_loss = 0.05977313647414786
Trained batch 673 in epoch 2, gen_loss = 0.4700524801228096, disc_loss = 0.05982884868166965
Trained batch 674 in epoch 2, gen_loss = 0.4699720569893166, disc_loss = 0.05976993938425073
Trained batch 675 in epoch 2, gen_loss = 0.470072313525973, disc_loss = 0.05969916361373072
Trained batch 676 in epoch 2, gen_loss = 0.4699597359143825, disc_loss = 0.059694550322035834
Trained batch 677 in epoch 2, gen_loss = 0.4699744651187486, disc_loss = 0.059683903899307535
Trained batch 678 in epoch 2, gen_loss = 0.46987152626307266, disc_loss = 0.059654682437136265
Trained batch 679 in epoch 2, gen_loss = 0.46982839550165567, disc_loss = 0.05957753355340922
Trained batch 680 in epoch 2, gen_loss = 0.4699339836441998, disc_loss = 0.05956127151037278
Trained batch 681 in epoch 2, gen_loss = 0.46983855940904085, disc_loss = 0.05950099848418379
Trained batch 682 in epoch 2, gen_loss = 0.46990981942389054, disc_loss = 0.05944220753083903
Trained batch 683 in epoch 2, gen_loss = 0.4700224318960954, disc_loss = 0.05951072979032209
Trained batch 684 in epoch 2, gen_loss = 0.46994975674761474, disc_loss = 0.059509708996127994
Trained batch 685 in epoch 2, gen_loss = 0.4699676960446049, disc_loss = 0.059454585520588625
Trained batch 686 in epoch 2, gen_loss = 0.46995116468773834, disc_loss = 0.059414925858964046
Trained batch 687 in epoch 2, gen_loss = 0.4700612579147483, disc_loss = 0.0595625072371128
Trained batch 688 in epoch 2, gen_loss = 0.47004422234000937, disc_loss = 0.05955575254079393
Trained batch 689 in epoch 2, gen_loss = 0.46994546859160713, disc_loss = 0.05950868736034718
Trained batch 690 in epoch 2, gen_loss = 0.46995364010937823, disc_loss = 0.05946356090467676
Trained batch 691 in epoch 2, gen_loss = 0.4699317699222895, disc_loss = 0.05950950506019455
Trained batch 692 in epoch 2, gen_loss = 0.47001050062165806, disc_loss = 0.059456636906100216
Trained batch 693 in epoch 2, gen_loss = 0.47004055929630567, disc_loss = 0.05938939619487318
Trained batch 694 in epoch 2, gen_loss = 0.47007601822880535, disc_loss = 0.05931421709012428
Trained batch 695 in epoch 2, gen_loss = 0.4700762029608776, disc_loss = 0.059267309182537614
Trained batch 696 in epoch 2, gen_loss = 0.4699872422167013, disc_loss = 0.059306285429580226
Trained batch 697 in epoch 2, gen_loss = 0.470063133320016, disc_loss = 0.05926642260436812
Trained batch 698 in epoch 2, gen_loss = 0.4701921853299475, disc_loss = 0.059329803568045895
Trained batch 699 in epoch 2, gen_loss = 0.4700855862242835, disc_loss = 0.05933702327177993
Trained batch 700 in epoch 2, gen_loss = 0.47003123083400317, disc_loss = 0.05938399553208608
Trained batch 701 in epoch 2, gen_loss = 0.47020426341611093, disc_loss = 0.0594610280511195
Trained batch 702 in epoch 2, gen_loss = 0.4701911118596919, disc_loss = 0.05961055990976214
Trained batch 703 in epoch 2, gen_loss = 0.47039216612889007, disc_loss = 0.05970651712347965
Trained batch 704 in epoch 2, gen_loss = 0.47039076715496414, disc_loss = 0.05965666190608807
Trained batch 705 in epoch 2, gen_loss = 0.47042092507858113, disc_loss = 0.05969541972481959
Trained batch 706 in epoch 2, gen_loss = 0.47046857840438205, disc_loss = 0.059672069293216314
Trained batch 707 in epoch 2, gen_loss = 0.4704084925900745, disc_loss = 0.05961615247467775
Trained batch 708 in epoch 2, gen_loss = 0.4705197708563004, disc_loss = 0.05954692283269591
Trained batch 709 in epoch 2, gen_loss = 0.47036809698796606, disc_loss = 0.059490423603639216
Trained batch 710 in epoch 2, gen_loss = 0.47036272626888903, disc_loss = 0.059477583942712194
Trained batch 711 in epoch 2, gen_loss = 0.4704423239977842, disc_loss = 0.05942712953769382
Trained batch 712 in epoch 2, gen_loss = 0.47054373996455073, disc_loss = 0.059379768785125825
Trained batch 713 in epoch 2, gen_loss = 0.47059661780251844, disc_loss = 0.05931791494775261
Trained batch 714 in epoch 2, gen_loss = 0.47065408609130166, disc_loss = 0.05925325216608239
Trained batch 715 in epoch 2, gen_loss = 0.4706852434816973, disc_loss = 0.0592013986913914
Trained batch 716 in epoch 2, gen_loss = 0.4707434613418712, disc_loss = 0.059137749654530565
Trained batch 717 in epoch 2, gen_loss = 0.4708721142542395, disc_loss = 0.05906512812143166
Trained batch 718 in epoch 2, gen_loss = 0.4708596443930985, disc_loss = 0.05899820541924122
Trained batch 719 in epoch 2, gen_loss = 0.4708907761507564, disc_loss = 0.05892888286357952
Trained batch 720 in epoch 2, gen_loss = 0.4709050685125978, disc_loss = 0.058859208211220086
Trained batch 721 in epoch 2, gen_loss = 0.4709545296315011, disc_loss = 0.0587913298907166
Trained batch 722 in epoch 2, gen_loss = 0.47091780056762167, disc_loss = 0.05871756552212342
Trained batch 723 in epoch 2, gen_loss = 0.47087942413697587, disc_loss = 0.058665466858897335
Trained batch 724 in epoch 2, gen_loss = 0.4708239496576375, disc_loss = 0.05860977608453611
Trained batch 725 in epoch 2, gen_loss = 0.4708721200543002, disc_loss = 0.05859769958638414
Trained batch 726 in epoch 2, gen_loss = 0.47100145514270464, disc_loss = 0.05854164783239488
Trained batch 727 in epoch 2, gen_loss = 0.47104986990382386, disc_loss = 0.058543209333208154
Trained batch 728 in epoch 2, gen_loss = 0.4710649738014153, disc_loss = 0.058493421392563846
Trained batch 729 in epoch 2, gen_loss = 0.47103792702498504, disc_loss = 0.05849665106491071
Trained batch 730 in epoch 2, gen_loss = 0.4709644321296186, disc_loss = 0.058454558412543156
Trained batch 731 in epoch 2, gen_loss = 0.47090322434739335, disc_loss = 0.05839230047915477
Trained batch 732 in epoch 2, gen_loss = 0.4709247787766372, disc_loss = 0.05834490116202815
Trained batch 733 in epoch 2, gen_loss = 0.4710436426407635, disc_loss = 0.05828127546403405
Trained batch 734 in epoch 2, gen_loss = 0.4710077175883209, disc_loss = 0.05821761570896218
Trained batch 735 in epoch 2, gen_loss = 0.471044462012208, disc_loss = 0.05822774610841525
Trained batch 736 in epoch 2, gen_loss = 0.47112654483140404, disc_loss = 0.05817527565195287
Trained batch 737 in epoch 2, gen_loss = 0.4711524314754377, disc_loss = 0.05814829720739467
Trained batch 738 in epoch 2, gen_loss = 0.47124375465435653, disc_loss = 0.05813678849175956
Trained batch 739 in epoch 2, gen_loss = 0.47120444500768505, disc_loss = 0.05808219162470384
Trained batch 740 in epoch 2, gen_loss = 0.47134615575414596, disc_loss = 0.05802993285727364
Trained batch 741 in epoch 2, gen_loss = 0.47150960821668414, disc_loss = 0.05797220429034045
Trained batch 742 in epoch 2, gen_loss = 0.4715276253014843, disc_loss = 0.05793556197098936
Trained batch 743 in epoch 2, gen_loss = 0.471465337260436, disc_loss = 0.05791024172363142
Trained batch 744 in epoch 2, gen_loss = 0.47145933264853973, disc_loss = 0.0580535720821295
Trained batch 745 in epoch 2, gen_loss = 0.47137778541997033, disc_loss = 0.05807819476740649
Testing Epoch 2

Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.4280190169811249, disc_loss = 0.046517837792634964
Trained batch 1 in epoch 3, gen_loss = 0.44147737324237823, disc_loss = 0.056321920827031136
Trained batch 2 in epoch 3, gen_loss = 0.45045603315035504, disc_loss = 0.13839017475644746
Trained batch 3 in epoch 3, gen_loss = 0.4423012360930443, disc_loss = 0.1387396017089486
Trained batch 4 in epoch 3, gen_loss = 0.4396376729011536, disc_loss = 0.1136924447491765
Trained batch 5 in epoch 3, gen_loss = 0.44588400920232135, disc_loss = 0.10280410898849368
Trained batch 6 in epoch 3, gen_loss = 0.4572684509413583, disc_loss = 0.09157870483717748
Trained batch 7 in epoch 3, gen_loss = 0.4561983123421669, disc_loss = 0.08259975735563785
Trained batch 8 in epoch 3, gen_loss = 0.44891101121902466, disc_loss = 0.07781253931009108
Trained batch 9 in epoch 3, gen_loss = 0.4503679096698761, disc_loss = 0.07241905005648733
Trained batch 10 in epoch 3, gen_loss = 0.4615306854248047, disc_loss = 0.06823153802278367
Trained batch 11 in epoch 3, gen_loss = 0.46795156101385754, disc_loss = 0.06376013299450278
Trained batch 12 in epoch 3, gen_loss = 0.4698725709548363, disc_loss = 0.06153152696788311
Trained batch 13 in epoch 3, gen_loss = 0.4780080148151943, disc_loss = 0.0615054742832269
Trained batch 14 in epoch 3, gen_loss = 0.47938419977823893, disc_loss = 0.062051965420444805
Trained batch 15 in epoch 3, gen_loss = 0.4752911813557148, disc_loss = 0.06215112435165793
Trained batch 16 in epoch 3, gen_loss = 0.47231068330652576, disc_loss = 0.06064086133504615
Trained batch 17 in epoch 3, gen_loss = 0.47119931711090934, disc_loss = 0.05765330043828322
Trained batch 18 in epoch 3, gen_loss = 0.4712487474868172, disc_loss = 0.055292560645428146
Trained batch 19 in epoch 3, gen_loss = 0.47381862848997114, disc_loss = 0.05790174358990043
Trained batch 20 in epoch 3, gen_loss = 0.47066994366191683, disc_loss = 0.05887647237007817
Trained batch 21 in epoch 3, gen_loss = 0.472229926423593, disc_loss = 0.058310194427824834
Trained batch 22 in epoch 3, gen_loss = 0.46946506526159204, disc_loss = 0.05626687170613719
Trained batch 23 in epoch 3, gen_loss = 0.4713151368002097, disc_loss = 0.05530812783399597
Trained batch 24 in epoch 3, gen_loss = 0.4733300507068634, disc_loss = 0.05371093342080712
Trained batch 25 in epoch 3, gen_loss = 0.47016763343260837, disc_loss = 0.05492291350562412
Trained batch 26 in epoch 3, gen_loss = 0.4717702700032128, disc_loss = 0.05397791210217057
Trained batch 27 in epoch 3, gen_loss = 0.47088281490973066, disc_loss = 0.05290934338700026
Trained batch 28 in epoch 3, gen_loss = 0.4713199919667737, disc_loss = 0.05314523060324377
Trained batch 29 in epoch 3, gen_loss = 0.47304370005925495, disc_loss = 0.05480563120606045
Trained batch 30 in epoch 3, gen_loss = 0.4746849940669152, disc_loss = 0.05338264366371497
Trained batch 31 in epoch 3, gen_loss = 0.4741072114557028, disc_loss = 0.05237463834055234
Trained batch 32 in epoch 3, gen_loss = 0.4751012921333313, disc_loss = 0.051159698219800535
Trained batch 33 in epoch 3, gen_loss = 0.47606537973179536, disc_loss = 0.05010881832362536
Trained batch 34 in epoch 3, gen_loss = 0.47595309785434176, disc_loss = 0.049833242688328026
Trained batch 35 in epoch 3, gen_loss = 0.4763237171702915, disc_loss = 0.04877216212399718
Trained batch 36 in epoch 3, gen_loss = 0.47754962379867966, disc_loss = 0.04886120254475925
Trained batch 37 in epoch 3, gen_loss = 0.4770352275748002, disc_loss = 0.049092931562642515
Trained batch 38 in epoch 3, gen_loss = 0.47663867932099563, disc_loss = 0.05039407254363864
Trained batch 39 in epoch 3, gen_loss = 0.4768357194960117, disc_loss = 0.04942428310168907
Trained batch 40 in epoch 3, gen_loss = 0.4771122023826692, disc_loss = 0.04855034190298217
Trained batch 41 in epoch 3, gen_loss = 0.47751255404381526, disc_loss = 0.04778074973174149
Trained batch 42 in epoch 3, gen_loss = 0.47636649497719696, disc_loss = 0.04745104591643741
Trained batch 43 in epoch 3, gen_loss = 0.4754581553014842, disc_loss = 0.04718050296122039
Trained batch 44 in epoch 3, gen_loss = 0.47689071032736036, disc_loss = 0.04653951350806488
Trained batch 45 in epoch 3, gen_loss = 0.47475897941900336, disc_loss = 0.04704648279584944
Trained batch 46 in epoch 3, gen_loss = 0.4735281213800958, disc_loss = 0.04713524076493179
Trained batch 47 in epoch 3, gen_loss = 0.4752911254763603, disc_loss = 0.04834182194705742
Trained batch 48 in epoch 3, gen_loss = 0.4744787082380178, disc_loss = 0.04759097162976253
Trained batch 49 in epoch 3, gen_loss = 0.475028555393219, disc_loss = 0.047598036704584956
Trained batch 50 in epoch 3, gen_loss = 0.4758036323622161, disc_loss = 0.04697119914835282
Trained batch 51 in epoch 3, gen_loss = 0.47584816068410873, disc_loss = 0.04628261143807322
Trained batch 52 in epoch 3, gen_loss = 0.4776348454772301, disc_loss = 0.046284895961366174
Trained batch 53 in epoch 3, gen_loss = 0.4775600913498137, disc_loss = 0.045608266368853276
Trained batch 54 in epoch 3, gen_loss = 0.47757532704960215, disc_loss = 0.047481464806266804
Trained batch 55 in epoch 3, gen_loss = 0.4784244958843504, disc_loss = 0.0469823391259914
Trained batch 56 in epoch 3, gen_loss = 0.4808135419561152, disc_loss = 0.049413447260137716
Trained batch 57 in epoch 3, gen_loss = 0.4793241486467164, disc_loss = 0.04880575696809281
Trained batch 58 in epoch 3, gen_loss = 0.4783881948155872, disc_loss = 0.04888725321013796
Trained batch 59 in epoch 3, gen_loss = 0.47809146642684935, disc_loss = 0.04934379969878743
Trained batch 60 in epoch 3, gen_loss = 0.47778233006352283, disc_loss = 0.04903786436303473
Trained batch 61 in epoch 3, gen_loss = 0.4771655423025931, disc_loss = 0.049103865963256645
Trained batch 62 in epoch 3, gen_loss = 0.47685767450029887, disc_loss = 0.04906255251447123
Trained batch 63 in epoch 3, gen_loss = 0.47715842723846436, disc_loss = 0.052004738558025565
Trained batch 64 in epoch 3, gen_loss = 0.4761174128605769, disc_loss = 0.05325834094188534
Trained batch 65 in epoch 3, gen_loss = 0.4754507681637099, disc_loss = 0.052898204257485995
Trained batch 66 in epoch 3, gen_loss = 0.4747741956319382, disc_loss = 0.05297572206733609
Trained batch 67 in epoch 3, gen_loss = 0.474908214281587, disc_loss = 0.05407497228588909
Trained batch 68 in epoch 3, gen_loss = 0.4748320216717927, disc_loss = 0.05462078152872298
Trained batch 69 in epoch 3, gen_loss = 0.473429788010461, disc_loss = 0.055507831667949044
Trained batch 70 in epoch 3, gen_loss = 0.4735280283739869, disc_loss = 0.05496740741917575
Trained batch 71 in epoch 3, gen_loss = 0.47366028899947804, disc_loss = 0.05496591434995127
Trained batch 72 in epoch 3, gen_loss = 0.47346550267036647, disc_loss = 0.05472336201099296
Trained batch 73 in epoch 3, gen_loss = 0.47181357322512446, disc_loss = 0.05552012857830001
Trained batch 74 in epoch 3, gen_loss = 0.4722802909215291, disc_loss = 0.057024154880394536
Trained batch 75 in epoch 3, gen_loss = 0.47112546939598887, disc_loss = 0.0569296712239616
Trained batch 76 in epoch 3, gen_loss = 0.470791283365968, disc_loss = 0.05695203858028565
Trained batch 77 in epoch 3, gen_loss = 0.47024831022971714, disc_loss = 0.056682111378997944
Trained batch 78 in epoch 3, gen_loss = 0.46995131803464285, disc_loss = 0.056498322983661406
Trained batch 79 in epoch 3, gen_loss = 0.46894504874944687, disc_loss = 0.0566233929421287
Trained batch 80 in epoch 3, gen_loss = 0.4685338592087781, disc_loss = 0.05672818111301756
Trained batch 81 in epoch 3, gen_loss = 0.468959142885557, disc_loss = 0.05632304102068812
Trained batch 82 in epoch 3, gen_loss = 0.4691720759294119, disc_loss = 0.05623102423185146
Trained batch 83 in epoch 3, gen_loss = 0.46850343651714776, disc_loss = 0.056107956489237644
Trained batch 84 in epoch 3, gen_loss = 0.46850207798621235, disc_loss = 0.056039814097697246
Trained batch 85 in epoch 3, gen_loss = 0.4681934939567433, disc_loss = 0.05574117803967796
Trained batch 86 in epoch 3, gen_loss = 0.46849497193577644, disc_loss = 0.05572066185781839
Trained batch 87 in epoch 3, gen_loss = 0.4685929275371812, disc_loss = 0.05520119130166925
Trained batch 88 in epoch 3, gen_loss = 0.46825341562206824, disc_loss = 0.055145286876457124
Trained batch 89 in epoch 3, gen_loss = 0.46793804698520236, disc_loss = 0.05491051385696563
Trained batch 90 in epoch 3, gen_loss = 0.46811728228579513, disc_loss = 0.055201548320538064
Trained batch 91 in epoch 3, gen_loss = 0.4683645989583886, disc_loss = 0.055228598673989916
Trained batch 92 in epoch 3, gen_loss = 0.4685582057122261, disc_loss = 0.05478410529453428
Trained batch 93 in epoch 3, gen_loss = 0.4684870636209528, disc_loss = 0.05565005408580157
Trained batch 94 in epoch 3, gen_loss = 0.4682110773889642, disc_loss = 0.056183571353750794
Trained batch 95 in epoch 3, gen_loss = 0.4680653993661205, disc_loss = 0.055719125652103685
Trained batch 96 in epoch 3, gen_loss = 0.46850658415519086, disc_loss = 0.056387188532341696
Trained batch 97 in epoch 3, gen_loss = 0.46816081994650316, disc_loss = 0.0564394398088738
Trained batch 98 in epoch 3, gen_loss = 0.46854015943979976, disc_loss = 0.058795538462811346
Trained batch 99 in epoch 3, gen_loss = 0.4690281417965889, disc_loss = 0.05892035836819559
Trained batch 100 in epoch 3, gen_loss = 0.4697634433165635, disc_loss = 0.05932932452639878
Trained batch 101 in epoch 3, gen_loss = 0.46924526288228874, disc_loss = 0.05946295367389479
Trained batch 102 in epoch 3, gen_loss = 0.468775514549422, disc_loss = 0.05934545971471274
Trained batch 103 in epoch 3, gen_loss = 0.4691493640152308, disc_loss = 0.05925614775892777
Trained batch 104 in epoch 3, gen_loss = 0.4690070350964864, disc_loss = 0.05915702274956164
Trained batch 105 in epoch 3, gen_loss = 0.4690152960565855, disc_loss = 0.05872588476851442
Trained batch 106 in epoch 3, gen_loss = 0.46892342417039606, disc_loss = 0.0584206696747689
Trained batch 107 in epoch 3, gen_loss = 0.4692014389567905, disc_loss = 0.05879984982742893
Trained batch 108 in epoch 3, gen_loss = 0.4687836295967802, disc_loss = 0.05864927357643706
Trained batch 109 in epoch 3, gen_loss = 0.46853719624606044, disc_loss = 0.05843219445933673
Trained batch 110 in epoch 3, gen_loss = 0.4682517014108263, disc_loss = 0.05822269686053062
Trained batch 111 in epoch 3, gen_loss = 0.4683128826852356, disc_loss = 0.05812637917447968
Trained batch 112 in epoch 3, gen_loss = 0.468713184637306, disc_loss = 0.05771332574942339
Trained batch 113 in epoch 3, gen_loss = 0.46871087504060643, disc_loss = 0.05730445980780611
Trained batch 114 in epoch 3, gen_loss = 0.46879781795584635, disc_loss = 0.05707916199918026
Trained batch 115 in epoch 3, gen_loss = 0.4685980048159073, disc_loss = 0.0571020448877444
Trained batch 116 in epoch 3, gen_loss = 0.4686543488094949, disc_loss = 0.05673917428725678
Trained batch 117 in epoch 3, gen_loss = 0.4690654343467648, disc_loss = 0.05848393337880024
Trained batch 118 in epoch 3, gen_loss = 0.4686206814621677, disc_loss = 0.06016603701927958
Trained batch 119 in epoch 3, gen_loss = 0.46859740068515143, disc_loss = 0.059823371667880564
Trained batch 120 in epoch 3, gen_loss = 0.4686599617654627, disc_loss = 0.05949405024659412
Trained batch 121 in epoch 3, gen_loss = 0.46878394313523025, disc_loss = 0.05915052312059847
Trained batch 122 in epoch 3, gen_loss = 0.46886480678387776, disc_loss = 0.058971529020132814
Trained batch 123 in epoch 3, gen_loss = 0.4690608069781334, disc_loss = 0.05861585245903341
Trained batch 124 in epoch 3, gen_loss = 0.46910508036613463, disc_loss = 0.05823210684582591
Trained batch 125 in epoch 3, gen_loss = 0.4696425637082448, disc_loss = 0.05814581531070409
Trained batch 126 in epoch 3, gen_loss = 0.4698069830109754, disc_loss = 0.0577912511868681
Trained batch 127 in epoch 3, gen_loss = 0.4699169627856463, disc_loss = 0.05748013659831486
Trained batch 128 in epoch 3, gen_loss = 0.47017849115438237, disc_loss = 0.057144509408218684
Trained batch 129 in epoch 3, gen_loss = 0.47079939590050623, disc_loss = 0.05677971484927604
Trained batch 130 in epoch 3, gen_loss = 0.47067956501291, disc_loss = 0.056728826199466266
Trained batch 131 in epoch 3, gen_loss = 0.4708508318572333, disc_loss = 0.0567221045247138
Trained batch 132 in epoch 3, gen_loss = 0.4710234901062528, disc_loss = 0.056867843371276795
Trained batch 133 in epoch 3, gen_loss = 0.471227780429285, disc_loss = 0.057607718677357284
Trained batch 134 in epoch 3, gen_loss = 0.4711839508127283, disc_loss = 0.05816195505429749
Trained batch 135 in epoch 3, gen_loss = 0.4709519150064272, disc_loss = 0.058952132982941455
Trained batch 136 in epoch 3, gen_loss = 0.470845520061298, disc_loss = 0.05953323642934
Trained batch 137 in epoch 3, gen_loss = 0.47097068636313727, disc_loss = 0.05934632480805875
Trained batch 138 in epoch 3, gen_loss = 0.47109533964301187, disc_loss = 0.05938945794076049
Trained batch 139 in epoch 3, gen_loss = 0.4712953497256551, disc_loss = 0.05918306920211762
Trained batch 140 in epoch 3, gen_loss = 0.4719492008922793, disc_loss = 0.05932036839121728
Trained batch 141 in epoch 3, gen_loss = 0.4717561514444754, disc_loss = 0.05918920482508838
Trained batch 142 in epoch 3, gen_loss = 0.472433314873622, disc_loss = 0.059401070389740324
Trained batch 143 in epoch 3, gen_loss = 0.47220360425611335, disc_loss = 0.059265490068355575
Trained batch 144 in epoch 3, gen_loss = 0.4713263756242292, disc_loss = 0.059420358996581414
Trained batch 145 in epoch 3, gen_loss = 0.47092116001534134, disc_loss = 0.06027444366888743
Trained batch 146 in epoch 3, gen_loss = 0.4712829261409993, disc_loss = 0.06017608506300924
Trained batch 147 in epoch 3, gen_loss = 0.47082092592845093, disc_loss = 0.06002362907197125
Trained batch 148 in epoch 3, gen_loss = 0.47093124197633474, disc_loss = 0.05991563690051237
Trained batch 149 in epoch 3, gen_loss = 0.4705107202132543, disc_loss = 0.059866284321372705
Trained batch 150 in epoch 3, gen_loss = 0.4701018449881219, disc_loss = 0.059945288074159664
Trained batch 151 in epoch 3, gen_loss = 0.46971109783963155, disc_loss = 0.05995791529513601
Trained batch 152 in epoch 3, gen_loss = 0.4704590798203462, disc_loss = 0.05994853142685458
Trained batch 153 in epoch 3, gen_loss = 0.4705571476128194, disc_loss = 0.05979101054140597
Trained batch 154 in epoch 3, gen_loss = 0.4702674631149538, disc_loss = 0.0601699493975649
Trained batch 155 in epoch 3, gen_loss = 0.47073154418896407, disc_loss = 0.05988605016281303
Trained batch 156 in epoch 3, gen_loss = 0.4710980581629808, disc_loss = 0.059636344756503964
Trained batch 157 in epoch 3, gen_loss = 0.47128936308848707, disc_loss = 0.05933622491569553
Trained batch 158 in epoch 3, gen_loss = 0.4715867724808507, disc_loss = 0.05908756599169951
Trained batch 159 in epoch 3, gen_loss = 0.47185761369764806, disc_loss = 0.05880054405715782
Trained batch 160 in epoch 3, gen_loss = 0.4721378706256795, disc_loss = 0.05851525858750347
Trained batch 161 in epoch 3, gen_loss = 0.47197696290634295, disc_loss = 0.058238776966952434
Trained batch 162 in epoch 3, gen_loss = 0.47228791103041246, disc_loss = 0.058839485086386374
Trained batch 163 in epoch 3, gen_loss = 0.4721969373342467, disc_loss = 0.05868922191297227
Trained batch 164 in epoch 3, gen_loss = 0.47215352022286616, disc_loss = 0.058454951443568326
Trained batch 165 in epoch 3, gen_loss = 0.47186001704399844, disc_loss = 0.05818553594591837
Trained batch 166 in epoch 3, gen_loss = 0.4716398464348502, disc_loss = 0.058003878368700516
Trained batch 167 in epoch 3, gen_loss = 0.47136130254893077, disc_loss = 0.0577062682409416
Trained batch 168 in epoch 3, gen_loss = 0.4711637137204232, disc_loss = 0.05741164669361428
Trained batch 169 in epoch 3, gen_loss = 0.47163534550105823, disc_loss = 0.0580114636268905
Trained batch 170 in epoch 3, gen_loss = 0.4712903473460883, disc_loss = 0.058001832058925555
Trained batch 171 in epoch 3, gen_loss = 0.47119470235220223, disc_loss = 0.057899683424228326
Trained batch 172 in epoch 3, gen_loss = 0.4712369772740182, disc_loss = 0.05767318000478638
Trained batch 173 in epoch 3, gen_loss = 0.47114844055011357, disc_loss = 0.057770927803291156
Trained batch 174 in epoch 3, gen_loss = 0.47103914567402433, disc_loss = 0.05771223431453109
Trained batch 175 in epoch 3, gen_loss = 0.47081241282549774, disc_loss = 0.057616133912233636
Trained batch 176 in epoch 3, gen_loss = 0.47070763003354693, disc_loss = 0.0573789615757595
Trained batch 177 in epoch 3, gen_loss = 0.47093087133396877, disc_loss = 0.057142655943321546
Trained batch 178 in epoch 3, gen_loss = 0.47107751842317636, disc_loss = 0.056905873231693854
Trained batch 179 in epoch 3, gen_loss = 0.47113793707556195, disc_loss = 0.05667646607746267
Trained batch 180 in epoch 3, gen_loss = 0.47050458703251835, disc_loss = 0.056462320913329145
Trained batch 181 in epoch 3, gen_loss = 0.4709042646400221, disc_loss = 0.05629481483445308
Trained batch 182 in epoch 3, gen_loss = 0.4717122699067892, disc_loss = 0.05625618721200713
Trained batch 183 in epoch 3, gen_loss = 0.47187475066470064, disc_loss = 0.05599804624216631
Trained batch 184 in epoch 3, gen_loss = 0.47185186147689817, disc_loss = 0.0562747832563882
Trained batch 185 in epoch 3, gen_loss = 0.4713461592953692, disc_loss = 0.056704120898258784
Trained batch 186 in epoch 3, gen_loss = 0.4710185392336412, disc_loss = 0.056777050078692125
Trained batch 187 in epoch 3, gen_loss = 0.4713504097246109, disc_loss = 0.05673865043369934
Trained batch 188 in epoch 3, gen_loss = 0.47139083219583705, disc_loss = 0.056502561629429536
Trained batch 189 in epoch 3, gen_loss = 0.4711217397137692, disc_loss = 0.05668950232579128
Trained batch 190 in epoch 3, gen_loss = 0.47135043425085654, disc_loss = 0.05669030906749568
Trained batch 191 in epoch 3, gen_loss = 0.47143303385625285, disc_loss = 0.0574506851141147
Trained batch 192 in epoch 3, gen_loss = 0.4710279982633541, disc_loss = 0.05819404373003334
Trained batch 193 in epoch 3, gen_loss = 0.4713961013506368, disc_loss = 0.058089797075396195
Trained batch 194 in epoch 3, gen_loss = 0.47150222475712117, disc_loss = 0.05803095274963058
Trained batch 195 in epoch 3, gen_loss = 0.4714904398638375, disc_loss = 0.057862917339068135
Trained batch 196 in epoch 3, gen_loss = 0.47152738764806446, disc_loss = 0.05765622605328557
Trained batch 197 in epoch 3, gen_loss = 0.47123841685478135, disc_loss = 0.05767010134230885
Trained batch 198 in epoch 3, gen_loss = 0.47089181458530716, disc_loss = 0.05766951372079439
Trained batch 199 in epoch 3, gen_loss = 0.4704186363518238, disc_loss = 0.05779456794960424
Trained batch 200 in epoch 3, gen_loss = 0.47056122872959916, disc_loss = 0.057719148924824465
Trained batch 201 in epoch 3, gen_loss = 0.4708537375277812, disc_loss = 0.05750297266058624
Trained batch 202 in epoch 3, gen_loss = 0.47112794741621156, disc_loss = 0.05742684112898455
Trained batch 203 in epoch 3, gen_loss = 0.4710434412255007, disc_loss = 0.05718550293058084
Trained batch 204 in epoch 3, gen_loss = 0.4708294696924163, disc_loss = 0.05704359263863142
Trained batch 205 in epoch 3, gen_loss = 0.4709543805677914, disc_loss = 0.05682557363072139
Trained batch 206 in epoch 3, gen_loss = 0.4710006402886432, disc_loss = 0.05673217202271312
Trained batch 207 in epoch 3, gen_loss = 0.47105736428728473, disc_loss = 0.05658087556366809
Trained batch 208 in epoch 3, gen_loss = 0.4709103039006867, disc_loss = 0.05654317742374026
Trained batch 209 in epoch 3, gen_loss = 0.47179622337931676, disc_loss = 0.05631179713111903
Trained batch 210 in epoch 3, gen_loss = 0.4717552500878465, disc_loss = 0.05612986277285698
Trained batch 211 in epoch 3, gen_loss = 0.47185605497292754, disc_loss = 0.056027073889777484
Trained batch 212 in epoch 3, gen_loss = 0.4717058710089312, disc_loss = 0.056122983794904234
Trained batch 213 in epoch 3, gen_loss = 0.4717806012273949, disc_loss = 0.05607724393648313
Trained batch 214 in epoch 3, gen_loss = 0.4716759171596793, disc_loss = 0.05584298666826514
Trained batch 215 in epoch 3, gen_loss = 0.4717435312491876, disc_loss = 0.05579068499651772
Trained batch 216 in epoch 3, gen_loss = 0.47179085867745535, disc_loss = 0.05560345909974542
Trained batch 217 in epoch 3, gen_loss = 0.4719065680689768, disc_loss = 0.05550708563639483
Trained batch 218 in epoch 3, gen_loss = 0.4720281710907749, disc_loss = 0.055337513588607036
Trained batch 219 in epoch 3, gen_loss = 0.4722548018802296, disc_loss = 0.055191191074184395
Trained batch 220 in epoch 3, gen_loss = 0.47228595236847304, disc_loss = 0.055010974095350475
Trained batch 221 in epoch 3, gen_loss = 0.47254238324659364, disc_loss = 0.054851131882887705
Trained batch 222 in epoch 3, gen_loss = 0.4724530520193245, disc_loss = 0.05470422234369501
Trained batch 223 in epoch 3, gen_loss = 0.4723698105663061, disc_loss = 0.054515330669736226
Trained batch 224 in epoch 3, gen_loss = 0.4720718958642748, disc_loss = 0.054337529014382095
Trained batch 225 in epoch 3, gen_loss = 0.4722698750221624, disc_loss = 0.054268843688037804
Trained batch 226 in epoch 3, gen_loss = 0.4725991626668081, disc_loss = 0.05482402495170086
Trained batch 227 in epoch 3, gen_loss = 0.47241997405102376, disc_loss = 0.054755027083222545
Trained batch 228 in epoch 3, gen_loss = 0.4722202680516972, disc_loss = 0.05506675341064883
Trained batch 229 in epoch 3, gen_loss = 0.472118929417237, disc_loss = 0.054867191790886546
Trained batch 230 in epoch 3, gen_loss = 0.47193994008617485, disc_loss = 0.05498523969864432
Trained batch 231 in epoch 3, gen_loss = 0.47194087107119886, disc_loss = 0.05485066731364049
Trained batch 232 in epoch 3, gen_loss = 0.47220047361860973, disc_loss = 0.054754720433203445
Trained batch 233 in epoch 3, gen_loss = 0.4726288890482014, disc_loss = 0.05474348476108832
Trained batch 234 in epoch 3, gen_loss = 0.47249510871603134, disc_loss = 0.054572565029276175
Trained batch 235 in epoch 3, gen_loss = 0.4724401433841657, disc_loss = 0.05444191127889237
Trained batch 236 in epoch 3, gen_loss = 0.472316547662397, disc_loss = 0.05493782834790427
Trained batch 237 in epoch 3, gen_loss = 0.47185802534848703, disc_loss = 0.05494439875816598
Trained batch 238 in epoch 3, gen_loss = 0.4718840933993272, disc_loss = 0.054824466875532184
Trained batch 239 in epoch 3, gen_loss = 0.47206441648304465, disc_loss = 0.05473932699921231
Trained batch 240 in epoch 3, gen_loss = 0.47199684047600043, disc_loss = 0.054824514894193634
Trained batch 241 in epoch 3, gen_loss = 0.47196923344095876, disc_loss = 0.054784382424078695
Trained batch 242 in epoch 3, gen_loss = 0.4718981827973338, disc_loss = 0.05485629250483258
Trained batch 243 in epoch 3, gen_loss = 0.47144740673362234, disc_loss = 0.05541905742443976
Trained batch 244 in epoch 3, gen_loss = 0.4718436129239141, disc_loss = 0.055239280974682496
Trained batch 245 in epoch 3, gen_loss = 0.47227675619164133, disc_loss = 0.05544459472251374
Trained batch 246 in epoch 3, gen_loss = 0.4728526868800885, disc_loss = 0.05526366857774103
Trained batch 247 in epoch 3, gen_loss = 0.4734281082787821, disc_loss = 0.05522462295278186
Trained batch 248 in epoch 3, gen_loss = 0.47342937574329147, disc_loss = 0.055166888510785904
Trained batch 249 in epoch 3, gen_loss = 0.473386696100235, disc_loss = 0.055387778125703335
Trained batch 250 in epoch 3, gen_loss = 0.473513947065133, disc_loss = 0.05522435435661638
Trained batch 251 in epoch 3, gen_loss = 0.4738162249799759, disc_loss = 0.0551762884179692
Trained batch 252 in epoch 3, gen_loss = 0.47352169542444555, disc_loss = 0.05500624077431416
Trained batch 253 in epoch 3, gen_loss = 0.473441295736418, disc_loss = 0.054879529441992835
Trained batch 254 in epoch 3, gen_loss = 0.4734581548793643, disc_loss = 0.05475537719606769
Trained batch 255 in epoch 3, gen_loss = 0.4737247029552236, disc_loss = 0.05459766381318332
Trained batch 256 in epoch 3, gen_loss = 0.4735457912261384, disc_loss = 0.05442552892889842
Trained batch 257 in epoch 3, gen_loss = 0.47342196153115856, disc_loss = 0.0543107633811039
Trained batch 258 in epoch 3, gen_loss = 0.47360441928664687, disc_loss = 0.054142719497868225
Trained batch 259 in epoch 3, gen_loss = 0.4737714765163568, disc_loss = 0.05407838232170504
Trained batch 260 in epoch 3, gen_loss = 0.47386749425610364, disc_loss = 0.05447697332235931
Trained batch 261 in epoch 3, gen_loss = 0.4735203909737463, disc_loss = 0.054681173244932
Trained batch 262 in epoch 3, gen_loss = 0.47372278480475394, disc_loss = 0.05451091700817809
Trained batch 263 in epoch 3, gen_loss = 0.47364302002119296, disc_loss = 0.05433647207929894
Trained batch 264 in epoch 3, gen_loss = 0.4735951654191287, disc_loss = 0.05426301551666462
Trained batch 265 in epoch 3, gen_loss = 0.47387126121754036, disc_loss = 0.05433304641829958
Trained batch 266 in epoch 3, gen_loss = 0.47390767976585846, disc_loss = 0.054210524521209995
Trained batch 267 in epoch 3, gen_loss = 0.4741397496702066, disc_loss = 0.05405172475947262
Trained batch 268 in epoch 3, gen_loss = 0.4739393185284058, disc_loss = 0.05389203031834727
Trained batch 269 in epoch 3, gen_loss = 0.47373479030750415, disc_loss = 0.053759626606134356
Trained batch 270 in epoch 3, gen_loss = 0.4740160457322518, disc_loss = 0.05359748363962253
Trained batch 271 in epoch 3, gen_loss = 0.4740642557906754, disc_loss = 0.05365452414844185
Trained batch 272 in epoch 3, gen_loss = 0.47397962780225844, disc_loss = 0.053551116262327184
Trained batch 273 in epoch 3, gen_loss = 0.47432585539173905, disc_loss = 0.0534765407864521
Trained batch 274 in epoch 3, gen_loss = 0.47445870497009973, disc_loss = 0.05342565381391482
Trained batch 275 in epoch 3, gen_loss = 0.4742729955393335, disc_loss = 0.0532489678758345
Trained batch 276 in epoch 3, gen_loss = 0.47431981757229413, disc_loss = 0.053133312782561844
Trained batch 277 in epoch 3, gen_loss = 0.47404294005400843, disc_loss = 0.05308646690803948
Trained batch 278 in epoch 3, gen_loss = 0.474197145003999, disc_loss = 0.052933985512623544
Trained batch 279 in epoch 3, gen_loss = 0.47409748466951507, disc_loss = 0.05277547673155953
Trained batch 280 in epoch 3, gen_loss = 0.4743680208391142, disc_loss = 0.05268517827774229
Trained batch 281 in epoch 3, gen_loss = 0.4744122063225888, disc_loss = 0.052522003470675635
Trained batch 282 in epoch 3, gen_loss = 0.4743864571037225, disc_loss = 0.05236812622875449
Trained batch 283 in epoch 3, gen_loss = 0.47443139962327313, disc_loss = 0.05220828082209165
Trained batch 284 in epoch 3, gen_loss = 0.4743824999583395, disc_loss = 0.052206592903913634
Trained batch 285 in epoch 3, gen_loss = 0.47423146081554307, disc_loss = 0.052265529880638824
Trained batch 286 in epoch 3, gen_loss = 0.47384539371168155, disc_loss = 0.052151603801078604
Trained batch 287 in epoch 3, gen_loss = 0.47358571955313283, disc_loss = 0.05237959136623734
Trained batch 288 in epoch 3, gen_loss = 0.47352670148582193, disc_loss = 0.05234977039814666
Trained batch 289 in epoch 3, gen_loss = 0.4734606755190882, disc_loss = 0.05222752641019379
Trained batch 290 in epoch 3, gen_loss = 0.47333328553901094, disc_loss = 0.0520856774514509
Trained batch 291 in epoch 3, gen_loss = 0.4733647131552435, disc_loss = 0.051987313354477184
Trained batch 292 in epoch 3, gen_loss = 0.4732915893349631, disc_loss = 0.052020827780315596
Trained batch 293 in epoch 3, gen_loss = 0.4731322127540095, disc_loss = 0.051863513030048436
Trained batch 294 in epoch 3, gen_loss = 0.47325790332535567, disc_loss = 0.05177167343228298
Trained batch 295 in epoch 3, gen_loss = 0.4727977971370156, disc_loss = 0.051725538496267855
Trained batch 296 in epoch 3, gen_loss = 0.47304408718841245, disc_loss = 0.051885633429932576
Trained batch 297 in epoch 3, gen_loss = 0.47301300890093684, disc_loss = 0.0517536289755555
Trained batch 298 in epoch 3, gen_loss = 0.47303985373232277, disc_loss = 0.051755058776936105
Trained batch 299 in epoch 3, gen_loss = 0.473048231502374, disc_loss = 0.05162354498635977
Trained batch 300 in epoch 3, gen_loss = 0.47299785788273097, disc_loss = 0.051557836040817324
Trained batch 301 in epoch 3, gen_loss = 0.47296358092336466, disc_loss = 0.051485803300539486
Trained batch 302 in epoch 3, gen_loss = 0.4728972816427942, disc_loss = 0.051431627509187255
Trained batch 303 in epoch 3, gen_loss = 0.47292420071990865, disc_loss = 0.05142105888042256
Trained batch 304 in epoch 3, gen_loss = 0.47303852096932836, disc_loss = 0.0513643631207772
Trained batch 305 in epoch 3, gen_loss = 0.47300923036204445, disc_loss = 0.0512470260758586
Trained batch 306 in epoch 3, gen_loss = 0.47273479999082485, disc_loss = 0.0511958286248099
Trained batch 307 in epoch 3, gen_loss = 0.47266605438350084, disc_loss = 0.05106650889615298
Trained batch 308 in epoch 3, gen_loss = 0.4727393469764191, disc_loss = 0.05094231523627651
Trained batch 309 in epoch 3, gen_loss = 0.47283905321551906, disc_loss = 0.05081306307035829
Trained batch 310 in epoch 3, gen_loss = 0.47290238086433656, disc_loss = 0.05071886074714291
Trained batch 311 in epoch 3, gen_loss = 0.47314724469414127, disc_loss = 0.05059432736687505
Trained batch 312 in epoch 3, gen_loss = 0.4730037040413378, disc_loss = 0.05052191897268636
Trained batch 313 in epoch 3, gen_loss = 0.47315417097252643, disc_loss = 0.05050991592887243
Trained batch 314 in epoch 3, gen_loss = 0.47291208893533737, disc_loss = 0.05051943109710775
Trained batch 315 in epoch 3, gen_loss = 0.47266603836530374, disc_loss = 0.051332620112520135
Trained batch 316 in epoch 3, gen_loss = 0.4727026968724344, disc_loss = 0.05127901495625309
Trained batch 317 in epoch 3, gen_loss = 0.47291227144265324, disc_loss = 0.05156933603978148
Trained batch 318 in epoch 3, gen_loss = 0.47297928195014644, disc_loss = 0.051440195719124664
Trained batch 319 in epoch 3, gen_loss = 0.47304635047912597, disc_loss = 0.051374890356964895
Trained batch 320 in epoch 3, gen_loss = 0.47330370164734553, disc_loss = 0.05142095453335071
Trained batch 321 in epoch 3, gen_loss = 0.47348003709538383, disc_loss = 0.05130964575873352
Trained batch 322 in epoch 3, gen_loss = 0.47363777057305206, disc_loss = 0.051191631605093234
Trained batch 323 in epoch 3, gen_loss = 0.4735147601660387, disc_loss = 0.051085864048577664
Trained batch 324 in epoch 3, gen_loss = 0.47380491458452667, disc_loss = 0.05109450768249539
Trained batch 325 in epoch 3, gen_loss = 0.47378323871665207, disc_loss = 0.050983424874114024
Trained batch 326 in epoch 3, gen_loss = 0.47367844833146544, disc_loss = 0.05102302661359265
Trained batch 327 in epoch 3, gen_loss = 0.4734800556084005, disc_loss = 0.05110365625828641
Trained batch 328 in epoch 3, gen_loss = 0.47338579019876964, disc_loss = 0.051002601137537636
Trained batch 329 in epoch 3, gen_loss = 0.4732939173777898, disc_loss = 0.05091760554068694
Trained batch 330 in epoch 3, gen_loss = 0.47323643089781353, disc_loss = 0.050887817301677706
Trained batch 331 in epoch 3, gen_loss = 0.4732964256980333, disc_loss = 0.05087875469772886
Trained batch 332 in epoch 3, gen_loss = 0.4734922358402619, disc_loss = 0.05158027731771539
Trained batch 333 in epoch 3, gen_loss = 0.47324397178467165, disc_loss = 0.05209663263131714
Trained batch 334 in epoch 3, gen_loss = 0.4731286454556593, disc_loss = 0.0520672169124791
Trained batch 335 in epoch 3, gen_loss = 0.4729515077280147, disc_loss = 0.052265816183838375
Trained batch 336 in epoch 3, gen_loss = 0.4730517677631152, disc_loss = 0.05268066342593964
Trained batch 337 in epoch 3, gen_loss = 0.472967442764333, disc_loss = 0.052661146146118554
Trained batch 338 in epoch 3, gen_loss = 0.4728612219337868, disc_loss = 0.05275894397496078
Trained batch 339 in epoch 3, gen_loss = 0.47272020701099843, disc_loss = 0.05315949508564218
Trained batch 340 in epoch 3, gen_loss = 0.47256155473745465, disc_loss = 0.05382646007812923
Trained batch 341 in epoch 3, gen_loss = 0.472423617341365, disc_loss = 0.05400794567349666
Trained batch 342 in epoch 3, gen_loss = 0.4722552936382961, disc_loss = 0.053916230649787816
Trained batch 343 in epoch 3, gen_loss = 0.4720506459301294, disc_loss = 0.05389277648240284
Trained batch 344 in epoch 3, gen_loss = 0.47215833292491194, disc_loss = 0.05389395296114726
Trained batch 345 in epoch 3, gen_loss = 0.47212488019052956, disc_loss = 0.05382042106730874
Trained batch 346 in epoch 3, gen_loss = 0.4720306429120924, disc_loss = 0.05391747824262602
Trained batch 347 in epoch 3, gen_loss = 0.4720655707107193, disc_loss = 0.05378410653291463
Trained batch 348 in epoch 3, gen_loss = 0.4720906365054385, disc_loss = 0.053979711074723644
Trained batch 349 in epoch 3, gen_loss = 0.47205129495688847, disc_loss = 0.05414212044461497
Trained batch 350 in epoch 3, gen_loss = 0.4720210710651854, disc_loss = 0.054358293916605564
Trained batch 351 in epoch 3, gen_loss = 0.47212116936729714, disc_loss = 0.05427073394821491
Trained batch 352 in epoch 3, gen_loss = 0.47226736709348877, disc_loss = 0.054417200593631344
Trained batch 353 in epoch 3, gen_loss = 0.4722898609220645, disc_loss = 0.054315275545521395
Trained batch 354 in epoch 3, gen_loss = 0.4721855964459164, disc_loss = 0.05429747095856238
Trained batch 355 in epoch 3, gen_loss = 0.47196735224027314, disc_loss = 0.054264326711980566
Trained batch 356 in epoch 3, gen_loss = 0.47188554082264084, disc_loss = 0.054140383214624575
Trained batch 357 in epoch 3, gen_loss = 0.4718257754874629, disc_loss = 0.05411014953425269
Trained batch 358 in epoch 3, gen_loss = 0.47167207703284897, disc_loss = 0.05418425522262132
Trained batch 359 in epoch 3, gen_loss = 0.4715451709098286, disc_loss = 0.05413469067748843
Trained batch 360 in epoch 3, gen_loss = 0.47171181308265536, disc_loss = 0.054086802603413774
Trained batch 361 in epoch 3, gen_loss = 0.4714907109737396, disc_loss = 0.05406010990514734
Trained batch 362 in epoch 3, gen_loss = 0.4712137438705802, disc_loss = 0.05399598590080362
Trained batch 363 in epoch 3, gen_loss = 0.4712547427350348, disc_loss = 0.05399568022131551
Trained batch 364 in epoch 3, gen_loss = 0.4711171173069575, disc_loss = 0.05400132464806307
Trained batch 365 in epoch 3, gen_loss = 0.47113799291555997, disc_loss = 0.05407294355551687
Trained batch 366 in epoch 3, gen_loss = 0.47117403214568987, disc_loss = 0.054149096962369025
Trained batch 367 in epoch 3, gen_loss = 0.47095602240575396, disc_loss = 0.05406412693201159
Trained batch 368 in epoch 3, gen_loss = 0.47104944712747404, disc_loss = 0.05413487648874077
Trained batch 369 in epoch 3, gen_loss = 0.4708422485235575, disc_loss = 0.054025236651855144
Trained batch 370 in epoch 3, gen_loss = 0.4707649028847481, disc_loss = 0.05390939075434505
Trained batch 371 in epoch 3, gen_loss = 0.47059041630196313, disc_loss = 0.05407013514915341
Trained batch 372 in epoch 3, gen_loss = 0.4705473370750212, disc_loss = 0.05394353788475888
Trained batch 373 in epoch 3, gen_loss = 0.47042044192393195, disc_loss = 0.054379352164220685
Trained batch 374 in epoch 3, gen_loss = 0.4703336430390676, disc_loss = 0.05442319052418073
Trained batch 375 in epoch 3, gen_loss = 0.47009289748174077, disc_loss = 0.054451766968803834
Trained batch 376 in epoch 3, gen_loss = 0.4699407894193968, disc_loss = 0.05436752188150383
Trained batch 377 in epoch 3, gen_loss = 0.46994280759935025, disc_loss = 0.05435306538468
Trained batch 378 in epoch 3, gen_loss = 0.4699567447079832, disc_loss = 0.0543612414051958
Trained batch 379 in epoch 3, gen_loss = 0.4698594676036584, disc_loss = 0.05432616583022632
Trained batch 380 in epoch 3, gen_loss = 0.4696834796839186, disc_loss = 0.054464218663809495
Trained batch 381 in epoch 3, gen_loss = 0.4697292071050374, disc_loss = 0.05455548837975994
Trained batch 382 in epoch 3, gen_loss = 0.46988529838407633, disc_loss = 0.05465221225087076
Trained batch 383 in epoch 3, gen_loss = 0.4699643904653688, disc_loss = 0.05454118487978121
Trained batch 384 in epoch 3, gen_loss = 0.46975015239282086, disc_loss = 0.054591665932207135
Trained batch 385 in epoch 3, gen_loss = 0.4697569810201467, disc_loss = 0.05448688229623159
Trained batch 386 in epoch 3, gen_loss = 0.4698174317061747, disc_loss = 0.05441972708392128
Trained batch 387 in epoch 3, gen_loss = 0.46981667043622005, disc_loss = 0.05430471453786895
Trained batch 388 in epoch 3, gen_loss = 0.4696929842463496, disc_loss = 0.05441714871368326
Trained batch 389 in epoch 3, gen_loss = 0.4698584642165746, disc_loss = 0.054726675862016586
Trained batch 390 in epoch 3, gen_loss = 0.46988623709324984, disc_loss = 0.0546603738628042
Trained batch 391 in epoch 3, gen_loss = 0.4700381652433045, disc_loss = 0.054631428239505966
Trained batch 392 in epoch 3, gen_loss = 0.46999010132772623, disc_loss = 0.05455319186478247
Trained batch 393 in epoch 3, gen_loss = 0.4700833354807142, disc_loss = 0.054458123322122444
Trained batch 394 in epoch 3, gen_loss = 0.47011560148830656, disc_loss = 0.0546257439835728
Trained batch 395 in epoch 3, gen_loss = 0.4698309312866192, disc_loss = 0.05457609705391782
Trained batch 396 in epoch 3, gen_loss = 0.46961932856430033, disc_loss = 0.054529675230928124
Trained batch 397 in epoch 3, gen_loss = 0.4698342624770936, disc_loss = 0.054759218425363604
Trained batch 398 in epoch 3, gen_loss = 0.46970115583343314, disc_loss = 0.054939783491044863
Trained batch 399 in epoch 3, gen_loss = 0.46966893173754215, disc_loss = 0.05490708990721032
Trained batch 400 in epoch 3, gen_loss = 0.4696205924276699, disc_loss = 0.05494460451214614
Trained batch 401 in epoch 3, gen_loss = 0.4694975581186921, disc_loss = 0.054953730574795114
Trained batch 402 in epoch 3, gen_loss = 0.4694728307777244, disc_loss = 0.055213876842768406
Trained batch 403 in epoch 3, gen_loss = 0.4695316536149176, disc_loss = 0.0551645510465755
Trained batch 404 in epoch 3, gen_loss = 0.4693719450338387, disc_loss = 0.05508384157524065
Trained batch 405 in epoch 3, gen_loss = 0.469465505460213, disc_loss = 0.05567676905460032
Trained batch 406 in epoch 3, gen_loss = 0.4695719137824431, disc_loss = 0.05591407847757788
Trained batch 407 in epoch 3, gen_loss = 0.4694026295168727, disc_loss = 0.055859484721212556
Trained batch 408 in epoch 3, gen_loss = 0.4695728128288661, disc_loss = 0.056125042447706455
Trained batch 409 in epoch 3, gen_loss = 0.4692752886109236, disc_loss = 0.05623425299120022
Trained batch 410 in epoch 3, gen_loss = 0.46920112754306653, disc_loss = 0.05629640784332134
Trained batch 411 in epoch 3, gen_loss = 0.4693623824605664, disc_loss = 0.05639813215815399
Trained batch 412 in epoch 3, gen_loss = 0.469261025978347, disc_loss = 0.056341861149174395
Trained batch 413 in epoch 3, gen_loss = 0.46900060744101296, disc_loss = 0.056392217237178396
Trained batch 414 in epoch 3, gen_loss = 0.46882348505847427, disc_loss = 0.056328452510916324
Trained batch 415 in epoch 3, gen_loss = 0.4687908444410333, disc_loss = 0.05627726535805358
Trained batch 416 in epoch 3, gen_loss = 0.4688012900827028, disc_loss = 0.05617418006393049
Trained batch 417 in epoch 3, gen_loss = 0.46871775238993063, disc_loss = 0.05609172769559271
Trained batch 418 in epoch 3, gen_loss = 0.4685501991848957, disc_loss = 0.05601141866527693
Trained batch 419 in epoch 3, gen_loss = 0.4686566028566588, disc_loss = 0.056001349562956465
Trained batch 420 in epoch 3, gen_loss = 0.4686044933110688, disc_loss = 0.05597474708967353
Trained batch 421 in epoch 3, gen_loss = 0.4685856033275478, disc_loss = 0.0563171143793629
Trained batch 422 in epoch 3, gen_loss = 0.4685590190385814, disc_loss = 0.05652329975400058
Trained batch 423 in epoch 3, gen_loss = 0.46846110950101094, disc_loss = 0.056919049803290586
Trained batch 424 in epoch 3, gen_loss = 0.4684017679270576, disc_loss = 0.05686380894525963
Trained batch 425 in epoch 3, gen_loss = 0.46821051598154884, disc_loss = 0.05707571613318134
Trained batch 426 in epoch 3, gen_loss = 0.46831422457929517, disc_loss = 0.05725011250235367
Trained batch 427 in epoch 3, gen_loss = 0.46832713275869314, disc_loss = 0.0572306637882873
Trained batch 428 in epoch 3, gen_loss = 0.4680701399738694, disc_loss = 0.057274959319312396
Trained batch 429 in epoch 3, gen_loss = 0.46802098695621935, disc_loss = 0.05726269498943936
Trained batch 430 in epoch 3, gen_loss = 0.4680197976719752, disc_loss = 0.05721881030356455
Trained batch 431 in epoch 3, gen_loss = 0.46775827301597156, disc_loss = 0.057241807560246716
Trained batch 432 in epoch 3, gen_loss = 0.46777035216811624, disc_loss = 0.05715941857787464
Trained batch 433 in epoch 3, gen_loss = 0.46773966398381966, disc_loss = 0.057066263276911965
Trained batch 434 in epoch 3, gen_loss = 0.4675611926221299, disc_loss = 0.0570028869221094
Trained batch 435 in epoch 3, gen_loss = 0.4676734189921563, disc_loss = 0.05691026159083693
Trained batch 436 in epoch 3, gen_loss = 0.4677244535981927, disc_loss = 0.05681206101180828
Trained batch 437 in epoch 3, gen_loss = 0.4676214745736013, disc_loss = 0.05685178262976819
Trained batch 438 in epoch 3, gen_loss = 0.46777628569233665, disc_loss = 0.05674945082354247
Trained batch 439 in epoch 3, gen_loss = 0.46792231601747597, disc_loss = 0.05683480243367905
Trained batch 440 in epoch 3, gen_loss = 0.46787131184082725, disc_loss = 0.056818996642688774
Trained batch 441 in epoch 3, gen_loss = 0.46766722269727096, disc_loss = 0.05696524475275526
Trained batch 442 in epoch 3, gen_loss = 0.4677674750173065, disc_loss = 0.05712196985617045
Trained batch 443 in epoch 3, gen_loss = 0.4678492273564811, disc_loss = 0.057041794451809416
Trained batch 444 in epoch 3, gen_loss = 0.46796264005510996, disc_loss = 0.05698020165221075
Trained batch 445 in epoch 3, gen_loss = 0.4679388123242844, disc_loss = 0.05688517612317418
Trained batch 446 in epoch 3, gen_loss = 0.46791900004316495, disc_loss = 0.05678289023413421
Trained batch 447 in epoch 3, gen_loss = 0.4678813097333269, disc_loss = 0.05673056030770697
Trained batch 448 in epoch 3, gen_loss = 0.46779322995905886, disc_loss = 0.05668207982094556
Trained batch 449 in epoch 3, gen_loss = 0.46767752197053697, disc_loss = 0.056573001714423296
Trained batch 450 in epoch 3, gen_loss = 0.46775294830423764, disc_loss = 0.05649776321148165
Trained batch 451 in epoch 3, gen_loss = 0.46778444649107687, disc_loss = 0.056552941232004855
Trained batch 452 in epoch 3, gen_loss = 0.4679036783198384, disc_loss = 0.05649680053922152
Trained batch 453 in epoch 3, gen_loss = 0.4678138285087594, disc_loss = 0.056765637505134886
Trained batch 454 in epoch 3, gen_loss = 0.4680380980392079, disc_loss = 0.0569724900064642
Trained batch 455 in epoch 3, gen_loss = 0.4681366616043082, disc_loss = 0.05689183420914209
Trained batch 456 in epoch 3, gen_loss = 0.467981712497298, disc_loss = 0.05681165335577642
Trained batch 457 in epoch 3, gen_loss = 0.4678448256446805, disc_loss = 0.05671517627911569
Trained batch 458 in epoch 3, gen_loss = 0.46776945158547045, disc_loss = 0.05665594724581165
Trained batch 459 in epoch 3, gen_loss = 0.46800146135299103, disc_loss = 0.056606107939075195
Trained batch 460 in epoch 3, gen_loss = 0.4680753592684574, disc_loss = 0.05663884701530516
Trained batch 461 in epoch 3, gen_loss = 0.46793220111559997, disc_loss = 0.056643006908888745
Trained batch 462 in epoch 3, gen_loss = 0.46785136445809644, disc_loss = 0.05662164379808384
Trained batch 463 in epoch 3, gen_loss = 0.4679631809222287, disc_loss = 0.056542605873205344
Trained batch 464 in epoch 3, gen_loss = 0.46805953402673045, disc_loss = 0.05644837388047768
Trained batch 465 in epoch 3, gen_loss = 0.46803727746009827, disc_loss = 0.05635280328874712
Trained batch 466 in epoch 3, gen_loss = 0.4679060538141835, disc_loss = 0.0563474962541662
Trained batch 467 in epoch 3, gen_loss = 0.46793470856470937, disc_loss = 0.0563430516099016
Trained batch 468 in epoch 3, gen_loss = 0.4679338929495578, disc_loss = 0.05664980068091931
Trained batch 469 in epoch 3, gen_loss = 0.46775633553241164, disc_loss = 0.05656130642313114
Trained batch 470 in epoch 3, gen_loss = 0.4677395503612081, disc_loss = 0.05659152496499336
Trained batch 471 in epoch 3, gen_loss = 0.4678157284477, disc_loss = 0.05657120863808382
Trained batch 472 in epoch 3, gen_loss = 0.46806368156164946, disc_loss = 0.05674386415413992
Trained batch 473 in epoch 3, gen_loss = 0.46795430496523654, disc_loss = 0.05670969031322826
Trained batch 474 in epoch 3, gen_loss = 0.46784710256676926, disc_loss = 0.05675884637687551
Trained batch 475 in epoch 3, gen_loss = 0.46783469154053375, disc_loss = 0.05677318656249676
Trained batch 476 in epoch 3, gen_loss = 0.46787020226694503, disc_loss = 0.05679226563891993
Trained batch 477 in epoch 3, gen_loss = 0.4681009648359969, disc_loss = 0.05701208209996911
Trained batch 478 in epoch 3, gen_loss = 0.4683076273299956, disc_loss = 0.05700229220617259
Trained batch 479 in epoch 3, gen_loss = 0.46828315885116656, disc_loss = 0.05710223471105565
Trained batch 480 in epoch 3, gen_loss = 0.4680838846986854, disc_loss = 0.0572608897565107
Trained batch 481 in epoch 3, gen_loss = 0.4681543075321126, disc_loss = 0.05725247102511343
Trained batch 482 in epoch 3, gen_loss = 0.46834751618081244, disc_loss = 0.05737244065052697
Trained batch 483 in epoch 3, gen_loss = 0.4685106259609057, disc_loss = 0.05734191595072558
Trained batch 484 in epoch 3, gen_loss = 0.46829668240448863, disc_loss = 0.05735330013558269
Trained batch 485 in epoch 3, gen_loss = 0.46834351330872914, disc_loss = 0.05736000179274797
Trained batch 486 in epoch 3, gen_loss = 0.4684281783059882, disc_loss = 0.05733865430173168
Trained batch 487 in epoch 3, gen_loss = 0.46849912288980405, disc_loss = 0.057306609905637865
Trained batch 488 in epoch 3, gen_loss = 0.468544232516201, disc_loss = 0.05732817950435668
Trained batch 489 in epoch 3, gen_loss = 0.46847073046528565, disc_loss = 0.057664110278710726
Trained batch 490 in epoch 3, gen_loss = 0.4685025471898058, disc_loss = 0.057609350937409154
Trained batch 491 in epoch 3, gen_loss = 0.4685823745964988, disc_loss = 0.0576385400528694
Trained batch 492 in epoch 3, gen_loss = 0.46847116747685913, disc_loss = 0.05755893339291517
Trained batch 493 in epoch 3, gen_loss = 0.46833102236151214, disc_loss = 0.05761976712307919
Trained batch 494 in epoch 3, gen_loss = 0.46813803736609644, disc_loss = 0.057540558781851124
Trained batch 495 in epoch 3, gen_loss = 0.4680279199514658, disc_loss = 0.05808288223136427
Trained batch 496 in epoch 3, gen_loss = 0.46800837526378974, disc_loss = 0.058222982641759236
Trained batch 497 in epoch 3, gen_loss = 0.46812883725606774, disc_loss = 0.058255225157245516
Trained batch 498 in epoch 3, gen_loss = 0.46828404779663546, disc_loss = 0.058353988994062245
Trained batch 499 in epoch 3, gen_loss = 0.4681597949266434, disc_loss = 0.05830461104866117
Trained batch 500 in epoch 3, gen_loss = 0.4681744313763525, disc_loss = 0.05828683197167432
Trained batch 501 in epoch 3, gen_loss = 0.4680122293799047, disc_loss = 0.05824548902409337
Trained batch 502 in epoch 3, gen_loss = 0.46795118583836565, disc_loss = 0.0583084534629661
Trained batch 503 in epoch 3, gen_loss = 0.46821270179417396, disc_loss = 0.058466265272785214
Trained batch 504 in epoch 3, gen_loss = 0.4681585671878097, disc_loss = 0.05839156846580382
Trained batch 505 in epoch 3, gen_loss = 0.4680576635443646, disc_loss = 0.05840544168756384
Trained batch 506 in epoch 3, gen_loss = 0.46808335784624316, disc_loss = 0.05830832284689685
Trained batch 507 in epoch 3, gen_loss = 0.4681785495614442, disc_loss = 0.05829332146782604
Trained batch 508 in epoch 3, gen_loss = 0.46814689900879775, disc_loss = 0.05822973952066951
Trained batch 509 in epoch 3, gen_loss = 0.4681715212616266, disc_loss = 0.05814101884196348
Trained batch 510 in epoch 3, gen_loss = 0.46799508705297793, disc_loss = 0.05805232765976843
Trained batch 511 in epoch 3, gen_loss = 0.4679262844729237, disc_loss = 0.05814724072934041
Trained batch 512 in epoch 3, gen_loss = 0.4679526689573106, disc_loss = 0.05815945018979686
Trained batch 513 in epoch 3, gen_loss = 0.46794498482798785, disc_loss = 0.05812070696390006
Trained batch 514 in epoch 3, gen_loss = 0.46802181786703834, disc_loss = 0.05802822984049766
Trained batch 515 in epoch 3, gen_loss = 0.46793674544770586, disc_loss = 0.057930267833772496
Trained batch 516 in epoch 3, gen_loss = 0.46767785257481514, disc_loss = 0.05800524328671381
Trained batch 517 in epoch 3, gen_loss = 0.46767880966074216, disc_loss = 0.057924069279919894
Trained batch 518 in epoch 3, gen_loss = 0.46767370107086637, disc_loss = 0.05791473383198785
Trained batch 519 in epoch 3, gen_loss = 0.46778727672421017, disc_loss = 0.057905382343317165
Trained batch 520 in epoch 3, gen_loss = 0.46782306385818234, disc_loss = 0.05791563375794012
Trained batch 521 in epoch 3, gen_loss = 0.4676729015920354, disc_loss = 0.058049085206562705
Trained batch 522 in epoch 3, gen_loss = 0.46775782894677914, disc_loss = 0.05796303588943289
Trained batch 523 in epoch 3, gen_loss = 0.46787598410635506, disc_loss = 0.05793840674423961
Trained batch 524 in epoch 3, gen_loss = 0.46795099088123865, disc_loss = 0.05785775064446387
Trained batch 525 in epoch 3, gen_loss = 0.46802292724525973, disc_loss = 0.05785748508171012
Trained batch 526 in epoch 3, gen_loss = 0.467924931809391, disc_loss = 0.05777375709064008
Trained batch 527 in epoch 3, gen_loss = 0.46788840278080013, disc_loss = 0.05770192068920358
Trained batch 528 in epoch 3, gen_loss = 0.46797869640397216, disc_loss = 0.05761818241747008
Trained batch 529 in epoch 3, gen_loss = 0.46815200650467065, disc_loss = 0.057526758025874786
Trained batch 530 in epoch 3, gen_loss = 0.4681681258193517, disc_loss = 0.05748299021789499
Trained batch 531 in epoch 3, gen_loss = 0.4680768770158739, disc_loss = 0.05762479512486607
Trained batch 532 in epoch 3, gen_loss = 0.46807954509307476, disc_loss = 0.05758209333721877
Trained batch 533 in epoch 3, gen_loss = 0.46821763849213777, disc_loss = 0.057665739195379484
Trained batch 534 in epoch 3, gen_loss = 0.46815695673505836, disc_loss = 0.057631797915341974
Trained batch 535 in epoch 3, gen_loss = 0.4681627707583691, disc_loss = 0.05758641679065803
Trained batch 536 in epoch 3, gen_loss = 0.46821848684627027, disc_loss = 0.05756812603117506
Trained batch 537 in epoch 3, gen_loss = 0.46827204060155664, disc_loss = 0.0575275924757857
Trained batch 538 in epoch 3, gen_loss = 0.4682723796323412, disc_loss = 0.05747126123102482
Trained batch 539 in epoch 3, gen_loss = 0.4682201922491745, disc_loss = 0.05738217758652927
Trained batch 540 in epoch 3, gen_loss = 0.4683256147639368, disc_loss = 0.05733496427635857
Trained batch 541 in epoch 3, gen_loss = 0.46830788546162777, disc_loss = 0.05736671388578838
Trained batch 542 in epoch 3, gen_loss = 0.46831168407234697, disc_loss = 0.057302756057486186
Trained batch 543 in epoch 3, gen_loss = 0.4683449489667135, disc_loss = 0.0572133244260091
Trained batch 544 in epoch 3, gen_loss = 0.4683923182684347, disc_loss = 0.057130668690821174
Trained batch 545 in epoch 3, gen_loss = 0.4682305510336663, disc_loss = 0.057151182274071455
Trained batch 546 in epoch 3, gen_loss = 0.4680346147560768, disc_loss = 0.05718840268002976
Trained batch 547 in epoch 3, gen_loss = 0.4681223782635953, disc_loss = 0.05716044519922567
Trained batch 548 in epoch 3, gen_loss = 0.46821271890065275, disc_loss = 0.057225626147774565
Trained batch 549 in epoch 3, gen_loss = 0.4682570919665423, disc_loss = 0.05714210616848008
Trained batch 550 in epoch 3, gen_loss = 0.4681024052703013, disc_loss = 0.05712639166806197
Trained batch 551 in epoch 3, gen_loss = 0.46809103518076567, disc_loss = 0.05707999893406784
Trained batch 552 in epoch 3, gen_loss = 0.46811347359127853, disc_loss = 0.05703870877606717
Trained batch 553 in epoch 3, gen_loss = 0.46809579641810395, disc_loss = 0.05711384345810955
Trained batch 554 in epoch 3, gen_loss = 0.4681189489794207, disc_loss = 0.05702537535060499
Trained batch 555 in epoch 3, gen_loss = 0.4680667809552426, disc_loss = 0.05714072973765567
Trained batch 556 in epoch 3, gen_loss = 0.4682455352328624, disc_loss = 0.05709558594854853
Trained batch 557 in epoch 3, gen_loss = 0.4681078887754871, disc_loss = 0.057077350361125816
Trained batch 558 in epoch 3, gen_loss = 0.4680500091828259, disc_loss = 0.05701503572712298
Trained batch 559 in epoch 3, gen_loss = 0.46803406184273105, disc_loss = 0.056993853373153665
Trained batch 560 in epoch 3, gen_loss = 0.46793342630068463, disc_loss = 0.05694564104448745
Trained batch 561 in epoch 3, gen_loss = 0.4679277639478127, disc_loss = 0.056889326764880496
Trained batch 562 in epoch 3, gen_loss = 0.4679432916810627, disc_loss = 0.05692837458041035
Trained batch 563 in epoch 3, gen_loss = 0.4680195616703507, disc_loss = 0.05685519125784833
Trained batch 564 in epoch 3, gen_loss = 0.46801208421192336, disc_loss = 0.056785198725529215
Trained batch 565 in epoch 3, gen_loss = 0.4679557055550835, disc_loss = 0.05683552348318217
Trained batch 566 in epoch 3, gen_loss = 0.4682633036869123, disc_loss = 0.0569198155041449
Trained batch 567 in epoch 3, gen_loss = 0.4682576575014793, disc_loss = 0.05684912319764049
Trained batch 568 in epoch 3, gen_loss = 0.46834212651571194, disc_loss = 0.05680142576365956
Trained batch 569 in epoch 3, gen_loss = 0.46841350872265664, disc_loss = 0.056837074813972176
Trained batch 570 in epoch 3, gen_loss = 0.4683937067638972, disc_loss = 0.05683215697346526
Trained batch 571 in epoch 3, gen_loss = 0.46839264045645307, disc_loss = 0.05680288564189096
Trained batch 572 in epoch 3, gen_loss = 0.46846802134788473, disc_loss = 0.056753879285419126
Trained batch 573 in epoch 3, gen_loss = 0.46853183973126294, disc_loss = 0.056740108363895
Trained batch 574 in epoch 3, gen_loss = 0.4683056436932605, disc_loss = 0.0566740668071029
Trained batch 575 in epoch 3, gen_loss = 0.4682264008766247, disc_loss = 0.05663861558019158
Trained batch 576 in epoch 3, gen_loss = 0.46834514949929157, disc_loss = 0.05669251417392539
Trained batch 577 in epoch 3, gen_loss = 0.468386767541661, disc_loss = 0.056694109069351045
Trained batch 578 in epoch 3, gen_loss = 0.4682989690793817, disc_loss = 0.056800928435711405
Trained batch 579 in epoch 3, gen_loss = 0.4683844374171619, disc_loss = 0.05674179858801051
Trained batch 580 in epoch 3, gen_loss = 0.46833347130355246, disc_loss = 0.05666104043800249
Trained batch 581 in epoch 3, gen_loss = 0.4682517354328608, disc_loss = 0.05665319900770905
Trained batch 582 in epoch 3, gen_loss = 0.4682023632076551, disc_loss = 0.05673629851967071
Trained batch 583 in epoch 3, gen_loss = 0.4681765838743073, disc_loss = 0.05665385330411644
Trained batch 584 in epoch 3, gen_loss = 0.46812976496851344, disc_loss = 0.05658516111966764
Trained batch 585 in epoch 3, gen_loss = 0.46814437398731507, disc_loss = 0.056550530150195795
Trained batch 586 in epoch 3, gen_loss = 0.46804704485394477, disc_loss = 0.05649172138260897
Trained batch 587 in epoch 3, gen_loss = 0.4680354492295356, disc_loss = 0.05683505925948599
Trained batch 588 in epoch 3, gen_loss = 0.46798768538368174, disc_loss = 0.05683895898666644
Trained batch 589 in epoch 3, gen_loss = 0.46783448528435273, disc_loss = 0.056799648316198235
Trained batch 590 in epoch 3, gen_loss = 0.467783780216969, disc_loss = 0.05684555893568496
Trained batch 591 in epoch 3, gen_loss = 0.4677144731520801, disc_loss = 0.05679894412940091
Trained batch 592 in epoch 3, gen_loss = 0.4677852468084525, disc_loss = 0.05676915296738179
Trained batch 593 in epoch 3, gen_loss = 0.4677979736918151, disc_loss = 0.05675866207035779
Trained batch 594 in epoch 3, gen_loss = 0.4677951046398708, disc_loss = 0.056844605423290936
Trained batch 595 in epoch 3, gen_loss = 0.4677163756033718, disc_loss = 0.05678438538007263
Trained batch 596 in epoch 3, gen_loss = 0.4676780273866414, disc_loss = 0.056765771655824464
Trained batch 597 in epoch 3, gen_loss = 0.4676319893985289, disc_loss = 0.05713387602631837
Trained batch 598 in epoch 3, gen_loss = 0.46748905294327586, disc_loss = 0.05711201992809449
Trained batch 599 in epoch 3, gen_loss = 0.46734390005469323, disc_loss = 0.057069953694784396
Trained batch 600 in epoch 3, gen_loss = 0.46755799760239297, disc_loss = 0.05721644609903114
Trained batch 601 in epoch 3, gen_loss = 0.467569504118837, disc_loss = 0.05717493711500444
Trained batch 602 in epoch 3, gen_loss = 0.46740293077766204, disc_loss = 0.057151890119652
Trained batch 603 in epoch 3, gen_loss = 0.4673468086695829, disc_loss = 0.05724269798293784
Trained batch 604 in epoch 3, gen_loss = 0.4673553024934343, disc_loss = 0.05734289431605827
Trained batch 605 in epoch 3, gen_loss = 0.4672492827617689, disc_loss = 0.05728527138443055
Trained batch 606 in epoch 3, gen_loss = 0.4671575558146299, disc_loss = 0.057252142543841575
Trained batch 607 in epoch 3, gen_loss = 0.4672081704790655, disc_loss = 0.057200948642658705
Trained batch 608 in epoch 3, gen_loss = 0.46718311637688936, disc_loss = 0.05719865368195918
Trained batch 609 in epoch 3, gen_loss = 0.46707835348903154, disc_loss = 0.057173306167461586
Trained batch 610 in epoch 3, gen_loss = 0.46716942358914454, disc_loss = 0.057384345835187575
Trained batch 611 in epoch 3, gen_loss = 0.46705445389147676, disc_loss = 0.05733838817637316
Trained batch 612 in epoch 3, gen_loss = 0.4670962588724849, disc_loss = 0.05732540166017647
Trained batch 613 in epoch 3, gen_loss = 0.4670885782385494, disc_loss = 0.057290474209989076
Trained batch 614 in epoch 3, gen_loss = 0.4670820186293222, disc_loss = 0.05730579555625232
Trained batch 615 in epoch 3, gen_loss = 0.4671527679961223, disc_loss = 0.057303338332023085
Trained batch 616 in epoch 3, gen_loss = 0.46722358924063523, disc_loss = 0.05724411978457286
Trained batch 617 in epoch 3, gen_loss = 0.4670735415324424, disc_loss = 0.0572368905911204
Trained batch 618 in epoch 3, gen_loss = 0.467151104922441, disc_loss = 0.05720202483594875
Trained batch 619 in epoch 3, gen_loss = 0.46728173792362215, disc_loss = 0.05717037573321572
Trained batch 620 in epoch 3, gen_loss = 0.46735987158405223, disc_loss = 0.05708953198540398
Trained batch 621 in epoch 3, gen_loss = 0.46744833038550865, disc_loss = 0.05701254951390303
Trained batch 622 in epoch 3, gen_loss = 0.46742253644125803, disc_loss = 0.05697421228997469
Trained batch 623 in epoch 3, gen_loss = 0.4673652806534217, disc_loss = 0.05691691399298202
Trained batch 624 in epoch 3, gen_loss = 0.46737226610183713, disc_loss = 0.0569723175726831
Trained batch 625 in epoch 3, gen_loss = 0.46748922512934993, disc_loss = 0.0573675727416663
Trained batch 626 in epoch 3, gen_loss = 0.46746568203542793, disc_loss = 0.05735978293061803
Trained batch 627 in epoch 3, gen_loss = 0.46726511660844655, disc_loss = 0.057309796596924735
Trained batch 628 in epoch 3, gen_loss = 0.4672757314669119, disc_loss = 0.05730300184875277
Trained batch 629 in epoch 3, gen_loss = 0.4673353993230396, disc_loss = 0.05725031472846038
Trained batch 630 in epoch 3, gen_loss = 0.46725807122874374, disc_loss = 0.05728232050786849
Trained batch 631 in epoch 3, gen_loss = 0.4672580108140843, disc_loss = 0.05726139920784302
Trained batch 632 in epoch 3, gen_loss = 0.46723574414072444, disc_loss = 0.057194949357989605
Trained batch 633 in epoch 3, gen_loss = 0.4672843175073527, disc_loss = 0.05718376680441812
Trained batch 634 in epoch 3, gen_loss = 0.4672563114034848, disc_loss = 0.05717481396667014
Trained batch 635 in epoch 3, gen_loss = 0.4672864854991811, disc_loss = 0.05716738372721926
Trained batch 636 in epoch 3, gen_loss = 0.4671520242230671, disc_loss = 0.05718001768539778
Trained batch 637 in epoch 3, gen_loss = 0.4670643305236643, disc_loss = 0.0572040912346348
Trained batch 638 in epoch 3, gen_loss = 0.46700247585866744, disc_loss = 0.05715162904513344
Trained batch 639 in epoch 3, gen_loss = 0.46691718404181304, disc_loss = 0.05710167139113764
Trained batch 640 in epoch 3, gen_loss = 0.4669384105529131, disc_loss = 0.05738527070245649
Trained batch 641 in epoch 3, gen_loss = 0.4668626232403461, disc_loss = 0.05754310511722813
Trained batch 642 in epoch 3, gen_loss = 0.46672010120485286, disc_loss = 0.057478019207988285
Trained batch 643 in epoch 3, gen_loss = 0.46664715636961207, disc_loss = 0.0575532613239708
Trained batch 644 in epoch 3, gen_loss = 0.46667249586231024, disc_loss = 0.05750971486098891
Trained batch 645 in epoch 3, gen_loss = 0.4666233170235489, disc_loss = 0.05750939605725877
Trained batch 646 in epoch 3, gen_loss = 0.4666026050838105, disc_loss = 0.05747629326035541
Trained batch 647 in epoch 3, gen_loss = 0.4665659098069609, disc_loss = 0.05755130234275036
Trained batch 648 in epoch 3, gen_loss = 0.46663349797986503, disc_loss = 0.057574199193310804
Trained batch 649 in epoch 3, gen_loss = 0.46647931694984435, disc_loss = 0.05751344668105818
Trained batch 650 in epoch 3, gen_loss = 0.4664455662308384, disc_loss = 0.057516829065618016
Trained batch 651 in epoch 3, gen_loss = 0.4664829635729819, disc_loss = 0.05751847040888059
Trained batch 652 in epoch 3, gen_loss = 0.46650882879953837, disc_loss = 0.05749086453115844
Trained batch 653 in epoch 3, gen_loss = 0.4664098843704305, disc_loss = 0.05754345340372294
Trained batch 654 in epoch 3, gen_loss = 0.46628629547039063, disc_loss = 0.057490913654528276
Trained batch 655 in epoch 3, gen_loss = 0.46631060822344406, disc_loss = 0.057420940072383596
Trained batch 656 in epoch 3, gen_loss = 0.46630633067866983, disc_loss = 0.057370237702053024
Trained batch 657 in epoch 3, gen_loss = 0.46637275543256373, disc_loss = 0.05741019760071665
Trained batch 658 in epoch 3, gen_loss = 0.46644830622332956, disc_loss = 0.05746922707778708
Trained batch 659 in epoch 3, gen_loss = 0.4664035418719956, disc_loss = 0.05741940935946662
Trained batch 660 in epoch 3, gen_loss = 0.4664289627150941, disc_loss = 0.05736644851725757
Trained batch 661 in epoch 3, gen_loss = 0.46636574465522596, disc_loss = 0.057325446898725416
Trained batch 662 in epoch 3, gen_loss = 0.46633228133706484, disc_loss = 0.05730935158545143
Trained batch 663 in epoch 3, gen_loss = 0.4662740809102374, disc_loss = 0.0572940352006748
Trained batch 664 in epoch 3, gen_loss = 0.4663655052059575, disc_loss = 0.05722896699492532
Trained batch 665 in epoch 3, gen_loss = 0.46648098349392236, disc_loss = 0.057185228577711515
Trained batch 666 in epoch 3, gen_loss = 0.46647546584459615, disc_loss = 0.05712626106978423
Trained batch 667 in epoch 3, gen_loss = 0.46635442218202316, disc_loss = 0.057053119038276284
Trained batch 668 in epoch 3, gen_loss = 0.466230801981839, disc_loss = 0.05699150212685423
Trained batch 669 in epoch 3, gen_loss = 0.46626993609008505, disc_loss = 0.056929539343508986
Trained batch 670 in epoch 3, gen_loss = 0.46625078093099526, disc_loss = 0.056893965014951906
Trained batch 671 in epoch 3, gen_loss = 0.4663046699105984, disc_loss = 0.05686168703513907
Trained batch 672 in epoch 3, gen_loss = 0.4663278073470979, disc_loss = 0.05680901692477214
Trained batch 673 in epoch 3, gen_loss = 0.4662806810009727, disc_loss = 0.056741105275814496
Trained batch 674 in epoch 3, gen_loss = 0.4662796868218316, disc_loss = 0.05666756862912465
Trained batch 675 in epoch 3, gen_loss = 0.466271213834455, disc_loss = 0.056620826606484424
Trained batch 676 in epoch 3, gen_loss = 0.4663042494342105, disc_loss = 0.05655762248712439
Trained batch 677 in epoch 3, gen_loss = 0.46637799197417795, disc_loss = 0.056484450976938494
Trained batch 678 in epoch 3, gen_loss = 0.46640586607234996, disc_loss = 0.056409489063735344
Trained batch 679 in epoch 3, gen_loss = 0.4664438714875894, disc_loss = 0.05634212933193125
Trained batch 680 in epoch 3, gen_loss = 0.46647691341573794, disc_loss = 0.056284091594696
Trained batch 681 in epoch 3, gen_loss = 0.4665577355717634, disc_loss = 0.056214737518119715
Trained batch 682 in epoch 3, gen_loss = 0.46659659270311693, disc_loss = 0.056142309410593
Trained batch 683 in epoch 3, gen_loss = 0.46668626860394113, disc_loss = 0.05608051304694548
Trained batch 684 in epoch 3, gen_loss = 0.46661472947058014, disc_loss = 0.05602602373645471
Trained batch 685 in epoch 3, gen_loss = 0.46659201513921555, disc_loss = 0.05602411276446357
Trained batch 686 in epoch 3, gen_loss = 0.46651138111493473, disc_loss = 0.05595927304971904
Trained batch 687 in epoch 3, gen_loss = 0.4664957394260307, disc_loss = 0.0559005199330534
Trained batch 688 in epoch 3, gen_loss = 0.4664978179080393, disc_loss = 0.05607941478804424
Trained batch 689 in epoch 3, gen_loss = 0.46649126043354255, disc_loss = 0.05603926943048187
Trained batch 690 in epoch 3, gen_loss = 0.4663909963088167, disc_loss = 0.056043161777442514
Trained batch 691 in epoch 3, gen_loss = 0.466266248999648, disc_loss = 0.056001349653768746
Trained batch 692 in epoch 3, gen_loss = 0.46628305208459386, disc_loss = 0.05593817446698014
Trained batch 693 in epoch 3, gen_loss = 0.46629843029920925, disc_loss = 0.055942724273682326
Trained batch 694 in epoch 3, gen_loss = 0.46623763317684475, disc_loss = 0.05592340588998451
Trained batch 695 in epoch 3, gen_loss = 0.46621077486324586, disc_loss = 0.055991976147239234
Trained batch 696 in epoch 3, gen_loss = 0.4661797905498461, disc_loss = 0.055960355216965955
Trained batch 697 in epoch 3, gen_loss = 0.4662895547199386, disc_loss = 0.05591211557110777
Trained batch 698 in epoch 3, gen_loss = 0.466347719765187, disc_loss = 0.05593384748513948
Trained batch 699 in epoch 3, gen_loss = 0.46654637724161147, disc_loss = 0.055915945496942315
Trained batch 700 in epoch 3, gen_loss = 0.4665352411770106, disc_loss = 0.055861631325962884
Trained batch 701 in epoch 3, gen_loss = 0.4665012585896033, disc_loss = 0.05584636397999406
Trained batch 702 in epoch 3, gen_loss = 0.46655616689881424, disc_loss = 0.05577980579111518
Trained batch 703 in epoch 3, gen_loss = 0.4665707920847291, disc_loss = 0.05571235099738591
Trained batch 704 in epoch 3, gen_loss = 0.466593591583536, disc_loss = 0.05567682420451802
Trained batch 705 in epoch 3, gen_loss = 0.4665160826684395, disc_loss = 0.055606843539574326
Trained batch 706 in epoch 3, gen_loss = 0.46662890582307226, disc_loss = 0.055578419124599564
Trained batch 707 in epoch 3, gen_loss = 0.4666097460072593, disc_loss = 0.055561010220672113
Trained batch 708 in epoch 3, gen_loss = 0.4665457118297329, disc_loss = 0.05548998147409478
Trained batch 709 in epoch 3, gen_loss = 0.4664802413171446, disc_loss = 0.055462414102996106
Trained batch 710 in epoch 3, gen_loss = 0.46665356602682173, disc_loss = 0.05545299411482805
Trained batch 711 in epoch 3, gen_loss = 0.4666335430791539, disc_loss = 0.05545269807060302
Trained batch 712 in epoch 3, gen_loss = 0.46663562215728815, disc_loss = 0.055419356276791905
Trained batch 713 in epoch 3, gen_loss = 0.4665265940234107, disc_loss = 0.0553637232862319
Trained batch 714 in epoch 3, gen_loss = 0.46655817302790553, disc_loss = 0.055310432384298606
Trained batch 715 in epoch 3, gen_loss = 0.46656034304110033, disc_loss = 0.05525767458043472
Trained batch 716 in epoch 3, gen_loss = 0.4665900230657107, disc_loss = 0.05518861475362958
Trained batch 717 in epoch 3, gen_loss = 0.46659310199424087, disc_loss = 0.05515647202556367
Trained batch 718 in epoch 3, gen_loss = 0.46652514799413825, disc_loss = 0.0551200433768933
Trained batch 719 in epoch 3, gen_loss = 0.4664674079666535, disc_loss = 0.05505200862017874
Trained batch 720 in epoch 3, gen_loss = 0.4665359640171062, disc_loss = 0.05498925516195854
Trained batch 721 in epoch 3, gen_loss = 0.466585071834831, disc_loss = 0.05492605245801158
Trained batch 722 in epoch 3, gen_loss = 0.46657244805478454, disc_loss = 0.054859453385224355
Trained batch 723 in epoch 3, gen_loss = 0.4665972496593855, disc_loss = 0.054789659843100906
Trained batch 724 in epoch 3, gen_loss = 0.46663420356553176, disc_loss = 0.05473583568080232
Trained batch 725 in epoch 3, gen_loss = 0.4666659813938719, disc_loss = 0.05468479710241097
Trained batch 726 in epoch 3, gen_loss = 0.46664231531885664, disc_loss = 0.05461980734773728
Trained batch 727 in epoch 3, gen_loss = 0.46671423872748574, disc_loss = 0.054559843821942317
Trained batch 728 in epoch 3, gen_loss = 0.4667359187033932, disc_loss = 0.05449155897453979
Trained batch 729 in epoch 3, gen_loss = 0.4667001466636788, disc_loss = 0.05442403074200839
Trained batch 730 in epoch 3, gen_loss = 0.4666925656893348, disc_loss = 0.05436116078978076
Trained batch 731 in epoch 3, gen_loss = 0.46671636146111567, disc_loss = 0.05429343247144926
Trained batch 732 in epoch 3, gen_loss = 0.46658585516362366, disc_loss = 0.05425168592914797
Trained batch 733 in epoch 3, gen_loss = 0.4666961596755955, disc_loss = 0.05439249810582529
Trained batch 734 in epoch 3, gen_loss = 0.46670678752620204, disc_loss = 0.054413681043958176
Trained batch 735 in epoch 3, gen_loss = 0.46660500979455916, disc_loss = 0.05442699418231116
Trained batch 736 in epoch 3, gen_loss = 0.46663276363907225, disc_loss = 0.054387299778645044
Trained batch 737 in epoch 3, gen_loss = 0.46659462388130385, disc_loss = 0.05439082598995145
Trained batch 738 in epoch 3, gen_loss = 0.466568019498185, disc_loss = 0.05433172273105552
Trained batch 739 in epoch 3, gen_loss = 0.4665359364570798, disc_loss = 0.05429225895000068
Trained batch 740 in epoch 3, gen_loss = 0.4665015933082493, disc_loss = 0.054301667257178166
Trained batch 741 in epoch 3, gen_loss = 0.4665162971398901, disc_loss = 0.05427656293347116
Trained batch 742 in epoch 3, gen_loss = 0.4665502266078425, disc_loss = 0.05424245701122573
Trained batch 743 in epoch 3, gen_loss = 0.4666427862179536, disc_loss = 0.05420467243980496
Trained batch 744 in epoch 3, gen_loss = 0.4667270443983526, disc_loss = 0.0541693954834802
Trained batch 745 in epoch 3, gen_loss = 0.46668507014938077, disc_loss = 0.05415227484637147
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.4790954887866974, disc_loss = 0.013452956452965736
Trained batch 1 in epoch 4, gen_loss = 0.4993576854467392, disc_loss = 0.011930863372981548
Trained batch 2 in epoch 4, gen_loss = 0.49144334594408673, disc_loss = 0.011664581795533499
Trained batch 3 in epoch 4, gen_loss = 0.47966399043798447, disc_loss = 0.011629619169980288
Trained batch 4 in epoch 4, gen_loss = 0.4810871422290802, disc_loss = 0.020219871029257774
Trained batch 5 in epoch 4, gen_loss = 0.4605814814567566, disc_loss = 0.029905228254695732
Trained batch 6 in epoch 4, gen_loss = 0.4578480763094766, disc_loss = 0.026800807831542834
Trained batch 7 in epoch 4, gen_loss = 0.4576970301568508, disc_loss = 0.028062909143045545
Trained batch 8 in epoch 4, gen_loss = 0.4678320785363515, disc_loss = 0.02615342289209366
Trained batch 9 in epoch 4, gen_loss = 0.46914770901203157, disc_loss = 0.024752815999090672
Trained batch 10 in epoch 4, gen_loss = 0.46170181848786096, disc_loss = 0.02303793840110302
Trained batch 11 in epoch 4, gen_loss = 0.46555688232183456, disc_loss = 0.02239833779943486
Trained batch 12 in epoch 4, gen_loss = 0.4617599913707146, disc_loss = 0.021158612691439115
Trained batch 13 in epoch 4, gen_loss = 0.45543391151087625, disc_loss = 0.020237425874386514
Trained batch 14 in epoch 4, gen_loss = 0.4573659300804138, disc_loss = 0.020117911572257677
Trained batch 15 in epoch 4, gen_loss = 0.46194231510162354, disc_loss = 0.01959556498331949
Trained batch 16 in epoch 4, gen_loss = 0.4581235980286318, disc_loss = 0.01900179437635576
Trained batch 17 in epoch 4, gen_loss = 0.462161757879787, disc_loss = 0.018502849309394758
Trained batch 18 in epoch 4, gen_loss = 0.46627792402317647, disc_loss = 0.01801514414776313
Trained batch 19 in epoch 4, gen_loss = 0.4683914765715599, disc_loss = 0.017525876173749566
Trained batch 20 in epoch 4, gen_loss = 0.4675129098551614, disc_loss = 0.017246001222658725
Trained batch 21 in epoch 4, gen_loss = 0.46763021973046387, disc_loss = 0.018532904584638098
Trained batch 22 in epoch 4, gen_loss = 0.46752623241880664, disc_loss = 0.020555166649105755
Trained batch 23 in epoch 4, gen_loss = 0.46833572288354236, disc_loss = 0.020272303295011323
Trained batch 24 in epoch 4, gen_loss = 0.4678751242160797, disc_loss = 0.02000017449259758
Trained batch 25 in epoch 4, gen_loss = 0.46741279386557066, disc_loss = 0.01953423460229085
Trained batch 26 in epoch 4, gen_loss = 0.4631858666737874, disc_loss = 0.020310319753156766
Trained batch 27 in epoch 4, gen_loss = 0.46461899152823855, disc_loss = 0.02672686700576118
Trained batch 28 in epoch 4, gen_loss = 0.46396284473353416, disc_loss = 0.0282953387319014
Trained batch 29 in epoch 4, gen_loss = 0.4631783942381541, disc_loss = 0.028004215533534684
Trained batch 30 in epoch 4, gen_loss = 0.4638155823753726, disc_loss = 0.027299747036229217
Trained batch 31 in epoch 4, gen_loss = 0.46395864989608526, disc_loss = 0.02676542090193834
Trained batch 32 in epoch 4, gen_loss = 0.46400038852836145, disc_loss = 0.026415132649355764
Trained batch 33 in epoch 4, gen_loss = 0.4673207936918034, disc_loss = 0.026244830709936863
Trained batch 34 in epoch 4, gen_loss = 0.46458760585103714, disc_loss = 0.02596119103421058
Trained batch 35 in epoch 4, gen_loss = 0.46463220732079613, disc_loss = 0.025674807153538697
Trained batch 36 in epoch 4, gen_loss = 0.46583152542243134, disc_loss = 0.027791818289237248
Trained batch 37 in epoch 4, gen_loss = 0.4661213724236739, disc_loss = 0.027757849973185283
Trained batch 38 in epoch 4, gen_loss = 0.4674031214836316, disc_loss = 0.02775719555285879
Trained batch 39 in epoch 4, gen_loss = 0.4661297664046288, disc_loss = 0.02757992543047294
Trained batch 40 in epoch 4, gen_loss = 0.46530022708381097, disc_loss = 0.028076665282885476
Trained batch 41 in epoch 4, gen_loss = 0.4658942563193185, disc_loss = 0.027624826201991665
Trained batch 42 in epoch 4, gen_loss = 0.4660359912140425, disc_loss = 0.027171324711119712
Trained batch 43 in epoch 4, gen_loss = 0.4654080644249916, disc_loss = 0.027536104888316582
Trained batch 44 in epoch 4, gen_loss = 0.46668081084887186, disc_loss = 0.027326090540736914
Trained batch 45 in epoch 4, gen_loss = 0.4680754289678905, disc_loss = 0.027680887466134584
Trained batch 46 in epoch 4, gen_loss = 0.4681506080830351, disc_loss = 0.027411398567021527
Trained batch 47 in epoch 4, gen_loss = 0.46825039635101956, disc_loss = 0.027080449285373714
Trained batch 48 in epoch 4, gen_loss = 0.4684865432126181, disc_loss = 0.02683642764138628
Trained batch 49 in epoch 4, gen_loss = 0.46941432178020476, disc_loss = 0.02674288268201053
Trained batch 50 in epoch 4, gen_loss = 0.47098902685969485, disc_loss = 0.026957025742340907
Trained batch 51 in epoch 4, gen_loss = 0.4720447115026988, disc_loss = 0.02661118623263274
Trained batch 52 in epoch 4, gen_loss = 0.4719070505421117, disc_loss = 0.026668873624348978
Trained batch 53 in epoch 4, gen_loss = 0.472189513069612, disc_loss = 0.026369860093971645
Trained batch 54 in epoch 4, gen_loss = 0.472949723222039, disc_loss = 0.02621327182278037
Trained batch 55 in epoch 4, gen_loss = 0.47236710840037893, disc_loss = 0.02582557571752529
Trained batch 56 in epoch 4, gen_loss = 0.4721755908246626, disc_loss = 0.02785793436168317
Trained batch 57 in epoch 4, gen_loss = 0.47280556066282864, disc_loss = 0.02997647295705974
Trained batch 58 in epoch 4, gen_loss = 0.4724543109788733, disc_loss = 0.029765908551102473
Trained batch 59 in epoch 4, gen_loss = 0.47296405682961146, disc_loss = 0.03037739550539603
Trained batch 60 in epoch 4, gen_loss = 0.4723294831690241, disc_loss = 0.029996695737430794
Trained batch 61 in epoch 4, gen_loss = 0.472621099122109, disc_loss = 0.029896968202064594
Trained batch 62 in epoch 4, gen_loss = 0.47279284208539935, disc_loss = 0.03005730255048663
Trained batch 63 in epoch 4, gen_loss = 0.4723567636683583, disc_loss = 0.030118050875898916
Trained batch 64 in epoch 4, gen_loss = 0.4707220944074484, disc_loss = 0.030198297943346775
Trained batch 65 in epoch 4, gen_loss = 0.47162454823652905, disc_loss = 0.030187284072973962
Trained batch 66 in epoch 4, gen_loss = 0.4709845905873313, disc_loss = 0.029873083797352974
Trained batch 67 in epoch 4, gen_loss = 0.4714612662792206, disc_loss = 0.029643737142631674
Trained batch 68 in epoch 4, gen_loss = 0.47214648084364075, disc_loss = 0.02961007886957647
Trained batch 69 in epoch 4, gen_loss = 0.47303046924727304, disc_loss = 0.02941407144202718
Trained batch 70 in epoch 4, gen_loss = 0.4737340228658327, disc_loss = 0.029236814039956097
Trained batch 71 in epoch 4, gen_loss = 0.47374217833081883, disc_loss = 0.028945944860525843
Trained batch 72 in epoch 4, gen_loss = 0.4747204588700647, disc_loss = 0.028919753675948675
Trained batch 73 in epoch 4, gen_loss = 0.4759767953608487, disc_loss = 0.028639042038923583
Trained batch 74 in epoch 4, gen_loss = 0.47530943115552265, disc_loss = 0.028864648186912138
Trained batch 75 in epoch 4, gen_loss = 0.474274658058819, disc_loss = 0.028892572570935283
Trained batch 76 in epoch 4, gen_loss = 0.47398512046058455, disc_loss = 0.02858519528738477
Trained batch 77 in epoch 4, gen_loss = 0.47376433053077793, disc_loss = 0.02827909704632102
Trained batch 78 in epoch 4, gen_loss = 0.4744579026216193, disc_loss = 0.02797652636006286
Trained batch 79 in epoch 4, gen_loss = 0.47432078532874583, disc_loss = 0.028090805991087108
Trained batch 80 in epoch 4, gen_loss = 0.4738089718200542, disc_loss = 0.028344240694962167
Trained batch 81 in epoch 4, gen_loss = 0.47449400839282246, disc_loss = 0.028087008744478226
Trained batch 82 in epoch 4, gen_loss = 0.4750780481171895, disc_loss = 0.02788728487913508
Trained batch 83 in epoch 4, gen_loss = 0.47483569844847634, disc_loss = 0.027770606301991
Trained batch 84 in epoch 4, gen_loss = 0.47405943029067094, disc_loss = 0.02770571008543758
Trained batch 85 in epoch 4, gen_loss = 0.47351436351620874, disc_loss = 0.02772514731081766
Trained batch 86 in epoch 4, gen_loss = 0.4726514970434123, disc_loss = 0.027599326484761703
Trained batch 87 in epoch 4, gen_loss = 0.4731480150737546, disc_loss = 0.027406726498156786
Trained batch 88 in epoch 4, gen_loss = 0.47341367870234374, disc_loss = 0.02716636278907235
Trained batch 89 in epoch 4, gen_loss = 0.4731852951976988, disc_loss = 0.027065387782123355
Trained batch 90 in epoch 4, gen_loss = 0.47358322045305273, disc_loss = 0.02686776237173395
Trained batch 91 in epoch 4, gen_loss = 0.4741058275103569, disc_loss = 0.026876965173236702
Trained batch 92 in epoch 4, gen_loss = 0.4734838858086576, disc_loss = 0.027265592728571226
Trained batch 93 in epoch 4, gen_loss = 0.473583736635269, disc_loss = 0.027304622384303427
Trained batch 94 in epoch 4, gen_loss = 0.47421613021900777, disc_loss = 0.027491269241038122
Trained batch 95 in epoch 4, gen_loss = 0.47446283729126054, disc_loss = 0.027520830257950973
Trained batch 96 in epoch 4, gen_loss = 0.473479776038337, disc_loss = 0.02748637663718966
Trained batch 97 in epoch 4, gen_loss = 0.4725643192626992, disc_loss = 0.027984513407002906
Trained batch 98 in epoch 4, gen_loss = 0.4729668784021127, disc_loss = 0.02791314415934712
Trained batch 99 in epoch 4, gen_loss = 0.4736017403006554, disc_loss = 0.027731467708945273
Trained batch 100 in epoch 4, gen_loss = 0.4734904928372638, disc_loss = 0.027505002560850124
Trained batch 101 in epoch 4, gen_loss = 0.4744049728501077, disc_loss = 0.027389132979271168
Trained batch 102 in epoch 4, gen_loss = 0.47437476475261947, disc_loss = 0.02751458056035985
Trained batch 103 in epoch 4, gen_loss = 0.4745077525193875, disc_loss = 0.027471957759609304
Trained batch 104 in epoch 4, gen_loss = 0.4749130476088751, disc_loss = 0.028075709544299613
Trained batch 105 in epoch 4, gen_loss = 0.47550279183207816, disc_loss = 0.028248052090793004
Trained batch 106 in epoch 4, gen_loss = 0.4749817678304476, disc_loss = 0.028406434836057582
Trained batch 107 in epoch 4, gen_loss = 0.47434086324992003, disc_loss = 0.0283498845571928
Trained batch 108 in epoch 4, gen_loss = 0.4738312051930559, disc_loss = 0.028583618423499917
Trained batch 109 in epoch 4, gen_loss = 0.4738400453870947, disc_loss = 0.02876974000087516
Trained batch 110 in epoch 4, gen_loss = 0.47308691906499434, disc_loss = 0.028790940064936876
Trained batch 111 in epoch 4, gen_loss = 0.4729240212057318, disc_loss = 0.028712612772194137
Trained batch 112 in epoch 4, gen_loss = 0.4725246432080733, disc_loss = 0.028551576547819164
Trained batch 113 in epoch 4, gen_loss = 0.47350440867114485, disc_loss = 0.02847568125856158
Trained batch 114 in epoch 4, gen_loss = 0.4737088327822478, disc_loss = 0.028620980100949173
Trained batch 115 in epoch 4, gen_loss = 0.47391061793113576, disc_loss = 0.028564275535433715
Trained batch 116 in epoch 4, gen_loss = 0.47360341034383857, disc_loss = 0.0283981261926138
Trained batch 117 in epoch 4, gen_loss = 0.4735328860707202, disc_loss = 0.02832035021461799
Trained batch 118 in epoch 4, gen_loss = 0.4727611727073413, disc_loss = 0.02861682158511351
Trained batch 119 in epoch 4, gen_loss = 0.4725865470866362, disc_loss = 0.029078907166452457
Trained batch 120 in epoch 4, gen_loss = 0.4722964667584285, disc_loss = 0.02937806399600688
Trained batch 121 in epoch 4, gen_loss = 0.4722130266857929, disc_loss = 0.02934456006318453
Trained batch 122 in epoch 4, gen_loss = 0.472143688579885, disc_loss = 0.029274924684739936
Trained batch 123 in epoch 4, gen_loss = 0.4720876716798352, disc_loss = 0.029160972733441138
Trained batch 124 in epoch 4, gen_loss = 0.471828887462616, disc_loss = 0.029410620141774417
Trained batch 125 in epoch 4, gen_loss = 0.471392085627904, disc_loss = 0.030300991923829155
Trained batch 126 in epoch 4, gen_loss = 0.4713761675076222, disc_loss = 0.030153873658878363
Trained batch 127 in epoch 4, gen_loss = 0.4713746460620314, disc_loss = 0.03072787556084222
Trained batch 128 in epoch 4, gen_loss = 0.47091636477514753, disc_loss = 0.030586331097279176
Trained batch 129 in epoch 4, gen_loss = 0.470781476681049, disc_loss = 0.030474722381824484
Trained batch 130 in epoch 4, gen_loss = 0.47037484627643616, disc_loss = 0.03038501662365694
Trained batch 131 in epoch 4, gen_loss = 0.47083687421047327, disc_loss = 0.030776558073491535
Trained batch 132 in epoch 4, gen_loss = 0.4708137610801181, disc_loss = 0.030616335567311012
Trained batch 133 in epoch 4, gen_loss = 0.46991092189034417, disc_loss = 0.030544144320371214
Trained batch 134 in epoch 4, gen_loss = 0.469527695134834, disc_loss = 0.03051902427924452
Trained batch 135 in epoch 4, gen_loss = 0.4695710971513215, disc_loss = 0.030443077040699255
Trained batch 136 in epoch 4, gen_loss = 0.46979231142649686, disc_loss = 0.030297329700314
Trained batch 137 in epoch 4, gen_loss = 0.4693569670552793, disc_loss = 0.030163300544212478
Trained batch 138 in epoch 4, gen_loss = 0.46942671961921584, disc_loss = 0.03004629506307433
Trained batch 139 in epoch 4, gen_loss = 0.4689758002758026, disc_loss = 0.030045629369228014
Trained batch 140 in epoch 4, gen_loss = 0.46881114887007586, disc_loss = 0.029947080626317586
Trained batch 141 in epoch 4, gen_loss = 0.4690899156348806, disc_loss = 0.0297942129324492
Trained batch 142 in epoch 4, gen_loss = 0.46931765796421293, disc_loss = 0.029677615699625307
Trained batch 143 in epoch 4, gen_loss = 0.4695943436688847, disc_loss = 0.029885482932311587
Trained batch 144 in epoch 4, gen_loss = 0.46928097297405374, disc_loss = 0.030143842624564623
Trained batch 145 in epoch 4, gen_loss = 0.4690306203006065, disc_loss = 0.030294414823364518
Trained batch 146 in epoch 4, gen_loss = 0.46863723895987686, disc_loss = 0.03027950197800386
Trained batch 147 in epoch 4, gen_loss = 0.4690862555761595, disc_loss = 0.030106283853308775
Trained batch 148 in epoch 4, gen_loss = 0.4694323623740433, disc_loss = 0.029961988132997046
Trained batch 149 in epoch 4, gen_loss = 0.4698041741053263, disc_loss = 0.030078888091569146
Trained batch 150 in epoch 4, gen_loss = 0.4694777073844379, disc_loss = 0.03007541668743191
Trained batch 151 in epoch 4, gen_loss = 0.46967391728570584, disc_loss = 0.03001000619750764
Trained batch 152 in epoch 4, gen_loss = 0.46980811100380093, disc_loss = 0.029868223275258846
Trained batch 153 in epoch 4, gen_loss = 0.4701508481007118, disc_loss = 0.029970608424854935
Trained batch 154 in epoch 4, gen_loss = 0.4701451109301659, disc_loss = 0.029840889197563933
Trained batch 155 in epoch 4, gen_loss = 0.4700237153432308, disc_loss = 0.029818882159769345
Trained batch 156 in epoch 4, gen_loss = 0.4702107847496203, disc_loss = 0.0298214012573052
Trained batch 157 in epoch 4, gen_loss = 0.46985803770868084, disc_loss = 0.029844841810792118
Trained batch 158 in epoch 4, gen_loss = 0.469656692173496, disc_loss = 0.02979557572002962
Trained batch 159 in epoch 4, gen_loss = 0.47020587231963873, disc_loss = 0.02975436555861961
Trained batch 160 in epoch 4, gen_loss = 0.4704848711164842, disc_loss = 0.029658629365195956
Trained batch 161 in epoch 4, gen_loss = 0.47056018128807164, disc_loss = 0.02950875826444431
Trained batch 162 in epoch 4, gen_loss = 0.4708592291989941, disc_loss = 0.029415060660339023
Trained batch 163 in epoch 4, gen_loss = 0.4705733944003175, disc_loss = 0.029336577931578022
Trained batch 164 in epoch 4, gen_loss = 0.4703725379524809, disc_loss = 0.029187032577553482
Trained batch 165 in epoch 4, gen_loss = 0.4708281322775117, disc_loss = 0.0290848198262638
Trained batch 166 in epoch 4, gen_loss = 0.4704505735171769, disc_loss = 0.02893753041384998
Trained batch 167 in epoch 4, gen_loss = 0.4703555864592393, disc_loss = 0.028809056645037516
Trained batch 168 in epoch 4, gen_loss = 0.4702104929636216, disc_loss = 0.028708645506326617
Trained batch 169 in epoch 4, gen_loss = 0.4702303716365029, disc_loss = 0.028572764318874653
Trained batch 170 in epoch 4, gen_loss = 0.47046787749257, disc_loss = 0.028462499064224506
Trained batch 171 in epoch 4, gen_loss = 0.4701203456105188, disc_loss = 0.028391654614012603
Trained batch 172 in epoch 4, gen_loss = 0.46990163064416435, disc_loss = 0.02824813038961305
Trained batch 173 in epoch 4, gen_loss = 0.46965060734200753, disc_loss = 0.028119098194393104
Trained batch 174 in epoch 4, gen_loss = 0.46977392537253243, disc_loss = 0.028044779670557806
Trained batch 175 in epoch 4, gen_loss = 0.4698069901628928, disc_loss = 0.027910411201777275
Trained batch 176 in epoch 4, gen_loss = 0.4699485258194013, disc_loss = 0.02782181534905639
Trained batch 177 in epoch 4, gen_loss = 0.46986708882149686, disc_loss = 0.027787515247408093
Trained batch 178 in epoch 4, gen_loss = 0.4698634429017925, disc_loss = 0.027673642268123407
Trained batch 179 in epoch 4, gen_loss = 0.46927294896708593, disc_loss = 0.027612441372022862
Trained batch 180 in epoch 4, gen_loss = 0.46879351912941064, disc_loss = 0.027489429916054506
Trained batch 181 in epoch 4, gen_loss = 0.4687734812825591, disc_loss = 0.02750840794376947
Trained batch 182 in epoch 4, gen_loss = 0.4684550190558199, disc_loss = 0.02742169795384824
Trained batch 183 in epoch 4, gen_loss = 0.46826847545478656, disc_loss = 0.02752479572739938
Trained batch 184 in epoch 4, gen_loss = 0.46783622873796, disc_loss = 0.02757150192518492
Trained batch 185 in epoch 4, gen_loss = 0.46795704544231453, disc_loss = 0.027476408759192113
Trained batch 186 in epoch 4, gen_loss = 0.46797967753945824, disc_loss = 0.02751534951123643
Trained batch 187 in epoch 4, gen_loss = 0.4678397018541681, disc_loss = 0.02746855445760996
Trained batch 188 in epoch 4, gen_loss = 0.4679483817052589, disc_loss = 0.027405871718964248
Trained batch 189 in epoch 4, gen_loss = 0.4685252950379723, disc_loss = 0.02831683484347243
Trained batch 190 in epoch 4, gen_loss = 0.46851807021345765, disc_loss = 0.028446936638567462
Trained batch 191 in epoch 4, gen_loss = 0.4680680899570386, disc_loss = 0.028545552825865645
Trained batch 192 in epoch 4, gen_loss = 0.46849673615836107, disc_loss = 0.028838627928279223
Trained batch 193 in epoch 4, gen_loss = 0.4682948199129596, disc_loss = 0.028941063383190902
Trained batch 194 in epoch 4, gen_loss = 0.4683134817160093, disc_loss = 0.029020946148114325
Trained batch 195 in epoch 4, gen_loss = 0.4681705014438045, disc_loss = 0.029106826787548407
Trained batch 196 in epoch 4, gen_loss = 0.46839104751645005, disc_loss = 0.02923525552156613
Trained batch 197 in epoch 4, gen_loss = 0.46841665410032174, disc_loss = 0.029158128378442442
Trained batch 198 in epoch 4, gen_loss = 0.4681677232735121, disc_loss = 0.029070574284797937
Trained batch 199 in epoch 4, gen_loss = 0.4678128717839718, disc_loss = 0.02905791827477515
Trained batch 200 in epoch 4, gen_loss = 0.4678106431047715, disc_loss = 0.029305698572477296
Trained batch 201 in epoch 4, gen_loss = 0.46785189093339563, disc_loss = 0.029203968565210257
Trained batch 202 in epoch 4, gen_loss = 0.4677148089913899, disc_loss = 0.02938082981212386
Trained batch 203 in epoch 4, gen_loss = 0.4675840818706681, disc_loss = 0.029306633827075653
Trained batch 204 in epoch 4, gen_loss = 0.46757888139747994, disc_loss = 0.029344537845108567
Trained batch 205 in epoch 4, gen_loss = 0.46792583630501644, disc_loss = 0.029340258383562842
Trained batch 206 in epoch 4, gen_loss = 0.4676507180151732, disc_loss = 0.029506118104293728
Trained batch 207 in epoch 4, gen_loss = 0.4677076004445553, disc_loss = 0.02963949636950229
Trained batch 208 in epoch 4, gen_loss = 0.4681034621439482, disc_loss = 0.029536070649703722
Trained batch 209 in epoch 4, gen_loss = 0.4679994158801578, disc_loss = 0.030880429418314072
Trained batch 210 in epoch 4, gen_loss = 0.46724641958684154, disc_loss = 0.0313582983909625
Trained batch 211 in epoch 4, gen_loss = 0.4673160750348613, disc_loss = 0.031572869012378296
Trained batch 212 in epoch 4, gen_loss = 0.4672915396835882, disc_loss = 0.031874796279439344
Trained batch 213 in epoch 4, gen_loss = 0.46722379424304605, disc_loss = 0.031880206820145945
Trained batch 214 in epoch 4, gen_loss = 0.46703303276106367, disc_loss = 0.03207508826325106
Trained batch 215 in epoch 4, gen_loss = 0.46733667701482773, disc_loss = 0.03203340333507017
Trained batch 216 in epoch 4, gen_loss = 0.4674382229005137, disc_loss = 0.03249563218399127
Trained batch 217 in epoch 4, gen_loss = 0.46714291154244625, disc_loss = 0.032536743140412036
Trained batch 218 in epoch 4, gen_loss = 0.46743007487358024, disc_loss = 0.03248693236069048
Trained batch 219 in epoch 4, gen_loss = 0.4673585278066722, disc_loss = 0.032477539439092984
Trained batch 220 in epoch 4, gen_loss = 0.46752247349169457, disc_loss = 0.03245766008298052
Trained batch 221 in epoch 4, gen_loss = 0.46750587090715634, disc_loss = 0.03267547789424121
Trained batch 222 in epoch 4, gen_loss = 0.46746091163746445, disc_loss = 0.03265976585915538
Trained batch 223 in epoch 4, gen_loss = 0.46763058113200323, disc_loss = 0.03255949731101282
Trained batch 224 in epoch 4, gen_loss = 0.4675628048843808, disc_loss = 0.032458115886482924
Trained batch 225 in epoch 4, gen_loss = 0.467497543291708, disc_loss = 0.032452187167101465
Trained batch 226 in epoch 4, gen_loss = 0.46757978056495936, disc_loss = 0.03246734984268307
Trained batch 227 in epoch 4, gen_loss = 0.46768385067320706, disc_loss = 0.03238733315007075
Trained batch 228 in epoch 4, gen_loss = 0.4671861481198057, disc_loss = 0.03243418017963525
Trained batch 229 in epoch 4, gen_loss = 0.46694879246794657, disc_loss = 0.03257595999976215
Trained batch 230 in epoch 4, gen_loss = 0.46746641036235925, disc_loss = 0.033015059698292444
Trained batch 231 in epoch 4, gen_loss = 0.46733825962091313, disc_loss = 0.03300094763057884
Trained batch 232 in epoch 4, gen_loss = 0.46744625532575945, disc_loss = 0.0331009711566593
Trained batch 233 in epoch 4, gen_loss = 0.46739479211660534, disc_loss = 0.033442105823315874
Trained batch 234 in epoch 4, gen_loss = 0.46682789769578487, disc_loss = 0.034236227780422
Trained batch 235 in epoch 4, gen_loss = 0.466473671339326, disc_loss = 0.03440922332564527
Trained batch 236 in epoch 4, gen_loss = 0.46649582564579284, disc_loss = 0.03447993833351613
Trained batch 237 in epoch 4, gen_loss = 0.46666922100952696, disc_loss = 0.03452986868160988
Trained batch 238 in epoch 4, gen_loss = 0.46639263442869466, disc_loss = 0.0345583115529004
Trained batch 239 in epoch 4, gen_loss = 0.46630447581410406, disc_loss = 0.03469474403730904
Trained batch 240 in epoch 4, gen_loss = 0.46645250063219507, disc_loss = 0.03489857622619363
Trained batch 241 in epoch 4, gen_loss = 0.46628721981994375, disc_loss = 0.03491161010528276
Trained batch 242 in epoch 4, gen_loss = 0.4664490836147418, disc_loss = 0.03481056375635995
Trained batch 243 in epoch 4, gen_loss = 0.46643242606374086, disc_loss = 0.034740084530327654
Trained batch 244 in epoch 4, gen_loss = 0.46654962775658587, disc_loss = 0.03469561103503315
Trained batch 245 in epoch 4, gen_loss = 0.4663276944945498, disc_loss = 0.034593531888402335
Trained batch 246 in epoch 4, gen_loss = 0.46600164756601153, disc_loss = 0.03476252649281068
Trained batch 247 in epoch 4, gen_loss = 0.465828197497514, disc_loss = 0.034648226874489936
Trained batch 248 in epoch 4, gen_loss = 0.466137044760118, disc_loss = 0.03473305468817791
Trained batch 249 in epoch 4, gen_loss = 0.46615522873401644, disc_loss = 0.03462081585451961
Trained batch 250 in epoch 4, gen_loss = 0.46601224942986236, disc_loss = 0.03452965919581424
Trained batch 251 in epoch 4, gen_loss = 0.4660329216765979, disc_loss = 0.03448773745728272
Trained batch 252 in epoch 4, gen_loss = 0.466222885451298, disc_loss = 0.034912548248799656
Trained batch 253 in epoch 4, gen_loss = 0.46628511738120104, disc_loss = 0.03485705076137514
Trained batch 254 in epoch 4, gen_loss = 0.46605023028803805, disc_loss = 0.03477814072633491
Trained batch 255 in epoch 4, gen_loss = 0.46590264211408794, disc_loss = 0.03469924823730253
Trained batch 256 in epoch 4, gen_loss = 0.46600443750967774, disc_loss = 0.034694824338771024
Trained batch 257 in epoch 4, gen_loss = 0.4657201972580695, disc_loss = 0.03462131034091923
Trained batch 258 in epoch 4, gen_loss = 0.46566096857247663, disc_loss = 0.03464160078568348
Trained batch 259 in epoch 4, gen_loss = 0.4659179747104645, disc_loss = 0.03454686009253447
Trained batch 260 in epoch 4, gen_loss = 0.46593884341561476, disc_loss = 0.034623982220659766
Trained batch 261 in epoch 4, gen_loss = 0.4661777154862426, disc_loss = 0.03458101413290919
Trained batch 262 in epoch 4, gen_loss = 0.4662373336775675, disc_loss = 0.03461044875217935
Trained batch 263 in epoch 4, gen_loss = 0.46629096838560974, disc_loss = 0.03461458360437642
Trained batch 264 in epoch 4, gen_loss = 0.4662890523109796, disc_loss = 0.03459887141186111
Trained batch 265 in epoch 4, gen_loss = 0.46646802956448463, disc_loss = 0.034512387994760856
Trained batch 266 in epoch 4, gen_loss = 0.4663715075687523, disc_loss = 0.03442171077184686
Trained batch 267 in epoch 4, gen_loss = 0.4664794271116826, disc_loss = 0.03435937837183253
Trained batch 268 in epoch 4, gen_loss = 0.46621700046674025, disc_loss = 0.03435415314115778
Trained batch 269 in epoch 4, gen_loss = 0.4659420688947042, disc_loss = 0.034608224165384414
Trained batch 270 in epoch 4, gen_loss = 0.46564272321018346, disc_loss = 0.03482490595828783
Trained batch 271 in epoch 4, gen_loss = 0.4656692983253914, disc_loss = 0.03472701800466679
Trained batch 272 in epoch 4, gen_loss = 0.46571655511419413, disc_loss = 0.0347311979589554
Trained batch 273 in epoch 4, gen_loss = 0.4655718747934286, disc_loss = 0.03463115594451771
Trained batch 274 in epoch 4, gen_loss = 0.46580891316587275, disc_loss = 0.034634590362283314
Trained batch 275 in epoch 4, gen_loss = 0.46591730566992273, disc_loss = 0.034578322638771024
Trained batch 276 in epoch 4, gen_loss = 0.4661975378163885, disc_loss = 0.03449497669128304
Trained batch 277 in epoch 4, gen_loss = 0.4662408052588538, disc_loss = 0.034402643668753424
Trained batch 278 in epoch 4, gen_loss = 0.46632454643112786, disc_loss = 0.03431508831319309
Trained batch 279 in epoch 4, gen_loss = 0.46655542105436326, disc_loss = 0.034361229886833045
Trained batch 280 in epoch 4, gen_loss = 0.46657145426366675, disc_loss = 0.03427900170105314
Trained batch 281 in epoch 4, gen_loss = 0.4663629289848585, disc_loss = 0.03422820950191177
Trained batch 282 in epoch 4, gen_loss = 0.46630516743070244, disc_loss = 0.03413389161452914
Trained batch 283 in epoch 4, gen_loss = 0.46635864863932974, disc_loss = 0.03411372848392897
Trained batch 284 in epoch 4, gen_loss = 0.4664572797323528, disc_loss = 0.03413248916009539
Trained batch 285 in epoch 4, gen_loss = 0.466294802881621, disc_loss = 0.034496733114462004
Trained batch 286 in epoch 4, gen_loss = 0.46623001997894525, disc_loss = 0.03446145293721443
Trained batch 287 in epoch 4, gen_loss = 0.4663144363504317, disc_loss = 0.034888773849363335
Trained batch 288 in epoch 4, gen_loss = 0.4661853684686047, disc_loss = 0.035002950337235286
Trained batch 289 in epoch 4, gen_loss = 0.46633309105346943, disc_loss = 0.03507462268823693
Trained batch 290 in epoch 4, gen_loss = 0.4662113212228231, disc_loss = 0.03513060952136709
Trained batch 291 in epoch 4, gen_loss = 0.4660532812345518, disc_loss = 0.03516615301128222
Trained batch 292 in epoch 4, gen_loss = 0.46582356095314026, disc_loss = 0.03522155696125669
Trained batch 293 in epoch 4, gen_loss = 0.46580485827257845, disc_loss = 0.03513313994622555
Trained batch 294 in epoch 4, gen_loss = 0.4656271209151058, disc_loss = 0.035303858402421916
Trained batch 295 in epoch 4, gen_loss = 0.465788446568154, disc_loss = 0.03598771674709546
Trained batch 296 in epoch 4, gen_loss = 0.4653559017060983, disc_loss = 0.03622197432550116
Trained batch 297 in epoch 4, gen_loss = 0.4653972344310492, disc_loss = 0.03617388980725668
Trained batch 298 in epoch 4, gen_loss = 0.465248165321988, disc_loss = 0.036181049109950514
Trained batch 299 in epoch 4, gen_loss = 0.4653170612454414, disc_loss = 0.03616635764017701
Trained batch 300 in epoch 4, gen_loss = 0.4652125317590973, disc_loss = 0.036273524901548095
Trained batch 301 in epoch 4, gen_loss = 0.4653918919776449, disc_loss = 0.03642430900910635
Trained batch 302 in epoch 4, gen_loss = 0.46537267345406436, disc_loss = 0.036501166137187395
Trained batch 303 in epoch 4, gen_loss = 0.46552085807841076, disc_loss = 0.03650415140375691
Trained batch 304 in epoch 4, gen_loss = 0.4655333022602269, disc_loss = 0.036471081274698995
Trained batch 305 in epoch 4, gen_loss = 0.4655959874001983, disc_loss = 0.03639323289317438
Trained batch 306 in epoch 4, gen_loss = 0.46549493889855253, disc_loss = 0.0367300481344376
Trained batch 307 in epoch 4, gen_loss = 0.4655124468656329, disc_loss = 0.03716638578440656
Trained batch 308 in epoch 4, gen_loss = 0.46545387201710425, disc_loss = 0.037093619433228635
Trained batch 309 in epoch 4, gen_loss = 0.4654963658701989, disc_loss = 0.037018822755424244
Trained batch 310 in epoch 4, gen_loss = 0.46561099133690836, disc_loss = 0.037013594692998183
Trained batch 311 in epoch 4, gen_loss = 0.46555754962639934, disc_loss = 0.037147416228738926
Trained batch 312 in epoch 4, gen_loss = 0.4657205044271085, disc_loss = 0.03710267352112852
Trained batch 313 in epoch 4, gen_loss = 0.46595323522379445, disc_loss = 0.03741923847478951
Trained batch 314 in epoch 4, gen_loss = 0.46580202551115124, disc_loss = 0.03750420981160705
Trained batch 315 in epoch 4, gen_loss = 0.4657857555754577, disc_loss = 0.03744845625449302
Trained batch 316 in epoch 4, gen_loss = 0.46568970048465186, disc_loss = 0.03745368048137389
Trained batch 317 in epoch 4, gen_loss = 0.46565823510008036, disc_loss = 0.037536507557327826
Trained batch 318 in epoch 4, gen_loss = 0.4655051363112411, disc_loss = 0.03806827570308806
Trained batch 319 in epoch 4, gen_loss = 0.4653075338341296, disc_loss = 0.038043571103480646
Trained batch 320 in epoch 4, gen_loss = 0.46551089838286425, disc_loss = 0.038282867512343645
Trained batch 321 in epoch 4, gen_loss = 0.4657417175747593, disc_loss = 0.038351469797585504
Trained batch 322 in epoch 4, gen_loss = 0.46570452881671326, disc_loss = 0.03841313412095832
Trained batch 323 in epoch 4, gen_loss = 0.4656226932082647, disc_loss = 0.03844425020406
Trained batch 324 in epoch 4, gen_loss = 0.46555755184246944, disc_loss = 0.038451499001911055
Trained batch 325 in epoch 4, gen_loss = 0.46574467905094286, disc_loss = 0.03848667891033314
Trained batch 326 in epoch 4, gen_loss = 0.465809612737154, disc_loss = 0.03844290002553926
Trained batch 327 in epoch 4, gen_loss = 0.46583403855925654, disc_loss = 0.03840020713226006
Trained batch 328 in epoch 4, gen_loss = 0.46577268349725787, disc_loss = 0.03830376876189761
Trained batch 329 in epoch 4, gen_loss = 0.46598808837659433, disc_loss = 0.038269039623044204
Trained batch 330 in epoch 4, gen_loss = 0.4662050332907824, disc_loss = 0.03924888660118344
Trained batch 331 in epoch 4, gen_loss = 0.46635632665760546, disc_loss = 0.039219674089059506
Trained batch 332 in epoch 4, gen_loss = 0.46618229249218207, disc_loss = 0.03940319398127205
Trained batch 333 in epoch 4, gen_loss = 0.46632586080514027, disc_loss = 0.039330589458134446
Trained batch 334 in epoch 4, gen_loss = 0.4663903621595297, disc_loss = 0.03926031332768833
Trained batch 335 in epoch 4, gen_loss = 0.46671569036940735, disc_loss = 0.03942697538600658
Trained batch 336 in epoch 4, gen_loss = 0.46666286642544347, disc_loss = 0.03947239922005849
Trained batch 337 in epoch 4, gen_loss = 0.46655512182317543, disc_loss = 0.03944726390956995
Trained batch 338 in epoch 4, gen_loss = 0.4666832774262161, disc_loss = 0.03957228304455634
Trained batch 339 in epoch 4, gen_loss = 0.4666003735626445, disc_loss = 0.03952801540521357
Trained batch 340 in epoch 4, gen_loss = 0.46632895240685807, disc_loss = 0.039433425326512096
Trained batch 341 in epoch 4, gen_loss = 0.46609299372859864, disc_loss = 0.03935077996810146
Trained batch 342 in epoch 4, gen_loss = 0.46593321855492215, disc_loss = 0.039278833620500025
Trained batch 343 in epoch 4, gen_loss = 0.4657974341061226, disc_loss = 0.03918271390639982
Trained batch 344 in epoch 4, gen_loss = 0.4656433013902194, disc_loss = 0.03912309197762954
Trained batch 345 in epoch 4, gen_loss = 0.4658124665648951, disc_loss = 0.03904554393879983
Trained batch 346 in epoch 4, gen_loss = 0.46579023319637397, disc_loss = 0.03915617844326051
Trained batch 347 in epoch 4, gen_loss = 0.46597969746110085, disc_loss = 0.0395094693608946
Trained batch 348 in epoch 4, gen_loss = 0.4659166317273006, disc_loss = 0.039639867283137016
Trained batch 349 in epoch 4, gen_loss = 0.465731520141874, disc_loss = 0.03960047514976135
Trained batch 350 in epoch 4, gen_loss = 0.46579578094332985, disc_loss = 0.039617465332712966
Trained batch 351 in epoch 4, gen_loss = 0.4659849859943444, disc_loss = 0.03978951155361508
Trained batch 352 in epoch 4, gen_loss = 0.46575290884917586, disc_loss = 0.039736423078164586
Trained batch 353 in epoch 4, gen_loss = 0.46577868724273425, disc_loss = 0.03975203807602536
Trained batch 354 in epoch 4, gen_loss = 0.4658014931309391, disc_loss = 0.03980295315620975
Trained batch 355 in epoch 4, gen_loss = 0.46548902461033187, disc_loss = 0.04033837067303405
Trained batch 356 in epoch 4, gen_loss = 0.46567846337954205, disc_loss = 0.04081125162588824
Trained batch 357 in epoch 4, gen_loss = 0.4656366115675292, disc_loss = 0.04077787243750716
Trained batch 358 in epoch 4, gen_loss = 0.4658864782215161, disc_loss = 0.040875131416090435
Trained batch 359 in epoch 4, gen_loss = 0.4657499154408773, disc_loss = 0.040972663235798894
Trained batch 360 in epoch 4, gen_loss = 0.46579702425531405, disc_loss = 0.04094331476894153
Trained batch 361 in epoch 4, gen_loss = 0.46574890045500594, disc_loss = 0.04086257155742805
Trained batch 362 in epoch 4, gen_loss = 0.46565337368279447, disc_loss = 0.04082951700499605
Trained batch 363 in epoch 4, gen_loss = 0.46572567457026176, disc_loss = 0.04078739392954938
Trained batch 364 in epoch 4, gen_loss = 0.4656412107487247, disc_loss = 0.040754627279477984
Trained batch 365 in epoch 4, gen_loss = 0.4659162607512187, disc_loss = 0.04071765773308774
Trained batch 366 in epoch 4, gen_loss = 0.4660349182114614, disc_loss = 0.040654271146998176
Trained batch 367 in epoch 4, gen_loss = 0.46594206924023834, disc_loss = 0.040565587032292766
Trained batch 368 in epoch 4, gen_loss = 0.46588649263549947, disc_loss = 0.040483326344500956
Trained batch 369 in epoch 4, gen_loss = 0.46588277881209916, disc_loss = 0.040461902882954155
Trained batch 370 in epoch 4, gen_loss = 0.46577070922543096, disc_loss = 0.04038074177456392
Trained batch 371 in epoch 4, gen_loss = 0.46577035499516356, disc_loss = 0.04032858958973559
Trained batch 372 in epoch 4, gen_loss = 0.46578200253340896, disc_loss = 0.04027978624104854
Trained batch 373 in epoch 4, gen_loss = 0.4656643901757378, disc_loss = 0.0402475693300466
Trained batch 374 in epoch 4, gen_loss = 0.4656500658194224, disc_loss = 0.04026922979081671
Trained batch 375 in epoch 4, gen_loss = 0.4658398468919257, disc_loss = 0.040274024625219645
Trained batch 376 in epoch 4, gen_loss = 0.46591989004327383, disc_loss = 0.04021856728422428
Trained batch 377 in epoch 4, gen_loss = 0.4657634230202468, disc_loss = 0.04014935611904889
Trained batch 378 in epoch 4, gen_loss = 0.4656221516685939, disc_loss = 0.04015965660847232
Trained batch 379 in epoch 4, gen_loss = 0.46564933845871376, disc_loss = 0.040081985536227493
Trained batch 380 in epoch 4, gen_loss = 0.4656560194148166, disc_loss = 0.040127273215093406
Trained batch 381 in epoch 4, gen_loss = 0.4657225908409238, disc_loss = 0.04009255479792065
Trained batch 382 in epoch 4, gen_loss = 0.46575788496057297, disc_loss = 0.04004568483208746
Trained batch 383 in epoch 4, gen_loss = 0.4658183012312899, disc_loss = 0.040041055686742766
Trained batch 384 in epoch 4, gen_loss = 0.4657893445584681, disc_loss = 0.040109408270664414
Trained batch 385 in epoch 4, gen_loss = 0.4658827380195183, disc_loss = 0.040041415297083674
Trained batch 386 in epoch 4, gen_loss = 0.4659400749422167, disc_loss = 0.04003377933204367
Trained batch 387 in epoch 4, gen_loss = 0.4659993860524954, disc_loss = 0.03994640449815689
Trained batch 388 in epoch 4, gen_loss = 0.4660188707410523, disc_loss = 0.03989468954125261
Trained batch 389 in epoch 4, gen_loss = 0.4660004943609238, disc_loss = 0.03981674080595183
Trained batch 390 in epoch 4, gen_loss = 0.4662599265575409, disc_loss = 0.039866828896781746
Trained batch 391 in epoch 4, gen_loss = 0.4660803766122886, disc_loss = 0.03978161520576485
Trained batch 392 in epoch 4, gen_loss = 0.4659766740623018, disc_loss = 0.03972710672002902
Trained batch 393 in epoch 4, gen_loss = 0.46585301336298135, disc_loss = 0.03965611950031051
Trained batch 394 in epoch 4, gen_loss = 0.46584177017211914, disc_loss = 0.03973839899194957
Trained batch 395 in epoch 4, gen_loss = 0.46559217835616584, disc_loss = 0.03971312110749722
Trained batch 396 in epoch 4, gen_loss = 0.4656697275206184, disc_loss = 0.03983997595226697
Trained batch 397 in epoch 4, gen_loss = 0.46560339172880855, disc_loss = 0.03991277579887391
Trained batch 398 in epoch 4, gen_loss = 0.46578247983354076, disc_loss = 0.039950877879711244
Trained batch 399 in epoch 4, gen_loss = 0.465717748478055, disc_loss = 0.03988379549584351
Trained batch 400 in epoch 4, gen_loss = 0.4656256200220817, disc_loss = 0.03984748752221019
Trained batch 401 in epoch 4, gen_loss = 0.46577363220316853, disc_loss = 0.039781046207688416
Trained batch 402 in epoch 4, gen_loss = 0.46562993378556394, disc_loss = 0.03981845169709464
Trained batch 403 in epoch 4, gen_loss = 0.46571681523087, disc_loss = 0.039908895012000484
Trained batch 404 in epoch 4, gen_loss = 0.4656062329992836, disc_loss = 0.03986892333300209
Trained batch 405 in epoch 4, gen_loss = 0.46568430857411747, disc_loss = 0.039926846801840096
Trained batch 406 in epoch 4, gen_loss = 0.46561390117579654, disc_loss = 0.0399559190100933
Trained batch 407 in epoch 4, gen_loss = 0.46563389429859087, disc_loss = 0.03999020341057878
Trained batch 408 in epoch 4, gen_loss = 0.4657955137616556, disc_loss = 0.040149112668088786
Trained batch 409 in epoch 4, gen_loss = 0.46581861413106684, disc_loss = 0.040116521303837256
Trained batch 410 in epoch 4, gen_loss = 0.4659300268856568, disc_loss = 0.040107907846325286
Trained batch 411 in epoch 4, gen_loss = 0.46587791814676766, disc_loss = 0.040039034079968276
Trained batch 412 in epoch 4, gen_loss = 0.46588827124808085, disc_loss = 0.03998932850233687
Trained batch 413 in epoch 4, gen_loss = 0.465861358144433, disc_loss = 0.039928658859768276
Trained batch 414 in epoch 4, gen_loss = 0.4656222339854183, disc_loss = 0.039854259359235145
Trained batch 415 in epoch 4, gen_loss = 0.4657730539687551, disc_loss = 0.03978821585210076
Trained batch 416 in epoch 4, gen_loss = 0.4658343786958882, disc_loss = 0.039728371943492324
Trained batch 417 in epoch 4, gen_loss = 0.4657813774769386, disc_loss = 0.039661476151286915
Trained batch 418 in epoch 4, gen_loss = 0.46580344474116486, disc_loss = 0.03961177665833606
Trained batch 419 in epoch 4, gen_loss = 0.46587314825682413, disc_loss = 0.03953827118744985
Trained batch 420 in epoch 4, gen_loss = 0.46577144483206107, disc_loss = 0.03955587166341601
Trained batch 421 in epoch 4, gen_loss = 0.4658080288584198, disc_loss = 0.03964938469103127
Trained batch 422 in epoch 4, gen_loss = 0.4657726802160836, disc_loss = 0.03964909435036299
Trained batch 423 in epoch 4, gen_loss = 0.46601943756049535, disc_loss = 0.0395923870657395
Trained batch 424 in epoch 4, gen_loss = 0.4660611635095933, disc_loss = 0.03952673525604255
Trained batch 425 in epoch 4, gen_loss = 0.46622331671311823, disc_loss = 0.039531147187278376
Trained batch 426 in epoch 4, gen_loss = 0.46618142919462235, disc_loss = 0.039489641760539186
Trained batch 427 in epoch 4, gen_loss = 0.4662129008602873, disc_loss = 0.03948480004953899
Trained batch 428 in epoch 4, gen_loss = 0.46627932349285045, disc_loss = 0.03943837393348763
Trained batch 429 in epoch 4, gen_loss = 0.46633259910483693, disc_loss = 0.0393952953964905
Trained batch 430 in epoch 4, gen_loss = 0.46657565485020525, disc_loss = 0.03938915762129799
Trained batch 431 in epoch 4, gen_loss = 0.46658639506333405, disc_loss = 0.03933291360671218
Trained batch 432 in epoch 4, gen_loss = 0.46652872320135524, disc_loss = 0.03929747266084059
Trained batch 433 in epoch 4, gen_loss = 0.466416569624079, disc_loss = 0.03924796322236172
Trained batch 434 in epoch 4, gen_loss = 0.4664666878766027, disc_loss = 0.03917416532299128
Trained batch 435 in epoch 4, gen_loss = 0.4663397391591597, disc_loss = 0.03910136553608394
Trained batch 436 in epoch 4, gen_loss = 0.4661923520761442, disc_loss = 0.03908454431689747
Trained batch 437 in epoch 4, gen_loss = 0.46616145111110113, disc_loss = 0.039029648426503416
Trained batch 438 in epoch 4, gen_loss = 0.46611330537698265, disc_loss = 0.038971850528659674
Trained batch 439 in epoch 4, gen_loss = 0.4661799084733833, disc_loss = 0.038906096839557654
Trained batch 440 in epoch 4, gen_loss = 0.4662797108393948, disc_loss = 0.03883886662398438
Trained batch 441 in epoch 4, gen_loss = 0.46631450991555035, disc_loss = 0.03876729390048738
Trained batch 442 in epoch 4, gen_loss = 0.46625978030415743, disc_loss = 0.03869635239663969
Trained batch 443 in epoch 4, gen_loss = 0.4661326850722502, disc_loss = 0.038632710787325025
Trained batch 444 in epoch 4, gen_loss = 0.466064047880387, disc_loss = 0.03862671037989386
Trained batch 445 in epoch 4, gen_loss = 0.46601238840096737, disc_loss = 0.038695736078236405
Trained batch 446 in epoch 4, gen_loss = 0.4658659170537987, disc_loss = 0.03876567863227937
Trained batch 447 in epoch 4, gen_loss = 0.4656803681116019, disc_loss = 0.0388023835714973
Trained batch 448 in epoch 4, gen_loss = 0.4657939641937647, disc_loss = 0.03891250949543808
Trained batch 449 in epoch 4, gen_loss = 0.4658353584342533, disc_loss = 0.03887629614108139
Trained batch 450 in epoch 4, gen_loss = 0.46592292685202114, disc_loss = 0.03886906772092018
Trained batch 451 in epoch 4, gen_loss = 0.4658651098740839, disc_loss = 0.03882400656069538
Trained batch 452 in epoch 4, gen_loss = 0.46606068842721565, disc_loss = 0.038752312154178126
Trained batch 453 in epoch 4, gen_loss = 0.4660717812141133, disc_loss = 0.03868977649092248
Trained batch 454 in epoch 4, gen_loss = 0.465987995496163, disc_loss = 0.03875740102420633
Trained batch 455 in epoch 4, gen_loss = 0.4661506650348504, disc_loss = 0.038775372579326166
Trained batch 456 in epoch 4, gen_loss = 0.46586794450194363, disc_loss = 0.038973365247013204
Trained batch 457 in epoch 4, gen_loss = 0.46574240350306817, disc_loss = 0.039013121455021234
Trained batch 458 in epoch 4, gen_loss = 0.46562461402421423, disc_loss = 0.03895666200793419
Trained batch 459 in epoch 4, gen_loss = 0.4656167152135269, disc_loss = 0.0389006588537165
Trained batch 460 in epoch 4, gen_loss = 0.46545376358735585, disc_loss = 0.03886124309972575
Trained batch 461 in epoch 4, gen_loss = 0.4655494381597032, disc_loss = 0.038841122625298895
Trained batch 462 in epoch 4, gen_loss = 0.4656024021669804, disc_loss = 0.03893181079894015
Trained batch 463 in epoch 4, gen_loss = 0.4656837035355897, disc_loss = 0.03892461244309931
Trained batch 464 in epoch 4, gen_loss = 0.46557292028139996, disc_loss = 0.03901094824816751
Trained batch 465 in epoch 4, gen_loss = 0.4655878985132782, disc_loss = 0.0390230179034861
Trained batch 466 in epoch 4, gen_loss = 0.46578909919399775, disc_loss = 0.03905935966902327
Trained batch 467 in epoch 4, gen_loss = 0.46581948937004447, disc_loss = 0.038997484005900085
Trained batch 468 in epoch 4, gen_loss = 0.46570410936880213, disc_loss = 0.03906262308649067
Trained batch 469 in epoch 4, gen_loss = 0.4656807392201525, disc_loss = 0.038999631888966296
Trained batch 470 in epoch 4, gen_loss = 0.4657648124765692, disc_loss = 0.039021790414186484
Trained batch 471 in epoch 4, gen_loss = 0.4657840974376363, disc_loss = 0.038969891653909204
Trained batch 472 in epoch 4, gen_loss = 0.46575579311832566, disc_loss = 0.038933759420346194
Trained batch 473 in epoch 4, gen_loss = 0.4657769098815033, disc_loss = 0.038870601245803355
Trained batch 474 in epoch 4, gen_loss = 0.4656624150276184, disc_loss = 0.038822325408262644
Trained batch 475 in epoch 4, gen_loss = 0.465658967484947, disc_loss = 0.03877268541709935
Trained batch 476 in epoch 4, gen_loss = 0.4656083313299175, disc_loss = 0.03871514068221365
Trained batch 477 in epoch 4, gen_loss = 0.4656120690217078, disc_loss = 0.03864892377229758
Trained batch 478 in epoch 4, gen_loss = 0.465635324569734, disc_loss = 0.03866531811790669
Trained batch 479 in epoch 4, gen_loss = 0.46566907173643507, disc_loss = 0.03864320610397651
Trained batch 480 in epoch 4, gen_loss = 0.4657812834157765, disc_loss = 0.038591846148919105
Trained batch 481 in epoch 4, gen_loss = 0.46584925321375187, disc_loss = 0.038553886848822605
Trained batch 482 in epoch 4, gen_loss = 0.46593423715289334, disc_loss = 0.038498878562880784
Trained batch 483 in epoch 4, gen_loss = 0.4659877739046231, disc_loss = 0.038483936177020166
Trained batch 484 in epoch 4, gen_loss = 0.46607584848846356, disc_loss = 0.03842494036791097
Trained batch 485 in epoch 4, gen_loss = 0.4660880679701581, disc_loss = 0.0383908964469339
Trained batch 486 in epoch 4, gen_loss = 0.46607174661614814, disc_loss = 0.03832767949510343
Trained batch 487 in epoch 4, gen_loss = 0.4660535244057413, disc_loss = 0.03826769403388083
Trained batch 488 in epoch 4, gen_loss = 0.46606216803650186, disc_loss = 0.03821701501021905
Trained batch 489 in epoch 4, gen_loss = 0.4659796813312842, disc_loss = 0.038165855609184625
Trained batch 490 in epoch 4, gen_loss = 0.4659562665673235, disc_loss = 0.03809945301158456
Trained batch 491 in epoch 4, gen_loss = 0.4659489534977006, disc_loss = 0.03808934451932678
Trained batch 492 in epoch 4, gen_loss = 0.4659240113431493, disc_loss = 0.03829095902442781
Trained batch 493 in epoch 4, gen_loss = 0.46594721495139935, disc_loss = 0.03844983454865332
Trained batch 494 in epoch 4, gen_loss = 0.46615404462573506, disc_loss = 0.03842530427688751
Trained batch 495 in epoch 4, gen_loss = 0.46617874034470125, disc_loss = 0.03836533876282403
Trained batch 496 in epoch 4, gen_loss = 0.4660688298688808, disc_loss = 0.038411942525191506
Trained batch 497 in epoch 4, gen_loss = 0.4659594523021016, disc_loss = 0.03835637587960435
Trained batch 498 in epoch 4, gen_loss = 0.46594118952512265, disc_loss = 0.038336987007140576
Trained batch 499 in epoch 4, gen_loss = 0.4661096746921539, disc_loss = 0.0383228006279096
Trained batch 500 in epoch 4, gen_loss = 0.4663577666301689, disc_loss = 0.03834696204685969
Trained batch 501 in epoch 4, gen_loss = 0.46638339176120985, disc_loss = 0.03829722696696353
Trained batch 502 in epoch 4, gen_loss = 0.46633921288116786, disc_loss = 0.03827638908476378
Trained batch 503 in epoch 4, gen_loss = 0.4663420854106782, disc_loss = 0.038225119662774164
Trained batch 504 in epoch 4, gen_loss = 0.46632142503662866, disc_loss = 0.038394209029761574
Trained batch 505 in epoch 4, gen_loss = 0.4662906766055601, disc_loss = 0.03867655034957402
Trained batch 506 in epoch 4, gen_loss = 0.4662607763645917, disc_loss = 0.038736354944496405
Trained batch 507 in epoch 4, gen_loss = 0.46627876790255074, disc_loss = 0.038743982952286114
Trained batch 508 in epoch 4, gen_loss = 0.46619113073601937, disc_loss = 0.03871255470000661
Trained batch 509 in epoch 4, gen_loss = 0.4659426832315969, disc_loss = 0.038674073008016924
Trained batch 510 in epoch 4, gen_loss = 0.4659058839490969, disc_loss = 0.0386706026527965
Trained batch 511 in epoch 4, gen_loss = 0.4658511735033244, disc_loss = 0.03870990418272413
Trained batch 512 in epoch 4, gen_loss = 0.46576377197548197, disc_loss = 0.0386520769278252
Trained batch 513 in epoch 4, gen_loss = 0.465785083545785, disc_loss = 0.03868208962115767
Trained batch 514 in epoch 4, gen_loss = 0.4656378015152459, disc_loss = 0.03870367094856298
Trained batch 515 in epoch 4, gen_loss = 0.4657854011007982, disc_loss = 0.03890345635004486
Trained batch 516 in epoch 4, gen_loss = 0.46575159491607254, disc_loss = 0.038897998244600725
Trained batch 517 in epoch 4, gen_loss = 0.4658073518842344, disc_loss = 0.03887985163713485
Trained batch 518 in epoch 4, gen_loss = 0.4658097753979567, disc_loss = 0.03899867175441228
Trained batch 519 in epoch 4, gen_loss = 0.4659567168698861, disc_loss = 0.039037570961786866
Trained batch 520 in epoch 4, gen_loss = 0.46588409478971, disc_loss = 0.03906363618047103
Trained batch 521 in epoch 4, gen_loss = 0.46599084589901557, disc_loss = 0.03906433022638133
Trained batch 522 in epoch 4, gen_loss = 0.4660439711227928, disc_loss = 0.03915761289655108
Trained batch 523 in epoch 4, gen_loss = 0.4659979267771007, disc_loss = 0.03911529578364504
Trained batch 524 in epoch 4, gen_loss = 0.4658822512058985, disc_loss = 0.03928227535582014
Trained batch 525 in epoch 4, gen_loss = 0.46600987323110094, disc_loss = 0.03930052938099115
Trained batch 526 in epoch 4, gen_loss = 0.46587316638152104, disc_loss = 0.03927594721158242
Trained batch 527 in epoch 4, gen_loss = 0.46589287720394856, disc_loss = 0.039334989599989385
Trained batch 528 in epoch 4, gen_loss = 0.4659836532262863, disc_loss = 0.03936263010000884
Trained batch 529 in epoch 4, gen_loss = 0.46617506078954013, disc_loss = 0.039338743696340696
Trained batch 530 in epoch 4, gen_loss = 0.4661827489256634, disc_loss = 0.03928214562320187
Trained batch 531 in epoch 4, gen_loss = 0.46613348191393944, disc_loss = 0.03935098380140988
Trained batch 532 in epoch 4, gen_loss = 0.46597833084344414, disc_loss = 0.03947814877842174
Trained batch 533 in epoch 4, gen_loss = 0.4658915219681986, disc_loss = 0.039418649003398
Trained batch 534 in epoch 4, gen_loss = 0.46585738419372347, disc_loss = 0.03944420174425729
Trained batch 535 in epoch 4, gen_loss = 0.46585526306237746, disc_loss = 0.03957894250382183
Trained batch 536 in epoch 4, gen_loss = 0.4658971310660826, disc_loss = 0.03952467597819851
Trained batch 537 in epoch 4, gen_loss = 0.4658398305837993, disc_loss = 0.03952971632076517
Trained batch 538 in epoch 4, gen_loss = 0.4657466751082709, disc_loss = 0.03955888155336338
Trained batch 539 in epoch 4, gen_loss = 0.46593615931493265, disc_loss = 0.039570002728659244
Trained batch 540 in epoch 4, gen_loss = 0.4659556819198312, disc_loss = 0.039524290929316044
Trained batch 541 in epoch 4, gen_loss = 0.46587636418008277, disc_loss = 0.03949203693249514
Trained batch 542 in epoch 4, gen_loss = 0.4659263161225433, disc_loss = 0.039442675105856924
Trained batch 543 in epoch 4, gen_loss = 0.46600900919121857, disc_loss = 0.03944366536555154
Trained batch 544 in epoch 4, gen_loss = 0.4660210296648358, disc_loss = 0.03949957789699419
Trained batch 545 in epoch 4, gen_loss = 0.4658961106132675, disc_loss = 0.03945495396333955
Trained batch 546 in epoch 4, gen_loss = 0.4658443257621263, disc_loss = 0.03939975258746138
Trained batch 547 in epoch 4, gen_loss = 0.46577917044832756, disc_loss = 0.03943184617716466
Trained batch 548 in epoch 4, gen_loss = 0.4657626979880863, disc_loss = 0.039416658327336304
Trained batch 549 in epoch 4, gen_loss = 0.46575385435061023, disc_loss = 0.039387685683640566
Trained batch 550 in epoch 4, gen_loss = 0.46578099036389814, disc_loss = 0.03965665816503514
Trained batch 551 in epoch 4, gen_loss = 0.4656569680765919, disc_loss = 0.03968219865329456
Trained batch 552 in epoch 4, gen_loss = 0.46562997282736984, disc_loss = 0.03970865306409099
Trained batch 553 in epoch 4, gen_loss = 0.4656549902491621, disc_loss = 0.03965280091706058
Trained batch 554 in epoch 4, gen_loss = 0.4656419225641199, disc_loss = 0.03961592192115548
Trained batch 555 in epoch 4, gen_loss = 0.4657943052568024, disc_loss = 0.039591772444948235
Trained batch 556 in epoch 4, gen_loss = 0.4657376789533043, disc_loss = 0.039530557506722755
Trained batch 557 in epoch 4, gen_loss = 0.46550296749051756, disc_loss = 0.03952184501921885
Trained batch 558 in epoch 4, gen_loss = 0.4654368004879926, disc_loss = 0.03972100194090434
Trained batch 559 in epoch 4, gen_loss = 0.46516649409064226, disc_loss = 0.039716326952579296
Trained batch 560 in epoch 4, gen_loss = 0.4650919015076071, disc_loss = 0.039714944037590544
Trained batch 561 in epoch 4, gen_loss = 0.4651038291403407, disc_loss = 0.03970853332264408
Trained batch 562 in epoch 4, gen_loss = 0.46498764450554314, disc_loss = 0.03979478972479304
Trained batch 563 in epoch 4, gen_loss = 0.46493728279221985, disc_loss = 0.03977140589907818
Trained batch 564 in epoch 4, gen_loss = 0.46484855434535877, disc_loss = 0.03984244112255035
Trained batch 565 in epoch 4, gen_loss = 0.4649714535832826, disc_loss = 0.039944222267690795
Trained batch 566 in epoch 4, gen_loss = 0.4649639826603037, disc_loss = 0.03989015072682705
Trained batch 567 in epoch 4, gen_loss = 0.46481770791218313, disc_loss = 0.03984946681639101
Trained batch 568 in epoch 4, gen_loss = 0.46477270257284437, disc_loss = 0.03992587633214904
Trained batch 569 in epoch 4, gen_loss = 0.4647285299865823, disc_loss = 0.0399863646757838
Trained batch 570 in epoch 4, gen_loss = 0.46491088461124336, disc_loss = 0.04005884620705179
Trained batch 571 in epoch 4, gen_loss = 0.4648604340382389, disc_loss = 0.040057697667173674
Trained batch 572 in epoch 4, gen_loss = 0.4647763615919449, disc_loss = 0.04006496005663957
Trained batch 573 in epoch 4, gen_loss = 0.464724536868338, disc_loss = 0.040105471252836936
Trained batch 574 in epoch 4, gen_loss = 0.464912486490996, disc_loss = 0.04005476963422869
Trained batch 575 in epoch 4, gen_loss = 0.4650238637501995, disc_loss = 0.040020832314945035
Trained batch 576 in epoch 4, gen_loss = 0.4650228119598931, disc_loss = 0.040011172867226746
Trained batch 577 in epoch 4, gen_loss = 0.4650168265232165, disc_loss = 0.04006356035220633
Trained batch 578 in epoch 4, gen_loss = 0.46500450388137543, disc_loss = 0.04008488924707413
Trained batch 579 in epoch 4, gen_loss = 0.46496128213816673, disc_loss = 0.040035311272367834
Trained batch 580 in epoch 4, gen_loss = 0.464895905910794, disc_loss = 0.04002703376043838
Trained batch 581 in epoch 4, gen_loss = 0.4648869256793019, disc_loss = 0.03998672949867099
Trained batch 582 in epoch 4, gen_loss = 0.46492387765881127, disc_loss = 0.03994517308367515
Trained batch 583 in epoch 4, gen_loss = 0.4649476021119993, disc_loss = 0.03990566911820118
Trained batch 584 in epoch 4, gen_loss = 0.4649337110356388, disc_loss = 0.03986500575979296
Trained batch 585 in epoch 4, gen_loss = 0.46485703685177876, disc_loss = 0.03988039370073139
Trained batch 586 in epoch 4, gen_loss = 0.46484383940696716, disc_loss = 0.03984945263472438
Trained batch 587 in epoch 4, gen_loss = 0.46491930410772764, disc_loss = 0.03986732302341281
Trained batch 588 in epoch 4, gen_loss = 0.4649358155468324, disc_loss = 0.03984301191152205
Trained batch 589 in epoch 4, gen_loss = 0.46499195907075525, disc_loss = 0.039789983527577025
Trained batch 590 in epoch 4, gen_loss = 0.46492766335530933, disc_loss = 0.03974572626334913
Trained batch 591 in epoch 4, gen_loss = 0.46482821503603783, disc_loss = 0.039697853601348865
Trained batch 592 in epoch 4, gen_loss = 0.4647736008110979, disc_loss = 0.03970386168148375
Trained batch 593 in epoch 4, gen_loss = 0.4648632705713362, disc_loss = 0.03965294866756809
Trained batch 594 in epoch 4, gen_loss = 0.4648467301320629, disc_loss = 0.03959865509023686
Trained batch 595 in epoch 4, gen_loss = 0.46479240104856107, disc_loss = 0.03954325088193553
Trained batch 596 in epoch 4, gen_loss = 0.4649493765691217, disc_loss = 0.03954708438922013
Trained batch 597 in epoch 4, gen_loss = 0.46490532413972263, disc_loss = 0.03949965534881256
Trained batch 598 in epoch 4, gen_loss = 0.4648617893606673, disc_loss = 0.03944811142066833
Trained batch 599 in epoch 4, gen_loss = 0.46479313229521113, disc_loss = 0.03939473749914517
Trained batch 600 in epoch 4, gen_loss = 0.4646986932207066, disc_loss = 0.03939696644803202
Trained batch 601 in epoch 4, gen_loss = 0.46456641825132594, disc_loss = 0.03935858096302397
Trained batch 602 in epoch 4, gen_loss = 0.4646994746838438, disc_loss = 0.03932882783159144
Trained batch 603 in epoch 4, gen_loss = 0.46478381373037564, disc_loss = 0.03932599208490393
Trained batch 604 in epoch 4, gen_loss = 0.4648082536606749, disc_loss = 0.03927334767327575
Trained batch 605 in epoch 4, gen_loss = 0.46484500769734777, disc_loss = 0.03924460300450327
Trained batch 606 in epoch 4, gen_loss = 0.46488098768268815, disc_loss = 0.039219658274074656
Trained batch 607 in epoch 4, gen_loss = 0.46479927527865295, disc_loss = 0.03918224828483194
Trained batch 608 in epoch 4, gen_loss = 0.46478695690338245, disc_loss = 0.03914468491232796
Trained batch 609 in epoch 4, gen_loss = 0.464850540092734, disc_loss = 0.03910122390408985
Trained batch 610 in epoch 4, gen_loss = 0.46497024027493505, disc_loss = 0.03906783647530403
Trained batch 611 in epoch 4, gen_loss = 0.46489136495621375, disc_loss = 0.03902883695748945
Trained batch 612 in epoch 4, gen_loss = 0.4648996473914453, disc_loss = 0.03897674870031596
Trained batch 613 in epoch 4, gen_loss = 0.4649654781197104, disc_loss = 0.038950141758964385
Trained batch 614 in epoch 4, gen_loss = 0.4650067863425588, disc_loss = 0.038971503197056494
Trained batch 615 in epoch 4, gen_loss = 0.46490903963129243, disc_loss = 0.03895032256176429
Trained batch 616 in epoch 4, gen_loss = 0.46495038483479034, disc_loss = 0.03890708808876224
Trained batch 617 in epoch 4, gen_loss = 0.4649777216625831, disc_loss = 0.03886188039538062
Trained batch 618 in epoch 4, gen_loss = 0.46494949071010594, disc_loss = 0.0388050411902338
Trained batch 619 in epoch 4, gen_loss = 0.46492166322085166, disc_loss = 0.03874863202405733
Trained batch 620 in epoch 4, gen_loss = 0.46475214346787397, disc_loss = 0.03870786262875582
Trained batch 621 in epoch 4, gen_loss = 0.4647294891417218, disc_loss = 0.0386794224404655
Trained batch 622 in epoch 4, gen_loss = 0.4646287223213557, disc_loss = 0.038642076652476126
Trained batch 623 in epoch 4, gen_loss = 0.4645958236681345, disc_loss = 0.03859078922295549
Trained batch 624 in epoch 4, gen_loss = 0.46461235704422, disc_loss = 0.03854000167362392
Trained batch 625 in epoch 4, gen_loss = 0.4645760626838611, disc_loss = 0.038799810852221665
Trained batch 626 in epoch 4, gen_loss = 0.4645570884481001, disc_loss = 0.03881321484527508
Trained batch 627 in epoch 4, gen_loss = 0.4645486627794375, disc_loss = 0.03882916803897364
Trained batch 628 in epoch 4, gen_loss = 0.4645983127133835, disc_loss = 0.03878229153594254
Trained batch 629 in epoch 4, gen_loss = 0.4646086740588385, disc_loss = 0.03873930031485442
Trained batch 630 in epoch 4, gen_loss = 0.46455287479938684, disc_loss = 0.038724116478838534
Trained batch 631 in epoch 4, gen_loss = 0.46452730828070943, disc_loss = 0.03871369846364118
Trained batch 632 in epoch 4, gen_loss = 0.4644709897078986, disc_loss = 0.03866567473827698
Trained batch 633 in epoch 4, gen_loss = 0.4644588084438998, disc_loss = 0.03862246552339758
Trained batch 634 in epoch 4, gen_loss = 0.46448699902361773, disc_loss = 0.03857924206453691
Trained batch 635 in epoch 4, gen_loss = 0.4644577090845168, disc_loss = 0.03854206844881681
Trained batch 636 in epoch 4, gen_loss = 0.46439953679379714, disc_loss = 0.038554105571042774
Trained batch 637 in epoch 4, gen_loss = 0.46445235203612933, disc_loss = 0.038514932529594995
Trained batch 638 in epoch 4, gen_loss = 0.46442616307679474, disc_loss = 0.038471465277032275
Trained batch 639 in epoch 4, gen_loss = 0.4643135694786906, disc_loss = 0.03842623408381769
Trained batch 640 in epoch 4, gen_loss = 0.4642481994517322, disc_loss = 0.038388835858661166
Trained batch 641 in epoch 4, gen_loss = 0.46429935664031363, disc_loss = 0.03834156274202213
Trained batch 642 in epoch 4, gen_loss = 0.46438973882520923, disc_loss = 0.03841212899337232
Trained batch 643 in epoch 4, gen_loss = 0.4643742707297669, disc_loss = 0.03839914910806204
Trained batch 644 in epoch 4, gen_loss = 0.4645397559154865, disc_loss = 0.038491066556438344
Trained batch 645 in epoch 4, gen_loss = 0.4644648921748064, disc_loss = 0.03844291157624036
Trained batch 646 in epoch 4, gen_loss = 0.4646697613702859, disc_loss = 0.03840126798105307
Trained batch 647 in epoch 4, gen_loss = 0.4647836822234554, disc_loss = 0.03835643634500476
Trained batch 648 in epoch 4, gen_loss = 0.46491557093357266, disc_loss = 0.038335606556612487
Trained batch 649 in epoch 4, gen_loss = 0.4650323133285229, disc_loss = 0.0382965102007326
Trained batch 650 in epoch 4, gen_loss = 0.46499916064208185, disc_loss = 0.03825644785273654
Trained batch 651 in epoch 4, gen_loss = 0.46499778796558733, disc_loss = 0.03826669924014014
Trained batch 652 in epoch 4, gen_loss = 0.46500992126888374, disc_loss = 0.03839926663992975
Trained batch 653 in epoch 4, gen_loss = 0.46509149178452447, disc_loss = 0.038382767858083394
Trained batch 654 in epoch 4, gen_loss = 0.4649672084637271, disc_loss = 0.038363522824738885
Trained batch 655 in epoch 4, gen_loss = 0.46493983373227643, disc_loss = 0.038322524295725136
Trained batch 656 in epoch 4, gen_loss = 0.4649347278262564, disc_loss = 0.03829829172866314
Trained batch 657 in epoch 4, gen_loss = 0.4649206234147846, disc_loss = 0.0384336404058669
Trained batch 658 in epoch 4, gen_loss = 0.46509744961815286, disc_loss = 0.038452817800162256
Trained batch 659 in epoch 4, gen_loss = 0.4650500428495985, disc_loss = 0.038423067015581625
Trained batch 660 in epoch 4, gen_loss = 0.4650797482337605, disc_loss = 0.038384493668993394
Trained batch 661 in epoch 4, gen_loss = 0.4649968423241935, disc_loss = 0.03838141207700016
Trained batch 662 in epoch 4, gen_loss = 0.4650385475536277, disc_loss = 0.038356121705682054
Trained batch 663 in epoch 4, gen_loss = 0.46509256263274745, disc_loss = 0.03840074471951215
Trained batch 664 in epoch 4, gen_loss = 0.4651136645697113, disc_loss = 0.03842100394938729
Trained batch 665 in epoch 4, gen_loss = 0.4651296242131843, disc_loss = 0.038386317947809515
Trained batch 666 in epoch 4, gen_loss = 0.4652334338632123, disc_loss = 0.038352114497858476
Trained batch 667 in epoch 4, gen_loss = 0.4652258756899548, disc_loss = 0.03831307770451531
Trained batch 668 in epoch 4, gen_loss = 0.4650785342994827, disc_loss = 0.03828311329867596
Trained batch 669 in epoch 4, gen_loss = 0.46510576196570896, disc_loss = 0.038240291274486304
Trained batch 670 in epoch 4, gen_loss = 0.4651228865461449, disc_loss = 0.03820864746212437
Trained batch 671 in epoch 4, gen_loss = 0.4651217887710248, disc_loss = 0.03817222400747206
Trained batch 672 in epoch 4, gen_loss = 0.46505947448700713, disc_loss = 0.03813671069129759
Trained batch 673 in epoch 4, gen_loss = 0.46506377046469055, disc_loss = 0.03810097699472266
Trained batch 674 in epoch 4, gen_loss = 0.4651219919875816, disc_loss = 0.03810190558468026
Trained batch 675 in epoch 4, gen_loss = 0.46508603745840005, disc_loss = 0.03805984051094925
Trained batch 676 in epoch 4, gen_loss = 0.46522587260432224, disc_loss = 0.03803836457201581
Trained batch 677 in epoch 4, gen_loss = 0.4652292960512955, disc_loss = 0.03802877358829872
Trained batch 678 in epoch 4, gen_loss = 0.4652122579986814, disc_loss = 0.037982088836343395
Trained batch 679 in epoch 4, gen_loss = 0.4652263731202658, disc_loss = 0.037963884507703105
Trained batch 680 in epoch 4, gen_loss = 0.4651763840481398, disc_loss = 0.03791925913336989
Trained batch 681 in epoch 4, gen_loss = 0.46516488164750713, disc_loss = 0.037885996021120055
Trained batch 682 in epoch 4, gen_loss = 0.4652294052292976, disc_loss = 0.03788645799738105
Trained batch 683 in epoch 4, gen_loss = 0.46523441056236187, disc_loss = 0.03788344651611783
Trained batch 684 in epoch 4, gen_loss = 0.46517746096109824, disc_loss = 0.03793665272061353
Trained batch 685 in epoch 4, gen_loss = 0.46534314234646, disc_loss = 0.03799988439343272
Trained batch 686 in epoch 4, gen_loss = 0.4653228408991857, disc_loss = 0.037973975209286095
Trained batch 687 in epoch 4, gen_loss = 0.4652892316063476, disc_loss = 0.037926945930447015
Trained batch 688 in epoch 4, gen_loss = 0.46523282390374404, disc_loss = 0.037910822062876146
Trained batch 689 in epoch 4, gen_loss = 0.46522676473942354, disc_loss = 0.0379917882413239
Trained batch 690 in epoch 4, gen_loss = 0.46519675786174325, disc_loss = 0.03798838901365858
Trained batch 691 in epoch 4, gen_loss = 0.4652063429700157, disc_loss = 0.0379900168657782
Trained batch 692 in epoch 4, gen_loss = 0.46519993811114696, disc_loss = 0.03797050939925273
Trained batch 693 in epoch 4, gen_loss = 0.4652793995327496, disc_loss = 0.037928294629644956
Trained batch 694 in epoch 4, gen_loss = 0.465210976188989, disc_loss = 0.037971058426585665
Trained batch 695 in epoch 4, gen_loss = 0.46514591322034254, disc_loss = 0.03797763105697298
Trained batch 696 in epoch 4, gen_loss = 0.46520163129528763, disc_loss = 0.03802668510928184
Trained batch 697 in epoch 4, gen_loss = 0.4651260510471284, disc_loss = 0.03807535112460536
Trained batch 698 in epoch 4, gen_loss = 0.46522390420344767, disc_loss = 0.03809434868087552
Trained batch 699 in epoch 4, gen_loss = 0.46513387573616843, disc_loss = 0.03814621155582634
Trained batch 700 in epoch 4, gen_loss = 0.4653865160598564, disc_loss = 0.03851708473030547
Trained batch 701 in epoch 4, gen_loss = 0.46525898104549473, disc_loss = 0.038663508002036
Trained batch 702 in epoch 4, gen_loss = 0.46526016267400716, disc_loss = 0.03865275369356962
Trained batch 703 in epoch 4, gen_loss = 0.4651613878509538, disc_loss = 0.03863118501381409
Trained batch 704 in epoch 4, gen_loss = 0.46513655392836173, disc_loss = 0.038640359469775294
Trained batch 705 in epoch 4, gen_loss = 0.4652771081448277, disc_loss = 0.0386123281033583
Trained batch 706 in epoch 4, gen_loss = 0.4653079915249027, disc_loss = 0.03860998185597824
Trained batch 707 in epoch 4, gen_loss = 0.46523081620702633, disc_loss = 0.0385759226233951
Trained batch 708 in epoch 4, gen_loss = 0.4652326283569228, disc_loss = 0.0386268844403069
Trained batch 709 in epoch 4, gen_loss = 0.4653949023132593, disc_loss = 0.03859174358494527
Trained batch 710 in epoch 4, gen_loss = 0.4655212938534057, disc_loss = 0.03854869940755666
Trained batch 711 in epoch 4, gen_loss = 0.46549895732255464, disc_loss = 0.038511894022316015
Trained batch 712 in epoch 4, gen_loss = 0.4655788988919947, disc_loss = 0.03847913275705324
Trained batch 713 in epoch 4, gen_loss = 0.4655915044185494, disc_loss = 0.03843314859446097
Trained batch 714 in epoch 4, gen_loss = 0.4655795393707035, disc_loss = 0.03839857426498059
Trained batch 715 in epoch 4, gen_loss = 0.4656108160341918, disc_loss = 0.03843519657000889
Trained batch 716 in epoch 4, gen_loss = 0.46561593565481973, disc_loss = 0.03841630320423224
Trained batch 717 in epoch 4, gen_loss = 0.46555511960578166, disc_loss = 0.038370351727032376
Trained batch 718 in epoch 4, gen_loss = 0.465564800071451, disc_loss = 0.038327545839166255
Trained batch 719 in epoch 4, gen_loss = 0.4655622431801425, disc_loss = 0.03831603908361608
Trained batch 720 in epoch 4, gen_loss = 0.4655182369869724, disc_loss = 0.03828605875113253
Trained batch 721 in epoch 4, gen_loss = 0.4656253201149177, disc_loss = 0.038254487961259805
Trained batch 722 in epoch 4, gen_loss = 0.46569340703893003, disc_loss = 0.03824526479726665
Trained batch 723 in epoch 4, gen_loss = 0.465772512538657, disc_loss = 0.03823609052847258
Trained batch 724 in epoch 4, gen_loss = 0.46586609511539856, disc_loss = 0.03819738460608341
Trained batch 725 in epoch 4, gen_loss = 0.4658202631168129, disc_loss = 0.03816159064503074
Trained batch 726 in epoch 4, gen_loss = 0.4658608276709566, disc_loss = 0.03811912289167276
Trained batch 727 in epoch 4, gen_loss = 0.4658468281338503, disc_loss = 0.03811933897828407
Trained batch 728 in epoch 4, gen_loss = 0.46582565557809524, disc_loss = 0.03814366430559021
Trained batch 729 in epoch 4, gen_loss = 0.4658267718471893, disc_loss = 0.03813907988720305
Trained batch 730 in epoch 4, gen_loss = 0.46584401394861014, disc_loss = 0.038110485912916006
Trained batch 731 in epoch 4, gen_loss = 0.4658503711142175, disc_loss = 0.03807326118669172
Trained batch 732 in epoch 4, gen_loss = 0.46584011087801414, disc_loss = 0.03804200485896314
Trained batch 733 in epoch 4, gen_loss = 0.4657424372044831, disc_loss = 0.0380392207783756
Trained batch 734 in epoch 4, gen_loss = 0.4657197129969694, disc_loss = 0.038005024052484807
Trained batch 735 in epoch 4, gen_loss = 0.4656112449567603, disc_loss = 0.03797374064268534
Trained batch 736 in epoch 4, gen_loss = 0.4656327627649786, disc_loss = 0.03793898212035999
Trained batch 737 in epoch 4, gen_loss = 0.46544534662551673, disc_loss = 0.03795957265814216
Trained batch 738 in epoch 4, gen_loss = 0.4655420693073608, disc_loss = 0.0379390234593302
Trained batch 739 in epoch 4, gen_loss = 0.4654601403990307, disc_loss = 0.037901754587624424
Trained batch 740 in epoch 4, gen_loss = 0.46541766945006235, disc_loss = 0.03786096344551124
Trained batch 741 in epoch 4, gen_loss = 0.4654312801328952, disc_loss = 0.037839877087499876
Trained batch 742 in epoch 4, gen_loss = 0.46536472507954285, disc_loss = 0.037804162202147246
Trained batch 743 in epoch 4, gen_loss = 0.46536217874256514, disc_loss = 0.0377592655347525
Trained batch 744 in epoch 4, gen_loss = 0.46539163205447615, disc_loss = 0.03779981204608593
Trained batch 745 in epoch 4, gen_loss = 0.4653393475203987, disc_loss = 0.03777738161236497
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.40143078565597534, disc_loss = 0.05490108206868172
Trained batch 1 in epoch 5, gen_loss = 0.4552500247955322, disc_loss = 0.032223972491919994
Trained batch 2 in epoch 5, gen_loss = 0.4549979468186696, disc_loss = 0.02565442646543185
Trained batch 3 in epoch 5, gen_loss = 0.45387275516986847, disc_loss = 0.028343810699880123
Trained batch 4 in epoch 5, gen_loss = 0.46613049507141113, disc_loss = 0.025709963589906692
Trained batch 5 in epoch 5, gen_loss = 0.4622172862291336, disc_loss = 0.022534197972466547
Trained batch 6 in epoch 5, gen_loss = 0.4551786780357361, disc_loss = 0.028763804185603346
Trained batch 7 in epoch 5, gen_loss = 0.4570974037051201, disc_loss = 0.033555520814843476
Trained batch 8 in epoch 5, gen_loss = 0.4506564206547207, disc_loss = 0.0364762537388338
Trained batch 9 in epoch 5, gen_loss = 0.45405509173870084, disc_loss = 0.03516594329848886
Trained batch 10 in epoch 5, gen_loss = 0.44791390137238934, disc_loss = 0.033770211464302105
Trained batch 11 in epoch 5, gen_loss = 0.4515514026085536, disc_loss = 0.031559722730889916
Trained batch 12 in epoch 5, gen_loss = 0.44648937537119937, disc_loss = 0.030471434315236714
Trained batch 13 in epoch 5, gen_loss = 0.44987685126917704, disc_loss = 0.03240869666582772
Trained batch 14 in epoch 5, gen_loss = 0.44996349612871805, disc_loss = 0.03527203494062026
Trained batch 15 in epoch 5, gen_loss = 0.4472863469272852, disc_loss = 0.03358308400493115
Trained batch 16 in epoch 5, gen_loss = 0.4506268273381626, disc_loss = 0.03439956147442846
Trained batch 17 in epoch 5, gen_loss = 0.4517157905631595, disc_loss = 0.03385877640297016
Trained batch 18 in epoch 5, gen_loss = 0.4507130509928653, disc_loss = 0.03249266459361503
Trained batch 19 in epoch 5, gen_loss = 0.4506362289190292, disc_loss = 0.031480066617950796
Trained batch 20 in epoch 5, gen_loss = 0.45054238466989427, disc_loss = 0.03149558475152368
Trained batch 21 in epoch 5, gen_loss = 0.45206023346294055, disc_loss = 0.03305300981314345
Trained batch 22 in epoch 5, gen_loss = 0.4560080144716346, disc_loss = 0.034048773793746594
Trained batch 23 in epoch 5, gen_loss = 0.45377694939573604, disc_loss = 0.033337595290504396
Trained batch 24 in epoch 5, gen_loss = 0.456887823343277, disc_loss = 0.033103891424834726
Trained batch 25 in epoch 5, gen_loss = 0.4538556956327878, disc_loss = 0.03488345454948453
Trained batch 26 in epoch 5, gen_loss = 0.45522435947700784, disc_loss = 0.03580270800739527
Trained batch 27 in epoch 5, gen_loss = 0.45935332987989697, disc_loss = 0.0368873688192772
Trained batch 28 in epoch 5, gen_loss = 0.45662918275800246, disc_loss = 0.04240339156240225
Trained batch 29 in epoch 5, gen_loss = 0.45410792926947274, disc_loss = 0.041879174578934905
Trained batch 30 in epoch 5, gen_loss = 0.4584025250327203, disc_loss = 0.043358918609878706
Trained batch 31 in epoch 5, gen_loss = 0.4594751438125968, disc_loss = 0.04258115423726849
Trained batch 32 in epoch 5, gen_loss = 0.4582850653113741, disc_loss = 0.0424417798887148
Trained batch 33 in epoch 5, gen_loss = 0.45852021522381725, disc_loss = 0.04144689059980652
Trained batch 34 in epoch 5, gen_loss = 0.4588401096207755, disc_loss = 0.041857583953865934
Trained batch 35 in epoch 5, gen_loss = 0.45872218410174054, disc_loss = 0.04167576530016959
Trained batch 36 in epoch 5, gen_loss = 0.46151192123825485, disc_loss = 0.044327593156816184
Trained batch 37 in epoch 5, gen_loss = 0.46301733192644623, disc_loss = 0.04347031516954303
Trained batch 38 in epoch 5, gen_loss = 0.4624910690845587, disc_loss = 0.043382836577410884
Trained batch 39 in epoch 5, gen_loss = 0.4623323269188404, disc_loss = 0.04248630185611546
Trained batch 40 in epoch 5, gen_loss = 0.46555718924941086, disc_loss = 0.04404835661918652
Trained batch 41 in epoch 5, gen_loss = 0.4641575501078651, disc_loss = 0.043386373713257764
Trained batch 42 in epoch 5, gen_loss = 0.4636560865612917, disc_loss = 0.0427039286641534
Trained batch 43 in epoch 5, gen_loss = 0.46333722837946634, disc_loss = 0.041923332599584355
Trained batch 44 in epoch 5, gen_loss = 0.46354621317651534, disc_loss = 0.041409532870683406
Trained batch 45 in epoch 5, gen_loss = 0.46463313763556274, disc_loss = 0.04066039008371856
Trained batch 46 in epoch 5, gen_loss = 0.4650573400740928, disc_loss = 0.04003140106400911
Trained batch 47 in epoch 5, gen_loss = 0.4650538098067045, disc_loss = 0.039300543071779735
Trained batch 48 in epoch 5, gen_loss = 0.46487937837230914, disc_loss = 0.038736478130960345
Trained batch 49 in epoch 5, gen_loss = 0.46478776156902313, disc_loss = 0.038336084922775626
Trained batch 50 in epoch 5, gen_loss = 0.46471942873562083, disc_loss = 0.03818954522812776
Trained batch 51 in epoch 5, gen_loss = 0.46503591308226955, disc_loss = 0.037774852074037954
Trained batch 52 in epoch 5, gen_loss = 0.46686970625283586, disc_loss = 0.0375224803398662
Trained batch 53 in epoch 5, gen_loss = 0.46627604961395264, disc_loss = 0.03763592728689589
Trained batch 54 in epoch 5, gen_loss = 0.4667291294444691, disc_loss = 0.03765018686482852
Trained batch 55 in epoch 5, gen_loss = 0.46539279924971716, disc_loss = 0.03718352330283129
Trained batch 56 in epoch 5, gen_loss = 0.4646973285758704, disc_loss = 0.038479765378788375
Trained batch 57 in epoch 5, gen_loss = 0.4641176287470193, disc_loss = 0.03965673209489163
Trained batch 58 in epoch 5, gen_loss = 0.4646883778652902, disc_loss = 0.039633661248105564
Trained batch 59 in epoch 5, gen_loss = 0.4634695157408714, disc_loss = 0.04339077546416471
Trained batch 60 in epoch 5, gen_loss = 0.4620748269753378, disc_loss = 0.043019999146888976
Trained batch 61 in epoch 5, gen_loss = 0.46070762507377133, disc_loss = 0.04344714759668756
Trained batch 62 in epoch 5, gen_loss = 0.46174289593620904, disc_loss = 0.04393221818590685
Trained batch 63 in epoch 5, gen_loss = 0.46113118529319763, disc_loss = 0.04344632181891939
Trained batch 64 in epoch 5, gen_loss = 0.4616882370068477, disc_loss = 0.04402613785261145
Trained batch 65 in epoch 5, gen_loss = 0.46021365758144495, disc_loss = 0.044145204035113704
Trained batch 66 in epoch 5, gen_loss = 0.45940726906505985, disc_loss = 0.045953105099554824
Trained batch 67 in epoch 5, gen_loss = 0.45898979244863286, disc_loss = 0.04620091838296503
Trained batch 68 in epoch 5, gen_loss = 0.4584247888862223, disc_loss = 0.04824929157325971
Trained batch 69 in epoch 5, gen_loss = 0.458182521377291, disc_loss = 0.04882368436748428
Trained batch 70 in epoch 5, gen_loss = 0.45719234120677893, disc_loss = 0.049058461502771565
Trained batch 71 in epoch 5, gen_loss = 0.4567255601286888, disc_loss = 0.04889463273058128
Trained batch 72 in epoch 5, gen_loss = 0.4568796647738104, disc_loss = 0.04910741064518894
Trained batch 73 in epoch 5, gen_loss = 0.4571919102926512, disc_loss = 0.049595935641460726
Trained batch 74 in epoch 5, gen_loss = 0.45686689217885335, disc_loss = 0.049547048279394705
Trained batch 75 in epoch 5, gen_loss = 0.45609135180711746, disc_loss = 0.05129745746595099
Trained batch 76 in epoch 5, gen_loss = 0.4569343053675317, disc_loss = 0.051601404269745986
Trained batch 77 in epoch 5, gen_loss = 0.456800333964519, disc_loss = 0.05154065918535567
Trained batch 78 in epoch 5, gen_loss = 0.4573040925249269, disc_loss = 0.051399461612624084
Trained batch 79 in epoch 5, gen_loss = 0.45761447623372076, disc_loss = 0.052389945992035794
Trained batch 80 in epoch 5, gen_loss = 0.45671911740008697, disc_loss = 0.051856381329995246
Trained batch 81 in epoch 5, gen_loss = 0.45608128970716055, disc_loss = 0.052059199519046556
Trained batch 82 in epoch 5, gen_loss = 0.456654745053096, disc_loss = 0.05200816676895841
Trained batch 83 in epoch 5, gen_loss = 0.45674828794740496, disc_loss = 0.05184420122254994
Trained batch 84 in epoch 5, gen_loss = 0.4572713469757753, disc_loss = 0.05156793964150198
Trained batch 85 in epoch 5, gen_loss = 0.45768995132557183, disc_loss = 0.052339262063723316
Trained batch 86 in epoch 5, gen_loss = 0.4577789505322774, disc_loss = 0.052729019076274385
Trained batch 87 in epoch 5, gen_loss = 0.45724893699992786, disc_loss = 0.05241753395371647
Trained batch 88 in epoch 5, gen_loss = 0.45687447304136297, disc_loss = 0.05221102342239759
Trained batch 89 in epoch 5, gen_loss = 0.45676964157157474, disc_loss = 0.0517536931619462
Trained batch 90 in epoch 5, gen_loss = 0.4570041449515374, disc_loss = 0.05147988263742773
Trained batch 91 in epoch 5, gen_loss = 0.4574775138626928, disc_loss = 0.05111841829594872
Trained batch 92 in epoch 5, gen_loss = 0.4570070409005688, disc_loss = 0.050962947594422485
Trained batch 93 in epoch 5, gen_loss = 0.45709674662732064, disc_loss = 0.05081263157301285
Trained batch 94 in epoch 5, gen_loss = 0.4569160913166247, disc_loss = 0.050461827537142914
Trained batch 95 in epoch 5, gen_loss = 0.4574947239210208, disc_loss = 0.050107525744048566
Trained batch 96 in epoch 5, gen_loss = 0.4569162729474687, disc_loss = 0.04982738147403315
Trained batch 97 in epoch 5, gen_loss = 0.455656463698465, disc_loss = 0.04951626861144846
Trained batch 98 in epoch 5, gen_loss = 0.4552187639655489, disc_loss = 0.049394347643799554
Trained batch 99 in epoch 5, gen_loss = 0.4552996337413788, disc_loss = 0.04904070211108774
Trained batch 100 in epoch 5, gen_loss = 0.45599058713063156, disc_loss = 0.0488402664357114
Trained batch 101 in epoch 5, gen_loss = 0.4555245415837157, disc_loss = 0.048901726195004346
Trained batch 102 in epoch 5, gen_loss = 0.4556828977413548, disc_loss = 0.04886869324407386
Trained batch 103 in epoch 5, gen_loss = 0.4558165996120526, disc_loss = 0.04951213835290848
Trained batch 104 in epoch 5, gen_loss = 0.4558457221303667, disc_loss = 0.05039716594896856
Trained batch 105 in epoch 5, gen_loss = 0.4559033951669369, disc_loss = 0.05072592196652209
Trained batch 106 in epoch 5, gen_loss = 0.45545170741660573, disc_loss = 0.0505592275854792
Trained batch 107 in epoch 5, gen_loss = 0.455178447343685, disc_loss = 0.05026234653174739
Trained batch 108 in epoch 5, gen_loss = 0.4550050986469339, disc_loss = 0.05013355566188693
Trained batch 109 in epoch 5, gen_loss = 0.4552160460840572, disc_loss = 0.0499130646401847
Trained batch 110 in epoch 5, gen_loss = 0.45562882439510244, disc_loss = 0.04973533119888859
Trained batch 111 in epoch 5, gen_loss = 0.45616875189755646, disc_loss = 0.05025779703282751
Trained batch 112 in epoch 5, gen_loss = 0.4559642683088252, disc_loss = 0.05056498688851706
Trained batch 113 in epoch 5, gen_loss = 0.4560654427398715, disc_loss = 0.050289928696624804
Trained batch 114 in epoch 5, gen_loss = 0.45576181048932285, disc_loss = 0.049983347972612016
Trained batch 115 in epoch 5, gen_loss = 0.45572887515199595, disc_loss = 0.04970430451493453
Trained batch 116 in epoch 5, gen_loss = 0.4557998103973193, disc_loss = 0.050607213579341136
Trained batch 117 in epoch 5, gen_loss = 0.455838610560207, disc_loss = 0.05026197940568929
Trained batch 118 in epoch 5, gen_loss = 0.45654560037019876, disc_loss = 0.05015887951227922
Trained batch 119 in epoch 5, gen_loss = 0.4569371610879898, disc_loss = 0.04986832320767765
Trained batch 120 in epoch 5, gen_loss = 0.4567094391042536, disc_loss = 0.05001948156955937
Trained batch 121 in epoch 5, gen_loss = 0.45722815345545287, disc_loss = 0.04991239164650562
Trained batch 122 in epoch 5, gen_loss = 0.4574806048133509, disc_loss = 0.049582431929534286
Trained batch 123 in epoch 5, gen_loss = 0.45732261528891904, disc_loss = 0.0492620543283861
Trained batch 124 in epoch 5, gen_loss = 0.45771881341934206, disc_loss = 0.04900538806989789
Trained batch 125 in epoch 5, gen_loss = 0.4582306652788132, disc_loss = 0.04883028086762698
Trained batch 126 in epoch 5, gen_loss = 0.45831827479084647, disc_loss = 0.048595201154422805
Trained batch 127 in epoch 5, gen_loss = 0.45897479355335236, disc_loss = 0.04837589423186728
Trained batch 128 in epoch 5, gen_loss = 0.4587516248688217, disc_loss = 0.04804380352486127
Trained batch 129 in epoch 5, gen_loss = 0.4588117058460529, disc_loss = 0.0492789261508733
Trained batch 130 in epoch 5, gen_loss = 0.45844700773253694, disc_loss = 0.05017623054005831
Trained batch 131 in epoch 5, gen_loss = 0.4587402686928258, disc_loss = 0.050017896789182545
Trained batch 132 in epoch 5, gen_loss = 0.4588863340983714, disc_loss = 0.049941980948713716
Trained batch 133 in epoch 5, gen_loss = 0.4592905020091071, disc_loss = 0.04979523951396235
Trained batch 134 in epoch 5, gen_loss = 0.45938579042752586, disc_loss = 0.049628872345029204
Trained batch 135 in epoch 5, gen_loss = 0.45909911306465373, disc_loss = 0.04942614497849718
Trained batch 136 in epoch 5, gen_loss = 0.4580719890820719, disc_loss = 0.04917901935545306
Trained batch 137 in epoch 5, gen_loss = 0.45805166791314667, disc_loss = 0.04908580701811698
Trained batch 138 in epoch 5, gen_loss = 0.4579099706179804, disc_loss = 0.04920645016949061
Trained batch 139 in epoch 5, gen_loss = 0.4577791837709291, disc_loss = 0.04902704524741109
Trained batch 140 in epoch 5, gen_loss = 0.45787133413849146, disc_loss = 0.04886747692242688
Trained batch 141 in epoch 5, gen_loss = 0.4583570505951492, disc_loss = 0.048585566091941486
Trained batch 142 in epoch 5, gen_loss = 0.4584823976029883, disc_loss = 0.048303969885007694
Trained batch 143 in epoch 5, gen_loss = 0.45845719344086117, disc_loss = 0.048356536261659734
Trained batch 144 in epoch 5, gen_loss = 0.4583922100478205, disc_loss = 0.048108245872346495
Trained batch 145 in epoch 5, gen_loss = 0.4582521576587468, disc_loss = 0.04795181155778876
Trained batch 146 in epoch 5, gen_loss = 0.4585800681795393, disc_loss = 0.04766673309614464
Trained batch 147 in epoch 5, gen_loss = 0.4586104223051587, disc_loss = 0.047466210366503614
Trained batch 148 in epoch 5, gen_loss = 0.4585974076450271, disc_loss = 0.0474514394698527
Trained batch 149 in epoch 5, gen_loss = 0.4586532612641652, disc_loss = 0.047345463559031485
Trained batch 150 in epoch 5, gen_loss = 0.4586502976764906, disc_loss = 0.047134494927051844
Trained batch 151 in epoch 5, gen_loss = 0.4583232443975775, disc_loss = 0.04689639673788885
Trained batch 152 in epoch 5, gen_loss = 0.45845502205923494, disc_loss = 0.04668125473084598
Trained batch 153 in epoch 5, gen_loss = 0.4586554357370773, disc_loss = 0.04645661150359295
Trained batch 154 in epoch 5, gen_loss = 0.45841903071249684, disc_loss = 0.046241334603438454
Trained batch 155 in epoch 5, gen_loss = 0.45782383034626645, disc_loss = 0.04597570563260561
Trained batch 156 in epoch 5, gen_loss = 0.45797629246286525, disc_loss = 0.04585571905040437
Trained batch 157 in epoch 5, gen_loss = 0.4581274807075911, disc_loss = 0.04561410784792108
Trained batch 158 in epoch 5, gen_loss = 0.45797281463940936, disc_loss = 0.04543647902824406
Trained batch 159 in epoch 5, gen_loss = 0.45837162490934136, disc_loss = 0.04568690030719154
Trained batch 160 in epoch 5, gen_loss = 0.4585751674560286, disc_loss = 0.04576010286507214
Trained batch 161 in epoch 5, gen_loss = 0.45850658140800615, disc_loss = 0.04554774500084696
Trained batch 162 in epoch 5, gen_loss = 0.45808363454473533, disc_loss = 0.04582021799669858
Trained batch 163 in epoch 5, gen_loss = 0.4585024309231014, disc_loss = 0.045803000088553966
Trained batch 164 in epoch 5, gen_loss = 0.45864368948069484, disc_loss = 0.04578095921174143
Trained batch 165 in epoch 5, gen_loss = 0.45828515129635133, disc_loss = 0.04625745080074811
Trained batch 166 in epoch 5, gen_loss = 0.45821383488392403, disc_loss = 0.04608293271952582
Trained batch 167 in epoch 5, gen_loss = 0.45851223614244235, disc_loss = 0.04586709423234597
Trained batch 168 in epoch 5, gen_loss = 0.45830830455531735, disc_loss = 0.04567987971647075
Trained batch 169 in epoch 5, gen_loss = 0.4579506078187157, disc_loss = 0.04546563059968107
Trained batch 170 in epoch 5, gen_loss = 0.45797680414210984, disc_loss = 0.04528232663869858
Trained batch 171 in epoch 5, gen_loss = 0.4578392822728601, disc_loss = 0.0451321987608491
Trained batch 172 in epoch 5, gen_loss = 0.4578432787015948, disc_loss = 0.0449246763267872
Trained batch 173 in epoch 5, gen_loss = 0.4578617215156555, disc_loss = 0.04470220082385958
Trained batch 174 in epoch 5, gen_loss = 0.45812837600708006, disc_loss = 0.04524953112538372
Trained batch 175 in epoch 5, gen_loss = 0.45775829475711693, disc_loss = 0.04538991584294391
Trained batch 176 in epoch 5, gen_loss = 0.45701602404400454, disc_loss = 0.045556218594859886
Trained batch 177 in epoch 5, gen_loss = 0.4569892098059815, disc_loss = 0.04549397897038065
Trained batch 178 in epoch 5, gen_loss = 0.4570326010941127, disc_loss = 0.04563800695575982
Trained batch 179 in epoch 5, gen_loss = 0.4569905118809806, disc_loss = 0.0454674815138181
Trained batch 180 in epoch 5, gen_loss = 0.4568298957953796, disc_loss = 0.04528077929512243
Trained batch 181 in epoch 5, gen_loss = 0.456378059891554, disc_loss = 0.045268599731990926
Trained batch 182 in epoch 5, gen_loss = 0.45704580281601576, disc_loss = 0.045289680127644796
Trained batch 183 in epoch 5, gen_loss = 0.45729011637361155, disc_loss = 0.045243696238764605
Trained batch 184 in epoch 5, gen_loss = 0.45726525026398734, disc_loss = 0.04512532634308209
Trained batch 185 in epoch 5, gen_loss = 0.4566580417656129, disc_loss = 0.044918741512623046
Trained batch 186 in epoch 5, gen_loss = 0.4570412860515921, disc_loss = 0.04485959324856254
Trained batch 187 in epoch 5, gen_loss = 0.4572140262164968, disc_loss = 0.044911902261640324
Trained batch 188 in epoch 5, gen_loss = 0.4571806514073932, disc_loss = 0.04473537016689541
Trained batch 189 in epoch 5, gen_loss = 0.457375169270917, disc_loss = 0.04456874640217345
Trained batch 190 in epoch 5, gen_loss = 0.4572717146411616, disc_loss = 0.04439185398109062
Trained batch 191 in epoch 5, gen_loss = 0.4569893825488786, disc_loss = 0.04418271676210376
Trained batch 192 in epoch 5, gen_loss = 0.4570109583244423, disc_loss = 0.044016296825723944
Trained batch 193 in epoch 5, gen_loss = 0.45734547385849905, disc_loss = 0.043886402074593246
Trained batch 194 in epoch 5, gen_loss = 0.4574815102112599, disc_loss = 0.04371838274483497
Trained batch 195 in epoch 5, gen_loss = 0.4572582100423015, disc_loss = 0.04352513116508799
Trained batch 196 in epoch 5, gen_loss = 0.45749294077079306, disc_loss = 0.043328217800404065
Trained batch 197 in epoch 5, gen_loss = 0.45788711204071236, disc_loss = 0.04321287372713965
Trained batch 198 in epoch 5, gen_loss = 0.4579404210624982, disc_loss = 0.04304611885770407
Trained batch 199 in epoch 5, gen_loss = 0.45794445857405663, disc_loss = 0.0428647882421501
Trained batch 200 in epoch 5, gen_loss = 0.4578737537955763, disc_loss = 0.0426888698271814
Trained batch 201 in epoch 5, gen_loss = 0.45825632831247726, disc_loss = 0.042535033268337644
Trained batch 202 in epoch 5, gen_loss = 0.4583064342660857, disc_loss = 0.04237472512552817
Trained batch 203 in epoch 5, gen_loss = 0.4582311781305893, disc_loss = 0.04221244808058163
Trained batch 204 in epoch 5, gen_loss = 0.4585526653906194, disc_loss = 0.042158708755472084
Trained batch 205 in epoch 5, gen_loss = 0.4587083787304684, disc_loss = 0.04201757181571453
Trained batch 206 in epoch 5, gen_loss = 0.45903027791907824, disc_loss = 0.042004307477784476
Trained batch 207 in epoch 5, gen_loss = 0.45899616840940255, disc_loss = 0.04188462943868497
Trained batch 208 in epoch 5, gen_loss = 0.4592191040801089, disc_loss = 0.04171720850749307
Trained batch 209 in epoch 5, gen_loss = 0.45975663718723114, disc_loss = 0.041544020896600115
Trained batch 210 in epoch 5, gen_loss = 0.45978485605728003, disc_loss = 0.041374924277083426
Trained batch 211 in epoch 5, gen_loss = 0.45999943563398327, disc_loss = 0.04119887130273471
Trained batch 212 in epoch 5, gen_loss = 0.4598151725222807, disc_loss = 0.04102371882061374
Trained batch 213 in epoch 5, gen_loss = 0.45976323307117567, disc_loss = 0.04088419602061056
Trained batch 214 in epoch 5, gen_loss = 0.46011554335438926, disc_loss = 0.04077067404855476
Trained batch 215 in epoch 5, gen_loss = 0.4602521032922798, disc_loss = 0.040601352221091035
Trained batch 216 in epoch 5, gen_loss = 0.460093795429177, disc_loss = 0.04047231204498748
Trained batch 217 in epoch 5, gen_loss = 0.45999789032914223, disc_loss = 0.040347545672584015
Trained batch 218 in epoch 5, gen_loss = 0.4601108378743472, disc_loss = 0.04020472528778663
Trained batch 219 in epoch 5, gen_loss = 0.460282649370757, disc_loss = 0.04004682718606835
Trained batch 220 in epoch 5, gen_loss = 0.460292624537222, disc_loss = 0.03989401742461984
Trained batch 221 in epoch 5, gen_loss = 0.4603561667708663, disc_loss = 0.03973280219570943
Trained batch 222 in epoch 5, gen_loss = 0.4602107027453692, disc_loss = 0.03957482897196249
Trained batch 223 in epoch 5, gen_loss = 0.46034577848123653, disc_loss = 0.03942845188014742
Trained batch 224 in epoch 5, gen_loss = 0.4602351107862261, disc_loss = 0.039276624783459634
Trained batch 225 in epoch 5, gen_loss = 0.46044132733239534, disc_loss = 0.039122848328516154
Trained batch 226 in epoch 5, gen_loss = 0.46107386006657775, disc_loss = 0.03896791477880486
Trained batch 227 in epoch 5, gen_loss = 0.4612492368670932, disc_loss = 0.03884182379197068
Trained batch 228 in epoch 5, gen_loss = 0.46160866586922555, disc_loss = 0.03877820123157842
Trained batch 229 in epoch 5, gen_loss = 0.46178436007188717, disc_loss = 0.03863928873780305
Trained batch 230 in epoch 5, gen_loss = 0.461849701094937, disc_loss = 0.038494412035346676
Trained batch 231 in epoch 5, gen_loss = 0.46181582890707873, disc_loss = 0.03834266482414838
Trained batch 232 in epoch 5, gen_loss = 0.461703550278373, disc_loss = 0.03819759396032746
Trained batch 233 in epoch 5, gen_loss = 0.46177904167745865, disc_loss = 0.038052825508917816
Trained batch 234 in epoch 5, gen_loss = 0.46212748999291275, disc_loss = 0.03790810906843461
Trained batch 235 in epoch 5, gen_loss = 0.46209718274363015, disc_loss = 0.037771620638708
Trained batch 236 in epoch 5, gen_loss = 0.46209371316282055, disc_loss = 0.03762763458940707
Trained batch 237 in epoch 5, gen_loss = 0.46222327799857166, disc_loss = 0.0374868508015501
Trained batch 238 in epoch 5, gen_loss = 0.46210422276452995, disc_loss = 0.03735262807945733
Trained batch 239 in epoch 5, gen_loss = 0.46198798045516015, disc_loss = 0.03721155059853724
Trained batch 240 in epoch 5, gen_loss = 0.4618534240485227, disc_loss = 0.03707063663847497
Trained batch 241 in epoch 5, gen_loss = 0.46188112526885733, disc_loss = 0.03693349105940962
Trained batch 242 in epoch 5, gen_loss = 0.46176485281912877, disc_loss = 0.03679474489284304
Trained batch 243 in epoch 5, gen_loss = 0.461871256593798, disc_loss = 0.03665400737014859
Trained batch 244 in epoch 5, gen_loss = 0.4619038507646444, disc_loss = 0.036533454943410294
Trained batch 245 in epoch 5, gen_loss = 0.461846504511872, disc_loss = 0.03639893524625104
Trained batch 246 in epoch 5, gen_loss = 0.461916338818276, disc_loss = 0.03627221341440944
Trained batch 247 in epoch 5, gen_loss = 0.46207498975338474, disc_loss = 0.03614039061733732
Trained batch 248 in epoch 5, gen_loss = 0.462205538787995, disc_loss = 0.036024333828738535
Trained batch 249 in epoch 5, gen_loss = 0.4624889967441559, disc_loss = 0.0359817805532366
Trained batch 250 in epoch 5, gen_loss = 0.4625423702585745, disc_loss = 0.03600174136111045
Trained batch 251 in epoch 5, gen_loss = 0.4626025485377463, disc_loss = 0.03588597072354917
Trained batch 252 in epoch 5, gen_loss = 0.4625025998226739, disc_loss = 0.03584317818261948
Trained batch 253 in epoch 5, gen_loss = 0.462489181146847, disc_loss = 0.035854965428213086
Trained batch 254 in epoch 5, gen_loss = 0.4627106958744573, disc_loss = 0.03573427505462485
Trained batch 255 in epoch 5, gen_loss = 0.4628606550395489, disc_loss = 0.03560936078065424
Trained batch 256 in epoch 5, gen_loss = 0.4630875098102288, disc_loss = 0.03550075599742539
Trained batch 257 in epoch 5, gen_loss = 0.4632740189400754, disc_loss = 0.03538727356380848
Trained batch 258 in epoch 5, gen_loss = 0.46368020059519294, disc_loss = 0.03529781985193721
Trained batch 259 in epoch 5, gen_loss = 0.46356346332109893, disc_loss = 0.03519586123382816
Trained batch 260 in epoch 5, gen_loss = 0.4632577196163236, disc_loss = 0.03507854543818996
Trained batch 261 in epoch 5, gen_loss = 0.4630990128480751, disc_loss = 0.03497541602523215
Trained batch 262 in epoch 5, gen_loss = 0.46318538843905516, disc_loss = 0.03487972640202243
Trained batch 263 in epoch 5, gen_loss = 0.4631473235785961, disc_loss = 0.034801686614765924
Trained batch 264 in epoch 5, gen_loss = 0.4635533974980408, disc_loss = 0.03474681968712863
Trained batch 265 in epoch 5, gen_loss = 0.46369728636472746, disc_loss = 0.03470385151817218
Trained batch 266 in epoch 5, gen_loss = 0.46346964974528393, disc_loss = 0.03459258167394036
Trained batch 267 in epoch 5, gen_loss = 0.4634623118300936, disc_loss = 0.034507540216210726
Trained batch 268 in epoch 5, gen_loss = 0.46323567318650427, disc_loss = 0.034464044089612574
Trained batch 269 in epoch 5, gen_loss = 0.46312878749988695, disc_loss = 0.03440978714885811
Trained batch 270 in epoch 5, gen_loss = 0.463117830867697, disc_loss = 0.03436884442962899
Trained batch 271 in epoch 5, gen_loss = 0.4632112714735901, disc_loss = 0.034256806063828714
Trained batch 272 in epoch 5, gen_loss = 0.463316757163722, disc_loss = 0.03424887890047343
Trained batch 273 in epoch 5, gen_loss = 0.4637473473583695, disc_loss = 0.03415095850733537
Trained batch 274 in epoch 5, gen_loss = 0.46370709256692366, disc_loss = 0.034046112787486475
Trained batch 275 in epoch 5, gen_loss = 0.46384673371263174, disc_loss = 0.033960756148123925
Trained batch 276 in epoch 5, gen_loss = 0.4637609754658778, disc_loss = 0.03384764485703344
Trained batch 277 in epoch 5, gen_loss = 0.46360133770558476, disc_loss = 0.03374655880352228
Trained batch 278 in epoch 5, gen_loss = 0.4635483432414284, disc_loss = 0.033644874709554844
Trained batch 279 in epoch 5, gen_loss = 0.46361059972218105, disc_loss = 0.03355756602166886
Trained batch 280 in epoch 5, gen_loss = 0.4636111103555062, disc_loss = 0.03345963950732928
Trained batch 281 in epoch 5, gen_loss = 0.46380119385026025, disc_loss = 0.033363181043330394
Trained batch 282 in epoch 5, gen_loss = 0.4638183223274487, disc_loss = 0.033275440791885075
Trained batch 283 in epoch 5, gen_loss = 0.46392492183917006, disc_loss = 0.033199197634838154
Trained batch 284 in epoch 5, gen_loss = 0.46397419404565243, disc_loss = 0.03311726402474992
Trained batch 285 in epoch 5, gen_loss = 0.4638553897400836, disc_loss = 0.03307020477869164
Trained batch 286 in epoch 5, gen_loss = 0.46412911003890356, disc_loss = 0.03302564102594938
Trained batch 287 in epoch 5, gen_loss = 0.46415704602582586, disc_loss = 0.03293428558309744
Trained batch 288 in epoch 5, gen_loss = 0.4641259002231809, disc_loss = 0.032888469991200056
Trained batch 289 in epoch 5, gen_loss = 0.46405903912823776, disc_loss = 0.0328509823186323
Trained batch 290 in epoch 5, gen_loss = 0.4640363108661167, disc_loss = 0.033363978752123886
Trained batch 291 in epoch 5, gen_loss = 0.46413478724760554, disc_loss = 0.03363276200850609
Trained batch 292 in epoch 5, gen_loss = 0.46420651979413863, disc_loss = 0.03359218302131996
Trained batch 293 in epoch 5, gen_loss = 0.4644780967916761, disc_loss = 0.033541410900874154
Trained batch 294 in epoch 5, gen_loss = 0.46429770356517724, disc_loss = 0.03345271963231518
Trained batch 295 in epoch 5, gen_loss = 0.46447672090820363, disc_loss = 0.03336194370530319
Trained batch 296 in epoch 5, gen_loss = 0.4648096547383652, disc_loss = 0.03326960294099794
Trained batch 297 in epoch 5, gen_loss = 0.46482021256581246, disc_loss = 0.03319509934724602
Trained batch 298 in epoch 5, gen_loss = 0.46472573718897076, disc_loss = 0.03310210227944505
Trained batch 299 in epoch 5, gen_loss = 0.46454481641451517, disc_loss = 0.033002131555695084
Trained batch 300 in epoch 5, gen_loss = 0.4645841187020869, disc_loss = 0.03290301136923118
Trained batch 301 in epoch 5, gen_loss = 0.4647773898989949, disc_loss = 0.03280414840428541
Trained batch 302 in epoch 5, gen_loss = 0.46455644459614265, disc_loss = 0.032706419818976235
Trained batch 303 in epoch 5, gen_loss = 0.4644396982498859, disc_loss = 0.03261063613938045
Trained batch 304 in epoch 5, gen_loss = 0.4644790786211608, disc_loss = 0.03251182383735527
Trained batch 305 in epoch 5, gen_loss = 0.46459463939947243, disc_loss = 0.03242458042983891
Trained batch 306 in epoch 5, gen_loss = 0.46484956387976484, disc_loss = 0.03232702436699177
Trained batch 307 in epoch 5, gen_loss = 0.4648597137881564, disc_loss = 0.03223052049318764
Trained batch 308 in epoch 5, gen_loss = 0.46490228899474284, disc_loss = 0.03213339379211001
Trained batch 309 in epoch 5, gen_loss = 0.46503875765108293, disc_loss = 0.03204275334569355
Trained batch 310 in epoch 5, gen_loss = 0.46518533741546214, disc_loss = 0.03196229386275149
Trained batch 311 in epoch 5, gen_loss = 0.4652229438607509, disc_loss = 0.031866442859142974
Trained batch 312 in epoch 5, gen_loss = 0.4653539758520766, disc_loss = 0.03185651328685447
Trained batch 313 in epoch 5, gen_loss = 0.4654391778122847, disc_loss = 0.031767749249086874
Trained batch 314 in epoch 5, gen_loss = 0.4653854088177757, disc_loss = 0.031674772314727304
Trained batch 315 in epoch 5, gen_loss = 0.4654396331951588, disc_loss = 0.03161194440437174
Trained batch 316 in epoch 5, gen_loss = 0.46544406682910977, disc_loss = 0.03153122527736359
Trained batch 317 in epoch 5, gen_loss = 0.46557266485391174, disc_loss = 0.03145248425755439
Trained batch 318 in epoch 5, gen_loss = 0.4655786382740942, disc_loss = 0.03138218101750487
Trained batch 319 in epoch 5, gen_loss = 0.4656419184990227, disc_loss = 0.03129667419270845
Trained batch 320 in epoch 5, gen_loss = 0.4656705406038932, disc_loss = 0.031229859962189032
Trained batch 321 in epoch 5, gen_loss = 0.4656685667563669, disc_loss = 0.031138435145333897
Trained batch 322 in epoch 5, gen_loss = 0.4656032829461821, disc_loss = 0.031078957102330683
Trained batch 323 in epoch 5, gen_loss = 0.4657294284782292, disc_loss = 0.030994222200127826
Trained batch 324 in epoch 5, gen_loss = 0.4659566752727215, disc_loss = 0.030918112143229405
Trained batch 325 in epoch 5, gen_loss = 0.4659424489992528, disc_loss = 0.03083469986771319
Trained batch 326 in epoch 5, gen_loss = 0.46586042669934963, disc_loss = 0.030760958655139243
Trained batch 327 in epoch 5, gen_loss = 0.4660115128428471, disc_loss = 0.03067515596070202
Trained batch 328 in epoch 5, gen_loss = 0.46580240067015305, disc_loss = 0.03067850849009473
Trained batch 329 in epoch 5, gen_loss = 0.4660147097977725, disc_loss = 0.030625189949095136
Trained batch 330 in epoch 5, gen_loss = 0.46607233975589096, disc_loss = 0.03055127163514709
Trained batch 331 in epoch 5, gen_loss = 0.4660838789430009, disc_loss = 0.030475571073790876
Trained batch 332 in epoch 5, gen_loss = 0.4661636558380929, disc_loss = 0.03046173096233112
Trained batch 333 in epoch 5, gen_loss = 0.46613293475733547, disc_loss = 0.03039983361729415
Trained batch 334 in epoch 5, gen_loss = 0.466238886028973, disc_loss = 0.030371555548036167
Trained batch 335 in epoch 5, gen_loss = 0.4661194376115288, disc_loss = 0.030344072613973237
Trained batch 336 in epoch 5, gen_loss = 0.46603839484095927, disc_loss = 0.030287808347258506
Trained batch 337 in epoch 5, gen_loss = 0.4659838381074589, disc_loss = 0.03030613421141473
Trained batch 338 in epoch 5, gen_loss = 0.4657481667038965, disc_loss = 0.030232088752626646
Trained batch 339 in epoch 5, gen_loss = 0.46583572100190557, disc_loss = 0.03015741774065913
Trained batch 340 in epoch 5, gen_loss = 0.4657255190908035, disc_loss = 0.03009554839596054
Trained batch 341 in epoch 5, gen_loss = 0.46606342433488857, disc_loss = 0.030076938291551402
Trained batch 342 in epoch 5, gen_loss = 0.4658671813004219, disc_loss = 0.03001603296497679
Trained batch 343 in epoch 5, gen_loss = 0.46571485239059424, disc_loss = 0.03014859389534036
Trained batch 344 in epoch 5, gen_loss = 0.4655184833035953, disc_loss = 0.03017641178743941
Trained batch 345 in epoch 5, gen_loss = 0.4655229945403303, disc_loss = 0.030124542319196992
Trained batch 346 in epoch 5, gen_loss = 0.46560218535170433, disc_loss = 0.03005482318109272
Trained batch 347 in epoch 5, gen_loss = 0.46565615111726455, disc_loss = 0.030002635528651955
Trained batch 348 in epoch 5, gen_loss = 0.4657753122740967, disc_loss = 0.029931666622709557
Trained batch 349 in epoch 5, gen_loss = 0.46583677709102633, disc_loss = 0.029866077464539557
Trained batch 350 in epoch 5, gen_loss = 0.46579393362387633, disc_loss = 0.02991740766513371
Trained batch 351 in epoch 5, gen_loss = 0.4656935558569702, disc_loss = 0.029858056890754433
Trained batch 352 in epoch 5, gen_loss = 0.4655460802252502, disc_loss = 0.029795986843933867
Trained batch 353 in epoch 5, gen_loss = 0.46560353949918587, disc_loss = 0.02976364250219885
Trained batch 354 in epoch 5, gen_loss = 0.46552688277943033, disc_loss = 0.029725513668586567
Trained batch 355 in epoch 5, gen_loss = 0.46551621336950344, disc_loss = 0.029670834128962036
Trained batch 356 in epoch 5, gen_loss = 0.46539334581345737, disc_loss = 0.02962400490406337
Trained batch 357 in epoch 5, gen_loss = 0.46510923116899733, disc_loss = 0.029826069631491522
Trained batch 358 in epoch 5, gen_loss = 0.4651998781228132, disc_loss = 0.029761154470189597
Trained batch 359 in epoch 5, gen_loss = 0.4652864538960987, disc_loss = 0.029820286737069383
Trained batch 360 in epoch 5, gen_loss = 0.46520039133748187, disc_loss = 0.02975731736553415
Trained batch 361 in epoch 5, gen_loss = 0.4652033456451985, disc_loss = 0.02976164068783587
Trained batch 362 in epoch 5, gen_loss = 0.46506724886329376, disc_loss = 0.029730131827518037
Trained batch 363 in epoch 5, gen_loss = 0.4650142038916493, disc_loss = 0.02972608011383512
Trained batch 364 in epoch 5, gen_loss = 0.4649285992530927, disc_loss = 0.029707180217150853
Trained batch 365 in epoch 5, gen_loss = 0.4650217950995503, disc_loss = 0.029652568428647382
Trained batch 366 in epoch 5, gen_loss = 0.4650952049432074, disc_loss = 0.02958356455439189
Trained batch 367 in epoch 5, gen_loss = 0.46507050129382504, disc_loss = 0.029558187976679463
Trained batch 368 in epoch 5, gen_loss = 0.4651594978522479, disc_loss = 0.02949846940093641
Trained batch 369 in epoch 5, gen_loss = 0.4651868744476422, disc_loss = 0.029490610442086552
Trained batch 370 in epoch 5, gen_loss = 0.46511088821765867, disc_loss = 0.029524594011611113
Trained batch 371 in epoch 5, gen_loss = 0.46508411350109247, disc_loss = 0.029527862805069513
Trained batch 372 in epoch 5, gen_loss = 0.4653647341453358, disc_loss = 0.029524551438300024
Trained batch 373 in epoch 5, gen_loss = 0.46528597080452555, disc_loss = 0.02948593003469903
Trained batch 374 in epoch 5, gen_loss = 0.4652275660832723, disc_loss = 0.029605880457597475
Trained batch 375 in epoch 5, gen_loss = 0.46535468957525616, disc_loss = 0.029601728452921923
Trained batch 376 in epoch 5, gen_loss = 0.46557957882590256, disc_loss = 0.02959274819623481
Trained batch 377 in epoch 5, gen_loss = 0.4654702459062849, disc_loss = 0.029573550047143484
Trained batch 378 in epoch 5, gen_loss = 0.4654661089889607, disc_loss = 0.02969772935172882
Trained batch 379 in epoch 5, gen_loss = 0.46538819568721873, disc_loss = 0.029825043681653608
Trained batch 380 in epoch 5, gen_loss = 0.4653772745389012, disc_loss = 0.02981636972255819
Trained batch 381 in epoch 5, gen_loss = 0.4655956114930008, disc_loss = 0.029965000196313728
Trained batch 382 in epoch 5, gen_loss = 0.4657508537134365, disc_loss = 0.029936262932557408
Trained batch 383 in epoch 5, gen_loss = 0.4659422809102883, disc_loss = 0.029925143684219318
Trained batch 384 in epoch 5, gen_loss = 0.46609839657684426, disc_loss = 0.03002421684508732
Trained batch 385 in epoch 5, gen_loss = 0.46607822588997183, disc_loss = 0.030305570839250392
Trained batch 386 in epoch 5, gen_loss = 0.46623366170151287, disc_loss = 0.03031656220019855
Trained batch 387 in epoch 5, gen_loss = 0.4662553281667306, disc_loss = 0.030284208100056276
Trained batch 388 in epoch 5, gen_loss = 0.46613526681394996, disc_loss = 0.03024404145062573
Trained batch 389 in epoch 5, gen_loss = 0.4661130198301413, disc_loss = 0.03023608907764682
Trained batch 390 in epoch 5, gen_loss = 0.46595254982523904, disc_loss = 0.030275970869792907
Trained batch 391 in epoch 5, gen_loss = 0.4660830688567794, disc_loss = 0.030358958211002814
Trained batch 392 in epoch 5, gen_loss = 0.46592892156605803, disc_loss = 0.030361920017832014
Trained batch 393 in epoch 5, gen_loss = 0.46581514232654864, disc_loss = 0.030564027456365772
Trained batch 394 in epoch 5, gen_loss = 0.465810529868814, disc_loss = 0.030614286652601123
Trained batch 395 in epoch 5, gen_loss = 0.46599237206909394, disc_loss = 0.03070125637682992
Trained batch 396 in epoch 5, gen_loss = 0.4660244707947114, disc_loss = 0.030825157976774993
Trained batch 397 in epoch 5, gen_loss = 0.46620936931377677, disc_loss = 0.030796999664890613
Trained batch 398 in epoch 5, gen_loss = 0.4660471992982659, disc_loss = 0.030744690892407976
Trained batch 399 in epoch 5, gen_loss = 0.4659549300372601, disc_loss = 0.030694583992881233
Trained batch 400 in epoch 5, gen_loss = 0.46598256384939923, disc_loss = 0.03067211466150456
Trained batch 401 in epoch 5, gen_loss = 0.46599630218240157, disc_loss = 0.030633315535213576
Trained batch 402 in epoch 5, gen_loss = 0.465863027140757, disc_loss = 0.030612699944865672
Trained batch 403 in epoch 5, gen_loss = 0.46606367118287795, disc_loss = 0.030549444761622864
Trained batch 404 in epoch 5, gen_loss = 0.4660193908361741, disc_loss = 0.030530127299731067
Trained batch 405 in epoch 5, gen_loss = 0.46594440320442465, disc_loss = 0.030477023317324905
Trained batch 406 in epoch 5, gen_loss = 0.46594808743099614, disc_loss = 0.03048080548784794
Trained batch 407 in epoch 5, gen_loss = 0.46609805086079764, disc_loss = 0.03052695152691027
Trained batch 408 in epoch 5, gen_loss = 0.46602695786865533, disc_loss = 0.03047308086760315
Trained batch 409 in epoch 5, gen_loss = 0.46608879013759336, disc_loss = 0.030416136603836515
Trained batch 410 in epoch 5, gen_loss = 0.4659486369494974, disc_loss = 0.03037519869536225
Trained batch 411 in epoch 5, gen_loss = 0.465807687093332, disc_loss = 0.030409038831757888
Trained batch 412 in epoch 5, gen_loss = 0.4658067193216042, disc_loss = 0.030352476339045344
Trained batch 413 in epoch 5, gen_loss = 0.465686970502858, disc_loss = 0.030300778455769076
Trained batch 414 in epoch 5, gen_loss = 0.4657514608768095, disc_loss = 0.030272341988341188
Trained batch 415 in epoch 5, gen_loss = 0.4656409129070548, disc_loss = 0.030256595142138673
Trained batch 416 in epoch 5, gen_loss = 0.46543707500258796, disc_loss = 0.030290082697555582
Trained batch 417 in epoch 5, gen_loss = 0.4653912560934085, disc_loss = 0.030551081453951336
Trained batch 418 in epoch 5, gen_loss = 0.4655913658671277, disc_loss = 0.030812888939393716
Trained batch 419 in epoch 5, gen_loss = 0.4655901829401652, disc_loss = 0.030759321412326592
Trained batch 420 in epoch 5, gen_loss = 0.46557089905840765, disc_loss = 0.030713478105215714
Trained batch 421 in epoch 5, gen_loss = 0.465568732381997, disc_loss = 0.030733624382454337
Trained batch 422 in epoch 5, gen_loss = 0.4655777198343976, disc_loss = 0.030697052142182123
Trained batch 423 in epoch 5, gen_loss = 0.46587442585600997, disc_loss = 0.0308297292418879
Trained batch 424 in epoch 5, gen_loss = 0.4658751887433669, disc_loss = 0.030852616378654014
Trained batch 425 in epoch 5, gen_loss = 0.4659074996838547, disc_loss = 0.031003822744966096
Trained batch 426 in epoch 5, gen_loss = 0.46606706763318884, disc_loss = 0.03118327909298634
Trained batch 427 in epoch 5, gen_loss = 0.4660737487339528, disc_loss = 0.031146108405392565
Trained batch 428 in epoch 5, gen_loss = 0.4659723669360012, disc_loss = 0.031145460679768942
Trained batch 429 in epoch 5, gen_loss = 0.46593671960886135, disc_loss = 0.031110620405254235
Trained batch 430 in epoch 5, gen_loss = 0.46587952992202514, disc_loss = 0.031151562334651998
Trained batch 431 in epoch 5, gen_loss = 0.46604047853637626, disc_loss = 0.03135057472536573
Trained batch 432 in epoch 5, gen_loss = 0.46599112475166143, disc_loss = 0.03156673363823977
Trained batch 433 in epoch 5, gen_loss = 0.4659317889109185, disc_loss = 0.03152698307799193
Trained batch 434 in epoch 5, gen_loss = 0.4659685217786109, disc_loss = 0.03150339058691357
Trained batch 435 in epoch 5, gen_loss = 0.4658376234113623, disc_loss = 0.03154859705288775
Trained batch 436 in epoch 5, gen_loss = 0.46600715301129586, disc_loss = 0.031582288850829844
Trained batch 437 in epoch 5, gen_loss = 0.46613114160489816, disc_loss = 0.031625802749629686
Trained batch 438 in epoch 5, gen_loss = 0.4661900283671186, disc_loss = 0.031572516597881656
Trained batch 439 in epoch 5, gen_loss = 0.46619582250714303, disc_loss = 0.03152386531291995
Trained batch 440 in epoch 5, gen_loss = 0.466219631452409, disc_loss = 0.03153315934488791
Trained batch 441 in epoch 5, gen_loss = 0.46605774679334994, disc_loss = 0.03149766984424128
Trained batch 442 in epoch 5, gen_loss = 0.46603256275637694, disc_loss = 0.03147789435203631
Trained batch 443 in epoch 5, gen_loss = 0.4661105985308553, disc_loss = 0.03144281513979533
Trained batch 444 in epoch 5, gen_loss = 0.46601555575145764, disc_loss = 0.03143874566682897
Trained batch 445 in epoch 5, gen_loss = 0.4661679421572407, disc_loss = 0.03138182115936318
Trained batch 446 in epoch 5, gen_loss = 0.4660475894108715, disc_loss = 0.031327934508311915
Trained batch 447 in epoch 5, gen_loss = 0.4659470343030989, disc_loss = 0.03127031372709358
Trained batch 448 in epoch 5, gen_loss = 0.46600018232596213, disc_loss = 0.031221518539595428
Trained batch 449 in epoch 5, gen_loss = 0.46598582128683724, disc_loss = 0.03117934386530477
Trained batch 450 in epoch 5, gen_loss = 0.465891051979657, disc_loss = 0.031144181697757425
Trained batch 451 in epoch 5, gen_loss = 0.46598269058539804, disc_loss = 0.031168657871925444
Trained batch 452 in epoch 5, gen_loss = 0.4659073108079418, disc_loss = 0.031157803873605533
Trained batch 453 in epoch 5, gen_loss = 0.46580599176201, disc_loss = 0.0313159865981054
Trained batch 454 in epoch 5, gen_loss = 0.46601402287954813, disc_loss = 0.03142548960577287
Trained batch 455 in epoch 5, gen_loss = 0.4659723644063138, disc_loss = 0.03137201521205593
Trained batch 456 in epoch 5, gen_loss = 0.46600602003103797, disc_loss = 0.03142996737504219
Trained batch 457 in epoch 5, gen_loss = 0.46596472355736396, disc_loss = 0.03153635143667386
Trained batch 458 in epoch 5, gen_loss = 0.46589654430844424, disc_loss = 0.03150502262278896
Trained batch 459 in epoch 5, gen_loss = 0.466135654695656, disc_loss = 0.03148705702067515
Trained batch 460 in epoch 5, gen_loss = 0.4660011644347888, disc_loss = 0.0316220825472887
Trained batch 461 in epoch 5, gen_loss = 0.46602186186489086, disc_loss = 0.03161179404821674
Trained batch 462 in epoch 5, gen_loss = 0.4661492030769908, disc_loss = 0.03176325965007932
Trained batch 463 in epoch 5, gen_loss = 0.46616019604021103, disc_loss = 0.03173308699378736
Trained batch 464 in epoch 5, gen_loss = 0.46596346773127073, disc_loss = 0.0316970796001354
Trained batch 465 in epoch 5, gen_loss = 0.4659550789216046, disc_loss = 0.03172381992562766
Trained batch 466 in epoch 5, gen_loss = 0.46595008680856204, disc_loss = 0.03167683427043586
Trained batch 467 in epoch 5, gen_loss = 0.46588539185687006, disc_loss = 0.03167316207386609
Trained batch 468 in epoch 5, gen_loss = 0.46596609923376964, disc_loss = 0.03231728843910727
Trained batch 469 in epoch 5, gen_loss = 0.46600847650081556, disc_loss = 0.03229033817472729
Trained batch 470 in epoch 5, gen_loss = 0.46575609665767403, disc_loss = 0.03264819370803172
Trained batch 471 in epoch 5, gen_loss = 0.4658049538857856, disc_loss = 0.03274521729351471
Trained batch 472 in epoch 5, gen_loss = 0.4656438763247484, disc_loss = 0.0327945072290017
Trained batch 473 in epoch 5, gen_loss = 0.4657988069178183, disc_loss = 0.033507764257661575
Trained batch 474 in epoch 5, gen_loss = 0.4656855525468525, disc_loss = 0.034031288542196544
Trained batch 475 in epoch 5, gen_loss = 0.46545685702512246, disc_loss = 0.03408661442921309
Trained batch 476 in epoch 5, gen_loss = 0.46542027780094986, disc_loss = 0.03413453493223367
Trained batch 477 in epoch 5, gen_loss = 0.46548411206470874, disc_loss = 0.03421713698291995
Trained batch 478 in epoch 5, gen_loss = 0.46537916433836074, disc_loss = 0.034190622475999556
Trained batch 479 in epoch 5, gen_loss = 0.4651473791648944, disc_loss = 0.03415057114010172
Trained batch 480 in epoch 5, gen_loss = 0.4650903484181902, disc_loss = 0.03448992848019706
Trained batch 481 in epoch 5, gen_loss = 0.4649699895461071, disc_loss = 0.03450044618288627
Trained batch 482 in epoch 5, gen_loss = 0.4647814090947927, disc_loss = 0.03453706779953972
Trained batch 483 in epoch 5, gen_loss = 0.4648670209340813, disc_loss = 0.03456891227724254
Trained batch 484 in epoch 5, gen_loss = 0.46481148717329673, disc_loss = 0.035245586037587796
Trained batch 485 in epoch 5, gen_loss = 0.46464212263317267, disc_loss = 0.035706584756463815
Trained batch 486 in epoch 5, gen_loss = 0.464551279248643, disc_loss = 0.03592123539168847
Trained batch 487 in epoch 5, gen_loss = 0.4644375670029492, disc_loss = 0.03619002087922484
Trained batch 488 in epoch 5, gen_loss = 0.4642519632122024, disc_loss = 0.036226668252975346
Trained batch 489 in epoch 5, gen_loss = 0.4641059576248636, disc_loss = 0.03630017441749687
Trained batch 490 in epoch 5, gen_loss = 0.4642206786120739, disc_loss = 0.036382092990677295
Trained batch 491 in epoch 5, gen_loss = 0.4641103532498445, disc_loss = 0.03668451893433921
Trained batch 492 in epoch 5, gen_loss = 0.4643573412788809, disc_loss = 0.03722420948086227
Trained batch 493 in epoch 5, gen_loss = 0.4641145958229598, disc_loss = 0.037242471391989315
Trained batch 494 in epoch 5, gen_loss = 0.46390802950570076, disc_loss = 0.0372621551652279
Trained batch 495 in epoch 5, gen_loss = 0.46407605052715345, disc_loss = 0.037219553995049455
Trained batch 496 in epoch 5, gen_loss = 0.46405647794005855, disc_loss = 0.03745809481202829
Trained batch 497 in epoch 5, gen_loss = 0.46377395225097856, disc_loss = 0.03773091678544094
Trained batch 498 in epoch 5, gen_loss = 0.46370543112496815, disc_loss = 0.03770655427638531
Trained batch 499 in epoch 5, gen_loss = 0.46353259140253067, disc_loss = 0.03785409772093408
Trained batch 500 in epoch 5, gen_loss = 0.4635446687301476, disc_loss = 0.03796744028068224
Trained batch 501 in epoch 5, gen_loss = 0.463357773672537, disc_loss = 0.03790416422395585
Trained batch 502 in epoch 5, gen_loss = 0.4633667591077907, disc_loss = 0.037926595799474945
Trained batch 503 in epoch 5, gen_loss = 0.46334793300382676, disc_loss = 0.03786447065737328
Trained batch 504 in epoch 5, gen_loss = 0.463344933845029, disc_loss = 0.03780399819185939
Trained batch 505 in epoch 5, gen_loss = 0.4633024874412024, disc_loss = 0.037767109704772636
Trained batch 506 in epoch 5, gen_loss = 0.46322821571511863, disc_loss = 0.037724324633161624
Trained batch 507 in epoch 5, gen_loss = 0.46324257681688924, disc_loss = 0.03780536635620263
Trained batch 508 in epoch 5, gen_loss = 0.4630458079176005, disc_loss = 0.03779594619664197
Trained batch 509 in epoch 5, gen_loss = 0.46311527052346396, disc_loss = 0.037743073470625735
Trained batch 510 in epoch 5, gen_loss = 0.4629367642439975, disc_loss = 0.037866226791808795
Trained batch 511 in epoch 5, gen_loss = 0.46303445927333087, disc_loss = 0.03802429649181249
Trained batch 512 in epoch 5, gen_loss = 0.46311971980925887, disc_loss = 0.03799193890081795
Trained batch 513 in epoch 5, gen_loss = 0.46301471717394743, disc_loss = 0.0381379380180312
Trained batch 514 in epoch 5, gen_loss = 0.4629293595124217, disc_loss = 0.0382657813529927
Trained batch 515 in epoch 5, gen_loss = 0.46286829988392747, disc_loss = 0.03824344742569401
Trained batch 516 in epoch 5, gen_loss = 0.46296533135196455, disc_loss = 0.03850146609550338
Trained batch 517 in epoch 5, gen_loss = 0.46293318795191274, disc_loss = 0.038612391471343196
Trained batch 518 in epoch 5, gen_loss = 0.46302587178630866, disc_loss = 0.038596789927494594
Trained batch 519 in epoch 5, gen_loss = 0.4630675950875649, disc_loss = 0.038545701814627346
Trained batch 520 in epoch 5, gen_loss = 0.4628227126575477, disc_loss = 0.03862254400652674
Trained batch 521 in epoch 5, gen_loss = 0.4629329576574523, disc_loss = 0.03869855692641367
Trained batch 522 in epoch 5, gen_loss = 0.46282864312140937, disc_loss = 0.03872165962564893
Trained batch 523 in epoch 5, gen_loss = 0.46274392795926744, disc_loss = 0.03878719726189054
Trained batch 524 in epoch 5, gen_loss = 0.4628322197142101, disc_loss = 0.03885113125467407
Trained batch 525 in epoch 5, gen_loss = 0.46283730122299704, disc_loss = 0.03880623958632173
Trained batch 526 in epoch 5, gen_loss = 0.46287916021057507, disc_loss = 0.038815730886464936
Trained batch 527 in epoch 5, gen_loss = 0.46287271307047567, disc_loss = 0.0387696576113795
Trained batch 528 in epoch 5, gen_loss = 0.46276108748746053, disc_loss = 0.03874772683992834
Trained batch 529 in epoch 5, gen_loss = 0.46280762952453686, disc_loss = 0.038973711357882496
Trained batch 530 in epoch 5, gen_loss = 0.46283360709578303, disc_loss = 0.03891365598030423
Trained batch 531 in epoch 5, gen_loss = 0.46270622385847837, disc_loss = 0.03896924297660554
Trained batch 532 in epoch 5, gen_loss = 0.4626708587047978, disc_loss = 0.03911042578608378
Trained batch 533 in epoch 5, gen_loss = 0.4625866145788507, disc_loss = 0.039066427055709695
Trained batch 534 in epoch 5, gen_loss = 0.46254926457583345, disc_loss = 0.03900610894447837
Trained batch 535 in epoch 5, gen_loss = 0.4626304895908975, disc_loss = 0.038990333954996514
Trained batch 536 in epoch 5, gen_loss = 0.4627132624998217, disc_loss = 0.038932495050477404
Trained batch 537 in epoch 5, gen_loss = 0.4627067381896937, disc_loss = 0.038884544517233846
Trained batch 538 in epoch 5, gen_loss = 0.46285440611043094, disc_loss = 0.03882928164688791
Trained batch 539 in epoch 5, gen_loss = 0.46286872967525766, disc_loss = 0.038772266714066195
Trained batch 540 in epoch 5, gen_loss = 0.4629966721296751, disc_loss = 0.03871251758452257
Trained batch 541 in epoch 5, gen_loss = 0.46296426224972487, disc_loss = 0.03866013225809777
Trained batch 542 in epoch 5, gen_loss = 0.4628618171311654, disc_loss = 0.038612012700589365
Trained batch 543 in epoch 5, gen_loss = 0.4628792934338836, disc_loss = 0.038558399644363604
Trained batch 544 in epoch 5, gen_loss = 0.4627487638674745, disc_loss = 0.03850491340208047
Trained batch 545 in epoch 5, gen_loss = 0.4626812121588669, disc_loss = 0.03844130184691597
Trained batch 546 in epoch 5, gen_loss = 0.46272836878923, disc_loss = 0.0383793415203333
Trained batch 547 in epoch 5, gen_loss = 0.46262186754794016, disc_loss = 0.038324243750849765
Trained batch 548 in epoch 5, gen_loss = 0.4626729468830296, disc_loss = 0.03826829662036748
Trained batch 549 in epoch 5, gen_loss = 0.46259361575950275, disc_loss = 0.038205656576266685
Trained batch 550 in epoch 5, gen_loss = 0.4625622936255703, disc_loss = 0.038141380088486644
Trained batch 551 in epoch 5, gen_loss = 0.462528502487618, disc_loss = 0.03807713646349747
Trained batch 552 in epoch 5, gen_loss = 0.46257819281133133, disc_loss = 0.03801560414779029
Trained batch 553 in epoch 5, gen_loss = 0.46252842134517025, disc_loss = 0.03795117442811325
Trained batch 554 in epoch 5, gen_loss = 0.4624447358621133, disc_loss = 0.03789001472843895
Trained batch 555 in epoch 5, gen_loss = 0.4624967445894111, disc_loss = 0.03783270698555799
Trained batch 556 in epoch 5, gen_loss = 0.462424245300156, disc_loss = 0.03776939259779337
Trained batch 557 in epoch 5, gen_loss = 0.4624140299990186, disc_loss = 0.03771435293326435
Trained batch 558 in epoch 5, gen_loss = 0.46237022697605684, disc_loss = 0.037657443389224894
Trained batch 559 in epoch 5, gen_loss = 0.46234959337328163, disc_loss = 0.03767951905382298
Trained batch 560 in epoch 5, gen_loss = 0.4623617991512897, disc_loss = 0.03762946399231732
Trained batch 561 in epoch 5, gen_loss = 0.4622513156556574, disc_loss = 0.037635977017267334
Trained batch 562 in epoch 5, gen_loss = 0.4622548174371093, disc_loss = 0.0376204679942182
Trained batch 563 in epoch 5, gen_loss = 0.4621479520772366, disc_loss = 0.03756267432282771
Trained batch 564 in epoch 5, gen_loss = 0.4621951388046805, disc_loss = 0.037513329120212754
Trained batch 565 in epoch 5, gen_loss = 0.462112079502837, disc_loss = 0.03745882503228433
Trained batch 566 in epoch 5, gen_loss = 0.46200404306988657, disc_loss = 0.03741326147129487
Trained batch 567 in epoch 5, gen_loss = 0.4619094021618366, disc_loss = 0.0373580053444168
Trained batch 568 in epoch 5, gen_loss = 0.46198504361829773, disc_loss = 0.03729877391030524
Trained batch 569 in epoch 5, gen_loss = 0.46207962595579916, disc_loss = 0.037240470204657566
Trained batch 570 in epoch 5, gen_loss = 0.4620211681321707, disc_loss = 0.03718159646517556
Trained batch 571 in epoch 5, gen_loss = 0.4619973471739909, disc_loss = 0.037130116253246234
Trained batch 572 in epoch 5, gen_loss = 0.461930307418264, disc_loss = 0.03707024247371746
Trained batch 573 in epoch 5, gen_loss = 0.4618372851755561, disc_loss = 0.03701630789719243
Trained batch 574 in epoch 5, gen_loss = 0.46187855948572576, disc_loss = 0.03696577295600234
Trained batch 575 in epoch 5, gen_loss = 0.4618921381317907, disc_loss = 0.03690616294645426
Trained batch 576 in epoch 5, gen_loss = 0.46184246384085154, disc_loss = 0.036859340702855
Trained batch 577 in epoch 5, gen_loss = 0.4617763495775243, disc_loss = 0.03680510006246405
Trained batch 578 in epoch 5, gen_loss = 0.4618556322417317, disc_loss = 0.03675229863053757
Trained batch 579 in epoch 5, gen_loss = 0.4619061298411468, disc_loss = 0.036709883101164076
Trained batch 580 in epoch 5, gen_loss = 0.46204109128288884, disc_loss = 0.03667267680143306
Trained batch 581 in epoch 5, gen_loss = 0.46207598824681284, disc_loss = 0.036623714307900776
Trained batch 582 in epoch 5, gen_loss = 0.4620471278247048, disc_loss = 0.03657712038996986
Trained batch 583 in epoch 5, gen_loss = 0.46197935107023747, disc_loss = 0.03653676709505468
Trained batch 584 in epoch 5, gen_loss = 0.46194622185495166, disc_loss = 0.03648630913494266
Trained batch 585 in epoch 5, gen_loss = 0.46205719862985123, disc_loss = 0.03643179964770821
Trained batch 586 in epoch 5, gen_loss = 0.4620930852028946, disc_loss = 0.036385205956897815
Trained batch 587 in epoch 5, gen_loss = 0.46199507367651477, disc_loss = 0.03634713802405088
Trained batch 588 in epoch 5, gen_loss = 0.46202921437286154, disc_loss = 0.03630580830269972
Trained batch 589 in epoch 5, gen_loss = 0.46207609691862334, disc_loss = 0.036263664381112906
Trained batch 590 in epoch 5, gen_loss = 0.46219950914382935, disc_loss = 0.03621030426265076
Trained batch 591 in epoch 5, gen_loss = 0.46225836133030623, disc_loss = 0.03616939179187899
Trained batch 592 in epoch 5, gen_loss = 0.46212717076578186, disc_loss = 0.036216116561570075
Trained batch 593 in epoch 5, gen_loss = 0.46209292143884334, disc_loss = 0.03631150194381831
Trained batch 594 in epoch 5, gen_loss = 0.4621814838477543, disc_loss = 0.03626382803376138
Trained batch 595 in epoch 5, gen_loss = 0.4620818988788848, disc_loss = 0.03629952843942454
Trained batch 596 in epoch 5, gen_loss = 0.4621099647465263, disc_loss = 0.03630243099300063
Trained batch 597 in epoch 5, gen_loss = 0.4621215876328905, disc_loss = 0.036309658170694856
Trained batch 598 in epoch 5, gen_loss = 0.46207881113125604, disc_loss = 0.03627946709872741
Trained batch 599 in epoch 5, gen_loss = 0.4620504580934842, disc_loss = 0.03623741652758326
Trained batch 600 in epoch 5, gen_loss = 0.4620663110111002, disc_loss = 0.036213535799400044
Trained batch 601 in epoch 5, gen_loss = 0.4618842913165837, disc_loss = 0.036182974591469116
Trained batch 602 in epoch 5, gen_loss = 0.46200492187321285, disc_loss = 0.03613551850195134
Trained batch 603 in epoch 5, gen_loss = 0.46201753058773004, disc_loss = 0.03612690894044967
Trained batch 604 in epoch 5, gen_loss = 0.46205785141503514, disc_loss = 0.03610530920068864
Trained batch 605 in epoch 5, gen_loss = 0.4621352532220752, disc_loss = 0.0360631100826116
Trained batch 606 in epoch 5, gen_loss = 0.46217408506245744, disc_loss = 0.03601231961568612
Trained batch 607 in epoch 5, gen_loss = 0.4622705574882658, disc_loss = 0.035961280698086885
Trained batch 608 in epoch 5, gen_loss = 0.46223183561036935, disc_loss = 0.035919962648328314
Trained batch 609 in epoch 5, gen_loss = 0.462229667677254, disc_loss = 0.03590065082554232
Trained batch 610 in epoch 5, gen_loss = 0.4622361015180909, disc_loss = 0.03590080538804989
Trained batch 611 in epoch 5, gen_loss = 0.46222679565350216, disc_loss = 0.03594131502828841
Trained batch 612 in epoch 5, gen_loss = 0.4622357063250674, disc_loss = 0.03592697942274703
Trained batch 613 in epoch 5, gen_loss = 0.4622226134670674, disc_loss = 0.03590106160674966
Trained batch 614 in epoch 5, gen_loss = 0.46230631683900103, disc_loss = 0.035860588285140695
Trained batch 615 in epoch 5, gen_loss = 0.46230108029656597, disc_loss = 0.03582209200683721
Trained batch 616 in epoch 5, gen_loss = 0.4623801830908468, disc_loss = 0.03578592413780544
Trained batch 617 in epoch 5, gen_loss = 0.46232203358006707, disc_loss = 0.035760770794674816
Trained batch 618 in epoch 5, gen_loss = 0.46231648874783554, disc_loss = 0.0357103405179161
Trained batch 619 in epoch 5, gen_loss = 0.46229643182408425, disc_loss = 0.03565937613546398
Trained batch 620 in epoch 5, gen_loss = 0.4623794915115584, disc_loss = 0.03568999530487332
Trained batch 621 in epoch 5, gen_loss = 0.46241633388007186, disc_loss = 0.03568245650817853
Trained batch 622 in epoch 5, gen_loss = 0.46229102107341946, disc_loss = 0.03564734043748556
Trained batch 623 in epoch 5, gen_loss = 0.4622447576182775, disc_loss = 0.03569543726599733
Trained batch 624 in epoch 5, gen_loss = 0.4622097720623016, disc_loss = 0.035747163196094334
Trained batch 625 in epoch 5, gen_loss = 0.46203519223025813, disc_loss = 0.035779350685861744
Trained batch 626 in epoch 5, gen_loss = 0.4622532532831128, disc_loss = 0.0359224035544618
Trained batch 627 in epoch 5, gen_loss = 0.46230561822462996, disc_loss = 0.03589848162191861
Trained batch 628 in epoch 5, gen_loss = 0.4622758663420836, disc_loss = 0.03593787367493417
Trained batch 629 in epoch 5, gen_loss = 0.462369470511164, disc_loss = 0.03589453943506149
Trained batch 630 in epoch 5, gen_loss = 0.46232621846410626, disc_loss = 0.03592634375525193
Trained batch 631 in epoch 5, gen_loss = 0.4623664193609847, disc_loss = 0.035918986433829604
Trained batch 632 in epoch 5, gen_loss = 0.46223343826394886, disc_loss = 0.03609793030308916
Trained batch 633 in epoch 5, gen_loss = 0.46219050912450915, disc_loss = 0.03623212798449361
Trained batch 634 in epoch 5, gen_loss = 0.46217503819878647, disc_loss = 0.03623137974205948
Trained batch 635 in epoch 5, gen_loss = 0.46204850902347444, disc_loss = 0.03624995361223565
Trained batch 636 in epoch 5, gen_loss = 0.46200571516806516, disc_loss = 0.03623391227051762
Trained batch 637 in epoch 5, gen_loss = 0.46207518609339915, disc_loss = 0.036231981526343535
Trained batch 638 in epoch 5, gen_loss = 0.4619781445822619, disc_loss = 0.03621795729508825
Trained batch 639 in epoch 5, gen_loss = 0.46195851974189284, disc_loss = 0.03619848424586962
Trained batch 640 in epoch 5, gen_loss = 0.46207955233206427, disc_loss = 0.03625335787294372
Trained batch 641 in epoch 5, gen_loss = 0.4621138599152877, disc_loss = 0.036217515557210866
Trained batch 642 in epoch 5, gen_loss = 0.4620871390933012, disc_loss = 0.036216728557458853
Trained batch 643 in epoch 5, gen_loss = 0.4620015859974097, disc_loss = 0.03618888102304798
Trained batch 644 in epoch 5, gen_loss = 0.46200472661691117, disc_loss = 0.03614954838128544
Trained batch 645 in epoch 5, gen_loss = 0.46198047226981115, disc_loss = 0.036151901862242375
Trained batch 646 in epoch 5, gen_loss = 0.46189922075920165, disc_loss = 0.036170882969076994
Trained batch 647 in epoch 5, gen_loss = 0.4618453614321756, disc_loss = 0.03615124757638069
Trained batch 648 in epoch 5, gen_loss = 0.4617428980733287, disc_loss = 0.03612139749032903
Trained batch 649 in epoch 5, gen_loss = 0.46156835097533006, disc_loss = 0.036080775407250396
Trained batch 650 in epoch 5, gen_loss = 0.46150291744281985, disc_loss = 0.03608896525826351
Trained batch 651 in epoch 5, gen_loss = 0.4613907915865717, disc_loss = 0.036079091148663804
Trained batch 652 in epoch 5, gen_loss = 0.46141612246792313, disc_loss = 0.03604515221352856
Trained batch 653 in epoch 5, gen_loss = 0.4613910226738052, disc_loss = 0.036058398697202
Trained batch 654 in epoch 5, gen_loss = 0.4613623897082933, disc_loss = 0.036048058228645444
Trained batch 655 in epoch 5, gen_loss = 0.46136548020309065, disc_loss = 0.03600803448938589
Trained batch 656 in epoch 5, gen_loss = 0.46138965516511343, disc_loss = 0.03598916727948163
Trained batch 657 in epoch 5, gen_loss = 0.4613827678026762, disc_loss = 0.03605403017417576
Trained batch 658 in epoch 5, gen_loss = 0.46145679248844546, disc_loss = 0.03623333996199269
Trained batch 659 in epoch 5, gen_loss = 0.4613308013840155, disc_loss = 0.03625313863175865
Trained batch 660 in epoch 5, gen_loss = 0.4613326842954408, disc_loss = 0.036218972781034815
Trained batch 661 in epoch 5, gen_loss = 0.46121441075448905, disc_loss = 0.03618036870217919
Trained batch 662 in epoch 5, gen_loss = 0.4611918258271426, disc_loss = 0.036149125466324095
Trained batch 663 in epoch 5, gen_loss = 0.46111750243658045, disc_loss = 0.03610647685355255
Trained batch 664 in epoch 5, gen_loss = 0.4611316686286066, disc_loss = 0.03617441226374638
Trained batch 665 in epoch 5, gen_loss = 0.46093966912578893, disc_loss = 0.03617537156038976
Trained batch 666 in epoch 5, gen_loss = 0.4610551049684299, disc_loss = 0.03613817016157773
Trained batch 667 in epoch 5, gen_loss = 0.4611632616041663, disc_loss = 0.03611238053905733
Trained batch 668 in epoch 5, gen_loss = 0.4611236460629422, disc_loss = 0.036131949932592874
Trained batch 669 in epoch 5, gen_loss = 0.46116295594777634, disc_loss = 0.03609732096448346
Trained batch 670 in epoch 5, gen_loss = 0.4610584395120112, disc_loss = 0.036098449106672405
Trained batch 671 in epoch 5, gen_loss = 0.4609644899943045, disc_loss = 0.03609557075642875
Trained batch 672 in epoch 5, gen_loss = 0.4610114298196285, disc_loss = 0.03605323017178377
Trained batch 673 in epoch 5, gen_loss = 0.4610427272691217, disc_loss = 0.03622089973281246
Trained batch 674 in epoch 5, gen_loss = 0.46094316407486247, disc_loss = 0.03629856595510824
Trained batch 675 in epoch 5, gen_loss = 0.46082894080842035, disc_loss = 0.036327329554668074
Trained batch 676 in epoch 5, gen_loss = 0.46088579231034, disc_loss = 0.03654919010831217
Trained batch 677 in epoch 5, gen_loss = 0.46090078797839734, disc_loss = 0.036537812887601676
Trained batch 678 in epoch 5, gen_loss = 0.4609091462284897, disc_loss = 0.03663616544283811
Trained batch 679 in epoch 5, gen_loss = 0.4608176085878821, disc_loss = 0.036657453692168926
Trained batch 680 in epoch 5, gen_loss = 0.4608240855335314, disc_loss = 0.03672316740660158
Trained batch 681 in epoch 5, gen_loss = 0.4607866581671399, disc_loss = 0.036856592097012406
Trained batch 682 in epoch 5, gen_loss = 0.4609130807275479, disc_loss = 0.03716579915449094
Trained batch 683 in epoch 5, gen_loss = 0.46079362436519034, disc_loss = 0.03716367109197366
Trained batch 684 in epoch 5, gen_loss = 0.46069377391007693, disc_loss = 0.03729434949532831
Trained batch 685 in epoch 5, gen_loss = 0.46058199713250986, disc_loss = 0.03731219769939482
Trained batch 686 in epoch 5, gen_loss = 0.46062150345966113, disc_loss = 0.0373100632338363
Trained batch 687 in epoch 5, gen_loss = 0.46048925860330114, disc_loss = 0.037441472135258155
Trained batch 688 in epoch 5, gen_loss = 0.46031398757621755, disc_loss = 0.03776764205953644
Trained batch 689 in epoch 5, gen_loss = 0.460209013759226, disc_loss = 0.037870426046277356
Trained batch 690 in epoch 5, gen_loss = 0.46017092733755816, disc_loss = 0.03788593820853539
Trained batch 691 in epoch 5, gen_loss = 0.4602029910149602, disc_loss = 0.03784613864112112
Trained batch 692 in epoch 5, gen_loss = 0.46011795200310746, disc_loss = 0.03781990501791115
Trained batch 693 in epoch 5, gen_loss = 0.45996047011026386, disc_loss = 0.03783067689637549
Trained batch 694 in epoch 5, gen_loss = 0.45989412884060427, disc_loss = 0.03786438628712924
Trained batch 695 in epoch 5, gen_loss = 0.4598536057205036, disc_loss = 0.03781851893575225
Trained batch 696 in epoch 5, gen_loss = 0.4598631137070731, disc_loss = 0.037881138952485044
Trained batch 697 in epoch 5, gen_loss = 0.4598554973103597, disc_loss = 0.037888480833548795
Trained batch 698 in epoch 5, gen_loss = 0.4598308748356433, disc_loss = 0.0378446266248633
Trained batch 699 in epoch 5, gen_loss = 0.45992134217705044, disc_loss = 0.03780573157610238
Trained batch 700 in epoch 5, gen_loss = 0.45995342357352526, disc_loss = 0.0377603039783512
Trained batch 701 in epoch 5, gen_loss = 0.459919467143863, disc_loss = 0.03789578743515791
Trained batch 702 in epoch 5, gen_loss = 0.4598967787381765, disc_loss = 0.037911691997832175
Trained batch 703 in epoch 5, gen_loss = 0.46010560847141524, disc_loss = 0.03795199621874252
Trained batch 704 in epoch 5, gen_loss = 0.46017967335721277, disc_loss = 0.037922167196268786
Trained batch 705 in epoch 5, gen_loss = 0.4602433955534322, disc_loss = 0.03790200599248286
Trained batch 706 in epoch 5, gen_loss = 0.46020577082876774, disc_loss = 0.0379022622088766
Trained batch 707 in epoch 5, gen_loss = 0.4602134537141202, disc_loss = 0.03785962856780491
Trained batch 708 in epoch 5, gen_loss = 0.46024716409036237, disc_loss = 0.03790244957309332
Trained batch 709 in epoch 5, gen_loss = 0.460234234198718, disc_loss = 0.037858978411163084
Trained batch 710 in epoch 5, gen_loss = 0.46037078767218503, disc_loss = 0.03783144977263996
Trained batch 711 in epoch 5, gen_loss = 0.4603077911593941, disc_loss = 0.03786138013895376
Trained batch 712 in epoch 5, gen_loss = 0.46037071525298195, disc_loss = 0.03789681126086007
Trained batch 713 in epoch 5, gen_loss = 0.46048399814370633, disc_loss = 0.0378763015665367
Trained batch 714 in epoch 5, gen_loss = 0.46036679419604215, disc_loss = 0.03806848137206365
Trained batch 715 in epoch 5, gen_loss = 0.46044065074880697, disc_loss = 0.03805510341674324
Trained batch 716 in epoch 5, gen_loss = 0.4604506543324416, disc_loss = 0.03802778750980816
Trained batch 717 in epoch 5, gen_loss = 0.4605384354471828, disc_loss = 0.038000553419773306
Trained batch 718 in epoch 5, gen_loss = 0.46044093246088574, disc_loss = 0.03797043148206057
Trained batch 719 in epoch 5, gen_loss = 0.4604436564776633, disc_loss = 0.03795962305885041
Trained batch 720 in epoch 5, gen_loss = 0.4603946267649139, disc_loss = 0.038027583665521905
Trained batch 721 in epoch 5, gen_loss = 0.46034961406378866, disc_loss = 0.03798602027525104
Trained batch 722 in epoch 5, gen_loss = 0.46041007140035617, disc_loss = 0.037967234707107694
Trained batch 723 in epoch 5, gen_loss = 0.46051812777038437, disc_loss = 0.038017126151588254
Trained batch 724 in epoch 5, gen_loss = 0.4605330640694191, disc_loss = 0.03799237164845369
Trained batch 725 in epoch 5, gen_loss = 0.4604266312168321, disc_loss = 0.037953078662290314
Trained batch 726 in epoch 5, gen_loss = 0.46043687976866016, disc_loss = 0.03792293927042349
Trained batch 727 in epoch 5, gen_loss = 0.46050234556525615, disc_loss = 0.03792960822833625
Trained batch 728 in epoch 5, gen_loss = 0.46053723477859393, disc_loss = 0.03810662368203249
Trained batch 729 in epoch 5, gen_loss = 0.4605703690280653, disc_loss = 0.03808460929893493
Trained batch 730 in epoch 5, gen_loss = 0.46073080479038725, disc_loss = 0.038185215602430135
Trained batch 731 in epoch 5, gen_loss = 0.4606217218389928, disc_loss = 0.0382032525279404
Trained batch 732 in epoch 5, gen_loss = 0.46058708095940853, disc_loss = 0.0382146544446076
Trained batch 733 in epoch 5, gen_loss = 0.4605026855780578, disc_loss = 0.03820299550307894
Trained batch 734 in epoch 5, gen_loss = 0.46056092847772195, disc_loss = 0.038203073037173726
Trained batch 735 in epoch 5, gen_loss = 0.46056598947261984, disc_loss = 0.03818527509160365
Trained batch 736 in epoch 5, gen_loss = 0.46053982027673657, disc_loss = 0.03822051089025119
Trained batch 737 in epoch 5, gen_loss = 0.4605944944510292, disc_loss = 0.03818900333506088
Trained batch 738 in epoch 5, gen_loss = 0.46061732651254966, disc_loss = 0.03816983011769854
Trained batch 739 in epoch 5, gen_loss = 0.46048682686444875, disc_loss = 0.03814925093068489
Trained batch 740 in epoch 5, gen_loss = 0.46049274650984284, disc_loss = 0.03817707901225424
Trained batch 741 in epoch 5, gen_loss = 0.4605117572767715, disc_loss = 0.038182206449539444
Trained batch 742 in epoch 5, gen_loss = 0.4604371269089377, disc_loss = 0.0382128315296182
Trained batch 743 in epoch 5, gen_loss = 0.4604784204594551, disc_loss = 0.03829763540563109
Trained batch 744 in epoch 5, gen_loss = 0.46046555338289913, disc_loss = 0.03835498281838935
Trained batch 745 in epoch 5, gen_loss = 0.4604846866297019, disc_loss = 0.03833428391548193
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.45831048488616943, disc_loss = 0.02880026027560234
Trained batch 1 in epoch 6, gen_loss = 0.4903673231601715, disc_loss = 0.14210004173219204
Trained batch 2 in epoch 6, gen_loss = 0.46808966000874835, disc_loss = 0.20495590940117836
Trained batch 3 in epoch 6, gen_loss = 0.4859667122364044, disc_loss = 0.17435707617551088
Trained batch 4 in epoch 6, gen_loss = 0.47437937259674073, disc_loss = 0.1598457731306553
Trained batch 5 in epoch 6, gen_loss = 0.47889065742492676, disc_loss = 0.13965968725581965
Trained batch 6 in epoch 6, gen_loss = 0.4711035745484488, disc_loss = 0.12560378494007246
Trained batch 7 in epoch 6, gen_loss = 0.47139493003487587, disc_loss = 0.14061045879498124
Trained batch 8 in epoch 6, gen_loss = 0.4734635916021135, disc_loss = 0.13719813318716156
Trained batch 9 in epoch 6, gen_loss = 0.4748400241136551, disc_loss = 0.12668374814093114
Trained batch 10 in epoch 6, gen_loss = 0.47440286658026953, disc_loss = 0.11837463521144607
Trained batch 11 in epoch 6, gen_loss = 0.4720621854066849, disc_loss = 0.11097228154540062
Trained batch 12 in epoch 6, gen_loss = 0.47023035242007327, disc_loss = 0.10642792828954183
Trained batch 13 in epoch 6, gen_loss = 0.47285815860543934, disc_loss = 0.10165630094707012
Trained batch 14 in epoch 6, gen_loss = 0.4709980885187785, disc_loss = 0.09541633240878582
Trained batch 15 in epoch 6, gen_loss = 0.46642367728054523, disc_loss = 0.09248079580720514
Trained batch 16 in epoch 6, gen_loss = 0.46929672360420227, disc_loss = 0.09349413511945921
Trained batch 17 in epoch 6, gen_loss = 0.4636586772070991, disc_loss = 0.09313586882005136
Trained batch 18 in epoch 6, gen_loss = 0.4629852803129899, disc_loss = 0.08879950995507993
Trained batch 19 in epoch 6, gen_loss = 0.45914071798324585, disc_loss = 0.08578075896948575
Trained batch 20 in epoch 6, gen_loss = 0.4553404180776505, disc_loss = 0.08314706819752853
Trained batch 21 in epoch 6, gen_loss = 0.4567577852444215, disc_loss = 0.08150998105041006
Trained batch 22 in epoch 6, gen_loss = 0.4561402836571569, disc_loss = 0.080907192648105
Trained batch 23 in epoch 6, gen_loss = 0.4587606576581796, disc_loss = 0.08112475904636085
Trained batch 24 in epoch 6, gen_loss = 0.46024073362350465, disc_loss = 0.08055497445166111
Trained batch 25 in epoch 6, gen_loss = 0.46138988320644087, disc_loss = 0.0783066817630942
Trained batch 26 in epoch 6, gen_loss = 0.4632632754467152, disc_loss = 0.08658427655420921
Trained batch 27 in epoch 6, gen_loss = 0.4624290700469698, disc_loss = 0.08442529550354395
Trained batch 28 in epoch 6, gen_loss = 0.45872468372871134, disc_loss = 0.08375927080111258
Trained batch 29 in epoch 6, gen_loss = 0.4612899343172709, disc_loss = 0.0821184721464912
Trained batch 30 in epoch 6, gen_loss = 0.46392002413349764, disc_loss = 0.0813365843627722
Trained batch 31 in epoch 6, gen_loss = 0.4614850403741002, disc_loss = 0.0848870049812831
Trained batch 32 in epoch 6, gen_loss = 0.4605287259275263, disc_loss = 0.09149594339683201
Trained batch 33 in epoch 6, gen_loss = 0.4602931878146003, disc_loss = 0.09445686950622235
Trained batch 34 in epoch 6, gen_loss = 0.45971647671290805, disc_loss = 0.09515274789716516
Trained batch 35 in epoch 6, gen_loss = 0.458980209297604, disc_loss = 0.0941936089657247
Trained batch 36 in epoch 6, gen_loss = 0.45913283728264476, disc_loss = 0.09260970862531984
Trained batch 37 in epoch 6, gen_loss = 0.46010973422150864, disc_loss = 0.0911883138806412
Trained batch 38 in epoch 6, gen_loss = 0.45869325750913376, disc_loss = 0.08950319976951832
Trained batch 39 in epoch 6, gen_loss = 0.4579525500535965, disc_loss = 0.08846456171013414
Trained batch 40 in epoch 6, gen_loss = 0.45821021315528127, disc_loss = 0.08687501705092628
Trained batch 41 in epoch 6, gen_loss = 0.45866326916785466, disc_loss = 0.08611906608123154
Trained batch 42 in epoch 6, gen_loss = 0.4573604083338449, disc_loss = 0.08497575709466325
Trained batch 43 in epoch 6, gen_loss = 0.4566615555774082, disc_loss = 0.08361723646521568
Trained batch 44 in epoch 6, gen_loss = 0.4572758548789554, disc_loss = 0.08230847414169047
Trained batch 45 in epoch 6, gen_loss = 0.45714840163355286, disc_loss = 0.08066523650094219
Trained batch 46 in epoch 6, gen_loss = 0.4574099062605107, disc_loss = 0.08066865825589667
Trained batch 47 in epoch 6, gen_loss = 0.458409961933891, disc_loss = 0.07991930904487769
Trained batch 48 in epoch 6, gen_loss = 0.4585449093458604, disc_loss = 0.07877399954868823
Trained batch 49 in epoch 6, gen_loss = 0.4569211459159851, disc_loss = 0.07743351303040981
Trained batch 50 in epoch 6, gen_loss = 0.45685043288212196, disc_loss = 0.07605693381571886
Trained batch 51 in epoch 6, gen_loss = 0.4571158524889212, disc_loss = 0.07520662242761599
Trained batch 52 in epoch 6, gen_loss = 0.45644138725298755, disc_loss = 0.07496836298268358
Trained batch 53 in epoch 6, gen_loss = 0.4562250353671886, disc_loss = 0.07372814620396605
Trained batch 54 in epoch 6, gen_loss = 0.4550434015013955, disc_loss = 0.07257089665667578
Trained batch 55 in epoch 6, gen_loss = 0.45565600586788996, disc_loss = 0.07208088815345295
Trained batch 56 in epoch 6, gen_loss = 0.45459312514254924, disc_loss = 0.07122804619894739
Trained batch 57 in epoch 6, gen_loss = 0.45469978965561964, disc_loss = 0.07152360578163944
Trained batch 58 in epoch 6, gen_loss = 0.45409617585650947, disc_loss = 0.07256739930707519
Trained batch 59 in epoch 6, gen_loss = 0.4544172694285711, disc_loss = 0.07199446462715665
Trained batch 60 in epoch 6, gen_loss = 0.4559494188574494, disc_loss = 0.07204801848799479
Trained batch 61 in epoch 6, gen_loss = 0.45502456686189097, disc_loss = 0.07121175209120396
Trained batch 62 in epoch 6, gen_loss = 0.45372586448987323, disc_loss = 0.0707096934673332
Trained batch 63 in epoch 6, gen_loss = 0.4526142389513552, disc_loss = 0.07055569411022589
Trained batch 64 in epoch 6, gen_loss = 0.4525450582687671, disc_loss = 0.0700755846615021
Trained batch 65 in epoch 6, gen_loss = 0.45341853165265283, disc_loss = 0.06938450800424273
Trained batch 66 in epoch 6, gen_loss = 0.45401557390369585, disc_loss = 0.06845080730185579
Trained batch 67 in epoch 6, gen_loss = 0.4543886145248133, disc_loss = 0.06756310086861692
Trained batch 68 in epoch 6, gen_loss = 0.45370225370794104, disc_loss = 0.06669022985801533
Trained batch 69 in epoch 6, gen_loss = 0.4529052721602576, disc_loss = 0.06592839850511933
Trained batch 70 in epoch 6, gen_loss = 0.45307800677460686, disc_loss = 0.06518872779413638
Trained batch 71 in epoch 6, gen_loss = 0.45318737543291515, disc_loss = 0.06450422449011563
Trained batch 72 in epoch 6, gen_loss = 0.4533492424716688, disc_loss = 0.06377610285472993
Trained batch 73 in epoch 6, gen_loss = 0.45409343613160624, disc_loss = 0.0634883789886796
Trained batch 74 in epoch 6, gen_loss = 0.4538691544532776, disc_loss = 0.06270336474602421
Trained batch 75 in epoch 6, gen_loss = 0.45351943373680115, disc_loss = 0.06196397061361686
Trained batch 76 in epoch 6, gen_loss = 0.45315816340508397, disc_loss = 0.061292257728417975
Trained batch 77 in epoch 6, gen_loss = 0.4534268165246034, disc_loss = 0.06071596830271375
Trained batch 78 in epoch 6, gen_loss = 0.4535826780373537, disc_loss = 0.06008710048479747
Trained batch 79 in epoch 6, gen_loss = 0.45393885783851146, disc_loss = 0.059630016062874346
Trained batch 80 in epoch 6, gen_loss = 0.45293028634271504, disc_loss = 0.05932757296357994
Trained batch 81 in epoch 6, gen_loss = 0.45264241099357605, disc_loss = 0.0587576550613271
Trained batch 82 in epoch 6, gen_loss = 0.4522920663816383, disc_loss = 0.058157757272472584
Trained batch 83 in epoch 6, gen_loss = 0.4530867433973721, disc_loss = 0.0578269780103472
Trained batch 84 in epoch 6, gen_loss = 0.4532760707771077, disc_loss = 0.05725065265946529
Trained batch 85 in epoch 6, gen_loss = 0.45387010484240775, disc_loss = 0.056792885498252024
Trained batch 86 in epoch 6, gen_loss = 0.45404549062937155, disc_loss = 0.056291189344449974
Trained batch 87 in epoch 6, gen_loss = 0.45485566183924675, disc_loss = 0.05593190956014124
Trained batch 88 in epoch 6, gen_loss = 0.4544736719533299, disc_loss = 0.055588264688012305
Trained batch 89 in epoch 6, gen_loss = 0.4547545628415214, disc_loss = 0.05591566293603844
Trained batch 90 in epoch 6, gen_loss = 0.4554144199732896, disc_loss = 0.05580749964484802
Trained batch 91 in epoch 6, gen_loss = 0.4558608489839927, disc_loss = 0.055897172337964825
Trained batch 92 in epoch 6, gen_loss = 0.45576892264427676, disc_loss = 0.055622333720807104
Trained batch 93 in epoch 6, gen_loss = 0.4564149820424141, disc_loss = 0.055096532426219674
Trained batch 94 in epoch 6, gen_loss = 0.4558456295414975, disc_loss = 0.05461815009383779
Trained batch 95 in epoch 6, gen_loss = 0.45658487267792225, disc_loss = 0.054111822857521474
Trained batch 96 in epoch 6, gen_loss = 0.45649577477543624, disc_loss = 0.05361432162564747
Trained batch 97 in epoch 6, gen_loss = 0.45729003937876955, disc_loss = 0.05318010084293023
Trained batch 98 in epoch 6, gen_loss = 0.4572031251107804, disc_loss = 0.05272735140728529
Trained batch 99 in epoch 6, gen_loss = 0.4574567461013794, disc_loss = 0.05232144580222666
Trained batch 100 in epoch 6, gen_loss = 0.4574263148968763, disc_loss = 0.05189912267361242
Trained batch 101 in epoch 6, gen_loss = 0.4573497932915594, disc_loss = 0.0517402707562581
Trained batch 102 in epoch 6, gen_loss = 0.4571589367482269, disc_loss = 0.051461401974185576
Trained batch 103 in epoch 6, gen_loss = 0.45800873551231164, disc_loss = 0.05103376467461483
Trained batch 104 in epoch 6, gen_loss = 0.457901558421907, disc_loss = 0.050945605470665865
Trained batch 105 in epoch 6, gen_loss = 0.4576949494064979, disc_loss = 0.05097827198475881
Trained batch 106 in epoch 6, gen_loss = 0.457815219030202, disc_loss = 0.05106325335278411
Trained batch 107 in epoch 6, gen_loss = 0.45800678459582506, disc_loss = 0.050815967109951156
Trained batch 108 in epoch 6, gen_loss = 0.45818584391830164, disc_loss = 0.05061744877197053
Trained batch 109 in epoch 6, gen_loss = 0.4588784125718203, disc_loss = 0.050295264705676926
Trained batch 110 in epoch 6, gen_loss = 0.4588939469676834, disc_loss = 0.05015951686177973
Trained batch 111 in epoch 6, gen_loss = 0.4588847527546542, disc_loss = 0.050183114154996086
Trained batch 112 in epoch 6, gen_loss = 0.459080642831009, disc_loss = 0.049838862876383075
Trained batch 113 in epoch 6, gen_loss = 0.46006047777962267, disc_loss = 0.05110071654219115
Trained batch 114 in epoch 6, gen_loss = 0.46003970581552256, disc_loss = 0.050754094180529535
Trained batch 115 in epoch 6, gen_loss = 0.4594590571419946, disc_loss = 0.05179643353993266
Trained batch 116 in epoch 6, gen_loss = 0.4605604430549165, disc_loss = 0.05200901913305379
Trained batch 117 in epoch 6, gen_loss = 0.4600891433024811, disc_loss = 0.051706406358882025
Trained batch 118 in epoch 6, gen_loss = 0.4600089996301827, disc_loss = 0.05138444351110639
Trained batch 119 in epoch 6, gen_loss = 0.4600284906725089, disc_loss = 0.051006883623388906
Trained batch 120 in epoch 6, gen_loss = 0.46028734903690244, disc_loss = 0.050870866714861275
Trained batch 121 in epoch 6, gen_loss = 0.4607712013311073, disc_loss = 0.05093702920483517
Trained batch 122 in epoch 6, gen_loss = 0.46115921789068515, disc_loss = 0.05061954257600918
Trained batch 123 in epoch 6, gen_loss = 0.46098377844018323, disc_loss = 0.05051873051260988
Trained batch 124 in epoch 6, gen_loss = 0.46116074299812315, disc_loss = 0.05016490200161934
Trained batch 125 in epoch 6, gen_loss = 0.4615977460902835, disc_loss = 0.04983298361508383
Trained batch 126 in epoch 6, gen_loss = 0.4620700607618948, disc_loss = 0.04951060002332362
Trained batch 127 in epoch 6, gen_loss = 0.4622830478474498, disc_loss = 0.04916852683527395
Trained batch 128 in epoch 6, gen_loss = 0.46188919950825297, disc_loss = 0.04905367489586505
Trained batch 129 in epoch 6, gen_loss = 0.4626220221702869, disc_loss = 0.048799230444889805
Trained batch 130 in epoch 6, gen_loss = 0.46280235370606865, disc_loss = 0.04850011999996109
Trained batch 131 in epoch 6, gen_loss = 0.46255602439244586, disc_loss = 0.04824871315169289
Trained batch 132 in epoch 6, gen_loss = 0.462486140485993, disc_loss = 0.047944791215871065
Trained batch 133 in epoch 6, gen_loss = 0.46269552876700215, disc_loss = 0.04761979457533071
Trained batch 134 in epoch 6, gen_loss = 0.4626009550359514, disc_loss = 0.04970046464974682
Trained batch 135 in epoch 6, gen_loss = 0.4622375355923877, disc_loss = 0.050304314077092224
Trained batch 136 in epoch 6, gen_loss = 0.4620965225418119, disc_loss = 0.04998731192024629
Trained batch 137 in epoch 6, gen_loss = 0.46215878578199854, disc_loss = 0.05042118053086966
Trained batch 138 in epoch 6, gen_loss = 0.4621321846255296, disc_loss = 0.05032265151803978
Trained batch 139 in epoch 6, gen_loss = 0.4622493292604174, disc_loss = 0.050364413408429495
Trained batch 140 in epoch 6, gen_loss = 0.4622767840294128, disc_loss = 0.05054194942869721
Trained batch 141 in epoch 6, gen_loss = 0.46245363627521086, disc_loss = 0.0514311574589671
Trained batch 142 in epoch 6, gen_loss = 0.4620962930726005, disc_loss = 0.051191309639545796
Trained batch 143 in epoch 6, gen_loss = 0.4622127976682451, disc_loss = 0.05198973779786482
Trained batch 144 in epoch 6, gen_loss = 0.462361104940546, disc_loss = 0.052294321823865175
Trained batch 145 in epoch 6, gen_loss = 0.46285678446292877, disc_loss = 0.05232451527302906
Trained batch 146 in epoch 6, gen_loss = 0.4631357535618503, disc_loss = 0.05307334770771618
Trained batch 147 in epoch 6, gen_loss = 0.46271948194181595, disc_loss = 0.05306692746455303
Trained batch 148 in epoch 6, gen_loss = 0.4628918052919759, disc_loss = 0.0528057905870346
Trained batch 149 in epoch 6, gen_loss = 0.46235853135585786, disc_loss = 0.052490645159656804
Trained batch 150 in epoch 6, gen_loss = 0.4623957225029042, disc_loss = 0.052220921713661474
Trained batch 151 in epoch 6, gen_loss = 0.4623126736597011, disc_loss = 0.0520453665767012
Trained batch 152 in epoch 6, gen_loss = 0.462213260480781, disc_loss = 0.052253812451061664
Trained batch 153 in epoch 6, gen_loss = 0.46205639452129216, disc_loss = 0.052020562531474926
Trained batch 154 in epoch 6, gen_loss = 0.4610058699884722, disc_loss = 0.051795240500641444
Trained batch 155 in epoch 6, gen_loss = 0.460585967088357, disc_loss = 0.05194842145264817
Trained batch 156 in epoch 6, gen_loss = 0.4605950101925309, disc_loss = 0.05208307878072759
Trained batch 157 in epoch 6, gen_loss = 0.460125823375545, disc_loss = 0.05190793180519927
Trained batch 158 in epoch 6, gen_loss = 0.4602001001999813, disc_loss = 0.05169886140644832
Trained batch 159 in epoch 6, gen_loss = 0.4603735953569412, disc_loss = 0.051841707070707344
Trained batch 160 in epoch 6, gen_loss = 0.46037902983819473, disc_loss = 0.052549542486089174
Trained batch 161 in epoch 6, gen_loss = 0.4603664345211453, disc_loss = 0.05230268052733147
Trained batch 162 in epoch 6, gen_loss = 0.46057957063423344, disc_loss = 0.05241534199302822
Trained batch 163 in epoch 6, gen_loss = 0.4603192172035938, disc_loss = 0.05229338579640792
Trained batch 164 in epoch 6, gen_loss = 0.46102533539136253, disc_loss = 0.05295511080855222
Trained batch 165 in epoch 6, gen_loss = 0.46071193519845066, disc_loss = 0.05282429772631142
Trained batch 166 in epoch 6, gen_loss = 0.46038527385203426, disc_loss = 0.0533076821502945
Trained batch 167 in epoch 6, gen_loss = 0.460965098547084, disc_loss = 0.05310155888963934
Trained batch 168 in epoch 6, gen_loss = 0.46053930182428754, disc_loss = 0.05307826638695668
Trained batch 169 in epoch 6, gen_loss = 0.4604018132476246, disc_loss = 0.053557231679887456
Trained batch 170 in epoch 6, gen_loss = 0.4601043361669395, disc_loss = 0.05335674470573751
Trained batch 171 in epoch 6, gen_loss = 0.4601706302789755, disc_loss = 0.05327303106300966
Trained batch 172 in epoch 6, gen_loss = 0.4603369570191885, disc_loss = 0.05327320060924212
Trained batch 173 in epoch 6, gen_loss = 0.4601877938056814, disc_loss = 0.05301679560818292
Trained batch 174 in epoch 6, gen_loss = 0.46033744999340603, disc_loss = 0.053107312718140225
Trained batch 175 in epoch 6, gen_loss = 0.4601109986278144, disc_loss = 0.05284649136063473
Trained batch 176 in epoch 6, gen_loss = 0.4597038113127994, disc_loss = 0.052988639430242915
Trained batch 177 in epoch 6, gen_loss = 0.45967874918760876, disc_loss = 0.05275786254984023
Trained batch 178 in epoch 6, gen_loss = 0.45923394281104957, disc_loss = 0.05299608169290024
Trained batch 179 in epoch 6, gen_loss = 0.4593151733279228, disc_loss = 0.0529740931181651
Trained batch 180 in epoch 6, gen_loss = 0.4591958099636584, disc_loss = 0.052734023096420654
Trained batch 181 in epoch 6, gen_loss = 0.4591735824123844, disc_loss = 0.052843496738165456
Trained batch 182 in epoch 6, gen_loss = 0.4588561155756966, disc_loss = 0.05264952976531426
Trained batch 183 in epoch 6, gen_loss = 0.4588553254371104, disc_loss = 0.0525524482439758
Trained batch 184 in epoch 6, gen_loss = 0.4586719376009864, disc_loss = 0.05233958271155889
Trained batch 185 in epoch 6, gen_loss = 0.4584755428055281, disc_loss = 0.052114634712036416
Trained batch 186 in epoch 6, gen_loss = 0.4586754772752364, disc_loss = 0.05200381013988094
Trained batch 187 in epoch 6, gen_loss = 0.45875766112449323, disc_loss = 0.05177395986739863
Trained batch 188 in epoch 6, gen_loss = 0.458901410695737, disc_loss = 0.05162019822401581
Trained batch 189 in epoch 6, gen_loss = 0.4582891490898634, disc_loss = 0.051986800837575606
Trained batch 190 in epoch 6, gen_loss = 0.45834107829638177, disc_loss = 0.05202517954691152
Trained batch 191 in epoch 6, gen_loss = 0.45820679763952893, disc_loss = 0.051872793844571184
Trained batch 192 in epoch 6, gen_loss = 0.45796342912115584, disc_loss = 0.05168424623202861
Trained batch 193 in epoch 6, gen_loss = 0.45820469109667944, disc_loss = 0.05152158373150706
Trained batch 194 in epoch 6, gen_loss = 0.4578674748922006, disc_loss = 0.051384779861053595
Trained batch 195 in epoch 6, gen_loss = 0.45796055316316836, disc_loss = 0.051152563665765434
Trained batch 196 in epoch 6, gen_loss = 0.45778749119206735, disc_loss = 0.05095236605922053
Trained batch 197 in epoch 6, gen_loss = 0.45825398073653983, disc_loss = 0.050767393140686734
Trained batch 198 in epoch 6, gen_loss = 0.45781746237122234, disc_loss = 0.050894493075677345
Trained batch 199 in epoch 6, gen_loss = 0.4584442375600338, disc_loss = 0.05103475814452395
Trained batch 200 in epoch 6, gen_loss = 0.45828340154382124, disc_loss = 0.050825787696579645
Trained batch 201 in epoch 6, gen_loss = 0.45807740844712397, disc_loss = 0.05083033877498664
Trained batch 202 in epoch 6, gen_loss = 0.4578687868682034, disc_loss = 0.050752544965998736
Trained batch 203 in epoch 6, gen_loss = 0.45811160405476886, disc_loss = 0.050874447703416294
Trained batch 204 in epoch 6, gen_loss = 0.4582112902548255, disc_loss = 0.05068399798715623
Trained batch 205 in epoch 6, gen_loss = 0.45853447624780597, disc_loss = 0.050704877947918274
Trained batch 206 in epoch 6, gen_loss = 0.4583031106110356, disc_loss = 0.050889596106835466
Trained batch 207 in epoch 6, gen_loss = 0.4577927917528611, disc_loss = 0.05072664651939144
Trained batch 208 in epoch 6, gen_loss = 0.4581200219512556, disc_loss = 0.05051481090352367
Trained batch 209 in epoch 6, gen_loss = 0.4586494296789169, disc_loss = 0.05035889645639275
Trained batch 210 in epoch 6, gen_loss = 0.4587045238481314, disc_loss = 0.05014163222808338
Trained batch 211 in epoch 6, gen_loss = 0.45861327549758946, disc_loss = 0.04993579525913481
Trained batch 212 in epoch 6, gen_loss = 0.4590746918474565, disc_loss = 0.04985410914026166
Trained batch 213 in epoch 6, gen_loss = 0.45854295191363753, disc_loss = 0.0497880637380251
Trained batch 214 in epoch 6, gen_loss = 0.4583003659581029, disc_loss = 0.05027902328820769
Trained batch 215 in epoch 6, gen_loss = 0.45861586459256987, disc_loss = 0.050124429638445794
Trained batch 216 in epoch 6, gen_loss = 0.45854615698212303, disc_loss = 0.05003489889333256
Trained batch 217 in epoch 6, gen_loss = 0.4590126240472181, disc_loss = 0.04999398087031729
Trained batch 218 in epoch 6, gen_loss = 0.4588575116847748, disc_loss = 0.050039155661770605
Trained batch 219 in epoch 6, gen_loss = 0.45841426293958315, disc_loss = 0.05005882510026409
Trained batch 220 in epoch 6, gen_loss = 0.45854978189209467, disc_loss = 0.050048323025783666
Trained batch 221 in epoch 6, gen_loss = 0.4583555936544865, disc_loss = 0.04998978746526346
Trained batch 222 in epoch 6, gen_loss = 0.4582740938449654, disc_loss = 0.05049454787278322
Trained batch 223 in epoch 6, gen_loss = 0.4579906950571707, disc_loss = 0.050417077417867925
Trained batch 224 in epoch 6, gen_loss = 0.45789619432555306, disc_loss = 0.050829140434248576
Trained batch 225 in epoch 6, gen_loss = 0.45810026128207687, disc_loss = 0.05074829752227308
Trained batch 226 in epoch 6, gen_loss = 0.45824075966154426, disc_loss = 0.05085254508780422
Trained batch 227 in epoch 6, gen_loss = 0.4583080792636202, disc_loss = 0.05087795748024068
Trained batch 228 in epoch 6, gen_loss = 0.45835593954444454, disc_loss = 0.05069518539704805
Trained batch 229 in epoch 6, gen_loss = 0.4580585123404213, disc_loss = 0.05069398351783014
Trained batch 230 in epoch 6, gen_loss = 0.4577548336157035, disc_loss = 0.05084158770248165
Trained batch 231 in epoch 6, gen_loss = 0.45794261298302946, disc_loss = 0.050663726667247326
Trained batch 232 in epoch 6, gen_loss = 0.45826254356572554, disc_loss = 0.05065181524224995
Trained batch 233 in epoch 6, gen_loss = 0.458078508448397, disc_loss = 0.0507915911411978
Trained batch 234 in epoch 6, gen_loss = 0.45787845672445093, disc_loss = 0.05073258164041537
Trained batch 235 in epoch 6, gen_loss = 0.4580984918747918, disc_loss = 0.05064486710441504
Trained batch 236 in epoch 6, gen_loss = 0.458148499455633, disc_loss = 0.05060237867537619
Trained batch 237 in epoch 6, gen_loss = 0.4582141940834142, disc_loss = 0.050476696481145604
Trained batch 238 in epoch 6, gen_loss = 0.4579453217683976, disc_loss = 0.05063106919050404
Trained batch 239 in epoch 6, gen_loss = 0.4578396055847406, disc_loss = 0.05047216094681062
Trained batch 240 in epoch 6, gen_loss = 0.45791693705740805, disc_loss = 0.050337063672245164
Trained batch 241 in epoch 6, gen_loss = 0.458004026619856, disc_loss = 0.050159000083496254
Trained batch 242 in epoch 6, gen_loss = 0.45759619533279794, disc_loss = 0.05000455024433725
Trained batch 243 in epoch 6, gen_loss = 0.45752834870678477, disc_loss = 0.04981874323595071
Trained batch 244 in epoch 6, gen_loss = 0.45763685508650176, disc_loss = 0.04971838930469691
Trained batch 245 in epoch 6, gen_loss = 0.45818478426313014, disc_loss = 0.049541963917407686
Trained batch 246 in epoch 6, gen_loss = 0.4580651823325678, disc_loss = 0.049403270866782194
Trained batch 247 in epoch 6, gen_loss = 0.45822513968713824, disc_loss = 0.0493599577344984
Trained batch 248 in epoch 6, gen_loss = 0.458215898419001, disc_loss = 0.04919894647982764
Trained batch 249 in epoch 6, gen_loss = 0.4582123445272446, disc_loss = 0.04906402916647494
Trained batch 250 in epoch 6, gen_loss = 0.4584181609144249, disc_loss = 0.048932993571196064
Trained batch 251 in epoch 6, gen_loss = 0.4586474643576713, disc_loss = 0.0487749545653868
Trained batch 252 in epoch 6, gen_loss = 0.4587595360316778, disc_loss = 0.04864697240609602
Trained batch 253 in epoch 6, gen_loss = 0.45856957818110156, disc_loss = 0.048547396265835624
Trained batch 254 in epoch 6, gen_loss = 0.4586011226270713, disc_loss = 0.048406614554936396
Trained batch 255 in epoch 6, gen_loss = 0.458299849065952, disc_loss = 0.04844918826893263
Trained batch 256 in epoch 6, gen_loss = 0.45814190880333866, disc_loss = 0.048540144725720824
Trained batch 257 in epoch 6, gen_loss = 0.458099043762037, disc_loss = 0.04880508977031812
Trained batch 258 in epoch 6, gen_loss = 0.45809103830440623, disc_loss = 0.04884271900633415
Trained batch 259 in epoch 6, gen_loss = 0.4582513936437093, disc_loss = 0.048905134847602595
Trained batch 260 in epoch 6, gen_loss = 0.45801539325166024, disc_loss = 0.04874053809228014
Trained batch 261 in epoch 6, gen_loss = 0.4579304710371804, disc_loss = 0.048923700342296074
Trained batch 262 in epoch 6, gen_loss = 0.45769966725160866, disc_loss = 0.04876455572387735
Trained batch 263 in epoch 6, gen_loss = 0.45751856978644023, disc_loss = 0.048896674022685285
Trained batch 264 in epoch 6, gen_loss = 0.45711765705414537, disc_loss = 0.04886625629656439
Trained batch 265 in epoch 6, gen_loss = 0.457209029255953, disc_loss = 0.04905626352673354
Trained batch 266 in epoch 6, gen_loss = 0.4573609697238336, disc_loss = 0.04893164779495601
Trained batch 267 in epoch 6, gen_loss = 0.4570396953999107, disc_loss = 0.048823339035804034
Trained batch 268 in epoch 6, gen_loss = 0.45707546113592096, disc_loss = 0.04961059636308303
Trained batch 269 in epoch 6, gen_loss = 0.45677189539980007, disc_loss = 0.04960822074467109
Trained batch 270 in epoch 6, gen_loss = 0.4567547284369099, disc_loss = 0.04956780638497639
Trained batch 271 in epoch 6, gen_loss = 0.4567553407567389, disc_loss = 0.04949060973184019
Trained batch 272 in epoch 6, gen_loss = 0.45658462672006517, disc_loss = 0.049347472754085346
Trained batch 273 in epoch 6, gen_loss = 0.4567809737946865, disc_loss = 0.049373282648174324
Trained batch 274 in epoch 6, gen_loss = 0.45646576989780774, disc_loss = 0.04962050367316062
Trained batch 275 in epoch 6, gen_loss = 0.4563941317407981, disc_loss = 0.04952572507318109
Trained batch 276 in epoch 6, gen_loss = 0.4568035323912486, disc_loss = 0.049651835286915844
Trained batch 277 in epoch 6, gen_loss = 0.45673436687575825, disc_loss = 0.04969148351073855
Trained batch 278 in epoch 6, gen_loss = 0.4564487059270182, disc_loss = 0.04957634186385513
Trained batch 279 in epoch 6, gen_loss = 0.4564865019704614, disc_loss = 0.04952649939638962
Trained batch 280 in epoch 6, gen_loss = 0.45646559640606105, disc_loss = 0.04960416631070479
Trained batch 281 in epoch 6, gen_loss = 0.45669979998405946, disc_loss = 0.05051577098978063
Trained batch 282 in epoch 6, gen_loss = 0.4563946236359357, disc_loss = 0.050545031315064576
Trained batch 283 in epoch 6, gen_loss = 0.45635932631475823, disc_loss = 0.050516933817613185
Trained batch 284 in epoch 6, gen_loss = 0.4559782416151281, disc_loss = 0.0506953729725067
Trained batch 285 in epoch 6, gen_loss = 0.45575682568800197, disc_loss = 0.051030880437799166
Trained batch 286 in epoch 6, gen_loss = 0.45532618800522145, disc_loss = 0.05177071891588772
Trained batch 287 in epoch 6, gen_loss = 0.4551393969191445, disc_loss = 0.051940264864242636
Trained batch 288 in epoch 6, gen_loss = 0.4549581327034115, disc_loss = 0.05199495698953737
Trained batch 289 in epoch 6, gen_loss = 0.45471690995939845, disc_loss = 0.052051443900463394
Trained batch 290 in epoch 6, gen_loss = 0.4546092410677487, disc_loss = 0.051942800902969544
Trained batch 291 in epoch 6, gen_loss = 0.4547851898082315, disc_loss = 0.05197724636025369
Trained batch 292 in epoch 6, gen_loss = 0.4547723228614078, disc_loss = 0.05231016551211171
Trained batch 293 in epoch 6, gen_loss = 0.45456674482141224, disc_loss = 0.05231851068021236
Trained batch 294 in epoch 6, gen_loss = 0.454345655542309, disc_loss = 0.05222887587338938
Trained batch 295 in epoch 6, gen_loss = 0.45440112004006233, disc_loss = 0.052173497367688025
Trained batch 296 in epoch 6, gen_loss = 0.45425061605594774, disc_loss = 0.05225687555385509
Trained batch 297 in epoch 6, gen_loss = 0.45392087952002586, disc_loss = 0.05220743338577449
Trained batch 298 in epoch 6, gen_loss = 0.45386586859074723, disc_loss = 0.0524022759835432
Trained batch 299 in epoch 6, gen_loss = 0.45394665122032163, disc_loss = 0.05230291712253044
Trained batch 300 in epoch 6, gen_loss = 0.45420314703272824, disc_loss = 0.052317880358596476
Trained batch 301 in epoch 6, gen_loss = 0.4540469054354737, disc_loss = 0.052346321111174904
Trained batch 302 in epoch 6, gen_loss = 0.45407145153177847, disc_loss = 0.0521964010284605
Trained batch 303 in epoch 6, gen_loss = 0.45422952955490664, disc_loss = 0.05216674327292774
Trained batch 304 in epoch 6, gen_loss = 0.454160994193593, disc_loss = 0.05203892468459538
Trained batch 305 in epoch 6, gen_loss = 0.4543606551254497, disc_loss = 0.05189925735798098
Trained batch 306 in epoch 6, gen_loss = 0.4543838552426826, disc_loss = 0.0518023415244145
Trained batch 307 in epoch 6, gen_loss = 0.4544049926198922, disc_loss = 0.05184180104300718
Trained batch 308 in epoch 6, gen_loss = 0.4546070595582326, disc_loss = 0.05170733116802226
Trained batch 309 in epoch 6, gen_loss = 0.4546427136467349, disc_loss = 0.0517780713421563
Trained batch 310 in epoch 6, gen_loss = 0.4547887902551142, disc_loss = 0.051704172067451995
Trained batch 311 in epoch 6, gen_loss = 0.45506268873428685, disc_loss = 0.05178564914520113
Trained batch 312 in epoch 6, gen_loss = 0.4548650876211282, disc_loss = 0.05179692244085784
Trained batch 313 in epoch 6, gen_loss = 0.4549460160504481, disc_loss = 0.051721987028303704
Trained batch 314 in epoch 6, gen_loss = 0.4551202919748094, disc_loss = 0.0516310214981555
Trained batch 315 in epoch 6, gen_loss = 0.45515824580871606, disc_loss = 0.051516129825370315
Trained batch 316 in epoch 6, gen_loss = 0.45508928310231833, disc_loss = 0.05154427148149075
Trained batch 317 in epoch 6, gen_loss = 0.4549123256836297, disc_loss = 0.0518139020654039
Trained batch 318 in epoch 6, gen_loss = 0.4549564636986831, disc_loss = 0.05172433732894941
Trained batch 319 in epoch 6, gen_loss = 0.4549449345096946, disc_loss = 0.05165607977687614
Trained batch 320 in epoch 6, gen_loss = 0.4548587895628077, disc_loss = 0.051540982774589385
Trained batch 321 in epoch 6, gen_loss = 0.4547509098460215, disc_loss = 0.051455644088051054
Trained batch 322 in epoch 6, gen_loss = 0.4547825229610821, disc_loss = 0.051402470006120186
Trained batch 323 in epoch 6, gen_loss = 0.45495691610339245, disc_loss = 0.05130563237859557
Trained batch 324 in epoch 6, gen_loss = 0.45490239730248083, disc_loss = 0.05122945634934765
Trained batch 325 in epoch 6, gen_loss = 0.4549912986762685, disc_loss = 0.051124186513579785
Trained batch 326 in epoch 6, gen_loss = 0.4548088179998077, disc_loss = 0.05126786851879517
Trained batch 327 in epoch 6, gen_loss = 0.454867795745774, disc_loss = 0.05119290558490675
Trained batch 328 in epoch 6, gen_loss = 0.4548072651889187, disc_loss = 0.051218937245964734
Trained batch 329 in epoch 6, gen_loss = 0.4545991785598524, disc_loss = 0.051193909066249474
Trained batch 330 in epoch 6, gen_loss = 0.4545270254964915, disc_loss = 0.05111839025903189
Trained batch 331 in epoch 6, gen_loss = 0.454355936721865, disc_loss = 0.05107693223939109
Trained batch 332 in epoch 6, gen_loss = 0.45451288457747335, disc_loss = 0.05112828260746312
Trained batch 333 in epoch 6, gen_loss = 0.45471940274367073, disc_loss = 0.05150253481990072
Trained batch 334 in epoch 6, gen_loss = 0.45453256226297634, disc_loss = 0.05191939313159283
Trained batch 335 in epoch 6, gen_loss = 0.45432295295454206, disc_loss = 0.05189565914112054
Trained batch 336 in epoch 6, gen_loss = 0.4543824052598427, disc_loss = 0.05184881767335428
Trained batch 337 in epoch 6, gen_loss = 0.45427463657757233, disc_loss = 0.05186256016990357
Trained batch 338 in epoch 6, gen_loss = 0.4544760569006996, disc_loss = 0.05184241812978391
Trained batch 339 in epoch 6, gen_loss = 0.45458408900920083, disc_loss = 0.051716231309589654
Trained batch 340 in epoch 6, gen_loss = 0.4543694979634103, disc_loss = 0.05211246408702385
Trained batch 341 in epoch 6, gen_loss = 0.4544751061159268, disc_loss = 0.051987247041845965
Trained batch 342 in epoch 6, gen_loss = 0.4544787430380941, disc_loss = 0.05207535252110821
Trained batch 343 in epoch 6, gen_loss = 0.4544734061630659, disc_loss = 0.05198827658395478
Trained batch 344 in epoch 6, gen_loss = 0.45452392023542654, disc_loss = 0.05196952211495111
Trained batch 345 in epoch 6, gen_loss = 0.4541495000523639, disc_loss = 0.05210835112641011
Trained batch 346 in epoch 6, gen_loss = 0.4539997231548045, disc_loss = 0.05201592598706269
Trained batch 347 in epoch 6, gen_loss = 0.45408830654689636, disc_loss = 0.05215503197918036
Trained batch 348 in epoch 6, gen_loss = 0.45417304623092825, disc_loss = 0.052163233629622656
Trained batch 349 in epoch 6, gen_loss = 0.45404210456780025, disc_loss = 0.05203817143903247
Trained batch 350 in epoch 6, gen_loss = 0.45442854534526833, disc_loss = 0.05197219492103427
Trained batch 351 in epoch 6, gen_loss = 0.4544365788725289, disc_loss = 0.05200628018594051
Trained batch 352 in epoch 6, gen_loss = 0.45462658216190066, disc_loss = 0.051919741681368
Trained batch 353 in epoch 6, gen_loss = 0.4546282425270242, disc_loss = 0.0518122137390014
Trained batch 354 in epoch 6, gen_loss = 0.4548000182064486, disc_loss = 0.05168425502308028
Trained batch 355 in epoch 6, gen_loss = 0.4547497624259316, disc_loss = 0.051585906275464326
Trained batch 356 in epoch 6, gen_loss = 0.45493677725978926, disc_loss = 0.05152196782648939
Trained batch 357 in epoch 6, gen_loss = 0.45496655434536537, disc_loss = 0.05144874848472215
Trained batch 358 in epoch 6, gen_loss = 0.4550451140715883, disc_loss = 0.05156311279806129
Trained batch 359 in epoch 6, gen_loss = 0.45488208788964485, disc_loss = 0.05165156443836168
Trained batch 360 in epoch 6, gen_loss = 0.4548992927384839, disc_loss = 0.05155362680146775
Trained batch 361 in epoch 6, gen_loss = 0.45489395208121663, disc_loss = 0.05147694071976067
Trained batch 362 in epoch 6, gen_loss = 0.45492340209727117, disc_loss = 0.05149071752003936
Trained batch 363 in epoch 6, gen_loss = 0.4549209854596264, disc_loss = 0.05140651655664852
Trained batch 364 in epoch 6, gen_loss = 0.45481567039881665, disc_loss = 0.05134612995595352
Trained batch 365 in epoch 6, gen_loss = 0.454890887268254, disc_loss = 0.05131953073375416
Trained batch 366 in epoch 6, gen_loss = 0.4548668704663051, disc_loss = 0.051239712408690505
Trained batch 367 in epoch 6, gen_loss = 0.4545863853038653, disc_loss = 0.05115055373449729
Trained batch 368 in epoch 6, gen_loss = 0.4546112875305217, disc_loss = 0.05104792173724712
Trained batch 369 in epoch 6, gen_loss = 0.4545158635120134, disc_loss = 0.050981787673977985
Trained batch 370 in epoch 6, gen_loss = 0.45461192052319366, disc_loss = 0.050885831150213744
Trained batch 371 in epoch 6, gen_loss = 0.45469959649027036, disc_loss = 0.0507670101917459
Trained batch 372 in epoch 6, gen_loss = 0.4547614453625104, disc_loss = 0.050667287673221914
Trained batch 373 in epoch 6, gen_loss = 0.4548861889596929, disc_loss = 0.05064204908573731
Trained batch 374 in epoch 6, gen_loss = 0.45485382262865703, disc_loss = 0.050531350345661245
Trained batch 375 in epoch 6, gen_loss = 0.4547860862568338, disc_loss = 0.05046579817017699
Trained batch 376 in epoch 6, gen_loss = 0.45492417956220693, disc_loss = 0.05036218923983468
Trained batch 377 in epoch 6, gen_loss = 0.4550504160148126, disc_loss = 0.05026691094183772
Trained batch 378 in epoch 6, gen_loss = 0.454888372355212, disc_loss = 0.05014931053871726
Trained batch 379 in epoch 6, gen_loss = 0.4549394643620441, disc_loss = 0.05012532000209352
Trained batch 380 in epoch 6, gen_loss = 0.45502891768933595, disc_loss = 0.05003408742384139
Trained batch 381 in epoch 6, gen_loss = 0.4551547615940034, disc_loss = 0.04991545923619838
Trained batch 382 in epoch 6, gen_loss = 0.45495315569187894, disc_loss = 0.049795242100613625
Trained batch 383 in epoch 6, gen_loss = 0.4551776259516676, disc_loss = 0.04969739679775861
Trained batch 384 in epoch 6, gen_loss = 0.45484461033499085, disc_loss = 0.04961377810082072
Trained batch 385 in epoch 6, gen_loss = 0.4548499732437529, disc_loss = 0.049556425030685844
Trained batch 386 in epoch 6, gen_loss = 0.45476147563266506, disc_loss = 0.04951602263491629
Trained batch 387 in epoch 6, gen_loss = 0.4546409531198826, disc_loss = 0.049568261765183634
Trained batch 388 in epoch 6, gen_loss = 0.4545853376235324, disc_loss = 0.04962830510407035
Trained batch 389 in epoch 6, gen_loss = 0.45459840702704896, disc_loss = 0.04951887422790512
Trained batch 390 in epoch 6, gen_loss = 0.45456249360233314, disc_loss = 0.049462819760165096
Trained batch 391 in epoch 6, gen_loss = 0.4545321418162511, disc_loss = 0.049364529875563265
Trained batch 392 in epoch 6, gen_loss = 0.45461904752345483, disc_loss = 0.049258574651454695
Trained batch 393 in epoch 6, gen_loss = 0.4547654527244229, disc_loss = 0.049265009504719286
Trained batch 394 in epoch 6, gen_loss = 0.4548371932174586, disc_loss = 0.04917727071980509
Trained batch 395 in epoch 6, gen_loss = 0.4548760565994966, disc_loss = 0.04906716056384447
Trained batch 396 in epoch 6, gen_loss = 0.45479542264710143, disc_loss = 0.048955896163185686
Trained batch 397 in epoch 6, gen_loss = 0.4547394544784747, disc_loss = 0.04887940958563482
Trained batch 398 in epoch 6, gen_loss = 0.45473875086707877, disc_loss = 0.0487714631980131
Trained batch 399 in epoch 6, gen_loss = 0.4548535328358412, disc_loss = 0.04866730919689871
Trained batch 400 in epoch 6, gen_loss = 0.4549710726054232, disc_loss = 0.048567232191609105
Trained batch 401 in epoch 6, gen_loss = 0.455126625462551, disc_loss = 0.04845660349785058
Trained batch 402 in epoch 6, gen_loss = 0.4549761298424553, disc_loss = 0.04836561151250975
Trained batch 403 in epoch 6, gen_loss = 0.4549793976515827, disc_loss = 0.0482643083358036
Trained batch 404 in epoch 6, gen_loss = 0.4547914764027537, disc_loss = 0.048186895841111736
Trained batch 405 in epoch 6, gen_loss = 0.4548704423781099, disc_loss = 0.048084758273715826
Trained batch 406 in epoch 6, gen_loss = 0.45477101690060384, disc_loss = 0.047984714465357674
Trained batch 407 in epoch 6, gen_loss = 0.45482337452909527, disc_loss = 0.04789001902442097
Trained batch 408 in epoch 6, gen_loss = 0.4548512679731933, disc_loss = 0.04778396875955037
Trained batch 409 in epoch 6, gen_loss = 0.455001876121614, disc_loss = 0.04767890738595913
Trained batch 410 in epoch 6, gen_loss = 0.4552380973405212, disc_loss = 0.04757739047445085
Trained batch 411 in epoch 6, gen_loss = 0.455373171029739, disc_loss = 0.04751391131069186
Trained batch 412 in epoch 6, gen_loss = 0.45534832180267965, disc_loss = 0.04742494089975412
Trained batch 413 in epoch 6, gen_loss = 0.45544854072844926, disc_loss = 0.0473570887039861
Trained batch 414 in epoch 6, gen_loss = 0.4554404582603868, disc_loss = 0.04726640897836671
Trained batch 415 in epoch 6, gen_loss = 0.4555239961124383, disc_loss = 0.04717087153515492
Trained batch 416 in epoch 6, gen_loss = 0.4555441652127593, disc_loss = 0.047082284025454835
Trained batch 417 in epoch 6, gen_loss = 0.45575242928055487, disc_loss = 0.047062075846164564
Trained batch 418 in epoch 6, gen_loss = 0.4557516303864754, disc_loss = 0.046962719507346505
Trained batch 419 in epoch 6, gen_loss = 0.4556289899916876, disc_loss = 0.04689802165431459
Trained batch 420 in epoch 6, gen_loss = 0.4554622037393747, disc_loss = 0.0467962381914435
Trained batch 421 in epoch 6, gen_loss = 0.45536289247573836, disc_loss = 0.0467193739100302
Trained batch 422 in epoch 6, gen_loss = 0.4555324712684532, disc_loss = 0.046648957460555064
Trained batch 423 in epoch 6, gen_loss = 0.45562046513242543, disc_loss = 0.04655173732591617
Trained batch 424 in epoch 6, gen_loss = 0.45554684582878563, disc_loss = 0.04645648901296012
Trained batch 425 in epoch 6, gen_loss = 0.455522895558899, disc_loss = 0.046383433874713983
Trained batch 426 in epoch 6, gen_loss = 0.455600127822063, disc_loss = 0.04630227475939646
Trained batch 427 in epoch 6, gen_loss = 0.4554448101286576, disc_loss = 0.04621244774191318
Trained batch 428 in epoch 6, gen_loss = 0.45559816524421143, disc_loss = 0.04611821590525495
Trained batch 429 in epoch 6, gen_loss = 0.4558572460052579, disc_loss = 0.0460270271614887
Trained batch 430 in epoch 6, gen_loss = 0.4559351723736234, disc_loss = 0.045929846215535065
Trained batch 431 in epoch 6, gen_loss = 0.4559126921274044, disc_loss = 0.04587346056467612
Trained batch 432 in epoch 6, gen_loss = 0.4559061939529128, disc_loss = 0.04578627738241304
Trained batch 433 in epoch 6, gen_loss = 0.4560563102158533, disc_loss = 0.04569969967668576
Trained batch 434 in epoch 6, gen_loss = 0.45599992720560095, disc_loss = 0.04560280842760085
Trained batch 435 in epoch 6, gen_loss = 0.45611227481463634, disc_loss = 0.04551381177168527
Trained batch 436 in epoch 6, gen_loss = 0.45616583584102394, disc_loss = 0.045500055171263744
Trained batch 437 in epoch 6, gen_loss = 0.4562361875897673, disc_loss = 0.04542714645543888
Trained batch 438 in epoch 6, gen_loss = 0.455921057077095, disc_loss = 0.045380509989378565
Trained batch 439 in epoch 6, gen_loss = 0.4558605017309839, disc_loss = 0.04529206725842828
Trained batch 440 in epoch 6, gen_loss = 0.45602351717667783, disc_loss = 0.04520113360033267
Trained batch 441 in epoch 6, gen_loss = 0.4560790517076648, disc_loss = 0.04511435103668027
Trained batch 442 in epoch 6, gen_loss = 0.4559360033502428, disc_loss = 0.04502471230354404
Trained batch 443 in epoch 6, gen_loss = 0.45598632043546383, disc_loss = 0.04493510132384915
Trained batch 444 in epoch 6, gen_loss = 0.45600212142708596, disc_loss = 0.04485469252404788
Trained batch 445 in epoch 6, gen_loss = 0.4561184237088858, disc_loss = 0.044774687249159166
Trained batch 446 in epoch 6, gen_loss = 0.4560920294099206, disc_loss = 0.04477887272040966
Trained batch 447 in epoch 6, gen_loss = 0.4561204354145697, disc_loss = 0.04470886849022853
Trained batch 448 in epoch 6, gen_loss = 0.4562399105930116, disc_loss = 0.044696353518514
Trained batch 449 in epoch 6, gen_loss = 0.4562116362651189, disc_loss = 0.0449910251232278
Trained batch 450 in epoch 6, gen_loss = 0.45608985523162554, disc_loss = 0.045335730427810035
Trained batch 451 in epoch 6, gen_loss = 0.4559961986620869, disc_loss = 0.045412679550555266
Trained batch 452 in epoch 6, gen_loss = 0.45578643594093404, disc_loss = 0.04542182648408476
Trained batch 453 in epoch 6, gen_loss = 0.4557883606870794, disc_loss = 0.045462088628122295
Trained batch 454 in epoch 6, gen_loss = 0.4559461094520904, disc_loss = 0.045480050107177636
Trained batch 455 in epoch 6, gen_loss = 0.45583477315672655, disc_loss = 0.045410830371812996
Trained batch 456 in epoch 6, gen_loss = 0.45574978320029946, disc_loss = 0.04536348710466315
Trained batch 457 in epoch 6, gen_loss = 0.45573331200920336, disc_loss = 0.04528204576309575
Trained batch 458 in epoch 6, gen_loss = 0.45564765309456384, disc_loss = 0.04522042867751926
Trained batch 459 in epoch 6, gen_loss = 0.4557199604485346, disc_loss = 0.04515384433173534
Trained batch 460 in epoch 6, gen_loss = 0.4557729284571981, disc_loss = 0.04512006454846525
Trained batch 461 in epoch 6, gen_loss = 0.45568226445546917, disc_loss = 0.04513247549741477
Trained batch 462 in epoch 6, gen_loss = 0.4555428514084085, disc_loss = 0.04509366858000294
Trained batch 463 in epoch 6, gen_loss = 0.4555676193458253, disc_loss = 0.04503728373825213
Trained batch 464 in epoch 6, gen_loss = 0.45567750373194293, disc_loss = 0.04505437308852311
Trained batch 465 in epoch 6, gen_loss = 0.45560493687959186, disc_loss = 0.04513393448767664
Trained batch 466 in epoch 6, gen_loss = 0.45549571648144366, disc_loss = 0.045510007183683726
Trained batch 467 in epoch 6, gen_loss = 0.45543381259736854, disc_loss = 0.045523083640927144
Trained batch 468 in epoch 6, gen_loss = 0.45549633527107075, disc_loss = 0.045612362711362715
Trained batch 469 in epoch 6, gen_loss = 0.4554474250433293, disc_loss = 0.04558008156191716
Trained batch 470 in epoch 6, gen_loss = 0.4554481076713327, disc_loss = 0.04552038142807592
Trained batch 471 in epoch 6, gen_loss = 0.45562540556667214, disc_loss = 0.04546354989613943
Trained batch 472 in epoch 6, gen_loss = 0.4557357874657589, disc_loss = 0.04554777933396872
Trained batch 473 in epoch 6, gen_loss = 0.45568472385909486, disc_loss = 0.04569447882235726
Trained batch 474 in epoch 6, gen_loss = 0.45559446052501074, disc_loss = 0.04563328963704407
Trained batch 475 in epoch 6, gen_loss = 0.45538949396680384, disc_loss = 0.04572653098515149
Trained batch 476 in epoch 6, gen_loss = 0.4554829341310625, disc_loss = 0.04570812898672399
Trained batch 477 in epoch 6, gen_loss = 0.4552974940343881, disc_loss = 0.04563408053068982
Trained batch 478 in epoch 6, gen_loss = 0.4553063337016454, disc_loss = 0.045573144544028756
Trained batch 479 in epoch 6, gen_loss = 0.4553826718280713, disc_loss = 0.04550368215762622
Trained batch 480 in epoch 6, gen_loss = 0.4553584360407197, disc_loss = 0.045498235630870576
Trained batch 481 in epoch 6, gen_loss = 0.4555328341811524, disc_loss = 0.04544762630523781
Trained batch 482 in epoch 6, gen_loss = 0.45565999732748075, disc_loss = 0.04552069214157236
Trained batch 483 in epoch 6, gen_loss = 0.45554401565435504, disc_loss = 0.04566125713687098
Trained batch 484 in epoch 6, gen_loss = 0.4555237074488217, disc_loss = 0.04559134250631575
Trained batch 485 in epoch 6, gen_loss = 0.45534731208542245, disc_loss = 0.045519400209307274
Trained batch 486 in epoch 6, gen_loss = 0.45548231694732605, disc_loss = 0.04545826162498452
Trained batch 487 in epoch 6, gen_loss = 0.4554011707545304, disc_loss = 0.04543014900276025
Trained batch 488 in epoch 6, gen_loss = 0.4552889179842116, disc_loss = 0.04535554768565227
Trained batch 489 in epoch 6, gen_loss = 0.45525959085445017, disc_loss = 0.045311420781024715
Trained batch 490 in epoch 6, gen_loss = 0.45534183798156785, disc_loss = 0.045273331012444046
Trained batch 491 in epoch 6, gen_loss = 0.4555040037607759, disc_loss = 0.04522487159006343
Trained batch 492 in epoch 6, gen_loss = 0.45569233544941606, disc_loss = 0.04515759520842854
Trained batch 493 in epoch 6, gen_loss = 0.45568551292062287, disc_loss = 0.045123068617208134
Trained batch 494 in epoch 6, gen_loss = 0.4557079513265629, disc_loss = 0.045043100493329796
Trained batch 495 in epoch 6, gen_loss = 0.45575379952788353, disc_loss = 0.04500350610103323
Trained batch 496 in epoch 6, gen_loss = 0.45570083319301335, disc_loss = 0.04500939119260541
Trained batch 497 in epoch 6, gen_loss = 0.4558427746755531, disc_loss = 0.04494288648959309
Trained batch 498 in epoch 6, gen_loss = 0.4560145582846984, disc_loss = 0.044882523694275346
Trained batch 499 in epoch 6, gen_loss = 0.4561533203125, disc_loss = 0.04488260800717399
Trained batch 500 in epoch 6, gen_loss = 0.45604960171286457, disc_loss = 0.044931906258256105
Trained batch 501 in epoch 6, gen_loss = 0.4561496376991272, disc_loss = 0.04489026780368248
Trained batch 502 in epoch 6, gen_loss = 0.4563783581403804, disc_loss = 0.04482850930412813
Trained batch 503 in epoch 6, gen_loss = 0.45630826085569365, disc_loss = 0.04475394461538628
Trained batch 504 in epoch 6, gen_loss = 0.45656068590607973, disc_loss = 0.04471161951181839
Trained batch 505 in epoch 6, gen_loss = 0.45641117168980627, disc_loss = 0.044647282033168485
Trained batch 506 in epoch 6, gen_loss = 0.4563626055063816, disc_loss = 0.04456775847692006
Trained batch 507 in epoch 6, gen_loss = 0.45623174256931137, disc_loss = 0.04448765446890263
Trained batch 508 in epoch 6, gen_loss = 0.45610585914145285, disc_loss = 0.044408209915574794
Trained batch 509 in epoch 6, gen_loss = 0.456057104176166, disc_loss = 0.0443267514819608
Trained batch 510 in epoch 6, gen_loss = 0.45591701313474176, disc_loss = 0.04424510248426399
Trained batch 511 in epoch 6, gen_loss = 0.45596493303310126, disc_loss = 0.04417491249068917
Trained batch 512 in epoch 6, gen_loss = 0.45601387696656565, disc_loss = 0.044095890926465854
Trained batch 513 in epoch 6, gen_loss = 0.4558495846703822, disc_loss = 0.044031104483779386
Trained batch 514 in epoch 6, gen_loss = 0.4557519790617008, disc_loss = 0.043958631308423805
Trained batch 515 in epoch 6, gen_loss = 0.45563468059828116, disc_loss = 0.04388534130985206
Trained batch 516 in epoch 6, gen_loss = 0.45580825238439976, disc_loss = 0.04381304950366874
Trained batch 517 in epoch 6, gen_loss = 0.4558763575369787, disc_loss = 0.04373661630551428
Trained batch 518 in epoch 6, gen_loss = 0.45593378992898387, disc_loss = 0.043664092686554856
Trained batch 519 in epoch 6, gen_loss = 0.4559278875589371, disc_loss = 0.04359686046238774
Trained batch 520 in epoch 6, gen_loss = 0.45595247348530965, disc_loss = 0.043524514226378756
Trained batch 521 in epoch 6, gen_loss = 0.4559782826809134, disc_loss = 0.043490228389917916
Trained batch 522 in epoch 6, gen_loss = 0.45582673603216506, disc_loss = 0.04341490283015453
Trained batch 523 in epoch 6, gen_loss = 0.45575093381277476, disc_loss = 0.04334458698232423
Trained batch 524 in epoch 6, gen_loss = 0.45577311266036263, disc_loss = 0.04327319510591527
Trained batch 525 in epoch 6, gen_loss = 0.4557596914215233, disc_loss = 0.04319628378944719
Trained batch 526 in epoch 6, gen_loss = 0.4557897636854219, disc_loss = 0.04312252447466795
Trained batch 527 in epoch 6, gen_loss = 0.4555973475516746, disc_loss = 0.04304594554185204
Trained batch 528 in epoch 6, gen_loss = 0.4554813116619853, disc_loss = 0.04297052093672378
Trained batch 529 in epoch 6, gen_loss = 0.4554692247003879, disc_loss = 0.04292346231490022
Trained batch 530 in epoch 6, gen_loss = 0.45536291329874157, disc_loss = 0.04285147121367299
Trained batch 531 in epoch 6, gen_loss = 0.45533398342759984, disc_loss = 0.04277616183586853
Trained batch 532 in epoch 6, gen_loss = 0.45532689292480083, disc_loss = 0.04270757989666126
Trained batch 533 in epoch 6, gen_loss = 0.45526339074645594, disc_loss = 0.04263760606463552
Trained batch 534 in epoch 6, gen_loss = 0.45517760075141334, disc_loss = 0.04256555428771981
Trained batch 535 in epoch 6, gen_loss = 0.4550707379161422, disc_loss = 0.04249052527671638
Trained batch 536 in epoch 6, gen_loss = 0.4549568041298864, disc_loss = 0.04241685492933504
Trained batch 537 in epoch 6, gen_loss = 0.45499968140985, disc_loss = 0.04234363516874016
Trained batch 538 in epoch 6, gen_loss = 0.4551639189746694, disc_loss = 0.042274823019640424
Trained batch 539 in epoch 6, gen_loss = 0.4551857883179629, disc_loss = 0.04221000267080618
Trained batch 540 in epoch 6, gen_loss = 0.45518902219597823, disc_loss = 0.04215546632435194
Trained batch 541 in epoch 6, gen_loss = 0.45518353064561684, disc_loss = 0.0420858226222505
Trained batch 542 in epoch 6, gen_loss = 0.45520445506875684, disc_loss = 0.042016016288950325
Trained batch 543 in epoch 6, gen_loss = 0.45521154846338663, disc_loss = 0.0419505167814992
Trained batch 544 in epoch 6, gen_loss = 0.45517876990344547, disc_loss = 0.041879126931532125
Trained batch 545 in epoch 6, gen_loss = 0.4551353585043233, disc_loss = 0.041816191002811844
Trained batch 546 in epoch 6, gen_loss = 0.4551435421873054, disc_loss = 0.041749678216312744
Trained batch 547 in epoch 6, gen_loss = 0.45525224294758193, disc_loss = 0.041702613932587014
Trained batch 548 in epoch 6, gen_loss = 0.4551699493752151, disc_loss = 0.04166531255884344
Trained batch 549 in epoch 6, gen_loss = 0.4551587826013565, disc_loss = 0.04161991648502986
Trained batch 550 in epoch 6, gen_loss = 0.4550925534887885, disc_loss = 0.041555987871733716
Trained batch 551 in epoch 6, gen_loss = 0.4550636255222818, disc_loss = 0.0414854922821995
Trained batch 552 in epoch 6, gen_loss = 0.45518532616320395, disc_loss = 0.041430376194313064
Trained batch 553 in epoch 6, gen_loss = 0.45506557962093974, disc_loss = 0.04136215787362442
Trained batch 554 in epoch 6, gen_loss = 0.4551390055600587, disc_loss = 0.04129435213593145
Trained batch 555 in epoch 6, gen_loss = 0.4550495281708326, disc_loss = 0.04122885424608579
Trained batch 556 in epoch 6, gen_loss = 0.4549550813233189, disc_loss = 0.041163376488604145
Trained batch 557 in epoch 6, gen_loss = 0.4548316435574631, disc_loss = 0.04109461015127065
Trained batch 558 in epoch 6, gen_loss = 0.4549360255009373, disc_loss = 0.04104494744551923
Trained batch 559 in epoch 6, gen_loss = 0.45490575219903673, disc_loss = 0.04097641102811654
Trained batch 560 in epoch 6, gen_loss = 0.4549053470718669, disc_loss = 0.040909294896043585
Trained batch 561 in epoch 6, gen_loss = 0.4550321527435262, disc_loss = 0.04084348764139629
Trained batch 562 in epoch 6, gen_loss = 0.4550882232760875, disc_loss = 0.04077587159620151
Trained batch 563 in epoch 6, gen_loss = 0.4550021228426737, disc_loss = 0.0407109133009997
Trained batch 564 in epoch 6, gen_loss = 0.454999106647694, disc_loss = 0.04064961246017004
Trained batch 565 in epoch 6, gen_loss = 0.45499652576741395, disc_loss = 0.04058257042300351
Trained batch 566 in epoch 6, gen_loss = 0.454958903779008, disc_loss = 0.040521449640613355
Trained batch 567 in epoch 6, gen_loss = 0.45479225844774446, disc_loss = 0.040456819557092925
Trained batch 568 in epoch 6, gen_loss = 0.45477805342950806, disc_loss = 0.040389796233652506
Trained batch 569 in epoch 6, gen_loss = 0.45475515195152216, disc_loss = 0.04032574189957558
Trained batch 570 in epoch 6, gen_loss = 0.45474256462892176, disc_loss = 0.04026725058543337
Trained batch 571 in epoch 6, gen_loss = 0.4548293794993754, disc_loss = 0.04022075348025696
Trained batch 572 in epoch 6, gen_loss = 0.45475669779910677, disc_loss = 0.040524443252301444
Trained batch 573 in epoch 6, gen_loss = 0.45473942285215396, disc_loss = 0.040610480185546215
Trained batch 574 in epoch 6, gen_loss = 0.4547017668122831, disc_loss = 0.0405896125426111
Trained batch 575 in epoch 6, gen_loss = 0.4548431031095485, disc_loss = 0.040540445969478846
Trained batch 576 in epoch 6, gen_loss = 0.45486138350422295, disc_loss = 0.04049156552932808
Trained batch 577 in epoch 6, gen_loss = 0.45479323315372927, disc_loss = 0.04043961577536377
Trained batch 578 in epoch 6, gen_loss = 0.45475173212703646, disc_loss = 0.04038489023336114
Trained batch 579 in epoch 6, gen_loss = 0.4547394995545519, disc_loss = 0.040331253913584456
Trained batch 580 in epoch 6, gen_loss = 0.45470633559095675, disc_loss = 0.04026987117181392
Trained batch 581 in epoch 6, gen_loss = 0.4546126032510574, disc_loss = 0.040212899265663626
Trained batch 582 in epoch 6, gen_loss = 0.45447682439769727, disc_loss = 0.04015045977751908
Trained batch 583 in epoch 6, gen_loss = 0.4546431643403556, disc_loss = 0.04021066666280927
Trained batch 584 in epoch 6, gen_loss = 0.45463467612225783, disc_loss = 0.040181448471406075
Trained batch 585 in epoch 6, gen_loss = 0.45455413019290963, disc_loss = 0.04016318602754445
Trained batch 586 in epoch 6, gen_loss = 0.4545563978779255, disc_loss = 0.040124201869474664
Trained batch 587 in epoch 6, gen_loss = 0.454569604374519, disc_loss = 0.04006628744022249
Trained batch 588 in epoch 6, gen_loss = 0.45445835069201396, disc_loss = 0.040083180169823165
Trained batch 589 in epoch 6, gen_loss = 0.4544462929842836, disc_loss = 0.04003536949423536
Trained batch 590 in epoch 6, gen_loss = 0.45445261973818346, disc_loss = 0.03997807171473094
Trained batch 591 in epoch 6, gen_loss = 0.45444323958174604, disc_loss = 0.039942297809190945
Trained batch 592 in epoch 6, gen_loss = 0.45441003332250635, disc_loss = 0.03988190389177047
Trained batch 593 in epoch 6, gen_loss = 0.45446887396602115, disc_loss = 0.03982964312024289
Trained batch 594 in epoch 6, gen_loss = 0.4544648352290402, disc_loss = 0.039768371084595425
Trained batch 595 in epoch 6, gen_loss = 0.45450050843842077, disc_loss = 0.039718769537597495
Trained batch 596 in epoch 6, gen_loss = 0.45439937356329047, disc_loss = 0.039676240777949394
Trained batch 597 in epoch 6, gen_loss = 0.4542607539473569, disc_loss = 0.039615559215691674
Trained batch 598 in epoch 6, gen_loss = 0.45432938319414806, disc_loss = 0.039598174870499284
Trained batch 599 in epoch 6, gen_loss = 0.45446333010991413, disc_loss = 0.03967234739878525
Trained batch 600 in epoch 6, gen_loss = 0.4544039392431643, disc_loss = 0.03968426764798591
Trained batch 601 in epoch 6, gen_loss = 0.4544279971392052, disc_loss = 0.039628896309198976
Trained batch 602 in epoch 6, gen_loss = 0.4544704225822468, disc_loss = 0.03957334250307474
Trained batch 603 in epoch 6, gen_loss = 0.4544364161147977, disc_loss = 0.03951749343591563
Trained batch 604 in epoch 6, gen_loss = 0.45440026674388856, disc_loss = 0.039463711663895895
Trained batch 605 in epoch 6, gen_loss = 0.45430333917290466, disc_loss = 0.03941006535316876
Trained batch 606 in epoch 6, gen_loss = 0.45430217351905594, disc_loss = 0.03936822507668538
Trained batch 607 in epoch 6, gen_loss = 0.4542462115519141, disc_loss = 0.03931799054982165
Trained batch 608 in epoch 6, gen_loss = 0.45429920102966637, disc_loss = 0.03928894893157683
Trained batch 609 in epoch 6, gen_loss = 0.4543050875429247, disc_loss = 0.03924511543047599
Trained batch 610 in epoch 6, gen_loss = 0.45440569729734753, disc_loss = 0.03921285654767226
Trained batch 611 in epoch 6, gen_loss = 0.45453521472955843, disc_loss = 0.03917902694585934
Trained batch 612 in epoch 6, gen_loss = 0.4546107887054929, disc_loss = 0.039142628845289275
Trained batch 613 in epoch 6, gen_loss = 0.45462008466161424, disc_loss = 0.03908397424101514
Trained batch 614 in epoch 6, gen_loss = 0.4546178323466603, disc_loss = 0.03904422476387969
Trained batch 615 in epoch 6, gen_loss = 0.45461783833898506, disc_loss = 0.03898676263671912
Trained batch 616 in epoch 6, gen_loss = 0.45456977558097345, disc_loss = 0.03892954810585893
Trained batch 617 in epoch 6, gen_loss = 0.45459019988293015, disc_loss = 0.03887224064885208
Trained batch 618 in epoch 6, gen_loss = 0.45458837635875327, disc_loss = 0.03881836603079683
Trained batch 619 in epoch 6, gen_loss = 0.4546409022423529, disc_loss = 0.03877425207568693
Trained batch 620 in epoch 6, gen_loss = 0.4546934535154014, disc_loss = 0.038718233513758304
Trained batch 621 in epoch 6, gen_loss = 0.4546662099970882, disc_loss = 0.03867473369022574
Trained batch 622 in epoch 6, gen_loss = 0.4546795497449596, disc_loss = 0.038622003811430994
Trained batch 623 in epoch 6, gen_loss = 0.45466734655201435, disc_loss = 0.03856792477092359
Trained batch 624 in epoch 6, gen_loss = 0.4547951228618622, disc_loss = 0.038527426553145054
Trained batch 625 in epoch 6, gen_loss = 0.45485773644508265, disc_loss = 0.03849872386197563
Trained batch 626 in epoch 6, gen_loss = 0.4549330139274232, disc_loss = 0.038447544714317106
Trained batch 627 in epoch 6, gen_loss = 0.4549794133491577, disc_loss = 0.03839170789882944
Trained batch 628 in epoch 6, gen_loss = 0.45504422540315953, disc_loss = 0.03833561931294056
Trained batch 629 in epoch 6, gen_loss = 0.45515742538467285, disc_loss = 0.03828229778298428
Trained batch 630 in epoch 6, gen_loss = 0.45515881570885564, disc_loss = 0.0382291033455184
Trained batch 631 in epoch 6, gen_loss = 0.45522554529995857, disc_loss = 0.03817477133169275
Trained batch 632 in epoch 6, gen_loss = 0.4552824863984498, disc_loss = 0.03812431447181445
Trained batch 633 in epoch 6, gen_loss = 0.4552274379256396, disc_loss = 0.03807663998848609
Trained batch 634 in epoch 6, gen_loss = 0.4552503798420974, disc_loss = 0.03802257018295799
Trained batch 635 in epoch 6, gen_loss = 0.4552943561249559, disc_loss = 0.03797794047174917
Trained batch 636 in epoch 6, gen_loss = 0.45537184499309424, disc_loss = 0.03793260225298079
Trained batch 637 in epoch 6, gen_loss = 0.4554891958132059, disc_loss = 0.03788342264548038
Trained batch 638 in epoch 6, gen_loss = 0.45554284236054277, disc_loss = 0.03788344651396519
Trained batch 639 in epoch 6, gen_loss = 0.45564670553430914, disc_loss = 0.037855080312874635
Trained batch 640 in epoch 6, gen_loss = 0.45566069196427295, disc_loss = 0.03782420087454611
Trained batch 641 in epoch 6, gen_loss = 0.4556341028287775, disc_loss = 0.0378270472249022
Trained batch 642 in epoch 6, gen_loss = 0.4557794120226455, disc_loss = 0.03779011526656327
Trained batch 643 in epoch 6, gen_loss = 0.45584513621855965, disc_loss = 0.03778558282719589
Trained batch 644 in epoch 6, gen_loss = 0.4559781256110169, disc_loss = 0.037737299611633135
Trained batch 645 in epoch 6, gen_loss = 0.45602271482117773, disc_loss = 0.03774802160129274
Trained batch 646 in epoch 6, gen_loss = 0.45605138860861705, disc_loss = 0.03773728955876791
Trained batch 647 in epoch 6, gen_loss = 0.45616326021191517, disc_loss = 0.03768756376567906
Trained batch 648 in epoch 6, gen_loss = 0.45613712977003795, disc_loss = 0.03764246236131123
Trained batch 649 in epoch 6, gen_loss = 0.45612754019407126, disc_loss = 0.037609061740625366
Trained batch 650 in epoch 6, gen_loss = 0.4561158689211041, disc_loss = 0.03758149027120545
Trained batch 651 in epoch 6, gen_loss = 0.4562701159185427, disc_loss = 0.03753184158772093
Trained batch 652 in epoch 6, gen_loss = 0.4562679217931505, disc_loss = 0.03750012512782312
Trained batch 653 in epoch 6, gen_loss = 0.45630589729055354, disc_loss = 0.03745895685536918
Trained batch 654 in epoch 6, gen_loss = 0.45640758967581596, disc_loss = 0.037412947201603694
Trained batch 655 in epoch 6, gen_loss = 0.45640123880854466, disc_loss = 0.03736411001697955
Trained batch 656 in epoch 6, gen_loss = 0.4563482082597741, disc_loss = 0.03731484860153458
Trained batch 657 in epoch 6, gen_loss = 0.4563873996759983, disc_loss = 0.03726275633747398
Trained batch 658 in epoch 6, gen_loss = 0.4564528799925299, disc_loss = 0.03721099934217058
Trained batch 659 in epoch 6, gen_loss = 0.4565387919093623, disc_loss = 0.03727467309006236
Trained batch 660 in epoch 6, gen_loss = 0.45656982920894823, disc_loss = 0.03745084528144838
Trained batch 661 in epoch 6, gen_loss = 0.4566188429417567, disc_loss = 0.037450242990183326
Trained batch 662 in epoch 6, gen_loss = 0.4566049651772368, disc_loss = 0.03740914554516384
Trained batch 663 in epoch 6, gen_loss = 0.4567287171551262, disc_loss = 0.03745495179858822
Trained batch 664 in epoch 6, gen_loss = 0.45664843612147454, disc_loss = 0.03740607076849704
Trained batch 665 in epoch 6, gen_loss = 0.4565831803613239, disc_loss = 0.0374772598933395
Trained batch 666 in epoch 6, gen_loss = 0.45654635473169847, disc_loss = 0.03763366032900035
Trained batch 667 in epoch 6, gen_loss = 0.4565100631046438, disc_loss = 0.03779857524553548
Trained batch 668 in epoch 6, gen_loss = 0.4565537820036992, disc_loss = 0.03785166830681988
Trained batch 669 in epoch 6, gen_loss = 0.4566698986647734, disc_loss = 0.03797904870458948
Trained batch 670 in epoch 6, gen_loss = 0.4567062759275053, disc_loss = 0.037931677010937435
Trained batch 671 in epoch 6, gen_loss = 0.45677231744463953, disc_loss = 0.037897397679487424
Trained batch 672 in epoch 6, gen_loss = 0.45669664187913134, disc_loss = 0.037850313592995524
Trained batch 673 in epoch 6, gen_loss = 0.4566119098344967, disc_loss = 0.03786021394334534
Trained batch 674 in epoch 6, gen_loss = 0.45661111840495355, disc_loss = 0.037841602278252444
Trained batch 675 in epoch 6, gen_loss = 0.45662136062891523, disc_loss = 0.037853660074354714
Trained batch 676 in epoch 6, gen_loss = 0.4566413338902782, disc_loss = 0.03781192589061475
Trained batch 677 in epoch 6, gen_loss = 0.4565438951714552, disc_loss = 0.037786415061064525
Trained batch 678 in epoch 6, gen_loss = 0.4565425643776934, disc_loss = 0.03774024460009342
Trained batch 679 in epoch 6, gen_loss = 0.45652054798077135, disc_loss = 0.03768915476633564
Trained batch 680 in epoch 6, gen_loss = 0.4565573388084266, disc_loss = 0.037641793959903996
Trained batch 681 in epoch 6, gen_loss = 0.45648269224201826, disc_loss = 0.037591349718958424
Trained batch 682 in epoch 6, gen_loss = 0.4564790719162842, disc_loss = 0.03755026093635048
Trained batch 683 in epoch 6, gen_loss = 0.4563804468390537, disc_loss = 0.03751454210182521
Trained batch 684 in epoch 6, gen_loss = 0.45649170832042274, disc_loss = 0.037485015321944426
Trained batch 685 in epoch 6, gen_loss = 0.4565728881094963, disc_loss = 0.03744859119324671
Trained batch 686 in epoch 6, gen_loss = 0.4566961450521255, disc_loss = 0.037399530657153617
Trained batch 687 in epoch 6, gen_loss = 0.45668307089701643, disc_loss = 0.03734957539073062
Trained batch 688 in epoch 6, gen_loss = 0.45662274411697, disc_loss = 0.037301845892490644
Trained batch 689 in epoch 6, gen_loss = 0.4565833962913873, disc_loss = 0.037251477171261996
Trained batch 690 in epoch 6, gen_loss = 0.45653559325745413, disc_loss = 0.037200894607729705
Trained batch 691 in epoch 6, gen_loss = 0.456521665645128, disc_loss = 0.03714948157545023
Trained batch 692 in epoch 6, gen_loss = 0.45644406391600684, disc_loss = 0.037101097077549224
Trained batch 693 in epoch 6, gen_loss = 0.45645828291730856, disc_loss = 0.03705069454744463
Trained batch 694 in epoch 6, gen_loss = 0.4564992655524247, disc_loss = 0.03700912453639556
Trained batch 695 in epoch 6, gen_loss = 0.45649878963314255, disc_loss = 0.036968008684156325
Trained batch 696 in epoch 6, gen_loss = 0.4564339192731138, disc_loss = 0.03692028071838892
Trained batch 697 in epoch 6, gen_loss = 0.45640094821637545, disc_loss = 0.03688513582594356
Trained batch 698 in epoch 6, gen_loss = 0.45638501797622877, disc_loss = 0.036836716285320495
Trained batch 699 in epoch 6, gen_loss = 0.456417156798499, disc_loss = 0.036791004498788554
Trained batch 700 in epoch 6, gen_loss = 0.45630925192302374, disc_loss = 0.036747892692282576
Trained batch 701 in epoch 6, gen_loss = 0.4563893366318483, disc_loss = 0.03670562860742344
Trained batch 702 in epoch 6, gen_loss = 0.45631932449205165, disc_loss = 0.036667385915722196
Trained batch 703 in epoch 6, gen_loss = 0.4561912681145424, disc_loss = 0.03662184588905471
Trained batch 704 in epoch 6, gen_loss = 0.45624389728755815, disc_loss = 0.0365740945455387
Trained batch 705 in epoch 6, gen_loss = 0.45623309572594023, disc_loss = 0.03652556194635583
Trained batch 706 in epoch 6, gen_loss = 0.45625202810916066, disc_loss = 0.036515411700693765
Trained batch 707 in epoch 6, gen_loss = 0.4562901931967439, disc_loss = 0.03647215850371736
Trained batch 708 in epoch 6, gen_loss = 0.45620529809690835, disc_loss = 0.036434720450130846
Trained batch 709 in epoch 6, gen_loss = 0.456190948838919, disc_loss = 0.036391054400616706
Trained batch 710 in epoch 6, gen_loss = 0.4561731697973152, disc_loss = 0.03634314432674063
Trained batch 711 in epoch 6, gen_loss = 0.45623168554366306, disc_loss = 0.036294502726909074
Trained batch 712 in epoch 6, gen_loss = 0.4562015029357493, disc_loss = 0.03624807566363197
Trained batch 713 in epoch 6, gen_loss = 0.45622006246522695, disc_loss = 0.036201259482447165
Trained batch 714 in epoch 6, gen_loss = 0.456186438815577, disc_loss = 0.03615532679584242
Trained batch 715 in epoch 6, gen_loss = 0.4561430324888762, disc_loss = 0.036107831232492976
Trained batch 716 in epoch 6, gen_loss = 0.4561595425446163, disc_loss = 0.03606191606308246
Trained batch 717 in epoch 6, gen_loss = 0.4561564325871242, disc_loss = 0.03601524583501793
Trained batch 718 in epoch 6, gen_loss = 0.45611932712072123, disc_loss = 0.03600178399626477
Trained batch 719 in epoch 6, gen_loss = 0.45613584605356056, disc_loss = 0.035957011249815374
Trained batch 720 in epoch 6, gen_loss = 0.4561429256870413, disc_loss = 0.035920050845613206
Trained batch 721 in epoch 6, gen_loss = 0.45609959043624326, disc_loss = 0.03587803567377231
Trained batch 722 in epoch 6, gen_loss = 0.4560362791866682, disc_loss = 0.035835594397887104
Trained batch 723 in epoch 6, gen_loss = 0.45610561633472285, disc_loss = 0.035851127689785336
Trained batch 724 in epoch 6, gen_loss = 0.45616157815374175, disc_loss = 0.03614766021275186
Trained batch 725 in epoch 6, gen_loss = 0.45600282468579034, disc_loss = 0.03619342221421146
Trained batch 726 in epoch 6, gen_loss = 0.45597954403911367, disc_loss = 0.03616372865904635
Trained batch 727 in epoch 6, gen_loss = 0.4559846600660911, disc_loss = 0.03616765282768628
Trained batch 728 in epoch 6, gen_loss = 0.4560398847396155, disc_loss = 0.03616425983747659
Trained batch 729 in epoch 6, gen_loss = 0.45608297280252796, disc_loss = 0.03613464511366408
Trained batch 730 in epoch 6, gen_loss = 0.45598305009621437, disc_loss = 0.036162276188371555
Trained batch 731 in epoch 6, gen_loss = 0.455859450491074, disc_loss = 0.0363061148728959
Trained batch 732 in epoch 6, gen_loss = 0.45597735372604487, disc_loss = 0.03627825264407939
Trained batch 733 in epoch 6, gen_loss = 0.45601788662597337, disc_loss = 0.03626269404633651
Trained batch 734 in epoch 6, gen_loss = 0.4560662700610907, disc_loss = 0.036238664472760744
Trained batch 735 in epoch 6, gen_loss = 0.4560652127408463, disc_loss = 0.036269560120158334
Trained batch 736 in epoch 6, gen_loss = 0.4560720181772473, disc_loss = 0.0364696028112564
Trained batch 737 in epoch 6, gen_loss = 0.4560502109731116, disc_loss = 0.03652047245560699
Trained batch 738 in epoch 6, gen_loss = 0.45598708635576685, disc_loss = 0.03658325427557759
Trained batch 739 in epoch 6, gen_loss = 0.45606805170710024, disc_loss = 0.036587755541109504
Trained batch 740 in epoch 6, gen_loss = 0.45606308222299646, disc_loss = 0.03656586049254682
Trained batch 741 in epoch 6, gen_loss = 0.4561311231870857, disc_loss = 0.036547029451649095
Trained batch 742 in epoch 6, gen_loss = 0.4561380791712257, disc_loss = 0.0365187292334136
Trained batch 743 in epoch 6, gen_loss = 0.4562316705542867, disc_loss = 0.03649155786357975
Trained batch 744 in epoch 6, gen_loss = 0.4562932162076835, disc_loss = 0.03645026366892052
Trained batch 745 in epoch 6, gen_loss = 0.4563099495447353, disc_loss = 0.03640713637689098
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.4519726634025574, disc_loss = 0.020019859075546265
Trained batch 1 in epoch 7, gen_loss = 0.46039479970932007, disc_loss = 0.031161895021796227
Trained batch 2 in epoch 7, gen_loss = 0.4814154307047526, disc_loss = 0.0547488716741403
Trained batch 3 in epoch 7, gen_loss = 0.4902702420949936, disc_loss = 0.04791047237813473
Trained batch 4 in epoch 7, gen_loss = 0.4839048385620117, disc_loss = 0.052312107384204866
Trained batch 5 in epoch 7, gen_loss = 0.46052591502666473, disc_loss = 0.058277043203512825
Trained batch 6 in epoch 7, gen_loss = 0.45956858141081675, disc_loss = 0.05733500633920942
Trained batch 7 in epoch 7, gen_loss = 0.4573274403810501, disc_loss = 0.05674505280330777
Trained batch 8 in epoch 7, gen_loss = 0.4598848621050517, disc_loss = 0.051805092953145504
Trained batch 9 in epoch 7, gen_loss = 0.4639592349529266, disc_loss = 0.048398477118462326
Trained batch 10 in epoch 7, gen_loss = 0.4589376151561737, disc_loss = 0.044965227134525776
Trained batch 11 in epoch 7, gen_loss = 0.46081358194351196, disc_loss = 0.04277779278345406
Trained batch 12 in epoch 7, gen_loss = 0.4566923540372115, disc_loss = 0.04281624256131741
Trained batch 13 in epoch 7, gen_loss = 0.4628435564892633, disc_loss = 0.04821302495630724
Trained batch 14 in epoch 7, gen_loss = 0.46492096185684206, disc_loss = 0.04538199578722318
Trained batch 15 in epoch 7, gen_loss = 0.46178065799176693, disc_loss = 0.050890633603557944
Trained batch 16 in epoch 7, gen_loss = 0.4643385112285614, disc_loss = 0.052063604268957585
Trained batch 17 in epoch 7, gen_loss = 0.46594056983788806, disc_loss = 0.057442049806316696
Trained batch 18 in epoch 7, gen_loss = 0.4615777683885474, disc_loss = 0.0558161669851918
Trained batch 19 in epoch 7, gen_loss = 0.4591779336333275, disc_loss = 0.06178116025403142
Trained batch 20 in epoch 7, gen_loss = 0.45722261496952604, disc_loss = 0.0630435369731415
Trained batch 21 in epoch 7, gen_loss = 0.45858237824656745, disc_loss = 0.06663356391205029
Trained batch 22 in epoch 7, gen_loss = 0.4553753604059634, disc_loss = 0.06914308286555436
Trained batch 23 in epoch 7, gen_loss = 0.4559631186227004, disc_loss = 0.06893881945870817
Trained batch 24 in epoch 7, gen_loss = 0.45631465792655945, disc_loss = 0.07089527852833272
Trained batch 25 in epoch 7, gen_loss = 0.4512328826464139, disc_loss = 0.0767707206452122
Trained batch 26 in epoch 7, gen_loss = 0.45437393585840863, disc_loss = 0.07452071616771044
Trained batch 27 in epoch 7, gen_loss = 0.45240162312984467, disc_loss = 0.07273343218756574
Trained batch 28 in epoch 7, gen_loss = 0.45066682120849344, disc_loss = 0.07089112673340173
Trained batch 29 in epoch 7, gen_loss = 0.44679403901100156, disc_loss = 0.07043012989064058
Trained batch 30 in epoch 7, gen_loss = 0.44784060216719107, disc_loss = 0.07116948705046408
Trained batch 31 in epoch 7, gen_loss = 0.449132202193141, disc_loss = 0.07064409472513944
Trained batch 32 in epoch 7, gen_loss = 0.4482980090560335, disc_loss = 0.07018932846911026
Trained batch 33 in epoch 7, gen_loss = 0.4464051276445389, disc_loss = 0.06934532654636047
Trained batch 34 in epoch 7, gen_loss = 0.4481187471321651, disc_loss = 0.06899523479597909
Trained batch 35 in epoch 7, gen_loss = 0.44935133473740685, disc_loss = 0.06876139394525024
Trained batch 36 in epoch 7, gen_loss = 0.4472280636027053, disc_loss = 0.06774508107352901
Trained batch 37 in epoch 7, gen_loss = 0.4451691178899062, disc_loss = 0.06656879956196797
Trained batch 38 in epoch 7, gen_loss = 0.4441436659067105, disc_loss = 0.0651016094459173
Trained batch 39 in epoch 7, gen_loss = 0.4432004041969776, disc_loss = 0.06430454100482166
Trained batch 40 in epoch 7, gen_loss = 0.44496331636498615, disc_loss = 0.06410215090869403
Trained batch 41 in epoch 7, gen_loss = 0.4448096120641345, disc_loss = 0.06303193437911216
Trained batch 42 in epoch 7, gen_loss = 0.44642160451689433, disc_loss = 0.061960890109455866
Trained batch 43 in epoch 7, gen_loss = 0.44594091922044754, disc_loss = 0.06089440923692151
Trained batch 44 in epoch 7, gen_loss = 0.4473818759123484, disc_loss = 0.05996564771566126
Trained batch 45 in epoch 7, gen_loss = 0.44692021543565, disc_loss = 0.059315586138678635
Trained batch 46 in epoch 7, gen_loss = 0.44674482370944735, disc_loss = 0.059170387130468446
Trained batch 47 in epoch 7, gen_loss = 0.447758777687947, disc_loss = 0.05822576109009484
Trained batch 48 in epoch 7, gen_loss = 0.4479341634682247, disc_loss = 0.05720031544642181
Trained batch 49 in epoch 7, gen_loss = 0.45017070591449737, disc_loss = 0.05667077438905835
Trained batch 50 in epoch 7, gen_loss = 0.45000451686335546, disc_loss = 0.055964000870053675
Trained batch 51 in epoch 7, gen_loss = 0.4488094116632755, disc_loss = 0.05534399248874532
Trained batch 52 in epoch 7, gen_loss = 0.45022868660261045, disc_loss = 0.05714551350628992
Trained batch 53 in epoch 7, gen_loss = 0.4503312905629476, disc_loss = 0.057109673455771476
Trained batch 54 in epoch 7, gen_loss = 0.4503386069427837, disc_loss = 0.056659142588349906
Trained batch 55 in epoch 7, gen_loss = 0.4508178899330752, disc_loss = 0.056230025814979205
Trained batch 56 in epoch 7, gen_loss = 0.44989422591109024, disc_loss = 0.057523234028434546
Trained batch 57 in epoch 7, gen_loss = 0.45197768714921227, disc_loss = 0.05862177502171233
Trained batch 58 in epoch 7, gen_loss = 0.451893449334775, disc_loss = 0.05887814186576564
Trained batch 59 in epoch 7, gen_loss = 0.4519278566042582, disc_loss = 0.05803864084494611
Trained batch 60 in epoch 7, gen_loss = 0.4512357892560177, disc_loss = 0.05748597711141481
Trained batch 61 in epoch 7, gen_loss = 0.4508703004929327, disc_loss = 0.05930834451329804
Trained batch 62 in epoch 7, gen_loss = 0.4533296199071975, disc_loss = 0.06362147199078685
Trained batch 63 in epoch 7, gen_loss = 0.4522673562169075, disc_loss = 0.06357696124177892
Trained batch 64 in epoch 7, gen_loss = 0.45105690956115724, disc_loss = 0.06463580207469372
Trained batch 65 in epoch 7, gen_loss = 0.45166201257344446, disc_loss = 0.06415668052310745
Trained batch 66 in epoch 7, gen_loss = 0.4507926893768026, disc_loss = 0.06391758834526165
Trained batch 67 in epoch 7, gen_loss = 0.44991207254283566, disc_loss = 0.06413257008363657
Trained batch 68 in epoch 7, gen_loss = 0.45022227237190027, disc_loss = 0.06372207879642214
Trained batch 69 in epoch 7, gen_loss = 0.450634542959077, disc_loss = 0.06352724476850459
Trained batch 70 in epoch 7, gen_loss = 0.45062838389839927, disc_loss = 0.06290970200961324
Trained batch 71 in epoch 7, gen_loss = 0.45055896995796096, disc_loss = 0.06279187467104445
Trained batch 72 in epoch 7, gen_loss = 0.45173603092154413, disc_loss = 0.06210774429499695
Trained batch 73 in epoch 7, gen_loss = 0.45116116589791067, disc_loss = 0.06153644902027539
Trained batch 74 in epoch 7, gen_loss = 0.4506934599081675, disc_loss = 0.06082350868731737
Trained batch 75 in epoch 7, gen_loss = 0.4513192874820609, disc_loss = 0.06048455122417133
Trained batch 76 in epoch 7, gen_loss = 0.4506890220301492, disc_loss = 0.05991795810253976
Trained batch 77 in epoch 7, gen_loss = 0.4509150225382585, disc_loss = 0.05928234995987553
Trained batch 78 in epoch 7, gen_loss = 0.45040079121348225, disc_loss = 0.06008544537132677
Trained batch 79 in epoch 7, gen_loss = 0.450309256836772, disc_loss = 0.06039686716394499
Trained batch 80 in epoch 7, gen_loss = 0.45102247448615085, disc_loss = 0.05971830345713246
Trained batch 81 in epoch 7, gen_loss = 0.44996822134750647, disc_loss = 0.05908416376858041
Trained batch 82 in epoch 7, gen_loss = 0.45006918296756515, disc_loss = 0.058915234221347486
Trained batch 83 in epoch 7, gen_loss = 0.4494782370470819, disc_loss = 0.058394610410600546
Trained batch 84 in epoch 7, gen_loss = 0.4492258005282458, disc_loss = 0.058303218701963914
Trained batch 85 in epoch 7, gen_loss = 0.4478695822316547, disc_loss = 0.05777911035625567
Trained batch 86 in epoch 7, gen_loss = 0.44821153701036826, disc_loss = 0.05744265541755434
Trained batch 87 in epoch 7, gen_loss = 0.4477178325707262, disc_loss = 0.05714264765529978
Trained batch 88 in epoch 7, gen_loss = 0.4470991897449065, disc_loss = 0.05771640997400947
Trained batch 89 in epoch 7, gen_loss = 0.44727132386631435, disc_loss = 0.058377845994093354
Trained batch 90 in epoch 7, gen_loss = 0.4480984492616339, disc_loss = 0.059078376448539256
Trained batch 91 in epoch 7, gen_loss = 0.44779638265785965, disc_loss = 0.059523892138436764
Trained batch 92 in epoch 7, gen_loss = 0.44715125714578935, disc_loss = 0.059148768018130016
Trained batch 93 in epoch 7, gen_loss = 0.4477974702703192, disc_loss = 0.0598854358317925
Trained batch 94 in epoch 7, gen_loss = 0.4482815883661571, disc_loss = 0.05966013065588317
Trained batch 95 in epoch 7, gen_loss = 0.4490629971648256, disc_loss = 0.05971745525312144
Trained batch 96 in epoch 7, gen_loss = 0.44898458117062284, disc_loss = 0.06054615789601944
Trained batch 97 in epoch 7, gen_loss = 0.4499520762842529, disc_loss = 0.06071097555342225
Trained batch 98 in epoch 7, gen_loss = 0.4495028121904893, disc_loss = 0.06028256895998963
Trained batch 99 in epoch 7, gen_loss = 0.44870574414730074, disc_loss = 0.060242438386194405
Trained batch 100 in epoch 7, gen_loss = 0.44831130852793705, disc_loss = 0.060152745404566575
Trained batch 101 in epoch 7, gen_loss = 0.4484992021439122, disc_loss = 0.05980123659394974
Trained batch 102 in epoch 7, gen_loss = 0.44909038184915934, disc_loss = 0.05946839943944106
Trained batch 103 in epoch 7, gen_loss = 0.44921637498415434, disc_loss = 0.05904567078239499
Trained batch 104 in epoch 7, gen_loss = 0.44955467752047945, disc_loss = 0.05880049000095044
Trained batch 105 in epoch 7, gen_loss = 0.4509220587195091, disc_loss = 0.05852609434832801
Trained batch 106 in epoch 7, gen_loss = 0.45069655776023865, disc_loss = 0.058543942812133896
Trained batch 107 in epoch 7, gen_loss = 0.450580055239024, disc_loss = 0.05814765301895224
Trained batch 108 in epoch 7, gen_loss = 0.4509153964869473, disc_loss = 0.05770310172982036
Trained batch 109 in epoch 7, gen_loss = 0.4513765126466751, disc_loss = 0.05758092814463783
Trained batch 110 in epoch 7, gen_loss = 0.45123552631687475, disc_loss = 0.05729040303393393
Trained batch 111 in epoch 7, gen_loss = 0.45149798478399006, disc_loss = 0.056914155916144536
Trained batch 112 in epoch 7, gen_loss = 0.4517357088295759, disc_loss = 0.05647861430899496
Trained batch 113 in epoch 7, gen_loss = 0.4520021990725869, disc_loss = 0.05654870418897062
Trained batch 114 in epoch 7, gen_loss = 0.45189550285754, disc_loss = 0.05629520025104284
Trained batch 115 in epoch 7, gen_loss = 0.45260737887744246, disc_loss = 0.05604162499918763
Trained batch 116 in epoch 7, gen_loss = 0.4528241025076972, disc_loss = 0.0560076739718644
Trained batch 117 in epoch 7, gen_loss = 0.453045522004871, disc_loss = 0.05689375404805198
Trained batch 118 in epoch 7, gen_loss = 0.45350351679224926, disc_loss = 0.05663348301587736
Trained batch 119 in epoch 7, gen_loss = 0.4532523088157177, disc_loss = 0.056953952019102874
Trained batch 120 in epoch 7, gen_loss = 0.4527588927548779, disc_loss = 0.05779201807531197
Trained batch 121 in epoch 7, gen_loss = 0.45228678916321424, disc_loss = 0.057437699860664174
Trained batch 122 in epoch 7, gen_loss = 0.45205466897507024, disc_loss = 0.057392315371189176
Trained batch 123 in epoch 7, gen_loss = 0.45283458814505606, disc_loss = 0.057015269927139726
Trained batch 124 in epoch 7, gen_loss = 0.45208932852745054, disc_loss = 0.05688391777127981
Trained batch 125 in epoch 7, gen_loss = 0.4521670180653769, disc_loss = 0.05728180738284238
Trained batch 126 in epoch 7, gen_loss = 0.4522039160484404, disc_loss = 0.057034695205667355
Trained batch 127 in epoch 7, gen_loss = 0.4526051899883896, disc_loss = 0.0566652932393481
Trained batch 128 in epoch 7, gen_loss = 0.4526090730530347, disc_loss = 0.056448259159864844
Trained batch 129 in epoch 7, gen_loss = 0.4528605064520469, disc_loss = 0.056250633163234365
Trained batch 130 in epoch 7, gen_loss = 0.4527460323035262, disc_loss = 0.05595493536328769
Trained batch 131 in epoch 7, gen_loss = 0.45315083951661084, disc_loss = 0.05567091306191728
Trained batch 132 in epoch 7, gen_loss = 0.45363352083622066, disc_loss = 0.055600000286292764
Trained batch 133 in epoch 7, gen_loss = 0.4541533424783109, disc_loss = 0.05562745774887613
Trained batch 134 in epoch 7, gen_loss = 0.4545650358553286, disc_loss = 0.05835067481492404
Trained batch 135 in epoch 7, gen_loss = 0.4546869607532726, disc_loss = 0.05871732550097958
Trained batch 136 in epoch 7, gen_loss = 0.4540457923481934, disc_loss = 0.06043052102989741
Trained batch 137 in epoch 7, gen_loss = 0.4539562858965086, disc_loss = 0.06135611371744586
Trained batch 138 in epoch 7, gen_loss = 0.45414923549556047, disc_loss = 0.06123517582983636
Trained batch 139 in epoch 7, gen_loss = 0.45440745183399744, disc_loss = 0.061148425624040624
Trained batch 140 in epoch 7, gen_loss = 0.4546562359265402, disc_loss = 0.06108772094817238
Trained batch 141 in epoch 7, gen_loss = 0.45510073425904124, disc_loss = 0.06089194610216458
Trained batch 142 in epoch 7, gen_loss = 0.4546494744457565, disc_loss = 0.060686989322669437
Trained batch 143 in epoch 7, gen_loss = 0.4549435904870431, disc_loss = 0.06063762626015685
Trained batch 144 in epoch 7, gen_loss = 0.4548016141200888, disc_loss = 0.06041865323766552
Trained batch 145 in epoch 7, gen_loss = 0.4548313135970129, disc_loss = 0.060164685163340746
Trained batch 146 in epoch 7, gen_loss = 0.4548263780924739, disc_loss = 0.0604546625534592
Trained batch 147 in epoch 7, gen_loss = 0.45480309950338826, disc_loss = 0.06025074998143356
Trained batch 148 in epoch 7, gen_loss = 0.4548923917264746, disc_loss = 0.06148378222855746
Trained batch 149 in epoch 7, gen_loss = 0.45452860713005067, disc_loss = 0.0629192984290421
Trained batch 150 in epoch 7, gen_loss = 0.4541145288786351, disc_loss = 0.0628790290138086
Trained batch 151 in epoch 7, gen_loss = 0.4539656505772942, disc_loss = 0.06402225794246126
Trained batch 152 in epoch 7, gen_loss = 0.45395590666851965, disc_loss = 0.06442763487765797
Trained batch 153 in epoch 7, gen_loss = 0.4537525608555063, disc_loss = 0.06463750492321788
Trained batch 154 in epoch 7, gen_loss = 0.45351778864860537, disc_loss = 0.06442456146281574
Trained batch 155 in epoch 7, gen_loss = 0.45397470872371626, disc_loss = 0.0642121599163287
Trained batch 156 in epoch 7, gen_loss = 0.45384789063672354, disc_loss = 0.06394291636504375
Trained batch 157 in epoch 7, gen_loss = 0.4535566704182685, disc_loss = 0.06370313276383507
Trained batch 158 in epoch 7, gen_loss = 0.4536805402182933, disc_loss = 0.06347623691782824
Trained batch 159 in epoch 7, gen_loss = 0.45399690363556144, disc_loss = 0.06316603043815121
Trained batch 160 in epoch 7, gen_loss = 0.4537425296647208, disc_loss = 0.062960292646511
Trained batch 161 in epoch 7, gen_loss = 0.45381498116034047, disc_loss = 0.06265087265889217
Trained batch 162 in epoch 7, gen_loss = 0.45367767456119046, disc_loss = 0.062365599182302965
Trained batch 163 in epoch 7, gen_loss = 0.45359340019342376, disc_loss = 0.06205451934848253
Trained batch 164 in epoch 7, gen_loss = 0.45349411548990193, disc_loss = 0.06179250434718349
Trained batch 165 in epoch 7, gen_loss = 0.4534622791660837, disc_loss = 0.06163291198885944
Trained batch 166 in epoch 7, gen_loss = 0.4538887241286432, disc_loss = 0.06134089591081985
Trained batch 167 in epoch 7, gen_loss = 0.4536253825894424, disc_loss = 0.061213470197149684
Trained batch 168 in epoch 7, gen_loss = 0.45366487806365335, disc_loss = 0.060953371777866014
Trained batch 169 in epoch 7, gen_loss = 0.4534727289396174, disc_loss = 0.0609286738669171
Trained batch 170 in epoch 7, gen_loss = 0.4536157318374567, disc_loss = 0.06077447529250418
Trained batch 171 in epoch 7, gen_loss = 0.4539011718575345, disc_loss = 0.06049487417628772
Trained batch 172 in epoch 7, gen_loss = 0.45386601441857444, disc_loss = 0.06020735565982113
Trained batch 173 in epoch 7, gen_loss = 0.45377451969289234, disc_loss = 0.06000841828598373
Trained batch 174 in epoch 7, gen_loss = 0.45381246055875507, disc_loss = 0.05969671872577497
Trained batch 175 in epoch 7, gen_loss = 0.45422123914415186, disc_loss = 0.05944070638559589
Trained batch 176 in epoch 7, gen_loss = 0.454086221880832, disc_loss = 0.05923676869100602
Trained batch 177 in epoch 7, gen_loss = 0.4535447901554322, disc_loss = 0.058956588665546664
Trained batch 178 in epoch 7, gen_loss = 0.4538897469057051, disc_loss = 0.059372573086794195
Trained batch 179 in epoch 7, gen_loss = 0.45375584645403755, disc_loss = 0.05928302528854046
Trained batch 180 in epoch 7, gen_loss = 0.4534769968762582, disc_loss = 0.059210838631659914
Trained batch 181 in epoch 7, gen_loss = 0.45388498492948304, disc_loss = 0.059091483432144584
Trained batch 182 in epoch 7, gen_loss = 0.4534870682518339, disc_loss = 0.0594403748782199
Trained batch 183 in epoch 7, gen_loss = 0.45333001827416214, disc_loss = 0.05978742785974527
Trained batch 184 in epoch 7, gen_loss = 0.45305404695304663, disc_loss = 0.059797149408306625
Trained batch 185 in epoch 7, gen_loss = 0.4528911248330147, disc_loss = 0.05957766273309306
Trained batch 186 in epoch 7, gen_loss = 0.45289157115839385, disc_loss = 0.05938537029878182
Trained batch 187 in epoch 7, gen_loss = 0.4528448792531135, disc_loss = 0.059187148454935945
Trained batch 188 in epoch 7, gen_loss = 0.45296481488242984, disc_loss = 0.0589375182858141
Trained batch 189 in epoch 7, gen_loss = 0.4530410314861097, disc_loss = 0.05874380936454001
Trained batch 190 in epoch 7, gen_loss = 0.4532452567397612, disc_loss = 0.05847123588059897
Trained batch 191 in epoch 7, gen_loss = 0.4532564184628427, disc_loss = 0.05837054033569681
Trained batch 192 in epoch 7, gen_loss = 0.4531998706913983, disc_loss = 0.0581714990572917
Trained batch 193 in epoch 7, gen_loss = 0.4532348318505533, disc_loss = 0.057991858590970335
Trained batch 194 in epoch 7, gen_loss = 0.4532817486004952, disc_loss = 0.057758272439241407
Trained batch 195 in epoch 7, gen_loss = 0.45308083599927473, disc_loss = 0.05752289358868587
Trained batch 196 in epoch 7, gen_loss = 0.45315039263764006, disc_loss = 0.05737198661388782
Trained batch 197 in epoch 7, gen_loss = 0.4529987230445399, disc_loss = 0.05722627515970456
Trained batch 198 in epoch 7, gen_loss = 0.4532213723240186, disc_loss = 0.05714455387325742
Trained batch 199 in epoch 7, gen_loss = 0.45323277682065966, disc_loss = 0.05694825053215027
Trained batch 200 in epoch 7, gen_loss = 0.45323170877214686, disc_loss = 0.05675713636388826
Trained batch 201 in epoch 7, gen_loss = 0.4528750147264783, disc_loss = 0.05652061851676738
Trained batch 202 in epoch 7, gen_loss = 0.45275157455153064, disc_loss = 0.056294295771662235
Trained batch 203 in epoch 7, gen_loss = 0.4526209591650495, disc_loss = 0.05631894547053996
Trained batch 204 in epoch 7, gen_loss = 0.4522388969979635, disc_loss = 0.05631284464786692
Trained batch 205 in epoch 7, gen_loss = 0.4522526222235948, disc_loss = 0.056108174854618255
Trained batch 206 in epoch 7, gen_loss = 0.45280054413178117, disc_loss = 0.05599210529187739
Trained batch 207 in epoch 7, gen_loss = 0.4532203460828616, disc_loss = 0.05587818504920086
Trained batch 208 in epoch 7, gen_loss = 0.45295576701323953, disc_loss = 0.05576962144359162
Trained batch 209 in epoch 7, gen_loss = 0.45271059913294653, disc_loss = 0.055541687627278624
Trained batch 210 in epoch 7, gen_loss = 0.45272055833260594, disc_loss = 0.05534702320958342
Trained batch 211 in epoch 7, gen_loss = 0.45248441974509435, disc_loss = 0.055123269711708965
Trained batch 212 in epoch 7, gen_loss = 0.45274317502415795, disc_loss = 0.054974205472764555
Trained batch 213 in epoch 7, gen_loss = 0.45269248516203087, disc_loss = 0.05475705980418998
Trained batch 214 in epoch 7, gen_loss = 0.4525640719158705, disc_loss = 0.05456822260694448
Trained batch 215 in epoch 7, gen_loss = 0.45281248001588714, disc_loss = 0.0543659588891185
Trained batch 216 in epoch 7, gen_loss = 0.4530331790447235, disc_loss = 0.054130034814138084
Trained batch 217 in epoch 7, gen_loss = 0.45300403141647305, disc_loss = 0.053912899607510535
Trained batch 218 in epoch 7, gen_loss = 0.45295146529533004, disc_loss = 0.05372122618301716
Trained batch 219 in epoch 7, gen_loss = 0.45327669517560437, disc_loss = 0.05349479396510023
Trained batch 220 in epoch 7, gen_loss = 0.4533228886343235, disc_loss = 0.05330036381761042
Trained batch 221 in epoch 7, gen_loss = 0.45369185829484787, disc_loss = 0.05308680256581152
Trained batch 222 in epoch 7, gen_loss = 0.45400370490390624, disc_loss = 0.05286982290617988
Trained batch 223 in epoch 7, gen_loss = 0.4539545963385275, disc_loss = 0.05264553851884557
Trained batch 224 in epoch 7, gen_loss = 0.45400956047905816, disc_loss = 0.052434544572606684
Trained batch 225 in epoch 7, gen_loss = 0.4544777907101454, disc_loss = 0.05224115118091777
Trained batch 226 in epoch 7, gen_loss = 0.45437187481556696, disc_loss = 0.05203145192751439
Trained batch 227 in epoch 7, gen_loss = 0.4546294350895965, disc_loss = 0.05182242311696571
Trained batch 228 in epoch 7, gen_loss = 0.45475388640399583, disc_loss = 0.051666079234437584
Trained batch 229 in epoch 7, gen_loss = 0.45457266672797825, disc_loss = 0.0514649615491457
Trained batch 230 in epoch 7, gen_loss = 0.4547830218876595, disc_loss = 0.05132856452938379
Trained batch 231 in epoch 7, gen_loss = 0.4549343358596851, disc_loss = 0.051147785751301605
Trained batch 232 in epoch 7, gen_loss = 0.4551521011432353, disc_loss = 0.05095258457766039
Trained batch 233 in epoch 7, gen_loss = 0.45536462809794986, disc_loss = 0.0507595557311518
Trained batch 234 in epoch 7, gen_loss = 0.45569475698978346, disc_loss = 0.05056708881413524
Trained batch 235 in epoch 7, gen_loss = 0.4557272760292231, disc_loss = 0.050430925664594554
Trained batch 236 in epoch 7, gen_loss = 0.455705993286165, disc_loss = 0.05025336148614213
Trained batch 237 in epoch 7, gen_loss = 0.45566805596111204, disc_loss = 0.050091890409831426
Trained batch 238 in epoch 7, gen_loss = 0.4558011597669274, disc_loss = 0.049894607000473774
Trained batch 239 in epoch 7, gen_loss = 0.4561107136309147, disc_loss = 0.049735220682729654
Trained batch 240 in epoch 7, gen_loss = 0.45622695283771053, disc_loss = 0.04957673014083653
Trained batch 241 in epoch 7, gen_loss = 0.45607705377350166, disc_loss = 0.049482954052192246
Trained batch 242 in epoch 7, gen_loss = 0.45617802778389227, disc_loss = 0.04931675518744092
Trained batch 243 in epoch 7, gen_loss = 0.45605529600479566, disc_loss = 0.049140620072082176
Trained batch 244 in epoch 7, gen_loss = 0.45606285187662865, disc_loss = 0.0489976045162398
Trained batch 245 in epoch 7, gen_loss = 0.4562875085729894, disc_loss = 0.04883562760972759
Trained batch 246 in epoch 7, gen_loss = 0.45596935500500174, disc_loss = 0.04871370173191373
Trained batch 247 in epoch 7, gen_loss = 0.45586502011264524, disc_loss = 0.04856531446303932
Trained batch 248 in epoch 7, gen_loss = 0.4559524718776764, disc_loss = 0.048437859941588106
Trained batch 249 in epoch 7, gen_loss = 0.4558709546327591, disc_loss = 0.04826148244924843
Trained batch 250 in epoch 7, gen_loss = 0.4560116385796156, disc_loss = 0.048094719553744766
Trained batch 251 in epoch 7, gen_loss = 0.456014693611198, disc_loss = 0.04791932862754616
Trained batch 252 in epoch 7, gen_loss = 0.4559772194845403, disc_loss = 0.04775056839651859
Trained batch 253 in epoch 7, gen_loss = 0.45598866526536114, disc_loss = 0.04758079272812218
Trained batch 254 in epoch 7, gen_loss = 0.4561561184770921, disc_loss = 0.04741124765691804
Trained batch 255 in epoch 7, gen_loss = 0.45602153963409364, disc_loss = 0.04728459992475109
Trained batch 256 in epoch 7, gen_loss = 0.45618303056356974, disc_loss = 0.04723560941271513
Trained batch 257 in epoch 7, gen_loss = 0.4559540969225787, disc_loss = 0.04717946965824957
Trained batch 258 in epoch 7, gen_loss = 0.45602840104618586, disc_loss = 0.04701895427325575
Trained batch 259 in epoch 7, gen_loss = 0.4561307985049028, disc_loss = 0.0468801700635455
Trained batch 260 in epoch 7, gen_loss = 0.4563203470003559, disc_loss = 0.04677293430193117
Trained batch 261 in epoch 7, gen_loss = 0.45650377300859407, disc_loss = 0.04661870725587977
Trained batch 262 in epoch 7, gen_loss = 0.45621414680897965, disc_loss = 0.046597044693638956
Trained batch 263 in epoch 7, gen_loss = 0.4561788988384334, disc_loss = 0.04648595873202959
Trained batch 264 in epoch 7, gen_loss = 0.4561405415804881, disc_loss = 0.04638195238691175
Trained batch 265 in epoch 7, gen_loss = 0.45606490992065657, disc_loss = 0.0462889999301782
Trained batch 266 in epoch 7, gen_loss = 0.4556689862901352, disc_loss = 0.04615586114112525
Trained batch 267 in epoch 7, gen_loss = 0.4559477136206271, disc_loss = 0.04600614002634729
Trained batch 268 in epoch 7, gen_loss = 0.4559602606695381, disc_loss = 0.04586316441050748
Trained batch 269 in epoch 7, gen_loss = 0.4563033682328683, disc_loss = 0.04572004684488531
Trained batch 270 in epoch 7, gen_loss = 0.4564498256053432, disc_loss = 0.046105568015404955
Trained batch 271 in epoch 7, gen_loss = 0.45670832255307364, disc_loss = 0.045954947575570684
Trained batch 272 in epoch 7, gen_loss = 0.45683131102240565, disc_loss = 0.04598857891906203
Trained batch 273 in epoch 7, gen_loss = 0.45658810937056576, disc_loss = 0.04645049466962253
Trained batch 274 in epoch 7, gen_loss = 0.45667454892938786, disc_loss = 0.046467665064741266
Trained batch 275 in epoch 7, gen_loss = 0.45697934536830237, disc_loss = 0.04633716194876942
Trained batch 276 in epoch 7, gen_loss = 0.45701028455035353, disc_loss = 0.046187448468301376
Trained batch 277 in epoch 7, gen_loss = 0.4566494723875746, disc_loss = 0.04632159216805167
Trained batch 278 in epoch 7, gen_loss = 0.45671485914551657, disc_loss = 0.04618586150688991
Trained batch 279 in epoch 7, gen_loss = 0.45682505326611655, disc_loss = 0.04625772689635466
Trained batch 280 in epoch 7, gen_loss = 0.45701627756777186, disc_loss = 0.04614016644199283
Trained batch 281 in epoch 7, gen_loss = 0.45695274117145135, disc_loss = 0.04611730650694816
Trained batch 282 in epoch 7, gen_loss = 0.4573653989040388, disc_loss = 0.0463964510626775
Trained batch 283 in epoch 7, gen_loss = 0.45729190006222525, disc_loss = 0.04651681219496515
Trained batch 284 in epoch 7, gen_loss = 0.4574299969171223, disc_loss = 0.0464145355171671
Trained batch 285 in epoch 7, gen_loss = 0.4576721952094898, disc_loss = 0.04644439276796277
Trained batch 286 in epoch 7, gen_loss = 0.4574432152904285, disc_loss = 0.04629674163656731
Trained batch 287 in epoch 7, gen_loss = 0.45751529569841093, disc_loss = 0.046284609142781444
Trained batch 288 in epoch 7, gen_loss = 0.45726727439045495, disc_loss = 0.046847597826401154
Trained batch 289 in epoch 7, gen_loss = 0.4573269744371546, disc_loss = 0.04675782203899118
Trained batch 290 in epoch 7, gen_loss = 0.4571607518441898, disc_loss = 0.046736900369825536
Trained batch 291 in epoch 7, gen_loss = 0.45709868173484935, disc_loss = 0.046669614531597355
Trained batch 292 in epoch 7, gen_loss = 0.45718053420655963, disc_loss = 0.04653778180333789
Trained batch 293 in epoch 7, gen_loss = 0.4573663525840863, disc_loss = 0.04643723112847783
Trained batch 294 in epoch 7, gen_loss = 0.4575003799745592, disc_loss = 0.04636809654312871
Trained batch 295 in epoch 7, gen_loss = 0.45764518106305924, disc_loss = 0.046233700388551666
Trained batch 296 in epoch 7, gen_loss = 0.45767533056663745, disc_loss = 0.04610741666050923
Trained batch 297 in epoch 7, gen_loss = 0.45770752449963714, disc_loss = 0.04620730987712491
Trained batch 298 in epoch 7, gen_loss = 0.45775777839099285, disc_loss = 0.046068288677101055
Trained batch 299 in epoch 7, gen_loss = 0.4577887068192164, disc_loss = 0.046091748443432154
Trained batch 300 in epoch 7, gen_loss = 0.4578776112030511, disc_loss = 0.04599141582469162
Trained batch 301 in epoch 7, gen_loss = 0.4581589963262444, disc_loss = 0.046562399818494124
Trained batch 302 in epoch 7, gen_loss = 0.458078402890624, disc_loss = 0.04647018052729787
Trained batch 303 in epoch 7, gen_loss = 0.45776676710106823, disc_loss = 0.046429764447231334
Trained batch 304 in epoch 7, gen_loss = 0.4575949062089451, disc_loss = 0.046341573683636596
Trained batch 305 in epoch 7, gen_loss = 0.45762331550027807, disc_loss = 0.046250152448800944
Trained batch 306 in epoch 7, gen_loss = 0.45754374054045166, disc_loss = 0.04630978103781708
Trained batch 307 in epoch 7, gen_loss = 0.45743964776977314, disc_loss = 0.04619640439549195
Trained batch 308 in epoch 7, gen_loss = 0.45752884143764533, disc_loss = 0.04611708318308285
Trained batch 309 in epoch 7, gen_loss = 0.4575875202494283, disc_loss = 0.04606027027381764
Trained batch 310 in epoch 7, gen_loss = 0.4575007360464507, disc_loss = 0.046049068509705866
Trained batch 311 in epoch 7, gen_loss = 0.4573361605214767, disc_loss = 0.04608900493864591
Trained batch 312 in epoch 7, gen_loss = 0.4573910939998139, disc_loss = 0.04608747477199847
Trained batch 313 in epoch 7, gen_loss = 0.4575618726622527, disc_loss = 0.046008598467240196
Trained batch 314 in epoch 7, gen_loss = 0.45767234109696886, disc_loss = 0.04597939508745358
Trained batch 315 in epoch 7, gen_loss = 0.45770166503100457, disc_loss = 0.04615855045304221
Trained batch 316 in epoch 7, gen_loss = 0.45749279856681824, disc_loss = 0.046235229107565966
Trained batch 317 in epoch 7, gen_loss = 0.4577078269150272, disc_loss = 0.04637426039959603
Trained batch 318 in epoch 7, gen_loss = 0.45767419960431543, disc_loss = 0.04636081785027837
Trained batch 319 in epoch 7, gen_loss = 0.4577849755063653, disc_loss = 0.04626269249274628
Trained batch 320 in epoch 7, gen_loss = 0.4576648506234368, disc_loss = 0.04613453279339311
Trained batch 321 in epoch 7, gen_loss = 0.45744477397536637, disc_loss = 0.046025009708687295
Trained batch 322 in epoch 7, gen_loss = 0.4574899339454462, disc_loss = 0.045924247491920235
Trained batch 323 in epoch 7, gen_loss = 0.45761874069770175, disc_loss = 0.04579827495430953
Trained batch 324 in epoch 7, gen_loss = 0.45773783463698164, disc_loss = 0.04616734351246403
Trained batch 325 in epoch 7, gen_loss = 0.45742531349322546, disc_loss = 0.04633487969139831
Trained batch 326 in epoch 7, gen_loss = 0.45734943508737314, disc_loss = 0.04642368126404258
Trained batch 327 in epoch 7, gen_loss = 0.4575100126789837, disc_loss = 0.047142011796340075
Trained batch 328 in epoch 7, gen_loss = 0.45716225983161696, disc_loss = 0.04727772840845051
Trained batch 329 in epoch 7, gen_loss = 0.4572315131172989, disc_loss = 0.04722605874959492
Trained batch 330 in epoch 7, gen_loss = 0.45715954683698556, disc_loss = 0.04723506422116902
Trained batch 331 in epoch 7, gen_loss = 0.4571039384926658, disc_loss = 0.0472129071033167
Trained batch 332 in epoch 7, gen_loss = 0.45710036793986597, disc_loss = 0.0472062949899461
Trained batch 333 in epoch 7, gen_loss = 0.45705346441911365, disc_loss = 0.04716061818703429
Trained batch 334 in epoch 7, gen_loss = 0.45693759722496147, disc_loss = 0.04713223225284201
Trained batch 335 in epoch 7, gen_loss = 0.45711447671055794, disc_loss = 0.04709219402727848
Trained batch 336 in epoch 7, gen_loss = 0.4571955438360616, disc_loss = 0.04710354300171623
Trained batch 337 in epoch 7, gen_loss = 0.45719017017875196, disc_loss = 0.047172424511587215
Trained batch 338 in epoch 7, gen_loss = 0.45714780846528247, disc_loss = 0.04709008557084607
Trained batch 339 in epoch 7, gen_loss = 0.457369092194473, disc_loss = 0.04699232332983657
Trained batch 340 in epoch 7, gen_loss = 0.4573580895351175, disc_loss = 0.04696298045545948
Trained batch 341 in epoch 7, gen_loss = 0.4573112168507269, disc_loss = 0.04700497651271174
Trained batch 342 in epoch 7, gen_loss = 0.45721945687911253, disc_loss = 0.04698170378462088
Trained batch 343 in epoch 7, gen_loss = 0.4573031117229961, disc_loss = 0.046892988892152994
Trained batch 344 in epoch 7, gen_loss = 0.45751048559727875, disc_loss = 0.047046404716599245
Trained batch 345 in epoch 7, gen_loss = 0.4574158171870116, disc_loss = 0.04705146076346107
Trained batch 346 in epoch 7, gen_loss = 0.4573838034864805, disc_loss = 0.04694078998071187
Trained batch 347 in epoch 7, gen_loss = 0.4574388465148279, disc_loss = 0.04692164314081143
Trained batch 348 in epoch 7, gen_loss = 0.4574264558645921, disc_loss = 0.046808510371630634
Trained batch 349 in epoch 7, gen_loss = 0.45752460607460566, disc_loss = 0.046784062240538854
Trained batch 350 in epoch 7, gen_loss = 0.4576348082462267, disc_loss = 0.046761964380136155
Trained batch 351 in epoch 7, gen_loss = 0.4576554457572373, disc_loss = 0.04668204391518058
Trained batch 352 in epoch 7, gen_loss = 0.45766875747243, disc_loss = 0.046732523648738436
Trained batch 353 in epoch 7, gen_loss = 0.4576688413060991, disc_loss = 0.04681659254540116
Trained batch 354 in epoch 7, gen_loss = 0.45775777999783906, disc_loss = 0.04670815374308698
Trained batch 355 in epoch 7, gen_loss = 0.4578653005569169, disc_loss = 0.046699870805507214
Trained batch 356 in epoch 7, gen_loss = 0.45786660876260754, disc_loss = 0.046589971620443406
Trained batch 357 in epoch 7, gen_loss = 0.4578821751491984, disc_loss = 0.046541058800479804
Trained batch 358 in epoch 7, gen_loss = 0.4578500003203708, disc_loss = 0.046437464461176754
Trained batch 359 in epoch 7, gen_loss = 0.45782734379172324, disc_loss = 0.046375494930220564
Trained batch 360 in epoch 7, gen_loss = 0.4579050523587541, disc_loss = 0.046278566244597495
Trained batch 361 in epoch 7, gen_loss = 0.4579091463135092, disc_loss = 0.046187968110377536
Trained batch 362 in epoch 7, gen_loss = 0.4578452850012083, disc_loss = 0.046168466654064814
Trained batch 363 in epoch 7, gen_loss = 0.45782326882357127, disc_loss = 0.046569663047493735
Trained batch 364 in epoch 7, gen_loss = 0.45808393857250473, disc_loss = 0.04656149032461929
Trained batch 365 in epoch 7, gen_loss = 0.45820396552320386, disc_loss = 0.04663725616537605
Trained batch 366 in epoch 7, gen_loss = 0.45831878324945224, disc_loss = 0.04671046190466275
Trained batch 367 in epoch 7, gen_loss = 0.45835868552651093, disc_loss = 0.046765492944320176
Trained batch 368 in epoch 7, gen_loss = 0.4582396304704309, disc_loss = 0.046839881030877994
Trained batch 369 in epoch 7, gen_loss = 0.45847394128103514, disc_loss = 0.046767960724143964
Trained batch 370 in epoch 7, gen_loss = 0.45854522283829124, disc_loss = 0.0467402929442651
Trained batch 371 in epoch 7, gen_loss = 0.45874034981894235, disc_loss = 0.04669490917610826
Trained batch 372 in epoch 7, gen_loss = 0.4589459246508877, disc_loss = 0.046835363913706976
Trained batch 373 in epoch 7, gen_loss = 0.4588869018828805, disc_loss = 0.046894932657549966
Trained batch 374 in epoch 7, gen_loss = 0.4588671871026357, disc_loss = 0.04683585898950696
Trained batch 375 in epoch 7, gen_loss = 0.45870038121938705, disc_loss = 0.04680018555843569
Trained batch 376 in epoch 7, gen_loss = 0.45878831650913554, disc_loss = 0.046790220553613704
Trained batch 377 in epoch 7, gen_loss = 0.459087332089742, disc_loss = 0.04669028032625281
Trained batch 378 in epoch 7, gen_loss = 0.4590836508607487, disc_loss = 0.04658361905104527
Trained batch 379 in epoch 7, gen_loss = 0.45907767650328185, disc_loss = 0.046477765638969444
Trained batch 380 in epoch 7, gen_loss = 0.45924488061995017, disc_loss = 0.04639380398081747
Trained batch 381 in epoch 7, gen_loss = 0.45931227294562377, disc_loss = 0.04629731399899456
Trained batch 382 in epoch 7, gen_loss = 0.4593633787594638, disc_loss = 0.0462145926552404
Trained batch 383 in epoch 7, gen_loss = 0.45923481485806406, disc_loss = 0.04610557075041773
Trained batch 384 in epoch 7, gen_loss = 0.4591518388166056, disc_loss = 0.04599574570144926
Trained batch 385 in epoch 7, gen_loss = 0.45922863684169984, disc_loss = 0.045894027079595494
Trained batch 386 in epoch 7, gen_loss = 0.4593618826348652, disc_loss = 0.04579503477120276
Trained batch 387 in epoch 7, gen_loss = 0.4594907444162467, disc_loss = 0.04568500385305259
Trained batch 388 in epoch 7, gen_loss = 0.459537369426541, disc_loss = 0.045578464917757175
Trained batch 389 in epoch 7, gen_loss = 0.4594112224303759, disc_loss = 0.0454885720460413
Trained batch 390 in epoch 7, gen_loss = 0.4594959213453181, disc_loss = 0.04546823606188016
Trained batch 391 in epoch 7, gen_loss = 0.45969923730103335, disc_loss = 0.045411037420735184
Trained batch 392 in epoch 7, gen_loss = 0.4598159008202055, disc_loss = 0.04532313701796224
Trained batch 393 in epoch 7, gen_loss = 0.4598945801330702, disc_loss = 0.04526828179729223
Trained batch 394 in epoch 7, gen_loss = 0.459725121003163, disc_loss = 0.045194393079845775
Trained batch 395 in epoch 7, gen_loss = 0.4597523377248735, disc_loss = 0.04514658174917309
Trained batch 396 in epoch 7, gen_loss = 0.45971522230645573, disc_loss = 0.04508274104340607
Trained batch 397 in epoch 7, gen_loss = 0.45972259312718355, disc_loss = 0.04500803257275522
Trained batch 398 in epoch 7, gen_loss = 0.45959961653353276, disc_loss = 0.0450592137876674
Trained batch 399 in epoch 7, gen_loss = 0.45936890959739685, disc_loss = 0.04501720044238027
Trained batch 400 in epoch 7, gen_loss = 0.45925507246704766, disc_loss = 0.04506153335964349
Trained batch 401 in epoch 7, gen_loss = 0.4594319211458092, disc_loss = 0.04499361643611699
Trained batch 402 in epoch 7, gen_loss = 0.45980077175881073, disc_loss = 0.044965964891640446
Trained batch 403 in epoch 7, gen_loss = 0.4596858627282747, disc_loss = 0.04487013318034184
Trained batch 404 in epoch 7, gen_loss = 0.45994123816490173, disc_loss = 0.04479040540812284
Trained batch 405 in epoch 7, gen_loss = 0.45971192280059964, disc_loss = 0.04472106877368017
Trained batch 406 in epoch 7, gen_loss = 0.4593902734046486, disc_loss = 0.044732337552683396
Trained batch 407 in epoch 7, gen_loss = 0.45942197499029774, disc_loss = 0.044641921632836444
Trained batch 408 in epoch 7, gen_loss = 0.4593784219624069, disc_loss = 0.0445481082111424
Trained batch 409 in epoch 7, gen_loss = 0.4593574806684401, disc_loss = 0.044559923925709614
Trained batch 410 in epoch 7, gen_loss = 0.45925229961854697, disc_loss = 0.04449232779907792
Trained batch 411 in epoch 7, gen_loss = 0.45921787077072757, disc_loss = 0.04439907682917162
Trained batch 412 in epoch 7, gen_loss = 0.45913417518283206, disc_loss = 0.044396781649544255
Trained batch 413 in epoch 7, gen_loss = 0.45925632392726656, disc_loss = 0.04450831188908036
Trained batch 414 in epoch 7, gen_loss = 0.45905446453266835, disc_loss = 0.04443881769372846
Trained batch 415 in epoch 7, gen_loss = 0.45896997739775824, disc_loss = 0.04445168581094969
Trained batch 416 in epoch 7, gen_loss = 0.4588890552377815, disc_loss = 0.04438132847931763
Trained batch 417 in epoch 7, gen_loss = 0.4590172313474582, disc_loss = 0.04453971475623459
Trained batch 418 in epoch 7, gen_loss = 0.45885493156449036, disc_loss = 0.044558233115266396
Trained batch 419 in epoch 7, gen_loss = 0.4587156819445746, disc_loss = 0.04465707044527378
Trained batch 420 in epoch 7, gen_loss = 0.4587708841876576, disc_loss = 0.04467713720311196
Trained batch 421 in epoch 7, gen_loss = 0.4586800285990204, disc_loss = 0.04466774501623718
Trained batch 422 in epoch 7, gen_loss = 0.45872813435029197, disc_loss = 0.044616930827996025
Trained batch 423 in epoch 7, gen_loss = 0.4587961625096933, disc_loss = 0.0445548577200103
Trained batch 424 in epoch 7, gen_loss = 0.45881642916623283, disc_loss = 0.044737741673803504
Trained batch 425 in epoch 7, gen_loss = 0.45890406879460865, disc_loss = 0.045019148423187785
Trained batch 426 in epoch 7, gen_loss = 0.4589742438156655, disc_loss = 0.045137060233075565
Trained batch 427 in epoch 7, gen_loss = 0.4589262441775509, disc_loss = 0.04521471993817086
Trained batch 428 in epoch 7, gen_loss = 0.45881261643552, disc_loss = 0.04532414265595689
Trained batch 429 in epoch 7, gen_loss = 0.45873762078063435, disc_loss = 0.0453169881241656
Trained batch 430 in epoch 7, gen_loss = 0.45871480448893215, disc_loss = 0.04523847746368921
Trained batch 431 in epoch 7, gen_loss = 0.4585928707211106, disc_loss = 0.045157037287868594
Trained batch 432 in epoch 7, gen_loss = 0.458441196082646, disc_loss = 0.04513488901837129
Trained batch 433 in epoch 7, gen_loss = 0.4585471426561681, disc_loss = 0.04504716451964363
Trained batch 434 in epoch 7, gen_loss = 0.45842627266357683, disc_loss = 0.044970630356057105
Trained batch 435 in epoch 7, gen_loss = 0.4582778770442403, disc_loss = 0.044887869493339484
Trained batch 436 in epoch 7, gen_loss = 0.45819582171243717, disc_loss = 0.0447960515283858
Trained batch 437 in epoch 7, gen_loss = 0.4583186090128607, disc_loss = 0.04470750609929482
Trained batch 438 in epoch 7, gen_loss = 0.4582626491038294, disc_loss = 0.044629582636172886
Trained batch 439 in epoch 7, gen_loss = 0.45822851630774414, disc_loss = 0.044539499711986126
Trained batch 440 in epoch 7, gen_loss = 0.4583949712939273, disc_loss = 0.0444652230078629
Trained batch 441 in epoch 7, gen_loss = 0.4583519080915063, disc_loss = 0.04447409244016133
Trained batch 442 in epoch 7, gen_loss = 0.4584857809355243, disc_loss = 0.04444232759797529
Trained batch 443 in epoch 7, gen_loss = 0.4586553483664452, disc_loss = 0.04436184736629445
Trained batch 444 in epoch 7, gen_loss = 0.4584449593940478, disc_loss = 0.044383844588307686
Trained batch 445 in epoch 7, gen_loss = 0.45845385584061454, disc_loss = 0.044316102981863906
Trained batch 446 in epoch 7, gen_loss = 0.45872366001675324, disc_loss = 0.04430190898984321
Trained batch 447 in epoch 7, gen_loss = 0.4584858112835458, disc_loss = 0.04423609906215071
Trained batch 448 in epoch 7, gen_loss = 0.4586996027249801, disc_loss = 0.0441589473216755
Trained batch 449 in epoch 7, gen_loss = 0.458591537144449, disc_loss = 0.04407284196104026
Trained batch 450 in epoch 7, gen_loss = 0.4586761031473291, disc_loss = 0.04415177409392585
Trained batch 451 in epoch 7, gen_loss = 0.45868966946032197, disc_loss = 0.044123941686816215
Trained batch 452 in epoch 7, gen_loss = 0.45861552632670793, disc_loss = 0.044080263748456604
Trained batch 453 in epoch 7, gen_loss = 0.45855809367438244, disc_loss = 0.043992597841050494
Trained batch 454 in epoch 7, gen_loss = 0.45853486814341704, disc_loss = 0.04392923225935262
Trained batch 455 in epoch 7, gen_loss = 0.4585922279378824, disc_loss = 0.04483953005125697
Trained batch 456 in epoch 7, gen_loss = 0.45836593918257784, disc_loss = 0.04486611365193921
Trained batch 457 in epoch 7, gen_loss = 0.4581802352677266, disc_loss = 0.045072543182141885
Trained batch 458 in epoch 7, gen_loss = 0.45815158662972627, disc_loss = 0.045342502352114046
Trained batch 459 in epoch 7, gen_loss = 0.4581102073840473, disc_loss = 0.04527805860954053
Trained batch 460 in epoch 7, gen_loss = 0.4579790965724664, disc_loss = 0.0452752768333775
Trained batch 461 in epoch 7, gen_loss = 0.4580098632481191, disc_loss = 0.04526807431855291
Trained batch 462 in epoch 7, gen_loss = 0.45788498889035334, disc_loss = 0.045219858279089656
Trained batch 463 in epoch 7, gen_loss = 0.45784079803731936, disc_loss = 0.04534278009919819
Trained batch 464 in epoch 7, gen_loss = 0.4577812539633884, disc_loss = 0.045390769225915756
Trained batch 465 in epoch 7, gen_loss = 0.45787146310182086, disc_loss = 0.04533707468356745
Trained batch 466 in epoch 7, gen_loss = 0.45787413491682016, disc_loss = 0.04529984452067705
Trained batch 467 in epoch 7, gen_loss = 0.4579296002530644, disc_loss = 0.045394513234157816
Trained batch 468 in epoch 7, gen_loss = 0.4576999935895395, disc_loss = 0.04587867095429045
Trained batch 469 in epoch 7, gen_loss = 0.4576331581841124, disc_loss = 0.045813743268298186
Trained batch 470 in epoch 7, gen_loss = 0.4575759629914715, disc_loss = 0.04582441234891946
Trained batch 471 in epoch 7, gen_loss = 0.4573861075786211, disc_loss = 0.045995943143202184
Trained batch 472 in epoch 7, gen_loss = 0.4575820047936026, disc_loss = 0.04620648125613829
Trained batch 473 in epoch 7, gen_loss = 0.4574905503777009, disc_loss = 0.04620019725046439
Trained batch 474 in epoch 7, gen_loss = 0.45740323487081025, disc_loss = 0.04611384595254142
Trained batch 475 in epoch 7, gen_loss = 0.4573531256002538, disc_loss = 0.04611064768699585
Trained batch 476 in epoch 7, gen_loss = 0.45724981086059185, disc_loss = 0.04604947785222102
Trained batch 477 in epoch 7, gen_loss = 0.4573585160357184, disc_loss = 0.04597739292119696
Trained batch 478 in epoch 7, gen_loss = 0.45742148758225254, disc_loss = 0.04592250648152962
Trained batch 479 in epoch 7, gen_loss = 0.45740522928535937, disc_loss = 0.04584128931116235
Trained batch 480 in epoch 7, gen_loss = 0.4574025008138153, disc_loss = 0.045780887846155346
Trained batch 481 in epoch 7, gen_loss = 0.45732125163820275, disc_loss = 0.045710622713151405
Trained batch 482 in epoch 7, gen_loss = 0.45731152677387926, disc_loss = 0.04565000015515333
Trained batch 483 in epoch 7, gen_loss = 0.45735936944396044, disc_loss = 0.04558350630479765
Trained batch 484 in epoch 7, gen_loss = 0.4573686422146473, disc_loss = 0.045506321989748744
Trained batch 485 in epoch 7, gen_loss = 0.45739134815004134, disc_loss = 0.04542380062251931
Trained batch 486 in epoch 7, gen_loss = 0.4573940901540878, disc_loss = 0.045343419634957
Trained batch 487 in epoch 7, gen_loss = 0.4572972517277374, disc_loss = 0.04530518726287333
Trained batch 488 in epoch 7, gen_loss = 0.4570816593789372, disc_loss = 0.04536262402789008
Trained batch 489 in epoch 7, gen_loss = 0.45706094400006897, disc_loss = 0.0453132495611944
Trained batch 490 in epoch 7, gen_loss = 0.4571328433249487, disc_loss = 0.045270096626826954
Trained batch 491 in epoch 7, gen_loss = 0.4570450999630176, disc_loss = 0.04521182338315312
Trained batch 492 in epoch 7, gen_loss = 0.45702996384541356, disc_loss = 0.045251244855251234
Trained batch 493 in epoch 7, gen_loss = 0.4570330098452356, disc_loss = 0.04538266692425573
Trained batch 494 in epoch 7, gen_loss = 0.4570983485742049, disc_loss = 0.04532777810648008
Trained batch 495 in epoch 7, gen_loss = 0.45706749094590066, disc_loss = 0.04535637658339129
Trained batch 496 in epoch 7, gen_loss = 0.4569572964664436, disc_loss = 0.04544276794206943
Trained batch 497 in epoch 7, gen_loss = 0.4569129132961174, disc_loss = 0.0453743637192538
Trained batch 498 in epoch 7, gen_loss = 0.4567359322178101, disc_loss = 0.045387247975314696
Trained batch 499 in epoch 7, gen_loss = 0.4567449907064438, disc_loss = 0.04536140205571428
Trained batch 500 in epoch 7, gen_loss = 0.4568723285507537, disc_loss = 0.04582301813397118
Trained batch 501 in epoch 7, gen_loss = 0.45669973021246996, disc_loss = 0.04594749054060766
Trained batch 502 in epoch 7, gen_loss = 0.4564726403053428, disc_loss = 0.04591786863502656
Trained batch 503 in epoch 7, gen_loss = 0.45651651575924856, disc_loss = 0.04600558393599746
Trained batch 504 in epoch 7, gen_loss = 0.4565934823291137, disc_loss = 0.04651247781406313
Trained batch 505 in epoch 7, gen_loss = 0.4567809157927517, disc_loss = 0.046493902543408745
Trained batch 506 in epoch 7, gen_loss = 0.45676676843763575, disc_loss = 0.04645648393164622
Trained batch 507 in epoch 7, gen_loss = 0.4567213050258441, disc_loss = 0.046398350457921185
Trained batch 508 in epoch 7, gen_loss = 0.4566937913360671, disc_loss = 0.046570751020567736
Trained batch 509 in epoch 7, gen_loss = 0.45674807931862627, disc_loss = 0.04660695683366309
Trained batch 510 in epoch 7, gen_loss = 0.4566480966463481, disc_loss = 0.04677533048000952
Trained batch 511 in epoch 7, gen_loss = 0.45666891388827935, disc_loss = 0.04672475540291998
Trained batch 512 in epoch 7, gen_loss = 0.4567610814906003, disc_loss = 0.046675051395921124
Trained batch 513 in epoch 7, gen_loss = 0.45666149635491204, disc_loss = 0.04664835554016718
Trained batch 514 in epoch 7, gen_loss = 0.45655474373437827, disc_loss = 0.04658353439242877
Trained batch 515 in epoch 7, gen_loss = 0.4562736510537391, disc_loss = 0.046505997415411816
Trained batch 516 in epoch 7, gen_loss = 0.45610893147365267, disc_loss = 0.04651894343600787
Trained batch 517 in epoch 7, gen_loss = 0.45587634539742267, disc_loss = 0.046569719546992315
Trained batch 518 in epoch 7, gen_loss = 0.45600595530517296, disc_loss = 0.04656965747387696
Trained batch 519 in epoch 7, gen_loss = 0.4559679703070567, disc_loss = 0.046513040366922866
Trained batch 520 in epoch 7, gen_loss = 0.4560898899345618, disc_loss = 0.0464604179658203
Trained batch 521 in epoch 7, gen_loss = 0.45609315932938876, disc_loss = 0.046414434998581666
Trained batch 522 in epoch 7, gen_loss = 0.45598016437107475, disc_loss = 0.04634755572177698
Trained batch 523 in epoch 7, gen_loss = 0.45599667949758416, disc_loss = 0.04635070049059968
Trained batch 524 in epoch 7, gen_loss = 0.4558872674192701, disc_loss = 0.04635583424275475
Trained batch 525 in epoch 7, gen_loss = 0.4560212857256371, disc_loss = 0.04634053739692534
Trained batch 526 in epoch 7, gen_loss = 0.4560320433335241, disc_loss = 0.046299403714920896
Trained batch 527 in epoch 7, gen_loss = 0.4559892403018294, disc_loss = 0.04644106568505804
Trained batch 528 in epoch 7, gen_loss = 0.4557086127917573, disc_loss = 0.04665326213134921
Trained batch 529 in epoch 7, gen_loss = 0.4556620789586373, disc_loss = 0.046698373768320485
Trained batch 530 in epoch 7, gen_loss = 0.45558505840669694, disc_loss = 0.04676610729639574
Trained batch 531 in epoch 7, gen_loss = 0.4556180336197516, disc_loss = 0.04690594321486183
Trained batch 532 in epoch 7, gen_loss = 0.4554633246577479, disc_loss = 0.04699125410822931
Trained batch 533 in epoch 7, gen_loss = 0.4554003755028328, disc_loss = 0.047099285708018315
Trained batch 534 in epoch 7, gen_loss = 0.45537830691471276, disc_loss = 0.0474163514583711
Trained batch 535 in epoch 7, gen_loss = 0.4553731017148317, disc_loss = 0.04736709935415133
Trained batch 536 in epoch 7, gen_loss = 0.4554662920909221, disc_loss = 0.04743304841863807
Trained batch 537 in epoch 7, gen_loss = 0.4553491744631728, disc_loss = 0.047632449553659716
Trained batch 538 in epoch 7, gen_loss = 0.4554845761500838, disc_loss = 0.04772554002209793
Trained batch 539 in epoch 7, gen_loss = 0.45561318386484073, disc_loss = 0.047789070701347316
Trained batch 540 in epoch 7, gen_loss = 0.4556236576130562, disc_loss = 0.04779814915127308
Trained batch 541 in epoch 7, gen_loss = 0.45545187581509244, disc_loss = 0.04776908663604958
Trained batch 542 in epoch 7, gen_loss = 0.4553221379086019, disc_loss = 0.04771897174944521
Trained batch 543 in epoch 7, gen_loss = 0.4553747895885916, disc_loss = 0.04772100944939987
Trained batch 544 in epoch 7, gen_loss = 0.4553722477834159, disc_loss = 0.0477163078122422
Trained batch 545 in epoch 7, gen_loss = 0.45552504477483446, disc_loss = 0.047687920869239384
Trained batch 546 in epoch 7, gen_loss = 0.45572217672355, disc_loss = 0.047662345615472695
Trained batch 547 in epoch 7, gen_loss = 0.45566926592022833, disc_loss = 0.047631788979722936
Trained batch 548 in epoch 7, gen_loss = 0.4556447681182069, disc_loss = 0.047570808376278896
Trained batch 549 in epoch 7, gen_loss = 0.45563008292154833, disc_loss = 0.047526269420896744
Trained batch 550 in epoch 7, gen_loss = 0.4555555820573263, disc_loss = 0.04748052416222268
Trained batch 551 in epoch 7, gen_loss = 0.45561576121743175, disc_loss = 0.04741581988924156
Trained batch 552 in epoch 7, gen_loss = 0.4556005990526775, disc_loss = 0.04740996127249252
Trained batch 553 in epoch 7, gen_loss = 0.45563017859355637, disc_loss = 0.04734332270757211
Trained batch 554 in epoch 7, gen_loss = 0.45577933841997437, disc_loss = 0.04748660951877969
Trained batch 555 in epoch 7, gen_loss = 0.4556474391933825, disc_loss = 0.047536126012568826
Trained batch 556 in epoch 7, gen_loss = 0.4556215090319327, disc_loss = 0.04749673303288593
Trained batch 557 in epoch 7, gen_loss = 0.45564043297562545, disc_loss = 0.04752262766467988
Trained batch 558 in epoch 7, gen_loss = 0.45558900291463345, disc_loss = 0.04746707526788662
Trained batch 559 in epoch 7, gen_loss = 0.4555401318307434, disc_loss = 0.04759300023142714
Trained batch 560 in epoch 7, gen_loss = 0.4556328207520028, disc_loss = 0.047525524441899863
Trained batch 561 in epoch 7, gen_loss = 0.4556872126682797, disc_loss = 0.04757048930679498
Trained batch 562 in epoch 7, gen_loss = 0.4555659887528123, disc_loss = 0.047534963866649446
Trained batch 563 in epoch 7, gen_loss = 0.45551524121076503, disc_loss = 0.04757495274633526
Trained batch 564 in epoch 7, gen_loss = 0.4555655062198639, disc_loss = 0.047686533088820565
Trained batch 565 in epoch 7, gen_loss = 0.45541789875013666, disc_loss = 0.04761354009293402
Trained batch 566 in epoch 7, gen_loss = 0.4552447632927533, disc_loss = 0.047579479111010306
Trained batch 567 in epoch 7, gen_loss = 0.4550944305431675, disc_loss = 0.04755530277599948
Trained batch 568 in epoch 7, gen_loss = 0.45531569245829523, disc_loss = 0.047514604808441864
Trained batch 569 in epoch 7, gen_loss = 0.4554646937470687, disc_loss = 0.04746845417958276
Trained batch 570 in epoch 7, gen_loss = 0.45546471127904237, disc_loss = 0.0473957551433664
Trained batch 571 in epoch 7, gen_loss = 0.4554182049277779, disc_loss = 0.04739738433822091
Trained batch 572 in epoch 7, gen_loss = 0.4554757123218157, disc_loss = 0.04737239793539502
Trained batch 573 in epoch 7, gen_loss = 0.45547112220255753, disc_loss = 0.047438697944207034
Trained batch 574 in epoch 7, gen_loss = 0.45538280704747075, disc_loss = 0.04798576406446164
Trained batch 575 in epoch 7, gen_loss = 0.45541118349259097, disc_loss = 0.048108398031116745
Trained batch 576 in epoch 7, gen_loss = 0.45529632572491413, disc_loss = 0.048160733092992694
Trained batch 577 in epoch 7, gen_loss = 0.45519896403315985, disc_loss = 0.048234944250740784
Trained batch 578 in epoch 7, gen_loss = 0.4551952682010868, disc_loss = 0.048684317248250925
Trained batch 579 in epoch 7, gen_loss = 0.4551662162973963, disc_loss = 0.048764320189566834
Trained batch 580 in epoch 7, gen_loss = 0.4552001271416111, disc_loss = 0.048834084345207335
Trained batch 581 in epoch 7, gen_loss = 0.4552026159062828, disc_loss = 0.04891018165856331
Trained batch 582 in epoch 7, gen_loss = 0.455234250727894, disc_loss = 0.04885363357347687
Trained batch 583 in epoch 7, gen_loss = 0.4551671111624535, disc_loss = 0.048796983336478035
Trained batch 584 in epoch 7, gen_loss = 0.4552202042860862, disc_loss = 0.04876022949201875
Trained batch 585 in epoch 7, gen_loss = 0.4551790268653082, disc_loss = 0.04869264728149698
Trained batch 586 in epoch 7, gen_loss = 0.4552735597453694, disc_loss = 0.04862537237996429
Trained batch 587 in epoch 7, gen_loss = 0.4552413534347703, disc_loss = 0.0485521026908382
Trained batch 588 in epoch 7, gen_loss = 0.4552754747644952, disc_loss = 0.04848227889280203
Trained batch 589 in epoch 7, gen_loss = 0.45513035998506063, disc_loss = 0.048419047811194875
Trained batch 590 in epoch 7, gen_loss = 0.4551690417497896, disc_loss = 0.04837234220987536
Trained batch 591 in epoch 7, gen_loss = 0.45523661878463384, disc_loss = 0.048583943306742164
Trained batch 592 in epoch 7, gen_loss = 0.45525984262535585, disc_loss = 0.048521469139476726
Trained batch 593 in epoch 7, gen_loss = 0.45523332054366167, disc_loss = 0.04848501023323736
Trained batch 594 in epoch 7, gen_loss = 0.4552353987673751, disc_loss = 0.048486388973625644
Trained batch 595 in epoch 7, gen_loss = 0.45525418406964946, disc_loss = 0.04842652671231307
Trained batch 596 in epoch 7, gen_loss = 0.4552986657299987, disc_loss = 0.04841610496759202
Trained batch 597 in epoch 7, gen_loss = 0.4552726292091867, disc_loss = 0.04838686488860016
Trained batch 598 in epoch 7, gen_loss = 0.4553300261198977, disc_loss = 0.04833629287162077
Trained batch 599 in epoch 7, gen_loss = 0.45538071662187574, disc_loss = 0.0482825228490401
Trained batch 600 in epoch 7, gen_loss = 0.45545439176670527, disc_loss = 0.04822296463069312
Trained batch 601 in epoch 7, gen_loss = 0.4555274464957342, disc_loss = 0.048163033699681765
Trained batch 602 in epoch 7, gen_loss = 0.4556086103912214, disc_loss = 0.04810180475164644
Trained batch 603 in epoch 7, gen_loss = 0.45562602461173835, disc_loss = 0.04810816787502463
Trained batch 604 in epoch 7, gen_loss = 0.45573235336414053, disc_loss = 0.048066607268126914
Trained batch 605 in epoch 7, gen_loss = 0.4557956855485935, disc_loss = 0.04804534577225141
Trained batch 606 in epoch 7, gen_loss = 0.45578841828239414, disc_loss = 0.04798670766048158
Trained batch 607 in epoch 7, gen_loss = 0.4557159369517314, disc_loss = 0.04795051986729959
Trained batch 608 in epoch 7, gen_loss = 0.45568210801663267, disc_loss = 0.04788005551780545
Trained batch 609 in epoch 7, gen_loss = 0.45571990360002046, disc_loss = 0.04790900634548276
Trained batch 610 in epoch 7, gen_loss = 0.4555929785079144, disc_loss = 0.04785118588633567
Trained batch 611 in epoch 7, gen_loss = 0.4555263253890611, disc_loss = 0.04780884756093382
Trained batch 612 in epoch 7, gen_loss = 0.4554252132019833, disc_loss = 0.047740312871640184
Trained batch 613 in epoch 7, gen_loss = 0.45549152291558853, disc_loss = 0.047676161436306416
Trained batch 614 in epoch 7, gen_loss = 0.4554905954415236, disc_loss = 0.04761606016711188
Trained batch 615 in epoch 7, gen_loss = 0.455440311317707, disc_loss = 0.0475805218905277
Trained batch 616 in epoch 7, gen_loss = 0.4554515529780179, disc_loss = 0.04754545905920141
Trained batch 617 in epoch 7, gen_loss = 0.45547996369766186, disc_loss = 0.047502658192390836
Trained batch 618 in epoch 7, gen_loss = 0.4555744626988117, disc_loss = 0.047435947818386705
Trained batch 619 in epoch 7, gen_loss = 0.4555941715836525, disc_loss = 0.047368427485813415
Trained batch 620 in epoch 7, gen_loss = 0.4558104215708716, disc_loss = 0.04730359044701353
Trained batch 621 in epoch 7, gen_loss = 0.4558082624455357, disc_loss = 0.04729933402810988
Trained batch 622 in epoch 7, gen_loss = 0.45577138700607694, disc_loss = 0.047281836391610495
Trained batch 623 in epoch 7, gen_loss = 0.45574207814076007, disc_loss = 0.04722120862443729
Trained batch 624 in epoch 7, gen_loss = 0.4557849150657654, disc_loss = 0.04716851274110377
Trained batch 625 in epoch 7, gen_loss = 0.4558606096349966, disc_loss = 0.04711596089074561
Trained batch 626 in epoch 7, gen_loss = 0.45586781971382373, disc_loss = 0.04707631269474313
Trained batch 627 in epoch 7, gen_loss = 0.4558460368851947, disc_loss = 0.04701725194552486
Trained batch 628 in epoch 7, gen_loss = 0.45587481423288534, disc_loss = 0.046955057818498847
Trained batch 629 in epoch 7, gen_loss = 0.4559318876455701, disc_loss = 0.04692034413631532
Trained batch 630 in epoch 7, gen_loss = 0.45603351453215873, disc_loss = 0.04685431683145275
Trained batch 631 in epoch 7, gen_loss = 0.4559616663410694, disc_loss = 0.04679222669801675
Trained batch 632 in epoch 7, gen_loss = 0.45591269351106495, disc_loss = 0.0467411022074962
Trained batch 633 in epoch 7, gen_loss = 0.45598323140234603, disc_loss = 0.046684321689225546
Trained batch 634 in epoch 7, gen_loss = 0.4559127565913313, disc_loss = 0.04662073395713636
Trained batch 635 in epoch 7, gen_loss = 0.45591509890443876, disc_loss = 0.046553603915641166
Trained batch 636 in epoch 7, gen_loss = 0.455954431972848, disc_loss = 0.04650756359148589
Trained batch 637 in epoch 7, gen_loss = 0.4559231303328631, disc_loss = 0.04644518068131807
Trained batch 638 in epoch 7, gen_loss = 0.45611778895060223, disc_loss = 0.04638637306645268
Trained batch 639 in epoch 7, gen_loss = 0.4561427731066942, disc_loss = 0.046323111457240884
Trained batch 640 in epoch 7, gen_loss = 0.4562322500157468, disc_loss = 0.04626130417981672
Trained batch 641 in epoch 7, gen_loss = 0.4561977021605055, disc_loss = 0.046202694934450464
Trained batch 642 in epoch 7, gen_loss = 0.4561723750171543, disc_loss = 0.04613973471063767
Trained batch 643 in epoch 7, gen_loss = 0.45621948513370125, disc_loss = 0.04608558087721062
Trained batch 644 in epoch 7, gen_loss = 0.45622302127438924, disc_loss = 0.04634225141553049
Trained batch 645 in epoch 7, gen_loss = 0.4561329109380858, disc_loss = 0.046429838645329624
Trained batch 646 in epoch 7, gen_loss = 0.45613835206171827, disc_loss = 0.04639686022559829
Trained batch 647 in epoch 7, gen_loss = 0.4562350712072702, disc_loss = 0.04636023292227441
Trained batch 648 in epoch 7, gen_loss = 0.45631037250689255, disc_loss = 0.04635385257760221
Trained batch 649 in epoch 7, gen_loss = 0.4563096430209967, disc_loss = 0.046305642735857806
Trained batch 650 in epoch 7, gen_loss = 0.4562233817375933, disc_loss = 0.046255219869741945
Trained batch 651 in epoch 7, gen_loss = 0.45618304902790513, disc_loss = 0.04622336958022217
Trained batch 652 in epoch 7, gen_loss = 0.4561507089853652, disc_loss = 0.04620964715512581
Trained batch 653 in epoch 7, gen_loss = 0.4560110513405698, disc_loss = 0.046185338421474105
Trained batch 654 in epoch 7, gen_loss = 0.4559523377254719, disc_loss = 0.04626904869530322
Trained batch 655 in epoch 7, gen_loss = 0.4559517806259597, disc_loss = 0.04632527314349384
Trained batch 656 in epoch 7, gen_loss = 0.45591933750852237, disc_loss = 0.0462831355439275
Trained batch 657 in epoch 7, gen_loss = 0.4559272093341706, disc_loss = 0.046269032214258696
Trained batch 658 in epoch 7, gen_loss = 0.455987066980197, disc_loss = 0.046308015705311
Trained batch 659 in epoch 7, gen_loss = 0.4559077308033452, disc_loss = 0.046271890476981006
Trained batch 660 in epoch 7, gen_loss = 0.45591124738939953, disc_loss = 0.046240648129706956
Trained batch 661 in epoch 7, gen_loss = 0.4559940078557438, disc_loss = 0.04619226892432338
Trained batch 662 in epoch 7, gen_loss = 0.4560091635310632, disc_loss = 0.04614925985350969
Trained batch 663 in epoch 7, gen_loss = 0.4561991701912449, disc_loss = 0.046166817665013134
Trained batch 664 in epoch 7, gen_loss = 0.45613051352644324, disc_loss = 0.04612500359640366
Trained batch 665 in epoch 7, gen_loss = 0.4560527771084874, disc_loss = 0.04610278044216189
Trained batch 666 in epoch 7, gen_loss = 0.456088537174365, disc_loss = 0.04604672902260908
Trained batch 667 in epoch 7, gen_loss = 0.45607163962311376, disc_loss = 0.045983602405417
Trained batch 668 in epoch 7, gen_loss = 0.456097528271611, disc_loss = 0.04593179835408915
Trained batch 669 in epoch 7, gen_loss = 0.45606409088889166, disc_loss = 0.04587254522389162
Trained batch 670 in epoch 7, gen_loss = 0.45602694495779567, disc_loss = 0.045808673899790105
Trained batch 671 in epoch 7, gen_loss = 0.4560193760497939, disc_loss = 0.045745333075285
Trained batch 672 in epoch 7, gen_loss = 0.4560836093918175, disc_loss = 0.045685954976627634
Trained batch 673 in epoch 7, gen_loss = 0.4561107503996405, disc_loss = 0.04562197989253576
Trained batch 674 in epoch 7, gen_loss = 0.45597661905818515, disc_loss = 0.04556391498211909
Trained batch 675 in epoch 7, gen_loss = 0.45593628675274595, disc_loss = 0.04550895782824076
Trained batch 676 in epoch 7, gen_loss = 0.4559242502185055, disc_loss = 0.04544904419775375
Trained batch 677 in epoch 7, gen_loss = 0.4558914045756545, disc_loss = 0.04538860457061974
Trained batch 678 in epoch 7, gen_loss = 0.45577193276520506, disc_loss = 0.04532689328267018
Trained batch 679 in epoch 7, gen_loss = 0.4557203643462237, disc_loss = 0.04529106603312197
Trained batch 680 in epoch 7, gen_loss = 0.4556767670068447, disc_loss = 0.04523485653114706
Trained batch 681 in epoch 7, gen_loss = 0.4555760209074468, disc_loss = 0.04518703952509517
Trained batch 682 in epoch 7, gen_loss = 0.45555664745117175, disc_loss = 0.04513191677715853
Trained batch 683 in epoch 7, gen_loss = 0.45567615831281705, disc_loss = 0.04507414168747665
Trained batch 684 in epoch 7, gen_loss = 0.45557344890859003, disc_loss = 0.04502156015152425
Trained batch 685 in epoch 7, gen_loss = 0.4556089604908801, disc_loss = 0.044995091586379175
Trained batch 686 in epoch 7, gen_loss = 0.45557353668337824, disc_loss = 0.04493960168780664
Trained batch 687 in epoch 7, gen_loss = 0.4555345564907373, disc_loss = 0.04488601570720189
Trained batch 688 in epoch 7, gen_loss = 0.45544027352194655, disc_loss = 0.04482856558410097
Trained batch 689 in epoch 7, gen_loss = 0.4553824859684792, disc_loss = 0.04477127809246219
Trained batch 690 in epoch 7, gen_loss = 0.4553721600607059, disc_loss = 0.04471025079274456
Trained batch 691 in epoch 7, gen_loss = 0.4553078619730955, disc_loss = 0.044649361024780274
Trained batch 692 in epoch 7, gen_loss = 0.45523259912390385, disc_loss = 0.04459016655993743
Trained batch 693 in epoch 7, gen_loss = 0.4552149183897876, disc_loss = 0.044533262393968744
Trained batch 694 in epoch 7, gen_loss = 0.45523169207915987, disc_loss = 0.044473553988613565
Trained batch 695 in epoch 7, gen_loss = 0.4552234582945533, disc_loss = 0.04441542730060535
Trained batch 696 in epoch 7, gen_loss = 0.45524341688949715, disc_loss = 0.04437172344826974
Trained batch 697 in epoch 7, gen_loss = 0.4550925859151392, disc_loss = 0.04431818659786925
Trained batch 698 in epoch 7, gen_loss = 0.45512802308380007, disc_loss = 0.04427152329247088
Trained batch 699 in epoch 7, gen_loss = 0.45518610749925886, disc_loss = 0.0442746831446753
Trained batch 700 in epoch 7, gen_loss = 0.4552426787994047, disc_loss = 0.04422439037179163
Trained batch 701 in epoch 7, gen_loss = 0.4551961873246734, disc_loss = 0.044167482471584404
Trained batch 702 in epoch 7, gen_loss = 0.45533675120700984, disc_loss = 0.04411038445477052
Trained batch 703 in epoch 7, gen_loss = 0.45527645251290366, disc_loss = 0.04405256920323485
Trained batch 704 in epoch 7, gen_loss = 0.4553370587369229, disc_loss = 0.04400256467778368
Trained batch 705 in epoch 7, gen_loss = 0.4553421316167113, disc_loss = 0.04395418869900034
Trained batch 706 in epoch 7, gen_loss = 0.4553913447526422, disc_loss = 0.04389778382732379
Trained batch 707 in epoch 7, gen_loss = 0.45535050816623507, disc_loss = 0.043839841181317625
Trained batch 708 in epoch 7, gen_loss = 0.45540960479858733, disc_loss = 0.04379164187266519
Trained batch 709 in epoch 7, gen_loss = 0.45542742492447436, disc_loss = 0.043735439100788094
Trained batch 710 in epoch 7, gen_loss = 0.45542101492861653, disc_loss = 0.04368880806220944
Trained batch 711 in epoch 7, gen_loss = 0.45539398922511704, disc_loss = 0.04365239224496057
Trained batch 712 in epoch 7, gen_loss = 0.4553588093330282, disc_loss = 0.04361572314241867
Trained batch 713 in epoch 7, gen_loss = 0.4553337636030689, disc_loss = 0.04357292612164127
Trained batch 714 in epoch 7, gen_loss = 0.4553173914655939, disc_loss = 0.04351803691588811
Trained batch 715 in epoch 7, gen_loss = 0.455416122295337, disc_loss = 0.04346328233264636
Trained batch 716 in epoch 7, gen_loss = 0.4554318800630929, disc_loss = 0.04341473906317848
Trained batch 717 in epoch 7, gen_loss = 0.455481166461052, disc_loss = 0.04336248336341699
Trained batch 718 in epoch 7, gen_loss = 0.45547542552125636, disc_loss = 0.0433074534651778
Trained batch 719 in epoch 7, gen_loss = 0.4554639554272095, disc_loss = 0.04325112723939431
Trained batch 720 in epoch 7, gen_loss = 0.45543821476368895, disc_loss = 0.04319385848500237
Trained batch 721 in epoch 7, gen_loss = 0.4554390991080831, disc_loss = 0.04313919503000562
Trained batch 722 in epoch 7, gen_loss = 0.4553575605195258, disc_loss = 0.04308674329818377
Trained batch 723 in epoch 7, gen_loss = 0.45535206947043455, disc_loss = 0.04303143336791391
Trained batch 724 in epoch 7, gen_loss = 0.45534571483217434, disc_loss = 0.04297517406208248
Trained batch 725 in epoch 7, gen_loss = 0.455221354632995, disc_loss = 0.042923933610874265
Trained batch 726 in epoch 7, gen_loss = 0.45524759527085734, disc_loss = 0.0428819651939641
Trained batch 727 in epoch 7, gen_loss = 0.45522094747194874, disc_loss = 0.04283098880122262
Trained batch 728 in epoch 7, gen_loss = 0.45521872508018923, disc_loss = 0.04277665473569302
Trained batch 729 in epoch 7, gen_loss = 0.45529795264544554, disc_loss = 0.04272553554021639
Trained batch 730 in epoch 7, gen_loss = 0.45535201967659467, disc_loss = 0.0426771187710177
Trained batch 731 in epoch 7, gen_loss = 0.45537292314031735, disc_loss = 0.04262701667466104
Trained batch 732 in epoch 7, gen_loss = 0.4554215527735498, disc_loss = 0.04258342515257928
Trained batch 733 in epoch 7, gen_loss = 0.45548005771572, disc_loss = 0.04253131156845642
Trained batch 734 in epoch 7, gen_loss = 0.4555825896003619, disc_loss = 0.042479850206093316
Trained batch 735 in epoch 7, gen_loss = 0.45561613887548447, disc_loss = 0.04243145300500581
Trained batch 736 in epoch 7, gen_loss = 0.45577183563964824, disc_loss = 0.04237757079629291
Trained batch 737 in epoch 7, gen_loss = 0.45578259508299634, disc_loss = 0.04232436234445682
Trained batch 738 in epoch 7, gen_loss = 0.4558475555118592, disc_loss = 0.042271238764626996
Trained batch 739 in epoch 7, gen_loss = 0.45582418691467597, disc_loss = 0.04221716724159951
Trained batch 740 in epoch 7, gen_loss = 0.4558226580803211, disc_loss = 0.04216270487788215
Trained batch 741 in epoch 7, gen_loss = 0.45578100895785256, disc_loss = 0.04212222985780203
Trained batch 742 in epoch 7, gen_loss = 0.4557547941101993, disc_loss = 0.042069755327884074
Trained batch 743 in epoch 7, gen_loss = 0.45565337307190384, disc_loss = 0.04201602260832504
Trained batch 744 in epoch 7, gen_loss = 0.4556484025196741, disc_loss = 0.04196419065080633
Trained batch 745 in epoch 7, gen_loss = 0.45558658981291283, disc_loss = 0.04191314004643773
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.530089259147644, disc_loss = 0.011435951106250286
Trained batch 1 in epoch 8, gen_loss = 0.4834541529417038, disc_loss = 0.007242764579132199
Trained batch 2 in epoch 8, gen_loss = 0.4741877218087514, disc_loss = 0.005609943143402536
Trained batch 3 in epoch 8, gen_loss = 0.46264906972646713, disc_loss = 0.005105746211484075
Trained batch 4 in epoch 8, gen_loss = 0.4689898192882538, disc_loss = 0.004809323325753212
Trained batch 5 in epoch 8, gen_loss = 0.46569958329200745, disc_loss = 0.004533256404101849
Trained batch 6 in epoch 8, gen_loss = 0.46077760628291536, disc_loss = 0.0042424575492207494
Trained batch 7 in epoch 8, gen_loss = 0.4549362473189831, disc_loss = 0.004170378495473415
Trained batch 8 in epoch 8, gen_loss = 0.4511410031053755, disc_loss = 0.003990555906461345
Trained batch 9 in epoch 8, gen_loss = 0.4490364998579025, disc_loss = 0.00398755962960422
Trained batch 10 in epoch 8, gen_loss = 0.4457456496628848, disc_loss = 0.0038354272361506114
Trained batch 11 in epoch 8, gen_loss = 0.4509993518392245, disc_loss = 0.0037412431362705925
Trained batch 12 in epoch 8, gen_loss = 0.4552041544364049, disc_loss = 0.003850021560748036
Trained batch 13 in epoch 8, gen_loss = 0.456612623163632, disc_loss = 0.0037443391380033325
Trained batch 14 in epoch 8, gen_loss = 0.45738758047421774, disc_loss = 0.004035170966138442
Trained batch 15 in epoch 8, gen_loss = 0.4592538680881262, disc_loss = 0.004334067256422713
Trained batch 16 in epoch 8, gen_loss = 0.45897047134006724, disc_loss = 0.004290263935485307
Trained batch 17 in epoch 8, gen_loss = 0.4603969868686464, disc_loss = 0.004405561782833602
Trained batch 18 in epoch 8, gen_loss = 0.4609057197445317, disc_loss = 0.004508032438982474
Trained batch 19 in epoch 8, gen_loss = 0.4607397899031639, disc_loss = 0.0045224751578643915
Trained batch 20 in epoch 8, gen_loss = 0.46172547198477243, disc_loss = 0.006259348709136248
Trained batch 21 in epoch 8, gen_loss = 0.4622818651524457, disc_loss = 0.006695481969720938
Trained batch 22 in epoch 8, gen_loss = 0.4614303150902624, disc_loss = 0.006700854627010615
Trained batch 23 in epoch 8, gen_loss = 0.46264959250887233, disc_loss = 0.0069683359082167344
Trained batch 24 in epoch 8, gen_loss = 0.4638967537879944, disc_loss = 0.0069700700044631955
Trained batch 25 in epoch 8, gen_loss = 0.4650130547009982, disc_loss = 0.006926461051289852
Trained batch 26 in epoch 8, gen_loss = 0.46579964293373954, disc_loss = 0.007053180666709387
Trained batch 27 in epoch 8, gen_loss = 0.4676615446805954, disc_loss = 0.0069276104498255464
Trained batch 28 in epoch 8, gen_loss = 0.4688961259249983, disc_loss = 0.006853430845036075
Trained batch 29 in epoch 8, gen_loss = 0.4701331655184428, disc_loss = 0.008478357666172087
Trained batch 30 in epoch 8, gen_loss = 0.4677534959008617, disc_loss = 0.009167779860417209
Trained batch 31 in epoch 8, gen_loss = 0.4704941315576434, disc_loss = 0.0094141903318814
Trained batch 32 in epoch 8, gen_loss = 0.4721174104647203, disc_loss = 0.009389275819006743
Trained batch 33 in epoch 8, gen_loss = 0.4725521259448108, disc_loss = 0.010716920903445604
Trained batch 34 in epoch 8, gen_loss = 0.47078449896403723, disc_loss = 0.013760253860216056
Trained batch 35 in epoch 8, gen_loss = 0.46922652506166035, disc_loss = 0.014293853678585341
Trained batch 36 in epoch 8, gen_loss = 0.4678078479058034, disc_loss = 0.014409307459671353
Trained batch 37 in epoch 8, gen_loss = 0.46663889524183777, disc_loss = 0.014747266528980904
Trained batch 38 in epoch 8, gen_loss = 0.467707029519937, disc_loss = 0.015350725233125
Trained batch 39 in epoch 8, gen_loss = 0.46709050312638284, disc_loss = 0.015985995827941225
Trained batch 40 in epoch 8, gen_loss = 0.4692291203068524, disc_loss = 0.015984258881383915
Trained batch 41 in epoch 8, gen_loss = 0.4668808721360706, disc_loss = 0.016189298254349047
Trained batch 42 in epoch 8, gen_loss = 0.46733964459840643, disc_loss = 0.016124633763548592
Trained batch 43 in epoch 8, gen_loss = 0.4679840843785893, disc_loss = 0.016652652565178207
Trained batch 44 in epoch 8, gen_loss = 0.4684835930665334, disc_loss = 0.01666247008057932
Trained batch 45 in epoch 8, gen_loss = 0.46744795532330224, disc_loss = 0.017145250311485775
Trained batch 46 in epoch 8, gen_loss = 0.46614031018094815, disc_loss = 0.018357662122419224
Trained batch 47 in epoch 8, gen_loss = 0.4646278955042362, disc_loss = 0.01819921785014837
Trained batch 48 in epoch 8, gen_loss = 0.46408926285043056, disc_loss = 0.018241648804586456
Trained batch 49 in epoch 8, gen_loss = 0.46565155923366547, disc_loss = 0.019758827569894492
Trained batch 50 in epoch 8, gen_loss = 0.46448246930159776, disc_loss = 0.02347348531361158
Trained batch 51 in epoch 8, gen_loss = 0.46362052628627193, disc_loss = 0.024353750511251677
Trained batch 52 in epoch 8, gen_loss = 0.46293925676705705, disc_loss = 0.024865194483009993
Trained batch 53 in epoch 8, gen_loss = 0.4623115294509464, disc_loss = 0.026073931712070824
Trained batch 54 in epoch 8, gen_loss = 0.4621690815145319, disc_loss = 0.028293328016827053
Trained batch 55 in epoch 8, gen_loss = 0.46179601337228504, disc_loss = 0.029139327180538594
Trained batch 56 in epoch 8, gen_loss = 0.4631840889913994, disc_loss = 0.0305976162117236
Trained batch 57 in epoch 8, gen_loss = 0.4622992385050346, disc_loss = 0.030253614648245275
Trained batch 58 in epoch 8, gen_loss = 0.4617057503279993, disc_loss = 0.030863650960026908
Trained batch 59 in epoch 8, gen_loss = 0.4613032693664233, disc_loss = 0.0317767010962901
Trained batch 60 in epoch 8, gen_loss = 0.46129799963998014, disc_loss = 0.03149785713262123
Trained batch 61 in epoch 8, gen_loss = 0.4612956157615108, disc_loss = 0.031618553375254474
Trained batch 62 in epoch 8, gen_loss = 0.46034472565802315, disc_loss = 0.03125011061673008
Trained batch 63 in epoch 8, gen_loss = 0.4612244418822229, disc_loss = 0.030878486733854515
Trained batch 64 in epoch 8, gen_loss = 0.460809627863077, disc_loss = 0.0335450522422504
Trained batch 65 in epoch 8, gen_loss = 0.46069224404566217, disc_loss = 0.03435826452209078
Trained batch 66 in epoch 8, gen_loss = 0.46040998332536043, disc_loss = 0.034521010311654034
Trained batch 67 in epoch 8, gen_loss = 0.459195823792149, disc_loss = 0.03415667896693134
Trained batch 68 in epoch 8, gen_loss = 0.4585208426351133, disc_loss = 0.033881878760386855
Trained batch 69 in epoch 8, gen_loss = 0.45922796726226806, disc_loss = 0.03386903493997774
Trained batch 70 in epoch 8, gen_loss = 0.4588816077776358, disc_loss = 0.034443891420304566
Trained batch 71 in epoch 8, gen_loss = 0.4604400342537297, disc_loss = 0.0347079489114953
Trained batch 72 in epoch 8, gen_loss = 0.460225083240091, disc_loss = 0.034371664106514155
Trained batch 73 in epoch 8, gen_loss = 0.4608115586074623, disc_loss = 0.034792401346478714
Trained batch 74 in epoch 8, gen_loss = 0.46151034514109296, disc_loss = 0.035681832479313016
Trained batch 75 in epoch 8, gen_loss = 0.46121181390787425, disc_loss = 0.035423920535801075
Trained batch 76 in epoch 8, gen_loss = 0.4614021661993745, disc_loss = 0.03527834892647897
Trained batch 77 in epoch 8, gen_loss = 0.46039537206674236, disc_loss = 0.03509803467060033
Trained batch 78 in epoch 8, gen_loss = 0.45989444587804096, disc_loss = 0.034904275628844204
Trained batch 79 in epoch 8, gen_loss = 0.4617318667471409, disc_loss = 0.03552051505248528
Trained batch 80 in epoch 8, gen_loss = 0.4615752910390312, disc_loss = 0.03533107094915101
Trained batch 81 in epoch 8, gen_loss = 0.46147974635042793, disc_loss = 0.035037246598044365
Trained batch 82 in epoch 8, gen_loss = 0.461769771863179, disc_loss = 0.03482927022647696
Trained batch 83 in epoch 8, gen_loss = 0.46206862443969365, disc_loss = 0.034835745444676526
Trained batch 84 in epoch 8, gen_loss = 0.46238067009869743, disc_loss = 0.03525008962160962
Trained batch 85 in epoch 8, gen_loss = 0.4622102806041407, disc_loss = 0.035427787013590166
Trained batch 86 in epoch 8, gen_loss = 0.4621310830116272, disc_loss = 0.035137964805973504
Trained batch 87 in epoch 8, gen_loss = 0.4618204676292159, disc_loss = 0.035816888989012856
Trained batch 88 in epoch 8, gen_loss = 0.46217075626501875, disc_loss = 0.03668299776481025
Trained batch 89 in epoch 8, gen_loss = 0.4621138277981016, disc_loss = 0.036754088463365205
Trained batch 90 in epoch 8, gen_loss = 0.46216235678274553, disc_loss = 0.03650737833999261
Trained batch 91 in epoch 8, gen_loss = 0.46191622543594113, disc_loss = 0.03695215950669397
Trained batch 92 in epoch 8, gen_loss = 0.4613991943738794, disc_loss = 0.03663463293955291
Trained batch 93 in epoch 8, gen_loss = 0.46215266559986357, disc_loss = 0.03662618483723874
Trained batch 94 in epoch 8, gen_loss = 0.46120197333787616, disc_loss = 0.03741852598215797
Trained batch 95 in epoch 8, gen_loss = 0.46212549321353436, disc_loss = 0.03793420258686334
Trained batch 96 in epoch 8, gen_loss = 0.4621760894342796, disc_loss = 0.03807382562351365
Trained batch 97 in epoch 8, gen_loss = 0.46136489328072994, disc_loss = 0.03841340237971851
Trained batch 98 in epoch 8, gen_loss = 0.4608264788232668, disc_loss = 0.038813320451858216
Trained batch 99 in epoch 8, gen_loss = 0.461119139790535, disc_loss = 0.03895438745850697
Trained batch 100 in epoch 8, gen_loss = 0.4608993946325661, disc_loss = 0.03866229438923742
Trained batch 101 in epoch 8, gen_loss = 0.4610393912184472, disc_loss = 0.03840395849535936
Trained batch 102 in epoch 8, gen_loss = 0.460486267087529, disc_loss = 0.03881922195376195
Trained batch 103 in epoch 8, gen_loss = 0.4608106679068162, disc_loss = 0.039034331550982855
Trained batch 104 in epoch 8, gen_loss = 0.461269653127307, disc_loss = 0.038813129149466045
Trained batch 105 in epoch 8, gen_loss = 0.4613748696052803, disc_loss = 0.0390940319223962
Trained batch 106 in epoch 8, gen_loss = 0.46118944159177977, disc_loss = 0.03879864434015319
Trained batch 107 in epoch 8, gen_loss = 0.461503709907885, disc_loss = 0.03867076537614964
Trained batch 108 in epoch 8, gen_loss = 0.46116613384780536, disc_loss = 0.038756267947290056
Trained batch 109 in epoch 8, gen_loss = 0.46107511032711374, disc_loss = 0.038476580815305084
Trained batch 110 in epoch 8, gen_loss = 0.461142868072063, disc_loss = 0.038344501939325315
Trained batch 111 in epoch 8, gen_loss = 0.46083393932453226, disc_loss = 0.03812169079277997
Trained batch 112 in epoch 8, gen_loss = 0.46070405788126245, disc_loss = 0.03787089933937959
Trained batch 113 in epoch 8, gen_loss = 0.46181531145907284, disc_loss = 0.03801276825834066
Trained batch 114 in epoch 8, gen_loss = 0.4611596117848935, disc_loss = 0.03784185682180459
Trained batch 115 in epoch 8, gen_loss = 0.46115526634043663, disc_loss = 0.03845051825568401
Trained batch 116 in epoch 8, gen_loss = 0.4617103091162494, disc_loss = 0.03836446623397498
Trained batch 117 in epoch 8, gen_loss = 0.4617318958044052, disc_loss = 0.03832725658263001
Trained batch 118 in epoch 8, gen_loss = 0.4608150993575569, disc_loss = 0.038069044460910334
Trained batch 119 in epoch 8, gen_loss = 0.4604085663954417, disc_loss = 0.037894820167760676
Trained batch 120 in epoch 8, gen_loss = 0.45992928152241985, disc_loss = 0.03766957395863989
Trained batch 121 in epoch 8, gen_loss = 0.4599572224695174, disc_loss = 0.03754358331970565
Trained batch 122 in epoch 8, gen_loss = 0.4596386023653232, disc_loss = 0.037357096319897025
Trained batch 123 in epoch 8, gen_loss = 0.4597810319354457, disc_loss = 0.04001917431108473
Trained batch 124 in epoch 8, gen_loss = 0.45867175579071046, disc_loss = 0.04016620730794966
Trained batch 125 in epoch 8, gen_loss = 0.457850100975188, disc_loss = 0.040408556477078014
Trained batch 126 in epoch 8, gen_loss = 0.4576266006691249, disc_loss = 0.04032776461672184
Trained batch 127 in epoch 8, gen_loss = 0.4575280633289367, disc_loss = 0.04052196703014488
Trained batch 128 in epoch 8, gen_loss = 0.4570980848268021, disc_loss = 0.04068264149512027
Trained batch 129 in epoch 8, gen_loss = 0.4566963961491218, disc_loss = 0.041723028092215265
Trained batch 130 in epoch 8, gen_loss = 0.45655954771369467, disc_loss = 0.04148594384039006
Trained batch 131 in epoch 8, gen_loss = 0.4559841686577508, disc_loss = 0.04152713721850887
Trained batch 132 in epoch 8, gen_loss = 0.45585814857841434, disc_loss = 0.041303540028533654
Trained batch 133 in epoch 8, gen_loss = 0.45581833128608873, disc_loss = 0.04123720874377429
Trained batch 134 in epoch 8, gen_loss = 0.4554706670619823, disc_loss = 0.04161542563147291
Trained batch 135 in epoch 8, gen_loss = 0.45502811538822513, disc_loss = 0.04210892925210133
Trained batch 136 in epoch 8, gen_loss = 0.455235542172063, disc_loss = 0.04188542374083432
Trained batch 137 in epoch 8, gen_loss = 0.4554208834534106, disc_loss = 0.04168466598882029
Trained batch 138 in epoch 8, gen_loss = 0.4555312757440608, disc_loss = 0.042488477764007965
Trained batch 139 in epoch 8, gen_loss = 0.45577554468597686, disc_loss = 0.04249278553262619
Trained batch 140 in epoch 8, gen_loss = 0.4557216298495624, disc_loss = 0.04238380501145854
Trained batch 141 in epoch 8, gen_loss = 0.455489296518581, disc_loss = 0.04218709594274963
Trained batch 142 in epoch 8, gen_loss = 0.45517560839653015, disc_loss = 0.041947374167572056
Trained batch 143 in epoch 8, gen_loss = 0.4552547118316094, disc_loss = 0.04176627590560303
Trained batch 144 in epoch 8, gen_loss = 0.4550555481992919, disc_loss = 0.041576090244704794
Trained batch 145 in epoch 8, gen_loss = 0.45469263522592307, disc_loss = 0.04148844756626154
Trained batch 146 in epoch 8, gen_loss = 0.4543192410955624, disc_loss = 0.043032175774185534
Trained batch 147 in epoch 8, gen_loss = 0.4539395063310056, disc_loss = 0.04371887661447447
Trained batch 148 in epoch 8, gen_loss = 0.4533379879973879, disc_loss = 0.04395490469279755
Trained batch 149 in epoch 8, gen_loss = 0.4535599903265635, disc_loss = 0.04391898676287383
Trained batch 150 in epoch 8, gen_loss = 0.4539820429505102, disc_loss = 0.044057233390145445
Trained batch 151 in epoch 8, gen_loss = 0.4537073042439787, disc_loss = 0.043982803767951405
Trained batch 152 in epoch 8, gen_loss = 0.45338448940538895, disc_loss = 0.04424021212426714
Trained batch 153 in epoch 8, gen_loss = 0.45311152199646093, disc_loss = 0.044133614574849316
Trained batch 154 in epoch 8, gen_loss = 0.4533209271969334, disc_loss = 0.04398252724429533
Trained batch 155 in epoch 8, gen_loss = 0.45377202274707645, disc_loss = 0.043851519213953555
Trained batch 156 in epoch 8, gen_loss = 0.4535752601304631, disc_loss = 0.04383073364692936
Trained batch 157 in epoch 8, gen_loss = 0.4533016279905657, disc_loss = 0.04391025060557913
Trained batch 158 in epoch 8, gen_loss = 0.45347417488038166, disc_loss = 0.043925385050909045
Trained batch 159 in epoch 8, gen_loss = 0.4537507938221097, disc_loss = 0.04384674625034677
Trained batch 160 in epoch 8, gen_loss = 0.4537279270820736, disc_loss = 0.04399293216425486
Trained batch 161 in epoch 8, gen_loss = 0.45376233554180756, disc_loss = 0.04417804080883708
Trained batch 162 in epoch 8, gen_loss = 0.4538953009924274, disc_loss = 0.04410471501645912
Trained batch 163 in epoch 8, gen_loss = 0.4537406869050933, disc_loss = 0.044346428994464164
Trained batch 164 in epoch 8, gen_loss = 0.45418556928634646, disc_loss = 0.04414259748053596
Trained batch 165 in epoch 8, gen_loss = 0.45473307766110066, disc_loss = 0.043970493898525025
Trained batch 166 in epoch 8, gen_loss = 0.4541627980634838, disc_loss = 0.043987508758646016
Trained batch 167 in epoch 8, gen_loss = 0.4543041799749647, disc_loss = 0.044412291393936834
Trained batch 168 in epoch 8, gen_loss = 0.4540850948652572, disc_loss = 0.04504590768769339
Trained batch 169 in epoch 8, gen_loss = 0.45410356398891, disc_loss = 0.0449066526708467
Trained batch 170 in epoch 8, gen_loss = 0.45424090683111673, disc_loss = 0.04471924978482662
Trained batch 171 in epoch 8, gen_loss = 0.45439843019080717, disc_loss = 0.04451786955347458
Trained batch 172 in epoch 8, gen_loss = 0.454134373306539, disc_loss = 0.044497812749559565
Trained batch 173 in epoch 8, gen_loss = 0.45389209293771066, disc_loss = 0.0451141174403608
Trained batch 174 in epoch 8, gen_loss = 0.4534021430356162, disc_loss = 0.045597331088834576
Trained batch 175 in epoch 8, gen_loss = 0.45326021838594566, disc_loss = 0.046053506255372086
Trained batch 176 in epoch 8, gen_loss = 0.4537622138942029, disc_loss = 0.04627394107023075
Trained batch 177 in epoch 8, gen_loss = 0.45411410609657843, disc_loss = 0.04646486181143169
Trained batch 178 in epoch 8, gen_loss = 0.4540933545408302, disc_loss = 0.04637710938578753
Trained batch 179 in epoch 8, gen_loss = 0.45367732180489434, disc_loss = 0.04756076928978372
Trained batch 180 in epoch 8, gen_loss = 0.45322429277620263, disc_loss = 0.04760392171907038
Trained batch 181 in epoch 8, gen_loss = 0.45373515146119253, disc_loss = 0.04771033393162825
Trained batch 182 in epoch 8, gen_loss = 0.45346644455617896, disc_loss = 0.047652052777763354
Trained batch 183 in epoch 8, gen_loss = 0.453528411200513, disc_loss = 0.04767800062899883
Trained batch 184 in epoch 8, gen_loss = 0.4534409589058644, disc_loss = 0.04771812978150273
Trained batch 185 in epoch 8, gen_loss = 0.45301587559202666, disc_loss = 0.047529679654236205
Trained batch 186 in epoch 8, gen_loss = 0.45304345781790384, disc_loss = 0.047336029836330264
Trained batch 187 in epoch 8, gen_loss = 0.4532491674131535, disc_loss = 0.04715090753396656
Trained batch 188 in epoch 8, gen_loss = 0.4533922434168518, disc_loss = 0.04702965918282865
Trained batch 189 in epoch 8, gen_loss = 0.45332734114245365, disc_loss = 0.046890077241206245
Trained batch 190 in epoch 8, gen_loss = 0.4533460333709317, disc_loss = 0.04669375773348616
Trained batch 191 in epoch 8, gen_loss = 0.45349944941699505, disc_loss = 0.046624632136323875
Trained batch 192 in epoch 8, gen_loss = 0.4533034522916369, disc_loss = 0.046563662560849685
Trained batch 193 in epoch 8, gen_loss = 0.4536699711047497, disc_loss = 0.04645130153596593
Trained batch 194 in epoch 8, gen_loss = 0.45325201474703275, disc_loss = 0.04632429291541951
Trained batch 195 in epoch 8, gen_loss = 0.45323993143986685, disc_loss = 0.04616589041792655
Trained batch 196 in epoch 8, gen_loss = 0.4532390616569422, disc_loss = 0.04600135133563905
Trained batch 197 in epoch 8, gen_loss = 0.45317214817711804, disc_loss = 0.04584277201693204
Trained batch 198 in epoch 8, gen_loss = 0.4527763868097085, disc_loss = 0.04564534745590958
Trained batch 199 in epoch 8, gen_loss = 0.4530011358857155, disc_loss = 0.045468190825777126
Trained batch 200 in epoch 8, gen_loss = 0.4529354409198856, disc_loss = 0.045312086862757506
Trained batch 201 in epoch 8, gen_loss = 0.4530619940545299, disc_loss = 0.04514883503912588
Trained batch 202 in epoch 8, gen_loss = 0.4531644797090239, disc_loss = 0.04502578738622661
Trained batch 203 in epoch 8, gen_loss = 0.45325186235063214, disc_loss = 0.04486865342215763
Trained batch 204 in epoch 8, gen_loss = 0.4535695288239456, disc_loss = 0.04498635519682089
Trained batch 205 in epoch 8, gen_loss = 0.4533670848434411, disc_loss = 0.044861082513183714
Trained batch 206 in epoch 8, gen_loss = 0.4531762011097249, disc_loss = 0.04474801653973614
Trained batch 207 in epoch 8, gen_loss = 0.4530497997139509, disc_loss = 0.044596884091823503
Trained batch 208 in epoch 8, gen_loss = 0.4529858258637515, disc_loss = 0.044408240953781174
Trained batch 209 in epoch 8, gen_loss = 0.45363349985508694, disc_loss = 0.04432704457237075
Trained batch 210 in epoch 8, gen_loss = 0.45366417937934117, disc_loss = 0.044141891371608837
Trained batch 211 in epoch 8, gen_loss = 0.45377316846037813, disc_loss = 0.04396629007643019
Trained batch 212 in epoch 8, gen_loss = 0.4537909722104319, disc_loss = 0.04384513169706322
Trained batch 213 in epoch 8, gen_loss = 0.4539329965259427, disc_loss = 0.04377026152775283
Trained batch 214 in epoch 8, gen_loss = 0.4545695711013883, disc_loss = 0.04373137672041911
Trained batch 215 in epoch 8, gen_loss = 0.4546355537518307, disc_loss = 0.04357261854521413
Trained batch 216 in epoch 8, gen_loss = 0.4545285045276589, disc_loss = 0.04339266852003604
Trained batch 217 in epoch 8, gen_loss = 0.4542161636396286, disc_loss = 0.04326394699202047
Trained batch 218 in epoch 8, gen_loss = 0.45425822214993167, disc_loss = 0.0431625986435625
Trained batch 219 in epoch 8, gen_loss = 0.4544608022678982, disc_loss = 0.043024080944120545
Trained batch 220 in epoch 8, gen_loss = 0.4547586418115176, disc_loss = 0.04284439435148637
Trained batch 221 in epoch 8, gen_loss = 0.45463670897591224, disc_loss = 0.04270898686986215
Trained batch 222 in epoch 8, gen_loss = 0.4548848620177384, disc_loss = 0.042585544433286035
Trained batch 223 in epoch 8, gen_loss = 0.45487517051930937, disc_loss = 0.0424470308716991
Trained batch 224 in epoch 8, gen_loss = 0.4546976301405165, disc_loss = 0.042299560352952945
Trained batch 225 in epoch 8, gen_loss = 0.45490472691249, disc_loss = 0.042137107823200654
Trained batch 226 in epoch 8, gen_loss = 0.4549918122228547, disc_loss = 0.04200088523537544
Trained batch 227 in epoch 8, gen_loss = 0.4549284223140332, disc_loss = 0.04187400291342974
Trained batch 228 in epoch 8, gen_loss = 0.45494600701019755, disc_loss = 0.04187118366470471
Trained batch 229 in epoch 8, gen_loss = 0.45480811220148337, disc_loss = 0.041753375780282785
Trained batch 230 in epoch 8, gen_loss = 0.455122288816419, disc_loss = 0.041652582471916104
Trained batch 231 in epoch 8, gen_loss = 0.4553550765689077, disc_loss = 0.04151521600554055
Trained batch 232 in epoch 8, gen_loss = 0.45536315185317666, disc_loss = 0.04136383588937443
Trained batch 233 in epoch 8, gen_loss = 0.4556896752781338, disc_loss = 0.04124954627313388
Trained batch 234 in epoch 8, gen_loss = 0.45562200761855914, disc_loss = 0.04111955075802163
Trained batch 235 in epoch 8, gen_loss = 0.4555987639952514, disc_loss = 0.04100739543811592
Trained batch 236 in epoch 8, gen_loss = 0.4553405208678185, disc_loss = 0.04084586575214716
Trained batch 237 in epoch 8, gen_loss = 0.45514565944170754, disc_loss = 0.04069168433574412
Trained batch 238 in epoch 8, gen_loss = 0.4550353757507133, disc_loss = 0.040547156857451326
Trained batch 239 in epoch 8, gen_loss = 0.4547531108061473, disc_loss = 0.040390731407872714
Trained batch 240 in epoch 8, gen_loss = 0.4547631942137643, disc_loss = 0.040236876102713134
Trained batch 241 in epoch 8, gen_loss = 0.4547113816846501, disc_loss = 0.04008722525813486
Trained batch 242 in epoch 8, gen_loss = 0.4547083868411343, disc_loss = 0.039933268454140476
Trained batch 243 in epoch 8, gen_loss = 0.45459931881212795, disc_loss = 0.039783965747566805
Trained batch 244 in epoch 8, gen_loss = 0.45462661385536196, disc_loss = 0.03963624661579272
Trained batch 245 in epoch 8, gen_loss = 0.454245254155097, disc_loss = 0.03948659662770607
Trained batch 246 in epoch 8, gen_loss = 0.45404840324089113, disc_loss = 0.039341739265753434
Trained batch 247 in epoch 8, gen_loss = 0.4539793855961292, disc_loss = 0.039200567460108186
Trained batch 248 in epoch 8, gen_loss = 0.4537033859984463, disc_loss = 0.03905306985773834
Trained batch 249 in epoch 8, gen_loss = 0.4535878700017929, disc_loss = 0.03891043394524604
Trained batch 250 in epoch 8, gen_loss = 0.45360566895321547, disc_loss = 0.03876581668122801
Trained batch 251 in epoch 8, gen_loss = 0.4538016863285549, disc_loss = 0.038626725519342084
Trained batch 252 in epoch 8, gen_loss = 0.4539668006388095, disc_loss = 0.03848299795297884
Trained batch 253 in epoch 8, gen_loss = 0.4540516826815493, disc_loss = 0.03834598742638106
Trained batch 254 in epoch 8, gen_loss = 0.45415573412296817, disc_loss = 0.03820402258824484
Trained batch 255 in epoch 8, gen_loss = 0.45411536272149533, disc_loss = 0.03807606515510997
Trained batch 256 in epoch 8, gen_loss = 0.45411247212135375, disc_loss = 0.03793864738801313
Trained batch 257 in epoch 8, gen_loss = 0.4542286207740621, disc_loss = 0.037808033799240005
Trained batch 258 in epoch 8, gen_loss = 0.45420768017014024, disc_loss = 0.03767344703930196
Trained batch 259 in epoch 8, gen_loss = 0.4543331999045152, disc_loss = 0.037538551705746125
Trained batch 260 in epoch 8, gen_loss = 0.4544849226757941, disc_loss = 0.037450796169839026
Trained batch 261 in epoch 8, gen_loss = 0.454286013850729, disc_loss = 0.03734299006786567
Trained batch 262 in epoch 8, gen_loss = 0.4540288864206452, disc_loss = 0.03721110847293481
Trained batch 263 in epoch 8, gen_loss = 0.4542592602471511, disc_loss = 0.0370791863322004
Trained batch 264 in epoch 8, gen_loss = 0.45401984003354917, disc_loss = 0.03694745192638124
Trained batch 265 in epoch 8, gen_loss = 0.4541819770085184, disc_loss = 0.03682262894497918
Trained batch 266 in epoch 8, gen_loss = 0.4543740836422095, disc_loss = 0.036693285443481716
Trained batch 267 in epoch 8, gen_loss = 0.45432298152304407, disc_loss = 0.03656260312600895
Trained batch 268 in epoch 8, gen_loss = 0.4543887935163363, disc_loss = 0.03643601773770658
Trained batch 269 in epoch 8, gen_loss = 0.45429963502619003, disc_loss = 0.0363080553356903
Trained batch 270 in epoch 8, gen_loss = 0.45421226185186325, disc_loss = 0.036181627295059034
Trained batch 271 in epoch 8, gen_loss = 0.45410044557031465, disc_loss = 0.03607347946757834
Trained batch 272 in epoch 8, gen_loss = 0.45410909146179645, disc_loss = 0.035950646394583986
Trained batch 273 in epoch 8, gen_loss = 0.45401733308812997, disc_loss = 0.035829047613818006
Trained batch 274 in epoch 8, gen_loss = 0.4538042376258157, disc_loss = 0.03571612455543469
Trained batch 275 in epoch 8, gen_loss = 0.4536795673379, disc_loss = 0.03559274486083861
Trained batch 276 in epoch 8, gen_loss = 0.4538752990724378, disc_loss = 0.03547188493974561
Trained batch 277 in epoch 8, gen_loss = 0.45382541964808815, disc_loss = 0.035369583197011736
Trained batch 278 in epoch 8, gen_loss = 0.45338741820772915, disc_loss = 0.03524841458743645
Trained batch 279 in epoch 8, gen_loss = 0.4534864740712302, disc_loss = 0.03514425443302441
Trained batch 280 in epoch 8, gen_loss = 0.4533333655353967, disc_loss = 0.03503040454907217
Trained batch 281 in epoch 8, gen_loss = 0.4534271426023321, disc_loss = 0.03491218131719197
Trained batch 282 in epoch 8, gen_loss = 0.4535852998179176, disc_loss = 0.03480231211283787
Trained batch 283 in epoch 8, gen_loss = 0.4535383163413531, disc_loss = 0.03470998249118361
Trained batch 284 in epoch 8, gen_loss = 0.45347837366555865, disc_loss = 0.0345978723618349
Trained batch 285 in epoch 8, gen_loss = 0.4533827088095925, disc_loss = 0.03449293823629435
Trained batch 286 in epoch 8, gen_loss = 0.453371941004896, disc_loss = 0.03438244501245614
Trained batch 287 in epoch 8, gen_loss = 0.4535210109833214, disc_loss = 0.034288687988818206
Trained batch 288 in epoch 8, gen_loss = 0.45353939892098977, disc_loss = 0.034179659057601924
Trained batch 289 in epoch 8, gen_loss = 0.45355686853671895, disc_loss = 0.03408437446562638
Trained batch 290 in epoch 8, gen_loss = 0.4533330050530712, disc_loss = 0.03397608085541867
Trained batch 291 in epoch 8, gen_loss = 0.45349306215162144, disc_loss = 0.03387622756497577
Trained batch 292 in epoch 8, gen_loss = 0.4534152519377425, disc_loss = 0.03376958693485745
Trained batch 293 in epoch 8, gen_loss = 0.45339898785360816, disc_loss = 0.03365958278656614
Trained batch 294 in epoch 8, gen_loss = 0.4534254477185718, disc_loss = 0.03355077036806398
Trained batch 295 in epoch 8, gen_loss = 0.4534071147240497, disc_loss = 0.03344592782141754
Trained batch 296 in epoch 8, gen_loss = 0.45316285195976796, disc_loss = 0.03334051340321386
Trained batch 297 in epoch 8, gen_loss = 0.45341504060182, disc_loss = 0.03323532411502049
Trained batch 298 in epoch 8, gen_loss = 0.4532441910493334, disc_loss = 0.033129727485025906
Trained batch 299 in epoch 8, gen_loss = 0.4531986078619957, disc_loss = 0.033027266405988485
Trained batch 300 in epoch 8, gen_loss = 0.45315174604967184, disc_loss = 0.03292558479982976
Trained batch 301 in epoch 8, gen_loss = 0.45328328240391436, disc_loss = 0.03323302335731858
Trained batch 302 in epoch 8, gen_loss = 0.45318445523973344, disc_loss = 0.03325431051713233
Trained batch 303 in epoch 8, gen_loss = 0.45309681749265446, disc_loss = 0.03339598659122681
Trained batch 304 in epoch 8, gen_loss = 0.45302076114982853, disc_loss = 0.03331761883617547
Trained batch 305 in epoch 8, gen_loss = 0.4528222150272793, disc_loss = 0.03327298370795629
Trained batch 306 in epoch 8, gen_loss = 0.45305299506513613, disc_loss = 0.03318633572107442
Trained batch 307 in epoch 8, gen_loss = 0.45279781530042745, disc_loss = 0.03309516369610081
Trained batch 308 in epoch 8, gen_loss = 0.45262536020726446, disc_loss = 0.03303043254723465
Trained batch 309 in epoch 8, gen_loss = 0.45249848183124297, disc_loss = 0.03297669264833413
Trained batch 310 in epoch 8, gen_loss = 0.4525917611321452, disc_loss = 0.03289172188019518
Trained batch 311 in epoch 8, gen_loss = 0.4525815372665723, disc_loss = 0.03281194478115186
Trained batch 312 in epoch 8, gen_loss = 0.4527396424509847, disc_loss = 0.032728690782728526
Trained batch 313 in epoch 8, gen_loss = 0.45260002079663003, disc_loss = 0.03263273344013342
Trained batch 314 in epoch 8, gen_loss = 0.452731688628121, disc_loss = 0.03254919408835352
Trained batch 315 in epoch 8, gen_loss = 0.45276712711098827, disc_loss = 0.032457315090371745
Trained batch 316 in epoch 8, gen_loss = 0.45292529322747554, disc_loss = 0.03237834302209059
Trained batch 317 in epoch 8, gen_loss = 0.4529520144814965, disc_loss = 0.032284292071741424
Trained batch 318 in epoch 8, gen_loss = 0.45285667194094403, disc_loss = 0.03219148370971594
Trained batch 319 in epoch 8, gen_loss = 0.4529508477076888, disc_loss = 0.032099657531944104
Trained batch 320 in epoch 8, gen_loss = 0.4531121900148481, disc_loss = 0.03200842626828039
Trained batch 321 in epoch 8, gen_loss = 0.4530920127163763, disc_loss = 0.03192488805633848
Trained batch 322 in epoch 8, gen_loss = 0.4530708046151389, disc_loss = 0.03189317333503358
Trained batch 323 in epoch 8, gen_loss = 0.4530321527042507, disc_loss = 0.031821422717235065
Trained batch 324 in epoch 8, gen_loss = 0.45297863327539883, disc_loss = 0.03174809035916741
Trained batch 325 in epoch 8, gen_loss = 0.4530690386434274, disc_loss = 0.03173437614730942
Trained batch 326 in epoch 8, gen_loss = 0.45304966191633034, disc_loss = 0.031652105193220606
Trained batch 327 in epoch 8, gen_loss = 0.4529191299182613, disc_loss = 0.031584429794570386
Trained batch 328 in epoch 8, gen_loss = 0.4533507403631703, disc_loss = 0.031500126653432985
Trained batch 329 in epoch 8, gen_loss = 0.45331791964444246, disc_loss = 0.03141985064104312
Trained batch 330 in epoch 8, gen_loss = 0.45322912679338023, disc_loss = 0.031657083610669226
Trained batch 331 in epoch 8, gen_loss = 0.45338230086378306, disc_loss = 0.03167102223680164
Trained batch 332 in epoch 8, gen_loss = 0.4532176121935114, disc_loss = 0.031685851070353085
Trained batch 333 in epoch 8, gen_loss = 0.4532422213675733, disc_loss = 0.031611364891802794
Trained batch 334 in epoch 8, gen_loss = 0.45322158745865326, disc_loss = 0.03154888377080101
Trained batch 335 in epoch 8, gen_loss = 0.45341222626822336, disc_loss = 0.03148221154073586
Trained batch 336 in epoch 8, gen_loss = 0.45345407618259465, disc_loss = 0.03140132527629837
Trained batch 337 in epoch 8, gen_loss = 0.4534679971326738, disc_loss = 0.0313399154961539
Trained batch 338 in epoch 8, gen_loss = 0.4535892864244174, disc_loss = 0.03126544976994329
Trained batch 339 in epoch 8, gen_loss = 0.4537124250741566, disc_loss = 0.031185526954804494
Trained batch 340 in epoch 8, gen_loss = 0.4538128717728724, disc_loss = 0.03178259256825703
Trained batch 341 in epoch 8, gen_loss = 0.45371762423487433, disc_loss = 0.03185576711963775
Trained batch 342 in epoch 8, gen_loss = 0.45384472469546705, disc_loss = 0.03183108906576589
Trained batch 343 in epoch 8, gen_loss = 0.45369105422219563, disc_loss = 0.031884239743555746
Trained batch 344 in epoch 8, gen_loss = 0.45389815620754076, disc_loss = 0.03194369729405836
Trained batch 345 in epoch 8, gen_loss = 0.45386597376338317, disc_loss = 0.031915539235678754
Trained batch 346 in epoch 8, gen_loss = 0.4536812672182188, disc_loss = 0.03196918864074225
Trained batch 347 in epoch 8, gen_loss = 0.45354946206013363, disc_loss = 0.032015544229224535
Trained batch 348 in epoch 8, gen_loss = 0.45359876478640604, disc_loss = 0.03224323041547613
Trained batch 349 in epoch 8, gen_loss = 0.4535265702860696, disc_loss = 0.03231347964876997
Trained batch 350 in epoch 8, gen_loss = 0.4535563508329908, disc_loss = 0.03226624301401235
Trained batch 351 in epoch 8, gen_loss = 0.45365334183655004, disc_loss = 0.032284539558697194
Trained batch 352 in epoch 8, gen_loss = 0.4537603183947609, disc_loss = 0.03222531653616166
Trained batch 353 in epoch 8, gen_loss = 0.45368123509116093, disc_loss = 0.03228388356615784
Trained batch 354 in epoch 8, gen_loss = 0.45385593813909614, disc_loss = 0.03238664425083134
Trained batch 355 in epoch 8, gen_loss = 0.45396765488921925, disc_loss = 0.032366002013179566
Trained batch 356 in epoch 8, gen_loss = 0.45410620606913954, disc_loss = 0.032354601184741
Trained batch 357 in epoch 8, gen_loss = 0.4540760436371052, disc_loss = 0.03230071233067786
Trained batch 358 in epoch 8, gen_loss = 0.45414717947872235, disc_loss = 0.03222702119647315
Trained batch 359 in epoch 8, gen_loss = 0.4542792621586058, disc_loss = 0.03221737634610488
Trained batch 360 in epoch 8, gen_loss = 0.45410985249891833, disc_loss = 0.032147977184478475
Trained batch 361 in epoch 8, gen_loss = 0.4543722108912073, disc_loss = 0.032157688574654494
Trained batch 362 in epoch 8, gen_loss = 0.45455038662455954, disc_loss = 0.03217631552083618
Trained batch 363 in epoch 8, gen_loss = 0.45466156500381427, disc_loss = 0.03219444032791736
Trained batch 364 in epoch 8, gen_loss = 0.45471287516698444, disc_loss = 0.032132658202277675
Trained batch 365 in epoch 8, gen_loss = 0.45468354428726465, disc_loss = 0.03206445314333637
Trained batch 366 in epoch 8, gen_loss = 0.45482593409371963, disc_loss = 0.03199523727774965
Trained batch 367 in epoch 8, gen_loss = 0.4548749961768803, disc_loss = 0.03191993828121391
Trained batch 368 in epoch 8, gen_loss = 0.45501720848768384, disc_loss = 0.031878446339223244
Trained batch 369 in epoch 8, gen_loss = 0.45517268221120577, disc_loss = 0.0318718247386199
Trained batch 370 in epoch 8, gen_loss = 0.4551126172118431, disc_loss = 0.03181790394490118
Trained batch 371 in epoch 8, gen_loss = 0.4549267055687084, disc_loss = 0.03184890306131634
Trained batch 372 in epoch 8, gen_loss = 0.4550079609050188, disc_loss = 0.03182209527991393
Trained batch 373 in epoch 8, gen_loss = 0.4547494206836517, disc_loss = 0.0317811941507616
Trained batch 374 in epoch 8, gen_loss = 0.4546079326470693, disc_loss = 0.03182375918515026
Trained batch 375 in epoch 8, gen_loss = 0.45468780073396703, disc_loss = 0.03179640799669172
Trained batch 376 in epoch 8, gen_loss = 0.45484677115232935, disc_loss = 0.031849310643827684
Trained batch 377 in epoch 8, gen_loss = 0.4548601497891088, disc_loss = 0.03179524109326796
Trained batch 378 in epoch 8, gen_loss = 0.4546770809665519, disc_loss = 0.03172829372152234
Trained batch 379 in epoch 8, gen_loss = 0.45441257859531203, disc_loss = 0.03193121872486939
Trained batch 380 in epoch 8, gen_loss = 0.4545397002865949, disc_loss = 0.03250920794491126
Trained batch 381 in epoch 8, gen_loss = 0.45477082685650333, disc_loss = 0.03245105892748947
Trained batch 382 in epoch 8, gen_loss = 0.45477128869248434, disc_loss = 0.03244942650332677
Trained batch 383 in epoch 8, gen_loss = 0.4546673294001569, disc_loss = 0.03247110150732624
Trained batch 384 in epoch 8, gen_loss = 0.4546646129775357, disc_loss = 0.03243194091278914
Trained batch 385 in epoch 8, gen_loss = 0.45497078328861473, disc_loss = 0.03240629352105617
Trained batch 386 in epoch 8, gen_loss = 0.45508243370733825, disc_loss = 0.03237505447665754
Trained batch 387 in epoch 8, gen_loss = 0.45520623926956627, disc_loss = 0.032314262623519434
Trained batch 388 in epoch 8, gen_loss = 0.45520470082606634, disc_loss = 0.03226058627718193
Trained batch 389 in epoch 8, gen_loss = 0.45507335571142343, disc_loss = 0.03219362709802599
Trained batch 390 in epoch 8, gen_loss = 0.4550469433102766, disc_loss = 0.03246111781431643
Trained batch 391 in epoch 8, gen_loss = 0.45523662158117, disc_loss = 0.0325629544124834
Trained batch 392 in epoch 8, gen_loss = 0.455375657812633, disc_loss = 0.03250847951125155
Trained batch 393 in epoch 8, gen_loss = 0.4554502119872776, disc_loss = 0.03246140253770302
Trained batch 394 in epoch 8, gen_loss = 0.45552287448810624, disc_loss = 0.0323909765810859
Trained batch 395 in epoch 8, gen_loss = 0.45544856786727905, disc_loss = 0.0323439653688863
Trained batch 396 in epoch 8, gen_loss = 0.45529500198003925, disc_loss = 0.032351205267964554
Trained batch 397 in epoch 8, gen_loss = 0.4555497278819731, disc_loss = 0.03233410808054178
Trained batch 398 in epoch 8, gen_loss = 0.4556396394445185, disc_loss = 0.03233662423827128
Trained batch 399 in epoch 8, gen_loss = 0.45548136249184606, disc_loss = 0.03254322460561525
Trained batch 400 in epoch 8, gen_loss = 0.4557704174905049, disc_loss = 0.03278014880135897
Trained batch 401 in epoch 8, gen_loss = 0.4555103951573965, disc_loss = 0.03271743792296846
Trained batch 402 in epoch 8, gen_loss = 0.45554896627111413, disc_loss = 0.032707013147617356
Trained batch 403 in epoch 8, gen_loss = 0.45547858891215653, disc_loss = 0.03274031534346079
Trained batch 404 in epoch 8, gen_loss = 0.4552764844011377, disc_loss = 0.032819799356231534
Trained batch 405 in epoch 8, gen_loss = 0.45537380837454583, disc_loss = 0.032802100696490866
Trained batch 406 in epoch 8, gen_loss = 0.45554796879063075, disc_loss = 0.03295944787101953
Trained batch 407 in epoch 8, gen_loss = 0.45546317421922494, disc_loss = 0.03294816435549828
Trained batch 408 in epoch 8, gen_loss = 0.4556047377201631, disc_loss = 0.03291593799834347
Trained batch 409 in epoch 8, gen_loss = 0.4555025057821739, disc_loss = 0.03288082789300328
Trained batch 410 in epoch 8, gen_loss = 0.4554579160799365, disc_loss = 0.03282560964133092
Trained batch 411 in epoch 8, gen_loss = 0.45557756287959017, disc_loss = 0.032788466015102755
Trained batch 412 in epoch 8, gen_loss = 0.45559871701870935, disc_loss = 0.03276012164481958
Trained batch 413 in epoch 8, gen_loss = 0.45575093071241884, disc_loss = 0.032702100431155144
Trained batch 414 in epoch 8, gen_loss = 0.4558811177690345, disc_loss = 0.03263421497778989
Trained batch 415 in epoch 8, gen_loss = 0.45597433692847306, disc_loss = 0.03259093562183597
Trained batch 416 in epoch 8, gen_loss = 0.4560526853128017, disc_loss = 0.032542017057908774
Trained batch 417 in epoch 8, gen_loss = 0.45602291309092036, disc_loss = 0.03249368232588003
Trained batch 418 in epoch 8, gen_loss = 0.4559814437761512, disc_loss = 0.032474460975469265
Trained batch 419 in epoch 8, gen_loss = 0.45594184994697573, disc_loss = 0.03240847211674831
Trained batch 420 in epoch 8, gen_loss = 0.4558928774541461, disc_loss = 0.03236309011940205
Trained batch 421 in epoch 8, gen_loss = 0.4558847465362594, disc_loss = 0.03230823108526962
Trained batch 422 in epoch 8, gen_loss = 0.4558649655634066, disc_loss = 0.03224032401353843
Trained batch 423 in epoch 8, gen_loss = 0.45589802533669294, disc_loss = 0.03227646801816212
Trained batch 424 in epoch 8, gen_loss = 0.4558734527756186, disc_loss = 0.032243399305049984
Trained batch 425 in epoch 8, gen_loss = 0.4559300213072781, disc_loss = 0.03226285740927719
Trained batch 426 in epoch 8, gen_loss = 0.4558290470679415, disc_loss = 0.0322155237630821
Trained batch 427 in epoch 8, gen_loss = 0.4558561774336289, disc_loss = 0.032168939736319235
Trained batch 428 in epoch 8, gen_loss = 0.45561697766497417, disc_loss = 0.032110431749864304
Trained batch 429 in epoch 8, gen_loss = 0.4557443579962087, disc_loss = 0.03218849475419712
Trained batch 430 in epoch 8, gen_loss = 0.45569596904613024, disc_loss = 0.0321685382032123
Trained batch 431 in epoch 8, gen_loss = 0.45588547901974785, disc_loss = 0.03222207884957445
Trained batch 432 in epoch 8, gen_loss = 0.4557923607820727, disc_loss = 0.032174531075195786
Trained batch 433 in epoch 8, gen_loss = 0.45560399611150065, disc_loss = 0.03211211656115108
Trained batch 434 in epoch 8, gen_loss = 0.45557837883631386, disc_loss = 0.03205229905219856
Trained batch 435 in epoch 8, gen_loss = 0.4554978607718004, disc_loss = 0.03198776633741437
Trained batch 436 in epoch 8, gen_loss = 0.4552037102816034, disc_loss = 0.032074675121125114
Trained batch 437 in epoch 8, gen_loss = 0.45526958716242283, disc_loss = 0.03204300610474035
Trained batch 438 in epoch 8, gen_loss = 0.4554161711135595, disc_loss = 0.03201655763867555
Trained batch 439 in epoch 8, gen_loss = 0.4552117651159113, disc_loss = 0.03197936299204064
Trained batch 440 in epoch 8, gen_loss = 0.4553165495260503, disc_loss = 0.03205718191672125
Trained batch 441 in epoch 8, gen_loss = 0.45553297006706306, disc_loss = 0.032002594317225276
Trained batch 442 in epoch 8, gen_loss = 0.4556712127431521, disc_loss = 0.032000953230153326
Trained batch 443 in epoch 8, gen_loss = 0.45560055454303555, disc_loss = 0.0319744992433829
Trained batch 444 in epoch 8, gen_loss = 0.4557734054795812, disc_loss = 0.03193108694512774
Trained batch 445 in epoch 8, gen_loss = 0.45579952796745726, disc_loss = 0.03188290138939821
Trained batch 446 in epoch 8, gen_loss = 0.4559385081132253, disc_loss = 0.031850639240549546
Trained batch 447 in epoch 8, gen_loss = 0.45610151619517375, disc_loss = 0.03179265065669564
Trained batch 448 in epoch 8, gen_loss = 0.4562166701579147, disc_loss = 0.031740253561493716
Trained batch 449 in epoch 8, gen_loss = 0.4561456176307466, disc_loss = 0.031725667332712974
Trained batch 450 in epoch 8, gen_loss = 0.4561195108552201, disc_loss = 0.03169571504073255
Trained batch 451 in epoch 8, gen_loss = 0.45597052481849637, disc_loss = 0.031694850841623656
Trained batch 452 in epoch 8, gen_loss = 0.455876560203287, disc_loss = 0.03169676885841451
Trained batch 453 in epoch 8, gen_loss = 0.4557936972721033, disc_loss = 0.03167351595657398
Trained batch 454 in epoch 8, gen_loss = 0.4557722813480503, disc_loss = 0.03165456964839045
Trained batch 455 in epoch 8, gen_loss = 0.45583386157165495, disc_loss = 0.03161189121065514
Trained batch 456 in epoch 8, gen_loss = 0.455799908358889, disc_loss = 0.031572683109581896
Trained batch 457 in epoch 8, gen_loss = 0.4558225919586082, disc_loss = 0.031530246218385814
Trained batch 458 in epoch 8, gen_loss = 0.45591634466497466, disc_loss = 0.031476325534531654
Trained batch 459 in epoch 8, gen_loss = 0.4559283377683681, disc_loss = 0.0314157077916088
Trained batch 460 in epoch 8, gen_loss = 0.4560247153496277, disc_loss = 0.031595215665523986
Trained batch 461 in epoch 8, gen_loss = 0.45606468037351383, disc_loss = 0.031551106598578973
Trained batch 462 in epoch 8, gen_loss = 0.45589753058507687, disc_loss = 0.031611033664517445
Trained batch 463 in epoch 8, gen_loss = 0.4558603461061058, disc_loss = 0.03157539138969853
Trained batch 464 in epoch 8, gen_loss = 0.45587809515255756, disc_loss = 0.03156017103452756
Trained batch 465 in epoch 8, gen_loss = 0.455870531723223, disc_loss = 0.03154660862432833
Trained batch 466 in epoch 8, gen_loss = 0.45594821592725066, disc_loss = 0.031494240567179865
Trained batch 467 in epoch 8, gen_loss = 0.4559688217237464, disc_loss = 0.031480874620978996
Trained batch 468 in epoch 8, gen_loss = 0.45596554551297414, disc_loss = 0.03144961950341379
Trained batch 469 in epoch 8, gen_loss = 0.45598789897370845, disc_loss = 0.03139748336360889
Trained batch 470 in epoch 8, gen_loss = 0.45604061941179247, disc_loss = 0.031344194185174604
Trained batch 471 in epoch 8, gen_loss = 0.45604071690369463, disc_loss = 0.03128682204839868
Trained batch 472 in epoch 8, gen_loss = 0.45585756334643535, disc_loss = 0.031227863012236123
Trained batch 473 in epoch 8, gen_loss = 0.45580193721040896, disc_loss = 0.031171289455825424
Trained batch 474 in epoch 8, gen_loss = 0.4558044682678423, disc_loss = 0.031121481803588962
Trained batch 475 in epoch 8, gen_loss = 0.4558852947935337, disc_loss = 0.031061175145784065
Trained batch 476 in epoch 8, gen_loss = 0.4558524741191784, disc_loss = 0.031012721234284325
Trained batch 477 in epoch 8, gen_loss = 0.4558624496769207, disc_loss = 0.030958456056929002
Trained batch 478 in epoch 8, gen_loss = 0.45596958699953083, disc_loss = 0.03090268733331813
Trained batch 479 in epoch 8, gen_loss = 0.4559395872056484, disc_loss = 0.030866948592301924
Trained batch 480 in epoch 8, gen_loss = 0.4559270244502228, disc_loss = 0.030840979361898904
Trained batch 481 in epoch 8, gen_loss = 0.4560550627495738, disc_loss = 0.030800053828079023
Trained batch 482 in epoch 8, gen_loss = 0.45607202319625, disc_loss = 0.03075625624953081
Trained batch 483 in epoch 8, gen_loss = 0.45586380263990606, disc_loss = 0.030699741212200867
Trained batch 484 in epoch 8, gen_loss = 0.4557774308416032, disc_loss = 0.030666283928529964
Trained batch 485 in epoch 8, gen_loss = 0.4559069854119187, disc_loss = 0.031071072148730203
Trained batch 486 in epoch 8, gen_loss = 0.4558709443105075, disc_loss = 0.031139194066072115
Trained batch 487 in epoch 8, gen_loss = 0.4557659767079549, disc_loss = 0.031100796206881002
Trained batch 488 in epoch 8, gen_loss = 0.45568123197750565, disc_loss = 0.031048215591921977
Trained batch 489 in epoch 8, gen_loss = 0.45560769718520494, disc_loss = 0.03101126250706385
Trained batch 490 in epoch 8, gen_loss = 0.4556035110518306, disc_loss = 0.0309667617567225
Trained batch 491 in epoch 8, gen_loss = 0.4555661867304546, disc_loss = 0.030932673769416212
Trained batch 492 in epoch 8, gen_loss = 0.45555241173227706, disc_loss = 0.030944470582061408
Trained batch 493 in epoch 8, gen_loss = 0.4556732123438646, disc_loss = 0.030898988278495968
Trained batch 494 in epoch 8, gen_loss = 0.45570583674642773, disc_loss = 0.030852800723861415
Trained batch 495 in epoch 8, gen_loss = 0.45564124943508255, disc_loss = 0.030800935576177923
Trained batch 496 in epoch 8, gen_loss = 0.45576219041822424, disc_loss = 0.030810494272420615
Trained batch 497 in epoch 8, gen_loss = 0.45578721626456004, disc_loss = 0.030757716279495584
Trained batch 498 in epoch 8, gen_loss = 0.45585030574120117, disc_loss = 0.030823392568171053
Trained batch 499 in epoch 8, gen_loss = 0.4557972369194031, disc_loss = 0.030872880729380995
Trained batch 500 in epoch 8, gen_loss = 0.45581903797899653, disc_loss = 0.03082273280417208
Trained batch 501 in epoch 8, gen_loss = 0.45590778152306244, disc_loss = 0.03085086755946175
Trained batch 502 in epoch 8, gen_loss = 0.4558956979757275, disc_loss = 0.0308026176693092
Trained batch 503 in epoch 8, gen_loss = 0.45582799495212617, disc_loss = 0.030757540502005243
Trained batch 504 in epoch 8, gen_loss = 0.45589447753264173, disc_loss = 0.030716968777285206
Trained batch 505 in epoch 8, gen_loss = 0.4559411569075151, disc_loss = 0.030695213111238958
Trained batch 506 in epoch 8, gen_loss = 0.4561462877299894, disc_loss = 0.030722411025657193
Trained batch 507 in epoch 8, gen_loss = 0.4561402259731856, disc_loss = 0.030757254660111213
Trained batch 508 in epoch 8, gen_loss = 0.4562087701908029, disc_loss = 0.03074662859756536
Trained batch 509 in epoch 8, gen_loss = 0.45603506787150516, disc_loss = 0.03076288961924101
Trained batch 510 in epoch 8, gen_loss = 0.45603105350016615, disc_loss = 0.03074626422964707
Trained batch 511 in epoch 8, gen_loss = 0.45620721171144396, disc_loss = 0.03076431255931311
Trained batch 512 in epoch 8, gen_loss = 0.45618374079291585, disc_loss = 0.03082223762630995
Trained batch 513 in epoch 8, gen_loss = 0.45620133040712035, disc_loss = 0.03077474425244236
Trained batch 514 in epoch 8, gen_loss = 0.45623448224901, disc_loss = 0.030811851525462224
Trained batch 515 in epoch 8, gen_loss = 0.45622610052426654, disc_loss = 0.03078656585827513
Trained batch 516 in epoch 8, gen_loss = 0.45601388010803456, disc_loss = 0.03099222400503114
Trained batch 517 in epoch 8, gen_loss = 0.45594483090413584, disc_loss = 0.030974922082782453
Trained batch 518 in epoch 8, gen_loss = 0.45615332945463516, disc_loss = 0.03097643040664322
Trained batch 519 in epoch 8, gen_loss = 0.4561763463112024, disc_loss = 0.031021606513352777
Trained batch 520 in epoch 8, gen_loss = 0.4561183456610352, disc_loss = 0.03102108417123542
Trained batch 521 in epoch 8, gen_loss = 0.45611900410889666, disc_loss = 0.030997577718801624
Trained batch 522 in epoch 8, gen_loss = 0.45619776588552996, disc_loss = 0.030964861783763505
Trained batch 523 in epoch 8, gen_loss = 0.4562885300576232, disc_loss = 0.030947867664952854
Trained batch 524 in epoch 8, gen_loss = 0.45632578179949806, disc_loss = 0.030897160098400146
Trained batch 525 in epoch 8, gen_loss = 0.4563967670551271, disc_loss = 0.03085996349786582
Trained batch 526 in epoch 8, gen_loss = 0.45636179375919944, disc_loss = 0.030865582222635
Trained batch 527 in epoch 8, gen_loss = 0.4562891214860208, disc_loss = 0.030865858150663728
Trained batch 528 in epoch 8, gen_loss = 0.45613506408179416, disc_loss = 0.030824493291560694
Trained batch 529 in epoch 8, gen_loss = 0.4560916298965238, disc_loss = 0.030771908938955022
Trained batch 530 in epoch 8, gen_loss = 0.4561073370348038, disc_loss = 0.030758016500727268
Trained batch 531 in epoch 8, gen_loss = 0.4561949245687714, disc_loss = 0.030740724801246944
Trained batch 532 in epoch 8, gen_loss = 0.4561602697475319, disc_loss = 0.03069460493867158
Trained batch 533 in epoch 8, gen_loss = 0.45610646579819225, disc_loss = 0.030670858548137912
Trained batch 534 in epoch 8, gen_loss = 0.45605497833724334, disc_loss = 0.030635373759144376
Trained batch 535 in epoch 8, gen_loss = 0.45614270971559767, disc_loss = 0.030643187322542627
Trained batch 536 in epoch 8, gen_loss = 0.45605932622870476, disc_loss = 0.03059300622084218
Trained batch 537 in epoch 8, gen_loss = 0.4562115665926809, disc_loss = 0.030547614436558547
Trained batch 538 in epoch 8, gen_loss = 0.45613894983434944, disc_loss = 0.030621473197540154
Trained batch 539 in epoch 8, gen_loss = 0.45611426063157895, disc_loss = 0.03059369233755947
Trained batch 540 in epoch 8, gen_loss = 0.4560925545732107, disc_loss = 0.030609056207673305
Trained batch 541 in epoch 8, gen_loss = 0.45601925176887936, disc_loss = 0.03056833926610635
Trained batch 542 in epoch 8, gen_loss = 0.45585804716658196, disc_loss = 0.03061868949333621
Trained batch 543 in epoch 8, gen_loss = 0.45579856431440396, disc_loss = 0.0305741044375121
Trained batch 544 in epoch 8, gen_loss = 0.45568779542905474, disc_loss = 0.030566915767609115
Trained batch 545 in epoch 8, gen_loss = 0.45570300699590327, disc_loss = 0.03053379946536702
Trained batch 546 in epoch 8, gen_loss = 0.4556342508282914, disc_loss = 0.030506666845487095
Trained batch 547 in epoch 8, gen_loss = 0.4555452507886573, disc_loss = 0.03047631130711835
Trained batch 548 in epoch 8, gen_loss = 0.4554869789351965, disc_loss = 0.030452056281109134
Trained batch 549 in epoch 8, gen_loss = 0.4554143076051365, disc_loss = 0.03050226840825582
Trained batch 550 in epoch 8, gen_loss = 0.4555811872824134, disc_loss = 0.03075553534320892
Trained batch 551 in epoch 8, gen_loss = 0.45571970038008, disc_loss = 0.030766942714209385
Trained batch 552 in epoch 8, gen_loss = 0.4556786319338607, disc_loss = 0.030736093992488642
Trained batch 553 in epoch 8, gen_loss = 0.45557650789241927, disc_loss = 0.030725295556665463
Trained batch 554 in epoch 8, gen_loss = 0.4555305204412959, disc_loss = 0.03070602140993484
Trained batch 555 in epoch 8, gen_loss = 0.4555898566576217, disc_loss = 0.030715327882861194
Trained batch 556 in epoch 8, gen_loss = 0.45560115575790405, disc_loss = 0.03068554143110354
Trained batch 557 in epoch 8, gen_loss = 0.4555900831803626, disc_loss = 0.030692956485872332
Trained batch 558 in epoch 8, gen_loss = 0.45552100766323544, disc_loss = 0.03077628371415723
Trained batch 559 in epoch 8, gen_loss = 0.4555091552968536, disc_loss = 0.030780928421050444
Trained batch 560 in epoch 8, gen_loss = 0.45552200743008847, disc_loss = 0.030759446222066163
Trained batch 561 in epoch 8, gen_loss = 0.455579661548774, disc_loss = 0.03072155141926228
Trained batch 562 in epoch 8, gen_loss = 0.4554772226679177, disc_loss = 0.030678545373374493
Trained batch 563 in epoch 8, gen_loss = 0.45541885003764576, disc_loss = 0.030690016894162044
Trained batch 564 in epoch 8, gen_loss = 0.45524949958894106, disc_loss = 0.03066290088731433
Trained batch 565 in epoch 8, gen_loss = 0.4551854915522013, disc_loss = 0.030837878656027305
Trained batch 566 in epoch 8, gen_loss = 0.45531112360365594, disc_loss = 0.0308652127336553
Trained batch 567 in epoch 8, gen_loss = 0.4554176193622636, disc_loss = 0.0308749702825493
Trained batch 568 in epoch 8, gen_loss = 0.455368131032518, disc_loss = 0.030864609666054116
Trained batch 569 in epoch 8, gen_loss = 0.4554193453830585, disc_loss = 0.03092703461981983
Trained batch 570 in epoch 8, gen_loss = 0.45545511341763045, disc_loss = 0.030882264812429634
Trained batch 571 in epoch 8, gen_loss = 0.4555374449574864, disc_loss = 0.0308786329843423
Trained batch 572 in epoch 8, gen_loss = 0.45564284405783206, disc_loss = 0.030837385601934574
Trained batch 573 in epoch 8, gen_loss = 0.4555813860706336, disc_loss = 0.030797294661068463
Trained batch 574 in epoch 8, gen_loss = 0.45579106595205227, disc_loss = 0.03078598144464195
Trained batch 575 in epoch 8, gen_loss = 0.45569100820769864, disc_loss = 0.030751613701593468
Trained batch 576 in epoch 8, gen_loss = 0.455586206871674, disc_loss = 0.03075161436370911
Trained batch 577 in epoch 8, gen_loss = 0.45557253552555627, disc_loss = 0.030782056329884667
Trained batch 578 in epoch 8, gen_loss = 0.45546241796902015, disc_loss = 0.030758653423589667
Trained batch 579 in epoch 8, gen_loss = 0.45537137348076395, disc_loss = 0.03073782879931467
Trained batch 580 in epoch 8, gen_loss = 0.4551863942211959, disc_loss = 0.03070456702174
Trained batch 581 in epoch 8, gen_loss = 0.45524088198581514, disc_loss = 0.030725262510667064
Trained batch 582 in epoch 8, gen_loss = 0.4552516612139615, disc_loss = 0.030898986907043267
Trained batch 583 in epoch 8, gen_loss = 0.4552232599115535, disc_loss = 0.03087191976015201
Trained batch 584 in epoch 8, gen_loss = 0.4550860242965894, disc_loss = 0.030881230904458042
Trained batch 585 in epoch 8, gen_loss = 0.45522090345112537, disc_loss = 0.030946935939049482
Trained batch 586 in epoch 8, gen_loss = 0.45522637373341, disc_loss = 0.030909425001892893
Trained batch 587 in epoch 8, gen_loss = 0.45521863103926585, disc_loss = 0.0308991598054849
Trained batch 588 in epoch 8, gen_loss = 0.4552033209132824, disc_loss = 0.03088199109960101
Trained batch 589 in epoch 8, gen_loss = 0.4553218131853362, disc_loss = 0.030955995839104942
Trained batch 590 in epoch 8, gen_loss = 0.4551665549955997, disc_loss = 0.03101101767802816
Trained batch 591 in epoch 8, gen_loss = 0.4550859741363171, disc_loss = 0.031001272924776137
Trained batch 592 in epoch 8, gen_loss = 0.45507836507705574, disc_loss = 0.03098166462475305
Trained batch 593 in epoch 8, gen_loss = 0.4550287014607227, disc_loss = 0.03095037569973919
Trained batch 594 in epoch 8, gen_loss = 0.45495424666324585, disc_loss = 0.030913864929589027
Trained batch 595 in epoch 8, gen_loss = 0.45486799237512104, disc_loss = 0.030973210057709366
Trained batch 596 in epoch 8, gen_loss = 0.4547531143005569, disc_loss = 0.030956915489645985
Trained batch 597 in epoch 8, gen_loss = 0.45450521068628813, disc_loss = 0.030998936336079495
Trained batch 598 in epoch 8, gen_loss = 0.4543249328466807, disc_loss = 0.031018808635281326
Trained batch 599 in epoch 8, gen_loss = 0.4545394450426102, disc_loss = 0.031135797577056413
Trained batch 600 in epoch 8, gen_loss = 0.45452787525046884, disc_loss = 0.031116937687341587
Trained batch 601 in epoch 8, gen_loss = 0.4544962849529875, disc_loss = 0.03108877682960917
Trained batch 602 in epoch 8, gen_loss = 0.4543912102333942, disc_loss = 0.0314936175448959
Trained batch 603 in epoch 8, gen_loss = 0.4544016844192088, disc_loss = 0.03159627255972857
Trained batch 604 in epoch 8, gen_loss = 0.45447719235065553, disc_loss = 0.031644028362487094
Trained batch 605 in epoch 8, gen_loss = 0.45433985606671956, disc_loss = 0.03174473513601649
Trained batch 606 in epoch 8, gen_loss = 0.45438000481250457, disc_loss = 0.031929683951734636
Trained batch 607 in epoch 8, gen_loss = 0.45427161920815706, disc_loss = 0.03219951303119734
Trained batch 608 in epoch 8, gen_loss = 0.45438006490909405, disc_loss = 0.03227124503761689
Trained batch 609 in epoch 8, gen_loss = 0.4543491523285381, disc_loss = 0.032249482805443715
Trained batch 610 in epoch 8, gen_loss = 0.45432974824928807, disc_loss = 0.0322557618119792
Trained batch 611 in epoch 8, gen_loss = 0.45448269139902264, disc_loss = 0.032265092506837345
Trained batch 612 in epoch 8, gen_loss = 0.4545088363218852, disc_loss = 0.032231017733357396
Trained batch 613 in epoch 8, gen_loss = 0.45456311359079343, disc_loss = 0.032195140430567246
Trained batch 614 in epoch 8, gen_loss = 0.4545423084158238, disc_loss = 0.032171923493421295
Trained batch 615 in epoch 8, gen_loss = 0.45463773588855544, disc_loss = 0.03212752127558803
Trained batch 616 in epoch 8, gen_loss = 0.4546552258913482, disc_loss = 0.03208989575558087
Trained batch 617 in epoch 8, gen_loss = 0.45462174525538696, disc_loss = 0.0320499460163909
Trained batch 618 in epoch 8, gen_loss = 0.45452628093312747, disc_loss = 0.032023112540492886
Trained batch 619 in epoch 8, gen_loss = 0.45456301728563925, disc_loss = 0.03198835688245092
Trained batch 620 in epoch 8, gen_loss = 0.4545784993832046, disc_loss = 0.031967480057676516
Trained batch 621 in epoch 8, gen_loss = 0.45465357893916186, disc_loss = 0.03192462959406161
Trained batch 622 in epoch 8, gen_loss = 0.4546932329335526, disc_loss = 0.0318917038653907
Trained batch 623 in epoch 8, gen_loss = 0.4545845033075565, disc_loss = 0.03185785348334601
Trained batch 624 in epoch 8, gen_loss = 0.454418425655365, disc_loss = 0.03191557978652418
Trained batch 625 in epoch 8, gen_loss = 0.4545100802621141, disc_loss = 0.031897113304034753
Trained batch 626 in epoch 8, gen_loss = 0.4544864871095052, disc_loss = 0.03186801825857987
Trained batch 627 in epoch 8, gen_loss = 0.4544504053273778, disc_loss = 0.03182797026071567
Trained batch 628 in epoch 8, gen_loss = 0.4543540903229403, disc_loss = 0.03179797295159668
Trained batch 629 in epoch 8, gen_loss = 0.45438655506050774, disc_loss = 0.03176647880417664
Trained batch 630 in epoch 8, gen_loss = 0.4543751062096204, disc_loss = 0.03175626202300486
Trained batch 631 in epoch 8, gen_loss = 0.45440724468495275, disc_loss = 0.03171638385694816
Trained batch 632 in epoch 8, gen_loss = 0.45441330387882334, disc_loss = 0.03167969813992639
Trained batch 633 in epoch 8, gen_loss = 0.4543433088327432, disc_loss = 0.03163723965367884
Trained batch 634 in epoch 8, gen_loss = 0.4543923137225504, disc_loss = 0.03163032143846096
Trained batch 635 in epoch 8, gen_loss = 0.45435492061781435, disc_loss = 0.03164531455013561
Trained batch 636 in epoch 8, gen_loss = 0.45432628052575247, disc_loss = 0.03162509876265362
Trained batch 637 in epoch 8, gen_loss = 0.4544071836344501, disc_loss = 0.03160758959574678
Trained batch 638 in epoch 8, gen_loss = 0.4545184940053077, disc_loss = 0.03158008750908497
Trained batch 639 in epoch 8, gen_loss = 0.45451014284044505, disc_loss = 0.03154161844031478
Trained batch 640 in epoch 8, gen_loss = 0.4544550086053411, disc_loss = 0.031644395789764995
Trained batch 641 in epoch 8, gen_loss = 0.4544405031519887, disc_loss = 0.03187335797003833
Trained batch 642 in epoch 8, gen_loss = 0.45453814209712606, disc_loss = 0.03184265868476133
Trained batch 643 in epoch 8, gen_loss = 0.45470997732803686, disc_loss = 0.03182550845125413
Trained batch 644 in epoch 8, gen_loss = 0.45465894355330355, disc_loss = 0.0318232442089898
Trained batch 645 in epoch 8, gen_loss = 0.45472011399158385, disc_loss = 0.03181173802669169
Trained batch 646 in epoch 8, gen_loss = 0.4546872085821131, disc_loss = 0.03177950033231407
Trained batch 647 in epoch 8, gen_loss = 0.4548309969221368, disc_loss = 0.03216369508192184
Trained batch 648 in epoch 8, gen_loss = 0.45491501900190934, disc_loss = 0.03218469987494243
Trained batch 649 in epoch 8, gen_loss = 0.45482710503614865, disc_loss = 0.03243692298957075
Trained batch 650 in epoch 8, gen_loss = 0.454842745799989, disc_loss = 0.032490961877743606
Trained batch 651 in epoch 8, gen_loss = 0.45480830185800974, disc_loss = 0.032483912293407836
Trained batch 652 in epoch 8, gen_loss = 0.45482115536517426, disc_loss = 0.032454185198156724
Trained batch 653 in epoch 8, gen_loss = 0.45486045467015074, disc_loss = 0.032414935984569015
Trained batch 654 in epoch 8, gen_loss = 0.45483003217755386, disc_loss = 0.032427206498620506
Trained batch 655 in epoch 8, gen_loss = 0.4547823360871251, disc_loss = 0.03243879054455802
Trained batch 656 in epoch 8, gen_loss = 0.4547166890114591, disc_loss = 0.032400144280758054
Trained batch 657 in epoch 8, gen_loss = 0.45468274134814196, disc_loss = 0.03238687903151811
Trained batch 658 in epoch 8, gen_loss = 0.45480344658194616, disc_loss = 0.032405643371655996
Trained batch 659 in epoch 8, gen_loss = 0.45470094883983786, disc_loss = 0.03238788175671785
Trained batch 660 in epoch 8, gen_loss = 0.45467663483071435, disc_loss = 0.032361044250809094
Trained batch 661 in epoch 8, gen_loss = 0.4546483181124367, disc_loss = 0.032341030794561604
Trained batch 662 in epoch 8, gen_loss = 0.4546129310202994, disc_loss = 0.032345167381919324
Trained batch 663 in epoch 8, gen_loss = 0.45454119787697334, disc_loss = 0.03231977807541647
Trained batch 664 in epoch 8, gen_loss = 0.45449296706601194, disc_loss = 0.03229418368765006
Trained batch 665 in epoch 8, gen_loss = 0.4543944554733442, disc_loss = 0.03226085243482344
Trained batch 666 in epoch 8, gen_loss = 0.4544166300160953, disc_loss = 0.03223149782930525
Trained batch 667 in epoch 8, gen_loss = 0.45429616622225255, disc_loss = 0.03220545192783096
Trained batch 668 in epoch 8, gen_loss = 0.45420029768316555, disc_loss = 0.03216679587017784
Trained batch 669 in epoch 8, gen_loss = 0.4542158279401153, disc_loss = 0.03214993295433528
Trained batch 670 in epoch 8, gen_loss = 0.454195972748556, disc_loss = 0.03211669015889674
Trained batch 671 in epoch 8, gen_loss = 0.45420751716232016, disc_loss = 0.032112282883428545
Trained batch 672 in epoch 8, gen_loss = 0.45421080160636956, disc_loss = 0.0320771553399343
Trained batch 673 in epoch 8, gen_loss = 0.4542143415184332, disc_loss = 0.032084997983453156
Trained batch 674 in epoch 8, gen_loss = 0.4543224291889756, disc_loss = 0.03213064324766122
Trained batch 675 in epoch 8, gen_loss = 0.4542844553406422, disc_loss = 0.03219715581577238
Trained batch 676 in epoch 8, gen_loss = 0.4542796182579621, disc_loss = 0.03221576497133442
Trained batch 677 in epoch 8, gen_loss = 0.4541571772819423, disc_loss = 0.032248876238541245
Trained batch 678 in epoch 8, gen_loss = 0.4540609780133912, disc_loss = 0.03227686878418569
Trained batch 679 in epoch 8, gen_loss = 0.4540326400714762, disc_loss = 0.03230200280839413
Trained batch 680 in epoch 8, gen_loss = 0.45425146616853107, disc_loss = 0.032362195847435646
Trained batch 681 in epoch 8, gen_loss = 0.4543660353006156, disc_loss = 0.03239677699188541
Trained batch 682 in epoch 8, gen_loss = 0.45436588400977596, disc_loss = 0.0324385608481666
Trained batch 683 in epoch 8, gen_loss = 0.45446853012892235, disc_loss = 0.032413575629096435
Trained batch 684 in epoch 8, gen_loss = 0.45445309707718173, disc_loss = 0.03241064215629586
Trained batch 685 in epoch 8, gen_loss = 0.4544070777496861, disc_loss = 0.03237737754445371
Trained batch 686 in epoch 8, gen_loss = 0.4544207898376637, disc_loss = 0.03234474038402923
Trained batch 687 in epoch 8, gen_loss = 0.4544535076548887, disc_loss = 0.032323589029675893
Trained batch 688 in epoch 8, gen_loss = 0.45445785570905933, disc_loss = 0.032281780848955444
Trained batch 689 in epoch 8, gen_loss = 0.45442775859349016, disc_loss = 0.03225125005650942
Trained batch 690 in epoch 8, gen_loss = 0.45450004525536564, disc_loss = 0.03221034483112093
Trained batch 691 in epoch 8, gen_loss = 0.45460433052109844, disc_loss = 0.032170889562337705
Trained batch 692 in epoch 8, gen_loss = 0.45455112188925473, disc_loss = 0.032131880057792876
Trained batch 693 in epoch 8, gen_loss = 0.4545376068061642, disc_loss = 0.03209180236956432
Trained batch 694 in epoch 8, gen_loss = 0.45455757525327395, disc_loss = 0.03205456384993661
Trained batch 695 in epoch 8, gen_loss = 0.4545389391139321, disc_loss = 0.03201664123388446
Trained batch 696 in epoch 8, gen_loss = 0.454567163883357, disc_loss = 0.03197869662846167
Trained batch 697 in epoch 8, gen_loss = 0.4545137942008098, disc_loss = 0.031937623170023
Trained batch 698 in epoch 8, gen_loss = 0.4544873665671833, disc_loss = 0.031895632975173845
Trained batch 699 in epoch 8, gen_loss = 0.45458282606942313, disc_loss = 0.03185739766107872
Trained batch 700 in epoch 8, gen_loss = 0.4544555126090193, disc_loss = 0.03182204527888027
Trained batch 701 in epoch 8, gen_loss = 0.4545019315263824, disc_loss = 0.03179745879150301
Trained batch 702 in epoch 8, gen_loss = 0.45459247038171097, disc_loss = 0.031774633541202454
Trained batch 703 in epoch 8, gen_loss = 0.45456452121619473, disc_loss = 0.03173486155620511
Trained batch 704 in epoch 8, gen_loss = 0.4545593497600961, disc_loss = 0.031697219193761124
Trained batch 705 in epoch 8, gen_loss = 0.45459371425274747, disc_loss = 0.031660270475170366
Trained batch 706 in epoch 8, gen_loss = 0.45458598091376384, disc_loss = 0.03161951422900794
Trained batch 707 in epoch 8, gen_loss = 0.45466410128747003, disc_loss = 0.03166790196828618
Trained batch 708 in epoch 8, gen_loss = 0.4545432559525849, disc_loss = 0.03165070129570266
Trained batch 709 in epoch 8, gen_loss = 0.4544419828015314, disc_loss = 0.031629770623952884
Trained batch 710 in epoch 8, gen_loss = 0.45445795438963654, disc_loss = 0.03159447923681205
Trained batch 711 in epoch 8, gen_loss = 0.45450169706110205, disc_loss = 0.03162377378726745
Trained batch 712 in epoch 8, gen_loss = 0.4545177069569704, disc_loss = 0.03161446621927575
Trained batch 713 in epoch 8, gen_loss = 0.4545052219756177, disc_loss = 0.03158643847254446
Trained batch 714 in epoch 8, gen_loss = 0.45458002394729563, disc_loss = 0.031578362694374855
Trained batch 715 in epoch 8, gen_loss = 0.45453047286198794, disc_loss = 0.03156073670866821
Trained batch 716 in epoch 8, gen_loss = 0.45457942918919786, disc_loss = 0.03152677639143352
Trained batch 717 in epoch 8, gen_loss = 0.45466713590708285, disc_loss = 0.03149212293182876
Trained batch 718 in epoch 8, gen_loss = 0.4546473536521238, disc_loss = 0.03146004350434973
Trained batch 719 in epoch 8, gen_loss = 0.45461807288229467, disc_loss = 0.031425765275424865
Trained batch 720 in epoch 8, gen_loss = 0.45462047243581233, disc_loss = 0.031398339033961276
Trained batch 721 in epoch 8, gen_loss = 0.45468119480273067, disc_loss = 0.031378038173058995
Trained batch 722 in epoch 8, gen_loss = 0.45471771088213675, disc_loss = 0.03134492889431822
Trained batch 723 in epoch 8, gen_loss = 0.454661533853955, disc_loss = 0.0313163918262291
Trained batch 724 in epoch 8, gen_loss = 0.4547603443162195, disc_loss = 0.03127971337241089
Trained batch 725 in epoch 8, gen_loss = 0.4547404767971065, disc_loss = 0.031243747705401285
Trained batch 726 in epoch 8, gen_loss = 0.45474791055368424, disc_loss = 0.031206420933740646
Trained batch 727 in epoch 8, gen_loss = 0.45466069365431977, disc_loss = 0.031168656558013305
Trained batch 728 in epoch 8, gen_loss = 0.4546396026313714, disc_loss = 0.0311329550772844
Trained batch 729 in epoch 8, gen_loss = 0.4546097178573478, disc_loss = 0.031093958500543074
Trained batch 730 in epoch 8, gen_loss = 0.454549267296915, disc_loss = 0.031056304703365945
Trained batch 731 in epoch 8, gen_loss = 0.4544835509172554, disc_loss = 0.031017576665884707
Trained batch 732 in epoch 8, gen_loss = 0.45446058201106804, disc_loss = 0.030981800251794117
Trained batch 733 in epoch 8, gen_loss = 0.45448248128962454, disc_loss = 0.0309489878907683
Trained batch 734 in epoch 8, gen_loss = 0.4544883494879924, disc_loss = 0.030910565921099108
Trained batch 735 in epoch 8, gen_loss = 0.45462166416742233, disc_loss = 0.03087220113704224
Trained batch 736 in epoch 8, gen_loss = 0.45457344543658895, disc_loss = 0.03083338652796831
Trained batch 737 in epoch 8, gen_loss = 0.45458442832880874, disc_loss = 0.030795580640606845
Trained batch 738 in epoch 8, gen_loss = 0.45455657262279475, disc_loss = 0.03076549012879356
Trained batch 739 in epoch 8, gen_loss = 0.454596333809801, disc_loss = 0.03072719793653468
Trained batch 740 in epoch 8, gen_loss = 0.45469411013097416, disc_loss = 0.030690779144386792
Trained batch 741 in epoch 8, gen_loss = 0.45468127807838254, disc_loss = 0.030656785260813155
Trained batch 742 in epoch 8, gen_loss = 0.4546564235822028, disc_loss = 0.030627238367086283
Trained batch 743 in epoch 8, gen_loss = 0.45459209951341795, disc_loss = 0.030593777382408358
Trained batch 744 in epoch 8, gen_loss = 0.4545912691810787, disc_loss = 0.030557759251170512
Trained batch 745 in epoch 8, gen_loss = 0.4545790334569225, disc_loss = 0.030521371356903228
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.4961448609828949, disc_loss = 0.0022196893114596605
Trained batch 1 in epoch 9, gen_loss = 0.4500201940536499, disc_loss = 0.00674352387432009
Trained batch 2 in epoch 9, gen_loss = 0.4472278853257497, disc_loss = 0.007158129553621014
Trained batch 3 in epoch 9, gen_loss = 0.4460882693529129, disc_loss = 0.006373429496306926
Trained batch 4 in epoch 9, gen_loss = 0.4537229657173157, disc_loss = 0.0056034338660538195
Trained batch 5 in epoch 9, gen_loss = 0.45045751829942066, disc_loss = 0.005310015248445173
Trained batch 6 in epoch 9, gen_loss = 0.44601056831223623, disc_loss = 0.004942753052871142
Trained batch 7 in epoch 9, gen_loss = 0.4402332566678524, disc_loss = 0.004750123218400404
Trained batch 8 in epoch 9, gen_loss = 0.4406048191918267, disc_loss = 0.004539908453201254
Trained batch 9 in epoch 9, gen_loss = 0.44167502522468566, disc_loss = 0.0043865678599104285
Trained batch 10 in epoch 9, gen_loss = 0.44726677374406293, disc_loss = 0.004180743761191314
Trained batch 11 in epoch 9, gen_loss = 0.4446685140331586, disc_loss = 0.004128329417047401
Trained batch 12 in epoch 9, gen_loss = 0.4442525551869319, disc_loss = 0.004215879473262108
Trained batch 13 in epoch 9, gen_loss = 0.44234039528029306, disc_loss = 0.004083347373775074
Trained batch 14 in epoch 9, gen_loss = 0.4438970943291982, disc_loss = 0.00397415803745389
Trained batch 15 in epoch 9, gen_loss = 0.44221552088856697, disc_loss = 0.0038272004894679412
Trained batch 16 in epoch 9, gen_loss = 0.4449689598644481, disc_loss = 0.003690877422580824
Trained batch 17 in epoch 9, gen_loss = 0.445044693019655, disc_loss = 0.0036910889385682014
Trained batch 18 in epoch 9, gen_loss = 0.44588334309427363, disc_loss = 0.0036822063603291384
Trained batch 19 in epoch 9, gen_loss = 0.44636745750904083, disc_loss = 0.0036473112064413725
Trained batch 20 in epoch 9, gen_loss = 0.4425133693785894, disc_loss = 0.003566765304033955
Trained batch 21 in epoch 9, gen_loss = 0.4441098503091119, disc_loss = 0.0036837465277957645
Trained batch 22 in epoch 9, gen_loss = 0.4438819626103277, disc_loss = 0.003613686563609087
Trained batch 23 in epoch 9, gen_loss = 0.44598161180814105, disc_loss = 0.0036111856849553683
Trained batch 24 in epoch 9, gen_loss = 0.4486790037155151, disc_loss = 0.0035501708555966617
Trained batch 25 in epoch 9, gen_loss = 0.4509740357215588, disc_loss = 0.0035518096634545005
Trained batch 26 in epoch 9, gen_loss = 0.45092721559383253, disc_loss = 0.0035482509906783147
Trained batch 27 in epoch 9, gen_loss = 0.45062228611537386, disc_loss = 0.0035074599436484277
Trained batch 28 in epoch 9, gen_loss = 0.45084103017017757, disc_loss = 0.0034766860771924257
Trained batch 29 in epoch 9, gen_loss = 0.44929011166095734, disc_loss = 0.0034268825547769666
Trained batch 30 in epoch 9, gen_loss = 0.45039602921855065, disc_loss = 0.0035396727297695415
Trained batch 31 in epoch 9, gen_loss = 0.4492708267644048, disc_loss = 0.0036726866019307636
Trained batch 32 in epoch 9, gen_loss = 0.4480304176157171, disc_loss = 0.003708690284948909
Trained batch 33 in epoch 9, gen_loss = 0.4465494576622458, disc_loss = 0.0038805110585492324
Trained batch 34 in epoch 9, gen_loss = 0.4450153487069266, disc_loss = 0.003843968501314521
Trained batch 35 in epoch 9, gen_loss = 0.4444718932112058, disc_loss = 0.0038186932668193346
Trained batch 36 in epoch 9, gen_loss = 0.4443617438947832, disc_loss = 0.003791564263755808
Trained batch 37 in epoch 9, gen_loss = 0.4436953538342526, disc_loss = 0.0037435052463000544
Trained batch 38 in epoch 9, gen_loss = 0.44573119817635953, disc_loss = 0.003697699598538188
Trained batch 39 in epoch 9, gen_loss = 0.4466899812221527, disc_loss = 0.003653926495462656
Trained batch 40 in epoch 9, gen_loss = 0.44687968710573706, disc_loss = 0.00359968378254008
Trained batch 41 in epoch 9, gen_loss = 0.44679544156505946, disc_loss = 0.003561547547135325
Trained batch 42 in epoch 9, gen_loss = 0.4463540537412776, disc_loss = 0.0037948308664179126
Trained batch 43 in epoch 9, gen_loss = 0.44597978483546863, disc_loss = 0.003876166047782383
Trained batch 44 in epoch 9, gen_loss = 0.4453060739570194, disc_loss = 0.0038490074117564495
Trained batch 45 in epoch 9, gen_loss = 0.44633857841077057, disc_loss = 0.003855771450933231
Trained batch 46 in epoch 9, gen_loss = 0.44757894759482525, disc_loss = 0.0038136605847072093
Trained batch 47 in epoch 9, gen_loss = 0.4473092233141263, disc_loss = 0.0038032034838882587
Trained batch 48 in epoch 9, gen_loss = 0.4460954593152416, disc_loss = 0.0037581058532683825
Trained batch 49 in epoch 9, gen_loss = 0.4480840063095093, disc_loss = 0.0037242421181872486
Trained batch 50 in epoch 9, gen_loss = 0.4474375879063326, disc_loss = 0.003676895899058995
Trained batch 51 in epoch 9, gen_loss = 0.4481893376662181, disc_loss = 0.003647601552074775
Trained batch 52 in epoch 9, gen_loss = 0.4484451896739456, disc_loss = 0.0036009409583507563
Trained batch 53 in epoch 9, gen_loss = 0.4483553750647439, disc_loss = 0.0035559303467851823
Trained batch 54 in epoch 9, gen_loss = 0.4493016475980932, disc_loss = 0.0035145971437238834
Trained batch 55 in epoch 9, gen_loss = 0.44869818538427353, disc_loss = 0.004067932773198534
Trained batch 56 in epoch 9, gen_loss = 0.4496068713957803, disc_loss = 0.004137358499543839
Trained batch 57 in epoch 9, gen_loss = 0.4487507076099001, disc_loss = 0.004138119906138885
Trained batch 58 in epoch 9, gen_loss = 0.44821630645606475, disc_loss = 0.004124339032618297
Trained batch 59 in epoch 9, gen_loss = 0.4497105086843173, disc_loss = 0.0043093593422478685
Trained batch 60 in epoch 9, gen_loss = 0.4500074293769774, disc_loss = 0.004357932221342916
Trained batch 61 in epoch 9, gen_loss = 0.4499256649324971, disc_loss = 0.004327025641912534
Trained batch 62 in epoch 9, gen_loss = 0.4499060289254264, disc_loss = 0.004307727723027624
Trained batch 63 in epoch 9, gen_loss = 0.4504046021029353, disc_loss = 0.004365473587313318
Trained batch 64 in epoch 9, gen_loss = 0.4495699882507324, disc_loss = 0.004412311754332712
Trained batch 65 in epoch 9, gen_loss = 0.45023018979665, disc_loss = 0.004504124177125932
Trained batch 66 in epoch 9, gen_loss = 0.45105729574587805, disc_loss = 0.004488542611682926
Trained batch 67 in epoch 9, gen_loss = 0.4524759961401715, disc_loss = 0.004459651729763102
Trained batch 68 in epoch 9, gen_loss = 0.4526950146840966, disc_loss = 0.0044973386077048335
Trained batch 69 in epoch 9, gen_loss = 0.45301891735621863, disc_loss = 0.004506844756126936
Trained batch 70 in epoch 9, gen_loss = 0.4529949418255981, disc_loss = 0.004506344600370757
Trained batch 71 in epoch 9, gen_loss = 0.4533403238488568, disc_loss = 0.0045186018833192065
Trained batch 72 in epoch 9, gen_loss = 0.4525680133741196, disc_loss = 0.004480490086230207
Trained batch 73 in epoch 9, gen_loss = 0.45276951226028234, disc_loss = 0.004449229361804051
Trained batch 74 in epoch 9, gen_loss = 0.4521324110031128, disc_loss = 0.0044314897510533535
Trained batch 75 in epoch 9, gen_loss = 0.45264606217020437, disc_loss = 0.004501269341409697
Trained batch 76 in epoch 9, gen_loss = 0.4533671616733848, disc_loss = 0.004489357569617788
Trained batch 77 in epoch 9, gen_loss = 0.4526733595591325, disc_loss = 0.004465513216415182
Trained batch 78 in epoch 9, gen_loss = 0.4526416327379927, disc_loss = 0.004441181502800105
Trained batch 79 in epoch 9, gen_loss = 0.45271937921643257, disc_loss = 0.004431411733094137
Trained batch 80 in epoch 9, gen_loss = 0.453235759779259, disc_loss = 0.0044131212692454826
Trained batch 81 in epoch 9, gen_loss = 0.45316350823495444, disc_loss = 0.00437802285745331
Trained batch 82 in epoch 9, gen_loss = 0.4541593775691756, disc_loss = 0.004352005679687732
Trained batch 83 in epoch 9, gen_loss = 0.4546751213215646, disc_loss = 0.004321214805323896
Trained batch 84 in epoch 9, gen_loss = 0.4546996681129231, disc_loss = 0.0043020599617568005
Trained batch 85 in epoch 9, gen_loss = 0.45462394141873647, disc_loss = 0.004277658501239277
Trained batch 86 in epoch 9, gen_loss = 0.45530434004191694, disc_loss = 0.004250817370183509
Trained batch 87 in epoch 9, gen_loss = 0.4548016200688752, disc_loss = 0.0042270398196044634
Trained batch 88 in epoch 9, gen_loss = 0.45501748330137703, disc_loss = 0.004220643941459529
Trained batch 89 in epoch 9, gen_loss = 0.4550758931371901, disc_loss = 0.004189615431500392
Trained batch 90 in epoch 9, gen_loss = 0.4552979308825273, disc_loss = 0.004161237453745043
Trained batch 91 in epoch 9, gen_loss = 0.4555340444912081, disc_loss = 0.0041320454873367335
Trained batch 92 in epoch 9, gen_loss = 0.45577545287788557, disc_loss = 0.004126128834492016
Trained batch 93 in epoch 9, gen_loss = 0.45586346501999714, disc_loss = 0.004260612794128742
Trained batch 94 in epoch 9, gen_loss = 0.4563944967169511, disc_loss = 0.0042365985125989505
Trained batch 95 in epoch 9, gen_loss = 0.45597119722515345, disc_loss = 0.004229982462372088
Trained batch 96 in epoch 9, gen_loss = 0.4568673989821955, disc_loss = 0.004214867701053082
Trained batch 97 in epoch 9, gen_loss = 0.45728740673892354, disc_loss = 0.0041992242830539385
Trained batch 98 in epoch 9, gen_loss = 0.457166544415734, disc_loss = 0.004201302207263205
Trained batch 99 in epoch 9, gen_loss = 0.45709744304418565, disc_loss = 0.004192415525903925
Trained batch 100 in epoch 9, gen_loss = 0.45684442514240153, disc_loss = 0.004188326674993012
Trained batch 101 in epoch 9, gen_loss = 0.4570038835791981, disc_loss = 0.004177370675903398
Trained batch 102 in epoch 9, gen_loss = 0.4569752343650003, disc_loss = 0.0041607397741828004
Trained batch 103 in epoch 9, gen_loss = 0.45683519771465886, disc_loss = 0.0041567264315045364
Trained batch 104 in epoch 9, gen_loss = 0.45671676312174114, disc_loss = 0.004154958727858251
Trained batch 105 in epoch 9, gen_loss = 0.4568140503932845, disc_loss = 0.004132867741337011
Trained batch 106 in epoch 9, gen_loss = 0.4566758244394142, disc_loss = 0.004116662615849245
Trained batch 107 in epoch 9, gen_loss = 0.45624036535068796, disc_loss = 0.004096564499411249
Trained batch 108 in epoch 9, gen_loss = 0.45644553593539317, disc_loss = 0.004073182290736073
Trained batch 109 in epoch 9, gen_loss = 0.4559541721235622, disc_loss = 0.004066157947421413
Trained batch 110 in epoch 9, gen_loss = 0.4560979320122315, disc_loss = 0.004052184743445937
Trained batch 111 in epoch 9, gen_loss = 0.456081021843212, disc_loss = 0.004027397584910172
Trained batch 112 in epoch 9, gen_loss = 0.4556534830975322, disc_loss = 0.0040114170313293555
Trained batch 113 in epoch 9, gen_loss = 0.45554038385550183, disc_loss = 0.003993835644347169
Trained batch 114 in epoch 9, gen_loss = 0.45573614472928253, disc_loss = 0.004007875398003861
Trained batch 115 in epoch 9, gen_loss = 0.4557781997939636, disc_loss = 0.003992618941742092
Trained batch 116 in epoch 9, gen_loss = 0.4551524573411697, disc_loss = 0.003985445326568288
Trained batch 117 in epoch 9, gen_loss = 0.4555887026807009, disc_loss = 0.003980927154524409
Trained batch 118 in epoch 9, gen_loss = 0.45519454564367023, disc_loss = 0.003964947541479115
Trained batch 119 in epoch 9, gen_loss = 0.45449251011013986, disc_loss = 0.003986123224603943
Trained batch 120 in epoch 9, gen_loss = 0.4540969825480595, disc_loss = 0.003963775810600866
Trained batch 121 in epoch 9, gen_loss = 0.45389522514382347, disc_loss = 0.003957582617628953
Trained batch 122 in epoch 9, gen_loss = 0.4541871378092262, disc_loss = 0.003939343592704736
Trained batch 123 in epoch 9, gen_loss = 0.45433603635718744, disc_loss = 0.003926594673107649
Trained batch 124 in epoch 9, gen_loss = 0.4544306116104126, disc_loss = 0.003914957719855011
Trained batch 125 in epoch 9, gen_loss = 0.4539926468379914, disc_loss = 0.003918329201128688
Trained batch 126 in epoch 9, gen_loss = 0.45398651309839383, disc_loss = 0.003906656966882017
Trained batch 127 in epoch 9, gen_loss = 0.4542641332373023, disc_loss = 0.0038921713903619093
Trained batch 128 in epoch 9, gen_loss = 0.4539660725944726, disc_loss = 0.0038965542326038776
Trained batch 129 in epoch 9, gen_loss = 0.4531146512581752, disc_loss = 0.003877996193925635
Trained batch 130 in epoch 9, gen_loss = 0.4529406250888155, disc_loss = 0.0038786450292531203
Trained batch 131 in epoch 9, gen_loss = 0.4530791680921208, disc_loss = 0.003897635155943025
Trained batch 132 in epoch 9, gen_loss = 0.45266181140913997, disc_loss = 0.0038811656221033153
Trained batch 133 in epoch 9, gen_loss = 0.4525967498323811, disc_loss = 0.0038824582050220845
Trained batch 134 in epoch 9, gen_loss = 0.45250736474990844, disc_loss = 0.003873350765314643
Trained batch 135 in epoch 9, gen_loss = 0.4525026170646443, disc_loss = 0.0038657632685499266
Trained batch 136 in epoch 9, gen_loss = 0.4522557360847501, disc_loss = 0.0038643272000494122
Trained batch 137 in epoch 9, gen_loss = 0.45228668896184454, disc_loss = 0.003852205532366761
Trained batch 138 in epoch 9, gen_loss = 0.45173598429281936, disc_loss = 0.0038390588425702863
Trained batch 139 in epoch 9, gen_loss = 0.4517006103481565, disc_loss = 0.0038322077606738145
Trained batch 140 in epoch 9, gen_loss = 0.4514522573626633, disc_loss = 0.0038151515594927977
Trained batch 141 in epoch 9, gen_loss = 0.4518288772710612, disc_loss = 0.003802126276792145
Trained batch 142 in epoch 9, gen_loss = 0.45147110094557275, disc_loss = 0.0037965794172059824
Trained batch 143 in epoch 9, gen_loss = 0.45144970280428726, disc_loss = 0.003779210504338456
Trained batch 144 in epoch 9, gen_loss = 0.45161405349599903, disc_loss = 0.0037614400289824297
Trained batch 145 in epoch 9, gen_loss = 0.4519051770641379, disc_loss = 0.0037640142174794862
Trained batch 146 in epoch 9, gen_loss = 0.4522181297240614, disc_loss = 0.003752711822982041
Trained batch 147 in epoch 9, gen_loss = 0.45205919827158386, disc_loss = 0.0037359941138797818
Trained batch 148 in epoch 9, gen_loss = 0.4521218550285237, disc_loss = 0.0037196274118610475
Trained batch 149 in epoch 9, gen_loss = 0.4520857044061025, disc_loss = 0.003707769140601158
Trained batch 150 in epoch 9, gen_loss = 0.45195039494937617, disc_loss = 0.003716583079997672
Trained batch 151 in epoch 9, gen_loss = 0.45221415377761187, disc_loss = 0.0037044161144876853
Trained batch 152 in epoch 9, gen_loss = 0.45193977644240935, disc_loss = 0.0036895545465822997
Trained batch 153 in epoch 9, gen_loss = 0.45242817022583703, disc_loss = 0.0036772565255485863
Trained batch 154 in epoch 9, gen_loss = 0.4523891314383476, disc_loss = 0.0036704065511003136
Trained batch 155 in epoch 9, gen_loss = 0.45216885858621353, disc_loss = 0.00365686526026529
Trained batch 156 in epoch 9, gen_loss = 0.45196596186631804, disc_loss = 0.0036438178718920535
Trained batch 157 in epoch 9, gen_loss = 0.45196771583979645, disc_loss = 0.003647038670362834
Trained batch 158 in epoch 9, gen_loss = 0.45158767775169706, disc_loss = 0.0036312433584950537
Trained batch 159 in epoch 9, gen_loss = 0.45151558965444566, disc_loss = 0.0036208561177772935
Trained batch 160 in epoch 9, gen_loss = 0.4511653214507962, disc_loss = 0.0036048712317328555
Trained batch 161 in epoch 9, gen_loss = 0.4513299862543742, disc_loss = 0.003595323834344055
Trained batch 162 in epoch 9, gen_loss = 0.4505953505361007, disc_loss = 0.003587719128021479
Trained batch 163 in epoch 9, gen_loss = 0.4504093725870295, disc_loss = 0.003573918957178049
Trained batch 164 in epoch 9, gen_loss = 0.45009230465599986, disc_loss = 0.0035596734350264976
Trained batch 165 in epoch 9, gen_loss = 0.45008653528000936, disc_loss = 0.0035523195871634476
Trained batch 166 in epoch 9, gen_loss = 0.4504592184891958, disc_loss = 0.0035525298590944735
Trained batch 167 in epoch 9, gen_loss = 0.4504654458945706, disc_loss = 0.0035438651338197467
Trained batch 168 in epoch 9, gen_loss = 0.4504515600980386, disc_loss = 0.003529725847049401
Trained batch 169 in epoch 9, gen_loss = 0.4502563311773188, disc_loss = 0.003525725063210463
Trained batch 170 in epoch 9, gen_loss = 0.45033808078682214, disc_loss = 0.0035199528255047854
Trained batch 171 in epoch 9, gen_loss = 0.45044592213492063, disc_loss = 0.0035420041395957734
Trained batch 172 in epoch 9, gen_loss = 0.45012899819826113, disc_loss = 0.0035690927549636778
Trained batch 173 in epoch 9, gen_loss = 0.44999787005884895, disc_loss = 0.0035597106271915823
Trained batch 174 in epoch 9, gen_loss = 0.4497146167073931, disc_loss = 0.0035551330773159863
Trained batch 175 in epoch 9, gen_loss = 0.4494352581148798, disc_loss = 0.003545205564560919
Trained batch 176 in epoch 9, gen_loss = 0.4497143439317154, disc_loss = 0.0035427758992402315
Trained batch 177 in epoch 9, gen_loss = 0.4498562737462226, disc_loss = 0.0035328097109096858
Trained batch 178 in epoch 9, gen_loss = 0.4494739566102374, disc_loss = 0.0035217180516435532
Trained batch 179 in epoch 9, gen_loss = 0.44970380465189613, disc_loss = 0.0035124600612713645
Trained batch 180 in epoch 9, gen_loss = 0.44989156443111145, disc_loss = 0.0035140281832566
Trained batch 181 in epoch 9, gen_loss = 0.44943965611222025, disc_loss = 0.0035044414670575043
Trained batch 182 in epoch 9, gen_loss = 0.4491077966051675, disc_loss = 0.0034998920561664336
Trained batch 183 in epoch 9, gen_loss = 0.44898389911522035, disc_loss = 0.0035420408182645865
Trained batch 184 in epoch 9, gen_loss = 0.44884848965180885, disc_loss = 0.0035543961746215417
Trained batch 185 in epoch 9, gen_loss = 0.449134303196784, disc_loss = 0.003566383859217768
Trained batch 186 in epoch 9, gen_loss = 0.44897785735002815, disc_loss = 0.0035568860709358427
Trained batch 187 in epoch 9, gen_loss = 0.4488071005078072, disc_loss = 0.00354371933536505
Trained batch 188 in epoch 9, gen_loss = 0.4489990215768259, disc_loss = 0.003533561753414611
Trained batch 189 in epoch 9, gen_loss = 0.4486138348516665, disc_loss = 0.0035255224799345198
Trained batch 190 in epoch 9, gen_loss = 0.44885983704272364, disc_loss = 0.003521299629633105
Trained batch 191 in epoch 9, gen_loss = 0.44883323088288307, disc_loss = 0.003515390281487877
Trained batch 192 in epoch 9, gen_loss = 0.4485778941391663, disc_loss = 0.0035200369317528496
Trained batch 193 in epoch 9, gen_loss = 0.44861574701427187, disc_loss = 0.003514108946546912
Trained batch 194 in epoch 9, gen_loss = 0.44815412301283614, disc_loss = 0.0035111942041951877
Trained batch 195 in epoch 9, gen_loss = 0.4483095936629237, disc_loss = 0.003506909003386236
Trained batch 196 in epoch 9, gen_loss = 0.44836951678779524, disc_loss = 0.0035014697764220123
Trained batch 197 in epoch 9, gen_loss = 0.44821433015544004, disc_loss = 0.003514671080858644
Trained batch 198 in epoch 9, gen_loss = 0.4480169959104241, disc_loss = 0.003534540867470392
Trained batch 199 in epoch 9, gen_loss = 0.44831718876957893, disc_loss = 0.0035454045387450605
Trained batch 200 in epoch 9, gen_loss = 0.44824288451849525, disc_loss = 0.0035523069681905545
Trained batch 201 in epoch 9, gen_loss = 0.4482801212827758, disc_loss = 0.0035780278728389653
Trained batch 202 in epoch 9, gen_loss = 0.44847558798461123, disc_loss = 0.003575809326325658
Trained batch 203 in epoch 9, gen_loss = 0.44872350128842337, disc_loss = 0.003582356012581537
Trained batch 204 in epoch 9, gen_loss = 0.4486976816886809, disc_loss = 0.0035774295297792045
Trained batch 205 in epoch 9, gen_loss = 0.4485388859672454, disc_loss = 0.0035759297717199885
Trained batch 206 in epoch 9, gen_loss = 0.44832923374890127, disc_loss = 0.0035650231076881362
Trained batch 207 in epoch 9, gen_loss = 0.4482713661228235, disc_loss = 0.003552688732899976
Trained batch 208 in epoch 9, gen_loss = 0.44817053216496155, disc_loss = 0.00354042121501078
Trained batch 209 in epoch 9, gen_loss = 0.44806036083471207, disc_loss = 0.0035305086528838034
Trained batch 210 in epoch 9, gen_loss = 0.4480987421426728, disc_loss = 0.003518615154686309
Trained batch 211 in epoch 9, gen_loss = 0.4479404978875844, disc_loss = 0.0035069964058424856
Trained batch 212 in epoch 9, gen_loss = 0.4478363583625202, disc_loss = 0.0034962026500733384
Trained batch 213 in epoch 9, gen_loss = 0.44778728081244173, disc_loss = 0.003485992729824872
Trained batch 214 in epoch 9, gen_loss = 0.44777242388836175, disc_loss = 0.0034822897157133666
Trained batch 215 in epoch 9, gen_loss = 0.44807017429007423, disc_loss = 0.0034710947845639937
Trained batch 216 in epoch 9, gen_loss = 0.44777550702820174, disc_loss = 0.003463666541137076
Trained batch 217 in epoch 9, gen_loss = 0.44766597969269534, disc_loss = 0.003452241514999539
Trained batch 218 in epoch 9, gen_loss = 0.4476765752110851, disc_loss = 0.0034403785269550096
Trained batch 219 in epoch 9, gen_loss = 0.4479452215812423, disc_loss = 0.0034323767936174673
Trained batch 220 in epoch 9, gen_loss = 0.44800766844015855, disc_loss = 0.00342234756615291
Trained batch 221 in epoch 9, gen_loss = 0.4480040860068691, disc_loss = 0.003414247879026424
Trained batch 222 in epoch 9, gen_loss = 0.44794719863365584, disc_loss = 0.0034025573537626507
Trained batch 223 in epoch 9, gen_loss = 0.4484047710097262, disc_loss = 0.0033929089625287035
Trained batch 224 in epoch 9, gen_loss = 0.44842473891046314, disc_loss = 0.0033830726604598266
Trained batch 225 in epoch 9, gen_loss = 0.44810874417292335, disc_loss = 0.003373442361166338
Trained batch 226 in epoch 9, gen_loss = 0.4482728564529167, disc_loss = 0.003364125404882323
Trained batch 227 in epoch 9, gen_loss = 0.44790320255254445, disc_loss = 0.0033542200432285633
Trained batch 228 in epoch 9, gen_loss = 0.4475593937796797, disc_loss = 0.0033441563469853953
Trained batch 229 in epoch 9, gen_loss = 0.44749493819216024, disc_loss = 0.003333942338814149
Trained batch 230 in epoch 9, gen_loss = 0.4477437648164245, disc_loss = 0.0033243293831128934
Trained batch 231 in epoch 9, gen_loss = 0.4474154868773345, disc_loss = 0.003314077767597688
Trained batch 232 in epoch 9, gen_loss = 0.4474037602991505, disc_loss = 0.0033040152657317404
Trained batch 233 in epoch 9, gen_loss = 0.4474761775161466, disc_loss = 0.0032961953565195743
Trained batch 234 in epoch 9, gen_loss = 0.4472648413891488, disc_loss = 0.0032898538738508967
Trained batch 235 in epoch 9, gen_loss = 0.4471698792304023, disc_loss = 0.0032811183642726233
Trained batch 236 in epoch 9, gen_loss = 0.4473359119540025, disc_loss = 0.0032731237792299928
Trained batch 237 in epoch 9, gen_loss = 0.44735475397911395, disc_loss = 0.0032826186700219274
Trained batch 238 in epoch 9, gen_loss = 0.44722364923944036, disc_loss = 0.003286435027464554
Trained batch 239 in epoch 9, gen_loss = 0.4470284761240085, disc_loss = 0.003282056211658831
Trained batch 240 in epoch 9, gen_loss = 0.4469020512588786, disc_loss = 0.003273389042554137
Trained batch 241 in epoch 9, gen_loss = 0.4468306290709283, disc_loss = 0.003271991660489416
Trained batch 242 in epoch 9, gen_loss = 0.4468717859605703, disc_loss = 0.0032696949115402444
Trained batch 243 in epoch 9, gen_loss = 0.4467826957096819, disc_loss = 0.003260065486786322
Trained batch 244 in epoch 9, gen_loss = 0.4467974972968199, disc_loss = 0.003251833412843775
Trained batch 245 in epoch 9, gen_loss = 0.44685847596908973, disc_loss = 0.003243285165749475
Trained batch 246 in epoch 9, gen_loss = 0.447024594555017, disc_loss = 0.003235366273443271
Trained batch 247 in epoch 9, gen_loss = 0.4468906426862363, disc_loss = 0.00322642316032509
Trained batch 248 in epoch 9, gen_loss = 0.4468655760987217, disc_loss = 0.00322003337768763
Trained batch 249 in epoch 9, gen_loss = 0.44699643898010255, disc_loss = 0.0032124561809469014
Trained batch 250 in epoch 9, gen_loss = 0.4470771270919131, disc_loss = 0.003203161560561122
Trained batch 251 in epoch 9, gen_loss = 0.4473399120190787, disc_loss = 0.0031952430937154633
Trained batch 252 in epoch 9, gen_loss = 0.44705556044465466, disc_loss = 0.0031868822837207954
Trained batch 253 in epoch 9, gen_loss = 0.4469086987765755, disc_loss = 0.00317772225395219
Trained batch 254 in epoch 9, gen_loss = 0.44680432104596907, disc_loss = 0.0031716375125517304
Trained batch 255 in epoch 9, gen_loss = 0.44678114471025765, disc_loss = 0.0031631970011858357
Trained batch 256 in epoch 9, gen_loss = 0.4463508976804607, disc_loss = 0.0031546059387087357
Trained batch 257 in epoch 9, gen_loss = 0.44634954816149186, disc_loss = 0.003146609367690836
Trained batch 258 in epoch 9, gen_loss = 0.44637573536298447, disc_loss = 0.0031379592873724215
Trained batch 259 in epoch 9, gen_loss = 0.4466330981025329, disc_loss = 0.0031304623533147747
Trained batch 260 in epoch 9, gen_loss = 0.4464963618594568, disc_loss = 0.003127638644438908
Trained batch 261 in epoch 9, gen_loss = 0.44649593623084877, disc_loss = 0.003118405462942932
Trained batch 262 in epoch 9, gen_loss = 0.4462845510176379, disc_loss = 0.0031102499389001116
Trained batch 263 in epoch 9, gen_loss = 0.4460174656952872, disc_loss = 0.0031014633083638423
Trained batch 264 in epoch 9, gen_loss = 0.4460729519151292, disc_loss = 0.0030936088140632186
Trained batch 265 in epoch 9, gen_loss = 0.4462196167026247, disc_loss = 0.003090108202112124
Trained batch 266 in epoch 9, gen_loss = 0.44647660717535553, disc_loss = 0.003088731718099631
Trained batch 267 in epoch 9, gen_loss = 0.4466167271359643, disc_loss = 0.003081192311556287
Trained batch 268 in epoch 9, gen_loss = 0.4464162974774173, disc_loss = 0.0030734587355160247
Trained batch 269 in epoch 9, gen_loss = 0.4465790208843019, disc_loss = 0.0030659367140658477
Trained batch 270 in epoch 9, gen_loss = 0.44645026106236163, disc_loss = 0.003058326309907673
Trained batch 271 in epoch 9, gen_loss = 0.4464070106692174, disc_loss = 0.00305299944268293
Trained batch 272 in epoch 9, gen_loss = 0.4464105832707751, disc_loss = 0.0030445690631811873
Trained batch 273 in epoch 9, gen_loss = 0.44630320359320536, disc_loss = 0.0030363797444687055
Trained batch 274 in epoch 9, gen_loss = 0.44629578612067483, disc_loss = 0.0030281205483796924
Trained batch 275 in epoch 9, gen_loss = 0.4461978181548741, disc_loss = 0.00301977713757694
Trained batch 276 in epoch 9, gen_loss = 0.4462714057536762, disc_loss = 0.0030125120464739277
Trained batch 277 in epoch 9, gen_loss = 0.4460807011710654, disc_loss = 0.0031719646816939224
Trained batch 278 in epoch 9, gen_loss = 0.44594861508270317, disc_loss = 0.003186966805788939
Trained batch 279 in epoch 9, gen_loss = 0.44588002413511274, disc_loss = 0.003189889034755262
Trained batch 280 in epoch 9, gen_loss = 0.4457933479568712, disc_loss = 0.003190174916745876
Trained batch 281 in epoch 9, gen_loss = 0.44574370610375774, disc_loss = 0.00318921265251776
Trained batch 282 in epoch 9, gen_loss = 0.4459191535471185, disc_loss = 0.0031873685548035923
Trained batch 283 in epoch 9, gen_loss = 0.44573589813121606, disc_loss = 0.0031836125663560356
Trained batch 284 in epoch 9, gen_loss = 0.4457340272895077, disc_loss = 0.0032013621107724152
Trained batch 285 in epoch 9, gen_loss = 0.44549437013122584, disc_loss = 0.003225238061627256
Trained batch 286 in epoch 9, gen_loss = 0.4454507698996142, disc_loss = 0.003255622746189245
Trained batch 287 in epoch 9, gen_loss = 0.4455361331088675, disc_loss = 0.003277134877053969
Trained batch 288 in epoch 9, gen_loss = 0.4458031491424798, disc_loss = 0.003319559266764967
Trained batch 289 in epoch 9, gen_loss = 0.44579424303153464, disc_loss = 0.003321073343174468
Trained batch 290 in epoch 9, gen_loss = 0.4456143525662701, disc_loss = 0.003368404585887323
Trained batch 291 in epoch 9, gen_loss = 0.44559838092082166, disc_loss = 0.0033796174899828045
Trained batch 292 in epoch 9, gen_loss = 0.4457294673439586, disc_loss = 0.0035108600881382976
Trained batch 293 in epoch 9, gen_loss = 0.44596749047438305, disc_loss = 0.003586558629061748
Trained batch 294 in epoch 9, gen_loss = 0.44605168336528844, disc_loss = 0.003670600477321926
Trained batch 295 in epoch 9, gen_loss = 0.4462132411631378, disc_loss = 0.003686635085614398
Trained batch 296 in epoch 9, gen_loss = 0.4460941250075395, disc_loss = 0.003702556602311907
Trained batch 297 in epoch 9, gen_loss = 0.4459230680793724, disc_loss = 0.0037509536303442295
Trained batch 298 in epoch 9, gen_loss = 0.44587405329962637, disc_loss = 0.0037995359453880367
Trained batch 299 in epoch 9, gen_loss = 0.4458884423971176, disc_loss = 0.003805549642226348
Trained batch 300 in epoch 9, gen_loss = 0.4462298584538837, disc_loss = 0.0038105649881349547
Trained batch 301 in epoch 9, gen_loss = 0.44616908367895924, disc_loss = 0.0038094352984751594
Trained batch 302 in epoch 9, gen_loss = 0.4460061182676762, disc_loss = 0.00380661301453146
Trained batch 303 in epoch 9, gen_loss = 0.4462462938145587, disc_loss = 0.0038086107118655683
Trained batch 304 in epoch 9, gen_loss = 0.4461760186758198, disc_loss = 0.003804747991599753
Trained batch 305 in epoch 9, gen_loss = 0.4462731809787501, disc_loss = 0.0037992578775932393
Trained batch 306 in epoch 9, gen_loss = 0.4462910821655286, disc_loss = 0.0038002313187509677
Trained batch 307 in epoch 9, gen_loss = 0.44618298616502194, disc_loss = 0.0037957913878785034
Trained batch 308 in epoch 9, gen_loss = 0.44588493452103006, disc_loss = 0.0038039293524456544
Trained batch 309 in epoch 9, gen_loss = 0.4458053986872396, disc_loss = 0.003821891560519655
Trained batch 310 in epoch 9, gen_loss = 0.44573407847781654, disc_loss = 0.003832345725848696
Trained batch 311 in epoch 9, gen_loss = 0.44574205042460024, disc_loss = 0.0038290737765447167
Trained batch 312 in epoch 9, gen_loss = 0.44529460108699126, disc_loss = 0.003863163769227295
Trained batch 313 in epoch 9, gen_loss = 0.44528731542408084, disc_loss = 0.0038635844748858717
Trained batch 314 in epoch 9, gen_loss = 0.4452664275964101, disc_loss = 0.003912543013898863
Trained batch 315 in epoch 9, gen_loss = 0.44533511930251424, disc_loss = 0.003912953355591273
Trained batch 316 in epoch 9, gen_loss = 0.4451592198869783, disc_loss = 0.003941262707155351
Trained batch 317 in epoch 9, gen_loss = 0.44526026777501376, disc_loss = 0.003956112725830069
Trained batch 318 in epoch 9, gen_loss = 0.4454555003246917, disc_loss = 0.003953171652365114
Trained batch 319 in epoch 9, gen_loss = 0.4457213383167982, disc_loss = 0.003975612781505333
Trained batch 320 in epoch 9, gen_loss = 0.4456723032525024, disc_loss = 0.003969263195820338
Trained batch 321 in epoch 9, gen_loss = 0.4455210300891296, disc_loss = 0.004009958516057257
Trained batch 322 in epoch 9, gen_loss = 0.44570003565250904, disc_loss = 0.004022282006539081
Trained batch 323 in epoch 9, gen_loss = 0.44585326580721657, disc_loss = 0.004030393273066615
Trained batch 324 in epoch 9, gen_loss = 0.4459312571929051, disc_loss = 0.004040018363425938
Trained batch 325 in epoch 9, gen_loss = 0.4458663627231048, disc_loss = 0.0040364341408248555
Trained batch 326 in epoch 9, gen_loss = 0.4460803395199849, disc_loss = 0.004038415225835044
Trained batch 327 in epoch 9, gen_loss = 0.44594010892437724, disc_loss = 0.004074547062528592
Trained batch 328 in epoch 9, gen_loss = 0.4460818432384711, disc_loss = 0.0041749722053265725
Trained batch 329 in epoch 9, gen_loss = 0.44600009945305913, disc_loss = 0.004182932204496341
Trained batch 330 in epoch 9, gen_loss = 0.4459843406864524, disc_loss = 0.004199028994643279
Trained batch 331 in epoch 9, gen_loss = 0.4459059422454202, disc_loss = 0.004327081043219912
Trained batch 332 in epoch 9, gen_loss = 0.44593867194187176, disc_loss = 0.004335742553223383
Trained batch 333 in epoch 9, gen_loss = 0.4461664046177607, disc_loss = 0.004376979547895736
Trained batch 334 in epoch 9, gen_loss = 0.44636731067700175, disc_loss = 0.004427943348453672
Trained batch 335 in epoch 9, gen_loss = 0.44649638421833515, disc_loss = 0.004439903936318366
Trained batch 336 in epoch 9, gen_loss = 0.4465119279810512, disc_loss = 0.004524993240758666
Trained batch 337 in epoch 9, gen_loss = 0.44641757575717905, disc_loss = 0.004535743415964624
Trained batch 338 in epoch 9, gen_loss = 0.44664615709169775, disc_loss = 0.004624845476884252
Trained batch 339 in epoch 9, gen_loss = 0.4465560835073976, disc_loss = 0.004989284310174887
Trained batch 340 in epoch 9, gen_loss = 0.44667928344693003, disc_loss = 0.005510754719761656
Trained batch 341 in epoch 9, gen_loss = 0.4466186089996706, disc_loss = 0.0055206322730028705
Trained batch 342 in epoch 9, gen_loss = 0.4463445135003971, disc_loss = 0.005958448617947192
Trained batch 343 in epoch 9, gen_loss = 0.446322594964227, disc_loss = 0.00602645839078536
Trained batch 344 in epoch 9, gen_loss = 0.4462886369746664, disc_loss = 0.006041785605265287
Trained batch 345 in epoch 9, gen_loss = 0.44602525854386343, disc_loss = 0.006123076494839688
Trained batch 346 in epoch 9, gen_loss = 0.4460415894256889, disc_loss = 0.006232631100564444
Trained batch 347 in epoch 9, gen_loss = 0.4458838066664235, disc_loss = 0.006284236100076794
Trained batch 348 in epoch 9, gen_loss = 0.4460517092044852, disc_loss = 0.006299949374202009
Trained batch 349 in epoch 9, gen_loss = 0.44621918056692395, disc_loss = 0.006295438089873642
Trained batch 350 in epoch 9, gen_loss = 0.44640500822298207, disc_loss = 0.006328635777750098
Trained batch 351 in epoch 9, gen_loss = 0.4465164129876278, disc_loss = 0.006752862288439329
Trained batch 352 in epoch 9, gen_loss = 0.44647874043615954, disc_loss = 0.006821116163769985
Trained batch 353 in epoch 9, gen_loss = 0.44622826618326583, disc_loss = 0.006963806121944223
Trained batch 354 in epoch 9, gen_loss = 0.4462383038561109, disc_loss = 0.007026974007185601
Trained batch 355 in epoch 9, gen_loss = 0.4462018220612172, disc_loss = 0.007050179918571323
Trained batch 356 in epoch 9, gen_loss = 0.4463443631718473, disc_loss = 0.0071741487698483404
Trained batch 357 in epoch 9, gen_loss = 0.44654782016517064, disc_loss = 0.007215235601166294
Trained batch 358 in epoch 9, gen_loss = 0.446792559454368, disc_loss = 0.007234699173550275
Trained batch 359 in epoch 9, gen_loss = 0.446694830722279, disc_loss = 0.007258569025240528
Trained batch 360 in epoch 9, gen_loss = 0.4468406354621507, disc_loss = 0.007289290541997102
Trained batch 361 in epoch 9, gen_loss = 0.4468534790514582, disc_loss = 0.007290985677404154
Trained batch 362 in epoch 9, gen_loss = 0.4469916575046939, disc_loss = 0.007306919959450741
Trained batch 363 in epoch 9, gen_loss = 0.4471581641298074, disc_loss = 0.007301297655730805
Trained batch 364 in epoch 9, gen_loss = 0.44721711669882686, disc_loss = 0.007377813065309741
Trained batch 365 in epoch 9, gen_loss = 0.44724945707725045, disc_loss = 0.008592205236938176
Trained batch 366 in epoch 9, gen_loss = 0.44696816899471126, disc_loss = 0.009466687428298069
Trained batch 367 in epoch 9, gen_loss = 0.44663058869216754, disc_loss = 0.00969981121022062
Trained batch 368 in epoch 9, gen_loss = 0.4467287070059841, disc_loss = 0.009802464196688135
Trained batch 369 in epoch 9, gen_loss = 0.44690566288458333, disc_loss = 0.010082524745863535
Trained batch 370 in epoch 9, gen_loss = 0.44694346237696725, disc_loss = 0.010133272416279664
Trained batch 371 in epoch 9, gen_loss = 0.44677938817329305, disc_loss = 0.010171680628905394
Trained batch 372 in epoch 9, gen_loss = 0.44679509914272914, disc_loss = 0.010185195480463352
Trained batch 373 in epoch 9, gen_loss = 0.44676770947196265, disc_loss = 0.010187824563320009
Trained batch 374 in epoch 9, gen_loss = 0.44678939922650657, disc_loss = 0.010230840819887817
Trained batch 375 in epoch 9, gen_loss = 0.4466089851203117, disc_loss = 0.010231204764692093
Trained batch 376 in epoch 9, gen_loss = 0.4465197475740701, disc_loss = 0.010242663247607135
Trained batch 377 in epoch 9, gen_loss = 0.4464884480786702, disc_loss = 0.010230843250321904
Trained batch 378 in epoch 9, gen_loss = 0.4464494301335478, disc_loss = 0.010217582680700263
Trained batch 379 in epoch 9, gen_loss = 0.4461757069355563, disc_loss = 0.010201789012583168
Trained batch 380 in epoch 9, gen_loss = 0.4460567403340277, disc_loss = 0.010182226704020454
Trained batch 381 in epoch 9, gen_loss = 0.4460785579306917, disc_loss = 0.010167250273498116
Trained batch 382 in epoch 9, gen_loss = 0.4460278081053542, disc_loss = 0.010385749477701014
Trained batch 383 in epoch 9, gen_loss = 0.4459637508261949, disc_loss = 0.010448832346507212
Trained batch 384 in epoch 9, gen_loss = 0.4458340006989318, disc_loss = 0.010474434650091865
Trained batch 385 in epoch 9, gen_loss = 0.4459200286031387, disc_loss = 0.010483593098792715
Trained batch 386 in epoch 9, gen_loss = 0.44589898875825473, disc_loss = 0.010471315237751244
Trained batch 387 in epoch 9, gen_loss = 0.4459132547538305, disc_loss = 0.010485806163057167
Trained batch 388 in epoch 9, gen_loss = 0.4458656678775895, disc_loss = 0.01047380711281179
Trained batch 389 in epoch 9, gen_loss = 0.44579882491857575, disc_loss = 0.010464916329604024
Trained batch 390 in epoch 9, gen_loss = 0.4457760004283827, disc_loss = 0.010513598069874928
Trained batch 391 in epoch 9, gen_loss = 0.44607500785163473, disc_loss = 0.010522862239705152
Trained batch 392 in epoch 9, gen_loss = 0.44637430313282644, disc_loss = 0.010649803949166895
Trained batch 393 in epoch 9, gen_loss = 0.4463652885958628, disc_loss = 0.010649617259369379
Trained batch 394 in epoch 9, gen_loss = 0.4464394329469415, disc_loss = 0.011082237854281652
Trained batch 395 in epoch 9, gen_loss = 0.4464621407666592, disc_loss = 0.011154832167026464
Trained batch 396 in epoch 9, gen_loss = 0.4465260802198117, disc_loss = 0.011258062462308338
Trained batch 397 in epoch 9, gen_loss = 0.446427776510991, disc_loss = 0.011275770029476634
Trained batch 398 in epoch 9, gen_loss = 0.44638189509100185, disc_loss = 0.011273307458819696
Trained batch 399 in epoch 9, gen_loss = 0.4465073276311159, disc_loss = 0.011338267977407668
Trained batch 400 in epoch 9, gen_loss = 0.44642108500449734, disc_loss = 0.011373150832730432
Trained batch 401 in epoch 9, gen_loss = 0.44630949028688877, disc_loss = 0.011524641199734766
Trained batch 402 in epoch 9, gen_loss = 0.4462606625136903, disc_loss = 0.011524129353022253
Trained batch 403 in epoch 9, gen_loss = 0.44636496259729463, disc_loss = 0.011579407405829759
Trained batch 404 in epoch 9, gen_loss = 0.4463159057829115, disc_loss = 0.011584993772910057
Trained batch 405 in epoch 9, gen_loss = 0.44637564977107963, disc_loss = 0.011597946835876777
Trained batch 406 in epoch 9, gen_loss = 0.44641625170918586, disc_loss = 0.011589296374078703
Trained batch 407 in epoch 9, gen_loss = 0.44633854165965436, disc_loss = 0.011582285619178768
Trained batch 408 in epoch 9, gen_loss = 0.4462218386619773, disc_loss = 0.011570487265056113
Trained batch 409 in epoch 9, gen_loss = 0.44609810477349815, disc_loss = 0.011553034458093617
Trained batch 410 in epoch 9, gen_loss = 0.44600588576347, disc_loss = 0.011550307617445733
Trained batch 411 in epoch 9, gen_loss = 0.44627552790549196, disc_loss = 0.011547507165797796
Trained batch 412 in epoch 9, gen_loss = 0.4462068271406049, disc_loss = 0.011537501999158999
Trained batch 413 in epoch 9, gen_loss = 0.4461586908729756, disc_loss = 0.01156695324793719
Trained batch 414 in epoch 9, gen_loss = 0.44618376120027287, disc_loss = 0.011561836910725806
Trained batch 415 in epoch 9, gen_loss = 0.4461043132469058, disc_loss = 0.011542627416929463
Trained batch 416 in epoch 9, gen_loss = 0.44612402617216684, disc_loss = 0.011537176058002316
Trained batch 417 in epoch 9, gen_loss = 0.4461059495450207, disc_loss = 0.011534423998759783
Trained batch 418 in epoch 9, gen_loss = 0.44601658697913543, disc_loss = 0.011516778186677125
Trained batch 419 in epoch 9, gen_loss = 0.4461257073850859, disc_loss = 0.011499415849435276
Trained batch 420 in epoch 9, gen_loss = 0.4460057534826057, disc_loss = 0.011476740897234945
Trained batch 421 in epoch 9, gen_loss = 0.4459670641552215, disc_loss = 0.011453950307298875
Trained batch 422 in epoch 9, gen_loss = 0.4460014544480236, disc_loss = 0.01143218400028378
Trained batch 423 in epoch 9, gen_loss = 0.44615420938100453, disc_loss = 0.011410477827358025
Trained batch 424 in epoch 9, gen_loss = 0.4462824180546929, disc_loss = 0.011390267416889616
Trained batch 425 in epoch 9, gen_loss = 0.446356014676497, disc_loss = 0.011370617634247324
Trained batch 426 in epoch 9, gen_loss = 0.446565216751791, disc_loss = 0.01135388144975707
Trained batch 427 in epoch 9, gen_loss = 0.4466478628254382, disc_loss = 0.011400498502298092
Trained batch 428 in epoch 9, gen_loss = 0.4466656170663856, disc_loss = 0.011384055866438696
Trained batch 429 in epoch 9, gen_loss = 0.44675826908544053, disc_loss = 0.011503014502624526
Trained batch 430 in epoch 9, gen_loss = 0.44661738376053195, disc_loss = 0.011561229554104366
Trained batch 431 in epoch 9, gen_loss = 0.4465994416149678, disc_loss = 0.011560684442142869
Trained batch 432 in epoch 9, gen_loss = 0.4464282348717608, disc_loss = 0.01161275775785887
Trained batch 433 in epoch 9, gen_loss = 0.4465184753528938, disc_loss = 0.011602250238170221
Trained batch 434 in epoch 9, gen_loss = 0.446638640795631, disc_loss = 0.011599702102496107
Trained batch 435 in epoch 9, gen_loss = 0.4468140796920575, disc_loss = 0.011587029023132278
Trained batch 436 in epoch 9, gen_loss = 0.4468854851253518, disc_loss = 0.011578858613987076
Trained batch 437 in epoch 9, gen_loss = 0.44697820269353855, disc_loss = 0.011602937162281802
Trained batch 438 in epoch 9, gen_loss = 0.4469477250527141, disc_loss = 0.01159397829541457
Trained batch 439 in epoch 9, gen_loss = 0.4468987498093735, disc_loss = 0.011585386613098143
Trained batch 440 in epoch 9, gen_loss = 0.4469325141706705, disc_loss = 0.011575275311159929
Trained batch 441 in epoch 9, gen_loss = 0.446935106995958, disc_loss = 0.011578982027207514
Trained batch 442 in epoch 9, gen_loss = 0.44717234844009707, disc_loss = 0.01156530879005899
Trained batch 443 in epoch 9, gen_loss = 0.44721676590474874, disc_loss = 0.011560480709466664
Trained batch 444 in epoch 9, gen_loss = 0.4472358341967122, disc_loss = 0.01154900484043435
Trained batch 445 in epoch 9, gen_loss = 0.4473003142350458, disc_loss = 0.01153902109057722
Trained batch 446 in epoch 9, gen_loss = 0.4473332355353123, disc_loss = 0.011540565855636509
Trained batch 447 in epoch 9, gen_loss = 0.44741488208195995, disc_loss = 0.01153374922666574
Trained batch 448 in epoch 9, gen_loss = 0.44744828469503695, disc_loss = 0.011532162609904225
Trained batch 449 in epoch 9, gen_loss = 0.4473779175678889, disc_loss = 0.011795282269983241
Trained batch 450 in epoch 9, gen_loss = 0.447271470682584, disc_loss = 0.012261007688660794
Trained batch 451 in epoch 9, gen_loss = 0.4471362117117485, disc_loss = 0.012279415632179831
Trained batch 452 in epoch 9, gen_loss = 0.4471661872158514, disc_loss = 0.012363548899659472
Trained batch 453 in epoch 9, gen_loss = 0.44724891121429494, disc_loss = 0.012370376442794971
Trained batch 454 in epoch 9, gen_loss = 0.4471905223615877, disc_loss = 0.012397089323468998
Trained batch 455 in epoch 9, gen_loss = 0.447167650910846, disc_loss = 0.012623989155256646
Trained batch 456 in epoch 9, gen_loss = 0.447331587125749, disc_loss = 0.012710462857488159
Trained batch 457 in epoch 9, gen_loss = 0.447449819489858, disc_loss = 0.012727858780580267
Trained batch 458 in epoch 9, gen_loss = 0.44746805087933095, disc_loss = 0.012712730522153895
Trained batch 459 in epoch 9, gen_loss = 0.44733895341987195, disc_loss = 0.012699772019961687
Trained batch 460 in epoch 9, gen_loss = 0.44724856016434195, disc_loss = 0.012702616009661228
Trained batch 461 in epoch 9, gen_loss = 0.4472330279035486, disc_loss = 0.012705714092337934
Trained batch 462 in epoch 9, gen_loss = 0.4473050125989234, disc_loss = 0.012689408746881905
Trained batch 463 in epoch 9, gen_loss = 0.44734696093304405, disc_loss = 0.012679285272717042
Trained batch 464 in epoch 9, gen_loss = 0.44725774065140755, disc_loss = 0.012661660256575273
Trained batch 465 in epoch 9, gen_loss = 0.44723499409630574, disc_loss = 0.012644157219576237
Trained batch 466 in epoch 9, gen_loss = 0.4470699266141691, disc_loss = 0.01263214289325407
Trained batch 467 in epoch 9, gen_loss = 0.4469584605505324, disc_loss = 0.012612702456575572
Trained batch 468 in epoch 9, gen_loss = 0.4469461537627523, disc_loss = 0.012594585351870337
Trained batch 469 in epoch 9, gen_loss = 0.4467283676913444, disc_loss = 0.01257450821923409
Trained batch 470 in epoch 9, gen_loss = 0.4467935711461774, disc_loss = 0.012555588002419476
Trained batch 471 in epoch 9, gen_loss = 0.4469443371487876, disc_loss = 0.012569204798822639
Trained batch 472 in epoch 9, gen_loss = 0.44702035478507235, disc_loss = 0.01258154671927658
Trained batch 473 in epoch 9, gen_loss = 0.44708583601416413, disc_loss = 0.01256209462738639
Trained batch 474 in epoch 9, gen_loss = 0.447037946236761, disc_loss = 0.012576117227099051
Trained batch 475 in epoch 9, gen_loss = 0.4471112839689776, disc_loss = 0.012564004690165264
Trained batch 476 in epoch 9, gen_loss = 0.4469213303904863, disc_loss = 0.01303024562070853
Trained batch 477 in epoch 9, gen_loss = 0.44714280707317416, disc_loss = 0.013394598932654274
Trained batch 478 in epoch 9, gen_loss = 0.44716778721092637, disc_loss = 0.013389958035432206
Trained batch 479 in epoch 9, gen_loss = 0.44719210639595985, disc_loss = 0.01337661885554553
Trained batch 480 in epoch 9, gen_loss = 0.44709004080716885, disc_loss = 0.013448376126980443
Trained batch 481 in epoch 9, gen_loss = 0.4470115697235487, disc_loss = 0.013468821127019838
Trained batch 482 in epoch 9, gen_loss = 0.4469871876402671, disc_loss = 0.013546747535102717
Trained batch 483 in epoch 9, gen_loss = 0.4469481462166329, disc_loss = 0.013534226899048745
Trained batch 484 in epoch 9, gen_loss = 0.4467643429938051, disc_loss = 0.013597037364517521
Trained batch 485 in epoch 9, gen_loss = 0.4465135685455652, disc_loss = 0.013597779786319628
Trained batch 486 in epoch 9, gen_loss = 0.44663056088668857, disc_loss = 0.013609906182111886
Trained batch 487 in epoch 9, gen_loss = 0.44665352035252776, disc_loss = 0.013601784296400585
Trained batch 488 in epoch 9, gen_loss = 0.44667296102441895, disc_loss = 0.013592433338415389
Trained batch 489 in epoch 9, gen_loss = 0.4468072705122889, disc_loss = 0.013590190141243214
Trained batch 490 in epoch 9, gen_loss = 0.44680834296036154, disc_loss = 0.013589683809894271
Trained batch 491 in epoch 9, gen_loss = 0.4469982788451319, disc_loss = 0.013574371818307318
Trained batch 492 in epoch 9, gen_loss = 0.44696170847266004, disc_loss = 0.013557612299720774
Trained batch 493 in epoch 9, gen_loss = 0.44703851350647233, disc_loss = 0.013540398594140931
Trained batch 494 in epoch 9, gen_loss = 0.4469865763428235, disc_loss = 0.013524702413129912
Trained batch 495 in epoch 9, gen_loss = 0.44712837635269087, disc_loss = 0.013512392706498729
Trained batch 496 in epoch 9, gen_loss = 0.4470337908152843, disc_loss = 0.01351961828707352
Trained batch 497 in epoch 9, gen_loss = 0.44706253096999893, disc_loss = 0.013501728204851335
Trained batch 498 in epoch 9, gen_loss = 0.44701553436223873, disc_loss = 0.013514888053619955
Trained batch 499 in epoch 9, gen_loss = 0.44698183083534243, disc_loss = 0.013527171124471351
Trained batch 500 in epoch 9, gen_loss = 0.44698923106441, disc_loss = 0.013585197797626956
Trained batch 501 in epoch 9, gen_loss = 0.4470870095301434, disc_loss = 0.013580451616266023
Trained batch 502 in epoch 9, gen_loss = 0.4472292342313952, disc_loss = 0.01357533907768674
Trained batch 503 in epoch 9, gen_loss = 0.44720964866971213, disc_loss = 0.0135759238275193
Trained batch 504 in epoch 9, gen_loss = 0.44724441896570793, disc_loss = 0.01358345988838205
Trained batch 505 in epoch 9, gen_loss = 0.44717867860916577, disc_loss = 0.013583719451302522
Trained batch 506 in epoch 9, gen_loss = 0.4472890911840593, disc_loss = 0.01361539023510443
Trained batch 507 in epoch 9, gen_loss = 0.4474184817568524, disc_loss = 0.013618368003471557
Trained batch 508 in epoch 9, gen_loss = 0.4477329543976512, disc_loss = 0.013727273587787008
Trained batch 509 in epoch 9, gen_loss = 0.44765732732473634, disc_loss = 0.013917092797026841
Trained batch 510 in epoch 9, gen_loss = 0.44760676851011305, disc_loss = 0.013909568272689594
Trained batch 511 in epoch 9, gen_loss = 0.4474826742662117, disc_loss = 0.013893838010289983
Trained batch 512 in epoch 9, gen_loss = 0.4475225200894748, disc_loss = 0.013940563820053771
Trained batch 513 in epoch 9, gen_loss = 0.44731598385113225, disc_loss = 0.013922126409969137
Trained batch 514 in epoch 9, gen_loss = 0.44712894333219066, disc_loss = 0.013956264041825333
Trained batch 515 in epoch 9, gen_loss = 0.44725360865740815, disc_loss = 0.013950746027028997
Trained batch 516 in epoch 9, gen_loss = 0.44732155611943925, disc_loss = 0.013950372180303403
Trained batch 517 in epoch 9, gen_loss = 0.4473866046510608, disc_loss = 0.013946615117035705
Trained batch 518 in epoch 9, gen_loss = 0.4473525885212628, disc_loss = 0.013946547324370829
Trained batch 519 in epoch 9, gen_loss = 0.4474653108761861, disc_loss = 0.013961367483492582
Trained batch 520 in epoch 9, gen_loss = 0.44760375951851167, disc_loss = 0.013956399987301577
Trained batch 521 in epoch 9, gen_loss = 0.44756444751987967, disc_loss = 0.014034559264006556
Trained batch 522 in epoch 9, gen_loss = 0.4476150507908706, disc_loss = 0.014025889998381997
Trained batch 523 in epoch 9, gen_loss = 0.4476149642399249, disc_loss = 0.014017793565645515
Trained batch 524 in epoch 9, gen_loss = 0.4475080671196892, disc_loss = 0.014005257887100536
Trained batch 525 in epoch 9, gen_loss = 0.4474852749150062, disc_loss = 0.013984381003232722
Trained batch 526 in epoch 9, gen_loss = 0.4475675109328536, disc_loss = 0.013992513918522851
Trained batch 527 in epoch 9, gen_loss = 0.44755198349329556, disc_loss = 0.013972943263952126
Trained batch 528 in epoch 9, gen_loss = 0.44760756822750114, disc_loss = 0.013969059767499074
Trained batch 529 in epoch 9, gen_loss = 0.4476672667939708, disc_loss = 0.013965080263541202
Trained batch 530 in epoch 9, gen_loss = 0.4476145647901151, disc_loss = 0.013975822599823964
Trained batch 531 in epoch 9, gen_loss = 0.44760502645171674, disc_loss = 0.01395567165424214
Trained batch 532 in epoch 9, gen_loss = 0.4475406931667793, disc_loss = 0.013942376532029241
Trained batch 533 in epoch 9, gen_loss = 0.44744062513001404, disc_loss = 0.013928454377808807
Trained batch 534 in epoch 9, gen_loss = 0.44751305658126544, disc_loss = 0.013914978721562042
Trained batch 535 in epoch 9, gen_loss = 0.44746518546520775, disc_loss = 0.01391221552808359
Trained batch 536 in epoch 9, gen_loss = 0.4474934784615728, disc_loss = 0.013914710314627009
Trained batch 537 in epoch 9, gen_loss = 0.44767087398851674, disc_loss = 0.014356243730302845
Trained batch 538 in epoch 9, gen_loss = 0.44763000964676075, disc_loss = 0.01455618258447305
Trained batch 539 in epoch 9, gen_loss = 0.44755622567953884, disc_loss = 0.014871945726918056
Trained batch 540 in epoch 9, gen_loss = 0.4476412412419557, disc_loss = 0.015067986604953856
Trained batch 541 in epoch 9, gen_loss = 0.4476357762773978, disc_loss = 0.015296577965467824
Trained batch 542 in epoch 9, gen_loss = 0.4476311728769903, disc_loss = 0.015390820044665693
Trained batch 543 in epoch 9, gen_loss = 0.4474308431038962, disc_loss = 0.015510539645594476
Trained batch 544 in epoch 9, gen_loss = 0.4474134746494643, disc_loss = 0.015575046233892645
Trained batch 545 in epoch 9, gen_loss = 0.4475295093360838, disc_loss = 0.015771361700499656
Trained batch 546 in epoch 9, gen_loss = 0.4475599805223441, disc_loss = 0.01591070046562402
Trained batch 547 in epoch 9, gen_loss = 0.447703487246576, disc_loss = 0.01591143185543882
Trained batch 548 in epoch 9, gen_loss = 0.447734099865394, disc_loss = 0.015924165620577125
Trained batch 549 in epoch 9, gen_loss = 0.44754873118617317, disc_loss = 0.015919023416724732
Trained batch 550 in epoch 9, gen_loss = 0.4476064127175215, disc_loss = 0.015925055589254763
Trained batch 551 in epoch 9, gen_loss = 0.44774892542889155, disc_loss = 0.015925062033879247
Trained batch 552 in epoch 9, gen_loss = 0.4477053310513281, disc_loss = 0.015909154074827368
Trained batch 553 in epoch 9, gen_loss = 0.4475173065270758, disc_loss = 0.01589003971686237
Trained batch 554 in epoch 9, gen_loss = 0.44751650803797954, disc_loss = 0.015877301452119272
Trained batch 555 in epoch 9, gen_loss = 0.44759571327151154, disc_loss = 0.015926942173785215
Trained batch 556 in epoch 9, gen_loss = 0.44752921926483, disc_loss = 0.015950605070721727
Trained batch 557 in epoch 9, gen_loss = 0.44753273429622786, disc_loss = 0.015938525660402447
Trained batch 558 in epoch 9, gen_loss = 0.4476013808962697, disc_loss = 0.015983616564821033
Trained batch 559 in epoch 9, gen_loss = 0.44765825447227275, disc_loss = 0.0159773790125785
Trained batch 560 in epoch 9, gen_loss = 0.44767927406305935, disc_loss = 0.01598121702763187
Trained batch 561 in epoch 9, gen_loss = 0.44779992087667947, disc_loss = 0.015981384160061736
Trained batch 562 in epoch 9, gen_loss = 0.447648554511011, disc_loss = 0.015973285437548338
Trained batch 563 in epoch 9, gen_loss = 0.4476352046567498, disc_loss = 0.015961578899973027
Trained batch 564 in epoch 9, gen_loss = 0.44771533107335587, disc_loss = 0.01594792481293424
Trained batch 565 in epoch 9, gen_loss = 0.4477691552453664, disc_loss = 0.015932557534865784
Trained batch 566 in epoch 9, gen_loss = 0.44779001126423923, disc_loss = 0.015915222532309696
Trained batch 567 in epoch 9, gen_loss = 0.44782337609311224, disc_loss = 0.01589320842147982
Trained batch 568 in epoch 9, gen_loss = 0.44775997696735736, disc_loss = 0.015881073758741007
Trained batch 569 in epoch 9, gen_loss = 0.4476200470276046, disc_loss = 0.015860344241822564
Trained batch 570 in epoch 9, gen_loss = 0.4476013010834228, disc_loss = 0.0158433110272551
Trained batch 571 in epoch 9, gen_loss = 0.44753367990463766, disc_loss = 0.015820575977139942
Trained batch 572 in epoch 9, gen_loss = 0.4476811158719487, disc_loss = 0.015801615083149683
Trained batch 573 in epoch 9, gen_loss = 0.4477600182182698, disc_loss = 0.015778627573351866
Trained batch 574 in epoch 9, gen_loss = 0.4478095805126688, disc_loss = 0.015754350316305846
Trained batch 575 in epoch 9, gen_loss = 0.44784661703225637, disc_loss = 0.0157309434930034
Trained batch 576 in epoch 9, gen_loss = 0.4479008227121892, disc_loss = 0.01570851778053877
Trained batch 577 in epoch 9, gen_loss = 0.4478973611209632, disc_loss = 0.01568503969588243
Trained batch 578 in epoch 9, gen_loss = 0.44789534889560495, disc_loss = 0.015662858574908543
Trained batch 579 in epoch 9, gen_loss = 0.44783803178318615, disc_loss = 0.015642061038143484
Trained batch 580 in epoch 9, gen_loss = 0.44780422893325555, disc_loss = 0.01562165003971208
Trained batch 581 in epoch 9, gen_loss = 0.4477172355676435, disc_loss = 0.015984599640764156
Trained batch 582 in epoch 9, gen_loss = 0.44758796006901186, disc_loss = 0.01631115505285721
Trained batch 583 in epoch 9, gen_loss = 0.44751566143272675, disc_loss = 0.01636888858545667
Trained batch 584 in epoch 9, gen_loss = 0.4475451136756147, disc_loss = 0.016451495222580166
Trained batch 585 in epoch 9, gen_loss = 0.44753888854598023, disc_loss = 0.01655337065613253
Trained batch 586 in epoch 9, gen_loss = 0.4476086507460937, disc_loss = 0.01657622178926829
Trained batch 587 in epoch 9, gen_loss = 0.4476380953375174, disc_loss = 0.016572945823118433
Trained batch 588 in epoch 9, gen_loss = 0.44752691476171, disc_loss = 0.01659356530321721
Trained batch 589 in epoch 9, gen_loss = 0.44754573642197304, disc_loss = 0.016578450070307352
Trained batch 590 in epoch 9, gen_loss = 0.44745005246144665, disc_loss = 0.016558212311442014
Trained batch 591 in epoch 9, gen_loss = 0.44755300970093626, disc_loss = 0.016546573492854117
Trained batch 592 in epoch 9, gen_loss = 0.44759855825221556, disc_loss = 0.01652943956902059
Trained batch 593 in epoch 9, gen_loss = 0.4477069951869823, disc_loss = 0.016512766424590024
Trained batch 594 in epoch 9, gen_loss = 0.44791160591510165, disc_loss = 0.016506637652216778
Trained batch 595 in epoch 9, gen_loss = 0.4479145898714962, disc_loss = 0.016527569268934818
Trained batch 596 in epoch 9, gen_loss = 0.44804378021102853, disc_loss = 0.016511369855969932
Trained batch 597 in epoch 9, gen_loss = 0.4480847525457076, disc_loss = 0.01649966497456244
Trained batch 598 in epoch 9, gen_loss = 0.44807480944814987, disc_loss = 0.01649463905984744
Trained batch 599 in epoch 9, gen_loss = 0.4481285664935907, disc_loss = 0.01647403081471566
Trained batch 600 in epoch 9, gen_loss = 0.44825649603631057, disc_loss = 0.016455994903252533
Trained batch 601 in epoch 9, gen_loss = 0.44837670206429553, disc_loss = 0.016440667261321568
Trained batch 602 in epoch 9, gen_loss = 0.44837121302215616, disc_loss = 0.016439674638179292
Trained batch 603 in epoch 9, gen_loss = 0.44848602906560264, disc_loss = 0.016420055647798512
Trained batch 604 in epoch 9, gen_loss = 0.4486085485328328, disc_loss = 0.016561077607310692
Trained batch 605 in epoch 9, gen_loss = 0.44851651492685374, disc_loss = 0.016621008734933405
Trained batch 606 in epoch 9, gen_loss = 0.44850364926423036, disc_loss = 0.016617092834609135
Trained batch 607 in epoch 9, gen_loss = 0.4485050310429774, disc_loss = 0.016621616287394364
Trained batch 608 in epoch 9, gen_loss = 0.4485379623857821, disc_loss = 0.016612536622378028
Trained batch 609 in epoch 9, gen_loss = 0.4486667362392926, disc_loss = 0.01659432228666074
Trained batch 610 in epoch 9, gen_loss = 0.448634176909826, disc_loss = 0.016585742391504153
Trained batch 611 in epoch 9, gen_loss = 0.448606378989282, disc_loss = 0.01656970142343483
Trained batch 612 in epoch 9, gen_loss = 0.4486571115731804, disc_loss = 0.016554614212052506
Trained batch 613 in epoch 9, gen_loss = 0.44869019178497677, disc_loss = 0.01654189789166419
Trained batch 614 in epoch 9, gen_loss = 0.4486445267995199, disc_loss = 0.016519922082978717
Trained batch 615 in epoch 9, gen_loss = 0.4486209077204203, disc_loss = 0.016502336365913115
Trained batch 616 in epoch 9, gen_loss = 0.4486203363687524, disc_loss = 0.016488347434804047
Trained batch 617 in epoch 9, gen_loss = 0.4487403229988123, disc_loss = 0.016468504821078422
Trained batch 618 in epoch 9, gen_loss = 0.4486125976280558, disc_loss = 0.01645097097736273
Trained batch 619 in epoch 9, gen_loss = 0.44859520898711297, disc_loss = 0.01643252257959947
Trained batch 620 in epoch 9, gen_loss = 0.44849656409495503, disc_loss = 0.016410443605442686
Trained batch 621 in epoch 9, gen_loss = 0.448491999669857, disc_loss = 0.016394125576725475
Trained batch 622 in epoch 9, gen_loss = 0.448414181199158, disc_loss = 0.01637311412352638
Trained batch 623 in epoch 9, gen_loss = 0.448397927177258, disc_loss = 0.016350650022407837
Trained batch 624 in epoch 9, gen_loss = 0.44832646427154543, disc_loss = 0.016328668636642396
Trained batch 625 in epoch 9, gen_loss = 0.4483333603261759, disc_loss = 0.016305196402853314
Trained batch 626 in epoch 9, gen_loss = 0.4483943398109083, disc_loss = 0.01628235068641591
Trained batch 627 in epoch 9, gen_loss = 0.44835862356006717, disc_loss = 0.016260381018339543
Trained batch 628 in epoch 9, gen_loss = 0.4483708683371733, disc_loss = 0.016237641422267534
Trained batch 629 in epoch 9, gen_loss = 0.44835811295206585, disc_loss = 0.01622500114312898
Trained batch 630 in epoch 9, gen_loss = 0.4483115455805783, disc_loss = 0.016202352382574767
Trained batch 631 in epoch 9, gen_loss = 0.4483024067705191, disc_loss = 0.016181273043083463
Trained batch 632 in epoch 9, gen_loss = 0.4482365839571749, disc_loss = 0.016166926353344456
Trained batch 633 in epoch 9, gen_loss = 0.4482263381172806, disc_loss = 0.016144868659409357
Trained batch 634 in epoch 9, gen_loss = 0.44830614206359143, disc_loss = 0.016123586351704584
Trained batch 635 in epoch 9, gen_loss = 0.4481783501288426, disc_loss = 0.016103999757496407
Trained batch 636 in epoch 9, gen_loss = 0.44814624053717034, disc_loss = 0.016083205105068697
Trained batch 637 in epoch 9, gen_loss = 0.44817732825735146, disc_loss = 0.016065799763468516
Trained batch 638 in epoch 9, gen_loss = 0.44814513551423996, disc_loss = 0.016043074950444658
Trained batch 639 in epoch 9, gen_loss = 0.4482527640182525, disc_loss = 0.016027331486475303
Trained batch 640 in epoch 9, gen_loss = 0.44829909938173995, disc_loss = 0.01600743119434894
Trained batch 641 in epoch 9, gen_loss = 0.44835349156106374, disc_loss = 0.015985322439632556
Trained batch 642 in epoch 9, gen_loss = 0.448335362213025, disc_loss = 0.015965674428992018
Trained batch 643 in epoch 9, gen_loss = 0.4483733809327487, disc_loss = 0.015948836404796957
Trained batch 644 in epoch 9, gen_loss = 0.44835783035256144, disc_loss = 0.015933254442192152
Trained batch 645 in epoch 9, gen_loss = 0.4482768439102468, disc_loss = 0.015910804659689002
Trained batch 646 in epoch 9, gen_loss = 0.4482509252921875, disc_loss = 0.01589089539999623
Trained batch 647 in epoch 9, gen_loss = 0.4482728763954875, disc_loss = 0.01587035549775105
Trained batch 648 in epoch 9, gen_loss = 0.44818006297472995, disc_loss = 0.01586590065259934
Trained batch 649 in epoch 9, gen_loss = 0.44809497590248404, disc_loss = 0.015844117185244193
Trained batch 650 in epoch 9, gen_loss = 0.4480560046095636, disc_loss = 0.015825367593471126
Trained batch 651 in epoch 9, gen_loss = 0.4481306816994047, disc_loss = 0.015803123618964608
Trained batch 652 in epoch 9, gen_loss = 0.4481367785112781, disc_loss = 0.015781790190654454
Trained batch 653 in epoch 9, gen_loss = 0.4481623354125825, disc_loss = 0.015759435692725175
Trained batch 654 in epoch 9, gen_loss = 0.44808862122870585, disc_loss = 0.01573915101111447
Trained batch 655 in epoch 9, gen_loss = 0.4480638148308527, disc_loss = 0.0157233014565796
Trained batch 656 in epoch 9, gen_loss = 0.44799003717198943, disc_loss = 0.015701322608997356
Trained batch 657 in epoch 9, gen_loss = 0.44792859913005656, disc_loss = 0.015680371624266158
Trained batch 658 in epoch 9, gen_loss = 0.44785920961311987, disc_loss = 0.015658621345745607
Trained batch 659 in epoch 9, gen_loss = 0.44791860363700176, disc_loss = 0.015637651923514732
Trained batch 660 in epoch 9, gen_loss = 0.4478896221486956, disc_loss = 0.015617762193676936
Trained batch 661 in epoch 9, gen_loss = 0.4480201568668342, disc_loss = 0.01559829074672066
Trained batch 662 in epoch 9, gen_loss = 0.44808311254730054, disc_loss = 0.015577292332473474
Trained batch 663 in epoch 9, gen_loss = 0.44803980342954036, disc_loss = 0.015556123177976774
Trained batch 664 in epoch 9, gen_loss = 0.44810623961283746, disc_loss = 0.01553945634671648
Trained batch 665 in epoch 9, gen_loss = 0.44805315772334375, disc_loss = 0.015517793960244235
Trained batch 666 in epoch 9, gen_loss = 0.4481997759803303, disc_loss = 0.015497380171726546
Trained batch 667 in epoch 9, gen_loss = 0.44816496602432454, disc_loss = 0.015477135432584345
Trained batch 668 in epoch 9, gen_loss = 0.448221983084586, disc_loss = 0.015456638514357988
Trained batch 669 in epoch 9, gen_loss = 0.44824397199189486, disc_loss = 0.01543574934780125
Trained batch 670 in epoch 9, gen_loss = 0.44832704079666363, disc_loss = 0.015414649208253958
Trained batch 671 in epoch 9, gen_loss = 0.44833998453049434, disc_loss = 0.015393515816997803
Trained batch 672 in epoch 9, gen_loss = 0.4483493282217505, disc_loss = 0.015372823651556207
Trained batch 673 in epoch 9, gen_loss = 0.44831256953120585, disc_loss = 0.015352278652301097
Trained batch 674 in epoch 9, gen_loss = 0.4483302739814476, disc_loss = 0.01533153222442639
Trained batch 675 in epoch 9, gen_loss = 0.44843698791145575, disc_loss = 0.015314265443101669
Trained batch 676 in epoch 9, gen_loss = 0.44841006173693093, disc_loss = 0.015294639684811531
Trained batch 677 in epoch 9, gen_loss = 0.4483899777002391, disc_loss = 0.015274655974468705
Trained batch 678 in epoch 9, gen_loss = 0.44843108484601063, disc_loss = 0.015255335780972991
Trained batch 679 in epoch 9, gen_loss = 0.44832762313239716, disc_loss = 0.015235622414312436
Trained batch 680 in epoch 9, gen_loss = 0.4482338219312144, disc_loss = 0.01521590792333978
Trained batch 681 in epoch 9, gen_loss = 0.4482625664329249, disc_loss = 0.01519585066646354
Trained batch 682 in epoch 9, gen_loss = 0.44823871659848563, disc_loss = 0.015180692056740741
Trained batch 683 in epoch 9, gen_loss = 0.44819036335275886, disc_loss = 0.015165298110199548
Trained batch 684 in epoch 9, gen_loss = 0.4481989363684271, disc_loss = 0.015147167197972482
Trained batch 685 in epoch 9, gen_loss = 0.4482538420326856, disc_loss = 0.015131076363237092
Trained batch 686 in epoch 9, gen_loss = 0.44833804608432487, disc_loss = 0.015112018070164716
Trained batch 687 in epoch 9, gen_loss = 0.44838581121591636, disc_loss = 0.015095023056769711
Trained batch 688 in epoch 9, gen_loss = 0.4484622875561043, disc_loss = 0.015076667328056959
Trained batch 689 in epoch 9, gen_loss = 0.4485282173191292, disc_loss = 0.015057346814791199
Trained batch 690 in epoch 9, gen_loss = 0.4484801251015339, disc_loss = 0.015039756300241866
Trained batch 691 in epoch 9, gen_loss = 0.4484549362879957, disc_loss = 0.015025417826298591
Trained batch 692 in epoch 9, gen_loss = 0.448397712102012, disc_loss = 0.015018146347844487
Trained batch 693 in epoch 9, gen_loss = 0.44827067817666, disc_loss = 0.015003451649253914
Trained batch 694 in epoch 9, gen_loss = 0.44829004484114887, disc_loss = 0.014986526324051909
Trained batch 695 in epoch 9, gen_loss = 0.4481927592778343, disc_loss = 0.014968663383637898
Trained batch 696 in epoch 9, gen_loss = 0.4482664565530364, disc_loss = 0.014950217787875197
Trained batch 697 in epoch 9, gen_loss = 0.44830843451883867, disc_loss = 0.01493777947104736
Trained batch 698 in epoch 9, gen_loss = 0.44832042089859303, disc_loss = 0.01491891186336623
Trained batch 699 in epoch 9, gen_loss = 0.4483044296503067, disc_loss = 0.014923146725964866
Trained batch 700 in epoch 9, gen_loss = 0.44826415015355325, disc_loss = 0.014905394063252801
Trained batch 701 in epoch 9, gen_loss = 0.4482545221378321, disc_loss = 0.014888460385053289
Trained batch 702 in epoch 9, gen_loss = 0.4482664231046674, disc_loss = 0.01486951328570932
Trained batch 703 in epoch 9, gen_loss = 0.4484236250546845, disc_loss = 0.014854883907570515
Trained batch 704 in epoch 9, gen_loss = 0.44839965430557305, disc_loss = 0.014843175733455371
Trained batch 705 in epoch 9, gen_loss = 0.4483917971001806, disc_loss = 0.014848996533071701
Trained batch 706 in epoch 9, gen_loss = 0.44838543023381916, disc_loss = 0.014833381690468266
Trained batch 707 in epoch 9, gen_loss = 0.44839377852819734, disc_loss = 0.014818353702591753
Trained batch 708 in epoch 9, gen_loss = 0.44843003965063055, disc_loss = 0.014804545832483942
Trained batch 709 in epoch 9, gen_loss = 0.44837397278194696, disc_loss = 0.01478777603282344
Trained batch 710 in epoch 9, gen_loss = 0.44837144679493374, disc_loss = 0.0147749846452407
Trained batch 711 in epoch 9, gen_loss = 0.44828729486365, disc_loss = 0.014768167384972095
Trained batch 712 in epoch 9, gen_loss = 0.44826151315661, disc_loss = 0.0147530984407458
Trained batch 713 in epoch 9, gen_loss = 0.4482289430390553, disc_loss = 0.01476228198461125
Trained batch 714 in epoch 9, gen_loss = 0.44819368778408825, disc_loss = 0.014746801929151105
Trained batch 715 in epoch 9, gen_loss = 0.4481252183794309, disc_loss = 0.014729736820116962
Trained batch 716 in epoch 9, gen_loss = 0.44813190722731533, disc_loss = 0.01471279022940454
Trained batch 717 in epoch 9, gen_loss = 0.4481667040699372, disc_loss = 0.014702057551033536
Trained batch 718 in epoch 9, gen_loss = 0.448159784078598, disc_loss = 0.014685638282436396
Trained batch 719 in epoch 9, gen_loss = 0.44818084951904086, disc_loss = 0.014669766566657926
Trained batch 720 in epoch 9, gen_loss = 0.4481313214553378, disc_loss = 0.01465216786913889
Trained batch 721 in epoch 9, gen_loss = 0.4481060160659357, disc_loss = 0.01463541765474789
Trained batch 722 in epoch 9, gen_loss = 0.44813878593108464, disc_loss = 0.014622092228170283
Trained batch 723 in epoch 9, gen_loss = 0.4480964198955515, disc_loss = 0.01460487925873951
Trained batch 724 in epoch 9, gen_loss = 0.448015533356831, disc_loss = 0.014589247215250185
Trained batch 725 in epoch 9, gen_loss = 0.448001420079184, disc_loss = 0.014582089176523363
Trained batch 726 in epoch 9, gen_loss = 0.4480794248833453, disc_loss = 0.014595957639296648
Trained batch 727 in epoch 9, gen_loss = 0.4481115541369705, disc_loss = 0.014580739738648645
Trained batch 728 in epoch 9, gen_loss = 0.44803354131832046, disc_loss = 0.014569029151794177
Trained batch 729 in epoch 9, gen_loss = 0.44803956628662267, disc_loss = 0.014563172639583634
Trained batch 730 in epoch 9, gen_loss = 0.4479966190950652, disc_loss = 0.014566109101504607
Trained batch 731 in epoch 9, gen_loss = 0.4479933755645335, disc_loss = 0.014588285703052985
Trained batch 732 in epoch 9, gen_loss = 0.4479630647626125, disc_loss = 0.014577672324946346
Trained batch 733 in epoch 9, gen_loss = 0.4480808258300256, disc_loss = 0.014575055315525954
Trained batch 734 in epoch 9, gen_loss = 0.4480406943632632, disc_loss = 0.014559317363559135
Trained batch 735 in epoch 9, gen_loss = 0.44804088293534255, disc_loss = 0.014549236145957484
Trained batch 736 in epoch 9, gen_loss = 0.44798610067270506, disc_loss = 0.014534676836562194
Trained batch 737 in epoch 9, gen_loss = 0.44796861538557503, disc_loss = 0.014519532019781014
Trained batch 738 in epoch 9, gen_loss = 0.44799727036117376, disc_loss = 0.014505819972517556
Trained batch 739 in epoch 9, gen_loss = 0.4480770224252263, disc_loss = 0.014489838005062445
Trained batch 740 in epoch 9, gen_loss = 0.44802060453837056, disc_loss = 0.014473259426853223
Trained batch 741 in epoch 9, gen_loss = 0.4480918683613728, disc_loss = 0.014459057452346668
Trained batch 742 in epoch 9, gen_loss = 0.44807386133584165, disc_loss = 0.014444921399945515
Trained batch 743 in epoch 9, gen_loss = 0.44808973271840363, disc_loss = 0.014433262765661673
Trained batch 744 in epoch 9, gen_loss = 0.44808312034446923, disc_loss = 0.01442086128064825
Trained batch 745 in epoch 9, gen_loss = 0.448057615165736, disc_loss = 0.01441079809130032
Testing Epoch 9
Training Epoch 10
Trained batch 0 in epoch 10, gen_loss = 0.4018769860267639, disc_loss = 0.003378803376108408
Trained batch 1 in epoch 10, gen_loss = 0.40679657459259033, disc_loss = 0.003203091211616993
Trained batch 2 in epoch 10, gen_loss = 0.40173924962679547, disc_loss = 0.011453732227285704
Trained batch 3 in epoch 10, gen_loss = 0.4287892058491707, disc_loss = 0.009938012575730681
Trained batch 4 in epoch 10, gen_loss = 0.4439478933811188, disc_loss = 0.017138667218387128
Trained batch 5 in epoch 10, gen_loss = 0.44192621608575183, disc_loss = 0.018729543779045343
Trained batch 6 in epoch 10, gen_loss = 0.4477838660989489, disc_loss = 0.025118740408548286
Trained batch 7 in epoch 10, gen_loss = 0.447064321488142, disc_loss = 0.02647825877647847
Trained batch 8 in epoch 10, gen_loss = 0.44566063748465645, disc_loss = 0.024968542572524812
Trained batch 9 in epoch 10, gen_loss = 0.445882847905159, disc_loss = 0.023545941244810818
Trained batch 10 in epoch 10, gen_loss = 0.45055934244936163, disc_loss = 0.021668165900998494
Trained batch 11 in epoch 10, gen_loss = 0.44779716183741886, disc_loss = 0.021801892648606252
Trained batch 12 in epoch 10, gen_loss = 0.4474198520183563, disc_loss = 0.02053741686261044
Trained batch 13 in epoch 10, gen_loss = 0.44917640728609903, disc_loss = 0.020495018173408295
Trained batch 14 in epoch 10, gen_loss = 0.45311580697695414, disc_loss = 0.022106375716005763
Trained batch 15 in epoch 10, gen_loss = 0.4487273897975683, disc_loss = 0.02900965364824515
Trained batch 16 in epoch 10, gen_loss = 0.45224332634140463, disc_loss = 0.02834936640882755
Trained batch 17 in epoch 10, gen_loss = 0.45532993310027653, disc_loss = 0.030912499603194494
Trained batch 18 in epoch 10, gen_loss = 0.45521744144590276, disc_loss = 0.02960585583442528
Trained batch 19 in epoch 10, gen_loss = 0.4545107424259186, disc_loss = 0.034357275220099834
Trained batch 20 in epoch 10, gen_loss = 0.45408425018900916, disc_loss = 0.03535166734253012
Trained batch 21 in epoch 10, gen_loss = 0.46032656729221344, disc_loss = 0.041752278095703914
Trained batch 22 in epoch 10, gen_loss = 0.45807740610578784, disc_loss = 0.045848867785104594
Trained batch 23 in epoch 10, gen_loss = 0.4569709536929925, disc_loss = 0.044752860335089885
Trained batch 24 in epoch 10, gen_loss = 0.45696213841438293, disc_loss = 0.04326822311617434
Trained batch 25 in epoch 10, gen_loss = 0.4570620094354336, disc_loss = 0.04180627043108241
Trained batch 26 in epoch 10, gen_loss = 0.4572483985512345, disc_loss = 0.04041849969265362
Trained batch 27 in epoch 10, gen_loss = 0.45725605317524504, disc_loss = 0.03939719949682642
Trained batch 28 in epoch 10, gen_loss = 0.4566861391067505, disc_loss = 0.03879302880598296
Trained batch 29 in epoch 10, gen_loss = 0.45334986845652264, disc_loss = 0.03781124753101418
Trained batch 30 in epoch 10, gen_loss = 0.4534448789012048, disc_loss = 0.03701888492721463
Trained batch 31 in epoch 10, gen_loss = 0.4568482041358948, disc_loss = 0.03610690897767199
Trained batch 32 in epoch 10, gen_loss = 0.45699788946093933, disc_loss = 0.03514376469662018
Trained batch 33 in epoch 10, gen_loss = 0.4566626417286256, disc_loss = 0.03418840523398317
Trained batch 34 in epoch 10, gen_loss = 0.45709502611841474, disc_loss = 0.03330488779049899
Trained batch 35 in epoch 10, gen_loss = 0.4564567274517483, disc_loss = 0.03278491234070518
Trained batch 36 in epoch 10, gen_loss = 0.4573675973995312, disc_loss = 0.03222963082402743
Trained batch 37 in epoch 10, gen_loss = 0.45773408758012873, disc_loss = 0.032228671106215766
Trained batch 38 in epoch 10, gen_loss = 0.4570723764407329, disc_loss = 0.03379263814228276
Trained batch 39 in epoch 10, gen_loss = 0.4573625549674034, disc_loss = 0.03369419341324829
Trained batch 40 in epoch 10, gen_loss = 0.45605731155814194, disc_loss = 0.03320610731635697
Trained batch 41 in epoch 10, gen_loss = 0.4575327407746088, disc_loss = 0.032620246073098054
Trained batch 42 in epoch 10, gen_loss = 0.45719578377036163, disc_loss = 0.03201527022323463
Trained batch 43 in epoch 10, gen_loss = 0.45741368152878503, disc_loss = 0.031688555604143236
Trained batch 44 in epoch 10, gen_loss = 0.45800063874986435, disc_loss = 0.03427592668578856
Trained batch 45 in epoch 10, gen_loss = 0.45629246014615765, disc_loss = 0.03931190352380762
Trained batch 46 in epoch 10, gen_loss = 0.457421655984635, disc_loss = 0.03946784998171349
Trained batch 47 in epoch 10, gen_loss = 0.4553014474610488, disc_loss = 0.04025421822734643
Trained batch 48 in epoch 10, gen_loss = 0.4527859468849338, disc_loss = 0.0410680380431289
Trained batch 49 in epoch 10, gen_loss = 0.45280609488487245, disc_loss = 0.04065763424616307
Trained batch 50 in epoch 10, gen_loss = 0.4522375955301173, disc_loss = 0.04033010722795392
Trained batch 51 in epoch 10, gen_loss = 0.452136089022343, disc_loss = 0.0401840663398616
Trained batch 52 in epoch 10, gen_loss = 0.45170141391034396, disc_loss = 0.04003218856183285
Trained batch 53 in epoch 10, gen_loss = 0.4517190776489399, disc_loss = 0.04046592971361759
Trained batch 54 in epoch 10, gen_loss = 0.45260943391106345, disc_loss = 0.0409868355459449
Trained batch 55 in epoch 10, gen_loss = 0.4533418427620615, disc_loss = 0.04079894598024631
Trained batch 56 in epoch 10, gen_loss = 0.4542982254111976, disc_loss = 0.040444887549567377
Trained batch 57 in epoch 10, gen_loss = 0.454251318656165, disc_loss = 0.04014191400372134
Trained batch 58 in epoch 10, gen_loss = 0.45467735195564013, disc_loss = 0.03971531445365715
Trained batch 59 in epoch 10, gen_loss = 0.45437550991773606, disc_loss = 0.03996609785826877
Trained batch 60 in epoch 10, gen_loss = 0.4540492413473911, disc_loss = 0.039841419372127436
Trained batch 61 in epoch 10, gen_loss = 0.45443839892264337, disc_loss = 0.039463628455245446
Trained batch 62 in epoch 10, gen_loss = 0.45426361144535127, disc_loss = 0.03921393187908781
Trained batch 63 in epoch 10, gen_loss = 0.4536630967631936, disc_loss = 0.039644005253649084
Trained batch 64 in epoch 10, gen_loss = 0.4538663148880005, disc_loss = 0.039413712814880104
Trained batch 65 in epoch 10, gen_loss = 0.45277982408350165, disc_loss = 0.03971894396906436
Trained batch 66 in epoch 10, gen_loss = 0.4537899912293278, disc_loss = 0.03987062173033717
Trained batch 67 in epoch 10, gen_loss = 0.4540569983861026, disc_loss = 0.04034744856043664
Trained batch 68 in epoch 10, gen_loss = 0.45415929218997125, disc_loss = 0.0409914446906929
Trained batch 69 in epoch 10, gen_loss = 0.4542062265532357, disc_loss = 0.040659382789661844
Trained batch 70 in epoch 10, gen_loss = 0.4557917806464182, disc_loss = 0.041532772380045394
Trained batch 71 in epoch 10, gen_loss = 0.45623383505476844, disc_loss = 0.04123834045539196
Trained batch 72 in epoch 10, gen_loss = 0.45586846544318005, disc_loss = 0.04082583630623372
Trained batch 73 in epoch 10, gen_loss = 0.454703399458447, disc_loss = 0.0403847386273933
Trained batch 74 in epoch 10, gen_loss = 0.45414453268051147, disc_loss = 0.03991686334523062
Trained batch 75 in epoch 10, gen_loss = 0.45427249842568446, disc_loss = 0.03999787093887694
Trained batch 76 in epoch 10, gen_loss = 0.4536706797488324, disc_loss = 0.03980213653163186
Trained batch 77 in epoch 10, gen_loss = 0.4530999874457335, disc_loss = 0.03947183113986961
Trained batch 78 in epoch 10, gen_loss = 0.4526531926438778, disc_loss = 0.039074739573900646
Trained batch 79 in epoch 10, gen_loss = 0.4520051900297403, disc_loss = 0.038647982609109024
Trained batch 80 in epoch 10, gen_loss = 0.45174086314660533, disc_loss = 0.0382104641125526
Trained batch 81 in epoch 10, gen_loss = 0.4517680213945668, disc_loss = 0.03786085827684984
Trained batch 82 in epoch 10, gen_loss = 0.45188170886901485, disc_loss = 0.037526418555931876
Trained batch 83 in epoch 10, gen_loss = 0.4523703157901764, disc_loss = 0.03748686443127337
Trained batch 84 in epoch 10, gen_loss = 0.45266704699572397, disc_loss = 0.03738910389297149
Trained batch 85 in epoch 10, gen_loss = 0.4532180345335672, disc_loss = 0.03741447714179061
Trained batch 86 in epoch 10, gen_loss = 0.4532898273961297, disc_loss = 0.0374741457488345
Trained batch 87 in epoch 10, gen_loss = 0.45324140109799127, disc_loss = 0.037408094429834324
Trained batch 88 in epoch 10, gen_loss = 0.45336890019727555, disc_loss = 0.03709235232783837
Trained batch 89 in epoch 10, gen_loss = 0.4533103088537852, disc_loss = 0.03731381969733371
Trained batch 90 in epoch 10, gen_loss = 0.45303829652922495, disc_loss = 0.03717372543946072
Trained batch 91 in epoch 10, gen_loss = 0.45380911846523697, disc_loss = 0.036893927461832114
Trained batch 92 in epoch 10, gen_loss = 0.4539545431572904, disc_loss = 0.03670643030675829
Trained batch 93 in epoch 10, gen_loss = 0.45409150199687226, disc_loss = 0.03723904681689245
Trained batch 94 in epoch 10, gen_loss = 0.45510688769189933, disc_loss = 0.037978046828586805
Trained batch 95 in epoch 10, gen_loss = 0.4547653812915087, disc_loss = 0.03777733387930008
Trained batch 96 in epoch 10, gen_loss = 0.4538860904801752, disc_loss = 0.037647295445587835
Trained batch 97 in epoch 10, gen_loss = 0.4549584559031895, disc_loss = 0.037401680920121014
Trained batch 98 in epoch 10, gen_loss = 0.4550283764949953, disc_loss = 0.037143159488385376
Trained batch 99 in epoch 10, gen_loss = 0.45450899690389635, disc_loss = 0.036958410125225785
Trained batch 100 in epoch 10, gen_loss = 0.4553045916675341, disc_loss = 0.037309654702497
Trained batch 101 in epoch 10, gen_loss = 0.4543122842031367, disc_loss = 0.03790950897496705
Trained batch 102 in epoch 10, gen_loss = 0.45427643008602475, disc_loss = 0.03776523962761592
Trained batch 103 in epoch 10, gen_loss = 0.45453562616155696, disc_loss = 0.038519857021478504
Trained batch 104 in epoch 10, gen_loss = 0.4537281853812081, disc_loss = 0.03940655844552177
Trained batch 105 in epoch 10, gen_loss = 0.45354695814960405, disc_loss = 0.03939385504795695
Trained batch 106 in epoch 10, gen_loss = 0.4541420490942269, disc_loss = 0.03907995993515181
Trained batch 107 in epoch 10, gen_loss = 0.454433336853981, disc_loss = 0.0389780505017067
Trained batch 108 in epoch 10, gen_loss = 0.45421725347501424, disc_loss = 0.03869375947504005
Trained batch 109 in epoch 10, gen_loss = 0.4543914643200961, disc_loss = 0.038485542841425
Trained batch 110 in epoch 10, gen_loss = 0.4546176906641539, disc_loss = 0.03818426235067146
Trained batch 111 in epoch 10, gen_loss = 0.4545475436108453, disc_loss = 0.03804841134530891
Trained batch 112 in epoch 10, gen_loss = 0.45440764843890097, disc_loss = 0.03787508535207109
Trained batch 113 in epoch 10, gen_loss = 0.45479001235543637, disc_loss = 0.03773873610618083
Trained batch 114 in epoch 10, gen_loss = 0.455078844661298, disc_loss = 0.03747439122880283
Trained batch 115 in epoch 10, gen_loss = 0.45584773169509296, disc_loss = 0.03730396853342395
Trained batch 116 in epoch 10, gen_loss = 0.45517426219760865, disc_loss = 0.03701062263666183
Trained batch 117 in epoch 10, gen_loss = 0.45466580608133544, disc_loss = 0.03680015897962375
Trained batch 118 in epoch 10, gen_loss = 0.4551282968340802, disc_loss = 0.03670876022005657
Trained batch 119 in epoch 10, gen_loss = 0.4548494006196658, disc_loss = 0.03645127142081037
Trained batch 120 in epoch 10, gen_loss = 0.45442345836931025, disc_loss = 0.036279246638228825
Trained batch 121 in epoch 10, gen_loss = 0.453419354362566, disc_loss = 0.03649757154759203
Trained batch 123 in epoch 10, gen_loss = 0.45384323068203464, disc_loss = 0.03642539496368338
Trained batch 124 in epoch 10, gen_loss = 0.45354579329490663, disc_loss = 0.03617325823009014
Trained batch 125 in epoch 10, gen_loss = 0.45313587903030333, disc_loss = 0.03617135670390867
Trained batch 126 in epoch 10, gen_loss = 0.45259308322208136, disc_loss = 0.036239520932628416
Trained batch 127 in epoch 10, gen_loss = 0.45304647949524224, disc_loss = 0.03636754564649891
Trained batch 128 in epoch 10, gen_loss = 0.4527443705141082, disc_loss = 0.036988108007367265
Trained batch 129 in epoch 10, gen_loss = 0.45210321637300344, disc_loss = 0.03725174291489216
Trained batch 130 in epoch 10, gen_loss = 0.4521359778542555, disc_loss = 0.03796191199305858
Trained batch 131 in epoch 10, gen_loss = 0.4519826824014837, disc_loss = 0.03837423025150642
Trained batch 132 in epoch 10, gen_loss = 0.4520511801977803, disc_loss = 0.03839176830212425
Trained batch 133 in epoch 10, gen_loss = 0.4516572138266777, disc_loss = 0.039183928825850804
Trained batch 134 in epoch 10, gen_loss = 0.4511532520806348, disc_loss = 0.03927487652334902
Trained batch 135 in epoch 10, gen_loss = 0.45125776266350465, disc_loss = 0.03930353481486878
Trained batch 136 in epoch 10, gen_loss = 0.4505757806945021, disc_loss = 0.03919035526685906
Trained batch 137 in epoch 10, gen_loss = 0.45003203032673267, disc_loss = 0.03899638524171019
Trained batch 138 in epoch 10, gen_loss = 0.44990295643429107, disc_loss = 0.0388498916190198
Trained batch 139 in epoch 10, gen_loss = 0.4502167241913932, disc_loss = 0.038882486675200716
Trained batch 140 in epoch 10, gen_loss = 0.4508337361592773, disc_loss = 0.039085578880147305
Trained batch 141 in epoch 10, gen_loss = 0.4508451693494555, disc_loss = 0.03899424952704092
Trained batch 142 in epoch 10, gen_loss = 0.45107216018063206, disc_loss = 0.03880234278894804
Trained batch 143 in epoch 10, gen_loss = 0.45128107174403137, disc_loss = 0.03874795035355621
Trained batch 144 in epoch 10, gen_loss = 0.45136894789235343, disc_loss = 0.03907787013670494
Trained batch 145 in epoch 10, gen_loss = 0.4517395608637431, disc_loss = 0.03909363153658501
Trained batch 146 in epoch 10, gen_loss = 0.45184297241321225, disc_loss = 0.03896471167452076
Trained batch 147 in epoch 10, gen_loss = 0.45203049279548024, disc_loss = 0.03884466760162566
Trained batch 148 in epoch 10, gen_loss = 0.4521325406612166, disc_loss = 0.03862935608415396
Trained batch 149 in epoch 10, gen_loss = 0.4527688241004944, disc_loss = 0.038429798111319545
Trained batch 150 in epoch 10, gen_loss = 0.45276673483532787, disc_loss = 0.038229093399663634
Trained batch 151 in epoch 10, gen_loss = 0.4526767181722741, disc_loss = 0.038014715831530724
Trained batch 152 in epoch 10, gen_loss = 0.4527573082961288, disc_loss = 0.03779517025899848
Trained batch 153 in epoch 10, gen_loss = 0.4529756688839429, disc_loss = 0.03764796603543611
Trained batch 154 in epoch 10, gen_loss = 0.45321259883142284, disc_loss = 0.03762424235502558
Trained batch 155 in epoch 10, gen_loss = 0.45292903310977495, disc_loss = 0.03803922878936506
Trained batch 156 in epoch 10, gen_loss = 0.4523606835656865, disc_loss = 0.03791406034687712
Trained batch 157 in epoch 10, gen_loss = 0.451921298345433, disc_loss = 0.03837044183990058
Trained batch 158 in epoch 10, gen_loss = 0.45214475063407944, disc_loss = 0.038788314469439804
Trained batch 159 in epoch 10, gen_loss = 0.45237664952874185, disc_loss = 0.038686185638653114
Trained batch 160 in epoch 10, gen_loss = 0.45235410888002525, disc_loss = 0.03855063762191845
Trained batch 161 in epoch 10, gen_loss = 0.4523697835795673, disc_loss = 0.0384606752878078
Trained batch 162 in epoch 10, gen_loss = 0.45238346867034773, disc_loss = 0.038295071406369924
Trained batch 163 in epoch 10, gen_loss = 0.45235254233930167, disc_loss = 0.03809502106954957
Trained batch 164 in epoch 10, gen_loss = 0.4524403942353798, disc_loss = 0.03789308687220469
Trained batch 165 in epoch 10, gen_loss = 0.45256081905709694, disc_loss = 0.03782020735621722
Trained batch 166 in epoch 10, gen_loss = 0.4528549848916288, disc_loss = 0.03777207509742793
Trained batch 167 in epoch 10, gen_loss = 0.4530428403190204, disc_loss = 0.038225679877325
Trained batch 168 in epoch 10, gen_loss = 0.45294768447001305, disc_loss = 0.038073290406709766
Trained batch 169 in epoch 10, gen_loss = 0.45283301525256214, disc_loss = 0.03840075852075482
Trained batch 170 in epoch 10, gen_loss = 0.4532396049178832, disc_loss = 0.038708235504791924
Trained batch 171 in epoch 10, gen_loss = 0.4534380053018415, disc_loss = 0.038573822085095875
Trained batch 172 in epoch 10, gen_loss = 0.453582709924334, disc_loss = 0.03922572856058361
Trained batch 173 in epoch 10, gen_loss = 0.4538936919864567, disc_loss = 0.039677989757459224
Trained batch 174 in epoch 10, gen_loss = 0.4539229956695012, disc_loss = 0.0395288827829063
Trained batch 175 in epoch 10, gen_loss = 0.45341414314779366, disc_loss = 0.039466200716560706
Trained batch 176 in epoch 10, gen_loss = 0.4534038126805408, disc_loss = 0.03936949110521519
Trained batch 177 in epoch 10, gen_loss = 0.4532366600934039, disc_loss = 0.03923855840458713
Trained batch 178 in epoch 10, gen_loss = 0.4528485872892028, disc_loss = 0.03904668966766093
Trained batch 179 in epoch 10, gen_loss = 0.4529488619830873, disc_loss = 0.038876421979835464
Trained batch 180 in epoch 10, gen_loss = 0.45279709673718194, disc_loss = 0.038711051886273516
Trained batch 181 in epoch 10, gen_loss = 0.45297067456848017, disc_loss = 0.03854828955513517
Trained batch 182 in epoch 10, gen_loss = 0.45262396628739404, disc_loss = 0.03839620581161373
Trained batch 183 in epoch 10, gen_loss = 0.45253288762077043, disc_loss = 0.03848240554646548
Trained batch 184 in epoch 10, gen_loss = 0.4527574663226669, disc_loss = 0.038417451967158026
Trained batch 185 in epoch 10, gen_loss = 0.45293164333348634, disc_loss = 0.03827045535198062
Trained batch 186 in epoch 10, gen_loss = 0.4531628036881513, disc_loss = 0.03809963735218912
Trained batch 187 in epoch 10, gen_loss = 0.45302265660559876, disc_loss = 0.0379656764871857
Trained batch 188 in epoch 10, gen_loss = 0.45311131899949736, disc_loss = 0.03779359023633694
Trained batch 189 in epoch 10, gen_loss = 0.45301432484074644, disc_loss = 0.037611756147816776
Trained batch 190 in epoch 10, gen_loss = 0.45304285918230786, disc_loss = 0.03742947152094106
Trained batch 191 in epoch 10, gen_loss = 0.4532996915901701, disc_loss = 0.03728098567444249
Trained batch 192 in epoch 10, gen_loss = 0.45313936394730997, disc_loss = 0.0371005417154185
Trained batch 193 in epoch 10, gen_loss = 0.4530998611265851, disc_loss = 0.0369857252088193
Trained batch 194 in epoch 10, gen_loss = 0.45282320135679, disc_loss = 0.03681334075159751
Trained batch 195 in epoch 10, gen_loss = 0.4526424125141027, disc_loss = 0.03664260549703613
Trained batch 196 in epoch 10, gen_loss = 0.45256899667875417, disc_loss = 0.036466346424886116
Trained batch 197 in epoch 10, gen_loss = 0.45239489834115965, disc_loss = 0.03629534765419484
Trained batch 198 in epoch 10, gen_loss = 0.4524204110979435, disc_loss = 0.0361316482262714
Trained batch 199 in epoch 10, gen_loss = 0.45227778881788255, disc_loss = 0.03596113445004448
Trained batch 200 in epoch 10, gen_loss = 0.4524168379567749, disc_loss = 0.03584174164779373
Trained batch 201 in epoch 10, gen_loss = 0.45240350480717006, disc_loss = 0.035675996856874614
Trained batch 202 in epoch 10, gen_loss = 0.452266078130365, disc_loss = 0.035515282479725005
Trained batch 203 in epoch 10, gen_loss = 0.4519087375671256, disc_loss = 0.0353814787802049
Trained batch 204 in epoch 10, gen_loss = 0.4523211250944835, disc_loss = 0.03522734693478702
Trained batch 205 in epoch 10, gen_loss = 0.45209900702087624, disc_loss = 0.035066190407412504
Trained batch 206 in epoch 10, gen_loss = 0.4524572226736281, disc_loss = 0.034912266940607325
Trained batch 207 in epoch 10, gen_loss = 0.4522598019013038, disc_loss = 0.034754564357661784
Trained batch 208 in epoch 10, gen_loss = 0.45191441540512745, disc_loss = 0.03501914161631757
Trained batch 209 in epoch 10, gen_loss = 0.45148987713314237, disc_loss = 0.03514481183207993
Trained batch 210 in epoch 10, gen_loss = 0.45104208475605573, disc_loss = 0.03513530539282514
Trained batch 211 in epoch 10, gen_loss = 0.4509547674712145, disc_loss = 0.035065071612271424
Trained batch 212 in epoch 10, gen_loss = 0.45059747497240704, disc_loss = 0.03510816077736727
Trained batch 213 in epoch 10, gen_loss = 0.4508277608133922, disc_loss = 0.03501775865900008
Trained batch 214 in epoch 10, gen_loss = 0.450934054546578, disc_loss = 0.03500793383803305
Trained batch 215 in epoch 10, gen_loss = 0.4507580026984215, disc_loss = 0.03492375668375408
Trained batch 216 in epoch 10, gen_loss = 0.45086627717941036, disc_loss = 0.035131139842759014
Trained batch 217 in epoch 10, gen_loss = 0.45161765034592477, disc_loss = 0.03571462475613545
Trained batch 218 in epoch 10, gen_loss = 0.4514721881036889, disc_loss = 0.03560125090279637
Trained batch 219 in epoch 10, gen_loss = 0.4514809968796643, disc_loss = 0.035690512447829614
Trained batch 220 in epoch 10, gen_loss = 0.45116668373211477, disc_loss = 0.03556423531360587
Trained batch 221 in epoch 10, gen_loss = 0.45122018214818593, disc_loss = 0.03559361268904664
Trained batch 222 in epoch 10, gen_loss = 0.45139822150025133, disc_loss = 0.035486654181141955
Trained batch 223 in epoch 10, gen_loss = 0.45122534967958927, disc_loss = 0.035545319035009015
Trained batch 224 in epoch 10, gen_loss = 0.4513802733686235, disc_loss = 0.035642844172608525
Trained batch 225 in epoch 10, gen_loss = 0.4514966895886227, disc_loss = 0.03557891408455418
Trained batch 226 in epoch 10, gen_loss = 0.4518897062093676, disc_loss = 0.035627029260768175
Trained batch 227 in epoch 10, gen_loss = 0.45221921239505736, disc_loss = 0.03580015634590956
Trained batch 228 in epoch 10, gen_loss = 0.4521958941195209, disc_loss = 0.0364997776532261
Trained batch 229 in epoch 10, gen_loss = 0.45230829067852185, disc_loss = 0.036841943842844796
Trained batch 230 in epoch 10, gen_loss = 0.4520323250716899, disc_loss = 0.036838960707856916
Trained batch 231 in epoch 10, gen_loss = 0.45192025897317917, disc_loss = 0.03679531491421773
Trained batch 232 in epoch 10, gen_loss = 0.45122187127371205, disc_loss = 0.03677113634702058
Trained batch 233 in epoch 10, gen_loss = 0.4514115552107493, disc_loss = 0.037038752211170256
Trained batch 234 in epoch 10, gen_loss = 0.45119542086378056, disc_loss = 0.037046593291922766
Trained batch 235 in epoch 10, gen_loss = 0.45123529914072, disc_loss = 0.03716160109862527
Trained batch 236 in epoch 10, gen_loss = 0.4515088369071735, disc_loss = 0.03704185906369318
Trained batch 237 in epoch 10, gen_loss = 0.4515225019525079, disc_loss = 0.03714193035789742
Trained batch 238 in epoch 10, gen_loss = 0.4516617502378121, disc_loss = 0.03704725177744286
Trained batch 239 in epoch 10, gen_loss = 0.45175177057584126, disc_loss = 0.03762419102616453
Trained batch 240 in epoch 10, gen_loss = 0.4516379401644236, disc_loss = 0.03765635901803143
Trained batch 241 in epoch 10, gen_loss = 0.45203384375276645, disc_loss = 0.037870313247765824
Trained batch 242 in epoch 10, gen_loss = 0.4521416809578491, disc_loss = 0.0377790986362906
Trained batch 243 in epoch 10, gen_loss = 0.4516101622434913, disc_loss = 0.03801379364163264
Trained batch 244 in epoch 10, gen_loss = 0.45130660813681933, disc_loss = 0.03789485927043977
Trained batch 245 in epoch 10, gen_loss = 0.4510314196832781, disc_loss = 0.0377880754242689
Trained batch 246 in epoch 10, gen_loss = 0.45101270308861363, disc_loss = 0.03772827259619317
Trained batch 247 in epoch 10, gen_loss = 0.4512601977875156, disc_loss = 0.03764600165454941
Trained batch 248 in epoch 10, gen_loss = 0.45108286216555826, disc_loss = 0.0375180292180758
Trained batch 249 in epoch 10, gen_loss = 0.4511475883722305, disc_loss = 0.03762478517089039
Trained batch 250 in epoch 10, gen_loss = 0.4509990228362292, disc_loss = 0.037502857720093485
Trained batch 251 in epoch 10, gen_loss = 0.45135484221908784, disc_loss = 0.03741718914511333
Trained batch 252 in epoch 10, gen_loss = 0.45160488660627673, disc_loss = 0.03736961991599809
Trained batch 253 in epoch 10, gen_loss = 0.45165562629699707, disc_loss = 0.037329151838702536
Trained batch 254 in epoch 10, gen_loss = 0.4517662306626638, disc_loss = 0.037212252955628085
Trained batch 255 in epoch 10, gen_loss = 0.4516246736748144, disc_loss = 0.037079976315908425
Trained batch 256 in epoch 10, gen_loss = 0.45158339138160886, disc_loss = 0.03697107287018708
Trained batch 257 in epoch 10, gen_loss = 0.45173244594141493, disc_loss = 0.036846897739000156
Trained batch 258 in epoch 10, gen_loss = 0.4515653466626024, disc_loss = 0.036712940430815216
Trained batch 259 in epoch 10, gen_loss = 0.4512567057059361, disc_loss = 0.03658358136980006
Trained batch 260 in epoch 10, gen_loss = 0.4512289772773611, disc_loss = 0.03645132171789405
Trained batch 261 in epoch 10, gen_loss = 0.45115349345079814, disc_loss = 0.03632201966900691
Trained batch 262 in epoch 10, gen_loss = 0.45103622616017275, disc_loss = 0.03619693363432422
Trained batch 263 in epoch 10, gen_loss = 0.45098347532929794, disc_loss = 0.03607472707164672
Trained batch 264 in epoch 10, gen_loss = 0.4507825435332532, disc_loss = 0.03595052598184853
Trained batch 265 in epoch 10, gen_loss = 0.45083773539478617, disc_loss = 0.03583053588566083
Trained batch 266 in epoch 10, gen_loss = 0.450734570231777, disc_loss = 0.036453413991571475
Trained batch 267 in epoch 10, gen_loss = 0.4503773493108465, disc_loss = 0.03646052227904603
Trained batch 268 in epoch 10, gen_loss = 0.45032534889572173, disc_loss = 0.036462076654013756
Trained batch 269 in epoch 10, gen_loss = 0.45005631358535203, disc_loss = 0.03643155347176448
Trained batch 270 in epoch 10, gen_loss = 0.450019122489704, disc_loss = 0.036412616052434565
Trained batch 271 in epoch 10, gen_loss = 0.44997625052928925, disc_loss = 0.0363906116639127
Trained batch 272 in epoch 10, gen_loss = 0.4503202783319103, disc_loss = 0.036286832619758645
Trained batch 273 in epoch 10, gen_loss = 0.45048241328148947, disc_loss = 0.03626987854542252
Trained batch 274 in epoch 10, gen_loss = 0.4501992455395785, disc_loss = 0.03616091519424861
Trained batch 275 in epoch 10, gen_loss = 0.45041580195876135, disc_loss = 0.03607247005034562
Trained batch 276 in epoch 10, gen_loss = 0.45064229762941493, disc_loss = 0.035993340262127804
Trained batch 277 in epoch 10, gen_loss = 0.45060727364725345, disc_loss = 0.03593442877989075
Trained batch 278 in epoch 10, gen_loss = 0.4507747459155257, disc_loss = 0.03594776550908723
Trained batch 279 in epoch 10, gen_loss = 0.45080413637416705, disc_loss = 0.03583281929771017
Trained batch 280 in epoch 10, gen_loss = 0.4508156310833222, disc_loss = 0.03574233670019648
Trained batch 281 in epoch 10, gen_loss = 0.4508405233739961, disc_loss = 0.03564772839288075
Trained batch 282 in epoch 10, gen_loss = 0.45107939607684266, disc_loss = 0.03566645627986153
Trained batch 283 in epoch 10, gen_loss = 0.45101613026689474, disc_loss = 0.03582005939793996
Trained batch 284 in epoch 10, gen_loss = 0.450813497158519, disc_loss = 0.03601053822295446
Trained batch 285 in epoch 10, gen_loss = 0.45068321746962886, disc_loss = 0.03597527798232655
Trained batch 286 in epoch 10, gen_loss = 0.45051347607104203, disc_loss = 0.035900371673254085
Trained batch 287 in epoch 10, gen_loss = 0.4506757063791156, disc_loss = 0.03589614463756637
Trained batch 288 in epoch 10, gen_loss = 0.450789240507931, disc_loss = 0.03597407827836987
Trained batch 289 in epoch 10, gen_loss = 0.45089536987502, disc_loss = 0.03598973329564364
Trained batch 290 in epoch 10, gen_loss = 0.45077975242817936, disc_loss = 0.035932089792583714
Trained batch 291 in epoch 10, gen_loss = 0.4506222884336563, disc_loss = 0.03588719180408763
Trained batch 292 in epoch 10, gen_loss = 0.4506335589055722, disc_loss = 0.03580860663110028
Trained batch 293 in epoch 10, gen_loss = 0.4507158606433544, disc_loss = 0.03576006356873834
Trained batch 294 in epoch 10, gen_loss = 0.4509637126478098, disc_loss = 0.03593244799333861
Trained batch 295 in epoch 10, gen_loss = 0.4508755628925723, disc_loss = 0.03584662324125954
Trained batch 296 in epoch 10, gen_loss = 0.45058612028757733, disc_loss = 0.035858617074825246
Trained batch 297 in epoch 10, gen_loss = 0.450386572304188, disc_loss = 0.03577307516852731
Trained batch 298 in epoch 10, gen_loss = 0.450456786315178, disc_loss = 0.03570661221764807
Trained batch 299 in epoch 10, gen_loss = 0.4503599828481674, disc_loss = 0.035649999605181316
Trained batch 300 in epoch 10, gen_loss = 0.4506092366586096, disc_loss = 0.03610188603258856
Trained batch 301 in epoch 10, gen_loss = 0.45043077354399574, disc_loss = 0.036599648636858294
Trained batch 302 in epoch 10, gen_loss = 0.45054707698302693, disc_loss = 0.03668357187377984
Trained batch 303 in epoch 10, gen_loss = 0.45066639182991103, disc_loss = 0.03666240996589247
Trained batch 304 in epoch 10, gen_loss = 0.4508264308093024, disc_loss = 0.03669676381453383
Trained batch 305 in epoch 10, gen_loss = 0.450705386941729, disc_loss = 0.03674641885989485
Trained batch 306 in epoch 10, gen_loss = 0.45078557894750215, disc_loss = 0.03668423875687031
Trained batch 307 in epoch 10, gen_loss = 0.4510758371128664, disc_loss = 0.036727259227364965
Trained batch 308 in epoch 10, gen_loss = 0.4511865642657172, disc_loss = 0.03662986011609049
Trained batch 309 in epoch 10, gen_loss = 0.45092066324526264, disc_loss = 0.036574841307235824
Trained batch 310 in epoch 10, gen_loss = 0.4506451436752675, disc_loss = 0.03663488020341831
Trained batch 311 in epoch 10, gen_loss = 0.4507989339912549, disc_loss = 0.03659777866097358
Trained batch 312 in epoch 10, gen_loss = 0.45105458496096795, disc_loss = 0.03660880192108571
Trained batch 313 in epoch 10, gen_loss = 0.45114791905804047, disc_loss = 0.03652838961470421
Trained batch 314 in epoch 10, gen_loss = 0.4510139759570833, disc_loss = 0.0364319083192164
Trained batch 315 in epoch 10, gen_loss = 0.45086537160073653, disc_loss = 0.03637093091766715
Trained batch 316 in epoch 10, gen_loss = 0.4509902263665425, disc_loss = 0.03629078185009515
Trained batch 317 in epoch 10, gen_loss = 0.45083077458090753, disc_loss = 0.036338953127053646
Trained batch 318 in epoch 10, gen_loss = 0.450881169040375, disc_loss = 0.03625445785351261
Trained batch 319 in epoch 10, gen_loss = 0.4509208920411766, disc_loss = 0.03621990747487871
Trained batch 320 in epoch 10, gen_loss = 0.4510892483861276, disc_loss = 0.03613285635774984
Trained batch 321 in epoch 10, gen_loss = 0.45105706849453614, disc_loss = 0.03614294731567226
Trained batch 322 in epoch 10, gen_loss = 0.45114802908233076, disc_loss = 0.036115634363236906
Trained batch 323 in epoch 10, gen_loss = 0.4515828944650697, disc_loss = 0.03605385733061229
Trained batch 324 in epoch 10, gen_loss = 0.451646911914532, disc_loss = 0.03599769266322255
Trained batch 325 in epoch 10, gen_loss = 0.4517180273320777, disc_loss = 0.03598603582940996
Trained batch 326 in epoch 10, gen_loss = 0.4517211647937786, disc_loss = 0.03595316616977801
Trained batch 327 in epoch 10, gen_loss = 0.45189518917624544, disc_loss = 0.03593562904137709
Trained batch 328 in epoch 10, gen_loss = 0.45204422357959223, disc_loss = 0.03585451988695829
Trained batch 329 in epoch 10, gen_loss = 0.45214766011093604, disc_loss = 0.03577318714338947
Trained batch 330 in epoch 10, gen_loss = 0.4522051571719236, disc_loss = 0.03569129278624481
Trained batch 331 in epoch 10, gen_loss = 0.4523947842149849, disc_loss = 0.035595411114978145
Trained batch 332 in epoch 10, gen_loss = 0.4523140516009059, disc_loss = 0.03560133048475863
Trained batch 333 in epoch 10, gen_loss = 0.45237281133314805, disc_loss = 0.03576418367621606
Trained batch 334 in epoch 10, gen_loss = 0.45241235396755275, disc_loss = 0.03570984193860595
Trained batch 335 in epoch 10, gen_loss = 0.4525507041031406, disc_loss = 0.035623060748635214
Trained batch 336 in epoch 10, gen_loss = 0.45289290959474243, disc_loss = 0.0355733845490708
Trained batch 337 in epoch 10, gen_loss = 0.4528732411783828, disc_loss = 0.03548542202792004
Trained batch 338 in epoch 10, gen_loss = 0.45284922645155307, disc_loss = 0.03552219608886536
Trained batch 339 in epoch 10, gen_loss = 0.45281534510500293, disc_loss = 0.03556694991968791
Trained batch 340 in epoch 10, gen_loss = 0.45265853763325825, disc_loss = 0.0355079198635765
Trained batch 341 in epoch 10, gen_loss = 0.4528447864522711, disc_loss = 0.03548217681508881
Trained batch 342 in epoch 10, gen_loss = 0.4529700823149945, disc_loss = 0.03542781559446333
Trained batch 343 in epoch 10, gen_loss = 0.45304489049107527, disc_loss = 0.035342105833521154
Trained batch 344 in epoch 10, gen_loss = 0.4529092600380165, disc_loss = 0.03532487613054505
Trained batch 345 in epoch 10, gen_loss = 0.45277327118236893, disc_loss = 0.03526935020240961
Trained batch 346 in epoch 10, gen_loss = 0.4528665210225053, disc_loss = 0.03526650957618263
Trained batch 347 in epoch 10, gen_loss = 0.4530160604365941, disc_loss = 0.03518653064083051
Trained batch 348 in epoch 10, gen_loss = 0.4530869432028522, disc_loss = 0.03509884758219977
Trained batch 349 in epoch 10, gen_loss = 0.4529969458920615, disc_loss = 0.03504980575692441
Trained batch 350 in epoch 10, gen_loss = 0.4529922492483742, disc_loss = 0.034984865131657945
Trained batch 351 in epoch 10, gen_loss = 0.45315259153192694, disc_loss = 0.034905126187368296
Trained batch 352 in epoch 10, gen_loss = 0.45318229492257744, disc_loss = 0.03484551118496837
Trained batch 353 in epoch 10, gen_loss = 0.45314917667100657, disc_loss = 0.034839049966921665
Trained batch 354 in epoch 10, gen_loss = 0.4529918256779792, disc_loss = 0.03479123485576309
Trained batch 355 in epoch 10, gen_loss = 0.4527969430671649, disc_loss = 0.034740737829032996
Trained batch 356 in epoch 10, gen_loss = 0.4526173813837249, disc_loss = 0.034653978002275904
Trained batch 357 in epoch 10, gen_loss = 0.45255170695941543, disc_loss = 0.03461129873127328
Trained batch 358 in epoch 10, gen_loss = 0.4525806925422966, disc_loss = 0.034532340360198345
Trained batch 359 in epoch 10, gen_loss = 0.45247849085264735, disc_loss = 0.034580798082364105
Trained batch 360 in epoch 10, gen_loss = 0.45259991164352753, disc_loss = 0.03500426158959103
Trained batch 361 in epoch 10, gen_loss = 0.45240778027318457, disc_loss = 0.03520872498198685
Trained batch 362 in epoch 10, gen_loss = 0.4525558978072868, disc_loss = 0.03521610212258317
Trained batch 363 in epoch 10, gen_loss = 0.4524995201564097, disc_loss = 0.03526181376354953
Trained batch 364 in epoch 10, gen_loss = 0.4526526402120721, disc_loss = 0.03521060487127876
Trained batch 365 in epoch 10, gen_loss = 0.4525402706177508, disc_loss = 0.03513597754273014
Trained batch 366 in epoch 10, gen_loss = 0.4525231212296343, disc_loss = 0.0350789325590923
Trained batch 367 in epoch 10, gen_loss = 0.45248130968083505, disc_loss = 0.03500518187850147
Trained batch 368 in epoch 10, gen_loss = 0.45240668609213375, disc_loss = 0.03495221405080583
Trained batch 369 in epoch 10, gen_loss = 0.4523712876680735, disc_loss = 0.03497413900001226
Trained batch 370 in epoch 10, gen_loss = 0.4525812216846127, disc_loss = 0.034945014690995375
Trained batch 371 in epoch 10, gen_loss = 0.45245856839802956, disc_loss = 0.034907759885774346
Trained batch 372 in epoch 10, gen_loss = 0.4524713816975141, disc_loss = 0.034861377680089935
Trained batch 373 in epoch 10, gen_loss = 0.4526155133617116, disc_loss = 0.035034834071097365
Trained batch 374 in epoch 10, gen_loss = 0.45272152026494344, disc_loss = 0.03504133115957181
Trained batch 375 in epoch 10, gen_loss = 0.45269278650905226, disc_loss = 0.0349609268844088
Trained batch 376 in epoch 10, gen_loss = 0.45278645628959496, disc_loss = 0.03488269672217712
Trained batch 377 in epoch 10, gen_loss = 0.4529100318276693, disc_loss = 0.034847770868086075
Trained batch 378 in epoch 10, gen_loss = 0.45267807776821006, disc_loss = 0.03488270384640406
Trained batch 379 in epoch 10, gen_loss = 0.4526491581609375, disc_loss = 0.034839071123860775
Trained batch 380 in epoch 10, gen_loss = 0.4525061724536375, disc_loss = 0.03487130356805883
Trained batch 381 in epoch 10, gen_loss = 0.45232317249500315, disc_loss = 0.03486511868629507
Trained batch 382 in epoch 10, gen_loss = 0.4526285515908473, disc_loss = 0.03498598560326132
Trained batch 383 in epoch 10, gen_loss = 0.4527089206967503, disc_loss = 0.034908725749119185
Trained batch 384 in epoch 10, gen_loss = 0.4527781453999606, disc_loss = 0.03484951803678429
Trained batch 385 in epoch 10, gen_loss = 0.4528020918369293, disc_loss = 0.03483782223440282
Trained batch 386 in epoch 10, gen_loss = 0.4529045876452473, disc_loss = 0.03477699768269863
Trained batch 387 in epoch 10, gen_loss = 0.4529479255842179, disc_loss = 0.034698173468548456
Trained batch 388 in epoch 10, gen_loss = 0.45282506467750566, disc_loss = 0.03464944598655238
Trained batch 389 in epoch 10, gen_loss = 0.45271959090844177, disc_loss = 0.03457112579176632
Trained batch 390 in epoch 10, gen_loss = 0.4525786196179402, disc_loss = 0.034655566328464796
Trained batch 391 in epoch 10, gen_loss = 0.45268527692069815, disc_loss = 0.03469615862395956
Trained batch 392 in epoch 10, gen_loss = 0.4526727621185264, disc_loss = 0.034637786475254305
Trained batch 393 in epoch 10, gen_loss = 0.452762892327938, disc_loss = 0.03456621635397943
Trained batch 394 in epoch 10, gen_loss = 0.45284119014498553, disc_loss = 0.034528134017003866
Trained batch 395 in epoch 10, gen_loss = 0.452768294723949, disc_loss = 0.03499212050975084
Trained batch 396 in epoch 10, gen_loss = 0.4528426035525517, disc_loss = 0.034937305360685296
Trained batch 397 in epoch 10, gen_loss = 0.45279416793854393, disc_loss = 0.03497236108655419
Trained batch 398 in epoch 10, gen_loss = 0.45256291236495017, disc_loss = 0.0350188908241876
Trained batch 399 in epoch 10, gen_loss = 0.45236377701163294, disc_loss = 0.03499448619666509
Trained batch 400 in epoch 10, gen_loss = 0.45216117587470056, disc_loss = 0.03496868776371168
Trained batch 401 in epoch 10, gen_loss = 0.4518779252299029, disc_loss = 0.03491904006793687
Trained batch 402 in epoch 10, gen_loss = 0.45183159444231547, disc_loss = 0.03484717839820398
Trained batch 403 in epoch 10, gen_loss = 0.45173502344601224, disc_loss = 0.03477140910356388
Trained batch 404 in epoch 10, gen_loss = 0.45179242079640614, disc_loss = 0.034705860375852125
Trained batch 405 in epoch 10, gen_loss = 0.4517190123132884, disc_loss = 0.03463262066662569
Trained batch 406 in epoch 10, gen_loss = 0.4518172284016152, disc_loss = 0.03456260231312099
Trained batch 407 in epoch 10, gen_loss = 0.4517490308658749, disc_loss = 0.03448911457477758
Trained batch 408 in epoch 10, gen_loss = 0.4516662827768069, disc_loss = 0.034430963296925965
Trained batch 409 in epoch 10, gen_loss = 0.45155186231543376, disc_loss = 0.0343793985252155
Trained batch 410 in epoch 10, gen_loss = 0.4514807606265493, disc_loss = 0.03430422994709254
Trained batch 411 in epoch 10, gen_loss = 0.4514440411647547, disc_loss = 0.03425085372901838
Trained batch 412 in epoch 10, gen_loss = 0.4513898794933901, disc_loss = 0.03418240211588346
Trained batch 413 in epoch 10, gen_loss = 0.4513798875797198, disc_loss = 0.034127420415103006
Trained batch 414 in epoch 10, gen_loss = 0.4513875055025859, disc_loss = 0.03407000292945339
Trained batch 415 in epoch 10, gen_loss = 0.4515054003837017, disc_loss = 0.0340115272690757
Trained batch 416 in epoch 10, gen_loss = 0.4513828878780063, disc_loss = 0.03395615531493434
Trained batch 417 in epoch 10, gen_loss = 0.45143589648333465, disc_loss = 0.03388753669385455
Trained batch 418 in epoch 10, gen_loss = 0.45143285848929376, disc_loss = 0.03381978686529974
Trained batch 419 in epoch 10, gen_loss = 0.45142342944939934, disc_loss = 0.03376259340660735
Trained batch 420 in epoch 10, gen_loss = 0.4514124503894543, disc_loss = 0.033723913879750954
Trained batch 421 in epoch 10, gen_loss = 0.4513714454044098, disc_loss = 0.03372527872900792
Trained batch 422 in epoch 10, gen_loss = 0.4513369072977251, disc_loss = 0.03365494788956804
Trained batch 423 in epoch 10, gen_loss = 0.4512454514514725, disc_loss = 0.033623136780971556
Trained batch 424 in epoch 10, gen_loss = 0.4512476339059718, disc_loss = 0.03356364621726029
Trained batch 425 in epoch 10, gen_loss = 0.45110186836529226, disc_loss = 0.033505666234744755
Trained batch 426 in epoch 10, gen_loss = 0.45112419219151034, disc_loss = 0.03346406769081601
Trained batch 427 in epoch 10, gen_loss = 0.4512439043583157, disc_loss = 0.03340058293733224
Trained batch 428 in epoch 10, gen_loss = 0.4512237405582464, disc_loss = 0.03333923857363857
Trained batch 429 in epoch 10, gen_loss = 0.4513314367726792, disc_loss = 0.03328636376360475
Trained batch 430 in epoch 10, gen_loss = 0.4513335324080527, disc_loss = 0.033225840646903225
Trained batch 431 in epoch 10, gen_loss = 0.4513799386029994, disc_loss = 0.03316007529523362
Trained batch 432 in epoch 10, gen_loss = 0.4513592618855263, disc_loss = 0.03317892853402926
Trained batch 433 in epoch 10, gen_loss = 0.45127736402821433, disc_loss = 0.03317389538520218
Trained batch 434 in epoch 10, gen_loss = 0.45115147061731625, disc_loss = 0.03319131573555113
Trained batch 435 in epoch 10, gen_loss = 0.45104411346923323, disc_loss = 0.03313468493427227
Trained batch 436 in epoch 10, gen_loss = 0.45107363454264415, disc_loss = 0.03307152847446143
Trained batch 437 in epoch 10, gen_loss = 0.4511420664177638, disc_loss = 0.03306104545800449
Trained batch 438 in epoch 10, gen_loss = 0.4513226607665929, disc_loss = 0.033065336637606246
Trained batch 439 in epoch 10, gen_loss = 0.4515439109368758, disc_loss = 0.03325092592064969
Trained batch 440 in epoch 10, gen_loss = 0.4518617118567296, disc_loss = 0.03331515196575667
Trained batch 441 in epoch 10, gen_loss = 0.4518283725593964, disc_loss = 0.033860303800789075
Trained batch 442 in epoch 10, gen_loss = 0.45175968194653704, disc_loss = 0.033924952151493486
Trained batch 443 in epoch 10, gen_loss = 0.4517659854378786, disc_loss = 0.03403618183565905
Trained batch 444 in epoch 10, gen_loss = 0.451718673009551, disc_loss = 0.03418421360423391
Trained batch 445 in epoch 10, gen_loss = 0.45159605232322164, disc_loss = 0.03434505856767163
Trained batch 446 in epoch 10, gen_loss = 0.45166759536303663, disc_loss = 0.03443731819498259
Trained batch 447 in epoch 10, gen_loss = 0.45151447917201687, disc_loss = 0.034412604979089725
Trained batch 448 in epoch 10, gen_loss = 0.4515733689667122, disc_loss = 0.034397658062289845
Trained batch 449 in epoch 10, gen_loss = 0.45131134695476954, disc_loss = 0.03467361482688122
Trained batch 450 in epoch 10, gen_loss = 0.45129581988518624, disc_loss = 0.03522763323005776
Trained batch 451 in epoch 10, gen_loss = 0.4512212033820363, disc_loss = 0.03520435316743643
Trained batch 452 in epoch 10, gen_loss = 0.4512014099567405, disc_loss = 0.035216563068757915
Trained batch 453 in epoch 10, gen_loss = 0.4511022651773192, disc_loss = 0.035393268044315904
Trained batch 454 in epoch 10, gen_loss = 0.45098322767477766, disc_loss = 0.035350223366621435
Trained batch 455 in epoch 10, gen_loss = 0.4508561497194725, disc_loss = 0.03535075826987036
Trained batch 456 in epoch 10, gen_loss = 0.45088220196949313, disc_loss = 0.03529661667637152
Trained batch 457 in epoch 10, gen_loss = 0.45070954500067184, disc_loss = 0.035253808683182994
Trained batch 458 in epoch 10, gen_loss = 0.4505697163491467, disc_loss = 0.03521331994589377
Trained batch 459 in epoch 10, gen_loss = 0.4505973614428354, disc_loss = 0.03524452563699173
Trained batch 460 in epoch 10, gen_loss = 0.45065657319319224, disc_loss = 0.035248552277328656
Trained batch 461 in epoch 10, gen_loss = 0.4506099226670864, disc_loss = 0.0352209849057324
Trained batch 462 in epoch 10, gen_loss = 0.45074538046546425, disc_loss = 0.035218687575173685
Trained batch 463 in epoch 10, gen_loss = 0.4506206374358514, disc_loss = 0.0353010339092399
Trained batch 464 in epoch 10, gen_loss = 0.45052956028651164, disc_loss = 0.035365435020417293
Trained batch 465 in epoch 10, gen_loss = 0.45027577582858663, disc_loss = 0.03572308744179972
Trained batch 466 in epoch 10, gen_loss = 0.4503979620382158, disc_loss = 0.0357944637704521
Trained batch 467 in epoch 10, gen_loss = 0.4505980829907279, disc_loss = 0.03574235879609154
Trained batch 468 in epoch 10, gen_loss = 0.45078829153260186, disc_loss = 0.035702683176519645
Trained batch 469 in epoch 10, gen_loss = 0.45071315112266136, disc_loss = 0.03565433061424088
Trained batch 470 in epoch 10, gen_loss = 0.4506300765617638, disc_loss = 0.035596720779397684
Trained batch 471 in epoch 10, gen_loss = 0.4506054352653229, disc_loss = 0.03553060290277383
Trained batch 472 in epoch 10, gen_loss = 0.45063111809797063, disc_loss = 0.035480973395434295
Trained batch 473 in epoch 10, gen_loss = 0.45058403550824033, disc_loss = 0.03541584948926598
Trained batch 474 in epoch 10, gen_loss = 0.450594260316146, disc_loss = 0.03535589536259833
Trained batch 475 in epoch 10, gen_loss = 0.4504858746248133, disc_loss = 0.035290237585622664
Trained batch 476 in epoch 10, gen_loss = 0.4504708167891832, disc_loss = 0.03529996353746304
Trained batch 477 in epoch 10, gen_loss = 0.45026243038506686, disc_loss = 0.03525651023707598
Trained batch 478 in epoch 10, gen_loss = 0.4502946662255767, disc_loss = 0.03520452882414042
Trained batch 479 in epoch 10, gen_loss = 0.45029093250632285, disc_loss = 0.03527399127196986
Trained batch 480 in epoch 10, gen_loss = 0.4503564487004231, disc_loss = 0.03522273721250854
Trained batch 481 in epoch 10, gen_loss = 0.4501861589207194, disc_loss = 0.03517950070477033
Trained batch 482 in epoch 10, gen_loss = 0.450014477067359, disc_loss = 0.03517541547805287
Trained batch 483 in epoch 10, gen_loss = 0.4498756902276977, disc_loss = 0.035196114894318245
Trained batch 484 in epoch 10, gen_loss = 0.450002845415135, disc_loss = 0.035146605877263336
Trained batch 485 in epoch 10, gen_loss = 0.45003162391882373, disc_loss = 0.03510688508308872
Trained batch 486 in epoch 10, gen_loss = 0.4503400972002096, disc_loss = 0.035379422083688286
Trained batch 487 in epoch 10, gen_loss = 0.4504530107388731, disc_loss = 0.03532821485165843
Trained batch 488 in epoch 10, gen_loss = 0.45028450274516224, disc_loss = 0.035650114051746264
Trained batch 489 in epoch 10, gen_loss = 0.4501433857849666, disc_loss = 0.035626531689788916
Trained batch 490 in epoch 10, gen_loss = 0.4503065017478772, disc_loss = 0.03595430060344807
Trained batch 491 in epoch 10, gen_loss = 0.4503476202972536, disc_loss = 0.035932631531874155
Trained batch 492 in epoch 10, gen_loss = 0.4503822124753956, disc_loss = 0.03601323269613646
Trained batch 493 in epoch 10, gen_loss = 0.45017475770552634, disc_loss = 0.03604920380107817
Trained batch 494 in epoch 10, gen_loss = 0.45019737644629043, disc_loss = 0.03605346778746356
Trained batch 495 in epoch 10, gen_loss = 0.45005674347762137, disc_loss = 0.036154252714515035
Trained batch 496 in epoch 10, gen_loss = 0.44988045312269354, disc_loss = 0.03655139091227886
Trained batch 497 in epoch 10, gen_loss = 0.4498202036542586, disc_loss = 0.03652285599434023
Trained batch 498 in epoch 10, gen_loss = 0.449849652622888, disc_loss = 0.03664412608235806
Trained batch 499 in epoch 10, gen_loss = 0.4499658892154694, disc_loss = 0.03661905969399959
Trained batch 500 in epoch 10, gen_loss = 0.4499677212652332, disc_loss = 0.03665195268387358
Trained batch 501 in epoch 10, gen_loss = 0.4500253813200263, disc_loss = 0.036721772329688845
Trained batch 502 in epoch 10, gen_loss = 0.4500177320144759, disc_loss = 0.03670897979611461
Trained batch 503 in epoch 10, gen_loss = 0.4499304239593801, disc_loss = 0.03666213672101823
Trained batch 504 in epoch 10, gen_loss = 0.4498274542907677, disc_loss = 0.036695018409760576
Trained batch 505 in epoch 10, gen_loss = 0.44975253768824774, disc_loss = 0.03665117579217809
Trained batch 506 in epoch 10, gen_loss = 0.4498256487841672, disc_loss = 0.03692211047516625
Trained batch 507 in epoch 10, gen_loss = 0.44983406030521617, disc_loss = 0.03692342717783511
Trained batch 508 in epoch 10, gen_loss = 0.4496606794462223, disc_loss = 0.03704097426326283
Trained batch 509 in epoch 10, gen_loss = 0.449729147495008, disc_loss = 0.037002756431077914
Trained batch 510 in epoch 10, gen_loss = 0.44982725976731214, disc_loss = 0.03706546272050932
Trained batch 511 in epoch 10, gen_loss = 0.44989480497315526, disc_loss = 0.03703113560095517
Trained batch 512 in epoch 10, gen_loss = 0.44982487096888746, disc_loss = 0.03699473125250106
Trained batch 513 in epoch 10, gen_loss = 0.4496933326183126, disc_loss = 0.03701979463198857
Trained batch 514 in epoch 10, gen_loss = 0.44966251832767595, disc_loss = 0.0369586749128925
Trained batch 515 in epoch 10, gen_loss = 0.4496760991539142, disc_loss = 0.03692039211331181
Trained batch 516 in epoch 10, gen_loss = 0.44977368797739425, disc_loss = 0.036868106563011725
Trained batch 517 in epoch 10, gen_loss = 0.4499682578686121, disc_loss = 0.03682127339463379
Trained batch 518 in epoch 10, gen_loss = 0.4498464172286105, disc_loss = 0.03677393592039916
Trained batch 519 in epoch 10, gen_loss = 0.4499242447889768, disc_loss = 0.03676618778755745
Trained batch 520 in epoch 10, gen_loss = 0.4496708872107764, disc_loss = 0.03674639214988576
Trained batch 521 in epoch 10, gen_loss = 0.4495358311810256, disc_loss = 0.036793699843088216
Trained batch 522 in epoch 10, gen_loss = 0.4494895733907163, disc_loss = 0.036972741614208056
Trained batch 523 in epoch 10, gen_loss = 0.44941536189263104, disc_loss = 0.036984358599608524
Trained batch 524 in epoch 10, gen_loss = 0.44966523823283966, disc_loss = 0.037109148834078086
Trained batch 525 in epoch 10, gen_loss = 0.4494233214696551, disc_loss = 0.03719851045122108
Trained batch 526 in epoch 10, gen_loss = 0.44934038826365175, disc_loss = 0.03725227308362383
Trained batch 527 in epoch 10, gen_loss = 0.44919137594600517, disc_loss = 0.037254244884631284
Trained batch 528 in epoch 10, gen_loss = 0.4494209394901146, disc_loss = 0.03761816684452426
Trained batch 529 in epoch 10, gen_loss = 0.4493521570034747, disc_loss = 0.037611791194539584
Trained batch 530 in epoch 10, gen_loss = 0.4492334099924946, disc_loss = 0.03795568803377913
Trained batch 531 in epoch 10, gen_loss = 0.4491123235539386, disc_loss = 0.03805657511023819
Trained batch 532 in epoch 10, gen_loss = 0.4491057304235605, disc_loss = 0.03818849606813398
Trained batch 533 in epoch 10, gen_loss = 0.44903052411275857, disc_loss = 0.03820873424934035
Trained batch 534 in epoch 10, gen_loss = 0.448964590391266, disc_loss = 0.03817563455064442
Trained batch 535 in epoch 10, gen_loss = 0.44885397246524467, disc_loss = 0.03814697700531792
Trained batch 536 in epoch 10, gen_loss = 0.4489824123666717, disc_loss = 0.038119826481453865
Trained batch 537 in epoch 10, gen_loss = 0.4490750188278, disc_loss = 0.038073896883976506
Trained batch 538 in epoch 10, gen_loss = 0.4490528646891104, disc_loss = 0.03807320617180809
Trained batch 539 in epoch 10, gen_loss = 0.44894920306073294, disc_loss = 0.03825761864858645
Trained batch 540 in epoch 10, gen_loss = 0.4488324583568326, disc_loss = 0.0382600676288997
Trained batch 541 in epoch 10, gen_loss = 0.4486333105396961, disc_loss = 0.038280588887439446
Trained batch 542 in epoch 10, gen_loss = 0.448605435658555, disc_loss = 0.03825900191183907
Trained batch 543 in epoch 10, gen_loss = 0.44876033615540056, disc_loss = 0.03821505915359868
Trained batch 544 in epoch 10, gen_loss = 0.44883792706585807, disc_loss = 0.03824471182300957
Trained batch 545 in epoch 10, gen_loss = 0.4486557228879614, disc_loss = 0.0386042419595869
Trained batch 546 in epoch 10, gen_loss = 0.44867605690110535, disc_loss = 0.03886797116010346
Trained batch 547 in epoch 10, gen_loss = 0.44861678877016054, disc_loss = 0.0388469702536988
Trained batch 548 in epoch 10, gen_loss = 0.44866633306652687, disc_loss = 0.03894157509212611
Trained batch 549 in epoch 10, gen_loss = 0.44881941134279424, disc_loss = 0.039045144140043044
Trained batch 550 in epoch 10, gen_loss = 0.4488743273186381, disc_loss = 0.03903834703978415
Trained batch 551 in epoch 10, gen_loss = 0.4488212714592616, disc_loss = 0.03899266322116381
Trained batch 552 in epoch 10, gen_loss = 0.4487221378422128, disc_loss = 0.03896481438352984
Trained batch 553 in epoch 10, gen_loss = 0.4486483324736034, disc_loss = 0.038948354990446826
Trained batch 554 in epoch 10, gen_loss = 0.4486135219131504, disc_loss = 0.038898877019213664
Trained batch 555 in epoch 10, gen_loss = 0.44867738888418074, disc_loss = 0.038838794403843475
Trained batch 556 in epoch 10, gen_loss = 0.44878995493455676, disc_loss = 0.038799263770178734
Trained batch 557 in epoch 10, gen_loss = 0.44883664091214487, disc_loss = 0.03874687494553198
Trained batch 558 in epoch 10, gen_loss = 0.4489757660143277, disc_loss = 0.03868624094410505
Trained batch 559 in epoch 10, gen_loss = 0.4490974125585386, disc_loss = 0.03866527307961535
Trained batch 560 in epoch 10, gen_loss = 0.44907005447329895, disc_loss = 0.03860341184797453
Trained batch 561 in epoch 10, gen_loss = 0.44914014207934994, disc_loss = 0.03856845997486038
Trained batch 562 in epoch 10, gen_loss = 0.44909010803720667, disc_loss = 0.03850907045887985
Trained batch 563 in epoch 10, gen_loss = 0.44902444588588486, disc_loss = 0.0384493105481742
Trained batch 564 in epoch 10, gen_loss = 0.4490497195087703, disc_loss = 0.0384235490303058
Trained batch 565 in epoch 10, gen_loss = 0.4489642731292509, disc_loss = 0.038368645240141365
Trained batch 566 in epoch 10, gen_loss = 0.4490904480061203, disc_loss = 0.03887762506517074
Trained batch 567 in epoch 10, gen_loss = 0.4490061136828342, disc_loss = 0.03884021810036231
Trained batch 568 in epoch 10, gen_loss = 0.4489017298644792, disc_loss = 0.03888556441809386
Trained batch 569 in epoch 10, gen_loss = 0.4489539415167089, disc_loss = 0.038932520851264134
Trained batch 570 in epoch 10, gen_loss = 0.44907155345910066, disc_loss = 0.03891382433699147
Trained batch 571 in epoch 10, gen_loss = 0.449137655171481, disc_loss = 0.03888643214599575
Trained batch 572 in epoch 10, gen_loss = 0.4492330756070934, disc_loss = 0.03884849137663971
Trained batch 573 in epoch 10, gen_loss = 0.4492274289658676, disc_loss = 0.0388087470170422
Trained batch 574 in epoch 10, gen_loss = 0.44917014495186186, disc_loss = 0.03878263305791694
Trained batch 575 in epoch 10, gen_loss = 0.4490730793525775, disc_loss = 0.03876040844301719
Trained batch 576 in epoch 10, gen_loss = 0.4490575992875124, disc_loss = 0.03871156454677056
Trained batch 577 in epoch 10, gen_loss = 0.4491027351275447, disc_loss = 0.03867309785989406
Trained batch 578 in epoch 10, gen_loss = 0.4490374910913807, disc_loss = 0.03861304814726217
Trained batch 579 in epoch 10, gen_loss = 0.4489381768066308, disc_loss = 0.03860496352747853
Trained batch 580 in epoch 10, gen_loss = 0.4489716464291341, disc_loss = 0.0385483821594315
Trained batch 581 in epoch 10, gen_loss = 0.4490551385273229, disc_loss = 0.03860652504034366
Trained batch 582 in epoch 10, gen_loss = 0.44902253498548506, disc_loss = 0.03860804875338159
Trained batch 583 in epoch 10, gen_loss = 0.4490585822152765, disc_loss = 0.03855037324254924
Trained batch 584 in epoch 10, gen_loss = 0.44908922329927103, disc_loss = 0.03850984832462974
Trained batch 585 in epoch 10, gen_loss = 0.4491365387679774, disc_loss = 0.038460208884195615
Trained batch 586 in epoch 10, gen_loss = 0.44908728251262253, disc_loss = 0.03846560996676299
Trained batch 587 in epoch 10, gen_loss = 0.4490110217815354, disc_loss = 0.038411648364319484
Trained batch 588 in epoch 10, gen_loss = 0.4490281382926656, disc_loss = 0.038423278908196246
Trained batch 589 in epoch 10, gen_loss = 0.44908385711201165, disc_loss = 0.03842163358388816
Trained batch 590 in epoch 10, gen_loss = 0.44905264229338787, disc_loss = 0.03840205958664619
Trained batch 591 in epoch 10, gen_loss = 0.4490349465427366, disc_loss = 0.03851826757356223
Trained batch 592 in epoch 10, gen_loss = 0.44896349597339086, disc_loss = 0.03878189346000779
Trained batch 593 in epoch 10, gen_loss = 0.4488723224361336, disc_loss = 0.03877891581630968
Trained batch 594 in epoch 10, gen_loss = 0.44883485331254847, disc_loss = 0.03876351328144054
Trained batch 595 in epoch 10, gen_loss = 0.44882207438849764, disc_loss = 0.038775310210958626
Trained batch 596 in epoch 10, gen_loss = 0.44870948212430306, disc_loss = 0.03872524455214665
Trained batch 597 in epoch 10, gen_loss = 0.4486370766441958, disc_loss = 0.03872829276358204
Trained batch 598 in epoch 10, gen_loss = 0.4487260564141759, disc_loss = 0.03874780521269434
Trained batch 599 in epoch 10, gen_loss = 0.4487459522982438, disc_loss = 0.03869105280842632
Trained batch 600 in epoch 10, gen_loss = 0.4488163180835235, disc_loss = 0.03863544733389072
Trained batch 601 in epoch 10, gen_loss = 0.44867465018830033, disc_loss = 0.038617079153168095
Trained batch 602 in epoch 10, gen_loss = 0.4487586019446403, disc_loss = 0.03856296045705676
Trained batch 603 in epoch 10, gen_loss = 0.4487522360406175, disc_loss = 0.03850787345378579
Trained batch 604 in epoch 10, gen_loss = 0.4488490091375083, disc_loss = 0.03845230793996044
Trained batch 605 in epoch 10, gen_loss = 0.44882591172020037, disc_loss = 0.038448505858174546
Trained batch 606 in epoch 10, gen_loss = 0.4490130687074174, disc_loss = 0.03839171022833425
Trained batch 607 in epoch 10, gen_loss = 0.4489281939734754, disc_loss = 0.0383359288619096
Trained batch 608 in epoch 10, gen_loss = 0.4488897379885362, disc_loss = 0.0382863363948435
Trained batch 609 in epoch 10, gen_loss = 0.44895894151242055, disc_loss = 0.038249415261518274
Trained batch 610 in epoch 10, gen_loss = 0.4490793448325655, disc_loss = 0.03819796334153404
Trained batch 611 in epoch 10, gen_loss = 0.44916653978863574, disc_loss = 0.03815447615788264
Trained batch 612 in epoch 10, gen_loss = 0.449355020754489, disc_loss = 0.038098316075626706
Trained batch 613 in epoch 10, gen_loss = 0.4492848608218109, disc_loss = 0.0380585295013956
Trained batch 614 in epoch 10, gen_loss = 0.4493222715893412, disc_loss = 0.038063028642180856
Trained batch 615 in epoch 10, gen_loss = 0.4492321404834072, disc_loss = 0.03801884378159914
Trained batch 616 in epoch 10, gen_loss = 0.4491460720859045, disc_loss = 0.03797770155528847
Trained batch 617 in epoch 10, gen_loss = 0.44915557664767825, disc_loss = 0.03792029148770924
Trained batch 618 in epoch 10, gen_loss = 0.4492142970804637, disc_loss = 0.03788970627818973
Trained batch 619 in epoch 10, gen_loss = 0.4491970113208217, disc_loss = 0.03783736520694689
Trained batch 620 in epoch 10, gen_loss = 0.4492137180146388, disc_loss = 0.037779966496746996
Trained batch 621 in epoch 10, gen_loss = 0.4493209991328586, disc_loss = 0.037722825610986235
Trained batch 622 in epoch 10, gen_loss = 0.4493441585553018, disc_loss = 0.03766614936268253
Trained batch 623 in epoch 10, gen_loss = 0.44930570028149164, disc_loss = 0.037609237366361924
Trained batch 624 in epoch 10, gen_loss = 0.4492075971126556, disc_loss = 0.03756784243658185
Trained batch 625 in epoch 10, gen_loss = 0.4491761647664701, disc_loss = 0.03751625082181832
Trained batch 626 in epoch 10, gen_loss = 0.4492114972935149, disc_loss = 0.03746120248248346
Trained batch 627 in epoch 10, gen_loss = 0.4491550685588721, disc_loss = 0.0374045970248708
Trained batch 628 in epoch 10, gen_loss = 0.44923413581613136, disc_loss = 0.03734820558847223
Trained batch 629 in epoch 10, gen_loss = 0.44917700952953765, disc_loss = 0.03729188976946124
Trained batch 630 in epoch 10, gen_loss = 0.44920296397904397, disc_loss = 0.037235360607547646
Trained batch 631 in epoch 10, gen_loss = 0.4491362567472307, disc_loss = 0.03718750566834307
Trained batch 632 in epoch 10, gen_loss = 0.4491822174845902, disc_loss = 0.03714074450085237
Trained batch 633 in epoch 10, gen_loss = 0.44918898899660503, disc_loss = 0.037095609301156206
Trained batch 634 in epoch 10, gen_loss = 0.44919997871391415, disc_loss = 0.03705221476256994
Trained batch 635 in epoch 10, gen_loss = 0.44927501355139715, disc_loss = 0.03700588357363207
Trained batch 636 in epoch 10, gen_loss = 0.4492732843199929, disc_loss = 0.036950734007907694
Trained batch 637 in epoch 10, gen_loss = 0.4493242079467983, disc_loss = 0.036899921232849055
Trained batch 638 in epoch 10, gen_loss = 0.44937166986704247, disc_loss = 0.03685011562136336
Trained batch 639 in epoch 10, gen_loss = 0.4494233600329608, disc_loss = 0.03679788308036223
Trained batch 640 in epoch 10, gen_loss = 0.44952283973998847, disc_loss = 0.036757226023233135
Trained batch 641 in epoch 10, gen_loss = 0.44961352618498224, disc_loss = 0.036704501784493644
Trained batch 642 in epoch 10, gen_loss = 0.44960947109974375, disc_loss = 0.03665407479256913
Trained batch 643 in epoch 10, gen_loss = 0.4496820242786259, disc_loss = 0.03659936766952178
Trained batch 644 in epoch 10, gen_loss = 0.4496500742527866, disc_loss = 0.03654512225942643
Trained batch 645 in epoch 10, gen_loss = 0.44964897268143234, disc_loss = 0.036490729209122136
Trained batch 646 in epoch 10, gen_loss = 0.4496682435965059, disc_loss = 0.03643824467097209
Trained batch 647 in epoch 10, gen_loss = 0.4496651551237813, disc_loss = 0.03638649666372882
Trained batch 648 in epoch 10, gen_loss = 0.4496062344230011, disc_loss = 0.03633850469908322
Trained batch 649 in epoch 10, gen_loss = 0.4495236723239605, disc_loss = 0.03628858862050737
Trained batch 650 in epoch 10, gen_loss = 0.44949176124713386, disc_loss = 0.036237829152034016
Trained batch 651 in epoch 10, gen_loss = 0.44940226602773725, disc_loss = 0.03618492740559952
Trained batch 652 in epoch 10, gen_loss = 0.44937589527271793, disc_loss = 0.03613149533105321
Trained batch 653 in epoch 10, gen_loss = 0.4493230859711994, disc_loss = 0.03608328527457647
Trained batch 654 in epoch 10, gen_loss = 0.44928419981294004, disc_loss = 0.036031730909554555
Trained batch 655 in epoch 10, gen_loss = 0.4493919774526503, disc_loss = 0.03597910881110626
Trained batch 656 in epoch 10, gen_loss = 0.4492833815753188, disc_loss = 0.03592665968257282
Trained batch 657 in epoch 10, gen_loss = 0.44926644879815064, disc_loss = 0.03587377010766802
Trained batch 658 in epoch 10, gen_loss = 0.4491804032749037, disc_loss = 0.035821501458874916
Trained batch 659 in epoch 10, gen_loss = 0.4491383349353617, disc_loss = 0.03577133744926841
Trained batch 660 in epoch 10, gen_loss = 0.449132194226881, disc_loss = 0.035721391284100026
Trained batch 661 in epoch 10, gen_loss = 0.4491421126076822, disc_loss = 0.03567488602780402
Trained batch 662 in epoch 10, gen_loss = 0.4489333984269276, disc_loss = 0.035649712764634155
Trained batch 663 in epoch 10, gen_loss = 0.44885221985449275, disc_loss = 0.03560406098342837
Trained batch 664 in epoch 10, gen_loss = 0.4487853106699492, disc_loss = 0.03556107929067448
Trained batch 665 in epoch 10, gen_loss = 0.4487727751602998, disc_loss = 0.03551015946084169
Trained batch 666 in epoch 10, gen_loss = 0.448826951065521, disc_loss = 0.035460044571576914
Trained batch 667 in epoch 10, gen_loss = 0.4487440610627928, disc_loss = 0.0354108220213065
Trained batch 668 in epoch 10, gen_loss = 0.4487040829587232, disc_loss = 0.03536012975125948
Trained batch 669 in epoch 10, gen_loss = 0.4488718045291616, disc_loss = 0.035312878104872
Trained batch 670 in epoch 10, gen_loss = 0.44887262431768654, disc_loss = 0.035262789366448964
Trained batch 671 in epoch 10, gen_loss = 0.44871628044971396, disc_loss = 0.03521773531437724
Trained batch 672 in epoch 10, gen_loss = 0.4486471761300341, disc_loss = 0.03516878215246661
Trained batch 673 in epoch 10, gen_loss = 0.44850283454363, disc_loss = 0.035122563413555734
Trained batch 674 in epoch 10, gen_loss = 0.44844504219514353, disc_loss = 0.035073660082114794
Trained batch 675 in epoch 10, gen_loss = 0.4482970820111636, disc_loss = 0.035024161232544454
Trained batch 676 in epoch 10, gen_loss = 0.4482546627873684, disc_loss = 0.03497515903975666
Trained batch 677 in epoch 10, gen_loss = 0.44821220917687654, disc_loss = 0.03492822192759036
Trained batch 678 in epoch 10, gen_loss = 0.4482045530921756, disc_loss = 0.03487885650178755
Trained batch 679 in epoch 10, gen_loss = 0.44830248715246424, disc_loss = 0.0348800586488591
Trained batch 680 in epoch 10, gen_loss = 0.44823688745673707, disc_loss = 0.034842592957409074
Trained batch 681 in epoch 10, gen_loss = 0.4482388967904877, disc_loss = 0.03479499631299148
Trained batch 682 in epoch 10, gen_loss = 0.4483200351368107, disc_loss = 0.03474854598282721
Trained batch 683 in epoch 10, gen_loss = 0.44831057951638575, disc_loss = 0.03473292262026528
Trained batch 684 in epoch 10, gen_loss = 0.4482979969821707, disc_loss = 0.03469801715228462
Trained batch 685 in epoch 10, gen_loss = 0.4483056968572188, disc_loss = 0.034660788160632026
Trained batch 686 in epoch 10, gen_loss = 0.4482251514166897, disc_loss = 0.034613874986607805
Trained batch 687 in epoch 10, gen_loss = 0.4482714660292448, disc_loss = 0.03456639321784889
Trained batch 688 in epoch 10, gen_loss = 0.4482352369409514, disc_loss = 0.03452081785737354
Trained batch 689 in epoch 10, gen_loss = 0.4481586322836254, disc_loss = 0.03447393618281121
Trained batch 690 in epoch 10, gen_loss = 0.4482209153268513, disc_loss = 0.03443170239200058
Trained batch 691 in epoch 10, gen_loss = 0.44827775786377794, disc_loss = 0.03438868348397896
Trained batch 692 in epoch 10, gen_loss = 0.4483944769373532, disc_loss = 0.034343431332829966
Trained batch 693 in epoch 10, gen_loss = 0.44821118685800676, disc_loss = 0.03429781048496922
Trained batch 694 in epoch 10, gen_loss = 0.44823788378736096, disc_loss = 0.03425315060056478
Trained batch 695 in epoch 10, gen_loss = 0.44834996931169224, disc_loss = 0.03430913049452028
Trained batch 696 in epoch 10, gen_loss = 0.4482564980022534, disc_loss = 0.03430405138942334
Trained batch 697 in epoch 10, gen_loss = 0.44821292247335004, disc_loss = 0.034268469294202235
Trained batch 698 in epoch 10, gen_loss = 0.448154257986167, disc_loss = 0.03422548963977437
Trained batch 699 in epoch 10, gen_loss = 0.44813938017402377, disc_loss = 0.03418543440555888
Trained batch 700 in epoch 10, gen_loss = 0.44816773220067696, disc_loss = 0.03417161370783024
Trained batch 701 in epoch 10, gen_loss = 0.4481504570130269, disc_loss = 0.03413524443384504
Trained batch 702 in epoch 10, gen_loss = 0.44818898060413376, disc_loss = 0.03409470576305435
Trained batch 703 in epoch 10, gen_loss = 0.4483432406136258, disc_loss = 0.034060485115994445
Trained batch 704 in epoch 10, gen_loss = 0.4484247326428163, disc_loss = 0.03405072864488507
Trained batch 705 in epoch 10, gen_loss = 0.4485048635232212, disc_loss = 0.03401070876012717
Trained batch 706 in epoch 10, gen_loss = 0.44847325034323643, disc_loss = 0.03400731522555672
Trained batch 707 in epoch 10, gen_loss = 0.44849516485033736, disc_loss = 0.034003479696289335
Trained batch 708 in epoch 10, gen_loss = 0.44856696412997116, disc_loss = 0.03397564768951455
Trained batch 709 in epoch 10, gen_loss = 0.44849332575227174, disc_loss = 0.0339692860087511
Trained batch 710 in epoch 10, gen_loss = 0.4486785665594576, disc_loss = 0.03407465379210988
Trained batch 711 in epoch 10, gen_loss = 0.4487681341556351, disc_loss = 0.034038301984376663
Trained batch 712 in epoch 10, gen_loss = 0.448591436861608, disc_loss = 0.034086302161180165
Trained batch 713 in epoch 10, gen_loss = 0.44845539310566185, disc_loss = 0.03407177556872222
Trained batch 714 in epoch 10, gen_loss = 0.44857542285552393, disc_loss = 0.03407953024965587
Trained batch 715 in epoch 10, gen_loss = 0.44853498670142455, disc_loss = 0.03404129288281579
Trained batch 716 in epoch 10, gen_loss = 0.4485355041599008, disc_loss = 0.03403180128228402
Trained batch 717 in epoch 10, gen_loss = 0.4486372415650854, disc_loss = 0.034023955081068084
Trained batch 718 in epoch 10, gen_loss = 0.4487401982756417, disc_loss = 0.03408424902424963
Trained batch 719 in epoch 10, gen_loss = 0.44877971497674785, disc_loss = 0.03406166723321399
Trained batch 720 in epoch 10, gen_loss = 0.44866258298639783, disc_loss = 0.03414643934415072
Trained batch 721 in epoch 10, gen_loss = 0.44877828063231756, disc_loss = 0.03418987268424616
Trained batch 722 in epoch 10, gen_loss = 0.4489324636561577, disc_loss = 0.03418369886283743
Trained batch 723 in epoch 10, gen_loss = 0.44897301696776026, disc_loss = 0.03415583694695871
Trained batch 724 in epoch 10, gen_loss = 0.44895163712830377, disc_loss = 0.03416771131407084
Trained batch 725 in epoch 10, gen_loss = 0.44896673889363764, disc_loss = 0.034182535890443635
Trained batch 726 in epoch 10, gen_loss = 0.4489489052613795, disc_loss = 0.03439641295082898
Trained batch 727 in epoch 10, gen_loss = 0.4490730040348493, disc_loss = 0.034398024784692734
Trained batch 728 in epoch 10, gen_loss = 0.4489723183981185, disc_loss = 0.03465049396574354
Trained batch 729 in epoch 10, gen_loss = 0.4489795692979473, disc_loss = 0.034615310584513906
Trained batch 730 in epoch 10, gen_loss = 0.4490858241406087, disc_loss = 0.03464815254156285
Trained batch 731 in epoch 10, gen_loss = 0.44900015244881314, disc_loss = 0.034778488476129625
Trained batch 732 in epoch 10, gen_loss = 0.44901736261574665, disc_loss = 0.034758197757991036
Trained batch 733 in epoch 10, gen_loss = 0.44893200663032584, disc_loss = 0.034728410358766566
Trained batch 734 in epoch 10, gen_loss = 0.4489642087294131, disc_loss = 0.03470504278519831
Trained batch 735 in epoch 10, gen_loss = 0.4488789425029055, disc_loss = 0.03477217600890942
Trained batch 736 in epoch 10, gen_loss = 0.4488732441552135, disc_loss = 0.034758271517426664
Trained batch 737 in epoch 10, gen_loss = 0.44886169398864756, disc_loss = 0.03477594033476763
Trained batch 738 in epoch 10, gen_loss = 0.44884387053881997, disc_loss = 0.03482169977733324
Trained batch 739 in epoch 10, gen_loss = 0.4488742430065129, disc_loss = 0.034960319727936104
Trained batch 740 in epoch 10, gen_loss = 0.44895825071534323, disc_loss = 0.03494438133548126
Trained batch 741 in epoch 10, gen_loss = 0.4489461318501886, disc_loss = 0.03493566059688171
Trained batch 742 in epoch 10, gen_loss = 0.44898167725848, disc_loss = 0.034906217664816136
Trained batch 743 in epoch 10, gen_loss = 0.4489677673786558, disc_loss = 0.034922211280127645
Trained batch 744 in epoch 10, gen_loss = 0.44896100035449804, disc_loss = 0.03505582397353629
Trained batch 745 in epoch 10, gen_loss = 0.44892154042746363, disc_loss = 0.035023290171455244
Testing Epoch 10
Training Epoch 11
Trained batch 0 in epoch 11, gen_loss = 0.41481855511665344, disc_loss = 0.008701842278242111
Trained batch 1 in epoch 11, gen_loss = 0.42534635961055756, disc_loss = 0.06420446000993252
Trained batch 2 in epoch 11, gen_loss = 0.4367638925711314, disc_loss = 0.055072749654452004
Trained batch 3 in epoch 11, gen_loss = 0.44243016839027405, disc_loss = 0.04422838124446571
Trained batch 4 in epoch 11, gen_loss = 0.45296248197555544, disc_loss = 0.04179901387542486
Trained batch 5 in epoch 11, gen_loss = 0.46325500806172687, disc_loss = 0.037914406352986894
Trained batch 6 in epoch 11, gen_loss = 0.46394942913736614, disc_loss = 0.039467439986765385
Trained batch 7 in epoch 11, gen_loss = 0.4754258804023266, disc_loss = 0.04471656016539782
Trained batch 8 in epoch 11, gen_loss = 0.47967349489529926, disc_loss = 0.04122309283249908
Trained batch 9 in epoch 11, gen_loss = 0.4762708246707916, disc_loss = 0.03955942764878273
Trained batch 10 in epoch 11, gen_loss = 0.47507141395048663, disc_loss = 0.04894778335636312
Trained batch 11 in epoch 11, gen_loss = 0.4666249950726827, disc_loss = 0.05646846381326517
Trained batch 12 in epoch 11, gen_loss = 0.46378225546616775, disc_loss = 0.055301880034116596
Trained batch 13 in epoch 11, gen_loss = 0.4694714205605643, disc_loss = 0.06127257485474859
Trained batch 14 in epoch 11, gen_loss = 0.4675563951333364, disc_loss = 0.0577866617590189
Trained batch 15 in epoch 11, gen_loss = 0.46425711177289486, disc_loss = 0.06086953391786665
Trained batch 16 in epoch 11, gen_loss = 0.4650270553196178, disc_loss = 0.06032075787730077
Trained batch 17 in epoch 11, gen_loss = 0.46280214024914634, disc_loss = 0.057508767892917
Trained batch 18 in epoch 11, gen_loss = 0.46219286950011, disc_loss = 0.05668434579121439
Trained batch 19 in epoch 11, gen_loss = 0.460341314971447, disc_loss = 0.054707306995987894
Trained batch 20 in epoch 11, gen_loss = 0.45504974609329585, disc_loss = 0.05424225543226514
Trained batch 21 in epoch 11, gen_loss = 0.4552139788866043, disc_loss = 0.05233004761182449
Trained batch 22 in epoch 11, gen_loss = 0.4528652766476507, disc_loss = 0.050828353906779186
Trained batch 23 in epoch 11, gen_loss = 0.4564700052142143, disc_loss = 0.051054697833023965
Trained batch 24 in epoch 11, gen_loss = 0.4570395350456238, disc_loss = 0.04933424912393093
Trained batch 25 in epoch 11, gen_loss = 0.4580120249436452, disc_loss = 0.04901497603322451
Trained batch 26 in epoch 11, gen_loss = 0.4599874648782942, disc_loss = 0.048001626023539794
Trained batch 27 in epoch 11, gen_loss = 0.4606997125915119, disc_loss = 0.04731151434992041
Trained batch 28 in epoch 11, gen_loss = 0.4635185547943773, disc_loss = 0.04637632538275472
Trained batch 29 in epoch 11, gen_loss = 0.4650114983320236, disc_loss = 0.04592601687957843
Trained batch 30 in epoch 11, gen_loss = 0.4650690488276943, disc_loss = 0.04462299422330914
Trained batch 31 in epoch 11, gen_loss = 0.46282110549509525, disc_loss = 0.045050286440528
Trained batch 32 in epoch 11, gen_loss = 0.4629477081876813, disc_loss = 0.044015551818478285
Trained batch 33 in epoch 11, gen_loss = 0.46275047081358295, disc_loss = 0.044546252541134465
Trained batch 34 in epoch 11, gen_loss = 0.46288907527923584, disc_loss = 0.05000341352341431
Trained batch 35 in epoch 11, gen_loss = 0.4647177772389518, disc_loss = 0.04910703364294022
Trained batch 36 in epoch 11, gen_loss = 0.46533205863591787, disc_loss = 0.04884524420658882
Trained batch 37 in epoch 11, gen_loss = 0.4634605693189721, disc_loss = 0.048247611775112
Trained batch 38 in epoch 11, gen_loss = 0.46238629558147526, disc_loss = 0.04739993651851247
Trained batch 39 in epoch 11, gen_loss = 0.4613800957798958, disc_loss = 0.04661542376270518
Trained batch 40 in epoch 11, gen_loss = 0.4595783599993078, disc_loss = 0.045661554501460096
Trained batch 41 in epoch 11, gen_loss = 0.45848734038216726, disc_loss = 0.04503845125215039
Trained batch 42 in epoch 11, gen_loss = 0.45921247296555096, disc_loss = 0.04566300005197178
Trained batch 43 in epoch 11, gen_loss = 0.4575755934823643, disc_loss = 0.04585411546709524
Trained batch 44 in epoch 11, gen_loss = 0.45823483334647286, disc_loss = 0.0456387027580705
Trained batch 45 in epoch 11, gen_loss = 0.4589090366726336, disc_loss = 0.04593218963228814
Trained batch 46 in epoch 11, gen_loss = 0.45950426319812204, disc_loss = 0.04545068030463571
Trained batch 47 in epoch 11, gen_loss = 0.4568130783736706, disc_loss = 0.04722837873850949
Trained batch 48 in epoch 11, gen_loss = 0.45626575971136285, disc_loss = 0.047365609813025414
Trained batch 49 in epoch 11, gen_loss = 0.454889577627182, disc_loss = 0.046613865857943894
Trained batch 50 in epoch 11, gen_loss = 0.45499619607831915, disc_loss = 0.04584972793236375
Trained batch 51 in epoch 11, gen_loss = 0.45395099142423045, disc_loss = 0.045311041633025385
Trained batch 52 in epoch 11, gen_loss = 0.45433628784035734, disc_loss = 0.044921769101594414
Trained batch 53 in epoch 11, gen_loss = 0.45375220753528456, disc_loss = 0.04427812806399608
Trained batch 54 in epoch 11, gen_loss = 0.45447049520232463, disc_loss = 0.04361694249409166
Trained batch 55 in epoch 11, gen_loss = 0.45385713928512167, disc_loss = 0.043334904667322656
Trained batch 56 in epoch 11, gen_loss = 0.4537749368893473, disc_loss = 0.04270641751620069
Trained batch 57 in epoch 11, gen_loss = 0.45433696898920783, disc_loss = 0.04225073347735251
Trained batch 58 in epoch 11, gen_loss = 0.45522582733024985, disc_loss = 0.04173624835182297
Trained batch 59 in epoch 11, gen_loss = 0.45318727791309354, disc_loss = 0.04161238463129848
Trained batch 60 in epoch 11, gen_loss = 0.45392882139956364, disc_loss = 0.0420072570091999
Trained batch 61 in epoch 11, gen_loss = 0.4528760592783651, disc_loss = 0.041522359723345406
Trained batch 62 in epoch 11, gen_loss = 0.4529061984448206, disc_loss = 0.041071667801588774
Trained batch 63 in epoch 11, gen_loss = 0.452838075812906, disc_loss = 0.04062922237062594
Trained batch 64 in epoch 11, gen_loss = 0.4539115167581118, disc_loss = 0.040157338195981884
Trained batch 65 in epoch 11, gen_loss = 0.45323561854434735, disc_loss = 0.039703608003698966
Trained batch 66 in epoch 11, gen_loss = 0.45439500372801256, disc_loss = 0.04035020174125015
Trained batch 67 in epoch 11, gen_loss = 0.45363423798014135, disc_loss = 0.039949299267712325
Trained batch 68 in epoch 11, gen_loss = 0.45283221723376843, disc_loss = 0.041449383596309286
Trained batch 69 in epoch 11, gen_loss = 0.4535107114485332, disc_loss = 0.041215932069878496
Trained batch 70 in epoch 11, gen_loss = 0.4535313739743031, disc_loss = 0.041085188257389924
Trained batch 71 in epoch 11, gen_loss = 0.45264488458633423, disc_loss = 0.04064677736540842
Trained batch 72 in epoch 11, gen_loss = 0.4522542447259981, disc_loss = 0.040204506399339604
Trained batch 73 in epoch 11, gen_loss = 0.4519672385744146, disc_loss = 0.039830715364046594
Trained batch 74 in epoch 11, gen_loss = 0.4523122787475586, disc_loss = 0.03944322724516193
Trained batch 75 in epoch 11, gen_loss = 0.45164286933447184, disc_loss = 0.039375254093963453
Trained batch 76 in epoch 11, gen_loss = 0.4515086350502906, disc_loss = 0.03899619181023596
Trained batch 77 in epoch 11, gen_loss = 0.4518684874742459, disc_loss = 0.03945252905265452
Trained batch 78 in epoch 11, gen_loss = 0.451657964836193, disc_loss = 0.03989989484389183
Trained batch 79 in epoch 11, gen_loss = 0.4502411525696516, disc_loss = 0.039584267273312435
Trained batch 80 in epoch 11, gen_loss = 0.44956891036327973, disc_loss = 0.03918738405070739
Trained batch 81 in epoch 11, gen_loss = 0.44966377099839655, disc_loss = 0.039333422503593125
Trained batch 82 in epoch 11, gen_loss = 0.4489412749388132, disc_loss = 0.04045366787026266
Trained batch 83 in epoch 11, gen_loss = 0.44863625757751013, disc_loss = 0.041396824859215746
Trained batch 84 in epoch 11, gen_loss = 0.44921350654433756, disc_loss = 0.041245512001435544
Trained batch 85 in epoch 11, gen_loss = 0.44898438557635906, disc_loss = 0.041283941107563844
Trained batch 86 in epoch 11, gen_loss = 0.44828774326149073, disc_loss = 0.04101504342116673
Trained batch 87 in epoch 11, gen_loss = 0.4483991007913243, disc_loss = 0.040754310104106975
Trained batch 88 in epoch 11, gen_loss = 0.4493164714802517, disc_loss = 0.040604036317070887
Trained batch 89 in epoch 11, gen_loss = 0.44880688620938197, disc_loss = 0.04053133057119946
Trained batch 90 in epoch 11, gen_loss = 0.448569723210492, disc_loss = 0.04015575506427622
Trained batch 91 in epoch 11, gen_loss = 0.4481913644982421, disc_loss = 0.0397642756326367
Trained batch 92 in epoch 11, gen_loss = 0.4486361713178696, disc_loss = 0.03942254073517297
Trained batch 93 in epoch 11, gen_loss = 0.44888051044433674, disc_loss = 0.03907697920766758
Trained batch 94 in epoch 11, gen_loss = 0.4492276784620787, disc_loss = 0.038841813758603835
Trained batch 95 in epoch 11, gen_loss = 0.4483680349464218, disc_loss = 0.038488386882818304
Trained batch 96 in epoch 11, gen_loss = 0.4478628134604582, disc_loss = 0.03817186360103414
Trained batch 97 in epoch 11, gen_loss = 0.4478782418431068, disc_loss = 0.03785366361143486
Trained batch 98 in epoch 11, gen_loss = 0.4477869278252727, disc_loss = 0.03754352389204532
Trained batch 99 in epoch 11, gen_loss = 0.4473884427547455, disc_loss = 0.03734702535439283
Trained batch 100 in epoch 11, gen_loss = 0.4482104011101298, disc_loss = 0.03718325064637431
Trained batch 101 in epoch 11, gen_loss = 0.44777709070373983, disc_loss = 0.03710669089638281
Trained batch 102 in epoch 11, gen_loss = 0.4483588470996005, disc_loss = 0.03679139720438754
Trained batch 103 in epoch 11, gen_loss = 0.44764783348028475, disc_loss = 0.036571471575790875
Trained batch 104 in epoch 11, gen_loss = 0.44743005207606723, disc_loss = 0.03642206268296355
Trained batch 105 in epoch 11, gen_loss = 0.44805717693184904, disc_loss = 0.036146355186641776
Trained batch 106 in epoch 11, gen_loss = 0.4484762967189896, disc_loss = 0.03584961335514193
Trained batch 107 in epoch 11, gen_loss = 0.44825292461448246, disc_loss = 0.03571017407294777
Trained batch 108 in epoch 11, gen_loss = 0.4490601261821362, disc_loss = 0.03560801380134504
Trained batch 109 in epoch 11, gen_loss = 0.4482464291832664, disc_loss = 0.03550741801207716
Trained batch 110 in epoch 11, gen_loss = 0.44837240431759806, disc_loss = 0.0352534257790057
Trained batch 111 in epoch 11, gen_loss = 0.4481693341263703, disc_loss = 0.0354404058016371
Trained batch 112 in epoch 11, gen_loss = 0.44849536218474395, disc_loss = 0.03532973403704509
Trained batch 113 in epoch 11, gen_loss = 0.44914134186610843, disc_loss = 0.03517732426540501
Trained batch 114 in epoch 11, gen_loss = 0.44876839907273003, disc_loss = 0.03504281740878587
Trained batch 115 in epoch 11, gen_loss = 0.4484887696031866, disc_loss = 0.034796969210407855
Trained batch 116 in epoch 11, gen_loss = 0.4484482124829904, disc_loss = 0.03463177105141246
Trained batch 117 in epoch 11, gen_loss = 0.4489361646316819, disc_loss = 0.034527849350756
Trained batch 118 in epoch 11, gen_loss = 0.44856592011051016, disc_loss = 0.03435084615841884
Trained batch 119 in epoch 11, gen_loss = 0.44864088023702303, disc_loss = 0.034123287136511256
Trained batch 120 in epoch 11, gen_loss = 0.4482797546820207, disc_loss = 0.035053819575739546
Trained batch 121 in epoch 11, gen_loss = 0.4484954952705102, disc_loss = 0.03532898166888684
Trained batch 122 in epoch 11, gen_loss = 0.44885868488288505, disc_loss = 0.03542452381651213
Trained batch 123 in epoch 11, gen_loss = 0.4491912388513165, disc_loss = 0.03539767594362098
Trained batch 124 in epoch 11, gen_loss = 0.44860974383354185, disc_loss = 0.03561975297704339
Trained batch 125 in epoch 11, gen_loss = 0.44806100380799124, disc_loss = 0.03541668308233576
Trained batch 126 in epoch 11, gen_loss = 0.448378855553199, disc_loss = 0.035648992435464
Trained batch 127 in epoch 11, gen_loss = 0.4487121587153524, disc_loss = 0.03547253704527975
Trained batch 128 in epoch 11, gen_loss = 0.44872506297836007, disc_loss = 0.03525815147892103
Trained batch 129 in epoch 11, gen_loss = 0.4487172103845156, disc_loss = 0.03509514345787466
Trained batch 130 in epoch 11, gen_loss = 0.44838777320985573, disc_loss = 0.03520735756686057
Trained batch 131 in epoch 11, gen_loss = 0.4488062368649425, disc_loss = 0.03504102449567819
Trained batch 132 in epoch 11, gen_loss = 0.44885163154817165, disc_loss = 0.03484050710020321
Trained batch 133 in epoch 11, gen_loss = 0.44904437527727725, disc_loss = 0.03474468050121483
Trained batch 134 in epoch 11, gen_loss = 0.44912280065042004, disc_loss = 0.03631831806635967
Trained batch 135 in epoch 11, gen_loss = 0.4491262556437184, disc_loss = 0.037724456493057966
Trained batch 136 in epoch 11, gen_loss = 0.44855326696904035, disc_loss = 0.0381167989095034
Trained batch 137 in epoch 11, gen_loss = 0.4487633044305055, disc_loss = 0.03858661232178734
Trained batch 138 in epoch 11, gen_loss = 0.4485316872596741, disc_loss = 0.038749580509397835
Trained batch 139 in epoch 11, gen_loss = 0.4485481760331563, disc_loss = 0.038775907207413446
Trained batch 140 in epoch 11, gen_loss = 0.4493624157939397, disc_loss = 0.0390421600900062
Trained batch 141 in epoch 11, gen_loss = 0.4493188243096983, disc_loss = 0.03895598423378673
Trained batch 142 in epoch 11, gen_loss = 0.4490102339874614, disc_loss = 0.03895696710104813
Trained batch 143 in epoch 11, gen_loss = 0.4488718577971061, disc_loss = 0.03886370295205981
Trained batch 144 in epoch 11, gen_loss = 0.44921257105366935, disc_loss = 0.03876707662089632
Trained batch 145 in epoch 11, gen_loss = 0.4494859459873748, disc_loss = 0.03867170579846285
Trained batch 146 in epoch 11, gen_loss = 0.44925208156611646, disc_loss = 0.03850456850831302
Trained batch 147 in epoch 11, gen_loss = 0.44912157670871633, disc_loss = 0.03831332491874393
Trained batch 148 in epoch 11, gen_loss = 0.4494587215001151, disc_loss = 0.03818174844432697
Trained batch 149 in epoch 11, gen_loss = 0.44983930230140684, disc_loss = 0.037980120073383056
Trained batch 150 in epoch 11, gen_loss = 0.4499718156081951, disc_loss = 0.0377778288328539
Trained batch 151 in epoch 11, gen_loss = 0.44985193504314674, disc_loss = 0.03760240894533988
Trained batch 152 in epoch 11, gen_loss = 0.4498225438828562, disc_loss = 0.037393376255541844
Trained batch 153 in epoch 11, gen_loss = 0.4492273537756561, disc_loss = 0.03718059646062456
Trained batch 154 in epoch 11, gen_loss = 0.4494121338090589, disc_loss = 0.0369590433329464
Trained batch 155 in epoch 11, gen_loss = 0.4498234630013124, disc_loss = 0.03674364121756158
Trained batch 156 in epoch 11, gen_loss = 0.449851072897577, disc_loss = 0.03687583738908314
Trained batch 157 in epoch 11, gen_loss = 0.4492740823498255, disc_loss = 0.03669578738398614
Trained batch 158 in epoch 11, gen_loss = 0.44887587877939333, disc_loss = 0.03666685515305953
Trained batch 159 in epoch 11, gen_loss = 0.44876927845180037, disc_loss = 0.03652700858801836
Trained batch 160 in epoch 11, gen_loss = 0.4483744938921484, disc_loss = 0.03633888076371889
Trained batch 161 in epoch 11, gen_loss = 0.4482751069245515, disc_loss = 0.03619999386352935
Trained batch 162 in epoch 11, gen_loss = 0.4483829970740102, disc_loss = 0.03605050270365654
Trained batch 163 in epoch 11, gen_loss = 0.4478158630975863, disc_loss = 0.03593805192816412
Trained batch 164 in epoch 11, gen_loss = 0.4475525933684725, disc_loss = 0.03575311493495423
Trained batch 165 in epoch 11, gen_loss = 0.4479208288781614, disc_loss = 0.03621716775611626
Trained batch 166 in epoch 11, gen_loss = 0.44772143242601864, disc_loss = 0.036796565325149966
Trained batch 167 in epoch 11, gen_loss = 0.44775622621888206, disc_loss = 0.03684573656729689
Trained batch 168 in epoch 11, gen_loss = 0.4477691320625283, disc_loss = 0.037099032542949335
Trained batch 169 in epoch 11, gen_loss = 0.447412170382107, disc_loss = 0.03751542875680196
Trained batch 170 in epoch 11, gen_loss = 0.446680540229842, disc_loss = 0.03759859544388427
Trained batch 171 in epoch 11, gen_loss = 0.44705619714980904, disc_loss = 0.03760888068638959
Trained batch 172 in epoch 11, gen_loss = 0.4474094964865315, disc_loss = 0.03751008370433627
Trained batch 173 in epoch 11, gen_loss = 0.4478422749316555, disc_loss = 0.037333885498141504
Trained batch 174 in epoch 11, gen_loss = 0.4477803562368665, disc_loss = 0.037605381151661274
Trained batch 175 in epoch 11, gen_loss = 0.4474135020917112, disc_loss = 0.03760942557577933
Trained batch 176 in epoch 11, gen_loss = 0.4476637340198129, disc_loss = 0.03749575380809437
Trained batch 177 in epoch 11, gen_loss = 0.4479098160949986, disc_loss = 0.037350934329756606
Trained batch 178 in epoch 11, gen_loss = 0.44808355340078554, disc_loss = 0.037251610284171705
Trained batch 179 in epoch 11, gen_loss = 0.4485572356316778, disc_loss = 0.0371938053272768
Trained batch 180 in epoch 11, gen_loss = 0.4485584711501612, disc_loss = 0.0371526633633702
Trained batch 181 in epoch 11, gen_loss = 0.44823301264217924, disc_loss = 0.03699483604369951
Trained batch 182 in epoch 11, gen_loss = 0.4479508383677957, disc_loss = 0.03697236721617643
Trained batch 183 in epoch 11, gen_loss = 0.4482053660828134, disc_loss = 0.03698060903116129
Trained batch 184 in epoch 11, gen_loss = 0.44821350107321867, disc_loss = 0.03684081050718354
Trained batch 185 in epoch 11, gen_loss = 0.44833874301884763, disc_loss = 0.03683838578847347
Trained batch 186 in epoch 11, gen_loss = 0.44836472699986424, disc_loss = 0.03677507984093366
Trained batch 187 in epoch 11, gen_loss = 0.4478730873224583, disc_loss = 0.03707132294422333
Trained batch 188 in epoch 11, gen_loss = 0.44775085805585146, disc_loss = 0.036979483904947756
Trained batch 189 in epoch 11, gen_loss = 0.4481705168360158, disc_loss = 0.03732251234867267
Trained batch 190 in epoch 11, gen_loss = 0.44817710812179207, disc_loss = 0.03777954669020758
Trained batch 191 in epoch 11, gen_loss = 0.44844435388222337, disc_loss = 0.03762684821776929
Trained batch 192 in epoch 11, gen_loss = 0.448556080074508, disc_loss = 0.03759442884692141
Trained batch 193 in epoch 11, gen_loss = 0.44846060180786956, disc_loss = 0.037647632950408016
Trained batch 194 in epoch 11, gen_loss = 0.4485741968338306, disc_loss = 0.03755761535050204
Trained batch 195 in epoch 11, gen_loss = 0.4485865857224075, disc_loss = 0.03749855717154676
Trained batch 196 in epoch 11, gen_loss = 0.4486162117895136, disc_loss = 0.037538443092814636
Trained batch 197 in epoch 11, gen_loss = 0.44870801059284593, disc_loss = 0.03739192483669166
Trained batch 198 in epoch 11, gen_loss = 0.4487810199284673, disc_loss = 0.037322336865177184
Trained batch 199 in epoch 11, gen_loss = 0.4487454694509506, disc_loss = 0.03727904844214208
Trained batch 200 in epoch 11, gen_loss = 0.44865851823370256, disc_loss = 0.03717559778168612
Trained batch 201 in epoch 11, gen_loss = 0.448615291921219, disc_loss = 0.03704101255850516
Trained batch 202 in epoch 11, gen_loss = 0.44883733136313303, disc_loss = 0.0369883785907436
Trained batch 203 in epoch 11, gen_loss = 0.44876837292138266, disc_loss = 0.03688024218746589
Trained batch 204 in epoch 11, gen_loss = 0.4493339367029143, disc_loss = 0.03698539578174127
Trained batch 205 in epoch 11, gen_loss = 0.4496238639632475, disc_loss = 0.036896392274693164
Trained batch 206 in epoch 11, gen_loss = 0.4500549562311403, disc_loss = 0.03680477881295705
Trained batch 207 in epoch 11, gen_loss = 0.44999422734746564, disc_loss = 0.03678720162917251
Trained batch 208 in epoch 11, gen_loss = 0.4500007401242781, disc_loss = 0.03717120285546986
Trained batch 209 in epoch 11, gen_loss = 0.44961449191683817, disc_loss = 0.03726437763820979
Trained batch 210 in epoch 11, gen_loss = 0.4492481643272237, disc_loss = 0.03713890691331954
Trained batch 211 in epoch 11, gen_loss = 0.44922596764452055, disc_loss = 0.03731345673605694
Trained batch 212 in epoch 11, gen_loss = 0.4490404429849884, disc_loss = 0.03716585055505201
Trained batch 213 in epoch 11, gen_loss = 0.44883441103396016, disc_loss = 0.03711103417836652
Trained batch 214 in epoch 11, gen_loss = 0.44914957271065825, disc_loss = 0.03720371625819352
Trained batch 215 in epoch 11, gen_loss = 0.44945921321158055, disc_loss = 0.037217253194992535
Trained batch 216 in epoch 11, gen_loss = 0.44911336802667184, disc_loss = 0.03768811865563801
Trained batch 217 in epoch 11, gen_loss = 0.4488196281391546, disc_loss = 0.037603896022603396
Trained batch 218 in epoch 11, gen_loss = 0.4488862623634948, disc_loss = 0.038074133208565855
Trained batch 219 in epoch 11, gen_loss = 0.4489775390787558, disc_loss = 0.037948618902274495
Trained batch 220 in epoch 11, gen_loss = 0.44905202003086314, disc_loss = 0.03791313206806476
Trained batch 221 in epoch 11, gen_loss = 0.4486451142274582, disc_loss = 0.03824593210362133
Trained batch 222 in epoch 11, gen_loss = 0.4492211888456558, disc_loss = 0.03939332973082537
Trained batch 223 in epoch 11, gen_loss = 0.44905358353363617, disc_loss = 0.03942470149091345
Trained batch 224 in epoch 11, gen_loss = 0.4491822930177053, disc_loss = 0.039320762915950686
Trained batch 225 in epoch 11, gen_loss = 0.4487189861525476, disc_loss = 0.03926732158391382
Trained batch 226 in epoch 11, gen_loss = 0.4487305257288895, disc_loss = 0.03912828589937268
Trained batch 227 in epoch 11, gen_loss = 0.4486679047868963, disc_loss = 0.03899004471002212
Trained batch 228 in epoch 11, gen_loss = 0.44848822909671665, disc_loss = 0.03884624861746083
Trained batch 229 in epoch 11, gen_loss = 0.44837606484475345, disc_loss = 0.03879600285815642
Trained batch 230 in epoch 11, gen_loss = 0.44795666125429656, disc_loss = 0.03868988903291781
Trained batch 231 in epoch 11, gen_loss = 0.447857440931016, disc_loss = 0.03855030888647387
Trained batch 232 in epoch 11, gen_loss = 0.4478296464860695, disc_loss = 0.03845762700150229
Trained batch 233 in epoch 11, gen_loss = 0.4477535732026793, disc_loss = 0.0383633559412506
Trained batch 234 in epoch 11, gen_loss = 0.44739482922756924, disc_loss = 0.0385207426565838
Trained batch 235 in epoch 11, gen_loss = 0.44756666368852227, disc_loss = 0.038764999695003854
Trained batch 236 in epoch 11, gen_loss = 0.4473831594493319, disc_loss = 0.03873836826474135
Trained batch 237 in epoch 11, gen_loss = 0.4471565571402301, disc_loss = 0.03896991143633118
Trained batch 238 in epoch 11, gen_loss = 0.4476831035384573, disc_loss = 0.03899749911343484
Trained batch 239 in epoch 11, gen_loss = 0.4477603609363238, disc_loss = 0.040550802249345
Trained batch 240 in epoch 11, gen_loss = 0.44743315535462247, disc_loss = 0.04071033836141445
Trained batch 241 in epoch 11, gen_loss = 0.44704709417563826, disc_loss = 0.04141124024359925
Trained batch 242 in epoch 11, gen_loss = 0.447193907121572, disc_loss = 0.042060360317252604
Trained batch 243 in epoch 11, gen_loss = 0.44709493451919713, disc_loss = 0.04236956582439025
Trained batch 244 in epoch 11, gen_loss = 0.44674924186297826, disc_loss = 0.042500539584921636
Trained batch 245 in epoch 11, gen_loss = 0.44686473445679115, disc_loss = 0.042542591665462565
Trained batch 246 in epoch 11, gen_loss = 0.4467706116828841, disc_loss = 0.04257643167476211
Trained batch 247 in epoch 11, gen_loss = 0.44684884144413856, disc_loss = 0.042481572942755695
Trained batch 248 in epoch 11, gen_loss = 0.44704052518649273, disc_loss = 0.042691800284225596
Trained batch 249 in epoch 11, gen_loss = 0.4468755965232849, disc_loss = 0.04271202089358121
Trained batch 250 in epoch 11, gen_loss = 0.44707327475585784, disc_loss = 0.04299935617343155
Trained batch 251 in epoch 11, gen_loss = 0.4468327025099406, disc_loss = 0.04290329762974695
Trained batch 252 in epoch 11, gen_loss = 0.44680263343535864, disc_loss = 0.042879138882695275
Trained batch 253 in epoch 11, gen_loss = 0.44688369767872366, disc_loss = 0.04276287991014551
Trained batch 254 in epoch 11, gen_loss = 0.44675464723624436, disc_loss = 0.042838250711450684
Trained batch 255 in epoch 11, gen_loss = 0.446443168213591, disc_loss = 0.042818852930395224
Trained batch 256 in epoch 11, gen_loss = 0.44616184056037134, disc_loss = 0.04276420639606794
Trained batch 257 in epoch 11, gen_loss = 0.4464799358632213, disc_loss = 0.042659053439093944
Trained batch 258 in epoch 11, gen_loss = 0.4467173742281424, disc_loss = 0.042814529127833297
Trained batch 259 in epoch 11, gen_loss = 0.4469972882133264, disc_loss = 0.042696047170410076
Trained batch 260 in epoch 11, gen_loss = 0.44680663543642707, disc_loss = 0.042961996231563535
Trained batch 261 in epoch 11, gen_loss = 0.44678079774816526, disc_loss = 0.04363402291752028
Trained batch 262 in epoch 11, gen_loss = 0.44670335364885655, disc_loss = 0.043718531073563285
Trained batch 263 in epoch 11, gen_loss = 0.44686573642221367, disc_loss = 0.04377443467312718
Trained batch 264 in epoch 11, gen_loss = 0.4471633336454068, disc_loss = 0.04379378857776382
Trained batch 265 in epoch 11, gen_loss = 0.44714273422732387, disc_loss = 0.04372581674741875
Trained batch 266 in epoch 11, gen_loss = 0.44721595066763487, disc_loss = 0.044609115508730326
Trained batch 267 in epoch 11, gen_loss = 0.44729015787145987, disc_loss = 0.04485621951510018
Trained batch 268 in epoch 11, gen_loss = 0.44686365504247105, disc_loss = 0.04482161823303532
Trained batch 269 in epoch 11, gen_loss = 0.44682303733295864, disc_loss = 0.044790991082684035
Trained batch 270 in epoch 11, gen_loss = 0.4469778541049394, disc_loss = 0.04528950274805109
Trained batch 271 in epoch 11, gen_loss = 0.44669908559059396, disc_loss = 0.04541328532008372
Trained batch 272 in epoch 11, gen_loss = 0.44652266587529865, disc_loss = 0.045442173459597834
Trained batch 273 in epoch 11, gen_loss = 0.44638309861621717, disc_loss = 0.04549729158289486
Trained batch 274 in epoch 11, gen_loss = 0.4461154887892983, disc_loss = 0.0455291358220645
Trained batch 275 in epoch 11, gen_loss = 0.4460385139437689, disc_loss = 0.04550834846821195
Trained batch 276 in epoch 11, gen_loss = 0.4458648823874091, disc_loss = 0.04541248650397661
Trained batch 277 in epoch 11, gen_loss = 0.44594701084730437, disc_loss = 0.04531170374616686
Trained batch 278 in epoch 11, gen_loss = 0.446033120903063, disc_loss = 0.04530657438384402
Trained batch 279 in epoch 11, gen_loss = 0.4464374796620437, disc_loss = 0.045242435369540805
Trained batch 280 in epoch 11, gen_loss = 0.4462225940940219, disc_loss = 0.045126256116191955
Trained batch 281 in epoch 11, gen_loss = 0.4464116438906244, disc_loss = 0.045026337606535155
Trained batch 282 in epoch 11, gen_loss = 0.44625993057190316, disc_loss = 0.04493516467449127
Trained batch 283 in epoch 11, gen_loss = 0.44636610717001096, disc_loss = 0.04494220184729579
Trained batch 284 in epoch 11, gen_loss = 0.4467401975079587, disc_loss = 0.04545176879894969
Trained batch 285 in epoch 11, gen_loss = 0.44669720290840925, disc_loss = 0.045335332606593476
Trained batch 286 in epoch 11, gen_loss = 0.4468437332517179, disc_loss = 0.045253461646240604
Trained batch 287 in epoch 11, gen_loss = 0.446677399178346, disc_loss = 0.045811554712094624
Trained batch 288 in epoch 11, gen_loss = 0.4465029397431542, disc_loss = 0.045910488889040264
Trained batch 289 in epoch 11, gen_loss = 0.44634103888067705, disc_loss = 0.04601861645451522
Trained batch 290 in epoch 11, gen_loss = 0.44636780125988307, disc_loss = 0.045922383215579225
Trained batch 291 in epoch 11, gen_loss = 0.4466673288851568, disc_loss = 0.045837321762818434
Trained batch 292 in epoch 11, gen_loss = 0.44675414696488364, disc_loss = 0.0457109573874114
Trained batch 293 in epoch 11, gen_loss = 0.4469746464774722, disc_loss = 0.04560703940477324
Trained batch 294 in epoch 11, gen_loss = 0.44700463545524466, disc_loss = 0.04550289150280089
Trained batch 295 in epoch 11, gen_loss = 0.44714114855270126, disc_loss = 0.04544000582835587
Trained batch 296 in epoch 11, gen_loss = 0.4472599821259277, disc_loss = 0.045464500632005356
Trained batch 297 in epoch 11, gen_loss = 0.44727297137247635, disc_loss = 0.04550979729982455
Trained batch 298 in epoch 11, gen_loss = 0.4472197575313989, disc_loss = 0.045444533201619786
Trained batch 299 in epoch 11, gen_loss = 0.4471137739221255, disc_loss = 0.04533448034043734
Trained batch 300 in epoch 11, gen_loss = 0.44679280590773424, disc_loss = 0.04534695037343598
Trained batch 301 in epoch 11, gen_loss = 0.44645845090711356, disc_loss = 0.045244667134001014
Trained batch 302 in epoch 11, gen_loss = 0.44645891262359744, disc_loss = 0.04512204677435161
Trained batch 303 in epoch 11, gen_loss = 0.4461204092949629, disc_loss = 0.04501255979764545
Trained batch 304 in epoch 11, gen_loss = 0.4460823413778524, disc_loss = 0.04488817455903551
Trained batch 305 in epoch 11, gen_loss = 0.44608983796795987, disc_loss = 0.044754017125419494
Trained batch 306 in epoch 11, gen_loss = 0.4459579263719751, disc_loss = 0.04470055252359118
Trained batch 307 in epoch 11, gen_loss = 0.4458049259015492, disc_loss = 0.044577919326982664
Trained batch 308 in epoch 11, gen_loss = 0.4459062888977211, disc_loss = 0.044477611568433904
Trained batch 309 in epoch 11, gen_loss = 0.44567012267728007, disc_loss = 0.04435577119415205
Trained batch 310 in epoch 11, gen_loss = 0.4458011984825134, disc_loss = 0.044236919799987284
Trained batch 311 in epoch 11, gen_loss = 0.445616609393022, disc_loss = 0.04411762790643992
Trained batch 312 in epoch 11, gen_loss = 0.44568839478797423, disc_loss = 0.043991723791889537
Trained batch 313 in epoch 11, gen_loss = 0.4459040693606541, disc_loss = 0.0438674001926319
Trained batch 314 in epoch 11, gen_loss = 0.4459102267310733, disc_loss = 0.043740387495222785
Trained batch 315 in epoch 11, gen_loss = 0.44587066948791093, disc_loss = 0.04363415519709852
Trained batch 316 in epoch 11, gen_loss = 0.4455603731543484, disc_loss = 0.04350731575168223
Trained batch 317 in epoch 11, gen_loss = 0.44560387805572843, disc_loss = 0.043381490940872416
Trained batch 318 in epoch 11, gen_loss = 0.44521119200323817, disc_loss = 0.04326038981341176
Trained batch 319 in epoch 11, gen_loss = 0.44509099861606954, disc_loss = 0.043140464594762305
Trained batch 320 in epoch 11, gen_loss = 0.4449232468538195, disc_loss = 0.04302240401721121
Trained batch 321 in epoch 11, gen_loss = 0.444914030454914, disc_loss = 0.04290175155204322
Trained batch 322 in epoch 11, gen_loss = 0.4448440657127014, disc_loss = 0.042781739902247214
Trained batch 323 in epoch 11, gen_loss = 0.4449438159296542, disc_loss = 0.042659745777290266
Trained batch 324 in epoch 11, gen_loss = 0.4447653867648198, disc_loss = 0.04254080755206255
Trained batch 325 in epoch 11, gen_loss = 0.44475719734934943, disc_loss = 0.04241719695973707
Trained batch 326 in epoch 11, gen_loss = 0.4448049251639515, disc_loss = 0.04233904503320062
Trained batch 327 in epoch 11, gen_loss = 0.4446496197544947, disc_loss = 0.04221785403773893
Trained batch 328 in epoch 11, gen_loss = 0.44466442684996815, disc_loss = 0.04212918041888228
Trained batch 329 in epoch 11, gen_loss = 0.4445735229687257, disc_loss = 0.04201650654854761
Trained batch 330 in epoch 11, gen_loss = 0.4446924337807739, disc_loss = 0.04192126891294387
Trained batch 331 in epoch 11, gen_loss = 0.44485664026564864, disc_loss = 0.04181695498136175
Trained batch 332 in epoch 11, gen_loss = 0.4448295249953284, disc_loss = 0.041703800591793995
Trained batch 333 in epoch 11, gen_loss = 0.4448911123825404, disc_loss = 0.04159926877337547
Trained batch 334 in epoch 11, gen_loss = 0.4449498756607967, disc_loss = 0.04148510971398496
Trained batch 335 in epoch 11, gen_loss = 0.44505228714219164, disc_loss = 0.0414031499558838
Trained batch 336 in epoch 11, gen_loss = 0.44478883587641954, disc_loss = 0.041292104561943065
Trained batch 337 in epoch 11, gen_loss = 0.4447086876666052, disc_loss = 0.041177243003263496
Trained batch 338 in epoch 11, gen_loss = 0.4449161477496842, disc_loss = 0.04110439174264603
Trained batch 339 in epoch 11, gen_loss = 0.4447941846707288, disc_loss = 0.04099021613091121
Trained batch 340 in epoch 11, gen_loss = 0.44491404871786794, disc_loss = 0.040921637716722234
Trained batch 341 in epoch 11, gen_loss = 0.4449838052193324, disc_loss = 0.04081297661545441
Trained batch 342 in epoch 11, gen_loss = 0.4450230693156796, disc_loss = 0.04070522917268944
Trained batch 343 in epoch 11, gen_loss = 0.4451461354660433, disc_loss = 0.04060088994785559
Trained batch 344 in epoch 11, gen_loss = 0.4453030897223431, disc_loss = 0.04049770746825506
Trained batch 345 in epoch 11, gen_loss = 0.44524096925823675, disc_loss = 0.04038689813692381
Trained batch 346 in epoch 11, gen_loss = 0.4451784683922869, disc_loss = 0.04029238030048737
Trained batch 347 in epoch 11, gen_loss = 0.445148641693181, disc_loss = 0.04018968699604337
Trained batch 348 in epoch 11, gen_loss = 0.44537345454481064, disc_loss = 0.04010200258651295
Trained batch 349 in epoch 11, gen_loss = 0.445367340019771, disc_loss = 0.04000144029235733
Trained batch 350 in epoch 11, gen_loss = 0.44543041157246993, disc_loss = 0.03989286554587257
Trained batch 351 in epoch 11, gen_loss = 0.445436655967073, disc_loss = 0.03978817931982286
Trained batch 352 in epoch 11, gen_loss = 0.44560969517521415, disc_loss = 0.03969010800484663
Trained batch 353 in epoch 11, gen_loss = 0.4457047489066582, disc_loss = 0.03959980443459383
Trained batch 354 in epoch 11, gen_loss = 0.4457367283357701, disc_loss = 0.03951022417258314
Trained batch 355 in epoch 11, gen_loss = 0.4457246728994873, disc_loss = 0.039407735717289276
Trained batch 356 in epoch 11, gen_loss = 0.4458075359421952, disc_loss = 0.03931167568941014
Trained batch 357 in epoch 11, gen_loss = 0.44573765918196245, disc_loss = 0.03921005504879601
Trained batch 358 in epoch 11, gen_loss = 0.44587173136495944, disc_loss = 0.039118498254406546
Trained batch 359 in epoch 11, gen_loss = 0.4459052360720105, disc_loss = 0.03902448114046517
Trained batch 360 in epoch 11, gen_loss = 0.445968696945592, disc_loss = 0.03896733595721341
Trained batch 361 in epoch 11, gen_loss = 0.4460183347457022, disc_loss = 0.03887519750741532
Trained batch 362 in epoch 11, gen_loss = 0.44597318185590845, disc_loss = 0.03878938047710508
Trained batch 363 in epoch 11, gen_loss = 0.44604935210484725, disc_loss = 0.03912879301652128
Trained batch 364 in epoch 11, gen_loss = 0.4458332621071437, disc_loss = 0.03935219355833347
Trained batch 365 in epoch 11, gen_loss = 0.44573023158018704, disc_loss = 0.039492432640666965
Trained batch 366 in epoch 11, gen_loss = 0.44575750998320307, disc_loss = 0.03951348218374076
Trained batch 367 in epoch 11, gen_loss = 0.4458819362942291, disc_loss = 0.03945584653094714
Trained batch 368 in epoch 11, gen_loss = 0.4458518617844517, disc_loss = 0.03950891035184931
Trained batch 369 in epoch 11, gen_loss = 0.4457003826225126, disc_loss = 0.0394826451133987
Trained batch 370 in epoch 11, gen_loss = 0.44574299302062576, disc_loss = 0.03944351765794072
Trained batch 371 in epoch 11, gen_loss = 0.4458923093093339, disc_loss = 0.03940680933683129
Trained batch 372 in epoch 11, gen_loss = 0.44597322276066836, disc_loss = 0.039337422410974994
Trained batch 373 in epoch 11, gen_loss = 0.4460387165374297, disc_loss = 0.039301739559249885
Trained batch 374 in epoch 11, gen_loss = 0.4461422941684723, disc_loss = 0.039234224857762456
Trained batch 375 in epoch 11, gen_loss = 0.44610175712311523, disc_loss = 0.03916173594931953
Trained batch 376 in epoch 11, gen_loss = 0.44617715952250936, disc_loss = 0.03910056111496683
Trained batch 377 in epoch 11, gen_loss = 0.446135365064182, disc_loss = 0.03901387734656474
Trained batch 378 in epoch 11, gen_loss = 0.44609908063682213, disc_loss = 0.038963649125209464
Trained batch 379 in epoch 11, gen_loss = 0.44597375769364206, disc_loss = 0.0389730982366018
Trained batch 380 in epoch 11, gen_loss = 0.44596933254732546, disc_loss = 0.03920264318010958
Trained batch 381 in epoch 11, gen_loss = 0.44598735432038134, disc_loss = 0.03918348258441675
Trained batch 382 in epoch 11, gen_loss = 0.4461320683009942, disc_loss = 0.03929842582310479
Trained batch 383 in epoch 11, gen_loss = 0.44640665291808546, disc_loss = 0.039275866941049266
Trained batch 384 in epoch 11, gen_loss = 0.44647680838386733, disc_loss = 0.03927948243444326
Trained batch 385 in epoch 11, gen_loss = 0.4464292598820721, disc_loss = 0.039266162641814525
Trained batch 386 in epoch 11, gen_loss = 0.4466225033582643, disc_loss = 0.039179421343433954
Trained batch 387 in epoch 11, gen_loss = 0.44658305019754724, disc_loss = 0.039094435104490594
Trained batch 388 in epoch 11, gen_loss = 0.4465667269836661, disc_loss = 0.03907727943865012
Trained batch 389 in epoch 11, gen_loss = 0.44665463490363877, disc_loss = 0.038990539699816744
Trained batch 390 in epoch 11, gen_loss = 0.4466967805267295, disc_loss = 0.038924191157212074
Trained batch 391 in epoch 11, gen_loss = 0.44666929953560536, disc_loss = 0.03886493109226018
Trained batch 392 in epoch 11, gen_loss = 0.44677791166244873, disc_loss = 0.039256607910438085
Trained batch 393 in epoch 11, gen_loss = 0.4469310017255357, disc_loss = 0.03936279330669718
Trained batch 394 in epoch 11, gen_loss = 0.447036809408212, disc_loss = 0.03935758124482877
Trained batch 395 in epoch 11, gen_loss = 0.44689948631055426, disc_loss = 0.03930128680958384
Trained batch 396 in epoch 11, gen_loss = 0.44688740109916897, disc_loss = 0.03932972495462886
Trained batch 397 in epoch 11, gen_loss = 0.4468118188968256, disc_loss = 0.03928962415470344
Trained batch 398 in epoch 11, gen_loss = 0.44679501817041173, disc_loss = 0.03921177900246902
Trained batch 399 in epoch 11, gen_loss = 0.44681406654417516, disc_loss = 0.03919134238793049
Trained batch 400 in epoch 11, gen_loss = 0.44709492777648413, disc_loss = 0.03926374545922396
Trained batch 401 in epoch 11, gen_loss = 0.44721405104321627, disc_loss = 0.03918884078154238
Trained batch 402 in epoch 11, gen_loss = 0.4471799663959011, disc_loss = 0.039288353302606174
Trained batch 403 in epoch 11, gen_loss = 0.4469627055643809, disc_loss = 0.03955407845292074
Trained batch 404 in epoch 11, gen_loss = 0.44664144427688035, disc_loss = 0.039667828333345645
Trained batch 405 in epoch 11, gen_loss = 0.44658842022195827, disc_loss = 0.039689516133096604
Trained batch 406 in epoch 11, gen_loss = 0.44652631263768056, disc_loss = 0.039689246471856864
Trained batch 407 in epoch 11, gen_loss = 0.44672340527176857, disc_loss = 0.03962579902601611
Trained batch 408 in epoch 11, gen_loss = 0.4469824541897529, disc_loss = 0.039657965646874536
Trained batch 409 in epoch 11, gen_loss = 0.4470202549201686, disc_loss = 0.039584701720102713
Trained batch 410 in epoch 11, gen_loss = 0.4470310457721534, disc_loss = 0.03951269690991989
Trained batch 411 in epoch 11, gen_loss = 0.44686941462523727, disc_loss = 0.039530841091724604
Trained batch 412 in epoch 11, gen_loss = 0.44691052340133425, disc_loss = 0.03948404926854044
Trained batch 413 in epoch 11, gen_loss = 0.44680625891339953, disc_loss = 0.03948890187514379
Trained batch 414 in epoch 11, gen_loss = 0.44694368968527, disc_loss = 0.039411496708214463
Trained batch 415 in epoch 11, gen_loss = 0.4469305516865391, disc_loss = 0.03992358769364028
Trained batch 416 in epoch 11, gen_loss = 0.4469712189347338, disc_loss = 0.04018288938835603
Trained batch 417 in epoch 11, gen_loss = 0.446840712399574, disc_loss = 0.0403105828907724
Trained batch 418 in epoch 11, gen_loss = 0.4468399737928249, disc_loss = 0.04035805477449551
Trained batch 419 in epoch 11, gen_loss = 0.447071807654131, disc_loss = 0.040369001621313925
Trained batch 420 in epoch 11, gen_loss = 0.4468880689342345, disc_loss = 0.04038591701105998
Trained batch 421 in epoch 11, gen_loss = 0.4466328359610662, disc_loss = 0.04040690789151478
Trained batch 422 in epoch 11, gen_loss = 0.4466371934323728, disc_loss = 0.0403312953991538
Trained batch 423 in epoch 11, gen_loss = 0.44680622423876004, disc_loss = 0.0403003138846955
Trained batch 424 in epoch 11, gen_loss = 0.44667215768028706, disc_loss = 0.0402866109948167
Trained batch 425 in epoch 11, gen_loss = 0.44672109725329795, disc_loss = 0.040325831517494096
Trained batch 426 in epoch 11, gen_loss = 0.44670807303254445, disc_loss = 0.04028001020278616
Trained batch 427 in epoch 11, gen_loss = 0.4468833497055223, disc_loss = 0.04021564070799031
Trained batch 428 in epoch 11, gen_loss = 0.44679037000471616, disc_loss = 0.04018418821354238
Trained batch 429 in epoch 11, gen_loss = 0.4469757687906886, disc_loss = 0.04012189895012091
Trained batch 430 in epoch 11, gen_loss = 0.4469621552806996, disc_loss = 0.04006349078699376
Trained batch 431 in epoch 11, gen_loss = 0.4468798353854153, disc_loss = 0.04007431830514516
Trained batch 432 in epoch 11, gen_loss = 0.4468803369283125, disc_loss = 0.04002956614838203
Trained batch 433 in epoch 11, gen_loss = 0.4468664279731188, disc_loss = 0.03995134970141051
Trained batch 434 in epoch 11, gen_loss = 0.4469134325268625, disc_loss = 0.03988319950809852
Trained batch 435 in epoch 11, gen_loss = 0.44682497531175613, disc_loss = 0.039805879948314686
Trained batch 436 in epoch 11, gen_loss = 0.44675976297129755, disc_loss = 0.03973454130372327
Trained batch 437 in epoch 11, gen_loss = 0.4467874486424607, disc_loss = 0.039653294843613046
Trained batch 438 in epoch 11, gen_loss = 0.4466255706372185, disc_loss = 0.03964070342788749
Trained batch 439 in epoch 11, gen_loss = 0.4467527837915854, disc_loss = 0.03956037096901458
Trained batch 440 in epoch 11, gen_loss = 0.4470223891221477, disc_loss = 0.03948133944242331
Trained batch 441 in epoch 11, gen_loss = 0.44691974025775943, disc_loss = 0.039398827020087325
Trained batch 442 in epoch 11, gen_loss = 0.446980528651188, disc_loss = 0.03932290907074649
Trained batch 443 in epoch 11, gen_loss = 0.4470758313262785, disc_loss = 0.03924478751372311
Trained batch 444 in epoch 11, gen_loss = 0.4469413459300995, disc_loss = 0.039202485298423954
Trained batch 445 in epoch 11, gen_loss = 0.4469687405455807, disc_loss = 0.03913159611647439
Trained batch 446 in epoch 11, gen_loss = 0.44699759751358287, disc_loss = 0.039251502878313894
Trained batch 447 in epoch 11, gen_loss = 0.4469242955424956, disc_loss = 0.03918225586364445
Trained batch 448 in epoch 11, gen_loss = 0.44694839149116145, disc_loss = 0.039129703606422865
Trained batch 449 in epoch 11, gen_loss = 0.44696402278211383, disc_loss = 0.03907652282466491
Trained batch 450 in epoch 11, gen_loss = 0.4468630469691198, disc_loss = 0.03901788374685792
Trained batch 451 in epoch 11, gen_loss = 0.44676986791655027, disc_loss = 0.03939562357253337
Trained batch 452 in epoch 11, gen_loss = 0.44679015315657944, disc_loss = 0.03936992725460208
Trained batch 453 in epoch 11, gen_loss = 0.44675862808847217, disc_loss = 0.03931937210819795
Trained batch 454 in epoch 11, gen_loss = 0.44668062532341085, disc_loss = 0.039287809024636564
Trained batch 455 in epoch 11, gen_loss = 0.4466653215257745, disc_loss = 0.039547448516251485
Trained batch 456 in epoch 11, gen_loss = 0.4466533022453801, disc_loss = 0.03948439169609899
Trained batch 457 in epoch 11, gen_loss = 0.44661536064470697, disc_loss = 0.03947828031108434
Trained batch 458 in epoch 11, gen_loss = 0.44636741468849267, disc_loss = 0.03945858207021988
Trained batch 459 in epoch 11, gen_loss = 0.44635953410812046, disc_loss = 0.0394526404713321
Trained batch 460 in epoch 11, gen_loss = 0.4464599905846693, disc_loss = 0.03942127647221799
Trained batch 461 in epoch 11, gen_loss = 0.4464232132677392, disc_loss = 0.039379262274687556
Trained batch 462 in epoch 11, gen_loss = 0.4463043051327279, disc_loss = 0.0393703529072149
Trained batch 463 in epoch 11, gen_loss = 0.4462292504593216, disc_loss = 0.03935438248625924
Trained batch 464 in epoch 11, gen_loss = 0.4460203077844394, disc_loss = 0.03929652244012843
Trained batch 465 in epoch 11, gen_loss = 0.44600913331488173, disc_loss = 0.03924547842715751
Trained batch 466 in epoch 11, gen_loss = 0.4458988783701584, disc_loss = 0.03928961954428565
Trained batch 467 in epoch 11, gen_loss = 0.44578858605052674, disc_loss = 0.03926119443355526
Trained batch 468 in epoch 11, gen_loss = 0.44600175305216044, disc_loss = 0.039286119988493955
Trained batch 469 in epoch 11, gen_loss = 0.44607763131882283, disc_loss = 0.03925713325077866
Trained batch 470 in epoch 11, gen_loss = 0.44599334924084366, disc_loss = 0.039258117783585296
Trained batch 471 in epoch 11, gen_loss = 0.4461253159758398, disc_loss = 0.03919922729748917
Trained batch 472 in epoch 11, gen_loss = 0.4459931047723863, disc_loss = 0.039187088778073136
Trained batch 473 in epoch 11, gen_loss = 0.446013335248589, disc_loss = 0.03927570378274228
Trained batch 474 in epoch 11, gen_loss = 0.4459904502567492, disc_loss = 0.039213368484848424
Trained batch 475 in epoch 11, gen_loss = 0.44599768200090956, disc_loss = 0.03914009055764485
Trained batch 476 in epoch 11, gen_loss = 0.445987681860194, disc_loss = 0.039102122535152
Trained batch 477 in epoch 11, gen_loss = 0.44616780875866385, disc_loss = 0.03904099027318374
Trained batch 478 in epoch 11, gen_loss = 0.44655346627772974, disc_loss = 0.03932728169443152
Trained batch 479 in epoch 11, gen_loss = 0.44656674172729255, disc_loss = 0.039322481240378696
Trained batch 480 in epoch 11, gen_loss = 0.4465574751029143, disc_loss = 0.039305078541461126
Trained batch 481 in epoch 11, gen_loss = 0.44658278361643006, disc_loss = 0.039269500027538214
Trained batch 482 in epoch 11, gen_loss = 0.44661945190982544, disc_loss = 0.039217182645269556
Trained batch 483 in epoch 11, gen_loss = 0.44673488455370436, disc_loss = 0.03916783269094534
Trained batch 484 in epoch 11, gen_loss = 0.4467218362178999, disc_loss = 0.03914364388923055
Trained batch 485 in epoch 11, gen_loss = 0.4466208356888696, disc_loss = 0.039144462518731264
Trained batch 486 in epoch 11, gen_loss = 0.4468289734891308, disc_loss = 0.039257692023958755
Trained batch 487 in epoch 11, gen_loss = 0.44679325263275477, disc_loss = 0.03924544539577404
Trained batch 488 in epoch 11, gen_loss = 0.44675933473680646, disc_loss = 0.03934582695364952
Trained batch 489 in epoch 11, gen_loss = 0.4468238867059046, disc_loss = 0.03966009071743002
Trained batch 490 in epoch 11, gen_loss = 0.4467728474839399, disc_loss = 0.03978984280206764
Trained batch 491 in epoch 11, gen_loss = 0.4466952093975331, disc_loss = 0.039798616583088066
Trained batch 492 in epoch 11, gen_loss = 0.44681346597826266, disc_loss = 0.03992119527461563
Trained batch 493 in epoch 11, gen_loss = 0.44684106919929567, disc_loss = 0.0399063989324005
Trained batch 494 in epoch 11, gen_loss = 0.44679275100881405, disc_loss = 0.039888118350445624
Trained batch 495 in epoch 11, gen_loss = 0.44671806212394466, disc_loss = 0.039877045246201656
Trained batch 496 in epoch 11, gen_loss = 0.4468194994048573, disc_loss = 0.039850202597063074
Trained batch 497 in epoch 11, gen_loss = 0.44683639968494815, disc_loss = 0.03978944647810366
Trained batch 498 in epoch 11, gen_loss = 0.4467741349536575, disc_loss = 0.039834173103208415
Trained batch 499 in epoch 11, gen_loss = 0.4466552271842957, disc_loss = 0.0397809482216835
Trained batch 500 in epoch 11, gen_loss = 0.44659106567234336, disc_loss = 0.039761573448033626
Trained batch 501 in epoch 11, gen_loss = 0.44676199377295506, disc_loss = 0.03981969406108457
Trained batch 502 in epoch 11, gen_loss = 0.446748234287171, disc_loss = 0.03985119871721116
Trained batch 503 in epoch 11, gen_loss = 0.4468145711081369, disc_loss = 0.03980483308375355
Trained batch 504 in epoch 11, gen_loss = 0.44686708698178285, disc_loss = 0.03976011788933584
Trained batch 505 in epoch 11, gen_loss = 0.44688462669199164, disc_loss = 0.039707313207062805
Trained batch 506 in epoch 11, gen_loss = 0.4468504003519137, disc_loss = 0.039643784421009305
Trained batch 507 in epoch 11, gen_loss = 0.44673378929847807, disc_loss = 0.03960171862373378
Trained batch 508 in epoch 11, gen_loss = 0.44650363945539434, disc_loss = 0.03954271012496328
Trained batch 509 in epoch 11, gen_loss = 0.44663357349003063, disc_loss = 0.03956934282848356
Trained batch 510 in epoch 11, gen_loss = 0.4465281102522012, disc_loss = 0.039529435961724146
Trained batch 511 in epoch 11, gen_loss = 0.44649285438936204, disc_loss = 0.0394999725958769
Trained batch 512 in epoch 11, gen_loss = 0.44665444199337134, disc_loss = 0.03943374579078854
Trained batch 513 in epoch 11, gen_loss = 0.4468541327385587, disc_loss = 0.03937422129749556
Trained batch 514 in epoch 11, gen_loss = 0.44671559727307664, disc_loss = 0.03961017359662982
Trained batch 515 in epoch 11, gen_loss = 0.4467967024376226, disc_loss = 0.03961904449460581
Trained batch 516 in epoch 11, gen_loss = 0.44679108244768656, disc_loss = 0.03958305467561435
Trained batch 517 in epoch 11, gen_loss = 0.44684986839193175, disc_loss = 0.03952935175488354
Trained batch 518 in epoch 11, gen_loss = 0.4469258834057001, disc_loss = 0.039478054646984
Trained batch 519 in epoch 11, gen_loss = 0.44688059257773255, disc_loss = 0.03945964890747116
Trained batch 520 in epoch 11, gen_loss = 0.4468616975360548, disc_loss = 0.03939701401630341
Trained batch 521 in epoch 11, gen_loss = 0.44673362551292695, disc_loss = 0.03935168347128763
Trained batch 522 in epoch 11, gen_loss = 0.4467922381871517, disc_loss = 0.039301352572750234
Trained batch 523 in epoch 11, gen_loss = 0.44692160450775203, disc_loss = 0.0392400243911423
Trained batch 524 in epoch 11, gen_loss = 0.44681727000645227, disc_loss = 0.03919442932786686
Trained batch 525 in epoch 11, gen_loss = 0.4468238293104752, disc_loss = 0.039134289570924734
Trained batch 526 in epoch 11, gen_loss = 0.4466434161283033, disc_loss = 0.03906940164192946
Trained batch 527 in epoch 11, gen_loss = 0.44670263322239573, disc_loss = 0.03901056679420766
Trained batch 528 in epoch 11, gen_loss = 0.4467229364837726, disc_loss = 0.0389507354434319
Trained batch 529 in epoch 11, gen_loss = 0.4466997448565825, disc_loss = 0.03888955597133147
Trained batch 530 in epoch 11, gen_loss = 0.4467398938486132, disc_loss = 0.03882468361214589
Trained batch 531 in epoch 11, gen_loss = 0.44657946618876065, disc_loss = 0.038788772467348756
Trained batch 532 in epoch 11, gen_loss = 0.44634907498368626, disc_loss = 0.03877139577159822
Trained batch 533 in epoch 11, gen_loss = 0.4462418392691273, disc_loss = 0.03870677224391799
Trained batch 534 in epoch 11, gen_loss = 0.446047977977824, disc_loss = 0.03865014748456322
Trained batch 535 in epoch 11, gen_loss = 0.4461062866360394, disc_loss = 0.038623154785400675
Trained batch 536 in epoch 11, gen_loss = 0.4461224776184537, disc_loss = 0.0385719020044504
Trained batch 537 in epoch 11, gen_loss = 0.4462229302603073, disc_loss = 0.03852065697097701
Trained batch 538 in epoch 11, gen_loss = 0.44627390633266356, disc_loss = 0.03858656946445274
Trained batch 539 in epoch 11, gen_loss = 0.44621015268343467, disc_loss = 0.03853973894104085
Trained batch 540 in epoch 11, gen_loss = 0.44615501325143686, disc_loss = 0.03850819720144688
Trained batch 541 in epoch 11, gen_loss = 0.4462377311888656, disc_loss = 0.03854699079737727
Trained batch 542 in epoch 11, gen_loss = 0.44638075689145434, disc_loss = 0.03849480418972054
Trained batch 543 in epoch 11, gen_loss = 0.4463856765890823, disc_loss = 0.03843386275762254
Trained batch 544 in epoch 11, gen_loss = 0.4463619203742491, disc_loss = 0.038371070978496596
Trained batch 545 in epoch 11, gen_loss = 0.4463764028453128, disc_loss = 0.0383137073538406
Trained batch 546 in epoch 11, gen_loss = 0.4462939230027103, disc_loss = 0.03834238633772246
Trained batch 547 in epoch 11, gen_loss = 0.44630267155649017, disc_loss = 0.038340207750154454
Trained batch 548 in epoch 11, gen_loss = 0.44625447600917084, disc_loss = 0.038355937668670285
Trained batch 549 in epoch 11, gen_loss = 0.4462326866388321, disc_loss = 0.0383649263700301
Trained batch 550 in epoch 11, gen_loss = 0.4463614452015034, disc_loss = 0.03837691470913034
Trained batch 551 in epoch 11, gen_loss = 0.44628953966109647, disc_loss = 0.03836483638261216
Trained batch 552 in epoch 11, gen_loss = 0.4463813012806028, disc_loss = 0.038364007055193564
Trained batch 553 in epoch 11, gen_loss = 0.4463608987925285, disc_loss = 0.03832629254081081
Trained batch 554 in epoch 11, gen_loss = 0.44642005788313377, disc_loss = 0.038284539968312326
Trained batch 555 in epoch 11, gen_loss = 0.44658888624512033, disc_loss = 0.03834339743815095
Trained batch 556 in epoch 11, gen_loss = 0.44646376355332146, disc_loss = 0.03830488554504658
Trained batch 557 in epoch 11, gen_loss = 0.44628158062162365, disc_loss = 0.03836664303763366
Trained batch 558 in epoch 11, gen_loss = 0.44637837915386414, disc_loss = 0.0383691697419756
Trained batch 559 in epoch 11, gen_loss = 0.4463078129504408, disc_loss = 0.03834331049583852
Trained batch 560 in epoch 11, gen_loss = 0.44630070750513606, disc_loss = 0.03829112303162694
Trained batch 561 in epoch 11, gen_loss = 0.4461616993586788, disc_loss = 0.03832408609001291
Trained batch 562 in epoch 11, gen_loss = 0.4462168815927861, disc_loss = 0.038266089908633096
Trained batch 563 in epoch 11, gen_loss = 0.4462062285301533, disc_loss = 0.03821625032112108
Trained batch 564 in epoch 11, gen_loss = 0.44632520011041016, disc_loss = 0.0381872587433431
Trained batch 565 in epoch 11, gen_loss = 0.44638478239938983, disc_loss = 0.038126018099065594
Trained batch 566 in epoch 11, gen_loss = 0.4464845263138019, disc_loss = 0.03806517398226316
Trained batch 567 in epoch 11, gen_loss = 0.4465239002880916, disc_loss = 0.038013267393542036
Trained batch 568 in epoch 11, gen_loss = 0.44649716420835683, disc_loss = 0.03795663231406001
Trained batch 569 in epoch 11, gen_loss = 0.4464770044673953, disc_loss = 0.03789386704131111
Trained batch 570 in epoch 11, gen_loss = 0.44658036548285474, disc_loss = 0.037842655209857065
Trained batch 571 in epoch 11, gen_loss = 0.446654812908256, disc_loss = 0.03778159824709597
Trained batch 572 in epoch 11, gen_loss = 0.44670684154537127, disc_loss = 0.03772265635256901
Trained batch 573 in epoch 11, gen_loss = 0.44670277672985287, disc_loss = 0.037661627195824186
Trained batch 574 in epoch 11, gen_loss = 0.4466903986619866, disc_loss = 0.03760469953691506
Trained batch 575 in epoch 11, gen_loss = 0.4466716916196876, disc_loss = 0.0375492852177154
Trained batch 576 in epoch 11, gen_loss = 0.44649746549191466, disc_loss = 0.037492733533886394
Trained batch 577 in epoch 11, gen_loss = 0.4465542495456946, disc_loss = 0.037457252470341394
Trained batch 578 in epoch 11, gen_loss = 0.4464414156265621, disc_loss = 0.037421537149417664
Trained batch 579 in epoch 11, gen_loss = 0.4465829678136727, disc_loss = 0.03736541824824787
Trained batch 580 in epoch 11, gen_loss = 0.4465145076306059, disc_loss = 0.037310288004375185
Trained batch 581 in epoch 11, gen_loss = 0.44664581980287416, disc_loss = 0.03725255506762857
Trained batch 582 in epoch 11, gen_loss = 0.44666666226975915, disc_loss = 0.03719241230462647
Trained batch 583 in epoch 11, gen_loss = 0.44664755172721327, disc_loss = 0.037131772995152995
Trained batch 584 in epoch 11, gen_loss = 0.4466660806765923, disc_loss = 0.037077204360722156
Trained batch 585 in epoch 11, gen_loss = 0.4466458071315655, disc_loss = 0.037028891005618465
Trained batch 586 in epoch 11, gen_loss = 0.446540549524395, disc_loss = 0.03697396602518888
Trained batch 587 in epoch 11, gen_loss = 0.44642667624415183, disc_loss = 0.036914235582617964
Trained batch 588 in epoch 11, gen_loss = 0.446554109175865, disc_loss = 0.036902456264270876
Trained batch 589 in epoch 11, gen_loss = 0.44647033694436994, disc_loss = 0.03685688676008702
Trained batch 590 in epoch 11, gen_loss = 0.44645333234630463, disc_loss = 0.03680249438924453
Trained batch 591 in epoch 11, gen_loss = 0.4464534415888625, disc_loss = 0.03674748406813927
Trained batch 592 in epoch 11, gen_loss = 0.44654864329109706, disc_loss = 0.03669144576914062
Trained batch 593 in epoch 11, gen_loss = 0.4465573932285662, disc_loss = 0.03663898519415139
Trained batch 594 in epoch 11, gen_loss = 0.446546039310824, disc_loss = 0.0365830781679804
Trained batch 595 in epoch 11, gen_loss = 0.44660090010038156, disc_loss = 0.03652772926955934
Trained batch 596 in epoch 11, gen_loss = 0.4465871154762792, disc_loss = 0.036472686272936636
Trained batch 597 in epoch 11, gen_loss = 0.44663400584240026, disc_loss = 0.03641549757830518
Trained batch 598 in epoch 11, gen_loss = 0.44662041417346376, disc_loss = 0.0363629343388882
Trained batch 599 in epoch 11, gen_loss = 0.4466098439693451, disc_loss = 0.03631070113721459
Trained batch 600 in epoch 11, gen_loss = 0.4465654037657276, disc_loss = 0.03625342551232959
Trained batch 601 in epoch 11, gen_loss = 0.446609421178352, disc_loss = 0.0361983993851063
Trained batch 602 in epoch 11, gen_loss = 0.4466837659898287, disc_loss = 0.03614283868059158
Trained batch 603 in epoch 11, gen_loss = 0.4466694293926094, disc_loss = 0.036096147053785596
Trained batch 604 in epoch 11, gen_loss = 0.4466415614628595, disc_loss = 0.036042892307905125
Trained batch 605 in epoch 11, gen_loss = 0.446658126641028, disc_loss = 0.035990835192056966
Trained batch 606 in epoch 11, gen_loss = 0.44663226481717344, disc_loss = 0.03593775960332921
Trained batch 607 in epoch 11, gen_loss = 0.4467011512698312, disc_loss = 0.03588302156008707
Trained batch 608 in epoch 11, gen_loss = 0.44685812644379086, disc_loss = 0.03583540750379951
Trained batch 609 in epoch 11, gen_loss = 0.44685070612391486, disc_loss = 0.03578203180423159
Trained batch 610 in epoch 11, gen_loss = 0.4468427697004546, disc_loss = 0.03573093247796529
Trained batch 611 in epoch 11, gen_loss = 0.44675903577430576, disc_loss = 0.035675205908916596
Trained batch 612 in epoch 11, gen_loss = 0.4468566144271154, disc_loss = 0.03562406138068773
Trained batch 613 in epoch 11, gen_loss = 0.4469240188889861, disc_loss = 0.03557186365106328
Trained batch 614 in epoch 11, gen_loss = 0.44691669277059354, disc_loss = 0.0355232126685238
Trained batch 615 in epoch 11, gen_loss = 0.44690570365879445, disc_loss = 0.03547428698995598
Trained batch 616 in epoch 11, gen_loss = 0.44692940027053, disc_loss = 0.03542192234405629
Trained batch 617 in epoch 11, gen_loss = 0.4469566674101314, disc_loss = 0.03537179526803611
Trained batch 618 in epoch 11, gen_loss = 0.4469721604722382, disc_loss = 0.03531904375783931
Trained batch 619 in epoch 11, gen_loss = 0.4470274037411136, disc_loss = 0.03528569523027287
Trained batch 620 in epoch 11, gen_loss = 0.4470087662699142, disc_loss = 0.03523208621188986
Trained batch 621 in epoch 11, gen_loss = 0.4470731623686395, disc_loss = 0.035185913816977804
Trained batch 622 in epoch 11, gen_loss = 0.4470795645568382, disc_loss = 0.03513399270037264
Trained batch 623 in epoch 11, gen_loss = 0.4471757240020312, disc_loss = 0.0350850601841021
Trained batch 624 in epoch 11, gen_loss = 0.44713346757888794, disc_loss = 0.03503245485275984
Trained batch 625 in epoch 11, gen_loss = 0.44717516976233107, disc_loss = 0.03498312040416601
Trained batch 626 in epoch 11, gen_loss = 0.4472987599064859, disc_loss = 0.03493329324199561
Trained batch 627 in epoch 11, gen_loss = 0.4473966137523864, disc_loss = 0.03488116449962673
Trained batch 628 in epoch 11, gen_loss = 0.44737498620924776, disc_loss = 0.034830390375747165
Trained batch 629 in epoch 11, gen_loss = 0.4474056585913613, disc_loss = 0.03477809136227099
Trained batch 630 in epoch 11, gen_loss = 0.4475254575631887, disc_loss = 0.03472857961003859
Trained batch 631 in epoch 11, gen_loss = 0.44759238412297225, disc_loss = 0.034679233224191586
Trained batch 632 in epoch 11, gen_loss = 0.44755634109932474, disc_loss = 0.03462884513242685
Trained batch 633 in epoch 11, gen_loss = 0.4474354132962904, disc_loss = 0.03457799220104388
Trained batch 634 in epoch 11, gen_loss = 0.4474581215794631, disc_loss = 0.034526955985141494
Trained batch 635 in epoch 11, gen_loss = 0.4474674384548979, disc_loss = 0.03447633492449187
Trained batch 636 in epoch 11, gen_loss = 0.4475669422928168, disc_loss = 0.03442632987253877
Trained batch 637 in epoch 11, gen_loss = 0.4475639044864798, disc_loss = 0.03437486589177538
Trained batch 638 in epoch 11, gen_loss = 0.44765067790782137, disc_loss = 0.03432340868140231
Trained batch 639 in epoch 11, gen_loss = 0.44766820608638225, disc_loss = 0.03427506917851133
Trained batch 640 in epoch 11, gen_loss = 0.44768165616832917, disc_loss = 0.03422482222389116
Trained batch 641 in epoch 11, gen_loss = 0.44761665796750805, disc_loss = 0.03417364303098783
Trained batch 642 in epoch 11, gen_loss = 0.44757335159122297, disc_loss = 0.03412416751744895
Trained batch 643 in epoch 11, gen_loss = 0.44758016338444645, disc_loss = 0.0340760295311501
Trained batch 644 in epoch 11, gen_loss = 0.4475865767907727, disc_loss = 0.034026430096917665
Trained batch 645 in epoch 11, gen_loss = 0.44750360424858127, disc_loss = 0.03397759350341811
Trained batch 646 in epoch 11, gen_loss = 0.4475488995289692, disc_loss = 0.033928507618883906
Trained batch 647 in epoch 11, gen_loss = 0.44748959717927156, disc_loss = 0.03387894690249483
Trained batch 648 in epoch 11, gen_loss = 0.4475710544453931, disc_loss = 0.03383030273875534
Trained batch 649 in epoch 11, gen_loss = 0.44745361286860247, disc_loss = 0.033782098387511304
Trained batch 650 in epoch 11, gen_loss = 0.4474182472708771, disc_loss = 0.033732340525558215
Trained batch 651 in epoch 11, gen_loss = 0.4475043908310083, disc_loss = 0.03368339332037011
Trained batch 652 in epoch 11, gen_loss = 0.4475823247870844, disc_loss = 0.03363441510210142
Trained batch 653 in epoch 11, gen_loss = 0.4476910252181033, disc_loss = 0.03358739437158034
Trained batch 654 in epoch 11, gen_loss = 0.4476810733325609, disc_loss = 0.03353994351363819
Trained batch 655 in epoch 11, gen_loss = 0.4476565254806745, disc_loss = 0.03349172293241193
Trained batch 656 in epoch 11, gen_loss = 0.4476213439323768, disc_loss = 0.03344377052092774
Trained batch 657 in epoch 11, gen_loss = 0.4476528709420317, disc_loss = 0.033396880814698056
Trained batch 658 in epoch 11, gen_loss = 0.44767107415452534, disc_loss = 0.03335090119346456
Trained batch 659 in epoch 11, gen_loss = 0.44756599488583476, disc_loss = 0.03330449794179224
Trained batch 660 in epoch 11, gen_loss = 0.44755434548079337, disc_loss = 0.033256250786392154
Trained batch 661 in epoch 11, gen_loss = 0.447539972484652, disc_loss = 0.033210603119854694
Trained batch 662 in epoch 11, gen_loss = 0.4475041317723995, disc_loss = 0.03316340841922549
Trained batch 663 in epoch 11, gen_loss = 0.4474166383944362, disc_loss = 0.033117929567317815
Trained batch 664 in epoch 11, gen_loss = 0.447280078095601, disc_loss = 0.03307645308480535
Trained batch 665 in epoch 11, gen_loss = 0.4472615366225486, disc_loss = 0.03303015728704156
Trained batch 666 in epoch 11, gen_loss = 0.44722455565718516, disc_loss = 0.03298428930349877
Trained batch 667 in epoch 11, gen_loss = 0.44729830409416893, disc_loss = 0.03293969352296721
Trained batch 668 in epoch 11, gen_loss = 0.4472963911090018, disc_loss = 0.032893074941069654
Trained batch 669 in epoch 11, gen_loss = 0.44734276506438186, disc_loss = 0.032848117445116
Trained batch 670 in epoch 11, gen_loss = 0.4473592917894287, disc_loss = 0.03280151763014168
Trained batch 671 in epoch 11, gen_loss = 0.44734185712323304, disc_loss = 0.032754963349968115
Trained batch 672 in epoch 11, gen_loss = 0.44733640998823326, disc_loss = 0.03270853524245765
Trained batch 673 in epoch 11, gen_loss = 0.44717810937488117, disc_loss = 0.0326616429814997
Trained batch 674 in epoch 11, gen_loss = 0.4472300864149023, disc_loss = 0.03261592302799087
Trained batch 675 in epoch 11, gen_loss = 0.4472233361217397, disc_loss = 0.032569727521305686
Trained batch 676 in epoch 11, gen_loss = 0.4471467263237236, disc_loss = 0.03252366229226645
Trained batch 677 in epoch 11, gen_loss = 0.44703282389493115, disc_loss = 0.032485942817313714
Trained batch 678 in epoch 11, gen_loss = 0.4470722877224345, disc_loss = 0.03244180947049097
Trained batch 679 in epoch 11, gen_loss = 0.44701047767611113, disc_loss = 0.03239858276878401
Trained batch 680 in epoch 11, gen_loss = 0.4470412876462446, disc_loss = 0.03235401150653557
Trained batch 681 in epoch 11, gen_loss = 0.4470306443940859, disc_loss = 0.03232481036880777
Trained batch 682 in epoch 11, gen_loss = 0.44696526694088345, disc_loss = 0.032279954998042176
Trained batch 683 in epoch 11, gen_loss = 0.4468366067573341, disc_loss = 0.032241890492014404
Trained batch 684 in epoch 11, gen_loss = 0.44685519363758336, disc_loss = 0.03220808693687058
Trained batch 685 in epoch 11, gen_loss = 0.44684760046596084, disc_loss = 0.03217361729002202
Trained batch 686 in epoch 11, gen_loss = 0.44672982557371715, disc_loss = 0.03213000351687137
Trained batch 687 in epoch 11, gen_loss = 0.44670616991298145, disc_loss = 0.03208772645742757
Trained batch 688 in epoch 11, gen_loss = 0.4467265080817379, disc_loss = 0.032047547391718535
Trained batch 689 in epoch 11, gen_loss = 0.44682599660279093, disc_loss = 0.03200468538055682
Trained batch 690 in epoch 11, gen_loss = 0.44688004626206485, disc_loss = 0.031960930183998884
Trained batch 691 in epoch 11, gen_loss = 0.4469126537872877, disc_loss = 0.031924594158705084
Trained batch 692 in epoch 11, gen_loss = 0.4468658667966229, disc_loss = 0.03188163625052223
Trained batch 693 in epoch 11, gen_loss = 0.44676840863585127, disc_loss = 0.03186046919632456
Trained batch 694 in epoch 11, gen_loss = 0.44682717271845973, disc_loss = 0.03182099880650639
Trained batch 695 in epoch 11, gen_loss = 0.44679434567518617, disc_loss = 0.03178014679364967
Trained batch 696 in epoch 11, gen_loss = 0.4468098507721079, disc_loss = 0.03174794418870911
Trained batch 697 in epoch 11, gen_loss = 0.4468090327557998, disc_loss = 0.031710274005842455
Trained batch 698 in epoch 11, gen_loss = 0.4467949325775725, disc_loss = 0.031674016524873706
Trained batch 699 in epoch 11, gen_loss = 0.4468385570389884, disc_loss = 0.031635384006159645
Trained batch 700 in epoch 11, gen_loss = 0.44688044958209855, disc_loss = 0.03159677858840403
Trained batch 701 in epoch 11, gen_loss = 0.4469205607630928, disc_loss = 0.03155457155587964
Trained batch 702 in epoch 11, gen_loss = 0.4469412079830767, disc_loss = 0.031522357058717976
Trained batch 703 in epoch 11, gen_loss = 0.44700868360020896, disc_loss = 0.03149195251832928
Trained batch 704 in epoch 11, gen_loss = 0.44707789539445375, disc_loss = 0.0314710329068785
Trained batch 705 in epoch 11, gen_loss = 0.4470822880778029, disc_loss = 0.03143134501778518
Trained batch 706 in epoch 11, gen_loss = 0.44699972707783486, disc_loss = 0.03139571682187759
Trained batch 707 in epoch 11, gen_loss = 0.44699687030860935, disc_loss = 0.03135419010426744
Trained batch 708 in epoch 11, gen_loss = 0.44691070746131273, disc_loss = 0.03132624864415364
Trained batch 709 in epoch 11, gen_loss = 0.44687746465206146, disc_loss = 0.03129975912882618
Trained batch 710 in epoch 11, gen_loss = 0.44696158493453775, disc_loss = 0.031263302931753306
Trained batch 711 in epoch 11, gen_loss = 0.44694223748833944, disc_loss = 0.03122529778642622
Trained batch 712 in epoch 11, gen_loss = 0.44702146414453153, disc_loss = 0.031189340265365878
Trained batch 713 in epoch 11, gen_loss = 0.4470457338652357, disc_loss = 0.031176661653183297
Trained batch 714 in epoch 11, gen_loss = 0.44709326449807707, disc_loss = 0.031174611782824452
Trained batch 715 in epoch 11, gen_loss = 0.4471491234762043, disc_loss = 0.031142593005687707
Trained batch 716 in epoch 11, gen_loss = 0.4471352028048687, disc_loss = 0.031107211308203108
Trained batch 717 in epoch 11, gen_loss = 0.44721505029287845, disc_loss = 0.031073832911670124
Trained batch 718 in epoch 11, gen_loss = 0.44714310665787177, disc_loss = 0.031043118571859988
Trained batch 719 in epoch 11, gen_loss = 0.44707234100335175, disc_loss = 0.03100931533586441
Trained batch 720 in epoch 11, gen_loss = 0.44716348739834333, disc_loss = 0.030971827450493834
Trained batch 721 in epoch 11, gen_loss = 0.4471758056297857, disc_loss = 0.030933934501875347
Trained batch 722 in epoch 11, gen_loss = 0.44716475757655594, disc_loss = 0.030895245193863188
Trained batch 723 in epoch 11, gen_loss = 0.44719593807313984, disc_loss = 0.030855405514221123
Trained batch 724 in epoch 11, gen_loss = 0.44720263267385546, disc_loss = 0.030818555414162833
Trained batch 725 in epoch 11, gen_loss = 0.4472113042741439, disc_loss = 0.030781737175967657
Trained batch 726 in epoch 11, gen_loss = 0.44714204456652046, disc_loss = 0.030743051021509742
Trained batch 727 in epoch 11, gen_loss = 0.44723806235488955, disc_loss = 0.03070382704570695
Trained batch 728 in epoch 11, gen_loss = 0.4472145931220349, disc_loss = 0.03066432711716859
Trained batch 729 in epoch 11, gen_loss = 0.4472421655099686, disc_loss = 0.030624848967481865
Trained batch 730 in epoch 11, gen_loss = 0.44725993483565574, disc_loss = 0.030586945669847845
Trained batch 731 in epoch 11, gen_loss = 0.4472072976615911, disc_loss = 0.030547027545154114
Trained batch 732 in epoch 11, gen_loss = 0.447233437516029, disc_loss = 0.03050787108146686
Trained batch 733 in epoch 11, gen_loss = 0.44726813302377916, disc_loss = 0.030471391439005194
Trained batch 734 in epoch 11, gen_loss = 0.4472159468803276, disc_loss = 0.03043198626358569
Trained batch 735 in epoch 11, gen_loss = 0.44720374019411596, disc_loss = 0.030393059700461734
Trained batch 736 in epoch 11, gen_loss = 0.44717734469811016, disc_loss = 0.03035631972135094
Trained batch 737 in epoch 11, gen_loss = 0.4471197086298046, disc_loss = 0.030317564734836995
Trained batch 738 in epoch 11, gen_loss = 0.44707566080299865, disc_loss = 0.03027876899927396
Trained batch 739 in epoch 11, gen_loss = 0.44707019828461314, disc_loss = 0.030240995095684068
Trained batch 740 in epoch 11, gen_loss = 0.44711900650248354, disc_loss = 0.03020269106982424
Trained batch 741 in epoch 11, gen_loss = 0.44715411049336434, disc_loss = 0.030164181934625684
Trained batch 742 in epoch 11, gen_loss = 0.44716195078268345, disc_loss = 0.030133581494199285
Trained batch 743 in epoch 11, gen_loss = 0.44715666534599435, disc_loss = 0.030099826144656637
Trained batch 744 in epoch 11, gen_loss = 0.44717924694886946, disc_loss = 0.030062311502242298
Trained batch 745 in epoch 11, gen_loss = 0.4471634921215814, disc_loss = 0.030024325984296697
Testing Epoch 11
Training Epoch 12
Trained batch 0 in epoch 12, gen_loss = 0.5475272536277771, disc_loss = 0.002659723861142993
Trained batch 1 in epoch 12, gen_loss = 0.4940876066684723, disc_loss = 0.0025685116415843368
Trained batch 2 in epoch 12, gen_loss = 0.4838568965593974, disc_loss = 0.0030058179205904403
Trained batch 3 in epoch 12, gen_loss = 0.4884263277053833, disc_loss = 0.002723400539252907
Trained batch 4 in epoch 12, gen_loss = 0.4930931806564331, disc_loss = 0.0028166058473289013
Trained batch 5 in epoch 12, gen_loss = 0.4959571659564972, disc_loss = 0.002852390520274639
Trained batch 6 in epoch 12, gen_loss = 0.48806847419057575, disc_loss = 0.002911945339292288
Trained batch 7 in epoch 12, gen_loss = 0.4858422093093395, disc_loss = 0.0031081201159395278
Trained batch 8 in epoch 12, gen_loss = 0.48371751109759015, disc_loss = 0.0030640029969314733
Trained batch 9 in epoch 12, gen_loss = 0.48009871542453764, disc_loss = 0.003004154562950134
Trained batch 10 in epoch 12, gen_loss = 0.47883656891909515, disc_loss = 0.003008761146867817
Trained batch 11 in epoch 12, gen_loss = 0.47537752240896225, disc_loss = 0.0030999097895498076
Trained batch 12 in epoch 12, gen_loss = 0.47195089092621434, disc_loss = 0.00303248749472774
Trained batch 13 in epoch 12, gen_loss = 0.4647982290812901, disc_loss = 0.0029505229654854964
Trained batch 14 in epoch 12, gen_loss = 0.46640015244483946, disc_loss = 0.0028546323146050176
Trained batch 15 in epoch 12, gen_loss = 0.46601251140236855, disc_loss = 0.002765845194517169
Trained batch 16 in epoch 12, gen_loss = 0.4678640313008252, disc_loss = 0.003564678495475913
Trained batch 17 in epoch 12, gen_loss = 0.4651167160934872, disc_loss = 0.003693191366942806
Trained batch 18 in epoch 12, gen_loss = 0.4642100585134406, disc_loss = 0.0038011071431499565
Trained batch 19 in epoch 12, gen_loss = 0.4622068464756012, disc_loss = 0.0037930830440018326
Trained batch 20 in epoch 12, gen_loss = 0.4583443970907302, disc_loss = 0.0036803047904478653
Trained batch 21 in epoch 12, gen_loss = 0.45641910894350574, disc_loss = 0.0036020448473705487
Trained batch 22 in epoch 12, gen_loss = 0.4557614572670149, disc_loss = 0.0037673926993232708
Trained batch 23 in epoch 12, gen_loss = 0.45348307862877846, disc_loss = 0.00376962842225718
Trained batch 24 in epoch 12, gen_loss = 0.45246925711631775, disc_loss = 0.0037425185088068246
Trained batch 25 in epoch 12, gen_loss = 0.45213299645827365, disc_loss = 0.00368978193280502
Trained batch 26 in epoch 12, gen_loss = 0.4513699886975465, disc_loss = 0.004367531199629108
Trained batch 27 in epoch 12, gen_loss = 0.4529224804469517, disc_loss = 0.004365633499609041
Trained batch 28 in epoch 12, gen_loss = 0.45359234768768836, disc_loss = 0.00521229264519081
Trained batch 29 in epoch 12, gen_loss = 0.45750089089075724, disc_loss = 0.005246184603311122
Trained batch 30 in epoch 12, gen_loss = 0.4565874934196472, disc_loss = 0.006017334661596725
Trained batch 31 in epoch 12, gen_loss = 0.45750144589692354, disc_loss = 0.0074304661466157995
Trained batch 32 in epoch 12, gen_loss = 0.4592193482500134, disc_loss = 0.007678094143612367
Trained batch 33 in epoch 12, gen_loss = 0.45812008749036226, disc_loss = 0.010264264878488201
Trained batch 34 in epoch 12, gen_loss = 0.45876692959240506, disc_loss = 0.011712394142523407
Trained batch 35 in epoch 12, gen_loss = 0.458294067117903, disc_loss = 0.012684477926490622
Trained batch 36 in epoch 12, gen_loss = 0.45781997812760844, disc_loss = 0.012518373185869408
Trained batch 37 in epoch 12, gen_loss = 0.4567168653011322, disc_loss = 0.012732246590435113
Trained batch 38 in epoch 12, gen_loss = 0.4554023857300098, disc_loss = 0.012507437996996136
Trained batch 39 in epoch 12, gen_loss = 0.4557716317474842, disc_loss = 0.012724196730414406
Trained batch 40 in epoch 12, gen_loss = 0.45291080053259686, disc_loss = 0.0132236299956808
Trained batch 41 in epoch 12, gen_loss = 0.4496855168115525, disc_loss = 0.014487760324430252
Trained batch 42 in epoch 12, gen_loss = 0.45061393047488013, disc_loss = 0.014283306772149233
Trained batch 43 in epoch 12, gen_loss = 0.44917571070519363, disc_loss = 0.014096743654756045
Trained batch 44 in epoch 12, gen_loss = 0.4501615047454834, disc_loss = 0.013937022800867756
Trained batch 45 in epoch 12, gen_loss = 0.45244567679322284, disc_loss = 0.013775481584319927
Trained batch 46 in epoch 12, gen_loss = 0.4514447640865407, disc_loss = 0.013656879383872481
Trained batch 47 in epoch 12, gen_loss = 0.45156602499385673, disc_loss = 0.0134527297874835
Trained batch 48 in epoch 12, gen_loss = 0.4519956190975345, disc_loss = 0.014617981308386947
Trained batch 49 in epoch 12, gen_loss = 0.4503623467683792, disc_loss = 0.01745982881169766
Trained batch 50 in epoch 12, gen_loss = 0.44967523801560494, disc_loss = 0.017599037716019096
Trained batch 51 in epoch 12, gen_loss = 0.4480157190790543, disc_loss = 0.018641609371675607
Trained batch 52 in epoch 12, gen_loss = 0.4476870967532104, disc_loss = 0.018821389040962425
Trained batch 53 in epoch 12, gen_loss = 0.44800113417484144, disc_loss = 0.01865426843761708
Trained batch 54 in epoch 12, gen_loss = 0.4494700074195862, disc_loss = 0.01844041470692239
Trained batch 55 in epoch 12, gen_loss = 0.4486884240593229, disc_loss = 0.018322198730727126
Trained batch 56 in epoch 12, gen_loss = 0.44841368261136505, disc_loss = 0.018459322433428543
Trained batch 57 in epoch 12, gen_loss = 0.44972045565473623, disc_loss = 0.01821330720799622
Trained batch 58 in epoch 12, gen_loss = 0.44944078942476695, disc_loss = 0.018176598549362714
Trained batch 59 in epoch 12, gen_loss = 0.44885579248269397, disc_loss = 0.018044320909151187
Trained batch 60 in epoch 12, gen_loss = 0.44897796726617656, disc_loss = 0.017812334462908693
Trained batch 61 in epoch 12, gen_loss = 0.44872790094344844, disc_loss = 0.018317243478621445
Trained batch 62 in epoch 12, gen_loss = 0.4492978207648747, disc_loss = 0.01817660261729052
Trained batch 63 in epoch 12, gen_loss = 0.45016434602439404, disc_loss = 0.01830669879927882
Trained batch 64 in epoch 12, gen_loss = 0.44960766434669497, disc_loss = 0.023093452050278965
Trained batch 65 in epoch 12, gen_loss = 0.4492296264930205, disc_loss = 0.023861369996500962
Trained batch 66 in epoch 12, gen_loss = 0.4484760205247509, disc_loss = 0.02428936883598677
Trained batch 67 in epoch 12, gen_loss = 0.4483689087278703, disc_loss = 0.02417685426018365
Trained batch 68 in epoch 12, gen_loss = 0.44809684027796204, disc_loss = 0.024151052662130933
Trained batch 69 in epoch 12, gen_loss = 0.4466428292649133, disc_loss = 0.02392214946781418
Trained batch 70 in epoch 12, gen_loss = 0.4468562107690623, disc_loss = 0.023775210082662146
Trained batch 71 in epoch 12, gen_loss = 0.44581393400828045, disc_loss = 0.025201290461053658
Trained batch 72 in epoch 12, gen_loss = 0.44629664372091427, disc_loss = 0.02528335651931391
Trained batch 73 in epoch 12, gen_loss = 0.44717219149744186, disc_loss = 0.025273344532989368
Trained batch 74 in epoch 12, gen_loss = 0.44767887075742085, disc_loss = 0.025530229238793254
Trained batch 75 in epoch 12, gen_loss = 0.4477505523123239, disc_loss = 0.025295208309360436
Trained batch 76 in epoch 12, gen_loss = 0.4471436111957996, disc_loss = 0.02515556080593401
Trained batch 77 in epoch 12, gen_loss = 0.4463658959437639, disc_loss = 0.024898499169816766
Trained batch 78 in epoch 12, gen_loss = 0.44635162662856187, disc_loss = 0.02462222202551327
Trained batch 79 in epoch 12, gen_loss = 0.4466774918138981, disc_loss = 0.024375004653120414
Trained batch 80 in epoch 12, gen_loss = 0.44626583287745347, disc_loss = 0.024110535901315785
Trained batch 81 in epoch 12, gen_loss = 0.4458023164330459, disc_loss = 0.02389175563528225
Trained batch 82 in epoch 12, gen_loss = 0.4456764344709465, disc_loss = 0.02363047838009086
Trained batch 83 in epoch 12, gen_loss = 0.4459118977898643, disc_loss = 0.023434785438612812
Trained batch 84 in epoch 12, gen_loss = 0.44564823823816635, disc_loss = 0.023523226730963763
Trained batch 85 in epoch 12, gen_loss = 0.44519088850464933, disc_loss = 0.023296777148146267
Trained batch 86 in epoch 12, gen_loss = 0.445308379743291, disc_loss = 0.02310402623923688
Trained batch 87 in epoch 12, gen_loss = 0.44536818970333447, disc_loss = 0.02290949155576527
Trained batch 88 in epoch 12, gen_loss = 0.44536823235201034, disc_loss = 0.022670988591251832
Trained batch 89 in epoch 12, gen_loss = 0.4450692769553926, disc_loss = 0.022448557808012186
Trained batch 90 in epoch 12, gen_loss = 0.44501680102977126, disc_loss = 0.022253006651925925
Trained batch 91 in epoch 12, gen_loss = 0.4446700795189194, disc_loss = 0.022071926957046937
Trained batch 92 in epoch 12, gen_loss = 0.4455541977959295, disc_loss = 0.02188039311803677
Trained batch 93 in epoch 12, gen_loss = 0.4451311791830875, disc_loss = 0.021734652467359332
Trained batch 94 in epoch 12, gen_loss = 0.4443994286813234, disc_loss = 0.021536710293424365
Trained batch 95 in epoch 12, gen_loss = 0.4444353540117542, disc_loss = 0.02135226409275977
Trained batch 96 in epoch 12, gen_loss = 0.4441780023968097, disc_loss = 0.02115972911262136
Trained batch 97 in epoch 12, gen_loss = 0.44366504221546404, disc_loss = 0.020982401382548695
Trained batch 98 in epoch 12, gen_loss = 0.4433885415395101, disc_loss = 0.020802604162717484
Trained batch 99 in epoch 12, gen_loss = 0.4425393825769424, disc_loss = 0.020769145895028488
Trained batch 100 in epoch 12, gen_loss = 0.4424571421476874, disc_loss = 0.02061966259498149
Trained batch 101 in epoch 12, gen_loss = 0.4421771300189635, disc_loss = 0.020483085005681086
Trained batch 102 in epoch 12, gen_loss = 0.44180428894978124, disc_loss = 0.020317299102740452
Trained batch 103 in epoch 12, gen_loss = 0.4414273606469998, disc_loss = 0.020284283432724457
Trained batch 104 in epoch 12, gen_loss = 0.4412238169284094, disc_loss = 0.020299919882035326
Trained batch 105 in epoch 12, gen_loss = 0.4414784053586564, disc_loss = 0.020140883990537095
Trained batch 106 in epoch 12, gen_loss = 0.44198203003295117, disc_loss = 0.020058361224821446
Trained batch 107 in epoch 12, gen_loss = 0.44198014200837527, disc_loss = 0.019973262776922504
Trained batch 108 in epoch 12, gen_loss = 0.4428411812410442, disc_loss = 0.01985651264373008
Trained batch 109 in epoch 12, gen_loss = 0.4423851346427744, disc_loss = 0.019795165400401774
Trained batch 110 in epoch 12, gen_loss = 0.44141880724881144, disc_loss = 0.019987847977989092
Trained batch 111 in epoch 12, gen_loss = 0.44144811161926817, disc_loss = 0.019891228746148824
Trained batch 112 in epoch 12, gen_loss = 0.44140172637669384, disc_loss = 0.02015168201981887
Trained batch 113 in epoch 12, gen_loss = 0.4417734608838433, disc_loss = 0.020061192759353537
Trained batch 114 in epoch 12, gen_loss = 0.441964177204215, disc_loss = 0.020040437306844346
Trained batch 115 in epoch 12, gen_loss = 0.4420842885457236, disc_loss = 0.020171966776051077
Trained batch 116 in epoch 12, gen_loss = 0.4422444000712827, disc_loss = 0.02016518367195709
Trained batch 117 in epoch 12, gen_loss = 0.4425793600789571, disc_loss = 0.02003831470333892
Trained batch 118 in epoch 12, gen_loss = 0.4428316522546175, disc_loss = 0.020338741235802843
Trained batch 119 in epoch 12, gen_loss = 0.443131110817194, disc_loss = 0.020234817843690203
Trained batch 120 in epoch 12, gen_loss = 0.44262554010083854, disc_loss = 0.0209811834939794
Trained batch 121 in epoch 12, gen_loss = 0.44330975388894317, disc_loss = 0.02101531460190375
Trained batch 122 in epoch 12, gen_loss = 0.4437158386397168, disc_loss = 0.02124210298951049
Trained batch 123 in epoch 12, gen_loss = 0.44381894411579254, disc_loss = 0.02112255282531072
Trained batch 124 in epoch 12, gen_loss = 0.44387304639816283, disc_loss = 0.0213425566656515
Trained batch 125 in epoch 12, gen_loss = 0.4434327804853046, disc_loss = 0.021400093628529696
Trained batch 126 in epoch 12, gen_loss = 0.4437130576982273, disc_loss = 0.021278444592342308
Trained batch 127 in epoch 12, gen_loss = 0.4435316182207316, disc_loss = 0.021176311481212906
Trained batch 128 in epoch 12, gen_loss = 0.44354482191477634, disc_loss = 0.02106212569642523
Trained batch 129 in epoch 12, gen_loss = 0.44324560669752266, disc_loss = 0.02096173008814311
Trained batch 130 in epoch 12, gen_loss = 0.44313610919559276, disc_loss = 0.02084274022601801
Trained batch 131 in epoch 12, gen_loss = 0.44341580502011557, disc_loss = 0.020733972283778712
Trained batch 132 in epoch 12, gen_loss = 0.4434032735967995, disc_loss = 0.021015734242842553
Trained batch 133 in epoch 12, gen_loss = 0.44307799704039275, disc_loss = 0.02127200955048954
Trained batch 134 in epoch 12, gen_loss = 0.44334475839579546, disc_loss = 0.022088105927428436
Trained batch 135 in epoch 12, gen_loss = 0.4434490655274952, disc_loss = 0.02202874430890113
Trained batch 136 in epoch 12, gen_loss = 0.44365906998188825, disc_loss = 0.021916663402480746
Trained batch 137 in epoch 12, gen_loss = 0.44347044760766235, disc_loss = 0.022610857818727854
Trained batch 138 in epoch 12, gen_loss = 0.4433939682065154, disc_loss = 0.026449880963894907
Trained batch 139 in epoch 12, gen_loss = 0.4426222503185272, disc_loss = 0.027456918843589456
Trained batch 140 in epoch 12, gen_loss = 0.4420596644388023, disc_loss = 0.028361599449008863
Trained batch 141 in epoch 12, gen_loss = 0.44173250630707805, disc_loss = 0.02959510784278112
Trained batch 142 in epoch 12, gen_loss = 0.44117123367903116, disc_loss = 0.030110590790815236
Trained batch 143 in epoch 12, gen_loss = 0.44077097148531014, disc_loss = 0.03073036681598751
Trained batch 144 in epoch 12, gen_loss = 0.4406215371756718, disc_loss = 0.031324496254292795
Trained batch 145 in epoch 12, gen_loss = 0.4406150191614073, disc_loss = 0.032193414158066605
Trained batch 146 in epoch 12, gen_loss = 0.4410985197339739, disc_loss = 0.03416800094042987
Trained batch 147 in epoch 12, gen_loss = 0.4410895715291436, disc_loss = 0.034284838405280446
Trained batch 148 in epoch 12, gen_loss = 0.4407111332320527, disc_loss = 0.03420021715527088
Trained batch 149 in epoch 12, gen_loss = 0.44074236949284873, disc_loss = 0.03475690867053345
Trained batch 150 in epoch 12, gen_loss = 0.4402895417829223, disc_loss = 0.03544024270049463
Trained batch 151 in epoch 12, gen_loss = 0.440123495890906, disc_loss = 0.035340455071969985
Trained batch 152 in epoch 12, gen_loss = 0.4400742897410798, disc_loss = 0.03517962828372891
Trained batch 153 in epoch 12, gen_loss = 0.4399275386875326, disc_loss = 0.035057050108685844
Trained batch 154 in epoch 12, gen_loss = 0.44017985347778565, disc_loss = 0.03500820402461555
Trained batch 155 in epoch 12, gen_loss = 0.44024446453803623, disc_loss = 0.035285327720115535
Trained batch 156 in epoch 12, gen_loss = 0.4401944032899893, disc_loss = 0.035527405079163514
Trained batch 157 in epoch 12, gen_loss = 0.4398496326389192, disc_loss = 0.03544601653569932
Trained batch 158 in epoch 12, gen_loss = 0.43994653843483833, disc_loss = 0.035287279552932385
Trained batch 159 in epoch 12, gen_loss = 0.44037698339670894, disc_loss = 0.03523455855829525
Trained batch 160 in epoch 12, gen_loss = 0.4404114799469894, disc_loss = 0.035106347664837834
Trained batch 161 in epoch 12, gen_loss = 0.4405054532819324, disc_loss = 0.03504816939361555
Trained batch 162 in epoch 12, gen_loss = 0.44053832848379215, disc_loss = 0.03488074342700213
Trained batch 163 in epoch 12, gen_loss = 0.4407624555070226, disc_loss = 0.034769078627904515
Trained batch 164 in epoch 12, gen_loss = 0.4407329830256375, disc_loss = 0.03465499300156918
Trained batch 165 in epoch 12, gen_loss = 0.44094172317579566, disc_loss = 0.03446869911409982
Trained batch 166 in epoch 12, gen_loss = 0.4410445061986318, disc_loss = 0.03447801213987551
Trained batch 167 in epoch 12, gen_loss = 0.44091499259784106, disc_loss = 0.034316592267021495
Trained batch 168 in epoch 12, gen_loss = 0.44126411919763103, disc_loss = 0.034186885096325635
Trained batch 169 in epoch 12, gen_loss = 0.4407782065517762, disc_loss = 0.034139831007376095
Trained batch 170 in epoch 12, gen_loss = 0.4407962637338025, disc_loss = 0.034197476778958236
Trained batch 171 in epoch 12, gen_loss = 0.4410159487363904, disc_loss = 0.03403366414957333
Trained batch 172 in epoch 12, gen_loss = 0.44092810980846425, disc_loss = 0.03389368914108121
Trained batch 173 in epoch 12, gen_loss = 0.4406948271153987, disc_loss = 0.03376260627764973
Trained batch 174 in epoch 12, gen_loss = 0.4408182804925101, disc_loss = 0.03378882130275347
Trained batch 175 in epoch 12, gen_loss = 0.44085561924360017, disc_loss = 0.03381081760413839
Trained batch 176 in epoch 12, gen_loss = 0.4405582422590525, disc_loss = 0.03365719369625789
Trained batch 177 in epoch 12, gen_loss = 0.4403721832492378, disc_loss = 0.03351936225316309
Trained batch 178 in epoch 12, gen_loss = 0.4406556562005475, disc_loss = 0.03339101097028827
Trained batch 179 in epoch 12, gen_loss = 0.4405918031930923, disc_loss = 0.03322502388554211
Trained batch 180 in epoch 12, gen_loss = 0.4404447538088698, disc_loss = 0.03318649194349962
Trained batch 181 in epoch 12, gen_loss = 0.4402606785297394, disc_loss = 0.03305264316680892
Trained batch 182 in epoch 12, gen_loss = 0.4402285449491824, disc_loss = 0.03290626240189345
Trained batch 183 in epoch 12, gen_loss = 0.44059485423824063, disc_loss = 0.03408197690568277
Trained batch 184 in epoch 12, gen_loss = 0.44084169945201357, disc_loss = 0.034235802337502105
Trained batch 185 in epoch 12, gen_loss = 0.44099224735331793, disc_loss = 0.034098072117069354
Trained batch 186 in epoch 12, gen_loss = 0.4407681714404713, disc_loss = 0.0342848807328037
Trained batch 187 in epoch 12, gen_loss = 0.4410055940772625, disc_loss = 0.03430505239521153
Trained batch 188 in epoch 12, gen_loss = 0.44116226910914064, disc_loss = 0.03439607189305462
Trained batch 189 in epoch 12, gen_loss = 0.44104240897454716, disc_loss = 0.03429098298809932
Trained batch 190 in epoch 12, gen_loss = 0.4408926303786133, disc_loss = 0.034398034458165666
Trained batch 191 in epoch 12, gen_loss = 0.44110495829954743, disc_loss = 0.034333251289960266
Trained batch 192 in epoch 12, gen_loss = 0.441417380472539, disc_loss = 0.03444353470740444
Trained batch 193 in epoch 12, gen_loss = 0.44129781424999237, disc_loss = 0.034318278811886406
Trained batch 194 in epoch 12, gen_loss = 0.4410222559403151, disc_loss = 0.03422214418398933
Trained batch 195 in epoch 12, gen_loss = 0.4410581184285028, disc_loss = 0.0340829242052919
Trained batch 196 in epoch 12, gen_loss = 0.4413593308574657, disc_loss = 0.03406764190528201
Trained batch 197 in epoch 12, gen_loss = 0.44139089247193, disc_loss = 0.033939814758886855
Trained batch 198 in epoch 12, gen_loss = 0.44142351243364153, disc_loss = 0.03402891863621865
Trained batch 199 in epoch 12, gen_loss = 0.44175472304224966, disc_loss = 0.033936467877938414
Trained batch 200 in epoch 12, gen_loss = 0.44212219208034115, disc_loss = 0.03379423053534377
Trained batch 201 in epoch 12, gen_loss = 0.44201079866673687, disc_loss = 0.033848457969148815
Trained batch 202 in epoch 12, gen_loss = 0.4422009474244611, disc_loss = 0.03371613294406899
Trained batch 203 in epoch 12, gen_loss = 0.4422789084560731, disc_loss = 0.03360903243632421
Trained batch 204 in epoch 12, gen_loss = 0.4419621707462683, disc_loss = 0.03346737080719322
Trained batch 205 in epoch 12, gen_loss = 0.44200507240388, disc_loss = 0.03344959726735714
Trained batch 206 in epoch 12, gen_loss = 0.4420330348798042, disc_loss = 0.03350313426195621
Trained batch 207 in epoch 12, gen_loss = 0.44204588363376945, disc_loss = 0.033373400328855496
Trained batch 208 in epoch 12, gen_loss = 0.44192211893186617, disc_loss = 0.033396239995702424
Trained batch 209 in epoch 12, gen_loss = 0.44197962127980733, disc_loss = 0.033263336531707044
Trained batch 210 in epoch 12, gen_loss = 0.44254050393240146, disc_loss = 0.03340781563219848
Trained batch 211 in epoch 12, gen_loss = 0.44256036967601414, disc_loss = 0.03331350770785543
Trained batch 212 in epoch 12, gen_loss = 0.44246917991011353, disc_loss = 0.033410746326009814
Trained batch 213 in epoch 12, gen_loss = 0.4424718710306649, disc_loss = 0.03340103567923881
Trained batch 214 in epoch 12, gen_loss = 0.442579838702845, disc_loss = 0.033364514401724
Trained batch 215 in epoch 12, gen_loss = 0.44299686299981894, disc_loss = 0.03416737270944631
Trained batch 216 in epoch 12, gen_loss = 0.4428155909760207, disc_loss = 0.0342721703568525
Trained batch 217 in epoch 12, gen_loss = 0.44286863902293216, disc_loss = 0.0345506746372114
Trained batch 218 in epoch 12, gen_loss = 0.4429122133342098, disc_loss = 0.03498574312442497
Trained batch 219 in epoch 12, gen_loss = 0.4425579252568158, disc_loss = 0.03537974682879973
Trained batch 220 in epoch 12, gen_loss = 0.44212284508873434, disc_loss = 0.03645628070557802
Trained batch 221 in epoch 12, gen_loss = 0.44186167472654636, disc_loss = 0.036812987213698425
Trained batch 222 in epoch 12, gen_loss = 0.441675164507109, disc_loss = 0.037135716679614586
Trained batch 223 in epoch 12, gen_loss = 0.4416493386296289, disc_loss = 0.037420230187438265
Trained batch 224 in epoch 12, gen_loss = 0.44205635878774857, disc_loss = 0.03745920635087208
Trained batch 225 in epoch 12, gen_loss = 0.44224314101501905, disc_loss = 0.03785824732993012
Trained batch 226 in epoch 12, gen_loss = 0.44233755721394713, disc_loss = 0.03795506767590124
Trained batch 227 in epoch 12, gen_loss = 0.4419050236281596, disc_loss = 0.038088442318104695
Trained batch 228 in epoch 12, gen_loss = 0.4420150819043405, disc_loss = 0.03805721759558228
Trained batch 229 in epoch 12, gen_loss = 0.44224120067513506, disc_loss = 0.03796338872407037
Trained batch 230 in epoch 12, gen_loss = 0.44209647668904556, disc_loss = 0.03794344207544073
Trained batch 231 in epoch 12, gen_loss = 0.44193243517957886, disc_loss = 0.03788414134409134
Trained batch 232 in epoch 12, gen_loss = 0.442246464444844, disc_loss = 0.0377633793478384
Trained batch 233 in epoch 12, gen_loss = 0.4422496803041197, disc_loss = 0.03770065768651712
Trained batch 234 in epoch 12, gen_loss = 0.4422947038995459, disc_loss = 0.03757736581189439
Trained batch 235 in epoch 12, gen_loss = 0.4424081007807942, disc_loss = 0.03748528423898664
Trained batch 236 in epoch 12, gen_loss = 0.44256577537029607, disc_loss = 0.03829327619974482
Trained batch 237 in epoch 12, gen_loss = 0.4421865188774942, disc_loss = 0.0387726608138461
Trained batch 238 in epoch 12, gen_loss = 0.4421127270205749, disc_loss = 0.039380884364492816
Trained batch 239 in epoch 12, gen_loss = 0.4424782272428274, disc_loss = 0.04002312072310209
Trained batch 240 in epoch 12, gen_loss = 0.44213284298592087, disc_loss = 0.04022336919469318
Trained batch 241 in epoch 12, gen_loss = 0.4421843706576292, disc_loss = 0.040563379850696524
Trained batch 242 in epoch 12, gen_loss = 0.4425328793349089, disc_loss = 0.04058507581312332
Trained batch 243 in epoch 12, gen_loss = 0.44248488056855123, disc_loss = 0.04053820854150232
Trained batch 244 in epoch 12, gen_loss = 0.4421947240829468, disc_loss = 0.04055191719172788
Trained batch 245 in epoch 12, gen_loss = 0.44205236459166053, disc_loss = 0.04043231739206391
Trained batch 246 in epoch 12, gen_loss = 0.44238233928255705, disc_loss = 0.0404376124992386
Trained batch 247 in epoch 12, gen_loss = 0.44263090866227306, disc_loss = 0.04033641269075639
Trained batch 248 in epoch 12, gen_loss = 0.4423569349878763, disc_loss = 0.04050243766856825
Trained batch 249 in epoch 12, gen_loss = 0.44220411241054536, disc_loss = 0.04047653248673305
Trained batch 250 in epoch 12, gen_loss = 0.44258021797791897, disc_loss = 0.040646835951509315
Trained batch 251 in epoch 12, gen_loss = 0.44262941571928205, disc_loss = 0.04081529609273218
Trained batch 252 in epoch 12, gen_loss = 0.44280316930985736, disc_loss = 0.04074126352204503
Trained batch 253 in epoch 12, gen_loss = 0.4426604639592133, disc_loss = 0.04063433033779014
Trained batch 254 in epoch 12, gen_loss = 0.4426531324199602, disc_loss = 0.0406441335196552
Trained batch 255 in epoch 12, gen_loss = 0.4429736118763685, disc_loss = 0.040501940040030604
Trained batch 256 in epoch 12, gen_loss = 0.4429558988675069, disc_loss = 0.04038449030157527
Trained batch 257 in epoch 12, gen_loss = 0.44307681086451506, disc_loss = 0.04052634050396394
Trained batch 258 in epoch 12, gen_loss = 0.44297006277504114, disc_loss = 0.04053566762844899
Trained batch 259 in epoch 12, gen_loss = 0.44285278824659496, disc_loss = 0.04056731506671685
Trained batch 260 in epoch 12, gen_loss = 0.4432046038894361, disc_loss = 0.040598481662938966
Trained batch 261 in epoch 12, gen_loss = 0.44337353883808805, disc_loss = 0.04051473241731283
Trained batch 262 in epoch 12, gen_loss = 0.44343432988050774, disc_loss = 0.04044436156075136
Trained batch 263 in epoch 12, gen_loss = 0.44354504809686635, disc_loss = 0.04037655659759008
Trained batch 264 in epoch 12, gen_loss = 0.44362850953947824, disc_loss = 0.04030067302629281
Trained batch 265 in epoch 12, gen_loss = 0.443686103798393, disc_loss = 0.040223991776259856
Trained batch 266 in epoch 12, gen_loss = 0.4436310585518455, disc_loss = 0.04009589304657451
Trained batch 267 in epoch 12, gen_loss = 0.44361447376101765, disc_loss = 0.04043003452599479
Trained batch 268 in epoch 12, gen_loss = 0.4438714484743026, disc_loss = 0.04122779407706389
Trained batch 269 in epoch 12, gen_loss = 0.44394527265319117, disc_loss = 0.041115709567977186
Trained batch 270 in epoch 12, gen_loss = 0.44370946387083327, disc_loss = 0.04135727830964907
Trained batch 271 in epoch 12, gen_loss = 0.4439503662288189, disc_loss = 0.041293475353621246
Trained batch 272 in epoch 12, gen_loss = 0.4438823734447633, disc_loss = 0.04139951241395399
Trained batch 273 in epoch 12, gen_loss = 0.44360165472013235, disc_loss = 0.04137669552761694
Trained batch 274 in epoch 12, gen_loss = 0.44344798543236474, disc_loss = 0.04127690184311095
Trained batch 275 in epoch 12, gen_loss = 0.443261187037696, disc_loss = 0.041164506312402344
Trained batch 276 in epoch 12, gen_loss = 0.443264634385436, disc_loss = 0.04106362867177488
Trained batch 277 in epoch 12, gen_loss = 0.44317496498282866, disc_loss = 0.041021896711728206
Trained batch 278 in epoch 12, gen_loss = 0.4431674575506573, disc_loss = 0.041149321353934225
Trained batch 279 in epoch 12, gen_loss = 0.44310864582657816, disc_loss = 0.041239043229974674
Trained batch 280 in epoch 12, gen_loss = 0.4426372353504561, disc_loss = 0.041163440977282875
Trained batch 281 in epoch 12, gen_loss = 0.442534291363777, disc_loss = 0.041067387289053875
Trained batch 282 in epoch 12, gen_loss = 0.44262782276308577, disc_loss = 0.042178808893702346
Trained batch 283 in epoch 12, gen_loss = 0.4426584858709658, disc_loss = 0.042413097886207944
Trained batch 284 in epoch 12, gen_loss = 0.44285408593060677, disc_loss = 0.042374190859284185
Trained batch 285 in epoch 12, gen_loss = 0.4428890791389492, disc_loss = 0.042360876733681406
Trained batch 286 in epoch 12, gen_loss = 0.4429615787928113, disc_loss = 0.042594830944845355
Trained batch 287 in epoch 12, gen_loss = 0.44273237066550386, disc_loss = 0.04255842724160175
Trained batch 288 in epoch 12, gen_loss = 0.4428379287150492, disc_loss = 0.04248599929913917
Trained batch 289 in epoch 12, gen_loss = 0.442825104553124, disc_loss = 0.04248483416198849
Trained batch 290 in epoch 12, gen_loss = 0.44277485027346003, disc_loss = 0.042382040577524586
Trained batch 291 in epoch 12, gen_loss = 0.4427218384122195, disc_loss = 0.04266148926937404
Trained batch 292 in epoch 12, gen_loss = 0.4427594833406572, disc_loss = 0.042651069590125754
Trained batch 293 in epoch 12, gen_loss = 0.4427780170424455, disc_loss = 0.04254058139124683
Trained batch 294 in epoch 12, gen_loss = 0.44304821531651384, disc_loss = 0.04242910723304534
Trained batch 295 in epoch 12, gen_loss = 0.4432101159079655, disc_loss = 0.04238883575316003
Trained batch 296 in epoch 12, gen_loss = 0.44314636124504936, disc_loss = 0.0423114047482177
Trained batch 297 in epoch 12, gen_loss = 0.4431626692714307, disc_loss = 0.04226253983125578
Trained batch 298 in epoch 12, gen_loss = 0.44317443932976613, disc_loss = 0.042156832714340835
Trained batch 299 in epoch 12, gen_loss = 0.4428583448131879, disc_loss = 0.0421472501300741
Trained batch 300 in epoch 12, gen_loss = 0.4429012335020046, disc_loss = 0.04210635126557548
Trained batch 301 in epoch 12, gen_loss = 0.4431384288712053, disc_loss = 0.04217634626798369
Trained batch 302 in epoch 12, gen_loss = 0.44319538196714797, disc_loss = 0.04206658258424033
Trained batch 303 in epoch 12, gen_loss = 0.44350340648701314, disc_loss = 0.04194699227312077
Trained batch 304 in epoch 12, gen_loss = 0.4437289322008852, disc_loss = 0.04191059169825166
Trained batch 305 in epoch 12, gen_loss = 0.4438409480004529, disc_loss = 0.04180248560851099
Trained batch 306 in epoch 12, gen_loss = 0.4439095614010814, disc_loss = 0.04168357617708669
Trained batch 307 in epoch 12, gen_loss = 0.443864548651429, disc_loss = 0.04157162335355065
Trained batch 308 in epoch 12, gen_loss = 0.444002748500182, disc_loss = 0.04150570974674703
Trained batch 309 in epoch 12, gen_loss = 0.44399701356887816, disc_loss = 0.04144419660423732
Trained batch 310 in epoch 12, gen_loss = 0.4437499220731557, disc_loss = 0.04136147300175232
Trained batch 311 in epoch 12, gen_loss = 0.4437159082064262, disc_loss = 0.04125062068319844
Trained batch 312 in epoch 12, gen_loss = 0.44352039904259266, disc_loss = 0.0411954972451886
Trained batch 313 in epoch 12, gen_loss = 0.4437068680858916, disc_loss = 0.04137144889793756
Trained batch 314 in epoch 12, gen_loss = 0.4435573925101568, disc_loss = 0.04147360913329832
Trained batch 315 in epoch 12, gen_loss = 0.44365056556991384, disc_loss = 0.041392736202857425
Trained batch 316 in epoch 12, gen_loss = 0.44355416824388955, disc_loss = 0.041390568835804775
Trained batch 317 in epoch 12, gen_loss = 0.44344015241418994, disc_loss = 0.04152648302736698
Trained batch 318 in epoch 12, gen_loss = 0.44359967654401605, disc_loss = 0.0423188130309233
Trained batch 319 in epoch 12, gen_loss = 0.44344228971749544, disc_loss = 0.042243539182163656
Trained batch 320 in epoch 12, gen_loss = 0.4432644396556129, disc_loss = 0.04224971188718273
Trained batch 321 in epoch 12, gen_loss = 0.4435938761471221, disc_loss = 0.04218609886271416
Trained batch 322 in epoch 12, gen_loss = 0.44356061984141915, disc_loss = 0.042289582690607536
Trained batch 323 in epoch 12, gen_loss = 0.4438383910391066, disc_loss = 0.042740594211572
Trained batch 324 in epoch 12, gen_loss = 0.44409747490516077, disc_loss = 0.04264863074219857
Trained batch 325 in epoch 12, gen_loss = 0.4441425332262472, disc_loss = 0.04264284599896669
Trained batch 326 in epoch 12, gen_loss = 0.44435778305800316, disc_loss = 0.04257770288067753
Trained batch 327 in epoch 12, gen_loss = 0.4443999825999504, disc_loss = 0.04249057608547269
Trained batch 328 in epoch 12, gen_loss = 0.44441420011969685, disc_loss = 0.04242512636774115
Trained batch 329 in epoch 12, gen_loss = 0.4442046706423615, disc_loss = 0.04257923625233216
Trained batch 330 in epoch 12, gen_loss = 0.44435062797408087, disc_loss = 0.042615863883915694
Trained batch 331 in epoch 12, gen_loss = 0.4442394317453166, disc_loss = 0.04278189680891123
Trained batch 332 in epoch 12, gen_loss = 0.4442287148298086, disc_loss = 0.0429171869799064
Trained batch 333 in epoch 12, gen_loss = 0.4441731217913999, disc_loss = 0.04287238590088868
Trained batch 334 in epoch 12, gen_loss = 0.44410246681811205, disc_loss = 0.0429023280110794
Trained batch 335 in epoch 12, gen_loss = 0.4439620354345867, disc_loss = 0.043624110789789394
Trained batch 336 in epoch 12, gen_loss = 0.443738346460665, disc_loss = 0.043696963605166964
Trained batch 337 in epoch 12, gen_loss = 0.44378275807792616, disc_loss = 0.04361336439477346
Trained batch 338 in epoch 12, gen_loss = 0.443582730131515, disc_loss = 0.04364069453804619
Trained batch 339 in epoch 12, gen_loss = 0.4436587302123799, disc_loss = 0.044016867452506526
Trained batch 340 in epoch 12, gen_loss = 0.44378522825031336, disc_loss = 0.04391930530993459
Trained batch 341 in epoch 12, gen_loss = 0.44375773410350955, disc_loss = 0.043866191953570416
Trained batch 342 in epoch 12, gen_loss = 0.44377951632435747, disc_loss = 0.04376297209068383
Trained batch 343 in epoch 12, gen_loss = 0.4436267763376236, disc_loss = 0.043676647469658554
Trained batch 344 in epoch 12, gen_loss = 0.4437615265880806, disc_loss = 0.043587357300819585
Trained batch 345 in epoch 12, gen_loss = 0.44370663191886306, disc_loss = 0.043494643294588915
Trained batch 346 in epoch 12, gen_loss = 0.44359006962446385, disc_loss = 0.043434466088730146
Trained batch 347 in epoch 12, gen_loss = 0.4438765895949013, disc_loss = 0.04346980977282945
Trained batch 348 in epoch 12, gen_loss = 0.4437816803127442, disc_loss = 0.043506929022126585
Trained batch 349 in epoch 12, gen_loss = 0.4442009710414069, disc_loss = 0.04340950946290312
Trained batch 350 in epoch 12, gen_loss = 0.4441826695050949, disc_loss = 0.04330015410251247
Trained batch 351 in epoch 12, gen_loss = 0.44414461446418, disc_loss = 0.04318701165737531
Trained batch 352 in epoch 12, gen_loss = 0.4443067010840343, disc_loss = 0.043129143671517815
Trained batch 353 in epoch 12, gen_loss = 0.44428488502731434, disc_loss = 0.04306048499966188
Trained batch 354 in epoch 12, gen_loss = 0.44435821612116316, disc_loss = 0.04297939608181814
Trained batch 355 in epoch 12, gen_loss = 0.44438110132900516, disc_loss = 0.04288956674641218
Trained batch 356 in epoch 12, gen_loss = 0.44440519717895016, disc_loss = 0.04344823260443332
Trained batch 357 in epoch 12, gen_loss = 0.4441402383856267, disc_loss = 0.04340313907742615
Trained batch 358 in epoch 12, gen_loss = 0.44407309604222395, disc_loss = 0.04348502617328062
Trained batch 359 in epoch 12, gen_loss = 0.44402713891532686, disc_loss = 0.043397346355939385
Trained batch 360 in epoch 12, gen_loss = 0.4442098442867522, disc_loss = 0.04351316248950319
Trained batch 361 in epoch 12, gen_loss = 0.44429163889990325, disc_loss = 0.043420061103431044
Trained batch 362 in epoch 12, gen_loss = 0.44444475653414556, disc_loss = 0.0437604138475635
Trained batch 363 in epoch 12, gen_loss = 0.44433646968432833, disc_loss = 0.0443243894078078
Trained batch 364 in epoch 12, gen_loss = 0.4442888198650047, disc_loss = 0.044242606612802673
Trained batch 365 in epoch 12, gen_loss = 0.444300731267434, disc_loss = 0.04415266281674499
Trained batch 366 in epoch 12, gen_loss = 0.4440961904032029, disc_loss = 0.04407970100477571
Trained batch 367 in epoch 12, gen_loss = 0.4440593584238187, disc_loss = 0.04399768097304648
Trained batch 368 in epoch 12, gen_loss = 0.44402310308725207, disc_loss = 0.04389475504041152
Trained batch 369 in epoch 12, gen_loss = 0.44383524189124235, disc_loss = 0.043791665534199394
Trained batch 370 in epoch 12, gen_loss = 0.4437323670502943, disc_loss = 0.0436831986574918
Trained batch 371 in epoch 12, gen_loss = 0.4437264843333152, disc_loss = 0.04358482365502715
Trained batch 372 in epoch 12, gen_loss = 0.44374690258790594, disc_loss = 0.0434978496618494
Trained batch 373 in epoch 12, gen_loss = 0.4435607527188439, disc_loss = 0.04343574586913318
Trained batch 374 in epoch 12, gen_loss = 0.44343530853589375, disc_loss = 0.04333296609080086
Trained batch 375 in epoch 12, gen_loss = 0.44349585774731126, disc_loss = 0.043233900936877734
Trained batch 376 in epoch 12, gen_loss = 0.4434714030365729, disc_loss = 0.04313835635841812
Trained batch 377 in epoch 12, gen_loss = 0.44330014249004385, disc_loss = 0.04315108703184508
Trained batch 378 in epoch 12, gen_loss = 0.44320182592698953, disc_loss = 0.04308176727499813
Trained batch 379 in epoch 12, gen_loss = 0.44330625651698363, disc_loss = 0.04326134828734211
Trained batch 380 in epoch 12, gen_loss = 0.4432629396909178, disc_loss = 0.043192758929201956
Trained batch 381 in epoch 12, gen_loss = 0.443227871784365, disc_loss = 0.04320754995112459
Trained batch 382 in epoch 12, gen_loss = 0.4431564800888689, disc_loss = 0.04319378780109891
Trained batch 383 in epoch 12, gen_loss = 0.4434320623210321, disc_loss = 0.04322706609946181
Trained batch 384 in epoch 12, gen_loss = 0.4434717397411148, disc_loss = 0.043181741719327676
Trained batch 385 in epoch 12, gen_loss = 0.4436642179371779, disc_loss = 0.04313687351200527
Trained batch 386 in epoch 12, gen_loss = 0.44356779334465046, disc_loss = 0.04313678026123535
Trained batch 387 in epoch 12, gen_loss = 0.4434101671441314, disc_loss = 0.043274508302217615
Trained batch 388 in epoch 12, gen_loss = 0.44357028327748216, disc_loss = 0.04343937072396556
Trained batch 389 in epoch 12, gen_loss = 0.44342590218935257, disc_loss = 0.04335352623482975
Trained batch 390 in epoch 12, gen_loss = 0.44340031096697463, disc_loss = 0.04326103870665221
Trained batch 391 in epoch 12, gen_loss = 0.44348796859991796, disc_loss = 0.04318679029351262
Trained batch 392 in epoch 12, gen_loss = 0.4434863875688791, disc_loss = 0.04309829935679122
Trained batch 393 in epoch 12, gen_loss = 0.44335091235068846, disc_loss = 0.04306697389518672
Trained batch 394 in epoch 12, gen_loss = 0.4435937563075295, disc_loss = 0.04300023795288245
Trained batch 395 in epoch 12, gen_loss = 0.44356132050355274, disc_loss = 0.0429197355538649
Trained batch 396 in epoch 12, gen_loss = 0.4436694492471008, disc_loss = 0.042856011636172815
Trained batch 397 in epoch 12, gen_loss = 0.4437512702229035, disc_loss = 0.04276360902524595
Trained batch 398 in epoch 12, gen_loss = 0.4438255909540898, disc_loss = 0.0441342821711777
Trained batch 399 in epoch 12, gen_loss = 0.44388329565525053, disc_loss = 0.04445104000886204
Trained batch 400 in epoch 12, gen_loss = 0.44372844525108907, disc_loss = 0.04447188635996573
Trained batch 401 in epoch 12, gen_loss = 0.4435492827376323, disc_loss = 0.044428422498292014
Trained batch 402 in epoch 12, gen_loss = 0.44353208774076797, disc_loss = 0.04436674378332786
Trained batch 403 in epoch 12, gen_loss = 0.4436941309878142, disc_loss = 0.04430911657521455
Trained batch 404 in epoch 12, gen_loss = 0.4436419665813446, disc_loss = 0.04421373712686523
Trained batch 405 in epoch 12, gen_loss = 0.4436523884975264, disc_loss = 0.04411960159012075
Trained batch 406 in epoch 12, gen_loss = 0.4437804350981841, disc_loss = 0.044030189273034565
Trained batch 407 in epoch 12, gen_loss = 0.44363828448980464, disc_loss = 0.04393236368338751
Trained batch 408 in epoch 12, gen_loss = 0.4436038938740355, disc_loss = 0.04383944684991381
Trained batch 409 in epoch 12, gen_loss = 0.4435752793056209, disc_loss = 0.04374075936431792
Trained batch 410 in epoch 12, gen_loss = 0.44378097460507765, disc_loss = 0.04366546335551942
Trained batch 411 in epoch 12, gen_loss = 0.4437520304351177, disc_loss = 0.043574536912362495
Trained batch 412 in epoch 12, gen_loss = 0.4436504075948609, disc_loss = 0.04347817002672738
Trained batch 413 in epoch 12, gen_loss = 0.4438559208515186, disc_loss = 0.04339629359985364
Trained batch 414 in epoch 12, gen_loss = 0.44381686283881405, disc_loss = 0.04332164092892669
Trained batch 415 in epoch 12, gen_loss = 0.4437868343666196, disc_loss = 0.04323661105305431
Trained batch 416 in epoch 12, gen_loss = 0.44380953972288173, disc_loss = 0.04313834205105659
Trained batch 417 in epoch 12, gen_loss = 0.4439300461961892, disc_loss = 0.04304301923248944
Trained batch 418 in epoch 12, gen_loss = 0.44395111917311364, disc_loss = 0.04295691970078973
Trained batch 419 in epoch 12, gen_loss = 0.4439129652011962, disc_loss = 0.04286971178510049
Trained batch 420 in epoch 12, gen_loss = 0.44383236149994043, disc_loss = 0.04278552567839596
Trained batch 421 in epoch 12, gen_loss = 0.44375536763837553, disc_loss = 0.04269305784150437
Trained batch 422 in epoch 12, gen_loss = 0.443710743112767, disc_loss = 0.04260952402611899
Trained batch 423 in epoch 12, gen_loss = 0.44376944539681923, disc_loss = 0.04251590096814567
Trained batch 424 in epoch 12, gen_loss = 0.44364266269347247, disc_loss = 0.042424398805562626
Trained batch 425 in epoch 12, gen_loss = 0.44369766864698257, disc_loss = 0.04236892465214538
Trained batch 426 in epoch 12, gen_loss = 0.44378429155718246, disc_loss = 0.04227701083847498
Trained batch 427 in epoch 12, gen_loss = 0.4439221785586571, disc_loss = 0.04222289780530182
Trained batch 428 in epoch 12, gen_loss = 0.44384469178728847, disc_loss = 0.04213390198708805
Trained batch 429 in epoch 12, gen_loss = 0.4438735398442246, disc_loss = 0.04207099665113356
Trained batch 430 in epoch 12, gen_loss = 0.4438189806075218, disc_loss = 0.04202556102120657
Trained batch 431 in epoch 12, gen_loss = 0.4438207204005233, disc_loss = 0.04194115420735519
Trained batch 432 in epoch 12, gen_loss = 0.4438431757839943, disc_loss = 0.041864658069504346
Trained batch 433 in epoch 12, gen_loss = 0.4438758015220616, disc_loss = 0.041808806306388537
Trained batch 434 in epoch 12, gen_loss = 0.4439519660911341, disc_loss = 0.04173791739987959
Trained batch 435 in epoch 12, gen_loss = 0.44399802147521883, disc_loss = 0.04165207415230683
Trained batch 436 in epoch 12, gen_loss = 0.44381690073067864, disc_loss = 0.041575851835559806
Trained batch 437 in epoch 12, gen_loss = 0.4437978428248401, disc_loss = 0.04152650750570688
Trained batch 438 in epoch 12, gen_loss = 0.4438143951610444, disc_loss = 0.0414521073382072
Trained batch 439 in epoch 12, gen_loss = 0.4439221705225381, disc_loss = 0.041400947999897075
Trained batch 440 in epoch 12, gen_loss = 0.443919909176102, disc_loss = 0.041326718174962244
Trained batch 441 in epoch 12, gen_loss = 0.444030720521422, disc_loss = 0.04125615445780041
Trained batch 442 in epoch 12, gen_loss = 0.44408961733630764, disc_loss = 0.04140970928717455
Trained batch 443 in epoch 12, gen_loss = 0.4440917524400058, disc_loss = 0.04177068694529275
Trained batch 444 in epoch 12, gen_loss = 0.44433400148756047, disc_loss = 0.04169076564486317
Trained batch 445 in epoch 12, gen_loss = 0.44442962637931244, disc_loss = 0.04162320991348467
Trained batch 446 in epoch 12, gen_loss = 0.44430522417328766, disc_loss = 0.04187372812435606
Trained batch 447 in epoch 12, gen_loss = 0.4444234828863825, disc_loss = 0.041929578863086396
Trained batch 448 in epoch 12, gen_loss = 0.44440506548021314, disc_loss = 0.04185656405998838
Trained batch 449 in epoch 12, gen_loss = 0.44418855177031624, disc_loss = 0.04197900175349787
Trained batch 450 in epoch 12, gen_loss = 0.44430291626247226, disc_loss = 0.04193815772453666
Trained batch 451 in epoch 12, gen_loss = 0.4443956823871199, disc_loss = 0.041946089572316464
Trained batch 452 in epoch 12, gen_loss = 0.44438711571903944, disc_loss = 0.041878880543591124
Trained batch 453 in epoch 12, gen_loss = 0.44461531425100065, disc_loss = 0.04180010670661672
Trained batch 454 in epoch 12, gen_loss = 0.44459014194352287, disc_loss = 0.041725563060666264
Trained batch 455 in epoch 12, gen_loss = 0.4445594987064077, disc_loss = 0.04166574073110895
Trained batch 456 in epoch 12, gen_loss = 0.44444724721772927, disc_loss = 0.04252910473321807
Trained batch 457 in epoch 12, gen_loss = 0.44450840087176413, disc_loss = 0.0426832897678591
Trained batch 458 in epoch 12, gen_loss = 0.4443267284525246, disc_loss = 0.04297638865829951
Trained batch 459 in epoch 12, gen_loss = 0.44432455638180607, disc_loss = 0.04294733554453832
Trained batch 460 in epoch 12, gen_loss = 0.44428622573937354, disc_loss = 0.04329387281507197
Trained batch 461 in epoch 12, gen_loss = 0.4441658199736566, disc_loss = 0.043307460073706214
Trained batch 462 in epoch 12, gen_loss = 0.44396312171130664, disc_loss = 0.04327845163407009
Trained batch 463 in epoch 12, gen_loss = 0.4439119017715084, disc_loss = 0.04325865711218974
Trained batch 464 in epoch 12, gen_loss = 0.44388196314534833, disc_loss = 0.043200913819945064
Trained batch 465 in epoch 12, gen_loss = 0.44366773221114164, disc_loss = 0.043188643441165804
Trained batch 466 in epoch 12, gen_loss = 0.4437226297002788, disc_loss = 0.043177337263315935
Trained batch 467 in epoch 12, gen_loss = 0.443639042476813, disc_loss = 0.043101710739245035
Trained batch 468 in epoch 12, gen_loss = 0.4435937730615327, disc_loss = 0.04304292510131569
Trained batch 469 in epoch 12, gen_loss = 0.4435660666607796, disc_loss = 0.04296321279215726
Trained batch 470 in epoch 12, gen_loss = 0.44362756439075346, disc_loss = 0.04288329971650706
Trained batch 471 in epoch 12, gen_loss = 0.44363975947943785, disc_loss = 0.04332149950456924
Trained batch 472 in epoch 12, gen_loss = 0.44364208606786504, disc_loss = 0.043280453039441516
Trained batch 473 in epoch 12, gen_loss = 0.44358095482683385, disc_loss = 0.04322839784362247
Trained batch 474 in epoch 12, gen_loss = 0.44347310085045666, disc_loss = 0.04338326110480059
Trained batch 475 in epoch 12, gen_loss = 0.44345948632274357, disc_loss = 0.04339784933004661
Trained batch 476 in epoch 12, gen_loss = 0.443499541695013, disc_loss = 0.043335951987968316
Trained batch 477 in epoch 12, gen_loss = 0.443492956802436, disc_loss = 0.04325584581567006
Trained batch 478 in epoch 12, gen_loss = 0.4435498765465611, disc_loss = 0.043213561268879146
Trained batch 479 in epoch 12, gen_loss = 0.4435070439552267, disc_loss = 0.04315448109822076
Trained batch 480 in epoch 12, gen_loss = 0.44347519983620753, disc_loss = 0.04310295478951016
Trained batch 481 in epoch 12, gen_loss = 0.4434510864533824, disc_loss = 0.04302217305808896
Trained batch 482 in epoch 12, gen_loss = 0.443488738860156, disc_loss = 0.0429977492400875
Trained batch 483 in epoch 12, gen_loss = 0.443512323658821, disc_loss = 0.042931974556899344
Trained batch 484 in epoch 12, gen_loss = 0.44356666858663263, disc_loss = 0.042857825363621344
Trained batch 485 in epoch 12, gen_loss = 0.44363324203118376, disc_loss = 0.04279029547115175
Trained batch 486 in epoch 12, gen_loss = 0.44348850044626476, disc_loss = 0.04271908400956067
Trained batch 487 in epoch 12, gen_loss = 0.4434417087401523, disc_loss = 0.04263816062970751
Trained batch 488 in epoch 12, gen_loss = 0.4433759636186627, disc_loss = 0.042570039121184594
Trained batch 489 in epoch 12, gen_loss = 0.4433914519086176, disc_loss = 0.04251194603869463
Trained batch 490 in epoch 12, gen_loss = 0.44346999502958934, disc_loss = 0.04244510366419205
Trained batch 491 in epoch 12, gen_loss = 0.4435992437164958, disc_loss = 0.04241560685152105
Trained batch 492 in epoch 12, gen_loss = 0.4435585418047334, disc_loss = 0.04234329435070429
Trained batch 493 in epoch 12, gen_loss = 0.4435601721891025, disc_loss = 0.04226983774821971
Trained batch 494 in epoch 12, gen_loss = 0.4436167850638881, disc_loss = 0.042196312126929335
Trained batch 495 in epoch 12, gen_loss = 0.4436343041879515, disc_loss = 0.04211596649533491
Trained batch 496 in epoch 12, gen_loss = 0.4437426576312159, disc_loss = 0.04212275992069858
Trained batch 497 in epoch 12, gen_loss = 0.44367242954581615, disc_loss = 0.04207750256000326
Trained batch 498 in epoch 12, gen_loss = 0.4435322855660815, disc_loss = 0.042006824328657426
Trained batch 499 in epoch 12, gen_loss = 0.4435349785089493, disc_loss = 0.04194444224680774
Trained batch 500 in epoch 12, gen_loss = 0.4437061740966614, disc_loss = 0.0418725986423588
Trained batch 501 in epoch 12, gen_loss = 0.44371116939056443, disc_loss = 0.04184947280371858
Trained batch 502 in epoch 12, gen_loss = 0.44374901945026923, disc_loss = 0.041787656115517983
Trained batch 503 in epoch 12, gen_loss = 0.44397477474477554, disc_loss = 0.041761554713639994
Trained batch 504 in epoch 12, gen_loss = 0.44394001234876046, disc_loss = 0.041689353061627854
Trained batch 505 in epoch 12, gen_loss = 0.4440562573699612, disc_loss = 0.041623782773047555
Trained batch 506 in epoch 12, gen_loss = 0.4440330606122929, disc_loss = 0.04157042422692826
Trained batch 507 in epoch 12, gen_loss = 0.44399174003619846, disc_loss = 0.041522786745161744
Trained batch 508 in epoch 12, gen_loss = 0.44411950284699325, disc_loss = 0.041508267911504186
Trained batch 509 in epoch 12, gen_loss = 0.44419589381591945, disc_loss = 0.04145363046783114
Trained batch 510 in epoch 12, gen_loss = 0.444310912414073, disc_loss = 0.04139219154626561
Trained batch 511 in epoch 12, gen_loss = 0.44445561175234616, disc_loss = 0.04131834002760115
Trained batch 512 in epoch 12, gen_loss = 0.4444750869831844, disc_loss = 0.04124627349381725
Trained batch 513 in epoch 12, gen_loss = 0.4444485571713763, disc_loss = 0.041173346397957986
Trained batch 514 in epoch 12, gen_loss = 0.4444666246766026, disc_loss = 0.04109987502542406
Trained batch 515 in epoch 12, gen_loss = 0.44424184128757593, disc_loss = 0.04103245805202651
Trained batch 516 in epoch 12, gen_loss = 0.44418606790398724, disc_loss = 0.040962452255594736
Trained batch 517 in epoch 12, gen_loss = 0.4443462928289612, disc_loss = 0.04089229472784297
Trained batch 518 in epoch 12, gen_loss = 0.4442870766211567, disc_loss = 0.040827499143824136
Trained batch 519 in epoch 12, gen_loss = 0.4441913513036875, disc_loss = 0.040756036464098054
Trained batch 520 in epoch 12, gen_loss = 0.4442371820991648, disc_loss = 0.04077871091017632
Trained batch 521 in epoch 12, gen_loss = 0.44425112003339207, disc_loss = 0.04074723715024155
Trained batch 522 in epoch 12, gen_loss = 0.44407643033031297, disc_loss = 0.040679862101501776
Trained batch 523 in epoch 12, gen_loss = 0.4440873769744662, disc_loss = 0.04061367259230216
Trained batch 524 in epoch 12, gen_loss = 0.44405411334264844, disc_loss = 0.04057730598397376
Trained batch 525 in epoch 12, gen_loss = 0.44399354875994274, disc_loss = 0.04051118852334281
Trained batch 526 in epoch 12, gen_loss = 0.44404916168390235, disc_loss = 0.04044570392938737
Trained batch 527 in epoch 12, gen_loss = 0.4440525583922863, disc_loss = 0.04038957997942238
Trained batch 528 in epoch 12, gen_loss = 0.44412540110613313, disc_loss = 0.040319276027538105
Trained batch 529 in epoch 12, gen_loss = 0.4440945630365947, disc_loss = 0.04026562053960625
Trained batch 530 in epoch 12, gen_loss = 0.44398297703423295, disc_loss = 0.040225477707870445
Trained batch 531 in epoch 12, gen_loss = 0.44398740135637443, disc_loss = 0.04019779092356514
Trained batch 532 in epoch 12, gen_loss = 0.4439529683196299, disc_loss = 0.040160779868546125
Trained batch 533 in epoch 12, gen_loss = 0.4440876577565733, disc_loss = 0.04010089050933949
Trained batch 534 in epoch 12, gen_loss = 0.44421138345638167, disc_loss = 0.040068448513580886
Trained batch 535 in epoch 12, gen_loss = 0.4442822845346892, disc_loss = 0.040342796237056784
Trained batch 536 in epoch 12, gen_loss = 0.44412049035120277, disc_loss = 0.040303319048533626
Trained batch 537 in epoch 12, gen_loss = 0.4440441322703344, disc_loss = 0.040449293400637014
Trained batch 538 in epoch 12, gen_loss = 0.44391461233703455, disc_loss = 0.04042536667993047
Trained batch 539 in epoch 12, gen_loss = 0.44379983284959085, disc_loss = 0.04045643692736997
Trained batch 540 in epoch 12, gen_loss = 0.4438028061786553, disc_loss = 0.040437826502236734
Trained batch 541 in epoch 12, gen_loss = 0.4437390552125734, disc_loss = 0.04039047841722407
Trained batch 542 in epoch 12, gen_loss = 0.44362487428535197, disc_loss = 0.04038009843784753
Trained batch 543 in epoch 12, gen_loss = 0.4437487257973236, disc_loss = 0.04036302304837805
Trained batch 544 in epoch 12, gen_loss = 0.4438352840209226, disc_loss = 0.04042980008344209
Trained batch 545 in epoch 12, gen_loss = 0.44381319488579535, disc_loss = 0.040435623695891376
Trained batch 546 in epoch 12, gen_loss = 0.4439406737657962, disc_loss = 0.04037975915175585
Trained batch 547 in epoch 12, gen_loss = 0.4440486684006496, disc_loss = 0.04034361607215816
Trained batch 548 in epoch 12, gen_loss = 0.44397580455344016, disc_loss = 0.04028752400647537
Trained batch 549 in epoch 12, gen_loss = 0.4439425297758796, disc_loss = 0.040232640639667146
Trained batch 550 in epoch 12, gen_loss = 0.4437726522422313, disc_loss = 0.04019196383497034
Trained batch 551 in epoch 12, gen_loss = 0.44369532518844673, disc_loss = 0.04035614272246333
Trained batch 552 in epoch 12, gen_loss = 0.44367152791989, disc_loss = 0.04050664337554856
Trained batch 553 in epoch 12, gen_loss = 0.44367840208301473, disc_loss = 0.04044579839882767
Trained batch 554 in epoch 12, gen_loss = 0.44359376156652297, disc_loss = 0.04038569694993229
Trained batch 555 in epoch 12, gen_loss = 0.4435623967283064, disc_loss = 0.040335716470521574
Trained batch 556 in epoch 12, gen_loss = 0.44359387256726757, disc_loss = 0.040375655057381915
Trained batch 557 in epoch 12, gen_loss = 0.44370258415258057, disc_loss = 0.040391358094812306
Trained batch 558 in epoch 12, gen_loss = 0.4436767850344424, disc_loss = 0.04035368853491066
Trained batch 559 in epoch 12, gen_loss = 0.4437536724976131, disc_loss = 0.04032248384838957
Trained batch 560 in epoch 12, gen_loss = 0.4436879241424023, disc_loss = 0.04038725223466123
Trained batch 561 in epoch 12, gen_loss = 0.4437289591679794, disc_loss = 0.04032455132698335
Trained batch 562 in epoch 12, gen_loss = 0.44399094025788044, disc_loss = 0.04038387282770524
Trained batch 563 in epoch 12, gen_loss = 0.44397969221603784, disc_loss = 0.04034663244593948
Trained batch 564 in epoch 12, gen_loss = 0.4440176710618281, disc_loss = 0.040348765984449565
Trained batch 565 in epoch 12, gen_loss = 0.4441535238031785, disc_loss = 0.040288049222731985
Trained batch 566 in epoch 12, gen_loss = 0.4442867918409788, disc_loss = 0.040372974482591625
Trained batch 567 in epoch 12, gen_loss = 0.44417358751238234, disc_loss = 0.04031897019976127
Trained batch 568 in epoch 12, gen_loss = 0.44418990088263377, disc_loss = 0.04061358086687066
Trained batch 569 in epoch 12, gen_loss = 0.4442601488347639, disc_loss = 0.040586015208125964
Trained batch 570 in epoch 12, gen_loss = 0.4444148499786123, disc_loss = 0.04061552501693792
Trained batch 571 in epoch 12, gen_loss = 0.4444363687734504, disc_loss = 0.04056369480892684
Trained batch 572 in epoch 12, gen_loss = 0.44441757230234397, disc_loss = 0.04056991016054217
Trained batch 573 in epoch 12, gen_loss = 0.4444956298177666, disc_loss = 0.04053132182967976
Trained batch 574 in epoch 12, gen_loss = 0.44455014342847077, disc_loss = 0.04048746823474927
Trained batch 575 in epoch 12, gen_loss = 0.4444732706890338, disc_loss = 0.04042581189039791
Trained batch 576 in epoch 12, gen_loss = 0.44455537468556516, disc_loss = 0.040370134135790534
Trained batch 577 in epoch 12, gen_loss = 0.4445414064149131, disc_loss = 0.04031583644988686
Trained batch 578 in epoch 12, gen_loss = 0.4446293447095907, disc_loss = 0.04028125794862585
Trained batch 579 in epoch 12, gen_loss = 0.4447126369537978, disc_loss = 0.04023397984404663
Trained batch 580 in epoch 12, gen_loss = 0.44478413319013205, disc_loss = 0.040173015725741196
Trained batch 581 in epoch 12, gen_loss = 0.44478760982297133, disc_loss = 0.04021278116552006
Trained batch 582 in epoch 12, gen_loss = 0.44485434225247616, disc_loss = 0.040159877802015284
Trained batch 583 in epoch 12, gen_loss = 0.44485669731073185, disc_loss = 0.04011381911580317
Trained batch 584 in epoch 12, gen_loss = 0.44472144353084075, disc_loss = 0.040094558070174965
Trained batch 585 in epoch 12, gen_loss = 0.44470853905222113, disc_loss = 0.040034221107205344
Trained batch 586 in epoch 12, gen_loss = 0.4446533816331899, disc_loss = 0.03997980494998567
Trained batch 587 in epoch 12, gen_loss = 0.4447451863868707, disc_loss = 0.039922644604562914
Trained batch 588 in epoch 12, gen_loss = 0.44462418945819293, disc_loss = 0.039870686206297794
Trained batch 589 in epoch 12, gen_loss = 0.44453274425813705, disc_loss = 0.03980795028402423
Trained batch 590 in epoch 12, gen_loss = 0.44454433470208027, disc_loss = 0.0397798600679503
Trained batch 591 in epoch 12, gen_loss = 0.44445906710383054, disc_loss = 0.039720113633233564
Trained batch 592 in epoch 12, gen_loss = 0.4445262993065543, disc_loss = 0.039660599701692355
Trained batch 593 in epoch 12, gen_loss = 0.4445526678654481, disc_loss = 0.039642996625286475
Trained batch 594 in epoch 12, gen_loss = 0.44464468099489934, disc_loss = 0.03958573144872305
Trained batch 595 in epoch 12, gen_loss = 0.44474626852561966, disc_loss = 0.03955385062766211
Trained batch 596 in epoch 12, gen_loss = 0.4447107773829545, disc_loss = 0.0395018834212383
Trained batch 597 in epoch 12, gen_loss = 0.44467229079642023, disc_loss = 0.03946783953446764
Trained batch 598 in epoch 12, gen_loss = 0.44465532724765783, disc_loss = 0.03940722688030489
Trained batch 599 in epoch 12, gen_loss = 0.44469676951567333, disc_loss = 0.039349194903043096
Trained batch 600 in epoch 12, gen_loss = 0.44468339766916537, disc_loss = 0.03929023514288677
Trained batch 601 in epoch 12, gen_loss = 0.4446611748977357, disc_loss = 0.03923553003650313
Trained batch 602 in epoch 12, gen_loss = 0.44465873732693356, disc_loss = 0.039173925806502585
Trained batch 603 in epoch 12, gen_loss = 0.4447260353936265, disc_loss = 0.03911686670910166
Trained batch 604 in epoch 12, gen_loss = 0.44475457973716676, disc_loss = 0.03906401397779676
Trained batch 605 in epoch 12, gen_loss = 0.4448023727132936, disc_loss = 0.03900353488394769
Trained batch 606 in epoch 12, gen_loss = 0.4447507269594579, disc_loss = 0.03894321144657452
Trained batch 607 in epoch 12, gen_loss = 0.444729038220095, disc_loss = 0.03888309422683577
Trained batch 608 in epoch 12, gen_loss = 0.444723304660841, disc_loss = 0.03885529589573952
Trained batch 609 in epoch 12, gen_loss = 0.44468501044101405, disc_loss = 0.03881009457552744
Trained batch 610 in epoch 12, gen_loss = 0.44473273518042555, disc_loss = 0.03875635652943878
Trained batch 611 in epoch 12, gen_loss = 0.4447832956325774, disc_loss = 0.038701820172623615
Trained batch 612 in epoch 12, gen_loss = 0.44483096695840846, disc_loss = 0.03864334235564148
Trained batch 613 in epoch 12, gen_loss = 0.4449050789547277, disc_loss = 0.038657450823436405
Trained batch 614 in epoch 12, gen_loss = 0.44484660116637625, disc_loss = 0.03860839812739987
Trained batch 615 in epoch 12, gen_loss = 0.4448749908766189, disc_loss = 0.03856133262709224
Trained batch 616 in epoch 12, gen_loss = 0.4448623807928744, disc_loss = 0.03850928919764939
Trained batch 617 in epoch 12, gen_loss = 0.4447990036705165, disc_loss = 0.03846440345601218
Trained batch 618 in epoch 12, gen_loss = 0.44481410911857405, disc_loss = 0.0384081404670089
Trained batch 619 in epoch 12, gen_loss = 0.4448257699608803, disc_loss = 0.03837000403211512
Trained batch 620 in epoch 12, gen_loss = 0.4447307460933876, disc_loss = 0.03833057668720689
Trained batch 621 in epoch 12, gen_loss = 0.44478041944588115, disc_loss = 0.03827729988173159
Trained batch 622 in epoch 12, gen_loss = 0.4447620589985702, disc_loss = 0.038240973018655436
Trained batch 623 in epoch 12, gen_loss = 0.44465224511730367, disc_loss = 0.038183170772427756
Trained batch 624 in epoch 12, gen_loss = 0.44471043748855593, disc_loss = 0.03817677762079984
Trained batch 625 in epoch 12, gen_loss = 0.444792192964889, disc_loss = 0.03818002861672298
Trained batch 626 in epoch 12, gen_loss = 0.4448765714487961, disc_loss = 0.03812840728306819
Trained batch 627 in epoch 12, gen_loss = 0.44494773124813275, disc_loss = 0.038077318603595554
Trained batch 628 in epoch 12, gen_loss = 0.4450613853472784, disc_loss = 0.03803038450097887
Trained batch 629 in epoch 12, gen_loss = 0.4451153692271974, disc_loss = 0.037987197653412644
Trained batch 630 in epoch 12, gen_loss = 0.44515969655026344, disc_loss = 0.03793115837063357
Trained batch 631 in epoch 12, gen_loss = 0.4451637558544738, disc_loss = 0.03790436887209557
Trained batch 632 in epoch 12, gen_loss = 0.4451594690293497, disc_loss = 0.03786472985274519
Trained batch 633 in epoch 12, gen_loss = 0.44530945240699155, disc_loss = 0.037821227656155885
Trained batch 634 in epoch 12, gen_loss = 0.4453811484528339, disc_loss = 0.037799089279678455
Trained batch 635 in epoch 12, gen_loss = 0.4454161803583679, disc_loss = 0.03775727900375506
Trained batch 636 in epoch 12, gen_loss = 0.44529842174783046, disc_loss = 0.037703204086581114
Trained batch 637 in epoch 12, gen_loss = 0.445328191296434, disc_loss = 0.03765241457401194
Trained batch 638 in epoch 12, gen_loss = 0.44526286616758187, disc_loss = 0.03760021745867835
Trained batch 639 in epoch 12, gen_loss = 0.44526831577531994, disc_loss = 0.03755038189428887
Trained batch 640 in epoch 12, gen_loss = 0.44522582880234385, disc_loss = 0.03749943237955858
Trained batch 641 in epoch 12, gen_loss = 0.4454131631464973, disc_loss = 0.037452370546521715
Trained batch 642 in epoch 12, gen_loss = 0.44539243404639084, disc_loss = 0.03739850166377584
Trained batch 643 in epoch 12, gen_loss = 0.44538933297862177, disc_loss = 0.03734834733659905
Trained batch 644 in epoch 12, gen_loss = 0.44554747814355894, disc_loss = 0.03729436784538678
Trained batch 645 in epoch 12, gen_loss = 0.4456063834690826, disc_loss = 0.03724128311379574
Trained batch 646 in epoch 12, gen_loss = 0.4455519601403285, disc_loss = 0.03718813242505188
Trained batch 647 in epoch 12, gen_loss = 0.445494997602554, disc_loss = 0.03713494316832145
Trained batch 648 in epoch 12, gen_loss = 0.445514606768251, disc_loss = 0.03708131922583292
Trained batch 649 in epoch 12, gen_loss = 0.4454922102506344, disc_loss = 0.037027808422616756
Trained batch 650 in epoch 12, gen_loss = 0.44547842321674214, disc_loss = 0.03697806531717191
Trained batch 651 in epoch 12, gen_loss = 0.44555769997871725, disc_loss = 0.03692943895177807
Trained batch 652 in epoch 12, gen_loss = 0.4455214378753446, disc_loss = 0.03687736827214812
Trained batch 653 in epoch 12, gen_loss = 0.445543128735064, disc_loss = 0.03683034041579614
Trained batch 654 in epoch 12, gen_loss = 0.4456972071687684, disc_loss = 0.03678021834690465
Trained batch 655 in epoch 12, gen_loss = 0.44573490062683097, disc_loss = 0.03672807862774168
Trained batch 656 in epoch 12, gen_loss = 0.4456929179359244, disc_loss = 0.036677267240633964
Trained batch 657 in epoch 12, gen_loss = 0.4456855245727174, disc_loss = 0.0366244423516324
Trained batch 658 in epoch 12, gen_loss = 0.44578902552268934, disc_loss = 0.036573993502649706
Trained batch 659 in epoch 12, gen_loss = 0.4458394756371325, disc_loss = 0.03652202455471552
Trained batch 660 in epoch 12, gen_loss = 0.4458514743691674, disc_loss = 0.03647271884374924
Trained batch 661 in epoch 12, gen_loss = 0.4458738035125675, disc_loss = 0.03642099081827722
Trained batch 662 in epoch 12, gen_loss = 0.44587868515003143, disc_loss = 0.036370134837103676
Trained batch 663 in epoch 12, gen_loss = 0.4458685533917812, disc_loss = 0.036318294172026554
Trained batch 664 in epoch 12, gen_loss = 0.44578853043398464, disc_loss = 0.03626961223536024
Trained batch 665 in epoch 12, gen_loss = 0.4457337767243743, disc_loss = 0.03621868649078114
Trained batch 666 in epoch 12, gen_loss = 0.44560813367634877, disc_loss = 0.03616753744409661
Trained batch 667 in epoch 12, gen_loss = 0.44556230498466665, disc_loss = 0.03611888950390875
Trained batch 668 in epoch 12, gen_loss = 0.445490844402969, disc_loss = 0.03606815099359806
Trained batch 669 in epoch 12, gen_loss = 0.4454763324847862, disc_loss = 0.03602076638976474
Trained batch 670 in epoch 12, gen_loss = 0.4454095463994363, disc_loss = 0.035969323273047235
Trained batch 671 in epoch 12, gen_loss = 0.4453622094311175, disc_loss = 0.03592334653530131
Trained batch 672 in epoch 12, gen_loss = 0.4454406426353228, disc_loss = 0.035872585683843786
Trained batch 673 in epoch 12, gen_loss = 0.44548183807810265, disc_loss = 0.035825139284513904
Trained batch 674 in epoch 12, gen_loss = 0.44537401225831774, disc_loss = 0.03577730278536263
Trained batch 675 in epoch 12, gen_loss = 0.4452284748649456, disc_loss = 0.035731059136234235
Trained batch 676 in epoch 12, gen_loss = 0.44525074250060664, disc_loss = 0.0356810893748228
Trained batch 677 in epoch 12, gen_loss = 0.44535204825323943, disc_loss = 0.0356323783514969
Trained batch 678 in epoch 12, gen_loss = 0.4453393084398952, disc_loss = 0.03558225865322899
Trained batch 679 in epoch 12, gen_loss = 0.4453959465465125, disc_loss = 0.03553281573609531
Trained batch 680 in epoch 12, gen_loss = 0.44539395596137304, disc_loss = 0.03548258678849497
Trained batch 681 in epoch 12, gen_loss = 0.44539461994975194, disc_loss = 0.0354345323448957
Trained batch 682 in epoch 12, gen_loss = 0.44529749839232574, disc_loss = 0.035387663142060204
Trained batch 683 in epoch 12, gen_loss = 0.4453189847500701, disc_loss = 0.03533918081479125
Trained batch 684 in epoch 12, gen_loss = 0.44527320535513604, disc_loss = 0.03529047559790422
Trained batch 685 in epoch 12, gen_loss = 0.445190449280572, disc_loss = 0.03524089180905122
Trained batch 686 in epoch 12, gen_loss = 0.44518425006533296, disc_loss = 0.03519159057458898
Trained batch 687 in epoch 12, gen_loss = 0.4451045676372772, disc_loss = 0.035142682828949924
Trained batch 688 in epoch 12, gen_loss = 0.4452132651006535, disc_loss = 0.03509512362195414
Trained batch 689 in epoch 12, gen_loss = 0.44530396141867706, disc_loss = 0.03504658219779072
Trained batch 690 in epoch 12, gen_loss = 0.44530628119122273, disc_loss = 0.03499866324034149
Trained batch 691 in epoch 12, gen_loss = 0.44531089877117574, disc_loss = 0.03495023020148153
Trained batch 692 in epoch 12, gen_loss = 0.4452757956661703, disc_loss = 0.03490264751376587
Trained batch 693 in epoch 12, gen_loss = 0.44523370751214647, disc_loss = 0.03485703978017214
Trained batch 694 in epoch 12, gen_loss = 0.4452529140513578, disc_loss = 0.034809287289733724
Trained batch 695 in epoch 12, gen_loss = 0.44529534049931613, disc_loss = 0.03476172242458808
Trained batch 696 in epoch 12, gen_loss = 0.44528446277039635, disc_loss = 0.034714058627657744
Trained batch 697 in epoch 12, gen_loss = 0.44524164532009713, disc_loss = 0.03466671757099157
Trained batch 698 in epoch 12, gen_loss = 0.4452478915495593, disc_loss = 0.03461939758985558
Trained batch 699 in epoch 12, gen_loss = 0.4451553529500961, disc_loss = 0.03457298006280325
Trained batch 700 in epoch 12, gen_loss = 0.4451207430998711, disc_loss = 0.034528706771967274
Trained batch 701 in epoch 12, gen_loss = 0.44517887521673133, disc_loss = 0.034483625379920356
Trained batch 702 in epoch 12, gen_loss = 0.4452217053807477, disc_loss = 0.034437595811807636
Trained batch 703 in epoch 12, gen_loss = 0.44520066314461554, disc_loss = 0.03439335430861816
Trained batch 704 in epoch 12, gen_loss = 0.44525941263699365, disc_loss = 0.03434713122018791
Trained batch 705 in epoch 12, gen_loss = 0.44511414739295374, disc_loss = 0.03430209724165278
Trained batch 706 in epoch 12, gen_loss = 0.44518468521609167, disc_loss = 0.0342573396808203
Trained batch 707 in epoch 12, gen_loss = 0.44521035548657345, disc_loss = 0.0342130509608341
Trained batch 708 in epoch 12, gen_loss = 0.4451441703041114, disc_loss = 0.034169185601899923
Trained batch 709 in epoch 12, gen_loss = 0.4451086208014421, disc_loss = 0.03412422722198961
Trained batch 710 in epoch 12, gen_loss = 0.4451180000680744, disc_loss = 0.0340785313461175
Trained batch 711 in epoch 12, gen_loss = 0.44507035328431077, disc_loss = 0.03403389069357667
Trained batch 712 in epoch 12, gen_loss = 0.44516373993136604, disc_loss = 0.033989749493228916
Trained batch 713 in epoch 12, gen_loss = 0.44509129297165645, disc_loss = 0.03394565643241801
Trained batch 714 in epoch 12, gen_loss = 0.44508111551925017, disc_loss = 0.03389998389199585
Trained batch 715 in epoch 12, gen_loss = 0.44517167461983986, disc_loss = 0.0338553844205775
Trained batch 716 in epoch 12, gen_loss = 0.4450585874553505, disc_loss = 0.03380938405378863
Trained batch 717 in epoch 12, gen_loss = 0.4450845335270369, disc_loss = 0.033764773518661646
Trained batch 718 in epoch 12, gen_loss = 0.4450658762488146, disc_loss = 0.033719312789188036
Trained batch 719 in epoch 12, gen_loss = 0.4450310250537263, disc_loss = 0.033678749638622524
Trained batch 720 in epoch 12, gen_loss = 0.44501436670180333, disc_loss = 0.03363361569226754
Trained batch 721 in epoch 12, gen_loss = 0.4450636544881435, disc_loss = 0.03359248132720316
Trained batch 722 in epoch 12, gen_loss = 0.4451440226487599, disc_loss = 0.033548257593033294
Trained batch 723 in epoch 12, gen_loss = 0.44513538195777336, disc_loss = 0.03350632820675247
Trained batch 724 in epoch 12, gen_loss = 0.445245421138303, disc_loss = 0.033480957920085
Trained batch 725 in epoch 12, gen_loss = 0.4452047935448402, disc_loss = 0.033441616399450994
Trained batch 726 in epoch 12, gen_loss = 0.44523876782460586, disc_loss = 0.03340385833122938
Trained batch 727 in epoch 12, gen_loss = 0.4452947673725558, disc_loss = 0.033360429690699196
Trained batch 728 in epoch 12, gen_loss = 0.44531871625752445, disc_loss = 0.033317631545709124
Trained batch 729 in epoch 12, gen_loss = 0.4453182935714722, disc_loss = 0.033274423406453014
Trained batch 730 in epoch 12, gen_loss = 0.4453344756454515, disc_loss = 0.03323065426863766
Trained batch 731 in epoch 12, gen_loss = 0.4454274715377333, disc_loss = 0.03318797196169343
Trained batch 732 in epoch 12, gen_loss = 0.44544862224980886, disc_loss = 0.033145964459012967
Trained batch 733 in epoch 12, gen_loss = 0.4454640198387307, disc_loss = 0.03310537679620183
Trained batch 734 in epoch 12, gen_loss = 0.445416367094533, disc_loss = 0.03306440663932614
Trained batch 735 in epoch 12, gen_loss = 0.4455130624625346, disc_loss = 0.0330229006167033
Trained batch 736 in epoch 12, gen_loss = 0.4454726978752312, disc_loss = 0.03299479745691731
Trained batch 737 in epoch 12, gen_loss = 0.44565220375048115, disc_loss = 0.032976151793421594
Trained batch 738 in epoch 12, gen_loss = 0.44574224932751894, disc_loss = 0.03294361156492755
Trained batch 739 in epoch 12, gen_loss = 0.4457471826592007, disc_loss = 0.03290327823063283
Trained batch 740 in epoch 12, gen_loss = 0.4457767545855158, disc_loss = 0.03286657157915238
Trained batch 741 in epoch 12, gen_loss = 0.44584574632728197, disc_loss = 0.03282985209993832
Trained batch 742 in epoch 12, gen_loss = 0.44584267477167727, disc_loss = 0.03279047895302497
Trained batch 743 in epoch 12, gen_loss = 0.4458388902887862, disc_loss = 0.03275063672176217
Trained batch 744 in epoch 12, gen_loss = 0.4457968581042834, disc_loss = 0.03271304913593344
Trained batch 745 in epoch 12, gen_loss = 0.4457366356661109, disc_loss = 0.03267292349943242
Testing Epoch 12
Training Epoch 13
Trained batch 0 in epoch 13, gen_loss = 0.4702448844909668, disc_loss = 0.002338323276489973
Trained batch 1 in epoch 13, gen_loss = 0.4902121424674988, disc_loss = 0.007147492142394185
Trained batch 2 in epoch 13, gen_loss = 0.4707409242788951, disc_loss = 0.005972526191423337
Trained batch 3 in epoch 13, gen_loss = 0.45491040498018265, disc_loss = 0.0068215165520086884
Trained batch 4 in epoch 13, gen_loss = 0.470185250043869, disc_loss = 0.006906804163008928
Trained batch 5 in epoch 13, gen_loss = 0.4665347586075465, disc_loss = 0.006226844930400451
Trained batch 6 in epoch 13, gen_loss = 0.46383928826877047, disc_loss = 0.005689654033631086
Trained batch 7 in epoch 13, gen_loss = 0.4575059823691845, disc_loss = 0.005219941784162074
Trained batch 8 in epoch 13, gen_loss = 0.45561749736468, disc_loss = 0.006757497839215729
Trained batch 9 in epoch 13, gen_loss = 0.45516799986362455, disc_loss = 0.00867339470423758
Trained batch 10 in epoch 13, gen_loss = 0.4510905715552243, disc_loss = 0.01002461247315461
Trained batch 11 in epoch 13, gen_loss = 0.4442853257060051, disc_loss = 0.01404102569601188
Trained batch 12 in epoch 13, gen_loss = 0.452014664044747, disc_loss = 0.017765709306471623
Trained batch 13 in epoch 13, gen_loss = 0.45391155779361725, disc_loss = 0.02181373366953007
Trained batch 14 in epoch 13, gen_loss = 0.4470921834309896, disc_loss = 0.02140364774192373
Trained batch 15 in epoch 13, gen_loss = 0.4429289288818836, disc_loss = 0.021090470399940386
Trained batch 16 in epoch 13, gen_loss = 0.4445558838984546, disc_loss = 0.026885510066195446
Trained batch 17 in epoch 13, gen_loss = 0.44561685290601516, disc_loss = 0.026643881496662896
Trained batch 18 in epoch 13, gen_loss = 0.44468197697087336, disc_loss = 0.02557806749092905
Trained batch 19 in epoch 13, gen_loss = 0.45122790336608887, disc_loss = 0.024581847619265317
Trained batch 20 in epoch 13, gen_loss = 0.44995968682425364, disc_loss = 0.0248213057361898
Trained batch 21 in epoch 13, gen_loss = 0.4496672356670553, disc_loss = 0.02427884614603086
Trained batch 22 in epoch 13, gen_loss = 0.447580416565356, disc_loss = 0.0234216149572445
Trained batch 23 in epoch 13, gen_loss = 0.4436132572591305, disc_loss = 0.022564445117798943
Trained batch 24 in epoch 13, gen_loss = 0.4435980927944183, disc_loss = 0.02179169373586774
Trained batch 25 in epoch 13, gen_loss = 0.444322869181633, disc_loss = 0.021103658749220464
Trained batch 26 in epoch 13, gen_loss = 0.44346983785982486, disc_loss = 0.02106194525819134
Trained batch 27 in epoch 13, gen_loss = 0.44190164123262676, disc_loss = 0.02097728299642248
Trained batch 28 in epoch 13, gen_loss = 0.4399874230910992, disc_loss = 0.02041364059751404
Trained batch 29 in epoch 13, gen_loss = 0.439728186527888, disc_loss = 0.019849808258004486
Trained batch 30 in epoch 13, gen_loss = 0.43746881907986057, disc_loss = 0.019437396020117785
Trained batch 31 in epoch 13, gen_loss = 0.43689700216054916, disc_loss = 0.018898480309871957
Trained batch 32 in epoch 13, gen_loss = 0.4381617000608733, disc_loss = 0.018374544966994137
Trained batch 33 in epoch 13, gen_loss = 0.43847254006301656, disc_loss = 0.017938901406630653
Trained batch 34 in epoch 13, gen_loss = 0.4391239549432482, disc_loss = 0.0174876858180921
Trained batch 35 in epoch 13, gen_loss = 0.43891118549638325, disc_loss = 0.01704366247415439
Trained batch 36 in epoch 13, gen_loss = 0.438300870560311, disc_loss = 0.016625556531613944
Trained batch 37 in epoch 13, gen_loss = 0.4385639844756377, disc_loss = 0.01625165529855478
Trained batch 38 in epoch 13, gen_loss = 0.43970220058392256, disc_loss = 0.015958675771402434
Trained batch 39 in epoch 13, gen_loss = 0.44008086919784545, disc_loss = 0.01561999849800486
Trained batch 40 in epoch 13, gen_loss = 0.43972466995076437, disc_loss = 0.015271811984570288
Trained batch 41 in epoch 13, gen_loss = 0.4396024360543206, disc_loss = 0.01494117581196839
Trained batch 42 in epoch 13, gen_loss = 0.43984188312707945, disc_loss = 0.014656399073469084
Trained batch 43 in epoch 13, gen_loss = 0.4389995322986083, disc_loss = 0.014364438509801403
Trained batch 44 in epoch 13, gen_loss = 0.4393953356477949, disc_loss = 0.014097670525208944
Trained batch 45 in epoch 13, gen_loss = 0.438643929751023, disc_loss = 0.01429663341158353
Trained batch 46 in epoch 13, gen_loss = 0.4396384922747916, disc_loss = 0.01405550228144498
Trained batch 47 in epoch 13, gen_loss = 0.4410690584530433, disc_loss = 0.01382454242411768
Trained batch 48 in epoch 13, gen_loss = 0.44192107721250884, disc_loss = 0.01370331384859295
Trained batch 49 in epoch 13, gen_loss = 0.44242227911949156, disc_loss = 0.013533172218594701
Trained batch 50 in epoch 13, gen_loss = 0.44285795852249743, disc_loss = 0.013362672912669094
Trained batch 51 in epoch 13, gen_loss = 0.4430329306767537, disc_loss = 0.01390416941901024
Trained batch 52 in epoch 13, gen_loss = 0.4426334399097371, disc_loss = 0.015328333697738653
Trained batch 53 in epoch 13, gen_loss = 0.4426639300805551, disc_loss = 0.015267915370511927
Trained batch 54 in epoch 13, gen_loss = 0.44238571362061935, disc_loss = 0.015319090745073151
Trained batch 55 in epoch 13, gen_loss = 0.44289095061165945, disc_loss = 0.015538497131534055
Trained batch 56 in epoch 13, gen_loss = 0.4429308165583694, disc_loss = 0.01630836558781499
Trained batch 57 in epoch 13, gen_loss = 0.4441308183916684, disc_loss = 0.01617548690410331
Trained batch 58 in epoch 13, gen_loss = 0.44408136757753663, disc_loss = 0.015957824185380113
Trained batch 59 in epoch 13, gen_loss = 0.4450747286279996, disc_loss = 0.015771445439895615
Trained batch 60 in epoch 13, gen_loss = 0.4442242193417471, disc_loss = 0.015827003188935092
Trained batch 61 in epoch 13, gen_loss = 0.4444593320931158, disc_loss = 0.01564711451928522
Trained batch 62 in epoch 13, gen_loss = 0.443569540977478, disc_loss = 0.015657914708191084
Trained batch 63 in epoch 13, gen_loss = 0.44350743433460593, disc_loss = 0.01587636529620795
Trained batch 64 in epoch 13, gen_loss = 0.44542244993723357, disc_loss = 0.01581878056928802
Trained batch 65 in epoch 13, gen_loss = 0.44729400087486615, disc_loss = 0.015706068760306207
Trained batch 66 in epoch 13, gen_loss = 0.4480824884194047, disc_loss = 0.01552043970041811
Trained batch 67 in epoch 13, gen_loss = 0.44869401744183374, disc_loss = 0.01576683865620426
Trained batch 68 in epoch 13, gen_loss = 0.4476695652457251, disc_loss = 0.01560638999681164
Trained batch 69 in epoch 13, gen_loss = 0.4468846538237163, disc_loss = 0.015519338615039097
Trained batch 70 in epoch 13, gen_loss = 0.4464679234464404, disc_loss = 0.015363378733934336
Trained batch 71 in epoch 13, gen_loss = 0.44658882667620975, disc_loss = 0.015172235109882118
Trained batch 72 in epoch 13, gen_loss = 0.44680933429770275, disc_loss = 0.015025598186782676
Trained batch 73 in epoch 13, gen_loss = 0.44705718554355, disc_loss = 0.01484259420917747
Trained batch 74 in epoch 13, gen_loss = 0.4463104514280955, disc_loss = 0.014665586010863384
Trained batch 75 in epoch 13, gen_loss = 0.44646671218307393, disc_loss = 0.014499587699231741
Trained batch 76 in epoch 13, gen_loss = 0.44562927817369435, disc_loss = 0.014343511382746813
Trained batch 77 in epoch 13, gen_loss = 0.4454642003163313, disc_loss = 0.014175071209394492
Trained batch 78 in epoch 13, gen_loss = 0.445724967537047, disc_loss = 0.014103274057100563
Trained batch 79 in epoch 13, gen_loss = 0.44671359471976757, disc_loss = 0.013949395195231773
Trained batch 80 in epoch 13, gen_loss = 0.4470740155673321, disc_loss = 0.01379910201397667
Trained batch 81 in epoch 13, gen_loss = 0.4470651073426735, disc_loss = 0.013649775391081122
Trained batch 82 in epoch 13, gen_loss = 0.44678154408213605, disc_loss = 0.0135302646310035
Trained batch 83 in epoch 13, gen_loss = 0.4470100012563524, disc_loss = 0.013382645350204603
Trained batch 84 in epoch 13, gen_loss = 0.4470940905458787, disc_loss = 0.013241449901012375
Trained batch 85 in epoch 13, gen_loss = 0.4469891540532888, disc_loss = 0.013179186584027268
Trained batch 86 in epoch 13, gen_loss = 0.4466586520617036, disc_loss = 0.01305228426929392
Trained batch 87 in epoch 13, gen_loss = 0.4470667408948595, disc_loss = 0.012928423991649073
Trained batch 88 in epoch 13, gen_loss = 0.44650581646501347, disc_loss = 0.012799094848366182
Trained batch 89 in epoch 13, gen_loss = 0.4464411755402883, disc_loss = 0.012684462425143768
Trained batch 90 in epoch 13, gen_loss = 0.44676641055515837, disc_loss = 0.012582242561780572
Trained batch 91 in epoch 13, gen_loss = 0.44699710315984226, disc_loss = 0.01246014180588131
Trained batch 92 in epoch 13, gen_loss = 0.44677958405146034, disc_loss = 0.012343823268849363
Trained batch 93 in epoch 13, gen_loss = 0.44652883201203447, disc_loss = 0.012229033349517813
Trained batch 94 in epoch 13, gen_loss = 0.44676138695917633, disc_loss = 0.012111659618829818
Trained batch 95 in epoch 13, gen_loss = 0.44663162529468536, disc_loss = 0.012006194763671374
Trained batch 96 in epoch 13, gen_loss = 0.4465218349215911, disc_loss = 0.011894990190786799
Trained batch 97 in epoch 13, gen_loss = 0.44626460300416365, disc_loss = 0.011785130377630798
Trained batch 98 in epoch 13, gen_loss = 0.44612027147803646, disc_loss = 0.0116790197213472
Trained batch 99 in epoch 13, gen_loss = 0.4460782447457314, disc_loss = 0.011571326757548376
Trained batch 100 in epoch 13, gen_loss = 0.4462301707503819, disc_loss = 0.011483794966906236
Trained batch 101 in epoch 13, gen_loss = 0.4457967760516148, disc_loss = 0.011380271014857892
Trained batch 102 in epoch 13, gen_loss = 0.4450374208029034, disc_loss = 0.011280023749438522
Trained batch 103 in epoch 13, gen_loss = 0.444956472573372, disc_loss = 0.011191519679134497
Trained batch 104 in epoch 13, gen_loss = 0.4453875203927358, disc_loss = 0.011099302350720834
Trained batch 105 in epoch 13, gen_loss = 0.4459217834585118, disc_loss = 0.011004691325207153
Trained batch 106 in epoch 13, gen_loss = 0.4458782979261095, disc_loss = 0.010909815095843765
Trained batch 107 in epoch 13, gen_loss = 0.4463023386067814, disc_loss = 0.010822834525714387
Trained batch 108 in epoch 13, gen_loss = 0.4465604137390032, disc_loss = 0.010731523049089614
Trained batch 109 in epoch 13, gen_loss = 0.4459880831566724, disc_loss = 0.01064165741078217
Trained batch 110 in epoch 13, gen_loss = 0.4462036114555221, disc_loss = 0.010555316207443809
Trained batch 111 in epoch 13, gen_loss = 0.4466319978237152, disc_loss = 0.010469287341818147
Trained batch 112 in epoch 13, gen_loss = 0.44669547123191633, disc_loss = 0.010390434125685586
Trained batch 113 in epoch 13, gen_loss = 0.44608491293170993, disc_loss = 0.010307351540847632
Trained batch 114 in epoch 13, gen_loss = 0.44557324311007623, disc_loss = 0.010317855479155221
Trained batch 115 in epoch 13, gen_loss = 0.44486391210350495, disc_loss = 0.010254000286483366
Trained batch 116 in epoch 13, gen_loss = 0.44416231197169703, disc_loss = 0.010190316051061655
Trained batch 117 in epoch 13, gen_loss = 0.4434833316984823, disc_loss = 0.010113254997492532
Trained batch 118 in epoch 13, gen_loss = 0.4443418195768565, disc_loss = 0.010040839761299934
Trained batch 119 in epoch 13, gen_loss = 0.44386486237247785, disc_loss = 0.009965280800436934
Trained batch 120 in epoch 13, gen_loss = 0.4439281890214967, disc_loss = 0.00989244251188722
Trained batch 121 in epoch 13, gen_loss = 0.44404722212767994, disc_loss = 0.009825078194167038
Trained batch 122 in epoch 13, gen_loss = 0.4439628272037196, disc_loss = 0.009753438577858535
Trained batch 123 in epoch 13, gen_loss = 0.44431808038103965, disc_loss = 0.009683018952097383
Trained batch 124 in epoch 13, gen_loss = 0.443734557390213, disc_loss = 0.009614282619208098
Trained batch 125 in epoch 13, gen_loss = 0.44325307815793963, disc_loss = 0.009546835761746421
Trained batch 126 in epoch 13, gen_loss = 0.4435547921131915, disc_loss = 0.009479358135979242
Trained batch 127 in epoch 13, gen_loss = 0.4432919218670577, disc_loss = 0.009414538653800264
Trained batch 128 in epoch 13, gen_loss = 0.4431702404521232, disc_loss = 0.009347768668753146
Trained batch 129 in epoch 13, gen_loss = 0.4430404763955336, disc_loss = 0.00928243835358164
Trained batch 130 in epoch 13, gen_loss = 0.44265480896898807, disc_loss = 0.009217717446198417
Trained batch 131 in epoch 13, gen_loss = 0.4427602363355232, disc_loss = 0.009157520953026093
Trained batch 132 in epoch 13, gen_loss = 0.44234034620729606, disc_loss = 0.009095399003717489
Trained batch 133 in epoch 13, gen_loss = 0.44200022540875333, disc_loss = 0.009032250950616827
Trained batch 134 in epoch 13, gen_loss = 0.44165421106197217, disc_loss = 0.008970336818257001
Trained batch 135 in epoch 13, gen_loss = 0.441125096862807, disc_loss = 0.008913801820787793
Trained batch 136 in epoch 13, gen_loss = 0.44110884022538677, disc_loss = 0.008861899129913807
Trained batch 137 in epoch 13, gen_loss = 0.44155918817589246, disc_loss = 0.008810869285219309
Trained batch 138 in epoch 13, gen_loss = 0.44142825118929363, disc_loss = 0.008754762900882675
Trained batch 139 in epoch 13, gen_loss = 0.44123926077570236, disc_loss = 0.008702798632189765
Trained batch 140 in epoch 13, gen_loss = 0.4414902952968652, disc_loss = 0.008656216595827186
Trained batch 141 in epoch 13, gen_loss = 0.4415755509070947, disc_loss = 0.008603944123024121
Trained batch 142 in epoch 13, gen_loss = 0.4410814242763119, disc_loss = 0.008552772909243285
Trained batch 143 in epoch 13, gen_loss = 0.4409606162872579, disc_loss = 0.008499818284083934
Trained batch 144 in epoch 13, gen_loss = 0.4410346653954736, disc_loss = 0.008452235236924528
Trained batch 145 in epoch 13, gen_loss = 0.4408977984973829, disc_loss = 0.008399777277053832
Trained batch 146 in epoch 13, gen_loss = 0.44058812374160405, disc_loss = 0.008356880490053571
Trained batch 147 in epoch 13, gen_loss = 0.44017385751814453, disc_loss = 0.008313230810705823
Trained batch 148 in epoch 13, gen_loss = 0.4404031894351012, disc_loss = 0.008271116089082054
Trained batch 149 in epoch 13, gen_loss = 0.44045893669128416, disc_loss = 0.008222765014506877
Trained batch 150 in epoch 13, gen_loss = 0.44027668908731826, disc_loss = 0.008177532408145928
Trained batch 151 in epoch 13, gen_loss = 0.43990088254213333, disc_loss = 0.008130296881733412
Trained batch 152 in epoch 13, gen_loss = 0.4400390460600261, disc_loss = 0.008091923604974998
Trained batch 153 in epoch 13, gen_loss = 0.43949928279820977, disc_loss = 0.008056198933929833
Trained batch 154 in epoch 13, gen_loss = 0.43918555167413525, disc_loss = 0.008016650196194889
Trained batch 155 in epoch 13, gen_loss = 0.4395013476411502, disc_loss = 0.00797443865508868
Trained batch 156 in epoch 13, gen_loss = 0.4395093376849108, disc_loss = 0.007933666205158231
Trained batch 157 in epoch 13, gen_loss = 0.4395666654351391, disc_loss = 0.007892618759659036
Trained batch 158 in epoch 13, gen_loss = 0.439357246805287, disc_loss = 0.007850325718352208
Trained batch 159 in epoch 13, gen_loss = 0.43949046041816475, disc_loss = 0.007806868071202189
Trained batch 160 in epoch 13, gen_loss = 0.43930923605557554, disc_loss = 0.007768137434711506
Trained batch 161 in epoch 13, gen_loss = 0.43910945933542134, disc_loss = 0.007724853636722805
Trained batch 162 in epoch 13, gen_loss = 0.4392582048302048, disc_loss = 0.007687423901383885
Trained batch 163 in epoch 13, gen_loss = 0.43966376835980064, disc_loss = 0.00764824867301064
Trained batch 164 in epoch 13, gen_loss = 0.4397530151135994, disc_loss = 0.007606901874356536
Trained batch 165 in epoch 13, gen_loss = 0.43950174192348157, disc_loss = 0.00756733102060529
Trained batch 166 in epoch 13, gen_loss = 0.43925316908402356, disc_loss = 0.007552191394473242
Trained batch 167 in epoch 13, gen_loss = 0.43893361517361235, disc_loss = 0.007514529752370436
Trained batch 168 in epoch 13, gen_loss = 0.4392563661880042, disc_loss = 0.007488620434763714
Trained batch 169 in epoch 13, gen_loss = 0.4392801358419306, disc_loss = 0.0074617870251292035
Trained batch 170 in epoch 13, gen_loss = 0.4390133040690283, disc_loss = 0.007426242001302954
Trained batch 171 in epoch 13, gen_loss = 0.43930241794780245, disc_loss = 0.007390337719021603
Trained batch 172 in epoch 13, gen_loss = 0.4395955396180897, disc_loss = 0.007391368961190492
Trained batch 173 in epoch 13, gen_loss = 0.4395369491700468, disc_loss = 0.007358121558898075
Trained batch 174 in epoch 13, gen_loss = 0.4394340767179217, disc_loss = 0.007328373481452997
Trained batch 175 in epoch 13, gen_loss = 0.4390783706171946, disc_loss = 0.007290629004935247
Trained batch 176 in epoch 13, gen_loss = 0.438782067958918, disc_loss = 0.0072534198436680864
Trained batch 177 in epoch 13, gen_loss = 0.4388868683174755, disc_loss = 0.0072177684482637
Trained batch 178 in epoch 13, gen_loss = 0.4388669639326341, disc_loss = 0.007187305521688231
Trained batch 179 in epoch 13, gen_loss = 0.4392299294471741, disc_loss = 0.007153136730711493
Trained batch 180 in epoch 13, gen_loss = 0.43920877888716386, disc_loss = 0.007119460156810012
Trained batch 181 in epoch 13, gen_loss = 0.4394289526965592, disc_loss = 0.007087548881907344
Trained batch 182 in epoch 13, gen_loss = 0.4392403934171291, disc_loss = 0.007055504441571732
Trained batch 183 in epoch 13, gen_loss = 0.4392173058636811, disc_loss = 0.007021593643635835
Trained batch 184 in epoch 13, gen_loss = 0.4391420401431419, disc_loss = 0.00698943799487441
Trained batch 185 in epoch 13, gen_loss = 0.4389489378019046, disc_loss = 0.006957112758305245
Trained batch 186 in epoch 13, gen_loss = 0.43864926424893463, disc_loss = 0.006923618430724955
Trained batch 187 in epoch 13, gen_loss = 0.43856757673177316, disc_loss = 0.006891384473110133
Trained batch 188 in epoch 13, gen_loss = 0.4381941394515769, disc_loss = 0.0068602827026523535
Trained batch 189 in epoch 13, gen_loss = 0.4380580480161466, disc_loss = 0.006827616485105337
Trained batch 190 in epoch 13, gen_loss = 0.43818845221509484, disc_loss = 0.0067962081557388435
Trained batch 191 in epoch 13, gen_loss = 0.4380033849738538, disc_loss = 0.006764778263156283
Trained batch 192 in epoch 13, gen_loss = 0.4379951811825056, disc_loss = 0.006734103245788539
Trained batch 193 in epoch 13, gen_loss = 0.43817603081157525, disc_loss = 0.0067048712022069685
Trained batch 194 in epoch 13, gen_loss = 0.43831345500090185, disc_loss = 0.006676235804274583
Trained batch 195 in epoch 13, gen_loss = 0.43857393793913785, disc_loss = 0.006646254771669414
Trained batch 196 in epoch 13, gen_loss = 0.43897212066021063, disc_loss = 0.0066197152151418895
Trained batch 197 in epoch 13, gen_loss = 0.43873707047014526, disc_loss = 0.006591229764227238
Trained batch 198 in epoch 13, gen_loss = 0.43881915921541914, disc_loss = 0.00656247363325171
Trained batch 199 in epoch 13, gen_loss = 0.43875826880335805, disc_loss = 0.006534631079994142
Trained batch 200 in epoch 13, gen_loss = 0.43879348410302726, disc_loss = 0.006507792676317121
Trained batch 201 in epoch 13, gen_loss = 0.4389092705332407, disc_loss = 0.006482218352427687
Trained batch 202 in epoch 13, gen_loss = 0.43889048372583433, disc_loss = 0.006454882734418466
Trained batch 203 in epoch 13, gen_loss = 0.4389746960471658, disc_loss = 0.006426958362948533
Trained batch 204 in epoch 13, gen_loss = 0.43874898480206004, disc_loss = 0.0064019992285998676
Trained batch 205 in epoch 13, gen_loss = 0.4386146618324576, disc_loss = 0.006374943247562256
Trained batch 206 in epoch 13, gen_loss = 0.4386100947568958, disc_loss = 0.006349526718596293
Trained batch 207 in epoch 13, gen_loss = 0.43845298442129904, disc_loss = 0.006323332761474796
Trained batch 208 in epoch 13, gen_loss = 0.43872266408929417, disc_loss = 0.006301367462392112
Trained batch 209 in epoch 13, gen_loss = 0.43887211226281664, disc_loss = 0.006278986893206214
Trained batch 210 in epoch 13, gen_loss = 0.4388649926931372, disc_loss = 0.006253357077628745
Trained batch 211 in epoch 13, gen_loss = 0.4388207346200943, disc_loss = 0.006229025612965244
Trained batch 212 in epoch 13, gen_loss = 0.4390062040566279, disc_loss = 0.006208630298109104
Trained batch 213 in epoch 13, gen_loss = 0.4387160868288201, disc_loss = 0.006182997859579241
Trained batch 214 in epoch 13, gen_loss = 0.4384301313134127, disc_loss = 0.006159754115871565
Trained batch 215 in epoch 13, gen_loss = 0.43871908800469506, disc_loss = 0.006139072868757433
Trained batch 216 in epoch 13, gen_loss = 0.439009580744027, disc_loss = 0.006118123958741362
Trained batch 217 in epoch 13, gen_loss = 0.43877069474360264, disc_loss = 0.006093799773659215
Trained batch 218 in epoch 13, gen_loss = 0.4391874426031766, disc_loss = 0.006071472829675566
Trained batch 219 in epoch 13, gen_loss = 0.43904053297909823, disc_loss = 0.00605267397001047
Trained batch 220 in epoch 13, gen_loss = 0.4390507496859693, disc_loss = 0.006031546744357845
Trained batch 221 in epoch 13, gen_loss = 0.4391478984742551, disc_loss = 0.0060093570338050325
Trained batch 222 in epoch 13, gen_loss = 0.43924119413700874, disc_loss = 0.00598870952417364
Trained batch 223 in epoch 13, gen_loss = 0.43905525508203674, disc_loss = 0.00596470063101151
Trained batch 224 in epoch 13, gen_loss = 0.43916713211271496, disc_loss = 0.005949798071653478
Trained batch 225 in epoch 13, gen_loss = 0.43922428430709165, disc_loss = 0.005929316430088891
Trained batch 226 in epoch 13, gen_loss = 0.439028165807808, disc_loss = 0.005912364512837865
Trained batch 227 in epoch 13, gen_loss = 0.43883818963117766, disc_loss = 0.005891103956137637
Trained batch 228 in epoch 13, gen_loss = 0.438734449413666, disc_loss = 0.0058687503033268825
Trained batch 229 in epoch 13, gen_loss = 0.4386869129927262, disc_loss = 0.005845976833243976
Trained batch 230 in epoch 13, gen_loss = 0.4385614815728489, disc_loss = 0.005827838411601059
Trained batch 231 in epoch 13, gen_loss = 0.43864469923849764, disc_loss = 0.005806266097351909
Trained batch 232 in epoch 13, gen_loss = 0.438346010676781, disc_loss = 0.005799504078908667
Trained batch 233 in epoch 13, gen_loss = 0.438550133863066, disc_loss = 0.005777787115438801
Trained batch 234 in epoch 13, gen_loss = 0.4386328525999759, disc_loss = 0.005758604257952105
Trained batch 235 in epoch 13, gen_loss = 0.4384759360198247, disc_loss = 0.005740161776252612
Trained batch 236 in epoch 13, gen_loss = 0.4384002274350275, disc_loss = 0.005718330998574914
Trained batch 237 in epoch 13, gen_loss = 0.4383185072606351, disc_loss = 0.00569723203104232
Trained batch 238 in epoch 13, gen_loss = 0.43849326402073624, disc_loss = 0.005676421127866595
Trained batch 239 in epoch 13, gen_loss = 0.43851188545425734, disc_loss = 0.0056553279854900515
Trained batch 240 in epoch 13, gen_loss = 0.4385664392556392, disc_loss = 0.0056355903031404956
Trained batch 241 in epoch 13, gen_loss = 0.43894648490365873, disc_loss = 0.005618987252843405
Trained batch 242 in epoch 13, gen_loss = 0.4390348804340441, disc_loss = 0.005599324066870283
Trained batch 243 in epoch 13, gen_loss = 0.43882292704504045, disc_loss = 0.005581412239660524
Trained batch 244 in epoch 13, gen_loss = 0.4389498840789406, disc_loss = 0.0055616972250483775
Trained batch 245 in epoch 13, gen_loss = 0.438838348640659, disc_loss = 0.005542195977300511
Trained batch 246 in epoch 13, gen_loss = 0.43884609971451854, disc_loss = 0.005522838818439121
Trained batch 247 in epoch 13, gen_loss = 0.43882922864248675, disc_loss = 0.00550401663725009
Trained batch 248 in epoch 13, gen_loss = 0.43879830609842474, disc_loss = 0.005489707244634928
Trained batch 249 in epoch 13, gen_loss = 0.4387217189073563, disc_loss = 0.005475040988530963
Trained batch 250 in epoch 13, gen_loss = 0.4387466068049351, disc_loss = 0.005456159441394219
Trained batch 251 in epoch 13, gen_loss = 0.43883088964318473, disc_loss = 0.005442292320482906
Trained batch 252 in epoch 13, gen_loss = 0.43884110062018683, disc_loss = 0.005425751005877325
Trained batch 253 in epoch 13, gen_loss = 0.43860102157423814, disc_loss = 0.005408467128176213
Trained batch 254 in epoch 13, gen_loss = 0.43852683107058205, disc_loss = 0.005391165661607303
Trained batch 255 in epoch 13, gen_loss = 0.43867279205005616, disc_loss = 0.005373668627044026
Trained batch 256 in epoch 13, gen_loss = 0.4386086045304161, disc_loss = 0.005356446254395079
Trained batch 257 in epoch 13, gen_loss = 0.43872057467468023, disc_loss = 0.005339679520084458
Trained batch 258 in epoch 13, gen_loss = 0.43882053250511643, disc_loss = 0.005321770759693142
Trained batch 259 in epoch 13, gen_loss = 0.4389566658781125, disc_loss = 0.005304415191102844
Trained batch 260 in epoch 13, gen_loss = 0.4388130575532657, disc_loss = 0.0052881642114067755
Trained batch 261 in epoch 13, gen_loss = 0.4387287880855662, disc_loss = 0.0052706595196545065
Trained batch 262 in epoch 13, gen_loss = 0.43864283554907535, disc_loss = 0.005252567927721364
Trained batch 263 in epoch 13, gen_loss = 0.43860389642191655, disc_loss = 0.005238020404993387
Trained batch 264 in epoch 13, gen_loss = 0.4386097681972216, disc_loss = 0.005225316533941846
Trained batch 265 in epoch 13, gen_loss = 0.4388307542505121, disc_loss = 0.005210175639354533
Trained batch 266 in epoch 13, gen_loss = 0.43896815939788963, disc_loss = 0.005195578444689819
Trained batch 267 in epoch 13, gen_loss = 0.43922406824222254, disc_loss = 0.0051796674283582774
Trained batch 268 in epoch 13, gen_loss = 0.4391460076362227, disc_loss = 0.005171991563592535
Trained batch 269 in epoch 13, gen_loss = 0.43909320025532333, disc_loss = 0.005155306518362421
Trained batch 270 in epoch 13, gen_loss = 0.43915096365217793, disc_loss = 0.0051395949087968285
Trained batch 271 in epoch 13, gen_loss = 0.4389814152656233, disc_loss = 0.006492028770427329
Trained batch 272 in epoch 13, gen_loss = 0.4390375194968758, disc_loss = 0.006825638795953803
Trained batch 273 in epoch 13, gen_loss = 0.43878252967430725, disc_loss = 0.006920638518836213
Trained batch 274 in epoch 13, gen_loss = 0.43898650537837636, disc_loss = 0.006941470406441526
Trained batch 275 in epoch 13, gen_loss = 0.43900348548439966, disc_loss = 0.006934462257735161
Trained batch 276 in epoch 13, gen_loss = 0.43906558377648086, disc_loss = 0.0069291960315220735
Trained batch 277 in epoch 13, gen_loss = 0.4390168277908572, disc_loss = 0.006913782186176387
Trained batch 278 in epoch 13, gen_loss = 0.43899403229409223, disc_loss = 0.006897382966433001
Trained batch 279 in epoch 13, gen_loss = 0.4388390317559242, disc_loss = 0.006878720327014369
Trained batch 280 in epoch 13, gen_loss = 0.43894545739231583, disc_loss = 0.006861567007563346
Trained batch 281 in epoch 13, gen_loss = 0.43878412923068866, disc_loss = 0.006841689745353944
Trained batch 282 in epoch 13, gen_loss = 0.4390153410999177, disc_loss = 0.0068231031661458285
Trained batch 283 in epoch 13, gen_loss = 0.43902525914386964, disc_loss = 0.006803763852435046
Trained batch 284 in epoch 13, gen_loss = 0.4390460721233435, disc_loss = 0.00678789257725472
Trained batch 285 in epoch 13, gen_loss = 0.4390640285882083, disc_loss = 0.006769042616381173
Trained batch 286 in epoch 13, gen_loss = 0.43923658963279855, disc_loss = 0.00675003060248424
Trained batch 287 in epoch 13, gen_loss = 0.4393383457014958, disc_loss = 0.006730335759332067
Trained batch 288 in epoch 13, gen_loss = 0.4394552993320676, disc_loss = 0.006710982105249997
Trained batch 289 in epoch 13, gen_loss = 0.4393861648337594, disc_loss = 0.006692025209536198
Trained batch 290 in epoch 13, gen_loss = 0.43938510596137687, disc_loss = 0.0067396646655961566
Trained batch 291 in epoch 13, gen_loss = 0.4391271347460681, disc_loss = 0.006730982003181739
Trained batch 292 in epoch 13, gen_loss = 0.4389833529247766, disc_loss = 0.0067276848164631795
Trained batch 293 in epoch 13, gen_loss = 0.43873243723191374, disc_loss = 0.006710864105388572
Trained batch 294 in epoch 13, gen_loss = 0.4388531053470353, disc_loss = 0.006696460591786999
Trained batch 295 in epoch 13, gen_loss = 0.43889172868551435, disc_loss = 0.0066803106416734185
Trained batch 296 in epoch 13, gen_loss = 0.43897643434479583, disc_loss = 0.006662260036231943
Trained batch 297 in epoch 13, gen_loss = 0.43921090452463035, disc_loss = 0.006646033624912168
Trained batch 298 in epoch 13, gen_loss = 0.43907731273102524, disc_loss = 0.0066337512921305205
Trained batch 299 in epoch 13, gen_loss = 0.4391819294293722, disc_loss = 0.0066206306281189125
Trained batch 300 in epoch 13, gen_loss = 0.43925644204862097, disc_loss = 0.006614247974367236
Trained batch 301 in epoch 13, gen_loss = 0.439163911224201, disc_loss = 0.0066040576017763935
Trained batch 302 in epoch 13, gen_loss = 0.43918647486777984, disc_loss = 0.006592722746417565
Trained batch 303 in epoch 13, gen_loss = 0.439174018015987, disc_loss = 0.006577255125816201
Trained batch 304 in epoch 13, gen_loss = 0.43911512064152075, disc_loss = 0.006562691620459444
Trained batch 305 in epoch 13, gen_loss = 0.4390326073161917, disc_loss = 0.006548636223515192
Trained batch 306 in epoch 13, gen_loss = 0.43901793401482053, disc_loss = 0.006541597904525212
Trained batch 307 in epoch 13, gen_loss = 0.4388954166274566, disc_loss = 0.006563527983168818
Trained batch 308 in epoch 13, gen_loss = 0.43908212128966373, disc_loss = 0.006557997052774774
Trained batch 309 in epoch 13, gen_loss = 0.4392007036555198, disc_loss = 0.006549294184397665
Trained batch 310 in epoch 13, gen_loss = 0.43939573952622735, disc_loss = 0.006545651116755782
Trained batch 311 in epoch 13, gen_loss = 0.4394548949904931, disc_loss = 0.006552441481079978
Trained batch 312 in epoch 13, gen_loss = 0.4395841154427574, disc_loss = 0.006556911982771473
Trained batch 313 in epoch 13, gen_loss = 0.43963908200051377, disc_loss = 0.006548480112565337
Trained batch 314 in epoch 13, gen_loss = 0.43967854721205574, disc_loss = 0.006682672564102899
Trained batch 315 in epoch 13, gen_loss = 0.43993475533361676, disc_loss = 0.006781887875713668
Trained batch 316 in epoch 13, gen_loss = 0.44008858130557305, disc_loss = 0.006826725702847381
Trained batch 317 in epoch 13, gen_loss = 0.4403385740218672, disc_loss = 0.006830474830001194
Trained batch 318 in epoch 13, gen_loss = 0.4404839656569741, disc_loss = 0.006998497898964836
Trained batch 319 in epoch 13, gen_loss = 0.44084650874137876, disc_loss = 0.007025308723314083
Trained batch 320 in epoch 13, gen_loss = 0.44091263107050244, disc_loss = 0.007080846564406152
Trained batch 321 in epoch 13, gen_loss = 0.4412397949591927, disc_loss = 0.007075761574658895
Trained batch 322 in epoch 13, gen_loss = 0.4412147521788122, disc_loss = 0.007073855361664789
Trained batch 323 in epoch 13, gen_loss = 0.4411043268111017, disc_loss = 0.0070661444969354545
Trained batch 324 in epoch 13, gen_loss = 0.4412377460186298, disc_loss = 0.007052957886615052
Trained batch 325 in epoch 13, gen_loss = 0.4411007624828011, disc_loss = 0.007050528086399077
Trained batch 326 in epoch 13, gen_loss = 0.44102804385558547, disc_loss = 0.007035130050691237
Trained batch 327 in epoch 13, gen_loss = 0.44101745662529296, disc_loss = 0.007028958937309387
Trained batch 328 in epoch 13, gen_loss = 0.4414312735335805, disc_loss = 0.007082221419182478
Trained batch 329 in epoch 13, gen_loss = 0.4415729492902756, disc_loss = 0.007080007890225247
Trained batch 330 in epoch 13, gen_loss = 0.4417793261860793, disc_loss = 0.007068265933231127
Trained batch 331 in epoch 13, gen_loss = 0.44196820627134964, disc_loss = 0.0070697702891726315
Trained batch 332 in epoch 13, gen_loss = 0.442053023132834, disc_loss = 0.007057250893042722
Trained batch 333 in epoch 13, gen_loss = 0.44188417306917155, disc_loss = 0.0070471729059190585
Trained batch 334 in epoch 13, gen_loss = 0.44193096000756793, disc_loss = 0.007037228230150666
Trained batch 335 in epoch 13, gen_loss = 0.44204776352714925, disc_loss = 0.007022517602655128
Trained batch 336 in epoch 13, gen_loss = 0.4422312503575571, disc_loss = 0.007008964265973062
Trained batch 337 in epoch 13, gen_loss = 0.44220140020875537, disc_loss = 0.0070027588868717605
Trained batch 338 in epoch 13, gen_loss = 0.4421325470142308, disc_loss = 0.006988382079242935
Trained batch 339 in epoch 13, gen_loss = 0.4422385454177856, disc_loss = 0.006976942142457975
Trained batch 340 in epoch 13, gen_loss = 0.4423672959776568, disc_loss = 0.0069655162808717475
Trained batch 341 in epoch 13, gen_loss = 0.4422460506882584, disc_loss = 0.006951257560949511
Trained batch 342 in epoch 13, gen_loss = 0.44213229756661127, disc_loss = 0.007182240764795104
Trained batch 343 in epoch 13, gen_loss = 0.442077710704748, disc_loss = 0.007262878657689556
Trained batch 344 in epoch 13, gen_loss = 0.4419137324975885, disc_loss = 0.007301062579347712
Trained batch 345 in epoch 13, gen_loss = 0.4417352529102667, disc_loss = 0.0075405149796649255
Trained batch 346 in epoch 13, gen_loss = 0.44181416366217113, disc_loss = 0.0077116048350656455
Trained batch 347 in epoch 13, gen_loss = 0.44184399139264535, disc_loss = 0.0077193594907662005
Trained batch 348 in epoch 13, gen_loss = 0.4418666621504677, disc_loss = 0.007712327871527683
Trained batch 349 in epoch 13, gen_loss = 0.44197796974863324, disc_loss = 0.0077172399781245205
Trained batch 350 in epoch 13, gen_loss = 0.4419583060123302, disc_loss = 0.007708889562596814
Trained batch 351 in epoch 13, gen_loss = 0.4422069874338128, disc_loss = 0.007736675166432344
Trained batch 352 in epoch 13, gen_loss = 0.4422705626859206, disc_loss = 0.007735306911880188
Trained batch 353 in epoch 13, gen_loss = 0.4424267573713583, disc_loss = 0.00774099818584746
Trained batch 354 in epoch 13, gen_loss = 0.4423762386953327, disc_loss = 0.007739167050852007
Trained batch 355 in epoch 13, gen_loss = 0.44223263290491, disc_loss = 0.0077418225959304384
Trained batch 356 in epoch 13, gen_loss = 0.4422556857268016, disc_loss = 0.007755503793121824
Trained batch 357 in epoch 13, gen_loss = 0.4423845553531327, disc_loss = 0.007746452295582991
Trained batch 358 in epoch 13, gen_loss = 0.44225668276252855, disc_loss = 0.007770120912402723
Trained batch 359 in epoch 13, gen_loss = 0.4423385535677274, disc_loss = 0.007766401068268655
Trained batch 360 in epoch 13, gen_loss = 0.4421262654406212, disc_loss = 0.007757154262722715
Trained batch 361 in epoch 13, gen_loss = 0.4421532668626111, disc_loss = 0.007755437675794041
Trained batch 362 in epoch 13, gen_loss = 0.44227645457940323, disc_loss = 0.007752400172871766
Trained batch 363 in epoch 13, gen_loss = 0.4422155731654429, disc_loss = 0.007741736002831853
Trained batch 364 in epoch 13, gen_loss = 0.442341526403819, disc_loss = 0.007732764449391565
Trained batch 365 in epoch 13, gen_loss = 0.44228325434069815, disc_loss = 0.0077469659313340695
Trained batch 366 in epoch 13, gen_loss = 0.44225868176699334, disc_loss = 0.007735329359447538
Trained batch 367 in epoch 13, gen_loss = 0.44214898169688555, disc_loss = 0.007739553953402007
Trained batch 368 in epoch 13, gen_loss = 0.4421075189178229, disc_loss = 0.007733756200874825
Trained batch 369 in epoch 13, gen_loss = 0.44205104491195163, disc_loss = 0.00773554922465386
Trained batch 370 in epoch 13, gen_loss = 0.4420231394369326, disc_loss = 0.007724491412741335
Trained batch 371 in epoch 13, gen_loss = 0.44214577315956033, disc_loss = 0.007715164731639708
Trained batch 372 in epoch 13, gen_loss = 0.4422993385919617, disc_loss = 0.0077227894394675985
Trained batch 373 in epoch 13, gen_loss = 0.4422938254746524, disc_loss = 0.007720677077802605
Trained batch 374 in epoch 13, gen_loss = 0.4424155013561249, disc_loss = 0.007707270165594916
Trained batch 375 in epoch 13, gen_loss = 0.4421483837860696, disc_loss = 0.0077214064698869446
Trained batch 376 in epoch 13, gen_loss = 0.4421455556581128, disc_loss = 0.007706945999500784
Trained batch 377 in epoch 13, gen_loss = 0.44237469065757024, disc_loss = 0.007713985940128585
Trained batch 378 in epoch 13, gen_loss = 0.44248862065237243, disc_loss = 0.007716910540381825
Trained batch 379 in epoch 13, gen_loss = 0.44240661145825133, disc_loss = 0.007730113406432792
Trained batch 380 in epoch 13, gen_loss = 0.44214752480739683, disc_loss = 0.00805203761847988
Trained batch 381 in epoch 13, gen_loss = 0.4423572481926823, disc_loss = 0.008187401557343656
Trained batch 382 in epoch 13, gen_loss = 0.44259984577293493, disc_loss = 0.008218775749238155
Trained batch 383 in epoch 13, gen_loss = 0.4426780430755268, disc_loss = 0.008323895080745084
Trained batch 384 in epoch 13, gen_loss = 0.4425507755248578, disc_loss = 0.008315053125299126
Trained batch 385 in epoch 13, gen_loss = 0.44244832364079867, disc_loss = 0.008357523798452777
Trained batch 386 in epoch 13, gen_loss = 0.44254879872928293, disc_loss = 0.00835653799748438
Trained batch 387 in epoch 13, gen_loss = 0.4426083095448533, disc_loss = 0.00834862557965926
Trained batch 388 in epoch 13, gen_loss = 0.4426141904528159, disc_loss = 0.008359308504489918
Trained batch 389 in epoch 13, gen_loss = 0.4426775111601903, disc_loss = 0.008347204243704581
Trained batch 390 in epoch 13, gen_loss = 0.4425987508290869, disc_loss = 0.008336164770335854
Trained batch 391 in epoch 13, gen_loss = 0.4424621284920342, disc_loss = 0.008322087532605462
Trained batch 392 in epoch 13, gen_loss = 0.44241159775178246, disc_loss = 0.008314259675255582
Trained batch 393 in epoch 13, gen_loss = 0.442390003407062, disc_loss = 0.008302213138661958
Trained batch 394 in epoch 13, gen_loss = 0.4422778036020979, disc_loss = 0.008289718881685617
Trained batch 395 in epoch 13, gen_loss = 0.44237811509707964, disc_loss = 0.008280872041888704
Trained batch 396 in epoch 13, gen_loss = 0.44232255993622077, disc_loss = 0.00826917515078827
Trained batch 397 in epoch 13, gen_loss = 0.44255335149753033, disc_loss = 0.008281939988546354
Trained batch 398 in epoch 13, gen_loss = 0.4425348788126369, disc_loss = 0.008283889131506154
Trained batch 399 in epoch 13, gen_loss = 0.4424854869395494, disc_loss = 0.008275214190653059
Trained batch 400 in epoch 13, gen_loss = 0.44260530051150526, disc_loss = 0.008280755902357176
Trained batch 401 in epoch 13, gen_loss = 0.44264960511406853, disc_loss = 0.008316202804189064
Trained batch 402 in epoch 13, gen_loss = 0.44280677767604515, disc_loss = 0.008337105854608525
Trained batch 403 in epoch 13, gen_loss = 0.4427387051948226, disc_loss = 0.008335169077687206
Trained batch 404 in epoch 13, gen_loss = 0.4428852805384883, disc_loss = 0.008330412262211335
Trained batch 405 in epoch 13, gen_loss = 0.442855876361208, disc_loss = 0.008319697028835732
Trained batch 406 in epoch 13, gen_loss = 0.4428929494698452, disc_loss = 0.008303372706263726
Trained batch 407 in epoch 13, gen_loss = 0.44293614549964083, disc_loss = 0.008290134745538143
Trained batch 408 in epoch 13, gen_loss = 0.4428786375994787, disc_loss = 0.008289065149107214
Trained batch 409 in epoch 13, gen_loss = 0.44307073950767517, disc_loss = 0.008293612740604524
Trained batch 410 in epoch 13, gen_loss = 0.4431697060591983, disc_loss = 0.008288645304211499
Trained batch 411 in epoch 13, gen_loss = 0.44328124944156816, disc_loss = 0.008292619354550465
Trained batch 412 in epoch 13, gen_loss = 0.44341856197929846, disc_loss = 0.008299512469286402
Trained batch 413 in epoch 13, gen_loss = 0.4435065788923254, disc_loss = 0.008288302687997818
Trained batch 414 in epoch 13, gen_loss = 0.4435792589762125, disc_loss = 0.00829838648948998
Trained batch 415 in epoch 13, gen_loss = 0.44365783580220663, disc_loss = 0.008292613897747988
Trained batch 416 in epoch 13, gen_loss = 0.4436630192134592, disc_loss = 0.008279199746316768
Trained batch 417 in epoch 13, gen_loss = 0.443756894917009, disc_loss = 0.008264283907798042
Trained batch 418 in epoch 13, gen_loss = 0.443740565054172, disc_loss = 0.008300438194051117
Trained batch 419 in epoch 13, gen_loss = 0.44363156259059905, disc_loss = 0.008288293599893916
Trained batch 420 in epoch 13, gen_loss = 0.4436405370467632, disc_loss = 0.008308386277228222
Trained batch 421 in epoch 13, gen_loss = 0.4436613751389969, disc_loss = 0.008302147204213075
Trained batch 422 in epoch 13, gen_loss = 0.44343805545610737, disc_loss = 0.008336359238412768
Trained batch 423 in epoch 13, gen_loss = 0.4433519710909645, disc_loss = 0.008339358436301755
Trained batch 424 in epoch 13, gen_loss = 0.4434819515312419, disc_loss = 0.008333487903754062
Trained batch 425 in epoch 13, gen_loss = 0.44371706967902297, disc_loss = 0.008373277181783524
Trained batch 426 in epoch 13, gen_loss = 0.4437556102069256, disc_loss = 0.008365713701958592
Trained batch 427 in epoch 13, gen_loss = 0.44389904158137666, disc_loss = 0.008377950184567284
Trained batch 428 in epoch 13, gen_loss = 0.4439304368896084, disc_loss = 0.008413390200834783
Trained batch 429 in epoch 13, gen_loss = 0.4439447448004124, disc_loss = 0.00843696399174934
Trained batch 430 in epoch 13, gen_loss = 0.4439478990235074, disc_loss = 0.008455830155936634
Trained batch 431 in epoch 13, gen_loss = 0.44402922027640873, disc_loss = 0.008446268859929492
Trained batch 432 in epoch 13, gen_loss = 0.44399991789811205, disc_loss = 0.008493523272324362
Trained batch 433 in epoch 13, gen_loss = 0.44403676867210373, disc_loss = 0.008564138829800373
Trained batch 434 in epoch 13, gen_loss = 0.4442015215583231, disc_loss = 0.008554563080174741
Trained batch 435 in epoch 13, gen_loss = 0.4440431439685165, disc_loss = 0.008556317715049047
Trained batch 436 in epoch 13, gen_loss = 0.4441535795444209, disc_loss = 0.008645603699381601
Trained batch 437 in epoch 13, gen_loss = 0.4442296588121484, disc_loss = 0.008698995813852832
Trained batch 438 in epoch 13, gen_loss = 0.4444269480221907, disc_loss = 0.008826845036745325
Trained batch 439 in epoch 13, gen_loss = 0.44452999430623924, disc_loss = 0.008827742622816003
Trained batch 440 in epoch 13, gen_loss = 0.4444673689855199, disc_loss = 0.008987196002846115
Trained batch 441 in epoch 13, gen_loss = 0.44449516112718107, disc_loss = 0.009002670040722869
Trained batch 442 in epoch 13, gen_loss = 0.4446763386172043, disc_loss = 0.009053868598737764
Trained batch 443 in epoch 13, gen_loss = 0.4448274231037578, disc_loss = 0.009065846801129263
Trained batch 444 in epoch 13, gen_loss = 0.44486038745119333, disc_loss = 0.009263955405913293
Trained batch 445 in epoch 13, gen_loss = 0.44506142619212113, disc_loss = 0.009475786153032892
Trained batch 446 in epoch 13, gen_loss = 0.4451366921665951, disc_loss = 0.009479078180594182
Trained batch 447 in epoch 13, gen_loss = 0.4449424482882023, disc_loss = 0.009680419189213094
Trained batch 448 in epoch 13, gen_loss = 0.44500939139810064, disc_loss = 0.00969208061320703
Trained batch 449 in epoch 13, gen_loss = 0.44486705780029295, disc_loss = 0.009817883798386901
Trained batch 450 in epoch 13, gen_loss = 0.44485698604002233, disc_loss = 0.009892983750043697
Trained batch 451 in epoch 13, gen_loss = 0.44469275279382686, disc_loss = 0.01004391939526597
Trained batch 452 in epoch 13, gen_loss = 0.4447940036029479, disc_loss = 0.010268096542489565
Trained batch 453 in epoch 13, gen_loss = 0.44463840120426884, disc_loss = 0.010403083821723754
Trained batch 454 in epoch 13, gen_loss = 0.44463354643884595, disc_loss = 0.01057798264338379
Trained batch 455 in epoch 13, gen_loss = 0.444674039226875, disc_loss = 0.010841502378880569
Trained batch 456 in epoch 13, gen_loss = 0.44466104607874246, disc_loss = 0.011301896255412414
Trained batch 457 in epoch 13, gen_loss = 0.44466287450759173, disc_loss = 0.011398998365430447
Trained batch 458 in epoch 13, gen_loss = 0.44470615136337693, disc_loss = 0.011432138557468738
Trained batch 459 in epoch 13, gen_loss = 0.4448021549893462, disc_loss = 0.011471985980777233
Trained batch 460 in epoch 13, gen_loss = 0.44477352280161647, disc_loss = 0.01146620296425673
Trained batch 461 in epoch 13, gen_loss = 0.4447416948936718, disc_loss = 0.01146057905055768
Trained batch 462 in epoch 13, gen_loss = 0.4446583984351313, disc_loss = 0.011562676587117912
Trained batch 463 in epoch 13, gen_loss = 0.4445784279498561, disc_loss = 0.011617468523236939
Trained batch 464 in epoch 13, gen_loss = 0.44459796131298107, disc_loss = 0.011619107769451714
Trained batch 465 in epoch 13, gen_loss = 0.44451121052191495, disc_loss = 0.01160957735774303
Trained batch 466 in epoch 13, gen_loss = 0.4443653107838151, disc_loss = 0.011702958107287786
Trained batch 467 in epoch 13, gen_loss = 0.4444484557860937, disc_loss = 0.011812828102847561
Trained batch 468 in epoch 13, gen_loss = 0.4444876183578963, disc_loss = 0.011812747505529205
Trained batch 469 in epoch 13, gen_loss = 0.44457825485696184, disc_loss = 0.011826747762623857
Trained batch 470 in epoch 13, gen_loss = 0.4447756293219872, disc_loss = 0.0118480944517118
Trained batch 471 in epoch 13, gen_loss = 0.44488455797150983, disc_loss = 0.01204131647793505
Trained batch 472 in epoch 13, gen_loss = 0.4447911848603545, disc_loss = 0.012039989675788985
Trained batch 473 in epoch 13, gen_loss = 0.4447058043776685, disc_loss = 0.012303675907783855
Trained batch 474 in epoch 13, gen_loss = 0.44488371867882576, disc_loss = 0.012334827602056689
Trained batch 475 in epoch 13, gen_loss = 0.44478562743473454, disc_loss = 0.012408607547169458
Trained batch 476 in epoch 13, gen_loss = 0.4448542663011411, disc_loss = 0.012424036694262997
Trained batch 477 in epoch 13, gen_loss = 0.44488684571188364, disc_loss = 0.012445963055789705
Trained batch 478 in epoch 13, gen_loss = 0.44460307344763167, disc_loss = 0.012622080472811263
Trained batch 479 in epoch 13, gen_loss = 0.4445630388955275, disc_loss = 0.012658644034672761
Trained batch 480 in epoch 13, gen_loss = 0.4445548786195053, disc_loss = 0.012708271059532903
Trained batch 481 in epoch 13, gen_loss = 0.44452522138589645, disc_loss = 0.012914377857623737
Trained batch 482 in epoch 13, gen_loss = 0.44454661221484465, disc_loss = 0.01307672671139757
Trained batch 483 in epoch 13, gen_loss = 0.4444316567098799, disc_loss = 0.013284611401931297
Trained batch 484 in epoch 13, gen_loss = 0.4444495730793353, disc_loss = 0.013311846294805177
Trained batch 485 in epoch 13, gen_loss = 0.44456830596237024, disc_loss = 0.01334384124541134
Trained batch 486 in epoch 13, gen_loss = 0.4446135425836888, disc_loss = 0.013367750146235024
Trained batch 487 in epoch 13, gen_loss = 0.44453304621284123, disc_loss = 0.013349759477127694
Trained batch 488 in epoch 13, gen_loss = 0.44448663955573414, disc_loss = 0.013360576438222362
Trained batch 489 in epoch 13, gen_loss = 0.4444679305261495, disc_loss = 0.013361357742378831
Trained batch 490 in epoch 13, gen_loss = 0.44451260050785274, disc_loss = 0.013355975832871698
Trained batch 491 in epoch 13, gen_loss = 0.4445444191010987, disc_loss = 0.013341903512137071
Trained batch 492 in epoch 13, gen_loss = 0.4445417955003936, disc_loss = 0.01332327304289886
Trained batch 493 in epoch 13, gen_loss = 0.44462170104990123, disc_loss = 0.013315429744878144
Trained batch 494 in epoch 13, gen_loss = 0.44450164184425817, disc_loss = 0.013302444839483183
Trained batch 495 in epoch 13, gen_loss = 0.4444985224474822, disc_loss = 0.013323264072354388
Trained batch 496 in epoch 13, gen_loss = 0.4444612441528251, disc_loss = 0.013334610714704563
Trained batch 497 in epoch 13, gen_loss = 0.44450380811729584, disc_loss = 0.013437490558474284
Trained batch 498 in epoch 13, gen_loss = 0.4445834482361176, disc_loss = 0.013496205441883293
Trained batch 499 in epoch 13, gen_loss = 0.44454474157094953, disc_loss = 0.013484188726870343
Trained batch 500 in epoch 13, gen_loss = 0.44443547874391676, disc_loss = 0.013475993291954482
Trained batch 501 in epoch 13, gen_loss = 0.4442508138745904, disc_loss = 0.01352422138693672
Trained batch 502 in epoch 13, gen_loss = 0.44413788773667506, disc_loss = 0.013512763623138946
Trained batch 503 in epoch 13, gen_loss = 0.44410081467931234, disc_loss = 0.013580190425042047
Trained batch 504 in epoch 13, gen_loss = 0.44406845793865696, disc_loss = 0.013562300963336509
Trained batch 505 in epoch 13, gen_loss = 0.4441274106502533, disc_loss = 0.013692092768647322
Trained batch 506 in epoch 13, gen_loss = 0.44407181897342085, disc_loss = 0.013693187238613631
Trained batch 507 in epoch 13, gen_loss = 0.4441592355412761, disc_loss = 0.013710719914364402
Trained batch 508 in epoch 13, gen_loss = 0.4441733331600669, disc_loss = 0.014266297360013051
Trained batch 509 in epoch 13, gen_loss = 0.44409619412001444, disc_loss = 0.01432248715507597
Trained batch 510 in epoch 13, gen_loss = 0.4440108060603506, disc_loss = 0.014380767744411797
Trained batch 511 in epoch 13, gen_loss = 0.4440755814430304, disc_loss = 0.014412585296440739
Trained batch 512 in epoch 13, gen_loss = 0.44396738699305127, disc_loss = 0.01446967162387028
Trained batch 513 in epoch 13, gen_loss = 0.4439440923906022, disc_loss = 0.014495716042271253
Trained batch 514 in epoch 13, gen_loss = 0.44383014104898694, disc_loss = 0.014507984138292813
Trained batch 515 in epoch 13, gen_loss = 0.44387598116268484, disc_loss = 0.014531733244143124
Trained batch 516 in epoch 13, gen_loss = 0.4437865454062272, disc_loss = 0.014593210604313825
Trained batch 517 in epoch 13, gen_loss = 0.4440519784983521, disc_loss = 0.014743718811046533
Trained batch 518 in epoch 13, gen_loss = 0.44408542537964835, disc_loss = 0.014738395300277497
Trained batch 519 in epoch 13, gen_loss = 0.44408323254722815, disc_loss = 0.014853509436495818
Trained batch 520 in epoch 13, gen_loss = 0.4440364381745315, disc_loss = 0.014926766057681085
Trained batch 521 in epoch 13, gen_loss = 0.4440439992024067, disc_loss = 0.014926013365250538
Trained batch 522 in epoch 13, gen_loss = 0.4441354013765747, disc_loss = 0.014914030841120784
Trained batch 523 in epoch 13, gen_loss = 0.44410653400967137, disc_loss = 0.014928630679154427
Trained batch 524 in epoch 13, gen_loss = 0.4441871726512909, disc_loss = 0.015256855876096303
Trained batch 525 in epoch 13, gen_loss = 0.4442453980445862, disc_loss = 0.015288722263817311
Trained batch 526 in epoch 13, gen_loss = 0.44428568298043064, disc_loss = 0.015346727528135722
Trained batch 527 in epoch 13, gen_loss = 0.44424832121215085, disc_loss = 0.015564891775835404
Trained batch 528 in epoch 13, gen_loss = 0.4441776897032905, disc_loss = 0.015661262649829748
Trained batch 529 in epoch 13, gen_loss = 0.4441332447078993, disc_loss = 0.01575275974255934
Trained batch 530 in epoch 13, gen_loss = 0.44419346629114026, disc_loss = 0.015881960700957102
Trained batch 531 in epoch 13, gen_loss = 0.4442770965117261, disc_loss = 0.015942822971785637
Trained batch 532 in epoch 13, gen_loss = 0.44438343334376923, disc_loss = 0.016013338321192613
Trained batch 533 in epoch 13, gen_loss = 0.44424140006861884, disc_loss = 0.016066040137167042
Trained batch 534 in epoch 13, gen_loss = 0.4444513651812188, disc_loss = 0.016074087179840376
Trained batch 535 in epoch 13, gen_loss = 0.4445016894545128, disc_loss = 0.016089018658211857
Trained batch 536 in epoch 13, gen_loss = 0.44452402056706464, disc_loss = 0.01608551739480041
Trained batch 537 in epoch 13, gen_loss = 0.4446861471385318, disc_loss = 0.016186874849526176
Trained batch 538 in epoch 13, gen_loss = 0.4446864720288809, disc_loss = 0.016173298301128583
Trained batch 539 in epoch 13, gen_loss = 0.444726259123396, disc_loss = 0.016155813829930223
Trained batch 540 in epoch 13, gen_loss = 0.4445941045522249, disc_loss = 0.0161568085426747
Trained batch 541 in epoch 13, gen_loss = 0.44461729517722043, disc_loss = 0.016184187616862536
Trained batch 542 in epoch 13, gen_loss = 0.4447234203802288, disc_loss = 0.016213628896306273
Trained batch 543 in epoch 13, gen_loss = 0.44474315446089296, disc_loss = 0.016195666502693818
Trained batch 544 in epoch 13, gen_loss = 0.44463307201315505, disc_loss = 0.0162136775695659
Trained batch 545 in epoch 13, gen_loss = 0.44455621590762784, disc_loss = 0.01625342141634754
Trained batch 546 in epoch 13, gen_loss = 0.44477542265023784, disc_loss = 0.016322173469979145
Trained batch 547 in epoch 13, gen_loss = 0.44481459559097775, disc_loss = 0.016350747499722023
Trained batch 548 in epoch 13, gen_loss = 0.4449625338252993, disc_loss = 0.01634844023465452
Trained batch 549 in epoch 13, gen_loss = 0.4450268730250272, disc_loss = 0.0164025642729195
Trained batch 550 in epoch 13, gen_loss = 0.44482478315514357, disc_loss = 0.016512389185571342
Trained batch 551 in epoch 13, gen_loss = 0.44487794218719867, disc_loss = 0.016548609861090063
Trained batch 552 in epoch 13, gen_loss = 0.444913837674729, disc_loss = 0.01653838943867737
Trained batch 553 in epoch 13, gen_loss = 0.4448871518407918, disc_loss = 0.016519267186614943
Trained batch 554 in epoch 13, gen_loss = 0.444805673274908, disc_loss = 0.016531717962467926
Trained batch 555 in epoch 13, gen_loss = 0.4448466984380921, disc_loss = 0.016518073609365122
Trained batch 556 in epoch 13, gen_loss = 0.444826258577179, disc_loss = 0.016610143252036448
Trained batch 557 in epoch 13, gen_loss = 0.44488825363283946, disc_loss = 0.01662215178287471
Trained batch 558 in epoch 13, gen_loss = 0.4448629728050266, disc_loss = 0.016657235341401493
Trained batch 559 in epoch 13, gen_loss = 0.44494450981063505, disc_loss = 0.016660208182500875
Trained batch 560 in epoch 13, gen_loss = 0.44516965598133584, disc_loss = 0.016638998437545027
Trained batch 561 in epoch 13, gen_loss = 0.4452397209787708, disc_loss = 0.016742452446104516
Trained batch 562 in epoch 13, gen_loss = 0.4452429659942539, disc_loss = 0.016748977157363395
Trained batch 563 in epoch 13, gen_loss = 0.4451408310139433, disc_loss = 0.016777726429215704
Trained batch 564 in epoch 13, gen_loss = 0.44511355625844634, disc_loss = 0.016759866613490854
Trained batch 565 in epoch 13, gen_loss = 0.44505339081632794, disc_loss = 0.016750511684324988
Trained batch 566 in epoch 13, gen_loss = 0.4450672354016985, disc_loss = 0.01672750120720542
Trained batch 567 in epoch 13, gen_loss = 0.4450306239682184, disc_loss = 0.01670463844985393
Trained batch 568 in epoch 13, gen_loss = 0.44497761669812597, disc_loss = 0.016680956748805233
Trained batch 569 in epoch 13, gen_loss = 0.44484443675007734, disc_loss = 0.016659847930637434
Trained batch 570 in epoch 13, gen_loss = 0.4446839946999024, disc_loss = 0.01664335430488023
Trained batch 571 in epoch 13, gen_loss = 0.44457339396426726, disc_loss = 0.01664506436355731
Trained batch 572 in epoch 13, gen_loss = 0.4446706388009156, disc_loss = 0.016632027572376838
Trained batch 573 in epoch 13, gen_loss = 0.44461862244464795, disc_loss = 0.01663295452126857
Trained batch 574 in epoch 13, gen_loss = 0.4444839238083881, disc_loss = 0.016639799504216922
Trained batch 575 in epoch 13, gen_loss = 0.4445513779193991, disc_loss = 0.016656015135595226
Trained batch 576 in epoch 13, gen_loss = 0.44455979188558753, disc_loss = 0.01664976673898815
Trained batch 577 in epoch 13, gen_loss = 0.4444671913104899, disc_loss = 0.016669766922041477
Trained batch 578 in epoch 13, gen_loss = 0.44439148110223353, disc_loss = 0.01666097281141197
Trained batch 579 in epoch 13, gen_loss = 0.44443539715018765, disc_loss = 0.016642182979708667
Trained batch 580 in epoch 13, gen_loss = 0.444438703601824, disc_loss = 0.016638411343035172
Trained batch 581 in epoch 13, gen_loss = 0.4446135889418756, disc_loss = 0.016695817755863287
Trained batch 582 in epoch 13, gen_loss = 0.44465561673735265, disc_loss = 0.016675217539802077
Trained batch 583 in epoch 13, gen_loss = 0.44469986151750773, disc_loss = 0.016669385825094054
Trained batch 584 in epoch 13, gen_loss = 0.4447149823873471, disc_loss = 0.01665347324162881
Trained batch 585 in epoch 13, gen_loss = 0.4446940143869192, disc_loss = 0.01663817642769163
Trained batch 586 in epoch 13, gen_loss = 0.4445950589452123, disc_loss = 0.01668256207181258
Trained batch 587 in epoch 13, gen_loss = 0.44468655878183794, disc_loss = 0.01670498184667311
Trained batch 588 in epoch 13, gen_loss = 0.444881130054163, disc_loss = 0.01683728848896282
Trained batch 589 in epoch 13, gen_loss = 0.4449271474854421, disc_loss = 0.01683137476763893
Trained batch 590 in epoch 13, gen_loss = 0.4449525593501057, disc_loss = 0.016839598946300115
Trained batch 591 in epoch 13, gen_loss = 0.44500615563545676, disc_loss = 0.01683689763622415
Trained batch 592 in epoch 13, gen_loss = 0.44506977737251463, disc_loss = 0.016847935245485432
Trained batch 593 in epoch 13, gen_loss = 0.44502379893253147, disc_loss = 0.016826910784613867
Trained batch 594 in epoch 13, gen_loss = 0.44499481280310815, disc_loss = 0.016812302630214694
Trained batch 595 in epoch 13, gen_loss = 0.4449482345641059, disc_loss = 0.01681748012353466
Trained batch 596 in epoch 13, gen_loss = 0.4449898982467364, disc_loss = 0.016827369481052148
Trained batch 597 in epoch 13, gen_loss = 0.4450769488727767, disc_loss = 0.016813381255197848
Trained batch 598 in epoch 13, gen_loss = 0.4450636623001258, disc_loss = 0.016811335143144982
Trained batch 599 in epoch 13, gen_loss = 0.44493126824498175, disc_loss = 0.01680851281872795
Trained batch 600 in epoch 13, gen_loss = 0.44483781922081744, disc_loss = 0.016832779435333973
Trained batch 601 in epoch 13, gen_loss = 0.44486120823411845, disc_loss = 0.016853098905501435
Trained batch 602 in epoch 13, gen_loss = 0.44483032372855824, disc_loss = 0.016903475967350156
Trained batch 603 in epoch 13, gen_loss = 0.44470072192269444, disc_loss = 0.016983185866454444
Trained batch 604 in epoch 13, gen_loss = 0.44482931514416846, disc_loss = 0.017487628292484778
Trained batch 605 in epoch 13, gen_loss = 0.4448029075321978, disc_loss = 0.017486710952196834
Trained batch 606 in epoch 13, gen_loss = 0.4448300604961653, disc_loss = 0.01747477827674235
Trained batch 607 in epoch 13, gen_loss = 0.4448704598961692, disc_loss = 0.017453538630146988
Trained batch 608 in epoch 13, gen_loss = 0.444841488730927, disc_loss = 0.017447422427730865
Trained batch 609 in epoch 13, gen_loss = 0.44490180767950466, disc_loss = 0.017431781306046015
Trained batch 610 in epoch 13, gen_loss = 0.4448488342976609, disc_loss = 0.01742204032177578
Trained batch 611 in epoch 13, gen_loss = 0.4447963622465632, disc_loss = 0.01744616388748826
Trained batch 612 in epoch 13, gen_loss = 0.4447516174242508, disc_loss = 0.01747986257207682
Trained batch 613 in epoch 13, gen_loss = 0.44475960648991775, disc_loss = 0.017890215561086623
Trained batch 614 in epoch 13, gen_loss = 0.44453733679724905, disc_loss = 0.018237978472313805
Trained batch 615 in epoch 13, gen_loss = 0.44441294679781057, disc_loss = 0.018367412183532043
Trained batch 616 in epoch 13, gen_loss = 0.4444901045755977, disc_loss = 0.018541106490253787
Trained batch 617 in epoch 13, gen_loss = 0.4444890401317078, disc_loss = 0.018705920407640474
Trained batch 618 in epoch 13, gen_loss = 0.44450695198841744, disc_loss = 0.01910872886018295
Trained batch 619 in epoch 13, gen_loss = 0.4443833772693911, disc_loss = 0.01912989303743797
Trained batch 620 in epoch 13, gen_loss = 0.4442205519779869, disc_loss = 0.019335367635301887
Trained batch 621 in epoch 13, gen_loss = 0.44410969158844166, disc_loss = 0.019380951148474296
Trained batch 622 in epoch 13, gen_loss = 0.4442028447292016, disc_loss = 0.019531080847042484
Trained batch 623 in epoch 13, gen_loss = 0.4442695377824398, disc_loss = 0.01952410980149393
Trained batch 624 in epoch 13, gen_loss = 0.4442086591720581, disc_loss = 0.019553951776959
Trained batch 625 in epoch 13, gen_loss = 0.4440453336737788, disc_loss = 0.019592876907046766
Trained batch 626 in epoch 13, gen_loss = 0.4439277265345651, disc_loss = 0.019605595132215707
Trained batch 627 in epoch 13, gen_loss = 0.4438498791805498, disc_loss = 0.019690032355275278
Trained batch 628 in epoch 13, gen_loss = 0.44388818916152506, disc_loss = 0.019678004471909413
Trained batch 629 in epoch 13, gen_loss = 0.44393680923514894, disc_loss = 0.019655385562625256
Trained batch 630 in epoch 13, gen_loss = 0.4438294808479194, disc_loss = 0.01964894004949116
Trained batch 631 in epoch 13, gen_loss = 0.4438153540220442, disc_loss = 0.020106059905249166
Trained batch 632 in epoch 13, gen_loss = 0.44380584665196016, disc_loss = 0.02020145879082211
Trained batch 633 in epoch 13, gen_loss = 0.44378022450001836, disc_loss = 0.02028603954567524
Trained batch 634 in epoch 13, gen_loss = 0.44371983310369056, disc_loss = 0.020265921203265567
Trained batch 635 in epoch 13, gen_loss = 0.4436003007697609, disc_loss = 0.020482331682208914
Trained batch 636 in epoch 13, gen_loss = 0.44370619276629136, disc_loss = 0.020596699439189462
Trained batch 637 in epoch 13, gen_loss = 0.44375037422935043, disc_loss = 0.020579130944414912
Trained batch 638 in epoch 13, gen_loss = 0.4436744293883, disc_loss = 0.020573092080362676
Trained batch 639 in epoch 13, gen_loss = 0.44365848912857475, disc_loss = 0.020598622645229624
Trained batch 640 in epoch 13, gen_loss = 0.4436565595279432, disc_loss = 0.02058295332648691
Trained batch 641 in epoch 13, gen_loss = 0.44369328583698037, disc_loss = 0.020581616922332454
Trained batch 642 in epoch 13, gen_loss = 0.44371133769281546, disc_loss = 0.02061201376325565
Trained batch 643 in epoch 13, gen_loss = 0.4436476687374322, disc_loss = 0.020656404106607313
Trained batch 644 in epoch 13, gen_loss = 0.4436350446800853, disc_loss = 0.021005372348775756
Trained batch 645 in epoch 13, gen_loss = 0.4436565511643702, disc_loss = 0.021158727818138424
Trained batch 646 in epoch 13, gen_loss = 0.4435738034465766, disc_loss = 0.02183773798506039
Trained batch 647 in epoch 13, gen_loss = 0.44360047408644065, disc_loss = 0.02195426719755446
Trained batch 648 in epoch 13, gen_loss = 0.4434947017895973, disc_loss = 0.022044466143489767
Trained batch 649 in epoch 13, gen_loss = 0.44335488754969377, disc_loss = 0.022076678835751058
Trained batch 650 in epoch 13, gen_loss = 0.4432953446416811, disc_loss = 0.022199821280216806
Trained batch 651 in epoch 13, gen_loss = 0.4432192479083143, disc_loss = 0.022291385458155243
Trained batch 652 in epoch 13, gen_loss = 0.44346437761831065, disc_loss = 0.02244467097516407
Trained batch 653 in epoch 13, gen_loss = 0.44342124393773735, disc_loss = 0.02244881626353129
Trained batch 654 in epoch 13, gen_loss = 0.4434410838680413, disc_loss = 0.02245657503238758
Trained batch 655 in epoch 13, gen_loss = 0.4434155030857499, disc_loss = 0.022563450130181125
Trained batch 656 in epoch 13, gen_loss = 0.443483257175762, disc_loss = 0.022583757951902438
Trained batch 657 in epoch 13, gen_loss = 0.4435667517880901, disc_loss = 0.022570533146635888
Trained batch 658 in epoch 13, gen_loss = 0.4435968640541632, disc_loss = 0.022587893607924455
Trained batch 659 in epoch 13, gen_loss = 0.44349722451332846, disc_loss = 0.02257684762395608
Trained batch 660 in epoch 13, gen_loss = 0.44338804221910716, disc_loss = 0.022632045118503114
Trained batch 661 in epoch 13, gen_loss = 0.4434875189537728, disc_loss = 0.022609259897534907
Trained batch 662 in epoch 13, gen_loss = 0.4435173920376808, disc_loss = 0.0226047508129541
Trained batch 663 in epoch 13, gen_loss = 0.4434925155736596, disc_loss = 0.022577842340716272
Trained batch 664 in epoch 13, gen_loss = 0.4434891969637763, disc_loss = 0.02255965546001085
Trained batch 665 in epoch 13, gen_loss = 0.4434670382612818, disc_loss = 0.022594509268208902
Trained batch 666 in epoch 13, gen_loss = 0.44353884391520154, disc_loss = 0.022596866095744385
Trained batch 667 in epoch 13, gen_loss = 0.4435878788193543, disc_loss = 0.02270721242861393
Trained batch 668 in epoch 13, gen_loss = 0.4436910633994503, disc_loss = 0.022773343732306297
Trained batch 669 in epoch 13, gen_loss = 0.44376656017196714, disc_loss = 0.022771591361813635
Trained batch 670 in epoch 13, gen_loss = 0.4438165190411751, disc_loss = 0.02275175928889778
Trained batch 671 in epoch 13, gen_loss = 0.4437834475899026, disc_loss = 0.022815684578138946
Trained batch 672 in epoch 13, gen_loss = 0.44380953438568965, disc_loss = 0.02280403603851535
Trained batch 673 in epoch 13, gen_loss = 0.4439807280853877, disc_loss = 0.02278009147361855
Trained batch 674 in epoch 13, gen_loss = 0.44398153168183785, disc_loss = 0.02276663600794833
Trained batch 675 in epoch 13, gen_loss = 0.44416089536699316, disc_loss = 0.022932538547251406
Trained batch 676 in epoch 13, gen_loss = 0.44421584527812996, disc_loss = 0.022919447708254517
Trained batch 677 in epoch 13, gen_loss = 0.4441349700225138, disc_loss = 0.02292883121782837
Trained batch 678 in epoch 13, gen_loss = 0.4441428791967513, disc_loss = 0.02304053238907826
Trained batch 679 in epoch 13, gen_loss = 0.4442340480054126, disc_loss = 0.02306601765979876
Trained batch 680 in epoch 13, gen_loss = 0.4442957955660099, disc_loss = 0.023069946410745744
Trained batch 681 in epoch 13, gen_loss = 0.44436601140806753, disc_loss = 0.023048293135843112
Trained batch 682 in epoch 13, gen_loss = 0.4443805604780401, disc_loss = 0.02303181563508813
Trained batch 683 in epoch 13, gen_loss = 0.44433859618086563, disc_loss = 0.023012589561999423
Trained batch 684 in epoch 13, gen_loss = 0.4444138335485528, disc_loss = 0.022994095813924868
Trained batch 685 in epoch 13, gen_loss = 0.44445881873108556, disc_loss = 0.02296576225052862
Trained batch 686 in epoch 13, gen_loss = 0.4444136737128706, disc_loss = 0.02294928772836582
Trained batch 687 in epoch 13, gen_loss = 0.44434573947516987, disc_loss = 0.02301310434166564
Trained batch 688 in epoch 13, gen_loss = 0.44421284867474925, disc_loss = 0.023144138161348467
Trained batch 689 in epoch 13, gen_loss = 0.444224940261979, disc_loss = 0.02313663797888338
Trained batch 690 in epoch 13, gen_loss = 0.44431385497108383, disc_loss = 0.023125324275124922
Trained batch 691 in epoch 13, gen_loss = 0.444257561957216, disc_loss = 0.023097410969499424
Trained batch 692 in epoch 13, gen_loss = 0.44429791601533325, disc_loss = 0.02315971705693655
Trained batch 693 in epoch 13, gen_loss = 0.4443272663983557, disc_loss = 0.02317180555841888
Trained batch 694 in epoch 13, gen_loss = 0.44437332830840737, disc_loss = 0.02322848726971839
Trained batch 695 in epoch 13, gen_loss = 0.44434020342840547, disc_loss = 0.023215223797402967
Trained batch 696 in epoch 13, gen_loss = 0.4443342315415228, disc_loss = 0.023213137099365712
Trained batch 697 in epoch 13, gen_loss = 0.4443758718007615, disc_loss = 0.02319049534243118
Trained batch 698 in epoch 13, gen_loss = 0.44455409113941274, disc_loss = 0.023175328636031667
Trained batch 699 in epoch 13, gen_loss = 0.4445255753823689, disc_loss = 0.0231520073014378
Trained batch 700 in epoch 13, gen_loss = 0.4445332044286497, disc_loss = 0.02312272768477629
Trained batch 701 in epoch 13, gen_loss = 0.44454081203692997, disc_loss = 0.023097413327203973
Trained batch 702 in epoch 13, gen_loss = 0.4446083235621961, disc_loss = 0.023068546259061698
Trained batch 703 in epoch 13, gen_loss = 0.44451308889653196, disc_loss = 0.02304081735383079
Trained batch 704 in epoch 13, gen_loss = 0.44455599784851074, disc_loss = 0.023016208628067046
Trained batch 705 in epoch 13, gen_loss = 0.44448686291914824, disc_loss = 0.022990249973760056
Trained batch 706 in epoch 13, gen_loss = 0.4445013850716587, disc_loss = 0.022966747720003962
Trained batch 707 in epoch 13, gen_loss = 0.444431236739886, disc_loss = 0.022939143402963654
Trained batch 708 in epoch 13, gen_loss = 0.4442670259976757, disc_loss = 0.022909558964834112
Trained batch 709 in epoch 13, gen_loss = 0.44425656119702567, disc_loss = 0.022879954704581956
Trained batch 710 in epoch 13, gen_loss = 0.44424990104555917, disc_loss = 0.022852545153184592
Trained batch 711 in epoch 13, gen_loss = 0.4442947534948922, disc_loss = 0.022823010458482763
Trained batch 712 in epoch 13, gen_loss = 0.4442296368794889, disc_loss = 0.022794575606463648
Trained batch 713 in epoch 13, gen_loss = 0.44425744640560044, disc_loss = 0.02276558742476288
Trained batch 714 in epoch 13, gen_loss = 0.4441611385428822, disc_loss = 0.02274027927453024
Trained batch 715 in epoch 13, gen_loss = 0.44411120305680696, disc_loss = 0.022710666310025232
Trained batch 716 in epoch 13, gen_loss = 0.4440864216499914, disc_loss = 0.02268322055845689
Trained batch 717 in epoch 13, gen_loss = 0.4439772775495285, disc_loss = 0.022662802442582713
Trained batch 718 in epoch 13, gen_loss = 0.4439101337308844, disc_loss = 0.022636436379802193
Trained batch 719 in epoch 13, gen_loss = 0.44391484264698294, disc_loss = 0.02260724954459066
Trained batch 720 in epoch 13, gen_loss = 0.4439428164294292, disc_loss = 0.02258167980382821
Trained batch 721 in epoch 13, gen_loss = 0.4439005383246493, disc_loss = 0.022553317020021616
Trained batch 722 in epoch 13, gen_loss = 0.443847006452199, disc_loss = 0.022525178522797736
Trained batch 723 in epoch 13, gen_loss = 0.44373286054443917, disc_loss = 0.022496200299941427
Trained batch 724 in epoch 13, gen_loss = 0.4437642048145163, disc_loss = 0.022468330710644607
Trained batch 725 in epoch 13, gen_loss = 0.443750335452642, disc_loss = 0.022440294573018098
Trained batch 726 in epoch 13, gen_loss = 0.44378429725048796, disc_loss = 0.022412106878523866
Trained batch 727 in epoch 13, gen_loss = 0.44384065340017226, disc_loss = 0.022383603770931886
Trained batch 728 in epoch 13, gen_loss = 0.4437972920012899, disc_loss = 0.0223582314315542
Trained batch 729 in epoch 13, gen_loss = 0.4437793897031105, disc_loss = 0.022329842783383107
Trained batch 730 in epoch 13, gen_loss = 0.4438408114597018, disc_loss = 0.02230176106815146
Trained batch 731 in epoch 13, gen_loss = 0.44382073091027513, disc_loss = 0.02227382896381527
Trained batch 732 in epoch 13, gen_loss = 0.4437791478259827, disc_loss = 0.022252683553178915
Trained batch 733 in epoch 13, gen_loss = 0.44374954883181755, disc_loss = 0.022224722126700562
Trained batch 734 in epoch 13, gen_loss = 0.44370518870094194, disc_loss = 0.022198553133255416
Trained batch 735 in epoch 13, gen_loss = 0.44379016291350126, disc_loss = 0.022172211741037798
Trained batch 736 in epoch 13, gen_loss = 0.4438497581426939, disc_loss = 0.022148778596532807
Trained batch 737 in epoch 13, gen_loss = 0.4438942279111402, disc_loss = 0.0221217026548185
Trained batch 738 in epoch 13, gen_loss = 0.44390183162947305, disc_loss = 0.022096206088290778
Trained batch 739 in epoch 13, gen_loss = 0.4438601712922792, disc_loss = 0.022069376660668216
Trained batch 740 in epoch 13, gen_loss = 0.44385606392353333, disc_loss = 0.022042927672670506
Trained batch 741 in epoch 13, gen_loss = 0.44379095697017373, disc_loss = 0.022015259469541748
Trained batch 742 in epoch 13, gen_loss = 0.44373042402164775, disc_loss = 0.021987659205189965
Trained batch 743 in epoch 13, gen_loss = 0.4436767310384781, disc_loss = 0.021962600257260205
Trained batch 744 in epoch 13, gen_loss = 0.4436236782361997, disc_loss = 0.021936118104276342
Trained batch 745 in epoch 13, gen_loss = 0.44358513134733923, disc_loss = 0.021911305242440296
Testing Epoch 13
Training Epoch 14
Trained batch 0 in epoch 14, gen_loss = 0.4716757535934448, disc_loss = 0.01342715136706829
Trained batch 1 in epoch 14, gen_loss = 0.4838454872369766, disc_loss = 0.008366641006432474
Trained batch 2 in epoch 14, gen_loss = 0.48797964056332904, disc_loss = 0.006419909341881673
Trained batch 3 in epoch 14, gen_loss = 0.4732324481010437, disc_loss = 0.00571297510759905
Trained batch 4 in epoch 14, gen_loss = 0.45717228651046754, disc_loss = 0.005251967860385775
Trained batch 5 in epoch 14, gen_loss = 0.45143402616182965, disc_loss = 0.00507886300329119
Trained batch 6 in epoch 14, gen_loss = 0.44669696262904574, disc_loss = 0.00488148579773094
Trained batch 7 in epoch 14, gen_loss = 0.4400116465985775, disc_loss = 0.004566138872178271
Trained batch 8 in epoch 14, gen_loss = 0.446017540163464, disc_loss = 0.005871650892206364
Trained batch 9 in epoch 14, gen_loss = 0.4475772619247437, disc_loss = 0.005658457474783063
Trained batch 10 in epoch 14, gen_loss = 0.445580544796857, disc_loss = 0.007236759644001722
Trained batch 11 in epoch 14, gen_loss = 0.44964751849571866, disc_loss = 0.007031275619131823
Trained batch 12 in epoch 14, gen_loss = 0.4448154018475459, disc_loss = 0.010724452861513082
Trained batch 13 in epoch 14, gen_loss = 0.44775604563099997, disc_loss = 0.010662748045953256
Trained batch 14 in epoch 14, gen_loss = 0.4502675950527191, disc_loss = 0.01600126496826609
Trained batch 15 in epoch 14, gen_loss = 0.44928607530891895, disc_loss = 0.01849434056202881
Trained batch 16 in epoch 14, gen_loss = 0.4525039844653186, disc_loss = 0.017756125314489883
Trained batch 17 in epoch 14, gen_loss = 0.4553259528345532, disc_loss = 0.017812321402339473
Trained batch 18 in epoch 14, gen_loss = 0.45277045745598643, disc_loss = 0.01724256153561567
Trained batch 19 in epoch 14, gen_loss = 0.4467524871230125, disc_loss = 0.018721784371882676
Trained batch 20 in epoch 14, gen_loss = 0.4480261504650116, disc_loss = 0.01924539916217327
Trained batch 21 in epoch 14, gen_loss = 0.44919904389164667, disc_loss = 0.02114625588398088
Trained batch 22 in epoch 14, gen_loss = 0.4529780240162559, disc_loss = 0.02096437055455602
Trained batch 23 in epoch 14, gen_loss = 0.45380357404549915, disc_loss = 0.020622889511287212
Trained batch 24 in epoch 14, gen_loss = 0.45490266680717467, disc_loss = 0.020853935703635217
Trained batch 25 in epoch 14, gen_loss = 0.4521668324103722, disc_loss = 0.02060928364069416
Trained batch 26 in epoch 14, gen_loss = 0.4491281310717265, disc_loss = 0.02056445695321869
Trained batch 27 in epoch 14, gen_loss = 0.44580541976860594, disc_loss = 0.020439275573672994
Trained batch 28 in epoch 14, gen_loss = 0.4424443892363844, disc_loss = 0.02096790887800784
Trained batch 29 in epoch 14, gen_loss = 0.44035342931747434, disc_loss = 0.021975139187028012
Trained batch 30 in epoch 14, gen_loss = 0.4401835578103219, disc_loss = 0.02274813313758181
Trained batch 31 in epoch 14, gen_loss = 0.4423835063353181, disc_loss = 0.022356531728291884
Trained batch 32 in epoch 14, gen_loss = 0.4428087536132697, disc_loss = 0.025516347141202652
Trained batch 33 in epoch 14, gen_loss = 0.44301898426869335, disc_loss = 0.025052929434048778
Trained batch 34 in epoch 14, gen_loss = 0.44277750168527874, disc_loss = 0.026646780355700426
Trained batch 35 in epoch 14, gen_loss = 0.4411799634496371, disc_loss = 0.026021986578901608
Trained batch 36 in epoch 14, gen_loss = 0.4438686620544743, disc_loss = 0.026747293166212133
Trained batch 37 in epoch 14, gen_loss = 0.44587910881167964, disc_loss = 0.026179671937011574
Trained batch 38 in epoch 14, gen_loss = 0.44652125468620885, disc_loss = 0.028857127082749054
Trained batch 39 in epoch 14, gen_loss = 0.44700193107128144, disc_loss = 0.03226764859864488
Trained batch 40 in epoch 14, gen_loss = 0.4453471521051919, disc_loss = 0.03165239028678071
Trained batch 41 in epoch 14, gen_loss = 0.4439058502515157, disc_loss = 0.031206033913241255
Trained batch 42 in epoch 14, gen_loss = 0.4430591179880985, disc_loss = 0.030673291436721418
Trained batch 43 in epoch 14, gen_loss = 0.4439127424901182, disc_loss = 0.03058512283446775
Trained batch 44 in epoch 14, gen_loss = 0.4449061943425073, disc_loss = 0.03014726834371686
Trained batch 45 in epoch 14, gen_loss = 0.44372024743453314, disc_loss = 0.029992671086169456
Trained batch 46 in epoch 14, gen_loss = 0.44352288639291804, disc_loss = 0.030198923104066164
Trained batch 47 in epoch 14, gen_loss = 0.442080598945419, disc_loss = 0.030744473731222872
Trained batch 48 in epoch 14, gen_loss = 0.44226400949517075, disc_loss = 0.030356494947431648
Trained batch 49 in epoch 14, gen_loss = 0.4429145741462708, disc_loss = 0.029982398161664606
Trained batch 50 in epoch 14, gen_loss = 0.4430421187597163, disc_loss = 0.029521691384633966
Trained batch 51 in epoch 14, gen_loss = 0.44242287828372073, disc_loss = 0.02910346984684181
Trained batch 52 in epoch 14, gen_loss = 0.44148504734039307, disc_loss = 0.02870957095632857
Trained batch 53 in epoch 14, gen_loss = 0.44125651430200646, disc_loss = 0.028246611831019872
Trained batch 54 in epoch 14, gen_loss = 0.4422983792695132, disc_loss = 0.0278238603760573
Trained batch 55 in epoch 14, gen_loss = 0.4432956028197493, disc_loss = 0.02750798940957923
Trained batch 56 in epoch 14, gen_loss = 0.44274164553274187, disc_loss = 0.027108735707180018
Trained batch 57 in epoch 14, gen_loss = 0.44213377966963013, disc_loss = 0.026708068081242
Trained batch 58 in epoch 14, gen_loss = 0.4415088018118325, disc_loss = 0.026310600533734185
Trained batch 59 in epoch 14, gen_loss = 0.44168817400932314, disc_loss = 0.025922004067494224
Trained batch 60 in epoch 14, gen_loss = 0.44217543377250923, disc_loss = 0.025595779664295375
Trained batch 61 in epoch 14, gen_loss = 0.4423644816683185, disc_loss = 0.025210682569342033
Trained batch 62 in epoch 14, gen_loss = 0.44258693002519156, disc_loss = 0.024848598014888545
Trained batch 63 in epoch 14, gen_loss = 0.44316662987694144, disc_loss = 0.02449499978320091
Trained batch 64 in epoch 14, gen_loss = 0.4447596004376045, disc_loss = 0.02452157403055865
Trained batch 65 in epoch 14, gen_loss = 0.44448908215219324, disc_loss = 0.024280153521844608
Trained batch 66 in epoch 14, gen_loss = 0.4453028920871108, disc_loss = 0.024007332347917246
Trained batch 67 in epoch 14, gen_loss = 0.4461371635689455, disc_loss = 0.023687524899073383
Trained batch 68 in epoch 14, gen_loss = 0.4451769763144894, disc_loss = 0.023429640049141817
Trained batch 69 in epoch 14, gen_loss = 0.44444877973624636, disc_loss = 0.02314834506583533
Trained batch 70 in epoch 14, gen_loss = 0.44461177646274297, disc_loss = 0.02284695932799032
Trained batch 71 in epoch 14, gen_loss = 0.44376880096064675, disc_loss = 0.022582660099336255
Trained batch 72 in epoch 14, gen_loss = 0.4436976240105825, disc_loss = 0.022314511188497282
Trained batch 73 in epoch 14, gen_loss = 0.44427514478966995, disc_loss = 0.02203753942661491
Trained batch 74 in epoch 14, gen_loss = 0.4442796782652537, disc_loss = 0.021766359851074717
Trained batch 75 in epoch 14, gen_loss = 0.44398383600147145, disc_loss = 0.02149620088656727
Trained batch 76 in epoch 14, gen_loss = 0.44399799348472, disc_loss = 0.021231817328008256
Trained batch 77 in epoch 14, gen_loss = 0.4427320334391716, disc_loss = 0.020990780332328703
Trained batch 78 in epoch 14, gen_loss = 0.4432076853287371, disc_loss = 0.02077628514593868
Trained batch 79 in epoch 14, gen_loss = 0.4433644138276577, disc_loss = 0.020540029744734057
Trained batch 80 in epoch 14, gen_loss = 0.4432611384509522, disc_loss = 0.020324431578226297
Trained batch 81 in epoch 14, gen_loss = 0.4436702459323697, disc_loss = 0.020098028732918022
Trained batch 82 in epoch 14, gen_loss = 0.443872903484896, disc_loss = 0.01987152034557054
Trained batch 83 in epoch 14, gen_loss = 0.4448946891796021, disc_loss = 0.019668065265120407
Trained batch 84 in epoch 14, gen_loss = 0.44513333334642297, disc_loss = 0.019475819960729602
Trained batch 85 in epoch 14, gen_loss = 0.4446569088586541, disc_loss = 0.019265222943896904
Trained batch 86 in epoch 14, gen_loss = 0.4445221307633937, disc_loss = 0.01906814684839812
Trained batch 87 in epoch 14, gen_loss = 0.4445277103646235, disc_loss = 0.018865910629921764
Trained batch 88 in epoch 14, gen_loss = 0.4437324508522334, disc_loss = 0.01868620709898055
Trained batch 89 in epoch 14, gen_loss = 0.44320576985677085, disc_loss = 0.01851795809990209
Trained batch 90 in epoch 14, gen_loss = 0.44343125885659523, disc_loss = 0.01832599133882508
Trained batch 91 in epoch 14, gen_loss = 0.44307550463987433, disc_loss = 0.018159560956637903
Trained batch 92 in epoch 14, gen_loss = 0.44263618159037765, disc_loss = 0.017983595724217594
Trained batch 93 in epoch 14, gen_loss = 0.4423746558579993, disc_loss = 0.017811719852034003
Trained batch 94 in epoch 14, gen_loss = 0.44251852725681506, disc_loss = 0.017669152442709005
Trained batch 95 in epoch 14, gen_loss = 0.4419515648235877, disc_loss = 0.017496370001026662
Trained batch 96 in epoch 14, gen_loss = 0.4409602895839927, disc_loss = 0.017349723166037237
Trained batch 97 in epoch 14, gen_loss = 0.44110022211561395, disc_loss = 0.017199841709284833
Trained batch 98 in epoch 14, gen_loss = 0.440151356988483, disc_loss = 0.01704026080286977
Trained batch 99 in epoch 14, gen_loss = 0.43942676454782487, disc_loss = 0.016886534336954355
Trained batch 100 in epoch 14, gen_loss = 0.43927088527396174, disc_loss = 0.016736686568578133
Trained batch 101 in epoch 14, gen_loss = 0.4391815972094442, disc_loss = 0.01658701739849194
Trained batch 102 in epoch 14, gen_loss = 0.4392077645051827, disc_loss = 0.016451560175588843
Trained batch 103 in epoch 14, gen_loss = 0.4391699585203941, disc_loss = 0.016311975260927845
Trained batch 104 in epoch 14, gen_loss = 0.4388726362160274, disc_loss = 0.016169744216659593
Trained batch 105 in epoch 14, gen_loss = 0.43907075080106844, disc_loss = 0.016036189386383893
Trained batch 106 in epoch 14, gen_loss = 0.4393304132412527, disc_loss = 0.015907523562809642
Trained batch 107 in epoch 14, gen_loss = 0.4393311247781471, disc_loss = 0.015774556714825815
Trained batch 108 in epoch 14, gen_loss = 0.4392766069381609, disc_loss = 0.01563913221236045
Trained batch 109 in epoch 14, gen_loss = 0.43977653031999414, disc_loss = 0.015513004253576086
Trained batch 110 in epoch 14, gen_loss = 0.4392689826252224, disc_loss = 0.015380450048240589
Trained batch 111 in epoch 14, gen_loss = 0.4391651898622513, disc_loss = 0.015268207032931969
Trained batch 112 in epoch 14, gen_loss = 0.43954856759679, disc_loss = 0.015142397523396113
Trained batch 113 in epoch 14, gen_loss = 0.4394936951106055, disc_loss = 0.01502146597200057
Trained batch 114 in epoch 14, gen_loss = 0.4391703621200893, disc_loss = 0.014903818795700435
Trained batch 115 in epoch 14, gen_loss = 0.4384063854813576, disc_loss = 0.01482213061335015
Trained batch 116 in epoch 14, gen_loss = 0.4385857151614295, disc_loss = 0.014710468996284354
Trained batch 117 in epoch 14, gen_loss = 0.4377291104045965, disc_loss = 0.014606917959685295
Trained batch 118 in epoch 14, gen_loss = 0.4376392970565988, disc_loss = 0.01450777447101574
Trained batch 119 in epoch 14, gen_loss = 0.43815277591347696, disc_loss = 0.014461312532269706
Trained batch 120 in epoch 14, gen_loss = 0.4384947539853656, disc_loss = 0.014369593240505407
Trained batch 121 in epoch 14, gen_loss = 0.4386989899346086, disc_loss = 0.014273828695161788
Trained batch 122 in epoch 14, gen_loss = 0.4383313493515418, disc_loss = 0.014173292409159183
Trained batch 123 in epoch 14, gen_loss = 0.43839547446658533, disc_loss = 0.014074075813104788
Trained batch 124 in epoch 14, gen_loss = 0.43781023383140566, disc_loss = 0.013972850625403226
Trained batch 125 in epoch 14, gen_loss = 0.4382894372656232, disc_loss = 0.013877270741402985
Trained batch 126 in epoch 14, gen_loss = 0.4380155684441093, disc_loss = 0.013879326163006462
Trained batch 127 in epoch 14, gen_loss = 0.4378341867122799, disc_loss = 0.013804084350340418
Trained batch 128 in epoch 14, gen_loss = 0.43733139763506806, disc_loss = 0.013729764338106264
Trained batch 129 in epoch 14, gen_loss = 0.4373588995291637, disc_loss = 0.013776034720313664
Trained batch 130 in epoch 14, gen_loss = 0.4372224300417281, disc_loss = 0.01370792462533155
Trained batch 131 in epoch 14, gen_loss = 0.43745294281027536, disc_loss = 0.013646655703654908
Trained batch 132 in epoch 14, gen_loss = 0.4377324518404509, disc_loss = 0.013570518336167797
Trained batch 133 in epoch 14, gen_loss = 0.43789438147153426, disc_loss = 0.013511080459913989
Trained batch 134 in epoch 14, gen_loss = 0.4378092505313732, disc_loss = 0.013431245961261017
Trained batch 135 in epoch 14, gen_loss = 0.43791407938389215, disc_loss = 0.013344490957987384
Trained batch 136 in epoch 14, gen_loss = 0.43822188338224033, disc_loss = 0.01325644422781375
Trained batch 137 in epoch 14, gen_loss = 0.4387117004480915, disc_loss = 0.013170794562767327
Trained batch 138 in epoch 14, gen_loss = 0.43880049980801644, disc_loss = 0.013090182366285124
Trained batch 139 in epoch 14, gen_loss = 0.4387050828763417, disc_loss = 0.0130151732151197
Trained batch 140 in epoch 14, gen_loss = 0.43893088875932895, disc_loss = 0.012938102772492414
Trained batch 141 in epoch 14, gen_loss = 0.43923992002514045, disc_loss = 0.012857929591096046
Trained batch 142 in epoch 14, gen_loss = 0.439338779532826, disc_loss = 0.012784137730030799
Trained batch 143 in epoch 14, gen_loss = 0.4393668013314406, disc_loss = 0.012705162126318706
Trained batch 144 in epoch 14, gen_loss = 0.4390897064373411, disc_loss = 0.012625445503388243
Trained batch 145 in epoch 14, gen_loss = 0.439385079765973, disc_loss = 0.012562377616756736
Trained batch 146 in epoch 14, gen_loss = 0.43952709841890397, disc_loss = 0.012491687657913433
Trained batch 147 in epoch 14, gen_loss = 0.4398884229563378, disc_loss = 0.012426714759754218
Trained batch 148 in epoch 14, gen_loss = 0.4396174458049288, disc_loss = 0.012374776997603476
Trained batch 149 in epoch 14, gen_loss = 0.43951558907826743, disc_loss = 0.01230028494183595
Trained batch 150 in epoch 14, gen_loss = 0.43925032315664736, disc_loss = 0.012231992701814812
Trained batch 151 in epoch 14, gen_loss = 0.43942177080010114, disc_loss = 0.012161676621058416
Trained batch 152 in epoch 14, gen_loss = 0.43932169461561965, disc_loss = 0.012089707440501871
Trained batch 153 in epoch 14, gen_loss = 0.4390422413488487, disc_loss = 0.012035058320699525
Trained batch 154 in epoch 14, gen_loss = 0.4387716012616311, disc_loss = 0.012080027636951736
Trained batch 155 in epoch 14, gen_loss = 0.438313276721881, disc_loss = 0.012017896113087399
Trained batch 156 in epoch 14, gen_loss = 0.4378541502982948, disc_loss = 0.01237583511648403
Trained batch 157 in epoch 14, gen_loss = 0.43776936885676804, disc_loss = 0.01232313921253633
Trained batch 158 in epoch 14, gen_loss = 0.4377318063996873, disc_loss = 0.012321401493617995
Trained batch 159 in epoch 14, gen_loss = 0.437407317198813, disc_loss = 0.012275228987709852
Trained batch 160 in epoch 14, gen_loss = 0.43792857461094115, disc_loss = 0.0122186008714984
Trained batch 161 in epoch 14, gen_loss = 0.43832330773642036, disc_loss = 0.012162259669922706
Trained batch 162 in epoch 14, gen_loss = 0.4387314851664327, disc_loss = 0.012104313919874925
Trained batch 163 in epoch 14, gen_loss = 0.43841907272978525, disc_loss = 0.012055494518036296
Trained batch 164 in epoch 14, gen_loss = 0.4382670863108201, disc_loss = 0.012007557580275743
Trained batch 165 in epoch 14, gen_loss = 0.43819280794586046, disc_loss = 0.011947123982511595
Trained batch 166 in epoch 14, gen_loss = 0.4383040100871446, disc_loss = 0.012018508470929534
Trained batch 167 in epoch 14, gen_loss = 0.4382946743142037, disc_loss = 0.012038947069889954
Trained batch 168 in epoch 14, gen_loss = 0.43794328961852036, disc_loss = 0.012027515382946816
Trained batch 169 in epoch 14, gen_loss = 0.4384524068411659, disc_loss = 0.011983875281807473
Trained batch 170 in epoch 14, gen_loss = 0.43828456513365804, disc_loss = 0.012169610260310446
Trained batch 171 in epoch 14, gen_loss = 0.439246335001879, disc_loss = 0.01217601180068477
Trained batch 172 in epoch 14, gen_loss = 0.44008448323762484, disc_loss = 0.012173011800075068
Trained batch 173 in epoch 14, gen_loss = 0.44020618121514377, disc_loss = 0.012310652070994564
Trained batch 174 in epoch 14, gen_loss = 0.4402951409135546, disc_loss = 0.012308257071168295
Trained batch 175 in epoch 14, gen_loss = 0.44000657089054585, disc_loss = 0.012261722922796087
Trained batch 176 in epoch 14, gen_loss = 0.4396932278312532, disc_loss = 0.01220455059142373
Trained batch 177 in epoch 14, gen_loss = 0.43977915202633716, disc_loss = 0.012153378387604412
Trained batch 178 in epoch 14, gen_loss = 0.43996352023918534, disc_loss = 0.012095926321038779
Trained batch 179 in epoch 14, gen_loss = 0.43962593608432343, disc_loss = 0.012042707711225375
Trained batch 180 in epoch 14, gen_loss = 0.43940987952506344, disc_loss = 0.01200139636716687
Trained batch 181 in epoch 14, gen_loss = 0.43924744230705304, disc_loss = 0.011949943170683193
Trained batch 182 in epoch 14, gen_loss = 0.4391062311787423, disc_loss = 0.011893884640802817
Trained batch 183 in epoch 14, gen_loss = 0.43934737777580385, disc_loss = 0.01184373737740553
Trained batch 184 in epoch 14, gen_loss = 0.43906830645896294, disc_loss = 0.011816703473419152
Trained batch 185 in epoch 14, gen_loss = 0.43916886692406026, disc_loss = 0.01176687078212478
Trained batch 186 in epoch 14, gen_loss = 0.43920282326280113, disc_loss = 0.012020663747359765
Trained batch 187 in epoch 14, gen_loss = 0.43947964795726413, disc_loss = 0.01203402201211615
Trained batch 188 in epoch 14, gen_loss = 0.43960144548189073, disc_loss = 0.012284965328896842
Trained batch 189 in epoch 14, gen_loss = 0.4397380973163404, disc_loss = 0.012279865131590907
Trained batch 190 in epoch 14, gen_loss = 0.43977466600103526, disc_loss = 0.012268058259005985
Trained batch 191 in epoch 14, gen_loss = 0.4396707887450854, disc_loss = 0.012383098583692723
Trained batch 192 in epoch 14, gen_loss = 0.440276549270116, disc_loss = 0.01238384804328894
Trained batch 193 in epoch 14, gen_loss = 0.44094722817853554, disc_loss = 0.012421644648618651
Trained batch 194 in epoch 14, gen_loss = 0.44104007543661655, disc_loss = 0.01240062701742714
Trained batch 195 in epoch 14, gen_loss = 0.44097819620249223, disc_loss = 0.012376014158077424
Trained batch 196 in epoch 14, gen_loss = 0.4409571126632884, disc_loss = 0.012330096849089082
Trained batch 197 in epoch 14, gen_loss = 0.4411181375534848, disc_loss = 0.012298638330927739
Trained batch 198 in epoch 14, gen_loss = 0.4408028965918862, disc_loss = 0.012247533867973366
Trained batch 199 in epoch 14, gen_loss = 0.4408113171160221, disc_loss = 0.012213533486356027
Trained batch 200 in epoch 14, gen_loss = 0.44118530996403293, disc_loss = 0.012167600755561236
Trained batch 201 in epoch 14, gen_loss = 0.4411535161261511, disc_loss = 0.012121366505801567
Trained batch 202 in epoch 14, gen_loss = 0.44140540085402613, disc_loss = 0.012102017865580475
Trained batch 203 in epoch 14, gen_loss = 0.4416501298546791, disc_loss = 0.012050339375170605
Trained batch 204 in epoch 14, gen_loss = 0.4417005848593828, disc_loss = 0.012001475567429712
Trained batch 205 in epoch 14, gen_loss = 0.44167409547903, disc_loss = 0.011949918495075217
Trained batch 206 in epoch 14, gen_loss = 0.4412858496253617, disc_loss = 0.011907777764748979
Trained batch 207 in epoch 14, gen_loss = 0.44112020559035814, disc_loss = 0.011861272809955362
Trained batch 208 in epoch 14, gen_loss = 0.4411440485972537, disc_loss = 0.011813507507818096
Trained batch 209 in epoch 14, gen_loss = 0.44126569543566024, disc_loss = 0.011763249924184666
Trained batch 210 in epoch 14, gen_loss = 0.4412188579403394, disc_loss = 0.01171476184280139
Trained batch 211 in epoch 14, gen_loss = 0.4409809206735413, disc_loss = 0.011673158039075305
Trained batch 212 in epoch 14, gen_loss = 0.44119424271471624, disc_loss = 0.011627582863777736
Trained batch 213 in epoch 14, gen_loss = 0.4410494557607954, disc_loss = 0.011583505874003553
Trained batch 214 in epoch 14, gen_loss = 0.44104489642520284, disc_loss = 0.01153718225852868
Trained batch 215 in epoch 14, gen_loss = 0.44120336958655604, disc_loss = 0.011503853422322276
Trained batch 216 in epoch 14, gen_loss = 0.4410601721106586, disc_loss = 0.011461118494765618
Trained batch 217 in epoch 14, gen_loss = 0.44117523388031427, disc_loss = 0.011417971213707068
Trained batch 218 in epoch 14, gen_loss = 0.4409946479481649, disc_loss = 0.011374567997892765
Trained batch 219 in epoch 14, gen_loss = 0.4408418370918794, disc_loss = 0.01133062955605882
Trained batch 220 in epoch 14, gen_loss = 0.44071824976761415, disc_loss = 0.011288867320452409
Trained batch 221 in epoch 14, gen_loss = 0.44053439084474033, disc_loss = 0.011244376551313745
Trained batch 222 in epoch 14, gen_loss = 0.440347691688837, disc_loss = 0.011202953423314933
Trained batch 223 in epoch 14, gen_loss = 0.44000627912048784, disc_loss = 0.011168206500899811
Trained batch 224 in epoch 14, gen_loss = 0.44024923854404024, disc_loss = 0.011126643833704293
Trained batch 225 in epoch 14, gen_loss = 0.4401772953240217, disc_loss = 0.012413622943820448
Trained batch 226 in epoch 14, gen_loss = 0.4399205135091286, disc_loss = 0.01251849238422293
Trained batch 227 in epoch 14, gen_loss = 0.4394743813757311, disc_loss = 0.01280693783426837
Trained batch 228 in epoch 14, gen_loss = 0.4394771100131705, disc_loss = 0.012782448163056771
Trained batch 229 in epoch 14, gen_loss = 0.4396228721608286, disc_loss = 0.012747636431848387
Trained batch 230 in epoch 14, gen_loss = 0.4397362151961306, disc_loss = 0.01271354760500921
Trained batch 231 in epoch 14, gen_loss = 0.4397123145132229, disc_loss = 0.012683364972652836
Trained batch 232 in epoch 14, gen_loss = 0.43989755219656, disc_loss = 0.012644424599339553
Trained batch 233 in epoch 14, gen_loss = 0.4398571976229676, disc_loss = 0.012612899602689326
Trained batch 234 in epoch 14, gen_loss = 0.43971181740152077, disc_loss = 0.012565735284674992
Trained batch 235 in epoch 14, gen_loss = 0.4395418266876269, disc_loss = 0.01252035773161925
Trained batch 236 in epoch 14, gen_loss = 0.439743669978677, disc_loss = 0.012478710559908034
Trained batch 237 in epoch 14, gen_loss = 0.4396576577124475, disc_loss = 0.012436609719136432
Trained batch 238 in epoch 14, gen_loss = 0.43939789630877923, disc_loss = 0.012396491954890254
Trained batch 239 in epoch 14, gen_loss = 0.4395395956933498, disc_loss = 0.012402684959427764
Trained batch 240 in epoch 14, gen_loss = 0.4395581778154334, disc_loss = 0.012364529314763936
Trained batch 241 in epoch 14, gen_loss = 0.4397615556381951, disc_loss = 0.012346085432285735
Trained batch 242 in epoch 14, gen_loss = 0.4399074652067428, disc_loss = 0.012363316861092431
Trained batch 243 in epoch 14, gen_loss = 0.44006693326547497, disc_loss = 0.012440948344415939
Trained batch 244 in epoch 14, gen_loss = 0.4399429920984774, disc_loss = 0.012411049576666283
Trained batch 245 in epoch 14, gen_loss = 0.4401125050172573, disc_loss = 0.012412644057663354
Trained batch 246 in epoch 14, gen_loss = 0.44006438438708967, disc_loss = 0.012376071297024427
Trained batch 247 in epoch 14, gen_loss = 0.4402323372421726, disc_loss = 0.01253924810988528
Trained batch 248 in epoch 14, gen_loss = 0.44053864239688856, disc_loss = 0.012695603798252034
Trained batch 249 in epoch 14, gen_loss = 0.4405298068523407, disc_loss = 0.012672335861250758
Trained batch 250 in epoch 14, gen_loss = 0.4403950803545842, disc_loss = 0.012639718480868287
Trained batch 251 in epoch 14, gen_loss = 0.44049570378330016, disc_loss = 0.01260449001399268
Trained batch 252 in epoch 14, gen_loss = 0.44051825811740436, disc_loss = 0.012565836243206275
Trained batch 253 in epoch 14, gen_loss = 0.44061875190791183, disc_loss = 0.012542185035358205
Trained batch 254 in epoch 14, gen_loss = 0.44039546508415073, disc_loss = 0.01250125125561859
Trained batch 255 in epoch 14, gen_loss = 0.44064797437749803, disc_loss = 0.01246954163252667
Trained batch 256 in epoch 14, gen_loss = 0.44049229162676323, disc_loss = 0.012433238698945087
Trained batch 257 in epoch 14, gen_loss = 0.44060711655043816, disc_loss = 0.012411418919588706
Trained batch 258 in epoch 14, gen_loss = 0.44058283473073745, disc_loss = 0.012409544970595699
Trained batch 259 in epoch 14, gen_loss = 0.4407451008374874, disc_loss = 0.012374072404614148
Trained batch 260 in epoch 14, gen_loss = 0.4405514887923025, disc_loss = 0.012339338691462674
Trained batch 261 in epoch 14, gen_loss = 0.4408029636353937, disc_loss = 0.012323464244739188
Trained batch 262 in epoch 14, gen_loss = 0.4405742377156087, disc_loss = 0.01228748353909942
Trained batch 263 in epoch 14, gen_loss = 0.44039458725036995, disc_loss = 0.012248341010876395
Trained batch 264 in epoch 14, gen_loss = 0.4404818628194197, disc_loss = 0.012210131866224813
Trained batch 265 in epoch 14, gen_loss = 0.4403687577722664, disc_loss = 0.012185253469882659
Trained batch 266 in epoch 14, gen_loss = 0.440251181411386, disc_loss = 0.012160579346936573
Trained batch 267 in epoch 14, gen_loss = 0.4402684909639074, disc_loss = 0.012132466782002584
Trained batch 268 in epoch 14, gen_loss = 0.43993536502012087, disc_loss = 0.012095659210426268
Trained batch 269 in epoch 14, gen_loss = 0.4398927813326871, disc_loss = 0.012057516201295786
Trained batch 270 in epoch 14, gen_loss = 0.4400676010499581, disc_loss = 0.012019116484312637
Trained batch 271 in epoch 14, gen_loss = 0.44031347630216794, disc_loss = 0.01198465204994564
Trained batch 272 in epoch 14, gen_loss = 0.44034430843133193, disc_loss = 0.011947388578660022
Trained batch 273 in epoch 14, gen_loss = 0.44038327440728237, disc_loss = 0.01191182586791021
Trained batch 274 in epoch 14, gen_loss = 0.4400552415847778, disc_loss = 0.011879926062697038
Trained batch 275 in epoch 14, gen_loss = 0.43997921945824137, disc_loss = 0.011848123736959626
Trained batch 276 in epoch 14, gen_loss = 0.4399672110803721, disc_loss = 0.01182572633349118
Trained batch 277 in epoch 14, gen_loss = 0.44013993291974923, disc_loss = 0.011791740634173771
Trained batch 278 in epoch 14, gen_loss = 0.4403231832929837, disc_loss = 0.011772451411154936
Trained batch 279 in epoch 14, gen_loss = 0.44041688750897134, disc_loss = 0.011754276235504742
Trained batch 280 in epoch 14, gen_loss = 0.4402915139639505, disc_loss = 0.011729755721823892
Trained batch 281 in epoch 14, gen_loss = 0.44024273298733624, disc_loss = 0.011707981744143742
Trained batch 282 in epoch 14, gen_loss = 0.44042135611860994, disc_loss = 0.011672795350768672
Trained batch 283 in epoch 14, gen_loss = 0.44004774597329155, disc_loss = 0.0116390639667655
Trained batch 284 in epoch 14, gen_loss = 0.44034883787757473, disc_loss = 0.011608603892831557
Trained batch 285 in epoch 14, gen_loss = 0.4403602819551121, disc_loss = 0.011581797068499003
Trained batch 286 in epoch 14, gen_loss = 0.4406069754931154, disc_loss = 0.011555318818395171
Trained batch 287 in epoch 14, gen_loss = 0.4404914184576935, disc_loss = 0.01152957733372912
Trained batch 288 in epoch 14, gen_loss = 0.4402059086672575, disc_loss = 0.011508270283229649
Trained batch 289 in epoch 14, gen_loss = 0.44021426542051906, disc_loss = 0.011487401832810377
Trained batch 290 in epoch 14, gen_loss = 0.44033842029440445, disc_loss = 0.011474827893760017
Trained batch 291 in epoch 14, gen_loss = 0.44060229703988113, disc_loss = 0.01144943423832333
Trained batch 292 in epoch 14, gen_loss = 0.44052456039617494, disc_loss = 0.0114166321647719
Trained batch 293 in epoch 14, gen_loss = 0.4403414294427755, disc_loss = 0.011417872808575884
Trained batch 294 in epoch 14, gen_loss = 0.44032184835207666, disc_loss = 0.011416922087418074
Trained batch 295 in epoch 14, gen_loss = 0.4405049685690854, disc_loss = 0.011386421854400102
Trained batch 296 in epoch 14, gen_loss = 0.4408370226320594, disc_loss = 0.011354979002998785
Trained batch 297 in epoch 14, gen_loss = 0.44091567787148006, disc_loss = 0.011328568176566405
Trained batch 298 in epoch 14, gen_loss = 0.4411245023327129, disc_loss = 0.01130169102638636
Trained batch 299 in epoch 14, gen_loss = 0.44109479665756224, disc_loss = 0.011271154168061912
Trained batch 300 in epoch 14, gen_loss = 0.44080631113131574, disc_loss = 0.011252724718723284
Trained batch 301 in epoch 14, gen_loss = 0.44086102292632423, disc_loss = 0.011222494140094677
Trained batch 302 in epoch 14, gen_loss = 0.4409348450281439, disc_loss = 0.011192442110060367
Trained batch 303 in epoch 14, gen_loss = 0.44099067592699276, disc_loss = 0.011167536503451533
Trained batch 304 in epoch 14, gen_loss = 0.4410223237803725, disc_loss = 0.011214898625907839
Trained batch 305 in epoch 14, gen_loss = 0.44095808871431286, disc_loss = 0.011201747232025452
Trained batch 306 in epoch 14, gen_loss = 0.44099225865901487, disc_loss = 0.011182139805102484
Trained batch 307 in epoch 14, gen_loss = 0.44102568305157996, disc_loss = 0.011152801664044186
Trained batch 308 in epoch 14, gen_loss = 0.4412226071249706, disc_loss = 0.011125251983102519
Trained batch 309 in epoch 14, gen_loss = 0.4411924361221252, disc_loss = 0.011105562900493462
Trained batch 310 in epoch 14, gen_loss = 0.44137354219074804, disc_loss = 0.011076196129029539
Trained batch 311 in epoch 14, gen_loss = 0.4409728957674442, disc_loss = 0.011063421863722257
Trained batch 312 in epoch 14, gen_loss = 0.44092361605205477, disc_loss = 0.01105645192659106
Trained batch 313 in epoch 14, gen_loss = 0.440761625197283, disc_loss = 0.011046891678332286
Trained batch 314 in epoch 14, gen_loss = 0.44087950587272645, disc_loss = 0.011021443710677207
Trained batch 315 in epoch 14, gen_loss = 0.44094168281630625, disc_loss = 0.011025050386810039
Trained batch 316 in epoch 14, gen_loss = 0.44104844952231326, disc_loss = 0.01099841422783299
Trained batch 317 in epoch 14, gen_loss = 0.44133702876432884, disc_loss = 0.010969435081175828
Trained batch 318 in epoch 14, gen_loss = 0.4412072483088155, disc_loss = 0.010941812568227396
Trained batch 319 in epoch 14, gen_loss = 0.44100162172690033, disc_loss = 0.010925893774765428
Trained batch 320 in epoch 14, gen_loss = 0.4408650428892296, disc_loss = 0.0109022472897324
Trained batch 321 in epoch 14, gen_loss = 0.4410855202756313, disc_loss = 0.010892913248375498
Trained batch 322 in epoch 14, gen_loss = 0.44098448808717283, disc_loss = 0.010984797566630315
Trained batch 323 in epoch 14, gen_loss = 0.44118470211087923, disc_loss = 0.01114690595236032
Trained batch 324 in epoch 14, gen_loss = 0.4412101029432737, disc_loss = 0.011148297253351373
Trained batch 325 in epoch 14, gen_loss = 0.44084480386570185, disc_loss = 0.01141627134570989
Trained batch 326 in epoch 14, gen_loss = 0.44087172438609856, disc_loss = 0.011569058055140717
Trained batch 327 in epoch 14, gen_loss = 0.44096511856811804, disc_loss = 0.011592731793714891
Trained batch 328 in epoch 14, gen_loss = 0.4410386355452262, disc_loss = 0.011584836468426086
Trained batch 329 in epoch 14, gen_loss = 0.4411947398474722, disc_loss = 0.011562995458459199
Trained batch 330 in epoch 14, gen_loss = 0.4410163879934755, disc_loss = 0.011542843802117397
Trained batch 331 in epoch 14, gen_loss = 0.44112355953239535, disc_loss = 0.011517840999680716
Trained batch 332 in epoch 14, gen_loss = 0.4413148857451774, disc_loss = 0.011942110788958097
Trained batch 333 in epoch 14, gen_loss = 0.44138079069688646, disc_loss = 0.012010143602386808
Trained batch 334 in epoch 14, gen_loss = 0.44094554461649993, disc_loss = 0.012061615361581877
Trained batch 335 in epoch 14, gen_loss = 0.4407689751436313, disc_loss = 0.012049762785387602
Trained batch 336 in epoch 14, gen_loss = 0.4406471660123027, disc_loss = 0.012150858535475543
Trained batch 337 in epoch 14, gen_loss = 0.4405917279290024, disc_loss = 0.012194846374790057
Trained batch 338 in epoch 14, gen_loss = 0.44064442237569873, disc_loss = 0.012284767869956088
Trained batch 339 in epoch 14, gen_loss = 0.4408406228703611, disc_loss = 0.012364049812929486
Trained batch 340 in epoch 14, gen_loss = 0.4408955198229233, disc_loss = 0.012361720623243654
Trained batch 341 in epoch 14, gen_loss = 0.4410305809207827, disc_loss = 0.012385775692888934
Trained batch 342 in epoch 14, gen_loss = 0.44110710601764935, disc_loss = 0.012381839137945227
Trained batch 343 in epoch 14, gen_loss = 0.44112935826875443, disc_loss = 0.012367848012810248
Trained batch 344 in epoch 14, gen_loss = 0.44120731198269386, disc_loss = 0.012354001214903225
Trained batch 345 in epoch 14, gen_loss = 0.44129145601925823, disc_loss = 0.012330302164817196
Trained batch 346 in epoch 14, gen_loss = 0.44146960209357294, disc_loss = 0.012305260237013808
Trained batch 347 in epoch 14, gen_loss = 0.44176052485046713, disc_loss = 0.012280207139710179
Trained batch 348 in epoch 14, gen_loss = 0.4418520797631119, disc_loss = 0.012258422398542116
Trained batch 349 in epoch 14, gen_loss = 0.4421437772682735, disc_loss = 0.012271945524761187
Trained batch 350 in epoch 14, gen_loss = 0.4420098366900387, disc_loss = 0.012257155268771462
Trained batch 351 in epoch 14, gen_loss = 0.44193116448480974, disc_loss = 0.012239082255043533
Trained batch 352 in epoch 14, gen_loss = 0.44203721632700804, disc_loss = 0.012213786214091433
Trained batch 353 in epoch 14, gen_loss = 0.4421025393372875, disc_loss = 0.012184857048481008
Trained batch 354 in epoch 14, gen_loss = 0.4419387610865311, disc_loss = 0.012156315672237584
Trained batch 355 in epoch 14, gen_loss = 0.44182331441493516, disc_loss = 0.012127338061658562
Trained batch 356 in epoch 14, gen_loss = 0.441719649636111, disc_loss = 0.012097866882906616
Trained batch 357 in epoch 14, gen_loss = 0.4417973323074799, disc_loss = 0.012071504449477034
Trained batch 358 in epoch 14, gen_loss = 0.44171035132036235, disc_loss = 0.012041989393846176
Trained batch 359 in epoch 14, gen_loss = 0.44166134612427815, disc_loss = 0.01201266867671317
Trained batch 360 in epoch 14, gen_loss = 0.44172786064755554, disc_loss = 0.011984383639004958
Trained batch 361 in epoch 14, gen_loss = 0.44181171207796804, disc_loss = 0.01195753749153829
Trained batch 362 in epoch 14, gen_loss = 0.4418079952398936, disc_loss = 0.011928027443146492
Trained batch 363 in epoch 14, gen_loss = 0.44189051735204654, disc_loss = 0.01189868533945448
Trained batch 364 in epoch 14, gen_loss = 0.44189740966444147, disc_loss = 0.011870276391480679
Trained batch 365 in epoch 14, gen_loss = 0.4419180421067066, disc_loss = 0.011842121247359923
Trained batch 366 in epoch 14, gen_loss = 0.44196368327582564, disc_loss = 0.011813297965157808
Trained batch 367 in epoch 14, gen_loss = 0.4419457017565551, disc_loss = 0.011785452664100929
Trained batch 368 in epoch 14, gen_loss = 0.44195118998770466, disc_loss = 0.011757646940666224
Trained batch 369 in epoch 14, gen_loss = 0.44205698854214437, disc_loss = 0.011735600215773023
Trained batch 370 in epoch 14, gen_loss = 0.44195786953936367, disc_loss = 0.011708487158470518
Trained batch 371 in epoch 14, gen_loss = 0.44188048482261677, disc_loss = 0.011679806762189675
Trained batch 372 in epoch 14, gen_loss = 0.44192652687949724, disc_loss = 0.011654501199727284
Trained batch 373 in epoch 14, gen_loss = 0.44197941934042434, disc_loss = 0.011627684998199005
Trained batch 374 in epoch 14, gen_loss = 0.4420035134156545, disc_loss = 0.01160128999967128
Trained batch 375 in epoch 14, gen_loss = 0.4420372693145529, disc_loss = 0.011574363745278381
Trained batch 376 in epoch 14, gen_loss = 0.441893372753887, disc_loss = 0.011585975706266037
Trained batch 377 in epoch 14, gen_loss = 0.44191786087063883, disc_loss = 0.011577509285108476
Trained batch 378 in epoch 14, gen_loss = 0.4417917932872722, disc_loss = 0.011574780279131591
Trained batch 379 in epoch 14, gen_loss = 0.441938840872363, disc_loss = 0.011550168324825598
Trained batch 380 in epoch 14, gen_loss = 0.44195874915348266, disc_loss = 0.011533407288483708
Trained batch 381 in epoch 14, gen_loss = 0.44199763012182025, disc_loss = 0.011508297512834375
Trained batch 382 in epoch 14, gen_loss = 0.4418718515270373, disc_loss = 0.011481719550812817
Trained batch 383 in epoch 14, gen_loss = 0.441669799387455, disc_loss = 0.011457761768118266
Trained batch 384 in epoch 14, gen_loss = 0.44177593735905435, disc_loss = 0.011432578698611008
Trained batch 385 in epoch 14, gen_loss = 0.4417277438652948, disc_loss = 0.011408016476490646
Trained batch 386 in epoch 14, gen_loss = 0.4417986417001532, disc_loss = 0.01138604058130844
Trained batch 387 in epoch 14, gen_loss = 0.44180165323400006, disc_loss = 0.011359868932709809
Trained batch 388 in epoch 14, gen_loss = 0.44181336634876184, disc_loss = 0.01133357256245117
Trained batch 389 in epoch 14, gen_loss = 0.44195546981615896, disc_loss = 0.01130998495590085
Trained batch 390 in epoch 14, gen_loss = 0.4419417981906315, disc_loss = 0.01128404486782687
Trained batch 391 in epoch 14, gen_loss = 0.4418435956598545, disc_loss = 0.011259352981067757
Trained batch 392 in epoch 14, gen_loss = 0.4418523773437238, disc_loss = 0.011236710998504576
Trained batch 393 in epoch 14, gen_loss = 0.44183533937495373, disc_loss = 0.011217713463273807
Trained batch 394 in epoch 14, gen_loss = 0.4417361289640016, disc_loss = 0.011194813354353456
Trained batch 395 in epoch 14, gen_loss = 0.4417478835040873, disc_loss = 0.011171443933195368
Trained batch 396 in epoch 14, gen_loss = 0.44170799416018375, disc_loss = 0.011148563429293334
Trained batch 397 in epoch 14, gen_loss = 0.44166303317451, disc_loss = 0.011123705355230551
Trained batch 398 in epoch 14, gen_loss = 0.4417717967714582, disc_loss = 0.011099628080908013
Trained batch 399 in epoch 14, gen_loss = 0.44171190828084944, disc_loss = 0.011074875716294627
Trained batch 400 in epoch 14, gen_loss = 0.44187113902812586, disc_loss = 0.011052503402372753
Trained batch 401 in epoch 14, gen_loss = 0.44197047905838904, disc_loss = 0.01103082914061761
Trained batch 402 in epoch 14, gen_loss = 0.44201808383979513, disc_loss = 0.01100682162895808
Trained batch 403 in epoch 14, gen_loss = 0.4420206433180535, disc_loss = 0.01098234740882365
Trained batch 404 in epoch 14, gen_loss = 0.44201265043682525, disc_loss = 0.010957991441907245
Trained batch 405 in epoch 14, gen_loss = 0.4419660198277441, disc_loss = 0.010933766138666479
Trained batch 406 in epoch 14, gen_loss = 0.44201645013448354, disc_loss = 0.01091165893513215
Trained batch 407 in epoch 14, gen_loss = 0.4420943342733617, disc_loss = 0.010889631778506251
Trained batch 408 in epoch 14, gen_loss = 0.44189448075364446, disc_loss = 0.010866768211570357
Trained batch 409 in epoch 14, gen_loss = 0.4418820019175367, disc_loss = 0.01084291214214229
Trained batch 410 in epoch 14, gen_loss = 0.44187903875562107, disc_loss = 0.010820545675912804
Trained batch 411 in epoch 14, gen_loss = 0.4417857072017725, disc_loss = 0.010798606777437103
Trained batch 412 in epoch 14, gen_loss = 0.44193137067282173, disc_loss = 0.010779492239091212
Trained batch 413 in epoch 14, gen_loss = 0.4419185016754169, disc_loss = 0.010757374506362754
Trained batch 414 in epoch 14, gen_loss = 0.4417504484394947, disc_loss = 0.010738318388810359
Trained batch 415 in epoch 14, gen_loss = 0.4415319369962582, disc_loss = 0.01076070923367157
Trained batch 416 in epoch 14, gen_loss = 0.4415157138586616, disc_loss = 0.01078327765969707
Trained batch 417 in epoch 14, gen_loss = 0.4415609712520855, disc_loss = 0.010801523574070925
Trained batch 418 in epoch 14, gen_loss = 0.4416962396842483, disc_loss = 0.01081622459732334
Trained batch 419 in epoch 14, gen_loss = 0.44174803438640775, disc_loss = 0.010800641277317134
Trained batch 420 in epoch 14, gen_loss = 0.4417069678210306, disc_loss = 0.010781199591690032
Trained batch 421 in epoch 14, gen_loss = 0.44163735161460405, disc_loss = 0.010760077274232326
Trained batch 422 in epoch 14, gen_loss = 0.44159654142163324, disc_loss = 0.01075243183365422
Trained batch 423 in epoch 14, gen_loss = 0.4416888454612696, disc_loss = 0.010731851372358232
Trained batch 424 in epoch 14, gen_loss = 0.44173447791267845, disc_loss = 0.01071059340118047
Trained batch 425 in epoch 14, gen_loss = 0.4416611136545038, disc_loss = 0.01068993736257418
Trained batch 426 in epoch 14, gen_loss = 0.44168324709217777, disc_loss = 0.010666961785224844
Trained batch 427 in epoch 14, gen_loss = 0.44167657830169266, disc_loss = 0.010644544304128754
Trained batch 428 in epoch 14, gen_loss = 0.44168108604448936, disc_loss = 0.010621813765785599
Trained batch 429 in epoch 14, gen_loss = 0.44147427019684815, disc_loss = 0.010603985880761472
Trained batch 430 in epoch 14, gen_loss = 0.4413266717142959, disc_loss = 0.010583427774378481
Trained batch 431 in epoch 14, gen_loss = 0.44117594034307533, disc_loss = 0.010561112084865777
Trained batch 432 in epoch 14, gen_loss = 0.44113243665485957, disc_loss = 0.01053904432654983
Trained batch 433 in epoch 14, gen_loss = 0.4412292837409929, disc_loss = 0.010517941782474175
Trained batch 434 in epoch 14, gen_loss = 0.44126223990286906, disc_loss = 0.010496059224951542
Trained batch 435 in epoch 14, gen_loss = 0.4412593617351777, disc_loss = 0.010475378410907787
Trained batch 436 in epoch 14, gen_loss = 0.4412967918666604, disc_loss = 0.010454669929625257
Trained batch 437 in epoch 14, gen_loss = 0.4413734089974399, disc_loss = 0.010433329990905493
Trained batch 438 in epoch 14, gen_loss = 0.441282450949141, disc_loss = 0.01041210031217486
Trained batch 439 in epoch 14, gen_loss = 0.44127040363170883, disc_loss = 0.010390395260368347
Trained batch 440 in epoch 14, gen_loss = 0.44112149489169217, disc_loss = 0.010387378311721299
Trained batch 441 in epoch 14, gen_loss = 0.44121390115891107, disc_loss = 0.010370085571499592
Trained batch 442 in epoch 14, gen_loss = 0.44116581973050034, disc_loss = 0.010357904196827215
Trained batch 443 in epoch 14, gen_loss = 0.441134562027884, disc_loss = 0.010340273973761705
Trained batch 444 in epoch 14, gen_loss = 0.44120603498448147, disc_loss = 0.010319247843273862
Trained batch 445 in epoch 14, gen_loss = 0.44119206692338525, disc_loss = 0.010298340823454365
Trained batch 446 in epoch 14, gen_loss = 0.44110364615250486, disc_loss = 0.01027719517875467
Trained batch 447 in epoch 14, gen_loss = 0.44099676003679633, disc_loss = 0.010256098421580515
Trained batch 448 in epoch 14, gen_loss = 0.4410162233562937, disc_loss = 0.01023712284712096
Trained batch 449 in epoch 14, gen_loss = 0.4409243835343255, disc_loss = 0.010216782603593957
Trained batch 450 in epoch 14, gen_loss = 0.4408909799386551, disc_loss = 0.01019594972081247
Trained batch 451 in epoch 14, gen_loss = 0.44080186767124496, disc_loss = 0.010174827507632142
Trained batch 452 in epoch 14, gen_loss = 0.4406671735229871, disc_loss = 0.01015405569322691
Trained batch 453 in epoch 14, gen_loss = 0.4405462819968026, disc_loss = 0.010135584136615774
Trained batch 454 in epoch 14, gen_loss = 0.44067483249601425, disc_loss = 0.010118578820729853
Trained batch 455 in epoch 14, gen_loss = 0.4407618351672825, disc_loss = 0.010098462083796653
Trained batch 456 in epoch 14, gen_loss = 0.44088363719195195, disc_loss = 0.010079606807983279
Trained batch 457 in epoch 14, gen_loss = 0.4409367796114959, disc_loss = 0.010059447318018621
Trained batch 458 in epoch 14, gen_loss = 0.4409410685365756, disc_loss = 0.010040565501149817
Trained batch 459 in epoch 14, gen_loss = 0.4410052262570547, disc_loss = 0.010021750388019111
Trained batch 460 in epoch 14, gen_loss = 0.44094530142310384, disc_loss = 0.010003777178925605
Trained batch 461 in epoch 14, gen_loss = 0.4407436281313628, disc_loss = 0.009983388315210949
Trained batch 462 in epoch 14, gen_loss = 0.44078704888568326, disc_loss = 0.009964007288106912
Trained batch 463 in epoch 14, gen_loss = 0.44095540547679213, disc_loss = 0.009946841085460118
Trained batch 464 in epoch 14, gen_loss = 0.4410113334655762, disc_loss = 0.009927397614510189
Trained batch 465 in epoch 14, gen_loss = 0.4409323627600854, disc_loss = 0.00990780793997767
Trained batch 466 in epoch 14, gen_loss = 0.4407926610246205, disc_loss = 0.00988823625361806
Trained batch 467 in epoch 14, gen_loss = 0.44077464154897594, disc_loss = 0.009868744892713964
Trained batch 468 in epoch 14, gen_loss = 0.4407946710139195, disc_loss = 0.009849569655886329
Trained batch 469 in epoch 14, gen_loss = 0.44080061119921665, disc_loss = 0.009830485188100051
Trained batch 470 in epoch 14, gen_loss = 0.4408780104795079, disc_loss = 0.009811859622754892
Trained batch 471 in epoch 14, gen_loss = 0.44085541102340664, disc_loss = 0.009793069084141388
Trained batch 472 in epoch 14, gen_loss = 0.4408853299774025, disc_loss = 0.009774082704067199
Trained batch 473 in epoch 14, gen_loss = 0.44087552074893116, disc_loss = 0.009754911379840516
Trained batch 474 in epoch 14, gen_loss = 0.4407516160136775, disc_loss = 0.009735953059831732
Trained batch 475 in epoch 14, gen_loss = 0.4407558040458615, disc_loss = 0.009717428642217493
Trained batch 476 in epoch 14, gen_loss = 0.4406591896241066, disc_loss = 0.009699199412387075
Trained batch 477 in epoch 14, gen_loss = 0.44063874667658465, disc_loss = 0.009681477241859105
Trained batch 478 in epoch 14, gen_loss = 0.4406060175756323, disc_loss = 0.009663151939971167
Trained batch 479 in epoch 14, gen_loss = 0.44065997103850046, disc_loss = 0.009646455951587996
Trained batch 480 in epoch 14, gen_loss = 0.4406946403073174, disc_loss = 0.009628516289583658
Trained batch 481 in epoch 14, gen_loss = 0.44072319919637626, disc_loss = 0.009611795942832357
Trained batch 482 in epoch 14, gen_loss = 0.44070136670493687, disc_loss = 0.009593682595013833
Trained batch 483 in epoch 14, gen_loss = 0.4406995445120433, disc_loss = 0.009575384334552349
Trained batch 484 in epoch 14, gen_loss = 0.4407407654314926, disc_loss = 0.009590882958109807
Trained batch 485 in epoch 14, gen_loss = 0.44074400891492393, disc_loss = 0.009580991585780158
Trained batch 486 in epoch 14, gen_loss = 0.44060043430671064, disc_loss = 0.009567867237209196
Trained batch 487 in epoch 14, gen_loss = 0.44057846234225834, disc_loss = 0.009558707354833624
Trained batch 488 in epoch 14, gen_loss = 0.4404366227868632, disc_loss = 0.009550991438968195
Trained batch 489 in epoch 14, gen_loss = 0.4404885366863134, disc_loss = 0.009534085607892663
Trained batch 490 in epoch 14, gen_loss = 0.44051645304666276, disc_loss = 0.009517442260877383
Trained batch 491 in epoch 14, gen_loss = 0.4404890213797732, disc_loss = 0.009502574854328797
Trained batch 492 in epoch 14, gen_loss = 0.4403694045954737, disc_loss = 0.009485131059371835
Trained batch 493 in epoch 14, gen_loss = 0.4403366662471401, disc_loss = 0.009467606719532371
Trained batch 494 in epoch 14, gen_loss = 0.4404441334984519, disc_loss = 0.009450477683643876
Trained batch 495 in epoch 14, gen_loss = 0.44033015182902735, disc_loss = 0.00943389296650909
Trained batch 496 in epoch 14, gen_loss = 0.440267637941679, disc_loss = 0.009416544310897551
Trained batch 497 in epoch 14, gen_loss = 0.44025903473417444, disc_loss = 0.009399198919504761
Trained batch 498 in epoch 14, gen_loss = 0.44028039829047744, disc_loss = 0.009381976675938344
Trained batch 499 in epoch 14, gen_loss = 0.44020498168468475, disc_loss = 0.009365697521949186
Trained batch 500 in epoch 14, gen_loss = 0.44033194076039356, disc_loss = 0.009350333806636656
Trained batch 501 in epoch 14, gen_loss = 0.4403507203101162, disc_loss = 0.00933404724518082
Trained batch 502 in epoch 14, gen_loss = 0.4402655235697214, disc_loss = 0.009318999659360774
Trained batch 503 in epoch 14, gen_loss = 0.44023085728524225, disc_loss = 0.009302212605516183
Trained batch 504 in epoch 14, gen_loss = 0.44024680020785567, disc_loss = 0.009288497907824187
Trained batch 505 in epoch 14, gen_loss = 0.44023409468147595, disc_loss = 0.009272065630809335
Trained batch 506 in epoch 14, gen_loss = 0.4402780646873414, disc_loss = 0.009255460863340557
Trained batch 507 in epoch 14, gen_loss = 0.4403435505163951, disc_loss = 0.009239215217370313
Trained batch 508 in epoch 14, gen_loss = 0.44023569949951996, disc_loss = 0.009223065429027713
Trained batch 509 in epoch 14, gen_loss = 0.44016965984129436, disc_loss = 0.009206569657373407
Trained batch 510 in epoch 14, gen_loss = 0.44021861351399505, disc_loss = 0.009201343706786203
Trained batch 511 in epoch 14, gen_loss = 0.4401656172121875, disc_loss = 0.009189531033030107
Trained batch 512 in epoch 14, gen_loss = 0.44023659139813504, disc_loss = 0.00917425094983408
Trained batch 513 in epoch 14, gen_loss = 0.4402234148422568, disc_loss = 0.009158439411403945
Trained batch 514 in epoch 14, gen_loss = 0.4402101860463041, disc_loss = 0.009141977395618207
Trained batch 515 in epoch 14, gen_loss = 0.44017037402751835, disc_loss = 0.0091255449703687
Trained batch 516 in epoch 14, gen_loss = 0.44016462426121045, disc_loss = 0.009110286151940756
Trained batch 517 in epoch 14, gen_loss = 0.44024170215985947, disc_loss = 0.009094413327305798
Trained batch 518 in epoch 14, gen_loss = 0.44031488493458154, disc_loss = 0.009078421860552879
Trained batch 519 in epoch 14, gen_loss = 0.44032593358021516, disc_loss = 0.009062554179175864
Trained batch 520 in epoch 14, gen_loss = 0.4404111228840365, disc_loss = 0.009046634243003088
Trained batch 521 in epoch 14, gen_loss = 0.4402450327101338, disc_loss = 0.00903078683355816
Trained batch 522 in epoch 14, gen_loss = 0.4402146466489504, disc_loss = 0.009015478539889604
Trained batch 523 in epoch 14, gen_loss = 0.4402923775651983, disc_loss = 0.009000595502390078
Trained batch 524 in epoch 14, gen_loss = 0.44013419894945055, disc_loss = 0.008985854299694654
Trained batch 525 in epoch 14, gen_loss = 0.44008800732998793, disc_loss = 0.008970320417754665
Trained batch 526 in epoch 14, gen_loss = 0.4400786713359478, disc_loss = 0.008957733099739398
Trained batch 527 in epoch 14, gen_loss = 0.4399863492245927, disc_loss = 0.008943620982322362
Trained batch 528 in epoch 14, gen_loss = 0.4399621219625996, disc_loss = 0.00892838802970312
Trained batch 529 in epoch 14, gen_loss = 0.43988615206952364, disc_loss = 0.008912865482358577
Trained batch 530 in epoch 14, gen_loss = 0.4398828103941937, disc_loss = 0.008897517269771903
Trained batch 531 in epoch 14, gen_loss = 0.43991722345800327, disc_loss = 0.008883460453725456
Trained batch 532 in epoch 14, gen_loss = 0.43983045695646616, disc_loss = 0.008868302073697498
Trained batch 533 in epoch 14, gen_loss = 0.43987780189915987, disc_loss = 0.008853994868325126
Trained batch 534 in epoch 14, gen_loss = 0.4398991273385342, disc_loss = 0.008839410623409306
Trained batch 535 in epoch 14, gen_loss = 0.4399977013913553, disc_loss = 0.008826730285798123
Trained batch 536 in epoch 14, gen_loss = 0.4399908964194399, disc_loss = 0.008811415785757106
Trained batch 537 in epoch 14, gen_loss = 0.43999995845179574, disc_loss = 0.008796721781676698
Trained batch 538 in epoch 14, gen_loss = 0.4400136238568789, disc_loss = 0.00878183210116564
Trained batch 539 in epoch 14, gen_loss = 0.4399167914633398, disc_loss = 0.008767372938692225
Trained batch 540 in epoch 14, gen_loss = 0.439995939542097, disc_loss = 0.008753522916812305
Trained batch 541 in epoch 14, gen_loss = 0.43991751902877624, disc_loss = 0.008740562215968074
Trained batch 542 in epoch 14, gen_loss = 0.43998010640425356, disc_loss = 0.008727241369242168
Trained batch 543 in epoch 14, gen_loss = 0.4399724482175182, disc_loss = 0.008712182787241866
Trained batch 544 in epoch 14, gen_loss = 0.44002370407821934, disc_loss = 0.008698833693852734
Trained batch 545 in epoch 14, gen_loss = 0.4400258753653411, disc_loss = 0.008684734047361524
Trained batch 546 in epoch 14, gen_loss = 0.4399726550474463, disc_loss = 0.008670550183873195
Trained batch 547 in epoch 14, gen_loss = 0.4400287429890493, disc_loss = 0.008656238641332407
Trained batch 548 in epoch 14, gen_loss = 0.44001529228709, disc_loss = 0.008641444268455738
Trained batch 549 in epoch 14, gen_loss = 0.4399290705810894, disc_loss = 0.00862782224854031
Trained batch 550 in epoch 14, gen_loss = 0.4398983178251235, disc_loss = 0.008613042308806954
Trained batch 551 in epoch 14, gen_loss = 0.4398504404918007, disc_loss = 0.00859902513173807
Trained batch 552 in epoch 14, gen_loss = 0.43980759414583176, disc_loss = 0.008584944794676983
Trained batch 553 in epoch 14, gen_loss = 0.4398311684277944, disc_loss = 0.008570635770401323
Trained batch 554 in epoch 14, gen_loss = 0.4398039525693601, disc_loss = 0.008556775436086395
Trained batch 555 in epoch 14, gen_loss = 0.43965706502576524, disc_loss = 0.008542808889170184
Trained batch 556 in epoch 14, gen_loss = 0.4395505053992759, disc_loss = 0.008528580360952264
Trained batch 557 in epoch 14, gen_loss = 0.4394830027361497, disc_loss = 0.008514636875285456
Trained batch 558 in epoch 14, gen_loss = 0.43941236240705994, disc_loss = 0.008500765175025491
Trained batch 559 in epoch 14, gen_loss = 0.439413046091795, disc_loss = 0.008486718602840223
Trained batch 560 in epoch 14, gen_loss = 0.43945987312763984, disc_loss = 0.008475022832593264
Trained batch 561 in epoch 14, gen_loss = 0.4394835049147284, disc_loss = 0.0084610543119741
Trained batch 562 in epoch 14, gen_loss = 0.439429658979548, disc_loss = 0.008448280313641138
Trained batch 563 in epoch 14, gen_loss = 0.43938595447557194, disc_loss = 0.008434613544497217
Trained batch 564 in epoch 14, gen_loss = 0.43935153574015184, disc_loss = 0.008421595091931522
Trained batch 565 in epoch 14, gen_loss = 0.43933801431959174, disc_loss = 0.008408892736235442
Trained batch 566 in epoch 14, gen_loss = 0.4392866852317117, disc_loss = 0.00839554678013867
Trained batch 567 in epoch 14, gen_loss = 0.43939410617024127, disc_loss = 0.008382836063466246
Trained batch 568 in epoch 14, gen_loss = 0.439385387568566, disc_loss = 0.00837038659350701
Trained batch 569 in epoch 14, gen_loss = 0.439394840911815, disc_loss = 0.008357016312003364
Trained batch 570 in epoch 14, gen_loss = 0.43940082797862184, disc_loss = 0.008344294569694034
Trained batch 571 in epoch 14, gen_loss = 0.4393814483305791, disc_loss = 0.008330965987459587
Trained batch 572 in epoch 14, gen_loss = 0.4392722440951782, disc_loss = 0.008317656007763583
Trained batch 573 in epoch 14, gen_loss = 0.43919734267407595, disc_loss = 0.00830412163767876
Trained batch 574 in epoch 14, gen_loss = 0.4392017359837242, disc_loss = 0.008291047140854694
Trained batch 575 in epoch 14, gen_loss = 0.43919335559217465, disc_loss = 0.00827797613823754
Trained batch 576 in epoch 14, gen_loss = 0.43920470394542765, disc_loss = 0.008264700663530234
Trained batch 577 in epoch 14, gen_loss = 0.43916760544875916, disc_loss = 0.008251268688446736
Trained batch 578 in epoch 14, gen_loss = 0.43895094824990255, disc_loss = 0.008238435269893181
Trained batch 579 in epoch 14, gen_loss = 0.43898937984787184, disc_loss = 0.008226303377686518
Trained batch 580 in epoch 14, gen_loss = 0.43900932169001605, disc_loss = 0.008214206493695277
Trained batch 581 in epoch 14, gen_loss = 0.4390871571920991, disc_loss = 0.008202148381783868
Trained batch 582 in epoch 14, gen_loss = 0.4390265458546208, disc_loss = 0.008190112449644104
Trained batch 583 in epoch 14, gen_loss = 0.43906387247859613, disc_loss = 0.008177362812590492
Trained batch 584 in epoch 14, gen_loss = 0.4390511542303949, disc_loss = 0.00816511336244388
Trained batch 585 in epoch 14, gen_loss = 0.43908909095432164, disc_loss = 0.008152488719710901
Trained batch 586 in epoch 14, gen_loss = 0.439091996602346, disc_loss = 0.008139832944151496
Trained batch 587 in epoch 14, gen_loss = 0.43906771031772196, disc_loss = 0.008127027568086621
Trained batch 588 in epoch 14, gen_loss = 0.4390611193176036, disc_loss = 0.008114333767645497
Trained batch 589 in epoch 14, gen_loss = 0.4389594977690002, disc_loss = 0.008101590684717679
Trained batch 590 in epoch 14, gen_loss = 0.43889850751195864, disc_loss = 0.0080893302248482
Trained batch 591 in epoch 14, gen_loss = 0.43882039189338684, disc_loss = 0.008077111790044
Trained batch 592 in epoch 14, gen_loss = 0.4387943748679973, disc_loss = 0.008064557101776192
Trained batch 593 in epoch 14, gen_loss = 0.4387702029762846, disc_loss = 0.008052016364219238
Trained batch 594 in epoch 14, gen_loss = 0.4387399888339163, disc_loss = 0.008039441425940257
Trained batch 595 in epoch 14, gen_loss = 0.4387321841196726, disc_loss = 0.00802791581919648
Trained batch 596 in epoch 14, gen_loss = 0.43870418155612656, disc_loss = 0.008016242510545531
Trained batch 597 in epoch 14, gen_loss = 0.4387005636823616, disc_loss = 0.008004289463452097
Trained batch 598 in epoch 14, gen_loss = 0.43869743069543665, disc_loss = 0.00799373727492391
Trained batch 599 in epoch 14, gen_loss = 0.43864383454124134, disc_loss = 0.00798191690594346
Trained batch 600 in epoch 14, gen_loss = 0.43864513003885647, disc_loss = 0.007971262731399548
Trained batch 601 in epoch 14, gen_loss = 0.43861814754151823, disc_loss = 0.007960129905847114
Trained batch 602 in epoch 14, gen_loss = 0.4386134779275353, disc_loss = 0.007948167038082175
Trained batch 603 in epoch 14, gen_loss = 0.43858733792968146, disc_loss = 0.007936141553908488
Trained batch 604 in epoch 14, gen_loss = 0.4386235796223002, disc_loss = 0.007926038930515859
Trained batch 605 in epoch 14, gen_loss = 0.43855242131173416, disc_loss = 0.00791386646599349
Trained batch 606 in epoch 14, gen_loss = 0.4385283566778142, disc_loss = 0.007904260446447143
Trained batch 607 in epoch 14, gen_loss = 0.438541374316341, disc_loss = 0.007892599578745399
Trained batch 608 in epoch 14, gen_loss = 0.43848452348818723, disc_loss = 0.007881535486985695
Trained batch 609 in epoch 14, gen_loss = 0.4383583430384026, disc_loss = 0.007871433343360445
Trained batch 610 in epoch 14, gen_loss = 0.4383745547109657, disc_loss = 0.007863081989862457
Trained batch 611 in epoch 14, gen_loss = 0.4383518226882991, disc_loss = 0.007851425714405053
Trained batch 612 in epoch 14, gen_loss = 0.4383034331763549, disc_loss = 0.007840229322823132
Trained batch 613 in epoch 14, gen_loss = 0.4382348457648622, disc_loss = 0.007829437675375448
Trained batch 614 in epoch 14, gen_loss = 0.4381052202325526, disc_loss = 0.007817793028463223
Trained batch 615 in epoch 14, gen_loss = 0.43817237290469085, disc_loss = 0.007806940536508367
Trained batch 616 in epoch 14, gen_loss = 0.4382299952800695, disc_loss = 0.007795798502552264
Trained batch 617 in epoch 14, gen_loss = 0.4382425277557188, disc_loss = 0.007785644362364899
Trained batch 618 in epoch 14, gen_loss = 0.4382839810000868, disc_loss = 0.007774549321348964
Trained batch 619 in epoch 14, gen_loss = 0.43832734222373654, disc_loss = 0.0077642942353474695
Trained batch 620 in epoch 14, gen_loss = 0.43830035326945416, disc_loss = 0.007755118269520555
Trained batch 621 in epoch 14, gen_loss = 0.4382899333618078, disc_loss = 0.007746844807653942
Trained batch 622 in epoch 14, gen_loss = 0.4383113878879272, disc_loss = 0.0077360313125799315
Trained batch 623 in epoch 14, gen_loss = 0.43828817753073496, disc_loss = 0.007725656662119153
Trained batch 624 in epoch 14, gen_loss = 0.4382089615345001, disc_loss = 0.00771466652257368
Trained batch 625 in epoch 14, gen_loss = 0.43828415542174454, disc_loss = 0.007704176358040274
Trained batch 626 in epoch 14, gen_loss = 0.43832831904648595, disc_loss = 0.007692989897249531
Trained batch 627 in epoch 14, gen_loss = 0.43834080632515016, disc_loss = 0.0076827618745222365
Trained batch 628 in epoch 14, gen_loss = 0.4383103321580326, disc_loss = 0.007671532126099896
Trained batch 629 in epoch 14, gen_loss = 0.43831863540505606, disc_loss = 0.007661181225511615
Trained batch 630 in epoch 14, gen_loss = 0.4383514198089364, disc_loss = 0.007651193263086678
Trained batch 631 in epoch 14, gen_loss = 0.4384063092307954, disc_loss = 0.0076404310764908445
Trained batch 632 in epoch 14, gen_loss = 0.43841069009255085, disc_loss = 0.007629275128670555
Trained batch 633 in epoch 14, gen_loss = 0.4383898583778448, disc_loss = 0.007618606507822971
Trained batch 634 in epoch 14, gen_loss = 0.4383533155824256, disc_loss = 0.007608793816789545
Trained batch 635 in epoch 14, gen_loss = 0.4382033906642746, disc_loss = 0.007597726506438054
Trained batch 636 in epoch 14, gen_loss = 0.4382556915470345, disc_loss = 0.007588736035183417
Trained batch 637 in epoch 14, gen_loss = 0.4382497454791981, disc_loss = 0.007577680173033679
Trained batch 638 in epoch 14, gen_loss = 0.4383162341673796, disc_loss = 0.007567273203559739
Trained batch 639 in epoch 14, gen_loss = 0.4382568866945803, disc_loss = 0.007556159253454098
Trained batch 640 in epoch 14, gen_loss = 0.43824660266617343, disc_loss = 0.0075456469212426235
Trained batch 641 in epoch 14, gen_loss = 0.4381454075422614, disc_loss = 0.007534721486812249
Trained batch 642 in epoch 14, gen_loss = 0.4380787711584735, disc_loss = 0.007523865957616236
Trained batch 643 in epoch 14, gen_loss = 0.4380152268069131, disc_loss = 0.007514217724826228
Trained batch 644 in epoch 14, gen_loss = 0.4379956713480543, disc_loss = 0.007505232961433254
Trained batch 645 in epoch 14, gen_loss = 0.4380185763256469, disc_loss = 0.007495140789733369
Trained batch 646 in epoch 14, gen_loss = 0.4379429758239935, disc_loss = 0.007485032690940151
Trained batch 647 in epoch 14, gen_loss = 0.4378662261146086, disc_loss = 0.007474510402567426
Trained batch 648 in epoch 14, gen_loss = 0.43791185115078013, disc_loss = 0.007464394208602751
Trained batch 649 in epoch 14, gen_loss = 0.4378784563449713, disc_loss = 0.007455513317120047
Trained batch 650 in epoch 14, gen_loss = 0.43782288802018, disc_loss = 0.00744517552714649
Trained batch 651 in epoch 14, gen_loss = 0.43775258030445297, disc_loss = 0.007435020838276358
Trained batch 652 in epoch 14, gen_loss = 0.4377175345446395, disc_loss = 0.007425418846786256
Trained batch 653 in epoch 14, gen_loss = 0.4376966500774436, disc_loss = 0.007417909062730251
Trained batch 654 in epoch 14, gen_loss = 0.4376456033182508, disc_loss = 0.007407633724839263
Trained batch 655 in epoch 14, gen_loss = 0.4375521994491176, disc_loss = 0.007397877267422012
Trained batch 656 in epoch 14, gen_loss = 0.43755112087164116, disc_loss = 0.007388421792634076
Trained batch 657 in epoch 14, gen_loss = 0.43747984112939575, disc_loss = 0.007379355278035264
Trained batch 658 in epoch 14, gen_loss = 0.43748595451368005, disc_loss = 0.007369658188546028
Trained batch 659 in epoch 14, gen_loss = 0.4374922626849377, disc_loss = 0.007360095740736913
Trained batch 660 in epoch 14, gen_loss = 0.4373575875059379, disc_loss = 0.007350092398445861
Trained batch 661 in epoch 14, gen_loss = 0.43740886688412495, disc_loss = 0.007341735839004575
Trained batch 662 in epoch 14, gen_loss = 0.4376242822921114, disc_loss = 0.0073335025512029
Trained batch 663 in epoch 14, gen_loss = 0.4375963545438037, disc_loss = 0.007324692073747297
Trained batch 664 in epoch 14, gen_loss = 0.4376531561514489, disc_loss = 0.0073163655587416
Trained batch 665 in epoch 14, gen_loss = 0.43752691100488555, disc_loss = 0.007306781763056372
Trained batch 666 in epoch 14, gen_loss = 0.43753597149248424, disc_loss = 0.007297308702490291
Trained batch 667 in epoch 14, gen_loss = 0.437611256218599, disc_loss = 0.0072886290996437226
Trained batch 668 in epoch 14, gen_loss = 0.43773453443217886, disc_loss = 0.007281756081520225
Trained batch 669 in epoch 14, gen_loss = 0.43775755376068515, disc_loss = 0.007272690417741968
Trained batch 670 in epoch 14, gen_loss = 0.43776050676354356, disc_loss = 0.007263687302461852
Trained batch 671 in epoch 14, gen_loss = 0.43785342290287926, disc_loss = 0.007258147926612375
Trained batch 672 in epoch 14, gen_loss = 0.4378854108954964, disc_loss = 0.0072526570168575675
Trained batch 673 in epoch 14, gen_loss = 0.43795682202460856, disc_loss = 0.007245991469443104
Trained batch 674 in epoch 14, gen_loss = 0.4379743846257528, disc_loss = 0.007237554315943271
Trained batch 675 in epoch 14, gen_loss = 0.43784191754795393, disc_loss = 0.007231101420478614
Trained batch 676 in epoch 14, gen_loss = 0.43784540072853845, disc_loss = 0.007224884037491748
Trained batch 677 in epoch 14, gen_loss = 0.4379236292874215, disc_loss = 0.007216192359790882
Trained batch 678 in epoch 14, gen_loss = 0.43781781222929134, disc_loss = 0.007210097797142975
Trained batch 679 in epoch 14, gen_loss = 0.4377794558072791, disc_loss = 0.007202322106476298
Trained batch 680 in epoch 14, gen_loss = 0.4377326661619671, disc_loss = 0.007194273674429125
Trained batch 681 in epoch 14, gen_loss = 0.4377162515505318, disc_loss = 0.007185394418322757
Trained batch 682 in epoch 14, gen_loss = 0.4376397337519058, disc_loss = 0.007178507684672041
Trained batch 683 in epoch 14, gen_loss = 0.4376495454830733, disc_loss = 0.007171777483536753
Trained batch 684 in epoch 14, gen_loss = 0.43762598794742225, disc_loss = 0.007164849568732817
Trained batch 685 in epoch 14, gen_loss = 0.43761309620764094, disc_loss = 0.007156577778307438
Trained batch 686 in epoch 14, gen_loss = 0.4376584569960182, disc_loss = 0.007149866318924615
Trained batch 687 in epoch 14, gen_loss = 0.4377174682395403, disc_loss = 0.007143891325202191
Trained batch 688 in epoch 14, gen_loss = 0.4377337270706935, disc_loss = 0.00713527470893674
Trained batch 689 in epoch 14, gen_loss = 0.43772251156793124, disc_loss = 0.007126462469434203
Trained batch 690 in epoch 14, gen_loss = 0.4376656304823852, disc_loss = 0.007117301261968312
Trained batch 691 in epoch 14, gen_loss = 0.4376578522641535, disc_loss = 0.007109297840264518
Trained batch 692 in epoch 14, gen_loss = 0.437719743274163, disc_loss = 0.007100667401393647
Trained batch 693 in epoch 14, gen_loss = 0.43759273838584634, disc_loss = 0.0070919363362069165
Trained batch 694 in epoch 14, gen_loss = 0.43761507585751924, disc_loss = 0.00708463604372705
Trained batch 695 in epoch 14, gen_loss = 0.43774965940707034, disc_loss = 0.007076687564964315
Trained batch 696 in epoch 14, gen_loss = 0.4376789926199865, disc_loss = 0.007072218351812373
Trained batch 697 in epoch 14, gen_loss = 0.4377418811563776, disc_loss = 0.007064213508684695
Trained batch 698 in epoch 14, gen_loss = 0.4376775738336839, disc_loss = 0.007057610460945427
Trained batch 699 in epoch 14, gen_loss = 0.43757067216294154, disc_loss = 0.007050044465494076
Trained batch 700 in epoch 14, gen_loss = 0.4376670513700657, disc_loss = 0.007042564125615338
Trained batch 701 in epoch 14, gen_loss = 0.4376372671619779, disc_loss = 0.007034036242406407
Trained batch 702 in epoch 14, gen_loss = 0.4376457240723953, disc_loss = 0.007025336654450092
Trained batch 703 in epoch 14, gen_loss = 0.4375840334899046, disc_loss = 0.0070164807795498
Trained batch 704 in epoch 14, gen_loss = 0.43757506558235654, disc_loss = 0.0070078337414797845
Trained batch 705 in epoch 14, gen_loss = 0.43757245375144244, disc_loss = 0.007004149824878196
Trained batch 706 in epoch 14, gen_loss = 0.43753939892311583, disc_loss = 0.006996275794519773
Trained batch 707 in epoch 14, gen_loss = 0.4375996072750307, disc_loss = 0.006989874806989111
Trained batch 708 in epoch 14, gen_loss = 0.4375979948699558, disc_loss = 0.006981467355597023
Trained batch 709 in epoch 14, gen_loss = 0.43749892988675076, disc_loss = 0.006975000733378488
Trained batch 710 in epoch 14, gen_loss = 0.4373887819663717, disc_loss = 0.006966870447585383
Trained batch 711 in epoch 14, gen_loss = 0.43734474701995263, disc_loss = 0.006959485854944371
Trained batch 712 in epoch 14, gen_loss = 0.4373732500123108, disc_loss = 0.0069515396598243216
Trained batch 713 in epoch 14, gen_loss = 0.43736600274799253, disc_loss = 0.00694371183831323
Trained batch 714 in epoch 14, gen_loss = 0.4373087079791756, disc_loss = 0.0069362397079349505
Trained batch 715 in epoch 14, gen_loss = 0.437365293544431, disc_loss = 0.006927952754562304
Trained batch 716 in epoch 14, gen_loss = 0.43727829628409703, disc_loss = 0.006919884138657469
Trained batch 717 in epoch 14, gen_loss = 0.43722547233768827, disc_loss = 0.006911328677405813
Trained batch 718 in epoch 14, gen_loss = 0.4372957406853104, disc_loss = 0.006903333123935249
Trained batch 719 in epoch 14, gen_loss = 0.4374265823099348, disc_loss = 0.006895499520760495
Trained batch 720 in epoch 14, gen_loss = 0.43741356785022933, disc_loss = 0.006887178906725898
Trained batch 721 in epoch 14, gen_loss = 0.4374033628325713, disc_loss = 0.00687903414135012
Trained batch 722 in epoch 14, gen_loss = 0.43735675346801883, disc_loss = 0.006871380960201023
Trained batch 723 in epoch 14, gen_loss = 0.4372530388568646, disc_loss = 0.006863505835275073
Trained batch 724 in epoch 14, gen_loss = 0.43718908811437673, disc_loss = 0.006855083206540038
Trained batch 725 in epoch 14, gen_loss = 0.4372513996996499, disc_loss = 0.0068479624773137085
Trained batch 726 in epoch 14, gen_loss = 0.43727675309863345, disc_loss = 0.006840839800764352
Trained batch 727 in epoch 14, gen_loss = 0.43718441072237363, disc_loss = 0.006832752654800361
Trained batch 728 in epoch 14, gen_loss = 0.4372386911523686, disc_loss = 0.006824725756817082
Trained batch 729 in epoch 14, gen_loss = 0.43722246130035347, disc_loss = 0.006816976075459349
Trained batch 730 in epoch 14, gen_loss = 0.4372692871354673, disc_loss = 0.006808759150539287
Trained batch 731 in epoch 14, gen_loss = 0.43730339452705747, disc_loss = 0.00680702982069301
Trained batch 732 in epoch 14, gen_loss = 0.437260083945679, disc_loss = 0.006800769094748125
Trained batch 733 in epoch 14, gen_loss = 0.4371647018665189, disc_loss = 0.006795723270291808
Trained batch 734 in epoch 14, gen_loss = 0.4371113997738378, disc_loss = 0.006789650633649229
Trained batch 735 in epoch 14, gen_loss = 0.4371299205104942, disc_loss = 0.006784187844222406
Trained batch 736 in epoch 14, gen_loss = 0.4372076695453846, disc_loss = 0.006776612527239461
Trained batch 737 in epoch 14, gen_loss = 0.4371329892457016, disc_loss = 0.0067693632649577055
Trained batch 738 in epoch 14, gen_loss = 0.4371984698211066, disc_loss = 0.006763455876151127
Trained batch 739 in epoch 14, gen_loss = 0.43727343746939223, disc_loss = 0.006756534854916075
Trained batch 740 in epoch 14, gen_loss = 0.4372431016080936, disc_loss = 0.0067503822727195475
Trained batch 741 in epoch 14, gen_loss = 0.4372224684834802, disc_loss = 0.006742838733516398
Trained batch 742 in epoch 14, gen_loss = 0.4372629656044022, disc_loss = 0.006735936350212339
Trained batch 743 in epoch 14, gen_loss = 0.4372837974099062, disc_loss = 0.006728998821536054
Trained batch 744 in epoch 14, gen_loss = 0.4372936894029579, disc_loss = 0.006722682329041621
Trained batch 745 in epoch 14, gen_loss = 0.43720347763865625, disc_loss = 0.00671488464087118
Testing Epoch 14
Training Epoch 15
Trained batch 0 in epoch 15, gen_loss = 0.4485971927642822, disc_loss = 0.002145809819921851
Trained batch 1 in epoch 15, gen_loss = 0.3937191814184189, disc_loss = 0.0016645985888317227
Trained batch 2 in epoch 15, gen_loss = 0.4265674849351247, disc_loss = 0.0019412233183781307
Trained batch 3 in epoch 15, gen_loss = 0.4248845726251602, disc_loss = 0.0019058207981288433
Trained batch 4 in epoch 15, gen_loss = 0.4359481930732727, disc_loss = 0.0018508936977013946
Trained batch 5 in epoch 15, gen_loss = 0.43374767899513245, disc_loss = 0.0017988112522289157
Trained batch 6 in epoch 15, gen_loss = 0.4303869775363377, disc_loss = 0.001687562292707818
Trained batch 7 in epoch 15, gen_loss = 0.4388674274086952, disc_loss = 0.0017215635161846876
Trained batch 8 in epoch 15, gen_loss = 0.43532849020428127, disc_loss = 0.0016561579735328753
Trained batch 9 in epoch 15, gen_loss = 0.4306822448968887, disc_loss = 0.0016936029540374875
Trained batch 10 in epoch 15, gen_loss = 0.4360910572788932, disc_loss = 0.0018927398434078152
Trained batch 11 in epoch 15, gen_loss = 0.4359651133418083, disc_loss = 0.0018623096887798358
Trained batch 12 in epoch 15, gen_loss = 0.43982914319405186, disc_loss = 0.0018910504071615064
Trained batch 13 in epoch 15, gen_loss = 0.4415257786001478, disc_loss = 0.0018756010020816965
Trained batch 14 in epoch 15, gen_loss = 0.4368190328280131, disc_loss = 0.001856222376227379
Trained batch 15 in epoch 15, gen_loss = 0.43449366092681885, disc_loss = 0.0017975461487367284
Trained batch 16 in epoch 15, gen_loss = 0.43423277139663696, disc_loss = 0.0017372747225796476
Trained batch 17 in epoch 15, gen_loss = 0.4367800835106108, disc_loss = 0.0016973833036091593
Trained batch 18 in epoch 15, gen_loss = 0.4370572535615218, disc_loss = 0.0016796957750461604
Trained batch 19 in epoch 15, gen_loss = 0.4359430715441704, disc_loss = 0.0016392107936553657
Trained batch 20 in epoch 15, gen_loss = 0.4363294570218949, disc_loss = 0.0016210717592565786
Trained batch 21 in epoch 15, gen_loss = 0.4337121153419668, disc_loss = 0.0017080593811856074
Trained batch 22 in epoch 15, gen_loss = 0.43363421507503674, disc_loss = 0.0016802705358713865
Trained batch 23 in epoch 15, gen_loss = 0.43700264766812325, disc_loss = 0.0016597163339611143
Trained batch 24 in epoch 15, gen_loss = 0.4360730469226837, disc_loss = 0.0016323623713105917
Trained batch 25 in epoch 15, gen_loss = 0.4342053887935785, disc_loss = 0.0016401120855544622
Trained batch 26 in epoch 15, gen_loss = 0.4370150731669532, disc_loss = 0.0016542281265612
Trained batch 27 in epoch 15, gen_loss = 0.438499642269952, disc_loss = 0.0019367167925728218
Trained batch 28 in epoch 15, gen_loss = 0.4389126835198238, disc_loss = 0.002010555680969666
Trained batch 29 in epoch 15, gen_loss = 0.4373577485481898, disc_loss = 0.002017125052710374
Trained batch 30 in epoch 15, gen_loss = 0.43883228782684575, disc_loss = 0.0020179533880324133
Trained batch 31 in epoch 15, gen_loss = 0.4381325403228402, disc_loss = 0.0019970335124526173
Trained batch 32 in epoch 15, gen_loss = 0.4349538132999883, disc_loss = 0.0022586481081265392
Trained batch 33 in epoch 15, gen_loss = 0.4361044492791681, disc_loss = 0.0022749913007240087
Trained batch 34 in epoch 15, gen_loss = 0.43699318170547485, disc_loss = 0.0022981817301894938
Trained batch 35 in epoch 15, gen_loss = 0.4388332847091887, disc_loss = 0.002291276080844303
Trained batch 36 in epoch 15, gen_loss = 0.4399090280403962, disc_loss = 0.0022906707033414292
Trained batch 37 in epoch 15, gen_loss = 0.439789731251566, disc_loss = 0.0022706990314059353
Trained batch 38 in epoch 15, gen_loss = 0.43996304732102615, disc_loss = 0.0024375784366081157
Trained batch 39 in epoch 15, gen_loss = 0.44149949997663496, disc_loss = 0.0024335227615665646
Trained batch 40 in epoch 15, gen_loss = 0.44069524945282357, disc_loss = 0.002456000580157085
Trained batch 41 in epoch 15, gen_loss = 0.44027682145436603, disc_loss = 0.0029897538645725164
Trained batch 42 in epoch 15, gen_loss = 0.4413881710795469, disc_loss = 0.005362906217098583
Trained batch 43 in epoch 15, gen_loss = 0.440245469185439, disc_loss = 0.00744766992283985
Trained batch 44 in epoch 15, gen_loss = 0.4397245519691043, disc_loss = 0.007789640382139219
Trained batch 45 in epoch 15, gen_loss = 0.4410239924555239, disc_loss = 0.007934647657827514
Trained batch 46 in epoch 15, gen_loss = 0.4402546521196974, disc_loss = 0.007984648741028727
Trained batch 47 in epoch 15, gen_loss = 0.4395022230843703, disc_loss = 0.008143946513882838
Trained batch 48 in epoch 15, gen_loss = 0.4403977752948294, disc_loss = 0.008586625611333519
Trained batch 49 in epoch 15, gen_loss = 0.4411273765563965, disc_loss = 0.009187047281302511
Trained batch 50 in epoch 15, gen_loss = 0.4420610157882466, disc_loss = 0.00935060489356664
Trained batch 51 in epoch 15, gen_loss = 0.4419038244164907, disc_loss = 0.009314542963133695
Trained batch 52 in epoch 15, gen_loss = 0.44152003133072043, disc_loss = 0.009260636995950679
Trained batch 53 in epoch 15, gen_loss = 0.4409692292964017, disc_loss = 0.009142022416064585
Trained batch 54 in epoch 15, gen_loss = 0.4410898138176311, disc_loss = 0.009039606022733179
Trained batch 55 in epoch 15, gen_loss = 0.4410757826907294, disc_loss = 0.008913692864423086
Trained batch 56 in epoch 15, gen_loss = 0.44118911027908325, disc_loss = 0.00878343053096742
Trained batch 57 in epoch 15, gen_loss = 0.44194847499502116, disc_loss = 0.008665584585757861
Trained batch 58 in epoch 15, gen_loss = 0.4436581412614402, disc_loss = 0.008602948460759501
Trained batch 59 in epoch 15, gen_loss = 0.4433287173509598, disc_loss = 0.00855229755009835
Trained batch 60 in epoch 15, gen_loss = 0.44388474890443147, disc_loss = 0.008483215750454635
Trained batch 61 in epoch 15, gen_loss = 0.44431132847262966, disc_loss = 0.008417990565630458
Trained batch 62 in epoch 15, gen_loss = 0.44378018095379784, disc_loss = 0.008347563841010607
Trained batch 63 in epoch 15, gen_loss = 0.4440325163304806, disc_loss = 0.008255706412455766
Trained batch 64 in epoch 15, gen_loss = 0.4436056430523212, disc_loss = 0.008172541881839817
Trained batch 65 in epoch 15, gen_loss = 0.44279248877005145, disc_loss = 0.008078098279480455
Trained batch 66 in epoch 15, gen_loss = 0.4420860810066337, disc_loss = 0.007977929098337
Trained batch 67 in epoch 15, gen_loss = 0.4425787781091297, disc_loss = 0.007908672943492146
Trained batch 68 in epoch 15, gen_loss = 0.44336572116699774, disc_loss = 0.007817133869705856
Trained batch 69 in epoch 15, gen_loss = 0.4422237562281745, disc_loss = 0.0077298607527544454
Trained batch 70 in epoch 15, gen_loss = 0.44223355701271916, disc_loss = 0.007637916813263486
Trained batch 71 in epoch 15, gen_loss = 0.44177982169720864, disc_loss = 0.00754804627245499
Trained batch 72 in epoch 15, gen_loss = 0.4421457644194773, disc_loss = 0.007471856929055632
Trained batch 73 in epoch 15, gen_loss = 0.4418755298530733, disc_loss = 0.0073836980563764636
Trained batch 74 in epoch 15, gen_loss = 0.4424488790829976, disc_loss = 0.00730131319258362
Trained batch 75 in epoch 15, gen_loss = 0.4428996651580459, disc_loss = 0.007231598219062251
Trained batch 76 in epoch 15, gen_loss = 0.4434284687816323, disc_loss = 0.007162669756715851
Trained batch 77 in epoch 15, gen_loss = 0.4435250006425075, disc_loss = 0.0071210100790127535
Trained batch 78 in epoch 15, gen_loss = 0.44302756876885135, disc_loss = 0.0070568504021208305
Trained batch 79 in epoch 15, gen_loss = 0.4422439582645893, disc_loss = 0.0069897459659841845
Trained batch 80 in epoch 15, gen_loss = 0.4422219314692933, disc_loss = 0.006926784787706479
Trained batch 81 in epoch 15, gen_loss = 0.44264723251505594, disc_loss = 0.0068579526254680095
Trained batch 82 in epoch 15, gen_loss = 0.4436118868460138, disc_loss = 0.0068742994623011856
Trained batch 83 in epoch 15, gen_loss = 0.4432709635723205, disc_loss = 0.0068403267900326425
Trained batch 84 in epoch 15, gen_loss = 0.442901528933469, disc_loss = 0.006784371576984139
Trained batch 85 in epoch 15, gen_loss = 0.44304420504459113, disc_loss = 0.0067217922038506975
Trained batch 86 in epoch 15, gen_loss = 0.4426831918201227, disc_loss = 0.00666637668364692
Trained batch 87 in epoch 15, gen_loss = 0.44241025231101294, disc_loss = 0.0066069002773887905
Trained batch 88 in epoch 15, gen_loss = 0.44145879283379974, disc_loss = 0.006551039257358885
Trained batch 89 in epoch 15, gen_loss = 0.4411948541800181, disc_loss = 0.0065380258990141256
Trained batch 90 in epoch 15, gen_loss = 0.44144964152640037, disc_loss = 0.006494540602204155
Trained batch 91 in epoch 15, gen_loss = 0.44146258675533795, disc_loss = 0.006436288497238623
Trained batch 92 in epoch 15, gen_loss = 0.44202699744573204, disc_loss = 0.006379008268116302
Trained batch 93 in epoch 15, gen_loss = 0.44142604920458284, disc_loss = 0.006320370864024029
Trained batch 94 in epoch 15, gen_loss = 0.441526030239306, disc_loss = 0.006278653156110331
Trained batch 95 in epoch 15, gen_loss = 0.44157291917751235, disc_loss = 0.00622779338057929
Trained batch 96 in epoch 15, gen_loss = 0.4414259121590054, disc_loss = 0.006180313951095816
Trained batch 97 in epoch 15, gen_loss = 0.44102434357818293, disc_loss = 0.006129518038431677
Trained batch 98 in epoch 15, gen_loss = 0.4410060707366828, disc_loss = 0.00608059093403169
Trained batch 99 in epoch 15, gen_loss = 0.4412316992878914, disc_loss = 0.006053302339278161
Trained batch 100 in epoch 15, gen_loss = 0.44135342848182907, disc_loss = 0.00600477529339271
Trained batch 101 in epoch 15, gen_loss = 0.441231801813724, disc_loss = 0.005956471438848358
Trained batch 102 in epoch 15, gen_loss = 0.441493841050898, disc_loss = 0.005917017135624457
Trained batch 103 in epoch 15, gen_loss = 0.4409968314262537, disc_loss = 0.005878673452221287
Trained batch 104 in epoch 15, gen_loss = 0.4406975632622128, disc_loss = 0.005847937168021287
Trained batch 105 in epoch 15, gen_loss = 0.44019956043306385, disc_loss = 0.005809392742724773
Trained batch 106 in epoch 15, gen_loss = 0.44014963730473383, disc_loss = 0.005765049771632059
Trained batch 107 in epoch 15, gen_loss = 0.44035464994333406, disc_loss = 0.005722897166075806
Trained batch 108 in epoch 15, gen_loss = 0.44052409278143434, disc_loss = 0.00570984822996986
Trained batch 109 in epoch 15, gen_loss = 0.44089802341027695, disc_loss = 0.005680005952969871
Trained batch 110 in epoch 15, gen_loss = 0.44108973483781555, disc_loss = 0.005651692813681858
Trained batch 111 in epoch 15, gen_loss = 0.44069456229252474, disc_loss = 0.005611391032289248
Trained batch 112 in epoch 15, gen_loss = 0.4407508795240284, disc_loss = 0.005574663827995217
Trained batch 113 in epoch 15, gen_loss = 0.44005367185985833, disc_loss = 0.005534202046283896
Trained batch 114 in epoch 15, gen_loss = 0.4402619605479033, disc_loss = 0.005495668990213586
Trained batch 115 in epoch 15, gen_loss = 0.44022049883316305, disc_loss = 0.005459200264685306
Trained batch 116 in epoch 15, gen_loss = 0.44024382875515866, disc_loss = 0.005421478267456604
Trained batch 117 in epoch 15, gen_loss = 0.43996479677951944, disc_loss = 0.005381444207159802
Trained batch 118 in epoch 15, gen_loss = 0.4403375549977567, disc_loss = 0.005342805072833479
Trained batch 119 in epoch 15, gen_loss = 0.4402639778951804, disc_loss = 0.005303137975958331
Trained batch 120 in epoch 15, gen_loss = 0.4402179624423508, disc_loss = 0.0052666749582964585
Trained batch 121 in epoch 15, gen_loss = 0.43987893887230606, disc_loss = 0.00522832270305161
Trained batch 122 in epoch 15, gen_loss = 0.4401687095320322, disc_loss = 0.005190941337609618
Trained batch 123 in epoch 15, gen_loss = 0.44049978304293846, disc_loss = 0.005154610772977674
Trained batch 124 in epoch 15, gen_loss = 0.4404268333911896, disc_loss = 0.005117778944317251
Trained batch 125 in epoch 15, gen_loss = 0.44023968326667, disc_loss = 0.005089485176583929
Trained batch 126 in epoch 15, gen_loss = 0.44007565304050295, disc_loss = 0.005054556851744593
Trained batch 127 in epoch 15, gen_loss = 0.43976866477169096, disc_loss = 0.0050204281533297035
Trained batch 128 in epoch 15, gen_loss = 0.43932227617086367, disc_loss = 0.004989937702266052
Trained batch 129 in epoch 15, gen_loss = 0.43942658351017877, disc_loss = 0.004956291451190527
Trained batch 130 in epoch 15, gen_loss = 0.4396230309974146, disc_loss = 0.00492410957573323
Trained batch 131 in epoch 15, gen_loss = 0.43964484559767175, disc_loss = 0.004893261417623073
Trained batch 132 in epoch 15, gen_loss = 0.4397156200462714, disc_loss = 0.004862936281448552
Trained batch 133 in epoch 15, gen_loss = 0.43926178274759603, disc_loss = 0.004831683398450294
Trained batch 134 in epoch 15, gen_loss = 0.4388965924580892, disc_loss = 0.004800646734441182
Trained batch 135 in epoch 15, gen_loss = 0.439245425602969, disc_loss = 0.004774286172452027
Trained batch 136 in epoch 15, gen_loss = 0.4390498158270425, disc_loss = 0.0047471239329247746
Trained batch 137 in epoch 15, gen_loss = 0.43917060567848926, disc_loss = 0.004719510446285721
Trained batch 138 in epoch 15, gen_loss = 0.43914664413431564, disc_loss = 0.004700832745217778
Trained batch 139 in epoch 15, gen_loss = 0.4386445456317493, disc_loss = 0.004672659892405916
Trained batch 140 in epoch 15, gen_loss = 0.4382212872200824, disc_loss = 0.004645385840950626
Trained batch 141 in epoch 15, gen_loss = 0.4381049308978336, disc_loss = 0.00461820583105166
Trained batch 142 in epoch 15, gen_loss = 0.437955750452055, disc_loss = 0.004591622722817103
Trained batch 143 in epoch 15, gen_loss = 0.437616766947839, disc_loss = 0.004564332755560624
Trained batch 144 in epoch 15, gen_loss = 0.43790776380177204, disc_loss = 0.004556474059916519
Trained batch 145 in epoch 15, gen_loss = 0.43750476694270357, disc_loss = 0.004535555722325887
Trained batch 146 in epoch 15, gen_loss = 0.43791050671720183, disc_loss = 0.004511192214491517
Trained batch 147 in epoch 15, gen_loss = 0.4378586755813779, disc_loss = 0.004485918445720312
Trained batch 148 in epoch 15, gen_loss = 0.4374104956252463, disc_loss = 0.004468588881982153
Trained batch 149 in epoch 15, gen_loss = 0.43738361875216164, disc_loss = 0.004450437002815306
Trained batch 150 in epoch 15, gen_loss = 0.43719897068888935, disc_loss = 0.004426457047221923
Trained batch 151 in epoch 15, gen_loss = 0.43751659832502665, disc_loss = 0.004402401305254132
Trained batch 152 in epoch 15, gen_loss = 0.43765027480187757, disc_loss = 0.004377963347056138
Trained batch 153 in epoch 15, gen_loss = 0.43778287783845676, disc_loss = 0.004356709794994057
Trained batch 154 in epoch 15, gen_loss = 0.4374746018840421, disc_loss = 0.004331951308995485
Trained batch 155 in epoch 15, gen_loss = 0.4374539897992061, disc_loss = 0.004308723594966488
Trained batch 156 in epoch 15, gen_loss = 0.43746430460055163, disc_loss = 0.00430057156248208
Trained batch 157 in epoch 15, gen_loss = 0.4372041923335836, disc_loss = 0.004282237467860001
Trained batch 158 in epoch 15, gen_loss = 0.4372470648783558, disc_loss = 0.004264075140272554
Trained batch 159 in epoch 15, gen_loss = 0.43743183724582196, disc_loss = 0.004245048795928597
Trained batch 160 in epoch 15, gen_loss = 0.43716058079500375, disc_loss = 0.004223309789555761
Trained batch 161 in epoch 15, gen_loss = 0.43712261539918407, disc_loss = 0.0042045156383041845
Trained batch 162 in epoch 15, gen_loss = 0.43720607413836055, disc_loss = 0.0041838166363925835
Trained batch 163 in epoch 15, gen_loss = 0.4372531708057334, disc_loss = 0.004163317004340791
Trained batch 164 in epoch 15, gen_loss = 0.43690586126211917, disc_loss = 0.004144044977852679
Trained batch 165 in epoch 15, gen_loss = 0.4369183794920703, disc_loss = 0.0041247313861112415
Trained batch 166 in epoch 15, gen_loss = 0.43677474727887594, disc_loss = 0.0047164608213442665
Trained batch 167 in epoch 15, gen_loss = 0.43649413844659213, disc_loss = 0.005231957283588902
Trained batch 168 in epoch 15, gen_loss = 0.4365424598462483, disc_loss = 0.00533023368554829
Trained batch 169 in epoch 15, gen_loss = 0.43655181614791644, disc_loss = 0.0054008798122488185
Trained batch 170 in epoch 15, gen_loss = 0.4366778705203742, disc_loss = 0.005609798718622357
Trained batch 171 in epoch 15, gen_loss = 0.4371914633138235, disc_loss = 0.005866988063559781
Trained batch 172 in epoch 15, gen_loss = 0.43770605067297214, disc_loss = 0.006114174218544187
Trained batch 173 in epoch 15, gen_loss = 0.43804277068582076, disc_loss = 0.006152665595478517
Trained batch 174 in epoch 15, gen_loss = 0.43812128288405283, disc_loss = 0.006377531832549721
Trained batch 175 in epoch 15, gen_loss = 0.4387392196804285, disc_loss = 0.006389381183742609
Trained batch 176 in epoch 15, gen_loss = 0.43899277812343535, disc_loss = 0.006417058423716617
Trained batch 177 in epoch 15, gen_loss = 0.43942659423592384, disc_loss = 0.0064123943235510645
Trained batch 178 in epoch 15, gen_loss = 0.4390889537734026, disc_loss = 0.006389072200988404
Trained batch 179 in epoch 15, gen_loss = 0.43907867156796987, disc_loss = 0.006365933986833423
Trained batch 180 in epoch 15, gen_loss = 0.43911088583219116, disc_loss = 0.00633886392010911
Trained batch 181 in epoch 15, gen_loss = 0.4390421036508057, disc_loss = 0.006315839517500845
Trained batch 182 in epoch 15, gen_loss = 0.43913012352146086, disc_loss = 0.006293022910659736
Trained batch 183 in epoch 15, gen_loss = 0.43895585478647897, disc_loss = 0.0062687572521415704
Trained batch 184 in epoch 15, gen_loss = 0.4389811270945781, disc_loss = 0.006242641942210596
Trained batch 185 in epoch 15, gen_loss = 0.438783368115784, disc_loss = 0.006216329130937436
Trained batch 186 in epoch 15, gen_loss = 0.4384189887161561, disc_loss = 0.006192379272829263
Trained batch 187 in epoch 15, gen_loss = 0.4384747157071499, disc_loss = 0.00616821680531312
Trained batch 188 in epoch 15, gen_loss = 0.43839869076612764, disc_loss = 0.006144332765692736
Trained batch 189 in epoch 15, gen_loss = 0.4378551097292649, disc_loss = 0.0061177672551773294
Trained batch 190 in epoch 15, gen_loss = 0.43795457575957814, disc_loss = 0.006100391601248893
Trained batch 191 in epoch 15, gen_loss = 0.4377634852814178, disc_loss = 0.006082131394274863
Trained batch 192 in epoch 15, gen_loss = 0.43750758059901895, disc_loss = 0.006061297181783813
Trained batch 193 in epoch 15, gen_loss = 0.43757300601177607, disc_loss = 0.0060374175469011795
Trained batch 194 in epoch 15, gen_loss = 0.4375453450740912, disc_loss = 0.006012470935148975
Trained batch 195 in epoch 15, gen_loss = 0.43766818682149966, disc_loss = 0.005996115775054264
Trained batch 196 in epoch 15, gen_loss = 0.43786568039564916, disc_loss = 0.005972791120095585
Trained batch 197 in epoch 15, gen_loss = 0.43777040505048, disc_loss = 0.005948848925669668
Trained batch 198 in epoch 15, gen_loss = 0.4382858739126867, disc_loss = 0.005930963631932291
Trained batch 199 in epoch 15, gen_loss = 0.4380438669025898, disc_loss = 0.005906371725432109
Trained batch 200 in epoch 15, gen_loss = 0.4380268518307909, disc_loss = 0.005883347623881916
Trained batch 201 in epoch 15, gen_loss = 0.4380339634890604, disc_loss = 0.005861718736365346
Trained batch 202 in epoch 15, gen_loss = 0.43788510296732336, disc_loss = 0.005837829310729127
Trained batch 203 in epoch 15, gen_loss = 0.4379843685264681, disc_loss = 0.005813471084990192
Trained batch 204 in epoch 15, gen_loss = 0.43796830220920285, disc_loss = 0.005789329153031293
Trained batch 205 in epoch 15, gen_loss = 0.43779023469073103, disc_loss = 0.005764910821843603
Trained batch 206 in epoch 15, gen_loss = 0.437884211252277, disc_loss = 0.005742921565933792
Trained batch 207 in epoch 15, gen_loss = 0.4380681405846889, disc_loss = 0.005720041929005395
Trained batch 208 in epoch 15, gen_loss = 0.4381543556183719, disc_loss = 0.005697261021833457
Trained batch 209 in epoch 15, gen_loss = 0.43813924179190683, disc_loss = 0.0056733711118189
Trained batch 210 in epoch 15, gen_loss = 0.4381818097632078, disc_loss = 0.005650842731423517
Trained batch 211 in epoch 15, gen_loss = 0.43824232946027, disc_loss = 0.00562743105808106
Trained batch 212 in epoch 15, gen_loss = 0.4380428805037843, disc_loss = 0.005615884964212233
Trained batch 213 in epoch 15, gen_loss = 0.43833638407359615, disc_loss = 0.005594368868727219
Trained batch 214 in epoch 15, gen_loss = 0.4381823966669482, disc_loss = 0.005573642104160214
Trained batch 215 in epoch 15, gen_loss = 0.4381353114214208, disc_loss = 0.005555008855784156
Trained batch 216 in epoch 15, gen_loss = 0.43834379123103234, disc_loss = 0.005534389577451922
Trained batch 217 in epoch 15, gen_loss = 0.4383620417446171, disc_loss = 0.005516275427349065
Trained batch 218 in epoch 15, gen_loss = 0.43867707361369374, disc_loss = 0.005498390647180838
Trained batch 219 in epoch 15, gen_loss = 0.4388682670213959, disc_loss = 0.005477165881629017
Trained batch 220 in epoch 15, gen_loss = 0.4388727897702299, disc_loss = 0.005456912110041305
Trained batch 221 in epoch 15, gen_loss = 0.4389008027207744, disc_loss = 0.00543784136414058
Trained batch 222 in epoch 15, gen_loss = 0.4388064363879473, disc_loss = 0.005417141093164599
Trained batch 223 in epoch 15, gen_loss = 0.43888329355312244, disc_loss = 0.0053982831276308775
Trained batch 224 in epoch 15, gen_loss = 0.4386225340101454, disc_loss = 0.0053774954003488855
Trained batch 225 in epoch 15, gen_loss = 0.43836627201696415, disc_loss = 0.005358741460295921
Trained batch 226 in epoch 15, gen_loss = 0.4381310832132852, disc_loss = 0.005340501084761686
Trained batch 227 in epoch 15, gen_loss = 0.4381730114681679, disc_loss = 0.005320932348503878
Trained batch 228 in epoch 15, gen_loss = 0.43801315369564375, disc_loss = 0.005302747104044467
Trained batch 229 in epoch 15, gen_loss = 0.4378613944934762, disc_loss = 0.0052825091275103065
Trained batch 230 in epoch 15, gen_loss = 0.4381992152500978, disc_loss = 0.005263644478231411
Trained batch 231 in epoch 15, gen_loss = 0.43805870323859414, disc_loss = 0.005244384917926348
Trained batch 232 in epoch 15, gen_loss = 0.4379451189174161, disc_loss = 0.00522873626873017
Trained batch 233 in epoch 15, gen_loss = 0.4380052020916572, disc_loss = 0.005215757955054744
Trained batch 234 in epoch 15, gen_loss = 0.4381171778161475, disc_loss = 0.005197412241002584
Trained batch 235 in epoch 15, gen_loss = 0.43838780878458994, disc_loss = 0.005178694242574037
Trained batch 236 in epoch 15, gen_loss = 0.4383259708619822, disc_loss = 0.005159373191049723
Trained batch 237 in epoch 15, gen_loss = 0.43817897466551353, disc_loss = 0.005140466105140073
Trained batch 238 in epoch 15, gen_loss = 0.4379233303927976, disc_loss = 0.005121077058221132
Trained batch 239 in epoch 15, gen_loss = 0.4379648788521687, disc_loss = 0.005103913431230467
Trained batch 240 in epoch 15, gen_loss = 0.43784921978024527, disc_loss = 0.005085637011368183
Trained batch 241 in epoch 15, gen_loss = 0.43750086402104904, disc_loss = 0.005067612374998044
Trained batch 242 in epoch 15, gen_loss = 0.43720161473309554, disc_loss = 0.00504980489531141
Trained batch 243 in epoch 15, gen_loss = 0.4372243232658652, disc_loss = 0.005033105054057249
Trained batch 244 in epoch 15, gen_loss = 0.4372255877572663, disc_loss = 0.005015879144835077
Trained batch 245 in epoch 15, gen_loss = 0.4373678905450232, disc_loss = 0.004998080001299731
Trained batch 246 in epoch 15, gen_loss = 0.43757019182931073, disc_loss = 0.0049807261114728895
Trained batch 247 in epoch 15, gen_loss = 0.4375402040539249, disc_loss = 0.004962983228559155
Trained batch 248 in epoch 15, gen_loss = 0.43759962341871605, disc_loss = 0.004945436989548186
Trained batch 249 in epoch 15, gen_loss = 0.4373784137964249, disc_loss = 0.00492857594275847
Trained batch 250 in epoch 15, gen_loss = 0.4373325952495712, disc_loss = 0.004912564649471115
Trained batch 251 in epoch 15, gen_loss = 0.43715244389715646, disc_loss = 0.004898267330385612
Trained batch 252 in epoch 15, gen_loss = 0.4371135299620421, disc_loss = 0.004882772339704878
Trained batch 253 in epoch 15, gen_loss = 0.4369965029044414, disc_loss = 0.0048692441056390826
Trained batch 254 in epoch 15, gen_loss = 0.4369606715791366, disc_loss = 0.0048594088387200795
Trained batch 255 in epoch 15, gen_loss = 0.4369985149241984, disc_loss = 0.004843072251560443
Trained batch 256 in epoch 15, gen_loss = 0.4367380265131999, disc_loss = 0.004828160554161549
Trained batch 257 in epoch 15, gen_loss = 0.4366994838612948, disc_loss = 0.004812849974557541
Trained batch 258 in epoch 15, gen_loss = 0.4363357880400875, disc_loss = 0.0047984371111462155
Trained batch 259 in epoch 15, gen_loss = 0.43624405287779294, disc_loss = 0.004782669109856495
Trained batch 260 in epoch 15, gen_loss = 0.43598000973577244, disc_loss = 0.004768039604115489
Trained batch 261 in epoch 15, gen_loss = 0.4361555134977093, disc_loss = 0.004753501802542468
Trained batch 262 in epoch 15, gen_loss = 0.4361386867983713, disc_loss = 0.004737553878345601
Trained batch 263 in epoch 15, gen_loss = 0.4359250231222673, disc_loss = 0.004721666586798771
Trained batch 264 in epoch 15, gen_loss = 0.4361251524034536, disc_loss = 0.0047071424684100695
Trained batch 265 in epoch 15, gen_loss = 0.4361453270329569, disc_loss = 0.004694899346520144
Trained batch 266 in epoch 15, gen_loss = 0.43620677967643023, disc_loss = 0.004680406993293388
Trained batch 267 in epoch 15, gen_loss = 0.43607718019343134, disc_loss = 0.004665829781434193
Trained batch 268 in epoch 15, gen_loss = 0.4360765723933961, disc_loss = 0.004650666333213933
Trained batch 269 in epoch 15, gen_loss = 0.4360722999881815, disc_loss = 0.004636111667302127
Trained batch 270 in epoch 15, gen_loss = 0.43624694562926064, disc_loss = 0.004621760851172627
Trained batch 271 in epoch 15, gen_loss = 0.4364285107482882, disc_loss = 0.00460808917063439
Trained batch 272 in epoch 15, gen_loss = 0.4363737032090351, disc_loss = 0.004594005505092128
Trained batch 273 in epoch 15, gen_loss = 0.4365126124046145, disc_loss = 0.004580227381347536
Trained batch 274 in epoch 15, gen_loss = 0.4365519071709026, disc_loss = 0.004567289775957099
Trained batch 275 in epoch 15, gen_loss = 0.43657240552314813, disc_loss = 0.004553751505201048
Trained batch 276 in epoch 15, gen_loss = 0.4364540206826551, disc_loss = 0.0045411232705497
Trained batch 277 in epoch 15, gen_loss = 0.43643018903492165, disc_loss = 0.004527193649291737
Trained batch 278 in epoch 15, gen_loss = 0.43667282660802204, disc_loss = 0.004513810804959948
Trained batch 279 in epoch 15, gen_loss = 0.43701215939862387, disc_loss = 0.0045001730769789515
Trained batch 280 in epoch 15, gen_loss = 0.43707645363654957, disc_loss = 0.004489938045969545
Trained batch 281 in epoch 15, gen_loss = 0.43709161032176186, disc_loss = 0.00447749420988096
Trained batch 282 in epoch 15, gen_loss = 0.43712769085442643, disc_loss = 0.004464586003964878
Trained batch 283 in epoch 15, gen_loss = 0.4370081436256288, disc_loss = 0.004452304887744388
Trained batch 284 in epoch 15, gen_loss = 0.4368984608273757, disc_loss = 0.0044408679623238485
Trained batch 285 in epoch 15, gen_loss = 0.43693392082944615, disc_loss = 0.004427522526308243
Trained batch 286 in epoch 15, gen_loss = 0.43696129020913554, disc_loss = 0.004414084756451591
Trained batch 287 in epoch 15, gen_loss = 0.4370366107258532, disc_loss = 0.004401040676990912
Trained batch 288 in epoch 15, gen_loss = 0.43726875542769383, disc_loss = 0.004387977394270533
Trained batch 289 in epoch 15, gen_loss = 0.4374677844088653, disc_loss = 0.004376943878516362
Trained batch 290 in epoch 15, gen_loss = 0.4371867275115141, disc_loss = 0.0043639755704603395
Trained batch 291 in epoch 15, gen_loss = 0.4370736325644467, disc_loss = 0.004351197823655651
Trained batch 292 in epoch 15, gen_loss = 0.43692188214116534, disc_loss = 0.0043384085630651555
Trained batch 293 in epoch 15, gen_loss = 0.4368394118587987, disc_loss = 0.004326129287836098
Trained batch 294 in epoch 15, gen_loss = 0.43665445002458864, disc_loss = 0.004313541048648372
Trained batch 295 in epoch 15, gen_loss = 0.4365071653312928, disc_loss = 0.004302299800533424
Trained batch 296 in epoch 15, gen_loss = 0.436429500579834, disc_loss = 0.004291072657162493
Trained batch 297 in epoch 15, gen_loss = 0.43629738648465816, disc_loss = 0.004280649769766844
Trained batch 298 in epoch 15, gen_loss = 0.43636476236043564, disc_loss = 0.00426973052202945
Trained batch 299 in epoch 15, gen_loss = 0.4361951611439387, disc_loss = 0.004260804990384107
Trained batch 300 in epoch 15, gen_loss = 0.43606437896177225, disc_loss = 0.004248461554962461
Trained batch 301 in epoch 15, gen_loss = 0.4361093565328232, disc_loss = 0.00423706808903822
Trained batch 302 in epoch 15, gen_loss = 0.43613559351895903, disc_loss = 0.00422651285406282
Trained batch 303 in epoch 15, gen_loss = 0.4362020688621621, disc_loss = 0.004214834606069704
Trained batch 304 in epoch 15, gen_loss = 0.4361606155262619, disc_loss = 0.0042031057093094
Trained batch 305 in epoch 15, gen_loss = 0.43610789066825817, disc_loss = 0.004193255614475621
Trained batch 306 in epoch 15, gen_loss = 0.4360822701298841, disc_loss = 0.00418156796250286
Trained batch 307 in epoch 15, gen_loss = 0.436170354388751, disc_loss = 0.004170319257272323
Trained batch 308 in epoch 15, gen_loss = 0.4360698504934033, disc_loss = 0.004160609006057388
Trained batch 309 in epoch 15, gen_loss = 0.43619067832346886, disc_loss = 0.004149519091269242
Trained batch 310 in epoch 15, gen_loss = 0.43605976990181533, disc_loss = 0.004138058062135227
Trained batch 311 in epoch 15, gen_loss = 0.4359965511621573, disc_loss = 0.004127033312099042
Trained batch 312 in epoch 15, gen_loss = 0.4359930541378241, disc_loss = 0.004115527996736855
Trained batch 313 in epoch 15, gen_loss = 0.4359084254806968, disc_loss = 0.004105001796447749
Trained batch 314 in epoch 15, gen_loss = 0.43576700318427314, disc_loss = 0.004094402446773731
Trained batch 315 in epoch 15, gen_loss = 0.4355070668308041, disc_loss = 0.004083949888141271
Trained batch 316 in epoch 15, gen_loss = 0.43554743832970266, disc_loss = 0.004074310091190475
Trained batch 317 in epoch 15, gen_loss = 0.4356257769296754, disc_loss = 0.004063391020344336
Trained batch 318 in epoch 15, gen_loss = 0.43563861860003217, disc_loss = 0.0040559025047431614
Trained batch 319 in epoch 15, gen_loss = 0.4354037565179169, disc_loss = 0.004044669823724689
Trained batch 320 in epoch 15, gen_loss = 0.435332637988147, disc_loss = 0.004035344124047051
Trained batch 321 in epoch 15, gen_loss = 0.43509829997646143, disc_loss = 0.004028906295982028
Trained batch 322 in epoch 15, gen_loss = 0.43532686899690065, disc_loss = 0.004018431723398234
Trained batch 323 in epoch 15, gen_loss = 0.43547554810841876, disc_loss = 0.004008179149366944
Trained batch 324 in epoch 15, gen_loss = 0.4353193809435918, disc_loss = 0.003999149260702185
Trained batch 325 in epoch 15, gen_loss = 0.4354913437659024, disc_loss = 0.003988572792632168
Trained batch 326 in epoch 15, gen_loss = 0.4355145820419358, disc_loss = 0.003978663579748078
Trained batch 327 in epoch 15, gen_loss = 0.435295350667907, disc_loss = 0.003968978615065259
Trained batch 328 in epoch 15, gen_loss = 0.4350702836883104, disc_loss = 0.003959580265055623
Trained batch 329 in epoch 15, gen_loss = 0.43515199169968116, disc_loss = 0.003950615155521187
Trained batch 330 in epoch 15, gen_loss = 0.43526017710881654, disc_loss = 0.0039410187740243265
Trained batch 331 in epoch 15, gen_loss = 0.4354052960154522, disc_loss = 0.00393084933252301
Trained batch 332 in epoch 15, gen_loss = 0.4353923444991355, disc_loss = 0.003920829093399075
Trained batch 333 in epoch 15, gen_loss = 0.43536312708597696, disc_loss = 0.003910386841029659
Trained batch 334 in epoch 15, gen_loss = 0.4352517396656435, disc_loss = 0.0039004203619317276
Trained batch 335 in epoch 15, gen_loss = 0.43527046706350075, disc_loss = 0.0038904314915271243
Trained batch 336 in epoch 15, gen_loss = 0.43516953700727806, disc_loss = 0.003881047068641159
Trained batch 337 in epoch 15, gen_loss = 0.4351413646745964, disc_loss = 0.0038707510982543647
Trained batch 338 in epoch 15, gen_loss = 0.4352649336015932, disc_loss = 0.003861995961806932
Trained batch 339 in epoch 15, gen_loss = 0.4352523591588525, disc_loss = 0.003852337058496607
Trained batch 340 in epoch 15, gen_loss = 0.435176368245631, disc_loss = 0.0038448879727410955
Trained batch 341 in epoch 15, gen_loss = 0.43514026091461294, disc_loss = 0.0038365497623504908
Trained batch 342 in epoch 15, gen_loss = 0.43530233860363415, disc_loss = 0.003827681399253265
Trained batch 343 in epoch 15, gen_loss = 0.4353047066996264, disc_loss = 0.00381901053350343
Trained batch 344 in epoch 15, gen_loss = 0.43523843011994295, disc_loss = 0.0038093569965196262
Trained batch 345 in epoch 15, gen_loss = 0.4352438301709346, disc_loss = 0.003800195713481742
Trained batch 346 in epoch 15, gen_loss = 0.4353644018214443, disc_loss = 0.003791384900496033
Trained batch 347 in epoch 15, gen_loss = 0.435157991089355, disc_loss = 0.0037821910966953113
Trained batch 348 in epoch 15, gen_loss = 0.43481533891150465, disc_loss = 0.003773390770460183
Trained batch 349 in epoch 15, gen_loss = 0.43495792422975815, disc_loss = 0.00376458366717478
Trained batch 350 in epoch 15, gen_loss = 0.43487050866129734, disc_loss = 0.0037555485511758494
Trained batch 351 in epoch 15, gen_loss = 0.4350605026226152, disc_loss = 0.0037475950215263188
Trained batch 352 in epoch 15, gen_loss = 0.43502428367860596, disc_loss = 0.003972774685298491
Trained batch 353 in epoch 15, gen_loss = 0.4349651128727164, disc_loss = 0.004011311939105886
Trained batch 354 in epoch 15, gen_loss = 0.43463110327720644, disc_loss = 0.004578524321468521
Trained batch 355 in epoch 15, gen_loss = 0.4346769565109457, disc_loss = 0.004697606111242269
Trained batch 356 in epoch 15, gen_loss = 0.43456999110240563, disc_loss = 0.004731164005857629
Trained batch 357 in epoch 15, gen_loss = 0.4346023912036885, disc_loss = 0.004781204886967316
Trained batch 358 in epoch 15, gen_loss = 0.4345291752503111, disc_loss = 0.004887845016812289
Trained batch 359 in epoch 15, gen_loss = 0.4346677786774106, disc_loss = 0.005453732560434016
Trained batch 360 in epoch 15, gen_loss = 0.4344911141904107, disc_loss = 0.006622966009848738
Trained batch 361 in epoch 15, gen_loss = 0.4343686267651247, disc_loss = 0.006868747317519049
Trained batch 362 in epoch 15, gen_loss = 0.4343561984126561, disc_loss = 0.007253438534347223
Trained batch 363 in epoch 15, gen_loss = 0.4344747604413347, disc_loss = 0.007486569431481197
Trained batch 364 in epoch 15, gen_loss = 0.43447696680892006, disc_loss = 0.007612214403144046
Trained batch 365 in epoch 15, gen_loss = 0.43458479504441955, disc_loss = 0.007842671729037742
Trained batch 366 in epoch 15, gen_loss = 0.43442354556325347, disc_loss = 0.008300697661737076
Trained batch 367 in epoch 15, gen_loss = 0.43468144276867743, disc_loss = 0.00851046147426646
Trained batch 368 in epoch 15, gen_loss = 0.4348849613815142, disc_loss = 0.008528270488472397
Trained batch 369 in epoch 15, gen_loss = 0.43497778483339256, disc_loss = 0.008557781999823762
Trained batch 370 in epoch 15, gen_loss = 0.4349341177233467, disc_loss = 0.00855833636154358
Trained batch 371 in epoch 15, gen_loss = 0.4347285875069198, disc_loss = 0.008617885328011877
Trained batch 372 in epoch 15, gen_loss = 0.4346406700304302, disc_loss = 0.008625483971642176
Trained batch 373 in epoch 15, gen_loss = 0.43484579154195635, disc_loss = 0.00863951435396672
Trained batch 374 in epoch 15, gen_loss = 0.4349257725079854, disc_loss = 0.008814429906352114
Trained batch 375 in epoch 15, gen_loss = 0.4351931464798907, disc_loss = 0.009160799259026386
Trained batch 376 in epoch 15, gen_loss = 0.4352331244502839, disc_loss = 0.00922594873332826
Trained batch 377 in epoch 15, gen_loss = 0.4352024561829037, disc_loss = 0.009298761732347812
Trained batch 378 in epoch 15, gen_loss = 0.4351924855979577, disc_loss = 0.00944213709461633
Trained batch 379 in epoch 15, gen_loss = 0.4351604257759295, disc_loss = 0.009650725466781297
Trained batch 380 in epoch 15, gen_loss = 0.4351456054239448, disc_loss = 0.009711978949570975
Trained batch 381 in epoch 15, gen_loss = 0.4352683927376233, disc_loss = 0.00977156787890702
Trained batch 382 in epoch 15, gen_loss = 0.4353529978981217, disc_loss = 0.009799230627213452
Trained batch 383 in epoch 15, gen_loss = 0.4352562833422174, disc_loss = 0.009876732546975594
Trained batch 384 in epoch 15, gen_loss = 0.435559062601684, disc_loss = 0.010045679152925051
Trained batch 385 in epoch 15, gen_loss = 0.43571316763527035, disc_loss = 0.010034018154997968
Trained batch 386 in epoch 15, gen_loss = 0.43551149625494806, disc_loss = 0.010098742097177007
Trained batch 387 in epoch 15, gen_loss = 0.43553447331657114, disc_loss = 0.010087110774115102
Trained batch 388 in epoch 15, gen_loss = 0.4355065941350932, disc_loss = 0.010076518087787912
Trained batch 389 in epoch 15, gen_loss = 0.43560494986864234, disc_loss = 0.010079781205888885
Trained batch 390 in epoch 15, gen_loss = 0.43565139631786004, disc_loss = 0.010168580410857934
Trained batch 391 in epoch 15, gen_loss = 0.43571687824263866, disc_loss = 0.010234336540838275
Trained batch 392 in epoch 15, gen_loss = 0.4358347320677973, disc_loss = 0.010221301221185655
Trained batch 393 in epoch 15, gen_loss = 0.4358912601991353, disc_loss = 0.010206212743326105
Trained batch 394 in epoch 15, gen_loss = 0.4358020071741901, disc_loss = 0.010331124741483858
Trained batch 395 in epoch 15, gen_loss = 0.43577084976314295, disc_loss = 0.010346549661739523
Trained batch 396 in epoch 15, gen_loss = 0.43589505996151595, disc_loss = 0.010382534185235602
Trained batch 397 in epoch 15, gen_loss = 0.43580285523405027, disc_loss = 0.01037243100327215
Trained batch 398 in epoch 15, gen_loss = 0.4357043072245175, disc_loss = 0.010356379390307901
Trained batch 399 in epoch 15, gen_loss = 0.4355048558861017, disc_loss = 0.010453773646004265
Trained batch 400 in epoch 15, gen_loss = 0.4355333088490731, disc_loss = 0.010513539365498568
Trained batch 401 in epoch 15, gen_loss = 0.43576888132154645, disc_loss = 0.010629166485087261
Trained batch 402 in epoch 15, gen_loss = 0.43581607353598545, disc_loss = 0.010797387494956357
Trained batch 403 in epoch 15, gen_loss = 0.43551414386175646, disc_loss = 0.010854949079549613
Trained batch 404 in epoch 15, gen_loss = 0.4358971664199123, disc_loss = 0.010865738410588906
Trained batch 405 in epoch 15, gen_loss = 0.4359225153629416, disc_loss = 0.010922327300326055
Trained batch 406 in epoch 15, gen_loss = 0.4357852370498807, disc_loss = 0.0109078791425838
Trained batch 407 in epoch 15, gen_loss = 0.4358825481989804, disc_loss = 0.010915589552942216
Trained batch 408 in epoch 15, gen_loss = 0.435729979302889, disc_loss = 0.01091324878400556
Trained batch 409 in epoch 15, gen_loss = 0.4359315505841883, disc_loss = 0.010900315717175013
Trained batch 410 in epoch 15, gen_loss = 0.43591231434014593, disc_loss = 0.010883983947340073
Trained batch 411 in epoch 15, gen_loss = 0.43611222657474497, disc_loss = 0.010891272112115703
Trained batch 412 in epoch 15, gen_loss = 0.43618230806713243, disc_loss = 0.010870874462368476
Trained batch 413 in epoch 15, gen_loss = 0.4362036883111161, disc_loss = 0.010854358458525955
Trained batch 414 in epoch 15, gen_loss = 0.4362632514482521, disc_loss = 0.01083791804407353
Trained batch 415 in epoch 15, gen_loss = 0.4363202816591813, disc_loss = 0.01086670631313889
Trained batch 416 in epoch 15, gen_loss = 0.4365381345474463, disc_loss = 0.010882987870697414
Trained batch 417 in epoch 15, gen_loss = 0.4367285547644328, disc_loss = 0.010877532113435942
Trained batch 418 in epoch 15, gen_loss = 0.4368138078573495, disc_loss = 0.01087821181405109
Trained batch 419 in epoch 15, gen_loss = 0.4369293103615443, disc_loss = 0.010859361498123256
Trained batch 420 in epoch 15, gen_loss = 0.437141157669013, disc_loss = 0.01084121445737527
Trained batch 421 in epoch 15, gen_loss = 0.43745962943510985, disc_loss = 0.010943960467815815
Trained batch 422 in epoch 15, gen_loss = 0.43747416547286033, disc_loss = 0.010954951049388996
Trained batch 423 in epoch 15, gen_loss = 0.43760627086432474, disc_loss = 0.01097385136436403
Trained batch 424 in epoch 15, gen_loss = 0.4376008005703197, disc_loss = 0.010990913984612287
Trained batch 425 in epoch 15, gen_loss = 0.43763020193912616, disc_loss = 0.01097808821996381
Trained batch 426 in epoch 15, gen_loss = 0.43765148750792066, disc_loss = 0.010981609410005436
Trained batch 427 in epoch 15, gen_loss = 0.4376074690545831, disc_loss = 0.010978130965192245
Trained batch 428 in epoch 15, gen_loss = 0.4376610838449918, disc_loss = 0.01096040936442535
Trained batch 429 in epoch 15, gen_loss = 0.4377986623797306, disc_loss = 0.010982306018812843
Trained batch 430 in epoch 15, gen_loss = 0.438067468717314, disc_loss = 0.010983123336924054
Trained batch 431 in epoch 15, gen_loss = 0.4381489065924176, disc_loss = 0.01097754680826997
Trained batch 432 in epoch 15, gen_loss = 0.4382975409130026, disc_loss = 0.010973312746702239
Trained batch 433 in epoch 15, gen_loss = 0.4382020215147651, disc_loss = 0.010957845251589868
Trained batch 434 in epoch 15, gen_loss = 0.4383488710584312, disc_loss = 0.010980370851506575
Trained batch 435 in epoch 15, gen_loss = 0.438556985775812, disc_loss = 0.01096914185159263
Trained batch 436 in epoch 15, gen_loss = 0.43858085323798573, disc_loss = 0.010961136920137855
Trained batch 437 in epoch 15, gen_loss = 0.43859172745110236, disc_loss = 0.010986498353835918
Trained batch 438 in epoch 15, gen_loss = 0.43846801588638495, disc_loss = 0.011020821399200742
Trained batch 439 in epoch 15, gen_loss = 0.4384734684093432, disc_loss = 0.011015237631694286
Trained batch 440 in epoch 15, gen_loss = 0.438539963933616, disc_loss = 0.011003741552993072
Trained batch 441 in epoch 15, gen_loss = 0.4385777925608924, disc_loss = 0.011006176789745276
Trained batch 442 in epoch 15, gen_loss = 0.438594820806189, disc_loss = 0.011003922160087326
Trained batch 443 in epoch 15, gen_loss = 0.4385088642572497, disc_loss = 0.011041201569159885
Trained batch 444 in epoch 15, gen_loss = 0.43867716126227646, disc_loss = 0.01117906131967379
Trained batch 445 in epoch 15, gen_loss = 0.43851155964782956, disc_loss = 0.01140133928152056
Trained batch 446 in epoch 15, gen_loss = 0.43855525809913143, disc_loss = 0.01146681788645714
Trained batch 447 in epoch 15, gen_loss = 0.4386786501854658, disc_loss = 0.011646351662550711
Trained batch 448 in epoch 15, gen_loss = 0.43876736798636895, disc_loss = 0.011633413980579115
Trained batch 449 in epoch 15, gen_loss = 0.43876788079738616, disc_loss = 0.011632426101585023
Trained batch 450 in epoch 15, gen_loss = 0.4388565050392616, disc_loss = 0.011636680068356293
Trained batch 451 in epoch 15, gen_loss = 0.43880944191354565, disc_loss = 0.01166493156953175
Trained batch 452 in epoch 15, gen_loss = 0.438590691184366, disc_loss = 0.011656499498500129
Trained batch 453 in epoch 15, gen_loss = 0.4386831329651341, disc_loss = 0.011648653226772257
Trained batch 454 in epoch 15, gen_loss = 0.4387477531537905, disc_loss = 0.011632937136500213
Trained batch 455 in epoch 15, gen_loss = 0.4387487514892168, disc_loss = 0.011648360416042954
Trained batch 456 in epoch 15, gen_loss = 0.4387907074760295, disc_loss = 0.01164979024530904
Trained batch 457 in epoch 15, gen_loss = 0.43879162445339054, disc_loss = 0.01163259864869674
Trained batch 458 in epoch 15, gen_loss = 0.4387498812867665, disc_loss = 0.011620408288139266
Trained batch 459 in epoch 15, gen_loss = 0.43863811933475993, disc_loss = 0.011599784754292594
Trained batch 460 in epoch 15, gen_loss = 0.43866159723275655, disc_loss = 0.011588492425569735
Trained batch 461 in epoch 15, gen_loss = 0.4385316147432699, disc_loss = 0.011572685115743888
Trained batch 462 in epoch 15, gen_loss = 0.43854065931384045, disc_loss = 0.011553369951157853
Trained batch 463 in epoch 15, gen_loss = 0.43851988807577513, disc_loss = 0.011535062520751722
Trained batch 464 in epoch 15, gen_loss = 0.43863260297365086, disc_loss = 0.011646998859816782
Trained batch 465 in epoch 15, gen_loss = 0.4388725980156993, disc_loss = 0.012213610562215092
Trained batch 466 in epoch 15, gen_loss = 0.43886998046899506, disc_loss = 0.012210845546293366
Trained batch 467 in epoch 15, gen_loss = 0.43873498550592327, disc_loss = 0.012252304509842299
Trained batch 468 in epoch 15, gen_loss = 0.43867396240803735, disc_loss = 0.012253518019597343
Trained batch 469 in epoch 15, gen_loss = 0.4385633814842143, disc_loss = 0.012263315210510243
Trained batch 470 in epoch 15, gen_loss = 0.4386634273640416, disc_loss = 0.012248548116379728
Trained batch 471 in epoch 15, gen_loss = 0.4386319455580186, disc_loss = 0.01223819150865153
Trained batch 472 in epoch 15, gen_loss = 0.4388349180367734, disc_loss = 0.012228993341463558
Trained batch 473 in epoch 15, gen_loss = 0.4389237475420352, disc_loss = 0.012212572325456235
Trained batch 474 in epoch 15, gen_loss = 0.439004751192896, disc_loss = 0.012195363689679653
Trained batch 475 in epoch 15, gen_loss = 0.4389722963967243, disc_loss = 0.012184139542519349
Trained batch 476 in epoch 15, gen_loss = 0.4388873690829087, disc_loss = 0.012164303113191938
Trained batch 477 in epoch 15, gen_loss = 0.4388859808195585, disc_loss = 0.012147526391056098
Trained batch 478 in epoch 15, gen_loss = 0.438738457843008, disc_loss = 0.012130127188147849
Trained batch 479 in epoch 15, gen_loss = 0.4387145812933644, disc_loss = 0.012109667590387592
Trained batch 480 in epoch 15, gen_loss = 0.4387327081324405, disc_loss = 0.012089622320133898
Trained batch 481 in epoch 15, gen_loss = 0.43861310895053185, disc_loss = 0.012072584750608992
Trained batch 482 in epoch 15, gen_loss = 0.438544372779242, disc_loss = 0.012051532444506536
Trained batch 483 in epoch 15, gen_loss = 0.4384112644417227, disc_loss = 0.012039254731590059
Trained batch 484 in epoch 15, gen_loss = 0.4382899234589842, disc_loss = 0.012018318955676111
Trained batch 485 in epoch 15, gen_loss = 0.43838384594201063, disc_loss = 0.01200647858858258
Trained batch 486 in epoch 15, gen_loss = 0.4384743596371684, disc_loss = 0.011986127998024891
Trained batch 487 in epoch 15, gen_loss = 0.4384584844600959, disc_loss = 0.011970877726481212
Trained batch 488 in epoch 15, gen_loss = 0.4385539168960478, disc_loss = 0.011949861476341632
Trained batch 489 in epoch 15, gen_loss = 0.43866545868163204, disc_loss = 0.011944757245020105
Trained batch 490 in epoch 15, gen_loss = 0.43863092796865644, disc_loss = 0.011930111847706936
Trained batch 491 in epoch 15, gen_loss = 0.4385166155492387, disc_loss = 0.011911894328115182
Trained batch 492 in epoch 15, gen_loss = 0.4384810859847504, disc_loss = 0.01189040435130026
Trained batch 493 in epoch 15, gen_loss = 0.4386050404324705, disc_loss = 0.011873214565823608
Trained batch 494 in epoch 15, gen_loss = 0.43864234938766017, disc_loss = 0.011852578356782106
Trained batch 495 in epoch 15, gen_loss = 0.43863964008708156, disc_loss = 0.011831337586866743
Trained batch 496 in epoch 15, gen_loss = 0.43852608244663754, disc_loss = 0.011809535122310678
Trained batch 497 in epoch 15, gen_loss = 0.4384763940390813, disc_loss = 0.011788958386844399
Trained batch 498 in epoch 15, gen_loss = 0.4383575533458847, disc_loss = 0.011771653874619549
Trained batch 499 in epoch 15, gen_loss = 0.4382525140047073, disc_loss = 0.011754460307885893
Trained batch 500 in epoch 15, gen_loss = 0.4382414017132894, disc_loss = 0.011738503615891453
Trained batch 501 in epoch 15, gen_loss = 0.43820744717263604, disc_loss = 0.01172095962136379
Trained batch 502 in epoch 15, gen_loss = 0.4381098352061588, disc_loss = 0.011702859587342502
Trained batch 503 in epoch 15, gen_loss = 0.4382589588917437, disc_loss = 0.011686133545207133
Trained batch 504 in epoch 15, gen_loss = 0.43816528863245896, disc_loss = 0.011665885338887093
Trained batch 505 in epoch 15, gen_loss = 0.4381178461398061, disc_loss = 0.0116468586432315
Trained batch 506 in epoch 15, gen_loss = 0.4379379935636088, disc_loss = 0.011627398617175285
Trained batch 507 in epoch 15, gen_loss = 0.438062836276734, disc_loss = 0.011608089763221082
Trained batch 508 in epoch 15, gen_loss = 0.4380999205740121, disc_loss = 0.01158974016707826
Trained batch 509 in epoch 15, gen_loss = 0.43795729577541354, disc_loss = 0.011570304776564715
Trained batch 510 in epoch 15, gen_loss = 0.43801658307502883, disc_loss = 0.01155338329757398
Trained batch 511 in epoch 15, gen_loss = 0.4380887047154829, disc_loss = 0.011533642031849922
Trained batch 512 in epoch 15, gen_loss = 0.43806322775853773, disc_loss = 0.011514987294688334
Trained batch 513 in epoch 15, gen_loss = 0.43798015002842544, disc_loss = 0.011495226946254425
Trained batch 514 in epoch 15, gen_loss = 0.4379370836956987, disc_loss = 0.011483877866632911
Trained batch 515 in epoch 15, gen_loss = 0.4379040742682856, disc_loss = 0.011470702504888068
Trained batch 516 in epoch 15, gen_loss = 0.43803168248161817, disc_loss = 0.011459628215651397
Trained batch 517 in epoch 15, gen_loss = 0.43799167911748627, disc_loss = 0.011442885989557887
Trained batch 518 in epoch 15, gen_loss = 0.4379347316447021, disc_loss = 0.011424038113612566
Trained batch 519 in epoch 15, gen_loss = 0.4378695555604421, disc_loss = 0.01140445148955153
Trained batch 520 in epoch 15, gen_loss = 0.4378185808200983, disc_loss = 0.011386985608913727
Trained batch 521 in epoch 15, gen_loss = 0.4377681314945221, disc_loss = 0.011368082409302644
Trained batch 522 in epoch 15, gen_loss = 0.437746390728832, disc_loss = 0.011348626387050023
Trained batch 523 in epoch 15, gen_loss = 0.43784227239266604, disc_loss = 0.011331198084188575
Trained batch 524 in epoch 15, gen_loss = 0.43787846934227714, disc_loss = 0.011378104929213545
Trained batch 525 in epoch 15, gen_loss = 0.438072115239535, disc_loss = 0.011395668236785762
Trained batch 526 in epoch 15, gen_loss = 0.43812678038960845, disc_loss = 0.011386077194867844
Trained batch 527 in epoch 15, gen_loss = 0.4381703749073274, disc_loss = 0.011372534067270339
Trained batch 528 in epoch 15, gen_loss = 0.4382566063187749, disc_loss = 0.011446173018833097
Trained batch 529 in epoch 15, gen_loss = 0.43824683500910705, disc_loss = 0.011466491872001053
Trained batch 530 in epoch 15, gen_loss = 0.43836217703343333, disc_loss = 0.011454430516969706
Trained batch 531 in epoch 15, gen_loss = 0.4384270893003708, disc_loss = 0.011440055814980445
Trained batch 532 in epoch 15, gen_loss = 0.4385000665796183, disc_loss = 0.01142456371930828
Trained batch 533 in epoch 15, gen_loss = 0.4384516595343079, disc_loss = 0.011409159450096773
Trained batch 534 in epoch 15, gen_loss = 0.4383443122712251, disc_loss = 0.011396157256192658
Trained batch 535 in epoch 15, gen_loss = 0.4382471877581148, disc_loss = 0.011384928982453803
Trained batch 536 in epoch 15, gen_loss = 0.4379645861837895, disc_loss = 0.011373836250895083
Trained batch 537 in epoch 15, gen_loss = 0.4379183495465708, disc_loss = 0.011362526734029791
Trained batch 538 in epoch 15, gen_loss = 0.4378950135274367, disc_loss = 0.011356932387867828
Trained batch 539 in epoch 15, gen_loss = 0.4379540397061242, disc_loss = 0.01140518077957461
Trained batch 540 in epoch 15, gen_loss = 0.43794760416483924, disc_loss = 0.011412141879382689
Trained batch 541 in epoch 15, gen_loss = 0.438025413624035, disc_loss = 0.011417233327045398
Trained batch 542 in epoch 15, gen_loss = 0.4381825359706282, disc_loss = 0.011426846426761577
Trained batch 543 in epoch 15, gen_loss = 0.4382216859170619, disc_loss = 0.011428452826508232
Trained batch 544 in epoch 15, gen_loss = 0.4381734743030793, disc_loss = 0.011413787349251124
Trained batch 545 in epoch 15, gen_loss = 0.43822681265217917, disc_loss = 0.011414923438535417
Trained batch 546 in epoch 15, gen_loss = 0.43819819840260354, disc_loss = 0.01140492325476277
Trained batch 547 in epoch 15, gen_loss = 0.43823767486062365, disc_loss = 0.011391054243966766
Trained batch 548 in epoch 15, gen_loss = 0.43826300823189085, disc_loss = 0.011385496222191
Trained batch 549 in epoch 15, gen_loss = 0.4383106991919604, disc_loss = 0.011370021117829972
Trained batch 550 in epoch 15, gen_loss = 0.43828243877191075, disc_loss = 0.011354300232681053
Trained batch 551 in epoch 15, gen_loss = 0.4383048326100992, disc_loss = 0.011341910640876977
Trained batch 552 in epoch 15, gen_loss = 0.43831453298573897, disc_loss = 0.011324637145613225
Trained batch 553 in epoch 15, gen_loss = 0.4384496361017227, disc_loss = 0.011316652702766938
Trained batch 554 in epoch 15, gen_loss = 0.4383641429849573, disc_loss = 0.011301319642718211
Trained batch 555 in epoch 15, gen_loss = 0.4383692602566678, disc_loss = 0.011287431823606468
Trained batch 556 in epoch 15, gen_loss = 0.4382349915093537, disc_loss = 0.011272227854022331
Trained batch 557 in epoch 15, gen_loss = 0.4383108013419695, disc_loss = 0.011271710059539612
Trained batch 558 in epoch 15, gen_loss = 0.4383238501220355, disc_loss = 0.011309220023350773
Trained batch 559 in epoch 15, gen_loss = 0.4382901148604495, disc_loss = 0.011294621158594965
Trained batch 560 in epoch 15, gen_loss = 0.43813666233829424, disc_loss = 0.011348030574012999
Trained batch 561 in epoch 15, gen_loss = 0.4381497108851463, disc_loss = 0.011488595151436081
Trained batch 562 in epoch 15, gen_loss = 0.4381151062768899, disc_loss = 0.011525390225650368
Trained batch 563 in epoch 15, gen_loss = 0.43813242134473, disc_loss = 0.011542534032206593
Trained batch 564 in epoch 15, gen_loss = 0.4381247296270016, disc_loss = 0.011539029715009924
Trained batch 565 in epoch 15, gen_loss = 0.43816053356593576, disc_loss = 0.011542822152985813
Trained batch 566 in epoch 15, gen_loss = 0.43808670518049275, disc_loss = 0.011536647203584518
Trained batch 567 in epoch 15, gen_loss = 0.43803157751828853, disc_loss = 0.011547784754800656
Trained batch 568 in epoch 15, gen_loss = 0.43805606990581236, disc_loss = 0.011598286977686768
Trained batch 569 in epoch 15, gen_loss = 0.4381346823876364, disc_loss = 0.011625653329783266
Trained batch 570 in epoch 15, gen_loss = 0.43810858127323427, disc_loss = 0.011634945668114575
Trained batch 571 in epoch 15, gen_loss = 0.43799566613002255, disc_loss = 0.011998843096487282
Trained batch 572 in epoch 15, gen_loss = 0.4380516612716994, disc_loss = 0.012026587446820784
Trained batch 573 in epoch 15, gen_loss = 0.43810447749360515, disc_loss = 0.012089362102808133
Trained batch 574 in epoch 15, gen_loss = 0.4381052268588025, disc_loss = 0.01211249784698062
Trained batch 575 in epoch 15, gen_loss = 0.43800460759343374, disc_loss = 0.012469798356505635
Trained batch 576 in epoch 15, gen_loss = 0.43810495269360533, disc_loss = 0.012757965869676206
Trained batch 577 in epoch 15, gen_loss = 0.4381177295966132, disc_loss = 0.012812468069496768
Trained batch 578 in epoch 15, gen_loss = 0.43811438589104307, disc_loss = 0.012849846862144736
Trained batch 579 in epoch 15, gen_loss = 0.4381694244927373, disc_loss = 0.012852685233068267
Trained batch 580 in epoch 15, gen_loss = 0.4383174439510667, disc_loss = 0.012876920433408018
Trained batch 581 in epoch 15, gen_loss = 0.43834269226007033, disc_loss = 0.01287677607195423
Trained batch 582 in epoch 15, gen_loss = 0.438255928188409, disc_loss = 0.012877678034661775
Trained batch 583 in epoch 15, gen_loss = 0.43832406442459315, disc_loss = 0.012865748959820724
Trained batch 584 in epoch 15, gen_loss = 0.4385117966904599, disc_loss = 0.012882174680538826
Trained batch 585 in epoch 15, gen_loss = 0.43855249327400847, disc_loss = 0.012868907882012713
Trained batch 586 in epoch 15, gen_loss = 0.4386454038258509, disc_loss = 0.01287239369608262
Trained batch 587 in epoch 15, gen_loss = 0.43866902412403197, disc_loss = 0.012886132871622036
Trained batch 588 in epoch 15, gen_loss = 0.43878382236929214, disc_loss = 0.012875903652469408
Trained batch 589 in epoch 15, gen_loss = 0.43882805007999226, disc_loss = 0.012924628119256695
Trained batch 590 in epoch 15, gen_loss = 0.43890250142657417, disc_loss = 0.012913947821852425
Trained batch 591 in epoch 15, gen_loss = 0.4388665999411731, disc_loss = 0.012901121817432451
Trained batch 592 in epoch 15, gen_loss = 0.4388682668868446, disc_loss = 0.012908045520623565
Trained batch 593 in epoch 15, gen_loss = 0.4388473140771943, disc_loss = 0.012908960204286914
Trained batch 594 in epoch 15, gen_loss = 0.4389346506415295, disc_loss = 0.012893519024345084
Trained batch 595 in epoch 15, gen_loss = 0.4390036359729383, disc_loss = 0.012895286914243225
Trained batch 596 in epoch 15, gen_loss = 0.43907109452052734, disc_loss = 0.012879779298030858
Trained batch 597 in epoch 15, gen_loss = 0.43906883586409895, disc_loss = 0.012866174770354831
Trained batch 598 in epoch 15, gen_loss = 0.4390527783630288, disc_loss = 0.012851430097060785
Trained batch 599 in epoch 15, gen_loss = 0.43904112940033274, disc_loss = 0.012838703646266367
Trained batch 600 in epoch 15, gen_loss = 0.4390036190508209, disc_loss = 0.012824619570983336
Trained batch 601 in epoch 15, gen_loss = 0.43888799667952466, disc_loss = 0.012818157698505054
Trained batch 602 in epoch 15, gen_loss = 0.43884399424540266, disc_loss = 0.01280238249257692
Trained batch 603 in epoch 15, gen_loss = 0.43879731098152946, disc_loss = 0.01280754329399622
Trained batch 604 in epoch 15, gen_loss = 0.4387588122166878, disc_loss = 0.01281942954558248
Trained batch 605 in epoch 15, gen_loss = 0.4389613792546118, disc_loss = 0.01283270627478823
Trained batch 606 in epoch 15, gen_loss = 0.4391851814515901, disc_loss = 0.012838454849659765
Trained batch 607 in epoch 15, gen_loss = 0.43920573822565767, disc_loss = 0.012827532364482115
Trained batch 608 in epoch 15, gen_loss = 0.4393232641451073, disc_loss = 0.012820888448400309
Trained batch 609 in epoch 15, gen_loss = 0.4393741228052827, disc_loss = 0.012869216743036037
Trained batch 610 in epoch 15, gen_loss = 0.43943805775548744, disc_loss = 0.012858462695328827
Trained batch 611 in epoch 15, gen_loss = 0.43956776601231956, disc_loss = 0.01287619265268505
Trained batch 612 in epoch 15, gen_loss = 0.43952886631399346, disc_loss = 0.012864046205282606
Trained batch 613 in epoch 15, gen_loss = 0.43955879160946276, disc_loss = 0.012850830106292958
Trained batch 614 in epoch 15, gen_loss = 0.4396477500113045, disc_loss = 0.012836181414143251
Trained batch 615 in epoch 15, gen_loss = 0.4396662830145328, disc_loss = 0.012820270899838206
Trained batch 616 in epoch 15, gen_loss = 0.4396018197992439, disc_loss = 0.012806626099499162
Trained batch 617 in epoch 15, gen_loss = 0.4395324512110559, disc_loss = 0.01279722906742923
Trained batch 618 in epoch 15, gen_loss = 0.43947831441397045, disc_loss = 0.012781494388207101
Trained batch 619 in epoch 15, gen_loss = 0.43927739700002055, disc_loss = 0.01276372307113507
Trained batch 620 in epoch 15, gen_loss = 0.43932865907988494, disc_loss = 0.01274724735122177
Trained batch 621 in epoch 15, gen_loss = 0.4393193750519461, disc_loss = 0.012730013834701109
Trained batch 622 in epoch 15, gen_loss = 0.4391703861578701, disc_loss = 0.012712523317167067
Trained batch 623 in epoch 15, gen_loss = 0.43912956247536034, disc_loss = 0.012695888920671469
Trained batch 624 in epoch 15, gen_loss = 0.4391080973625183, disc_loss = 0.01267835437161848
Trained batch 625 in epoch 15, gen_loss = 0.43910922686132, disc_loss = 0.012660567922359213
Trained batch 626 in epoch 15, gen_loss = 0.4390622723901101, disc_loss = 0.012642788308902095
Trained batch 627 in epoch 15, gen_loss = 0.43911433945985356, disc_loss = 0.01263680652695616
Trained batch 628 in epoch 15, gen_loss = 0.43903725349088163, disc_loss = 0.012623563881453411
Trained batch 629 in epoch 15, gen_loss = 0.4390127722233061, disc_loss = 0.012606121045223156
Trained batch 630 in epoch 15, gen_loss = 0.4390112555537095, disc_loss = 0.012589117144872826
Trained batch 631 in epoch 15, gen_loss = 0.43907458311583425, disc_loss = 0.012578759911522429
Trained batch 632 in epoch 15, gen_loss = 0.4392474332786096, disc_loss = 0.012563476952415924
Trained batch 633 in epoch 15, gen_loss = 0.4392162553895535, disc_loss = 0.012546304653656496
Trained batch 634 in epoch 15, gen_loss = 0.4392386655169209, disc_loss = 0.012531403743196279
Trained batch 635 in epoch 15, gen_loss = 0.4392539129223464, disc_loss = 0.012513899817567103
Trained batch 636 in epoch 15, gen_loss = 0.43922577847491256, disc_loss = 0.012498505011744054
Trained batch 637 in epoch 15, gen_loss = 0.4391944017903558, disc_loss = 0.01248382587125598
Trained batch 638 in epoch 15, gen_loss = 0.43935108931038486, disc_loss = 0.012466900479773581
Trained batch 639 in epoch 15, gen_loss = 0.439337267447263, disc_loss = 0.012454748959044082
Trained batch 640 in epoch 15, gen_loss = 0.43940441359223886, disc_loss = 0.012441334719918581
Trained batch 641 in epoch 15, gen_loss = 0.43933823365845787, disc_loss = 0.01242765185205234
Trained batch 642 in epoch 15, gen_loss = 0.43932238962750414, disc_loss = 0.012414194265736084
Trained batch 643 in epoch 15, gen_loss = 0.43919642061365316, disc_loss = 0.012397569873835168
Trained batch 644 in epoch 15, gen_loss = 0.43924711577652037, disc_loss = 0.012382532921421175
Trained batch 645 in epoch 15, gen_loss = 0.4392250803509733, disc_loss = 0.012365173791292277
Trained batch 646 in epoch 15, gen_loss = 0.43920149178556533, disc_loss = 0.012351744355460402
Trained batch 647 in epoch 15, gen_loss = 0.4392333041738581, disc_loss = 0.01233499252083237
Trained batch 648 in epoch 15, gen_loss = 0.43920865012060145, disc_loss = 0.012318422152995862
Trained batch 649 in epoch 15, gen_loss = 0.4392186525693307, disc_loss = 0.012303144799706598
Trained batch 650 in epoch 15, gen_loss = 0.43922075972579044, disc_loss = 0.01228618813947218
Trained batch 651 in epoch 15, gen_loss = 0.4392016045977733, disc_loss = 0.012270054594342928
Trained batch 652 in epoch 15, gen_loss = 0.43914083308136664, disc_loss = 0.012255011827475997
Trained batch 653 in epoch 15, gen_loss = 0.4390121089573665, disc_loss = 0.012245291378438068
Trained batch 654 in epoch 15, gen_loss = 0.43897969941146503, disc_loss = 0.012229043430247067
Trained batch 655 in epoch 15, gen_loss = 0.4388804034125514, disc_loss = 0.01221367559992359
Trained batch 656 in epoch 15, gen_loss = 0.43885105508103217, disc_loss = 0.012196851953353075
Trained batch 657 in epoch 15, gen_loss = 0.43874260647318647, disc_loss = 0.012180100337975152
Trained batch 658 in epoch 15, gen_loss = 0.438819991755377, disc_loss = 0.012164015114029703
Trained batch 659 in epoch 15, gen_loss = 0.43886026306585835, disc_loss = 0.01215144532378128
Trained batch 660 in epoch 15, gen_loss = 0.438807766439334, disc_loss = 0.012135792201939328
Trained batch 661 in epoch 15, gen_loss = 0.43879153451170444, disc_loss = 0.012121905631008009
Trained batch 662 in epoch 15, gen_loss = 0.43882185814067787, disc_loss = 0.012111699546362115
Trained batch 663 in epoch 15, gen_loss = 0.4388390220252864, disc_loss = 0.012095253190417713
Trained batch 664 in epoch 15, gen_loss = 0.43875146615774113, disc_loss = 0.012079803318685075
Trained batch 665 in epoch 15, gen_loss = 0.43869115573328893, disc_loss = 0.012065965806112371
Trained batch 666 in epoch 15, gen_loss = 0.4387189693626078, disc_loss = 0.012058158707508267
Trained batch 667 in epoch 15, gen_loss = 0.43876984858227347, disc_loss = 0.012043806547971726
Trained batch 668 in epoch 15, gen_loss = 0.43879059175382995, disc_loss = 0.012030000288978425
Trained batch 669 in epoch 15, gen_loss = 0.4387942241198981, disc_loss = 0.012014969925608125
Trained batch 670 in epoch 15, gen_loss = 0.4388538651423731, disc_loss = 0.012000084704155277
Trained batch 671 in epoch 15, gen_loss = 0.4387723919713781, disc_loss = 0.011988147157136978
Trained batch 672 in epoch 15, gen_loss = 0.43869607852436987, disc_loss = 0.011972811112244701
Trained batch 673 in epoch 15, gen_loss = 0.438766521852165, disc_loss = 0.011958043235481941
Trained batch 674 in epoch 15, gen_loss = 0.43873685585127936, disc_loss = 0.011952506534979437
Trained batch 675 in epoch 15, gen_loss = 0.4386762868194185, disc_loss = 0.012041287242587155
Trained batch 676 in epoch 15, gen_loss = 0.43837101376743404, disc_loss = 0.012370881710584623
Trained batch 677 in epoch 15, gen_loss = 0.43838618322108, disc_loss = 0.012432700522456203
Trained batch 678 in epoch 15, gen_loss = 0.43841157596838143, disc_loss = 0.012489107948441925
Trained batch 679 in epoch 15, gen_loss = 0.4382863731506993, disc_loss = 0.01259007692715386
Trained batch 680 in epoch 15, gen_loss = 0.4382060274328604, disc_loss = 0.012665905878334148
Trained batch 681 in epoch 15, gen_loss = 0.4382053765296237, disc_loss = 0.012821714166511544
Trained batch 682 in epoch 15, gen_loss = 0.4380302210590675, disc_loss = 0.013014220878823441
Trained batch 683 in epoch 15, gen_loss = 0.4381906616321781, disc_loss = 0.013370083056186729
Trained batch 684 in epoch 15, gen_loss = 0.43809521502821985, disc_loss = 0.013553536448875837
Trained batch 685 in epoch 15, gen_loss = 0.4379663317961178, disc_loss = 0.013665233936337971
Trained batch 686 in epoch 15, gen_loss = 0.43805032300463237, disc_loss = 0.013858606601747368
Trained batch 687 in epoch 15, gen_loss = 0.43800425832701284, disc_loss = 0.013905896539315933
Trained batch 688 in epoch 15, gen_loss = 0.4380254075039281, disc_loss = 0.013900262850498259
Trained batch 689 in epoch 15, gen_loss = 0.437940263359443, disc_loss = 0.013965207426825646
Trained batch 690 in epoch 15, gen_loss = 0.4378952603091724, disc_loss = 0.014187467061525667
Trained batch 691 in epoch 15, gen_loss = 0.43774948376796147, disc_loss = 0.014234757074508197
Trained batch 692 in epoch 15, gen_loss = 0.4377300164314232, disc_loss = 0.014595916359749196
Trained batch 693 in epoch 15, gen_loss = 0.4377919153366721, disc_loss = 0.014714700056549285
Trained batch 694 in epoch 15, gen_loss = 0.4377468754490502, disc_loss = 0.014772448047623708
Trained batch 695 in epoch 15, gen_loss = 0.4377471678729715, disc_loss = 0.01476861667712607
Trained batch 696 in epoch 15, gen_loss = 0.4377325994297969, disc_loss = 0.014784077875308794
Trained batch 697 in epoch 15, gen_loss = 0.4376889724700704, disc_loss = 0.014795721271812494
Trained batch 698 in epoch 15, gen_loss = 0.4377746381217318, disc_loss = 0.014817949992758442
Trained batch 699 in epoch 15, gen_loss = 0.4377670548643385, disc_loss = 0.014812695693440868
Trained batch 700 in epoch 15, gen_loss = 0.43775705557406885, disc_loss = 0.014878947107860694
Trained batch 701 in epoch 15, gen_loss = 0.43788549053533127, disc_loss = 0.01488368703854042
Trained batch 702 in epoch 15, gen_loss = 0.43790937436593547, disc_loss = 0.014878831320998006
Trained batch 703 in epoch 15, gen_loss = 0.43787292831323366, disc_loss = 0.01487588800103946
Trained batch 704 in epoch 15, gen_loss = 0.43786046885429547, disc_loss = 0.014862928947133296
Trained batch 705 in epoch 15, gen_loss = 0.43791290547793715, disc_loss = 0.014857379062099265
Trained batch 706 in epoch 15, gen_loss = 0.4379139273642145, disc_loss = 0.014845138741805333
Trained batch 707 in epoch 15, gen_loss = 0.43781759232114265, disc_loss = 0.014978887831037837
Trained batch 708 in epoch 15, gen_loss = 0.43763470901925067, disc_loss = 0.015064174666089808
Trained batch 709 in epoch 15, gen_loss = 0.4375185660073455, disc_loss = 0.015278126784144494
Trained batch 710 in epoch 15, gen_loss = 0.43758900553700625, disc_loss = 0.015515081303566824
Trained batch 711 in epoch 15, gen_loss = 0.4376541795522979, disc_loss = 0.01566825717305987
Trained batch 712 in epoch 15, gen_loss = 0.4377648573771098, disc_loss = 0.015724038417293685
Trained batch 713 in epoch 15, gen_loss = 0.437725796836431, disc_loss = 0.015979295676780855
Trained batch 714 in epoch 15, gen_loss = 0.4377199739426166, disc_loss = 0.016024517509646688
Trained batch 715 in epoch 15, gen_loss = 0.43761654114923, disc_loss = 0.01615834410646059
Trained batch 716 in epoch 15, gen_loss = 0.4376513839931834, disc_loss = 0.016152554980821444
Trained batch 717 in epoch 15, gen_loss = 0.4376678256354292, disc_loss = 0.016245083095493513
Trained batch 718 in epoch 15, gen_loss = 0.43764397443915937, disc_loss = 0.016234966050085425
Trained batch 719 in epoch 15, gen_loss = 0.4378015557510985, disc_loss = 0.0163129698492412
Trained batch 720 in epoch 15, gen_loss = 0.4377376397092531, disc_loss = 0.016329670410901023
Trained batch 721 in epoch 15, gen_loss = 0.43766041223857544, disc_loss = 0.01639462148435633
Trained batch 722 in epoch 15, gen_loss = 0.4377362584672034, disc_loss = 0.01639923502095005
Trained batch 723 in epoch 15, gen_loss = 0.43775076801934953, disc_loss = 0.01645972627385208
Trained batch 724 in epoch 15, gen_loss = 0.4377144044843213, disc_loss = 0.016527442668227414
Trained batch 725 in epoch 15, gen_loss = 0.4377038981303696, disc_loss = 0.016547910266920807
Trained batch 726 in epoch 15, gen_loss = 0.4376959719143019, disc_loss = 0.016593776195629677
Trained batch 727 in epoch 15, gen_loss = 0.4375763334907018, disc_loss = 0.01683020355651004
Trained batch 728 in epoch 15, gen_loss = 0.43761587576284006, disc_loss = 0.017137283991478684
Trained batch 729 in epoch 15, gen_loss = 0.437495760272627, disc_loss = 0.017230032836740888
Trained batch 730 in epoch 15, gen_loss = 0.43743884322907467, disc_loss = 0.01727050941167705
Trained batch 731 in epoch 15, gen_loss = 0.4373328800165588, disc_loss = 0.01748079481692743
Trained batch 732 in epoch 15, gen_loss = 0.4373040629034966, disc_loss = 0.017622662180323805
Trained batch 733 in epoch 15, gen_loss = 0.43725993193949925, disc_loss = 0.017637240018505904
Trained batch 734 in epoch 15, gen_loss = 0.4373425374631168, disc_loss = 0.018292985441635178
Trained batch 735 in epoch 15, gen_loss = 0.4373335595769079, disc_loss = 0.01838827502741997
Trained batch 736 in epoch 15, gen_loss = 0.4372996410084547, disc_loss = 0.018887471281996016
Trained batch 737 in epoch 15, gen_loss = 0.437192262713179, disc_loss = 0.0189245023587523
Trained batch 738 in epoch 15, gen_loss = 0.4372103832490712, disc_loss = 0.019137290560407878
Trained batch 739 in epoch 15, gen_loss = 0.4370750902069582, disc_loss = 0.019292894167577016
Trained batch 740 in epoch 15, gen_loss = 0.4369711605241263, disc_loss = 0.019418386132352673
Trained batch 741 in epoch 15, gen_loss = 0.4370312119992274, disc_loss = 0.019504504203699112
Trained batch 742 in epoch 15, gen_loss = 0.4370571960109721, disc_loss = 0.01966836811947382
Trained batch 743 in epoch 15, gen_loss = 0.43706646309264247, disc_loss = 0.01979630147127287
Trained batch 744 in epoch 15, gen_loss = 0.43700165492576243, disc_loss = 0.019816053784436752
Trained batch 745 in epoch 15, gen_loss = 0.43697892880471717, disc_loss = 0.01984324744765537
Testing Epoch 15
Training Epoch 16
Trained batch 0 in epoch 16, gen_loss = 0.4547567367553711, disc_loss = 0.1121903657913208
Trained batch 1 in epoch 16, gen_loss = 0.41067543625831604, disc_loss = 0.17504238337278366
Trained batch 2 in epoch 16, gen_loss = 0.43032071987787884, disc_loss = 0.12403116623560588
Trained batch 3 in epoch 16, gen_loss = 0.44477710127830505, disc_loss = 0.10013577062636614
Trained batch 4 in epoch 16, gen_loss = 0.440732741355896, disc_loss = 0.08745201528072358
Trained batch 5 in epoch 16, gen_loss = 0.44883788625399273, disc_loss = 0.0768824393550555
Trained batch 6 in epoch 16, gen_loss = 0.44074299931526184, disc_loss = 0.07866196015051433
Trained batch 7 in epoch 16, gen_loss = 0.44745712354779243, disc_loss = 0.07474713306874037
Trained batch 8 in epoch 16, gen_loss = 0.4496118326981862, disc_loss = 0.07352018439107472
Trained batch 9 in epoch 16, gen_loss = 0.4446654230356216, disc_loss = 0.08105650022625924
Trained batch 10 in epoch 16, gen_loss = 0.44382585178722034, disc_loss = 0.0751054435968399
Trained batch 11 in epoch 16, gen_loss = 0.44919706384340924, disc_loss = 0.07247985899448395
Trained batch 12 in epoch 16, gen_loss = 0.4506331452956566, disc_loss = 0.06807771360931489
Trained batch 13 in epoch 16, gen_loss = 0.45254987478256226, disc_loss = 0.06395298754796386
Trained batch 14 in epoch 16, gen_loss = 0.45179816484451296, disc_loss = 0.0612768167629838
Trained batch 15 in epoch 16, gen_loss = 0.4476860910654068, disc_loss = 0.05870834499364719
Trained batch 16 in epoch 16, gen_loss = 0.4484102568205665, disc_loss = 0.06107570970540538
Trained batch 17 in epoch 16, gen_loss = 0.4485069231854545, disc_loss = 0.06274180895545417
Trained batch 18 in epoch 16, gen_loss = 0.44765423787267583, disc_loss = 0.06203210172488501
Trained batch 19 in epoch 16, gen_loss = 0.44745523780584334, disc_loss = 0.059525408688932656
Trained batch 20 in epoch 16, gen_loss = 0.4461657873221806, disc_loss = 0.06488703980687119
Trained batch 21 in epoch 16, gen_loss = 0.4441545605659485, disc_loss = 0.06686472054570913
Trained batch 22 in epoch 16, gen_loss = 0.4446877746478371, disc_loss = 0.06482442144466483
Trained batch 23 in epoch 16, gen_loss = 0.4445389087001483, disc_loss = 0.06383061812569697
Trained batch 24 in epoch 16, gen_loss = 0.44790263414382936, disc_loss = 0.08580921798944473
Trained batch 25 in epoch 16, gen_loss = 0.4446380241559102, disc_loss = 0.08772223299512497
Trained batch 26 in epoch 16, gen_loss = 0.44185952676667106, disc_loss = 0.08635845062909303
Trained batch 27 in epoch 16, gen_loss = 0.4433527982660702, disc_loss = 0.08558672081146922
Trained batch 28 in epoch 16, gen_loss = 0.441846351171362, disc_loss = 0.08377134581578188
Trained batch 29 in epoch 16, gen_loss = 0.4433032989501953, disc_loss = 0.08438014996548494
Trained batch 30 in epoch 16, gen_loss = 0.44078873049828315, disc_loss = 0.08259219243641823
Trained batch 31 in epoch 16, gen_loss = 0.43781915307044983, disc_loss = 0.08272981131449342
Trained batch 32 in epoch 16, gen_loss = 0.4375607597105431, disc_loss = 0.08062720535831018
Trained batch 33 in epoch 16, gen_loss = 0.43938471552203684, disc_loss = 0.0977692819912644
Trained batch 34 in epoch 16, gen_loss = 0.4383392972605569, disc_loss = 0.0994537920824119
Trained batch 35 in epoch 16, gen_loss = 0.43904662546184325, disc_loss = 0.10084989511718352
Trained batch 36 in epoch 16, gen_loss = 0.43844425597706355, disc_loss = 0.10293798158700401
Trained batch 37 in epoch 16, gen_loss = 0.43675774335861206, disc_loss = 0.10140127247493518
Trained batch 38 in epoch 16, gen_loss = 0.4360187672651731, disc_loss = 0.09952018758616386
Trained batch 39 in epoch 16, gen_loss = 0.4352006308734417, disc_loss = 0.09776523080654442
Trained batch 40 in epoch 16, gen_loss = 0.4340162269952821, disc_loss = 0.09556282484313337
Trained batch 41 in epoch 16, gen_loss = 0.43375118218717124, disc_loss = 0.0934358786658517
Trained batch 42 in epoch 16, gen_loss = 0.4334878817547199, disc_loss = 0.09148612408357304
Trained batch 43 in epoch 16, gen_loss = 0.43307151239026676, disc_loss = 0.0895351332781667
Trained batch 44 in epoch 16, gen_loss = 0.43235726290278964, disc_loss = 0.08763395179477003
Trained batch 45 in epoch 16, gen_loss = 0.43166830034359643, disc_loss = 0.08577993342592179
Trained batch 46 in epoch 16, gen_loss = 0.4323713132675658, disc_loss = 0.08427506150737246
Trained batch 47 in epoch 16, gen_loss = 0.4310214004168908, disc_loss = 0.0835989449454549
Trained batch 48 in epoch 16, gen_loss = 0.4307037871711108, disc_loss = 0.08219289415211854
Trained batch 49 in epoch 16, gen_loss = 0.4306163144111633, disc_loss = 0.08071204688865691
Trained batch 50 in epoch 16, gen_loss = 0.43117308908817814, disc_loss = 0.08039249374312074
Trained batch 51 in epoch 16, gen_loss = 0.43145165821680653, disc_loss = 0.0789829890575045
Trained batch 52 in epoch 16, gen_loss = 0.4303065127921554, disc_loss = 0.07891205540541911
Trained batch 53 in epoch 16, gen_loss = 0.42943104604880017, disc_loss = 0.08266164166249197
Trained batch 54 in epoch 16, gen_loss = 0.43052454482425345, disc_loss = 0.08400964571417055
Trained batch 55 in epoch 16, gen_loss = 0.4296299357499395, disc_loss = 0.08313620566540132
Trained batch 56 in epoch 16, gen_loss = 0.4305300158366822, disc_loss = 0.08247982668526993
Trained batch 57 in epoch 16, gen_loss = 0.4291271397779728, disc_loss = 0.08155573114897285
Trained batch 58 in epoch 16, gen_loss = 0.4279728511632499, disc_loss = 0.0842926800921875
Trained batch 59 in epoch 16, gen_loss = 0.42807660847902296, disc_loss = 0.08348479240279023
Trained batch 60 in epoch 16, gen_loss = 0.4278192564112241, disc_loss = 0.08337421123259013
Trained batch 61 in epoch 16, gen_loss = 0.428616147368185, disc_loss = 0.08423660161168946
Trained batch 62 in epoch 16, gen_loss = 0.427707771933268, disc_loss = 0.08325161347683105
Trained batch 63 in epoch 16, gen_loss = 0.4271698291413486, disc_loss = 0.08391812933041365
Trained batch 64 in epoch 16, gen_loss = 0.42602979082327624, disc_loss = 0.08402593583226776
Trained batch 65 in epoch 16, gen_loss = 0.4273739271994793, disc_loss = 0.08736627650884629
Trained batch 66 in epoch 16, gen_loss = 0.4274660415613829, disc_loss = 0.0862035303786675
Trained batch 67 in epoch 16, gen_loss = 0.426939981386942, disc_loss = 0.08641908564673298
Trained batch 68 in epoch 16, gen_loss = 0.4262382854586062, disc_loss = 0.08794795457557168
Trained batch 69 in epoch 16, gen_loss = 0.4252846304859434, disc_loss = 0.08757366149885847
Trained batch 70 in epoch 16, gen_loss = 0.42524095236415593, disc_loss = 0.08720090634084608
Trained batch 71 in epoch 16, gen_loss = 0.4252621812952889, disc_loss = 0.08622796404395355
Trained batch 72 in epoch 16, gen_loss = 0.42547108865764044, disc_loss = 0.0863060147520665
Trained batch 73 in epoch 16, gen_loss = 0.4249382417749714, disc_loss = 0.08529111879210718
Trained batch 74 in epoch 16, gen_loss = 0.42527271072069806, disc_loss = 0.08427753960403303
Trained batch 75 in epoch 16, gen_loss = 0.42501080114590495, disc_loss = 0.0834310716538886
Trained batch 76 in epoch 16, gen_loss = 0.4256656080871433, disc_loss = 0.08243545329548999
Trained batch 77 in epoch 16, gen_loss = 0.42593755553930235, disc_loss = 0.08149531682750258
Trained batch 78 in epoch 16, gen_loss = 0.42544284274306476, disc_loss = 0.08052370395758955
Trained batch 79 in epoch 16, gen_loss = 0.4257145024836063, disc_loss = 0.07963446809735615
Trained batch 80 in epoch 16, gen_loss = 0.4254772420282717, disc_loss = 0.078681335384946
Trained batch 81 in epoch 16, gen_loss = 0.4249493174436616, disc_loss = 0.0777651842927742
Trained batch 82 in epoch 16, gen_loss = 0.42546245742993183, disc_loss = 0.07694816980679262
Trained batch 83 in epoch 16, gen_loss = 0.42546624477420536, disc_loss = 0.07616590784718505
Trained batch 84 in epoch 16, gen_loss = 0.42602136520778433, disc_loss = 0.07530865283847293
Trained batch 85 in epoch 16, gen_loss = 0.4252417596966721, disc_loss = 0.07445820971652
Trained batch 86 in epoch 16, gen_loss = 0.425292712861094, disc_loss = 0.07368879368121939
Trained batch 87 in epoch 16, gen_loss = 0.42568376524881885, disc_loss = 0.07288894617919471
Trained batch 88 in epoch 16, gen_loss = 0.4256263365236561, disc_loss = 0.07208567745512708
Trained batch 89 in epoch 16, gen_loss = 0.425288137462404, disc_loss = 0.07130728795503577
Trained batch 90 in epoch 16, gen_loss = 0.425963085431319, disc_loss = 0.07056892674498177
Trained batch 91 in epoch 16, gen_loss = 0.4265079786596091, disc_loss = 0.06982072587023773
Trained batch 92 in epoch 16, gen_loss = 0.42679857855202047, disc_loss = 0.06909060778511908
Trained batch 93 in epoch 16, gen_loss = 0.4256711316869614, disc_loss = 0.06838261688182606
Trained batch 94 in epoch 16, gen_loss = 0.42600655492983364, disc_loss = 0.06767981776501983
Trained batch 95 in epoch 16, gen_loss = 0.42624989959100884, disc_loss = 0.06709641809599513
Trained batch 96 in epoch 16, gen_loss = 0.4263799961694737, disc_loss = 0.06648174823698655
Trained batch 97 in epoch 16, gen_loss = 0.42713751081301243, disc_loss = 0.0658379654811068
Trained batch 98 in epoch 16, gen_loss = 0.4281711719854914, disc_loss = 0.06519458754190403
Trained batch 99 in epoch 16, gen_loss = 0.42764539510011673, disc_loss = 0.06456747806048951
Trained batch 100 in epoch 16, gen_loss = 0.4280339491249311, disc_loss = 0.06395263239478527
Trained batch 101 in epoch 16, gen_loss = 0.42827068532214446, disc_loss = 0.06335514828256861
Trained batch 102 in epoch 16, gen_loss = 0.42898604302730375, disc_loss = 0.06279576017896564
Trained batch 103 in epoch 16, gen_loss = 0.42923856927798343, disc_loss = 0.06221602980804164
Trained batch 104 in epoch 16, gen_loss = 0.42994809718359084, disc_loss = 0.061647323262877765
Trained batch 105 in epoch 16, gen_loss = 0.43018986847040785, disc_loss = 0.061086577953076655
Trained batch 106 in epoch 16, gen_loss = 0.43020497666341123, disc_loss = 0.06054821800305639
Trained batch 107 in epoch 16, gen_loss = 0.43044073245039693, disc_loss = 0.06003642785125757
Trained batch 108 in epoch 16, gen_loss = 0.4310961800430893, disc_loss = 0.059546902930628885
Trained batch 109 in epoch 16, gen_loss = 0.43073452684012326, disc_loss = 0.05902071858290583
Trained batch 110 in epoch 16, gen_loss = 0.430695192770915, disc_loss = 0.05854364225498258
Trained batch 111 in epoch 16, gen_loss = 0.43018118425139357, disc_loss = 0.05805372304582436
Trained batch 112 in epoch 16, gen_loss = 0.4306998796167627, disc_loss = 0.05756850770790031
Trained batch 113 in epoch 16, gen_loss = 0.43125849831522556, disc_loss = 0.05708217191338343
Trained batch 114 in epoch 16, gen_loss = 0.4309155992839647, disc_loss = 0.05660043049745424
Trained batch 115 in epoch 16, gen_loss = 0.43123115599155426, disc_loss = 0.05612610938159974
Trained batch 116 in epoch 16, gen_loss = 0.43117173003335285, disc_loss = 0.05569875024708831
Trained batch 117 in epoch 16, gen_loss = 0.4315671976340019, disc_loss = 0.05524853108573105
Trained batch 118 in epoch 16, gen_loss = 0.43128410958442365, disc_loss = 0.054816978992385586
Trained batch 119 in epoch 16, gen_loss = 0.4315482959151268, disc_loss = 0.054414290373097175
Trained batch 120 in epoch 16, gen_loss = 0.431744477965615, disc_loss = 0.05400695707668235
Trained batch 121 in epoch 16, gen_loss = 0.43202433967199483, disc_loss = 0.053605241644707674
Trained batch 122 in epoch 16, gen_loss = 0.43228978790887973, disc_loss = 0.05320281874695111
Trained batch 123 in epoch 16, gen_loss = 0.43301575654937374, disc_loss = 0.052811339889059686
Trained batch 124 in epoch 16, gen_loss = 0.4329018030166626, disc_loss = 0.05240424594655633
Trained batch 125 in epoch 16, gen_loss = 0.4329587005906635, disc_loss = 0.05200083238453353
Trained batch 126 in epoch 16, gen_loss = 0.43309166135750415, disc_loss = 0.051603990798544754
Trained batch 127 in epoch 16, gen_loss = 0.43293879088014364, disc_loss = 0.05120985879420914
Trained batch 128 in epoch 16, gen_loss = 0.4330445724402287, disc_loss = 0.05082183393068583
Trained batch 129 in epoch 16, gen_loss = 0.43300361931324005, disc_loss = 0.0504392006353905
Trained batch 130 in epoch 16, gen_loss = 0.43283679580870477, disc_loss = 0.050063609259331045
Trained batch 131 in epoch 16, gen_loss = 0.43273229468049423, disc_loss = 0.04972418292185687
Trained batch 132 in epoch 16, gen_loss = 0.43262548688659097, disc_loss = 0.04935888243888162
Trained batch 133 in epoch 16, gen_loss = 0.4324884325710695, disc_loss = 0.04901535882190593
Trained batch 134 in epoch 16, gen_loss = 0.43300107143543387, disc_loss = 0.048697530124681414
Trained batch 135 in epoch 16, gen_loss = 0.4327322926153155, disc_loss = 0.04835062974940657
Trained batch 136 in epoch 16, gen_loss = 0.4326716080634263, disc_loss = 0.04803544267617764
Trained batch 137 in epoch 16, gen_loss = 0.4328610313975293, disc_loss = 0.047702879894632795
Trained batch 138 in epoch 16, gen_loss = 0.4335657396762491, disc_loss = 0.04736748866053472
Trained batch 139 in epoch 16, gen_loss = 0.43376664625746864, disc_loss = 0.047389043870914194
Trained batch 140 in epoch 16, gen_loss = 0.4336221340700244, disc_loss = 0.04710309731886319
Trained batch 141 in epoch 16, gen_loss = 0.43350319501379847, disc_loss = 0.046793637764443397
Trained batch 142 in epoch 16, gen_loss = 0.4338315917061759, disc_loss = 0.046512677946447076
Trained batch 143 in epoch 16, gen_loss = 0.4336877237591479, disc_loss = 0.046203878595002204
Trained batch 144 in epoch 16, gen_loss = 0.43435985548742884, disc_loss = 0.045902433973769176
Trained batch 145 in epoch 16, gen_loss = 0.4345704776375261, disc_loss = 0.045637004512795946
Trained batch 146 in epoch 16, gen_loss = 0.43413518582071575, disc_loss = 0.045339412634026535
Trained batch 147 in epoch 16, gen_loss = 0.4338878326722094, disc_loss = 0.04505157013222374
Trained batch 148 in epoch 16, gen_loss = 0.4338620071043104, disc_loss = 0.04476716141872758
Trained batch 149 in epoch 16, gen_loss = 0.4336989331245422, disc_loss = 0.0444827458417664
Trained batch 150 in epoch 16, gen_loss = 0.43364288554286323, disc_loss = 0.044199837615331077
Trained batch 151 in epoch 16, gen_loss = 0.43349341930527435, disc_loss = 0.043935485677425994
Trained batch 152 in epoch 16, gen_loss = 0.43344199462653765, disc_loss = 0.04366438455873601
Trained batch 153 in epoch 16, gen_loss = 0.43383569376809256, disc_loss = 0.04340630368625915
Trained batch 154 in epoch 16, gen_loss = 0.43384905399814727, disc_loss = 0.0431473828957326
Trained batch 155 in epoch 16, gen_loss = 0.43404267441767913, disc_loss = 0.04289361442743729
Trained batch 156 in epoch 16, gen_loss = 0.43417271971702576, disc_loss = 0.04263321067663325
Trained batch 157 in epoch 16, gen_loss = 0.43426262672188914, disc_loss = 0.042417945870775964
Trained batch 158 in epoch 16, gen_loss = 0.4341243569206142, disc_loss = 0.04229186545565443
Trained batch 159 in epoch 16, gen_loss = 0.43451596815139054, disc_loss = 0.04209599478635937
Trained batch 160 in epoch 16, gen_loss = 0.43429764179709535, disc_loss = 0.04202380490645489
Trained batch 161 in epoch 16, gen_loss = 0.4344573077964194, disc_loss = 0.04250566354366364
Trained batch 162 in epoch 16, gen_loss = 0.43462335423457843, disc_loss = 0.042456659654075385
Trained batch 163 in epoch 16, gen_loss = 0.4348058575173704, disc_loss = 0.04223835844796423
Trained batch 164 in epoch 16, gen_loss = 0.43508841702432344, disc_loss = 0.042107075063342395
Trained batch 165 in epoch 16, gen_loss = 0.43476654858474273, disc_loss = 0.04198942180296563
Trained batch 166 in epoch 16, gen_loss = 0.4351155522340786, disc_loss = 0.04175818688793855
Trained batch 167 in epoch 16, gen_loss = 0.43477793658773106, disc_loss = 0.0415320060717585
Trained batch 168 in epoch 16, gen_loss = 0.4345428742600616, disc_loss = 0.041355160501724955
Trained batch 169 in epoch 16, gen_loss = 0.4349823597599478, disc_loss = 0.041355558508075776
Trained batch 170 in epoch 16, gen_loss = 0.4347277977313215, disc_loss = 0.041260004382613194
Trained batch 171 in epoch 16, gen_loss = 0.4345308893988299, disc_loss = 0.04106290302602141
Trained batch 172 in epoch 16, gen_loss = 0.4346183548772955, disc_loss = 0.04086312109125358
Trained batch 173 in epoch 16, gen_loss = 0.4345659877376995, disc_loss = 0.04098021973529296
Trained batch 174 in epoch 16, gen_loss = 0.4346515875203269, disc_loss = 0.04076675727298217
Trained batch 175 in epoch 16, gen_loss = 0.43480570292608306, disc_loss = 0.0409096150211884
Trained batch 176 in epoch 16, gen_loss = 0.43494393882778404, disc_loss = 0.040818385625952636
Trained batch 177 in epoch 16, gen_loss = 0.43498989805746613, disc_loss = 0.0406311669797647
Trained batch 178 in epoch 16, gen_loss = 0.4353494965497342, disc_loss = 0.04044529682873389
Trained batch 179 in epoch 16, gen_loss = 0.43576061841514374, disc_loss = 0.04024857983588138
Trained batch 180 in epoch 16, gen_loss = 0.43625897383162987, disc_loss = 0.04017529644210983
Trained batch 181 in epoch 16, gen_loss = 0.43606609187938355, disc_loss = 0.0399912975557087
Trained batch 182 in epoch 16, gen_loss = 0.4358133528727651, disc_loss = 0.03980462276885703
Trained batch 183 in epoch 16, gen_loss = 0.4357537964115972, disc_loss = 0.039610209883666474
Trained batch 184 in epoch 16, gen_loss = 0.43573863828504406, disc_loss = 0.03945405018968961
Trained batch 185 in epoch 16, gen_loss = 0.4356557010642944, disc_loss = 0.03930071764250075
Trained batch 186 in epoch 16, gen_loss = 0.43605794195822856, disc_loss = 0.03919706779362803
Trained batch 187 in epoch 16, gen_loss = 0.43601717895015757, disc_loss = 0.03911004640394822
Trained batch 188 in epoch 16, gen_loss = 0.4362654509367766, disc_loss = 0.038952364397811745
Trained batch 189 in epoch 16, gen_loss = 0.43655257115238594, disc_loss = 0.03877292513773826
Trained batch 190 in epoch 16, gen_loss = 0.436866410895792, disc_loss = 0.03861065126141212
Trained batch 191 in epoch 16, gen_loss = 0.4367474790972968, disc_loss = 0.03842440383717379
Trained batch 192 in epoch 16, gen_loss = 0.4366739650155596, disc_loss = 0.03823976666869239
Trained batch 193 in epoch 16, gen_loss = 0.43672874446996707, disc_loss = 0.038052894742727356
Trained batch 194 in epoch 16, gen_loss = 0.4370935158851819, disc_loss = 0.03786929791363386
Trained batch 195 in epoch 16, gen_loss = 0.43725590210179893, disc_loss = 0.0376898919562429
Trained batch 196 in epoch 16, gen_loss = 0.43749829294717857, disc_loss = 0.03753177814426723
Trained batch 197 in epoch 16, gen_loss = 0.4370440967155225, disc_loss = 0.03737575467793516
Trained batch 198 in epoch 16, gen_loss = 0.43732039952397944, disc_loss = 0.03719962545408488
Trained batch 199 in epoch 16, gen_loss = 0.43725663229823114, disc_loss = 0.03701930437237024
Trained batch 200 in epoch 16, gen_loss = 0.43750676972356006, disc_loss = 0.036860102646293774
Trained batch 201 in epoch 16, gen_loss = 0.4374808618927946, disc_loss = 0.0366854496826971
Trained batch 202 in epoch 16, gen_loss = 0.43739603760794465, disc_loss = 0.03651248158604879
Trained batch 203 in epoch 16, gen_loss = 0.43766945994952144, disc_loss = 0.03634085100858618
Trained batch 204 in epoch 16, gen_loss = 0.4377832696205232, disc_loss = 0.036170247580469925
Trained batch 205 in epoch 16, gen_loss = 0.43763555933549564, disc_loss = 0.03600171641322323
Trained batch 206 in epoch 16, gen_loss = 0.4378308345730178, disc_loss = 0.035833531664459455
Trained batch 207 in epoch 16, gen_loss = 0.43780740894950354, disc_loss = 0.03566703410335602
Trained batch 208 in epoch 16, gen_loss = 0.4377789444615396, disc_loss = 0.035502992423349304
Trained batch 209 in epoch 16, gen_loss = 0.4379388763791039, disc_loss = 0.035344029914232945
Trained batch 210 in epoch 16, gen_loss = 0.4381194083611547, disc_loss = 0.03518168659995517
Trained batch 211 in epoch 16, gen_loss = 0.43836265211960057, disc_loss = 0.03502260017448175
Trained batch 212 in epoch 16, gen_loss = 0.4382497065223998, disc_loss = 0.034863309573465215
Trained batch 213 in epoch 16, gen_loss = 0.4382093363554678, disc_loss = 0.034705032522150396
Trained batch 214 in epoch 16, gen_loss = 0.4382685723692872, disc_loss = 0.0345474754655084
Trained batch 215 in epoch 16, gen_loss = 0.43800827474505816, disc_loss = 0.03440148878575268
Trained batch 216 in epoch 16, gen_loss = 0.4378985706287595, disc_loss = 0.03425120201159251
Trained batch 217 in epoch 16, gen_loss = 0.43793192669885966, disc_loss = 0.03410056392702812
Trained batch 218 in epoch 16, gen_loss = 0.4379018673069401, disc_loss = 0.03395021619959883
Trained batch 219 in epoch 16, gen_loss = 0.4380386595021595, disc_loss = 0.03380352468970655
Trained batch 220 in epoch 16, gen_loss = 0.43790425784987025, disc_loss = 0.03365505073004617
Trained batch 221 in epoch 16, gen_loss = 0.4379249291645514, disc_loss = 0.03350900119560695
Trained batch 222 in epoch 16, gen_loss = 0.4378361087208906, disc_loss = 0.0333644762398224
Trained batch 223 in epoch 16, gen_loss = 0.4374626560934952, disc_loss = 0.033227087387786014
Trained batch 224 in epoch 16, gen_loss = 0.4372803905275133, disc_loss = 0.03308512537791911
Trained batch 225 in epoch 16, gen_loss = 0.4374344168247375, disc_loss = 0.03294806321310209
Trained batch 226 in epoch 16, gen_loss = 0.4375244201805098, disc_loss = 0.0328072057780502
Trained batch 227 in epoch 16, gen_loss = 0.4373958084666938, disc_loss = 0.03266715965710638
Trained batch 228 in epoch 16, gen_loss = 0.43780632284530907, disc_loss = 0.032539911471321514
Trained batch 229 in epoch 16, gen_loss = 0.43754910645277606, disc_loss = 0.0324037797918604
Trained batch 230 in epoch 16, gen_loss = 0.4375423857401976, disc_loss = 0.032272451912764524
Trained batch 231 in epoch 16, gen_loss = 0.4373987811649668, disc_loss = 0.03213682455253579
Trained batch 232 in epoch 16, gen_loss = 0.4371015666124647, disc_loss = 0.03200942567048011
Trained batch 233 in epoch 16, gen_loss = 0.43719596778735137, disc_loss = 0.03188498282822995
Trained batch 234 in epoch 16, gen_loss = 0.4370272248349291, disc_loss = 0.031752834725441374
Trained batch 235 in epoch 16, gen_loss = 0.43693361885971943, disc_loss = 0.03162645285685697
Trained batch 236 in epoch 16, gen_loss = 0.43727898434244633, disc_loss = 0.03150042629322304
Trained batch 237 in epoch 16, gen_loss = 0.4371265027703357, disc_loss = 0.031379561882295855
Trained batch 238 in epoch 16, gen_loss = 0.43737871726686484, disc_loss = 0.0312538775661668
Trained batch 239 in epoch 16, gen_loss = 0.43740137678881486, disc_loss = 0.03112934893797501
Trained batch 240 in epoch 16, gen_loss = 0.43743383760768845, disc_loss = 0.03100782011744771
Trained batch 241 in epoch 16, gen_loss = 0.4374684897089793, disc_loss = 0.030888513094516595
Trained batch 242 in epoch 16, gen_loss = 0.4371465366073106, disc_loss = 0.030766643576827974
Trained batch 243 in epoch 16, gen_loss = 0.4374366822789927, disc_loss = 0.030648402749230613
Trained batch 244 in epoch 16, gen_loss = 0.43738638551867737, disc_loss = 0.030529033765909548
Trained batch 245 in epoch 16, gen_loss = 0.43735012315153105, disc_loss = 0.030409019413674857
Trained batch 246 in epoch 16, gen_loss = 0.43721002267922465, disc_loss = 0.03028927780739654
Trained batch 247 in epoch 16, gen_loss = 0.43698472854110504, disc_loss = 0.030171703191186797
Trained batch 248 in epoch 16, gen_loss = 0.4369784485862916, disc_loss = 0.03005560452420541
Trained batch 249 in epoch 16, gen_loss = 0.43675928604602815, disc_loss = 0.029941229325486346
Trained batch 250 in epoch 16, gen_loss = 0.436941780417089, disc_loss = 0.029825576957439506
Trained batch 251 in epoch 16, gen_loss = 0.43675787273853545, disc_loss = 0.029710858535263614
Trained batch 252 in epoch 16, gen_loss = 0.43683412034992175, disc_loss = 0.029613636790916487
Trained batch 253 in epoch 16, gen_loss = 0.43670647914015404, disc_loss = 0.029500211961429903
Trained batch 254 in epoch 16, gen_loss = 0.436648899083044, disc_loss = 0.02938846221819118
Trained batch 255 in epoch 16, gen_loss = 0.4363301951671019, disc_loss = 0.029276532508220043
Trained batch 256 in epoch 16, gen_loss = 0.43644699802194586, disc_loss = 0.029166739084078398
Trained batch 257 in epoch 16, gen_loss = 0.4365195577689844, disc_loss = 0.02905804265896039
Trained batch 258 in epoch 16, gen_loss = 0.4368229682150955, disc_loss = 0.02895140620672169
Trained batch 259 in epoch 16, gen_loss = 0.4368505222293047, disc_loss = 0.028843540734333845
Trained batch 260 in epoch 16, gen_loss = 0.4368897097549219, disc_loss = 0.028738839559612074
Trained batch 261 in epoch 16, gen_loss = 0.436669506075728, disc_loss = 0.028632191257535317
Trained batch 262 in epoch 16, gen_loss = 0.43660276142363313, disc_loss = 0.028527062359051742
Trained batch 263 in epoch 16, gen_loss = 0.43653996943524387, disc_loss = 0.028422871915664116
Trained batch 264 in epoch 16, gen_loss = 0.43657978188316776, disc_loss = 0.02831950573237472
Trained batch 265 in epoch 16, gen_loss = 0.43643269615065783, disc_loss = 0.028219664489712103
Trained batch 266 in epoch 16, gen_loss = 0.43624126777220307, disc_loss = 0.028119064201487486
Trained batch 267 in epoch 16, gen_loss = 0.43617948322598615, disc_loss = 0.028019187689381792
Trained batch 268 in epoch 16, gen_loss = 0.4359750551583599, disc_loss = 0.027920963722376367
Trained batch 269 in epoch 16, gen_loss = 0.43625753223896024, disc_loss = 0.027823576510720024
Trained batch 270 in epoch 16, gen_loss = 0.4361581712191395, disc_loss = 0.027728340183204293
Trained batch 271 in epoch 16, gen_loss = 0.4363572620512808, disc_loss = 0.02763172537957229
Trained batch 272 in epoch 16, gen_loss = 0.4362849929393866, disc_loss = 0.027535687299443567
Trained batch 273 in epoch 16, gen_loss = 0.436179890902373, disc_loss = 0.02744476890754818
Trained batch 274 in epoch 16, gen_loss = 0.43647723761471835, disc_loss = 0.027351274596823547
Trained batch 275 in epoch 16, gen_loss = 0.436606694822726, disc_loss = 0.02725876528542806
Trained batch 276 in epoch 16, gen_loss = 0.43659550801511277, disc_loss = 0.027170338352515096
Trained batch 277 in epoch 16, gen_loss = 0.4367018167277892, disc_loss = 0.02707662397100282
Trained batch 278 in epoch 16, gen_loss = 0.436876898063981, disc_loss = 0.026985225244967673
Trained batch 279 in epoch 16, gen_loss = 0.43688676399844034, disc_loss = 0.026893414599596457
Trained batch 280 in epoch 16, gen_loss = 0.43676580504590506, disc_loss = 0.02680843524585952
Trained batch 281 in epoch 16, gen_loss = 0.43684006561624245, disc_loss = 0.026717444308183045
Trained batch 282 in epoch 16, gen_loss = 0.4368377103611774, disc_loss = 0.02662746430034897
Trained batch 283 in epoch 16, gen_loss = 0.4367757728192168, disc_loss = 0.026539338294139566
Trained batch 284 in epoch 16, gen_loss = 0.43684776467189457, disc_loss = 0.026451556182981124
Trained batch 285 in epoch 16, gen_loss = 0.4366495224770966, disc_loss = 0.026363150882770768
Trained batch 286 in epoch 16, gen_loss = 0.43655182229101863, disc_loss = 0.026273685276673828
Trained batch 287 in epoch 16, gen_loss = 0.436668808468514, disc_loss = 0.026185042727269722
Trained batch 288 in epoch 16, gen_loss = 0.4368617294362672, disc_loss = 0.026097801389498153
Trained batch 289 in epoch 16, gen_loss = 0.436655376902942, disc_loss = 0.02601190705920152
Trained batch 290 in epoch 16, gen_loss = 0.43644160687718603, disc_loss = 0.02592539308729495
Trained batch 291 in epoch 16, gen_loss = 0.4364503106638177, disc_loss = 0.02584500706093609
Trained batch 292 in epoch 16, gen_loss = 0.43648984102665767, disc_loss = 0.0257609974723643
Trained batch 293 in epoch 16, gen_loss = 0.43652196826578, disc_loss = 0.025687239002349285
Trained batch 294 in epoch 16, gen_loss = 0.4364565449245906, disc_loss = 0.025603028426688733
Trained batch 295 in epoch 16, gen_loss = 0.4365756970805091, disc_loss = 0.025527757281402906
Trained batch 296 in epoch 16, gen_loss = 0.43671071168148157, disc_loss = 0.025447313344538813
Trained batch 297 in epoch 16, gen_loss = 0.4367327757129733, disc_loss = 0.025367314517873045
Trained batch 298 in epoch 16, gen_loss = 0.43674608855741875, disc_loss = 0.025286286240786215
Trained batch 299 in epoch 16, gen_loss = 0.43662811517715455, disc_loss = 0.025208031521566834
Trained batch 300 in epoch 16, gen_loss = 0.4365578929451217, disc_loss = 0.025129115470821205
Trained batch 301 in epoch 16, gen_loss = 0.43667974100997115, disc_loss = 0.02505164305233884
Trained batch 302 in epoch 16, gen_loss = 0.4364886814021435, disc_loss = 0.02497150708664602
Trained batch 303 in epoch 16, gen_loss = 0.4363788983931667, disc_loss = 0.024894348178732845
Trained batch 304 in epoch 16, gen_loss = 0.4364751426900019, disc_loss = 0.024820471410715923
Trained batch 305 in epoch 16, gen_loss = 0.43633003133574344, disc_loss = 0.024748120559653378
Trained batch 306 in epoch 16, gen_loss = 0.4363119252729882, disc_loss = 0.02467097183052414
Trained batch 307 in epoch 16, gen_loss = 0.4362318789610615, disc_loss = 0.024595069675555137
Trained batch 308 in epoch 16, gen_loss = 0.43634939753121926, disc_loss = 0.02451966176770965
Trained batch 309 in epoch 16, gen_loss = 0.4363613555508275, disc_loss = 0.024443481212496877
Trained batch 310 in epoch 16, gen_loss = 0.43642730919877815, disc_loss = 0.024367167967015286
Trained batch 311 in epoch 16, gen_loss = 0.4364049358245654, disc_loss = 0.024300486898610894
Trained batch 312 in epoch 16, gen_loss = 0.436424133781427, disc_loss = 0.0242266797999176
Trained batch 313 in epoch 16, gen_loss = 0.4367247490556377, disc_loss = 0.024158901326613393
Trained batch 314 in epoch 16, gen_loss = 0.4366009834266844, disc_loss = 0.02408982931621491
Trained batch 315 in epoch 16, gen_loss = 0.43685479471577876, disc_loss = 0.024022030535808328
Trained batch 316 in epoch 16, gen_loss = 0.4371076078633029, disc_loss = 0.023949889248759966
Trained batch 317 in epoch 16, gen_loss = 0.43703020743603976, disc_loss = 0.023878940239068377
Trained batch 318 in epoch 16, gen_loss = 0.43716717121369414, disc_loss = 0.023808969403719266
Trained batch 319 in epoch 16, gen_loss = 0.4373758317902684, disc_loss = 0.02375275161175523
Trained batch 320 in epoch 16, gen_loss = 0.43750744073933157, disc_loss = 0.02373042857895295
Trained batch 321 in epoch 16, gen_loss = 0.43751578153290366, disc_loss = 0.02367164696109776
Trained batch 322 in epoch 16, gen_loss = 0.4373289898453113, disc_loss = 0.023606219444994817
Trained batch 323 in epoch 16, gen_loss = 0.43737812781775437, disc_loss = 0.023551295319554844
Trained batch 324 in epoch 16, gen_loss = 0.4376544901040884, disc_loss = 0.02348533004952165
Trained batch 325 in epoch 16, gen_loss = 0.4376969368545556, disc_loss = 0.023427994494709226
Trained batch 326 in epoch 16, gen_loss = 0.4378369985552738, disc_loss = 0.023377546862576624
Trained batch 327 in epoch 16, gen_loss = 0.4379791094944244, disc_loss = 0.023322350735969204
Trained batch 328 in epoch 16, gen_loss = 0.4379585509423427, disc_loss = 0.023264282524563078
Trained batch 329 in epoch 16, gen_loss = 0.437772210077806, disc_loss = 0.023202259839286633
Trained batch 330 in epoch 16, gen_loss = 0.43774909195222883, disc_loss = 0.02315295634023125
Trained batch 331 in epoch 16, gen_loss = 0.4376908234623541, disc_loss = 0.02308866508615046
Trained batch 332 in epoch 16, gen_loss = 0.4378506252178559, disc_loss = 0.02422036549570067
Trained batch 333 in epoch 16, gen_loss = 0.4375398819318075, disc_loss = 0.02480684538841705
Trained batch 334 in epoch 16, gen_loss = 0.4373529437762588, disc_loss = 0.024902293565961072
Trained batch 335 in epoch 16, gen_loss = 0.43708714966972667, disc_loss = 0.025094522708275776
Trained batch 336 in epoch 16, gen_loss = 0.43718216795949627, disc_loss = 0.025086903609183427
Trained batch 337 in epoch 16, gen_loss = 0.43717574773455514, disc_loss = 0.025063249146491398
Trained batch 338 in epoch 16, gen_loss = 0.4371161838020899, disc_loss = 0.02501848503943137
Trained batch 339 in epoch 16, gen_loss = 0.4371630321530735, disc_loss = 0.02496238220243386
Trained batch 340 in epoch 16, gen_loss = 0.4371657736839787, disc_loss = 0.024900934842273133
Trained batch 341 in epoch 16, gen_loss = 0.43723457964540224, disc_loss = 0.02485237182397123
Trained batch 342 in epoch 16, gen_loss = 0.43706959095015124, disc_loss = 0.02480125803746142
Trained batch 343 in epoch 16, gen_loss = 0.43714957562989964, disc_loss = 0.02476130539536487
Trained batch 344 in epoch 16, gen_loss = 0.4370219848294189, disc_loss = 0.024863292308240807
Trained batch 345 in epoch 16, gen_loss = 0.43698504592986465, disc_loss = 0.02496710356030172
Trained batch 346 in epoch 16, gen_loss = 0.437100154522173, disc_loss = 0.0249602232300824
Trained batch 347 in epoch 16, gen_loss = 0.4368075653054248, disc_loss = 0.025042760977053203
Trained batch 348 in epoch 16, gen_loss = 0.4366194022589905, disc_loss = 0.025071672891416083
Trained batch 349 in epoch 16, gen_loss = 0.4366171079022544, disc_loss = 0.025069743367244622
Trained batch 350 in epoch 16, gen_loss = 0.4367143881117177, disc_loss = 0.025052612195351293
Trained batch 351 in epoch 16, gen_loss = 0.43698296399617736, disc_loss = 0.025028571998766645
Trained batch 352 in epoch 16, gen_loss = 0.436924300433556, disc_loss = 0.025033093602713146
Trained batch 353 in epoch 16, gen_loss = 0.4370247349563965, disc_loss = 0.025023269381881874
Trained batch 354 in epoch 16, gen_loss = 0.4375191972289287, disc_loss = 0.025088534991151955
Trained batch 355 in epoch 16, gen_loss = 0.437477269618029, disc_loss = 0.025047372764020928
Trained batch 356 in epoch 16, gen_loss = 0.4373527047346954, disc_loss = 0.025098679351479504
Trained batch 357 in epoch 16, gen_loss = 0.43739719239360125, disc_loss = 0.02505216433688759
Trained batch 358 in epoch 16, gen_loss = 0.4372112356686659, disc_loss = 0.025011893557994252
Trained batch 359 in epoch 16, gen_loss = 0.43738399917880694, disc_loss = 0.024966680570570235
Trained batch 360 in epoch 16, gen_loss = 0.43739605404003173, disc_loss = 0.024903747730712997
Trained batch 361 in epoch 16, gen_loss = 0.43742180356333926, disc_loss = 0.024853767534185365
Trained batch 362 in epoch 16, gen_loss = 0.4375691357230352, disc_loss = 0.02482526840227746
Trained batch 363 in epoch 16, gen_loss = 0.4376470236987858, disc_loss = 0.02476875867424686
Trained batch 364 in epoch 16, gen_loss = 0.43761183766469564, disc_loss = 0.024720128395033313
Trained batch 365 in epoch 16, gen_loss = 0.43751398510620243, disc_loss = 0.02466498265873712
Trained batch 366 in epoch 16, gen_loss = 0.43735343477706495, disc_loss = 0.024604074530397372
Trained batch 367 in epoch 16, gen_loss = 0.4375671177454617, disc_loss = 0.024545426364373114
Trained batch 368 in epoch 16, gen_loss = 0.4375724448421137, disc_loss = 0.024505713821116198
Trained batch 369 in epoch 16, gen_loss = 0.43751036283132194, disc_loss = 0.024444903345539462
Trained batch 370 in epoch 16, gen_loss = 0.4373959531841895, disc_loss = 0.024398641481636608
Trained batch 371 in epoch 16, gen_loss = 0.4376198860105648, disc_loss = 0.02434455290823544
Trained batch 372 in epoch 16, gen_loss = 0.43766446119978347, disc_loss = 0.02428378088458444
Trained batch 373 in epoch 16, gen_loss = 0.437779265610292, disc_loss = 0.024229458673610624
Trained batch 374 in epoch 16, gen_loss = 0.4380210297902425, disc_loss = 0.02417493446636945
Trained batch 375 in epoch 16, gen_loss = 0.43804391877765353, disc_loss = 0.02411882132211294
Trained batch 376 in epoch 16, gen_loss = 0.43794113010247127, disc_loss = 0.024062978193615945
Trained batch 377 in epoch 16, gen_loss = 0.4379095615690978, disc_loss = 0.024003789314837563
Trained batch 378 in epoch 16, gen_loss = 0.43805290259283264, disc_loss = 0.023947899718830327
Trained batch 379 in epoch 16, gen_loss = 0.4380983246784461, disc_loss = 0.02388760438372724
Trained batch 380 in epoch 16, gen_loss = 0.4379227080057299, disc_loss = 0.02383014717471744
Trained batch 381 in epoch 16, gen_loss = 0.43787714893593216, disc_loss = 0.023771492236827778
Trained batch 382 in epoch 16, gen_loss = 0.43790476424887037, disc_loss = 0.023722742720964234
Trained batch 383 in epoch 16, gen_loss = 0.43783985381014645, disc_loss = 0.023663922819650907
Trained batch 384 in epoch 16, gen_loss = 0.4378295243560494, disc_loss = 0.02360551576492945
Trained batch 385 in epoch 16, gen_loss = 0.4378253765828869, disc_loss = 0.02354720815258593
Trained batch 386 in epoch 16, gen_loss = 0.43802732960814345, disc_loss = 0.02350988071435913
Trained batch 387 in epoch 16, gen_loss = 0.43814377770903185, disc_loss = 0.02345251437689456
Trained batch 388 in epoch 16, gen_loss = 0.4381949393638915, disc_loss = 0.0233963001534405
Trained batch 389 in epoch 16, gen_loss = 0.43818000302864957, disc_loss = 0.023340422546682067
Trained batch 390 in epoch 16, gen_loss = 0.43789160808029076, disc_loss = 0.023297543183702717
Trained batch 391 in epoch 16, gen_loss = 0.43776891616230107, disc_loss = 0.023242240393895428
Trained batch 392 in epoch 16, gen_loss = 0.4377916201987036, disc_loss = 0.02318922309714438
Trained batch 393 in epoch 16, gen_loss = 0.43773472974748173, disc_loss = 0.023133310462173245
Trained batch 394 in epoch 16, gen_loss = 0.43766508751277683, disc_loss = 0.023077581281761957
Trained batch 395 in epoch 16, gen_loss = 0.43751654043944194, disc_loss = 0.023025240887878367
Trained batch 396 in epoch 16, gen_loss = 0.43746770066338164, disc_loss = 0.022971688891451347
Trained batch 397 in epoch 16, gen_loss = 0.4372233555993842, disc_loss = 0.022920711991791357
Trained batch 398 in epoch 16, gen_loss = 0.43719044118596795, disc_loss = 0.022870850519109098
Trained batch 399 in epoch 16, gen_loss = 0.4372264214605093, disc_loss = 0.02282423887139885
Trained batch 400 in epoch 16, gen_loss = 0.4372912607436763, disc_loss = 0.022770332931970567
Trained batch 401 in epoch 16, gen_loss = 0.43739279607931775, disc_loss = 0.022724597330265377
Trained batch 402 in epoch 16, gen_loss = 0.43743352004079605, disc_loss = 0.022672326002436374
Trained batch 403 in epoch 16, gen_loss = 0.4372952215299748, disc_loss = 0.02262111441324474
Trained batch 404 in epoch 16, gen_loss = 0.4372588810361462, disc_loss = 0.022571867550320833
Trained batch 405 in epoch 16, gen_loss = 0.4372669829083194, disc_loss = 0.022520985208873825
Trained batch 406 in epoch 16, gen_loss = 0.43712337084425756, disc_loss = 0.0225203892911718
Trained batch 407 in epoch 16, gen_loss = 0.4370346763262562, disc_loss = 0.0224779491568459
Trained batch 408 in epoch 16, gen_loss = 0.43707316028168264, disc_loss = 0.022438960143053008
Trained batch 409 in epoch 16, gen_loss = 0.43690604618409784, disc_loss = 0.022400695195694157
Trained batch 410 in epoch 16, gen_loss = 0.4370206481348859, disc_loss = 0.02235543097815773
Trained batch 411 in epoch 16, gen_loss = 0.4370619742905052, disc_loss = 0.022314918746276606
Trained batch 412 in epoch 16, gen_loss = 0.437087329262394, disc_loss = 0.02227940341259283
Trained batch 413 in epoch 16, gen_loss = 0.4370950484909297, disc_loss = 0.02223571484283081
Trained batch 414 in epoch 16, gen_loss = 0.43693788690739366, disc_loss = 0.022630316206444817
Trained batch 415 in epoch 16, gen_loss = 0.4370524467757115, disc_loss = 0.022732312780975077
Trained batch 416 in epoch 16, gen_loss = 0.4371961881216767, disc_loss = 0.022858780841130934
Trained batch 417 in epoch 16, gen_loss = 0.43712749713630766, disc_loss = 0.0229543661999485
Trained batch 418 in epoch 16, gen_loss = 0.4369882339509404, disc_loss = 0.022916666585463045
Trained batch 419 in epoch 16, gen_loss = 0.4370666633759226, disc_loss = 0.022881044819951058
Trained batch 420 in epoch 16, gen_loss = 0.43701714206478093, disc_loss = 0.022843977455226726
Trained batch 421 in epoch 16, gen_loss = 0.4369212937722274, disc_loss = 0.02280002173535102
Trained batch 422 in epoch 16, gen_loss = 0.43709043739253467, disc_loss = 0.02276693022618374
Trained batch 423 in epoch 16, gen_loss = 0.43691546083340105, disc_loss = 0.022720470480326528
Trained batch 424 in epoch 16, gen_loss = 0.43695858310250674, disc_loss = 0.023514913689235552
Trained batch 425 in epoch 16, gen_loss = 0.43671887735245934, disc_loss = 0.023607698702603194
Trained batch 426 in epoch 16, gen_loss = 0.43654275505827517, disc_loss = 0.023806032849545536
Trained batch 427 in epoch 16, gen_loss = 0.4365471412784585, disc_loss = 0.023766437700457835
Trained batch 428 in epoch 16, gen_loss = 0.43657432076258534, disc_loss = 0.023745342056290843
Trained batch 429 in epoch 16, gen_loss = 0.4364952417307122, disc_loss = 0.023820230703216132
Trained batch 430 in epoch 16, gen_loss = 0.43642174865696104, disc_loss = 0.02382749338145962
Trained batch 431 in epoch 16, gen_loss = 0.43642634456908264, disc_loss = 0.02392362379005472
Trained batch 432 in epoch 16, gen_loss = 0.436130875734479, disc_loss = 0.024617384095927893
Trained batch 433 in epoch 16, gen_loss = 0.4363071097893649, disc_loss = 0.024722186239620816
Trained batch 434 in epoch 16, gen_loss = 0.4364920124925416, disc_loss = 0.02485673030271013
Trained batch 435 in epoch 16, gen_loss = 0.43649946782020255, disc_loss = 0.02513516578159013
Trained batch 436 in epoch 16, gen_loss = 0.4363629516529546, disc_loss = 0.025563115795895253
Trained batch 437 in epoch 16, gen_loss = 0.4364020779524764, disc_loss = 0.025547089714867372
Trained batch 438 in epoch 16, gen_loss = 0.43636100248758236, disc_loss = 0.025671540303919507
Trained batch 439 in epoch 16, gen_loss = 0.43639024963433093, disc_loss = 0.025688035037389704
Trained batch 440 in epoch 16, gen_loss = 0.43639400452713306, disc_loss = 0.025704269029744934
Trained batch 441 in epoch 16, gen_loss = 0.43626136005733884, disc_loss = 0.025870547183721886
Trained batch 442 in epoch 16, gen_loss = 0.4363908382220946, disc_loss = 0.02616251723863958
Trained batch 443 in epoch 16, gen_loss = 0.436438334283528, disc_loss = 0.02625391333256974
Trained batch 444 in epoch 16, gen_loss = 0.4364309049054478, disc_loss = 0.0262052389337901
Trained batch 445 in epoch 16, gen_loss = 0.43623362976072083, disc_loss = 0.026402251134551392
Trained batch 446 in epoch 16, gen_loss = 0.4361617443145522, disc_loss = 0.02698278333731329
Trained batch 447 in epoch 16, gen_loss = 0.43619421530248864, disc_loss = 0.026983581008867726
Trained batch 448 in epoch 16, gen_loss = 0.4361348239111741, disc_loss = 0.026955979085425723
Trained batch 449 in epoch 16, gen_loss = 0.43628272924158307, disc_loss = 0.027034233919758763
Trained batch 450 in epoch 16, gen_loss = 0.4361615020393532, disc_loss = 0.02700368039869598
Trained batch 451 in epoch 16, gen_loss = 0.43606959672364515, disc_loss = 0.02698301579916553
Trained batch 452 in epoch 16, gen_loss = 0.4360535340198618, disc_loss = 0.027045187291074503
Trained batch 453 in epoch 16, gen_loss = 0.436057488955065, disc_loss = 0.027006863414859687
Trained batch 454 in epoch 16, gen_loss = 0.43598113053447596, disc_loss = 0.026978163064488178
Trained batch 455 in epoch 16, gen_loss = 0.4358830502289429, disc_loss = 0.02698344360218024
Trained batch 456 in epoch 16, gen_loss = 0.43616238471193963, disc_loss = 0.02700461318799961
Trained batch 457 in epoch 16, gen_loss = 0.43621230281596624, disc_loss = 0.02696608922568325
Trained batch 458 in epoch 16, gen_loss = 0.4361296389617172, disc_loss = 0.026963412889009566
Trained batch 459 in epoch 16, gen_loss = 0.4362966468800669, disc_loss = 0.026928303479318225
Trained batch 460 in epoch 16, gen_loss = 0.4363891714436372, disc_loss = 0.026925986486743658
Trained batch 461 in epoch 16, gen_loss = 0.4361668454233186, disc_loss = 0.027281102111051062
Trained batch 462 in epoch 16, gen_loss = 0.4361116582322584, disc_loss = 0.02736076420891153
Trained batch 463 in epoch 16, gen_loss = 0.4361889856899607, disc_loss = 0.027345453741747468
Trained batch 464 in epoch 16, gen_loss = 0.4362832134769809, disc_loss = 0.02731765908369374
Trained batch 465 in epoch 16, gen_loss = 0.43646118991364735, disc_loss = 0.02727042127734394
Trained batch 466 in epoch 16, gen_loss = 0.43639878070328936, disc_loss = 0.027228658806983327
Trained batch 467 in epoch 16, gen_loss = 0.43629236430184454, disc_loss = 0.027210240108538102
Trained batch 468 in epoch 16, gen_loss = 0.4362542395398561, disc_loss = 0.027169795241703324
Trained batch 469 in epoch 16, gen_loss = 0.436244952551862, disc_loss = 0.02714049117788276
Trained batch 470 in epoch 16, gen_loss = 0.43631830539419897, disc_loss = 0.02709247742091442
Trained batch 471 in epoch 16, gen_loss = 0.43628079368401385, disc_loss = 0.027157744147589872
Trained batch 472 in epoch 16, gen_loss = 0.43624062436075595, disc_loss = 0.027197919116034537
Trained batch 473 in epoch 16, gen_loss = 0.4363117984452831, disc_loss = 0.027153970429551973
Trained batch 474 in epoch 16, gen_loss = 0.43643095361559014, disc_loss = 0.02710789873362764
Trained batch 475 in epoch 16, gen_loss = 0.43631611902172823, disc_loss = 0.027074037397088593
Trained batch 476 in epoch 16, gen_loss = 0.4364232902007033, disc_loss = 0.0270239255206554
Trained batch 477 in epoch 16, gen_loss = 0.4363516574748889, disc_loss = 0.027002919954832286
Trained batch 478 in epoch 16, gen_loss = 0.4363883097883555, disc_loss = 0.027042717580043854
Trained batch 479 in epoch 16, gen_loss = 0.4363589668025573, disc_loss = 0.027008099582841776
Trained batch 480 in epoch 16, gen_loss = 0.43657259522257624, disc_loss = 0.02695935170975535
Trained batch 481 in epoch 16, gen_loss = 0.4366358984184463, disc_loss = 0.02692603775738696
Trained batch 482 in epoch 16, gen_loss = 0.43667374227357947, disc_loss = 0.026887440283186965
Trained batch 483 in epoch 16, gen_loss = 0.43662250399096936, disc_loss = 0.026877298228123247
Trained batch 484 in epoch 16, gen_loss = 0.4367446583570893, disc_loss = 0.026837998183597764
Trained batch 485 in epoch 16, gen_loss = 0.436636256766908, disc_loss = 0.02679533352586728
Trained batch 486 in epoch 16, gen_loss = 0.43660209727238336, disc_loss = 0.02674613256644251
Trained batch 487 in epoch 16, gen_loss = 0.4366693584645381, disc_loss = 0.026702937091315226
Trained batch 488 in epoch 16, gen_loss = 0.43661427589281937, disc_loss = 0.026651865504882043
Trained batch 489 in epoch 16, gen_loss = 0.4367371484333155, disc_loss = 0.026601093797231738
Trained batch 490 in epoch 16, gen_loss = 0.4367398104332615, disc_loss = 0.02654989717396397
Trained batch 491 in epoch 16, gen_loss = 0.4366720634989622, disc_loss = 0.02649838979567999
Trained batch 492 in epoch 16, gen_loss = 0.43664907393542557, disc_loss = 0.02644982888518207
Trained batch 493 in epoch 16, gen_loss = 0.43674094365675925, disc_loss = 0.02644075405254191
Trained batch 494 in epoch 16, gen_loss = 0.4367122982487534, disc_loss = 0.02647166995924305
Trained batch 495 in epoch 16, gen_loss = 0.4368189233205011, disc_loss = 0.026432665977946242
Trained batch 496 in epoch 16, gen_loss = 0.4371737241744995, disc_loss = 0.026441803003869335
Trained batch 497 in epoch 16, gen_loss = 0.43735656214047625, disc_loss = 0.026451998379504137
Trained batch 498 in epoch 16, gen_loss = 0.4374402815211034, disc_loss = 0.026478147377280558
Trained batch 499 in epoch 16, gen_loss = 0.4372982738018036, disc_loss = 0.02644054730469361
Trained batch 500 in epoch 16, gen_loss = 0.437286731785167, disc_loss = 0.0264283442101116
Trained batch 501 in epoch 16, gen_loss = 0.43729046408636163, disc_loss = 0.026399511477049158
Trained batch 502 in epoch 16, gen_loss = 0.4373848844119616, disc_loss = 0.02635667257049819
Trained batch 503 in epoch 16, gen_loss = 0.43742324187169, disc_loss = 0.02638000998108293
Trained batch 504 in epoch 16, gen_loss = 0.4374305525038502, disc_loss = 0.026557261078609246
Trained batch 505 in epoch 16, gen_loss = 0.4374887616384642, disc_loss = 0.027124845495046276
Trained batch 506 in epoch 16, gen_loss = 0.43752473469316605, disc_loss = 0.02715216986550279
Trained batch 507 in epoch 16, gen_loss = 0.4375108295068966, disc_loss = 0.027129772557844004
Trained batch 508 in epoch 16, gen_loss = 0.43769223856317035, disc_loss = 0.027171647888361267
Trained batch 509 in epoch 16, gen_loss = 0.4377356946468353, disc_loss = 0.02734986352871227
Trained batch 510 in epoch 16, gen_loss = 0.4377972439893771, disc_loss = 0.02740262180371775
Trained batch 511 in epoch 16, gen_loss = 0.43789021897828206, disc_loss = 0.02759225692580003
Trained batch 512 in epoch 16, gen_loss = 0.4379209676797395, disc_loss = 0.0276268790907192
Trained batch 513 in epoch 16, gen_loss = 0.4380642400061574, disc_loss = 0.0276345786287953
Trained batch 514 in epoch 16, gen_loss = 0.4382198219739118, disc_loss = 0.027619464017758236
Trained batch 515 in epoch 16, gen_loss = 0.4381369181959204, disc_loss = 0.02763601080848395
Trained batch 516 in epoch 16, gen_loss = 0.43799010328444105, disc_loss = 0.02761680515963995
Trained batch 517 in epoch 16, gen_loss = 0.4381604348830735, disc_loss = 0.02758965748281337
Trained batch 518 in epoch 16, gen_loss = 0.4384359191378187, disc_loss = 0.027595793687054792
Trained batch 519 in epoch 16, gen_loss = 0.4384612826200632, disc_loss = 0.027563316341435825
Trained batch 520 in epoch 16, gen_loss = 0.4384062072823464, disc_loss = 0.027526188829928036
Trained batch 521 in epoch 16, gen_loss = 0.43852082979633433, disc_loss = 0.02753305948879998
Trained batch 522 in epoch 16, gen_loss = 0.43850361816513833, disc_loss = 0.027535070451938086
Trained batch 523 in epoch 16, gen_loss = 0.43858992126379304, disc_loss = 0.027488371124935428
Trained batch 524 in epoch 16, gen_loss = 0.43849833431698026, disc_loss = 0.027458127109511267
Trained batch 525 in epoch 16, gen_loss = 0.4383540026588585, disc_loss = 0.027425296192531944
Trained batch 526 in epoch 16, gen_loss = 0.4383799774144587, disc_loss = 0.028128380353953087
Trained batch 527 in epoch 16, gen_loss = 0.438369329962315, disc_loss = 0.028155020218092075
Trained batch 528 in epoch 16, gen_loss = 0.4382047059968649, disc_loss = 0.028394524034883805
Trained batch 529 in epoch 16, gen_loss = 0.43823808875848663, disc_loss = 0.028406052880498738
Trained batch 530 in epoch 16, gen_loss = 0.43815907145624106, disc_loss = 0.028418970428031858
Trained batch 531 in epoch 16, gen_loss = 0.43834870022938666, disc_loss = 0.028983819647254494
Trained batch 532 in epoch 16, gen_loss = 0.43827697947817046, disc_loss = 0.0291314560830013
Trained batch 533 in epoch 16, gen_loss = 0.4380670851201154, disc_loss = 0.029490935743946848
Trained batch 534 in epoch 16, gen_loss = 0.4380476464735013, disc_loss = 0.02945533363348761
Trained batch 535 in epoch 16, gen_loss = 0.43791814415312524, disc_loss = 0.02979644865306692
Trained batch 536 in epoch 16, gen_loss = 0.4378532351062285, disc_loss = 0.02986262973746566
Trained batch 537 in epoch 16, gen_loss = 0.4377262720831265, disc_loss = 0.030096905152348034
Trained batch 538 in epoch 16, gen_loss = 0.43790427043840485, disc_loss = 0.030301143754366957
Trained batch 539 in epoch 16, gen_loss = 0.4378829610016611, disc_loss = 0.030284787209583792
Trained batch 540 in epoch 16, gen_loss = 0.4377273437937174, disc_loss = 0.030251070341033356
Trained batch 541 in epoch 16, gen_loss = 0.4377167455824539, disc_loss = 0.03021521738522456
Trained batch 542 in epoch 16, gen_loss = 0.43791241957557353, disc_loss = 0.030181726857995816
Trained batch 543 in epoch 16, gen_loss = 0.43772690650075674, disc_loss = 0.030154739450475008
Trained batch 544 in epoch 16, gen_loss = 0.4377150762518612, disc_loss = 0.030137003420365103
Trained batch 545 in epoch 16, gen_loss = 0.4378070496704989, disc_loss = 0.030089167940716904
Trained batch 546 in epoch 16, gen_loss = 0.43798782865787556, disc_loss = 0.03005487241073966
Trained batch 547 in epoch 16, gen_loss = 0.4380651000533661, disc_loss = 0.030069289859435282
Trained batch 548 in epoch 16, gen_loss = 0.43806768603663626, disc_loss = 0.030406976747623424
Trained batch 549 in epoch 16, gen_loss = 0.4379098081046885, disc_loss = 0.030949699642898683
Trained batch 550 in epoch 16, gen_loss = 0.43790720395081273, disc_loss = 0.030931112244505496
Trained batch 551 in epoch 16, gen_loss = 0.4379107158469117, disc_loss = 0.030989261979719733
Trained batch 552 in epoch 16, gen_loss = 0.4378502956350716, disc_loss = 0.031032554011633635
Trained batch 553 in epoch 16, gen_loss = 0.43783169333900357, disc_loss = 0.031026356152110877
Trained batch 554 in epoch 16, gen_loss = 0.4377710328982757, disc_loss = 0.030998785835313233
Trained batch 555 in epoch 16, gen_loss = 0.43774971285526704, disc_loss = 0.031047036805568706
Trained batch 556 in epoch 16, gen_loss = 0.4377268939086736, disc_loss = 0.03157090905450177
Trained batch 557 in epoch 16, gen_loss = 0.4377287455357104, disc_loss = 0.03163617569076959
Trained batch 558 in epoch 16, gen_loss = 0.4378157947912199, disc_loss = 0.03161231487487944
Trained batch 559 in epoch 16, gen_loss = 0.43780107950525626, disc_loss = 0.03158598968085633
Trained batch 560 in epoch 16, gen_loss = 0.4378780805490871, disc_loss = 0.03157747598114272
Trained batch 561 in epoch 16, gen_loss = 0.4378268753188361, disc_loss = 0.03153008996596845
Trained batch 562 in epoch 16, gen_loss = 0.4379180327825394, disc_loss = 0.031493488091687616
Trained batch 563 in epoch 16, gen_loss = 0.4379379462371481, disc_loss = 0.03147816292880473
Trained batch 564 in epoch 16, gen_loss = 0.437858783196559, disc_loss = 0.031442253683504146
Trained batch 565 in epoch 16, gen_loss = 0.4378149063448181, disc_loss = 0.03139784455409622
Trained batch 566 in epoch 16, gen_loss = 0.43776817895748, disc_loss = 0.031348212338767195
Trained batch 567 in epoch 16, gen_loss = 0.43769912054421195, disc_loss = 0.031299837805498
Trained batch 568 in epoch 16, gen_loss = 0.4377042865397012, disc_loss = 0.03131627343122001
Trained batch 569 in epoch 16, gen_loss = 0.43755353061776414, disc_loss = 0.031272683537303746
Trained batch 570 in epoch 16, gen_loss = 0.43761538545847356, disc_loss = 0.031232359952451546
Trained batch 571 in epoch 16, gen_loss = 0.4375836771580723, disc_loss = 0.031183767779258086
Trained batch 572 in epoch 16, gen_loss = 0.43761884713672217, disc_loss = 0.0311336725325296
Trained batch 573 in epoch 16, gen_loss = 0.43774079669020316, disc_loss = 0.031085045236318602
Trained batch 574 in epoch 16, gen_loss = 0.4376370305600374, disc_loss = 0.031057781679555772
Trained batch 575 in epoch 16, gen_loss = 0.43767461159990895, disc_loss = 0.03101101612871086
Trained batch 576 in epoch 16, gen_loss = 0.4376567178107217, disc_loss = 0.030965670605514528
Trained batch 577 in epoch 16, gen_loss = 0.43767197966369376, disc_loss = 0.03091574545303572
Trained batch 578 in epoch 16, gen_loss = 0.4376782423371066, disc_loss = 0.030865070404845173
Trained batch 579 in epoch 16, gen_loss = 0.4376680607425755, disc_loss = 0.030825715659362873
Trained batch 580 in epoch 16, gen_loss = 0.4377726518553834, disc_loss = 0.030778681408540183
Trained batch 581 in epoch 16, gen_loss = 0.4378376428511544, disc_loss = 0.030736956660174907
Trained batch 582 in epoch 16, gen_loss = 0.4378969169399137, disc_loss = 0.03069280504207502
Trained batch 583 in epoch 16, gen_loss = 0.43789828783028745, disc_loss = 0.030643971080729124
Trained batch 584 in epoch 16, gen_loss = 0.4378929487150958, disc_loss = 0.030600741310204325
Trained batch 585 in epoch 16, gen_loss = 0.4380296615712065, disc_loss = 0.030556410279700297
Trained batch 586 in epoch 16, gen_loss = 0.43816165019340775, disc_loss = 0.03053013713406859
Trained batch 587 in epoch 16, gen_loss = 0.43825888892217557, disc_loss = 0.030484201285598457
Trained batch 588 in epoch 16, gen_loss = 0.43817771751123696, disc_loss = 0.030455954117124904
Trained batch 589 in epoch 16, gen_loss = 0.43818768065864755, disc_loss = 0.03040899365698382
Trained batch 590 in epoch 16, gen_loss = 0.4380608982644509, disc_loss = 0.030363645445155185
Trained batch 591 in epoch 16, gen_loss = 0.43814664676382736, disc_loss = 0.03031799014904725
Trained batch 592 in epoch 16, gen_loss = 0.43802918214822095, disc_loss = 0.030270638147331334
Trained batch 593 in epoch 16, gen_loss = 0.43801412498108067, disc_loss = 0.030239929282420037
Trained batch 594 in epoch 16, gen_loss = 0.4379352069702469, disc_loss = 0.030193152280618286
Trained batch 595 in epoch 16, gen_loss = 0.43807212748383517, disc_loss = 0.03014954864930349
Trained batch 596 in epoch 16, gen_loss = 0.4381507809337859, disc_loss = 0.030106628344470705
Trained batch 597 in epoch 16, gen_loss = 0.4381482920618759, disc_loss = 0.030063132857078418
Trained batch 598 in epoch 16, gen_loss = 0.43808282252544156, disc_loss = 0.03002833675955405
Trained batch 599 in epoch 16, gen_loss = 0.4381291039288044, disc_loss = 0.029987490754186486
Trained batch 600 in epoch 16, gen_loss = 0.4380689230615803, disc_loss = 0.02994318174766981
Trained batch 601 in epoch 16, gen_loss = 0.4380153290853152, disc_loss = 0.029896269320932672
Trained batch 602 in epoch 16, gen_loss = 0.43807669273063315, disc_loss = 0.029851852754975792
Trained batch 603 in epoch 16, gen_loss = 0.4381040684533435, disc_loss = 0.029806095553023913
Trained batch 604 in epoch 16, gen_loss = 0.43821110927368984, disc_loss = 0.029771971171298487
Trained batch 605 in epoch 16, gen_loss = 0.43819488078454144, disc_loss = 0.029727837042199147
Trained batch 606 in epoch 16, gen_loss = 0.43817372480177214, disc_loss = 0.029697882361929478
Trained batch 607 in epoch 16, gen_loss = 0.4381134252210981, disc_loss = 0.029674750964707192
Trained batch 608 in epoch 16, gen_loss = 0.4382158475752143, disc_loss = 0.029794780164918815
Trained batch 609 in epoch 16, gen_loss = 0.43820956598539823, disc_loss = 0.029938391025643794
Trained batch 610 in epoch 16, gen_loss = 0.43817069828998045, disc_loss = 0.02991137838081812
Trained batch 611 in epoch 16, gen_loss = 0.43817703386926965, disc_loss = 0.029899515476940638
Trained batch 612 in epoch 16, gen_loss = 0.43840449776190527, disc_loss = 0.02986862873609161
Trained batch 613 in epoch 16, gen_loss = 0.43834750169845665, disc_loss = 0.029905536922463897
Trained batch 614 in epoch 16, gen_loss = 0.43835185393085324, disc_loss = 0.029886508406503354
Trained batch 615 in epoch 16, gen_loss = 0.4383521039377559, disc_loss = 0.02985796569328749
Trained batch 616 in epoch 16, gen_loss = 0.43830940093561355, disc_loss = 0.029824361086421537
Trained batch 617 in epoch 16, gen_loss = 0.4383302669501999, disc_loss = 0.029781799482951742
Trained batch 618 in epoch 16, gen_loss = 0.43844640717175165, disc_loss = 0.029757583919899036
Trained batch 619 in epoch 16, gen_loss = 0.43846831018886256, disc_loss = 0.029720015743289203
Trained batch 620 in epoch 16, gen_loss = 0.4384190942642193, disc_loss = 0.029678924104248303
Trained batch 621 in epoch 16, gen_loss = 0.43831405585026817, disc_loss = 0.029641278334212012
Trained batch 622 in epoch 16, gen_loss = 0.43842392131375274, disc_loss = 0.029608131300196065
Trained batch 623 in epoch 16, gen_loss = 0.4385736870746582, disc_loss = 0.029576762366513066
Trained batch 624 in epoch 16, gen_loss = 0.4386529887676239, disc_loss = 0.02953445458393544
Trained batch 625 in epoch 16, gen_loss = 0.4386795270747651, disc_loss = 0.029494045197200506
Trained batch 626 in epoch 16, gen_loss = 0.4386220723152921, disc_loss = 0.029452737711000137
Trained batch 627 in epoch 16, gen_loss = 0.4387080831702348, disc_loss = 0.029409657552605495
Trained batch 628 in epoch 16, gen_loss = 0.4387053319020567, disc_loss = 0.02936639920945334
Trained batch 629 in epoch 16, gen_loss = 0.43890969653924305, disc_loss = 0.02934320124128597
Trained batch 630 in epoch 16, gen_loss = 0.4389304733597533, disc_loss = 0.02930208370026803
Trained batch 631 in epoch 16, gen_loss = 0.43890695075822783, disc_loss = 0.029260090691342514
Trained batch 632 in epoch 16, gen_loss = 0.4388743423831783, disc_loss = 0.029224445361983896
Trained batch 633 in epoch 16, gen_loss = 0.4388475300103708, disc_loss = 0.02918286570799552
Trained batch 634 in epoch 16, gen_loss = 0.43881243518957, disc_loss = 0.02914565143149757
Trained batch 635 in epoch 16, gen_loss = 0.43891715370821505, disc_loss = 0.029105211401822442
Trained batch 636 in epoch 16, gen_loss = 0.4389528038456825, disc_loss = 0.02906275294765719
Trained batch 637 in epoch 16, gen_loss = 0.43897080094463026, disc_loss = 0.029020420400619938
Trained batch 638 in epoch 16, gen_loss = 0.438979897887121, disc_loss = 0.028979603368213258
Trained batch 639 in epoch 16, gen_loss = 0.43903424101881683, disc_loss = 0.02893904627944721
Trained batch 640 in epoch 16, gen_loss = 0.43896935942950377, disc_loss = 0.028896915848590665
Trained batch 641 in epoch 16, gen_loss = 0.4390698283725067, disc_loss = 0.028858922924041297
Trained batch 642 in epoch 16, gen_loss = 0.43909354278496227, disc_loss = 0.028817943186342752
Trained batch 643 in epoch 16, gen_loss = 0.43906316073229595, disc_loss = 0.028779253114690217
Trained batch 644 in epoch 16, gen_loss = 0.4389347812464071, disc_loss = 0.02873707274570628
Trained batch 645 in epoch 16, gen_loss = 0.4388489003521001, disc_loss = 0.028744600212450885
Trained batch 646 in epoch 16, gen_loss = 0.4387860534917074, disc_loss = 0.02871941592075777
Trained batch 647 in epoch 16, gen_loss = 0.43882073167665503, disc_loss = 0.02876809292367263
Trained batch 648 in epoch 16, gen_loss = 0.4387654962451506, disc_loss = 0.028758559147296373
Trained batch 649 in epoch 16, gen_loss = 0.4388333139511255, disc_loss = 0.02879313410564254
Trained batch 650 in epoch 16, gen_loss = 0.438961920970779, disc_loss = 0.028782521096450176
Trained batch 651 in epoch 16, gen_loss = 0.4390588574157171, disc_loss = 0.028860463373158757
Trained batch 652 in epoch 16, gen_loss = 0.4390455870953307, disc_loss = 0.02882534950764088
Trained batch 653 in epoch 16, gen_loss = 0.4391062880327942, disc_loss = 0.028810311374589174
Trained batch 654 in epoch 16, gen_loss = 0.439034692294725, disc_loss = 0.028772968051862684
Trained batch 655 in epoch 16, gen_loss = 0.43902757523081654, disc_loss = 0.02873994597172075
Trained batch 656 in epoch 16, gen_loss = 0.4391367809685398, disc_loss = 0.028702710855991794
Trained batch 657 in epoch 16, gen_loss = 0.43921618104705695, disc_loss = 0.028694277943648386
Trained batch 658 in epoch 16, gen_loss = 0.43918512103590146, disc_loss = 0.02865454813056344
Trained batch 659 in epoch 16, gen_loss = 0.4390246548435905, disc_loss = 0.028614968032343313
Trained batch 660 in epoch 16, gen_loss = 0.43904397612981466, disc_loss = 0.028576988255733318
Trained batch 661 in epoch 16, gen_loss = 0.43917401945302853, disc_loss = 0.028541014180342834
Trained batch 662 in epoch 16, gen_loss = 0.4391179765331619, disc_loss = 0.028502200128051255
Trained batch 663 in epoch 16, gen_loss = 0.439177514424166, disc_loss = 0.028462615986011013
Trained batch 664 in epoch 16, gen_loss = 0.43919135354515304, disc_loss = 0.028426540363404928
Trained batch 665 in epoch 16, gen_loss = 0.43913018197805676, disc_loss = 0.028389845906047838
Trained batch 666 in epoch 16, gen_loss = 0.43919993818610503, disc_loss = 0.028349777555855542
Trained batch 667 in epoch 16, gen_loss = 0.43916588379237465, disc_loss = 0.028310088204459738
Trained batch 668 in epoch 16, gen_loss = 0.4391893833563823, disc_loss = 0.028278138010340823
Trained batch 669 in epoch 16, gen_loss = 0.4392732119382317, disc_loss = 0.02824082557709693
Trained batch 670 in epoch 16, gen_loss = 0.43932270110985916, disc_loss = 0.028214422824213783
Trained batch 671 in epoch 16, gen_loss = 0.4393758339629996, disc_loss = 0.02818009532347787
Trained batch 672 in epoch 16, gen_loss = 0.4393488027897136, disc_loss = 0.02814193992124093
Trained batch 673 in epoch 16, gen_loss = 0.43940685941486757, disc_loss = 0.02810931988253924
Trained batch 674 in epoch 16, gen_loss = 0.43924044918130944, disc_loss = 0.028070317961068618
Trained batch 675 in epoch 16, gen_loss = 0.4392540222088966, disc_loss = 0.028033203916202613
Trained batch 676 in epoch 16, gen_loss = 0.43916695900646585, disc_loss = 0.02799914513667839
Trained batch 677 in epoch 16, gen_loss = 0.43910170282761957, disc_loss = 0.02798047349383027
Trained batch 678 in epoch 16, gen_loss = 0.43918737115143675, disc_loss = 0.027945239339997673
Trained batch 679 in epoch 16, gen_loss = 0.4392208319814766, disc_loss = 0.02791290031163953
Trained batch 680 in epoch 16, gen_loss = 0.43936910341314633, disc_loss = 0.027878925623782472
Trained batch 681 in epoch 16, gen_loss = 0.43945723522967955, disc_loss = 0.027843964612862517
Trained batch 682 in epoch 16, gen_loss = 0.439620684608708, disc_loss = 0.027824011705283997
Trained batch 683 in epoch 16, gen_loss = 0.43976560047669716, disc_loss = 0.027796425903284083
Trained batch 684 in epoch 16, gen_loss = 0.43972778368170246, disc_loss = 0.02776435946427068
Trained batch 685 in epoch 16, gen_loss = 0.4397688268659414, disc_loss = 0.027728914354490687
Trained batch 686 in epoch 16, gen_loss = 0.4397787772758906, disc_loss = 0.02769440556828914
Trained batch 687 in epoch 16, gen_loss = 0.4398414009618898, disc_loss = 0.027658341652483594
Trained batch 688 in epoch 16, gen_loss = 0.43980415340604906, disc_loss = 0.02762012437617214
Trained batch 689 in epoch 16, gen_loss = 0.43975764906060866, disc_loss = 0.027587602337808822
Trained batch 690 in epoch 16, gen_loss = 0.43978098504967694, disc_loss = 0.0275523743532226
Trained batch 691 in epoch 16, gen_loss = 0.4397401563349487, disc_loss = 0.02751426183554005
Trained batch 692 in epoch 16, gen_loss = 0.4398529234558645, disc_loss = 0.027476369404814557
Trained batch 693 in epoch 16, gen_loss = 0.43989691181210344, disc_loss = 0.027439311110335388
Trained batch 694 in epoch 16, gen_loss = 0.43992976391915795, disc_loss = 0.027403456416389763
Trained batch 695 in epoch 16, gen_loss = 0.4399106503389348, disc_loss = 0.027368346996767306
Trained batch 696 in epoch 16, gen_loss = 0.43985042005905634, disc_loss = 0.02733144345990592
Trained batch 697 in epoch 16, gen_loss = 0.4398959723106428, disc_loss = 0.027301806540736783
Trained batch 698 in epoch 16, gen_loss = 0.43989827325074626, disc_loss = 0.027264788088479344
Trained batch 699 in epoch 16, gen_loss = 0.4398952032412801, disc_loss = 0.02723116099418673
Trained batch 700 in epoch 16, gen_loss = 0.4397614447349488, disc_loss = 0.027197372463741706
Trained batch 701 in epoch 16, gen_loss = 0.4397765157738982, disc_loss = 0.027162034877946075
Trained batch 702 in epoch 16, gen_loss = 0.4396916164951677, disc_loss = 0.027127162964218382
Trained batch 703 in epoch 16, gen_loss = 0.4396762162108313, disc_loss = 0.027093003780630006
Trained batch 704 in epoch 16, gen_loss = 0.4395761951909843, disc_loss = 0.02705751169978225
Trained batch 705 in epoch 16, gen_loss = 0.43962300929739523, disc_loss = 0.027126518789996727
Trained batch 706 in epoch 16, gen_loss = 0.4394975683982504, disc_loss = 0.02727180106787319
Trained batch 707 in epoch 16, gen_loss = 0.43931318444889145, disc_loss = 0.02739591421615359
Trained batch 708 in epoch 16, gen_loss = 0.4392590180186526, disc_loss = 0.02740105706755051
Trained batch 709 in epoch 16, gen_loss = 0.4392363049194846, disc_loss = 0.02748655812949283
Trained batch 710 in epoch 16, gen_loss = 0.4392641736233788, disc_loss = 0.027505095783030318
Trained batch 711 in epoch 16, gen_loss = 0.4392854968985815, disc_loss = 0.02752945412769835
Trained batch 712 in epoch 16, gen_loss = 0.4393240775165852, disc_loss = 0.027511365886230342
Trained batch 713 in epoch 16, gen_loss = 0.4391993286312461, disc_loss = 0.02751245031590477
Trained batch 714 in epoch 16, gen_loss = 0.43919612982056355, disc_loss = 0.0275091794373181
Trained batch 715 in epoch 16, gen_loss = 0.43909791403309595, disc_loss = 0.02755049287485266
Trained batch 716 in epoch 16, gen_loss = 0.4391901560408301, disc_loss = 0.027613750438925496
Trained batch 717 in epoch 16, gen_loss = 0.4391991575365279, disc_loss = 0.02758224281592004
Trained batch 718 in epoch 16, gen_loss = 0.43933648845085016, disc_loss = 0.027608742028952773
Trained batch 719 in epoch 16, gen_loss = 0.4392936003290945, disc_loss = 0.02762602120201336
Trained batch 720 in epoch 16, gen_loss = 0.4392798850919932, disc_loss = 0.027595283038786323
Trained batch 721 in epoch 16, gen_loss = 0.4392212430360905, disc_loss = 0.027593061569310632
Trained batch 722 in epoch 16, gen_loss = 0.43912217132283443, disc_loss = 0.027719014386239398
Trained batch 723 in epoch 16, gen_loss = 0.4392004487264222, disc_loss = 0.028139365985069824
Trained batch 724 in epoch 16, gen_loss = 0.4393345337900622, disc_loss = 0.028413844431172414
Trained batch 725 in epoch 16, gen_loss = 0.43930134866848464, disc_loss = 0.02843712330183281
Trained batch 726 in epoch 16, gen_loss = 0.439084910133026, disc_loss = 0.028444773520271267
Trained batch 727 in epoch 16, gen_loss = 0.4389922771152559, disc_loss = 0.028494103784976108
Trained batch 728 in epoch 16, gen_loss = 0.43892169244004864, disc_loss = 0.028621492423379056
Trained batch 729 in epoch 16, gen_loss = 0.4389364102931872, disc_loss = 0.028682128691006045
Trained batch 730 in epoch 16, gen_loss = 0.4388395557243749, disc_loss = 0.028731050445168202
Trained batch 731 in epoch 16, gen_loss = 0.43893207255445543, disc_loss = 0.02871352856450134
Trained batch 732 in epoch 16, gen_loss = 0.4389120639996834, disc_loss = 0.02869622207721276
Trained batch 733 in epoch 16, gen_loss = 0.43893688986184487, disc_loss = 0.028689154097842107
Trained batch 734 in epoch 16, gen_loss = 0.4388966554281663, disc_loss = 0.028748507013538104
Trained batch 735 in epoch 16, gen_loss = 0.43887490495715453, disc_loss = 0.02872162680891368
Trained batch 736 in epoch 16, gen_loss = 0.4389645224348661, disc_loss = 0.028707431484136372
Trained batch 737 in epoch 16, gen_loss = 0.43899671600116946, disc_loss = 0.028681194218068678
Trained batch 738 in epoch 16, gen_loss = 0.43910704413996016, disc_loss = 0.028645632233557636
Trained batch 739 in epoch 16, gen_loss = 0.439142749961969, disc_loss = 0.028619675702774093
Trained batch 740 in epoch 16, gen_loss = 0.4391783878468631, disc_loss = 0.0285991744778349
Trained batch 741 in epoch 16, gen_loss = 0.43922918536913685, disc_loss = 0.02857406799712236
Trained batch 742 in epoch 16, gen_loss = 0.4391704718325372, disc_loss = 0.028545278518255123
Trained batch 743 in epoch 16, gen_loss = 0.43907989521500884, disc_loss = 0.028517027435134547
Trained batch 744 in epoch 16, gen_loss = 0.439120722297054, disc_loss = 0.02849387518839673
Trained batch 745 in epoch 16, gen_loss = 0.4390076663315136, disc_loss = 0.028728024073565582
Testing Epoch 16
Training Epoch 17
Trained batch 0 in epoch 17, gen_loss = 0.39474356174468994, disc_loss = 0.010903595015406609
Trained batch 1 in epoch 17, gen_loss = 0.41147156059741974, disc_loss = 0.00915589090436697
Trained batch 2 in epoch 17, gen_loss = 0.3966975112756093, disc_loss = 0.03353444424768289
Trained batch 3 in epoch 17, gen_loss = 0.40755079686641693, disc_loss = 0.028408611426129937
Trained batch 4 in epoch 17, gen_loss = 0.4138788223266602, disc_loss = 0.0415308641269803
Trained batch 5 in epoch 17, gen_loss = 0.4025445481141408, disc_loss = 0.06110087921842933
Trained batch 6 in epoch 17, gen_loss = 0.41305642468588694, disc_loss = 0.053814569621213844
Trained batch 7 in epoch 17, gen_loss = 0.4220529571175575, disc_loss = 0.05624326772522181
Trained batch 8 in epoch 17, gen_loss = 0.41770629750357735, disc_loss = 0.0510344427699844
Trained batch 9 in epoch 17, gen_loss = 0.4129940360784531, disc_loss = 0.046838636975735426
Trained batch 10 in epoch 17, gen_loss = 0.4110430804165927, disc_loss = 0.05089371473613111
Trained batch 11 in epoch 17, gen_loss = 0.41568200786908466, disc_loss = 0.06181159638799727
Trained batch 12 in epoch 17, gen_loss = 0.41036596435766953, disc_loss = 0.06157424924178766
Trained batch 13 in epoch 17, gen_loss = 0.41522911403860363, disc_loss = 0.07663026126101613
Trained batch 14 in epoch 17, gen_loss = 0.412725031375885, disc_loss = 0.08559580935786168
Trained batch 15 in epoch 17, gen_loss = 0.4127078950405121, disc_loss = 0.08423064596718177
Trained batch 16 in epoch 17, gen_loss = 0.4138576370828292, disc_loss = 0.08233538154950913
Trained batch 17 in epoch 17, gen_loss = 0.41474196645948624, disc_loss = 0.0799266004210545
Trained batch 18 in epoch 17, gen_loss = 0.41613042982001053, disc_loss = 0.07624419964849949
Trained batch 19 in epoch 17, gen_loss = 0.41554380804300306, disc_loss = 0.07325168596580625
Trained batch 20 in epoch 17, gen_loss = 0.4152453967503139, disc_loss = 0.07070826224627949
Trained batch 21 in epoch 17, gen_loss = 0.4187116324901581, disc_loss = 0.0687765498560938
Trained batch 22 in epoch 17, gen_loss = 0.4215403613836869, disc_loss = 0.06796559100241764
Trained batch 23 in epoch 17, gen_loss = 0.4199371325472991, disc_loss = 0.06748400713937978
Trained batch 24 in epoch 17, gen_loss = 0.4187811362743378, disc_loss = 0.06535679154098034
Trained batch 25 in epoch 17, gen_loss = 0.4199042973610071, disc_loss = 0.07678685100892416
Trained batch 26 in epoch 17, gen_loss = 0.4200964029188509, disc_loss = 0.0826545114180556
Trained batch 27 in epoch 17, gen_loss = 0.4231738160763468, disc_loss = 0.08111354342794844
Trained batch 28 in epoch 17, gen_loss = 0.4224383306914362, disc_loss = 0.08576777275523235
Trained batch 29 in epoch 17, gen_loss = 0.4219857037067413, disc_loss = 0.08436390105634928
Trained batch 30 in epoch 17, gen_loss = 0.42450899077999976, disc_loss = 0.08662691033415255
Trained batch 31 in epoch 17, gen_loss = 0.42065998911857605, disc_loss = 0.08634801203152165
Trained batch 32 in epoch 17, gen_loss = 0.4187987139730742, disc_loss = 0.08771660963468479
Trained batch 33 in epoch 17, gen_loss = 0.4194796015234554, disc_loss = 0.08712556448710315
Trained batch 34 in epoch 17, gen_loss = 0.4201108651501792, disc_loss = 0.08499505623642888
Trained batch 35 in epoch 17, gen_loss = 0.4204123806622293, disc_loss = 0.0836686327173892
Trained batch 36 in epoch 17, gen_loss = 0.42030731810105815, disc_loss = 0.08161797132846471
Trained batch 37 in epoch 17, gen_loss = 0.42179389062680694, disc_loss = 0.08002968245234929
Trained batch 38 in epoch 17, gen_loss = 0.42366471122472715, disc_loss = 0.0781798679381609
Trained batch 39 in epoch 17, gen_loss = 0.4238239534199238, disc_loss = 0.0763594260206446
Trained batch 40 in epoch 17, gen_loss = 0.42457706244980414, disc_loss = 0.0746723276835571
Trained batch 41 in epoch 17, gen_loss = 0.42463916823977516, disc_loss = 0.07319651966515396
Trained batch 42 in epoch 17, gen_loss = 0.4253898207531419, disc_loss = 0.07234024157920896
Trained batch 43 in epoch 17, gen_loss = 0.4264027638868852, disc_loss = 0.07126311599065295
Trained batch 44 in epoch 17, gen_loss = 0.4260515246126387, disc_loss = 0.06988284290871687
Trained batch 45 in epoch 17, gen_loss = 0.42666338513726776, disc_loss = 0.0684569489474044
Trained batch 46 in epoch 17, gen_loss = 0.4259345607554659, disc_loss = 0.06870470704273024
Trained batch 47 in epoch 17, gen_loss = 0.42739480671783286, disc_loss = 0.06768413261549237
Trained batch 48 in epoch 17, gen_loss = 0.4273056497379225, disc_loss = 0.06654545639128405
Trained batch 49 in epoch 17, gen_loss = 0.4282387334108353, disc_loss = 0.06552108720876276
Trained batch 50 in epoch 17, gen_loss = 0.4282463537711723, disc_loss = 0.06511818720758253
Trained batch 51 in epoch 17, gen_loss = 0.4308182339255626, disc_loss = 0.06528369968649574
Trained batch 52 in epoch 17, gen_loss = 0.4325019419193268, disc_loss = 0.0643241094899768
Trained batch 53 in epoch 17, gen_loss = 0.43239727837068065, disc_loss = 0.06412770572394409
Trained batch 54 in epoch 17, gen_loss = 0.43296583999286997, disc_loss = 0.06353851625357163
Trained batch 55 in epoch 17, gen_loss = 0.4341687240770885, disc_loss = 0.06403630280900481
Trained batch 56 in epoch 17, gen_loss = 0.4336655396118499, disc_loss = 0.06302555665994684
Trained batch 57 in epoch 17, gen_loss = 0.43348674578913327, disc_loss = 0.06211263629415169
Trained batch 58 in epoch 17, gen_loss = 0.4321855660212242, disc_loss = 0.06117204315486854
Trained batch 59 in epoch 17, gen_loss = 0.43271650473276774, disc_loss = 0.06023140699447443
Trained batch 60 in epoch 17, gen_loss = 0.4318435094395622, disc_loss = 0.059308231945653433
Trained batch 61 in epoch 17, gen_loss = 0.4325788198940216, disc_loss = 0.058429958644293005
Trained batch 62 in epoch 17, gen_loss = 0.43170123630099827, disc_loss = 0.05756962502611771
Trained batch 63 in epoch 17, gen_loss = 0.4316222723573446, disc_loss = 0.056775048848066945
Trained batch 64 in epoch 17, gen_loss = 0.4317495194765238, disc_loss = 0.056013243237080484
Trained batch 65 in epoch 17, gen_loss = 0.4323937346537908, disc_loss = 0.05528556038343319
Trained batch 66 in epoch 17, gen_loss = 0.4327072292121489, disc_loss = 0.05452475407675131
Trained batch 67 in epoch 17, gen_loss = 0.4318311433581745, disc_loss = 0.05377429520355209
Trained batch 68 in epoch 17, gen_loss = 0.4320366516493369, disc_loss = 0.05304227734281533
Trained batch 69 in epoch 17, gen_loss = 0.43238391067300525, disc_loss = 0.05234505582068648
Trained batch 70 in epoch 17, gen_loss = 0.43137977870417316, disc_loss = 0.05165533332521437
Trained batch 71 in epoch 17, gen_loss = 0.4328225350214375, disc_loss = 0.05099517717543575
Trained batch 72 in epoch 17, gen_loss = 0.43280708340749346, disc_loss = 0.05036201308902404
Trained batch 73 in epoch 17, gen_loss = 0.4331206103434434, disc_loss = 0.049704186652938055
Trained batch 74 in epoch 17, gen_loss = 0.43349587559700015, disc_loss = 0.049067043674488865
Trained batch 75 in epoch 17, gen_loss = 0.43495133793667745, disc_loss = 0.048490129723703784
Trained batch 76 in epoch 17, gen_loss = 0.43475300344553863, disc_loss = 0.047887758309529585
Trained batch 77 in epoch 17, gen_loss = 0.43431418904891383, disc_loss = 0.04730983784135718
Trained batch 78 in epoch 17, gen_loss = 0.4340763899344432, disc_loss = 0.04675525547995503
Trained batch 79 in epoch 17, gen_loss = 0.43400032371282576, disc_loss = 0.046189015332493
Trained batch 80 in epoch 17, gen_loss = 0.4338995858475014, disc_loss = 0.04563434212899732
Trained batch 81 in epoch 17, gen_loss = 0.4343324543499365, disc_loss = 0.04509640464178718
Trained batch 82 in epoch 17, gen_loss = 0.434842666947698, disc_loss = 0.04457605914324971
Trained batch 83 in epoch 17, gen_loss = 0.4346899439891179, disc_loss = 0.044069389937379
Trained batch 84 in epoch 17, gen_loss = 0.4357681933571311, disc_loss = 0.04357192954459392
Trained batch 85 in epoch 17, gen_loss = 0.43601160097953884, disc_loss = 0.043113472474858076
Trained batch 86 in epoch 17, gen_loss = 0.43630976272725513, disc_loss = 0.04263596836579214
Trained batch 87 in epoch 17, gen_loss = 0.43690232085910713, disc_loss = 0.04217335504654329
Trained batch 88 in epoch 17, gen_loss = 0.4370810580387544, disc_loss = 0.04172044665175961
Trained batch 89 in epoch 17, gen_loss = 0.43697958721054925, disc_loss = 0.04128899136299474
Trained batch 90 in epoch 17, gen_loss = 0.43693872402002526, disc_loss = 0.04085766860529535
Trained batch 91 in epoch 17, gen_loss = 0.43659834596125974, disc_loss = 0.04043125011705105
Trained batch 92 in epoch 17, gen_loss = 0.43740513023509775, disc_loss = 0.04003926940632844
Trained batch 93 in epoch 17, gen_loss = 0.436763382021417, disc_loss = 0.03963265171958173
Trained batch 94 in epoch 17, gen_loss = 0.437390219851544, disc_loss = 0.03924797957910127
Trained batch 95 in epoch 17, gen_loss = 0.43745861668139696, disc_loss = 0.03886069141299231
Trained batch 96 in epoch 17, gen_loss = 0.4376021288719374, disc_loss = 0.03851163006848512
Trained batch 97 in epoch 17, gen_loss = 0.4369305469551865, disc_loss = 0.038150438428286235
Trained batch 98 in epoch 17, gen_loss = 0.4367129658207749, disc_loss = 0.03777966481713446
Trained batch 99 in epoch 17, gen_loss = 0.43695817232131956, disc_loss = 0.037424628090811894
Trained batch 100 in epoch 17, gen_loss = 0.4373950132048956, disc_loss = 0.03709748720561182
Trained batch 101 in epoch 17, gen_loss = 0.43791766026440787, disc_loss = 0.03677250659800883
Trained batch 102 in epoch 17, gen_loss = 0.4375420687268081, disc_loss = 0.036456340461634824
Trained batch 103 in epoch 17, gen_loss = 0.4378458413367088, disc_loss = 0.03612094415159216
Trained batch 104 in epoch 17, gen_loss = 0.4380873989491236, disc_loss = 0.03579707953834995
Trained batch 105 in epoch 17, gen_loss = 0.43860503665681155, disc_loss = 0.03548051606762698
Trained batch 106 in epoch 17, gen_loss = 0.43904076279880844, disc_loss = 0.03517967317945315
Trained batch 107 in epoch 17, gen_loss = 0.4390560120896057, disc_loss = 0.034880612708447084
Trained batch 108 in epoch 17, gen_loss = 0.4392968812666902, disc_loss = 0.03469001029195144
Trained batch 109 in epoch 17, gen_loss = 0.43934261121533136, disc_loss = 0.03442368616921489
Trained batch 110 in epoch 17, gen_loss = 0.4391115289013665, disc_loss = 0.03415601132416611
Trained batch 111 in epoch 17, gen_loss = 0.4397436414978334, disc_loss = 0.03391048977313663
Trained batch 112 in epoch 17, gen_loss = 0.43949113140064006, disc_loss = 0.03364981277289479
Trained batch 113 in epoch 17, gen_loss = 0.43892711296416165, disc_loss = 0.03336847464353859
Trained batch 114 in epoch 17, gen_loss = 0.4392049312591553, disc_loss = 0.03346916636674786
Trained batch 115 in epoch 17, gen_loss = 0.43968364262375337, disc_loss = 0.03326689381581924
Trained batch 116 in epoch 17, gen_loss = 0.44036512981113207, disc_loss = 0.03306850790479977
Trained batch 117 in epoch 17, gen_loss = 0.4406222496497429, disc_loss = 0.032807795736362555
Trained batch 118 in epoch 17, gen_loss = 0.4402046794650935, disc_loss = 0.0325514828608207
Trained batch 119 in epoch 17, gen_loss = 0.44018985678752265, disc_loss = 0.03229907614780435
Trained batch 120 in epoch 17, gen_loss = 0.4405473963288236, disc_loss = 0.03215994660777217
Trained batch 121 in epoch 17, gen_loss = 0.4405897618805776, disc_loss = 0.031985014489065614
Trained batch 122 in epoch 17, gen_loss = 0.44071986423275333, disc_loss = 0.031787789058568695
Trained batch 123 in epoch 17, gen_loss = 0.4408070094162418, disc_loss = 0.03155366625663104
Trained batch 124 in epoch 17, gen_loss = 0.44100582456588744, disc_loss = 0.0313177096163854
Trained batch 125 in epoch 17, gen_loss = 0.441059324476454, disc_loss = 0.031087334989385294
Trained batch 126 in epoch 17, gen_loss = 0.4413595938776422, disc_loss = 0.03089403242375115
Trained batch 127 in epoch 17, gen_loss = 0.44141574669629335, disc_loss = 0.030694222278725647
Trained batch 128 in epoch 17, gen_loss = 0.4415059865907181, disc_loss = 0.030474051231222387
Trained batch 129 in epoch 17, gen_loss = 0.44096706074017744, disc_loss = 0.03024949595923177
Trained batch 130 in epoch 17, gen_loss = 0.44157417061674686, disc_loss = 0.030034130127240283
Trained batch 131 in epoch 17, gen_loss = 0.44145131382075226, disc_loss = 0.02982332006848248
Trained batch 132 in epoch 17, gen_loss = 0.44076688554053917, disc_loss = 0.029611443732234937
Trained batch 133 in epoch 17, gen_loss = 0.44074471272639376, disc_loss = 0.029399643467092857
Trained batch 134 in epoch 17, gen_loss = 0.44034548114847255, disc_loss = 0.029231748949839837
Trained batch 135 in epoch 17, gen_loss = 0.44057953554917784, disc_loss = 0.02902504898734418
Trained batch 136 in epoch 17, gen_loss = 0.44067850165123484, disc_loss = 0.028827182660525134
Trained batch 137 in epoch 17, gen_loss = 0.4405378910942354, disc_loss = 0.028634303518523717
Trained batch 138 in epoch 17, gen_loss = 0.44027948036468284, disc_loss = 0.02844189576345677
Trained batch 139 in epoch 17, gen_loss = 0.4402154794761113, disc_loss = 0.028246123865912003
Trained batch 140 in epoch 17, gen_loss = 0.4406062030623145, disc_loss = 0.028063453283121296
Trained batch 141 in epoch 17, gen_loss = 0.44025079654136173, disc_loss = 0.027874629954400827
Trained batch 142 in epoch 17, gen_loss = 0.4400759524815566, disc_loss = 0.027690765477221956
Trained batch 143 in epoch 17, gen_loss = 0.43997414306634003, disc_loss = 0.02751070083953285
Trained batch 144 in epoch 17, gen_loss = 0.43990074437240073, disc_loss = 0.027339250920340417
Trained batch 145 in epoch 17, gen_loss = 0.43958445056660533, disc_loss = 0.027161483537271772
Trained batch 146 in epoch 17, gen_loss = 0.43963248003907757, disc_loss = 0.026986840051966308
Trained batch 147 in epoch 17, gen_loss = 0.43946784754862656, disc_loss = 0.026824577930981194
Trained batch 148 in epoch 17, gen_loss = 0.439863869407833, disc_loss = 0.026657852599703574
Trained batch 149 in epoch 17, gen_loss = 0.439415836930275, disc_loss = 0.026489133807675293
Trained batch 150 in epoch 17, gen_loss = 0.43936573136721224, disc_loss = 0.026326109538786113
Trained batch 151 in epoch 17, gen_loss = 0.4389554001390934, disc_loss = 0.026158026474724084
Trained batch 152 in epoch 17, gen_loss = 0.4391349014503504, disc_loss = 0.025996959433446522
Trained batch 153 in epoch 17, gen_loss = 0.43914312820929985, disc_loss = 0.025838286510076035
Trained batch 154 in epoch 17, gen_loss = 0.43852503741941146, disc_loss = 0.025714786543000127
Trained batch 155 in epoch 17, gen_loss = 0.43833570984693676, disc_loss = 0.025568832264234048
Trained batch 156 in epoch 17, gen_loss = 0.43849113127987854, disc_loss = 0.025417757119722426
Trained batch 157 in epoch 17, gen_loss = 0.4384620016134238, disc_loss = 0.025306518631692553
Trained batch 158 in epoch 17, gen_loss = 0.43842451471202776, disc_loss = 0.025187984914313885
Trained batch 159 in epoch 17, gen_loss = 0.43833314906805754, disc_loss = 0.025103978006518445
Trained batch 160 in epoch 17, gen_loss = 0.4382692593965471, disc_loss = 0.02495974605550168
Trained batch 161 in epoch 17, gen_loss = 0.4383712079789903, disc_loss = 0.024826617858280647
Trained batch 162 in epoch 17, gen_loss = 0.4387043445753905, disc_loss = 0.024688001400705404
Trained batch 163 in epoch 17, gen_loss = 0.4382026088310451, disc_loss = 0.024544867330582858
Trained batch 164 in epoch 17, gen_loss = 0.4380762501196428, disc_loss = 0.024403935217891227
Trained batch 165 in epoch 17, gen_loss = 0.4380230377596545, disc_loss = 0.024263085468520736
Trained batch 166 in epoch 17, gen_loss = 0.4382814463384137, disc_loss = 0.02433669855636907
Trained batch 167 in epoch 17, gen_loss = 0.4381032830902508, disc_loss = 0.024214109220858
Trained batch 168 in epoch 17, gen_loss = 0.4382066962987008, disc_loss = 0.02409663176254959
Trained batch 169 in epoch 17, gen_loss = 0.4382610855733647, disc_loss = 0.023967301279224237
Trained batch 170 in epoch 17, gen_loss = 0.43775114347363075, disc_loss = 0.023860066146753206
Trained batch 171 in epoch 17, gen_loss = 0.4371759241750074, disc_loss = 0.02373376007118739
Trained batch 172 in epoch 17, gen_loss = 0.43687227816250973, disc_loss = 0.023620460804880224
Trained batch 173 in epoch 17, gen_loss = 0.4368984783175348, disc_loss = 0.023590876119366538
Trained batch 174 in epoch 17, gen_loss = 0.43704203162874494, disc_loss = 0.02347211458919836
Trained batch 175 in epoch 17, gen_loss = 0.4369501732289791, disc_loss = 0.023607196943141225
Trained batch 176 in epoch 17, gen_loss = 0.4375459127506967, disc_loss = 0.023705291462467595
Trained batch 177 in epoch 17, gen_loss = 0.43785743264669785, disc_loss = 0.023681209444230567
Trained batch 178 in epoch 17, gen_loss = 0.4379947090615107, disc_loss = 0.023579285116528043
Trained batch 179 in epoch 17, gen_loss = 0.4382083023587863, disc_loss = 0.023564779091652277
Trained batch 180 in epoch 17, gen_loss = 0.4380402718130396, disc_loss = 0.023552048329433726
Trained batch 181 in epoch 17, gen_loss = 0.43817753860583675, disc_loss = 0.02348957892960183
Trained batch 182 in epoch 17, gen_loss = 0.4378710838614917, disc_loss = 0.02338706437928368
Trained batch 183 in epoch 17, gen_loss = 0.4377408008212629, disc_loss = 0.023284588801882066
Trained batch 184 in epoch 17, gen_loss = 0.43783692363146187, disc_loss = 0.02320159799859834
Trained batch 185 in epoch 17, gen_loss = 0.4378425305889499, disc_loss = 0.023086065385160188
Trained batch 186 in epoch 17, gen_loss = 0.4378594217453411, disc_loss = 0.022973474054124185
Trained batch 187 in epoch 17, gen_loss = 0.43760900183561, disc_loss = 0.02286715061463257
Trained batch 188 in epoch 17, gen_loss = 0.43810453285615913, disc_loss = 0.02277933851761556
Trained batch 189 in epoch 17, gen_loss = 0.4378512976985229, disc_loss = 0.022677590548501988
Trained batch 190 in epoch 17, gen_loss = 0.4383855563495796, disc_loss = 0.022572790248153722
Trained batch 191 in epoch 17, gen_loss = 0.43853200087323785, disc_loss = 0.022473262056640426
Trained batch 192 in epoch 17, gen_loss = 0.4384544443898868, disc_loss = 0.022366596745939955
Trained batch 193 in epoch 17, gen_loss = 0.43834095870711137, disc_loss = 0.02226167676319877
Trained batch 194 in epoch 17, gen_loss = 0.4380471559671255, disc_loss = 0.022155938409149457
Trained batch 195 in epoch 17, gen_loss = 0.4380922180657484, disc_loss = 0.022049548492852445
Trained batch 196 in epoch 17, gen_loss = 0.43775337268858394, disc_loss = 0.02195338625342675
Trained batch 197 in epoch 17, gen_loss = 0.437325273047794, disc_loss = 0.021855524027334393
Trained batch 198 in epoch 17, gen_loss = 0.4378131210204944, disc_loss = 0.0217684688193995
Trained batch 199 in epoch 17, gen_loss = 0.4374735313653946, disc_loss = 0.0216704212280456
Trained batch 200 in epoch 17, gen_loss = 0.43735771036859766, disc_loss = 0.02157737831446106
Trained batch 201 in epoch 17, gen_loss = 0.43758739472025693, disc_loss = 0.02148466618468819
Trained batch 202 in epoch 17, gen_loss = 0.43742304599931087, disc_loss = 0.021414354699319734
Trained batch 203 in epoch 17, gen_loss = 0.43770361238834904, disc_loss = 0.021321645943566645
Trained batch 204 in epoch 17, gen_loss = 0.43781891785016874, disc_loss = 0.021223661806661544
Trained batch 205 in epoch 17, gen_loss = 0.43789890654457425, disc_loss = 0.02112812279877298
Trained batch 206 in epoch 17, gen_loss = 0.43813200489334436, disc_loss = 0.021047913460375895
Trained batch 207 in epoch 17, gen_loss = 0.4381177310760205, disc_loss = 0.020966215934514858
Trained batch 208 in epoch 17, gen_loss = 0.4378978798263951, disc_loss = 0.020870836636577354
Trained batch 209 in epoch 17, gen_loss = 0.4380500147740046, disc_loss = 0.020782985753335412
Trained batch 210 in epoch 17, gen_loss = 0.43852859128142985, disc_loss = 0.020712851690154927
Trained batch 211 in epoch 17, gen_loss = 0.43842542691613146, disc_loss = 0.02062443475555277
Trained batch 212 in epoch 17, gen_loss = 0.4382626966971187, disc_loss = 0.021741990616518846
Trained batch 213 in epoch 17, gen_loss = 0.43773320916100084, disc_loss = 0.02207806501450522
Trained batch 214 in epoch 17, gen_loss = 0.43741460012835126, disc_loss = 0.022700615023630997
Trained batch 215 in epoch 17, gen_loss = 0.4377232963840167, disc_loss = 0.022820170904095802
Trained batch 216 in epoch 17, gen_loss = 0.43777771671796173, disc_loss = 0.022835167669927194
Trained batch 217 in epoch 17, gen_loss = 0.4378164484413392, disc_loss = 0.022772278730680637
Trained batch 218 in epoch 17, gen_loss = 0.4375624769626687, disc_loss = 0.02276054212661911
Trained batch 219 in epoch 17, gen_loss = 0.437355847927657, disc_loss = 0.022693110481751235
Trained batch 220 in epoch 17, gen_loss = 0.4374649883395407, disc_loss = 0.022637591899553843
Trained batch 221 in epoch 17, gen_loss = 0.4375832895706366, disc_loss = 0.022556733205780253
Trained batch 222 in epoch 17, gen_loss = 0.4372912765618397, disc_loss = 0.02252704391230917
Trained batch 223 in epoch 17, gen_loss = 0.43726634327322245, disc_loss = 0.02244903159277913
Trained batch 224 in epoch 17, gen_loss = 0.4371032989025116, disc_loss = 0.02239087916082806
Trained batch 225 in epoch 17, gen_loss = 0.4371624461053747, disc_loss = 0.022311797330518607
Trained batch 226 in epoch 17, gen_loss = 0.4373927965825875, disc_loss = 0.022224149168243362
Trained batch 227 in epoch 17, gen_loss = 0.4376386414494431, disc_loss = 0.02214232290249416
Trained batch 228 in epoch 17, gen_loss = 0.4375723295857292, disc_loss = 0.022064397118652167
Trained batch 229 in epoch 17, gen_loss = 0.4374859614216763, disc_loss = 0.021991691034813615
Trained batch 230 in epoch 17, gen_loss = 0.4374875639166151, disc_loss = 0.021916273079240024
Trained batch 231 in epoch 17, gen_loss = 0.4371771513131158, disc_loss = 0.021931194797647987
Trained batch 232 in epoch 17, gen_loss = 0.4372647781996256, disc_loss = 0.021866654174786077
Trained batch 233 in epoch 17, gen_loss = 0.4372139430453635, disc_loss = 0.0217996041646673
Trained batch 234 in epoch 17, gen_loss = 0.4373222603442821, disc_loss = 0.021874308129376237
Trained batch 235 in epoch 17, gen_loss = 0.4375427520628703, disc_loss = 0.022038484484517663
Trained batch 236 in epoch 17, gen_loss = 0.4377158812329739, disc_loss = 0.022268807007597154
Trained batch 237 in epoch 17, gen_loss = 0.43745585098987866, disc_loss = 0.022363673053298366
Trained batch 238 in epoch 17, gen_loss = 0.43751582727771426, disc_loss = 0.022391557852273893
Trained batch 239 in epoch 17, gen_loss = 0.43751532572011154, disc_loss = 0.02232991091926427
Trained batch 240 in epoch 17, gen_loss = 0.4372946179754012, disc_loss = 0.022913252491372563
Trained batch 241 in epoch 17, gen_loss = 0.43764309375739296, disc_loss = 0.023590047325176947
Trained batch 242 in epoch 17, gen_loss = 0.43771766414367613, disc_loss = 0.02379900874443536
Trained batch 243 in epoch 17, gen_loss = 0.43798519328969426, disc_loss = 0.023871766095103115
Trained batch 244 in epoch 17, gen_loss = 0.4382158223463565, disc_loss = 0.023852132121101023
Trained batch 245 in epoch 17, gen_loss = 0.43826509745624975, disc_loss = 0.023815602568599086
Trained batch 246 in epoch 17, gen_loss = 0.4381438765207283, disc_loss = 0.023794756241723412
Trained batch 247 in epoch 17, gen_loss = 0.43831820798016363, disc_loss = 0.023749950714597116
Trained batch 248 in epoch 17, gen_loss = 0.43858119893265535, disc_loss = 0.02382681798283385
Trained batch 249 in epoch 17, gen_loss = 0.4386439025402069, disc_loss = 0.023776057061739266
Trained batch 250 in epoch 17, gen_loss = 0.4386535702473614, disc_loss = 0.023822453003784872
Trained batch 251 in epoch 17, gen_loss = 0.43890050928744057, disc_loss = 0.023841383302443852
Trained batch 252 in epoch 17, gen_loss = 0.4388674245521485, disc_loss = 0.023793796185043313
Trained batch 253 in epoch 17, gen_loss = 0.43911275572664155, disc_loss = 0.023716132509463476
Trained batch 254 in epoch 17, gen_loss = 0.43910848171103234, disc_loss = 0.02364060920480566
Trained batch 255 in epoch 17, gen_loss = 0.4389643374597654, disc_loss = 0.023555745365683833
Trained batch 256 in epoch 17, gen_loss = 0.4388817849094302, disc_loss = 0.023571629014232192
Trained batch 257 in epoch 17, gen_loss = 0.4388637375230937, disc_loss = 0.02352682722582619
Trained batch 258 in epoch 17, gen_loss = 0.438634287781697, disc_loss = 0.023453584543616297
Trained batch 259 in epoch 17, gen_loss = 0.4387233159863032, disc_loss = 0.02337888718734925
Trained batch 260 in epoch 17, gen_loss = 0.43857138344154506, disc_loss = 0.023298876718225465
Trained batch 261 in epoch 17, gen_loss = 0.4384721474338124, disc_loss = 0.023221272126974127
Trained batch 262 in epoch 17, gen_loss = 0.4385209499429841, disc_loss = 0.02314034958782574
Trained batch 263 in epoch 17, gen_loss = 0.4384640022886522, disc_loss = 0.02307918432272731
Trained batch 264 in epoch 17, gen_loss = 0.43827239207501684, disc_loss = 0.02300220768116766
Trained batch 265 in epoch 17, gen_loss = 0.4385647533979631, disc_loss = 0.02292443028103238
Trained batch 266 in epoch 17, gen_loss = 0.43858310680710866, disc_loss = 0.02285200272109499
Trained batch 267 in epoch 17, gen_loss = 0.43809275329113007, disc_loss = 0.02278280618327753
Trained batch 268 in epoch 17, gen_loss = 0.437990276897707, disc_loss = 0.02270460252772989
Trained batch 269 in epoch 17, gen_loss = 0.43785253597630397, disc_loss = 0.022631319679957986
Trained batch 270 in epoch 17, gen_loss = 0.4376484773695689, disc_loss = 0.022554152767600085
Trained batch 271 in epoch 17, gen_loss = 0.4376148546443266, disc_loss = 0.02247763734040371
Trained batch 272 in epoch 17, gen_loss = 0.4378971055750445, disc_loss = 0.022406166415122566
Trained batch 273 in epoch 17, gen_loss = 0.43787671103529685, disc_loss = 0.022329763184304956
Trained batch 274 in epoch 17, gen_loss = 0.43787635218013415, disc_loss = 0.022253980245864526
Trained batch 275 in epoch 17, gen_loss = 0.4378517382386802, disc_loss = 0.022181768298058003
Trained batch 276 in epoch 17, gen_loss = 0.43780692357448897, disc_loss = 0.02210517581644727
Trained batch 277 in epoch 17, gen_loss = 0.437620942433961, disc_loss = 0.022035799653808714
Trained batch 278 in epoch 17, gen_loss = 0.4377406432850814, disc_loss = 0.021961985291132042
Trained batch 279 in epoch 17, gen_loss = 0.4377474419772625, disc_loss = 0.021894411375978962
Trained batch 280 in epoch 17, gen_loss = 0.4377170847828278, disc_loss = 0.021822845155631734
Trained batch 281 in epoch 17, gen_loss = 0.43772888225866546, disc_loss = 0.021757223280080666
Trained batch 282 in epoch 17, gen_loss = 0.4377805529550613, disc_loss = 0.021686036605799288
Trained batch 283 in epoch 17, gen_loss = 0.43756977731073404, disc_loss = 0.021615049761185477
Trained batch 284 in epoch 17, gen_loss = 0.4375126698560882, disc_loss = 0.02154537722215122
Trained batch 285 in epoch 17, gen_loss = 0.4374827033989913, disc_loss = 0.021475915166946663
Trained batch 286 in epoch 17, gen_loss = 0.43762183023246737, disc_loss = 0.02141041858673407
Trained batch 287 in epoch 17, gen_loss = 0.4376426360880335, disc_loss = 0.021342279614246864
Trained batch 288 in epoch 17, gen_loss = 0.4375693726910852, disc_loss = 0.021272815282176213
Trained batch 289 in epoch 17, gen_loss = 0.43757068309290653, disc_loss = 0.021206966163751124
Trained batch 290 in epoch 17, gen_loss = 0.4374852292111649, disc_loss = 0.021138082943693494
Trained batch 291 in epoch 17, gen_loss = 0.4372959410491055, disc_loss = 0.02107126696780005
Trained batch 292 in epoch 17, gen_loss = 0.43744407355175086, disc_loss = 0.021008178615170202
Trained batch 293 in epoch 17, gen_loss = 0.43746033250069133, disc_loss = 0.020942093747854867
Trained batch 294 in epoch 17, gen_loss = 0.43749622581368786, disc_loss = 0.020874513465500736
Trained batch 295 in epoch 17, gen_loss = 0.4376763164795734, disc_loss = 0.02081292262064872
Trained batch 296 in epoch 17, gen_loss = 0.437733171764849, disc_loss = 0.020747719184410842
Trained batch 297 in epoch 17, gen_loss = 0.4377759334024967, disc_loss = 0.020685117428453526
Trained batch 298 in epoch 17, gen_loss = 0.4377305721957548, disc_loss = 0.020620158639499748
Trained batch 299 in epoch 17, gen_loss = 0.43768173972765606, disc_loss = 0.020556685192277654
Trained batch 300 in epoch 17, gen_loss = 0.437726362896124, disc_loss = 0.020493580357935838
Trained batch 301 in epoch 17, gen_loss = 0.4379002409462897, disc_loss = 0.020433519188999293
Trained batch 302 in epoch 17, gen_loss = 0.43791688098372406, disc_loss = 0.020371731974664006
Trained batch 303 in epoch 17, gen_loss = 0.43781090253277827, disc_loss = 0.020309733884412134
Trained batch 304 in epoch 17, gen_loss = 0.4378308059739285, disc_loss = 0.02024645646156163
Trained batch 305 in epoch 17, gen_loss = 0.43789076590849685, disc_loss = 0.020187698432862198
Trained batch 306 in epoch 17, gen_loss = 0.43832876375521435, disc_loss = 0.020150155781962414
Trained batch 307 in epoch 17, gen_loss = 0.43831474672664295, disc_loss = 0.020089310306266508
Trained batch 308 in epoch 17, gen_loss = 0.43839878152489276, disc_loss = 0.02003171792499492
Trained batch 309 in epoch 17, gen_loss = 0.4381444617625206, disc_loss = 0.019971646662546142
Trained batch 310 in epoch 17, gen_loss = 0.43822780989373994, disc_loss = 0.019913390956720234
Trained batch 311 in epoch 17, gen_loss = 0.43830697286205417, disc_loss = 0.019852627286663614
Trained batch 312 in epoch 17, gen_loss = 0.4383263109971921, disc_loss = 0.019793031454538576
Trained batch 313 in epoch 17, gen_loss = 0.43840583684338125, disc_loss = 0.019733149210172024
Trained batch 314 in epoch 17, gen_loss = 0.4383328026249295, disc_loss = 0.019675288754811008
Trained batch 315 in epoch 17, gen_loss = 0.43834543897758554, disc_loss = 0.019617777331393284
Trained batch 316 in epoch 17, gen_loss = 0.438310567042805, disc_loss = 0.01956019522247642
Trained batch 317 in epoch 17, gen_loss = 0.4382579228225744, disc_loss = 0.019501616671841016
Trained batch 318 in epoch 17, gen_loss = 0.43834301829338074, disc_loss = 0.01944517841300603
Trained batch 319 in epoch 17, gen_loss = 0.4382651380263269, disc_loss = 0.019387296210152272
Trained batch 320 in epoch 17, gen_loss = 0.4383860496902763, disc_loss = 0.019356058612922816
Trained batch 321 in epoch 17, gen_loss = 0.4384429820390962, disc_loss = 0.01930036019698011
Trained batch 322 in epoch 17, gen_loss = 0.4383785914710432, disc_loss = 0.019246130511517877
Trained batch 323 in epoch 17, gen_loss = 0.4385317658752571, disc_loss = 0.019207236761073467
Trained batch 324 in epoch 17, gen_loss = 0.4383870723614326, disc_loss = 0.01915470540541439
Trained batch 325 in epoch 17, gen_loss = 0.43836447139459156, disc_loss = 0.019099844696230193
Trained batch 326 in epoch 17, gen_loss = 0.4383090357168005, disc_loss = 0.019052349987392816
Trained batch 327 in epoch 17, gen_loss = 0.438228329870759, disc_loss = 0.018998837923146956
Trained batch 328 in epoch 17, gen_loss = 0.4381081191964425, disc_loss = 0.01894396114606116
Trained batch 329 in epoch 17, gen_loss = 0.4381421176773129, disc_loss = 0.01889011688904385
Trained batch 330 in epoch 17, gen_loss = 0.4383619196285294, disc_loss = 0.01883927714593112
Trained batch 331 in epoch 17, gen_loss = 0.43821114606886025, disc_loss = 0.018798525229514387
Trained batch 332 in epoch 17, gen_loss = 0.43800500849703766, disc_loss = 0.01874595483892259
Trained batch 333 in epoch 17, gen_loss = 0.4379993463883143, disc_loss = 0.01869476776922813
Trained batch 334 in epoch 17, gen_loss = 0.4380432942909981, disc_loss = 0.018645447360893797
Trained batch 335 in epoch 17, gen_loss = 0.4382234074707542, disc_loss = 0.01859313060620999
Trained batch 336 in epoch 17, gen_loss = 0.438115266646405, disc_loss = 0.018547120701676394
Trained batch 337 in epoch 17, gen_loss = 0.4380591781534387, disc_loss = 0.01849700247844097
Trained batch 338 in epoch 17, gen_loss = 0.43795727742808405, disc_loss = 0.018445723271821583
Trained batch 339 in epoch 17, gen_loss = 0.4379563195740475, disc_loss = 0.01839597097817151
Trained batch 340 in epoch 17, gen_loss = 0.43801627498218393, disc_loss = 0.018345623797412055
Trained batch 341 in epoch 17, gen_loss = 0.43822894615736624, disc_loss = 0.018306952743240963
Trained batch 342 in epoch 17, gen_loss = 0.43838082866487976, disc_loss = 0.018258485206573898
Trained batch 343 in epoch 17, gen_loss = 0.4383025116525417, disc_loss = 0.01820919436719377
Trained batch 344 in epoch 17, gen_loss = 0.4383013326188792, disc_loss = 0.018160201547721373
Trained batch 345 in epoch 17, gen_loss = 0.438454834712034, disc_loss = 0.0181202992004197
Trained batch 346 in epoch 17, gen_loss = 0.43858462812577614, disc_loss = 0.01807424516527127
Trained batch 347 in epoch 17, gen_loss = 0.43865343654292754, disc_loss = 0.018033442141664826
Trained batch 348 in epoch 17, gen_loss = 0.43850591087068047, disc_loss = 0.017987581113364046
Trained batch 349 in epoch 17, gen_loss = 0.43848796350615366, disc_loss = 0.017938988787188595
Trained batch 350 in epoch 17, gen_loss = 0.43841084965273863, disc_loss = 0.017895922792791535
Trained batch 351 in epoch 17, gen_loss = 0.43844806572253053, disc_loss = 0.017850185715691292
Trained batch 352 in epoch 17, gen_loss = 0.4384132741868665, disc_loss = 0.017810025051560666
Trained batch 353 in epoch 17, gen_loss = 0.43851342713092006, disc_loss = 0.017765372517679182
Trained batch 354 in epoch 17, gen_loss = 0.43866261890236763, disc_loss = 0.017722880639280125
Trained batch 355 in epoch 17, gen_loss = 0.4387981127319711, disc_loss = 0.017677190664860034
Trained batch 356 in epoch 17, gen_loss = 0.4386698571907706, disc_loss = 0.01763012289481775
Trained batch 357 in epoch 17, gen_loss = 0.43860560588996506, disc_loss = 0.017584094750387958
Trained batch 358 in epoch 17, gen_loss = 0.4385632236687918, disc_loss = 0.01753820088260073
Trained batch 359 in epoch 17, gen_loss = 0.43861707374453546, disc_loss = 0.01749337406007625
Trained batch 360 in epoch 17, gen_loss = 0.43862113843664235, disc_loss = 0.017448764033821975
Trained batch 361 in epoch 17, gen_loss = 0.4386379818396015, disc_loss = 0.017403005930088276
Trained batch 362 in epoch 17, gen_loss = 0.4387716767544917, disc_loss = 0.01736049470459637
Trained batch 363 in epoch 17, gen_loss = 0.4387507154555111, disc_loss = 0.017317539806974088
Trained batch 364 in epoch 17, gen_loss = 0.438765628697121, disc_loss = 0.017272996994322293
Trained batch 365 in epoch 17, gen_loss = 0.43867529619261214, disc_loss = 0.01722824201401313
Trained batch 366 in epoch 17, gen_loss = 0.4388024408258599, disc_loss = 0.017187226577332036
Trained batch 367 in epoch 17, gen_loss = 0.43889359319987503, disc_loss = 0.01714378496652226
Trained batch 368 in epoch 17, gen_loss = 0.4388162333790849, disc_loss = 0.017100953863274943
Trained batch 369 in epoch 17, gen_loss = 0.4387063690133997, disc_loss = 0.01705746586950546
Trained batch 370 in epoch 17, gen_loss = 0.43862636600221905, disc_loss = 0.017013727405674584
Trained batch 371 in epoch 17, gen_loss = 0.4385070745502749, disc_loss = 0.016970237700289905
Trained batch 372 in epoch 17, gen_loss = 0.43847264952697956, disc_loss = 0.016927314657392105
Trained batch 373 in epoch 17, gen_loss = 0.4383870304268312, disc_loss = 0.016885638945919018
Trained batch 374 in epoch 17, gen_loss = 0.4386296755472819, disc_loss = 0.016844081265696635
Trained batch 375 in epoch 17, gen_loss = 0.43860046303969746, disc_loss = 0.01680158053669073
Trained batch 376 in epoch 17, gen_loss = 0.43883033638291397, disc_loss = 0.016760667658933446
Trained batch 377 in epoch 17, gen_loss = 0.43888940445329777, disc_loss = 0.016718432393784895
Trained batch 378 in epoch 17, gen_loss = 0.43885470120762143, disc_loss = 0.01668072666568647
Trained batch 379 in epoch 17, gen_loss = 0.43896451090511523, disc_loss = 0.016639110333696742
Trained batch 380 in epoch 17, gen_loss = 0.439101858714747, disc_loss = 0.016598319069371165
Trained batch 381 in epoch 17, gen_loss = 0.43897167846794527, disc_loss = 0.01655849517449244
Trained batch 382 in epoch 17, gen_loss = 0.4390746495898025, disc_loss = 0.01652149927809071
Trained batch 383 in epoch 17, gen_loss = 0.43910670358066756, disc_loss = 0.016481411236630567
Trained batch 384 in epoch 17, gen_loss = 0.43932401019257383, disc_loss = 0.016441668246648965
Trained batch 385 in epoch 17, gen_loss = 0.4393756991068934, disc_loss = 0.016402935828631164
Trained batch 386 in epoch 17, gen_loss = 0.4393842947267439, disc_loss = 0.016362687045658963
Trained batch 387 in epoch 17, gen_loss = 0.4394360151641148, disc_loss = 0.01632318935088799
Trained batch 388 in epoch 17, gen_loss = 0.43931575092680963, disc_loss = 0.016283468425466623
Trained batch 389 in epoch 17, gen_loss = 0.43921801356168894, disc_loss = 0.016244501922763166
Trained batch 390 in epoch 17, gen_loss = 0.43918742121333054, disc_loss = 0.016205706919604185
Trained batch 391 in epoch 17, gen_loss = 0.4392898711470925, disc_loss = 0.01616731433127175
Trained batch 392 in epoch 17, gen_loss = 0.43916964318612756, disc_loss = 0.016127959904041728
Trained batch 393 in epoch 17, gen_loss = 0.4390021443820847, disc_loss = 0.01608888536669801
Trained batch 394 in epoch 17, gen_loss = 0.43885348137420943, disc_loss = 0.016051329718755347
Trained batch 395 in epoch 17, gen_loss = 0.4389197253669151, disc_loss = 0.016013738706459838
Trained batch 396 in epoch 17, gen_loss = 0.4389960436286494, disc_loss = 0.015975656507769012
Trained batch 397 in epoch 17, gen_loss = 0.4389029718074367, disc_loss = 0.015941232581208716
Trained batch 398 in epoch 17, gen_loss = 0.43897269132143274, disc_loss = 0.015902888606492672
Trained batch 399 in epoch 17, gen_loss = 0.439035337343812, disc_loss = 0.01586765287342132
Trained batch 400 in epoch 17, gen_loss = 0.438973568547099, disc_loss = 0.015829885129246657
Trained batch 401 in epoch 17, gen_loss = 0.4389924734682586, disc_loss = 0.015794161126389403
Trained batch 402 in epoch 17, gen_loss = 0.4388671450816076, disc_loss = 0.01575946548873346
Trained batch 403 in epoch 17, gen_loss = 0.43890201543817425, disc_loss = 0.015724103603457874
Trained batch 404 in epoch 17, gen_loss = 0.43872462886351127, disc_loss = 0.015686985929812776
Trained batch 405 in epoch 17, gen_loss = 0.43859641444800523, disc_loss = 0.01565105728463848
Trained batch 406 in epoch 17, gen_loss = 0.4385291218611181, disc_loss = 0.015615037296462748
Trained batch 407 in epoch 17, gen_loss = 0.43845930147696943, disc_loss = 0.015580920817977613
Trained batch 408 in epoch 17, gen_loss = 0.43845717867604095, disc_loss = 0.015544721836646595
Trained batch 409 in epoch 17, gen_loss = 0.4383984594083414, disc_loss = 0.01551745607355814
Trained batch 410 in epoch 17, gen_loss = 0.43823587263587616, disc_loss = 0.015481428438095135
Trained batch 411 in epoch 17, gen_loss = 0.43805124198348777, disc_loss = 0.015446049598377939
Trained batch 412 in epoch 17, gen_loss = 0.43793422358953926, disc_loss = 0.015411621878559522
Trained batch 413 in epoch 17, gen_loss = 0.4378713229716112, disc_loss = 0.015375787513313708
Trained batch 414 in epoch 17, gen_loss = 0.43773357911282273, disc_loss = 0.015340025837572449
Trained batch 415 in epoch 17, gen_loss = 0.4377597623433058, disc_loss = 0.015304567294991172
Trained batch 416 in epoch 17, gen_loss = 0.43780656898622033, disc_loss = 0.01526940876840808
Trained batch 417 in epoch 17, gen_loss = 0.43794952988909763, disc_loss = 0.015235011009794646
Trained batch 418 in epoch 17, gen_loss = 0.43808672785189956, disc_loss = 0.015200585284968282
Trained batch 419 in epoch 17, gen_loss = 0.4380527180575189, disc_loss = 0.015167021656608475
Trained batch 420 in epoch 17, gen_loss = 0.4380706716461589, disc_loss = 0.015133044860937419
Trained batch 421 in epoch 17, gen_loss = 0.4380325953966068, disc_loss = 0.015098697049747402
Trained batch 422 in epoch 17, gen_loss = 0.43799865421955747, disc_loss = 0.015065088542288359
Trained batch 423 in epoch 17, gen_loss = 0.4379797437280979, disc_loss = 0.015031764191110785
Trained batch 424 in epoch 17, gen_loss = 0.43785918656517475, disc_loss = 0.014997918131240807
Trained batch 425 in epoch 17, gen_loss = 0.4379302109351181, disc_loss = 0.014964290278195295
Trained batch 426 in epoch 17, gen_loss = 0.43792424471372743, disc_loss = 0.014932355546448117
Trained batch 427 in epoch 17, gen_loss = 0.43782231803530847, disc_loss = 0.014899245265160826
Trained batch 428 in epoch 17, gen_loss = 0.43771476894269734, disc_loss = 0.014866686545503445
Trained batch 429 in epoch 17, gen_loss = 0.43774499886257706, disc_loss = 0.014836666207262423
Trained batch 430 in epoch 17, gen_loss = 0.4378562286807324, disc_loss = 0.014804001102383895
Trained batch 431 in epoch 17, gen_loss = 0.43773376093142563, disc_loss = 0.014774119827456566
Trained batch 432 in epoch 17, gen_loss = 0.43758256991520766, disc_loss = 0.014742338266890436
Trained batch 433 in epoch 17, gen_loss = 0.4375341673325833, disc_loss = 0.014710363397623674
Trained batch 434 in epoch 17, gen_loss = 0.43759080404522777, disc_loss = 0.014679637164594713
Trained batch 435 in epoch 17, gen_loss = 0.43762012632614977, disc_loss = 0.014647908285025234
Trained batch 436 in epoch 17, gen_loss = 0.43756852870129337, disc_loss = 0.014615896541797886
Trained batch 437 in epoch 17, gen_loss = 0.43745729204726547, disc_loss = 0.014583954185175127
Trained batch 438 in epoch 17, gen_loss = 0.4374009592793797, disc_loss = 0.014552897036341836
Trained batch 439 in epoch 17, gen_loss = 0.43735454976558685, disc_loss = 0.014522307348802728
Trained batch 440 in epoch 17, gen_loss = 0.4373467639595473, disc_loss = 0.014490804551834506
Trained batch 441 in epoch 17, gen_loss = 0.4373627917933788, disc_loss = 0.014459817692409881
Trained batch 442 in epoch 17, gen_loss = 0.43715033802975384, disc_loss = 0.014428654663805045
Trained batch 443 in epoch 17, gen_loss = 0.43716306467582516, disc_loss = 0.014397763754901904
Trained batch 444 in epoch 17, gen_loss = 0.43698353814275076, disc_loss = 0.014368217563769372
Trained batch 445 in epoch 17, gen_loss = 0.437176588872623, disc_loss = 0.014337758304741268
Trained batch 446 in epoch 17, gen_loss = 0.43710741174034357, disc_loss = 0.014308366668514774
Trained batch 447 in epoch 17, gen_loss = 0.4370517831827913, disc_loss = 0.014278263060207661
Trained batch 448 in epoch 17, gen_loss = 0.43699839346127417, disc_loss = 0.014247611574185618
Trained batch 449 in epoch 17, gen_loss = 0.43687097754743365, disc_loss = 0.014217846819406582
Trained batch 450 in epoch 17, gen_loss = 0.4369755687972659, disc_loss = 0.01419074990902253
Trained batch 451 in epoch 17, gen_loss = 0.43687800291628964, disc_loss = 0.014163586040093374
Trained batch 452 in epoch 17, gen_loss = 0.4368140264589002, disc_loss = 0.014135289993795009
Trained batch 453 in epoch 17, gen_loss = 0.4368662158035497, disc_loss = 0.014106158585090699
Trained batch 454 in epoch 17, gen_loss = 0.4368667551449367, disc_loss = 0.01407977077895059
Trained batch 455 in epoch 17, gen_loss = 0.4368264641808836, disc_loss = 0.01405058592698831
Trained batch 456 in epoch 17, gen_loss = 0.4367733974034207, disc_loss = 0.014021462020341968
Trained batch 457 in epoch 17, gen_loss = 0.4367484248621495, disc_loss = 0.013995439571371164
Trained batch 458 in epoch 17, gen_loss = 0.43679888166633307, disc_loss = 0.013966228141325622
Trained batch 459 in epoch 17, gen_loss = 0.43677689517321794, disc_loss = 0.013937156002097965
Trained batch 460 in epoch 17, gen_loss = 0.43675065564230053, disc_loss = 0.01390854939752725
Trained batch 461 in epoch 17, gen_loss = 0.4367823660115659, disc_loss = 0.013880294136596175
Trained batch 462 in epoch 17, gen_loss = 0.4366830696812459, disc_loss = 0.013852993776663719
Trained batch 463 in epoch 17, gen_loss = 0.4366601362567523, disc_loss = 0.013824805921668203
Trained batch 464 in epoch 17, gen_loss = 0.4365388140883497, disc_loss = 0.013797516842192459
Trained batch 465 in epoch 17, gen_loss = 0.4365680054661542, disc_loss = 0.01376915266929702
Trained batch 466 in epoch 17, gen_loss = 0.4364736880429041, disc_loss = 0.013741114826317541
Trained batch 467 in epoch 17, gen_loss = 0.4364195388988552, disc_loss = 0.013713351608444061
Trained batch 468 in epoch 17, gen_loss = 0.4362793102193235, disc_loss = 0.01368518691072598
Trained batch 469 in epoch 17, gen_loss = 0.43620439907337755, disc_loss = 0.013657244422938674
Trained batch 470 in epoch 17, gen_loss = 0.43600708758755097, disc_loss = 0.013629979966850971
Trained batch 471 in epoch 17, gen_loss = 0.43595392945206773, disc_loss = 0.013603796835414576
Trained batch 472 in epoch 17, gen_loss = 0.43610128331890063, disc_loss = 0.013604940185234754
Trained batch 473 in epoch 17, gen_loss = 0.4359106541560169, disc_loss = 0.013579200647716344
Trained batch 474 in epoch 17, gen_loss = 0.4358015729251661, disc_loss = 0.01355489507268526
Trained batch 475 in epoch 17, gen_loss = 0.43584779599884976, disc_loss = 0.013528743731650375
Trained batch 476 in epoch 17, gen_loss = 0.43595626356716677, disc_loss = 0.013504520116961587
Trained batch 477 in epoch 17, gen_loss = 0.4359422644062521, disc_loss = 0.013479211111212048
Trained batch 478 in epoch 17, gen_loss = 0.43603811339943793, disc_loss = 0.013453613955280616
Trained batch 479 in epoch 17, gen_loss = 0.43604855580876273, disc_loss = 0.013429655116487993
Trained batch 480 in epoch 17, gen_loss = 0.43594737254904115, disc_loss = 0.013403302580147223
Trained batch 481 in epoch 17, gen_loss = 0.43601988787720314, disc_loss = 0.013379083221045968
Trained batch 482 in epoch 17, gen_loss = 0.43597194527740557, disc_loss = 0.013352865020129405
Trained batch 483 in epoch 17, gen_loss = 0.43595219526655415, disc_loss = 0.01332633664339881
Trained batch 484 in epoch 17, gen_loss = 0.4360772290180639, disc_loss = 0.01330128084056886
Trained batch 485 in epoch 17, gen_loss = 0.4360803152308052, disc_loss = 0.013280996992185696
Trained batch 486 in epoch 17, gen_loss = 0.43617834820884455, disc_loss = 0.013258843798165495
Trained batch 487 in epoch 17, gen_loss = 0.4360507903162573, disc_loss = 0.013233481161582634
Trained batch 488 in epoch 17, gen_loss = 0.4361623206874832, disc_loss = 0.013209351047764937
Trained batch 489 in epoch 17, gen_loss = 0.43602709557328906, disc_loss = 0.013184041426070414
Trained batch 490 in epoch 17, gen_loss = 0.43592257199850687, disc_loss = 0.013159685854727968
Trained batch 491 in epoch 17, gen_loss = 0.43594230432820513, disc_loss = 0.01313469799072671
Trained batch 492 in epoch 17, gen_loss = 0.4359725997244852, disc_loss = 0.013109928241040195
Trained batch 493 in epoch 17, gen_loss = 0.43597016975223296, disc_loss = 0.013085399877241348
Trained batch 494 in epoch 17, gen_loss = 0.4358804234952638, disc_loss = 0.013061512482583033
Trained batch 495 in epoch 17, gen_loss = 0.4359551128600874, disc_loss = 0.013037271040605359
Trained batch 496 in epoch 17, gen_loss = 0.4359932736731631, disc_loss = 0.013014893440208333
Trained batch 497 in epoch 17, gen_loss = 0.4359908355287759, disc_loss = 0.012990361856961488
Trained batch 498 in epoch 17, gen_loss = 0.4359319421475779, disc_loss = 0.012965843902213989
Trained batch 499 in epoch 17, gen_loss = 0.43596278834342955, disc_loss = 0.012941171927610412
Trained batch 500 in epoch 17, gen_loss = 0.4358992232771929, disc_loss = 0.012919413892713984
Trained batch 501 in epoch 17, gen_loss = 0.43587771473652814, disc_loss = 0.012894875078927726
Trained batch 502 in epoch 17, gen_loss = 0.43582630809211353, disc_loss = 0.012872496988044803
Trained batch 503 in epoch 17, gen_loss = 0.43576870675361346, disc_loss = 0.012849847140300664
Trained batch 504 in epoch 17, gen_loss = 0.4357748880834863, disc_loss = 0.012826158686098411
Trained batch 505 in epoch 17, gen_loss = 0.4357344710190777, disc_loss = 0.0128028657401934
Trained batch 506 in epoch 17, gen_loss = 0.43581188653818015, disc_loss = 0.012779263515921797
Trained batch 507 in epoch 17, gen_loss = 0.43589733887141147, disc_loss = 0.012756420165120705
Trained batch 508 in epoch 17, gen_loss = 0.43592192780058137, disc_loss = 0.012733502127550367
Trained batch 509 in epoch 17, gen_loss = 0.435995667588477, disc_loss = 0.012710546839333998
Trained batch 510 in epoch 17, gen_loss = 0.435928766974731, disc_loss = 0.012687012890386604
Trained batch 511 in epoch 17, gen_loss = 0.4359227232635021, disc_loss = 0.01266363634181289
Trained batch 512 in epoch 17, gen_loss = 0.43588909942504256, disc_loss = 0.012640659272540034
Trained batch 513 in epoch 17, gen_loss = 0.43583776665568813, disc_loss = 0.0126177065183385
Trained batch 514 in epoch 17, gen_loss = 0.43575461223287487, disc_loss = 0.012594153162530505
Trained batch 515 in epoch 17, gen_loss = 0.43589504005372987, disc_loss = 0.012572807507465825
Trained batch 516 in epoch 17, gen_loss = 0.43571311973280324, disc_loss = 0.01255382013647246
Trained batch 517 in epoch 17, gen_loss = 0.43581776240387476, disc_loss = 0.012531909591704428
Trained batch 518 in epoch 17, gen_loss = 0.43569585233065433, disc_loss = 0.012509629888072438
Trained batch 519 in epoch 17, gen_loss = 0.4357346530144031, disc_loss = 0.01248710276771677
Trained batch 520 in epoch 17, gen_loss = 0.4358127999214202, disc_loss = 0.01246509338372017
Trained batch 521 in epoch 17, gen_loss = 0.43590359138574636, disc_loss = 0.012447792033230444
Trained batch 522 in epoch 17, gen_loss = 0.43600254453163073, disc_loss = 0.012427168279146352
Trained batch 523 in epoch 17, gen_loss = 0.43593614099134925, disc_loss = 0.012406190893393301
Trained batch 524 in epoch 17, gen_loss = 0.4358991519042424, disc_loss = 0.012383638906980021
Trained batch 525 in epoch 17, gen_loss = 0.435940137267566, disc_loss = 0.012362163270112771
Trained batch 526 in epoch 17, gen_loss = 0.4358017061195518, disc_loss = 0.012341123922667034
Trained batch 527 in epoch 17, gen_loss = 0.4358510329867854, disc_loss = 0.012319699156333545
Trained batch 528 in epoch 17, gen_loss = 0.4358113795687886, disc_loss = 0.012300886345709479
Trained batch 529 in epoch 17, gen_loss = 0.43584040707012395, disc_loss = 0.012280498638217566
Trained batch 530 in epoch 17, gen_loss = 0.4359852972452699, disc_loss = 0.012259327473400403
Trained batch 531 in epoch 17, gen_loss = 0.4359361268860057, disc_loss = 0.012237464476799543
Trained batch 532 in epoch 17, gen_loss = 0.43591436687821966, disc_loss = 0.01221579361264026
Trained batch 533 in epoch 17, gen_loss = 0.43595807533362385, disc_loss = 0.01219548719123264
Trained batch 534 in epoch 17, gen_loss = 0.43593924363082814, disc_loss = 0.01217904084288106
Trained batch 535 in epoch 17, gen_loss = 0.4358624080335026, disc_loss = 0.01215801603914892
Trained batch 536 in epoch 17, gen_loss = 0.4358692317368598, disc_loss = 0.012139049423702435
Trained batch 537 in epoch 17, gen_loss = 0.4358439903055425, disc_loss = 0.012119081120186772
Trained batch 538 in epoch 17, gen_loss = 0.4358103182408717, disc_loss = 0.0120989645508175
Trained batch 539 in epoch 17, gen_loss = 0.4358230721619394, disc_loss = 0.012079056469439011
Trained batch 540 in epoch 17, gen_loss = 0.43578345332700974, disc_loss = 0.012068828350740404
Trained batch 541 in epoch 17, gen_loss = 0.43586083669284176, disc_loss = 0.012053550964408653
Trained batch 542 in epoch 17, gen_loss = 0.4359953492934752, disc_loss = 0.012046605476579573
Trained batch 543 in epoch 17, gen_loss = 0.4359303867334829, disc_loss = 0.012030052571336616
Trained batch 544 in epoch 17, gen_loss = 0.43606063477489926, disc_loss = 0.01202026162907447
Trained batch 545 in epoch 17, gen_loss = 0.4359684705515921, disc_loss = 0.012001947295765014
Trained batch 546 in epoch 17, gen_loss = 0.4360223907221388, disc_loss = 0.012009501989064244
Trained batch 547 in epoch 17, gen_loss = 0.4359614481999926, disc_loss = 0.011991951967900564
Trained batch 548 in epoch 17, gen_loss = 0.43606785607468235, disc_loss = 0.011979085311610828
Trained batch 549 in epoch 17, gen_loss = 0.43602282475341453, disc_loss = 0.011960612840484828
Trained batch 550 in epoch 17, gen_loss = 0.43613319312595844, disc_loss = 0.011948244169755026
Trained batch 551 in epoch 17, gen_loss = 0.4362280067542325, disc_loss = 0.011931766396298992
Trained batch 552 in epoch 17, gen_loss = 0.4363794192052017, disc_loss = 0.011913715125563442
Trained batch 553 in epoch 17, gen_loss = 0.4364174980441586, disc_loss = 0.011894319488058398
Trained batch 554 in epoch 17, gen_loss = 0.43634919046281695, disc_loss = 0.01187524775961867
Trained batch 555 in epoch 17, gen_loss = 0.4362975386299675, disc_loss = 0.011856128774682168
Trained batch 556 in epoch 17, gen_loss = 0.43628085783182824, disc_loss = 0.011836975453633821
Trained batch 557 in epoch 17, gen_loss = 0.4363533934598328, disc_loss = 0.011817271234951646
Trained batch 558 in epoch 17, gen_loss = 0.436437583460151, disc_loss = 0.011798251626016788
Trained batch 559 in epoch 17, gen_loss = 0.4364830061261143, disc_loss = 0.011778866432099936
Trained batch 560 in epoch 17, gen_loss = 0.4364512607375568, disc_loss = 0.011759517006654917
Trained batch 561 in epoch 17, gen_loss = 0.4364506968717982, disc_loss = 0.011740484468293379
Trained batch 562 in epoch 17, gen_loss = 0.43642796737474404, disc_loss = 0.011721436291098508
Trained batch 563 in epoch 17, gen_loss = 0.43649025129299635, disc_loss = 0.011702497406257482
Trained batch 564 in epoch 17, gen_loss = 0.4364028533475589, disc_loss = 0.011685949478574527
Trained batch 565 in epoch 17, gen_loss = 0.4365033226173253, disc_loss = 0.011667477115375803
Trained batch 566 in epoch 17, gen_loss = 0.43658045554497465, disc_loss = 0.01164987871275124
Trained batch 567 in epoch 17, gen_loss = 0.43645812691727154, disc_loss = 0.01163191804024932
Trained batch 568 in epoch 17, gen_loss = 0.4363517352692482, disc_loss = 0.011613043586752969
Trained batch 569 in epoch 17, gen_loss = 0.43632448509074095, disc_loss = 0.011594229290596813
Trained batch 570 in epoch 17, gen_loss = 0.43631395118249067, disc_loss = 0.011576378876025317
Trained batch 571 in epoch 17, gen_loss = 0.43638140775940637, disc_loss = 0.011559340974008273
Trained batch 572 in epoch 17, gen_loss = 0.43629519643999937, disc_loss = 0.011540264829551967
Trained batch 573 in epoch 17, gen_loss = 0.43628756997892665, disc_loss = 0.011521792146462448
Trained batch 574 in epoch 17, gen_loss = 0.4362717682382335, disc_loss = 0.011506400493925194
Trained batch 575 in epoch 17, gen_loss = 0.436276678306361, disc_loss = 0.011490164460560158
Trained batch 576 in epoch 17, gen_loss = 0.4363408144466592, disc_loss = 0.011473297418811014
Trained batch 577 in epoch 17, gen_loss = 0.43638896266688115, disc_loss = 0.0114561234912827
Trained batch 578 in epoch 17, gen_loss = 0.4363547440534635, disc_loss = 0.01144093901109166
Trained batch 579 in epoch 17, gen_loss = 0.4363152741872031, disc_loss = 0.01142398006983246
Trained batch 580 in epoch 17, gen_loss = 0.43645487148667367, disc_loss = 0.011408286580832743
Trained batch 581 in epoch 17, gen_loss = 0.4363843235875323, disc_loss = 0.011390463131519124
Trained batch 582 in epoch 17, gen_loss = 0.43635132254499104, disc_loss = 0.011374989058123503
Trained batch 583 in epoch 17, gen_loss = 0.43622627609396636, disc_loss = 0.011357067753772142
Trained batch 584 in epoch 17, gen_loss = 0.43622508354676076, disc_loss = 0.011341690532087037
Trained batch 585 in epoch 17, gen_loss = 0.4362687210174144, disc_loss = 0.01132451856670561
Trained batch 586 in epoch 17, gen_loss = 0.43629997186806985, disc_loss = 0.011307178993231031
Trained batch 587 in epoch 17, gen_loss = 0.4362298354101019, disc_loss = 0.01129048420712241
Trained batch 588 in epoch 17, gen_loss = 0.4363498220723028, disc_loss = 0.011273169622923357
Trained batch 589 in epoch 17, gen_loss = 0.43651422560215, disc_loss = 0.011256214236876122
Trained batch 590 in epoch 17, gen_loss = 0.4364814099220657, disc_loss = 0.011238412599945236
Trained batch 591 in epoch 17, gen_loss = 0.43633624493471673, disc_loss = 0.011223146635382215
Trained batch 592 in epoch 17, gen_loss = 0.43634725697527044, disc_loss = 0.011205620366297065
Trained batch 593 in epoch 17, gen_loss = 0.43629756308966616, disc_loss = 0.011190410382298578
Trained batch 594 in epoch 17, gen_loss = 0.4362482869324564, disc_loss = 0.011174060090370632
Trained batch 595 in epoch 17, gen_loss = 0.43624592517446353, disc_loss = 0.011160068297442267
Trained batch 596 in epoch 17, gen_loss = 0.436250823826047, disc_loss = 0.011143316823963413
Trained batch 597 in epoch 17, gen_loss = 0.4362106600832381, disc_loss = 0.01112649312745515
Trained batch 598 in epoch 17, gen_loss = 0.4362592120500956, disc_loss = 0.011109131588448984
Trained batch 599 in epoch 17, gen_loss = 0.4362107776105404, disc_loss = 0.011091913093696348
Trained batch 600 in epoch 17, gen_loss = 0.4363181128378914, disc_loss = 0.011076014841668085
Trained batch 601 in epoch 17, gen_loss = 0.436204735474333, disc_loss = 0.011059115487661374
Trained batch 602 in epoch 17, gen_loss = 0.43631472007354494, disc_loss = 0.011045284271178455
Trained batch 603 in epoch 17, gen_loss = 0.43621432208857, disc_loss = 0.011028920192948375
Trained batch 604 in epoch 17, gen_loss = 0.43619075747560865, disc_loss = 0.011012674347990123
Trained batch 605 in epoch 17, gen_loss = 0.4362089001502928, disc_loss = 0.010996404631261595
Trained batch 606 in epoch 17, gen_loss = 0.43618117781015364, disc_loss = 0.010982030751206644
Trained batch 607 in epoch 17, gen_loss = 0.4361025583195059, disc_loss = 0.010964947222275537
Trained batch 608 in epoch 17, gen_loss = 0.43602533161346546, disc_loss = 0.010949304919576727
Trained batch 609 in epoch 17, gen_loss = 0.43594106728913357, disc_loss = 0.010934411333759362
Trained batch 610 in epoch 17, gen_loss = 0.4358614827041345, disc_loss = 0.010918759287040796
Trained batch 611 in epoch 17, gen_loss = 0.43584033364758773, disc_loss = 0.010902618569340192
Trained batch 612 in epoch 17, gen_loss = 0.43574426939398003, disc_loss = 0.010886290045223406
Trained batch 613 in epoch 17, gen_loss = 0.4357433350156107, disc_loss = 0.010869612273701743
Trained batch 614 in epoch 17, gen_loss = 0.4357083514453919, disc_loss = 0.01085321204424495
Trained batch 615 in epoch 17, gen_loss = 0.43567381441206127, disc_loss = 0.010836845414082568
Trained batch 616 in epoch 17, gen_loss = 0.4357664042199257, disc_loss = 0.010825285432759122
Trained batch 617 in epoch 17, gen_loss = 0.43574467600356415, disc_loss = 0.010810512898664644
Trained batch 618 in epoch 17, gen_loss = 0.43566858046274387, disc_loss = 0.010794608279015502
Trained batch 619 in epoch 17, gen_loss = 0.4356138874926875, disc_loss = 0.010778627124419736
Trained batch 620 in epoch 17, gen_loss = 0.4356405094337924, disc_loss = 0.010763935823122493
Trained batch 621 in epoch 17, gen_loss = 0.4356707639728712, disc_loss = 0.010747727014066748
Trained batch 622 in epoch 17, gen_loss = 0.43570827906816767, disc_loss = 0.01073209003272151
Trained batch 623 in epoch 17, gen_loss = 0.4356905800314286, disc_loss = 0.010715929245821033
Trained batch 624 in epoch 17, gen_loss = 0.4358537571430206, disc_loss = 0.010702199698239564
Trained batch 625 in epoch 17, gen_loss = 0.4359713463832776, disc_loss = 0.010687237897792612
Trained batch 626 in epoch 17, gen_loss = 0.4359230009847851, disc_loss = 0.01067446643617331
Trained batch 627 in epoch 17, gen_loss = 0.4359251530781673, disc_loss = 0.010658861376874587
Trained batch 628 in epoch 17, gen_loss = 0.4358857652625522, disc_loss = 0.010643219939430817
Trained batch 629 in epoch 17, gen_loss = 0.4357976137645661, disc_loss = 0.010629092360429082
Trained batch 630 in epoch 17, gen_loss = 0.43569300641348546, disc_loss = 0.01061407438445786
Trained batch 631 in epoch 17, gen_loss = 0.43571537902838064, disc_loss = 0.0105992151733563
Trained batch 632 in epoch 17, gen_loss = 0.43566555053136924, disc_loss = 0.010584934177903361
Trained batch 633 in epoch 17, gen_loss = 0.4356514499390539, disc_loss = 0.010569497829355293
Trained batch 634 in epoch 17, gen_loss = 0.435761676998589, disc_loss = 0.01055476590578525
Trained batch 635 in epoch 17, gen_loss = 0.4358026255976479, disc_loss = 0.01054009706111048
Trained batch 636 in epoch 17, gen_loss = 0.4358170716504287, disc_loss = 0.010534895014063874
Trained batch 637 in epoch 17, gen_loss = 0.43582634795982633, disc_loss = 0.010519766132803459
Trained batch 638 in epoch 17, gen_loss = 0.4357301484624358, disc_loss = 0.010509338669048211
Trained batch 639 in epoch 17, gen_loss = 0.43577281003817914, disc_loss = 0.010494597436718323
Trained batch 640 in epoch 17, gen_loss = 0.4358104258171296, disc_loss = 0.0104805246321884
Trained batch 641 in epoch 17, gen_loss = 0.4358350498561176, disc_loss = 0.01046705606632512
Trained batch 642 in epoch 17, gen_loss = 0.4359545545945086, disc_loss = 0.010451896383820325
Trained batch 643 in epoch 17, gen_loss = 0.4358914918873621, disc_loss = 0.010437285384869707
Trained batch 644 in epoch 17, gen_loss = 0.43596755751343663, disc_loss = 0.010424737670989491
Trained batch 645 in epoch 17, gen_loss = 0.4359682535885288, disc_loss = 0.01041029601499522
Trained batch 646 in epoch 17, gen_loss = 0.4359735885672444, disc_loss = 0.010395931625984166
Trained batch 647 in epoch 17, gen_loss = 0.4359382226787232, disc_loss = 0.010381315966595948
Trained batch 648 in epoch 17, gen_loss = 0.43606873042594485, disc_loss = 0.010374741875139626
Trained batch 649 in epoch 17, gen_loss = 0.4361159713910176, disc_loss = 0.010360107344951337
Trained batch 650 in epoch 17, gen_loss = 0.4360048752135029, disc_loss = 0.010348363169064794
Trained batch 651 in epoch 17, gen_loss = 0.43593068475737895, disc_loss = 0.010334190714799376
Trained batch 652 in epoch 17, gen_loss = 0.4358318154151005, disc_loss = 0.010319646662988973
Trained batch 653 in epoch 17, gen_loss = 0.4359294930729297, disc_loss = 0.010305290936975846
Trained batch 654 in epoch 17, gen_loss = 0.4358741213347166, disc_loss = 0.010290667521838411
Trained batch 655 in epoch 17, gen_loss = 0.4357292382728036, disc_loss = 0.010276640969273214
Trained batch 656 in epoch 17, gen_loss = 0.43574028036910106, disc_loss = 0.010263208800975001
Trained batch 657 in epoch 17, gen_loss = 0.4358227877540791, disc_loss = 0.010250546167304564
Trained batch 658 in epoch 17, gen_loss = 0.43579779531416657, disc_loss = 0.010237288664480917
Trained batch 659 in epoch 17, gen_loss = 0.43587072613564404, disc_loss = 0.010224162880684052
Trained batch 660 in epoch 17, gen_loss = 0.43589779518195254, disc_loss = 0.010210004193093994
Trained batch 661 in epoch 17, gen_loss = 0.4359058890367923, disc_loss = 0.01019599580953708
Trained batch 662 in epoch 17, gen_loss = 0.43586234301103904, disc_loss = 0.010183349451567096
Trained batch 663 in epoch 17, gen_loss = 0.43588232244533226, disc_loss = 0.010176146124189451
Trained batch 664 in epoch 17, gen_loss = 0.43592646915213507, disc_loss = 0.010162771695916702
Trained batch 665 in epoch 17, gen_loss = 0.4359680602589885, disc_loss = 0.010154037979325172
Trained batch 666 in epoch 17, gen_loss = 0.436036582516766, disc_loss = 0.010141949260096322
Trained batch 667 in epoch 17, gen_loss = 0.4360435258842514, disc_loss = 0.010130160652703332
Trained batch 668 in epoch 17, gen_loss = 0.4360718074935434, disc_loss = 0.010119624768268255
Trained batch 669 in epoch 17, gen_loss = 0.43587968954399453, disc_loss = 0.010117878204336695
Trained batch 670 in epoch 17, gen_loss = 0.4357804477481302, disc_loss = 0.01010591098858285
Trained batch 671 in epoch 17, gen_loss = 0.435724257491529, disc_loss = 0.010092296322649677
Trained batch 672 in epoch 17, gen_loss = 0.4357256018300645, disc_loss = 0.010078870439846595
Trained batch 673 in epoch 17, gen_loss = 0.43570440945710204, disc_loss = 0.010065173707627457
Trained batch 674 in epoch 17, gen_loss = 0.43568309386571247, disc_loss = 0.01005137212626222
Trained batch 675 in epoch 17, gen_loss = 0.4355676950523134, disc_loss = 0.01003833949123647
Trained batch 676 in epoch 17, gen_loss = 0.43552941229177894, disc_loss = 0.010024954186562598
Trained batch 677 in epoch 17, gen_loss = 0.43559070274365685, disc_loss = 0.01001253342039603
Trained batch 678 in epoch 17, gen_loss = 0.4356299843721432, disc_loss = 0.009999005051791965
Trained batch 679 in epoch 17, gen_loss = 0.43559798760449187, disc_loss = 0.009987458989181665
Trained batch 680 in epoch 17, gen_loss = 0.4355390201843783, disc_loss = 0.009974196985727737
Trained batch 681 in epoch 17, gen_loss = 0.4354430074828112, disc_loss = 0.009960956873387218
Trained batch 682 in epoch 17, gen_loss = 0.43545028144060083, disc_loss = 0.009947329268966002
Trained batch 683 in epoch 17, gen_loss = 0.43547362620718993, disc_loss = 0.00993384822819461
Trained batch 684 in epoch 17, gen_loss = 0.4354627638837717, disc_loss = 0.009921175415583471
Trained batch 685 in epoch 17, gen_loss = 0.43541510802837574, disc_loss = 0.009908014922772749
Trained batch 686 in epoch 17, gen_loss = 0.43540535557044474, disc_loss = 0.009895002144237023
Trained batch 687 in epoch 17, gen_loss = 0.43546086917956206, disc_loss = 0.009881710155537422
Trained batch 688 in epoch 17, gen_loss = 0.4355072253674312, disc_loss = 0.009868590622895001
Trained batch 689 in epoch 17, gen_loss = 0.4354526911092841, disc_loss = 0.009857149841348249
Trained batch 690 in epoch 17, gen_loss = 0.43549268545014125, disc_loss = 0.009843730660358931
Trained batch 691 in epoch 17, gen_loss = 0.43546596432180074, disc_loss = 0.009830633511533288
Trained batch 692 in epoch 17, gen_loss = 0.43553877977753785, disc_loss = 0.009819031908485265
Trained batch 693 in epoch 17, gen_loss = 0.43554069535533013, disc_loss = 0.009806125412976251
Trained batch 694 in epoch 17, gen_loss = 0.4354632613899039, disc_loss = 0.009793811377469557
Trained batch 695 in epoch 17, gen_loss = 0.4353911957178993, disc_loss = 0.009781239731836096
Trained batch 696 in epoch 17, gen_loss = 0.4353218069634102, disc_loss = 0.009769481064706983
Trained batch 697 in epoch 17, gen_loss = 0.435276337544351, disc_loss = 0.009757474468194381
Trained batch 698 in epoch 17, gen_loss = 0.4352401626297674, disc_loss = 0.009745224430715434
Trained batch 699 in epoch 17, gen_loss = 0.43510591660227094, disc_loss = 0.009733941918488458
Trained batch 700 in epoch 17, gen_loss = 0.43512275751239055, disc_loss = 0.009721921794976742
Trained batch 701 in epoch 17, gen_loss = 0.4351574548459121, disc_loss = 0.009709948655188035
Trained batch 702 in epoch 17, gen_loss = 0.43515442538566645, disc_loss = 0.00970021741268335
Trained batch 703 in epoch 17, gen_loss = 0.4351025332104076, disc_loss = 0.009687618361981136
Trained batch 704 in epoch 17, gen_loss = 0.4350634030416502, disc_loss = 0.009676114361690264
Trained batch 705 in epoch 17, gen_loss = 0.4350154615157724, disc_loss = 0.009663331159044232
Trained batch 706 in epoch 17, gen_loss = 0.4350753083003124, disc_loss = 0.00965068151313506
Trained batch 707 in epoch 17, gen_loss = 0.4350656725592532, disc_loss = 0.009638177579131352
Trained batch 708 in epoch 17, gen_loss = 0.4350039608387752, disc_loss = 0.009626225204412578
Trained batch 709 in epoch 17, gen_loss = 0.43511731507072987, disc_loss = 0.009618420094090946
Trained batch 710 in epoch 17, gen_loss = 0.43509326650958857, disc_loss = 0.009606663518111744
Trained batch 711 in epoch 17, gen_loss = 0.4351190858928675, disc_loss = 0.009594644452468099
Trained batch 712 in epoch 17, gen_loss = 0.43513599924252044, disc_loss = 0.009582107546324561
Trained batch 713 in epoch 17, gen_loss = 0.43507368674799174, disc_loss = 0.00957051518036337
Trained batch 714 in epoch 17, gen_loss = 0.4350666856015479, disc_loss = 0.00955797784995952
Trained batch 715 in epoch 17, gen_loss = 0.43506739663178695, disc_loss = 0.009546742331566336
Trained batch 716 in epoch 17, gen_loss = 0.4349979587844891, disc_loss = 0.009534943707834805
Trained batch 717 in epoch 17, gen_loss = 0.4349212488756206, disc_loss = 0.009524495421871828
Trained batch 718 in epoch 17, gen_loss = 0.43501166665670105, disc_loss = 0.009512969812683332
Trained batch 719 in epoch 17, gen_loss = 0.4350270756416851, disc_loss = 0.009503180905448971
Trained batch 720 in epoch 17, gen_loss = 0.43506458670355574, disc_loss = 0.009491494939202021
Trained batch 721 in epoch 17, gen_loss = 0.4350818643279353, disc_loss = 0.009481135668788348
Trained batch 722 in epoch 17, gen_loss = 0.4350885166831696, disc_loss = 0.009469026611988429
Trained batch 723 in epoch 17, gen_loss = 0.4351012893226924, disc_loss = 0.009458787890021865
Trained batch 724 in epoch 17, gen_loss = 0.43512559487901886, disc_loss = 0.009448314147343024
Trained batch 725 in epoch 17, gen_loss = 0.43516845964203194, disc_loss = 0.009436863050978893
Trained batch 726 in epoch 17, gen_loss = 0.43509071614424166, disc_loss = 0.009427780318864976
Trained batch 727 in epoch 17, gen_loss = 0.43515290115233307, disc_loss = 0.00941585265496582
Trained batch 728 in epoch 17, gen_loss = 0.43525819801335797, disc_loss = 0.009404761975424157
Trained batch 729 in epoch 17, gen_loss = 0.4351964474540867, disc_loss = 0.00939303793775377
Trained batch 730 in epoch 17, gen_loss = 0.43513653550689424, disc_loss = 0.009381648590858317
Trained batch 731 in epoch 17, gen_loss = 0.43506065328590204, disc_loss = 0.009370002349698026
Trained batch 732 in epoch 17, gen_loss = 0.43506007191266405, disc_loss = 0.009358193547468719
Trained batch 733 in epoch 17, gen_loss = 0.43510220278998485, disc_loss = 0.009346469346216907
Trained batch 734 in epoch 17, gen_loss = 0.43511752056426745, disc_loss = 0.009335757971133049
Trained batch 735 in epoch 17, gen_loss = 0.43513214009125595, disc_loss = 0.009324258719377964
Trained batch 736 in epoch 17, gen_loss = 0.4351831726739979, disc_loss = 0.009313246584260455
Trained batch 737 in epoch 17, gen_loss = 0.43511828396540025, disc_loss = 0.00930145872653674
Trained batch 738 in epoch 17, gen_loss = 0.43513309265989736, disc_loss = 0.009290118654575501
Trained batch 739 in epoch 17, gen_loss = 0.4350464217566155, disc_loss = 0.009278465888063372
Trained batch 740 in epoch 17, gen_loss = 0.43507564630907397, disc_loss = 0.009267172617328763
Trained batch 741 in epoch 17, gen_loss = 0.43502344251321656, disc_loss = 0.009255423050215643
Trained batch 742 in epoch 17, gen_loss = 0.43493710263741286, disc_loss = 0.00924390468440579
Trained batch 743 in epoch 17, gen_loss = 0.43496844004238805, disc_loss = 0.00923255891276283
Trained batch 744 in epoch 17, gen_loss = 0.4349278646027482, disc_loss = 0.00922265752068652
Trained batch 745 in epoch 17, gen_loss = 0.4349655650416264, disc_loss = 0.009211142914464582
Testing Epoch 17
Training Epoch 18
Trained batch 0 in epoch 18, gen_loss = 0.5213945508003235, disc_loss = 0.0015089433873072267
Trained batch 1 in epoch 18, gen_loss = 0.4788530766963959, disc_loss = 0.001015551039017737
Trained batch 2 in epoch 18, gen_loss = 0.4599982003370921, disc_loss = 0.0009285283158533275
Trained batch 3 in epoch 18, gen_loss = 0.4454665705561638, disc_loss = 0.0008291887497762218
Trained batch 4 in epoch 18, gen_loss = 0.4293497622013092, disc_loss = 0.0007996545289643108
Trained batch 5 in epoch 18, gen_loss = 0.42910173038641614, disc_loss = 0.0008334668915874014
Trained batch 6 in epoch 18, gen_loss = 0.41624991382871357, disc_loss = 0.0009243692121734577
Trained batch 7 in epoch 18, gen_loss = 0.4217026047408581, disc_loss = 0.0009200223939842544
Trained batch 8 in epoch 18, gen_loss = 0.4203701747788323, disc_loss = 0.0008837327865573267
Trained batch 9 in epoch 18, gen_loss = 0.42239742279052733, disc_loss = 0.000942974555073306
Trained batch 10 in epoch 18, gen_loss = 0.4235801967707547, disc_loss = 0.001039039994462986
Trained batch 11 in epoch 18, gen_loss = 0.4218523179491361, disc_loss = 0.0010497392844020699
Trained batch 12 in epoch 18, gen_loss = 0.4219905321414654, disc_loss = 0.0010503546755689268
Trained batch 13 in epoch 18, gen_loss = 0.42306967079639435, disc_loss = 0.0010132129911133753
Trained batch 14 in epoch 18, gen_loss = 0.42252057790756226, disc_loss = 0.0009839493354472022
Trained batch 15 in epoch 18, gen_loss = 0.42678987979888916, disc_loss = 0.0009710488411656115
Trained batch 16 in epoch 18, gen_loss = 0.42488856525982127, disc_loss = 0.0009500194779213737
Trained batch 17 in epoch 18, gen_loss = 0.42103543877601624, disc_loss = 0.0009319069892323265
Trained batch 18 in epoch 18, gen_loss = 0.4210073116578554, disc_loss = 0.0009118304220273307
Trained batch 19 in epoch 18, gen_loss = 0.4210652098059654, disc_loss = 0.000889275356894359
Trained batch 20 in epoch 18, gen_loss = 0.4216476536932446, disc_loss = 0.0009072204951995186
Trained batch 21 in epoch 18, gen_loss = 0.4226486357775601, disc_loss = 0.0009007954821837219
Trained batch 22 in epoch 18, gen_loss = 0.424847107866536, disc_loss = 0.0008870450648195717
Trained batch 23 in epoch 18, gen_loss = 0.4243427279094855, disc_loss = 0.0008699154447337302
Trained batch 24 in epoch 18, gen_loss = 0.4240355348587036, disc_loss = 0.0008710860577411949
Trained batch 25 in epoch 18, gen_loss = 0.4235322177410126, disc_loss = 0.0008597872555793191
Trained batch 26 in epoch 18, gen_loss = 0.42386832612532155, disc_loss = 0.0008558005491202628
Trained batch 27 in epoch 18, gen_loss = 0.4250169662492616, disc_loss = 0.0008670182599286948
Trained batch 28 in epoch 18, gen_loss = 0.4249140455805022, disc_loss = 0.0008706614607945085
Trained batch 29 in epoch 18, gen_loss = 0.42551620304584503, disc_loss = 0.0008620049920864403
Trained batch 30 in epoch 18, gen_loss = 0.42556642332384664, disc_loss = 0.000875083151303472
Trained batch 31 in epoch 18, gen_loss = 0.4253143835812807, disc_loss = 0.0008790250576566905
Trained batch 32 in epoch 18, gen_loss = 0.4251272271979939, disc_loss = 0.0008810166318929105
Trained batch 33 in epoch 18, gen_loss = 0.42506731082411375, disc_loss = 0.0008785475887741675
Trained batch 34 in epoch 18, gen_loss = 0.42596158640725273, disc_loss = 0.0008755144197493791
Trained batch 35 in epoch 18, gen_loss = 0.4258241173293855, disc_loss = 0.0008929517579316678
Trained batch 36 in epoch 18, gen_loss = 0.42509841838398493, disc_loss = 0.0008895056073654543
Trained batch 37 in epoch 18, gen_loss = 0.42324400967673254, disc_loss = 0.0008824323288679711
Trained batch 38 in epoch 18, gen_loss = 0.4222518625931862, disc_loss = 0.000886068433129157
Trained batch 39 in epoch 18, gen_loss = 0.4233688436448574, disc_loss = 0.0008985533015220426
Trained batch 40 in epoch 18, gen_loss = 0.4246288494365971, disc_loss = 0.0008915642307639667
Trained batch 41 in epoch 18, gen_loss = 0.42487589660144987, disc_loss = 0.0008935626884478898
Trained batch 42 in epoch 18, gen_loss = 0.42607573852982633, disc_loss = 0.0008941348669184155
Trained batch 43 in epoch 18, gen_loss = 0.42758465626023034, disc_loss = 0.000899292769397355
Trained batch 44 in epoch 18, gen_loss = 0.42705661985609267, disc_loss = 0.0009142571206515034
Trained batch 45 in epoch 18, gen_loss = 0.4285137705180956, disc_loss = 0.0009157756652237605
Trained batch 46 in epoch 18, gen_loss = 0.42792795059528754, disc_loss = 0.0009178808280960359
Trained batch 47 in epoch 18, gen_loss = 0.4278370725611846, disc_loss = 0.0009180221289473897
Trained batch 48 in epoch 18, gen_loss = 0.4268616097314017, disc_loss = 0.0009085959101532947
Trained batch 49 in epoch 18, gen_loss = 0.4259528857469559, disc_loss = 0.0009026538766920566
Trained batch 50 in epoch 18, gen_loss = 0.426983013456943, disc_loss = 0.0009102293874557112
Trained batch 51 in epoch 18, gen_loss = 0.428243708725159, disc_loss = 0.0009084423867394575
Trained batch 52 in epoch 18, gen_loss = 0.42734073636666786, disc_loss = 0.0009097193108590425
Trained batch 53 in epoch 18, gen_loss = 0.42709731227821773, disc_loss = 0.0009017198926476003
Trained batch 54 in epoch 18, gen_loss = 0.4265939712524414, disc_loss = 0.0008949551106938584
Trained batch 55 in epoch 18, gen_loss = 0.4264640451541969, disc_loss = 0.0008870572273735888
Trained batch 56 in epoch 18, gen_loss = 0.42694694431204544, disc_loss = 0.000883040313502741
Trained batch 57 in epoch 18, gen_loss = 0.4277219679848901, disc_loss = 0.0008841938216736989
Trained batch 58 in epoch 18, gen_loss = 0.42755481550249, disc_loss = 0.0008796007023192942
Trained batch 59 in epoch 18, gen_loss = 0.42696425716082254, disc_loss = 0.0008848781823568667
Trained batch 60 in epoch 18, gen_loss = 0.4268722553722194, disc_loss = 0.000879739541903932
Trained batch 61 in epoch 18, gen_loss = 0.42646858576805363, disc_loss = 0.000873556220716226
Trained batch 62 in epoch 18, gen_loss = 0.42668024888114325, disc_loss = 0.0008674925987771343
Trained batch 63 in epoch 18, gen_loss = 0.4273535585962236, disc_loss = 0.000863910394400591
Trained batch 64 in epoch 18, gen_loss = 0.42781360378632177, disc_loss = 0.0008581622512652897
Trained batch 65 in epoch 18, gen_loss = 0.4275948951641719, disc_loss = 0.0008579862602125628
Trained batch 66 in epoch 18, gen_loss = 0.4280422369935619, disc_loss = 0.0008540932973499284
Trained batch 67 in epoch 18, gen_loss = 0.42835009711630206, disc_loss = 0.0008649587475434493
Trained batch 68 in epoch 18, gen_loss = 0.42834049463272095, disc_loss = 0.0008618394629962311
Trained batch 69 in epoch 18, gen_loss = 0.42850716624941143, disc_loss = 0.0008594856622429299
Trained batch 70 in epoch 18, gen_loss = 0.42901346675107177, disc_loss = 0.0008558156534465371
Trained batch 71 in epoch 18, gen_loss = 0.43025747645232415, disc_loss = 0.0008542997634827367
Trained batch 72 in epoch 18, gen_loss = 0.430040470949591, disc_loss = 0.000851666270946599
Trained batch 73 in epoch 18, gen_loss = 0.4304689543472754, disc_loss = 0.0008516582185276658
Trained batch 74 in epoch 18, gen_loss = 0.43114315032958983, disc_loss = 0.0008519541029818356
Trained batch 75 in epoch 18, gen_loss = 0.4314622780994365, disc_loss = 0.0008556328087395645
Trained batch 76 in epoch 18, gen_loss = 0.4314176111252277, disc_loss = 0.0008500760614678457
Trained batch 77 in epoch 18, gen_loss = 0.43127289911111194, disc_loss = 0.0008471910199986246
Trained batch 78 in epoch 18, gen_loss = 0.43089682920069633, disc_loss = 0.0008465901107079337
Trained batch 79 in epoch 18, gen_loss = 0.4304135710000992, disc_loss = 0.0008432020244072191
Trained batch 80 in epoch 18, gen_loss = 0.4299645287755095, disc_loss = 0.0008377538409003597
Trained batch 81 in epoch 18, gen_loss = 0.42919462955579524, disc_loss = 0.0008412349533301029
Trained batch 82 in epoch 18, gen_loss = 0.42868351828621093, disc_loss = 0.000837882772419063
Trained batch 83 in epoch 18, gen_loss = 0.42893128593762714, disc_loss = 0.000838651218579062
Trained batch 84 in epoch 18, gen_loss = 0.42864630187259, disc_loss = 0.0008389723329695271
Trained batch 85 in epoch 18, gen_loss = 0.4283591917780943, disc_loss = 0.000833921131087727
Trained batch 86 in epoch 18, gen_loss = 0.4282318822953893, disc_loss = 0.0008376534772640758
Trained batch 87 in epoch 18, gen_loss = 0.42865595255385747, disc_loss = 0.0008362633518779396
Trained batch 88 in epoch 18, gen_loss = 0.4286001669556907, disc_loss = 0.0008362399798744683
Trained batch 89 in epoch 18, gen_loss = 0.428538911541303, disc_loss = 0.000838812263423784
Trained batch 90 in epoch 18, gen_loss = 0.42856585193466357, disc_loss = 0.0008389586083857077
Trained batch 91 in epoch 18, gen_loss = 0.4291983901158623, disc_loss = 0.0008379871603961953
Trained batch 92 in epoch 18, gen_loss = 0.4287805172704881, disc_loss = 0.0008364447451356838
Trained batch 93 in epoch 18, gen_loss = 0.4292426844860645, disc_loss = 0.0008411824578132004
Trained batch 94 in epoch 18, gen_loss = 0.42847232097073606, disc_loss = 0.0008401351453932492
Trained batch 95 in epoch 18, gen_loss = 0.42864006012678146, disc_loss = 0.0008405517619394232
Trained batch 96 in epoch 18, gen_loss = 0.4281002777753417, disc_loss = 0.0008382319998399345
Trained batch 97 in epoch 18, gen_loss = 0.42850090806581537, disc_loss = 0.0008360894850683304
Trained batch 98 in epoch 18, gen_loss = 0.4287368724442492, disc_loss = 0.0008421451573006132
Trained batch 99 in epoch 18, gen_loss = 0.42904754877090456, disc_loss = 0.0008395369292702525
Trained batch 100 in epoch 18, gen_loss = 0.42951020922991306, disc_loss = 0.0015124566426574445
Trained batch 101 in epoch 18, gen_loss = 0.4284863732024735, disc_loss = 0.0019141561568568589
Trained batch 102 in epoch 18, gen_loss = 0.42746311397228426, disc_loss = 0.0034687195314564608
Trained batch 103 in epoch 18, gen_loss = 0.42804234904738575, disc_loss = 0.00421059951342893
Trained batch 104 in epoch 18, gen_loss = 0.4277126300902594, disc_loss = 0.0044661564785721045
Trained batch 105 in epoch 18, gen_loss = 0.4271263244017115, disc_loss = 0.00451012246886198
Trained batch 106 in epoch 18, gen_loss = 0.42696497512754994, disc_loss = 0.004569233259160037
Trained batch 107 in epoch 18, gen_loss = 0.4268024053286623, disc_loss = 0.004611407918639964
Trained batch 108 in epoch 18, gen_loss = 0.4262888092513478, disc_loss = 0.0048397676538624755
Trained batch 109 in epoch 18, gen_loss = 0.42708871960639955, disc_loss = 0.005082376634659754
Trained batch 110 in epoch 18, gen_loss = 0.42776695994643477, disc_loss = 0.005088177000944343
Trained batch 111 in epoch 18, gen_loss = 0.4281327559479645, disc_loss = 0.00507169704048595
Trained batch 112 in epoch 18, gen_loss = 0.42829019253232836, disc_loss = 0.0050484327201739745
Trained batch 113 in epoch 18, gen_loss = 0.4280965226261239, disc_loss = 0.005464761774259897
Trained batch 114 in epoch 18, gen_loss = 0.4278246638567551, disc_loss = 0.005562114192213377
Trained batch 115 in epoch 18, gen_loss = 0.42759476242394284, disc_loss = 0.0055736657302296756
Trained batch 116 in epoch 18, gen_loss = 0.4276343759817955, disc_loss = 0.005674127894294504
Trained batch 117 in epoch 18, gen_loss = 0.4286725750919116, disc_loss = 0.005670181865275095
Trained batch 118 in epoch 18, gen_loss = 0.4290116233985965, disc_loss = 0.005663801057992049
Trained batch 119 in epoch 18, gen_loss = 0.42928467790285746, disc_loss = 0.00563844458568686
Trained batch 120 in epoch 18, gen_loss = 0.4295233626010989, disc_loss = 0.005610917509179409
Trained batch 121 in epoch 18, gen_loss = 0.42981493986043773, disc_loss = 0.0055850887848598665
Trained batch 122 in epoch 18, gen_loss = 0.4297381380224616, disc_loss = 0.005565123705428124
Trained batch 123 in epoch 18, gen_loss = 0.42993563677995433, disc_loss = 0.0056749374066825
Trained batch 124 in epoch 18, gen_loss = 0.4302034480571747, disc_loss = 0.005756738361902535
Trained batch 125 in epoch 18, gen_loss = 0.4298388690702499, disc_loss = 0.006016148576727285
Trained batch 126 in epoch 18, gen_loss = 0.43005383742137215, disc_loss = 0.00633640765986134
Trained batch 127 in epoch 18, gen_loss = 0.430794007377699, disc_loss = 0.008782519053966098
Trained batch 128 in epoch 18, gen_loss = 0.4301289045071417, disc_loss = 0.009246398800399241
Trained batch 129 in epoch 18, gen_loss = 0.42950938504475816, disc_loss = 0.011027256941172079
Trained batch 130 in epoch 18, gen_loss = 0.4296754223244791, disc_loss = 0.013991530526976834
Trained batch 131 in epoch 18, gen_loss = 0.4291283233147679, disc_loss = 0.014069088844928157
Trained batch 132 in epoch 18, gen_loss = 0.4289329721963495, disc_loss = 0.014439091615946054
Trained batch 133 in epoch 18, gen_loss = 0.4291228338408826, disc_loss = 0.014553198060055556
Trained batch 134 in epoch 18, gen_loss = 0.42885207644215334, disc_loss = 0.01468378379682286
Trained batch 135 in epoch 18, gen_loss = 0.4288400326143293, disc_loss = 0.01464899536650217
Trained batch 136 in epoch 18, gen_loss = 0.42848523211305156, disc_loss = 0.014579025098041081
Trained batch 137 in epoch 18, gen_loss = 0.42854422525219293, disc_loss = 0.014513153964957304
Trained batch 138 in epoch 18, gen_loss = 0.4284212186182146, disc_loss = 0.01443627151818075
Trained batch 139 in epoch 18, gen_loss = 0.4290159778935569, disc_loss = 0.014355778931141166
Trained batch 140 in epoch 18, gen_loss = 0.4289809522476602, disc_loss = 0.014272700900258166
Trained batch 141 in epoch 18, gen_loss = 0.42879702066871483, disc_loss = 0.014183975043739389
Trained batch 142 in epoch 18, gen_loss = 0.4284924104080334, disc_loss = 0.014096826129312907
Trained batch 143 in epoch 18, gen_loss = 0.42902190507286125, disc_loss = 0.014013228731022941
Trained batch 144 in epoch 18, gen_loss = 0.4291254275831683, disc_loss = 0.01394358988979767
Trained batch 145 in epoch 18, gen_loss = 0.42905690776158684, disc_loss = 0.013857254300789577
Trained batch 146 in epoch 18, gen_loss = 0.4290856510198035, disc_loss = 0.013775481531225448
Trained batch 147 in epoch 18, gen_loss = 0.42868196642076645, disc_loss = 0.013696955478391485
Trained batch 148 in epoch 18, gen_loss = 0.42877564174216865, disc_loss = 0.013619967868345345
Trained batch 149 in epoch 18, gen_loss = 0.42947360277175906, disc_loss = 0.013547021222766489
Trained batch 150 in epoch 18, gen_loss = 0.429675224995771, disc_loss = 0.01346978456142747
Trained batch 151 in epoch 18, gen_loss = 0.4295175753925976, disc_loss = 0.013391502488766013
Trained batch 152 in epoch 18, gen_loss = 0.4297727732097401, disc_loss = 0.013319914417152651
Trained batch 153 in epoch 18, gen_loss = 0.429901857074205, disc_loss = 0.013252362658045944
Trained batch 154 in epoch 18, gen_loss = 0.42935610875006647, disc_loss = 0.01317722091616522
Trained batch 155 in epoch 18, gen_loss = 0.42928817256903035, disc_loss = 0.013176481713367721
Trained batch 156 in epoch 18, gen_loss = 0.4289973359199087, disc_loss = 0.013275939113294385
Trained batch 157 in epoch 18, gen_loss = 0.42949743851830685, disc_loss = 0.013332544574720337
Trained batch 158 in epoch 18, gen_loss = 0.429370291577945, disc_loss = 0.013270558290763424
Trained batch 159 in epoch 18, gen_loss = 0.4290509060025215, disc_loss = 0.013208907978696515
Trained batch 160 in epoch 18, gen_loss = 0.4288330098486835, disc_loss = 0.013349105386346902
Trained batch 161 in epoch 18, gen_loss = 0.4288614265344761, disc_loss = 0.013286620251299744
Trained batch 162 in epoch 18, gen_loss = 0.4286695014845374, disc_loss = 0.013309171251192735
Trained batch 163 in epoch 18, gen_loss = 0.428608448948802, disc_loss = 0.013258099416128882
Trained batch 164 in epoch 18, gen_loss = 0.4289569574775118, disc_loss = 0.013634150629778477
Trained batch 165 in epoch 18, gen_loss = 0.4291417135531644, disc_loss = 0.013839648898371148
Trained batch 166 in epoch 18, gen_loss = 0.4286654935982413, disc_loss = 0.013912562600861187
Trained batch 167 in epoch 18, gen_loss = 0.428858750632831, disc_loss = 0.014099063359372806
Trained batch 168 in epoch 18, gen_loss = 0.42924968448616346, disc_loss = 0.014203276911601644
Trained batch 169 in epoch 18, gen_loss = 0.4296116753536112, disc_loss = 0.014167447751798831
Trained batch 170 in epoch 18, gen_loss = 0.42992292126716924, disc_loss = 0.014451499148108587
Trained batch 171 in epoch 18, gen_loss = 0.43035181940988054, disc_loss = 0.01486137393675203
Trained batch 172 in epoch 18, gen_loss = 0.4301737007722689, disc_loss = 0.01480194670215486
Trained batch 173 in epoch 18, gen_loss = 0.4298641847810526, disc_loss = 0.014826165578440475
Trained batch 174 in epoch 18, gen_loss = 0.42988040276936124, disc_loss = 0.01481053396194641
Trained batch 175 in epoch 18, gen_loss = 0.4301031131974675, disc_loss = 0.014912771941453684
Trained batch 176 in epoch 18, gen_loss = 0.4309876576318579, disc_loss = 0.01495994039413935
Trained batch 177 in epoch 18, gen_loss = 0.4315846235899443, disc_loss = 0.014957822829856422
Trained batch 178 in epoch 18, gen_loss = 0.4319522166052344, disc_loss = 0.014906205462588404
Trained batch 179 in epoch 18, gen_loss = 0.43230104827218585, disc_loss = 0.014839957994020854
Trained batch 180 in epoch 18, gen_loss = 0.43287143144159684, disc_loss = 0.01481908124817525
Trained batch 181 in epoch 18, gen_loss = 0.43252168399292035, disc_loss = 0.015151712688448542
Trained batch 182 in epoch 18, gen_loss = 0.43220831315374114, disc_loss = 0.015150044106399956
Trained batch 183 in epoch 18, gen_loss = 0.43184776749947795, disc_loss = 0.015093475168332983
Trained batch 184 in epoch 18, gen_loss = 0.4318660194809372, disc_loss = 0.015029542606852546
Trained batch 185 in epoch 18, gen_loss = 0.4318318807630129, disc_loss = 0.01497450077428072
Trained batch 186 in epoch 18, gen_loss = 0.43184817777597967, disc_loss = 0.014912592104566408
Trained batch 187 in epoch 18, gen_loss = 0.43179312126433594, disc_loss = 0.014840926968200292
Trained batch 188 in epoch 18, gen_loss = 0.43136917425211146, disc_loss = 0.014773240067168243
Trained batch 189 in epoch 18, gen_loss = 0.43125900343844764, disc_loss = 0.014710464468838549
Trained batch 190 in epoch 18, gen_loss = 0.43132113989111015, disc_loss = 0.014651720661362779
Trained batch 191 in epoch 18, gen_loss = 0.4316065496144195, disc_loss = 0.014584816147059124
Trained batch 192 in epoch 18, gen_loss = 0.4315706942365577, disc_loss = 0.014517030178043277
Trained batch 193 in epoch 18, gen_loss = 0.43144271484355334, disc_loss = 0.014450113936543427
Trained batch 194 in epoch 18, gen_loss = 0.43158300595405774, disc_loss = 0.014387469200823361
Trained batch 195 in epoch 18, gen_loss = 0.4317223300435105, disc_loss = 0.014337078085506563
Trained batch 196 in epoch 18, gen_loss = 0.4315422602413875, disc_loss = 0.014276158656135466
Trained batch 197 in epoch 18, gen_loss = 0.4316040894599876, disc_loss = 0.014261654338851158
Trained batch 198 in epoch 18, gen_loss = 0.43118552841133806, disc_loss = 0.015360505994638644
Trained batch 199 in epoch 18, gen_loss = 0.4319326733052731, disc_loss = 0.016249338943162002
Trained batch 200 in epoch 18, gen_loss = 0.43178109194508835, disc_loss = 0.016297982983054845
Trained batch 201 in epoch 18, gen_loss = 0.43161305858947263, disc_loss = 0.01628740494759606
Trained batch 202 in epoch 18, gen_loss = 0.4312446609212847, disc_loss = 0.01738759348217141
Trained batch 203 in epoch 18, gen_loss = 0.43147440912092433, disc_loss = 0.017491704634249247
Trained batch 204 in epoch 18, gen_loss = 0.4318473913320681, disc_loss = 0.017647318138241223
Trained batch 205 in epoch 18, gen_loss = 0.43159746082083694, disc_loss = 0.017699569550193667
Trained batch 206 in epoch 18, gen_loss = 0.4316710435249955, disc_loss = 0.017656788918873574
Trained batch 207 in epoch 18, gen_loss = 0.43175474081475, disc_loss = 0.017672558857436974
Trained batch 208 in epoch 18, gen_loss = 0.431546151638031, disc_loss = 0.01777498855903905
Trained batch 209 in epoch 18, gen_loss = 0.4314500019663856, disc_loss = 0.018046816975610065
Trained batch 210 in epoch 18, gen_loss = 0.43169550392865, disc_loss = 0.021194997208824125
Trained batch 211 in epoch 18, gen_loss = 0.43161181880618044, disc_loss = 0.02154938813863445
Trained batch 212 in epoch 18, gen_loss = 0.43142032819174825, disc_loss = 0.02195832578021543
Trained batch 213 in epoch 18, gen_loss = 0.4314610079348644, disc_loss = 0.02216328378107451
Trained batch 214 in epoch 18, gen_loss = 0.4311786693195964, disc_loss = 0.022517253740604013
Trained batch 215 in epoch 18, gen_loss = 0.4313001047681879, disc_loss = 0.02254020825892911
Trained batch 216 in epoch 18, gen_loss = 0.43121933593728023, disc_loss = 0.02251643397843182
Trained batch 217 in epoch 18, gen_loss = 0.4309984870733471, disc_loss = 0.02255701260489557
Trained batch 218 in epoch 18, gen_loss = 0.43126686005831855, disc_loss = 0.022536580221723237
Trained batch 219 in epoch 18, gen_loss = 0.4312419764020226, disc_loss = 0.022496922344329175
Trained batch 220 in epoch 18, gen_loss = 0.43110710881414455, disc_loss = 0.023047972281412876
Trained batch 221 in epoch 18, gen_loss = 0.43135013894454854, disc_loss = 0.024750074519050046
Trained batch 222 in epoch 18, gen_loss = 0.4313685884657462, disc_loss = 0.02547876726921581
Trained batch 223 in epoch 18, gen_loss = 0.4312824678740331, disc_loss = 0.025943862969143083
Trained batch 224 in epoch 18, gen_loss = 0.4310329602824317, disc_loss = 0.026470357672725285
Trained batch 225 in epoch 18, gen_loss = 0.43090164714154944, disc_loss = 0.027044998231010132
Trained batch 226 in epoch 18, gen_loss = 0.43086562440258813, disc_loss = 0.027095287788499327
Trained batch 227 in epoch 18, gen_loss = 0.43098509625384684, disc_loss = 0.0274611616536787
Trained batch 228 in epoch 18, gen_loss = 0.4308695851715371, disc_loss = 0.02754425756505174
Trained batch 229 in epoch 18, gen_loss = 0.4307671027339023, disc_loss = 0.02758081086921384
Trained batch 230 in epoch 18, gen_loss = 0.43066887357534267, disc_loss = 0.027641031355395494
Trained batch 231 in epoch 18, gen_loss = 0.43100106086710405, disc_loss = 0.028009691593289407
Trained batch 232 in epoch 18, gen_loss = 0.43108505368744354, disc_loss = 0.02810062570027735
Trained batch 233 in epoch 18, gen_loss = 0.4306942919890086, disc_loss = 0.028103585017180372
Trained batch 234 in epoch 18, gen_loss = 0.43071828332353146, disc_loss = 0.028098121083817106
Trained batch 235 in epoch 18, gen_loss = 0.4307454259971441, disc_loss = 0.02800074304795382
Trained batch 236 in epoch 18, gen_loss = 0.43103028538357857, disc_loss = 0.027901280772054907
Trained batch 237 in epoch 18, gen_loss = 0.43112987304935935, disc_loss = 0.028022712666420032
Trained batch 238 in epoch 18, gen_loss = 0.43129210965902737, disc_loss = 0.0281080695314364
Trained batch 239 in epoch 18, gen_loss = 0.4313802018761635, disc_loss = 0.02803056688523308
Trained batch 240 in epoch 18, gen_loss = 0.43160916166186825, disc_loss = 0.027929862336587948
Trained batch 241 in epoch 18, gen_loss = 0.4316838001909335, disc_loss = 0.027884897384850293
Trained batch 242 in epoch 18, gen_loss = 0.43170455122680823, disc_loss = 0.027789338728999375
Trained batch 243 in epoch 18, gen_loss = 0.43180631992758295, disc_loss = 0.02768487095323269
Trained batch 244 in epoch 18, gen_loss = 0.43150912985509754, disc_loss = 0.027608911387565337
Trained batch 245 in epoch 18, gen_loss = 0.4314648695592958, disc_loss = 0.027509200594452308
Trained batch 246 in epoch 18, gen_loss = 0.4315785944220508, disc_loss = 0.02741221626438125
Trained batch 247 in epoch 18, gen_loss = 0.43131262088014233, disc_loss = 0.02730966223856329
Trained batch 248 in epoch 18, gen_loss = 0.43142919368054494, disc_loss = 0.027206157886771012
Trained batch 249 in epoch 18, gen_loss = 0.4314298536777496, disc_loss = 0.02731825043540448
Trained batch 250 in epoch 18, gen_loss = 0.43083851045346355, disc_loss = 0.027265606250472932
Trained batch 251 in epoch 18, gen_loss = 0.4307603555775824, disc_loss = 0.027218191850272612
Trained batch 252 in epoch 18, gen_loss = 0.43077197529581696, disc_loss = 0.027126991608743316
Trained batch 253 in epoch 18, gen_loss = 0.4306756531394373, disc_loss = 0.02703425748911723
Trained batch 254 in epoch 18, gen_loss = 0.4304636275067049, disc_loss = 0.026965320218062284
Trained batch 255 in epoch 18, gen_loss = 0.43047042458783835, disc_loss = 0.026947070195092238
Trained batch 256 in epoch 18, gen_loss = 0.4305314509785129, disc_loss = 0.026955145036127663
Trained batch 257 in epoch 18, gen_loss = 0.4306776948677477, disc_loss = 0.026875998990884584
Trained batch 258 in epoch 18, gen_loss = 0.43090788657600815, disc_loss = 0.026971387666107145
Trained batch 259 in epoch 18, gen_loss = 0.4308482562120144, disc_loss = 0.027207270400741924
Trained batch 260 in epoch 18, gen_loss = 0.43108446056815397, disc_loss = 0.027354414114493065
Trained batch 261 in epoch 18, gen_loss = 0.43124313504641293, disc_loss = 0.028568151023039837
Trained batch 262 in epoch 18, gen_loss = 0.43132758446519365, disc_loss = 0.028517632281315645
Trained batch 263 in epoch 18, gen_loss = 0.4312741815140753, disc_loss = 0.028817717458657695
Trained batch 264 in epoch 18, gen_loss = 0.4314384006104379, disc_loss = 0.028842803280589715
Trained batch 265 in epoch 18, gen_loss = 0.43165308640415506, disc_loss = 0.0290493363570562
Trained batch 266 in epoch 18, gen_loss = 0.43125579174091755, disc_loss = 0.029307184964139362
Trained batch 267 in epoch 18, gen_loss = 0.4316167357697416, disc_loss = 0.030574465900270353
Trained batch 268 in epoch 18, gen_loss = 0.4315828787349857, disc_loss = 0.03076416351676652
Trained batch 269 in epoch 18, gen_loss = 0.4317305600201642, disc_loss = 0.03090209854007871
Trained batch 270 in epoch 18, gen_loss = 0.431595226275525, disc_loss = 0.030814624623467672
Trained batch 271 in epoch 18, gen_loss = 0.43162981245447607, disc_loss = 0.030894712122116127
Trained batch 272 in epoch 18, gen_loss = 0.4318701723119715, disc_loss = 0.031128321445100145
Trained batch 273 in epoch 18, gen_loss = 0.43196700720021325, disc_loss = 0.031072812027427076
Trained batch 274 in epoch 18, gen_loss = 0.43179687044837256, disc_loss = 0.0310076520439576
Trained batch 275 in epoch 18, gen_loss = 0.4318933949090432, disc_loss = 0.030946058489422758
Trained batch 276 in epoch 18, gen_loss = 0.4319269265508824, disc_loss = 0.03096416607223424
Trained batch 277 in epoch 18, gen_loss = 0.4317436726402036, disc_loss = 0.030974832100445313
Trained batch 278 in epoch 18, gen_loss = 0.43168719994124544, disc_loss = 0.030906559670791298
Trained batch 279 in epoch 18, gen_loss = 0.4314210541546345, disc_loss = 0.03149299028695428
Trained batch 280 in epoch 18, gen_loss = 0.4314920061211569, disc_loss = 0.03161168775067157
Trained batch 281 in epoch 18, gen_loss = 0.4314101346841095, disc_loss = 0.03154323665352525
Trained batch 282 in epoch 18, gen_loss = 0.4314643173040855, disc_loss = 0.031564282172757724
Trained batch 283 in epoch 18, gen_loss = 0.43138275925122516, disc_loss = 0.03188445982293711
Trained batch 284 in epoch 18, gen_loss = 0.4315629127778505, disc_loss = 0.03179573104471752
Trained batch 285 in epoch 18, gen_loss = 0.4317811716061372, disc_loss = 0.031858331662231495
Trained batch 286 in epoch 18, gen_loss = 0.4318965875936302, disc_loss = 0.031768085923409316
Trained batch 287 in epoch 18, gen_loss = 0.4319972832583719, disc_loss = 0.03170838739121488
Trained batch 288 in epoch 18, gen_loss = 0.4322808110590212, disc_loss = 0.03161197485060634
Trained batch 289 in epoch 18, gen_loss = 0.43223735484583625, disc_loss = 0.03152115845667391
Trained batch 290 in epoch 18, gen_loss = 0.43234822645629806, disc_loss = 0.03147434022380007
Trained batch 291 in epoch 18, gen_loss = 0.43242676607141756, disc_loss = 0.032064633689540094
Trained batch 292 in epoch 18, gen_loss = 0.4323467674312331, disc_loss = 0.032868509778415995
Trained batch 293 in epoch 18, gen_loss = 0.4320941788404166, disc_loss = 0.03326021242874111
Trained batch 294 in epoch 18, gen_loss = 0.4320556841664395, disc_loss = 0.03346128924986569
Trained batch 295 in epoch 18, gen_loss = 0.43187109763557846, disc_loss = 0.03359303141730158
Trained batch 296 in epoch 18, gen_loss = 0.43188039993597604, disc_loss = 0.03351588718129027
Trained batch 297 in epoch 18, gen_loss = 0.43157415051988307, disc_loss = 0.03391248728117387
Trained batch 298 in epoch 18, gen_loss = 0.43168150092845775, disc_loss = 0.033897244633116254
Trained batch 299 in epoch 18, gen_loss = 0.4317891203363736, disc_loss = 0.03402172398753464
Trained batch 300 in epoch 18, gen_loss = 0.43174941446694026, disc_loss = 0.034045923993214225
Trained batch 301 in epoch 18, gen_loss = 0.4315467182768891, disc_loss = 0.03406826259617675
Trained batch 302 in epoch 18, gen_loss = 0.43145532773272827, disc_loss = 0.03415966423369772
Trained batch 303 in epoch 18, gen_loss = 0.43136441962499367, disc_loss = 0.03451018193185231
Trained batch 304 in epoch 18, gen_loss = 0.43179924292642563, disc_loss = 0.03469524404003484
Trained batch 305 in epoch 18, gen_loss = 0.4317424124946781, disc_loss = 0.035260475450651904
Trained batch 306 in epoch 18, gen_loss = 0.4318152564162152, disc_loss = 0.03525229685117736
Trained batch 307 in epoch 18, gen_loss = 0.4319786954816286, disc_loss = 0.03520783921401319
Trained batch 308 in epoch 18, gen_loss = 0.43190682840964556, disc_loss = 0.035144924728688104
Trained batch 309 in epoch 18, gen_loss = 0.4317860979226328, disc_loss = 0.035587675001231896
Trained batch 310 in epoch 18, gen_loss = 0.4317953790690738, disc_loss = 0.03570431568794599
Trained batch 311 in epoch 18, gen_loss = 0.43181474086565846, disc_loss = 0.03566424009831957
Trained batch 312 in epoch 18, gen_loss = 0.43183068574046174, disc_loss = 0.035567858195402466
Trained batch 313 in epoch 18, gen_loss = 0.4318468534642724, disc_loss = 0.03562719887567411
Trained batch 314 in epoch 18, gen_loss = 0.4315320923214867, disc_loss = 0.03560130847026668
Trained batch 315 in epoch 18, gen_loss = 0.43183154961730863, disc_loss = 0.03550937270621852
Trained batch 316 in epoch 18, gen_loss = 0.4317573865505423, disc_loss = 0.03541056333808963
Trained batch 317 in epoch 18, gen_loss = 0.43176241865697895, disc_loss = 0.03534385753186338
Trained batch 318 in epoch 18, gen_loss = 0.431727386473862, disc_loss = 0.035279834850291285
Trained batch 319 in epoch 18, gen_loss = 0.43191513707861307, disc_loss = 0.03523043497407343
Trained batch 320 in epoch 18, gen_loss = 0.4320683663136491, disc_loss = 0.035171617353422065
Trained batch 321 in epoch 18, gen_loss = 0.4320541573052081, disc_loss = 0.035103751922037844
Trained batch 322 in epoch 18, gen_loss = 0.4320041915580584, disc_loss = 0.03501957492908642
Trained batch 323 in epoch 18, gen_loss = 0.43222086168365714, disc_loss = 0.03495785169142448
Trained batch 324 in epoch 18, gen_loss = 0.43228103967813347, disc_loss = 0.03557510099158837
Trained batch 325 in epoch 18, gen_loss = 0.43254060759866164, disc_loss = 0.035491197764233574
Trained batch 326 in epoch 18, gen_loss = 0.4324859235811671, disc_loss = 0.0358199958521474
Trained batch 327 in epoch 18, gen_loss = 0.43253419193916204, disc_loss = 0.035799077433738405
Trained batch 328 in epoch 18, gen_loss = 0.4326651227691616, disc_loss = 0.0357246314455673
Trained batch 329 in epoch 18, gen_loss = 0.4327048507603732, disc_loss = 0.035730852141524806
Trained batch 330 in epoch 18, gen_loss = 0.4328340633218022, disc_loss = 0.03567508969377175
Trained batch 331 in epoch 18, gen_loss = 0.4329173103513488, disc_loss = 0.03608132659805467
Trained batch 332 in epoch 18, gen_loss = 0.43284351295895046, disc_loss = 0.03607539381753575
Trained batch 333 in epoch 18, gen_loss = 0.432608654399118, disc_loss = 0.03632705981012233
Trained batch 334 in epoch 18, gen_loss = 0.43287382339363667, disc_loss = 0.03630027172169579
Trained batch 335 in epoch 18, gen_loss = 0.4331338570586273, disc_loss = 0.03632919367824104
Trained batch 336 in epoch 18, gen_loss = 0.43309173730785133, disc_loss = 0.036400495174421045
Trained batch 337 in epoch 18, gen_loss = 0.43297265020347914, disc_loss = 0.036383290725523196
Trained batch 338 in epoch 18, gen_loss = 0.43300573839902173, disc_loss = 0.03633841844193176
Trained batch 339 in epoch 18, gen_loss = 0.4328591040828649, disc_loss = 0.03672803402056589
Trained batch 340 in epoch 18, gen_loss = 0.43332704517149156, disc_loss = 0.03801088273809278
Trained batch 341 in epoch 18, gen_loss = 0.4333483319707781, disc_loss = 0.038829316940616095
Trained batch 342 in epoch 18, gen_loss = 0.4334328801048045, disc_loss = 0.0388629738480374
Trained batch 343 in epoch 18, gen_loss = 0.4335133020094661, disc_loss = 0.03895850367519225
Trained batch 344 in epoch 18, gen_loss = 0.43351056247517683, disc_loss = 0.03892535003631011
Trained batch 345 in epoch 18, gen_loss = 0.4333484053956291, disc_loss = 0.03899056564564305
Trained batch 346 in epoch 18, gen_loss = 0.4335407133748277, disc_loss = 0.03891675527441055
Trained batch 347 in epoch 18, gen_loss = 0.4334684711420673, disc_loss = 0.038839649574981
Trained batch 348 in epoch 18, gen_loss = 0.43359987612781686, disc_loss = 0.03874835509267825
Trained batch 349 in epoch 18, gen_loss = 0.4334535327979497, disc_loss = 0.038669517557801944
Trained batch 350 in epoch 18, gen_loss = 0.4335600968100067, disc_loss = 0.03858238604434493
Trained batch 351 in epoch 18, gen_loss = 0.43353511494669045, disc_loss = 0.03848460655453065
Trained batch 352 in epoch 18, gen_loss = 0.4335377846155896, disc_loss = 0.038553563166916285
Trained batch 353 in epoch 18, gen_loss = 0.43347541508028065, disc_loss = 0.03849267190990517
Trained batch 354 in epoch 18, gen_loss = 0.43357776823178146, disc_loss = 0.038425636696825985
Trained batch 355 in epoch 18, gen_loss = 0.4335056228584118, disc_loss = 0.0383462162774705
Trained batch 356 in epoch 18, gen_loss = 0.43354936248781967, disc_loss = 0.03831217497070672
Trained batch 357 in epoch 18, gen_loss = 0.43370324406543925, disc_loss = 0.03824718690258789
Trained batch 358 in epoch 18, gen_loss = 0.4337772037989582, disc_loss = 0.03824884824657133
Trained batch 359 in epoch 18, gen_loss = 0.43354368292623097, disc_loss = 0.03817694085106874
Trained batch 360 in epoch 18, gen_loss = 0.43352699378851045, disc_loss = 0.038094323625081215
Trained batch 361 in epoch 18, gen_loss = 0.4333062408214116, disc_loss = 0.038196954887761675
Trained batch 362 in epoch 18, gen_loss = 0.43342842305330537, disc_loss = 0.038285276502340045
Trained batch 363 in epoch 18, gen_loss = 0.43340879736038357, disc_loss = 0.03835795998987793
Trained batch 364 in epoch 18, gen_loss = 0.4332761037839602, disc_loss = 0.03847205180751338
Trained batch 365 in epoch 18, gen_loss = 0.4329944594147427, disc_loss = 0.038570215051505166
Trained batch 366 in epoch 18, gen_loss = 0.4330468518045358, disc_loss = 0.03860887151328233
Trained batch 367 in epoch 18, gen_loss = 0.43314556121502235, disc_loss = 0.0385572361448557
Trained batch 368 in epoch 18, gen_loss = 0.43337835246308387, disc_loss = 0.03848398945907631
Trained batch 369 in epoch 18, gen_loss = 0.43315027122561994, disc_loss = 0.03841855179996708
Trained batch 370 in epoch 18, gen_loss = 0.4330844139313762, disc_loss = 0.03841135002587322
Trained batch 371 in epoch 18, gen_loss = 0.4329580012508618, disc_loss = 0.038488528684973315
Trained batch 372 in epoch 18, gen_loss = 0.43323826454280207, disc_loss = 0.038751100430929226
Trained batch 373 in epoch 18, gen_loss = 0.43326528489908434, disc_loss = 0.03903675400452778
Trained batch 374 in epoch 18, gen_loss = 0.4332808393637339, disc_loss = 0.03895772320156296
Trained batch 375 in epoch 18, gen_loss = 0.43334341722917047, disc_loss = 0.03898561585501351
Trained batch 376 in epoch 18, gen_loss = 0.433628111445303, disc_loss = 0.03892881229188817
Trained batch 377 in epoch 18, gen_loss = 0.4337231272427493, disc_loss = 0.038896163084135245
Trained batch 378 in epoch 18, gen_loss = 0.43395104414554886, disc_loss = 0.03888344397709403
Trained batch 379 in epoch 18, gen_loss = 0.43408028750043165, disc_loss = 0.03880311489521869
Trained batch 380 in epoch 18, gen_loss = 0.43411017707952365, disc_loss = 0.03872999621388989
Trained batch 381 in epoch 18, gen_loss = 0.4341300215708648, disc_loss = 0.03866050028271427
Trained batch 382 in epoch 18, gen_loss = 0.43422140200517817, disc_loss = 0.03939349274941314
Trained batch 383 in epoch 18, gen_loss = 0.4339413344083975, disc_loss = 0.03976901495116181
Trained batch 384 in epoch 18, gen_loss = 0.4338818057790979, disc_loss = 0.039708930163269304
Trained batch 385 in epoch 18, gen_loss = 0.4340311124380388, disc_loss = 0.03980722333005403
Trained batch 386 in epoch 18, gen_loss = 0.434193282626396, disc_loss = 0.039852038147385194
Trained batch 387 in epoch 18, gen_loss = 0.4342396871484432, disc_loss = 0.039874681575252605
Trained batch 388 in epoch 18, gen_loss = 0.43416277608405657, disc_loss = 0.03984749359904685
Trained batch 389 in epoch 18, gen_loss = 0.43430954951506395, disc_loss = 0.03982692391086274
Trained batch 390 in epoch 18, gen_loss = 0.4341841493268757, disc_loss = 0.03987026332384523
Trained batch 391 in epoch 18, gen_loss = 0.43416060720171246, disc_loss = 0.039898637336517245
Trained batch 392 in epoch 18, gen_loss = 0.43436398836795914, disc_loss = 0.039889535410495586
Trained batch 393 in epoch 18, gen_loss = 0.43442882536934113, disc_loss = 0.039839013911036746
Trained batch 394 in epoch 18, gen_loss = 0.4343203107767467, disc_loss = 0.0398300964727149
Trained batch 395 in epoch 18, gen_loss = 0.43426895480264316, disc_loss = 0.03976396809336776
Trained batch 396 in epoch 18, gen_loss = 0.4342367418617085, disc_loss = 0.03971605859016554
Trained batch 397 in epoch 18, gen_loss = 0.4343426964390817, disc_loss = 0.03964425309973034
Trained batch 398 in epoch 18, gen_loss = 0.4343144281167434, disc_loss = 0.039660535025688115
Trained batch 399 in epoch 18, gen_loss = 0.43446611531078816, disc_loss = 0.03960324436542578
Trained batch 400 in epoch 18, gen_loss = 0.43467145898098364, disc_loss = 0.039592395066295256
Trained batch 401 in epoch 18, gen_loss = 0.4346086784678312, disc_loss = 0.03952248866753236
Trained batch 402 in epoch 18, gen_loss = 0.4347758272445527, disc_loss = 0.03943391279929847
Trained batch 403 in epoch 18, gen_loss = 0.43481821714356395, disc_loss = 0.03934446530644828
Trained batch 404 in epoch 18, gen_loss = 0.4347214055650028, disc_loss = 0.03926232637619071
Trained batch 405 in epoch 18, gen_loss = 0.43479109940857724, disc_loss = 0.039229269645846644
Trained batch 406 in epoch 18, gen_loss = 0.43500777837392446, disc_loss = 0.03915020310736424
Trained batch 407 in epoch 18, gen_loss = 0.4349120774982022, disc_loss = 0.03908645476079911
Trained batch 408 in epoch 18, gen_loss = 0.4348387028156691, disc_loss = 0.03900388120058787
Trained batch 409 in epoch 18, gen_loss = 0.4348563512650932, disc_loss = 0.03892400055135623
Trained batch 410 in epoch 18, gen_loss = 0.4349160767239666, disc_loss = 0.03884422692012522
Trained batch 411 in epoch 18, gen_loss = 0.434963617944023, disc_loss = 0.038762585432336495
Trained batch 412 in epoch 18, gen_loss = 0.4350440414852438, disc_loss = 0.03867522381036373
Trained batch 413 in epoch 18, gen_loss = 0.4350710052654939, disc_loss = 0.03858821181713149
Trained batch 414 in epoch 18, gen_loss = 0.4351145539657179, disc_loss = 0.038523973600310554
Trained batch 415 in epoch 18, gen_loss = 0.43511781841516495, disc_loss = 0.038443613189044226
Trained batch 416 in epoch 18, gen_loss = 0.4350637494803047, disc_loss = 0.03835779355003608
Trained batch 417 in epoch 18, gen_loss = 0.43522379657868565, disc_loss = 0.03827887580676548
Trained batch 418 in epoch 18, gen_loss = 0.4351222840157784, disc_loss = 0.03820080489369203
Trained batch 419 in epoch 18, gen_loss = 0.4352148000683103, disc_loss = 0.03815079658358757
Trained batch 420 in epoch 18, gen_loss = 0.43521990904898655, disc_loss = 0.03807972882035898
Trained batch 421 in epoch 18, gen_loss = 0.43530258070236133, disc_loss = 0.03803023230615491
Trained batch 422 in epoch 18, gen_loss = 0.4353396822092945, disc_loss = 0.03794971514982006
Trained batch 423 in epoch 18, gen_loss = 0.43503151862126477, disc_loss = 0.03819425071629186
Trained batch 424 in epoch 18, gen_loss = 0.4349359508121715, disc_loss = 0.038168351401520126
Trained batch 425 in epoch 18, gen_loss = 0.43478166441402527, disc_loss = 0.0381880627886038
Trained batch 426 in epoch 18, gen_loss = 0.434830196638018, disc_loss = 0.03812972603767098
Trained batch 427 in epoch 18, gen_loss = 0.4348787349239688, disc_loss = 0.03826703894644035
Trained batch 428 in epoch 18, gen_loss = 0.43483677284145134, disc_loss = 0.038220479490673975
Trained batch 429 in epoch 18, gen_loss = 0.43497308291668113, disc_loss = 0.038272144676857564
Trained batch 430 in epoch 18, gen_loss = 0.43491784554069945, disc_loss = 0.03819728592678628
Trained batch 431 in epoch 18, gen_loss = 0.43517156931813117, disc_loss = 0.03819702380375626
Trained batch 432 in epoch 18, gen_loss = 0.4351345604203865, disc_loss = 0.03815428502362987
Trained batch 433 in epoch 18, gen_loss = 0.4351722086492222, disc_loss = 0.03809258031384152
Trained batch 434 in epoch 18, gen_loss = 0.43542826936162754, disc_loss = 0.038042153562579686
Trained batch 435 in epoch 18, gen_loss = 0.435513913973209, disc_loss = 0.03796405368484557
Trained batch 436 in epoch 18, gen_loss = 0.4354407276523468, disc_loss = 0.03795322070209399
Trained batch 437 in epoch 18, gen_loss = 0.43540902844030566, disc_loss = 0.03788195312189015
Trained batch 438 in epoch 18, gen_loss = 0.43538361394052355, disc_loss = 0.037806160071257984
Trained batch 439 in epoch 18, gen_loss = 0.4355035119436004, disc_loss = 0.03772949087539349
Trained batch 440 in epoch 18, gen_loss = 0.4354959484400933, disc_loss = 0.03767384893351705
Trained batch 441 in epoch 18, gen_loss = 0.43545136536678036, disc_loss = 0.03759822926307055
Trained batch 442 in epoch 18, gen_loss = 0.43534214037804786, disc_loss = 0.03752981921086092
Trained batch 443 in epoch 18, gen_loss = 0.4354184094715763, disc_loss = 0.03745213406462524
Trained batch 444 in epoch 18, gen_loss = 0.43545078367329715, disc_loss = 0.037381667072434774
Trained batch 445 in epoch 18, gen_loss = 0.4354330180338145, disc_loss = 0.03730778882254934
Trained batch 446 in epoch 18, gen_loss = 0.43540292658261803, disc_loss = 0.03723042451264024
Trained batch 447 in epoch 18, gen_loss = 0.43531630128355964, disc_loss = 0.037154119211793714
Trained batch 448 in epoch 18, gen_loss = 0.4352174621647875, disc_loss = 0.03707543857870644
Trained batch 449 in epoch 18, gen_loss = 0.4351139862007565, disc_loss = 0.037001388111772636
Trained batch 450 in epoch 18, gen_loss = 0.4350577558487852, disc_loss = 0.036924851578691284
Trained batch 451 in epoch 18, gen_loss = 0.4350510953670054, disc_loss = 0.03685495537959155
Trained batch 452 in epoch 18, gen_loss = 0.4348759524211715, disc_loss = 0.036778005834557856
Trained batch 453 in epoch 18, gen_loss = 0.4347854813946501, disc_loss = 0.036704102947503855
Trained batch 454 in epoch 18, gen_loss = 0.43475068860001614, disc_loss = 0.036632251150005464
Trained batch 455 in epoch 18, gen_loss = 0.43476797757964386, disc_loss = 0.03655621110923229
Trained batch 456 in epoch 18, gen_loss = 0.4348413404281082, disc_loss = 0.036489062093777065
Trained batch 457 in epoch 18, gen_loss = 0.43474906663446966, disc_loss = 0.03641732048098909
Trained batch 458 in epoch 18, gen_loss = 0.43472486598039767, disc_loss = 0.03636651221015501
Trained batch 459 in epoch 18, gen_loss = 0.43488621355398843, disc_loss = 0.03630548862629044
Trained batch 460 in epoch 18, gen_loss = 0.4349782616223275, disc_loss = 0.03624034825249811
Trained batch 461 in epoch 18, gen_loss = 0.4350364793301661, disc_loss = 0.03617779209703868
Trained batch 462 in epoch 18, gen_loss = 0.43506468018239314, disc_loss = 0.03611019577430742
Trained batch 463 in epoch 18, gen_loss = 0.43508091189994896, disc_loss = 0.036041705104911795
Trained batch 464 in epoch 18, gen_loss = 0.43500789910234433, disc_loss = 0.035968634694994936
Trained batch 465 in epoch 18, gen_loss = 0.43504198765294233, disc_loss = 0.03591196893768329
Trained batch 466 in epoch 18, gen_loss = 0.43521119025585736, disc_loss = 0.03585180997044821
Trained batch 467 in epoch 18, gen_loss = 0.4352658431117351, disc_loss = 0.0357844709039618
Trained batch 468 in epoch 18, gen_loss = 0.43535885259286683, disc_loss = 0.0357148960388617
Trained batch 469 in epoch 18, gen_loss = 0.4354817641542313, disc_loss = 0.0356504651167965
Trained batch 470 in epoch 18, gen_loss = 0.43539873024966813, disc_loss = 0.03558198444450357
Trained batch 471 in epoch 18, gen_loss = 0.4354277239260027, disc_loss = 0.03551072154812696
Trained batch 472 in epoch 18, gen_loss = 0.4353435014317454, disc_loss = 0.03549248410805264
Trained batch 473 in epoch 18, gen_loss = 0.4353579010515776, disc_loss = 0.035429374002193335
Trained batch 474 in epoch 18, gen_loss = 0.43523842228086373, disc_loss = 0.035364176468972705
Trained batch 475 in epoch 18, gen_loss = 0.43532564453467604, disc_loss = 0.035294241950594815
Trained batch 476 in epoch 18, gen_loss = 0.43538980014169243, disc_loss = 0.03522638610463621
Trained batch 477 in epoch 18, gen_loss = 0.43535137612949354, disc_loss = 0.03515613437109046
Trained batch 478 in epoch 18, gen_loss = 0.4353563583345154, disc_loss = 0.035085439997470484
Trained batch 479 in epoch 18, gen_loss = 0.4353799984479944, disc_loss = 0.03501673512995088
Trained batch 480 in epoch 18, gen_loss = 0.43549239808952983, disc_loss = 0.034949880444276264
Trained batch 481 in epoch 18, gen_loss = 0.43540912631636336, disc_loss = 0.034889351029269766
Trained batch 482 in epoch 18, gen_loss = 0.4353429791720017, disc_loss = 0.0348206336371886
Trained batch 483 in epoch 18, gen_loss = 0.4353014385897266, disc_loss = 0.034754313904241746
Trained batch 484 in epoch 18, gen_loss = 0.43524385764426793, disc_loss = 0.034746387019542226
Trained batch 485 in epoch 18, gen_loss = 0.4353802328001815, disc_loss = 0.034694586035895154
Trained batch 486 in epoch 18, gen_loss = 0.4355033119601146, disc_loss = 0.03463860530668231
Trained batch 487 in epoch 18, gen_loss = 0.43544801513923975, disc_loss = 0.03457688507824357
Trained batch 488 in epoch 18, gen_loss = 0.4354090035449264, disc_loss = 0.034514508282019164
Trained batch 489 in epoch 18, gen_loss = 0.4354842934073234, disc_loss = 0.03445054626814565
Trained batch 490 in epoch 18, gen_loss = 0.4353816860076609, disc_loss = 0.03438315603904836
Trained batch 491 in epoch 18, gen_loss = 0.4353684129996028, disc_loss = 0.03431945946304188
Trained batch 492 in epoch 18, gen_loss = 0.4353474768494496, disc_loss = 0.034253869555195375
Trained batch 493 in epoch 18, gen_loss = 0.4353214298423968, disc_loss = 0.034189433307172015
Trained batch 494 in epoch 18, gen_loss = 0.4353302386674014, disc_loss = 0.03412253881070876
Trained batch 495 in epoch 18, gen_loss = 0.4353757225457699, disc_loss = 0.034056901577353145
Trained batch 496 in epoch 18, gen_loss = 0.4355913183578783, disc_loss = 0.03399143474442618
Trained batch 497 in epoch 18, gen_loss = 0.4355793477421305, disc_loss = 0.033930699244220125
Trained batch 498 in epoch 18, gen_loss = 0.4354696653051701, disc_loss = 0.03386506280149772
Trained batch 499 in epoch 18, gen_loss = 0.43539419227838516, disc_loss = 0.03379993545799516
Trained batch 500 in epoch 18, gen_loss = 0.4354275833227915, disc_loss = 0.03373690083982635
Trained batch 501 in epoch 18, gen_loss = 0.4354945859942303, disc_loss = 0.03367339080177337
Trained batch 502 in epoch 18, gen_loss = 0.43547918740845104, disc_loss = 0.033608918235161406
Trained batch 503 in epoch 18, gen_loss = 0.43553553125451483, disc_loss = 0.033545124803259524
Trained batch 504 in epoch 18, gen_loss = 0.43544923568716143, disc_loss = 0.03348127644057247
Trained batch 505 in epoch 18, gen_loss = 0.4354231450633098, disc_loss = 0.03341748791686057
Trained batch 506 in epoch 18, gen_loss = 0.4355050602843305, disc_loss = 0.03335415706643743
Trained batch 507 in epoch 18, gen_loss = 0.4353056749490302, disc_loss = 0.03329409521066686
Trained batch 508 in epoch 18, gen_loss = 0.43547926447948915, disc_loss = 0.03323454251087477
Trained batch 509 in epoch 18, gen_loss = 0.4354841804971882, disc_loss = 0.03317184952434664
Trained batch 510 in epoch 18, gen_loss = 0.4354382009188956, disc_loss = 0.03310874218454697
Trained batch 511 in epoch 18, gen_loss = 0.4353933085221797, disc_loss = 0.0330460502718779
Trained batch 512 in epoch 18, gen_loss = 0.4353658780600825, disc_loss = 0.03298453979587208
Trained batch 513 in epoch 18, gen_loss = 0.4353429664085811, disc_loss = 0.03292230782502219
Trained batch 514 in epoch 18, gen_loss = 0.4353476810802534, disc_loss = 0.032861891777923743
Trained batch 515 in epoch 18, gen_loss = 0.4353552388474923, disc_loss = 0.032800590374431206
Trained batch 516 in epoch 18, gen_loss = 0.4354251091092883, disc_loss = 0.03274143865688684
Trained batch 517 in epoch 18, gen_loss = 0.4354202204804623, disc_loss = 0.03268113554883245
Trained batch 518 in epoch 18, gen_loss = 0.43542708206728015, disc_loss = 0.0326205269839105
Trained batch 519 in epoch 18, gen_loss = 0.4353101967619016, disc_loss = 0.032566509855230553
Trained batch 520 in epoch 18, gen_loss = 0.43525443790970286, disc_loss = 0.0325136630887062
Trained batch 521 in epoch 18, gen_loss = 0.43527774444256706, disc_loss = 0.03245488164069531
Trained batch 522 in epoch 18, gen_loss = 0.4352014253403899, disc_loss = 0.0323945938019228
Trained batch 523 in epoch 18, gen_loss = 0.4352314072938366, disc_loss = 0.03233568142221544
Trained batch 524 in epoch 18, gen_loss = 0.4352319976829347, disc_loss = 0.032276457595372836
Trained batch 525 in epoch 18, gen_loss = 0.43523307365609665, disc_loss = 0.0322166940602589
Trained batch 526 in epoch 18, gen_loss = 0.43527683202862966, disc_loss = 0.03215691256696938
Trained batch 527 in epoch 18, gen_loss = 0.43525348948032566, disc_loss = 0.03209774490658839
Trained batch 528 in epoch 18, gen_loss = 0.4350871999795586, disc_loss = 0.03204820398098238
Trained batch 529 in epoch 18, gen_loss = 0.4350854271987699, disc_loss = 0.031991144388646135
Trained batch 530 in epoch 18, gen_loss = 0.4350404611976358, disc_loss = 0.03193490369025734
Trained batch 531 in epoch 18, gen_loss = 0.4350470494394912, disc_loss = 0.0318777890296266
Trained batch 532 in epoch 18, gen_loss = 0.4350770052110053, disc_loss = 0.03182032896788078
Trained batch 533 in epoch 18, gen_loss = 0.4350875464271517, disc_loss = 0.031763869015415364
Trained batch 534 in epoch 18, gen_loss = 0.4348786064397509, disc_loss = 0.03170622764949504
Trained batch 535 in epoch 18, gen_loss = 0.434906831872997, disc_loss = 0.03164904763013795
Trained batch 536 in epoch 18, gen_loss = 0.4349289679105499, disc_loss = 0.031591621113640174
Trained batch 537 in epoch 18, gen_loss = 0.43502145844986007, disc_loss = 0.03153578581153865
Trained batch 538 in epoch 18, gen_loss = 0.4351024857146842, disc_loss = 0.03148622769468891
Trained batch 539 in epoch 18, gen_loss = 0.43500409385672323, disc_loss = 0.03142936642171763
Trained batch 540 in epoch 18, gen_loss = 0.43507159345692054, disc_loss = 0.03137357318922344
Trained batch 541 in epoch 18, gen_loss = 0.43503034400763985, disc_loss = 0.03131797045739488
Trained batch 542 in epoch 18, gen_loss = 0.4350074981347852, disc_loss = 0.03126309876247441
Trained batch 543 in epoch 18, gen_loss = 0.4349532184355399, disc_loss = 0.03120748414831349
Trained batch 544 in epoch 18, gen_loss = 0.434803328546909, disc_loss = 0.03115171703527075
Trained batch 545 in epoch 18, gen_loss = 0.43467286180008896, disc_loss = 0.031096624723471866
Trained batch 546 in epoch 18, gen_loss = 0.4346420917476117, disc_loss = 0.03104152758952683
Trained batch 547 in epoch 18, gen_loss = 0.4345815138768976, disc_loss = 0.030986937340225746
Trained batch 548 in epoch 18, gen_loss = 0.43450123511376926, disc_loss = 0.030932298946369927
Trained batch 549 in epoch 18, gen_loss = 0.43451376010071147, disc_loss = 0.03087826127916659
Trained batch 550 in epoch 18, gen_loss = 0.4344256188713704, disc_loss = 0.03082371680135712
Trained batch 551 in epoch 18, gen_loss = 0.4345471824964751, disc_loss = 0.03077113280628312
Trained batch 552 in epoch 18, gen_loss = 0.43449194823639303, disc_loss = 0.030717128502949397
Trained batch 553 in epoch 18, gen_loss = 0.43445755046412404, disc_loss = 0.03066316193779964
Trained batch 554 in epoch 18, gen_loss = 0.4345997962328765, disc_loss = 0.030610745966325403
Trained batch 555 in epoch 18, gen_loss = 0.4345626454237554, disc_loss = 0.030557211630026268
Trained batch 556 in epoch 18, gen_loss = 0.43448365537225664, disc_loss = 0.030504124714780593
Trained batch 557 in epoch 18, gen_loss = 0.43451377161942073, disc_loss = 0.030451037027763778
Trained batch 558 in epoch 18, gen_loss = 0.43457962889790747, disc_loss = 0.03039850967664235
Trained batch 559 in epoch 18, gen_loss = 0.4345745946147612, disc_loss = 0.03034542200548458
Trained batch 560 in epoch 18, gen_loss = 0.4346659226001053, disc_loss = 0.030293150784081735
Trained batch 561 in epoch 18, gen_loss = 0.4346377856472633, disc_loss = 0.030241323744872373
Trained batch 562 in epoch 18, gen_loss = 0.43466208898999975, disc_loss = 0.03018901075394063
Trained batch 563 in epoch 18, gen_loss = 0.4345941778721539, disc_loss = 0.03013645272152102
Trained batch 564 in epoch 18, gen_loss = 0.43452838247856207, disc_loss = 0.030084711512596042
Trained batch 565 in epoch 18, gen_loss = 0.4346461179189042, disc_loss = 0.0300331445386783
Trained batch 566 in epoch 18, gen_loss = 0.43454800974544816, disc_loss = 0.029982796355953023
Trained batch 567 in epoch 18, gen_loss = 0.4344038721961035, disc_loss = 0.02993193941924993
Trained batch 568 in epoch 18, gen_loss = 0.43443590172145824, disc_loss = 0.029880902639190014
Trained batch 569 in epoch 18, gen_loss = 0.43440326765963905, disc_loss = 0.029831823531697554
Trained batch 570 in epoch 18, gen_loss = 0.43435614262487343, disc_loss = 0.029780967851192244
Trained batch 571 in epoch 18, gen_loss = 0.43436646320811517, disc_loss = 0.029730945572597332
Trained batch 572 in epoch 18, gen_loss = 0.43443128596633723, disc_loss = 0.029681727981940888
Trained batch 573 in epoch 18, gen_loss = 0.43428907312374915, disc_loss = 0.02963141954174583
Trained batch 574 in epoch 18, gen_loss = 0.43436220557793326, disc_loss = 0.029582755267215165
Trained batch 575 in epoch 18, gen_loss = 0.4343170563483404, disc_loss = 0.029532909307413827
Trained batch 576 in epoch 18, gen_loss = 0.4342983410511314, disc_loss = 0.02948297576133833
Trained batch 577 in epoch 18, gen_loss = 0.4341358496552933, disc_loss = 0.029435083174402906
Trained batch 578 in epoch 18, gen_loss = 0.4340491355083149, disc_loss = 0.029386318085066948
Trained batch 579 in epoch 18, gen_loss = 0.4340794094163796, disc_loss = 0.02933819473797359
Trained batch 580 in epoch 18, gen_loss = 0.4341230799737362, disc_loss = 0.02929024103541639
Trained batch 581 in epoch 18, gen_loss = 0.434178315999172, disc_loss = 0.029241334245087344
Trained batch 582 in epoch 18, gen_loss = 0.4342540493346815, disc_loss = 0.0291929236520561
Trained batch 583 in epoch 18, gen_loss = 0.4342841747893046, disc_loss = 0.02914424859035572
Trained batch 584 in epoch 18, gen_loss = 0.4342987632140135, disc_loss = 0.029095577163637705
Trained batch 585 in epoch 18, gen_loss = 0.4343994463263111, disc_loss = 0.029047304487257956
Trained batch 586 in epoch 18, gen_loss = 0.4342937197352187, disc_loss = 0.02899897771756985
Trained batch 587 in epoch 18, gen_loss = 0.43426491710401716, disc_loss = 0.028952091052945304
Trained batch 588 in epoch 18, gen_loss = 0.4342417189747044, disc_loss = 0.028903857117707734
Trained batch 589 in epoch 18, gen_loss = 0.43416679541943437, disc_loss = 0.02885694242195005
Trained batch 590 in epoch 18, gen_loss = 0.43408975958219037, disc_loss = 0.02880915486909348
Trained batch 591 in epoch 18, gen_loss = 0.4341518312591959, disc_loss = 0.02876200198148286
Trained batch 592 in epoch 18, gen_loss = 0.4340037718591159, disc_loss = 0.028714610941093226
Trained batch 593 in epoch 18, gen_loss = 0.4340464017206571, disc_loss = 0.028667520782839732
Trained batch 594 in epoch 18, gen_loss = 0.4341027270345127, disc_loss = 0.02862027139919458
Trained batch 595 in epoch 18, gen_loss = 0.4340830220272077, disc_loss = 0.02857360272149121
Trained batch 596 in epoch 18, gen_loss = 0.434089232978709, disc_loss = 0.028527154245080778
Trained batch 597 in epoch 18, gen_loss = 0.434079962779447, disc_loss = 0.028480583952543603
Trained batch 598 in epoch 18, gen_loss = 0.4341235696174864, disc_loss = 0.02843499255117079
Trained batch 599 in epoch 18, gen_loss = 0.4340638917684555, disc_loss = 0.028388654281540464
Trained batch 600 in epoch 18, gen_loss = 0.43406914231582805, disc_loss = 0.028342655818628926
Trained batch 601 in epoch 18, gen_loss = 0.43400580478070977, disc_loss = 0.02829761577087866
Trained batch 602 in epoch 18, gen_loss = 0.4339068151429716, disc_loss = 0.028251847356405714
Trained batch 603 in epoch 18, gen_loss = 0.433928239917913, disc_loss = 0.028208507316180086
Trained batch 604 in epoch 18, gen_loss = 0.433805127281788, disc_loss = 0.028164989698951495
Trained batch 605 in epoch 18, gen_loss = 0.4337659617363423, disc_loss = 0.028120407523343757
Trained batch 606 in epoch 18, gen_loss = 0.43374710032928127, disc_loss = 0.02807854938723954
Trained batch 607 in epoch 18, gen_loss = 0.4337480797579414, disc_loss = 0.02803341734110482
Trained batch 608 in epoch 18, gen_loss = 0.43368801479464875, disc_loss = 0.02798889154852758
Trained batch 609 in epoch 18, gen_loss = 0.43354226648807526, disc_loss = 0.027945181179684815
Trained batch 610 in epoch 18, gen_loss = 0.43357362328691684, disc_loss = 0.02790109467015902
Trained batch 611 in epoch 18, gen_loss = 0.43358472199027054, disc_loss = 0.02785668648445364
Trained batch 612 in epoch 18, gen_loss = 0.43355466977223683, disc_loss = 0.027812113356529652
Trained batch 613 in epoch 18, gen_loss = 0.43360348924363473, disc_loss = 0.02776977849556573
Trained batch 614 in epoch 18, gen_loss = 0.4334493642415458, disc_loss = 0.027726449098199515
Trained batch 615 in epoch 18, gen_loss = 0.43340701788857383, disc_loss = 0.02768322415606424
Trained batch 616 in epoch 18, gen_loss = 0.4333605646024454, disc_loss = 0.027639546266223367
Trained batch 617 in epoch 18, gen_loss = 0.43343593966227906, disc_loss = 0.027596215594391876
Trained batch 618 in epoch 18, gen_loss = 0.433344280296073, disc_loss = 0.02755269924590969
Trained batch 619 in epoch 18, gen_loss = 0.4333119576977145, disc_loss = 0.02750932928850694
Trained batch 620 in epoch 18, gen_loss = 0.4333667002150402, disc_loss = 0.027466491057185814
Trained batch 621 in epoch 18, gen_loss = 0.4332582825058143, disc_loss = 0.02742566470361099
Trained batch 622 in epoch 18, gen_loss = 0.4332354771000233, disc_loss = 0.0273825988856654
Trained batch 623 in epoch 18, gen_loss = 0.4332260648982647, disc_loss = 0.02734032927289193
Trained batch 624 in epoch 18, gen_loss = 0.4331930902957916, disc_loss = 0.027297487694770098
Trained batch 625 in epoch 18, gen_loss = 0.4331295236040609, disc_loss = 0.027254912022950526
Trained batch 626 in epoch 18, gen_loss = 0.43304418324473565, disc_loss = 0.027212557890504432
Trained batch 627 in epoch 18, gen_loss = 0.4329985802055924, disc_loss = 0.02717029022386188
Trained batch 628 in epoch 18, gen_loss = 0.43291764470655325, disc_loss = 0.027129404743284208
Trained batch 629 in epoch 18, gen_loss = 0.4328311019000553, disc_loss = 0.02708840102617008
Trained batch 630 in epoch 18, gen_loss = 0.4328988064109996, disc_loss = 0.027046759695603575
Trained batch 631 in epoch 18, gen_loss = 0.43289326508588427, disc_loss = 0.027005098329833412
Trained batch 632 in epoch 18, gen_loss = 0.4328198187159136, disc_loss = 0.026963763504868777
Trained batch 633 in epoch 18, gen_loss = 0.43289955317598033, disc_loss = 0.026922385180214777
Trained batch 634 in epoch 18, gen_loss = 0.43287890731819034, disc_loss = 0.026881004917512347
Trained batch 635 in epoch 18, gen_loss = 0.43296170960994634, disc_loss = 0.026839702144582204
Trained batch 636 in epoch 18, gen_loss = 0.432957220114943, disc_loss = 0.02679850090102452
Trained batch 637 in epoch 18, gen_loss = 0.4328950613176561, disc_loss = 0.026757467359845997
Trained batch 638 in epoch 18, gen_loss = 0.4329032578472054, disc_loss = 0.02671681424697237
Trained batch 639 in epoch 18, gen_loss = 0.4330206178594381, disc_loss = 0.02667664511818657
Trained batch 640 in epoch 18, gen_loss = 0.43307635904102354, disc_loss = 0.026637105726983468
Trained batch 641 in epoch 18, gen_loss = 0.43302894757358457, disc_loss = 0.02659668882819534
Trained batch 642 in epoch 18, gen_loss = 0.43292686398811697, disc_loss = 0.02655720302676145
Trained batch 643 in epoch 18, gen_loss = 0.43289495578833986, disc_loss = 0.026517651804237662
Trained batch 644 in epoch 18, gen_loss = 0.4329169385654982, disc_loss = 0.026479128217270467
Trained batch 645 in epoch 18, gen_loss = 0.4329684738865578, disc_loss = 0.02643931303540931
Trained batch 646 in epoch 18, gen_loss = 0.4328847935616141, disc_loss = 0.026400777543326363
Trained batch 647 in epoch 18, gen_loss = 0.43284699481762484, disc_loss = 0.02636130059365741
Trained batch 648 in epoch 18, gen_loss = 0.4328671373277673, disc_loss = 0.026321779433670145
Trained batch 649 in epoch 18, gen_loss = 0.4328381976714501, disc_loss = 0.02628269008047377
Trained batch 650 in epoch 18, gen_loss = 0.4328056879215709, disc_loss = 0.02624347447950576
Trained batch 651 in epoch 18, gen_loss = 0.43275579906131595, disc_loss = 0.02620400876127129
Trained batch 652 in epoch 18, gen_loss = 0.4327614905731966, disc_loss = 0.026167432554825645
Trained batch 653 in epoch 18, gen_loss = 0.4326802265206608, disc_loss = 0.026131107193216346
Trained batch 654 in epoch 18, gen_loss = 0.43261042305531394, disc_loss = 0.026092390784236624
Trained batch 655 in epoch 18, gen_loss = 0.432577724954704, disc_loss = 0.026053455416109587
Trained batch 656 in epoch 18, gen_loss = 0.43250991134157285, disc_loss = 0.026015388323337867
Trained batch 657 in epoch 18, gen_loss = 0.4324062247859671, disc_loss = 0.025976514033338064
Trained batch 658 in epoch 18, gen_loss = 0.43237852032701957, disc_loss = 0.0259379460173818
Trained batch 659 in epoch 18, gen_loss = 0.4323323180729693, disc_loss = 0.02589946261719116
Trained batch 660 in epoch 18, gen_loss = 0.43237023941507496, disc_loss = 0.02586129149639558
Trained batch 661 in epoch 18, gen_loss = 0.4323775083096726, disc_loss = 0.02582354009123498
Trained batch 662 in epoch 18, gen_loss = 0.4323396492597744, disc_loss = 0.025786000084921053
Trained batch 663 in epoch 18, gen_loss = 0.4322353844272803, disc_loss = 0.025748012599744623
Trained batch 664 in epoch 18, gen_loss = 0.43219360220701175, disc_loss = 0.025710031788146712
Trained batch 665 in epoch 18, gen_loss = 0.43222279327588753, disc_loss = 0.025672901719509676
Trained batch 666 in epoch 18, gen_loss = 0.4321130980169219, disc_loss = 0.02563527566421815
Trained batch 667 in epoch 18, gen_loss = 0.43210785987669836, disc_loss = 0.025598686658956798
Trained batch 668 in epoch 18, gen_loss = 0.432072806785994, disc_loss = 0.025561469205909567
Trained batch 669 in epoch 18, gen_loss = 0.43196873615926773, disc_loss = 0.02552616347418924
Trained batch 670 in epoch 18, gen_loss = 0.4320166919785711, disc_loss = 0.02548951606635572
Trained batch 671 in epoch 18, gen_loss = 0.43199524678112494, disc_loss = 0.025452420998850096
Trained batch 672 in epoch 18, gen_loss = 0.4319999806505433, disc_loss = 0.025416071733114217
Trained batch 673 in epoch 18, gen_loss = 0.4320540615642106, disc_loss = 0.025379575777100052
Trained batch 674 in epoch 18, gen_loss = 0.43211403489112854, disc_loss = 0.025343245119072013
Trained batch 675 in epoch 18, gen_loss = 0.4320748550211184, disc_loss = 0.02530708614435941
Trained batch 676 in epoch 18, gen_loss = 0.4321192449709865, disc_loss = 0.025273366089976646
Trained batch 677 in epoch 18, gen_loss = 0.432263158459579, disc_loss = 0.025240280670479592
Trained batch 678 in epoch 18, gen_loss = 0.4321884942599003, disc_loss = 0.025204863480063545
Trained batch 679 in epoch 18, gen_loss = 0.4321852077017812, disc_loss = 0.025169604918996544
Trained batch 680 in epoch 18, gen_loss = 0.4321517729461631, disc_loss = 0.02513487851056585
Trained batch 681 in epoch 18, gen_loss = 0.4322183154020841, disc_loss = 0.025100673456914257
Trained batch 682 in epoch 18, gen_loss = 0.43227222339300597, disc_loss = 0.02506575181145026
Trained batch 683 in epoch 18, gen_loss = 0.4322755531957972, disc_loss = 0.025030483063118062
Trained batch 684 in epoch 18, gen_loss = 0.43230618899756107, disc_loss = 0.024995143692320157
Trained batch 685 in epoch 18, gen_loss = 0.4322558837798872, disc_loss = 0.02496005104848424
Trained batch 686 in epoch 18, gen_loss = 0.43223228100605926, disc_loss = 0.02492467227324625
Trained batch 687 in epoch 18, gen_loss = 0.43229244688395846, disc_loss = 0.024889603345802116
Trained batch 688 in epoch 18, gen_loss = 0.43237730895313714, disc_loss = 0.024855383268463885
Trained batch 689 in epoch 18, gen_loss = 0.43242557934228926, disc_loss = 0.024821046168664537
Trained batch 690 in epoch 18, gen_loss = 0.4323579898877703, disc_loss = 0.024786840704923048
Trained batch 691 in epoch 18, gen_loss = 0.43233826812464377, disc_loss = 0.024752933404775475
Trained batch 692 in epoch 18, gen_loss = 0.432352797680603, disc_loss = 0.024718722495817195
Trained batch 693 in epoch 18, gen_loss = 0.432383790053964, disc_loss = 0.024684239460498573
Trained batch 694 in epoch 18, gen_loss = 0.43239482606915264, disc_loss = 0.02465026671742759
Trained batch 695 in epoch 18, gen_loss = 0.4324101511089281, disc_loss = 0.02461593808122374
Trained batch 696 in epoch 18, gen_loss = 0.4323578426878969, disc_loss = 0.024581774373876514
Trained batch 697 in epoch 18, gen_loss = 0.4323808532048091, disc_loss = 0.0245473554409506
Trained batch 698 in epoch 18, gen_loss = 0.43228034523764736, disc_loss = 0.024513330730402745
Trained batch 699 in epoch 18, gen_loss = 0.4322739548768316, disc_loss = 0.024479424860785783
Trained batch 700 in epoch 18, gen_loss = 0.4323458355690715, disc_loss = 0.024446077205859503
Trained batch 701 in epoch 18, gen_loss = 0.4323174598125311, disc_loss = 0.024412845162350746
Trained batch 702 in epoch 18, gen_loss = 0.4322575416792168, disc_loss = 0.024379420832468853
Trained batch 703 in epoch 18, gen_loss = 0.4322921617210589, disc_loss = 0.02434647630670125
Trained batch 704 in epoch 18, gen_loss = 0.43229132163609174, disc_loss = 0.02431285137806834
Trained batch 705 in epoch 18, gen_loss = 0.4322940925447529, disc_loss = 0.02428119871475986
Trained batch 706 in epoch 18, gen_loss = 0.4323435542522765, disc_loss = 0.024249148011924515
Trained batch 707 in epoch 18, gen_loss = 0.43228090066189145, disc_loss = 0.024216498553170495
Trained batch 708 in epoch 18, gen_loss = 0.43227548584110814, disc_loss = 0.024183824545960304
Trained batch 709 in epoch 18, gen_loss = 0.43229327873444895, disc_loss = 0.02415059471513558
Trained batch 710 in epoch 18, gen_loss = 0.4322574852891109, disc_loss = 0.02411768407730023
Trained batch 711 in epoch 18, gen_loss = 0.4321707781780972, disc_loss = 0.024084925500104097
Trained batch 712 in epoch 18, gen_loss = 0.43217269409588976, disc_loss = 0.024052897082838632
Trained batch 713 in epoch 18, gen_loss = 0.43216988527808203, disc_loss = 0.024019969958531232
Trained batch 714 in epoch 18, gen_loss = 0.43222742964337757, disc_loss = 0.02398735193793753
Trained batch 715 in epoch 18, gen_loss = 0.4323157906199301, disc_loss = 0.02395502528519267
Trained batch 716 in epoch 18, gen_loss = 0.4323980317787479, disc_loss = 0.02392330545562026
Trained batch 717 in epoch 18, gen_loss = 0.43230844473772395, disc_loss = 0.023890965139439193
Trained batch 718 in epoch 18, gen_loss = 0.43227105246797226, disc_loss = 0.0238588854957677
Trained batch 719 in epoch 18, gen_loss = 0.4322147292395433, disc_loss = 0.023826760443908926
Trained batch 720 in epoch 18, gen_loss = 0.43219473734808034, disc_loss = 0.02379458505456367
Trained batch 721 in epoch 18, gen_loss = 0.4323007258434375, disc_loss = 0.023762672138714795
Trained batch 722 in epoch 18, gen_loss = 0.4323235790182116, disc_loss = 0.02373076449661196
Trained batch 723 in epoch 18, gen_loss = 0.43233962706933365, disc_loss = 0.023698987715881772
Trained batch 724 in epoch 18, gen_loss = 0.43235217275290655, disc_loss = 0.02366973776566989
Trained batch 725 in epoch 18, gen_loss = 0.43238850459251194, disc_loss = 0.023641347590124828
Trained batch 726 in epoch 18, gen_loss = 0.43222780085003526, disc_loss = 0.023610796460132737
Trained batch 727 in epoch 18, gen_loss = 0.4322273612513647, disc_loss = 0.023582330791404083
Trained batch 728 in epoch 18, gen_loss = 0.4321888553180485, disc_loss = 0.023551020402097514
Trained batch 729 in epoch 18, gen_loss = 0.4321956852935765, disc_loss = 0.023520349761294138
Trained batch 730 in epoch 18, gen_loss = 0.4321530694511455, disc_loss = 0.02348923898379576
Trained batch 731 in epoch 18, gen_loss = 0.43212476421575075, disc_loss = 0.023458288839814326
Trained batch 732 in epoch 18, gen_loss = 0.43218580433161163, disc_loss = 0.023427659413918007
Trained batch 733 in epoch 18, gen_loss = 0.43224590476754576, disc_loss = 0.02339755584959579
Trained batch 734 in epoch 18, gen_loss = 0.432159203250392, disc_loss = 0.023367399399027825
Trained batch 735 in epoch 18, gen_loss = 0.4321990695417575, disc_loss = 0.023336713339235954
Trained batch 736 in epoch 18, gen_loss = 0.4321685116358981, disc_loss = 0.023306264826012876
Trained batch 737 in epoch 18, gen_loss = 0.4321347720577788, disc_loss = 0.023275724418111446
Trained batch 738 in epoch 18, gen_loss = 0.4321119321537921, disc_loss = 0.023245001171631436
Trained batch 739 in epoch 18, gen_loss = 0.4320691186834026, disc_loss = 0.023217278276766787
Trained batch 740 in epoch 18, gen_loss = 0.43201087095476837, disc_loss = 0.0231867225410768
Trained batch 741 in epoch 18, gen_loss = 0.4321512814480661, disc_loss = 0.023158266965726284
Trained batch 742 in epoch 18, gen_loss = 0.43215534022807434, disc_loss = 0.02312836362037859
Trained batch 743 in epoch 18, gen_loss = 0.43210276256325425, disc_loss = 0.023098160170188602
Trained batch 744 in epoch 18, gen_loss = 0.43203659509652415, disc_loss = 0.0230689160786366
Trained batch 745 in epoch 18, gen_loss = 0.4319890609695189, disc_loss = 0.023039292403249926
Testing Epoch 18
Training Epoch 19
Trained batch 0 in epoch 19, gen_loss = 0.39671996235847473, disc_loss = 0.0015500206500291824
Trained batch 1 in epoch 19, gen_loss = 0.43242497742176056, disc_loss = 0.0011123219155706465
Trained batch 2 in epoch 19, gen_loss = 0.4149083693822225, disc_loss = 0.0010301022169490655
Trained batch 3 in epoch 19, gen_loss = 0.4291074648499489, disc_loss = 0.0010099667706526816
Trained batch 4 in epoch 19, gen_loss = 0.43431589007377625, disc_loss = 0.0010629576165229083
Trained batch 5 in epoch 19, gen_loss = 0.43026310205459595, disc_loss = 0.0010709603666327894
Trained batch 6 in epoch 19, gen_loss = 0.4253424278327397, disc_loss = 0.0010180189523712865
Trained batch 7 in epoch 19, gen_loss = 0.41962989047169685, disc_loss = 0.0009768601230462082
Trained batch 8 in epoch 19, gen_loss = 0.4155927068657345, disc_loss = 0.0009444319811235699
Trained batch 9 in epoch 19, gen_loss = 0.4179545134305954, disc_loss = 0.0009569134155754
Trained batch 10 in epoch 19, gen_loss = 0.4167208102616397, disc_loss = 0.0009224334022622894
Trained batch 11 in epoch 19, gen_loss = 0.4129490926861763, disc_loss = 0.0009336561536959683
Trained batch 12 in epoch 19, gen_loss = 0.4151716163525215, disc_loss = 0.0009194756320749337
Trained batch 13 in epoch 19, gen_loss = 0.41348559728690554, disc_loss = 0.000971357587591878
Trained batch 14 in epoch 19, gen_loss = 0.4147654394308726, disc_loss = 0.0009596078229757647
Trained batch 15 in epoch 19, gen_loss = 0.41283543035387993, disc_loss = 0.0009562148443365004
Trained batch 16 in epoch 19, gen_loss = 0.41802960984847126, disc_loss = 0.0009460894164957982
Trained batch 17 in epoch 19, gen_loss = 0.4198838505480025, disc_loss = 0.0009487395840955691
Trained batch 18 in epoch 19, gen_loss = 0.42217710614204407, disc_loss = 0.0009464186640750421
Trained batch 19 in epoch 19, gen_loss = 0.4240628555417061, disc_loss = 0.0009361801086924971
Trained batch 20 in epoch 19, gen_loss = 0.42265138030052185, disc_loss = 0.0009357309844788341
Trained batch 21 in epoch 19, gen_loss = 0.42335857586427167, disc_loss = 0.0009252239595463669
Trained batch 22 in epoch 19, gen_loss = 0.4230203784030417, disc_loss = 0.0009566139779053628
Trained batch 23 in epoch 19, gen_loss = 0.42312856763601303, disc_loss = 0.0009495865645779608
Trained batch 24 in epoch 19, gen_loss = 0.42216410994529724, disc_loss = 0.0009524551988579333
Trained batch 25 in epoch 19, gen_loss = 0.41933442422976863, disc_loss = 0.0010139429964160977
Trained batch 26 in epoch 19, gen_loss = 0.4189066423310174, disc_loss = 0.0010278513676624883
Trained batch 27 in epoch 19, gen_loss = 0.4237108656338283, disc_loss = 0.001035270407945583
Trained batch 28 in epoch 19, gen_loss = 0.42460568095075674, disc_loss = 0.001031568117343403
Trained batch 29 in epoch 19, gen_loss = 0.4241613020499547, disc_loss = 0.0010210592319102338
Trained batch 30 in epoch 19, gen_loss = 0.42509225010871887, disc_loss = 0.0010168307081555887
Trained batch 31 in epoch 19, gen_loss = 0.42552824411541224, disc_loss = 0.0010116939829458715
Trained batch 32 in epoch 19, gen_loss = 0.4264712586547389, disc_loss = 0.001002053836021911
Trained batch 33 in epoch 19, gen_loss = 0.42755087070605335, disc_loss = 0.000989111325265292
Trained batch 34 in epoch 19, gen_loss = 0.4257907245840345, disc_loss = 0.0009801021228278322
Trained batch 35 in epoch 19, gen_loss = 0.4256579155723254, disc_loss = 0.0009746153324764842
Trained batch 36 in epoch 19, gen_loss = 0.4260506170826989, disc_loss = 0.0009690152710882594
Trained batch 37 in epoch 19, gen_loss = 0.4266748287175831, disc_loss = 0.0009892150885302965
Trained batch 38 in epoch 19, gen_loss = 0.4257366978205167, disc_loss = 0.0009841246736379196
Trained batch 39 in epoch 19, gen_loss = 0.42715945839881897, disc_loss = 0.0009837898236582988
Trained batch 40 in epoch 19, gen_loss = 0.4267975397226287, disc_loss = 0.0009735243908901949
Trained batch 41 in epoch 19, gen_loss = 0.42838169989131747, disc_loss = 0.0009716340642799402
Trained batch 42 in epoch 19, gen_loss = 0.42917110614998394, disc_loss = 0.0009693187244539691
Trained batch 43 in epoch 19, gen_loss = 0.43082854829051276, disc_loss = 0.001024685855637389
Trained batch 44 in epoch 19, gen_loss = 0.4309962153434753, disc_loss = 0.0010165915281201401
Trained batch 45 in epoch 19, gen_loss = 0.4307421834572502, disc_loss = 0.0010086497413399427
Trained batch 46 in epoch 19, gen_loss = 0.430114264817948, disc_loss = 0.0010083031003422878
Trained batch 47 in epoch 19, gen_loss = 0.4284261465072632, disc_loss = 0.0012298500684361595
Trained batch 48 in epoch 19, gen_loss = 0.42799905185796777, disc_loss = 0.0012375887682927506
Trained batch 49 in epoch 19, gen_loss = 0.4284204649925232, disc_loss = 0.0012556647323071957
Trained batch 50 in epoch 19, gen_loss = 0.42639754566491817, disc_loss = 0.0012592913140086275
Trained batch 51 in epoch 19, gen_loss = 0.42575124364632827, disc_loss = 0.0012479284364067449
Trained batch 52 in epoch 19, gen_loss = 0.42726934405992617, disc_loss = 0.0012428951570500602
Trained batch 53 in epoch 19, gen_loss = 0.428800607169116, disc_loss = 0.0012362318930509329
Trained batch 54 in epoch 19, gen_loss = 0.4285477096384222, disc_loss = 0.0012274303642863576
Trained batch 55 in epoch 19, gen_loss = 0.4291400925389358, disc_loss = 0.0012203790382565266
Trained batch 56 in epoch 19, gen_loss = 0.43041001024999115, disc_loss = 0.0012140317233851213
Trained batch 57 in epoch 19, gen_loss = 0.43104533799763384, disc_loss = 0.0012042228130479183
Trained batch 58 in epoch 19, gen_loss = 0.43107755355915783, disc_loss = 0.0012080787465970774
Trained batch 59 in epoch 19, gen_loss = 0.43086765160163243, disc_loss = 0.0011979657855893796
Trained batch 60 in epoch 19, gen_loss = 0.4308591616935417, disc_loss = 0.0011895394008072306
Trained batch 61 in epoch 19, gen_loss = 0.4314236616896045, disc_loss = 0.0011814945375531792
Trained batch 62 in epoch 19, gen_loss = 0.4316423208940597, disc_loss = 0.0011754612381096989
Trained batch 63 in epoch 19, gen_loss = 0.4313544053584337, disc_loss = 0.0011693381384247914
Trained batch 64 in epoch 19, gen_loss = 0.4313237190246582, disc_loss = 0.0011644386381913837
Trained batch 65 in epoch 19, gen_loss = 0.430903079383301, disc_loss = 0.0011582060974571064
Trained batch 66 in epoch 19, gen_loss = 0.43008522088847945, disc_loss = 0.0011492994580932184
Trained batch 67 in epoch 19, gen_loss = 0.4308142175569254, disc_loss = 0.0011512336555717733
Trained batch 68 in epoch 19, gen_loss = 0.43152437391488446, disc_loss = 0.001158940900231887
Trained batch 69 in epoch 19, gen_loss = 0.431872946875436, disc_loss = 0.0011532687390821853
Trained batch 70 in epoch 19, gen_loss = 0.43230968545859966, disc_loss = 0.0011468764655226448
Trained batch 71 in epoch 19, gen_loss = 0.4321931555039353, disc_loss = 0.0011434357705487248
Trained batch 72 in epoch 19, gen_loss = 0.43139522042992995, disc_loss = 0.0011377010529554667
Trained batch 73 in epoch 19, gen_loss = 0.43158377143176824, disc_loss = 0.0011405049920761706
Trained batch 74 in epoch 19, gen_loss = 0.4326219149430593, disc_loss = 0.0011437814915552734
Trained batch 75 in epoch 19, gen_loss = 0.43311820767427744, disc_loss = 0.0011404379788712646
Trained batch 76 in epoch 19, gen_loss = 0.43262436831152284, disc_loss = 0.001144916794335397
Trained batch 77 in epoch 19, gen_loss = 0.4327172182309322, disc_loss = 0.0011389278709733237
Trained batch 78 in epoch 19, gen_loss = 0.4324162764639794, disc_loss = 0.0011319902348273163
Trained batch 79 in epoch 19, gen_loss = 0.4316706255078316, disc_loss = 0.001124245575920213
Trained batch 80 in epoch 19, gen_loss = 0.4321126937866211, disc_loss = 0.001121712040104386
Trained batch 81 in epoch 19, gen_loss = 0.4320870783270859, disc_loss = 0.0011164813761020125
Trained batch 82 in epoch 19, gen_loss = 0.4318840905844447, disc_loss = 0.0011133826085287764
Trained batch 83 in epoch 19, gen_loss = 0.43199149128936587, disc_loss = 0.0011075629278950924
Trained batch 84 in epoch 19, gen_loss = 0.43126013629576737, disc_loss = 0.0011043440968291286
Trained batch 85 in epoch 19, gen_loss = 0.43073275130848554, disc_loss = 0.0011014331099685542
Trained batch 86 in epoch 19, gen_loss = 0.4308843718863082, disc_loss = 0.0010974498642287377
Trained batch 87 in epoch 19, gen_loss = 0.43042889203537593, disc_loss = 0.0010916796878022565
Trained batch 88 in epoch 19, gen_loss = 0.4301715992139966, disc_loss = 0.00109788944442453
Trained batch 89 in epoch 19, gen_loss = 0.4303599440389209, disc_loss = 0.0010934713503552808
Trained batch 90 in epoch 19, gen_loss = 0.43022055514566193, disc_loss = 0.0010896209815445428
Trained batch 91 in epoch 19, gen_loss = 0.43054782437241595, disc_loss = 0.0010853591153610741
Trained batch 92 in epoch 19, gen_loss = 0.4305842499579153, disc_loss = 0.001081235659864521
Trained batch 93 in epoch 19, gen_loss = 0.4305104099689646, disc_loss = 0.001077543394863011
Trained batch 94 in epoch 19, gen_loss = 0.4304167314579612, disc_loss = 0.0010778396751878684
Trained batch 95 in epoch 19, gen_loss = 0.4306980427354574, disc_loss = 0.0010750921555882087
Trained batch 96 in epoch 19, gen_loss = 0.43115534057322236, disc_loss = 0.0010750437960671932
Trained batch 97 in epoch 19, gen_loss = 0.4309993760318172, disc_loss = 0.0010720212000650258
Trained batch 98 in epoch 19, gen_loss = 0.43122007088227704, disc_loss = 0.0010730488957235156
Trained batch 99 in epoch 19, gen_loss = 0.43146435588598253, disc_loss = 0.0010747723642271013
Trained batch 100 in epoch 19, gen_loss = 0.43217734859721496, disc_loss = 0.0010753273053352933
Trained batch 101 in epoch 19, gen_loss = 0.43229015668233234, disc_loss = 0.0010739225265341719
Trained batch 102 in epoch 19, gen_loss = 0.43254082989924164, disc_loss = 0.0010771190287608616
Trained batch 103 in epoch 19, gen_loss = 0.4324626521422313, disc_loss = 0.0010804572034080943
Trained batch 104 in epoch 19, gen_loss = 0.4318724603880019, disc_loss = 0.001122672533771644
Trained batch 105 in epoch 19, gen_loss = 0.4320253111281485, disc_loss = 0.0011390299719696829
Trained batch 106 in epoch 19, gen_loss = 0.43094136503255254, disc_loss = 0.0011475451446190546
Trained batch 107 in epoch 19, gen_loss = 0.43118942087447204, disc_loss = 0.0011470461812913763
Trained batch 108 in epoch 19, gen_loss = 0.431226964390606, disc_loss = 0.0011458430624003053
Trained batch 109 in epoch 19, gen_loss = 0.430957249619744, disc_loss = 0.0011444352667736397
Trained batch 110 in epoch 19, gen_loss = 0.4309949864138354, disc_loss = 0.001141409413272364
Trained batch 111 in epoch 19, gen_loss = 0.4308159843619381, disc_loss = 0.0011467724819210292
Trained batch 112 in epoch 19, gen_loss = 0.4308114869404683, disc_loss = 0.0011452216422185302
Trained batch 113 in epoch 19, gen_loss = 0.4302063108536235, disc_loss = 0.0011499127538531627
Trained batch 114 in epoch 19, gen_loss = 0.42986625329307887, disc_loss = 0.001153513769943105
Trained batch 115 in epoch 19, gen_loss = 0.43055663900128727, disc_loss = 0.0011791216725371137
Trained batch 116 in epoch 19, gen_loss = 0.4303600833966182, disc_loss = 0.001185297910283264
Trained batch 117 in epoch 19, gen_loss = 0.4305639362941354, disc_loss = 0.0011920885368392376
Trained batch 118 in epoch 19, gen_loss = 0.4306204622032262, disc_loss = 0.001191293725845631
Trained batch 119 in epoch 19, gen_loss = 0.4307120176653067, disc_loss = 0.0011928517022170126
Trained batch 120 in epoch 19, gen_loss = 0.4308778269231812, disc_loss = 0.001200120807586869
Trained batch 121 in epoch 19, gen_loss = 0.43073349042994075, disc_loss = 0.0012512701815452242
Trained batch 122 in epoch 19, gen_loss = 0.430857437170618, disc_loss = 0.001670882389767141
Trained batch 123 in epoch 19, gen_loss = 0.43101409534292834, disc_loss = 0.0016855421089266816
Trained batch 124 in epoch 19, gen_loss = 0.43070379638671874, disc_loss = 0.0020875053349882363
Trained batch 125 in epoch 19, gen_loss = 0.43125301552197287, disc_loss = 0.0021095327046211985
Trained batch 126 in epoch 19, gen_loss = 0.43164846723473915, disc_loss = 0.0021634220024644153
Trained batch 127 in epoch 19, gen_loss = 0.431344490731135, disc_loss = 0.0022093441384640755
Trained batch 128 in epoch 19, gen_loss = 0.4316086983957956, disc_loss = 0.002243350063226828
Trained batch 129 in epoch 19, gen_loss = 0.4312426972847718, disc_loss = 0.002269089474486044
Trained batch 130 in epoch 19, gen_loss = 0.4313144424489436, disc_loss = 0.00227197433309985
Trained batch 131 in epoch 19, gen_loss = 0.43093531691666803, disc_loss = 0.002272713112743628
Trained batch 132 in epoch 19, gen_loss = 0.4306399553341973, disc_loss = 0.002269733357558349
Trained batch 133 in epoch 19, gen_loss = 0.4300150842364155, disc_loss = 0.002264425286210017
Trained batch 134 in epoch 19, gen_loss = 0.42995293581927263, disc_loss = 0.002262365768870546
Trained batch 135 in epoch 19, gen_loss = 0.42978766385246725, disc_loss = 0.0022763068854521193
Trained batch 136 in epoch 19, gen_loss = 0.43013576412723015, disc_loss = 0.0033523191512650707
Trained batch 137 in epoch 19, gen_loss = 0.4295621404181356, disc_loss = 0.0037058025178418534
Trained batch 138 in epoch 19, gen_loss = 0.4294925651533141, disc_loss = 0.003759170087597085
Trained batch 139 in epoch 19, gen_loss = 0.4294503256678581, disc_loss = 0.0037691229214293085
Trained batch 140 in epoch 19, gen_loss = 0.42960096293307365, disc_loss = 0.0038055036512553587
Trained batch 141 in epoch 19, gen_loss = 0.4302061750015742, disc_loss = 0.003925987223366564
Trained batch 142 in epoch 19, gen_loss = 0.43048517874904446, disc_loss = 0.003985232067086011
Trained batch 143 in epoch 19, gen_loss = 0.43103777762088513, disc_loss = 0.004073418184513382
Trained batch 144 in epoch 19, gen_loss = 0.43210769131265836, disc_loss = 0.004191532743099178
Trained batch 145 in epoch 19, gen_loss = 0.43233505299646563, disc_loss = 0.004353806082229449
Trained batch 146 in epoch 19, gen_loss = 0.4324638498883669, disc_loss = 0.004562431641499556
Trained batch 147 in epoch 19, gen_loss = 0.43278549269244476, disc_loss = 0.005115707467052129
Trained batch 148 in epoch 19, gen_loss = 0.4326047273290237, disc_loss = 0.006543469695755649
Trained batch 149 in epoch 19, gen_loss = 0.43280607342720034, disc_loss = 0.006842978012282401
Trained batch 150 in epoch 19, gen_loss = 0.43326229607032624, disc_loss = 0.006936771054258755
Trained batch 151 in epoch 19, gen_loss = 0.43327343110975464, disc_loss = 0.006945471885142308
Trained batch 152 in epoch 19, gen_loss = 0.4332214330925661, disc_loss = 0.006967856913190213
Trained batch 153 in epoch 19, gen_loss = 0.43347665686886033, disc_loss = 0.006985506991547375
Trained batch 154 in epoch 19, gen_loss = 0.4331034089288404, disc_loss = 0.007009966905048537
Trained batch 155 in epoch 19, gen_loss = 0.43302538914558214, disc_loss = 0.007003942987350269
Trained batch 156 in epoch 19, gen_loss = 0.4326363627318364, disc_loss = 0.006982434673715312
Trained batch 157 in epoch 19, gen_loss = 0.43251875948302354, disc_loss = 0.006957600915162011
Trained batch 158 in epoch 19, gen_loss = 0.4324490744737709, disc_loss = 0.0069429691399172325
Trained batch 159 in epoch 19, gen_loss = 0.4319157337769866, disc_loss = 0.00691558107137098
Trained batch 160 in epoch 19, gen_loss = 0.4321242378365179, disc_loss = 0.006897231444618115
Trained batch 161 in epoch 19, gen_loss = 0.43206662712273775, disc_loss = 0.00686974967987978
Trained batch 162 in epoch 19, gen_loss = 0.4314842247889817, disc_loss = 0.006900698125813774
Trained batch 163 in epoch 19, gen_loss = 0.43128877514746133, disc_loss = 0.0068794002042367785
Trained batch 164 in epoch 19, gen_loss = 0.4309281446717002, disc_loss = 0.006867964792234654
Trained batch 165 in epoch 19, gen_loss = 0.4311485699860446, disc_loss = 0.006843856470631324
Trained batch 166 in epoch 19, gen_loss = 0.43144660349377617, disc_loss = 0.0068189035996538165
Trained batch 167 in epoch 19, gen_loss = 0.4313596552681355, disc_loss = 0.006788117303152657
Trained batch 168 in epoch 19, gen_loss = 0.4312568275180794, disc_loss = 0.006760251054611917
Trained batch 169 in epoch 19, gen_loss = 0.4311899502487744, disc_loss = 0.006782479109653436
Trained batch 170 in epoch 19, gen_loss = 0.4311625788434904, disc_loss = 0.0067717404266797575
Trained batch 171 in epoch 19, gen_loss = 0.43141477364440295, disc_loss = 0.006767446003978812
Trained batch 172 in epoch 19, gen_loss = 0.4319533182017376, disc_loss = 0.006778190711195543
Trained batch 173 in epoch 19, gen_loss = 0.432487350085686, disc_loss = 0.00676114522870737
Trained batch 174 in epoch 19, gen_loss = 0.4328060015610286, disc_loss = 0.006739421593956649
Trained batch 175 in epoch 19, gen_loss = 0.4327084037729285, disc_loss = 0.006716452367651404
Trained batch 176 in epoch 19, gen_loss = 0.4326730698852216, disc_loss = 0.006746610729839379
Trained batch 177 in epoch 19, gen_loss = 0.43233712151479187, disc_loss = 0.007663086860498225
Trained batch 178 in epoch 19, gen_loss = 0.4327115651282518, disc_loss = 0.00920857877051718
Trained batch 179 in epoch 19, gen_loss = 0.43262797511286205, disc_loss = 0.009213192479607338
Trained batch 180 in epoch 19, gen_loss = 0.4325406452568855, disc_loss = 0.009547417672757491
Trained batch 181 in epoch 19, gen_loss = 0.4325795808991233, disc_loss = 0.009546929236711259
Trained batch 182 in epoch 19, gen_loss = 0.4327391594485507, disc_loss = 0.009610506500463545
Trained batch 183 in epoch 19, gen_loss = 0.4325314559366392, disc_loss = 0.009780887902192973
Trained batch 184 in epoch 19, gen_loss = 0.4326565911640992, disc_loss = 0.010783472398572878
Trained batch 185 in epoch 19, gen_loss = 0.432453649178628, disc_loss = 0.01090839797923822
Trained batch 186 in epoch 19, gen_loss = 0.4322571886733254, disc_loss = 0.011392116111474122
Trained batch 187 in epoch 19, gen_loss = 0.4327301673115568, disc_loss = 0.011488927838496586
Trained batch 188 in epoch 19, gen_loss = 0.4329451322555542, disc_loss = 0.011481213652548533
Trained batch 189 in epoch 19, gen_loss = 0.43295520371512364, disc_loss = 0.01163267160729064
Trained batch 190 in epoch 19, gen_loss = 0.4327268023141392, disc_loss = 0.011619980235496312
Trained batch 191 in epoch 19, gen_loss = 0.4322982599648337, disc_loss = 0.011580557223472473
Trained batch 192 in epoch 19, gen_loss = 0.43247685330519403, disc_loss = 0.011681344698501721
Trained batch 193 in epoch 19, gen_loss = 0.4323052111052975, disc_loss = 0.011685276567844731
Trained batch 194 in epoch 19, gen_loss = 0.43232204700127624, disc_loss = 0.011651272238948598
Trained batch 195 in epoch 19, gen_loss = 0.43220143932469035, disc_loss = 0.011643039265158112
Trained batch 196 in epoch 19, gen_loss = 0.4323222820226311, disc_loss = 0.011622285064390203
Trained batch 197 in epoch 19, gen_loss = 0.43217456777288454, disc_loss = 0.011671546226334428
Trained batch 198 in epoch 19, gen_loss = 0.4321521661389413, disc_loss = 0.011627167887428784
Trained batch 199 in epoch 19, gen_loss = 0.4326877075433731, disc_loss = 0.012025191013817675
Trained batch 200 in epoch 19, gen_loss = 0.43254256722938955, disc_loss = 0.01202699746206792
Trained batch 201 in epoch 19, gen_loss = 0.43248621396499104, disc_loss = 0.012003572674417444
Trained batch 202 in epoch 19, gen_loss = 0.43240615945731475, disc_loss = 0.011994290113416982
Trained batch 203 in epoch 19, gen_loss = 0.4322128534024837, disc_loss = 0.012126486701091897
Trained batch 204 in epoch 19, gen_loss = 0.43230357722538276, disc_loss = 0.012161489510795147
Trained batch 205 in epoch 19, gen_loss = 0.4321346812456557, disc_loss = 0.012329352719514875
Trained batch 206 in epoch 19, gen_loss = 0.43189333372070016, disc_loss = 0.012908750981348905
Trained batch 207 in epoch 19, gen_loss = 0.43210617567484194, disc_loss = 0.012888323200548677
Trained batch 208 in epoch 19, gen_loss = 0.4325971597689761, disc_loss = 0.013025372568183717
Trained batch 209 in epoch 19, gen_loss = 0.43255064004943483, disc_loss = 0.013060916825530252
Trained batch 210 in epoch 19, gen_loss = 0.43260065836929035, disc_loss = 0.01303281710357339
Trained batch 211 in epoch 19, gen_loss = 0.4330683370243828, disc_loss = 0.013001408788731392
Trained batch 212 in epoch 19, gen_loss = 0.4334625867610806, disc_loss = 0.012973360503595235
Trained batch 213 in epoch 19, gen_loss = 0.4336376805728841, disc_loss = 0.012980959992355311
Trained batch 214 in epoch 19, gen_loss = 0.433752000747725, disc_loss = 0.012948022586250201
Trained batch 215 in epoch 19, gen_loss = 0.4340651894885081, disc_loss = 0.012969905142435218
Trained batch 216 in epoch 19, gen_loss = 0.4337278314724496, disc_loss = 0.01293811764759076
Trained batch 217 in epoch 19, gen_loss = 0.43404115353702405, disc_loss = 0.012901488055556227
Trained batch 218 in epoch 19, gen_loss = 0.43433156840877446, disc_loss = 0.012886148265596973
Trained batch 219 in epoch 19, gen_loss = 0.43434812114997345, disc_loss = 0.012861391891915859
Trained batch 220 in epoch 19, gen_loss = 0.4347071543807897, disc_loss = 0.012831140994894998
Trained batch 221 in epoch 19, gen_loss = 0.43479603112817883, disc_loss = 0.012785126232261022
Trained batch 222 in epoch 19, gen_loss = 0.4348508123592411, disc_loss = 0.012739597403678225
Trained batch 223 in epoch 19, gen_loss = 0.4346146366692015, disc_loss = 0.012692287368346504
Trained batch 224 in epoch 19, gen_loss = 0.43433449586232503, disc_loss = 0.01264629713104417
Trained batch 225 in epoch 19, gen_loss = 0.434273538204421, disc_loss = 0.01262316413262892
Trained batch 226 in epoch 19, gen_loss = 0.4342466191048139, disc_loss = 0.012579161127606644
Trained batch 227 in epoch 19, gen_loss = 0.4343312385312298, disc_loss = 0.012530951981796278
Trained batch 228 in epoch 19, gen_loss = 0.43435801324886003, disc_loss = 0.012505601941583492
Trained batch 229 in epoch 19, gen_loss = 0.43434111022430916, disc_loss = 0.012458423811071755
Trained batch 230 in epoch 19, gen_loss = 0.43403096297086574, disc_loss = 0.012418507452695368
Trained batch 231 in epoch 19, gen_loss = 0.43405838413485165, disc_loss = 0.0123740153157369
Trained batch 232 in epoch 19, gen_loss = 0.43405312120658646, disc_loss = 0.012327762885726668
Trained batch 233 in epoch 19, gen_loss = 0.4340159433265018, disc_loss = 0.012283118264590446
Trained batch 234 in epoch 19, gen_loss = 0.4338321269826686, disc_loss = 0.01226950045873193
Trained batch 235 in epoch 19, gen_loss = 0.43391717174800776, disc_loss = 0.012253080595332056
Trained batch 236 in epoch 19, gen_loss = 0.43363789956277937, disc_loss = 0.012209121587308996
Trained batch 237 in epoch 19, gen_loss = 0.43370537885597776, disc_loss = 0.012163421877233327
Trained batch 238 in epoch 19, gen_loss = 0.43367260781790923, disc_loss = 0.01212903496441061
Trained batch 239 in epoch 19, gen_loss = 0.4337150233487288, disc_loss = 0.012087298175417042
Trained batch 240 in epoch 19, gen_loss = 0.433849089620519, disc_loss = 0.012043549487931475
Trained batch 241 in epoch 19, gen_loss = 0.43380618772723456, disc_loss = 0.012001415755992279
Trained batch 242 in epoch 19, gen_loss = 0.43389905001891493, disc_loss = 0.011967487911092032
Trained batch 243 in epoch 19, gen_loss = 0.43379581279930524, disc_loss = 0.011927389180990027
Trained batch 244 in epoch 19, gen_loss = 0.43399089586978057, disc_loss = 0.011885444809473594
Trained batch 245 in epoch 19, gen_loss = 0.4340566996394134, disc_loss = 0.011873847408394322
Trained batch 246 in epoch 19, gen_loss = 0.43402032946285446, disc_loss = 0.01183048331910209
Trained batch 247 in epoch 19, gen_loss = 0.4341325970186341, disc_loss = 0.01179134551221655
Trained batch 248 in epoch 19, gen_loss = 0.43383097445150937, disc_loss = 0.011790827499238783
Trained batch 249 in epoch 19, gen_loss = 0.43392817628383634, disc_loss = 0.01175531395431608
Trained batch 250 in epoch 19, gen_loss = 0.43379020679044533, disc_loss = 0.011742737696161012
Trained batch 251 in epoch 19, gen_loss = 0.43374940622893593, disc_loss = 0.011702789010347001
Trained batch 252 in epoch 19, gen_loss = 0.4337592394691211, disc_loss = 0.011670871741753144
Trained batch 253 in epoch 19, gen_loss = 0.43377345213739893, disc_loss = 0.011634906078322137
Trained batch 254 in epoch 19, gen_loss = 0.433910161373662, disc_loss = 0.011635459761372676
Trained batch 255 in epoch 19, gen_loss = 0.4338791851187125, disc_loss = 0.011602415410379763
Trained batch 256 in epoch 19, gen_loss = 0.43381157946493837, disc_loss = 0.01159247065847196
Trained batch 257 in epoch 19, gen_loss = 0.43373759114002997, disc_loss = 0.01164371391592273
Trained batch 258 in epoch 19, gen_loss = 0.43346772656477556, disc_loss = 0.011657369939761388
Trained batch 259 in epoch 19, gen_loss = 0.43388939648866653, disc_loss = 0.011699044548619825
Trained batch 260 in epoch 19, gen_loss = 0.4339059478250043, disc_loss = 0.01168463654794741
Trained batch 261 in epoch 19, gen_loss = 0.43396355791856317, disc_loss = 0.011885262074887411
Trained batch 262 in epoch 19, gen_loss = 0.43411935112322236, disc_loss = 0.012098204544586034
Trained batch 263 in epoch 19, gen_loss = 0.43425770995743346, disc_loss = 0.012068255758618541
Trained batch 264 in epoch 19, gen_loss = 0.4339608537700941, disc_loss = 0.01245397231980877
Trained batch 265 in epoch 19, gen_loss = 0.43362988329919655, disc_loss = 0.012460931851983742
Trained batch 266 in epoch 19, gen_loss = 0.4336827675278267, disc_loss = 0.01255036470190751
Trained batch 267 in epoch 19, gen_loss = 0.43376559919830576, disc_loss = 0.012553534623402269
Trained batch 268 in epoch 19, gen_loss = 0.4339320723895247, disc_loss = 0.012807634212492125
Trained batch 269 in epoch 19, gen_loss = 0.4340501470698251, disc_loss = 0.01327122778252319
Trained batch 270 in epoch 19, gen_loss = 0.43390402219832164, disc_loss = 0.01334574024065834
Trained batch 271 in epoch 19, gen_loss = 0.43398284342359095, disc_loss = 0.013334884458933683
Trained batch 272 in epoch 19, gen_loss = 0.43417912022971406, disc_loss = 0.013294299860611121
Trained batch 273 in epoch 19, gen_loss = 0.4342152678618466, disc_loss = 0.013259247113631046
Trained batch 274 in epoch 19, gen_loss = 0.4343792810223319, disc_loss = 0.013234235593541102
Trained batch 275 in epoch 19, gen_loss = 0.43429466812075046, disc_loss = 0.013194411630283339
Trained batch 276 in epoch 19, gen_loss = 0.4342600732288636, disc_loss = 0.013185577223326217
Trained batch 277 in epoch 19, gen_loss = 0.43442809881923866, disc_loss = 0.013153035707919182
Trained batch 278 in epoch 19, gen_loss = 0.4346140882661266, disc_loss = 0.013125367259012541
Trained batch 279 in epoch 19, gen_loss = 0.43464369688715254, disc_loss = 0.013126163204599703
Trained batch 280 in epoch 19, gen_loss = 0.43466515844402787, disc_loss = 0.013092828283146077
Trained batch 281 in epoch 19, gen_loss = 0.4345608284921511, disc_loss = 0.013054596337800225
Trained batch 282 in epoch 19, gen_loss = 0.4345345310735197, disc_loss = 0.013021624276855492
Trained batch 283 in epoch 19, gen_loss = 0.4343210897395309, disc_loss = 0.013002308992288587
Trained batch 284 in epoch 19, gen_loss = 0.4341957576442183, disc_loss = 0.013006517322113116
Trained batch 285 in epoch 19, gen_loss = 0.4343010882189224, disc_loss = 0.012974598345678899
Trained batch 286 in epoch 19, gen_loss = 0.4342849414523055, disc_loss = 0.012949056366867408
Trained batch 287 in epoch 19, gen_loss = 0.4340564896249109, disc_loss = 0.012930434717822613
Trained batch 288 in epoch 19, gen_loss = 0.4341856115417084, disc_loss = 0.012911717600759544
Trained batch 289 in epoch 19, gen_loss = 0.43433873180685373, disc_loss = 0.012877484838125007
Trained batch 290 in epoch 19, gen_loss = 0.43454963245342687, disc_loss = 0.012844187952418047
Trained batch 291 in epoch 19, gen_loss = 0.43454090026143477, disc_loss = 0.012832824337736333
Trained batch 292 in epoch 19, gen_loss = 0.4347034743621488, disc_loss = 0.012803543677693392
Trained batch 293 in epoch 19, gen_loss = 0.434857739376373, disc_loss = 0.01278054017374026
Trained batch 294 in epoch 19, gen_loss = 0.43490083136800994, disc_loss = 0.012760516449461802
Trained batch 295 in epoch 19, gen_loss = 0.4350525695528533, disc_loss = 0.012725303983127044
Trained batch 296 in epoch 19, gen_loss = 0.4348522668535059, disc_loss = 0.01274922386169283
Trained batch 297 in epoch 19, gen_loss = 0.4350008478500699, disc_loss = 0.01275255328400573
Trained batch 298 in epoch 19, gen_loss = 0.43522614420058336, disc_loss = 0.0127497664933096
Trained batch 299 in epoch 19, gen_loss = 0.4355693856875102, disc_loss = 0.012750653669548532
Trained batch 300 in epoch 19, gen_loss = 0.43549813137101967, disc_loss = 0.01272275861185601
Trained batch 301 in epoch 19, gen_loss = 0.43566085852139835, disc_loss = 0.01269561273742788
Trained batch 302 in epoch 19, gen_loss = 0.4357913094188514, disc_loss = 0.012669625595248866
Trained batch 303 in epoch 19, gen_loss = 0.4358353746172629, disc_loss = 0.012638500687899068
Trained batch 304 in epoch 19, gen_loss = 0.4356947726890689, disc_loss = 0.012617346111562898
Trained batch 305 in epoch 19, gen_loss = 0.43560248360135195, disc_loss = 0.012581668192675957
Trained batch 306 in epoch 19, gen_loss = 0.4354558796758372, disc_loss = 0.012548554249954219
Trained batch 307 in epoch 19, gen_loss = 0.43549600669315885, disc_loss = 0.012512503447715652
Trained batch 308 in epoch 19, gen_loss = 0.43540200465705403, disc_loss = 0.012478685196003843
Trained batch 309 in epoch 19, gen_loss = 0.4352418139096229, disc_loss = 0.012461894026191364
Trained batch 310 in epoch 19, gen_loss = 0.4351802774947556, disc_loss = 0.012447581164931153
Trained batch 311 in epoch 19, gen_loss = 0.43507879065015376, disc_loss = 0.012415683250322055
Trained batch 312 in epoch 19, gen_loss = 0.4350060644431617, disc_loss = 0.012379886802678671
Trained batch 313 in epoch 19, gen_loss = 0.43495810335608803, disc_loss = 0.012351852557681215
Trained batch 314 in epoch 19, gen_loss = 0.43496853538921904, disc_loss = 0.012317994633127773
Trained batch 315 in epoch 19, gen_loss = 0.4350460722476621, disc_loss = 0.012284827607616051
Trained batch 316 in epoch 19, gen_loss = 0.4350852570511189, disc_loss = 0.01225032069395687
Trained batch 317 in epoch 19, gen_loss = 0.4348671602190666, disc_loss = 0.012218465047826955
Trained batch 318 in epoch 19, gen_loss = 0.4349199316718362, disc_loss = 0.012193972351785667
Trained batch 319 in epoch 19, gen_loss = 0.4346621262840927, disc_loss = 0.01216310130803322
Trained batch 320 in epoch 19, gen_loss = 0.4347374801323793, disc_loss = 0.01212898247354487
Trained batch 321 in epoch 19, gen_loss = 0.4346948534435367, disc_loss = 0.012108605330078197
Trained batch 322 in epoch 19, gen_loss = 0.4349253022633839, disc_loss = 0.012075310844377306
Trained batch 323 in epoch 19, gen_loss = 0.43494859438987427, disc_loss = 0.012044475103777338
Trained batch 324 in epoch 19, gen_loss = 0.4349323552388411, disc_loss = 0.012011820266309838
Trained batch 325 in epoch 19, gen_loss = 0.43488614800517544, disc_loss = 0.01197886509475144
Trained batch 326 in epoch 19, gen_loss = 0.43473394967000417, disc_loss = 0.01194577224642346
Trained batch 327 in epoch 19, gen_loss = 0.43487868803303414, disc_loss = 0.011916501584914287
Trained batch 328 in epoch 19, gen_loss = 0.4349981356174388, disc_loss = 0.01188362401444465
Trained batch 329 in epoch 19, gen_loss = 0.4350514587127801, disc_loss = 0.011862183101545793
Trained batch 330 in epoch 19, gen_loss = 0.4347848739148627, disc_loss = 0.011830171756235337
Trained batch 331 in epoch 19, gen_loss = 0.43470081920365256, disc_loss = 0.011805374860126772
Trained batch 332 in epoch 19, gen_loss = 0.4345889055693114, disc_loss = 0.011773800549751802
Trained batch 333 in epoch 19, gen_loss = 0.43470039339122657, disc_loss = 0.011744270374103376
Trained batch 334 in epoch 19, gen_loss = 0.4346527877138622, disc_loss = 0.011717306799255311
Trained batch 335 in epoch 19, gen_loss = 0.43482342255967005, disc_loss = 0.011691896189794144
Trained batch 336 in epoch 19, gen_loss = 0.43465972079367593, disc_loss = 0.011662670388024644
Trained batch 337 in epoch 19, gen_loss = 0.43468840384977103, disc_loss = 0.011632250731786128
Trained batch 338 in epoch 19, gen_loss = 0.4346515044877663, disc_loss = 0.011602979493712055
Trained batch 339 in epoch 19, gen_loss = 0.4346108797718497, disc_loss = 0.011574833040632417
Trained batch 340 in epoch 19, gen_loss = 0.4345809978124333, disc_loss = 0.011548652824716331
Trained batch 341 in epoch 19, gen_loss = 0.43461778176109694, disc_loss = 0.011525683283699644
Trained batch 342 in epoch 19, gen_loss = 0.43466940018247935, disc_loss = 0.011496587352672423
Trained batch 343 in epoch 19, gen_loss = 0.43456583305500274, disc_loss = 0.011466225917480864
Trained batch 344 in epoch 19, gen_loss = 0.4346613575582919, disc_loss = 0.01143976027328197
Trained batch 345 in epoch 19, gen_loss = 0.4347226739446552, disc_loss = 0.011417150823466716
Trained batch 346 in epoch 19, gen_loss = 0.43468230181193834, disc_loss = 0.011387484500410106
Trained batch 347 in epoch 19, gen_loss = 0.4349047604134713, disc_loss = 0.011365811327798828
Trained batch 348 in epoch 19, gen_loss = 0.4348173086827669, disc_loss = 0.011337601558043805
Trained batch 349 in epoch 19, gen_loss = 0.43479318090847563, disc_loss = 0.011313690708484501
Trained batch 350 in epoch 19, gen_loss = 0.4349364006621206, disc_loss = 0.011286175638991819
Trained batch 351 in epoch 19, gen_loss = 0.4349588213319128, disc_loss = 0.011371712371328613
Trained batch 352 in epoch 19, gen_loss = 0.4352367189383034, disc_loss = 0.011509102694334056
Trained batch 353 in epoch 19, gen_loss = 0.43522548616605966, disc_loss = 0.011486656533351621
Trained batch 354 in epoch 19, gen_loss = 0.4351117104711667, disc_loss = 0.011641481236397275
Trained batch 355 in epoch 19, gen_loss = 0.4352141222759579, disc_loss = 0.01170702093494062
Trained batch 356 in epoch 19, gen_loss = 0.43511964827358557, disc_loss = 0.01187422163151883
Trained batch 357 in epoch 19, gen_loss = 0.43514179384242224, disc_loss = 0.011863540968267174
Trained batch 358 in epoch 19, gen_loss = 0.43538293449991594, disc_loss = 0.01184823463215625
Trained batch 359 in epoch 19, gen_loss = 0.4353997473087576, disc_loss = 0.011826102185619271
Trained batch 360 in epoch 19, gen_loss = 0.43561423064268856, disc_loss = 0.011799131599745076
Trained batch 361 in epoch 19, gen_loss = 0.4355837894572738, disc_loss = 0.011772965036978358
Trained batch 362 in epoch 19, gen_loss = 0.435709088794456, disc_loss = 0.011746123577750317
Trained batch 363 in epoch 19, gen_loss = 0.435878065097463, disc_loss = 0.011724952775614009
Trained batch 364 in epoch 19, gen_loss = 0.4357990700904637, disc_loss = 0.01169891643867356
Trained batch 365 in epoch 19, gen_loss = 0.43582840630265535, disc_loss = 0.011670892654544079
Trained batch 366 in epoch 19, gen_loss = 0.43580562103671666, disc_loss = 0.01164245373335964
Trained batch 367 in epoch 19, gen_loss = 0.43587846584294154, disc_loss = 0.011615955330299861
Trained batch 368 in epoch 19, gen_loss = 0.4358382037661586, disc_loss = 0.011597173716267192
Trained batch 369 in epoch 19, gen_loss = 0.4359386799303261, disc_loss = 0.011569487050842694
Trained batch 370 in epoch 19, gen_loss = 0.43581766500627256, disc_loss = 0.011549364523447528
Trained batch 371 in epoch 19, gen_loss = 0.4357149645846377, disc_loss = 0.011525101007415502
Trained batch 372 in epoch 19, gen_loss = 0.43571412882919924, disc_loss = 0.011498534700823274
Trained batch 373 in epoch 19, gen_loss = 0.4358561385602237, disc_loss = 0.01147466947114155
Trained batch 374 in epoch 19, gen_loss = 0.4357922568321228, disc_loss = 0.0114465212803334
Trained batch 375 in epoch 19, gen_loss = 0.4357655370172034, disc_loss = 0.011422923498569017
Trained batch 376 in epoch 19, gen_loss = 0.43571701527274254, disc_loss = 0.011400298618116176
Trained batch 377 in epoch 19, gen_loss = 0.43543649476671975, disc_loss = 0.011408288004714502
Trained batch 378 in epoch 19, gen_loss = 0.43541392982792415, disc_loss = 0.011386590908431402
Trained batch 379 in epoch 19, gen_loss = 0.43524684349172993, disc_loss = 0.011362331792540653
Trained batch 380 in epoch 19, gen_loss = 0.4352396322986272, disc_loss = 0.011344692291535457
Trained batch 381 in epoch 19, gen_loss = 0.43508584227861535, disc_loss = 0.011321078481259926
Trained batch 382 in epoch 19, gen_loss = 0.4350287095684918, disc_loss = 0.011295467431537866
Trained batch 383 in epoch 19, gen_loss = 0.43495513995488483, disc_loss = 0.01127037149277991
Trained batch 384 in epoch 19, gen_loss = 0.43499190265482124, disc_loss = 0.0112461838088083
Trained batch 385 in epoch 19, gen_loss = 0.43487011181875834, disc_loss = 0.011220238267424772
Trained batch 386 in epoch 19, gen_loss = 0.4349173093334957, disc_loss = 0.011197109994880413
Trained batch 387 in epoch 19, gen_loss = 0.43505554723063694, disc_loss = 0.011192041088601324
Trained batch 388 in epoch 19, gen_loss = 0.43513838161539603, disc_loss = 0.011187601661558591
Trained batch 389 in epoch 19, gen_loss = 0.4350536172206585, disc_loss = 0.011188973910891666
Trained batch 390 in epoch 19, gen_loss = 0.435125212535224, disc_loss = 0.011184332017546228
Trained batch 391 in epoch 19, gen_loss = 0.4353520970563499, disc_loss = 0.011187854257996708
Trained batch 392 in epoch 19, gen_loss = 0.4352905137544977, disc_loss = 0.011174729987907842
Trained batch 393 in epoch 19, gen_loss = 0.4353212294390964, disc_loss = 0.01115630304400672
Trained batch 394 in epoch 19, gen_loss = 0.4354735929754716, disc_loss = 0.011135558547640714
Trained batch 395 in epoch 19, gen_loss = 0.43549484473587285, disc_loss = 0.011115889679969787
Trained batch 396 in epoch 19, gen_loss = 0.4354984143218706, disc_loss = 0.011092471392234078
Trained batch 397 in epoch 19, gen_loss = 0.43540151102758534, disc_loss = 0.011067893870301245
Trained batch 398 in epoch 19, gen_loss = 0.43539249620640785, disc_loss = 0.011058144658257751
Trained batch 399 in epoch 19, gen_loss = 0.4354036654531956, disc_loss = 0.01103565068624448
Trained batch 400 in epoch 19, gen_loss = 0.43532307999687003, disc_loss = 0.011022363954857735
Trained batch 401 in epoch 19, gen_loss = 0.4352631542961396, disc_loss = 0.010999195154325398
Trained batch 402 in epoch 19, gen_loss = 0.43538161069524495, disc_loss = 0.01098608216397908
Trained batch 403 in epoch 19, gen_loss = 0.4352066105250085, disc_loss = 0.010964419667396953
Trained batch 404 in epoch 19, gen_loss = 0.43516215387685797, disc_loss = 0.010946923872616924
Trained batch 405 in epoch 19, gen_loss = 0.43528423704243646, disc_loss = 0.010923797332938632
Trained batch 406 in epoch 19, gen_loss = 0.43522469292987476, disc_loss = 0.01090209893378857
Trained batch 407 in epoch 19, gen_loss = 0.43517809090953247, disc_loss = 0.010879123122910695
Trained batch 408 in epoch 19, gen_loss = 0.4352044769196172, disc_loss = 0.010863375627438021
Trained batch 409 in epoch 19, gen_loss = 0.43533593430751705, disc_loss = 0.010841429908475952
Trained batch 410 in epoch 19, gen_loss = 0.4355709406291191, disc_loss = 0.01085866482190815
Trained batch 411 in epoch 19, gen_loss = 0.4355016148929457, disc_loss = 0.010851210935179198
Trained batch 412 in epoch 19, gen_loss = 0.435482027311302, disc_loss = 0.010832634798169911
Trained batch 413 in epoch 19, gen_loss = 0.4354041892549266, disc_loss = 0.010810995836357546
Trained batch 414 in epoch 19, gen_loss = 0.43544669819165427, disc_loss = 0.010812637779626053
Trained batch 415 in epoch 19, gen_loss = 0.43577805455200946, disc_loss = 0.010797370392817985
Trained batch 416 in epoch 19, gen_loss = 0.43588791798344617, disc_loss = 0.010799303829247842
Trained batch 417 in epoch 19, gen_loss = 0.43593509117381996, disc_loss = 0.010785759182404014
Trained batch 418 in epoch 19, gen_loss = 0.4360758926817227, disc_loss = 0.010769835040628964
Trained batch 419 in epoch 19, gen_loss = 0.43608127796933766, disc_loss = 0.010752992561208971
Trained batch 420 in epoch 19, gen_loss = 0.43620811781520796, disc_loss = 0.010741689992070888
Trained batch 421 in epoch 19, gen_loss = 0.4361544973901098, disc_loss = 0.01072261515774177
Trained batch 422 in epoch 19, gen_loss = 0.43611977518873013, disc_loss = 0.010704980795734053
Trained batch 423 in epoch 19, gen_loss = 0.4360021581205557, disc_loss = 0.010682095297972479
Trained batch 424 in epoch 19, gen_loss = 0.43589765085893517, disc_loss = 0.010662422093069729
Trained batch 425 in epoch 19, gen_loss = 0.4357140521068528, disc_loss = 0.010639568682303084
Trained batch 426 in epoch 19, gen_loss = 0.4354287542280604, disc_loss = 0.010627591006176445
Trained batch 427 in epoch 19, gen_loss = 0.4354808586780156, disc_loss = 0.010606436212558003
Trained batch 428 in epoch 19, gen_loss = 0.43546724493131217, disc_loss = 0.01058706089594816
Trained batch 429 in epoch 19, gen_loss = 0.43545372382152914, disc_loss = 0.010568321256107802
Trained batch 430 in epoch 19, gen_loss = 0.43557569716480105, disc_loss = 0.010545679462075302
Trained batch 431 in epoch 19, gen_loss = 0.43539676042618575, disc_loss = 0.010579447125093322
Trained batch 432 in epoch 19, gen_loss = 0.43535356392210683, disc_loss = 0.010561454161468196
Trained batch 433 in epoch 19, gen_loss = 0.43540237782188274, disc_loss = 0.010543744442426527
Trained batch 434 in epoch 19, gen_loss = 0.4354359913146359, disc_loss = 0.010525587005754825
Trained batch 435 in epoch 19, gen_loss = 0.43541083580583606, disc_loss = 0.010510164886550688
Trained batch 436 in epoch 19, gen_loss = 0.4355374246631116, disc_loss = 0.010497707944977133
Trained batch 437 in epoch 19, gen_loss = 0.43550318915005687, disc_loss = 0.010480726026126172
Trained batch 438 in epoch 19, gen_loss = 0.4355399252885023, disc_loss = 0.010463298834618478
Trained batch 439 in epoch 19, gen_loss = 0.43556984947486355, disc_loss = 0.010466381314274093
Trained batch 440 in epoch 19, gen_loss = 0.435707908909337, disc_loss = 0.010448153588979964
Trained batch 441 in epoch 19, gen_loss = 0.4357059654606953, disc_loss = 0.010427995839069821
Trained batch 442 in epoch 19, gen_loss = 0.43590180572483933, disc_loss = 0.0104130866774936
Trained batch 443 in epoch 19, gen_loss = 0.4360586371239241, disc_loss = 0.01039457883028238
Trained batch 444 in epoch 19, gen_loss = 0.43590418837043676, disc_loss = 0.010377210357456645
Trained batch 445 in epoch 19, gen_loss = 0.43596241078569214, disc_loss = 0.010360349664796611
Trained batch 446 in epoch 19, gen_loss = 0.435947177127437, disc_loss = 0.010342588918273164
Trained batch 447 in epoch 19, gen_loss = 0.43595001972945674, disc_loss = 0.010324297928361505
Trained batch 448 in epoch 19, gen_loss = 0.43596581434353954, disc_loss = 0.010304317717079512
Trained batch 449 in epoch 19, gen_loss = 0.43599654184447395, disc_loss = 0.010285698126794564
Trained batch 450 in epoch 19, gen_loss = 0.43580365696397433, disc_loss = 0.010269905320222091
Trained batch 451 in epoch 19, gen_loss = 0.43584073414053537, disc_loss = 0.010250286937050473
Trained batch 452 in epoch 19, gen_loss = 0.43592737282875094, disc_loss = 0.01023451606182805
Trained batch 453 in epoch 19, gen_loss = 0.4359948624598297, disc_loss = 0.01021597984412045
Trained batch 454 in epoch 19, gen_loss = 0.4358400891770373, disc_loss = 0.01020056905639409
Trained batch 455 in epoch 19, gen_loss = 0.43592679278369534, disc_loss = 0.010181258092001244
Trained batch 456 in epoch 19, gen_loss = 0.43585614824190705, disc_loss = 0.010160975732903773
Trained batch 457 in epoch 19, gen_loss = 0.43592941136339347, disc_loss = 0.010141184498600695
Trained batch 458 in epoch 19, gen_loss = 0.436082251840687, disc_loss = 0.010121261259167574
Trained batch 459 in epoch 19, gen_loss = 0.4359759523816731, disc_loss = 0.010102078918134794
Trained batch 460 in epoch 19, gen_loss = 0.43607216788993225, disc_loss = 0.010086874938428548
Trained batch 461 in epoch 19, gen_loss = 0.43601911931068865, disc_loss = 0.010069362038305005
Trained batch 462 in epoch 19, gen_loss = 0.4358018325806694, disc_loss = 0.010049509881371049
Trained batch 463 in epoch 19, gen_loss = 0.4356436578492666, disc_loss = 0.010029948579577994
Trained batch 464 in epoch 19, gen_loss = 0.43571104682901857, disc_loss = 0.01001045846753323
Trained batch 465 in epoch 19, gen_loss = 0.43563539550795577, disc_loss = 0.009992935430071648
Trained batch 466 in epoch 19, gen_loss = 0.4356133650023115, disc_loss = 0.009972939453595288
Trained batch 467 in epoch 19, gen_loss = 0.4357817312463736, disc_loss = 0.0099545292516237
Trained batch 468 in epoch 19, gen_loss = 0.4357740992167865, disc_loss = 0.00993820709344655
Trained batch 469 in epoch 19, gen_loss = 0.4358424836016716, disc_loss = 0.009918759279993382
Trained batch 470 in epoch 19, gen_loss = 0.4356949154738408, disc_loss = 0.009899295441486978
Trained batch 471 in epoch 19, gen_loss = 0.43570282827999635, disc_loss = 0.009880294382174587
Trained batch 472 in epoch 19, gen_loss = 0.435689039134576, disc_loss = 0.009860933495214875
Trained batch 473 in epoch 19, gen_loss = 0.4356518633003476, disc_loss = 0.009842218436990405
Trained batch 474 in epoch 19, gen_loss = 0.4357038485376458, disc_loss = 0.009823244459510438
Trained batch 475 in epoch 19, gen_loss = 0.4356890637584093, disc_loss = 0.009803926143350135
Trained batch 476 in epoch 19, gen_loss = 0.43582012961995426, disc_loss = 0.009785528958699934
Trained batch 477 in epoch 19, gen_loss = 0.4358327177403861, disc_loss = 0.009768457267999407
Trained batch 478 in epoch 19, gen_loss = 0.4357164242695667, disc_loss = 0.009749601189351382
Trained batch 479 in epoch 19, gen_loss = 0.4357474172487855, disc_loss = 0.00973285750139136
Trained batch 480 in epoch 19, gen_loss = 0.43575569634130246, disc_loss = 0.009714394215452766
Trained batch 481 in epoch 19, gen_loss = 0.4356479747414094, disc_loss = 0.009696636416227653
Trained batch 482 in epoch 19, gen_loss = 0.4355265427203405, disc_loss = 0.009678170651001721
Trained batch 483 in epoch 19, gen_loss = 0.43546931334763517, disc_loss = 0.009660398570627305
Trained batch 484 in epoch 19, gen_loss = 0.43551022373523907, disc_loss = 0.009644119375140512
Trained batch 485 in epoch 19, gen_loss = 0.4354989657431473, disc_loss = 0.00962661158251806
Trained batch 486 in epoch 19, gen_loss = 0.435618978506241, disc_loss = 0.009608768523709937
Trained batch 487 in epoch 19, gen_loss = 0.4354834218249946, disc_loss = 0.00959042080815931
Trained batch 488 in epoch 19, gen_loss = 0.43560462885351514, disc_loss = 0.009572533442441694
Trained batch 489 in epoch 19, gen_loss = 0.4355420168565244, disc_loss = 0.009555175780361443
Trained batch 490 in epoch 19, gen_loss = 0.4356131519052502, disc_loss = 0.00953767034512055
Trained batch 491 in epoch 19, gen_loss = 0.43553199201095394, disc_loss = 0.009519554612986796
Trained batch 492 in epoch 19, gen_loss = 0.4353746189065202, disc_loss = 0.009501677709225467
Trained batch 493 in epoch 19, gen_loss = 0.4353432872517389, disc_loss = 0.009484972540847203
Trained batch 494 in epoch 19, gen_loss = 0.435356985800194, disc_loss = 0.009468223465220872
Trained batch 495 in epoch 19, gen_loss = 0.43546001384815863, disc_loss = 0.009450721324091934
Trained batch 496 in epoch 19, gen_loss = 0.4355388602140684, disc_loss = 0.009433094255501588
Trained batch 497 in epoch 19, gen_loss = 0.4355465788917848, disc_loss = 0.009415667469591748
Trained batch 498 in epoch 19, gen_loss = 0.4354073331805174, disc_loss = 0.00939785961805001
Trained batch 499 in epoch 19, gen_loss = 0.43525882399082183, disc_loss = 0.009380477327154949
Trained batch 500 in epoch 19, gen_loss = 0.4352343152026216, disc_loss = 0.009362979062429505
Trained batch 501 in epoch 19, gen_loss = 0.4352730228250245, disc_loss = 0.009346148875760902
Trained batch 502 in epoch 19, gen_loss = 0.43540500107389796, disc_loss = 0.009329212395748342
Trained batch 503 in epoch 19, gen_loss = 0.4353088533712758, disc_loss = 0.009312921116361395
Trained batch 504 in epoch 19, gen_loss = 0.4354098656980118, disc_loss = 0.009296547017973101
Trained batch 505 in epoch 19, gen_loss = 0.43548748692269384, disc_loss = 0.009279272132764825
Trained batch 506 in epoch 19, gen_loss = 0.4354794530943771, disc_loss = 0.009262739597127223
Trained batch 507 in epoch 19, gen_loss = 0.43547389445107754, disc_loss = 0.009245848771749342
Trained batch 508 in epoch 19, gen_loss = 0.435410919498601, disc_loss = 0.009229578231260077
Trained batch 509 in epoch 19, gen_loss = 0.43528864301887216, disc_loss = 0.009212925067792336
Trained batch 510 in epoch 19, gen_loss = 0.43530091666662063, disc_loss = 0.009196915775182094
Trained batch 511 in epoch 19, gen_loss = 0.43554072693223134, disc_loss = 0.009181315777141208
Trained batch 512 in epoch 19, gen_loss = 0.4354152698614444, disc_loss = 0.009165133356178436
Trained batch 513 in epoch 19, gen_loss = 0.4353734287886304, disc_loss = 0.009150466316149493
Trained batch 514 in epoch 19, gen_loss = 0.43537013212453973, disc_loss = 0.009133806069227821
Trained batch 515 in epoch 19, gen_loss = 0.43533594825471095, disc_loss = 0.009118009079337958
Trained batch 516 in epoch 19, gen_loss = 0.4352730138504759, disc_loss = 0.00910129686753352
Trained batch 517 in epoch 19, gen_loss = 0.43537137504940326, disc_loss = 0.00908533155718777
Trained batch 518 in epoch 19, gen_loss = 0.4354549745144412, disc_loss = 0.00906897916756651
Trained batch 519 in epoch 19, gen_loss = 0.4354767193014805, disc_loss = 0.009052850050871851
Trained batch 520 in epoch 19, gen_loss = 0.43540171738320715, disc_loss = 0.009037656218473552
Trained batch 521 in epoch 19, gen_loss = 0.43532295525074005, disc_loss = 0.009021593597608304
Trained batch 522 in epoch 19, gen_loss = 0.4352833535771525, disc_loss = 0.00900684449999561
Trained batch 523 in epoch 19, gen_loss = 0.4353226191214933, disc_loss = 0.008990841327230215
Trained batch 524 in epoch 19, gen_loss = 0.4353160690693628, disc_loss = 0.008975337762551914
Trained batch 525 in epoch 19, gen_loss = 0.43518171813551465, disc_loss = 0.0089598747194163
Trained batch 526 in epoch 19, gen_loss = 0.43518334864665253, disc_loss = 0.008944700748460417
Trained batch 527 in epoch 19, gen_loss = 0.43508027121424675, disc_loss = 0.008929528335515484
Trained batch 528 in epoch 19, gen_loss = 0.43507111816189914, disc_loss = 0.008914708078714327
Trained batch 529 in epoch 19, gen_loss = 0.43507772487289503, disc_loss = 0.008899235080450967
Trained batch 530 in epoch 19, gen_loss = 0.4351017120980049, disc_loss = 0.008883749403130954
Trained batch 531 in epoch 19, gen_loss = 0.4350690395760357, disc_loss = 0.008868265387007381
Trained batch 532 in epoch 19, gen_loss = 0.435047437281367, disc_loss = 0.008852683908625385
Trained batch 533 in epoch 19, gen_loss = 0.43503059625402374, disc_loss = 0.008837170799230992
Trained batch 534 in epoch 19, gen_loss = 0.4349523908624025, disc_loss = 0.008821758068282
Trained batch 535 in epoch 19, gen_loss = 0.43508104446218976, disc_loss = 0.008807498880945678
Trained batch 536 in epoch 19, gen_loss = 0.43506407898675575, disc_loss = 0.00879207322302663
Trained batch 537 in epoch 19, gen_loss = 0.43517059996225577, disc_loss = 0.00877824883346946
Trained batch 538 in epoch 19, gen_loss = 0.435127366506987, disc_loss = 0.008763068648764055
Trained batch 539 in epoch 19, gen_loss = 0.4350506713544881, disc_loss = 0.008748030498531147
Trained batch 540 in epoch 19, gen_loss = 0.43501780009974833, disc_loss = 0.00873335531673673
Trained batch 541 in epoch 19, gen_loss = 0.43503682573783004, disc_loss = 0.008718456161035332
Trained batch 542 in epoch 19, gen_loss = 0.43498350517964934, disc_loss = 0.008705290874029367
Trained batch 543 in epoch 19, gen_loss = 0.4350299669210525, disc_loss = 0.008690749858140086
Trained batch 544 in epoch 19, gen_loss = 0.4351313324696427, disc_loss = 0.008676554162937448
Trained batch 545 in epoch 19, gen_loss = 0.43519418531066767, disc_loss = 0.008663685439973678
Trained batch 546 in epoch 19, gen_loss = 0.43515926060118665, disc_loss = 0.008649259778703742
Trained batch 547 in epoch 19, gen_loss = 0.4351278764814356, disc_loss = 0.008634743231157925
Trained batch 548 in epoch 19, gen_loss = 0.435079853554241, disc_loss = 0.008620283148412207
Trained batch 549 in epoch 19, gen_loss = 0.4351377805254676, disc_loss = 0.00860554026116998
Trained batch 550 in epoch 19, gen_loss = 0.43501300317406005, disc_loss = 0.008591083973000069
Trained batch 551 in epoch 19, gen_loss = 0.4349714376680229, disc_loss = 0.008576570916151126
Trained batch 552 in epoch 19, gen_loss = 0.4348286970183388, disc_loss = 0.008562014932661262
Trained batch 553 in epoch 19, gen_loss = 0.4349016127603579, disc_loss = 0.008547881515122974
Trained batch 554 in epoch 19, gen_loss = 0.4348887401658135, disc_loss = 0.008533353016655138
Trained batch 555 in epoch 19, gen_loss = 0.43495428808730285, disc_loss = 0.008519363117589792
Trained batch 556 in epoch 19, gen_loss = 0.4349423297003741, disc_loss = 0.00850515573236822
Trained batch 557 in epoch 19, gen_loss = 0.43477892261465817, disc_loss = 0.008491421470076003
Trained batch 558 in epoch 19, gen_loss = 0.43488126118835696, disc_loss = 0.008478935716674981
Trained batch 559 in epoch 19, gen_loss = 0.43491886236837934, disc_loss = 0.008464889374642683
Trained batch 560 in epoch 19, gen_loss = 0.43498565992357047, disc_loss = 0.008451139734451595
Trained batch 561 in epoch 19, gen_loss = 0.43496966133974624, disc_loss = 0.008439125925428035
Trained batch 562 in epoch 19, gen_loss = 0.4349204141441501, disc_loss = 0.008428111759402755
Trained batch 563 in epoch 19, gen_loss = 0.4348961526514791, disc_loss = 0.008414552252438721
Trained batch 564 in epoch 19, gen_loss = 0.43493992749568633, disc_loss = 0.008401495947005986
Trained batch 565 in epoch 19, gen_loss = 0.43491889962880437, disc_loss = 0.008387619933035708
Trained batch 566 in epoch 19, gen_loss = 0.43496458098371193, disc_loss = 0.008375476108241015
Trained batch 567 in epoch 19, gen_loss = 0.43489010773704084, disc_loss = 0.00836198473875747
Trained batch 568 in epoch 19, gen_loss = 0.43487924981620063, disc_loss = 0.008348243210948791
Trained batch 569 in epoch 19, gen_loss = 0.4349167939340859, disc_loss = 0.00833538627193775
Trained batch 570 in epoch 19, gen_loss = 0.4347412126911918, disc_loss = 0.00832287105787733
Trained batch 571 in epoch 19, gen_loss = 0.4347980717470596, disc_loss = 0.008309630298805082
Trained batch 572 in epoch 19, gen_loss = 0.4347837781614866, disc_loss = 0.0083000039656701
Trained batch 573 in epoch 19, gen_loss = 0.43475960501395033, disc_loss = 0.008287286349640792
Trained batch 574 in epoch 19, gen_loss = 0.4346762039350427, disc_loss = 0.00827579180958033
Trained batch 575 in epoch 19, gen_loss = 0.4347231219936576, disc_loss = 0.008264377799757009
Trained batch 576 in epoch 19, gen_loss = 0.43469339542000507, disc_loss = 0.008253580242190816
Trained batch 577 in epoch 19, gen_loss = 0.4346557377634577, disc_loss = 0.008240986237623472
Trained batch 578 in epoch 19, gen_loss = 0.43470579462965536, disc_loss = 0.008229418402420686
Trained batch 579 in epoch 19, gen_loss = 0.43466624812833193, disc_loss = 0.0082166142879628
Trained batch 580 in epoch 19, gen_loss = 0.4346104255026261, disc_loss = 0.00820366793993192
Trained batch 581 in epoch 19, gen_loss = 0.4346496820245002, disc_loss = 0.008192341352596517
Trained batch 582 in epoch 19, gen_loss = 0.4346507641504396, disc_loss = 0.00818204916737084
Trained batch 583 in epoch 19, gen_loss = 0.4346547230874022, disc_loss = 0.00816921701608744
Trained batch 584 in epoch 19, gen_loss = 0.43474016612411565, disc_loss = 0.00815757322508213
Trained batch 585 in epoch 19, gen_loss = 0.43475383921898264, disc_loss = 0.008145674222449727
Trained batch 586 in epoch 19, gen_loss = 0.43470557711802715, disc_loss = 0.008137177566537996
Trained batch 587 in epoch 19, gen_loss = 0.4347004092165402, disc_loss = 0.008127393949427245
Trained batch 588 in epoch 19, gen_loss = 0.43462342889078204, disc_loss = 0.008117164080815883
Trained batch 589 in epoch 19, gen_loss = 0.4346384779881623, disc_loss = 0.008107050736010533
Trained batch 590 in epoch 19, gen_loss = 0.43450890428523725, disc_loss = 0.008117326918657311
Trained batch 591 in epoch 19, gen_loss = 0.43438598251826055, disc_loss = 0.00811469257771662
Trained batch 592 in epoch 19, gen_loss = 0.4345099302809717, disc_loss = 0.008112333459407798
Trained batch 593 in epoch 19, gen_loss = 0.4345504974676704, disc_loss = 0.008101132643922163
Trained batch 594 in epoch 19, gen_loss = 0.43463432368110205, disc_loss = 0.008098097783053575
Trained batch 595 in epoch 19, gen_loss = 0.4347115457557992, disc_loss = 0.008087377782198897
Trained batch 596 in epoch 19, gen_loss = 0.43482050893694113, disc_loss = 0.008077602355611875
Trained batch 597 in epoch 19, gen_loss = 0.43491746978616236, disc_loss = 0.00806962637360991
Trained batch 598 in epoch 19, gen_loss = 0.4350213482105274, disc_loss = 0.008058755900969305
Trained batch 599 in epoch 19, gen_loss = 0.4349843602379163, disc_loss = 0.008047472329975184
Trained batch 600 in epoch 19, gen_loss = 0.4349790795174692, disc_loss = 0.008035412451499118
Trained batch 601 in epoch 19, gen_loss = 0.4350196263718843, disc_loss = 0.00802536590796999
Trained batch 602 in epoch 19, gen_loss = 0.43494199194125277, disc_loss = 0.008015843524582527
Trained batch 603 in epoch 19, gen_loss = 0.4350033884510299, disc_loss = 0.008006338999633267
Trained batch 604 in epoch 19, gen_loss = 0.43500783901569273, disc_loss = 0.007996536397292425
Trained batch 605 in epoch 19, gen_loss = 0.4350994574551535, disc_loss = 0.007988752176796498
Trained batch 606 in epoch 19, gen_loss = 0.43499142663089996, disc_loss = 0.008001501176821196
Trained batch 607 in epoch 19, gen_loss = 0.43497976503874125, disc_loss = 0.007991225266873937
Trained batch 608 in epoch 19, gen_loss = 0.4350289176837564, disc_loss = 0.00798963481597243
Trained batch 609 in epoch 19, gen_loss = 0.43501278274371974, disc_loss = 0.007981223733685377
Trained batch 610 in epoch 19, gen_loss = 0.43515357443431785, disc_loss = 0.007972124302517791
Trained batch 611 in epoch 19, gen_loss = 0.43509193178680206, disc_loss = 0.00797578995881695
Trained batch 612 in epoch 19, gen_loss = 0.4350947256870021, disc_loss = 0.007965671533475998
Trained batch 613 in epoch 19, gen_loss = 0.43509713019144264, disc_loss = 0.007966496408183253
Trained batch 614 in epoch 19, gen_loss = 0.435117248742561, disc_loss = 0.007958118063520746
Trained batch 615 in epoch 19, gen_loss = 0.4350970864973285, disc_loss = 0.007948265872321579
Trained batch 616 in epoch 19, gen_loss = 0.43513697593486483, disc_loss = 0.007938753631099155
Trained batch 617 in epoch 19, gen_loss = 0.43513876402262347, disc_loss = 0.007928081929262103
Trained batch 618 in epoch 19, gen_loss = 0.4350007066145082, disc_loss = 0.00797115414320064
Trained batch 619 in epoch 19, gen_loss = 0.43501889436475694, disc_loss = 0.00797087522171956
Trained batch 620 in epoch 19, gen_loss = 0.43517127781866444, disc_loss = 0.008629727679210672
Trained batch 621 in epoch 19, gen_loss = 0.4350770603134701, disc_loss = 0.008817118735786698
Trained batch 622 in epoch 19, gen_loss = 0.43514615737416007, disc_loss = 0.008893391451797258
Trained batch 623 in epoch 19, gen_loss = 0.43516496382653713, disc_loss = 0.008905274112410738
Trained batch 624 in epoch 19, gen_loss = 0.43516147956848145, disc_loss = 0.0089145902747754
Trained batch 625 in epoch 19, gen_loss = 0.4351204478512176, disc_loss = 0.008938572559434662
Trained batch 626 in epoch 19, gen_loss = 0.43505409583330534, disc_loss = 0.009157351468679714
Trained batch 627 in epoch 19, gen_loss = 0.4349699837102252, disc_loss = 0.009468068335597199
Trained batch 628 in epoch 19, gen_loss = 0.43509340698465065, disc_loss = 0.00954087555582638
Trained batch 629 in epoch 19, gen_loss = 0.43502286559059505, disc_loss = 0.009711891870496661
Trained batch 630 in epoch 19, gen_loss = 0.43481975349873636, disc_loss = 0.010054309714650853
Trained batch 631 in epoch 19, gen_loss = 0.4349127998457679, disc_loss = 0.010135235909832703
Trained batch 632 in epoch 19, gen_loss = 0.4347883264223735, disc_loss = 0.010178845107496906
Trained batch 633 in epoch 19, gen_loss = 0.43489819906111393, disc_loss = 0.010214436396286964
Trained batch 634 in epoch 19, gen_loss = 0.4348550876763862, disc_loss = 0.01022136824697762
Trained batch 635 in epoch 19, gen_loss = 0.43494152586977436, disc_loss = 0.010264658746421235
Trained batch 636 in epoch 19, gen_loss = 0.4349820440754973, disc_loss = 0.010259882719711046
Trained batch 637 in epoch 19, gen_loss = 0.43489105532348715, disc_loss = 0.010250011689862058
Trained batch 638 in epoch 19, gen_loss = 0.4348183558767017, disc_loss = 0.010253251539202589
Trained batch 639 in epoch 19, gen_loss = 0.43474923698231577, disc_loss = 0.010267293917650022
Trained batch 640 in epoch 19, gen_loss = 0.4347928899591687, disc_loss = 0.010264362959932556
Trained batch 641 in epoch 19, gen_loss = 0.4348058183895093, disc_loss = 0.010265569680095128
Trained batch 642 in epoch 19, gen_loss = 0.43488605197629143, disc_loss = 0.010267337309321516
Trained batch 643 in epoch 19, gen_loss = 0.4348826270943843, disc_loss = 0.01053686281804448
Trained batch 644 in epoch 19, gen_loss = 0.43479122038959533, disc_loss = 0.011176846970762523
Trained batch 645 in epoch 19, gen_loss = 0.43474195722271414, disc_loss = 0.011359853309807339
Trained batch 646 in epoch 19, gen_loss = 0.43456000416687873, disc_loss = 0.011661370709717312
Trained batch 647 in epoch 19, gen_loss = 0.43444860078118464, disc_loss = 0.011953552095674017
Trained batch 648 in epoch 19, gen_loss = 0.434344520783755, disc_loss = 0.012118494970652595
Trained batch 649 in epoch 19, gen_loss = 0.43428866528547727, disc_loss = 0.012286637050251906
Trained batch 650 in epoch 19, gen_loss = 0.4341455620188501, disc_loss = 0.012347423899484249
Trained batch 651 in epoch 19, gen_loss = 0.43415581124143365, disc_loss = 0.012391861982615392
Trained batch 652 in epoch 19, gen_loss = 0.43405465131331733, disc_loss = 0.01242050218202814
Trained batch 653 in epoch 19, gen_loss = 0.43420383511880123, disc_loss = 0.012438066050473285
Trained batch 654 in epoch 19, gen_loss = 0.43409399290121237, disc_loss = 0.012444328224039387
Trained batch 655 in epoch 19, gen_loss = 0.4339260141842249, disc_loss = 0.0127073930800135
Trained batch 656 in epoch 19, gen_loss = 0.4339609615153192, disc_loss = 0.012869479140570484
Trained batch 657 in epoch 19, gen_loss = 0.43396887056371, disc_loss = 0.01293024915861607
Trained batch 658 in epoch 19, gen_loss = 0.43405604878036314, disc_loss = 0.013023783604245935
Trained batch 659 in epoch 19, gen_loss = 0.43408604246197324, disc_loss = 0.013118165384521215
Trained batch 660 in epoch 19, gen_loss = 0.4341806035810087, disc_loss = 0.013309706845252074
Trained batch 661 in epoch 19, gen_loss = 0.43414640016966355, disc_loss = 0.01340085544062988
Trained batch 662 in epoch 19, gen_loss = 0.4341451609746004, disc_loss = 0.013421388573568458
Trained batch 663 in epoch 19, gen_loss = 0.4341235673391675, disc_loss = 0.013445451583775359
Trained batch 664 in epoch 19, gen_loss = 0.43427013535248604, disc_loss = 0.013446558338521692
Trained batch 665 in epoch 19, gen_loss = 0.4342171513103508, disc_loss = 0.013513733416331818
Trained batch 666 in epoch 19, gen_loss = 0.43434304365332516, disc_loss = 0.013527767541666475
Trained batch 667 in epoch 19, gen_loss = 0.434369483170752, disc_loss = 0.013521005613054915
Trained batch 668 in epoch 19, gen_loss = 0.43435250354098276, disc_loss = 0.013580880420408122
Trained batch 669 in epoch 19, gen_loss = 0.43440632446488336, disc_loss = 0.013604130219440532
Trained batch 670 in epoch 19, gen_loss = 0.43440560199287004, disc_loss = 0.013614055523157866
Trained batch 671 in epoch 19, gen_loss = 0.43441339094369186, disc_loss = 0.013602376192292945
Trained batch 672 in epoch 19, gen_loss = 0.4344272397425341, disc_loss = 0.013606006932975227
Trained batch 673 in epoch 19, gen_loss = 0.43441802174825694, disc_loss = 0.013596118209707048
Trained batch 674 in epoch 19, gen_loss = 0.434344616289492, disc_loss = 0.013579461090137353
Trained batch 675 in epoch 19, gen_loss = 0.43423569436080356, disc_loss = 0.01356312629723537
Trained batch 676 in epoch 19, gen_loss = 0.4342552437123731, disc_loss = 0.013546874062847717
Trained batch 677 in epoch 19, gen_loss = 0.4342615181541724, disc_loss = 0.013530596577884165
Trained batch 678 in epoch 19, gen_loss = 0.4342816021287915, disc_loss = 0.01352508993571952
Trained batch 679 in epoch 19, gen_loss = 0.43428825538824584, disc_loss = 0.013510798510063015
Trained batch 680 in epoch 19, gen_loss = 0.43430370740078267, disc_loss = 0.013500353005393675
Trained batch 681 in epoch 19, gen_loss = 0.43431297704970734, disc_loss = 0.013488498933436116
Trained batch 682 in epoch 19, gen_loss = 0.434307041751169, disc_loss = 0.01347271090709689
Trained batch 683 in epoch 19, gen_loss = 0.4342836280576667, disc_loss = 0.013460787147842143
Trained batch 684 in epoch 19, gen_loss = 0.4341640170038181, disc_loss = 0.013444886304120308
Trained batch 685 in epoch 19, gen_loss = 0.4341564393512709, disc_loss = 0.013427989363798304
Trained batch 686 in epoch 19, gen_loss = 0.43425093745213583, disc_loss = 0.013414091315926045
Trained batch 687 in epoch 19, gen_loss = 0.434211892054178, disc_loss = 0.01339888507196562
Trained batch 688 in epoch 19, gen_loss = 0.4340865698971492, disc_loss = 0.013384220366278685
Trained batch 689 in epoch 19, gen_loss = 0.4340361891881279, disc_loss = 0.013367233739742348
Trained batch 690 in epoch 19, gen_loss = 0.4339330899818934, disc_loss = 0.013349778371886317
Trained batch 691 in epoch 19, gen_loss = 0.433969776323765, disc_loss = 0.013332435676050467
Trained batch 692 in epoch 19, gen_loss = 0.4338496532533076, disc_loss = 0.013315762317288213
Trained batch 693 in epoch 19, gen_loss = 0.43384239159159427, disc_loss = 0.013298894956103065
Trained batch 694 in epoch 19, gen_loss = 0.4338625934484194, disc_loss = 0.013281878028709856
Trained batch 695 in epoch 19, gen_loss = 0.4338566778206277, disc_loss = 0.013265358246356081
Trained batch 696 in epoch 19, gen_loss = 0.43380967932759945, disc_loss = 0.013248830492926595
Trained batch 697 in epoch 19, gen_loss = 0.4337056912375043, disc_loss = 0.013231861628273457
Trained batch 698 in epoch 19, gen_loss = 0.4336647643295992, disc_loss = 0.013216537646977604
Trained batch 699 in epoch 19, gen_loss = 0.4336217338698251, disc_loss = 0.013204858636059465
Trained batch 700 in epoch 19, gen_loss = 0.4336381004047122, disc_loss = 0.013187758105127114
Trained batch 701 in epoch 19, gen_loss = 0.4336917081110158, disc_loss = 0.013171020633100924
Trained batch 702 in epoch 19, gen_loss = 0.43370801528351405, disc_loss = 0.013155890689511316
Trained batch 703 in epoch 19, gen_loss = 0.43363733420317824, disc_loss = 0.013138865323981008
Trained batch 704 in epoch 19, gen_loss = 0.43372560845199204, disc_loss = 0.013127688039961132
Trained batch 705 in epoch 19, gen_loss = 0.4337126262718152, disc_loss = 0.01311135260710953
Trained batch 706 in epoch 19, gen_loss = 0.4336972461731464, disc_loss = 0.013094514091388827
Trained batch 707 in epoch 19, gen_loss = 0.4337287295588666, disc_loss = 0.013078583774098002
Trained batch 708 in epoch 19, gen_loss = 0.4336809623981228, disc_loss = 0.01306235881697824
Trained batch 709 in epoch 19, gen_loss = 0.4337675041296113, disc_loss = 0.013046773798102972
Trained batch 710 in epoch 19, gen_loss = 0.4337328479175997, disc_loss = 0.013030134064530817
Trained batch 711 in epoch 19, gen_loss = 0.43376538437906276, disc_loss = 0.013016353983975217
Trained batch 712 in epoch 19, gen_loss = 0.43371208737307815, disc_loss = 0.013000548519117387
Trained batch 713 in epoch 19, gen_loss = 0.4337060962821923, disc_loss = 0.012998148419084588
Trained batch 714 in epoch 19, gen_loss = 0.4336554249266644, disc_loss = 0.012984662830961504
Trained batch 715 in epoch 19, gen_loss = 0.4335499987339174, disc_loss = 0.012969950174071564
Trained batch 716 in epoch 19, gen_loss = 0.4335983880227912, disc_loss = 0.01295450216941334
Trained batch 717 in epoch 19, gen_loss = 0.4335868003308607, disc_loss = 0.01293820020919283
Trained batch 718 in epoch 19, gen_loss = 0.4335440606997971, disc_loss = 0.01292163942719846
Trained batch 719 in epoch 19, gen_loss = 0.4335539448592398, disc_loss = 0.012905432067095211
Trained batch 720 in epoch 19, gen_loss = 0.4335253735107787, disc_loss = 0.012888968315942021
Trained batch 721 in epoch 19, gen_loss = 0.433538336296491, disc_loss = 0.012872889310992555
Trained batch 722 in epoch 19, gen_loss = 0.4335081066580729, disc_loss = 0.012858374753458435
Trained batch 723 in epoch 19, gen_loss = 0.4333870750105842, disc_loss = 0.012842195051169417
Trained batch 724 in epoch 19, gen_loss = 0.433321626761864, disc_loss = 0.012826914126254169
Trained batch 725 in epoch 19, gen_loss = 0.43329904119666285, disc_loss = 0.01281724140143757
Trained batch 726 in epoch 19, gen_loss = 0.433271276327734, disc_loss = 0.012805125568367277
Trained batch 727 in epoch 19, gen_loss = 0.4332712123190964, disc_loss = 0.012788886926720587
Trained batch 728 in epoch 19, gen_loss = 0.4332093349536587, disc_loss = 0.012772901127932834
Trained batch 729 in epoch 19, gen_loss = 0.43316322679389013, disc_loss = 0.012756932890305793
Trained batch 730 in epoch 19, gen_loss = 0.4331837729047653, disc_loss = 0.01274267700616246
Trained batch 731 in epoch 19, gen_loss = 0.43317109387103325, disc_loss = 0.012726628330869847
Trained batch 732 in epoch 19, gen_loss = 0.4332156543191751, disc_loss = 0.012711017333534273
Trained batch 733 in epoch 19, gen_loss = 0.43319142449454323, disc_loss = 0.012696261094587763
Trained batch 734 in epoch 19, gen_loss = 0.43311699742362614, disc_loss = 0.01268047589977386
Trained batch 735 in epoch 19, gen_loss = 0.433242028174193, disc_loss = 0.012665114266224997
Trained batch 736 in epoch 19, gen_loss = 0.43324975222551354, disc_loss = 0.012649601722697523
Trained batch 737 in epoch 19, gen_loss = 0.433334347395716, disc_loss = 0.012634721443003111
Trained batch 738 in epoch 19, gen_loss = 0.43347402673128976, disc_loss = 0.012619833703632044
Trained batch 739 in epoch 19, gen_loss = 0.43355525824669244, disc_loss = 0.012606342677758516
Trained batch 740 in epoch 19, gen_loss = 0.433570184366584, disc_loss = 0.012590633952267801
Trained batch 741 in epoch 19, gen_loss = 0.43347456982996907, disc_loss = 0.01257596748873668
Trained batch 742 in epoch 19, gen_loss = 0.4334946982712957, disc_loss = 0.012560516638183982
Trained batch 743 in epoch 19, gen_loss = 0.4335867638789838, disc_loss = 0.012545378797229752
Trained batch 744 in epoch 19, gen_loss = 0.4335890709153758, disc_loss = 0.012530305044570839
Trained batch 745 in epoch 19, gen_loss = 0.4334732348413953, disc_loss = 0.012522020703563954
Testing Epoch 19
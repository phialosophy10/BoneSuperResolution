/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 1.0950822830200195, disc_loss = 0.7244495153427124
Trained batch 1 in epoch 0, gen_loss = 1.3753646612167358, disc_loss = 1.1453598141670227
Trained batch 2 in epoch 0, gen_loss = 1.2214815219243367, disc_loss = 0.9387183785438538
Trained batch 3 in epoch 0, gen_loss = 1.1585561037063599, disc_loss = 0.8169024810194969
Trained batch 4 in epoch 0, gen_loss = 1.096321940422058, disc_loss = 0.7233095705509186
Trained batch 5 in epoch 0, gen_loss = 1.0201536516348522, disc_loss = 0.6549209902683893
Trained batch 6 in epoch 0, gen_loss = 0.9900953684534345, disc_loss = 0.6031442752906254
Trained batch 7 in epoch 0, gen_loss = 0.9639854654669762, disc_loss = 0.5573425143957138
Trained batch 8 in epoch 0, gen_loss = 0.9456233117315505, disc_loss = 0.5222280356619093
Trained batch 9 in epoch 0, gen_loss = 0.9218695342540741, disc_loss = 0.4881901890039444
Trained batch 10 in epoch 0, gen_loss = 0.9014722054654901, disc_loss = 0.4610320817340504
Trained batch 11 in epoch 0, gen_loss = 0.9057651509841284, disc_loss = 0.4368540570139885
Trained batch 12 in epoch 0, gen_loss = 0.9043288643543537, disc_loss = 0.41553319646761966
Trained batch 13 in epoch 0, gen_loss = 0.9004256299563816, disc_loss = 0.3960080508674894
Trained batch 14 in epoch 0, gen_loss = 0.9032357215881348, disc_loss = 0.37786874969800316
Trained batch 15 in epoch 0, gen_loss = 0.8965704366564751, disc_loss = 0.3620821684598923
Trained batch 16 in epoch 0, gen_loss = 0.8889474202604855, disc_loss = 0.3486443828133976
Trained batch 17 in epoch 0, gen_loss = 0.8800293505191803, disc_loss = 0.3368000586827596
Trained batch 18 in epoch 0, gen_loss = 0.8794957273884824, disc_loss = 0.3245710652125509
Trained batch 19 in epoch 0, gen_loss = 0.8822509676218033, disc_loss = 0.31387138813734056
Trained batch 20 in epoch 0, gen_loss = 0.8805525501569113, disc_loss = 0.3039969177473159
Trained batch 21 in epoch 0, gen_loss = 0.8857843632047827, disc_loss = 0.2959915426644412
Trained batch 22 in epoch 0, gen_loss = 0.8902417654576509, disc_loss = 0.2886061422202898
Trained batch 23 in epoch 0, gen_loss = 0.901764489710331, disc_loss = 0.2803181856870651
Trained batch 24 in epoch 0, gen_loss = 0.9083697485923767, disc_loss = 0.27320387959480286
Trained batch 25 in epoch 0, gen_loss = 0.9117077199312357, disc_loss = 0.2656634171994833
Trained batch 26 in epoch 0, gen_loss = 0.9203499136147676, disc_loss = 0.2579412813539858
Trained batch 27 in epoch 0, gen_loss = 0.9254318369286401, disc_loss = 0.25068456307053566
Trained batch 28 in epoch 0, gen_loss = 0.9266170736016899, disc_loss = 0.24471686189544611
Trained batch 29 in epoch 0, gen_loss = 0.9360740602016449, disc_loss = 0.23919253821174305
Trained batch 30 in epoch 0, gen_loss = 0.9343465970408532, disc_loss = 0.23538014629194814
Trained batch 31 in epoch 0, gen_loss = 0.9407938327640295, disc_loss = 0.2338282293640077
Trained batch 32 in epoch 0, gen_loss = 0.9325979388121403, disc_loss = 0.2364559178099488
Trained batch 33 in epoch 0, gen_loss = 0.9322588776840883, disc_loss = 0.23417757407707326
Trained batch 34 in epoch 0, gen_loss = 0.9417258518082755, disc_loss = 0.23299961345536369
Trained batch 35 in epoch 0, gen_loss = 0.9424747791555192, disc_loss = 0.22955388265351453
Trained batch 36 in epoch 0, gen_loss = 0.9431350650014104, disc_loss = 0.22516865464481148
Trained batch 37 in epoch 0, gen_loss = 0.9432552111776251, disc_loss = 0.2214623234773937
Trained batch 38 in epoch 0, gen_loss = 0.9436939878341479, disc_loss = 0.21730412151186895
Trained batch 39 in epoch 0, gen_loss = 0.9474074020981789, disc_loss = 0.21307970033958554
Trained batch 40 in epoch 0, gen_loss = 0.9522299257720389, disc_loss = 0.20937212329448723
Trained batch 41 in epoch 0, gen_loss = 0.9508866156850543, disc_loss = 0.20604387608667216
Trained batch 42 in epoch 0, gen_loss = 0.9505664428999258, disc_loss = 0.20233895499692406
Trained batch 43 in epoch 0, gen_loss = 0.9522375261241739, disc_loss = 0.19898257362232966
Trained batch 44 in epoch 0, gen_loss = 0.9534294936392043, disc_loss = 0.1958038395477666
Trained batch 45 in epoch 0, gen_loss = 0.9512539713279061, disc_loss = 0.1936785982840735
Trained batch 46 in epoch 0, gen_loss = 0.9506287600131745, disc_loss = 0.19107595870786526
Trained batch 47 in epoch 0, gen_loss = 0.952912762761116, disc_loss = 0.18835531524382532
Trained batch 48 in epoch 0, gen_loss = 0.9551524045516033, disc_loss = 0.18604778490808546
Trained batch 49 in epoch 0, gen_loss = 0.9550617551803589, disc_loss = 0.18398386485874652
Trained batch 50 in epoch 0, gen_loss = 0.9577856975443223, disc_loss = 0.181547954240266
Trained batch 51 in epoch 0, gen_loss = 0.9597991406917572, disc_loss = 0.17906310502439737
Trained batch 52 in epoch 0, gen_loss = 0.9578954802369172, disc_loss = 0.1775623269660293
Trained batch 53 in epoch 0, gen_loss = 0.9613406117315646, disc_loss = 0.1754015034271611
Trained batch 54 in epoch 0, gen_loss = 0.9655382752418518, disc_loss = 0.17379692535508762
Trained batch 55 in epoch 0, gen_loss = 0.9635616189667157, disc_loss = 0.17197120854897158
Trained batch 56 in epoch 0, gen_loss = 0.9646413734084681, disc_loss = 0.17001872196009285
Trained batch 57 in epoch 0, gen_loss = 0.9680175668206709, disc_loss = 0.16791708202197633
Trained batch 58 in epoch 0, gen_loss = 0.9707682506512787, disc_loss = 0.16576739167005328
Trained batch 59 in epoch 0, gen_loss = 0.9704898724953334, disc_loss = 0.16442001952479282
Trained batch 60 in epoch 0, gen_loss = 0.97437941539483, disc_loss = 0.16288228473458133
Trained batch 61 in epoch 0, gen_loss = 0.9733670680753647, disc_loss = 0.16168955202785232
Trained batch 62 in epoch 0, gen_loss = 0.9696663845153082, disc_loss = 0.16247040122037842
Trained batch 63 in epoch 0, gen_loss = 0.9733505342155695, disc_loss = 0.16112331085605547
Trained batch 64 in epoch 0, gen_loss = 0.9754733470770028, disc_loss = 0.16021988901954431
Trained batch 65 in epoch 0, gen_loss = 0.9741407217401447, disc_loss = 0.1594502098971244
Trained batch 66 in epoch 0, gen_loss = 0.9736811749970735, disc_loss = 0.15886614099144936
Trained batch 67 in epoch 0, gen_loss = 0.9757456349975923, disc_loss = 0.15738611821742618
Trained batch 68 in epoch 0, gen_loss = 0.9793734939202018, disc_loss = 0.1564979518669239
Trained batch 69 in epoch 0, gen_loss = 0.9773270317486354, disc_loss = 0.1559822433761188
Trained batch 70 in epoch 0, gen_loss = 0.9793892578339912, disc_loss = 0.15458455744763494
Trained batch 71 in epoch 0, gen_loss = 0.9799567692809634, disc_loss = 0.1534595045571526
Trained batch 72 in epoch 0, gen_loss = 0.9755187589828282, disc_loss = 0.15364838738555778
Trained batch 73 in epoch 0, gen_loss = 0.9774103615735028, disc_loss = 0.15307196934480924
Trained batch 74 in epoch 0, gen_loss = 0.9763795773188273, disc_loss = 0.15197337756554286
Trained batch 75 in epoch 0, gen_loss = 0.973442941904068, disc_loss = 0.15228112463496232
Trained batch 76 in epoch 0, gen_loss = 0.975281345379817, disc_loss = 0.15186268352455906
Trained batch 77 in epoch 0, gen_loss = 0.9750759762067062, disc_loss = 0.1509301790442222
Trained batch 78 in epoch 0, gen_loss = 0.9749419915525219, disc_loss = 0.1505438930626157
Trained batch 79 in epoch 0, gen_loss = 0.9770567342638969, disc_loss = 0.14974992396309972
Trained batch 80 in epoch 0, gen_loss = 0.9768644873006844, disc_loss = 0.1490300390639423
Trained batch 81 in epoch 0, gen_loss = 0.9751528094454509, disc_loss = 0.14882676130751285
Trained batch 82 in epoch 0, gen_loss = 0.9752744967678943, disc_loss = 0.148493996406176
Trained batch 83 in epoch 0, gen_loss = 0.9730829106909888, disc_loss = 0.14926368831878617
Trained batch 84 in epoch 0, gen_loss = 0.9758686170858495, disc_loss = 0.150597963087699
Trained batch 85 in epoch 0, gen_loss = 0.9738709476105002, disc_loss = 0.15219865860634071
Trained batch 86 in epoch 0, gen_loss = 0.9718108307356121, disc_loss = 0.15185182635811553
Trained batch 87 in epoch 0, gen_loss = 0.9740141433748332, disc_loss = 0.15217452005229212
Trained batch 88 in epoch 0, gen_loss = 0.9741819742020597, disc_loss = 0.1517598121688607
Trained batch 89 in epoch 0, gen_loss = 0.9733764131863912, disc_loss = 0.15109362883700264
Trained batch 90 in epoch 0, gen_loss = 0.9715129588986491, disc_loss = 0.15041681829389636
Trained batch 91 in epoch 0, gen_loss = 0.9722928450159405, disc_loss = 0.15007606116325958
Trained batch 92 in epoch 0, gen_loss = 0.9702914587913021, disc_loss = 0.149826015515994
Trained batch 93 in epoch 0, gen_loss = 0.9712840806930623, disc_loss = 0.14901574487064748
Trained batch 94 in epoch 0, gen_loss = 0.9706585890368411, disc_loss = 0.14840214119145745
Trained batch 95 in epoch 0, gen_loss = 0.9716217375049988, disc_loss = 0.14772866029913226
Trained batch 96 in epoch 0, gen_loss = 0.9704239337714677, disc_loss = 0.14735019959739803
Trained batch 97 in epoch 0, gen_loss = 0.971227094226954, disc_loss = 0.14696281023171484
Trained batch 98 in epoch 0, gen_loss = 0.9716431486486184, disc_loss = 0.14769915318248247
Trained batch 99 in epoch 0, gen_loss = 0.9685343980789185, disc_loss = 0.15264615416526794
Trained batch 100 in epoch 0, gen_loss = 0.9662715444470397, disc_loss = 0.15283748389470694
Trained batch 101 in epoch 0, gen_loss = 0.967674149017708, disc_loss = 0.15299597689334085
Trained batch 102 in epoch 0, gen_loss = 0.9674588065702938, disc_loss = 0.1531962157742491
Trained batch 103 in epoch 0, gen_loss = 0.9658671244978905, disc_loss = 0.15312630554231313
Trained batch 104 in epoch 0, gen_loss = 0.965699357078189, disc_loss = 0.15355625777017504
Trained batch 105 in epoch 0, gen_loss = 0.9654791366379216, disc_loss = 0.15341441558217103
Trained batch 106 in epoch 0, gen_loss = 0.9658297055235533, disc_loss = 0.15307001720800578
Trained batch 107 in epoch 0, gen_loss = 0.9659104904642811, disc_loss = 0.152893769727261
Trained batch 108 in epoch 0, gen_loss = 0.9671665632396663, disc_loss = 0.1526161165002289
Trained batch 109 in epoch 0, gen_loss = 0.9659725189208984, disc_loss = 0.15256467414173214
Trained batch 110 in epoch 0, gen_loss = 0.9660343667408368, disc_loss = 0.15294929150794004
Trained batch 111 in epoch 0, gen_loss = 0.9637221081980637, disc_loss = 0.15440354569415962
Trained batch 112 in epoch 0, gen_loss = 0.9653129677856918, disc_loss = 0.15462507999840036
Trained batch 113 in epoch 0, gen_loss = 0.9652961921273616, disc_loss = 0.15393626814087233
Trained batch 114 in epoch 0, gen_loss = 0.9634276540383049, disc_loss = 0.1546811576122823
Trained batch 115 in epoch 0, gen_loss = 0.9615665997924476, disc_loss = 0.1544704093629944
Trained batch 116 in epoch 0, gen_loss = 0.9604768009267302, disc_loss = 0.15431681740233022
Trained batch 117 in epoch 0, gen_loss = 0.960034840187784, disc_loss = 0.1540363895059642
Trained batch 118 in epoch 0, gen_loss = 0.959764403956277, disc_loss = 0.153532335800784
Trained batch 119 in epoch 0, gen_loss = 0.9600193391243617, disc_loss = 0.15287873564908902
Trained batch 120 in epoch 0, gen_loss = 0.9585692527865576, disc_loss = 0.1528295542706143
Trained batch 121 in epoch 0, gen_loss = 0.9587795167672829, disc_loss = 0.15232336197475918
Trained batch 122 in epoch 0, gen_loss = 0.9601633413051202, disc_loss = 0.15276776987120388
Trained batch 123 in epoch 0, gen_loss = 0.957054500137606, disc_loss = 0.15394933563807317
Trained batch 124 in epoch 0, gen_loss = 0.9575790143013001, disc_loss = 0.15422555416822434
Trained batch 125 in epoch 0, gen_loss = 0.9581773456126924, disc_loss = 0.1536762071625581
Trained batch 126 in epoch 0, gen_loss = 0.9561593903331306, disc_loss = 0.15511666912966826
Trained batch 127 in epoch 0, gen_loss = 0.9560879240743816, disc_loss = 0.1549729139660485
Trained batch 128 in epoch 0, gen_loss = 0.9565884101298429, disc_loss = 0.1555353173798369
Trained batch 129 in epoch 0, gen_loss = 0.9554177857362307, disc_loss = 0.1552116019794574
Trained batch 130 in epoch 0, gen_loss = 0.9538792590148576, disc_loss = 0.1560850361262569
Trained batch 131 in epoch 0, gen_loss = 0.9533382265856771, disc_loss = 0.1558918645323226
Trained batch 132 in epoch 0, gen_loss = 0.9534740017769032, disc_loss = 0.1560674955634246
Trained batch 133 in epoch 0, gen_loss = 0.9519461758101164, disc_loss = 0.15594236358110583
Trained batch 134 in epoch 0, gen_loss = 0.9505968380857397, disc_loss = 0.15595960567394893
Trained batch 135 in epoch 0, gen_loss = 0.9507309080046766, disc_loss = 0.15594275651828332
Trained batch 136 in epoch 0, gen_loss = 0.9489406995529676, disc_loss = 0.1561650162304405
Trained batch 137 in epoch 0, gen_loss = 0.9482708210530488, disc_loss = 0.15613243518316228
Trained batch 138 in epoch 0, gen_loss = 0.9483968444007764, disc_loss = 0.15553308808975083
Trained batch 139 in epoch 0, gen_loss = 0.9471996707575662, disc_loss = 0.15565488040447234
Trained batch 140 in epoch 0, gen_loss = 0.948588471040658, disc_loss = 0.1559766076558025
Trained batch 141 in epoch 0, gen_loss = 0.9481399361516388, disc_loss = 0.15532112278988663
Trained batch 142 in epoch 0, gen_loss = 0.9469228228489002, disc_loss = 0.15622443158726593
Trained batch 143 in epoch 0, gen_loss = 0.9486878667440679, disc_loss = 0.15766983634481826
Trained batch 144 in epoch 0, gen_loss = 0.9489184359024311, disc_loss = 0.1569359157105972
Trained batch 145 in epoch 0, gen_loss = 0.9479927636989175, disc_loss = 0.15649416614068698
Trained batch 146 in epoch 0, gen_loss = 0.9456158985896986, disc_loss = 0.15732719196754247
Trained batch 147 in epoch 0, gen_loss = 0.9444189220666885, disc_loss = 0.1579179127474089
Trained batch 148 in epoch 0, gen_loss = 0.9439914182528554, disc_loss = 0.15823793061227606
Trained batch 149 in epoch 0, gen_loss = 0.9427060476938883, disc_loss = 0.15836515347162883
Trained batch 150 in epoch 0, gen_loss = 0.9414546513399541, disc_loss = 0.1583048026293319
Trained batch 151 in epoch 0, gen_loss = 0.9418044698081518, disc_loss = 0.15836251840779655
Trained batch 152 in epoch 0, gen_loss = 0.9409408958908779, disc_loss = 0.1584057590735504
Trained batch 153 in epoch 0, gen_loss = 0.9398281225910434, disc_loss = 0.15829879229331945
Trained batch 154 in epoch 0, gen_loss = 0.9397038136759112, disc_loss = 0.1580233964227861
Trained batch 155 in epoch 0, gen_loss = 0.9393686201327887, disc_loss = 0.15785069973805013
Trained batch 156 in epoch 0, gen_loss = 0.9387622202277943, disc_loss = 0.15787564369903248
Trained batch 157 in epoch 0, gen_loss = 0.9376020027866846, disc_loss = 0.15823640872406053
Trained batch 158 in epoch 0, gen_loss = 0.940044178527856, disc_loss = 0.15885823833867438
Trained batch 159 in epoch 0, gen_loss = 0.9401725396513939, disc_loss = 0.1582728024572134
Trained batch 160 in epoch 0, gen_loss = 0.9380866029988164, disc_loss = 0.15950028348413314
Trained batch 161 in epoch 0, gen_loss = 0.9388614664843054, disc_loss = 0.15967042707366708
Trained batch 162 in epoch 0, gen_loss = 0.9385128039523868, disc_loss = 0.15960771275078592
Trained batch 163 in epoch 0, gen_loss = 0.9370762887524395, disc_loss = 0.15968473900745556
Trained batch 164 in epoch 0, gen_loss = 0.9367086266026352, disc_loss = 0.1595562756061554
Trained batch 165 in epoch 0, gen_loss = 0.936101906270866, disc_loss = 0.15940764016774764
Trained batch 166 in epoch 0, gen_loss = 0.9358691805137132, disc_loss = 0.15932232623328707
Trained batch 167 in epoch 0, gen_loss = 0.9346830561047509, disc_loss = 0.15937810355708712
Trained batch 168 in epoch 0, gen_loss = 0.9363016976407293, disc_loss = 0.15934814689074747
Trained batch 169 in epoch 0, gen_loss = 0.9349118755144231, disc_loss = 0.15925666190245572
Trained batch 170 in epoch 0, gen_loss = 0.9339936215278001, disc_loss = 0.15966757983840696
Trained batch 171 in epoch 0, gen_loss = 0.9359325763098029, disc_loss = 0.16169103746150815
Trained batch 172 in epoch 0, gen_loss = 0.9360601815874177, disc_loss = 0.16159559734639406
Trained batch 173 in epoch 0, gen_loss = 0.9346909707990186, disc_loss = 0.16175019646855607
Trained batch 174 in epoch 0, gen_loss = 0.9343195945875985, disc_loss = 0.16177833242075784
Trained batch 175 in epoch 0, gen_loss = 0.9338062429292635, disc_loss = 0.1621109019456939
Trained batch 176 in epoch 0, gen_loss = 0.9323351645873765, disc_loss = 0.16244144603020727
Trained batch 177 in epoch 0, gen_loss = 0.9317846911007099, disc_loss = 0.16238863054621086
Trained batch 178 in epoch 0, gen_loss = 0.9309245804168659, disc_loss = 0.16220900408049535
Trained batch 179 in epoch 0, gen_loss = 0.9300502833392885, disc_loss = 0.16217746378646958
Trained batch 180 in epoch 0, gen_loss = 0.9298524477863839, disc_loss = 0.16228462195857454
Trained batch 181 in epoch 0, gen_loss = 0.9289837410816779, disc_loss = 0.16242069390776392
Trained batch 182 in epoch 0, gen_loss = 0.9289322260950432, disc_loss = 0.16240109796406793
Trained batch 183 in epoch 0, gen_loss = 0.9290488041613413, disc_loss = 0.16247867072082084
Trained batch 184 in epoch 0, gen_loss = 0.927951772470732, disc_loss = 0.16269744771557884
Trained batch 185 in epoch 0, gen_loss = 0.927899553250241, disc_loss = 0.16242970341956744
Trained batch 186 in epoch 0, gen_loss = 0.9286366850934564, disc_loss = 0.1621954292855798
Trained batch 187 in epoch 0, gen_loss = 0.9276352489882327, disc_loss = 0.16200787478939016
Trained batch 188 in epoch 0, gen_loss = 0.9277420539073843, disc_loss = 0.16177646453103062
Trained batch 189 in epoch 0, gen_loss = 0.9288676189748865, disc_loss = 0.16259706859525883
Trained batch 190 in epoch 0, gen_loss = 0.9270189785208377, disc_loss = 0.16405297004427585
Trained batch 191 in epoch 0, gen_loss = 0.9265058155482014, disc_loss = 0.16415707425524792
Trained batch 192 in epoch 0, gen_loss = 0.9270913801662662, disc_loss = 0.16497901112922114
Trained batch 193 in epoch 0, gen_loss = 0.9265815723188144, disc_loss = 0.1650403025992138
Trained batch 194 in epoch 0, gen_loss = 0.9259301543235778, disc_loss = 0.1651674761221959
Trained batch 195 in epoch 0, gen_loss = 0.9259297425041393, disc_loss = 0.16518181159484144
Trained batch 196 in epoch 0, gen_loss = 0.9250642403128183, disc_loss = 0.16520694994986965
Trained batch 197 in epoch 0, gen_loss = 0.9244613861194765, disc_loss = 0.1651494244884963
Trained batch 198 in epoch 0, gen_loss = 0.924709045707281, disc_loss = 0.16511589049094885
Trained batch 199 in epoch 0, gen_loss = 0.9242628461122513, disc_loss = 0.16501639902591705
Trained batch 200 in epoch 0, gen_loss = 0.923717186522128, disc_loss = 0.16474132406622616
Trained batch 201 in epoch 0, gen_loss = 0.923971163754416, disc_loss = 0.1645578135284457
Trained batch 202 in epoch 0, gen_loss = 0.9241612074997625, disc_loss = 0.16422954245741145
Trained batch 203 in epoch 0, gen_loss = 0.9230033235222685, disc_loss = 0.1640467120005804
Trained batch 204 in epoch 0, gen_loss = 0.9225118241659025, disc_loss = 0.16400051473117455
Trained batch 205 in epoch 0, gen_loss = 0.9241349627670733, disc_loss = 0.16482790660800287
Trained batch 206 in epoch 0, gen_loss = 0.9230687929236371, disc_loss = 0.16513005546901538
Trained batch 207 in epoch 0, gen_loss = 0.9224179495985692, disc_loss = 0.16554736346006393
Trained batch 208 in epoch 0, gen_loss = 0.9227070058361765, disc_loss = 0.1657197064760199
Trained batch 209 in epoch 0, gen_loss = 0.9230843001887912, disc_loss = 0.16572241470927285
Trained batch 210 in epoch 0, gen_loss = 0.922812380779411, disc_loss = 0.16558822819971925
Trained batch 211 in epoch 0, gen_loss = 0.9223751198008375, disc_loss = 0.16558681498720962
Trained batch 212 in epoch 0, gen_loss = 0.9217598354312736, disc_loss = 0.16562983981320556
Trained batch 213 in epoch 0, gen_loss = 0.9207597784349851, disc_loss = 0.16579639647051553
Trained batch 214 in epoch 0, gen_loss = 0.9197892394176749, disc_loss = 0.16572330420793488
Trained batch 215 in epoch 0, gen_loss = 0.9195291913217969, disc_loss = 0.16541346272936575
Trained batch 216 in epoch 0, gen_loss = 0.9198944791121417, disc_loss = 0.16519526502091764
Trained batch 217 in epoch 0, gen_loss = 0.9186262348923114, disc_loss = 0.16573613133589063
Trained batch 218 in epoch 0, gen_loss = 0.9199723334617267, disc_loss = 0.16602871430927216
Trained batch 219 in epoch 0, gen_loss = 0.9195457916368138, disc_loss = 0.16615588553249835
Trained batch 220 in epoch 0, gen_loss = 0.919443930705748, disc_loss = 0.16582526330629624
Trained batch 221 in epoch 0, gen_loss = 0.9186888930496869, disc_loss = 0.1657679328308986
Trained batch 222 in epoch 0, gen_loss = 0.919279168806803, disc_loss = 0.16606394047828
Trained batch 223 in epoch 0, gen_loss = 0.9180361221411398, disc_loss = 0.16625206302186207
Trained batch 224 in epoch 0, gen_loss = 0.91675406826867, disc_loss = 0.1662477727399932
Trained batch 225 in epoch 0, gen_loss = 0.9161618206880789, disc_loss = 0.16630649688628923
Trained batch 226 in epoch 0, gen_loss = 0.9157570763306471, disc_loss = 0.16622162794095305
Trained batch 227 in epoch 0, gen_loss = 0.9151801184604043, disc_loss = 0.16604538036412314
Trained batch 228 in epoch 0, gen_loss = 0.9146453274910107, disc_loss = 0.16595591464807893
Trained batch 229 in epoch 0, gen_loss = 0.9139847879824431, disc_loss = 0.16596514372074087
Trained batch 230 in epoch 0, gen_loss = 0.9142126758377274, disc_loss = 0.1660484577089677
Trained batch 231 in epoch 0, gen_loss = 0.9140132881444076, disc_loss = 0.16603407382579713
Trained batch 232 in epoch 0, gen_loss = 0.9140165110514399, disc_loss = 0.16590246740456815
Trained batch 233 in epoch 0, gen_loss = 0.9139200685880123, disc_loss = 0.16579826395863143
Trained batch 234 in epoch 0, gen_loss = 0.9136726115612274, disc_loss = 0.16563724098687477
Trained batch 235 in epoch 0, gen_loss = 0.9137367184384394, disc_loss = 0.16558459978866374
Trained batch 236 in epoch 0, gen_loss = 0.9128766253527709, disc_loss = 0.16551849965933507
Trained batch 237 in epoch 0, gen_loss = 0.913413057557675, disc_loss = 0.16560020626467817
Trained batch 238 in epoch 0, gen_loss = 0.9133588147961444, disc_loss = 0.16534382064347486
Trained batch 239 in epoch 0, gen_loss = 0.9127938608328502, disc_loss = 0.16527741424118478
Trained batch 240 in epoch 0, gen_loss = 0.9141969473035504, disc_loss = 0.1654239321336212
Trained batch 241 in epoch 0, gen_loss = 0.9134167225892879, disc_loss = 0.16616623987220536
Trained batch 242 in epoch 0, gen_loss = 0.9139431719917329, disc_loss = 0.1666591238276458
Trained batch 243 in epoch 0, gen_loss = 0.9132509270652396, disc_loss = 0.16687604830768266
Trained batch 244 in epoch 0, gen_loss = 0.9124297764836525, disc_loss = 0.1668202466806587
Trained batch 245 in epoch 0, gen_loss = 0.9133401508253765, disc_loss = 0.1667371058791149
Trained batch 246 in epoch 0, gen_loss = 0.9131333224686534, disc_loss = 0.16671676212838787
Trained batch 247 in epoch 0, gen_loss = 0.912796891985401, disc_loss = 0.1667350407149042
Trained batch 248 in epoch 0, gen_loss = 0.9128364628577328, disc_loss = 0.16668860132555408
Trained batch 249 in epoch 0, gen_loss = 0.9125329904556274, disc_loss = 0.1665054935514927
Trained batch 250 in epoch 0, gen_loss = 0.9121555921091027, disc_loss = 0.1663192275807677
Trained batch 251 in epoch 0, gen_loss = 0.9115448310261681, disc_loss = 0.16621387445382654
Trained batch 252 in epoch 0, gen_loss = 0.9107721761281311, disc_loss = 0.16623805077533005
Trained batch 253 in epoch 0, gen_loss = 0.9115717518986679, disc_loss = 0.16611686785976718
Trained batch 254 in epoch 0, gen_loss = 0.9105372164763657, disc_loss = 0.1666369390546107
Trained batch 255 in epoch 0, gen_loss = 0.9112165018450469, disc_loss = 0.16653789216070436
Trained batch 256 in epoch 0, gen_loss = 0.9105850418717945, disc_loss = 0.16648610785661505
Trained batch 257 in epoch 0, gen_loss = 0.9096936419490695, disc_loss = 0.16665939683484476
Trained batch 258 in epoch 0, gen_loss = 0.9099755388429266, disc_loss = 0.16689000974865953
Trained batch 259 in epoch 0, gen_loss = 0.9093950730103713, disc_loss = 0.16701004788852655
Trained batch 260 in epoch 0, gen_loss = 0.9096867917141238, disc_loss = 0.16684923235369825
Trained batch 261 in epoch 0, gen_loss = 0.9094282818659571, disc_loss = 0.1666520871790766
Trained batch 262 in epoch 0, gen_loss = 0.9087363465657252, disc_loss = 0.16674330431132262
Trained batch 263 in epoch 0, gen_loss = 0.90863474413301, disc_loss = 0.16666099358575814
Trained batch 264 in epoch 0, gen_loss = 0.9090685234879547, disc_loss = 0.16639078754299091
Trained batch 265 in epoch 0, gen_loss = 0.9088179917263806, disc_loss = 0.16608556057501556
Trained batch 266 in epoch 0, gen_loss = 0.9088735093784689, disc_loss = 0.16602903219421258
Trained batch 267 in epoch 0, gen_loss = 0.9093126721346556, disc_loss = 0.1662452432757883
Trained batch 268 in epoch 0, gen_loss = 0.9081549219039293, disc_loss = 0.16627833141934917
Trained batch 269 in epoch 0, gen_loss = 0.9079938535337095, disc_loss = 0.16612078230138178
Trained batch 270 in epoch 0, gen_loss = 0.9080940495997777, disc_loss = 0.1665741980790652
Trained batch 271 in epoch 0, gen_loss = 0.9069594653213725, disc_loss = 0.1675566303653314
Trained batch 272 in epoch 0, gen_loss = 0.9063322295199384, disc_loss = 0.16762300395157748
Trained batch 273 in epoch 0, gen_loss = 0.9069527757428858, disc_loss = 0.167819302692248
Trained batch 274 in epoch 0, gen_loss = 0.9067497816952792, disc_loss = 0.16791598333553834
Trained batch 275 in epoch 0, gen_loss = 0.9062448733526728, disc_loss = 0.16804617959196153
Trained batch 276 in epoch 0, gen_loss = 0.9065946841928503, disc_loss = 0.16826006224116694
Trained batch 277 in epoch 0, gen_loss = 0.9061980148871168, disc_loss = 0.16814599590871832
Trained batch 278 in epoch 0, gen_loss = 0.9052934356060507, disc_loss = 0.16813400390434435
Trained batch 279 in epoch 0, gen_loss = 0.9047099294407027, disc_loss = 0.16805190271032708
Trained batch 280 in epoch 0, gen_loss = 0.904325414170574, disc_loss = 0.16799414065066606
Trained batch 281 in epoch 0, gen_loss = 0.9038196719707327, disc_loss = 0.16786319463916705
Trained batch 282 in epoch 0, gen_loss = 0.9033309442415676, disc_loss = 0.16768897630195315
Trained batch 283 in epoch 0, gen_loss = 0.9033916580005431, disc_loss = 0.1675462179987783
Trained batch 284 in epoch 0, gen_loss = 0.9032534273047196, disc_loss = 0.1674244205418386
Trained batch 285 in epoch 0, gen_loss = 0.9023961570713069, disc_loss = 0.16741783127605497
Trained batch 286 in epoch 0, gen_loss = 0.9020227507431748, disc_loss = 0.1673859993599433
Trained batch 287 in epoch 0, gen_loss = 0.9027593452483416, disc_loss = 0.16726612467836174
Trained batch 288 in epoch 0, gen_loss = 0.9023159666044902, disc_loss = 0.16719238988565327
Trained batch 289 in epoch 0, gen_loss = 0.901808965000613, disc_loss = 0.16708487434120015
Trained batch 290 in epoch 0, gen_loss = 0.9016224725549573, disc_loss = 0.16705822737253817
Trained batch 291 in epoch 0, gen_loss = 0.9023359738392372, disc_loss = 0.16735987056506008
Trained batch 292 in epoch 0, gen_loss = 0.9016700895573092, disc_loss = 0.16748776342783364
Trained batch 293 in epoch 0, gen_loss = 0.90126863993755, disc_loss = 0.16715382961999803
Trained batch 294 in epoch 0, gen_loss = 0.9008777460809482, disc_loss = 0.16709560499352924
Trained batch 295 in epoch 0, gen_loss = 0.9009930837798763, disc_loss = 0.16683707295640096
Trained batch 296 in epoch 0, gen_loss = 0.9010580131903241, disc_loss = 0.16659845948620677
Trained batch 297 in epoch 0, gen_loss = 0.9006915008461716, disc_loss = 0.1665002984688586
Trained batch 298 in epoch 0, gen_loss = 0.9002226156534558, disc_loss = 0.16622518503845335
Trained batch 299 in epoch 0, gen_loss = 0.9009889209270477, disc_loss = 0.1660299388319254
Trained batch 300 in epoch 0, gen_loss = 0.9003332203804852, disc_loss = 0.16585556791470296
Trained batch 301 in epoch 0, gen_loss = 0.9000743059133063, disc_loss = 0.16563376207028005
Trained batch 302 in epoch 0, gen_loss = 0.9014085550906241, disc_loss = 0.16620717559120443
Trained batch 303 in epoch 0, gen_loss = 0.9009064520268064, disc_loss = 0.1663627253943368
Trained batch 304 in epoch 0, gen_loss = 0.9002911417210688, disc_loss = 0.16626519438673237
Trained batch 305 in epoch 0, gen_loss = 0.9006363361879112, disc_loss = 0.16670184144202402
Trained batch 306 in epoch 0, gen_loss = 0.8999080225000164, disc_loss = 0.1670637958309938
Trained batch 307 in epoch 0, gen_loss = 0.8998253709310061, disc_loss = 0.16733664695125122
Trained batch 308 in epoch 0, gen_loss = 0.8998813513413216, disc_loss = 0.1673782090249571
Trained batch 309 in epoch 0, gen_loss = 0.8990177802501186, disc_loss = 0.16743257050552676
Trained batch 310 in epoch 0, gen_loss = 0.898101676890321, disc_loss = 0.16742205471279537
Trained batch 311 in epoch 0, gen_loss = 0.8979623590906461, disc_loss = 0.1672844394850425
Trained batch 312 in epoch 0, gen_loss = 0.8976446873844622, disc_loss = 0.167362893113313
Trained batch 313 in epoch 0, gen_loss = 0.8970119338126699, disc_loss = 0.1676327474652582
Trained batch 314 in epoch 0, gen_loss = 0.8969865973033603, disc_loss = 0.16755067261438522
Trained batch 315 in epoch 0, gen_loss = 0.8971494670155682, disc_loss = 0.16763359223362767
Trained batch 316 in epoch 0, gen_loss = 0.896658596932324, disc_loss = 0.16755979769049384
Trained batch 317 in epoch 0, gen_loss = 0.8962579639452808, disc_loss = 0.16754227056630752
Trained batch 318 in epoch 0, gen_loss = 0.8954881732366675, disc_loss = 0.16736354636828354
Trained batch 319 in epoch 0, gen_loss = 0.895476233586669, disc_loss = 0.16718016206286848
Trained batch 320 in epoch 0, gen_loss = 0.8952967595088519, disc_loss = 0.1669478829590331
Trained batch 321 in epoch 0, gen_loss = 0.895220404826336, disc_loss = 0.16677034560660398
Trained batch 322 in epoch 0, gen_loss = 0.8955494213399503, disc_loss = 0.1668682231484183
Trained batch 323 in epoch 0, gen_loss = 0.8947292097188808, disc_loss = 0.16718519628507855
Trained batch 324 in epoch 0, gen_loss = 0.8951673641571631, disc_loss = 0.1670482742557159
Trained batch 325 in epoch 0, gen_loss = 0.895047120521405, disc_loss = 0.1668009310503679
Trained batch 326 in epoch 0, gen_loss = 0.8946554580595151, disc_loss = 0.16668828761358873
Trained batch 327 in epoch 0, gen_loss = 0.8953732979006883, disc_loss = 0.16713353096530204
Trained batch 328 in epoch 0, gen_loss = 0.8947732790987543, disc_loss = 0.16763582504085495
Trained batch 329 in epoch 0, gen_loss = 0.8943652375177904, disc_loss = 0.16753558828072115
Trained batch 330 in epoch 0, gen_loss = 0.8948359797368237, disc_loss = 0.16758683152789436
Trained batch 331 in epoch 0, gen_loss = 0.8944021088172154, disc_loss = 0.16748943305518255
Trained batch 332 in epoch 0, gen_loss = 0.8936025081454096, disc_loss = 0.16780516093557662
Trained batch 333 in epoch 0, gen_loss = 0.8933322704480794, disc_loss = 0.16786361222495577
Trained batch 334 in epoch 0, gen_loss = 0.8931378892998197, disc_loss = 0.16773298645197457
Trained batch 335 in epoch 0, gen_loss = 0.8930469832959629, disc_loss = 0.16757484986668542
Trained batch 336 in epoch 0, gen_loss = 0.8930406619957717, disc_loss = 0.16739581704405013
Trained batch 337 in epoch 0, gen_loss = 0.8936416115281145, disc_loss = 0.16724734204496153
Trained batch 338 in epoch 0, gen_loss = 0.8930374260848954, disc_loss = 0.16697464872338427
Trained batch 339 in epoch 0, gen_loss = 0.8920972403358011, disc_loss = 0.1672199849915855
Trained batch 340 in epoch 0, gen_loss = 0.892360588147843, disc_loss = 0.16720818230046555
Trained batch 341 in epoch 0, gen_loss = 0.8926095535532076, disc_loss = 0.1670865808444762
Trained batch 342 in epoch 0, gen_loss = 0.8923596701538598, disc_loss = 0.16678075396806089
Trained batch 343 in epoch 0, gen_loss = 0.8918886468854061, disc_loss = 0.16675871788242527
Trained batch 344 in epoch 0, gen_loss = 0.8924158020295958, disc_loss = 0.1666330816305202
Trained batch 345 in epoch 0, gen_loss = 0.8920022728126173, disc_loss = 0.16654936665658318
Trained batch 346 in epoch 0, gen_loss = 0.8917254389878309, disc_loss = 0.16640334421774153
Trained batch 347 in epoch 0, gen_loss = 0.8917615884679487, disc_loss = 0.16640870416558337
Trained batch 348 in epoch 0, gen_loss = 0.890949694509151, disc_loss = 0.16696676541450714
Trained batch 349 in epoch 0, gen_loss = 0.8905076587200165, disc_loss = 0.1670189262500831
Trained batch 350 in epoch 0, gen_loss = 0.8905306908479783, disc_loss = 0.16712822094347402
Trained batch 351 in epoch 0, gen_loss = 0.8900459515438839, disc_loss = 0.1672131239902228
Trained batch 352 in epoch 0, gen_loss = 0.8898533515146704, disc_loss = 0.16719132132047296
Trained batch 353 in epoch 0, gen_loss = 0.8893225194707428, disc_loss = 0.16740091206074434
Trained batch 354 in epoch 0, gen_loss = 0.8892196159967234, disc_loss = 0.16741840740744496
Trained batch 355 in epoch 0, gen_loss = 0.8893532778105039, disc_loss = 0.1674198123385732
Trained batch 356 in epoch 0, gen_loss = 0.8893549013204601, disc_loss = 0.1672906123247801
Trained batch 357 in epoch 0, gen_loss = 0.8887436266717964, disc_loss = 0.16747136424456896
Trained batch 358 in epoch 0, gen_loss = 0.8895685583103998, disc_loss = 0.16773939632854754
Trained batch 359 in epoch 0, gen_loss = 0.8892308738496568, disc_loss = 0.16748837932116456
Trained batch 360 in epoch 0, gen_loss = 0.8888120804797249, disc_loss = 0.16765570896484186
Trained batch 361 in epoch 0, gen_loss = 0.8882297361423956, disc_loss = 0.16755996257560687
Trained batch 362 in epoch 0, gen_loss = 0.888091364839517, disc_loss = 0.16773826881381107
Trained batch 363 in epoch 0, gen_loss = 0.8880672942806076, disc_loss = 0.16748363491925564
Trained batch 364 in epoch 0, gen_loss = 0.8875596077474829, disc_loss = 0.1673955016756711
Trained batch 365 in epoch 0, gen_loss = 0.8876791554070561, disc_loss = 0.1673772328131186
Trained batch 366 in epoch 0, gen_loss = 0.8867481966434447, disc_loss = 0.1674693539860463
Trained batch 367 in epoch 0, gen_loss = 0.8869387635394282, disc_loss = 0.16752552941603505
Trained batch 368 in epoch 0, gen_loss = 0.8867481425202636, disc_loss = 0.16761979731279336
Trained batch 369 in epoch 0, gen_loss = 0.8865342457552214, disc_loss = 0.1675534911655091
Trained batch 370 in epoch 0, gen_loss = 0.8866579179172567, disc_loss = 0.16734130479736792
Trained batch 371 in epoch 0, gen_loss = 0.8861574754920057, disc_loss = 0.1672806670508718
Trained batch 372 in epoch 0, gen_loss = 0.8862500318573243, disc_loss = 0.1670850511770146
Trained batch 373 in epoch 0, gen_loss = 0.885706461687139, disc_loss = 0.1668962926310014
Trained batch 374 in epoch 0, gen_loss = 0.8852961066563925, disc_loss = 0.16668766305843988
Trained batch 375 in epoch 0, gen_loss = 0.8849049841469907, disc_loss = 0.16655743817620455
Trained batch 376 in epoch 0, gen_loss = 0.8859462643175606, disc_loss = 0.16659005075218822
Trained batch 377 in epoch 0, gen_loss = 0.8851413159143358, disc_loss = 0.16680806664326203
Trained batch 378 in epoch 0, gen_loss = 0.8853637907939096, disc_loss = 0.16669502677420514
Trained batch 379 in epoch 0, gen_loss = 0.885467803478241, disc_loss = 0.16660848103071513
Trained batch 380 in epoch 0, gen_loss = 0.8848266773649401, disc_loss = 0.16700696843502716
Trained batch 381 in epoch 0, gen_loss = 0.8850055330710885, disc_loss = 0.16676342151864038
Trained batch 382 in epoch 0, gen_loss = 0.8851614857466974, disc_loss = 0.16676779612704296
Trained batch 383 in epoch 0, gen_loss = 0.8849127140517036, disc_loss = 0.16646677407940538
Trained batch 384 in epoch 0, gen_loss = 0.8844189275394786, disc_loss = 0.1665952886563617
Trained batch 385 in epoch 0, gen_loss = 0.8850341908672313, disc_loss = 0.16682972180912842
Trained batch 386 in epoch 0, gen_loss = 0.8844017232419292, disc_loss = 0.16674118973218502
Trained batch 387 in epoch 0, gen_loss = 0.8843707380835543, disc_loss = 0.1665454360646839
Trained batch 388 in epoch 0, gen_loss = 0.8841814434007385, disc_loss = 0.1664174183494481
Trained batch 389 in epoch 0, gen_loss = 0.8844211858052474, disc_loss = 0.1662925104968823
Trained batch 390 in epoch 0, gen_loss = 0.8847942737972035, disc_loss = 0.16598430869486325
Trained batch 391 in epoch 0, gen_loss = 0.8844384829304657, disc_loss = 0.16575973362148722
Trained batch 392 in epoch 0, gen_loss = 0.884331051174921, disc_loss = 0.16555065605742028
Trained batch 393 in epoch 0, gen_loss = 0.883960293483008, disc_loss = 0.16544077879167754
Trained batch 394 in epoch 0, gen_loss = 0.884093756615361, disc_loss = 0.16533468306253227
Trained batch 395 in epoch 0, gen_loss = 0.8836992045845649, disc_loss = 0.16509868993866023
Trained batch 396 in epoch 0, gen_loss = 0.8837432101631645, disc_loss = 0.1647729169417839
Trained batch 397 in epoch 0, gen_loss = 0.8838150430863826, disc_loss = 0.16456705435698654
Trained batch 398 in epoch 0, gen_loss = 0.8844848463409826, disc_loss = 0.16474865084714757
Trained batch 399 in epoch 0, gen_loss = 0.8843284864723683, disc_loss = 0.16465520366095007
Trained batch 400 in epoch 0, gen_loss = 0.8840872177162076, disc_loss = 0.16440991324342397
Trained batch 401 in epoch 0, gen_loss = 0.884630296360794, disc_loss = 0.16432095948254588
Trained batch 402 in epoch 0, gen_loss = 0.8845922500264851, disc_loss = 0.1640518031385785
Trained batch 403 in epoch 0, gen_loss = 0.8849048679417902, disc_loss = 0.16379252692112828
Trained batch 404 in epoch 0, gen_loss = 0.8854592432210475, disc_loss = 0.16347187866951213
Trained batch 405 in epoch 0, gen_loss = 0.8861636128918878, disc_loss = 0.16312081223638186
Trained batch 406 in epoch 0, gen_loss = 0.8859941080688551, disc_loss = 0.162868010919056
Trained batch 407 in epoch 0, gen_loss = 0.8862829304793302, disc_loss = 0.1625763799757788
Trained batch 408 in epoch 0, gen_loss = 0.8870501110198153, disc_loss = 0.16222848833372366
Trained batch 409 in epoch 0, gen_loss = 0.8874918870809602, disc_loss = 0.16189878457112283
Trained batch 410 in epoch 0, gen_loss = 0.8876756593548758, disc_loss = 0.16156796684574762
Trained batch 411 in epoch 0, gen_loss = 0.8879452132194945, disc_loss = 0.16125344925840357
Trained batch 412 in epoch 0, gen_loss = 0.8889184620132169, disc_loss = 0.16096522357341886
Trained batch 413 in epoch 0, gen_loss = 0.8888727966426075, disc_loss = 0.16064029729110751
Trained batch 414 in epoch 0, gen_loss = 0.8886298130793744, disc_loss = 0.16040722832353
Trained batch 415 in epoch 0, gen_loss = 0.8897163842159969, disc_loss = 0.16031156670606622
Trained batch 416 in epoch 0, gen_loss = 0.8894096312763022, disc_loss = 0.16009368962324638
Trained batch 417 in epoch 0, gen_loss = 0.8899018028706455, disc_loss = 0.15975797296675484
Trained batch 418 in epoch 0, gen_loss = 0.8901822487323552, disc_loss = 0.15941269653527007
Trained batch 419 in epoch 0, gen_loss = 0.8904321426437014, disc_loss = 0.15909640765970662
Trained batch 420 in epoch 0, gen_loss = 0.8902764661578271, disc_loss = 0.15881704877079808
Trained batch 421 in epoch 0, gen_loss = 0.8904598465462996, disc_loss = 0.15849050024956887
Trained batch 422 in epoch 0, gen_loss = 0.8906729646890158, disc_loss = 0.15814588412897876
Trained batch 423 in epoch 0, gen_loss = 0.8908838567868719, disc_loss = 0.15783869111163648
Trained batch 424 in epoch 0, gen_loss = 0.8914833270802217, disc_loss = 0.15755401838132563
Trained batch 425 in epoch 0, gen_loss = 0.8915952830247476, disc_loss = 0.1572516058186865
Trained batch 426 in epoch 0, gen_loss = 0.8922984346014554, disc_loss = 0.15713111596701088
Trained batch 427 in epoch 0, gen_loss = 0.8915286880230235, disc_loss = 0.15768456714288723
Trained batch 428 in epoch 0, gen_loss = 0.8919374706583979, disc_loss = 0.15760466266458198
Trained batch 429 in epoch 0, gen_loss = 0.891189656423968, disc_loss = 0.15800961766521945
Trained batch 430 in epoch 0, gen_loss = 0.8914177377649913, disc_loss = 0.15820471041137893
Trained batch 431 in epoch 0, gen_loss = 0.8910737759261219, disc_loss = 0.15830112825777312
Trained batch 432 in epoch 0, gen_loss = 0.8912129663705275, disc_loss = 0.1581324528812433
Trained batch 433 in epoch 0, gen_loss = 0.891637376101885, disc_loss = 0.1579354324137732
Trained batch 434 in epoch 0, gen_loss = 0.8915054591222741, disc_loss = 0.15776626559552448
Trained batch 435 in epoch 0, gen_loss = 0.8916311585301653, disc_loss = 0.15798752313402883
Trained batch 436 in epoch 0, gen_loss = 0.890744411836227, disc_loss = 0.1586525682594363
Trained batch 437 in epoch 0, gen_loss = 0.8902073629098396, disc_loss = 0.15862965368831608
Trained batch 438 in epoch 0, gen_loss = 0.8902823843554104, disc_loss = 0.15895716662058323
Trained batch 439 in epoch 0, gen_loss = 0.889773717387156, disc_loss = 0.15893419814423065
Trained batch 440 in epoch 0, gen_loss = 0.8891983622866694, disc_loss = 0.15898315239562538
Trained batch 441 in epoch 0, gen_loss = 0.8890427017913145, disc_loss = 0.15901013729436433
Trained batch 442 in epoch 0, gen_loss = 0.8887116922481872, disc_loss = 0.1590945197218865
Trained batch 443 in epoch 0, gen_loss = 0.8881451906384649, disc_loss = 0.15917850610682624
Trained batch 444 in epoch 0, gen_loss = 0.8878260785274291, disc_loss = 0.15914590769981066
Trained batch 445 in epoch 0, gen_loss = 0.8875515593274292, disc_loss = 0.15924963027013322
Trained batch 446 in epoch 0, gen_loss = 0.8873215033704003, disc_loss = 0.1591635199672057
Trained batch 447 in epoch 0, gen_loss = 0.8870502590600934, disc_loss = 0.15920418294055189
Trained batch 448 in epoch 0, gen_loss = 0.8873609357528007, disc_loss = 0.15932964076617845
Trained batch 449 in epoch 0, gen_loss = 0.8870200430022346, disc_loss = 0.1591736332182255
Trained batch 450 in epoch 0, gen_loss = 0.8863986158318107, disc_loss = 0.15928577897066618
Trained batch 451 in epoch 0, gen_loss = 0.8868198665106191, disc_loss = 0.15960413424619596
Trained batch 452 in epoch 0, gen_loss = 0.8864609489904071, disc_loss = 0.1596166312830239
Trained batch 453 in epoch 0, gen_loss = 0.8859881845339804, disc_loss = 0.1596427835495363
Trained batch 454 in epoch 0, gen_loss = 0.8856609746650025, disc_loss = 0.15964499619676845
Trained batch 455 in epoch 0, gen_loss = 0.8852784760427057, disc_loss = 0.1595747590395867
Trained batch 456 in epoch 0, gen_loss = 0.8850324729078447, disc_loss = 0.1595700319216503
Trained batch 457 in epoch 0, gen_loss = 0.8845361948794153, disc_loss = 0.1595731854507919
Trained batch 458 in epoch 0, gen_loss = 0.8844413059988833, disc_loss = 0.15942845345233325
Trained batch 459 in epoch 0, gen_loss = 0.8843538969755173, disc_loss = 0.15924523198450713
Trained batch 460 in epoch 0, gen_loss = 0.8839151265822884, disc_loss = 0.15919490951495224
Trained batch 461 in epoch 0, gen_loss = 0.8837739733648506, disc_loss = 0.15930156826819758
Trained batch 462 in epoch 0, gen_loss = 0.8838030925064828, disc_loss = 0.15905556557639694
Trained batch 463 in epoch 0, gen_loss = 0.883498246556726, disc_loss = 0.15894130208120072
Trained batch 464 in epoch 0, gen_loss = 0.8836424190510985, disc_loss = 0.15883159206639375
Trained batch 465 in epoch 0, gen_loss = 0.8833055410518155, disc_loss = 0.15871591437727917
Trained batch 466 in epoch 0, gen_loss = 0.8831268617887313, disc_loss = 0.15864902527552155
Trained batch 467 in epoch 0, gen_loss = 0.8839549626040663, disc_loss = 0.158955027629884
Trained batch 468 in epoch 0, gen_loss = 0.8835616968333848, disc_loss = 0.15891847068638498
Trained batch 469 in epoch 0, gen_loss = 0.88331842371758, disc_loss = 0.15872992581707682
Trained batch 470 in epoch 0, gen_loss = 0.8835149700980783, disc_loss = 0.15864717805532702
Trained batch 471 in epoch 0, gen_loss = 0.8832050840985977, disc_loss = 0.15842225237047078
Trained batch 472 in epoch 0, gen_loss = 0.8825306141351292, disc_loss = 0.15866676897763513
Trained batch 473 in epoch 0, gen_loss = 0.8828681340197471, disc_loss = 0.15909342309224267
Trained batch 474 in epoch 0, gen_loss = 0.8825007122441342, disc_loss = 0.15898943752246467
Trained batch 475 in epoch 0, gen_loss = 0.8818801123054087, disc_loss = 0.15899262754363985
Trained batch 476 in epoch 0, gen_loss = 0.881471778986589, disc_loss = 0.15899660376015762
Trained batch 477 in epoch 0, gen_loss = 0.8813626430772837, disc_loss = 0.15876767648165757
Trained batch 478 in epoch 0, gen_loss = 0.8808809259988072, disc_loss = 0.158702602444726
Trained batch 479 in epoch 0, gen_loss = 0.8808586080869039, disc_loss = 0.15863927504396996
Trained batch 480 in epoch 0, gen_loss = 0.8807182313250901, disc_loss = 0.15853217384524318
Trained batch 481 in epoch 0, gen_loss = 0.8805673927439693, disc_loss = 0.15840045779487466
Trained batch 482 in epoch 0, gen_loss = 0.8801778600576254, disc_loss = 0.15833763422841673
Trained batch 483 in epoch 0, gen_loss = 0.8805859518691528, disc_loss = 0.15822265932359542
Trained batch 484 in epoch 0, gen_loss = 0.8801832723863346, disc_loss = 0.15810389670245734
Trained batch 485 in epoch 0, gen_loss = 0.8804766801894938, disc_loss = 0.1578432125568298
Trained batch 486 in epoch 0, gen_loss = 0.8808876825553925, disc_loss = 0.1576042480066847
Trained batch 487 in epoch 0, gen_loss = 0.8804997134892667, disc_loss = 0.15758945017511056
Trained batch 488 in epoch 0, gen_loss = 0.8810713317984209, disc_loss = 0.15787494408275268
Trained batch 489 in epoch 0, gen_loss = 0.8808686500909377, disc_loss = 0.15765736897723104
Trained batch 490 in epoch 0, gen_loss = 0.8804004351378943, disc_loss = 0.15787056116709702
Trained batch 491 in epoch 0, gen_loss = 0.8808692212754149, disc_loss = 0.15809028575431586
Trained batch 492 in epoch 0, gen_loss = 0.8807339566716316, disc_loss = 0.15798589220916584
Trained batch 493 in epoch 0, gen_loss = 0.8804843150652372, disc_loss = 0.15776376495032235
Trained batch 494 in epoch 0, gen_loss = 0.8801785301680517, disc_loss = 0.15758714645235528
Trained batch 495 in epoch 0, gen_loss = 0.8804889435489331, disc_loss = 0.1574379324766567
Trained batch 496 in epoch 0, gen_loss = 0.8800842080797467, disc_loss = 0.15728261925362544
Trained batch 497 in epoch 0, gen_loss = 0.8794543340981725, disc_loss = 0.15722486576678824
Trained batch 498 in epoch 0, gen_loss = 0.8793324944012628, disc_loss = 0.15703654706754344
Trained batch 499 in epoch 0, gen_loss = 0.8797780969142914, disc_loss = 0.156987383807078
Trained batch 500 in epoch 0, gen_loss = 0.8793317052180658, disc_loss = 0.15709758006564217
Trained batch 501 in epoch 0, gen_loss = 0.8790809109628913, disc_loss = 0.1570352101234712
Trained batch 502 in epoch 0, gen_loss = 0.8790829791937387, disc_loss = 0.15684632046951746
Trained batch 503 in epoch 0, gen_loss = 0.8795117053484159, disc_loss = 0.15687836676518183
Trained batch 504 in epoch 0, gen_loss = 0.879067859673264, disc_loss = 0.15678666221660256
Trained batch 505 in epoch 0, gen_loss = 0.8791085518160356, disc_loss = 0.15655458408772296
Trained batch 506 in epoch 0, gen_loss = 0.8792270966300363, disc_loss = 0.15629811770295543
Trained batch 507 in epoch 0, gen_loss = 0.8795731486532632, disc_loss = 0.1560501738755751
Trained batch 508 in epoch 0, gen_loss = 0.8791599317009182, disc_loss = 0.15589191738428265
Trained batch 509 in epoch 0, gen_loss = 0.8791896561781566, disc_loss = 0.15584475767853506
Trained batch 510 in epoch 0, gen_loss = 0.8792815868635233, disc_loss = 0.15571475185184155
Trained batch 511 in epoch 0, gen_loss = 0.8789337740745395, disc_loss = 0.15573541952653613
Trained batch 512 in epoch 0, gen_loss = 0.8790894931519938, disc_loss = 0.15564869319725977
Trained batch 513 in epoch 0, gen_loss = 0.8793402614528567, disc_loss = 0.15543922603108598
Trained batch 514 in epoch 0, gen_loss = 0.8789482411829014, disc_loss = 0.15531985251395736
Trained batch 515 in epoch 0, gen_loss = 0.8791625905175542, disc_loss = 0.15528943081559657
Trained batch 516 in epoch 0, gen_loss = 0.8787289644578901, disc_loss = 0.15527338554228817
Trained batch 517 in epoch 0, gen_loss = 0.8789526776457385, disc_loss = 0.1552301385605341
Trained batch 518 in epoch 0, gen_loss = 0.8787162587592138, disc_loss = 0.1550883995692079
Trained batch 519 in epoch 0, gen_loss = 0.8792289790052634, disc_loss = 0.15501582697929384
Trained batch 520 in epoch 0, gen_loss = 0.8789446975127749, disc_loss = 0.15488725922994617
Trained batch 521 in epoch 0, gen_loss = 0.8788368877779935, disc_loss = 0.15474179459350376
Trained batch 522 in epoch 0, gen_loss = 0.878010688160847, disc_loss = 0.15479050475007092
Trained batch 523 in epoch 0, gen_loss = 0.8777104277192181, disc_loss = 0.15466193744791884
Trained batch 524 in epoch 0, gen_loss = 0.8786082392647153, disc_loss = 0.15509733709018855
Trained batch 525 in epoch 0, gen_loss = 0.8782357707223059, disc_loss = 0.15527318050631608
Trained batch 526 in epoch 0, gen_loss = 0.8780813859581269, disc_loss = 0.1553130115716377
Trained batch 527 in epoch 0, gen_loss = 0.8780010383237492, disc_loss = 0.15536924822178358
Trained batch 528 in epoch 0, gen_loss = 0.8776418397692516, disc_loss = 0.15538384339513367
Trained batch 529 in epoch 0, gen_loss = 0.8774382893769246, disc_loss = 0.15530988130683326
Trained batch 530 in epoch 0, gen_loss = 0.8773979061965439, disc_loss = 0.1554838935397355
Trained batch 531 in epoch 0, gen_loss = 0.8769165097098601, disc_loss = 0.15577205792384544
Trained batch 532 in epoch 0, gen_loss = 0.8766986895457441, disc_loss = 0.15574219952360158
Trained batch 533 in epoch 0, gen_loss = 0.8768614199054375, disc_loss = 0.15562187392815724
Trained batch 534 in epoch 0, gen_loss = 0.8765486729479282, disc_loss = 0.15550304727332892
Trained batch 535 in epoch 0, gen_loss = 0.8759061966591807, disc_loss = 0.15569093654717583
Trained batch 536 in epoch 0, gen_loss = 0.8760479893986295, disc_loss = 0.15608079160704127
Trained batch 537 in epoch 0, gen_loss = 0.8755048189907713, disc_loss = 0.15619976733565386
Trained batch 538 in epoch 0, gen_loss = 0.8751029713919078, disc_loss = 0.15614820995535666
Trained batch 539 in epoch 0, gen_loss = 0.8749345293751469, disc_loss = 0.15614533800528282
Trained batch 540 in epoch 0, gen_loss = 0.8745666546213429, disc_loss = 0.15620283874237217
Trained batch 541 in epoch 0, gen_loss = 0.8745299388561741, disc_loss = 0.15611136686297417
Trained batch 542 in epoch 0, gen_loss = 0.8741655326679926, disc_loss = 0.15611797357989993
Trained batch 543 in epoch 0, gen_loss = 0.8741727759513784, disc_loss = 0.15609627431566717
Trained batch 544 in epoch 0, gen_loss = 0.8738548008673782, disc_loss = 0.15597029677805824
Trained batch 545 in epoch 0, gen_loss = 0.8738646786728185, disc_loss = 0.15579688291989893
Trained batch 546 in epoch 0, gen_loss = 0.8735688214328214, disc_loss = 0.15569366984089777
Trained batch 547 in epoch 0, gen_loss = 0.8737230405320217, disc_loss = 0.15559882176598114
Trained batch 548 in epoch 0, gen_loss = 0.8733120815784337, disc_loss = 0.155550625760495
Trained batch 549 in epoch 0, gen_loss = 0.8731237477605993, disc_loss = 0.1554297795299102
Trained batch 550 in epoch 0, gen_loss = 0.8733595669161386, disc_loss = 0.15539227787932608
Trained batch 551 in epoch 0, gen_loss = 0.8733469247817993, disc_loss = 0.155150977612905
Trained batch 552 in epoch 0, gen_loss = 0.8727207032940055, disc_loss = 0.15527558198895905
Trained batch 553 in epoch 0, gen_loss = 0.8728720756644376, disc_loss = 0.15518912986519373
Trained batch 554 in epoch 0, gen_loss = 0.8736180889713872, disc_loss = 0.15513168317139955
Trained batch 555 in epoch 0, gen_loss = 0.8732375680542678, disc_loss = 0.1549976868772705
Trained batch 556 in epoch 0, gen_loss = 0.8727214368498304, disc_loss = 0.1549974801420122
Trained batch 557 in epoch 0, gen_loss = 0.8729473326795845, disc_loss = 0.15497392440201402
Trained batch 558 in epoch 0, gen_loss = 0.8727542607643524, disc_loss = 0.15490345872958625
Trained batch 559 in epoch 0, gen_loss = 0.8723124035767147, disc_loss = 0.15489727918757126
Trained batch 560 in epoch 0, gen_loss = 0.8716268451243586, disc_loss = 0.15525274241837853
Trained batch 561 in epoch 0, gen_loss = 0.8718320306297723, disc_loss = 0.15536438350423215
Trained batch 562 in epoch 0, gen_loss = 0.8718546543197564, disc_loss = 0.1551876928323142
Trained batch 563 in epoch 0, gen_loss = 0.8713988121731061, disc_loss = 0.15516286900973753
Trained batch 564 in epoch 0, gen_loss = 0.8710773627314947, disc_loss = 0.1551969418236244
Trained batch 565 in epoch 0, gen_loss = 0.8717628564725074, disc_loss = 0.155341819114654
Trained batch 566 in epoch 0, gen_loss = 0.8714928457766403, disc_loss = 0.15526000443333512
Trained batch 567 in epoch 0, gen_loss = 0.8711477229502839, disc_loss = 0.1551872884582492
Trained batch 568 in epoch 0, gen_loss = 0.8712977285125344, disc_loss = 0.15515164570205292
Trained batch 569 in epoch 0, gen_loss = 0.8711500901924937, disc_loss = 0.1549820534182353
Trained batch 570 in epoch 0, gen_loss = 0.8707945880246872, disc_loss = 0.1549214657653782
Trained batch 571 in epoch 0, gen_loss = 0.8706778075311568, disc_loss = 0.15502899802628567
Trained batch 572 in epoch 0, gen_loss = 0.8700961830520297, disc_loss = 0.1550955063050668
Trained batch 573 in epoch 0, gen_loss = 0.8698671556723658, disc_loss = 0.15502775022565332
Trained batch 574 in epoch 0, gen_loss = 0.8698125880697499, disc_loss = 0.15502037375679484
Trained batch 575 in epoch 0, gen_loss = 0.8696365245721407, disc_loss = 0.15497545045056743
Trained batch 576 in epoch 0, gen_loss = 0.8694191047182529, disc_loss = 0.15486890885436608
Trained batch 577 in epoch 0, gen_loss = 0.8697649869539333, disc_loss = 0.15471519074309295
Trained batch 578 in epoch 0, gen_loss = 0.8695248024657188, disc_loss = 0.15475987678551353
Trained batch 579 in epoch 0, gen_loss = 0.8697234333589159, disc_loss = 0.15475840869937735
Trained batch 580 in epoch 0, gen_loss = 0.869219877941473, disc_loss = 0.15479639547808086
Trained batch 581 in epoch 0, gen_loss = 0.8691255291507826, disc_loss = 0.1547931310675936
Trained batch 582 in epoch 0, gen_loss = 0.8690572074306154, disc_loss = 0.1546693046626796
Trained batch 583 in epoch 0, gen_loss = 0.8688828283793306, disc_loss = 0.15453137481132243
Trained batch 584 in epoch 0, gen_loss = 0.8688699296397022, disc_loss = 0.15431618390079493
Trained batch 585 in epoch 0, gen_loss = 0.8687065987253352, disc_loss = 0.15424278775331765
Trained batch 586 in epoch 0, gen_loss = 0.8684403302316162, disc_loss = 0.15423205842817714
Trained batch 587 in epoch 0, gen_loss = 0.8680867563907791, disc_loss = 0.15411670151369355
Trained batch 588 in epoch 0, gen_loss = 0.8680030734915483, disc_loss = 0.15396520466478905
Trained batch 589 in epoch 0, gen_loss = 0.867989117917368, disc_loss = 0.1538932525773801
Trained batch 590 in epoch 0, gen_loss = 0.8679318573269142, disc_loss = 0.15375370802215968
Trained batch 591 in epoch 0, gen_loss = 0.8683800526164673, disc_loss = 0.15357022959191502
Trained batch 592 in epoch 0, gen_loss = 0.8683988406726522, disc_loss = 0.15339919453734943
Trained batch 593 in epoch 0, gen_loss = 0.8681909263334692, disc_loss = 0.15330208049183994
Trained batch 594 in epoch 0, gen_loss = 0.8688522849764143, disc_loss = 0.1537273306696981
Trained batch 595 in epoch 0, gen_loss = 0.8681305211362422, disc_loss = 0.1542658827739499
Trained batch 596 in epoch 0, gen_loss = 0.868195086517925, disc_loss = 0.15437814517342915
Trained batch 597 in epoch 0, gen_loss = 0.8679989212033741, disc_loss = 0.1543565131241088
Trained batch 598 in epoch 0, gen_loss = 0.867792407588688, disc_loss = 0.15423290569720813
Trained batch 599 in epoch 0, gen_loss = 0.8674611302713553, disc_loss = 0.15408301322565723
Trained batch 600 in epoch 0, gen_loss = 0.8670865984109792, disc_loss = 0.15403715950187402
Trained batch 601 in epoch 0, gen_loss = 0.8671518027089363, disc_loss = 0.15396276461826855
Trained batch 602 in epoch 0, gen_loss = 0.8670044741523799, disc_loss = 0.15385969404662475
Trained batch 603 in epoch 0, gen_loss = 0.8665901982527695, disc_loss = 0.15383718603302954
Trained batch 604 in epoch 0, gen_loss = 0.8665868403990407, disc_loss = 0.15376521831855547
Trained batch 605 in epoch 0, gen_loss = 0.8667780017793769, disc_loss = 0.15363627465798368
Trained batch 606 in epoch 0, gen_loss = 0.8663168318287349, disc_loss = 0.15392001535547084
Trained batch 607 in epoch 0, gen_loss = 0.8667889695712611, disc_loss = 0.15392359571782627
Trained batch 608 in epoch 0, gen_loss = 0.8670024412312531, disc_loss = 0.15371144956439636
Trained batch 609 in epoch 0, gen_loss = 0.866927655065646, disc_loss = 0.15352911738617742
Trained batch 610 in epoch 0, gen_loss = 0.8665891054121445, disc_loss = 0.15354495718252104
Trained batch 611 in epoch 0, gen_loss = 0.8669372853013425, disc_loss = 0.15376132950217164
Trained batch 612 in epoch 0, gen_loss = 0.8665626427769466, disc_loss = 0.15372913161392945
Trained batch 613 in epoch 0, gen_loss = 0.8660001873678804, disc_loss = 0.1537645559845923
Trained batch 614 in epoch 0, gen_loss = 0.8659141942252958, disc_loss = 0.15370714201220895
Trained batch 615 in epoch 0, gen_loss = 0.86600408978857, disc_loss = 0.15360940723867433
Trained batch 616 in epoch 0, gen_loss = 0.8657018817128007, disc_loss = 0.1536407870839756
Trained batch 617 in epoch 0, gen_loss = 0.8656612368945551, disc_loss = 0.15359258571711992
Trained batch 618 in epoch 0, gen_loss = 0.8657811655270263, disc_loss = 0.1534419670499416
Trained batch 619 in epoch 0, gen_loss = 0.8657106146216392, disc_loss = 0.153333225895861
Trained batch 620 in epoch 0, gen_loss = 0.8655766343244992, disc_loss = 0.15317094577521373
Trained batch 621 in epoch 0, gen_loss = 0.8655199041033098, disc_loss = 0.1530107520475768
Trained batch 622 in epoch 0, gen_loss = 0.8655537577827325, disc_loss = 0.1528253089920595
Trained batch 623 in epoch 0, gen_loss = 0.8658454313587683, disc_loss = 0.1527890981703352
Trained batch 624 in epoch 0, gen_loss = 0.8654395944118499, disc_loss = 0.15283251498490572
Trained batch 625 in epoch 0, gen_loss = 0.8656940158849327, disc_loss = 0.15270577764626556
Trained batch 626 in epoch 0, gen_loss = 0.8662951992174085, disc_loss = 0.15265995481064873
Trained batch 627 in epoch 0, gen_loss = 0.8659934450391751, disc_loss = 0.1525534665298049
Trained batch 628 in epoch 0, gen_loss = 0.8659788682369814, disc_loss = 0.15233958070277456
Trained batch 629 in epoch 0, gen_loss = 0.8662603264290188, disc_loss = 0.1521341632179443
Trained batch 630 in epoch 0, gen_loss = 0.8659328815015107, disc_loss = 0.15220720056597906
Trained batch 631 in epoch 0, gen_loss = 0.8667611345365832, disc_loss = 0.15266191566958315
Trained batch 632 in epoch 0, gen_loss = 0.8664773457329044, disc_loss = 0.1525427098584613
Trained batch 633 in epoch 0, gen_loss = 0.8659743976423793, disc_loss = 0.15265997670949305
Trained batch 634 in epoch 0, gen_loss = 0.8660242215385587, disc_loss = 0.15274883147446425
Trained batch 635 in epoch 0, gen_loss = 0.8657336084629005, disc_loss = 0.15283730286524966
Trained batch 636 in epoch 0, gen_loss = 0.8651720560981865, disc_loss = 0.1529003984106228
Trained batch 637 in epoch 0, gen_loss = 0.8648145424441485, disc_loss = 0.15288829876016533
Trained batch 638 in epoch 0, gen_loss = 0.864569109137256, disc_loss = 0.15283595918822038
Trained batch 639 in epoch 0, gen_loss = 0.8644221155438572, disc_loss = 0.15285152804717655
Trained batch 640 in epoch 0, gen_loss = 0.863982273384859, disc_loss = 0.15287468244296945
Trained batch 641 in epoch 0, gen_loss = 0.8634290056900815, disc_loss = 0.1529247363190808
Trained batch 642 in epoch 0, gen_loss = 0.8633673243444778, disc_loss = 0.15283087395496586
Trained batch 643 in epoch 0, gen_loss = 0.863477243446045, disc_loss = 0.15303564644476503
Trained batch 644 in epoch 0, gen_loss = 0.8631174620269805, disc_loss = 0.15290302685209253
Trained batch 645 in epoch 0, gen_loss = 0.8625677829095084, disc_loss = 0.15332145089479654
Trained batch 646 in epoch 0, gen_loss = 0.8623107428989234, disc_loss = 0.15328641726536074
Trained batch 647 in epoch 0, gen_loss = 0.862516788466845, disc_loss = 0.15342804223994644
Trained batch 648 in epoch 0, gen_loss = 0.8623616616880214, disc_loss = 0.15330538702540342
Trained batch 649 in epoch 0, gen_loss = 0.8621374359956154, disc_loss = 0.15323160050150295
Trained batch 650 in epoch 0, gen_loss = 0.861801015479224, disc_loss = 0.1532451414536061
Trained batch 651 in epoch 0, gen_loss = 0.8616584207108415, disc_loss = 0.1531548613890937
Trained batch 652 in epoch 0, gen_loss = 0.8618206357609075, disc_loss = 0.15310274187909015
Trained batch 653 in epoch 0, gen_loss = 0.8615580533349186, disc_loss = 0.15310673169729042
Trained batch 654 in epoch 0, gen_loss = 0.8616057694868277, disc_loss = 0.15317639076214937
Trained batch 655 in epoch 0, gen_loss = 0.861693328337335, disc_loss = 0.15301615841510682
Trained batch 656 in epoch 0, gen_loss = 0.8616017946460294, disc_loss = 0.1528561360569872
Trained batch 657 in epoch 0, gen_loss = 0.8615004913513421, disc_loss = 0.15276475359563996
Trained batch 658 in epoch 0, gen_loss = 0.8616058014683731, disc_loss = 0.1526742520924426
Trained batch 659 in epoch 0, gen_loss = 0.8615755698446071, disc_loss = 0.15258639663824755
Trained batch 660 in epoch 0, gen_loss = 0.8613691841690335, disc_loss = 0.15252870908669236
Trained batch 661 in epoch 0, gen_loss = 0.8609428520559184, disc_loss = 0.15259089833125472
Trained batch 662 in epoch 0, gen_loss = 0.8609507861090642, disc_loss = 0.1526066093504721
Trained batch 663 in epoch 0, gen_loss = 0.8606957488480103, disc_loss = 0.1526385444870039
Trained batch 664 in epoch 0, gen_loss = 0.860982641824206, disc_loss = 0.1529650271064917
Trained batch 665 in epoch 0, gen_loss = 0.8608081446843104, disc_loss = 0.15285138319478603
Trained batch 666 in epoch 0, gen_loss = 0.8604535753133594, disc_loss = 0.15291942031760847
Trained batch 667 in epoch 0, gen_loss = 0.8605590796845402, disc_loss = 0.15295560288934518
Trained batch 668 in epoch 0, gen_loss = 0.860296805833309, disc_loss = 0.15295646353158404
Trained batch 669 in epoch 0, gen_loss = 0.8601291308207298, disc_loss = 0.15294405914870884
Trained batch 670 in epoch 0, gen_loss = 0.8597308630470725, disc_loss = 0.15299273939767155
Trained batch 671 in epoch 0, gen_loss = 0.8597017259203962, disc_loss = 0.15304051833144122
Trained batch 672 in epoch 0, gen_loss = 0.8596668609626934, disc_loss = 0.15310580228188284
Trained batch 673 in epoch 0, gen_loss = 0.8593100305392409, disc_loss = 0.15309620260755677
Trained batch 674 in epoch 0, gen_loss = 0.8590555646242919, disc_loss = 0.153085651807487
Trained batch 675 in epoch 0, gen_loss = 0.859195595618183, disc_loss = 0.15324584400341928
Trained batch 676 in epoch 0, gen_loss = 0.8587947807864917, disc_loss = 0.15351598461239738
Trained batch 677 in epoch 0, gen_loss = 0.8588023578259094, disc_loss = 0.15348509990453588
Trained batch 678 in epoch 0, gen_loss = 0.8588810279987347, disc_loss = 0.15344974564440517
Trained batch 679 in epoch 0, gen_loss = 0.8586684713030562, disc_loss = 0.1534317801008001
Trained batch 680 in epoch 0, gen_loss = 0.8583281770589243, disc_loss = 0.15344918018313625
Trained batch 681 in epoch 0, gen_loss = 0.8583250730530607, disc_loss = 0.15337236814577776
Trained batch 682 in epoch 0, gen_loss = 0.858389170723115, disc_loss = 0.1532245460218623
Trained batch 683 in epoch 0, gen_loss = 0.8583028550472176, disc_loss = 0.15311047579815382
Trained batch 684 in epoch 0, gen_loss = 0.8580653279802225, disc_loss = 0.15300824817433192
Trained batch 685 in epoch 0, gen_loss = 0.8579387887660685, disc_loss = 0.15291761488683586
Trained batch 686 in epoch 0, gen_loss = 0.8581977021138915, disc_loss = 0.15289627008134665
Trained batch 687 in epoch 0, gen_loss = 0.8577489471279605, disc_loss = 0.15302779479087655
Trained batch 688 in epoch 0, gen_loss = 0.8579365533650873, disc_loss = 0.1530576483812859
Trained batch 689 in epoch 0, gen_loss = 0.8579250337852948, disc_loss = 0.15299785520638462
Trained batch 690 in epoch 0, gen_loss = 0.8575683714425685, disc_loss = 0.1530727606425776
Trained batch 691 in epoch 0, gen_loss = 0.8579966783781962, disc_loss = 0.15300438242070807
Trained batch 692 in epoch 0, gen_loss = 0.8581403707615053, disc_loss = 0.15286455306252747
Trained batch 693 in epoch 0, gen_loss = 0.8579707168450617, disc_loss = 0.15271988823091992
Trained batch 694 in epoch 0, gen_loss = 0.8574212912604106, disc_loss = 0.15289705372783993
Trained batch 695 in epoch 0, gen_loss = 0.8575195447895033, disc_loss = 0.15284739039308423
Trained batch 696 in epoch 0, gen_loss = 0.8575503371623873, disc_loss = 0.1527326228952241
Trained batch 697 in epoch 0, gen_loss = 0.8573385666212585, disc_loss = 0.15262335426384918
Trained batch 698 in epoch 0, gen_loss = 0.8572208961106847, disc_loss = 0.15249588013958393
Trained batch 699 in epoch 0, gen_loss = 0.8570170357823372, disc_loss = 0.1525231120056872
Trained batch 700 in epoch 0, gen_loss = 0.8567904275171087, disc_loss = 0.15243951785650514
Trained batch 701 in epoch 0, gen_loss = 0.8564021370434693, disc_loss = 0.1524292248502862
Trained batch 702 in epoch 0, gen_loss = 0.8569149310100469, disc_loss = 0.15236341206762266
Trained batch 703 in epoch 0, gen_loss = 0.8569177598692477, disc_loss = 0.15221906688979783
Trained batch 704 in epoch 0, gen_loss = 0.8570383944832687, disc_loss = 0.15202775310777814
Trained batch 705 in epoch 0, gen_loss = 0.8567921772134878, disc_loss = 0.15190919599081615
Trained batch 706 in epoch 0, gen_loss = 0.8565932752978178, disc_loss = 0.1518437586569318
Trained batch 707 in epoch 0, gen_loss = 0.8570522271559737, disc_loss = 0.15196466313985488
Trained batch 708 in epoch 0, gen_loss = 0.8567683471022607, disc_loss = 0.15199810737935754
Trained batch 709 in epoch 0, gen_loss = 0.8566467847202865, disc_loss = 0.1519588606523901
Trained batch 710 in epoch 0, gen_loss = 0.8567797543714151, disc_loss = 0.15188351540358636
Trained batch 711 in epoch 0, gen_loss = 0.8564165997622388, disc_loss = 0.151925213536865
Trained batch 712 in epoch 0, gen_loss = 0.8566264644327872, disc_loss = 0.15187996392481834
Trained batch 713 in epoch 0, gen_loss = 0.8566172238574976, disc_loss = 0.15173661193995625
Trained batch 714 in epoch 0, gen_loss = 0.856245237338793, disc_loss = 0.15168971157391797
Trained batch 715 in epoch 0, gen_loss = 0.8561770726598841, disc_loss = 0.15156417403125605
Trained batch 716 in epoch 0, gen_loss = 0.8560296347367381, disc_loss = 0.1514926410684131
Trained batch 717 in epoch 0, gen_loss = 0.8560256541688462, disc_loss = 0.15138983127367903
Trained batch 718 in epoch 0, gen_loss = 0.8559856685461354, disc_loss = 0.15127160577997253
Trained batch 719 in epoch 0, gen_loss = 0.8556613189064795, disc_loss = 0.15129476126102318
Trained batch 720 in epoch 0, gen_loss = 0.856073701141942, disc_loss = 0.15158808002592
Trained batch 721 in epoch 0, gen_loss = 0.8563171036108048, disc_loss = 0.1514071062209802
Trained batch 722 in epoch 0, gen_loss = 0.856094707056035, disc_loss = 0.15135778129786087
Trained batch 723 in epoch 0, gen_loss = 0.8557230869297823, disc_loss = 0.15136119576803928
Trained batch 724 in epoch 0, gen_loss = 0.8554202876830923, disc_loss = 0.15142192901850773
Trained batch 725 in epoch 0, gen_loss = 0.8557301393143073, disc_loss = 0.15175428239053973
Trained batch 726 in epoch 0, gen_loss = 0.8555538704749479, disc_loss = 0.1518671512770296
Trained batch 727 in epoch 0, gen_loss = 0.8553534415806388, disc_loss = 0.1519875741310438
Trained batch 728 in epoch 0, gen_loss = 0.8553585927264027, disc_loss = 0.1520268113731786
Trained batch 729 in epoch 0, gen_loss = 0.8552547799806073, disc_loss = 0.15201873546211075
Trained batch 730 in epoch 0, gen_loss = 0.8550063778127757, disc_loss = 0.15205273969498975
Trained batch 731 in epoch 0, gen_loss = 0.8552210057775179, disc_loss = 0.15210627019023676
Trained batch 732 in epoch 0, gen_loss = 0.8550193028837076, disc_loss = 0.15207946836811173
Trained batch 733 in epoch 0, gen_loss = 0.8547844969203102, disc_loss = 0.15207046123820406
Trained batch 734 in epoch 0, gen_loss = 0.8549410367904067, disc_loss = 0.152019324925329
Trained batch 735 in epoch 0, gen_loss = 0.8547026484637804, disc_loss = 0.15199817810840296
Trained batch 736 in epoch 0, gen_loss = 0.8545600664745031, disc_loss = 0.15193946759268298
Trained batch 737 in epoch 0, gen_loss = 0.8544913455642013, disc_loss = 0.1518623008983346
Trained batch 738 in epoch 0, gen_loss = 0.8544367322337805, disc_loss = 0.15190997059017178
Trained batch 739 in epoch 0, gen_loss = 0.854169448122785, disc_loss = 0.15186709683715693
Trained batch 740 in epoch 0, gen_loss = 0.8539914173877191, disc_loss = 0.1517961235244365
Trained batch 741 in epoch 0, gen_loss = 0.8539213128086691, disc_loss = 0.15169617348548897
Trained batch 742 in epoch 0, gen_loss = 0.8538747843390038, disc_loss = 0.15167225782620353
Trained batch 743 in epoch 0, gen_loss = 0.853570981812413, disc_loss = 0.15164362791029395
Trained batch 744 in epoch 0, gen_loss = 0.8534860796176347, disc_loss = 0.1516230757767022
Trained batch 745 in epoch 0, gen_loss = 0.8534249445628225, disc_loss = 0.15155963040014414
Trained batch 746 in epoch 0, gen_loss = 0.8532526411285681, disc_loss = 0.1514904603544109
Trained batch 747 in epoch 0, gen_loss = 0.8536388164455878, disc_loss = 0.1513920287280418
Trained batch 748 in epoch 0, gen_loss = 0.8532946568544462, disc_loss = 0.15149590671087337
Trained batch 749 in epoch 0, gen_loss = 0.8536561340093612, disc_loss = 0.15171936813617745
Trained batch 750 in epoch 0, gen_loss = 0.8535701547973801, disc_loss = 0.15167821822353153
Trained batch 751 in epoch 0, gen_loss = 0.8535010942674064, disc_loss = 0.1515477782850986
Trained batch 752 in epoch 0, gen_loss = 0.8535753041703704, disc_loss = 0.15138665220736072
Trained batch 753 in epoch 0, gen_loss = 0.8537424920961775, disc_loss = 0.1512792407194108
Trained batch 754 in epoch 0, gen_loss = 0.8536151004548105, disc_loss = 0.15125880864208305
Trained batch 755 in epoch 0, gen_loss = 0.8538936765657531, disc_loss = 0.1510756806576398
Trained batch 756 in epoch 0, gen_loss = 0.853590448868007, disc_loss = 0.15102741689282215
Trained batch 757 in epoch 0, gen_loss = 0.8540052431475833, disc_loss = 0.1510295207405802
Trained batch 758 in epoch 0, gen_loss = 0.8537364938592094, disc_loss = 0.1509884602460171
Trained batch 759 in epoch 0, gen_loss = 0.8537164344207236, disc_loss = 0.15086128962789908
Trained batch 760 in epoch 0, gen_loss = 0.8536326239441133, disc_loss = 0.15074952226866442
Trained batch 761 in epoch 0, gen_loss = 0.8536061782614766, disc_loss = 0.15072092705398915
Trained batch 762 in epoch 0, gen_loss = 0.8533871668741244, disc_loss = 0.1506424963017767
Trained batch 763 in epoch 0, gen_loss = 0.853344007975456, disc_loss = 0.1505251551127422
Trained batch 764 in epoch 0, gen_loss = 0.8535918818969352, disc_loss = 0.1504418798825807
Trained batch 765 in epoch 0, gen_loss = 0.8534229177174306, disc_loss = 0.15037205405946694
Trained batch 766 in epoch 0, gen_loss = 0.8533340835897677, disc_loss = 0.15025177515552632
Trained batch 767 in epoch 0, gen_loss = 0.8531864101144796, disc_loss = 0.150234088467793
Trained batch 768 in epoch 0, gen_loss = 0.8529069003962726, disc_loss = 0.15041302124302355
Trained batch 769 in epoch 0, gen_loss = 0.8535350039794848, disc_loss = 0.1506737685544634
Trained batch 770 in epoch 0, gen_loss = 0.8533189425440614, disc_loss = 0.15060581791730435
Trained batch 771 in epoch 0, gen_loss = 0.8529081447677291, disc_loss = 0.15073712831338953
Trained batch 772 in epoch 0, gen_loss = 0.8530332620748419, disc_loss = 0.15088760449079963
Trained batch 773 in epoch 0, gen_loss = 0.8530741653932158, disc_loss = 0.15076091882317913
Trained batch 774 in epoch 0, gen_loss = 0.8527150045287225, disc_loss = 0.1508608965010893
Trained batch 775 in epoch 0, gen_loss = 0.8529091612963947, disc_loss = 0.15078540438829355
Trained batch 776 in epoch 0, gen_loss = 0.8526723375268271, disc_loss = 0.15077408051844615
Trained batch 777 in epoch 0, gen_loss = 0.8523286328600734, disc_loss = 0.15081398699140525
Trained batch 778 in epoch 0, gen_loss = 0.8520901902113708, disc_loss = 0.1507661788950319
Trained batch 779 in epoch 0, gen_loss = 0.8519727293879558, disc_loss = 0.15068179104023446
Trained batch 780 in epoch 0, gen_loss = 0.8517462457416916, disc_loss = 0.15064518788660114
Trained batch 781 in epoch 0, gen_loss = 0.8514475469927654, disc_loss = 0.15061337429949123
Trained batch 782 in epoch 0, gen_loss = 0.8513956824710086, disc_loss = 0.1505567890438483
Trained batch 783 in epoch 0, gen_loss = 0.8512864398332883, disc_loss = 0.1504112834179755
Trained batch 784 in epoch 0, gen_loss = 0.8508872725781361, disc_loss = 0.15038401453287167
Trained batch 785 in epoch 0, gen_loss = 0.8508374087000621, disc_loss = 0.15027230670059494
Trained batch 786 in epoch 0, gen_loss = 0.8511691050653688, disc_loss = 0.15020489298029693
Trained batch 787 in epoch 0, gen_loss = 0.8508222791068445, disc_loss = 0.15029431479689925
Trained batch 788 in epoch 0, gen_loss = 0.851071626476764, disc_loss = 0.15029730064338792
Trained batch 789 in epoch 0, gen_loss = 0.851217040042334, disc_loss = 0.15014896973425262
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.5415632724761963, disc_loss = 0.29531392455101013
Trained batch 1 in epoch 1, gen_loss = 0.6968545317649841, disc_loss = 0.22561965882778168
Trained batch 2 in epoch 1, gen_loss = 0.7152132987976074, disc_loss = 0.17947150518496832
Trained batch 3 in epoch 1, gen_loss = 0.7209569364786148, disc_loss = 0.15997128002345562
Trained batch 4 in epoch 1, gen_loss = 0.7304159760475158, disc_loss = 0.14455391317605973
Trained batch 5 in epoch 1, gen_loss = 0.780021478732427, disc_loss = 0.12924464916189513
Trained batch 6 in epoch 1, gen_loss = 0.7483773486954826, disc_loss = 0.13017655802624567
Trained batch 7 in epoch 1, gen_loss = 0.7578176856040955, disc_loss = 0.12013620929792523
Trained batch 8 in epoch 1, gen_loss = 0.7956823507944742, disc_loss = 0.11403143033385277
Trained batch 9 in epoch 1, gen_loss = 0.7778212308883667, disc_loss = 0.12184231542050838
Trained batch 10 in epoch 1, gen_loss = 0.7949327447197654, disc_loss = 0.11907012659040364
Trained batch 11 in epoch 1, gen_loss = 0.800802876551946, disc_loss = 0.11328805952022473
Trained batch 12 in epoch 1, gen_loss = 0.8006542645967923, disc_loss = 0.10974998055742337
Trained batch 13 in epoch 1, gen_loss = 0.7964589595794678, disc_loss = 0.10786804370582104
Trained batch 14 in epoch 1, gen_loss = 0.7923170844713847, disc_loss = 0.11103144610921542
Trained batch 15 in epoch 1, gen_loss = 0.8127465508878231, disc_loss = 0.1146514464635402
Trained batch 16 in epoch 1, gen_loss = 0.8136446265613332, disc_loss = 0.11107984908363398
Trained batch 17 in epoch 1, gen_loss = 0.8073380059666104, disc_loss = 0.1101896342717939
Trained batch 18 in epoch 1, gen_loss = 0.813789891569238, disc_loss = 0.11494434997439384
Trained batch 19 in epoch 1, gen_loss = 0.7998824447393418, disc_loss = 0.11956815663725137
Trained batch 20 in epoch 1, gen_loss = 0.7925395255997068, disc_loss = 0.11940615677407809
Trained batch 21 in epoch 1, gen_loss = 0.8016680397770621, disc_loss = 0.120268747379834
Trained batch 22 in epoch 1, gen_loss = 0.8007857955020407, disc_loss = 0.11864121274455734
Trained batch 23 in epoch 1, gen_loss = 0.7957376763224602, disc_loss = 0.12455552521472175
Trained batch 24 in epoch 1, gen_loss = 0.8055928206443786, disc_loss = 0.12244317546486855
Trained batch 25 in epoch 1, gen_loss = 0.8273375836702493, disc_loss = 0.12378921202169015
Trained batch 26 in epoch 1, gen_loss = 0.8252616922060648, disc_loss = 0.12111729700808171
Trained batch 27 in epoch 1, gen_loss = 0.8220140231507165, disc_loss = 0.12417633605322667
Trained batch 28 in epoch 1, gen_loss = 0.8308078564446548, disc_loss = 0.12227182437119813
Trained batch 29 in epoch 1, gen_loss = 0.8306641141573589, disc_loss = 0.12285946595172087
Trained batch 30 in epoch 1, gen_loss = 0.829593708438258, disc_loss = 0.12070390497965197
Trained batch 31 in epoch 1, gen_loss = 0.8260794170200825, disc_loss = 0.12258830259088427
Trained batch 32 in epoch 1, gen_loss = 0.8259182265310576, disc_loss = 0.12152568397648407
Trained batch 33 in epoch 1, gen_loss = 0.8307111526236814, disc_loss = 0.1190491372390705
Trained batch 34 in epoch 1, gen_loss = 0.8226511001586914, disc_loss = 0.12103262511747225
Trained batch 35 in epoch 1, gen_loss = 0.8246266378296746, disc_loss = 0.1190772174547116
Trained batch 36 in epoch 1, gen_loss = 0.8389760545782141, disc_loss = 0.12111278220608428
Trained batch 37 in epoch 1, gen_loss = 0.8449294127916035, disc_loss = 0.11823197797332939
Trained batch 38 in epoch 1, gen_loss = 0.8360152091735449, disc_loss = 0.11962265301591311
Trained batch 39 in epoch 1, gen_loss = 0.8314404532313346, disc_loss = 0.11862169830128551
Trained batch 40 in epoch 1, gen_loss = 0.8397392049068357, disc_loss = 0.12012194633120443
Trained batch 41 in epoch 1, gen_loss = 0.8357545662493933, disc_loss = 0.12092407322710469
Trained batch 42 in epoch 1, gen_loss = 0.8310336692388668, disc_loss = 0.12131892447901327
Trained batch 43 in epoch 1, gen_loss = 0.8321602290326898, disc_loss = 0.12218982480805028
Trained batch 44 in epoch 1, gen_loss = 0.8324408319261339, disc_loss = 0.12168822925951746
Trained batch 45 in epoch 1, gen_loss = 0.8323972004911174, disc_loss = 0.12150469268469707
Trained batch 46 in epoch 1, gen_loss = 0.8301212445218512, disc_loss = 0.12073651566467386
Trained batch 47 in epoch 1, gen_loss = 0.8279882334172726, disc_loss = 0.11996894772164524
Trained batch 48 in epoch 1, gen_loss = 0.8265086120488693, disc_loss = 0.1202542740015351
Trained batch 49 in epoch 1, gen_loss = 0.8299990010261535, disc_loss = 0.12623671241104603
Trained batch 50 in epoch 1, gen_loss = 0.8284662961959839, disc_loss = 0.12446882904452436
Trained batch 51 in epoch 1, gen_loss = 0.8236792970162171, disc_loss = 0.12658901849331763
Trained batch 52 in epoch 1, gen_loss = 0.8220632717294513, disc_loss = 0.12763411193242613
Trained batch 53 in epoch 1, gen_loss = 0.8239051015288742, disc_loss = 0.12957048381644268
Trained batch 54 in epoch 1, gen_loss = 0.8206528273495761, disc_loss = 0.1302375803616914
Trained batch 55 in epoch 1, gen_loss = 0.8180047667452267, disc_loss = 0.1302169241410281
Trained batch 56 in epoch 1, gen_loss = 0.8161146138843737, disc_loss = 0.13051724322793776
Trained batch 57 in epoch 1, gen_loss = 0.8151112866812739, disc_loss = 0.13094834360326157
Trained batch 58 in epoch 1, gen_loss = 0.8129771372019234, disc_loss = 0.13082396245356334
Trained batch 59 in epoch 1, gen_loss = 0.8113648076852162, disc_loss = 0.13052909256269535
Trained batch 60 in epoch 1, gen_loss = 0.8087624164878345, disc_loss = 0.13106625374467645
Trained batch 61 in epoch 1, gen_loss = 0.8117102336498999, disc_loss = 0.13155963854683983
Trained batch 62 in epoch 1, gen_loss = 0.8076687114579337, disc_loss = 0.13205869288908112
Trained batch 63 in epoch 1, gen_loss = 0.8043229999020696, disc_loss = 0.13247228047112003
Trained batch 64 in epoch 1, gen_loss = 0.8038790721159715, disc_loss = 0.132074108089392
Trained batch 65 in epoch 1, gen_loss = 0.803652188091567, disc_loss = 0.13248723457482728
Trained batch 66 in epoch 1, gen_loss = 0.8032813641562391, disc_loss = 0.1309315734334401
Trained batch 67 in epoch 1, gen_loss = 0.7995596922495786, disc_loss = 0.1324091681607944
Trained batch 68 in epoch 1, gen_loss = 0.8013088400813116, disc_loss = 0.13251585640229177
Trained batch 69 in epoch 1, gen_loss = 0.800419465984617, disc_loss = 0.1324759124379073
Trained batch 70 in epoch 1, gen_loss = 0.7970309022446753, disc_loss = 0.13282534928703812
Trained batch 71 in epoch 1, gen_loss = 0.7989947150150934, disc_loss = 0.13275246661052936
Trained batch 72 in epoch 1, gen_loss = 0.8006754550215316, disc_loss = 0.1326527698348238
Trained batch 73 in epoch 1, gen_loss = 0.8007856696038633, disc_loss = 0.1314914125596752
Trained batch 74 in epoch 1, gen_loss = 0.8006846880912781, disc_loss = 0.13039062110086283
Trained batch 75 in epoch 1, gen_loss = 0.798549841109075, disc_loss = 0.13010266793303585
Trained batch 76 in epoch 1, gen_loss = 0.7977768283385736, disc_loss = 0.13036794261402124
Trained batch 77 in epoch 1, gen_loss = 0.7960377389039749, disc_loss = 0.13013314816336602
Trained batch 78 in epoch 1, gen_loss = 0.7931341528892517, disc_loss = 0.1305162076472859
Trained batch 79 in epoch 1, gen_loss = 0.7957314141094685, disc_loss = 0.1296211129752919
Trained batch 80 in epoch 1, gen_loss = 0.7990803254975213, disc_loss = 0.12901956521342567
Trained batch 81 in epoch 1, gen_loss = 0.8029698576869034, disc_loss = 0.12764005076776191
Trained batch 82 in epoch 1, gen_loss = 0.7999121819634035, disc_loss = 0.12907233318111982
Trained batch 83 in epoch 1, gen_loss = 0.8028177966674169, disc_loss = 0.13079642916896514
Trained batch 84 in epoch 1, gen_loss = 0.8045132819344015, disc_loss = 0.12954611988628612
Trained batch 85 in epoch 1, gen_loss = 0.8027155981507412, disc_loss = 0.12952662345974944
Trained batch 86 in epoch 1, gen_loss = 0.8028262031489405, disc_loss = 0.12902574943399978
Trained batch 87 in epoch 1, gen_loss = 0.8011145137927749, disc_loss = 0.12886872853745113
Trained batch 88 in epoch 1, gen_loss = 0.8010984143514311, disc_loss = 0.1299559043699436
Trained batch 89 in epoch 1, gen_loss = 0.7986149516370561, disc_loss = 0.1312965682811207
Trained batch 90 in epoch 1, gen_loss = 0.7973054372347318, disc_loss = 0.13158373960426875
Trained batch 91 in epoch 1, gen_loss = 0.7995863699394724, disc_loss = 0.1321934289906336
Trained batch 92 in epoch 1, gen_loss = 0.7981356138824135, disc_loss = 0.13207615871903716
Trained batch 93 in epoch 1, gen_loss = 0.7948914417561065, disc_loss = 0.1333431897169732
Trained batch 94 in epoch 1, gen_loss = 0.7943407786519904, disc_loss = 0.1327986430964972
Trained batch 95 in epoch 1, gen_loss = 0.7970518209040165, disc_loss = 0.13296107101875046
Trained batch 96 in epoch 1, gen_loss = 0.7957115412987384, disc_loss = 0.13273446891725676
Trained batch 97 in epoch 1, gen_loss = 0.7942060037535064, disc_loss = 0.13312506903799212
Trained batch 98 in epoch 1, gen_loss = 0.794933314877327, disc_loss = 0.1329019684532676
Trained batch 99 in epoch 1, gen_loss = 0.7950713759660721, disc_loss = 0.13239653386175632
Trained batch 100 in epoch 1, gen_loss = 0.7942729002178306, disc_loss = 0.13203246441513006
Trained batch 101 in epoch 1, gen_loss = 0.7946822152418249, disc_loss = 0.131308049949653
Trained batch 102 in epoch 1, gen_loss = 0.7967518961545333, disc_loss = 0.1309528796779878
Trained batch 103 in epoch 1, gen_loss = 0.7997813052856005, disc_loss = 0.13017471231376895
Trained batch 104 in epoch 1, gen_loss = 0.7992856678508576, disc_loss = 0.12963571445572944
Trained batch 105 in epoch 1, gen_loss = 0.7958659799593799, disc_loss = 0.1314776661753092
Trained batch 106 in epoch 1, gen_loss = 0.7983389613784362, disc_loss = 0.13121984303693904
Trained batch 107 in epoch 1, gen_loss = 0.8007656887725547, disc_loss = 0.13165684972234346
Trained batch 108 in epoch 1, gen_loss = 0.7983630305036492, disc_loss = 0.1322282104658971
Trained batch 109 in epoch 1, gen_loss = 0.7972537593408064, disc_loss = 0.1326880708675493
Trained batch 110 in epoch 1, gen_loss = 0.7969754408071706, disc_loss = 0.1328010264079313
Trained batch 111 in epoch 1, gen_loss = 0.7966151631304196, disc_loss = 0.13269777107052505
Trained batch 112 in epoch 1, gen_loss = 0.7959751629196437, disc_loss = 0.13229715405444128
Trained batch 113 in epoch 1, gen_loss = 0.7961990153580382, disc_loss = 0.1315827893518042
Trained batch 114 in epoch 1, gen_loss = 0.7950075781863669, disc_loss = 0.13133792828606522
Trained batch 115 in epoch 1, gen_loss = 0.7940512484517591, disc_loss = 0.13125328491602478
Trained batch 116 in epoch 1, gen_loss = 0.7958748299851377, disc_loss = 0.13216776359412405
Trained batch 117 in epoch 1, gen_loss = 0.7961851080595437, disc_loss = 0.13154211754010894
Trained batch 118 in epoch 1, gen_loss = 0.7966542890091904, disc_loss = 0.13106598598616465
Trained batch 119 in epoch 1, gen_loss = 0.7965693215529124, disc_loss = 0.1310900405049324
Trained batch 120 in epoch 1, gen_loss = 0.7965671425023355, disc_loss = 0.13065829983920105
Trained batch 121 in epoch 1, gen_loss = 0.7953111666147826, disc_loss = 0.13080194079485097
Trained batch 122 in epoch 1, gen_loss = 0.7952486286318399, disc_loss = 0.13060624328086046
Trained batch 123 in epoch 1, gen_loss = 0.7937322903063989, disc_loss = 0.130547488048192
Trained batch 124 in epoch 1, gen_loss = 0.7937437958717346, disc_loss = 0.13055533516407014
Trained batch 125 in epoch 1, gen_loss = 0.795496623194407, disc_loss = 0.13264151047619563
Trained batch 126 in epoch 1, gen_loss = 0.7926061756498232, disc_loss = 0.1336573138246386
Trained batch 127 in epoch 1, gen_loss = 0.7920588541310281, disc_loss = 0.13425434555392712
Trained batch 128 in epoch 1, gen_loss = 0.7917999322562255, disc_loss = 0.13473462376945702
Trained batch 129 in epoch 1, gen_loss = 0.7916956747953708, disc_loss = 0.13511153493936245
Trained batch 130 in epoch 1, gen_loss = 0.7912076431831331, disc_loss = 0.13547387446155984
Trained batch 131 in epoch 1, gen_loss = 0.7908794859593565, disc_loss = 0.13551535604126524
Trained batch 132 in epoch 1, gen_loss = 0.7898583436818948, disc_loss = 0.13549409425796421
Trained batch 133 in epoch 1, gen_loss = 0.7911026106396718, disc_loss = 0.13566912165773448
Trained batch 134 in epoch 1, gen_loss = 0.7899929481524008, disc_loss = 0.13593321608172523
Trained batch 135 in epoch 1, gen_loss = 0.7893863892292275, disc_loss = 0.13577047954587376
Trained batch 136 in epoch 1, gen_loss = 0.789116667787524, disc_loss = 0.13601557116438873
Trained batch 137 in epoch 1, gen_loss = 0.788557245031647, disc_loss = 0.13564900060494742
Trained batch 138 in epoch 1, gen_loss = 0.787633750721705, disc_loss = 0.13578009937735772
Trained batch 139 in epoch 1, gen_loss = 0.7884521580168179, disc_loss = 0.13622082737939697
Trained batch 140 in epoch 1, gen_loss = 0.7874826148469397, disc_loss = 0.13622325870162205
Trained batch 141 in epoch 1, gen_loss = 0.7867410214434207, disc_loss = 0.136054804417449
Trained batch 142 in epoch 1, gen_loss = 0.7860631819788393, disc_loss = 0.13616059543369533
Trained batch 143 in epoch 1, gen_loss = 0.7865809022138516, disc_loss = 0.1361254836536116
Trained batch 144 in epoch 1, gen_loss = 0.7868061528123659, disc_loss = 0.13558177524085702
Trained batch 145 in epoch 1, gen_loss = 0.7862383545669791, disc_loss = 0.1357119253594173
Trained batch 146 in epoch 1, gen_loss = 0.7861139139756054, disc_loss = 0.13573605133866778
Trained batch 147 in epoch 1, gen_loss = 0.7857048356452504, disc_loss = 0.1356707759755286
Trained batch 148 in epoch 1, gen_loss = 0.7860717567421446, disc_loss = 0.13506578176513614
Trained batch 149 in epoch 1, gen_loss = 0.7849206668138504, disc_loss = 0.13526072291036448
Trained batch 150 in epoch 1, gen_loss = 0.785616169504772, disc_loss = 0.1349096109486179
Trained batch 151 in epoch 1, gen_loss = 0.7861764068274122, disc_loss = 0.13492578785180262
Trained batch 152 in epoch 1, gen_loss = 0.7861069664846059, disc_loss = 0.13485031665053243
Trained batch 153 in epoch 1, gen_loss = 0.7860640726693264, disc_loss = 0.1347822659927142
Trained batch 154 in epoch 1, gen_loss = 0.7858452556594726, disc_loss = 0.13447361509165456
Trained batch 155 in epoch 1, gen_loss = 0.7863825240578407, disc_loss = 0.13422602350608662
Trained batch 156 in epoch 1, gen_loss = 0.7855837677314783, disc_loss = 0.1344716948735866
Trained batch 157 in epoch 1, gen_loss = 0.7871989394667782, disc_loss = 0.13446866798721538
Trained batch 158 in epoch 1, gen_loss = 0.7874389120242881, disc_loss = 0.13388920708928467
Trained batch 159 in epoch 1, gen_loss = 0.7864431222900748, disc_loss = 0.13428349138703197
Trained batch 160 in epoch 1, gen_loss = 0.7876246728882286, disc_loss = 0.1341851727331277
Trained batch 161 in epoch 1, gen_loss = 0.7894737932049198, disc_loss = 0.13389621396767504
Trained batch 162 in epoch 1, gen_loss = 0.7878152064384858, disc_loss = 0.13442167052370638
Trained batch 163 in epoch 1, gen_loss = 0.7872487319315352, disc_loss = 0.13411117324651015
Trained batch 164 in epoch 1, gen_loss = 0.7870425641536712, disc_loss = 0.13415188985792073
Trained batch 165 in epoch 1, gen_loss = 0.7862676089427557, disc_loss = 0.13415305673268185
Trained batch 166 in epoch 1, gen_loss = 0.7862129188226369, disc_loss = 0.13409624063593897
Trained batch 167 in epoch 1, gen_loss = 0.7863366307602042, disc_loss = 0.13370762035871545
Trained batch 168 in epoch 1, gen_loss = 0.7865735463489442, disc_loss = 0.13333696953555535
Trained batch 169 in epoch 1, gen_loss = 0.7866476243033128, disc_loss = 0.13288494377013516
Trained batch 170 in epoch 1, gen_loss = 0.7864364317634649, disc_loss = 0.13243461803298945
Trained batch 171 in epoch 1, gen_loss = 0.7850499529131624, disc_loss = 0.1326873792595295
Trained batch 172 in epoch 1, gen_loss = 0.7850647663449966, disc_loss = 0.13237617072256314
Trained batch 173 in epoch 1, gen_loss = 0.7862603909325325, disc_loss = 0.13206128315764598
Trained batch 174 in epoch 1, gen_loss = 0.7859513815811702, disc_loss = 0.13195542401501112
Trained batch 175 in epoch 1, gen_loss = 0.78566406480968, disc_loss = 0.131677697730166
Trained batch 176 in epoch 1, gen_loss = 0.7858014650600779, disc_loss = 0.13152994806904578
Trained batch 177 in epoch 1, gen_loss = 0.7856734838713421, disc_loss = 0.1313879970209987
Trained batch 178 in epoch 1, gen_loss = 0.7862828918342484, disc_loss = 0.13127984974387638
Trained batch 179 in epoch 1, gen_loss = 0.786050423151917, disc_loss = 0.1311873491646515
Trained batch 180 in epoch 1, gen_loss = 0.7874303912918871, disc_loss = 0.1307323345122087
Trained batch 181 in epoch 1, gen_loss = 0.786550644498605, disc_loss = 0.13085987965402368
Trained batch 182 in epoch 1, gen_loss = 0.7880395900030606, disc_loss = 0.13097813438440933
Trained batch 183 in epoch 1, gen_loss = 0.788579236716032, disc_loss = 0.1304261962700959
Trained batch 184 in epoch 1, gen_loss = 0.7877951372314144, disc_loss = 0.1303685918953773
Trained batch 185 in epoch 1, gen_loss = 0.7890271622967976, disc_loss = 0.13075375614026863
Trained batch 186 in epoch 1, gen_loss = 0.7878845574702809, disc_loss = 0.13122572810613217
Trained batch 187 in epoch 1, gen_loss = 0.788808489257985, disc_loss = 0.1310115800675084
Trained batch 188 in epoch 1, gen_loss = 0.7896404914439671, disc_loss = 0.13162438123038522
Trained batch 189 in epoch 1, gen_loss = 0.7884148144408276, disc_loss = 0.13247226665874845
Trained batch 190 in epoch 1, gen_loss = 0.7882170800451209, disc_loss = 0.1325039770844251
Trained batch 191 in epoch 1, gen_loss = 0.7891805958934128, disc_loss = 0.13268615554746552
Trained batch 192 in epoch 1, gen_loss = 0.788537705654925, disc_loss = 0.1326464037917593
Trained batch 193 in epoch 1, gen_loss = 0.7880539723585561, disc_loss = 0.1326622067441799
Trained batch 194 in epoch 1, gen_loss = 0.7877563768472426, disc_loss = 0.1323704697478276
Trained batch 195 in epoch 1, gen_loss = 0.7883200878087355, disc_loss = 0.13206677265199168
Trained batch 196 in epoch 1, gen_loss = 0.7883836341085773, disc_loss = 0.13183189324353856
Trained batch 197 in epoch 1, gen_loss = 0.7878904211701769, disc_loss = 0.1316708285417972
Trained batch 198 in epoch 1, gen_loss = 0.7879620180956682, disc_loss = 0.13167989348534065
Trained batch 199 in epoch 1, gen_loss = 0.7868796266615391, disc_loss = 0.13169416253454982
Trained batch 200 in epoch 1, gen_loss = 0.7876861882743551, disc_loss = 0.13144924144135484
Trained batch 201 in epoch 1, gen_loss = 0.7883355636702906, disc_loss = 0.1309878262829515
Trained batch 202 in epoch 1, gen_loss = 0.7898080649927919, disc_loss = 0.13049646236663087
Trained batch 203 in epoch 1, gen_loss = 0.7897043664957962, disc_loss = 0.130059889837296
Trained batch 204 in epoch 1, gen_loss = 0.7908617588078103, disc_loss = 0.12949888380017222
Trained batch 205 in epoch 1, gen_loss = 0.7907889501273053, disc_loss = 0.12903700513059943
Trained batch 206 in epoch 1, gen_loss = 0.78986521029242, disc_loss = 0.12905893050998019
Trained batch 207 in epoch 1, gen_loss = 0.7920105633540795, disc_loss = 0.12963268480514392
Trained batch 208 in epoch 1, gen_loss = 0.7910778646548969, disc_loss = 0.1294330157892128
Trained batch 209 in epoch 1, gen_loss = 0.7901939629089265, disc_loss = 0.12968002072579804
Trained batch 210 in epoch 1, gen_loss = 0.7915828746359496, disc_loss = 0.12993261971073974
Trained batch 211 in epoch 1, gen_loss = 0.7919843032393815, disc_loss = 0.1298205424890906
Trained batch 212 in epoch 1, gen_loss = 0.7924023487478354, disc_loss = 0.12938051314875834
Trained batch 213 in epoch 1, gen_loss = 0.7920858276503109, disc_loss = 0.12897656601200871
Trained batch 214 in epoch 1, gen_loss = 0.7922992427681768, disc_loss = 0.12862838096916676
Trained batch 215 in epoch 1, gen_loss = 0.7935430108121148, disc_loss = 0.12845005735720474
Trained batch 216 in epoch 1, gen_loss = 0.7930656703111763, disc_loss = 0.12856339295029914
Trained batch 217 in epoch 1, gen_loss = 0.7933528744572893, disc_loss = 0.12868099857053353
Trained batch 218 in epoch 1, gen_loss = 0.794380133418732, disc_loss = 0.1281843839732071
Trained batch 219 in epoch 1, gen_loss = 0.793685865808617, disc_loss = 0.12817736617712813
Trained batch 220 in epoch 1, gen_loss = 0.7941976368966686, disc_loss = 0.12813318251922928
Trained batch 221 in epoch 1, gen_loss = 0.7942998289793461, disc_loss = 0.1278168864229375
Trained batch 222 in epoch 1, gen_loss = 0.7930150797816136, disc_loss = 0.12788270932576315
Trained batch 223 in epoch 1, gen_loss = 0.7923051000439695, disc_loss = 0.12787121152671585
Trained batch 224 in epoch 1, gen_loss = 0.7919636476039886, disc_loss = 0.12786038296918073
Trained batch 225 in epoch 1, gen_loss = 0.7916022226610014, disc_loss = 0.12785910311427
Trained batch 226 in epoch 1, gen_loss = 0.7916425528242724, disc_loss = 0.12775818672900946
Trained batch 227 in epoch 1, gen_loss = 0.7915409624315145, disc_loss = 0.12770705112141736
Trained batch 228 in epoch 1, gen_loss = 0.790767012334807, disc_loss = 0.12750502962895616
Trained batch 229 in epoch 1, gen_loss = 0.7903877604266871, disc_loss = 0.127318189981515
Trained batch 230 in epoch 1, gen_loss = 0.78954876359407, disc_loss = 0.12726792374633866
Trained batch 231 in epoch 1, gen_loss = 0.7901159197348973, disc_loss = 0.1272828430338795
Trained batch 232 in epoch 1, gen_loss = 0.7903531565942478, disc_loss = 0.1271392174240985
Trained batch 233 in epoch 1, gen_loss = 0.7900170776833836, disc_loss = 0.12713333589430803
Trained batch 234 in epoch 1, gen_loss = 0.7909609638630075, disc_loss = 0.12687433705209417
Trained batch 235 in epoch 1, gen_loss = 0.7918739219085645, disc_loss = 0.1267299433080953
Trained batch 236 in epoch 1, gen_loss = 0.7924730006904038, disc_loss = 0.12660231438901606
Trained batch 237 in epoch 1, gen_loss = 0.7925747183441114, disc_loss = 0.1266085893745307
Trained batch 238 in epoch 1, gen_loss = 0.7929401221883846, disc_loss = 0.12650805082811223
Trained batch 239 in epoch 1, gen_loss = 0.7928746204823256, disc_loss = 0.1263495979908233
Trained batch 240 in epoch 1, gen_loss = 0.7929461198970985, disc_loss = 0.12599864027837748
Trained batch 241 in epoch 1, gen_loss = 0.7934841847370478, disc_loss = 0.12560388933836428
Trained batch 242 in epoch 1, gen_loss = 0.7928891131662047, disc_loss = 0.1255817517730189
Trained batch 243 in epoch 1, gen_loss = 0.7923491146476542, disc_loss = 0.12579264468895118
Trained batch 244 in epoch 1, gen_loss = 0.7927325848413973, disc_loss = 0.12617368590162725
Trained batch 245 in epoch 1, gen_loss = 0.7925236834500863, disc_loss = 0.1263523884571907
Trained batch 246 in epoch 1, gen_loss = 0.7916205348032206, disc_loss = 0.12654794012064394
Trained batch 247 in epoch 1, gen_loss = 0.7937421614844953, disc_loss = 0.1266652830095301
Trained batch 248 in epoch 1, gen_loss = 0.7944862185472465, disc_loss = 0.12632233468464102
Trained batch 249 in epoch 1, gen_loss = 0.793847905755043, disc_loss = 0.12629765652120115
Trained batch 250 in epoch 1, gen_loss = 0.7943702673769567, disc_loss = 0.1262051778812095
Trained batch 251 in epoch 1, gen_loss = 0.7938676477661208, disc_loss = 0.12608867385498587
Trained batch 252 in epoch 1, gen_loss = 0.794868898132573, disc_loss = 0.12625793681255443
Trained batch 253 in epoch 1, gen_loss = 0.7955981475396419, disc_loss = 0.12586066867481535
Trained batch 254 in epoch 1, gen_loss = 0.7946175796144149, disc_loss = 0.1262865113423151
Trained batch 255 in epoch 1, gen_loss = 0.7947058513527736, disc_loss = 0.12628098153800238
Trained batch 256 in epoch 1, gen_loss = 0.7951058876421665, disc_loss = 0.12654805115282766
Trained batch 257 in epoch 1, gen_loss = 0.7943298623774403, disc_loss = 0.1266787475653628
Trained batch 258 in epoch 1, gen_loss = 0.7939211179620971, disc_loss = 0.12667857802339963
Trained batch 259 in epoch 1, gen_loss = 0.7951945212024909, disc_loss = 0.12719966455434378
Trained batch 260 in epoch 1, gen_loss = 0.7948566089416372, disc_loss = 0.1271481637154274
Trained batch 261 in epoch 1, gen_loss = 0.7941109598365449, disc_loss = 0.12746183942463107
Trained batch 262 in epoch 1, gen_loss = 0.794230859882478, disc_loss = 0.12776340168861836
Trained batch 263 in epoch 1, gen_loss = 0.7951398373327472, disc_loss = 0.12785726219810772
Trained batch 264 in epoch 1, gen_loss = 0.794463811393054, disc_loss = 0.12843207490612876
Trained batch 265 in epoch 1, gen_loss = 0.7941764464279762, disc_loss = 0.12833374723287902
Trained batch 266 in epoch 1, gen_loss = 0.7946242976947671, disc_loss = 0.12858932196033582
Trained batch 267 in epoch 1, gen_loss = 0.7941431233019971, disc_loss = 0.1285988379464443
Trained batch 268 in epoch 1, gen_loss = 0.7932767609902918, disc_loss = 0.12871182420495275
Trained batch 269 in epoch 1, gen_loss = 0.7934877774229756, disc_loss = 0.12862336399654548
Trained batch 270 in epoch 1, gen_loss = 0.7937226056832669, disc_loss = 0.1286325207962981
Trained batch 271 in epoch 1, gen_loss = 0.7935824469827554, disc_loss = 0.1286314141470939
Trained batch 272 in epoch 1, gen_loss = 0.7932060274667355, disc_loss = 0.12866518437698649
Trained batch 273 in epoch 1, gen_loss = 0.7925338624385152, disc_loss = 0.12892125967047074
Trained batch 274 in epoch 1, gen_loss = 0.7927728788419204, disc_loss = 0.1290537053482099
Trained batch 275 in epoch 1, gen_loss = 0.7922388264450474, disc_loss = 0.12900261369034433
Trained batch 276 in epoch 1, gen_loss = 0.7921307645334664, disc_loss = 0.1288081228813755
Trained batch 277 in epoch 1, gen_loss = 0.791478027006705, disc_loss = 0.12890860892617875
Trained batch 278 in epoch 1, gen_loss = 0.7912931118601112, disc_loss = 0.12908997751211607
Trained batch 279 in epoch 1, gen_loss = 0.7904602060360568, disc_loss = 0.12923817399090953
Trained batch 280 in epoch 1, gen_loss = 0.7902702652050507, disc_loss = 0.12919558808737802
Trained batch 281 in epoch 1, gen_loss = 0.7904325963546198, disc_loss = 0.12907574374677863
Trained batch 282 in epoch 1, gen_loss = 0.7912405349129923, disc_loss = 0.12877479481244256
Trained batch 283 in epoch 1, gen_loss = 0.7903945251879557, disc_loss = 0.12894561095819088
Trained batch 284 in epoch 1, gen_loss = 0.7902163763840994, disc_loss = 0.12890476972648973
Trained batch 285 in epoch 1, gen_loss = 0.7895938648835762, disc_loss = 0.128903143902446
Trained batch 286 in epoch 1, gen_loss = 0.7894209564147511, disc_loss = 0.1287881641775266
Trained batch 287 in epoch 1, gen_loss = 0.7888094119520651, disc_loss = 0.12885399045060492
Trained batch 288 in epoch 1, gen_loss = 0.7886261908034552, disc_loss = 0.12879438230374693
Trained batch 289 in epoch 1, gen_loss = 0.7888697392981628, disc_loss = 0.1287497547294559
Trained batch 290 in epoch 1, gen_loss = 0.7887525209241716, disc_loss = 0.12880691713125436
Trained batch 291 in epoch 1, gen_loss = 0.7884112864936867, disc_loss = 0.12875936054050513
Trained batch 292 in epoch 1, gen_loss = 0.7898097517343918, disc_loss = 0.1290457975055781
Trained batch 293 in epoch 1, gen_loss = 0.7895796516922866, disc_loss = 0.12880257095153236
Trained batch 294 in epoch 1, gen_loss = 0.7891207156545025, disc_loss = 0.1289752086719214
Trained batch 295 in epoch 1, gen_loss = 0.789918025502482, disc_loss = 0.12900555510124243
Trained batch 296 in epoch 1, gen_loss = 0.7897668182849884, disc_loss = 0.12877055672734272
Trained batch 297 in epoch 1, gen_loss = 0.7895553231039303, disc_loss = 0.1285648620593668
Trained batch 298 in epoch 1, gen_loss = 0.789359819031878, disc_loss = 0.1285468642802342
Trained batch 299 in epoch 1, gen_loss = 0.7895846592386564, disc_loss = 0.1282815187300245
Trained batch 300 in epoch 1, gen_loss = 0.7891502585323942, disc_loss = 0.12817634856235546
Trained batch 301 in epoch 1, gen_loss = 0.7898033678729013, disc_loss = 0.12782956340307036
Trained batch 302 in epoch 1, gen_loss = 0.7920911767498495, disc_loss = 0.12828052423820638
Trained batch 303 in epoch 1, gen_loss = 0.7925636324247247, disc_loss = 0.1279160822067704
Trained batch 304 in epoch 1, gen_loss = 0.7921516526917942, disc_loss = 0.12780367974497256
Trained batch 305 in epoch 1, gen_loss = 0.7921054196708343, disc_loss = 0.12745089939144116
Trained batch 306 in epoch 1, gen_loss = 0.7923129999870586, disc_loss = 0.12712063707702517
Trained batch 307 in epoch 1, gen_loss = 0.7925679922684447, disc_loss = 0.12683716496791353
Trained batch 308 in epoch 1, gen_loss = 0.7930931700664816, disc_loss = 0.12653148796976
Trained batch 309 in epoch 1, gen_loss = 0.7935707721979387, disc_loss = 0.1261868875533823
Trained batch 310 in epoch 1, gen_loss = 0.7936925798942038, disc_loss = 0.12589621485788915
Trained batch 311 in epoch 1, gen_loss = 0.794275274930092, disc_loss = 0.12554512803968138
Trained batch 312 in epoch 1, gen_loss = 0.7942446888254854, disc_loss = 0.12523598051942386
Trained batch 313 in epoch 1, gen_loss = 0.7958864287775793, disc_loss = 0.12496990677870952
Trained batch 314 in epoch 1, gen_loss = 0.7963376659249503, disc_loss = 0.12463330074198663
Trained batch 315 in epoch 1, gen_loss = 0.7975804071071781, disc_loss = 0.12443815826002179
Trained batch 316 in epoch 1, gen_loss = 0.7972995985757665, disc_loss = 0.12462198122019648
Trained batch 317 in epoch 1, gen_loss = 0.7981096895048453, disc_loss = 0.1243197455088485
Trained batch 318 in epoch 1, gen_loss = 0.7991401378450722, disc_loss = 0.12408298187448313
Trained batch 319 in epoch 1, gen_loss = 0.7996253448538482, disc_loss = 0.12373057470540516
Trained batch 320 in epoch 1, gen_loss = 0.7989613958794008, disc_loss = 0.1239833712194846
Trained batch 321 in epoch 1, gen_loss = 0.7998936069863183, disc_loss = 0.124045226763448
Trained batch 322 in epoch 1, gen_loss = 0.8001044851153997, disc_loss = 0.12395645026982569
Trained batch 323 in epoch 1, gen_loss = 0.799978026913272, disc_loss = 0.12377901450604384
Trained batch 324 in epoch 1, gen_loss = 0.7996863279892849, disc_loss = 0.12364975380782897
Trained batch 325 in epoch 1, gen_loss = 0.7994912607721024, disc_loss = 0.12355102305557647
Trained batch 326 in epoch 1, gen_loss = 0.8003227529358062, disc_loss = 0.1234709963783485
Trained batch 327 in epoch 1, gen_loss = 0.7993402947194692, disc_loss = 0.12383025849987639
Trained batch 328 in epoch 1, gen_loss = 0.799615168191017, disc_loss = 0.12379023547660797
Trained batch 329 in epoch 1, gen_loss = 0.8000701583696134, disc_loss = 0.12382763373016407
Trained batch 330 in epoch 1, gen_loss = 0.7999168354398895, disc_loss = 0.12359422019308608
Trained batch 331 in epoch 1, gen_loss = 0.7996714597186411, disc_loss = 0.12349459995145359
Trained batch 332 in epoch 1, gen_loss = 0.8009387831967156, disc_loss = 0.12355313912682885
Trained batch 333 in epoch 1, gen_loss = 0.8005890110117233, disc_loss = 0.1236450356671107
Trained batch 334 in epoch 1, gen_loss = 0.8002454644708491, disc_loss = 0.12358809829091848
Trained batch 335 in epoch 1, gen_loss = 0.7999197976397616, disc_loss = 0.12348823574748599
Trained batch 336 in epoch 1, gen_loss = 0.7996456125192897, disc_loss = 0.12339111989590641
Trained batch 337 in epoch 1, gen_loss = 0.7994850666741647, disc_loss = 0.12329245845307789
Trained batch 338 in epoch 1, gen_loss = 0.8006685737487489, disc_loss = 0.12312391639349207
Trained batch 339 in epoch 1, gen_loss = 0.8002420154564521, disc_loss = 0.12328569618985057
Trained batch 340 in epoch 1, gen_loss = 0.8009657215687537, disc_loss = 0.12309507431893929
Trained batch 341 in epoch 1, gen_loss = 0.8004760263781798, disc_loss = 0.12307251086295173
Trained batch 342 in epoch 1, gen_loss = 0.8009547380073425, disc_loss = 0.1229903178653373
Trained batch 343 in epoch 1, gen_loss = 0.8009930059833582, disc_loss = 0.12281457586538826
Trained batch 344 in epoch 1, gen_loss = 0.8002715961656709, disc_loss = 0.12290018426011438
Trained batch 345 in epoch 1, gen_loss = 0.8007009373062608, disc_loss = 0.12290257924489376
Trained batch 346 in epoch 1, gen_loss = 0.800312886406434, disc_loss = 0.12286887084394264
Trained batch 347 in epoch 1, gen_loss = 0.7999202488311405, disc_loss = 0.1226868667939528
Trained batch 348 in epoch 1, gen_loss = 0.7996352869152681, disc_loss = 0.12253318717943393
Trained batch 349 in epoch 1, gen_loss = 0.8000441708735058, disc_loss = 0.12280943418719939
Trained batch 350 in epoch 1, gen_loss = 0.7994769812479318, disc_loss = 0.12310781339952918
Trained batch 351 in epoch 1, gen_loss = 0.7994627403095365, disc_loss = 0.12296534053960138
Trained batch 352 in epoch 1, gen_loss = 0.7996013427084634, disc_loss = 0.12293295650386776
Trained batch 353 in epoch 1, gen_loss = 0.7991821839142654, disc_loss = 0.12291387023961982
Trained batch 354 in epoch 1, gen_loss = 0.7986473811344361, disc_loss = 0.12291877367861674
Trained batch 355 in epoch 1, gen_loss = 0.7985299568665162, disc_loss = 0.12309292035721493
Trained batch 356 in epoch 1, gen_loss = 0.7979594947410231, disc_loss = 0.12306674066357084
Trained batch 357 in epoch 1, gen_loss = 0.7976002447598474, disc_loss = 0.12298979318320917
Trained batch 358 in epoch 1, gen_loss = 0.7980515056167804, disc_loss = 0.12294636354950311
Trained batch 359 in epoch 1, gen_loss = 0.7977043591439724, disc_loss = 0.12301605558540259
Trained batch 360 in epoch 1, gen_loss = 0.7976908811736966, disc_loss = 0.1229311327019144
Trained batch 361 in epoch 1, gen_loss = 0.7981550132866064, disc_loss = 0.12300325865800703
Trained batch 362 in epoch 1, gen_loss = 0.7975415268055992, disc_loss = 0.12327903691299527
Trained batch 363 in epoch 1, gen_loss = 0.7979335035760324, disc_loss = 0.12322997119134435
Trained batch 364 in epoch 1, gen_loss = 0.7981933672950693, disc_loss = 0.12311001819596715
Trained batch 365 in epoch 1, gen_loss = 0.7983642941127058, disc_loss = 0.12287136239045468
Trained batch 366 in epoch 1, gen_loss = 0.7978574746473609, disc_loss = 0.12274190026769359
Trained batch 367 in epoch 1, gen_loss = 0.7974285519803348, disc_loss = 0.12255713896846156
Trained batch 368 in epoch 1, gen_loss = 0.7972326082427327, disc_loss = 0.12251805849777166
Trained batch 369 in epoch 1, gen_loss = 0.7971392184495926, disc_loss = 0.12243819323846618
Trained batch 370 in epoch 1, gen_loss = 0.7968409942648803, disc_loss = 0.1223072118284005
Trained batch 371 in epoch 1, gen_loss = 0.7967365775858203, disc_loss = 0.12209563738896802
Trained batch 372 in epoch 1, gen_loss = 0.7977962878210615, disc_loss = 0.12209123741066329
Trained batch 373 in epoch 1, gen_loss = 0.7967871227525772, disc_loss = 0.12269476455023741
Trained batch 374 in epoch 1, gen_loss = 0.7968198163509369, disc_loss = 0.12249888970951239
Trained batch 375 in epoch 1, gen_loss = 0.7975915306584632, disc_loss = 0.12284881116802547
Trained batch 376 in epoch 1, gen_loss = 0.7970465880964416, disc_loss = 0.12288042763124568
Trained batch 377 in epoch 1, gen_loss = 0.796918461956675, disc_loss = 0.12282890180451056
Trained batch 378 in epoch 1, gen_loss = 0.797572877995257, disc_loss = 0.12296119961877769
Trained batch 379 in epoch 1, gen_loss = 0.7971888969603338, disc_loss = 0.12287849788308929
Trained batch 380 in epoch 1, gen_loss = 0.7970340283993348, disc_loss = 0.12279696150968863
Trained batch 381 in epoch 1, gen_loss = 0.7972363298320021, disc_loss = 0.12311314228258988
Trained batch 382 in epoch 1, gen_loss = 0.796473915287471, disc_loss = 0.12353781529510145
Trained batch 383 in epoch 1, gen_loss = 0.7962604656349868, disc_loss = 0.12363426964050934
Trained batch 384 in epoch 1, gen_loss = 0.7971311458519527, disc_loss = 0.12377170291910698
Trained batch 385 in epoch 1, gen_loss = 0.7965234596031318, disc_loss = 0.12430092250841424
Trained batch 386 in epoch 1, gen_loss = 0.7963012319048554, disc_loss = 0.12419017027457092
Trained batch 387 in epoch 1, gen_loss = 0.7964694658966408, disc_loss = 0.12427967739262685
Trained batch 388 in epoch 1, gen_loss = 0.796352800106328, disc_loss = 0.12420262389153165
Trained batch 389 in epoch 1, gen_loss = 0.7954928553257233, disc_loss = 0.12426135758272348
Trained batch 390 in epoch 1, gen_loss = 0.7953219531899522, disc_loss = 0.12431745323092888
Trained batch 391 in epoch 1, gen_loss = 0.7953828630246678, disc_loss = 0.12426210472797405
Trained batch 392 in epoch 1, gen_loss = 0.7951964199846331, disc_loss = 0.12416421370367513
Trained batch 393 in epoch 1, gen_loss = 0.7947128043713303, disc_loss = 0.12419201653488547
Trained batch 394 in epoch 1, gen_loss = 0.794553966084613, disc_loss = 0.12412670888949799
Trained batch 395 in epoch 1, gen_loss = 0.7949395486050181, disc_loss = 0.12417007941809116
Trained batch 396 in epoch 1, gen_loss = 0.7943301599482144, disc_loss = 0.12413944769885288
Trained batch 397 in epoch 1, gen_loss = 0.7940026034212592, disc_loss = 0.1242513004830809
Trained batch 398 in epoch 1, gen_loss = 0.7943094315236074, disc_loss = 0.124212226272563
Trained batch 399 in epoch 1, gen_loss = 0.7941495754569768, disc_loss = 0.12413643662352115
Trained batch 400 in epoch 1, gen_loss = 0.7942310122034496, disc_loss = 0.12399750621408745
Trained batch 401 in epoch 1, gen_loss = 0.7944075510424761, disc_loss = 0.12380015108252491
Trained batch 402 in epoch 1, gen_loss = 0.7941796379556727, disc_loss = 0.12380752854381986
Trained batch 403 in epoch 1, gen_loss = 0.7945822476603017, disc_loss = 0.12378132663722528
Trained batch 404 in epoch 1, gen_loss = 0.7945208267665204, disc_loss = 0.12364429428161662
Trained batch 405 in epoch 1, gen_loss = 0.7943941826744033, disc_loss = 0.12354622520231114
Trained batch 406 in epoch 1, gen_loss = 0.7942744598195359, disc_loss = 0.12334049785514282
Trained batch 407 in epoch 1, gen_loss = 0.7940541471482492, disc_loss = 0.12322134597172194
Trained batch 408 in epoch 1, gen_loss = 0.7940211943863074, disc_loss = 0.1231712343303309
Trained batch 409 in epoch 1, gen_loss = 0.793801306733271, disc_loss = 0.12309397140563261
Trained batch 410 in epoch 1, gen_loss = 0.7939358470358697, disc_loss = 0.12301362976159928
Trained batch 411 in epoch 1, gen_loss = 0.7947058532278515, disc_loss = 0.12279732481495124
Trained batch 412 in epoch 1, gen_loss = 0.793999214654396, disc_loss = 0.12287682121209169
Trained batch 413 in epoch 1, gen_loss = 0.7937555322468569, disc_loss = 0.122863018763778
Trained batch 414 in epoch 1, gen_loss = 0.7943622121609837, disc_loss = 0.12292387192418058
Trained batch 415 in epoch 1, gen_loss = 0.7945168953245649, disc_loss = 0.12288168462691829
Trained batch 416 in epoch 1, gen_loss = 0.794258982229004, disc_loss = 0.1227822663213352
Trained batch 417 in epoch 1, gen_loss = 0.7943675210744, disc_loss = 0.12267357427805092
Trained batch 418 in epoch 1, gen_loss = 0.794455861917259, disc_loss = 0.12253892346594243
Trained batch 419 in epoch 1, gen_loss = 0.7937863837395396, disc_loss = 0.12260714091271871
Trained batch 420 in epoch 1, gen_loss = 0.7939363596983023, disc_loss = 0.12243594455304876
Trained batch 421 in epoch 1, gen_loss = 0.7949302666136439, disc_loss = 0.12258373196920937
Trained batch 422 in epoch 1, gen_loss = 0.7953122884528293, disc_loss = 0.12236926168749378
Trained batch 423 in epoch 1, gen_loss = 0.7949015730816238, disc_loss = 0.12238628928163
Trained batch 424 in epoch 1, gen_loss = 0.7947820598237655, disc_loss = 0.1222939714394948
Trained batch 425 in epoch 1, gen_loss = 0.7958944232111246, disc_loss = 0.12257757787745743
Trained batch 426 in epoch 1, gen_loss = 0.7963161331010368, disc_loss = 0.1223433446051854
Trained batch 427 in epoch 1, gen_loss = 0.795391166182322, disc_loss = 0.12294379473341821
Trained batch 428 in epoch 1, gen_loss = 0.7954517773814969, disc_loss = 0.1229933326399618
Trained batch 429 in epoch 1, gen_loss = 0.7959362369637156, disc_loss = 0.12313227294402761
Trained batch 430 in epoch 1, gen_loss = 0.7956007597341338, disc_loss = 0.12313900042212894
Trained batch 431 in epoch 1, gen_loss = 0.7953919315779651, disc_loss = 0.12315895878796086
Trained batch 432 in epoch 1, gen_loss = 0.7952490475106184, disc_loss = 0.12309404494838819
Trained batch 433 in epoch 1, gen_loss = 0.7957878442403907, disc_loss = 0.12299195827684507
Trained batch 434 in epoch 1, gen_loss = 0.7957360399180445, disc_loss = 0.12279268274105143
Trained batch 435 in epoch 1, gen_loss = 0.7958984578694772, disc_loss = 0.12256744095132849
Trained batch 436 in epoch 1, gen_loss = 0.7957516045264849, disc_loss = 0.12249047867953777
Trained batch 437 in epoch 1, gen_loss = 0.7958987243643635, disc_loss = 0.12236477638335397
Trained batch 438 in epoch 1, gen_loss = 0.7956460543265376, disc_loss = 0.12225875831665238
Trained batch 439 in epoch 1, gen_loss = 0.7958724317225543, disc_loss = 0.12201568016951735
Trained batch 440 in epoch 1, gen_loss = 0.7957725127538046, disc_loss = 0.12186498966177846
Trained batch 441 in epoch 1, gen_loss = 0.7954142523836766, disc_loss = 0.12176006837701636
Trained batch 442 in epoch 1, gen_loss = 0.7958487474084169, disc_loss = 0.12169612775100543
Trained batch 443 in epoch 1, gen_loss = 0.7965661332950936, disc_loss = 0.12147097722920883
Trained batch 444 in epoch 1, gen_loss = 0.7957996272638942, disc_loss = 0.12192518587611365
Trained batch 445 in epoch 1, gen_loss = 0.7967364064380192, disc_loss = 0.1219367164107783
Trained batch 446 in epoch 1, gen_loss = 0.7973870343676616, disc_loss = 0.12190740245917366
Trained batch 447 in epoch 1, gen_loss = 0.7973091010935605, disc_loss = 0.12169592046328555
Trained batch 448 in epoch 1, gen_loss = 0.7970594238730475, disc_loss = 0.12173943029496744
Trained batch 449 in epoch 1, gen_loss = 0.7974661116467582, disc_loss = 0.1215201965553893
Trained batch 450 in epoch 1, gen_loss = 0.7974993766940089, disc_loss = 0.12134699351639547
Trained batch 451 in epoch 1, gen_loss = 0.7979039194441475, disc_loss = 0.12124013193611023
Trained batch 452 in epoch 1, gen_loss = 0.7975592942822058, disc_loss = 0.12122458709654692
Trained batch 453 in epoch 1, gen_loss = 0.797638188440369, disc_loss = 0.12107084687421762
Trained batch 454 in epoch 1, gen_loss = 0.7986441838217305, disc_loss = 0.12109026845831138
Trained batch 455 in epoch 1, gen_loss = 0.7980340143436926, disc_loss = 0.12129275346370905
Trained batch 456 in epoch 1, gen_loss = 0.7978521801319373, disc_loss = 0.12128994717411452
Trained batch 457 in epoch 1, gen_loss = 0.7986480127125328, disc_loss = 0.1213946695557458
Trained batch 458 in epoch 1, gen_loss = 0.7989701244955748, disc_loss = 0.12127577408758644
Trained batch 459 in epoch 1, gen_loss = 0.7986169964722966, disc_loss = 0.12133125968115485
Trained batch 460 in epoch 1, gen_loss = 0.7983899736481995, disc_loss = 0.12131038439862123
Trained batch 461 in epoch 1, gen_loss = 0.7986615549821359, disc_loss = 0.12132656425076388
Trained batch 462 in epoch 1, gen_loss = 0.7984618223382897, disc_loss = 0.12122219333477463
Trained batch 463 in epoch 1, gen_loss = 0.7979139404949444, disc_loss = 0.12132182103132122
Trained batch 464 in epoch 1, gen_loss = 0.7981162428214986, disc_loss = 0.1212453730404377
Trained batch 465 in epoch 1, gen_loss = 0.7981695184252293, disc_loss = 0.12118198520348052
Trained batch 466 in epoch 1, gen_loss = 0.798781902108509, disc_loss = 0.1209926060630244
Trained batch 467 in epoch 1, gen_loss = 0.7984093681741984, disc_loss = 0.12095163040595432
Trained batch 468 in epoch 1, gen_loss = 0.798547679109614, disc_loss = 0.12073998210002491
Trained batch 469 in epoch 1, gen_loss = 0.7983361403358743, disc_loss = 0.12064811013084142
Trained batch 470 in epoch 1, gen_loss = 0.7985567010765117, disc_loss = 0.1204932857811008
Trained batch 471 in epoch 1, gen_loss = 0.7989421099803206, disc_loss = 0.12038443674396535
Trained batch 472 in epoch 1, gen_loss = 0.7984585908830292, disc_loss = 0.12055242261268498
Trained batch 473 in epoch 1, gen_loss = 0.7982376419667956, disc_loss = 0.12046134889613098
Trained batch 474 in epoch 1, gen_loss = 0.7990035634919217, disc_loss = 0.12035557136331734
Trained batch 475 in epoch 1, gen_loss = 0.7985223236830294, disc_loss = 0.1204863974018445
Trained batch 476 in epoch 1, gen_loss = 0.7993237847926982, disc_loss = 0.12045060924061064
Trained batch 477 in epoch 1, gen_loss = 0.798924404644567, disc_loss = 0.12051164883746138
Trained batch 478 in epoch 1, gen_loss = 0.7984575001456792, disc_loss = 0.12049990207625705
Trained batch 479 in epoch 1, gen_loss = 0.7985808004314701, disc_loss = 0.12050107378745452
Trained batch 480 in epoch 1, gen_loss = 0.798808608568136, disc_loss = 0.120689928682672
Trained batch 481 in epoch 1, gen_loss = 0.7983688177285847, disc_loss = 0.12072003088288659
Trained batch 482 in epoch 1, gen_loss = 0.7980953952910738, disc_loss = 0.12073931656006577
Trained batch 483 in epoch 1, gen_loss = 0.7984373972805079, disc_loss = 0.12087225362519957
Trained batch 484 in epoch 1, gen_loss = 0.7984607126909433, disc_loss = 0.12096848459818314
Trained batch 485 in epoch 1, gen_loss = 0.7984919105905565, disc_loss = 0.12087962147492318
Trained batch 486 in epoch 1, gen_loss = 0.7985274059204595, disc_loss = 0.12072650426941363
Trained batch 487 in epoch 1, gen_loss = 0.7995686913977881, disc_loss = 0.12065469064047468
Trained batch 488 in epoch 1, gen_loss = 0.7997902855429425, disc_loss = 0.120474154746697
Trained batch 489 in epoch 1, gen_loss = 0.7992562823757834, disc_loss = 0.12066068870908751
Trained batch 490 in epoch 1, gen_loss = 0.7992508291833998, disc_loss = 0.12061547249358322
Trained batch 491 in epoch 1, gen_loss = 0.7997576421717318, disc_loss = 0.12081450353777869
Trained batch 492 in epoch 1, gen_loss = 0.7992680119331662, disc_loss = 0.12094076439874288
Trained batch 493 in epoch 1, gen_loss = 0.7992144098528001, disc_loss = 0.12087891511392859
Trained batch 494 in epoch 1, gen_loss = 0.7990210628870762, disc_loss = 0.12086667130616578
Trained batch 495 in epoch 1, gen_loss = 0.7989054263959969, disc_loss = 0.120861015053496
Trained batch 496 in epoch 1, gen_loss = 0.7991438232797012, disc_loss = 0.12072036966636507
Trained batch 497 in epoch 1, gen_loss = 0.7991880967794173, disc_loss = 0.1205725273057579
Trained batch 498 in epoch 1, gen_loss = 0.7992070336977323, disc_loss = 0.12044901767734416
Trained batch 499 in epoch 1, gen_loss = 0.7991705285906792, disc_loss = 0.12048235313221813
Trained batch 500 in epoch 1, gen_loss = 0.7990120099095289, disc_loss = 0.12057199685680058
Trained batch 501 in epoch 1, gen_loss = 0.7995108173069251, disc_loss = 0.12048410343384719
Trained batch 502 in epoch 1, gen_loss = 0.7988402182847321, disc_loss = 0.12057639585500564
Trained batch 503 in epoch 1, gen_loss = 0.7986341590091349, disc_loss = 0.12060703820223728
Trained batch 504 in epoch 1, gen_loss = 0.7989215642508893, disc_loss = 0.12069680895471926
Trained batch 505 in epoch 1, gen_loss = 0.798741107224947, disc_loss = 0.12056374863864994
Trained batch 506 in epoch 1, gen_loss = 0.7987623831341722, disc_loss = 0.1204666526955084
Trained batch 507 in epoch 1, gen_loss = 0.7989536369527419, disc_loss = 0.12034551677932068
Trained batch 508 in epoch 1, gen_loss = 0.7986311557133681, disc_loss = 0.12046624388187128
Trained batch 509 in epoch 1, gen_loss = 0.7986806909827625, disc_loss = 0.12033534733322905
Trained batch 510 in epoch 1, gen_loss = 0.7988852482369267, disc_loss = 0.12039057437673123
Trained batch 511 in epoch 1, gen_loss = 0.7987754907808267, disc_loss = 0.12032816899227328
Trained batch 512 in epoch 1, gen_loss = 0.7986668505747648, disc_loss = 0.12015489709961136
Trained batch 513 in epoch 1, gen_loss = 0.7987486413364744, disc_loss = 0.11998616287607974
Trained batch 514 in epoch 1, gen_loss = 0.7987128710862502, disc_loss = 0.11989054113843488
Trained batch 515 in epoch 1, gen_loss = 0.7995319726277691, disc_loss = 0.11978179607323783
Trained batch 516 in epoch 1, gen_loss = 0.7993578366084994, disc_loss = 0.11963235309106122
Trained batch 517 in epoch 1, gen_loss = 0.7992453337521166, disc_loss = 0.11952489176153791
Trained batch 518 in epoch 1, gen_loss = 0.7994728098140746, disc_loss = 0.11948275797585876
Trained batch 519 in epoch 1, gen_loss = 0.7992999017811738, disc_loss = 0.11939287035582731
Trained batch 520 in epoch 1, gen_loss = 0.799303901458656, disc_loss = 0.11925139974967189
Trained batch 521 in epoch 1, gen_loss = 0.7989540741247235, disc_loss = 0.11921826128087852
Trained batch 522 in epoch 1, gen_loss = 0.7991800214204916, disc_loss = 0.11918960392375408
Trained batch 523 in epoch 1, gen_loss = 0.7999760068896162, disc_loss = 0.11906672806926925
Trained batch 524 in epoch 1, gen_loss = 0.8006482230481647, disc_loss = 0.1188796140111628
Trained batch 525 in epoch 1, gen_loss = 0.8006059368187031, disc_loss = 0.11881545380806062
Trained batch 526 in epoch 1, gen_loss = 0.8006108839213283, disc_loss = 0.1186539701608485
Trained batch 527 in epoch 1, gen_loss = 0.8012905123671799, disc_loss = 0.11849338320704798
Trained batch 528 in epoch 1, gen_loss = 0.8012344240578902, disc_loss = 0.11834258660110725
Trained batch 529 in epoch 1, gen_loss = 0.8013063569676201, disc_loss = 0.11819189838221612
Trained batch 530 in epoch 1, gen_loss = 0.8015897292538551, disc_loss = 0.1180730801980711
Trained batch 531 in epoch 1, gen_loss = 0.8013774045091823, disc_loss = 0.11807782640610646
Trained batch 532 in epoch 1, gen_loss = 0.8018348128106759, disc_loss = 0.11800490721612888
Trained batch 533 in epoch 1, gen_loss = 0.8024999218598734, disc_loss = 0.11784429177083773
Trained batch 534 in epoch 1, gen_loss = 0.8030294470140867, disc_loss = 0.11766900480072075
Trained batch 535 in epoch 1, gen_loss = 0.803019027712185, disc_loss = 0.1175080220729335
Trained batch 536 in epoch 1, gen_loss = 0.8030656221525629, disc_loss = 0.11733209337602114
Trained batch 537 in epoch 1, gen_loss = 0.803227654010833, disc_loss = 0.1171408812671235
Trained batch 538 in epoch 1, gen_loss = 0.8035345149947009, disc_loss = 0.1169770189210192
Trained batch 539 in epoch 1, gen_loss = 0.8034015705740011, disc_loss = 0.11682227295305994
Trained batch 540 in epoch 1, gen_loss = 0.8031843644523797, disc_loss = 0.1167562912440344
Trained batch 541 in epoch 1, gen_loss = 0.8032007731524781, disc_loss = 0.11679671578301715
Trained batch 542 in epoch 1, gen_loss = 0.8031433108871593, disc_loss = 0.11670778380298702
Trained batch 543 in epoch 1, gen_loss = 0.8032122147543466, disc_loss = 0.11656532258562305
Trained batch 544 in epoch 1, gen_loss = 0.8032628746754532, disc_loss = 0.1164193619008458
Trained batch 545 in epoch 1, gen_loss = 0.8031193640751716, disc_loss = 0.11638996415795425
Trained batch 546 in epoch 1, gen_loss = 0.8031005269321707, disc_loss = 0.11625901271863219
Trained batch 547 in epoch 1, gen_loss = 0.8038707310809706, disc_loss = 0.11624911666786583
Trained batch 548 in epoch 1, gen_loss = 0.8041466940838999, disc_loss = 0.11606972322600786
Trained batch 549 in epoch 1, gen_loss = 0.8035257151451978, disc_loss = 0.11627349375323816
Trained batch 550 in epoch 1, gen_loss = 0.8037466068774083, disc_loss = 0.11632670779896734
Trained batch 551 in epoch 1, gen_loss = 0.8035227239023948, disc_loss = 0.11622569198463706
Trained batch 552 in epoch 1, gen_loss = 0.8041534584965456, disc_loss = 0.1161372589509914
Trained batch 553 in epoch 1, gen_loss = 0.8039437925664957, disc_loss = 0.11602315996581897
Trained batch 554 in epoch 1, gen_loss = 0.8040395169107764, disc_loss = 0.11585699688005555
Trained batch 555 in epoch 1, gen_loss = 0.8039970624682714, disc_loss = 0.11575765818317267
Trained batch 556 in epoch 1, gen_loss = 0.8045831000034428, disc_loss = 0.1158045980731557
Trained batch 557 in epoch 1, gen_loss = 0.8046360698972551, disc_loss = 0.11574220915381733
Trained batch 558 in epoch 1, gen_loss = 0.8042419732469992, disc_loss = 0.11604586138668235
Trained batch 559 in epoch 1, gen_loss = 0.8045202835862125, disc_loss = 0.11599962143560073
Trained batch 560 in epoch 1, gen_loss = 0.8052144812921365, disc_loss = 0.11596098345988255
Trained batch 561 in epoch 1, gen_loss = 0.8053535617012995, disc_loss = 0.11577172030187692
Trained batch 562 in epoch 1, gen_loss = 0.8054423847270478, disc_loss = 0.11560936607288107
Trained batch 563 in epoch 1, gen_loss = 0.8054010896078239, disc_loss = 0.11546765963038337
Trained batch 564 in epoch 1, gen_loss = 0.8056194688894053, disc_loss = 0.11532881140247384
Trained batch 565 in epoch 1, gen_loss = 0.8054166732638969, disc_loss = 0.11519853049040156
Trained batch 566 in epoch 1, gen_loss = 0.8055034536848623, disc_loss = 0.11506342228561167
Trained batch 567 in epoch 1, gen_loss = 0.8057675329627285, disc_loss = 0.11499671100533869
Trained batch 568 in epoch 1, gen_loss = 0.8060215344433206, disc_loss = 0.11484338780161261
Trained batch 569 in epoch 1, gen_loss = 0.805539063874044, disc_loss = 0.11502583910171923
Trained batch 570 in epoch 1, gen_loss = 0.8056237798334211, disc_loss = 0.11500887625937183
Trained batch 571 in epoch 1, gen_loss = 0.8053581564055456, disc_loss = 0.11501240907106679
Trained batch 572 in epoch 1, gen_loss = 0.8050440653352421, disc_loss = 0.11502434758966817
Trained batch 573 in epoch 1, gen_loss = 0.8056177022876639, disc_loss = 0.11514175803650444
Trained batch 574 in epoch 1, gen_loss = 0.8052721761102262, disc_loss = 0.1152582812147296
Trained batch 575 in epoch 1, gen_loss = 0.8049291968863044, disc_loss = 0.11526336030349033
Trained batch 576 in epoch 1, gen_loss = 0.8048886662442721, disc_loss = 0.11529771276980484
Trained batch 577 in epoch 1, gen_loss = 0.8054652284689016, disc_loss = 0.115207231564892
Trained batch 578 in epoch 1, gen_loss = 0.8054572698468783, disc_loss = 0.11511359053353469
Trained batch 579 in epoch 1, gen_loss = 0.8053581057437535, disc_loss = 0.1149947396479547
Trained batch 580 in epoch 1, gen_loss = 0.805050111422235, disc_loss = 0.11501342820872436
Trained batch 581 in epoch 1, gen_loss = 0.8053725003888926, disc_loss = 0.11501139978145304
Trained batch 582 in epoch 1, gen_loss = 0.8057303991469061, disc_loss = 0.1148562937732115
Trained batch 583 in epoch 1, gen_loss = 0.8056739696799076, disc_loss = 0.11474690880396798
Trained batch 584 in epoch 1, gen_loss = 0.8054929363931346, disc_loss = 0.11475969878399474
Trained batch 585 in epoch 1, gen_loss = 0.8053709367741497, disc_loss = 0.11474592418571991
Trained batch 586 in epoch 1, gen_loss = 0.8054248240270241, disc_loss = 0.11487277364278976
Trained batch 587 in epoch 1, gen_loss = 0.8055878804147649, disc_loss = 0.1147149346743514
Trained batch 588 in epoch 1, gen_loss = 0.805209589075354, disc_loss = 0.11471448489583409
Trained batch 589 in epoch 1, gen_loss = 0.804981087577545, disc_loss = 0.11468197487420954
Trained batch 590 in epoch 1, gen_loss = 0.8050726913861211, disc_loss = 0.11468163514651623
Trained batch 591 in epoch 1, gen_loss = 0.805373276659363, disc_loss = 0.1145967439295271
Trained batch 592 in epoch 1, gen_loss = 0.804998655795649, disc_loss = 0.11464623756342353
Trained batch 593 in epoch 1, gen_loss = 0.8049153852643389, disc_loss = 0.11459564273355384
Trained batch 594 in epoch 1, gen_loss = 0.8051786577501217, disc_loss = 0.11456977618592126
Trained batch 595 in epoch 1, gen_loss = 0.8057685286906742, disc_loss = 0.11451671758804145
Trained batch 596 in epoch 1, gen_loss = 0.8054214287143656, disc_loss = 0.11460079251471876
Trained batch 597 in epoch 1, gen_loss = 0.8052482980250515, disc_loss = 0.11457239113822829
Trained batch 598 in epoch 1, gen_loss = 0.8052048544354351, disc_loss = 0.11454355943083563
Trained batch 599 in epoch 1, gen_loss = 0.805321166763703, disc_loss = 0.11449394707878431
Trained batch 600 in epoch 1, gen_loss = 0.805736058414875, disc_loss = 0.11442394197582206
Trained batch 601 in epoch 1, gen_loss = 0.80549191057286, disc_loss = 0.11438291909736256
Trained batch 602 in epoch 1, gen_loss = 0.8052756991453629, disc_loss = 0.11425105524967559
Trained batch 603 in epoch 1, gen_loss = 0.805126926707511, disc_loss = 0.11422026856179467
Trained batch 604 in epoch 1, gen_loss = 0.8056717584448413, disc_loss = 0.11441610071900463
Trained batch 605 in epoch 1, gen_loss = 0.8057831533179425, disc_loss = 0.1142837809945884
Trained batch 606 in epoch 1, gen_loss = 0.8056430467565527, disc_loss = 0.11427053659417877
Trained batch 607 in epoch 1, gen_loss = 0.8058755096342218, disc_loss = 0.11427995226787109
Trained batch 608 in epoch 1, gen_loss = 0.8055573322600723, disc_loss = 0.11434392401052422
Trained batch 609 in epoch 1, gen_loss = 0.8059833597452914, disc_loss = 0.11452657309223394
Trained batch 610 in epoch 1, gen_loss = 0.8057382477968688, disc_loss = 0.11455700133123882
Trained batch 611 in epoch 1, gen_loss = 0.805738122683335, disc_loss = 0.11454376712246658
Trained batch 612 in epoch 1, gen_loss = 0.805830350270279, disc_loss = 0.114493868187629
Trained batch 613 in epoch 1, gen_loss = 0.8054845142345087, disc_loss = 0.11449873508090694
Trained batch 614 in epoch 1, gen_loss = 0.8054160852257798, disc_loss = 0.11445609253596484
Trained batch 615 in epoch 1, gen_loss = 0.8057208556149688, disc_loss = 0.11435083101515646
Trained batch 616 in epoch 1, gen_loss = 0.8054564110753601, disc_loss = 0.11432210814865906
Trained batch 617 in epoch 1, gen_loss = 0.8055868707717815, disc_loss = 0.114247777640916
Trained batch 618 in epoch 1, gen_loss = 0.8052505678911008, disc_loss = 0.11421857911473522
Trained batch 619 in epoch 1, gen_loss = 0.805720328371371, disc_loss = 0.11428162397876862
Trained batch 620 in epoch 1, gen_loss = 0.8054028987020686, disc_loss = 0.11422014247248138
Trained batch 621 in epoch 1, gen_loss = 0.8050985168126619, disc_loss = 0.11428467077697205
Trained batch 622 in epoch 1, gen_loss = 0.8058142277918887, disc_loss = 0.11510928050520715
Trained batch 623 in epoch 1, gen_loss = 0.8054977701738094, disc_loss = 0.11512185107821073
Trained batch 624 in epoch 1, gen_loss = 0.8052613598346711, disc_loss = 0.11517029881477356
Trained batch 625 in epoch 1, gen_loss = 0.8055095180821495, disc_loss = 0.11531815147057128
Trained batch 626 in epoch 1, gen_loss = 0.8054686950629598, disc_loss = 0.11534516867458156
Trained batch 627 in epoch 1, gen_loss = 0.8050750065476272, disc_loss = 0.11530466966188638
Trained batch 628 in epoch 1, gen_loss = 0.8049662675596003, disc_loss = 0.11526150733753683
Trained batch 629 in epoch 1, gen_loss = 0.8046966846500124, disc_loss = 0.11525608696161754
Trained batch 630 in epoch 1, gen_loss = 0.8048785507867907, disc_loss = 0.115189109983516
Trained batch 631 in epoch 1, gen_loss = 0.80483757548883, disc_loss = 0.11511092144948772
Trained batch 632 in epoch 1, gen_loss = 0.8049468512501197, disc_loss = 0.11496607719745493
Trained batch 633 in epoch 1, gen_loss = 0.8050342793062282, disc_loss = 0.1149555554889636
Trained batch 634 in epoch 1, gen_loss = 0.8051718333105403, disc_loss = 0.11484267608973923
Trained batch 635 in epoch 1, gen_loss = 0.8051011244174819, disc_loss = 0.1147497410142103
Trained batch 636 in epoch 1, gen_loss = 0.8048409867791965, disc_loss = 0.11479876361775623
Trained batch 637 in epoch 1, gen_loss = 0.8050948934028141, disc_loss = 0.11476873081516135
Trained batch 638 in epoch 1, gen_loss = 0.80567284551025, disc_loss = 0.1147160424977681
Trained batch 639 in epoch 1, gen_loss = 0.8052052277605981, disc_loss = 0.11469789054826833
Trained batch 640 in epoch 1, gen_loss = 0.8048970925733563, disc_loss = 0.1147956203570511
Trained batch 641 in epoch 1, gen_loss = 0.8054523419275462, disc_loss = 0.11487988763810875
Trained batch 642 in epoch 1, gen_loss = 0.8052669832624877, disc_loss = 0.1148827834747164
Trained batch 643 in epoch 1, gen_loss = 0.8051386540813475, disc_loss = 0.11490147984846964
Trained batch 644 in epoch 1, gen_loss = 0.804938810601715, disc_loss = 0.11491579789408418
Trained batch 645 in epoch 1, gen_loss = 0.8048484824113432, disc_loss = 0.11489046409426275
Trained batch 646 in epoch 1, gen_loss = 0.8049824786425742, disc_loss = 0.11489462247334271
Trained batch 647 in epoch 1, gen_loss = 0.8047475753650989, disc_loss = 0.11497267292536519
Trained batch 648 in epoch 1, gen_loss = 0.8047340220681324, disc_loss = 0.1149704685299808
Trained batch 649 in epoch 1, gen_loss = 0.8045637038579354, disc_loss = 0.11494752148596141
Trained batch 650 in epoch 1, gen_loss = 0.8045024434633885, disc_loss = 0.114910893914749
Trained batch 651 in epoch 1, gen_loss = 0.8046387556963172, disc_loss = 0.11480558477342129
Trained batch 652 in epoch 1, gen_loss = 0.8044439920696329, disc_loss = 0.11476115842462499
Trained batch 653 in epoch 1, gen_loss = 0.8042779438630521, disc_loss = 0.11474087808155868
Trained batch 654 in epoch 1, gen_loss = 0.8043949476180186, disc_loss = 0.11477550428559762
Trained batch 655 in epoch 1, gen_loss = 0.8044417979786309, disc_loss = 0.11466322704672632
Trained batch 656 in epoch 1, gen_loss = 0.8045064451759809, disc_loss = 0.11454874464229906
Trained batch 657 in epoch 1, gen_loss = 0.8044537713915382, disc_loss = 0.11450426194443167
Trained batch 658 in epoch 1, gen_loss = 0.8042966332258331, disc_loss = 0.11440101860597028
Trained batch 659 in epoch 1, gen_loss = 0.8046616762424961, disc_loss = 0.11425037894567305
Trained batch 660 in epoch 1, gen_loss = 0.8046161788043745, disc_loss = 0.11414689427796813
Trained batch 661 in epoch 1, gen_loss = 0.8042647998408609, disc_loss = 0.11423246510990887
Trained batch 662 in epoch 1, gen_loss = 0.8043570707736152, disc_loss = 0.11427163388046294
Trained batch 663 in epoch 1, gen_loss = 0.8046963597726391, disc_loss = 0.11427532717955849
Trained batch 664 in epoch 1, gen_loss = 0.8051353211241558, disc_loss = 0.11414754503315552
Trained batch 665 in epoch 1, gen_loss = 0.805295055827221, disc_loss = 0.11403176605186842
Trained batch 666 in epoch 1, gen_loss = 0.8055081676239374, disc_loss = 0.11389313208712809
Trained batch 667 in epoch 1, gen_loss = 0.8057302384230192, disc_loss = 0.11373894058814842
Trained batch 668 in epoch 1, gen_loss = 0.8057398000907471, disc_loss = 0.11360526111628443
Trained batch 669 in epoch 1, gen_loss = 0.8059520278848818, disc_loss = 0.11346770012612219
Trained batch 670 in epoch 1, gen_loss = 0.8063850797679492, disc_loss = 0.1133240452383252
Trained batch 671 in epoch 1, gen_loss = 0.8059225657156536, disc_loss = 0.11336324864255619
Trained batch 672 in epoch 1, gen_loss = 0.8059986084035389, disc_loss = 0.11327964023453077
Trained batch 673 in epoch 1, gen_loss = 0.8067871952976601, disc_loss = 0.113334704911784
Trained batch 674 in epoch 1, gen_loss = 0.8069787113754837, disc_loss = 0.1132711562431521
Trained batch 675 in epoch 1, gen_loss = 0.8067528009414673, disc_loss = 0.11331007058991219
Trained batch 676 in epoch 1, gen_loss = 0.8069034628184895, disc_loss = 0.1132170487789539
Trained batch 677 in epoch 1, gen_loss = 0.806945852122124, disc_loss = 0.11325814280724894
Trained batch 678 in epoch 1, gen_loss = 0.8066722677803883, disc_loss = 0.1132456419553295
Trained batch 679 in epoch 1, gen_loss = 0.8064724233220605, disc_loss = 0.11320284862783464
Trained batch 680 in epoch 1, gen_loss = 0.8065521077262497, disc_loss = 0.11313430163270839
Trained batch 681 in epoch 1, gen_loss = 0.8066605837289189, disc_loss = 0.11312283167227709
Trained batch 682 in epoch 1, gen_loss = 0.8063777951335488, disc_loss = 0.11310054776620114
Trained batch 683 in epoch 1, gen_loss = 0.8061982117898283, disc_loss = 0.11313816748439656
Trained batch 684 in epoch 1, gen_loss = 0.806273256253152, disc_loss = 0.11319483042470295
Trained batch 685 in epoch 1, gen_loss = 0.8060429582790453, disc_loss = 0.11321286694486096
Trained batch 686 in epoch 1, gen_loss = 0.8059272082438462, disc_loss = 0.11310382547694783
Trained batch 687 in epoch 1, gen_loss = 0.805671307583188, disc_loss = 0.11312497301341229
Trained batch 688 in epoch 1, gen_loss = 0.8059310646638469, disc_loss = 0.11318019322553549
Trained batch 689 in epoch 1, gen_loss = 0.8062410567117774, disc_loss = 0.11315711212169001
Trained batch 690 in epoch 1, gen_loss = 0.8060497480259963, disc_loss = 0.1131497186496746
Trained batch 691 in epoch 1, gen_loss = 0.8056967906180145, disc_loss = 0.11319069143632329
Trained batch 692 in epoch 1, gen_loss = 0.8058188764907925, disc_loss = 0.11321923757324057
Trained batch 693 in epoch 1, gen_loss = 0.8058730202380793, disc_loss = 0.11315420593379297
Trained batch 694 in epoch 1, gen_loss = 0.8065366803313331, disc_loss = 0.11305856417676957
Trained batch 695 in epoch 1, gen_loss = 0.8065672163990723, disc_loss = 0.11292847203379817
Trained batch 696 in epoch 1, gen_loss = 0.8062890839029418, disc_loss = 0.11328057942903966
Trained batch 697 in epoch 1, gen_loss = 0.8068988542672898, disc_loss = 0.11347475332237332
Trained batch 698 in epoch 1, gen_loss = 0.8066532805412795, disc_loss = 0.11345498587067461
Trained batch 699 in epoch 1, gen_loss = 0.8065967596428735, disc_loss = 0.11343533632212452
Trained batch 700 in epoch 1, gen_loss = 0.806216345789089, disc_loss = 0.11350744930009614
Trained batch 701 in epoch 1, gen_loss = 0.8059687874256036, disc_loss = 0.11351165634200529
Trained batch 702 in epoch 1, gen_loss = 0.8060414383285924, disc_loss = 0.11347385624405076
Trained batch 703 in epoch 1, gen_loss = 0.8060796331952919, disc_loss = 0.11335268687848425
Trained batch 704 in epoch 1, gen_loss = 0.8060799253747818, disc_loss = 0.1132611568066034
Trained batch 705 in epoch 1, gen_loss = 0.8061488969805558, disc_loss = 0.11312610270038627
Trained batch 706 in epoch 1, gen_loss = 0.8061111959743364, disc_loss = 0.11303060005723249
Trained batch 707 in epoch 1, gen_loss = 0.8061636941412748, disc_loss = 0.11298099486683469
Trained batch 708 in epoch 1, gen_loss = 0.806456643452261, disc_loss = 0.11289229769685288
Trained batch 709 in epoch 1, gen_loss = 0.8063188159129989, disc_loss = 0.1128849679027015
Trained batch 710 in epoch 1, gen_loss = 0.806472364860245, disc_loss = 0.11285526157944933
Trained batch 711 in epoch 1, gen_loss = 0.8069287739442975, disc_loss = 0.11272994952872814
Trained batch 712 in epoch 1, gen_loss = 0.806747126295055, disc_loss = 0.11273706726061095
Trained batch 713 in epoch 1, gen_loss = 0.8070820497364557, disc_loss = 0.11263584446537644
Trained batch 714 in epoch 1, gen_loss = 0.8073625618761237, disc_loss = 0.11258342641998421
Trained batch 715 in epoch 1, gen_loss = 0.8073775219684206, disc_loss = 0.1125003770644147
Trained batch 716 in epoch 1, gen_loss = 0.807375251748073, disc_loss = 0.11239880254047935
Trained batch 717 in epoch 1, gen_loss = 0.8075674796336872, disc_loss = 0.11228695044081274
Trained batch 718 in epoch 1, gen_loss = 0.807419373362386, disc_loss = 0.11229587002542071
Trained batch 719 in epoch 1, gen_loss = 0.8073683871991104, disc_loss = 0.11223463647119288
Trained batch 720 in epoch 1, gen_loss = 0.8073366744012344, disc_loss = 0.11220503150228406
Trained batch 721 in epoch 1, gen_loss = 0.8080391163145736, disc_loss = 0.11227866261423543
Trained batch 722 in epoch 1, gen_loss = 0.8077487333022048, disc_loss = 0.11249443885830346
Trained batch 723 in epoch 1, gen_loss = 0.8075901539944812, disc_loss = 0.11246311875801142
Trained batch 724 in epoch 1, gen_loss = 0.8076655409253877, disc_loss = 0.11245691670682924
Trained batch 725 in epoch 1, gen_loss = 0.8082324481535877, disc_loss = 0.11249658538505805
Trained batch 726 in epoch 1, gen_loss = 0.8080767260293029, disc_loss = 0.11247901735568555
Trained batch 727 in epoch 1, gen_loss = 0.8078121840135082, disc_loss = 0.11247040605899151
Trained batch 728 in epoch 1, gen_loss = 0.8076951174251991, disc_loss = 0.11247375985896228
Trained batch 729 in epoch 1, gen_loss = 0.8079755881877795, disc_loss = 0.11244319626576688
Trained batch 730 in epoch 1, gen_loss = 0.8075685058344568, disc_loss = 0.11260155644700971
Trained batch 731 in epoch 1, gen_loss = 0.8077095662309823, disc_loss = 0.11255049949023323
Trained batch 732 in epoch 1, gen_loss = 0.8084002453503472, disc_loss = 0.11263674651342476
Trained batch 733 in epoch 1, gen_loss = 0.8085493943996586, disc_loss = 0.11251702043671942
Trained batch 734 in epoch 1, gen_loss = 0.8083756201121272, disc_loss = 0.11251359210685402
Trained batch 735 in epoch 1, gen_loss = 0.8080358191028886, disc_loss = 0.11256002444196897
Trained batch 736 in epoch 1, gen_loss = 0.8082637249857308, disc_loss = 0.11274733629679179
Trained batch 737 in epoch 1, gen_loss = 0.8083616503208957, disc_loss = 0.11271229278053937
Trained batch 738 in epoch 1, gen_loss = 0.8080247488170257, disc_loss = 0.11283034917738424
Trained batch 739 in epoch 1, gen_loss = 0.8079379892027055, disc_loss = 0.11279759217506728
Trained batch 740 in epoch 1, gen_loss = 0.8079447379479041, disc_loss = 0.11277111343959002
Trained batch 741 in epoch 1, gen_loss = 0.8078987012012306, disc_loss = 0.11272103381355737
Trained batch 742 in epoch 1, gen_loss = 0.8080038119453441, disc_loss = 0.11263988537821683
Trained batch 743 in epoch 1, gen_loss = 0.8076526730932215, disc_loss = 0.11269849006797597
Trained batch 744 in epoch 1, gen_loss = 0.8076611582064789, disc_loss = 0.11265707824804239
Trained batch 745 in epoch 1, gen_loss = 0.807866419528189, disc_loss = 0.1126268742825766
Trained batch 746 in epoch 1, gen_loss = 0.8078111398970107, disc_loss = 0.11254269786059377
Trained batch 747 in epoch 1, gen_loss = 0.8076388953841306, disc_loss = 0.112501563113382
Trained batch 748 in epoch 1, gen_loss = 0.807767782176289, disc_loss = 0.11249214949680664
Trained batch 749 in epoch 1, gen_loss = 0.807725219964981, disc_loss = 0.1124776393448313
Trained batch 750 in epoch 1, gen_loss = 0.8075005929574827, disc_loss = 0.1125686398512633
Trained batch 751 in epoch 1, gen_loss = 0.8078149389871891, disc_loss = 0.11269393990044185
Trained batch 752 in epoch 1, gen_loss = 0.8075395195607645, disc_loss = 0.1127988577636075
Trained batch 753 in epoch 1, gen_loss = 0.8072955383071849, disc_loss = 0.1128295863847636
Trained batch 754 in epoch 1, gen_loss = 0.8072739350085227, disc_loss = 0.11277425400419346
Trained batch 755 in epoch 1, gen_loss = 0.8071382462032257, disc_loss = 0.1128517706908049
Trained batch 756 in epoch 1, gen_loss = 0.806968960610847, disc_loss = 0.11287501024001105
Trained batch 757 in epoch 1, gen_loss = 0.8070323473545367, disc_loss = 0.11287040722195187
Trained batch 758 in epoch 1, gen_loss = 0.8068685486068524, disc_loss = 0.11283237783284919
Trained batch 759 in epoch 1, gen_loss = 0.8069488404612792, disc_loss = 0.11277405677216226
Trained batch 760 in epoch 1, gen_loss = 0.8067648331689772, disc_loss = 0.11281396776349645
Trained batch 761 in epoch 1, gen_loss = 0.8069397295553853, disc_loss = 0.11274235359982164
Trained batch 762 in epoch 1, gen_loss = 0.8068115167505306, disc_loss = 0.1127309289542399
Trained batch 763 in epoch 1, gen_loss = 0.8072151423124743, disc_loss = 0.11269055933725694
Trained batch 764 in epoch 1, gen_loss = 0.8072431073469274, disc_loss = 0.11270786318075812
Trained batch 765 in epoch 1, gen_loss = 0.8077441891241945, disc_loss = 0.11276463026973582
Trained batch 766 in epoch 1, gen_loss = 0.8075346026613317, disc_loss = 0.11287896005580059
Trained batch 767 in epoch 1, gen_loss = 0.8074433846243968, disc_loss = 0.11294558412191691
Trained batch 768 in epoch 1, gen_loss = 0.8075516006106364, disc_loss = 0.11303840223724029
Trained batch 769 in epoch 1, gen_loss = 0.8079349757014931, disc_loss = 0.11300410489708959
Trained batch 770 in epoch 1, gen_loss = 0.8078033440153268, disc_loss = 0.11294697676139041
Trained batch 771 in epoch 1, gen_loss = 0.8077080248242215, disc_loss = 0.11293644312083953
Trained batch 772 in epoch 1, gen_loss = 0.8079715344144024, disc_loss = 0.11304140874313583
Trained batch 773 in epoch 1, gen_loss = 0.8077112874473404, disc_loss = 0.1131231801449598
Trained batch 774 in epoch 1, gen_loss = 0.8073734662609715, disc_loss = 0.11316071105339835
Trained batch 775 in epoch 1, gen_loss = 0.8073552756272641, disc_loss = 0.11311552304649707
Trained batch 776 in epoch 1, gen_loss = 0.8073087036226093, disc_loss = 0.11312420258449542
Trained batch 777 in epoch 1, gen_loss = 0.8071975089743695, disc_loss = 0.11311084886050393
Trained batch 778 in epoch 1, gen_loss = 0.8071320247435907, disc_loss = 0.11311625751196878
Trained batch 779 in epoch 1, gen_loss = 0.8071152800168746, disc_loss = 0.11302303394589286
Trained batch 780 in epoch 1, gen_loss = 0.8069564423854159, disc_loss = 0.11296481719996575
Trained batch 781 in epoch 1, gen_loss = 0.8067326131074325, disc_loss = 0.1129768759445728
Trained batch 782 in epoch 1, gen_loss = 0.8065549218943902, disc_loss = 0.11293799474616541
Trained batch 783 in epoch 1, gen_loss = 0.8065703813822902, disc_loss = 0.11291056762839079
Trained batch 784 in epoch 1, gen_loss = 0.8064984479527565, disc_loss = 0.11281621409402152
Trained batch 785 in epoch 1, gen_loss = 0.8068745045261528, disc_loss = 0.11278460942369911
Trained batch 786 in epoch 1, gen_loss = 0.8068342848078571, disc_loss = 0.11273994890137504
Trained batch 787 in epoch 1, gen_loss = 0.806738148561589, disc_loss = 0.11271147122417534
Trained batch 788 in epoch 1, gen_loss = 0.806665780350887, disc_loss = 0.11271363342622312
Trained batch 789 in epoch 1, gen_loss = 0.8065529289879376, disc_loss = 0.11268946341462904
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.8510676622390747, disc_loss = 0.10610637068748474
Trained batch 1 in epoch 2, gen_loss = 0.7967197895050049, disc_loss = 0.08578696474432945
Trained batch 2 in epoch 2, gen_loss = 0.8775080839792887, disc_loss = 0.08536608268817265
Trained batch 3 in epoch 2, gen_loss = 0.8158460855484009, disc_loss = 0.08016548864543438
Trained batch 4 in epoch 2, gen_loss = 0.8115117430686951, disc_loss = 0.08336193710565568
Trained batch 5 in epoch 2, gen_loss = 0.8180247247219086, disc_loss = 0.07996602356433868
Trained batch 6 in epoch 2, gen_loss = 0.8566649385860988, disc_loss = 0.07697740889021329
Trained batch 7 in epoch 2, gen_loss = 0.8395925536751747, disc_loss = 0.07460298063233495
Trained batch 8 in epoch 2, gen_loss = 0.8350323041280111, disc_loss = 0.07989376824763086
Trained batch 9 in epoch 2, gen_loss = 0.8466497778892517, disc_loss = 0.0747515244409442
Trained batch 10 in epoch 2, gen_loss = 0.8334051749923013, disc_loss = 0.07404468394815922
Trained batch 11 in epoch 2, gen_loss = 0.8337900588909785, disc_loss = 0.0749103835163017
Trained batch 12 in epoch 2, gen_loss = 0.8455161773241483, disc_loss = 0.0764574258086773
Trained batch 13 in epoch 2, gen_loss = 0.8440468907356262, disc_loss = 0.07528104699615921
Trained batch 14 in epoch 2, gen_loss = 0.842528780301412, disc_loss = 0.07661457819243273
Trained batch 15 in epoch 2, gen_loss = 0.8587813302874565, disc_loss = 0.07912698911968619
Trained batch 16 in epoch 2, gen_loss = 0.8696351962931016, disc_loss = 0.07600466194836532
Trained batch 17 in epoch 2, gen_loss = 0.874374743964937, disc_loss = 0.07515317108482122
Trained batch 18 in epoch 2, gen_loss = 0.8751359048642611, disc_loss = 0.0725981442159728
Trained batch 19 in epoch 2, gen_loss = 0.8743871033191681, disc_loss = 0.07111922297626734
Trained batch 20 in epoch 2, gen_loss = 0.8809945526577178, disc_loss = 0.07025627401613053
Trained batch 21 in epoch 2, gen_loss = 0.8649938242001967, disc_loss = 0.07171885398301212
Trained batch 22 in epoch 2, gen_loss = 0.8574219916177832, disc_loss = 0.07227154335250026
Trained batch 23 in epoch 2, gen_loss = 0.8580035840471586, disc_loss = 0.07236351662625869
Trained batch 24 in epoch 2, gen_loss = 0.8731611990928649, disc_loss = 0.07094921454787255
Trained batch 25 in epoch 2, gen_loss = 0.8663419187068939, disc_loss = 0.07036616380971211
Trained batch 26 in epoch 2, gen_loss = 0.8589343538990727, disc_loss = 0.07163318177616154
Trained batch 27 in epoch 2, gen_loss = 0.8614302703312465, disc_loss = 0.07562399934977293
Trained batch 28 in epoch 2, gen_loss = 0.8573059419105793, disc_loss = 0.0765035158858217
Trained batch 29 in epoch 2, gen_loss = 0.8465328494707743, disc_loss = 0.07916257840891679
Trained batch 30 in epoch 2, gen_loss = 0.8411525430217865, disc_loss = 0.08072721441426585
Trained batch 31 in epoch 2, gen_loss = 0.8394657652825117, disc_loss = 0.08003430266398937
Trained batch 32 in epoch 2, gen_loss = 0.8458765582604841, disc_loss = 0.0788584358312867
Trained batch 33 in epoch 2, gen_loss = 0.8389389006530538, disc_loss = 0.07945159998010187
Trained batch 34 in epoch 2, gen_loss = 0.8396861127444676, disc_loss = 0.08014365988118308
Trained batch 35 in epoch 2, gen_loss = 0.8456684036387337, disc_loss = 0.07832094287085864
Trained batch 36 in epoch 2, gen_loss = 0.8426186329609638, disc_loss = 0.0780975035819653
Trained batch 37 in epoch 2, gen_loss = 0.8435447749338651, disc_loss = 0.07936269892869811
Trained batch 38 in epoch 2, gen_loss = 0.8402386934329302, disc_loss = 0.0785235164161676
Trained batch 39 in epoch 2, gen_loss = 0.8429826229810715, disc_loss = 0.07688656880054623
Trained batch 40 in epoch 2, gen_loss = 0.8403555503705653, disc_loss = 0.07651408564117623
Trained batch 41 in epoch 2, gen_loss = 0.8359675975072951, disc_loss = 0.07791196308763963
Trained batch 42 in epoch 2, gen_loss = 0.8362645188043284, disc_loss = 0.07819201643470415
Trained batch 43 in epoch 2, gen_loss = 0.8318658823316748, disc_loss = 0.07892137784934179
Trained batch 44 in epoch 2, gen_loss = 0.8331234137217204, disc_loss = 0.07876074100948043
Trained batch 45 in epoch 2, gen_loss = 0.8363446606242139, disc_loss = 0.07814962491798012
Trained batch 46 in epoch 2, gen_loss = 0.8319014589837257, disc_loss = 0.0795722370174654
Trained batch 47 in epoch 2, gen_loss = 0.8396781881650289, disc_loss = 0.08013455470791087
Trained batch 48 in epoch 2, gen_loss = 0.848981998404678, disc_loss = 0.08011972944119147
Trained batch 49 in epoch 2, gen_loss = 0.8478805363178253, disc_loss = 0.08014601299539209
Trained batch 50 in epoch 2, gen_loss = 0.8436266581217448, disc_loss = 0.08116224884767742
Trained batch 51 in epoch 2, gen_loss = 0.847099081828044, disc_loss = 0.08095456855013393
Trained batch 52 in epoch 2, gen_loss = 0.8476490187195113, disc_loss = 0.0799338683521129
Trained batch 53 in epoch 2, gen_loss = 0.8452560427012267, disc_loss = 0.08097095078685218
Trained batch 54 in epoch 2, gen_loss = 0.8432015104727312, disc_loss = 0.08044201489537954
Trained batch 55 in epoch 2, gen_loss = 0.8426994234323502, disc_loss = 0.07932169051907424
Trained batch 56 in epoch 2, gen_loss = 0.8486666825779697, disc_loss = 0.08020288126314418
Trained batch 57 in epoch 2, gen_loss = 0.8424167669024961, disc_loss = 0.08230113785649681
Trained batch 58 in epoch 2, gen_loss = 0.8459722384557886, disc_loss = 0.08129531560244702
Trained batch 59 in epoch 2, gen_loss = 0.8485193048914274, disc_loss = 0.08044332512654365
Trained batch 60 in epoch 2, gen_loss = 0.8478523849463854, disc_loss = 0.07964441630622891
Trained batch 61 in epoch 2, gen_loss = 0.8549975988364988, disc_loss = 0.0795855422263905
Trained batch 62 in epoch 2, gen_loss = 0.8555934244678134, disc_loss = 0.0785469590050597
Trained batch 63 in epoch 2, gen_loss = 0.8519599116407335, disc_loss = 0.07989104696025606
Trained batch 64 in epoch 2, gen_loss = 0.8518905442494612, disc_loss = 0.0811932258737775
Trained batch 65 in epoch 2, gen_loss = 0.8517430916880117, disc_loss = 0.08052344562372926
Trained batch 66 in epoch 2, gen_loss = 0.8492695684753248, disc_loss = 0.08093046428941524
Trained batch 67 in epoch 2, gen_loss = 0.8483980994890717, disc_loss = 0.08130419274846859
Trained batch 68 in epoch 2, gen_loss = 0.8491987365743389, disc_loss = 0.08168753677898127
Trained batch 69 in epoch 2, gen_loss = 0.8493610045739582, disc_loss = 0.08252586806192994
Trained batch 70 in epoch 2, gen_loss = 0.8510338483561932, disc_loss = 0.0831028854631832
Trained batch 71 in epoch 2, gen_loss = 0.8474859872625934, disc_loss = 0.084728119468006
Trained batch 72 in epoch 2, gen_loss = 0.8486945102476093, disc_loss = 0.084193265945842
Trained batch 73 in epoch 2, gen_loss = 0.8504906067171613, disc_loss = 0.08392325158205789
Trained batch 74 in epoch 2, gen_loss = 0.851273854970932, disc_loss = 0.08321242505063613
Trained batch 75 in epoch 2, gen_loss = 0.8492025015385527, disc_loss = 0.08306414706289376
Trained batch 76 in epoch 2, gen_loss = 0.8494268822205531, disc_loss = 0.08292523039770978
Trained batch 77 in epoch 2, gen_loss = 0.8494209612791355, disc_loss = 0.08285885393762818
Trained batch 78 in epoch 2, gen_loss = 0.8473151827914805, disc_loss = 0.08265874217724122
Trained batch 79 in epoch 2, gen_loss = 0.8485627796500921, disc_loss = 0.08227037260076031
Trained batch 80 in epoch 2, gen_loss = 0.8501884823228106, disc_loss = 0.08146708744957491
Trained batch 81 in epoch 2, gen_loss = 0.8496743662328254, disc_loss = 0.08113615797469165
Trained batch 82 in epoch 2, gen_loss = 0.8488085460231964, disc_loss = 0.08063615258244505
Trained batch 83 in epoch 2, gen_loss = 0.8533560509483019, disc_loss = 0.08106061790715016
Trained batch 84 in epoch 2, gen_loss = 0.8505636976045721, disc_loss = 0.08272065162001287
Trained batch 85 in epoch 2, gen_loss = 0.8501209502303323, disc_loss = 0.08232270598108339
Trained batch 86 in epoch 2, gen_loss = 0.8532889009207144, disc_loss = 0.08243653855832486
Trained batch 87 in epoch 2, gen_loss = 0.8505779487842863, disc_loss = 0.08284499192483384
Trained batch 88 in epoch 2, gen_loss = 0.8483332405599315, disc_loss = 0.08326818116971951
Trained batch 89 in epoch 2, gen_loss = 0.8504484319024616, disc_loss = 0.08352364418614242
Trained batch 90 in epoch 2, gen_loss = 0.849993388403903, disc_loss = 0.08316427269684416
Trained batch 91 in epoch 2, gen_loss = 0.8535226761646892, disc_loss = 0.08329095170104309
Trained batch 92 in epoch 2, gen_loss = 0.8527290997325733, disc_loss = 0.08318669297882626
Trained batch 93 in epoch 2, gen_loss = 0.8515591694319502, disc_loss = 0.08303412871356024
Trained batch 94 in epoch 2, gen_loss = 0.8514967783501274, disc_loss = 0.08245695851939289
Trained batch 95 in epoch 2, gen_loss = 0.8500819786762198, disc_loss = 0.08279159019972819
Trained batch 96 in epoch 2, gen_loss = 0.8571956216060009, disc_loss = 0.08499933248289775
Trained batch 97 in epoch 2, gen_loss = 0.8575287227119718, disc_loss = 0.08512243422280465
Trained batch 98 in epoch 2, gen_loss = 0.853373775879542, disc_loss = 0.08677994187996545
Trained batch 99 in epoch 2, gen_loss = 0.8544250884652138, disc_loss = 0.08691227718256414
Trained batch 100 in epoch 2, gen_loss = 0.8551738707735987, disc_loss = 0.08636681166578933
Trained batch 101 in epoch 2, gen_loss = 0.8528289862123191, disc_loss = 0.08700964591630242
Trained batch 102 in epoch 2, gen_loss = 0.8539096982155031, disc_loss = 0.0868741558792377
Trained batch 103 in epoch 2, gen_loss = 0.852530610962556, disc_loss = 0.08654068459649213
Trained batch 104 in epoch 2, gen_loss = 0.85144930879275, disc_loss = 0.08643879754734891
Trained batch 105 in epoch 2, gen_loss = 0.8501883888582014, disc_loss = 0.08646280268418058
Trained batch 106 in epoch 2, gen_loss = 0.8508927574224561, disc_loss = 0.08692565134717761
Trained batch 107 in epoch 2, gen_loss = 0.8499067549904188, disc_loss = 0.08703819357928026
Trained batch 108 in epoch 2, gen_loss = 0.8489225886830496, disc_loss = 0.08672410091641572
Trained batch 109 in epoch 2, gen_loss = 0.8472145440903577, disc_loss = 0.08731087587604469
Trained batch 110 in epoch 2, gen_loss = 0.8488953148459529, disc_loss = 0.08763810286617225
Trained batch 111 in epoch 2, gen_loss = 0.8471091743558645, disc_loss = 0.08804797732903223
Trained batch 112 in epoch 2, gen_loss = 0.8490785647810033, disc_loss = 0.08835937444582186
Trained batch 113 in epoch 2, gen_loss = 0.8461741792005405, disc_loss = 0.08898282056805074
Trained batch 114 in epoch 2, gen_loss = 0.8454109256682188, disc_loss = 0.08871788508056298
Trained batch 115 in epoch 2, gen_loss = 0.845029970952149, disc_loss = 0.08855038273533614
Trained batch 116 in epoch 2, gen_loss = 0.8449521311837384, disc_loss = 0.0886474180027333
Trained batch 117 in epoch 2, gen_loss = 0.8447623598878666, disc_loss = 0.0883737834943932
Trained batch 118 in epoch 2, gen_loss = 0.8422825859875238, disc_loss = 0.08942049875573702
Trained batch 119 in epoch 2, gen_loss = 0.8418433311084906, disc_loss = 0.08910391364091387
Trained batch 120 in epoch 2, gen_loss = 0.8426968157291412, disc_loss = 0.08932107732408057
Trained batch 121 in epoch 2, gen_loss = 0.842580259579127, disc_loss = 0.0895515555347942
Trained batch 122 in epoch 2, gen_loss = 0.8429663333950973, disc_loss = 0.08919373590014572
Trained batch 123 in epoch 2, gen_loss = 0.8420628912506565, disc_loss = 0.08931385676917289
Trained batch 124 in epoch 2, gen_loss = 0.8421817729473114, disc_loss = 0.08893014561384917
Trained batch 125 in epoch 2, gen_loss = 0.8439087562617802, disc_loss = 0.08857263068092011
Trained batch 126 in epoch 2, gen_loss = 0.8416239311845284, disc_loss = 0.08938573722500266
Trained batch 127 in epoch 2, gen_loss = 0.845275113126263, disc_loss = 0.08967640448099701
Trained batch 128 in epoch 2, gen_loss = 0.8440833010876826, disc_loss = 0.08969592273437468
Trained batch 129 in epoch 2, gen_loss = 0.8443260947099098, disc_loss = 0.0893602004346366
Trained batch 130 in epoch 2, gen_loss = 0.8429368554635812, disc_loss = 0.08957187631629578
Trained batch 131 in epoch 2, gen_loss = 0.8409225617845854, disc_loss = 0.08982927746591017
Trained batch 132 in epoch 2, gen_loss = 0.8413226526034506, disc_loss = 0.09010700062897645
Trained batch 133 in epoch 2, gen_loss = 0.8417860111638681, disc_loss = 0.08955040366263754
Trained batch 134 in epoch 2, gen_loss = 0.8404774367809296, disc_loss = 0.08942130846143873
Trained batch 135 in epoch 2, gen_loss = 0.8385635857634685, disc_loss = 0.09011274924748303
Trained batch 136 in epoch 2, gen_loss = 0.8400238071479936, disc_loss = 0.09054179628971067
Trained batch 137 in epoch 2, gen_loss = 0.8395205725362336, disc_loss = 0.09037341288817317
Trained batch 138 in epoch 2, gen_loss = 0.8382712870621852, disc_loss = 0.09034930875109469
Trained batch 139 in epoch 2, gen_loss = 0.8398381243859019, disc_loss = 0.09006022521560746
Trained batch 140 in epoch 2, gen_loss = 0.839651069108476, disc_loss = 0.08964737788080535
Trained batch 141 in epoch 2, gen_loss = 0.837268579383971, disc_loss = 0.08998553730993414
Trained batch 142 in epoch 2, gen_loss = 0.8367128607693252, disc_loss = 0.08977077420071497
Trained batch 143 in epoch 2, gen_loss = 0.8382253483351734, disc_loss = 0.09082483632826349
Trained batch 144 in epoch 2, gen_loss = 0.837062610634442, disc_loss = 0.09138834741737308
Trained batch 145 in epoch 2, gen_loss = 0.8369296260484277, disc_loss = 0.09125334359322713
Trained batch 146 in epoch 2, gen_loss = 0.8368698924171681, disc_loss = 0.09088516390571992
Trained batch 147 in epoch 2, gen_loss = 0.8365713533114743, disc_loss = 0.09076033686791118
Trained batch 148 in epoch 2, gen_loss = 0.8371119569211998, disc_loss = 0.09034953847052467
Trained batch 149 in epoch 2, gen_loss = 0.8363700236876805, disc_loss = 0.08993345579132438
Trained batch 150 in epoch 2, gen_loss = 0.8356399103900455, disc_loss = 0.08974295068186837
Trained batch 151 in epoch 2, gen_loss = 0.8354246735964951, disc_loss = 0.08939122085729123
Trained batch 152 in epoch 2, gen_loss = 0.8364552167895573, disc_loss = 0.09061338105452021
Trained batch 153 in epoch 2, gen_loss = 0.8354898902115884, disc_loss = 0.09083869260457622
Trained batch 154 in epoch 2, gen_loss = 0.834603347509138, disc_loss = 0.0908396921390968
Trained batch 155 in epoch 2, gen_loss = 0.8345131008670881, disc_loss = 0.0905230487159525
Trained batch 156 in epoch 2, gen_loss = 0.8344300930287428, disc_loss = 0.09042111528550933
Trained batch 157 in epoch 2, gen_loss = 0.832853685262837, disc_loss = 0.09089174919136905
Trained batch 158 in epoch 2, gen_loss = 0.8334909773097848, disc_loss = 0.09137163433662188
Trained batch 159 in epoch 2, gen_loss = 0.832678540982306, disc_loss = 0.09154421440907753
Trained batch 160 in epoch 2, gen_loss = 0.8315352995573364, disc_loss = 0.09137994653157751
Trained batch 161 in epoch 2, gen_loss = 0.8311830900701476, disc_loss = 0.09145526445965156
Trained batch 162 in epoch 2, gen_loss = 0.831240357979675, disc_loss = 0.09139642284531718
Trained batch 163 in epoch 2, gen_loss = 0.8304465087812122, disc_loss = 0.09142254861412434
Trained batch 164 in epoch 2, gen_loss = 0.8306751188003656, disc_loss = 0.09118098540400917
Trained batch 165 in epoch 2, gen_loss = 0.8309180652161678, disc_loss = 0.09080471541081746
Trained batch 166 in epoch 2, gen_loss = 0.8307374185787704, disc_loss = 0.09063837662183061
Trained batch 167 in epoch 2, gen_loss = 0.8296512335184074, disc_loss = 0.09074620413039589
Trained batch 168 in epoch 2, gen_loss = 0.8283817688741627, disc_loss = 0.09076200375476709
Trained batch 169 in epoch 2, gen_loss = 0.8297959031427607, disc_loss = 0.09057287015568684
Trained batch 170 in epoch 2, gen_loss = 0.8298810004142293, disc_loss = 0.09016867313664734
Trained batch 171 in epoch 2, gen_loss = 0.8316678157032922, disc_loss = 0.0898468988936741
Trained batch 172 in epoch 2, gen_loss = 0.8329040964559323, disc_loss = 0.08940828863983553
Trained batch 173 in epoch 2, gen_loss = 0.8325325889491487, disc_loss = 0.0889984371525974
Trained batch 174 in epoch 2, gen_loss = 0.8310750687122345, disc_loss = 0.08940939023026398
Trained batch 175 in epoch 2, gen_loss = 0.831572971391407, disc_loss = 0.08920594134410335
Trained batch 176 in epoch 2, gen_loss = 0.8312078268177765, disc_loss = 0.08938024170949298
Trained batch 177 in epoch 2, gen_loss = 0.8304754788621088, disc_loss = 0.08935444545670507
Trained batch 178 in epoch 2, gen_loss = 0.8305531828430112, disc_loss = 0.08931161141720231
Trained batch 179 in epoch 2, gen_loss = 0.8321716654631827, disc_loss = 0.08904031735534469
Trained batch 180 in epoch 2, gen_loss = 0.8315976527185072, disc_loss = 0.08905554452694911
Trained batch 181 in epoch 2, gen_loss = 0.8306445487580456, disc_loss = 0.08904034199172652
Trained batch 182 in epoch 2, gen_loss = 0.8310550583190606, disc_loss = 0.08932881795195609
Trained batch 183 in epoch 2, gen_loss = 0.8311223382859126, disc_loss = 0.0890343194199807
Trained batch 184 in epoch 2, gen_loss = 0.8307876923599758, disc_loss = 0.08903922528229855
Trained batch 185 in epoch 2, gen_loss = 0.8293215986541522, disc_loss = 0.08942615706473589
Trained batch 186 in epoch 2, gen_loss = 0.8285504115775307, disc_loss = 0.08931665502010501
Trained batch 187 in epoch 2, gen_loss = 0.8306913764235822, disc_loss = 0.08961380349392904
Trained batch 188 in epoch 2, gen_loss = 0.8295937260938069, disc_loss = 0.08996890048698458
Trained batch 189 in epoch 2, gen_loss = 0.8296053756224482, disc_loss = 0.09001039228353061
Trained batch 190 in epoch 2, gen_loss = 0.8302274968923699, disc_loss = 0.08992164579088463
Trained batch 191 in epoch 2, gen_loss = 0.8301920873733858, disc_loss = 0.09001735552252892
Trained batch 192 in epoch 2, gen_loss = 0.8296901884783118, disc_loss = 0.08985488187193562
Trained batch 193 in epoch 2, gen_loss = 0.8307513147592545, disc_loss = 0.0900048111306177
Trained batch 194 in epoch 2, gen_loss = 0.8285482186537523, disc_loss = 0.09086351670706884
Trained batch 195 in epoch 2, gen_loss = 0.8287359819728501, disc_loss = 0.09061817238487456
Trained batch 196 in epoch 2, gen_loss = 0.8302264991145448, disc_loss = 0.09082978077913602
Trained batch 197 in epoch 2, gen_loss = 0.8291198650393823, disc_loss = 0.09095515430237007
Trained batch 198 in epoch 2, gen_loss = 0.8290149878017866, disc_loss = 0.09080915674380022
Trained batch 199 in epoch 2, gen_loss = 0.8288742011785507, disc_loss = 0.09048472411930561
Trained batch 200 in epoch 2, gen_loss = 0.8274601015878554, disc_loss = 0.0912526931928758
Trained batch 201 in epoch 2, gen_loss = 0.8283764914710923, disc_loss = 0.09164094747883259
Trained batch 202 in epoch 2, gen_loss = 0.8295977990615544, disc_loss = 0.09147527193641428
Trained batch 203 in epoch 2, gen_loss = 0.8286228250054752, disc_loss = 0.09191764924017821
Trained batch 204 in epoch 2, gen_loss = 0.8274096456969656, disc_loss = 0.09227133505954975
Trained batch 205 in epoch 2, gen_loss = 0.8278994418463661, disc_loss = 0.09272366729610175
Trained batch 206 in epoch 2, gen_loss = 0.8280294531785347, disc_loss = 0.09241684653980721
Trained batch 207 in epoch 2, gen_loss = 0.8275693500271211, disc_loss = 0.09235720044503418
Trained batch 208 in epoch 2, gen_loss = 0.8264584786583933, disc_loss = 0.092519118900647
Trained batch 209 in epoch 2, gen_loss = 0.8270239052318391, disc_loss = 0.09274505336014997
Trained batch 210 in epoch 2, gen_loss = 0.8277847975916207, disc_loss = 0.09251800636756477
Trained batch 211 in epoch 2, gen_loss = 0.8271628081236245, disc_loss = 0.09245838493741346
Trained batch 212 in epoch 2, gen_loss = 0.8270286293656613, disc_loss = 0.09219051210183493
Trained batch 213 in epoch 2, gen_loss = 0.8278571111019527, disc_loss = 0.09195487208176996
Trained batch 214 in epoch 2, gen_loss = 0.826513804391373, disc_loss = 0.09190573033898376
Trained batch 215 in epoch 2, gen_loss = 0.8264897101455264, disc_loss = 0.09174617617908451
Trained batch 216 in epoch 2, gen_loss = 0.8263447408302589, disc_loss = 0.09162045634149955
Trained batch 217 in epoch 2, gen_loss = 0.827137285963111, disc_loss = 0.0919796750291225
Trained batch 218 in epoch 2, gen_loss = 0.8259497897265708, disc_loss = 0.09270065128122836
Trained batch 219 in epoch 2, gen_loss = 0.8260607109828428, disc_loss = 0.09263057607141408
Trained batch 220 in epoch 2, gen_loss = 0.8253125669729656, disc_loss = 0.09288710510838626
Trained batch 221 in epoch 2, gen_loss = 0.8248795018539773, disc_loss = 0.09276099143935754
Trained batch 222 in epoch 2, gen_loss = 0.8245113836810193, disc_loss = 0.09266542011846876
Trained batch 223 in epoch 2, gen_loss = 0.8251974662499768, disc_loss = 0.09236382268967905
Trained batch 224 in epoch 2, gen_loss = 0.8251353549957275, disc_loss = 0.09216500873366992
Trained batch 225 in epoch 2, gen_loss = 0.8247755644595729, disc_loss = 0.09214761063654338
Trained batch 226 in epoch 2, gen_loss = 0.8255272951420183, disc_loss = 0.09203547109656922
Trained batch 227 in epoch 2, gen_loss = 0.8243939319723531, disc_loss = 0.09238793892099668
Trained batch 228 in epoch 2, gen_loss = 0.8250925697093447, disc_loss = 0.09226357561076573
Trained batch 229 in epoch 2, gen_loss = 0.8258666883344236, disc_loss = 0.0920465754426044
Trained batch 230 in epoch 2, gen_loss = 0.8259556701172998, disc_loss = 0.09176947290956716
Trained batch 231 in epoch 2, gen_loss = 0.8254658117376524, disc_loss = 0.09173680673321259
Trained batch 232 in epoch 2, gen_loss = 0.8258297745250326, disc_loss = 0.09181058379649604
Trained batch 233 in epoch 2, gen_loss = 0.825316805105943, disc_loss = 0.0918016443745448
Trained batch 234 in epoch 2, gen_loss = 0.825885450079086, disc_loss = 0.09173071446253898
Trained batch 235 in epoch 2, gen_loss = 0.8252661983340474, disc_loss = 0.09192737082998126
Trained batch 236 in epoch 2, gen_loss = 0.8251242152246242, disc_loss = 0.09225715242546319
Trained batch 237 in epoch 2, gen_loss = 0.8258672449268213, disc_loss = 0.09277465818997692
Trained batch 238 in epoch 2, gen_loss = 0.8264227788817433, disc_loss = 0.09255289325342518
Trained batch 239 in epoch 2, gen_loss = 0.8262368110318978, disc_loss = 0.09233979542429248
Trained batch 240 in epoch 2, gen_loss = 0.8255612832876656, disc_loss = 0.0923646529247652
Trained batch 241 in epoch 2, gen_loss = 0.8254025598202855, disc_loss = 0.09228066647471475
Trained batch 242 in epoch 2, gen_loss = 0.8252858001999404, disc_loss = 0.0924020676026619
Trained batch 243 in epoch 2, gen_loss = 0.8249060980609206, disc_loss = 0.09240172595762816
Trained batch 244 in epoch 2, gen_loss = 0.8248648765135784, disc_loss = 0.09222685969909843
Trained batch 245 in epoch 2, gen_loss = 0.8257865779768161, disc_loss = 0.0924151137138043
Trained batch 246 in epoch 2, gen_loss = 0.8248268824357253, disc_loss = 0.09265951837906954
Trained batch 247 in epoch 2, gen_loss = 0.8257407882521229, disc_loss = 0.09275636393877287
Trained batch 248 in epoch 2, gen_loss = 0.8261047932038824, disc_loss = 0.09244532987520278
Trained batch 249 in epoch 2, gen_loss = 0.8261375155448913, disc_loss = 0.09215886409208178
Trained batch 250 in epoch 2, gen_loss = 0.825762039399242, disc_loss = 0.0920807725278683
Trained batch 251 in epoch 2, gen_loss = 0.8255027584613316, disc_loss = 0.09209760616622156
Trained batch 252 in epoch 2, gen_loss = 0.8263127285501232, disc_loss = 0.09220672152538897
Trained batch 253 in epoch 2, gen_loss = 0.8265467363549029, disc_loss = 0.09190207811835127
Trained batch 254 in epoch 2, gen_loss = 0.825873518223856, disc_loss = 0.09177427468273569
Trained batch 255 in epoch 2, gen_loss = 0.8255321483593434, disc_loss = 0.09168894106915104
Trained batch 256 in epoch 2, gen_loss = 0.8251461595412822, disc_loss = 0.0916742033176559
Trained batch 257 in epoch 2, gen_loss = 0.8265396058559418, disc_loss = 0.09208711780708774
Trained batch 258 in epoch 2, gen_loss = 0.8257790394271203, disc_loss = 0.0924759049320946
Trained batch 259 in epoch 2, gen_loss = 0.8262541188643528, disc_loss = 0.09254440316715493
Trained batch 260 in epoch 2, gen_loss = 0.8260090922030453, disc_loss = 0.09231289303094377
Trained batch 261 in epoch 2, gen_loss = 0.8252695598675095, disc_loss = 0.09229963043534005
Trained batch 262 in epoch 2, gen_loss = 0.8250333252061909, disc_loss = 0.09248445478724776
Trained batch 263 in epoch 2, gen_loss = 0.8253074238697687, disc_loss = 0.09234409465694404
Trained batch 264 in epoch 2, gen_loss = 0.8246630344750746, disc_loss = 0.09256120742702821
Trained batch 265 in epoch 2, gen_loss = 0.8245758622660673, disc_loss = 0.09257667794249448
Trained batch 266 in epoch 2, gen_loss = 0.8246947274672405, disc_loss = 0.09240165704072972
Trained batch 267 in epoch 2, gen_loss = 0.8240049283451109, disc_loss = 0.09251419232060104
Trained batch 268 in epoch 2, gen_loss = 0.8241322426104635, disc_loss = 0.09236834200659981
Trained batch 269 in epoch 2, gen_loss = 0.8238707546834593, disc_loss = 0.0924109448954739
Trained batch 270 in epoch 2, gen_loss = 0.8240305917729311, disc_loss = 0.09219238356896763
Trained batch 271 in epoch 2, gen_loss = 0.8228177971699658, disc_loss = 0.09229025038931628
Trained batch 272 in epoch 2, gen_loss = 0.8236398120502849, disc_loss = 0.09217554097142303
Trained batch 273 in epoch 2, gen_loss = 0.8239213049846844, disc_loss = 0.09236713815276532
Trained batch 274 in epoch 2, gen_loss = 0.8233445193550804, disc_loss = 0.09254987230016426
Trained batch 275 in epoch 2, gen_loss = 0.8232572832401248, disc_loss = 0.09243562664715169
Trained batch 276 in epoch 2, gen_loss = 0.8238920874974357, disc_loss = 0.09242377043886628
Trained batch 277 in epoch 2, gen_loss = 0.8240593395216002, disc_loss = 0.09222796290992297
Trained batch 278 in epoch 2, gen_loss = 0.8240428613932756, disc_loss = 0.09215436202530686
Trained batch 279 in epoch 2, gen_loss = 0.8240468725562096, disc_loss = 0.09209385689547551
Trained batch 280 in epoch 2, gen_loss = 0.8244030375921854, disc_loss = 0.09191568028446936
Trained batch 281 in epoch 2, gen_loss = 0.8253464252813488, disc_loss = 0.09188944042878265
Trained batch 282 in epoch 2, gen_loss = 0.8254462476332701, disc_loss = 0.09166807450630535
Trained batch 283 in epoch 2, gen_loss = 0.8247365703884985, disc_loss = 0.09217263095435017
Trained batch 284 in epoch 2, gen_loss = 0.8251833518346151, disc_loss = 0.09212010556080362
Trained batch 285 in epoch 2, gen_loss = 0.8271705808339419, disc_loss = 0.09207702220671556
Trained batch 286 in epoch 2, gen_loss = 0.8269681980385598, disc_loss = 0.09202379378642667
Trained batch 287 in epoch 2, gen_loss = 0.8265409715887573, disc_loss = 0.09199832815405291
Trained batch 288 in epoch 2, gen_loss = 0.8259385997448826, disc_loss = 0.09206148797394804
Trained batch 289 in epoch 2, gen_loss = 0.8274183511734009, disc_loss = 0.09229089916715848
Trained batch 290 in epoch 2, gen_loss = 0.8270113605404228, disc_loss = 0.09234867653012582
Trained batch 291 in epoch 2, gen_loss = 0.8258308489641099, disc_loss = 0.09290133055286763
Trained batch 292 in epoch 2, gen_loss = 0.8253048551570841, disc_loss = 0.09289102928566749
Trained batch 293 in epoch 2, gen_loss = 0.8258780728594787, disc_loss = 0.09276897706991048
Trained batch 294 in epoch 2, gen_loss = 0.8261586933822955, disc_loss = 0.09254687357441349
Trained batch 295 in epoch 2, gen_loss = 0.8260675601258471, disc_loss = 0.09237354102456388
Trained batch 296 in epoch 2, gen_loss = 0.8259101986684382, disc_loss = 0.09215306673474886
Trained batch 297 in epoch 2, gen_loss = 0.8258834616249839, disc_loss = 0.09200492625956068
Trained batch 298 in epoch 2, gen_loss = 0.8258069286178984, disc_loss = 0.09178930760538798
Trained batch 299 in epoch 2, gen_loss = 0.8257134156425794, disc_loss = 0.09157176008758446
Trained batch 300 in epoch 2, gen_loss = 0.8258851359650938, disc_loss = 0.09143149561598353
Trained batch 301 in epoch 2, gen_loss = 0.8261225735706998, disc_loss = 0.09128998669900543
Trained batch 302 in epoch 2, gen_loss = 0.8261291277487286, disc_loss = 0.09124247322516768
Trained batch 303 in epoch 2, gen_loss = 0.8260456312839922, disc_loss = 0.09104886840673555
Trained batch 304 in epoch 2, gen_loss = 0.8255089387541912, disc_loss = 0.09112379544521453
Trained batch 305 in epoch 2, gen_loss = 0.8264086490947437, disc_loss = 0.0911303533977689
Trained batch 306 in epoch 2, gen_loss = 0.8260218179769547, disc_loss = 0.09100788012328967
Trained batch 307 in epoch 2, gen_loss = 0.8258055989424904, disc_loss = 0.09087525517074996
Trained batch 308 in epoch 2, gen_loss = 0.8252000545413749, disc_loss = 0.09086830394107451
Trained batch 309 in epoch 2, gen_loss = 0.8253847613450019, disc_loss = 0.09080700560382778
Trained batch 310 in epoch 2, gen_loss = 0.825888189184704, disc_loss = 0.09057944650399435
Trained batch 311 in epoch 2, gen_loss = 0.8264447243358845, disc_loss = 0.09038338616478424
Trained batch 312 in epoch 2, gen_loss = 0.8261053698321882, disc_loss = 0.09025628837093283
Trained batch 313 in epoch 2, gen_loss = 0.8264063212332452, disc_loss = 0.09013990598440075
Trained batch 314 in epoch 2, gen_loss = 0.8255094890556638, disc_loss = 0.09023406227370576
Trained batch 315 in epoch 2, gen_loss = 0.8245928463867948, disc_loss = 0.09042947636504622
Trained batch 316 in epoch 2, gen_loss = 0.8248425976899144, disc_loss = 0.09062928770748128
Trained batch 317 in epoch 2, gen_loss = 0.8255638100628583, disc_loss = 0.09043565924050954
Trained batch 318 in epoch 2, gen_loss = 0.8253783601391652, disc_loss = 0.09031861025232786
Trained batch 319 in epoch 2, gen_loss = 0.8261395615525544, disc_loss = 0.09015511701290961
Trained batch 320 in epoch 2, gen_loss = 0.8267554550713097, disc_loss = 0.08993713447760292
Trained batch 321 in epoch 2, gen_loss = 0.826780220273859, disc_loss = 0.0897672342871148
Trained batch 322 in epoch 2, gen_loss = 0.8264434142932066, disc_loss = 0.08964296076562106
Trained batch 323 in epoch 2, gen_loss = 0.8265620327474158, disc_loss = 0.08963974557506542
Trained batch 324 in epoch 2, gen_loss = 0.8272122934231392, disc_loss = 0.08943346933963207
Trained batch 325 in epoch 2, gen_loss = 0.8266832950107891, disc_loss = 0.08945434403668609
Trained batch 326 in epoch 2, gen_loss = 0.8268886163876327, disc_loss = 0.089282274568049
Trained batch 327 in epoch 2, gen_loss = 0.8271344085110397, disc_loss = 0.089551728312494
Trained batch 328 in epoch 2, gen_loss = 0.8267392053249034, disc_loss = 0.08947696555179394
Trained batch 329 in epoch 2, gen_loss = 0.8264908554879102, disc_loss = 0.0893588873952853
Trained batch 330 in epoch 2, gen_loss = 0.8269895328675873, disc_loss = 0.08916755314083528
Trained batch 331 in epoch 2, gen_loss = 0.8260988181075418, disc_loss = 0.08951392119851367
Trained batch 332 in epoch 2, gen_loss = 0.826346581494128, disc_loss = 0.08934393480095688
Trained batch 333 in epoch 2, gen_loss = 0.8277284582396467, disc_loss = 0.0895049335507531
Trained batch 334 in epoch 2, gen_loss = 0.8270182421847956, disc_loss = 0.08963115731004014
Trained batch 335 in epoch 2, gen_loss = 0.8269459708992924, disc_loss = 0.08948336199890557
Trained batch 336 in epoch 2, gen_loss = 0.8268360816583435, disc_loss = 0.08939153687525485
Trained batch 337 in epoch 2, gen_loss = 0.8267071794652374, disc_loss = 0.08932520135873433
Trained batch 338 in epoch 2, gen_loss = 0.8272597344048256, disc_loss = 0.08916767076438067
Trained batch 339 in epoch 2, gen_loss = 0.8279188847717117, disc_loss = 0.08893176986945464
Trained batch 340 in epoch 2, gen_loss = 0.8275960731890893, disc_loss = 0.08883601022048518
Trained batch 341 in epoch 2, gen_loss = 0.8273251352080128, disc_loss = 0.0886765572525648
Trained batch 342 in epoch 2, gen_loss = 0.8278347850714759, disc_loss = 0.0884894459120082
Trained batch 343 in epoch 2, gen_loss = 0.8275628588054069, disc_loss = 0.08844932483043522
Trained batch 344 in epoch 2, gen_loss = 0.8277972858021225, disc_loss = 0.08832432634426632
Trained batch 345 in epoch 2, gen_loss = 0.8288367077966646, disc_loss = 0.08821749616403542
Trained batch 346 in epoch 2, gen_loss = 0.828942505959475, disc_loss = 0.0880223432802716
Trained batch 347 in epoch 2, gen_loss = 0.8284071422685152, disc_loss = 0.08822528530051396
Trained batch 348 in epoch 2, gen_loss = 0.8284789854100235, disc_loss = 0.08822077111658616
Trained batch 349 in epoch 2, gen_loss = 0.8286366300071989, disc_loss = 0.08813136311780129
Trained batch 350 in epoch 2, gen_loss = 0.8283189704105725, disc_loss = 0.08818744866182747
Trained batch 351 in epoch 2, gen_loss = 0.8281944880939343, disc_loss = 0.08825787085119043
Trained batch 352 in epoch 2, gen_loss = 0.8286641416569945, disc_loss = 0.08864191601121477
Trained batch 353 in epoch 2, gen_loss = 0.8285023316656802, disc_loss = 0.08941979020423556
Trained batch 354 in epoch 2, gen_loss = 0.8284467303417098, disc_loss = 0.08997257263989936
Trained batch 355 in epoch 2, gen_loss = 0.828407583025734, disc_loss = 0.09030405210404333
Trained batch 356 in epoch 2, gen_loss = 0.8288208073427697, disc_loss = 0.09053807490940939
Trained batch 357 in epoch 2, gen_loss = 0.828521852469977, disc_loss = 0.090679654614823
Trained batch 358 in epoch 2, gen_loss = 0.8283508271394002, disc_loss = 0.09067252693661491
Trained batch 359 in epoch 2, gen_loss = 0.8288586976627509, disc_loss = 0.0906736954037721
Trained batch 360 in epoch 2, gen_loss = 0.8288603506755301, disc_loss = 0.09059424267261394
Trained batch 361 in epoch 2, gen_loss = 0.8292504982889027, disc_loss = 0.09046964672810877
Trained batch 362 in epoch 2, gen_loss = 0.8283674435346251, disc_loss = 0.09098814879659532
Trained batch 363 in epoch 2, gen_loss = 0.8296583027138815, disc_loss = 0.09206551563373389
Trained batch 364 in epoch 2, gen_loss = 0.8298885302184379, disc_loss = 0.09196180029938074
Trained batch 365 in epoch 2, gen_loss = 0.8296449050062993, disc_loss = 0.09191939682837148
Trained batch 366 in epoch 2, gen_loss = 0.8288751544192312, disc_loss = 0.0923597809429755
Trained batch 367 in epoch 2, gen_loss = 0.8293094572651646, disc_loss = 0.09225709115043687
Trained batch 368 in epoch 2, gen_loss = 0.8292176748517406, disc_loss = 0.09214629619798767
Trained batch 369 in epoch 2, gen_loss = 0.829065360169153, disc_loss = 0.09218347261131213
Trained batch 370 in epoch 2, gen_loss = 0.8291038707742151, disc_loss = 0.0920383997507534
Trained batch 371 in epoch 2, gen_loss = 0.8286666417474388, disc_loss = 0.0918961609388271
Trained batch 372 in epoch 2, gen_loss = 0.8282752643481656, disc_loss = 0.0918827952377638
Trained batch 373 in epoch 2, gen_loss = 0.8286485277554568, disc_loss = 0.09185662357893618
Trained batch 374 in epoch 2, gen_loss = 0.8287871069113414, disc_loss = 0.09176861777156592
Trained batch 375 in epoch 2, gen_loss = 0.8282109702679705, disc_loss = 0.09182935945461801
Trained batch 376 in epoch 2, gen_loss = 0.8278450936632384, disc_loss = 0.09174419435813272
Trained batch 377 in epoch 2, gen_loss = 0.8280452462258162, disc_loss = 0.09203190725326302
Trained batch 378 in epoch 2, gen_loss = 0.8280915821605118, disc_loss = 0.09186058246965537
Trained batch 379 in epoch 2, gen_loss = 0.8279811878737651, disc_loss = 0.09170936623735255
Trained batch 380 in epoch 2, gen_loss = 0.8279985393595508, disc_loss = 0.0915281939836038
Trained batch 381 in epoch 2, gen_loss = 0.8273796812870116, disc_loss = 0.09156503996699658
Trained batch 382 in epoch 2, gen_loss = 0.8275174278347672, disc_loss = 0.0915466312041832
Trained batch 383 in epoch 2, gen_loss = 0.8272135759859035, disc_loss = 0.09160798716523762
Trained batch 384 in epoch 2, gen_loss = 0.8273566847497766, disc_loss = 0.09147416686324718
Trained batch 385 in epoch 2, gen_loss = 0.8277856124651864, disc_loss = 0.09131616239865441
Trained batch 386 in epoch 2, gen_loss = 0.8282230990031585, disc_loss = 0.09111533859547334
Trained batch 387 in epoch 2, gen_loss = 0.8285611784181643, disc_loss = 0.09090358318434548
Trained batch 388 in epoch 2, gen_loss = 0.8278665578610487, disc_loss = 0.0909931755847367
Trained batch 389 in epoch 2, gen_loss = 0.8276705591342388, disc_loss = 0.09098790916494834
Trained batch 390 in epoch 2, gen_loss = 0.8290634477687309, disc_loss = 0.09213271716137982
Trained batch 391 in epoch 2, gen_loss = 0.8284645516197292, disc_loss = 0.0923639983508964
Trained batch 392 in epoch 2, gen_loss = 0.8278732491661878, disc_loss = 0.0923747840425137
Trained batch 393 in epoch 2, gen_loss = 0.8279145133828149, disc_loss = 0.09253448629893628
Trained batch 394 in epoch 2, gen_loss = 0.8275190296806867, disc_loss = 0.09264377876173092
Trained batch 395 in epoch 2, gen_loss = 0.8275045199376164, disc_loss = 0.09267049670369938
Trained batch 396 in epoch 2, gen_loss = 0.8269591662535439, disc_loss = 0.09284337379169705
Trained batch 397 in epoch 2, gen_loss = 0.8271264058710942, disc_loss = 0.09275076180771367
Trained batch 398 in epoch 2, gen_loss = 0.8270360974590283, disc_loss = 0.09283007601075303
Trained batch 399 in epoch 2, gen_loss = 0.8268330276757478, disc_loss = 0.09268610863946378
Trained batch 400 in epoch 2, gen_loss = 0.8261741147820194, disc_loss = 0.09281325053209973
Trained batch 401 in epoch 2, gen_loss = 0.8267563344975609, disc_loss = 0.09297321368917007
Trained batch 402 in epoch 2, gen_loss = 0.8264895487512016, disc_loss = 0.09291479900183512
Trained batch 403 in epoch 2, gen_loss = 0.8256863813736651, disc_loss = 0.09320114548364193
Trained batch 404 in epoch 2, gen_loss = 0.825554151373145, disc_loss = 0.0931516908477118
Trained batch 405 in epoch 2, gen_loss = 0.8254294208264703, disc_loss = 0.09326947497873764
Trained batch 406 in epoch 2, gen_loss = 0.8250476059661743, disc_loss = 0.09331906137470825
Trained batch 407 in epoch 2, gen_loss = 0.8253029779914547, disc_loss = 0.09335632204972938
Trained batch 408 in epoch 2, gen_loss = 0.8248836219602226, disc_loss = 0.09336604437538056
Trained batch 409 in epoch 2, gen_loss = 0.8249003634947102, disc_loss = 0.09337085540883425
Trained batch 410 in epoch 2, gen_loss = 0.8246305788665502, disc_loss = 0.09334112077480106
Trained batch 411 in epoch 2, gen_loss = 0.8250908642573264, disc_loss = 0.09320024117031722
Trained batch 412 in epoch 2, gen_loss = 0.8248737264632025, disc_loss = 0.09312828153949096
Trained batch 413 in epoch 2, gen_loss = 0.824534314626081, disc_loss = 0.0930189723463882
Trained batch 414 in epoch 2, gen_loss = 0.8247293587908687, disc_loss = 0.0929037435586194
Trained batch 415 in epoch 2, gen_loss = 0.8244335507400907, disc_loss = 0.092907509014297
Trained batch 416 in epoch 2, gen_loss = 0.8243018615302994, disc_loss = 0.0928125388527231
Trained batch 417 in epoch 2, gen_loss = 0.8234680555226129, disc_loss = 0.09297565238006662
Trained batch 418 in epoch 2, gen_loss = 0.8233983548700383, disc_loss = 0.09297925983344456
Trained batch 419 in epoch 2, gen_loss = 0.8231349826568649, disc_loss = 0.0929704714300377
Trained batch 420 in epoch 2, gen_loss = 0.822852796514357, disc_loss = 0.09297902339675647
Trained batch 421 in epoch 2, gen_loss = 0.8229391267655585, disc_loss = 0.09286678900227162
Trained batch 422 in epoch 2, gen_loss = 0.8224282269641299, disc_loss = 0.09297785472926237
Trained batch 423 in epoch 2, gen_loss = 0.8229799837858047, disc_loss = 0.09299720995971616
Trained batch 424 in epoch 2, gen_loss = 0.8227002440480625, disc_loss = 0.09289449865327162
Trained batch 425 in epoch 2, gen_loss = 0.8227428923330397, disc_loss = 0.09279807245122715
Trained batch 426 in epoch 2, gen_loss = 0.8224633980271967, disc_loss = 0.09269969262165263
Trained batch 427 in epoch 2, gen_loss = 0.822666848443936, disc_loss = 0.09254009108642273
Trained batch 428 in epoch 2, gen_loss = 0.8225528761084541, disc_loss = 0.09238062887116051
Trained batch 429 in epoch 2, gen_loss = 0.822407461113708, disc_loss = 0.09232323812104241
Trained batch 430 in epoch 2, gen_loss = 0.8231236534301201, disc_loss = 0.09243231432257423
Trained batch 431 in epoch 2, gen_loss = 0.8233312814737912, disc_loss = 0.09225764024261109
Trained batch 432 in epoch 2, gen_loss = 0.8227955765729689, disc_loss = 0.09239397590708925
Trained batch 433 in epoch 2, gen_loss = 0.8229513681291984, disc_loss = 0.09225498723115103
Trained batch 434 in epoch 2, gen_loss = 0.8233175529145647, disc_loss = 0.09230661816552453
Trained batch 435 in epoch 2, gen_loss = 0.8232995208113565, disc_loss = 0.09218679645756653
Trained batch 436 in epoch 2, gen_loss = 0.8228232733035797, disc_loss = 0.09237510399377183
Trained batch 437 in epoch 2, gen_loss = 0.8229644878950293, disc_loss = 0.09224544937156787
Trained batch 438 in epoch 2, gen_loss = 0.8231557571670732, disc_loss = 0.09207857000070852
Trained batch 439 in epoch 2, gen_loss = 0.8232089923864061, disc_loss = 0.09199537062932822
Trained batch 440 in epoch 2, gen_loss = 0.8228504655717992, disc_loss = 0.09195892084094268
Trained batch 441 in epoch 2, gen_loss = 0.8234610013427778, disc_loss = 0.09193979352459783
Trained batch 442 in epoch 2, gen_loss = 0.8233150294214554, disc_loss = 0.0918325402776019
Trained batch 443 in epoch 2, gen_loss = 0.8234792098671466, disc_loss = 0.09170458523288101
Trained batch 444 in epoch 2, gen_loss = 0.8232908138398374, disc_loss = 0.09166043205291367
Trained batch 445 in epoch 2, gen_loss = 0.8231407031751, disc_loss = 0.09154482673218833
Trained batch 446 in epoch 2, gen_loss = 0.8233515015517838, disc_loss = 0.0918210702812845
Trained batch 447 in epoch 2, gen_loss = 0.8230618791255567, disc_loss = 0.09172423181839154
Trained batch 448 in epoch 2, gen_loss = 0.8231498104559553, disc_loss = 0.09160002980190422
Trained batch 449 in epoch 2, gen_loss = 0.8230532343520058, disc_loss = 0.09149620142661863
Trained batch 450 in epoch 2, gen_loss = 0.8231553683127638, disc_loss = 0.09148979648336471
Trained batch 451 in epoch 2, gen_loss = 0.8236121820796908, disc_loss = 0.09153969620923157
Trained batch 452 in epoch 2, gen_loss = 0.8229188053944779, disc_loss = 0.09225893279262068
Trained batch 453 in epoch 2, gen_loss = 0.8231364273946191, disc_loss = 0.09225095968102699
Trained batch 454 in epoch 2, gen_loss = 0.8230869947553991, disc_loss = 0.09220229510504466
Trained batch 455 in epoch 2, gen_loss = 0.8229615383111594, disc_loss = 0.0921271108131725
Trained batch 456 in epoch 2, gen_loss = 0.822460339223269, disc_loss = 0.09210864032661498
Trained batch 457 in epoch 2, gen_loss = 0.8226644574424585, disc_loss = 0.09209571632772164
Trained batch 458 in epoch 2, gen_loss = 0.8223567222587943, disc_loss = 0.09207924611639223
Trained batch 459 in epoch 2, gen_loss = 0.8225824661228968, disc_loss = 0.0919456237603141
Trained batch 460 in epoch 2, gen_loss = 0.8224312932656799, disc_loss = 0.09183820304733553
Trained batch 461 in epoch 2, gen_loss = 0.8225587316792765, disc_loss = 0.0920356112286384
Trained batch 462 in epoch 2, gen_loss = 0.8225770021746535, disc_loss = 0.09188828594805612
Trained batch 463 in epoch 2, gen_loss = 0.8222899410616735, disc_loss = 0.09176898641704485
Trained batch 464 in epoch 2, gen_loss = 0.8223227220837788, disc_loss = 0.09167853481667017
Trained batch 465 in epoch 2, gen_loss = 0.8224947350859131, disc_loss = 0.09155372602169606
Trained batch 466 in epoch 2, gen_loss = 0.8230086938344436, disc_loss = 0.09150186959630162
Trained batch 467 in epoch 2, gen_loss = 0.8230371608311294, disc_loss = 0.09138775253907228
Trained batch 468 in epoch 2, gen_loss = 0.8229530946151026, disc_loss = 0.09134185312589857
Trained batch 469 in epoch 2, gen_loss = 0.8232356140588192, disc_loss = 0.09123023000169307
Trained batch 470 in epoch 2, gen_loss = 0.8232527045560744, disc_loss = 0.09112058242984639
Trained batch 471 in epoch 2, gen_loss = 0.8234921648972116, disc_loss = 0.09106034594509056
Trained batch 472 in epoch 2, gen_loss = 0.8230955327918111, disc_loss = 0.09110810884902644
Trained batch 473 in epoch 2, gen_loss = 0.8231937164118521, disc_loss = 0.09097193027473201
Trained batch 474 in epoch 2, gen_loss = 0.8234998758843071, disc_loss = 0.09112281937348216
Trained batch 475 in epoch 2, gen_loss = 0.8230371850253153, disc_loss = 0.09121471674752836
Trained batch 476 in epoch 2, gen_loss = 0.822824553311246, disc_loss = 0.09109223711321938
Trained batch 477 in epoch 2, gen_loss = 0.8235047848030115, disc_loss = 0.09124743826999075
Trained batch 478 in epoch 2, gen_loss = 0.8229263100718656, disc_loss = 0.09158672875333927
Trained batch 479 in epoch 2, gen_loss = 0.8231627207870285, disc_loss = 0.09155174697904538
Trained batch 480 in epoch 2, gen_loss = 0.8229776808600912, disc_loss = 0.09146632590251752
Trained batch 481 in epoch 2, gen_loss = 0.8228819719612351, disc_loss = 0.09147651114837263
Trained batch 482 in epoch 2, gen_loss = 0.8234015666796801, disc_loss = 0.09134976201792928
Trained batch 483 in epoch 2, gen_loss = 0.8230855800519304, disc_loss = 0.09134472183082715
Trained batch 484 in epoch 2, gen_loss = 0.8235464175337369, disc_loss = 0.09135665090120945
Trained batch 485 in epoch 2, gen_loss = 0.8234349796433508, disc_loss = 0.0912152958780895
Trained batch 486 in epoch 2, gen_loss = 0.823123561834163, disc_loss = 0.09127259308001834
Trained batch 487 in epoch 2, gen_loss = 0.822993801204396, disc_loss = 0.09115555888560951
Trained batch 488 in epoch 2, gen_loss = 0.8230423181944342, disc_loss = 0.09107957018543118
Trained batch 489 in epoch 2, gen_loss = 0.8230691614807869, disc_loss = 0.09104254486001268
Trained batch 490 in epoch 2, gen_loss = 0.8232552318733238, disc_loss = 0.09088536657870969
Trained batch 491 in epoch 2, gen_loss = 0.8228874994608445, disc_loss = 0.09093235741460287
Trained batch 492 in epoch 2, gen_loss = 0.8230625892144913, disc_loss = 0.09081655433382574
Trained batch 493 in epoch 2, gen_loss = 0.8233541161545858, disc_loss = 0.09093163510301878
Trained batch 494 in epoch 2, gen_loss = 0.8230091622983566, disc_loss = 0.09086111224999632
Trained batch 495 in epoch 2, gen_loss = 0.8233031726051723, disc_loss = 0.09076387858236089
Trained batch 496 in epoch 2, gen_loss = 0.8229102879103041, disc_loss = 0.09074959996338161
Trained batch 497 in epoch 2, gen_loss = 0.8231639990725191, disc_loss = 0.09065319714603953
Trained batch 498 in epoch 2, gen_loss = 0.8238133375415343, disc_loss = 0.0905752784193667
Trained batch 499 in epoch 2, gen_loss = 0.8239235087037087, disc_loss = 0.09047983426041901
Trained batch 500 in epoch 2, gen_loss = 0.82396763331162, disc_loss = 0.09034027417419022
Trained batch 501 in epoch 2, gen_loss = 0.8239086039394021, disc_loss = 0.0903398144147934
Trained batch 502 in epoch 2, gen_loss = 0.8236162285089019, disc_loss = 0.09040437580436231
Trained batch 503 in epoch 2, gen_loss = 0.8239272160544282, disc_loss = 0.09035436163974246
Trained batch 504 in epoch 2, gen_loss = 0.8242038460651246, disc_loss = 0.09021947631188254
Trained batch 505 in epoch 2, gen_loss = 0.8241649692355408, disc_loss = 0.09021854482539617
Trained batch 506 in epoch 2, gen_loss = 0.8238560589695353, disc_loss = 0.09020364642532679
Trained batch 507 in epoch 2, gen_loss = 0.8244103114083996, disc_loss = 0.09039315733303294
Trained batch 508 in epoch 2, gen_loss = 0.8242618353170121, disc_loss = 0.09034285459608893
Trained batch 509 in epoch 2, gen_loss = 0.8242037938505995, disc_loss = 0.09027857052381424
Trained batch 510 in epoch 2, gen_loss = 0.8243310403100665, disc_loss = 0.09024001151476413
Trained batch 511 in epoch 2, gen_loss = 0.8241805966827087, disc_loss = 0.0902151668069564
Trained batch 512 in epoch 2, gen_loss = 0.8245028841216662, disc_loss = 0.09026463728644984
Trained batch 513 in epoch 2, gen_loss = 0.8250030001429732, disc_loss = 0.09013868272775633
Trained batch 514 in epoch 2, gen_loss = 0.825210811617305, disc_loss = 0.09000309645876434
Trained batch 515 in epoch 2, gen_loss = 0.8250955386563789, disc_loss = 0.09000303639034025
Trained batch 516 in epoch 2, gen_loss = 0.8250517374196412, disc_loss = 0.08993970681471855
Trained batch 517 in epoch 2, gen_loss = 0.8253507114170141, disc_loss = 0.08986950561612787
Trained batch 518 in epoch 2, gen_loss = 0.825227532715237, disc_loss = 0.08980061814569382
Trained batch 519 in epoch 2, gen_loss = 0.8257637039400064, disc_loss = 0.08965848441271541
Trained batch 520 in epoch 2, gen_loss = 0.8263124615926432, disc_loss = 0.0895446889663755
Trained batch 521 in epoch 2, gen_loss = 0.8260009980178884, disc_loss = 0.089592805533702
Trained batch 522 in epoch 2, gen_loss = 0.8265660681528525, disc_loss = 0.08948361465661123
Trained batch 523 in epoch 2, gen_loss = 0.8269002270948795, disc_loss = 0.08933847991550584
Trained batch 524 in epoch 2, gen_loss = 0.826929996978669, disc_loss = 0.08923802266163486
Trained batch 525 in epoch 2, gen_loss = 0.8269103820446326, disc_loss = 0.08912082313570573
Trained batch 526 in epoch 2, gen_loss = 0.8272466504030933, disc_loss = 0.08907732047649557
Trained batch 527 in epoch 2, gen_loss = 0.8270067695076718, disc_loss = 0.08905221168727924
Trained batch 528 in epoch 2, gen_loss = 0.827543528916029, disc_loss = 0.08909429457313284
Trained batch 529 in epoch 2, gen_loss = 0.8268507256260458, disc_loss = 0.08937771480249346
Trained batch 530 in epoch 2, gen_loss = 0.8269152943809602, disc_loss = 0.08937689055479965
Trained batch 531 in epoch 2, gen_loss = 0.8269211465590879, disc_loss = 0.08929089779258334
Trained batch 532 in epoch 2, gen_loss = 0.8264919478606999, disc_loss = 0.08923193330458919
Trained batch 533 in epoch 2, gen_loss = 0.8268300044291028, disc_loss = 0.08923808789780635
Trained batch 534 in epoch 2, gen_loss = 0.8270194873074505, disc_loss = 0.08921850960457993
Trained batch 535 in epoch 2, gen_loss = 0.8265918298110143, disc_loss = 0.08927900475144053
Trained batch 536 in epoch 2, gen_loss = 0.8266935810807475, disc_loss = 0.08930406259161244
Trained batch 537 in epoch 2, gen_loss = 0.8270581145822781, disc_loss = 0.08920865005650817
Trained batch 538 in epoch 2, gen_loss = 0.8277521523230593, disc_loss = 0.08912078697227481
Trained batch 539 in epoch 2, gen_loss = 0.8275492939132231, disc_loss = 0.08904499836886923
Trained batch 540 in epoch 2, gen_loss = 0.8275433412431128, disc_loss = 0.08894640006565672
Trained batch 541 in epoch 2, gen_loss = 0.8274823932520138, disc_loss = 0.08888738721650355
Trained batch 542 in epoch 2, gen_loss = 0.8283549133914611, disc_loss = 0.08884670093833962
Trained batch 543 in epoch 2, gen_loss = 0.8283378980944262, disc_loss = 0.08876125879845966
Trained batch 544 in epoch 2, gen_loss = 0.8275785070493681, disc_loss = 0.08897913662597128
Trained batch 545 in epoch 2, gen_loss = 0.8277292723729933, disc_loss = 0.08904323046992878
Trained batch 546 in epoch 2, gen_loss = 0.8280025833376583, disc_loss = 0.08900929368705483
Trained batch 547 in epoch 2, gen_loss = 0.8276989898868721, disc_loss = 0.08903621331224368
Trained batch 548 in epoch 2, gen_loss = 0.8276713947020811, disc_loss = 0.08901721943095191
Trained batch 549 in epoch 2, gen_loss = 0.8275766356966713, disc_loss = 0.0889802223816514
Trained batch 550 in epoch 2, gen_loss = 0.8280602671381783, disc_loss = 0.08892951632246457
Trained batch 551 in epoch 2, gen_loss = 0.8279466431965863, disc_loss = 0.08890189188262583
Trained batch 552 in epoch 2, gen_loss = 0.827726640871593, disc_loss = 0.08891953475045791
Trained batch 553 in epoch 2, gen_loss = 0.8277853524534281, disc_loss = 0.08881811348768455
Trained batch 554 in epoch 2, gen_loss = 0.8278575310298989, disc_loss = 0.08871137273606954
Trained batch 555 in epoch 2, gen_loss = 0.8278542115426749, disc_loss = 0.08861571406315771
Trained batch 556 in epoch 2, gen_loss = 0.8278245647141921, disc_loss = 0.0885219905371619
Trained batch 557 in epoch 2, gen_loss = 0.8281104559859922, disc_loss = 0.08852877427146212
Trained batch 558 in epoch 2, gen_loss = 0.8279619866812166, disc_loss = 0.08848712406052886
Trained batch 559 in epoch 2, gen_loss = 0.8282449029918227, disc_loss = 0.08836481978318521
Trained batch 560 in epoch 2, gen_loss = 0.8282442347357405, disc_loss = 0.08832176074837193
Trained batch 561 in epoch 2, gen_loss = 0.8289116308676391, disc_loss = 0.08831741829200572
Trained batch 562 in epoch 2, gen_loss = 0.8285823442690325, disc_loss = 0.08835953618292275
Trained batch 563 in epoch 2, gen_loss = 0.8285783121877528, disc_loss = 0.08832493246077223
Trained batch 564 in epoch 2, gen_loss = 0.8286655907609821, disc_loss = 0.08823428964984101
Trained batch 565 in epoch 2, gen_loss = 0.8285118072382552, disc_loss = 0.08819250246450673
Trained batch 566 in epoch 2, gen_loss = 0.8285134651778657, disc_loss = 0.08811826069676687
Trained batch 567 in epoch 2, gen_loss = 0.8284127994007627, disc_loss = 0.08801442836280125
Trained batch 568 in epoch 2, gen_loss = 0.8288382063955331, disc_loss = 0.08789870192694538
Trained batch 569 in epoch 2, gen_loss = 0.828458256627384, disc_loss = 0.08791375885668554
Trained batch 570 in epoch 2, gen_loss = 0.8287437102527418, disc_loss = 0.08788019941953351
Trained batch 571 in epoch 2, gen_loss = 0.8285789550705389, disc_loss = 0.08779079734080739
Trained batch 572 in epoch 2, gen_loss = 0.8292169026367328, disc_loss = 0.08769166153606944
Trained batch 573 in epoch 2, gen_loss = 0.8295365697103926, disc_loss = 0.08755963591806824
Trained batch 574 in epoch 2, gen_loss = 0.8296195855866307, disc_loss = 0.08746938647297413
Trained batch 575 in epoch 2, gen_loss = 0.8293974821248816, disc_loss = 0.08745077762190097
Trained batch 576 in epoch 2, gen_loss = 0.8302468767509097, disc_loss = 0.08748545246021225
Trained batch 577 in epoch 2, gen_loss = 0.8305923237004494, disc_loss = 0.08737080830236361
Trained batch 578 in epoch 2, gen_loss = 0.8307046138252001, disc_loss = 0.08732636340303485
Trained batch 579 in epoch 2, gen_loss = 0.8304196791916058, disc_loss = 0.08744372009171238
Trained batch 580 in epoch 2, gen_loss = 0.8310241221663464, disc_loss = 0.08739133702235204
Trained batch 581 in epoch 2, gen_loss = 0.8317319833228678, disc_loss = 0.08729793801359653
Trained batch 582 in epoch 2, gen_loss = 0.8320718781310126, disc_loss = 0.08719460249400823
Trained batch 583 in epoch 2, gen_loss = 0.8320150368732132, disc_loss = 0.08713760104968073
Trained batch 584 in epoch 2, gen_loss = 0.8318429975937575, disc_loss = 0.08704556792051109
Trained batch 585 in epoch 2, gen_loss = 0.8322211040673403, disc_loss = 0.08698837727200202
Trained batch 586 in epoch 2, gen_loss = 0.8323177550578239, disc_loss = 0.0869270402928608
Trained batch 587 in epoch 2, gen_loss = 0.83224669266112, disc_loss = 0.08687661369457891
Trained batch 588 in epoch 2, gen_loss = 0.8320906830663795, disc_loss = 0.08685094696676741
Trained batch 589 in epoch 2, gen_loss = 0.831906995177269, disc_loss = 0.08689405131864093
Trained batch 590 in epoch 2, gen_loss = 0.8325309380762872, disc_loss = 0.08691513903168001
Trained batch 591 in epoch 2, gen_loss = 0.8322766599924983, disc_loss = 0.08690912670902656
Trained batch 592 in epoch 2, gen_loss = 0.8322051730867582, disc_loss = 0.0868176069113773
Trained batch 593 in epoch 2, gen_loss = 0.8323304861382603, disc_loss = 0.0867287808016369
Trained batch 594 in epoch 2, gen_loss = 0.832664196381048, disc_loss = 0.0869290217303303
Trained batch 595 in epoch 2, gen_loss = 0.8321585262681814, disc_loss = 0.08731831156886213
Trained batch 596 in epoch 2, gen_loss = 0.8319561956216343, disc_loss = 0.08731295379780395
Trained batch 597 in epoch 2, gen_loss = 0.8317554413175902, disc_loss = 0.08732947507050873
Trained batch 598 in epoch 2, gen_loss = 0.8328795868387207, disc_loss = 0.08787334641171168
Trained batch 599 in epoch 2, gen_loss = 0.8322571478287379, disc_loss = 0.0883568115454788
Trained batch 600 in epoch 2, gen_loss = 0.8318915757879044, disc_loss = 0.08846898177815307
Trained batch 601 in epoch 2, gen_loss = 0.8320043794934536, disc_loss = 0.08858911558657737
Trained batch 602 in epoch 2, gen_loss = 0.832186935651757, disc_loss = 0.08857032691729355
Trained batch 603 in epoch 2, gen_loss = 0.8321524368019293, disc_loss = 0.08848439388143652
Trained batch 604 in epoch 2, gen_loss = 0.8317608700310888, disc_loss = 0.08853794003044031
Trained batch 605 in epoch 2, gen_loss = 0.8317785058477924, disc_loss = 0.0884668464286763
Trained batch 606 in epoch 2, gen_loss = 0.832160792005121, disc_loss = 0.08840667689449262
Trained batch 607 in epoch 2, gen_loss = 0.8325431968428587, disc_loss = 0.08835694246992812
Trained batch 608 in epoch 2, gen_loss = 0.8323916429760813, disc_loss = 0.08825437904890682
Trained batch 609 in epoch 2, gen_loss = 0.8325172924604572, disc_loss = 0.088149713014909
Trained batch 610 in epoch 2, gen_loss = 0.8324530707053389, disc_loss = 0.08808399502602565
Trained batch 611 in epoch 2, gen_loss = 0.8324967799038668, disc_loss = 0.08797722589681108
Trained batch 612 in epoch 2, gen_loss = 0.8322328790949375, disc_loss = 0.08801820220161369
Trained batch 613 in epoch 2, gen_loss = 0.8328154701557532, disc_loss = 0.08797751963957659
Trained batch 614 in epoch 2, gen_loss = 0.8325017674182489, disc_loss = 0.08797489688012416
Trained batch 615 in epoch 2, gen_loss = 0.8326702322085182, disc_loss = 0.0879345615681672
Trained batch 616 in epoch 2, gen_loss = 0.8324702088411662, disc_loss = 0.08786769899444555
Trained batch 617 in epoch 2, gen_loss = 0.832508436588022, disc_loss = 0.08779883643154139
Trained batch 618 in epoch 2, gen_loss = 0.832365267688893, disc_loss = 0.08772793732830271
Trained batch 619 in epoch 2, gen_loss = 0.832208296175926, disc_loss = 0.08773299286652717
Trained batch 620 in epoch 2, gen_loss = 0.8326708168607211, disc_loss = 0.08766873755406786
Trained batch 621 in epoch 2, gen_loss = 0.8325137074353994, disc_loss = 0.08758189170875877
Trained batch 622 in epoch 2, gen_loss = 0.8326736394895979, disc_loss = 0.0874649632608527
Trained batch 623 in epoch 2, gen_loss = 0.8322415240108967, disc_loss = 0.08749085787731485
Trained batch 624 in epoch 2, gen_loss = 0.8324821284294128, disc_loss = 0.08744605803489686
Trained batch 625 in epoch 2, gen_loss = 0.8332058087514993, disc_loss = 0.08741489069435163
Trained batch 626 in epoch 2, gen_loss = 0.8333020833880898, disc_loss = 0.08730038131870911
Trained batch 627 in epoch 2, gen_loss = 0.8329689795044577, disc_loss = 0.08730481875834951
Trained batch 628 in epoch 2, gen_loss = 0.8329873485860839, disc_loss = 0.08725330667105312
Trained batch 629 in epoch 2, gen_loss = 0.8332663484035976, disc_loss = 0.08730179510182805
Trained batch 630 in epoch 2, gen_loss = 0.8331495208898928, disc_loss = 0.08721758294171653
Trained batch 631 in epoch 2, gen_loss = 0.8330248951723304, disc_loss = 0.08717787272850924
Trained batch 632 in epoch 2, gen_loss = 0.8326365346027211, disc_loss = 0.08727362947347228
Trained batch 633 in epoch 2, gen_loss = 0.8327714346748797, disc_loss = 0.08722379535718672
Trained batch 634 in epoch 2, gen_loss = 0.8327110529884578, disc_loss = 0.08718682364450665
Trained batch 635 in epoch 2, gen_loss = 0.8325328649777286, disc_loss = 0.08721926651379597
Trained batch 636 in epoch 2, gen_loss = 0.8322928667629906, disc_loss = 0.08721261110092444
Trained batch 637 in epoch 2, gen_loss = 0.83195408450025, disc_loss = 0.08718239371212298
Trained batch 638 in epoch 2, gen_loss = 0.8318294358551969, disc_loss = 0.08715352829959658
Trained batch 639 in epoch 2, gen_loss = 0.8317909525707364, disc_loss = 0.08710257073980757
Trained batch 640 in epoch 2, gen_loss = 0.8319828655344089, disc_loss = 0.08707833595213578
Trained batch 641 in epoch 2, gen_loss = 0.8315570579139614, disc_loss = 0.08734466003782096
Trained batch 642 in epoch 2, gen_loss = 0.8321068713305342, disc_loss = 0.08730996513093241
Trained batch 643 in epoch 2, gen_loss = 0.8321280193439922, disc_loss = 0.08733089803284184
Trained batch 644 in epoch 2, gen_loss = 0.8317793612332307, disc_loss = 0.08744655159670253
Trained batch 645 in epoch 2, gen_loss = 0.831394841611939, disc_loss = 0.08746869498200645
Trained batch 646 in epoch 2, gen_loss = 0.8317185093114696, disc_loss = 0.08753589155523818
Trained batch 647 in epoch 2, gen_loss = 0.8317553450663885, disc_loss = 0.08752659843360752
Trained batch 648 in epoch 2, gen_loss = 0.8317314663726854, disc_loss = 0.08747056309128028
Trained batch 649 in epoch 2, gen_loss = 0.8314876374831567, disc_loss = 0.08740729748056485
Trained batch 650 in epoch 2, gen_loss = 0.8313938642060885, disc_loss = 0.08754590807193618
Trained batch 651 in epoch 2, gen_loss = 0.8310600962558407, disc_loss = 0.08761159882543643
Trained batch 652 in epoch 2, gen_loss = 0.8310062840558121, disc_loss = 0.08757059595007079
Trained batch 653 in epoch 2, gen_loss = 0.8316206466349623, disc_loss = 0.08757125777092731
Trained batch 654 in epoch 2, gen_loss = 0.8313477677243356, disc_loss = 0.08755960485521164
Trained batch 655 in epoch 2, gen_loss = 0.8312445754503331, disc_loss = 0.08745665466923994
Trained batch 656 in epoch 2, gen_loss = 0.8312591861372125, disc_loss = 0.08737550610378725
Trained batch 657 in epoch 2, gen_loss = 0.8311338620345281, disc_loss = 0.08746968320992671
Trained batch 658 in epoch 2, gen_loss = 0.8311723585555695, disc_loss = 0.08748557164484977
Trained batch 659 in epoch 2, gen_loss = 0.8307906715255795, disc_loss = 0.08748030849083355
Trained batch 660 in epoch 2, gen_loss = 0.8306407711148803, disc_loss = 0.08744163655375839
Trained batch 661 in epoch 2, gen_loss = 0.8304936994778785, disc_loss = 0.08738802526191192
Trained batch 662 in epoch 2, gen_loss = 0.8303949328569266, disc_loss = 0.08730795125717221
Trained batch 663 in epoch 2, gen_loss = 0.8306189475648375, disc_loss = 0.0875043643509453
Trained batch 664 in epoch 2, gen_loss = 0.8304299141231336, disc_loss = 0.08752692440678751
Trained batch 665 in epoch 2, gen_loss = 0.8302703498899042, disc_loss = 0.08752748336889096
Trained batch 666 in epoch 2, gen_loss = 0.8303207908791939, disc_loss = 0.08747513980131368
Trained batch 667 in epoch 2, gen_loss = 0.8305252737806229, disc_loss = 0.08747701339345582
Trained batch 668 in epoch 2, gen_loss = 0.830091669865966, disc_loss = 0.08761582766647029
Trained batch 669 in epoch 2, gen_loss = 0.8298724963593839, disc_loss = 0.0875654647627206
Trained batch 670 in epoch 2, gen_loss = 0.8302962800429582, disc_loss = 0.08762399737074994
Trained batch 671 in epoch 2, gen_loss = 0.8302130974119618, disc_loss = 0.08759386196921003
Trained batch 672 in epoch 2, gen_loss = 0.8299881462533619, disc_loss = 0.08761796767354277
Trained batch 673 in epoch 2, gen_loss = 0.8301536302891966, disc_loss = 0.08752384250955961
Trained batch 674 in epoch 2, gen_loss = 0.8309240427723638, disc_loss = 0.08766652970126382
Trained batch 675 in epoch 2, gen_loss = 0.8304678866496453, disc_loss = 0.08792746113062169
Trained batch 676 in epoch 2, gen_loss = 0.8303844139882346, disc_loss = 0.08790393198731643
Trained batch 677 in epoch 2, gen_loss = 0.8306317814683493, disc_loss = 0.08793773219417945
Trained batch 678 in epoch 2, gen_loss = 0.8304326091845011, disc_loss = 0.08794502100587681
Trained batch 679 in epoch 2, gen_loss = 0.8304881946128957, disc_loss = 0.0879171190865557
Trained batch 680 in epoch 2, gen_loss = 0.8303731609020989, disc_loss = 0.08789799356677196
Trained batch 681 in epoch 2, gen_loss = 0.8301573678020857, disc_loss = 0.08787148670618397
Trained batch 682 in epoch 2, gen_loss = 0.8299999715294007, disc_loss = 0.08783091246634503
Trained batch 683 in epoch 2, gen_loss = 0.8302781824131458, disc_loss = 0.08784561039749206
Trained batch 684 in epoch 2, gen_loss = 0.8302064669393275, disc_loss = 0.08784767832797374
Trained batch 685 in epoch 2, gen_loss = 0.8297889084927195, disc_loss = 0.08821837860091696
Trained batch 686 in epoch 2, gen_loss = 0.8304528525476025, disc_loss = 0.08819460746014743
Trained batch 687 in epoch 2, gen_loss = 0.8302086414119532, disc_loss = 0.08824018686522492
Trained batch 688 in epoch 2, gen_loss = 0.8307135730592536, disc_loss = 0.08820748902013842
Trained batch 689 in epoch 2, gen_loss = 0.8306002826794334, disc_loss = 0.08816026920803648
Trained batch 690 in epoch 2, gen_loss = 0.8304901113558436, disc_loss = 0.08808885062687563
Trained batch 691 in epoch 2, gen_loss = 0.8303325817936418, disc_loss = 0.0880167461969389
Trained batch 692 in epoch 2, gen_loss = 0.8306692492050182, disc_loss = 0.08800155145598611
Trained batch 693 in epoch 2, gen_loss = 0.8308773085432025, disc_loss = 0.08792091712559592
Trained batch 694 in epoch 2, gen_loss = 0.830480360727516, disc_loss = 0.08800752850906025
Trained batch 695 in epoch 2, gen_loss = 0.8304524157067825, disc_loss = 0.08792574207255638
Trained batch 696 in epoch 2, gen_loss = 0.8308930190940156, disc_loss = 0.08811723559806217
Trained batch 697 in epoch 2, gen_loss = 0.8308922108743115, disc_loss = 0.08803049650011227
Trained batch 698 in epoch 2, gen_loss = 0.8307286842016021, disc_loss = 0.0880485845353982
Trained batch 699 in epoch 2, gen_loss = 0.8307136709349496, disc_loss = 0.08795557520751442
Trained batch 700 in epoch 2, gen_loss = 0.8310936908749132, disc_loss = 0.08786653174345146
Trained batch 701 in epoch 2, gen_loss = 0.8310045447954085, disc_loss = 0.08778638458755027
Trained batch 702 in epoch 2, gen_loss = 0.8309989998893412, disc_loss = 0.08772822199482073
Trained batch 703 in epoch 2, gen_loss = 0.8312482670457526, disc_loss = 0.08766543636341918
Trained batch 704 in epoch 2, gen_loss = 0.8309392681358554, disc_loss = 0.0877088441467243
Trained batch 705 in epoch 2, gen_loss = 0.8307933714504621, disc_loss = 0.08772988045171283
Trained batch 706 in epoch 2, gen_loss = 0.8309816793977287, disc_loss = 0.08763200664020748
Trained batch 707 in epoch 2, gen_loss = 0.8312930218075628, disc_loss = 0.08758131070272987
Trained batch 708 in epoch 2, gen_loss = 0.8313402087967554, disc_loss = 0.08749271920857207
Trained batch 709 in epoch 2, gen_loss = 0.8310590978239624, disc_loss = 0.08753763887454087
Trained batch 710 in epoch 2, gen_loss = 0.831318383394582, disc_loss = 0.08751118761577686
Trained batch 711 in epoch 2, gen_loss = 0.8313907658618488, disc_loss = 0.08744500134809968
Trained batch 712 in epoch 2, gen_loss = 0.8312553359616187, disc_loss = 0.08738944990374932
Trained batch 713 in epoch 2, gen_loss = 0.8313886758660068, disc_loss = 0.08731148389353305
Trained batch 714 in epoch 2, gen_loss = 0.8314545341304965, disc_loss = 0.08735124210898693
Trained batch 715 in epoch 2, gen_loss = 0.8312907798330211, disc_loss = 0.08734251128499235
Trained batch 716 in epoch 2, gen_loss = 0.8310828281246967, disc_loss = 0.08729639318947013
Trained batch 717 in epoch 2, gen_loss = 0.831417071038966, disc_loss = 0.08725965400758227
Trained batch 718 in epoch 2, gen_loss = 0.8313599412895543, disc_loss = 0.08724361427014328
Trained batch 719 in epoch 2, gen_loss = 0.8310777471297317, disc_loss = 0.08731859130784869
Trained batch 720 in epoch 2, gen_loss = 0.8310501996257269, disc_loss = 0.08733497965104371
Trained batch 721 in epoch 2, gen_loss = 0.8309771006622473, disc_loss = 0.08742177777425734
Trained batch 722 in epoch 2, gen_loss = 0.8306636425304544, disc_loss = 0.08741177621595098
Trained batch 723 in epoch 2, gen_loss = 0.8306578412569688, disc_loss = 0.08737075973034564
Trained batch 724 in epoch 2, gen_loss = 0.8308464244316364, disc_loss = 0.08731536990609662
Trained batch 725 in epoch 2, gen_loss = 0.8307831957320536, disc_loss = 0.08726330950712534
Trained batch 726 in epoch 2, gen_loss = 0.8305664385529299, disc_loss = 0.08726134642630692
Trained batch 727 in epoch 2, gen_loss = 0.8308563795718518, disc_loss = 0.08722813096368215
Trained batch 728 in epoch 2, gen_loss = 0.8308410794156078, disc_loss = 0.08718132144874996
Trained batch 729 in epoch 2, gen_loss = 0.8308792418813052, disc_loss = 0.08719452010238007
Trained batch 730 in epoch 2, gen_loss = 0.8307719204559535, disc_loss = 0.08722538979043713
Trained batch 731 in epoch 2, gen_loss = 0.8306284600594005, disc_loss = 0.08721895657398336
Trained batch 732 in epoch 2, gen_loss = 0.8308739862207827, disc_loss = 0.08721284498174714
Trained batch 733 in epoch 2, gen_loss = 0.8306166169916251, disc_loss = 0.08721798874579918
Trained batch 734 in epoch 2, gen_loss = 0.8305811804168078, disc_loss = 0.08729881276281512
Trained batch 735 in epoch 2, gen_loss = 0.8304428903628951, disc_loss = 0.08727308852679055
Trained batch 736 in epoch 2, gen_loss = 0.8306219282596696, disc_loss = 0.08721961254908563
Trained batch 737 in epoch 2, gen_loss = 0.8308839520949335, disc_loss = 0.08714729192134164
Trained batch 738 in epoch 2, gen_loss = 0.830675020350171, disc_loss = 0.08718743899154083
Trained batch 739 in epoch 2, gen_loss = 0.8304237779733297, disc_loss = 0.08719640546352476
Trained batch 740 in epoch 2, gen_loss = 0.8306400259496712, disc_loss = 0.08715628742588516
Trained batch 741 in epoch 2, gen_loss = 0.8307618924549648, disc_loss = 0.08706920642927891
Trained batch 742 in epoch 2, gen_loss = 0.8305055796698959, disc_loss = 0.08703640724806815
Trained batch 743 in epoch 2, gen_loss = 0.830734831992016, disc_loss = 0.08708131240971226
Trained batch 744 in epoch 2, gen_loss = 0.8304599438737703, disc_loss = 0.08711103162659495
Trained batch 745 in epoch 2, gen_loss = 0.8302219065840059, disc_loss = 0.08712318461468249
Trained batch 746 in epoch 2, gen_loss = 0.8306964525736, disc_loss = 0.08722434562682069
Trained batch 747 in epoch 2, gen_loss = 0.8305306067281866, disc_loss = 0.08725713525853931
Trained batch 748 in epoch 2, gen_loss = 0.8303908233808103, disc_loss = 0.08724069916388301
Trained batch 749 in epoch 2, gen_loss = 0.8302145647207896, disc_loss = 0.08724035524080197
Trained batch 750 in epoch 2, gen_loss = 0.8300369667625935, disc_loss = 0.08732955424380445
Trained batch 751 in epoch 2, gen_loss = 0.8298943301940218, disc_loss = 0.08731587153631559
Trained batch 752 in epoch 2, gen_loss = 0.8296895475184933, disc_loss = 0.08732533662432773
Trained batch 753 in epoch 2, gen_loss = 0.8302267943200129, disc_loss = 0.08744224800977766
Trained batch 754 in epoch 2, gen_loss = 0.8299409635019618, disc_loss = 0.08746049088111382
Trained batch 755 in epoch 2, gen_loss = 0.8298182269883534, disc_loss = 0.08749359594559465
Trained batch 756 in epoch 2, gen_loss = 0.8296168097731617, disc_loss = 0.08752240163558304
Trained batch 757 in epoch 2, gen_loss = 0.8295450459055033, disc_loss = 0.08747289022357058
Trained batch 758 in epoch 2, gen_loss = 0.8293992453727169, disc_loss = 0.08748455728712211
Trained batch 759 in epoch 2, gen_loss = 0.8297817407470001, disc_loss = 0.08754431046790591
Trained batch 760 in epoch 2, gen_loss = 0.829441894369589, disc_loss = 0.08757705311199133
Trained batch 761 in epoch 2, gen_loss = 0.8290541836908796, disc_loss = 0.08783765649789665
Trained batch 762 in epoch 2, gen_loss = 0.8291945915234668, disc_loss = 0.08792121724260979
Trained batch 763 in epoch 2, gen_loss = 0.8290128514404697, disc_loss = 0.08795632710875408
Trained batch 764 in epoch 2, gen_loss = 0.8292294542773876, disc_loss = 0.08802123866683127
Trained batch 765 in epoch 2, gen_loss = 0.8289403981546197, disc_loss = 0.08811697846536304
Trained batch 766 in epoch 2, gen_loss = 0.8287139852012774, disc_loss = 0.0881670445344633
Trained batch 767 in epoch 2, gen_loss = 0.8287874603799233, disc_loss = 0.08823781123161704
Trained batch 768 in epoch 2, gen_loss = 0.8290522480662065, disc_loss = 0.0881817207365298
Trained batch 769 in epoch 2, gen_loss = 0.8289590117993293, disc_loss = 0.08815174504582371
Trained batch 770 in epoch 2, gen_loss = 0.8289602695735976, disc_loss = 0.08807129933995264
Trained batch 771 in epoch 2, gen_loss = 0.8289055659826555, disc_loss = 0.08803128601423431
Trained batch 772 in epoch 2, gen_loss = 0.8288024377853719, disc_loss = 0.08799734217431614
Trained batch 773 in epoch 2, gen_loss = 0.8289884006176192, disc_loss = 0.08801779487153433
Trained batch 774 in epoch 2, gen_loss = 0.8289233969103905, disc_loss = 0.08795724878628408
Trained batch 775 in epoch 2, gen_loss = 0.8287034158393279, disc_loss = 0.08804968760118426
Trained batch 776 in epoch 2, gen_loss = 0.8289433674002246, disc_loss = 0.08846388230078699
Trained batch 777 in epoch 2, gen_loss = 0.8286116969003162, disc_loss = 0.08861755964928007
Trained batch 778 in epoch 2, gen_loss = 0.8282329069787638, disc_loss = 0.08878457974953355
Trained batch 779 in epoch 2, gen_loss = 0.8288865881852615, disc_loss = 0.08904503339615005
Trained batch 780 in epoch 2, gen_loss = 0.8289032534966854, disc_loss = 0.0891169808189672
Trained batch 781 in epoch 2, gen_loss = 0.8285338788691079, disc_loss = 0.08920063842754916
Trained batch 782 in epoch 2, gen_loss = 0.8281257046745807, disc_loss = 0.08933644276707033
Trained batch 783 in epoch 2, gen_loss = 0.8285416949312298, disc_loss = 0.08937180819873679
Trained batch 784 in epoch 2, gen_loss = 0.8282896949227448, disc_loss = 0.08944826469916826
Trained batch 785 in epoch 2, gen_loss = 0.8280065595800337, disc_loss = 0.08950325041184672
Trained batch 786 in epoch 2, gen_loss = 0.8280168089357689, disc_loss = 0.08947785841738935
Trained batch 787 in epoch 2, gen_loss = 0.827925143961979, disc_loss = 0.08949098382665194
Trained batch 788 in epoch 2, gen_loss = 0.8281579593288582, disc_loss = 0.08946467293202122
Trained batch 789 in epoch 2, gen_loss = 0.8279051991203163, disc_loss = 0.08949221577495337
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.8192246556282043, disc_loss = 0.06338299065828323
Trained batch 1 in epoch 3, gen_loss = 0.8505483269691467, disc_loss = 0.07043175026774406
Trained batch 2 in epoch 3, gen_loss = 0.8979173898696899, disc_loss = 0.05859840288758278
Trained batch 3 in epoch 3, gen_loss = 0.8346354812383652, disc_loss = 0.07768808212131262
Trained batch 4 in epoch 3, gen_loss = 0.8089717507362366, disc_loss = 0.08168256208300591
Trained batch 5 in epoch 3, gen_loss = 0.8154694736003876, disc_loss = 0.07778890244662762
Trained batch 6 in epoch 3, gen_loss = 0.8044702751295907, disc_loss = 0.07720458773630005
Trained batch 7 in epoch 3, gen_loss = 0.7928241640329361, disc_loss = 0.07992718974128366
Trained batch 8 in epoch 3, gen_loss = 0.7916007041931152, disc_loss = 0.07540751538342899
Trained batch 9 in epoch 3, gen_loss = 0.78722665309906, disc_loss = 0.07151037752628327
Trained batch 10 in epoch 3, gen_loss = 0.7890427816997875, disc_loss = 0.0697054856202819
Trained batch 11 in epoch 3, gen_loss = 0.8213674773772558, disc_loss = 0.07039720006287098
Trained batch 12 in epoch 3, gen_loss = 0.8134765579150274, disc_loss = 0.07583709806203842
Trained batch 13 in epoch 3, gen_loss = 0.8116557683263507, disc_loss = 0.07555960650954928
Trained batch 14 in epoch 3, gen_loss = 0.8197234034538269, disc_loss = 0.07373868674039841
Trained batch 15 in epoch 3, gen_loss = 0.8128802962601185, disc_loss = 0.07481672335416079
Trained batch 16 in epoch 3, gen_loss = 0.8283513959716348, disc_loss = 0.07606011541450725
Trained batch 17 in epoch 3, gen_loss = 0.8228130373689864, disc_loss = 0.07437388226389885
Trained batch 18 in epoch 3, gen_loss = 0.8186084471250835, disc_loss = 0.07312313094735146
Trained batch 19 in epoch 3, gen_loss = 0.8281381368637085, disc_loss = 0.07285389360040426
Trained batch 20 in epoch 3, gen_loss = 0.8304368484587896, disc_loss = 0.07021822106270563
Trained batch 21 in epoch 3, gen_loss = 0.822466871955178, disc_loss = 0.07108888978307898
Trained batch 22 in epoch 3, gen_loss = 0.8157749383345895, disc_loss = 0.06968413325755493
Trained batch 23 in epoch 3, gen_loss = 0.8188547591368357, disc_loss = 0.06817698913315932
Trained batch 24 in epoch 3, gen_loss = 0.8272932434082031, disc_loss = 0.06693510547280311
Trained batch 25 in epoch 3, gen_loss = 0.8264016554905818, disc_loss = 0.06487443434217802
Trained batch 26 in epoch 3, gen_loss = 0.8238657161041543, disc_loss = 0.06319193783457633
Trained batch 27 in epoch 3, gen_loss = 0.8192434119326728, disc_loss = 0.062417993255491765
Trained batch 28 in epoch 3, gen_loss = 0.8183552335048544, disc_loss = 0.06301746074238727
Trained batch 29 in epoch 3, gen_loss = 0.8246701737244924, disc_loss = 0.06229705133785804
Trained batch 30 in epoch 3, gen_loss = 0.8207304150827469, disc_loss = 0.06360126424941324
Trained batch 31 in epoch 3, gen_loss = 0.8215609192848206, disc_loss = 0.06261980364797637
Trained batch 32 in epoch 3, gen_loss = 0.8294014497236772, disc_loss = 0.0614170664074746
Trained batch 33 in epoch 3, gen_loss = 0.8344625480034772, disc_loss = 0.06012469902634621
Trained batch 34 in epoch 3, gen_loss = 0.8330830608095442, disc_loss = 0.05980265374694552
Trained batch 35 in epoch 3, gen_loss = 0.8241838249895308, disc_loss = 0.06045816383428044
Trained batch 36 in epoch 3, gen_loss = 0.8284696678857546, disc_loss = 0.06009730012030215
Trained batch 37 in epoch 3, gen_loss = 0.8316212265115035, disc_loss = 0.05903092379632749
Trained batch 38 in epoch 3, gen_loss = 0.8361955758852836, disc_loss = 0.05781290806734409
Trained batch 39 in epoch 3, gen_loss = 0.8358203694224358, disc_loss = 0.05704017526004464
Trained batch 40 in epoch 3, gen_loss = 0.8369693697952643, disc_loss = 0.05608533320539608
Trained batch 41 in epoch 3, gen_loss = 0.8387109282470885, disc_loss = 0.05533748064633636
Trained batch 42 in epoch 3, gen_loss = 0.8401998600294424, disc_loss = 0.05599130947835917
Trained batch 43 in epoch 3, gen_loss = 0.8390134830366481, disc_loss = 0.055633874334902925
Trained batch 44 in epoch 3, gen_loss = 0.8314056687884861, disc_loss = 0.05661596115678549
Trained batch 45 in epoch 3, gen_loss = 0.8323054106339164, disc_loss = 0.05567839482556219
Trained batch 46 in epoch 3, gen_loss = 0.83641487486819, disc_loss = 0.055266359543546716
Trained batch 47 in epoch 3, gen_loss = 0.8363889108101527, disc_loss = 0.05459541377301017
Trained batch 48 in epoch 3, gen_loss = 0.8371551340940048, disc_loss = 0.05396989254014833
Trained batch 49 in epoch 3, gen_loss = 0.8415831029415131, disc_loss = 0.05434612311422825
Trained batch 50 in epoch 3, gen_loss = 0.8401571009673324, disc_loss = 0.05385251635429906
Trained batch 51 in epoch 3, gen_loss = 0.8383095447833722, disc_loss = 0.05393279121758846
Trained batch 52 in epoch 3, gen_loss = 0.8461318510883259, disc_loss = 0.05503933546396921
Trained batch 53 in epoch 3, gen_loss = 0.8433637254767947, disc_loss = 0.05579872698419624
Trained batch 54 in epoch 3, gen_loss = 0.8444920680739663, disc_loss = 0.055163776535879484
Trained batch 55 in epoch 3, gen_loss = 0.8452266859156745, disc_loss = 0.054957654659769366
Trained batch 56 in epoch 3, gen_loss = 0.8473553929412574, disc_loss = 0.05462650582194328
Trained batch 57 in epoch 3, gen_loss = 0.8545496813182173, disc_loss = 0.055015279365510775
Trained batch 58 in epoch 3, gen_loss = 0.8542531718642025, disc_loss = 0.054800408687126836
Trained batch 59 in epoch 3, gen_loss = 0.8523965030908585, disc_loss = 0.05453907952954372
Trained batch 60 in epoch 3, gen_loss = 0.8513684878583814, disc_loss = 0.05392918051754842
Trained batch 61 in epoch 3, gen_loss = 0.8555028803886906, disc_loss = 0.05357122727699818
Trained batch 62 in epoch 3, gen_loss = 0.8646122860530067, disc_loss = 0.0541309363666981
Trained batch 63 in epoch 3, gen_loss = 0.8659153133630753, disc_loss = 0.05353517964249477
Trained batch 64 in epoch 3, gen_loss = 0.8658317492558406, disc_loss = 0.05292629112417881
Trained batch 65 in epoch 3, gen_loss = 0.8644176242929517, disc_loss = 0.05277094284467625
Trained batch 66 in epoch 3, gen_loss = 0.8652365803718567, disc_loss = 0.05235222782661666
Trained batch 67 in epoch 3, gen_loss = 0.8632765841834685, disc_loss = 0.05202834160231492
Trained batch 68 in epoch 3, gen_loss = 0.8625717776409094, disc_loss = 0.05186051297662915
Trained batch 69 in epoch 3, gen_loss = 0.8649879889828819, disc_loss = 0.051724383820380485
Trained batch 70 in epoch 3, gen_loss = 0.8693556978668965, disc_loss = 0.051558829056964794
Trained batch 71 in epoch 3, gen_loss = 0.8659252532654338, disc_loss = 0.05280903928602735
Trained batch 72 in epoch 3, gen_loss = 0.8696733313064052, disc_loss = 0.05258810326252898
Trained batch 73 in epoch 3, gen_loss = 0.8700266222696047, disc_loss = 0.05243751502318962
Trained batch 74 in epoch 3, gen_loss = 0.871359932422638, disc_loss = 0.051905082687735554
Trained batch 75 in epoch 3, gen_loss = 0.8702747217918697, disc_loss = 0.05147334837697839
Trained batch 76 in epoch 3, gen_loss = 0.8690520517237774, disc_loss = 0.051603329621932724
Trained batch 77 in epoch 3, gen_loss = 0.8702776317413037, disc_loss = 0.051595778013460145
Trained batch 78 in epoch 3, gen_loss = 0.8713188616535331, disc_loss = 0.051456593755113925
Trained batch 79 in epoch 3, gen_loss = 0.8727770693600178, disc_loss = 0.05096662750001997
Trained batch 80 in epoch 3, gen_loss = 0.8707070549329122, disc_loss = 0.05156931563935898
Trained batch 81 in epoch 3, gen_loss = 0.8729944396309737, disc_loss = 0.052085212522708785
Trained batch 82 in epoch 3, gen_loss = 0.873278707624918, disc_loss = 0.051892210448901334
Trained batch 83 in epoch 3, gen_loss = 0.8762627307857785, disc_loss = 0.051712139043956995
Trained batch 84 in epoch 3, gen_loss = 0.875566077933592, disc_loss = 0.0512808237443952
Trained batch 85 in epoch 3, gen_loss = 0.8722609718178593, disc_loss = 0.05206505984587725
Trained batch 86 in epoch 3, gen_loss = 0.8770017384112566, disc_loss = 0.05378775585485601
Trained batch 87 in epoch 3, gen_loss = 0.8771653764627196, disc_loss = 0.05340533227321099
Trained batch 88 in epoch 3, gen_loss = 0.8729642596137658, disc_loss = 0.055513811894179727
Trained batch 89 in epoch 3, gen_loss = 0.8744512829515669, disc_loss = 0.05652896362460322
Trained batch 90 in epoch 3, gen_loss = 0.87391765497543, disc_loss = 0.05670948561976899
Trained batch 91 in epoch 3, gen_loss = 0.873273338312688, disc_loss = 0.056387693317526064
Trained batch 92 in epoch 3, gen_loss = 0.87500447803928, disc_loss = 0.0559181596042328
Trained batch 93 in epoch 3, gen_loss = 0.8784583141195014, disc_loss = 0.055725807304236485
Trained batch 94 in epoch 3, gen_loss = 0.8771143254480864, disc_loss = 0.05545831624614565
Trained batch 95 in epoch 3, gen_loss = 0.8750856338689724, disc_loss = 0.05509145612207552
Trained batch 96 in epoch 3, gen_loss = 0.8758324304806817, disc_loss = 0.05464178989113299
Trained batch 97 in epoch 3, gen_loss = 0.8756181397000138, disc_loss = 0.0542201355327757
Trained batch 98 in epoch 3, gen_loss = 0.8775036846748506, disc_loss = 0.053785179299537585
Trained batch 99 in epoch 3, gen_loss = 0.8787811952829361, disc_loss = 0.05353276219218969
Trained batch 100 in epoch 3, gen_loss = 0.878096085373718, disc_loss = 0.05312117296132711
Trained batch 101 in epoch 3, gen_loss = 0.8754944713676677, disc_loss = 0.05408313267809503
Trained batch 102 in epoch 3, gen_loss = 0.8753078377362594, disc_loss = 0.054148738426201555
Trained batch 103 in epoch 3, gen_loss = 0.8742077362078887, disc_loss = 0.05384303926705168
Trained batch 104 in epoch 3, gen_loss = 0.8747207868666876, disc_loss = 0.05376932291047914
Trained batch 105 in epoch 3, gen_loss = 0.8727735427190673, disc_loss = 0.05384594838152516
Trained batch 106 in epoch 3, gen_loss = 0.8727302434288453, disc_loss = 0.05348322822529579
Trained batch 107 in epoch 3, gen_loss = 0.8730450829973927, disc_loss = 0.05326823629783811
Trained batch 108 in epoch 3, gen_loss = 0.872011796596947, disc_loss = 0.05328753595710348
Trained batch 109 in epoch 3, gen_loss = 0.8705112917856737, disc_loss = 0.053288865377279844
Trained batch 110 in epoch 3, gen_loss = 0.8698089761776967, disc_loss = 0.053312413411231725
Trained batch 111 in epoch 3, gen_loss = 0.8701622310493674, disc_loss = 0.05306242740646537
Trained batch 112 in epoch 3, gen_loss = 0.8695705364235734, disc_loss = 0.053470723413392506
Trained batch 113 in epoch 3, gen_loss = 0.8674485568414655, disc_loss = 0.05416263432421705
Trained batch 114 in epoch 3, gen_loss = 0.8681002741274626, disc_loss = 0.054422176548320315
Trained batch 115 in epoch 3, gen_loss = 0.8683479207343069, disc_loss = 0.054431352619852484
Trained batch 116 in epoch 3, gen_loss = 0.8699457426356454, disc_loss = 0.05414412473129411
Trained batch 117 in epoch 3, gen_loss = 0.868715366064492, disc_loss = 0.0541308280711962
Trained batch 118 in epoch 3, gen_loss = 0.8672980325562614, disc_loss = 0.054309428207764104
Trained batch 119 in epoch 3, gen_loss = 0.8682836815714836, disc_loss = 0.05438300517077247
Trained batch 120 in epoch 3, gen_loss = 0.867855071528884, disc_loss = 0.054210014887585124
Trained batch 121 in epoch 3, gen_loss = 0.8695939950278548, disc_loss = 0.05395552111392627
Trained batch 122 in epoch 3, gen_loss = 0.8689484009897805, disc_loss = 0.0537644416184687
Trained batch 123 in epoch 3, gen_loss = 0.8662049265638474, disc_loss = 0.05399857532052744
Trained batch 124 in epoch 3, gen_loss = 0.8652424912452698, disc_loss = 0.0547928391546011
Trained batch 125 in epoch 3, gen_loss = 0.8635526247440822, disc_loss = 0.054964360603619186
Trained batch 126 in epoch 3, gen_loss = 0.8612452646878761, disc_loss = 0.05574955772168524
Trained batch 127 in epoch 3, gen_loss = 0.861673513893038, disc_loss = 0.055949151268578134
Trained batch 128 in epoch 3, gen_loss = 0.8619596833406493, disc_loss = 0.055878058148100394
Trained batch 129 in epoch 3, gen_loss = 0.8602725446224213, disc_loss = 0.05616302938702015
Trained batch 130 in epoch 3, gen_loss = 0.8596927641912271, disc_loss = 0.056063805728127025
Trained batch 131 in epoch 3, gen_loss = 0.8599086968284665, disc_loss = 0.05669468315318227
Trained batch 132 in epoch 3, gen_loss = 0.8579219360100595, disc_loss = 0.056802298075386455
Trained batch 133 in epoch 3, gen_loss = 0.8558637553186559, disc_loss = 0.057188450192004
Trained batch 134 in epoch 3, gen_loss = 0.857581388508832, disc_loss = 0.057413987277282606
Trained batch 135 in epoch 3, gen_loss = 0.858269708998063, disc_loss = 0.057350131148910695
Trained batch 136 in epoch 3, gen_loss = 0.8563347019418313, disc_loss = 0.057893349918244526
Trained batch 137 in epoch 3, gen_loss = 0.8561035688372626, disc_loss = 0.05791977821322887
Trained batch 138 in epoch 3, gen_loss = 0.8558311290878187, disc_loss = 0.05790616021149879
Trained batch 139 in epoch 3, gen_loss = 0.8571516803332737, disc_loss = 0.05820530829951167
Trained batch 140 in epoch 3, gen_loss = 0.8554803970012259, disc_loss = 0.059322706945504705
Trained batch 141 in epoch 3, gen_loss = 0.8555644125166074, disc_loss = 0.059085045232844184
Trained batch 142 in epoch 3, gen_loss = 0.8561195839535106, disc_loss = 0.05913311916475113
Trained batch 143 in epoch 3, gen_loss = 0.8570310303734409, disc_loss = 0.05913685302301827
Trained batch 144 in epoch 3, gen_loss = 0.8572433956738176, disc_loss = 0.059027174256485085
Trained batch 145 in epoch 3, gen_loss = 0.857582935731705, disc_loss = 0.058830938633684424
Trained batch 146 in epoch 3, gen_loss = 0.8577365242705053, disc_loss = 0.05872318484395945
Trained batch 147 in epoch 3, gen_loss = 0.8570414564094028, disc_loss = 0.05873297606720715
Trained batch 148 in epoch 3, gen_loss = 0.8594360887604272, disc_loss = 0.05942065962559025
Trained batch 149 in epoch 3, gen_loss = 0.8595964829126994, disc_loss = 0.05922001159439484
Trained batch 150 in epoch 3, gen_loss = 0.8595513890910622, disc_loss = 0.0591392173795708
Trained batch 151 in epoch 3, gen_loss = 0.8587845250179893, disc_loss = 0.059251705147816164
Trained batch 152 in epoch 3, gen_loss = 0.8572105784821354, disc_loss = 0.059452310460163096
Trained batch 153 in epoch 3, gen_loss = 0.8597241841353379, disc_loss = 0.06313006750416833
Trained batch 154 in epoch 3, gen_loss = 0.858310249159413, disc_loss = 0.06323890668009557
Trained batch 155 in epoch 3, gen_loss = 0.8570373356342316, disc_loss = 0.06359687706646629
Trained batch 156 in epoch 3, gen_loss = 0.8568050842376271, disc_loss = 0.06370916569925797
Trained batch 157 in epoch 3, gen_loss = 0.8568432293360746, disc_loss = 0.06375547075243312
Trained batch 158 in epoch 3, gen_loss = 0.8567335028318489, disc_loss = 0.06396592123750246
Trained batch 159 in epoch 3, gen_loss = 0.8556014731526375, disc_loss = 0.06396619352744892
Trained batch 160 in epoch 3, gen_loss = 0.8552474242559871, disc_loss = 0.06390960159370247
Trained batch 161 in epoch 3, gen_loss = 0.855041966026212, disc_loss = 0.06382786998824205
Trained batch 162 in epoch 3, gen_loss = 0.8544560484359601, disc_loss = 0.06391097396109367
Trained batch 163 in epoch 3, gen_loss = 0.8545705439840875, disc_loss = 0.06457586205996028
Trained batch 164 in epoch 3, gen_loss = 0.8545002814495202, disc_loss = 0.06444117911159992
Trained batch 165 in epoch 3, gen_loss = 0.8528575692550245, disc_loss = 0.06466051645532071
Trained batch 166 in epoch 3, gen_loss = 0.8515243298279311, disc_loss = 0.06484954840988813
Trained batch 167 in epoch 3, gen_loss = 0.8536408802583104, disc_loss = 0.06511629786386731
Trained batch 168 in epoch 3, gen_loss = 0.8555476753669378, disc_loss = 0.06505267212949914
Trained batch 169 in epoch 3, gen_loss = 0.8544818362768959, disc_loss = 0.06514862886465647
Trained batch 170 in epoch 3, gen_loss = 0.8541883742600157, disc_loss = 0.06522001518884249
Trained batch 171 in epoch 3, gen_loss = 0.8527989571177682, disc_loss = 0.0653728356823152
Trained batch 172 in epoch 3, gen_loss = 0.8537818176208893, disc_loss = 0.0652841872756364
Trained batch 173 in epoch 3, gen_loss = 0.8537085470797001, disc_loss = 0.06544394436795478
Trained batch 174 in epoch 3, gen_loss = 0.8514465451240539, disc_loss = 0.06711580452110086
Trained batch 175 in epoch 3, gen_loss = 0.8510393815284426, disc_loss = 0.06713127976664426
Trained batch 176 in epoch 3, gen_loss = 0.8512743687899099, disc_loss = 0.06772192602314181
Trained batch 177 in epoch 3, gen_loss = 0.8500166686063402, disc_loss = 0.06811929767260726
Trained batch 178 in epoch 3, gen_loss = 0.8491298869335452, disc_loss = 0.06837842052583921
Trained batch 179 in epoch 3, gen_loss = 0.851029137439198, disc_loss = 0.06874004206102756
Trained batch 180 in epoch 3, gen_loss = 0.8494837873548434, disc_loss = 0.06930664841353235
Trained batch 181 in epoch 3, gen_loss = 0.8499870631065998, disc_loss = 0.06907948592657244
Trained batch 182 in epoch 3, gen_loss = 0.8512631469085569, disc_loss = 0.06890315231689013
Trained batch 183 in epoch 3, gen_loss = 0.8517605947411578, disc_loss = 0.0688002134329113
Trained batch 184 in epoch 3, gen_loss = 0.8512126945160531, disc_loss = 0.06867585034185164
Trained batch 185 in epoch 3, gen_loss = 0.8503271748301804, disc_loss = 0.06905010227434417
Trained batch 186 in epoch 3, gen_loss = 0.8499571222035005, disc_loss = 0.06892858287269737
Trained batch 187 in epoch 3, gen_loss = 0.8498421526969747, disc_loss = 0.06973990125264576
Trained batch 188 in epoch 3, gen_loss = 0.848531204556662, disc_loss = 0.0700449672424131
Trained batch 189 in epoch 3, gen_loss = 0.8471404684217353, disc_loss = 0.07020497126994948
Trained batch 190 in epoch 3, gen_loss = 0.8488390558053062, disc_loss = 0.07101404660074187
Trained batch 191 in epoch 3, gen_loss = 0.8485793878013889, disc_loss = 0.07104080101513925
Trained batch 192 in epoch 3, gen_loss = 0.8480366199745415, disc_loss = 0.07096258644497147
Trained batch 193 in epoch 3, gen_loss = 0.848169292678538, disc_loss = 0.07098569794913236
Trained batch 194 in epoch 3, gen_loss = 0.8474759496175326, disc_loss = 0.0710053365295514
Trained batch 195 in epoch 3, gen_loss = 0.8478055873087474, disc_loss = 0.07079111878779165
Trained batch 196 in epoch 3, gen_loss = 0.8470177178455488, disc_loss = 0.07093146294922696
Trained batch 197 in epoch 3, gen_loss = 0.8470238651892151, disc_loss = 0.071053948846053
Trained batch 198 in epoch 3, gen_loss = 0.846962882945286, disc_loss = 0.07086438196126241
Trained batch 199 in epoch 3, gen_loss = 0.8459749636054039, disc_loss = 0.0709820478502661
Trained batch 200 in epoch 3, gen_loss = 0.8462067201955995, disc_loss = 0.07098502129205127
Trained batch 201 in epoch 3, gen_loss = 0.8461147481852239, disc_loss = 0.07096108654975006
Trained batch 202 in epoch 3, gen_loss = 0.845597822384294, disc_loss = 0.07100534517079445
Trained batch 203 in epoch 3, gen_loss = 0.8451204022356108, disc_loss = 0.0710092200167185
Trained batch 204 in epoch 3, gen_loss = 0.8434700515212082, disc_loss = 0.0713980105682844
Trained batch 205 in epoch 3, gen_loss = 0.8441489845224954, disc_loss = 0.07132482985305844
Trained batch 206 in epoch 3, gen_loss = 0.8448487477026124, disc_loss = 0.07110035096425653
Trained batch 207 in epoch 3, gen_loss = 0.8441588721023157, disc_loss = 0.07110966248616862
Trained batch 208 in epoch 3, gen_loss = 0.8437455787042681, disc_loss = 0.07094122767983156
Trained batch 209 in epoch 3, gen_loss = 0.843770037094752, disc_loss = 0.0708096750878862
Trained batch 210 in epoch 3, gen_loss = 0.8438715946052877, disc_loss = 0.0705545666711449
Trained batch 211 in epoch 3, gen_loss = 0.8432678136060823, disc_loss = 0.07042564231164332
Trained batch 212 in epoch 3, gen_loss = 0.8425614761074943, disc_loss = 0.07059079542441267
Trained batch 213 in epoch 3, gen_loss = 0.8417021473434484, disc_loss = 0.07061010290146152
Trained batch 214 in epoch 3, gen_loss = 0.8422680200532425, disc_loss = 0.07036660593436207
Trained batch 215 in epoch 3, gen_loss = 0.8438080935566513, disc_loss = 0.07084639435116616
Trained batch 216 in epoch 3, gen_loss = 0.842744020547735, disc_loss = 0.07094515217167716
Trained batch 217 in epoch 3, gen_loss = 0.8414284261541629, disc_loss = 0.07138532218138832
Trained batch 218 in epoch 3, gen_loss = 0.8418471949285569, disc_loss = 0.07160966168901964
Trained batch 219 in epoch 3, gen_loss = 0.8432538298043337, disc_loss = 0.07193862317468633
Trained batch 220 in epoch 3, gen_loss = 0.8419139075063472, disc_loss = 0.07235215498952034
Trained batch 221 in epoch 3, gen_loss = 0.8410671753389342, disc_loss = 0.07250335455981193
Trained batch 222 in epoch 3, gen_loss = 0.8412564185702748, disc_loss = 0.07274761621426841
Trained batch 223 in epoch 3, gen_loss = 0.8414800768452031, disc_loss = 0.07319850174410801
Trained batch 224 in epoch 3, gen_loss = 0.8409969305992127, disc_loss = 0.07340502301024066
Trained batch 225 in epoch 3, gen_loss = 0.8398221106128355, disc_loss = 0.0736506778367721
Trained batch 226 in epoch 3, gen_loss = 0.8394176495232771, disc_loss = 0.07380464307898205
Trained batch 227 in epoch 3, gen_loss = 0.8386763038865307, disc_loss = 0.0738021906448953
Trained batch 228 in epoch 3, gen_loss = 0.837430576309887, disc_loss = 0.07391608518641848
Trained batch 229 in epoch 3, gen_loss = 0.8370812957701476, disc_loss = 0.07395055659277283
Trained batch 230 in epoch 3, gen_loss = 0.8373031789090211, disc_loss = 0.07401720691649687
Trained batch 231 in epoch 3, gen_loss = 0.8369578547004995, disc_loss = 0.07391001124352474
Trained batch 232 in epoch 3, gen_loss = 0.8364690294081562, disc_loss = 0.07380284907000514
Trained batch 233 in epoch 3, gen_loss = 0.8369151514310104, disc_loss = 0.07365222185308862
Trained batch 234 in epoch 3, gen_loss = 0.837201689659281, disc_loss = 0.07356310926694819
Trained batch 235 in epoch 3, gen_loss = 0.8363798914824502, disc_loss = 0.07349519822272961
Trained batch 236 in epoch 3, gen_loss = 0.8371172366262991, disc_loss = 0.07345201083722246
Trained batch 237 in epoch 3, gen_loss = 0.8369735471841668, disc_loss = 0.07341633013160039
Trained batch 238 in epoch 3, gen_loss = 0.8359771425753957, disc_loss = 0.07374270593116224
Trained batch 239 in epoch 3, gen_loss = 0.8367302688459556, disc_loss = 0.07354846682865172
Trained batch 240 in epoch 3, gen_loss = 0.8381365317526694, disc_loss = 0.0741289989999592
Trained batch 241 in epoch 3, gen_loss = 0.8369641439481215, disc_loss = 0.07415214974494759
Trained batch 242 in epoch 3, gen_loss = 0.8358430857521025, disc_loss = 0.07445359627865715
Trained batch 243 in epoch 3, gen_loss = 0.8367893119327358, disc_loss = 0.07498290358477684
Trained batch 244 in epoch 3, gen_loss = 0.8369310140609741, disc_loss = 0.07479996539044137
Trained batch 245 in epoch 3, gen_loss = 0.8359149796206776, disc_loss = 0.07497371288728182
Trained batch 246 in epoch 3, gen_loss = 0.8364788173181326, disc_loss = 0.07491089178151206
Trained batch 247 in epoch 3, gen_loss = 0.8366505251296105, disc_loss = 0.07482652255754557
Trained batch 248 in epoch 3, gen_loss = 0.836199764267029, disc_loss = 0.07477792733195555
Trained batch 249 in epoch 3, gen_loss = 0.8360119254589081, disc_loss = 0.0749099398329854
Trained batch 250 in epoch 3, gen_loss = 0.836369116230315, disc_loss = 0.07480955655979683
Trained batch 251 in epoch 3, gen_loss = 0.8365513651616989, disc_loss = 0.07501835858685867
Trained batch 252 in epoch 3, gen_loss = 0.8372302552456913, disc_loss = 0.07517974797945484
Trained batch 253 in epoch 3, gen_loss = 0.8380817393148978, disc_loss = 0.07538572259569966
Trained batch 254 in epoch 3, gen_loss = 0.8373302043653001, disc_loss = 0.07588180649076022
Trained batch 255 in epoch 3, gen_loss = 0.83828886738047, disc_loss = 0.07586612064187648
Trained batch 256 in epoch 3, gen_loss = 0.8384217404205976, disc_loss = 0.07613844549870445
Trained batch 257 in epoch 3, gen_loss = 0.8380041579867519, disc_loss = 0.07631373793146638
Trained batch 258 in epoch 3, gen_loss = 0.8378621270757844, disc_loss = 0.07640962671617973
Trained batch 259 in epoch 3, gen_loss = 0.8375152633740351, disc_loss = 0.07635379203666862
Trained batch 260 in epoch 3, gen_loss = 0.8380350598430268, disc_loss = 0.07640083921338178
Trained batch 261 in epoch 3, gen_loss = 0.8380713633453573, disc_loss = 0.07622886237951408
Trained batch 262 in epoch 3, gen_loss = 0.8381398014242658, disc_loss = 0.07605747012386077
Trained batch 263 in epoch 3, gen_loss = 0.8382590799169107, disc_loss = 0.07595793344785995
Trained batch 264 in epoch 3, gen_loss = 0.8384929951631798, disc_loss = 0.07578106140893585
Trained batch 265 in epoch 3, gen_loss = 0.8387035458607781, disc_loss = 0.07568689838359903
Trained batch 266 in epoch 3, gen_loss = 0.8391651337066394, disc_loss = 0.07545364108494716
Trained batch 267 in epoch 3, gen_loss = 0.8397676373150811, disc_loss = 0.07532177288988744
Trained batch 268 in epoch 3, gen_loss = 0.8396343227655915, disc_loss = 0.0752210471966065
Trained batch 269 in epoch 3, gen_loss = 0.8387210841532107, disc_loss = 0.07533156742445296
Trained batch 270 in epoch 3, gen_loss = 0.838696506850394, disc_loss = 0.07520817074842229
Trained batch 271 in epoch 3, gen_loss = 0.8387930294608369, disc_loss = 0.07503163067089832
Trained batch 272 in epoch 3, gen_loss = 0.8408268818925152, disc_loss = 0.07519484658285484
Trained batch 273 in epoch 3, gen_loss = 0.840660968183601, disc_loss = 0.07514049348346617
Trained batch 274 in epoch 3, gen_loss = 0.8411620541052385, disc_loss = 0.07490730949762192
Trained batch 275 in epoch 3, gen_loss = 0.841653860349586, disc_loss = 0.07468878663064021
Trained batch 276 in epoch 3, gen_loss = 0.8426115867893619, disc_loss = 0.07450569978837825
Trained batch 277 in epoch 3, gen_loss = 0.841912411957336, disc_loss = 0.07459140339491072
Trained batch 278 in epoch 3, gen_loss = 0.8421039111298045, disc_loss = 0.07437144465223756
Trained batch 279 in epoch 3, gen_loss = 0.8430510780641011, disc_loss = 0.07439885735179165
Trained batch 280 in epoch 3, gen_loss = 0.843495104236535, disc_loss = 0.07430045792892628
Trained batch 281 in epoch 3, gen_loss = 0.8428590126494144, disc_loss = 0.07437733115284895
Trained batch 282 in epoch 3, gen_loss = 0.8425095679481964, disc_loss = 0.0742618660722257
Trained batch 283 in epoch 3, gen_loss = 0.8424561414080607, disc_loss = 0.07408907594697052
Trained batch 284 in epoch 3, gen_loss = 0.8431423291825412, disc_loss = 0.07431689714849518
Trained batch 285 in epoch 3, gen_loss = 0.8435145837443692, disc_loss = 0.07413169441718634
Trained batch 286 in epoch 3, gen_loss = 0.8436041522109134, disc_loss = 0.07400819012499334
Trained batch 287 in epoch 3, gen_loss = 0.8448978567288982, disc_loss = 0.07385578448560813
Trained batch 288 in epoch 3, gen_loss = 0.8441672824245836, disc_loss = 0.07421659342751268
Trained batch 289 in epoch 3, gen_loss = 0.8451937206860246, disc_loss = 0.07426769062555556
Trained batch 290 in epoch 3, gen_loss = 0.8452175671292335, disc_loss = 0.07439756387991901
Trained batch 291 in epoch 3, gen_loss = 0.8442491503202751, disc_loss = 0.07474592863582075
Trained batch 292 in epoch 3, gen_loss = 0.8437307118962649, disc_loss = 0.07475331158348623
Trained batch 293 in epoch 3, gen_loss = 0.8446872313411868, disc_loss = 0.07500278282923256
Trained batch 294 in epoch 3, gen_loss = 0.844137116407944, disc_loss = 0.07502663706003104
Trained batch 295 in epoch 3, gen_loss = 0.8436701851519378, disc_loss = 0.07518382979292623
Trained batch 296 in epoch 3, gen_loss = 0.8436253642795062, disc_loss = 0.07521302463417803
Trained batch 297 in epoch 3, gen_loss = 0.8442726661294899, disc_loss = 0.07525501449923687
Trained batch 298 in epoch 3, gen_loss = 0.843766037835724, disc_loss = 0.07545435961560162
Trained batch 299 in epoch 3, gen_loss = 0.8429801877339681, disc_loss = 0.07545362715609372
Trained batch 300 in epoch 3, gen_loss = 0.8435529462522843, disc_loss = 0.07536919238943099
Trained batch 301 in epoch 3, gen_loss = 0.8428970435202516, disc_loss = 0.07545352245785839
Trained batch 302 in epoch 3, gen_loss = 0.8435541216296332, disc_loss = 0.07547433265844489
Trained batch 303 in epoch 3, gen_loss = 0.8435258083045483, disc_loss = 0.07565788395004347
Trained batch 304 in epoch 3, gen_loss = 0.8426036869893309, disc_loss = 0.07616362146361441
Trained batch 305 in epoch 3, gen_loss = 0.8426569219118629, disc_loss = 0.0763404708252185
Trained batch 306 in epoch 3, gen_loss = 0.841910220512738, disc_loss = 0.07635425249302717
Trained batch 307 in epoch 3, gen_loss = 0.8420418880202554, disc_loss = 0.07630823587381898
Trained batch 308 in epoch 3, gen_loss = 0.8422156016803483, disc_loss = 0.07616372875157973
Trained batch 309 in epoch 3, gen_loss = 0.841890009372465, disc_loss = 0.07618561421611136
Trained batch 310 in epoch 3, gen_loss = 0.8421106338500977, disc_loss = 0.07617692149564671
Trained batch 311 in epoch 3, gen_loss = 0.8423977643251419, disc_loss = 0.07598818300996357
Trained batch 312 in epoch 3, gen_loss = 0.8425911137471184, disc_loss = 0.07578997599621551
Trained batch 313 in epoch 3, gen_loss = 0.8415276930210697, disc_loss = 0.07590744713214552
Trained batch 314 in epoch 3, gen_loss = 0.842380968918876, disc_loss = 0.0757418304681778
Trained batch 315 in epoch 3, gen_loss = 0.8435740069120745, disc_loss = 0.07561925235145454
Trained batch 316 in epoch 3, gen_loss = 0.843633914031441, disc_loss = 0.0754319943299617
Trained batch 317 in epoch 3, gen_loss = 0.8437156270509996, disc_loss = 0.07530329473691541
Trained batch 318 in epoch 3, gen_loss = 0.8429376053212204, disc_loss = 0.07540383050948102
Trained batch 319 in epoch 3, gen_loss = 0.8436898848041892, disc_loss = 0.07529311958933249
Trained batch 320 in epoch 3, gen_loss = 0.8446969816989245, disc_loss = 0.07537871544652638
Trained batch 321 in epoch 3, gen_loss = 0.844467823734935, disc_loss = 0.0752788789176978
Trained batch 322 in epoch 3, gen_loss = 0.8442197602599767, disc_loss = 0.07520067237386763
Trained batch 323 in epoch 3, gen_loss = 0.8444161019575449, disc_loss = 0.07512380478236778
Trained batch 324 in epoch 3, gen_loss = 0.8442485712124751, disc_loss = 0.07503779246256902
Trained batch 325 in epoch 3, gen_loss = 0.8457821986060933, disc_loss = 0.07502960032023535
Trained batch 326 in epoch 3, gen_loss = 0.8466507420627349, disc_loss = 0.07487997130151917
Trained batch 327 in epoch 3, gen_loss = 0.8461634794749865, disc_loss = 0.07489530412798248
Trained batch 328 in epoch 3, gen_loss = 0.8461646992022506, disc_loss = 0.07488563197090271
Trained batch 329 in epoch 3, gen_loss = 0.8461346057328311, disc_loss = 0.07476076755785581
Trained batch 330 in epoch 3, gen_loss = 0.8461378706545988, disc_loss = 0.07460226519230269
Trained batch 331 in epoch 3, gen_loss = 0.8467426089996315, disc_loss = 0.07442117791275034
Trained batch 332 in epoch 3, gen_loss = 0.8472054783288423, disc_loss = 0.07430503163039237
Trained batch 333 in epoch 3, gen_loss = 0.8472673259452431, disc_loss = 0.07411388547332612
Trained batch 334 in epoch 3, gen_loss = 0.8468339596221696, disc_loss = 0.07440185647791446
Trained batch 335 in epoch 3, gen_loss = 0.8475191994082361, disc_loss = 0.07431523768796719
Trained batch 336 in epoch 3, gen_loss = 0.8477140666823005, disc_loss = 0.07428685390840917
Trained batch 337 in epoch 3, gen_loss = 0.8475540398493321, disc_loss = 0.07420805397239574
Trained batch 338 in epoch 3, gen_loss = 0.8474951509529158, disc_loss = 0.07418827686986301
Trained batch 339 in epoch 3, gen_loss = 0.8473066068747465, disc_loss = 0.07420877609128022
Trained batch 340 in epoch 3, gen_loss = 0.847463403104687, disc_loss = 0.0741272438781833
Trained batch 341 in epoch 3, gen_loss = 0.8465142645682507, disc_loss = 0.07445218826627784
Trained batch 342 in epoch 3, gen_loss = 0.8467807867089097, disc_loss = 0.0745623903349042
Trained batch 343 in epoch 3, gen_loss = 0.8468214458850927, disc_loss = 0.07444973062279872
Trained batch 344 in epoch 3, gen_loss = 0.8463046652683314, disc_loss = 0.0744797933117851
Trained batch 345 in epoch 3, gen_loss = 0.8468124189473301, disc_loss = 0.07433715724047123
Trained batch 346 in epoch 3, gen_loss = 0.8461913131499497, disc_loss = 0.07431462659132841
Trained batch 347 in epoch 3, gen_loss = 0.8458547253033211, disc_loss = 0.07429449717064612
Trained batch 348 in epoch 3, gen_loss = 0.8459692356579624, disc_loss = 0.07420246818377757
Trained batch 349 in epoch 3, gen_loss = 0.8453718842778887, disc_loss = 0.07423280936000602
Trained batch 350 in epoch 3, gen_loss = 0.8449032432333357, disc_loss = 0.07415103475878976
Trained batch 351 in epoch 3, gen_loss = 0.8459976833652366, disc_loss = 0.07410157218691893
Trained batch 352 in epoch 3, gen_loss = 0.8461934984912278, disc_loss = 0.07396766232331903
Trained batch 353 in epoch 3, gen_loss = 0.8459225881234401, disc_loss = 0.07396281577152132
Trained batch 354 in epoch 3, gen_loss = 0.8455928312221044, disc_loss = 0.07389845679396055
Trained batch 355 in epoch 3, gen_loss = 0.8446396346507448, disc_loss = 0.0741702080364182
Trained batch 356 in epoch 3, gen_loss = 0.8455762377306193, disc_loss = 0.07442009823882029
Trained batch 357 in epoch 3, gen_loss = 0.845021295480888, disc_loss = 0.0743974616995612
Trained batch 358 in epoch 3, gen_loss = 0.8443209885886784, disc_loss = 0.07445963867745442
Trained batch 359 in epoch 3, gen_loss = 0.844906230767568, disc_loss = 0.07431523564219888
Trained batch 360 in epoch 3, gen_loss = 0.8447899641752904, disc_loss = 0.07422654187549267
Trained batch 361 in epoch 3, gen_loss = 0.8444347554478198, disc_loss = 0.07419702088851379
Trained batch 362 in epoch 3, gen_loss = 0.8442333936691284, disc_loss = 0.07412419717799944
Trained batch 363 in epoch 3, gen_loss = 0.8443842340301682, disc_loss = 0.07396878052635916
Trained batch 364 in epoch 3, gen_loss = 0.8444039008388781, disc_loss = 0.07380321390467555
Trained batch 365 in epoch 3, gen_loss = 0.8447590167405176, disc_loss = 0.07364910191352494
Trained batch 366 in epoch 3, gen_loss = 0.8448026313443925, disc_loss = 0.0735237187698321
Trained batch 367 in epoch 3, gen_loss = 0.8447581928061403, disc_loss = 0.07340228617059714
Trained batch 368 in epoch 3, gen_loss = 0.8449635326377745, disc_loss = 0.07331794817101583
Trained batch 369 in epoch 3, gen_loss = 0.8449144068601969, disc_loss = 0.07326357881916133
Trained batch 370 in epoch 3, gen_loss = 0.8450499207504355, disc_loss = 0.07312207700900553
Trained batch 371 in epoch 3, gen_loss = 0.8453067412940405, disc_loss = 0.07301327152307877
Trained batch 372 in epoch 3, gen_loss = 0.8449741365442967, disc_loss = 0.0730893894625533
Trained batch 373 in epoch 3, gen_loss = 0.8450779306059852, disc_loss = 0.07315148152958821
Trained batch 374 in epoch 3, gen_loss = 0.845608190536499, disc_loss = 0.07301852576682966
Trained batch 375 in epoch 3, gen_loss = 0.8457163987641639, disc_loss = 0.07291305802039247
Trained batch 376 in epoch 3, gen_loss = 0.8455607185945587, disc_loss = 0.07293022295277299
Trained batch 377 in epoch 3, gen_loss = 0.8459699295815968, disc_loss = 0.07280334417102119
Trained batch 378 in epoch 3, gen_loss = 0.8457162342474139, disc_loss = 0.07269331964474948
Trained batch 379 in epoch 3, gen_loss = 0.8466403678843849, disc_loss = 0.07277027233503759
Trained batch 380 in epoch 3, gen_loss = 0.8460631332998201, disc_loss = 0.07293530506890981
Trained batch 381 in epoch 3, gen_loss = 0.8462645842142754, disc_loss = 0.07293495120656193
Trained batch 382 in epoch 3, gen_loss = 0.8460453185337953, disc_loss = 0.07296050933503373
Trained batch 383 in epoch 3, gen_loss = 0.8453449625521898, disc_loss = 0.0730588954781221
Trained batch 384 in epoch 3, gen_loss = 0.8461814861793022, disc_loss = 0.0731675784913944
Trained batch 385 in epoch 3, gen_loss = 0.8464682466625549, disc_loss = 0.07302444173660072
Trained batch 386 in epoch 3, gen_loss = 0.8461433604398131, disc_loss = 0.07300134792741032
Trained batch 387 in epoch 3, gen_loss = 0.8466599984574563, disc_loss = 0.07284994014135572
Trained batch 388 in epoch 3, gen_loss = 0.846147561441044, disc_loss = 0.07285188285724899
Trained batch 389 in epoch 3, gen_loss = 0.8461151369107075, disc_loss = 0.07280994799608985
Trained batch 390 in epoch 3, gen_loss = 0.8463510956300799, disc_loss = 0.07282344605106755
Trained batch 391 in epoch 3, gen_loss = 0.8465381114154445, disc_loss = 0.07276708106937989
Trained batch 392 in epoch 3, gen_loss = 0.8461735491230894, disc_loss = 0.0728421264396786
Trained batch 393 in epoch 3, gen_loss = 0.8462495174504778, disc_loss = 0.07282807372349698
Trained batch 394 in epoch 3, gen_loss = 0.8477293696584581, disc_loss = 0.0728392435284921
Trained batch 395 in epoch 3, gen_loss = 0.8474841369221909, disc_loss = 0.07274970372508496
Trained batch 396 in epoch 3, gen_loss = 0.8471079344112867, disc_loss = 0.07282592404765131
Trained batch 397 in epoch 3, gen_loss = 0.847746705589582, disc_loss = 0.07309187641460917
Trained batch 398 in epoch 3, gen_loss = 0.8478371123024694, disc_loss = 0.07302046242055663
Trained batch 399 in epoch 3, gen_loss = 0.8476908572018147, disc_loss = 0.07313850678270682
Trained batch 400 in epoch 3, gen_loss = 0.8478936706100616, disc_loss = 0.07316473466193216
Trained batch 401 in epoch 3, gen_loss = 0.8480574284026872, disc_loss = 0.07314549977497305
Trained batch 402 in epoch 3, gen_loss = 0.8477648792432496, disc_loss = 0.073065140719061
Trained batch 403 in epoch 3, gen_loss = 0.8474340931613846, disc_loss = 0.07308665083693618
Trained batch 404 in epoch 3, gen_loss = 0.8477817954840483, disc_loss = 0.07318068337799222
Trained batch 405 in epoch 3, gen_loss = 0.8471555445581821, disc_loss = 0.07347961276393439
Trained batch 406 in epoch 3, gen_loss = 0.8472168227378508, disc_loss = 0.07344752468434174
Trained batch 407 in epoch 3, gen_loss = 0.8473961793032347, disc_loss = 0.07342281171312447
Trained batch 408 in epoch 3, gen_loss = 0.8473777323596926, disc_loss = 0.07340834988167277
Trained batch 409 in epoch 3, gen_loss = 0.8469465185956258, disc_loss = 0.07354091413818845
Trained batch 410 in epoch 3, gen_loss = 0.847038969651336, disc_loss = 0.0736799332995303
Trained batch 411 in epoch 3, gen_loss = 0.8466893379549378, disc_loss = 0.07367150941908866
Trained batch 412 in epoch 3, gen_loss = 0.8468742419674667, disc_loss = 0.0735896098118537
Trained batch 413 in epoch 3, gen_loss = 0.8463320778187923, disc_loss = 0.07357598053615379
Trained batch 414 in epoch 3, gen_loss = 0.8463208740016064, disc_loss = 0.07357834937297796
Trained batch 415 in epoch 3, gen_loss = 0.8459747701596755, disc_loss = 0.07361562373430039
Trained batch 416 in epoch 3, gen_loss = 0.8461354536404141, disc_loss = 0.07351224996122739
Trained batch 417 in epoch 3, gen_loss = 0.8464354578958174, disc_loss = 0.07346573326531708
Trained batch 418 in epoch 3, gen_loss = 0.8465270742880701, disc_loss = 0.07333767927765206
Trained batch 419 in epoch 3, gen_loss = 0.8465064027479716, disc_loss = 0.07331316949844005
Trained batch 420 in epoch 3, gen_loss = 0.8460071946266428, disc_loss = 0.07336623810736059
Trained batch 421 in epoch 3, gen_loss = 0.8466415223069665, disc_loss = 0.07356829644441251
Trained batch 422 in epoch 3, gen_loss = 0.8466962743594573, disc_loss = 0.07346383357821275
Trained batch 423 in epoch 3, gen_loss = 0.8460481445182044, disc_loss = 0.07368881136556771
Trained batch 424 in epoch 3, gen_loss = 0.8460367476238924, disc_loss = 0.07381893603898147
Trained batch 425 in epoch 3, gen_loss = 0.8461029922738321, disc_loss = 0.07368736123631188
Trained batch 426 in epoch 3, gen_loss = 0.8465410787830309, disc_loss = 0.07355725192693902
Trained batch 427 in epoch 3, gen_loss = 0.846094521406655, disc_loss = 0.07364878211405441
Trained batch 428 in epoch 3, gen_loss = 0.8463064993455971, disc_loss = 0.07360131420099582
Trained batch 429 in epoch 3, gen_loss = 0.8460589910662452, disc_loss = 0.0735117575955079
Trained batch 430 in epoch 3, gen_loss = 0.8458050886328978, disc_loss = 0.07369585056722233
Trained batch 431 in epoch 3, gen_loss = 0.8462262237789454, disc_loss = 0.07364363646505538
Trained batch 432 in epoch 3, gen_loss = 0.8460043196590062, disc_loss = 0.0735751639763388
Trained batch 433 in epoch 3, gen_loss = 0.8461153433070204, disc_loss = 0.07349780093543747
Trained batch 434 in epoch 3, gen_loss = 0.8460424694521674, disc_loss = 0.0734149548664004
Trained batch 435 in epoch 3, gen_loss = 0.8462664687305416, disc_loss = 0.07332775005088145
Trained batch 436 in epoch 3, gen_loss = 0.8461921216421324, disc_loss = 0.07332042880671726
Trained batch 437 in epoch 3, gen_loss = 0.8468481646553022, disc_loss = 0.07324831275116295
Trained batch 438 in epoch 3, gen_loss = 0.8468623294374122, disc_loss = 0.0732041366020714
Trained batch 439 in epoch 3, gen_loss = 0.8468026619065891, disc_loss = 0.07311872695784338
Trained batch 440 in epoch 3, gen_loss = 0.8468432567016878, disc_loss = 0.07302513199725322
Trained batch 441 in epoch 3, gen_loss = 0.847425303308133, disc_loss = 0.07305131835559577
Trained batch 442 in epoch 3, gen_loss = 0.846721453672069, disc_loss = 0.07330447599989767
Trained batch 443 in epoch 3, gen_loss = 0.846723890922091, disc_loss = 0.07322605257761572
Trained batch 444 in epoch 3, gen_loss = 0.8474700575464227, disc_loss = 0.07324646754671683
Trained batch 445 in epoch 3, gen_loss = 0.8473403523321109, disc_loss = 0.07324087539387057
Trained batch 446 in epoch 3, gen_loss = 0.84681145230129, disc_loss = 0.07340043816315447
Trained batch 447 in epoch 3, gen_loss = 0.8471062779426575, disc_loss = 0.07346990155513465
Trained batch 448 in epoch 3, gen_loss = 0.8474769058631099, disc_loss = 0.07342254353649831
Trained batch 449 in epoch 3, gen_loss = 0.8476457528273265, disc_loss = 0.0733311106906169
Trained batch 450 in epoch 3, gen_loss = 0.8473993498840248, disc_loss = 0.07327766605588854
Trained batch 451 in epoch 3, gen_loss = 0.8476196523525018, disc_loss = 0.07325065803334974
Trained batch 452 in epoch 3, gen_loss = 0.8474615932037236, disc_loss = 0.07315266465616081
Trained batch 453 in epoch 3, gen_loss = 0.8474729695246608, disc_loss = 0.0730368005058478
Trained batch 454 in epoch 3, gen_loss = 0.8469449072093754, disc_loss = 0.07331783045492657
Trained batch 455 in epoch 3, gen_loss = 0.8481533048968566, disc_loss = 0.07353758051574819
Trained batch 456 in epoch 3, gen_loss = 0.8486251142405837, disc_loss = 0.07364630191515585
Trained batch 457 in epoch 3, gen_loss = 0.8481411577312187, disc_loss = 0.07394493069686808
Trained batch 458 in epoch 3, gen_loss = 0.8479162461097983, disc_loss = 0.07403855159886846
Trained batch 459 in epoch 3, gen_loss = 0.8480254826338395, disc_loss = 0.07412899608885788
Trained batch 460 in epoch 3, gen_loss = 0.848100596420677, disc_loss = 0.07427517451758046
Trained batch 461 in epoch 3, gen_loss = 0.8484312181090896, disc_loss = 0.07434546329218136
Trained batch 462 in epoch 3, gen_loss = 0.8483523506325213, disc_loss = 0.07432159788898528
Trained batch 463 in epoch 3, gen_loss = 0.8483243854395275, disc_loss = 0.07443081113260946
Trained batch 464 in epoch 3, gen_loss = 0.8479759370127032, disc_loss = 0.0744307450329264
Trained batch 465 in epoch 3, gen_loss = 0.847648301349689, disc_loss = 0.07443584397219345
Trained batch 466 in epoch 3, gen_loss = 0.8476879661803072, disc_loss = 0.07445178071846607
Trained batch 467 in epoch 3, gen_loss = 0.8476833818305252, disc_loss = 0.07435315424918683
Trained batch 468 in epoch 3, gen_loss = 0.8476318980076674, disc_loss = 0.07431263916059407
Trained batch 469 in epoch 3, gen_loss = 0.8471015133756272, disc_loss = 0.07451618170524214
Trained batch 470 in epoch 3, gen_loss = 0.8473845257121286, disc_loss = 0.0744170060523661
Trained batch 471 in epoch 3, gen_loss = 0.8481990154516899, disc_loss = 0.07435764588013102
Trained batch 472 in epoch 3, gen_loss = 0.8477680332816933, disc_loss = 0.07454015948784087
Trained batch 473 in epoch 3, gen_loss = 0.8481720758892816, disc_loss = 0.07448261050617457
Trained batch 474 in epoch 3, gen_loss = 0.848256533020421, disc_loss = 0.07443016561434457
Trained batch 475 in epoch 3, gen_loss = 0.8485162090353605, disc_loss = 0.07433909779031049
Trained batch 476 in epoch 3, gen_loss = 0.8484029534977687, disc_loss = 0.07425407429793908
Trained batch 477 in epoch 3, gen_loss = 0.8486968197832546, disc_loss = 0.07413527098090766
Trained batch 478 in epoch 3, gen_loss = 0.8485353208285035, disc_loss = 0.07412296856922683
Trained batch 479 in epoch 3, gen_loss = 0.848597385858496, disc_loss = 0.07402493844468457
Trained batch 480 in epoch 3, gen_loss = 0.8490802427587291, disc_loss = 0.07397996262683999
Trained batch 481 in epoch 3, gen_loss = 0.8490293452601215, disc_loss = 0.07391026872886476
Trained batch 482 in epoch 3, gen_loss = 0.8489698155572942, disc_loss = 0.07380766845954193
Trained batch 483 in epoch 3, gen_loss = 0.8490276872372824, disc_loss = 0.07368183810040663
Trained batch 484 in epoch 3, gen_loss = 0.8492979541267316, disc_loss = 0.07355309661055348
Trained batch 485 in epoch 3, gen_loss = 0.8489351871082321, disc_loss = 0.07345277543175859
Trained batch 486 in epoch 3, gen_loss = 0.8495779656776412, disc_loss = 0.07358570739596286
Trained batch 487 in epoch 3, gen_loss = 0.8486418518863741, disc_loss = 0.07387907430529594
Trained batch 488 in epoch 3, gen_loss = 0.8491489504500157, disc_loss = 0.07391268578653198
Trained batch 489 in epoch 3, gen_loss = 0.8487922470180356, disc_loss = 0.07401645127303746
Trained batch 490 in epoch 3, gen_loss = 0.8492403638581394, disc_loss = 0.07439587938991923
Trained batch 491 in epoch 3, gen_loss = 0.8490985610136171, disc_loss = 0.07441871178646882
Trained batch 492 in epoch 3, gen_loss = 0.8486897958703263, disc_loss = 0.07448650428054299
Trained batch 493 in epoch 3, gen_loss = 0.8486646294352497, disc_loss = 0.07445771102359904
Trained batch 494 in epoch 3, gen_loss = 0.8485443376531505, disc_loss = 0.07442468068364895
Trained batch 495 in epoch 3, gen_loss = 0.8485277778198642, disc_loss = 0.07471942031125148
Trained batch 496 in epoch 3, gen_loss = 0.8482833932822859, disc_loss = 0.07476082831711117
Trained batch 497 in epoch 3, gen_loss = 0.8477426647661201, disc_loss = 0.07499118167981805
Trained batch 498 in epoch 3, gen_loss = 0.848061586190799, disc_loss = 0.07497450427893168
Trained batch 499 in epoch 3, gen_loss = 0.8480704823732376, disc_loss = 0.07495911624282599
Trained batch 500 in epoch 3, gen_loss = 0.8477597625669605, disc_loss = 0.0749295207034209
Trained batch 501 in epoch 3, gen_loss = 0.8477694027689824, disc_loss = 0.07487771038960413
Trained batch 502 in epoch 3, gen_loss = 0.8476429613636692, disc_loss = 0.07481562997960665
Trained batch 503 in epoch 3, gen_loss = 0.8476008041983559, disc_loss = 0.07477490319353011
Trained batch 504 in epoch 3, gen_loss = 0.8479315580707966, disc_loss = 0.07482961771069187
Trained batch 505 in epoch 3, gen_loss = 0.8473849350755865, disc_loss = 0.07498729868751505
Trained batch 506 in epoch 3, gen_loss = 0.847413308639263, disc_loss = 0.07492164401172181
Trained batch 507 in epoch 3, gen_loss = 0.8480240450365337, disc_loss = 0.07493793486991501
Trained batch 508 in epoch 3, gen_loss = 0.8478072343031877, disc_loss = 0.07485293804106169
Trained batch 509 in epoch 3, gen_loss = 0.8476857476374682, disc_loss = 0.07477777136453226
Trained batch 510 in epoch 3, gen_loss = 0.8475122676903488, disc_loss = 0.07468083727951735
Trained batch 511 in epoch 3, gen_loss = 0.8469620546093211, disc_loss = 0.07481382254263735
Trained batch 512 in epoch 3, gen_loss = 0.8473245775722853, disc_loss = 0.07492185117891076
Trained batch 513 in epoch 3, gen_loss = 0.8466878382612295, disc_loss = 0.07507014352509368
Trained batch 514 in epoch 3, gen_loss = 0.8466547308616268, disc_loss = 0.07502976985449351
Trained batch 515 in epoch 3, gen_loss = 0.846732402956763, disc_loss = 0.07498862046762839
Trained batch 516 in epoch 3, gen_loss = 0.8464692708832614, disc_loss = 0.07498159605065789
Trained batch 517 in epoch 3, gen_loss = 0.8466389298899294, disc_loss = 0.07502043741650909
Trained batch 518 in epoch 3, gen_loss = 0.8462425402593521, disc_loss = 0.0750276718489639
Trained batch 519 in epoch 3, gen_loss = 0.8461246749529472, disc_loss = 0.07496693118188817
Trained batch 520 in epoch 3, gen_loss = 0.8460176432658981, disc_loss = 0.07486083468282863
Trained batch 521 in epoch 3, gen_loss = 0.8458975560363682, disc_loss = 0.07479547640358694
Trained batch 522 in epoch 3, gen_loss = 0.8461079432221261, disc_loss = 0.07472887630601116
Trained batch 523 in epoch 3, gen_loss = 0.8459767080445326, disc_loss = 0.07465831374834853
Trained batch 524 in epoch 3, gen_loss = 0.8459370147614252, disc_loss = 0.07466830982693604
Trained batch 525 in epoch 3, gen_loss = 0.8454046036354036, disc_loss = 0.07469353494464558
Trained batch 526 in epoch 3, gen_loss = 0.8453446552016025, disc_loss = 0.07473766674734723
Trained batch 527 in epoch 3, gen_loss = 0.8450355495918881, disc_loss = 0.07474469364917075
Trained batch 528 in epoch 3, gen_loss = 0.8449832674235612, disc_loss = 0.07473423582323896
Trained batch 529 in epoch 3, gen_loss = 0.8446650785095287, disc_loss = 0.07474564331812117
Trained batch 530 in epoch 3, gen_loss = 0.844352882348436, disc_loss = 0.07471382501842051
Trained batch 531 in epoch 3, gen_loss = 0.8447280139627313, disc_loss = 0.07463598302110358
Trained batch 532 in epoch 3, gen_loss = 0.8443522414168095, disc_loss = 0.07460468594075703
Trained batch 533 in epoch 3, gen_loss = 0.8444281538550773, disc_loss = 0.07453388067429767
Trained batch 534 in epoch 3, gen_loss = 0.8450770746881717, disc_loss = 0.07449776129535983
Trained batch 535 in epoch 3, gen_loss = 0.8448876605105045, disc_loss = 0.07451879436414299
Trained batch 536 in epoch 3, gen_loss = 0.8445642000026099, disc_loss = 0.07451463625653607
Trained batch 537 in epoch 3, gen_loss = 0.8454614841140335, disc_loss = 0.07492836504191382
Trained batch 538 in epoch 3, gen_loss = 0.8453705297551483, disc_loss = 0.07482633631545117
Trained batch 539 in epoch 3, gen_loss = 0.8446839352448782, disc_loss = 0.07505361267744944
Trained batch 540 in epoch 3, gen_loss = 0.8447331315708689, disc_loss = 0.0750346430809738
Trained batch 541 in epoch 3, gen_loss = 0.8447608320915391, disc_loss = 0.07492993180244831
Trained batch 542 in epoch 3, gen_loss = 0.8448023265896581, disc_loss = 0.07496251272205709
Trained batch 543 in epoch 3, gen_loss = 0.8445551784380394, disc_loss = 0.0749691830304287
Trained batch 544 in epoch 3, gen_loss = 0.8448043380308589, disc_loss = 0.0749061783314298
Trained batch 545 in epoch 3, gen_loss = 0.8448326739417764, disc_loss = 0.07484192985891204
Trained batch 546 in epoch 3, gen_loss = 0.8451308568827195, disc_loss = 0.07480088587325931
Trained batch 547 in epoch 3, gen_loss = 0.8447923029426241, disc_loss = 0.0747640906921486
Trained batch 548 in epoch 3, gen_loss = 0.8448352926632963, disc_loss = 0.07467984385069168
Trained batch 549 in epoch 3, gen_loss = 0.8447586752067913, disc_loss = 0.07468908502296968
Trained batch 550 in epoch 3, gen_loss = 0.8450181816320886, disc_loss = 0.07464044856181379
Trained batch 551 in epoch 3, gen_loss = 0.8456808284356974, disc_loss = 0.07462072344091923
Trained batch 552 in epoch 3, gen_loss = 0.8452697322985148, disc_loss = 0.0747207300114373
Trained batch 553 in epoch 3, gen_loss = 0.845024749367676, disc_loss = 0.0747600306995509
Trained batch 554 in epoch 3, gen_loss = 0.8456439865602029, disc_loss = 0.0749690101221875
Trained batch 555 in epoch 3, gen_loss = 0.8454615455522811, disc_loss = 0.07498810146834782
Trained batch 556 in epoch 3, gen_loss = 0.8453624781415108, disc_loss = 0.07492708459603509
Trained batch 557 in epoch 3, gen_loss = 0.8454002360930152, disc_loss = 0.07488665734434427
Trained batch 558 in epoch 3, gen_loss = 0.845709448103828, disc_loss = 0.0749607206070679
Trained batch 559 in epoch 3, gen_loss = 0.8453026543770518, disc_loss = 0.07501477848605385
Trained batch 560 in epoch 3, gen_loss = 0.845317252817001, disc_loss = 0.07494475806726279
Trained batch 561 in epoch 3, gen_loss = 0.8456969948425836, disc_loss = 0.07502898577852606
Trained batch 562 in epoch 3, gen_loss = 0.8453681321804731, disc_loss = 0.07503466333260968
Trained batch 563 in epoch 3, gen_loss = 0.8451683380713699, disc_loss = 0.07494415802194189
Trained batch 564 in epoch 3, gen_loss = 0.8453370456146982, disc_loss = 0.07485462341094966
Trained batch 565 in epoch 3, gen_loss = 0.8455721351578042, disc_loss = 0.07492248392449988
Trained batch 566 in epoch 3, gen_loss = 0.8451550856258924, disc_loss = 0.07509033944017568
Trained batch 567 in epoch 3, gen_loss = 0.8449696526980736, disc_loss = 0.07503646324572324
Trained batch 568 in epoch 3, gen_loss = 0.8456548337148656, disc_loss = 0.07522582333135584
Trained batch 569 in epoch 3, gen_loss = 0.8452216687955354, disc_loss = 0.07529303976252937
Trained batch 570 in epoch 3, gen_loss = 0.8447966756211062, disc_loss = 0.07544058969410727
Trained batch 571 in epoch 3, gen_loss = 0.8450999290167869, disc_loss = 0.07539173387238508
Trained batch 572 in epoch 3, gen_loss = 0.8450135534554459, disc_loss = 0.07537357957406297
Trained batch 573 in epoch 3, gen_loss = 0.8448545930692959, disc_loss = 0.07532080661713142
Trained batch 574 in epoch 3, gen_loss = 0.8452385836062224, disc_loss = 0.07528196986926639
Trained batch 575 in epoch 3, gen_loss = 0.8450411771320634, disc_loss = 0.0752008792963655
Trained batch 576 in epoch 3, gen_loss = 0.8446048993998219, disc_loss = 0.07539362177265682
Trained batch 577 in epoch 3, gen_loss = 0.8450389223940232, disc_loss = 0.0753645912218826
Trained batch 578 in epoch 3, gen_loss = 0.8448881180587005, disc_loss = 0.0752968233760723
Trained batch 579 in epoch 3, gen_loss = 0.8451866080021037, disc_loss = 0.07531309746655411
Trained batch 580 in epoch 3, gen_loss = 0.844919844153826, disc_loss = 0.07539334347897983
Trained batch 581 in epoch 3, gen_loss = 0.8449857369116491, disc_loss = 0.07529880857587987
Trained batch 582 in epoch 3, gen_loss = 0.8450310270127874, disc_loss = 0.07525364254277014
Trained batch 583 in epoch 3, gen_loss = 0.8449840041464323, disc_loss = 0.07518759488817049
Trained batch 584 in epoch 3, gen_loss = 0.8454468788244786, disc_loss = 0.07527138454855507
Trained batch 585 in epoch 3, gen_loss = 0.8449148191933746, disc_loss = 0.07550450601637261
Trained batch 586 in epoch 3, gen_loss = 0.8450242667831798, disc_loss = 0.07541835282372351
Trained batch 587 in epoch 3, gen_loss = 0.8452005444132552, disc_loss = 0.07542551918031305
Trained batch 588 in epoch 3, gen_loss = 0.8449292163695058, disc_loss = 0.07546930417026344
Trained batch 589 in epoch 3, gen_loss = 0.8450785670240046, disc_loss = 0.07547046796939635
Trained batch 590 in epoch 3, gen_loss = 0.845135990435702, disc_loss = 0.07540473408442362
Trained batch 591 in epoch 3, gen_loss = 0.8447335966535516, disc_loss = 0.07541771002453626
Trained batch 592 in epoch 3, gen_loss = 0.8446549542034657, disc_loss = 0.07539752317658464
Trained batch 593 in epoch 3, gen_loss = 0.844760656657845, disc_loss = 0.0753300804927042
Trained batch 594 in epoch 3, gen_loss = 0.8445028125738897, disc_loss = 0.07528488316393199
Trained batch 595 in epoch 3, gen_loss = 0.8445222963822768, disc_loss = 0.07542030234202343
Trained batch 596 in epoch 3, gen_loss = 0.8439782045195051, disc_loss = 0.07546683786190435
Trained batch 597 in epoch 3, gen_loss = 0.8443646576492284, disc_loss = 0.07539092432894436
Trained batch 598 in epoch 3, gen_loss = 0.8443185601489174, disc_loss = 0.07530533278886484
Trained batch 599 in epoch 3, gen_loss = 0.844488677084446, disc_loss = 0.07523226676198344
Trained batch 600 in epoch 3, gen_loss = 0.8444596679754146, disc_loss = 0.07515812140212282
Trained batch 601 in epoch 3, gen_loss = 0.8444846763563315, disc_loss = 0.07509784943167355
Trained batch 602 in epoch 3, gen_loss = 0.844545273836177, disc_loss = 0.07500751040394034
Trained batch 603 in epoch 3, gen_loss = 0.8446721859917735, disc_loss = 0.0749800122583544
Trained batch 604 in epoch 3, gen_loss = 0.8452122021312556, disc_loss = 0.07488392175229128
Trained batch 605 in epoch 3, gen_loss = 0.8453465854570811, disc_loss = 0.07483632183901154
Trained batch 606 in epoch 3, gen_loss = 0.8447583916257987, disc_loss = 0.07507140784719238
Trained batch 607 in epoch 3, gen_loss = 0.8450232854505119, disc_loss = 0.07498104231873233
Trained batch 608 in epoch 3, gen_loss = 0.8454294898141976, disc_loss = 0.07489434425368881
Trained batch 609 in epoch 3, gen_loss = 0.8452994559143411, disc_loss = 0.07483497585673801
Trained batch 610 in epoch 3, gen_loss = 0.8450570536225596, disc_loss = 0.07485247507032904
Trained batch 611 in epoch 3, gen_loss = 0.8452482980742954, disc_loss = 0.07485927155643117
Trained batch 612 in epoch 3, gen_loss = 0.8453834300426246, disc_loss = 0.07480388795303676
Trained batch 613 in epoch 3, gen_loss = 0.8454207681386401, disc_loss = 0.0747488254274724
Trained batch 614 in epoch 3, gen_loss = 0.8452253137662159, disc_loss = 0.07478732494561653
Trained batch 615 in epoch 3, gen_loss = 0.8454064930510985, disc_loss = 0.0748111048664946
Trained batch 616 in epoch 3, gen_loss = 0.8455200393833643, disc_loss = 0.07476545934304232
Trained batch 617 in epoch 3, gen_loss = 0.8455462547857013, disc_loss = 0.07472143283047529
Trained batch 618 in epoch 3, gen_loss = 0.8456646355654388, disc_loss = 0.07464561967693739
Trained batch 619 in epoch 3, gen_loss = 0.845626361860383, disc_loss = 0.07464052603369759
Trained batch 620 in epoch 3, gen_loss = 0.8455654866933439, disc_loss = 0.07459926100120837
Trained batch 621 in epoch 3, gen_loss = 0.8458354174611653, disc_loss = 0.0745111705429876
Trained batch 622 in epoch 3, gen_loss = 0.8460257867079103, disc_loss = 0.07443704989172195
Trained batch 623 in epoch 3, gen_loss = 0.8457430187039651, disc_loss = 0.07440901934825934
Trained batch 624 in epoch 3, gen_loss = 0.8456659018039704, disc_loss = 0.0743459035128355
Trained batch 625 in epoch 3, gen_loss = 0.8460938209257187, disc_loss = 0.07432337528683793
Trained batch 626 in epoch 3, gen_loss = 0.8460330573850842, disc_loss = 0.0742701653248528
Trained batch 627 in epoch 3, gen_loss = 0.8464180548574515, disc_loss = 0.07424929784610868
Trained batch 628 in epoch 3, gen_loss = 0.845974570948672, disc_loss = 0.07445993085224507
Trained batch 629 in epoch 3, gen_loss = 0.8462262556193367, disc_loss = 0.07435744861732163
Trained batch 630 in epoch 3, gen_loss = 0.8468569620569988, disc_loss = 0.07455439731425557
Trained batch 631 in epoch 3, gen_loss = 0.8465179716578767, disc_loss = 0.07465028930661752
Trained batch 632 in epoch 3, gen_loss = 0.8464529911206232, disc_loss = 0.0745783368696416
Trained batch 633 in epoch 3, gen_loss = 0.8463058352752438, disc_loss = 0.07458990262762558
Trained batch 634 in epoch 3, gen_loss = 0.8464283626379929, disc_loss = 0.07462623788586517
Trained batch 635 in epoch 3, gen_loss = 0.8460543202060573, disc_loss = 0.07463272253736714
Trained batch 636 in epoch 3, gen_loss = 0.8460632869081931, disc_loss = 0.07462369569166442
Trained batch 637 in epoch 3, gen_loss = 0.8461986325657853, disc_loss = 0.07455763642801713
Trained batch 638 in epoch 3, gen_loss = 0.845824830362308, disc_loss = 0.07459405632849916
Trained batch 639 in epoch 3, gen_loss = 0.8461885069962591, disc_loss = 0.07457990386028542
Trained batch 640 in epoch 3, gen_loss = 0.8459771774395394, disc_loss = 0.07462784871546183
Trained batch 641 in epoch 3, gen_loss = 0.8461751770286173, disc_loss = 0.07465237174096091
Trained batch 642 in epoch 3, gen_loss = 0.8462856592230997, disc_loss = 0.07468850577386273
Trained batch 643 in epoch 3, gen_loss = 0.8460720143980861, disc_loss = 0.07476487996849168
Trained batch 644 in epoch 3, gen_loss = 0.8459886799949085, disc_loss = 0.07474824576385955
Trained batch 645 in epoch 3, gen_loss = 0.8464758146565765, disc_loss = 0.07489723223621954
Trained batch 646 in epoch 3, gen_loss = 0.8460273220789672, disc_loss = 0.07499543385554272
Trained batch 647 in epoch 3, gen_loss = 0.8457417081075685, disc_loss = 0.07497140962233836
Trained batch 648 in epoch 3, gen_loss = 0.8461288371236739, disc_loss = 0.07514144759625196
Trained batch 649 in epoch 3, gen_loss = 0.8457762531592296, disc_loss = 0.07518204183962483
Trained batch 650 in epoch 3, gen_loss = 0.8458669142148095, disc_loss = 0.0751696418550226
Trained batch 651 in epoch 3, gen_loss = 0.8459197354554399, disc_loss = 0.07508956475120518
Trained batch 652 in epoch 3, gen_loss = 0.8458195226024523, disc_loss = 0.07519991849770179
Trained batch 653 in epoch 3, gen_loss = 0.8458885707713049, disc_loss = 0.075182979087707
Trained batch 654 in epoch 3, gen_loss = 0.8457258693589509, disc_loss = 0.07526816699426365
Trained batch 655 in epoch 3, gen_loss = 0.8458451644585627, disc_loss = 0.07520511361242203
Trained batch 656 in epoch 3, gen_loss = 0.8460296176067771, disc_loss = 0.0752371145083457
Trained batch 657 in epoch 3, gen_loss = 0.8459602124694633, disc_loss = 0.07525750299304225
Trained batch 658 in epoch 3, gen_loss = 0.8455211570393153, disc_loss = 0.07534822871221712
Trained batch 659 in epoch 3, gen_loss = 0.8459930127768805, disc_loss = 0.0755676965581987
Trained batch 660 in epoch 3, gen_loss = 0.8456974664812911, disc_loss = 0.07560926914615232
Trained batch 661 in epoch 3, gen_loss = 0.8458701679623739, disc_loss = 0.0755476509614811
Trained batch 662 in epoch 3, gen_loss = 0.8459672538133768, disc_loss = 0.07547099338380864
Trained batch 663 in epoch 3, gen_loss = 0.845932421510119, disc_loss = 0.07545652981785811
Trained batch 664 in epoch 3, gen_loss = 0.8460598808930333, disc_loss = 0.07543405146106966
Trained batch 665 in epoch 3, gen_loss = 0.8460719118694643, disc_loss = 0.07539077141873159
Trained batch 666 in epoch 3, gen_loss = 0.8460667036373218, disc_loss = 0.07533318920387723
Trained batch 667 in epoch 3, gen_loss = 0.8466442776565066, disc_loss = 0.07533280815912444
Trained batch 668 in epoch 3, gen_loss = 0.8464864149845591, disc_loss = 0.07530277806107283
Trained batch 669 in epoch 3, gen_loss = 0.8464099342698481, disc_loss = 0.07523007438615409
Trained batch 670 in epoch 3, gen_loss = 0.8464435348301105, disc_loss = 0.07515156784423817
Trained batch 671 in epoch 3, gen_loss = 0.8466674977736104, disc_loss = 0.075081817873676
Trained batch 672 in epoch 3, gen_loss = 0.8467165525299656, disc_loss = 0.07499852768916299
Trained batch 673 in epoch 3, gen_loss = 0.8462695062425795, disc_loss = 0.07511366847543273
Trained batch 674 in epoch 3, gen_loss = 0.8464772380281378, disc_loss = 0.07506576404665355
Trained batch 675 in epoch 3, gen_loss = 0.8463966421915229, disc_loss = 0.07496866142823631
Trained batch 676 in epoch 3, gen_loss = 0.846387853342462, disc_loss = 0.07489171044067362
Trained batch 677 in epoch 3, gen_loss = 0.8461601085807018, disc_loss = 0.07492265039175793
Trained batch 678 in epoch 3, gen_loss = 0.8463745545129537, disc_loss = 0.07490898776163014
Trained batch 679 in epoch 3, gen_loss = 0.8460898050052278, disc_loss = 0.07490747371441958
Trained batch 680 in epoch 3, gen_loss = 0.8462726922374815, disc_loss = 0.07485862637947965
Trained batch 681 in epoch 3, gen_loss = 0.8463112976281874, disc_loss = 0.07481930400941335
Trained batch 682 in epoch 3, gen_loss = 0.8464102008943153, disc_loss = 0.0747506660047924
Trained batch 683 in epoch 3, gen_loss = 0.8462659446032423, disc_loss = 0.07477292295256684
Trained batch 684 in epoch 3, gen_loss = 0.8468645507836864, disc_loss = 0.07476897823631111
Trained batch 685 in epoch 3, gen_loss = 0.8469621896656887, disc_loss = 0.07470493428762079
Trained batch 686 in epoch 3, gen_loss = 0.8469939844837355, disc_loss = 0.07463498202761232
Trained batch 687 in epoch 3, gen_loss = 0.846879726449071, disc_loss = 0.07457445715256251
Trained batch 688 in epoch 3, gen_loss = 0.846783509404981, disc_loss = 0.07458100791923236
Trained batch 689 in epoch 3, gen_loss = 0.8472140721220901, disc_loss = 0.07468470594832215
Trained batch 690 in epoch 3, gen_loss = 0.8469295574597443, disc_loss = 0.07466365572323891
Trained batch 691 in epoch 3, gen_loss = 0.8471659112269478, disc_loss = 0.07458932991839429
Trained batch 692 in epoch 3, gen_loss = 0.8468373479351164, disc_loss = 0.07477242138484039
Trained batch 693 in epoch 3, gen_loss = 0.8471852479561605, disc_loss = 0.07505951123043723
Trained batch 694 in epoch 3, gen_loss = 0.847153194731088, disc_loss = 0.07498005620143611
Trained batch 695 in epoch 3, gen_loss = 0.8467161316724344, disc_loss = 0.07505118429537691
Trained batch 696 in epoch 3, gen_loss = 0.8467998145899095, disc_loss = 0.0750031551811176
Trained batch 697 in epoch 3, gen_loss = 0.8473324490908566, disc_loss = 0.07498147883679301
Trained batch 698 in epoch 3, gen_loss = 0.8470782690037986, disc_loss = 0.07505871748447802
Trained batch 699 in epoch 3, gen_loss = 0.8469956573843956, disc_loss = 0.07500791303946504
Trained batch 700 in epoch 3, gen_loss = 0.8472356995655365, disc_loss = 0.07502558893429782
Trained batch 701 in epoch 3, gen_loss = 0.8473783049233619, disc_loss = 0.074954714319613
Trained batch 702 in epoch 3, gen_loss = 0.8473293183114416, disc_loss = 0.07486615121062543
Trained batch 703 in epoch 3, gen_loss = 0.8470693995583464, disc_loss = 0.07485650802449197
Trained batch 704 in epoch 3, gen_loss = 0.8474063774795397, disc_loss = 0.07482899420940918
Trained batch 705 in epoch 3, gen_loss = 0.8476614941534172, disc_loss = 0.07474711612157164
Trained batch 706 in epoch 3, gen_loss = 0.847437115631144, disc_loss = 0.07467627288349489
Trained batch 707 in epoch 3, gen_loss = 0.8475433391450489, disc_loss = 0.07460500486589716
Trained batch 708 in epoch 3, gen_loss = 0.8477553329699803, disc_loss = 0.07455344071377946
Trained batch 709 in epoch 3, gen_loss = 0.8474108192702414, disc_loss = 0.07466892045856992
Trained batch 710 in epoch 3, gen_loss = 0.8478296405403926, disc_loss = 0.07468999489361182
Trained batch 711 in epoch 3, gen_loss = 0.8478997504192122, disc_loss = 0.07460047238836003
Trained batch 712 in epoch 3, gen_loss = 0.847690494540363, disc_loss = 0.07454760087494638
Trained batch 713 in epoch 3, gen_loss = 0.8479168168386492, disc_loss = 0.0745342459532247
Trained batch 714 in epoch 3, gen_loss = 0.8480316517653165, disc_loss = 0.07458410094381421
Trained batch 715 in epoch 3, gen_loss = 0.8479090834546356, disc_loss = 0.07455913191427108
Trained batch 716 in epoch 3, gen_loss = 0.8475169224802254, disc_loss = 0.07459301730771153
Trained batch 717 in epoch 3, gen_loss = 0.8477299652142777, disc_loss = 0.0746025457046926
Trained batch 718 in epoch 3, gen_loss = 0.8477780031809721, disc_loss = 0.07457653640980556
Trained batch 719 in epoch 3, gen_loss = 0.847609188945757, disc_loss = 0.07462426985536391
Trained batch 720 in epoch 3, gen_loss = 0.8477331199444282, disc_loss = 0.07454607309579808
Trained batch 721 in epoch 3, gen_loss = 0.8479896152696451, disc_loss = 0.07445976361013185
Trained batch 722 in epoch 3, gen_loss = 0.8483536267758734, disc_loss = 0.07447457610324211
Trained batch 723 in epoch 3, gen_loss = 0.84796608823933, disc_loss = 0.07451479743075305
Trained batch 724 in epoch 3, gen_loss = 0.847862635768693, disc_loss = 0.07451891511678696
Trained batch 725 in epoch 3, gen_loss = 0.8477427294021139, disc_loss = 0.07454575108718281
Trained batch 726 in epoch 3, gen_loss = 0.8478190521344522, disc_loss = 0.07450345716089461
Trained batch 727 in epoch 3, gen_loss = 0.8478831153895173, disc_loss = 0.07443802895351917
Trained batch 728 in epoch 3, gen_loss = 0.8478914549566591, disc_loss = 0.07445918680238953
Trained batch 729 in epoch 3, gen_loss = 0.8477785466876748, disc_loss = 0.07449420227681937
Trained batch 730 in epoch 3, gen_loss = 0.847735729206114, disc_loss = 0.0744155787655169
Trained batch 731 in epoch 3, gen_loss = 0.8477844376463056, disc_loss = 0.07432933712296717
Trained batch 732 in epoch 3, gen_loss = 0.8478203955402478, disc_loss = 0.0743105268337107
Trained batch 733 in epoch 3, gen_loss = 0.8476567830717856, disc_loss = 0.07431813660623349
Trained batch 734 in epoch 3, gen_loss = 0.847788334501033, disc_loss = 0.07427004076236365
Trained batch 735 in epoch 3, gen_loss = 0.8473741429574464, disc_loss = 0.07436173210052126
Trained batch 736 in epoch 3, gen_loss = 0.847356319872301, disc_loss = 0.07446019340614855
Trained batch 737 in epoch 3, gen_loss = 0.8471847080037522, disc_loss = 0.07443701117715942
Trained batch 738 in epoch 3, gen_loss = 0.8474125199534089, disc_loss = 0.07443663553764517
Trained batch 739 in epoch 3, gen_loss = 0.847456438195061, disc_loss = 0.07436479835997561
Trained batch 740 in epoch 3, gen_loss = 0.847679484590345, disc_loss = 0.07427704388680446
Trained batch 741 in epoch 3, gen_loss = 0.847656872274098, disc_loss = 0.07421003677568466
Trained batch 742 in epoch 3, gen_loss = 0.8477272747102047, disc_loss = 0.07413254792439786
Trained batch 743 in epoch 3, gen_loss = 0.8478953984556019, disc_loss = 0.07405621757585636
Trained batch 744 in epoch 3, gen_loss = 0.8477214344795918, disc_loss = 0.07401823513334829
Trained batch 745 in epoch 3, gen_loss = 0.8477578043697986, disc_loss = 0.07393844979228427
Trained batch 746 in epoch 3, gen_loss = 0.8481034881857983, disc_loss = 0.07390580329560292
Trained batch 747 in epoch 3, gen_loss = 0.8482524176093347, disc_loss = 0.07384579598076921
Trained batch 748 in epoch 3, gen_loss = 0.8478547706702682, disc_loss = 0.07396968229560652
Trained batch 749 in epoch 3, gen_loss = 0.8477162340084712, disc_loss = 0.073920963101089
Trained batch 750 in epoch 3, gen_loss = 0.8482603124788058, disc_loss = 0.07411016040939228
Trained batch 751 in epoch 3, gen_loss = 0.8480342313885054, disc_loss = 0.07413505570854041
Trained batch 752 in epoch 3, gen_loss = 0.848097410057962, disc_loss = 0.07407177240645901
Trained batch 753 in epoch 3, gen_loss = 0.8481486598202658, disc_loss = 0.07398937605889588
Trained batch 754 in epoch 3, gen_loss = 0.8482687402639958, disc_loss = 0.07393717318649916
Trained batch 755 in epoch 3, gen_loss = 0.8486336903676154, disc_loss = 0.07407366408394876
Trained batch 756 in epoch 3, gen_loss = 0.8483186028356439, disc_loss = 0.07415751308630882
Trained batch 757 in epoch 3, gen_loss = 0.8483917842518371, disc_loss = 0.07419855040338352
Trained batch 758 in epoch 3, gen_loss = 0.8481908625529218, disc_loss = 0.07420602042169086
Trained batch 759 in epoch 3, gen_loss = 0.8480801297253684, disc_loss = 0.07421380463668978
Trained batch 760 in epoch 3, gen_loss = 0.8482646724789278, disc_loss = 0.0741483326817761
Trained batch 761 in epoch 3, gen_loss = 0.8479193436896081, disc_loss = 0.07417909978837596
Trained batch 762 in epoch 3, gen_loss = 0.84822159970416, disc_loss = 0.07418391196274468
Trained batch 763 in epoch 3, gen_loss = 0.8481582562726829, disc_loss = 0.07415020326761948
Trained batch 764 in epoch 3, gen_loss = 0.8478349434394462, disc_loss = 0.07423001636257943
Trained batch 765 in epoch 3, gen_loss = 0.8479536823519839, disc_loss = 0.07420446699747801
Trained batch 766 in epoch 3, gen_loss = 0.8481296538296392, disc_loss = 0.07419219466759258
Trained batch 767 in epoch 3, gen_loss = 0.8485796302168941, disc_loss = 0.07433687299271696
Trained batch 768 in epoch 3, gen_loss = 0.8483374278086525, disc_loss = 0.07442774027174215
Trained batch 769 in epoch 3, gen_loss = 0.8480084329843521, disc_loss = 0.07454178292038185
Trained batch 770 in epoch 3, gen_loss = 0.8485695250844523, disc_loss = 0.07481256986807563
Trained batch 771 in epoch 3, gen_loss = 0.8485206121993806, disc_loss = 0.07476188215774537
Trained batch 772 in epoch 3, gen_loss = 0.8483232469870233, disc_loss = 0.07491184902506341
Trained batch 773 in epoch 3, gen_loss = 0.8483117510413014, disc_loss = 0.07490084051137708
Trained batch 774 in epoch 3, gen_loss = 0.8486249506473541, disc_loss = 0.07488360584623391
Trained batch 775 in epoch 3, gen_loss = 0.8485859666672564, disc_loss = 0.07486926695000687
Trained batch 776 in epoch 3, gen_loss = 0.8481898231472594, disc_loss = 0.07495377512775754
Trained batch 777 in epoch 3, gen_loss = 0.848133665775272, disc_loss = 0.07489613806206379
Trained batch 778 in epoch 3, gen_loss = 0.8483856241954001, disc_loss = 0.07486249291874822
Trained batch 779 in epoch 3, gen_loss = 0.8484708844469144, disc_loss = 0.07482309516352148
Trained batch 780 in epoch 3, gen_loss = 0.8482987322437932, disc_loss = 0.07486547470669931
Trained batch 781 in epoch 3, gen_loss = 0.848218285938358, disc_loss = 0.07483559659779872
Trained batch 782 in epoch 3, gen_loss = 0.8484493055182246, disc_loss = 0.07490513198396445
Trained batch 783 in epoch 3, gen_loss = 0.8483935262703773, disc_loss = 0.07484893258114593
Trained batch 784 in epoch 3, gen_loss = 0.8481901585296461, disc_loss = 0.07484830128752691
Trained batch 785 in epoch 3, gen_loss = 0.8481761623960719, disc_loss = 0.07483917536953365
Trained batch 786 in epoch 3, gen_loss = 0.8483590239415175, disc_loss = 0.07477829128792544
Trained batch 787 in epoch 3, gen_loss = 0.8481935881796827, disc_loss = 0.07475358448794991
Trained batch 788 in epoch 3, gen_loss = 0.8484865028519746, disc_loss = 0.07470901992351421
Trained batch 789 in epoch 3, gen_loss = 0.8483819934763486, disc_loss = 0.0747750702738479
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.71291184425354, disc_loss = 0.03646353259682655
Trained batch 1 in epoch 4, gen_loss = 0.7821420133113861, disc_loss = 0.026533045805990696
Trained batch 2 in epoch 4, gen_loss = 0.7551441192626953, disc_loss = 0.04711759649217129
Trained batch 3 in epoch 4, gen_loss = 0.7547112852334976, disc_loss = 0.05655859084799886
Trained batch 4 in epoch 4, gen_loss = 0.7605512261390686, disc_loss = 0.04874555058777332
Trained batch 5 in epoch 4, gen_loss = 0.7793805499871572, disc_loss = 0.04917049314826727
Trained batch 6 in epoch 4, gen_loss = 0.7735397730554853, disc_loss = 0.05363342831177371
Trained batch 7 in epoch 4, gen_loss = 0.7685434445738792, disc_loss = 0.05606753588654101
Trained batch 8 in epoch 4, gen_loss = 0.7625370422999064, disc_loss = 0.054610556405451566
Trained batch 9 in epoch 4, gen_loss = 0.7779557108879089, disc_loss = 0.053133116103708744
Trained batch 10 in epoch 4, gen_loss = 0.7827701460231434, disc_loss = 0.05034705590118061
Trained batch 11 in epoch 4, gen_loss = 0.7772392481565475, disc_loss = 0.05171694171925386
Trained batch 12 in epoch 4, gen_loss = 0.7592083536661588, disc_loss = 0.0551415727688716
Trained batch 13 in epoch 4, gen_loss = 0.7814666926860809, disc_loss = 0.0626506677695683
Trained batch 14 in epoch 4, gen_loss = 0.7832828243573506, disc_loss = 0.06115092039108276
Trained batch 15 in epoch 4, gen_loss = 0.7685307301580906, disc_loss = 0.07629831694066525
Trained batch 16 in epoch 4, gen_loss = 0.7882399734328774, disc_loss = 0.07773266776519663
Trained batch 17 in epoch 4, gen_loss = 0.8053468101554446, disc_loss = 0.07831656229164866
Trained batch 18 in epoch 4, gen_loss = 0.7997644418164304, disc_loss = 0.0763362152011771
Trained batch 19 in epoch 4, gen_loss = 0.7943951815366745, disc_loss = 0.07964854836463928
Trained batch 20 in epoch 4, gen_loss = 0.8185817145165943, disc_loss = 0.07879603121961866
Trained batch 21 in epoch 4, gen_loss = 0.8247712444175374, disc_loss = 0.07583689350973476
Trained batch 22 in epoch 4, gen_loss = 0.83323851098185, disc_loss = 0.074453038851852
Trained batch 23 in epoch 4, gen_loss = 0.8293200805783272, disc_loss = 0.07433241869633396
Trained batch 24 in epoch 4, gen_loss = 0.8277678322792054, disc_loss = 0.07532709553837776
Trained batch 25 in epoch 4, gen_loss = 0.8275940487017999, disc_loss = 0.07303677728542915
Trained batch 26 in epoch 4, gen_loss = 0.8338312330069365, disc_loss = 0.07135568842015884
Trained batch 27 in epoch 4, gen_loss = 0.8404705801180431, disc_loss = 0.07010547730273434
Trained batch 28 in epoch 4, gen_loss = 0.8378229798941776, disc_loss = 0.06893167535549607
Trained batch 29 in epoch 4, gen_loss = 0.8440731565157572, disc_loss = 0.06826384905725717
Trained batch 30 in epoch 4, gen_loss = 0.8524023678994948, disc_loss = 0.06746167202870693
Trained batch 31 in epoch 4, gen_loss = 0.8445255011320114, disc_loss = 0.0691023314720951
Trained batch 32 in epoch 4, gen_loss = 0.843849854035811, disc_loss = 0.06771588952026585
Trained batch 33 in epoch 4, gen_loss = 0.8452569088515114, disc_loss = 0.06611264886005837
Trained batch 34 in epoch 4, gen_loss = 0.8521862592015947, disc_loss = 0.06528842018118926
Trained batch 35 in epoch 4, gen_loss = 0.853311762213707, disc_loss = 0.06462589004594418
Trained batch 36 in epoch 4, gen_loss = 0.8475657073227135, disc_loss = 0.06695352066811677
Trained batch 37 in epoch 4, gen_loss = 0.8469467147400505, disc_loss = 0.06680110415541812
Trained batch 38 in epoch 4, gen_loss = 0.8450428935197684, disc_loss = 0.06638245881558993
Trained batch 39 in epoch 4, gen_loss = 0.8481092259287835, disc_loss = 0.06557311504147947
Trained batch 40 in epoch 4, gen_loss = 0.8448068761244053, disc_loss = 0.06553268882377845
Trained batch 41 in epoch 4, gen_loss = 0.8440644357885633, disc_loss = 0.06447211808214585
Trained batch 42 in epoch 4, gen_loss = 0.8535622510799142, disc_loss = 0.06894558715785659
Trained batch 43 in epoch 4, gen_loss = 0.8485174869949167, disc_loss = 0.07023958468132398
Trained batch 44 in epoch 4, gen_loss = 0.8426327665646871, disc_loss = 0.07110144177244769
Trained batch 45 in epoch 4, gen_loss = 0.8446647563706273, disc_loss = 0.07129497838247081
Trained batch 46 in epoch 4, gen_loss = 0.8463185290072827, disc_loss = 0.07063402516886275
Trained batch 47 in epoch 4, gen_loss = 0.8368477995196978, disc_loss = 0.07386802319282045
Trained batch 48 in epoch 4, gen_loss = 0.8423039791535358, disc_loss = 0.07403516507118332
Trained batch 49 in epoch 4, gen_loss = 0.8383682525157928, disc_loss = 0.0737496541813016
Trained batch 50 in epoch 4, gen_loss = 0.8378247291434044, disc_loss = 0.07355546180670168
Trained batch 51 in epoch 4, gen_loss = 0.8331714421510696, disc_loss = 0.07428307290403889
Trained batch 52 in epoch 4, gen_loss = 0.8350193601734234, disc_loss = 0.07376618623592944
Trained batch 53 in epoch 4, gen_loss = 0.8351914717091454, disc_loss = 0.07315394941165491
Trained batch 54 in epoch 4, gen_loss = 0.8363313328136097, disc_loss = 0.07264841642569411
Trained batch 55 in epoch 4, gen_loss = 0.8449370563030243, disc_loss = 0.07226887993913676
Trained batch 56 in epoch 4, gen_loss = 0.8448353106515449, disc_loss = 0.07160995701295242
Trained batch 57 in epoch 4, gen_loss = 0.8422100143185978, disc_loss = 0.07224308837462089
Trained batch 58 in epoch 4, gen_loss = 0.8486175425982071, disc_loss = 0.07199620048247152
Trained batch 59 in epoch 4, gen_loss = 0.8535843660434087, disc_loss = 0.07153875303144257
Trained batch 60 in epoch 4, gen_loss = 0.8521531400133352, disc_loss = 0.07113435690398098
Trained batch 61 in epoch 4, gen_loss = 0.8496247443460649, disc_loss = 0.07082271452752813
Trained batch 62 in epoch 4, gen_loss = 0.8478688644984412, disc_loss = 0.07074186912486477
Trained batch 63 in epoch 4, gen_loss = 0.8481874680146575, disc_loss = 0.07008801714982837
Trained batch 64 in epoch 4, gen_loss = 0.8488745056665861, disc_loss = 0.06938686594367027
Trained batch 65 in epoch 4, gen_loss = 0.8482628627256914, disc_loss = 0.06867976514904787
Trained batch 66 in epoch 4, gen_loss = 0.8474467485698302, disc_loss = 0.06818186247081899
Trained batch 67 in epoch 4, gen_loss = 0.8475896970314138, disc_loss = 0.0675120030201095
Trained batch 68 in epoch 4, gen_loss = 0.8525123587553052, disc_loss = 0.06861261578033799
Trained batch 69 in epoch 4, gen_loss = 0.8499070814677647, disc_loss = 0.06902097716395345
Trained batch 70 in epoch 4, gen_loss = 0.847555461903693, disc_loss = 0.0687845568369392
Trained batch 71 in epoch 4, gen_loss = 0.849565221203698, disc_loss = 0.0684295010804716
Trained batch 72 in epoch 4, gen_loss = 0.8506675370751995, disc_loss = 0.06846587816636039
Trained batch 73 in epoch 4, gen_loss = 0.8505780471337808, disc_loss = 0.06803347474920589
Trained batch 74 in epoch 4, gen_loss = 0.8494715992609659, disc_loss = 0.06783589981496334
Trained batch 75 in epoch 4, gen_loss = 0.8530430307513789, disc_loss = 0.06951811519990626
Trained batch 76 in epoch 4, gen_loss = 0.8555458288688165, disc_loss = 0.06875324294019441
Trained batch 77 in epoch 4, gen_loss = 0.8538762674881861, disc_loss = 0.06871134516759178
Trained batch 78 in epoch 4, gen_loss = 0.8522262407254569, disc_loss = 0.06917262960319655
Trained batch 79 in epoch 4, gen_loss = 0.8574971571564675, disc_loss = 0.06935192380333319
Trained batch 80 in epoch 4, gen_loss = 0.8549707355322661, disc_loss = 0.07015709042043229
Trained batch 81 in epoch 4, gen_loss = 0.856611950368416, disc_loss = 0.06955110460020057
Trained batch 82 in epoch 4, gen_loss = 0.8550904307020716, disc_loss = 0.06970096833959043
Trained batch 83 in epoch 4, gen_loss = 0.8561518071662813, disc_loss = 0.06907588561686377
Trained batch 84 in epoch 4, gen_loss = 0.8549257495824029, disc_loss = 0.06922157940399998
Trained batch 85 in epoch 4, gen_loss = 0.8535213893236115, disc_loss = 0.06913441700081147
Trained batch 86 in epoch 4, gen_loss = 0.8569142085382309, disc_loss = 0.06868452573430607
Trained batch 87 in epoch 4, gen_loss = 0.859588894654404, disc_loss = 0.0682430313794281
Trained batch 88 in epoch 4, gen_loss = 0.8597835918490806, disc_loss = 0.06780753112031837
Trained batch 89 in epoch 4, gen_loss = 0.8576883249812656, disc_loss = 0.06813663131453924
Trained batch 90 in epoch 4, gen_loss = 0.8601053468473665, disc_loss = 0.06825348525052215
Trained batch 91 in epoch 4, gen_loss = 0.8587059300878773, disc_loss = 0.06915446616830709
Trained batch 92 in epoch 4, gen_loss = 0.858005299363085, disc_loss = 0.06875597195880066
Trained batch 93 in epoch 4, gen_loss = 0.855050966460654, disc_loss = 0.06921921653593792
Trained batch 94 in epoch 4, gen_loss = 0.8545818579824347, disc_loss = 0.06915012550001082
Trained batch 95 in epoch 4, gen_loss = 0.8553389466057221, disc_loss = 0.07100062568012315
Trained batch 96 in epoch 4, gen_loss = 0.852100972662267, disc_loss = 0.0723928145430598
Trained batch 97 in epoch 4, gen_loss = 0.8504566836113833, disc_loss = 0.07229284059294329
Trained batch 98 in epoch 4, gen_loss = 0.849838497060718, disc_loss = 0.07185219665707061
Trained batch 99 in epoch 4, gen_loss = 0.8523865622282029, disc_loss = 0.07206775412894785
Trained batch 100 in epoch 4, gen_loss = 0.8491089408940607, disc_loss = 0.07333132345229387
Trained batch 101 in epoch 4, gen_loss = 0.8480672888896045, disc_loss = 0.07336407579372034
Trained batch 102 in epoch 4, gen_loss = 0.8474593642845895, disc_loss = 0.07377876595422192
Trained batch 103 in epoch 4, gen_loss = 0.8469879529797114, disc_loss = 0.07339584742350361
Trained batch 104 in epoch 4, gen_loss = 0.8485041953268505, disc_loss = 0.07332574080321051
Trained batch 105 in epoch 4, gen_loss = 0.844884990521197, disc_loss = 0.07411451209863683
Trained batch 106 in epoch 4, gen_loss = 0.8455344984464557, disc_loss = 0.0741583319972748
Trained batch 107 in epoch 4, gen_loss = 0.8457511210883105, disc_loss = 0.07365784917406186
Trained batch 108 in epoch 4, gen_loss = 0.8441884583289471, disc_loss = 0.0734582947943052
Trained batch 109 in epoch 4, gen_loss = 0.8436149185354059, disc_loss = 0.07334198517386209
Trained batch 110 in epoch 4, gen_loss = 0.8431864171414762, disc_loss = 0.07304045449740984
Trained batch 111 in epoch 4, gen_loss = 0.8419376521238259, disc_loss = 0.07319974905112758
Trained batch 112 in epoch 4, gen_loss = 0.8428335859712246, disc_loss = 0.07277317001459609
Trained batch 113 in epoch 4, gen_loss = 0.8444362277524513, disc_loss = 0.07292693355855973
Trained batch 114 in epoch 4, gen_loss = 0.843417053118996, disc_loss = 0.07279827632819828
Trained batch 115 in epoch 4, gen_loss = 0.8407591792016194, disc_loss = 0.07341650782698958
Trained batch 116 in epoch 4, gen_loss = 0.8439528733237177, disc_loss = 0.07415295015765816
Trained batch 117 in epoch 4, gen_loss = 0.8435138736741018, disc_loss = 0.07378037778218671
Trained batch 118 in epoch 4, gen_loss = 0.8421089448848692, disc_loss = 0.07390643517729364
Trained batch 119 in epoch 4, gen_loss = 0.8408191372950872, disc_loss = 0.0737412399224316
Trained batch 120 in epoch 4, gen_loss = 0.843999727698397, disc_loss = 0.07410319333449622
Trained batch 121 in epoch 4, gen_loss = 0.8417664800511032, disc_loss = 0.07460875784001145
Trained batch 122 in epoch 4, gen_loss = 0.8411426350353209, disc_loss = 0.07481663521924396
Trained batch 123 in epoch 4, gen_loss = 0.8422435406715639, disc_loss = 0.0751465070436919
Trained batch 124 in epoch 4, gen_loss = 0.8399449591636657, disc_loss = 0.07587112503498793
Trained batch 125 in epoch 4, gen_loss = 0.8411553099987998, disc_loss = 0.07539122346197329
Trained batch 126 in epoch 4, gen_loss = 0.8391236062124958, disc_loss = 0.07540952808802992
Trained batch 127 in epoch 4, gen_loss = 0.8416394018568099, disc_loss = 0.07632241760438774
Trained batch 128 in epoch 4, gen_loss = 0.8411776751510857, disc_loss = 0.0762745092456886
Trained batch 129 in epoch 4, gen_loss = 0.8392535301355215, disc_loss = 0.0763011006351847
Trained batch 130 in epoch 4, gen_loss = 0.8389143406889821, disc_loss = 0.07610567671936432
Trained batch 131 in epoch 4, gen_loss = 0.8388022355961077, disc_loss = 0.07644249449455828
Trained batch 132 in epoch 4, gen_loss = 0.8381125546039495, disc_loss = 0.07618769861869794
Trained batch 133 in epoch 4, gen_loss = 0.8367550586586567, disc_loss = 0.07604917949204569
Trained batch 134 in epoch 4, gen_loss = 0.8389503991162336, disc_loss = 0.07606034067769846
Trained batch 135 in epoch 4, gen_loss = 0.8400210334974176, disc_loss = 0.0755861476132208
Trained batch 136 in epoch 4, gen_loss = 0.839437794946406, disc_loss = 0.07521306797454175
Trained batch 137 in epoch 4, gen_loss = 0.8388961925022844, disc_loss = 0.0750390730217855
Trained batch 138 in epoch 4, gen_loss = 0.8390270145676977, disc_loss = 0.07463125756559827
Trained batch 139 in epoch 4, gen_loss = 0.8384894549846649, disc_loss = 0.0744597999711654
Trained batch 140 in epoch 4, gen_loss = 0.840175395316266, disc_loss = 0.07514741631713531
Trained batch 141 in epoch 4, gen_loss = 0.8407412876545544, disc_loss = 0.07475714323202699
Trained batch 142 in epoch 4, gen_loss = 0.84049042871782, disc_loss = 0.0747642976694278
Trained batch 143 in epoch 4, gen_loss = 0.8396904120842615, disc_loss = 0.07510778851832987
Trained batch 144 in epoch 4, gen_loss = 0.8413055880316372, disc_loss = 0.07551437241892363
Trained batch 145 in epoch 4, gen_loss = 0.8409129413839889, disc_loss = 0.07524718615315752
Trained batch 146 in epoch 4, gen_loss = 0.840402023727391, disc_loss = 0.07509020189469566
Trained batch 147 in epoch 4, gen_loss = 0.8407617473119015, disc_loss = 0.07480898812237019
Trained batch 148 in epoch 4, gen_loss = 0.8412748579210882, disc_loss = 0.0745343909780151
Trained batch 149 in epoch 4, gen_loss = 0.842077465057373, disc_loss = 0.07420103843634328
Trained batch 150 in epoch 4, gen_loss = 0.8424997140240196, disc_loss = 0.07390815035026792
Trained batch 151 in epoch 4, gen_loss = 0.8421225163497423, disc_loss = 0.07378747542756364
Trained batch 152 in epoch 4, gen_loss = 0.842122389210595, disc_loss = 0.07446180228630897
Trained batch 153 in epoch 4, gen_loss = 0.8410065932707353, disc_loss = 0.07456849097552432
Trained batch 154 in epoch 4, gen_loss = 0.8427137190295804, disc_loss = 0.07560166589795582
Trained batch 155 in epoch 4, gen_loss = 0.840238770040182, disc_loss = 0.07670528411220473
Trained batch 156 in epoch 4, gen_loss = 0.8398464806140609, disc_loss = 0.07712362942161263
Trained batch 157 in epoch 4, gen_loss = 0.8395076369560217, disc_loss = 0.07755910490250474
Trained batch 158 in epoch 4, gen_loss = 0.8401721215473031, disc_loss = 0.0790785454365911
Trained batch 159 in epoch 4, gen_loss = 0.8393844554200769, disc_loss = 0.07978000667062587
Trained batch 160 in epoch 4, gen_loss = 0.8390790125968294, disc_loss = 0.08002263310463717
Trained batch 161 in epoch 4, gen_loss = 0.8396116239421162, disc_loss = 0.07999701460501478
Trained batch 162 in epoch 4, gen_loss = 0.8385138231918124, disc_loss = 0.08005538302262319
Trained batch 163 in epoch 4, gen_loss = 0.8394128271355862, disc_loss = 0.07967604020406015
Trained batch 164 in epoch 4, gen_loss = 0.8405325382044821, disc_loss = 0.07969319784844464
Trained batch 165 in epoch 4, gen_loss = 0.8400508224605078, disc_loss = 0.07946324115619063
Trained batch 166 in epoch 4, gen_loss = 0.8396993349055331, disc_loss = 0.07927946227150941
Trained batch 167 in epoch 4, gen_loss = 0.839678537455343, disc_loss = 0.07950972941415828
Trained batch 168 in epoch 4, gen_loss = 0.8385567021440472, disc_loss = 0.0794688613820799
Trained batch 169 in epoch 4, gen_loss = 0.8390520763747832, disc_loss = 0.07922287095228539
Trained batch 170 in epoch 4, gen_loss = 0.8399585180463847, disc_loss = 0.07884699214598415
Trained batch 171 in epoch 4, gen_loss = 0.8389383181929588, disc_loss = 0.07880306763162967
Trained batch 172 in epoch 4, gen_loss = 0.8374596133052958, disc_loss = 0.0787166875943197
Trained batch 173 in epoch 4, gen_loss = 0.8377372151476213, disc_loss = 0.07874676854424607
Trained batch 174 in epoch 4, gen_loss = 0.8384673866203853, disc_loss = 0.07845744128205946
Trained batch 175 in epoch 4, gen_loss = 0.8373288029635494, disc_loss = 0.0784178156437437
Trained batch 176 in epoch 4, gen_loss = 0.836486320206001, disc_loss = 0.0782576179721177
Trained batch 177 in epoch 4, gen_loss = 0.837841024057249, disc_loss = 0.07812104277375541
Trained batch 178 in epoch 4, gen_loss = 0.8391889148917278, disc_loss = 0.07778847244094704
Trained batch 179 in epoch 4, gen_loss = 0.8383645178543196, disc_loss = 0.07764709245723983
Trained batch 180 in epoch 4, gen_loss = 0.8386044563180175, disc_loss = 0.077523542141017
Trained batch 181 in epoch 4, gen_loss = 0.8378025969633689, disc_loss = 0.07733030901239304
Trained batch 182 in epoch 4, gen_loss = 0.8361008077697024, disc_loss = 0.0773924453326506
Trained batch 183 in epoch 4, gen_loss = 0.8360427639082723, disc_loss = 0.07720514343869266
Trained batch 184 in epoch 4, gen_loss = 0.8371911443568565, disc_loss = 0.077900513014882
Trained batch 185 in epoch 4, gen_loss = 0.8373864765769692, disc_loss = 0.07767407387314786
Trained batch 186 in epoch 4, gen_loss = 0.8357409071476064, disc_loss = 0.078216981197543
Trained batch 187 in epoch 4, gen_loss = 0.8366157645557789, disc_loss = 0.07852020153795626
Trained batch 188 in epoch 4, gen_loss = 0.8361870793123094, disc_loss = 0.07839317504986726
Trained batch 189 in epoch 4, gen_loss = 0.8355611266274201, disc_loss = 0.07840994090135944
Trained batch 190 in epoch 4, gen_loss = 0.8351795534500901, disc_loss = 0.07827228051732192
Trained batch 191 in epoch 4, gen_loss = 0.8339026845060289, disc_loss = 0.07837252397924506
Trained batch 192 in epoch 4, gen_loss = 0.833423905576449, disc_loss = 0.07821552354572196
Trained batch 193 in epoch 4, gen_loss = 0.835053754375153, disc_loss = 0.07884950520585954
Trained batch 194 in epoch 4, gen_loss = 0.8351414000376677, disc_loss = 0.07858542522463279
Trained batch 195 in epoch 4, gen_loss = 0.833855330183798, disc_loss = 0.0788278943640465
Trained batch 196 in epoch 4, gen_loss = 0.8351794982016995, disc_loss = 0.07909624457718606
Trained batch 197 in epoch 4, gen_loss = 0.8344124788888777, disc_loss = 0.0792292025495283
Trained batch 198 in epoch 4, gen_loss = 0.8340301080864279, disc_loss = 0.07927501004601094
Trained batch 199 in epoch 4, gen_loss = 0.8331794671714305, disc_loss = 0.07914218423422426
Trained batch 200 in epoch 4, gen_loss = 0.8323456080102208, disc_loss = 0.07914600144626933
Trained batch 201 in epoch 4, gen_loss = 0.8329127668449194, disc_loss = 0.07942148133430003
Trained batch 202 in epoch 4, gen_loss = 0.8324235773145272, disc_loss = 0.07922747086623473
Trained batch 203 in epoch 4, gen_loss = 0.8331987514507537, disc_loss = 0.0789019538537033
Trained batch 204 in epoch 4, gen_loss = 0.8323674226679453, disc_loss = 0.07885386802528689
Trained batch 205 in epoch 4, gen_loss = 0.8325917033605206, disc_loss = 0.07851942481690095
Trained batch 206 in epoch 4, gen_loss = 0.8326205267134495, disc_loss = 0.07826692487252651
Trained batch 207 in epoch 4, gen_loss = 0.832922977466996, disc_loss = 0.07803717078730607
Trained batch 208 in epoch 4, gen_loss = 0.8330744614726618, disc_loss = 0.07773828960990792
Trained batch 209 in epoch 4, gen_loss = 0.8325596146640324, disc_loss = 0.07752543808448882
Trained batch 210 in epoch 4, gen_loss = 0.8323167626044197, disc_loss = 0.07726681451379405
Trained batch 211 in epoch 4, gen_loss = 0.8341451232444566, disc_loss = 0.07706387214503198
Trained batch 212 in epoch 4, gen_loss = 0.8336885821931239, disc_loss = 0.07690296878277415
Trained batch 213 in epoch 4, gen_loss = 0.833343224686997, disc_loss = 0.07663678325643049
Trained batch 214 in epoch 4, gen_loss = 0.8335953214833903, disc_loss = 0.0763673614277396
Trained batch 215 in epoch 4, gen_loss = 0.834491208885555, disc_loss = 0.07614277023822069
Trained batch 216 in epoch 4, gen_loss = 0.8350701756466369, disc_loss = 0.07590581397719097
Trained batch 217 in epoch 4, gen_loss = 0.8348646422318362, disc_loss = 0.0759469508919694
Trained batch 218 in epoch 4, gen_loss = 0.8362172233731779, disc_loss = 0.07609893276130772
Trained batch 219 in epoch 4, gen_loss = 0.8362059513276273, disc_loss = 0.07583124729889361
Trained batch 220 in epoch 4, gen_loss = 0.83636397325615, disc_loss = 0.07566359333221999
Trained batch 221 in epoch 4, gen_loss = 0.8362140130620819, disc_loss = 0.07554520966132751
Trained batch 222 in epoch 4, gen_loss = 0.8351777512663683, disc_loss = 0.07569188525223679
Trained batch 223 in epoch 4, gen_loss = 0.8353963285418493, disc_loss = 0.07588973572377913
Trained batch 224 in epoch 4, gen_loss = 0.835603091319402, disc_loss = 0.07582311359544595
Trained batch 225 in epoch 4, gen_loss = 0.8354086792838257, disc_loss = 0.07565671728874467
Trained batch 226 in epoch 4, gen_loss = 0.8345984213940373, disc_loss = 0.07603349509579233
Trained batch 227 in epoch 4, gen_loss = 0.8345015748289594, disc_loss = 0.07580633875668834
Trained batch 228 in epoch 4, gen_loss = 0.8357307425492716, disc_loss = 0.07573790609934185
Trained batch 229 in epoch 4, gen_loss = 0.8359773543865784, disc_loss = 0.07562160157477078
Trained batch 230 in epoch 4, gen_loss = 0.8347774595667273, disc_loss = 0.07591383264791139
Trained batch 231 in epoch 4, gen_loss = 0.8346728051787821, disc_loss = 0.0758509178372935
Trained batch 232 in epoch 4, gen_loss = 0.835133267190835, disc_loss = 0.07564163732426361
Trained batch 233 in epoch 4, gen_loss = 0.8355064347513721, disc_loss = 0.07545800965565902
Trained batch 234 in epoch 4, gen_loss = 0.8352737986026926, disc_loss = 0.07530579928387987
Trained batch 235 in epoch 4, gen_loss = 0.8366062207999876, disc_loss = 0.07568471986105886
Trained batch 236 in epoch 4, gen_loss = 0.8358723444526206, disc_loss = 0.07598091957438344
Trained batch 237 in epoch 4, gen_loss = 0.8356314523129904, disc_loss = 0.07597845410849868
Trained batch 238 in epoch 4, gen_loss = 0.8360388813906634, disc_loss = 0.0758781358287923
Trained batch 239 in epoch 4, gen_loss = 0.8357041489332915, disc_loss = 0.07572325865427652
Trained batch 240 in epoch 4, gen_loss = 0.8354578405247685, disc_loss = 0.07560865092574313
Trained batch 241 in epoch 4, gen_loss = 0.8344732179375719, disc_loss = 0.07562088125870248
Trained batch 242 in epoch 4, gen_loss = 0.835210862105766, disc_loss = 0.07576585490517165
Trained batch 243 in epoch 4, gen_loss = 0.8351436236598453, disc_loss = 0.0759814975813764
Trained batch 244 in epoch 4, gen_loss = 0.8335330379252531, disc_loss = 0.07666194195650061
Trained batch 245 in epoch 4, gen_loss = 0.8343622442183456, disc_loss = 0.07703151475123274
Trained batch 246 in epoch 4, gen_loss = 0.8339996284801467, disc_loss = 0.07686572573204273
Trained batch 247 in epoch 4, gen_loss = 0.8342197311501349, disc_loss = 0.0766946819400595
Trained batch 248 in epoch 4, gen_loss = 0.8336293824226502, disc_loss = 0.0771261404556443
Trained batch 249 in epoch 4, gen_loss = 0.8344025518894196, disc_loss = 0.07698216608166694
Trained batch 250 in epoch 4, gen_loss = 0.8339089608762369, disc_loss = 0.07720517865808836
Trained batch 251 in epoch 4, gen_loss = 0.8328473116197284, disc_loss = 0.07775775044565163
Trained batch 252 in epoch 4, gen_loss = 0.8327741163521416, disc_loss = 0.07773393315995634
Trained batch 253 in epoch 4, gen_loss = 0.832319667254846, disc_loss = 0.07807780444387376
Trained batch 254 in epoch 4, gen_loss = 0.8329816128693375, disc_loss = 0.07786860834149753
Trained batch 255 in epoch 4, gen_loss = 0.8331155767664313, disc_loss = 0.07772191462572664
Trained batch 256 in epoch 4, gen_loss = 0.8332738199122685, disc_loss = 0.07747799004446208
Trained batch 257 in epoch 4, gen_loss = 0.8341599933860838, disc_loss = 0.07728987836907077
Trained batch 258 in epoch 4, gen_loss = 0.8345348236643669, disc_loss = 0.07708383141567349
Trained batch 259 in epoch 4, gen_loss = 0.8345856918738439, disc_loss = 0.07690385710448026
Trained batch 260 in epoch 4, gen_loss = 0.8342434012570143, disc_loss = 0.0768495766567316
Trained batch 261 in epoch 4, gen_loss = 0.8343124940195157, disc_loss = 0.07685256247472672
Trained batch 262 in epoch 4, gen_loss = 0.8345361907219252, disc_loss = 0.07668644128926806
Trained batch 263 in epoch 4, gen_loss = 0.8343198890938903, disc_loss = 0.0765676081857898
Trained batch 264 in epoch 4, gen_loss = 0.8345246150808514, disc_loss = 0.07637483759449339
Trained batch 265 in epoch 4, gen_loss = 0.8346451258748994, disc_loss = 0.07628146932229288
Trained batch 266 in epoch 4, gen_loss = 0.8348163725731524, disc_loss = 0.07614527150904865
Trained batch 267 in epoch 4, gen_loss = 0.8343653118432458, disc_loss = 0.07598664239743974
Trained batch 268 in epoch 4, gen_loss = 0.8353686439060367, disc_loss = 0.07608952205004967
Trained batch 269 in epoch 4, gen_loss = 0.8348553635455944, disc_loss = 0.07604477980208618
Trained batch 270 in epoch 4, gen_loss = 0.8344423102276791, disc_loss = 0.07598104791860079
Trained batch 271 in epoch 4, gen_loss = 0.8345615898861605, disc_loss = 0.07593918078825534
Trained batch 272 in epoch 4, gen_loss = 0.8338217709090684, disc_loss = 0.07590069200829927
Trained batch 273 in epoch 4, gen_loss = 0.8359775295222762, disc_loss = 0.07616718637546266
Trained batch 274 in epoch 4, gen_loss = 0.8352955601432107, disc_loss = 0.07620955891907215
Trained batch 275 in epoch 4, gen_loss = 0.8356531068034794, disc_loss = 0.07611872633055285
Trained batch 276 in epoch 4, gen_loss = 0.8351277345354376, disc_loss = 0.07618915151791236
Trained batch 277 in epoch 4, gen_loss = 0.8353816748951837, disc_loss = 0.07597342330506808
Trained batch 278 in epoch 4, gen_loss = 0.8365137015192312, disc_loss = 0.07614916625789844
Trained batch 279 in epoch 4, gen_loss = 0.8364105282085282, disc_loss = 0.07597832430952361
Trained batch 280 in epoch 4, gen_loss = 0.8356418514166862, disc_loss = 0.07603038286664308
Trained batch 281 in epoch 4, gen_loss = 0.8347378614101004, disc_loss = 0.07610035918864376
Trained batch 282 in epoch 4, gen_loss = 0.835384039912544, disc_loss = 0.07632803399602853
Trained batch 283 in epoch 4, gen_loss = 0.8350712711542425, disc_loss = 0.07623165510070155
Trained batch 284 in epoch 4, gen_loss = 0.8347986873827482, disc_loss = 0.07618092625287541
Trained batch 285 in epoch 4, gen_loss = 0.8358360095457598, disc_loss = 0.07655638167178715
Trained batch 286 in epoch 4, gen_loss = 0.8353301199471078, disc_loss = 0.07656075519863322
Trained batch 287 in epoch 4, gen_loss = 0.8353090008927716, disc_loss = 0.07649024217648225
Trained batch 288 in epoch 4, gen_loss = 0.8354701230682716, disc_loss = 0.07653130491660541
Trained batch 289 in epoch 4, gen_loss = 0.8353040150527297, disc_loss = 0.07648680938472008
Trained batch 290 in epoch 4, gen_loss = 0.8347921787258685, disc_loss = 0.07658185227374031
Trained batch 291 in epoch 4, gen_loss = 0.8344335774444553, disc_loss = 0.0766114832527221
Trained batch 292 in epoch 4, gen_loss = 0.8357545196399754, disc_loss = 0.07769973073853974
Trained batch 293 in epoch 4, gen_loss = 0.8351421966439202, disc_loss = 0.07778953290766194
Trained batch 294 in epoch 4, gen_loss = 0.8347712425862328, disc_loss = 0.07786242541367724
Trained batch 295 in epoch 4, gen_loss = 0.8342072287121335, disc_loss = 0.07800047473377876
Trained batch 296 in epoch 4, gen_loss = 0.8341164568859318, disc_loss = 0.0783863670822948
Trained batch 297 in epoch 4, gen_loss = 0.8343344786823196, disc_loss = 0.07834234177416204
Trained batch 298 in epoch 4, gen_loss = 0.833960831564007, disc_loss = 0.07837012433836292
Trained batch 299 in epoch 4, gen_loss = 0.8334524653355281, disc_loss = 0.07841022306432327
Trained batch 300 in epoch 4, gen_loss = 0.834266643389515, disc_loss = 0.07851661856833883
Trained batch 301 in epoch 4, gen_loss = 0.8340812670868754, disc_loss = 0.0783870362411469
Trained batch 302 in epoch 4, gen_loss = 0.8331860150441085, disc_loss = 0.07857464638726153
Trained batch 303 in epoch 4, gen_loss = 0.8343456583587747, disc_loss = 0.07853632036743588
Trained batch 304 in epoch 4, gen_loss = 0.8345909724470044, disc_loss = 0.07836874250750073
Trained batch 305 in epoch 4, gen_loss = 0.8341569179802938, disc_loss = 0.07839908902502916
Trained batch 306 in epoch 4, gen_loss = 0.8345058521541011, disc_loss = 0.07834035195774286
Trained batch 307 in epoch 4, gen_loss = 0.8343337302084093, disc_loss = 0.07837872711530366
Trained batch 308 in epoch 4, gen_loss = 0.8347261854745809, disc_loss = 0.07832009903483791
Trained batch 309 in epoch 4, gen_loss = 0.8341124388479417, disc_loss = 0.07828034440115575
Trained batch 310 in epoch 4, gen_loss = 0.8340800600036548, disc_loss = 0.07816194087698146
Trained batch 311 in epoch 4, gen_loss = 0.8343785561812229, disc_loss = 0.07799672190911877
Trained batch 312 in epoch 4, gen_loss = 0.8342664064690709, disc_loss = 0.0778596475363349
Trained batch 313 in epoch 4, gen_loss = 0.8350842327448973, disc_loss = 0.07783311511728035
Trained batch 314 in epoch 4, gen_loss = 0.8348680513245719, disc_loss = 0.07766849953267309
Trained batch 315 in epoch 4, gen_loss = 0.8349693947577779, disc_loss = 0.07745043999704096
Trained batch 316 in epoch 4, gen_loss = 0.834648932944337, disc_loss = 0.077408864015966
Trained batch 317 in epoch 4, gen_loss = 0.8344250105836857, disc_loss = 0.07725148629572876
Trained batch 318 in epoch 4, gen_loss = 0.8339217114598027, disc_loss = 0.0772568038387405
Trained batch 319 in epoch 4, gen_loss = 0.8339816262945533, disc_loss = 0.07714465094322805
Trained batch 320 in epoch 4, gen_loss = 0.8341705102786839, disc_loss = 0.07704255423824828
Trained batch 321 in epoch 4, gen_loss = 0.8339597540242332, disc_loss = 0.0769221609984727
Trained batch 322 in epoch 4, gen_loss = 0.8339523307679239, disc_loss = 0.07674283151667646
Trained batch 323 in epoch 4, gen_loss = 0.8342734665414433, disc_loss = 0.07659530608891797
Trained batch 324 in epoch 4, gen_loss = 0.8345500302314758, disc_loss = 0.07652048562868283
Trained batch 325 in epoch 4, gen_loss = 0.834014122654324, disc_loss = 0.07643776174714687
Trained batch 326 in epoch 4, gen_loss = 0.833344715633159, disc_loss = 0.07643830247895525
Trained batch 327 in epoch 4, gen_loss = 0.8345347063207045, disc_loss = 0.07645436989927165
Trained batch 328 in epoch 4, gen_loss = 0.8343474080497371, disc_loss = 0.07635756201849611
Trained batch 329 in epoch 4, gen_loss = 0.8339523508693233, disc_loss = 0.07623700881376863
Trained batch 330 in epoch 4, gen_loss = 0.8344410288730056, disc_loss = 0.07605693803036591
Trained batch 331 in epoch 4, gen_loss = 0.8356511127876948, disc_loss = 0.07596459450390954
Trained batch 332 in epoch 4, gen_loss = 0.8358803137286648, disc_loss = 0.07587178710109747
Trained batch 333 in epoch 4, gen_loss = 0.835519657698934, disc_loss = 0.0760947155465043
Trained batch 334 in epoch 4, gen_loss = 0.8350464192788992, disc_loss = 0.0761969916939513
Trained batch 335 in epoch 4, gen_loss = 0.8354646050859065, disc_loss = 0.07615635731157713
Trained batch 336 in epoch 4, gen_loss = 0.8360003121528852, disc_loss = 0.07618942795713772
Trained batch 337 in epoch 4, gen_loss = 0.836053643177247, disc_loss = 0.07616548159451791
Trained batch 338 in epoch 4, gen_loss = 0.8354001920835107, disc_loss = 0.07648627823465957
Trained batch 339 in epoch 4, gen_loss = 0.8360213416464188, disc_loss = 0.07644579608595985
Trained batch 340 in epoch 4, gen_loss = 0.8360646996330307, disc_loss = 0.07637523852911425
Trained batch 341 in epoch 4, gen_loss = 0.8361608600407316, disc_loss = 0.07627801153514731
Trained batch 342 in epoch 4, gen_loss = 0.8360267340615609, disc_loss = 0.07616402867790474
Trained batch 343 in epoch 4, gen_loss = 0.836008338214353, disc_loss = 0.07608866278721063
Trained batch 344 in epoch 4, gen_loss = 0.8363356833872588, disc_loss = 0.07603093755795903
Trained batch 345 in epoch 4, gen_loss = 0.836287159106635, disc_loss = 0.07599645003278045
Trained batch 346 in epoch 4, gen_loss = 0.8359696854775508, disc_loss = 0.07600238670994895
Trained batch 347 in epoch 4, gen_loss = 0.836568778273703, disc_loss = 0.0759153398069628
Trained batch 348 in epoch 4, gen_loss = 0.8367450126262654, disc_loss = 0.07575383456557307
Trained batch 349 in epoch 4, gen_loss = 0.836800605228969, disc_loss = 0.07569597970960396
Trained batch 350 in epoch 4, gen_loss = 0.8375951068693417, disc_loss = 0.07570331548725354
Trained batch 351 in epoch 4, gen_loss = 0.8377996012568474, disc_loss = 0.07556392531577413
Trained batch 352 in epoch 4, gen_loss = 0.8375780237970541, disc_loss = 0.07542231234407881
Trained batch 353 in epoch 4, gen_loss = 0.8368014519834249, disc_loss = 0.07563674768517162
Trained batch 354 in epoch 4, gen_loss = 0.8370701260969673, disc_loss = 0.0762491979937948
Trained batch 355 in epoch 4, gen_loss = 0.8380220172445426, disc_loss = 0.07629757927824858
Trained batch 356 in epoch 4, gen_loss = 0.8372595719262665, disc_loss = 0.07659856562635728
Trained batch 357 in epoch 4, gen_loss = 0.8378083750855323, disc_loss = 0.0764304606956768
Trained batch 358 in epoch 4, gen_loss = 0.8381991346566458, disc_loss = 0.07638687710731723
Trained batch 359 in epoch 4, gen_loss = 0.838895312945048, disc_loss = 0.07625309535457442
Trained batch 360 in epoch 4, gen_loss = 0.838587801046979, disc_loss = 0.07631817712110578
Trained batch 361 in epoch 4, gen_loss = 0.8392248026903163, disc_loss = 0.07621040192396683
Trained batch 362 in epoch 4, gen_loss = 0.8399409934180498, disc_loss = 0.07608808769226157
Trained batch 363 in epoch 4, gen_loss = 0.8398234154824372, disc_loss = 0.07605258075796723
Trained batch 364 in epoch 4, gen_loss = 0.8404769236094332, disc_loss = 0.07597550669404333
Trained batch 365 in epoch 4, gen_loss = 0.8398551214588145, disc_loss = 0.0759288697055658
Trained batch 366 in epoch 4, gen_loss = 0.8400077514492523, disc_loss = 0.07579423596052204
Trained batch 367 in epoch 4, gen_loss = 0.8399038300242113, disc_loss = 0.0756436146912165
Trained batch 368 in epoch 4, gen_loss = 0.8398565188009888, disc_loss = 0.07553023387372575
Trained batch 369 in epoch 4, gen_loss = 0.8397987850614497, disc_loss = 0.07565946968373012
Trained batch 370 in epoch 4, gen_loss = 0.8393255078567649, disc_loss = 0.0759234646375409
Trained batch 371 in epoch 4, gen_loss = 0.8399440606114685, disc_loss = 0.07590825265643977
Trained batch 372 in epoch 4, gen_loss = 0.8407123911796243, disc_loss = 0.07585077915320687
Trained batch 373 in epoch 4, gen_loss = 0.8401794059072586, disc_loss = 0.07581759131398988
Trained batch 374 in epoch 4, gen_loss = 0.8401527126630147, disc_loss = 0.07572707282255094
Trained batch 375 in epoch 4, gen_loss = 0.8396927646182953, disc_loss = 0.07565318913684484
Trained batch 376 in epoch 4, gen_loss = 0.8400663202257941, disc_loss = 0.07559703160769032
Trained batch 377 in epoch 4, gen_loss = 0.8401072782183451, disc_loss = 0.07545588541746376
Trained batch 378 in epoch 4, gen_loss = 0.8406060679292301, disc_loss = 0.07531018189761522
Trained batch 379 in epoch 4, gen_loss = 0.8400927476192775, disc_loss = 0.07528985629201328
Trained batch 380 in epoch 4, gen_loss = 0.8406898150919616, disc_loss = 0.07513771095408464
Trained batch 381 in epoch 4, gen_loss = 0.8406767700043024, disc_loss = 0.07503501755668153
Trained batch 382 in epoch 4, gen_loss = 0.8404179069143052, disc_loss = 0.07502369106778821
Trained batch 383 in epoch 4, gen_loss = 0.8402221328578889, disc_loss = 0.07494855901798776
Trained batch 384 in epoch 4, gen_loss = 0.8407843442706319, disc_loss = 0.07492413949221373
Trained batch 385 in epoch 4, gen_loss = 0.8410544315150364, disc_loss = 0.07479436955429189
Trained batch 386 in epoch 4, gen_loss = 0.8407934856353189, disc_loss = 0.07473423716296906
Trained batch 387 in epoch 4, gen_loss = 0.8413242517980104, disc_loss = 0.07458558412431979
Trained batch 388 in epoch 4, gen_loss = 0.8420695840239831, disc_loss = 0.07445789147455695
Trained batch 389 in epoch 4, gen_loss = 0.8426003766365541, disc_loss = 0.07431128251676758
Trained batch 390 in epoch 4, gen_loss = 0.8424033768036786, disc_loss = 0.07429940374734838
Trained batch 391 in epoch 4, gen_loss = 0.8430536279872972, disc_loss = 0.07417041306830563
Trained batch 392 in epoch 4, gen_loss = 0.8434620370695003, disc_loss = 0.07415558919357965
Trained batch 393 in epoch 4, gen_loss = 0.8430807759919142, disc_loss = 0.07413584181358139
Trained batch 394 in epoch 4, gen_loss = 0.8433703873730913, disc_loss = 0.07402070912803653
Trained batch 395 in epoch 4, gen_loss = 0.8434277133207129, disc_loss = 0.07397327687111542
Trained batch 396 in epoch 4, gen_loss = 0.8429174436730161, disc_loss = 0.07399208554927664
Trained batch 397 in epoch 4, gen_loss = 0.8430989428081704, disc_loss = 0.0740298144168328
Trained batch 398 in epoch 4, gen_loss = 0.8435391075629041, disc_loss = 0.07391311280793489
Trained batch 399 in epoch 4, gen_loss = 0.8431982941925525, disc_loss = 0.07390633948380128
Trained batch 400 in epoch 4, gen_loss = 0.843098571027009, disc_loss = 0.07382434233326345
Trained batch 401 in epoch 4, gen_loss = 0.8434972794198278, disc_loss = 0.07376697209353249
Trained batch 402 in epoch 4, gen_loss = 0.8437837325313843, disc_loss = 0.07374301203584331
Trained batch 403 in epoch 4, gen_loss = 0.8431565621406725, disc_loss = 0.07407948922707082
Trained batch 404 in epoch 4, gen_loss = 0.8446229889069075, disc_loss = 0.07410888094455004
Trained batch 405 in epoch 4, gen_loss = 0.8456694405948, disc_loss = 0.07402306910962086
Trained batch 406 in epoch 4, gen_loss = 0.8459905085751114, disc_loss = 0.07395123700663923
Trained batch 407 in epoch 4, gen_loss = 0.8459769821926659, disc_loss = 0.07413873336889654
Trained batch 408 in epoch 4, gen_loss = 0.8462797401878245, disc_loss = 0.07439506051419781
Trained batch 409 in epoch 4, gen_loss = 0.8473583522366315, disc_loss = 0.07466579724057781
Trained batch 410 in epoch 4, gen_loss = 0.8473361140330052, disc_loss = 0.07467724637801412
Trained batch 411 in epoch 4, gen_loss = 0.847032023431028, disc_loss = 0.07478478644269257
Trained batch 412 in epoch 4, gen_loss = 0.8470025514286309, disc_loss = 0.07471371813030062
Trained batch 413 in epoch 4, gen_loss = 0.8477021517672977, disc_loss = 0.07475003426678586
Trained batch 414 in epoch 4, gen_loss = 0.8474727976753051, disc_loss = 0.07474132825856108
Trained batch 415 in epoch 4, gen_loss = 0.8482673639574876, disc_loss = 0.07471626566481203
Trained batch 416 in epoch 4, gen_loss = 0.8483483724171024, disc_loss = 0.07463089729786562
Trained batch 417 in epoch 4, gen_loss = 0.8481404749970687, disc_loss = 0.07459084892146396
Trained batch 418 in epoch 4, gen_loss = 0.8484486492266234, disc_loss = 0.07476797027108849
Trained batch 419 in epoch 4, gen_loss = 0.8476946251732963, disc_loss = 0.07484659505786286
Trained batch 420 in epoch 4, gen_loss = 0.8476589272537594, disc_loss = 0.07475450623674305
Trained batch 421 in epoch 4, gen_loss = 0.8476164044362109, disc_loss = 0.07473568223919984
Trained batch 422 in epoch 4, gen_loss = 0.8476379455967716, disc_loss = 0.07486441700849197
Trained batch 423 in epoch 4, gen_loss = 0.8470331845137308, disc_loss = 0.07493381728725683
Trained batch 424 in epoch 4, gen_loss = 0.8465257601176991, disc_loss = 0.07508113159195465
Trained batch 425 in epoch 4, gen_loss = 0.8465846602066022, disc_loss = 0.0749901908476063
Trained batch 426 in epoch 4, gen_loss = 0.8468238680647464, disc_loss = 0.07506704875060839
Trained batch 427 in epoch 4, gen_loss = 0.8462128093309491, disc_loss = 0.07533096205486664
Trained batch 428 in epoch 4, gen_loss = 0.846443325489551, disc_loss = 0.07520147489648668
Trained batch 429 in epoch 4, gen_loss = 0.8463886256827865, disc_loss = 0.07528299800401857
Trained batch 430 in epoch 4, gen_loss = 0.8469107523041922, disc_loss = 0.07514521637996291
Trained batch 431 in epoch 4, gen_loss = 0.8468658922723046, disc_loss = 0.07512395398872387
Trained batch 432 in epoch 4, gen_loss = 0.8463675255863551, disc_loss = 0.07534799039338051
Trained batch 433 in epoch 4, gen_loss = 0.8464037737538738, disc_loss = 0.07534097143006833
Trained batch 434 in epoch 4, gen_loss = 0.8462546106042533, disc_loss = 0.07557900353795154
Trained batch 435 in epoch 4, gen_loss = 0.8452366515310532, disc_loss = 0.07587171914354993
Trained batch 436 in epoch 4, gen_loss = 0.8457891358663616, disc_loss = 0.07578930512999847
Trained batch 437 in epoch 4, gen_loss = 0.8461547819174589, disc_loss = 0.07580864786906126
Trained batch 438 in epoch 4, gen_loss = 0.8460155677958339, disc_loss = 0.07576290266227681
Trained batch 439 in epoch 4, gen_loss = 0.8459524487907236, disc_loss = 0.0757205394117839
Trained batch 440 in epoch 4, gen_loss = 0.8463683382453832, disc_loss = 0.07566738985436641
Trained batch 441 in epoch 4, gen_loss = 0.8457674342312964, disc_loss = 0.07581007115045621
Trained batch 442 in epoch 4, gen_loss = 0.8457333539732422, disc_loss = 0.0757538448981352
Trained batch 443 in epoch 4, gen_loss = 0.8466854953282589, disc_loss = 0.07573340617766318
Trained batch 444 in epoch 4, gen_loss = 0.8460871338844299, disc_loss = 0.07587707460638178
Trained batch 445 in epoch 4, gen_loss = 0.846456278466323, disc_loss = 0.07580340850989714
Trained batch 446 in epoch 4, gen_loss = 0.8460795189976958, disc_loss = 0.07574665294939306
Trained batch 447 in epoch 4, gen_loss = 0.8460025682247111, disc_loss = 0.07572872160276997
Trained batch 448 in epoch 4, gen_loss = 0.8455332945078147, disc_loss = 0.07574382751458272
Trained batch 449 in epoch 4, gen_loss = 0.8453815836376614, disc_loss = 0.07584404314764671
Trained batch 450 in epoch 4, gen_loss = 0.8446252125329823, disc_loss = 0.07604657145146851
Trained batch 451 in epoch 4, gen_loss = 0.844673833092757, disc_loss = 0.07614731401477041
Trained batch 452 in epoch 4, gen_loss = 0.844573989740797, disc_loss = 0.07614483766742955
Trained batch 453 in epoch 4, gen_loss = 0.8444138767960838, disc_loss = 0.07605957843995108
Trained batch 454 in epoch 4, gen_loss = 0.8447122284344264, disc_loss = 0.07603949036776692
Trained batch 455 in epoch 4, gen_loss = 0.8444375543479334, disc_loss = 0.07597097114194185
Trained batch 456 in epoch 4, gen_loss = 0.844544312103572, disc_loss = 0.07585571002198843
Trained batch 457 in epoch 4, gen_loss = 0.8445404468665477, disc_loss = 0.07576768430698191
Trained batch 458 in epoch 4, gen_loss = 0.8458124103109821, disc_loss = 0.07613519576128597
Trained batch 459 in epoch 4, gen_loss = 0.8459197466788084, disc_loss = 0.0760643053982083
Trained batch 460 in epoch 4, gen_loss = 0.8461959173260438, disc_loss = 0.07596027739386432
Trained batch 461 in epoch 4, gen_loss = 0.8454762145038291, disc_loss = 0.07615380616278036
Trained batch 462 in epoch 4, gen_loss = 0.845745258789598, disc_loss = 0.07615067233526616
Trained batch 463 in epoch 4, gen_loss = 0.845557744004603, disc_loss = 0.07617314846921262
Trained batch 464 in epoch 4, gen_loss = 0.8454431126194616, disc_loss = 0.07611258028135184
Trained batch 465 in epoch 4, gen_loss = 0.8454335119591251, disc_loss = 0.07604624702527224
Trained batch 466 in epoch 4, gen_loss = 0.8454742612879588, disc_loss = 0.07599841582945825
Trained batch 467 in epoch 4, gen_loss = 0.8453753297654991, disc_loss = 0.07589544351690282
Trained batch 468 in epoch 4, gen_loss = 0.8447161807434391, disc_loss = 0.07600059319557602
Trained batch 469 in epoch 4, gen_loss = 0.844697760394279, disc_loss = 0.0758811911270815
Trained batch 470 in epoch 4, gen_loss = 0.8450361977463822, disc_loss = 0.07590564760140237
Trained batch 471 in epoch 4, gen_loss = 0.8453746381199966, disc_loss = 0.07580894825119777
Trained batch 472 in epoch 4, gen_loss = 0.8449717171600455, disc_loss = 0.07576054498261868
Trained batch 473 in epoch 4, gen_loss = 0.8444681326045266, disc_loss = 0.07576623486496414
Trained batch 474 in epoch 4, gen_loss = 0.8447340925116288, disc_loss = 0.07573553092973796
Trained batch 475 in epoch 4, gen_loss = 0.8453295170759955, disc_loss = 0.07572633279839672
Trained batch 476 in epoch 4, gen_loss = 0.8447998568446881, disc_loss = 0.07573174561649186
Trained batch 477 in epoch 4, gen_loss = 0.8443369415265247, disc_loss = 0.07570101608128665
Trained batch 478 in epoch 4, gen_loss = 0.8445109182459327, disc_loss = 0.07558169704521685
Trained batch 479 in epoch 4, gen_loss = 0.8450928945094347, disc_loss = 0.0756861531039855
Trained batch 480 in epoch 4, gen_loss = 0.8447926038268202, disc_loss = 0.07569286385415559
Trained batch 481 in epoch 4, gen_loss = 0.8446350284384494, disc_loss = 0.07561487006796408
Trained batch 482 in epoch 4, gen_loss = 0.8446625213198533, disc_loss = 0.07568545151486468
Trained batch 483 in epoch 4, gen_loss = 0.844709774802539, disc_loss = 0.0757027089476493
Trained batch 484 in epoch 4, gen_loss = 0.8445141209769494, disc_loss = 0.07562902035364479
Trained batch 485 in epoch 4, gen_loss = 0.8440915907851954, disc_loss = 0.07570106928800176
Trained batch 486 in epoch 4, gen_loss = 0.844588526710103, disc_loss = 0.07576534063488367
Trained batch 487 in epoch 4, gen_loss = 0.8445653384093379, disc_loss = 0.07563860468818333
Trained batch 488 in epoch 4, gen_loss = 0.8443749013122606, disc_loss = 0.07557473646511147
Trained batch 489 in epoch 4, gen_loss = 0.8444928211825234, disc_loss = 0.07544840036188158
Trained batch 490 in epoch 4, gen_loss = 0.8446545677369578, disc_loss = 0.0753433297117015
Trained batch 491 in epoch 4, gen_loss = 0.8450065438098054, disc_loss = 0.07534311702891397
Trained batch 492 in epoch 4, gen_loss = 0.8448762254105621, disc_loss = 0.07532872465339019
Trained batch 493 in epoch 4, gen_loss = 0.8447958281648303, disc_loss = 0.07527090441850334
Trained batch 494 in epoch 4, gen_loss = 0.8451959000693428, disc_loss = 0.07535797737049635
Trained batch 495 in epoch 4, gen_loss = 0.8450106045892162, disc_loss = 0.07539536819169898
Trained batch 496 in epoch 4, gen_loss = 0.8452925264715428, disc_loss = 0.07534616207610254
Trained batch 497 in epoch 4, gen_loss = 0.8449756078212616, disc_loss = 0.07527047805824733
Trained batch 498 in epoch 4, gen_loss = 0.8458247393787743, disc_loss = 0.07531645965906147
Trained batch 499 in epoch 4, gen_loss = 0.8455639902353287, disc_loss = 0.07526022453047335
Trained batch 500 in epoch 4, gen_loss = 0.845400427034991, disc_loss = 0.07525017742483975
Trained batch 501 in epoch 4, gen_loss = 0.8456218697397833, disc_loss = 0.0752867928453799
Trained batch 502 in epoch 4, gen_loss = 0.845479002648272, disc_loss = 0.07523725836706269
Trained batch 503 in epoch 4, gen_loss = 0.845667556992599, disc_loss = 0.07533947190838969
Trained batch 504 in epoch 4, gen_loss = 0.8451204442741848, disc_loss = 0.07544812496825315
Trained batch 505 in epoch 4, gen_loss = 0.8447468804983282, disc_loss = 0.07550306699382281
Trained batch 506 in epoch 4, gen_loss = 0.8454888423048768, disc_loss = 0.07581708127820104
Trained batch 507 in epoch 4, gen_loss = 0.8453335110831448, disc_loss = 0.0757698191230838
Trained batch 508 in epoch 4, gen_loss = 0.8452478466895802, disc_loss = 0.07571250357809668
Trained batch 509 in epoch 4, gen_loss = 0.8451302544743406, disc_loss = 0.07568818401800943
Trained batch 510 in epoch 4, gen_loss = 0.845268974682123, disc_loss = 0.07582728979733651
Trained batch 511 in epoch 4, gen_loss = 0.844771733507514, disc_loss = 0.07609202349885891
Trained batch 512 in epoch 4, gen_loss = 0.8453696001807616, disc_loss = 0.07627181276918678
Trained batch 513 in epoch 4, gen_loss = 0.8453798995639563, disc_loss = 0.07622499330737538
Trained batch 514 in epoch 4, gen_loss = 0.8448417851068442, disc_loss = 0.07631755605954858
Trained batch 515 in epoch 4, gen_loss = 0.8445725376291793, disc_loss = 0.07623803467027727
Trained batch 516 in epoch 4, gen_loss = 0.844664602837664, disc_loss = 0.07618048120059462
Trained batch 517 in epoch 4, gen_loss = 0.8447736894071792, disc_loss = 0.07636207887456972
Trained batch 518 in epoch 4, gen_loss = 0.8440380405369062, disc_loss = 0.07687120876222964
Trained batch 519 in epoch 4, gen_loss = 0.8439919287195572, disc_loss = 0.07679951238410118
Trained batch 520 in epoch 4, gen_loss = 0.8444400482351629, disc_loss = 0.07679122676554488
Trained batch 521 in epoch 4, gen_loss = 0.8454652030120864, disc_loss = 0.07694527585509009
Trained batch 522 in epoch 4, gen_loss = 0.8454577853301287, disc_loss = 0.07685890491966364
Trained batch 523 in epoch 4, gen_loss = 0.844825601532259, disc_loss = 0.07709169581368963
Trained batch 524 in epoch 4, gen_loss = 0.8449580310639881, disc_loss = 0.07702975855874164
Trained batch 525 in epoch 4, gen_loss = 0.8452780924369174, disc_loss = 0.0770588497588758
Trained batch 526 in epoch 4, gen_loss = 0.8453808179164068, disc_loss = 0.07694535238926337
Trained batch 527 in epoch 4, gen_loss = 0.8456993868405168, disc_loss = 0.07682773851521427
Trained batch 528 in epoch 4, gen_loss = 0.8453199820617647, disc_loss = 0.07690601665984367
Trained batch 529 in epoch 4, gen_loss = 0.8455255399335105, disc_loss = 0.0768130860379282
Trained batch 530 in epoch 4, gen_loss = 0.8459870567205038, disc_loss = 0.0769302486503416
Trained batch 531 in epoch 4, gen_loss = 0.8459592499679193, disc_loss = 0.07684387311451417
Trained batch 532 in epoch 4, gen_loss = 0.8459732686824691, disc_loss = 0.07675259363248693
Trained batch 533 in epoch 4, gen_loss = 0.8460055216867826, disc_loss = 0.07668845807568411
Trained batch 534 in epoch 4, gen_loss = 0.8457068302921046, disc_loss = 0.07661459598446561
Trained batch 535 in epoch 4, gen_loss = 0.8454641434016512, disc_loss = 0.07664578184902446
Trained batch 536 in epoch 4, gen_loss = 0.8456367427410361, disc_loss = 0.07652674256034847
Trained batch 537 in epoch 4, gen_loss = 0.8456892043241337, disc_loss = 0.07642903242287916
Trained batch 538 in epoch 4, gen_loss = 0.8460022861307318, disc_loss = 0.07644364997703092
Trained batch 539 in epoch 4, gen_loss = 0.8454595694939295, disc_loss = 0.07648527028590993
Trained batch 540 in epoch 4, gen_loss = 0.8452626290471188, disc_loss = 0.07645707999230422
Trained batch 541 in epoch 4, gen_loss = 0.8453660678819537, disc_loss = 0.07640153105367263
Trained batch 542 in epoch 4, gen_loss = 0.8452845736103163, disc_loss = 0.07631723114853625
Trained batch 543 in epoch 4, gen_loss = 0.8451435426797937, disc_loss = 0.07625644268495414
Trained batch 544 in epoch 4, gen_loss = 0.8450798184499828, disc_loss = 0.07618522458120223
Trained batch 545 in epoch 4, gen_loss = 0.8451005471495044, disc_loss = 0.07615608831819816
Trained batch 546 in epoch 4, gen_loss = 0.8449684166821091, disc_loss = 0.07611175603360973
Trained batch 547 in epoch 4, gen_loss = 0.8452109708620684, disc_loss = 0.07607946401448364
Trained batch 548 in epoch 4, gen_loss = 0.8452578217388285, disc_loss = 0.07596671965163208
Trained batch 549 in epoch 4, gen_loss = 0.8452061636881395, disc_loss = 0.07590832852335139
Trained batch 550 in epoch 4, gen_loss = 0.8451434114234634, disc_loss = 0.07580948189516196
Trained batch 551 in epoch 4, gen_loss = 0.8455049231432487, disc_loss = 0.07570731223297669
Trained batch 552 in epoch 4, gen_loss = 0.8458472169113849, disc_loss = 0.07560252493068872
Trained batch 553 in epoch 4, gen_loss = 0.8458214976727317, disc_loss = 0.07548854281177697
Trained batch 554 in epoch 4, gen_loss = 0.8463020322559116, disc_loss = 0.0753750234942984
Trained batch 555 in epoch 4, gen_loss = 0.8461664128217766, disc_loss = 0.07530752921530562
Trained batch 556 in epoch 4, gen_loss = 0.8459665649027114, disc_loss = 0.07528151555364714
Trained batch 557 in epoch 4, gen_loss = 0.846042307794735, disc_loss = 0.07524637849567505
Trained batch 558 in epoch 4, gen_loss = 0.8466994735763836, disc_loss = 0.07519354091787274
Trained batch 559 in epoch 4, gen_loss = 0.8464290642312595, disc_loss = 0.07514519474934786
Trained batch 560 in epoch 4, gen_loss = 0.8463426337522619, disc_loss = 0.0750531103867048
Trained batch 561 in epoch 4, gen_loss = 0.8461795495922455, disc_loss = 0.07495806393714032
Trained batch 562 in epoch 4, gen_loss = 0.8463067398613342, disc_loss = 0.07485137273082725
Trained batch 563 in epoch 4, gen_loss = 0.8461652372745757, disc_loss = 0.0748519865954493
Trained batch 564 in epoch 4, gen_loss = 0.8460984666790582, disc_loss = 0.07476906596097799
Trained batch 565 in epoch 4, gen_loss = 0.8460046886976532, disc_loss = 0.0747365786763099
Trained batch 566 in epoch 4, gen_loss = 0.8463644079430394, disc_loss = 0.07491759927302756
Trained batch 567 in epoch 4, gen_loss = 0.8462998842899229, disc_loss = 0.07486068239947125
Trained batch 568 in epoch 4, gen_loss = 0.8462730047991909, disc_loss = 0.07476616857380251
Trained batch 569 in epoch 4, gen_loss = 0.846576393173452, disc_loss = 0.07466251428908946
Trained batch 570 in epoch 4, gen_loss = 0.8465872989435748, disc_loss = 0.07460668333031355
Trained batch 571 in epoch 4, gen_loss = 0.8467994777264295, disc_loss = 0.07451707591348282
Trained batch 572 in epoch 4, gen_loss = 0.8467164992453956, disc_loss = 0.07446124333478706
Trained batch 573 in epoch 4, gen_loss = 0.8468564894141221, disc_loss = 0.07435861429465669
Trained batch 574 in epoch 4, gen_loss = 0.8473906593737395, disc_loss = 0.0743455474499775
Trained batch 575 in epoch 4, gen_loss = 0.847120094526973, disc_loss = 0.0742957051423016
Trained batch 576 in epoch 4, gen_loss = 0.8470530750639931, disc_loss = 0.07421769675971421
Trained batch 577 in epoch 4, gen_loss = 0.8469530301729288, disc_loss = 0.07411528120597238
Trained batch 578 in epoch 4, gen_loss = 0.8478342921622677, disc_loss = 0.07418025350310745
Trained batch 579 in epoch 4, gen_loss = 0.8478377960879228, disc_loss = 0.0740761044033771
Trained batch 580 in epoch 4, gen_loss = 0.8476241021681571, disc_loss = 0.07396928351148065
Trained batch 581 in epoch 4, gen_loss = 0.8473795826492441, disc_loss = 0.07393905928172811
Trained batch 582 in epoch 4, gen_loss = 0.8474628081861532, disc_loss = 0.07388974715976322
Trained batch 583 in epoch 4, gen_loss = 0.8478084630141519, disc_loss = 0.07381543005523208
Trained batch 584 in epoch 4, gen_loss = 0.8482114045029012, disc_loss = 0.07372648753225804
Trained batch 585 in epoch 4, gen_loss = 0.8483138024400119, disc_loss = 0.07364449195830794
Trained batch 586 in epoch 4, gen_loss = 0.8484939276867465, disc_loss = 0.07354723350533635
Trained batch 587 in epoch 4, gen_loss = 0.8485073454323269, disc_loss = 0.07349711951172473
Trained batch 588 in epoch 4, gen_loss = 0.8484888673840638, disc_loss = 0.0734210968877747
Trained batch 589 in epoch 4, gen_loss = 0.8489241060564073, disc_loss = 0.07337356971229538
Trained batch 590 in epoch 4, gen_loss = 0.8491192715220444, disc_loss = 0.07327624525112146
Trained batch 591 in epoch 4, gen_loss = 0.8496246418437442, disc_loss = 0.07321378219923055
Trained batch 592 in epoch 4, gen_loss = 0.8493805422147651, disc_loss = 0.07314303793126174
Trained batch 593 in epoch 4, gen_loss = 0.8495355603670833, disc_loss = 0.07303543239267486
Trained batch 594 in epoch 4, gen_loss = 0.8499618842822163, disc_loss = 0.07292752401011081
Trained batch 595 in epoch 4, gen_loss = 0.8501467576762974, disc_loss = 0.07285712467312763
Trained batch 596 in epoch 4, gen_loss = 0.8507281781441003, disc_loss = 0.07278602930188328
Trained batch 597 in epoch 4, gen_loss = 0.8507977914451357, disc_loss = 0.07271131525364359
Trained batch 598 in epoch 4, gen_loss = 0.8505961278046112, disc_loss = 0.07268679262494951
Trained batch 599 in epoch 4, gen_loss = 0.8513535002867381, disc_loss = 0.07261046461295337
Trained batch 600 in epoch 4, gen_loss = 0.8517027720437074, disc_loss = 0.0725182232101403
Trained batch 601 in epoch 4, gen_loss = 0.8518162284578595, disc_loss = 0.07240879308723186
Trained batch 602 in epoch 4, gen_loss = 0.8523687746987414, disc_loss = 0.07230746669611379
Trained batch 603 in epoch 4, gen_loss = 0.8526038751499543, disc_loss = 0.07221873713170011
Trained batch 604 in epoch 4, gen_loss = 0.8529860412778933, disc_loss = 0.07216482113061612
Trained batch 605 in epoch 4, gen_loss = 0.8528997454509484, disc_loss = 0.07208331569064126
Trained batch 606 in epoch 4, gen_loss = 0.852670152065585, disc_loss = 0.07212290022203076
Trained batch 607 in epoch 4, gen_loss = 0.8529312702778139, disc_loss = 0.07202533541529096
Trained batch 608 in epoch 4, gen_loss = 0.8532467422814205, disc_loss = 0.07198530612651056
Trained batch 609 in epoch 4, gen_loss = 0.8532367752223718, disc_loss = 0.07190471404216817
Trained batch 610 in epoch 4, gen_loss = 0.8531050151381672, disc_loss = 0.07187167077390828
Trained batch 611 in epoch 4, gen_loss = 0.8534640393225975, disc_loss = 0.07182835033041687
Trained batch 612 in epoch 4, gen_loss = 0.8537276108152131, disc_loss = 0.07189284763671154
Trained batch 613 in epoch 4, gen_loss = 0.853469586527697, disc_loss = 0.07184139930670444
Trained batch 614 in epoch 4, gen_loss = 0.8530806151832022, disc_loss = 0.07186758803218846
Trained batch 615 in epoch 4, gen_loss = 0.8526345026957525, disc_loss = 0.07200179797258567
Trained batch 616 in epoch 4, gen_loss = 0.8537000728774109, disc_loss = 0.07229368353935753
Trained batch 617 in epoch 4, gen_loss = 0.8535126843112958, disc_loss = 0.07224287941123579
Trained batch 618 in epoch 4, gen_loss = 0.8535723380010232, disc_loss = 0.07215531683423118
Trained batch 619 in epoch 4, gen_loss = 0.8537912643724872, disc_loss = 0.07208452743868674
Trained batch 620 in epoch 4, gen_loss = 0.8538629493275702, disc_loss = 0.07198928267621524
Trained batch 621 in epoch 4, gen_loss = 0.8538140775306432, disc_loss = 0.07198401914094948
Trained batch 622 in epoch 4, gen_loss = 0.8543655017023102, disc_loss = 0.07194392438559385
Trained batch 623 in epoch 4, gen_loss = 0.8542542908436213, disc_loss = 0.0718640527726772
Trained batch 624 in epoch 4, gen_loss = 0.8539284545898438, disc_loss = 0.07185217002779246
Trained batch 625 in epoch 4, gen_loss = 0.8542160926916348, disc_loss = 0.0718039264173482
Trained batch 626 in epoch 4, gen_loss = 0.85402684348622, disc_loss = 0.07183892808206961
Trained batch 627 in epoch 4, gen_loss = 0.8538571425304291, disc_loss = 0.07187202720677445
Trained batch 628 in epoch 4, gen_loss = 0.8539983680403669, disc_loss = 0.07179517259403755
Trained batch 629 in epoch 4, gen_loss = 0.8539976867418441, disc_loss = 0.07172983728851827
Trained batch 630 in epoch 4, gen_loss = 0.8540702697403268, disc_loss = 0.071695564649763
Trained batch 631 in epoch 4, gen_loss = 0.85401149112967, disc_loss = 0.07166850964886526
Trained batch 632 in epoch 4, gen_loss = 0.8542544412386925, disc_loss = 0.07172775944903799
Trained batch 633 in epoch 4, gen_loss = 0.8538579908831262, disc_loss = 0.0718807407055485
Trained batch 634 in epoch 4, gen_loss = 0.854000083104832, disc_loss = 0.07186573266425705
Trained batch 635 in epoch 4, gen_loss = 0.8546089788652816, disc_loss = 0.07182977896377023
Trained batch 636 in epoch 4, gen_loss = 0.8548500511672471, disc_loss = 0.07180554466687576
Trained batch 637 in epoch 4, gen_loss = 0.8545271765475736, disc_loss = 0.07181988378729799
Trained batch 638 in epoch 4, gen_loss = 0.8543950912538268, disc_loss = 0.07180812965542172
Trained batch 639 in epoch 4, gen_loss = 0.8547662721946836, disc_loss = 0.07172915697592544
Trained batch 640 in epoch 4, gen_loss = 0.8551687063553404, disc_loss = 0.07167750179285239
Trained batch 641 in epoch 4, gen_loss = 0.8552883207983688, disc_loss = 0.07158450637378286
Trained batch 642 in epoch 4, gen_loss = 0.8555653660701555, disc_loss = 0.07149755712424755
Trained batch 643 in epoch 4, gen_loss = 0.8555735717093722, disc_loss = 0.07141950294832404
Trained batch 644 in epoch 4, gen_loss = 0.8556685228680455, disc_loss = 0.07133723167168309
Trained batch 645 in epoch 4, gen_loss = 0.855407635032577, disc_loss = 0.07129724585702037
Trained batch 646 in epoch 4, gen_loss = 0.8556772545095205, disc_loss = 0.07121345046274306
Trained batch 647 in epoch 4, gen_loss = 0.8561022486767651, disc_loss = 0.07114088624560584
Trained batch 648 in epoch 4, gen_loss = 0.8563698477847917, disc_loss = 0.07104500654786366
Trained batch 649 in epoch 4, gen_loss = 0.856511030288843, disc_loss = 0.07097187116025733
Trained batch 650 in epoch 4, gen_loss = 0.856589544570208, disc_loss = 0.07088076288793264
Trained batch 651 in epoch 4, gen_loss = 0.856641264872317, disc_loss = 0.07081131099871835
Trained batch 652 in epoch 4, gen_loss = 0.8568678531128269, disc_loss = 0.07071632364761957
Trained batch 653 in epoch 4, gen_loss = 0.8565888203429884, disc_loss = 0.07069861997682203
Trained batch 654 in epoch 4, gen_loss = 0.8570164335593012, disc_loss = 0.07061927576783959
Trained batch 655 in epoch 4, gen_loss = 0.8572743539584846, disc_loss = 0.07057238881271787
Trained batch 656 in epoch 4, gen_loss = 0.8574015561667025, disc_loss = 0.07049205467739969
Trained batch 657 in epoch 4, gen_loss = 0.8573218943681398, disc_loss = 0.07039700353399236
Trained batch 658 in epoch 4, gen_loss = 0.8571984468533888, disc_loss = 0.07031196216757273
Trained batch 659 in epoch 4, gen_loss = 0.8570008215579119, disc_loss = 0.07025678821585395
Trained batch 660 in epoch 4, gen_loss = 0.8573322538709136, disc_loss = 0.07016806018999502
Trained batch 661 in epoch 4, gen_loss = 0.8578157508661379, disc_loss = 0.07011085405124189
Trained batch 662 in epoch 4, gen_loss = 0.8580639949391511, disc_loss = 0.07003239790879494
Trained batch 663 in epoch 4, gen_loss = 0.858150578765984, disc_loss = 0.0699572320129857
Trained batch 664 in epoch 4, gen_loss = 0.8580616542271206, disc_loss = 0.06992491473044668
Trained batch 665 in epoch 4, gen_loss = 0.85800158333134, disc_loss = 0.06987874895088128
Trained batch 666 in epoch 4, gen_loss = 0.8580596340649846, disc_loss = 0.06979527660942954
Trained batch 667 in epoch 4, gen_loss = 0.8587065429209235, disc_loss = 0.06989797126936788
Trained batch 668 in epoch 4, gen_loss = 0.8587877569533606, disc_loss = 0.06983642477781606
Trained batch 669 in epoch 4, gen_loss = 0.8583679678724773, disc_loss = 0.0700596898293762
Trained batch 670 in epoch 4, gen_loss = 0.8587629779973435, disc_loss = 0.07000285593567947
Trained batch 671 in epoch 4, gen_loss = 0.8590421493032149, disc_loss = 0.06993438968146663
Trained batch 672 in epoch 4, gen_loss = 0.858636263486712, disc_loss = 0.06991777002235755
Trained batch 673 in epoch 4, gen_loss = 0.8585612750902374, disc_loss = 0.06984461303689801
Trained batch 674 in epoch 4, gen_loss = 0.8585587464438544, disc_loss = 0.06977944927635016
Trained batch 675 in epoch 4, gen_loss = 0.858853020082564, disc_loss = 0.06969178149741165
Trained batch 676 in epoch 4, gen_loss = 0.8588338695037312, disc_loss = 0.06960145494951543
Trained batch 677 in epoch 4, gen_loss = 0.8588587553803548, disc_loss = 0.06952263547552634
Trained batch 678 in epoch 4, gen_loss = 0.8587343004560962, disc_loss = 0.0695226098189956
Trained batch 679 in epoch 4, gen_loss = 0.8585882207050043, disc_loss = 0.06944601955166196
Trained batch 680 in epoch 4, gen_loss = 0.8584277860043508, disc_loss = 0.06941767489584094
Trained batch 681 in epoch 4, gen_loss = 0.8587376689456425, disc_loss = 0.06933662364166503
Trained batch 682 in epoch 4, gen_loss = 0.8593577170092749, disc_loss = 0.06943659385118094
Trained batch 683 in epoch 4, gen_loss = 0.8588091799477388, disc_loss = 0.06953161733758728
Trained batch 684 in epoch 4, gen_loss = 0.8587138007592111, disc_loss = 0.06950598282426813
Trained batch 685 in epoch 4, gen_loss = 0.8590526332747485, disc_loss = 0.06945501820187006
Trained batch 686 in epoch 4, gen_loss = 0.8587150959382064, disc_loss = 0.06945340592940127
Trained batch 687 in epoch 4, gen_loss = 0.8589433470177789, disc_loss = 0.06936249100781847
Trained batch 688 in epoch 4, gen_loss = 0.8591300503868496, disc_loss = 0.0693556097537517
Trained batch 689 in epoch 4, gen_loss = 0.8588922245346982, disc_loss = 0.06935127683766726
Trained batch 690 in epoch 4, gen_loss = 0.8590026407700717, disc_loss = 0.06943243202468981
Trained batch 691 in epoch 4, gen_loss = 0.8588864770152665, disc_loss = 0.06936907930961794
Trained batch 692 in epoch 4, gen_loss = 0.8586161721062351, disc_loss = 0.0693596639451376
Trained batch 693 in epoch 4, gen_loss = 0.8585183674990272, disc_loss = 0.06927886155570834
Trained batch 694 in epoch 4, gen_loss = 0.8588233544243326, disc_loss = 0.06922304556443751
Trained batch 695 in epoch 4, gen_loss = 0.8585751830418219, disc_loss = 0.06922955045760235
Trained batch 696 in epoch 4, gen_loss = 0.8586725565675684, disc_loss = 0.06914661055192929
Trained batch 697 in epoch 4, gen_loss = 0.858584219157525, disc_loss = 0.06907425739303402
Trained batch 698 in epoch 4, gen_loss = 0.8588128108238117, disc_loss = 0.06918469256453631
Trained batch 699 in epoch 4, gen_loss = 0.8585708929385458, disc_loss = 0.06925395807650472
Trained batch 700 in epoch 4, gen_loss = 0.8586085291204711, disc_loss = 0.06920692104761211
Trained batch 701 in epoch 4, gen_loss = 0.8586559082962509, disc_loss = 0.06918551317652279
Trained batch 702 in epoch 4, gen_loss = 0.8586944442131103, disc_loss = 0.06911578568448425
Trained batch 703 in epoch 4, gen_loss = 0.8586628994565796, disc_loss = 0.06905329404848586
Trained batch 704 in epoch 4, gen_loss = 0.8590292060206123, disc_loss = 0.06908453398166185
Trained batch 705 in epoch 4, gen_loss = 0.8587592543437866, disc_loss = 0.06915296261296436
Trained batch 706 in epoch 4, gen_loss = 0.8585645751619272, disc_loss = 0.06912936521707237
Trained batch 707 in epoch 4, gen_loss = 0.8591840126167583, disc_loss = 0.06941294207732261
Trained batch 708 in epoch 4, gen_loss = 0.8589447229386048, disc_loss = 0.06943510685704533
Trained batch 709 in epoch 4, gen_loss = 0.8586307484079415, disc_loss = 0.06949660762960852
Trained batch 710 in epoch 4, gen_loss = 0.8587705534470232, disc_loss = 0.069442869564872
Trained batch 711 in epoch 4, gen_loss = 0.8584150602057409, disc_loss = 0.06958992148388513
Trained batch 712 in epoch 4, gen_loss = 0.8588824377905938, disc_loss = 0.06969482786195852
Trained batch 713 in epoch 4, gen_loss = 0.8589825784208394, disc_loss = 0.06971987211784604
Trained batch 714 in epoch 4, gen_loss = 0.8584722705654331, disc_loss = 0.06996321392773124
Trained batch 715 in epoch 4, gen_loss = 0.8581236056442367, disc_loss = 0.06996177550139915
Trained batch 716 in epoch 4, gen_loss = 0.8582925961938696, disc_loss = 0.07030964734336696
Trained batch 717 in epoch 4, gen_loss = 0.8584337392225239, disc_loss = 0.07024574289254035
Trained batch 718 in epoch 4, gen_loss = 0.8582488315825004, disc_loss = 0.07023494142096008
Trained batch 719 in epoch 4, gen_loss = 0.8579065884980891, disc_loss = 0.07025369440541707
Trained batch 720 in epoch 4, gen_loss = 0.8578786368012924, disc_loss = 0.07022818210618713
Trained batch 721 in epoch 4, gen_loss = 0.8578010684400385, disc_loss = 0.07021160546685067
Trained batch 722 in epoch 4, gen_loss = 0.8576144831638943, disc_loss = 0.07017558340220242
Trained batch 723 in epoch 4, gen_loss = 0.8573421657250072, disc_loss = 0.07020282544818249
Trained batch 724 in epoch 4, gen_loss = 0.8575972005416607, disc_loss = 0.0704643649595051
Trained batch 725 in epoch 4, gen_loss = 0.8575632004041646, disc_loss = 0.07041128188212589
Trained batch 726 in epoch 4, gen_loss = 0.8572965749684194, disc_loss = 0.07037560805867962
Trained batch 727 in epoch 4, gen_loss = 0.8572464401905353, disc_loss = 0.07036589880366452
Trained batch 728 in epoch 4, gen_loss = 0.8573396754526471, disc_loss = 0.07036615330828111
Trained batch 729 in epoch 4, gen_loss = 0.8574087893309659, disc_loss = 0.07028880651963697
Trained batch 730 in epoch 4, gen_loss = 0.8571501571567864, disc_loss = 0.07023580302898397
Trained batch 731 in epoch 4, gen_loss = 0.8570113090869508, disc_loss = 0.07024511713102012
Trained batch 732 in epoch 4, gen_loss = 0.8572171121469786, disc_loss = 0.07016293680623154
Trained batch 733 in epoch 4, gen_loss = 0.8570664406472396, disc_loss = 0.07018336003559975
Trained batch 734 in epoch 4, gen_loss = 0.8574693929581415, disc_loss = 0.07015432222258478
Trained batch 735 in epoch 4, gen_loss = 0.8571915969900463, disc_loss = 0.07009236856981221
Trained batch 736 in epoch 4, gen_loss = 0.8569673324860582, disc_loss = 0.0700803100936408
Trained batch 737 in epoch 4, gen_loss = 0.8567289499247946, disc_loss = 0.07002646787228381
Trained batch 738 in epoch 4, gen_loss = 0.8568614222845302, disc_loss = 0.0701896831801562
Trained batch 739 in epoch 4, gen_loss = 0.8568963979547088, disc_loss = 0.0701410920610903
Trained batch 740 in epoch 4, gen_loss = 0.8566078934592274, disc_loss = 0.07011239828137171
Trained batch 741 in epoch 4, gen_loss = 0.8569784574913528, disc_loss = 0.07006632468620481
Trained batch 742 in epoch 4, gen_loss = 0.8571959513353627, disc_loss = 0.06998901547861573
Trained batch 743 in epoch 4, gen_loss = 0.8571293816290876, disc_loss = 0.06993446983672398
Trained batch 744 in epoch 4, gen_loss = 0.8570285901127246, disc_loss = 0.06989333676486807
Trained batch 745 in epoch 4, gen_loss = 0.8571758796798, disc_loss = 0.0698185590415414
Trained batch 746 in epoch 4, gen_loss = 0.8570285729934253, disc_loss = 0.06983510012472849
Trained batch 747 in epoch 4, gen_loss = 0.8571366906006705, disc_loss = 0.0697961288272717
Trained batch 748 in epoch 4, gen_loss = 0.8569297030548229, disc_loss = 0.06973334623299271
Trained batch 749 in epoch 4, gen_loss = 0.856658570766449, disc_loss = 0.06975839652245243
Trained batch 750 in epoch 4, gen_loss = 0.8570126072862018, disc_loss = 0.06978209907642892
Trained batch 751 in epoch 4, gen_loss = 0.8571217784539182, disc_loss = 0.06970481392481621
Trained batch 752 in epoch 4, gen_loss = 0.8571855429000905, disc_loss = 0.0696305999282505
Trained batch 753 in epoch 4, gen_loss = 0.8572608434869377, disc_loss = 0.06958824962832093
Trained batch 754 in epoch 4, gen_loss = 0.8570741683442071, disc_loss = 0.06961308731049891
Trained batch 755 in epoch 4, gen_loss = 0.8570667879764365, disc_loss = 0.06953423840693498
Trained batch 756 in epoch 4, gen_loss = 0.8573614394334065, disc_loss = 0.06946057705467018
Trained batch 757 in epoch 4, gen_loss = 0.8574552580832177, disc_loss = 0.06941756498225839
Trained batch 758 in epoch 4, gen_loss = 0.8578004872374855, disc_loss = 0.0693630077980449
Trained batch 759 in epoch 4, gen_loss = 0.8578094368702487, disc_loss = 0.06929996674390215
Trained batch 760 in epoch 4, gen_loss = 0.8576231500165691, disc_loss = 0.0692914906943048
Trained batch 761 in epoch 4, gen_loss = 0.8579853143435451, disc_loss = 0.06929554166443391
Trained batch 762 in epoch 4, gen_loss = 0.8579597472363343, disc_loss = 0.06923549451412411
Trained batch 763 in epoch 4, gen_loss = 0.8579857169177519, disc_loss = 0.06924999176636729
Trained batch 764 in epoch 4, gen_loss = 0.8578542587024713, disc_loss = 0.06924277694981082
Trained batch 765 in epoch 4, gen_loss = 0.8577235243806017, disc_loss = 0.0691993917890535
Trained batch 766 in epoch 4, gen_loss = 0.8579606006633504, disc_loss = 0.06912955283788379
Trained batch 767 in epoch 4, gen_loss = 0.8578897750315567, disc_loss = 0.06908759301586542
Trained batch 768 in epoch 4, gen_loss = 0.857763382176274, disc_loss = 0.06902344927666479
Trained batch 769 in epoch 4, gen_loss = 0.8580054535494223, disc_loss = 0.06900413849862752
Trained batch 770 in epoch 4, gen_loss = 0.8584096376070253, disc_loss = 0.06894746270325475
Trained batch 771 in epoch 4, gen_loss = 0.8580072238037624, disc_loss = 0.06911263383509968
Trained batch 772 in epoch 4, gen_loss = 0.8582338558902716, disc_loss = 0.06906829982330928
Trained batch 773 in epoch 4, gen_loss = 0.8582431441437675, disc_loss = 0.06906925806732372
Trained batch 774 in epoch 4, gen_loss = 0.858337045638792, disc_loss = 0.06899654691498126
Trained batch 775 in epoch 4, gen_loss = 0.8579849391868434, disc_loss = 0.06901320057786695
Trained batch 776 in epoch 4, gen_loss = 0.8578713741848675, disc_loss = 0.0689527267419962
Trained batch 777 in epoch 4, gen_loss = 0.8579974933730913, disc_loss = 0.06896087614182565
Trained batch 778 in epoch 4, gen_loss = 0.857869845835327, disc_loss = 0.06895790943237493
Trained batch 779 in epoch 4, gen_loss = 0.8583457733576114, disc_loss = 0.06892603031861094
Trained batch 780 in epoch 4, gen_loss = 0.8587296241834741, disc_loss = 0.06887067261506134
Trained batch 781 in epoch 4, gen_loss = 0.8585514655655913, disc_loss = 0.0688824525622227
Trained batch 782 in epoch 4, gen_loss = 0.8582919952513157, disc_loss = 0.06887035223620909
Trained batch 783 in epoch 4, gen_loss = 0.858680823551757, disc_loss = 0.0689640107270026
Trained batch 784 in epoch 4, gen_loss = 0.8584279814343544, disc_loss = 0.06900796345939302
Trained batch 785 in epoch 4, gen_loss = 0.858567822828851, disc_loss = 0.068936989884397
Trained batch 786 in epoch 4, gen_loss = 0.8587975405071409, disc_loss = 0.06891983844756398
Trained batch 787 in epoch 4, gen_loss = 0.8591173024952109, disc_loss = 0.0688756508539965
Trained batch 788 in epoch 4, gen_loss = 0.8592771428468412, disc_loss = 0.06881106012891529
Trained batch 789 in epoch 4, gen_loss = 0.8589794034444833, disc_loss = 0.06888791011245568
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 1.0848067998886108, disc_loss = 0.09651821106672287
Trained batch 1 in epoch 5, gen_loss = 0.8887686133384705, disc_loss = 0.0848931297659874
Trained batch 2 in epoch 5, gen_loss = 0.9306809902191162, disc_loss = 0.0650683871159951
Trained batch 3 in epoch 5, gen_loss = 0.955977737903595, disc_loss = 0.05245573492720723
Trained batch 4 in epoch 5, gen_loss = 0.9316186428070068, disc_loss = 0.0491819191724062
Trained batch 5 in epoch 5, gen_loss = 0.9559716780980428, disc_loss = 0.04278910222152869
Trained batch 6 in epoch 5, gen_loss = 0.945869539465223, disc_loss = 0.042017952139888494
Trained batch 7 in epoch 5, gen_loss = 0.8920954540371895, disc_loss = 0.06483331741765141
Trained batch 8 in epoch 5, gen_loss = 0.8698955575625101, disc_loss = 0.0633195431696044
Trained batch 9 in epoch 5, gen_loss = 0.8525376081466675, disc_loss = 0.07212665006518364
Trained batch 10 in epoch 5, gen_loss = 0.8783229264346036, disc_loss = 0.07590263404629448
Trained batch 11 in epoch 5, gen_loss = 0.8534659345944723, disc_loss = 0.08385570471485455
Trained batch 12 in epoch 5, gen_loss = 0.8332604811741755, disc_loss = 0.08613711022413693
Trained batch 13 in epoch 5, gen_loss = 0.8515668255942208, disc_loss = 0.09054879524878093
Trained batch 14 in epoch 5, gen_loss = 0.8648174842198689, disc_loss = 0.09088039298852285
Trained batch 15 in epoch 5, gen_loss = 0.8659805282950401, disc_loss = 0.08609474718105048
Trained batch 16 in epoch 5, gen_loss = 0.8703132902874666, disc_loss = 0.0821709724910119
Trained batch 17 in epoch 5, gen_loss = 0.8649257785744138, disc_loss = 0.07997912127110693
Trained batch 18 in epoch 5, gen_loss = 0.8600184258661772, disc_loss = 0.07730679439478799
Trained batch 19 in epoch 5, gen_loss = 0.870331934094429, disc_loss = 0.07831683522090316
Trained batch 20 in epoch 5, gen_loss = 0.8615040495282128, disc_loss = 0.0790735429064149
Trained batch 21 in epoch 5, gen_loss = 0.8621072498234835, disc_loss = 0.07744760650464079
Trained batch 22 in epoch 5, gen_loss = 0.8590925698694976, disc_loss = 0.07743031410095484
Trained batch 23 in epoch 5, gen_loss = 0.8629340703288714, disc_loss = 0.0771162942207108
Trained batch 24 in epoch 5, gen_loss = 0.8596432185173035, disc_loss = 0.07538938410580158
Trained batch 25 in epoch 5, gen_loss = 0.863241372200159, disc_loss = 0.07291377371606919
Trained batch 26 in epoch 5, gen_loss = 0.8656746480200026, disc_loss = 0.07143874018004646
Trained batch 27 in epoch 5, gen_loss = 0.8671773225069046, disc_loss = 0.06972459430939384
Trained batch 28 in epoch 5, gen_loss = 0.8674768599970587, disc_loss = 0.06973901179073186
Trained batch 29 in epoch 5, gen_loss = 0.866219307978948, disc_loss = 0.07043146186818679
Trained batch 30 in epoch 5, gen_loss = 0.8611017254091078, disc_loss = 0.06971265117247258
Trained batch 31 in epoch 5, gen_loss = 0.8711992856115103, disc_loss = 0.07043954293476418
Trained batch 32 in epoch 5, gen_loss = 0.863436039650079, disc_loss = 0.07094651646912098
Trained batch 33 in epoch 5, gen_loss = 0.8539625178365147, disc_loss = 0.0725593444726923
Trained batch 34 in epoch 5, gen_loss = 0.8623527543885368, disc_loss = 0.07879934145935945
Trained batch 35 in epoch 5, gen_loss = 0.8644509530729718, disc_loss = 0.07692732827530967
Trained batch 36 in epoch 5, gen_loss = 0.8662475041441016, disc_loss = 0.07521410306563249
Trained batch 37 in epoch 5, gen_loss = 0.864292605927116, disc_loss = 0.074660774320364
Trained batch 38 in epoch 5, gen_loss = 0.8682367954498682, disc_loss = 0.07309098176371592
Trained batch 39 in epoch 5, gen_loss = 0.8673070311546326, disc_loss = 0.07195178850088269
Trained batch 40 in epoch 5, gen_loss = 0.8708666882863859, disc_loss = 0.07069363556347968
Trained batch 41 in epoch 5, gen_loss = 0.8705843488375345, disc_loss = 0.07090406618746263
Trained batch 42 in epoch 5, gen_loss = 0.8693139151085255, disc_loss = 0.07008563850594815
Trained batch 43 in epoch 5, gen_loss = 0.8688598519021814, disc_loss = 0.06914315992881628
Trained batch 44 in epoch 5, gen_loss = 0.8749086300532023, disc_loss = 0.06833480813850959
Trained batch 45 in epoch 5, gen_loss = 0.8764607258464979, disc_loss = 0.067048412727435
Trained batch 46 in epoch 5, gen_loss = 0.8766520023345947, disc_loss = 0.06608422403719197
Trained batch 47 in epoch 5, gen_loss = 0.8757747995356718, disc_loss = 0.06535961519693956
Trained batch 48 in epoch 5, gen_loss = 0.8823293824585117, disc_loss = 0.0647153222781359
Trained batch 49 in epoch 5, gen_loss = 0.8890057718753814, disc_loss = 0.06397392967715859
Trained batch 50 in epoch 5, gen_loss = 0.8905328231699327, disc_loss = 0.06311470030934788
Trained batch 51 in epoch 5, gen_loss = 0.8861471494803062, disc_loss = 0.0628900861260123
Trained batch 52 in epoch 5, gen_loss = 0.8908389773008958, disc_loss = 0.062386560429520205
Trained batch 53 in epoch 5, gen_loss = 0.8931019030235432, disc_loss = 0.06165602560051613
Trained batch 54 in epoch 5, gen_loss = 0.8910733645612543, disc_loss = 0.061459949324754154
Trained batch 55 in epoch 5, gen_loss = 0.8935174675924438, disc_loss = 0.06056739429810217
Trained batch 56 in epoch 5, gen_loss = 0.8935175057043109, disc_loss = 0.05962389771287378
Trained batch 57 in epoch 5, gen_loss = 0.894060965242057, disc_loss = 0.05939379814562613
Trained batch 58 in epoch 5, gen_loss = 0.8921241659229084, disc_loss = 0.05899043019734702
Trained batch 59 in epoch 5, gen_loss = 0.8894905179738999, disc_loss = 0.05912218582816422
Trained batch 60 in epoch 5, gen_loss = 0.8950145410709693, disc_loss = 0.05905213559687626
Trained batch 61 in epoch 5, gen_loss = 0.8993176077642748, disc_loss = 0.059093302100776665
Trained batch 62 in epoch 5, gen_loss = 0.8992741316083878, disc_loss = 0.05841809373703741
Trained batch 63 in epoch 5, gen_loss = 0.8959742672741413, disc_loss = 0.05940064815513324
Trained batch 64 in epoch 5, gen_loss = 0.8937368924801167, disc_loss = 0.05920807872540676
Trained batch 65 in epoch 5, gen_loss = 0.898880357092077, disc_loss = 0.058973199419790144
Trained batch 66 in epoch 5, gen_loss = 0.8975630393668786, disc_loss = 0.05853359333114393
Trained batch 67 in epoch 5, gen_loss = 0.8991928924532497, disc_loss = 0.058072821524761176
Trained batch 68 in epoch 5, gen_loss = 0.8982321093047875, disc_loss = 0.05858736303027557
Trained batch 69 in epoch 5, gen_loss = 0.897476145199367, disc_loss = 0.05891067301854491
Trained batch 70 in epoch 5, gen_loss = 0.8972912808539162, disc_loss = 0.05869812755779901
Trained batch 71 in epoch 5, gen_loss = 0.8973798619376289, disc_loss = 0.058118864880978234
Trained batch 72 in epoch 5, gen_loss = 0.8940494027856278, disc_loss = 0.05856789933032777
Trained batch 73 in epoch 5, gen_loss = 0.8947458895477088, disc_loss = 0.06060906317135369
Trained batch 74 in epoch 5, gen_loss = 0.8935909175872803, disc_loss = 0.06035314926256736
Trained batch 75 in epoch 5, gen_loss = 0.8913873324268743, disc_loss = 0.06035709835735983
Trained batch 76 in epoch 5, gen_loss = 0.8887977305944864, disc_loss = 0.06097261050062907
Trained batch 77 in epoch 5, gen_loss = 0.8918561736742655, disc_loss = 0.06049106443205323
Trained batch 78 in epoch 5, gen_loss = 0.8926977884920337, disc_loss = 0.05983768337512318
Trained batch 79 in epoch 5, gen_loss = 0.8939422525465488, disc_loss = 0.05919928775401786
Trained batch 80 in epoch 5, gen_loss = 0.8930545662656243, disc_loss = 0.05867762080635185
Trained batch 81 in epoch 5, gen_loss = 0.8919232494947387, disc_loss = 0.05847252568048311
Trained batch 82 in epoch 5, gen_loss = 0.8909835865698665, disc_loss = 0.05829190452729004
Trained batch 83 in epoch 5, gen_loss = 0.8956851412852606, disc_loss = 0.05961854329022268
Trained batch 84 in epoch 5, gen_loss = 0.8917343707645641, disc_loss = 0.06025075972737635
Trained batch 85 in epoch 5, gen_loss = 0.8912255424399709, disc_loss = 0.059892985958952545
Trained batch 86 in epoch 5, gen_loss = 0.8891304053109268, disc_loss = 0.0598387415360274
Trained batch 87 in epoch 5, gen_loss = 0.891231702809984, disc_loss = 0.0596379285403104
Trained batch 88 in epoch 5, gen_loss = 0.8915128071656387, disc_loss = 0.059315398283135354
Trained batch 89 in epoch 5, gen_loss = 0.8888316916094886, disc_loss = 0.05975070631959372
Trained batch 90 in epoch 5, gen_loss = 0.8864156780662117, disc_loss = 0.059969004233377976
Trained batch 91 in epoch 5, gen_loss = 0.8890139499436254, disc_loss = 0.05977477634366116
Trained batch 92 in epoch 5, gen_loss = 0.8883612463551183, disc_loss = 0.0594971565209249
Trained batch 93 in epoch 5, gen_loss = 0.8884833822859094, disc_loss = 0.05912366744249742
Trained batch 94 in epoch 5, gen_loss = 0.891047329651682, disc_loss = 0.058643687447827116
Trained batch 95 in epoch 5, gen_loss = 0.8880703002214432, disc_loss = 0.0597567473402402
Trained batch 96 in epoch 5, gen_loss = 0.8920004036008697, disc_loss = 0.06100393252773691
Trained batch 97 in epoch 5, gen_loss = 0.8897993674083632, disc_loss = 0.06080771816362228
Trained batch 98 in epoch 5, gen_loss = 0.8887127758276583, disc_loss = 0.06101498813979855
Trained batch 99 in epoch 5, gen_loss = 0.8855172216892242, disc_loss = 0.061393486941233276
Trained batch 100 in epoch 5, gen_loss = 0.8847757489374368, disc_loss = 0.06093663619001313
Trained batch 101 in epoch 5, gen_loss = 0.8836511168994156, disc_loss = 0.06121412854568631
Trained batch 102 in epoch 5, gen_loss = 0.8829229728689472, disc_loss = 0.06088528586822806
Trained batch 103 in epoch 5, gen_loss = 0.883029797902474, disc_loss = 0.06064497478879415
Trained batch 104 in epoch 5, gen_loss = 0.8828078008833385, disc_loss = 0.06025257369592076
Trained batch 105 in epoch 5, gen_loss = 0.8803777998348452, disc_loss = 0.06029351607386796
Trained batch 106 in epoch 5, gen_loss = 0.8845542479898328, disc_loss = 0.06161898879386554
Trained batch 107 in epoch 5, gen_loss = 0.8833401997884115, disc_loss = 0.061461024158806714
Trained batch 108 in epoch 5, gen_loss = 0.8823294377108233, disc_loss = 0.06116610873114625
Trained batch 109 in epoch 5, gen_loss = 0.8823950789191506, disc_loss = 0.061143952184780075
Trained batch 110 in epoch 5, gen_loss = 0.880768016651944, disc_loss = 0.06126412626792182
Trained batch 111 in epoch 5, gen_loss = 0.880767502955028, disc_loss = 0.06186328946413206
Trained batch 112 in epoch 5, gen_loss = 0.8791701187074712, disc_loss = 0.062104235164227736
Trained batch 113 in epoch 5, gen_loss = 0.8774686539382265, disc_loss = 0.06199751279659962
Trained batch 114 in epoch 5, gen_loss = 0.878871866931086, disc_loss = 0.06159042628562969
Trained batch 115 in epoch 5, gen_loss = 0.8788973945995857, disc_loss = 0.06114280085753778
Trained batch 116 in epoch 5, gen_loss = 0.8782519051152416, disc_loss = 0.0607950510059157
Trained batch 117 in epoch 5, gen_loss = 0.8798306099439072, disc_loss = 0.06118580986256317
Trained batch 118 in epoch 5, gen_loss = 0.8800724744796753, disc_loss = 0.06083079577744508
Trained batch 119 in epoch 5, gen_loss = 0.880915533999602, disc_loss = 0.06050120846678813
Trained batch 120 in epoch 5, gen_loss = 0.881261252667293, disc_loss = 0.060125400327638655
Trained batch 121 in epoch 5, gen_loss = 0.8819193971938775, disc_loss = 0.05989741869118126
Trained batch 122 in epoch 5, gen_loss = 0.8807435059935097, disc_loss = 0.06004497286962057
Trained batch 123 in epoch 5, gen_loss = 0.8813551741261636, disc_loss = 0.05964282404391035
Trained batch 124 in epoch 5, gen_loss = 0.8810994377136231, disc_loss = 0.059303514540195466
Trained batch 125 in epoch 5, gen_loss = 0.8818879761393108, disc_loss = 0.05898409555592234
Trained batch 126 in epoch 5, gen_loss = 0.8822330349073635, disc_loss = 0.05866740181983456
Trained batch 127 in epoch 5, gen_loss = 0.8816818315535784, disc_loss = 0.05839882398140617
Trained batch 128 in epoch 5, gen_loss = 0.8796778903451077, disc_loss = 0.058334496449823525
Trained batch 129 in epoch 5, gen_loss = 0.8799582669368157, disc_loss = 0.05824521682583369
Trained batch 130 in epoch 5, gen_loss = 0.8795116561969728, disc_loss = 0.057947021503826135
Trained batch 131 in epoch 5, gen_loss = 0.8811833935253548, disc_loss = 0.0576019818386571
Trained batch 132 in epoch 5, gen_loss = 0.8810098408756399, disc_loss = 0.05722321261462748
Trained batch 133 in epoch 5, gen_loss = 0.8794518758111926, disc_loss = 0.05723571123680406
Trained batch 134 in epoch 5, gen_loss = 0.8810449445689166, disc_loss = 0.057251560022295624
Trained batch 135 in epoch 5, gen_loss = 0.88260849214652, disc_loss = 0.05705913358628202
Trained batch 136 in epoch 5, gen_loss = 0.8807316318045567, disc_loss = 0.05759550179320857
Trained batch 137 in epoch 5, gen_loss = 0.8821112483307936, disc_loss = 0.05741547557957254
Trained batch 138 in epoch 5, gen_loss = 0.8803867050212064, disc_loss = 0.0576881950406237
Trained batch 139 in epoch 5, gen_loss = 0.8816037459032876, disc_loss = 0.05821988398674875
Trained batch 140 in epoch 5, gen_loss = 0.8792223190584927, disc_loss = 0.059793261424737405
Trained batch 141 in epoch 5, gen_loss = 0.880475640716687, disc_loss = 0.05947738192962404
Trained batch 142 in epoch 5, gen_loss = 0.8810549957768901, disc_loss = 0.06005303717667719
Trained batch 143 in epoch 5, gen_loss = 0.8791545745399263, disc_loss = 0.060841466296955735
Trained batch 144 in epoch 5, gen_loss = 0.8790493623963718, disc_loss = 0.06073020341773999
Trained batch 145 in epoch 5, gen_loss = 0.8805657433320399, disc_loss = 0.060544925164558915
Trained batch 146 in epoch 5, gen_loss = 0.8787499402656036, disc_loss = 0.06075587024481422
Trained batch 147 in epoch 5, gen_loss = 0.8781885174480645, disc_loss = 0.06108601509303962
Trained batch 148 in epoch 5, gen_loss = 0.8776939275280741, disc_loss = 0.0608955449924723
Trained batch 149 in epoch 5, gen_loss = 0.876203891436259, disc_loss = 0.061036597810064756
Trained batch 150 in epoch 5, gen_loss = 0.8767013360332969, disc_loss = 0.06071621826263946
Trained batch 151 in epoch 5, gen_loss = 0.8762990604890021, disc_loss = 0.06047037175525666
Trained batch 152 in epoch 5, gen_loss = 0.8757613149343753, disc_loss = 0.0602549522950807
Trained batch 153 in epoch 5, gen_loss = 0.8769376355332213, disc_loss = 0.06022375706256694
Trained batch 154 in epoch 5, gen_loss = 0.875543337868106, disc_loss = 0.06039791996741006
Trained batch 155 in epoch 5, gen_loss = 0.8753828532420672, disc_loss = 0.06016392524963102
Trained batch 156 in epoch 5, gen_loss = 0.8771733261977032, disc_loss = 0.06108376095783274
Trained batch 157 in epoch 5, gen_loss = 0.8765821445591843, disc_loss = 0.06109634104562051
Trained batch 158 in epoch 5, gen_loss = 0.8763517819860447, disc_loss = 0.060953129097561606
Trained batch 159 in epoch 5, gen_loss = 0.876853733509779, disc_loss = 0.06066964579222258
Trained batch 160 in epoch 5, gen_loss = 0.8794615853647267, disc_loss = 0.06064843373396289
Trained batch 161 in epoch 5, gen_loss = 0.8777153804714297, disc_loss = 0.06089608592878061
Trained batch 162 in epoch 5, gen_loss = 0.8770164050207547, disc_loss = 0.06065814861844928
Trained batch 163 in epoch 5, gen_loss = 0.879017116456497, disc_loss = 0.06116571638267487
Trained batch 164 in epoch 5, gen_loss = 0.8785454233487447, disc_loss = 0.06092240758183779
Trained batch 165 in epoch 5, gen_loss = 0.8766894236386541, disc_loss = 0.0611817418648132
Trained batch 166 in epoch 5, gen_loss = 0.8769894934699921, disc_loss = 0.06121123133472608
Trained batch 167 in epoch 5, gen_loss = 0.8760952332190105, disc_loss = 0.061109896147778876
Trained batch 168 in epoch 5, gen_loss = 0.877254166546658, disc_loss = 0.060967035919494005
Trained batch 169 in epoch 5, gen_loss = 0.8769167156780467, disc_loss = 0.06094979106667726
Trained batch 170 in epoch 5, gen_loss = 0.8754762676027086, disc_loss = 0.06135893371010646
Trained batch 171 in epoch 5, gen_loss = 0.8746587287547977, disc_loss = 0.06157227421211902
Trained batch 172 in epoch 5, gen_loss = 0.8752433354454923, disc_loss = 0.061649409480759004
Trained batch 173 in epoch 5, gen_loss = 0.8755498367479477, disc_loss = 0.06153045412442037
Trained batch 174 in epoch 5, gen_loss = 0.8770587427275521, disc_loss = 0.061687107445406064
Trained batch 175 in epoch 5, gen_loss = 0.8751636299897324, disc_loss = 0.06214737428341654
Trained batch 176 in epoch 5, gen_loss = 0.874917016527747, disc_loss = 0.06262477047183672
Trained batch 177 in epoch 5, gen_loss = 0.8741821053992497, disc_loss = 0.06275737379531093
Trained batch 178 in epoch 5, gen_loss = 0.8743246091144711, disc_loss = 0.06281819437791765
Trained batch 179 in epoch 5, gen_loss = 0.872667517595821, disc_loss = 0.0629661702628558
Trained batch 180 in epoch 5, gen_loss = 0.8727283744522221, disc_loss = 0.06274878731491404
Trained batch 181 in epoch 5, gen_loss = 0.8727538333489344, disc_loss = 0.06293998621557685
Trained batch 182 in epoch 5, gen_loss = 0.8719829402334703, disc_loss = 0.0629698153702247
Trained batch 183 in epoch 5, gen_loss = 0.8708998920476955, disc_loss = 0.06295717100400235
Trained batch 184 in epoch 5, gen_loss = 0.8724002042332211, disc_loss = 0.06275834038199203
Trained batch 185 in epoch 5, gen_loss = 0.8731434515086554, disc_loss = 0.06268551881344969
Trained batch 186 in epoch 5, gen_loss = 0.8719064657063408, disc_loss = 0.06255204029092416
Trained batch 187 in epoch 5, gen_loss = 0.8708543504806275, disc_loss = 0.06265193241539392
Trained batch 188 in epoch 5, gen_loss = 0.8710060220546824, disc_loss = 0.06252478742873464
Trained batch 189 in epoch 5, gen_loss = 0.8701718393125032, disc_loss = 0.06254785325329162
Trained batch 190 in epoch 5, gen_loss = 0.8687444494656867, disc_loss = 0.06275184719496607
Trained batch 191 in epoch 5, gen_loss = 0.8696056542297205, disc_loss = 0.06269471814691012
Trained batch 192 in epoch 5, gen_loss = 0.8695092145643086, disc_loss = 0.06250031700435003
Trained batch 193 in epoch 5, gen_loss = 0.8693336328280341, disc_loss = 0.06226292413601786
Trained batch 194 in epoch 5, gen_loss = 0.8689981720386407, disc_loss = 0.062016302898812756
Trained batch 195 in epoch 5, gen_loss = 0.8679145018056947, disc_loss = 0.06233797300065278
Trained batch 196 in epoch 5, gen_loss = 0.869223900555354, disc_loss = 0.06267892302434683
Trained batch 197 in epoch 5, gen_loss = 0.8686615921030141, disc_loss = 0.06266157116242355
Trained batch 198 in epoch 5, gen_loss = 0.8681914144424937, disc_loss = 0.06258419797938299
Trained batch 199 in epoch 5, gen_loss = 0.866681367456913, disc_loss = 0.0629767726152204
Trained batch 200 in epoch 5, gen_loss = 0.8667305218639658, disc_loss = 0.06292808936000686
Trained batch 201 in epoch 5, gen_loss = 0.8664471663460873, disc_loss = 0.0627620658067304
Trained batch 202 in epoch 5, gen_loss = 0.8674442624223644, disc_loss = 0.06297442556262531
Trained batch 203 in epoch 5, gen_loss = 0.8655466416887209, disc_loss = 0.06334375484855663
Trained batch 204 in epoch 5, gen_loss = 0.8656942225084072, disc_loss = 0.06328878932200917
Trained batch 205 in epoch 5, gen_loss = 0.8654771733631208, disc_loss = 0.06311293129664529
Trained batch 206 in epoch 5, gen_loss = 0.8643567202171841, disc_loss = 0.06343505004924781
Trained batch 207 in epoch 5, gen_loss = 0.8645210647239134, disc_loss = 0.06331577666703826
Trained batch 208 in epoch 5, gen_loss = 0.8653077249321641, disc_loss = 0.06383523522123125
Trained batch 209 in epoch 5, gen_loss = 0.8660648195516496, disc_loss = 0.06359729693892101
Trained batch 210 in epoch 5, gen_loss = 0.8659811491649863, disc_loss = 0.06346134871235602
Trained batch 211 in epoch 5, gen_loss = 0.8652129378521217, disc_loss = 0.06341734719858065
Trained batch 212 in epoch 5, gen_loss = 0.8643463735289417, disc_loss = 0.06354326766832544
Trained batch 213 in epoch 5, gen_loss = 0.8648824020523891, disc_loss = 0.06329918200820336
Trained batch 214 in epoch 5, gen_loss = 0.8647112876869911, disc_loss = 0.0634343647051516
Trained batch 215 in epoch 5, gen_loss = 0.863722462621, disc_loss = 0.06354654291256641
Trained batch 216 in epoch 5, gen_loss = 0.8634909037071439, disc_loss = 0.06336756912167377
Trained batch 217 in epoch 5, gen_loss = 0.8640106306710374, disc_loss = 0.06331750041155845
Trained batch 218 in epoch 5, gen_loss = 0.8645261520664441, disc_loss = 0.06308270166904482
Trained batch 219 in epoch 5, gen_loss = 0.8629829141226681, disc_loss = 0.06334224566182291
Trained batch 220 in epoch 5, gen_loss = 0.8641321033374216, disc_loss = 0.06346420386839843
Trained batch 221 in epoch 5, gen_loss = 0.8643111471120302, disc_loss = 0.06330236634197603
Trained batch 222 in epoch 5, gen_loss = 0.8634410901454532, disc_loss = 0.06316839259811113
Trained batch 223 in epoch 5, gen_loss = 0.8624752677444901, disc_loss = 0.06305527556729171
Trained batch 224 in epoch 5, gen_loss = 0.8614886297119988, disc_loss = 0.06304509445404013
Trained batch 225 in epoch 5, gen_loss = 0.8627335405455226, disc_loss = 0.06312803044890473
Trained batch 226 in epoch 5, gen_loss = 0.8628990411233272, disc_loss = 0.06301219424331306
Trained batch 227 in epoch 5, gen_loss = 0.8624278155335209, disc_loss = 0.06291778064782225
Trained batch 228 in epoch 5, gen_loss = 0.8618454573976941, disc_loss = 0.06308535092172729
Trained batch 229 in epoch 5, gen_loss = 0.861800335801166, disc_loss = 0.06289984691766617
Trained batch 230 in epoch 5, gen_loss = 0.8610965287014519, disc_loss = 0.06293569902941842
Trained batch 231 in epoch 5, gen_loss = 0.862890813885064, disc_loss = 0.06313108483626476
Trained batch 232 in epoch 5, gen_loss = 0.8623219600562886, disc_loss = 0.06298820701799487
Trained batch 233 in epoch 5, gen_loss = 0.8624843195972279, disc_loss = 0.06287315569252858
Trained batch 234 in epoch 5, gen_loss = 0.8610876796093393, disc_loss = 0.06334973185501518
Trained batch 235 in epoch 5, gen_loss = 0.8613430079767259, disc_loss = 0.06317372512174928
Trained batch 236 in epoch 5, gen_loss = 0.8614293180940523, disc_loss = 0.06332910135742041
Trained batch 237 in epoch 5, gen_loss = 0.8602377436742061, disc_loss = 0.06362705752292663
Trained batch 238 in epoch 5, gen_loss = 0.8591055221637423, disc_loss = 0.06414030448077675
Trained batch 239 in epoch 5, gen_loss = 0.8602162291606267, disc_loss = 0.06398549170892996
Trained batch 240 in epoch 5, gen_loss = 0.8606330725167303, disc_loss = 0.06395895787827763
Trained batch 241 in epoch 5, gen_loss = 0.8602052424564834, disc_loss = 0.06383699402867332
Trained batch 242 in epoch 5, gen_loss = 0.8589758902420233, disc_loss = 0.0641234008376889
Trained batch 243 in epoch 5, gen_loss = 0.8600941583758495, disc_loss = 0.06404250655056085
Trained batch 244 in epoch 5, gen_loss = 0.8605173578067702, disc_loss = 0.06388916869894887
Trained batch 245 in epoch 5, gen_loss = 0.8595497651797969, disc_loss = 0.0640383437067664
Trained batch 246 in epoch 5, gen_loss = 0.8592367567996747, disc_loss = 0.0641551091456371
Trained batch 247 in epoch 5, gen_loss = 0.8596061472931216, disc_loss = 0.06407361792498117
Trained batch 248 in epoch 5, gen_loss = 0.8591979775562822, disc_loss = 0.06400587632092666
Trained batch 249 in epoch 5, gen_loss = 0.8594936008453369, disc_loss = 0.06378566555865109
Trained batch 250 in epoch 5, gen_loss = 0.8593905717728147, disc_loss = 0.06369080289315239
Trained batch 251 in epoch 5, gen_loss = 0.8589313758744134, disc_loss = 0.06367051901687527
Trained batch 252 in epoch 5, gen_loss = 0.8588445620103315, disc_loss = 0.06358722906758486
Trained batch 253 in epoch 5, gen_loss = 0.8586873700768929, disc_loss = 0.06341276342217905
Trained batch 254 in epoch 5, gen_loss = 0.8597357490483453, disc_loss = 0.06345599116392288
Trained batch 255 in epoch 5, gen_loss = 0.8591644861735404, disc_loss = 0.0635957531430904
Trained batch 256 in epoch 5, gen_loss = 0.8587667009709874, disc_loss = 0.06348960027134894
Trained batch 257 in epoch 5, gen_loss = 0.8597033264101014, disc_loss = 0.06349006989183872
Trained batch 258 in epoch 5, gen_loss = 0.8606307428315799, disc_loss = 0.06331720595287597
Trained batch 259 in epoch 5, gen_loss = 0.8599592793446321, disc_loss = 0.0631857475785252
Trained batch 260 in epoch 5, gen_loss = 0.8593456610409236, disc_loss = 0.06322005229299153
Trained batch 261 in epoch 5, gen_loss = 0.8596367719974226, disc_loss = 0.06334428174442519
Trained batch 262 in epoch 5, gen_loss = 0.8586141195134065, disc_loss = 0.0636016546125336
Trained batch 263 in epoch 5, gen_loss = 0.8587915874791868, disc_loss = 0.0635074012521231
Trained batch 264 in epoch 5, gen_loss = 0.8596978754367468, disc_loss = 0.06365714253998309
Trained batch 265 in epoch 5, gen_loss = 0.8586933931013695, disc_loss = 0.06380483957140573
Trained batch 266 in epoch 5, gen_loss = 0.8584050350867853, disc_loss = 0.06385270783273078
Trained batch 267 in epoch 5, gen_loss = 0.8578078835757811, disc_loss = 0.06409872162899476
Trained batch 268 in epoch 5, gen_loss = 0.8571716276686431, disc_loss = 0.06413540405612508
Trained batch 269 in epoch 5, gen_loss = 0.8576050466961331, disc_loss = 0.06421290719709187
Trained batch 270 in epoch 5, gen_loss = 0.8580648173265352, disc_loss = 0.0641139506884744
Trained batch 271 in epoch 5, gen_loss = 0.8581266052582684, disc_loss = 0.06401650324936353
Trained batch 272 in epoch 5, gen_loss = 0.8572289360748543, disc_loss = 0.06404501624958037
Trained batch 273 in epoch 5, gen_loss = 0.8575458700639488, disc_loss = 0.06405908018384592
Trained batch 274 in epoch 5, gen_loss = 0.8577726539698514, disc_loss = 0.06394316239282488
Trained batch 275 in epoch 5, gen_loss = 0.8568694224392158, disc_loss = 0.06410939383583711
Trained batch 276 in epoch 5, gen_loss = 0.856910428415567, disc_loss = 0.06469639567725549
Trained batch 277 in epoch 5, gen_loss = 0.8564521100023668, disc_loss = 0.06465636501457248
Trained batch 278 in epoch 5, gen_loss = 0.855945536953574, disc_loss = 0.0647377995824221
Trained batch 279 in epoch 5, gen_loss = 0.8561865646924292, disc_loss = 0.0647804022051527
Trained batch 280 in epoch 5, gen_loss = 0.8562527398621909, disc_loss = 0.06489355455971327
Trained batch 281 in epoch 5, gen_loss = 0.8560740436222536, disc_loss = 0.06533228291086324
Trained batch 282 in epoch 5, gen_loss = 0.85579984263902, disc_loss = 0.06544964191382059
Trained batch 283 in epoch 5, gen_loss = 0.8565267517533101, disc_loss = 0.06554777145838286
Trained batch 284 in epoch 5, gen_loss = 0.8552606614012467, disc_loss = 0.06565404374381167
Trained batch 285 in epoch 5, gen_loss = 0.8545703002206095, disc_loss = 0.0656200711260439
Trained batch 286 in epoch 5, gen_loss = 0.8539745651886438, disc_loss = 0.06567069984978967
Trained batch 287 in epoch 5, gen_loss = 0.8556402799569898, disc_loss = 0.06626670981737941
Trained batch 288 in epoch 5, gen_loss = 0.8547617621900301, disc_loss = 0.0662851714993147
Trained batch 289 in epoch 5, gen_loss = 0.8542434135387684, disc_loss = 0.06626031168351143
Trained batch 290 in epoch 5, gen_loss = 0.8544277976878321, disc_loss = 0.06610079558527808
Trained batch 291 in epoch 5, gen_loss = 0.8544719737686522, disc_loss = 0.0659281633083058
Trained batch 292 in epoch 5, gen_loss = 0.8542603722204527, disc_loss = 0.06596448231304108
Trained batch 293 in epoch 5, gen_loss = 0.854383415916339, disc_loss = 0.06593445995917582
Trained batch 294 in epoch 5, gen_loss = 0.8532419972500559, disc_loss = 0.06616360452499682
Trained batch 295 in epoch 5, gen_loss = 0.8530392151426625, disc_loss = 0.06610324534090437
Trained batch 296 in epoch 5, gen_loss = 0.8531827972794221, disc_loss = 0.06639843821205725
Trained batch 297 in epoch 5, gen_loss = 0.853105282023449, disc_loss = 0.06623764158126542
Trained batch 298 in epoch 5, gen_loss = 0.8534707159900347, disc_loss = 0.0660966303165267
Trained batch 299 in epoch 5, gen_loss = 0.8524032308657964, disc_loss = 0.0667451834011202
Trained batch 300 in epoch 5, gen_loss = 0.8531122558140676, disc_loss = 0.06730994263639135
Trained batch 301 in epoch 5, gen_loss = 0.8525900724313117, disc_loss = 0.06731978955135884
Trained batch 302 in epoch 5, gen_loss = 0.853093953219184, disc_loss = 0.06734177301308945
Trained batch 303 in epoch 5, gen_loss = 0.8526902318392929, disc_loss = 0.067453278162774
Trained batch 304 in epoch 5, gen_loss = 0.8521801223520373, disc_loss = 0.06739660286054504
Trained batch 305 in epoch 5, gen_loss = 0.8524981092393787, disc_loss = 0.06732776805642822
Trained batch 306 in epoch 5, gen_loss = 0.8523506906599486, disc_loss = 0.06731283255315808
Trained batch 307 in epoch 5, gen_loss = 0.8513323871733306, disc_loss = 0.06769294149768479
Trained batch 308 in epoch 5, gen_loss = 0.8514798869978648, disc_loss = 0.06769400288450342
Trained batch 309 in epoch 5, gen_loss = 0.8520152209266539, disc_loss = 0.06772605049303702
Trained batch 310 in epoch 5, gen_loss = 0.8512293171269334, disc_loss = 0.06781708200722693
Trained batch 311 in epoch 5, gen_loss = 0.8509047835683211, disc_loss = 0.06779300645501234
Trained batch 312 in epoch 5, gen_loss = 0.851223487633105, disc_loss = 0.06794432516897116
Trained batch 313 in epoch 5, gen_loss = 0.8505551862488886, disc_loss = 0.06800583429237128
Trained batch 314 in epoch 5, gen_loss = 0.8507897123457894, disc_loss = 0.06792362304700036
Trained batch 315 in epoch 5, gen_loss = 0.8508127007303359, disc_loss = 0.0678082493714446
Trained batch 316 in epoch 5, gen_loss = 0.8499160794429599, disc_loss = 0.06791796835656469
Trained batch 317 in epoch 5, gen_loss = 0.8497570003353575, disc_loss = 0.06775430972547324
Trained batch 318 in epoch 5, gen_loss = 0.8497110113828533, disc_loss = 0.06771510021562534
Trained batch 319 in epoch 5, gen_loss = 0.8493179423734546, disc_loss = 0.0677816966039245
Trained batch 320 in epoch 5, gen_loss = 0.84885287674788, disc_loss = 0.06768335071987128
Trained batch 321 in epoch 5, gen_loss = 0.8493888268929831, disc_loss = 0.06751251161266233
Trained batch 322 in epoch 5, gen_loss = 0.8497580968927673, disc_loss = 0.0674685960817194
Trained batch 323 in epoch 5, gen_loss = 0.8497381396131751, disc_loss = 0.06734055382584762
Trained batch 324 in epoch 5, gen_loss = 0.8504407326991742, disc_loss = 0.06725266143249778
Trained batch 325 in epoch 5, gen_loss = 0.8506056478052783, disc_loss = 0.06708493402679136
Trained batch 326 in epoch 5, gen_loss = 0.8497841360007586, disc_loss = 0.06717100428610995
Trained batch 327 in epoch 5, gen_loss = 0.8495560760905103, disc_loss = 0.06722939694896568
Trained batch 328 in epoch 5, gen_loss = 0.8502298568157439, disc_loss = 0.06713025612858517
Trained batch 329 in epoch 5, gen_loss = 0.8503464326714024, disc_loss = 0.06699503380946363
Trained batch 330 in epoch 5, gen_loss = 0.8507345012667676, disc_loss = 0.06682335469573511
Trained batch 331 in epoch 5, gen_loss = 0.8504945741719511, disc_loss = 0.06681066191704742
Trained batch 332 in epoch 5, gen_loss = 0.8503810484130103, disc_loss = 0.06666454181282057
Trained batch 333 in epoch 5, gen_loss = 0.8500054469722473, disc_loss = 0.06673144117070216
Trained batch 334 in epoch 5, gen_loss = 0.8503302636431225, disc_loss = 0.0667388237526279
Trained batch 335 in epoch 5, gen_loss = 0.851663274956601, disc_loss = 0.06670633892645128
Trained batch 336 in epoch 5, gen_loss = 0.8515308364916272, disc_loss = 0.06658972394777025
Trained batch 337 in epoch 5, gen_loss = 0.8517391688724947, disc_loss = 0.06644738784208673
Trained batch 338 in epoch 5, gen_loss = 0.852000371720587, disc_loss = 0.06631400061573471
Trained batch 339 in epoch 5, gen_loss = 0.8524076561717426, disc_loss = 0.0661413833992008
Trained batch 340 in epoch 5, gen_loss = 0.8530412672901433, disc_loss = 0.0659749425095547
Trained batch 341 in epoch 5, gen_loss = 0.8538176377265774, disc_loss = 0.06583906069114717
Trained batch 342 in epoch 5, gen_loss = 0.8539432890213613, disc_loss = 0.06568579969292306
Trained batch 343 in epoch 5, gen_loss = 0.853482375311297, disc_loss = 0.0655740644338779
Trained batch 344 in epoch 5, gen_loss = 0.8539512817410455, disc_loss = 0.0654049370424363
Trained batch 345 in epoch 5, gen_loss = 0.8543404933345111, disc_loss = 0.06531957819428015
Trained batch 346 in epoch 5, gen_loss = 0.8549740486254953, disc_loss = 0.06516248730523914
Trained batch 347 in epoch 5, gen_loss = 0.8555502525006218, disc_loss = 0.06500617809053082
Trained batch 348 in epoch 5, gen_loss = 0.8556698707591497, disc_loss = 0.06485592745068379
Trained batch 349 in epoch 5, gen_loss = 0.8555533104283469, disc_loss = 0.06477330967118697
Trained batch 350 in epoch 5, gen_loss = 0.8559346953008928, disc_loss = 0.06466413555040616
Trained batch 351 in epoch 5, gen_loss = 0.856612776490775, disc_loss = 0.06453989794747693
Trained batch 352 in epoch 5, gen_loss = 0.8570066551986565, disc_loss = 0.06441464683927448
Trained batch 353 in epoch 5, gen_loss = 0.8562408554351936, disc_loss = 0.06443936598097832
Trained batch 354 in epoch 5, gen_loss = 0.8570773527655803, disc_loss = 0.06445136671938317
Trained batch 355 in epoch 5, gen_loss = 0.8570562748426802, disc_loss = 0.06432905170433433
Trained batch 356 in epoch 5, gen_loss = 0.856458372094718, disc_loss = 0.0643538184534414
Trained batch 357 in epoch 5, gen_loss = 0.8569393637460038, disc_loss = 0.0644285630879601
Trained batch 358 in epoch 5, gen_loss = 0.8571378787912034, disc_loss = 0.06436084071693107
Trained batch 359 in epoch 5, gen_loss = 0.8567182355456882, disc_loss = 0.06443093305117348
Trained batch 360 in epoch 5, gen_loss = 0.8578202367819577, disc_loss = 0.06440011126961859
Trained batch 361 in epoch 5, gen_loss = 0.8581768434021354, disc_loss = 0.06437075692640608
Trained batch 362 in epoch 5, gen_loss = 0.8582904222254583, disc_loss = 0.06429730469525148
Trained batch 363 in epoch 5, gen_loss = 0.8579581265266125, disc_loss = 0.06429375258688866
Trained batch 364 in epoch 5, gen_loss = 0.8585910702404911, disc_loss = 0.06432516140965362
Trained batch 365 in epoch 5, gen_loss = 0.8586847990588412, disc_loss = 0.06419302176434771
Trained batch 366 in epoch 5, gen_loss = 0.858264698644425, disc_loss = 0.06414682956473339
Trained batch 367 in epoch 5, gen_loss = 0.8584387940557107, disc_loss = 0.06407616771732295
Trained batch 368 in epoch 5, gen_loss = 0.8588677173061423, disc_loss = 0.06396658555415224
Trained batch 369 in epoch 5, gen_loss = 0.8584175098586727, disc_loss = 0.06407247099496827
Trained batch 370 in epoch 5, gen_loss = 0.8586599765762165, disc_loss = 0.0639884672855652
Trained batch 371 in epoch 5, gen_loss = 0.8592063710894636, disc_loss = 0.0638539252479771
Trained batch 372 in epoch 5, gen_loss = 0.8587936380273855, disc_loss = 0.06378937292289757
Trained batch 373 in epoch 5, gen_loss = 0.8584506728432395, disc_loss = 0.06366809841399804
Trained batch 374 in epoch 5, gen_loss = 0.8591481202443441, disc_loss = 0.06364600122347475
Trained batch 375 in epoch 5, gen_loss = 0.8584615962302431, disc_loss = 0.06364664043413792
Trained batch 376 in epoch 5, gen_loss = 0.8578354362151351, disc_loss = 0.06402115354225514
Trained batch 377 in epoch 5, gen_loss = 0.8576056517305828, disc_loss = 0.06397741952561158
Trained batch 378 in epoch 5, gen_loss = 0.8584608709277453, disc_loss = 0.06426445619230181
Trained batch 379 in epoch 5, gen_loss = 0.857745927885959, disc_loss = 0.06443117882835826
Trained batch 380 in epoch 5, gen_loss = 0.8575972534540132, disc_loss = 0.06439531203774916
Trained batch 381 in epoch 5, gen_loss = 0.857693867845685, disc_loss = 0.06426535146335306
Trained batch 382 in epoch 5, gen_loss = 0.857749363460989, disc_loss = 0.06430986209823591
Trained batch 383 in epoch 5, gen_loss = 0.8574082137395939, disc_loss = 0.06434419713696116
Trained batch 384 in epoch 5, gen_loss = 0.8575793904143495, disc_loss = 0.06424671916968443
Trained batch 385 in epoch 5, gen_loss = 0.8569392750300274, disc_loss = 0.06439004869711792
Trained batch 386 in epoch 5, gen_loss = 0.8574719663122211, disc_loss = 0.06433122364794523
Trained batch 387 in epoch 5, gen_loss = 0.8573025750745203, disc_loss = 0.06434049033295824
Trained batch 388 in epoch 5, gen_loss = 0.8571865515721181, disc_loss = 0.06435639361771911
Trained batch 389 in epoch 5, gen_loss = 0.8572009936357156, disc_loss = 0.06431129414659853
Trained batch 390 in epoch 5, gen_loss = 0.8570738846383741, disc_loss = 0.06419975933073388
Trained batch 391 in epoch 5, gen_loss = 0.8576138176176012, disc_loss = 0.06417592931705128
Trained batch 392 in epoch 5, gen_loss = 0.8571184025769318, disc_loss = 0.06413875174597285
Trained batch 393 in epoch 5, gen_loss = 0.8570384653994274, disc_loss = 0.06403600194179429
Trained batch 394 in epoch 5, gen_loss = 0.8575022650670402, disc_loss = 0.06394460456257191
Trained batch 395 in epoch 5, gen_loss = 0.8575324217478434, disc_loss = 0.06380840935485645
Trained batch 396 in epoch 5, gen_loss = 0.857394756237866, disc_loss = 0.06371371001263222
Trained batch 397 in epoch 5, gen_loss = 0.8570920411665836, disc_loss = 0.0637011672428636
Trained batch 398 in epoch 5, gen_loss = 0.8567770211618945, disc_loss = 0.06363058229208104
Trained batch 399 in epoch 5, gen_loss = 0.8575144082307815, disc_loss = 0.06379454866866581
Trained batch 400 in epoch 5, gen_loss = 0.8569495801319208, disc_loss = 0.06379897596007979
Trained batch 401 in epoch 5, gen_loss = 0.8571053053905715, disc_loss = 0.06369297090449848
Trained batch 402 in epoch 5, gen_loss = 0.8568750643552681, disc_loss = 0.06364013325704941
Trained batch 403 in epoch 5, gen_loss = 0.8568127825118528, disc_loss = 0.06357395136152569
Trained batch 404 in epoch 5, gen_loss = 0.8568893102951992, disc_loss = 0.06346725075402193
Trained batch 405 in epoch 5, gen_loss = 0.856810435872947, disc_loss = 0.06364730628909258
Trained batch 406 in epoch 5, gen_loss = 0.8566846206088616, disc_loss = 0.063555175890455
Trained batch 407 in epoch 5, gen_loss = 0.8568927896957771, disc_loss = 0.06347970195986587
Trained batch 408 in epoch 5, gen_loss = 0.8566546652894148, disc_loss = 0.0634445950723638
Trained batch 409 in epoch 5, gen_loss = 0.8559407647063092, disc_loss = 0.06374351059586354
Trained batch 410 in epoch 5, gen_loss = 0.8566615578611981, disc_loss = 0.06375545242329983
Trained batch 411 in epoch 5, gen_loss = 0.8569345919831285, disc_loss = 0.06366726830126988
Trained batch 412 in epoch 5, gen_loss = 0.8575156401779692, disc_loss = 0.0636168697219766
Trained batch 413 in epoch 5, gen_loss = 0.8578899796458258, disc_loss = 0.06351292393269278
Trained batch 414 in epoch 5, gen_loss = 0.857929600003254, disc_loss = 0.06339998915679304
Trained batch 415 in epoch 5, gen_loss = 0.8577816522178742, disc_loss = 0.06332973178471618
Trained batch 416 in epoch 5, gen_loss = 0.8584478817683615, disc_loss = 0.06345597993050942
Trained batch 417 in epoch 5, gen_loss = 0.8577866271922463, disc_loss = 0.0636309057053036
Trained batch 418 in epoch 5, gen_loss = 0.8582370306825297, disc_loss = 0.06353849057788319
Trained batch 419 in epoch 5, gen_loss = 0.8586321328367506, disc_loss = 0.06357606091381361
Trained batch 420 in epoch 5, gen_loss = 0.8583380637995704, disc_loss = 0.06364957210353428
Trained batch 421 in epoch 5, gen_loss = 0.8585471118230955, disc_loss = 0.06359483727024454
Trained batch 422 in epoch 5, gen_loss = 0.8581394361547826, disc_loss = 0.06362651283115184
Trained batch 423 in epoch 5, gen_loss = 0.8580161955840183, disc_loss = 0.06413056214564075
Trained batch 424 in epoch 5, gen_loss = 0.8575963363927953, disc_loss = 0.0642196463300463
Trained batch 425 in epoch 5, gen_loss = 0.8575341255172317, disc_loss = 0.06412793402428883
Trained batch 426 in epoch 5, gen_loss = 0.8577688591820853, disc_loss = 0.06418598070195429
Trained batch 427 in epoch 5, gen_loss = 0.8569991027361878, disc_loss = 0.06443812679303548
Trained batch 428 in epoch 5, gen_loss = 0.8565974384198933, disc_loss = 0.06448648507339937
Trained batch 429 in epoch 5, gen_loss = 0.85694755884104, disc_loss = 0.06460624576632887
Trained batch 430 in epoch 5, gen_loss = 0.8563543562269543, disc_loss = 0.0648541763076978
Trained batch 431 in epoch 5, gen_loss = 0.8561158490677675, disc_loss = 0.06483146527898498
Trained batch 432 in epoch 5, gen_loss = 0.8563140073219018, disc_loss = 0.06473335593951733
Trained batch 433 in epoch 5, gen_loss = 0.8559782281174638, disc_loss = 0.06510686999173998
Trained batch 434 in epoch 5, gen_loss = 0.8551455918399767, disc_loss = 0.06551737334343723
Trained batch 435 in epoch 5, gen_loss = 0.8554393650468336, disc_loss = 0.06542438519328252
Trained batch 436 in epoch 5, gen_loss = 0.8559942541460697, disc_loss = 0.06553415044848072
Trained batch 437 in epoch 5, gen_loss = 0.8556747048684995, disc_loss = 0.06559807628065722
Trained batch 438 in epoch 5, gen_loss = 0.8555538680124392, disc_loss = 0.06554314432504474
Trained batch 439 in epoch 5, gen_loss = 0.8552805425091223, disc_loss = 0.06548155654031275
Trained batch 440 in epoch 5, gen_loss = 0.8559286309207648, disc_loss = 0.06553985134016325
Trained batch 441 in epoch 5, gen_loss = 0.8562975168497854, disc_loss = 0.06546181072775965
Trained batch 442 in epoch 5, gen_loss = 0.8556180592315191, disc_loss = 0.06564635061816591
Trained batch 443 in epoch 5, gen_loss = 0.855692895414593, disc_loss = 0.06561374456961513
Trained batch 444 in epoch 5, gen_loss = 0.8554737847842527, disc_loss = 0.06562777962640262
Trained batch 445 in epoch 5, gen_loss = 0.855546928173758, disc_loss = 0.06550207180221619
Trained batch 446 in epoch 5, gen_loss = 0.8555335551833679, disc_loss = 0.0653888958577125
Trained batch 447 in epoch 5, gen_loss = 0.8554708835269723, disc_loss = 0.06531463142995822
Trained batch 448 in epoch 5, gen_loss = 0.8551874691765664, disc_loss = 0.06533963973623574
Trained batch 449 in epoch 5, gen_loss = 0.8555485945277744, disc_loss = 0.06523885120430754
Trained batch 450 in epoch 5, gen_loss = 0.8553032976825062, disc_loss = 0.06521482652821423
Trained batch 451 in epoch 5, gen_loss = 0.856035414127122, disc_loss = 0.06520143566978684
Trained batch 452 in epoch 5, gen_loss = 0.8566642495706908, disc_loss = 0.06509357267604199
Trained batch 453 in epoch 5, gen_loss = 0.8568092281335251, disc_loss = 0.06501951374191511
Trained batch 454 in epoch 5, gen_loss = 0.8564142685670119, disc_loss = 0.06510615598021464
Trained batch 455 in epoch 5, gen_loss = 0.8564226619507137, disc_loss = 0.06506223963847253
Trained batch 456 in epoch 5, gen_loss = 0.8567829356412658, disc_loss = 0.06502212131094326
Trained batch 457 in epoch 5, gen_loss = 0.856816158804831, disc_loss = 0.0649372121699431
Trained batch 458 in epoch 5, gen_loss = 0.8563462099738111, disc_loss = 0.06495317290303722
Trained batch 459 in epoch 5, gen_loss = 0.8566508252983508, disc_loss = 0.06487500373901718
Trained batch 460 in epoch 5, gen_loss = 0.8572120988446564, disc_loss = 0.06479808342200653
Trained batch 461 in epoch 5, gen_loss = 0.8574278350774344, disc_loss = 0.0646784398815639
Trained batch 462 in epoch 5, gen_loss = 0.8575108559806197, disc_loss = 0.06457711203772068
Trained batch 463 in epoch 5, gen_loss = 0.8569713064051908, disc_loss = 0.06460396474496269
Trained batch 464 in epoch 5, gen_loss = 0.857262421295207, disc_loss = 0.06462667891555415
Trained batch 465 in epoch 5, gen_loss = 0.8577205552819461, disc_loss = 0.06450860170035946
Trained batch 466 in epoch 5, gen_loss = 0.857579374083615, disc_loss = 0.06442294551889219
Trained batch 467 in epoch 5, gen_loss = 0.857174062066608, disc_loss = 0.06447791236225897
Trained batch 468 in epoch 5, gen_loss = 0.8570488082574629, disc_loss = 0.06443136571936293
Trained batch 469 in epoch 5, gen_loss = 0.8570192985078122, disc_loss = 0.06453904234209752
Trained batch 470 in epoch 5, gen_loss = 0.856674524629192, disc_loss = 0.0646181205325145
Trained batch 471 in epoch 5, gen_loss = 0.8567674160003662, disc_loss = 0.06459399810459433
Trained batch 472 in epoch 5, gen_loss = 0.8563456883138129, disc_loss = 0.064569294048044
Trained batch 473 in epoch 5, gen_loss = 0.8565601058901614, disc_loss = 0.06446330816846514
Trained batch 474 in epoch 5, gen_loss = 0.856727642887517, disc_loss = 0.06457079178506607
Trained batch 475 in epoch 5, gen_loss = 0.8565688065621031, disc_loss = 0.06453940515825134
Trained batch 476 in epoch 5, gen_loss = 0.8570479014634587, disc_loss = 0.06445117001236265
Trained batch 477 in epoch 5, gen_loss = 0.856494135687042, disc_loss = 0.0644521948785977
Trained batch 478 in epoch 5, gen_loss = 0.8565404958914118, disc_loss = 0.0643721628547228
Trained batch 479 in epoch 5, gen_loss = 0.8563990934441487, disc_loss = 0.06432201413845177
Trained batch 480 in epoch 5, gen_loss = 0.8563298814757698, disc_loss = 0.06423365558728018
Trained batch 481 in epoch 5, gen_loss = 0.8562450662440779, disc_loss = 0.06422202561255468
Trained batch 482 in epoch 5, gen_loss = 0.8563305929334021, disc_loss = 0.06412890988188039
Trained batch 483 in epoch 5, gen_loss = 0.8561933435930693, disc_loss = 0.0640742732644897
Trained batch 484 in epoch 5, gen_loss = 0.8558371665551491, disc_loss = 0.06411611081878703
Trained batch 485 in epoch 5, gen_loss = 0.856268138429265, disc_loss = 0.06429747112359806
Trained batch 486 in epoch 5, gen_loss = 0.8566187398634407, disc_loss = 0.06429502324084513
Trained batch 487 in epoch 5, gen_loss = 0.8559372101406582, disc_loss = 0.06462779734760797
Trained batch 488 in epoch 5, gen_loss = 0.856228043330959, disc_loss = 0.06454693044274894
Trained batch 489 in epoch 5, gen_loss = 0.856788260474497, disc_loss = 0.06451148361594854
Trained batch 490 in epoch 5, gen_loss = 0.8564045175515465, disc_loss = 0.06451370416573285
Trained batch 491 in epoch 5, gen_loss = 0.8557740989012447, disc_loss = 0.06460415474725963
Trained batch 492 in epoch 5, gen_loss = 0.8556541007382391, disc_loss = 0.06464078623147844
Trained batch 493 in epoch 5, gen_loss = 0.8553557543136813, disc_loss = 0.06466378020933312
Trained batch 494 in epoch 5, gen_loss = 0.8550784679374309, disc_loss = 0.06461032340491209
Trained batch 495 in epoch 5, gen_loss = 0.8556571506684826, disc_loss = 0.06465378172804541
Trained batch 496 in epoch 5, gen_loss = 0.8555619649484124, disc_loss = 0.06455862284984656
Trained batch 497 in epoch 5, gen_loss = 0.8549052304532154, disc_loss = 0.06461745272876777
Trained batch 498 in epoch 5, gen_loss = 0.854673603971401, disc_loss = 0.06455893697821813
Trained batch 499 in epoch 5, gen_loss = 0.8547317594289779, disc_loss = 0.06454572102148086
Trained batch 500 in epoch 5, gen_loss = 0.855022698700309, disc_loss = 0.06451958909113993
Trained batch 501 in epoch 5, gen_loss = 0.8553126168203544, disc_loss = 0.06442840334373078
Trained batch 502 in epoch 5, gen_loss = 0.854778553927632, disc_loss = 0.06463968904251992
Trained batch 503 in epoch 5, gen_loss = 0.8546713303242411, disc_loss = 0.064631115594354
Trained batch 504 in epoch 5, gen_loss = 0.8547866185112755, disc_loss = 0.06483240326091942
Trained batch 505 in epoch 5, gen_loss = 0.8548862021195559, disc_loss = 0.06476088966750963
Trained batch 506 in epoch 5, gen_loss = 0.8545128978215731, disc_loss = 0.06479138685610784
Trained batch 507 in epoch 5, gen_loss = 0.8542548161088013, disc_loss = 0.06480819362446695
Trained batch 508 in epoch 5, gen_loss = 0.8541012426256431, disc_loss = 0.06474295084425093
Trained batch 509 in epoch 5, gen_loss = 0.8547742857652552, disc_loss = 0.06483891103873211
Trained batch 510 in epoch 5, gen_loss = 0.8547447898849816, disc_loss = 0.0647451354349269
Trained batch 511 in epoch 5, gen_loss = 0.854145766585134, disc_loss = 0.06485842253187002
Trained batch 512 in epoch 5, gen_loss = 0.8542674867033261, disc_loss = 0.06489466902387798
Trained batch 513 in epoch 5, gen_loss = 0.8546603682672004, disc_loss = 0.06492400613381502
Trained batch 514 in epoch 5, gen_loss = 0.8543438375574871, disc_loss = 0.0648790859599209
Trained batch 515 in epoch 5, gen_loss = 0.8541708843883618, disc_loss = 0.06481963893950939
Trained batch 516 in epoch 5, gen_loss = 0.8539233506302308, disc_loss = 0.06479575530116084
Trained batch 517 in epoch 5, gen_loss = 0.8544742908026721, disc_loss = 0.064742525705967
Trained batch 518 in epoch 5, gen_loss = 0.8546648418283187, disc_loss = 0.06464444443867012
Trained batch 519 in epoch 5, gen_loss = 0.8545884978312712, disc_loss = 0.06458587366998052
Trained batch 520 in epoch 5, gen_loss = 0.8542491736430353, disc_loss = 0.0645520391359196
Trained batch 521 in epoch 5, gen_loss = 0.8549897324764866, disc_loss = 0.0645493593243561
Trained batch 522 in epoch 5, gen_loss = 0.8549077329626503, disc_loss = 0.06447654591346191
Trained batch 523 in epoch 5, gen_loss = 0.8550870324136647, disc_loss = 0.06437902361819278
Trained batch 524 in epoch 5, gen_loss = 0.8550556675593058, disc_loss = 0.06433656242188243
Trained batch 525 in epoch 5, gen_loss = 0.855671237403449, disc_loss = 0.06455783923723143
Trained batch 526 in epoch 5, gen_loss = 0.8556492149942966, disc_loss = 0.06449578044603825
Trained batch 527 in epoch 5, gen_loss = 0.855038721678835, disc_loss = 0.0645881115386587
Trained batch 528 in epoch 5, gen_loss = 0.8546215050161899, disc_loss = 0.06476971041851295
Trained batch 529 in epoch 5, gen_loss = 0.8544329649997208, disc_loss = 0.06475380448501487
Trained batch 530 in epoch 5, gen_loss = 0.8542403072511634, disc_loss = 0.06471009942809937
Trained batch 531 in epoch 5, gen_loss = 0.8539780463491168, disc_loss = 0.06467093128441392
Trained batch 532 in epoch 5, gen_loss = 0.8541977159525171, disc_loss = 0.06456886543708855
Trained batch 533 in epoch 5, gen_loss = 0.854122911722919, disc_loss = 0.06448922606362972
Trained batch 534 in epoch 5, gen_loss = 0.8538610242237554, disc_loss = 0.06450882666944482
Trained batch 535 in epoch 5, gen_loss = 0.8535579776585992, disc_loss = 0.06450656107922237
Trained batch 536 in epoch 5, gen_loss = 0.8536123623395099, disc_loss = 0.06448725241304026
Trained batch 537 in epoch 5, gen_loss = 0.8532613048323026, disc_loss = 0.0645265121741712
Trained batch 538 in epoch 5, gen_loss = 0.8533414532611896, disc_loss = 0.06454219552385923
Trained batch 539 in epoch 5, gen_loss = 0.8534533329583981, disc_loss = 0.06445925647686063
Trained batch 540 in epoch 5, gen_loss = 0.8533891720383974, disc_loss = 0.06440205976122546
Trained batch 541 in epoch 5, gen_loss = 0.8534219344163733, disc_loss = 0.06438125904419242
Trained batch 542 in epoch 5, gen_loss = 0.8528455507908956, disc_loss = 0.06443068945718651
Trained batch 543 in epoch 5, gen_loss = 0.8528243704315495, disc_loss = 0.06433672489519641
Trained batch 544 in epoch 5, gen_loss = 0.8533246121275315, disc_loss = 0.06449506995140003
Trained batch 545 in epoch 5, gen_loss = 0.8530000140378763, disc_loss = 0.06451042895819378
Trained batch 546 in epoch 5, gen_loss = 0.8532800600341295, disc_loss = 0.06445256069088032
Trained batch 547 in epoch 5, gen_loss = 0.8534651863096404, disc_loss = 0.06436111304966774
Trained batch 548 in epoch 5, gen_loss = 0.8532934729518786, disc_loss = 0.0643008213044095
Trained batch 549 in epoch 5, gen_loss = 0.8537164443189448, disc_loss = 0.06422036110423505
Trained batch 550 in epoch 5, gen_loss = 0.8534393745411979, disc_loss = 0.06416679999644034
Trained batch 551 in epoch 5, gen_loss = 0.853315665130166, disc_loss = 0.06411508556904164
Trained batch 552 in epoch 5, gen_loss = 0.8529556086438473, disc_loss = 0.06408571466470094
Trained batch 553 in epoch 5, gen_loss = 0.8532883501224999, disc_loss = 0.0639957848201684
Trained batch 554 in epoch 5, gen_loss = 0.8529883312749433, disc_loss = 0.06409616415883909
Trained batch 555 in epoch 5, gen_loss = 0.8530098554684962, disc_loss = 0.06411387956878774
Trained batch 556 in epoch 5, gen_loss = 0.8527121962293902, disc_loss = 0.06406846447785919
Trained batch 557 in epoch 5, gen_loss = 0.8527541528038654, disc_loss = 0.06400681097364207
Trained batch 558 in epoch 5, gen_loss = 0.8531415522205169, disc_loss = 0.06394367073187754
Trained batch 559 in epoch 5, gen_loss = 0.8530730013336454, disc_loss = 0.0638584243524487
Trained batch 560 in epoch 5, gen_loss = 0.8529340150947027, disc_loss = 0.06387140998889072
Trained batch 561 in epoch 5, gen_loss = 0.8525958825897068, disc_loss = 0.06385238110618102
Trained batch 562 in epoch 5, gen_loss = 0.8527733931321234, disc_loss = 0.06380000783851764
Trained batch 563 in epoch 5, gen_loss = 0.8525600385792712, disc_loss = 0.06376514683480883
Trained batch 564 in epoch 5, gen_loss = 0.8521052524051835, disc_loss = 0.063738998532526
Trained batch 565 in epoch 5, gen_loss = 0.8523291484205967, disc_loss = 0.0636685445021127
Trained batch 566 in epoch 5, gen_loss = 0.8524730621822296, disc_loss = 0.06362380529794927
Trained batch 567 in epoch 5, gen_loss = 0.8522793378838351, disc_loss = 0.06356601126108345
Trained batch 568 in epoch 5, gen_loss = 0.852771259045559, disc_loss = 0.06350147666782796
Trained batch 569 in epoch 5, gen_loss = 0.8524026568521533, disc_loss = 0.063583500450477
Trained batch 570 in epoch 5, gen_loss = 0.8529777868199057, disc_loss = 0.0635536121401851
Trained batch 571 in epoch 5, gen_loss = 0.8529025446493309, disc_loss = 0.06346585182391654
Trained batch 572 in epoch 5, gen_loss = 0.853139643685772, disc_loss = 0.06340701492782845
Trained batch 573 in epoch 5, gen_loss = 0.8532599719559274, disc_loss = 0.06335947512266087
Trained batch 574 in epoch 5, gen_loss = 0.8534241714684859, disc_loss = 0.06328376999610792
Trained batch 575 in epoch 5, gen_loss = 0.8530638684622116, disc_loss = 0.0633471943332956
Trained batch 576 in epoch 5, gen_loss = 0.8530302569399261, disc_loss = 0.06328652872327889
Trained batch 577 in epoch 5, gen_loss = 0.8531415631614342, disc_loss = 0.06326210954078315
Trained batch 578 in epoch 5, gen_loss = 0.8529826864883278, disc_loss = 0.06324936171819895
Trained batch 579 in epoch 5, gen_loss = 0.8526377126060684, disc_loss = 0.0632673418623042
Trained batch 580 in epoch 5, gen_loss = 0.8523166867008307, disc_loss = 0.06325576873977064
Trained batch 581 in epoch 5, gen_loss = 0.8532054897436162, disc_loss = 0.0634878366390288
Trained batch 582 in epoch 5, gen_loss = 0.8528312037780396, disc_loss = 0.06352620862191144
Trained batch 583 in epoch 5, gen_loss = 0.8527116753058891, disc_loss = 0.06347768958131719
Trained batch 584 in epoch 5, gen_loss = 0.852607189080654, disc_loss = 0.06343242859977305
Trained batch 585 in epoch 5, gen_loss = 0.8526251832779764, disc_loss = 0.06347186295331517
Trained batch 586 in epoch 5, gen_loss = 0.8524193345383444, disc_loss = 0.06344844877094767
Trained batch 587 in epoch 5, gen_loss = 0.852736657979537, disc_loss = 0.06338460270717715
Trained batch 588 in epoch 5, gen_loss = 0.8529222923345193, disc_loss = 0.06333200924386269
Trained batch 589 in epoch 5, gen_loss = 0.852688354758893, disc_loss = 0.06330802152012238
Trained batch 590 in epoch 5, gen_loss = 0.8525150226659177, disc_loss = 0.06334452756464658
Trained batch 591 in epoch 5, gen_loss = 0.8523406137687128, disc_loss = 0.06341428322815085
Trained batch 592 in epoch 5, gen_loss = 0.8524871120766484, disc_loss = 0.06336560921310047
Trained batch 593 in epoch 5, gen_loss = 0.8522319419416113, disc_loss = 0.06333498792136433
Trained batch 594 in epoch 5, gen_loss = 0.8521282678892632, disc_loss = 0.06326049814125946
Trained batch 595 in epoch 5, gen_loss = 0.8526129182553132, disc_loss = 0.06325520174312187
Trained batch 596 in epoch 5, gen_loss = 0.8531346532767342, disc_loss = 0.06318318786355394
Trained batch 597 in epoch 5, gen_loss = 0.8525929037344495, disc_loss = 0.0634597838415537
Trained batch 598 in epoch 5, gen_loss = 0.8528905835294962, disc_loss = 0.06354938179972848
Trained batch 599 in epoch 5, gen_loss = 0.8529434487223625, disc_loss = 0.06351794099978482
Trained batch 600 in epoch 5, gen_loss = 0.8531365466990606, disc_loss = 0.0634564020525286
Trained batch 601 in epoch 5, gen_loss = 0.8529461191540144, disc_loss = 0.0634968691123371
Trained batch 602 in epoch 5, gen_loss = 0.8532846965402315, disc_loss = 0.06346689503729516
Trained batch 603 in epoch 5, gen_loss = 0.8530675018860014, disc_loss = 0.06350789403478116
Trained batch 604 in epoch 5, gen_loss = 0.8533510667233428, disc_loss = 0.06356008776255752
Trained batch 605 in epoch 5, gen_loss = 0.8530482175720013, disc_loss = 0.06353836148138167
Trained batch 606 in epoch 5, gen_loss = 0.8527422896916234, disc_loss = 0.06359862439760929
Trained batch 607 in epoch 5, gen_loss = 0.852690636621494, disc_loss = 0.0635971798075939
Trained batch 608 in epoch 5, gen_loss = 0.8525370025673915, disc_loss = 0.06359843785487641
Trained batch 609 in epoch 5, gen_loss = 0.8522255945401114, disc_loss = 0.06359735429821323
Trained batch 610 in epoch 5, gen_loss = 0.8521919558754529, disc_loss = 0.06361428629256383
Trained batch 611 in epoch 5, gen_loss = 0.8522362370117038, disc_loss = 0.0635451673662436
Trained batch 612 in epoch 5, gen_loss = 0.8522082691674909, disc_loss = 0.06349004789819215
Trained batch 613 in epoch 5, gen_loss = 0.8521919475704529, disc_loss = 0.06341788443245285
Trained batch 614 in epoch 5, gen_loss = 0.8523866833710089, disc_loss = 0.06339700701684366
Trained batch 615 in epoch 5, gen_loss = 0.8523801139422825, disc_loss = 0.06332120341898922
Trained batch 616 in epoch 5, gen_loss = 0.8523386570004629, disc_loss = 0.0632616916189885
Trained batch 617 in epoch 5, gen_loss = 0.8522901928540573, disc_loss = 0.06320028816813959
Trained batch 618 in epoch 5, gen_loss = 0.8524900951177508, disc_loss = 0.06313010220534751
Trained batch 619 in epoch 5, gen_loss = 0.8525799644570197, disc_loss = 0.06309968825775168
Trained batch 620 in epoch 5, gen_loss = 0.8523073366298768, disc_loss = 0.06306830345129598
Trained batch 621 in epoch 5, gen_loss = 0.8525178410424297, disc_loss = 0.06299355979394947
Trained batch 622 in epoch 5, gen_loss = 0.8527398655732218, disc_loss = 0.06299846276063861
Trained batch 623 in epoch 5, gen_loss = 0.8527821502051293, disc_loss = 0.0629310571455743
Trained batch 624 in epoch 5, gen_loss = 0.8527962721824646, disc_loss = 0.06286986554786562
Trained batch 625 in epoch 5, gen_loss = 0.8529293724713615, disc_loss = 0.06284941318623435
Trained batch 626 in epoch 5, gen_loss = 0.8527789792755954, disc_loss = 0.06281662462546565
Trained batch 627 in epoch 5, gen_loss = 0.8528335694294826, disc_loss = 0.06277170128880104
Trained batch 628 in epoch 5, gen_loss = 0.8529919251349469, disc_loss = 0.06276136427593605
Trained batch 629 in epoch 5, gen_loss = 0.8529785248968337, disc_loss = 0.06272940134762653
Trained batch 630 in epoch 5, gen_loss = 0.8530596392657224, disc_loss = 0.06264750045693218
Trained batch 631 in epoch 5, gen_loss = 0.8529115285300002, disc_loss = 0.06261420682812392
Trained batch 632 in epoch 5, gen_loss = 0.8537977532752882, disc_loss = 0.06267784848017692
Trained batch 633 in epoch 5, gen_loss = 0.8541861276145237, disc_loss = 0.06262761479234823
Trained batch 634 in epoch 5, gen_loss = 0.8539492688779756, disc_loss = 0.06287443675614131
Trained batch 635 in epoch 5, gen_loss = 0.8542020267473077, disc_loss = 0.06282247671104804
Trained batch 636 in epoch 5, gen_loss = 0.8550296990987457, disc_loss = 0.06282412133499793
Trained batch 637 in epoch 5, gen_loss = 0.855496446634161, disc_loss = 0.0627875809687654
Trained batch 638 in epoch 5, gen_loss = 0.8551070333833053, disc_loss = 0.06294030210160663
Trained batch 639 in epoch 5, gen_loss = 0.8553612370043993, disc_loss = 0.06288700886871083
Trained batch 640 in epoch 5, gen_loss = 0.8557285159686798, disc_loss = 0.06281317623372824
Trained batch 641 in epoch 5, gen_loss = 0.8558388070154042, disc_loss = 0.06274658599592792
Trained batch 642 in epoch 5, gen_loss = 0.8561799034916594, disc_loss = 0.06268061023903648
Trained batch 643 in epoch 5, gen_loss = 0.8561843634577271, disc_loss = 0.06259947905233072
Trained batch 644 in epoch 5, gen_loss = 0.8556426090787548, disc_loss = 0.06265855027189435
Trained batch 645 in epoch 5, gen_loss = 0.8554854294279411, disc_loss = 0.0626310731850899
Trained batch 646 in epoch 5, gen_loss = 0.8557258500750687, disc_loss = 0.06264589968680115
Trained batch 647 in epoch 5, gen_loss = 0.8560926422108839, disc_loss = 0.0625714060230997
Trained batch 648 in epoch 5, gen_loss = 0.8561740670071912, disc_loss = 0.06250742177489015
Trained batch 649 in epoch 5, gen_loss = 0.8564486425656539, disc_loss = 0.062463240134171566
Trained batch 650 in epoch 5, gen_loss = 0.8563946971695544, disc_loss = 0.06238729003087236
Trained batch 651 in epoch 5, gen_loss = 0.8564352852983709, disc_loss = 0.062330304967108084
Trained batch 652 in epoch 5, gen_loss = 0.8566377853909094, disc_loss = 0.06225068203799689
Trained batch 653 in epoch 5, gen_loss = 0.8567908445447228, disc_loss = 0.06222391940314403
Trained batch 654 in epoch 5, gen_loss = 0.8561927759465371, disc_loss = 0.062440355139862715
Trained batch 655 in epoch 5, gen_loss = 0.856031208003803, disc_loss = 0.062476243375851656
Trained batch 656 in epoch 5, gen_loss = 0.8561824582392403, disc_loss = 0.06248435710983484
Trained batch 657 in epoch 5, gen_loss = 0.8562034452305739, disc_loss = 0.062421792940488566
Trained batch 658 in epoch 5, gen_loss = 0.8557327188472285, disc_loss = 0.06251566195493063
Trained batch 659 in epoch 5, gen_loss = 0.8557383039232457, disc_loss = 0.06251495860756912
Trained batch 660 in epoch 5, gen_loss = 0.8561622195182518, disc_loss = 0.062488187649026625
Trained batch 661 in epoch 5, gen_loss = 0.8558735147433699, disc_loss = 0.062493345413914124
Trained batch 662 in epoch 5, gen_loss = 0.8558225227606961, disc_loss = 0.062466544160256966
Trained batch 663 in epoch 5, gen_loss = 0.8562254191611904, disc_loss = 0.06261095995748281
Trained batch 664 in epoch 5, gen_loss = 0.8557070653689535, disc_loss = 0.06293499611836291
Trained batch 665 in epoch 5, gen_loss = 0.8552949503287897, disc_loss = 0.0629608193587221
Trained batch 666 in epoch 5, gen_loss = 0.8555837379492026, disc_loss = 0.06305656331693237
Trained batch 667 in epoch 5, gen_loss = 0.855406899250553, disc_loss = 0.06302761019160134
Trained batch 668 in epoch 5, gen_loss = 0.8551137856749319, disc_loss = 0.06300204585588945
Trained batch 669 in epoch 5, gen_loss = 0.8551133593961374, disc_loss = 0.06296153554289755
Trained batch 670 in epoch 5, gen_loss = 0.8552089508084355, disc_loss = 0.06297153361966132
Trained batch 671 in epoch 5, gen_loss = 0.8550483376408616, disc_loss = 0.06290441964977488
Trained batch 672 in epoch 5, gen_loss = 0.85474845368476, disc_loss = 0.0629183833963372
Trained batch 673 in epoch 5, gen_loss = 0.8550164547889806, disc_loss = 0.06287889520344753
Trained batch 674 in epoch 5, gen_loss = 0.8552604541513655, disc_loss = 0.06281942546988527
Trained batch 675 in epoch 5, gen_loss = 0.8554545268416405, disc_loss = 0.06275684704808464
Trained batch 676 in epoch 5, gen_loss = 0.8554796588385651, disc_loss = 0.06268745113612652
Trained batch 677 in epoch 5, gen_loss = 0.8554416054909209, disc_loss = 0.06267686503400867
Trained batch 678 in epoch 5, gen_loss = 0.8558474784834922, disc_loss = 0.06262215632953529
Trained batch 679 in epoch 5, gen_loss = 0.8554750600720153, disc_loss = 0.06263434014844653
Trained batch 680 in epoch 5, gen_loss = 0.8556982051696022, disc_loss = 0.06269872374627493
Trained batch 681 in epoch 5, gen_loss = 0.8552901720808398, disc_loss = 0.06275079958755359
Trained batch 682 in epoch 5, gen_loss = 0.8552602592795695, disc_loss = 0.06270968185405017
Trained batch 683 in epoch 5, gen_loss = 0.8552067151282265, disc_loss = 0.06269110664139824
Trained batch 684 in epoch 5, gen_loss = 0.8553248341501194, disc_loss = 0.06264106587296094
Trained batch 685 in epoch 5, gen_loss = 0.8556177192544103, disc_loss = 0.0625930693979394
Trained batch 686 in epoch 5, gen_loss = 0.8552777336414203, disc_loss = 0.0627138194332531
Trained batch 687 in epoch 5, gen_loss = 0.8556426030172165, disc_loss = 0.06270354762362035
Trained batch 688 in epoch 5, gen_loss = 0.8559060350644399, disc_loss = 0.06268963806874542
Trained batch 689 in epoch 5, gen_loss = 0.8556502718424451, disc_loss = 0.06265106920652308
Trained batch 690 in epoch 5, gen_loss = 0.8554287123697366, disc_loss = 0.0626283392947647
Trained batch 691 in epoch 5, gen_loss = 0.8554283428312726, disc_loss = 0.06256375321916526
Trained batch 692 in epoch 5, gen_loss = 0.855687712135081, disc_loss = 0.06253254873823229
Trained batch 693 in epoch 5, gen_loss = 0.8555838764143265, disc_loss = 0.062494572768020056
Trained batch 694 in epoch 5, gen_loss = 0.8557046179719966, disc_loss = 0.06243281760085508
Trained batch 695 in epoch 5, gen_loss = 0.8557997792531019, disc_loss = 0.06236964869968614
Trained batch 696 in epoch 5, gen_loss = 0.8555600825734597, disc_loss = 0.062392907535825645
Trained batch 697 in epoch 5, gen_loss = 0.8559046534122232, disc_loss = 0.06249426719519099
Trained batch 698 in epoch 5, gen_loss = 0.8559118626540652, disc_loss = 0.06243369462453522
Trained batch 699 in epoch 5, gen_loss = 0.8556576457619667, disc_loss = 0.062427051387328125
Trained batch 700 in epoch 5, gen_loss = 0.8560686449436591, disc_loss = 0.06241591201468069
Trained batch 701 in epoch 5, gen_loss = 0.8560755983462022, disc_loss = 0.06234372686395724
Trained batch 702 in epoch 5, gen_loss = 0.8559924072001771, disc_loss = 0.062282442066892665
Trained batch 703 in epoch 5, gen_loss = 0.8562048729085787, disc_loss = 0.06220809919614112
Trained batch 704 in epoch 5, gen_loss = 0.8563471293195765, disc_loss = 0.062144062393972424
Trained batch 705 in epoch 5, gen_loss = 0.8567474850429692, disc_loss = 0.06208140074101306
Trained batch 706 in epoch 5, gen_loss = 0.8563826119967195, disc_loss = 0.062125527099054174
Trained batch 707 in epoch 5, gen_loss = 0.8565722668995965, disc_loss = 0.06211568039281578
Trained batch 708 in epoch 5, gen_loss = 0.8565451167786575, disc_loss = 0.06205023578808174
Trained batch 709 in epoch 5, gen_loss = 0.8564860416550032, disc_loss = 0.061984491511575986
Trained batch 710 in epoch 5, gen_loss = 0.8567218043213991, disc_loss = 0.0619674074285403
Trained batch 711 in epoch 5, gen_loss = 0.8563254131946001, disc_loss = 0.062167832225671016
Trained batch 712 in epoch 5, gen_loss = 0.8567692749881477, disc_loss = 0.062187465349915025
Trained batch 713 in epoch 5, gen_loss = 0.856534005672324, disc_loss = 0.06215393110778423
Trained batch 714 in epoch 5, gen_loss = 0.8563258183169198, disc_loss = 0.062100218401218835
Trained batch 715 in epoch 5, gen_loss = 0.8565675801488274, disc_loss = 0.06202618637598281
Trained batch 716 in epoch 5, gen_loss = 0.8567297824839003, disc_loss = 0.06196184287294538
Trained batch 717 in epoch 5, gen_loss = 0.8567741903837013, disc_loss = 0.061908088425371516
Trained batch 718 in epoch 5, gen_loss = 0.8566705610639362, disc_loss = 0.06187754855795617
Trained batch 719 in epoch 5, gen_loss = 0.8567319673382574, disc_loss = 0.061918521266973885
Trained batch 720 in epoch 5, gen_loss = 0.8568083787344696, disc_loss = 0.0618534283744799
Trained batch 721 in epoch 5, gen_loss = 0.8566971524022623, disc_loss = 0.06180053153668641
Trained batch 722 in epoch 5, gen_loss = 0.8563100390167158, disc_loss = 0.061838356341991474
Trained batch 723 in epoch 5, gen_loss = 0.8564569224392512, disc_loss = 0.06180998930921109
Trained batch 724 in epoch 5, gen_loss = 0.8566295102958021, disc_loss = 0.061790253529646275
Trained batch 725 in epoch 5, gen_loss = 0.8567167893667852, disc_loss = 0.06173704219430418
Trained batch 726 in epoch 5, gen_loss = 0.8563157147439671, disc_loss = 0.06193477804599614
Trained batch 727 in epoch 5, gen_loss = 0.8563044825671139, disc_loss = 0.06191486021654762
Trained batch 728 in epoch 5, gen_loss = 0.8564435454144236, disc_loss = 0.06189227994053595
Trained batch 729 in epoch 5, gen_loss = 0.8566797087862067, disc_loss = 0.061818123383651655
Trained batch 730 in epoch 5, gen_loss = 0.8564346555401298, disc_loss = 0.06179481098000292
Trained batch 731 in epoch 5, gen_loss = 0.8564663109639303, disc_loss = 0.06173245030864971
Trained batch 732 in epoch 5, gen_loss = 0.8564870253022339, disc_loss = 0.061684947976103056
Trained batch 733 in epoch 5, gen_loss = 0.8564316918236033, disc_loss = 0.06162229451041273
Trained batch 734 in epoch 5, gen_loss = 0.8565349084584891, disc_loss = 0.06158508297727525
Trained batch 735 in epoch 5, gen_loss = 0.8568305443243488, disc_loss = 0.061606930803543
Trained batch 736 in epoch 5, gen_loss = 0.8567936500102241, disc_loss = 0.061639716206156374
Trained batch 737 in epoch 5, gen_loss = 0.856819924582957, disc_loss = 0.061596671605815854
Trained batch 738 in epoch 5, gen_loss = 0.8569989387092152, disc_loss = 0.06154276901120081
Trained batch 739 in epoch 5, gen_loss = 0.8576995841957428, disc_loss = 0.06156301618918676
Trained batch 740 in epoch 5, gen_loss = 0.857483890334926, disc_loss = 0.06154545928651967
Trained batch 741 in epoch 5, gen_loss = 0.8575130923980009, disc_loss = 0.06148328265298228
Trained batch 742 in epoch 5, gen_loss = 0.857642251301261, disc_loss = 0.06142180144954799
Trained batch 743 in epoch 5, gen_loss = 0.8577390864731804, disc_loss = 0.061359991609264086
Trained batch 744 in epoch 5, gen_loss = 0.8577710651311299, disc_loss = 0.06129408435170983
Trained batch 745 in epoch 5, gen_loss = 0.8575485903599946, disc_loss = 0.061284255595308486
Trained batch 746 in epoch 5, gen_loss = 0.8577378712584535, disc_loss = 0.06128300146861787
Trained batch 747 in epoch 5, gen_loss = 0.857626805848935, disc_loss = 0.06121397188199774
Trained batch 748 in epoch 5, gen_loss = 0.8572154244450287, disc_loss = 0.061299860820010085
Trained batch 749 in epoch 5, gen_loss = 0.8575646062294642, disc_loss = 0.06135103484429419
Trained batch 750 in epoch 5, gen_loss = 0.8575701250455351, disc_loss = 0.061323485558557406
Trained batch 751 in epoch 5, gen_loss = 0.8574380853629493, disc_loss = 0.0613432179367358
Trained batch 752 in epoch 5, gen_loss = 0.8573010405142152, disc_loss = 0.061333237301835306
Trained batch 753 in epoch 5, gen_loss = 0.8574503632138831, disc_loss = 0.06134034072132954
Trained batch 754 in epoch 5, gen_loss = 0.8574628260356701, disc_loss = 0.06127863565755897
Trained batch 755 in epoch 5, gen_loss = 0.8575012876637398, disc_loss = 0.06124319038514008
Trained batch 756 in epoch 5, gen_loss = 0.8575987541455101, disc_loss = 0.061212946353861604
Trained batch 757 in epoch 5, gen_loss = 0.8572811392728131, disc_loss = 0.06124674176888192
Trained batch 758 in epoch 5, gen_loss = 0.8571659546046074, disc_loss = 0.061236695504878626
Trained batch 759 in epoch 5, gen_loss = 0.8578752796508764, disc_loss = 0.06122723976088884
Trained batch 760 in epoch 5, gen_loss = 0.857937984922399, disc_loss = 0.061185784691163925
Trained batch 761 in epoch 5, gen_loss = 0.857909488591935, disc_loss = 0.06114229807212186
Trained batch 762 in epoch 5, gen_loss = 0.8573773620091134, disc_loss = 0.06120503900772837
Trained batch 763 in epoch 5, gen_loss = 0.8575018021370728, disc_loss = 0.06120214030982839
Trained batch 764 in epoch 5, gen_loss = 0.8575130283053405, disc_loss = 0.06124455529429457
Trained batch 765 in epoch 5, gen_loss = 0.8572200299009641, disc_loss = 0.06128148070181533
Trained batch 766 in epoch 5, gen_loss = 0.8572659429934998, disc_loss = 0.06124147677531823
Trained batch 767 in epoch 5, gen_loss = 0.8569066690979525, disc_loss = 0.0612934149873278
Trained batch 768 in epoch 5, gen_loss = 0.8568851952822528, disc_loss = 0.061445205608656524
Trained batch 769 in epoch 5, gen_loss = 0.8565799484392265, disc_loss = 0.06149432745205795
Trained batch 770 in epoch 5, gen_loss = 0.8563972456832495, disc_loss = 0.061477370830144054
Trained batch 771 in epoch 5, gen_loss = 0.856675389864593, disc_loss = 0.0614941999638318
Trained batch 772 in epoch 5, gen_loss = 0.856744951410713, disc_loss = 0.06144188555502086
Trained batch 773 in epoch 5, gen_loss = 0.8566697622223418, disc_loss = 0.06142102118800526
Trained batch 774 in epoch 5, gen_loss = 0.8565270407353678, disc_loss = 0.061380124331842506
Trained batch 775 in epoch 5, gen_loss = 0.8569951839745045, disc_loss = 0.061439106096249536
Trained batch 776 in epoch 5, gen_loss = 0.8566460164894315, disc_loss = 0.06141753181122349
Trained batch 777 in epoch 5, gen_loss = 0.8569286375624968, disc_loss = 0.06135662833939769
Trained batch 778 in epoch 5, gen_loss = 0.8568957690938599, disc_loss = 0.06131105155735462
Trained batch 779 in epoch 5, gen_loss = 0.856912056184732, disc_loss = 0.06125027849398649
Trained batch 780 in epoch 5, gen_loss = 0.8569905534672829, disc_loss = 0.06124637679169467
Trained batch 781 in epoch 5, gen_loss = 0.8568892966374717, disc_loss = 0.06126091610866568
Trained batch 782 in epoch 5, gen_loss = 0.8567286150893946, disc_loss = 0.06127209629028522
Trained batch 783 in epoch 5, gen_loss = 0.8570834893581211, disc_loss = 0.06129390698541621
Trained batch 784 in epoch 5, gen_loss = 0.8569645645891785, disc_loss = 0.06125529577101397
Trained batch 785 in epoch 5, gen_loss = 0.8568705248696203, disc_loss = 0.06120414391773784
Trained batch 786 in epoch 5, gen_loss = 0.8568810016636321, disc_loss = 0.06115385098737845
Trained batch 787 in epoch 5, gen_loss = 0.8568800236594859, disc_loss = 0.061105897250055774
Trained batch 788 in epoch 5, gen_loss = 0.8571880162517683, disc_loss = 0.06108601546830985
Trained batch 789 in epoch 5, gen_loss = 0.857291799972329, disc_loss = 0.06104134240753571
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.763542890548706, disc_loss = 0.033059630542993546
Trained batch 1 in epoch 6, gen_loss = 0.8697264194488525, disc_loss = 0.02961578220129013
Trained batch 2 in epoch 6, gen_loss = 0.9370193878809611, disc_loss = 0.030230216681957245
Trained batch 3 in epoch 6, gen_loss = 0.8652091920375824, disc_loss = 0.032191626727581024
Trained batch 4 in epoch 6, gen_loss = 0.8503630876541137, disc_loss = 0.03921727240085602
Trained batch 5 in epoch 6, gen_loss = 0.8465847174326578, disc_loss = 0.037792276901503406
Trained batch 6 in epoch 6, gen_loss = 0.8801893506731305, disc_loss = 0.051410263404250145
Trained batch 7 in epoch 6, gen_loss = 0.8382942453026772, disc_loss = 0.06543721933849156
Trained batch 8 in epoch 6, gen_loss = 0.8496786223517524, disc_loss = 0.061707250153024994
Trained batch 9 in epoch 6, gen_loss = 0.8528356790542603, disc_loss = 0.05794640723615885
Trained batch 10 in epoch 6, gen_loss = 0.8594861030578613, disc_loss = 0.054901522330262444
Trained batch 11 in epoch 6, gen_loss = 0.8516919811566671, disc_loss = 0.05564892633507649
Trained batch 12 in epoch 6, gen_loss = 0.851746889261099, disc_loss = 0.059655092943173185
Trained batch 13 in epoch 6, gen_loss = 0.8559605692114148, disc_loss = 0.05661514348217419
Trained batch 14 in epoch 6, gen_loss = 0.8451185663541158, disc_loss = 0.055810347696145374
Trained batch 15 in epoch 6, gen_loss = 0.8597567565739155, disc_loss = 0.053661084501072764
Trained batch 16 in epoch 6, gen_loss = 0.8783843973103691, disc_loss = 0.05413518166717361
Trained batch 17 in epoch 6, gen_loss = 0.8595295250415802, disc_loss = 0.06047606902817885
Trained batch 18 in epoch 6, gen_loss = 0.8710634363325018, disc_loss = 0.05956865592222465
Trained batch 19 in epoch 6, gen_loss = 0.8787104159593582, disc_loss = 0.059017600119113924
Trained batch 20 in epoch 6, gen_loss = 0.8706423668634324, disc_loss = 0.058082490804649535
Trained batch 21 in epoch 6, gen_loss = 0.8606620810248635, disc_loss = 0.058189559558575805
Trained batch 22 in epoch 6, gen_loss = 0.8607671675474747, disc_loss = 0.05811595398446788
Trained batch 23 in epoch 6, gen_loss = 0.8616141850749651, disc_loss = 0.05631828773766756
Trained batch 24 in epoch 6, gen_loss = 0.8630302548408508, disc_loss = 0.05438785757869482
Trained batch 25 in epoch 6, gen_loss = 0.858843553524751, disc_loss = 0.05407064318513641
Trained batch 26 in epoch 6, gen_loss = 0.8593252036306593, disc_loss = 0.05516843356330086
Trained batch 27 in epoch 6, gen_loss = 0.8571231045893261, disc_loss = 0.05429358604098005
Trained batch 28 in epoch 6, gen_loss = 0.8604127641381889, disc_loss = 0.05291014315624689
Trained batch 29 in epoch 6, gen_loss = 0.8591078539689382, disc_loss = 0.05362226587409775
Trained batch 30 in epoch 6, gen_loss = 0.8569588795784981, disc_loss = 0.053817116895750645
Trained batch 31 in epoch 6, gen_loss = 0.8557980116456747, disc_loss = 0.05432877244311385
Trained batch 32 in epoch 6, gen_loss = 0.8580941702380325, disc_loss = 0.05410434031915484
Trained batch 33 in epoch 6, gen_loss = 0.858569076832603, disc_loss = 0.05310318528619759
Trained batch 34 in epoch 6, gen_loss = 0.8523820979254586, disc_loss = 0.05418631751090288
Trained batch 35 in epoch 6, gen_loss = 0.8625667326980166, disc_loss = 0.05348917870368394
Trained batch 36 in epoch 6, gen_loss = 0.8639945919449264, disc_loss = 0.05243125051964779
Trained batch 37 in epoch 6, gen_loss = 0.8706456077726263, disc_loss = 0.052518922222876234
Trained batch 38 in epoch 6, gen_loss = 0.865274482812637, disc_loss = 0.0520671781582328
Trained batch 39 in epoch 6, gen_loss = 0.8618667021393775, disc_loss = 0.0537311946740374
Trained batch 40 in epoch 6, gen_loss = 0.8706544797594954, disc_loss = 0.054714398208733014
Trained batch 41 in epoch 6, gen_loss = 0.8815444012482961, disc_loss = 0.0565104521589265
Trained batch 42 in epoch 6, gen_loss = 0.8849538134974103, disc_loss = 0.056153860268031444
Trained batch 43 in epoch 6, gen_loss = 0.879838996312835, disc_loss = 0.05878351059403609
Trained batch 44 in epoch 6, gen_loss = 0.8816959314876133, disc_loss = 0.05789191306879123
Trained batch 45 in epoch 6, gen_loss = 0.8871938962003459, disc_loss = 0.05696110060924421
Trained batch 46 in epoch 6, gen_loss = 0.8874637750869102, disc_loss = 0.05629036870804873
Trained batch 47 in epoch 6, gen_loss = 0.888324656834205, disc_loss = 0.055361445081265025
Trained batch 48 in epoch 6, gen_loss = 0.8840962453764312, disc_loss = 0.05557946284890783
Trained batch 49 in epoch 6, gen_loss = 0.891103982925415, disc_loss = 0.05535848246887326
Trained batch 50 in epoch 6, gen_loss = 0.8904796675139782, disc_loss = 0.05498117195697976
Trained batch 51 in epoch 6, gen_loss = 0.8912882128587136, disc_loss = 0.05433863274251612
Trained batch 52 in epoch 6, gen_loss = 0.8931176583721953, disc_loss = 0.053655863669261616
Trained batch 53 in epoch 6, gen_loss = 0.891861108718095, disc_loss = 0.05341888634763934
Trained batch 54 in epoch 6, gen_loss = 0.8891251769932833, disc_loss = 0.05342374825003472
Trained batch 55 in epoch 6, gen_loss = 0.8928651203002248, disc_loss = 0.0527807999169454
Trained batch 56 in epoch 6, gen_loss = 0.8967718063739308, disc_loss = 0.05258320352029905
Trained batch 57 in epoch 6, gen_loss = 0.8927724042843128, disc_loss = 0.05351735421873886
Trained batch 58 in epoch 6, gen_loss = 0.8922027753571332, disc_loss = 0.05298076180141356
Trained batch 59 in epoch 6, gen_loss = 0.8943507611751557, disc_loss = 0.05292135546915233
Trained batch 60 in epoch 6, gen_loss = 0.8936000818111858, disc_loss = 0.0522460175494923
Trained batch 61 in epoch 6, gen_loss = 0.8956056516016683, disc_loss = 0.05163173255841098
Trained batch 62 in epoch 6, gen_loss = 0.8950055279428997, disc_loss = 0.050957151659069555
Trained batch 63 in epoch 6, gen_loss = 0.8967284737154841, disc_loss = 0.05034472058468964
Trained batch 64 in epoch 6, gen_loss = 0.8968539467224708, disc_loss = 0.0498053223037949
Trained batch 65 in epoch 6, gen_loss = 0.9007377489046617, disc_loss = 0.04923593211975513
Trained batch 66 in epoch 6, gen_loss = 0.9004929910844831, disc_loss = 0.048671443348945076
Trained batch 67 in epoch 6, gen_loss = 0.8976691707092173, disc_loss = 0.04835034057717113
Trained batch 68 in epoch 6, gen_loss = 0.8969619783802308, disc_loss = 0.047779378494706704
Trained batch 69 in epoch 6, gen_loss = 0.8952305597918374, disc_loss = 0.04726033019168036
Trained batch 70 in epoch 6, gen_loss = 0.8990641823956664, disc_loss = 0.04693372959507183
Trained batch 71 in epoch 6, gen_loss = 0.8987747439079814, disc_loss = 0.04659067153827184
Trained batch 72 in epoch 6, gen_loss = 0.8959627763865745, disc_loss = 0.046781547750308086
Trained batch 73 in epoch 6, gen_loss = 0.8969453420187976, disc_loss = 0.04638766827112114
Trained batch 74 in epoch 6, gen_loss = 0.8961914944648742, disc_loss = 0.0460130100697279
Trained batch 75 in epoch 6, gen_loss = 0.896285388030504, disc_loss = 0.04582972184901959
Trained batch 76 in epoch 6, gen_loss = 0.8961729298938405, disc_loss = 0.046265891789422406
Trained batch 77 in epoch 6, gen_loss = 0.8921958001760336, disc_loss = 0.04748880688865215
Trained batch 78 in epoch 6, gen_loss = 0.8930469955070109, disc_loss = 0.04752553888608383
Trained batch 79 in epoch 6, gen_loss = 0.8963330499827862, disc_loss = 0.047290182881988586
Trained batch 80 in epoch 6, gen_loss = 0.8947475501048712, disc_loss = 0.04711353712151816
Trained batch 81 in epoch 6, gen_loss = 0.8944782978150903, disc_loss = 0.04667528044068959
Trained batch 82 in epoch 6, gen_loss = 0.891927383750318, disc_loss = 0.04675203124173435
Trained batch 83 in epoch 6, gen_loss = 0.8960141731160027, disc_loss = 0.04883866644065295
Trained batch 84 in epoch 6, gen_loss = 0.8920215487480163, disc_loss = 0.05002082211568075
Trained batch 85 in epoch 6, gen_loss = 0.8901694236799728, disc_loss = 0.05002650863296071
Trained batch 86 in epoch 6, gen_loss = 0.8898875336537416, disc_loss = 0.05141970722925389
Trained batch 87 in epoch 6, gen_loss = 0.8878577697006139, disc_loss = 0.05165673472749239
Trained batch 88 in epoch 6, gen_loss = 0.8862569526340185, disc_loss = 0.05160616892860847
Trained batch 89 in epoch 6, gen_loss = 0.8846696496009827, disc_loss = 0.05154478026347028
Trained batch 90 in epoch 6, gen_loss = 0.8847193796556074, disc_loss = 0.052046065781633934
Trained batch 91 in epoch 6, gen_loss = 0.8830286925253661, disc_loss = 0.05203782983691148
Trained batch 92 in epoch 6, gen_loss = 0.880989428489439, disc_loss = 0.051785238527803014
Trained batch 93 in epoch 6, gen_loss = 0.8804564590149737, disc_loss = 0.05214934736648773
Trained batch 94 in epoch 6, gen_loss = 0.8778306710092645, disc_loss = 0.05227690366537947
Trained batch 95 in epoch 6, gen_loss = 0.879886315514644, disc_loss = 0.05206084557964156
Trained batch 96 in epoch 6, gen_loss = 0.8791882979501154, disc_loss = 0.05195787533656838
Trained batch 97 in epoch 6, gen_loss = 0.8763562355722699, disc_loss = 0.05287691570666372
Trained batch 98 in epoch 6, gen_loss = 0.8771779404746162, disc_loss = 0.052915586779514946
Trained batch 99 in epoch 6, gen_loss = 0.8793216454982757, disc_loss = 0.05266329564154148
Trained batch 100 in epoch 6, gen_loss = 0.8782020040077738, disc_loss = 0.05267536677051299
Trained batch 101 in epoch 6, gen_loss = 0.8775753671047735, disc_loss = 0.052556332931214686
Trained batch 102 in epoch 6, gen_loss = 0.8779434602237443, disc_loss = 0.0527061073525438
Trained batch 103 in epoch 6, gen_loss = 0.8774561028067882, disc_loss = 0.05235443769309383
Trained batch 104 in epoch 6, gen_loss = 0.8758549457504636, disc_loss = 0.052147767178359485
Trained batch 105 in epoch 6, gen_loss = 0.8737473808369547, disc_loss = 0.05231334235659748
Trained batch 106 in epoch 6, gen_loss = 0.875722460100584, disc_loss = 0.052931843046969344
Trained batch 107 in epoch 6, gen_loss = 0.8752644856770834, disc_loss = 0.052662798582955646
Trained batch 108 in epoch 6, gen_loss = 0.8743107193106905, disc_loss = 0.05258674755555774
Trained batch 109 in epoch 6, gen_loss = 0.8757879652760245, disc_loss = 0.05234484447335655
Trained batch 110 in epoch 6, gen_loss = 0.8753915155256117, disc_loss = 0.05214110659519294
Trained batch 111 in epoch 6, gen_loss = 0.8749392447727067, disc_loss = 0.05211931475371655
Trained batch 112 in epoch 6, gen_loss = 0.8762759075755566, disc_loss = 0.05189669618498435
Trained batch 113 in epoch 6, gen_loss = 0.8743915615374582, disc_loss = 0.05225035154440424
Trained batch 114 in epoch 6, gen_loss = 0.8756667090498883, disc_loss = 0.051987745693844296
Trained batch 115 in epoch 6, gen_loss = 0.8758003516443844, disc_loss = 0.05191387603830161
Trained batch 116 in epoch 6, gen_loss = 0.8767840882651826, disc_loss = 0.05174253436808403
Trained batch 117 in epoch 6, gen_loss = 0.8758175272052571, disc_loss = 0.0522758021982292
Trained batch 118 in epoch 6, gen_loss = 0.8774348547478684, disc_loss = 0.052038924205077795
Trained batch 119 in epoch 6, gen_loss = 0.8778270314137141, disc_loss = 0.05173213480350872
Trained batch 120 in epoch 6, gen_loss = 0.8774167983985144, disc_loss = 0.05149371452506416
Trained batch 121 in epoch 6, gen_loss = 0.8782763222201926, disc_loss = 0.05118070510750423
Trained batch 122 in epoch 6, gen_loss = 0.8771151469005802, disc_loss = 0.051222472519772806
Trained batch 123 in epoch 6, gen_loss = 0.8768723510926769, disc_loss = 0.05129340869344531
Trained batch 124 in epoch 6, gen_loss = 0.8734692423343658, disc_loss = 0.052202629461884496
Trained batch 125 in epoch 6, gen_loss = 0.8748609501691091, disc_loss = 0.05202730184805299
Trained batch 126 in epoch 6, gen_loss = 0.8748991341572109, disc_loss = 0.051817779553922146
Trained batch 127 in epoch 6, gen_loss = 0.8757065779063851, disc_loss = 0.05257204358349554
Trained batch 128 in epoch 6, gen_loss = 0.8726430054782897, disc_loss = 0.05377239055296247
Trained batch 129 in epoch 6, gen_loss = 0.8727135772888477, disc_loss = 0.0535327417919269
Trained batch 130 in epoch 6, gen_loss = 0.8738734471888943, disc_loss = 0.053425529104380205
Trained batch 131 in epoch 6, gen_loss = 0.8737268027934161, disc_loss = 0.05368012051577821
Trained batch 132 in epoch 6, gen_loss = 0.8726240114161843, disc_loss = 0.05372610032782519
Trained batch 133 in epoch 6, gen_loss = 0.8717275871269738, disc_loss = 0.05365020792875717
Trained batch 134 in epoch 6, gen_loss = 0.8725571817821927, disc_loss = 0.05352540976471371
Trained batch 135 in epoch 6, gen_loss = 0.8714320782352897, disc_loss = 0.05361593974863782
Trained batch 136 in epoch 6, gen_loss = 0.8732999745946731, disc_loss = 0.053733403230235524
Trained batch 137 in epoch 6, gen_loss = 0.8707617676776388, disc_loss = 0.05444030269332554
Trained batch 138 in epoch 6, gen_loss = 0.8720920274583556, disc_loss = 0.05449336898519838
Trained batch 139 in epoch 6, gen_loss = 0.872028112411499, disc_loss = 0.05418063733460648
Trained batch 140 in epoch 6, gen_loss = 0.87149785427337, disc_loss = 0.05419160995024738
Trained batch 141 in epoch 6, gen_loss = 0.8700977005589177, disc_loss = 0.05434093229525106
Trained batch 142 in epoch 6, gen_loss = 0.8705282465561287, disc_loss = 0.05405455038368285
Trained batch 143 in epoch 6, gen_loss = 0.8707465959919823, disc_loss = 0.053910666404085025
Trained batch 144 in epoch 6, gen_loss = 0.8698300953569084, disc_loss = 0.05377630786649112
Trained batch 145 in epoch 6, gen_loss = 0.8696222305297852, disc_loss = 0.05356560611765679
Trained batch 146 in epoch 6, gen_loss = 0.8700945649017282, disc_loss = 0.05340601360666103
Trained batch 147 in epoch 6, gen_loss = 0.8698574292498666, disc_loss = 0.05312642127879568
Trained batch 148 in epoch 6, gen_loss = 0.8699652864628991, disc_loss = 0.05285405945157845
Trained batch 149 in epoch 6, gen_loss = 0.8712840672334036, disc_loss = 0.05300492954750856
Trained batch 150 in epoch 6, gen_loss = 0.8693494737543017, disc_loss = 0.05332668429080224
Trained batch 151 in epoch 6, gen_loss = 0.8703214083062975, disc_loss = 0.05307752469946679
Trained batch 152 in epoch 6, gen_loss = 0.8706073967459934, disc_loss = 0.05281780311971708
Trained batch 153 in epoch 6, gen_loss = 0.8697983309046015, disc_loss = 0.05275760433793842
Trained batch 154 in epoch 6, gen_loss = 0.871655906784919, disc_loss = 0.05253014343400155
Trained batch 155 in epoch 6, gen_loss = 0.8703727741272022, disc_loss = 0.052533453736358725
Trained batch 156 in epoch 6, gen_loss = 0.8689968115205218, disc_loss = 0.05266906888147069
Trained batch 157 in epoch 6, gen_loss = 0.8689159830159778, disc_loss = 0.052536444762085056
Trained batch 158 in epoch 6, gen_loss = 0.8729206012479914, disc_loss = 0.05364444523862323
Trained batch 159 in epoch 6, gen_loss = 0.8731239933520556, disc_loss = 0.053504194889683276
Trained batch 160 in epoch 6, gen_loss = 0.8714127873782045, disc_loss = 0.054456905745293785
Trained batch 161 in epoch 6, gen_loss = 0.8725151198881643, disc_loss = 0.054331224975118664
Trained batch 162 in epoch 6, gen_loss = 0.8734817358613746, disc_loss = 0.05447512994194689
Trained batch 163 in epoch 6, gen_loss = 0.8718157443331509, disc_loss = 0.05455504645161876
Trained batch 164 in epoch 6, gen_loss = 0.8706887371612317, disc_loss = 0.054793182568568174
Trained batch 165 in epoch 6, gen_loss = 0.8699748760246369, disc_loss = 0.054971752273120796
Trained batch 166 in epoch 6, gen_loss = 0.8687221682714131, disc_loss = 0.05509213711731805
Trained batch 167 in epoch 6, gen_loss = 0.8689048134145283, disc_loss = 0.05488197788197015
Trained batch 168 in epoch 6, gen_loss = 0.8698059024190056, disc_loss = 0.054838530620086125
Trained batch 169 in epoch 6, gen_loss = 0.8685965320643256, disc_loss = 0.05486586125677123
Trained batch 170 in epoch 6, gen_loss = 0.8678947627892968, disc_loss = 0.054874189818898834
Trained batch 171 in epoch 6, gen_loss = 0.8690786441398222, disc_loss = 0.054698099750419
Trained batch 172 in epoch 6, gen_loss = 0.869452579517585, disc_loss = 0.05454793998788547
Trained batch 173 in epoch 6, gen_loss = 0.8700547187492765, disc_loss = 0.05447272496062449
Trained batch 174 in epoch 6, gen_loss = 0.8704709948812213, disc_loss = 0.05447389100279127
Trained batch 175 in epoch 6, gen_loss = 0.8707198117944327, disc_loss = 0.05429270025342703
Trained batch 176 in epoch 6, gen_loss = 0.8712400396664938, disc_loss = 0.054061874557854765
Trained batch 177 in epoch 6, gen_loss = 0.8720028256432394, disc_loss = 0.05383176361786181
Trained batch 178 in epoch 6, gen_loss = 0.8716259282394494, disc_loss = 0.053584953343402075
Trained batch 179 in epoch 6, gen_loss = 0.872236532635159, disc_loss = 0.05334259261791077
Trained batch 180 in epoch 6, gen_loss = 0.8722045270118924, disc_loss = 0.05312778548085393
Trained batch 181 in epoch 6, gen_loss = 0.8715643181905641, disc_loss = 0.053101646524577675
Trained batch 182 in epoch 6, gen_loss = 0.8729274070979468, disc_loss = 0.053096694317061065
Trained batch 183 in epoch 6, gen_loss = 0.8732727889133536, disc_loss = 0.052880740532165633
Trained batch 184 in epoch 6, gen_loss = 0.8723953762569943, disc_loss = 0.053093124251510644
Trained batch 185 in epoch 6, gen_loss = 0.8738186538860362, disc_loss = 0.05316466815088705
Trained batch 186 in epoch 6, gen_loss = 0.8731545872866788, disc_loss = 0.053140689972489275
Trained batch 187 in epoch 6, gen_loss = 0.8744298365521939, disc_loss = 0.05295322935513042
Trained batch 188 in epoch 6, gen_loss = 0.8731225274858021, disc_loss = 0.05320982655717267
Trained batch 189 in epoch 6, gen_loss = 0.873053777217865, disc_loss = 0.05339781627255051
Trained batch 190 in epoch 6, gen_loss = 0.8731429480133256, disc_loss = 0.053328285110792566
Trained batch 191 in epoch 6, gen_loss = 0.8733454188331962, disc_loss = 0.05357717465570507
Trained batch 192 in epoch 6, gen_loss = 0.8714494553872341, disc_loss = 0.05483728576779674
Trained batch 193 in epoch 6, gen_loss = 0.8704682364291751, disc_loss = 0.05485273504956174
Trained batch 194 in epoch 6, gen_loss = 0.8712613365589044, disc_loss = 0.055552133220510606
Trained batch 195 in epoch 6, gen_loss = 0.8703352167290084, disc_loss = 0.055846768402855615
Trained batch 196 in epoch 6, gen_loss = 0.868875353772023, disc_loss = 0.05615631179874621
Trained batch 197 in epoch 6, gen_loss = 0.8701548784068136, disc_loss = 0.0565109472213821
Trained batch 198 in epoch 6, gen_loss = 0.8689322603407816, disc_loss = 0.056554030187091035
Trained batch 199 in epoch 6, gen_loss = 0.8675985625386238, disc_loss = 0.05679168495349586
Trained batch 200 in epoch 6, gen_loss = 0.8670807901899613, disc_loss = 0.056969035389040835
Trained batch 201 in epoch 6, gen_loss = 0.8658900367151393, disc_loss = 0.05701893463841464
Trained batch 202 in epoch 6, gen_loss = 0.8664486966109628, disc_loss = 0.05688804237566558
Trained batch 203 in epoch 6, gen_loss = 0.8658472691096512, disc_loss = 0.056854819732846
Trained batch 204 in epoch 6, gen_loss = 0.8659233334587841, disc_loss = 0.05713480994468782
Trained batch 205 in epoch 6, gen_loss = 0.8658622650845537, disc_loss = 0.05708322699353533
Trained batch 206 in epoch 6, gen_loss = 0.8653982863334067, disc_loss = 0.057046607460664665
Trained batch 207 in epoch 6, gen_loss = 0.8649122970035443, disc_loss = 0.056898818288643196
Trained batch 208 in epoch 6, gen_loss = 0.8644404009198458, disc_loss = 0.056845971084596436
Trained batch 209 in epoch 6, gen_loss = 0.8654128259136563, disc_loss = 0.05685528799714077
Trained batch 210 in epoch 6, gen_loss = 0.8653450563055645, disc_loss = 0.056703317813328095
Trained batch 211 in epoch 6, gen_loss = 0.8648354141217358, disc_loss = 0.05669274385842794
Trained batch 212 in epoch 6, gen_loss = 0.8646335727731946, disc_loss = 0.05674998840850563
Trained batch 213 in epoch 6, gen_loss = 0.8649303286432106, disc_loss = 0.0565957930896466
Trained batch 214 in epoch 6, gen_loss = 0.8655604465063228, disc_loss = 0.05647557269521924
Trained batch 215 in epoch 6, gen_loss = 0.8643880398185165, disc_loss = 0.0564582473512187
Trained batch 216 in epoch 6, gen_loss = 0.8638063185775335, disc_loss = 0.05632598474106756
Trained batch 217 in epoch 6, gen_loss = 0.864603705909274, disc_loss = 0.0563052940959914
Trained batch 218 in epoch 6, gen_loss = 0.8638537664936013, disc_loss = 0.056330035802095994
Trained batch 219 in epoch 6, gen_loss = 0.863277634436434, disc_loss = 0.05629532502286814
Trained batch 220 in epoch 6, gen_loss = 0.8635438286880562, disc_loss = 0.056234158634532634
Trained batch 221 in epoch 6, gen_loss = 0.8638181632703489, disc_loss = 0.056136742611793244
Trained batch 222 in epoch 6, gen_loss = 0.8633529338066888, disc_loss = 0.056277892356028474
Trained batch 223 in epoch 6, gen_loss = 0.8629427642694542, disc_loss = 0.05612014737978045
Trained batch 224 in epoch 6, gen_loss = 0.8642960728539361, disc_loss = 0.05688974756333563
Trained batch 225 in epoch 6, gen_loss = 0.8632359863382525, disc_loss = 0.05705850180732993
Trained batch 226 in epoch 6, gen_loss = 0.8620240830114759, disc_loss = 0.05750968269511467
Trained batch 227 in epoch 6, gen_loss = 0.8635205103639971, disc_loss = 0.05788415257018386
Trained batch 228 in epoch 6, gen_loss = 0.8628387274179917, disc_loss = 0.058032043619837825
Trained batch 229 in epoch 6, gen_loss = 0.8628710578317228, disc_loss = 0.05816074128708114
Trained batch 230 in epoch 6, gen_loss = 0.8627968577595501, disc_loss = 0.058029607293151673
Trained batch 231 in epoch 6, gen_loss = 0.8612387719853171, disc_loss = 0.058273090210197304
Trained batch 232 in epoch 6, gen_loss = 0.8594070708802841, disc_loss = 0.058900928324640056
Trained batch 233 in epoch 6, gen_loss = 0.861175326200632, disc_loss = 0.05953635787989339
Trained batch 234 in epoch 6, gen_loss = 0.8601727084910616, disc_loss = 0.05967992189082694
Trained batch 235 in epoch 6, gen_loss = 0.8590667487706168, disc_loss = 0.059792671226343866
Trained batch 236 in epoch 6, gen_loss = 0.8599379543010696, disc_loss = 0.059947930999446015
Trained batch 237 in epoch 6, gen_loss = 0.8596117524038843, disc_loss = 0.05989642782496805
Trained batch 238 in epoch 6, gen_loss = 0.8589996550871238, disc_loss = 0.05976777088099693
Trained batch 239 in epoch 6, gen_loss = 0.8588215269148349, disc_loss = 0.059596502866285546
Trained batch 240 in epoch 6, gen_loss = 0.8581651011443236, disc_loss = 0.059815253606413904
Trained batch 241 in epoch 6, gen_loss = 0.8585029527668125, disc_loss = 0.059633196662526484
Trained batch 242 in epoch 6, gen_loss = 0.8593179563926571, disc_loss = 0.059472690577860234
Trained batch 243 in epoch 6, gen_loss = 0.8587590429137965, disc_loss = 0.05933075392099678
Trained batch 244 in epoch 6, gen_loss = 0.8585301829844105, disc_loss = 0.059465671771643115
Trained batch 245 in epoch 6, gen_loss = 0.8581212737211367, disc_loss = 0.059385683856965084
Trained batch 246 in epoch 6, gen_loss = 0.857992204577334, disc_loss = 0.05925856676963177
Trained batch 247 in epoch 6, gen_loss = 0.8587320317183772, disc_loss = 0.059131027830223885
Trained batch 248 in epoch 6, gen_loss = 0.8583152409059456, disc_loss = 0.05904754939447924
Trained batch 249 in epoch 6, gen_loss = 0.8584258804321289, disc_loss = 0.05893315140157938
Trained batch 250 in epoch 6, gen_loss = 0.8587838772283607, disc_loss = 0.05887493638848641
Trained batch 251 in epoch 6, gen_loss = 0.8587424535126913, disc_loss = 0.058749626405418864
Trained batch 252 in epoch 6, gen_loss = 0.8580439196744927, disc_loss = 0.05881861267471502
Trained batch 253 in epoch 6, gen_loss = 0.8578273876914828, disc_loss = 0.058742531758593765
Trained batch 254 in epoch 6, gen_loss = 0.8581888367148006, disc_loss = 0.05865862354928372
Trained batch 255 in epoch 6, gen_loss = 0.8588766721077263, disc_loss = 0.058493336211540736
Trained batch 256 in epoch 6, gen_loss = 0.8596464376969096, disc_loss = 0.05842979701692492
Trained batch 257 in epoch 6, gen_loss = 0.858439296021942, disc_loss = 0.05886917904943459
Trained batch 258 in epoch 6, gen_loss = 0.8591785925695795, disc_loss = 0.05872942324598324
Trained batch 259 in epoch 6, gen_loss = 0.8605196381990726, disc_loss = 0.05865228093014314
Trained batch 260 in epoch 6, gen_loss = 0.8605247432244691, disc_loss = 0.05856458503053563
Trained batch 261 in epoch 6, gen_loss = 0.8606561570222141, disc_loss = 0.0584105079254235
Trained batch 262 in epoch 6, gen_loss = 0.8602073571074598, disc_loss = 0.058901683579662904
Trained batch 263 in epoch 6, gen_loss = 0.8594404237739968, disc_loss = 0.05897835597649894
Trained batch 264 in epoch 6, gen_loss = 0.859471202571437, disc_loss = 0.05885953425939353
Trained batch 265 in epoch 6, gen_loss = 0.8594161166732472, disc_loss = 0.05906096840963552
Trained batch 266 in epoch 6, gen_loss = 0.8590019023820256, disc_loss = 0.05924059267152338
Trained batch 267 in epoch 6, gen_loss = 0.8593140631469328, disc_loss = 0.05908326374422481
Trained batch 268 in epoch 6, gen_loss = 0.8602509910732397, disc_loss = 0.059679171333581096
Trained batch 269 in epoch 6, gen_loss = 0.8595574462855303, disc_loss = 0.05963910770499044
Trained batch 270 in epoch 6, gen_loss = 0.8600963354110718, disc_loss = 0.05957139607147757
Trained batch 271 in epoch 6, gen_loss = 0.8591696453445098, disc_loss = 0.059519180665066576
Trained batch 272 in epoch 6, gen_loss = 0.8586742576662001, disc_loss = 0.05948535416398074
Trained batch 273 in epoch 6, gen_loss = 0.8584448547258864, disc_loss = 0.05975250900471515
Trained batch 274 in epoch 6, gen_loss = 0.8586618401787498, disc_loss = 0.05976997368037701
Trained batch 275 in epoch 6, gen_loss = 0.858479720958765, disc_loss = 0.059700030273339456
Trained batch 276 in epoch 6, gen_loss = 0.8576053122751119, disc_loss = 0.060003849391956625
Trained batch 277 in epoch 6, gen_loss = 0.8585427502076403, disc_loss = 0.06080754833604149
Trained batch 278 in epoch 6, gen_loss = 0.8580937274467988, disc_loss = 0.06074779167584407
Trained batch 279 in epoch 6, gen_loss = 0.8572330134255546, disc_loss = 0.06088667269130903
Trained batch 280 in epoch 6, gen_loss = 0.8566019878692899, disc_loss = 0.06085935455756892
Trained batch 281 in epoch 6, gen_loss = 0.8568014677957441, disc_loss = 0.06109650922503243
Trained batch 282 in epoch 6, gen_loss = 0.8564882870276488, disc_loss = 0.06109428103657788
Trained batch 283 in epoch 6, gen_loss = 0.8560462791315266, disc_loss = 0.06110862658923151
Trained batch 284 in epoch 6, gen_loss = 0.85732772183, disc_loss = 0.06125625924190931
Trained batch 285 in epoch 6, gen_loss = 0.8575827952448305, disc_loss = 0.06111692943304152
Trained batch 286 in epoch 6, gen_loss = 0.8573234685622025, disc_loss = 0.06097153844863488
Trained batch 287 in epoch 6, gen_loss = 0.8564106107999881, disc_loss = 0.06113453698991281
Trained batch 288 in epoch 6, gen_loss = 0.8573002586315247, disc_loss = 0.061319430220137416
Trained batch 289 in epoch 6, gen_loss = 0.8573705237487267, disc_loss = 0.06120282224668511
Trained batch 290 in epoch 6, gen_loss = 0.8564136941818028, disc_loss = 0.06132922649921216
Trained batch 291 in epoch 6, gen_loss = 0.8565424239798768, disc_loss = 0.06123732852634706
Trained batch 292 in epoch 6, gen_loss = 0.8561831338413747, disc_loss = 0.06120531625231988
Trained batch 293 in epoch 6, gen_loss = 0.8558936200174344, disc_loss = 0.061225800876359954
Trained batch 294 in epoch 6, gen_loss = 0.8555910429712069, disc_loss = 0.06217947873144837
Trained batch 295 in epoch 6, gen_loss = 0.8552032773559158, disc_loss = 0.062085505266598354
Trained batch 296 in epoch 6, gen_loss = 0.8540036299011924, disc_loss = 0.062310018466929795
Trained batch 297 in epoch 6, gen_loss = 0.8537700630274395, disc_loss = 0.062338571364197556
Trained batch 298 in epoch 6, gen_loss = 0.8539820965317181, disc_loss = 0.062372683326287016
Trained batch 299 in epoch 6, gen_loss = 0.8530030959844589, disc_loss = 0.06267433935776352
Trained batch 300 in epoch 6, gen_loss = 0.8530241395547936, disc_loss = 0.06281930917991554
Trained batch 301 in epoch 6, gen_loss = 0.8523927775045105, disc_loss = 0.0631235075793815
Trained batch 302 in epoch 6, gen_loss = 0.8518469422170432, disc_loss = 0.06318350575815136
Trained batch 303 in epoch 6, gen_loss = 0.8512966542651779, disc_loss = 0.06330355888502182
Trained batch 304 in epoch 6, gen_loss = 0.8522379840006594, disc_loss = 0.06379426663405582
Trained batch 305 in epoch 6, gen_loss = 0.851826511566935, disc_loss = 0.06367760356150422
Trained batch 306 in epoch 6, gen_loss = 0.8513800468817596, disc_loss = 0.06381138884962964
Trained batch 307 in epoch 6, gen_loss = 0.8514614877375689, disc_loss = 0.06366781078811203
Trained batch 308 in epoch 6, gen_loss = 0.8507841549644964, disc_loss = 0.06369504044405079
Trained batch 309 in epoch 6, gen_loss = 0.8504332590487695, disc_loss = 0.0636466262802001
Trained batch 310 in epoch 6, gen_loss = 0.8502800297890445, disc_loss = 0.06374302913713302
Trained batch 311 in epoch 6, gen_loss = 0.849707960509337, disc_loss = 0.0638859510803834
Trained batch 312 in epoch 6, gen_loss = 0.8490039283475175, disc_loss = 0.06388549416209943
Trained batch 313 in epoch 6, gen_loss = 0.8494577846329683, disc_loss = 0.06373825067784755
Trained batch 314 in epoch 6, gen_loss = 0.8499285760379973, disc_loss = 0.06359271349769736
Trained batch 315 in epoch 6, gen_loss = 0.849606985721407, disc_loss = 0.06353998666959285
Trained batch 316 in epoch 6, gen_loss = 0.8503604027375061, disc_loss = 0.06412470243777198
Trained batch 317 in epoch 6, gen_loss = 0.8495499579786504, disc_loss = 0.06444350889526636
Trained batch 318 in epoch 6, gen_loss = 0.8493750046786843, disc_loss = 0.06439120158389632
Trained batch 319 in epoch 6, gen_loss = 0.8501704689115286, disc_loss = 0.0645929449412506
Trained batch 320 in epoch 6, gen_loss = 0.849743164031305, disc_loss = 0.06454650553471389
Trained batch 321 in epoch 6, gen_loss = 0.8496706728239237, disc_loss = 0.06440249113770931
Trained batch 322 in epoch 6, gen_loss = 0.8499321300916997, disc_loss = 0.06424885136205069
Trained batch 323 in epoch 6, gen_loss = 0.8497287014752258, disc_loss = 0.0642378235862441
Trained batch 324 in epoch 6, gen_loss = 0.8498485779762268, disc_loss = 0.06418912212722576
Trained batch 325 in epoch 6, gen_loss = 0.849958803573269, disc_loss = 0.06408251309767365
Trained batch 326 in epoch 6, gen_loss = 0.8500320067464029, disc_loss = 0.0639931597128875
Trained batch 327 in epoch 6, gen_loss = 0.8497578091010815, disc_loss = 0.06388309000275756
Trained batch 328 in epoch 6, gen_loss = 0.8509924969774612, disc_loss = 0.06384177642696082
Trained batch 329 in epoch 6, gen_loss = 0.8500882206541119, disc_loss = 0.0641340995461426
Trained batch 330 in epoch 6, gen_loss = 0.8505552535330781, disc_loss = 0.06399882561456852
Trained batch 331 in epoch 6, gen_loss = 0.8513442457440388, disc_loss = 0.06421676391724453
Trained batch 332 in epoch 6, gen_loss = 0.850443984116162, disc_loss = 0.06435532652277935
Trained batch 333 in epoch 6, gen_loss = 0.8507161914945363, disc_loss = 0.06424340784471638
Trained batch 334 in epoch 6, gen_loss = 0.8510380851688669, disc_loss = 0.06408446150651174
Trained batch 335 in epoch 6, gen_loss = 0.8502992982310908, disc_loss = 0.06425919157308749
Trained batch 336 in epoch 6, gen_loss = 0.8509378279352047, disc_loss = 0.06424015996706857
Trained batch 337 in epoch 6, gen_loss = 0.8505921596606102, disc_loss = 0.06426934048963281
Trained batch 338 in epoch 6, gen_loss = 0.850979295803734, disc_loss = 0.06440919982461715
Trained batch 339 in epoch 6, gen_loss = 0.8504788142793319, disc_loss = 0.06430776575306321
Trained batch 340 in epoch 6, gen_loss = 0.8502916768848722, disc_loss = 0.06429067932757551
Trained batch 341 in epoch 6, gen_loss = 0.8503919665576422, disc_loss = 0.06414547156030584
Trained batch 342 in epoch 6, gen_loss = 0.8508088037849515, disc_loss = 0.06416330685019059
Trained batch 343 in epoch 6, gen_loss = 0.8506711763004924, disc_loss = 0.06405431339463089
Trained batch 344 in epoch 6, gen_loss = 0.8513290222140326, disc_loss = 0.06394758530878934
Trained batch 345 in epoch 6, gen_loss = 0.8514822128880231, disc_loss = 0.06381081306574747
Trained batch 346 in epoch 6, gen_loss = 0.8510487237649967, disc_loss = 0.06377277105928583
Trained batch 347 in epoch 6, gen_loss = 0.8511132798318205, disc_loss = 0.06383528306962516
Trained batch 348 in epoch 6, gen_loss = 0.8511215000917713, disc_loss = 0.06371713486529439
Trained batch 349 in epoch 6, gen_loss = 0.8504644397326878, disc_loss = 0.06386870815551707
Trained batch 350 in epoch 6, gen_loss = 0.8501603306188882, disc_loss = 0.06376049975649668
Trained batch 351 in epoch 6, gen_loss = 0.85020107826726, disc_loss = 0.06365698026969437
Trained batch 352 in epoch 6, gen_loss = 0.8501817894724881, disc_loss = 0.06360278028741521
Trained batch 353 in epoch 6, gen_loss = 0.8499061571339429, disc_loss = 0.06352861492110595
Trained batch 354 in epoch 6, gen_loss = 0.8495215229585137, disc_loss = 0.06348648393710314
Trained batch 355 in epoch 6, gen_loss = 0.8501020745280083, disc_loss = 0.0634286311805625
Trained batch 356 in epoch 6, gen_loss = 0.8505885853152984, disc_loss = 0.06328053772188619
Trained batch 357 in epoch 6, gen_loss = 0.8505064681921591, disc_loss = 0.06317989246961375
Trained batch 358 in epoch 6, gen_loss = 0.8503552904368111, disc_loss = 0.06309430585255779
Trained batch 359 in epoch 6, gen_loss = 0.8506166630321079, disc_loss = 0.06326757199389653
Trained batch 360 in epoch 6, gen_loss = 0.8507339888332293, disc_loss = 0.0631679846077043
Trained batch 361 in epoch 6, gen_loss = 0.850179839035424, disc_loss = 0.06342121371896474
Trained batch 362 in epoch 6, gen_loss = 0.8511601349867408, disc_loss = 0.06372089562655399
Trained batch 363 in epoch 6, gen_loss = 0.8531196538236115, disc_loss = 0.06426846724934876
Trained batch 364 in epoch 6, gen_loss = 0.8520876486007481, disc_loss = 0.06479163828931034
Trained batch 365 in epoch 6, gen_loss = 0.8523446889848657, disc_loss = 0.06478268530759249
Trained batch 366 in epoch 6, gen_loss = 0.8529158984932652, disc_loss = 0.06474193725328922
Trained batch 367 in epoch 6, gen_loss = 0.8529108599152254, disc_loss = 0.06468734501243528
Trained batch 368 in epoch 6, gen_loss = 0.8529178228804736, disc_loss = 0.06455161955288351
Trained batch 369 in epoch 6, gen_loss = 0.8527408482255162, disc_loss = 0.06445414049148157
Trained batch 370 in epoch 6, gen_loss = 0.8522803193796678, disc_loss = 0.06442671731827314
Trained batch 371 in epoch 6, gen_loss = 0.8533073280767728, disc_loss = 0.06467316402573019
Trained batch 372 in epoch 6, gen_loss = 0.8534242784050131, disc_loss = 0.06454761769502716
Trained batch 373 in epoch 6, gen_loss = 0.8530109311170119, disc_loss = 0.06487720626789857
Trained batch 374 in epoch 6, gen_loss = 0.8536709289550781, disc_loss = 0.06481132962057988
Trained batch 375 in epoch 6, gen_loss = 0.8539604719014878, disc_loss = 0.06475357664501334
Trained batch 376 in epoch 6, gen_loss = 0.8532931761969306, disc_loss = 0.06477665510621484
Trained batch 377 in epoch 6, gen_loss = 0.8532998505092803, disc_loss = 0.06486380804655334
Trained batch 378 in epoch 6, gen_loss = 0.8530347650787132, disc_loss = 0.06474786636353247
Trained batch 379 in epoch 6, gen_loss = 0.852633632327381, disc_loss = 0.06464076482592837
Trained batch 380 in epoch 6, gen_loss = 0.8521085791387583, disc_loss = 0.06460119516214752
Trained batch 381 in epoch 6, gen_loss = 0.8530141859466492, disc_loss = 0.06447100715897001
Trained batch 382 in epoch 6, gen_loss = 0.853431264818804, disc_loss = 0.06457946732076124
Trained batch 383 in epoch 6, gen_loss = 0.8532068063504994, disc_loss = 0.0645752509056668
Trained batch 384 in epoch 6, gen_loss = 0.8532242657302263, disc_loss = 0.06454851196280548
Trained batch 385 in epoch 6, gen_loss = 0.8533232882232864, disc_loss = 0.06449613268993834
Trained batch 386 in epoch 6, gen_loss = 0.8534987323967985, disc_loss = 0.06440916260372298
Trained batch 387 in epoch 6, gen_loss = 0.8540496377600837, disc_loss = 0.06436818553442039
Trained batch 388 in epoch 6, gen_loss = 0.8543165001280817, disc_loss = 0.06423501429509534
Trained batch 389 in epoch 6, gen_loss = 0.8541952104140551, disc_loss = 0.06411285718473105
Trained batch 390 in epoch 6, gen_loss = 0.8546761583794108, disc_loss = 0.06400297918950049
Trained batch 391 in epoch 6, gen_loss = 0.8539097803283711, disc_loss = 0.06404366989962149
Trained batch 392 in epoch 6, gen_loss = 0.8543463567741044, disc_loss = 0.06393014574684108
Trained batch 393 in epoch 6, gen_loss = 0.8546537032284712, disc_loss = 0.06378488520841082
Trained batch 394 in epoch 6, gen_loss = 0.8545511541487295, disc_loss = 0.06370614755049914
Trained batch 395 in epoch 6, gen_loss = 0.8546539963495852, disc_loss = 0.06362095429336256
Trained batch 396 in epoch 6, gen_loss = 0.8545584921872886, disc_loss = 0.0634895487751821
Trained batch 397 in epoch 6, gen_loss = 0.854704972787119, disc_loss = 0.06336514516288985
Trained batch 398 in epoch 6, gen_loss = 0.8549353976297498, disc_loss = 0.0634194241211117
Trained batch 399 in epoch 6, gen_loss = 0.8545594082772732, disc_loss = 0.06368263132171706
Trained batch 400 in epoch 6, gen_loss = 0.854060809659839, disc_loss = 0.06369808246788018
Trained batch 401 in epoch 6, gen_loss = 0.8542472092962977, disc_loss = 0.06379798081800786
Trained batch 402 in epoch 6, gen_loss = 0.8547602482232504, disc_loss = 0.06377626676574608
Trained batch 403 in epoch 6, gen_loss = 0.8545045942658245, disc_loss = 0.06369860835677695
Trained batch 404 in epoch 6, gen_loss = 0.8539040100427322, disc_loss = 0.06381526574906375
Trained batch 405 in epoch 6, gen_loss = 0.8541172989483538, disc_loss = 0.06385424935254337
Trained batch 406 in epoch 6, gen_loss = 0.8540043907024937, disc_loss = 0.06378944896628362
Trained batch 407 in epoch 6, gen_loss = 0.8542086278983191, disc_loss = 0.06366478849668056
Trained batch 408 in epoch 6, gen_loss = 0.8544082526472786, disc_loss = 0.06385686294765446
Trained batch 409 in epoch 6, gen_loss = 0.8537762124363969, disc_loss = 0.0639358389009608
Trained batch 410 in epoch 6, gen_loss = 0.8529132071637759, disc_loss = 0.06401584789365385
Trained batch 411 in epoch 6, gen_loss = 0.8533555469611316, disc_loss = 0.06425538761043939
Trained batch 412 in epoch 6, gen_loss = 0.8541487184765841, disc_loss = 0.06431342167757254
Trained batch 413 in epoch 6, gen_loss = 0.8534892769395441, disc_loss = 0.06451559913286192
Trained batch 414 in epoch 6, gen_loss = 0.8534814905689423, disc_loss = 0.06442816873047366
Trained batch 415 in epoch 6, gen_loss = 0.8535421799438504, disc_loss = 0.06440335538802454
Trained batch 416 in epoch 6, gen_loss = 0.8535177358191648, disc_loss = 0.0643577745666714
Trained batch 417 in epoch 6, gen_loss = 0.8533207833339153, disc_loss = 0.06454105916517702
Trained batch 418 in epoch 6, gen_loss = 0.8529463880528698, disc_loss = 0.06458215062286447
Trained batch 419 in epoch 6, gen_loss = 0.8526996953856377, disc_loss = 0.06457283069113536
Trained batch 420 in epoch 6, gen_loss = 0.852647442644962, disc_loss = 0.06458326501466528
Trained batch 421 in epoch 6, gen_loss = 0.85288313179502, disc_loss = 0.06445915753604464
Trained batch 422 in epoch 6, gen_loss = 0.8529881923052154, disc_loss = 0.06434846768732541
Trained batch 423 in epoch 6, gen_loss = 0.8530081031879164, disc_loss = 0.064218931624947
Trained batch 424 in epoch 6, gen_loss = 0.8530955820223864, disc_loss = 0.06409626815906343
Trained batch 425 in epoch 6, gen_loss = 0.8533333946421673, disc_loss = 0.06397654094073064
Trained batch 426 in epoch 6, gen_loss = 0.853931511662883, disc_loss = 0.06389564306058636
Trained batch 427 in epoch 6, gen_loss = 0.853639625291401, disc_loss = 0.06393568075662391
Trained batch 428 in epoch 6, gen_loss = 0.8537004012744743, disc_loss = 0.06383035477632895
Trained batch 429 in epoch 6, gen_loss = 0.8545980034179466, disc_loss = 0.063961311462227
Trained batch 430 in epoch 6, gen_loss = 0.8540780717839774, disc_loss = 0.06405398795670741
Trained batch 431 in epoch 6, gen_loss = 0.85375426730348, disc_loss = 0.06398992458384277
Trained batch 432 in epoch 6, gen_loss = 0.8536175874171577, disc_loss = 0.06451193245631098
Trained batch 433 in epoch 6, gen_loss = 0.8531603676520185, disc_loss = 0.0644988171769143
Trained batch 434 in epoch 6, gen_loss = 0.852812021285638, disc_loss = 0.06449219925949971
Trained batch 435 in epoch 6, gen_loss = 0.852204804641938, disc_loss = 0.06458653684560244
Trained batch 436 in epoch 6, gen_loss = 0.8529325778888074, disc_loss = 0.06501335407515617
Trained batch 437 in epoch 6, gen_loss = 0.8525895364072225, disc_loss = 0.0650753197260201
Trained batch 438 in epoch 6, gen_loss = 0.8520091828425544, disc_loss = 0.06513954638577743
Trained batch 439 in epoch 6, gen_loss = 0.852422135187821, disc_loss = 0.0650961795377291
Trained batch 440 in epoch 6, gen_loss = 0.8519615708700383, disc_loss = 0.06510784078913143
Trained batch 441 in epoch 6, gen_loss = 0.8526764515433376, disc_loss = 0.06529423148409207
Trained batch 442 in epoch 6, gen_loss = 0.8524706461225083, disc_loss = 0.06534329916794131
Trained batch 443 in epoch 6, gen_loss = 0.8522150756136792, disc_loss = 0.0654027899202832
Trained batch 444 in epoch 6, gen_loss = 0.8519382019391221, disc_loss = 0.06533243857700838
Trained batch 445 in epoch 6, gen_loss = 0.8516702317202572, disc_loss = 0.0653832911204697
Trained batch 446 in epoch 6, gen_loss = 0.8515660818124511, disc_loss = 0.06550716476044066
Trained batch 447 in epoch 6, gen_loss = 0.8510720049297171, disc_loss = 0.06563354748193108
Trained batch 448 in epoch 6, gen_loss = 0.8512664617169938, disc_loss = 0.06562619749041801
Trained batch 449 in epoch 6, gen_loss = 0.8513279033369489, disc_loss = 0.06551709632699688
Trained batch 450 in epoch 6, gen_loss = 0.8512247793558168, disc_loss = 0.0655496762652454
Trained batch 451 in epoch 6, gen_loss = 0.8511157197366773, disc_loss = 0.0655922528945602
Trained batch 452 in epoch 6, gen_loss = 0.8510841021343046, disc_loss = 0.06554406252843852
Trained batch 453 in epoch 6, gen_loss = 0.8513569246961157, disc_loss = 0.06543528489842354
Trained batch 454 in epoch 6, gen_loss = 0.8516214418542254, disc_loss = 0.06549506563447662
Trained batch 455 in epoch 6, gen_loss = 0.8509987520152017, disc_loss = 0.06568260016450822
Trained batch 456 in epoch 6, gen_loss = 0.8510195463569733, disc_loss = 0.06558560266789187
Trained batch 457 in epoch 6, gen_loss = 0.8510523951860495, disc_loss = 0.06552086013072378
Trained batch 458 in epoch 6, gen_loss = 0.851456347179309, disc_loss = 0.06545093917533398
Trained batch 459 in epoch 6, gen_loss = 0.8512001261115074, disc_loss = 0.06546162774017
Trained batch 460 in epoch 6, gen_loss = 0.850838405255899, disc_loss = 0.06549943908200541
Trained batch 461 in epoch 6, gen_loss = 0.851910972040453, disc_loss = 0.06583815566929323
Trained batch 462 in epoch 6, gen_loss = 0.8520823322542286, disc_loss = 0.06577586610127667
Trained batch 463 in epoch 6, gen_loss = 0.8516463125445719, disc_loss = 0.06597365022050859
Trained batch 464 in epoch 6, gen_loss = 0.8518663236530878, disc_loss = 0.06595731586498278
Trained batch 465 in epoch 6, gen_loss = 0.8516355594979846, disc_loss = 0.06594357220456004
Trained batch 466 in epoch 6, gen_loss = 0.8514702438159469, disc_loss = 0.06585544252636537
Trained batch 467 in epoch 6, gen_loss = 0.8511956115691071, disc_loss = 0.065808949026908
Trained batch 468 in epoch 6, gen_loss = 0.8515742578104869, disc_loss = 0.0656921956191725
Trained batch 469 in epoch 6, gen_loss = 0.8516346046899227, disc_loss = 0.06565196766379348
Trained batch 470 in epoch 6, gen_loss = 0.8515321330786257, disc_loss = 0.06562277162348705
Trained batch 471 in epoch 6, gen_loss = 0.8509825026711165, disc_loss = 0.06568720408170721
Trained batch 472 in epoch 6, gen_loss = 0.8513667349709517, disc_loss = 0.06559495939174174
Trained batch 473 in epoch 6, gen_loss = 0.851827226422004, disc_loss = 0.06552177689820214
Trained batch 474 in epoch 6, gen_loss = 0.8518814707429786, disc_loss = 0.06542463018902038
Trained batch 475 in epoch 6, gen_loss = 0.8517169122811125, disc_loss = 0.06535500942478974
Trained batch 476 in epoch 6, gen_loss = 0.8517981354670454, disc_loss = 0.06524966518732424
Trained batch 477 in epoch 6, gen_loss = 0.8517453841958584, disc_loss = 0.06514833664334531
Trained batch 478 in epoch 6, gen_loss = 0.8519638397872821, disc_loss = 0.06504043299969216
Trained batch 479 in epoch 6, gen_loss = 0.8530096507941684, disc_loss = 0.06533772607993645
Trained batch 480 in epoch 6, gen_loss = 0.8532414140795471, disc_loss = 0.06524108551063124
Trained batch 481 in epoch 6, gen_loss = 0.8528502108026836, disc_loss = 0.06525624258428256
Trained batch 482 in epoch 6, gen_loss = 0.8529110437964801, disc_loss = 0.0651562138408515
Trained batch 483 in epoch 6, gen_loss = 0.8529194850197508, disc_loss = 0.06505747979760847
Trained batch 484 in epoch 6, gen_loss = 0.8530110846475227, disc_loss = 0.06494147080697657
Trained batch 485 in epoch 6, gen_loss = 0.8537194140776685, disc_loss = 0.06490107592570868
Trained batch 486 in epoch 6, gen_loss = 0.8538399101894739, disc_loss = 0.06479962983644841
Trained batch 487 in epoch 6, gen_loss = 0.8539478778228408, disc_loss = 0.06468623760156333
Trained batch 488 in epoch 6, gen_loss = 0.8539096694173013, disc_loss = 0.0645869970055019
Trained batch 489 in epoch 6, gen_loss = 0.8541851196362048, disc_loss = 0.06446935319037614
Trained batch 490 in epoch 6, gen_loss = 0.8545660466987587, disc_loss = 0.06441733482826782
Trained batch 491 in epoch 6, gen_loss = 0.8544946074849222, disc_loss = 0.06431514186485542
Trained batch 492 in epoch 6, gen_loss = 0.8546324548203853, disc_loss = 0.06421224683292709
Trained batch 493 in epoch 6, gen_loss = 0.8544283644993779, disc_loss = 0.06417358652613152
Trained batch 494 in epoch 6, gen_loss = 0.854432174232271, disc_loss = 0.06413769348985468
Trained batch 495 in epoch 6, gen_loss = 0.8545554892550553, disc_loss = 0.06403279117770463
Trained batch 496 in epoch 6, gen_loss = 0.8545279886041369, disc_loss = 0.063943639853913
Trained batch 497 in epoch 6, gen_loss = 0.8548241843540506, disc_loss = 0.06384350411335837
Trained batch 498 in epoch 6, gen_loss = 0.8549841216546978, disc_loss = 0.06374407108996309
Trained batch 499 in epoch 6, gen_loss = 0.8545133966803551, disc_loss = 0.06381063293199986
Trained batch 500 in epoch 6, gen_loss = 0.8551646834481024, disc_loss = 0.0638405499253013
Trained batch 501 in epoch 6, gen_loss = 0.8565196268468264, disc_loss = 0.06396649484300014
Trained batch 502 in epoch 6, gen_loss = 0.8565492337906574, disc_loss = 0.06391853806109095
Trained batch 503 in epoch 6, gen_loss = 0.8567293603860197, disc_loss = 0.06385614577632782
Trained batch 504 in epoch 6, gen_loss = 0.8566891127883798, disc_loss = 0.06378970401693541
Trained batch 505 in epoch 6, gen_loss = 0.8564365867216125, disc_loss = 0.06375396708413046
Trained batch 506 in epoch 6, gen_loss = 0.8565730782302879, disc_loss = 0.06367775554542798
Trained batch 507 in epoch 6, gen_loss = 0.8563628944707667, disc_loss = 0.06369140756584146
Trained batch 508 in epoch 6, gen_loss = 0.8560985966726464, disc_loss = 0.0637715267180328
Trained batch 509 in epoch 6, gen_loss = 0.855956093061204, disc_loss = 0.06372325040454811
Trained batch 510 in epoch 6, gen_loss = 0.855986079416163, disc_loss = 0.0636471535330693
Trained batch 511 in epoch 6, gen_loss = 0.8559734210721217, disc_loss = 0.06358795294636366
Trained batch 512 in epoch 6, gen_loss = 0.8552878856310371, disc_loss = 0.06370794426261304
Trained batch 513 in epoch 6, gen_loss = 0.8550533375735413, disc_loss = 0.0637094521567095
Trained batch 514 in epoch 6, gen_loss = 0.8554537601262621, disc_loss = 0.06398760837240561
Trained batch 515 in epoch 6, gen_loss = 0.8547590640048648, disc_loss = 0.06414328837792511
Trained batch 516 in epoch 6, gen_loss = 0.8543739722937173, disc_loss = 0.06433462150074268
Trained batch 517 in epoch 6, gen_loss = 0.8543688855691306, disc_loss = 0.06435168359309981
Trained batch 518 in epoch 6, gen_loss = 0.8539693470979701, disc_loss = 0.06450125937097076
Trained batch 519 in epoch 6, gen_loss = 0.8539984815968917, disc_loss = 0.06445799523230213
Trained batch 520 in epoch 6, gen_loss = 0.8540879490851441, disc_loss = 0.06446684676985795
Trained batch 521 in epoch 6, gen_loss = 0.8539718820560024, disc_loss = 0.0644071495679646
Trained batch 522 in epoch 6, gen_loss = 0.8541299597597031, disc_loss = 0.06437661635812308
Trained batch 523 in epoch 6, gen_loss = 0.8536051662482378, disc_loss = 0.06444738209798562
Trained batch 524 in epoch 6, gen_loss = 0.853755300669443, disc_loss = 0.06435784300434448
Trained batch 525 in epoch 6, gen_loss = 0.8534540736289985, disc_loss = 0.06440295328867725
Trained batch 526 in epoch 6, gen_loss = 0.8536199213092196, disc_loss = 0.06430969637795661
Trained batch 527 in epoch 6, gen_loss = 0.853860098473502, disc_loss = 0.06424283930082862
Trained batch 528 in epoch 6, gen_loss = 0.8541293709287121, disc_loss = 0.06416346277383161
Trained batch 529 in epoch 6, gen_loss = 0.8534617252507299, disc_loss = 0.06443211988299945
Trained batch 530 in epoch 6, gen_loss = 0.8534985126860847, disc_loss = 0.0643966756436602
Trained batch 531 in epoch 6, gen_loss = 0.8534926928411749, disc_loss = 0.06433193227958943
Trained batch 532 in epoch 6, gen_loss = 0.8532716044230041, disc_loss = 0.06432351356679766
Trained batch 533 in epoch 6, gen_loss = 0.8534863829501113, disc_loss = 0.06431459083591591
Trained batch 534 in epoch 6, gen_loss = 0.8536263601245168, disc_loss = 0.06428176946502841
Trained batch 535 in epoch 6, gen_loss = 0.8530555044425957, disc_loss = 0.06446040248578247
Trained batch 536 in epoch 6, gen_loss = 0.8536455872671564, disc_loss = 0.06456972732775787
Trained batch 537 in epoch 6, gen_loss = 0.8535447091307339, disc_loss = 0.06467072725846505
Trained batch 538 in epoch 6, gen_loss = 0.8533169746067174, disc_loss = 0.06472491273131215
Trained batch 539 in epoch 6, gen_loss = 0.8533086788323191, disc_loss = 0.06464720352777038
Trained batch 540 in epoch 6, gen_loss = 0.853754714158899, disc_loss = 0.0648476254021105
Trained batch 541 in epoch 6, gen_loss = 0.8534929497765439, disc_loss = 0.0648990031082623
Trained batch 542 in epoch 6, gen_loss = 0.8534071419669339, disc_loss = 0.06482459992619702
Trained batch 543 in epoch 6, gen_loss = 0.8539928610381835, disc_loss = 0.06488083436766721
Trained batch 544 in epoch 6, gen_loss = 0.8538458149914347, disc_loss = 0.06485870149960622
Trained batch 545 in epoch 6, gen_loss = 0.85366287396286, disc_loss = 0.0648395134086615
Trained batch 546 in epoch 6, gen_loss = 0.8533686834780781, disc_loss = 0.0648410565209604
Trained batch 547 in epoch 6, gen_loss = 0.8530864423535166, disc_loss = 0.06480634293644723
Trained batch 548 in epoch 6, gen_loss = 0.8531200468323052, disc_loss = 0.06481976761908452
Trained batch 549 in epoch 6, gen_loss = 0.8529076479239898, disc_loss = 0.06493899267759513
Trained batch 550 in epoch 6, gen_loss = 0.8529608471964751, disc_loss = 0.06484565130281118
Trained batch 551 in epoch 6, gen_loss = 0.8525113940130973, disc_loss = 0.06496065247220163
Trained batch 552 in epoch 6, gen_loss = 0.8522782985922657, disc_loss = 0.06496556730651268
Trained batch 553 in epoch 6, gen_loss = 0.8522076962334154, disc_loss = 0.0649800596696523
Trained batch 554 in epoch 6, gen_loss = 0.8520009151987127, disc_loss = 0.06509286503114545
Trained batch 555 in epoch 6, gen_loss = 0.8520000833723185, disc_loss = 0.0651500095042112
Trained batch 556 in epoch 6, gen_loss = 0.8521237629641323, disc_loss = 0.06510734718202661
Trained batch 557 in epoch 6, gen_loss = 0.8518446546622075, disc_loss = 0.06509634045513488
Trained batch 558 in epoch 6, gen_loss = 0.8519240772894755, disc_loss = 0.06503950478842278
Trained batch 559 in epoch 6, gen_loss = 0.8520395845706974, disc_loss = 0.06498911746228779
Trained batch 560 in epoch 6, gen_loss = 0.852142904584633, disc_loss = 0.0649023927447723
Trained batch 561 in epoch 6, gen_loss = 0.8519277906184519, disc_loss = 0.0649168614979197
Trained batch 562 in epoch 6, gen_loss = 0.8520037342875296, disc_loss = 0.06492486455085725
Trained batch 563 in epoch 6, gen_loss = 0.8520456289885737, disc_loss = 0.06485948118410925
Trained batch 564 in epoch 6, gen_loss = 0.851916579809864, disc_loss = 0.06487159835735122
Trained batch 565 in epoch 6, gen_loss = 0.851895664848203, disc_loss = 0.06483431442068106
Trained batch 566 in epoch 6, gen_loss = 0.8518272777608673, disc_loss = 0.06482381755946043
Trained batch 567 in epoch 6, gen_loss = 0.8520074428492029, disc_loss = 0.06478376630742863
Trained batch 568 in epoch 6, gen_loss = 0.8519317087159215, disc_loss = 0.06469902730021489
Trained batch 569 in epoch 6, gen_loss = 0.851778508644355, disc_loss = 0.06464994199361587
Trained batch 570 in epoch 6, gen_loss = 0.8516780440214428, disc_loss = 0.06470443167350208
Trained batch 571 in epoch 6, gen_loss = 0.8519976305273863, disc_loss = 0.06467333644989982
Trained batch 572 in epoch 6, gen_loss = 0.8518955875545688, disc_loss = 0.06459389677609319
Trained batch 573 in epoch 6, gen_loss = 0.8520241408294086, disc_loss = 0.06451581552777219
Trained batch 574 in epoch 6, gen_loss = 0.8518022239208222, disc_loss = 0.064488961527367
Trained batch 575 in epoch 6, gen_loss = 0.8525695341846181, disc_loss = 0.06449322874525226
Trained batch 576 in epoch 6, gen_loss = 0.8520732210558457, disc_loss = 0.06471091158852704
Trained batch 577 in epoch 6, gen_loss = 0.8516659254536909, disc_loss = 0.0647108315975183
Trained batch 578 in epoch 6, gen_loss = 0.851231246466052, disc_loss = 0.06472341645435013
Trained batch 579 in epoch 6, gen_loss = 0.8514179218945832, disc_loss = 0.06486108864352493
Trained batch 580 in epoch 6, gen_loss = 0.8515488210417933, disc_loss = 0.06479523199403629
Trained batch 581 in epoch 6, gen_loss = 0.8513884543860492, disc_loss = 0.06483024020064815
Trained batch 582 in epoch 6, gen_loss = 0.8510537311613662, disc_loss = 0.06486960771968062
Trained batch 583 in epoch 6, gen_loss = 0.8511254197012071, disc_loss = 0.06516691518561557
Trained batch 584 in epoch 6, gen_loss = 0.8507753314625504, disc_loss = 0.0651537310037539
Trained batch 585 in epoch 6, gen_loss = 0.8511847139116847, disc_loss = 0.06517025985303669
Trained batch 586 in epoch 6, gen_loss = 0.8515155467203163, disc_loss = 0.06510306314646157
Trained batch 587 in epoch 6, gen_loss = 0.851567379927554, disc_loss = 0.06504300457099135
Trained batch 588 in epoch 6, gen_loss = 0.8515011675794987, disc_loss = 0.06496732996567983
Trained batch 589 in epoch 6, gen_loss = 0.851446488701691, disc_loss = 0.0649245841673307
Trained batch 590 in epoch 6, gen_loss = 0.8514509438560699, disc_loss = 0.06484132358337896
Trained batch 591 in epoch 6, gen_loss = 0.8514951811348265, disc_loss = 0.06475617728318793
Trained batch 592 in epoch 6, gen_loss = 0.8515933318343171, disc_loss = 0.06469784280234982
Trained batch 593 in epoch 6, gen_loss = 0.851057141467377, disc_loss = 0.0648566953334581
Trained batch 594 in epoch 6, gen_loss = 0.8508740368510495, disc_loss = 0.06494274400096356
Trained batch 595 in epoch 6, gen_loss = 0.8512485636860733, disc_loss = 0.06488755297450186
Trained batch 596 in epoch 6, gen_loss = 0.8510571306374803, disc_loss = 0.06486197985580794
Trained batch 597 in epoch 6, gen_loss = 0.850969012216182, disc_loss = 0.0648202148342449
Trained batch 598 in epoch 6, gen_loss = 0.851035573894472, disc_loss = 0.06473732831964085
Trained batch 599 in epoch 6, gen_loss = 0.8515946444372336, disc_loss = 0.06470406445596988
Trained batch 600 in epoch 6, gen_loss = 0.8518860376317569, disc_loss = 0.06461326932974668
Trained batch 601 in epoch 6, gen_loss = 0.8517261183638113, disc_loss = 0.06463659865444409
Trained batch 602 in epoch 6, gen_loss = 0.8517248647821879, disc_loss = 0.06455378162490813
Trained batch 603 in epoch 6, gen_loss = 0.8515947341228163, disc_loss = 0.06455420991112878
Trained batch 604 in epoch 6, gen_loss = 0.8518067494404218, disc_loss = 0.0645048456228038
Trained batch 605 in epoch 6, gen_loss = 0.8515131125847498, disc_loss = 0.06447537950694979
Trained batch 606 in epoch 6, gen_loss = 0.8514897606812749, disc_loss = 0.06440794196430918
Trained batch 607 in epoch 6, gen_loss = 0.8519453927384395, disc_loss = 0.0643370944070691
Trained batch 608 in epoch 6, gen_loss = 0.8521608555160328, disc_loss = 0.064279937539372
Trained batch 609 in epoch 6, gen_loss = 0.8517980646403109, disc_loss = 0.0642880820844811
Trained batch 610 in epoch 6, gen_loss = 0.8517593012211171, disc_loss = 0.06421979748203424
Trained batch 611 in epoch 6, gen_loss = 0.8518739162025109, disc_loss = 0.06419578122562467
Trained batch 612 in epoch 6, gen_loss = 0.8522725243844566, disc_loss = 0.06414177410113116
Trained batch 613 in epoch 6, gen_loss = 0.8516889701351669, disc_loss = 0.06424769753490117
Trained batch 614 in epoch 6, gen_loss = 0.8516004549293983, disc_loss = 0.06421694463966944
Trained batch 615 in epoch 6, gen_loss = 0.8515846019538192, disc_loss = 0.06417335381552988
Trained batch 616 in epoch 6, gen_loss = 0.8516393378739225, disc_loss = 0.06415780373838409
Trained batch 617 in epoch 6, gen_loss = 0.851528054736193, disc_loss = 0.06413597749579324
Trained batch 618 in epoch 6, gen_loss = 0.8520017726067002, disc_loss = 0.06418257199230819
Trained batch 619 in epoch 6, gen_loss = 0.8515297826740049, disc_loss = 0.06422228028231691
Trained batch 620 in epoch 6, gen_loss = 0.8515590376036178, disc_loss = 0.06419395310834242
Trained batch 621 in epoch 6, gen_loss = 0.851812238143188, disc_loss = 0.0641320653812259
Trained batch 622 in epoch 6, gen_loss = 0.8520071053485809, disc_loss = 0.064129414432271
Trained batch 623 in epoch 6, gen_loss = 0.851380928634451, disc_loss = 0.06442616365100735
Trained batch 624 in epoch 6, gen_loss = 0.8523134338855743, disc_loss = 0.06452171464934946
Trained batch 625 in epoch 6, gen_loss = 0.8523867600165997, disc_loss = 0.06448586246805094
Trained batch 626 in epoch 6, gen_loss = 0.8520710751105344, disc_loss = 0.06452298513502239
Trained batch 627 in epoch 6, gen_loss = 0.8518516400912005, disc_loss = 0.06452526849513625
Trained batch 628 in epoch 6, gen_loss = 0.8518449969720007, disc_loss = 0.06447709416704095
Trained batch 629 in epoch 6, gen_loss = 0.8512797622926651, disc_loss = 0.06474279493817853
Trained batch 630 in epoch 6, gen_loss = 0.8516142463249563, disc_loss = 0.06475750329533796
Trained batch 631 in epoch 6, gen_loss = 0.8512307566272307, disc_loss = 0.06484865523135007
Trained batch 632 in epoch 6, gen_loss = 0.8515485879651743, disc_loss = 0.06496613931519937
Trained batch 633 in epoch 6, gen_loss = 0.8516220646419735, disc_loss = 0.06500771522818703
Trained batch 634 in epoch 6, gen_loss = 0.8510423871945209, disc_loss = 0.0651057616088862
Trained batch 635 in epoch 6, gen_loss = 0.8510310015869591, disc_loss = 0.06505761973035622
Trained batch 636 in epoch 6, gen_loss = 0.8512419455186164, disc_loss = 0.06497793415929753
Trained batch 637 in epoch 6, gen_loss = 0.8514584862980349, disc_loss = 0.0649045980805502
Trained batch 638 in epoch 6, gen_loss = 0.8512741004077482, disc_loss = 0.06488912059897804
Trained batch 639 in epoch 6, gen_loss = 0.8511150837410242, disc_loss = 0.06484575905415113
Trained batch 640 in epoch 6, gen_loss = 0.8511613473970321, disc_loss = 0.06476373266786127
Trained batch 641 in epoch 6, gen_loss = 0.8513434972625655, disc_loss = 0.06470301111135922
Trained batch 642 in epoch 6, gen_loss = 0.8511582750647472, disc_loss = 0.06465728284681034
Trained batch 643 in epoch 6, gen_loss = 0.8513541480306512, disc_loss = 0.06457715797865682
Trained batch 644 in epoch 6, gen_loss = 0.8514997424543366, disc_loss = 0.06449069964028029
Trained batch 645 in epoch 6, gen_loss = 0.8516491739650259, disc_loss = 0.06447513829325628
Trained batch 646 in epoch 6, gen_loss = 0.8517692727043972, disc_loss = 0.06439288343638297
Trained batch 647 in epoch 6, gen_loss = 0.8520045726111641, disc_loss = 0.06433292898208616
Trained batch 648 in epoch 6, gen_loss = 0.8519152733963701, disc_loss = 0.06425509677097799
Trained batch 649 in epoch 6, gen_loss = 0.85142891732546, disc_loss = 0.06446771702585885
Trained batch 650 in epoch 6, gen_loss = 0.8518982623487756, disc_loss = 0.06447749801864204
Trained batch 651 in epoch 6, gen_loss = 0.8518272568386025, disc_loss = 0.06444242028190977
Trained batch 652 in epoch 6, gen_loss = 0.8521275644006627, disc_loss = 0.06437026776136634
Trained batch 653 in epoch 6, gen_loss = 0.8520493395740468, disc_loss = 0.0643477064225572
Trained batch 654 in epoch 6, gen_loss = 0.8517008012942685, disc_loss = 0.06442640141178747
Trained batch 655 in epoch 6, gen_loss = 0.8513480849654936, disc_loss = 0.06453442134647402
Trained batch 656 in epoch 6, gen_loss = 0.8519320814123256, disc_loss = 0.0648795354216894
Trained batch 657 in epoch 6, gen_loss = 0.8520658140758613, disc_loss = 0.06490478470516717
Trained batch 658 in epoch 6, gen_loss = 0.8514581557380231, disc_loss = 0.0651949898082599
Trained batch 659 in epoch 6, gen_loss = 0.8513235977653301, disc_loss = 0.06517706961074675
Trained batch 660 in epoch 6, gen_loss = 0.8513903497477342, disc_loss = 0.06521599706608955
Trained batch 661 in epoch 6, gen_loss = 0.8509996833668014, disc_loss = 0.06530665007020343
Trained batch 662 in epoch 6, gen_loss = 0.8513209952398303, disc_loss = 0.06563067428984007
Trained batch 663 in epoch 6, gen_loss = 0.8512416184397347, disc_loss = 0.06559361088305644
Trained batch 664 in epoch 6, gen_loss = 0.8509660144049422, disc_loss = 0.06561457481781455
Trained batch 665 in epoch 6, gen_loss = 0.8507662048121473, disc_loss = 0.06574061502389296
Trained batch 666 in epoch 6, gen_loss = 0.850342481702879, disc_loss = 0.0658110387607951
Trained batch 667 in epoch 6, gen_loss = 0.8504855671596384, disc_loss = 0.06575274234986167
Trained batch 668 in epoch 6, gen_loss = 0.8504675767079597, disc_loss = 0.06571991049569038
Trained batch 669 in epoch 6, gen_loss = 0.8504300907031813, disc_loss = 0.0657191925702978
Trained batch 670 in epoch 6, gen_loss = 0.8501984359343965, disc_loss = 0.06575555648118946
Trained batch 671 in epoch 6, gen_loss = 0.8499941999270093, disc_loss = 0.06572584437630472
Trained batch 672 in epoch 6, gen_loss = 0.8504729057934804, disc_loss = 0.06584262088519614
Trained batch 673 in epoch 6, gen_loss = 0.8503684430253258, disc_loss = 0.06580103908455447
Trained batch 674 in epoch 6, gen_loss = 0.8501768400492492, disc_loss = 0.06578175506175116
Trained batch 675 in epoch 6, gen_loss = 0.8499383896853797, disc_loss = 0.06574450201319101
Trained batch 676 in epoch 6, gen_loss = 0.8497745805424108, disc_loss = 0.06572314954405455
Trained batch 677 in epoch 6, gen_loss = 0.8501014056722674, disc_loss = 0.06571258311187382
Trained batch 678 in epoch 6, gen_loss = 0.85005367903892, disc_loss = 0.06569072381498646
Trained batch 679 in epoch 6, gen_loss = 0.8499169170418206, disc_loss = 0.06566997362259666
Trained batch 680 in epoch 6, gen_loss = 0.8497764053761346, disc_loss = 0.06562055698862619
Trained batch 681 in epoch 6, gen_loss = 0.8492028980223664, disc_loss = 0.06587073260500394
Trained batch 682 in epoch 6, gen_loss = 0.8502394012877742, disc_loss = 0.06634609539833569
Trained batch 683 in epoch 6, gen_loss = 0.8501019454751796, disc_loss = 0.0663441441611425
Trained batch 684 in epoch 6, gen_loss = 0.8500687591785933, disc_loss = 0.0663978634096247
Trained batch 685 in epoch 6, gen_loss = 0.849705197937982, disc_loss = 0.06658085077286918
Trained batch 686 in epoch 6, gen_loss = 0.849926612653066, disc_loss = 0.06668372001170873
Trained batch 687 in epoch 6, gen_loss = 0.8497004751982384, disc_loss = 0.0667726272767204
Trained batch 688 in epoch 6, gen_loss = 0.8495173048990385, disc_loss = 0.06672623784434056
Trained batch 689 in epoch 6, gen_loss = 0.8494726660890856, disc_loss = 0.06671684601992045
Trained batch 690 in epoch 6, gen_loss = 0.84948882236322, disc_loss = 0.0666812439381742
Trained batch 691 in epoch 6, gen_loss = 0.849106745611381, disc_loss = 0.06668988986255742
Trained batch 692 in epoch 6, gen_loss = 0.8495999955253684, disc_loss = 0.06672178465311253
Trained batch 693 in epoch 6, gen_loss = 0.8494306865016734, disc_loss = 0.06668494852267808
Trained batch 694 in epoch 6, gen_loss = 0.849375632898413, disc_loss = 0.0667508297264844
Trained batch 695 in epoch 6, gen_loss = 0.8493206002160736, disc_loss = 0.06677356271418454
Trained batch 696 in epoch 6, gen_loss = 0.8493329193790469, disc_loss = 0.06674415183719916
Trained batch 697 in epoch 6, gen_loss = 0.8489979681022529, disc_loss = 0.0668390258822462
Trained batch 698 in epoch 6, gen_loss = 0.849371955587458, disc_loss = 0.06683095766881611
Trained batch 699 in epoch 6, gen_loss = 0.8494166251165526, disc_loss = 0.06676822196226567
Trained batch 700 in epoch 6, gen_loss = 0.84911399463274, disc_loss = 0.06684019378374481
Trained batch 701 in epoch 6, gen_loss = 0.8496174989347784, disc_loss = 0.06686559943628213
Trained batch 702 in epoch 6, gen_loss = 0.8495429010258969, disc_loss = 0.06682882550772634
Trained batch 703 in epoch 6, gen_loss = 0.8495265147648752, disc_loss = 0.06675328938912241
Trained batch 704 in epoch 6, gen_loss = 0.8495869086566546, disc_loss = 0.06668116623562173
Trained batch 705 in epoch 6, gen_loss = 0.8494162631693373, disc_loss = 0.06666664190777702
Trained batch 706 in epoch 6, gen_loss = 0.8494160232230326, disc_loss = 0.06674869804770872
Trained batch 707 in epoch 6, gen_loss = 0.8495948641734609, disc_loss = 0.06667959217263628
Trained batch 708 in epoch 6, gen_loss = 0.8497060402408138, disc_loss = 0.066610143378729
Trained batch 709 in epoch 6, gen_loss = 0.8500053198824467, disc_loss = 0.06653689088522863
Trained batch 710 in epoch 6, gen_loss = 0.8498739393535378, disc_loss = 0.06648854083681555
Trained batch 711 in epoch 6, gen_loss = 0.8495920486748219, disc_loss = 0.06644548807656811
Trained batch 712 in epoch 6, gen_loss = 0.8494136972564468, disc_loss = 0.06644408240963981
Trained batch 713 in epoch 6, gen_loss = 0.8496721746290431, disc_loss = 0.06643432157742857
Trained batch 714 in epoch 6, gen_loss = 0.849752945041323, disc_loss = 0.06636804430517595
Trained batch 715 in epoch 6, gen_loss = 0.8500635174815881, disc_loss = 0.06628988398038704
Trained batch 716 in epoch 6, gen_loss = 0.8497218542434847, disc_loss = 0.0663667108696032
Trained batch 717 in epoch 6, gen_loss = 0.849819266571972, disc_loss = 0.06631259654368427
Trained batch 718 in epoch 6, gen_loss = 0.8505477875844162, disc_loss = 0.06642830360393262
Trained batch 719 in epoch 6, gen_loss = 0.850487054594689, disc_loss = 0.06637803846905525
Trained batch 720 in epoch 6, gen_loss = 0.8503070691504856, disc_loss = 0.06636430405728756
Trained batch 721 in epoch 6, gen_loss = 0.850445620117095, disc_loss = 0.06630125944373659
Trained batch 722 in epoch 6, gen_loss = 0.8504118101972762, disc_loss = 0.06633593631717653
Trained batch 723 in epoch 6, gen_loss = 0.8502840917166425, disc_loss = 0.06633311966163986
Trained batch 724 in epoch 6, gen_loss = 0.8503698608381994, disc_loss = 0.06631669876069345
Trained batch 725 in epoch 6, gen_loss = 0.8503128931788374, disc_loss = 0.06628635455084549
Trained batch 726 in epoch 6, gen_loss = 0.850526159821383, disc_loss = 0.06623231383307006
Trained batch 727 in epoch 6, gen_loss = 0.8508062589872669, disc_loss = 0.0661571296629148
Trained batch 728 in epoch 6, gen_loss = 0.8505899801094019, disc_loss = 0.06613972987302558
Trained batch 729 in epoch 6, gen_loss = 0.8503474262887485, disc_loss = 0.06617791807623452
Trained batch 730 in epoch 6, gen_loss = 0.8510927010414212, disc_loss = 0.06629992395489083
Trained batch 731 in epoch 6, gen_loss = 0.8506566551132281, disc_loss = 0.06641686870398437
Trained batch 732 in epoch 6, gen_loss = 0.8506721435025802, disc_loss = 0.06640419074604834
Trained batch 733 in epoch 6, gen_loss = 0.8508785732029569, disc_loss = 0.0665354194501491
Trained batch 734 in epoch 6, gen_loss = 0.8506138256212481, disc_loss = 0.06665471152902967
Trained batch 735 in epoch 6, gen_loss = 0.850785625734083, disc_loss = 0.06667263869957937
Trained batch 736 in epoch 6, gen_loss = 0.8503895349790478, disc_loss = 0.06683353963781911
Trained batch 737 in epoch 6, gen_loss = 0.8502400572787778, disc_loss = 0.06685464515547623
Trained batch 738 in epoch 6, gen_loss = 0.8506957896265512, disc_loss = 0.06695470935066454
Trained batch 739 in epoch 6, gen_loss = 0.8507088916124524, disc_loss = 0.06694539897458476
Trained batch 740 in epoch 6, gen_loss = 0.850328917807413, disc_loss = 0.06702985516315711
Trained batch 741 in epoch 6, gen_loss = 0.8504690275279017, disc_loss = 0.06701258853933902
Trained batch 742 in epoch 6, gen_loss = 0.8503840263647154, disc_loss = 0.06705749655408161
Trained batch 743 in epoch 6, gen_loss = 0.8501752264477233, disc_loss = 0.06709128690154982
Trained batch 744 in epoch 6, gen_loss = 0.8507331842144064, disc_loss = 0.06708963565190866
Trained batch 745 in epoch 6, gen_loss = 0.8510551940420038, disc_loss = 0.06706529597367282
Trained batch 746 in epoch 6, gen_loss = 0.850580845132889, disc_loss = 0.06720566124514424
Trained batch 747 in epoch 6, gen_loss = 0.8505539094461477, disc_loss = 0.0671588279298173
Trained batch 748 in epoch 6, gen_loss = 0.850414929267402, disc_loss = 0.06724220188334584
Trained batch 749 in epoch 6, gen_loss = 0.8501179709831873, disc_loss = 0.06738989228320619
Trained batch 750 in epoch 6, gen_loss = 0.8502941425646668, disc_loss = 0.06733947925172876
Trained batch 751 in epoch 6, gen_loss = 0.8503924920124576, disc_loss = 0.06732057009023575
Trained batch 752 in epoch 6, gen_loss = 0.8502124940177517, disc_loss = 0.06729423886308493
Trained batch 753 in epoch 6, gen_loss = 0.850213738943917, disc_loss = 0.06725077655485064
Trained batch 754 in epoch 6, gen_loss = 0.8503219159628381, disc_loss = 0.06727242454306673
Trained batch 755 in epoch 6, gen_loss = 0.8499049068522201, disc_loss = 0.067382518086883
Trained batch 756 in epoch 6, gen_loss = 0.8498597572234065, disc_loss = 0.06741225335911862
Trained batch 757 in epoch 6, gen_loss = 0.8498265850591157, disc_loss = 0.06740209320007201
Trained batch 758 in epoch 6, gen_loss = 0.8497523085480465, disc_loss = 0.0673561000513043
Trained batch 759 in epoch 6, gen_loss = 0.8501280203069511, disc_loss = 0.06733102531135572
Trained batch 760 in epoch 6, gen_loss = 0.8499632960628429, disc_loss = 0.06735495764103751
Trained batch 761 in epoch 6, gen_loss = 0.8496171319343913, disc_loss = 0.06755313712656205
Trained batch 762 in epoch 6, gen_loss = 0.8498644801064212, disc_loss = 0.06751437372739182
Trained batch 763 in epoch 6, gen_loss = 0.8499645123853109, disc_loss = 0.06745393991931121
Trained batch 764 in epoch 6, gen_loss = 0.8499221167143653, disc_loss = 0.06741316202918396
Trained batch 765 in epoch 6, gen_loss = 0.8501266699780372, disc_loss = 0.06738665160436096
Trained batch 766 in epoch 6, gen_loss = 0.8497598237677378, disc_loss = 0.06745368099772654
Trained batch 767 in epoch 6, gen_loss = 0.8497848246479407, disc_loss = 0.06744389237246651
Trained batch 768 in epoch 6, gen_loss = 0.8499862238939159, disc_loss = 0.06740164004268684
Trained batch 769 in epoch 6, gen_loss = 0.8499640120701356, disc_loss = 0.06733889308177515
Trained batch 770 in epoch 6, gen_loss = 0.850144488145096, disc_loss = 0.06727233977539009
Trained batch 771 in epoch 6, gen_loss = 0.8501269002420915, disc_loss = 0.06720941937275211
Trained batch 772 in epoch 6, gen_loss = 0.8499980785945409, disc_loss = 0.06719248996623449
Trained batch 773 in epoch 6, gen_loss = 0.8504904775425445, disc_loss = 0.0673478228149536
Trained batch 774 in epoch 6, gen_loss = 0.8503385084290658, disc_loss = 0.06735466227716495
Trained batch 775 in epoch 6, gen_loss = 0.8501087034255573, disc_loss = 0.0674254313026094
Trained batch 776 in epoch 6, gen_loss = 0.850136248723267, disc_loss = 0.06738039577725023
Trained batch 777 in epoch 6, gen_loss = 0.8501182106972354, disc_loss = 0.06730920614394573
Trained batch 778 in epoch 6, gen_loss = 0.850161663719258, disc_loss = 0.06725827334161767
Trained batch 779 in epoch 6, gen_loss = 0.8502191593631719, disc_loss = 0.06719519954282217
Trained batch 780 in epoch 6, gen_loss = 0.8501059598028278, disc_loss = 0.06718141749494073
Trained batch 781 in epoch 6, gen_loss = 0.8502033288445314, disc_loss = 0.06711212402540724
Trained batch 782 in epoch 6, gen_loss = 0.8500336762969674, disc_loss = 0.06710751364982924
Trained batch 783 in epoch 6, gen_loss = 0.8501987592222131, disc_loss = 0.06709670531860439
Trained batch 784 in epoch 6, gen_loss = 0.8499351970329406, disc_loss = 0.06710682163774302
Trained batch 785 in epoch 6, gen_loss = 0.8498326990061437, disc_loss = 0.0670435393813277
Trained batch 786 in epoch 6, gen_loss = 0.8499143891216385, disc_loss = 0.06723867531740396
Trained batch 787 in epoch 6, gen_loss = 0.8496644324835787, disc_loss = 0.067259876831047
Trained batch 788 in epoch 6, gen_loss = 0.8496602746092623, disc_loss = 0.06724626013621952
Trained batch 789 in epoch 6, gen_loss = 0.8495178183045569, disc_loss = 0.06723174241347875
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.7287803888320923, disc_loss = 0.057400450110435486
Trained batch 1 in epoch 7, gen_loss = 0.6844786703586578, disc_loss = 0.08017200231552124
Trained batch 2 in epoch 7, gen_loss = 0.8949104348818461, disc_loss = 0.13898640871047974
Trained batch 3 in epoch 7, gen_loss = 0.8865327090024948, disc_loss = 0.12628051824867725
Trained batch 4 in epoch 7, gen_loss = 0.8479773163795471, disc_loss = 0.11366431266069413
Trained batch 5 in epoch 7, gen_loss = 0.8557772437731425, disc_loss = 0.11083858336011569
Trained batch 6 in epoch 7, gen_loss = 0.8442963872637067, disc_loss = 0.1015130143080439
Trained batch 7 in epoch 7, gen_loss = 0.8295707926154137, disc_loss = 0.09344434784725308
Trained batch 8 in epoch 7, gen_loss = 0.82234302494261, disc_loss = 0.08828553640180165
Trained batch 9 in epoch 7, gen_loss = 0.8489339292049408, disc_loss = 0.08132459837943315
Trained batch 10 in epoch 7, gen_loss = 0.8456778905608437, disc_loss = 0.07590972530570897
Trained batch 11 in epoch 7, gen_loss = 0.8642400453488032, disc_loss = 0.07450625114142895
Trained batch 12 in epoch 7, gen_loss = 0.8770043070499713, disc_loss = 0.0698930540910134
Trained batch 13 in epoch 7, gen_loss = 0.85948560493333, disc_loss = 0.06914179027080536
Trained batch 14 in epoch 7, gen_loss = 0.8633073846499125, disc_loss = 0.06626445576548576
Trained batch 15 in epoch 7, gen_loss = 0.8703629709780216, disc_loss = 0.06259541591862217
Trained batch 16 in epoch 7, gen_loss = 0.8793341166832868, disc_loss = 0.05947968763682772
Trained batch 17 in epoch 7, gen_loss = 0.8739277422428131, disc_loss = 0.05768819427531627
Trained batch 18 in epoch 7, gen_loss = 0.8645154206376326, disc_loss = 0.05684764197978534
Trained batch 19 in epoch 7, gen_loss = 0.8725363224744797, disc_loss = 0.05862288461066782
Trained batch 20 in epoch 7, gen_loss = 0.8682679647491092, disc_loss = 0.05740271158339012
Trained batch 21 in epoch 7, gen_loss = 0.8788482465527274, disc_loss = 0.05692869242788716
Trained batch 22 in epoch 7, gen_loss = 0.8673966475155043, disc_loss = 0.05878352815204341
Trained batch 23 in epoch 7, gen_loss = 0.857786126434803, disc_loss = 0.05951691314112395
Trained batch 24 in epoch 7, gen_loss = 0.8647372555732727, disc_loss = 0.061689174957573416
Trained batch 25 in epoch 7, gen_loss = 0.8659193034355457, disc_loss = 0.061436830267596707
Trained batch 26 in epoch 7, gen_loss = 0.860637574284165, disc_loss = 0.060985054855269415
Trained batch 27 in epoch 7, gen_loss = 0.8557456199611936, disc_loss = 0.060380241999934824
Trained batch 28 in epoch 7, gen_loss = 0.8608420820071779, disc_loss = 0.058931458067020465
Trained batch 29 in epoch 7, gen_loss = 0.8675549725691477, disc_loss = 0.05730099420373638
Trained batch 30 in epoch 7, gen_loss = 0.8742554245456573, disc_loss = 0.05758091509943047
Trained batch 31 in epoch 7, gen_loss = 0.8710194434970617, disc_loss = 0.05716682437923737
Trained batch 32 in epoch 7, gen_loss = 0.863347331682841, disc_loss = 0.05719701745406245
Trained batch 33 in epoch 7, gen_loss = 0.8667574349571677, disc_loss = 0.058310368728330904
Trained batch 34 in epoch 7, gen_loss = 0.8648375136511667, disc_loss = 0.05728675007287945
Trained batch 35 in epoch 7, gen_loss = 0.8570671942498949, disc_loss = 0.06065615564067331
Trained batch 36 in epoch 7, gen_loss = 0.8595528908678003, disc_loss = 0.06007539709979618
Trained batch 37 in epoch 7, gen_loss = 0.8695744699553439, disc_loss = 0.06026857471289603
Trained batch 38 in epoch 7, gen_loss = 0.8634066872107677, disc_loss = 0.060458667074831635
Trained batch 39 in epoch 7, gen_loss = 0.8568394705653191, disc_loss = 0.061862547579221425
Trained batch 40 in epoch 7, gen_loss = 0.8578335584663763, disc_loss = 0.0642988553452419
Trained batch 41 in epoch 7, gen_loss = 0.8644742185161227, disc_loss = 0.0645540742247942
Trained batch 42 in epoch 7, gen_loss = 0.855632834656294, disc_loss = 0.06842418212097051
Trained batch 43 in epoch 7, gen_loss = 0.8564522970806469, disc_loss = 0.06981193297542632
Trained batch 44 in epoch 7, gen_loss = 0.852936053276062, disc_loss = 0.06975781973451375
Trained batch 45 in epoch 7, gen_loss = 0.847566166649694, disc_loss = 0.07002398345376486
Trained batch 46 in epoch 7, gen_loss = 0.8501919089479649, disc_loss = 0.07088040994440621
Trained batch 47 in epoch 7, gen_loss = 0.8464958034455776, disc_loss = 0.07138840114930645
Trained batch 48 in epoch 7, gen_loss = 0.8437549106928767, disc_loss = 0.07107933312274363
Trained batch 49 in epoch 7, gen_loss = 0.8501460468769073, disc_loss = 0.07793291857466102
Trained batch 50 in epoch 7, gen_loss = 0.8439093723016626, disc_loss = 0.0785179105130773
Trained batch 51 in epoch 7, gen_loss = 0.8402363921587284, disc_loss = 0.08003475192862634
Trained batch 52 in epoch 7, gen_loss = 0.8388753420901749, disc_loss = 0.08096709332587022
Trained batch 53 in epoch 7, gen_loss = 0.8390014557926743, disc_loss = 0.08246788787828
Trained batch 54 in epoch 7, gen_loss = 0.8354795315048912, disc_loss = 0.08252526770599863
Trained batch 55 in epoch 7, gen_loss = 0.8314159650887761, disc_loss = 0.08283446268511138
Trained batch 56 in epoch 7, gen_loss = 0.8294837589849505, disc_loss = 0.08471384479484537
Trained batch 57 in epoch 7, gen_loss = 0.8354860944994564, disc_loss = 0.08381628840840583
Trained batch 58 in epoch 7, gen_loss = 0.8333204166363861, disc_loss = 0.0837125344265063
Trained batch 59 in epoch 7, gen_loss = 0.8312085350354512, disc_loss = 0.08712854290691514
Trained batch 60 in epoch 7, gen_loss = 0.8285749623032866, disc_loss = 0.08728982097484538
Trained batch 61 in epoch 7, gen_loss = 0.8255084378104056, disc_loss = 0.08761597164876518
Trained batch 62 in epoch 7, gen_loss = 0.8255184273871164, disc_loss = 0.08928780995368485
Trained batch 63 in epoch 7, gen_loss = 0.8218016792088747, disc_loss = 0.09172147167555522
Trained batch 64 in epoch 7, gen_loss = 0.8230698127012986, disc_loss = 0.09064080587659891
Trained batch 65 in epoch 7, gen_loss = 0.8237440920237339, disc_loss = 0.09153593228565472
Trained batch 66 in epoch 7, gen_loss = 0.8182456053015011, disc_loss = 0.09335405645030204
Trained batch 67 in epoch 7, gen_loss = 0.8179740471874967, disc_loss = 0.09277211161165991
Trained batch 68 in epoch 7, gen_loss = 0.820175122955571, disc_loss = 0.09248063884729492
Trained batch 69 in epoch 7, gen_loss = 0.819874683873994, disc_loss = 0.09158344621370945
Trained batch 70 in epoch 7, gen_loss = 0.8202194575692566, disc_loss = 0.09086560291356184
Trained batch 71 in epoch 7, gen_loss = 0.8166964919202857, disc_loss = 0.09153258129178236
Trained batch 72 in epoch 7, gen_loss = 0.8166149719937207, disc_loss = 0.09148631072666956
Trained batch 73 in epoch 7, gen_loss = 0.8177577237019668, disc_loss = 0.09128335502149688
Trained batch 74 in epoch 7, gen_loss = 0.8169706809520721, disc_loss = 0.09045959374556939
Trained batch 75 in epoch 7, gen_loss = 0.8141198491579608, disc_loss = 0.09063699548622887
Trained batch 76 in epoch 7, gen_loss = 0.8134173816674716, disc_loss = 0.08994795165520597
Trained batch 77 in epoch 7, gen_loss = 0.81718309987814, disc_loss = 0.09127893142449932
Trained batch 78 in epoch 7, gen_loss = 0.8170277978046031, disc_loss = 0.09058044238982699
Trained batch 79 in epoch 7, gen_loss = 0.8174318965524435, disc_loss = 0.08991924711735919
Trained batch 80 in epoch 7, gen_loss = 0.8165134688218435, disc_loss = 0.09027949482616451
Trained batch 81 in epoch 7, gen_loss = 0.8175381403870698, disc_loss = 0.0898190575606394
Trained batch 82 in epoch 7, gen_loss = 0.8145966138466295, disc_loss = 0.09019211802003255
Trained batch 83 in epoch 7, gen_loss = 0.8156704161138761, disc_loss = 0.0896719865434404
Trained batch 84 in epoch 7, gen_loss = 0.8180014340316548, disc_loss = 0.08999803233891726
Trained batch 85 in epoch 7, gen_loss = 0.8161490362050922, disc_loss = 0.09065605519166173
Trained batch 86 in epoch 7, gen_loss = 0.8175805666665922, disc_loss = 0.09049597443563157
Trained batch 87 in epoch 7, gen_loss = 0.8163320920006796, disc_loss = 0.09004827234259044
Trained batch 88 in epoch 7, gen_loss = 0.8191674555955308, disc_loss = 0.08945037367010719
Trained batch 89 in epoch 7, gen_loss = 0.8181388904651006, disc_loss = 0.08882226531083386
Trained batch 90 in epoch 7, gen_loss = 0.8164110914036468, disc_loss = 0.08848511641538077
Trained batch 91 in epoch 7, gen_loss = 0.8145708198780599, disc_loss = 0.08874858155563149
Trained batch 92 in epoch 7, gen_loss = 0.8159056443680999, disc_loss = 0.08851071295919277
Trained batch 93 in epoch 7, gen_loss = 0.8149456923946421, disc_loss = 0.08897368912089695
Trained batch 94 in epoch 7, gen_loss = 0.8143580483762841, disc_loss = 0.08837546883641105
Trained batch 95 in epoch 7, gen_loss = 0.8183440612629056, disc_loss = 0.08848099787913573
Trained batch 96 in epoch 7, gen_loss = 0.8171936934141769, disc_loss = 0.0884163341744198
Trained batch 97 in epoch 7, gen_loss = 0.8195854093955488, disc_loss = 0.08912630642441158
Trained batch 98 in epoch 7, gen_loss = 0.8168351562938305, disc_loss = 0.0903483047197112
Trained batch 99 in epoch 7, gen_loss = 0.8164097580313683, disc_loss = 0.09045154851861298
Trained batch 100 in epoch 7, gen_loss = 0.8181094075783645, disc_loss = 0.09059067163616419
Trained batch 101 in epoch 7, gen_loss = 0.8165607011201335, disc_loss = 0.09032687900003557
Trained batch 102 in epoch 7, gen_loss = 0.8145903681667106, disc_loss = 0.09046345418409525
Trained batch 103 in epoch 7, gen_loss = 0.8158513952333194, disc_loss = 0.09164273972587231
Trained batch 104 in epoch 7, gen_loss = 0.8149607275213514, disc_loss = 0.09119243047954072
Trained batch 105 in epoch 7, gen_loss = 0.814853918158783, disc_loss = 0.09063187983976502
Trained batch 106 in epoch 7, gen_loss = 0.8148822926472281, disc_loss = 0.09045882172290688
Trained batch 107 in epoch 7, gen_loss = 0.8154510748055246, disc_loss = 0.08992175820835487
Trained batch 108 in epoch 7, gen_loss = 0.8140479946902038, disc_loss = 0.08993223071132504
Trained batch 109 in epoch 7, gen_loss = 0.8165922032161193, disc_loss = 0.08927156048911539
Trained batch 110 in epoch 7, gen_loss = 0.8179519957787281, disc_loss = 0.08875839892976187
Trained batch 111 in epoch 7, gen_loss = 0.8159468176641634, disc_loss = 0.08918652015771451
Trained batch 112 in epoch 7, gen_loss = 0.8175526316714498, disc_loss = 0.08874064674848213
Trained batch 113 in epoch 7, gen_loss = 0.8185882790569674, disc_loss = 0.08820259233675244
Trained batch 114 in epoch 7, gen_loss = 0.8184861330882363, disc_loss = 0.08792299672799266
Trained batch 115 in epoch 7, gen_loss = 0.8196913294237236, disc_loss = 0.0872532594387002
Trained batch 116 in epoch 7, gen_loss = 0.8205949447603307, disc_loss = 0.08661407274472663
Trained batch 117 in epoch 7, gen_loss = 0.8220123085430113, disc_loss = 0.08760849403028013
Trained batch 118 in epoch 7, gen_loss = 0.8207170109288031, disc_loss = 0.0874889918501262
Trained batch 119 in epoch 7, gen_loss = 0.8198486424982547, disc_loss = 0.08740496657943973
Trained batch 120 in epoch 7, gen_loss = 0.8233130783581537, disc_loss = 0.0871905419467525
Trained batch 121 in epoch 7, gen_loss = 0.8229720414173408, disc_loss = 0.08728867608168331
Trained batch 122 in epoch 7, gen_loss = 0.8197670959360231, disc_loss = 0.08830682652419418
Trained batch 123 in epoch 7, gen_loss = 0.8189601078629494, disc_loss = 0.08810180062878757
Trained batch 124 in epoch 7, gen_loss = 0.820999871969223, disc_loss = 0.08791219005733729
Trained batch 125 in epoch 7, gen_loss = 0.82187334294357, disc_loss = 0.08736013222692741
Trained batch 126 in epoch 7, gen_loss = 0.822709093647679, disc_loss = 0.08711897271619302
Trained batch 127 in epoch 7, gen_loss = 0.8213224408682436, disc_loss = 0.0872061587360804
Trained batch 128 in epoch 7, gen_loss = 0.8210518635058588, disc_loss = 0.08677295746296182
Trained batch 129 in epoch 7, gen_loss = 0.8200988143682479, disc_loss = 0.0865584695353531
Trained batch 130 in epoch 7, gen_loss = 0.8219864620962216, disc_loss = 0.08654513799421887
Trained batch 131 in epoch 7, gen_loss = 0.8211910072149653, disc_loss = 0.08618283729689817
Trained batch 132 in epoch 7, gen_loss = 0.8219663081760693, disc_loss = 0.08561008386453964
Trained batch 133 in epoch 7, gen_loss = 0.8237054132258714, disc_loss = 0.08515454932296676
Trained batch 134 in epoch 7, gen_loss = 0.8230398582087622, disc_loss = 0.08468095976859331
Trained batch 135 in epoch 7, gen_loss = 0.8224611065405256, disc_loss = 0.0843522844986771
Trained batch 136 in epoch 7, gen_loss = 0.8219642345487637, disc_loss = 0.08435915986307128
Trained batch 137 in epoch 7, gen_loss = 0.8222677623448165, disc_loss = 0.08398674713933597
Trained batch 138 in epoch 7, gen_loss = 0.8211378453017997, disc_loss = 0.08381934106859157
Trained batch 139 in epoch 7, gen_loss = 0.8212079292961529, disc_loss = 0.08339022252309536
Trained batch 140 in epoch 7, gen_loss = 0.8229833974483165, disc_loss = 0.08396800552620322
Trained batch 141 in epoch 7, gen_loss = 0.8211515535351256, disc_loss = 0.08455238599513829
Trained batch 142 in epoch 7, gen_loss = 0.820297836215346, disc_loss = 0.08424320335701838
Trained batch 143 in epoch 7, gen_loss = 0.8219453417178657, disc_loss = 0.0842225755784764
Trained batch 144 in epoch 7, gen_loss = 0.8213297373261945, disc_loss = 0.08398171764124056
Trained batch 145 in epoch 7, gen_loss = 0.8195915367097071, disc_loss = 0.08418284324061585
Trained batch 146 in epoch 7, gen_loss = 0.8186390487109723, disc_loss = 0.0846195311988799
Trained batch 147 in epoch 7, gen_loss = 0.8183907872518977, disc_loss = 0.08467040793038905
Trained batch 148 in epoch 7, gen_loss = 0.8167749137286372, disc_loss = 0.08493715582802992
Trained batch 149 in epoch 7, gen_loss = 0.8150885643561682, disc_loss = 0.08519764376804233
Trained batch 150 in epoch 7, gen_loss = 0.816965746366425, disc_loss = 0.08572432204513558
Trained batch 151 in epoch 7, gen_loss = 0.8174884270288443, disc_loss = 0.0854905450924937
Trained batch 152 in epoch 7, gen_loss = 0.8161370370512694, disc_loss = 0.0856619305190405
Trained batch 153 in epoch 7, gen_loss = 0.8161755341601062, disc_loss = 0.08525047041838626
Trained batch 154 in epoch 7, gen_loss = 0.8164303723842867, disc_loss = 0.08483525326535586
Trained batch 155 in epoch 7, gen_loss = 0.8165427635495479, disc_loss = 0.0847389351707907
Trained batch 156 in epoch 7, gen_loss = 0.8171231942192004, disc_loss = 0.08490203913585966
Trained batch 157 in epoch 7, gen_loss = 0.8160994435790219, disc_loss = 0.08473333593198581
Trained batch 158 in epoch 7, gen_loss = 0.8163729360643422, disc_loss = 0.08454618030725597
Trained batch 159 in epoch 7, gen_loss = 0.8157598389312625, disc_loss = 0.08461610385566018
Trained batch 160 in epoch 7, gen_loss = 0.8155156194423296, disc_loss = 0.08470221288988124
Trained batch 161 in epoch 7, gen_loss = 0.8151514182488123, disc_loss = 0.0844147871248424
Trained batch 162 in epoch 7, gen_loss = 0.8154731756704716, disc_loss = 0.08402133106248327
Trained batch 163 in epoch 7, gen_loss = 0.816620999174874, disc_loss = 0.0836633813805969
Trained batch 164 in epoch 7, gen_loss = 0.8168722472407601, disc_loss = 0.08335657204981103
Trained batch 165 in epoch 7, gen_loss = 0.8176054708569883, disc_loss = 0.08298526919188809
Trained batch 166 in epoch 7, gen_loss = 0.8164170193458031, disc_loss = 0.08280851794016397
Trained batch 167 in epoch 7, gen_loss = 0.8167358645725817, disc_loss = 0.08300447286040123
Trained batch 168 in epoch 7, gen_loss = 0.8172848413329152, disc_loss = 0.0826381009083087
Trained batch 169 in epoch 7, gen_loss = 0.817463017035933, disc_loss = 0.08226462662329569
Trained batch 170 in epoch 7, gen_loss = 0.8203647267400173, disc_loss = 0.08237329672760609
Trained batch 171 in epoch 7, gen_loss = 0.820039453374785, disc_loss = 0.0822335876968451
Trained batch 172 in epoch 7, gen_loss = 0.8201919799250674, disc_loss = 0.08214008169130266
Trained batch 173 in epoch 7, gen_loss = 0.8213159207297468, disc_loss = 0.08196430523269649
Trained batch 174 in epoch 7, gen_loss = 0.8202871498039791, disc_loss = 0.0818764417352421
Trained batch 175 in epoch 7, gen_loss = 0.8195651679892432, disc_loss = 0.08175939074399965
Trained batch 176 in epoch 7, gen_loss = 0.8219673679036609, disc_loss = 0.08187065937024894
Trained batch 177 in epoch 7, gen_loss = 0.8210703561480126, disc_loss = 0.08184823731295346
Trained batch 178 in epoch 7, gen_loss = 0.8219406489886385, disc_loss = 0.08163858969388894
Trained batch 179 in epoch 7, gen_loss = 0.823446337878704, disc_loss = 0.08127266424708068
Trained batch 180 in epoch 7, gen_loss = 0.8233994191193449, disc_loss = 0.08097290891371874
Trained batch 181 in epoch 7, gen_loss = 0.8233982945209021, disc_loss = 0.08066454711421342
Trained batch 182 in epoch 7, gen_loss = 0.8242517046915377, disc_loss = 0.08027340592358445
Trained batch 183 in epoch 7, gen_loss = 0.8268684584485448, disc_loss = 0.08167226918790814
Trained batch 184 in epoch 7, gen_loss = 0.8252160840743297, disc_loss = 0.08252735144483882
Trained batch 185 in epoch 7, gen_loss = 0.8257429088636111, disc_loss = 0.08316469551514714
Trained batch 186 in epoch 7, gen_loss = 0.8244770295160977, disc_loss = 0.0835620429277181
Trained batch 187 in epoch 7, gen_loss = 0.8254070340635928, disc_loss = 0.08415875859816183
Trained batch 188 in epoch 7, gen_loss = 0.8255477634371904, disc_loss = 0.08584346238366038
Trained batch 189 in epoch 7, gen_loss = 0.8262819533285342, disc_loss = 0.09086294698185826
Trained batch 190 in epoch 7, gen_loss = 0.8285882664912658, disc_loss = 0.09388548157699601
Trained batch 191 in epoch 7, gen_loss = 0.8286323887296021, disc_loss = 0.09585824506454325
Trained batch 192 in epoch 7, gen_loss = 0.8293070550718455, disc_loss = 0.1017782461776403
Trained batch 193 in epoch 7, gen_loss = 0.8314075597475484, disc_loss = 0.10750581576133665
Trained batch 194 in epoch 7, gen_loss = 0.8316294369025108, disc_loss = 0.10924854498738662
Trained batch 195 in epoch 7, gen_loss = 0.8308346525442843, disc_loss = 0.11022305631610964
Trained batch 196 in epoch 7, gen_loss = 0.8295291285526935, disc_loss = 0.11095308189559255
Trained batch 197 in epoch 7, gen_loss = 0.8279923704838512, disc_loss = 0.11149134703751917
Trained batch 198 in epoch 7, gen_loss = 0.8268149056326803, disc_loss = 0.1121052460014895
Trained batch 199 in epoch 7, gen_loss = 0.8256055895984172, disc_loss = 0.11262674956116825
Trained batch 200 in epoch 7, gen_loss = 0.8242385172428777, disc_loss = 0.11307602956316512
Trained batch 201 in epoch 7, gen_loss = 0.8227783682027666, disc_loss = 0.1133714552719773
Trained batch 202 in epoch 7, gen_loss = 0.8210081117493766, disc_loss = 0.11387882317907264
Trained batch 203 in epoch 7, gen_loss = 0.8202295215690837, disc_loss = 0.11424609571786634
Trained batch 204 in epoch 7, gen_loss = 0.8192108602058596, disc_loss = 0.11457306617734636
Trained batch 205 in epoch 7, gen_loss = 0.818786034884962, disc_loss = 0.11463114726402372
Trained batch 206 in epoch 7, gen_loss = 0.818099190071585, disc_loss = 0.11475377380937914
Trained batch 207 in epoch 7, gen_loss = 0.8173815567906086, disc_loss = 0.1149191671418241
Trained batch 208 in epoch 7, gen_loss = 0.8163060645737716, disc_loss = 0.11521976172442784
Trained batch 209 in epoch 7, gen_loss = 0.815139947618757, disc_loss = 0.11561350778543523
Trained batch 210 in epoch 7, gen_loss = 0.8139175363061553, disc_loss = 0.11601822832555143
Trained batch 211 in epoch 7, gen_loss = 0.8132983859417573, disc_loss = 0.1161294180135471
Trained batch 212 in epoch 7, gen_loss = 0.8121236699847548, disc_loss = 0.11645790975226063
Trained batch 213 in epoch 7, gen_loss = 0.8103106434100142, disc_loss = 0.11677549283725218
Trained batch 214 in epoch 7, gen_loss = 0.8093223624451216, disc_loss = 0.11722666093169949
Trained batch 215 in epoch 7, gen_loss = 0.808965919746293, disc_loss = 0.11750434448131947
Trained batch 216 in epoch 7, gen_loss = 0.8085814346366215, disc_loss = 0.11740300401375728
Trained batch 217 in epoch 7, gen_loss = 0.8073844937009549, disc_loss = 0.11791512662749909
Trained batch 218 in epoch 7, gen_loss = 0.8073159850895677, disc_loss = 0.11784992314722031
Trained batch 219 in epoch 7, gen_loss = 0.806864520907402, disc_loss = 0.11797626694579694
Trained batch 220 in epoch 7, gen_loss = 0.8064311192585871, disc_loss = 0.11782653989245044
Trained batch 221 in epoch 7, gen_loss = 0.8065822967537889, disc_loss = 0.11768474045989884
Trained batch 222 in epoch 7, gen_loss = 0.8064624461357903, disc_loss = 0.11771715377695491
Trained batch 223 in epoch 7, gen_loss = 0.8048564799662147, disc_loss = 0.11815062506606669
Trained batch 224 in epoch 7, gen_loss = 0.8058340483241611, disc_loss = 0.11799470433344443
Trained batch 225 in epoch 7, gen_loss = 0.8061953579957506, disc_loss = 0.11778725326407403
Trained batch 226 in epoch 7, gen_loss = 0.8060355987317762, disc_loss = 0.11762584429562485
Trained batch 227 in epoch 7, gen_loss = 0.8056605690926836, disc_loss = 0.11736112125953169
Trained batch 228 in epoch 7, gen_loss = 0.8055259845662845, disc_loss = 0.11728082618810334
Trained batch 229 in epoch 7, gen_loss = 0.8053458926470384, disc_loss = 0.11724065281855671
Trained batch 230 in epoch 7, gen_loss = 0.8048234300695972, disc_loss = 0.11716457916367234
Trained batch 231 in epoch 7, gen_loss = 0.8051976582099651, disc_loss = 0.11701848061257523
Trained batch 232 in epoch 7, gen_loss = 0.8047168160201142, disc_loss = 0.1167934864575579
Trained batch 233 in epoch 7, gen_loss = 0.8044776919051113, disc_loss = 0.1164667132931451
Trained batch 234 in epoch 7, gen_loss = 0.8047182176975494, disc_loss = 0.11630177558498814
Trained batch 235 in epoch 7, gen_loss = 0.8051716445361153, disc_loss = 0.11646834006769803
Trained batch 236 in epoch 7, gen_loss = 0.8036972895453248, disc_loss = 0.11705853884748894
Trained batch 237 in epoch 7, gen_loss = 0.8041449136593762, disc_loss = 0.1168368782793336
Trained batch 238 in epoch 7, gen_loss = 0.8033904647727391, disc_loss = 0.11719164137327147
Trained batch 239 in epoch 7, gen_loss = 0.8023774998883406, disc_loss = 0.11741479483510678
Trained batch 240 in epoch 7, gen_loss = 0.8022856707394865, disc_loss = 0.11725147412046481
Trained batch 241 in epoch 7, gen_loss = 0.8012518025626821, disc_loss = 0.11723072516293195
Trained batch 242 in epoch 7, gen_loss = 0.8010802158602962, disc_loss = 0.11705225093267214
Trained batch 243 in epoch 7, gen_loss = 0.8003186693445581, disc_loss = 0.11705506657494506
Trained batch 244 in epoch 7, gen_loss = 0.8001080724657799, disc_loss = 0.11738622009526102
Trained batch 245 in epoch 7, gen_loss = 0.8005576792771254, disc_loss = 0.1170690794157364
Trained batch 246 in epoch 7, gen_loss = 0.8001113934555517, disc_loss = 0.11683658049309906
Trained batch 247 in epoch 7, gen_loss = 0.7995024330673679, disc_loss = 0.11709966613054876
Trained batch 248 in epoch 7, gen_loss = 0.8000060607151813, disc_loss = 0.11774206311483101
Trained batch 249 in epoch 7, gen_loss = 0.7989336206912995, disc_loss = 0.11801412719860672
Trained batch 250 in epoch 7, gen_loss = 0.7982785777741694, disc_loss = 0.11786092245261151
Trained batch 251 in epoch 7, gen_loss = 0.7994000069678776, disc_loss = 0.11774755083394074
Trained batch 252 in epoch 7, gen_loss = 0.7992992893509243, disc_loss = 0.11757717764910619
Trained batch 253 in epoch 7, gen_loss = 0.7993100543660442, disc_loss = 0.11722066723118264
Trained batch 254 in epoch 7, gen_loss = 0.7990292803913939, disc_loss = 0.11696313463662769
Trained batch 255 in epoch 7, gen_loss = 0.7993262002710253, disc_loss = 0.11657897067561862
Trained batch 256 in epoch 7, gen_loss = 0.7993180320420618, disc_loss = 0.11660432156378309
Trained batch 257 in epoch 7, gen_loss = 0.798284136047659, disc_loss = 0.11696407934217605
Trained batch 258 in epoch 7, gen_loss = 0.797894362317089, disc_loss = 0.1168748381004658
Trained batch 259 in epoch 7, gen_loss = 0.7983839997878441, disc_loss = 0.11696540078936288
Trained batch 260 in epoch 7, gen_loss = 0.7985184078472327, disc_loss = 0.11663453969248068
Trained batch 261 in epoch 7, gen_loss = 0.7988624440804692, disc_loss = 0.11637324021190747
Trained batch 262 in epoch 7, gen_loss = 0.7984184473186391, disc_loss = 0.11630605671469817
Trained batch 263 in epoch 7, gen_loss = 0.7975260527296499, disc_loss = 0.11656856683971868
Trained batch 264 in epoch 7, gen_loss = 0.7991135576985917, disc_loss = 0.11680495328849778
Trained batch 265 in epoch 7, gen_loss = 0.7984843861339683, disc_loss = 0.1169193608343209
Trained batch 266 in epoch 7, gen_loss = 0.7982993820186858, disc_loss = 0.11684677981830827
Trained batch 267 in epoch 7, gen_loss = 0.7974763074472769, disc_loss = 0.11697533888283616
Trained batch 268 in epoch 7, gen_loss = 0.797327659165549, disc_loss = 0.11667355948013555
Trained batch 269 in epoch 7, gen_loss = 0.7969567864029495, disc_loss = 0.1165196575258893
Trained batch 270 in epoch 7, gen_loss = 0.7965946591208342, disc_loss = 0.11638869084349088
Trained batch 271 in epoch 7, gen_loss = 0.7963622795308337, disc_loss = 0.11634711094323874
Trained batch 272 in epoch 7, gen_loss = 0.7967262883762737, disc_loss = 0.116233909335465
Trained batch 273 in epoch 7, gen_loss = 0.7959050618819077, disc_loss = 0.11623674933288763
Trained batch 274 in epoch 7, gen_loss = 0.7958934007991444, disc_loss = 0.11596176158636809
Trained batch 275 in epoch 7, gen_loss = 0.7955184807811958, disc_loss = 0.11617030765172905
Trained batch 276 in epoch 7, gen_loss = 0.7960057680357234, disc_loss = 0.11588752216286285
Trained batch 277 in epoch 7, gen_loss = 0.7961201774988244, disc_loss = 0.11558524912169618
Trained batch 278 in epoch 7, gen_loss = 0.7955203784836663, disc_loss = 0.11540766134123755
Trained batch 279 in epoch 7, gen_loss = 0.7962011301091739, disc_loss = 0.1151710243396727
Trained batch 280 in epoch 7, gen_loss = 0.7953426157028225, disc_loss = 0.11515050047670501
Trained batch 281 in epoch 7, gen_loss = 0.7965333806284776, disc_loss = 0.11506255573744997
Trained batch 282 in epoch 7, gen_loss = 0.7963252431933534, disc_loss = 0.11496777727528616
Trained batch 283 in epoch 7, gen_loss = 0.7953231215057238, disc_loss = 0.1150045464713861
Trained batch 284 in epoch 7, gen_loss = 0.7955643373623229, disc_loss = 0.1148243480378337
Trained batch 285 in epoch 7, gen_loss = 0.7955572411313757, disc_loss = 0.11476059636049024
Trained batch 286 in epoch 7, gen_loss = 0.7953453967380192, disc_loss = 0.11467477505643713
Trained batch 287 in epoch 7, gen_loss = 0.7955780078967413, disc_loss = 0.11450359401512994
Trained batch 288 in epoch 7, gen_loss = 0.7954738373162424, disc_loss = 0.11431944074115642
Trained batch 289 in epoch 7, gen_loss = 0.7954554257721737, disc_loss = 0.11402204300373278
Trained batch 290 in epoch 7, gen_loss = 0.7959209909963444, disc_loss = 0.11380979614940398
Trained batch 291 in epoch 7, gen_loss = 0.7956268542433438, disc_loss = 0.11359454559047438
Trained batch 292 in epoch 7, gen_loss = 0.7954230935093486, disc_loss = 0.11334531621072988
Trained batch 293 in epoch 7, gen_loss = 0.7960965854375541, disc_loss = 0.1130576084849431
Trained batch 294 in epoch 7, gen_loss = 0.7957857956320552, disc_loss = 0.11299621417676493
Trained batch 295 in epoch 7, gen_loss = 0.7964501656793259, disc_loss = 0.11290751194040216
Trained batch 296 in epoch 7, gen_loss = 0.7963157382477012, disc_loss = 0.11273448458035486
Trained batch 297 in epoch 7, gen_loss = 0.7961292862892151, disc_loss = 0.112577657199671
Trained batch 298 in epoch 7, gen_loss = 0.7967568554208431, disc_loss = 0.11249769723547443
Trained batch 299 in epoch 7, gen_loss = 0.7967210406064987, disc_loss = 0.11222741158368686
Trained batch 300 in epoch 7, gen_loss = 0.796983275896687, disc_loss = 0.11213067972543726
Trained batch 301 in epoch 7, gen_loss = 0.7960622699450184, disc_loss = 0.11235295469558101
Trained batch 302 in epoch 7, gen_loss = 0.7958240398872803, disc_loss = 0.11262740048798102
Trained batch 303 in epoch 7, gen_loss = 0.7969782105401942, disc_loss = 0.11273650155022838
Trained batch 304 in epoch 7, gen_loss = 0.7964806005602977, disc_loss = 0.11286427111471774
Trained batch 305 in epoch 7, gen_loss = 0.7960421053412693, disc_loss = 0.11279393726765038
Trained batch 306 in epoch 7, gen_loss = 0.7968515879944792, disc_loss = 0.11277829883893169
Trained batch 307 in epoch 7, gen_loss = 0.7968423879378802, disc_loss = 0.11264394109088977
Trained batch 308 in epoch 7, gen_loss = 0.7965826295726122, disc_loss = 0.11250331384524655
Trained batch 309 in epoch 7, gen_loss = 0.7961616377676687, disc_loss = 0.11246768071826908
Trained batch 310 in epoch 7, gen_loss = 0.796365016526348, disc_loss = 0.1124322077475033
Trained batch 311 in epoch 7, gen_loss = 0.7961492794446456, disc_loss = 0.11225494760602044
Trained batch 312 in epoch 7, gen_loss = 0.7959521513777419, disc_loss = 0.11219007247231734
Trained batch 313 in epoch 7, gen_loss = 0.795626285729135, disc_loss = 0.11205393243521737
Trained batch 314 in epoch 7, gen_loss = 0.7958042892198715, disc_loss = 0.11184071784040757
Trained batch 315 in epoch 7, gen_loss = 0.795364177868336, disc_loss = 0.11164457562285228
Trained batch 316 in epoch 7, gen_loss = 0.794678325720766, disc_loss = 0.11161194766698293
Trained batch 317 in epoch 7, gen_loss = 0.7952323700272063, disc_loss = 0.11161773861825185
Trained batch 318 in epoch 7, gen_loss = 0.7953828946923761, disc_loss = 0.11168571240721172
Trained batch 319 in epoch 7, gen_loss = 0.7945526044815778, disc_loss = 0.11236278870201204
Trained batch 320 in epoch 7, gen_loss = 0.7943975639491809, disc_loss = 0.11223593729365373
Trained batch 321 in epoch 7, gen_loss = 0.7939879846128618, disc_loss = 0.11229691287988554
Trained batch 322 in epoch 7, gen_loss = 0.7940865723710311, disc_loss = 0.11248366981341097
Trained batch 323 in epoch 7, gen_loss = 0.7932758528141328, disc_loss = 0.11260071699507535
Trained batch 324 in epoch 7, gen_loss = 0.7923723964507763, disc_loss = 0.11291963631430497
Trained batch 325 in epoch 7, gen_loss = 0.7931438105786505, disc_loss = 0.11324925180467452
Trained batch 326 in epoch 7, gen_loss = 0.7928887901867566, disc_loss = 0.11312952290491318
Trained batch 327 in epoch 7, gen_loss = 0.7924656018433047, disc_loss = 0.11307467996404029
Trained batch 328 in epoch 7, gen_loss = 0.7924042939233925, disc_loss = 0.11299218875172018
Trained batch 329 in epoch 7, gen_loss = 0.7916073801842602, disc_loss = 0.11306872019318469
Trained batch 330 in epoch 7, gen_loss = 0.7942157759587211, disc_loss = 0.11382818828953087
Trained batch 331 in epoch 7, gen_loss = 0.7939409623483578, disc_loss = 0.11374063048433199
Trained batch 332 in epoch 7, gen_loss = 0.7939501949795732, disc_loss = 0.11352655488729209
Trained batch 333 in epoch 7, gen_loss = 0.793963500750279, disc_loss = 0.11353582594666385
Trained batch 334 in epoch 7, gen_loss = 0.7940631447443322, disc_loss = 0.11330639268758137
Trained batch 335 in epoch 7, gen_loss = 0.7940340490036067, disc_loss = 0.11305388705416893
Trained batch 336 in epoch 7, gen_loss = 0.7945835463901656, disc_loss = 0.11297153240727477
Trained batch 337 in epoch 7, gen_loss = 0.7940417894068554, disc_loss = 0.11306968259972316
Trained batch 338 in epoch 7, gen_loss = 0.7945402926575821, disc_loss = 0.11305290846577172
Trained batch 339 in epoch 7, gen_loss = 0.794219645068926, disc_loss = 0.1129266859333524
Trained batch 340 in epoch 7, gen_loss = 0.7940796810336127, disc_loss = 0.11275557165588539
Trained batch 341 in epoch 7, gen_loss = 0.7941922518419243, disc_loss = 0.11319596805386463
Trained batch 342 in epoch 7, gen_loss = 0.79356080841045, disc_loss = 0.11314206910604725
Trained batch 343 in epoch 7, gen_loss = 0.7938384295029696, disc_loss = 0.11304226382581387
Trained batch 344 in epoch 7, gen_loss = 0.793794937669367, disc_loss = 0.11303397077203228
Trained batch 345 in epoch 7, gen_loss = 0.7933636901178801, disc_loss = 0.11284483720769169
Trained batch 346 in epoch 7, gen_loss = 0.7928728455253569, disc_loss = 0.11271307992370483
Trained batch 347 in epoch 7, gen_loss = 0.7923054964891796, disc_loss = 0.11256926037082128
Trained batch 348 in epoch 7, gen_loss = 0.7932952433226785, disc_loss = 0.1125366488514324
Trained batch 349 in epoch 7, gen_loss = 0.7933537223509379, disc_loss = 0.11235269977844187
Trained batch 350 in epoch 7, gen_loss = 0.7931541025298953, disc_loss = 0.11226364814456118
Trained batch 351 in epoch 7, gen_loss = 0.7930357414721088, disc_loss = 0.11205266007825478
Trained batch 352 in epoch 7, gen_loss = 0.7932554666617775, disc_loss = 0.1119199099715683
Trained batch 353 in epoch 7, gen_loss = 0.7934858897479914, disc_loss = 0.11184176649256362
Trained batch 354 in epoch 7, gen_loss = 0.7927459979561013, disc_loss = 0.11181800691017382
Trained batch 355 in epoch 7, gen_loss = 0.7927881677666407, disc_loss = 0.11160052247774484
Trained batch 356 in epoch 7, gen_loss = 0.7925547509133315, disc_loss = 0.11139624509751714
Trained batch 357 in epoch 7, gen_loss = 0.7930567488490536, disc_loss = 0.11148293978435783
Trained batch 358 in epoch 7, gen_loss = 0.7924641655514167, disc_loss = 0.11151862638667849
Trained batch 359 in epoch 7, gen_loss = 0.7924789694448312, disc_loss = 0.11131611188304508
Trained batch 360 in epoch 7, gen_loss = 0.7922177180193798, disc_loss = 0.11121391857151262
Trained batch 361 in epoch 7, gen_loss = 0.7919029032821814, disc_loss = 0.11106984371072433
Trained batch 362 in epoch 7, gen_loss = 0.7926330398101123, disc_loss = 0.11084538902676877
Trained batch 363 in epoch 7, gen_loss = 0.7916826588603166, disc_loss = 0.11104093794199218
Trained batch 364 in epoch 7, gen_loss = 0.7928872404849693, disc_loss = 0.11135325455553319
Trained batch 365 in epoch 7, gen_loss = 0.7930350130210158, disc_loss = 0.11114133458045092
Trained batch 366 in epoch 7, gen_loss = 0.7930717230330371, disc_loss = 0.11098629574491883
Trained batch 367 in epoch 7, gen_loss = 0.7924956992754469, disc_loss = 0.11095473946973114
Trained batch 368 in epoch 7, gen_loss = 0.7924563032663289, disc_loss = 0.11082935877659214
Trained batch 369 in epoch 7, gen_loss = 0.793064482228176, disc_loss = 0.11087664735528666
Trained batch 370 in epoch 7, gen_loss = 0.7922217264329648, disc_loss = 0.11138614674031011
Trained batch 371 in epoch 7, gen_loss = 0.7929376764323122, disc_loss = 0.11168699574616728
Trained batch 372 in epoch 7, gen_loss = 0.792113288477982, disc_loss = 0.11194171725794792
Trained batch 373 in epoch 7, gen_loss = 0.7918908489260444, disc_loss = 0.1122611888515001
Trained batch 374 in epoch 7, gen_loss = 0.791454176902771, disc_loss = 0.11217345419774453
Trained batch 375 in epoch 7, gen_loss = 0.7913352054484347, disc_loss = 0.11202263080346536
Trained batch 376 in epoch 7, gen_loss = 0.7908176344965118, disc_loss = 0.11207934341761494
Trained batch 377 in epoch 7, gen_loss = 0.7915094643042832, disc_loss = 0.11188063044445934
Trained batch 378 in epoch 7, gen_loss = 0.7916108805460162, disc_loss = 0.11165491862365076
Trained batch 379 in epoch 7, gen_loss = 0.7913894872916373, disc_loss = 0.11149495568763661
Trained batch 380 in epoch 7, gen_loss = 0.791362128545606, disc_loss = 0.11128494754834516
Trained batch 381 in epoch 7, gen_loss = 0.7912388684237814, disc_loss = 0.11120576599944403
Trained batch 382 in epoch 7, gen_loss = 0.7909472410423637, disc_loss = 0.11113383853686463
Trained batch 383 in epoch 7, gen_loss = 0.7918954875009755, disc_loss = 0.11116485040838597
Trained batch 384 in epoch 7, gen_loss = 0.7912877771761511, disc_loss = 0.11123815975454333
Trained batch 385 in epoch 7, gen_loss = 0.7914667696223976, disc_loss = 0.11105836472604327
Trained batch 386 in epoch 7, gen_loss = 0.7920804447289893, disc_loss = 0.11082265187940471
Trained batch 387 in epoch 7, gen_loss = 0.7919969497267733, disc_loss = 0.1107391724146941
Trained batch 388 in epoch 7, gen_loss = 0.7916112698442219, disc_loss = 0.11076029024989485
Trained batch 389 in epoch 7, gen_loss = 0.7919369488190382, disc_loss = 0.11064967737318232
Trained batch 390 in epoch 7, gen_loss = 0.7922305739139353, disc_loss = 0.11041288077116698
Trained batch 391 in epoch 7, gen_loss = 0.7923353878515107, disc_loss = 0.11054073687766355
Trained batch 392 in epoch 7, gen_loss = 0.7923753713530135, disc_loss = 0.11031486821282684
Trained batch 393 in epoch 7, gen_loss = 0.7917108806559277, disc_loss = 0.11037417984600675
Trained batch 394 in epoch 7, gen_loss = 0.7915850251535826, disc_loss = 0.11021886418184525
Trained batch 395 in epoch 7, gen_loss = 0.7923379177697981, disc_loss = 0.1101257173706674
Trained batch 396 in epoch 7, gen_loss = 0.7924032206799582, disc_loss = 0.1099449657584055
Trained batch 397 in epoch 7, gen_loss = 0.7925169891747997, disc_loss = 0.10970164860491102
Trained batch 398 in epoch 7, gen_loss = 0.7919430805925738, disc_loss = 0.1098180825058791
Trained batch 399 in epoch 7, gen_loss = 0.7926468561589718, disc_loss = 0.10969480481697247
Trained batch 400 in epoch 7, gen_loss = 0.7928503580818747, disc_loss = 0.10954626243412867
Trained batch 401 in epoch 7, gen_loss = 0.7927088384604573, disc_loss = 0.10934776812560153
Trained batch 402 in epoch 7, gen_loss = 0.7925611394214866, disc_loss = 0.10914573741489768
Trained batch 403 in epoch 7, gen_loss = 0.7920777687046787, disc_loss = 0.10920389382731133
Trained batch 404 in epoch 7, gen_loss = 0.7927161992332081, disc_loss = 0.10907366568061673
Trained batch 405 in epoch 7, gen_loss = 0.7926382544299064, disc_loss = 0.10951010653235276
Trained batch 406 in epoch 7, gen_loss = 0.7920268992241243, disc_loss = 0.10963764528375512
Trained batch 407 in epoch 7, gen_loss = 0.7919701044173801, disc_loss = 0.10956404951410185
Trained batch 408 in epoch 7, gen_loss = 0.791423781139635, disc_loss = 0.10959899157495182
Trained batch 409 in epoch 7, gen_loss = 0.7918287854369094, disc_loss = 0.10971840636168674
Trained batch 410 in epoch 7, gen_loss = 0.7920193293668928, disc_loss = 0.10954219654628468
Trained batch 411 in epoch 7, gen_loss = 0.7919341126113262, disc_loss = 0.10942198606253177
Trained batch 412 in epoch 7, gen_loss = 0.7919639402382599, disc_loss = 0.1093141427083216
Trained batch 413 in epoch 7, gen_loss = 0.7926640549431676, disc_loss = 0.10912121801101715
Trained batch 414 in epoch 7, gen_loss = 0.7928888345339212, disc_loss = 0.1089312819404954
Trained batch 415 in epoch 7, gen_loss = 0.7930143832300718, disc_loss = 0.10869618792024155
Trained batch 416 in epoch 7, gen_loss = 0.7931552809491146, disc_loss = 0.10850548468824985
Trained batch 417 in epoch 7, gen_loss = 0.7931450073513688, disc_loss = 0.10834928648100729
Trained batch 418 in epoch 7, gen_loss = 0.7930558579918309, disc_loss = 0.10824451036973542
Trained batch 419 in epoch 7, gen_loss = 0.7933466100976581, disc_loss = 0.10801351152227394
Trained batch 420 in epoch 7, gen_loss = 0.7936945097463431, disc_loss = 0.10781453689892119
Trained batch 421 in epoch 7, gen_loss = 0.7931906569625529, disc_loss = 0.10771471472298152
Trained batch 422 in epoch 7, gen_loss = 0.7934827642519705, disc_loss = 0.10757239475784643
Trained batch 423 in epoch 7, gen_loss = 0.7931382612518545, disc_loss = 0.1075341192201518
Trained batch 424 in epoch 7, gen_loss = 0.7940007713261773, disc_loss = 0.1073529636312057
Trained batch 425 in epoch 7, gen_loss = 0.7948496754460491, disc_loss = 0.10714863722339413
Trained batch 426 in epoch 7, gen_loss = 0.7948323788352537, disc_loss = 0.10694348541430833
Trained batch 427 in epoch 7, gen_loss = 0.7948814715458968, disc_loss = 0.1067895353967585
Trained batch 428 in epoch 7, gen_loss = 0.7950981281576179, disc_loss = 0.10656858259694768
Trained batch 429 in epoch 7, gen_loss = 0.795157388060592, disc_loss = 0.10637222067344673
Trained batch 430 in epoch 7, gen_loss = 0.7954920793077509, disc_loss = 0.10615652769786714
Trained batch 431 in epoch 7, gen_loss = 0.7960660347232112, disc_loss = 0.10596396932723345
Trained batch 432 in epoch 7, gen_loss = 0.7963001678502036, disc_loss = 0.10579235883597414
Trained batch 433 in epoch 7, gen_loss = 0.7958887507838588, disc_loss = 0.10582056863894386
Trained batch 434 in epoch 7, gen_loss = 0.7969778170530823, disc_loss = 0.10593219840492325
Trained batch 435 in epoch 7, gen_loss = 0.7972430668839621, disc_loss = 0.10571208201058277
Trained batch 436 in epoch 7, gen_loss = 0.7968716236764833, disc_loss = 0.1057068747287143
Trained batch 437 in epoch 7, gen_loss = 0.7968235911299649, disc_loss = 0.10551801805711908
Trained batch 438 in epoch 7, gen_loss = 0.7962627307700676, disc_loss = 0.10543875963531078
Trained batch 439 in epoch 7, gen_loss = 0.7964241389523853, disc_loss = 0.10543275547044521
Trained batch 440 in epoch 7, gen_loss = 0.7959191123374195, disc_loss = 0.10566535241090927
Trained batch 441 in epoch 7, gen_loss = 0.795176790041082, disc_loss = 0.10617601817971037
Trained batch 442 in epoch 7, gen_loss = 0.794965629383888, disc_loss = 0.10614142185560602
Trained batch 443 in epoch 7, gen_loss = 0.7953345883000005, disc_loss = 0.10607223795424844
Trained batch 444 in epoch 7, gen_loss = 0.7952080967720975, disc_loss = 0.10603840887295396
Trained batch 445 in epoch 7, gen_loss = 0.7951503935950754, disc_loss = 0.10600737477715373
Trained batch 446 in epoch 7, gen_loss = 0.7944917864180785, disc_loss = 0.10609849826151492
Trained batch 447 in epoch 7, gen_loss = 0.794768564136965, disc_loss = 0.10596082404871206
Trained batch 448 in epoch 7, gen_loss = 0.7948409565838515, disc_loss = 0.10577716745170693
Trained batch 449 in epoch 7, gen_loss = 0.794909854862425, disc_loss = 0.10564994915078084
Trained batch 450 in epoch 7, gen_loss = 0.795580123189812, disc_loss = 0.105727819345908
Trained batch 451 in epoch 7, gen_loss = 0.7948245377799051, disc_loss = 0.10616984370420068
Trained batch 452 in epoch 7, gen_loss = 0.7955382573551952, disc_loss = 0.1061651763972923
Trained batch 453 in epoch 7, gen_loss = 0.7956920408598652, disc_loss = 0.10611689928098528
Trained batch 454 in epoch 7, gen_loss = 0.7954193005850027, disc_loss = 0.10608848974026822
Trained batch 455 in epoch 7, gen_loss = 0.7955952489977343, disc_loss = 0.10598901301834798
Trained batch 456 in epoch 7, gen_loss = 0.7952342984843306, disc_loss = 0.10595837001091672
Trained batch 457 in epoch 7, gen_loss = 0.7946494562006413, disc_loss = 0.10595673742789499
Trained batch 458 in epoch 7, gen_loss = 0.7947961647136539, disc_loss = 0.10591774877396154
Trained batch 459 in epoch 7, gen_loss = 0.7950995627304782, disc_loss = 0.1058854002384064
Trained batch 460 in epoch 7, gen_loss = 0.7949714947031273, disc_loss = 0.10583832247865563
Trained batch 461 in epoch 7, gen_loss = 0.7948683876366842, disc_loss = 0.10567633443596688
Trained batch 462 in epoch 7, gen_loss = 0.7952721192950049, disc_loss = 0.10578416449220984
Trained batch 463 in epoch 7, gen_loss = 0.7948203682257183, disc_loss = 0.10574373905145532
Trained batch 464 in epoch 7, gen_loss = 0.7946636779974866, disc_loss = 0.10564295586639194
Trained batch 465 in epoch 7, gen_loss = 0.7953560938778865, disc_loss = 0.10552406050824428
Trained batch 466 in epoch 7, gen_loss = 0.795647376418369, disc_loss = 0.1053771648428361
Trained batch 467 in epoch 7, gen_loss = 0.7951799987090958, disc_loss = 0.10533644654987077
Trained batch 468 in epoch 7, gen_loss = 0.7955354996708665, disc_loss = 0.10515621092035445
Trained batch 469 in epoch 7, gen_loss = 0.7951181200590539, disc_loss = 0.10509969730405731
Trained batch 470 in epoch 7, gen_loss = 0.7948774541639219, disc_loss = 0.10496214186800387
Trained batch 471 in epoch 7, gen_loss = 0.7947517413077718, disc_loss = 0.10482873532021324
Trained batch 472 in epoch 7, gen_loss = 0.7954322018406608, disc_loss = 0.10484832609918984
Trained batch 473 in epoch 7, gen_loss = 0.7958392394620155, disc_loss = 0.10466376798549659
Trained batch 474 in epoch 7, gen_loss = 0.7953912428178286, disc_loss = 0.10482212649756356
Trained batch 475 in epoch 7, gen_loss = 0.7956375204840628, disc_loss = 0.1046247112744746
Trained batch 476 in epoch 7, gen_loss = 0.7956426305465978, disc_loss = 0.10447009933226013
Trained batch 477 in epoch 7, gen_loss = 0.7957154221240447, disc_loss = 0.10454762702862339
Trained batch 478 in epoch 7, gen_loss = 0.7960697270012101, disc_loss = 0.10442689848997648
Trained batch 479 in epoch 7, gen_loss = 0.7954806522155802, disc_loss = 0.10476223283912986
Trained batch 480 in epoch 7, gen_loss = 0.7963932748272117, disc_loss = 0.10513185188484044
Trained batch 481 in epoch 7, gen_loss = 0.7961622527897111, disc_loss = 0.10505153440495497
Trained batch 482 in epoch 7, gen_loss = 0.7957411020315459, disc_loss = 0.10515469850251147
Trained batch 483 in epoch 7, gen_loss = 0.7964060139680696, disc_loss = 0.10520682213751
Trained batch 484 in epoch 7, gen_loss = 0.7963944771240667, disc_loss = 0.1051730920743082
Trained batch 485 in epoch 7, gen_loss = 0.7960976676808463, disc_loss = 0.10519392735520262
Trained batch 486 in epoch 7, gen_loss = 0.7959219641386851, disc_loss = 0.10516268497589187
Trained batch 487 in epoch 7, gen_loss = 0.7959034239537404, disc_loss = 0.1052514880697136
Trained batch 488 in epoch 7, gen_loss = 0.7960626954071849, disc_loss = 0.10511094568666748
Trained batch 489 in epoch 7, gen_loss = 0.7956965645357054, disc_loss = 0.10512705143465072
Trained batch 490 in epoch 7, gen_loss = 0.7955395337156269, disc_loss = 0.10505419988526589
Trained batch 491 in epoch 7, gen_loss = 0.7960367836966747, disc_loss = 0.10500941923024451
Trained batch 492 in epoch 7, gen_loss = 0.7958698261219396, disc_loss = 0.10488722729543885
Trained batch 493 in epoch 7, gen_loss = 0.7960532916340268, disc_loss = 0.10475566220820433
Trained batch 494 in epoch 7, gen_loss = 0.7960581373084675, disc_loss = 0.10464521897110073
Trained batch 495 in epoch 7, gen_loss = 0.7959612901773183, disc_loss = 0.10448659274862299
Trained batch 496 in epoch 7, gen_loss = 0.7965586776104971, disc_loss = 0.10458510379930977
Trained batch 497 in epoch 7, gen_loss = 0.7966758553163115, disc_loss = 0.10441393578372686
Trained batch 498 in epoch 7, gen_loss = 0.7967987618967144, disc_loss = 0.10425142458974121
Trained batch 499 in epoch 7, gen_loss = 0.7973549928069115, disc_loss = 0.10408964690938592
Trained batch 500 in epoch 7, gen_loss = 0.7970992107234315, disc_loss = 0.10402123743441409
Trained batch 501 in epoch 7, gen_loss = 0.7974946478092338, disc_loss = 0.10384111115115276
Trained batch 502 in epoch 7, gen_loss = 0.7977204207279099, disc_loss = 0.10367917352972578
Trained batch 503 in epoch 7, gen_loss = 0.7980917326159893, disc_loss = 0.10372640339413747
Trained batch 504 in epoch 7, gen_loss = 0.7977885754391698, disc_loss = 0.10377368867065352
Trained batch 505 in epoch 7, gen_loss = 0.7976104416277098, disc_loss = 0.10365628262451691
Trained batch 506 in epoch 7, gen_loss = 0.798298722834747, disc_loss = 0.10359087833102344
Trained batch 507 in epoch 7, gen_loss = 0.7981345806652167, disc_loss = 0.1035730162631779
Trained batch 508 in epoch 7, gen_loss = 0.7980283372879965, disc_loss = 0.10347892546546893
Trained batch 509 in epoch 7, gen_loss = 0.7981777764418546, disc_loss = 0.10333922782036312
Trained batch 510 in epoch 7, gen_loss = 0.7978546540681163, disc_loss = 0.10324784323624144
Trained batch 511 in epoch 7, gen_loss = 0.7982771830284037, disc_loss = 0.10312284404608363
Trained batch 512 in epoch 7, gen_loss = 0.7990797579753236, disc_loss = 0.10317733864069392
Trained batch 513 in epoch 7, gen_loss = 0.7987464591570865, disc_loss = 0.10315384452524758
Trained batch 514 in epoch 7, gen_loss = 0.7986040618234468, disc_loss = 0.10306946307384562
Trained batch 515 in epoch 7, gen_loss = 0.7992722295628961, disc_loss = 0.10300744979555697
Trained batch 516 in epoch 7, gen_loss = 0.7993942835229508, disc_loss = 0.10294958383270054
Trained batch 517 in epoch 7, gen_loss = 0.7989805947744708, disc_loss = 0.10320928050420862
Trained batch 518 in epoch 7, gen_loss = 0.7992329890902562, disc_loss = 0.10307707971137785
Trained batch 519 in epoch 7, gen_loss = 0.7990375620241349, disc_loss = 0.10304467169961963
Trained batch 520 in epoch 7, gen_loss = 0.799035536064525, disc_loss = 0.10302383237252023
Trained batch 521 in epoch 7, gen_loss = 0.7989892972726018, disc_loss = 0.10290673549083629
Trained batch 522 in epoch 7, gen_loss = 0.7990842812033958, disc_loss = 0.10273426882993879
Trained batch 523 in epoch 7, gen_loss = 0.7987816686962397, disc_loss = 0.10267515893570567
Trained batch 524 in epoch 7, gen_loss = 0.7994734530789511, disc_loss = 0.10269253805279732
Trained batch 525 in epoch 7, gen_loss = 0.7997274621471253, disc_loss = 0.10251242847327044
Trained batch 526 in epoch 7, gen_loss = 0.799601593381766, disc_loss = 0.10246161686740744
Trained batch 527 in epoch 7, gen_loss = 0.7999442306093194, disc_loss = 0.10235136348020399
Trained batch 528 in epoch 7, gen_loss = 0.7996566300694118, disc_loss = 0.10228077437735686
Trained batch 529 in epoch 7, gen_loss = 0.799575962266832, disc_loss = 0.10217819483775013
Trained batch 530 in epoch 7, gen_loss = 0.7996726077042955, disc_loss = 0.10210752962841152
Trained batch 531 in epoch 7, gen_loss = 0.8001622441679912, disc_loss = 0.10194357506461665
Trained batch 532 in epoch 7, gen_loss = 0.8002942890543875, disc_loss = 0.10179752023544644
Trained batch 533 in epoch 7, gen_loss = 0.8001719335380119, disc_loss = 0.10177760980221048
Trained batch 534 in epoch 7, gen_loss = 0.7998720851457007, disc_loss = 0.101705256189768
Trained batch 535 in epoch 7, gen_loss = 0.8006313417051265, disc_loss = 0.10157454315635528
Trained batch 536 in epoch 7, gen_loss = 0.8011764501615165, disc_loss = 0.10143577367296265
Trained batch 537 in epoch 7, gen_loss = 0.8015841640615109, disc_loss = 0.10132261278578616
Trained batch 538 in epoch 7, gen_loss = 0.8015000904756486, disc_loss = 0.1012304377014678
Trained batch 539 in epoch 7, gen_loss = 0.8015625460832208, disc_loss = 0.10121230950958475
Trained batch 540 in epoch 7, gen_loss = 0.8014301942478927, disc_loss = 0.10107226801137552
Trained batch 541 in epoch 7, gen_loss = 0.8015369498531757, disc_loss = 0.10092761922744532
Trained batch 542 in epoch 7, gen_loss = 0.8016070068760691, disc_loss = 0.10077124704567383
Trained batch 543 in epoch 7, gen_loss = 0.8021958115894128, disc_loss = 0.10105483937385383
Trained batch 544 in epoch 7, gen_loss = 0.8018715659959601, disc_loss = 0.10110024874944479
Trained batch 545 in epoch 7, gen_loss = 0.8017826510982199, disc_loss = 0.10104403026135904
Trained batch 546 in epoch 7, gen_loss = 0.8018695460921885, disc_loss = 0.10110492866241136
Trained batch 547 in epoch 7, gen_loss = 0.8019868534085525, disc_loss = 0.10094072671274036
Trained batch 548 in epoch 7, gen_loss = 0.8017625458579246, disc_loss = 0.1008756136189203
Trained batch 549 in epoch 7, gen_loss = 0.8018043587966399, disc_loss = 0.10073350922797214
Trained batch 550 in epoch 7, gen_loss = 0.8017064677500682, disc_loss = 0.10061105648512038
Trained batch 551 in epoch 7, gen_loss = 0.8025146330288355, disc_loss = 0.10053931863175408
Trained batch 552 in epoch 7, gen_loss = 0.802605107884726, disc_loss = 0.10042047784385856
Trained batch 553 in epoch 7, gen_loss = 0.8024753109965513, disc_loss = 0.10030975515049771
Trained batch 554 in epoch 7, gen_loss = 0.8023351825572349, disc_loss = 0.10021636549987503
Trained batch 555 in epoch 7, gen_loss = 0.802964553719373, disc_loss = 0.10028149929440332
Trained batch 556 in epoch 7, gen_loss = 0.8027472431291583, disc_loss = 0.10020535225399788
Trained batch 557 in epoch 7, gen_loss = 0.8026460685289889, disc_loss = 0.10014309471232756
Trained batch 558 in epoch 7, gen_loss = 0.8029044568538666, disc_loss = 0.09998079207067732
Trained batch 559 in epoch 7, gen_loss = 0.8035417091101408, disc_loss = 0.09985071719025394
Trained batch 560 in epoch 7, gen_loss = 0.8037558416313029, disc_loss = 0.09970094931250481
Trained batch 561 in epoch 7, gen_loss = 0.803771779471445, disc_loss = 0.09954418086039162
Trained batch 562 in epoch 7, gen_loss = 0.8037971842034883, disc_loss = 0.09944517130849363
Trained batch 563 in epoch 7, gen_loss = 0.8040812627960604, disc_loss = 0.09929275562729131
Trained batch 564 in epoch 7, gen_loss = 0.8046321883138302, disc_loss = 0.0991635157685496
Trained batch 565 in epoch 7, gen_loss = 0.804729490471813, disc_loss = 0.09900431327732419
Trained batch 566 in epoch 7, gen_loss = 0.8044855781228033, disc_loss = 0.09896380567965894
Trained batch 567 in epoch 7, gen_loss = 0.8050480939867631, disc_loss = 0.09881591934441838
Trained batch 568 in epoch 7, gen_loss = 0.8063431422509292, disc_loss = 0.09882656992732274
Trained batch 569 in epoch 7, gen_loss = 0.8063598032060423, disc_loss = 0.0986837049701104
Trained batch 570 in epoch 7, gen_loss = 0.8066324847905314, disc_loss = 0.09861032815320636
Trained batch 571 in epoch 7, gen_loss = 0.8065303404118631, disc_loss = 0.09850861226416915
Trained batch 572 in epoch 7, gen_loss = 0.8071214289877428, disc_loss = 0.09840087512472277
Trained batch 573 in epoch 7, gen_loss = 0.8077343054868619, disc_loss = 0.0982635192628236
Trained batch 574 in epoch 7, gen_loss = 0.807865133130032, disc_loss = 0.09811406568178664
Trained batch 575 in epoch 7, gen_loss = 0.8080383686659237, disc_loss = 0.09796139836867547
Trained batch 576 in epoch 7, gen_loss = 0.8084067588145852, disc_loss = 0.09780928836021721
Trained batch 577 in epoch 7, gen_loss = 0.8085137971235394, disc_loss = 0.09770481104102102
Trained batch 578 in epoch 7, gen_loss = 0.80833220867913, disc_loss = 0.09757003894908955
Trained batch 579 in epoch 7, gen_loss = 0.8085865069566102, disc_loss = 0.09741770839318634
Trained batch 580 in epoch 7, gen_loss = 0.8084369960935104, disc_loss = 0.0972760797281094
Trained batch 581 in epoch 7, gen_loss = 0.808481893025313, disc_loss = 0.09713302246899795
Trained batch 582 in epoch 7, gen_loss = 0.8091679840615438, disc_loss = 0.09705153767236765
Trained batch 583 in epoch 7, gen_loss = 0.8092675958696294, disc_loss = 0.09697404813997397
Trained batch 584 in epoch 7, gen_loss = 0.8093597962815537, disc_loss = 0.09683381131667103
Trained batch 585 in epoch 7, gen_loss = 0.8094211851879192, disc_loss = 0.0966875420950048
Trained batch 586 in epoch 7, gen_loss = 0.8099487126888977, disc_loss = 0.09656874981615217
Trained batch 587 in epoch 7, gen_loss = 0.8099487061504604, disc_loss = 0.0964220557995394
Trained batch 588 in epoch 7, gen_loss = 0.8098820490930198, disc_loss = 0.09628685159017356
Trained batch 589 in epoch 7, gen_loss = 0.8102378823494507, disc_loss = 0.09620323698273149
Trained batch 590 in epoch 7, gen_loss = 0.8104675775756287, disc_loss = 0.09605487314085973
Trained batch 591 in epoch 7, gen_loss = 0.8105330948994772, disc_loss = 0.09593038389308227
Trained batch 592 in epoch 7, gen_loss = 0.8103533004729382, disc_loss = 0.0958309292567118
Trained batch 593 in epoch 7, gen_loss = 0.810408119651605, disc_loss = 0.09573289679256754
Trained batch 594 in epoch 7, gen_loss = 0.8105729648546011, disc_loss = 0.09560145065188408
Trained batch 595 in epoch 7, gen_loss = 0.8107166040763759, disc_loss = 0.09548145105074717
Trained batch 596 in epoch 7, gen_loss = 0.8106133038774008, disc_loss = 0.09541010414211194
Trained batch 597 in epoch 7, gen_loss = 0.8107778109535325, disc_loss = 0.09548118490613623
Trained batch 598 in epoch 7, gen_loss = 0.8108804702062241, disc_loss = 0.09536437254604294
Trained batch 599 in epoch 7, gen_loss = 0.8108581999440988, disc_loss = 0.0952449541601042
Trained batch 600 in epoch 7, gen_loss = 0.8106654429693587, disc_loss = 0.09521202044484024
Trained batch 601 in epoch 7, gen_loss = 0.8109176394056244, disc_loss = 0.09513308479763147
Trained batch 602 in epoch 7, gen_loss = 0.8110274766906972, disc_loss = 0.09499518799705194
Trained batch 603 in epoch 7, gen_loss = 0.811191429809624, disc_loss = 0.09486024949193889
Trained batch 604 in epoch 7, gen_loss = 0.8111401950524858, disc_loss = 0.09478164816136696
Trained batch 605 in epoch 7, gen_loss = 0.8117064985603389, disc_loss = 0.09474156630646573
Trained batch 606 in epoch 7, gen_loss = 0.8123092182483862, disc_loss = 0.09462889431188684
Trained batch 607 in epoch 7, gen_loss = 0.8121426882418362, disc_loss = 0.0945691319525634
Trained batch 608 in epoch 7, gen_loss = 0.811960417893524, disc_loss = 0.09445923267693943
Trained batch 609 in epoch 7, gen_loss = 0.8119706386914018, disc_loss = 0.09439408599597508
Trained batch 610 in epoch 7, gen_loss = 0.8119663472749208, disc_loss = 0.09427649854894259
Trained batch 611 in epoch 7, gen_loss = 0.8122095518739395, disc_loss = 0.09414519757805453
Trained batch 612 in epoch 7, gen_loss = 0.8125806405629847, disc_loss = 0.09403020515582156
Trained batch 613 in epoch 7, gen_loss = 0.8126403207402276, disc_loss = 0.0939223274652291
Trained batch 614 in epoch 7, gen_loss = 0.812952416650648, disc_loss = 0.09380774845225297
Trained batch 615 in epoch 7, gen_loss = 0.813667384012566, disc_loss = 0.0938275673490187
Trained batch 616 in epoch 7, gen_loss = 0.8134058856403809, disc_loss = 0.09383509232778844
Trained batch 617 in epoch 7, gen_loss = 0.8135134303357608, disc_loss = 0.09370536285883545
Trained batch 618 in epoch 7, gen_loss = 0.8134604163335483, disc_loss = 0.09358986051714045
Trained batch 619 in epoch 7, gen_loss = 0.8136983342228398, disc_loss = 0.09346090877398608
Trained batch 620 in epoch 7, gen_loss = 0.8134581614135736, disc_loss = 0.09342619563316426
Trained batch 621 in epoch 7, gen_loss = 0.8135002722598349, disc_loss = 0.09330877668742342
Trained batch 622 in epoch 7, gen_loss = 0.8140136586624777, disc_loss = 0.09321962638846322
Trained batch 623 in epoch 7, gen_loss = 0.8142491618696696, disc_loss = 0.09310473973462836
Trained batch 624 in epoch 7, gen_loss = 0.8140276751041412, disc_loss = 0.09311208242326975
Trained batch 625 in epoch 7, gen_loss = 0.8145809785340922, disc_loss = 0.09312551872233471
Trained batch 626 in epoch 7, gen_loss = 0.8148313380979845, disc_loss = 0.09299934559919094
Trained batch 627 in epoch 7, gen_loss = 0.8148912239321477, disc_loss = 0.09288018750424265
Trained batch 628 in epoch 7, gen_loss = 0.8145920810051298, disc_loss = 0.0929919656896179
Trained batch 629 in epoch 7, gen_loss = 0.8146194226685024, disc_loss = 0.09294419289374399
Trained batch 630 in epoch 7, gen_loss = 0.8144516713929063, disc_loss = 0.09288752808865815
Trained batch 631 in epoch 7, gen_loss = 0.8146910254808166, disc_loss = 0.0927716846403937
Trained batch 632 in epoch 7, gen_loss = 0.814510236560451, disc_loss = 0.09269584621351336
Trained batch 633 in epoch 7, gen_loss = 0.814713464127354, disc_loss = 0.09265339701386516
Trained batch 634 in epoch 7, gen_loss = 0.8144836348342145, disc_loss = 0.09259671749708455
Trained batch 635 in epoch 7, gen_loss = 0.8143398444513855, disc_loss = 0.09257766895095741
Trained batch 636 in epoch 7, gen_loss = 0.8144877058464092, disc_loss = 0.09258449773685758
Trained batch 637 in epoch 7, gen_loss = 0.8149141021376494, disc_loss = 0.09248390140560774
Trained batch 638 in epoch 7, gen_loss = 0.8150350809190569, disc_loss = 0.09236320721040915
Trained batch 639 in epoch 7, gen_loss = 0.8145903602708131, disc_loss = 0.09232135852362262
Trained batch 640 in epoch 7, gen_loss = 0.8149739165852855, disc_loss = 0.092323703457443
Trained batch 641 in epoch 7, gen_loss = 0.814721646756398, disc_loss = 0.0923020316598316
Trained batch 642 in epoch 7, gen_loss = 0.8148485811001406, disc_loss = 0.09221493100101479
Trained batch 643 in epoch 7, gen_loss = 0.8148924981862862, disc_loss = 0.092134975390046
Trained batch 644 in epoch 7, gen_loss = 0.8150057313516158, disc_loss = 0.092039317815283
Trained batch 645 in epoch 7, gen_loss = 0.8153515850704152, disc_loss = 0.09203768392228998
Trained batch 646 in epoch 7, gen_loss = 0.8147937426979796, disc_loss = 0.09225790458119588
Trained batch 647 in epoch 7, gen_loss = 0.8151735870374573, disc_loss = 0.09233640106596099
Trained batch 648 in epoch 7, gen_loss = 0.814921854365221, disc_loss = 0.09231260833179776
Trained batch 649 in epoch 7, gen_loss = 0.8149628034921793, disc_loss = 0.09220390386736163
Trained batch 650 in epoch 7, gen_loss = 0.8152415484144208, disc_loss = 0.09213618925427831
Trained batch 651 in epoch 7, gen_loss = 0.8151641286041108, disc_loss = 0.09206410147038294
Trained batch 652 in epoch 7, gen_loss = 0.8154051174248524, disc_loss = 0.09194587396991198
Trained batch 653 in epoch 7, gen_loss = 0.8157255356100357, disc_loss = 0.09186825966206166
Trained batch 654 in epoch 7, gen_loss = 0.8162653353378063, disc_loss = 0.09174891909342686
Trained batch 655 in epoch 7, gen_loss = 0.8159948136748337, disc_loss = 0.0917495902196118
Trained batch 656 in epoch 7, gen_loss = 0.8162314354738326, disc_loss = 0.09165814602846788
Trained batch 657 in epoch 7, gen_loss = 0.8162411042803327, disc_loss = 0.0915444182503776
Trained batch 658 in epoch 7, gen_loss = 0.8164053892148645, disc_loss = 0.09143417102478343
Trained batch 659 in epoch 7, gen_loss = 0.8165725628534953, disc_loss = 0.09133044146001339
Trained batch 660 in epoch 7, gen_loss = 0.8166425486916673, disc_loss = 0.09121286801278095
Trained batch 661 in epoch 7, gen_loss = 0.8168495775529625, disc_loss = 0.09108846626326082
Trained batch 662 in epoch 7, gen_loss = 0.816740099211444, disc_loss = 0.09101340316410203
Trained batch 663 in epoch 7, gen_loss = 0.8174102504748896, disc_loss = 0.09096240529549275
Trained batch 664 in epoch 7, gen_loss = 0.8179227638065367, disc_loss = 0.09092747581548484
Trained batch 665 in epoch 7, gen_loss = 0.8177545315868504, disc_loss = 0.0909891538783438
Trained batch 666 in epoch 7, gen_loss = 0.8177588216547129, disc_loss = 0.09095450803620748
Trained batch 667 in epoch 7, gen_loss = 0.8182725647609391, disc_loss = 0.09092955312602401
Trained batch 668 in epoch 7, gen_loss = 0.8185726924505647, disc_loss = 0.090811547544828
Trained batch 669 in epoch 7, gen_loss = 0.8187700463764703, disc_loss = 0.09089736653936666
Trained batch 670 in epoch 7, gen_loss = 0.8183341640118516, disc_loss = 0.09094652167247988
Trained batch 671 in epoch 7, gen_loss = 0.8183842424658083, disc_loss = 0.09084422200214162
Trained batch 672 in epoch 7, gen_loss = 0.8184269947424686, disc_loss = 0.09085508488135255
Trained batch 673 in epoch 7, gen_loss = 0.8187610161233726, disc_loss = 0.09074436094285782
Trained batch 674 in epoch 7, gen_loss = 0.8184987925600122, disc_loss = 0.09079397718525595
Trained batch 675 in epoch 7, gen_loss = 0.8186229581134559, disc_loss = 0.09069519976468085
Trained batch 676 in epoch 7, gen_loss = 0.8190072148906251, disc_loss = 0.09074371794934771
Trained batch 677 in epoch 7, gen_loss = 0.8191129884361166, disc_loss = 0.0906383037487468
Trained batch 678 in epoch 7, gen_loss = 0.8188812473736736, disc_loss = 0.0905955607587244
Trained batch 679 in epoch 7, gen_loss = 0.8185811772942543, disc_loss = 0.09060390475890873
Trained batch 680 in epoch 7, gen_loss = 0.8191426359609361, disc_loss = 0.09096167478765116
Trained batch 681 in epoch 7, gen_loss = 0.8188800926257438, disc_loss = 0.09100852675511996
Trained batch 682 in epoch 7, gen_loss = 0.8188149966572249, disc_loss = 0.09095755550399488
Trained batch 683 in epoch 7, gen_loss = 0.8185782457827128, disc_loss = 0.09095663017843855
Trained batch 684 in epoch 7, gen_loss = 0.8186934395428122, disc_loss = 0.09093302433263428
Trained batch 685 in epoch 7, gen_loss = 0.8187111307684951, disc_loss = 0.0908454914561014
Trained batch 686 in epoch 7, gen_loss = 0.8186666485697595, disc_loss = 0.09076255204337697
Trained batch 687 in epoch 7, gen_loss = 0.8185837207318738, disc_loss = 0.09070619639296215
Trained batch 688 in epoch 7, gen_loss = 0.8187860067074115, disc_loss = 0.0907168065972291
Trained batch 689 in epoch 7, gen_loss = 0.8184290546437968, disc_loss = 0.09083976562715311
Trained batch 690 in epoch 7, gen_loss = 0.8185446119170458, disc_loss = 0.09082853865935082
Trained batch 691 in epoch 7, gen_loss = 0.8186189857866034, disc_loss = 0.0907207483659913
Trained batch 692 in epoch 7, gen_loss = 0.8183844503214177, disc_loss = 0.09067097952264169
Trained batch 693 in epoch 7, gen_loss = 0.8182333159858968, disc_loss = 0.09062078656757556
Trained batch 694 in epoch 7, gen_loss = 0.8184650496613207, disc_loss = 0.09058983005824492
Trained batch 695 in epoch 7, gen_loss = 0.8181824995868507, disc_loss = 0.09061947072476106
Trained batch 696 in epoch 7, gen_loss = 0.8188107290774199, disc_loss = 0.09055710805064252
Trained batch 697 in epoch 7, gen_loss = 0.8188089196354066, disc_loss = 0.09059425031253934
Trained batch 698 in epoch 7, gen_loss = 0.818411383079698, disc_loss = 0.09074981582986566
Trained batch 699 in epoch 7, gen_loss = 0.8186176349435533, disc_loss = 0.09069945040957204
Trained batch 700 in epoch 7, gen_loss = 0.8188176081966232, disc_loss = 0.0905890028416239
Trained batch 701 in epoch 7, gen_loss = 0.8185314958931035, disc_loss = 0.09056696186818586
Trained batch 702 in epoch 7, gen_loss = 0.8184526165891677, disc_loss = 0.09070233332329718
Trained batch 703 in epoch 7, gen_loss = 0.8184262741865083, disc_loss = 0.09063240931639237
Trained batch 704 in epoch 7, gen_loss = 0.8181056075907768, disc_loss = 0.09066227118993271
Trained batch 705 in epoch 7, gen_loss = 0.8181101446786616, disc_loss = 0.0906506482625206
Trained batch 706 in epoch 7, gen_loss = 0.8187523193372864, disc_loss = 0.09078380486979301
Trained batch 707 in epoch 7, gen_loss = 0.818612719575564, disc_loss = 0.0907064499004644
Trained batch 708 in epoch 7, gen_loss = 0.8182054378922466, disc_loss = 0.09082904314472535
Trained batch 709 in epoch 7, gen_loss = 0.818296488825704, disc_loss = 0.0908074754788737
Trained batch 710 in epoch 7, gen_loss = 0.8181935795248813, disc_loss = 0.0907899458131605
Trained batch 711 in epoch 7, gen_loss = 0.8181675341859292, disc_loss = 0.09071597511738831
Trained batch 712 in epoch 7, gen_loss = 0.8181449038617908, disc_loss = 0.09061604009766189
Trained batch 713 in epoch 7, gen_loss = 0.8182539531663686, disc_loss = 0.09052746491089296
Trained batch 714 in epoch 7, gen_loss = 0.8182474122180805, disc_loss = 0.09050383830013184
Trained batch 715 in epoch 7, gen_loss = 0.818245636268035, disc_loss = 0.09041010818506627
Trained batch 716 in epoch 7, gen_loss = 0.8180521138874889, disc_loss = 0.09034531499224104
Trained batch 717 in epoch 7, gen_loss = 0.8180529928473045, disc_loss = 0.09035921722655717
Trained batch 718 in epoch 7, gen_loss = 0.8175471656345691, disc_loss = 0.09058319932816133
Trained batch 719 in epoch 7, gen_loss = 0.8177816975447867, disc_loss = 0.09053329264667506
Trained batch 720 in epoch 7, gen_loss = 0.8177170975859718, disc_loss = 0.09064587595357189
Trained batch 721 in epoch 7, gen_loss = 0.8177565591322088, disc_loss = 0.09055288892543753
Trained batch 722 in epoch 7, gen_loss = 0.8175651287636816, disc_loss = 0.09055725809825613
Trained batch 723 in epoch 7, gen_loss = 0.8176481347551662, disc_loss = 0.09047181544264583
Trained batch 724 in epoch 7, gen_loss = 0.8177841384657498, disc_loss = 0.09040658962238451
Trained batch 725 in epoch 7, gen_loss = 0.8177498852418474, disc_loss = 0.09034041031173971
Trained batch 726 in epoch 7, gen_loss = 0.8175870081745447, disc_loss = 0.09027834374078407
Trained batch 727 in epoch 7, gen_loss = 0.8180556657550099, disc_loss = 0.0903079506575263
Trained batch 728 in epoch 7, gen_loss = 0.8179937766249125, disc_loss = 0.09022940077597917
Trained batch 729 in epoch 7, gen_loss = 0.8176592911759468, disc_loss = 0.09029910131293821
Trained batch 730 in epoch 7, gen_loss = 0.8182512166235907, disc_loss = 0.09039629220824928
Trained batch 731 in epoch 7, gen_loss = 0.8184141304160728, disc_loss = 0.09030313125322954
Trained batch 732 in epoch 7, gen_loss = 0.8181910850666717, disc_loss = 0.0903061591253945
Trained batch 733 in epoch 7, gen_loss = 0.8184648606855148, disc_loss = 0.09031017779496978
Trained batch 734 in epoch 7, gen_loss = 0.8182414054059658, disc_loss = 0.0902995955389069
Trained batch 735 in epoch 7, gen_loss = 0.8179311465633952, disc_loss = 0.09030149304232074
Trained batch 736 in epoch 7, gen_loss = 0.8179611357452102, disc_loss = 0.09033910952523613
Trained batch 737 in epoch 7, gen_loss = 0.8181110109255566, disc_loss = 0.09029948685272801
Trained batch 738 in epoch 7, gen_loss = 0.817913709135275, disc_loss = 0.09027310726087898
Trained batch 739 in epoch 7, gen_loss = 0.8178935114596341, disc_loss = 0.09018554446740529
Trained batch 740 in epoch 7, gen_loss = 0.817694459447333, disc_loss = 0.09016020065010116
Trained batch 741 in epoch 7, gen_loss = 0.8183049401343672, disc_loss = 0.09024404222145677
Trained batch 742 in epoch 7, gen_loss = 0.8183583819368807, disc_loss = 0.09020745973723213
Trained batch 743 in epoch 7, gen_loss = 0.8183444093472214, disc_loss = 0.09013712608320538
Trained batch 744 in epoch 7, gen_loss = 0.8181910441225807, disc_loss = 0.09015342501060875
Trained batch 745 in epoch 7, gen_loss = 0.8184426402917816, disc_loss = 0.09023505489119696
Trained batch 746 in epoch 7, gen_loss = 0.8182786543525685, disc_loss = 0.09017519718547223
Trained batch 747 in epoch 7, gen_loss = 0.817933644362312, disc_loss = 0.09017046008951325
Trained batch 748 in epoch 7, gen_loss = 0.8183532825935985, disc_loss = 0.09027445170958744
Trained batch 749 in epoch 7, gen_loss = 0.8182590758800506, disc_loss = 0.09020000110939146
Trained batch 750 in epoch 7, gen_loss = 0.8180599982506743, disc_loss = 0.09019707532081202
Trained batch 751 in epoch 7, gen_loss = 0.8178981311143713, disc_loss = 0.09014557123535927
Trained batch 752 in epoch 7, gen_loss = 0.8180490178890912, disc_loss = 0.09012488752559006
Trained batch 753 in epoch 7, gen_loss = 0.818109805213994, disc_loss = 0.09005203283705628
Trained batch 754 in epoch 7, gen_loss = 0.8179156569455633, disc_loss = 0.0900483839152171
Trained batch 755 in epoch 7, gen_loss = 0.8179793975971363, disc_loss = 0.09005776037728148
Trained batch 756 in epoch 7, gen_loss = 0.8179465730722546, disc_loss = 0.0899772587733016
Trained batch 757 in epoch 7, gen_loss = 0.8177947202269823, disc_loss = 0.08997195097924969
Trained batch 758 in epoch 7, gen_loss = 0.8177231524301611, disc_loss = 0.08990681820643553
Trained batch 759 in epoch 7, gen_loss = 0.8182174435571621, disc_loss = 0.0899810744486259
Trained batch 760 in epoch 7, gen_loss = 0.8184965379761334, disc_loss = 0.08987928305369522
Trained batch 761 in epoch 7, gen_loss = 0.8181437859385032, disc_loss = 0.0899411370975315
Trained batch 762 in epoch 7, gen_loss = 0.8177997440216894, disc_loss = 0.09011993092529935
Trained batch 763 in epoch 7, gen_loss = 0.8181319103347069, disc_loss = 0.09023386326920807
Trained batch 764 in epoch 7, gen_loss = 0.8182964646738339, disc_loss = 0.09017104328384781
Trained batch 765 in epoch 7, gen_loss = 0.8182557201105372, disc_loss = 0.09015610047759531
Trained batch 766 in epoch 7, gen_loss = 0.817865789713729, disc_loss = 0.09039116220614318
Trained batch 767 in epoch 7, gen_loss = 0.8178872182810059, disc_loss = 0.09032390787736706
Trained batch 768 in epoch 7, gen_loss = 0.8177912073265592, disc_loss = 0.09024679467387216
Trained batch 769 in epoch 7, gen_loss = 0.8179189283352394, disc_loss = 0.09014887558417274
Trained batch 770 in epoch 7, gen_loss = 0.8179755774453457, disc_loss = 0.0900952098420042
Trained batch 771 in epoch 7, gen_loss = 0.818006199490221, disc_loss = 0.09001007895443801
Trained batch 772 in epoch 7, gen_loss = 0.8179644114141477, disc_loss = 0.08996891878294683
Trained batch 773 in epoch 7, gen_loss = 0.818290717457, disc_loss = 0.08996574952476477
Trained batch 774 in epoch 7, gen_loss = 0.8183517436058291, disc_loss = 0.0899699626358286
Trained batch 775 in epoch 7, gen_loss = 0.818036231797995, disc_loss = 0.09001960700675461
Trained batch 776 in epoch 7, gen_loss = 0.8175425285921747, disc_loss = 0.0901362224286626
Trained batch 777 in epoch 7, gen_loss = 0.8178864106497605, disc_loss = 0.09016971189796848
Trained batch 778 in epoch 7, gen_loss = 0.8181188950107094, disc_loss = 0.09012333622419864
Trained batch 779 in epoch 7, gen_loss = 0.8179025857494427, disc_loss = 0.09014185056902277
Trained batch 780 in epoch 7, gen_loss = 0.8179563829215022, disc_loss = 0.09006538476303659
Trained batch 781 in epoch 7, gen_loss = 0.8181153860924494, disc_loss = 0.09009153128642103
Trained batch 782 in epoch 7, gen_loss = 0.8180194522609808, disc_loss = 0.09002489819266331
Trained batch 783 in epoch 7, gen_loss = 0.8176868791710965, disc_loss = 0.09012458805108861
Trained batch 784 in epoch 7, gen_loss = 0.8180730740355838, disc_loss = 0.09011994470266779
Trained batch 785 in epoch 7, gen_loss = 0.8178908845774697, disc_loss = 0.09024704654366915
Trained batch 786 in epoch 7, gen_loss = 0.8176934288523552, disc_loss = 0.09019876353849753
Trained batch 787 in epoch 7, gen_loss = 0.8174678775940449, disc_loss = 0.09021497205807473
Trained batch 788 in epoch 7, gen_loss = 0.818018265890078, disc_loss = 0.09031516190792974
Trained batch 789 in epoch 7, gen_loss = 0.8179654004075859, disc_loss = 0.09025189933143085
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.6673064231872559, disc_loss = 0.07722567021846771
Trained batch 1 in epoch 8, gen_loss = 0.804694652557373, disc_loss = 0.053604068234562874
Trained batch 2 in epoch 8, gen_loss = 0.8922869364420573, disc_loss = 0.0721551738679409
Trained batch 3 in epoch 8, gen_loss = 0.8472573161125183, disc_loss = 0.06471189577132463
Trained batch 4 in epoch 8, gen_loss = 0.8200920581817627, disc_loss = 0.07316746190190315
Trained batch 5 in epoch 8, gen_loss = 0.8657329678535461, disc_loss = 0.06927453974882762
Trained batch 6 in epoch 8, gen_loss = 0.8898143938609532, disc_loss = 0.06180888121681554
Trained batch 7 in epoch 8, gen_loss = 0.8713386952877045, disc_loss = 0.06223638472147286
Trained batch 8 in epoch 8, gen_loss = 0.8666476143731011, disc_loss = 0.060384588316082954
Trained batch 9 in epoch 8, gen_loss = 0.8646655917167664, disc_loss = 0.055486299004405736
Trained batch 10 in epoch 8, gen_loss = 0.8723862008614973, disc_loss = 0.05115809418599714
Trained batch 11 in epoch 8, gen_loss = 0.8625807414452235, disc_loss = 0.05255318425285319
Trained batch 12 in epoch 8, gen_loss = 0.8474841255408067, disc_loss = 0.05221445679378051
Trained batch 13 in epoch 8, gen_loss = 0.84237659403256, disc_loss = 0.05604475250999842
Trained batch 14 in epoch 8, gen_loss = 0.8164272566636404, disc_loss = 0.06244620724270741
Trained batch 15 in epoch 8, gen_loss = 0.8213869426399469, disc_loss = 0.06019169831415638
Trained batch 16 in epoch 8, gen_loss = 0.8416438470868504, disc_loss = 0.07496355906786288
Trained batch 17 in epoch 8, gen_loss = 0.8244360370768441, disc_loss = 0.08130727868734135
Trained batch 18 in epoch 8, gen_loss = 0.8134527975007108, disc_loss = 0.08145801600460943
Trained batch 19 in epoch 8, gen_loss = 0.8322511151432991, disc_loss = 0.08685009512118995
Trained batch 20 in epoch 8, gen_loss = 0.8271545185929253, disc_loss = 0.0874048758386856
Trained batch 21 in epoch 8, gen_loss = 0.8127009882168337, disc_loss = 0.09349419951269572
Trained batch 22 in epoch 8, gen_loss = 0.8063196734241818, disc_loss = 0.09092546671466983
Trained batch 23 in epoch 8, gen_loss = 0.8051129840314388, disc_loss = 0.09582085531049718
Trained batch 24 in epoch 8, gen_loss = 0.8012550485134124, disc_loss = 0.09515501793473959
Trained batch 25 in epoch 8, gen_loss = 0.791436561025106, disc_loss = 0.09917817719710562
Trained batch 26 in epoch 8, gen_loss = 0.7899984772558566, disc_loss = 0.0973602375705485
Trained batch 27 in epoch 8, gen_loss = 0.7920429270182338, disc_loss = 0.09606339220356729
Trained batch 28 in epoch 8, gen_loss = 0.7870630323886871, disc_loss = 0.09528884596737294
Trained batch 29 in epoch 8, gen_loss = 0.7905796378850937, disc_loss = 0.09284096686169505
Trained batch 30 in epoch 8, gen_loss = 0.797196110410075, disc_loss = 0.0917821953433656
Trained batch 31 in epoch 8, gen_loss = 0.7916342439129949, disc_loss = 0.09115347373881377
Trained batch 32 in epoch 8, gen_loss = 0.7925487693512079, disc_loss = 0.08884995676238429
Trained batch 33 in epoch 8, gen_loss = 0.7912183938657537, disc_loss = 0.08710189084248508
Trained batch 34 in epoch 8, gen_loss = 0.7923568597861699, disc_loss = 0.08544053533779723
Trained batch 35 in epoch 8, gen_loss = 0.7967603082458178, disc_loss = 0.08402619937745233
Trained batch 36 in epoch 8, gen_loss = 0.8006853517648336, disc_loss = 0.08200297768957712
Trained batch 37 in epoch 8, gen_loss = 0.8011903488322308, disc_loss = 0.08071030904293845
Trained batch 38 in epoch 8, gen_loss = 0.8010704738971515, disc_loss = 0.07949191611260176
Trained batch 39 in epoch 8, gen_loss = 0.8005948968231678, disc_loss = 0.07885531012434513
Trained batch 40 in epoch 8, gen_loss = 0.7994766242620421, disc_loss = 0.07740413045465219
Trained batch 41 in epoch 8, gen_loss = 0.7989912934246517, disc_loss = 0.0784558085502968
Trained batch 42 in epoch 8, gen_loss = 0.7982677006444265, disc_loss = 0.07820153905641894
Trained batch 43 in epoch 8, gen_loss = 0.8086240542205897, disc_loss = 0.08020548600788144
Trained batch 44 in epoch 8, gen_loss = 0.8082464807563358, disc_loss = 0.079102001277109
Trained batch 45 in epoch 8, gen_loss = 0.8114833682775497, disc_loss = 0.07779621764126679
Trained batch 46 in epoch 8, gen_loss = 0.8126198186519298, disc_loss = 0.07746774515018184
Trained batch 47 in epoch 8, gen_loss = 0.8107458433757225, disc_loss = 0.0773465700331144
Trained batch 48 in epoch 8, gen_loss = 0.815026303335112, disc_loss = 0.07676725304324408
Trained batch 49 in epoch 8, gen_loss = 0.8119812494516373, disc_loss = 0.07668661819770932
Trained batch 50 in epoch 8, gen_loss = 0.8143702622722176, disc_loss = 0.07717430096704002
Trained batch 51 in epoch 8, gen_loss = 0.8160693479272035, disc_loss = 0.07701546944176349
Trained batch 52 in epoch 8, gen_loss = 0.8159398993231216, disc_loss = 0.07647376256239302
Trained batch 53 in epoch 8, gen_loss = 0.8201366823028635, disc_loss = 0.07547524452416433
Trained batch 54 in epoch 8, gen_loss = 0.821974121982401, disc_loss = 0.07435795121233571
Trained batch 55 in epoch 8, gen_loss = 0.8231620964195047, disc_loss = 0.07340287954346943
Trained batch 56 in epoch 8, gen_loss = 0.824936233591615, disc_loss = 0.07277033038502723
Trained batch 57 in epoch 8, gen_loss = 0.8239900587961592, disc_loss = 0.07232401659712195
Trained batch 58 in epoch 8, gen_loss = 0.8267304053751089, disc_loss = 0.07182744137500807
Trained batch 59 in epoch 8, gen_loss = 0.8297496880094211, disc_loss = 0.07098243017680943
Trained batch 60 in epoch 8, gen_loss = 0.8345335472802646, disc_loss = 0.07064002549245221
Trained batch 61 in epoch 8, gen_loss = 0.8365658574527309, disc_loss = 0.06986475986759028
Trained batch 62 in epoch 8, gen_loss = 0.8390032701076023, disc_loss = 0.06897251968759865
Trained batch 63 in epoch 8, gen_loss = 0.8380309981293976, disc_loss = 0.0684106655389769
Trained batch 64 in epoch 8, gen_loss = 0.8408855369457832, disc_loss = 0.06753449361198223
Trained batch 65 in epoch 8, gen_loss = 0.8458399181113099, disc_loss = 0.06696990895734141
Trained batch 66 in epoch 8, gen_loss = 0.8452326348468439, disc_loss = 0.0662308078565037
Trained batch 67 in epoch 8, gen_loss = 0.8479699181283221, disc_loss = 0.06598186581943404
Trained batch 68 in epoch 8, gen_loss = 0.8456157139246014, disc_loss = 0.06609697544110427
Trained batch 69 in epoch 8, gen_loss = 0.8455283509833472, disc_loss = 0.0655102622429175
Trained batch 70 in epoch 8, gen_loss = 0.8508733364058213, disc_loss = 0.06529229618346608
Trained batch 71 in epoch 8, gen_loss = 0.8502681739628315, disc_loss = 0.06473792167121752
Trained batch 72 in epoch 8, gen_loss = 0.8489183093587013, disc_loss = 0.06446675230327943
Trained batch 73 in epoch 8, gen_loss = 0.8464065149829194, disc_loss = 0.06419609848258866
Trained batch 74 in epoch 8, gen_loss = 0.8476315295696258, disc_loss = 0.06376837833474079
Trained batch 75 in epoch 8, gen_loss = 0.847213818446586, disc_loss = 0.06335067987981204
Trained batch 76 in epoch 8, gen_loss = 0.8487729859816564, disc_loss = 0.06280651421274071
Trained batch 77 in epoch 8, gen_loss = 0.8538552816861715, disc_loss = 0.06334024919674565
Trained batch 78 in epoch 8, gen_loss = 0.8498848695543748, disc_loss = 0.06417560901587145
Trained batch 79 in epoch 8, gen_loss = 0.8477555233985186, disc_loss = 0.06423657139530406
Trained batch 80 in epoch 8, gen_loss = 0.8461856948740688, disc_loss = 0.06462540609739077
Trained batch 81 in epoch 8, gen_loss = 0.8468691673947544, disc_loss = 0.06444746740843828
Trained batch 82 in epoch 8, gen_loss = 0.8442840946007923, disc_loss = 0.06457248746406243
Trained batch 83 in epoch 8, gen_loss = 0.8453373217156955, disc_loss = 0.06414790598986049
Trained batch 84 in epoch 8, gen_loss = 0.8500887579777662, disc_loss = 0.06539833831655628
Trained batch 85 in epoch 8, gen_loss = 0.8498223330392394, disc_loss = 0.06525095154769546
Trained batch 86 in epoch 8, gen_loss = 0.8460628763697613, disc_loss = 0.06703204568475485
Trained batch 87 in epoch 8, gen_loss = 0.8458678258413618, disc_loss = 0.06821654907385395
Trained batch 88 in epoch 8, gen_loss = 0.8477385522944204, disc_loss = 0.06824924563465828
Trained batch 89 in epoch 8, gen_loss = 0.8455301162269381, disc_loss = 0.06847489949108826
Trained batch 90 in epoch 8, gen_loss = 0.8433597936080053, disc_loss = 0.0687090929004026
Trained batch 91 in epoch 8, gen_loss = 0.8466300533517547, disc_loss = 0.06879969573903667
Trained batch 92 in epoch 8, gen_loss = 0.8478933332427856, disc_loss = 0.06838527238697455
Trained batch 93 in epoch 8, gen_loss = 0.8442815818051075, disc_loss = 0.06956859706762306
Trained batch 94 in epoch 8, gen_loss = 0.8426165150968652, disc_loss = 0.0696366981946324
Trained batch 95 in epoch 8, gen_loss = 0.8464059056714177, disc_loss = 0.06981477689502451
Trained batch 96 in epoch 8, gen_loss = 0.8492109059672994, disc_loss = 0.07065722750519048
Trained batch 97 in epoch 8, gen_loss = 0.8468585169436981, disc_loss = 0.07058387642194118
Trained batch 98 in epoch 8, gen_loss = 0.8458824774833641, disc_loss = 0.07031410880800751
Trained batch 99 in epoch 8, gen_loss = 0.8440377524495125, disc_loss = 0.07033263065852224
Trained batch 100 in epoch 8, gen_loss = 0.8441276340791495, disc_loss = 0.06998118150536672
Trained batch 101 in epoch 8, gen_loss = 0.8467847357193629, disc_loss = 0.07058575936574854
Trained batch 102 in epoch 8, gen_loss = 0.8460009436584214, disc_loss = 0.07025675465651218
Trained batch 103 in epoch 8, gen_loss = 0.8441342674195766, disc_loss = 0.07044117006723984
Trained batch 104 in epoch 8, gen_loss = 0.8441224220253173, disc_loss = 0.07005488972756124
Trained batch 105 in epoch 8, gen_loss = 0.8462869533390369, disc_loss = 0.07032333343412797
Trained batch 106 in epoch 8, gen_loss = 0.8442087282087202, disc_loss = 0.0704432423792292
Trained batch 107 in epoch 8, gen_loss = 0.8416414787923848, disc_loss = 0.07143482428768443
Trained batch 108 in epoch 8, gen_loss = 0.8438436326083787, disc_loss = 0.07124459532456934
Trained batch 109 in epoch 8, gen_loss = 0.8459833554246209, disc_loss = 0.07200905485078693
Trained batch 110 in epoch 8, gen_loss = 0.8449854445350062, disc_loss = 0.07268123591301946
Trained batch 111 in epoch 8, gen_loss = 0.842283355604325, disc_loss = 0.07332191983005032
Trained batch 112 in epoch 8, gen_loss = 0.8414969431088034, disc_loss = 0.07343447268569628
Trained batch 113 in epoch 8, gen_loss = 0.8427649221399374, disc_loss = 0.07370621568049517
Trained batch 114 in epoch 8, gen_loss = 0.8435494648373645, disc_loss = 0.07378303467741479
Trained batch 115 in epoch 8, gen_loss = 0.842824816960713, disc_loss = 0.07388313481552077
Trained batch 116 in epoch 8, gen_loss = 0.8413327924716167, disc_loss = 0.07364882570970008
Trained batch 117 in epoch 8, gen_loss = 0.843323962415679, disc_loss = 0.07434571273151343
Trained batch 118 in epoch 8, gen_loss = 0.8407291041201904, disc_loss = 0.07471534425877974
Trained batch 119 in epoch 8, gen_loss = 0.8403085219363372, disc_loss = 0.07447497873411825
Trained batch 120 in epoch 8, gen_loss = 0.8417267294462062, disc_loss = 0.07481769457736537
Trained batch 121 in epoch 8, gen_loss = 0.8402035297428976, disc_loss = 0.07507196371825259
Trained batch 122 in epoch 8, gen_loss = 0.8399640866896001, disc_loss = 0.07509728827763622
Trained batch 123 in epoch 8, gen_loss = 0.8406148521650222, disc_loss = 0.07465295761733526
Trained batch 124 in epoch 8, gen_loss = 0.8408113505840301, disc_loss = 0.07488208053261042
Trained batch 125 in epoch 8, gen_loss = 0.8408472649161778, disc_loss = 0.07446727321468412
Trained batch 126 in epoch 8, gen_loss = 0.8404956875354286, disc_loss = 0.07413114474602336
Trained batch 127 in epoch 8, gen_loss = 0.8398758082184941, disc_loss = 0.07381417266878998
Trained batch 128 in epoch 8, gen_loss = 0.8406970923723176, disc_loss = 0.0739761817579468
Trained batch 129 in epoch 8, gen_loss = 0.8392387131085762, disc_loss = 0.07395778896573645
Trained batch 130 in epoch 8, gen_loss = 0.8413463064277446, disc_loss = 0.07382589799728785
Trained batch 131 in epoch 8, gen_loss = 0.8411195741006823, disc_loss = 0.07350651253099469
Trained batch 132 in epoch 8, gen_loss = 0.8398942873442083, disc_loss = 0.07340282041411426
Trained batch 133 in epoch 8, gen_loss = 0.837781441523068, disc_loss = 0.07379110532103857
Trained batch 134 in epoch 8, gen_loss = 0.8413215352429284, disc_loss = 0.0748069545392085
Trained batch 135 in epoch 8, gen_loss = 0.8418776596731999, disc_loss = 0.07461353072978776
Trained batch 136 in epoch 8, gen_loss = 0.8400221430037144, disc_loss = 0.07482747830804029
Trained batch 137 in epoch 8, gen_loss = 0.8384942967390668, disc_loss = 0.07491412995707082
Trained batch 138 in epoch 8, gen_loss = 0.8390594997423159, disc_loss = 0.07488870223407908
Trained batch 139 in epoch 8, gen_loss = 0.8396700405648776, disc_loss = 0.07482424606569112
Trained batch 140 in epoch 8, gen_loss = 0.8388391874783429, disc_loss = 0.07454218857439486
Trained batch 141 in epoch 8, gen_loss = 0.8373457048560532, disc_loss = 0.0746229072626103
Trained batch 142 in epoch 8, gen_loss = 0.8385267830812014, disc_loss = 0.07419409285709783
Trained batch 143 in epoch 8, gen_loss = 0.8396371638195382, disc_loss = 0.0743926274137468
Trained batch 144 in epoch 8, gen_loss = 0.840076305331855, disc_loss = 0.07393800058755381
Trained batch 145 in epoch 8, gen_loss = 0.839694451183489, disc_loss = 0.07374848795365797
Trained batch 146 in epoch 8, gen_loss = 0.8395408629154673, disc_loss = 0.07348011330175562
Trained batch 147 in epoch 8, gen_loss = 0.8394014233270207, disc_loss = 0.07309921328733499
Trained batch 148 in epoch 8, gen_loss = 0.8403396360426141, disc_loss = 0.0726717799564436
Trained batch 149 in epoch 8, gen_loss = 0.8397621490557988, disc_loss = 0.07243093406781555
Trained batch 150 in epoch 8, gen_loss = 0.8394983641753923, disc_loss = 0.07232862672096255
Trained batch 151 in epoch 8, gen_loss = 0.8390611463079327, disc_loss = 0.07206558179428899
Trained batch 152 in epoch 8, gen_loss = 0.83845391596844, disc_loss = 0.07205401578297217
Trained batch 153 in epoch 8, gen_loss = 0.8396460450701899, disc_loss = 0.07181831573245007
Trained batch 154 in epoch 8, gen_loss = 0.8386455987730334, disc_loss = 0.07189198235470441
Trained batch 155 in epoch 8, gen_loss = 0.8379373135857093, disc_loss = 0.0716042071640587
Trained batch 156 in epoch 8, gen_loss = 0.8394415930957552, disc_loss = 0.07137472073956849
Trained batch 157 in epoch 8, gen_loss = 0.8396947434808635, disc_loss = 0.0710505019177836
Trained batch 158 in epoch 8, gen_loss = 0.8392379371999944, disc_loss = 0.07171993794610852
Trained batch 159 in epoch 8, gen_loss = 0.83779351208359, disc_loss = 0.07224425927852281
Trained batch 160 in epoch 8, gen_loss = 0.8359370855441005, disc_loss = 0.0725274746659102
Trained batch 161 in epoch 8, gen_loss = 0.8361682669248109, disc_loss = 0.07264494774633168
Trained batch 162 in epoch 8, gen_loss = 0.835898746559225, disc_loss = 0.07250585830399046
Trained batch 163 in epoch 8, gen_loss = 0.8349788725012686, disc_loss = 0.07241105881701337
Trained batch 164 in epoch 8, gen_loss = 0.835429021987048, disc_loss = 0.07210369051970315
Trained batch 165 in epoch 8, gen_loss = 0.8353781816830118, disc_loss = 0.07225636846711297
Trained batch 166 in epoch 8, gen_loss = 0.8346724747540708, disc_loss = 0.07212473461571746
Trained batch 167 in epoch 8, gen_loss = 0.8347183006505171, disc_loss = 0.07263226621407307
Trained batch 168 in epoch 8, gen_loss = 0.8334875750471149, disc_loss = 0.07286115709868585
Trained batch 169 in epoch 8, gen_loss = 0.8347883478683584, disc_loss = 0.07280130825169823
Trained batch 170 in epoch 8, gen_loss = 0.8361487404296273, disc_loss = 0.07257601747844826
Trained batch 171 in epoch 8, gen_loss = 0.8363303166142729, disc_loss = 0.07234711473439495
Trained batch 172 in epoch 8, gen_loss = 0.8382154515368401, disc_loss = 0.0722593174213705
Trained batch 173 in epoch 8, gen_loss = 0.8360959238362038, disc_loss = 0.07294970417352414
Trained batch 174 in epoch 8, gen_loss = 0.8360864974771227, disc_loss = 0.07276761664343731
Trained batch 175 in epoch 8, gen_loss = 0.8365645227445797, disc_loss = 0.07249016461322423
Trained batch 176 in epoch 8, gen_loss = 0.8358210825313956, disc_loss = 0.07232412069215108
Trained batch 177 in epoch 8, gen_loss = 0.836080223824201, disc_loss = 0.07265781599170204
Trained batch 178 in epoch 8, gen_loss = 0.8355777984557871, disc_loss = 0.07260881294106139
Trained batch 179 in epoch 8, gen_loss = 0.8351250461406178, disc_loss = 0.07271037065010104
Trained batch 180 in epoch 8, gen_loss = 0.8355821214657462, disc_loss = 0.0727583790733093
Trained batch 181 in epoch 8, gen_loss = 0.8340595693706156, disc_loss = 0.07335394564094944
Trained batch 182 in epoch 8, gen_loss = 0.8331803488926809, disc_loss = 0.0732643527584405
Trained batch 183 in epoch 8, gen_loss = 0.8344622806686423, disc_loss = 0.07319147978484145
Trained batch 184 in epoch 8, gen_loss = 0.8344292287890975, disc_loss = 0.07290109372320207
Trained batch 185 in epoch 8, gen_loss = 0.8337273490364834, disc_loss = 0.07280519010338893
Trained batch 186 in epoch 8, gen_loss = 0.8339193601978017, disc_loss = 0.07255180586966123
Trained batch 187 in epoch 8, gen_loss = 0.8355577272620607, disc_loss = 0.07260822445808097
Trained batch 188 in epoch 8, gen_loss = 0.8345963899736051, disc_loss = 0.07279250708226331
Trained batch 189 in epoch 8, gen_loss = 0.8325858266730057, disc_loss = 0.07332878383856854
Trained batch 190 in epoch 8, gen_loss = 0.8349136226464317, disc_loss = 0.07351662932909753
Trained batch 191 in epoch 8, gen_loss = 0.8345932103693485, disc_loss = 0.07332427109455845
Trained batch 192 in epoch 8, gen_loss = 0.8360018038379096, disc_loss = 0.07301534800621358
Trained batch 193 in epoch 8, gen_loss = 0.8352893197659365, disc_loss = 0.0729559834652878
Trained batch 194 in epoch 8, gen_loss = 0.8369143828367576, disc_loss = 0.07335808899444647
Trained batch 195 in epoch 8, gen_loss = 0.8361053357318956, disc_loss = 0.07353579362721316
Trained batch 196 in epoch 8, gen_loss = 0.8371978713776255, disc_loss = 0.07335589258331181
Trained batch 197 in epoch 8, gen_loss = 0.8371345611533734, disc_loss = 0.07315431226214225
Trained batch 198 in epoch 8, gen_loss = 0.8366401342291329, disc_loss = 0.07295588605648759
Trained batch 199 in epoch 8, gen_loss = 0.8363590052723885, disc_loss = 0.07274532640818507
Trained batch 200 in epoch 8, gen_loss = 0.8363212083109576, disc_loss = 0.0729869744828462
Trained batch 201 in epoch 8, gen_loss = 0.8357435296667685, disc_loss = 0.07272682459287272
Trained batch 202 in epoch 8, gen_loss = 0.8363361244131191, disc_loss = 0.07264701545403655
Trained batch 203 in epoch 8, gen_loss = 0.8349000814498639, disc_loss = 0.07317711121183545
Trained batch 204 in epoch 8, gen_loss = 0.8362646687321547, disc_loss = 0.07295498594914268
Trained batch 205 in epoch 8, gen_loss = 0.8374870080971023, disc_loss = 0.07301131977238556
Trained batch 206 in epoch 8, gen_loss = 0.8361525757301257, disc_loss = 0.07311726963948369
Trained batch 207 in epoch 8, gen_loss = 0.8360849994306381, disc_loss = 0.07290116429346828
Trained batch 208 in epoch 8, gen_loss = 0.8368303313780059, disc_loss = 0.07268378238804175
Trained batch 209 in epoch 8, gen_loss = 0.8363065438611167, disc_loss = 0.0727144265503046
Trained batch 210 in epoch 8, gen_loss = 0.8356677480218535, disc_loss = 0.07269596965692196
Trained batch 211 in epoch 8, gen_loss = 0.8359359539342377, disc_loss = 0.07252186370293065
Trained batch 212 in epoch 8, gen_loss = 0.8350054504166187, disc_loss = 0.07246529717138256
Trained batch 213 in epoch 8, gen_loss = 0.8356759648456752, disc_loss = 0.07251665940090457
Trained batch 214 in epoch 8, gen_loss = 0.8348162396009579, disc_loss = 0.07265247890162607
Trained batch 215 in epoch 8, gen_loss = 0.8334452479525849, disc_loss = 0.07311466716109188
Trained batch 216 in epoch 8, gen_loss = 0.8340437044196415, disc_loss = 0.07288288771848662
Trained batch 217 in epoch 8, gen_loss = 0.8345334136157955, disc_loss = 0.07346128423296668
Trained batch 218 in epoch 8, gen_loss = 0.833411660368584, disc_loss = 0.07373042884771819
Trained batch 219 in epoch 8, gen_loss = 0.834006189216267, disc_loss = 0.07350168142213741
Trained batch 220 in epoch 8, gen_loss = 0.8354273678490479, disc_loss = 0.07350839329335619
Trained batch 221 in epoch 8, gen_loss = 0.8368063332798245, disc_loss = 0.07337084614361326
Trained batch 222 in epoch 8, gen_loss = 0.8360786253561353, disc_loss = 0.07336846438775282
Trained batch 223 in epoch 8, gen_loss = 0.8346368210124118, disc_loss = 0.0738955332074381
Trained batch 224 in epoch 8, gen_loss = 0.8350458598136902, disc_loss = 0.07390654716640711
Trained batch 225 in epoch 8, gen_loss = 0.8356949462827328, disc_loss = 0.07384982761572552
Trained batch 226 in epoch 8, gen_loss = 0.8362711741535674, disc_loss = 0.07365201948218802
Trained batch 227 in epoch 8, gen_loss = 0.8352455512473458, disc_loss = 0.07374206008471287
Trained batch 228 in epoch 8, gen_loss = 0.8346150389925361, disc_loss = 0.0735637549611874
Trained batch 229 in epoch 8, gen_loss = 0.8338854320671247, disc_loss = 0.0734794128321759
Trained batch 230 in epoch 8, gen_loss = 0.8361736631496645, disc_loss = 0.07480852184534977
Trained batch 231 in epoch 8, gen_loss = 0.8352296103177399, disc_loss = 0.07486367053432583
Trained batch 232 in epoch 8, gen_loss = 0.8347042428065778, disc_loss = 0.07485700329533847
Trained batch 233 in epoch 8, gen_loss = 0.8346264548281319, disc_loss = 0.074992600394588
Trained batch 234 in epoch 8, gen_loss = 0.8337877070650141, disc_loss = 0.07494584415107966
Trained batch 235 in epoch 8, gen_loss = 0.8336441158238104, disc_loss = 0.07473004731286506
Trained batch 236 in epoch 8, gen_loss = 0.8339412841112804, disc_loss = 0.07450647275297577
Trained batch 237 in epoch 8, gen_loss = 0.8345306701019031, disc_loss = 0.07443965007668409
Trained batch 238 in epoch 8, gen_loss = 0.8339890865102473, disc_loss = 0.07441962604258973
Trained batch 239 in epoch 8, gen_loss = 0.834266812602679, disc_loss = 0.0742146165537027
Trained batch 240 in epoch 8, gen_loss = 0.8345635659467135, disc_loss = 0.07420989318801036
Trained batch 241 in epoch 8, gen_loss = 0.8344694602587992, disc_loss = 0.0740448561543214
Trained batch 242 in epoch 8, gen_loss = 0.8337266278365021, disc_loss = 0.0740687166428799
Trained batch 243 in epoch 8, gen_loss = 0.8344553718801404, disc_loss = 0.07416531779101027
Trained batch 244 in epoch 8, gen_loss = 0.8340777382558706, disc_loss = 0.07418651860207319
Trained batch 245 in epoch 8, gen_loss = 0.8359545793959765, disc_loss = 0.07434613944780899
Trained batch 246 in epoch 8, gen_loss = 0.8345534145108119, disc_loss = 0.07471001898937742
Trained batch 247 in epoch 8, gen_loss = 0.8349488533792957, disc_loss = 0.07446118371726404
Trained batch 248 in epoch 8, gen_loss = 0.8346700065107231, disc_loss = 0.07429870597674067
Trained batch 249 in epoch 8, gen_loss = 0.8347019605636596, disc_loss = 0.07420654031261802
Trained batch 250 in epoch 8, gen_loss = 0.8344937280354747, disc_loss = 0.07405298848476899
Trained batch 251 in epoch 8, gen_loss = 0.8342785494668143, disc_loss = 0.073840730198999
Trained batch 252 in epoch 8, gen_loss = 0.8347736154149172, disc_loss = 0.07358134597937463
Trained batch 253 in epoch 8, gen_loss = 0.8356804096792626, disc_loss = 0.07341086444642952
Trained batch 254 in epoch 8, gen_loss = 0.8359733139767366, disc_loss = 0.07319973779148331
Trained batch 256 in epoch 8, gen_loss = 0.8356379184741455, disc_loss = 0.07286850724311306
Trained batch 257 in epoch 8, gen_loss = 0.8364783481572026, disc_loss = 0.0728713251657553
Trained batch 258 in epoch 8, gen_loss = 0.836873471736908, disc_loss = 0.07264534275777437
Trained batch 259 in epoch 8, gen_loss = 0.8373083215493422, disc_loss = 0.07243122870747287
Trained batch 260 in epoch 8, gen_loss = 0.8363315049715883, disc_loss = 0.07275550329693775
Trained batch 261 in epoch 8, gen_loss = 0.8366513739105399, disc_loss = 0.0725463985337499
Trained batch 262 in epoch 8, gen_loss = 0.8375840971225115, disc_loss = 0.07241906726754097
Trained batch 263 in epoch 8, gen_loss = 0.837497357617725, disc_loss = 0.07237110416419014
Trained batch 264 in epoch 8, gen_loss = 0.8376446629470249, disc_loss = 0.07220910643842422
Trained batch 265 in epoch 8, gen_loss = 0.8368975027163226, disc_loss = 0.07204160645001925
Trained batch 266 in epoch 8, gen_loss = 0.8381400385152981, disc_loss = 0.0721083829416597
Trained batch 267 in epoch 8, gen_loss = 0.8375788580125837, disc_loss = 0.07217033603923645
Trained batch 268 in epoch 8, gen_loss = 0.8375833743566917, disc_loss = 0.0719414592779425
Trained batch 269 in epoch 8, gen_loss = 0.837792827906432, disc_loss = 0.07174142125511059
Trained batch 270 in epoch 8, gen_loss = 0.8380049418699258, disc_loss = 0.0715347692830921
Trained batch 271 in epoch 8, gen_loss = 0.8383765045334312, disc_loss = 0.07139515595661257
Trained batch 272 in epoch 8, gen_loss = 0.8381646456735912, disc_loss = 0.07118189154404314
Trained batch 273 in epoch 8, gen_loss = 0.8392008007877935, disc_loss = 0.07106484781039783
Trained batch 274 in epoch 8, gen_loss = 0.838739202672785, disc_loss = 0.07098291384564205
Trained batch 275 in epoch 8, gen_loss = 0.8393637075804282, disc_loss = 0.07076620350699818
Trained batch 276 in epoch 8, gen_loss = 0.838776743368982, disc_loss = 0.07082842152888487
Trained batch 277 in epoch 8, gen_loss = 0.839544688626159, disc_loss = 0.07131393899363901
Trained batch 278 in epoch 8, gen_loss = 0.8388967667856524, disc_loss = 0.07130825580648517
Trained batch 279 in epoch 8, gen_loss = 0.8390302713428225, disc_loss = 0.07126948658842594
Trained batch 280 in epoch 8, gen_loss = 0.8389896082284187, disc_loss = 0.07108086990225676
Trained batch 281 in epoch 8, gen_loss = 0.838844157068442, disc_loss = 0.0709554557094073
Trained batch 282 in epoch 8, gen_loss = 0.8378320612250284, disc_loss = 0.070938078716213
Trained batch 283 in epoch 8, gen_loss = 0.8384477647257523, disc_loss = 0.07073688610050251
Trained batch 284 in epoch 8, gen_loss = 0.8385367247096279, disc_loss = 0.0705842358174554
Trained batch 285 in epoch 8, gen_loss = 0.8384979175520944, disc_loss = 0.07046545565883805
Trained batch 286 in epoch 8, gen_loss = 0.8392424919879395, disc_loss = 0.07031229131235271
Trained batch 287 in epoch 8, gen_loss = 0.8400134224858549, disc_loss = 0.07019550359109417
Trained batch 288 in epoch 8, gen_loss = 0.8399503043366139, disc_loss = 0.07008263789065775
Trained batch 289 in epoch 8, gen_loss = 0.8397927037600813, disc_loss = 0.07002532520042411
Trained batch 290 in epoch 8, gen_loss = 0.839885842759175, disc_loss = 0.0698815448548888
Trained batch 291 in epoch 8, gen_loss = 0.8410751917590834, disc_loss = 0.06984615575343575
Trained batch 292 in epoch 8, gen_loss = 0.8407862603460969, disc_loss = 0.06968174901482595
Trained batch 293 in epoch 8, gen_loss = 0.8405891679176668, disc_loss = 0.06953279896430214
Trained batch 294 in epoch 8, gen_loss = 0.8413344078144784, disc_loss = 0.06962171663545956
Trained batch 295 in epoch 8, gen_loss = 0.8403748926278707, disc_loss = 0.06993138968214593
Trained batch 296 in epoch 8, gen_loss = 0.8403552236781778, disc_loss = 0.07028702098989126
Trained batch 297 in epoch 8, gen_loss = 0.8408683994472427, disc_loss = 0.07009737171082689
Trained batch 298 in epoch 8, gen_loss = 0.840124771547158, disc_loss = 0.0701546337592562
Trained batch 299 in epoch 8, gen_loss = 0.8406686268250148, disc_loss = 0.06999322944010297
Trained batch 300 in epoch 8, gen_loss = 0.8396103354387505, disc_loss = 0.07029874457597138
Trained batch 301 in epoch 8, gen_loss = 0.8411007981426668, disc_loss = 0.07082832252471061
Trained batch 302 in epoch 8, gen_loss = 0.841080108491501, disc_loss = 0.07079779107750643
Trained batch 303 in epoch 8, gen_loss = 0.8406973485099641, disc_loss = 0.070832698673353
Trained batch 304 in epoch 8, gen_loss = 0.8400283227201368, disc_loss = 0.07129729553202137
Trained batch 305 in epoch 8, gen_loss = 0.839103983508216, disc_loss = 0.07155892683278306
Trained batch 306 in epoch 8, gen_loss = 0.8394084388347712, disc_loss = 0.07169530668723662
Trained batch 307 in epoch 8, gen_loss = 0.8392367579720237, disc_loss = 0.07177135163869758
Trained batch 308 in epoch 8, gen_loss = 0.8392084082739253, disc_loss = 0.07194896258751358
Trained batch 309 in epoch 8, gen_loss = 0.8388443660351538, disc_loss = 0.07196505520973474
Trained batch 310 in epoch 8, gen_loss = 0.8386907104127277, disc_loss = 0.07187349455269396
Trained batch 311 in epoch 8, gen_loss = 0.8390346945096285, disc_loss = 0.0716951606878772
Trained batch 312 in epoch 8, gen_loss = 0.8395176318506844, disc_loss = 0.07187727559655428
Trained batch 313 in epoch 8, gen_loss = 0.8387448764910364, disc_loss = 0.07204603426941451
Trained batch 314 in epoch 8, gen_loss = 0.8380561554242694, disc_loss = 0.07210106378391622
Trained batch 315 in epoch 8, gen_loss = 0.8388709325956393, disc_loss = 0.07218432885630033
Trained batch 316 in epoch 8, gen_loss = 0.8383899733471194, disc_loss = 0.07233620636541196
Trained batch 317 in epoch 8, gen_loss = 0.8377000175931919, disc_loss = 0.07247044518004236
Trained batch 318 in epoch 8, gen_loss = 0.8376247458697113, disc_loss = 0.07246349221183028
Trained batch 319 in epoch 8, gen_loss = 0.8378951294347644, disc_loss = 0.07260351240984164
Trained batch 320 in epoch 8, gen_loss = 0.8382301869050736, disc_loss = 0.07251841199476956
Trained batch 321 in epoch 8, gen_loss = 0.8377719155009489, disc_loss = 0.07265829783719704
Trained batch 322 in epoch 8, gen_loss = 0.8382390357392491, disc_loss = 0.07246955339407589
Trained batch 323 in epoch 8, gen_loss = 0.8383744679115437, disc_loss = 0.07240345158303778
Trained batch 324 in epoch 8, gen_loss = 0.8385522904762855, disc_loss = 0.07223988124957452
Trained batch 325 in epoch 8, gen_loss = 0.8379127898830577, disc_loss = 0.07226150446325723
Trained batch 326 in epoch 8, gen_loss = 0.8371371482854953, disc_loss = 0.07223551786456268
Trained batch 327 in epoch 8, gen_loss = 0.8379570242108368, disc_loss = 0.07218150960326922
Trained batch 328 in epoch 8, gen_loss = 0.8386235258861878, disc_loss = 0.07206045921133282
Trained batch 329 in epoch 8, gen_loss = 0.8380184601653706, disc_loss = 0.07218483066694303
Trained batch 330 in epoch 8, gen_loss = 0.8379427783438806, disc_loss = 0.07200333102974826
Trained batch 331 in epoch 8, gen_loss = 0.8383913232260439, disc_loss = 0.07218143331021609
Trained batch 332 in epoch 8, gen_loss = 0.8386322977664592, disc_loss = 0.07202021878872726
Trained batch 333 in epoch 8, gen_loss = 0.8390834575998569, disc_loss = 0.07190053744386592
Trained batch 334 in epoch 8, gen_loss = 0.8382170614911549, disc_loss = 0.07200566447381652
Trained batch 335 in epoch 8, gen_loss = 0.8375699454475016, disc_loss = 0.07229104267233717
Trained batch 336 in epoch 8, gen_loss = 0.8383524051759647, disc_loss = 0.07274357830270992
Trained batch 337 in epoch 8, gen_loss = 0.8377969171521227, disc_loss = 0.07270747587944452
Trained batch 338 in epoch 8, gen_loss = 0.8378431902522534, disc_loss = 0.07257906374436389
Trained batch 339 in epoch 8, gen_loss = 0.8386282072347753, disc_loss = 0.07264870460528661
Trained batch 340 in epoch 8, gen_loss = 0.8380572991636841, disc_loss = 0.07264038503628847
Trained batch 341 in epoch 8, gen_loss = 0.8380238044331645, disc_loss = 0.07250834191599262
Trained batch 342 in epoch 8, gen_loss = 0.8387842060178083, disc_loss = 0.07256427544655153
Trained batch 343 in epoch 8, gen_loss = 0.8384628645902457, disc_loss = 0.07246776450923535
Trained batch 344 in epoch 8, gen_loss = 0.8382415375847747, disc_loss = 0.07231839156129222
Trained batch 345 in epoch 8, gen_loss = 0.8391141803622935, disc_loss = 0.07264799189167043
Trained batch 346 in epoch 8, gen_loss = 0.8387551465707829, disc_loss = 0.07269506276147682
Trained batch 347 in epoch 8, gen_loss = 0.838972264494019, disc_loss = 0.07258852885436566
Trained batch 348 in epoch 8, gen_loss = 0.8394573658790151, disc_loss = 0.07247297406559516
Trained batch 349 in epoch 8, gen_loss = 0.8389688081400735, disc_loss = 0.07253450573022877
Trained batch 350 in epoch 8, gen_loss = 0.8397362906369049, disc_loss = 0.07236093285883594
Trained batch 351 in epoch 8, gen_loss = 0.8393722085112875, disc_loss = 0.07233807748310607
Trained batch 352 in epoch 8, gen_loss = 0.8396309153216419, disc_loss = 0.0721982976912439
Trained batch 353 in epoch 8, gen_loss = 0.839751071175613, disc_loss = 0.07208355006861822
Trained batch 354 in epoch 8, gen_loss = 0.8400306562302817, disc_loss = 0.07198593517844105
Trained batch 355 in epoch 8, gen_loss = 0.8393098283349798, disc_loss = 0.07203850595887458
Trained batch 356 in epoch 8, gen_loss = 0.839368222474384, disc_loss = 0.07189566573696811
Trained batch 357 in epoch 8, gen_loss = 0.8397031263266196, disc_loss = 0.0724657153003126
Trained batch 358 in epoch 8, gen_loss = 0.8390029482854774, disc_loss = 0.07244945409341941
Trained batch 359 in epoch 8, gen_loss = 0.8390937447547913, disc_loss = 0.07237014025967155
Trained batch 360 in epoch 8, gen_loss = 0.8387067441795011, disc_loss = 0.07236815514842725
Trained batch 361 in epoch 8, gen_loss = 0.8393216151229584, disc_loss = 0.0722322349915106
Trained batch 362 in epoch 8, gen_loss = 0.839637336652141, disc_loss = 0.07215868252183287
Trained batch 363 in epoch 8, gen_loss = 0.839047684446796, disc_loss = 0.07207581830200749
Trained batch 364 in epoch 8, gen_loss = 0.8388590979249511, disc_loss = 0.07204358342473638
Trained batch 365 in epoch 8, gen_loss = 0.8393001002692134, disc_loss = 0.07224913492615594
Trained batch 366 in epoch 8, gen_loss = 0.8388295621897934, disc_loss = 0.0721698452030849
Trained batch 367 in epoch 8, gen_loss = 0.8380831729458726, disc_loss = 0.07243190519005546
Trained batch 368 in epoch 8, gen_loss = 0.8388492498940568, disc_loss = 0.07234968983525344
Trained batch 369 in epoch 8, gen_loss = 0.8389526798918441, disc_loss = 0.07256141743446524
Trained batch 370 in epoch 8, gen_loss = 0.8382544456466511, disc_loss = 0.07254571270328165
Trained batch 371 in epoch 8, gen_loss = 0.8374160569842144, disc_loss = 0.07271160110731119
Trained batch 372 in epoch 8, gen_loss = 0.8376960171131922, disc_loss = 0.07295237994445712
Trained batch 373 in epoch 8, gen_loss = 0.837569808736842, disc_loss = 0.07310871705711684
Trained batch 374 in epoch 8, gen_loss = 0.8372327426274617, disc_loss = 0.07329365421831607
Trained batch 375 in epoch 8, gen_loss = 0.8371326244891958, disc_loss = 0.07326818124311878
Trained batch 376 in epoch 8, gen_loss = 0.8369220180600012, disc_loss = 0.07323947880387464
Trained batch 377 in epoch 8, gen_loss = 0.8369055879179133, disc_loss = 0.07311613817339536
Trained batch 378 in epoch 8, gen_loss = 0.8361082004682999, disc_loss = 0.07326222821519683
Trained batch 379 in epoch 8, gen_loss = 0.8361886557779814, disc_loss = 0.07312830945378855
Trained batch 380 in epoch 8, gen_loss = 0.8359152621484491, disc_loss = 0.0730231171498305
Trained batch 381 in epoch 8, gen_loss = 0.8359881734660782, disc_loss = 0.07296599885595094
Trained batch 382 in epoch 8, gen_loss = 0.8351540148413835, disc_loss = 0.07313989022109589
Trained batch 383 in epoch 8, gen_loss = 0.8354860035081705, disc_loss = 0.0730743180514158
Trained batch 384 in epoch 8, gen_loss = 0.8348916857273547, disc_loss = 0.07321086507532504
Trained batch 385 in epoch 8, gen_loss = 0.8348513483383495, disc_loss = 0.07320941317768603
Trained batch 386 in epoch 8, gen_loss = 0.8354428153321416, disc_loss = 0.07358238652579543
Trained batch 387 in epoch 8, gen_loss = 0.8349620318904365, disc_loss = 0.07368282744296126
Trained batch 388 in epoch 8, gen_loss = 0.8344114108686276, disc_loss = 0.07375054223257042
Trained batch 389 in epoch 8, gen_loss = 0.834629452534211, disc_loss = 0.07392986971789446
Trained batch 390 in epoch 8, gen_loss = 0.8343639562806815, disc_loss = 0.07385734664966993
Trained batch 391 in epoch 8, gen_loss = 0.8339340841891815, disc_loss = 0.07397736392307039
Trained batch 392 in epoch 8, gen_loss = 0.833461726591484, disc_loss = 0.07396988752689071
Trained batch 393 in epoch 8, gen_loss = 0.8341538536972201, disc_loss = 0.07407039040841427
Trained batch 394 in epoch 8, gen_loss = 0.8338497492331493, disc_loss = 0.07402720102403737
Trained batch 395 in epoch 8, gen_loss = 0.8334809741889587, disc_loss = 0.0740636664094648
Trained batch 396 in epoch 8, gen_loss = 0.833535341982277, disc_loss = 0.07418966773775422
Trained batch 397 in epoch 8, gen_loss = 0.8326739586477903, disc_loss = 0.07450084410720136
Trained batch 398 in epoch 8, gen_loss = 0.8330123082438209, disc_loss = 0.07454897610839446
Trained batch 399 in epoch 8, gen_loss = 0.8322252084314823, disc_loss = 0.07459300637245178
Trained batch 400 in epoch 8, gen_loss = 0.8319710980627008, disc_loss = 0.07456388798289168
Trained batch 401 in epoch 8, gen_loss = 0.8324360725891531, disc_loss = 0.07488801801086065
Trained batch 402 in epoch 8, gen_loss = 0.8319958105276595, disc_loss = 0.074788659533703
Trained batch 403 in epoch 8, gen_loss = 0.831352164839754, disc_loss = 0.07501899069267334
Trained batch 404 in epoch 8, gen_loss = 0.8317545556727751, disc_loss = 0.0748976693937072
Trained batch 405 in epoch 8, gen_loss = 0.8316717994917789, disc_loss = 0.07494398266113744
Trained batch 406 in epoch 8, gen_loss = 0.8310862567266609, disc_loss = 0.075025767975782
Trained batch 407 in epoch 8, gen_loss = 0.8312782919874379, disc_loss = 0.0748909481837615
Trained batch 408 in epoch 8, gen_loss = 0.831061632534111, disc_loss = 0.07496683216656042
Trained batch 409 in epoch 8, gen_loss = 0.831097765230551, disc_loss = 0.07488450786871154
Trained batch 410 in epoch 8, gen_loss = 0.8305267286996771, disc_loss = 0.07494376803727916
Trained batch 411 in epoch 8, gen_loss = 0.8310083807672112, disc_loss = 0.07498207389042505
Trained batch 412 in epoch 8, gen_loss = 0.8306268121659323, disc_loss = 0.07494275361191274
Trained batch 413 in epoch 8, gen_loss = 0.8308830857276917, disc_loss = 0.07479065942582516
Trained batch 414 in epoch 8, gen_loss = 0.8313894912420985, disc_loss = 0.07463927843708949
Trained batch 415 in epoch 8, gen_loss = 0.8316939573448437, disc_loss = 0.07449411402698249
Trained batch 416 in epoch 8, gen_loss = 0.8316249623001336, disc_loss = 0.07444512686631877
Trained batch 417 in epoch 8, gen_loss = 0.8316669689411181, disc_loss = 0.07445215178724895
Trained batch 418 in epoch 8, gen_loss = 0.8317700177786743, disc_loss = 0.07432358885997449
Trained batch 419 in epoch 8, gen_loss = 0.8314177358434314, disc_loss = 0.07428369819009233
Trained batch 420 in epoch 8, gen_loss = 0.8320182166869736, disc_loss = 0.07417607245272172
Trained batch 421 in epoch 8, gen_loss = 0.832055470107291, disc_loss = 0.07406572652627577
Trained batch 422 in epoch 8, gen_loss = 0.8315948259182292, disc_loss = 0.074133005153925
Trained batch 423 in epoch 8, gen_loss = 0.8322029394923516, disc_loss = 0.07459452716009866
Trained batch 424 in epoch 8, gen_loss = 0.8321799543324638, disc_loss = 0.07446329869987334
Trained batch 425 in epoch 8, gen_loss = 0.8320974574682298, disc_loss = 0.07460741803023807
Trained batch 426 in epoch 8, gen_loss = 0.8321017645281986, disc_loss = 0.07453989737669324
Trained batch 427 in epoch 8, gen_loss = 0.8326165582810607, disc_loss = 0.07447813929354545
Trained batch 428 in epoch 8, gen_loss = 0.8326381290709222, disc_loss = 0.07437226077919448
Trained batch 429 in epoch 8, gen_loss = 0.8325785808785017, disc_loss = 0.07430671313777566
Trained batch 430 in epoch 8, gen_loss = 0.8320287107868151, disc_loss = 0.07434784239611811
Trained batch 431 in epoch 8, gen_loss = 0.831857993784878, disc_loss = 0.07463207179292415
Trained batch 432 in epoch 8, gen_loss = 0.8324490971433097, disc_loss = 0.07454446951619954
Trained batch 433 in epoch 8, gen_loss = 0.8326145667359576, disc_loss = 0.07441327576461132
Trained batch 434 in epoch 8, gen_loss = 0.8325441082318624, disc_loss = 0.07427561695676768
Trained batch 435 in epoch 8, gen_loss = 0.832852965921437, disc_loss = 0.07415746651171203
Trained batch 436 in epoch 8, gen_loss = 0.8325209683084379, disc_loss = 0.07405819742379868
Trained batch 437 in epoch 8, gen_loss = 0.8325473017072025, disc_loss = 0.07392697390721745
Trained batch 438 in epoch 8, gen_loss = 0.8325723903868899, disc_loss = 0.07379389561262992
Trained batch 439 in epoch 8, gen_loss = 0.8322491896423426, disc_loss = 0.07390452422074635
Trained batch 440 in epoch 8, gen_loss = 0.832462853720399, disc_loss = 0.07381472774821411
Trained batch 441 in epoch 8, gen_loss = 0.8319078592153696, disc_loss = 0.0738223254010587
Trained batch 442 in epoch 8, gen_loss = 0.8321028789063878, disc_loss = 0.0736774108593371
Trained batch 443 in epoch 8, gen_loss = 0.8329589860933321, disc_loss = 0.0736349322182873
Trained batch 444 in epoch 8, gen_loss = 0.8327489148364978, disc_loss = 0.07360535593640603
Trained batch 445 in epoch 8, gen_loss = 0.833355647833358, disc_loss = 0.07366710882675688
Trained batch 446 in epoch 8, gen_loss = 0.8333885684376061, disc_loss = 0.07358303657572475
Trained batch 447 in epoch 8, gen_loss = 0.8331466629835111, disc_loss = 0.07350186700724796
Trained batch 448 in epoch 8, gen_loss = 0.8334504721690392, disc_loss = 0.07337129868376162
Trained batch 449 in epoch 8, gen_loss = 0.8345438652568393, disc_loss = 0.07328337187361386
Trained batch 450 in epoch 8, gen_loss = 0.8347612803103919, disc_loss = 0.07316188404993247
Trained batch 451 in epoch 8, gen_loss = 0.8340637257932562, disc_loss = 0.07334243255436618
Trained batch 452 in epoch 8, gen_loss = 0.8349426849262077, disc_loss = 0.07353710318827142
Trained batch 453 in epoch 8, gen_loss = 0.8353436425131323, disc_loss = 0.07345062830497712
Trained batch 454 in epoch 8, gen_loss = 0.8351236528092688, disc_loss = 0.0733644035470846
Trained batch 455 in epoch 8, gen_loss = 0.835383021125668, disc_loss = 0.07326065264274612
Trained batch 456 in epoch 8, gen_loss = 0.836031232021048, disc_loss = 0.07314797993993928
Trained batch 457 in epoch 8, gen_loss = 0.8358175012742588, disc_loss = 0.07309731886840087
Trained batch 458 in epoch 8, gen_loss = 0.8361644900702183, disc_loss = 0.07297135456333298
Trained batch 459 in epoch 8, gen_loss = 0.8361773322457853, disc_loss = 0.07291755728302118
Trained batch 460 in epoch 8, gen_loss = 0.8362259877736553, disc_loss = 0.07280597480422052
Trained batch 461 in epoch 8, gen_loss = 0.8359763660988251, disc_loss = 0.0727123469860168
Trained batch 462 in epoch 8, gen_loss = 0.8364188261732427, disc_loss = 0.07257999368132641
Trained batch 463 in epoch 8, gen_loss = 0.836533952761313, disc_loss = 0.07244984750387035
Trained batch 464 in epoch 8, gen_loss = 0.8362661219412281, disc_loss = 0.07235313020446288
Trained batch 465 in epoch 8, gen_loss = 0.8368908444443486, disc_loss = 0.07230077267628435
Trained batch 466 in epoch 8, gen_loss = 0.836834871666845, disc_loss = 0.07217032122934273
Trained batch 467 in epoch 8, gen_loss = 0.8364854708441303, disc_loss = 0.07212018413055274
Trained batch 468 in epoch 8, gen_loss = 0.8367016718331685, disc_loss = 0.07199266670085093
Trained batch 469 in epoch 8, gen_loss = 0.8368353313588082, disc_loss = 0.07186884975377866
Trained batch 470 in epoch 8, gen_loss = 0.8372893148673315, disc_loss = 0.07204560356732703
Trained batch 471 in epoch 8, gen_loss = 0.8374739049349801, disc_loss = 0.07196919877531986
Trained batch 472 in epoch 8, gen_loss = 0.8373056650161743, disc_loss = 0.07193567923784067
Trained batch 473 in epoch 8, gen_loss = 0.8384371774609078, disc_loss = 0.07192507936552418
Trained batch 474 in epoch 8, gen_loss = 0.8390097736057482, disc_loss = 0.07182872492427889
Trained batch 475 in epoch 8, gen_loss = 0.838982212192872, disc_loss = 0.07179361164859425
Trained batch 476 in epoch 8, gen_loss = 0.8392110490698984, disc_loss = 0.07173498674828864
Trained batch 477 in epoch 8, gen_loss = 0.8383915198647327, disc_loss = 0.07195740367897696
Trained batch 478 in epoch 8, gen_loss = 0.8386644407453517, disc_loss = 0.07189695671830708
Trained batch 479 in epoch 8, gen_loss = 0.838702147329847, disc_loss = 0.07177945478858115
Trained batch 480 in epoch 8, gen_loss = 0.8385557687208212, disc_loss = 0.07169503405527551
Trained batch 481 in epoch 8, gen_loss = 0.8385609929987009, disc_loss = 0.07158353286930573
Trained batch 482 in epoch 8, gen_loss = 0.8389953791971779, disc_loss = 0.07156480816973848
Trained batch 483 in epoch 8, gen_loss = 0.8387851446620689, disc_loss = 0.07157663335015398
Trained batch 484 in epoch 8, gen_loss = 0.838696895063538, disc_loss = 0.07154756336444125
Trained batch 485 in epoch 8, gen_loss = 0.8390552635791371, disc_loss = 0.07142309180303734
Trained batch 486 in epoch 8, gen_loss = 0.8400696123160376, disc_loss = 0.07193469797362415
Trained batch 487 in epoch 8, gen_loss = 0.8393142683828463, disc_loss = 0.0722504432320778
Trained batch 488 in epoch 8, gen_loss = 0.8393311723609643, disc_loss = 0.07273983529907915
Trained batch 489 in epoch 8, gen_loss = 0.8385900252935837, disc_loss = 0.07308857064998271
Trained batch 490 in epoch 8, gen_loss = 0.8382372442185272, disc_loss = 0.07341370333646198
Trained batch 491 in epoch 8, gen_loss = 0.8377930902368654, disc_loss = 0.07345646967717666
Trained batch 492 in epoch 8, gen_loss = 0.8374549392270751, disc_loss = 0.07369893290193158
Trained batch 493 in epoch 8, gen_loss = 0.8372842997674518, disc_loss = 0.0737762625031324
Trained batch 494 in epoch 8, gen_loss = 0.8368155138661163, disc_loss = 0.0739023008242701
Trained batch 495 in epoch 8, gen_loss = 0.8363641002966512, disc_loss = 0.07420902862589085
Trained batch 496 in epoch 8, gen_loss = 0.8360305613195392, disc_loss = 0.07447815653109095
Trained batch 497 in epoch 8, gen_loss = 0.8362474272768181, disc_loss = 0.07445864566044516
Trained batch 498 in epoch 8, gen_loss = 0.8358278218395485, disc_loss = 0.07451702158278478
Trained batch 499 in epoch 8, gen_loss = 0.835920858502388, disc_loss = 0.07441911749541759
Trained batch 500 in epoch 8, gen_loss = 0.836042104842896, disc_loss = 0.07432335258987612
Trained batch 501 in epoch 8, gen_loss = 0.8363413849912317, disc_loss = 0.07433973292104039
Trained batch 502 in epoch 8, gen_loss = 0.8364397806391327, disc_loss = 0.07425986388864858
Trained batch 503 in epoch 8, gen_loss = 0.8360905344524081, disc_loss = 0.07429877003388745
Trained batch 504 in epoch 8, gen_loss = 0.8362922794748061, disc_loss = 0.07420471759494579
Trained batch 505 in epoch 8, gen_loss = 0.8367336115582659, disc_loss = 0.07409466331154697
Trained batch 506 in epoch 8, gen_loss = 0.8365502191718514, disc_loss = 0.07400973584995232
Trained batch 507 in epoch 8, gen_loss = 0.8366980702858272, disc_loss = 0.07389119854856899
Trained batch 508 in epoch 8, gen_loss = 0.8366762759174954, disc_loss = 0.07379755308240477
Trained batch 509 in epoch 8, gen_loss = 0.8366589225974738, disc_loss = 0.07370277193977552
Trained batch 510 in epoch 8, gen_loss = 0.8364299120501762, disc_loss = 0.07374648292733033
Trained batch 511 in epoch 8, gen_loss = 0.836335904430598, disc_loss = 0.07370751775306417
Trained batch 512 in epoch 8, gen_loss = 0.8356601649906203, disc_loss = 0.07388878024780494
Trained batch 513 in epoch 8, gen_loss = 0.8363081912006386, disc_loss = 0.0738729975378351
Trained batch 514 in epoch 8, gen_loss = 0.8362460399715645, disc_loss = 0.07378057481232778
Trained batch 515 in epoch 8, gen_loss = 0.836690848361152, disc_loss = 0.07367340583975117
Trained batch 516 in epoch 8, gen_loss = 0.8368525243935317, disc_loss = 0.07357509066377779
Trained batch 517 in epoch 8, gen_loss = 0.8362927428198598, disc_loss = 0.07370084884817421
Trained batch 518 in epoch 8, gen_loss = 0.8367769599305412, disc_loss = 0.07383288627917482
Trained batch 519 in epoch 8, gen_loss = 0.8365616051623455, disc_loss = 0.07381686683959113
Trained batch 520 in epoch 8, gen_loss = 0.8367219573591126, disc_loss = 0.07372604392383127
Trained batch 521 in epoch 8, gen_loss = 0.836909253078859, disc_loss = 0.07361230322327536
Trained batch 522 in epoch 8, gen_loss = 0.8369149013527493, disc_loss = 0.07353701143673341
Trained batch 523 in epoch 8, gen_loss = 0.8369254882212813, disc_loss = 0.0734260926798043
Trained batch 524 in epoch 8, gen_loss = 0.8367884781814757, disc_loss = 0.0735202850011133
Trained batch 525 in epoch 8, gen_loss = 0.8367355705554042, disc_loss = 0.07347167841736015
Trained batch 526 in epoch 8, gen_loss = 0.8365818216293993, disc_loss = 0.0733942942803397
Trained batch 527 in epoch 8, gen_loss = 0.8366228123618797, disc_loss = 0.07334289579497029
Trained batch 528 in epoch 8, gen_loss = 0.8368647510365412, disc_loss = 0.0732311123369406
Trained batch 529 in epoch 8, gen_loss = 0.8369236549678839, disc_loss = 0.07313953690968876
Trained batch 530 in epoch 8, gen_loss = 0.8368509685140096, disc_loss = 0.07305624914266128
Trained batch 531 in epoch 8, gen_loss = 0.8366923855995774, disc_loss = 0.07294503865322392
Trained batch 532 in epoch 8, gen_loss = 0.8372000314393142, disc_loss = 0.07296454583383803
Trained batch 533 in epoch 8, gen_loss = 0.8377353501565448, disc_loss = 0.07286032809516631
Trained batch 534 in epoch 8, gen_loss = 0.8374654378289375, disc_loss = 0.07279418095354444
Trained batch 535 in epoch 8, gen_loss = 0.8371756541083998, disc_loss = 0.0727444590788696
Trained batch 536 in epoch 8, gen_loss = 0.8370413886213214, disc_loss = 0.0727258140769279
Trained batch 537 in epoch 8, gen_loss = 0.8375842262710337, disc_loss = 0.07261837469967823
Trained batch 538 in epoch 8, gen_loss = 0.8379165862508962, disc_loss = 0.07250388409140657
Trained batch 539 in epoch 8, gen_loss = 0.8383493312531047, disc_loss = 0.07238681595944972
Trained batch 540 in epoch 8, gen_loss = 0.8380585502895102, disc_loss = 0.07240449647675656
Trained batch 541 in epoch 8, gen_loss = 0.8381774310586197, disc_loss = 0.0724639458138482
Trained batch 542 in epoch 8, gen_loss = 0.8381273550552558, disc_loss = 0.07238737386213975
Trained batch 543 in epoch 8, gen_loss = 0.8379695347017225, disc_loss = 0.07237277428708587
Trained batch 544 in epoch 8, gen_loss = 0.8382156964288939, disc_loss = 0.07240387111936414
Trained batch 545 in epoch 8, gen_loss = 0.8389072913280774, disc_loss = 0.0723279183815769
Trained batch 546 in epoch 8, gen_loss = 0.8386919221124004, disc_loss = 0.07225062521225628
Trained batch 547 in epoch 8, gen_loss = 0.8389268243943688, disc_loss = 0.07214013804056185
Trained batch 548 in epoch 8, gen_loss = 0.8390951682635344, disc_loss = 0.07202112108964358
Trained batch 549 in epoch 8, gen_loss = 0.8389941593191841, disc_loss = 0.07195173313163898
Trained batch 550 in epoch 8, gen_loss = 0.8388440183308077, disc_loss = 0.07190325235045378
Trained batch 551 in epoch 8, gen_loss = 0.8393015270323857, disc_loss = 0.07188169964069528
Trained batch 552 in epoch 8, gen_loss = 0.8393410349948497, disc_loss = 0.07179445314101511
Trained batch 553 in epoch 8, gen_loss = 0.8394390476417025, disc_loss = 0.07173491716015049
Trained batch 554 in epoch 8, gen_loss = 0.8388670187275689, disc_loss = 0.0718643779170003
Trained batch 555 in epoch 8, gen_loss = 0.8396182785467278, disc_loss = 0.07197938106531987
Trained batch 556 in epoch 8, gen_loss = 0.84008488947228, disc_loss = 0.07191572893624941
Trained batch 557 in epoch 8, gen_loss = 0.8399735029559836, disc_loss = 0.07194778256578951
Trained batch 558 in epoch 8, gen_loss = 0.839755994635959, disc_loss = 0.07192838950539157
Trained batch 559 in epoch 8, gen_loss = 0.8398489050034966, disc_loss = 0.07198502662358805
Trained batch 560 in epoch 8, gen_loss = 0.8400409997784518, disc_loss = 0.0719125599695001
Trained batch 561 in epoch 8, gen_loss = 0.8401819035357851, disc_loss = 0.0718454700443907
Trained batch 562 in epoch 8, gen_loss = 0.8409143049488271, disc_loss = 0.07178989945551907
Trained batch 563 in epoch 8, gen_loss = 0.8409939771319958, disc_loss = 0.07180698359457789
Trained batch 564 in epoch 8, gen_loss = 0.841306774542395, disc_loss = 0.07170079724154377
Trained batch 565 in epoch 8, gen_loss = 0.8416956957469138, disc_loss = 0.07160537915844009
Trained batch 566 in epoch 8, gen_loss = 0.8418844882037484, disc_loss = 0.0715841043960612
Trained batch 567 in epoch 8, gen_loss = 0.8421020075993638, disc_loss = 0.0714886042463239
Trained batch 568 in epoch 8, gen_loss = 0.8415884486086967, disc_loss = 0.07164556736876183
Trained batch 569 in epoch 8, gen_loss = 0.842050062198388, disc_loss = 0.07170068554482177
Trained batch 570 in epoch 8, gen_loss = 0.8427197006767561, disc_loss = 0.07161356508568738
Trained batch 571 in epoch 8, gen_loss = 0.8425356268986955, disc_loss = 0.07160801161569055
Trained batch 572 in epoch 8, gen_loss = 0.8423490526892544, disc_loss = 0.07154349889606237
Trained batch 573 in epoch 8, gen_loss = 0.8426779569337592, disc_loss = 0.07148975074025136
Trained batch 574 in epoch 8, gen_loss = 0.8432648387680883, disc_loss = 0.07143636042495137
Trained batch 575 in epoch 8, gen_loss = 0.8431818547865583, disc_loss = 0.07139405859601942
Trained batch 576 in epoch 8, gen_loss = 0.843078580896404, disc_loss = 0.07136621849653367
Trained batch 577 in epoch 8, gen_loss = 0.8433428937279229, disc_loss = 0.07126712901227718
Trained batch 578 in epoch 8, gen_loss = 0.8432881284974811, disc_loss = 0.07133862295466281
Trained batch 579 in epoch 8, gen_loss = 0.8431251086551568, disc_loss = 0.07133324759337922
Trained batch 580 in epoch 8, gen_loss = 0.8430515551833812, disc_loss = 0.07123783701412033
Trained batch 581 in epoch 8, gen_loss = 0.8435740589173799, disc_loss = 0.07117212001759161
Trained batch 582 in epoch 8, gen_loss = 0.8441314731515293, disc_loss = 0.07114008667129595
Trained batch 583 in epoch 8, gen_loss = 0.8437026422215651, disc_loss = 0.0712151423811096
Trained batch 584 in epoch 8, gen_loss = 0.8431599182450873, disc_loss = 0.07129139006137848
Trained batch 585 in epoch 8, gen_loss = 0.8433366990028388, disc_loss = 0.07129124073953759
Trained batch 586 in epoch 8, gen_loss = 0.843400684034601, disc_loss = 0.07120090875349419
Trained batch 587 in epoch 8, gen_loss = 0.8433677415762629, disc_loss = 0.07112654742347646
Trained batch 588 in epoch 8, gen_loss = 0.8438821380834628, disc_loss = 0.07136606955378995
Trained batch 589 in epoch 8, gen_loss = 0.8434399206254442, disc_loss = 0.07161206340701398
Trained batch 590 in epoch 8, gen_loss = 0.8434955000171404, disc_loss = 0.07152758640207212
Trained batch 591 in epoch 8, gen_loss = 0.8435986838932779, disc_loss = 0.0715183214523603
Trained batch 592 in epoch 8, gen_loss = 0.8435350983681607, disc_loss = 0.07147846473962018
Trained batch 593 in epoch 8, gen_loss = 0.8430416943749997, disc_loss = 0.07155612945205435
Trained batch 594 in epoch 8, gen_loss = 0.8430561442835992, disc_loss = 0.07148379178232506
Trained batch 595 in epoch 8, gen_loss = 0.8430859889060058, disc_loss = 0.07152438364397959
Trained batch 596 in epoch 8, gen_loss = 0.8432192509397989, disc_loss = 0.07142275368086556
Trained batch 597 in epoch 8, gen_loss = 0.8432019114195304, disc_loss = 0.07135171870884788
Trained batch 598 in epoch 8, gen_loss = 0.8433451907762104, disc_loss = 0.07126042535699569
Trained batch 599 in epoch 8, gen_loss = 0.8438319304088752, disc_loss = 0.07122047846826414
Trained batch 600 in epoch 8, gen_loss = 0.8438289574596926, disc_loss = 0.07115815886406356
Trained batch 601 in epoch 8, gen_loss = 0.843802640851946, disc_loss = 0.07119613903515858
Trained batch 602 in epoch 8, gen_loss = 0.8437205796712272, disc_loss = 0.07112113991520595
Trained batch 603 in epoch 8, gen_loss = 0.8434378148013393, disc_loss = 0.07111943625098724
Trained batch 604 in epoch 8, gen_loss = 0.8436842359294576, disc_loss = 0.0711067885745409
Trained batch 605 in epoch 8, gen_loss = 0.8435022282620074, disc_loss = 0.07105379110577181
Trained batch 606 in epoch 8, gen_loss = 0.84350801167221, disc_loss = 0.07098878085723721
Trained batch 607 in epoch 8, gen_loss = 0.8436455072246885, disc_loss = 0.07107140825093283
Trained batch 608 in epoch 8, gen_loss = 0.8435993290006234, disc_loss = 0.07101589346179137
Trained batch 609 in epoch 8, gen_loss = 0.843617001273593, disc_loss = 0.07104715331472823
Trained batch 610 in epoch 8, gen_loss = 0.8436717828537555, disc_loss = 0.07098555925520177
Trained batch 611 in epoch 8, gen_loss = 0.8434206047186664, disc_loss = 0.07103060919706242
Trained batch 612 in epoch 8, gen_loss = 0.8435704098926283, disc_loss = 0.07105291382900361
Trained batch 613 in epoch 8, gen_loss = 0.8434676150836852, disc_loss = 0.07099409723891012
Trained batch 614 in epoch 8, gen_loss = 0.8437089394263135, disc_loss = 0.07090700958378432
Trained batch 615 in epoch 8, gen_loss = 0.8434864400172388, disc_loss = 0.07097660931879533
Trained batch 616 in epoch 8, gen_loss = 0.8433784643970007, disc_loss = 0.07090469486286903
Trained batch 617 in epoch 8, gen_loss = 0.843311202998686, disc_loss = 0.07082793673856069
Trained batch 618 in epoch 8, gen_loss = 0.8436374685972303, disc_loss = 0.0707314499745654
Trained batch 619 in epoch 8, gen_loss = 0.8439088898801035, disc_loss = 0.07064773648857109
Trained batch 620 in epoch 8, gen_loss = 0.8438803318905945, disc_loss = 0.07057571132185954
Trained batch 621 in epoch 8, gen_loss = 0.843891335214066, disc_loss = 0.07057208274985241
Trained batch 622 in epoch 8, gen_loss = 0.8438866277663322, disc_loss = 0.07052971102165755
Trained batch 623 in epoch 8, gen_loss = 0.8433366869218074, disc_loss = 0.0707351576584654
Trained batch 624 in epoch 8, gen_loss = 0.8436517479419708, disc_loss = 0.07066585627794265
Trained batch 625 in epoch 8, gen_loss = 0.8438627608001422, disc_loss = 0.07065223220485849
Trained batch 626 in epoch 8, gen_loss = 0.8434806915276358, disc_loss = 0.07064495251129309
Trained batch 627 in epoch 8, gen_loss = 0.8442477010143031, disc_loss = 0.07060055941295852
Trained batch 628 in epoch 8, gen_loss = 0.8443088191776094, disc_loss = 0.07055551969166401
Trained batch 629 in epoch 8, gen_loss = 0.8443828919104167, disc_loss = 0.07049592616893942
Trained batch 630 in epoch 8, gen_loss = 0.8444131655757288, disc_loss = 0.07046149927892512
Trained batch 631 in epoch 8, gen_loss = 0.8446456562208978, disc_loss = 0.07038530377565022
Trained batch 632 in epoch 8, gen_loss = 0.8441550169981675, disc_loss = 0.0706061414850502
Trained batch 633 in epoch 8, gen_loss = 0.8441146365381565, disc_loss = 0.07064715771985824
Trained batch 634 in epoch 8, gen_loss = 0.8440356635202573, disc_loss = 0.07065073565293954
Trained batch 635 in epoch 8, gen_loss = 0.8437836574589681, disc_loss = 0.0705817885837465
Trained batch 636 in epoch 8, gen_loss = 0.8434822818080148, disc_loss = 0.07054665427964935
Trained batch 637 in epoch 8, gen_loss = 0.8437491082192214, disc_loss = 0.07047508180515145
Trained batch 638 in epoch 8, gen_loss = 0.8436769269908164, disc_loss = 0.07040332853852396
Trained batch 639 in epoch 8, gen_loss = 0.843388904305175, disc_loss = 0.07046603971684817
Trained batch 640 in epoch 8, gen_loss = 0.8434547396513303, disc_loss = 0.07037838430589939
Trained batch 641 in epoch 8, gen_loss = 0.8436662546849325, disc_loss = 0.07029105815456199
Trained batch 642 in epoch 8, gen_loss = 0.8434410523014899, disc_loss = 0.07037989887616034
Trained batch 643 in epoch 8, gen_loss = 0.8438013051144825, disc_loss = 0.07033146892078453
Trained batch 644 in epoch 8, gen_loss = 0.8435943502326344, disc_loss = 0.07027140901705553
Trained batch 645 in epoch 8, gen_loss = 0.8434194241976222, disc_loss = 0.07023344892178066
Trained batch 646 in epoch 8, gen_loss = 0.8440104104359699, disc_loss = 0.07033353161579214
Trained batch 647 in epoch 8, gen_loss = 0.8438309177664327, disc_loss = 0.07031298222675643
Trained batch 648 in epoch 8, gen_loss = 0.8435782017344136, disc_loss = 0.07031877417811903
Trained batch 649 in epoch 8, gen_loss = 0.8432511778519703, disc_loss = 0.07032318377437499
Trained batch 650 in epoch 8, gen_loss = 0.8436574642467792, disc_loss = 0.07075668554094988
Trained batch 651 in epoch 8, gen_loss = 0.8431550629574097, disc_loss = 0.07108263951080616
Trained batch 652 in epoch 8, gen_loss = 0.8430756200418721, disc_loss = 0.07109041355413372
Trained batch 653 in epoch 8, gen_loss = 0.8431741853646182, disc_loss = 0.07111410511549368
Trained batch 654 in epoch 8, gen_loss = 0.8431808251915998, disc_loss = 0.07105824236139541
Trained batch 655 in epoch 8, gen_loss = 0.8426723613335592, disc_loss = 0.07120599453167127
Trained batch 656 in epoch 8, gen_loss = 0.8427544897096161, disc_loss = 0.07135018276240637
Trained batch 657 in epoch 8, gen_loss = 0.8427370338726189, disc_loss = 0.07137241018341577
Trained batch 658 in epoch 8, gen_loss = 0.842559228672424, disc_loss = 0.07148038980032406
Trained batch 659 in epoch 8, gen_loss = 0.8427830168243611, disc_loss = 0.07139886871657589
Trained batch 660 in epoch 8, gen_loss = 0.8430389300687591, disc_loss = 0.07144639166508789
Trained batch 661 in epoch 8, gen_loss = 0.8433422037031716, disc_loss = 0.07145718468234978
Trained batch 662 in epoch 8, gen_loss = 0.8428520413275757, disc_loss = 0.07164217842964744
Trained batch 663 in epoch 8, gen_loss = 0.8428768985512027, disc_loss = 0.07160037160144155
Trained batch 664 in epoch 8, gen_loss = 0.8430840739182064, disc_loss = 0.07154428744898703
Trained batch 665 in epoch 8, gen_loss = 0.843013190605619, disc_loss = 0.07152162638825697
Trained batch 666 in epoch 8, gen_loss = 0.8430852510671745, disc_loss = 0.07145436118165592
Trained batch 667 in epoch 8, gen_loss = 0.8428394460303341, disc_loss = 0.07159991882473765
Trained batch 668 in epoch 8, gen_loss = 0.8423487095465753, disc_loss = 0.07163523967267865
Trained batch 669 in epoch 8, gen_loss = 0.8421920372034186, disc_loss = 0.07158178002643051
Trained batch 670 in epoch 8, gen_loss = 0.8424052808839056, disc_loss = 0.07154108174755926
Trained batch 671 in epoch 8, gen_loss = 0.8422776689930331, disc_loss = 0.07149255831193711
Trained batch 672 in epoch 8, gen_loss = 0.8418770304494946, disc_loss = 0.07163895235949072
Trained batch 673 in epoch 8, gen_loss = 0.8418381020028797, disc_loss = 0.07161915826249193
Trained batch 674 in epoch 8, gen_loss = 0.8421569455552984, disc_loss = 0.07159153685525611
Trained batch 675 in epoch 8, gen_loss = 0.841997809002738, disc_loss = 0.07159773794901089
Trained batch 676 in epoch 8, gen_loss = 0.8422355402255516, disc_loss = 0.07158329782448984
Trained batch 677 in epoch 8, gen_loss = 0.8420750810421322, disc_loss = 0.0715653573363404
Trained batch 678 in epoch 8, gen_loss = 0.8417279692654757, disc_loss = 0.07155464388792224
Trained batch 679 in epoch 8, gen_loss = 0.841437344384544, disc_loss = 0.07165403321166249
Trained batch 680 in epoch 8, gen_loss = 0.841249500120964, disc_loss = 0.07167743919923267
Trained batch 681 in epoch 8, gen_loss = 0.8417617305020783, disc_loss = 0.07162390980334225
Trained batch 682 in epoch 8, gen_loss = 0.8420062007963396, disc_loss = 0.0716190784733257
Trained batch 683 in epoch 8, gen_loss = 0.8419573572382593, disc_loss = 0.07155195996165276
Trained batch 684 in epoch 8, gen_loss = 0.8415222098792556, disc_loss = 0.07164754471639648
Trained batch 685 in epoch 8, gen_loss = 0.8414775357736443, disc_loss = 0.07160766170232533
Trained batch 686 in epoch 8, gen_loss = 0.8415505924686421, disc_loss = 0.07189369626245644
Trained batch 687 in epoch 8, gen_loss = 0.8412288633976565, disc_loss = 0.07188233271306164
Trained batch 688 in epoch 8, gen_loss = 0.84121108474683, disc_loss = 0.07184536596665535
Trained batch 689 in epoch 8, gen_loss = 0.8411388017561124, disc_loss = 0.07182017922725366
Trained batch 690 in epoch 8, gen_loss = 0.8412156929241765, disc_loss = 0.07178687371108708
Trained batch 691 in epoch 8, gen_loss = 0.8412671185211639, disc_loss = 0.0718725581109696
Trained batch 692 in epoch 8, gen_loss = 0.8409472355164834, disc_loss = 0.07201399417623641
Trained batch 693 in epoch 8, gen_loss = 0.8412410931645622, disc_loss = 0.07194771603157782
Trained batch 694 in epoch 8, gen_loss = 0.8415826794483678, disc_loss = 0.07191027675708421
Trained batch 695 in epoch 8, gen_loss = 0.8416173645220268, disc_loss = 0.07183406727613303
Trained batch 696 in epoch 8, gen_loss = 0.8414201882254958, disc_loss = 0.07179462636314557
Trained batch 697 in epoch 8, gen_loss = 0.8411740872016268, disc_loss = 0.07176218255767251
Trained batch 698 in epoch 8, gen_loss = 0.8410388608603007, disc_loss = 0.07198844474070147
Trained batch 699 in epoch 8, gen_loss = 0.8407661102073534, disc_loss = 0.07197770226480706
Trained batch 700 in epoch 8, gen_loss = 0.8404620657548755, disc_loss = 0.07195750808080235
Trained batch 701 in epoch 8, gen_loss = 0.840681442974979, disc_loss = 0.07191464902721664
Trained batch 702 in epoch 8, gen_loss = 0.840865146172674, disc_loss = 0.07190104589597514
Trained batch 703 in epoch 8, gen_loss = 0.8406798273578964, disc_loss = 0.07187318484118971
Trained batch 704 in epoch 8, gen_loss = 0.8405323729024711, disc_loss = 0.07183959955177831
Trained batch 705 in epoch 8, gen_loss = 0.8408237020709359, disc_loss = 0.07177455147343131
Trained batch 706 in epoch 8, gen_loss = 0.8408289725827699, disc_loss = 0.07170530611219719
Trained batch 707 in epoch 8, gen_loss = 0.8407500858950077, disc_loss = 0.07170496764461283
Trained batch 708 in epoch 8, gen_loss = 0.8406468706759814, disc_loss = 0.07166253501347072
Trained batch 709 in epoch 8, gen_loss = 0.8402368947233952, disc_loss = 0.07179899455218668
Trained batch 710 in epoch 8, gen_loss = 0.8407032885883428, disc_loss = 0.07177483789497036
Trained batch 711 in epoch 8, gen_loss = 0.8408653430975555, disc_loss = 0.07171712743296299
Trained batch 712 in epoch 8, gen_loss = 0.840706249064182, disc_loss = 0.07172976456958732
Trained batch 713 in epoch 8, gen_loss = 0.8404436945831743, disc_loss = 0.07173760646187208
Trained batch 714 in epoch 8, gen_loss = 0.8407020298334268, disc_loss = 0.0716699879512295
Trained batch 715 in epoch 8, gen_loss = 0.8412858961597501, disc_loss = 0.07178653520922171
Trained batch 716 in epoch 8, gen_loss = 0.84092343314921, disc_loss = 0.07187846704351104
Trained batch 717 in epoch 8, gen_loss = 0.8408118091668924, disc_loss = 0.07188000045664879
Trained batch 718 in epoch 8, gen_loss = 0.8412925665252563, disc_loss = 0.07199180521257481
Trained batch 719 in epoch 8, gen_loss = 0.841211441366209, disc_loss = 0.0719461017107177
Trained batch 720 in epoch 8, gen_loss = 0.841111843075071, disc_loss = 0.07190268054015511
Trained batch 721 in epoch 8, gen_loss = 0.8413542124785875, disc_loss = 0.07186770624122543
Trained batch 722 in epoch 8, gen_loss = 0.8416465712533452, disc_loss = 0.07178984401054567
Trained batch 723 in epoch 8, gen_loss = 0.8414102121364346, disc_loss = 0.07177348349510965
Trained batch 724 in epoch 8, gen_loss = 0.8414496054731566, disc_loss = 0.07172299235031522
Trained batch 725 in epoch 8, gen_loss = 0.8415826364900126, disc_loss = 0.07172317014745444
Trained batch 726 in epoch 8, gen_loss = 0.8412484458174961, disc_loss = 0.07190581774941172
Trained batch 727 in epoch 8, gen_loss = 0.8415474416381055, disc_loss = 0.07190040865360381
Trained batch 728 in epoch 8, gen_loss = 0.841750778411151, disc_loss = 0.07188477701365703
Trained batch 729 in epoch 8, gen_loss = 0.841324805437702, disc_loss = 0.07205323658577384
Trained batch 730 in epoch 8, gen_loss = 0.8413113778413728, disc_loss = 0.07204824578011901
Trained batch 731 in epoch 8, gen_loss = 0.8417235733788522, disc_loss = 0.07200576921751917
Trained batch 732 in epoch 8, gen_loss = 0.8414160958497618, disc_loss = 0.07213437287861134
Trained batch 733 in epoch 8, gen_loss = 0.8416192868181406, disc_loss = 0.0721334949115479
Trained batch 734 in epoch 8, gen_loss = 0.8419434007738723, disc_loss = 0.07219109870746833
Trained batch 735 in epoch 8, gen_loss = 0.8418406145647168, disc_loss = 0.07215618084022857
Trained batch 736 in epoch 8, gen_loss = 0.8416625471176578, disc_loss = 0.07219758903761893
Trained batch 737 in epoch 8, gen_loss = 0.8413303840531889, disc_loss = 0.072205079865811
Trained batch 738 in epoch 8, gen_loss = 0.8419249196901051, disc_loss = 0.07238823391184594
Trained batch 739 in epoch 8, gen_loss = 0.8416845542756287, disc_loss = 0.07242243645360341
Trained batch 740 in epoch 8, gen_loss = 0.8413538159387797, disc_loss = 0.07246049620241289
Trained batch 741 in epoch 8, gen_loss = 0.8411661804606009, disc_loss = 0.07247446578829436
Trained batch 742 in epoch 8, gen_loss = 0.8413488313375219, disc_loss = 0.0725414873593428
Trained batch 743 in epoch 8, gen_loss = 0.840970690251999, disc_loss = 0.07262490690755909
Trained batch 744 in epoch 8, gen_loss = 0.8407929152850336, disc_loss = 0.07260535266375381
Trained batch 745 in epoch 8, gen_loss = 0.8409464346100114, disc_loss = 0.07256061996235924
Trained batch 746 in epoch 8, gen_loss = 0.840606781413437, disc_loss = 0.07254348267393419
Trained batch 747 in epoch 8, gen_loss = 0.8405427163377165, disc_loss = 0.07246381135278925
Trained batch 748 in epoch 8, gen_loss = 0.8406624090926192, disc_loss = 0.07245973521751539
Trained batch 749 in epoch 8, gen_loss = 0.8406541465520859, disc_loss = 0.0724041305705905
Trained batch 750 in epoch 8, gen_loss = 0.8405789244428932, disc_loss = 0.07234232490770667
Trained batch 751 in epoch 8, gen_loss = 0.8410014676207558, disc_loss = 0.07230213365735526
Trained batch 752 in epoch 8, gen_loss = 0.8409417476232942, disc_loss = 0.07223497549811524
Trained batch 753 in epoch 8, gen_loss = 0.8405575542377224, disc_loss = 0.07232957075421627
Trained batch 754 in epoch 8, gen_loss = 0.8407009322516965, disc_loss = 0.07232318766267094
Trained batch 755 in epoch 8, gen_loss = 0.8408659584228955, disc_loss = 0.07224860914770967
Trained batch 756 in epoch 8, gen_loss = 0.8407019962171582, disc_loss = 0.07222318691859708
Trained batch 757 in epoch 8, gen_loss = 0.8408380146470108, disc_loss = 0.07214542534104045
Trained batch 758 in epoch 8, gen_loss = 0.840556924090241, disc_loss = 0.0721355840657029
Trained batch 759 in epoch 8, gen_loss = 0.8407075623540502, disc_loss = 0.07224130264581426
Trained batch 760 in epoch 8, gen_loss = 0.8404132110138917, disc_loss = 0.07231414124966842
Trained batch 761 in epoch 8, gen_loss = 0.8404156236745554, disc_loss = 0.0722629565750481
Trained batch 762 in epoch 8, gen_loss = 0.8405241512767921, disc_loss = 0.07224486231423065
Trained batch 763 in epoch 8, gen_loss = 0.8405933726910522, disc_loss = 0.07222615829205715
Trained batch 764 in epoch 8, gen_loss = 0.8402218306376263, disc_loss = 0.07258021947653855
Trained batch 765 in epoch 8, gen_loss = 0.8407856439563687, disc_loss = 0.07266213726641382
Trained batch 766 in epoch 8, gen_loss = 0.8403025388406806, disc_loss = 0.07286957430142078
Trained batch 767 in epoch 8, gen_loss = 0.8406481270988783, disc_loss = 0.07306654362522143
Trained batch 768 in epoch 8, gen_loss = 0.8404765808845838, disc_loss = 0.07304365068470625
Trained batch 769 in epoch 8, gen_loss = 0.8405383937544637, disc_loss = 0.07298704688376807
Trained batch 770 in epoch 8, gen_loss = 0.8403187601328206, disc_loss = 0.07299273701483715
Trained batch 771 in epoch 8, gen_loss = 0.8405938181698014, disc_loss = 0.07293921643192518
Trained batch 772 in epoch 8, gen_loss = 0.8405576547243925, disc_loss = 0.07291791716983294
Trained batch 773 in epoch 8, gen_loss = 0.8406570931121669, disc_loss = 0.07285885024064964
Trained batch 774 in epoch 8, gen_loss = 0.840299101029673, disc_loss = 0.07292458970940882
Trained batch 775 in epoch 8, gen_loss = 0.8403923096730537, disc_loss = 0.07286814032074486
Trained batch 776 in epoch 8, gen_loss = 0.8405176631272069, disc_loss = 0.07292039717572767
Trained batch 777 in epoch 8, gen_loss = 0.8401979702144172, disc_loss = 0.0729517951574186
Trained batch 778 in epoch 8, gen_loss = 0.8401937057791381, disc_loss = 0.07288487765828054
Trained batch 779 in epoch 8, gen_loss = 0.8403861983464315, disc_loss = 0.0728083395709594
Trained batch 780 in epoch 8, gen_loss = 0.8402335716270759, disc_loss = 0.07290851011891371
Trained batch 781 in epoch 8, gen_loss = 0.8403902491340247, disc_loss = 0.07283190079271565
Trained batch 782 in epoch 8, gen_loss = 0.84035749377571, disc_loss = 0.07283002175010103
Trained batch 783 in epoch 8, gen_loss = 0.8402527820090858, disc_loss = 0.07277578260150872
Trained batch 784 in epoch 8, gen_loss = 0.8404388550740138, disc_loss = 0.07272695275676098
Trained batch 785 in epoch 8, gen_loss = 0.8403819233709923, disc_loss = 0.07270719365716814
Trained batch 786 in epoch 8, gen_loss = 0.8403759376066613, disc_loss = 0.0726302505377325
Trained batch 787 in epoch 8, gen_loss = 0.8399387556813696, disc_loss = 0.07267363748848817
Trained batch 788 in epoch 8, gen_loss = 0.8400930943975582, disc_loss = 0.07283597775936806
Trained batch 789 in epoch 8, gen_loss = 0.8398732989271985, disc_loss = 0.07283216810349046
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.9681068062782288, disc_loss = 0.038113534450531006
Trained batch 1 in epoch 9, gen_loss = 0.794631153345108, disc_loss = 0.0572064183652401
Trained batch 2 in epoch 9, gen_loss = 0.8789432247479757, disc_loss = 0.04296916909515858
Trained batch 3 in epoch 9, gen_loss = 0.8932080268859863, disc_loss = 0.034188148099929094
Trained batch 4 in epoch 9, gen_loss = 0.851084852218628, disc_loss = 0.03421699590981007
Trained batch 5 in epoch 9, gen_loss = 0.8877229690551758, disc_loss = 0.0767766401792566
Trained batch 6 in epoch 9, gen_loss = 0.834638774394989, disc_loss = 0.11068119028849262
Trained batch 7 in epoch 9, gen_loss = 0.8670187368988991, disc_loss = 0.10086278733797371
Trained batch 8 in epoch 9, gen_loss = 0.8875313666131761, disc_loss = 0.0984943105528752
Trained batch 9 in epoch 9, gen_loss = 0.8702728569507598, disc_loss = 0.09137542638927698
Trained batch 10 in epoch 9, gen_loss = 0.8704308813268488, disc_loss = 0.08511026830158451
Trained batch 11 in epoch 9, gen_loss = 0.8634653141101202, disc_loss = 0.081887011261036
Trained batch 12 in epoch 9, gen_loss = 0.86128496665221, disc_loss = 0.07811542557409176
Trained batch 13 in epoch 9, gen_loss = 0.8698302464825767, disc_loss = 0.07754009762512785
Trained batch 14 in epoch 9, gen_loss = 0.8764402031898498, disc_loss = 0.07301530639330546
Trained batch 15 in epoch 9, gen_loss = 0.8796596862375736, disc_loss = 0.0692329850862734
Trained batch 16 in epoch 9, gen_loss = 0.8721336406819961, disc_loss = 0.0703868556439
Trained batch 17 in epoch 9, gen_loss = 0.868953287601471, disc_loss = 0.06854933639988303
Trained batch 18 in epoch 9, gen_loss = 0.8752841196562114, disc_loss = 0.06822187997596829
Trained batch 19 in epoch 9, gen_loss = 0.8693239092826843, disc_loss = 0.06639163638465106
Trained batch 20 in epoch 9, gen_loss = 0.8570518834250314, disc_loss = 0.06767649411977757
Trained batch 21 in epoch 9, gen_loss = 0.8765021400018171, disc_loss = 0.06808922571045431
Trained batch 22 in epoch 9, gen_loss = 0.8804359695185786, disc_loss = 0.06599270499756803
Trained batch 23 in epoch 9, gen_loss = 0.8797542427976927, disc_loss = 0.06468051776755601
Trained batch 24 in epoch 9, gen_loss = 0.8728651356697082, disc_loss = 0.06377504136413335
Trained batch 25 in epoch 9, gen_loss = 0.8684473519141858, disc_loss = 0.06931156976721607
Trained batch 26 in epoch 9, gen_loss = 0.8706486600416677, disc_loss = 0.06723656467403527
Trained batch 27 in epoch 9, gen_loss = 0.8633623932089124, disc_loss = 0.06797693766254399
Trained batch 28 in epoch 9, gen_loss = 0.8687354572888079, disc_loss = 0.06723866062559958
Trained batch 29 in epoch 9, gen_loss = 0.866323717435201, disc_loss = 0.06694787905241052
Trained batch 30 in epoch 9, gen_loss = 0.8657416355225348, disc_loss = 0.06562057122467987
Trained batch 31 in epoch 9, gen_loss = 0.8676753435283899, disc_loss = 0.06484743961482309
Trained batch 32 in epoch 9, gen_loss = 0.8678839405377706, disc_loss = 0.063275223372109
Trained batch 33 in epoch 9, gen_loss = 0.8797080429161296, disc_loss = 0.06329307129935306
Trained batch 34 in epoch 9, gen_loss = 0.8718537790434701, disc_loss = 0.06313884093293122
Trained batch 35 in epoch 9, gen_loss = 0.8735318531592687, disc_loss = 0.06231227439517776
Trained batch 36 in epoch 9, gen_loss = 0.8798980954531077, disc_loss = 0.060877052060252915
Trained batch 37 in epoch 9, gen_loss = 0.8787670966825987, disc_loss = 0.05956663975590154
Trained batch 38 in epoch 9, gen_loss = 0.876503314727392, disc_loss = 0.05912183225154877
Trained batch 39 in epoch 9, gen_loss = 0.8793974727392196, disc_loss = 0.058059498015791175
Trained batch 40 in epoch 9, gen_loss = 0.8792853573473488, disc_loss = 0.05710756874120817
Trained batch 41 in epoch 9, gen_loss = 0.8823284010092417, disc_loss = 0.05700410348141477
Trained batch 42 in epoch 9, gen_loss = 0.8762720254964607, disc_loss = 0.05849053896963596
Trained batch 43 in epoch 9, gen_loss = 0.8780824934894388, disc_loss = 0.05788132510232655
Trained batch 44 in epoch 9, gen_loss = 0.880233195092943, disc_loss = 0.056939790377186404
Trained batch 45 in epoch 9, gen_loss = 0.8847663272982058, disc_loss = 0.06077244106437201
Trained batch 46 in epoch 9, gen_loss = 0.8788229303157076, disc_loss = 0.061266180108043744
Trained batch 47 in epoch 9, gen_loss = 0.8744582583506902, disc_loss = 0.061468658406132214
Trained batch 48 in epoch 9, gen_loss = 0.874821198229887, disc_loss = 0.06052693652407247
Trained batch 49 in epoch 9, gen_loss = 0.8725807619094849, disc_loss = 0.060699841864407064
Trained batch 50 in epoch 9, gen_loss = 0.8761586488461962, disc_loss = 0.059822417466956025
Trained batch 51 in epoch 9, gen_loss = 0.8814931580653558, disc_loss = 0.059394187616327636
Trained batch 52 in epoch 9, gen_loss = 0.8758524577572661, disc_loss = 0.06061500686941282
Trained batch 53 in epoch 9, gen_loss = 0.8768642478519015, disc_loss = 0.05979254120891845
Trained batch 54 in epoch 9, gen_loss = 0.8756825880570845, disc_loss = 0.06235582283274694
Trained batch 55 in epoch 9, gen_loss = 0.8792110553809575, disc_loss = 0.061569019786215255
Trained batch 56 in epoch 9, gen_loss = 0.8767771553574947, disc_loss = 0.06222898150353055
Trained batch 57 in epoch 9, gen_loss = 0.8795604315297357, disc_loss = 0.06179271114925886
Trained batch 58 in epoch 9, gen_loss = 0.8752122824474916, disc_loss = 0.06261427425858328
Trained batch 59 in epoch 9, gen_loss = 0.8787339617808659, disc_loss = 0.061766814440488815
Trained batch 60 in epoch 9, gen_loss = 0.8802570524762888, disc_loss = 0.06249524152181188
Trained batch 61 in epoch 9, gen_loss = 0.8769779714845842, disc_loss = 0.0622698567927845
Trained batch 62 in epoch 9, gen_loss = 0.8808727803684416, disc_loss = 0.061756216699168795
Trained batch 63 in epoch 9, gen_loss = 0.8777779964730144, disc_loss = 0.06199087051209062
Trained batch 64 in epoch 9, gen_loss = 0.8808081397643456, disc_loss = 0.06152431460527273
Trained batch 65 in epoch 9, gen_loss = 0.8843994998570645, disc_loss = 0.0608851487437884
Trained batch 66 in epoch 9, gen_loss = 0.8885533302577574, disc_loss = 0.060347263993167165
Trained batch 67 in epoch 9, gen_loss = 0.8877015473211513, disc_loss = 0.05969526544761132
Trained batch 68 in epoch 9, gen_loss = 0.8837585794752922, disc_loss = 0.06020913362179114
Trained batch 69 in epoch 9, gen_loss = 0.8844303659030369, disc_loss = 0.05946815934564386
Trained batch 70 in epoch 9, gen_loss = 0.8857019963398786, disc_loss = 0.060053025175568084
Trained batch 71 in epoch 9, gen_loss = 0.8838976315326161, disc_loss = 0.06075749923992488
Trained batch 72 in epoch 9, gen_loss = 0.8777117067820406, disc_loss = 0.06341940251319375
Trained batch 73 in epoch 9, gen_loss = 0.8790887868082201, disc_loss = 0.06373201295532085
Trained batch 74 in epoch 9, gen_loss = 0.8790577141443888, disc_loss = 0.06325148388743401
Trained batch 75 in epoch 9, gen_loss = 0.8769698652781939, disc_loss = 0.06286155800090025
Trained batch 76 in epoch 9, gen_loss = 0.8761110274822681, disc_loss = 0.06223025018131578
Trained batch 77 in epoch 9, gen_loss = 0.8779232547833369, disc_loss = 0.06176457047844545
Trained batch 78 in epoch 9, gen_loss = 0.8801602547681784, disc_loss = 0.06140656132675425
Trained batch 79 in epoch 9, gen_loss = 0.8796190232038498, disc_loss = 0.060761200182605536
Trained batch 80 in epoch 9, gen_loss = 0.8768225996582596, disc_loss = 0.06072687970497358
Trained batch 81 in epoch 9, gen_loss = 0.8744265204522668, disc_loss = 0.06061008832667295
Trained batch 82 in epoch 9, gen_loss = 0.8748183824929846, disc_loss = 0.05996447767927704
Trained batch 83 in epoch 9, gen_loss = 0.8767536992118472, disc_loss = 0.05982338076102592
Trained batch 84 in epoch 9, gen_loss = 0.8749997685937321, disc_loss = 0.05970008143169039
Trained batch 85 in epoch 9, gen_loss = 0.8738981873490089, disc_loss = 0.05919896962857524
Trained batch 86 in epoch 9, gen_loss = 0.8763055719178299, disc_loss = 0.05926744764049848
Trained batch 87 in epoch 9, gen_loss = 0.8746641176668081, disc_loss = 0.05940587043931538
Trained batch 88 in epoch 9, gen_loss = 0.8745211918702286, disc_loss = 0.05910584259401547
Trained batch 89 in epoch 9, gen_loss = 0.8732405033376481, disc_loss = 0.0588785191377004
Trained batch 90 in epoch 9, gen_loss = 0.8745280628675943, disc_loss = 0.058881612842554575
Trained batch 91 in epoch 9, gen_loss = 0.8745726424714794, disc_loss = 0.05845253594705592
Trained batch 92 in epoch 9, gen_loss = 0.8728219277115279, disc_loss = 0.05811143606420486
Trained batch 93 in epoch 9, gen_loss = 0.871092362606779, disc_loss = 0.05806981938633513
Trained batch 94 in epoch 9, gen_loss = 0.8728346975226151, disc_loss = 0.05756817213014553
Trained batch 95 in epoch 9, gen_loss = 0.8733187814553579, disc_loss = 0.05763349313444147
Trained batch 96 in epoch 9, gen_loss = 0.8719425963372299, disc_loss = 0.05755805608230768
Trained batch 97 in epoch 9, gen_loss = 0.8739232189801275, disc_loss = 0.05825099189366613
Trained batch 98 in epoch 9, gen_loss = 0.8709314050096454, disc_loss = 0.059619738823837705
Trained batch 99 in epoch 9, gen_loss = 0.8676851975917816, disc_loss = 0.060167424976825715
Trained batch 100 in epoch 9, gen_loss = 0.8707904780265128, disc_loss = 0.06147513472207702
Trained batch 101 in epoch 9, gen_loss = 0.8667793647915709, disc_loss = 0.0626938074242835
Trained batch 102 in epoch 9, gen_loss = 0.8677393776699177, disc_loss = 0.062299877983852496
Trained batch 103 in epoch 9, gen_loss = 0.8683350710914686, disc_loss = 0.0618665253277868
Trained batch 104 in epoch 9, gen_loss = 0.8676303000677199, disc_loss = 0.061629443988204004
Trained batch 105 in epoch 9, gen_loss = 0.8655444496082809, disc_loss = 0.06217762509817785
Trained batch 106 in epoch 9, gen_loss = 0.8658817839399676, disc_loss = 0.06199163283769772
Trained batch 107 in epoch 9, gen_loss = 0.8655498518987939, disc_loss = 0.06152822698156039
Trained batch 108 in epoch 9, gen_loss = 0.8637449577314045, disc_loss = 0.06188626689921825
Trained batch 109 in epoch 9, gen_loss = 0.864499160376462, disc_loss = 0.06278429038145325
Trained batch 110 in epoch 9, gen_loss = 0.8663940311552168, disc_loss = 0.06238722878399196
Trained batch 111 in epoch 9, gen_loss = 0.8636965442981038, disc_loss = 0.06269386853091419
Trained batch 112 in epoch 9, gen_loss = 0.864147809226956, disc_loss = 0.062388935530212075
Trained batch 113 in epoch 9, gen_loss = 0.8621591732167361, disc_loss = 0.06273362957137196
Trained batch 114 in epoch 9, gen_loss = 0.8641930543858072, disc_loss = 0.0630151667834624
Trained batch 115 in epoch 9, gen_loss = 0.8634393960237503, disc_loss = 0.06282037549555816
Trained batch 116 in epoch 9, gen_loss = 0.8633814703704964, disc_loss = 0.0624384885160332
Trained batch 117 in epoch 9, gen_loss = 0.8638015783439248, disc_loss = 0.06328229391473834
Trained batch 118 in epoch 9, gen_loss = 0.8615889959976453, disc_loss = 0.06354880827565153
Trained batch 119 in epoch 9, gen_loss = 0.860430121421814, disc_loss = 0.06363276739915212
Trained batch 120 in epoch 9, gen_loss = 0.8627334557288935, disc_loss = 0.06340275129134004
Trained batch 121 in epoch 9, gen_loss = 0.8619655571022972, disc_loss = 0.06323823515997558
Trained batch 122 in epoch 9, gen_loss = 0.8634346912546855, disc_loss = 0.06319236522161864
Trained batch 123 in epoch 9, gen_loss = 0.8641876198591725, disc_loss = 0.06284428366850461
Trained batch 124 in epoch 9, gen_loss = 0.8620971331596374, disc_loss = 0.06315859547257423
Trained batch 125 in epoch 9, gen_loss = 0.8635116281017424, disc_loss = 0.0630125416117528
Trained batch 126 in epoch 9, gen_loss = 0.8651883597449055, disc_loss = 0.06280496836764606
Trained batch 127 in epoch 9, gen_loss = 0.8655894473195076, disc_loss = 0.06254874193109572
Trained batch 128 in epoch 9, gen_loss = 0.863445196040841, disc_loss = 0.06293517807426378
Trained batch 129 in epoch 9, gen_loss = 0.8628021098100223, disc_loss = 0.06274500105243463
Trained batch 130 in epoch 9, gen_loss = 0.8630406424289442, disc_loss = 0.06295702083192709
Trained batch 131 in epoch 9, gen_loss = 0.8606515973806381, disc_loss = 0.06388719735497778
Trained batch 132 in epoch 9, gen_loss = 0.8611611826975543, disc_loss = 0.06366760194077528
Trained batch 133 in epoch 9, gen_loss = 0.8625153703476066, disc_loss = 0.06327559957419758
Trained batch 134 in epoch 9, gen_loss = 0.863080256515079, disc_loss = 0.06291109989224761
Trained batch 135 in epoch 9, gen_loss = 0.8624734926749679, disc_loss = 0.06319542906438823
Trained batch 136 in epoch 9, gen_loss = 0.8630216239142592, disc_loss = 0.06288895677829529
Trained batch 137 in epoch 9, gen_loss = 0.8622131740701371, disc_loss = 0.06294973122387909
Trained batch 138 in epoch 9, gen_loss = 0.8612126905283481, disc_loss = 0.06289267613009798
Trained batch 139 in epoch 9, gen_loss = 0.8607861863715308, disc_loss = 0.06308016051272196
Trained batch 140 in epoch 9, gen_loss = 0.8622181335239546, disc_loss = 0.06518819820505718
Trained batch 141 in epoch 9, gen_loss = 0.8617987603368894, disc_loss = 0.06517742692925771
Trained batch 142 in epoch 9, gen_loss = 0.8597915160072434, disc_loss = 0.0653518064572782
Trained batch 143 in epoch 9, gen_loss = 0.8596994384295411, disc_loss = 0.06552522187767965
Trained batch 144 in epoch 9, gen_loss = 0.8564064056708895, disc_loss = 0.0672003878922812
Trained batch 145 in epoch 9, gen_loss = 0.8562809067637953, disc_loss = 0.0671444882587721
Trained batch 146 in epoch 9, gen_loss = 0.8573873742502562, disc_loss = 0.06739105865181912
Trained batch 147 in epoch 9, gen_loss = 0.8570671768204586, disc_loss = 0.06718276064163325
Trained batch 148 in epoch 9, gen_loss = 0.8566242722456887, disc_loss = 0.06694245289061093
Trained batch 149 in epoch 9, gen_loss = 0.8572500548760096, disc_loss = 0.06715856468304991
Trained batch 150 in epoch 9, gen_loss = 0.8554921712701684, disc_loss = 0.06753401967098578
Trained batch 151 in epoch 9, gen_loss = 0.8541612991769063, disc_loss = 0.06796932510271865
Trained batch 152 in epoch 9, gen_loss = 0.8545238272426954, disc_loss = 0.06818521705157811
Trained batch 153 in epoch 9, gen_loss = 0.8543121979221121, disc_loss = 0.06793834511553506
Trained batch 154 in epoch 9, gen_loss = 0.8533461830308361, disc_loss = 0.06784801555857543
Trained batch 155 in epoch 9, gen_loss = 0.8532833027151915, disc_loss = 0.06866465533414903
Trained batch 156 in epoch 9, gen_loss = 0.8531586366474249, disc_loss = 0.06864676112605697
Trained batch 157 in epoch 9, gen_loss = 0.8522170983915087, disc_loss = 0.06849907914506673
Trained batch 158 in epoch 9, gen_loss = 0.8514417704171354, disc_loss = 0.06842261895467087
Trained batch 159 in epoch 9, gen_loss = 0.8518583262339234, disc_loss = 0.06858823565416969
Trained batch 160 in epoch 9, gen_loss = 0.8522597568005509, disc_loss = 0.06825404750148517
Trained batch 161 in epoch 9, gen_loss = 0.8504635310835309, disc_loss = 0.06862826969037637
Trained batch 162 in epoch 9, gen_loss = 0.8517334850653548, disc_loss = 0.06846443857951946
Trained batch 163 in epoch 9, gen_loss = 0.854278271699824, disc_loss = 0.06887791484662491
Trained batch 164 in epoch 9, gen_loss = 0.8549473908814517, disc_loss = 0.06859246858706076
Trained batch 165 in epoch 9, gen_loss = 0.8534510733492403, disc_loss = 0.06862637266539127
Trained batch 166 in epoch 9, gen_loss = 0.8539607962091526, disc_loss = 0.06900515680028471
Trained batch 167 in epoch 9, gen_loss = 0.8534341640770435, disc_loss = 0.06901184638540837
Trained batch 168 in epoch 9, gen_loss = 0.8521433626053602, disc_loss = 0.06888841924163894
Trained batch 169 in epoch 9, gen_loss = 0.8515983460580602, disc_loss = 0.06871623325106853
Trained batch 170 in epoch 9, gen_loss = 0.852489860957129, disc_loss = 0.06872497410213912
Trained batch 171 in epoch 9, gen_loss = 0.8536021077009135, disc_loss = 0.06853419594834884
Trained batch 172 in epoch 9, gen_loss = 0.8521670859328584, disc_loss = 0.06898482187484213
Trained batch 173 in epoch 9, gen_loss = 0.8520990108278976, disc_loss = 0.06886828156059673
Trained batch 174 in epoch 9, gen_loss = 0.8514222116129739, disc_loss = 0.06881535811615842
Trained batch 175 in epoch 9, gen_loss = 0.8527048065919768, disc_loss = 0.06867739571448923
Trained batch 176 in epoch 9, gen_loss = 0.8530141753328722, disc_loss = 0.06844578123004255
Trained batch 177 in epoch 9, gen_loss = 0.8546505829926287, disc_loss = 0.06816153315659822
Trained batch 178 in epoch 9, gen_loss = 0.8541128110952217, disc_loss = 0.067990456229107
Trained batch 179 in epoch 9, gen_loss = 0.853802315890789, disc_loss = 0.06792086426479121
Trained batch 180 in epoch 9, gen_loss = 0.8550601919382317, disc_loss = 0.06766167747690369
Trained batch 181 in epoch 9, gen_loss = 0.8548247786341133, disc_loss = 0.06745414446609524
Trained batch 182 in epoch 9, gen_loss = 0.8549502340496563, disc_loss = 0.06724863349271765
Trained batch 183 in epoch 9, gen_loss = 0.8541913047108961, disc_loss = 0.06705591552789607
Trained batch 184 in epoch 9, gen_loss = 0.8537039584404713, disc_loss = 0.06680775842050443
Trained batch 185 in epoch 9, gen_loss = 0.8522152037069362, disc_loss = 0.06679488067084582
Trained batch 186 in epoch 9, gen_loss = 0.8530553211184109, disc_loss = 0.06654861329850506
Trained batch 187 in epoch 9, gen_loss = 0.8552779055973316, disc_loss = 0.06689383089047005
Trained batch 188 in epoch 9, gen_loss = 0.8546412850498523, disc_loss = 0.06705608998952561
Trained batch 189 in epoch 9, gen_loss = 0.8540420185578497, disc_loss = 0.0671656656765232
Trained batch 190 in epoch 9, gen_loss = 0.8555982935178966, disc_loss = 0.06705285364479138
Trained batch 191 in epoch 9, gen_loss = 0.8545291534004112, disc_loss = 0.06726442585447028
Trained batch 192 in epoch 9, gen_loss = 0.8544957673302587, disc_loss = 0.06729046488422032
Trained batch 193 in epoch 9, gen_loss = 0.8542459316782116, disc_loss = 0.06714236833750434
Trained batch 194 in epoch 9, gen_loss = 0.8546940105083661, disc_loss = 0.06693316419632771
Trained batch 195 in epoch 9, gen_loss = 0.8547723024171225, disc_loss = 0.06668547772308242
Trained batch 196 in epoch 9, gen_loss = 0.8539113579365203, disc_loss = 0.06672758865761122
Trained batch 197 in epoch 9, gen_loss = 0.8541844268940916, disc_loss = 0.06674873647797439
Trained batch 198 in epoch 9, gen_loss = 0.8531980198531893, disc_loss = 0.06738457412706997
Trained batch 199 in epoch 9, gen_loss = 0.8518375827372074, disc_loss = 0.06771161764394491
Trained batch 200 in epoch 9, gen_loss = 0.8525622699094649, disc_loss = 0.06759502293440092
Trained batch 201 in epoch 9, gen_loss = 0.8525491402585907, disc_loss = 0.06801415924075069
Trained batch 202 in epoch 9, gen_loss = 0.8512986368440055, disc_loss = 0.06825604986656329
Trained batch 203 in epoch 9, gen_loss = 0.851388616743041, disc_loss = 0.06813706975777213
Trained batch 204 in epoch 9, gen_loss = 0.8502033924184195, disc_loss = 0.06816848737710132
Trained batch 205 in epoch 9, gen_loss = 0.849669668714977, disc_loss = 0.06836885094045869
Trained batch 206 in epoch 9, gen_loss = 0.8503157307848263, disc_loss = 0.06819154742817228
Trained batch 207 in epoch 9, gen_loss = 0.851286638671389, disc_loss = 0.06810393767843309
Trained batch 208 in epoch 9, gen_loss = 0.8497817577642687, disc_loss = 0.06826078780797537
Trained batch 209 in epoch 9, gen_loss = 0.8496475797323954, disc_loss = 0.0679876686029491
Trained batch 210 in epoch 9, gen_loss = 0.8482729005870095, disc_loss = 0.06821025500153478
Trained batch 211 in epoch 9, gen_loss = 0.8490260868983449, disc_loss = 0.06838384026415506
Trained batch 212 in epoch 9, gen_loss = 0.8493591649151744, disc_loss = 0.06819168095227698
Trained batch 213 in epoch 9, gen_loss = 0.8483399048308345, disc_loss = 0.06826358551385804
Trained batch 214 in epoch 9, gen_loss = 0.8484538648017618, disc_loss = 0.06825269458945407
Trained batch 215 in epoch 9, gen_loss = 0.8477480498452982, disc_loss = 0.0682482664404368
Trained batch 216 in epoch 9, gen_loss = 0.8474962100180613, disc_loss = 0.0681515751483803
Trained batch 217 in epoch 9, gen_loss = 0.8471839213316593, disc_loss = 0.06811881231126982
Trained batch 218 in epoch 9, gen_loss = 0.8472577715845413, disc_loss = 0.06832432255284972
Trained batch 219 in epoch 9, gen_loss = 0.8482709663835439, disc_loss = 0.06812921752306549
Trained batch 220 in epoch 9, gen_loss = 0.8476635186650634, disc_loss = 0.06829652490254441
Trained batch 221 in epoch 9, gen_loss = 0.8461749270424113, disc_loss = 0.06859027275496775
Trained batch 222 in epoch 9, gen_loss = 0.8463044210667033, disc_loss = 0.06851710836849939
Trained batch 223 in epoch 9, gen_loss = 0.8469917349783438, disc_loss = 0.06846336765946555
Trained batch 224 in epoch 9, gen_loss = 0.8484931756390466, disc_loss = 0.06826659338341819
Trained batch 225 in epoch 9, gen_loss = 0.8477387305645816, disc_loss = 0.06832599811321866
Trained batch 226 in epoch 9, gen_loss = 0.8476508878138622, disc_loss = 0.06810929352983766
Trained batch 227 in epoch 9, gen_loss = 0.8483890515931866, disc_loss = 0.06796968884341288
Trained batch 228 in epoch 9, gen_loss = 0.8481335107676327, disc_loss = 0.06782586136466812
Trained batch 229 in epoch 9, gen_loss = 0.8490073213110799, disc_loss = 0.06757391185054312
Trained batch 230 in epoch 9, gen_loss = 0.8504286512926027, disc_loss = 0.06746884308819905
Trained batch 231 in epoch 9, gen_loss = 0.8499602823164957, disc_loss = 0.06741626720458012
Trained batch 232 in epoch 9, gen_loss = 0.8503985969037968, disc_loss = 0.06722228122723205
Trained batch 233 in epoch 9, gen_loss = 0.8492893221286627, disc_loss = 0.06753160991570634
Trained batch 234 in epoch 9, gen_loss = 0.8505891106230148, disc_loss = 0.06826846582933943
Trained batch 235 in epoch 9, gen_loss = 0.8497365598203772, disc_loss = 0.06846926878285357
Trained batch 236 in epoch 9, gen_loss = 0.8510389515367741, disc_loss = 0.06837734098267204
Trained batch 237 in epoch 9, gen_loss = 0.8522423066261435, disc_loss = 0.06855143314743993
Trained batch 238 in epoch 9, gen_loss = 0.8507270238140138, disc_loss = 0.06891610771885227
Trained batch 239 in epoch 9, gen_loss = 0.850567880148689, disc_loss = 0.06868563717386375
Trained batch 240 in epoch 9, gen_loss = 0.8512668687525626, disc_loss = 0.06862686847286353
Trained batch 241 in epoch 9, gen_loss = 0.8503120476303022, disc_loss = 0.06885527019689153
Trained batch 242 in epoch 9, gen_loss = 0.8506571374557637, disc_loss = 0.06879628612947317
Trained batch 243 in epoch 9, gen_loss = 0.850374699005338, disc_loss = 0.06858412437446293
Trained batch 244 in epoch 9, gen_loss = 0.8505940394742149, disc_loss = 0.06836159919217533
Trained batch 245 in epoch 9, gen_loss = 0.8505656906986624, disc_loss = 0.06815372497918523
Trained batch 246 in epoch 9, gen_loss = 0.8505860517623454, disc_loss = 0.06799682395283872
Trained batch 247 in epoch 9, gen_loss = 0.8501651009484645, disc_loss = 0.06788382062973876
Trained batch 248 in epoch 9, gen_loss = 0.8491193466636551, disc_loss = 0.06808422670052593
Trained batch 249 in epoch 9, gen_loss = 0.8492793508768082, disc_loss = 0.06826497166976332
Trained batch 250 in epoch 9, gen_loss = 0.8492596886784907, disc_loss = 0.06808944392682191
Trained batch 251 in epoch 9, gen_loss = 0.848886719890057, disc_loss = 0.06790795983997958
Trained batch 252 in epoch 9, gen_loss = 0.8493236050068625, disc_loss = 0.06776809217886845
Trained batch 253 in epoch 9, gen_loss = 0.8486101454871846, disc_loss = 0.06784472115499181
Trained batch 254 in epoch 9, gen_loss = 0.8483075559139251, disc_loss = 0.06776580997176615
Trained batch 255 in epoch 9, gen_loss = 0.8501057649264112, disc_loss = 0.06771340960040106
Trained batch 256 in epoch 9, gen_loss = 0.8503086834798064, disc_loss = 0.06753557120678141
Trained batch 257 in epoch 9, gen_loss = 0.8502526774193889, disc_loss = 0.0673807497035221
Trained batch 258 in epoch 9, gen_loss = 0.8506332685358275, disc_loss = 0.06735557945207854
Trained batch 259 in epoch 9, gen_loss = 0.8503488892546067, disc_loss = 0.06718455203808844
Trained batch 260 in epoch 9, gen_loss = 0.8509762263161013, disc_loss = 0.06706832363930355
Trained batch 261 in epoch 9, gen_loss = 0.8509365783165429, disc_loss = 0.06686197429582591
Trained batch 262 in epoch 9, gen_loss = 0.8518090709307348, disc_loss = 0.06676841457108808
Trained batch 263 in epoch 9, gen_loss = 0.8508791856919274, disc_loss = 0.06675830184990032
Trained batch 264 in epoch 9, gen_loss = 0.8514881805428919, disc_loss = 0.06653647291351039
Trained batch 265 in epoch 9, gen_loss = 0.8522707462534869, disc_loss = 0.0665420036188754
Trained batch 266 in epoch 9, gen_loss = 0.8520683787958452, disc_loss = 0.06642699106997542
Trained batch 267 in epoch 9, gen_loss = 0.8512891472053172, disc_loss = 0.06644100603411224
Trained batch 268 in epoch 9, gen_loss = 0.8507031422786996, disc_loss = 0.06700454261084693
Trained batch 269 in epoch 9, gen_loss = 0.851339669028918, disc_loss = 0.06679492142327406
Trained batch 270 in epoch 9, gen_loss = 0.8512328824653836, disc_loss = 0.06662371048765649
Trained batch 271 in epoch 9, gen_loss = 0.851509598795982, disc_loss = 0.06646108556785346
Trained batch 272 in epoch 9, gen_loss = 0.8507362592132973, disc_loss = 0.06672770751728899
Trained batch 273 in epoch 9, gen_loss = 0.8505842749872347, disc_loss = 0.06662337656683513
Trained batch 274 in epoch 9, gen_loss = 0.8509953185645017, disc_loss = 0.06698243223130702
Trained batch 275 in epoch 9, gen_loss = 0.8527824376588282, disc_loss = 0.06729972649338668
Trained batch 276 in epoch 9, gen_loss = 0.8521541175213961, disc_loss = 0.06736082845243091
Trained batch 277 in epoch 9, gen_loss = 0.8517983914922467, disc_loss = 0.06720934502726836
Trained batch 278 in epoch 9, gen_loss = 0.8507360394069371, disc_loss = 0.06745906494637971
Trained batch 279 in epoch 9, gen_loss = 0.8505721987358161, disc_loss = 0.06794176532753876
Trained batch 280 in epoch 9, gen_loss = 0.850548513101089, disc_loss = 0.06800962271321287
Trained batch 281 in epoch 9, gen_loss = 0.8497998943776949, disc_loss = 0.06805844269428693
Trained batch 282 in epoch 9, gen_loss = 0.8496601384646479, disc_loss = 0.06806431068337848
Trained batch 283 in epoch 9, gen_loss = 0.8492757989697053, disc_loss = 0.06809506381691342
Trained batch 284 in epoch 9, gen_loss = 0.8494625209716329, disc_loss = 0.0678998445078992
Trained batch 285 in epoch 9, gen_loss = 0.8491400539666623, disc_loss = 0.06781207026353667
Trained batch 286 in epoch 9, gen_loss = 0.8485252746098548, disc_loss = 0.06781809227962943
Trained batch 287 in epoch 9, gen_loss = 0.8488815893522568, disc_loss = 0.06772029493004084
Trained batch 288 in epoch 9, gen_loss = 0.8488272654350241, disc_loss = 0.0675252537858579
Trained batch 289 in epoch 9, gen_loss = 0.8491258089912349, disc_loss = 0.06732581669850082
Trained batch 290 in epoch 9, gen_loss = 0.8495230362382541, disc_loss = 0.0671300395996761
Trained batch 291 in epoch 9, gen_loss = 0.8496860838303827, disc_loss = 0.06694033546437038
Trained batch 292 in epoch 9, gen_loss = 0.8497272854982383, disc_loss = 0.06687011326577375
Trained batch 293 in epoch 9, gen_loss = 0.8503953797273895, disc_loss = 0.0668352060621845
Trained batch 294 in epoch 9, gen_loss = 0.8492447896529052, disc_loss = 0.06739907318694612
Trained batch 295 in epoch 9, gen_loss = 0.85027554339251, disc_loss = 0.06734266543345577
Trained batch 296 in epoch 9, gen_loss = 0.8505907115912197, disc_loss = 0.06765087589508656
Trained batch 297 in epoch 9, gen_loss = 0.850513726772878, disc_loss = 0.067678603759323
Trained batch 298 in epoch 9, gen_loss = 0.8496872281350419, disc_loss = 0.06774583873479163
Trained batch 299 in epoch 9, gen_loss = 0.8506496305267016, disc_loss = 0.06804819152690471
Trained batch 300 in epoch 9, gen_loss = 0.8506839854574679, disc_loss = 0.06788434597827568
Trained batch 301 in epoch 9, gen_loss = 0.8506010481655992, disc_loss = 0.06773506498753729
Trained batch 302 in epoch 9, gen_loss = 0.8513970747835958, disc_loss = 0.0675643253979264
Trained batch 303 in epoch 9, gen_loss = 0.8518834442488457, disc_loss = 0.06737295620596821
Trained batch 304 in epoch 9, gen_loss = 0.8527934057790725, disc_loss = 0.06718752135934888
Trained batch 305 in epoch 9, gen_loss = 0.8516721973816553, disc_loss = 0.06731529201204384
Trained batch 306 in epoch 9, gen_loss = 0.8510880440182329, disc_loss = 0.06736879488483605
Trained batch 307 in epoch 9, gen_loss = 0.850324909505132, disc_loss = 0.06741617795067852
Trained batch 308 in epoch 9, gen_loss = 0.8503662393123972, disc_loss = 0.06755035983935047
Trained batch 309 in epoch 9, gen_loss = 0.8499265639051314, disc_loss = 0.06779869480899746
Trained batch 310 in epoch 9, gen_loss = 0.8487521746342589, disc_loss = 0.0683052350895725
Trained batch 311 in epoch 9, gen_loss = 0.8491356138808605, disc_loss = 0.06819004488762659
Trained batch 312 in epoch 9, gen_loss = 0.8496292889499055, disc_loss = 0.06820085553970105
Trained batch 313 in epoch 9, gen_loss = 0.849757745292536, disc_loss = 0.0680595064553533
Trained batch 314 in epoch 9, gen_loss = 0.8496368929507241, disc_loss = 0.06804218543249936
Trained batch 315 in epoch 9, gen_loss = 0.8493003878223745, disc_loss = 0.06809645948070986
Trained batch 316 in epoch 9, gen_loss = 0.8508459234651331, disc_loss = 0.06810668223957628
Trained batch 317 in epoch 9, gen_loss = 0.8514432156423353, disc_loss = 0.06795220657796511
Trained batch 318 in epoch 9, gen_loss = 0.8508022839559657, disc_loss = 0.06805589710738871
Trained batch 319 in epoch 9, gen_loss = 0.8509727920405566, disc_loss = 0.06812685946642887
Trained batch 320 in epoch 9, gen_loss = 0.8501498805956678, disc_loss = 0.0681608076007149
Trained batch 321 in epoch 9, gen_loss = 0.8501647217488437, disc_loss = 0.06804709103802994
Trained batch 322 in epoch 9, gen_loss = 0.8503108451794544, disc_loss = 0.06792637900429152
Trained batch 323 in epoch 9, gen_loss = 0.850036771669064, disc_loss = 0.06782899938098351
Trained batch 324 in epoch 9, gen_loss = 0.8498122599491706, disc_loss = 0.06775364273729233
Trained batch 325 in epoch 9, gen_loss = 0.8496088717429916, disc_loss = 0.06763613464859275
Trained batch 326 in epoch 9, gen_loss = 0.8497715298006658, disc_loss = 0.06807846859359504
Trained batch 327 in epoch 9, gen_loss = 0.8493086271351431, disc_loss = 0.06843765378395868
Trained batch 328 in epoch 9, gen_loss = 0.8502637924213178, disc_loss = 0.06833763165529648
Trained batch 329 in epoch 9, gen_loss = 0.8497472316026687, disc_loss = 0.06829642413861373
Trained batch 330 in epoch 9, gen_loss = 0.849949777396424, disc_loss = 0.06841361621434144
Trained batch 331 in epoch 9, gen_loss = 0.8499752729233488, disc_loss = 0.06836603786964643
Trained batch 332 in epoch 9, gen_loss = 0.8492276354415996, disc_loss = 0.0684194674760148
Trained batch 333 in epoch 9, gen_loss = 0.849759600565819, disc_loss = 0.0687678025193334
Trained batch 334 in epoch 9, gen_loss = 0.8493193666436779, disc_loss = 0.06884101280914759
Trained batch 335 in epoch 9, gen_loss = 0.8490390228551059, disc_loss = 0.06887109979843012
Trained batch 336 in epoch 9, gen_loss = 0.8489675317567604, disc_loss = 0.06873697782825203
Trained batch 337 in epoch 9, gen_loss = 0.849411538631253, disc_loss = 0.068788822737561
Trained batch 338 in epoch 9, gen_loss = 0.8490949771573059, disc_loss = 0.06884556749126816
Trained batch 339 in epoch 9, gen_loss = 0.8492444058551508, disc_loss = 0.06881200597511933
Trained batch 340 in epoch 9, gen_loss = 0.8485486135979202, disc_loss = 0.06889526933551796
Trained batch 341 in epoch 9, gen_loss = 0.8500528000077309, disc_loss = 0.06884688371792436
Trained batch 342 in epoch 9, gen_loss = 0.8500405978357132, disc_loss = 0.06898036036292857
Trained batch 343 in epoch 9, gen_loss = 0.849335311023995, disc_loss = 0.06920833307112632
Trained batch 344 in epoch 9, gen_loss = 0.8489554300688316, disc_loss = 0.06912626941296933
Trained batch 345 in epoch 9, gen_loss = 0.8494487366063057, disc_loss = 0.06911752820607124
Trained batch 346 in epoch 9, gen_loss = 0.8495719347804012, disc_loss = 0.06923729378558287
Trained batch 347 in epoch 9, gen_loss = 0.848632532546575, disc_loss = 0.06950551874924922
Trained batch 348 in epoch 9, gen_loss = 0.8482138672496664, disc_loss = 0.0694717414501019
Trained batch 349 in epoch 9, gen_loss = 0.8489725057567868, disc_loss = 0.0695136813154178
Trained batch 350 in epoch 9, gen_loss = 0.8492630710798791, disc_loss = 0.06946175779744006
Trained batch 351 in epoch 9, gen_loss = 0.8491551240228794, disc_loss = 0.06952557419373823
Trained batch 352 in epoch 9, gen_loss = 0.8486503581318572, disc_loss = 0.06948112972640029
Trained batch 353 in epoch 9, gen_loss = 0.8483273024107777, disc_loss = 0.06943895118205813
Trained batch 354 in epoch 9, gen_loss = 0.8491474276697132, disc_loss = 0.0693417513323292
Trained batch 355 in epoch 9, gen_loss = 0.8497104146674778, disc_loss = 0.06932285163038818
Trained batch 356 in epoch 9, gen_loss = 0.8499661092163802, disc_loss = 0.06917119937419307
Trained batch 357 in epoch 9, gen_loss = 0.84926691076942, disc_loss = 0.06935837212689845
Trained batch 358 in epoch 9, gen_loss = 0.8494318996797365, disc_loss = 0.06921455192750627
Trained batch 359 in epoch 9, gen_loss = 0.8503322035902077, disc_loss = 0.06913171080717197
Trained batch 360 in epoch 9, gen_loss = 0.8510938200098656, disc_loss = 0.06901469322339401
Trained batch 361 in epoch 9, gen_loss = 0.8502121705211987, disc_loss = 0.06916182802331464
Trained batch 362 in epoch 9, gen_loss = 0.8499478884143934, disc_loss = 0.0690376092718283
Trained batch 363 in epoch 9, gen_loss = 0.8503172303457837, disc_loss = 0.06887292058800686
Trained batch 364 in epoch 9, gen_loss = 0.8507443141447355, disc_loss = 0.06871578611994851
Trained batch 365 in epoch 9, gen_loss = 0.8505164265144066, disc_loss = 0.06863371915148338
Trained batch 366 in epoch 9, gen_loss = 0.8505176066215422, disc_loss = 0.06855788062851906
Trained batch 367 in epoch 9, gen_loss = 0.8501699528778377, disc_loss = 0.06853802780792846
Trained batch 368 in epoch 9, gen_loss = 0.8500591081170855, disc_loss = 0.06849734935667215
Trained batch 369 in epoch 9, gen_loss = 0.8511674395284137, disc_loss = 0.06842605045971435
Trained batch 370 in epoch 9, gen_loss = 0.8503083478247702, disc_loss = 0.06853010261687387
Trained batch 371 in epoch 9, gen_loss = 0.8507919509404449, disc_loss = 0.06894403074427398
Trained batch 372 in epoch 9, gen_loss = 0.8501803338847276, disc_loss = 0.06908096893673049
Trained batch 373 in epoch 9, gen_loss = 0.850257059230524, disc_loss = 0.06894738688058952
Trained batch 374 in epoch 9, gen_loss = 0.8504442959626516, disc_loss = 0.06899888853977124
Trained batch 375 in epoch 9, gen_loss = 0.8503199968724808, disc_loss = 0.06886391223537082
Trained batch 376 in epoch 9, gen_loss = 0.8501072281709716, disc_loss = 0.06881940214393231
Trained batch 377 in epoch 9, gen_loss = 0.8507115460104413, disc_loss = 0.06875987864153647
Trained batch 378 in epoch 9, gen_loss = 0.8505799585565099, disc_loss = 0.06863031270704908
Trained batch 379 in epoch 9, gen_loss = 0.8501733818336537, disc_loss = 0.06859423008159195
Trained batch 380 in epoch 9, gen_loss = 0.8506304170359463, disc_loss = 0.06851913484444064
Trained batch 381 in epoch 9, gen_loss = 0.8513427390009946, disc_loss = 0.06842813523564273
Trained batch 382 in epoch 9, gen_loss = 0.8510274962563428, disc_loss = 0.06833722946956249
Trained batch 383 in epoch 9, gen_loss = 0.8512485603957126, disc_loss = 0.06817946963322659
Trained batch 384 in epoch 9, gen_loss = 0.8514286817668321, disc_loss = 0.06812235946198562
Trained batch 385 in epoch 9, gen_loss = 0.8514514870439787, disc_loss = 0.06802055097807566
Trained batch 386 in epoch 9, gen_loss = 0.851248245599658, disc_loss = 0.06788212153338646
Trained batch 387 in epoch 9, gen_loss = 0.8511953858524254, disc_loss = 0.06779682095709842
Trained batch 388 in epoch 9, gen_loss = 0.8515613760157539, disc_loss = 0.06765170797830146
Trained batch 389 in epoch 9, gen_loss = 0.8522525461056294, disc_loss = 0.06756862930428141
Trained batch 390 in epoch 9, gen_loss = 0.8522629398671563, disc_loss = 0.06746986978794531
Trained batch 391 in epoch 9, gen_loss = 0.8525293483874019, disc_loss = 0.06733445445674338
Trained batch 392 in epoch 9, gen_loss = 0.8531010028818484, disc_loss = 0.06718830366644998
Trained batch 393 in epoch 9, gen_loss = 0.852906915061365, disc_loss = 0.067096643286951
Trained batch 394 in epoch 9, gen_loss = 0.8531757761405994, disc_loss = 0.06694970052642159
Trained batch 395 in epoch 9, gen_loss = 0.8531111101761009, disc_loss = 0.06680925815798944
Trained batch 396 in epoch 9, gen_loss = 0.8533032025287974, disc_loss = 0.06670282334699214
Trained batch 397 in epoch 9, gen_loss = 0.8533588115444135, disc_loss = 0.06657423698881539
Trained batch 398 in epoch 9, gen_loss = 0.8536237526806375, disc_loss = 0.06643033052857657
Trained batch 399 in epoch 9, gen_loss = 0.8540334764868021, disc_loss = 0.06639955724589526
Trained batch 400 in epoch 9, gen_loss = 0.8535753837101477, disc_loss = 0.06655419752596323
Trained batch 401 in epoch 9, gen_loss = 0.8532845007987758, disc_loss = 0.06646040435046402
Trained batch 402 in epoch 9, gen_loss = 0.8533137216609405, disc_loss = 0.06636027266588015
Trained batch 403 in epoch 9, gen_loss = 0.854101526781474, disc_loss = 0.06670037549597645
Trained batch 404 in epoch 9, gen_loss = 0.8536424082738382, disc_loss = 0.06677396405534244
Trained batch 405 in epoch 9, gen_loss = 0.8530794491468392, disc_loss = 0.06681330888784431
Trained batch 406 in epoch 9, gen_loss = 0.853691487186371, disc_loss = 0.06702307710099133
Trained batch 407 in epoch 9, gen_loss = 0.8534811335597553, disc_loss = 0.06701460023702797
Trained batch 408 in epoch 9, gen_loss = 0.8530301465527644, disc_loss = 0.06709107297101494
Trained batch 409 in epoch 9, gen_loss = 0.8529296256420089, disc_loss = 0.06706807140442657
Trained batch 410 in epoch 9, gen_loss = 0.8530267751854992, disc_loss = 0.06736526081288673
Trained batch 411 in epoch 9, gen_loss = 0.8526573449517917, disc_loss = 0.06737530646954203
Trained batch 412 in epoch 9, gen_loss = 0.8522863569184597, disc_loss = 0.06740042956469279
Trained batch 413 in epoch 9, gen_loss = 0.8532549340799811, disc_loss = 0.06749932971391556
Trained batch 414 in epoch 9, gen_loss = 0.8528450854571469, disc_loss = 0.06753356944634972
Trained batch 415 in epoch 9, gen_loss = 0.8529594773426652, disc_loss = 0.06743343481167148
Trained batch 416 in epoch 9, gen_loss = 0.8528065167599731, disc_loss = 0.06740047993937985
Trained batch 417 in epoch 9, gen_loss = 0.8529479307563681, disc_loss = 0.06734691251461443
Trained batch 418 in epoch 9, gen_loss = 0.8532811546240331, disc_loss = 0.06734150149781692
Trained batch 419 in epoch 9, gen_loss = 0.8536335034739404, disc_loss = 0.06723130477947138
Trained batch 420 in epoch 9, gen_loss = 0.8529375809247024, disc_loss = 0.06728502974852106
Trained batch 421 in epoch 9, gen_loss = 0.8530771487273311, disc_loss = 0.06715973168258418
Trained batch 422 in epoch 9, gen_loss = 0.8537921387675806, disc_loss = 0.06713765078437807
Trained batch 423 in epoch 9, gen_loss = 0.8533136125583693, disc_loss = 0.06707382918212493
Trained batch 424 in epoch 9, gen_loss = 0.8532709345396827, disc_loss = 0.06694921535165871
Trained batch 425 in epoch 9, gen_loss = 0.8532610248092195, disc_loss = 0.06690900875561534
Trained batch 426 in epoch 9, gen_loss = 0.8531551629793449, disc_loss = 0.06684464345788649
Trained batch 427 in epoch 9, gen_loss = 0.8529137791456464, disc_loss = 0.06687943702215486
Trained batch 428 in epoch 9, gen_loss = 0.8526689046885306, disc_loss = 0.06686455008328517
Trained batch 429 in epoch 9, gen_loss = 0.853328188006268, disc_loss = 0.06708898797717898
Trained batch 430 in epoch 9, gen_loss = 0.8534883898952997, disc_loss = 0.06698100490110932
Trained batch 431 in epoch 9, gen_loss = 0.853419903182873, disc_loss = 0.06687586576056977
Trained batch 432 in epoch 9, gen_loss = 0.8528860373117081, disc_loss = 0.0669297585328374
Trained batch 433 in epoch 9, gen_loss = 0.8528974473064396, disc_loss = 0.06704662140235648
Trained batch 434 in epoch 9, gen_loss = 0.8520142434657305, disc_loss = 0.06732325517069335
Trained batch 435 in epoch 9, gen_loss = 0.8527839238490533, disc_loss = 0.06732732564245068
Trained batch 436 in epoch 9, gen_loss = 0.8526820148974316, disc_loss = 0.06722346332256664
Trained batch 437 in epoch 9, gen_loss = 0.8524233814516023, disc_loss = 0.06713447954981974
Trained batch 438 in epoch 9, gen_loss = 0.8524283348563592, disc_loss = 0.06710381349782059
Trained batch 439 in epoch 9, gen_loss = 0.8524674557826736, disc_loss = 0.06700464730066331
Trained batch 440 in epoch 9, gen_loss = 0.8527333444478561, disc_loss = 0.06702298247793904
Trained batch 441 in epoch 9, gen_loss = 0.852329400599812, disc_loss = 0.06700553688562025
Trained batch 442 in epoch 9, gen_loss = 0.8523673830936509, disc_loss = 0.06693149640584369
Trained batch 443 in epoch 9, gen_loss = 0.853417298278293, disc_loss = 0.06706610434428528
Trained batch 444 in epoch 9, gen_loss = 0.8529320518622238, disc_loss = 0.06709181703208537
Trained batch 445 in epoch 9, gen_loss = 0.8526231149386932, disc_loss = 0.06713277034695372
Trained batch 446 in epoch 9, gen_loss = 0.8528493949497573, disc_loss = 0.06703732709006575
Trained batch 447 in epoch 9, gen_loss = 0.8528746144313898, disc_loss = 0.0669196599524834
Trained batch 448 in epoch 9, gen_loss = 0.8530737024904094, disc_loss = 0.06687491245874783
Trained batch 449 in epoch 9, gen_loss = 0.8530271025498708, disc_loss = 0.06682449345580406
Trained batch 450 in epoch 9, gen_loss = 0.8529414275533079, disc_loss = 0.06673259688892345
Trained batch 451 in epoch 9, gen_loss = 0.8534743254427362, disc_loss = 0.06732525059384649
Trained batch 452 in epoch 9, gen_loss = 0.8525746655516804, disc_loss = 0.06790217911211927
Trained batch 453 in epoch 9, gen_loss = 0.852374098899606, disc_loss = 0.06811186887266418
Trained batch 454 in epoch 9, gen_loss = 0.8526276725989121, disc_loss = 0.06817426972377759
Trained batch 455 in epoch 9, gen_loss = 0.8521228313707468, disc_loss = 0.06832072425739873
Trained batch 456 in epoch 9, gen_loss = 0.8523690233606217, disc_loss = 0.06868312238252984
Trained batch 457 in epoch 9, gen_loss = 0.8518349477557636, disc_loss = 0.06896892771751144
Trained batch 458 in epoch 9, gen_loss = 0.8516120597687682, disc_loss = 0.0689343228583145
Trained batch 459 in epoch 9, gen_loss = 0.8521415507015975, disc_loss = 0.069046991960267
Trained batch 460 in epoch 9, gen_loss = 0.851875222168879, disc_loss = 0.06901249474767038
Trained batch 461 in epoch 9, gen_loss = 0.8515841785447422, disc_loss = 0.0690013891049697
Trained batch 462 in epoch 9, gen_loss = 0.8518796924895911, disc_loss = 0.06891758790436818
Trained batch 463 in epoch 9, gen_loss = 0.8516104732607973, disc_loss = 0.06889458999222402
Trained batch 464 in epoch 9, gen_loss = 0.8517178750807239, disc_loss = 0.06891075553552758
Trained batch 465 in epoch 9, gen_loss = 0.8512468719175446, disc_loss = 0.06897522046834294
Trained batch 466 in epoch 9, gen_loss = 0.8510206363441092, disc_loss = 0.06893466441539102
Trained batch 467 in epoch 9, gen_loss = 0.8506188104804765, disc_loss = 0.06900985021359073
Trained batch 468 in epoch 9, gen_loss = 0.8506345675189866, disc_loss = 0.06892494041758623
Trained batch 469 in epoch 9, gen_loss = 0.8505508088051005, disc_loss = 0.06892782308042367
Trained batch 470 in epoch 9, gen_loss = 0.8509499467355683, disc_loss = 0.0688244279833894
Trained batch 471 in epoch 9, gen_loss = 0.8509066983804865, disc_loss = 0.06875091670594036
Trained batch 472 in epoch 9, gen_loss = 0.8502822682166956, disc_loss = 0.06880984531939975
Trained batch 473 in epoch 9, gen_loss = 0.8508876492957023, disc_loss = 0.06879526770669762
Trained batch 474 in epoch 9, gen_loss = 0.8507257107684487, disc_loss = 0.06871606193678943
Trained batch 475 in epoch 9, gen_loss = 0.8509188214270007, disc_loss = 0.0685930911807672
Trained batch 476 in epoch 9, gen_loss = 0.8508830033008408, disc_loss = 0.06852877730273288
Trained batch 477 in epoch 9, gen_loss = 0.8506827753458063, disc_loss = 0.06848758231326314
Trained batch 478 in epoch 9, gen_loss = 0.8508089372658779, disc_loss = 0.06838909655008349
Trained batch 479 in epoch 9, gen_loss = 0.8511354096233845, disc_loss = 0.06857547957333736
Trained batch 480 in epoch 9, gen_loss = 0.8508512537593406, disc_loss = 0.06854941996623783
Trained batch 481 in epoch 9, gen_loss = 0.8501920193062779, disc_loss = 0.06872234362297347
Trained batch 482 in epoch 9, gen_loss = 0.8505926539438852, disc_loss = 0.06879485067072677
Trained batch 483 in epoch 9, gen_loss = 0.8501659140360257, disc_loss = 0.06883133692505254
Trained batch 484 in epoch 9, gen_loss = 0.8502979400231666, disc_loss = 0.06876782092275387
Trained batch 485 in epoch 9, gen_loss = 0.8501766313005377, disc_loss = 0.0687523060363292
Trained batch 486 in epoch 9, gen_loss = 0.8497343686327062, disc_loss = 0.0687956777429954
Trained batch 487 in epoch 9, gen_loss = 0.8494203944430977, disc_loss = 0.06882299913559109
Trained batch 488 in epoch 9, gen_loss = 0.8499584893995024, disc_loss = 0.0691005061942406
Trained batch 489 in epoch 9, gen_loss = 0.8502810462396972, disc_loss = 0.06908162840813094
Trained batch 490 in epoch 9, gen_loss = 0.8503735685785531, disc_loss = 0.06905902740251568
Trained batch 491 in epoch 9, gen_loss = 0.8497265742077091, disc_loss = 0.06944333153352808
Trained batch 492 in epoch 9, gen_loss = 0.8501150685439971, disc_loss = 0.069418741879384
Trained batch 493 in epoch 9, gen_loss = 0.8499904243569625, disc_loss = 0.06955501809904752
Trained batch 494 in epoch 9, gen_loss = 0.8498299785334654, disc_loss = 0.06954663378007785
Trained batch 495 in epoch 9, gen_loss = 0.8496396494728904, disc_loss = 0.06960508661652584
Trained batch 496 in epoch 9, gen_loss = 0.8493101825896403, disc_loss = 0.06962176160680757
Trained batch 497 in epoch 9, gen_loss = 0.8493264045820658, disc_loss = 0.06953192733594751
Trained batch 498 in epoch 9, gen_loss = 0.8492529569025746, disc_loss = 0.06959132960099794
Trained batch 499 in epoch 9, gen_loss = 0.8491048274040223, disc_loss = 0.06956849783100187
Trained batch 500 in epoch 9, gen_loss = 0.8489647071042699, disc_loss = 0.06950825961592966
Trained batch 501 in epoch 9, gen_loss = 0.8490692092128009, disc_loss = 0.06954972662840528
Trained batch 502 in epoch 9, gen_loss = 0.8492270762593325, disc_loss = 0.06946266353108121
Trained batch 503 in epoch 9, gen_loss = 0.8489258997733631, disc_loss = 0.06942655398355176
Trained batch 504 in epoch 9, gen_loss = 0.8491479114730759, disc_loss = 0.06935741813798058
Trained batch 505 in epoch 9, gen_loss = 0.8494213971460289, disc_loss = 0.06929782344573159
Trained batch 506 in epoch 9, gen_loss = 0.8492698402564671, disc_loss = 0.0692574362375239
Trained batch 507 in epoch 9, gen_loss = 0.8490192039510397, disc_loss = 0.06919964128100556
Trained batch 508 in epoch 9, gen_loss = 0.8488725691975217, disc_loss = 0.06911803288879294
Trained batch 509 in epoch 9, gen_loss = 0.8496141095956167, disc_loss = 0.06915948256740675
Trained batch 510 in epoch 9, gen_loss = 0.8495079140140586, disc_loss = 0.06910893242485427
Trained batch 511 in epoch 9, gen_loss = 0.8494017651537433, disc_loss = 0.06912084772375238
Trained batch 512 in epoch 9, gen_loss = 0.8501008970928007, disc_loss = 0.06906445655013212
Trained batch 513 in epoch 9, gen_loss = 0.8498889464116746, disc_loss = 0.06902804374441157
Trained batch 514 in epoch 9, gen_loss = 0.8502462378983359, disc_loss = 0.06910554473876085
Trained batch 515 in epoch 9, gen_loss = 0.8500251334535983, disc_loss = 0.06907797608589537
Trained batch 516 in epoch 9, gen_loss = 0.8502388533125532, disc_loss = 0.06900363858803617
Trained batch 517 in epoch 9, gen_loss = 0.8501478599305319, disc_loss = 0.06930458069056215
Trained batch 518 in epoch 9, gen_loss = 0.8496632766631756, disc_loss = 0.06936354033096276
Trained batch 519 in epoch 9, gen_loss = 0.8494848540196052, disc_loss = 0.0692888071670985
Trained batch 520 in epoch 9, gen_loss = 0.8493558447557767, disc_loss = 0.0692982907083436
Trained batch 521 in epoch 9, gen_loss = 0.8495552376540685, disc_loss = 0.06922109015250286
Trained batch 522 in epoch 9, gen_loss = 0.8494743996550886, disc_loss = 0.06918464362243792
Trained batch 523 in epoch 9, gen_loss = 0.8495930526547759, disc_loss = 0.06907357366840916
Trained batch 524 in epoch 9, gen_loss = 0.8496811946233114, disc_loss = 0.06900052207566443
Trained batch 525 in epoch 9, gen_loss = 0.8492567467825495, disc_loss = 0.06894599533013064
Trained batch 526 in epoch 9, gen_loss = 0.8497196995782219, disc_loss = 0.06884463391915331
Trained batch 527 in epoch 9, gen_loss = 0.8500302249960827, disc_loss = 0.06881561860174054
Trained batch 528 in epoch 9, gen_loss = 0.8498663576654315, disc_loss = 0.06874090322207076
Trained batch 529 in epoch 9, gen_loss = 0.8498430298184448, disc_loss = 0.06865677653970022
Trained batch 530 in epoch 9, gen_loss = 0.85006967922164, disc_loss = 0.06855625455949996
Trained batch 531 in epoch 9, gen_loss = 0.849487614250721, disc_loss = 0.06859375257920333
Trained batch 532 in epoch 9, gen_loss = 0.8500012122444096, disc_loss = 0.06892166868390386
Trained batch 533 in epoch 9, gen_loss = 0.8496207946471954, disc_loss = 0.06893892915682233
Trained batch 534 in epoch 9, gen_loss = 0.8495322776732044, disc_loss = 0.0689072072662622
Trained batch 535 in epoch 9, gen_loss = 0.8501031055156865, disc_loss = 0.06918374406097373
Trained batch 536 in epoch 9, gen_loss = 0.8498497492108266, disc_loss = 0.06914018191140513
Trained batch 537 in epoch 9, gen_loss = 0.8491440532819046, disc_loss = 0.0693062982265751
Trained batch 538 in epoch 9, gen_loss = 0.8492517191536573, disc_loss = 0.06952850401214909
Trained batch 539 in epoch 9, gen_loss = 0.8494941577867225, disc_loss = 0.06942610466266395
Trained batch 540 in epoch 9, gen_loss = 0.8492087129083447, disc_loss = 0.06949857308558582
Trained batch 541 in epoch 9, gen_loss = 0.8494857876283216, disc_loss = 0.06959859673724238
Trained batch 542 in epoch 9, gen_loss = 0.8492354371929696, disc_loss = 0.06963044465528063
Trained batch 543 in epoch 9, gen_loss = 0.8488430005005178, disc_loss = 0.06976788863710895
Trained batch 544 in epoch 9, gen_loss = 0.8488661747459971, disc_loss = 0.06986529031648822
Trained batch 545 in epoch 9, gen_loss = 0.8485654777004605, disc_loss = 0.06983907178433223
Trained batch 546 in epoch 9, gen_loss = 0.8486212129130878, disc_loss = 0.06980954633150556
Trained batch 547 in epoch 9, gen_loss = 0.8481595317160127, disc_loss = 0.06975905118122643
Trained batch 548 in epoch 9, gen_loss = 0.8475995398175739, disc_loss = 0.06989685121163698
Trained batch 549 in epoch 9, gen_loss = 0.8477871374650435, disc_loss = 0.06979182279414751
Trained batch 550 in epoch 9, gen_loss = 0.8480617477543341, disc_loss = 0.06968162628820339
Trained batch 551 in epoch 9, gen_loss = 0.8483242748872094, disc_loss = 0.06957161258163767
Trained batch 552 in epoch 9, gen_loss = 0.8482945191709301, disc_loss = 0.06961627255040634
Trained batch 553 in epoch 9, gen_loss = 0.8478917921708379, disc_loss = 0.069596572644632
Trained batch 554 in epoch 9, gen_loss = 0.8484708046053981, disc_loss = 0.06957527886035743
Trained batch 555 in epoch 9, gen_loss = 0.847912725463188, disc_loss = 0.06976570466050891
Trained batch 556 in epoch 9, gen_loss = 0.8480640990087759, disc_loss = 0.06980006185091056
Trained batch 557 in epoch 9, gen_loss = 0.8477748035316399, disc_loss = 0.06986348753908522
Trained batch 558 in epoch 9, gen_loss = 0.8475781738864715, disc_loss = 0.0699931462670215
Trained batch 559 in epoch 9, gen_loss = 0.8476352040256773, disc_loss = 0.06993132651717003
Trained batch 560 in epoch 9, gen_loss = 0.847213495648906, disc_loss = 0.06996543434865228
Trained batch 561 in epoch 9, gen_loss = 0.8470400124257994, disc_loss = 0.06990970932013518
Trained batch 562 in epoch 9, gen_loss = 0.8477354405404831, disc_loss = 0.0699287997674508
Trained batch 563 in epoch 9, gen_loss = 0.8475358258959249, disc_loss = 0.06984816540481774
Trained batch 564 in epoch 9, gen_loss = 0.8474671299478649, disc_loss = 0.06976146871735037
Trained batch 565 in epoch 9, gen_loss = 0.8471083948553241, disc_loss = 0.06981401131965562
Trained batch 566 in epoch 9, gen_loss = 0.8475928056387254, disc_loss = 0.06984923177807735
Trained batch 567 in epoch 9, gen_loss = 0.8476518442932989, disc_loss = 0.06978575071700337
Trained batch 568 in epoch 9, gen_loss = 0.8475108720715729, disc_loss = 0.06983971032387658
Trained batch 569 in epoch 9, gen_loss = 0.8474255442619324, disc_loss = 0.06983099451386615
Trained batch 570 in epoch 9, gen_loss = 0.8474760350955556, disc_loss = 0.06978354059916557
Trained batch 571 in epoch 9, gen_loss = 0.8476031746689257, disc_loss = 0.06970649291077381
Trained batch 572 in epoch 9, gen_loss = 0.8473376127229727, disc_loss = 0.06972396426084881
Trained batch 573 in epoch 9, gen_loss = 0.8468639791427174, disc_loss = 0.06979641557479672
Trained batch 574 in epoch 9, gen_loss = 0.8468501854979473, disc_loss = 0.06989902462972247
Trained batch 575 in epoch 9, gen_loss = 0.8475731653678749, disc_loss = 0.07022698718032593
Trained batch 576 in epoch 9, gen_loss = 0.8474645074360085, disc_loss = 0.07016050620924559
Trained batch 577 in epoch 9, gen_loss = 0.8469482121995576, disc_loss = 0.07030770472963066
Trained batch 578 in epoch 9, gen_loss = 0.8468158969813266, disc_loss = 0.07028134956325377
Trained batch 579 in epoch 9, gen_loss = 0.8470406682326876, disc_loss = 0.07033446744919337
Trained batch 580 in epoch 9, gen_loss = 0.8469346645777074, disc_loss = 0.07030031546988812
Trained batch 581 in epoch 9, gen_loss = 0.8466079036394755, disc_loss = 0.07036170558331861
Trained batch 582 in epoch 9, gen_loss = 0.8465113157269067, disc_loss = 0.07028193121670552
Trained batch 583 in epoch 9, gen_loss = 0.8461674643705969, disc_loss = 0.07029568568854401
Trained batch 584 in epoch 9, gen_loss = 0.8468051148276043, disc_loss = 0.07058368826078044
Trained batch 585 in epoch 9, gen_loss = 0.8469566022373304, disc_loss = 0.07052803280168934
Trained batch 586 in epoch 9, gen_loss = 0.8465584941982613, disc_loss = 0.07056544392704456
Trained batch 587 in epoch 9, gen_loss = 0.8461617582103833, disc_loss = 0.07055952889388617
Trained batch 588 in epoch 9, gen_loss = 0.8460114971688729, disc_loss = 0.0704968882620284
Trained batch 589 in epoch 9, gen_loss = 0.8458839446811353, disc_loss = 0.07044420216106258
Trained batch 590 in epoch 9, gen_loss = 0.8465837542780765, disc_loss = 0.07050545414351872
Trained batch 591 in epoch 9, gen_loss = 0.8463090221221382, disc_loss = 0.07055077568715992
Trained batch 592 in epoch 9, gen_loss = 0.846338750741132, disc_loss = 0.0704728682096702
Trained batch 593 in epoch 9, gen_loss = 0.846134924226337, disc_loss = 0.07049868915932447
Trained batch 594 in epoch 9, gen_loss = 0.8468615510884453, disc_loss = 0.07095198556467766
Trained batch 595 in epoch 9, gen_loss = 0.8467181735990832, disc_loss = 0.07095305496926775
Trained batch 596 in epoch 9, gen_loss = 0.8466381036256825, disc_loss = 0.07094082231609965
Trained batch 597 in epoch 9, gen_loss = 0.8466080558738581, disc_loss = 0.07091124283841323
Trained batch 598 in epoch 9, gen_loss = 0.8467244783506569, disc_loss = 0.07108769495232974
Trained batch 599 in epoch 9, gen_loss = 0.8463957103093466, disc_loss = 0.07110440562479198
Trained batch 600 in epoch 9, gen_loss = 0.8460156764841318, disc_loss = 0.07107991830270718
Trained batch 601 in epoch 9, gen_loss = 0.8463203604039163, disc_loss = 0.07106486242883328
Trained batch 602 in epoch 9, gen_loss = 0.8460144514270486, disc_loss = 0.07109880466230374
Trained batch 603 in epoch 9, gen_loss = 0.8458436372264332, disc_loss = 0.07110377925676324
Trained batch 604 in epoch 9, gen_loss = 0.845988647011686, disc_loss = 0.07103876821573608
Trained batch 605 in epoch 9, gen_loss = 0.8454920745918854, disc_loss = 0.07117281775774047
Trained batch 606 in epoch 9, gen_loss = 0.8457015400270653, disc_loss = 0.07109198490344909
Trained batch 607 in epoch 9, gen_loss = 0.845864041463325, disc_loss = 0.07125933542480006
Trained batch 608 in epoch 9, gen_loss = 0.8454832220312409, disc_loss = 0.07132645360574934
Trained batch 609 in epoch 9, gen_loss = 0.8458214918120963, disc_loss = 0.07124044578217092
Trained batch 610 in epoch 9, gen_loss = 0.8455466365658125, disc_loss = 0.07126469071802063
Trained batch 611 in epoch 9, gen_loss = 0.8453633699541777, disc_loss = 0.07130010733441784
Trained batch 612 in epoch 9, gen_loss = 0.8454607581236623, disc_loss = 0.07123059547562487
Trained batch 613 in epoch 9, gen_loss = 0.8453644083066562, disc_loss = 0.07117875015320627
Trained batch 614 in epoch 9, gen_loss = 0.8450184229912797, disc_loss = 0.07114980872871915
Trained batch 615 in epoch 9, gen_loss = 0.8450115728494408, disc_loss = 0.07111979312529522
Trained batch 616 in epoch 9, gen_loss = 0.8447644993590381, disc_loss = 0.07109198968923942
Trained batch 617 in epoch 9, gen_loss = 0.8449528636862931, disc_loss = 0.07110354437833369
Trained batch 618 in epoch 9, gen_loss = 0.8447597808714638, disc_loss = 0.07117742470650662
Trained batch 619 in epoch 9, gen_loss = 0.8443767684121286, disc_loss = 0.07136050186029845
Trained batch 620 in epoch 9, gen_loss = 0.8448464444294068, disc_loss = 0.07128457841125951
Trained batch 621 in epoch 9, gen_loss = 0.8449754791627743, disc_loss = 0.07118666772446161
Trained batch 622 in epoch 9, gen_loss = 0.8454476914474708, disc_loss = 0.07111905830019837
Trained batch 623 in epoch 9, gen_loss = 0.8454729744639152, disc_loss = 0.0710363993062996
Trained batch 624 in epoch 9, gen_loss = 0.8449723252296448, disc_loss = 0.07120853494405746
Trained batch 625 in epoch 9, gen_loss = 0.8449850366138422, disc_loss = 0.07114949467154547
Trained batch 626 in epoch 9, gen_loss = 0.8450167326455671, disc_loss = 0.07127243902480773
Trained batch 627 in epoch 9, gen_loss = 0.8450679276969023, disc_loss = 0.07117633943321408
Trained batch 628 in epoch 9, gen_loss = 0.845034506438457, disc_loss = 0.07110635333639734
Trained batch 629 in epoch 9, gen_loss = 0.8450266998911661, disc_loss = 0.07104075432769837
Trained batch 630 in epoch 9, gen_loss = 0.8454252685495488, disc_loss = 0.07095626130310462
Trained batch 631 in epoch 9, gen_loss = 0.8457926204310188, disc_loss = 0.07087536175334472
Trained batch 632 in epoch 9, gen_loss = 0.8458575957570973, disc_loss = 0.07078285747476946
Trained batch 633 in epoch 9, gen_loss = 0.8456494798795658, disc_loss = 0.0707474104407881
Trained batch 634 in epoch 9, gen_loss = 0.8458098925004794, disc_loss = 0.07074091547410788
Trained batch 635 in epoch 9, gen_loss = 0.8453355159774516, disc_loss = 0.07076256361690426
Trained batch 636 in epoch 9, gen_loss = 0.8454036622818448, disc_loss = 0.07076873453962654
Trained batch 637 in epoch 9, gen_loss = 0.8454513446103816, disc_loss = 0.07073748831383207
Trained batch 638 in epoch 9, gen_loss = 0.8452577000492615, disc_loss = 0.07068192257206299
Trained batch 639 in epoch 9, gen_loss = 0.8456226848997176, disc_loss = 0.07059117080498253
Trained batch 640 in epoch 9, gen_loss = 0.845950465399464, disc_loss = 0.07050241335104808
Trained batch 641 in epoch 9, gen_loss = 0.8457632214295159, disc_loss = 0.07048245032993943
Trained batch 642 in epoch 9, gen_loss = 0.845960997033453, disc_loss = 0.07041520667501362
Trained batch 643 in epoch 9, gen_loss = 0.8459217911181243, disc_loss = 0.07039471407224257
Trained batch 644 in epoch 9, gen_loss = 0.846465627167576, disc_loss = 0.07032366278473028
Trained batch 645 in epoch 9, gen_loss = 0.8461402917609495, disc_loss = 0.07043261841175956
Trained batch 646 in epoch 9, gen_loss = 0.8458901062446547, disc_loss = 0.07041317920187572
Trained batch 647 in epoch 9, gen_loss = 0.8457220479110141, disc_loss = 0.07034703389379299
Trained batch 648 in epoch 9, gen_loss = 0.8461022357727603, disc_loss = 0.0705391668595477
Trained batch 649 in epoch 9, gen_loss = 0.8461342507142287, disc_loss = 0.07047135918616103
Trained batch 650 in epoch 9, gen_loss = 0.84577749594016, disc_loss = 0.07061570238882817
Trained batch 651 in epoch 9, gen_loss = 0.8461338214896208, disc_loss = 0.07070034730213871
Trained batch 652 in epoch 9, gen_loss = 0.8460353683183971, disc_loss = 0.07063716143272691
Trained batch 653 in epoch 9, gen_loss = 0.8456970180757913, disc_loss = 0.07070230260713521
Trained batch 654 in epoch 9, gen_loss = 0.8457967838258234, disc_loss = 0.07064350147710274
Trained batch 655 in epoch 9, gen_loss = 0.8452224159022657, disc_loss = 0.0708183104714674
Trained batch 656 in epoch 9, gen_loss = 0.8454298755349634, disc_loss = 0.07096177768642635
Trained batch 657 in epoch 9, gen_loss = 0.8457260755057755, disc_loss = 0.07103170727812727
Trained batch 658 in epoch 9, gen_loss = 0.845741831478472, disc_loss = 0.07095809206394804
Trained batch 659 in epoch 9, gen_loss = 0.8453789972897732, disc_loss = 0.07126762885177
Trained batch 660 in epoch 9, gen_loss = 0.845587157626015, disc_loss = 0.07120505187367392
Trained batch 661 in epoch 9, gen_loss = 0.8459472551806816, disc_loss = 0.07116145823077719
Trained batch 662 in epoch 9, gen_loss = 0.8459676207460429, disc_loss = 0.07110066455262144
Trained batch 663 in epoch 9, gen_loss = 0.8456244886998671, disc_loss = 0.07123939445696727
Trained batch 664 in epoch 9, gen_loss = 0.8457166349081169, disc_loss = 0.07134320549526833
Trained batch 665 in epoch 9, gen_loss = 0.845929380293723, disc_loss = 0.07126838102092121
Trained batch 666 in epoch 9, gen_loss = 0.8454550722728427, disc_loss = 0.07139667831891883
Trained batch 667 in epoch 9, gen_loss = 0.8453402543317772, disc_loss = 0.07133938095108522
Trained batch 668 in epoch 9, gen_loss = 0.8458492569681062, disc_loss = 0.07142886951125835
Trained batch 669 in epoch 9, gen_loss = 0.8457813315427125, disc_loss = 0.07134213354438543
Trained batch 670 in epoch 9, gen_loss = 0.8456180601112889, disc_loss = 0.07129212946599091
Trained batch 671 in epoch 9, gen_loss = 0.8454149564994233, disc_loss = 0.07128578617647734
Trained batch 672 in epoch 9, gen_loss = 0.8454299441595489, disc_loss = 0.07138677096661362
Trained batch 673 in epoch 9, gen_loss = 0.8450827083000444, disc_loss = 0.07152277532169037
Trained batch 674 in epoch 9, gen_loss = 0.8454871925601253, disc_loss = 0.07145138514814553
Trained batch 675 in epoch 9, gen_loss = 0.8455045234698516, disc_loss = 0.07141934500555315
Trained batch 676 in epoch 9, gen_loss = 0.8451089393264962, disc_loss = 0.07148696737504252
Trained batch 677 in epoch 9, gen_loss = 0.8451821380308596, disc_loss = 0.07142989518214292
Trained batch 678 in epoch 9, gen_loss = 0.8454358410940606, disc_loss = 0.07133928192326791
Trained batch 679 in epoch 9, gen_loss = 0.8453988508266561, disc_loss = 0.07125795375391403
Trained batch 680 in epoch 9, gen_loss = 0.8453394466909893, disc_loss = 0.0712214973666288
Trained batch 681 in epoch 9, gen_loss = 0.8455707537463684, disc_loss = 0.07115083954998912
Trained batch 682 in epoch 9, gen_loss = 0.845721486721346, disc_loss = 0.07111244994770642
Trained batch 683 in epoch 9, gen_loss = 0.8455729505472016, disc_loss = 0.07112892092156567
Trained batch 684 in epoch 9, gen_loss = 0.8451494418791611, disc_loss = 0.07122096630615475
Trained batch 685 in epoch 9, gen_loss = 0.8457765070064422, disc_loss = 0.07144048890647405
Trained batch 686 in epoch 9, gen_loss = 0.8456571031866116, disc_loss = 0.07142232497001753
Trained batch 687 in epoch 9, gen_loss = 0.8455190529483695, disc_loss = 0.07135540920006501
Trained batch 688 in epoch 9, gen_loss = 0.8455114742667997, disc_loss = 0.07133887006924183
Trained batch 689 in epoch 9, gen_loss = 0.8459896174893863, disc_loss = 0.0712891966374456
Trained batch 690 in epoch 9, gen_loss = 0.8459173113150811, disc_loss = 0.07126059780482273
Trained batch 691 in epoch 9, gen_loss = 0.846036110482464, disc_loss = 0.07116988795739464
Trained batch 692 in epoch 9, gen_loss = 0.8460626758710302, disc_loss = 0.07109117041601333
Trained batch 693 in epoch 9, gen_loss = 0.8457408672794485, disc_loss = 0.0711398943963458
Trained batch 694 in epoch 9, gen_loss = 0.8460367022658424, disc_loss = 0.07109371435781606
Trained batch 695 in epoch 9, gen_loss = 0.8465285638625595, disc_loss = 0.0710803966075396
Trained batch 696 in epoch 9, gen_loss = 0.8464947200060917, disc_loss = 0.07104616002627305
Trained batch 697 in epoch 9, gen_loss = 0.8462651170427273, disc_loss = 0.07110890725568833
Trained batch 698 in epoch 9, gen_loss = 0.8461637580514124, disc_loss = 0.07108572700749737
Trained batch 699 in epoch 9, gen_loss = 0.8462794549124582, disc_loss = 0.07102359031194022
Trained batch 700 in epoch 9, gen_loss = 0.8464985139529817, disc_loss = 0.07099492129698375
Trained batch 701 in epoch 9, gen_loss = 0.8465595859238225, disc_loss = 0.07091891988740433
Trained batch 702 in epoch 9, gen_loss = 0.8463908833256826, disc_loss = 0.07089482858024569
Trained batch 703 in epoch 9, gen_loss = 0.8463600761341777, disc_loss = 0.0708696512023876
Trained batch 704 in epoch 9, gen_loss = 0.8469258679565809, disc_loss = 0.07088554454240815
Trained batch 705 in epoch 9, gen_loss = 0.8470396069392941, disc_loss = 0.07084529937400612
Trained batch 706 in epoch 9, gen_loss = 0.8469742527271092, disc_loss = 0.07088270673562563
Trained batch 707 in epoch 9, gen_loss = 0.8467813491989664, disc_loss = 0.07085616351762987
Trained batch 708 in epoch 9, gen_loss = 0.846958777043648, disc_loss = 0.0707734248696791
Trained batch 709 in epoch 9, gen_loss = 0.8469342604489394, disc_loss = 0.07076378482275865
Trained batch 710 in epoch 9, gen_loss = 0.8470422210572641, disc_loss = 0.07099655015674405
Trained batch 711 in epoch 9, gen_loss = 0.8470367566588219, disc_loss = 0.0709672008112617
Trained batch 712 in epoch 9, gen_loss = 0.8469367013071228, disc_loss = 0.07098743543394569
Trained batch 713 in epoch 9, gen_loss = 0.8464366966435889, disc_loss = 0.07107358718296143
Trained batch 714 in epoch 9, gen_loss = 0.8470206524942304, disc_loss = 0.07118817449293353
Trained batch 715 in epoch 9, gen_loss = 0.8468968906549103, disc_loss = 0.07119291554876296
Trained batch 716 in epoch 9, gen_loss = 0.8467170288539498, disc_loss = 0.07114908255823736
Trained batch 717 in epoch 9, gen_loss = 0.8464429118673117, disc_loss = 0.07119935337703125
Trained batch 718 in epoch 9, gen_loss = 0.846786260521959, disc_loss = 0.07137555694039159
Trained batch 719 in epoch 9, gen_loss = 0.8464582450687885, disc_loss = 0.0713630724258514
Trained batch 720 in epoch 9, gen_loss = 0.8462094083407715, disc_loss = 0.07139477266796998
Trained batch 721 in epoch 9, gen_loss = 0.8461929340111581, disc_loss = 0.07141046337215771
Trained batch 722 in epoch 9, gen_loss = 0.8462820285583432, disc_loss = 0.07133473414427924
Trained batch 723 in epoch 9, gen_loss = 0.8468920027024179, disc_loss = 0.07132461511411638
Trained batch 724 in epoch 9, gen_loss = 0.8467240693651397, disc_loss = 0.07135443544336434
Trained batch 725 in epoch 9, gen_loss = 0.8468670025673123, disc_loss = 0.07128891245957167
Trained batch 726 in epoch 9, gen_loss = 0.8467272695517769, disc_loss = 0.0712377333980274
Trained batch 727 in epoch 9, gen_loss = 0.8464843038837988, disc_loss = 0.07125427200110977
Trained batch 728 in epoch 9, gen_loss = 0.8465511147213898, disc_loss = 0.07125272449305273
Trained batch 729 in epoch 9, gen_loss = 0.8468467564615485, disc_loss = 0.07126299881516662
Trained batch 730 in epoch 9, gen_loss = 0.8464486942245598, disc_loss = 0.07131902733626591
Trained batch 731 in epoch 9, gen_loss = 0.8462446430504648, disc_loss = 0.07127222233792879
Trained batch 732 in epoch 9, gen_loss = 0.8463752564922036, disc_loss = 0.07138068923449695
Trained batch 733 in epoch 9, gen_loss = 0.8465633526322627, disc_loss = 0.07135302633585089
Trained batch 734 in epoch 9, gen_loss = 0.8461828407787141, disc_loss = 0.0714836838826233
Trained batch 735 in epoch 9, gen_loss = 0.8458401410961929, disc_loss = 0.07155429340301729
Trained batch 736 in epoch 9, gen_loss = 0.8459801192684768, disc_loss = 0.07161528108896766
Trained batch 737 in epoch 9, gen_loss = 0.8461375831750028, disc_loss = 0.07155843845096627
Trained batch 738 in epoch 9, gen_loss = 0.8461887851780903, disc_loss = 0.07149195243605741
Trained batch 739 in epoch 9, gen_loss = 0.8461033883932475, disc_loss = 0.071430555670648
Trained batch 740 in epoch 9, gen_loss = 0.8458485379714554, disc_loss = 0.07149348554783344
Trained batch 741 in epoch 9, gen_loss = 0.8461962769616325, disc_loss = 0.07142241509766832
Trained batch 742 in epoch 9, gen_loss = 0.8464321934519032, disc_loss = 0.07151949563857123
Trained batch 743 in epoch 9, gen_loss = 0.8461645642115224, disc_loss = 0.0715449890597493
Trained batch 744 in epoch 9, gen_loss = 0.8461207958675871, disc_loss = 0.07148042354957769
Trained batch 745 in epoch 9, gen_loss = 0.8463666566095787, disc_loss = 0.07140710746405032
Trained batch 746 in epoch 9, gen_loss = 0.8460878970792175, disc_loss = 0.07139037302389761
Trained batch 747 in epoch 9, gen_loss = 0.8461557960605877, disc_loss = 0.07134211336556363
Trained batch 748 in epoch 9, gen_loss = 0.8460688171622273, disc_loss = 0.07128364129989186
Trained batch 749 in epoch 9, gen_loss = 0.8463386062781016, disc_loss = 0.07122222489366929
Trained batch 750 in epoch 9, gen_loss = 0.8462547007476918, disc_loss = 0.07117163900598467
Trained batch 751 in epoch 9, gen_loss = 0.8460281541214344, disc_loss = 0.07116855057501333
Trained batch 752 in epoch 9, gen_loss = 0.846067703656783, disc_loss = 0.07114537691284381
Trained batch 753 in epoch 9, gen_loss = 0.8457468080109564, disc_loss = 0.07113523744491351
Trained batch 754 in epoch 9, gen_loss = 0.8460592479105816, disc_loss = 0.07118472995495559
Trained batch 755 in epoch 9, gen_loss = 0.8460469708713905, disc_loss = 0.07113146514350933
Trained batch 756 in epoch 9, gen_loss = 0.8456446775671985, disc_loss = 0.07120920342234513
Trained batch 757 in epoch 9, gen_loss = 0.845640203647689, disc_loss = 0.07119066547848146
Trained batch 758 in epoch 9, gen_loss = 0.8457288023511411, disc_loss = 0.07119891927510068
Trained batch 759 in epoch 9, gen_loss = 0.8457831679990417, disc_loss = 0.07112229610303122
Trained batch 760 in epoch 9, gen_loss = 0.8454836117453707, disc_loss = 0.07118538993994525
Trained batch 761 in epoch 9, gen_loss = 0.8460327174876305, disc_loss = 0.07120753078430578
Trained batch 762 in epoch 9, gen_loss = 0.8464064492623116, disc_loss = 0.07118958631484021
Trained batch 763 in epoch 9, gen_loss = 0.8461748108033734, disc_loss = 0.07118808930856785
Trained batch 764 in epoch 9, gen_loss = 0.8461472048478968, disc_loss = 0.07117575104378797
Trained batch 765 in epoch 9, gen_loss = 0.8464125746535259, disc_loss = 0.07109884030912704
Trained batch 766 in epoch 9, gen_loss = 0.8466904648279739, disc_loss = 0.07102085098337668
Trained batch 767 in epoch 9, gen_loss = 0.8466240675188601, disc_loss = 0.07095545996344299
Trained batch 768 in epoch 9, gen_loss = 0.8465384075173475, disc_loss = 0.07090633393898703
Trained batch 769 in epoch 9, gen_loss = 0.8463387470740776, disc_loss = 0.07091718944418546
Trained batch 770 in epoch 9, gen_loss = 0.8464743600899762, disc_loss = 0.07110381827372018
Trained batch 771 in epoch 9, gen_loss = 0.8464800871406812, disc_loss = 0.07106247250294709
Trained batch 772 in epoch 9, gen_loss = 0.8463820251425365, disc_loss = 0.07100102526014056
Trained batch 773 in epoch 9, gen_loss = 0.8461013275369501, disc_loss = 0.0710477739252458
Trained batch 774 in epoch 9, gen_loss = 0.8463436127478077, disc_loss = 0.07106192911704702
Trained batch 775 in epoch 9, gen_loss = 0.8466060712319059, disc_loss = 0.07105592670778446
Trained batch 776 in epoch 9, gen_loss = 0.8464660913787754, disc_loss = 0.07104032602583081
Trained batch 777 in epoch 9, gen_loss = 0.8466435486216165, disc_loss = 0.07109640476324985
Trained batch 778 in epoch 9, gen_loss = 0.8462157736081674, disc_loss = 0.07126207964253325
Trained batch 779 in epoch 9, gen_loss = 0.8463233085014881, disc_loss = 0.07120477797296376
Trained batch 780 in epoch 9, gen_loss = 0.8467200015326926, disc_loss = 0.07182782754259096
Trained batch 781 in epoch 9, gen_loss = 0.8463671548134836, disc_loss = 0.07193777945888279
Trained batch 782 in epoch 9, gen_loss = 0.8461435433396283, disc_loss = 0.0719233713128234
Trained batch 783 in epoch 9, gen_loss = 0.8465960291879517, disc_loss = 0.07192169733188704
Trained batch 784 in epoch 9, gen_loss = 0.8463274290607233, disc_loss = 0.07190316578456361
Trained batch 785 in epoch 9, gen_loss = 0.8464633021645873, disc_loss = 0.07185524514741229
Trained batch 786 in epoch 9, gen_loss = 0.8463232704311647, disc_loss = 0.07182804602429063
Trained batch 787 in epoch 9, gen_loss = 0.8464978015816151, disc_loss = 0.07183201825080751
Trained batch 788 in epoch 9, gen_loss = 0.8462028466401142, disc_loss = 0.07183011704689914
Trained batch 789 in epoch 9, gen_loss = 0.846195306506338, disc_loss = 0.07177224688679923
Testing Epoch 9
Training Epoch 10
Trained batch 0 in epoch 10, gen_loss = 0.8048818111419678, disc_loss = 0.019570818170905113
Trained batch 1 in epoch 10, gen_loss = 0.9547041654586792, disc_loss = 0.04156869184225798
Trained batch 2 in epoch 10, gen_loss = 0.9102075099945068, disc_loss = 0.0434955737243096
Trained batch 3 in epoch 10, gen_loss = 0.8711987137794495, disc_loss = 0.03819755092263222
Trained batch 4 in epoch 10, gen_loss = 0.8005106449127197, disc_loss = 0.05045811086893082
Trained batch 5 in epoch 10, gen_loss = 0.8210916121800741, disc_loss = 0.05083402867118517
Trained batch 6 in epoch 10, gen_loss = 0.7974958760397775, disc_loss = 0.057285356734480174
Trained batch 7 in epoch 10, gen_loss = 0.7900956347584724, disc_loss = 0.055370575748384
Trained batch 8 in epoch 10, gen_loss = 0.8632092807028029, disc_loss = 0.07417493644687864
Trained batch 9 in epoch 10, gen_loss = 0.8455821573734283, disc_loss = 0.07108553647994995
Trained batch 10 in epoch 10, gen_loss = 0.814452897418629, disc_loss = 0.07969578152353113
Trained batch 11 in epoch 10, gen_loss = 0.8154732982317606, disc_loss = 0.08246397227048874
Trained batch 12 in epoch 10, gen_loss = 0.8259623325788058, disc_loss = 0.07778092187184554
Trained batch 13 in epoch 10, gen_loss = 0.8299950063228607, disc_loss = 0.08079877815076283
Trained batch 14 in epoch 10, gen_loss = 0.8186655799547832, disc_loss = 0.08081655452648799
Trained batch 15 in epoch 10, gen_loss = 0.8179398514330387, disc_loss = 0.0768154039978981
Trained batch 16 in epoch 10, gen_loss = 0.8163088770473704, disc_loss = 0.07640984303811017
Trained batch 17 in epoch 10, gen_loss = 0.828319337632921, disc_loss = 0.07308495996726884
Trained batch 18 in epoch 10, gen_loss = 0.8104109042569211, disc_loss = 0.07459997542594608
Trained batch 19 in epoch 10, gen_loss = 0.809010636806488, disc_loss = 0.07249090299010277
Trained batch 20 in epoch 10, gen_loss = 0.834315612202599, disc_loss = 0.0724468653400739
Trained batch 21 in epoch 10, gen_loss = 0.8400409004905007, disc_loss = 0.0701331922953779
Trained batch 22 in epoch 10, gen_loss = 0.8334941915843798, disc_loss = 0.0688471507443034
Trained batch 23 in epoch 10, gen_loss = 0.828296368320783, disc_loss = 0.06736329104751348
Trained batch 24 in epoch 10, gen_loss = 0.83033118724823, disc_loss = 0.06525690242648124
Trained batch 25 in epoch 10, gen_loss = 0.8412817670748785, disc_loss = 0.06339216533188637
Trained batch 26 in epoch 10, gen_loss = 0.8403850087413082, disc_loss = 0.062321724853029954
Trained batch 27 in epoch 10, gen_loss = 0.8400737409080777, disc_loss = 0.0609812479732292
Trained batch 28 in epoch 10, gen_loss = 0.8394352238753746, disc_loss = 0.059534289970480166
Trained batch 29 in epoch 10, gen_loss = 0.844219704469045, disc_loss = 0.05825606236855189
Trained batch 30 in epoch 10, gen_loss = 0.8409021458318157, disc_loss = 0.062121657113875114
Trained batch 31 in epoch 10, gen_loss = 0.8352611269801855, disc_loss = 0.0635229938197881
Trained batch 32 in epoch 10, gen_loss = 0.8296835404453855, disc_loss = 0.06408824636177583
Trained batch 33 in epoch 10, gen_loss = 0.8367277331211987, disc_loss = 0.0700874541173963
Trained batch 34 in epoch 10, gen_loss = 0.8318585923739842, disc_loss = 0.07016459022249494
Trained batch 35 in epoch 10, gen_loss = 0.8311761816342672, disc_loss = 0.06888595254470904
Trained batch 36 in epoch 10, gen_loss = 0.8403261577760851, disc_loss = 0.06731366454246077
Trained batch 37 in epoch 10, gen_loss = 0.8370135724544525, disc_loss = 0.06780712019750162
Trained batch 38 in epoch 10, gen_loss = 0.8330500080035284, disc_loss = 0.07032230255217889
Trained batch 39 in epoch 10, gen_loss = 0.830371905863285, disc_loss = 0.07001632030587643
Trained batch 40 in epoch 10, gen_loss = 0.8289522063441392, disc_loss = 0.0701600430169847
Trained batch 41 in epoch 10, gen_loss = 0.8283039828141531, disc_loss = 0.07076525481949959
Trained batch 42 in epoch 10, gen_loss = 0.8236087934915409, disc_loss = 0.0716009275814475
Trained batch 43 in epoch 10, gen_loss = 0.8206185508858074, disc_loss = 0.07265339967456054
Trained batch 44 in epoch 10, gen_loss = 0.8299708498848809, disc_loss = 0.07501309255345
Trained batch 45 in epoch 10, gen_loss = 0.8328390082587367, disc_loss = 0.07483795922978417
Trained batch 46 in epoch 10, gen_loss = 0.832310566242705, disc_loss = 0.07403936591791979
Trained batch 47 in epoch 10, gen_loss = 0.8233456754436096, disc_loss = 0.07862724912896131
Trained batch 48 in epoch 10, gen_loss = 0.8284829629927265, disc_loss = 0.07779902324308546
Trained batch 49 in epoch 10, gen_loss = 0.8330702203512191, disc_loss = 0.07787674320861697
Trained batch 50 in epoch 10, gen_loss = 0.8310575666380864, disc_loss = 0.07846190311087697
Trained batch 51 in epoch 10, gen_loss = 0.8271785189325993, disc_loss = 0.0794803922673544
Trained batch 52 in epoch 10, gen_loss = 0.826571560693237, disc_loss = 0.07939878933764291
Trained batch 53 in epoch 10, gen_loss = 0.8303979916705025, disc_loss = 0.0784923108122139
Trained batch 54 in epoch 10, gen_loss = 0.8318611627275293, disc_loss = 0.07725715601647443
Trained batch 55 in epoch 10, gen_loss = 0.8280445853514331, disc_loss = 0.07758190580976329
Trained batch 56 in epoch 10, gen_loss = 0.8274772758023781, disc_loss = 0.07777025176440938
Trained batch 57 in epoch 10, gen_loss = 0.8285075739539903, disc_loss = 0.07671817201029124
Trained batch 58 in epoch 10, gen_loss = 0.8274014203225152, disc_loss = 0.07683984242316524
Trained batch 59 in epoch 10, gen_loss = 0.8262897943456967, disc_loss = 0.07650166925353309
Trained batch 60 in epoch 10, gen_loss = 0.8278355339511496, disc_loss = 0.07547846670094573
Trained batch 61 in epoch 10, gen_loss = 0.8292981371764214, disc_loss = 0.07450500914766904
Trained batch 62 in epoch 10, gen_loss = 0.83258532578983, disc_loss = 0.07512876808288552
Trained batch 63 in epoch 10, gen_loss = 0.8339225207455456, disc_loss = 0.0742409337835852
Trained batch 64 in epoch 10, gen_loss = 0.8321221282848945, disc_loss = 0.0734859340179425
Trained batch 65 in epoch 10, gen_loss = 0.834778397823825, disc_loss = 0.07270340048566912
Trained batch 66 in epoch 10, gen_loss = 0.835626988713421, disc_loss = 0.07317796963920344
Trained batch 67 in epoch 10, gen_loss = 0.8353178400327178, disc_loss = 0.07337576800080783
Trained batch 68 in epoch 10, gen_loss = 0.8333573311135389, disc_loss = 0.07308032290767068
Trained batch 69 in epoch 10, gen_loss = 0.8333418569394521, disc_loss = 0.0740798096837742
Trained batch 70 in epoch 10, gen_loss = 0.8340245321602888, disc_loss = 0.07358912832405366
Trained batch 71 in epoch 10, gen_loss = 0.8329031413627995, disc_loss = 0.07336485740314755
Trained batch 72 in epoch 10, gen_loss = 0.8342792036598676, disc_loss = 0.07272195530264344
Trained batch 73 in epoch 10, gen_loss = 0.8360064186759897, disc_loss = 0.0718574271461851
Trained batch 74 in epoch 10, gen_loss = 0.8355326918760936, disc_loss = 0.07110826941827933
Trained batch 75 in epoch 10, gen_loss = 0.835183758092554, disc_loss = 0.071404666517322
Trained batch 76 in epoch 10, gen_loss = 0.8350687595930967, disc_loss = 0.07077757542493282
Trained batch 77 in epoch 10, gen_loss = 0.8334564180710377, disc_loss = 0.07075895189952391
Trained batch 78 in epoch 10, gen_loss = 0.8348144500315944, disc_loss = 0.07082727638698078
Trained batch 79 in epoch 10, gen_loss = 0.8318589787930251, disc_loss = 0.07133161064703017
Trained batch 80 in epoch 10, gen_loss = 0.8359268620426272, disc_loss = 0.07145512924978027
Trained batch 81 in epoch 10, gen_loss = 0.839286827096125, disc_loss = 0.07083788371031605
Trained batch 82 in epoch 10, gen_loss = 0.8400064904287637, disc_loss = 0.07013735625084984
Trained batch 83 in epoch 10, gen_loss = 0.8389084009187562, disc_loss = 0.06958404667897239
Trained batch 84 in epoch 10, gen_loss = 0.8395787880701178, disc_loss = 0.06904697371098925
Trained batch 85 in epoch 10, gen_loss = 0.8405148937951686, disc_loss = 0.06906566756972393
Trained batch 86 in epoch 10, gen_loss = 0.8382634434891844, disc_loss = 0.06891917973628332
Trained batch 87 in epoch 10, gen_loss = 0.8366856151683764, disc_loss = 0.0691690939923071
Trained batch 88 in epoch 10, gen_loss = 0.8379551878805911, disc_loss = 0.06956453768934091
Trained batch 89 in epoch 10, gen_loss = 0.8385129541158676, disc_loss = 0.06915022922265861
Trained batch 90 in epoch 10, gen_loss = 0.8401040516711853, disc_loss = 0.0685199339167921
Trained batch 91 in epoch 10, gen_loss = 0.8356745197721149, disc_loss = 0.06963391347950243
Trained batch 92 in epoch 10, gen_loss = 0.8387631043311088, disc_loss = 0.06976304376517893
Trained batch 93 in epoch 10, gen_loss = 0.8382260304816226, disc_loss = 0.06933841766155463
Trained batch 94 in epoch 10, gen_loss = 0.8364511496142337, disc_loss = 0.06948291399565182
Trained batch 95 in epoch 10, gen_loss = 0.83802047620217, disc_loss = 0.06887047664107133
Trained batch 96 in epoch 10, gen_loss = 0.8373436374762624, disc_loss = 0.06913095493752931
Trained batch 97 in epoch 10, gen_loss = 0.8368499242529577, disc_loss = 0.06875674004609487
Trained batch 98 in epoch 10, gen_loss = 0.836867838194876, disc_loss = 0.06838419751235933
Trained batch 99 in epoch 10, gen_loss = 0.8369157695770264, disc_loss = 0.06856633190065622
Trained batch 100 in epoch 10, gen_loss = 0.8348077358585773, disc_loss = 0.06880685757144843
Trained batch 101 in epoch 10, gen_loss = 0.83577626359229, disc_loss = 0.0683704289954667
Trained batch 102 in epoch 10, gen_loss = 0.8388410332133469, disc_loss = 0.06837000477227193
Trained batch 103 in epoch 10, gen_loss = 0.8378922732976767, disc_loss = 0.06842541769863321
Trained batch 104 in epoch 10, gen_loss = 0.8370709640639169, disc_loss = 0.06807643427025704
Trained batch 105 in epoch 10, gen_loss = 0.8365177394084211, disc_loss = 0.06762653468001001
Trained batch 106 in epoch 10, gen_loss = 0.835620089669094, disc_loss = 0.06760984580859403
Trained batch 107 in epoch 10, gen_loss = 0.8378490811144864, disc_loss = 0.06767123632339968
Trained batch 108 in epoch 10, gen_loss = 0.8366367909886422, disc_loss = 0.06751380811248897
Trained batch 109 in epoch 10, gen_loss = 0.8365720846436241, disc_loss = 0.06747170928865671
Trained batch 110 in epoch 10, gen_loss = 0.8355682374120833, disc_loss = 0.06744741452102726
Trained batch 111 in epoch 10, gen_loss = 0.8345643441591944, disc_loss = 0.06708969975755151
Trained batch 112 in epoch 10, gen_loss = 0.8372003093229986, disc_loss = 0.06678463658730013
Trained batch 113 in epoch 10, gen_loss = 0.8359839027388054, disc_loss = 0.06668579403572437
Trained batch 114 in epoch 10, gen_loss = 0.8352792745051176, disc_loss = 0.06662322368634783
Trained batch 115 in epoch 10, gen_loss = 0.8356474766443516, disc_loss = 0.06615857609772477
Trained batch 116 in epoch 10, gen_loss = 0.834159696713472, disc_loss = 0.06658932576194787
Trained batch 117 in epoch 10, gen_loss = 0.8367806152772095, disc_loss = 0.0663945881681422
Trained batch 118 in epoch 10, gen_loss = 0.8411259215419032, disc_loss = 0.06632148408714462
Trained batch 119 in epoch 10, gen_loss = 0.839808810253938, disc_loss = 0.06668868819251657
Trained batch 120 in epoch 10, gen_loss = 0.8402529260343756, disc_loss = 0.06640639263859466
Trained batch 121 in epoch 10, gen_loss = 0.8406043653605414, disc_loss = 0.06608879586040485
Trained batch 122 in epoch 10, gen_loss = 0.8387987419841735, disc_loss = 0.066362618324839
Trained batch 123 in epoch 10, gen_loss = 0.8419286570241374, disc_loss = 0.06677632275668363
Trained batch 124 in epoch 10, gen_loss = 0.8400959053039551, disc_loss = 0.06690730620920658
Trained batch 125 in epoch 10, gen_loss = 0.8402330402343993, disc_loss = 0.06653328194090771
Trained batch 126 in epoch 10, gen_loss = 0.8410543860412958, disc_loss = 0.0673497901334772
Trained batch 127 in epoch 10, gen_loss = 0.8401113683357835, disc_loss = 0.06749471895454917
Trained batch 128 in epoch 10, gen_loss = 0.8385007547777753, disc_loss = 0.06787904584419358
Trained batch 129 in epoch 10, gen_loss = 0.8376293503321134, disc_loss = 0.06764264197017138
Trained batch 130 in epoch 10, gen_loss = 0.8404051229243971, disc_loss = 0.06747986613737263
Trained batch 131 in epoch 10, gen_loss = 0.8420303156881621, disc_loss = 0.06716460930747968
Trained batch 132 in epoch 10, gen_loss = 0.8413812558453783, disc_loss = 0.0672937141297231
Trained batch 133 in epoch 10, gen_loss = 0.8423525335183785, disc_loss = 0.0671995702658349
Trained batch 134 in epoch 10, gen_loss = 0.8428077755150971, disc_loss = 0.06721818878970764
Trained batch 135 in epoch 10, gen_loss = 0.8414888009428978, disc_loss = 0.06772798629861106
Trained batch 136 in epoch 10, gen_loss = 0.8425622634644055, disc_loss = 0.06759586066932138
Trained batch 137 in epoch 10, gen_loss = 0.8406667838925901, disc_loss = 0.06777362208273532
Trained batch 138 in epoch 10, gen_loss = 0.8420917241693401, disc_loss = 0.06758261904817262
Trained batch 139 in epoch 10, gen_loss = 0.8431435661656516, disc_loss = 0.0673297692223319
Trained batch 140 in epoch 10, gen_loss = 0.8421249719376259, disc_loss = 0.06744555205582305
Trained batch 141 in epoch 10, gen_loss = 0.8434124303535676, disc_loss = 0.06710494649399754
Trained batch 142 in epoch 10, gen_loss = 0.8443327458588393, disc_loss = 0.06674265211539251
Trained batch 143 in epoch 10, gen_loss = 0.8435424280663332, disc_loss = 0.0665965847696902
Trained batch 144 in epoch 10, gen_loss = 0.8441280299219592, disc_loss = 0.06624639053539984
Trained batch 145 in epoch 10, gen_loss = 0.8432054482910731, disc_loss = 0.06602856048625218
Trained batch 146 in epoch 10, gen_loss = 0.844559963463115, disc_loss = 0.06636768621297515
Trained batch 147 in epoch 10, gen_loss = 0.8433984509996466, disc_loss = 0.06635878191052659
Trained batch 148 in epoch 10, gen_loss = 0.8439235415234662, disc_loss = 0.06600000403646454
Trained batch 149 in epoch 10, gen_loss = 0.8452578703562419, disc_loss = 0.06565608426307638
Trained batch 150 in epoch 10, gen_loss = 0.8457146306701054, disc_loss = 0.06541167771357377
Trained batch 151 in epoch 10, gen_loss = 0.8461053453777966, disc_loss = 0.06511678895300352
Trained batch 152 in epoch 10, gen_loss = 0.8473896166078405, disc_loss = 0.06477350938237375
Trained batch 153 in epoch 10, gen_loss = 0.8465303689628453, disc_loss = 0.06455176359332808
Trained batch 154 in epoch 10, gen_loss = 0.8462810001065654, disc_loss = 0.06457462038604482
Trained batch 155 in epoch 10, gen_loss = 0.8454969876851791, disc_loss = 0.06474163031611496
Trained batch 156 in epoch 10, gen_loss = 0.8445502565165234, disc_loss = 0.06456926364783838
Trained batch 157 in epoch 10, gen_loss = 0.8445308646069297, disc_loss = 0.06442652552541864
Trained batch 158 in epoch 10, gen_loss = 0.8468141833191398, disc_loss = 0.06416882313905084
Trained batch 159 in epoch 10, gen_loss = 0.8477301172912121, disc_loss = 0.06390484268194996
Trained batch 160 in epoch 10, gen_loss = 0.8496874881827313, disc_loss = 0.06360773387602213
Trained batch 161 in epoch 10, gen_loss = 0.8503374806892725, disc_loss = 0.06342197261911667
Trained batch 162 in epoch 10, gen_loss = 0.8498730875231737, disc_loss = 0.06327919044354759
Trained batch 163 in epoch 10, gen_loss = 0.8496664188257078, disc_loss = 0.06310746195816958
Trained batch 164 in epoch 10, gen_loss = 0.850366519797932, disc_loss = 0.06281393608360579
Trained batch 165 in epoch 10, gen_loss = 0.8531410791069628, disc_loss = 0.06366278774228441
Trained batch 166 in epoch 10, gen_loss = 0.8515303202731881, disc_loss = 0.06467590382891501
Trained batch 167 in epoch 10, gen_loss = 0.8520358697999091, disc_loss = 0.06438810248593134
Trained batch 168 in epoch 10, gen_loss = 0.8523285149117193, disc_loss = 0.06413379204652365
Trained batch 169 in epoch 10, gen_loss = 0.852979076609892, disc_loss = 0.06402176135383984
Trained batch 170 in epoch 10, gen_loss = 0.8527855545456646, disc_loss = 0.06378387033460084
Trained batch 171 in epoch 10, gen_loss = 0.8515066802501678, disc_loss = 0.06396981308150083
Trained batch 172 in epoch 10, gen_loss = 0.8531645398608522, disc_loss = 0.064261578335669
Trained batch 173 in epoch 10, gen_loss = 0.8529354820306274, disc_loss = 0.06396440724874365
Trained batch 174 in epoch 10, gen_loss = 0.8522917740685599, disc_loss = 0.06378681578806468
Trained batch 175 in epoch 10, gen_loss = 0.8527367954904382, disc_loss = 0.06371531275693666
Trained batch 176 in epoch 10, gen_loss = 0.8518238303351537, disc_loss = 0.06367785445714401
Trained batch 177 in epoch 10, gen_loss = 0.8516787062869983, disc_loss = 0.06355999816167221
Trained batch 178 in epoch 10, gen_loss = 0.8534620174482548, disc_loss = 0.06360093720631893
Trained batch 179 in epoch 10, gen_loss = 0.8543935722774929, disc_loss = 0.06345632328755325
Trained batch 180 in epoch 10, gen_loss = 0.8527567788382262, disc_loss = 0.06382950074270943
Trained batch 181 in epoch 10, gen_loss = 0.8517097503274351, disc_loss = 0.0641212940297939
Trained batch 182 in epoch 10, gen_loss = 0.8527838617074684, disc_loss = 0.06436391358004241
Trained batch 183 in epoch 10, gen_loss = 0.8531734671281732, disc_loss = 0.06429037540827108
Trained batch 184 in epoch 10, gen_loss = 0.8533355864318641, disc_loss = 0.06431895740128853
Trained batch 185 in epoch 10, gen_loss = 0.8537668393504235, disc_loss = 0.06464241224751678
Trained batch 186 in epoch 10, gen_loss = 0.8543998022130467, disc_loss = 0.06441544476438334
Trained batch 187 in epoch 10, gen_loss = 0.8534029893418575, disc_loss = 0.06464727292273273
Trained batch 188 in epoch 10, gen_loss = 0.8538794157997011, disc_loss = 0.0644592635294117
Trained batch 189 in epoch 10, gen_loss = 0.8553290122433712, disc_loss = 0.06423475602151532
Trained batch 190 in epoch 10, gen_loss = 0.856026305578142, disc_loss = 0.06405089382101728
Trained batch 191 in epoch 10, gen_loss = 0.8560078665614128, disc_loss = 0.06386072249733843
Trained batch 192 in epoch 10, gen_loss = 0.8560408245714217, disc_loss = 0.06363251377765687
Trained batch 193 in epoch 10, gen_loss = 0.8565743998768404, disc_loss = 0.06336024458299286
Trained batch 194 in epoch 10, gen_loss = 0.8570387274791033, disc_loss = 0.06308246900637944
Trained batch 195 in epoch 10, gen_loss = 0.8562128857082251, disc_loss = 0.06311678156560781
Trained batch 196 in epoch 10, gen_loss = 0.8568263026663494, disc_loss = 0.0629792328602469
Trained batch 197 in epoch 10, gen_loss = 0.8573150520372872, disc_loss = 0.06271253751985954
Trained batch 198 in epoch 10, gen_loss = 0.856529613236087, disc_loss = 0.06257460962737625
Trained batch 199 in epoch 10, gen_loss = 0.8564646941423416, disc_loss = 0.06252339404076337
Trained batch 200 in epoch 10, gen_loss = 0.8569035616087083, disc_loss = 0.06233003124854161
Trained batch 201 in epoch 10, gen_loss = 0.856580500850583, disc_loss = 0.06234994609056428
Trained batch 202 in epoch 10, gen_loss = 0.8562307827578389, disc_loss = 0.06214882380196026
Trained batch 203 in epoch 10, gen_loss = 0.8574736948106804, disc_loss = 0.06359754267203457
Trained batch 204 in epoch 10, gen_loss = 0.8579665407901857, disc_loss = 0.06352664766515173
Trained batch 205 in epoch 10, gen_loss = 0.8563360835163338, disc_loss = 0.06429141886459971
Trained batch 206 in epoch 10, gen_loss = 0.8560531067387493, disc_loss = 0.06409377561531206
Trained batch 207 in epoch 10, gen_loss = 0.8567533816855687, disc_loss = 0.06415872379707602
Trained batch 208 in epoch 10, gen_loss = 0.8571024788053412, disc_loss = 0.06411632506898715
Trained batch 209 in epoch 10, gen_loss = 0.8570194888682593, disc_loss = 0.06390592594231878
Trained batch 210 in epoch 10, gen_loss = 0.8563981581638209, disc_loss = 0.06376356416121479
Trained batch 211 in epoch 10, gen_loss = 0.8565779676977193, disc_loss = 0.06350752309773047
Trained batch 212 in epoch 10, gen_loss = 0.8558023574766419, disc_loss = 0.0636087323280987
Trained batch 213 in epoch 10, gen_loss = 0.8550123550067438, disc_loss = 0.06358394085072747
Trained batch 214 in epoch 10, gen_loss = 0.8571424700493037, disc_loss = 0.06434753706115623
Trained batch 215 in epoch 10, gen_loss = 0.8553349128751843, disc_loss = 0.06538149717056917
Trained batch 216 in epoch 10, gen_loss = 0.8545043810446691, disc_loss = 0.06530214338842351
Trained batch 217 in epoch 10, gen_loss = 0.8554032211183408, disc_loss = 0.06543186786285507
Trained batch 218 in epoch 10, gen_loss = 0.8547565206272961, disc_loss = 0.06550343355937907
Trained batch 219 in epoch 10, gen_loss = 0.8543859935619614, disc_loss = 0.06538039294325493
Trained batch 220 in epoch 10, gen_loss = 0.8543834644475135, disc_loss = 0.06542306586392055
Trained batch 221 in epoch 10, gen_loss = 0.8536666761915963, disc_loss = 0.06554824218724493
Trained batch 222 in epoch 10, gen_loss = 0.8525185952539401, disc_loss = 0.06574505628525142
Trained batch 223 in epoch 10, gen_loss = 0.8526738071814179, disc_loss = 0.0655062448058743
Trained batch 224 in epoch 10, gen_loss = 0.8531549640496572, disc_loss = 0.06548659653713305
Trained batch 225 in epoch 10, gen_loss = 0.8538285753632013, disc_loss = 0.06524023323410512
Trained batch 226 in epoch 10, gen_loss = 0.8537359102444502, disc_loss = 0.06509967227486918
Trained batch 227 in epoch 10, gen_loss = 0.8531641208550387, disc_loss = 0.06511207412225767
Trained batch 228 in epoch 10, gen_loss = 0.8524411688985782, disc_loss = 0.0650167160394996
Trained batch 229 in epoch 10, gen_loss = 0.8533692998730618, disc_loss = 0.0650633823329016
Trained batch 230 in epoch 10, gen_loss = 0.8533376136641482, disc_loss = 0.06507750665486763
Trained batch 231 in epoch 10, gen_loss = 0.8519870095468801, disc_loss = 0.06546649314736112
Trained batch 232 in epoch 10, gen_loss = 0.8534773236436394, disc_loss = 0.06530404981833288
Trained batch 233 in epoch 10, gen_loss = 0.8545990022074463, disc_loss = 0.06522451118669575
Trained batch 234 in epoch 10, gen_loss = 0.8550658075099296, disc_loss = 0.06499340571859416
Trained batch 235 in epoch 10, gen_loss = 0.8547654143076832, disc_loss = 0.06513098895281427
Trained batch 236 in epoch 10, gen_loss = 0.855474286064317, disc_loss = 0.06513341402689993
Trained batch 237 in epoch 10, gen_loss = 0.8567317905796676, disc_loss = 0.06492772799752214
Trained batch 238 in epoch 10, gen_loss = 0.8572583032701804, disc_loss = 0.06476572838272884
Trained batch 239 in epoch 10, gen_loss = 0.8561251785606145, disc_loss = 0.06477970697839434
Trained batch 240 in epoch 10, gen_loss = 0.8564704732034216, disc_loss = 0.06462165112394638
Trained batch 241 in epoch 10, gen_loss = 0.8568587176317026, disc_loss = 0.06450163916692384
Trained batch 242 in epoch 10, gen_loss = 0.8558671784744342, disc_loss = 0.06439120704576434
Trained batch 243 in epoch 10, gen_loss = 0.8559775492939793, disc_loss = 0.06417732652597373
Trained batch 244 in epoch 10, gen_loss = 0.8562128275024647, disc_loss = 0.06395977174064943
Trained batch 245 in epoch 10, gen_loss = 0.8570481401875736, disc_loss = 0.06375063304993801
Trained batch 246 in epoch 10, gen_loss = 0.8571248789306595, disc_loss = 0.06354073263131656
Trained batch 247 in epoch 10, gen_loss = 0.8581454562804391, disc_loss = 0.06336691464117218
Trained batch 248 in epoch 10, gen_loss = 0.8580411812627172, disc_loss = 0.06318310256224559
Trained batch 249 in epoch 10, gen_loss = 0.8577060190439224, disc_loss = 0.06348786115646363
Trained batch 250 in epoch 10, gen_loss = 0.8571835683873925, disc_loss = 0.06347617627199427
Trained batch 251 in epoch 10, gen_loss = 0.8564725041625991, disc_loss = 0.0634120147793539
Trained batch 252 in epoch 10, gen_loss = 0.8565943108010198, disc_loss = 0.063383606008508
Trained batch 253 in epoch 10, gen_loss = 0.8556293388755303, disc_loss = 0.0635817305104235
Trained batch 254 in epoch 10, gen_loss = 0.8562129113019682, disc_loss = 0.06356424499376147
Trained batch 255 in epoch 10, gen_loss = 0.8558092637686059, disc_loss = 0.06363665268872865
Trained batch 256 in epoch 10, gen_loss = 0.8556791141571238, disc_loss = 0.06348690730501473
Trained batch 257 in epoch 10, gen_loss = 0.8551440967838894, disc_loss = 0.06329334623635162
Trained batch 258 in epoch 10, gen_loss = 0.8563944288892635, disc_loss = 0.06317174306290375
Trained batch 259 in epoch 10, gen_loss = 0.8567188115074085, disc_loss = 0.06296787092892023
Trained batch 260 in epoch 10, gen_loss = 0.8561514980263181, disc_loss = 0.06289088045214784
Trained batch 261 in epoch 10, gen_loss = 0.8568552471981704, disc_loss = 0.06268257457222648
Trained batch 262 in epoch 10, gen_loss = 0.8577309814016175, disc_loss = 0.06263876015129198
Trained batch 263 in epoch 10, gen_loss = 0.8573237177774762, disc_loss = 0.06251632477241484
Trained batch 264 in epoch 10, gen_loss = 0.857116025686264, disc_loss = 0.06243209078345659
Trained batch 265 in epoch 10, gen_loss = 0.857637451443457, disc_loss = 0.06239289604127407
Trained batch 266 in epoch 10, gen_loss = 0.8593002779876695, disc_loss = 0.0627049281216516
Trained batch 267 in epoch 10, gen_loss = 0.8583049099169561, disc_loss = 0.06321619766583639
Trained batch 268 in epoch 10, gen_loss = 0.8587502129237448, disc_loss = 0.06310003868487687
Trained batch 269 in epoch 10, gen_loss = 0.8588253110647202, disc_loss = 0.06314529931103742
Trained batch 270 in epoch 10, gen_loss = 0.8579055049982458, disc_loss = 0.06342251983735835
Trained batch 271 in epoch 10, gen_loss = 0.8582959491759539, disc_loss = 0.06331254251520424
Trained batch 272 in epoch 10, gen_loss = 0.858886909244698, disc_loss = 0.06319466214831714
Trained batch 273 in epoch 10, gen_loss = 0.858852679385756, disc_loss = 0.06307814427291172
Trained batch 274 in epoch 10, gen_loss = 0.8587543562325565, disc_loss = 0.06294714634391395
Trained batch 275 in epoch 10, gen_loss = 0.8593676484365395, disc_loss = 0.0627960121407565
Trained batch 276 in epoch 10, gen_loss = 0.8600638856311137, disc_loss = 0.06316607521463602
Trained batch 277 in epoch 10, gen_loss = 0.8587302665273062, disc_loss = 0.06447138994422963
Trained batch 278 in epoch 10, gen_loss = 0.8589986805206559, disc_loss = 0.06446012705698022
Trained batch 279 in epoch 10, gen_loss = 0.8592742356870856, disc_loss = 0.06464033457450569
Trained batch 280 in epoch 10, gen_loss = 0.8585191126183683, disc_loss = 0.06470880066823492
Trained batch 281 in epoch 10, gen_loss = 0.8580809401493545, disc_loss = 0.06473541786194059
Trained batch 282 in epoch 10, gen_loss = 0.858467559405856, disc_loss = 0.06473792097514805
Trained batch 283 in epoch 10, gen_loss = 0.8590014911663364, disc_loss = 0.06465757478841803
Trained batch 284 in epoch 10, gen_loss = 0.8585907177966937, disc_loss = 0.06474405368299861
Trained batch 285 in epoch 10, gen_loss = 0.8598409702519437, disc_loss = 0.06466360320499935
Trained batch 286 in epoch 10, gen_loss = 0.8593416188029047, disc_loss = 0.0646232734353181
Trained batch 287 in epoch 10, gen_loss = 0.8588428605968753, disc_loss = 0.06449708820501757
Trained batch 288 in epoch 10, gen_loss = 0.8589483735676868, disc_loss = 0.0643333226996619
Trained batch 289 in epoch 10, gen_loss = 0.8590162563940574, disc_loss = 0.06451885167766234
Trained batch 290 in epoch 10, gen_loss = 0.8582486533831895, disc_loss = 0.06473296165747945
Trained batch 291 in epoch 10, gen_loss = 0.8587151583131045, disc_loss = 0.06468119471627351
Trained batch 292 in epoch 10, gen_loss = 0.8593011562531312, disc_loss = 0.06459228752289005
Trained batch 293 in epoch 10, gen_loss = 0.8587482629381881, disc_loss = 0.0645173062462689
Trained batch 294 in epoch 10, gen_loss = 0.8583436653775683, disc_loss = 0.0643763852258355
Trained batch 295 in epoch 10, gen_loss = 0.858157112892415, disc_loss = 0.06422749675835508
Trained batch 296 in epoch 10, gen_loss = 0.8590570669182221, disc_loss = 0.06413636705916538
Trained batch 297 in epoch 10, gen_loss = 0.8592623317201665, disc_loss = 0.06418015288451574
Trained batch 298 in epoch 10, gen_loss = 0.8603892833692174, disc_loss = 0.06402755541770554
Trained batch 299 in epoch 10, gen_loss = 0.8591711810231208, disc_loss = 0.06428833872700732
Trained batch 300 in epoch 10, gen_loss = 0.8575978827634919, disc_loss = 0.06491713548246214
Trained batch 301 in epoch 10, gen_loss = 0.858428508438022, disc_loss = 0.06586841114531487
Trained batch 302 in epoch 10, gen_loss = 0.8579212513693882, disc_loss = 0.0658278986258377
Trained batch 303 in epoch 10, gen_loss = 0.8575770129498682, disc_loss = 0.06587956862303575
Trained batch 304 in epoch 10, gen_loss = 0.8574769328852169, disc_loss = 0.06575265127982273
Trained batch 305 in epoch 10, gen_loss = 0.8575780979948107, disc_loss = 0.06579191994311567
Trained batch 306 in epoch 10, gen_loss = 0.8573410165426397, disc_loss = 0.06599950452459558
Trained batch 307 in epoch 10, gen_loss = 0.857054232776939, disc_loss = 0.06589741276141692
Trained batch 308 in epoch 10, gen_loss = 0.8566726640975977, disc_loss = 0.06579591835996673
Trained batch 309 in epoch 10, gen_loss = 0.8561717619819026, disc_loss = 0.0657633192777153
Trained batch 310 in epoch 10, gen_loss = 0.8562052688797954, disc_loss = 0.06623151536036725
Trained batch 311 in epoch 10, gen_loss = 0.8559842669428923, disc_loss = 0.06609159957569762
Trained batch 312 in epoch 10, gen_loss = 0.8553721906658941, disc_loss = 0.0662719670314187
Trained batch 313 in epoch 10, gen_loss = 0.8548170371799712, disc_loss = 0.06625711115872025
Trained batch 314 in epoch 10, gen_loss = 0.8558228755754138, disc_loss = 0.06655195379067981
Trained batch 315 in epoch 10, gen_loss = 0.8555547517688968, disc_loss = 0.06651773904980737
Trained batch 316 in epoch 10, gen_loss = 0.8551801554036065, disc_loss = 0.06645727557150724
Trained batch 317 in epoch 10, gen_loss = 0.8550225187022731, disc_loss = 0.06651020028962279
Trained batch 318 in epoch 10, gen_loss = 0.8547150182499781, disc_loss = 0.06649989317109967
Trained batch 319 in epoch 10, gen_loss = 0.8537429520860315, disc_loss = 0.06666327612474561
Trained batch 320 in epoch 10, gen_loss = 0.8542040592042085, disc_loss = 0.06681939720457589
Trained batch 321 in epoch 10, gen_loss = 0.8542778169886666, disc_loss = 0.06681736135242149
Trained batch 322 in epoch 10, gen_loss = 0.8538686430122092, disc_loss = 0.06676432421148377
Trained batch 323 in epoch 10, gen_loss = 0.8537883418209758, disc_loss = 0.06670108731882071
Trained batch 324 in epoch 10, gen_loss = 0.8532192551172697, disc_loss = 0.06661535987487206
Trained batch 325 in epoch 10, gen_loss = 0.8531627697081654, disc_loss = 0.06650943904429492
Trained batch 326 in epoch 10, gen_loss = 0.8531543816630629, disc_loss = 0.06653571123149052
Trained batch 327 in epoch 10, gen_loss = 0.8526998720154529, disc_loss = 0.06645904159991116
Trained batch 328 in epoch 10, gen_loss = 0.8524810852975468, disc_loss = 0.06633979922845552
Trained batch 329 in epoch 10, gen_loss = 0.852482902100592, disc_loss = 0.0664023248817433
Trained batch 330 in epoch 10, gen_loss = 0.8535572303025745, disc_loss = 0.06641078513577085
Trained batch 331 in epoch 10, gen_loss = 0.8524749735931316, disc_loss = 0.06642464773325496
Trained batch 332 in epoch 10, gen_loss = 0.8515080783639226, disc_loss = 0.06653676319073092
Trained batch 333 in epoch 10, gen_loss = 0.8529046760526245, disc_loss = 0.06656300216846302
Trained batch 334 in epoch 10, gen_loss = 0.853645094206084, disc_loss = 0.06646418185042802
Trained batch 335 in epoch 10, gen_loss = 0.8529934280862411, disc_loss = 0.06643307024413454
Trained batch 336 in epoch 10, gen_loss = 0.8524121634153655, disc_loss = 0.06651117930669637
Trained batch 337 in epoch 10, gen_loss = 0.8530496948745829, disc_loss = 0.06645496243048878
Trained batch 338 in epoch 10, gen_loss = 0.8534926402006178, disc_loss = 0.0663288147696967
Trained batch 339 in epoch 10, gen_loss = 0.8530790561262299, disc_loss = 0.0663606085924103
Trained batch 340 in epoch 10, gen_loss = 0.8530220890150042, disc_loss = 0.06627189162080763
Trained batch 341 in epoch 10, gen_loss = 0.8540599035066471, disc_loss = 0.06634088406851243
Trained batch 342 in epoch 10, gen_loss = 0.8542765353754728, disc_loss = 0.06617999221293294
Trained batch 343 in epoch 10, gen_loss = 0.8544002510607243, disc_loss = 0.06602327459286032
Trained batch 344 in epoch 10, gen_loss = 0.8536111271035844, disc_loss = 0.06638497203534496
Trained batch 345 in epoch 10, gen_loss = 0.8539359639318003, disc_loss = 0.06656283737467117
Trained batch 346 in epoch 10, gen_loss = 0.8539092850788182, disc_loss = 0.06648261514183681
Trained batch 347 in epoch 10, gen_loss = 0.8534695145556297, disc_loss = 0.0664074158633192
Trained batch 348 in epoch 10, gen_loss = 0.8538128172599825, disc_loss = 0.06627807389667263
Trained batch 349 in epoch 10, gen_loss = 0.8538721545253481, disc_loss = 0.06616619813921196
Trained batch 350 in epoch 10, gen_loss = 0.85395602852191, disc_loss = 0.06654567109351908
Trained batch 351 in epoch 10, gen_loss = 0.8532887980849906, disc_loss = 0.06679865829276176
Trained batch 352 in epoch 10, gen_loss = 0.8528493385308187, disc_loss = 0.06684437061979227
Trained batch 353 in epoch 10, gen_loss = 0.8532961616239979, disc_loss = 0.06670817637837119
Trained batch 354 in epoch 10, gen_loss = 0.8534926091281461, disc_loss = 0.0666972053696362
Trained batch 355 in epoch 10, gen_loss = 0.8530630699536773, disc_loss = 0.06664914984957138
Trained batch 356 in epoch 10, gen_loss = 0.8525419069104502, disc_loss = 0.06664490012885058
Trained batch 357 in epoch 10, gen_loss = 0.8526671284903361, disc_loss = 0.06648469641128316
Trained batch 358 in epoch 10, gen_loss = 0.8521882600272931, disc_loss = 0.06643404109886014
Trained batch 359 in epoch 10, gen_loss = 0.8522081152432495, disc_loss = 0.0665786090798469
Trained batch 360 in epoch 10, gen_loss = 0.8517182442124861, disc_loss = 0.06653748435894456
Trained batch 361 in epoch 10, gen_loss = 0.851907556310543, disc_loss = 0.06640494298652967
Trained batch 362 in epoch 10, gen_loss = 0.8524001568309532, disc_loss = 0.06629542772178397
Trained batch 363 in epoch 10, gen_loss = 0.8528817516270575, disc_loss = 0.06617954917569327
Trained batch 364 in epoch 10, gen_loss = 0.8528527237781106, disc_loss = 0.06625684099399472
Trained batch 365 in epoch 10, gen_loss = 0.8526339119737917, disc_loss = 0.06622112208285211
Trained batch 366 in epoch 10, gen_loss = 0.8523859275296858, disc_loss = 0.06616415955095833
Trained batch 367 in epoch 10, gen_loss = 0.8534601164738769, disc_loss = 0.06610290733236901
Trained batch 368 in epoch 10, gen_loss = 0.8532353344810041, disc_loss = 0.06607894808165023
Trained batch 369 in epoch 10, gen_loss = 0.8536609739065171, disc_loss = 0.0660178331482048
Trained batch 370 in epoch 10, gen_loss = 0.8537917631173713, disc_loss = 0.06596441225291824
Trained batch 371 in epoch 10, gen_loss = 0.8536056436357959, disc_loss = 0.06602508934985807
Trained batch 372 in epoch 10, gen_loss = 0.8526176507447424, disc_loss = 0.0662463318941061
Trained batch 373 in epoch 10, gen_loss = 0.8533090731517516, disc_loss = 0.06655817239590109
Trained batch 374 in epoch 10, gen_loss = 0.8538562293847402, disc_loss = 0.06642261668791373
Trained batch 375 in epoch 10, gen_loss = 0.8531644968117805, disc_loss = 0.06642513738776695
Trained batch 376 in epoch 10, gen_loss = 0.8543785221538746, disc_loss = 0.06646459999022418
Trained batch 377 in epoch 10, gen_loss = 0.8544469386654556, disc_loss = 0.06632219805633502
Trained batch 378 in epoch 10, gen_loss = 0.8538961832787556, disc_loss = 0.06643140580170938
Trained batch 379 in epoch 10, gen_loss = 0.8544990527786707, disc_loss = 0.06636194861984175
Trained batch 380 in epoch 10, gen_loss = 0.854521373673061, disc_loss = 0.06621983937987584
Trained batch 381 in epoch 10, gen_loss = 0.8549589538917491, disc_loss = 0.06639427361346742
Trained batch 382 in epoch 10, gen_loss = 0.8545849758246549, disc_loss = 0.06641596447987672
Trained batch 383 in epoch 10, gen_loss = 0.8541398805100471, disc_loss = 0.06643099063512636
Trained batch 384 in epoch 10, gen_loss = 0.8542306863642358, disc_loss = 0.0664197753219829
Trained batch 385 in epoch 10, gen_loss = 0.8550760138374536, disc_loss = 0.06642757014762321
Trained batch 386 in epoch 10, gen_loss = 0.8550788412876523, disc_loss = 0.06637421406526359
Trained batch 387 in epoch 10, gen_loss = 0.8552942309029323, disc_loss = 0.0662381159568916
Trained batch 388 in epoch 10, gen_loss = 0.8549707393260112, disc_loss = 0.0661530742268521
Trained batch 389 in epoch 10, gen_loss = 0.8550274158899601, disc_loss = 0.06602762717610368
Trained batch 390 in epoch 10, gen_loss = 0.8555562173771432, disc_loss = 0.06610498558062955
Trained batch 391 in epoch 10, gen_loss = 0.8558954779742932, disc_loss = 0.06600954682727782
Trained batch 392 in epoch 10, gen_loss = 0.8565167805165735, disc_loss = 0.06590073451200743
Trained batch 393 in epoch 10, gen_loss = 0.8563239416343912, disc_loss = 0.06585501508579263
Trained batch 394 in epoch 10, gen_loss = 0.8562778325775001, disc_loss = 0.06576744636544321
Trained batch 395 in epoch 10, gen_loss = 0.8563017687863774, disc_loss = 0.06564523718752568
Trained batch 396 in epoch 10, gen_loss = 0.8562489556575602, disc_loss = 0.06554823067808707
Trained batch 397 in epoch 10, gen_loss = 0.856510459852578, disc_loss = 0.06542074540395983
Trained batch 398 in epoch 10, gen_loss = 0.8574528512649966, disc_loss = 0.06535125785696327
Trained batch 399 in epoch 10, gen_loss = 0.8572362019866705, disc_loss = 0.0652907675737515
Trained batch 400 in epoch 10, gen_loss = 0.8570448804525961, disc_loss = 0.06520463740383449
Trained batch 401 in epoch 10, gen_loss = 0.85751973092556, disc_loss = 0.06515437664362181
Trained batch 402 in epoch 10, gen_loss = 0.8574420031039945, disc_loss = 0.06501967499203629
Trained batch 403 in epoch 10, gen_loss = 0.8570032015737921, disc_loss = 0.06494312947800401
Trained batch 404 in epoch 10, gen_loss = 0.8576560499491515, disc_loss = 0.06481318422535687
Trained batch 405 in epoch 10, gen_loss = 0.8576285345066944, disc_loss = 0.06470378473850674
Trained batch 406 in epoch 10, gen_loss = 0.8578250398653439, disc_loss = 0.06456039392181125
Trained batch 407 in epoch 10, gen_loss = 0.8585416036931908, disc_loss = 0.06445594395593028
Trained batch 408 in epoch 10, gen_loss = 0.8586737966041985, disc_loss = 0.0643322586143403
Trained batch 409 in epoch 10, gen_loss = 0.8587355428352589, disc_loss = 0.0642198076903275
Trained batch 410 in epoch 10, gen_loss = 0.8584704154744346, disc_loss = 0.06414042321915246
Trained batch 411 in epoch 10, gen_loss = 0.8588621557771581, disc_loss = 0.06400562500246593
Trained batch 412 in epoch 10, gen_loss = 0.8598301632208051, disc_loss = 0.06388616054736024
Trained batch 413 in epoch 10, gen_loss = 0.8597615431040382, disc_loss = 0.06376357383549142
Trained batch 414 in epoch 10, gen_loss = 0.860626213306404, disc_loss = 0.06386626172272197
Trained batch 415 in epoch 10, gen_loss = 0.8601793061512021, disc_loss = 0.06384928219799454
Trained batch 416 in epoch 10, gen_loss = 0.8600756363760081, disc_loss = 0.0638394174489865
Trained batch 417 in epoch 10, gen_loss = 0.8605808557933597, disc_loss = 0.06397991465921536
Trained batch 418 in epoch 10, gen_loss = 0.8607014189329807, disc_loss = 0.06385949495424093
Trained batch 419 in epoch 10, gen_loss = 0.8606737539172172, disc_loss = 0.06374490782175035
Trained batch 420 in epoch 10, gen_loss = 0.8600593561089803, disc_loss = 0.06390766572481521
Trained batch 421 in epoch 10, gen_loss = 0.8598008799185685, disc_loss = 0.06384842852086393
Trained batch 422 in epoch 10, gen_loss = 0.8604601488468495, disc_loss = 0.06387883470994783
Trained batch 423 in epoch 10, gen_loss = 0.8611631193110403, disc_loss = 0.06387056271932176
Trained batch 424 in epoch 10, gen_loss = 0.8614527544554542, disc_loss = 0.06375979703577125
Trained batch 425 in epoch 10, gen_loss = 0.8613401860558371, disc_loss = 0.06367018662760375
Trained batch 426 in epoch 10, gen_loss = 0.8607493317238899, disc_loss = 0.06377921940484008
Trained batch 427 in epoch 10, gen_loss = 0.8609288969190321, disc_loss = 0.06369299084278886
Trained batch 428 in epoch 10, gen_loss = 0.8613306816780206, disc_loss = 0.06359718190744901
Trained batch 429 in epoch 10, gen_loss = 0.8618738209785417, disc_loss = 0.06350700289963983
Trained batch 430 in epoch 10, gen_loss = 0.8618971941227702, disc_loss = 0.06339363249239194
Trained batch 431 in epoch 10, gen_loss = 0.8621615112793667, disc_loss = 0.06332294158508173
Trained batch 432 in epoch 10, gen_loss = 0.8624834867740614, disc_loss = 0.06319293514319951
Trained batch 433 in epoch 10, gen_loss = 0.8629087947892703, disc_loss = 0.06319891726962948
Trained batch 434 in epoch 10, gen_loss = 0.8623613530876992, disc_loss = 0.06323296217376302
Trained batch 435 in epoch 10, gen_loss = 0.8622241138454971, disc_loss = 0.063208348266225
Trained batch 436 in epoch 10, gen_loss = 0.862928550426147, disc_loss = 0.06313339824888438
Trained batch 437 in epoch 10, gen_loss = 0.8633187095460282, disc_loss = 0.06306888331812233
Trained batch 438 in epoch 10, gen_loss = 0.8631965649019341, disc_loss = 0.0630160381535921
Trained batch 439 in epoch 10, gen_loss = 0.8633930120278489, disc_loss = 0.06289819577518342
Trained batch 440 in epoch 10, gen_loss = 0.8634140146157098, disc_loss = 0.0631801158626925
Trained batch 441 in epoch 10, gen_loss = 0.862926543096072, disc_loss = 0.06316275376620033
Trained batch 442 in epoch 10, gen_loss = 0.8628036856785853, disc_loss = 0.063069781884509
Trained batch 443 in epoch 10, gen_loss = 0.8625966819959718, disc_loss = 0.06307211323108457
Trained batch 444 in epoch 10, gen_loss = 0.861995295661219, disc_loss = 0.06318244679067074
Trained batch 445 in epoch 10, gen_loss = 0.8630448087314854, disc_loss = 0.06319085720220723
Trained batch 446 in epoch 10, gen_loss = 0.8630331228643455, disc_loss = 0.06308742537907006
Trained batch 447 in epoch 10, gen_loss = 0.8628943486006132, disc_loss = 0.06302234580653021
Trained batch 448 in epoch 10, gen_loss = 0.8627987925485938, disc_loss = 0.06292106552497548
Trained batch 449 in epoch 10, gen_loss = 0.8629331737756729, disc_loss = 0.06279800672187573
Trained batch 450 in epoch 10, gen_loss = 0.8627989039056317, disc_loss = 0.06274582430443618
Trained batch 451 in epoch 10, gen_loss = 0.8627107471095777, disc_loss = 0.06269356364948857
Trained batch 452 in epoch 10, gen_loss = 0.8625788991945995, disc_loss = 0.0626984968602608
Trained batch 453 in epoch 10, gen_loss = 0.8629581766112786, disc_loss = 0.06260142923488655
Trained batch 454 in epoch 10, gen_loss = 0.8627435496220222, disc_loss = 0.06251689436036971
Trained batch 455 in epoch 10, gen_loss = 0.8631189230894833, disc_loss = 0.062433348181289865
Trained batch 456 in epoch 10, gen_loss = 0.8633433295417927, disc_loss = 0.06232208910926003
Trained batch 457 in epoch 10, gen_loss = 0.8633657758282782, disc_loss = 0.06222490380583209
Trained batch 458 in epoch 10, gen_loss = 0.8631695173274977, disc_loss = 0.06214940694337285
Trained batch 459 in epoch 10, gen_loss = 0.8634037817949834, disc_loss = 0.062047702431395325
Trained batch 460 in epoch 10, gen_loss = 0.8634724512922531, disc_loss = 0.06195943894414251
Trained batch 461 in epoch 10, gen_loss = 0.8640964964638541, disc_loss = 0.061876695438840494
Trained batch 462 in epoch 10, gen_loss = 0.8642378520888335, disc_loss = 0.06178235089744302
Trained batch 463 in epoch 10, gen_loss = 0.864297406234104, disc_loss = 0.061689767967468
Trained batch 464 in epoch 10, gen_loss = 0.8648603642499575, disc_loss = 0.06157412250896776
Trained batch 465 in epoch 10, gen_loss = 0.8648521054072441, disc_loss = 0.06146056643015677
Trained batch 466 in epoch 10, gen_loss = 0.864838723771322, disc_loss = 0.061379738067270796
Trained batch 467 in epoch 10, gen_loss = 0.8647039819859031, disc_loss = 0.06128763555027704
Trained batch 468 in epoch 10, gen_loss = 0.8653283250738563, disc_loss = 0.06120718381246492
Trained batch 469 in epoch 10, gen_loss = 0.8654603773609121, disc_loss = 0.06110530318395096
Trained batch 470 in epoch 10, gen_loss = 0.8655514327963446, disc_loss = 0.061106733229375126
Trained batch 471 in epoch 10, gen_loss = 0.8651023548159559, disc_loss = 0.061213233629517826
Trained batch 472 in epoch 10, gen_loss = 0.8653313419909608, disc_loss = 0.061100800912512215
Trained batch 473 in epoch 10, gen_loss = 0.8653927497597184, disc_loss = 0.06102784541396243
Trained batch 474 in epoch 10, gen_loss = 0.865993545369098, disc_loss = 0.06119498802545039
Trained batch 475 in epoch 10, gen_loss = 0.8653922886783335, disc_loss = 0.06142354221963676
Trained batch 476 in epoch 10, gen_loss = 0.865258434721009, disc_loss = 0.061370062674015013
Trained batch 477 in epoch 10, gen_loss = 0.8659767809647396, disc_loss = 0.06134116952697197
Trained batch 478 in epoch 10, gen_loss = 0.8663350932906714, disc_loss = 0.06126418203749307
Trained batch 479 in epoch 10, gen_loss = 0.8662073168282708, disc_loss = 0.06117805075191427
Trained batch 480 in epoch 10, gen_loss = 0.8660525071769642, disc_loss = 0.06116528190544607
Trained batch 481 in epoch 10, gen_loss = 0.8663411222676518, disc_loss = 0.06108360900930071
Trained batch 482 in epoch 10, gen_loss = 0.8665885955527208, disc_loss = 0.060977799217284155
Trained batch 483 in epoch 10, gen_loss = 0.866762498378261, disc_loss = 0.060873849632041455
Trained batch 484 in epoch 10, gen_loss = 0.8672555433720658, disc_loss = 0.060778555987383596
Trained batch 485 in epoch 10, gen_loss = 0.8671269070341754, disc_loss = 0.06075028690256546
Trained batch 486 in epoch 10, gen_loss = 0.8680199971556418, disc_loss = 0.060677985240967305
Trained batch 487 in epoch 10, gen_loss = 0.8682036512821424, disc_loss = 0.06058215302106024
Trained batch 488 in epoch 10, gen_loss = 0.868286382871659, disc_loss = 0.06052471088923529
Trained batch 489 in epoch 10, gen_loss = 0.8685634422667172, disc_loss = 0.0604289734802608
Trained batch 490 in epoch 10, gen_loss = 0.8681585362025531, disc_loss = 0.06054862925039259
Trained batch 491 in epoch 10, gen_loss = 0.8688917577387841, disc_loss = 0.06051316409375579
Trained batch 492 in epoch 10, gen_loss = 0.8697169843237492, disc_loss = 0.060530708436844737
Trained batch 493 in epoch 10, gen_loss = 0.8694888469781953, disc_loss = 0.060612951321451954
Trained batch 494 in epoch 10, gen_loss = 0.8693667193253835, disc_loss = 0.06060775742969579
Trained batch 495 in epoch 10, gen_loss = 0.8694259022632914, disc_loss = 0.06050214488641359
Trained batch 496 in epoch 10, gen_loss = 0.8694454216261505, disc_loss = 0.06040020231101324
Trained batch 497 in epoch 10, gen_loss = 0.8696059247695778, disc_loss = 0.06029869496624124
Trained batch 498 in epoch 10, gen_loss = 0.8696317185978134, disc_loss = 0.06020168480715287
Trained batch 499 in epoch 10, gen_loss = 0.8701000123620033, disc_loss = 0.0601409221207723
Trained batch 500 in epoch 10, gen_loss = 0.8700188365644086, disc_loss = 0.06014956136005457
Trained batch 501 in epoch 10, gen_loss = 0.8697868146863117, disc_loss = 0.060135644047049824
Trained batch 502 in epoch 10, gen_loss = 0.8694650731669743, disc_loss = 0.06008213815403358
Trained batch 503 in epoch 10, gen_loss = 0.8698876763265284, disc_loss = 0.06000962442744316
Trained batch 504 in epoch 10, gen_loss = 0.87091661945428, disc_loss = 0.060004049837404844
Trained batch 505 in epoch 10, gen_loss = 0.8707586323673074, disc_loss = 0.05995510763253119
Trained batch 506 in epoch 10, gen_loss = 0.870348199643562, disc_loss = 0.05997010745398362
Trained batch 507 in epoch 10, gen_loss = 0.8702340358941574, disc_loss = 0.059880867012864436
Trained batch 508 in epoch 10, gen_loss = 0.8707018287921936, disc_loss = 0.05982368687453198
Trained batch 509 in epoch 10, gen_loss = 0.8713119067982131, disc_loss = 0.059799719286863416
Trained batch 510 in epoch 10, gen_loss = 0.8712471028946617, disc_loss = 0.05972199743329283
Trained batch 511 in epoch 10, gen_loss = 0.8714460332994349, disc_loss = 0.05962751456445403
Trained batch 512 in epoch 10, gen_loss = 0.8708956284016429, disc_loss = 0.05970224563747673
Trained batch 513 in epoch 10, gen_loss = 0.8718338472486006, disc_loss = 0.05974213084557496
Trained batch 514 in epoch 10, gen_loss = 0.8718835898394723, disc_loss = 0.05969037331767308
Trained batch 515 in epoch 10, gen_loss = 0.871919814179572, disc_loss = 0.05961344960279214
Trained batch 516 in epoch 10, gen_loss = 0.8720110342972975, disc_loss = 0.05954844819028759
Trained batch 517 in epoch 10, gen_loss = 0.8718718395615176, disc_loss = 0.059478036296090046
Trained batch 518 in epoch 10, gen_loss = 0.8722096972727362, disc_loss = 0.059394066757657106
Trained batch 519 in epoch 10, gen_loss = 0.8727185624723252, disc_loss = 0.05929470300907269
Trained batch 520 in epoch 10, gen_loss = 0.873362450533316, disc_loss = 0.05921526799593371
Trained batch 521 in epoch 10, gen_loss = 0.8736538950396681, disc_loss = 0.05912343598634604
Trained batch 522 in epoch 10, gen_loss = 0.8736148103359325, disc_loss = 0.05904317099554731
Trained batch 523 in epoch 10, gen_loss = 0.8738787806102337, disc_loss = 0.05895403766105278
Trained batch 524 in epoch 10, gen_loss = 0.8742856047834668, disc_loss = 0.058936882287796054
Trained batch 525 in epoch 10, gen_loss = 0.8742018417373809, disc_loss = 0.05887098452377314
Trained batch 526 in epoch 10, gen_loss = 0.873945677472699, disc_loss = 0.0588885739196509
Trained batch 527 in epoch 10, gen_loss = 0.8743596196061734, disc_loss = 0.058904822385749976
Trained batch 528 in epoch 10, gen_loss = 0.8744459361232296, disc_loss = 0.058825504748654216
Trained batch 529 in epoch 10, gen_loss = 0.8749747799814872, disc_loss = 0.05874669605532204
Trained batch 530 in epoch 10, gen_loss = 0.8750566373773887, disc_loss = 0.05868844704337685
Trained batch 531 in epoch 10, gen_loss = 0.8751686212599725, disc_loss = 0.05864875294054557
Trained batch 532 in epoch 10, gen_loss = 0.8756091567298038, disc_loss = 0.05857177922243557
Trained batch 533 in epoch 10, gen_loss = 0.8760685975966829, disc_loss = 0.05851046295840056
Trained batch 534 in epoch 10, gen_loss = 0.8760635642804833, disc_loss = 0.058435609002780414
Trained batch 535 in epoch 10, gen_loss = 0.8760707609133044, disc_loss = 0.05839067739139158
Trained batch 536 in epoch 10, gen_loss = 0.8758886744523181, disc_loss = 0.05834659420602454
Trained batch 537 in epoch 10, gen_loss = 0.8758663082543802, disc_loss = 0.05827078365436911
Trained batch 538 in epoch 10, gen_loss = 0.8753977617549542, disc_loss = 0.05827757846373988
Trained batch 539 in epoch 10, gen_loss = 0.876054191534166, disc_loss = 0.058370809094049035
Trained batch 540 in epoch 10, gen_loss = 0.8763208390934851, disc_loss = 0.05834886525600956
Trained batch 541 in epoch 10, gen_loss = 0.8759103139718081, disc_loss = 0.058467782074173164
Trained batch 542 in epoch 10, gen_loss = 0.8754391314026181, disc_loss = 0.05849358398539338
Trained batch 543 in epoch 10, gen_loss = 0.8754285254570491, disc_loss = 0.05845615768596284
Trained batch 544 in epoch 10, gen_loss = 0.8754186520335872, disc_loss = 0.0584157073126952
Trained batch 545 in epoch 10, gen_loss = 0.8752469991917139, disc_loss = 0.058360296655480405
Trained batch 546 in epoch 10, gen_loss = 0.8749452919258278, disc_loss = 0.05837657567798083
Trained batch 547 in epoch 10, gen_loss = 0.8743995638550633, disc_loss = 0.05848021466322379
Trained batch 548 in epoch 10, gen_loss = 0.8750083517615695, disc_loss = 0.05864917842047001
Trained batch 549 in epoch 10, gen_loss = 0.874778460318392, disc_loss = 0.05861883538267152
Trained batch 550 in epoch 10, gen_loss = 0.8748108887953681, disc_loss = 0.058535171952436654
Trained batch 551 in epoch 10, gen_loss = 0.8748375156327434, disc_loss = 0.05845363963095039
Trained batch 552 in epoch 10, gen_loss = 0.874560829150957, disc_loss = 0.05847590032604542
Trained batch 553 in epoch 10, gen_loss = 0.8751086797632466, disc_loss = 0.058442612893926486
Trained batch 554 in epoch 10, gen_loss = 0.8750872836993622, disc_loss = 0.05846203258764502
Trained batch 555 in epoch 10, gen_loss = 0.8751392757399477, disc_loss = 0.05838772639039261
Trained batch 556 in epoch 10, gen_loss = 0.8746248136409951, disc_loss = 0.05843822762982074
Trained batch 557 in epoch 10, gen_loss = 0.8745929974274823, disc_loss = 0.058420300930170976
Trained batch 558 in epoch 10, gen_loss = 0.8746900260448456, disc_loss = 0.05840847547847464
Trained batch 559 in epoch 10, gen_loss = 0.8744105901569128, disc_loss = 0.05839042372785375
Trained batch 560 in epoch 10, gen_loss = 0.8739459453525815, disc_loss = 0.05850144634322129
Trained batch 561 in epoch 10, gen_loss = 0.8741444657387683, disc_loss = 0.0584307518345221
Trained batch 562 in epoch 10, gen_loss = 0.8748031579897628, disc_loss = 0.05893887086071696
Trained batch 563 in epoch 10, gen_loss = 0.8741970349182474, disc_loss = 0.05902702314036086
Trained batch 564 in epoch 10, gen_loss = 0.8739861216692798, disc_loss = 0.058997069868728914
Trained batch 565 in epoch 10, gen_loss = 0.8737524716782485, disc_loss = 0.05904986092231694
Trained batch 566 in epoch 10, gen_loss = 0.8734598949788108, disc_loss = 0.059173821078242185
Trained batch 567 in epoch 10, gen_loss = 0.8737469642409976, disc_loss = 0.05917033777673873
Trained batch 568 in epoch 10, gen_loss = 0.8739226254616554, disc_loss = 0.05917393576815358
Trained batch 569 in epoch 10, gen_loss = 0.8734199551636712, disc_loss = 0.05926640004556822
Trained batch 570 in epoch 10, gen_loss = 0.8733372537455083, disc_loss = 0.05919570075478502
Trained batch 571 in epoch 10, gen_loss = 0.8733843053866933, disc_loss = 0.059171411107046774
Trained batch 572 in epoch 10, gen_loss = 0.8738916346227935, disc_loss = 0.05910257097531962
Trained batch 573 in epoch 10, gen_loss = 0.8734534662671205, disc_loss = 0.05919995396041055
Trained batch 574 in epoch 10, gen_loss = 0.873569723367691, disc_loss = 0.059138423919515765
Trained batch 575 in epoch 10, gen_loss = 0.8737312956299219, disc_loss = 0.05920626488498076
Trained batch 576 in epoch 10, gen_loss = 0.8736128828244565, disc_loss = 0.059158999062073864
Trained batch 577 in epoch 10, gen_loss = 0.8736067161118696, disc_loss = 0.05907073577263338
Trained batch 578 in epoch 10, gen_loss = 0.8739209731522826, disc_loss = 0.059009270062943556
Trained batch 579 in epoch 10, gen_loss = 0.8740308185589725, disc_loss = 0.05898898078112638
Trained batch 580 in epoch 10, gen_loss = 0.8733342753117344, disc_loss = 0.05921829309676759
Trained batch 581 in epoch 10, gen_loss = 0.8736053746692913, disc_loss = 0.05919127323651923
Trained batch 582 in epoch 10, gen_loss = 0.8737077058179505, disc_loss = 0.05921567488209333
Trained batch 583 in epoch 10, gen_loss = 0.8734972574429153, disc_loss = 0.059185797258516235
Trained batch 584 in epoch 10, gen_loss = 0.8732631996656075, disc_loss = 0.05912927196751166
Trained batch 585 in epoch 10, gen_loss = 0.8730392036482743, disc_loss = 0.059143466944091096
Trained batch 586 in epoch 10, gen_loss = 0.8732822095210548, disc_loss = 0.05914051061515178
Trained batch 587 in epoch 10, gen_loss = 0.8735439389639971, disc_loss = 0.05907368033943812
Trained batch 588 in epoch 10, gen_loss = 0.8731583554696146, disc_loss = 0.05908004828161087
Trained batch 589 in epoch 10, gen_loss = 0.8734205182831166, disc_loss = 0.05900307356979761
Trained batch 590 in epoch 10, gen_loss = 0.8733472166025094, disc_loss = 0.05905308341134699
Trained batch 591 in epoch 10, gen_loss = 0.8729362489303222, disc_loss = 0.059088896216692506
Trained batch 592 in epoch 10, gen_loss = 0.8729939335614795, disc_loss = 0.05900256757814481
Trained batch 593 in epoch 10, gen_loss = 0.8738713081336583, disc_loss = 0.05931676756073204
Trained batch 594 in epoch 10, gen_loss = 0.8736883044743738, disc_loss = 0.059325649832696226
Trained batch 595 in epoch 10, gen_loss = 0.8736728038263801, disc_loss = 0.059264615989890225
Trained batch 596 in epoch 10, gen_loss = 0.8732680655903553, disc_loss = 0.05936857314087712
Trained batch 597 in epoch 10, gen_loss = 0.8736785614869268, disc_loss = 0.059330709140754015
Trained batch 598 in epoch 10, gen_loss = 0.8738986773662057, disc_loss = 0.05940988251802594
Trained batch 599 in epoch 10, gen_loss = 0.8741625861823559, disc_loss = 0.05940030393423513
Trained batch 600 in epoch 10, gen_loss = 0.8737633285328077, disc_loss = 0.05948118096800171
Trained batch 601 in epoch 10, gen_loss = 0.8736131028380505, disc_loss = 0.05948479318189933
Trained batch 602 in epoch 10, gen_loss = 0.873595630499854, disc_loss = 0.05941766407109093
Trained batch 603 in epoch 10, gen_loss = 0.8738089414523137, disc_loss = 0.0593307026282619
Trained batch 604 in epoch 10, gen_loss = 0.8741532342985642, disc_loss = 0.05962224071768443
Trained batch 605 in epoch 10, gen_loss = 0.8738253254799953, disc_loss = 0.059667478519931386
Trained batch 606 in epoch 10, gen_loss = 0.8737639311019828, disc_loss = 0.05963155612367922
Trained batch 607 in epoch 10, gen_loss = 0.8735161945713978, disc_loss = 0.05961292805487143
Trained batch 608 in epoch 10, gen_loss = 0.873619850779989, disc_loss = 0.059536441905219076
Trained batch 609 in epoch 10, gen_loss = 0.8734399327977759, disc_loss = 0.059505214897885184
Trained batch 610 in epoch 10, gen_loss = 0.8736856086652135, disc_loss = 0.059420323010027996
Trained batch 611 in epoch 10, gen_loss = 0.8737255109388844, disc_loss = 0.05935364368895154
Trained batch 612 in epoch 10, gen_loss = 0.8736109819633926, disc_loss = 0.059298415540688675
Trained batch 613 in epoch 10, gen_loss = 0.8738064300450906, disc_loss = 0.0592129048193632
Trained batch 614 in epoch 10, gen_loss = 0.8740377856948511, disc_loss = 0.0591268451687524
Trained batch 615 in epoch 10, gen_loss = 0.8741796252305631, disc_loss = 0.059092318212806985
Trained batch 616 in epoch 10, gen_loss = 0.8738059040696347, disc_loss = 0.05912554635691971
Trained batch 617 in epoch 10, gen_loss = 0.8741459303978577, disc_loss = 0.059058039238176104
Trained batch 618 in epoch 10, gen_loss = 0.8741240060868671, disc_loss = 0.059025087548789955
Trained batch 619 in epoch 10, gen_loss = 0.8739947992467111, disc_loss = 0.05896249022935667
Trained batch 620 in epoch 10, gen_loss = 0.8740448463654172, disc_loss = 0.05887761116162806
Trained batch 621 in epoch 10, gen_loss = 0.8739447518464454, disc_loss = 0.05885797645971538
Trained batch 622 in epoch 10, gen_loss = 0.8735874293799576, disc_loss = 0.0589324297184606
Trained batch 623 in epoch 10, gen_loss = 0.8741176179490793, disc_loss = 0.059146833060554065
Trained batch 624 in epoch 10, gen_loss = 0.8739022759914398, disc_loss = 0.059133601710945366
Trained batch 625 in epoch 10, gen_loss = 0.8736908027824883, disc_loss = 0.0591575319799907
Trained batch 626 in epoch 10, gen_loss = 0.8740818918321691, disc_loss = 0.0591939469061174
Trained batch 627 in epoch 10, gen_loss = 0.8741729412773612, disc_loss = 0.05912798253751129
Trained batch 628 in epoch 10, gen_loss = 0.8739342436976197, disc_loss = 0.05914238776155823
Trained batch 629 in epoch 10, gen_loss = 0.8735891458061006, disc_loss = 0.059173838780187664
Trained batch 630 in epoch 10, gen_loss = 0.8737247253276655, disc_loss = 0.05912674332137933
Trained batch 631 in epoch 10, gen_loss = 0.8739865896162353, disc_loss = 0.05906025055409822
Trained batch 632 in epoch 10, gen_loss = 0.873945644916893, disc_loss = 0.05899368169810182
Trained batch 633 in epoch 10, gen_loss = 0.8737676851098846, disc_loss = 0.05914668719818939
Trained batch 634 in epoch 10, gen_loss = 0.8736078350093421, disc_loss = 0.05919255617580663
Trained batch 635 in epoch 10, gen_loss = 0.8732690846301475, disc_loss = 0.05921176191691731
Trained batch 636 in epoch 10, gen_loss = 0.8736046904016701, disc_loss = 0.05943314601072173
Trained batch 637 in epoch 10, gen_loss = 0.873466267808104, disc_loss = 0.05938308883157667
Trained batch 638 in epoch 10, gen_loss = 0.8736937633236063, disc_loss = 0.05931421220433754
Trained batch 639 in epoch 10, gen_loss = 0.8735102717299015, disc_loss = 0.05934065732071758
Trained batch 640 in epoch 10, gen_loss = 0.873279964821573, disc_loss = 0.05934404568781556
Trained batch 641 in epoch 10, gen_loss = 0.873137165220727, disc_loss = 0.059287375620366116
Trained batch 642 in epoch 10, gen_loss = 0.8733518011925936, disc_loss = 0.0592175198184445
Trained batch 643 in epoch 10, gen_loss = 0.8733058541735507, disc_loss = 0.05916973105732999
Trained batch 644 in epoch 10, gen_loss = 0.8732692423254944, disc_loss = 0.059117810847598685
Trained batch 645 in epoch 10, gen_loss = 0.8733265008258376, disc_loss = 0.05905467286005316
Trained batch 646 in epoch 10, gen_loss = 0.8737316674666574, disc_loss = 0.05905709668225285
Trained batch 647 in epoch 10, gen_loss = 0.8736844871791056, disc_loss = 0.05899660298845121
Trained batch 648 in epoch 10, gen_loss = 0.8738105529904917, disc_loss = 0.058930587962711764
Trained batch 649 in epoch 10, gen_loss = 0.8734054008355507, disc_loss = 0.05908860758305169
Trained batch 650 in epoch 10, gen_loss = 0.8734772601343703, disc_loss = 0.059027137081017186
Trained batch 651 in epoch 10, gen_loss = 0.8735730771912388, disc_loss = 0.05900406204749676
Trained batch 652 in epoch 10, gen_loss = 0.8733131773712807, disc_loss = 0.05909174572673568
Trained batch 653 in epoch 10, gen_loss = 0.8727740120905985, disc_loss = 0.05915973760794267
Trained batch 654 in epoch 10, gen_loss = 0.8730357234259598, disc_loss = 0.059117931290351936
Trained batch 655 in epoch 10, gen_loss = 0.8730516633155142, disc_loss = 0.05922173695403106
Trained batch 656 in epoch 10, gen_loss = 0.8728073802259233, disc_loss = 0.05922426690830873
Trained batch 657 in epoch 10, gen_loss = 0.8725872571073404, disc_loss = 0.05926056837275239
Trained batch 658 in epoch 10, gen_loss = 0.8722969552725327, disc_loss = 0.05931482603490827
Trained batch 659 in epoch 10, gen_loss = 0.8724879245414878, disc_loss = 0.059286430109094714
Trained batch 660 in epoch 10, gen_loss = 0.8726471730602311, disc_loss = 0.059296760142396196
Trained batch 661 in epoch 10, gen_loss = 0.8724186429894583, disc_loss = 0.05929207345231625
Trained batch 662 in epoch 10, gen_loss = 0.8721855988959202, disc_loss = 0.05937054955932911
Trained batch 663 in epoch 10, gen_loss = 0.8720618003912001, disc_loss = 0.05932206128715504
Trained batch 664 in epoch 10, gen_loss = 0.8716217831113284, disc_loss = 0.05939024448240722
Trained batch 665 in epoch 10, gen_loss = 0.8718970650219703, disc_loss = 0.05942733810764287
Trained batch 666 in epoch 10, gen_loss = 0.8717425918203779, disc_loss = 0.059545769115331874
Trained batch 667 in epoch 10, gen_loss = 0.8710060726828918, disc_loss = 0.05987511317644402
Trained batch 668 in epoch 10, gen_loss = 0.8711599419380696, disc_loss = 0.05990692810607887
Trained batch 669 in epoch 10, gen_loss = 0.8716266861157631, disc_loss = 0.05988363806061002
Trained batch 670 in epoch 10, gen_loss = 0.8716901988901431, disc_loss = 0.05997757542664643
Trained batch 671 in epoch 10, gen_loss = 0.8713763945602945, disc_loss = 0.05996485958166886
Trained batch 672 in epoch 10, gen_loss = 0.8710206800637238, disc_loss = 0.059978068395923234
Trained batch 673 in epoch 10, gen_loss = 0.8709079705023978, disc_loss = 0.05993122561387054
Trained batch 674 in epoch 10, gen_loss = 0.8712691039067727, disc_loss = 0.05988131301891473
Trained batch 675 in epoch 10, gen_loss = 0.8708747950266804, disc_loss = 0.06001332176907109
Trained batch 676 in epoch 10, gen_loss = 0.8707167107826498, disc_loss = 0.060023449411535944
Trained batch 677 in epoch 10, gen_loss = 0.8704647608650821, disc_loss = 0.06004650646389344
Trained batch 678 in epoch 10, gen_loss = 0.8707948602264163, disc_loss = 0.06005890241210981
Trained batch 679 in epoch 10, gen_loss = 0.8708968514466987, disc_loss = 0.059991043223314645
Trained batch 680 in epoch 10, gen_loss = 0.8707973109380439, disc_loss = 0.05993236946324967
Trained batch 681 in epoch 10, gen_loss = 0.8704571525984146, disc_loss = 0.06002157149068967
Trained batch 682 in epoch 10, gen_loss = 0.8703833271696139, disc_loss = 0.05997706159722949
Trained batch 683 in epoch 10, gen_loss = 0.8709076827293948, disc_loss = 0.06008239595657922
Trained batch 684 in epoch 10, gen_loss = 0.8704478540124684, disc_loss = 0.060186868816967644
Trained batch 685 in epoch 10, gen_loss = 0.8703047793478035, disc_loss = 0.060178612614778186
Trained batch 686 in epoch 10, gen_loss = 0.8705142499144247, disc_loss = 0.06026248809890998
Trained batch 687 in epoch 10, gen_loss = 0.8703725383465373, disc_loss = 0.060260626972723365
Trained batch 688 in epoch 10, gen_loss = 0.8700476705335913, disc_loss = 0.060255601740589554
Trained batch 689 in epoch 10, gen_loss = 0.8699290694101997, disc_loss = 0.06019613313677626
Trained batch 690 in epoch 10, gen_loss = 0.8698182625725714, disc_loss = 0.060141755761942584
Trained batch 691 in epoch 10, gen_loss = 0.8698861845742071, disc_loss = 0.06007461782579843
Trained batch 692 in epoch 10, gen_loss = 0.8697648903766235, disc_loss = 0.060110806341687535
Trained batch 693 in epoch 10, gen_loss = 0.8697025582237271, disc_loss = 0.060075526298171374
Trained batch 694 in epoch 10, gen_loss = 0.8693396798569522, disc_loss = 0.060104754340010794
Trained batch 695 in epoch 10, gen_loss = 0.8695308946758166, disc_loss = 0.06008049539335864
Trained batch 696 in epoch 10, gen_loss = 0.8695134307168306, disc_loss = 0.06003529455852154
Trained batch 697 in epoch 10, gen_loss = 0.869033224218896, disc_loss = 0.06018878257283701
Trained batch 698 in epoch 10, gen_loss = 0.8687334077296851, disc_loss = 0.06018726768915426
Trained batch 699 in epoch 10, gen_loss = 0.8690273073315621, disc_loss = 0.06047252919325339
Trained batch 700 in epoch 10, gen_loss = 0.8689168717568679, disc_loss = 0.06043561440447449
Trained batch 701 in epoch 10, gen_loss = 0.8685475647704214, disc_loss = 0.06053686404980167
Trained batch 702 in epoch 10, gen_loss = 0.8682779786342577, disc_loss = 0.060630336380663036
Trained batch 703 in epoch 10, gen_loss = 0.8683377046730708, disc_loss = 0.06058657299317102
Trained batch 704 in epoch 10, gen_loss = 0.8682462773001786, disc_loss = 0.060636532431507996
Trained batch 705 in epoch 10, gen_loss = 0.8684085251673761, disc_loss = 0.06062082798357409
Trained batch 706 in epoch 10, gen_loss = 0.8685159482999772, disc_loss = 0.06057094964705924
Trained batch 707 in epoch 10, gen_loss = 0.8685296525978773, disc_loss = 0.06054459579386301
Trained batch 708 in epoch 10, gen_loss = 0.8684522854676536, disc_loss = 0.060531455144018184
Trained batch 709 in epoch 10, gen_loss = 0.8688200115737781, disc_loss = 0.06049560662949274
Trained batch 710 in epoch 10, gen_loss = 0.8690248995642119, disc_loss = 0.06044293777446057
Trained batch 711 in epoch 10, gen_loss = 0.8687871950312277, disc_loss = 0.06071169652225282
Trained batch 712 in epoch 10, gen_loss = 0.8686620086891287, disc_loss = 0.06067177833895216
Trained batch 713 in epoch 10, gen_loss = 0.8688281899323317, disc_loss = 0.06078348868964788
Trained batch 714 in epoch 10, gen_loss = 0.8683667456770277, disc_loss = 0.061023510136101
Trained batch 715 in epoch 10, gen_loss = 0.8680873852452087, disc_loss = 0.061030423672552424
Trained batch 716 in epoch 10, gen_loss = 0.8679664566842749, disc_loss = 0.061001860933453673
Trained batch 717 in epoch 10, gen_loss = 0.8680773076489775, disc_loss = 0.061100101786533315
Trained batch 718 in epoch 10, gen_loss = 0.8683767540481392, disc_loss = 0.06112385386606271
Trained batch 719 in epoch 10, gen_loss = 0.8681834723800421, disc_loss = 0.061176693365107185
Trained batch 720 in epoch 10, gen_loss = 0.8679816131370243, disc_loss = 0.0611587082340683
Trained batch 721 in epoch 10, gen_loss = 0.8682070312159874, disc_loss = 0.06110100145064749
Trained batch 722 in epoch 10, gen_loss = 0.8684084839593326, disc_loss = 0.06104493744859413
Trained batch 723 in epoch 10, gen_loss = 0.8682657428785582, disc_loss = 0.06100700958053072
Trained batch 724 in epoch 10, gen_loss = 0.8683767865855119, disc_loss = 0.06096246865096277
Trained batch 725 in epoch 10, gen_loss = 0.8683781463334711, disc_loss = 0.0609774608197096
Trained batch 726 in epoch 10, gen_loss = 0.8687875927150496, disc_loss = 0.060926297646876744
Trained batch 727 in epoch 10, gen_loss = 0.8684675430285407, disc_loss = 0.06095160704149588
Trained batch 728 in epoch 10, gen_loss = 0.8683357149239921, disc_loss = 0.06090817978447214
Trained batch 729 in epoch 10, gen_loss = 0.868278697867916, disc_loss = 0.060858455387722346
Trained batch 730 in epoch 10, gen_loss = 0.8686143169243261, disc_loss = 0.060888842324740296
Trained batch 731 in epoch 10, gen_loss = 0.8687053652978985, disc_loss = 0.06081954784922892
Trained batch 732 in epoch 10, gen_loss = 0.8686705965543672, disc_loss = 0.06077704791266771
Trained batch 733 in epoch 10, gen_loss = 0.868429776880007, disc_loss = 0.060814369238319246
Trained batch 734 in epoch 10, gen_loss = 0.8683096879599046, disc_loss = 0.060758055413940124
Trained batch 735 in epoch 10, gen_loss = 0.8681840457265144, disc_loss = 0.06073912625573069
Trained batch 736 in epoch 10, gen_loss = 0.8681289417368424, disc_loss = 0.06068128956926625
Trained batch 737 in epoch 10, gen_loss = 0.8682297475050459, disc_loss = 0.06061420143521353
Trained batch 738 in epoch 10, gen_loss = 0.8680465306496911, disc_loss = 0.06057215746711431
Trained batch 739 in epoch 10, gen_loss = 0.868429791081596, disc_loss = 0.06053247399489722
Trained batch 740 in epoch 10, gen_loss = 0.8685214744325269, disc_loss = 0.060531123885042795
Trained batch 741 in epoch 10, gen_loss = 0.8688112994972265, disc_loss = 0.06047046517343273
Trained batch 742 in epoch 10, gen_loss = 0.8684803962627298, disc_loss = 0.060512114937315675
Trained batch 743 in epoch 10, gen_loss = 0.8686873894785682, disc_loss = 0.06044974347253541
Trained batch 744 in epoch 10, gen_loss = 0.8689336083479375, disc_loss = 0.06037942722077238
Trained batch 745 in epoch 10, gen_loss = 0.869213571936771, disc_loss = 0.060324516526271084
Trained batch 746 in epoch 10, gen_loss = 0.8692659535002677, disc_loss = 0.0602596403072168
Trained batch 747 in epoch 10, gen_loss = 0.8690499872527021, disc_loss = 0.06024041209173175
Trained batch 748 in epoch 10, gen_loss = 0.8689437145305093, disc_loss = 0.060191506744351225
Trained batch 749 in epoch 10, gen_loss = 0.8693347864548365, disc_loss = 0.0601314683885624
Trained batch 750 in epoch 10, gen_loss = 0.8695262151853381, disc_loss = 0.06006461942875969
Trained batch 751 in epoch 10, gen_loss = 0.8700001194201251, disc_loss = 0.06002855498499752
Trained batch 752 in epoch 10, gen_loss = 0.8700775186299962, disc_loss = 0.05997384072604229
Trained batch 753 in epoch 10, gen_loss = 0.8699718634313867, disc_loss = 0.05993247089909998
Trained batch 754 in epoch 10, gen_loss = 0.8700000674124585, disc_loss = 0.05986428072873429
Trained batch 755 in epoch 10, gen_loss = 0.8700398078592366, disc_loss = 0.05979314171672163
Trained batch 756 in epoch 10, gen_loss = 0.869914696545708, disc_loss = 0.059748490649193055
Trained batch 757 in epoch 10, gen_loss = 0.8701676427138513, disc_loss = 0.05967937370192132
Trained batch 758 in epoch 10, gen_loss = 0.8698527554985092, disc_loss = 0.05965405457305853
Trained batch 759 in epoch 10, gen_loss = 0.8700853557570984, disc_loss = 0.05959620295018938
Trained batch 760 in epoch 10, gen_loss = 0.8706035701345051, disc_loss = 0.05960340879774321
Trained batch 761 in epoch 10, gen_loss = 0.8705975971431557, disc_loss = 0.05955213791228772
Trained batch 762 in epoch 10, gen_loss = 0.870490548456012, disc_loss = 0.05950572707740343
Trained batch 763 in epoch 10, gen_loss = 0.8705321872187535, disc_loss = 0.05947940047532905
Trained batch 764 in epoch 10, gen_loss = 0.8704206025288775, disc_loss = 0.05944181277349689
Trained batch 765 in epoch 10, gen_loss = 0.8702176037796484, disc_loss = 0.05940122810355327
Trained batch 766 in epoch 10, gen_loss = 0.8703326133348174, disc_loss = 0.05935544100610692
Trained batch 767 in epoch 10, gen_loss = 0.870611904693457, disc_loss = 0.05934434092705487
Trained batch 768 in epoch 10, gen_loss = 0.8706849582871163, disc_loss = 0.059280574348390645
Trained batch 769 in epoch 10, gen_loss = 0.8703185244427099, disc_loss = 0.05938472454375648
Trained batch 770 in epoch 10, gen_loss = 0.8704937520580688, disc_loss = 0.05938049519601267
Trained batch 771 in epoch 10, gen_loss = 0.8706767730839512, disc_loss = 0.05933956360116292
Trained batch 772 in epoch 10, gen_loss = 0.8708719323939833, disc_loss = 0.05928345349645013
Trained batch 773 in epoch 10, gen_loss = 0.8710537296009926, disc_loss = 0.05922151442487226
Trained batch 774 in epoch 10, gen_loss = 0.8707117897848929, disc_loss = 0.059209900742336626
Trained batch 775 in epoch 10, gen_loss = 0.8707739228824365, disc_loss = 0.05914812048863543
Trained batch 776 in epoch 10, gen_loss = 0.8707971550246156, disc_loss = 0.05911414554532009
Trained batch 777 in epoch 10, gen_loss = 0.8706948241185406, disc_loss = 0.0590582012586717
Trained batch 778 in epoch 10, gen_loss = 0.8710389680902214, disc_loss = 0.05899824423115313
Trained batch 779 in epoch 10, gen_loss = 0.8706704726968056, disc_loss = 0.05904246511487051
Trained batch 780 in epoch 10, gen_loss = 0.8707084582877678, disc_loss = 0.05898089252087966
Trained batch 781 in epoch 10, gen_loss = 0.8711853780786095, disc_loss = 0.059048413060834186
Trained batch 782 in epoch 10, gen_loss = 0.8708999351447265, disc_loss = 0.05905915477276229
Trained batch 783 in epoch 10, gen_loss = 0.8711877218542659, disc_loss = 0.05900984179532649
Trained batch 784 in epoch 10, gen_loss = 0.8709901973320421, disc_loss = 0.05895069107223468
Trained batch 785 in epoch 10, gen_loss = 0.8708591180220815, disc_loss = 0.05889289939430076
Trained batch 786 in epoch 10, gen_loss = 0.870733724426587, disc_loss = 0.0588710874962837
Trained batch 787 in epoch 10, gen_loss = 0.8707951821273353, disc_loss = 0.05886253038525279
Trained batch 788 in epoch 10, gen_loss = 0.8705099486050648, disc_loss = 0.05887165650517617
Trained batch 789 in epoch 10, gen_loss = 0.8705049933134755, disc_loss = 0.05886762153027179
Testing Epoch 10
Training Epoch 11
Trained batch 0 in epoch 11, gen_loss = 0.9327930212020874, disc_loss = 0.019544456154108047
Trained batch 1 in epoch 11, gen_loss = 0.8856440782546997, disc_loss = 0.02467519138008356
Trained batch 2 in epoch 11, gen_loss = 0.9086627960205078, disc_loss = 0.027484473461906116
Trained batch 3 in epoch 11, gen_loss = 0.9481334686279297, disc_loss = 0.02296979958191514
Trained batch 4 in epoch 11, gen_loss = 0.922111177444458, disc_loss = 0.02504274360835552
Trained batch 5 in epoch 11, gen_loss = 0.9205817182858785, disc_loss = 0.026039105529586475
Trained batch 6 in epoch 11, gen_loss = 0.9271548816135952, disc_loss = 0.03135351464152336
Trained batch 7 in epoch 11, gen_loss = 0.8996635004878044, disc_loss = 0.03501542052254081
Trained batch 8 in epoch 11, gen_loss = 0.8978595733642578, disc_loss = 0.03248629139529334
Trained batch 9 in epoch 11, gen_loss = 0.8837638795375824, disc_loss = 0.033336276188492775
Trained batch 10 in epoch 11, gen_loss = 0.9057492071932013, disc_loss = 0.04509016634388403
Trained batch 11 in epoch 11, gen_loss = 0.9072939654191335, disc_loss = 0.04486940956364075
Trained batch 12 in epoch 11, gen_loss = 0.8919908954547002, disc_loss = 0.04604232024687987
Trained batch 13 in epoch 11, gen_loss = 0.9180706696850913, disc_loss = 0.049100479909351895
Trained batch 14 in epoch 11, gen_loss = 0.9302464604377747, disc_loss = 0.04862973888715108
Trained batch 15 in epoch 11, gen_loss = 0.9191539771854877, disc_loss = 0.0496400473639369
Trained batch 16 in epoch 11, gen_loss = 0.9138030164382037, disc_loss = 0.05004684407921398
Trained batch 17 in epoch 11, gen_loss = 0.9105810655487908, disc_loss = 0.049510198127892285
Trained batch 18 in epoch 11, gen_loss = 0.9080472306201333, disc_loss = 0.04863041345226137
Trained batch 19 in epoch 11, gen_loss = 0.9078652739524842, disc_loss = 0.04767637401819229
Trained batch 20 in epoch 11, gen_loss = 0.9004585686184111, disc_loss = 0.04663799055630252
Trained batch 21 in epoch 11, gen_loss = 0.9007075754078951, disc_loss = 0.04509110003709793
Trained batch 22 in epoch 11, gen_loss = 0.9051336050033569, disc_loss = 0.04402529010954111
Trained batch 23 in epoch 11, gen_loss = 0.9018854995568594, disc_loss = 0.04333038783321778
Trained batch 24 in epoch 11, gen_loss = 0.9079412841796874, disc_loss = 0.041976343095302585
Trained batch 25 in epoch 11, gen_loss = 0.9027519592872033, disc_loss = 0.042574928930172555
Trained batch 26 in epoch 11, gen_loss = 0.906945820207949, disc_loss = 0.04133742561356889
Trained batch 27 in epoch 11, gen_loss = 0.9000918141433171, disc_loss = 0.042088741004200916
Trained batch 28 in epoch 11, gen_loss = 0.9036377668380737, disc_loss = 0.04175555124750425
Trained batch 29 in epoch 11, gen_loss = 0.893755050500234, disc_loss = 0.04398114293192824
Trained batch 30 in epoch 11, gen_loss = 0.8872416980804936, disc_loss = 0.044166617906622345
Trained batch 31 in epoch 11, gen_loss = 0.8857832662761211, disc_loss = 0.044515738351037726
Trained batch 32 in epoch 11, gen_loss = 0.8959887786345049, disc_loss = 0.05138585882995165
Trained batch 33 in epoch 11, gen_loss = 0.8951287900700289, disc_loss = 0.05077541814021328
Trained batch 34 in epoch 11, gen_loss = 0.8827994585037231, disc_loss = 0.05550632793456316
Trained batch 35 in epoch 11, gen_loss = 0.8783731063206991, disc_loss = 0.059696089243516326
Trained batch 36 in epoch 11, gen_loss = 0.8761899890126409, disc_loss = 0.05949432722519379
Trained batch 37 in epoch 11, gen_loss = 0.8721443132350319, disc_loss = 0.05975719421219669
Trained batch 38 in epoch 11, gen_loss = 0.8754134728358343, disc_loss = 0.0598547370531238
Trained batch 39 in epoch 11, gen_loss = 0.8741952419281006, disc_loss = 0.059187267511151734
Trained batch 40 in epoch 11, gen_loss = 0.871672874543725, disc_loss = 0.06381926029102832
Trained batch 41 in epoch 11, gen_loss = 0.8667393511249906, disc_loss = 0.06694154385920792
Trained batch 42 in epoch 11, gen_loss = 0.8710202491560648, disc_loss = 0.06786589599539374
Trained batch 43 in epoch 11, gen_loss = 0.8677359575575049, disc_loss = 0.06709130715832791
Trained batch 44 in epoch 11, gen_loss = 0.8581894040107727, disc_loss = 0.06965324876623022
Trained batch 45 in epoch 11, gen_loss = 0.8600368823694147, disc_loss = 0.06933553263787991
Trained batch 46 in epoch 11, gen_loss = 0.8684112125254692, disc_loss = 0.07124655176588196
Trained batch 47 in epoch 11, gen_loss = 0.8621918770174185, disc_loss = 0.07305906998226419
Trained batch 48 in epoch 11, gen_loss = 0.8613502723830087, disc_loss = 0.07284374936122676
Trained batch 49 in epoch 11, gen_loss = 0.8631236183643342, disc_loss = 0.07196630084887147
Trained batch 50 in epoch 11, gen_loss = 0.8630111533052781, disc_loss = 0.07144309231536645
Trained batch 51 in epoch 11, gen_loss = 0.8595922726851243, disc_loss = 0.07153667454034664
Trained batch 52 in epoch 11, gen_loss = 0.8565456079986861, disc_loss = 0.07126549626085556
Trained batch 53 in epoch 11, gen_loss = 0.8608709043926663, disc_loss = 0.07110279814029734
Trained batch 54 in epoch 11, gen_loss = 0.8584764242172241, disc_loss = 0.0710273844443939
Trained batch 55 in epoch 11, gen_loss = 0.8573364594152996, disc_loss = 0.07037092866708658
Trained batch 56 in epoch 11, gen_loss = 0.8626081629803306, disc_loss = 0.06943297521783072
Trained batch 57 in epoch 11, gen_loss = 0.8643614074279522, disc_loss = 0.06879969312135002
Trained batch 58 in epoch 11, gen_loss = 0.8645397485312769, disc_loss = 0.0687955473786441
Trained batch 59 in epoch 11, gen_loss = 0.8601961592833202, disc_loss = 0.07052493267692625
Trained batch 60 in epoch 11, gen_loss = 0.8590714335441589, disc_loss = 0.06979847423060508
Trained batch 61 in epoch 11, gen_loss = 0.8638829617731033, disc_loss = 0.07049211287390321
Trained batch 62 in epoch 11, gen_loss = 0.8637630646190946, disc_loss = 0.0696292437819971
Trained batch 63 in epoch 11, gen_loss = 0.8618180109187961, disc_loss = 0.0690013898856705
Trained batch 64 in epoch 11, gen_loss = 0.8569620609283447, disc_loss = 0.06990349153773143
Trained batch 65 in epoch 11, gen_loss = 0.8578151473493287, disc_loss = 0.06988744357262146
Trained batch 66 in epoch 11, gen_loss = 0.8603096515385072, disc_loss = 0.06988169229241895
Trained batch 67 in epoch 11, gen_loss = 0.8614025045843685, disc_loss = 0.06902750369216151
Trained batch 68 in epoch 11, gen_loss = 0.8628257720366769, disc_loss = 0.06819450040010439
Trained batch 69 in epoch 11, gen_loss = 0.8601877672331674, disc_loss = 0.068410670916949
Trained batch 70 in epoch 11, gen_loss = 0.8607021880821443, disc_loss = 0.06813648385061345
Trained batch 71 in epoch 11, gen_loss = 0.8583949622180727, disc_loss = 0.06848816780580415
Trained batch 72 in epoch 11, gen_loss = 0.8563292614401203, disc_loss = 0.06851772157704994
Trained batch 73 in epoch 11, gen_loss = 0.8564468348348463, disc_loss = 0.06817920012651263
Trained batch 74 in epoch 11, gen_loss = 0.8595117457707723, disc_loss = 0.06816881606976191
Trained batch 75 in epoch 11, gen_loss = 0.8596453619630713, disc_loss = 0.06759128062740753
Trained batch 76 in epoch 11, gen_loss = 0.8540780544281006, disc_loss = 0.06961535681764801
Trained batch 77 in epoch 11, gen_loss = 0.8593473587280664, disc_loss = 0.06977518867605771
Trained batch 78 in epoch 11, gen_loss = 0.8604823365996156, disc_loss = 0.07186199187100688
Trained batch 79 in epoch 11, gen_loss = 0.8587070792913437, disc_loss = 0.07199141886085272
Trained batch 80 in epoch 11, gen_loss = 0.8558002254109324, disc_loss = 0.07272000279691485
Trained batch 81 in epoch 11, gen_loss = 0.8571103731306587, disc_loss = 0.07307550956199808
Trained batch 82 in epoch 11, gen_loss = 0.8547847371503531, disc_loss = 0.07316274806318512
Trained batch 83 in epoch 11, gen_loss = 0.8536795462880816, disc_loss = 0.07288480918144896
Trained batch 84 in epoch 11, gen_loss = 0.8529058477457832, disc_loss = 0.07238086352453513
Trained batch 85 in epoch 11, gen_loss = 0.8525321878666101, disc_loss = 0.07218430490168028
Trained batch 86 in epoch 11, gen_loss = 0.8571876554653562, disc_loss = 0.07321577240852103
Trained batch 87 in epoch 11, gen_loss = 0.8509132354096933, disc_loss = 0.07555594502694228
Trained batch 88 in epoch 11, gen_loss = 0.8495081991292117, disc_loss = 0.07620039837581388
Trained batch 89 in epoch 11, gen_loss = 0.8493237647745344, disc_loss = 0.07785544598268138
Trained batch 90 in epoch 11, gen_loss = 0.8477176958388024, disc_loss = 0.0778489775628179
Trained batch 91 in epoch 11, gen_loss = 0.8475581116002538, disc_loss = 0.07742097038451744
Trained batch 92 in epoch 11, gen_loss = 0.8480777464887147, disc_loss = 0.07685311621315377
Trained batch 93 in epoch 11, gen_loss = 0.8479645264909622, disc_loss = 0.07622622280441066
Trained batch 94 in epoch 11, gen_loss = 0.8485264640105398, disc_loss = 0.07583972758760578
Trained batch 95 in epoch 11, gen_loss = 0.8496068666378657, disc_loss = 0.07538070492834474
Trained batch 96 in epoch 11, gen_loss = 0.8483715979094358, disc_loss = 0.07492365371243856
Trained batch 97 in epoch 11, gen_loss = 0.8479751482301828, disc_loss = 0.0746975895587583
Trained batch 98 in epoch 11, gen_loss = 0.8479123886185463, disc_loss = 0.07424114100785568
Trained batch 99 in epoch 11, gen_loss = 0.8457806897163391, disc_loss = 0.07490990338847041
Trained batch 100 in epoch 11, gen_loss = 0.8481531473669676, disc_loss = 0.07440271191667802
Trained batch 101 in epoch 11, gen_loss = 0.850274947344088, disc_loss = 0.0738409115549396
Trained batch 102 in epoch 11, gen_loss = 0.8491310268929861, disc_loss = 0.0736691841078036
Trained batch 103 in epoch 11, gen_loss = 0.8478049091421641, disc_loss = 0.07366894550908071
Trained batch 104 in epoch 11, gen_loss = 0.8466803545043582, disc_loss = 0.07325095770259699
Trained batch 105 in epoch 11, gen_loss = 0.8493909402838293, disc_loss = 0.07280275016531067
Trained batch 106 in epoch 11, gen_loss = 0.852031239282305, disc_loss = 0.07229096395459687
Trained batch 107 in epoch 11, gen_loss = 0.8555483635928895, disc_loss = 0.07181296682123232
Trained batch 108 in epoch 11, gen_loss = 0.85435456256254, disc_loss = 0.07201290908141421
Trained batch 109 in epoch 11, gen_loss = 0.8541279966180975, disc_loss = 0.072161641090431
Trained batch 110 in epoch 11, gen_loss = 0.8532298572428592, disc_loss = 0.07176778487324177
Trained batch 111 in epoch 11, gen_loss = 0.8531740989003863, disc_loss = 0.0715994084686307
Trained batch 112 in epoch 11, gen_loss = 0.8509621504133782, disc_loss = 0.07227318715798643
Trained batch 113 in epoch 11, gen_loss = 0.8505854167436299, disc_loss = 0.07211154714030654
Trained batch 114 in epoch 11, gen_loss = 0.8516168298928634, disc_loss = 0.07175376275959222
Trained batch 115 in epoch 11, gen_loss = 0.8521237039360506, disc_loss = 0.07153745942973885
Trained batch 116 in epoch 11, gen_loss = 0.8559026733422891, disc_loss = 0.071975542152794
Trained batch 117 in epoch 11, gen_loss = 0.8548370119878801, disc_loss = 0.07161124828824048
Trained batch 118 in epoch 11, gen_loss = 0.8515229337856549, disc_loss = 0.07320740789237644
Trained batch 119 in epoch 11, gen_loss = 0.8497537684937319, disc_loss = 0.0738795053989937
Trained batch 120 in epoch 11, gen_loss = 0.8513056948657863, disc_loss = 0.07439788087648301
Trained batch 121 in epoch 11, gen_loss = 0.8521603245715625, disc_loss = 0.07458724070828958
Trained batch 122 in epoch 11, gen_loss = 0.8518936117974724, disc_loss = 0.0745392732655372
Trained batch 123 in epoch 11, gen_loss = 0.8515275594207549, disc_loss = 0.07418818279139457
Trained batch 124 in epoch 11, gen_loss = 0.8505495460033416, disc_loss = 0.07441199231147766
Trained batch 125 in epoch 11, gen_loss = 0.8489663882388009, disc_loss = 0.07454946282364074
Trained batch 126 in epoch 11, gen_loss = 0.849279416593041, disc_loss = 0.07407515163086062
Trained batch 127 in epoch 11, gen_loss = 0.851588818943128, disc_loss = 0.07382282831531484
Trained batch 128 in epoch 11, gen_loss = 0.8503803502219592, disc_loss = 0.07409161065033702
Trained batch 129 in epoch 11, gen_loss = 0.8508175379954852, disc_loss = 0.0736564189912035
Trained batch 130 in epoch 11, gen_loss = 0.8501256429057085, disc_loss = 0.07338752886209324
Trained batch 131 in epoch 11, gen_loss = 0.8488780465541463, disc_loss = 0.07324067400203961
Trained batch 132 in epoch 11, gen_loss = 0.8506732585286736, disc_loss = 0.07317996651102278
Trained batch 133 in epoch 11, gen_loss = 0.8503642582626485, disc_loss = 0.07286217459824992
Trained batch 134 in epoch 11, gen_loss = 0.8483876906059407, disc_loss = 0.07299299903765873
Trained batch 135 in epoch 11, gen_loss = 0.847591569975895, disc_loss = 0.07258280483074486
Trained batch 136 in epoch 11, gen_loss = 0.8500056630068452, disc_loss = 0.07262855236602091
Trained batch 137 in epoch 11, gen_loss = 0.8499140331278676, disc_loss = 0.07221504724652007
Trained batch 138 in epoch 11, gen_loss = 0.848592910620806, disc_loss = 0.0720245386038324
Trained batch 139 in epoch 11, gen_loss = 0.8481379758034434, disc_loss = 0.07168452779629401
Trained batch 140 in epoch 11, gen_loss = 0.8491260153604737, disc_loss = 0.07155712083616156
Trained batch 141 in epoch 11, gen_loss = 0.8488188526580032, disc_loss = 0.07166747725240781
Trained batch 142 in epoch 11, gen_loss = 0.8475414020615024, disc_loss = 0.07175074457809642
Trained batch 143 in epoch 11, gen_loss = 0.8476841571844287, disc_loss = 0.07144671604813387
Trained batch 144 in epoch 11, gen_loss = 0.8512553566488726, disc_loss = 0.07185664309252952
Trained batch 145 in epoch 11, gen_loss = 0.850231240669342, disc_loss = 0.07184951419444525
Trained batch 146 in epoch 11, gen_loss = 0.850390728030886, disc_loss = 0.07159586366088617
Trained batch 147 in epoch 11, gen_loss = 0.8510667321247023, disc_loss = 0.0711917635934377
Trained batch 148 in epoch 11, gen_loss = 0.8509311922044562, disc_loss = 0.0712764003007804
Trained batch 149 in epoch 11, gen_loss = 0.8514283814032872, disc_loss = 0.0708946380764246
Trained batch 150 in epoch 11, gen_loss = 0.8504514763292098, disc_loss = 0.07078603598357036
Trained batch 151 in epoch 11, gen_loss = 0.8508547283709049, disc_loss = 0.07056718763258112
Trained batch 152 in epoch 11, gen_loss = 0.852918905954735, disc_loss = 0.07047462675209139
Trained batch 153 in epoch 11, gen_loss = 0.8515155487633371, disc_loss = 0.07073859219717515
Trained batch 154 in epoch 11, gen_loss = 0.8518664327359968, disc_loss = 0.0709961160296394
Trained batch 155 in epoch 11, gen_loss = 0.8515144645785674, disc_loss = 0.07091944043835004
Trained batch 156 in epoch 11, gen_loss = 0.8524692588171382, disc_loss = 0.07073113395814683
Trained batch 157 in epoch 11, gen_loss = 0.852677532955061, disc_loss = 0.07044299043526378
Trained batch 158 in epoch 11, gen_loss = 0.8545111813260324, disc_loss = 0.0702727347987253
Trained batch 159 in epoch 11, gen_loss = 0.8527173435315489, disc_loss = 0.070969161670655
Trained batch 160 in epoch 11, gen_loss = 0.8531138280533855, disc_loss = 0.07094722592867679
Trained batch 161 in epoch 11, gen_loss = 0.8525397731566134, disc_loss = 0.07078337952218673
Trained batch 162 in epoch 11, gen_loss = 0.8521621649616336, disc_loss = 0.07077027361360064
Trained batch 163 in epoch 11, gen_loss = 0.851350449025631, disc_loss = 0.0707930779175424
Trained batch 164 in epoch 11, gen_loss = 0.8520456352017143, disc_loss = 0.07043771379147515
Trained batch 165 in epoch 11, gen_loss = 0.8507175777690956, disc_loss = 0.07059244875493179
Trained batch 166 in epoch 11, gen_loss = 0.8507264636590809, disc_loss = 0.07041331221109735
Trained batch 167 in epoch 11, gen_loss = 0.8525363737273783, disc_loss = 0.07059777205410812
Trained batch 168 in epoch 11, gen_loss = 0.8537054229417497, disc_loss = 0.07032556061429032
Trained batch 169 in epoch 11, gen_loss = 0.85247562965926, disc_loss = 0.07059638645938214
Trained batch 170 in epoch 11, gen_loss = 0.8518275878234216, disc_loss = 0.07043875552365306
Trained batch 171 in epoch 11, gen_loss = 0.8539006604358207, disc_loss = 0.0712882460441527
Trained batch 172 in epoch 11, gen_loss = 0.8520781489121432, disc_loss = 0.07133603796922747
Trained batch 173 in epoch 11, gen_loss = 0.8512491678026901, disc_loss = 0.07126550846358483
Trained batch 174 in epoch 11, gen_loss = 0.8512796441146305, disc_loss = 0.07127246638493878
Trained batch 175 in epoch 11, gen_loss = 0.8513760866427963, disc_loss = 0.07112059616272083
Trained batch 176 in epoch 11, gen_loss = 0.8509572894222992, disc_loss = 0.07100012343860952
Trained batch 177 in epoch 11, gen_loss = 0.8502629933397422, disc_loss = 0.07095351242826561
Trained batch 178 in epoch 11, gen_loss = 0.8498025877848684, disc_loss = 0.07088818760099691
Trained batch 179 in epoch 11, gen_loss = 0.8512311490045653, disc_loss = 0.0715881743054423
Trained batch 180 in epoch 11, gen_loss = 0.8492415219710018, disc_loss = 0.07242417283026882
Trained batch 181 in epoch 11, gen_loss = 0.8481636274974425, disc_loss = 0.07228176546497987
Trained batch 182 in epoch 11, gen_loss = 0.8510018181605418, disc_loss = 0.07248717506767297
Trained batch 183 in epoch 11, gen_loss = 0.8516367970277434, disc_loss = 0.07233671043270631
Trained batch 184 in epoch 11, gen_loss = 0.8505664727172336, disc_loss = 0.07233139708436824
Trained batch 185 in epoch 11, gen_loss = 0.8496622034618931, disc_loss = 0.072296331336181
Trained batch 186 in epoch 11, gen_loss = 0.8502955498861119, disc_loss = 0.0719769097077735
Trained batch 187 in epoch 11, gen_loss = 0.8523540374763469, disc_loss = 0.07255427092016536
Trained batch 188 in epoch 11, gen_loss = 0.852923516085539, disc_loss = 0.07233709970577842
Trained batch 189 in epoch 11, gen_loss = 0.8516392514893883, disc_loss = 0.0723598765552436
Trained batch 190 in epoch 11, gen_loss = 0.8505583740965859, disc_loss = 0.07229006975518627
Trained batch 191 in epoch 11, gen_loss = 0.8519276493849853, disc_loss = 0.07235621659492608
Trained batch 192 in epoch 11, gen_loss = 0.853690959165751, disc_loss = 0.07230835248248102
Trained batch 193 in epoch 11, gen_loss = 0.8528516927023524, disc_loss = 0.07230807739530795
Trained batch 194 in epoch 11, gen_loss = 0.853258852316783, disc_loss = 0.07212050011238226
Trained batch 195 in epoch 11, gen_loss = 0.8533687018314187, disc_loss = 0.07180349301185687
Trained batch 196 in epoch 11, gen_loss = 0.8521345431732043, disc_loss = 0.07195875881154676
Trained batch 197 in epoch 11, gen_loss = 0.8539557018966386, disc_loss = 0.07178397605082754
Trained batch 198 in epoch 11, gen_loss = 0.8542258489371544, disc_loss = 0.07157132310802164
Trained batch 199 in epoch 11, gen_loss = 0.8545210708677768, disc_loss = 0.07135694504249841
Trained batch 200 in epoch 11, gen_loss = 0.8555634930655731, disc_loss = 0.07117120985089992
Trained batch 201 in epoch 11, gen_loss = 0.8549583337389597, disc_loss = 0.07121112356700077
Trained batch 202 in epoch 11, gen_loss = 0.8543117303272774, disc_loss = 0.07099756146574696
Trained batch 203 in epoch 11, gen_loss = 0.8551303211088274, disc_loss = 0.07073179521488354
Trained batch 204 in epoch 11, gen_loss = 0.8563086479175381, disc_loss = 0.0705153504113962
Trained batch 205 in epoch 11, gen_loss = 0.8560380668026729, disc_loss = 0.07029868452131603
Trained batch 206 in epoch 11, gen_loss = 0.8557230402594027, disc_loss = 0.07007579158559657
Trained batch 207 in epoch 11, gen_loss = 0.8559369411892616, disc_loss = 0.06978738953162414
Trained batch 208 in epoch 11, gen_loss = 0.8553767730459643, disc_loss = 0.06957411905527827
Trained batch 209 in epoch 11, gen_loss = 0.8558483499856222, disc_loss = 0.06930737899438966
Trained batch 210 in epoch 11, gen_loss = 0.8554846320954544, disc_loss = 0.06908846227672852
Trained batch 211 in epoch 11, gen_loss = 0.8564752662238085, disc_loss = 0.06905274212202232
Trained batch 212 in epoch 11, gen_loss = 0.8566230170323815, disc_loss = 0.06879352808365939
Trained batch 213 in epoch 11, gen_loss = 0.8569908330095148, disc_loss = 0.06855006983817041
Trained batch 214 in epoch 11, gen_loss = 0.8571988231913988, disc_loss = 0.06830549750823614
Trained batch 215 in epoch 11, gen_loss = 0.8570545016339531, disc_loss = 0.06814193230174068
Trained batch 216 in epoch 11, gen_loss = 0.8591883763464915, disc_loss = 0.06806205123371106
Trained batch 217 in epoch 11, gen_loss = 0.8604126855594303, disc_loss = 0.0678393347316994
Trained batch 218 in epoch 11, gen_loss = 0.8611344337191211, disc_loss = 0.06757511504283642
Trained batch 219 in epoch 11, gen_loss = 0.8610602542757988, disc_loss = 0.06734073641709984
Trained batch 220 in epoch 11, gen_loss = 0.8608831427485695, disc_loss = 0.06711932737380266
Trained batch 221 in epoch 11, gen_loss = 0.8614565006516002, disc_loss = 0.06688043911865837
Trained batch 222 in epoch 11, gen_loss = 0.8601603624264755, disc_loss = 0.06710879130898703
Trained batch 223 in epoch 11, gen_loss = 0.8622340164812548, disc_loss = 0.06783419388895189
Trained batch 224 in epoch 11, gen_loss = 0.8619895403914981, disc_loss = 0.06775823722696966
Trained batch 225 in epoch 11, gen_loss = 0.8616395016423369, disc_loss = 0.0675614262205771
Trained batch 226 in epoch 11, gen_loss = 0.861020620042532, disc_loss = 0.06746733841375502
Trained batch 227 in epoch 11, gen_loss = 0.8617665416054558, disc_loss = 0.06769570554279837
Trained batch 228 in epoch 11, gen_loss = 0.8625114696775461, disc_loss = 0.06775618721547996
Trained batch 229 in epoch 11, gen_loss = 0.8611539137104284, disc_loss = 0.06894537342874252
Trained batch 230 in epoch 11, gen_loss = 0.8597292261464256, disc_loss = 0.06909835093062032
Trained batch 231 in epoch 11, gen_loss = 0.8606796995576086, disc_loss = 0.06934409189953245
Trained batch 232 in epoch 11, gen_loss = 0.8610656316444086, disc_loss = 0.0692021958649862
Trained batch 233 in epoch 11, gen_loss = 0.8609324786652867, disc_loss = 0.06927669184823704
Trained batch 234 in epoch 11, gen_loss = 0.8609860784195839, disc_loss = 0.06910491423641747
Trained batch 235 in epoch 11, gen_loss = 0.8610912449026512, disc_loss = 0.06894815453896457
Trained batch 236 in epoch 11, gen_loss = 0.8613697168444783, disc_loss = 0.06876648646162406
Trained batch 237 in epoch 11, gen_loss = 0.8619200811416161, disc_loss = 0.06861034259121834
Trained batch 238 in epoch 11, gen_loss = 0.8619582851312151, disc_loss = 0.06837340486800945
Trained batch 239 in epoch 11, gen_loss = 0.8610226975133022, disc_loss = 0.06845865652042751
Trained batch 240 in epoch 11, gen_loss = 0.8620506308632767, disc_loss = 0.06839808723135732
Trained batch 241 in epoch 11, gen_loss = 0.8625245171883875, disc_loss = 0.06823350927476918
Trained batch 242 in epoch 11, gen_loss = 0.8617997516575173, disc_loss = 0.06833799963303432
Trained batch 243 in epoch 11, gen_loss = 0.8621496586281745, disc_loss = 0.06844350275369819
Trained batch 244 in epoch 11, gen_loss = 0.8614002421194193, disc_loss = 0.06842812361689854
Trained batch 245 in epoch 11, gen_loss = 0.8613860613204599, disc_loss = 0.06834464407775824
Trained batch 246 in epoch 11, gen_loss = 0.861602280424674, disc_loss = 0.06818479796124977
Trained batch 247 in epoch 11, gen_loss = 0.8618552128393804, disc_loss = 0.06798708877120647
Trained batch 248 in epoch 11, gen_loss = 0.8611605388811793, disc_loss = 0.06804121602476242
Trained batch 249 in epoch 11, gen_loss = 0.861449480175972, disc_loss = 0.06827803280577063
Trained batch 250 in epoch 11, gen_loss = 0.8617944794584556, disc_loss = 0.06806153364746693
Trained batch 251 in epoch 11, gen_loss = 0.8623043176910233, disc_loss = 0.06789202130000506
Trained batch 252 in epoch 11, gen_loss = 0.862430211230229, disc_loss = 0.06775478373020298
Trained batch 253 in epoch 11, gen_loss = 0.8627933124153633, disc_loss = 0.06764585045936304
Trained batch 254 in epoch 11, gen_loss = 0.8618126716099533, disc_loss = 0.06774869680258573
Trained batch 255 in epoch 11, gen_loss = 0.8626867729471996, disc_loss = 0.06788573902304051
Trained batch 256 in epoch 11, gen_loss = 0.8626121330122075, disc_loss = 0.06766713833153712
Trained batch 257 in epoch 11, gen_loss = 0.8633942230958347, disc_loss = 0.06745949197676061
Trained batch 258 in epoch 11, gen_loss = 0.8632479380226503, disc_loss = 0.06725401687705494
Trained batch 259 in epoch 11, gen_loss = 0.8640294422323888, disc_loss = 0.06703865011939063
Trained batch 260 in epoch 11, gen_loss = 0.8639461134357014, disc_loss = 0.06702521991098863
Trained batch 261 in epoch 11, gen_loss = 0.8645074607534263, disc_loss = 0.06685037842333202
Trained batch 262 in epoch 11, gen_loss = 0.864821003757049, disc_loss = 0.06667212441124504
Trained batch 263 in epoch 11, gen_loss = 0.8644962436096235, disc_loss = 0.06666289531329478
Trained batch 264 in epoch 11, gen_loss = 0.8649236482269359, disc_loss = 0.06650716318344732
Trained batch 265 in epoch 11, gen_loss = 0.8662768737938171, disc_loss = 0.06640302632494192
Trained batch 266 in epoch 11, gen_loss = 0.8670112324341406, disc_loss = 0.0661793624989214
Trained batch 267 in epoch 11, gen_loss = 0.867605720549377, disc_loss = 0.06599714900992477
Trained batch 268 in epoch 11, gen_loss = 0.8679478727973526, disc_loss = 0.06584885300285975
Trained batch 269 in epoch 11, gen_loss = 0.8684933769482154, disc_loss = 0.06571099140025952
Trained batch 270 in epoch 11, gen_loss = 0.8690116714507451, disc_loss = 0.0655121137267769
Trained batch 271 in epoch 11, gen_loss = 0.8688478418351973, disc_loss = 0.06533539880012326
Trained batch 272 in epoch 11, gen_loss = 0.8678629316471436, disc_loss = 0.06544971644823805
Trained batch 273 in epoch 11, gen_loss = 0.8694604266516484, disc_loss = 0.06543035725009268
Trained batch 274 in epoch 11, gen_loss = 0.8703899757428603, disc_loss = 0.06540132816542278
Trained batch 275 in epoch 11, gen_loss = 0.8696388091514076, disc_loss = 0.06541611520114585
Trained batch 276 in epoch 11, gen_loss = 0.868439507505954, disc_loss = 0.06630506956889311
Trained batch 277 in epoch 11, gen_loss = 0.8685538015134043, disc_loss = 0.06613580724425452
Trained batch 278 in epoch 11, gen_loss = 0.8685042218281804, disc_loss = 0.06642421078617855
Trained batch 279 in epoch 11, gen_loss = 0.868015637674502, disc_loss = 0.0663477317563125
Trained batch 280 in epoch 11, gen_loss = 0.8670202006860984, disc_loss = 0.06641263069313191
Trained batch 281 in epoch 11, gen_loss = 0.8666686716865986, disc_loss = 0.06626481815168621
Trained batch 282 in epoch 11, gen_loss = 0.8666898539757139, disc_loss = 0.0662996672988991
Trained batch 283 in epoch 11, gen_loss = 0.8663754321529832, disc_loss = 0.06621306264956653
Trained batch 284 in epoch 11, gen_loss = 0.8667272566703328, disc_loss = 0.06614203341958816
Trained batch 285 in epoch 11, gen_loss = 0.866612224833115, disc_loss = 0.06604765609584072
Trained batch 286 in epoch 11, gen_loss = 0.8662697765262285, disc_loss = 0.06599614170837485
Trained batch 287 in epoch 11, gen_loss = 0.8652279858166972, disc_loss = 0.06606502446811646
Trained batch 288 in epoch 11, gen_loss = 0.8656333490020264, disc_loss = 0.06611701442657045
Trained batch 289 in epoch 11, gen_loss = 0.8665452549169803, disc_loss = 0.0661247020523096
Trained batch 290 in epoch 11, gen_loss = 0.8660184356969657, disc_loss = 0.06624673858694605
Trained batch 291 in epoch 11, gen_loss = 0.8666723377696456, disc_loss = 0.06612074707494411
Trained batch 292 in epoch 11, gen_loss = 0.8657062152343399, disc_loss = 0.06616220845119335
Trained batch 293 in epoch 11, gen_loss = 0.866608707373645, disc_loss = 0.06605479703443189
Trained batch 294 in epoch 11, gen_loss = 0.8677533611402674, disc_loss = 0.06596704228323395
Trained batch 295 in epoch 11, gen_loss = 0.8670268369888937, disc_loss = 0.06593330797890352
Trained batch 296 in epoch 11, gen_loss = 0.8653335309389866, disc_loss = 0.0663923312053837
Trained batch 297 in epoch 11, gen_loss = 0.8652216647095328, disc_loss = 0.066359803211819
Trained batch 298 in epoch 11, gen_loss = 0.8652455642271202, disc_loss = 0.06653400543566332
Trained batch 299 in epoch 11, gen_loss = 0.864560349881649, disc_loss = 0.06654263422514002
Trained batch 300 in epoch 11, gen_loss = 0.8654976997066574, disc_loss = 0.06664328564861882
Trained batch 301 in epoch 11, gen_loss = 0.8646944513581446, disc_loss = 0.06688039646860187
Trained batch 302 in epoch 11, gen_loss = 0.8642242058078842, disc_loss = 0.0667900974023165
Trained batch 303 in epoch 11, gen_loss = 0.8646667477135596, disc_loss = 0.06718150789138715
Trained batch 304 in epoch 11, gen_loss = 0.8646897526060948, disc_loss = 0.06703067735203955
Trained batch 305 in epoch 11, gen_loss = 0.8645217166422239, disc_loss = 0.06684798746083687
Trained batch 306 in epoch 11, gen_loss = 0.8647739488255317, disc_loss = 0.06671815257555887
Trained batch 307 in epoch 11, gen_loss = 0.8640360864145415, disc_loss = 0.06704421536150304
Trained batch 308 in epoch 11, gen_loss = 0.8647901789077277, disc_loss = 0.0676189406524777
Trained batch 309 in epoch 11, gen_loss = 0.8646891987131488, disc_loss = 0.0675042770322292
Trained batch 310 in epoch 11, gen_loss = 0.8638999984387032, disc_loss = 0.06757648638973665
Trained batch 311 in epoch 11, gen_loss = 0.863801799619045, disc_loss = 0.06755556471836872
Trained batch 312 in epoch 11, gen_loss = 0.8631189790206214, disc_loss = 0.06741771249534985
Trained batch 313 in epoch 11, gen_loss = 0.8631075707021033, disc_loss = 0.0672668682435041
Trained batch 314 in epoch 11, gen_loss = 0.8631794735552772, disc_loss = 0.06716621438307421
Trained batch 315 in epoch 11, gen_loss = 0.8632783417271662, disc_loss = 0.06714990529337828
Trained batch 316 in epoch 11, gen_loss = 0.8634397747576801, disc_loss = 0.06698805073199776
Trained batch 317 in epoch 11, gen_loss = 0.8628745711636994, disc_loss = 0.06692729432885565
Trained batch 318 in epoch 11, gen_loss = 0.8633708605385125, disc_loss = 0.06687877370996348
Trained batch 319 in epoch 11, gen_loss = 0.8628185921348631, disc_loss = 0.06687566714244894
Trained batch 320 in epoch 11, gen_loss = 0.8631082642301221, disc_loss = 0.06673115212760425
Trained batch 321 in epoch 11, gen_loss = 0.862762710970381, disc_loss = 0.06660993164115996
Trained batch 322 in epoch 11, gen_loss = 0.8634408205839872, disc_loss = 0.06647404957989421
Trained batch 323 in epoch 11, gen_loss = 0.8642345220770364, disc_loss = 0.06636025906069043
Trained batch 324 in epoch 11, gen_loss = 0.863863609295625, disc_loss = 0.06638074063337766
Trained batch 325 in epoch 11, gen_loss = 0.8640284639743209, disc_loss = 0.06624659323962005
Trained batch 326 in epoch 11, gen_loss = 0.8633911967824358, disc_loss = 0.06636891652479632
Trained batch 327 in epoch 11, gen_loss = 0.863310379316894, disc_loss = 0.06629139629601524
Trained batch 328 in epoch 11, gen_loss = 0.863938247994449, disc_loss = 0.06685826290500743
Trained batch 329 in epoch 11, gen_loss = 0.8634943327217391, disc_loss = 0.06682410984666962
Trained batch 330 in epoch 11, gen_loss = 0.8624323866698677, disc_loss = 0.06707660187024544
Trained batch 331 in epoch 11, gen_loss = 0.8625660500074007, disc_loss = 0.06712135990677648
Trained batch 332 in epoch 11, gen_loss = 0.861851090693975, disc_loss = 0.06744490625957648
Trained batch 333 in epoch 11, gen_loss = 0.8627087694263744, disc_loss = 0.06779471873500925
Trained batch 334 in epoch 11, gen_loss = 0.8619024944839193, disc_loss = 0.06777780024306988
Trained batch 335 in epoch 11, gen_loss = 0.8616788425438461, disc_loss = 0.06770066982911278
Trained batch 336 in epoch 11, gen_loss = 0.8614204933629191, disc_loss = 0.06772706292304334
Trained batch 337 in epoch 11, gen_loss = 0.8617884942589427, disc_loss = 0.06812701916002487
Trained batch 338 in epoch 11, gen_loss = 0.862609008332621, disc_loss = 0.06801173295880665
Trained batch 339 in epoch 11, gen_loss = 0.8616577494670363, disc_loss = 0.06901311456390163
Trained batch 340 in epoch 11, gen_loss = 0.8608252130820255, disc_loss = 0.069154818982017
Trained batch 341 in epoch 11, gen_loss = 0.8612674944407759, disc_loss = 0.06928569904653824
Trained batch 342 in epoch 11, gen_loss = 0.8611448661752762, disc_loss = 0.06943539356807404
Trained batch 343 in epoch 11, gen_loss = 0.8604469865040724, disc_loss = 0.06950780113097714
Trained batch 344 in epoch 11, gen_loss = 0.8599844910960267, disc_loss = 0.06954147533338138
Trained batch 345 in epoch 11, gen_loss = 0.8598860379071595, disc_loss = 0.06964794200215209
Trained batch 346 in epoch 11, gen_loss = 0.8598560583522753, disc_loss = 0.0695942009635463
Trained batch 347 in epoch 11, gen_loss = 0.8591969305242615, disc_loss = 0.0696844300736898
Trained batch 348 in epoch 11, gen_loss = 0.8596308037510574, disc_loss = 0.0695379934404419
Trained batch 349 in epoch 11, gen_loss = 0.8592725526435034, disc_loss = 0.06948942415948425
Trained batch 350 in epoch 11, gen_loss = 0.858958470260995, disc_loss = 0.0694419851744192
Trained batch 351 in epoch 11, gen_loss = 0.8597381420602853, disc_loss = 0.06932178914906796
Trained batch 352 in epoch 11, gen_loss = 0.8599832639646935, disc_loss = 0.06914744741961402
Trained batch 353 in epoch 11, gen_loss = 0.8592869003782164, disc_loss = 0.06934697937094055
Trained batch 354 in epoch 11, gen_loss = 0.859367088280933, disc_loss = 0.06922356837861975
Trained batch 355 in epoch 11, gen_loss = 0.8597946522778339, disc_loss = 0.06917679685513291
Trained batch 356 in epoch 11, gen_loss = 0.8593983273713195, disc_loss = 0.06931078426685988
Trained batch 357 in epoch 11, gen_loss = 0.8591543013989592, disc_loss = 0.06924443012467643
Trained batch 358 in epoch 11, gen_loss = 0.8583063070654537, disc_loss = 0.06959443071384948
Trained batch 359 in epoch 11, gen_loss = 0.8582424929572476, disc_loss = 0.06952924951910973
Trained batch 360 in epoch 11, gen_loss = 0.8587453306711942, disc_loss = 0.06941475713021868
Trained batch 361 in epoch 11, gen_loss = 0.8590650045575358, disc_loss = 0.0693242983964596
Trained batch 362 in epoch 11, gen_loss = 0.8588005030943342, disc_loss = 0.06925184417197855
Trained batch 363 in epoch 11, gen_loss = 0.8579824638071951, disc_loss = 0.06936054435241354
Trained batch 364 in epoch 11, gen_loss = 0.8584593432406856, disc_loss = 0.06920398079267104
Trained batch 365 in epoch 11, gen_loss = 0.8583757368430414, disc_loss = 0.06932133618905081
Trained batch 366 in epoch 11, gen_loss = 0.8587287569403323, disc_loss = 0.06938579257790821
Trained batch 367 in epoch 11, gen_loss = 0.8584351114442815, disc_loss = 0.06933861917755364
Trained batch 368 in epoch 11, gen_loss = 0.8586690953268914, disc_loss = 0.06917786055565042
Trained batch 369 in epoch 11, gen_loss = 0.858710220133936, disc_loss = 0.06906170755926822
Trained batch 370 in epoch 11, gen_loss = 0.8574333946820539, disc_loss = 0.06982671997115779
Trained batch 371 in epoch 11, gen_loss = 0.8582313103220796, disc_loss = 0.07001762888744793
Trained batch 372 in epoch 11, gen_loss = 0.8589236180999643, disc_loss = 0.06998508819566175
Trained batch 373 in epoch 11, gen_loss = 0.8587058208046112, disc_loss = 0.06995961773782013
Trained batch 374 in epoch 11, gen_loss = 0.8578102602163951, disc_loss = 0.07025509924193224
Trained batch 375 in epoch 11, gen_loss = 0.858070757240057, disc_loss = 0.07013010548209732
Trained batch 376 in epoch 11, gen_loss = 0.8594022190064903, disc_loss = 0.07103983039624337
Trained batch 377 in epoch 11, gen_loss = 0.8587675096969756, disc_loss = 0.07121596999328446
Trained batch 378 in epoch 11, gen_loss = 0.8584893283711889, disc_loss = 0.07138820426504185
Trained batch 379 in epoch 11, gen_loss = 0.8579012203373407, disc_loss = 0.07146622661599203
Trained batch 380 in epoch 11, gen_loss = 0.857830569108953, disc_loss = 0.07151252631186031
Trained batch 381 in epoch 11, gen_loss = 0.8569600442473176, disc_loss = 0.07153694317505466
Trained batch 382 in epoch 11, gen_loss = 0.8567743639877509, disc_loss = 0.07139807306813664
Trained batch 383 in epoch 11, gen_loss = 0.8572602963540703, disc_loss = 0.07124019436499414
Trained batch 384 in epoch 11, gen_loss = 0.8570994924415242, disc_loss = 0.07112561356421415
Trained batch 385 in epoch 11, gen_loss = 0.8573969124666767, disc_loss = 0.07105259268684554
Trained batch 386 in epoch 11, gen_loss = 0.8569992918530792, disc_loss = 0.07100144981163571
Trained batch 387 in epoch 11, gen_loss = 0.8569700939907241, disc_loss = 0.0708616251826824
Trained batch 388 in epoch 11, gen_loss = 0.8571067181988057, disc_loss = 0.07076786030897904
Trained batch 389 in epoch 11, gen_loss = 0.8569052846767964, disc_loss = 0.07071353185157746
Trained batch 390 in epoch 11, gen_loss = 0.8573076009293041, disc_loss = 0.07058757464008411
Trained batch 391 in epoch 11, gen_loss = 0.8572134795997824, disc_loss = 0.0704675255704443
Trained batch 392 in epoch 11, gen_loss = 0.8573996381450245, disc_loss = 0.07039519833547772
Trained batch 393 in epoch 11, gen_loss = 0.8571561294309984, disc_loss = 0.07028183187854471
Trained batch 394 in epoch 11, gen_loss = 0.8572584711298158, disc_loss = 0.07016891430167457
Trained batch 395 in epoch 11, gen_loss = 0.8571012093111722, disc_loss = 0.07008402602220273
Trained batch 396 in epoch 11, gen_loss = 0.8570950779716674, disc_loss = 0.07007384466790882
Trained batch 397 in epoch 11, gen_loss = 0.8568853396716429, disc_loss = 0.07002778017621993
Trained batch 398 in epoch 11, gen_loss = 0.8569571401989251, disc_loss = 0.06991140852521237
Trained batch 399 in epoch 11, gen_loss = 0.8582200986891985, disc_loss = 0.07043962603434921
Trained batch 400 in epoch 11, gen_loss = 0.8582210635157892, disc_loss = 0.07041516409550522
Trained batch 401 in epoch 11, gen_loss = 0.8573955722264389, disc_loss = 0.0709490214117724
Trained batch 402 in epoch 11, gen_loss = 0.8575545862206159, disc_loss = 0.07096611858153758
Trained batch 403 in epoch 11, gen_loss = 0.8581021878831457, disc_loss = 0.0711223425546495
Trained batch 404 in epoch 11, gen_loss = 0.8577609516220328, disc_loss = 0.07108363343609704
Trained batch 405 in epoch 11, gen_loss = 0.85729748252871, disc_loss = 0.07111748555684325
Trained batch 406 in epoch 11, gen_loss = 0.8573914989646002, disc_loss = 0.07118770093897343
Trained batch 407 in epoch 11, gen_loss = 0.8573111086061188, disc_loss = 0.07111347829192585
Trained batch 408 in epoch 11, gen_loss = 0.8569383973160116, disc_loss = 0.07115752859300681
Trained batch 409 in epoch 11, gen_loss = 0.8584860408451499, disc_loss = 0.07175146645707328
Trained batch 410 in epoch 11, gen_loss = 0.8581644922422377, disc_loss = 0.07172930859700026
Trained batch 411 in epoch 11, gen_loss = 0.8573994358043069, disc_loss = 0.07183870768120278
Trained batch 412 in epoch 11, gen_loss = 0.8572615009098884, disc_loss = 0.07176321141475915
Trained batch 413 in epoch 11, gen_loss = 0.8576137077261284, disc_loss = 0.07174817374614989
Trained batch 414 in epoch 11, gen_loss = 0.8578601238957371, disc_loss = 0.07163250057632664
Trained batch 415 in epoch 11, gen_loss = 0.8578914545046595, disc_loss = 0.07152166328160092
Trained batch 416 in epoch 11, gen_loss = 0.8575004204142865, disc_loss = 0.07151156204263512
Trained batch 417 in epoch 11, gen_loss = 0.8574713042906027, disc_loss = 0.07143026548014446
Trained batch 418 in epoch 11, gen_loss = 0.8573973661817628, disc_loss = 0.07132056745787224
Trained batch 419 in epoch 11, gen_loss = 0.8570769160276368, disc_loss = 0.07121953212079547
Trained batch 420 in epoch 11, gen_loss = 0.856931975859078, disc_loss = 0.07108939651426396
Trained batch 421 in epoch 11, gen_loss = 0.857130516408744, disc_loss = 0.07096309420515858
Trained batch 422 in epoch 11, gen_loss = 0.8571157770376678, disc_loss = 0.07097136747999112
Trained batch 423 in epoch 11, gen_loss = 0.8566458110679995, disc_loss = 0.07104088173616889
Trained batch 424 in epoch 11, gen_loss = 0.8569887658427743, disc_loss = 0.07097380532937891
Trained batch 425 in epoch 11, gen_loss = 0.8571338668255739, disc_loss = 0.07087587611968389
Trained batch 426 in epoch 11, gen_loss = 0.8565068822135969, disc_loss = 0.07085795234234467
Trained batch 427 in epoch 11, gen_loss = 0.8570424442954152, disc_loss = 0.07072653915193454
Trained batch 428 in epoch 11, gen_loss = 0.8573704737744409, disc_loss = 0.07061643988362976
Trained batch 429 in epoch 11, gen_loss = 0.8573046991298365, disc_loss = 0.07050459120682506
Trained batch 430 in epoch 11, gen_loss = 0.8568113849362199, disc_loss = 0.07056736635809155
Trained batch 431 in epoch 11, gen_loss = 0.8568091778153623, disc_loss = 0.07049178203602356
Trained batch 432 in epoch 11, gen_loss = 0.8573122478109585, disc_loss = 0.07042416666073006
Trained batch 433 in epoch 11, gen_loss = 0.8571806370799991, disc_loss = 0.07035991364944091
Trained batch 434 in epoch 11, gen_loss = 0.8567243479449174, disc_loss = 0.07035895302549176
Trained batch 435 in epoch 11, gen_loss = 0.8571003789611913, disc_loss = 0.07036016615739929
Trained batch 436 in epoch 11, gen_loss = 0.8564971751561153, disc_loss = 0.07037126751152001
Trained batch 437 in epoch 11, gen_loss = 0.856825388525719, disc_loss = 0.07025661744755697
Trained batch 438 in epoch 11, gen_loss = 0.8570851460268938, disc_loss = 0.07012814319860147
Trained batch 439 in epoch 11, gen_loss = 0.8571506668898192, disc_loss = 0.07001790284941142
Trained batch 440 in epoch 11, gen_loss = 0.8570352636632466, disc_loss = 0.06989669004062406
Trained batch 441 in epoch 11, gen_loss = 0.8570123466566137, disc_loss = 0.06982435836410361
Trained batch 442 in epoch 11, gen_loss = 0.8568373364869413, disc_loss = 0.0697162282646846
Trained batch 443 in epoch 11, gen_loss = 0.8562547518192111, disc_loss = 0.06978771353543207
Trained batch 444 in epoch 11, gen_loss = 0.8564805928910716, disc_loss = 0.0699104932042655
Trained batch 445 in epoch 11, gen_loss = 0.8562898767502318, disc_loss = 0.06978814161461966
Trained batch 446 in epoch 11, gen_loss = 0.8563552383475123, disc_loss = 0.06971481186181507
Trained batch 447 in epoch 11, gen_loss = 0.8561210334966225, disc_loss = 0.06964359570909957
Trained batch 448 in epoch 11, gen_loss = 0.856416875442577, disc_loss = 0.06955853869976737
Trained batch 449 in epoch 11, gen_loss = 0.8569886891709434, disc_loss = 0.06956191358053022
Trained batch 450 in epoch 11, gen_loss = 0.8570165029518356, disc_loss = 0.06953827589502488
Trained batch 451 in epoch 11, gen_loss = 0.8567891503989169, disc_loss = 0.06957384115249841
Trained batch 452 in epoch 11, gen_loss = 0.8564203574299549, disc_loss = 0.06960083503547489
Trained batch 453 in epoch 11, gen_loss = 0.8563938511757073, disc_loss = 0.06955155932512709
Trained batch 454 in epoch 11, gen_loss = 0.8567347343806382, disc_loss = 0.06953033047963629
Trained batch 455 in epoch 11, gen_loss = 0.8571286562895566, disc_loss = 0.06940317737232697
Trained batch 456 in epoch 11, gen_loss = 0.8568480041538339, disc_loss = 0.06934552983721184
Trained batch 457 in epoch 11, gen_loss = 0.8564137541180615, disc_loss = 0.06940545013182549
Trained batch 458 in epoch 11, gen_loss = 0.8571147973890658, disc_loss = 0.06942103200943121
Trained batch 459 in epoch 11, gen_loss = 0.8564967366016429, disc_loss = 0.06960532216598159
Trained batch 460 in epoch 11, gen_loss = 0.8567694914961586, disc_loss = 0.06949996268235292
Trained batch 461 in epoch 11, gen_loss = 0.8569267209603156, disc_loss = 0.06953142740203318
Trained batch 462 in epoch 11, gen_loss = 0.8569529987952107, disc_loss = 0.06942938239621421
Trained batch 463 in epoch 11, gen_loss = 0.8568868202253662, disc_loss = 0.06934542399188824
Trained batch 464 in epoch 11, gen_loss = 0.8564269803544526, disc_loss = 0.06951557103824872
Trained batch 465 in epoch 11, gen_loss = 0.8566574269481995, disc_loss = 0.0694584582528587
Trained batch 466 in epoch 11, gen_loss = 0.856960561533301, disc_loss = 0.06964162041530875
Trained batch 467 in epoch 11, gen_loss = 0.8570427965277281, disc_loss = 0.06951577281459975
Trained batch 468 in epoch 11, gen_loss = 0.8564694984508222, disc_loss = 0.06960227716761802
Trained batch 469 in epoch 11, gen_loss = 0.8556988742123259, disc_loss = 0.06977072193069343
Trained batch 470 in epoch 11, gen_loss = 0.855773596437114, disc_loss = 0.06999336869402487
Trained batch 471 in epoch 11, gen_loss = 0.8557247680501413, disc_loss = 0.06992311241949703
Trained batch 472 in epoch 11, gen_loss = 0.85568757559986, disc_loss = 0.06984749374749734
Trained batch 473 in epoch 11, gen_loss = 0.8553471524378419, disc_loss = 0.06993172974581142
Trained batch 474 in epoch 11, gen_loss = 0.8554844772815704, disc_loss = 0.07000033187042726
Trained batch 475 in epoch 11, gen_loss = 0.8553694100314829, disc_loss = 0.06993384317870588
Trained batch 476 in epoch 11, gen_loss = 0.8553741683625076, disc_loss = 0.06996112733696679
Trained batch 477 in epoch 11, gen_loss = 0.8557167836936448, disc_loss = 0.0699133648435784
Trained batch 478 in epoch 11, gen_loss = 0.8551278699788271, disc_loss = 0.07026695852636482
Trained batch 479 in epoch 11, gen_loss = 0.8552003980303804, disc_loss = 0.07020571008130598
Trained batch 480 in epoch 11, gen_loss = 0.8556992790183505, disc_loss = 0.07014741543138288
Trained batch 481 in epoch 11, gen_loss = 0.8554372051073802, disc_loss = 0.07010539683524937
Trained batch 482 in epoch 11, gen_loss = 0.8559594041442279, disc_loss = 0.07006755695479688
Trained batch 483 in epoch 11, gen_loss = 0.8555685050847116, disc_loss = 0.0701109780102568
Trained batch 484 in epoch 11, gen_loss = 0.8556145199180878, disc_loss = 0.0700501752786876
Trained batch 485 in epoch 11, gen_loss = 0.8556059197265915, disc_loss = 0.06997353812572335
Trained batch 486 in epoch 11, gen_loss = 0.8548504060910712, disc_loss = 0.07001079322705217
Trained batch 487 in epoch 11, gen_loss = 0.8546949396001511, disc_loss = 0.0701917527209143
Trained batch 488 in epoch 11, gen_loss = 0.8550269362994742, disc_loss = 0.07010800788914194
Trained batch 489 in epoch 11, gen_loss = 0.8549015109028135, disc_loss = 0.07004067701458627
Trained batch 490 in epoch 11, gen_loss = 0.8550487752480322, disc_loss = 0.06994967296332606
Trained batch 491 in epoch 11, gen_loss = 0.8545727861242566, disc_loss = 0.07002544924200368
Trained batch 492 in epoch 11, gen_loss = 0.8542661796839677, disc_loss = 0.06999052522428198
Trained batch 493 in epoch 11, gen_loss = 0.8553948638289564, disc_loss = 0.07011550420005372
Trained batch 494 in epoch 11, gen_loss = 0.8550563537111187, disc_loss = 0.07006692162554974
Trained batch 495 in epoch 11, gen_loss = 0.8552366137624748, disc_loss = 0.06997128671613492
Trained batch 496 in epoch 11, gen_loss = 0.8555026240871706, disc_loss = 0.06984802626515599
Trained batch 497 in epoch 11, gen_loss = 0.8558581841877665, disc_loss = 0.06978690306502712
Trained batch 498 in epoch 11, gen_loss = 0.8556935992054566, disc_loss = 0.06972699641681207
Trained batch 499 in epoch 11, gen_loss = 0.8560581588149071, disc_loss = 0.06960326010733843
Trained batch 500 in epoch 11, gen_loss = 0.8562235321232421, disc_loss = 0.06948095779427273
Trained batch 501 in epoch 11, gen_loss = 0.8563383178288243, disc_loss = 0.0693661970461151
Trained batch 502 in epoch 11, gen_loss = 0.856861503828117, disc_loss = 0.06925360422959148
Trained batch 503 in epoch 11, gen_loss = 0.8570877012634088, disc_loss = 0.06917885527576483
Trained batch 504 in epoch 11, gen_loss = 0.857096405135523, disc_loss = 0.06909595677020526
Trained batch 505 in epoch 11, gen_loss = 0.8570376059165585, disc_loss = 0.06900981314509753
Trained batch 506 in epoch 11, gen_loss = 0.8576261540489084, disc_loss = 0.06890788906909658
Trained batch 507 in epoch 11, gen_loss = 0.8580459632624792, disc_loss = 0.06882742763768265
Trained batch 508 in epoch 11, gen_loss = 0.8581215675429885, disc_loss = 0.06871456211370605
Trained batch 509 in epoch 11, gen_loss = 0.8582562961414748, disc_loss = 0.06859354698099196
Trained batch 510 in epoch 11, gen_loss = 0.8581548001318295, disc_loss = 0.06848471622035607
Trained batch 511 in epoch 11, gen_loss = 0.8584053667145781, disc_loss = 0.06836555568861513
Trained batch 512 in epoch 11, gen_loss = 0.8586720509952039, disc_loss = 0.0682640013259565
Trained batch 513 in epoch 11, gen_loss = 0.858933817377814, disc_loss = 0.06814723587703642
Trained batch 514 in epoch 11, gen_loss = 0.8592260738599647, disc_loss = 0.06808533397711163
Trained batch 515 in epoch 11, gen_loss = 0.8588362216602924, disc_loss = 0.06806150962898233
Trained batch 516 in epoch 11, gen_loss = 0.8594112788800806, disc_loss = 0.06799152352697643
Trained batch 517 in epoch 11, gen_loss = 0.8596719568415498, disc_loss = 0.06787867076842395
Trained batch 518 in epoch 11, gen_loss = 0.8597571459923635, disc_loss = 0.06776332429489965
Trained batch 519 in epoch 11, gen_loss = 0.8600909664653815, disc_loss = 0.06765313753231357
Trained batch 520 in epoch 11, gen_loss = 0.8600902386338606, disc_loss = 0.06754091553007487
Trained batch 521 in epoch 11, gen_loss = 0.8600318697334706, disc_loss = 0.06744305592590508
Trained batch 522 in epoch 11, gen_loss = 0.859989293959583, disc_loss = 0.06738196376864274
Trained batch 523 in epoch 11, gen_loss = 0.8604055165903259, disc_loss = 0.06726817153340903
Trained batch 524 in epoch 11, gen_loss = 0.860209759360268, disc_loss = 0.06720487423684625
Trained batch 525 in epoch 11, gen_loss = 0.8609010117702158, disc_loss = 0.06714442950326369
Trained batch 526 in epoch 11, gen_loss = 0.8613058308835726, disc_loss = 0.06702997217279995
Trained batch 527 in epoch 11, gen_loss = 0.8613541957668283, disc_loss = 0.06696075433071448
Trained batch 528 in epoch 11, gen_loss = 0.861584908851829, disc_loss = 0.06684686585869958
Trained batch 529 in epoch 11, gen_loss = 0.8619521375534669, disc_loss = 0.06686074271323686
Trained batch 530 in epoch 11, gen_loss = 0.8618083639445727, disc_loss = 0.06676556930566828
Trained batch 531 in epoch 11, gen_loss = 0.8615592639137032, disc_loss = 0.06673883174850669
Trained batch 532 in epoch 11, gen_loss = 0.8614410997890845, disc_loss = 0.06668008427881753
Trained batch 533 in epoch 11, gen_loss = 0.8618163852097837, disc_loss = 0.06659229225409305
Trained batch 534 in epoch 11, gen_loss = 0.8625396748012472, disc_loss = 0.06655294738588072
Trained batch 535 in epoch 11, gen_loss = 0.8630334781065806, disc_loss = 0.06646063966318659
Trained batch 536 in epoch 11, gen_loss = 0.8626521150382094, disc_loss = 0.06640036105918845
Trained batch 537 in epoch 11, gen_loss = 0.8629331054186732, disc_loss = 0.06629077694205684
Trained batch 538 in epoch 11, gen_loss = 0.8629916377213537, disc_loss = 0.06618108691177668
Trained batch 539 in epoch 11, gen_loss = 0.8633548605773184, disc_loss = 0.06610732831112627
Trained batch 540 in epoch 11, gen_loss = 0.8637019932931099, disc_loss = 0.06601003772370834
Trained batch 541 in epoch 11, gen_loss = 0.8636203243833627, disc_loss = 0.0659474850781743
Trained batch 542 in epoch 11, gen_loss = 0.8635497461476159, disc_loss = 0.06586076228057838
Trained batch 543 in epoch 11, gen_loss = 0.8636289148536676, disc_loss = 0.0657691759586348
Trained batch 544 in epoch 11, gen_loss = 0.8639007580936502, disc_loss = 0.06566580121892444
Trained batch 545 in epoch 11, gen_loss = 0.8641205354160442, disc_loss = 0.06555780103931633
Trained batch 546 in epoch 11, gen_loss = 0.8641983752821656, disc_loss = 0.06545014706247876
Trained batch 547 in epoch 11, gen_loss = 0.8642852961690757, disc_loss = 0.06534298650842214
Trained batch 548 in epoch 11, gen_loss = 0.8642974195693143, disc_loss = 0.0652339686673535
Trained batch 549 in epoch 11, gen_loss = 0.8643353391235525, disc_loss = 0.06513291304846379
Trained batch 550 in epoch 11, gen_loss = 0.8641326518867929, disc_loss = 0.06506607438878793
Trained batch 551 in epoch 11, gen_loss = 0.8647024031674516, disc_loss = 0.06498321502189408
Trained batch 552 in epoch 11, gen_loss = 0.865055599059593, disc_loss = 0.0648772614346194
Trained batch 553 in epoch 11, gen_loss = 0.8648730138256231, disc_loss = 0.06479294812777467
Trained batch 554 in epoch 11, gen_loss = 0.8649977014408455, disc_loss = 0.0646871783921646
Trained batch 555 in epoch 11, gen_loss = 0.8655104163846523, disc_loss = 0.06462308939750702
Trained batch 556 in epoch 11, gen_loss = 0.8654574267633085, disc_loss = 0.06452301946256303
Trained batch 557 in epoch 11, gen_loss = 0.8653313137831227, disc_loss = 0.06446447558984775
Trained batch 558 in epoch 11, gen_loss = 0.8656697990322796, disc_loss = 0.06437590305505184
Trained batch 559 in epoch 11, gen_loss = 0.8659455342484372, disc_loss = 0.0642728713183065
Trained batch 560 in epoch 11, gen_loss = 0.8665266564504348, disc_loss = 0.06420698707903372
Trained batch 561 in epoch 11, gen_loss = 0.8664379039799192, disc_loss = 0.06415693081825892
Trained batch 562 in epoch 11, gen_loss = 0.8665688807015732, disc_loss = 0.06405592991575122
Trained batch 563 in epoch 11, gen_loss = 0.8667360811051747, disc_loss = 0.06397823936798022
Trained batch 564 in epoch 11, gen_loss = 0.866874206224374, disc_loss = 0.0638868073438319
Trained batch 565 in epoch 11, gen_loss = 0.8670769295401792, disc_loss = 0.06378317823758606
Trained batch 566 in epoch 11, gen_loss = 0.8674675593615839, disc_loss = 0.0637072290259379
Trained batch 567 in epoch 11, gen_loss = 0.8674095714281143, disc_loss = 0.06362458342410834
Trained batch 568 in epoch 11, gen_loss = 0.8674185431590189, disc_loss = 0.06353585707982888
Trained batch 569 in epoch 11, gen_loss = 0.8675106375363835, disc_loss = 0.06351222886556858
Trained batch 570 in epoch 11, gen_loss = 0.8676420658461476, disc_loss = 0.06343076314007286
Trained batch 571 in epoch 11, gen_loss = 0.8677131947833341, disc_loss = 0.06336739009825865
Trained batch 572 in epoch 11, gen_loss = 0.868449663980677, disc_loss = 0.06335301437686615
Trained batch 573 in epoch 11, gen_loss = 0.868374787296983, disc_loss = 0.06329357864997165
Trained batch 574 in epoch 11, gen_loss = 0.8686016433653624, disc_loss = 0.06321198175620774
Trained batch 575 in epoch 11, gen_loss = 0.868482016492635, disc_loss = 0.06312365849993916
Trained batch 576 in epoch 11, gen_loss = 0.868452725470376, disc_loss = 0.06304567037360094
Trained batch 577 in epoch 11, gen_loss = 0.8689084109241162, disc_loss = 0.06298511645798555
Trained batch 578 in epoch 11, gen_loss = 0.8692193143005404, disc_loss = 0.06289777971984294
Trained batch 579 in epoch 11, gen_loss = 0.8692523455311512, disc_loss = 0.06282029494578982
Trained batch 580 in epoch 11, gen_loss = 0.869368074221373, disc_loss = 0.0627294689795185
Trained batch 581 in epoch 11, gen_loss = 0.869460592820882, disc_loss = 0.06275730665542723
Trained batch 582 in epoch 11, gen_loss = 0.869728207434839, disc_loss = 0.06267125668294894
Trained batch 583 in epoch 11, gen_loss = 0.869476761873046, disc_loss = 0.06270301121459279
Trained batch 584 in epoch 11, gen_loss = 0.8696846912559281, disc_loss = 0.06263366764904851
Trained batch 585 in epoch 11, gen_loss = 0.8698268109112469, disc_loss = 0.06255142599242539
Trained batch 586 in epoch 11, gen_loss = 0.8695597537433065, disc_loss = 0.06248980763747501
Trained batch 587 in epoch 11, gen_loss = 0.8698598550391846, disc_loss = 0.06240283546424439
Trained batch 588 in epoch 11, gen_loss = 0.8696125920337003, disc_loss = 0.062351385868314166
Trained batch 589 in epoch 11, gen_loss = 0.8699971304606583, disc_loss = 0.062318888988535284
Trained batch 590 in epoch 11, gen_loss = 0.8701855429840571, disc_loss = 0.0623381160161822
Trained batch 591 in epoch 11, gen_loss = 0.870191378720306, disc_loss = 0.06225865644818122
Trained batch 592 in epoch 11, gen_loss = 0.8705745776125794, disc_loss = 0.062190473101668774
Trained batch 593 in epoch 11, gen_loss = 0.8705324269204028, disc_loss = 0.062142116506819174
Trained batch 594 in epoch 11, gen_loss = 0.8705010781268112, disc_loss = 0.062060225100702596
Trained batch 595 in epoch 11, gen_loss = 0.8702800404405434, disc_loss = 0.06203257757857842
Trained batch 596 in epoch 11, gen_loss = 0.8699566899132689, disc_loss = 0.06205776121960313
Trained batch 597 in epoch 11, gen_loss = 0.8706721432731304, disc_loss = 0.06208132203967376
Trained batch 598 in epoch 11, gen_loss = 0.8705549530174975, disc_loss = 0.06199625433299796
Trained batch 599 in epoch 11, gen_loss = 0.8707201046248277, disc_loss = 0.06196284567626814
Trained batch 600 in epoch 11, gen_loss = 0.8700377551866649, disc_loss = 0.06246988835144856
Trained batch 601 in epoch 11, gen_loss = 0.870683455734554, disc_loss = 0.06277405166460133
Trained batch 602 in epoch 11, gen_loss = 0.8704843682732748, disc_loss = 0.06275070413242821
Trained batch 603 in epoch 11, gen_loss = 0.8699930304821754, disc_loss = 0.06275470804312075
Trained batch 604 in epoch 11, gen_loss = 0.8701173895154117, disc_loss = 0.06267053178734769
Trained batch 605 in epoch 11, gen_loss = 0.8701015612964976, disc_loss = 0.06273912978220252
Trained batch 606 in epoch 11, gen_loss = 0.8699587132333727, disc_loss = 0.06270270046963675
Trained batch 607 in epoch 11, gen_loss = 0.8698376409807488, disc_loss = 0.06263729136308509
Trained batch 608 in epoch 11, gen_loss = 0.8702889143050402, disc_loss = 0.06264994391783069
Trained batch 609 in epoch 11, gen_loss = 0.8705720944971335, disc_loss = 0.06257813053022399
Trained batch 610 in epoch 11, gen_loss = 0.870151276332852, disc_loss = 0.06262234212303269
Trained batch 611 in epoch 11, gen_loss = 0.869820852051763, disc_loss = 0.06260148954906446
Trained batch 612 in epoch 11, gen_loss = 0.8699314054132091, disc_loss = 0.06257349682810791
Trained batch 613 in epoch 11, gen_loss = 0.8701484984314791, disc_loss = 0.06250049117254852
Trained batch 614 in epoch 11, gen_loss = 0.8699220919512152, disc_loss = 0.06247097330576763
Trained batch 615 in epoch 11, gen_loss = 0.8697273797512829, disc_loss = 0.062467340844102784
Trained batch 616 in epoch 11, gen_loss = 0.869187970940066, disc_loss = 0.06255159506987859
Trained batch 617 in epoch 11, gen_loss = 0.8693120364328805, disc_loss = 0.06251849366568969
Trained batch 618 in epoch 11, gen_loss = 0.8695108142827362, disc_loss = 0.06249380719386077
Trained batch 619 in epoch 11, gen_loss = 0.8696022842680254, disc_loss = 0.06242165833921923
Trained batch 620 in epoch 11, gen_loss = 0.869069140650416, disc_loss = 0.06279876899430094
Trained batch 621 in epoch 11, gen_loss = 0.8697764050826382, disc_loss = 0.06286361877480072
Trained batch 622 in epoch 11, gen_loss = 0.8697800297128637, disc_loss = 0.06282445648311373
Trained batch 623 in epoch 11, gen_loss = 0.8697527824208523, disc_loss = 0.06280635001036362
Trained batch 624 in epoch 11, gen_loss = 0.8697564883708954, disc_loss = 0.06290936426967382
Trained batch 625 in epoch 11, gen_loss = 0.8694761439729423, disc_loss = 0.06284038561690873
Trained batch 626 in epoch 11, gen_loss = 0.8690205035312324, disc_loss = 0.06287919549179372
Trained batch 627 in epoch 11, gen_loss = 0.8691013092353086, disc_loss = 0.06281713857078201
Trained batch 628 in epoch 11, gen_loss = 0.8691922616219483, disc_loss = 0.06284105162238421
Trained batch 629 in epoch 11, gen_loss = 0.8686804910027791, disc_loss = 0.06291602171573138
Trained batch 630 in epoch 11, gen_loss = 0.868969564061913, disc_loss = 0.06285486286638892
Trained batch 631 in epoch 11, gen_loss = 0.8691091227663469, disc_loss = 0.06281383008595934
Trained batch 632 in epoch 11, gen_loss = 0.8691554986187632, disc_loss = 0.06273584277773685
Trained batch 633 in epoch 11, gen_loss = 0.8693141425351615, disc_loss = 0.06269491750494303
Trained batch 634 in epoch 11, gen_loss = 0.8691731238459038, disc_loss = 0.06270672309205054
Trained batch 635 in epoch 11, gen_loss = 0.8689769504111517, disc_loss = 0.06267001242494011
Trained batch 636 in epoch 11, gen_loss = 0.8691711019215815, disc_loss = 0.06260746169039977
Trained batch 637 in epoch 11, gen_loss = 0.8693634878411935, disc_loss = 0.06256805438122079
Trained batch 638 in epoch 11, gen_loss = 0.8696652896620671, disc_loss = 0.062486117036724596
Trained batch 639 in epoch 11, gen_loss = 0.8693111393135041, disc_loss = 0.06260938865452773
Trained batch 640 in epoch 11, gen_loss = 0.8688170260367639, disc_loss = 0.06279610248366821
Trained batch 641 in epoch 11, gen_loss = 0.868984290047598, disc_loss = 0.06274808521855425
Trained batch 642 in epoch 11, gen_loss = 0.8691570186411055, disc_loss = 0.06270078819210338
Trained batch 643 in epoch 11, gen_loss = 0.868988519916253, disc_loss = 0.06266386822438712
Trained batch 644 in epoch 11, gen_loss = 0.8686906316021616, disc_loss = 0.06264095120853926
Trained batch 645 in epoch 11, gen_loss = 0.8687164557884353, disc_loss = 0.06256741931771531
Trained batch 646 in epoch 11, gen_loss = 0.8691004237859659, disc_loss = 0.06251685893655376
Trained batch 647 in epoch 11, gen_loss = 0.869125854315949, disc_loss = 0.062435851656590345
Trained batch 648 in epoch 11, gen_loss = 0.8692656242516816, disc_loss = 0.06241629078685778
Trained batch 649 in epoch 11, gen_loss = 0.8689707294335732, disc_loss = 0.06243651743118579
Trained batch 650 in epoch 11, gen_loss = 0.8689900475987641, disc_loss = 0.06240923526466534
Trained batch 651 in epoch 11, gen_loss = 0.8689177268030454, disc_loss = 0.06233525102489565
Trained batch 652 in epoch 11, gen_loss = 0.869465385927358, disc_loss = 0.06234255207169111
Trained batch 653 in epoch 11, gen_loss = 0.8695632427566278, disc_loss = 0.06225948583403038
Trained batch 654 in epoch 11, gen_loss = 0.8690840577806225, disc_loss = 0.062299430799734504
Trained batch 655 in epoch 11, gen_loss = 0.8690956423467979, disc_loss = 0.06238668253815665
Trained batch 656 in epoch 11, gen_loss = 0.8691396199314199, disc_loss = 0.062453314806568565
Trained batch 657 in epoch 11, gen_loss = 0.8686620528303018, disc_loss = 0.06256514693409386
Trained batch 658 in epoch 11, gen_loss = 0.868128329334563, disc_loss = 0.06275855663638104
Trained batch 659 in epoch 11, gen_loss = 0.8684187164360827, disc_loss = 0.06284311420255989
Trained batch 660 in epoch 11, gen_loss = 0.8683488723820529, disc_loss = 0.06279502953043413
Trained batch 661 in epoch 11, gen_loss = 0.8683957213991719, disc_loss = 0.06274035549089538
Trained batch 662 in epoch 11, gen_loss = 0.8680325330742165, disc_loss = 0.06280922392723158
Trained batch 663 in epoch 11, gen_loss = 0.8683015342846693, disc_loss = 0.06277886367156114
Trained batch 664 in epoch 11, gen_loss = 0.8686450063285971, disc_loss = 0.06275232749942102
Trained batch 665 in epoch 11, gen_loss = 0.8683586212339344, disc_loss = 0.06278088311566873
Trained batch 666 in epoch 11, gen_loss = 0.8681759294988155, disc_loss = 0.06280553949413181
Trained batch 667 in epoch 11, gen_loss = 0.8678697951271862, disc_loss = 0.06281024410283405
Trained batch 668 in epoch 11, gen_loss = 0.8680081858852341, disc_loss = 0.06273850616936326
Trained batch 669 in epoch 11, gen_loss = 0.8684207051102795, disc_loss = 0.06268521496581275
Trained batch 670 in epoch 11, gen_loss = 0.8681590378995091, disc_loss = 0.06264020190969798
Trained batch 671 in epoch 11, gen_loss = 0.8680911911651492, disc_loss = 0.06256650033728442
Trained batch 672 in epoch 11, gen_loss = 0.8678651334715102, disc_loss = 0.06274671215193144
Trained batch 673 in epoch 11, gen_loss = 0.8679903836296291, disc_loss = 0.06269559524234837
Trained batch 674 in epoch 11, gen_loss = 0.8676908557944828, disc_loss = 0.0626922915737938
Trained batch 675 in epoch 11, gen_loss = 0.8677639740370434, disc_loss = 0.06263516661187513
Trained batch 676 in epoch 11, gen_loss = 0.8674279616449573, disc_loss = 0.06270163899983666
Trained batch 677 in epoch 11, gen_loss = 0.8677204242058559, disc_loss = 0.06265011689128426
Trained batch 678 in epoch 11, gen_loss = 0.8678551015604579, disc_loss = 0.0625710667650022
Trained batch 679 in epoch 11, gen_loss = 0.8677530267221086, disc_loss = 0.06256999415071572
Trained batch 680 in epoch 11, gen_loss = 0.8677608477999286, disc_loss = 0.06251611891537685
Trained batch 681 in epoch 11, gen_loss = 0.8675477839023137, disc_loss = 0.06251882776465059
Trained batch 682 in epoch 11, gen_loss = 0.8673341297387728, disc_loss = 0.062459329484060605
Trained batch 683 in epoch 11, gen_loss = 0.8676989946884719, disc_loss = 0.06241795910271811
Trained batch 684 in epoch 11, gen_loss = 0.867742488984644, disc_loss = 0.06238348165894077
Trained batch 685 in epoch 11, gen_loss = 0.8675542275255692, disc_loss = 0.06234853538214813
Trained batch 686 in epoch 11, gen_loss = 0.8678017288576567, disc_loss = 0.06229876437572846
Trained batch 687 in epoch 11, gen_loss = 0.8675650690443987, disc_loss = 0.062332289815923675
Trained batch 688 in epoch 11, gen_loss = 0.8672670343531234, disc_loss = 0.06231458126384824
Trained batch 689 in epoch 11, gen_loss = 0.8677091940157655, disc_loss = 0.06224894781151544
Trained batch 690 in epoch 11, gen_loss = 0.8677182920848582, disc_loss = 0.06217908987427715
Trained batch 691 in epoch 11, gen_loss = 0.8674872379340878, disc_loss = 0.06217881239751472
Trained batch 692 in epoch 11, gen_loss = 0.8675959297330864, disc_loss = 0.0622164842324576
Trained batch 693 in epoch 11, gen_loss = 0.8680634532521025, disc_loss = 0.06215909980532716
Trained batch 694 in epoch 11, gen_loss = 0.8679432841084844, disc_loss = 0.06212121546670473
Trained batch 695 in epoch 11, gen_loss = 0.8675981655117424, disc_loss = 0.062142015246128474
Trained batch 696 in epoch 11, gen_loss = 0.8677740897047982, disc_loss = 0.062084313860187146
Trained batch 697 in epoch 11, gen_loss = 0.8682299447179183, disc_loss = 0.062026407520278735
Trained batch 698 in epoch 11, gen_loss = 0.8686147961920082, disc_loss = 0.0619696036543436
Trained batch 699 in epoch 11, gen_loss = 0.8682876759341784, disc_loss = 0.06194982472141938
Trained batch 700 in epoch 11, gen_loss = 0.8680799622593525, disc_loss = 0.06192383458027444
Trained batch 701 in epoch 11, gen_loss = 0.8680873840537846, disc_loss = 0.06202053281735958
Trained batch 702 in epoch 11, gen_loss = 0.867869645357132, disc_loss = 0.062058262303100624
Trained batch 703 in epoch 11, gen_loss = 0.8679681499488652, disc_loss = 0.062017329670859246
Trained batch 704 in epoch 11, gen_loss = 0.8679498765062779, disc_loss = 0.06199091494162666
Trained batch 705 in epoch 11, gen_loss = 0.867610226398487, disc_loss = 0.06198496037893651
Trained batch 706 in epoch 11, gen_loss = 0.8676903004609207, disc_loss = 0.06190984210465762
Trained batch 707 in epoch 11, gen_loss = 0.8675186875260482, disc_loss = 0.06201518975371905
Trained batch 708 in epoch 11, gen_loss = 0.8672670453408541, disc_loss = 0.06207476529110176
Trained batch 709 in epoch 11, gen_loss = 0.8674562578050183, disc_loss = 0.06200471141205077
Trained batch 710 in epoch 11, gen_loss = 0.8672882440472454, disc_loss = 0.06204258546406081
Trained batch 711 in epoch 11, gen_loss = 0.8671487953639432, disc_loss = 0.06207120202591622
Trained batch 712 in epoch 11, gen_loss = 0.8669978292008436, disc_loss = 0.06206599086507381
Trained batch 713 in epoch 11, gen_loss = 0.8667548152328539, disc_loss = 0.06200925553874934
Trained batch 714 in epoch 11, gen_loss = 0.866922691193494, disc_loss = 0.061950561538390764
Trained batch 715 in epoch 11, gen_loss = 0.8668328885342822, disc_loss = 0.06190193973497264
Trained batch 716 in epoch 11, gen_loss = 0.8668245942107138, disc_loss = 0.06194499169698445
Trained batch 717 in epoch 11, gen_loss = 0.8668039704680774, disc_loss = 0.06198133302406307
Trained batch 718 in epoch 11, gen_loss = 0.8669347634982002, disc_loss = 0.0620009682396419
Trained batch 719 in epoch 11, gen_loss = 0.866961667396956, disc_loss = 0.06196224445658219
Trained batch 720 in epoch 11, gen_loss = 0.8667301459963874, disc_loss = 0.06206148894227287
Trained batch 721 in epoch 11, gen_loss = 0.8670053557593407, disc_loss = 0.062056189133344514
Trained batch 722 in epoch 11, gen_loss = 0.8673650096808232, disc_loss = 0.06202360072957653
Trained batch 723 in epoch 11, gen_loss = 0.8674684548493248, disc_loss = 0.06200726714000641
Trained batch 724 in epoch 11, gen_loss = 0.867231973491866, disc_loss = 0.06198776952023136
Trained batch 725 in epoch 11, gen_loss = 0.8675207351603784, disc_loss = 0.06193271203777309
Trained batch 726 in epoch 11, gen_loss = 0.8677424105932164, disc_loss = 0.061886550350040405
Trained batch 727 in epoch 11, gen_loss = 0.8677484898694924, disc_loss = 0.06193592128277357
Trained batch 728 in epoch 11, gen_loss = 0.8675277543411334, disc_loss = 0.06196923483551489
Trained batch 729 in epoch 11, gen_loss = 0.8673134220381306, disc_loss = 0.061952494453536726
Trained batch 730 in epoch 11, gen_loss = 0.8675848486567, disc_loss = 0.06188605574027173
Trained batch 731 in epoch 11, gen_loss = 0.8676448573098808, disc_loss = 0.06183191103468868
Trained batch 732 in epoch 11, gen_loss = 0.8676122436338037, disc_loss = 0.061777804337828174
Trained batch 733 in epoch 11, gen_loss = 0.8675660277825935, disc_loss = 0.06176397636943885
Trained batch 734 in epoch 11, gen_loss = 0.8674077276064425, disc_loss = 0.06173006930344162
Trained batch 735 in epoch 11, gen_loss = 0.8672908953917415, disc_loss = 0.0617242700726543
Trained batch 736 in epoch 11, gen_loss = 0.8672283659392167, disc_loss = 0.06167117481624134
Trained batch 737 in epoch 11, gen_loss = 0.8672886502532778, disc_loss = 0.061667330882342934
Trained batch 738 in epoch 11, gen_loss = 0.8671716712566448, disc_loss = 0.06162080274458788
Trained batch 739 in epoch 11, gen_loss = 0.867162570880877, disc_loss = 0.06166111462296465
Trained batch 740 in epoch 11, gen_loss = 0.8670872085088017, disc_loss = 0.06163979001348278
Trained batch 741 in epoch 11, gen_loss = 0.8669496252931996, disc_loss = 0.061632517367511026
Trained batch 742 in epoch 11, gen_loss = 0.8672694420670115, disc_loss = 0.061606041148234744
Trained batch 743 in epoch 11, gen_loss = 0.8674038362999758, disc_loss = 0.061556582873617045
Trained batch 744 in epoch 11, gen_loss = 0.8674386412905367, disc_loss = 0.06151723958576886
Trained batch 745 in epoch 11, gen_loss = 0.8675281986714048, disc_loss = 0.061455868947352145
Trained batch 746 in epoch 11, gen_loss = 0.8673385279165853, disc_loss = 0.06142924856045439
Trained batch 747 in epoch 11, gen_loss = 0.8674385571145119, disc_loss = 0.061377511358506144
Trained batch 748 in epoch 11, gen_loss = 0.867693240039339, disc_loss = 0.06137766005553415
Trained batch 749 in epoch 11, gen_loss = 0.8678102697928747, disc_loss = 0.06131258494779467
Trained batch 750 in epoch 11, gen_loss = 0.8676937754636757, disc_loss = 0.06134125292822024
Trained batch 751 in epoch 11, gen_loss = 0.8672365460227779, disc_loss = 0.061409803435573
Trained batch 752 in epoch 11, gen_loss = 0.8678035615370726, disc_loss = 0.0614384808262209
Trained batch 753 in epoch 11, gen_loss = 0.8677111919030587, disc_loss = 0.06141010754981353
Trained batch 754 in epoch 11, gen_loss = 0.8676815918344536, disc_loss = 0.06134330565541588
Trained batch 755 in epoch 11, gen_loss = 0.8677332749363607, disc_loss = 0.061279213886274386
Trained batch 756 in epoch 11, gen_loss = 0.8680514884199775, disc_loss = 0.06124028981056758
Trained batch 757 in epoch 11, gen_loss = 0.8677485554938581, disc_loss = 0.06121126089815178
Trained batch 758 in epoch 11, gen_loss = 0.8676754939461885, disc_loss = 0.06116515390417871
Trained batch 759 in epoch 11, gen_loss = 0.8679531459353472, disc_loss = 0.061107670481463795
Trained batch 760 in epoch 11, gen_loss = 0.8676880631355982, disc_loss = 0.06114734267221174
Trained batch 761 in epoch 11, gen_loss = 0.8678927498617823, disc_loss = 0.06116953722428618
Trained batch 762 in epoch 11, gen_loss = 0.8675413321151958, disc_loss = 0.06120900240962346
Trained batch 763 in epoch 11, gen_loss = 0.867978114303182, disc_loss = 0.061213942112996
Trained batch 764 in epoch 11, gen_loss = 0.8682090543064417, disc_loss = 0.061146532084330234
Trained batch 765 in epoch 11, gen_loss = 0.8681464508448195, disc_loss = 0.06109457879567971
Trained batch 766 in epoch 11, gen_loss = 0.8679654409008822, disc_loss = 0.06106707717703638
Trained batch 767 in epoch 11, gen_loss = 0.8680515399901196, disc_loss = 0.06101898831548169
Trained batch 768 in epoch 11, gen_loss = 0.8682764424846758, disc_loss = 0.06097182751632016
Trained batch 769 in epoch 11, gen_loss = 0.8679877893104182, disc_loss = 0.06095578710657436
Trained batch 770 in epoch 11, gen_loss = 0.8678993440091842, disc_loss = 0.06090424001342514
Trained batch 771 in epoch 11, gen_loss = 0.8682936760814078, disc_loss = 0.060886950282756376
Trained batch 772 in epoch 11, gen_loss = 0.8679526915140017, disc_loss = 0.060869620500896296
Trained batch 773 in epoch 11, gen_loss = 0.8681100152952727, disc_loss = 0.06095401553595944
Trained batch 774 in epoch 11, gen_loss = 0.8678885920201579, disc_loss = 0.06097646805307558
Trained batch 775 in epoch 11, gen_loss = 0.8679554226241776, disc_loss = 0.0609147007104259
Trained batch 776 in epoch 11, gen_loss = 0.868168558278139, disc_loss = 0.06099411987482619
Trained batch 777 in epoch 11, gen_loss = 0.8678562749550705, disc_loss = 0.060972311329288084
Trained batch 778 in epoch 11, gen_loss = 0.8678803494790706, disc_loss = 0.06092806925234386
Trained batch 779 in epoch 11, gen_loss = 0.8678384999052072, disc_loss = 0.060885027749463916
Trained batch 780 in epoch 11, gen_loss = 0.867513397858787, disc_loss = 0.06100214169826955
Trained batch 781 in epoch 11, gen_loss = 0.8674911563582433, disc_loss = 0.06095862619774154
Trained batch 782 in epoch 11, gen_loss = 0.8677742328604214, disc_loss = 0.06095541979508572
Trained batch 783 in epoch 11, gen_loss = 0.868152186844726, disc_loss = 0.06092531810044216
Trained batch 784 in epoch 11, gen_loss = 0.8679042867414511, disc_loss = 0.06096380489765649
Trained batch 785 in epoch 11, gen_loss = 0.8680772181913143, disc_loss = 0.06097355377019096
Trained batch 786 in epoch 11, gen_loss = 0.8681962887319858, disc_loss = 0.0609103281268663
Trained batch 787 in epoch 11, gen_loss = 0.8678551731905356, disc_loss = 0.06101288724227378
Trained batch 788 in epoch 11, gen_loss = 0.8680268586135182, disc_loss = 0.06131200938330932
Trained batch 789 in epoch 11, gen_loss = 0.8681407764365402, disc_loss = 0.06131179799809109
Testing Epoch 11
Training Epoch 12
Trained batch 0 in epoch 12, gen_loss = 0.7621322870254517, disc_loss = 0.050177764147520065
Trained batch 1 in epoch 12, gen_loss = 0.7611148357391357, disc_loss = 0.03842144459486008
Trained batch 2 in epoch 12, gen_loss = 0.8074051141738892, disc_loss = 0.032166656106710434
Trained batch 3 in epoch 12, gen_loss = 0.761659100651741, disc_loss = 0.04980382788926363
Trained batch 4 in epoch 12, gen_loss = 0.7721464991569519, disc_loss = 0.05548929050564766
Trained batch 5 in epoch 12, gen_loss = 0.8074122667312622, disc_loss = 0.049553215193251766
Trained batch 6 in epoch 12, gen_loss = 0.8176633971078056, disc_loss = 0.045676647286329954
Trained batch 7 in epoch 12, gen_loss = 0.8044746294617653, disc_loss = 0.05118090636096895
Trained batch 8 in epoch 12, gen_loss = 0.8364173372586569, disc_loss = 0.04708875736428632
Trained batch 9 in epoch 12, gen_loss = 0.8337300181388855, disc_loss = 0.05621662009507418
Trained batch 10 in epoch 12, gen_loss = 0.8335137150504373, disc_loss = 0.053296801380135796
Trained batch 11 in epoch 12, gen_loss = 0.8223549971977869, disc_loss = 0.0530674293016394
Trained batch 12 in epoch 12, gen_loss = 0.8280852620418255, disc_loss = 0.05373423689833054
Trained batch 13 in epoch 12, gen_loss = 0.8377874323299953, disc_loss = 0.05140782733048711
Trained batch 14 in epoch 12, gen_loss = 0.8180024067560832, disc_loss = 0.05761523693799973
Trained batch 15 in epoch 12, gen_loss = 0.8199200853705406, disc_loss = 0.06111444113776088
Trained batch 16 in epoch 12, gen_loss = 0.8177090918316561, disc_loss = 0.058570562040104586
Trained batch 17 in epoch 12, gen_loss = 0.8191012508339353, disc_loss = 0.055933161017795406
Trained batch 18 in epoch 12, gen_loss = 0.8217304850879469, disc_loss = 0.05343384555491962
Trained batch 19 in epoch 12, gen_loss = 0.8122046411037445, disc_loss = 0.053012125799432396
Trained batch 20 in epoch 12, gen_loss = 0.8265866268248785, disc_loss = 0.05130953816253515
Trained batch 21 in epoch 12, gen_loss = 0.8276340473781932, disc_loss = 0.05119645540517839
Trained batch 22 in epoch 12, gen_loss = 0.8336758950482244, disc_loss = 0.049376555597004684
Trained batch 23 in epoch 12, gen_loss = 0.831187884012858, disc_loss = 0.048934800239900746
Trained batch 24 in epoch 12, gen_loss = 0.8340279960632324, disc_loss = 0.0484406590461731
Trained batch 25 in epoch 12, gen_loss = 0.830134398662127, disc_loss = 0.04773860166852291
Trained batch 26 in epoch 12, gen_loss = 0.8372246976251956, disc_loss = 0.049608616089379345
Trained batch 27 in epoch 12, gen_loss = 0.8228737637400627, disc_loss = 0.055387017716254504
Trained batch 28 in epoch 12, gen_loss = 0.8222556576646608, disc_loss = 0.05988511879896295
Trained batch 29 in epoch 12, gen_loss = 0.8189394563436508, disc_loss = 0.0598944125076135
Trained batch 30 in epoch 12, gen_loss = 0.8262240204118914, disc_loss = 0.0585498831445171
Trained batch 31 in epoch 12, gen_loss = 0.8168260036036372, disc_loss = 0.06345242937095463
Trained batch 32 in epoch 12, gen_loss = 0.8149181595354369, disc_loss = 0.06298260785865062
Trained batch 33 in epoch 12, gen_loss = 0.8204552487415426, disc_loss = 0.06359239481389523
Trained batch 34 in epoch 12, gen_loss = 0.8300542550427573, disc_loss = 0.06263465971818992
Trained batch 35 in epoch 12, gen_loss = 0.8348045671979586, disc_loss = 0.061700082642750606
Trained batch 36 in epoch 12, gen_loss = 0.8301511221640819, disc_loss = 0.06146351565178987
Trained batch 37 in epoch 12, gen_loss = 0.8258243744310579, disc_loss = 0.060990575455913416
Trained batch 38 in epoch 12, gen_loss = 0.8315426210562388, disc_loss = 0.06305464180425191
Trained batch 39 in epoch 12, gen_loss = 0.8326523490250111, disc_loss = 0.06528429496102035
Trained batch 40 in epoch 12, gen_loss = 0.8221883315865587, disc_loss = 0.07379471197179178
Trained batch 41 in epoch 12, gen_loss = 0.8220125983158747, disc_loss = 0.0728871077742605
Trained batch 42 in epoch 12, gen_loss = 0.8201358907444533, disc_loss = 0.07347602384208246
Trained batch 43 in epoch 12, gen_loss = 0.8172046196731654, disc_loss = 0.07415253605524247
Trained batch 44 in epoch 12, gen_loss = 0.8207146147886912, disc_loss = 0.07432053424417973
Trained batch 45 in epoch 12, gen_loss = 0.8154318339150884, disc_loss = 0.07495653325610835
Trained batch 46 in epoch 12, gen_loss = 0.8155997807675219, disc_loss = 0.07571430936297203
Trained batch 47 in epoch 12, gen_loss = 0.8089280743151903, disc_loss = 0.07642187942595531
Trained batch 48 in epoch 12, gen_loss = 0.8062269559928349, disc_loss = 0.07668049682920076
Trained batch 49 in epoch 12, gen_loss = 0.8091525238752365, disc_loss = 0.07544216552749276
Trained batch 50 in epoch 12, gen_loss = 0.8132654866751503, disc_loss = 0.07777832808228684
Trained batch 51 in epoch 12, gen_loss = 0.8090296909213066, disc_loss = 0.07833828786029838
Trained batch 52 in epoch 12, gen_loss = 0.8073480326049732, disc_loss = 0.07741133248398327
Trained batch 53 in epoch 12, gen_loss = 0.8082728766732745, disc_loss = 0.07734987579493059
Trained batch 54 in epoch 12, gen_loss = 0.8067517762834375, disc_loss = 0.07761658441952683
Trained batch 55 in epoch 12, gen_loss = 0.8067513879920755, disc_loss = 0.07665544996104602
Trained batch 56 in epoch 12, gen_loss = 0.8090827616683224, disc_loss = 0.07581912629763808
Trained batch 57 in epoch 12, gen_loss = 0.8159833062311699, disc_loss = 0.07591639030403619
Trained batch 58 in epoch 12, gen_loss = 0.815222503270133, disc_loss = 0.0752562248637363
Trained batch 59 in epoch 12, gen_loss = 0.8129501973589262, disc_loss = 0.07481547446611027
Trained batch 60 in epoch 12, gen_loss = 0.8132718992037852, disc_loss = 0.07410194579756162
Trained batch 61 in epoch 12, gen_loss = 0.8109145409637882, disc_loss = 0.07489292433245047
Trained batch 62 in epoch 12, gen_loss = 0.8114231905293843, disc_loss = 0.07456219091361004
Trained batch 63 in epoch 12, gen_loss = 0.8092977968044579, disc_loss = 0.07400655596575234
Trained batch 64 in epoch 12, gen_loss = 0.8087743525321667, disc_loss = 0.07469512810214207
Trained batch 65 in epoch 12, gen_loss = 0.8104611495227525, disc_loss = 0.07438697373833168
Trained batch 66 in epoch 12, gen_loss = 0.8072710299669806, disc_loss = 0.07489878730153415
Trained batch 67 in epoch 12, gen_loss = 0.8062745889320093, disc_loss = 0.07417223105371437
Trained batch 68 in epoch 12, gen_loss = 0.8114255576030068, disc_loss = 0.07348947903222364
Trained batch 69 in epoch 12, gen_loss = 0.8082623588187354, disc_loss = 0.07343397264235786
Trained batch 70 in epoch 12, gen_loss = 0.8115407316617562, disc_loss = 0.07295053794612767
Trained batch 71 in epoch 12, gen_loss = 0.8112115640607145, disc_loss = 0.07218420791387972
Trained batch 72 in epoch 12, gen_loss = 0.8078743419418596, disc_loss = 0.07233595783018494
Trained batch 73 in epoch 12, gen_loss = 0.8125581922563346, disc_loss = 0.07185445460365028
Trained batch 74 in epoch 12, gen_loss = 0.813365181684494, disc_loss = 0.07139847781509161
Trained batch 75 in epoch 12, gen_loss = 0.8158476544838202, disc_loss = 0.0721171963592305
Trained batch 76 in epoch 12, gen_loss = 0.8135149211852581, disc_loss = 0.07322977605433047
Trained batch 77 in epoch 12, gen_loss = 0.8146058959074509, disc_loss = 0.07255220734394896
Trained batch 78 in epoch 12, gen_loss = 0.8174638834935201, disc_loss = 0.0741921159309111
Trained batch 79 in epoch 12, gen_loss = 0.8138786535710096, disc_loss = 0.07518562466138974
Trained batch 80 in epoch 12, gen_loss = 0.8134850642563384, disc_loss = 0.0756461906971203
Trained batch 81 in epoch 12, gen_loss = 0.8131394019214119, disc_loss = 0.07698908935460012
Trained batch 82 in epoch 12, gen_loss = 0.8103249220244856, disc_loss = 0.07760853846613543
Trained batch 83 in epoch 12, gen_loss = 0.8091627611290841, disc_loss = 0.07769901302110936
Trained batch 84 in epoch 12, gen_loss = 0.8101698549354778, disc_loss = 0.07729026540456449
Trained batch 85 in epoch 12, gen_loss = 0.8110137668459915, disc_loss = 0.07658362829364664
Trained batch 86 in epoch 12, gen_loss = 0.8122514256800728, disc_loss = 0.07606072530107594
Trained batch 87 in epoch 12, gen_loss = 0.8127257956022566, disc_loss = 0.07546290567949075
Trained batch 88 in epoch 12, gen_loss = 0.8140364707855696, disc_loss = 0.07476316066982036
Trained batch 89 in epoch 12, gen_loss = 0.8145355406734679, disc_loss = 0.07415463764013516
Trained batch 90 in epoch 12, gen_loss = 0.8141748410659831, disc_loss = 0.07399563148494932
Trained batch 91 in epoch 12, gen_loss = 0.8147557270915612, disc_loss = 0.07332250855498663
Trained batch 92 in epoch 12, gen_loss = 0.8172220129479644, disc_loss = 0.07262813047535958
Trained batch 93 in epoch 12, gen_loss = 0.8189056550568723, disc_loss = 0.07198796308341812
Trained batch 94 in epoch 12, gen_loss = 0.8206305463063089, disc_loss = 0.07132931263431122
Trained batch 95 in epoch 12, gen_loss = 0.8210269284124175, disc_loss = 0.07080282664780195
Trained batch 96 in epoch 12, gen_loss = 0.8216132401805563, disc_loss = 0.07016296710665386
Trained batch 97 in epoch 12, gen_loss = 0.8266907416436137, disc_loss = 0.07019777864940008
Trained batch 98 in epoch 12, gen_loss = 0.8260621232817872, disc_loss = 0.06979443397222444
Trained batch 99 in epoch 12, gen_loss = 0.8258415403962135, disc_loss = 0.0693537177797407
Trained batch 100 in epoch 12, gen_loss = 0.8258136501996824, disc_loss = 0.06891902520478067
Trained batch 101 in epoch 12, gen_loss = 0.8270994743295744, disc_loss = 0.06832686608072881
Trained batch 102 in epoch 12, gen_loss = 0.8300518656818612, disc_loss = 0.0678051224846429
Trained batch 103 in epoch 12, gen_loss = 0.8302288092672825, disc_loss = 0.06735583438645475
Trained batch 104 in epoch 12, gen_loss = 0.830575499364308, disc_loss = 0.06688143544431244
Trained batch 105 in epoch 12, gen_loss = 0.8303169430989139, disc_loss = 0.06648999915616412
Trained batch 106 in epoch 12, gen_loss = 0.8331735549129058, disc_loss = 0.06599001635179341
Trained batch 107 in epoch 12, gen_loss = 0.8322256651741488, disc_loss = 0.06561933062901651
Trained batch 108 in epoch 12, gen_loss = 0.8295066517974259, disc_loss = 0.06566823333706878
Trained batch 109 in epoch 12, gen_loss = 0.8314584382555702, disc_loss = 0.06611799704418941
Trained batch 110 in epoch 12, gen_loss = 0.8344892207029704, disc_loss = 0.06566467141178814
Trained batch 111 in epoch 12, gen_loss = 0.8346006473792451, disc_loss = 0.06539510734312769
Trained batch 112 in epoch 12, gen_loss = 0.8343350362461225, disc_loss = 0.06519491780977861
Trained batch 113 in epoch 12, gen_loss = 0.8349446337996868, disc_loss = 0.06469229692103047
Trained batch 114 in epoch 12, gen_loss = 0.8366147743619007, disc_loss = 0.06420023849476938
Trained batch 115 in epoch 12, gen_loss = 0.8378670942680589, disc_loss = 0.06372191059274664
Trained batch 116 in epoch 12, gen_loss = 0.8366226001173003, disc_loss = 0.06343933061943349
Trained batch 117 in epoch 12, gen_loss = 0.8384406215558617, disc_loss = 0.06330434508400701
Trained batch 118 in epoch 12, gen_loss = 0.838809412817995, disc_loss = 0.06297873900498913
Trained batch 119 in epoch 12, gen_loss = 0.839426214247942, disc_loss = 0.06250973839002351
Trained batch 120 in epoch 12, gen_loss = 0.8409793128159421, disc_loss = 0.06204717753316499
Trained batch 121 in epoch 12, gen_loss = 0.8406435024054324, disc_loss = 0.06180344844908744
Trained batch 122 in epoch 12, gen_loss = 0.8425847328290706, disc_loss = 0.06152679829487229
Trained batch 123 in epoch 12, gen_loss = 0.8445273375799579, disc_loss = 0.061094562155044364
Trained batch 124 in epoch 12, gen_loss = 0.8449128024578094, disc_loss = 0.060660653579980135
Trained batch 125 in epoch 12, gen_loss = 0.8461963910432089, disc_loss = 0.06031455754834626
Trained batch 126 in epoch 12, gen_loss = 0.8464789829385562, disc_loss = 0.060024220646747686
Trained batch 127 in epoch 12, gen_loss = 0.8451096329372376, disc_loss = 0.060508623198984424
Trained batch 128 in epoch 12, gen_loss = 0.8497941630293232, disc_loss = 0.061138970391146207
Trained batch 129 in epoch 12, gen_loss = 0.8538440069326988, disc_loss = 0.06125450633251323
Trained batch 130 in epoch 12, gen_loss = 0.8533256979844043, disc_loss = 0.06129276940513772
Trained batch 131 in epoch 12, gen_loss = 0.8521456445256869, disc_loss = 0.061260685807968854
Trained batch 132 in epoch 12, gen_loss = 0.8516086499045666, disc_loss = 0.06090598648301977
Trained batch 133 in epoch 12, gen_loss = 0.8537206763207023, disc_loss = 0.062241949248753155
Trained batch 134 in epoch 12, gen_loss = 0.850957997419216, disc_loss = 0.06279638663141264
Trained batch 135 in epoch 12, gen_loss = 0.8526667687384522, disc_loss = 0.06294101246235453
Trained batch 136 in epoch 12, gen_loss = 0.852198217689556, disc_loss = 0.06272136561069501
Trained batch 137 in epoch 12, gen_loss = 0.8525902557632198, disc_loss = 0.06241074622527737
Trained batch 138 in epoch 12, gen_loss = 0.8511780519708455, disc_loss = 0.062401872607309825
Trained batch 139 in epoch 12, gen_loss = 0.8504578979951994, disc_loss = 0.06234064644668251
Trained batch 140 in epoch 12, gen_loss = 0.851465050844436, disc_loss = 0.062163382342600444
Trained batch 141 in epoch 12, gen_loss = 0.8522153049707413, disc_loss = 0.06181989125841835
Trained batch 142 in epoch 12, gen_loss = 0.8529764895255749, disc_loss = 0.06148947153071111
Trained batch 143 in epoch 12, gen_loss = 0.8527117083883948, disc_loss = 0.061210523957722925
Trained batch 144 in epoch 12, gen_loss = 0.8531029736173564, disc_loss = 0.06099689333410613
Trained batch 145 in epoch 12, gen_loss = 0.8556173029419494, disc_loss = 0.060745373014233085
Trained batch 146 in epoch 12, gen_loss = 0.8559326312574399, disc_loss = 0.06041920267767748
Trained batch 147 in epoch 12, gen_loss = 0.855453591693092, disc_loss = 0.060212272348360636
Trained batch 148 in epoch 12, gen_loss = 0.8540467477884869, disc_loss = 0.06016895392809638
Trained batch 149 in epoch 12, gen_loss = 0.8552136260271073, disc_loss = 0.060796776292845606
Trained batch 150 in epoch 12, gen_loss = 0.8538033755015064, disc_loss = 0.0609173498190446
Trained batch 151 in epoch 12, gen_loss = 0.8533103679747958, disc_loss = 0.06067302552554266
Trained batch 152 in epoch 12, gen_loss = 0.8551234304904938, disc_loss = 0.06224644928257547
Trained batch 153 in epoch 12, gen_loss = 0.8527807790737647, disc_loss = 0.06381727294548863
Trained batch 154 in epoch 12, gen_loss = 0.8509878527733588, disc_loss = 0.06446062032313597
Trained batch 155 in epoch 12, gen_loss = 0.8516089343107663, disc_loss = 0.06480050845465694
Trained batch 156 in epoch 12, gen_loss = 0.8498560615405915, disc_loss = 0.06513992833732894
Trained batch 157 in epoch 12, gen_loss = 0.8486006569258774, disc_loss = 0.06497833825046598
Trained batch 158 in epoch 12, gen_loss = 0.8494210434409807, disc_loss = 0.06483930638997154
Trained batch 159 in epoch 12, gen_loss = 0.8495233524590731, disc_loss = 0.06465626732970123
Trained batch 160 in epoch 12, gen_loss = 0.8486652955505418, disc_loss = 0.06456621978374094
Trained batch 161 in epoch 12, gen_loss = 0.8490533059761848, disc_loss = 0.06452705418219629
Trained batch 162 in epoch 12, gen_loss = 0.8484450074061294, disc_loss = 0.06439649767636613
Trained batch 163 in epoch 12, gen_loss = 0.8482917274643735, disc_loss = 0.06430912766571543
Trained batch 164 in epoch 12, gen_loss = 0.8508464209961168, disc_loss = 0.06470236637432016
Trained batch 165 in epoch 12, gen_loss = 0.8511483342532652, disc_loss = 0.06441263982700746
Trained batch 166 in epoch 12, gen_loss = 0.8523714438883844, disc_loss = 0.06414470225182212
Trained batch 167 in epoch 12, gen_loss = 0.850939310732342, disc_loss = 0.0642015668480391
Trained batch 168 in epoch 12, gen_loss = 0.8522156681534807, disc_loss = 0.06419601945272653
Trained batch 169 in epoch 12, gen_loss = 0.8530816519961638, disc_loss = 0.06403043551973123
Trained batch 170 in epoch 12, gen_loss = 0.8532145134886803, disc_loss = 0.06411637410750254
Trained batch 171 in epoch 12, gen_loss = 0.8519936203956604, disc_loss = 0.06423504877196581
Trained batch 172 in epoch 12, gen_loss = 0.8533851066765757, disc_loss = 0.06408270893381596
Trained batch 173 in epoch 12, gen_loss = 0.8550683020175188, disc_loss = 0.06388878434007966
Trained batch 174 in epoch 12, gen_loss = 0.854752539225987, disc_loss = 0.06375023387638586
Trained batch 175 in epoch 12, gen_loss = 0.8547303734177892, disc_loss = 0.06359316636437805
Trained batch 176 in epoch 12, gen_loss = 0.8552837176511516, disc_loss = 0.0633652802414687
Trained batch 177 in epoch 12, gen_loss = 0.8555239221353209, disc_loss = 0.06311709255116123
Trained batch 178 in epoch 12, gen_loss = 0.8561352151732206, disc_loss = 0.06302028483653951
Trained batch 179 in epoch 12, gen_loss = 0.8555658837159474, disc_loss = 0.06283416965614176
Trained batch 180 in epoch 12, gen_loss = 0.8554763425120991, disc_loss = 0.06264356034164682
Trained batch 181 in epoch 12, gen_loss = 0.8560828189928453, disc_loss = 0.062495035746206455
Trained batch 182 in epoch 12, gen_loss = 0.8550963476707375, disc_loss = 0.062459568144458404
Trained batch 183 in epoch 12, gen_loss = 0.8563320387316786, disc_loss = 0.062177397100680064
Trained batch 184 in epoch 12, gen_loss = 0.855561395915779, disc_loss = 0.06266102826323461
Trained batch 185 in epoch 12, gen_loss = 0.8550249383013736, disc_loss = 0.06270017626354851
Trained batch 186 in epoch 12, gen_loss = 0.8539108554309702, disc_loss = 0.06270302899112118
Trained batch 187 in epoch 12, gen_loss = 0.8539541788557743, disc_loss = 0.06326058851010068
Trained batch 188 in epoch 12, gen_loss = 0.8531684777724049, disc_loss = 0.06353284571585911
Trained batch 189 in epoch 12, gen_loss = 0.852979924804286, disc_loss = 0.06347172041913789
Trained batch 190 in epoch 12, gen_loss = 0.853651082640543, disc_loss = 0.06377528999147068
Trained batch 191 in epoch 12, gen_loss = 0.8541637479017178, disc_loss = 0.0637464432050668
Trained batch 192 in epoch 12, gen_loss = 0.8536850223269488, disc_loss = 0.06375238997379193
Trained batch 193 in epoch 12, gen_loss = 0.8524110135958367, disc_loss = 0.06384708674038886
Trained batch 194 in epoch 12, gen_loss = 0.8523541404650762, disc_loss = 0.06390168692868872
Trained batch 195 in epoch 12, gen_loss = 0.8538167449284573, disc_loss = 0.06432389455837939
Trained batch 196 in epoch 12, gen_loss = 0.8525412944972818, disc_loss = 0.0648037085077976
Trained batch 197 in epoch 12, gen_loss = 0.8528086049388154, disc_loss = 0.06482011255939876
Trained batch 198 in epoch 12, gen_loss = 0.8520971503689061, disc_loss = 0.06585842815822168
Trained batch 199 in epoch 12, gen_loss = 0.8500048217177391, disc_loss = 0.0666940629039891
Trained batch 200 in epoch 12, gen_loss = 0.8490844979808105, disc_loss = 0.06709261330548878
Trained batch 201 in epoch 12, gen_loss = 0.8492367317770967, disc_loss = 0.06708672354320562
Trained batch 202 in epoch 12, gen_loss = 0.8501963606608912, disc_loss = 0.06718708797968154
Trained batch 203 in epoch 12, gen_loss = 0.8493579664066726, disc_loss = 0.06705810329831187
Trained batch 204 in epoch 12, gen_loss = 0.8480529991591849, disc_loss = 0.06714441695636729
Trained batch 205 in epoch 12, gen_loss = 0.8496755364450436, disc_loss = 0.06765074665585841
Trained batch 206 in epoch 12, gen_loss = 0.8495723878703831, disc_loss = 0.06741036067307356
Trained batch 207 in epoch 12, gen_loss = 0.8482104413784467, disc_loss = 0.067551210730856
Trained batch 208 in epoch 12, gen_loss = 0.8493158418025697, disc_loss = 0.06743544558704827
Trained batch 209 in epoch 12, gen_loss = 0.8488723402931577, disc_loss = 0.06734433412951019
Trained batch 210 in epoch 12, gen_loss = 0.8480764579433966, disc_loss = 0.06731100547484947
Trained batch 211 in epoch 12, gen_loss = 0.8483295331023774, disc_loss = 0.06718251335144676
Trained batch 212 in epoch 12, gen_loss = 0.8485445147948646, disc_loss = 0.06722141100321087
Trained batch 213 in epoch 12, gen_loss = 0.8477763583726972, disc_loss = 0.06723081909999182
Trained batch 214 in epoch 12, gen_loss = 0.8491275399230247, disc_loss = 0.06700941689182506
Trained batch 215 in epoch 12, gen_loss = 0.8502378590680935, disc_loss = 0.06688725413038844
Trained batch 216 in epoch 12, gen_loss = 0.850549663266828, disc_loss = 0.06664947025297631
Trained batch 217 in epoch 12, gen_loss = 0.8492869770308153, disc_loss = 0.06694542568544387
Trained batch 218 in epoch 12, gen_loss = 0.8494168958163153, disc_loss = 0.06671320810089032
Trained batch 219 in epoch 12, gen_loss = 0.8514534156430852, disc_loss = 0.06689214150802317
Trained batch 220 in epoch 12, gen_loss = 0.8514797725289116, disc_loss = 0.0667144309674554
Trained batch 221 in epoch 12, gen_loss = 0.8513845226786159, disc_loss = 0.06652621021032804
Trained batch 222 in epoch 12, gen_loss = 0.8506290001184951, disc_loss = 0.06672110166943594
Trained batch 223 in epoch 12, gen_loss = 0.8512514552899769, disc_loss = 0.06666714104981761
Trained batch 224 in epoch 12, gen_loss = 0.8512872489293416, disc_loss = 0.0664279214065108
Trained batch 225 in epoch 12, gen_loss = 0.8519392498826559, disc_loss = 0.06618042185333912
Trained batch 226 in epoch 12, gen_loss = 0.8519133886051599, disc_loss = 0.06610017605248987
Trained batch 227 in epoch 12, gen_loss = 0.8528616119895065, disc_loss = 0.06587376771290508
Trained batch 228 in epoch 12, gen_loss = 0.8530246297865456, disc_loss = 0.06562581304745448
Trained batch 229 in epoch 12, gen_loss = 0.8531650841236115, disc_loss = 0.06537128948282613
Trained batch 230 in epoch 12, gen_loss = 0.8526982417354336, disc_loss = 0.06526297942666716
Trained batch 231 in epoch 12, gen_loss = 0.8542535605615583, disc_loss = 0.0654625074580665
Trained batch 232 in epoch 12, gen_loss = 0.8528558657916319, disc_loss = 0.06553586475479181
Trained batch 233 in epoch 12, gen_loss = 0.8530751550808932, disc_loss = 0.0652862356370713
Trained batch 234 in epoch 12, gen_loss = 0.8535028381550566, disc_loss = 0.06505251485616603
Trained batch 235 in epoch 12, gen_loss = 0.8524558683068065, disc_loss = 0.06512456876620398
Trained batch 236 in epoch 12, gen_loss = 0.8535084882868996, disc_loss = 0.0655446139631895
Trained batch 237 in epoch 12, gen_loss = 0.8518232926100242, disc_loss = 0.06593513485639035
Trained batch 238 in epoch 12, gen_loss = 0.8520173098751691, disc_loss = 0.06571437370141181
Trained batch 239 in epoch 12, gen_loss = 0.8523090938727061, disc_loss = 0.06551515442940097
Trained batch 240 in epoch 12, gen_loss = 0.8521401313330622, disc_loss = 0.06531048219851933
Trained batch 241 in epoch 12, gen_loss = 0.8536578382342315, disc_loss = 0.06554922446115943
Trained batch 242 in epoch 12, gen_loss = 0.852816257947757, disc_loss = 0.06554508052858306
Trained batch 243 in epoch 12, gen_loss = 0.8521106712153701, disc_loss = 0.06556628897908282
Trained batch 244 in epoch 12, gen_loss = 0.8516253714658776, disc_loss = 0.0655010238289833
Trained batch 245 in epoch 12, gen_loss = 0.8526277677799629, disc_loss = 0.06576906656467818
Trained batch 246 in epoch 12, gen_loss = 0.8520246942033652, disc_loss = 0.06583136781627832
Trained batch 247 in epoch 12, gen_loss = 0.8508801912107775, disc_loss = 0.06624836393541866
Trained batch 248 in epoch 12, gen_loss = 0.85108217154162, disc_loss = 0.06601855172270751
Trained batch 249 in epoch 12, gen_loss = 0.8513933844566345, disc_loss = 0.06592802898585796
Trained batch 250 in epoch 12, gen_loss = 0.8514815293460253, disc_loss = 0.06574494699646989
Trained batch 251 in epoch 12, gen_loss = 0.8513148883505474, disc_loss = 0.06560081106773208
Trained batch 252 in epoch 12, gen_loss = 0.8512301409668602, disc_loss = 0.06553067434063778
Trained batch 253 in epoch 12, gen_loss = 0.8508422182300898, disc_loss = 0.06547799586927093
Trained batch 254 in epoch 12, gen_loss = 0.8511231188680611, disc_loss = 0.06526896644602803
Trained batch 255 in epoch 12, gen_loss = 0.8526056702248752, disc_loss = 0.06516998649021843
Trained batch 256 in epoch 12, gen_loss = 0.852901078615671, disc_loss = 0.06497926954252478
Trained batch 257 in epoch 12, gen_loss = 0.8521564166213191, disc_loss = 0.06501016291508148
Trained batch 258 in epoch 12, gen_loss = 0.8537198901176453, disc_loss = 0.06500397998710167
Trained batch 259 in epoch 12, gen_loss = 0.8545034745564828, disc_loss = 0.0647974006831646
Trained batch 260 in epoch 12, gen_loss = 0.8549942673394506, disc_loss = 0.06460361503835382
Trained batch 261 in epoch 12, gen_loss = 0.855414520238192, disc_loss = 0.0644489285742281
Trained batch 262 in epoch 12, gen_loss = 0.8549398260878066, disc_loss = 0.06452216251891375
Trained batch 263 in epoch 12, gen_loss = 0.8553305421814774, disc_loss = 0.06444644239364249
Trained batch 264 in epoch 12, gen_loss = 0.8554466679411115, disc_loss = 0.06436477348489582
Trained batch 265 in epoch 12, gen_loss = 0.8560283394684469, disc_loss = 0.06416407635057331
Trained batch 266 in epoch 12, gen_loss = 0.8552865647198109, disc_loss = 0.06414990287539218
Trained batch 267 in epoch 12, gen_loss = 0.8550059194885083, disc_loss = 0.0648716997160618
Trained batch 268 in epoch 12, gen_loss = 0.8544907459095952, disc_loss = 0.06483060345884592
Trained batch 269 in epoch 12, gen_loss = 0.8546332306332058, disc_loss = 0.06462848043000256
Trained batch 270 in epoch 12, gen_loss = 0.8533726429147473, disc_loss = 0.06491854500946523
Trained batch 271 in epoch 12, gen_loss = 0.8539724310531336, disc_loss = 0.06480432748246719
Trained batch 272 in epoch 12, gen_loss = 0.8546729327994825, disc_loss = 0.06545798101158806
Trained batch 273 in epoch 12, gen_loss = 0.8546719259589258, disc_loss = 0.06526608937453941
Trained batch 274 in epoch 12, gen_loss = 0.8532848092642698, disc_loss = 0.06569753157482906
Trained batch 275 in epoch 12, gen_loss = 0.8530419055318487, disc_loss = 0.06559396900601037
Trained batch 276 in epoch 12, gen_loss = 0.8546617083816321, disc_loss = 0.065701126551343
Trained batch 277 in epoch 12, gen_loss = 0.854298995231553, disc_loss = 0.06569416974771687
Trained batch 278 in epoch 12, gen_loss = 0.8537722453207952, disc_loss = 0.0656482055749891
Trained batch 279 in epoch 12, gen_loss = 0.8542661848877158, disc_loss = 0.06567257565246629
Trained batch 280 in epoch 12, gen_loss = 0.8543939118495615, disc_loss = 0.06567266723638221
Trained batch 281 in epoch 12, gen_loss = 0.8529321102174461, disc_loss = 0.06611111202336689
Trained batch 282 in epoch 12, gen_loss = 0.8526963253535146, disc_loss = 0.0660487497620311
Trained batch 283 in epoch 12, gen_loss = 0.8540133499133755, disc_loss = 0.06608193634982995
Trained batch 284 in epoch 12, gen_loss = 0.8546383854589964, disc_loss = 0.06628891872405483
Trained batch 285 in epoch 12, gen_loss = 0.8540590433599232, disc_loss = 0.0663364713497043
Trained batch 286 in epoch 12, gen_loss = 0.8542052614356582, disc_loss = 0.06618127192107746
Trained batch 287 in epoch 12, gen_loss = 0.8543116561033659, disc_loss = 0.06613991750054993
Trained batch 288 in epoch 12, gen_loss = 0.8532454308547776, disc_loss = 0.06645520422349854
Trained batch 289 in epoch 12, gen_loss = 0.8527902704888377, disc_loss = 0.06637234977157465
Trained batch 290 in epoch 12, gen_loss = 0.8525077156799356, disc_loss = 0.06630764529429044
Trained batch 291 in epoch 12, gen_loss = 0.8528319869751799, disc_loss = 0.0666759415395711
Trained batch 292 in epoch 12, gen_loss = 0.8532947846036723, disc_loss = 0.06655153449395919
Trained batch 293 in epoch 12, gen_loss = 0.852694894687659, disc_loss = 0.0667584749337818
Trained batch 294 in epoch 12, gen_loss = 0.8524219578605587, disc_loss = 0.06688072083170636
Trained batch 295 in epoch 12, gen_loss = 0.85167270385333, disc_loss = 0.06712551367456547
Trained batch 296 in epoch 12, gen_loss = 0.8522901740740445, disc_loss = 0.06696271855283767
Trained batch 297 in epoch 12, gen_loss = 0.8515229730198047, disc_loss = 0.06697577402158171
Trained batch 298 in epoch 12, gen_loss = 0.8520935583473448, disc_loss = 0.06684747809562895
Trained batch 299 in epoch 12, gen_loss = 0.852735333542029, disc_loss = 0.06669348930629591
Trained batch 300 in epoch 12, gen_loss = 0.8522107590274557, disc_loss = 0.06678111534689452
Trained batch 301 in epoch 12, gen_loss = 0.8517334458251663, disc_loss = 0.06670270576789383
Trained batch 302 in epoch 12, gen_loss = 0.8515630603426754, disc_loss = 0.06668110280651168
Trained batch 303 in epoch 12, gen_loss = 0.8520559724420309, disc_loss = 0.06684186513302848
Trained batch 304 in epoch 12, gen_loss = 0.8515075422701288, disc_loss = 0.066971432848177
Trained batch 305 in epoch 12, gen_loss = 0.8517180538060618, disc_loss = 0.0668604638263145
Trained batch 306 in epoch 12, gen_loss = 0.8517432039063606, disc_loss = 0.06676052670003634
Trained batch 307 in epoch 12, gen_loss = 0.8515768988759487, disc_loss = 0.06667125306406675
Trained batch 308 in epoch 12, gen_loss = 0.8513947716615733, disc_loss = 0.06654507982993685
Trained batch 309 in epoch 12, gen_loss = 0.8515105504182077, disc_loss = 0.0663724044848594
Trained batch 310 in epoch 12, gen_loss = 0.8524368356470127, disc_loss = 0.06639993370142301
Trained batch 311 in epoch 12, gen_loss = 0.8527191649071681, disc_loss = 0.06629234031499483
Trained batch 312 in epoch 12, gen_loss = 0.8519502134559254, disc_loss = 0.06650068051220415
Trained batch 313 in epoch 12, gen_loss = 0.852928939044096, disc_loss = 0.06641799000026599
Trained batch 314 in epoch 12, gen_loss = 0.8529662540034643, disc_loss = 0.06636253159847998
Trained batch 315 in epoch 12, gen_loss = 0.852892321404777, disc_loss = 0.0661981138960706
Trained batch 316 in epoch 12, gen_loss = 0.8519558608531952, disc_loss = 0.06626488424966857
Trained batch 317 in epoch 12, gen_loss = 0.8510242534695931, disc_loss = 0.06635253254687355
Trained batch 318 in epoch 12, gen_loss = 0.8525852165812609, disc_loss = 0.0665937856125841
Trained batch 319 in epoch 12, gen_loss = 0.8518993434496224, disc_loss = 0.06658489042019937
Trained batch 320 in epoch 12, gen_loss = 0.851871915788294, disc_loss = 0.06650516063822114
Trained batch 321 in epoch 12, gen_loss = 0.8525709125751294, disc_loss = 0.06661812024283575
Trained batch 322 in epoch 12, gen_loss = 0.853298624694901, disc_loss = 0.06646144674693007
Trained batch 323 in epoch 12, gen_loss = 0.8537405020108929, disc_loss = 0.06638484570933621
Trained batch 324 in epoch 12, gen_loss = 0.8528685704561381, disc_loss = 0.06660160017414735
Trained batch 325 in epoch 12, gen_loss = 0.8530979203117406, disc_loss = 0.06661055916691759
Trained batch 326 in epoch 12, gen_loss = 0.8539597702864842, disc_loss = 0.06671804766988079
Trained batch 327 in epoch 12, gen_loss = 0.8534183890172621, disc_loss = 0.06669559429411026
Trained batch 328 in epoch 12, gen_loss = 0.8529869494648328, disc_loss = 0.06667634031500407
Trained batch 329 in epoch 12, gen_loss = 0.8536335770830964, disc_loss = 0.06650267306884582
Trained batch 330 in epoch 12, gen_loss = 0.8528948229065114, disc_loss = 0.06647894637563527
Trained batch 331 in epoch 12, gen_loss = 0.8532519660979868, disc_loss = 0.06633501810986683
Trained batch 332 in epoch 12, gen_loss = 0.8536781417177962, disc_loss = 0.06616186121529019
Trained batch 333 in epoch 12, gen_loss = 0.8535106124099857, disc_loss = 0.06601611627154276
Trained batch 334 in epoch 12, gen_loss = 0.8533890433275878, disc_loss = 0.06589767594557645
Trained batch 335 in epoch 12, gen_loss = 0.8533452750139293, disc_loss = 0.06575488521706402
Trained batch 336 in epoch 12, gen_loss = 0.8532590113513902, disc_loss = 0.06569705738545083
Trained batch 337 in epoch 12, gen_loss = 0.8538325637931654, disc_loss = 0.0655434310529932
Trained batch 338 in epoch 12, gen_loss = 0.8541952555334322, disc_loss = 0.06538132393243654
Trained batch 339 in epoch 12, gen_loss = 0.8546128396602238, disc_loss = 0.06526989190400961
Trained batch 340 in epoch 12, gen_loss = 0.8537805011370315, disc_loss = 0.06555179808878742
Trained batch 341 in epoch 12, gen_loss = 0.8537748191963163, disc_loss = 0.06540262271862543
Trained batch 342 in epoch 12, gen_loss = 0.8540988282107751, disc_loss = 0.0652370872709129
Trained batch 343 in epoch 12, gen_loss = 0.8547858069975709, disc_loss = 0.06511657829071547
Trained batch 344 in epoch 12, gen_loss = 0.854766314185184, disc_loss = 0.06521116407669109
Trained batch 345 in epoch 12, gen_loss = 0.8548627925573746, disc_loss = 0.06510275248115117
Trained batch 346 in epoch 12, gen_loss = 0.8549462315500298, disc_loss = 0.0649586190101865
Trained batch 347 in epoch 12, gen_loss = 0.8545049823734953, disc_loss = 0.06494783585216722
Trained batch 348 in epoch 12, gen_loss = 0.8545725288397945, disc_loss = 0.06482735175084334
Trained batch 349 in epoch 12, gen_loss = 0.8551548022031784, disc_loss = 0.06467989831896764
Trained batch 350 in epoch 12, gen_loss = 0.8557334015002618, disc_loss = 0.06456755478720465
Trained batch 351 in epoch 12, gen_loss = 0.8560201181098819, disc_loss = 0.06440776446040465
Trained batch 352 in epoch 12, gen_loss = 0.8560021181113322, disc_loss = 0.06425398589499695
Trained batch 353 in epoch 12, gen_loss = 0.8553476841267893, disc_loss = 0.06462045192013437
Trained batch 354 in epoch 12, gen_loss = 0.8550716342220843, disc_loss = 0.06454450487303481
Trained batch 355 in epoch 12, gen_loss = 0.8568340887346965, disc_loss = 0.06570506940616734
Trained batch 356 in epoch 12, gen_loss = 0.8569066610489907, disc_loss = 0.0656087448538727
Trained batch 357 in epoch 12, gen_loss = 0.8561615681681554, disc_loss = 0.06613557847404031
Trained batch 358 in epoch 12, gen_loss = 0.8558238782092389, disc_loss = 0.06615630766859376
Trained batch 359 in epoch 12, gen_loss = 0.8564364440739155, disc_loss = 0.06671664651948958
Trained batch 360 in epoch 12, gen_loss = 0.8560769340833468, disc_loss = 0.06669594724391718
Trained batch 361 in epoch 12, gen_loss = 0.8555724443816348, disc_loss = 0.06679628691919025
Trained batch 362 in epoch 12, gen_loss = 0.8553156223014695, disc_loss = 0.06672199043001435
Trained batch 363 in epoch 12, gen_loss = 0.8551717728867636, disc_loss = 0.06662657444754226
Trained batch 364 in epoch 12, gen_loss = 0.8553665112959196, disc_loss = 0.06675246299997176
Trained batch 365 in epoch 12, gen_loss = 0.8555865247881478, disc_loss = 0.06671135232636267
Trained batch 366 in epoch 12, gen_loss = 0.8550719466943507, disc_loss = 0.0666992960051108
Trained batch 367 in epoch 12, gen_loss = 0.8546946997065907, disc_loss = 0.06675197393886502
Trained batch 368 in epoch 12, gen_loss = 0.8548824272666197, disc_loss = 0.06665352256186205
Trained batch 369 in epoch 12, gen_loss = 0.8544411007616971, disc_loss = 0.06702566999388306
Trained batch 370 in epoch 12, gen_loss = 0.854289443264753, disc_loss = 0.06693265455300515
Trained batch 371 in epoch 12, gen_loss = 0.854923147908462, disc_loss = 0.06682068809256038
Trained batch 372 in epoch 12, gen_loss = 0.8546861642647046, disc_loss = 0.06670880981598638
Trained batch 373 in epoch 12, gen_loss = 0.8542509355487671, disc_loss = 0.06674812129265405
Trained batch 374 in epoch 12, gen_loss = 0.8552478665510813, disc_loss = 0.0669188103750348
Trained batch 375 in epoch 12, gen_loss = 0.8547450284215998, disc_loss = 0.06681513531936055
Trained batch 376 in epoch 12, gen_loss = 0.854967141578305, disc_loss = 0.06683334752927171
Trained batch 377 in epoch 12, gen_loss = 0.8544464220918676, disc_loss = 0.06674961375427388
Trained batch 378 in epoch 12, gen_loss = 0.8540549032134557, disc_loss = 0.06685850985770883
Trained batch 379 in epoch 12, gen_loss = 0.8544266919556417, disc_loss = 0.06685150412989682
Trained batch 380 in epoch 12, gen_loss = 0.8547737336377772, disc_loss = 0.06687430744340492
Trained batch 381 in epoch 12, gen_loss = 0.8545934255990683, disc_loss = 0.06675302870912936
Trained batch 382 in epoch 12, gen_loss = 0.8536636409964947, disc_loss = 0.06715564462587276
Trained batch 383 in epoch 12, gen_loss = 0.8538295479957014, disc_loss = 0.06706313158065313
Trained batch 384 in epoch 12, gen_loss = 0.8541492433517011, disc_loss = 0.06694724577442779
Trained batch 385 in epoch 12, gen_loss = 0.8545372482254098, disc_loss = 0.06726240307102317
Trained batch 386 in epoch 12, gen_loss = 0.8542933219933079, disc_loss = 0.06716947805482981
Trained batch 387 in epoch 12, gen_loss = 0.8539070222027523, disc_loss = 0.06718131735892102
Trained batch 388 in epoch 12, gen_loss = 0.8537792164286488, disc_loss = 0.06707414210197016
Trained batch 389 in epoch 12, gen_loss = 0.8535534964922147, disc_loss = 0.0669531260473797
Trained batch 390 in epoch 12, gen_loss = 0.8548447219154719, disc_loss = 0.06710594049547716
Trained batch 391 in epoch 12, gen_loss = 0.8549265161308707, disc_loss = 0.06695637873335912
Trained batch 392 in epoch 12, gen_loss = 0.8547680119370079, disc_loss = 0.06682467600686177
Trained batch 393 in epoch 12, gen_loss = 0.8538867367554437, disc_loss = 0.06707284209758119
Trained batch 394 in epoch 12, gen_loss = 0.8544328299504292, disc_loss = 0.06717660932365475
Trained batch 395 in epoch 12, gen_loss = 0.8546906445514072, disc_loss = 0.0671065496633563
Trained batch 396 in epoch 12, gen_loss = 0.854773474505326, disc_loss = 0.0670073526355459
Trained batch 397 in epoch 12, gen_loss = 0.8544862118348404, disc_loss = 0.06689658079380591
Trained batch 398 in epoch 12, gen_loss = 0.8540781908913663, disc_loss = 0.06691364323799696
Trained batch 399 in epoch 12, gen_loss = 0.8544514250010252, disc_loss = 0.06679843159159646
Trained batch 400 in epoch 12, gen_loss = 0.8545683918897053, disc_loss = 0.06691908395786461
Trained batch 401 in epoch 12, gen_loss = 0.8540998520097922, disc_loss = 0.06690480005672544
Trained batch 402 in epoch 12, gen_loss = 0.8542235095063155, disc_loss = 0.06680318362151201
Trained batch 403 in epoch 12, gen_loss = 0.8540583768545991, disc_loss = 0.06669592881104955
Trained batch 404 in epoch 12, gen_loss = 0.8537086740688041, disc_loss = 0.06667974197340232
Trained batch 405 in epoch 12, gen_loss = 0.8537314819731736, disc_loss = 0.06662130666658135
Trained batch 406 in epoch 12, gen_loss = 0.853401503120652, disc_loss = 0.06654114746408542
Trained batch 407 in epoch 12, gen_loss = 0.8535558171570301, disc_loss = 0.06644419028980694
Trained batch 408 in epoch 12, gen_loss = 0.8542856912886893, disc_loss = 0.06648263819561247
Trained batch 409 in epoch 12, gen_loss = 0.8551302374136157, disc_loss = 0.06635391444376693
Trained batch 410 in epoch 12, gen_loss = 0.8542232222655683, disc_loss = 0.0666511881566287
Trained batch 411 in epoch 12, gen_loss = 0.8545810238105579, disc_loss = 0.06655050266886726
Trained batch 412 in epoch 12, gen_loss = 0.8552168041251185, disc_loss = 0.06644742646126063
Trained batch 413 in epoch 12, gen_loss = 0.8557917469221613, disc_loss = 0.06632875443035782
Trained batch 414 in epoch 12, gen_loss = 0.8555547664682549, disc_loss = 0.06625193133725818
Trained batch 415 in epoch 12, gen_loss = 0.8554336502431676, disc_loss = 0.06617951037389083
Trained batch 416 in epoch 12, gen_loss = 0.8551967733626743, disc_loss = 0.06609575840593171
Trained batch 417 in epoch 12, gen_loss = 0.8559894208845339, disc_loss = 0.06607919404479234
Trained batch 418 in epoch 12, gen_loss = 0.8564800784383013, disc_loss = 0.06595976035241793
Trained batch 419 in epoch 12, gen_loss = 0.8561716233690579, disc_loss = 0.06588729447685182
Trained batch 420 in epoch 12, gen_loss = 0.8562045367058553, disc_loss = 0.0658458859998193
Trained batch 421 in epoch 12, gen_loss = 0.8558798625147174, disc_loss = 0.06579812747421918
Trained batch 422 in epoch 12, gen_loss = 0.8556589659646894, disc_loss = 0.06574774895250868
Trained batch 423 in epoch 12, gen_loss = 0.8557780704830052, disc_loss = 0.06602688689654658
Trained batch 424 in epoch 12, gen_loss = 0.855284443953458, disc_loss = 0.066028744549874
Trained batch 425 in epoch 12, gen_loss = 0.8548358014911553, disc_loss = 0.06606745437233591
Trained batch 426 in epoch 12, gen_loss = 0.85530871634461, disc_loss = 0.0661723065392858
Trained batch 427 in epoch 12, gen_loss = 0.855450028919171, disc_loss = 0.06609462156987567
Trained batch 428 in epoch 12, gen_loss = 0.855325275576198, disc_loss = 0.0659849067133936
Trained batch 429 in epoch 12, gen_loss = 0.855241774057233, disc_loss = 0.06586555221962721
Trained batch 430 in epoch 12, gen_loss = 0.8550291373253975, disc_loss = 0.06579815449620967
Trained batch 431 in epoch 12, gen_loss = 0.8549890713421283, disc_loss = 0.06572904440582972
Trained batch 432 in epoch 12, gen_loss = 0.8553836157773439, disc_loss = 0.06560570200126592
Trained batch 433 in epoch 12, gen_loss = 0.8554635791597278, disc_loss = 0.0654962591350525
Trained batch 434 in epoch 12, gen_loss = 0.8556477041765191, disc_loss = 0.06539028202365527
Trained batch 435 in epoch 12, gen_loss = 0.8552480664685231, disc_loss = 0.06547133642710198
Trained batch 436 in epoch 12, gen_loss = 0.8552589770449108, disc_loss = 0.06539167430746269
Trained batch 437 in epoch 12, gen_loss = 0.8556109124530941, disc_loss = 0.06553617376009147
Trained batch 438 in epoch 12, gen_loss = 0.855051921481152, disc_loss = 0.06560840569054686
Trained batch 439 in epoch 12, gen_loss = 0.8544156692922116, disc_loss = 0.06570783160330558
Trained batch 440 in epoch 12, gen_loss = 0.8554741790910967, disc_loss = 0.06610076056155556
Trained batch 441 in epoch 12, gen_loss = 0.8554237962982774, disc_loss = 0.0659883582555769
Trained batch 442 in epoch 12, gen_loss = 0.8549914582722882, disc_loss = 0.06598795189587378
Trained batch 443 in epoch 12, gen_loss = 0.8549203948528917, disc_loss = 0.0659094443649624
Trained batch 444 in epoch 12, gen_loss = 0.8553743247905474, disc_loss = 0.06585569726826435
Trained batch 445 in epoch 12, gen_loss = 0.8551082364513201, disc_loss = 0.06580186414954173
Trained batch 446 in epoch 12, gen_loss = 0.8549367194074379, disc_loss = 0.06582855325092206
Trained batch 447 in epoch 12, gen_loss = 0.85451383615977, disc_loss = 0.06586326570790593
Trained batch 448 in epoch 12, gen_loss = 0.8554876869531941, disc_loss = 0.06609408157713761
Trained batch 449 in epoch 12, gen_loss = 0.8546280239025752, disc_loss = 0.06627520486919417
Trained batch 450 in epoch 12, gen_loss = 0.8549279051847309, disc_loss = 0.06618030241457229
Trained batch 451 in epoch 12, gen_loss = 0.8551270048570844, disc_loss = 0.06607483967570012
Trained batch 452 in epoch 12, gen_loss = 0.8547071195464524, disc_loss = 0.0660840030862368
Trained batch 453 in epoch 12, gen_loss = 0.8547095548082554, disc_loss = 0.06599519611643996
Trained batch 454 in epoch 12, gen_loss = 0.8549492327066568, disc_loss = 0.06588349253102974
Trained batch 455 in epoch 12, gen_loss = 0.8554225874443849, disc_loss = 0.066339011279572
Trained batch 456 in epoch 12, gen_loss = 0.8545055808723625, disc_loss = 0.06677377128594553
Trained batch 457 in epoch 12, gen_loss = 0.8543652756115234, disc_loss = 0.06669416871556288
Trained batch 458 in epoch 12, gen_loss = 0.8547426295306428, disc_loss = 0.06701159052761811
Trained batch 459 in epoch 12, gen_loss = 0.85489433504965, disc_loss = 0.0670581636302497
Trained batch 460 in epoch 12, gen_loss = 0.8544737875720166, disc_loss = 0.06707421052643378
Trained batch 461 in epoch 12, gen_loss = 0.8545024056326259, disc_loss = 0.06703569787631045
Trained batch 462 in epoch 12, gen_loss = 0.8544954066013929, disc_loss = 0.06694736622161278
Trained batch 463 in epoch 12, gen_loss = 0.8538384104211783, disc_loss = 0.06705023766623745
Trained batch 464 in epoch 12, gen_loss = 0.8545244786688077, disc_loss = 0.06727716237787278
Trained batch 465 in epoch 12, gen_loss = 0.8542347251729392, disc_loss = 0.06725296478062996
Trained batch 466 in epoch 12, gen_loss = 0.8537008285650094, disc_loss = 0.06734554546962969
Trained batch 467 in epoch 12, gen_loss = 0.8540489172451516, disc_loss = 0.06744069022596137
Trained batch 468 in epoch 12, gen_loss = 0.8539036777355015, disc_loss = 0.0673463211448462
Trained batch 469 in epoch 12, gen_loss = 0.8534078556806484, disc_loss = 0.06736286586903512
Trained batch 470 in epoch 12, gen_loss = 0.8527386408069837, disc_loss = 0.06758513281046712
Trained batch 471 in epoch 12, gen_loss = 0.8530466117722503, disc_loss = 0.067848873908742
Trained batch 472 in epoch 12, gen_loss = 0.8529743453286919, disc_loss = 0.06781465111272783
Trained batch 473 in epoch 12, gen_loss = 0.8523931773025778, disc_loss = 0.06788418669929484
Trained batch 474 in epoch 12, gen_loss = 0.8520763864642695, disc_loss = 0.0680266092482366
Trained batch 475 in epoch 12, gen_loss = 0.8518970358897658, disc_loss = 0.06833606894214113
Trained batch 476 in epoch 12, gen_loss = 0.8515298875747737, disc_loss = 0.06840409243194312
Trained batch 477 in epoch 12, gen_loss = 0.8514832785064705, disc_loss = 0.06831315827700134
Trained batch 478 in epoch 12, gen_loss = 0.8510654296780429, disc_loss = 0.06833443749454922
Trained batch 479 in epoch 12, gen_loss = 0.851273926285406, disc_loss = 0.06829601909654835
Trained batch 480 in epoch 12, gen_loss = 0.850855148693628, disc_loss = 0.06825476817461408
Trained batch 481 in epoch 12, gen_loss = 0.8504265021857385, disc_loss = 0.06830877282838356
Trained batch 482 in epoch 12, gen_loss = 0.8510813909904804, disc_loss = 0.06830998247115262
Trained batch 483 in epoch 12, gen_loss = 0.850932627854761, disc_loss = 0.06823686040045063
Trained batch 484 in epoch 12, gen_loss = 0.85108035391139, disc_loss = 0.06811821253720632
Trained batch 485 in epoch 12, gen_loss = 0.8514474455589129, disc_loss = 0.06816085604682504
Trained batch 486 in epoch 12, gen_loss = 0.8511669283897235, disc_loss = 0.06814038103687323
Trained batch 487 in epoch 12, gen_loss = 0.8508566888507272, disc_loss = 0.06813166304644136
Trained batch 488 in epoch 12, gen_loss = 0.8511083548420046, disc_loss = 0.06811026228184228
Trained batch 489 in epoch 12, gen_loss = 0.8508235983094391, disc_loss = 0.06800421712425898
Trained batch 490 in epoch 12, gen_loss = 0.8510861186170287, disc_loss = 0.06794019323032038
Trained batch 491 in epoch 12, gen_loss = 0.850828875068242, disc_loss = 0.0679265612971068
Trained batch 492 in epoch 12, gen_loss = 0.8510488790986988, disc_loss = 0.0678109585951719
Trained batch 493 in epoch 12, gen_loss = 0.8510803424033077, disc_loss = 0.06775135555217865
Trained batch 494 in epoch 12, gen_loss = 0.8507696501534394, disc_loss = 0.06778973012108995
Trained batch 495 in epoch 12, gen_loss = 0.8510794392636707, disc_loss = 0.06773278239603725
Trained batch 496 in epoch 12, gen_loss = 0.851600067536356, disc_loss = 0.06767598426407971
Trained batch 497 in epoch 12, gen_loss = 0.851639839599889, disc_loss = 0.06760483448315098
Trained batch 498 in epoch 12, gen_loss = 0.8511088188879475, disc_loss = 0.06765160690955743
Trained batch 499 in epoch 12, gen_loss = 0.8508781562447548, disc_loss = 0.06824733916670084
Trained batch 500 in epoch 12, gen_loss = 0.851035747877852, disc_loss = 0.06814697213069408
Trained batch 501 in epoch 12, gen_loss = 0.8517069623646033, disc_loss = 0.06810970198496642
Trained batch 502 in epoch 12, gen_loss = 0.8512781891031246, disc_loss = 0.06818990099056814
Trained batch 503 in epoch 12, gen_loss = 0.8512694729817292, disc_loss = 0.06810989683227879
Trained batch 504 in epoch 12, gen_loss = 0.8509293626440634, disc_loss = 0.06807086451513933
Trained batch 505 in epoch 12, gen_loss = 0.8509819128885571, disc_loss = 0.06796975306459802
Trained batch 506 in epoch 12, gen_loss = 0.851588182959566, disc_loss = 0.06789096941183187
Trained batch 507 in epoch 12, gen_loss = 0.8517834963643645, disc_loss = 0.0677733026650243
Trained batch 508 in epoch 12, gen_loss = 0.8517436252244563, disc_loss = 0.06771436789620133
Trained batch 509 in epoch 12, gen_loss = 0.8516078561544418, disc_loss = 0.06762300991617581
Trained batch 510 in epoch 12, gen_loss = 0.8514892004590678, disc_loss = 0.0675329170508744
Trained batch 511 in epoch 12, gen_loss = 0.8509066522237845, disc_loss = 0.06757694225962041
Trained batch 512 in epoch 12, gen_loss = 0.8510756776695363, disc_loss = 0.06748661311020163
Trained batch 513 in epoch 12, gen_loss = 0.8517666533879269, disc_loss = 0.06754006125786657
Trained batch 514 in epoch 12, gen_loss = 0.851614250430783, disc_loss = 0.06751012513504445
Trained batch 515 in epoch 12, gen_loss = 0.8513197757361471, disc_loss = 0.06747776695866456
Trained batch 516 in epoch 12, gen_loss = 0.8517647704372554, disc_loss = 0.06784095667028796
Trained batch 517 in epoch 12, gen_loss = 0.8517936224757935, disc_loss = 0.0677558036096768
Trained batch 518 in epoch 12, gen_loss = 0.8517738000161386, disc_loss = 0.06772884796867021
Trained batch 519 in epoch 12, gen_loss = 0.8516982113512662, disc_loss = 0.0678565303150278
Trained batch 520 in epoch 12, gen_loss = 0.8513936509669627, disc_loss = 0.06781229382513124
Trained batch 521 in epoch 12, gen_loss = 0.8508880133258885, disc_loss = 0.06798088533439856
Trained batch 522 in epoch 12, gen_loss = 0.8513710901682509, disc_loss = 0.06813069015570399
Trained batch 523 in epoch 12, gen_loss = 0.8515421265295444, disc_loss = 0.06805359513875638
Trained batch 524 in epoch 12, gen_loss = 0.850972178266162, disc_loss = 0.06807147630623409
Trained batch 525 in epoch 12, gen_loss = 0.8510131454626417, disc_loss = 0.06798077776263195
Trained batch 526 in epoch 12, gen_loss = 0.8512145664818599, disc_loss = 0.06787054202531728
Trained batch 527 in epoch 12, gen_loss = 0.8510111563020584, disc_loss = 0.0678192359451769
Trained batch 528 in epoch 12, gen_loss = 0.85113879542495, disc_loss = 0.06782018651020325
Trained batch 529 in epoch 12, gen_loss = 0.8507133844326127, disc_loss = 0.06793158979348417
Trained batch 530 in epoch 12, gen_loss = 0.851134706183342, disc_loss = 0.06782840969823231
Trained batch 531 in epoch 12, gen_loss = 0.8512287171823638, disc_loss = 0.0679626764284965
Trained batch 532 in epoch 12, gen_loss = 0.8510617505877819, disc_loss = 0.06795608996121845
Trained batch 533 in epoch 12, gen_loss = 0.8508904639366415, disc_loss = 0.06794829672369897
Trained batch 534 in epoch 12, gen_loss = 0.8507127568543514, disc_loss = 0.06787765762968877
Trained batch 535 in epoch 12, gen_loss = 0.8509982228835127, disc_loss = 0.06827103998685784
Trained batch 536 in epoch 12, gen_loss = 0.8506585925096019, disc_loss = 0.06838480774590701
Trained batch 537 in epoch 12, gen_loss = 0.8504062075043256, disc_loss = 0.0683476638315474
Trained batch 538 in epoch 12, gen_loss = 0.8510790808413157, disc_loss = 0.0683962310956366
Trained batch 539 in epoch 12, gen_loss = 0.850911383441201, disc_loss = 0.06835516783132874
Trained batch 540 in epoch 12, gen_loss = 0.8514195089529711, disc_loss = 0.06825760948211781
Trained batch 541 in epoch 12, gen_loss = 0.8510614267904381, disc_loss = 0.06823874730273147
Trained batch 542 in epoch 12, gen_loss = 0.851109992458895, disc_loss = 0.06816021508055278
Trained batch 543 in epoch 12, gen_loss = 0.851247000398443, disc_loss = 0.06835601311724852
Trained batch 544 in epoch 12, gen_loss = 0.851063533058954, disc_loss = 0.0683092281837529
Trained batch 545 in epoch 12, gen_loss = 0.8516700178821445, disc_loss = 0.06821967156146799
Trained batch 546 in epoch 12, gen_loss = 0.8523151502421831, disc_loss = 0.0681275827043998
Trained batch 547 in epoch 12, gen_loss = 0.8523970825502473, disc_loss = 0.06807702064622928
Trained batch 548 in epoch 12, gen_loss = 0.8525079387241808, disc_loss = 0.06798385448061703
Trained batch 549 in epoch 12, gen_loss = 0.8526152166995136, disc_loss = 0.06798906394703821
Trained batch 550 in epoch 12, gen_loss = 0.852778597611481, disc_loss = 0.06802878087342543
Trained batch 551 in epoch 12, gen_loss = 0.8532482257679753, disc_loss = 0.06792986337635395
Trained batch 552 in epoch 12, gen_loss = 0.8532419633153981, disc_loss = 0.0678447406085555
Trained batch 553 in epoch 12, gen_loss = 0.85352240868639, disc_loss = 0.06774710361183443
Trained batch 554 in epoch 12, gen_loss = 0.8536728124897759, disc_loss = 0.06764615657361778
Trained batch 555 in epoch 12, gen_loss = 0.8539675740565328, disc_loss = 0.06754512548707961
Trained batch 556 in epoch 12, gen_loss = 0.8539080276844532, disc_loss = 0.0674643054540993
Trained batch 557 in epoch 12, gen_loss = 0.8539846607327034, disc_loss = 0.06736247368343842
Trained batch 558 in epoch 12, gen_loss = 0.8537569297127732, disc_loss = 0.06731175843206416
Trained batch 559 in epoch 12, gen_loss = 0.8536175414387669, disc_loss = 0.0672347023085292
Trained batch 560 in epoch 12, gen_loss = 0.8537229568881785, disc_loss = 0.06722441587245188
Trained batch 561 in epoch 12, gen_loss = 0.8531028695696189, disc_loss = 0.06726908929699044
Trained batch 562 in epoch 12, gen_loss = 0.8530257772488874, disc_loss = 0.0672019444617772
Trained batch 563 in epoch 12, gen_loss = 0.8534688234646269, disc_loss = 0.06714349185902599
Trained batch 564 in epoch 12, gen_loss = 0.853722417829311, disc_loss = 0.06704401631171988
Trained batch 565 in epoch 12, gen_loss = 0.853981212202736, disc_loss = 0.06694721482371642
Trained batch 566 in epoch 12, gen_loss = 0.8541742329349383, disc_loss = 0.06685172284360338
Trained batch 567 in epoch 12, gen_loss = 0.854556570957664, disc_loss = 0.06675045686268943
Trained batch 568 in epoch 12, gen_loss = 0.8546824622342792, disc_loss = 0.06666994774599538
Trained batch 569 in epoch 12, gen_loss = 0.8542633865486111, disc_loss = 0.0666773472062982
Trained batch 570 in epoch 12, gen_loss = 0.8546071150152571, disc_loss = 0.06671940091827758
Trained batch 571 in epoch 12, gen_loss = 0.854749087530833, disc_loss = 0.06666198729250866
Trained batch 572 in epoch 12, gen_loss = 0.8543831565097156, disc_loss = 0.06673010171636497
Trained batch 573 in epoch 12, gen_loss = 0.8540958495817118, disc_loss = 0.0666928828778297
Trained batch 574 in epoch 12, gen_loss = 0.8549002860421719, disc_loss = 0.06679399912286065
Trained batch 575 in epoch 12, gen_loss = 0.8548753364529047, disc_loss = 0.06674120812709185
Trained batch 576 in epoch 12, gen_loss = 0.8547400427753012, disc_loss = 0.06665081883808098
Trained batch 577 in epoch 12, gen_loss = 0.8545070374610102, disc_loss = 0.06660843059697727
Trained batch 578 in epoch 12, gen_loss = 0.8543741076618484, disc_loss = 0.06655095354050707
Trained batch 579 in epoch 12, gen_loss = 0.8548855184994895, disc_loss = 0.06663002214908342
Trained batch 580 in epoch 12, gen_loss = 0.8550134026758026, disc_loss = 0.06655852878289922
Trained batch 581 in epoch 12, gen_loss = 0.8544638253671607, disc_loss = 0.06694998706873391
Trained batch 582 in epoch 12, gen_loss = 0.8541930471746632, disc_loss = 0.06698391310020796
Trained batch 583 in epoch 12, gen_loss = 0.8548195816780606, disc_loss = 0.06749391487691143
Trained batch 584 in epoch 12, gen_loss = 0.8549633015424777, disc_loss = 0.06747601114563707
Trained batch 585 in epoch 12, gen_loss = 0.8544747005041956, disc_loss = 0.06758363540649871
Trained batch 586 in epoch 12, gen_loss = 0.855010587423786, disc_loss = 0.06758715041787752
Trained batch 587 in epoch 12, gen_loss = 0.8548033585657879, disc_loss = 0.06756283782682299
Trained batch 588 in epoch 12, gen_loss = 0.8545638943669751, disc_loss = 0.06754015592450248
Trained batch 589 in epoch 12, gen_loss = 0.8548211404327619, disc_loss = 0.06752230594629201
Trained batch 590 in epoch 12, gen_loss = 0.8544661652315692, disc_loss = 0.0676738581369598
Trained batch 591 in epoch 12, gen_loss = 0.8545230786643319, disc_loss = 0.06758552927341363
Trained batch 592 in epoch 12, gen_loss = 0.8542501924914413, disc_loss = 0.06755843405999733
Trained batch 593 in epoch 12, gen_loss = 0.8542130058160936, disc_loss = 0.06756211622063109
Trained batch 594 in epoch 12, gen_loss = 0.8537672076405597, disc_loss = 0.0677307935869869
Trained batch 595 in epoch 12, gen_loss = 0.8539704091896947, disc_loss = 0.06773754119741787
Trained batch 596 in epoch 12, gen_loss = 0.8536033767651473, disc_loss = 0.06779454274561687
Trained batch 597 in epoch 12, gen_loss = 0.8541138313187404, disc_loss = 0.06774848560494275
Trained batch 598 in epoch 12, gen_loss = 0.8543187743534827, disc_loss = 0.06765981955774042
Trained batch 599 in epoch 12, gen_loss = 0.8545533647636573, disc_loss = 0.06756851059384644
Trained batch 600 in epoch 12, gen_loss = 0.8546356545411014, disc_loss = 0.06749271901135337
Trained batch 601 in epoch 12, gen_loss = 0.8543621223927337, disc_loss = 0.0674893348091019
Trained batch 602 in epoch 12, gen_loss = 0.8543141265314808, disc_loss = 0.06748880773078446
Trained batch 603 in epoch 12, gen_loss = 0.8541194777318973, disc_loss = 0.06755311768316966
Trained batch 604 in epoch 12, gen_loss = 0.8541596054538222, disc_loss = 0.06747109618438177
Trained batch 605 in epoch 12, gen_loss = 0.8546310986327653, disc_loss = 0.06738945629091153
Trained batch 606 in epoch 12, gen_loss = 0.8547798465366615, disc_loss = 0.06729709264658133
Trained batch 607 in epoch 12, gen_loss = 0.8541206116052834, disc_loss = 0.06745292103886114
Trained batch 608 in epoch 12, gen_loss = 0.8545322616405675, disc_loss = 0.06741907772086622
Trained batch 609 in epoch 12, gen_loss = 0.8549301685368429, disc_loss = 0.06750532663808984
Trained batch 610 in epoch 12, gen_loss = 0.8549886440977137, disc_loss = 0.06743669624816864
Trained batch 611 in epoch 12, gen_loss = 0.8545450893979446, disc_loss = 0.06752414289508867
Trained batch 612 in epoch 12, gen_loss = 0.854215252700871, disc_loss = 0.06754232961593308
Trained batch 613 in epoch 12, gen_loss = 0.8544973770356722, disc_loss = 0.06787823913891948
Trained batch 614 in epoch 12, gen_loss = 0.8545592232932889, disc_loss = 0.06782324455557315
Trained batch 615 in epoch 12, gen_loss = 0.8543271502213818, disc_loss = 0.06781650878573683
Trained batch 616 in epoch 12, gen_loss = 0.854293552412979, disc_loss = 0.0677367568142845
Trained batch 617 in epoch 12, gen_loss = 0.8542891621686108, disc_loss = 0.06768623945336415
Trained batch 618 in epoch 12, gen_loss = 0.8544795259424096, disc_loss = 0.06765979376466574
Trained batch 619 in epoch 12, gen_loss = 0.8544336423277855, disc_loss = 0.06759482395324495
Trained batch 620 in epoch 12, gen_loss = 0.8540560945316598, disc_loss = 0.06768101943587815
Trained batch 621 in epoch 12, gen_loss = 0.8544905896259657, disc_loss = 0.06763498205691576
Trained batch 622 in epoch 12, gen_loss = 0.8547538568177537, disc_loss = 0.06761578657330997
Trained batch 623 in epoch 12, gen_loss = 0.8549071007336562, disc_loss = 0.06759801335955182
Trained batch 624 in epoch 12, gen_loss = 0.854787060880661, disc_loss = 0.06751992940306664
Trained batch 625 in epoch 12, gen_loss = 0.8546055184480862, disc_loss = 0.06751516350089742
Trained batch 626 in epoch 12, gen_loss = 0.8540928656119479, disc_loss = 0.06773720050090998
Trained batch 627 in epoch 12, gen_loss = 0.8541272416900677, disc_loss = 0.0676973924918729
Trained batch 628 in epoch 12, gen_loss = 0.8551782319864143, disc_loss = 0.06797498565267872
Trained batch 629 in epoch 12, gen_loss = 0.8551035981802714, disc_loss = 0.06792015738430478
Trained batch 630 in epoch 12, gen_loss = 0.8548322616118448, disc_loss = 0.0678819462763243
Trained batch 631 in epoch 12, gen_loss = 0.8545095549448382, disc_loss = 0.06792008449453153
Trained batch 632 in epoch 12, gen_loss = 0.8544714577484281, disc_loss = 0.06790697432783731
Trained batch 633 in epoch 12, gen_loss = 0.8546935245159673, disc_loss = 0.0678684505507679
Trained batch 634 in epoch 12, gen_loss = 0.8546511131478107, disc_loss = 0.0678393064932091
Trained batch 635 in epoch 12, gen_loss = 0.8545936841353681, disc_loss = 0.06776175297995878
Trained batch 636 in epoch 12, gen_loss = 0.8544278832114472, disc_loss = 0.06771776333065291
Trained batch 637 in epoch 12, gen_loss = 0.8544225413877762, disc_loss = 0.06771509284241166
Trained batch 638 in epoch 12, gen_loss = 0.8537933996678891, disc_loss = 0.0679989616664969
Trained batch 639 in epoch 12, gen_loss = 0.8535412319470197, disc_loss = 0.06802771552756895
Trained batch 640 in epoch 12, gen_loss = 0.8531794784686495, disc_loss = 0.06804066629391657
Trained batch 641 in epoch 12, gen_loss = 0.8537742997348494, disc_loss = 0.06812198331573763
Trained batch 642 in epoch 12, gen_loss = 0.8539112828104158, disc_loss = 0.06808764572381325
Trained batch 643 in epoch 12, gen_loss = 0.8534349461797601, disc_loss = 0.06820622482481672
Trained batch 644 in epoch 12, gen_loss = 0.8535299406033153, disc_loss = 0.0681908682364133
Trained batch 645 in epoch 12, gen_loss = 0.8532738136156425, disc_loss = 0.06815806297937137
Trained batch 646 in epoch 12, gen_loss = 0.8531110891510936, disc_loss = 0.06820358931615235
Trained batch 647 in epoch 12, gen_loss = 0.8534582857456472, disc_loss = 0.06819249066685176
Trained batch 648 in epoch 12, gen_loss = 0.8533048926865558, disc_loss = 0.06813211595275094
Trained batch 649 in epoch 12, gen_loss = 0.8530928959754797, disc_loss = 0.0680913477534285
Trained batch 650 in epoch 12, gen_loss = 0.8530826013300642, disc_loss = 0.06800904218250522
Trained batch 651 in epoch 12, gen_loss = 0.8531427518264648, disc_loss = 0.06792032857928311
Trained batch 652 in epoch 12, gen_loss = 0.8532753310652641, disc_loss = 0.06783567329620512
Trained batch 653 in epoch 12, gen_loss = 0.8528876403511847, disc_loss = 0.06794244831923497
Trained batch 654 in epoch 12, gen_loss = 0.8530029486608869, disc_loss = 0.06795786427518793
Trained batch 655 in epoch 12, gen_loss = 0.8528591681998677, disc_loss = 0.06792741139964541
Trained batch 656 in epoch 12, gen_loss = 0.8529639363379602, disc_loss = 0.0679547978420508
Trained batch 657 in epoch 12, gen_loss = 0.8526095078980669, disc_loss = 0.06808438363250084
Trained batch 658 in epoch 12, gen_loss = 0.8526021333945539, disc_loss = 0.06806198791325183
Trained batch 659 in epoch 12, gen_loss = 0.8520686925812201, disc_loss = 0.0682055742677414
Trained batch 660 in epoch 12, gen_loss = 0.852391893086383, disc_loss = 0.06839336152787288
Trained batch 661 in epoch 12, gen_loss = 0.8517892725338029, disc_loss = 0.06855335329684606
Trained batch 662 in epoch 12, gen_loss = 0.8521323681417095, disc_loss = 0.06866810015693509
Trained batch 663 in epoch 12, gen_loss = 0.8522234918123268, disc_loss = 0.06863587327772774
Trained batch 664 in epoch 12, gen_loss = 0.8523073981579085, disc_loss = 0.06858137928341565
Trained batch 665 in epoch 12, gen_loss = 0.851951230664153, disc_loss = 0.06861234785759593
Trained batch 666 in epoch 12, gen_loss = 0.8518544049456023, disc_loss = 0.06869640742530529
Trained batch 667 in epoch 12, gen_loss = 0.8515319560994645, disc_loss = 0.06876316425128433
Trained batch 668 in epoch 12, gen_loss = 0.8511379082284879, disc_loss = 0.06906300938516989
Trained batch 669 in epoch 12, gen_loss = 0.8514162629397948, disc_loss = 0.06909472435824017
Trained batch 670 in epoch 12, gen_loss = 0.8513030317430169, disc_loss = 0.06903200105232382
Trained batch 671 in epoch 12, gen_loss = 0.8507539205075729, disc_loss = 0.0692857006797567
Trained batch 672 in epoch 12, gen_loss = 0.8508186983318243, disc_loss = 0.06936261654010853
Trained batch 673 in epoch 12, gen_loss = 0.8509889661558304, disc_loss = 0.06944315457711057
Trained batch 674 in epoch 12, gen_loss = 0.8511093687128137, disc_loss = 0.06943327261893838
Trained batch 675 in epoch 12, gen_loss = 0.8510076869168931, disc_loss = 0.06937055841925935
Trained batch 676 in epoch 12, gen_loss = 0.8507245787841706, disc_loss = 0.06942820169328763
Trained batch 677 in epoch 12, gen_loss = 0.8505422413173327, disc_loss = 0.06941222598924573
Trained batch 678 in epoch 12, gen_loss = 0.8509222216388438, disc_loss = 0.06955054008973892
Trained batch 679 in epoch 12, gen_loss = 0.8507699417717317, disc_loss = 0.0695541983415537
Trained batch 680 in epoch 12, gen_loss = 0.8504361442882409, disc_loss = 0.06970022796556113
Trained batch 681 in epoch 12, gen_loss = 0.8503368968837771, disc_loss = 0.0697007394311103
Trained batch 682 in epoch 12, gen_loss = 0.8506714133532121, disc_loss = 0.06986007046930787
Trained batch 683 in epoch 12, gen_loss = 0.8506856077072913, disc_loss = 0.06994911516902216
Trained batch 684 in epoch 12, gen_loss = 0.8503235650758674, disc_loss = 0.06998059459737617
Trained batch 685 in epoch 12, gen_loss = 0.8498163830608391, disc_loss = 0.07015560610279571
Trained batch 686 in epoch 12, gen_loss = 0.8496474815421403, disc_loss = 0.07019982011405836
Trained batch 687 in epoch 12, gen_loss = 0.8494802712527818, disc_loss = 0.07019269400882687
Trained batch 688 in epoch 12, gen_loss = 0.8496920014846481, disc_loss = 0.07014098540164736
Trained batch 689 in epoch 12, gen_loss = 0.8497892165529555, disc_loss = 0.07021139341312042
Trained batch 690 in epoch 12, gen_loss = 0.84964029738941, disc_loss = 0.07016031290424715
Trained batch 691 in epoch 12, gen_loss = 0.8494128589168449, disc_loss = 0.07012970654584597
Trained batch 692 in epoch 12, gen_loss = 0.849768893113212, disc_loss = 0.07013979491281819
Trained batch 693 in epoch 12, gen_loss = 0.8494893725564225, disc_loss = 0.07018472326742298
Trained batch 694 in epoch 12, gen_loss = 0.8495384394693718, disc_loss = 0.0702087464682061
Trained batch 695 in epoch 12, gen_loss = 0.8495499303286103, disc_loss = 0.07025618932006517
Trained batch 696 in epoch 12, gen_loss = 0.8498595265439114, disc_loss = 0.0704020822268391
Trained batch 697 in epoch 12, gen_loss = 0.8494182001895413, disc_loss = 0.07065775251298886
Trained batch 698 in epoch 12, gen_loss = 0.8492435557136209, disc_loss = 0.07067310856455386
Trained batch 699 in epoch 12, gen_loss = 0.8498427684817995, disc_loss = 0.07078581243221249
Trained batch 700 in epoch 12, gen_loss = 0.8498774983743458, disc_loss = 0.07072844170033932
Trained batch 701 in epoch 12, gen_loss = 0.849614650520504, disc_loss = 0.07076421545346154
Trained batch 702 in epoch 12, gen_loss = 0.8493353970359433, disc_loss = 0.0708016570986038
Trained batch 703 in epoch 12, gen_loss = 0.8497436580840837, disc_loss = 0.07127139447204006
Trained batch 704 in epoch 12, gen_loss = 0.8497537363505533, disc_loss = 0.07128901053352137
Trained batch 705 in epoch 12, gen_loss = 0.8496673416990058, disc_loss = 0.07126258416286017
Trained batch 706 in epoch 12, gen_loss = 0.849469364363874, disc_loss = 0.07127038421322719
Trained batch 707 in epoch 12, gen_loss = 0.8493687186369114, disc_loss = 0.07122816075702425
Trained batch 708 in epoch 12, gen_loss = 0.8494437621073595, disc_loss = 0.07114811127214615
Trained batch 709 in epoch 12, gen_loss = 0.8492497805978211, disc_loss = 0.07113145419960501
Trained batch 710 in epoch 12, gen_loss = 0.8488315204695475, disc_loss = 0.07112018336606135
Trained batch 711 in epoch 12, gen_loss = 0.8490876927134696, disc_loss = 0.07125524423226422
Trained batch 712 in epoch 12, gen_loss = 0.8490037172405783, disc_loss = 0.07125998035642785
Trained batch 713 in epoch 12, gen_loss = 0.8489237681490367, disc_loss = 0.07119813690963789
Trained batch 714 in epoch 12, gen_loss = 0.8489109561159894, disc_loss = 0.07112157054740441
Trained batch 715 in epoch 12, gen_loss = 0.8490317942543403, disc_loss = 0.07104390316289022
Trained batch 716 in epoch 12, gen_loss = 0.8485744688633928, disc_loss = 0.07119869765912597
Trained batch 717 in epoch 12, gen_loss = 0.8487755233696909, disc_loss = 0.0711225198755627
Trained batch 718 in epoch 12, gen_loss = 0.8489565756456908, disc_loss = 0.07107531368053714
Trained batch 719 in epoch 12, gen_loss = 0.8484267623474201, disc_loss = 0.07124679697703364
Trained batch 720 in epoch 12, gen_loss = 0.8485219712974956, disc_loss = 0.07126313699706459
Trained batch 721 in epoch 12, gen_loss = 0.8482664242758315, disc_loss = 0.07122357363149606
Trained batch 722 in epoch 12, gen_loss = 0.8481191069011371, disc_loss = 0.0711727089790903
Trained batch 723 in epoch 12, gen_loss = 0.848414010805649, disc_loss = 0.07111633752050774
Trained batch 724 in epoch 12, gen_loss = 0.8486098820998751, disc_loss = 0.07103810528871314
Trained batch 725 in epoch 12, gen_loss = 0.8482873510805372, disc_loss = 0.07102740188219044
Trained batch 726 in epoch 12, gen_loss = 0.8485071034756126, disc_loss = 0.07097030177000177
Trained batch 727 in epoch 12, gen_loss = 0.848580116139991, disc_loss = 0.07088154069004723
Trained batch 728 in epoch 12, gen_loss = 0.8487161558596685, disc_loss = 0.07087244816758097
Trained batch 729 in epoch 12, gen_loss = 0.8483375696695015, disc_loss = 0.0708726497315993
Trained batch 730 in epoch 12, gen_loss = 0.8481758044046515, disc_loss = 0.0708518017429945
Trained batch 731 in epoch 12, gen_loss = 0.8484511103867833, disc_loss = 0.07076629361168282
Trained batch 732 in epoch 12, gen_loss = 0.848582554115605, disc_loss = 0.07067888041279732
Trained batch 733 in epoch 12, gen_loss = 0.8486406697158267, disc_loss = 0.07076783899765979
Trained batch 734 in epoch 12, gen_loss = 0.8486664839747812, disc_loss = 0.07068917069356052
Trained batch 735 in epoch 12, gen_loss = 0.8481256705101418, disc_loss = 0.07098702470134215
Trained batch 736 in epoch 12, gen_loss = 0.848302652020629, disc_loss = 0.0709673967161892
Trained batch 737 in epoch 12, gen_loss = 0.8483316795774268, disc_loss = 0.07096321605458895
Trained batch 738 in epoch 12, gen_loss = 0.8483438619257472, disc_loss = 0.07089937240621315
Trained batch 739 in epoch 12, gen_loss = 0.8481927045293757, disc_loss = 0.0709136233665049
Trained batch 740 in epoch 12, gen_loss = 0.8476389623605288, disc_loss = 0.07109448853905304
Trained batch 741 in epoch 12, gen_loss = 0.8475083232006294, disc_loss = 0.07107964789901541
Trained batch 742 in epoch 12, gen_loss = 0.8479337227376602, disc_loss = 0.0711360396403684
Trained batch 743 in epoch 12, gen_loss = 0.8481883102607343, disc_loss = 0.07106460581072957
Trained batch 744 in epoch 12, gen_loss = 0.8476455805285665, disc_loss = 0.07113787118070478
Trained batch 745 in epoch 12, gen_loss = 0.8474156722306566, disc_loss = 0.071140364204451
Trained batch 746 in epoch 12, gen_loss = 0.8475628876622262, disc_loss = 0.07106396381230838
Trained batch 747 in epoch 12, gen_loss = 0.8475106454150562, disc_loss = 0.07123633913252563
Trained batch 748 in epoch 12, gen_loss = 0.8472269740060111, disc_loss = 0.07122927969657332
Trained batch 749 in epoch 12, gen_loss = 0.846859994093577, disc_loss = 0.07123551207656661
Trained batch 750 in epoch 12, gen_loss = 0.8466580639507736, disc_loss = 0.07122445534964336
Trained batch 751 in epoch 12, gen_loss = 0.8468779426939944, disc_loss = 0.07114955178769107
Trained batch 752 in epoch 12, gen_loss = 0.847097056003839, disc_loss = 0.07110954255390056
Trained batch 753 in epoch 12, gen_loss = 0.8469548207221044, disc_loss = 0.07105400798402588
Trained batch 754 in epoch 12, gen_loss = 0.8468839131443706, disc_loss = 0.07104266020191821
Trained batch 755 in epoch 12, gen_loss = 0.8467593821425917, disc_loss = 0.07102366748497521
Trained batch 756 in epoch 12, gen_loss = 0.8467218941237526, disc_loss = 0.07102000567437085
Trained batch 757 in epoch 12, gen_loss = 0.8471488753692455, disc_loss = 0.07095719896512484
Trained batch 758 in epoch 12, gen_loss = 0.8472812866033773, disc_loss = 0.07087852093434067
Trained batch 759 in epoch 12, gen_loss = 0.8473156192585042, disc_loss = 0.07079544476674575
Trained batch 760 in epoch 12, gen_loss = 0.8473524288341657, disc_loss = 0.07086797584822394
Trained batch 761 in epoch 12, gen_loss = 0.8471709853551519, disc_loss = 0.07081275232370914
Trained batch 762 in epoch 12, gen_loss = 0.8468538761763866, disc_loss = 0.07096671433643308
Trained batch 763 in epoch 12, gen_loss = 0.847033073764821, disc_loss = 0.0708998488164775
Trained batch 764 in epoch 12, gen_loss = 0.8474761147904241, disc_loss = 0.0708610872719802
Trained batch 765 in epoch 12, gen_loss = 0.8474854472100579, disc_loss = 0.07078983621579393
Trained batch 766 in epoch 12, gen_loss = 0.847499343609095, disc_loss = 0.07071158286630913
Trained batch 767 in epoch 12, gen_loss = 0.8474345395807177, disc_loss = 0.07064192312949065
Trained batch 768 in epoch 12, gen_loss = 0.8478074536521971, disc_loss = 0.07067561940797477
Trained batch 769 in epoch 12, gen_loss = 0.84778101126869, disc_loss = 0.07062339557625064
Trained batch 770 in epoch 12, gen_loss = 0.8479569088933379, disc_loss = 0.07055161779217335
Trained batch 771 in epoch 12, gen_loss = 0.8478007088825492, disc_loss = 0.07052981254519229
Trained batch 772 in epoch 12, gen_loss = 0.8477438780808048, disc_loss = 0.07051536825787937
Trained batch 773 in epoch 12, gen_loss = 0.8479032611970138, disc_loss = 0.07044015092491257
Trained batch 774 in epoch 12, gen_loss = 0.8481606732645343, disc_loss = 0.07039148546274632
Trained batch 775 in epoch 12, gen_loss = 0.8480784237077555, disc_loss = 0.07035886968447606
Trained batch 776 in epoch 12, gen_loss = 0.8480059893435032, disc_loss = 0.07033550938977315
Trained batch 777 in epoch 12, gen_loss = 0.8483141130530742, disc_loss = 0.07033183109877118
Trained batch 778 in epoch 12, gen_loss = 0.8480117477868733, disc_loss = 0.07032754541218128
Trained batch 779 in epoch 12, gen_loss = 0.8479239971209795, disc_loss = 0.07025714421119446
Trained batch 780 in epoch 12, gen_loss = 0.8483157189951663, disc_loss = 0.07028402016997795
Trained batch 781 in epoch 12, gen_loss = 0.8481678997769075, disc_loss = 0.07025362643153618
Trained batch 782 in epoch 12, gen_loss = 0.84811157323087, disc_loss = 0.07021323158518716
Trained batch 783 in epoch 12, gen_loss = 0.8481463455424016, disc_loss = 0.07015526911471875
Trained batch 784 in epoch 12, gen_loss = 0.8479141864806983, disc_loss = 0.0701307474238098
Trained batch 785 in epoch 12, gen_loss = 0.8480856690849663, disc_loss = 0.07005671138872817
Trained batch 786 in epoch 12, gen_loss = 0.8479823199736269, disc_loss = 0.07009363768141826
Trained batch 787 in epoch 12, gen_loss = 0.8479820881700758, disc_loss = 0.07006381186042075
Trained batch 788 in epoch 12, gen_loss = 0.8480254677614181, disc_loss = 0.06998954064487768
Trained batch 789 in epoch 12, gen_loss = 0.847722015199782, disc_loss = 0.07001914428075469
Testing Epoch 12
Training Epoch 13
Trained batch 0 in epoch 13, gen_loss = 0.5697793960571289, disc_loss = 0.11523380875587463
Trained batch 1 in epoch 13, gen_loss = 0.8640937209129333, disc_loss = 0.1286689043045044
Trained batch 2 in epoch 13, gen_loss = 0.8171042998631796, disc_loss = 0.0992264598608017
Trained batch 3 in epoch 13, gen_loss = 0.8318054378032684, disc_loss = 0.10154950805008411
Trained batch 4 in epoch 13, gen_loss = 0.8257026672363281, disc_loss = 0.08713063672184944
Trained batch 5 in epoch 13, gen_loss = 0.8085828026135763, disc_loss = 0.07870697292188804
Trained batch 6 in epoch 13, gen_loss = 0.7914316824504307, disc_loss = 0.07706615275570325
Trained batch 7 in epoch 13, gen_loss = 0.8582751899957657, disc_loss = 0.09293929068371654
Trained batch 8 in epoch 13, gen_loss = 0.8770826790067885, disc_loss = 0.09213558460275333
Trained batch 9 in epoch 13, gen_loss = 0.8476446151733399, disc_loss = 0.10097418837249279
Trained batch 10 in epoch 13, gen_loss = 0.8372746109962463, disc_loss = 0.095549133352258
Trained batch 11 in epoch 13, gen_loss = 0.8309991757074991, disc_loss = 0.09170305139074723
Trained batch 12 in epoch 13, gen_loss = 0.8307033135340764, disc_loss = 0.09358555393723342
Trained batch 13 in epoch 13, gen_loss = 0.8143135564667838, disc_loss = 0.0933797053460564
Trained batch 14 in epoch 13, gen_loss = 0.8158517281214396, disc_loss = 0.08891164138913155
Trained batch 15 in epoch 13, gen_loss = 0.835040770471096, disc_loss = 0.090977763524279
Trained batch 16 in epoch 13, gen_loss = 0.8330803233034471, disc_loss = 0.08712552948033109
Trained batch 17 in epoch 13, gen_loss = 0.8225437965657976, disc_loss = 0.08547419102655517
Trained batch 18 in epoch 13, gen_loss = 0.8136180639266968, disc_loss = 0.08548267969959661
Trained batch 19 in epoch 13, gen_loss = 0.816231906414032, disc_loss = 0.08214855501428246
Trained batch 20 in epoch 13, gen_loss = 0.8135123025803339, disc_loss = 0.08125573086241882
Trained batch 21 in epoch 13, gen_loss = 0.8290553689002991, disc_loss = 0.08373762641779402
Trained batch 22 in epoch 13, gen_loss = 0.8254581663919531, disc_loss = 0.08238230216438355
Trained batch 23 in epoch 13, gen_loss = 0.8125809828440348, disc_loss = 0.0849760059112062
Trained batch 24 in epoch 13, gen_loss = 0.8147862792015076, disc_loss = 0.08297839038074016
Trained batch 25 in epoch 13, gen_loss = 0.8224321122352893, disc_loss = 0.08058115918762408
Trained batch 26 in epoch 13, gen_loss = 0.8225897241521765, disc_loss = 0.08202141682030978
Trained batch 27 in epoch 13, gen_loss = 0.8178514114448002, disc_loss = 0.08173679234459996
Trained batch 28 in epoch 13, gen_loss = 0.8056082684418251, disc_loss = 0.08437788788357685
Trained batch 29 in epoch 13, gen_loss = 0.8065101424853007, disc_loss = 0.0831321540599068
Trained batch 30 in epoch 13, gen_loss = 0.8028869455860507, disc_loss = 0.08297616441644007
Trained batch 31 in epoch 13, gen_loss = 0.8026113826781511, disc_loss = 0.08081228780793026
Trained batch 32 in epoch 13, gen_loss = 0.8031137657888008, disc_loss = 0.07977313971654935
Trained batch 33 in epoch 13, gen_loss = 0.8056874012245852, disc_loss = 0.08003163003527067
Trained batch 34 in epoch 13, gen_loss = 0.7986269422939846, disc_loss = 0.07968793612505709
Trained batch 35 in epoch 13, gen_loss = 0.7883685645129945, disc_loss = 0.08521953240657847
Trained batch 36 in epoch 13, gen_loss = 0.8054921385404226, disc_loss = 0.09523105716987236
Trained batch 37 in epoch 13, gen_loss = 0.8049628499307131, disc_loss = 0.09712701619259621
Trained batch 38 in epoch 13, gen_loss = 0.8017664398902502, disc_loss = 0.0962338131876328
Trained batch 39 in epoch 13, gen_loss = 0.7957103952765465, disc_loss = 0.09708898453973233
Trained batch 40 in epoch 13, gen_loss = 0.7951493510385839, disc_loss = 0.09772399590327972
Trained batch 41 in epoch 13, gen_loss = 0.7893720922015962, disc_loss = 0.10050372331447545
Trained batch 42 in epoch 13, gen_loss = 0.80357737319414, disc_loss = 0.10415722650670728
Trained batch 43 in epoch 13, gen_loss = 0.8041727095842361, disc_loss = 0.10237498060715469
Trained batch 44 in epoch 13, gen_loss = 0.7967579689290788, disc_loss = 0.10484150337676207
Trained batch 45 in epoch 13, gen_loss = 0.8013730910809144, disc_loss = 0.10406128094410119
Trained batch 46 in epoch 13, gen_loss = 0.7995827889188807, disc_loss = 0.1044380958489281
Trained batch 47 in epoch 13, gen_loss = 0.8004806470125914, disc_loss = 0.10359398900376011
Trained batch 48 in epoch 13, gen_loss = 0.798608231909421, disc_loss = 0.10263790558947593
Trained batch 49 in epoch 13, gen_loss = 0.7963337606191635, disc_loss = 0.10232874874025583
Trained batch 50 in epoch 13, gen_loss = 0.7961479524771372, disc_loss = 0.10074355084376008
Trained batch 51 in epoch 13, gen_loss = 0.800688966535605, disc_loss = 0.09895649262202474
Trained batch 52 in epoch 13, gen_loss = 0.8016769363070434, disc_loss = 0.0973015308801858
Trained batch 53 in epoch 13, gen_loss = 0.8053244766261842, disc_loss = 0.09591580037441519
Trained batch 54 in epoch 13, gen_loss = 0.8013548054478385, disc_loss = 0.0963958778841929
Trained batch 55 in epoch 13, gen_loss = 0.7999534718692303, disc_loss = 0.0958935100186084
Trained batch 56 in epoch 13, gen_loss = 0.8012074592866396, disc_loss = 0.09483137027474872
Trained batch 57 in epoch 13, gen_loss = 0.8066913141258831, disc_loss = 0.09655044285644745
Trained batch 58 in epoch 13, gen_loss = 0.8021853359068855, disc_loss = 0.09803207982647216
Trained batch 59 in epoch 13, gen_loss = 0.7997283642490705, disc_loss = 0.09732899237424135
Trained batch 60 in epoch 13, gen_loss = 0.798119705720026, disc_loss = 0.09761259197944501
Trained batch 61 in epoch 13, gen_loss = 0.7945502751296566, disc_loss = 0.09818306559276196
Trained batch 62 in epoch 13, gen_loss = 0.798950740742305, disc_loss = 0.09788374336702484
Trained batch 63 in epoch 13, gen_loss = 0.7951045124791563, disc_loss = 0.09827844909159467
Trained batch 64 in epoch 13, gen_loss = 0.7935936290484208, disc_loss = 0.09823901005662404
Trained batch 65 in epoch 13, gen_loss = 0.7944517970988245, disc_loss = 0.09698106908719197
Trained batch 66 in epoch 13, gen_loss = 0.7946783379832311, disc_loss = 0.09596339547867651
Trained batch 67 in epoch 13, gen_loss = 0.7935678893152405, disc_loss = 0.0954837389427292
Trained batch 68 in epoch 13, gen_loss = 0.7920330663522085, disc_loss = 0.09495139333918906
Trained batch 69 in epoch 13, gen_loss = 0.7946781801325934, disc_loss = 0.09441126825820123
Trained batch 70 in epoch 13, gen_loss = 0.7942493041636238, disc_loss = 0.09360278194481639
Trained batch 71 in epoch 13, gen_loss = 0.7969683710899618, disc_loss = 0.09279361766918252
Trained batch 72 in epoch 13, gen_loss = 0.7972511073497877, disc_loss = 0.09214647564628761
Trained batch 73 in epoch 13, gen_loss = 0.7965452393164506, disc_loss = 0.09174391955791696
Trained batch 74 in epoch 13, gen_loss = 0.7945227340857188, disc_loss = 0.0911240249996384
Trained batch 75 in epoch 13, gen_loss = 0.7964971806657942, disc_loss = 0.0901848321510969
Trained batch 76 in epoch 13, gen_loss = 0.7959511624528216, disc_loss = 0.08989004854886949
Trained batch 77 in epoch 13, gen_loss = 0.7974070818760456, disc_loss = 0.08891607054437582
Trained batch 78 in epoch 13, gen_loss = 0.7979181676725798, disc_loss = 0.08825667209546023
Trained batch 79 in epoch 13, gen_loss = 0.7992671478539706, disc_loss = 0.08752927312161773
Trained batch 80 in epoch 13, gen_loss = 0.8027380531952705, disc_loss = 0.08762646363013321
Trained batch 81 in epoch 13, gen_loss = 0.8012902594921065, disc_loss = 0.08719876210954858
Trained batch 82 in epoch 13, gen_loss = 0.8029154434979681, disc_loss = 0.08627313434943018
Trained batch 83 in epoch 13, gen_loss = 0.8028620655337969, disc_loss = 0.08563255914486945
Trained batch 84 in epoch 13, gen_loss = 0.8021610151318943, disc_loss = 0.08489926519858486
Trained batch 85 in epoch 13, gen_loss = 0.8035331441219463, disc_loss = 0.08422600725925593
Trained batch 86 in epoch 13, gen_loss = 0.8026962016505756, disc_loss = 0.08413174822284229
Trained batch 87 in epoch 13, gen_loss = 0.8056816157292236, disc_loss = 0.08335730544587766
Trained batch 88 in epoch 13, gen_loss = 0.8091903050963798, disc_loss = 0.08312714820874206
Trained batch 89 in epoch 13, gen_loss = 0.8091601997613906, disc_loss = 0.08270809754936231
Trained batch 90 in epoch 13, gen_loss = 0.8097191593804203, disc_loss = 0.08342648130728976
Trained batch 91 in epoch 13, gen_loss = 0.8097066338295522, disc_loss = 0.08293701247717052
Trained batch 92 in epoch 13, gen_loss = 0.8096215869149854, disc_loss = 0.08256716682745885
Trained batch 93 in epoch 13, gen_loss = 0.8131861448922055, disc_loss = 0.08338826697597161
Trained batch 94 in epoch 13, gen_loss = 0.812807855166887, disc_loss = 0.08320799572883468
Trained batch 95 in epoch 13, gen_loss = 0.8159015181784829, disc_loss = 0.08277642727868322
Trained batch 96 in epoch 13, gen_loss = 0.8148241113756121, disc_loss = 0.08269131921961442
Trained batch 97 in epoch 13, gen_loss = 0.815290056625191, disc_loss = 0.08225278123947126
Trained batch 98 in epoch 13, gen_loss = 0.8164246199708997, disc_loss = 0.08170100552679012
Trained batch 99 in epoch 13, gen_loss = 0.8206146928668022, disc_loss = 0.08125967721454799
Trained batch 100 in epoch 13, gen_loss = 0.8224672819718276, disc_loss = 0.08055745729125373
Trained batch 101 in epoch 13, gen_loss = 0.8245539194812962, disc_loss = 0.07997118778453738
Trained batch 102 in epoch 13, gen_loss = 0.8227837603647732, disc_loss = 0.08014104755830417
Trained batch 103 in epoch 13, gen_loss = 0.8256034045838393, disc_loss = 0.07956303229842049
Trained batch 104 in epoch 13, gen_loss = 0.8274831882544926, disc_loss = 0.07939004397818021
Trained batch 105 in epoch 13, gen_loss = 0.8295331988132225, disc_loss = 0.07874843666224547
Trained batch 106 in epoch 13, gen_loss = 0.8277075638837903, disc_loss = 0.07912171630310678
Trained batch 107 in epoch 13, gen_loss = 0.8277248124833461, disc_loss = 0.07874808313876942
Trained batch 108 in epoch 13, gen_loss = 0.8303976061694119, disc_loss = 0.0781486641889045
Trained batch 109 in epoch 13, gen_loss = 0.8312171266837554, disc_loss = 0.07757864474234256
Trained batch 110 in epoch 13, gen_loss = 0.8310894238519239, disc_loss = 0.07701297927446463
Trained batch 111 in epoch 13, gen_loss = 0.8315362501889467, disc_loss = 0.07640916038404352
Trained batch 112 in epoch 13, gen_loss = 0.8339852788279541, disc_loss = 0.0758360018871263
Trained batch 113 in epoch 13, gen_loss = 0.8352207141487222, disc_loss = 0.07538933996437934
Trained batch 114 in epoch 13, gen_loss = 0.8365172020767047, disc_loss = 0.07490426021749559
Trained batch 115 in epoch 13, gen_loss = 0.8349939222479689, disc_loss = 0.07478777272626758
Trained batch 116 in epoch 13, gen_loss = 0.8353509319643689, disc_loss = 0.07427309772684279
Trained batch 117 in epoch 13, gen_loss = 0.8336526233766038, disc_loss = 0.07429632614761339
Trained batch 118 in epoch 13, gen_loss = 0.837196500111027, disc_loss = 0.07470494703616665
Trained batch 119 in epoch 13, gen_loss = 0.836443912734588, disc_loss = 0.07460452474188059
Trained batch 120 in epoch 13, gen_loss = 0.8340480857151599, disc_loss = 0.0750697367893886
Trained batch 121 in epoch 13, gen_loss = 0.8353891072214626, disc_loss = 0.07471001552051452
Trained batch 122 in epoch 13, gen_loss = 0.836897628336418, disc_loss = 0.07500317172578923
Trained batch 123 in epoch 13, gen_loss = 0.8367845418472444, disc_loss = 0.07451315941439281
Trained batch 124 in epoch 13, gen_loss = 0.8371337993144989, disc_loss = 0.07402970919013023
Trained batch 125 in epoch 13, gen_loss = 0.8373439683327599, disc_loss = 0.07369586041877194
Trained batch 126 in epoch 13, gen_loss = 0.8381524515433574, disc_loss = 0.07321460309665738
Trained batch 127 in epoch 13, gen_loss = 0.836868992773816, disc_loss = 0.07304739692335716
Trained batch 128 in epoch 13, gen_loss = 0.8391748710658199, disc_loss = 0.0729811017928544
Trained batch 129 in epoch 13, gen_loss = 0.841352880688814, disc_loss = 0.07267443293419022
Trained batch 130 in epoch 13, gen_loss = 0.8393774976712147, disc_loss = 0.07280518975506985
Trained batch 131 in epoch 13, gen_loss = 0.8423594017371987, disc_loss = 0.07251108586647068
Trained batch 132 in epoch 13, gen_loss = 0.8423109518406087, disc_loss = 0.07205698638454192
Trained batch 133 in epoch 13, gen_loss = 0.8423945309955683, disc_loss = 0.0721634345532242
Trained batch 134 in epoch 13, gen_loss = 0.841000791169979, disc_loss = 0.0723457044404414
Trained batch 135 in epoch 13, gen_loss = 0.8407909052775187, disc_loss = 0.07196108226472621
Trained batch 136 in epoch 13, gen_loss = 0.840893836569612, disc_loss = 0.07181675587338905
Trained batch 137 in epoch 13, gen_loss = 0.8431405915298323, disc_loss = 0.07187095572632077
Trained batch 138 in epoch 13, gen_loss = 0.8448263670471933, disc_loss = 0.07155136148304604
Trained batch 139 in epoch 13, gen_loss = 0.8432842495185988, disc_loss = 0.07181409763039223
Trained batch 140 in epoch 13, gen_loss = 0.8433566611286596, disc_loss = 0.07152836495706587
Trained batch 141 in epoch 13, gen_loss = 0.8450969384169914, disc_loss = 0.07144369450594548
Trained batch 142 in epoch 13, gen_loss = 0.845927203243429, disc_loss = 0.07099464954482718
Trained batch 143 in epoch 13, gen_loss = 0.8448803017122878, disc_loss = 0.07123183109150785
Trained batch 144 in epoch 13, gen_loss = 0.8455279829173252, disc_loss = 0.07079310223845572
Trained batch 145 in epoch 13, gen_loss = 0.8433733568207858, disc_loss = 0.0713728865519268
Trained batch 146 in epoch 13, gen_loss = 0.8429958056024953, disc_loss = 0.07101127377958322
Trained batch 147 in epoch 13, gen_loss = 0.8475831390635388, disc_loss = 0.07123390156649859
Trained batch 148 in epoch 13, gen_loss = 0.8500059329023297, disc_loss = 0.07101292757554942
Trained batch 149 in epoch 13, gen_loss = 0.8516187649965287, disc_loss = 0.07066936052714785
Trained batch 150 in epoch 13, gen_loss = 0.8502300975733246, disc_loss = 0.07053024972486772
Trained batch 151 in epoch 13, gen_loss = 0.8505733140597218, disc_loss = 0.07014291631180401
Trained batch 152 in epoch 13, gen_loss = 0.8502155076834111, disc_loss = 0.06994013459683439
Trained batch 153 in epoch 13, gen_loss = 0.8502151263611657, disc_loss = 0.06956043371374344
Trained batch 154 in epoch 13, gen_loss = 0.8502557894875926, disc_loss = 0.07001417073751649
Trained batch 155 in epoch 13, gen_loss = 0.8500142962886736, disc_loss = 0.06970404020438974
Trained batch 156 in epoch 13, gen_loss = 0.8479732535067638, disc_loss = 0.06984637239888596
Trained batch 157 in epoch 13, gen_loss = 0.8492504488441008, disc_loss = 0.06945436949476222
Trained batch 158 in epoch 13, gen_loss = 0.8489750805515913, disc_loss = 0.06911968691098802
Trained batch 159 in epoch 13, gen_loss = 0.8486168505623937, disc_loss = 0.06877045378205367
Trained batch 160 in epoch 13, gen_loss = 0.8512751806226576, disc_loss = 0.06886772124779335
Trained batch 161 in epoch 13, gen_loss = 0.851828447278635, disc_loss = 0.06860898805920172
Trained batch 162 in epoch 13, gen_loss = 0.851944111424721, disc_loss = 0.06832079354536497
Trained batch 163 in epoch 13, gen_loss = 0.8522600911375953, disc_loss = 0.06803520376476027
Trained batch 164 in epoch 13, gen_loss = 0.8509597241878509, disc_loss = 0.06796662519036821
Trained batch 165 in epoch 13, gen_loss = 0.8509841423077755, disc_loss = 0.06765932273905141
Trained batch 166 in epoch 13, gen_loss = 0.8523681633129805, disc_loss = 0.06754122436336593
Trained batch 167 in epoch 13, gen_loss = 0.8531556344103246, disc_loss = 0.06718330646011357
Trained batch 168 in epoch 13, gen_loss = 0.852840880494146, disc_loss = 0.06696334572442801
Trained batch 169 in epoch 13, gen_loss = 0.8516312650021385, disc_loss = 0.06675681365270386
Trained batch 170 in epoch 13, gen_loss = 0.8511275807667894, disc_loss = 0.06649334760034206
Trained batch 171 in epoch 13, gen_loss = 0.8535580629872721, disc_loss = 0.06641664928594214
Trained batch 172 in epoch 13, gen_loss = 0.8529167628357176, disc_loss = 0.06667376491321908
Trained batch 173 in epoch 13, gen_loss = 0.8535554373058779, disc_loss = 0.0664786229140243
Trained batch 174 in epoch 13, gen_loss = 0.8526965091909681, disc_loss = 0.06660591239109635
Trained batch 175 in epoch 13, gen_loss = 0.8516093179244887, disc_loss = 0.06667321093581532
Trained batch 176 in epoch 13, gen_loss = 0.8521232475331948, disc_loss = 0.06644323527928715
Trained batch 177 in epoch 13, gen_loss = 0.8528943381617579, disc_loss = 0.06613093305619831
Trained batch 178 in epoch 13, gen_loss = 0.8561444254227857, disc_loss = 0.06643851568360486
Trained batch 179 in epoch 13, gen_loss = 0.8556516735090149, disc_loss = 0.0664886342232219
Trained batch 180 in epoch 13, gen_loss = 0.8541458415392355, disc_loss = 0.06650401047528695
Trained batch 181 in epoch 13, gen_loss = 0.8553214425241554, disc_loss = 0.0662771500416796
Trained batch 182 in epoch 13, gen_loss = 0.8563825965253382, disc_loss = 0.06607467986266714
Trained batch 183 in epoch 13, gen_loss = 0.8553297349616237, disc_loss = 0.06601762996085556
Trained batch 184 in epoch 13, gen_loss = 0.854965722399789, disc_loss = 0.06578988525261348
Trained batch 185 in epoch 13, gen_loss = 0.8548006263150963, disc_loss = 0.06551267082242154
Trained batch 186 in epoch 13, gen_loss = 0.8561886442217598, disc_loss = 0.06545423182165798
Trained batch 187 in epoch 13, gen_loss = 0.8558943653677372, disc_loss = 0.0654473101021722
Trained batch 188 in epoch 13, gen_loss = 0.8563895618158673, disc_loss = 0.06515674697846253
Trained batch 189 in epoch 13, gen_loss = 0.8567363128850335, disc_loss = 0.06504078143472342
Trained batch 190 in epoch 13, gen_loss = 0.8570981080307386, disc_loss = 0.06474272860701717
Trained batch 191 in epoch 13, gen_loss = 0.8576138508506119, disc_loss = 0.0644549358767108
Trained batch 192 in epoch 13, gen_loss = 0.856642008908672, disc_loss = 0.06445360882207751
Trained batch 193 in epoch 13, gen_loss = 0.8576055345768782, disc_loss = 0.06416843584546647
Trained batch 194 in epoch 13, gen_loss = 0.857465083629657, disc_loss = 0.06389137650481784
Trained batch 195 in epoch 13, gen_loss = 0.8586554957591758, disc_loss = 0.0638952464202647
Trained batch 196 in epoch 13, gen_loss = 0.8587956850601332, disc_loss = 0.06364411386769965
Trained batch 197 in epoch 13, gen_loss = 0.8589802972897135, disc_loss = 0.06357671198849049
Trained batch 198 in epoch 13, gen_loss = 0.8591394953092738, disc_loss = 0.06332450438917957
Trained batch 199 in epoch 13, gen_loss = 0.8589000199735165, disc_loss = 0.06324261559406295
Trained batch 200 in epoch 13, gen_loss = 0.8611184754478398, disc_loss = 0.06314453771986549
Trained batch 201 in epoch 13, gen_loss = 0.8621579489790567, disc_loss = 0.06320379420165156
Trained batch 202 in epoch 13, gen_loss = 0.8610096140741714, disc_loss = 0.06313599631639905
Trained batch 203 in epoch 13, gen_loss = 0.8619169205719349, disc_loss = 0.06293257758907024
Trained batch 204 in epoch 13, gen_loss = 0.8622687291808244, disc_loss = 0.06266603484159199
Trained batch 205 in epoch 13, gen_loss = 0.8621153853182654, disc_loss = 0.06252003068475107
Trained batch 206 in epoch 13, gen_loss = 0.8627597970375116, disc_loss = 0.062303635833901916
Trained batch 207 in epoch 13, gen_loss = 0.8636137919070629, disc_loss = 0.062234689112161644
Trained batch 208 in epoch 13, gen_loss = 0.8636944292549882, disc_loss = 0.06201578963449911
Trained batch 209 in epoch 13, gen_loss = 0.8640780399243037, disc_loss = 0.061806346509339555
Trained batch 210 in epoch 13, gen_loss = 0.8646335885705541, disc_loss = 0.06159799556375892
Trained batch 211 in epoch 13, gen_loss = 0.8644682074773986, disc_loss = 0.061376471298676474
Trained batch 212 in epoch 13, gen_loss = 0.8660103968331512, disc_loss = 0.06147827251547589
Trained batch 213 in epoch 13, gen_loss = 0.8659092802032132, disc_loss = 0.061312808130789445
Trained batch 214 in epoch 13, gen_loss = 0.8658445137877797, disc_loss = 0.06119513536565179
Trained batch 215 in epoch 13, gen_loss = 0.8662686597693849, disc_loss = 0.0609486407656395
Trained batch 216 in epoch 13, gen_loss = 0.8665364913402065, disc_loss = 0.06094520887754823
Trained batch 217 in epoch 13, gen_loss = 0.8658288229222691, disc_loss = 0.060957564214039424
Trained batch 218 in epoch 13, gen_loss = 0.8655985521671434, disc_loss = 0.06096854675178454
Trained batch 219 in epoch 13, gen_loss = 0.866328273984519, disc_loss = 0.0609557562105527
Trained batch 220 in epoch 13, gen_loss = 0.8662563105244442, disc_loss = 0.06081622383215916
Trained batch 221 in epoch 13, gen_loss = 0.8665274007094873, disc_loss = 0.060590891073130676
Trained batch 222 in epoch 13, gen_loss = 0.8660765192701143, disc_loss = 0.06043545227506169
Trained batch 223 in epoch 13, gen_loss = 0.8668256477851953, disc_loss = 0.06022125442021726
Trained batch 224 in epoch 13, gen_loss = 0.8665838857491811, disc_loss = 0.06011411777180102
Trained batch 225 in epoch 13, gen_loss = 0.8667276866931831, disc_loss = 0.05994358066411738
Trained batch 226 in epoch 13, gen_loss = 0.8674604993822291, disc_loss = 0.05989992716411203
Trained batch 227 in epoch 13, gen_loss = 0.8679951211078125, disc_loss = 0.05967340877549233
Trained batch 228 in epoch 13, gen_loss = 0.8670799704878611, disc_loss = 0.059919105519390135
Trained batch 229 in epoch 13, gen_loss = 0.866364734976188, disc_loss = 0.0599807251184045
Trained batch 230 in epoch 13, gen_loss = 0.8687692672917338, disc_loss = 0.060363170430789904
Trained batch 231 in epoch 13, gen_loss = 0.8683019864918857, disc_loss = 0.06049249967728774
Trained batch 232 in epoch 13, gen_loss = 0.8681797202308802, disc_loss = 0.060342479898902096
Trained batch 233 in epoch 13, gen_loss = 0.8675043627492383, disc_loss = 0.06035587194964735
Trained batch 234 in epoch 13, gen_loss = 0.8679432738334575, disc_loss = 0.06039259427603572
Trained batch 235 in epoch 13, gen_loss = 0.8680636810801797, disc_loss = 0.060240512037002564
Trained batch 236 in epoch 13, gen_loss = 0.8681474947979682, disc_loss = 0.060083863040518784
Trained batch 237 in epoch 13, gen_loss = 0.8691165671378625, disc_loss = 0.05988097309228815
Trained batch 238 in epoch 13, gen_loss = 0.869517230463826, disc_loss = 0.059705875605485056
Trained batch 239 in epoch 13, gen_loss = 0.8682057610402505, disc_loss = 0.05989211655881566
Trained batch 240 in epoch 13, gen_loss = 0.8677035556541933, disc_loss = 0.05983236524241656
Trained batch 241 in epoch 13, gen_loss = 0.8681465349167832, disc_loss = 0.06022973678244108
Trained batch 242 in epoch 13, gen_loss = 0.8679799983285582, disc_loss = 0.06004535057869406
Trained batch 243 in epoch 13, gen_loss = 0.8679836554849734, disc_loss = 0.059878752648937286
Trained batch 244 in epoch 13, gen_loss = 0.8672541991788514, disc_loss = 0.06003560688992848
Trained batch 245 in epoch 13, gen_loss = 0.8668576002847858, disc_loss = 0.059890283928517765
Trained batch 246 in epoch 13, gen_loss = 0.8678705430465189, disc_loss = 0.05979633467603731
Trained batch 247 in epoch 13, gen_loss = 0.868281745261723, disc_loss = 0.05961484265055567
Trained batch 248 in epoch 13, gen_loss = 0.8680700373697472, disc_loss = 0.05978568530936976
Trained batch 249 in epoch 13, gen_loss = 0.8673339294195175, disc_loss = 0.059664384422823784
Trained batch 250 in epoch 13, gen_loss = 0.8666670549200826, disc_loss = 0.05969227918523894
Trained batch 251 in epoch 13, gen_loss = 0.8666335889507853, disc_loss = 0.059572023936429075
Trained batch 252 in epoch 13, gen_loss = 0.8653630259715521, disc_loss = 0.05996336301111362
Trained batch 253 in epoch 13, gen_loss = 0.8669754136500396, disc_loss = 0.060058322997294425
Trained batch 254 in epoch 13, gen_loss = 0.8675391002028596, disc_loss = 0.05988186119562563
Trained batch 255 in epoch 13, gen_loss = 0.8667620184132829, disc_loss = 0.05990254102835024
Trained batch 256 in epoch 13, gen_loss = 0.8673753901910225, disc_loss = 0.05969813949127722
Trained batch 257 in epoch 13, gen_loss = 0.8675391887740571, disc_loss = 0.059569845304557285
Trained batch 258 in epoch 13, gen_loss = 0.8671311336824793, disc_loss = 0.05943191230915573
Trained batch 259 in epoch 13, gen_loss = 0.8667632991304765, disc_loss = 0.05941141257420755
Trained batch 260 in epoch 13, gen_loss = 0.8674875345951752, disc_loss = 0.059294769365583117
Trained batch 261 in epoch 13, gen_loss = 0.8670051387930644, disc_loss = 0.05923300216912882
Trained batch 262 in epoch 13, gen_loss = 0.8672217251910003, disc_loss = 0.05907239196574167
Trained batch 263 in epoch 13, gen_loss = 0.8667503117837689, disc_loss = 0.05897046114445071
Trained batch 264 in epoch 13, gen_loss = 0.8678905434203598, disc_loss = 0.05893424404609316
Trained batch 265 in epoch 13, gen_loss = 0.8674182482904061, disc_loss = 0.05884375110534685
Trained batch 266 in epoch 13, gen_loss = 0.8672237493348925, disc_loss = 0.05869723924467068
Trained batch 267 in epoch 13, gen_loss = 0.8676019621206753, disc_loss = 0.058511936769528844
Trained batch 268 in epoch 13, gen_loss = 0.8680085771367453, disc_loss = 0.05872876702229662
Trained batch 269 in epoch 13, gen_loss = 0.8673157408281609, disc_loss = 0.05875204816391623
Trained batch 270 in epoch 13, gen_loss = 0.8670662039980237, disc_loss = 0.05861511983568488
Trained batch 271 in epoch 13, gen_loss = 0.8678368558997617, disc_loss = 0.058558755050933754
Trained batch 272 in epoch 13, gen_loss = 0.8676278103183914, disc_loss = 0.05847816280133668
Trained batch 273 in epoch 13, gen_loss = 0.8670694141709892, disc_loss = 0.058503880624380646
Trained batch 274 in epoch 13, gen_loss = 0.8667760858752511, disc_loss = 0.05835561546751044
Trained batch 275 in epoch 13, gen_loss = 0.8671946379801502, disc_loss = 0.05819707573391497
Trained batch 276 in epoch 13, gen_loss = 0.8676664509713005, disc_loss = 0.05802909414273845
Trained batch 277 in epoch 13, gen_loss = 0.8672258743493677, disc_loss = 0.05799215677254599
Trained batch 278 in epoch 13, gen_loss = 0.8679535932651985, disc_loss = 0.05789805158612228
Trained batch 279 in epoch 13, gen_loss = 0.8669249158884798, disc_loss = 0.05819635583154325
Trained batch 280 in epoch 13, gen_loss = 0.8674596262784191, disc_loss = 0.05853524990048379
Trained batch 281 in epoch 13, gen_loss = 0.866682989694548, disc_loss = 0.05857856022458233
Trained batch 282 in epoch 13, gen_loss = 0.8670041665382183, disc_loss = 0.05873239317138814
Trained batch 283 in epoch 13, gen_loss = 0.8668311342177256, disc_loss = 0.05862508029808146
Trained batch 284 in epoch 13, gen_loss = 0.8655252894811463, disc_loss = 0.05906706586022649
Trained batch 285 in epoch 13, gen_loss = 0.8659745353710401, disc_loss = 0.059492836286268246
Trained batch 286 in epoch 13, gen_loss = 0.86642834689559, disc_loss = 0.059418852155450536
Trained batch 287 in epoch 13, gen_loss = 0.8656981803683771, disc_loss = 0.05955857314337562
Trained batch 288 in epoch 13, gen_loss = 0.8649438927949094, disc_loss = 0.059577642108561875
Trained batch 289 in epoch 13, gen_loss = 0.8649134669838281, disc_loss = 0.059746452488390535
Trained batch 290 in epoch 13, gen_loss = 0.8652034720399535, disc_loss = 0.05976653026410497
Trained batch 291 in epoch 13, gen_loss = 0.8652658663588028, disc_loss = 0.059649763874428934
Trained batch 292 in epoch 13, gen_loss = 0.864281576342957, disc_loss = 0.059950502675166516
Trained batch 293 in epoch 13, gen_loss = 0.864201693814628, disc_loss = 0.06011069081026782
Trained batch 294 in epoch 13, gen_loss = 0.8644686178635743, disc_loss = 0.05995963829238031
Trained batch 295 in epoch 13, gen_loss = 0.864536807243083, disc_loss = 0.05982179616615679
Trained batch 296 in epoch 13, gen_loss = 0.8647411438551816, disc_loss = 0.059713111208870955
Trained batch 297 in epoch 13, gen_loss = 0.8645924260752313, disc_loss = 0.059588125878757475
Trained batch 298 in epoch 13, gen_loss = 0.8648073108100572, disc_loss = 0.05944632507399671
Trained batch 299 in epoch 13, gen_loss = 0.864695850511392, disc_loss = 0.059452526547635595
Trained batch 300 in epoch 13, gen_loss = 0.8646426873151646, disc_loss = 0.05942406790312441
Trained batch 301 in epoch 13, gen_loss = 0.8645822677193888, disc_loss = 0.059290106627251336
Trained batch 302 in epoch 13, gen_loss = 0.8658841709689339, disc_loss = 0.059237280808290826
Trained batch 303 in epoch 13, gen_loss = 0.8659742263782966, disc_loss = 0.05908644064881006
Trained batch 304 in epoch 13, gen_loss = 0.8660033830853759, disc_loss = 0.058981375142809794
Trained batch 305 in epoch 13, gen_loss = 0.8655243057246301, disc_loss = 0.05889047427541193
Trained batch 306 in epoch 13, gen_loss = 0.8647515190346622, disc_loss = 0.05903630046908067
Trained batch 307 in epoch 13, gen_loss = 0.8654690500010144, disc_loss = 0.05936650981122701
Trained batch 308 in epoch 13, gen_loss = 0.8656220739906274, disc_loss = 0.05926904620898098
Trained batch 309 in epoch 13, gen_loss = 0.8651164419228031, disc_loss = 0.0592582781318455
Trained batch 310 in epoch 13, gen_loss = 0.8654940727247686, disc_loss = 0.059104235965602846
Trained batch 311 in epoch 13, gen_loss = 0.8670953081395382, disc_loss = 0.059450066358877875
Trained batch 312 in epoch 13, gen_loss = 0.8659804881380769, disc_loss = 0.05975246917123136
Trained batch 313 in epoch 13, gen_loss = 0.8658371507931667, disc_loss = 0.05961335284018498
Trained batch 314 in epoch 13, gen_loss = 0.8657390907643333, disc_loss = 0.05950688849543295
Trained batch 315 in epoch 13, gen_loss = 0.8657594099640846, disc_loss = 0.05950770451380765
Trained batch 316 in epoch 13, gen_loss = 0.8658553479409744, disc_loss = 0.05938672208835368
Trained batch 317 in epoch 13, gen_loss = 0.8656917755146446, disc_loss = 0.05925836754705077
Trained batch 318 in epoch 13, gen_loss = 0.8655615907664583, disc_loss = 0.0591973498621284
Trained batch 319 in epoch 13, gen_loss = 0.865129938069731, disc_loss = 0.05914916919718962
Trained batch 320 in epoch 13, gen_loss = 0.8661590481287222, disc_loss = 0.05958774734311664
Trained batch 321 in epoch 13, gen_loss = 0.865711663728175, disc_loss = 0.059636422678805104
Trained batch 322 in epoch 13, gen_loss = 0.8661848811357752, disc_loss = 0.059812876713049856
Trained batch 323 in epoch 13, gen_loss = 0.8655396599644496, disc_loss = 0.05980593432603335
Trained batch 324 in epoch 13, gen_loss = 0.864793743628722, disc_loss = 0.05982860239365926
Trained batch 325 in epoch 13, gen_loss = 0.8650702293847967, disc_loss = 0.05969743381191525
Trained batch 326 in epoch 13, gen_loss = 0.8659281013391069, disc_loss = 0.059601828350545984
Trained batch 327 in epoch 13, gen_loss = 0.8661414616536803, disc_loss = 0.05967835921555667
Trained batch 328 in epoch 13, gen_loss = 0.8656926605295627, disc_loss = 0.059662446410800006
Trained batch 329 in epoch 13, gen_loss = 0.8656481489087596, disc_loss = 0.05953610652606144
Trained batch 330 in epoch 13, gen_loss = 0.8658912740985433, disc_loss = 0.05950576184300588
Trained batch 331 in epoch 13, gen_loss = 0.8654854896377369, disc_loss = 0.05948017530019833
Trained batch 332 in epoch 13, gen_loss = 0.8665385245381891, disc_loss = 0.060062229468322195
Trained batch 333 in epoch 13, gen_loss = 0.8664199384208211, disc_loss = 0.06011771608400577
Trained batch 334 in epoch 13, gen_loss = 0.8662837878092011, disc_loss = 0.06009086406331009
Trained batch 335 in epoch 13, gen_loss = 0.8662302773445845, disc_loss = 0.06006668473959768
Trained batch 336 in epoch 13, gen_loss = 0.8664236619670597, disc_loss = 0.06029501558731943
Trained batch 337 in epoch 13, gen_loss = 0.8662370026287948, disc_loss = 0.060278783086687326
Trained batch 338 in epoch 13, gen_loss = 0.865164776203555, disc_loss = 0.060597738369222415
Trained batch 339 in epoch 13, gen_loss = 0.8660198706914397, disc_loss = 0.060986090793876964
Trained batch 340 in epoch 13, gen_loss = 0.8660687799852265, disc_loss = 0.06083416752790338
Trained batch 341 in epoch 13, gen_loss = 0.8653914849137703, disc_loss = 0.06079196249957235
Trained batch 342 in epoch 13, gen_loss = 0.8658987576516655, disc_loss = 0.06065104566188665
Trained batch 343 in epoch 13, gen_loss = 0.8654686760937058, disc_loss = 0.06068620470157543
Trained batch 344 in epoch 13, gen_loss = 0.8653085262015245, disc_loss = 0.060645094708256096
Trained batch 345 in epoch 13, gen_loss = 0.8656854153196246, disc_loss = 0.06071083381169104
Trained batch 346 in epoch 13, gen_loss = 0.8650214846436504, disc_loss = 0.060853240276104434
Trained batch 347 in epoch 13, gen_loss = 0.864445953105373, disc_loss = 0.06086382633824458
Trained batch 348 in epoch 13, gen_loss = 0.8648051603304964, disc_loss = 0.060734993818197344
Trained batch 349 in epoch 13, gen_loss = 0.8652672685044153, disc_loss = 0.0605841061260019
Trained batch 350 in epoch 13, gen_loss = 0.8646146148188502, disc_loss = 0.06058670256679554
Trained batch 351 in epoch 13, gen_loss = 0.8654207672754471, disc_loss = 0.060675639415752484
Trained batch 352 in epoch 13, gen_loss = 0.8639736957320411, disc_loss = 0.06143260146715486
Trained batch 353 in epoch 13, gen_loss = 0.8645418338519705, disc_loss = 0.06150620452807111
Trained batch 354 in epoch 13, gen_loss = 0.8642421210315866, disc_loss = 0.06155038388891959
Trained batch 355 in epoch 13, gen_loss = 0.8637620955705643, disc_loss = 0.06165699975753433
Trained batch 356 in epoch 13, gen_loss = 0.863489541352964, disc_loss = 0.061748097392440845
Trained batch 357 in epoch 13, gen_loss = 0.8636182110402837, disc_loss = 0.06174534351133101
Trained batch 358 in epoch 13, gen_loss = 0.8633567035032182, disc_loss = 0.061753179909127
Trained batch 359 in epoch 13, gen_loss = 0.8633330858416027, disc_loss = 0.06168917970110973
Trained batch 360 in epoch 13, gen_loss = 0.8634823098407227, disc_loss = 0.061551561181812736
Trained batch 361 in epoch 13, gen_loss = 0.8635872187535407, disc_loss = 0.06154690405034887
Trained batch 362 in epoch 13, gen_loss = 0.8632586498234226, disc_loss = 0.06159971377327422
Trained batch 363 in epoch 13, gen_loss = 0.863837908584993, disc_loss = 0.06156012520275928
Trained batch 364 in epoch 13, gen_loss = 0.863425114710037, disc_loss = 0.061536636866935314
Trained batch 365 in epoch 13, gen_loss = 0.8637876891698993, disc_loss = 0.061719495172057645
Trained batch 366 in epoch 13, gen_loss = 0.8633684023849321, disc_loss = 0.06171629246963792
Trained batch 367 in epoch 13, gen_loss = 0.8633002978952035, disc_loss = 0.06170172735279345
Trained batch 368 in epoch 13, gen_loss = 0.8630228889020801, disc_loss = 0.06162881851196289
Trained batch 369 in epoch 13, gen_loss = 0.863295664497324, disc_loss = 0.061673312714776475
Trained batch 370 in epoch 13, gen_loss = 0.8630427976824203, disc_loss = 0.06170663524750429
Trained batch 371 in epoch 13, gen_loss = 0.8633621956712456, disc_loss = 0.061673757409857165
Trained batch 372 in epoch 13, gen_loss = 0.8625029574770071, disc_loss = 0.062195370368279976
Trained batch 373 in epoch 13, gen_loss = 0.8636174154154119, disc_loss = 0.06242499883002776
Trained batch 374 in epoch 13, gen_loss = 0.8631570118268331, disc_loss = 0.062335761278867724
Trained batch 375 in epoch 13, gen_loss = 0.8633842596665342, disc_loss = 0.06219756625037878
Trained batch 376 in epoch 13, gen_loss = 0.8633572146177925, disc_loss = 0.0620908398398591
Trained batch 377 in epoch 13, gen_loss = 0.8634184181059479, disc_loss = 0.06207228716581114
Trained batch 378 in epoch 13, gen_loss = 0.8638014382926015, disc_loss = 0.06197951988152432
Trained batch 379 in epoch 13, gen_loss = 0.8634223403115021, disc_loss = 0.06199025943581211
Trained batch 380 in epoch 13, gen_loss = 0.8633167604448915, disc_loss = 0.06186365481866939
Trained batch 381 in epoch 13, gen_loss = 0.8634683717607827, disc_loss = 0.06175335441077255
Trained batch 382 in epoch 13, gen_loss = 0.8629926611175737, disc_loss = 0.061719928325856634
Trained batch 383 in epoch 13, gen_loss = 0.8625266828263799, disc_loss = 0.062088957628778495
Trained batch 384 in epoch 13, gen_loss = 0.8623396255753257, disc_loss = 0.061992365755624584
Trained batch 385 in epoch 13, gen_loss = 0.8615081787418207, disc_loss = 0.062088902243485414
Trained batch 386 in epoch 13, gen_loss = 0.8615840120525015, disc_loss = 0.06206658544639746
Trained batch 387 in epoch 13, gen_loss = 0.8616673342653156, disc_loss = 0.06196824456901126
Trained batch 388 in epoch 13, gen_loss = 0.8615585904194947, disc_loss = 0.06184935440000501
Trained batch 389 in epoch 13, gen_loss = 0.8612689829789675, disc_loss = 0.06183210037744198
Trained batch 390 in epoch 13, gen_loss = 0.8612726974060468, disc_loss = 0.06187170564347064
Trained batch 391 in epoch 13, gen_loss = 0.8615277636111999, disc_loss = 0.061751822164111146
Trained batch 392 in epoch 13, gen_loss = 0.8616875981859882, disc_loss = 0.06167949567627133
Trained batch 393 in epoch 13, gen_loss = 0.8615283197557866, disc_loss = 0.06161585370986368
Trained batch 394 in epoch 13, gen_loss = 0.8615707540813881, disc_loss = 0.06150355152078445
Trained batch 395 in epoch 13, gen_loss = 0.8611454522669918, disc_loss = 0.061599276675325304
Trained batch 396 in epoch 13, gen_loss = 0.8620851936208211, disc_loss = 0.06153995164386196
Trained batch 397 in epoch 13, gen_loss = 0.8623693353267171, disc_loss = 0.06167189145797686
Trained batch 398 in epoch 13, gen_loss = 0.8630267251703075, disc_loss = 0.06158813885308074
Trained batch 399 in epoch 13, gen_loss = 0.8624111054837704, disc_loss = 0.06187022051541135
Trained batch 400 in epoch 13, gen_loss = 0.8618627169780303, disc_loss = 0.06193771487115848
Trained batch 401 in epoch 13, gen_loss = 0.8624693708336768, disc_loss = 0.06190033344811394
Trained batch 402 in epoch 13, gen_loss = 0.862547404712838, disc_loss = 0.06181322855103031
Trained batch 403 in epoch 13, gen_loss = 0.8629879865906026, disc_loss = 0.0617869771661993
Trained batch 404 in epoch 13, gen_loss = 0.8621782311686763, disc_loss = 0.06178583814360109
Trained batch 405 in epoch 13, gen_loss = 0.8622937280262633, disc_loss = 0.06167677027205455
Trained batch 406 in epoch 13, gen_loss = 0.8618071755847415, disc_loss = 0.061665971232555274
Trained batch 407 in epoch 13, gen_loss = 0.8619803960124651, disc_loss = 0.06163278976957515
Trained batch 408 in epoch 13, gen_loss = 0.8618693382349457, disc_loss = 0.06150436842436094
Trained batch 409 in epoch 13, gen_loss = 0.862120781729861, disc_loss = 0.06144801820969073
Trained batch 410 in epoch 13, gen_loss = 0.862246197505589, disc_loss = 0.061458158478992844
Trained batch 411 in epoch 13, gen_loss = 0.8618284724291089, disc_loss = 0.06145653996878819
Trained batch 412 in epoch 13, gen_loss = 0.86260637879083, disc_loss = 0.06159365935066205
Trained batch 413 in epoch 13, gen_loss = 0.8621694648611373, disc_loss = 0.061708005282416004
Trained batch 414 in epoch 13, gen_loss = 0.861608839896788, disc_loss = 0.061705421398292826
Trained batch 415 in epoch 13, gen_loss = 0.8616464666735667, disc_loss = 0.0617259440858526
Trained batch 416 in epoch 13, gen_loss = 0.861263852897022, disc_loss = 0.06180902611803737
Trained batch 417 in epoch 13, gen_loss = 0.8613933366166348, disc_loss = 0.061710530114426995
Trained batch 418 in epoch 13, gen_loss = 0.861332572160871, disc_loss = 0.06160788525891688
Trained batch 419 in epoch 13, gen_loss = 0.8608867577144078, disc_loss = 0.061551081280534464
Trained batch 420 in epoch 13, gen_loss = 0.8613794240702359, disc_loss = 0.06149718744764348
Trained batch 421 in epoch 13, gen_loss = 0.8612690316557319, disc_loss = 0.06144505822854514
Trained batch 422 in epoch 13, gen_loss = 0.8610038111959507, disc_loss = 0.061437266891993955
Trained batch 423 in epoch 13, gen_loss = 0.860496221145369, disc_loss = 0.061407617458036905
Trained batch 424 in epoch 13, gen_loss = 0.8608668443735908, disc_loss = 0.06130042208249078
Trained batch 425 in epoch 13, gen_loss = 0.861030229940101, disc_loss = 0.061177138376876085
Trained batch 426 in epoch 13, gen_loss = 0.8609177546981347, disc_loss = 0.0611853389095611
Trained batch 427 in epoch 13, gen_loss = 0.8614456492049671, disc_loss = 0.06110374651910198
Trained batch 428 in epoch 13, gen_loss = 0.8610227334471572, disc_loss = 0.0610823820134525
Trained batch 429 in epoch 13, gen_loss = 0.8615077693795049, disc_loss = 0.06156741046931508
Trained batch 430 in epoch 13, gen_loss = 0.8618653034942609, disc_loss = 0.061456549700928675
Trained batch 431 in epoch 13, gen_loss = 0.8615821582023744, disc_loss = 0.06138774585754921
Trained batch 432 in epoch 13, gen_loss = 0.8612596915720792, disc_loss = 0.0614239412981492
Trained batch 433 in epoch 13, gen_loss = 0.8607396050806968, disc_loss = 0.061540094564758965
Trained batch 434 in epoch 13, gen_loss = 0.8609737975844022, disc_loss = 0.06142599384846358
Trained batch 435 in epoch 13, gen_loss = 0.8614223510573763, disc_loss = 0.061473951093989225
Trained batch 436 in epoch 13, gen_loss = 0.8612249373571278, disc_loss = 0.06149174734199893
Trained batch 437 in epoch 13, gen_loss = 0.8616416882978727, disc_loss = 0.061441303600799545
Trained batch 438 in epoch 13, gen_loss = 0.8609473456825917, disc_loss = 0.06161075284819125
Trained batch 439 in epoch 13, gen_loss = 0.861578547548164, disc_loss = 0.061893062166530975
Trained batch 440 in epoch 13, gen_loss = 0.8610461889481058, disc_loss = 0.06198818235744695
Trained batch 441 in epoch 13, gen_loss = 0.8607104578438927, disc_loss = 0.06208701355054098
Trained batch 442 in epoch 13, gen_loss = 0.8610145756407193, disc_loss = 0.06201997232827322
Trained batch 443 in epoch 13, gen_loss = 0.8603089592746787, disc_loss = 0.062027618423238534
Trained batch 444 in epoch 13, gen_loss = 0.8599426672699746, disc_loss = 0.06209597544053967
Trained batch 445 in epoch 13, gen_loss = 0.8598723360775832, disc_loss = 0.06203277861791341
Trained batch 446 in epoch 13, gen_loss = 0.8594192535818557, disc_loss = 0.06215562174717585
Trained batch 447 in epoch 13, gen_loss = 0.8595486144934382, disc_loss = 0.062196484949838905
Trained batch 448 in epoch 13, gen_loss = 0.8594290347301083, disc_loss = 0.06208692962108781
Trained batch 449 in epoch 13, gen_loss = 0.8593625269995795, disc_loss = 0.06199626453841726
Trained batch 450 in epoch 13, gen_loss = 0.8596029812903732, disc_loss = 0.06188714254168409
Trained batch 451 in epoch 13, gen_loss = 0.8590948319276878, disc_loss = 0.06195662956297464
Trained batch 452 in epoch 13, gen_loss = 0.8588360619071304, disc_loss = 0.06194613499990428
Trained batch 453 in epoch 13, gen_loss = 0.8586289551814748, disc_loss = 0.06227878035796962
Trained batch 454 in epoch 13, gen_loss = 0.8585571689920111, disc_loss = 0.06219735809775827
Trained batch 455 in epoch 13, gen_loss = 0.8587248718790841, disc_loss = 0.06211076597805674
Trained batch 456 in epoch 13, gen_loss = 0.8581578327216518, disc_loss = 0.062161651766029564
Trained batch 457 in epoch 13, gen_loss = 0.8585141524997861, disc_loss = 0.062221529875276
Trained batch 458 in epoch 13, gen_loss = 0.8585446734054416, disc_loss = 0.062299680875813127
Trained batch 459 in epoch 13, gen_loss = 0.8587021064499151, disc_loss = 0.06219127348057278
Trained batch 460 in epoch 13, gen_loss = 0.8579193487472493, disc_loss = 0.06246564078090183
Trained batch 461 in epoch 13, gen_loss = 0.8575285620890655, disc_loss = 0.06249519116426637
Trained batch 462 in epoch 13, gen_loss = 0.8580347764955484, disc_loss = 0.06311905504552322
Trained batch 463 in epoch 13, gen_loss = 0.8579092967998365, disc_loss = 0.06319731892817172
Trained batch 464 in epoch 13, gen_loss = 0.8571408618521946, disc_loss = 0.06342367454361851
Trained batch 465 in epoch 13, gen_loss = 0.8567945111079277, disc_loss = 0.06353075869277504
Trained batch 466 in epoch 13, gen_loss = 0.8572405817294274, disc_loss = 0.06372040241948734
Trained batch 467 in epoch 13, gen_loss = 0.8569292467501428, disc_loss = 0.06366431312516141
Trained batch 468 in epoch 13, gen_loss = 0.8567892425477124, disc_loss = 0.06361238278551841
Trained batch 469 in epoch 13, gen_loss = 0.8562346169923214, disc_loss = 0.06362214771475881
Trained batch 470 in epoch 13, gen_loss = 0.8558915803513456, disc_loss = 0.06354640052711191
Trained batch 471 in epoch 13, gen_loss = 0.8559522248046884, disc_loss = 0.06350118536857288
Trained batch 472 in epoch 13, gen_loss = 0.855954704589622, disc_loss = 0.06341555293050868
Trained batch 473 in epoch 13, gen_loss = 0.8560751014495198, disc_loss = 0.06331143407583363
Trained batch 474 in epoch 13, gen_loss = 0.8562297009794335, disc_loss = 0.06321014412531727
Trained batch 475 in epoch 13, gen_loss = 0.8556568192458954, disc_loss = 0.06323072081431746
Trained batch 476 in epoch 13, gen_loss = 0.8558729747681247, disc_loss = 0.06312195272175146
Trained batch 477 in epoch 13, gen_loss = 0.8559157760447538, disc_loss = 0.06329040297513602
Trained batch 478 in epoch 13, gen_loss = 0.8557204019923798, disc_loss = 0.0632352391238439
Trained batch 479 in epoch 13, gen_loss = 0.8554471790169677, disc_loss = 0.06318926586536691
Trained batch 480 in epoch 13, gen_loss = 0.8555430898175665, disc_loss = 0.0631077301082455
Trained batch 481 in epoch 13, gen_loss = 0.8559710327149427, disc_loss = 0.06303416102490855
Trained batch 482 in epoch 13, gen_loss = 0.8555735552656478, disc_loss = 0.06299576125884772
Trained batch 483 in epoch 13, gen_loss = 0.8560885061040397, disc_loss = 0.06303288842636076
Trained batch 484 in epoch 13, gen_loss = 0.8561102489220728, disc_loss = 0.06296864624720873
Trained batch 485 in epoch 13, gen_loss = 0.8555980763194982, disc_loss = 0.06306999441573527
Trained batch 486 in epoch 13, gen_loss = 0.8553765717840293, disc_loss = 0.06306957983979822
Trained batch 487 in epoch 13, gen_loss = 0.8552474984746488, disc_loss = 0.06299991091545366
Trained batch 488 in epoch 13, gen_loss = 0.8549902299552363, disc_loss = 0.06299180693254026
Trained batch 489 in epoch 13, gen_loss = 0.8560292070617481, disc_loss = 0.06324989016034774
Trained batch 490 in epoch 13, gen_loss = 0.8558731466956634, disc_loss = 0.06329938572453991
Trained batch 491 in epoch 13, gen_loss = 0.8559628751098625, disc_loss = 0.06330446237546762
Trained batch 492 in epoch 13, gen_loss = 0.8554901360377337, disc_loss = 0.06341405743714157
Trained batch 493 in epoch 13, gen_loss = 0.8561826144997408, disc_loss = 0.06339295359652655
Trained batch 494 in epoch 13, gen_loss = 0.8564987637177862, disc_loss = 0.0633445646538578
Trained batch 495 in epoch 13, gen_loss = 0.8568717603601755, disc_loss = 0.0632387657965263
Trained batch 496 in epoch 13, gen_loss = 0.85651540870158, disc_loss = 0.06342887104127248
Trained batch 497 in epoch 13, gen_loss = 0.8563338485228489, disc_loss = 0.0633827799848883
Trained batch 498 in epoch 13, gen_loss = 0.8568695839158519, disc_loss = 0.0634206532909421
Trained batch 499 in epoch 13, gen_loss = 0.8568512309193611, disc_loss = 0.06335224139690399
Trained batch 500 in epoch 13, gen_loss = 0.8566787237535693, disc_loss = 0.06327895211899828
Trained batch 501 in epoch 13, gen_loss = 0.8569050494774404, disc_loss = 0.06326425588314989
Trained batch 502 in epoch 13, gen_loss = 0.8570361165237237, disc_loss = 0.0631906832670182
Trained batch 503 in epoch 13, gen_loss = 0.8566219295182872, disc_loss = 0.06322191313042172
Trained batch 504 in epoch 13, gen_loss = 0.8563361790510687, disc_loss = 0.06333036780136056
Trained batch 505 in epoch 13, gen_loss = 0.8567709545255179, disc_loss = 0.06333762958366056
Trained batch 506 in epoch 13, gen_loss = 0.8565410377358543, disc_loss = 0.0633575076336515
Trained batch 507 in epoch 13, gen_loss = 0.8572224917726254, disc_loss = 0.06336012488876389
Trained batch 508 in epoch 13, gen_loss = 0.856870910449206, disc_loss = 0.06335042797995105
Trained batch 509 in epoch 13, gen_loss = 0.8563210339522829, disc_loss = 0.06347874628343418
Trained batch 510 in epoch 13, gen_loss = 0.8561426064622846, disc_loss = 0.06348218915003503
Trained batch 511 in epoch 13, gen_loss = 0.8561698221019469, disc_loss = 0.06344502202773583
Trained batch 512 in epoch 13, gen_loss = 0.8556472250708828, disc_loss = 0.06357152639846472
Trained batch 513 in epoch 13, gen_loss = 0.8563119135362165, disc_loss = 0.06382786716309155
Trained batch 514 in epoch 13, gen_loss = 0.8558830089360765, disc_loss = 0.06389955527067763
Trained batch 515 in epoch 13, gen_loss = 0.8558619903155076, disc_loss = 0.06391164806649782
Trained batch 516 in epoch 13, gen_loss = 0.8559049531039232, disc_loss = 0.06389065062702855
Trained batch 517 in epoch 13, gen_loss = 0.855674204621536, disc_loss = 0.06388172534254873
Trained batch 518 in epoch 13, gen_loss = 0.8559381304333894, disc_loss = 0.06388907952445895
Trained batch 519 in epoch 13, gen_loss = 0.8559220605744765, disc_loss = 0.06381686273604058
Trained batch 520 in epoch 13, gen_loss = 0.8555555335047607, disc_loss = 0.06383228623406557
Trained batch 521 in epoch 13, gen_loss = 0.8560964024957569, disc_loss = 0.06376764912629264
Trained batch 522 in epoch 13, gen_loss = 0.8561320878693525, disc_loss = 0.06368045216109283
Trained batch 523 in epoch 13, gen_loss = 0.8563962994527271, disc_loss = 0.06358710083513315
Trained batch 524 in epoch 13, gen_loss = 0.8566365601335253, disc_loss = 0.06348775204625867
Trained batch 525 in epoch 13, gen_loss = 0.856326499649327, disc_loss = 0.06346317865273175
Trained batch 526 in epoch 13, gen_loss = 0.8563618504458179, disc_loss = 0.06337182679738447
Trained batch 527 in epoch 13, gen_loss = 0.8563419730035644, disc_loss = 0.06326905669905528
Trained batch 528 in epoch 13, gen_loss = 0.8563144721358394, disc_loss = 0.06326122558895773
Trained batch 529 in epoch 13, gen_loss = 0.8564349794725202, disc_loss = 0.06317189390120923
Trained batch 530 in epoch 13, gen_loss = 0.8564420863845703, disc_loss = 0.06309796393219304
Trained batch 531 in epoch 13, gen_loss = 0.8568125442790806, disc_loss = 0.0630079731957889
Trained batch 532 in epoch 13, gen_loss = 0.8569447181797385, disc_loss = 0.06290772256020309
Trained batch 533 in epoch 13, gen_loss = 0.8571484099501527, disc_loss = 0.06282826070063346
Trained batch 534 in epoch 13, gen_loss = 0.8571174133046765, disc_loss = 0.06275735567106265
Trained batch 535 in epoch 13, gen_loss = 0.8568569672530266, disc_loss = 0.06269925401837968
Trained batch 536 in epoch 13, gen_loss = 0.8570524392514255, disc_loss = 0.06264342995468021
Trained batch 537 in epoch 13, gen_loss = 0.8569492986321893, disc_loss = 0.06258042713412565
Trained batch 538 in epoch 13, gen_loss = 0.8568500763078346, disc_loss = 0.06250463994237178
Trained batch 539 in epoch 13, gen_loss = 0.8578226454280041, disc_loss = 0.06262980651248384
Trained batch 540 in epoch 13, gen_loss = 0.857597233242116, disc_loss = 0.06264809819279228
Trained batch 541 in epoch 13, gen_loss = 0.8573692251285504, disc_loss = 0.06261090410536506
Trained batch 542 in epoch 13, gen_loss = 0.8575686199340153, disc_loss = 0.06257403644683392
Trained batch 543 in epoch 13, gen_loss = 0.8575782761087313, disc_loss = 0.0625007146736607
Trained batch 544 in epoch 13, gen_loss = 0.8574005721359078, disc_loss = 0.06256015771709451
Trained batch 545 in epoch 13, gen_loss = 0.8576612528754678, disc_loss = 0.062473471012075635
Trained batch 546 in epoch 13, gen_loss = 0.8575488478762576, disc_loss = 0.06247095518338561
Trained batch 547 in epoch 13, gen_loss = 0.8574567187550294, disc_loss = 0.06238883958252514
Trained batch 548 in epoch 13, gen_loss = 0.8582650662445631, disc_loss = 0.06257170391436971
Trained batch 549 in epoch 13, gen_loss = 0.8582483493739909, disc_loss = 0.062488555181771516
Trained batch 550 in epoch 13, gen_loss = 0.8577856095321814, disc_loss = 0.06247349638329606
Trained batch 551 in epoch 13, gen_loss = 0.8577038928110531, disc_loss = 0.06239520028348256
Trained batch 552 in epoch 13, gen_loss = 0.8584659321075322, disc_loss = 0.06258561292572273
Trained batch 553 in epoch 13, gen_loss = 0.8579090981599656, disc_loss = 0.06288350964072648
Trained batch 554 in epoch 13, gen_loss = 0.858096553881963, disc_loss = 0.06279820761567838
Trained batch 555 in epoch 13, gen_loss = 0.8585130006825323, disc_loss = 0.0628319099719683
Trained batch 556 in epoch 13, gen_loss = 0.8583826060462041, disc_loss = 0.06275923730039724
Trained batch 557 in epoch 13, gen_loss = 0.8584177129264373, disc_loss = 0.0627107995639031
Trained batch 558 in epoch 13, gen_loss = 0.8582138381298625, disc_loss = 0.06266174394110874
Trained batch 559 in epoch 13, gen_loss = 0.8584447036364249, disc_loss = 0.0626266977816288
Trained batch 560 in epoch 13, gen_loss = 0.8588400980899253, disc_loss = 0.06259477275976523
Trained batch 561 in epoch 13, gen_loss = 0.8585286136729862, disc_loss = 0.06253167135753665
Trained batch 562 in epoch 13, gen_loss = 0.8587102812200414, disc_loss = 0.06244485516623854
Trained batch 563 in epoch 13, gen_loss = 0.8584731382364077, disc_loss = 0.06241199900957604
Trained batch 564 in epoch 13, gen_loss = 0.8586472235422219, disc_loss = 0.062315765174880494
Trained batch 565 in epoch 13, gen_loss = 0.8592748617220262, disc_loss = 0.062287533497799835
Trained batch 566 in epoch 13, gen_loss = 0.8594513854547363, disc_loss = 0.062216256904486414
Trained batch 567 in epoch 13, gen_loss = 0.8592581877511152, disc_loss = 0.06216598996026835
Trained batch 568 in epoch 13, gen_loss = 0.8595025665625956, disc_loss = 0.062110206207198294
Trained batch 569 in epoch 13, gen_loss = 0.859204485489611, disc_loss = 0.062093937828352576
Trained batch 570 in epoch 13, gen_loss = 0.8592583861221574, disc_loss = 0.062024527172282365
Trained batch 571 in epoch 13, gen_loss = 0.859231062337652, disc_loss = 0.06197008683339699
Trained batch 572 in epoch 13, gen_loss = 0.8588515193986643, disc_loss = 0.061975481609503426
Trained batch 573 in epoch 13, gen_loss = 0.8588300329156038, disc_loss = 0.06189468371737034
Trained batch 574 in epoch 13, gen_loss = 0.8590526817674222, disc_loss = 0.0618038862247182
Trained batch 575 in epoch 13, gen_loss = 0.8592202443526022, disc_loss = 0.06173468160785786
Trained batch 576 in epoch 13, gen_loss = 0.859357695387389, disc_loss = 0.06166262461915225
Trained batch 577 in epoch 13, gen_loss = 0.8590447386552719, disc_loss = 0.06161784641863617
Trained batch 578 in epoch 13, gen_loss = 0.8592104332743531, disc_loss = 0.06154388165670819
Trained batch 579 in epoch 13, gen_loss = 0.8593991847387675, disc_loss = 0.061488298713711316
Trained batch 580 in epoch 13, gen_loss = 0.8596848407936588, disc_loss = 0.06140115153583058
Trained batch 581 in epoch 13, gen_loss = 0.8593059058758811, disc_loss = 0.061438613566425965
Trained batch 582 in epoch 13, gen_loss = 0.8600051584517772, disc_loss = 0.06146987833523577
Trained batch 583 in epoch 13, gen_loss = 0.8600211050106238, disc_loss = 0.06139009863884533
Trained batch 584 in epoch 13, gen_loss = 0.8603539161702507, disc_loss = 0.06130883874069167
Trained batch 585 in epoch 13, gen_loss = 0.8598542962566578, disc_loss = 0.06138453576173443
Trained batch 586 in epoch 13, gen_loss = 0.860031183117293, disc_loss = 0.06153896453058953
Trained batch 587 in epoch 13, gen_loss = 0.8598888524028719, disc_loss = 0.06148845307864756
Trained batch 588 in epoch 13, gen_loss = 0.8599443117406453, disc_loss = 0.06141380507954363
Trained batch 589 in epoch 13, gen_loss = 0.8600820573204655, disc_loss = 0.06138777248087828
Trained batch 590 in epoch 13, gen_loss = 0.8597585123706791, disc_loss = 0.06141645348017843
Trained batch 591 in epoch 13, gen_loss = 0.8597959343948074, disc_loss = 0.06132419871849108
Trained batch 592 in epoch 13, gen_loss = 0.859792045507624, disc_loss = 0.06172580674092771
Trained batch 593 in epoch 13, gen_loss = 0.8594719045591676, disc_loss = 0.06172093430530869
Trained batch 594 in epoch 13, gen_loss = 0.858899838633898, disc_loss = 0.061943892096051896
Trained batch 595 in epoch 13, gen_loss = 0.8596005446258808, disc_loss = 0.062333896681947644
Trained batch 596 in epoch 13, gen_loss = 0.859607741710928, disc_loss = 0.062385671041200755
Trained batch 597 in epoch 13, gen_loss = 0.8593448015260059, disc_loss = 0.062374871548881945
Trained batch 598 in epoch 13, gen_loss = 0.8588898183407887, disc_loss = 0.06245384386543166
Trained batch 599 in epoch 13, gen_loss = 0.8590094311535359, disc_loss = 0.06247448043354476
Trained batch 600 in epoch 13, gen_loss = 0.8590142237465711, disc_loss = 0.0626018088126552
Trained batch 601 in epoch 13, gen_loss = 0.8587500800028988, disc_loss = 0.06269085990261918
Trained batch 602 in epoch 13, gen_loss = 0.8590278305718753, disc_loss = 0.06260321815737568
Trained batch 603 in epoch 13, gen_loss = 0.858745344871322, disc_loss = 0.06262600563839694
Trained batch 604 in epoch 13, gen_loss = 0.8583123917914619, disc_loss = 0.06265251297919341
Trained batch 605 in epoch 13, gen_loss = 0.8590736542106068, disc_loss = 0.06270314225690322
Trained batch 606 in epoch 13, gen_loss = 0.8590205711921711, disc_loss = 0.06266491796400957
Trained batch 607 in epoch 13, gen_loss = 0.8595619119801804, disc_loss = 0.06280272874420534
Trained batch 608 in epoch 13, gen_loss = 0.8593516285685678, disc_loss = 0.06281311175142137
Trained batch 609 in epoch 13, gen_loss = 0.8590128621605576, disc_loss = 0.06287737007588759
Trained batch 610 in epoch 13, gen_loss = 0.8592825020296093, disc_loss = 0.0627908643934138
Trained batch 611 in epoch 13, gen_loss = 0.8591820786104483, disc_loss = 0.06283093546441104
Trained batch 612 in epoch 13, gen_loss = 0.8592198598540433, disc_loss = 0.06278523865427828
Trained batch 613 in epoch 13, gen_loss = 0.858821522869194, disc_loss = 0.06286143217348047
Trained batch 614 in epoch 13, gen_loss = 0.858332036229653, disc_loss = 0.0628723097109516
Trained batch 615 in epoch 13, gen_loss = 0.858713018091081, disc_loss = 0.06281441344967258
Trained batch 616 in epoch 13, gen_loss = 0.8589403138071829, disc_loss = 0.0627295103164109
Trained batch 617 in epoch 13, gen_loss = 0.8588002612965007, disc_loss = 0.06268792615639811
Trained batch 618 in epoch 13, gen_loss = 0.8590223730958528, disc_loss = 0.06260841588455106
Trained batch 619 in epoch 13, gen_loss = 0.8590885217632017, disc_loss = 0.0625265832742556
Trained batch 620 in epoch 13, gen_loss = 0.8593314202223423, disc_loss = 0.06253519495829173
Trained batch 621 in epoch 13, gen_loss = 0.85931810798944, disc_loss = 0.06247556579023767
Trained batch 622 in epoch 13, gen_loss = 0.8589507694898793, disc_loss = 0.0625895758601949
Trained batch 623 in epoch 13, gen_loss = 0.8594077507941387, disc_loss = 0.06265650248343053
Trained batch 624 in epoch 13, gen_loss = 0.8593852157115937, disc_loss = 0.06262471132799984
Trained batch 625 in epoch 13, gen_loss = 0.8589144285780173, disc_loss = 0.06270226658196948
Trained batch 626 in epoch 13, gen_loss = 0.8588006897120954, disc_loss = 0.06278139803680388
Trained batch 627 in epoch 13, gen_loss = 0.8584428805929081, disc_loss = 0.06274158926309935
Trained batch 628 in epoch 13, gen_loss = 0.8583821488961886, disc_loss = 0.0627439532699937
Trained batch 629 in epoch 13, gen_loss = 0.8579812826145263, disc_loss = 0.06274830008236071
Trained batch 630 in epoch 13, gen_loss = 0.8580100803197658, disc_loss = 0.062706405818669
Trained batch 631 in epoch 13, gen_loss = 0.8579903925427154, disc_loss = 0.06264572642092252
Trained batch 632 in epoch 13, gen_loss = 0.8579891282141114, disc_loss = 0.06260512771797005
Trained batch 633 in epoch 13, gen_loss = 0.8580131995659145, disc_loss = 0.06254008537737142
Trained batch 634 in epoch 13, gen_loss = 0.8579167126201269, disc_loss = 0.06251771080080332
Trained batch 635 in epoch 13, gen_loss = 0.8583076594854301, disc_loss = 0.06244598212139388
Trained batch 636 in epoch 13, gen_loss = 0.8583388562947277, disc_loss = 0.06236795716505246
Trained batch 637 in epoch 13, gen_loss = 0.8582088503064033, disc_loss = 0.06229699422681243
Trained batch 638 in epoch 13, gen_loss = 0.8585082000130219, disc_loss = 0.06226407897225778
Trained batch 639 in epoch 13, gen_loss = 0.8583169948775321, disc_loss = 0.06224202395897009
Trained batch 640 in epoch 13, gen_loss = 0.8580374567538454, disc_loss = 0.06221108065697244
Trained batch 641 in epoch 13, gen_loss = 0.8584057997413143, disc_loss = 0.06217091388179343
Trained batch 642 in epoch 13, gen_loss = 0.8590462389945243, disc_loss = 0.06211953079270005
Trained batch 643 in epoch 13, gen_loss = 0.8591470189438843, disc_loss = 0.06207183463663812
Trained batch 644 in epoch 13, gen_loss = 0.8588015388610751, disc_loss = 0.06214564396212845
Trained batch 645 in epoch 13, gen_loss = 0.8586680116391403, disc_loss = 0.062128917528201044
Trained batch 646 in epoch 13, gen_loss = 0.8585828254819837, disc_loss = 0.06212200110755181
Trained batch 647 in epoch 13, gen_loss = 0.8581965739068426, disc_loss = 0.06214119079249716
Trained batch 648 in epoch 13, gen_loss = 0.8581017377472071, disc_loss = 0.06212962117800934
Trained batch 649 in epoch 13, gen_loss = 0.858556414613357, disc_loss = 0.06236145880144949
Trained batch 650 in epoch 13, gen_loss = 0.858308956416155, disc_loss = 0.062497255929564045
Trained batch 651 in epoch 13, gen_loss = 0.8582142002286355, disc_loss = 0.06251885324639433
Trained batch 652 in epoch 13, gen_loss = 0.8582831285722771, disc_loss = 0.06251379006412479
Trained batch 653 in epoch 13, gen_loss = 0.8583419630560306, disc_loss = 0.06260697200498473
Trained batch 654 in epoch 13, gen_loss = 0.8578883352625462, disc_loss = 0.06278978327772658
Trained batch 655 in epoch 13, gen_loss = 0.8580046855367538, disc_loss = 0.06279140788985121
Trained batch 656 in epoch 13, gen_loss = 0.8587521960111151, disc_loss = 0.06279013565949858
Trained batch 657 in epoch 13, gen_loss = 0.8586563043590737, disc_loss = 0.06274258211540981
Trained batch 658 in epoch 13, gen_loss = 0.8580930729104101, disc_loss = 0.062931934801921
Trained batch 659 in epoch 13, gen_loss = 0.858221617928057, disc_loss = 0.06294783123303205
Trained batch 660 in epoch 13, gen_loss = 0.8584078025980183, disc_loss = 0.06288142755145767
Trained batch 661 in epoch 13, gen_loss = 0.8580474618068274, disc_loss = 0.06300568137545802
Trained batch 662 in epoch 13, gen_loss = 0.8581360124085284, disc_loss = 0.06299642538988955
Trained batch 663 in epoch 13, gen_loss = 0.8586758867534529, disc_loss = 0.06308143924015674
Trained batch 664 in epoch 13, gen_loss = 0.858398966995397, disc_loss = 0.06308387305405468
Trained batch 665 in epoch 13, gen_loss = 0.8585982291816591, disc_loss = 0.06301172451373448
Trained batch 666 in epoch 13, gen_loss = 0.8585427268066149, disc_loss = 0.0629445134907838
Trained batch 667 in epoch 13, gen_loss = 0.8587266369583364, disc_loss = 0.06286608224698415
Trained batch 668 in epoch 13, gen_loss = 0.85865875980601, disc_loss = 0.06280230737941392
Trained batch 669 in epoch 13, gen_loss = 0.8582605416650203, disc_loss = 0.06282383603210659
Trained batch 670 in epoch 13, gen_loss = 0.8586315090272537, disc_loss = 0.06322394237519088
Trained batch 671 in epoch 13, gen_loss = 0.8587178420718937, disc_loss = 0.06317837841162968
Trained batch 672 in epoch 13, gen_loss = 0.8583160526773728, disc_loss = 0.06340959206442134
Trained batch 673 in epoch 13, gen_loss = 0.8585381691374482, disc_loss = 0.06333290867836322
Trained batch 674 in epoch 13, gen_loss = 0.8589173312981924, disc_loss = 0.06340846200163165
Trained batch 675 in epoch 13, gen_loss = 0.8586067292376383, disc_loss = 0.06349197015119441
Trained batch 676 in epoch 13, gen_loss = 0.8581430058447613, disc_loss = 0.06363971573692723
Trained batch 677 in epoch 13, gen_loss = 0.8578373282971987, disc_loss = 0.06364133062217506
Trained batch 678 in epoch 13, gen_loss = 0.8577108876080155, disc_loss = 0.06363285214891204
Trained batch 679 in epoch 13, gen_loss = 0.8572358094155789, disc_loss = 0.0636986049816615
Trained batch 680 in epoch 13, gen_loss = 0.8575514636813456, disc_loss = 0.06380977309220054
Trained batch 681 in epoch 13, gen_loss = 0.8574015488984648, disc_loss = 0.06376228685752977
Trained batch 682 in epoch 13, gen_loss = 0.8569516712802395, disc_loss = 0.06382019855941089
Trained batch 683 in epoch 13, gen_loss = 0.8572018377875027, disc_loss = 0.06374566949160541
Trained batch 684 in epoch 13, gen_loss = 0.8571128458437258, disc_loss = 0.06372926077961813
Trained batch 685 in epoch 13, gen_loss = 0.8570824520494082, disc_loss = 0.0638993492305181
Trained batch 686 in epoch 13, gen_loss = 0.8569626342695006, disc_loss = 0.06386259659579813
Trained batch 687 in epoch 13, gen_loss = 0.8567007325676291, disc_loss = 0.06382906515365142
Trained batch 688 in epoch 13, gen_loss = 0.8567498141605034, disc_loss = 0.06377044108632753
Trained batch 689 in epoch 13, gen_loss = 0.8570307941972346, disc_loss = 0.06370944201176905
Trained batch 690 in epoch 13, gen_loss = 0.8570917725304273, disc_loss = 0.06365386896609031
Trained batch 691 in epoch 13, gen_loss = 0.8569534635009793, disc_loss = 0.06358887754701013
Trained batch 692 in epoch 13, gen_loss = 0.8569493498895076, disc_loss = 0.06352802505716681
Trained batch 693 in epoch 13, gen_loss = 0.8567943123386641, disc_loss = 0.06348037964970367
Trained batch 694 in epoch 13, gen_loss = 0.8569099750879, disc_loss = 0.06340893962413822
Trained batch 695 in epoch 13, gen_loss = 0.8569428306287048, disc_loss = 0.06335828498329689
Trained batch 696 in epoch 13, gen_loss = 0.8569176732809677, disc_loss = 0.0632943283944221
Trained batch 697 in epoch 13, gen_loss = 0.8567879460004817, disc_loss = 0.06324308110003421
Trained batch 698 in epoch 13, gen_loss = 0.8566863731679657, disc_loss = 0.06321547962845075
Trained batch 699 in epoch 13, gen_loss = 0.8567101397258895, disc_loss = 0.06316027871798724
Trained batch 700 in epoch 13, gen_loss = 0.8563601409062509, disc_loss = 0.06316649660364473
Trained batch 701 in epoch 13, gen_loss = 0.8569642868731436, disc_loss = 0.06345650079882999
Trained batch 702 in epoch 13, gen_loss = 0.8570794549215569, disc_loss = 0.06338125627135506
Trained batch 703 in epoch 13, gen_loss = 0.8567245450632816, disc_loss = 0.06354739968678173
Trained batch 704 in epoch 13, gen_loss = 0.8562003863196, disc_loss = 0.06365767124287308
Trained batch 705 in epoch 13, gen_loss = 0.8564500493385299, disc_loss = 0.06385260884565626
Trained batch 706 in epoch 13, gen_loss = 0.8567015582213476, disc_loss = 0.06382385051520766
Trained batch 707 in epoch 13, gen_loss = 0.8562223126238349, disc_loss = 0.06392876662137671
Trained batch 708 in epoch 13, gen_loss = 0.856457471132951, disc_loss = 0.06386315959015774
Trained batch 709 in epoch 13, gen_loss = 0.8564445617753016, disc_loss = 0.06382018648625784
Trained batch 710 in epoch 13, gen_loss = 0.8566627000706105, disc_loss = 0.06385949316713566
Trained batch 711 in epoch 13, gen_loss = 0.8567904426057017, disc_loss = 0.06382034013500396
Trained batch 712 in epoch 13, gen_loss = 0.8569118488804656, disc_loss = 0.06376432870197284
Trained batch 713 in epoch 13, gen_loss = 0.8568460571081364, disc_loss = 0.06369837453127095
Trained batch 714 in epoch 13, gen_loss = 0.8568660826532991, disc_loss = 0.06363826256076044
Trained batch 715 in epoch 13, gen_loss = 0.8569333598683666, disc_loss = 0.06357378785839231
Trained batch 716 in epoch 13, gen_loss = 0.8570444437167302, disc_loss = 0.06360933625800444
Trained batch 717 in epoch 13, gen_loss = 0.8571416557582308, disc_loss = 0.06354777902834284
Trained batch 718 in epoch 13, gen_loss = 0.8568895424771873, disc_loss = 0.06349557807399621
Trained batch 719 in epoch 13, gen_loss = 0.8569021125220591, disc_loss = 0.06353886705215296
Trained batch 720 in epoch 13, gen_loss = 0.8567708855115094, disc_loss = 0.06352325519882711
Trained batch 721 in epoch 13, gen_loss = 0.8563661860544596, disc_loss = 0.06356999351658504
Trained batch 722 in epoch 13, gen_loss = 0.8563096615206321, disc_loss = 0.06352854816160612
Trained batch 723 in epoch 13, gen_loss = 0.8569268600305141, disc_loss = 0.06354821483972509
Trained batch 724 in epoch 13, gen_loss = 0.856591865070935, disc_loss = 0.0636111857902644
Trained batch 725 in epoch 13, gen_loss = 0.8572335563004838, disc_loss = 0.06360690897399914
Trained batch 726 in epoch 13, gen_loss = 0.8572301011547918, disc_loss = 0.06355335358261263
Trained batch 727 in epoch 13, gen_loss = 0.8571965456582032, disc_loss = 0.06351294003972006
Trained batch 728 in epoch 13, gen_loss = 0.8570789498147977, disc_loss = 0.06347922530901633
Trained batch 729 in epoch 13, gen_loss = 0.8568348355080984, disc_loss = 0.06353314662645634
Trained batch 730 in epoch 13, gen_loss = 0.8570740198061665, disc_loss = 0.06357303364508149
Trained batch 731 in epoch 13, gen_loss = 0.8576562269056429, disc_loss = 0.06360949875972656
Trained batch 732 in epoch 13, gen_loss = 0.8577208246979837, disc_loss = 0.06358376674742869
Trained batch 733 in epoch 13, gen_loss = 0.8572901306668809, disc_loss = 0.06392566401737283
Trained batch 734 in epoch 13, gen_loss = 0.8575157909571719, disc_loss = 0.06387439194091019
Trained batch 735 in epoch 13, gen_loss = 0.8576498449901524, disc_loss = 0.06391919637415254
Trained batch 736 in epoch 13, gen_loss = 0.8576918095956826, disc_loss = 0.06398703262343841
Trained batch 737 in epoch 13, gen_loss = 0.8575184892428923, disc_loss = 0.06407594145023261
Trained batch 738 in epoch 13, gen_loss = 0.8570931209037043, disc_loss = 0.06414954889885809
Trained batch 739 in epoch 13, gen_loss = 0.8570646148678419, disc_loss = 0.06415294070816221
Trained batch 740 in epoch 13, gen_loss = 0.8573818478265754, disc_loss = 0.06412049229401345
Trained batch 741 in epoch 13, gen_loss = 0.8574998856313788, disc_loss = 0.06407799203553792
Trained batch 742 in epoch 13, gen_loss = 0.8574686917209369, disc_loss = 0.06404863280704193
Trained batch 743 in epoch 13, gen_loss = 0.8572880989841877, disc_loss = 0.06402945979961484
Trained batch 744 in epoch 13, gen_loss = 0.8570074523455344, disc_loss = 0.06408531076568585
Trained batch 745 in epoch 13, gen_loss = 0.8571818682287717, disc_loss = 0.06407315255362471
Trained batch 746 in epoch 13, gen_loss = 0.8575154728439438, disc_loss = 0.0640823005105168
Trained batch 747 in epoch 13, gen_loss = 0.8578082613527456, disc_loss = 0.06402015638037181
Trained batch 748 in epoch 13, gen_loss = 0.8577512754537713, disc_loss = 0.06405496711498287
Trained batch 749 in epoch 13, gen_loss = 0.8578807308276495, disc_loss = 0.06401529125186305
Trained batch 750 in epoch 13, gen_loss = 0.8578026975280594, disc_loss = 0.06403143689862283
Trained batch 751 in epoch 13, gen_loss = 0.8580249411232294, disc_loss = 0.06400058374732752
Trained batch 752 in epoch 13, gen_loss = 0.857796679573705, disc_loss = 0.06405377674756317
Trained batch 753 in epoch 13, gen_loss = 0.8575586855648684, disc_loss = 0.06405952314732581
Trained batch 754 in epoch 13, gen_loss = 0.8576765103450674, disc_loss = 0.0641309034825605
Trained batch 755 in epoch 13, gen_loss = 0.8581351012228027, disc_loss = 0.06441935763642606
Trained batch 756 in epoch 13, gen_loss = 0.8576339549401005, disc_loss = 0.06456349011390043
Trained batch 757 in epoch 13, gen_loss = 0.8576271646412822, disc_loss = 0.06456837009719639
Trained batch 758 in epoch 13, gen_loss = 0.8577074745427007, disc_loss = 0.06455482300358661
Trained batch 759 in epoch 13, gen_loss = 0.8578093587567932, disc_loss = 0.06451320185779447
Trained batch 760 in epoch 13, gen_loss = 0.8576482243042894, disc_loss = 0.06447785077787907
Trained batch 761 in epoch 13, gen_loss = 0.8572058970221071, disc_loss = 0.06466506737690135
Trained batch 762 in epoch 13, gen_loss = 0.8568904666256936, disc_loss = 0.06467224366848173
Trained batch 763 in epoch 13, gen_loss = 0.8571222649974973, disc_loss = 0.06463527859186179
Trained batch 764 in epoch 13, gen_loss = 0.8571260069709977, disc_loss = 0.06459593367549817
Trained batch 765 in epoch 13, gen_loss = 0.857256145841459, disc_loss = 0.0645325621620414
Trained batch 766 in epoch 13, gen_loss = 0.8571492754496061, disc_loss = 0.06451333349696912
Trained batch 767 in epoch 13, gen_loss = 0.8573320655462643, disc_loss = 0.06445053802417533
Trained batch 768 in epoch 13, gen_loss = 0.8572694531342763, disc_loss = 0.06440432379700448
Trained batch 769 in epoch 13, gen_loss = 0.8572216880011868, disc_loss = 0.06435476963698573
Trained batch 770 in epoch 13, gen_loss = 0.8572266829307595, disc_loss = 0.06430799423036891
Trained batch 771 in epoch 13, gen_loss = 0.8568196326803049, disc_loss = 0.06435339399697887
Trained batch 772 in epoch 13, gen_loss = 0.8569767480525748, disc_loss = 0.06429655656741419
Trained batch 773 in epoch 13, gen_loss = 0.8570024773131969, disc_loss = 0.06425246692175955
Trained batch 774 in epoch 13, gen_loss = 0.8569839865161527, disc_loss = 0.06419585664486212
Trained batch 775 in epoch 13, gen_loss = 0.8569556683609166, disc_loss = 0.0641889754285527
Trained batch 776 in epoch 13, gen_loss = 0.8569642145047623, disc_loss = 0.06415983150500991
Trained batch 777 in epoch 13, gen_loss = 0.8568982182401005, disc_loss = 0.06417621043989565
Trained batch 778 in epoch 13, gen_loss = 0.8568723854418744, disc_loss = 0.0643681512532256
Trained batch 779 in epoch 13, gen_loss = 0.8569905972633607, disc_loss = 0.06430227427134434
Trained batch 780 in epoch 13, gen_loss = 0.8565580274780947, disc_loss = 0.06457342445151583
Trained batch 781 in epoch 13, gen_loss = 0.8565363968577226, disc_loss = 0.06461365523038294
Trained batch 782 in epoch 13, gen_loss = 0.8566141473379172, disc_loss = 0.06456574514486838
Trained batch 783 in epoch 13, gen_loss = 0.8568767744819729, disc_loss = 0.06452507832104207
Trained batch 784 in epoch 13, gen_loss = 0.857263022091738, disc_loss = 0.06448003511318261
Trained batch 785 in epoch 13, gen_loss = 0.8570882588549121, disc_loss = 0.06450517129795223
Trained batch 786 in epoch 13, gen_loss = 0.8569942882433629, disc_loss = 0.06445978031099657
Trained batch 787 in epoch 13, gen_loss = 0.8572400669155992, disc_loss = 0.06450294905760548
Trained batch 788 in epoch 13, gen_loss = 0.8575512311304477, disc_loss = 0.06443608879832921
Trained batch 789 in epoch 13, gen_loss = 0.8574108708508407, disc_loss = 0.06441715542592485
Testing Epoch 13
Training Epoch 14
Trained batch 0 in epoch 14, gen_loss = 0.5692318677902222, disc_loss = 0.09755831211805344
Trained batch 1 in epoch 14, gen_loss = 0.740626871585846, disc_loss = 0.05746000073850155
Trained batch 2 in epoch 14, gen_loss = 0.8408938646316528, disc_loss = 0.07254496589303017
Trained batch 3 in epoch 14, gen_loss = 0.838360995054245, disc_loss = 0.06225715670734644
Trained batch 4 in epoch 14, gen_loss = 0.8720002412796021, disc_loss = 0.05214574187994003
Trained batch 5 in epoch 14, gen_loss = 0.8558709919452667, disc_loss = 0.04745433914164702
Trained batch 6 in epoch 14, gen_loss = 0.8692380615643093, disc_loss = 0.049919024642024724
Trained batch 7 in epoch 14, gen_loss = 0.8332431092858315, disc_loss = 0.05904743308201432
Trained batch 8 in epoch 14, gen_loss = 0.84267701043023, disc_loss = 0.0555362676580747
Trained batch 9 in epoch 14, gen_loss = 0.8605309963226319, disc_loss = 0.05979294553399086
Trained batch 10 in epoch 14, gen_loss = 0.8349308317357843, disc_loss = 0.060848998752507294
Trained batch 11 in epoch 14, gen_loss = 0.8417644600073496, disc_loss = 0.05753975873813033
Trained batch 12 in epoch 14, gen_loss = 0.8586673094676092, disc_loss = 0.054364634391206965
Trained batch 13 in epoch 14, gen_loss = 0.8452663336481366, disc_loss = 0.054232802375086715
Trained batch 14 in epoch 14, gen_loss = 0.8423646132151286, disc_loss = 0.053266553208231926
Trained batch 15 in epoch 14, gen_loss = 0.866370216012001, disc_loss = 0.06291498534847051
Trained batch 16 in epoch 14, gen_loss = 0.8510237266035641, disc_loss = 0.06651771912241683
Trained batch 17 in epoch 14, gen_loss = 0.8490463131003909, disc_loss = 0.06879972883810599
Trained batch 18 in epoch 14, gen_loss = 0.8402288493357206, disc_loss = 0.06941424241583598
Trained batch 19 in epoch 14, gen_loss = 0.8357511788606644, disc_loss = 0.06743968017399311
Trained batch 20 in epoch 14, gen_loss = 0.8469312900588626, disc_loss = 0.06515566774067424
Trained batch 21 in epoch 14, gen_loss = 0.8471592231230303, disc_loss = 0.06278365528718992
Trained batch 22 in epoch 14, gen_loss = 0.8553833132204802, disc_loss = 0.06048310171488835
Trained batch 23 in epoch 14, gen_loss = 0.8535983686645826, disc_loss = 0.059058950010997556
Trained batch 24 in epoch 14, gen_loss = 0.8530220580101013, disc_loss = 0.05836409036070109
Trained batch 25 in epoch 14, gen_loss = 0.8540969284681174, disc_loss = 0.0577961656694802
Trained batch 26 in epoch 14, gen_loss = 0.8523053968394244, disc_loss = 0.056738182040000404
Trained batch 27 in epoch 14, gen_loss = 0.861142709851265, disc_loss = 0.06058922273639057
Trained batch 28 in epoch 14, gen_loss = 0.8615543862869, disc_loss = 0.05989394038273343
Trained batch 29 in epoch 14, gen_loss = 0.8579714735349019, disc_loss = 0.059905915055423975
Trained batch 30 in epoch 14, gen_loss = 0.8541458152955578, disc_loss = 0.060362643862683925
Trained batch 31 in epoch 14, gen_loss = 0.8627355732023716, disc_loss = 0.061074061872204766
Trained batch 32 in epoch 14, gen_loss = 0.8552192196701512, disc_loss = 0.06170428372129346
Trained batch 33 in epoch 14, gen_loss = 0.8525000740500057, disc_loss = 0.061847042374532014
Trained batch 34 in epoch 14, gen_loss = 0.8531439747129168, disc_loss = 0.06132420139121158
Trained batch 35 in epoch 14, gen_loss = 0.854863241314888, disc_loss = 0.06035409844480455
Trained batch 36 in epoch 14, gen_loss = 0.8482349192773974, disc_loss = 0.06310206951221099
Trained batch 37 in epoch 14, gen_loss = 0.8517015184226789, disc_loss = 0.06208343129899157
Trained batch 38 in epoch 14, gen_loss = 0.8524861427453848, disc_loss = 0.06086981606980165
Trained batch 39 in epoch 14, gen_loss = 0.845936757326126, disc_loss = 0.06173167717643082
Trained batch 40 in epoch 14, gen_loss = 0.8488177686202817, disc_loss = 0.061030908010718296
Trained batch 41 in epoch 14, gen_loss = 0.8494853079319, disc_loss = 0.059961107648199514
Trained batch 42 in epoch 14, gen_loss = 0.849941048511239, disc_loss = 0.06004962494033714
Trained batch 43 in epoch 14, gen_loss = 0.8431470881808888, disc_loss = 0.06282633843577722
Trained batch 44 in epoch 14, gen_loss = 0.8511687358220418, disc_loss = 0.06282636866801315
Trained batch 45 in epoch 14, gen_loss = 0.8572564358296602, disc_loss = 0.06302892072531192
Trained batch 46 in epoch 14, gen_loss = 0.8554937991690128, disc_loss = 0.062260258229489024
Trained batch 47 in epoch 14, gen_loss = 0.8506337354580561, disc_loss = 0.06304900581017137
Trained batch 48 in epoch 14, gen_loss = 0.8518344553149476, disc_loss = 0.0620772440594678
Trained batch 49 in epoch 14, gen_loss = 0.8472416603565216, disc_loss = 0.06248903322964907
Trained batch 50 in epoch 14, gen_loss = 0.8495719444517996, disc_loss = 0.06390511744893064
Trained batch 51 in epoch 14, gen_loss = 0.8552915740471619, disc_loss = 0.06389545409295422
Trained batch 52 in epoch 14, gen_loss = 0.8525108807491806, disc_loss = 0.06330317163945369
Trained batch 53 in epoch 14, gen_loss = 0.8496334585878584, disc_loss = 0.06284324172884226
Trained batch 54 in epoch 14, gen_loss = 0.8495899959044023, disc_loss = 0.06217670071531426
Trained batch 55 in epoch 14, gen_loss = 0.8491535122905459, disc_loss = 0.061896695189976265
Trained batch 56 in epoch 14, gen_loss = 0.8507806616916991, disc_loss = 0.06179547626851944
Trained batch 57 in epoch 14, gen_loss = 0.8482801102358719, disc_loss = 0.06203895694865235
Trained batch 58 in epoch 14, gen_loss = 0.849527186256344, disc_loss = 0.0612577519111209
Trained batch 59 in epoch 14, gen_loss = 0.8496659457683563, disc_loss = 0.060552306255946556
Trained batch 60 in epoch 14, gen_loss = 0.8458443801911151, disc_loss = 0.06001123092824318
Trained batch 61 in epoch 14, gen_loss = 0.8442848036366124, disc_loss = 0.059848721259303635
Trained batch 62 in epoch 14, gen_loss = 0.8499825379205128, disc_loss = 0.05921316667208596
Trained batch 63 in epoch 14, gen_loss = 0.8518489627167583, disc_loss = 0.05851061150315218
Trained batch 64 in epoch 14, gen_loss = 0.8509575871320871, disc_loss = 0.05791253874508234
Trained batch 65 in epoch 14, gen_loss = 0.8531947587475632, disc_loss = 0.05715716534265966
Trained batch 66 in epoch 14, gen_loss = 0.8527493396801735, disc_loss = 0.05655984335870885
Trained batch 67 in epoch 14, gen_loss = 0.8561814909472185, disc_loss = 0.05615995947600288
Trained batch 68 in epoch 14, gen_loss = 0.8540494424709375, disc_loss = 0.05617142892510131
Trained batch 69 in epoch 14, gen_loss = 0.8583580204418727, disc_loss = 0.05632482695260218
Trained batch 70 in epoch 14, gen_loss = 0.8585175586418367, disc_loss = 0.055838663891797334
Trained batch 71 in epoch 14, gen_loss = 0.8572291028168466, disc_loss = 0.05553664678397278
Trained batch 72 in epoch 14, gen_loss = 0.8597224175113521, disc_loss = 0.0551266119343369
Trained batch 73 in epoch 14, gen_loss = 0.859801854636218, disc_loss = 0.05458979173940984
Trained batch 74 in epoch 14, gen_loss = 0.8668986733754476, disc_loss = 0.054407534164687
Trained batch 75 in epoch 14, gen_loss = 0.8667152398510983, disc_loss = 0.05402002283862155
Trained batch 76 in epoch 14, gen_loss = 0.8689033412314081, disc_loss = 0.05362762463605636
Trained batch 77 in epoch 14, gen_loss = 0.8674189417790144, disc_loss = 0.05317780159366054
Trained batch 78 in epoch 14, gen_loss = 0.8677238950246497, disc_loss = 0.05265453582794606
Trained batch 79 in epoch 14, gen_loss = 0.8674556359648704, disc_loss = 0.05222825251985341
Trained batch 80 in epoch 14, gen_loss = 0.8677821144645597, disc_loss = 0.05174743378373944
Trained batch 81 in epoch 14, gen_loss = 0.8670613613070511, disc_loss = 0.051379052797196116
Trained batch 82 in epoch 14, gen_loss = 0.8703875749944204, disc_loss = 0.05168134531746787
Trained batch 83 in epoch 14, gen_loss = 0.8685746512242726, disc_loss = 0.05157004045100794
Trained batch 84 in epoch 14, gen_loss = 0.8683150067048915, disc_loss = 0.051201200846801784
Trained batch 85 in epoch 14, gen_loss = 0.8702638911646466, disc_loss = 0.05068903661679563
Trained batch 86 in epoch 14, gen_loss = 0.8707286667549747, disc_loss = 0.050290439647204914
Trained batch 87 in epoch 14, gen_loss = 0.8704909668727354, disc_loss = 0.04989235736535524
Trained batch 88 in epoch 14, gen_loss = 0.8726657414704226, disc_loss = 0.049482588337085555
Trained batch 89 in epoch 14, gen_loss = 0.8723217341634962, disc_loss = 0.049326158713342415
Trained batch 90 in epoch 14, gen_loss = 0.8752023112642896, disc_loss = 0.04894843336788344
Trained batch 91 in epoch 14, gen_loss = 0.87468472511872, disc_loss = 0.04885973319229062
Trained batch 92 in epoch 14, gen_loss = 0.8771457005572575, disc_loss = 0.04861332539729373
Trained batch 93 in epoch 14, gen_loss = 0.876887192117407, disc_loss = 0.04846502011740937
Trained batch 94 in epoch 14, gen_loss = 0.8778662756869667, disc_loss = 0.04813424426768171
Trained batch 95 in epoch 14, gen_loss = 0.880432765930891, disc_loss = 0.04790435009150921
Trained batch 96 in epoch 14, gen_loss = 0.8818153732830716, disc_loss = 0.04750266235763418
Trained batch 97 in epoch 14, gen_loss = 0.8832786995537427, disc_loss = 0.04709376739718172
Trained batch 98 in epoch 14, gen_loss = 0.8817511465814378, disc_loss = 0.04708142250287111
Trained batch 99 in epoch 14, gen_loss = 0.8806300693750382, disc_loss = 0.04688496918417513
Trained batch 100 in epoch 14, gen_loss = 0.8827496607704918, disc_loss = 0.04659203422431013
Trained batch 101 in epoch 14, gen_loss = 0.8878816675906088, disc_loss = 0.04673886822317453
Trained batch 102 in epoch 14, gen_loss = 0.8881342445762412, disc_loss = 0.046400664781120794
Trained batch 103 in epoch 14, gen_loss = 0.8871709480881691, disc_loss = 0.04615751703162319
Trained batch 104 in epoch 14, gen_loss = 0.8874376507032485, disc_loss = 0.04591092150658369
Trained batch 105 in epoch 14, gen_loss = 0.888995665986583, disc_loss = 0.04555411778284975
Trained batch 106 in epoch 14, gen_loss = 0.8892874589590268, disc_loss = 0.04533250568103846
Trained batch 107 in epoch 14, gen_loss = 0.8911304832608612, disc_loss = 0.0451831877041884
Trained batch 108 in epoch 14, gen_loss = 0.8913339031945675, disc_loss = 0.04486084344087664
Trained batch 109 in epoch 14, gen_loss = 0.8925616367296739, disc_loss = 0.04457928856665438
Trained batch 110 in epoch 14, gen_loss = 0.8945888801737949, disc_loss = 0.04438610708861201
Trained batch 111 in epoch 14, gen_loss = 0.894559060888631, disc_loss = 0.04464361901461546
Trained batch 112 in epoch 14, gen_loss = 0.8953952420074328, disc_loss = 0.04444798542005298
Trained batch 113 in epoch 14, gen_loss = 0.8936694698375568, disc_loss = 0.0448000516513722
Trained batch 114 in epoch 14, gen_loss = 0.8969584667164346, disc_loss = 0.044901406230485955
Trained batch 115 in epoch 14, gen_loss = 0.8967946176898891, disc_loss = 0.044583932665208804
Trained batch 116 in epoch 14, gen_loss = 0.8971972628536388, disc_loss = 0.04426752891725837
Trained batch 117 in epoch 14, gen_loss = 0.8982212614204924, disc_loss = 0.04397267631602363
Trained batch 118 in epoch 14, gen_loss = 0.89763992273507, disc_loss = 0.04370483038790461
Trained batch 119 in epoch 14, gen_loss = 0.8999113549788793, disc_loss = 0.04345677812816575
Trained batch 120 in epoch 14, gen_loss = 0.9006089853846337, disc_loss = 0.043482976676973185
Trained batch 121 in epoch 14, gen_loss = 0.8994753834654073, disc_loss = 0.043453351987647965
Trained batch 122 in epoch 14, gen_loss = 0.8984137022398352, disc_loss = 0.043520828129769096
Trained batch 123 in epoch 14, gen_loss = 0.8973963390434941, disc_loss = 0.043478458620337467
Trained batch 124 in epoch 14, gen_loss = 0.8987127623558044, disc_loss = 0.043404326479882
Trained batch 125 in epoch 14, gen_loss = 0.9007503413964831, disc_loss = 0.04330338138185205
Trained batch 126 in epoch 14, gen_loss = 0.9012830177630027, disc_loss = 0.043514234252186035
Trained batch 127 in epoch 14, gen_loss = 0.8983283564448357, disc_loss = 0.044672635525785154
Trained batch 128 in epoch 14, gen_loss = 0.9006072735601618, disc_loss = 0.044536163940188264
Trained batch 129 in epoch 14, gen_loss = 0.9034219714311453, disc_loss = 0.04499504240587927
Trained batch 130 in epoch 14, gen_loss = 0.9030456087971461, disc_loss = 0.044760762603654886
Trained batch 131 in epoch 14, gen_loss = 0.9023790603334253, disc_loss = 0.04458601419658711
Trained batch 132 in epoch 14, gen_loss = 0.9024166330359036, disc_loss = 0.04466274198270718
Trained batch 133 in epoch 14, gen_loss = 0.9023555552781518, disc_loss = 0.04451029402648669
Trained batch 134 in epoch 14, gen_loss = 0.9006964242016827, disc_loss = 0.04444849350041261
Trained batch 135 in epoch 14, gen_loss = 0.9017333265613107, disc_loss = 0.04436599668320816
Trained batch 136 in epoch 14, gen_loss = 0.9023987437686781, disc_loss = 0.04409216785885013
Trained batch 137 in epoch 14, gen_loss = 0.902264736700749, disc_loss = 0.04383978229083553
Trained batch 138 in epoch 14, gen_loss = 0.9019393839424462, disc_loss = 0.043616839279186165
Trained batch 139 in epoch 14, gen_loss = 0.9028116460357394, disc_loss = 0.04344051700151925
Trained batch 140 in epoch 14, gen_loss = 0.9027055679483617, disc_loss = 0.04352327628087596
Trained batch 141 in epoch 14, gen_loss = 0.9012678995938368, disc_loss = 0.04349913596647831
Trained batch 142 in epoch 14, gen_loss = 0.9027505096022066, disc_loss = 0.04340869111783959
Trained batch 143 in epoch 14, gen_loss = 0.9028443247079849, disc_loss = 0.04334316295636301
Trained batch 144 in epoch 14, gen_loss = 0.9025150364842908, disc_loss = 0.04315926169591217
Trained batch 145 in epoch 14, gen_loss = 0.9018365642795824, disc_loss = 0.043024231619137814
Trained batch 146 in epoch 14, gen_loss = 0.9016126264520243, disc_loss = 0.042862924883382864
Trained batch 147 in epoch 14, gen_loss = 0.9025591482987275, disc_loss = 0.04264621227362973
Trained batch 148 in epoch 14, gen_loss = 0.903511913830802, disc_loss = 0.04246347347874469
Trained batch 149 in epoch 14, gen_loss = 0.9055324482917786, disc_loss = 0.0424053879113247
Trained batch 150 in epoch 14, gen_loss = 0.9046548281284358, disc_loss = 0.04247996907076792
Trained batch 151 in epoch 14, gen_loss = 0.9043428654733457, disc_loss = 0.04241389575671699
Trained batch 152 in epoch 14, gen_loss = 0.9050184488296509, disc_loss = 0.0422056180644123
Trained batch 153 in epoch 14, gen_loss = 0.9074900560564809, disc_loss = 0.04213100159238395
Trained batch 154 in epoch 14, gen_loss = 0.9074495127124171, disc_loss = 0.04190428496728982
Trained batch 155 in epoch 14, gen_loss = 0.9074363223253152, disc_loss = 0.041747198338644244
Trained batch 156 in epoch 14, gen_loss = 0.9067855948095869, disc_loss = 0.041541883247388396
Trained batch 157 in epoch 14, gen_loss = 0.9066092224815224, disc_loss = 0.04140224914903505
Trained batch 158 in epoch 14, gen_loss = 0.9064557278681101, disc_loss = 0.04131933047477179
Trained batch 159 in epoch 14, gen_loss = 0.9075620856136084, disc_loss = 0.041220513498410584
Trained batch 160 in epoch 14, gen_loss = 0.9065205499252177, disc_loss = 0.041075211110877696
Trained batch 161 in epoch 14, gen_loss = 0.9061223934462042, disc_loss = 0.04091163818942912
Trained batch 162 in epoch 14, gen_loss = 0.905793537757148, disc_loss = 0.04078251105144711
Trained batch 163 in epoch 14, gen_loss = 0.904237242370117, disc_loss = 0.04079073967366684
Trained batch 164 in epoch 14, gen_loss = 0.9028632492730112, disc_loss = 0.040810840328534444
Trained batch 165 in epoch 14, gen_loss = 0.9034086411975952, disc_loss = 0.04117445921502918
Trained batch 166 in epoch 14, gen_loss = 0.9032777494299198, disc_loss = 0.04111479746992003
Trained batch 167 in epoch 14, gen_loss = 0.9034742709426653, disc_loss = 0.04098870787059977
Trained batch 168 in epoch 14, gen_loss = 0.9021111832567926, disc_loss = 0.04112856292865685
Trained batch 169 in epoch 14, gen_loss = 0.9018781037891612, disc_loss = 0.04093907687484342
Trained batch 170 in epoch 14, gen_loss = 0.9039595224703961, disc_loss = 0.04095736842558921
Trained batch 171 in epoch 14, gen_loss = 0.9038388881572458, disc_loss = 0.040869755015253674
Trained batch 172 in epoch 14, gen_loss = 0.903835325571843, disc_loss = 0.040717446627472176
Trained batch 173 in epoch 14, gen_loss = 0.9058815240859985, disc_loss = 0.04078825728047168
Trained batch 174 in epoch 14, gen_loss = 0.9061365284238543, disc_loss = 0.04066958193268095
Trained batch 175 in epoch 14, gen_loss = 0.9047827083956111, disc_loss = 0.0408389887095175
Trained batch 176 in epoch 14, gen_loss = 0.9035559889286925, disc_loss = 0.04099001933289113
Trained batch 177 in epoch 14, gen_loss = 0.9034802796465627, disc_loss = 0.04185127266002505
Trained batch 178 in epoch 14, gen_loss = 0.9036878640425272, disc_loss = 0.0417538496702077
Trained batch 179 in epoch 14, gen_loss = 0.9039076540205214, disc_loss = 0.041633412811077304
Trained batch 180 in epoch 14, gen_loss = 0.9022035117966035, disc_loss = 0.04194429272898982
Trained batch 181 in epoch 14, gen_loss = 0.900944485441669, disc_loss = 0.04195638683593863
Trained batch 182 in epoch 14, gen_loss = 0.9015865036047221, disc_loss = 0.04193490188914896
Trained batch 183 in epoch 14, gen_loss = 0.9012603568642036, disc_loss = 0.041832505330524364
Trained batch 184 in epoch 14, gen_loss = 0.8991160737501608, disc_loss = 0.04236024228503575
Trained batch 185 in epoch 14, gen_loss = 0.9013929799679787, disc_loss = 0.04312242788853504
Trained batch 186 in epoch 14, gen_loss = 0.902078649895714, disc_loss = 0.04339778452195267
Trained batch 187 in epoch 14, gen_loss = 0.9004950108046227, disc_loss = 0.04365899826974628
Trained batch 188 in epoch 14, gen_loss = 0.9003655737039273, disc_loss = 0.043575040986219414
Trained batch 189 in epoch 14, gen_loss = 0.8996874407718056, disc_loss = 0.04360813858281625
Trained batch 190 in epoch 14, gen_loss = 0.8995079828806573, disc_loss = 0.0447580030977882
Trained batch 191 in epoch 14, gen_loss = 0.899756332548956, disc_loss = 0.044966962528026976
Trained batch 192 in epoch 14, gen_loss = 0.8989335208976824, disc_loss = 0.04511782784651907
Trained batch 193 in epoch 14, gen_loss = 0.8980951542706833, disc_loss = 0.04511123456867393
Trained batch 194 in epoch 14, gen_loss = 0.8963775243514623, disc_loss = 0.04553878833659184
Trained batch 195 in epoch 14, gen_loss = 0.8978887249012383, disc_loss = 0.04706379595421711
Trained batch 196 in epoch 14, gen_loss = 0.8974897885685644, disc_loss = 0.04716959935116587
Trained batch 197 in epoch 14, gen_loss = 0.8966309900837716, disc_loss = 0.047210642324779374
Trained batch 198 in epoch 14, gen_loss = 0.8969926366853953, disc_loss = 0.047129144405375176
Trained batch 199 in epoch 14, gen_loss = 0.8964558699727059, disc_loss = 0.0470392197649926
Trained batch 200 in epoch 14, gen_loss = 0.8959033246064068, disc_loss = 0.04702381340240068
Trained batch 201 in epoch 14, gen_loss = 0.8946011101845468, disc_loss = 0.04720663602952615
Trained batch 202 in epoch 14, gen_loss = 0.8940395768640077, disc_loss = 0.047725463799875356
Trained batch 203 in epoch 14, gen_loss = 0.8941327163986131, disc_loss = 0.047629970290205055
Trained batch 204 in epoch 14, gen_loss = 0.8934809888281473, disc_loss = 0.04750423533160512
Trained batch 205 in epoch 14, gen_loss = 0.8914484822923697, disc_loss = 0.04792864266240481
Trained batch 206 in epoch 14, gen_loss = 0.8924140586081334, disc_loss = 0.047969106368828514
Trained batch 207 in epoch 14, gen_loss = 0.89211670237665, disc_loss = 0.047906709082711205
Trained batch 208 in epoch 14, gen_loss = 0.891847229317615, disc_loss = 0.04804435197673916
Trained batch 209 in epoch 14, gen_loss = 0.8909356149889174, disc_loss = 0.04812423193028995
Trained batch 210 in epoch 14, gen_loss = 0.8915867798418795, disc_loss = 0.04794228270261491
Trained batch 211 in epoch 14, gen_loss = 0.891258863486209, disc_loss = 0.047772314654276615
Trained batch 212 in epoch 14, gen_loss = 0.8908970570060569, disc_loss = 0.047726595616886316
Trained batch 213 in epoch 14, gen_loss = 0.8907619983514893, disc_loss = 0.04797333833178349
Trained batch 214 in epoch 14, gen_loss = 0.8903349317783533, disc_loss = 0.0478680519257174
Trained batch 215 in epoch 14, gen_loss = 0.8905476722176429, disc_loss = 0.047751739922979916
Trained batch 216 in epoch 14, gen_loss = 0.8929422598005989, disc_loss = 0.049242060880438525
Trained batch 217 in epoch 14, gen_loss = 0.8921776543790048, disc_loss = 0.049290355064248274
Trained batch 218 in epoch 14, gen_loss = 0.8906282016403599, disc_loss = 0.050151438209904385
Trained batch 219 in epoch 14, gen_loss = 0.8909353720870885, disc_loss = 0.05000445322048935
Trained batch 220 in epoch 14, gen_loss = 0.8915757009616265, disc_loss = 0.049989730330411666
Trained batch 221 in epoch 14, gen_loss = 0.8917377769678563, disc_loss = 0.04994910810277
Trained batch 222 in epoch 14, gen_loss = 0.8906851190355326, disc_loss = 0.050239116011914116
Trained batch 223 in epoch 14, gen_loss = 0.8901072209700942, disc_loss = 0.05017064050272373
Trained batch 224 in epoch 14, gen_loss = 0.889300096432368, disc_loss = 0.05056583925253815
Trained batch 225 in epoch 14, gen_loss = 0.8879437716925038, disc_loss = 0.05116923849831904
Trained batch 226 in epoch 14, gen_loss = 0.888551307275957, disc_loss = 0.05120323684542452
Trained batch 227 in epoch 14, gen_loss = 0.8889186279031268, disc_loss = 0.05102144644121852
Trained batch 228 in epoch 14, gen_loss = 0.8895791353877455, disc_loss = 0.05103656862695665
Trained batch 229 in epoch 14, gen_loss = 0.8897586030804593, disc_loss = 0.05085993090077587
Trained batch 230 in epoch 14, gen_loss = 0.8888836083732126, disc_loss = 0.05078479105776006
Trained batch 231 in epoch 14, gen_loss = 0.8884810837435311, disc_loss = 0.05082544440339352
Trained batch 232 in epoch 14, gen_loss = 0.8891416518217504, disc_loss = 0.05072170517571239
Trained batch 233 in epoch 14, gen_loss = 0.8889533837891033, disc_loss = 0.05099090057401321
Trained batch 234 in epoch 14, gen_loss = 0.8888635025379505, disc_loss = 0.050898948914193096
Trained batch 235 in epoch 14, gen_loss = 0.8879892875329923, disc_loss = 0.05095785486874944
Trained batch 236 in epoch 14, gen_loss = 0.8877553269581453, disc_loss = 0.05087575819421921
Trained batch 237 in epoch 14, gen_loss = 0.8884827222894219, disc_loss = 0.05104642649408148
Trained batch 238 in epoch 14, gen_loss = 0.8881768311167362, disc_loss = 0.051112785374270324
Trained batch 239 in epoch 14, gen_loss = 0.8873203872392575, disc_loss = 0.051561840002735455
Trained batch 240 in epoch 14, gen_loss = 0.8861443114725881, disc_loss = 0.0517902911265856
Trained batch 241 in epoch 14, gen_loss = 0.8871183290708163, disc_loss = 0.051812729205597534
Trained batch 242 in epoch 14, gen_loss = 0.8873798360304578, disc_loss = 0.051672214910449314
Trained batch 243 in epoch 14, gen_loss = 0.88726529149247, disc_loss = 0.05159575672301113
Trained batch 244 in epoch 14, gen_loss = 0.8865874851236538, disc_loss = 0.0517057583344226
Trained batch 245 in epoch 14, gen_loss = 0.8878615596672383, disc_loss = 0.051580724427552245
Trained batch 246 in epoch 14, gen_loss = 0.8881702506349154, disc_loss = 0.05176979927006762
Trained batch 247 in epoch 14, gen_loss = 0.8872198473301626, disc_loss = 0.05184639265550481
Trained batch 248 in epoch 14, gen_loss = 0.8876735925913815, disc_loss = 0.05166630536863902
Trained batch 249 in epoch 14, gen_loss = 0.8859864856004716, disc_loss = 0.05243320340104401
Trained batch 250 in epoch 14, gen_loss = 0.8871104177013337, disc_loss = 0.05240371876926833
Trained batch 251 in epoch 14, gen_loss = 0.887845584915744, disc_loss = 0.05245168661026077
Trained batch 252 in epoch 14, gen_loss = 0.887892601400496, disc_loss = 0.05227429997139121
Trained batch 253 in epoch 14, gen_loss = 0.8871914231636393, disc_loss = 0.05234777508120192
Trained batch 254 in epoch 14, gen_loss = 0.8863068654256708, disc_loss = 0.05237093395644835
Trained batch 255 in epoch 14, gen_loss = 0.8858655436197296, disc_loss = 0.052459486500083585
Trained batch 256 in epoch 14, gen_loss = 0.885392654382765, disc_loss = 0.05240543198442007
Trained batch 257 in epoch 14, gen_loss = 0.8863409116517665, disc_loss = 0.052348036898386685
Trained batch 258 in epoch 14, gen_loss = 0.8864369112782496, disc_loss = 0.05226834924014206
Trained batch 259 in epoch 14, gen_loss = 0.8858042310063655, disc_loss = 0.05220452916915887
Trained batch 260 in epoch 14, gen_loss = 0.8851981646028059, disc_loss = 0.052111760640010184
Trained batch 261 in epoch 14, gen_loss = 0.8856201082013035, disc_loss = 0.05194422992422665
Trained batch 262 in epoch 14, gen_loss = 0.8850321875098993, disc_loss = 0.051892946968244626
Trained batch 263 in epoch 14, gen_loss = 0.8849826289171522, disc_loss = 0.05186331478321473
Trained batch 264 in epoch 14, gen_loss = 0.887258598602043, disc_loss = 0.052055189914931105
Trained batch 265 in epoch 14, gen_loss = 0.887067605790339, disc_loss = 0.052075132925441504
Trained batch 266 in epoch 14, gen_loss = 0.8863841515132104, disc_loss = 0.05204193740699454
Trained batch 267 in epoch 14, gen_loss = 0.8864800154940405, disc_loss = 0.05220166905331356
Trained batch 268 in epoch 14, gen_loss = 0.8859799596235212, disc_loss = 0.05217354221366429
Trained batch 269 in epoch 14, gen_loss = 0.886602285725099, disc_loss = 0.05200570597382331
Trained batch 270 in epoch 14, gen_loss = 0.8865301401192852, disc_loss = 0.05195012833490088
Trained batch 271 in epoch 14, gen_loss = 0.8863674786818379, disc_loss = 0.051785100907128415
Trained batch 272 in epoch 14, gen_loss = 0.886812095567857, disc_loss = 0.051639210492468036
Trained batch 273 in epoch 14, gen_loss = 0.8871059834304518, disc_loss = 0.051483443630587336
Trained batch 274 in epoch 14, gen_loss = 0.8865017204934901, disc_loss = 0.05143983965400945
Trained batch 275 in epoch 14, gen_loss = 0.8867141765312873, disc_loss = 0.05184678792568814
Trained batch 276 in epoch 14, gen_loss = 0.886166153509264, disc_loss = 0.051874745406869406
Trained batch 277 in epoch 14, gen_loss = 0.8851405336059255, disc_loss = 0.051839535853242594
Trained batch 278 in epoch 14, gen_loss = 0.8864631991446232, disc_loss = 0.05212882126257571
Trained batch 279 in epoch 14, gen_loss = 0.8872062909815993, disc_loss = 0.05201797203127561
Trained batch 280 in epoch 14, gen_loss = 0.8875289791631529, disc_loss = 0.05188538124983686
Trained batch 281 in epoch 14, gen_loss = 0.887354737583627, disc_loss = 0.05188627633702089
Trained batch 282 in epoch 14, gen_loss = 0.8855367855764531, disc_loss = 0.05250695092577237
Trained batch 283 in epoch 14, gen_loss = 0.8864838568047738, disc_loss = 0.05322161240955736
Trained batch 284 in epoch 14, gen_loss = 0.8861467565360822, disc_loss = 0.05323386397702914
Trained batch 285 in epoch 14, gen_loss = 0.8856702616789958, disc_loss = 0.05324964878032101
Trained batch 286 in epoch 14, gen_loss = 0.8852819537659555, disc_loss = 0.05320817475022183
Trained batch 287 in epoch 14, gen_loss = 0.8850675938237045, disc_loss = 0.0531364908820251
Trained batch 288 in epoch 14, gen_loss = 0.8862318407911742, disc_loss = 0.053102342136346035
Trained batch 289 in epoch 14, gen_loss = 0.8859261877577881, disc_loss = 0.05301192762041143
Trained batch 290 in epoch 14, gen_loss = 0.885404038982293, disc_loss = 0.053205843126766156
Trained batch 291 in epoch 14, gen_loss = 0.8862417175957601, disc_loss = 0.05369232579179057
Trained batch 292 in epoch 14, gen_loss = 0.8851423398829971, disc_loss = 0.05410974418884302
Trained batch 293 in epoch 14, gen_loss = 0.8857778830795872, disc_loss = 0.0544073779316505
Trained batch 294 in epoch 14, gen_loss = 0.8858880118798401, disc_loss = 0.05444710203683225
Trained batch 295 in epoch 14, gen_loss = 0.8853032765154903, disc_loss = 0.05450995555430701
Trained batch 296 in epoch 14, gen_loss = 0.8842468732334547, disc_loss = 0.05500076020838887
Trained batch 297 in epoch 14, gen_loss = 0.8848550876715039, disc_loss = 0.05523075167896013
Trained batch 298 in epoch 14, gen_loss = 0.8835700193177098, disc_loss = 0.05548199009069282
Trained batch 299 in epoch 14, gen_loss = 0.8830125857392946, disc_loss = 0.05559130690526217
Trained batch 300 in epoch 14, gen_loss = 0.8827915026301958, disc_loss = 0.05567362884282323
Trained batch 301 in epoch 14, gen_loss = 0.8831148349883541, disc_loss = 0.05588340850096714
Trained batch 302 in epoch 14, gen_loss = 0.8815144077189291, disc_loss = 0.05635639653378243
Trained batch 303 in epoch 14, gen_loss = 0.8822401912000618, disc_loss = 0.056306061403838134
Trained batch 304 in epoch 14, gen_loss = 0.8825256706261244, disc_loss = 0.05621031671915142
Trained batch 305 in epoch 14, gen_loss = 0.8820979157888812, disc_loss = 0.05614532586461043
Trained batch 306 in epoch 14, gen_loss = 0.8814526873030958, disc_loss = 0.056069019916452204
Trained batch 307 in epoch 14, gen_loss = 0.8811767057745488, disc_loss = 0.056110392834132466
Trained batch 308 in epoch 14, gen_loss = 0.8819652524773742, disc_loss = 0.05635554988606317
Trained batch 309 in epoch 14, gen_loss = 0.8816340399365271, disc_loss = 0.05635154331553607
Trained batch 310 in epoch 14, gen_loss = 0.8805294595538995, disc_loss = 0.056664535304130174
Trained batch 311 in epoch 14, gen_loss = 0.8799675512963381, disc_loss = 0.05678483736492359
Trained batch 312 in epoch 14, gen_loss = 0.8807090365658172, disc_loss = 0.05676396976793393
Trained batch 313 in epoch 14, gen_loss = 0.8801366828239647, disc_loss = 0.056923048275635595
Trained batch 314 in epoch 14, gen_loss = 0.8795473654118795, disc_loss = 0.05715834049153186
Trained batch 315 in epoch 14, gen_loss = 0.8797567153844652, disc_loss = 0.05701943827480596
Trained batch 316 in epoch 14, gen_loss = 0.8786486454002489, disc_loss = 0.05727583316686543
Trained batch 317 in epoch 14, gen_loss = 0.8789242047746226, disc_loss = 0.05731060317096611
Trained batch 318 in epoch 14, gen_loss = 0.878807062172217, disc_loss = 0.05724574500391242
Trained batch 319 in epoch 14, gen_loss = 0.8777984614484012, disc_loss = 0.05743572345090797
Trained batch 320 in epoch 14, gen_loss = 0.8789601254500332, disc_loss = 0.057682709030029464
Trained batch 321 in epoch 14, gen_loss = 0.8784748688802956, disc_loss = 0.05768554124211812
Trained batch 322 in epoch 14, gen_loss = 0.8776590786297624, disc_loss = 0.057793203532269036
Trained batch 323 in epoch 14, gen_loss = 0.8769932027768206, disc_loss = 0.057829429509037716
Trained batch 324 in epoch 14, gen_loss = 0.8773332954370059, disc_loss = 0.0576902667991817
Trained batch 325 in epoch 14, gen_loss = 0.8779639589823097, disc_loss = 0.05766371207203191
Trained batch 326 in epoch 14, gen_loss = 0.8780443189887825, disc_loss = 0.057515121374096985
Trained batch 327 in epoch 14, gen_loss = 0.8776328282930502, disc_loss = 0.05743918114018104
Trained batch 328 in epoch 14, gen_loss = 0.8773865832927379, disc_loss = 0.05736489594407312
Trained batch 329 in epoch 14, gen_loss = 0.8767885069955479, disc_loss = 0.05732183322508001
Trained batch 330 in epoch 14, gen_loss = 0.8765813847863062, disc_loss = 0.05730028984381668
Trained batch 331 in epoch 14, gen_loss = 0.876414242907461, disc_loss = 0.057392295027791286
Trained batch 332 in epoch 14, gen_loss = 0.8762001585852992, disc_loss = 0.0572814877849777
Trained batch 333 in epoch 14, gen_loss = 0.8766939942529816, disc_loss = 0.05730781710740112
Trained batch 334 in epoch 14, gen_loss = 0.8757548769018544, disc_loss = 0.05761425853081381
Trained batch 335 in epoch 14, gen_loss = 0.8749743340803045, disc_loss = 0.05782826827877822
Trained batch 336 in epoch 14, gen_loss = 0.8762165193918551, disc_loss = 0.05840395702579741
Trained batch 337 in epoch 14, gen_loss = 0.8780250763575707, disc_loss = 0.0585412966547611
Trained batch 338 in epoch 14, gen_loss = 0.8770285404361455, disc_loss = 0.05910060277681215
Trained batch 339 in epoch 14, gen_loss = 0.8764123968341772, disc_loss = 0.059184220585259885
Trained batch 340 in epoch 14, gen_loss = 0.8769228062496857, disc_loss = 0.059224527098424185
Trained batch 341 in epoch 14, gen_loss = 0.8764180501824931, disc_loss = 0.05920147000300039
Trained batch 342 in epoch 14, gen_loss = 0.8759505435085853, disc_loss = 0.05916219973480519
Trained batch 343 in epoch 14, gen_loss = 0.875599269863478, disc_loss = 0.059228344927379474
Trained batch 344 in epoch 14, gen_loss = 0.8756466935510221, disc_loss = 0.05915328368841522
Trained batch 345 in epoch 14, gen_loss = 0.8751268306736312, disc_loss = 0.059147796489976645
Trained batch 346 in epoch 14, gen_loss = 0.8753781932746986, disc_loss = 0.05901327282217162
Trained batch 347 in epoch 14, gen_loss = 0.8753581714184805, disc_loss = 0.058940965357108105
Trained batch 348 in epoch 14, gen_loss = 0.8749087481068335, disc_loss = 0.05894743279289764
Trained batch 349 in epoch 14, gen_loss = 0.8759077486821584, disc_loss = 0.058876244102471643
Trained batch 350 in epoch 14, gen_loss = 0.8754215222648066, disc_loss = 0.05897487035191
Trained batch 351 in epoch 14, gen_loss = 0.875270425172692, disc_loss = 0.058909543870620175
Trained batch 352 in epoch 14, gen_loss = 0.8751600618571803, disc_loss = 0.05895290377737147
Trained batch 353 in epoch 14, gen_loss = 0.8740646764215103, disc_loss = 0.059089871550947005
Trained batch 354 in epoch 14, gen_loss = 0.8739328047759096, disc_loss = 0.05905094254420887
Trained batch 355 in epoch 14, gen_loss = 0.8740747504857149, disc_loss = 0.058985966473577144
Trained batch 356 in epoch 14, gen_loss = 0.8733883315608615, disc_loss = 0.05900435395544024
Trained batch 357 in epoch 14, gen_loss = 0.8734248264708333, disc_loss = 0.05897841323297159
Trained batch 358 in epoch 14, gen_loss = 0.8729893355150409, disc_loss = 0.058962049752650236
Trained batch 359 in epoch 14, gen_loss = 0.8730146125786834, disc_loss = 0.05885112127935928
Trained batch 360 in epoch 14, gen_loss = 0.8726403004079645, disc_loss = 0.05875931069941113
Trained batch 361 in epoch 14, gen_loss = 0.8721118310044483, disc_loss = 0.058704957207767756
Trained batch 362 in epoch 14, gen_loss = 0.8726310353141186, disc_loss = 0.0587282536959291
Trained batch 363 in epoch 14, gen_loss = 0.8724771291836277, disc_loss = 0.058643998185449006
Trained batch 364 in epoch 14, gen_loss = 0.8724649142729093, disc_loss = 0.05858767971217836
Trained batch 365 in epoch 14, gen_loss = 0.8723843531693266, disc_loss = 0.05873985773415554
Trained batch 366 in epoch 14, gen_loss = 0.8724029646420024, disc_loss = 0.05864177168821485
Trained batch 367 in epoch 14, gen_loss = 0.8717613844605892, disc_loss = 0.05877875117205448
Trained batch 368 in epoch 14, gen_loss = 0.8725346368018204, disc_loss = 0.059289857075072644
Trained batch 369 in epoch 14, gen_loss = 0.8723564736746453, disc_loss = 0.059214927101306415
Trained batch 370 in epoch 14, gen_loss = 0.8720773007831162, disc_loss = 0.05920699578797761
Trained batch 371 in epoch 14, gen_loss = 0.8710582194629536, disc_loss = 0.0594598420868097
Trained batch 372 in epoch 14, gen_loss = 0.8704599513604877, disc_loss = 0.0596285511979249
Trained batch 373 in epoch 14, gen_loss = 0.8715090615385994, disc_loss = 0.06006124939017476
Trained batch 374 in epoch 14, gen_loss = 0.8718413258393606, disc_loss = 0.06002854663754503
Trained batch 375 in epoch 14, gen_loss = 0.871424830736632, disc_loss = 0.059984883993239875
Trained batch 376 in epoch 14, gen_loss = 0.8706543803689334, disc_loss = 0.060170122959579415
Trained batch 377 in epoch 14, gen_loss = 0.8704891193007666, disc_loss = 0.0600828790714442
Trained batch 378 in epoch 14, gen_loss = 0.8710709348674814, disc_loss = 0.06011134352274534
Trained batch 379 in epoch 14, gen_loss = 0.870930281203044, disc_loss = 0.059986722588196005
Trained batch 380 in epoch 14, gen_loss = 0.8711775732947773, disc_loss = 0.05990130767309329
Trained batch 381 in epoch 14, gen_loss = 0.8707938415061741, disc_loss = 0.059942082605563614
Trained batch 382 in epoch 14, gen_loss = 0.8707888788560663, disc_loss = 0.05996524371503422
Trained batch 383 in epoch 14, gen_loss = 0.8702906235897293, disc_loss = 0.059916979566575414
Trained batch 384 in epoch 14, gen_loss = 0.8704626155364049, disc_loss = 0.05978994185056586
Trained batch 385 in epoch 14, gen_loss = 0.8704686942341414, disc_loss = 0.059663680187846325
Trained batch 386 in epoch 14, gen_loss = 0.8704273080795002, disc_loss = 0.05956996645109405
Trained batch 387 in epoch 14, gen_loss = 0.8706841878208917, disc_loss = 0.059459541030180134
Trained batch 388 in epoch 14, gen_loss = 0.870710549516972, disc_loss = 0.0593620680911816
Trained batch 389 in epoch 14, gen_loss = 0.8699308964686516, disc_loss = 0.05948722793195301
Trained batch 390 in epoch 14, gen_loss = 0.8701796166579742, disc_loss = 0.05946758696142479
Trained batch 391 in epoch 14, gen_loss = 0.8699730230989505, disc_loss = 0.059373008409201414
Trained batch 392 in epoch 14, gen_loss = 0.8700903145259876, disc_loss = 0.05925546310078969
Trained batch 393 in epoch 14, gen_loss = 0.8697761963617984, disc_loss = 0.05925334101604288
Trained batch 394 in epoch 14, gen_loss = 0.8697661506224282, disc_loss = 0.05920677964422333
Trained batch 395 in epoch 14, gen_loss = 0.8697893182286108, disc_loss = 0.059155335879150894
Trained batch 396 in epoch 14, gen_loss = 0.8696854938037449, disc_loss = 0.059045162763896986
Trained batch 397 in epoch 14, gen_loss = 0.8697207022701675, disc_loss = 0.058937185826528835
Trained batch 398 in epoch 14, gen_loss = 0.8701808011173305, disc_loss = 0.058812707052204316
Trained batch 399 in epoch 14, gen_loss = 0.8698688600212335, disc_loss = 0.05874836425879039
Trained batch 400 in epoch 14, gen_loss = 0.869355022535657, disc_loss = 0.05877686592580709
Trained batch 401 in epoch 14, gen_loss = 0.8693711349175344, disc_loss = 0.05870549168683292
Trained batch 402 in epoch 14, gen_loss = 0.8686280447998946, disc_loss = 0.05884251907287586
Trained batch 403 in epoch 14, gen_loss = 0.8693979464397572, disc_loss = 0.05900913616296568
Trained batch 404 in epoch 14, gen_loss = 0.8693906246144094, disc_loss = 0.05891223523742807
Trained batch 405 in epoch 14, gen_loss = 0.8692380371205325, disc_loss = 0.05882067874812617
Trained batch 406 in epoch 14, gen_loss = 0.8692026474405565, disc_loss = 0.05874751136278967
Trained batch 407 in epoch 14, gen_loss = 0.8688144342718171, disc_loss = 0.05878959177632579
Trained batch 408 in epoch 14, gen_loss = 0.8690709755152537, disc_loss = 0.058703854512696524
Trained batch 409 in epoch 14, gen_loss = 0.8699543286387513, disc_loss = 0.05870719362709035
Trained batch 410 in epoch 14, gen_loss = 0.8696620025628965, disc_loss = 0.05868510103958983
Trained batch 411 in epoch 14, gen_loss = 0.8695914267191609, disc_loss = 0.05900894257000385
Trained batch 412 in epoch 14, gen_loss = 0.868898269411438, disc_loss = 0.05908019537304598
Trained batch 413 in epoch 14, gen_loss = 0.8686375267407744, disc_loss = 0.059070385962157794
Trained batch 414 in epoch 14, gen_loss = 0.8681359264505915, disc_loss = 0.05911843130948493
Trained batch 415 in epoch 14, gen_loss = 0.869065888154392, disc_loss = 0.05912339927901765
Trained batch 416 in epoch 14, gen_loss = 0.8688054012594749, disc_loss = 0.05904729824794604
Trained batch 417 in epoch 14, gen_loss = 0.8681966936901996, disc_loss = 0.059214991028309225
Trained batch 418 in epoch 14, gen_loss = 0.8687013064051016, disc_loss = 0.05940516182468195
Trained batch 419 in epoch 14, gen_loss = 0.8698301750279608, disc_loss = 0.059381418902471304
Trained batch 420 in epoch 14, gen_loss = 0.869894687537626, disc_loss = 0.05927837702983243
Trained batch 421 in epoch 14, gen_loss = 0.8696308828784391, disc_loss = 0.0592461567983402
Trained batch 422 in epoch 14, gen_loss = 0.8695154052676884, disc_loss = 0.05922396916204768
Trained batch 423 in epoch 14, gen_loss = 0.8692598562898501, disc_loss = 0.05914049858846789
Trained batch 424 in epoch 14, gen_loss = 0.8690958562318016, disc_loss = 0.059047348066507015
Trained batch 425 in epoch 14, gen_loss = 0.8688195552764364, disc_loss = 0.05908542249391092
Trained batch 426 in epoch 14, gen_loss = 0.8685273784245484, disc_loss = 0.059233483412375006
Trained batch 427 in epoch 14, gen_loss = 0.8688971512367792, disc_loss = 0.05916968343679349
Trained batch 428 in epoch 14, gen_loss = 0.8691184394982033, disc_loss = 0.059246195889444964
Trained batch 429 in epoch 14, gen_loss = 0.8684264261362165, disc_loss = 0.05955473084630834
Trained batch 430 in epoch 14, gen_loss = 0.8680368728953005, disc_loss = 0.05957852147212749
Trained batch 431 in epoch 14, gen_loss = 0.8680311596641938, disc_loss = 0.05957825781661086
Trained batch 432 in epoch 14, gen_loss = 0.8682739254921743, disc_loss = 0.05958876261212293
Trained batch 433 in epoch 14, gen_loss = 0.8685844877760531, disc_loss = 0.05951153318406285
Trained batch 434 in epoch 14, gen_loss = 0.8682912976577364, disc_loss = 0.059447876917433806
Trained batch 435 in epoch 14, gen_loss = 0.867419545871949, disc_loss = 0.05962559884657588
Trained batch 436 in epoch 14, gen_loss = 0.8676982189888812, disc_loss = 0.05983106061939823
Trained batch 437 in epoch 14, gen_loss = 0.8678171433950668, disc_loss = 0.0597290803548629
Trained batch 438 in epoch 14, gen_loss = 0.8669710698323261, disc_loss = 0.05990560817508905
Trained batch 439 in epoch 14, gen_loss = 0.8667506899346005, disc_loss = 0.059991736537565225
Trained batch 440 in epoch 14, gen_loss = 0.8664051344335214, disc_loss = 0.05994589312230142
Trained batch 441 in epoch 14, gen_loss = 0.866992691388497, disc_loss = 0.05994861469840066
Trained batch 442 in epoch 14, gen_loss = 0.8669372319367884, disc_loss = 0.05983771708463876
Trained batch 443 in epoch 14, gen_loss = 0.8665059433058575, disc_loss = 0.05987896864315042
Trained batch 444 in epoch 14, gen_loss = 0.8669960443893175, disc_loss = 0.05988381003667967
Trained batch 445 in epoch 14, gen_loss = 0.8669800150287525, disc_loss = 0.05996868977502757
Trained batch 446 in epoch 14, gen_loss = 0.8668178222590112, disc_loss = 0.059929978320170905
Trained batch 447 in epoch 14, gen_loss = 0.8664112754964403, disc_loss = 0.060003545360814314
Trained batch 448 in epoch 14, gen_loss = 0.8660943224063695, disc_loss = 0.06013225877806876
Trained batch 449 in epoch 14, gen_loss = 0.8668453033765157, disc_loss = 0.06053861759706504
Trained batch 450 in epoch 14, gen_loss = 0.8667963634837758, disc_loss = 0.06049940977224919
Trained batch 451 in epoch 14, gen_loss = 0.8668439640144331, disc_loss = 0.06044714530390086
Trained batch 452 in epoch 14, gen_loss = 0.8669134896848901, disc_loss = 0.060405493449732235
Trained batch 453 in epoch 14, gen_loss = 0.8667130600250765, disc_loss = 0.060432969285831646
Trained batch 454 in epoch 14, gen_loss = 0.8664277510328607, disc_loss = 0.0605200926118254
Trained batch 455 in epoch 14, gen_loss = 0.8670133262088424, disc_loss = 0.06063257701176202
Trained batch 456 in epoch 14, gen_loss = 0.8666030441123495, disc_loss = 0.06067407358727159
Trained batch 457 in epoch 14, gen_loss = 0.8664564695941309, disc_loss = 0.06066628055154919
Trained batch 458 in epoch 14, gen_loss = 0.8665097950590462, disc_loss = 0.0605821409201846
Trained batch 459 in epoch 14, gen_loss = 0.8664274284373159, disc_loss = 0.06053150638877212
Trained batch 460 in epoch 14, gen_loss = 0.8665841684682768, disc_loss = 0.06043862967313532
Trained batch 461 in epoch 14, gen_loss = 0.8663823685862801, disc_loss = 0.06040874511926753
Trained batch 462 in epoch 14, gen_loss = 0.8661854708683928, disc_loss = 0.060388753336470084
Trained batch 463 in epoch 14, gen_loss = 0.866629916403828, disc_loss = 0.06036882095765483
Trained batch 464 in epoch 14, gen_loss = 0.866684482046353, disc_loss = 0.06033006547299284
Trained batch 465 in epoch 14, gen_loss = 0.8664161198384772, disc_loss = 0.06025939860557058
Trained batch 466 in epoch 14, gen_loss = 0.8666023024910268, disc_loss = 0.06018482575121254
Trained batch 467 in epoch 14, gen_loss = 0.8659536758294473, disc_loss = 0.06023769595353808
Trained batch 468 in epoch 14, gen_loss = 0.8656300270735328, disc_loss = 0.06028263600193647
Trained batch 469 in epoch 14, gen_loss = 0.8660781776651423, disc_loss = 0.06041702059533526
Trained batch 470 in epoch 14, gen_loss = 0.8660043474215611, disc_loss = 0.060497003396866235
Trained batch 471 in epoch 14, gen_loss = 0.8657033752839444, disc_loss = 0.060586339325478335
Trained batch 472 in epoch 14, gen_loss = 0.8653752449703015, disc_loss = 0.06057899611968602
Trained batch 473 in epoch 14, gen_loss = 0.8651940074399553, disc_loss = 0.060577673355180314
Trained batch 474 in epoch 14, gen_loss = 0.8652306042219463, disc_loss = 0.060469617893625247
Trained batch 475 in epoch 14, gen_loss = 0.8654806487450079, disc_loss = 0.06041556519569688
Trained batch 476 in epoch 14, gen_loss = 0.8653284882349538, disc_loss = 0.060343268105810983
Trained batch 477 in epoch 14, gen_loss = 0.8650836178947193, disc_loss = 0.060346748067112835
Trained batch 478 in epoch 14, gen_loss = 0.8655429550899594, disc_loss = 0.06031434411680742
Trained batch 479 in epoch 14, gen_loss = 0.8657885365188122, disc_loss = 0.060282292212165585
Trained batch 480 in epoch 14, gen_loss = 0.8655330847305964, disc_loss = 0.060304875536908914
Trained batch 481 in epoch 14, gen_loss = 0.8654072143724845, disc_loss = 0.06024523308458139
Trained batch 482 in epoch 14, gen_loss = 0.8655484756821185, disc_loss = 0.06017028785158358
Trained batch 483 in epoch 14, gen_loss = 0.8660591490997755, disc_loss = 0.06024181124973611
Trained batch 484 in epoch 14, gen_loss = 0.8660640986924318, disc_loss = 0.06014949031385411
Trained batch 485 in epoch 14, gen_loss = 0.8662643097800973, disc_loss = 0.060044770381018645
Trained batch 486 in epoch 14, gen_loss = 0.8663428074525367, disc_loss = 0.059995518820417676
Trained batch 487 in epoch 14, gen_loss = 0.8655642415167856, disc_loss = 0.06013777256908934
Trained batch 488 in epoch 14, gen_loss = 0.8652927522035221, disc_loss = 0.060099106231525326
Trained batch 489 in epoch 14, gen_loss = 0.8658431481341926, disc_loss = 0.06035726770131412
Trained batch 490 in epoch 14, gen_loss = 0.8655919460560785, disc_loss = 0.060376128089820964
Trained batch 491 in epoch 14, gen_loss = 0.8654993845195305, disc_loss = 0.06067457680336798
Trained batch 492 in epoch 14, gen_loss = 0.8651474690098792, disc_loss = 0.0606473606206386
Trained batch 493 in epoch 14, gen_loss = 0.8650843263396367, disc_loss = 0.06058346582218432
Trained batch 494 in epoch 14, gen_loss = 0.8652865389380792, disc_loss = 0.060473988632285834
Trained batch 495 in epoch 14, gen_loss = 0.8649729529936467, disc_loss = 0.06047005829544017
Trained batch 496 in epoch 14, gen_loss = 0.8657936010082483, disc_loss = 0.06066745254108064
Trained batch 497 in epoch 14, gen_loss = 0.8655379116535187, disc_loss = 0.06063404300597956
Trained batch 498 in epoch 14, gen_loss = 0.8650383477459451, disc_loss = 0.06083173035851163
Trained batch 499 in epoch 14, gen_loss = 0.8657693110704422, disc_loss = 0.060916634811088444
Trained batch 500 in epoch 14, gen_loss = 0.8661211230559739, disc_loss = 0.06089602016514825
Trained batch 501 in epoch 14, gen_loss = 0.8664359957335954, disc_loss = 0.060797032388112696
Trained batch 502 in epoch 14, gen_loss = 0.865994449164237, disc_loss = 0.06095981570127352
Trained batch 503 in epoch 14, gen_loss = 0.8659600752686697, disc_loss = 0.06090248128147944
Trained batch 504 in epoch 14, gen_loss = 0.8663885735049106, disc_loss = 0.060843988415775915
Trained batch 505 in epoch 14, gen_loss = 0.8660445226275403, disc_loss = 0.06086996835638059
Trained batch 506 in epoch 14, gen_loss = 0.8664096312880281, disc_loss = 0.060807056772785306
Trained batch 507 in epoch 14, gen_loss = 0.8662524053196269, disc_loss = 0.06076041475950381
Trained batch 508 in epoch 14, gen_loss = 0.8664549057516462, disc_loss = 0.06067099351772567
Trained batch 509 in epoch 14, gen_loss = 0.8661222899661345, disc_loss = 0.06065887533968278
Trained batch 510 in epoch 14, gen_loss = 0.8662004431166528, disc_loss = 0.06056906608955793
Trained batch 511 in epoch 14, gen_loss = 0.866581394104287, disc_loss = 0.06063350391377753
Trained batch 512 in epoch 14, gen_loss = 0.8661376039187113, disc_loss = 0.06059345820297798
Trained batch 513 in epoch 14, gen_loss = 0.8659329507137551, disc_loss = 0.060563352649328425
Trained batch 514 in epoch 14, gen_loss = 0.8655427573954018, disc_loss = 0.060620997016074006
Trained batch 515 in epoch 14, gen_loss = 0.8664391126281531, disc_loss = 0.0608368063970043
Trained batch 516 in epoch 14, gen_loss = 0.8662928392393676, disc_loss = 0.06077626237476414
Trained batch 517 in epoch 14, gen_loss = 0.8662664814345165, disc_loss = 0.0607052858160183
Trained batch 518 in epoch 14, gen_loss = 0.8666245905190764, disc_loss = 0.060606482602038596
Trained batch 519 in epoch 14, gen_loss = 0.8662869668923892, disc_loss = 0.06063816525901739
Trained batch 520 in epoch 14, gen_loss = 0.865856705265631, disc_loss = 0.06065401802422218
Trained batch 521 in epoch 14, gen_loss = 0.8657552221954097, disc_loss = 0.06064277708930074
Trained batch 522 in epoch 14, gen_loss = 0.8655234936546413, disc_loss = 0.06056025818018795
Trained batch 523 in epoch 14, gen_loss = 0.8652644331446131, disc_loss = 0.06052769245650932
Trained batch 524 in epoch 14, gen_loss = 0.8653689278875079, disc_loss = 0.0607398628053211
Trained batch 525 in epoch 14, gen_loss = 0.8650335149393336, disc_loss = 0.06078521675030088
Trained batch 526 in epoch 14, gen_loss = 0.8646563073263223, disc_loss = 0.060881039307963465
Trained batch 527 in epoch 14, gen_loss = 0.8649761099932771, disc_loss = 0.060823999190082155
Trained batch 528 in epoch 14, gen_loss = 0.8642806298115303, disc_loss = 0.06101036585853321
Trained batch 529 in epoch 14, gen_loss = 0.8645133374996905, disc_loss = 0.060969667937958015
Trained batch 530 in epoch 14, gen_loss = 0.8645905698535582, disc_loss = 0.060900472013346446
Trained batch 531 in epoch 14, gen_loss = 0.8644196823575443, disc_loss = 0.060961870595644736
Trained batch 532 in epoch 14, gen_loss = 0.864315583267534, disc_loss = 0.06093399026771871
Trained batch 533 in epoch 14, gen_loss = 0.86424131395665, disc_loss = 0.06085956538242571
Trained batch 534 in epoch 14, gen_loss = 0.8643521062681608, disc_loss = 0.06077814028363362
Trained batch 535 in epoch 14, gen_loss = 0.8643326048753155, disc_loss = 0.06070421179826024
Trained batch 536 in epoch 14, gen_loss = 0.8647194087394345, disc_loss = 0.060705005016101585
Trained batch 537 in epoch 14, gen_loss = 0.8651399498313777, disc_loss = 0.06061418664721308
Trained batch 538 in epoch 14, gen_loss = 0.8645624226453353, disc_loss = 0.06075891979550165
Trained batch 539 in epoch 14, gen_loss = 0.8645157659495318, disc_loss = 0.060703318300484504
Trained batch 540 in epoch 14, gen_loss = 0.8647248343927803, disc_loss = 0.06094394432459984
Trained batch 541 in epoch 14, gen_loss = 0.8640352983536316, disc_loss = 0.061171842494986375
Trained batch 542 in epoch 14, gen_loss = 0.8643410773347535, disc_loss = 0.061228882442494345
Trained batch 543 in epoch 14, gen_loss = 0.8640967133071493, disc_loss = 0.06121773109428913
Trained batch 544 in epoch 14, gen_loss = 0.8636273291132865, disc_loss = 0.06145721951140723
Trained batch 545 in epoch 14, gen_loss = 0.8642046395893935, disc_loss = 0.06173142800005255
Trained batch 546 in epoch 14, gen_loss = 0.8636037853343831, disc_loss = 0.06180975536800499
Trained batch 547 in epoch 14, gen_loss = 0.8634683540920272, disc_loss = 0.0617489206203579
Trained batch 548 in epoch 14, gen_loss = 0.863928846865621, disc_loss = 0.061682949548346314
Trained batch 549 in epoch 14, gen_loss = 0.8637584493376992, disc_loss = 0.061661213226616385
Trained batch 550 in epoch 14, gen_loss = 0.8636388073382922, disc_loss = 0.06164099342661306
Trained batch 551 in epoch 14, gen_loss = 0.8634381127962167, disc_loss = 0.061622952148183315
Trained batch 552 in epoch 14, gen_loss = 0.8639501471200429, disc_loss = 0.061722513668872346
Trained batch 553 in epoch 14, gen_loss = 0.8638097160774878, disc_loss = 0.061739067130113554
Trained batch 554 in epoch 14, gen_loss = 0.8633109741382771, disc_loss = 0.06202198984856541
Trained batch 555 in epoch 14, gen_loss = 0.8636631873442973, disc_loss = 0.06220128897430121
Trained batch 556 in epoch 14, gen_loss = 0.863840970359542, disc_loss = 0.062121259088709926
Trained batch 557 in epoch 14, gen_loss = 0.8638937839684093, disc_loss = 0.0621120906785451
Trained batch 558 in epoch 14, gen_loss = 0.8636947557836611, disc_loss = 0.0622212439808788
Trained batch 559 in epoch 14, gen_loss = 0.8638051075594766, disc_loss = 0.06223920862123902
Trained batch 560 in epoch 14, gen_loss = 0.8633793452206779, disc_loss = 0.062424676585776495
Trained batch 561 in epoch 14, gen_loss = 0.8638966075041964, disc_loss = 0.062410139385942254
Trained batch 562 in epoch 14, gen_loss = 0.8635069688725853, disc_loss = 0.0624691671584311
Trained batch 563 in epoch 14, gen_loss = 0.8634591707101105, disc_loss = 0.062409379403932506
Trained batch 564 in epoch 14, gen_loss = 0.8635151023358371, disc_loss = 0.06250115189602418
Trained batch 565 in epoch 14, gen_loss = 0.863612344534574, disc_loss = 0.062440868272929856
Trained batch 566 in epoch 14, gen_loss = 0.8631959260035654, disc_loss = 0.06260471753250459
Trained batch 567 in epoch 14, gen_loss = 0.8630357742519446, disc_loss = 0.06269600962839601
Trained batch 568 in epoch 14, gen_loss = 0.8639032512850837, disc_loss = 0.06285255816429591
Trained batch 569 in epoch 14, gen_loss = 0.8633575283644492, disc_loss = 0.06303261522726532
Trained batch 570 in epoch 14, gen_loss = 0.8634625598135847, disc_loss = 0.06296279143391996
Trained batch 571 in epoch 14, gen_loss = 0.8629876127193025, disc_loss = 0.06302419876992389
Trained batch 572 in epoch 14, gen_loss = 0.8629426036621679, disc_loss = 0.06308171979068773
Trained batch 573 in epoch 14, gen_loss = 0.86310622501041, disc_loss = 0.06301810446711263
Trained batch 574 in epoch 14, gen_loss = 0.8627051834438159, disc_loss = 0.0631035695484151
Trained batch 575 in epoch 14, gen_loss = 0.8625001702457666, disc_loss = 0.06307410653486538
Trained batch 576 in epoch 14, gen_loss = 0.8622431858366862, disc_loss = 0.06304764759563801
Trained batch 577 in epoch 14, gen_loss = 0.8624570784271794, disc_loss = 0.06311674928131504
Trained batch 578 in epoch 14, gen_loss = 0.8628170368790833, disc_loss = 0.06306874435169812
Trained batch 579 in epoch 14, gen_loss = 0.862291079965131, disc_loss = 0.06318788206975522
Trained batch 580 in epoch 14, gen_loss = 0.862663779529565, disc_loss = 0.06312277455927993
Trained batch 581 in epoch 14, gen_loss = 0.8627522333790756, disc_loss = 0.06305388449547217
Trained batch 582 in epoch 14, gen_loss = 0.8625769497599856, disc_loss = 0.06301043070149871
Trained batch 583 in epoch 14, gen_loss = 0.8622584138831048, disc_loss = 0.06300095602079
Trained batch 584 in epoch 14, gen_loss = 0.8623939259439453, disc_loss = 0.06291340586339307
Trained batch 585 in epoch 14, gen_loss = 0.862947422693207, disc_loss = 0.06294485091934228
Trained batch 586 in epoch 14, gen_loss = 0.8625579560635647, disc_loss = 0.06298499490297836
Trained batch 587 in epoch 14, gen_loss = 0.8622809415366374, disc_loss = 0.06309704457846832
Trained batch 588 in epoch 14, gen_loss = 0.8624253546240375, disc_loss = 0.06300897129253186
Trained batch 589 in epoch 14, gen_loss = 0.8619686965215004, disc_loss = 0.06305525337772097
Trained batch 590 in epoch 14, gen_loss = 0.8616654420060353, disc_loss = 0.06314587060601629
Trained batch 591 in epoch 14, gen_loss = 0.8616121301578509, disc_loss = 0.0631977050467646
Trained batch 592 in epoch 14, gen_loss = 0.8616449577611374, disc_loss = 0.06312147774348824
Trained batch 593 in epoch 14, gen_loss = 0.8615787926346364, disc_loss = 0.06312376520555679
Trained batch 594 in epoch 14, gen_loss = 0.8613639389767366, disc_loss = 0.06312483889872537
Trained batch 595 in epoch 14, gen_loss = 0.8619207384802351, disc_loss = 0.0632735852842788
Trained batch 596 in epoch 14, gen_loss = 0.8614718336955187, disc_loss = 0.06341347747468319
Trained batch 597 in epoch 14, gen_loss = 0.8616872814586729, disc_loss = 0.06334581277348773
Trained batch 598 in epoch 14, gen_loss = 0.8618596461858097, disc_loss = 0.0632809794528133
Trained batch 599 in epoch 14, gen_loss = 0.861748381058375, disc_loss = 0.06321443750678252
Trained batch 600 in epoch 14, gen_loss = 0.8618150528972836, disc_loss = 0.06314925394623777
Trained batch 601 in epoch 14, gen_loss = 0.8619569318239079, disc_loss = 0.06310525081241102
Trained batch 602 in epoch 14, gen_loss = 0.8617039627301357, disc_loss = 0.06308275850560782
Trained batch 603 in epoch 14, gen_loss = 0.862047410859967, disc_loss = 0.06302798333861526
Trained batch 604 in epoch 14, gen_loss = 0.8616242969331662, disc_loss = 0.06306214825642749
Trained batch 605 in epoch 14, gen_loss = 0.8619028254113968, disc_loss = 0.0629885299423273
Trained batch 606 in epoch 14, gen_loss = 0.862293775136624, disc_loss = 0.06298960291947771
Trained batch 607 in epoch 14, gen_loss = 0.8620345388588152, disc_loss = 0.06294576122921794
Trained batch 608 in epoch 14, gen_loss = 0.8620384426539754, disc_loss = 0.06301743274306869
Trained batch 609 in epoch 14, gen_loss = 0.8616393078546055, disc_loss = 0.06324017441327699
Trained batch 610 in epoch 14, gen_loss = 0.8617317139029308, disc_loss = 0.06328575153501305
Trained batch 611 in epoch 14, gen_loss = 0.8615336306149664, disc_loss = 0.06330532696420704
Trained batch 612 in epoch 14, gen_loss = 0.8616164209986589, disc_loss = 0.06324747897727113
Trained batch 613 in epoch 14, gen_loss = 0.8611631809888523, disc_loss = 0.06340198049091215
Trained batch 614 in epoch 14, gen_loss = 0.8615964091890227, disc_loss = 0.06348707564629433
Trained batch 615 in epoch 14, gen_loss = 0.8615727437200484, disc_loss = 0.0634513578767731
Trained batch 616 in epoch 14, gen_loss = 0.8616882554909012, disc_loss = 0.06338657597094967
Trained batch 617 in epoch 14, gen_loss = 0.8618642492973303, disc_loss = 0.06330331859350638
Trained batch 618 in epoch 14, gen_loss = 0.8620052769033897, disc_loss = 0.06321996505942454
Trained batch 619 in epoch 14, gen_loss = 0.8615824744586021, disc_loss = 0.06341725321216209
Trained batch 620 in epoch 14, gen_loss = 0.8619453652661395, disc_loss = 0.06336438656903072
Trained batch 621 in epoch 14, gen_loss = 0.8621255986368541, disc_loss = 0.06344207986991648
Trained batch 622 in epoch 14, gen_loss = 0.8622378702148389, disc_loss = 0.06340206535099549
Trained batch 623 in epoch 14, gen_loss = 0.8620590306818485, disc_loss = 0.06335338101071568
Trained batch 624 in epoch 14, gen_loss = 0.8622543225288392, disc_loss = 0.06328824268132448
Trained batch 625 in epoch 14, gen_loss = 0.8618803509888938, disc_loss = 0.06345168071034284
Trained batch 626 in epoch 14, gen_loss = 0.8621101949773907, disc_loss = 0.06339500567161344
Trained batch 627 in epoch 14, gen_loss = 0.8623724281787872, disc_loss = 0.0633826822140343
Trained batch 628 in epoch 14, gen_loss = 0.8617222880521147, disc_loss = 0.06372910668845444
Trained batch 629 in epoch 14, gen_loss = 0.862172046634886, disc_loss = 0.06389048508264952
Trained batch 630 in epoch 14, gen_loss = 0.8616573599930233, disc_loss = 0.06388866471159146
Trained batch 631 in epoch 14, gen_loss = 0.8618293671479708, disc_loss = 0.0638515517024229
Trained batch 632 in epoch 14, gen_loss = 0.861283323493614, disc_loss = 0.06397568800090848
Trained batch 633 in epoch 14, gen_loss = 0.861215824208425, disc_loss = 0.06391276396393823
Trained batch 634 in epoch 14, gen_loss = 0.8613896846771241, disc_loss = 0.06402091060831087
Trained batch 635 in epoch 14, gen_loss = 0.8607536007492047, disc_loss = 0.06405527920919066
Trained batch 636 in epoch 14, gen_loss = 0.8611009462006987, disc_loss = 0.06414636309453092
Trained batch 637 in epoch 14, gen_loss = 0.8610347995657158, disc_loss = 0.06412852430120577
Trained batch 638 in epoch 14, gen_loss = 0.860896519325522, disc_loss = 0.06408174770428028
Trained batch 639 in epoch 14, gen_loss = 0.8605127837043256, disc_loss = 0.06411970649642171
Trained batch 640 in epoch 14, gen_loss = 0.860575495988084, disc_loss = 0.06407917861197603
Trained batch 641 in epoch 14, gen_loss = 0.8611462662617365, disc_loss = 0.06403295987799207
Trained batch 642 in epoch 14, gen_loss = 0.8608877260707215, disc_loss = 0.06398443012856074
Trained batch 643 in epoch 14, gen_loss = 0.8609692745419762, disc_loss = 0.06390520914527154
Trained batch 644 in epoch 14, gen_loss = 0.8610739846100178, disc_loss = 0.06383626932465984
Trained batch 645 in epoch 14, gen_loss = 0.8609197273988842, disc_loss = 0.0638180048718195
Trained batch 646 in epoch 14, gen_loss = 0.8602577475989251, disc_loss = 0.06391522613205765
Trained batch 647 in epoch 14, gen_loss = 0.8600602759347286, disc_loss = 0.06386625862329692
Trained batch 648 in epoch 14, gen_loss = 0.8601688549312861, disc_loss = 0.06380533028784308
Trained batch 649 in epoch 14, gen_loss = 0.8605955480153744, disc_loss = 0.06378862531282581
Trained batch 650 in epoch 14, gen_loss = 0.8605172138334969, disc_loss = 0.0637537361853706
Trained batch 651 in epoch 14, gen_loss = 0.8603065522627596, disc_loss = 0.06373877805783384
Trained batch 652 in epoch 14, gen_loss = 0.860639630972335, disc_loss = 0.0636725961280613
Trained batch 653 in epoch 14, gen_loss = 0.8603208705281628, disc_loss = 0.06371699098002064
Trained batch 654 in epoch 14, gen_loss = 0.8603730380535126, disc_loss = 0.0637749966305062
Trained batch 655 in epoch 14, gen_loss = 0.8604148381457823, disc_loss = 0.06369666533016531
Trained batch 656 in epoch 14, gen_loss = 0.860642345029651, disc_loss = 0.06363290825453297
Trained batch 657 in epoch 14, gen_loss = 0.8601331834463363, disc_loss = 0.06386664469434815
Trained batch 658 in epoch 14, gen_loss = 0.860084352118835, disc_loss = 0.063850994083369
Trained batch 659 in epoch 14, gen_loss = 0.8605474037202921, disc_loss = 0.06396937173734786
Trained batch 660 in epoch 14, gen_loss = 0.8604318069888676, disc_loss = 0.06391673571318839
Trained batch 661 in epoch 14, gen_loss = 0.8603573061098145, disc_loss = 0.06386487940157513
Trained batch 662 in epoch 14, gen_loss = 0.860353188232419, disc_loss = 0.06383827392877182
Trained batch 663 in epoch 14, gen_loss = 0.8605197943208447, disc_loss = 0.06379899549920741
Trained batch 664 in epoch 14, gen_loss = 0.861215824516196, disc_loss = 0.06419979411324388
Trained batch 665 in epoch 14, gen_loss = 0.8609115229444103, disc_loss = 0.06421439383352348
Trained batch 666 in epoch 14, gen_loss = 0.8606411900924242, disc_loss = 0.06427212251766377
Trained batch 667 in epoch 14, gen_loss = 0.8607478458099737, disc_loss = 0.06421114519255203
Trained batch 668 in epoch 14, gen_loss = 0.860578767253679, disc_loss = 0.06416577749338519
Trained batch 669 in epoch 14, gen_loss = 0.8608614740531836, disc_loss = 0.06413038988361386
Trained batch 670 in epoch 14, gen_loss = 0.8609458495447782, disc_loss = 0.06409533295624968
Trained batch 671 in epoch 14, gen_loss = 0.8606066216404239, disc_loss = 0.06422432561244239
Trained batch 672 in epoch 14, gen_loss = 0.8606251483951954, disc_loss = 0.06415842685095667
Trained batch 673 in epoch 14, gen_loss = 0.8608503021985204, disc_loss = 0.06424484418660889
Trained batch 674 in epoch 14, gen_loss = 0.8607139473049729, disc_loss = 0.06418377153713394
Trained batch 675 in epoch 14, gen_loss = 0.8606323480341561, disc_loss = 0.0641378590591891
Trained batch 676 in epoch 14, gen_loss = 0.8609149875545783, disc_loss = 0.06410618950550938
Trained batch 677 in epoch 14, gen_loss = 0.8609692609503558, disc_loss = 0.06402675174918454
Trained batch 678 in epoch 14, gen_loss = 0.8611009819254783, disc_loss = 0.06396328301384321
Trained batch 679 in epoch 14, gen_loss = 0.8612368785721414, disc_loss = 0.06392253697165014
Trained batch 680 in epoch 14, gen_loss = 0.8613544590935308, disc_loss = 0.06385086998261413
Trained batch 681 in epoch 14, gen_loss = 0.8614435300362075, disc_loss = 0.06377901232602004
Trained batch 682 in epoch 14, gen_loss = 0.8614806209528604, disc_loss = 0.06371747157611443
Trained batch 683 in epoch 14, gen_loss = 0.8614334591735177, disc_loss = 0.06364456057679235
Trained batch 684 in epoch 14, gen_loss = 0.8615434289413647, disc_loss = 0.06356587214871262
Trained batch 685 in epoch 14, gen_loss = 0.8618348028413061, disc_loss = 0.06349369502998345
Trained batch 686 in epoch 14, gen_loss = 0.8617974393492703, disc_loss = 0.06342003729432995
Trained batch 687 in epoch 14, gen_loss = 0.8618244538733433, disc_loss = 0.06335074853742236
Trained batch 688 in epoch 14, gen_loss = 0.8621688890439851, disc_loss = 0.06327551407996343
Trained batch 689 in epoch 14, gen_loss = 0.8618595906357834, disc_loss = 0.06327097019504593
Trained batch 690 in epoch 14, gen_loss = 0.8620354893324862, disc_loss = 0.06322137714807058
Trained batch 691 in epoch 14, gen_loss = 0.8622256839981658, disc_loss = 0.06320878861046725
Trained batch 692 in epoch 14, gen_loss = 0.8625780513018241, disc_loss = 0.06313371669345173
Trained batch 693 in epoch 14, gen_loss = 0.8627807237315247, disc_loss = 0.06306940881583721
Trained batch 694 in epoch 14, gen_loss = 0.8629746054145072, disc_loss = 0.06298941651479803
Trained batch 695 in epoch 14, gen_loss = 0.8625879963838506, disc_loss = 0.06305297121576879
Trained batch 696 in epoch 14, gen_loss = 0.8626661733797667, disc_loss = 0.0630011351263335
Trained batch 697 in epoch 14, gen_loss = 0.8632934322756819, disc_loss = 0.06298660239829204
Trained batch 698 in epoch 14, gen_loss = 0.8633180801704717, disc_loss = 0.0629064477453853
Trained batch 699 in epoch 14, gen_loss = 0.8632622995121139, disc_loss = 0.06285378218561943
Trained batch 700 in epoch 14, gen_loss = 0.8631253559222065, disc_loss = 0.06278758038821153
Trained batch 701 in epoch 14, gen_loss = 0.8629357945120912, disc_loss = 0.06277656421779079
Trained batch 702 in epoch 14, gen_loss = 0.8631308422573599, disc_loss = 0.06269932344123975
Trained batch 703 in epoch 14, gen_loss = 0.8632229693995958, disc_loss = 0.06264238113296662
Trained batch 704 in epoch 14, gen_loss = 0.8632226986665252, disc_loss = 0.0625913337857218
Trained batch 705 in epoch 14, gen_loss = 0.8635022672732221, disc_loss = 0.06251880506293653
Trained batch 706 in epoch 14, gen_loss = 0.8638343860354417, disc_loss = 0.06245123818213755
Trained batch 707 in epoch 14, gen_loss = 0.864208551492058, disc_loss = 0.0623877628128923
Trained batch 708 in epoch 14, gen_loss = 0.8643476788600847, disc_loss = 0.062310509494018486
Trained batch 709 in epoch 14, gen_loss = 0.8643907202381483, disc_loss = 0.0622413692287576
Trained batch 710 in epoch 14, gen_loss = 0.8645623133906836, disc_loss = 0.06216457690296985
Trained batch 711 in epoch 14, gen_loss = 0.8645061015496763, disc_loss = 0.06212079663972862
Trained batch 712 in epoch 14, gen_loss = 0.8645665386030751, disc_loss = 0.06204492588910218
Trained batch 713 in epoch 14, gen_loss = 0.8645473858472013, disc_loss = 0.06198189147821098
Trained batch 714 in epoch 14, gen_loss = 0.8648103930316605, disc_loss = 0.06190943604178883
Trained batch 715 in epoch 14, gen_loss = 0.864933309067228, disc_loss = 0.06184487545657279
Trained batch 716 in epoch 14, gen_loss = 0.8649724203589239, disc_loss = 0.06190533470817045
Trained batch 717 in epoch 14, gen_loss = 0.8647818743435454, disc_loss = 0.06189433110989423
Trained batch 718 in epoch 14, gen_loss = 0.8647548295609311, disc_loss = 0.06182555451028059
Trained batch 719 in epoch 14, gen_loss = 0.8647287100967433, disc_loss = 0.06175580220232304
Trained batch 720 in epoch 14, gen_loss = 0.8649770230178859, disc_loss = 0.06168507971063297
Trained batch 721 in epoch 14, gen_loss = 0.8653245099776339, disc_loss = 0.061647641495092054
Trained batch 722 in epoch 14, gen_loss = 0.8654185057428367, disc_loss = 0.06157745862699128
Trained batch 723 in epoch 14, gen_loss = 0.8658113766523355, disc_loss = 0.06150343747055724
Trained batch 724 in epoch 14, gen_loss = 0.8657802465455285, disc_loss = 0.06144107982965893
Trained batch 725 in epoch 14, gen_loss = 0.8658259728148621, disc_loss = 0.06139006201862858
Trained batch 726 in epoch 14, gen_loss = 0.8655148905687844, disc_loss = 0.061374225367393544
Trained batch 727 in epoch 14, gen_loss = 0.8660521281698903, disc_loss = 0.061444139312108424
Trained batch 728 in epoch 14, gen_loss = 0.8661954645348511, disc_loss = 0.0613732331021036
Trained batch 729 in epoch 14, gen_loss = 0.8658320329368931, disc_loss = 0.06142299291805352
Trained batch 730 in epoch 14, gen_loss = 0.8661205110161804, disc_loss = 0.061366541764065724
Trained batch 731 in epoch 14, gen_loss = 0.8662134310016867, disc_loss = 0.061397532496698035
Trained batch 732 in epoch 14, gen_loss = 0.8661851619877237, disc_loss = 0.06135739561609954
Trained batch 733 in epoch 14, gen_loss = 0.866168096417952, disc_loss = 0.06130913835797936
Trained batch 734 in epoch 14, gen_loss = 0.8661920800095513, disc_loss = 0.06125403979134296
Trained batch 735 in epoch 14, gen_loss = 0.8662048968203042, disc_loss = 0.061190799453786734
Trained batch 736 in epoch 14, gen_loss = 0.8663284732092026, disc_loss = 0.06112029507763815
Trained batch 737 in epoch 14, gen_loss = 0.866444431467431, disc_loss = 0.06105286171495773
Trained batch 738 in epoch 14, gen_loss = 0.8664611710666481, disc_loss = 0.06101904428691297
Trained batch 739 in epoch 14, gen_loss = 0.8668691753132923, disc_loss = 0.06095338433515281
Trained batch 740 in epoch 14, gen_loss = 0.8668537190166401, disc_loss = 0.06091347338214476
Trained batch 741 in epoch 14, gen_loss = 0.8665438720559817, disc_loss = 0.06088742156854437
Trained batch 742 in epoch 14, gen_loss = 0.8667798679657932, disc_loss = 0.060817143286316384
Trained batch 743 in epoch 14, gen_loss = 0.8670709090287326, disc_loss = 0.0607623705303707
Trained batch 744 in epoch 14, gen_loss = 0.8673775740517866, disc_loss = 0.060713372638936614
Trained batch 745 in epoch 14, gen_loss = 0.8670469847265581, disc_loss = 0.06073462536081612
Trained batch 746 in epoch 14, gen_loss = 0.8671704618886134, disc_loss = 0.06075330957747906
Trained batch 747 in epoch 14, gen_loss = 0.8670238615436987, disc_loss = 0.060716291854063416
Trained batch 748 in epoch 14, gen_loss = 0.8668671821322397, disc_loss = 0.06068685116092158
Trained batch 749 in epoch 14, gen_loss = 0.866808340271314, disc_loss = 0.060626255196208755
Trained batch 750 in epoch 14, gen_loss = 0.8669778875679214, disc_loss = 0.06071102149107465
Trained batch 751 in epoch 14, gen_loss = 0.8668105742160944, disc_loss = 0.0606788486617548
Trained batch 752 in epoch 14, gen_loss = 0.8669707741474567, disc_loss = 0.06061887486737622
Trained batch 753 in epoch 14, gen_loss = 0.8668061424076399, disc_loss = 0.06062067695275759
Trained batch 754 in epoch 14, gen_loss = 0.8665464435586866, disc_loss = 0.06065469723601906
Trained batch 755 in epoch 14, gen_loss = 0.8671112656199113, disc_loss = 0.06112891333066814
Trained batch 756 in epoch 14, gen_loss = 0.8671719403137776, disc_loss = 0.061065795831997415
Trained batch 757 in epoch 14, gen_loss = 0.8667546715538231, disc_loss = 0.061182144920570204
Trained batch 758 in epoch 14, gen_loss = 0.866787665249959, disc_loss = 0.061143266608293154
Trained batch 759 in epoch 14, gen_loss = 0.8670966328366807, disc_loss = 0.06118686477543394
Trained batch 760 in epoch 14, gen_loss = 0.8665105131468228, disc_loss = 0.06128574702117724
Trained batch 761 in epoch 14, gen_loss = 0.8667523083802596, disc_loss = 0.061223300862592936
Trained batch 762 in epoch 14, gen_loss = 0.8666775235576679, disc_loss = 0.06124920646939549
Trained batch 763 in epoch 14, gen_loss = 0.8661708463939073, disc_loss = 0.06157495360272932
Trained batch 764 in epoch 14, gen_loss = 0.8663954523264193, disc_loss = 0.061565401497010896
Trained batch 765 in epoch 14, gen_loss = 0.8662787637340182, disc_loss = 0.06159586057628629
Trained batch 766 in epoch 14, gen_loss = 0.866420118990591, disc_loss = 0.06156571250168468
Trained batch 767 in epoch 14, gen_loss = 0.8658915603300557, disc_loss = 0.06169369706124902
Trained batch 768 in epoch 14, gen_loss = 0.8657240782742073, disc_loss = 0.0617041665429712
Trained batch 769 in epoch 14, gen_loss = 0.8659969663078134, disc_loss = 0.06165277034757877
Trained batch 770 in epoch 14, gen_loss = 0.8659187384075383, disc_loss = 0.06163532791741376
Trained batch 771 in epoch 14, gen_loss = 0.8657115931415187, disc_loss = 0.06179062633623171
Trained batch 772 in epoch 14, gen_loss = 0.8656324819405051, disc_loss = 0.0617732030091347
Trained batch 773 in epoch 14, gen_loss = 0.8655655226581165, disc_loss = 0.061728776444004756
Trained batch 774 in epoch 14, gen_loss = 0.8652468264102936, disc_loss = 0.06171191347642772
Trained batch 775 in epoch 14, gen_loss = 0.8655617139926276, disc_loss = 0.06169280122195073
Trained batch 776 in epoch 14, gen_loss = 0.8660250617960705, disc_loss = 0.06175415927875053
Trained batch 777 in epoch 14, gen_loss = 0.8657271480115949, disc_loss = 0.06183655190779552
Trained batch 778 in epoch 14, gen_loss = 0.8655923569386057, disc_loss = 0.06178647945832284
Trained batch 779 in epoch 14, gen_loss = 0.8657650109667044, disc_loss = 0.061725723631799415
Trained batch 780 in epoch 14, gen_loss = 0.8654570198318564, disc_loss = 0.061741835599295344
Trained batch 781 in epoch 14, gen_loss = 0.8655396179698617, disc_loss = 0.061797037971375125
Trained batch 782 in epoch 14, gen_loss = 0.8651075704572758, disc_loss = 0.06191440598710915
Trained batch 783 in epoch 14, gen_loss = 0.8652998282365045, disc_loss = 0.06190545025711632
Trained batch 784 in epoch 14, gen_loss = 0.8649799917533899, disc_loss = 0.06192709130003669
Trained batch 785 in epoch 14, gen_loss = 0.8650471974192685, disc_loss = 0.062133417692883816
Trained batch 786 in epoch 14, gen_loss = 0.8652645143120534, disc_loss = 0.06207490991031824
Trained batch 787 in epoch 14, gen_loss = 0.8650011321539202, disc_loss = 0.062122685525703436
Trained batch 788 in epoch 14, gen_loss = 0.8649674322744135, disc_loss = 0.06207366798873353
Trained batch 789 in epoch 14, gen_loss = 0.8646223195368731, disc_loss = 0.06206122017465532
Testing Epoch 14
Training Epoch 15
Trained batch 0 in epoch 15, gen_loss = 0.9206001162528992, disc_loss = 0.04048006236553192
Trained batch 1 in epoch 15, gen_loss = 0.8011704981327057, disc_loss = 0.05024390667676926
Trained batch 2 in epoch 15, gen_loss = 0.9249069492022196, disc_loss = 0.03823211323469877
Trained batch 3 in epoch 15, gen_loss = 0.9159134179353714, disc_loss = 0.033558702329173684
Trained batch 4 in epoch 15, gen_loss = 0.8936418175697327, disc_loss = 0.03450081516057253
Trained batch 5 in epoch 15, gen_loss = 0.8502358694871267, disc_loss = 0.047075456784417234
Trained batch 6 in epoch 15, gen_loss = 0.8663085188184466, disc_loss = 0.0500915509515575
Trained batch 7 in epoch 15, gen_loss = 0.8297814652323723, disc_loss = 0.05284972221124917
Trained batch 8 in epoch 15, gen_loss = 0.8313978844218783, disc_loss = 0.05317565809107489
Trained batch 9 in epoch 15, gen_loss = 0.8657203376293182, disc_loss = 0.06307871202006936
Trained batch 10 in epoch 15, gen_loss = 0.8385398116978732, disc_loss = 0.06515914345668121
Trained batch 11 in epoch 15, gen_loss = 0.8128988494475683, disc_loss = 0.07641357439570129
Trained batch 12 in epoch 15, gen_loss = 0.8301516725466802, disc_loss = 0.0719339970069436
Trained batch 13 in epoch 15, gen_loss = 0.840479701757431, disc_loss = 0.07313548527391893
Trained batch 14 in epoch 15, gen_loss = 0.832414464155833, disc_loss = 0.07200487970064083
Trained batch 15 in epoch 15, gen_loss = 0.8179424963891506, disc_loss = 0.07320258690742776
Trained batch 16 in epoch 15, gen_loss = 0.8267743832924787, disc_loss = 0.07000859514536227
Trained batch 17 in epoch 15, gen_loss = 0.824256118800905, disc_loss = 0.0685517870200177
Trained batch 18 in epoch 15, gen_loss = 0.837500694550966, disc_loss = 0.07489708923783742
Trained batch 19 in epoch 15, gen_loss = 0.827408766746521, disc_loss = 0.07847723658196629
Trained batch 20 in epoch 15, gen_loss = 0.8216944705872309, disc_loss = 0.07695140241689626
Trained batch 21 in epoch 15, gen_loss = 0.8290615650740537, disc_loss = 0.07869466474618424
Trained batch 22 in epoch 15, gen_loss = 0.8397630790005559, disc_loss = 0.07782244321930668
Trained batch 23 in epoch 15, gen_loss = 0.8302893514434496, disc_loss = 0.08275259375416984
Trained batch 24 in epoch 15, gen_loss = 0.8275275468826294, disc_loss = 0.08083239313215017
Trained batch 25 in epoch 15, gen_loss = 0.8321722035224621, disc_loss = 0.08376180606249434
Trained batch 26 in epoch 15, gen_loss = 0.826463485205615, disc_loss = 0.08171479386725912
Trained batch 27 in epoch 15, gen_loss = 0.8260410172598702, disc_loss = 0.08017977895880384
Trained batch 28 in epoch 15, gen_loss = 0.8323118851102632, disc_loss = 0.07792034825502799
Trained batch 29 in epoch 15, gen_loss = 0.825420484940211, disc_loss = 0.0790279669376711
Trained batch 30 in epoch 15, gen_loss = 0.8267368847324003, disc_loss = 0.07719861598865639
Trained batch 31 in epoch 15, gen_loss = 0.8339111134409904, disc_loss = 0.07543515853467397
Trained batch 32 in epoch 15, gen_loss = 0.8385284308231238, disc_loss = 0.0735871076414531
Trained batch 33 in epoch 15, gen_loss = 0.8312286401496214, disc_loss = 0.0735768185216276
Trained batch 34 in epoch 15, gen_loss = 0.8372756668499538, disc_loss = 0.0734087686719639
Trained batch 35 in epoch 15, gen_loss = 0.8349432001511256, disc_loss = 0.07440996772816612
Trained batch 36 in epoch 15, gen_loss = 0.8265710376404427, disc_loss = 0.07656882041310137
Trained batch 37 in epoch 15, gen_loss = 0.8245767637303001, disc_loss = 0.07820596332710825
Trained batch 38 in epoch 15, gen_loss = 0.8201922086568979, disc_loss = 0.0775860702045835
Trained batch 39 in epoch 15, gen_loss = 0.8212488919496537, disc_loss = 0.07598494910635054
Trained batch 40 in epoch 15, gen_loss = 0.8223903019253801, disc_loss = 0.08150592323665212
Trained batch 41 in epoch 15, gen_loss = 0.8251497206233797, disc_loss = 0.08014657982580718
Trained batch 42 in epoch 15, gen_loss = 0.8286131273868472, disc_loss = 0.07891851321382579
Trained batch 43 in epoch 15, gen_loss = 0.8266726569695906, disc_loss = 0.07836207633160731
Trained batch 44 in epoch 15, gen_loss = 0.832798449198405, disc_loss = 0.07797291042904059
Trained batch 45 in epoch 15, gen_loss = 0.8301535145096157, disc_loss = 0.0771883411494934
Trained batch 46 in epoch 15, gen_loss = 0.8304295894947458, disc_loss = 0.07617047175447991
Trained batch 47 in epoch 15, gen_loss = 0.8276336515943209, disc_loss = 0.07598560986419518
Trained batch 48 in epoch 15, gen_loss = 0.8320017323202017, disc_loss = 0.0757405765506686
Trained batch 49 in epoch 15, gen_loss = 0.830181155204773, disc_loss = 0.07473410952836275
Trained batch 50 in epoch 15, gen_loss = 0.8286867889703489, disc_loss = 0.07446102582502599
Trained batch 51 in epoch 15, gen_loss = 0.8286638878859006, disc_loss = 0.0744075094922804
Trained batch 52 in epoch 15, gen_loss = 0.8330989266341587, disc_loss = 0.07408226003764935
Trained batch 53 in epoch 15, gen_loss = 0.8307706537070098, disc_loss = 0.07415176972884822
Trained batch 54 in epoch 15, gen_loss = 0.832051915472204, disc_loss = 0.07317185259678147
Trained batch 55 in epoch 15, gen_loss = 0.8337620007140296, disc_loss = 0.0720842293064509
Trained batch 56 in epoch 15, gen_loss = 0.8391896841818827, disc_loss = 0.07120567717050251
Trained batch 57 in epoch 15, gen_loss = 0.8417184373428082, disc_loss = 0.0702439714865438
Trained batch 58 in epoch 15, gen_loss = 0.8410551649028972, disc_loss = 0.06985329760838363
Trained batch 59 in epoch 15, gen_loss = 0.8357477893431982, disc_loss = 0.07046505336960157
Trained batch 60 in epoch 15, gen_loss = 0.8401866633383954, disc_loss = 0.06975360804038946
Trained batch 61 in epoch 15, gen_loss = 0.8392255142811806, disc_loss = 0.06883164950376076
Trained batch 62 in epoch 15, gen_loss = 0.8385699883339897, disc_loss = 0.07006321538476244
Trained batch 63 in epoch 15, gen_loss = 0.8324330025352538, disc_loss = 0.07336939776723739
Trained batch 64 in epoch 15, gen_loss = 0.8324034200264857, disc_loss = 0.07322020540730312
Trained batch 65 in epoch 15, gen_loss = 0.8322457838239092, disc_loss = 0.07279421015162811
Trained batch 66 in epoch 15, gen_loss = 0.8323121555705568, disc_loss = 0.07189392522255432
Trained batch 67 in epoch 15, gen_loss = 0.8327417325447587, disc_loss = 0.07103597967173247
Trained batch 68 in epoch 15, gen_loss = 0.8334812690382418, disc_loss = 0.0702061489008475
Trained batch 69 in epoch 15, gen_loss = 0.8366615299667631, disc_loss = 0.06942153200507165
Trained batch 70 in epoch 15, gen_loss = 0.8366537971395842, disc_loss = 0.06893925987918612
Trained batch 71 in epoch 15, gen_loss = 0.8390117639468776, disc_loss = 0.06821955295486583
Trained batch 72 in epoch 15, gen_loss = 0.8420758496408594, disc_loss = 0.06739980060198944
Trained batch 73 in epoch 15, gen_loss = 0.8406444445655152, disc_loss = 0.06695557638650408
Trained batch 74 in epoch 15, gen_loss = 0.8373154540856679, disc_loss = 0.06669742376854022
Trained batch 75 in epoch 15, gen_loss = 0.8423665161979826, disc_loss = 0.06853387947194278
Trained batch 76 in epoch 15, gen_loss = 0.8398953006639109, disc_loss = 0.06898059435914476
Trained batch 77 in epoch 15, gen_loss = 0.8362550754577686, disc_loss = 0.06967919177781695
Trained batch 78 in epoch 15, gen_loss = 0.837824338976341, disc_loss = 0.07095167937959675
Trained batch 79 in epoch 15, gen_loss = 0.8410862255841494, disc_loss = 0.07118726467015221
Trained batch 80 in epoch 15, gen_loss = 0.8388058583677551, disc_loss = 0.07150509246383552
Trained batch 81 in epoch 15, gen_loss = 0.835648667885036, disc_loss = 0.07181991756007802
Trained batch 82 in epoch 15, gen_loss = 0.8373335186975548, disc_loss = 0.07126288202378046
Trained batch 83 in epoch 15, gen_loss = 0.8360389233345077, disc_loss = 0.07097094835314367
Trained batch 84 in epoch 15, gen_loss = 0.83677339238279, disc_loss = 0.07090281818938605
Trained batch 85 in epoch 15, gen_loss = 0.834851089951604, disc_loss = 0.07053403752357808
Trained batch 86 in epoch 15, gen_loss = 0.8338779543323078, disc_loss = 0.06997716149593565
Trained batch 87 in epoch 15, gen_loss = 0.8354501849548384, disc_loss = 0.06972012492108413
Trained batch 88 in epoch 15, gen_loss = 0.8373326294207841, disc_loss = 0.06908119332798746
Trained batch 89 in epoch 15, gen_loss = 0.8364924301703771, disc_loss = 0.06895196757589778
Trained batch 90 in epoch 15, gen_loss = 0.8385781184002593, disc_loss = 0.06861018730266082
Trained batch 91 in epoch 15, gen_loss = 0.8371065864744394, disc_loss = 0.06809791794006267
Trained batch 92 in epoch 15, gen_loss = 0.8377597187795947, disc_loss = 0.06755902609156986
Trained batch 93 in epoch 15, gen_loss = 0.8384193597321815, disc_loss = 0.0673185012580708
Trained batch 94 in epoch 15, gen_loss = 0.8353016787453702, disc_loss = 0.06738766662188267
Trained batch 95 in epoch 15, gen_loss = 0.8370815102631847, disc_loss = 0.06709935317242828
Trained batch 96 in epoch 15, gen_loss = 0.8355068893162245, disc_loss = 0.06709859576844371
Trained batch 97 in epoch 15, gen_loss = 0.8340152821370533, disc_loss = 0.06722768779121796
Trained batch 98 in epoch 15, gen_loss = 0.8334392191785754, disc_loss = 0.06682783817740703
Trained batch 99 in epoch 15, gen_loss = 0.8316952952742577, disc_loss = 0.0664956307504326
Trained batch 100 in epoch 15, gen_loss = 0.8325895363151437, disc_loss = 0.06643771554463275
Trained batch 101 in epoch 15, gen_loss = 0.830392865281479, disc_loss = 0.06671940496045292
Trained batch 102 in epoch 15, gen_loss = 0.8292626307427304, disc_loss = 0.06651348538371255
Trained batch 103 in epoch 15, gen_loss = 0.8312389452296954, disc_loss = 0.06599301023659511
Trained batch 104 in epoch 15, gen_loss = 0.8335171952134087, disc_loss = 0.06555280028177159
Trained batch 105 in epoch 15, gen_loss = 0.8318682821854105, disc_loss = 0.06539230581970429
Trained batch 106 in epoch 15, gen_loss = 0.8301550325389221, disc_loss = 0.06527178089578296
Trained batch 107 in epoch 15, gen_loss = 0.8331244066357613, disc_loss = 0.06613920824774713
Trained batch 108 in epoch 15, gen_loss = 0.833735715632045, disc_loss = 0.06562729882196001
Trained batch 109 in epoch 15, gen_loss = 0.833201450380412, disc_loss = 0.06523888380351392
Trained batch 110 in epoch 15, gen_loss = 0.8318382262646615, disc_loss = 0.06511787081825303
Trained batch 111 in epoch 15, gen_loss = 0.8329951260238886, disc_loss = 0.0646600610510047
Trained batch 112 in epoch 15, gen_loss = 0.8364860935021291, disc_loss = 0.06466653122179276
Trained batch 113 in epoch 15, gen_loss = 0.8362736981688884, disc_loss = 0.06426269796333815
Trained batch 114 in epoch 15, gen_loss = 0.8334466071232506, disc_loss = 0.06533389519090238
Trained batch 115 in epoch 15, gen_loss = 0.8340043674769073, disc_loss = 0.06521571482178466
Trained batch 116 in epoch 15, gen_loss = 0.8339805208210253, disc_loss = 0.0649925767738595
Trained batch 117 in epoch 15, gen_loss = 0.8314146497997187, disc_loss = 0.06559243930850998
Trained batch 118 in epoch 15, gen_loss = 0.831506731880813, disc_loss = 0.06515236101856753
Trained batch 119 in epoch 15, gen_loss = 0.8339253850281239, disc_loss = 0.06505996960525712
Trained batch 120 in epoch 15, gen_loss = 0.8331178813433844, disc_loss = 0.06531777968707163
Trained batch 121 in epoch 15, gen_loss = 0.8311825108821275, disc_loss = 0.06623537927010997
Trained batch 122 in epoch 15, gen_loss = 0.8331462268422289, disc_loss = 0.066114748941689
Trained batch 123 in epoch 15, gen_loss = 0.8334973601083602, disc_loss = 0.06585513782357016
Trained batch 124 in epoch 15, gen_loss = 0.8335776698589324, disc_loss = 0.06571866288781165
Trained batch 125 in epoch 15, gen_loss = 0.8339937563453402, disc_loss = 0.06541157581858219
Trained batch 126 in epoch 15, gen_loss = 0.8345070638525205, disc_loss = 0.06516912119008425
Trained batch 127 in epoch 15, gen_loss = 0.833983093732968, disc_loss = 0.06482377716747578
Trained batch 128 in epoch 15, gen_loss = 0.8339495762836101, disc_loss = 0.06456016705826272
Trained batch 129 in epoch 15, gen_loss = 0.834085597212498, disc_loss = 0.06414559814505852
Trained batch 130 in epoch 15, gen_loss = 0.8354297027788089, disc_loss = 0.06469124315292325
Trained batch 131 in epoch 15, gen_loss = 0.8334821519075017, disc_loss = 0.0657019706471174
Trained batch 132 in epoch 15, gen_loss = 0.8331535523547265, disc_loss = 0.0658879100688194
Trained batch 133 in epoch 15, gen_loss = 0.8327408937820747, disc_loss = 0.0667995334422188
Trained batch 134 in epoch 15, gen_loss = 0.831128575846001, disc_loss = 0.06714550912104271
Trained batch 135 in epoch 15, gen_loss = 0.8319505713880062, disc_loss = 0.06761873177910115
Trained batch 136 in epoch 15, gen_loss = 0.8325472558936934, disc_loss = 0.06731678060099591
Trained batch 137 in epoch 15, gen_loss = 0.8309952316508777, disc_loss = 0.06752423487225737
Trained batch 138 in epoch 15, gen_loss = 0.8325507437153686, disc_loss = 0.06730087207322069
Trained batch 139 in epoch 15, gen_loss = 0.831571658381394, disc_loss = 0.06705512078478933
Trained batch 140 in epoch 15, gen_loss = 0.8323951488268291, disc_loss = 0.06678583928720748
Trained batch 141 in epoch 15, gen_loss = 0.8335609291221054, disc_loss = 0.06646318241796444
Trained batch 142 in epoch 15, gen_loss = 0.8330596479085776, disc_loss = 0.06624935097158789
Trained batch 143 in epoch 15, gen_loss = 0.833496046356029, disc_loss = 0.06628704675111091
Trained batch 144 in epoch 15, gen_loss = 0.8318136640663805, disc_loss = 0.06656826132073485
Trained batch 145 in epoch 15, gen_loss = 0.8310694394454564, disc_loss = 0.06653335525922172
Trained batch 146 in epoch 15, gen_loss = 0.8332840433331574, disc_loss = 0.06695177115905447
Trained batch 147 in epoch 15, gen_loss = 0.8328258006556614, disc_loss = 0.06673285590384055
Trained batch 148 in epoch 15, gen_loss = 0.8345856552556057, disc_loss = 0.06638841703534126
Trained batch 149 in epoch 15, gen_loss = 0.8335958351691564, disc_loss = 0.06623648047447205
Trained batch 150 in epoch 15, gen_loss = 0.8334340834064989, disc_loss = 0.06600526700548778
Trained batch 151 in epoch 15, gen_loss = 0.8347559043843495, disc_loss = 0.06570985208657619
Trained batch 152 in epoch 15, gen_loss = 0.8368720320704716, disc_loss = 0.06593448333929178
Trained batch 153 in epoch 15, gen_loss = 0.835262482235958, disc_loss = 0.06738161306537978
Trained batch 154 in epoch 15, gen_loss = 0.8365690679319443, disc_loss = 0.06703986271975503
Trained batch 155 in epoch 15, gen_loss = 0.836559578585319, disc_loss = 0.06672888852130526
Trained batch 156 in epoch 15, gen_loss = 0.836511290187289, disc_loss = 0.0663641528967934
Trained batch 157 in epoch 15, gen_loss = 0.8389095945071571, disc_loss = 0.06622891475246111
Trained batch 158 in epoch 15, gen_loss = 0.8392553717460273, disc_loss = 0.06594453185632732
Trained batch 159 in epoch 15, gen_loss = 0.8381463309749961, disc_loss = 0.06575408934731967
Trained batch 160 in epoch 15, gen_loss = 0.8376103648858041, disc_loss = 0.0656138009316525
Trained batch 161 in epoch 15, gen_loss = 0.8390568805697524, disc_loss = 0.06526036458204926
Trained batch 162 in epoch 15, gen_loss = 0.8411000515420013, disc_loss = 0.06568052787676545
Trained batch 163 in epoch 15, gen_loss = 0.840435394971836, disc_loss = 0.06554575538171864
Trained batch 164 in epoch 15, gen_loss = 0.8386552136955839, disc_loss = 0.06577529849653894
Trained batch 165 in epoch 15, gen_loss = 0.839745822261615, disc_loss = 0.06558523965573096
Trained batch 166 in epoch 15, gen_loss = 0.8414244757084075, disc_loss = 0.06535570155048442
Trained batch 167 in epoch 15, gen_loss = 0.8427181696253163, disc_loss = 0.06502761942378822
Trained batch 168 in epoch 15, gen_loss = 0.8424936637017854, disc_loss = 0.06481337459129695
Trained batch 169 in epoch 15, gen_loss = 0.8436305556227179, disc_loss = 0.0645482072387548
Trained batch 170 in epoch 15, gen_loss = 0.843162440242823, disc_loss = 0.06435628541423911
Trained batch 171 in epoch 15, gen_loss = 0.8446974045661992, disc_loss = 0.06426043287569354
Trained batch 172 in epoch 15, gen_loss = 0.8440939220734415, disc_loss = 0.06403203168614752
Trained batch 173 in epoch 15, gen_loss = 0.8433734909898933, disc_loss = 0.06378072369629624
Trained batch 174 in epoch 15, gen_loss = 0.843400149175099, disc_loss = 0.06356752066739968
Trained batch 175 in epoch 15, gen_loss = 0.8441417445851997, disc_loss = 0.06324601437187415
Trained batch 176 in epoch 15, gen_loss = 0.8440088628038849, disc_loss = 0.06302393636387368
Trained batch 177 in epoch 15, gen_loss = 0.8455921881989147, disc_loss = 0.06272563442661103
Trained batch 178 in epoch 15, gen_loss = 0.8462533120003493, disc_loss = 0.06258450036181668
Trained batch 179 in epoch 15, gen_loss = 0.8465999883082178, disc_loss = 0.06239294280142834
Trained batch 180 in epoch 15, gen_loss = 0.8480806246976167, disc_loss = 0.0622635127343649
Trained batch 181 in epoch 15, gen_loss = 0.8480405150861531, disc_loss = 0.062097123657752364
Trained batch 182 in epoch 15, gen_loss = 0.8490186178944802, disc_loss = 0.061810865700550256
Trained batch 183 in epoch 15, gen_loss = 0.8490636868645316, disc_loss = 0.06178214521218172
Trained batch 184 in epoch 15, gen_loss = 0.8508665853255504, disc_loss = 0.06169729622181606
Trained batch 185 in epoch 15, gen_loss = 0.8515608626347716, disc_loss = 0.06163492517155265
Trained batch 186 in epoch 15, gen_loss = 0.8497040700466237, disc_loss = 0.06247082702008718
Trained batch 187 in epoch 15, gen_loss = 0.8505207308112307, disc_loss = 0.06245178395158988
Trained batch 188 in epoch 15, gen_loss = 0.8513367537152831, disc_loss = 0.06261754440754731
Trained batch 189 in epoch 15, gen_loss = 0.8509892986008996, disc_loss = 0.06267761241791672
Trained batch 190 in epoch 15, gen_loss = 0.8506703365847702, disc_loss = 0.062433621185436765
Trained batch 191 in epoch 15, gen_loss = 0.8512667884739736, disc_loss = 0.062390068941264566
Trained batch 192 in epoch 15, gen_loss = 0.8515063686383203, disc_loss = 0.06233328249585366
Trained batch 193 in epoch 15, gen_loss = 0.8498900555765506, disc_loss = 0.062499873270520694
Trained batch 194 in epoch 15, gen_loss = 0.8498913035942958, disc_loss = 0.062382463812350464
Trained batch 195 in epoch 15, gen_loss = 0.8518290305320098, disc_loss = 0.06223683124550675
Trained batch 196 in epoch 15, gen_loss = 0.8520169976701591, disc_loss = 0.062097272204547214
Trained batch 197 in epoch 15, gen_loss = 0.8524839668863952, disc_loss = 0.06188382921185382
Trained batch 198 in epoch 15, gen_loss = 0.8517909087427896, disc_loss = 0.06195914818105012
Trained batch 199 in epoch 15, gen_loss = 0.8529582788050175, disc_loss = 0.06236406681826338
Trained batch 200 in epoch 15, gen_loss = 0.8522792916689346, disc_loss = 0.062424944016378166
Trained batch 201 in epoch 15, gen_loss = 0.8514036440318173, disc_loss = 0.06266155740993079
Trained batch 202 in epoch 15, gen_loss = 0.8516997664139189, disc_loss = 0.06259956030780679
Trained batch 203 in epoch 15, gen_loss = 0.852735754467693, disc_loss = 0.062381532059197185
Trained batch 204 in epoch 15, gen_loss = 0.8530819937950227, disc_loss = 0.06219294421692811
Trained batch 205 in epoch 15, gen_loss = 0.8524720221757889, disc_loss = 0.06201656953684841
Trained batch 206 in epoch 15, gen_loss = 0.8512358128448615, disc_loss = 0.06212035853388733
Trained batch 207 in epoch 15, gen_loss = 0.8521498279789319, disc_loss = 0.06245624434086494
Trained batch 208 in epoch 15, gen_loss = 0.8515308472243223, disc_loss = 0.06244389811512885
Trained batch 209 in epoch 15, gen_loss = 0.8510030807483764, disc_loss = 0.06224646258522712
Trained batch 210 in epoch 15, gen_loss = 0.851503305949306, disc_loss = 0.062185600283003954
Trained batch 211 in epoch 15, gen_loss = 0.8529545792712355, disc_loss = 0.06326681623929443
Trained batch 212 in epoch 15, gen_loss = 0.8519020873895833, disc_loss = 0.06349556188934216
Trained batch 213 in epoch 15, gen_loss = 0.8506161649929029, disc_loss = 0.06439244683405437
Trained batch 214 in epoch 15, gen_loss = 0.8516481400922288, disc_loss = 0.0644440152162556
Trained batch 215 in epoch 15, gen_loss = 0.8522005860728247, disc_loss = 0.06439478399395873
Trained batch 216 in epoch 15, gen_loss = 0.8513344398566655, disc_loss = 0.06434343261472572
Trained batch 217 in epoch 15, gen_loss = 0.8519647970385508, disc_loss = 0.06496949774777055
Trained batch 218 in epoch 15, gen_loss = 0.8511841929938695, disc_loss = 0.06498633165839532
Trained batch 219 in epoch 15, gen_loss = 0.8504517784172838, disc_loss = 0.06500607150479812
Trained batch 220 in epoch 15, gen_loss = 0.8501391509269697, disc_loss = 0.06546241790688348
Trained batch 221 in epoch 15, gen_loss = 0.8494822024493605, disc_loss = 0.06542969156719476
Trained batch 222 in epoch 15, gen_loss = 0.849282457823176, disc_loss = 0.06524025410572443
Trained batch 223 in epoch 15, gen_loss = 0.8497524930696402, disc_loss = 0.06507640019948926
Trained batch 224 in epoch 15, gen_loss = 0.8491699021392398, disc_loss = 0.06517875807773736
Trained batch 225 in epoch 15, gen_loss = 0.8499464422991846, disc_loss = 0.0654527948225593
Trained batch 226 in epoch 15, gen_loss = 0.8479260562012374, disc_loss = 0.06679884056121702
Trained batch 227 in epoch 15, gen_loss = 0.8474126634629149, disc_loss = 0.06671982409489717
Trained batch 228 in epoch 15, gen_loss = 0.847775201479941, disc_loss = 0.06669939680870898
Trained batch 229 in epoch 15, gen_loss = 0.8475432215825371, disc_loss = 0.06664967503520133
Trained batch 230 in epoch 15, gen_loss = 0.8472171754806073, disc_loss = 0.0665436470820629
Trained batch 231 in epoch 15, gen_loss = 0.8464022968606703, disc_loss = 0.06647762301947986
Trained batch 232 in epoch 15, gen_loss = 0.8470241165212296, disc_loss = 0.0664669275823421
Trained batch 233 in epoch 15, gen_loss = 0.8470863059290454, disc_loss = 0.06627839602108121
Trained batch 234 in epoch 15, gen_loss = 0.8459909095409068, disc_loss = 0.06650075182279057
Trained batch 235 in epoch 15, gen_loss = 0.8466096670698311, disc_loss = 0.06682693376403176
Trained batch 236 in epoch 15, gen_loss = 0.8468828617520473, disc_loss = 0.06683303018686075
Trained batch 237 in epoch 15, gen_loss = 0.8454375541260263, disc_loss = 0.0672463782722553
Trained batch 238 in epoch 15, gen_loss = 0.8439894602887301, disc_loss = 0.06738274029132649
Trained batch 239 in epoch 15, gen_loss = 0.8463638228674729, disc_loss = 0.06832697278781173
Trained batch 240 in epoch 15, gen_loss = 0.8462627752687921, disc_loss = 0.06824761232423028
Trained batch 241 in epoch 15, gen_loss = 0.845655166166873, disc_loss = 0.06812594799240204
Trained batch 242 in epoch 15, gen_loss = 0.8449997595308248, disc_loss = 0.06808230709169566
Trained batch 243 in epoch 15, gen_loss = 0.8450425430888036, disc_loss = 0.06827710577111203
Trained batch 244 in epoch 15, gen_loss = 0.844872340134212, disc_loss = 0.06808441362476775
Trained batch 245 in epoch 15, gen_loss = 0.8447775440972026, disc_loss = 0.06791796106504412
Trained batch 246 in epoch 15, gen_loss = 0.8446446833340263, disc_loss = 0.06772268434368105
Trained batch 247 in epoch 15, gen_loss = 0.8438877907972182, disc_loss = 0.06765394017002696
Trained batch 248 in epoch 15, gen_loss = 0.8443375842638284, disc_loss = 0.06754411072339339
Trained batch 249 in epoch 15, gen_loss = 0.8446301400661469, disc_loss = 0.06739560300670565
Trained batch 250 in epoch 15, gen_loss = 0.8433179444525821, disc_loss = 0.06749992236398546
Trained batch 251 in epoch 15, gen_loss = 0.8437840030306861, disc_loss = 0.06758357913211166
Trained batch 252 in epoch 15, gen_loss = 0.8434005443286519, disc_loss = 0.06757365632986304
Trained batch 253 in epoch 15, gen_loss = 0.8434401391528723, disc_loss = 0.06735720868794409
Trained batch 254 in epoch 15, gen_loss = 0.8430208881696065, disc_loss = 0.06726394271405012
Trained batch 255 in epoch 15, gen_loss = 0.8432225906290114, disc_loss = 0.0670773426300002
Trained batch 256 in epoch 15, gen_loss = 0.8428566059249848, disc_loss = 0.06697525483182838
Trained batch 257 in epoch 15, gen_loss = 0.8437576083711875, disc_loss = 0.06677819303121389
Trained batch 258 in epoch 15, gen_loss = 0.8434516520573826, disc_loss = 0.06664948189688638
Trained batch 259 in epoch 15, gen_loss = 0.8437531799077987, disc_loss = 0.0668017897880278
Trained batch 260 in epoch 15, gen_loss = 0.8431942903675795, disc_loss = 0.06682814673210184
Trained batch 261 in epoch 15, gen_loss = 0.8432227607446773, disc_loss = 0.06668052959383843
Trained batch 262 in epoch 15, gen_loss = 0.8432556698984066, disc_loss = 0.06663353852184044
Trained batch 263 in epoch 15, gen_loss = 0.8433748522039616, disc_loss = 0.06652635615848174
Trained batch 264 in epoch 15, gen_loss = 0.8445803208171196, disc_loss = 0.06644307293946732
Trained batch 265 in epoch 15, gen_loss = 0.8428456572661722, disc_loss = 0.06751679878898974
Trained batch 266 in epoch 15, gen_loss = 0.8431000178226371, disc_loss = 0.06738929396620795
Trained batch 267 in epoch 15, gen_loss = 0.8426639949207875, disc_loss = 0.06752299280218613
Trained batch 268 in epoch 15, gen_loss = 0.8433617734554532, disc_loss = 0.06749631282198329
Trained batch 269 in epoch 15, gen_loss = 0.8437429927013539, disc_loss = 0.06744709567304838
Trained batch 270 in epoch 15, gen_loss = 0.8431813521138857, disc_loss = 0.06744341486790029
Trained batch 271 in epoch 15, gen_loss = 0.8428213149309158, disc_loss = 0.06744673215914243
Trained batch 272 in epoch 15, gen_loss = 0.843419441810021, disc_loss = 0.06765101121861365
Trained batch 273 in epoch 15, gen_loss = 0.843364491514916, disc_loss = 0.06766375994996378
Trained batch 274 in epoch 15, gen_loss = 0.8431015266071666, disc_loss = 0.06766722901808944
Trained batch 275 in epoch 15, gen_loss = 0.8438451773878457, disc_loss = 0.06835859512363601
Trained batch 276 in epoch 15, gen_loss = 0.8428283779199373, disc_loss = 0.06844191934193891
Trained batch 277 in epoch 15, gen_loss = 0.8430423065483998, disc_loss = 0.06854169762679946
Trained batch 278 in epoch 15, gen_loss = 0.8421694213344205, disc_loss = 0.06887677910580804
Trained batch 279 in epoch 15, gen_loss = 0.8416877718908446, disc_loss = 0.06894887436148045
Trained batch 280 in epoch 15, gen_loss = 0.8431944463176659, disc_loss = 0.06903942486642466
Trained batch 281 in epoch 15, gen_loss = 0.8434865155541305, disc_loss = 0.06891380941845371
Trained batch 282 in epoch 15, gen_loss = 0.842290041092849, disc_loss = 0.06934571407518149
Trained batch 283 in epoch 15, gen_loss = 0.8430605675552932, disc_loss = 0.0691866834277392
Trained batch 284 in epoch 15, gen_loss = 0.8426148146913762, disc_loss = 0.0691669536509404
Trained batch 285 in epoch 15, gen_loss = 0.8430249407574847, disc_loss = 0.06921031237319372
Trained batch 286 in epoch 15, gen_loss = 0.8418039713794762, disc_loss = 0.0695592174322737
Trained batch 287 in epoch 15, gen_loss = 0.842334671670364, disc_loss = 0.06936598096217494
Trained batch 288 in epoch 15, gen_loss = 0.8429933098566986, disc_loss = 0.06922319477784954
Trained batch 289 in epoch 15, gen_loss = 0.8427823174616386, disc_loss = 0.06920836802154523
Trained batch 290 in epoch 15, gen_loss = 0.8426649227379933, disc_loss = 0.06901542135575127
Trained batch 291 in epoch 15, gen_loss = 0.8423047683214488, disc_loss = 0.0689510690823376
Trained batch 292 in epoch 15, gen_loss = 0.8427648219842553, disc_loss = 0.06877538673547907
Trained batch 293 in epoch 15, gen_loss = 0.8432215587014243, disc_loss = 0.06857605807033373
Trained batch 294 in epoch 15, gen_loss = 0.844037449258869, disc_loss = 0.0684218876837295
Trained batch 295 in epoch 15, gen_loss = 0.8438801832899854, disc_loss = 0.0682492488004091
Trained batch 296 in epoch 15, gen_loss = 0.843457637912898, disc_loss = 0.06815660168081271
Trained batch 297 in epoch 15, gen_loss = 0.8445917680959574, disc_loss = 0.06922293097037047
Trained batch 298 in epoch 15, gen_loss = 0.843451252848807, disc_loss = 0.06947596393756095
Trained batch 299 in epoch 15, gen_loss = 0.8437050375342369, disc_loss = 0.0692935495901232
Trained batch 300 in epoch 15, gen_loss = 0.8437215859113738, disc_loss = 0.0691742647231937
Trained batch 301 in epoch 15, gen_loss = 0.8429702799643902, disc_loss = 0.06923114387040945
Trained batch 302 in epoch 15, gen_loss = 0.8434101542820631, disc_loss = 0.06924122416571078
Trained batch 303 in epoch 15, gen_loss = 0.8432273636326978, disc_loss = 0.0691288515977488
Trained batch 304 in epoch 15, gen_loss = 0.8429886598078931, disc_loss = 0.06922113518764983
Trained batch 305 in epoch 15, gen_loss = 0.8424929659935384, disc_loss = 0.06939950594648085
Trained batch 306 in epoch 15, gen_loss = 0.8423066773127267, disc_loss = 0.06923504124762618
Trained batch 307 in epoch 15, gen_loss = 0.8441388042909759, disc_loss = 0.06966794426885567
Trained batch 308 in epoch 15, gen_loss = 0.8442467324749166, disc_loss = 0.06957813447136371
Trained batch 309 in epoch 15, gen_loss = 0.844591177759632, disc_loss = 0.06946429504051564
Trained batch 310 in epoch 15, gen_loss = 0.8444768611066211, disc_loss = 0.06944025956675219
Trained batch 311 in epoch 15, gen_loss = 0.8447440215983452, disc_loss = 0.06925801406704032
Trained batch 312 in epoch 15, gen_loss = 0.8450674994494587, disc_loss = 0.06913562926401298
Trained batch 313 in epoch 15, gen_loss = 0.8456063618895354, disc_loss = 0.0689829932510924
Trained batch 314 in epoch 15, gen_loss = 0.8450856404645103, disc_loss = 0.06895306989521024
Trained batch 315 in epoch 15, gen_loss = 0.8456286734229401, disc_loss = 0.06886020706394758
Trained batch 316 in epoch 15, gen_loss = 0.8460751996619468, disc_loss = 0.06872940382976025
Trained batch 317 in epoch 15, gen_loss = 0.8455192723176764, disc_loss = 0.06876413584921111
Trained batch 318 in epoch 15, gen_loss = 0.846308703239435, disc_loss = 0.06859408051423659
Trained batch 319 in epoch 15, gen_loss = 0.8459147299639881, disc_loss = 0.06846313372807344
Trained batch 320 in epoch 15, gen_loss = 0.8462752804763591, disc_loss = 0.06827126596140388
Trained batch 321 in epoch 15, gen_loss = 0.8460670601322043, disc_loss = 0.06809991402175532
Trained batch 322 in epoch 15, gen_loss = 0.8465509705314695, disc_loss = 0.067937209451104
Trained batch 323 in epoch 15, gen_loss = 0.8467841314864747, disc_loss = 0.06775557934047861
Trained batch 324 in epoch 15, gen_loss = 0.847267260643152, disc_loss = 0.06758052851288364
Trained batch 325 in epoch 15, gen_loss = 0.8485741535761605, disc_loss = 0.06744299919424476
Trained batch 326 in epoch 15, gen_loss = 0.8487665537482737, disc_loss = 0.06725833983237453
Trained batch 327 in epoch 15, gen_loss = 0.8487213536551813, disc_loss = 0.0671360830381717
Trained batch 328 in epoch 15, gen_loss = 0.8485949980632874, disc_loss = 0.06697765322073751
Trained batch 329 in epoch 15, gen_loss = 0.8489779348626282, disc_loss = 0.06679486545423667
Trained batch 330 in epoch 15, gen_loss = 0.8495219757729787, disc_loss = 0.0666127197101172
Trained batch 331 in epoch 15, gen_loss = 0.8495949541768396, disc_loss = 0.06647407056774988
Trained batch 332 in epoch 15, gen_loss = 0.8499760492606921, disc_loss = 0.0662886640742175
Trained batch 333 in epoch 15, gen_loss = 0.8497440883677877, disc_loss = 0.06614654049874022
Trained batch 334 in epoch 15, gen_loss = 0.8502741917745391, disc_loss = 0.06614757105013105
Trained batch 335 in epoch 15, gen_loss = 0.849631895710315, disc_loss = 0.06616603880649477
Trained batch 336 in epoch 15, gen_loss = 0.8504875888633445, disc_loss = 0.06614023405445038
Trained batch 337 in epoch 15, gen_loss = 0.8504053841857515, disc_loss = 0.06601941423385939
Trained batch 338 in epoch 15, gen_loss = 0.8503119325743312, disc_loss = 0.06584542272557507
Trained batch 339 in epoch 15, gen_loss = 0.8511744147714446, disc_loss = 0.06569387312184143
Trained batch 340 in epoch 15, gen_loss = 0.8511598846954335, disc_loss = 0.0655943206620684
Trained batch 341 in epoch 15, gen_loss = 0.8514050748090298, disc_loss = 0.06548033942664533
Trained batch 342 in epoch 15, gen_loss = 0.8521091160378025, disc_loss = 0.06531584842412926
Trained batch 343 in epoch 15, gen_loss = 0.8521508861246497, disc_loss = 0.0652034638224841
Trained batch 344 in epoch 15, gen_loss = 0.8531453598236692, disc_loss = 0.06575967361880601
Trained batch 345 in epoch 15, gen_loss = 0.8522685393260393, disc_loss = 0.06610331476687567
Trained batch 346 in epoch 15, gen_loss = 0.8524977362980417, disc_loss = 0.06594153294898032
Trained batch 347 in epoch 15, gen_loss = 0.8526062726460654, disc_loss = 0.06581719986018564
Trained batch 348 in epoch 15, gen_loss = 0.8532171328805579, disc_loss = 0.06570784734658107
Trained batch 349 in epoch 15, gen_loss = 0.8530110555887223, disc_loss = 0.06564432381386204
Trained batch 350 in epoch 15, gen_loss = 0.8530792470840987, disc_loss = 0.06556426318617076
Trained batch 351 in epoch 15, gen_loss = 0.8537734192372723, disc_loss = 0.06563229315824257
Trained batch 352 in epoch 15, gen_loss = 0.8533951904381977, disc_loss = 0.06555739463974455
Trained batch 353 in epoch 15, gen_loss = 0.8533877776672611, disc_loss = 0.06550468215955642
Trained batch 354 in epoch 15, gen_loss = 0.8529922553351228, disc_loss = 0.06552128646863808
Trained batch 355 in epoch 15, gen_loss = 0.8536779248480046, disc_loss = 0.06537041658132724
Trained batch 356 in epoch 15, gen_loss = 0.8544435698945984, disc_loss = 0.06521834805477358
Trained batch 357 in epoch 15, gen_loss = 0.8544690146959028, disc_loss = 0.06509762157311444
Trained batch 358 in epoch 15, gen_loss = 0.8553994366883567, disc_loss = 0.06496959265119144
Trained batch 359 in epoch 15, gen_loss = 0.8553268890413973, disc_loss = 0.06484265705544709
Trained batch 360 in epoch 15, gen_loss = 0.8557305141994498, disc_loss = 0.06468709997724421
Trained batch 361 in epoch 15, gen_loss = 0.8561701656869762, disc_loss = 0.06453392761296371
Trained batch 362 in epoch 15, gen_loss = 0.8564530091344817, disc_loss = 0.06437773101632137
Trained batch 363 in epoch 15, gen_loss = 0.8566567785628549, disc_loss = 0.06422383515906244
Trained batch 364 in epoch 15, gen_loss = 0.8570254026210471, disc_loss = 0.06423744030220256
Trained batch 365 in epoch 15, gen_loss = 0.8568174576010209, disc_loss = 0.06410457175148682
Trained batch 366 in epoch 15, gen_loss = 0.8562971653178213, disc_loss = 0.06406156402664914
Trained batch 367 in epoch 15, gen_loss = 0.8566924117343582, disc_loss = 0.06391910900508621
Trained batch 368 in epoch 15, gen_loss = 0.856750665237587, disc_loss = 0.0638502547959103
Trained batch 369 in epoch 15, gen_loss = 0.8571804110262845, disc_loss = 0.06371440297319882
Trained batch 370 in epoch 15, gen_loss = 0.8574998299227249, disc_loss = 0.06356245220947579
Trained batch 371 in epoch 15, gen_loss = 0.8574439191850283, disc_loss = 0.06342984686770867
Trained batch 372 in epoch 15, gen_loss = 0.8573091657327903, disc_loss = 0.06331697053303467
Trained batch 373 in epoch 15, gen_loss = 0.8583621185890493, disc_loss = 0.06322680256717943
Trained batch 374 in epoch 15, gen_loss = 0.8587657436529795, disc_loss = 0.06315222452456752
Trained batch 375 in epoch 15, gen_loss = 0.8597689116413288, disc_loss = 0.06304692530860886
Trained batch 376 in epoch 15, gen_loss = 0.8595988529904768, disc_loss = 0.06303226718906343
Trained batch 377 in epoch 15, gen_loss = 0.8595151271296557, disc_loss = 0.06290068564488104
Trained batch 378 in epoch 15, gen_loss = 0.8595948805123331, disc_loss = 0.06275430461391807
Trained batch 379 in epoch 15, gen_loss = 0.8596674661103048, disc_loss = 0.06261983149268321
Trained batch 380 in epoch 15, gen_loss = 0.8598346909669441, disc_loss = 0.06247835472504806
Trained batch 381 in epoch 15, gen_loss = 0.8602123144253386, disc_loss = 0.062472768265666216
Trained batch 382 in epoch 15, gen_loss = 0.8595603871750147, disc_loss = 0.06247657520074018
Trained batch 383 in epoch 15, gen_loss = 0.8599433662214627, disc_loss = 0.06233357284145313
Trained batch 384 in epoch 15, gen_loss = 0.8603080593920374, disc_loss = 0.06219102188267491
Trained batch 385 in epoch 15, gen_loss = 0.8605019721188076, disc_loss = 0.06205503357371672
Trained batch 386 in epoch 15, gen_loss = 0.8604494411045883, disc_loss = 0.0619257242666697
Trained batch 387 in epoch 15, gen_loss = 0.8605921186276317, disc_loss = 0.061820392993749265
Trained batch 388 in epoch 15, gen_loss = 0.8605822630437296, disc_loss = 0.061773066547792646
Trained batch 389 in epoch 15, gen_loss = 0.859926815598439, disc_loss = 0.06198991950458059
Trained batch 390 in epoch 15, gen_loss = 0.8604203173723977, disc_loss = 0.061910715952153555
Trained batch 391 in epoch 15, gen_loss = 0.8610770678793898, disc_loss = 0.06179043015569677
Trained batch 392 in epoch 15, gen_loss = 0.8612449979812438, disc_loss = 0.0616553511835502
Trained batch 393 in epoch 15, gen_loss = 0.861096087521708, disc_loss = 0.0615406253914051
Trained batch 394 in epoch 15, gen_loss = 0.8614323177669622, disc_loss = 0.061422532931253125
Trained batch 395 in epoch 15, gen_loss = 0.8619375649576235, disc_loss = 0.06129428018543004
Trained batch 396 in epoch 15, gen_loss = 0.8624549037413273, disc_loss = 0.06117090654162976
Trained batch 397 in epoch 15, gen_loss = 0.8623555622358418, disc_loss = 0.061165106852524846
Trained batch 398 in epoch 15, gen_loss = 0.8622990790614509, disc_loss = 0.06111612540662737
Trained batch 399 in epoch 15, gen_loss = 0.8621377063542605, disc_loss = 0.06100608414504677
Trained batch 400 in epoch 15, gen_loss = 0.8628682169385087, disc_loss = 0.06097650154960572
Trained batch 401 in epoch 15, gen_loss = 0.8635839651621396, disc_loss = 0.06104713727011165
Trained batch 402 in epoch 15, gen_loss = 0.8634618014171165, disc_loss = 0.06092937342896503
Trained batch 403 in epoch 15, gen_loss = 0.8629400058105441, disc_loss = 0.06099102596780009
Trained batch 404 in epoch 15, gen_loss = 0.8636250046300299, disc_loss = 0.06091361609230071
Trained batch 405 in epoch 15, gen_loss = 0.8633318290187808, disc_loss = 0.06082034224800288
Trained batch 406 in epoch 15, gen_loss = 0.8633401876439041, disc_loss = 0.06080593479023812
Trained batch 407 in epoch 15, gen_loss = 0.863433591510151, disc_loss = 0.06067558569495803
Trained batch 408 in epoch 15, gen_loss = 0.8635279707483091, disc_loss = 0.06056436791351124
Trained batch 409 in epoch 15, gen_loss = 0.8647635600188883, disc_loss = 0.06053464625984794
Trained batch 410 in epoch 15, gen_loss = 0.864517265065163, disc_loss = 0.06043913758103792
Trained batch 411 in epoch 15, gen_loss = 0.8646973897386523, disc_loss = 0.060333109304797156
Trained batch 412 in epoch 15, gen_loss = 0.8646199434057563, disc_loss = 0.060210323716642346
Trained batch 413 in epoch 15, gen_loss = 0.8645987070844945, disc_loss = 0.060090381568882634
Trained batch 414 in epoch 15, gen_loss = 0.8648860340376935, disc_loss = 0.06000975454562759
Trained batch 415 in epoch 15, gen_loss = 0.8650849637073966, disc_loss = 0.06011320961988531
Trained batch 416 in epoch 15, gen_loss = 0.8646585278802639, disc_loss = 0.06014596797499082
Trained batch 417 in epoch 15, gen_loss = 0.8641642438310185, disc_loss = 0.06020128204482808
Trained batch 418 in epoch 15, gen_loss = 0.8641185422643557, disc_loss = 0.060153349991754444
Trained batch 419 in epoch 15, gen_loss = 0.8642193823343232, disc_loss = 0.06010046263136679
Trained batch 420 in epoch 15, gen_loss = 0.8640955559856252, disc_loss = 0.0600013534500841
Trained batch 421 in epoch 15, gen_loss = 0.8644045713529768, disc_loss = 0.05988704288042905
Trained batch 422 in epoch 15, gen_loss = 0.8647848345850094, disc_loss = 0.0597618146828127
Trained batch 423 in epoch 15, gen_loss = 0.8646130719977729, disc_loss = 0.059742066251412734
Trained batch 424 in epoch 15, gen_loss = 0.8650262942734886, disc_loss = 0.059889144860208035
Trained batch 425 in epoch 15, gen_loss = 0.8646823675000052, disc_loss = 0.06005674610876351
Trained batch 426 in epoch 15, gen_loss = 0.8644841492734413, disc_loss = 0.060058842417489586
Trained batch 427 in epoch 15, gen_loss = 0.8642313223436614, disc_loss = 0.06001309041482196
Trained batch 428 in epoch 15, gen_loss = 0.8646401552470414, disc_loss = 0.05995478999251739
Trained batch 429 in epoch 15, gen_loss = 0.8653276977844017, disc_loss = 0.059908079587702834
Trained batch 430 in epoch 15, gen_loss = 0.8655123766641329, disc_loss = 0.05984879164738265
Trained batch 431 in epoch 15, gen_loss = 0.8646989406120998, disc_loss = 0.060153749174248705
Trained batch 432 in epoch 15, gen_loss = 0.8651770914261666, disc_loss = 0.06014986658645213
Trained batch 433 in epoch 15, gen_loss = 0.8660294423866931, disc_loss = 0.060323592453491164
Trained batch 434 in epoch 15, gen_loss = 0.865697432317953, disc_loss = 0.0602461742408488
Trained batch 435 in epoch 15, gen_loss = 0.8655435841428031, disc_loss = 0.06025614727655887
Trained batch 436 in epoch 15, gen_loss = 0.8653529321165325, disc_loss = 0.06029997675443064
Trained batch 437 in epoch 15, gen_loss = 0.8642849335659585, disc_loss = 0.06098932267451599
Trained batch 438 in epoch 15, gen_loss = 0.8652240096300773, disc_loss = 0.062056763787119565
Trained batch 439 in epoch 15, gen_loss = 0.8656641595742919, disc_loss = 0.06222686325411566
Trained batch 440 in epoch 15, gen_loss = 0.8654913522488946, disc_loss = 0.06216325987417614
Trained batch 441 in epoch 15, gen_loss = 0.8648533195392039, disc_loss = 0.06238457556957236
Trained batch 442 in epoch 15, gen_loss = 0.864709664951867, disc_loss = 0.062326600331535593
Trained batch 443 in epoch 15, gen_loss = 0.8649983626228195, disc_loss = 0.06227658987506754
Trained batch 444 in epoch 15, gen_loss = 0.8653891346427832, disc_loss = 0.06220004769314206
Trained batch 445 in epoch 15, gen_loss = 0.8651391905252175, disc_loss = 0.06215914195787679
Trained batch 446 in epoch 15, gen_loss = 0.8642457568938834, disc_loss = 0.062480504987073825
Trained batch 447 in epoch 15, gen_loss = 0.8641304107648986, disc_loss = 0.06245090941125194
Trained batch 448 in epoch 15, gen_loss = 0.8647503597964689, disc_loss = 0.06298049649468443
Trained batch 449 in epoch 15, gen_loss = 0.8641805509726207, disc_loss = 0.06302541561217771
Trained batch 450 in epoch 15, gen_loss = 0.8639933540921518, disc_loss = 0.06298753215070244
Trained batch 451 in epoch 15, gen_loss = 0.8637712802243444, disc_loss = 0.06289939503844795
Trained batch 452 in epoch 15, gen_loss = 0.8635629195777522, disc_loss = 0.0628347738191617
Trained batch 453 in epoch 15, gen_loss = 0.863202032407475, disc_loss = 0.06279472639734984
Trained batch 454 in epoch 15, gen_loss = 0.8629914693779998, disc_loss = 0.06273873472729555
Trained batch 455 in epoch 15, gen_loss = 0.8632573132452211, disc_loss = 0.06267013497805844
Trained batch 456 in epoch 15, gen_loss = 0.862671835286873, disc_loss = 0.06271048495647878
Trained batch 457 in epoch 15, gen_loss = 0.8632872915424114, disc_loss = 0.06285506453340686
Trained batch 458 in epoch 15, gen_loss = 0.8634055785364055, disc_loss = 0.06280164235354703
Trained batch 459 in epoch 15, gen_loss = 0.8631524827169336, disc_loss = 0.06280927617386307
Trained batch 460 in epoch 15, gen_loss = 0.8627766445763975, disc_loss = 0.06275780507668433
Trained batch 461 in epoch 15, gen_loss = 0.8627000008568619, disc_loss = 0.06269042379146209
Trained batch 462 in epoch 15, gen_loss = 0.8631510151385231, disc_loss = 0.0626131803034674
Trained batch 463 in epoch 15, gen_loss = 0.8636905611332121, disc_loss = 0.06252862294084104
Trained batch 464 in epoch 15, gen_loss = 0.863463346932524, disc_loss = 0.06257522935548457
Trained batch 465 in epoch 15, gen_loss = 0.8630285564921957, disc_loss = 0.06268153946582916
Trained batch 466 in epoch 15, gen_loss = 0.8624122902208529, disc_loss = 0.06279069266024762
Trained batch 467 in epoch 15, gen_loss = 0.8631011394099293, disc_loss = 0.06276081444528432
Trained batch 468 in epoch 15, gen_loss = 0.8631752381192596, disc_loss = 0.06288276955302653
Trained batch 469 in epoch 15, gen_loss = 0.863745068489237, disc_loss = 0.06292205571216788
Trained batch 470 in epoch 15, gen_loss = 0.8633227292646015, disc_loss = 0.06321203333153656
Trained batch 471 in epoch 15, gen_loss = 0.8630375849493479, disc_loss = 0.06324190110702194
Trained batch 472 in epoch 15, gen_loss = 0.8630868418272152, disc_loss = 0.06314663274950066
Trained batch 473 in epoch 15, gen_loss = 0.8633157392091388, disc_loss = 0.0630530388220233
Trained batch 474 in epoch 15, gen_loss = 0.8639565809149491, disc_loss = 0.06318028095717493
Trained batch 475 in epoch 15, gen_loss = 0.8637969118206441, disc_loss = 0.06313291801131886
Trained batch 476 in epoch 15, gen_loss = 0.8631659701185407, disc_loss = 0.06330681201929629
Trained batch 477 in epoch 15, gen_loss = 0.863166699100239, disc_loss = 0.06322129378017334
Trained batch 478 in epoch 15, gen_loss = 0.8629871132727207, disc_loss = 0.0631492523289828
Trained batch 479 in epoch 15, gen_loss = 0.8631008024017016, disc_loss = 0.06307206227405307
Trained batch 480 in epoch 15, gen_loss = 0.8629650647080118, disc_loss = 0.06298823978194266
Trained batch 481 in epoch 15, gen_loss = 0.862785392653398, disc_loss = 0.06299548319258816
Trained batch 482 in epoch 15, gen_loss = 0.8631193054141959, disc_loss = 0.0630458738967221
Trained batch 483 in epoch 15, gen_loss = 0.8626048266887665, disc_loss = 0.06317567671187345
Trained batch 484 in epoch 15, gen_loss = 0.8618946876722513, disc_loss = 0.0632646325918049
Trained batch 485 in epoch 15, gen_loss = 0.8619589990794413, disc_loss = 0.06316512132278133
Trained batch 486 in epoch 15, gen_loss = 0.8621581587213755, disc_loss = 0.06315973964644103
Trained batch 487 in epoch 15, gen_loss = 0.8623440575892808, disc_loss = 0.06316643192043497
Trained batch 488 in epoch 15, gen_loss = 0.8616382001855378, disc_loss = 0.06326333487288291
Trained batch 489 in epoch 15, gen_loss = 0.8611852215260876, disc_loss = 0.06323996574560903
Trained batch 490 in epoch 15, gen_loss = 0.8614061916675684, disc_loss = 0.06329301183819468
Trained batch 491 in epoch 15, gen_loss = 0.8612390464641214, disc_loss = 0.06326185198447751
Trained batch 492 in epoch 15, gen_loss = 0.8617420529013473, disc_loss = 0.06326039092951505
Trained batch 493 in epoch 15, gen_loss = 0.861943972376194, disc_loss = 0.06316793597442841
Trained batch 494 in epoch 15, gen_loss = 0.8612121672943385, disc_loss = 0.063336406111943
Trained batch 495 in epoch 15, gen_loss = 0.8611689699633468, disc_loss = 0.06327947821550732
Trained batch 496 in epoch 15, gen_loss = 0.8614018080340065, disc_loss = 0.06322941129888507
Trained batch 497 in epoch 15, gen_loss = 0.8611966422403673, disc_loss = 0.06322811934236722
Trained batch 498 in epoch 15, gen_loss = 0.8612130097372976, disc_loss = 0.06314793852659946
Trained batch 499 in epoch 15, gen_loss = 0.8611481309533119, disc_loss = 0.0630575122255832
Trained batch 500 in epoch 15, gen_loss = 0.8609657244173115, disc_loss = 0.06304022909407904
Trained batch 501 in epoch 15, gen_loss = 0.8606128901005741, disc_loss = 0.06299315052537388
Trained batch 502 in epoch 15, gen_loss = 0.8606849601325648, disc_loss = 0.06290691831958282
Trained batch 503 in epoch 15, gen_loss = 0.8608521111309528, disc_loss = 0.06280058596305371
Trained batch 504 in epoch 15, gen_loss = 0.8608544244034455, disc_loss = 0.06270251699935386
Trained batch 505 in epoch 15, gen_loss = 0.861238494515419, disc_loss = 0.06262272027442636
Trained batch 506 in epoch 15, gen_loss = 0.8612393168420246, disc_loss = 0.06252331835726603
Trained batch 507 in epoch 15, gen_loss = 0.8610340715275975, disc_loss = 0.062492163707025525
Trained batch 508 in epoch 15, gen_loss = 0.8614686993929632, disc_loss = 0.06242733396231133
Trained batch 509 in epoch 15, gen_loss = 0.8611917035836799, disc_loss = 0.062392848184076595
Trained batch 510 in epoch 15, gen_loss = 0.8610800507600527, disc_loss = 0.062456924353458294
Trained batch 511 in epoch 15, gen_loss = 0.8609433074598201, disc_loss = 0.062380939760259935
Trained batch 512 in epoch 15, gen_loss = 0.861017555927905, disc_loss = 0.06230210291573934
Trained batch 513 in epoch 15, gen_loss = 0.8613674199418799, disc_loss = 0.062205554741699295
Trained batch 514 in epoch 15, gen_loss = 0.8613870982406209, disc_loss = 0.0621497632718636
Trained batch 515 in epoch 15, gen_loss = 0.8617974982358688, disc_loss = 0.06208377345753906
Trained batch 516 in epoch 15, gen_loss = 0.862195918188796, disc_loss = 0.06199870401780829
Trained batch 517 in epoch 15, gen_loss = 0.8624697661883122, disc_loss = 0.061897695533801804
Trained batch 518 in epoch 15, gen_loss = 0.8623481492201487, disc_loss = 0.06180346069358619
Trained batch 519 in epoch 15, gen_loss = 0.8620582071061318, disc_loss = 0.06180431690031233
Trained batch 520 in epoch 15, gen_loss = 0.862688624641488, disc_loss = 0.061769268718582085
Trained batch 521 in epoch 15, gen_loss = 0.8631890657646902, disc_loss = 0.06170430682934963
Trained batch 522 in epoch 15, gen_loss = 0.8632477892858348, disc_loss = 0.061625532818384766
Trained batch 523 in epoch 15, gen_loss = 0.8631040451067095, disc_loss = 0.06155057799049746
Trained batch 524 in epoch 15, gen_loss = 0.863363709620067, disc_loss = 0.061620985583535265
Trained batch 525 in epoch 15, gen_loss = 0.8632550283189963, disc_loss = 0.06154545858863585
Trained batch 526 in epoch 15, gen_loss = 0.8637405666160403, disc_loss = 0.06144954524828259
Trained batch 527 in epoch 15, gen_loss = 0.8638934382999485, disc_loss = 0.061348772209109455
Trained batch 528 in epoch 15, gen_loss = 0.8639814159031852, disc_loss = 0.061252200007720345
Trained batch 529 in epoch 15, gen_loss = 0.8642086143201252, disc_loss = 0.06118160871402273
Trained batch 530 in epoch 15, gen_loss = 0.8643857194093212, disc_loss = 0.061093907192938744
Trained batch 531 in epoch 15, gen_loss = 0.864556941154756, disc_loss = 0.06101384781357041
Trained batch 532 in epoch 15, gen_loss = 0.8644506258655892, disc_loss = 0.06092359804623458
Trained batch 533 in epoch 15, gen_loss = 0.8642268203729101, disc_loss = 0.0608476847898536
Trained batch 534 in epoch 15, gen_loss = 0.8644707551069348, disc_loss = 0.06081577992049333
Trained batch 535 in epoch 15, gen_loss = 0.8652598464778111, disc_loss = 0.06075843690143926
Trained batch 536 in epoch 15, gen_loss = 0.8649479027011985, disc_loss = 0.060732226253416066
Trained batch 537 in epoch 15, gen_loss = 0.865263035140073, disc_loss = 0.0606297087582126
Trained batch 538 in epoch 15, gen_loss = 0.8656669351408787, disc_loss = 0.06057198896852075
Trained batch 539 in epoch 15, gen_loss = 0.866132960330557, disc_loss = 0.06049723519978148
Trained batch 540 in epoch 15, gen_loss = 0.8664516462305778, disc_loss = 0.06040019287715723
Trained batch 541 in epoch 15, gen_loss = 0.8663583135582864, disc_loss = 0.060363960117307866
Trained batch 542 in epoch 15, gen_loss = 0.8664503343965906, disc_loss = 0.06028389664363411
Trained batch 543 in epoch 15, gen_loss = 0.8667577781769282, disc_loss = 0.06019519565469476
Trained batch 544 in epoch 15, gen_loss = 0.8671030968154242, disc_loss = 0.06009563970029217
Trained batch 545 in epoch 15, gen_loss = 0.8670602348588762, disc_loss = 0.05999919658461961
Trained batch 546 in epoch 15, gen_loss = 0.8673538492083331, disc_loss = 0.05991742654977676
Trained batch 547 in epoch 15, gen_loss = 0.8676146048590214, disc_loss = 0.05982712161281982
Trained batch 548 in epoch 15, gen_loss = 0.8679055252904666, disc_loss = 0.05974005258816866
Trained batch 549 in epoch 15, gen_loss = 0.8679468722235073, disc_loss = 0.059657798037779604
Trained batch 550 in epoch 15, gen_loss = 0.8677725006036879, disc_loss = 0.05961894341397983
Trained batch 551 in epoch 15, gen_loss = 0.8677777236030586, disc_loss = 0.059554324047538736
Trained batch 552 in epoch 15, gen_loss = 0.8674893148014385, disc_loss = 0.059507444683651003
Trained batch 553 in epoch 15, gen_loss = 0.8682495268996442, disc_loss = 0.05957460763279201
Trained batch 554 in epoch 15, gen_loss = 0.8679515398837424, disc_loss = 0.05963440132788844
Trained batch 555 in epoch 15, gen_loss = 0.8684594573841679, disc_loss = 0.05956725299562723
Trained batch 556 in epoch 15, gen_loss = 0.8688720426717823, disc_loss = 0.0595015314628355
Trained batch 557 in epoch 15, gen_loss = 0.8689743274535757, disc_loss = 0.05941155969872937
Trained batch 558 in epoch 15, gen_loss = 0.8693126990778075, disc_loss = 0.05933345644110031
Trained batch 559 in epoch 15, gen_loss = 0.8697302231299026, disc_loss = 0.05925471250915767
Trained batch 560 in epoch 15, gen_loss = 0.8694546295466058, disc_loss = 0.05921611611261539
Trained batch 561 in epoch 15, gen_loss = 0.8693130882291183, disc_loss = 0.059214974973132016
Trained batch 562 in epoch 15, gen_loss = 0.8696958153222425, disc_loss = 0.05913090098196009
Trained batch 563 in epoch 15, gen_loss = 0.8699438523844625, disc_loss = 0.05904397795534964
Trained batch 564 in epoch 15, gen_loss = 0.8703188911475966, disc_loss = 0.05903914367483385
Trained batch 565 in epoch 15, gen_loss = 0.8704630530870424, disc_loss = 0.05895619793110544
Trained batch 566 in epoch 15, gen_loss = 0.8706092437633972, disc_loss = 0.05886604930019594
Trained batch 567 in epoch 15, gen_loss = 0.8703884924696365, disc_loss = 0.05880772801932656
Trained batch 568 in epoch 15, gen_loss = 0.8704542518185815, disc_loss = 0.05873063621348546
Trained batch 569 in epoch 15, gen_loss = 0.87076241211933, disc_loss = 0.05864780493848549
Trained batch 570 in epoch 15, gen_loss = 0.870898019672484, disc_loss = 0.05855332487776562
Trained batch 571 in epoch 15, gen_loss = 0.8715844652973689, disc_loss = 0.058529062553999256
Trained batch 572 in epoch 15, gen_loss = 0.8718722449651355, disc_loss = 0.05844307209675511
Trained batch 573 in epoch 15, gen_loss = 0.8716107679057205, disc_loss = 0.058408304872899885
Trained batch 574 in epoch 15, gen_loss = 0.8715691565948984, disc_loss = 0.058317751788898656
Trained batch 575 in epoch 15, gen_loss = 0.8715292002695302, disc_loss = 0.05826135063964304
Trained batch 576 in epoch 15, gen_loss = 0.8717084076107064, disc_loss = 0.05817284516302588
Trained batch 577 in epoch 15, gen_loss = 0.8722325747503954, disc_loss = 0.058108626428998
Trained batch 578 in epoch 15, gen_loss = 0.8726380380427076, disc_loss = 0.058040402005289864
Trained batch 579 in epoch 15, gen_loss = 0.8729213655508797, disc_loss = 0.05795721139774883
Trained batch 580 in epoch 15, gen_loss = 0.8729566085872059, disc_loss = 0.05790392144722624
Trained batch 581 in epoch 15, gen_loss = 0.8727298992913204, disc_loss = 0.057858587061039
Trained batch 582 in epoch 15, gen_loss = 0.8723926335113126, disc_loss = 0.05785728939992614
Trained batch 583 in epoch 15, gen_loss = 0.8727193829437642, disc_loss = 0.057813493204016034
Trained batch 584 in epoch 15, gen_loss = 0.8727902689041236, disc_loss = 0.05773119164121329
Trained batch 585 in epoch 15, gen_loss = 0.8728995381666939, disc_loss = 0.0576528616562651
Trained batch 586 in epoch 15, gen_loss = 0.8729948574578742, disc_loss = 0.057568631955982524
Trained batch 587 in epoch 15, gen_loss = 0.8731752236177321, disc_loss = 0.05751095523465374
Trained batch 588 in epoch 15, gen_loss = 0.8729105380779616, disc_loss = 0.057465485903530907
Trained batch 589 in epoch 15, gen_loss = 0.8729239607766524, disc_loss = 0.05738339687350317
Trained batch 590 in epoch 15, gen_loss = 0.8729219320159273, disc_loss = 0.057352907866611444
Trained batch 591 in epoch 15, gen_loss = 0.8730121509146851, disc_loss = 0.05727512858307769
Trained batch 592 in epoch 15, gen_loss = 0.8730957466373959, disc_loss = 0.05718981286096206
Trained batch 593 in epoch 15, gen_loss = 0.8728163591037295, disc_loss = 0.05713000765888754
Trained batch 594 in epoch 15, gen_loss = 0.8732690271710147, disc_loss = 0.0570480721611373
Trained batch 595 in epoch 15, gen_loss = 0.8736400893770608, disc_loss = 0.05697366088900665
Trained batch 596 in epoch 15, gen_loss = 0.8735143011638667, disc_loss = 0.05693469122847795
Trained batch 597 in epoch 15, gen_loss = 0.8734472249961617, disc_loss = 0.05686455196078032
Trained batch 598 in epoch 15, gen_loss = 0.8737536771767127, disc_loss = 0.05678529373427638
Trained batch 599 in epoch 15, gen_loss = 0.8740407206118107, disc_loss = 0.05671238863763089
Trained batch 600 in epoch 15, gen_loss = 0.8746119879942369, disc_loss = 0.05675746710543302
Trained batch 601 in epoch 15, gen_loss = 0.8747468194197182, disc_loss = 0.05669619118179074
Trained batch 602 in epoch 15, gen_loss = 0.8746253637037862, disc_loss = 0.05670417014858492
Trained batch 603 in epoch 15, gen_loss = 0.8745212078785265, disc_loss = 0.05664943931362166
Trained batch 604 in epoch 15, gen_loss = 0.8746880934750738, disc_loss = 0.056584101563612044
Trained batch 605 in epoch 15, gen_loss = 0.8749181191028148, disc_loss = 0.05652138641758794
Trained batch 606 in epoch 15, gen_loss = 0.8746401579709973, disc_loss = 0.05648653410433422
Trained batch 607 in epoch 15, gen_loss = 0.8742819789699033, disc_loss = 0.056507315449140914
Trained batch 608 in epoch 15, gen_loss = 0.8746377059880932, disc_loss = 0.05654592731239638
Trained batch 609 in epoch 15, gen_loss = 0.8747933034525543, disc_loss = 0.05648800201149138
Trained batch 610 in epoch 15, gen_loss = 0.8747061877808673, disc_loss = 0.05645197947508063
Trained batch 611 in epoch 15, gen_loss = 0.8744474553497009, disc_loss = 0.05638698230914504
Trained batch 612 in epoch 15, gen_loss = 0.8742172340292721, disc_loss = 0.05637839361098496
Trained batch 613 in epoch 15, gen_loss = 0.874167319083835, disc_loss = 0.056303654083715154
Trained batch 614 in epoch 15, gen_loss = 0.8746798471222079, disc_loss = 0.05636153308280963
Trained batch 615 in epoch 15, gen_loss = 0.8746421604671262, disc_loss = 0.05629348001282589
Trained batch 616 in epoch 15, gen_loss = 0.8748580753030422, disc_loss = 0.056227221302356044
Trained batch 617 in epoch 15, gen_loss = 0.8743828698558714, disc_loss = 0.0563798378391981
Trained batch 618 in epoch 15, gen_loss = 0.874261509380356, disc_loss = 0.05634468078526017
Trained batch 619 in epoch 15, gen_loss = 0.8741835559087415, disc_loss = 0.05631269385602566
Trained batch 620 in epoch 15, gen_loss = 0.8745414929977362, disc_loss = 0.05633947364431049
Trained batch 621 in epoch 15, gen_loss = 0.8744067448607595, disc_loss = 0.05631640826208199
Trained batch 622 in epoch 15, gen_loss = 0.87499996732747, disc_loss = 0.056299134475264224
Trained batch 623 in epoch 15, gen_loss = 0.8747024559535277, disc_loss = 0.056289636776991524
Trained batch 624 in epoch 15, gen_loss = 0.8743876762866973, disc_loss = 0.05627999542579055
Trained batch 625 in epoch 15, gen_loss = 0.8743037609532237, disc_loss = 0.05621746623034651
Trained batch 626 in epoch 15, gen_loss = 0.8747361848514046, disc_loss = 0.05617769624209076
Trained batch 627 in epoch 15, gen_loss = 0.8748175408335248, disc_loss = 0.05609949396561333
Trained batch 628 in epoch 15, gen_loss = 0.8745029319924656, disc_loss = 0.05604584075788862
Trained batch 629 in epoch 15, gen_loss = 0.874074086736119, disc_loss = 0.05612359174808103
Trained batch 630 in epoch 15, gen_loss = 0.8749280805727571, disc_loss = 0.05650647157115386
Trained batch 631 in epoch 15, gen_loss = 0.8748663267285763, disc_loss = 0.05657059469560892
Trained batch 632 in epoch 15, gen_loss = 0.8744147667105164, disc_loss = 0.056794296945688
Trained batch 633 in epoch 15, gen_loss = 0.873843678775646, disc_loss = 0.056880857021333386
Trained batch 634 in epoch 15, gen_loss = 0.8743476969519938, disc_loss = 0.05753040798448437
Trained batch 635 in epoch 15, gen_loss = 0.8742561595713567, disc_loss = 0.057503945342083494
Trained batch 636 in epoch 15, gen_loss = 0.8740206359413393, disc_loss = 0.05752337933481441
Trained batch 637 in epoch 15, gen_loss = 0.873728703882627, disc_loss = 0.05757636658783103
Trained batch 638 in epoch 15, gen_loss = 0.8735925777697228, disc_loss = 0.05754683549910877
Trained batch 639 in epoch 15, gen_loss = 0.8733588153030724, disc_loss = 0.057531010523962325
Trained batch 640 in epoch 15, gen_loss = 0.8732422984985405, disc_loss = 0.057537393642999174
Trained batch 641 in epoch 15, gen_loss = 0.8729553758819527, disc_loss = 0.05752399744396316
Trained batch 642 in epoch 15, gen_loss = 0.8731473733904203, disc_loss = 0.05746003643147543
Trained batch 643 in epoch 15, gen_loss = 0.8730175817697685, disc_loss = 0.05742255862229591
Trained batch 644 in epoch 15, gen_loss = 0.8727900686652161, disc_loss = 0.05740249808588924
Trained batch 645 in epoch 15, gen_loss = 0.8722486954078585, disc_loss = 0.057486524097563774
Trained batch 646 in epoch 15, gen_loss = 0.8725166652910123, disc_loss = 0.05748735539402116
Trained batch 647 in epoch 15, gen_loss = 0.8727808867431717, disc_loss = 0.05753483492909804
Trained batch 648 in epoch 15, gen_loss = 0.8727384160498074, disc_loss = 0.05750444483367844
Trained batch 649 in epoch 15, gen_loss = 0.8728559385354703, disc_loss = 0.057437783016894874
Trained batch 650 in epoch 15, gen_loss = 0.872535533848263, disc_loss = 0.05757555882439315
Trained batch 651 in epoch 15, gen_loss = 0.8726920003265691, disc_loss = 0.057625120695668955
Trained batch 652 in epoch 15, gen_loss = 0.8724909265501394, disc_loss = 0.05767104462798896
Trained batch 653 in epoch 15, gen_loss = 0.8719039372985881, disc_loss = 0.0578859899070581
Trained batch 654 in epoch 15, gen_loss = 0.8719690228691538, disc_loss = 0.057916413425318614
Trained batch 655 in epoch 15, gen_loss = 0.8724121077485928, disc_loss = 0.057910557445876934
Trained batch 656 in epoch 15, gen_loss = 0.8722097573850072, disc_loss = 0.05788071069276723
Trained batch 657 in epoch 15, gen_loss = 0.8721849874431964, disc_loss = 0.057875759187678164
Trained batch 658 in epoch 15, gen_loss = 0.8717960293358121, disc_loss = 0.05794001679460494
Trained batch 659 in epoch 15, gen_loss = 0.8717758089755521, disc_loss = 0.0578893221420885
Trained batch 660 in epoch 15, gen_loss = 0.8718904743306395, disc_loss = 0.057961121738328965
Trained batch 661 in epoch 15, gen_loss = 0.8718432758419895, disc_loss = 0.057972139548060124
Trained batch 662 in epoch 15, gen_loss = 0.8715007385607039, disc_loss = 0.057994495808999555
Trained batch 663 in epoch 15, gen_loss = 0.8712539105081415, disc_loss = 0.058028330472410176
Trained batch 664 in epoch 15, gen_loss = 0.8711711381162915, disc_loss = 0.05806058743422417
Trained batch 665 in epoch 15, gen_loss = 0.8711066039743366, disc_loss = 0.05800946853221492
Trained batch 666 in epoch 15, gen_loss = 0.8711571480291358, disc_loss = 0.057966625020522314
Trained batch 667 in epoch 15, gen_loss = 0.8707536846666992, disc_loss = 0.058000649951543366
Trained batch 668 in epoch 15, gen_loss = 0.8707096619901814, disc_loss = 0.05799585753029995
Trained batch 669 in epoch 15, gen_loss = 0.8709193247912536, disc_loss = 0.05792723833652797
Trained batch 670 in epoch 15, gen_loss = 0.8705210896700221, disc_loss = 0.05802296816708656
Trained batch 671 in epoch 15, gen_loss = 0.8704368623328351, disc_loss = 0.0580261499313305
Trained batch 672 in epoch 15, gen_loss = 0.8704516534730903, disc_loss = 0.05844327348684352
Trained batch 673 in epoch 15, gen_loss = 0.8703278014408729, disc_loss = 0.05851250444331624
Trained batch 674 in epoch 15, gen_loss = 0.8703156074329659, disc_loss = 0.05846007305024951
Trained batch 675 in epoch 15, gen_loss = 0.8696274072725392, disc_loss = 0.05889504233005969
Trained batch 676 in epoch 15, gen_loss = 0.8699003704101331, disc_loss = 0.05898610961264442
Trained batch 677 in epoch 15, gen_loss = 0.8698513818613548, disc_loss = 0.058949233028642106
Trained batch 678 in epoch 15, gen_loss = 0.869805792601716, disc_loss = 0.058938508327990025
Trained batch 679 in epoch 15, gen_loss = 0.8697675113730571, disc_loss = 0.058881767276291026
Trained batch 680 in epoch 15, gen_loss = 0.8697890119843196, disc_loss = 0.05881375355014192
Trained batch 681 in epoch 15, gen_loss = 0.8695492515029096, disc_loss = 0.05880776998147237
Trained batch 682 in epoch 15, gen_loss = 0.8698076909928859, disc_loss = 0.05875225772325762
Trained batch 683 in epoch 15, gen_loss = 0.8695634328569585, disc_loss = 0.05873096039605855
Trained batch 684 in epoch 15, gen_loss = 0.8693619792913868, disc_loss = 0.05867968178524153
Trained batch 685 in epoch 15, gen_loss = 0.8691128027943064, disc_loss = 0.05869908690311384
Trained batch 686 in epoch 15, gen_loss = 0.8693751838963799, disc_loss = 0.05871811424269513
Trained batch 687 in epoch 15, gen_loss = 0.8691914803673362, disc_loss = 0.058676338605691006
Trained batch 688 in epoch 15, gen_loss = 0.8688752507177251, disc_loss = 0.05866758165548519
Trained batch 689 in epoch 15, gen_loss = 0.8690427593994832, disc_loss = 0.05859632310390041
Trained batch 690 in epoch 15, gen_loss = 0.8691986781557114, disc_loss = 0.05854237725211553
Trained batch 691 in epoch 15, gen_loss = 0.8690361274201746, disc_loss = 0.05852285198425885
Trained batch 692 in epoch 15, gen_loss = 0.8689057638204803, disc_loss = 0.058489665956186696
Trained batch 693 in epoch 15, gen_loss = 0.8692905853478297, disc_loss = 0.058589472644761074
Trained batch 694 in epoch 15, gen_loss = 0.8689541119036914, disc_loss = 0.05864684525743234
Trained batch 695 in epoch 15, gen_loss = 0.868840314576338, disc_loss = 0.05861891268474189
Trained batch 696 in epoch 15, gen_loss = 0.8686379098909315, disc_loss = 0.05856889098016826
Trained batch 697 in epoch 15, gen_loss = 0.8688819130460991, disc_loss = 0.058619713018458856
Trained batch 698 in epoch 15, gen_loss = 0.8685596937870604, disc_loss = 0.05859568273017079
Trained batch 699 in epoch 15, gen_loss = 0.8686503876532827, disc_loss = 0.05861667589683618
Trained batch 700 in epoch 15, gen_loss = 0.8685695395915213, disc_loss = 0.05866503676455388
Trained batch 701 in epoch 15, gen_loss = 0.8681584217524596, disc_loss = 0.05875883642265685
Trained batch 702 in epoch 15, gen_loss = 0.8682632560326399, disc_loss = 0.05869740212354729
Trained batch 703 in epoch 15, gen_loss = 0.8682158907282759, disc_loss = 0.058686684400361795
Trained batch 704 in epoch 15, gen_loss = 0.8678787001058565, disc_loss = 0.0587972183242863
Trained batch 705 in epoch 15, gen_loss = 0.8678768188943269, disc_loss = 0.05876079090493639
Trained batch 706 in epoch 15, gen_loss = 0.8676639986257405, disc_loss = 0.058751249041729715
Trained batch 707 in epoch 15, gen_loss = 0.8676623124103088, disc_loss = 0.05870483636377263
Trained batch 708 in epoch 15, gen_loss = 0.867900944689265, disc_loss = 0.058641592819606216
Trained batch 709 in epoch 15, gen_loss = 0.8678723932571815, disc_loss = 0.05862246509772581
Trained batch 710 in epoch 15, gen_loss = 0.8675837098043176, disc_loss = 0.05860810801675006
Trained batch 711 in epoch 15, gen_loss = 0.8674044169150712, disc_loss = 0.058727625552093966
Trained batch 712 in epoch 15, gen_loss = 0.8673475673539776, disc_loss = 0.05869435158337442
Trained batch 713 in epoch 15, gen_loss = 0.867453764758858, disc_loss = 0.05865198402360332
Trained batch 714 in epoch 15, gen_loss = 0.8672520587077508, disc_loss = 0.05868820684955462
Trained batch 715 in epoch 15, gen_loss = 0.8670304863396303, disc_loss = 0.058699741453587924
Trained batch 716 in epoch 15, gen_loss = 0.8673339689376464, disc_loss = 0.05875498406989097
Trained batch 717 in epoch 15, gen_loss = 0.8673940454933968, disc_loss = 0.05875740161238233
Trained batch 718 in epoch 15, gen_loss = 0.8676331344582606, disc_loss = 0.058761631392502074
Trained batch 719 in epoch 15, gen_loss = 0.8676845629596048, disc_loss = 0.05869657975854352
Trained batch 720 in epoch 15, gen_loss = 0.8677458817271022, disc_loss = 0.05865789516008719
Trained batch 721 in epoch 15, gen_loss = 0.8672968119052639, disc_loss = 0.05877941756166125
Trained batch 722 in epoch 15, gen_loss = 0.8675948026516626, disc_loss = 0.05913722024712696
Trained batch 723 in epoch 15, gen_loss = 0.8671901584577165, disc_loss = 0.0592070325131101
Trained batch 724 in epoch 15, gen_loss = 0.8669616623993578, disc_loss = 0.05930451347010917
Trained batch 725 in epoch 15, gen_loss = 0.866519502577046, disc_loss = 0.059481078426587106
Trained batch 726 in epoch 15, gen_loss = 0.8661460593199304, disc_loss = 0.05966724784458069
Trained batch 727 in epoch 15, gen_loss = 0.8663706232967613, disc_loss = 0.059961183704077624
Trained batch 728 in epoch 15, gen_loss = 0.8664285514825656, disc_loss = 0.05997658925787616
Trained batch 729 in epoch 15, gen_loss = 0.8660952065497228, disc_loss = 0.06009723859622258
Trained batch 730 in epoch 15, gen_loss = 0.8659142034406049, disc_loss = 0.06010729806413607
Trained batch 731 in epoch 15, gen_loss = 0.8656953316324395, disc_loss = 0.06009546040475898
Trained batch 732 in epoch 15, gen_loss = 0.8667140205836719, disc_loss = 0.0605155222262745
Trained batch 733 in epoch 15, gen_loss = 0.8661301231433001, disc_loss = 0.06069952939898385
Trained batch 734 in epoch 15, gen_loss = 0.8658653810316203, disc_loss = 0.06076030544809946
Trained batch 735 in epoch 15, gen_loss = 0.8658368651066786, disc_loss = 0.06072615331124879
Trained batch 736 in epoch 15, gen_loss = 0.8656644331470759, disc_loss = 0.06071072644105477
Trained batch 737 in epoch 15, gen_loss = 0.8655603812719749, disc_loss = 0.0606842162024462
Trained batch 738 in epoch 15, gen_loss = 0.8654257626510925, disc_loss = 0.06071557790792077
Trained batch 739 in epoch 15, gen_loss = 0.86517411716081, disc_loss = 0.060722415719332325
Trained batch 740 in epoch 15, gen_loss = 0.8653267471172549, disc_loss = 0.06066276331516372
Trained batch 741 in epoch 15, gen_loss = 0.8652353500821841, disc_loss = 0.06062908931396841
Trained batch 742 in epoch 15, gen_loss = 0.865289877794312, disc_loss = 0.060682104169710725
Trained batch 743 in epoch 15, gen_loss = 0.8649258625202922, disc_loss = 0.06088931152411807
Trained batch 744 in epoch 15, gen_loss = 0.864816079723755, disc_loss = 0.06097878564599176
Trained batch 745 in epoch 15, gen_loss = 0.8651862806433327, disc_loss = 0.06097165894527338
Trained batch 746 in epoch 15, gen_loss = 0.8649363009884974, disc_loss = 0.06098504077114534
Trained batch 747 in epoch 15, gen_loss = 0.8648289998664576, disc_loss = 0.06097701782445339
Trained batch 748 in epoch 15, gen_loss = 0.8645743114528096, disc_loss = 0.061032211836999424
Trained batch 749 in epoch 15, gen_loss = 0.8648703167041143, disc_loss = 0.061070837516337635
Trained batch 750 in epoch 15, gen_loss = 0.8650023339988389, disc_loss = 0.061103519224642355
Trained batch 751 in epoch 15, gen_loss = 0.8646126446175448, disc_loss = 0.0611800140332173
Trained batch 752 in epoch 15, gen_loss = 0.8645712207275558, disc_loss = 0.06116774518804682
Trained batch 753 in epoch 15, gen_loss = 0.8643703850811293, disc_loss = 0.061155555921727764
Trained batch 754 in epoch 15, gen_loss = 0.8646343920799281, disc_loss = 0.06115340675714592
Trained batch 755 in epoch 15, gen_loss = 0.8646199464719132, disc_loss = 0.061097043604594926
Trained batch 756 in epoch 15, gen_loss = 0.864698347319385, disc_loss = 0.06103629487366114
Trained batch 757 in epoch 15, gen_loss = 0.8645867664062253, disc_loss = 0.06100442818191522
Trained batch 758 in epoch 15, gen_loss = 0.8648997752170161, disc_loss = 0.060940028765829025
Trained batch 759 in epoch 15, gen_loss = 0.8646482723716058, disc_loss = 0.060915295463545543
Trained batch 760 in epoch 15, gen_loss = 0.8648283646470144, disc_loss = 0.06086891862403469
Trained batch 761 in epoch 15, gen_loss = 0.8650372770280037, disc_loss = 0.06080363682664325
Trained batch 762 in epoch 15, gen_loss = 0.8647565124934811, disc_loss = 0.060822007146225765
Trained batch 763 in epoch 15, gen_loss = 0.864705760948633, disc_loss = 0.06079136471127535
Trained batch 764 in epoch 15, gen_loss = 0.8650958995024364, disc_loss = 0.060827852153748856
Trained batch 765 in epoch 15, gen_loss = 0.8650258599389004, disc_loss = 0.06077033844375229
Trained batch 766 in epoch 15, gen_loss = 0.8648644603759711, disc_loss = 0.0607163964975941
Trained batch 767 in epoch 15, gen_loss = 0.8649036549419785, disc_loss = 0.060678546934165446
Trained batch 768 in epoch 15, gen_loss = 0.864879299085999, disc_loss = 0.06075058620355258
Trained batch 769 in epoch 15, gen_loss = 0.8643763210479315, disc_loss = 0.06089213465933095
Trained batch 770 in epoch 15, gen_loss = 0.8643397338272841, disc_loss = 0.060847640447028645
Trained batch 771 in epoch 15, gen_loss = 0.864637072646865, disc_loss = 0.06079904075079824
Trained batch 772 in epoch 15, gen_loss = 0.8642512295024053, disc_loss = 0.060904612671945337
Trained batch 773 in epoch 15, gen_loss = 0.8641949487363954, disc_loss = 0.06098034224311703
Trained batch 774 in epoch 15, gen_loss = 0.8641433865408743, disc_loss = 0.06094394062916118
Trained batch 775 in epoch 15, gen_loss = 0.8643557319091153, disc_loss = 0.060910587670694384
Trained batch 776 in epoch 15, gen_loss = 0.8640652339200716, disc_loss = 0.060945385883644974
Trained batch 777 in epoch 15, gen_loss = 0.8643918614690899, disc_loss = 0.06090475019464954
Trained batch 778 in epoch 15, gen_loss = 0.8644287811546791, disc_loss = 0.06090062377622903
Trained batch 779 in epoch 15, gen_loss = 0.8645294137872183, disc_loss = 0.06088897853444975
Trained batch 780 in epoch 15, gen_loss = 0.8646130141696002, disc_loss = 0.06096950133430096
Trained batch 781 in epoch 15, gen_loss = 0.864133944901664, disc_loss = 0.06113934905751777
Trained batch 782 in epoch 15, gen_loss = 0.8643107159993353, disc_loss = 0.06118132991509305
Trained batch 783 in epoch 15, gen_loss = 0.8644440641664729, disc_loss = 0.06115304216937333
Trained batch 784 in epoch 15, gen_loss = 0.8641917885488766, disc_loss = 0.06122340871388935
Trained batch 785 in epoch 15, gen_loss = 0.8640128142051114, disc_loss = 0.061190050030150864
Trained batch 786 in epoch 15, gen_loss = 0.8642168251047292, disc_loss = 0.06114150385290687
Trained batch 787 in epoch 15, gen_loss = 0.8646327360027333, disc_loss = 0.06115254980445778
Trained batch 788 in epoch 15, gen_loss = 0.8643171494149134, disc_loss = 0.06113423648230137
Trained batch 789 in epoch 15, gen_loss = 0.8640004219888132, disc_loss = 0.06115411749534026
Testing Epoch 15
Training Epoch 16
Trained batch 0 in epoch 16, gen_loss = 1.2838163375854492, disc_loss = 0.20448532700538635
Trained batch 1 in epoch 16, gen_loss = 0.9480074644088745, disc_loss = 0.14647092670202255
Trained batch 2 in epoch 16, gen_loss = 0.8982652028401693, disc_loss = 0.1098520780603091
Trained batch 3 in epoch 16, gen_loss = 0.8768317848443985, disc_loss = 0.08871503733098507
Trained batch 4 in epoch 16, gen_loss = 0.9196943879127503, disc_loss = 0.0925531879067421
Trained batch 5 in epoch 16, gen_loss = 0.9114118019739786, disc_loss = 0.08073253091424704
Trained batch 6 in epoch 16, gen_loss = 0.8753945657185146, disc_loss = 0.07966947901461806
Trained batch 7 in epoch 16, gen_loss = 0.8813495337963104, disc_loss = 0.08170918864198029
Trained batch 8 in epoch 16, gen_loss = 0.8983671135372586, disc_loss = 0.07378327370517784
Trained batch 9 in epoch 16, gen_loss = 0.8825958371162415, disc_loss = 0.07145208138972521
Trained batch 10 in epoch 16, gen_loss = 0.8545400337739424, disc_loss = 0.07842223498631608
Trained batch 11 in epoch 16, gen_loss = 0.874970148007075, disc_loss = 0.07598821182424824
Trained batch 12 in epoch 16, gen_loss = 0.8876830614530123, disc_loss = 0.0711763260456232
Trained batch 13 in epoch 16, gen_loss = 0.871606205190931, disc_loss = 0.07130981822099004
Trained batch 14 in epoch 16, gen_loss = 0.8758660078048706, disc_loss = 0.06841396192709605
Trained batch 15 in epoch 16, gen_loss = 0.8834018148481846, disc_loss = 0.06486043578479439
Trained batch 16 in epoch 16, gen_loss = 0.884311276323655, disc_loss = 0.06509155878687606
Trained batch 17 in epoch 16, gen_loss = 0.8816834853755103, disc_loss = 0.0624870742774672
Trained batch 18 in epoch 16, gen_loss = 0.8842317022775349, disc_loss = 0.06372775313885588
Trained batch 19 in epoch 16, gen_loss = 0.8784524947404861, disc_loss = 0.06314062457531691
Trained batch 20 in epoch 16, gen_loss = 0.8827504685946873, disc_loss = 0.06065525438281752
Trained batch 21 in epoch 16, gen_loss = 0.8810500448400324, disc_loss = 0.05845759584653107
Trained batch 22 in epoch 16, gen_loss = 0.883772471676702, disc_loss = 0.056401490152853985
Trained batch 23 in epoch 16, gen_loss = 0.8808923612038294, disc_loss = 0.05539731242849181
Trained batch 24 in epoch 16, gen_loss = 0.8952396106719971, disc_loss = 0.05439933937042952
Trained batch 25 in epoch 16, gen_loss = 0.8921457529067993, disc_loss = 0.05284428499782315
Trained batch 26 in epoch 16, gen_loss = 0.8905857713134201, disc_loss = 0.05153295173551197
Trained batch 27 in epoch 16, gen_loss = 0.8943089417048863, disc_loss = 0.049978498269670775
Trained batch 28 in epoch 16, gen_loss = 0.9028535218074404, disc_loss = 0.04912115919307388
Trained batch 29 in epoch 16, gen_loss = 0.8987635791301727, disc_loss = 0.04842953678841392
Trained batch 30 in epoch 16, gen_loss = 0.8976447293835301, disc_loss = 0.047412231774820436
Trained batch 31 in epoch 16, gen_loss = 0.9015094991773367, disc_loss = 0.05335046790423803
Trained batch 32 in epoch 16, gen_loss = 0.8877095995527325, disc_loss = 0.057112655150845196
Trained batch 33 in epoch 16, gen_loss = 0.8897189357701469, disc_loss = 0.056373632321243775
Trained batch 34 in epoch 16, gen_loss = 0.8844895533152989, disc_loss = 0.05766552577593497
Trained batch 35 in epoch 16, gen_loss = 0.8933268884817759, disc_loss = 0.0614218196262502
Trained batch 36 in epoch 16, gen_loss = 0.886384591862962, disc_loss = 0.06270633051423607
Trained batch 37 in epoch 16, gen_loss = 0.8817779719829559, disc_loss = 0.06298933744332508
Trained batch 38 in epoch 16, gen_loss = 0.8812803198129703, disc_loss = 0.06287265222710677
Trained batch 39 in epoch 16, gen_loss = 0.8871204987168312, disc_loss = 0.06299483419861644
Trained batch 40 in epoch 16, gen_loss = 0.8910957153250532, disc_loss = 0.06241002049660537
Trained batch 41 in epoch 16, gen_loss = 0.8868452083496821, disc_loss = 0.0616518574145933
Trained batch 42 in epoch 16, gen_loss = 0.8813713594924572, disc_loss = 0.06161589168965123
Trained batch 43 in epoch 16, gen_loss = 0.8867904868992892, disc_loss = 0.06215886511331932
Trained batch 44 in epoch 16, gen_loss = 0.8806431677606371, disc_loss = 0.06233002255774207
Trained batch 45 in epoch 16, gen_loss = 0.8782076822674793, disc_loss = 0.061738615713851606
Trained batch 46 in epoch 16, gen_loss = 0.8783324157938044, disc_loss = 0.06075736596942582
Trained batch 47 in epoch 16, gen_loss = 0.874976634979248, disc_loss = 0.0604311103040042
Trained batch 48 in epoch 16, gen_loss = 0.8745109876807855, disc_loss = 0.06166405377111265
Trained batch 49 in epoch 16, gen_loss = 0.8699139881134034, disc_loss = 0.061960385832935574
Trained batch 50 in epoch 16, gen_loss = 0.874274263194963, disc_loss = 0.061192295514047146
Trained batch 51 in epoch 16, gen_loss = 0.8749179725463574, disc_loss = 0.06081637104328435
Trained batch 52 in epoch 16, gen_loss = 0.869856910885505, disc_loss = 0.06183297870645545
Trained batch 53 in epoch 16, gen_loss = 0.8699215374611042, disc_loss = 0.06143263135864227
Trained batch 54 in epoch 16, gen_loss = 0.8766623984683644, disc_loss = 0.06171445915983482
Trained batch 55 in epoch 16, gen_loss = 0.8731908894010952, disc_loss = 0.061536839115433395
Trained batch 56 in epoch 16, gen_loss = 0.8711137886632953, disc_loss = 0.06158790307675015
Trained batch 57 in epoch 16, gen_loss = 0.8736180611725511, disc_loss = 0.06085065660741309
Trained batch 58 in epoch 16, gen_loss = 0.8721350643594387, disc_loss = 0.06081660955323506
Trained batch 59 in epoch 16, gen_loss = 0.872210098306338, disc_loss = 0.06007995513888697
Trained batch 60 in epoch 16, gen_loss = 0.8746599027367888, disc_loss = 0.05939008687912929
Trained batch 61 in epoch 16, gen_loss = 0.8718434543378891, disc_loss = 0.05942880904542342
Trained batch 62 in epoch 16, gen_loss = 0.871930235908145, disc_loss = 0.05890262678324703
Trained batch 63 in epoch 16, gen_loss = 0.8732242602854967, disc_loss = 0.05839447288599331
Trained batch 64 in epoch 16, gen_loss = 0.8755959254044753, disc_loss = 0.05763033360529404
Trained batch 65 in epoch 16, gen_loss = 0.8711874304395734, disc_loss = 0.058692722002778086
Trained batch 66 in epoch 16, gen_loss = 0.8727507617936205, disc_loss = 0.058190059542322335
Trained batch 67 in epoch 16, gen_loss = 0.8783546852714875, disc_loss = 0.05844546176547952
Trained batch 68 in epoch 16, gen_loss = 0.8754080974537394, disc_loss = 0.058651452168714306
Trained batch 69 in epoch 16, gen_loss = 0.8763655253819057, disc_loss = 0.05795821060559579
Trained batch 70 in epoch 16, gen_loss = 0.8768305795293458, disc_loss = 0.057318023445320804
Trained batch 71 in epoch 16, gen_loss = 0.8809223456515206, disc_loss = 0.058775936201628715
Trained batch 72 in epoch 16, gen_loss = 0.8763209622200221, disc_loss = 0.06034368751187847
Trained batch 73 in epoch 16, gen_loss = 0.8735674498854457, disc_loss = 0.0605955302614618
Trained batch 74 in epoch 16, gen_loss = 0.8755204876263937, disc_loss = 0.059954942824939884
Trained batch 75 in epoch 16, gen_loss = 0.8808787018060684, disc_loss = 0.06060095353199071
Trained batch 76 in epoch 16, gen_loss = 0.8800352432511069, disc_loss = 0.06048548014761953
Trained batch 77 in epoch 16, gen_loss = 0.8813637166451185, disc_loss = 0.0599641831090244
Trained batch 78 in epoch 16, gen_loss = 0.8799997402142875, disc_loss = 0.05957507258399001
Trained batch 79 in epoch 16, gen_loss = 0.8764137998223305, disc_loss = 0.05936094886856154
Trained batch 80 in epoch 16, gen_loss = 0.8760299402990459, disc_loss = 0.05884563896437118
Trained batch 81 in epoch 16, gen_loss = 0.8777406942553636, disc_loss = 0.05828266414790982
Trained batch 82 in epoch 16, gen_loss = 0.8782654986324081, disc_loss = 0.05840127319321934
Trained batch 83 in epoch 16, gen_loss = 0.8772613860311962, disc_loss = 0.057982535156909196
Trained batch 84 in epoch 16, gen_loss = 0.8766358649029451, disc_loss = 0.05756613227593548
Trained batch 85 in epoch 16, gen_loss = 0.8758898938811103, disc_loss = 0.057155722936312124
Trained batch 86 in epoch 16, gen_loss = 0.8755390102835907, disc_loss = 0.056734706489262224
Trained batch 87 in epoch 16, gen_loss = 0.8764054104685783, disc_loss = 0.05654157123486088
Trained batch 88 in epoch 16, gen_loss = 0.8760802163166946, disc_loss = 0.05621372319213795
Trained batch 89 in epoch 16, gen_loss = 0.8772529886828528, disc_loss = 0.0558116562354068
Trained batch 90 in epoch 16, gen_loss = 0.8771832153037354, disc_loss = 0.05541742720978928
Trained batch 91 in epoch 16, gen_loss = 0.8779799620742383, disc_loss = 0.05541963681943067
Trained batch 92 in epoch 16, gen_loss = 0.8772238992875622, disc_loss = 0.05514127153262336
Trained batch 93 in epoch 16, gen_loss = 0.8769196893306489, disc_loss = 0.05492696075878562
Trained batch 94 in epoch 16, gen_loss = 0.8773933090661702, disc_loss = 0.054596050328722126
Trained batch 95 in epoch 16, gen_loss = 0.8777778726071119, disc_loss = 0.05415426359589522
Trained batch 96 in epoch 16, gen_loss = 0.8745300308945253, disc_loss = 0.05515987028550241
Trained batch 97 in epoch 16, gen_loss = 0.8769665792280313, disc_loss = 0.05496982395724983
Trained batch 98 in epoch 16, gen_loss = 0.8817192719440268, disc_loss = 0.05557110380720009
Trained batch 99 in epoch 16, gen_loss = 0.8797952264547348, disc_loss = 0.05591742428019643
Trained batch 100 in epoch 16, gen_loss = 0.8773083315037264, disc_loss = 0.05620411556619819
Trained batch 101 in epoch 16, gen_loss = 0.8745826143844455, disc_loss = 0.057145096672077976
Trained batch 102 in epoch 16, gen_loss = 0.8758404822025484, disc_loss = 0.05788088338540017
Trained batch 103 in epoch 16, gen_loss = 0.8775024127501708, disc_loss = 0.05794997214196393
Trained batch 104 in epoch 16, gen_loss = 0.8741947253545125, disc_loss = 0.0592531872824544
Trained batch 105 in epoch 16, gen_loss = 0.8731474044188013, disc_loss = 0.0593269542738233
Trained batch 106 in epoch 16, gen_loss = 0.8730337714480463, disc_loss = 0.05919018500945836
Trained batch 107 in epoch 16, gen_loss = 0.8732123286635788, disc_loss = 0.058998021555857524
Trained batch 108 in epoch 16, gen_loss = 0.8713215600459947, disc_loss = 0.058963326566399785
Trained batch 109 in epoch 16, gen_loss = 0.8689297063784166, disc_loss = 0.0602529959414493
Trained batch 110 in epoch 16, gen_loss = 0.8665096899410626, disc_loss = 0.06127564516757523
Trained batch 111 in epoch 16, gen_loss = 0.8651088396353381, disc_loss = 0.06131106004717627
Trained batch 112 in epoch 16, gen_loss = 0.8681132629909346, disc_loss = 0.061201782435574364
Trained batch 113 in epoch 16, gen_loss = 0.8700387493560189, disc_loss = 0.061193039526411315
Trained batch 114 in epoch 16, gen_loss = 0.8682016854700835, disc_loss = 0.06131180549121421
Trained batch 115 in epoch 16, gen_loss = 0.8675445179487097, disc_loss = 0.061118314412004986
Trained batch 116 in epoch 16, gen_loss = 0.8707963936349266, disc_loss = 0.060920651922495954
Trained batch 117 in epoch 16, gen_loss = 0.8714832501896357, disc_loss = 0.06055898353520591
Trained batch 118 in epoch 16, gen_loss = 0.8715329831387816, disc_loss = 0.060296448698940394
Trained batch 119 in epoch 16, gen_loss = 0.8709832752744356, disc_loss = 0.060145232686772944
Trained batch 120 in epoch 16, gen_loss = 0.8675660840735948, disc_loss = 0.06133123639632355
Trained batch 121 in epoch 16, gen_loss = 0.8695156378824203, disc_loss = 0.06149361861228454
Trained batch 122 in epoch 16, gen_loss = 0.8689352700380775, disc_loss = 0.06159648134153548
Trained batch 123 in epoch 16, gen_loss = 0.8684152412799097, disc_loss = 0.06163906743149123
Trained batch 124 in epoch 16, gen_loss = 0.8669618072509766, disc_loss = 0.06196463339030742
Trained batch 125 in epoch 16, gen_loss = 0.86635488744766, disc_loss = 0.062198261819070295
Trained batch 126 in epoch 16, gen_loss = 0.8682668922454353, disc_loss = 0.061795709288026406
Trained batch 127 in epoch 16, gen_loss = 0.8687440762296319, disc_loss = 0.06139604745840188
Trained batch 128 in epoch 16, gen_loss = 0.8688739039177118, disc_loss = 0.06099636386357998
Trained batch 129 in epoch 16, gen_loss = 0.8702335788653447, disc_loss = 0.06069047756206531
Trained batch 130 in epoch 16, gen_loss = 0.8710715238374608, disc_loss = 0.06029455588405369
Trained batch 131 in epoch 16, gen_loss = 0.8709443012873331, disc_loss = 0.059968933801759376
Trained batch 132 in epoch 16, gen_loss = 0.8701897729608349, disc_loss = 0.060000525605409666
Trained batch 133 in epoch 16, gen_loss = 0.8709235658396536, disc_loss = 0.05967485297248879
Trained batch 134 in epoch 16, gen_loss = 0.8708914169558772, disc_loss = 0.05939128219529435
Trained batch 135 in epoch 16, gen_loss = 0.8718893032740144, disc_loss = 0.059048903845798445
Trained batch 136 in epoch 16, gen_loss = 0.8728711009025574, disc_loss = 0.05867890926608204
Trained batch 137 in epoch 16, gen_loss = 0.8732501272706018, disc_loss = 0.05884999231151913
Trained batch 138 in epoch 16, gen_loss = 0.8722140398814524, disc_loss = 0.058690252037142676
Trained batch 139 in epoch 16, gen_loss = 0.8707494599478586, disc_loss = 0.05882954424513238
Trained batch 140 in epoch 16, gen_loss = 0.8711059385157646, disc_loss = 0.0584715114681856
Trained batch 141 in epoch 16, gen_loss = 0.8745742066645287, disc_loss = 0.05906296009853692
Trained batch 142 in epoch 16, gen_loss = 0.8761640349468152, disc_loss = 0.05920301828455258
Trained batch 143 in epoch 16, gen_loss = 0.8746791957981057, disc_loss = 0.059588422145073615
Trained batch 144 in epoch 16, gen_loss = 0.8746588653531567, disc_loss = 0.059252075382090846
Trained batch 145 in epoch 16, gen_loss = 0.8735769566607802, disc_loss = 0.05937324642293053
Trained batch 146 in epoch 16, gen_loss = 0.8742198522399072, disc_loss = 0.059057279496269974
Trained batch 147 in epoch 16, gen_loss = 0.8753358125686646, disc_loss = 0.059772376260544
Trained batch 148 in epoch 16, gen_loss = 0.8746139659177536, disc_loss = 0.05956404792432417
Trained batch 149 in epoch 16, gen_loss = 0.8756530308723449, disc_loss = 0.05922015398740768
Trained batch 150 in epoch 16, gen_loss = 0.8745096645607854, disc_loss = 0.059173254974630496
Trained batch 151 in epoch 16, gen_loss = 0.8744278526619861, disc_loss = 0.058946221429658566
Trained batch 152 in epoch 16, gen_loss = 0.8727799073543424, disc_loss = 0.059124964806768626
Trained batch 153 in epoch 16, gen_loss = 0.8737584611812195, disc_loss = 0.05951264099060715
Trained batch 154 in epoch 16, gen_loss = 0.8734010669492906, disc_loss = 0.0598310447508289
Trained batch 155 in epoch 16, gen_loss = 0.8742313984877024, disc_loss = 0.05972938067637957
Trained batch 156 in epoch 16, gen_loss = 0.872312338109229, disc_loss = 0.060690681076353524
Trained batch 157 in epoch 16, gen_loss = 0.8710698066632959, disc_loss = 0.06067688701839387
Trained batch 158 in epoch 16, gen_loss = 0.8725296607557332, disc_loss = 0.06084792957928196
Trained batch 159 in epoch 16, gen_loss = 0.87276949621737, disc_loss = 0.06059122036676854
Trained batch 160 in epoch 16, gen_loss = 0.8722160236435648, disc_loss = 0.06031269767547246
Trained batch 161 in epoch 16, gen_loss = 0.8716317161365792, disc_loss = 0.0600957788159082
Trained batch 162 in epoch 16, gen_loss = 0.8701105428619619, disc_loss = 0.06002970828326202
Trained batch 163 in epoch 16, gen_loss = 0.873101482667574, disc_loss = 0.06023172404980514
Trained batch 164 in epoch 16, gen_loss = 0.8735447294784314, disc_loss = 0.06010444656465993
Trained batch 165 in epoch 16, gen_loss = 0.8726586466094097, disc_loss = 0.06010126674839531
Trained batch 166 in epoch 16, gen_loss = 0.8740349861676108, disc_loss = 0.05979577010263226
Trained batch 167 in epoch 16, gen_loss = 0.8758832517833937, disc_loss = 0.0595062221289568
Trained batch 168 in epoch 16, gen_loss = 0.8766797227266978, disc_loss = 0.059196113085253
Trained batch 169 in epoch 16, gen_loss = 0.8763536800356472, disc_loss = 0.058949368118363266
Trained batch 170 in epoch 16, gen_loss = 0.878058730161678, disc_loss = 0.05873066433079061
Trained batch 171 in epoch 16, gen_loss = 0.8787997514009476, disc_loss = 0.05845251419516497
Trained batch 172 in epoch 16, gen_loss = 0.8779923150994186, disc_loss = 0.05841262496447976
Trained batch 173 in epoch 16, gen_loss = 0.8779103985463066, disc_loss = 0.058187158949587536
Trained batch 174 in epoch 16, gen_loss = 0.8792800572940281, disc_loss = 0.058122526896851406
Trained batch 175 in epoch 16, gen_loss = 0.8794590746137229, disc_loss = 0.05786008358700201
Trained batch 176 in epoch 16, gen_loss = 0.8788839332801474, disc_loss = 0.05779102116844243
Trained batch 177 in epoch 16, gen_loss = 0.880323805500952, disc_loss = 0.05758485022743934
Trained batch 178 in epoch 16, gen_loss = 0.878601414198316, disc_loss = 0.05777928283614986
Trained batch 179 in epoch 16, gen_loss = 0.8795548203918669, disc_loss = 0.05763936161270572
Trained batch 180 in epoch 16, gen_loss = 0.8814259138555158, disc_loss = 0.05777645010748127
Trained batch 181 in epoch 16, gen_loss = 0.8812909866427328, disc_loss = 0.057692979293578604
Trained batch 182 in epoch 16, gen_loss = 0.879347548784454, disc_loss = 0.058231590615962045
Trained batch 183 in epoch 16, gen_loss = 0.8787515950591668, disc_loss = 0.058867206619849996
Trained batch 184 in epoch 16, gen_loss = 0.8782064267106958, disc_loss = 0.058700097196206856
Trained batch 185 in epoch 16, gen_loss = 0.8784898926493943, disc_loss = 0.05844742526871062
Trained batch 186 in epoch 16, gen_loss = 0.8780245153024235, disc_loss = 0.05839616911396145
Trained batch 187 in epoch 16, gen_loss = 0.8776588268736576, disc_loss = 0.05838895940340738
Trained batch 188 in epoch 16, gen_loss = 0.8766158604748034, disc_loss = 0.05839924311767968
Trained batch 189 in epoch 16, gen_loss = 0.8751573427727348, disc_loss = 0.05885150866386922
Trained batch 190 in epoch 16, gen_loss = 0.877393137410049, disc_loss = 0.06036164976792966
Trained batch 191 in epoch 16, gen_loss = 0.87759277690202, disc_loss = 0.06028456811812551
Trained batch 192 in epoch 16, gen_loss = 0.8763319550400571, disc_loss = 0.06038926627216716
Trained batch 193 in epoch 16, gen_loss = 0.8756507730361113, disc_loss = 0.06024131067961301
Trained batch 194 in epoch 16, gen_loss = 0.8757771488947746, disc_loss = 0.06050064633003412
Trained batch 195 in epoch 16, gen_loss = 0.8750214956852854, disc_loss = 0.06088329616420883
Trained batch 196 in epoch 16, gen_loss = 0.8736856485986467, disc_loss = 0.06154319175476501
Trained batch 197 in epoch 16, gen_loss = 0.8739674654271867, disc_loss = 0.061453749853741337
Trained batch 198 in epoch 16, gen_loss = 0.872894654621431, disc_loss = 0.06182495999295059
Trained batch 199 in epoch 16, gen_loss = 0.8747073379158974, disc_loss = 0.06211534705478698
Trained batch 200 in epoch 16, gen_loss = 0.8737902371444513, disc_loss = 0.06216850065491834
Trained batch 201 in epoch 16, gen_loss = 0.8735621187946584, disc_loss = 0.062059884637336034
Trained batch 202 in epoch 16, gen_loss = 0.8724585906625382, disc_loss = 0.06210738514536267
Trained batch 203 in epoch 16, gen_loss = 0.8722933411013847, disc_loss = 0.06227259321923496
Trained batch 204 in epoch 16, gen_loss = 0.8717261791229248, disc_loss = 0.06233580859786854
Trained batch 205 in epoch 16, gen_loss = 0.871188164914696, disc_loss = 0.06236758074515219
Trained batch 206 in epoch 16, gen_loss = 0.8704793240137146, disc_loss = 0.06227111266161077
Trained batch 207 in epoch 16, gen_loss = 0.8698611697898462, disc_loss = 0.06216229391373837
Trained batch 208 in epoch 16, gen_loss = 0.8696532300784827, disc_loss = 0.062033725095886075
Trained batch 209 in epoch 16, gen_loss = 0.8711396472794669, disc_loss = 0.06189948189560147
Trained batch 210 in epoch 16, gen_loss = 0.871871146545591, disc_loss = 0.06234370133623269
Trained batch 211 in epoch 16, gen_loss = 0.8714540718861346, disc_loss = 0.06237631238873978
Trained batch 212 in epoch 16, gen_loss = 0.8709839498493034, disc_loss = 0.06229646133582497
Trained batch 213 in epoch 16, gen_loss = 0.8696344884756569, disc_loss = 0.06236390411314145
Trained batch 214 in epoch 16, gen_loss = 0.8695995078530423, disc_loss = 0.06248945296243873
Trained batch 215 in epoch 16, gen_loss = 0.8710948838679878, disc_loss = 0.062440896859496005
Trained batch 216 in epoch 16, gen_loss = 0.8696003056341602, disc_loss = 0.06310078718437714
Trained batch 217 in epoch 16, gen_loss = 0.8680517823871122, disc_loss = 0.06328259261940188
Trained batch 218 in epoch 16, gen_loss = 0.8683381001698917, disc_loss = 0.06340053361589641
Trained batch 219 in epoch 16, gen_loss = 0.8701171937313947, disc_loss = 0.06390007189475
Trained batch 220 in epoch 16, gen_loss = 0.8691386766563174, disc_loss = 0.06395558012034154
Trained batch 221 in epoch 16, gen_loss = 0.8674924851537825, disc_loss = 0.06450122551623362
Trained batch 222 in epoch 16, gen_loss = 0.8664724725244292, disc_loss = 0.06464575081144881
Trained batch 223 in epoch 16, gen_loss = 0.8682884451534066, disc_loss = 0.06521614345339392
Trained batch 224 in epoch 16, gen_loss = 0.8686330755551656, disc_loss = 0.06519836297051775
Trained batch 225 in epoch 16, gen_loss = 0.8670807588944393, disc_loss = 0.06572728284708826
Trained batch 226 in epoch 16, gen_loss = 0.8677637889521763, disc_loss = 0.06551897891341721
Trained batch 227 in epoch 16, gen_loss = 0.8680355389390075, disc_loss = 0.06542307476251664
Trained batch 228 in epoch 16, gen_loss = 0.8672410942060979, disc_loss = 0.06532595498186403
Trained batch 229 in epoch 16, gen_loss = 0.8675610801447993, disc_loss = 0.06514796555933097
Trained batch 230 in epoch 16, gen_loss = 0.8674738412295585, disc_loss = 0.06492302909864363
Trained batch 231 in epoch 16, gen_loss = 0.8673467720890867, disc_loss = 0.06486714944034687
Trained batch 232 in epoch 16, gen_loss = 0.8661123258361489, disc_loss = 0.06499921694765659
Trained batch 233 in epoch 16, gen_loss = 0.8660266427402823, disc_loss = 0.06540004566359596
Trained batch 234 in epoch 16, gen_loss = 0.8654243656929503, disc_loss = 0.06523589809286467
Trained batch 235 in epoch 16, gen_loss = 0.8648677175327882, disc_loss = 0.0651797567991445
Trained batch 236 in epoch 16, gen_loss = 0.8654946244718656, disc_loss = 0.06542406599371368
Trained batch 237 in epoch 16, gen_loss = 0.8651720733702684, disc_loss = 0.06532734423140142
Trained batch 238 in epoch 16, gen_loss = 0.8648151408678318, disc_loss = 0.0652401597593681
Trained batch 239 in epoch 16, gen_loss = 0.8641305374602477, disc_loss = 0.06515918875811622
Trained batch 240 in epoch 16, gen_loss = 0.8648197984794364, disc_loss = 0.06564629466284484
Trained batch 241 in epoch 16, gen_loss = 0.863731495112427, disc_loss = 0.06587610244827945
Trained batch 242 in epoch 16, gen_loss = 0.8635754575454649, disc_loss = 0.06570302488458622
Trained batch 243 in epoch 16, gen_loss = 0.863782031369991, disc_loss = 0.06550258057207235
Trained batch 244 in epoch 16, gen_loss = 0.8635105585565372, disc_loss = 0.06529654475423147
Trained batch 245 in epoch 16, gen_loss = 0.8640451712336966, disc_loss = 0.0650997448947311
Trained batch 246 in epoch 16, gen_loss = 0.8646381046125281, disc_loss = 0.06503514049250467
Trained batch 247 in epoch 16, gen_loss = 0.865110945317053, disc_loss = 0.06492257603038583
Trained batch 248 in epoch 16, gen_loss = 0.864956176424601, disc_loss = 0.06493227609833441
Trained batch 249 in epoch 16, gen_loss = 0.8638352394104004, disc_loss = 0.06529364485666156
Trained batch 250 in epoch 16, gen_loss = 0.8649809218022928, disc_loss = 0.06534432754499385
Trained batch 251 in epoch 16, gen_loss = 0.8659847936933003, disc_loss = 0.0652206627733355
Trained batch 252 in epoch 16, gen_loss = 0.865263769749125, disc_loss = 0.06518076828095636
Trained batch 253 in epoch 16, gen_loss = 0.8646037144454446, disc_loss = 0.06528908846987866
Trained batch 254 in epoch 16, gen_loss = 0.8640724600530139, disc_loss = 0.06534225642315897
Trained batch 255 in epoch 16, gen_loss = 0.863808054709807, disc_loss = 0.06525935796889826
Trained batch 256 in epoch 16, gen_loss = 0.8640830264017276, disc_loss = 0.06514631002663059
Trained batch 257 in epoch 16, gen_loss = 0.8640222743500111, disc_loss = 0.06513749576686312
Trained batch 258 in epoch 16, gen_loss = 0.8637319478749308, disc_loss = 0.06496128924982082
Trained batch 259 in epoch 16, gen_loss = 0.86365204338844, disc_loss = 0.0647896604361729
Trained batch 260 in epoch 16, gen_loss = 0.8631204508273538, disc_loss = 0.06462730810945404
Trained batch 261 in epoch 16, gen_loss = 0.8627717936311969, disc_loss = 0.06448225598455272
Trained batch 262 in epoch 16, gen_loss = 0.8624918073302439, disc_loss = 0.06440479815105409
Trained batch 263 in epoch 16, gen_loss = 0.862429078103918, disc_loss = 0.06423769421014709
Trained batch 264 in epoch 16, gen_loss = 0.8623630339244627, disc_loss = 0.06415231406056093
Trained batch 265 in epoch 16, gen_loss = 0.8637257630663707, disc_loss = 0.06432011957049258
Trained batch 266 in epoch 16, gen_loss = 0.8625880247644717, disc_loss = 0.06435569890248083
Trained batch 267 in epoch 16, gen_loss = 0.8622135266439238, disc_loss = 0.06428319959095054
Trained batch 268 in epoch 16, gen_loss = 0.8632191393012008, disc_loss = 0.06423001132254597
Trained batch 269 in epoch 16, gen_loss = 0.862826876728623, disc_loss = 0.06419493100364451
Trained batch 270 in epoch 16, gen_loss = 0.8632391290911009, disc_loss = 0.06401549566990775
Trained batch 271 in epoch 16, gen_loss = 0.8640617351321613, disc_loss = 0.06390911500955768
Trained batch 272 in epoch 16, gen_loss = 0.8639146831882742, disc_loss = 0.06376126218901013
Trained batch 273 in epoch 16, gen_loss = 0.8635721983265703, disc_loss = 0.06358169484883547
Trained batch 274 in epoch 16, gen_loss = 0.8625123864954168, disc_loss = 0.0638065054538575
Trained batch 275 in epoch 16, gen_loss = 0.8636365528555884, disc_loss = 0.06389164779524224
Trained batch 276 in epoch 16, gen_loss = 0.8638950945668272, disc_loss = 0.0637975500338452
Trained batch 277 in epoch 16, gen_loss = 0.8635559770271932, disc_loss = 0.06377559456063046
Trained batch 278 in epoch 16, gen_loss = 0.8632358319015914, disc_loss = 0.0636082052129678
Trained batch 279 in epoch 16, gen_loss = 0.8634265410048622, disc_loss = 0.06343666057301951
Trained batch 280 in epoch 16, gen_loss = 0.8631498081828352, disc_loss = 0.06334762675919672
Trained batch 281 in epoch 16, gen_loss = 0.8621304092255044, disc_loss = 0.06331079679455423
Trained batch 282 in epoch 16, gen_loss = 0.8629612474053993, disc_loss = 0.06328012169315726
Trained batch 283 in epoch 16, gen_loss = 0.8632686476052647, disc_loss = 0.06313818972885714
Trained batch 284 in epoch 16, gen_loss = 0.8627012648080524, disc_loss = 0.06324824943419612
Trained batch 285 in epoch 16, gen_loss = 0.8626518284941053, disc_loss = 0.0630671142313916
Trained batch 286 in epoch 16, gen_loss = 0.8629838510672805, disc_loss = 0.06302221549369837
Trained batch 287 in epoch 16, gen_loss = 0.8620196394622326, disc_loss = 0.06322875599855454
Trained batch 288 in epoch 16, gen_loss = 0.8619552073181707, disc_loss = 0.06311429280684584
Trained batch 289 in epoch 16, gen_loss = 0.8614755611995171, disc_loss = 0.06301665035365471
Trained batch 290 in epoch 16, gen_loss = 0.8622421933613282, disc_loss = 0.06302969568949897
Trained batch 291 in epoch 16, gen_loss = 0.8618833632910088, disc_loss = 0.0629280246443383
Trained batch 292 in epoch 16, gen_loss = 0.862856055892775, disc_loss = 0.06275099785458106
Trained batch 293 in epoch 16, gen_loss = 0.8632276733310855, disc_loss = 0.06256597800192987
Trained batch 294 in epoch 16, gen_loss = 0.863704592696691, disc_loss = 0.06238080726904889
Trained batch 295 in epoch 16, gen_loss = 0.8641592084958747, disc_loss = 0.062285830949533834
Trained batch 296 in epoch 16, gen_loss = 0.8634189955313197, disc_loss = 0.06248545822583967
Trained batch 297 in epoch 16, gen_loss = 0.8625637960913998, disc_loss = 0.06257637167949505
Trained batch 298 in epoch 16, gen_loss = 0.8628816772065434, disc_loss = 0.06294510249721266
Trained batch 299 in epoch 16, gen_loss = 0.863400395711263, disc_loss = 0.06277931132043402
Trained batch 300 in epoch 16, gen_loss = 0.8628620570680232, disc_loss = 0.06276798610300123
Trained batch 301 in epoch 16, gen_loss = 0.8630341621029456, disc_loss = 0.06267990541354512
Trained batch 302 in epoch 16, gen_loss = 0.8632279778077657, disc_loss = 0.0625175301311384
Trained batch 303 in epoch 16, gen_loss = 0.8637135030799791, disc_loss = 0.0623665499886939
Trained batch 304 in epoch 16, gen_loss = 0.8628293707722523, disc_loss = 0.06264852088433309
Trained batch 305 in epoch 16, gen_loss = 0.8625034863263173, disc_loss = 0.06254657288234121
Trained batch 306 in epoch 16, gen_loss = 0.8632610517914986, disc_loss = 0.06316041823549359
Trained batch 307 in epoch 16, gen_loss = 0.8638269268460088, disc_loss = 0.06302523379843053
Trained batch 308 in epoch 16, gen_loss = 0.8628566128150544, disc_loss = 0.06307795891254947
Trained batch 309 in epoch 16, gen_loss = 0.8627403380409364, disc_loss = 0.06301624796864005
Trained batch 310 in epoch 16, gen_loss = 0.863029765737785, disc_loss = 0.06305014883793915
Trained batch 311 in epoch 16, gen_loss = 0.8625275135422364, disc_loss = 0.06317021456869462
Trained batch 312 in epoch 16, gen_loss = 0.8634293561164563, disc_loss = 0.06313780820467316
Trained batch 313 in epoch 16, gen_loss = 0.8628081227563749, disc_loss = 0.06321781891795575
Trained batch 314 in epoch 16, gen_loss = 0.8631896227125138, disc_loss = 0.06304427766433311
Trained batch 315 in epoch 16, gen_loss = 0.863038536302651, disc_loss = 0.06294056261253037
Trained batch 316 in epoch 16, gen_loss = 0.86250007246571, disc_loss = 0.06295019582983354
Trained batch 317 in epoch 16, gen_loss = 0.8625161773378744, disc_loss = 0.06294054384255465
Trained batch 318 in epoch 16, gen_loss = 0.8634531073809417, disc_loss = 0.0632362199515151
Trained batch 319 in epoch 16, gen_loss = 0.8631778864189983, disc_loss = 0.06325273463444318
Trained batch 320 in epoch 16, gen_loss = 0.8623850633422162, disc_loss = 0.06332448557471838
Trained batch 321 in epoch 16, gen_loss = 0.8630314789573599, disc_loss = 0.0638234810238438
Trained batch 322 in epoch 16, gen_loss = 0.8617894297044713, disc_loss = 0.06431908278953827
Trained batch 323 in epoch 16, gen_loss = 0.862296027349837, disc_loss = 0.06425219289900988
Trained batch 324 in epoch 16, gen_loss = 0.8621101911251362, disc_loss = 0.06427992227845467
Trained batch 325 in epoch 16, gen_loss = 0.862069171264859, disc_loss = 0.06423711214225991
Trained batch 326 in epoch 16, gen_loss = 0.8617865599988068, disc_loss = 0.06419295386698906
Trained batch 327 in epoch 16, gen_loss = 0.8622333950749258, disc_loss = 0.06416570314308401
Trained batch 328 in epoch 16, gen_loss = 0.8614484026439284, disc_loss = 0.06428353785958968
Trained batch 329 in epoch 16, gen_loss = 0.8612735294934475, disc_loss = 0.0642043225213208
Trained batch 330 in epoch 16, gen_loss = 0.8619591467690252, disc_loss = 0.06407012292704463
Trained batch 331 in epoch 16, gen_loss = 0.8620622535067869, disc_loss = 0.06422113561834467
Trained batch 332 in epoch 16, gen_loss = 0.8617274009429656, disc_loss = 0.06412975445065323
Trained batch 333 in epoch 16, gen_loss = 0.860825240255116, disc_loss = 0.06421500105065053
Trained batch 334 in epoch 16, gen_loss = 0.8609479850797511, disc_loss = 0.06436752765647956
Trained batch 335 in epoch 16, gen_loss = 0.8600348464789844, disc_loss = 0.06462922332797288
Trained batch 336 in epoch 16, gen_loss = 0.8609054785453955, disc_loss = 0.06472642098219086
Trained batch 337 in epoch 16, gen_loss = 0.8601800219194423, disc_loss = 0.06475007346384888
Trained batch 338 in epoch 16, gen_loss = 0.8598287617210794, disc_loss = 0.06460541127123225
Trained batch 339 in epoch 16, gen_loss = 0.8606147641644758, disc_loss = 0.06461695571539595
Trained batch 340 in epoch 16, gen_loss = 0.8606470174803412, disc_loss = 0.06446954180811507
Trained batch 341 in epoch 16, gen_loss = 0.8598944006258982, disc_loss = 0.064704155549407
Trained batch 342 in epoch 16, gen_loss = 0.8599816039421816, disc_loss = 0.06472543271872115
Trained batch 343 in epoch 16, gen_loss = 0.8602602946203809, disc_loss = 0.0646155115953365
Trained batch 344 in epoch 16, gen_loss = 0.8595244317814924, disc_loss = 0.06481342909560688
Trained batch 345 in epoch 16, gen_loss = 0.8607345547290207, disc_loss = 0.06482627886654324
Trained batch 346 in epoch 16, gen_loss = 0.8606850300467324, disc_loss = 0.06508311317959849
Trained batch 347 in epoch 16, gen_loss = 0.8601480155498132, disc_loss = 0.06519168358424614
Trained batch 348 in epoch 16, gen_loss = 0.8598998472478806, disc_loss = 0.06533645289845999
Trained batch 349 in epoch 16, gen_loss = 0.8594277046407972, disc_loss = 0.0652406117107187
Trained batch 350 in epoch 16, gen_loss = 0.8596376936320226, disc_loss = 0.06543199720121178
Trained batch 351 in epoch 16, gen_loss = 0.8588197187266566, disc_loss = 0.06562731696546754
Trained batch 352 in epoch 16, gen_loss = 0.8590222774416462, disc_loss = 0.06547712813271342
Trained batch 353 in epoch 16, gen_loss = 0.85981624594516, disc_loss = 0.06539775543756741
Trained batch 354 in epoch 16, gen_loss = 0.8599420503831245, disc_loss = 0.06523743917457235
Trained batch 355 in epoch 16, gen_loss = 0.8597021253591173, disc_loss = 0.06535295553222885
Trained batch 356 in epoch 16, gen_loss = 0.8594831405233603, disc_loss = 0.06522769624685623
Trained batch 357 in epoch 16, gen_loss = 0.8591424594711325, disc_loss = 0.06516397466321149
Trained batch 358 in epoch 16, gen_loss = 0.8599243208890506, disc_loss = 0.06502412108854912
Trained batch 359 in epoch 16, gen_loss = 0.859659592476156, disc_loss = 0.06491489969970038
Trained batch 360 in epoch 16, gen_loss = 0.8601386264750832, disc_loss = 0.06476803380645131
Trained batch 361 in epoch 16, gen_loss = 0.8606715177633486, disc_loss = 0.06478673829671346
Trained batch 362 in epoch 16, gen_loss = 0.8604087450287559, disc_loss = 0.06477713857626045
Trained batch 363 in epoch 16, gen_loss = 0.8596641455705349, disc_loss = 0.06484118934751458
Trained batch 364 in epoch 16, gen_loss = 0.8606160547635326, disc_loss = 0.06485228695434658
Trained batch 365 in epoch 16, gen_loss = 0.8600199914695136, disc_loss = 0.06478520756322748
Trained batch 366 in epoch 16, gen_loss = 0.8596928139148681, disc_loss = 0.06470924768881106
Trained batch 367 in epoch 16, gen_loss = 0.8592542435811914, disc_loss = 0.06468001838884843
Trained batch 368 in epoch 16, gen_loss = 0.8592252191812365, disc_loss = 0.064554531361938
Trained batch 369 in epoch 16, gen_loss = 0.8595753548918543, disc_loss = 0.06455584293533419
Trained batch 370 in epoch 16, gen_loss = 0.8599946914978747, disc_loss = 0.06440554589103416
Trained batch 371 in epoch 16, gen_loss = 0.8595483593081915, disc_loss = 0.06455401703464969
Trained batch 372 in epoch 16, gen_loss = 0.8585868198174893, disc_loss = 0.06475294814582405
Trained batch 373 in epoch 16, gen_loss = 0.8583390282437126, disc_loss = 0.06467155075039376
Trained batch 374 in epoch 16, gen_loss = 0.8586892708142598, disc_loss = 0.06468363512307405
Trained batch 375 in epoch 16, gen_loss = 0.8586223028758739, disc_loss = 0.06462646205166474
Trained batch 376 in epoch 16, gen_loss = 0.8581437422679021, disc_loss = 0.06465513704576843
Trained batch 377 in epoch 16, gen_loss = 0.8582847935182077, disc_loss = 0.06454865732254884
Trained batch 378 in epoch 16, gen_loss = 0.8578418254223222, disc_loss = 0.06450310738948924
Trained batch 379 in epoch 16, gen_loss = 0.8575189068129189, disc_loss = 0.06448742948521517
Trained batch 380 in epoch 16, gen_loss = 0.8568882641829844, disc_loss = 0.06446243050383536
Trained batch 381 in epoch 16, gen_loss = 0.8568287349808279, disc_loss = 0.06433402106204894
Trained batch 382 in epoch 16, gen_loss = 0.8575065426975877, disc_loss = 0.0642961697268735
Trained batch 383 in epoch 16, gen_loss = 0.8578548699927827, disc_loss = 0.06424020773071486
Trained batch 384 in epoch 16, gen_loss = 0.8570859726373251, disc_loss = 0.06444200535679792
Trained batch 385 in epoch 16, gen_loss = 0.8568338852163424, disc_loss = 0.06442725586034165
Trained batch 386 in epoch 16, gen_loss = 0.856954466772942, disc_loss = 0.06428492331314226
Trained batch 387 in epoch 16, gen_loss = 0.8564409705781445, disc_loss = 0.06432698986051393
Trained batch 388 in epoch 16, gen_loss = 0.8565919400793728, disc_loss = 0.06419386564583965
Trained batch 389 in epoch 16, gen_loss = 0.8568989382340357, disc_loss = 0.06429408742114902
Trained batch 390 in epoch 16, gen_loss = 0.8568695480256434, disc_loss = 0.06420210862051115
Trained batch 391 in epoch 16, gen_loss = 0.8565355315804482, disc_loss = 0.06415892314232353
Trained batch 392 in epoch 16, gen_loss = 0.8553558978567293, disc_loss = 0.0644558628111054
Trained batch 393 in epoch 16, gen_loss = 0.8550553216698206, disc_loss = 0.06439142934930733
Trained batch 394 in epoch 16, gen_loss = 0.854877013269859, disc_loss = 0.0644618438934035
Trained batch 395 in epoch 16, gen_loss = 0.8545094301754778, disc_loss = 0.06443115177733655
Trained batch 396 in epoch 16, gen_loss = 0.85411172842499, disc_loss = 0.0643240114702123
Trained batch 397 in epoch 16, gen_loss = 0.8539915090080482, disc_loss = 0.06431668289426958
Trained batch 398 in epoch 16, gen_loss = 0.853874698542712, disc_loss = 0.06423054055023686
Trained batch 399 in epoch 16, gen_loss = 0.8548337390273809, disc_loss = 0.06476303635397926
Trained batch 400 in epoch 16, gen_loss = 0.8538909195515878, disc_loss = 0.06524921517280347
Trained batch 401 in epoch 16, gen_loss = 0.8537940652067981, disc_loss = 0.06525653111632561
Trained batch 402 in epoch 16, gen_loss = 0.8534942539247035, disc_loss = 0.06524251854606435
Trained batch 403 in epoch 16, gen_loss = 0.8536395766209848, disc_loss = 0.06522447529414871
Trained batch 404 in epoch 16, gen_loss = 0.8535178285322071, disc_loss = 0.06523262906451652
Trained batch 405 in epoch 16, gen_loss = 0.8534207635471973, disc_loss = 0.06515440661597795
Trained batch 406 in epoch 16, gen_loss = 0.8537554634730412, disc_loss = 0.06501420232163015
Trained batch 407 in epoch 16, gen_loss = 0.8538275066690117, disc_loss = 0.06488577485102795
Trained batch 408 in epoch 16, gen_loss = 0.8537408969658803, disc_loss = 0.06486269041513318
Trained batch 409 in epoch 16, gen_loss = 0.8541429664303617, disc_loss = 0.06480386020479406
Trained batch 410 in epoch 16, gen_loss = 0.8543045609971903, disc_loss = 0.06470760089909508
Trained batch 411 in epoch 16, gen_loss = 0.8545395352163361, disc_loss = 0.06456991162567029
Trained batch 412 in epoch 16, gen_loss = 0.8543007973464292, disc_loss = 0.0644895415482524
Trained batch 413 in epoch 16, gen_loss = 0.8540895347289993, disc_loss = 0.06447696251623729
Trained batch 414 in epoch 16, gen_loss = 0.8546455911125045, disc_loss = 0.06469852929284056
Trained batch 415 in epoch 16, gen_loss = 0.8544026116768901, disc_loss = 0.0646172910883951
Trained batch 416 in epoch 16, gen_loss = 0.8547007493692622, disc_loss = 0.06449347097489187
Trained batch 417 in epoch 16, gen_loss = 0.8541071345789011, disc_loss = 0.06456719216797055
Trained batch 418 in epoch 16, gen_loss = 0.8541258608384462, disc_loss = 0.06457398690478898
Trained batch 419 in epoch 16, gen_loss = 0.8540779710525558, disc_loss = 0.06448291420847888
Trained batch 420 in epoch 16, gen_loss = 0.8538653301937846, disc_loss = 0.06441388852151018
Trained batch 421 in epoch 16, gen_loss = 0.8542246096083338, disc_loss = 0.06432357509466002
Trained batch 422 in epoch 16, gen_loss = 0.8547105420706683, disc_loss = 0.06425046251016728
Trained batch 423 in epoch 16, gen_loss = 0.8543618778996872, disc_loss = 0.06414822946337737
Trained batch 424 in epoch 16, gen_loss = 0.8539695833009832, disc_loss = 0.06406762327779741
Trained batch 425 in epoch 16, gen_loss = 0.8546841920401569, disc_loss = 0.06397359982622622
Trained batch 426 in epoch 16, gen_loss = 0.8546640591682818, disc_loss = 0.06386850320622849
Trained batch 427 in epoch 16, gen_loss = 0.855013812883435, disc_loss = 0.06379459706074167
Trained batch 428 in epoch 16, gen_loss = 0.8551268314287102, disc_loss = 0.06372097317815383
Trained batch 429 in epoch 16, gen_loss = 0.8546447219543679, disc_loss = 0.0637648059964873
Trained batch 430 in epoch 16, gen_loss = 0.8546215134679304, disc_loss = 0.06365709774317155
Trained batch 431 in epoch 16, gen_loss = 0.8544974729280781, disc_loss = 0.0638421878080677
Trained batch 432 in epoch 16, gen_loss = 0.854397640974362, disc_loss = 0.06378593430026298
Trained batch 433 in epoch 16, gen_loss = 0.853691849222381, disc_loss = 0.06387066168169822
Trained batch 434 in epoch 16, gen_loss = 0.8535327849031865, disc_loss = 0.06379555993895421
Trained batch 435 in epoch 16, gen_loss = 0.8545042041928397, disc_loss = 0.06379076832512376
Trained batch 436 in epoch 16, gen_loss = 0.8547520436329481, disc_loss = 0.06368814294548275
Trained batch 437 in epoch 16, gen_loss = 0.85453206171456, disc_loss = 0.06366872226130472
Trained batch 438 in epoch 16, gen_loss = 0.8548441832728157, disc_loss = 0.06354903519696689
Trained batch 439 in epoch 16, gen_loss = 0.8551561329175126, disc_loss = 0.06346508912234143
Trained batch 440 in epoch 16, gen_loss = 0.8552073181486454, disc_loss = 0.06335156235438423
Trained batch 441 in epoch 16, gen_loss = 0.8553652689872284, disc_loss = 0.06323091504142969
Trained batch 442 in epoch 16, gen_loss = 0.8554751850815981, disc_loss = 0.06312408199445524
Trained batch 443 in epoch 16, gen_loss = 0.8557406899494093, disc_loss = 0.0630401466629124
Trained batch 444 in epoch 16, gen_loss = 0.8555177240559224, disc_loss = 0.06294453868202948
Trained batch 445 in epoch 16, gen_loss = 0.854820894486701, disc_loss = 0.06308024781735222
Trained batch 446 in epoch 16, gen_loss = 0.8553165831421846, disc_loss = 0.06320747887294831
Trained batch 447 in epoch 16, gen_loss = 0.855776604996728, disc_loss = 0.06318483678790342
Trained batch 448 in epoch 16, gen_loss = 0.856010809042937, disc_loss = 0.06307531071449309
Trained batch 449 in epoch 16, gen_loss = 0.855857319633166, disc_loss = 0.0630246392182178
Trained batch 450 in epoch 16, gen_loss = 0.8557848965381571, disc_loss = 0.0630010425044996
Trained batch 451 in epoch 16, gen_loss = 0.8552888963470416, disc_loss = 0.06307989894206413
Trained batch 452 in epoch 16, gen_loss = 0.856327412078449, disc_loss = 0.06322256712115495
Trained batch 453 in epoch 16, gen_loss = 0.8557452561440447, disc_loss = 0.06323010782559406
Trained batch 454 in epoch 16, gen_loss = 0.8558549775527073, disc_loss = 0.06337770531056347
Trained batch 455 in epoch 16, gen_loss = 0.8552618399915988, disc_loss = 0.06355236731714715
Trained batch 456 in epoch 16, gen_loss = 0.8556264588686778, disc_loss = 0.06344084371965485
Trained batch 457 in epoch 16, gen_loss = 0.8556892033097004, disc_loss = 0.0634056670412291
Trained batch 458 in epoch 16, gen_loss = 0.8554029487446763, disc_loss = 0.06347006707490789
Trained batch 459 in epoch 16, gen_loss = 0.8553192395878875, disc_loss = 0.06337869353187472
Trained batch 460 in epoch 16, gen_loss = 0.8548167091258954, disc_loss = 0.06336594969761475
Trained batch 461 in epoch 16, gen_loss = 0.8548016152727655, disc_loss = 0.06334912233877105
Trained batch 462 in epoch 16, gen_loss = 0.8549391264920616, disc_loss = 0.0634769085939515
Trained batch 463 in epoch 16, gen_loss = 0.8543551295096504, disc_loss = 0.06358859173006154
Trained batch 464 in epoch 16, gen_loss = 0.8549065139344943, disc_loss = 0.06356860055958712
Trained batch 465 in epoch 16, gen_loss = 0.8546488111750762, disc_loss = 0.06352237000054173
Trained batch 466 in epoch 16, gen_loss = 0.8543680188359745, disc_loss = 0.0634698885467055
Trained batch 467 in epoch 16, gen_loss = 0.8546582957745618, disc_loss = 0.0636638685161423
Trained batch 468 in epoch 16, gen_loss = 0.8548205925076247, disc_loss = 0.06355040190197321
Trained batch 469 in epoch 16, gen_loss = 0.8540728246277951, disc_loss = 0.06392363108734184
Trained batch 470 in epoch 16, gen_loss = 0.8538828544682505, disc_loss = 0.06390577200562901
Trained batch 471 in epoch 16, gen_loss = 0.8542204312980175, disc_loss = 0.06390098342080049
Trained batch 472 in epoch 16, gen_loss = 0.8544031655687611, disc_loss = 0.06392015398816692
Trained batch 473 in epoch 16, gen_loss = 0.8543731705423145, disc_loss = 0.06387246881301205
Trained batch 474 in epoch 16, gen_loss = 0.8542357436606759, disc_loss = 0.06378302590039216
Trained batch 475 in epoch 16, gen_loss = 0.853676385175781, disc_loss = 0.06382548849943619
Trained batch 476 in epoch 16, gen_loss = 0.8537723992480671, disc_loss = 0.06371896874464159
Trained batch 477 in epoch 16, gen_loss = 0.8543824824703289, disc_loss = 0.06373720977330681
Trained batch 478 in epoch 16, gen_loss = 0.8545136907777607, disc_loss = 0.0636484987668242
Trained batch 479 in epoch 16, gen_loss = 0.8540085831657052, disc_loss = 0.06370368588638181
Trained batch 480 in epoch 16, gen_loss = 0.8541565239429474, disc_loss = 0.06364969653997128
Trained batch 481 in epoch 16, gen_loss = 0.8542629364738821, disc_loss = 0.06354281621602562
Trained batch 482 in epoch 16, gen_loss = 0.8545855160949146, disc_loss = 0.06347231458926546
Trained batch 483 in epoch 16, gen_loss = 0.8547273110136513, disc_loss = 0.06336619205434214
Trained batch 484 in epoch 16, gen_loss = 0.8545805114446227, disc_loss = 0.06342030292780129
Trained batch 485 in epoch 16, gen_loss = 0.8542718683128003, disc_loss = 0.06338134714605387
Trained batch 486 in epoch 16, gen_loss = 0.8545739623188238, disc_loss = 0.06333678570677367
Trained batch 487 in epoch 16, gen_loss = 0.8548006275516065, disc_loss = 0.0634410802397083
Trained batch 488 in epoch 16, gen_loss = 0.8544392535169676, disc_loss = 0.06370416073345699
Trained batch 489 in epoch 16, gen_loss = 0.8551867906536375, disc_loss = 0.06375964270258436
Trained batch 490 in epoch 16, gen_loss = 0.8549941713236986, disc_loss = 0.06368456738043099
Trained batch 491 in epoch 16, gen_loss = 0.8550144984591298, disc_loss = 0.06362754030425738
Trained batch 492 in epoch 16, gen_loss = 0.8550653390541038, disc_loss = 0.063793801477757
Trained batch 493 in epoch 16, gen_loss = 0.8546812445649251, disc_loss = 0.06379484591500359
Trained batch 494 in epoch 16, gen_loss = 0.8542728647439167, disc_loss = 0.06382383633066308
Trained batch 495 in epoch 16, gen_loss = 0.8545958048273479, disc_loss = 0.06372673959366136
Trained batch 496 in epoch 16, gen_loss = 0.8548017070446935, disc_loss = 0.06373082259876027
Trained batch 497 in epoch 16, gen_loss = 0.8550890495619142, disc_loss = 0.06365586856537196
Trained batch 498 in epoch 16, gen_loss = 0.854124561280669, disc_loss = 0.06411676891596021
Trained batch 499 in epoch 16, gen_loss = 0.8541531229615211, disc_loss = 0.06402927280962467
Trained batch 500 in epoch 16, gen_loss = 0.8544790307561795, disc_loss = 0.06395953923404336
Trained batch 501 in epoch 16, gen_loss = 0.8544573283409217, disc_loss = 0.0639165680469626
Trained batch 502 in epoch 16, gen_loss = 0.8546197374701263, disc_loss = 0.06387438460680885
Trained batch 503 in epoch 16, gen_loss = 0.8543740938461962, disc_loss = 0.06386328141929375
Trained batch 504 in epoch 16, gen_loss = 0.8544011770498634, disc_loss = 0.06380532901770998
Trained batch 505 in epoch 16, gen_loss = 0.8546482299274135, disc_loss = 0.06372134169571013
Trained batch 506 in epoch 16, gen_loss = 0.8550011587918863, disc_loss = 0.06383957140720807
Trained batch 507 in epoch 16, gen_loss = 0.8543567343607662, disc_loss = 0.06422285599208723
Trained batch 508 in epoch 16, gen_loss = 0.8543443563293615, disc_loss = 0.06416064185366649
Trained batch 509 in epoch 16, gen_loss = 0.8552287607216368, disc_loss = 0.06455421185522688
Trained batch 510 in epoch 16, gen_loss = 0.8552111680610306, disc_loss = 0.06449238376403975
Trained batch 511 in epoch 16, gen_loss = 0.8551934966235422, disc_loss = 0.06448586330952821
Trained batch 512 in epoch 16, gen_loss = 0.8547942335726457, disc_loss = 0.06457368770276593
Trained batch 513 in epoch 16, gen_loss = 0.8549928893027139, disc_loss = 0.06450842453550967
Trained batch 514 in epoch 16, gen_loss = 0.8552166749551459, disc_loss = 0.06465051752126333
Trained batch 515 in epoch 16, gen_loss = 0.8548841592530871, disc_loss = 0.0647294612947938
Trained batch 516 in epoch 16, gen_loss = 0.8543784254639476, disc_loss = 0.0648430645883775
Trained batch 517 in epoch 16, gen_loss = 0.8544246619387483, disc_loss = 0.06476301098652328
Trained batch 518 in epoch 16, gen_loss = 0.8544611718957824, disc_loss = 0.06467010041336334
Trained batch 519 in epoch 16, gen_loss = 0.85470530591332, disc_loss = 0.06464725247082802
Trained batch 520 in epoch 16, gen_loss = 0.8546675530024544, disc_loss = 0.06464512792063766
Trained batch 521 in epoch 16, gen_loss = 0.8543443442875398, disc_loss = 0.06475660713011278
Trained batch 522 in epoch 16, gen_loss = 0.8541831553666132, disc_loss = 0.0647486040144304
Trained batch 523 in epoch 16, gen_loss = 0.8539176015112236, disc_loss = 0.06494231062820395
Trained batch 524 in epoch 16, gen_loss = 0.8539202892780304, disc_loss = 0.06502333757423219
Trained batch 525 in epoch 16, gen_loss = 0.8536157036348894, disc_loss = 0.06500066788477589
Trained batch 526 in epoch 16, gen_loss = 0.8530925831826407, disc_loss = 0.06511002402943497
Trained batch 527 in epoch 16, gen_loss = 0.8527067990578485, disc_loss = 0.06509465471643841
Trained batch 528 in epoch 16, gen_loss = 0.8528928189399337, disc_loss = 0.06521435770679737
Trained batch 529 in epoch 16, gen_loss = 0.8532324361913609, disc_loss = 0.06517802708132087
Trained batch 530 in epoch 16, gen_loss = 0.8525799895073735, disc_loss = 0.06535467511769068
Trained batch 531 in epoch 16, gen_loss = 0.8528415008931232, disc_loss = 0.06528646888253384
Trained batch 532 in epoch 16, gen_loss = 0.852410529556686, disc_loss = 0.0653090654797223
Trained batch 533 in epoch 16, gen_loss = 0.8528139066048775, disc_loss = 0.0652897148375654
Trained batch 534 in epoch 16, gen_loss = 0.8533528605911219, disc_loss = 0.06523742464797519
Trained batch 535 in epoch 16, gen_loss = 0.85336015356788, disc_loss = 0.06516047181742293
Trained batch 536 in epoch 16, gen_loss = 0.8534907664777625, disc_loss = 0.0650735073055191
Trained batch 537 in epoch 16, gen_loss = 0.8534360901906145, disc_loss = 0.06503589314211257
Trained batch 538 in epoch 16, gen_loss = 0.8534763115345879, disc_loss = 0.06497028258202359
Trained batch 539 in epoch 16, gen_loss = 0.8534047351391227, disc_loss = 0.06490278869384417
Trained batch 540 in epoch 16, gen_loss = 0.8536749123535403, disc_loss = 0.0648682893816788
Trained batch 541 in epoch 16, gen_loss = 0.8537094517717502, disc_loss = 0.06476478143062483
Trained batch 542 in epoch 16, gen_loss = 0.8535199891467121, disc_loss = 0.06473259454075089
Trained batch 543 in epoch 16, gen_loss = 0.8534991301267463, disc_loss = 0.06466209117891542
Trained batch 544 in epoch 16, gen_loss = 0.8541515359637935, disc_loss = 0.06461387958651016
Trained batch 545 in epoch 16, gen_loss = 0.8542331168393948, disc_loss = 0.06451744553650092
Trained batch 546 in epoch 16, gen_loss = 0.8542749780950424, disc_loss = 0.06442070725481187
Trained batch 547 in epoch 16, gen_loss = 0.8541195203896856, disc_loss = 0.06435994717231305
Trained batch 548 in epoch 16, gen_loss = 0.8539663362698476, disc_loss = 0.06455520658884435
Trained batch 549 in epoch 16, gen_loss = 0.8538565910404379, disc_loss = 0.06447776729749008
Trained batch 550 in epoch 16, gen_loss = 0.8536689168420332, disc_loss = 0.06449873441536176
Trained batch 551 in epoch 16, gen_loss = 0.8538844229626483, disc_loss = 0.06444992082854868
Trained batch 552 in epoch 16, gen_loss = 0.8543798365709363, disc_loss = 0.06437029917918105
Trained batch 553 in epoch 16, gen_loss = 0.8545674536955485, disc_loss = 0.06427338458463173
Trained batch 554 in epoch 16, gen_loss = 0.8544416823365667, disc_loss = 0.06422762589545937
Trained batch 555 in epoch 16, gen_loss = 0.8551186325845959, disc_loss = 0.06427934680723672
Trained batch 556 in epoch 16, gen_loss = 0.8545744600480077, disc_loss = 0.06432968731869274
Trained batch 557 in epoch 16, gen_loss = 0.8540933595229221, disc_loss = 0.06433439915031729
Trained batch 558 in epoch 16, gen_loss = 0.8541232899284533, disc_loss = 0.064276068662968
Trained batch 559 in epoch 16, gen_loss = 0.8546367236013923, disc_loss = 0.0649048468962844
Trained batch 560 in epoch 16, gen_loss = 0.8540878613046147, disc_loss = 0.06496662798598275
Trained batch 561 in epoch 16, gen_loss = 0.8536648484629669, disc_loss = 0.0649712452220853
Trained batch 562 in epoch 16, gen_loss = 0.8539940971570159, disc_loss = 0.06491902348838521
Trained batch 563 in epoch 16, gen_loss = 0.8542352941759089, disc_loss = 0.06483099166739811
Trained batch 564 in epoch 16, gen_loss = 0.8539308954656651, disc_loss = 0.06481105898531665
Trained batch 565 in epoch 16, gen_loss = 0.8539385887738251, disc_loss = 0.06475522808480494
Trained batch 566 in epoch 16, gen_loss = 0.8537775403713213, disc_loss = 0.06470472688541946
Trained batch 567 in epoch 16, gen_loss = 0.8536276903895426, disc_loss = 0.06500458204134985
Trained batch 568 in epoch 16, gen_loss = 0.853669925240934, disc_loss = 0.06493778534312135
Trained batch 569 in epoch 16, gen_loss = 0.8541616697583282, disc_loss = 0.06486518811434508
Trained batch 570 in epoch 16, gen_loss = 0.8541122262093733, disc_loss = 0.0648127591201543
Trained batch 571 in epoch 16, gen_loss = 0.8536094821520619, disc_loss = 0.06497235129541763
Trained batch 572 in epoch 16, gen_loss = 0.8540261576625066, disc_loss = 0.06511890864484077
Trained batch 573 in epoch 16, gen_loss = 0.8536325386280798, disc_loss = 0.06515591458875024
Trained batch 574 in epoch 16, gen_loss = 0.8532370513936748, disc_loss = 0.06516802477771821
Trained batch 575 in epoch 16, gen_loss = 0.8536078321954442, disc_loss = 0.06531682968488894
Trained batch 576 in epoch 16, gen_loss = 0.853398841888074, disc_loss = 0.06529706566428291
Trained batch 577 in epoch 16, gen_loss = 0.8531663080090882, disc_loss = 0.06527032178849188
Trained batch 578 in epoch 16, gen_loss = 0.8530503817687587, disc_loss = 0.06525588553199393
Trained batch 579 in epoch 16, gen_loss = 0.8535266896260196, disc_loss = 0.06529290920508833
Trained batch 580 in epoch 16, gen_loss = 0.853328878980085, disc_loss = 0.0652515235518886
Trained batch 581 in epoch 16, gen_loss = 0.8533802504084774, disc_loss = 0.06521599687623097
Trained batch 582 in epoch 16, gen_loss = 0.8535337591764244, disc_loss = 0.06512395227343917
Trained batch 583 in epoch 16, gen_loss = 0.8535906870989767, disc_loss = 0.06504009361697795
Trained batch 584 in epoch 16, gen_loss = 0.8536536832650502, disc_loss = 0.06494828965037297
Trained batch 585 in epoch 16, gen_loss = 0.8534480661357222, disc_loss = 0.0649433251368613
Trained batch 586 in epoch 16, gen_loss = 0.8529005781247628, disc_loss = 0.06501792699377826
Trained batch 587 in epoch 16, gen_loss = 0.8531870780652072, disc_loss = 0.06513667581159444
Trained batch 588 in epoch 16, gen_loss = 0.8536981647306063, disc_loss = 0.06511818119190342
Trained batch 589 in epoch 16, gen_loss = 0.8534164932319673, disc_loss = 0.06511036571809801
Trained batch 590 in epoch 16, gen_loss = 0.8529701334268308, disc_loss = 0.06516573360022757
Trained batch 591 in epoch 16, gen_loss = 0.8533535829770404, disc_loss = 0.06524436491717761
Trained batch 592 in epoch 16, gen_loss = 0.8529483908646023, disc_loss = 0.06519845135597917
Trained batch 593 in epoch 16, gen_loss = 0.8528944535387887, disc_loss = 0.06511839492064635
Trained batch 594 in epoch 16, gen_loss = 0.8527449889844205, disc_loss = 0.06509353474972128
Trained batch 595 in epoch 16, gen_loss = 0.852940425426768, disc_loss = 0.06506933486589149
Trained batch 596 in epoch 16, gen_loss = 0.8531182544614802, disc_loss = 0.06499507138115578
Trained batch 597 in epoch 16, gen_loss = 0.8531500468385658, disc_loss = 0.064923414387382
Trained batch 598 in epoch 16, gen_loss = 0.8531773624217172, disc_loss = 0.06488149221333518
Trained batch 599 in epoch 16, gen_loss = 0.8526063710947831, disc_loss = 0.06501386329531669
Trained batch 600 in epoch 16, gen_loss = 0.852656922651805, disc_loss = 0.06494456537055493
Trained batch 601 in epoch 16, gen_loss = 0.8528772777200141, disc_loss = 0.06485146068754387
Trained batch 602 in epoch 16, gen_loss = 0.8532881371516295, disc_loss = 0.06496498621320645
Trained batch 603 in epoch 16, gen_loss = 0.8528853473777802, disc_loss = 0.06510284291395288
Trained batch 604 in epoch 16, gen_loss = 0.8527691594332703, disc_loss = 0.0650637672952384
Trained batch 605 in epoch 16, gen_loss = 0.853222174170387, disc_loss = 0.06500493030282038
Trained batch 606 in epoch 16, gen_loss = 0.8535842466884626, disc_loss = 0.06522411894501237
Trained batch 607 in epoch 16, gen_loss = 0.853225608552365, disc_loss = 0.06524729304395518
Trained batch 608 in epoch 16, gen_loss = 0.8528957299900368, disc_loss = 0.0652069888415644
Trained batch 609 in epoch 16, gen_loss = 0.8526384173358073, disc_loss = 0.06518202608787134
Trained batch 610 in epoch 16, gen_loss = 0.8525104889015129, disc_loss = 0.06517964605479798
Trained batch 611 in epoch 16, gen_loss = 0.852871510084548, disc_loss = 0.06508859430798908
Trained batch 612 in epoch 16, gen_loss = 0.8530711193749799, disc_loss = 0.06522491094192906
Trained batch 613 in epoch 16, gen_loss = 0.8530225248503762, disc_loss = 0.065162497087221
Trained batch 614 in epoch 16, gen_loss = 0.8526249566213872, disc_loss = 0.06519882693826183
Trained batch 615 in epoch 16, gen_loss = 0.8528059123495182, disc_loss = 0.06510599504237051
Trained batch 616 in epoch 16, gen_loss = 0.8531029292501545, disc_loss = 0.06508224289652981
Trained batch 617 in epoch 16, gen_loss = 0.8530316989880935, disc_loss = 0.06500667191041229
Trained batch 618 in epoch 16, gen_loss = 0.8527096882101407, disc_loss = 0.06502106003102173
Trained batch 619 in epoch 16, gen_loss = 0.8528391475158353, disc_loss = 0.06494711095827722
Trained batch 620 in epoch 16, gen_loss = 0.8525787889957428, disc_loss = 0.06490175668660089
Trained batch 621 in epoch 16, gen_loss = 0.8533858477206859, disc_loss = 0.0649146359575571
Trained batch 622 in epoch 16, gen_loss = 0.8533355719492103, disc_loss = 0.06484530016146062
Trained batch 623 in epoch 16, gen_loss = 0.8529753676878337, disc_loss = 0.06488601277427127
Trained batch 624 in epoch 16, gen_loss = 0.8528955913066864, disc_loss = 0.06487688021361827
Trained batch 625 in epoch 16, gen_loss = 0.8528724982620428, disc_loss = 0.0648493320077134
Trained batch 626 in epoch 16, gen_loss = 0.8526316586959115, disc_loss = 0.064802411738694
Trained batch 627 in epoch 16, gen_loss = 0.8531418877896989, disc_loss = 0.06474817285587074
Trained batch 628 in epoch 16, gen_loss = 0.8529045547229877, disc_loss = 0.06475152175974201
Trained batch 629 in epoch 16, gen_loss = 0.8530868162711461, disc_loss = 0.06466307026881074
Trained batch 630 in epoch 16, gen_loss = 0.8530059581985564, disc_loss = 0.0648349122027682
Trained batch 631 in epoch 16, gen_loss = 0.8530666177880161, disc_loss = 0.06475614747798801
Trained batch 632 in epoch 16, gen_loss = 0.8530117868906325, disc_loss = 0.06467463856042138
Trained batch 633 in epoch 16, gen_loss = 0.8532477706106679, disc_loss = 0.06458784800980605
Trained batch 634 in epoch 16, gen_loss = 0.8529900100756818, disc_loss = 0.06458933841671766
Trained batch 635 in epoch 16, gen_loss = 0.8525371358923193, disc_loss = 0.06465973828204633
Trained batch 636 in epoch 16, gen_loss = 0.8532147437942271, disc_loss = 0.06471269160327817
Trained batch 637 in epoch 16, gen_loss = 0.8534553664324799, disc_loss = 0.06474052109320569
Trained batch 638 in epoch 16, gen_loss = 0.8528118039334137, disc_loss = 0.06489707591487255
Trained batch 639 in epoch 16, gen_loss = 0.8529561153613031, disc_loss = 0.06481853163713822
Trained batch 640 in epoch 16, gen_loss = 0.8531561069853034, disc_loss = 0.06478239829083919
Trained batch 641 in epoch 16, gen_loss = 0.853055001976334, disc_loss = 0.06472420972856081
Trained batch 642 in epoch 16, gen_loss = 0.8528744223329179, disc_loss = 0.06467053212636784
Trained batch 643 in epoch 16, gen_loss = 0.8529579445071842, disc_loss = 0.06465401950072475
Trained batch 644 in epoch 16, gen_loss = 0.8527326269667278, disc_loss = 0.0646756532652549
Trained batch 645 in epoch 16, gen_loss = 0.8529047691047007, disc_loss = 0.06482353048318357
Trained batch 646 in epoch 16, gen_loss = 0.8522887737526222, disc_loss = 0.06514426064713523
Trained batch 647 in epoch 16, gen_loss = 0.8521318275619436, disc_loss = 0.06515172535099412
Trained batch 648 in epoch 16, gen_loss = 0.8523041834632862, disc_loss = 0.06512471275958011
Trained batch 649 in epoch 16, gen_loss = 0.8525790797747098, disc_loss = 0.06515194650023029
Trained batch 650 in epoch 16, gen_loss = 0.8525557352284315, disc_loss = 0.06514891614842754
Trained batch 651 in epoch 16, gen_loss = 0.851975787865238, disc_loss = 0.06526608355029091
Trained batch 652 in epoch 16, gen_loss = 0.8518102346572906, disc_loss = 0.06526329466619545
Trained batch 653 in epoch 16, gen_loss = 0.8523336253855207, disc_loss = 0.06524031400390037
Trained batch 654 in epoch 16, gen_loss = 0.8520076872283265, disc_loss = 0.06522094631382755
Trained batch 655 in epoch 16, gen_loss = 0.8523053525515446, disc_loss = 0.06515670594015363
Trained batch 656 in epoch 16, gen_loss = 0.8524148441068659, disc_loss = 0.0650914031374332
Trained batch 657 in epoch 16, gen_loss = 0.8522520643690075, disc_loss = 0.0651106939334026
Trained batch 658 in epoch 16, gen_loss = 0.8523084302863873, disc_loss = 0.0650653091919282
Trained batch 659 in epoch 16, gen_loss = 0.8520433241219232, disc_loss = 0.06507003733069834
Trained batch 660 in epoch 16, gen_loss = 0.8520720498734992, disc_loss = 0.06505274305010211
Trained batch 661 in epoch 16, gen_loss = 0.8528662633229599, disc_loss = 0.06524820984946142
Trained batch 662 in epoch 16, gen_loss = 0.8530927036592504, disc_loss = 0.06516990076812323
Trained batch 663 in epoch 16, gen_loss = 0.8527367714209011, disc_loss = 0.065302744171167
Trained batch 664 in epoch 16, gen_loss = 0.8527848748784316, disc_loss = 0.06522918524766776
Trained batch 665 in epoch 16, gen_loss = 0.8534108457175104, disc_loss = 0.06529050890647166
Trained batch 666 in epoch 16, gen_loss = 0.8535107803577069, disc_loss = 0.06522575150923929
Trained batch 667 in epoch 16, gen_loss = 0.8533709450307007, disc_loss = 0.06522297310994235
Trained batch 668 in epoch 16, gen_loss = 0.8538622321123855, disc_loss = 0.06518571435714694
Trained batch 669 in epoch 16, gen_loss = 0.8534685054376944, disc_loss = 0.06520298580958772
Trained batch 670 in epoch 16, gen_loss = 0.8532686313911273, disc_loss = 0.0652187311891383
Trained batch 671 in epoch 16, gen_loss = 0.853269176868101, disc_loss = 0.06516902002372912
Trained batch 672 in epoch 16, gen_loss = 0.8530790446683166, disc_loss = 0.06515252395335136
Trained batch 673 in epoch 16, gen_loss = 0.8533845015467098, disc_loss = 0.06507879574935142
Trained batch 674 in epoch 16, gen_loss = 0.8535809941203506, disc_loss = 0.06508920176989502
Trained batch 675 in epoch 16, gen_loss = 0.8532801893424, disc_loss = 0.06511679168008047
Trained batch 676 in epoch 16, gen_loss = 0.8536273107658989, disc_loss = 0.06504946605108425
Trained batch 677 in epoch 16, gen_loss = 0.8536999067813598, disc_loss = 0.06499619641036322
Trained batch 678 in epoch 16, gen_loss = 0.8539141251078761, disc_loss = 0.06497141017423551
Trained batch 679 in epoch 16, gen_loss = 0.8535400938900078, disc_loss = 0.06497161211719846
Trained batch 680 in epoch 16, gen_loss = 0.8535134227352871, disc_loss = 0.06493499724908285
Trained batch 681 in epoch 16, gen_loss = 0.8535453810457609, disc_loss = 0.06491787955875009
Trained batch 682 in epoch 16, gen_loss = 0.8538465104113561, disc_loss = 0.06487252085713743
Trained batch 683 in epoch 16, gen_loss = 0.8541756835684442, disc_loss = 0.06479223570731953
Trained batch 684 in epoch 16, gen_loss = 0.8540518157238508, disc_loss = 0.06476091635243518
Trained batch 685 in epoch 16, gen_loss = 0.8534242627658928, disc_loss = 0.06486806713734311
Trained batch 686 in epoch 16, gen_loss = 0.853913962624132, disc_loss = 0.06488140464626155
Trained batch 687 in epoch 16, gen_loss = 0.8539331070645604, disc_loss = 0.0648437638721039
Trained batch 688 in epoch 16, gen_loss = 0.8536947838886383, disc_loss = 0.0648597326759568
Trained batch 689 in epoch 16, gen_loss = 0.8540473932373351, disc_loss = 0.06490556371357778
Trained batch 690 in epoch 16, gen_loss = 0.8540725838689487, disc_loss = 0.06483010688120049
Trained batch 691 in epoch 16, gen_loss = 0.8537846498320557, disc_loss = 0.06489947211331112
Trained batch 692 in epoch 16, gen_loss = 0.8538169905134781, disc_loss = 0.06491216540089331
Trained batch 693 in epoch 16, gen_loss = 0.8539518470465278, disc_loss = 0.06486991261768152
Trained batch 694 in epoch 16, gen_loss = 0.8538177248814123, disc_loss = 0.06483531709251215
Trained batch 695 in epoch 16, gen_loss = 0.853613299242724, disc_loss = 0.06487224024356525
Trained batch 696 in epoch 16, gen_loss = 0.8538368131799712, disc_loss = 0.06483336501464868
Trained batch 697 in epoch 16, gen_loss = 0.8542405271683859, disc_loss = 0.06487098054154469
Trained batch 698 in epoch 16, gen_loss = 0.8538978915443066, disc_loss = 0.06501035398413268
Trained batch 699 in epoch 16, gen_loss = 0.8538757605637823, disc_loss = 0.06498683719496642
Trained batch 700 in epoch 16, gen_loss = 0.8541305249240702, disc_loss = 0.06493516667306252
Trained batch 701 in epoch 16, gen_loss = 0.8540114576575423, disc_loss = 0.0649868173397377
Trained batch 702 in epoch 16, gen_loss = 0.8540629566054935, disc_loss = 0.06493488774445454
Trained batch 703 in epoch 16, gen_loss = 0.8542775466445495, disc_loss = 0.06488403734031388
Trained batch 704 in epoch 16, gen_loss = 0.8539896008393443, disc_loss = 0.06494803324024728
Trained batch 705 in epoch 16, gen_loss = 0.8539213608665439, disc_loss = 0.06491115236544069
Trained batch 706 in epoch 16, gen_loss = 0.8538821704232541, disc_loss = 0.0650201532699937
Trained batch 707 in epoch 16, gen_loss = 0.8536901195759827, disc_loss = 0.06498731734325826
Trained batch 708 in epoch 16, gen_loss = 0.8535327771402716, disc_loss = 0.0649578692430922
Trained batch 709 in epoch 16, gen_loss = 0.8535981135888838, disc_loss = 0.06515118610376204
Trained batch 710 in epoch 16, gen_loss = 0.8538274669026858, disc_loss = 0.06507776589060803
Trained batch 711 in epoch 16, gen_loss = 0.8534746328682712, disc_loss = 0.06530261679625746
Trained batch 712 in epoch 16, gen_loss = 0.8537594490850456, disc_loss = 0.06524107269524776
Trained batch 713 in epoch 16, gen_loss = 0.8539026221390866, disc_loss = 0.0651739677127336
Trained batch 714 in epoch 16, gen_loss = 0.8540322337534044, disc_loss = 0.06520704778132738
Trained batch 715 in epoch 16, gen_loss = 0.8541627726491603, disc_loss = 0.06513766080723794
Trained batch 716 in epoch 16, gen_loss = 0.8539467920734959, disc_loss = 0.06517299439243691
Trained batch 717 in epoch 16, gen_loss = 0.8538040313298988, disc_loss = 0.06511635725544687
Trained batch 718 in epoch 16, gen_loss = 0.8540349724975846, disc_loss = 0.06504320310783651
Trained batch 719 in epoch 16, gen_loss = 0.854226275988751, disc_loss = 0.06502178930677474
Trained batch 720 in epoch 16, gen_loss = 0.854180555940501, disc_loss = 0.06497180203541637
Trained batch 721 in epoch 16, gen_loss = 0.8543171076480701, disc_loss = 0.06489787835091188
Trained batch 722 in epoch 16, gen_loss = 0.854207262005219, disc_loss = 0.06491522437649397
Trained batch 723 in epoch 16, gen_loss = 0.8542584451275635, disc_loss = 0.06487139180889198
Trained batch 724 in epoch 16, gen_loss = 0.8542777408813608, disc_loss = 0.06495754122990986
Trained batch 725 in epoch 16, gen_loss = 0.8542980577581185, disc_loss = 0.06489143289430657
Trained batch 726 in epoch 16, gen_loss = 0.8538925023403587, disc_loss = 0.06492708297254213
Trained batch 727 in epoch 16, gen_loss = 0.8538700410543563, disc_loss = 0.06486733676609839
Trained batch 728 in epoch 16, gen_loss = 0.8542482757682827, disc_loss = 0.06502360840607818
Trained batch 729 in epoch 16, gen_loss = 0.8542665317042233, disc_loss = 0.06497200151573714
Trained batch 730 in epoch 16, gen_loss = 0.8539532487027133, disc_loss = 0.06502087123528959
Trained batch 731 in epoch 16, gen_loss = 0.8538780769770914, disc_loss = 0.06505447102690248
Trained batch 732 in epoch 16, gen_loss = 0.8539929777424462, disc_loss = 0.06499776833450567
Trained batch 733 in epoch 16, gen_loss = 0.8539743641497979, disc_loss = 0.06492184725024151
Trained batch 734 in epoch 16, gen_loss = 0.8538912493760894, disc_loss = 0.06485864689104817
Trained batch 735 in epoch 16, gen_loss = 0.8538424739938067, disc_loss = 0.06481925680798115
Trained batch 736 in epoch 16, gen_loss = 0.8536456373281363, disc_loss = 0.06476010823700694
Trained batch 737 in epoch 16, gen_loss = 0.8542772684559267, disc_loss = 0.06477493076739192
Trained batch 738 in epoch 16, gen_loss = 0.8541267951786599, disc_loss = 0.06473285069938683
Trained batch 739 in epoch 16, gen_loss = 0.853796894284519, disc_loss = 0.06472155957457584
Trained batch 740 in epoch 16, gen_loss = 0.8537965195301251, disc_loss = 0.0646552830751025
Trained batch 741 in epoch 16, gen_loss = 0.8538598478081413, disc_loss = 0.06460448977414449
Trained batch 742 in epoch 16, gen_loss = 0.8539492827645863, disc_loss = 0.06452947167847631
Trained batch 743 in epoch 16, gen_loss = 0.8539810671360903, disc_loss = 0.06460883897749246
Trained batch 744 in epoch 16, gen_loss = 0.8539476289445121, disc_loss = 0.0645678342113759
Trained batch 745 in epoch 16, gen_loss = 0.8541359933787313, disc_loss = 0.06451277355176593
Trained batch 746 in epoch 16, gen_loss = 0.8543097733892749, disc_loss = 0.0644497874715282
Trained batch 747 in epoch 16, gen_loss = 0.8543579244119598, disc_loss = 0.06438967931447899
Trained batch 748 in epoch 16, gen_loss = 0.8538373263480666, disc_loss = 0.06455076587584133
Trained batch 749 in epoch 16, gen_loss = 0.8540799438556035, disc_loss = 0.0645014010493954
Trained batch 750 in epoch 16, gen_loss = 0.8545416032029849, disc_loss = 0.06464891800639554
Trained batch 751 in epoch 16, gen_loss = 0.8543782778322062, disc_loss = 0.06461654441242919
Trained batch 752 in epoch 16, gen_loss = 0.854125478867674, disc_loss = 0.06460180197153513
Trained batch 753 in epoch 16, gen_loss = 0.8547572357980263, disc_loss = 0.06465830965417213
Trained batch 754 in epoch 16, gen_loss = 0.8545443981293811, disc_loss = 0.06464427397987306
Trained batch 755 in epoch 16, gen_loss = 0.8545783062381719, disc_loss = 0.06460028374074865
Trained batch 756 in epoch 16, gen_loss = 0.8543250172975986, disc_loss = 0.06457390075935791
Trained batch 757 in epoch 16, gen_loss = 0.8541820888704864, disc_loss = 0.06453964046612971
Trained batch 758 in epoch 16, gen_loss = 0.8543018443075564, disc_loss = 0.06446874962091367
Trained batch 759 in epoch 16, gen_loss = 0.8543766233089723, disc_loss = 0.06439475896890814
Trained batch 760 in epoch 16, gen_loss = 0.8545121445997316, disc_loss = 0.06436291376542443
Trained batch 761 in epoch 16, gen_loss = 0.8545315301246218, disc_loss = 0.06430328919324936
Trained batch 762 in epoch 16, gen_loss = 0.85432575551273, disc_loss = 0.06429245034269354
Trained batch 763 in epoch 16, gen_loss = 0.8542568077825751, disc_loss = 0.06425018289555547
Trained batch 764 in epoch 16, gen_loss = 0.8543602957834605, disc_loss = 0.06419079302402299
Trained batch 765 in epoch 16, gen_loss = 0.8543045719594308, disc_loss = 0.06421226537944481
Trained batch 766 in epoch 16, gen_loss = 0.8538954510138586, disc_loss = 0.06431388558341479
Trained batch 767 in epoch 16, gen_loss = 0.8541098287096247, disc_loss = 0.0642543952332441
Trained batch 768 in epoch 16, gen_loss = 0.8547528346973836, disc_loss = 0.06423986541477889
Trained batch 769 in epoch 16, gen_loss = 0.8547723609518695, disc_loss = 0.06417677639439315
Trained batch 770 in epoch 16, gen_loss = 0.854842206499456, disc_loss = 0.06411453553302704
Trained batch 771 in epoch 16, gen_loss = 0.8549551050820499, disc_loss = 0.06421991863645073
Trained batch 772 in epoch 16, gen_loss = 0.854580185276108, disc_loss = 0.06435863183447453
Trained batch 773 in epoch 16, gen_loss = 0.8543277091373153, disc_loss = 0.06435869969499781
Trained batch 774 in epoch 16, gen_loss = 0.8541665108357707, disc_loss = 0.06434059594787897
Trained batch 775 in epoch 16, gen_loss = 0.8545599051741595, disc_loss = 0.06437217678332259
Trained batch 776 in epoch 16, gen_loss = 0.8549737820217201, disc_loss = 0.06434552828772916
Trained batch 777 in epoch 16, gen_loss = 0.8546970696942665, disc_loss = 0.06441567608234317
Trained batch 778 in epoch 16, gen_loss = 0.8546115541412221, disc_loss = 0.0643696272697907
Trained batch 779 in epoch 16, gen_loss = 0.8542476547452119, disc_loss = 0.06438958125117307
Trained batch 780 in epoch 16, gen_loss = 0.8545845461944918, disc_loss = 0.06459946827259434
Trained batch 781 in epoch 16, gen_loss = 0.854573024851282, disc_loss = 0.06455241337709149
Trained batch 782 in epoch 16, gen_loss = 0.8542903726813437, disc_loss = 0.06462319385222282
Trained batch 783 in epoch 16, gen_loss = 0.8542359489187294, disc_loss = 0.06458333392309178
Trained batch 784 in epoch 16, gen_loss = 0.8547377898814572, disc_loss = 0.06455778185468002
Trained batch 785 in epoch 16, gen_loss = 0.8544746859913868, disc_loss = 0.06454332107583265
Trained batch 786 in epoch 16, gen_loss = 0.8546200386678097, disc_loss = 0.06455558723163006
Trained batch 787 in epoch 16, gen_loss = 0.8543840892196912, disc_loss = 0.06454043835519724
Trained batch 788 in epoch 16, gen_loss = 0.8541391714368634, disc_loss = 0.06455880579277778
Trained batch 789 in epoch 16, gen_loss = 0.8541494327632687, disc_loss = 0.06449154831492637
Testing Epoch 16
Training Epoch 17
Trained batch 0 in epoch 17, gen_loss = 0.7937596440315247, disc_loss = 0.09136005491018295
Trained batch 1 in epoch 17, gen_loss = 0.885696679353714, disc_loss = 0.05458431411534548
Trained batch 2 in epoch 17, gen_loss = 0.8336623907089233, disc_loss = 0.05354968644678593
Trained batch 3 in epoch 17, gen_loss = 0.8585411459207535, disc_loss = 0.0530703398399055
Trained batch 4 in epoch 17, gen_loss = 0.851337444782257, disc_loss = 0.047615482658147815
Trained batch 5 in epoch 17, gen_loss = 0.8435943822065989, disc_loss = 0.04123526501158873
Trained batch 6 in epoch 17, gen_loss = 0.827847250870296, disc_loss = 0.04083655135972159
Trained batch 7 in epoch 17, gen_loss = 0.8367475494742393, disc_loss = 0.0374475265853107
Trained batch 8 in epoch 17, gen_loss = 0.8331476913558112, disc_loss = 0.03658967837691307
Trained batch 9 in epoch 17, gen_loss = 0.8276068210601807, disc_loss = 0.034333969186991456
Trained batch 10 in epoch 17, gen_loss = 0.8221339745955034, disc_loss = 0.03655378816818649
Trained batch 11 in epoch 17, gen_loss = 0.8303418705860773, disc_loss = 0.03438754581535856
Trained batch 12 in epoch 17, gen_loss = 0.8215936284798843, disc_loss = 0.03759535989509179
Trained batch 13 in epoch 17, gen_loss = 0.812330573797226, disc_loss = 0.03835565423859017
Trained batch 14 in epoch 17, gen_loss = 0.8183648705482482, disc_loss = 0.038458801930149396
Trained batch 15 in epoch 17, gen_loss = 0.8220826387405396, disc_loss = 0.03797340008895844
Trained batch 16 in epoch 17, gen_loss = 0.8325423808658824, disc_loss = 0.036524308352347684
Trained batch 17 in epoch 17, gen_loss = 0.8343955311510298, disc_loss = 0.03499521009830965
Trained batch 18 in epoch 17, gen_loss = 0.8537523338669225, disc_loss = 0.035778875266642945
Trained batch 19 in epoch 17, gen_loss = 0.8521306484937667, disc_loss = 0.03500905805267394
Trained batch 20 in epoch 17, gen_loss = 0.852631770429157, disc_loss = 0.03423172568104097
Trained batch 21 in epoch 17, gen_loss = 0.8522644909945402, disc_loss = 0.03352298718792471
Trained batch 22 in epoch 17, gen_loss = 0.8558422741682633, disc_loss = 0.032849971326472965
Trained batch 23 in epoch 17, gen_loss = 0.863082672158877, disc_loss = 0.03191531352543583
Trained batch 24 in epoch 17, gen_loss = 0.8625678563117981, disc_loss = 0.030997744090855123
Trained batch 25 in epoch 17, gen_loss = 0.8719568825685061, disc_loss = 0.03015608064687023
Trained batch 26 in epoch 17, gen_loss = 0.8673609583466141, disc_loss = 0.03136714365057371
Trained batch 27 in epoch 17, gen_loss = 0.8650717032807214, disc_loss = 0.030753853897164975
Trained batch 28 in epoch 17, gen_loss = 0.8736558844303263, disc_loss = 0.03174445357430598
Trained batch 29 in epoch 17, gen_loss = 0.8747035721937816, disc_loss = 0.03226723996922374
Trained batch 30 in epoch 17, gen_loss = 0.8768058188499943, disc_loss = 0.03164331750163148
Trained batch 31 in epoch 17, gen_loss = 0.867016701027751, disc_loss = 0.03700127443880774
Trained batch 32 in epoch 17, gen_loss = 0.8682729330929843, disc_loss = 0.03738882135825627
Trained batch 33 in epoch 17, gen_loss = 0.8774829121196971, disc_loss = 0.03922489540213171
Trained batch 34 in epoch 17, gen_loss = 0.8867711612156459, disc_loss = 0.03982234163475888
Trained batch 35 in epoch 17, gen_loss = 0.8893216815259721, disc_loss = 0.03967285262317293
Trained batch 36 in epoch 17, gen_loss = 0.8859112810444187, disc_loss = 0.04003802206165887
Trained batch 37 in epoch 17, gen_loss = 0.8852901364627638, disc_loss = 0.03976687634559838
Trained batch 38 in epoch 17, gen_loss = 0.8861593619371072, disc_loss = 0.03946161019400908
Trained batch 39 in epoch 17, gen_loss = 0.8805628925561905, disc_loss = 0.03984995137434453
Trained batch 40 in epoch 17, gen_loss = 0.8811980907509966, disc_loss = 0.04009873862946179
Trained batch 41 in epoch 17, gen_loss = 0.8811442979744503, disc_loss = 0.03951589565812832
Trained batch 42 in epoch 17, gen_loss = 0.8883093138073765, disc_loss = 0.041297206156995406
Trained batch 43 in epoch 17, gen_loss = 0.8836208852854642, disc_loss = 0.04292873037047684
Trained batch 44 in epoch 17, gen_loss = 0.8787369741333856, disc_loss = 0.04389121480700042
Trained batch 45 in epoch 17, gen_loss = 0.8804349432820859, disc_loss = 0.04417515422581979
Trained batch 46 in epoch 17, gen_loss = 0.882996769661599, disc_loss = 0.0435988026215358
Trained batch 47 in epoch 17, gen_loss = 0.8878753135601679, disc_loss = 0.04303562646964565
Trained batch 48 in epoch 17, gen_loss = 0.8847057430111632, disc_loss = 0.04297358137840519
Trained batch 49 in epoch 17, gen_loss = 0.8873804903030396, disc_loss = 0.04246958402916789
Trained batch 50 in epoch 17, gen_loss = 0.8792637925522, disc_loss = 0.04482712492565898
Trained batch 51 in epoch 17, gen_loss = 0.88485565666969, disc_loss = 0.04531600310180623
Trained batch 52 in epoch 17, gen_loss = 0.8860872567824598, disc_loss = 0.04538186173886061
Trained batch 53 in epoch 17, gen_loss = 0.8853359630814305, disc_loss = 0.04480048267308761
Trained batch 54 in epoch 17, gen_loss = 0.8856281833215194, disc_loss = 0.04420017269863324
Trained batch 55 in epoch 17, gen_loss = 0.8824022220713752, disc_loss = 0.04418468417134136
Trained batch 56 in epoch 17, gen_loss = 0.8802817620729145, disc_loss = 0.04409103587335139
Trained batch 57 in epoch 17, gen_loss = 0.8826610117123045, disc_loss = 0.04532350402261163
Trained batch 58 in epoch 17, gen_loss = 0.8810201459011789, disc_loss = 0.04511730671244658
Trained batch 59 in epoch 17, gen_loss = 0.881702008843422, disc_loss = 0.0446393010361741
Trained batch 60 in epoch 17, gen_loss = 0.8775146359302959, disc_loss = 0.0451312124820762
Trained batch 61 in epoch 17, gen_loss = 0.878355824178265, disc_loss = 0.04462006922450758
Trained batch 62 in epoch 17, gen_loss = 0.8801499169970316, disc_loss = 0.044592683100038104
Trained batch 63 in epoch 17, gen_loss = 0.8793412763625383, disc_loss = 0.04411852826888207
Trained batch 64 in epoch 17, gen_loss = 0.8798349949029776, disc_loss = 0.043579589704481454
Trained batch 65 in epoch 17, gen_loss = 0.8812487269892837, disc_loss = 0.043050131972201845
Trained batch 66 in epoch 17, gen_loss = 0.8778614962278907, disc_loss = 0.042862480325596544
Trained batch 67 in epoch 17, gen_loss = 0.8776014701408499, disc_loss = 0.04236992378719151
Trained batch 68 in epoch 17, gen_loss = 0.8810217302778492, disc_loss = 0.042276345692790936
Trained batch 69 in epoch 17, gen_loss = 0.8773180450711932, disc_loss = 0.04320255950359361
Trained batch 70 in epoch 17, gen_loss = 0.8807512404213489, disc_loss = 0.043689536757137576
Trained batch 71 in epoch 17, gen_loss = 0.8802214372489188, disc_loss = 0.043217365151374705
Trained batch 72 in epoch 17, gen_loss = 0.8810440685651074, disc_loss = 0.04275333732111405
Trained batch 73 in epoch 17, gen_loss = 0.8808017365030341, disc_loss = 0.0423449553498948
Trained batch 74 in epoch 17, gen_loss = 0.8795584066708882, disc_loss = 0.04228807566066583
Trained batch 75 in epoch 17, gen_loss = 0.8788146133485594, disc_loss = 0.0420202974377102
Trained batch 76 in epoch 17, gen_loss = 0.8779309693869058, disc_loss = 0.041724063964052635
Trained batch 77 in epoch 17, gen_loss = 0.8806376839295412, disc_loss = 0.04252976811944674
Trained batch 78 in epoch 17, gen_loss = 0.881573039519636, disc_loss = 0.04211952898038339
Trained batch 79 in epoch 17, gen_loss = 0.8829059451818466, disc_loss = 0.04174448567209765
Trained batch 80 in epoch 17, gen_loss = 0.8838258621133404, disc_loss = 0.04135641026782033
Trained batch 81 in epoch 17, gen_loss = 0.8830509411125649, disc_loss = 0.04139688328226528
Trained batch 82 in epoch 17, gen_loss = 0.8819711933653038, disc_loss = 0.0413192861029003
Trained batch 83 in epoch 17, gen_loss = 0.8803436834187734, disc_loss = 0.0412531462165394
Trained batch 84 in epoch 17, gen_loss = 0.8833640975110671, disc_loss = 0.041418158865588556
Trained batch 85 in epoch 17, gen_loss = 0.8823869526386261, disc_loss = 0.04144958687166488
Trained batch 86 in epoch 17, gen_loss = 0.8835232155076389, disc_loss = 0.04114636124764708
Trained batch 87 in epoch 17, gen_loss = 0.8845827057957649, disc_loss = 0.04077390817375007
Trained batch 88 in epoch 17, gen_loss = 0.8856052367874746, disc_loss = 0.04041178330904647
Trained batch 89 in epoch 17, gen_loss = 0.8849846363067627, disc_loss = 0.04012343955950604
Trained batch 90 in epoch 17, gen_loss = 0.8864062592223451, disc_loss = 0.03983917853866632
Trained batch 91 in epoch 17, gen_loss = 0.8885204532872075, disc_loss = 0.039612121120824115
Trained batch 92 in epoch 17, gen_loss = 0.8867313451664423, disc_loss = 0.03957136316845814
Trained batch 93 in epoch 17, gen_loss = 0.884913942281236, disc_loss = 0.0393970808351135
Trained batch 94 in epoch 17, gen_loss = 0.8846330121943825, disc_loss = 0.03905087942747693
Trained batch 95 in epoch 17, gen_loss = 0.8879524463166794, disc_loss = 0.038904556597117335
Trained batch 96 in epoch 17, gen_loss = 0.8886801127305964, disc_loss = 0.038638124972121005
Trained batch 97 in epoch 17, gen_loss = 0.8902457502423501, disc_loss = 0.03847248185121892
Trained batch 98 in epoch 17, gen_loss = 0.8885106197511307, disc_loss = 0.03863068453666538
Trained batch 99 in epoch 17, gen_loss = 0.8897627437114716, disc_loss = 0.03892903821542859
Trained batch 100 in epoch 17, gen_loss = 0.8885142018299291, disc_loss = 0.038904083597630555
Trained batch 101 in epoch 17, gen_loss = 0.8911868655214122, disc_loss = 0.03880238752154743
Trained batch 102 in epoch 17, gen_loss = 0.8916577465325883, disc_loss = 0.038543177931343466
Trained batch 103 in epoch 17, gen_loss = 0.8918212990348156, disc_loss = 0.03834597015968309
Trained batch 104 in epoch 17, gen_loss = 0.8908449786049979, disc_loss = 0.03822208307683468
Trained batch 105 in epoch 17, gen_loss = 0.8924960325349052, disc_loss = 0.03826168089894191
Trained batch 106 in epoch 17, gen_loss = 0.8944217757643941, disc_loss = 0.03805105499575071
Trained batch 107 in epoch 17, gen_loss = 0.8943167566149323, disc_loss = 0.038045629755490355
Trained batch 108 in epoch 17, gen_loss = 0.8954318439194916, disc_loss = 0.03793108776006677
Trained batch 109 in epoch 17, gen_loss = 0.8947386454452168, disc_loss = 0.037848219140009444
Trained batch 110 in epoch 17, gen_loss = 0.8955029200863194, disc_loss = 0.03762945643550641
Trained batch 111 in epoch 17, gen_loss = 0.8979976203824792, disc_loss = 0.03750023036263883
Trained batch 112 in epoch 17, gen_loss = 0.898836577360609, disc_loss = 0.03723115401869986
Trained batch 113 in epoch 17, gen_loss = 0.8988647142000366, disc_loss = 0.03707691584713757
Trained batch 114 in epoch 17, gen_loss = 0.897685996864153, disc_loss = 0.03726128076162675
Trained batch 115 in epoch 17, gen_loss = 0.8990769309216532, disc_loss = 0.03702673585362861
Trained batch 116 in epoch 17, gen_loss = 0.8981009675906255, disc_loss = 0.03714157366711232
Trained batch 117 in epoch 17, gen_loss = 0.8984864480414633, disc_loss = 0.0369312454259686
Trained batch 118 in epoch 17, gen_loss = 0.8976596027863126, disc_loss = 0.036864373124666325
Trained batch 119 in epoch 17, gen_loss = 0.897346667945385, disc_loss = 0.036770837610432254
Trained batch 120 in epoch 17, gen_loss = 0.9015810750732737, disc_loss = 0.03715823711981335
Trained batch 121 in epoch 17, gen_loss = 0.9024751992499243, disc_loss = 0.036950478631789324
Trained batch 122 in epoch 17, gen_loss = 0.9006984694217278, disc_loss = 0.03692242999492985
Trained batch 123 in epoch 17, gen_loss = 0.9018752531659219, disc_loss = 0.036703571358004644
Trained batch 124 in epoch 17, gen_loss = 0.9007436270713807, disc_loss = 0.03654095109924674
Trained batch 125 in epoch 17, gen_loss = 0.9017588349561843, disc_loss = 0.036504076819659934
Trained batch 126 in epoch 17, gen_loss = 0.9008838252758417, disc_loss = 0.03647656465594576
Trained batch 127 in epoch 17, gen_loss = 0.9013925576582551, disc_loss = 0.03632845016181818
Trained batch 128 in epoch 17, gen_loss = 0.9012191193972448, disc_loss = 0.036268439761168045
Trained batch 129 in epoch 17, gen_loss = 0.9035274753203759, disc_loss = 0.036120433141835606
Trained batch 130 in epoch 17, gen_loss = 0.9034296387934503, disc_loss = 0.03595976956288209
Trained batch 131 in epoch 17, gen_loss = 0.9027865425203786, disc_loss = 0.036010344862006605
Trained batch 132 in epoch 17, gen_loss = 0.9018166123476243, disc_loss = 0.036037937573444354
Trained batch 133 in epoch 17, gen_loss = 0.9042247458180385, disc_loss = 0.03608830671743559
Trained batch 134 in epoch 17, gen_loss = 0.9046771274672614, disc_loss = 0.035901832397751236
Trained batch 135 in epoch 17, gen_loss = 0.9026701494174845, disc_loss = 0.036512813842444515
Trained batch 136 in epoch 17, gen_loss = 0.9044560315835215, disc_loss = 0.03689252980474899
Trained batch 137 in epoch 17, gen_loss = 0.9021975121636322, disc_loss = 0.03699326343442975
Trained batch 138 in epoch 17, gen_loss = 0.9030292908922374, disc_loss = 0.03681600305231677
Trained batch 139 in epoch 17, gen_loss = 0.904676525933402, disc_loss = 0.036770110800197084
Trained batch 140 in epoch 17, gen_loss = 0.9041335012050385, disc_loss = 0.03677761804061473
Trained batch 141 in epoch 17, gen_loss = 0.9046818634993593, disc_loss = 0.036589854872378876
Trained batch 142 in epoch 17, gen_loss = 0.9026227743475588, disc_loss = 0.03700878438898004
Trained batch 143 in epoch 17, gen_loss = 0.9025804868174924, disc_loss = 0.03707361447999978
Trained batch 144 in epoch 17, gen_loss = 0.9031529570447987, disc_loss = 0.03706115804419949
Trained batch 145 in epoch 17, gen_loss = 0.9027111028155236, disc_loss = 0.037056758199269846
Trained batch 146 in epoch 17, gen_loss = 0.9003455294232791, disc_loss = 0.037264091339671894
Trained batch 147 in epoch 17, gen_loss = 0.9018165432923549, disc_loss = 0.037200784187990464
Trained batch 148 in epoch 17, gen_loss = 0.9036275744438171, disc_loss = 0.03712708187045767
Trained batch 149 in epoch 17, gen_loss = 0.9041723088423411, disc_loss = 0.036932620191946625
Trained batch 150 in epoch 17, gen_loss = 0.9042007169186674, disc_loss = 0.03679698020750225
Trained batch 151 in epoch 17, gen_loss = 0.9054025650808686, disc_loss = 0.037427884241639585
Trained batch 152 in epoch 17, gen_loss = 0.9035403085689918, disc_loss = 0.038115128543033124
Trained batch 153 in epoch 17, gen_loss = 0.905394968661395, disc_loss = 0.03930786751246975
Trained batch 154 in epoch 17, gen_loss = 0.9036207206787602, disc_loss = 0.04017214290497284
Trained batch 155 in epoch 17, gen_loss = 0.9027611605632, disc_loss = 0.04040916546737441
Trained batch 156 in epoch 17, gen_loss = 0.9035796990060503, disc_loss = 0.04040332962788499
Trained batch 157 in epoch 17, gen_loss = 0.9038311522218245, disc_loss = 0.04066381276632317
Trained batch 158 in epoch 17, gen_loss = 0.9033454859031821, disc_loss = 0.04050693364298475
Trained batch 159 in epoch 17, gen_loss = 0.9015426225960255, disc_loss = 0.04078721784462687
Trained batch 160 in epoch 17, gen_loss = 0.9016574132516517, disc_loss = 0.040787396949617576
Trained batch 161 in epoch 17, gen_loss = 0.9000545228704994, disc_loss = 0.04152393376420217
Trained batch 162 in epoch 17, gen_loss = 0.8983494551635227, disc_loss = 0.04191749459246825
Trained batch 163 in epoch 17, gen_loss = 0.8971424993218445, disc_loss = 0.0418161517094321
Trained batch 164 in epoch 17, gen_loss = 0.8986752773776199, disc_loss = 0.04218280828755462
Trained batch 165 in epoch 17, gen_loss = 0.8978482366326344, disc_loss = 0.04225556218873216
Trained batch 166 in epoch 17, gen_loss = 0.8970474429473192, disc_loss = 0.042501799168321724
Trained batch 167 in epoch 17, gen_loss = 0.8948757318513734, disc_loss = 0.043054054699106406
Trained batch 168 in epoch 17, gen_loss = 0.8937623151660671, disc_loss = 0.04314397095520733
Trained batch 169 in epoch 17, gen_loss = 0.8958826194791233, disc_loss = 0.044400159803712196
Trained batch 170 in epoch 17, gen_loss = 0.8953762716717191, disc_loss = 0.04430083761383828
Trained batch 171 in epoch 17, gen_loss = 0.8943864526443703, disc_loss = 0.04420158486585891
Trained batch 172 in epoch 17, gen_loss = 0.894278002267628, disc_loss = 0.044263185736739395
Trained batch 173 in epoch 17, gen_loss = 0.8935228418344738, disc_loss = 0.044379333513200114
Trained batch 174 in epoch 17, gen_loss = 0.8929166279520308, disc_loss = 0.04443887862509915
Trained batch 175 in epoch 17, gen_loss = 0.8927307897670702, disc_loss = 0.04442659300614402
Trained batch 176 in epoch 17, gen_loss = 0.8929416911076691, disc_loss = 0.04428201382137877
Trained batch 177 in epoch 17, gen_loss = 0.8935744949940885, disc_loss = 0.04411743717069288
Trained batch 178 in epoch 17, gen_loss = 0.8922987177385299, disc_loss = 0.044083602286812816
Trained batch 179 in epoch 17, gen_loss = 0.8942584806018405, disc_loss = 0.04400981387071726
Trained batch 180 in epoch 17, gen_loss = 0.8942057384970439, disc_loss = 0.04484277506466976
Trained batch 181 in epoch 17, gen_loss = 0.8937292475621779, disc_loss = 0.044870164508900634
Trained batch 182 in epoch 17, gen_loss = 0.89299050673761, disc_loss = 0.04485611572525785
Trained batch 183 in epoch 17, gen_loss = 0.892977360797965, disc_loss = 0.04469502368263657
Trained batch 184 in epoch 17, gen_loss = 0.8916927144334122, disc_loss = 0.04468261187996816
Trained batch 185 in epoch 17, gen_loss = 0.8921623079366582, disc_loss = 0.04450227047557071
Trained batch 186 in epoch 17, gen_loss = 0.8923582941453088, disc_loss = 0.044621921874044894
Trained batch 187 in epoch 17, gen_loss = 0.890920580701625, disc_loss = 0.04465118872665582
Trained batch 188 in epoch 17, gen_loss = 0.8922767702233855, disc_loss = 0.04450867776192291
Trained batch 189 in epoch 17, gen_loss = 0.8908030158595035, disc_loss = 0.045033662548092636
Trained batch 190 in epoch 17, gen_loss = 0.8915683811247661, disc_loss = 0.04524478341418645
Trained batch 191 in epoch 17, gen_loss = 0.8915520751227936, disc_loss = 0.04539747541760638
Trained batch 192 in epoch 17, gen_loss = 0.8911353442335376, disc_loss = 0.04525770281484939
Trained batch 193 in epoch 17, gen_loss = 0.8905755035656014, disc_loss = 0.04524144215134846
Trained batch 194 in epoch 17, gen_loss = 0.8889276156058679, disc_loss = 0.0454181847640146
Trained batch 195 in epoch 17, gen_loss = 0.889130252356432, disc_loss = 0.04534972692621225
Trained batch 196 in epoch 17, gen_loss = 0.8895535220954623, disc_loss = 0.045542570367587853
Trained batch 197 in epoch 17, gen_loss = 0.8880762566219677, disc_loss = 0.04571174395345904
Trained batch 198 in epoch 17, gen_loss = 0.8883167553187614, disc_loss = 0.045951558246590835
Trained batch 199 in epoch 17, gen_loss = 0.8889437502622605, disc_loss = 0.04578502107644453
Trained batch 200 in epoch 17, gen_loss = 0.8867996790219302, disc_loss = 0.04653590980833813
Trained batch 201 in epoch 17, gen_loss = 0.8866663662218811, disc_loss = 0.04675854916112627
Trained batch 202 in epoch 17, gen_loss = 0.8877886303246315, disc_loss = 0.0466385039482541
Trained batch 203 in epoch 17, gen_loss = 0.8875565474816397, disc_loss = 0.046471292127891646
Trained batch 204 in epoch 17, gen_loss = 0.8879671982148799, disc_loss = 0.04634068177831246
Trained batch 205 in epoch 17, gen_loss = 0.886390635255471, disc_loss = 0.04642234469800102
Trained batch 206 in epoch 17, gen_loss = 0.8871240381169434, disc_loss = 0.04626610813266485
Trained batch 207 in epoch 17, gen_loss = 0.8863202346345553, disc_loss = 0.04643639545359362
Trained batch 208 in epoch 17, gen_loss = 0.8850055672050092, disc_loss = 0.0467264496756976
Trained batch 209 in epoch 17, gen_loss = 0.8840688167583375, disc_loss = 0.04681668635679498
Trained batch 210 in epoch 17, gen_loss = 0.8851341761966453, disc_loss = 0.047300478569298136
Trained batch 211 in epoch 17, gen_loss = 0.8840491005553389, disc_loss = 0.04722041625503169
Trained batch 212 in epoch 17, gen_loss = 0.8843457991248566, disc_loss = 0.047068482678068777
Trained batch 213 in epoch 17, gen_loss = 0.8836251813396115, disc_loss = 0.04722394653439313
Trained batch 214 in epoch 17, gen_loss = 0.8839570493199105, disc_loss = 0.04714571627636635
Trained batch 215 in epoch 17, gen_loss = 0.8852496305825533, disc_loss = 0.04725945746327785
Trained batch 216 in epoch 17, gen_loss = 0.8840954055159872, disc_loss = 0.04735944775675642
Trained batch 217 in epoch 17, gen_loss = 0.8834011290871769, disc_loss = 0.04734401367476569
Trained batch 218 in epoch 17, gen_loss = 0.8837080003191892, disc_loss = 0.04777793896057086
Trained batch 219 in epoch 17, gen_loss = 0.883163636516441, disc_loss = 0.04770353727931665
Trained batch 220 in epoch 17, gen_loss = 0.8838777953413277, disc_loss = 0.0476052545841227
Trained batch 221 in epoch 17, gen_loss = 0.8831902491348284, disc_loss = 0.04754931880958244
Trained batch 222 in epoch 17, gen_loss = 0.8842421033724541, disc_loss = 0.04738823023954648
Trained batch 223 in epoch 17, gen_loss = 0.8836698687768408, disc_loss = 0.047371310150733086
Trained batch 224 in epoch 17, gen_loss = 0.8844619275463952, disc_loss = 0.048131521776732474
Trained batch 225 in epoch 17, gen_loss = 0.8829637735554602, disc_loss = 0.04852578522167704
Trained batch 226 in epoch 17, gen_loss = 0.883083565513468, disc_loss = 0.04837485277483707
Trained batch 227 in epoch 17, gen_loss = 0.884326821225777, disc_loss = 0.048374211965047084
Trained batch 228 in epoch 17, gen_loss = 0.8830608830962119, disc_loss = 0.04832865412684572
Trained batch 229 in epoch 17, gen_loss = 0.8829216256089832, disc_loss = 0.04820724921098546
Trained batch 230 in epoch 17, gen_loss = 0.8821191892221376, disc_loss = 0.04814019926029431
Trained batch 231 in epoch 17, gen_loss = 0.8831455112788184, disc_loss = 0.04816206773654718
Trained batch 232 in epoch 17, gen_loss = 0.8828792639812175, disc_loss = 0.04804757088942397
Trained batch 233 in epoch 17, gen_loss = 0.8819358355214453, disc_loss = 0.04812505117092186
Trained batch 234 in epoch 17, gen_loss = 0.8819774537644488, disc_loss = 0.048088133543174955
Trained batch 235 in epoch 17, gen_loss = 0.8831380879727461, disc_loss = 0.04806589655838591
Trained batch 236 in epoch 17, gen_loss = 0.8846058766298657, disc_loss = 0.04799499100404261
Trained batch 237 in epoch 17, gen_loss = 0.8841766666214005, disc_loss = 0.048010863866578754
Trained batch 238 in epoch 17, gen_loss = 0.8826357371886904, disc_loss = 0.04837274133855142
Trained batch 239 in epoch 17, gen_loss = 0.8826535370200872, disc_loss = 0.04823112716937127
Trained batch 240 in epoch 17, gen_loss = 0.882776730659097, disc_loss = 0.04818400004260335
Trained batch 241 in epoch 17, gen_loss = 0.8832154363886384, disc_loss = 0.04803145070529489
Trained batch 242 in epoch 17, gen_loss = 0.882758709996816, disc_loss = 0.04792090462628031
Trained batch 243 in epoch 17, gen_loss = 0.8830532950700306, disc_loss = 0.04781440703663975
Trained batch 244 in epoch 17, gen_loss = 0.8828255192357667, disc_loss = 0.04770084870599058
Trained batch 245 in epoch 17, gen_loss = 0.8825082092023477, disc_loss = 0.04760005557720315
Trained batch 246 in epoch 17, gen_loss = 0.8843174773430534, disc_loss = 0.04780511186469482
Trained batch 247 in epoch 17, gen_loss = 0.8845667453302491, disc_loss = 0.047664344034743525
Trained batch 248 in epoch 17, gen_loss = 0.884745866299633, disc_loss = 0.04750216215377651
Trained batch 249 in epoch 17, gen_loss = 0.8847654663324356, disc_loss = 0.04742109178192914
Trained batch 250 in epoch 17, gen_loss = 0.8838141098677874, disc_loss = 0.04743793157237281
Trained batch 251 in epoch 17, gen_loss = 0.885053525013583, disc_loss = 0.047642005091932206
Trained batch 252 in epoch 17, gen_loss = 0.8851728930539293, disc_loss = 0.0485327496936935
Trained batch 253 in epoch 17, gen_loss = 0.8839028042367124, disc_loss = 0.04886288634560063
Trained batch 254 in epoch 17, gen_loss = 0.882945011994418, disc_loss = 0.04915377440880619
Trained batch 255 in epoch 17, gen_loss = 0.8827578936470672, disc_loss = 0.04910910742364649
Trained batch 256 in epoch 17, gen_loss = 0.8831279919073276, disc_loss = 0.04925298460501931
Trained batch 257 in epoch 17, gen_loss = 0.8830899754466937, disc_loss = 0.04967960809328586
Trained batch 258 in epoch 17, gen_loss = 0.8830555986943852, disc_loss = 0.049745186258999194
Trained batch 259 in epoch 17, gen_loss = 0.8825666103225488, disc_loss = 0.04966564597024654
Trained batch 260 in epoch 17, gen_loss = 0.8823473249130322, disc_loss = 0.04955558660279574
Trained batch 261 in epoch 17, gen_loss = 0.8824908816404925, disc_loss = 0.049439709791771445
Trained batch 262 in epoch 17, gen_loss = 0.8829875147614642, disc_loss = 0.04928011564226262
Trained batch 263 in epoch 17, gen_loss = 0.8829687022124276, disc_loss = 0.04925491441584503
Trained batch 264 in epoch 17, gen_loss = 0.8830547920937808, disc_loss = 0.04910797766884262
Trained batch 265 in epoch 17, gen_loss = 0.883111503675468, disc_loss = 0.04900243558178663
Trained batch 266 in epoch 17, gen_loss = 0.8833239769444483, disc_loss = 0.04889021976938129
Trained batch 267 in epoch 17, gen_loss = 0.8831094164234489, disc_loss = 0.04879715781373931
Trained batch 268 in epoch 17, gen_loss = 0.8836256366458524, disc_loss = 0.048645971386198326
Trained batch 269 in epoch 17, gen_loss = 0.883193040004483, disc_loss = 0.04856689978149478
Trained batch 270 in epoch 17, gen_loss = 0.882882781244292, disc_loss = 0.04848381282582989
Trained batch 271 in epoch 17, gen_loss = 0.8827468793400947, disc_loss = 0.04833164099460084
Trained batch 272 in epoch 17, gen_loss = 0.8821618269869697, disc_loss = 0.048239780451774926
Trained batch 273 in epoch 17, gen_loss = 0.8813536664212707, disc_loss = 0.048260436350833213
Trained batch 274 in epoch 17, gen_loss = 0.8819200391119176, disc_loss = 0.048121718508614734
Trained batch 275 in epoch 17, gen_loss = 0.8824126812210982, disc_loss = 0.047974959569240826
Trained batch 276 in epoch 17, gen_loss = 0.882698279317966, disc_loss = 0.04783373715403063
Trained batch 277 in epoch 17, gen_loss = 0.882752049633925, disc_loss = 0.04768960584598265
Trained batch 278 in epoch 17, gen_loss = 0.8818545334014414, disc_loss = 0.04764653399827019
Trained batch 279 in epoch 17, gen_loss = 0.8816675363906792, disc_loss = 0.04758726651115077
Trained batch 280 in epoch 17, gen_loss = 0.8823132055722097, disc_loss = 0.04745594767382985
Trained batch 281 in epoch 17, gen_loss = 0.8823133042306764, disc_loss = 0.04738414982426251
Trained batch 282 in epoch 17, gen_loss = 0.8821294251895203, disc_loss = 0.04727721933683532
Trained batch 283 in epoch 17, gen_loss = 0.8826165576006325, disc_loss = 0.047162743603390914
Trained batch 284 in epoch 17, gen_loss = 0.8829184370082721, disc_loss = 0.04704315973151671
Trained batch 285 in epoch 17, gen_loss = 0.8822806357712178, disc_loss = 0.047146116933700716
Trained batch 286 in epoch 17, gen_loss = 0.8818377776636064, disc_loss = 0.04728864086305119
Trained batch 287 in epoch 17, gen_loss = 0.8827017004498177, disc_loss = 0.04718608497447955
Trained batch 288 in epoch 17, gen_loss = 0.8822321036901442, disc_loss = 0.04715910498826252
Trained batch 289 in epoch 17, gen_loss = 0.8812110449733406, disc_loss = 0.047541320185851436
Trained batch 290 in epoch 17, gen_loss = 0.8835253102058398, disc_loss = 0.04774971082614562
Trained batch 291 in epoch 17, gen_loss = 0.8837962418998757, disc_loss = 0.04769952471801781
Trained batch 292 in epoch 17, gen_loss = 0.8830565021916867, disc_loss = 0.04787137488113023
Trained batch 293 in epoch 17, gen_loss = 0.8832820792790173, disc_loss = 0.04777705700130386
Trained batch 294 in epoch 17, gen_loss = 0.8833440923084647, disc_loss = 0.0478017558769907
Trained batch 295 in epoch 17, gen_loss = 0.8832670418998679, disc_loss = 0.0477117702421556
Trained batch 296 in epoch 17, gen_loss = 0.8841036065459653, disc_loss = 0.047713124431569366
Trained batch 297 in epoch 17, gen_loss = 0.8841710979706489, disc_loss = 0.04760651070087048
Trained batch 298 in epoch 17, gen_loss = 0.8829519372919331, disc_loss = 0.0479596692751034
Trained batch 299 in epoch 17, gen_loss = 0.8822258376081784, disc_loss = 0.04800229293294251
Trained batch 300 in epoch 17, gen_loss = 0.8814883122214447, disc_loss = 0.0482083602322643
Trained batch 301 in epoch 17, gen_loss = 0.882378508811755, disc_loss = 0.048485088892996506
Trained batch 302 in epoch 17, gen_loss = 0.8819818359987177, disc_loss = 0.04898793727048848
Trained batch 303 in epoch 17, gen_loss = 0.8818273592348161, disc_loss = 0.049162001615561744
Trained batch 304 in epoch 17, gen_loss = 0.8809743718045657, disc_loss = 0.049474002320136205
Trained batch 305 in epoch 17, gen_loss = 0.8822564062924166, disc_loss = 0.04964671101043719
Trained batch 306 in epoch 17, gen_loss = 0.8819467135089228, disc_loss = 0.0496898386415082
Trained batch 307 in epoch 17, gen_loss = 0.8812663095531525, disc_loss = 0.04973654204362689
Trained batch 308 in epoch 17, gen_loss = 0.8810773255562705, disc_loss = 0.049681499392445226
Trained batch 309 in epoch 17, gen_loss = 0.8813399179327872, disc_loss = 0.04990780183805093
Trained batch 310 in epoch 17, gen_loss = 0.8807227991976538, disc_loss = 0.04992553356651612
Trained batch 311 in epoch 17, gen_loss = 0.8812109076250823, disc_loss = 0.04979699897245528
Trained batch 312 in epoch 17, gen_loss = 0.8801229831319266, disc_loss = 0.04996763980878999
Trained batch 313 in epoch 17, gen_loss = 0.8804843857599671, disc_loss = 0.04984792571657213
Trained batch 314 in epoch 17, gen_loss = 0.8808955513295673, disc_loss = 0.049931806260867725
Trained batch 315 in epoch 17, gen_loss = 0.880751514642299, disc_loss = 0.04983495221815155
Trained batch 316 in epoch 17, gen_loss = 0.881371082097574, disc_loss = 0.049740834214521884
Trained batch 317 in epoch 17, gen_loss = 0.8809132987410767, disc_loss = 0.04975070560690742
Trained batch 318 in epoch 17, gen_loss = 0.8801553050365568, disc_loss = 0.04985563064630502
Trained batch 319 in epoch 17, gen_loss = 0.8801725336350501, disc_loss = 0.0497552256740164
Trained batch 320 in epoch 17, gen_loss = 0.8797492372841107, disc_loss = 0.049668283175642244
Trained batch 321 in epoch 17, gen_loss = 0.8805345912342486, disc_loss = 0.04961678672651326
Trained batch 322 in epoch 17, gen_loss = 0.8799452642353696, disc_loss = 0.0495896929004244
Trained batch 323 in epoch 17, gen_loss = 0.879566257842529, disc_loss = 0.04952324820498442
Trained batch 324 in epoch 17, gen_loss = 0.8798311667258922, disc_loss = 0.04939483958511398
Trained batch 325 in epoch 17, gen_loss = 0.8800007237429999, disc_loss = 0.04930397359214357
Trained batch 326 in epoch 17, gen_loss = 0.8804654139079814, disc_loss = 0.049200141923473606
Trained batch 327 in epoch 17, gen_loss = 0.8794753857683845, disc_loss = 0.0494712484878397
Trained batch 328 in epoch 17, gen_loss = 0.8802842033126796, disc_loss = 0.050342071474470354
Trained batch 329 in epoch 17, gen_loss = 0.880589060440208, disc_loss = 0.050217420891435306
Trained batch 330 in epoch 17, gen_loss = 0.8800569512512749, disc_loss = 0.0502026045647115
Trained batch 331 in epoch 17, gen_loss = 0.8799206854169628, disc_loss = 0.05024559666958065
Trained batch 332 in epoch 17, gen_loss = 0.8802993737004541, disc_loss = 0.0502826076451208
Trained batch 333 in epoch 17, gen_loss = 0.8800172804893848, disc_loss = 0.05038376419225005
Trained batch 334 in epoch 17, gen_loss = 0.8795041030022636, disc_loss = 0.05049751068590515
Trained batch 335 in epoch 17, gen_loss = 0.8788362737035468, disc_loss = 0.050648758111665734
Trained batch 336 in epoch 17, gen_loss = 0.8794120068189298, disc_loss = 0.05125836909884029
Trained batch 337 in epoch 17, gen_loss = 0.8790879899404458, disc_loss = 0.051153901084078225
Trained batch 338 in epoch 17, gen_loss = 0.8789715454817522, disc_loss = 0.051040875636162046
Trained batch 339 in epoch 17, gen_loss = 0.8786126577678849, disc_loss = 0.05101405695655986
Trained batch 340 in epoch 17, gen_loss = 0.878118408827488, disc_loss = 0.051012162175138764
Trained batch 341 in epoch 17, gen_loss = 0.877490139582701, disc_loss = 0.05102926637699599
Trained batch 342 in epoch 17, gen_loss = 0.877055111935813, disc_loss = 0.05097299939260408
Trained batch 343 in epoch 17, gen_loss = 0.8778374785080899, disc_loss = 0.0511139434949105
Trained batch 344 in epoch 17, gen_loss = 0.8777280481829159, disc_loss = 0.051026464503366446
Trained batch 345 in epoch 17, gen_loss = 0.8773639845538002, disc_loss = 0.05094195842188433
Trained batch 346 in epoch 17, gen_loss = 0.8767016917381232, disc_loss = 0.05090651770796015
Trained batch 347 in epoch 17, gen_loss = 0.8766111898525007, disc_loss = 0.050827847382899416
Trained batch 348 in epoch 17, gen_loss = 0.8772931572871768, disc_loss = 0.05074560754454793
Trained batch 349 in epoch 17, gen_loss = 0.8771415721518653, disc_loss = 0.0506551443851952
Trained batch 350 in epoch 17, gen_loss = 0.8772181171467501, disc_loss = 0.05053568901653346
Trained batch 351 in epoch 17, gen_loss = 0.8768065977333621, disc_loss = 0.050481506672275085
Trained batch 352 in epoch 17, gen_loss = 0.8768269444153599, disc_loss = 0.05043061372689459
Trained batch 353 in epoch 17, gen_loss = 0.8767659047060767, disc_loss = 0.05035796914760044
Trained batch 354 in epoch 17, gen_loss = 0.876215111789569, disc_loss = 0.05029441645159058
Trained batch 355 in epoch 17, gen_loss = 0.8767460535249013, disc_loss = 0.05020902630888721
Trained batch 356 in epoch 17, gen_loss = 0.8773495086601802, disc_loss = 0.050100316767025144
Trained batch 357 in epoch 17, gen_loss = 0.8776983616238866, disc_loss = 0.05002714242583255
Trained batch 358 in epoch 17, gen_loss = 0.8776891798528124, disc_loss = 0.049954697823094876
Trained batch 359 in epoch 17, gen_loss = 0.877870589411921, disc_loss = 0.04985759131636264
Trained batch 360 in epoch 17, gen_loss = 0.8790638954520555, disc_loss = 0.04986607948565788
Trained batch 361 in epoch 17, gen_loss = 0.8799569935265167, disc_loss = 0.04978914346509917
Trained batch 362 in epoch 17, gen_loss = 0.8800547680414741, disc_loss = 0.04971482372424532
Trained batch 363 in epoch 17, gen_loss = 0.8805818733769458, disc_loss = 0.04961259402257933
Trained batch 364 in epoch 17, gen_loss = 0.8802962596285833, disc_loss = 0.049528422156884654
Trained batch 365 in epoch 17, gen_loss = 0.8805781507589778, disc_loss = 0.04944838368832617
Trained batch 366 in epoch 17, gen_loss = 0.8809379065556487, disc_loss = 0.049342100273777174
Trained batch 367 in epoch 17, gen_loss = 0.8805523662949386, disc_loss = 0.04929378903698702
Trained batch 368 in epoch 17, gen_loss = 0.8807878144549807, disc_loss = 0.04918234231112005
Trained batch 369 in epoch 17, gen_loss = 0.8804008112565891, disc_loss = 0.049142249141240844
Trained batch 370 in epoch 17, gen_loss = 0.8795303709584105, disc_loss = 0.04926286865844118
Trained batch 371 in epoch 17, gen_loss = 0.8792488497271332, disc_loss = 0.04918507810667037
Trained batch 372 in epoch 17, gen_loss = 0.8794122121768726, disc_loss = 0.04907565703615546
Trained batch 373 in epoch 17, gen_loss = 0.8792703064845845, disc_loss = 0.04898856498953453
Trained batch 374 in epoch 17, gen_loss = 0.8796202547550201, disc_loss = 0.049072847032298646
Trained batch 375 in epoch 17, gen_loss = 0.8789028507122334, disc_loss = 0.04910677914542364
Trained batch 376 in epoch 17, gen_loss = 0.878644410352808, disc_loss = 0.049054160100267086
Trained batch 377 in epoch 17, gen_loss = 0.87876616765267, disc_loss = 0.04895720926911703
Trained batch 378 in epoch 17, gen_loss = 0.8781794280521473, disc_loss = 0.048986244046112085
Trained batch 379 in epoch 17, gen_loss = 0.8788273418420239, disc_loss = 0.0489660552396488
Trained batch 380 in epoch 17, gen_loss = 0.8793586995501531, disc_loss = 0.04891251931406968
Trained batch 381 in epoch 17, gen_loss = 0.8784582167863846, disc_loss = 0.04909009802769577
Trained batch 382 in epoch 17, gen_loss = 0.8781076158462554, disc_loss = 0.0490104785765334
Trained batch 383 in epoch 17, gen_loss = 0.8787929508058975, disc_loss = 0.049160805699405806
Trained batch 384 in epoch 17, gen_loss = 0.8783194613921178, disc_loss = 0.04917301907530659
Trained batch 385 in epoch 17, gen_loss = 0.8785038060011642, disc_loss = 0.04906341326760775
Trained batch 386 in epoch 17, gen_loss = 0.8796082735831732, disc_loss = 0.04913859565451125
Trained batch 387 in epoch 17, gen_loss = 0.8786833827796671, disc_loss = 0.04961323683730989
Trained batch 388 in epoch 17, gen_loss = 0.878683857332465, disc_loss = 0.04953202567779121
Trained batch 389 in epoch 17, gen_loss = 0.8785687713286816, disc_loss = 0.049513081622381626
Trained batch 390 in epoch 17, gen_loss = 0.8791339267092897, disc_loss = 0.04949807270746821
Trained batch 391 in epoch 17, gen_loss = 0.8787285798818482, disc_loss = 0.04958486783066384
Trained batch 392 in epoch 17, gen_loss = 0.8786862412936814, disc_loss = 0.04949224238703383
Trained batch 393 in epoch 17, gen_loss = 0.8789879551847574, disc_loss = 0.049387843597462865
Trained batch 394 in epoch 17, gen_loss = 0.8786713466614108, disc_loss = 0.04941841995673655
Trained batch 395 in epoch 17, gen_loss = 0.8789229494604197, disc_loss = 0.04935335776547553
Trained batch 396 in epoch 17, gen_loss = 0.8789148127251969, disc_loss = 0.049313754935324264
Trained batch 397 in epoch 17, gen_loss = 0.8783887989407209, disc_loss = 0.04938758110707092
Trained batch 398 in epoch 17, gen_loss = 0.8787146041118411, disc_loss = 0.04938986091139285
Trained batch 399 in epoch 17, gen_loss = 0.8789123769849538, disc_loss = 0.04928679394884966
Trained batch 400 in epoch 17, gen_loss = 0.8794716476948184, disc_loss = 0.04921924069574907
Trained batch 401 in epoch 17, gen_loss = 0.8790798592775022, disc_loss = 0.04916259206585882
Trained batch 402 in epoch 17, gen_loss = 0.8790281537005091, disc_loss = 0.04910057505232192
Trained batch 403 in epoch 17, gen_loss = 0.8789769550508791, disc_loss = 0.049024131567457156
Trained batch 404 in epoch 17, gen_loss = 0.8790323423014746, disc_loss = 0.049007593641448535
Trained batch 405 in epoch 17, gen_loss = 0.8787500365761113, disc_loss = 0.04899126743975788
Trained batch 406 in epoch 17, gen_loss = 0.8789791549013639, disc_loss = 0.04894392665004225
Trained batch 407 in epoch 17, gen_loss = 0.8783913354809377, disc_loss = 0.04895400720096065
Trained batch 408 in epoch 17, gen_loss = 0.878569072426677, disc_loss = 0.04887423818603085
Trained batch 409 in epoch 17, gen_loss = 0.8792585363475288, disc_loss = 0.04897445032668368
Trained batch 410 in epoch 17, gen_loss = 0.879263589489489, disc_loss = 0.048907389192458996
Trained batch 411 in epoch 17, gen_loss = 0.8793114130792109, disc_loss = 0.04881544172587506
Trained batch 412 in epoch 17, gen_loss = 0.8794747023114858, disc_loss = 0.04871676958190868
Trained batch 413 in epoch 17, gen_loss = 0.879415380709989, disc_loss = 0.04866632852806813
Trained batch 414 in epoch 17, gen_loss = 0.879396455761898, disc_loss = 0.048619865409536174
Trained batch 415 in epoch 17, gen_loss = 0.8799516322950904, disc_loss = 0.04854168170557106
Trained batch 416 in epoch 17, gen_loss = 0.8803857572787671, disc_loss = 0.04849121406812855
Trained batch 417 in epoch 17, gen_loss = 0.8805602129424017, disc_loss = 0.0484094241016843
Trained batch 418 in epoch 17, gen_loss = 0.8814025194804253, disc_loss = 0.04834590692557661
Trained batch 419 in epoch 17, gen_loss = 0.8819040890960467, disc_loss = 0.04829783445734176
Trained batch 420 in epoch 17, gen_loss = 0.881269201459341, disc_loss = 0.04834125310319726
Trained batch 421 in epoch 17, gen_loss = 0.8816827156391189, disc_loss = 0.048362101652213677
Trained batch 422 in epoch 17, gen_loss = 0.8816545239999785, disc_loss = 0.04830545399131046
Trained batch 423 in epoch 17, gen_loss = 0.8816828563949972, disc_loss = 0.04821979684452087
Trained batch 424 in epoch 17, gen_loss = 0.8819821163486032, disc_loss = 0.04815046327407746
Trained batch 425 in epoch 17, gen_loss = 0.8821255838227384, disc_loss = 0.04806207448676963
Trained batch 426 in epoch 17, gen_loss = 0.8820722332743348, disc_loss = 0.048014166984113864
Trained batch 427 in epoch 17, gen_loss = 0.8824041035270023, disc_loss = 0.0479173827535586
Trained batch 428 in epoch 17, gen_loss = 0.8829154963398869, disc_loss = 0.047908087846082754
Trained batch 429 in epoch 17, gen_loss = 0.8826690262833307, disc_loss = 0.04787687834807087
Trained batch 430 in epoch 17, gen_loss = 0.882654609024663, disc_loss = 0.04778015024834712
Trained batch 431 in epoch 17, gen_loss = 0.8828745199436391, disc_loss = 0.04769341234242785
Trained batch 432 in epoch 17, gen_loss = 0.882656331907519, disc_loss = 0.04764997163856312
Trained batch 433 in epoch 17, gen_loss = 0.8829448131784317, disc_loss = 0.047661392950594496
Trained batch 434 in epoch 17, gen_loss = 0.8829749584883109, disc_loss = 0.04764032609353977
Trained batch 435 in epoch 17, gen_loss = 0.8827762976288795, disc_loss = 0.04761726013277957
Trained batch 436 in epoch 17, gen_loss = 0.8826431177164379, disc_loss = 0.047556405397903526
Trained batch 437 in epoch 17, gen_loss = 0.8827090845124362, disc_loss = 0.04749141399297846
Trained batch 438 in epoch 17, gen_loss = 0.8829424706434063, disc_loss = 0.047412313999298426
Trained batch 439 in epoch 17, gen_loss = 0.8828806451098485, disc_loss = 0.047316639035389844
Trained batch 440 in epoch 17, gen_loss = 0.883531825815469, disc_loss = 0.047249276498269266
Trained batch 441 in epoch 17, gen_loss = 0.8827927908881218, disc_loss = 0.04735903121105382
Trained batch 442 in epoch 17, gen_loss = 0.8833533345845698, disc_loss = 0.04727967512219909
Trained batch 443 in epoch 17, gen_loss = 0.8838760756828763, disc_loss = 0.04722373663166723
Trained batch 444 in epoch 17, gen_loss = 0.8834440257442131, disc_loss = 0.04717557761253099
Trained batch 445 in epoch 17, gen_loss = 0.8841418043246718, disc_loss = 0.04709966508608996
Trained batch 446 in epoch 17, gen_loss = 0.8839296408547651, disc_loss = 0.04709546985854739
Trained batch 447 in epoch 17, gen_loss = 0.8844741680659354, disc_loss = 0.04704851565994821
Trained batch 448 in epoch 17, gen_loss = 0.8842747209465053, disc_loss = 0.046971472526769795
Trained batch 449 in epoch 17, gen_loss = 0.8841660261816449, disc_loss = 0.04689164021880263
Trained batch 450 in epoch 17, gen_loss = 0.8848964259391878, disc_loss = 0.04688107637903279
Trained batch 451 in epoch 17, gen_loss = 0.8850900469496187, disc_loss = 0.04707251809871203
Trained batch 452 in epoch 17, gen_loss = 0.884095214455333, disc_loss = 0.04770865797211167
Trained batch 453 in epoch 17, gen_loss = 0.8837692190109371, disc_loss = 0.047738593409149724
Trained batch 454 in epoch 17, gen_loss = 0.8844813976969038, disc_loss = 0.04779225885151671
Trained batch 455 in epoch 17, gen_loss = 0.8852928086069592, disc_loss = 0.04783795003701622
Trained batch 456 in epoch 17, gen_loss = 0.884296660806731, disc_loss = 0.04842760501209345
Trained batch 457 in epoch 17, gen_loss = 0.8838000151137597, disc_loss = 0.04864461402059024
Trained batch 458 in epoch 17, gen_loss = 0.883799651284623, disc_loss = 0.04878571018483287
Trained batch 459 in epoch 17, gen_loss = 0.8835920694729557, disc_loss = 0.049026323685867956
Trained batch 460 in epoch 17, gen_loss = 0.8832606693281269, disc_loss = 0.04911179461671997
Trained batch 461 in epoch 17, gen_loss = 0.883161903008238, disc_loss = 0.049105569422930415
Trained batch 462 in epoch 17, gen_loss = 0.883370072808173, disc_loss = 0.04906764085108885
Trained batch 463 in epoch 17, gen_loss = 0.8824578826155128, disc_loss = 0.04923430961207487
Trained batch 464 in epoch 17, gen_loss = 0.8822738962147826, disc_loss = 0.049147716097493646
Trained batch 465 in epoch 17, gen_loss = 0.8823634923911402, disc_loss = 0.04906159215366924
Trained batch 466 in epoch 17, gen_loss = 0.8830945926381383, disc_loss = 0.0491215959959115
Trained batch 467 in epoch 17, gen_loss = 0.8829585232923174, disc_loss = 0.0491015014375966
Trained batch 468 in epoch 17, gen_loss = 0.8825264489854069, disc_loss = 0.049278981607359676
Trained batch 469 in epoch 17, gen_loss = 0.8827716741790163, disc_loss = 0.049400663444217535
Trained batch 470 in epoch 17, gen_loss = 0.8828678772074908, disc_loss = 0.0493254576149276
Trained batch 471 in epoch 17, gen_loss = 0.8823383590048652, disc_loss = 0.049393398846081314
Trained batch 472 in epoch 17, gen_loss = 0.8822354676229505, disc_loss = 0.04935446652991354
Trained batch 473 in epoch 17, gen_loss = 0.8823399689001373, disc_loss = 0.04927796085820954
Trained batch 474 in epoch 17, gen_loss = 0.882209369446102, disc_loss = 0.049274532337133824
Trained batch 475 in epoch 17, gen_loss = 0.8828204453868025, disc_loss = 0.04947369399836615
Trained batch 476 in epoch 17, gen_loss = 0.8821673769995851, disc_loss = 0.04971984623632622
Trained batch 477 in epoch 17, gen_loss = 0.8816267809982579, disc_loss = 0.04975660470758553
Trained batch 478 in epoch 17, gen_loss = 0.8814727244023739, disc_loss = 0.04978758807241575
Trained batch 479 in epoch 17, gen_loss = 0.8816024941081803, disc_loss = 0.04989688127631477
Trained batch 480 in epoch 17, gen_loss = 0.8815377503943295, disc_loss = 0.04984121011151872
Trained batch 481 in epoch 17, gen_loss = 0.8807658937091155, disc_loss = 0.050013734488574116
Trained batch 482 in epoch 17, gen_loss = 0.8805403384239283, disc_loss = 0.050116629369641744
Trained batch 483 in epoch 17, gen_loss = 0.8799610987059341, disc_loss = 0.050355552000085985
Trained batch 484 in epoch 17, gen_loss = 0.8803972452571711, disc_loss = 0.05037663448889999
Trained batch 485 in epoch 17, gen_loss = 0.8810277193048854, disc_loss = 0.05032411984305967
Trained batch 486 in epoch 17, gen_loss = 0.8809338458632052, disc_loss = 0.05025677185685391
Trained batch 487 in epoch 17, gen_loss = 0.8803573724065648, disc_loss = 0.050361895476674017
Trained batch 488 in epoch 17, gen_loss = 0.8804095785432554, disc_loss = 0.05028094846759075
Trained batch 489 in epoch 17, gen_loss = 0.8804799947811632, disc_loss = 0.050357752661125695
Trained batch 490 in epoch 17, gen_loss = 0.8807969680264622, disc_loss = 0.05031518517024132
Trained batch 491 in epoch 17, gen_loss = 0.880405284222064, disc_loss = 0.0504809853959662
Trained batch 492 in epoch 17, gen_loss = 0.8798772773080134, disc_loss = 0.05061247313402699
Trained batch 493 in epoch 17, gen_loss = 0.8799388326010723, disc_loss = 0.05074972837601566
Trained batch 494 in epoch 17, gen_loss = 0.8807746361602437, disc_loss = 0.051095275598756894
Trained batch 495 in epoch 17, gen_loss = 0.8802204568900408, disc_loss = 0.051302578092755506
Trained batch 496 in epoch 17, gen_loss = 0.8797776568943346, disc_loss = 0.051347344876707376
Trained batch 497 in epoch 17, gen_loss = 0.8796386476381716, disc_loss = 0.051398665239346254
Trained batch 498 in epoch 17, gen_loss = 0.8797568956572929, disc_loss = 0.051466535354118964
Trained batch 499 in epoch 17, gen_loss = 0.8796048246026039, disc_loss = 0.051431237819604576
Trained batch 500 in epoch 17, gen_loss = 0.8789286069170443, disc_loss = 0.051607087406026805
Trained batch 501 in epoch 17, gen_loss = 0.878706581385962, disc_loss = 0.05153390288119208
Trained batch 502 in epoch 17, gen_loss = 0.8788355862051545, disc_loss = 0.05193818134772286
Trained batch 503 in epoch 17, gen_loss = 0.8785544700684056, disc_loss = 0.051911579142878986
Trained batch 504 in epoch 17, gen_loss = 0.8778408273021774, disc_loss = 0.05203451830801545
Trained batch 505 in epoch 17, gen_loss = 0.8776887754795579, disc_loss = 0.052002485893968595
Trained batch 506 in epoch 17, gen_loss = 0.8773210621797122, disc_loss = 0.052132097847164556
Trained batch 507 in epoch 17, gen_loss = 0.8767716461631256, disc_loss = 0.052155337796003856
Trained batch 508 in epoch 17, gen_loss = 0.8767974709832129, disc_loss = 0.05210233369315215
Trained batch 509 in epoch 17, gen_loss = 0.8768566807695464, disc_loss = 0.05202460939375063
Trained batch 510 in epoch 17, gen_loss = 0.8766213336452813, disc_loss = 0.052030911128749295
Trained batch 511 in epoch 17, gen_loss = 0.8767777237226255, disc_loss = 0.05201513863266882
Trained batch 512 in epoch 17, gen_loss = 0.8764548855334462, disc_loss = 0.05197980727176191
Trained batch 513 in epoch 17, gen_loss = 0.8763063191091968, disc_loss = 0.05197564269242091
Trained batch 514 in epoch 17, gen_loss = 0.8759638710508069, disc_loss = 0.05208039087270504
Trained batch 515 in epoch 17, gen_loss = 0.8757487838697988, disc_loss = 0.05205630933660148
Trained batch 516 in epoch 17, gen_loss = 0.8759016460906606, disc_loss = 0.051976698048131785
Trained batch 517 in epoch 17, gen_loss = 0.8759012143469225, disc_loss = 0.05208365632037715
Trained batch 518 in epoch 17, gen_loss = 0.8759982144327292, disc_loss = 0.0520071884938417
Trained batch 519 in epoch 17, gen_loss = 0.8756524989811274, disc_loss = 0.05204475628874766
Trained batch 520 in epoch 17, gen_loss = 0.8756545075642628, disc_loss = 0.05199937384143014
Trained batch 521 in epoch 17, gen_loss = 0.8760119832452686, disc_loss = 0.05198569763255559
Trained batch 522 in epoch 17, gen_loss = 0.8757229939131618, disc_loss = 0.05203583815631886
Trained batch 523 in epoch 17, gen_loss = 0.8752121591499744, disc_loss = 0.052137266905829024
Trained batch 524 in epoch 17, gen_loss = 0.8751810463837215, disc_loss = 0.052176362791409095
Trained batch 525 in epoch 17, gen_loss = 0.8752490263361441, disc_loss = 0.05228298048828746
Trained batch 526 in epoch 17, gen_loss = 0.8749168415110297, disc_loss = 0.05228426104298381
Trained batch 527 in epoch 17, gen_loss = 0.8744475178307656, disc_loss = 0.052424614420901475
Trained batch 528 in epoch 17, gen_loss = 0.8740963391072358, disc_loss = 0.05239583993161587
Trained batch 529 in epoch 17, gen_loss = 0.8749016654378963, disc_loss = 0.05270818943280797
Trained batch 530 in epoch 17, gen_loss = 0.8747653061499479, disc_loss = 0.05271673782442726
Trained batch 531 in epoch 17, gen_loss = 0.8743925222888925, disc_loss = 0.05285263200609112
Trained batch 532 in epoch 17, gen_loss = 0.874298869612964, disc_loss = 0.05281168879158306
Trained batch 533 in epoch 17, gen_loss = 0.8743089232663537, disc_loss = 0.05284561590493869
Trained batch 534 in epoch 17, gen_loss = 0.8750898283775722, disc_loss = 0.053057347500052685
Trained batch 535 in epoch 17, gen_loss = 0.874849331968311, disc_loss = 0.053105095231995934
Trained batch 536 in epoch 17, gen_loss = 0.8745498866453295, disc_loss = 0.05315262256571728
Trained batch 537 in epoch 17, gen_loss = 0.8744488761216734, disc_loss = 0.053195920323634516
Trained batch 538 in epoch 17, gen_loss = 0.8741302923169781, disc_loss = 0.05322746687580819
Trained batch 539 in epoch 17, gen_loss = 0.8740327505601777, disc_loss = 0.053343728030341916
Trained batch 540 in epoch 17, gen_loss = 0.8745881977341312, disc_loss = 0.05358793704672381
Trained batch 541 in epoch 17, gen_loss = 0.8740507058001972, disc_loss = 0.053651677256422566
Trained batch 542 in epoch 17, gen_loss = 0.8733950741932098, disc_loss = 0.053891047832777324
Trained batch 543 in epoch 17, gen_loss = 0.8734213275396648, disc_loss = 0.053842891439939304
Trained batch 544 in epoch 17, gen_loss = 0.8740546013783971, disc_loss = 0.054095896744434165
Trained batch 545 in epoch 17, gen_loss = 0.8737841557997924, disc_loss = 0.0540765465924605
Trained batch 546 in epoch 17, gen_loss = 0.8735816249354884, disc_loss = 0.05404088463739814
Trained batch 547 in epoch 17, gen_loss = 0.8733557590494191, disc_loss = 0.05402034332204175
Trained batch 548 in epoch 17, gen_loss = 0.873014024426594, disc_loss = 0.054046953080870035
Trained batch 549 in epoch 17, gen_loss = 0.8728122786500238, disc_loss = 0.05402314090000635
Trained batch 550 in epoch 17, gen_loss = 0.8729227755874558, disc_loss = 0.05410291911770476
Trained batch 551 in epoch 17, gen_loss = 0.8732116501508416, disc_loss = 0.054051688798885465
Trained batch 552 in epoch 17, gen_loss = 0.8727890949891661, disc_loss = 0.05408347326046223
Trained batch 553 in epoch 17, gen_loss = 0.8725096377332288, disc_loss = 0.05404450004795963
Trained batch 554 in epoch 17, gen_loss = 0.8720427572727203, disc_loss = 0.054099783060552034
Trained batch 555 in epoch 17, gen_loss = 0.8725693100969568, disc_loss = 0.05410342187898756
Trained batch 556 in epoch 17, gen_loss = 0.8727831632380426, disc_loss = 0.05405536902018386
Trained batch 557 in epoch 17, gen_loss = 0.8727333716060098, disc_loss = 0.05398352810775855
Trained batch 558 in epoch 17, gen_loss = 0.8725260504136572, disc_loss = 0.05399151276447185
Trained batch 559 in epoch 17, gen_loss = 0.8722439908023392, disc_loss = 0.05397888462674538
Trained batch 560 in epoch 17, gen_loss = 0.8728265058441808, disc_loss = 0.05400937261166128
Trained batch 561 in epoch 17, gen_loss = 0.8730864076745892, disc_loss = 0.05406124948928285
Trained batch 562 in epoch 17, gen_loss = 0.8727365750720192, disc_loss = 0.054083565115220646
Trained batch 563 in epoch 17, gen_loss = 0.8725916789250171, disc_loss = 0.05406194193542981
Trained batch 564 in epoch 17, gen_loss = 0.8725431686481543, disc_loss = 0.05415894452531913
Trained batch 565 in epoch 17, gen_loss = 0.87248916250025, disc_loss = 0.054131453864230336
Trained batch 566 in epoch 17, gen_loss = 0.8724150375399009, disc_loss = 0.05407714444036863
Trained batch 567 in epoch 17, gen_loss = 0.872427844612951, disc_loss = 0.05400086180913642
Trained batch 568 in epoch 17, gen_loss = 0.8724507807323509, disc_loss = 0.053923379481722634
Trained batch 569 in epoch 17, gen_loss = 0.8722320675327067, disc_loss = 0.05385675802418407
Trained batch 570 in epoch 17, gen_loss = 0.8726734569632234, disc_loss = 0.053836253912868254
Trained batch 571 in epoch 17, gen_loss = 0.8725818446153527, disc_loss = 0.05378493882139324
Trained batch 572 in epoch 17, gen_loss = 0.8729518228072355, disc_loss = 0.05372628081918257
Trained batch 573 in epoch 17, gen_loss = 0.8730418150952469, disc_loss = 0.05364507501733973
Trained batch 574 in epoch 17, gen_loss = 0.8727295337034309, disc_loss = 0.05361354133438157
Trained batch 575 in epoch 17, gen_loss = 0.8727378584961925, disc_loss = 0.053609559462024156
Trained batch 576 in epoch 17, gen_loss = 0.8725858560571225, disc_loss = 0.05357976379906
Trained batch 577 in epoch 17, gen_loss = 0.8730580220482341, disc_loss = 0.05354585809307656
Trained batch 578 in epoch 17, gen_loss = 0.873074668728214, disc_loss = 0.053466558831201834
Trained batch 579 in epoch 17, gen_loss = 0.8732963227506342, disc_loss = 0.053390030628712525
Trained batch 580 in epoch 17, gen_loss = 0.8731469606881298, disc_loss = 0.05334888108029782
Trained batch 581 in epoch 17, gen_loss = 0.87355070154077, disc_loss = 0.05330599027548203
Trained batch 582 in epoch 17, gen_loss = 0.873382323857646, disc_loss = 0.053273689933121204
Trained batch 583 in epoch 17, gen_loss = 0.8728384765962215, disc_loss = 0.05330399165331858
Trained batch 584 in epoch 17, gen_loss = 0.8726881516794873, disc_loss = 0.05324845541204907
Trained batch 585 in epoch 17, gen_loss = 0.8730986499237119, disc_loss = 0.05318635228366524
Trained batch 586 in epoch 17, gen_loss = 0.873326157843234, disc_loss = 0.05312848314357322
Trained batch 587 in epoch 17, gen_loss = 0.873498904613816, disc_loss = 0.05308571960745367
Trained batch 588 in epoch 17, gen_loss = 0.8729447615672858, disc_loss = 0.053266359899502964
Trained batch 589 in epoch 17, gen_loss = 0.873167212282197, disc_loss = 0.053383995010122906
Trained batch 590 in epoch 17, gen_loss = 0.8729452057639153, disc_loss = 0.05334236784704193
Trained batch 591 in epoch 17, gen_loss = 0.8727891599709118, disc_loss = 0.05327155326990209
Trained batch 592 in epoch 17, gen_loss = 0.8733735986644462, disc_loss = 0.05328771523961681
Trained batch 593 in epoch 17, gen_loss = 0.8733721770321079, disc_loss = 0.0534162676567055
Trained batch 594 in epoch 17, gen_loss = 0.8727934646506269, disc_loss = 0.053576500217641605
Trained batch 595 in epoch 17, gen_loss = 0.8721995047174844, disc_loss = 0.05370385576533341
Trained batch 596 in epoch 17, gen_loss = 0.8722864599583336, disc_loss = 0.05374561806039345
Trained batch 597 in epoch 17, gen_loss = 0.872330088729045, disc_loss = 0.053742033100833364
Trained batch 598 in epoch 17, gen_loss = 0.872435782459224, disc_loss = 0.05367837740708522
Trained batch 599 in epoch 17, gen_loss = 0.8727480071286361, disc_loss = 0.05376809896435589
Trained batch 600 in epoch 17, gen_loss = 0.8720678484777048, disc_loss = 0.05434547760330153
Trained batch 601 in epoch 17, gen_loss = 0.8716164622393954, disc_loss = 0.054510508501512366
Trained batch 602 in epoch 17, gen_loss = 0.8716786092588953, disc_loss = 0.054673930344358704
Trained batch 603 in epoch 17, gen_loss = 0.8718118524511919, disc_loss = 0.0546685996301941
Trained batch 604 in epoch 17, gen_loss = 0.8719841445773101, disc_loss = 0.05474698293707834
Trained batch 605 in epoch 17, gen_loss = 0.8719641915445674, disc_loss = 0.05469341867022438
Trained batch 606 in epoch 17, gen_loss = 0.8715907655398575, disc_loss = 0.05476623954776141
Trained batch 607 in epoch 17, gen_loss = 0.8716214614871302, disc_loss = 0.05470480435791327
Trained batch 608 in epoch 17, gen_loss = 0.8712340297761614, disc_loss = 0.05472864148670376
Trained batch 609 in epoch 17, gen_loss = 0.8718653665214289, disc_loss = 0.0549394043422014
Trained batch 610 in epoch 17, gen_loss = 0.8717043830993327, disc_loss = 0.054940081356968214
Trained batch 611 in epoch 17, gen_loss = 0.8713415241708943, disc_loss = 0.05497596986756167
Trained batch 612 in epoch 17, gen_loss = 0.8711113340508491, disc_loss = 0.05496538187214591
Trained batch 613 in epoch 17, gen_loss = 0.8708646598390337, disc_loss = 0.05496146923525665
Trained batch 614 in epoch 17, gen_loss = 0.8709344931734286, disc_loss = 0.05488936590500237
Trained batch 615 in epoch 17, gen_loss = 0.8705571893747751, disc_loss = 0.05493325176013803
Trained batch 616 in epoch 17, gen_loss = 0.8704840019224529, disc_loss = 0.05490646688977024
Trained batch 617 in epoch 17, gen_loss = 0.8705965225557679, disc_loss = 0.054981784492694925
Trained batch 618 in epoch 17, gen_loss = 0.8702691449679928, disc_loss = 0.05500337000190008
Trained batch 619 in epoch 17, gen_loss = 0.8705682017149464, disc_loss = 0.05495927392264768
Trained batch 620 in epoch 17, gen_loss = 0.8704566714652302, disc_loss = 0.05491835610032226
Trained batch 621 in epoch 17, gen_loss = 0.870163106362536, disc_loss = 0.05493346090695051
Trained batch 622 in epoch 17, gen_loss = 0.8703204934899343, disc_loss = 0.05486392022751834
Trained batch 623 in epoch 17, gen_loss = 0.8699124835622616, disc_loss = 0.05497448250072268
Trained batch 624 in epoch 17, gen_loss = 0.8699850805282593, disc_loss = 0.054982964013516905
Trained batch 625 in epoch 17, gen_loss = 0.8701895673434955, disc_loss = 0.055043363662513965
Trained batch 626 in epoch 17, gen_loss = 0.8698992854670474, disc_loss = 0.05503072590081458
Trained batch 627 in epoch 17, gen_loss = 0.8697889124511913, disc_loss = 0.05496093893133009
Trained batch 628 in epoch 17, gen_loss = 0.8698919914864205, disc_loss = 0.05488853355712703
Trained batch 629 in epoch 17, gen_loss = 0.8695521619584825, disc_loss = 0.05487646586631262
Trained batch 630 in epoch 17, gen_loss = 0.8697063736794679, disc_loss = 0.05482812782398258
Trained batch 631 in epoch 17, gen_loss = 0.8699905060325996, disc_loss = 0.054905215636355496
Trained batch 632 in epoch 17, gen_loss = 0.8697064869211748, disc_loss = 0.05490391871981664
Trained batch 633 in epoch 17, gen_loss = 0.869589763672946, disc_loss = 0.05486034349705848
Trained batch 634 in epoch 17, gen_loss = 0.8695419883164834, disc_loss = 0.05484454672138287
Trained batch 635 in epoch 17, gen_loss = 0.8692933389413282, disc_loss = 0.05483843320424218
Trained batch 636 in epoch 17, gen_loss = 0.8691149592586739, disc_loss = 0.05480143995560834
Trained batch 637 in epoch 17, gen_loss = 0.8689944400309022, disc_loss = 0.05474461955646035
Trained batch 638 in epoch 17, gen_loss = 0.8689142751022124, disc_loss = 0.05471947927505991
Trained batch 639 in epoch 17, gen_loss = 0.8689772652462124, disc_loss = 0.05469752994977171
Trained batch 640 in epoch 17, gen_loss = 0.8695319007599781, disc_loss = 0.054705127523035135
Trained batch 641 in epoch 17, gen_loss = 0.8697790943573569, disc_loss = 0.054638483333822076
Trained batch 642 in epoch 17, gen_loss = 0.869409855472541, disc_loss = 0.0547090245144294
Trained batch 643 in epoch 17, gen_loss = 0.8691656209111954, disc_loss = 0.05475685703394622
Trained batch 644 in epoch 17, gen_loss = 0.8695247240768846, disc_loss = 0.05474293241927097
Trained batch 645 in epoch 17, gen_loss = 0.8696930915947669, disc_loss = 0.05468103714754384
Trained batch 646 in epoch 17, gen_loss = 0.8699589919822847, disc_loss = 0.054631234155291294
Trained batch 647 in epoch 17, gen_loss = 0.8701166948418558, disc_loss = 0.054568971178126466
Trained batch 648 in epoch 17, gen_loss = 0.8699157609961617, disc_loss = 0.05455116474590564
Trained batch 649 in epoch 17, gen_loss = 0.8700249650845161, disc_loss = 0.05451153261300463
Trained batch 650 in epoch 17, gen_loss = 0.8701657175834644, disc_loss = 0.054469519432136265
Trained batch 651 in epoch 17, gen_loss = 0.8703863317249743, disc_loss = 0.05442641315370387
Trained batch 652 in epoch 17, gen_loss = 0.8698575875477988, disc_loss = 0.05475637436363772
Trained batch 653 in epoch 17, gen_loss = 0.869756319016127, disc_loss = 0.05470774130075486
Trained batch 654 in epoch 17, gen_loss = 0.8700533971531701, disc_loss = 0.054643455565771985
Trained batch 655 in epoch 17, gen_loss = 0.8701349193366562, disc_loss = 0.05487345939036459
Trained batch 656 in epoch 17, gen_loss = 0.8698752370054863, disc_loss = 0.05495328997946493
Trained batch 657 in epoch 17, gen_loss = 0.8696113938075068, disc_loss = 0.054996536741752214
Trained batch 658 in epoch 17, gen_loss = 0.8695667329977785, disc_loss = 0.05502099066418744
Trained batch 659 in epoch 17, gen_loss = 0.8696490474722602, disc_loss = 0.0551416568542746
Trained batch 660 in epoch 17, gen_loss = 0.8695701150598396, disc_loss = 0.05512036333274823
Trained batch 661 in epoch 17, gen_loss = 0.8695011131713037, disc_loss = 0.0551284222224913
Trained batch 662 in epoch 17, gen_loss = 0.8694240183851838, disc_loss = 0.05509042424651293
Trained batch 663 in epoch 17, gen_loss = 0.8695369598018118, disc_loss = 0.05503248557425946
Trained batch 664 in epoch 17, gen_loss = 0.8692928561590668, disc_loss = 0.055044936388731
Trained batch 665 in epoch 17, gen_loss = 0.8694637109925439, disc_loss = 0.054981640784780274
Trained batch 666 in epoch 17, gen_loss = 0.8695816621966269, disc_loss = 0.05491506827037329
Trained batch 667 in epoch 17, gen_loss = 0.8694530545237535, disc_loss = 0.054847778801243016
Trained batch 668 in epoch 17, gen_loss = 0.8694988453512947, disc_loss = 0.0549094441356569
Trained batch 669 in epoch 17, gen_loss = 0.8690121990531238, disc_loss = 0.055009545412248194
Trained batch 670 in epoch 17, gen_loss = 0.8688588876127309, disc_loss = 0.05497391359677924
Trained batch 671 in epoch 17, gen_loss = 0.8687234528007961, disc_loss = 0.054938211606072616
Trained batch 672 in epoch 17, gen_loss = 0.8691233773819582, disc_loss = 0.05493593498383598
Trained batch 673 in epoch 17, gen_loss = 0.8692982978566111, disc_loss = 0.05489651469834348
Trained batch 674 in epoch 17, gen_loss = 0.8690343334056713, disc_loss = 0.054879079296908995
Trained batch 675 in epoch 17, gen_loss = 0.8690004204151899, disc_loss = 0.05486792915765218
Trained batch 676 in epoch 17, gen_loss = 0.8693318560697479, disc_loss = 0.054921561685642516
Trained batch 677 in epoch 17, gen_loss = 0.868938047625674, disc_loss = 0.054926480659747985
Trained batch 678 in epoch 17, gen_loss = 0.8691900966795976, disc_loss = 0.054877312995208115
Trained batch 679 in epoch 17, gen_loss = 0.868945056550643, disc_loss = 0.0549227075829335
Trained batch 680 in epoch 17, gen_loss = 0.8688552295583986, disc_loss = 0.05492269278540879
Trained batch 681 in epoch 17, gen_loss = 0.86902058849936, disc_loss = 0.05493582066427097
Trained batch 682 in epoch 17, gen_loss = 0.8690733337995772, disc_loss = 0.05488265667787015
Trained batch 683 in epoch 17, gen_loss = 0.8687987467873166, disc_loss = 0.05490246638301651
Trained batch 684 in epoch 17, gen_loss = 0.8686603031889365, disc_loss = 0.05485464236189196
Trained batch 685 in epoch 17, gen_loss = 0.8695530767169708, disc_loss = 0.054904440104277155
Trained batch 686 in epoch 17, gen_loss = 0.8696958620475369, disc_loss = 0.05489693838680025
Trained batch 687 in epoch 17, gen_loss = 0.8696401349680368, disc_loss = 0.054855870707014705
Trained batch 688 in epoch 17, gen_loss = 0.869651476167283, disc_loss = 0.054809205354352214
Trained batch 689 in epoch 17, gen_loss = 0.8692054883293484, disc_loss = 0.05487701170605378
Trained batch 690 in epoch 17, gen_loss = 0.8691773449977814, disc_loss = 0.05482217729463634
Trained batch 691 in epoch 17, gen_loss = 0.8694100926893984, disc_loss = 0.05485662266294434
Trained batch 692 in epoch 17, gen_loss = 0.8697615783623974, disc_loss = 0.05481314100190718
Trained batch 693 in epoch 17, gen_loss = 0.8696781506799484, disc_loss = 0.05476882294630927
Trained batch 694 in epoch 17, gen_loss = 0.8694279834520903, disc_loss = 0.05476622193274524
Trained batch 695 in epoch 17, gen_loss = 0.8690975393200743, disc_loss = 0.05477609510945649
Trained batch 696 in epoch 17, gen_loss = 0.8692167461174974, disc_loss = 0.05480076206802595
Trained batch 697 in epoch 17, gen_loss = 0.8689443701317795, disc_loss = 0.054822738956190366
Trained batch 698 in epoch 17, gen_loss = 0.8685862141446835, disc_loss = 0.05489195668896679
Trained batch 699 in epoch 17, gen_loss = 0.8689039519854954, disc_loss = 0.05493312508799136
Trained batch 700 in epoch 17, gen_loss = 0.8686653680025936, disc_loss = 0.054956569745552096
Trained batch 701 in epoch 17, gen_loss = 0.868969204588833, disc_loss = 0.05490699763465513
Trained batch 702 in epoch 17, gen_loss = 0.8689314711992635, disc_loss = 0.05485756178737577
Trained batch 703 in epoch 17, gen_loss = 0.8692441806197166, disc_loss = 0.05480362717406189
Trained batch 704 in epoch 17, gen_loss = 0.8689747215162777, disc_loss = 0.05489521278266577
Trained batch 705 in epoch 17, gen_loss = 0.8685047207743183, disc_loss = 0.05503261346955686
Trained batch 706 in epoch 17, gen_loss = 0.8689425413139807, disc_loss = 0.05506905517244482
Trained batch 707 in epoch 17, gen_loss = 0.8687932578857336, disc_loss = 0.05508150543496644
Trained batch 708 in epoch 17, gen_loss = 0.8682922351007233, disc_loss = 0.055264860476999
Trained batch 709 in epoch 17, gen_loss = 0.868358171154076, disc_loss = 0.05548952492741002
Trained batch 710 in epoch 17, gen_loss = 0.8688021951922217, disc_loss = 0.05545825214791943
Trained batch 711 in epoch 17, gen_loss = 0.8686819958050599, disc_loss = 0.055461800402145454
Trained batch 712 in epoch 17, gen_loss = 0.8684448781220809, disc_loss = 0.055545698424218665
Trained batch 713 in epoch 17, gen_loss = 0.8682781879474469, disc_loss = 0.05553806465280866
Trained batch 714 in epoch 17, gen_loss = 0.8684127610046547, disc_loss = 0.05555321356034154
Trained batch 715 in epoch 17, gen_loss = 0.8682034574240945, disc_loss = 0.05554633450892093
Trained batch 716 in epoch 17, gen_loss = 0.8678797310532552, disc_loss = 0.05557520976069291
Trained batch 717 in epoch 17, gen_loss = 0.8683269414064944, disc_loss = 0.05564402619345648
Trained batch 718 in epoch 17, gen_loss = 0.8678448981137866, disc_loss = 0.05572214211377423
Trained batch 719 in epoch 17, gen_loss = 0.8678647362523608, disc_loss = 0.055694230119439046
Trained batch 720 in epoch 17, gen_loss = 0.8683397915426141, disc_loss = 0.05580510156831075
Trained batch 721 in epoch 17, gen_loss = 0.8679195794372347, disc_loss = 0.05584699074528761
Trained batch 722 in epoch 17, gen_loss = 0.8675956538109364, disc_loss = 0.055868497384998064
Trained batch 723 in epoch 17, gen_loss = 0.8676817741512594, disc_loss = 0.055912574764742456
Trained batch 724 in epoch 17, gen_loss = 0.8675249884046358, disc_loss = 0.05588389077705556
Trained batch 725 in epoch 17, gen_loss = 0.867531763538513, disc_loss = 0.05584212492243194
Trained batch 726 in epoch 17, gen_loss = 0.8674570806580691, disc_loss = 0.05584560420897058
Trained batch 727 in epoch 17, gen_loss = 0.8678236643855388, disc_loss = 0.05596643094879135
Trained batch 728 in epoch 17, gen_loss = 0.8677000290572398, disc_loss = 0.0559214753084733
Trained batch 729 in epoch 17, gen_loss = 0.8674903432800345, disc_loss = 0.055910436055074404
Trained batch 730 in epoch 17, gen_loss = 0.8672511264498355, disc_loss = 0.0558938851946947
Trained batch 731 in epoch 17, gen_loss = 0.8670397961074537, disc_loss = 0.055883047024622726
Trained batch 732 in epoch 17, gen_loss = 0.866689174432221, disc_loss = 0.05597511148474104
Trained batch 733 in epoch 17, gen_loss = 0.8672261910477516, disc_loss = 0.056116877089455036
Trained batch 734 in epoch 17, gen_loss = 0.866734093954774, disc_loss = 0.05630789811843309
Trained batch 735 in epoch 17, gen_loss = 0.866814326899855, disc_loss = 0.0564290328551104
Trained batch 736 in epoch 17, gen_loss = 0.866784485984528, disc_loss = 0.05638432014592022
Trained batch 737 in epoch 17, gen_loss = 0.8666244929398947, disc_loss = 0.05637240620976097
Trained batch 738 in epoch 17, gen_loss = 0.8667690738612164, disc_loss = 0.05631486237986726
Trained batch 739 in epoch 17, gen_loss = 0.86656326377714, disc_loss = 0.05642364835870024
Trained batch 740 in epoch 17, gen_loss = 0.8667650814802862, disc_loss = 0.056361036548609675
Trained batch 741 in epoch 17, gen_loss = 0.8665085038888165, disc_loss = 0.05636981146214304
Trained batch 742 in epoch 17, gen_loss = 0.8667207669922994, disc_loss = 0.05631526562098218
Trained batch 743 in epoch 17, gen_loss = 0.8671138720006071, disc_loss = 0.056275890153702546
Trained batch 744 in epoch 17, gen_loss = 0.8672537834852334, disc_loss = 0.056230142250057034
Trained batch 745 in epoch 17, gen_loss = 0.8672262421402152, disc_loss = 0.056199824295178974
Trained batch 746 in epoch 17, gen_loss = 0.8668475359319204, disc_loss = 0.05644104677879587
Trained batch 747 in epoch 17, gen_loss = 0.8672590282033471, disc_loss = 0.05663735360992863
Trained batch 748 in epoch 17, gen_loss = 0.867145368190251, disc_loss = 0.05668549873531661
Trained batch 749 in epoch 17, gen_loss = 0.8672031603654226, disc_loss = 0.056626031868159774
Trained batch 750 in epoch 17, gen_loss = 0.8670626092211067, disc_loss = 0.05663799724917358
Trained batch 751 in epoch 17, gen_loss = 0.8669048932163005, disc_loss = 0.056609354658111774
Trained batch 752 in epoch 17, gen_loss = 0.86721386860408, disc_loss = 0.0566522454345725
Trained batch 753 in epoch 17, gen_loss = 0.866966090167549, disc_loss = 0.056725702194165964
Trained batch 754 in epoch 17, gen_loss = 0.867030477129071, disc_loss = 0.056703538904028225
Trained batch 755 in epoch 17, gen_loss = 0.867197055349905, disc_loss = 0.056724543045102445
Trained batch 756 in epoch 17, gen_loss = 0.8670364674992731, disc_loss = 0.05673729698942627
Trained batch 757 in epoch 17, gen_loss = 0.8669925453165905, disc_loss = 0.05670076445246356
Trained batch 758 in epoch 17, gen_loss = 0.867326979580604, disc_loss = 0.05665758018024825
Trained batch 759 in epoch 17, gen_loss = 0.8671028359940177, disc_loss = 0.05671187094657829
Trained batch 760 in epoch 17, gen_loss = 0.8668520816365617, disc_loss = 0.056758731902233094
Trained batch 761 in epoch 17, gen_loss = 0.8668565836947734, disc_loss = 0.05673345524495042
Trained batch 762 in epoch 17, gen_loss = 0.8672652662503454, disc_loss = 0.05669190852779549
Trained batch 763 in epoch 17, gen_loss = 0.867653679083155, disc_loss = 0.056636851622250066
Trained batch 764 in epoch 17, gen_loss = 0.8674339398059969, disc_loss = 0.056670179963111876
Trained batch 765 in epoch 17, gen_loss = 0.8675988423917685, disc_loss = 0.05675572511927266
Trained batch 766 in epoch 17, gen_loss = 0.8677526341734219, disc_loss = 0.056725059034888094
Trained batch 767 in epoch 17, gen_loss = 0.8672494422644377, disc_loss = 0.05691387160428955
Trained batch 768 in epoch 17, gen_loss = 0.8673343525906378, disc_loss = 0.056855030784138776
Trained batch 769 in epoch 17, gen_loss = 0.8675198911846458, disc_loss = 0.0571070745103545
Trained batch 770 in epoch 17, gen_loss = 0.8672974585095268, disc_loss = 0.05715404471186812
Trained batch 771 in epoch 17, gen_loss = 0.8670679966248379, disc_loss = 0.05719762485609462
Trained batch 772 in epoch 17, gen_loss = 0.8671445194222177, disc_loss = 0.05716758771747698
Trained batch 773 in epoch 17, gen_loss = 0.8672697135182315, disc_loss = 0.05712743679624657
Trained batch 774 in epoch 17, gen_loss = 0.867163205992791, disc_loss = 0.05710989217123678
Trained batch 775 in epoch 17, gen_loss = 0.8670616285856237, disc_loss = 0.05709576914951052
Trained batch 776 in epoch 17, gen_loss = 0.8668936592271429, disc_loss = 0.057063920459346884
Trained batch 777 in epoch 17, gen_loss = 0.8663831620948786, disc_loss = 0.05715203805704503
Trained batch 778 in epoch 17, gen_loss = 0.86644014922737, disc_loss = 0.05724141131297462
Trained batch 779 in epoch 17, gen_loss = 0.8664581591884295, disc_loss = 0.05724708491888566
Trained batch 780 in epoch 17, gen_loss = 0.8660924632708028, disc_loss = 0.057334883937495314
Trained batch 781 in epoch 17, gen_loss = 0.8658752261144121, disc_loss = 0.0573361928972518
Trained batch 782 in epoch 17, gen_loss = 0.8658929951726857, disc_loss = 0.05733931255390056
Trained batch 783 in epoch 17, gen_loss = 0.8662394403422974, disc_loss = 0.05733301166958195
Trained batch 784 in epoch 17, gen_loss = 0.8661515585556152, disc_loss = 0.05730002664836349
Trained batch 785 in epoch 17, gen_loss = 0.8662814342111121, disc_loss = 0.057244946912367076
Trained batch 786 in epoch 17, gen_loss = 0.8659446460243404, disc_loss = 0.05737957848044257
Trained batch 787 in epoch 17, gen_loss = 0.86653382535362, disc_loss = 0.0574458106751861
Trained batch 788 in epoch 17, gen_loss = 0.866618669040605, disc_loss = 0.057385754262785346
Trained batch 789 in epoch 17, gen_loss = 0.86657248550578, disc_loss = 0.05735413521009533
Testing Epoch 17
Training Epoch 18
Trained batch 0 in epoch 18, gen_loss = 0.8775526285171509, disc_loss = 0.013315634801983833
Trained batch 1 in epoch 18, gen_loss = 0.8101100325584412, disc_loss = 0.032738166861236095
Trained batch 2 in epoch 18, gen_loss = 0.84659343957901, disc_loss = 0.027338977282245953
Trained batch 3 in epoch 18, gen_loss = 0.9209282547235489, disc_loss = 0.02273735497146845
Trained batch 4 in epoch 18, gen_loss = 0.850360906124115, disc_loss = 0.042170118540525436
Trained batch 5 in epoch 18, gen_loss = 0.8290886382261912, disc_loss = 0.0459800244619449
Trained batch 6 in epoch 18, gen_loss = 0.8320842811039516, disc_loss = 0.05187761091760227
Trained batch 7 in epoch 18, gen_loss = 0.8164553493261337, disc_loss = 0.053476674016565084
Trained batch 8 in epoch 18, gen_loss = 0.7946033808920119, disc_loss = 0.06144225555989477
Trained batch 9 in epoch 18, gen_loss = 0.8309054434299469, disc_loss = 0.06572667621076107
Trained batch 10 in epoch 18, gen_loss = 0.8015036203644492, disc_loss = 0.07397644052451308
Trained batch 11 in epoch 18, gen_loss = 0.8318708588679632, disc_loss = 0.07610516715794802
Trained batch 12 in epoch 18, gen_loss = 0.8292385385586665, disc_loss = 0.07261313326083697
Trained batch 13 in epoch 18, gen_loss = 0.8258844869477409, disc_loss = 0.0689065581453698
Trained batch 14 in epoch 18, gen_loss = 0.8131300131479899, disc_loss = 0.06768553107976913
Trained batch 15 in epoch 18, gen_loss = 0.8241378702223301, disc_loss = 0.06418744300026447
Trained batch 16 in epoch 18, gen_loss = 0.8378357922329622, disc_loss = 0.06859368973356836
Trained batch 17 in epoch 18, gen_loss = 0.8244840469625261, disc_loss = 0.07253142373843326
Trained batch 18 in epoch 18, gen_loss = 0.8173907524661014, disc_loss = 0.07284034798411947
Trained batch 19 in epoch 18, gen_loss = 0.8094389617443085, disc_loss = 0.07198509508743882
Trained batch 20 in epoch 18, gen_loss = 0.814940679640997, disc_loss = 0.07522699458613283
Trained batch 21 in epoch 18, gen_loss = 0.8193061595613306, disc_loss = 0.07289408773861149
Trained batch 22 in epoch 18, gen_loss = 0.8028048199156056, disc_loss = 0.07750882742845494
Trained batch 23 in epoch 18, gen_loss = 0.7978664462765058, disc_loss = 0.07812457050507267
Trained batch 24 in epoch 18, gen_loss = 0.807128484249115, disc_loss = 0.07724984899163247
Trained batch 25 in epoch 18, gen_loss = 0.8042395527546222, disc_loss = 0.07682013153456725
Trained batch 26 in epoch 18, gen_loss = 0.8092245062192281, disc_loss = 0.07461758164895906
Trained batch 27 in epoch 18, gen_loss = 0.8067090596471514, disc_loss = 0.07436077576130629
Trained batch 28 in epoch 18, gen_loss = 0.807023155278173, disc_loss = 0.07542515841537509
Trained batch 29 in epoch 18, gen_loss = 0.8071977496147156, disc_loss = 0.07386192629734675
Trained batch 30 in epoch 18, gen_loss = 0.8002002162318076, disc_loss = 0.07491168668193202
Trained batch 31 in epoch 18, gen_loss = 0.8088787645101547, disc_loss = 0.07414040574803948
Trained batch 32 in epoch 18, gen_loss = 0.8115643949219675, disc_loss = 0.07248037353609547
Trained batch 33 in epoch 18, gen_loss = 0.8162233303574955, disc_loss = 0.07061291738029789
Trained batch 34 in epoch 18, gen_loss = 0.8251383713313512, disc_loss = 0.07035654623593603
Trained batch 35 in epoch 18, gen_loss = 0.8254223929511176, disc_loss = 0.06873850488207406
Trained batch 36 in epoch 18, gen_loss = 0.8240271194561107, disc_loss = 0.06913008123032145
Trained batch 37 in epoch 18, gen_loss = 0.8258800632075259, disc_loss = 0.06764488123161227
Trained batch 38 in epoch 18, gen_loss = 0.8218324979146322, disc_loss = 0.0677001373603558
Trained batch 39 in epoch 18, gen_loss = 0.824669086933136, disc_loss = 0.07005646680481732
Trained batch 40 in epoch 18, gen_loss = 0.822004728200959, disc_loss = 0.06968434886416285
Trained batch 41 in epoch 18, gen_loss = 0.8258757818312872, disc_loss = 0.06829900139321883
Trained batch 42 in epoch 18, gen_loss = 0.8329136926074361, disc_loss = 0.06737261642377045
Trained batch 43 in epoch 18, gen_loss = 0.824851939624006, disc_loss = 0.06988708213479682
Trained batch 44 in epoch 18, gen_loss = 0.8310036698977152, disc_loss = 0.06921510899232494
Trained batch 45 in epoch 18, gen_loss = 0.8322015780469646, disc_loss = 0.06804258356113797
Trained batch 46 in epoch 18, gen_loss = 0.8305333345494372, disc_loss = 0.06739546544849873
Trained batch 47 in epoch 18, gen_loss = 0.8282148949801922, disc_loss = 0.06720513877614091
Trained batch 48 in epoch 18, gen_loss = 0.8320224808186901, disc_loss = 0.06706973967351476
Trained batch 49 in epoch 18, gen_loss = 0.8310099375247956, disc_loss = 0.06626147039234638
Trained batch 50 in epoch 18, gen_loss = 0.8319929756370246, disc_loss = 0.06518682421130292
Trained batch 51 in epoch 18, gen_loss = 0.8347563777978604, disc_loss = 0.06407564307133165
Trained batch 52 in epoch 18, gen_loss = 0.8384092697557414, disc_loss = 0.06301848235417087
Trained batch 53 in epoch 18, gen_loss = 0.8389604168909567, disc_loss = 0.06253713628070222
Trained batch 54 in epoch 18, gen_loss = 0.8343890341845426, disc_loss = 0.0629916465756568
Trained batch 55 in epoch 18, gen_loss = 0.8367565444537571, disc_loss = 0.061991950505346595
Trained batch 56 in epoch 18, gen_loss = 0.8393478330812956, disc_loss = 0.06125707745454029
Trained batch 57 in epoch 18, gen_loss = 0.8401216535732664, disc_loss = 0.06314701411134467
Trained batch 58 in epoch 18, gen_loss = 0.8406149876319756, disc_loss = 0.062355952155855245
Trained batch 59 in epoch 18, gen_loss = 0.8351004232962926, disc_loss = 0.06449701082116614
Trained batch 60 in epoch 18, gen_loss = 0.8404845595359802, disc_loss = 0.0649513342478847
Trained batch 61 in epoch 18, gen_loss = 0.838775860686456, disc_loss = 0.06468415768787024
Trained batch 62 in epoch 18, gen_loss = 0.8443417161230057, disc_loss = 0.06423589070549324
Trained batch 63 in epoch 18, gen_loss = 0.8427869519218802, disc_loss = 0.0639782441794523
Trained batch 64 in epoch 18, gen_loss = 0.8432400804299575, disc_loss = 0.06358250853104087
Trained batch 65 in epoch 18, gen_loss = 0.840715181646925, disc_loss = 0.06330690717070618
Trained batch 66 in epoch 18, gen_loss = 0.8428008680912986, disc_loss = 0.06249401018496102
Trained batch 67 in epoch 18, gen_loss = 0.8436894364216748, disc_loss = 0.061962992288446164
Trained batch 68 in epoch 18, gen_loss = 0.8417753482210464, disc_loss = 0.06214313479680298
Trained batch 69 in epoch 18, gen_loss = 0.8414041527679988, disc_loss = 0.06155410023805286
Trained batch 70 in epoch 18, gen_loss = 0.8431461151217071, disc_loss = 0.06103060096108787
Trained batch 71 in epoch 18, gen_loss = 0.8419321502248446, disc_loss = 0.06064104191156932
Trained batch 72 in epoch 18, gen_loss = 0.8428354777701913, disc_loss = 0.06000499740523631
Trained batch 73 in epoch 18, gen_loss = 0.8488341432970923, disc_loss = 0.06051322140076475
Trained batch 74 in epoch 18, gen_loss = 0.8445441921552023, disc_loss = 0.062030221292128165
Trained batch 75 in epoch 18, gen_loss = 0.8455018079594562, disc_loss = 0.062443798279242686
Trained batch 76 in epoch 18, gen_loss = 0.8453056750359473, disc_loss = 0.06174001150292816
Trained batch 77 in epoch 18, gen_loss = 0.8441558304505471, disc_loss = 0.06138663628520683
Trained batch 78 in epoch 18, gen_loss = 0.8441668333886545, disc_loss = 0.061445822391093155
Trained batch 79 in epoch 18, gen_loss = 0.8442753709852695, disc_loss = 0.06165778221911751
Trained batch 80 in epoch 18, gen_loss = 0.840208700409642, disc_loss = 0.06476697357325459
Trained batch 81 in epoch 18, gen_loss = 0.8378667053652973, disc_loss = 0.06466866602053548
Trained batch 82 in epoch 18, gen_loss = 0.8399668809879257, disc_loss = 0.06709751172036112
Trained batch 83 in epoch 18, gen_loss = 0.8400704740058809, disc_loss = 0.06654532293101684
Trained batch 84 in epoch 18, gen_loss = 0.8387115134912378, disc_loss = 0.06654283127692692
Trained batch 85 in epoch 18, gen_loss = 0.8371774900791257, disc_loss = 0.06644629400635008
Trained batch 86 in epoch 18, gen_loss = 0.8379483325728054, disc_loss = 0.06607162078371508
Trained batch 87 in epoch 18, gen_loss = 0.8384251127188856, disc_loss = 0.06618027913447638
Trained batch 88 in epoch 18, gen_loss = 0.8373633335145672, disc_loss = 0.06620317722116126
Trained batch 89 in epoch 18, gen_loss = 0.8394039968649546, disc_loss = 0.0655667345919129
Trained batch 90 in epoch 18, gen_loss = 0.8407877808088785, disc_loss = 0.06587607212426079
Trained batch 91 in epoch 18, gen_loss = 0.8394578222347342, disc_loss = 0.06537869059905896
Trained batch 92 in epoch 18, gen_loss = 0.8397848920155597, disc_loss = 0.06490056674867388
Trained batch 93 in epoch 18, gen_loss = 0.8377740148534166, disc_loss = 0.06498335033873136
Trained batch 94 in epoch 18, gen_loss = 0.8396423571988156, disc_loss = 0.06447034646315794
Trained batch 95 in epoch 18, gen_loss = 0.8410592420647541, disc_loss = 0.06436315089134344
Trained batch 96 in epoch 18, gen_loss = 0.843302021936043, disc_loss = 0.06428968064851828
Trained batch 97 in epoch 18, gen_loss = 0.8395369439100733, disc_loss = 0.06663114033468372
Trained batch 98 in epoch 18, gen_loss = 0.8389632253333775, disc_loss = 0.06615659778448518
Trained batch 99 in epoch 18, gen_loss = 0.8418886837363243, disc_loss = 0.0662991403369233
Trained batch 100 in epoch 18, gen_loss = 0.8431247699968886, disc_loss = 0.06585100855180386
Trained batch 101 in epoch 18, gen_loss = 0.8426151757731157, disc_loss = 0.06571966586360599
Trained batch 102 in epoch 18, gen_loss = 0.8426141637621574, disc_loss = 0.06543504947217778
Trained batch 103 in epoch 18, gen_loss = 0.8409290350973606, disc_loss = 0.065265276554363
Trained batch 104 in epoch 18, gen_loss = 0.8434843826861609, disc_loss = 0.06507258870683255
Trained batch 105 in epoch 18, gen_loss = 0.843229168147411, disc_loss = 0.06484360568980985
Trained batch 106 in epoch 18, gen_loss = 0.8443831013184842, disc_loss = 0.06437407825229184
Trained batch 107 in epoch 18, gen_loss = 0.8439779256780943, disc_loss = 0.06398582532225798
Trained batch 108 in epoch 18, gen_loss = 0.841694076947116, disc_loss = 0.06478632881878577
Trained batch 109 in epoch 18, gen_loss = 0.8437434161251242, disc_loss = 0.06466813484968786
Trained batch 110 in epoch 18, gen_loss = 0.8465848524828214, disc_loss = 0.06441016332036606
Trained batch 111 in epoch 18, gen_loss = 0.8463904226997069, disc_loss = 0.06403488670392628
Trained batch 112 in epoch 18, gen_loss = 0.8478581259208443, disc_loss = 0.06369312199459007
Trained batch 113 in epoch 18, gen_loss = 0.8462429551178949, disc_loss = 0.0638757784597641
Trained batch 114 in epoch 18, gen_loss = 0.8468915237032849, disc_loss = 0.06368262767386826
Trained batch 115 in epoch 18, gen_loss = 0.849871261623399, disc_loss = 0.06462870756212365
Trained batch 116 in epoch 18, gen_loss = 0.849698136250178, disc_loss = 0.06461505247598402
Trained batch 117 in epoch 18, gen_loss = 0.8476151639627199, disc_loss = 0.06497365387424953
Trained batch 118 in epoch 18, gen_loss = 0.8490738205048216, disc_loss = 0.06457129771578587
Trained batch 119 in epoch 18, gen_loss = 0.8485692235330741, disc_loss = 0.06443145566542323
Trained batch 120 in epoch 18, gen_loss = 0.8493602820171797, disc_loss = 0.06409924617037177
Trained batch 121 in epoch 18, gen_loss = 0.8480674416803923, disc_loss = 0.06427567859455088
Trained batch 122 in epoch 18, gen_loss = 0.8500706759410176, disc_loss = 0.06395215513487536
Trained batch 123 in epoch 18, gen_loss = 0.8523959293961525, disc_loss = 0.06364008204095185
Trained batch 124 in epoch 18, gen_loss = 0.850334706068039, disc_loss = 0.06363396921381355
Trained batch 125 in epoch 18, gen_loss = 0.8509416733942334, disc_loss = 0.06323814847772675
Trained batch 126 in epoch 18, gen_loss = 0.8522378555902346, disc_loss = 0.06295616210870973
Trained batch 127 in epoch 18, gen_loss = 0.8522566214669496, disc_loss = 0.06261227759023313
Trained batch 128 in epoch 18, gen_loss = 0.8530359247396159, disc_loss = 0.06222239173154614
Trained batch 129 in epoch 18, gen_loss = 0.8512683398448504, disc_loss = 0.0625431179606284
Trained batch 130 in epoch 18, gen_loss = 0.8531488978680764, disc_loss = 0.0635498741264846
Trained batch 131 in epoch 18, gen_loss = 0.8546111906568209, disc_loss = 0.06337693513187607
Trained batch 132 in epoch 18, gen_loss = 0.8535526585310025, disc_loss = 0.06336468569164101
Trained batch 133 in epoch 18, gen_loss = 0.8540159924261606, disc_loss = 0.06303266729506206
Trained batch 134 in epoch 18, gen_loss = 0.8523681859175364, disc_loss = 0.06311263943229009
Trained batch 135 in epoch 18, gen_loss = 0.8534241702188464, disc_loss = 0.06312657984809074
Trained batch 136 in epoch 18, gen_loss = 0.8548361591614075, disc_loss = 0.06275176378238918
Trained batch 137 in epoch 18, gen_loss = 0.8532005714765494, disc_loss = 0.06269308559232108
Trained batch 138 in epoch 18, gen_loss = 0.8535153657841168, disc_loss = 0.06274935449373058
Trained batch 139 in epoch 18, gen_loss = 0.8534199461340904, disc_loss = 0.06247012443907027
Trained batch 140 in epoch 18, gen_loss = 0.8513717995890488, disc_loss = 0.0631784812468005
Trained batch 141 in epoch 18, gen_loss = 0.8527315970457775, disc_loss = 0.06309398362399932
Trained batch 142 in epoch 18, gen_loss = 0.8530333890364721, disc_loss = 0.06278552451346825
Trained batch 143 in epoch 18, gen_loss = 0.8543492412815491, disc_loss = 0.062446131199572444
Trained batch 144 in epoch 18, gen_loss = 0.8527384484636372, disc_loss = 0.06242433437949111
Trained batch 145 in epoch 18, gen_loss = 0.8525994997726728, disc_loss = 0.06217198175607785
Trained batch 146 in epoch 18, gen_loss = 0.8539333495558524, disc_loss = 0.06187305770193537
Trained batch 147 in epoch 18, gen_loss = 0.8544257482564127, disc_loss = 0.06162781422844509
Trained batch 148 in epoch 18, gen_loss = 0.8535095355254692, disc_loss = 0.06158276208232613
Trained batch 149 in epoch 18, gen_loss = 0.8554264416297277, disc_loss = 0.06137506344355643
Trained batch 150 in epoch 18, gen_loss = 0.8546996864656738, disc_loss = 0.06144822259057338
Trained batch 151 in epoch 18, gen_loss = 0.8551781834348252, disc_loss = 0.0611932849554394
Trained batch 152 in epoch 18, gen_loss = 0.8548009237822365, disc_loss = 0.06095340106258887
Trained batch 153 in epoch 18, gen_loss = 0.8543326558617802, disc_loss = 0.062316053277849184
Trained batch 154 in epoch 18, gen_loss = 0.8537525536552553, disc_loss = 0.062019091781469124
Trained batch 155 in epoch 18, gen_loss = 0.8519556543383843, disc_loss = 0.06253530346275045
Trained batch 156 in epoch 18, gen_loss = 0.8524327712833502, disc_loss = 0.06234556370990196
Trained batch 157 in epoch 18, gen_loss = 0.8539161118148249, disc_loss = 0.06236818122465305
Trained batch 158 in epoch 18, gen_loss = 0.852486844520149, disc_loss = 0.06254147293936438
Trained batch 159 in epoch 18, gen_loss = 0.8535492302849889, disc_loss = 0.06233775132277515
Trained batch 160 in epoch 18, gen_loss = 0.8516897779443989, disc_loss = 0.06273713005382729
Trained batch 161 in epoch 18, gen_loss = 0.8538326093076188, disc_loss = 0.06311290840802278
Trained batch 162 in epoch 18, gen_loss = 0.8523074748691606, disc_loss = 0.0633565471850427
Trained batch 163 in epoch 18, gen_loss = 0.8528613686198141, disc_loss = 0.06312929057209503
Trained batch 164 in epoch 18, gen_loss = 0.8529958325805086, disc_loss = 0.06285582500594583
Trained batch 165 in epoch 18, gen_loss = 0.8537858791020979, disc_loss = 0.06285530709975724
Trained batch 166 in epoch 18, gen_loss = 0.8551954568146232, disc_loss = 0.06257584980761487
Trained batch 167 in epoch 18, gen_loss = 0.852849730068729, disc_loss = 0.06312580481781402
Trained batch 168 in epoch 18, gen_loss = 0.8545481816551389, disc_loss = 0.06326529520051279
Trained batch 169 in epoch 18, gen_loss = 0.8538325036273283, disc_loss = 0.0631948919610723
Trained batch 170 in epoch 18, gen_loss = 0.8525330121057075, disc_loss = 0.06342213994915984
Trained batch 171 in epoch 18, gen_loss = 0.8511560607788174, disc_loss = 0.06412393259436845
Trained batch 172 in epoch 18, gen_loss = 0.8518101390386592, disc_loss = 0.06432112368534325
Trained batch 173 in epoch 18, gen_loss = 0.850930858274986, disc_loss = 0.06420171939254064
Trained batch 174 in epoch 18, gen_loss = 0.8495117558751788, disc_loss = 0.06442323839824114
Trained batch 175 in epoch 18, gen_loss = 0.851142646575516, disc_loss = 0.06414734569790942
Trained batch 176 in epoch 18, gen_loss = 0.8517545229297573, disc_loss = 0.06393895797841882
Trained batch 177 in epoch 18, gen_loss = 0.850775371776538, disc_loss = 0.06384522822329754
Trained batch 178 in epoch 18, gen_loss = 0.8498122325822628, disc_loss = 0.0638352009498998
Trained batch 179 in epoch 18, gen_loss = 0.8487800379594167, disc_loss = 0.06365029671902044
Trained batch 180 in epoch 18, gen_loss = 0.8498492649246975, disc_loss = 0.0637434588523983
Trained batch 181 in epoch 18, gen_loss = 0.8505540883148109, disc_loss = 0.06360390975528939
Trained batch 182 in epoch 18, gen_loss = 0.8488781474978546, disc_loss = 0.06378061878825717
Trained batch 183 in epoch 18, gen_loss = 0.8478045547785966, disc_loss = 0.06383490939776454
Trained batch 184 in epoch 18, gen_loss = 0.8472879193924568, disc_loss = 0.06361323046070096
Trained batch 185 in epoch 18, gen_loss = 0.8492090948807296, disc_loss = 0.06371253863808209
Trained batch 186 in epoch 18, gen_loss = 0.849086772630559, disc_loss = 0.06358840570282091
Trained batch 187 in epoch 18, gen_loss = 0.8497536290199199, disc_loss = 0.06350101067615237
Trained batch 188 in epoch 18, gen_loss = 0.8501361021919857, disc_loss = 0.0632377320718237
Trained batch 189 in epoch 18, gen_loss = 0.8507245019862526, disc_loss = 0.06296078307603142
Trained batch 190 in epoch 18, gen_loss = 0.8504633969037321, disc_loss = 0.06272034963144292
Trained batch 191 in epoch 18, gen_loss = 0.8508266368880868, disc_loss = 0.06248043362817649
Trained batch 192 in epoch 18, gen_loss = 0.8522774743910281, disc_loss = 0.06280601852443166
Trained batch 193 in epoch 18, gen_loss = 0.8526980741736815, disc_loss = 0.06253412797730223
Trained batch 194 in epoch 18, gen_loss = 0.8511822523214878, disc_loss = 0.06286837062917841
Trained batch 195 in epoch 18, gen_loss = 0.850625286905133, disc_loss = 0.06287649378171001
Trained batch 196 in epoch 18, gen_loss = 0.850910669050846, disc_loss = 0.0627640435249937
Trained batch 197 in epoch 18, gen_loss = 0.8516393400201894, disc_loss = 0.06252809489531574
Trained batch 198 in epoch 18, gen_loss = 0.8516527402341066, disc_loss = 0.062450650141073684
Trained batch 199 in epoch 18, gen_loss = 0.8522205871343612, disc_loss = 0.062244969371240584
Trained batch 200 in epoch 18, gen_loss = 0.8520269239719828, disc_loss = 0.062161219660748744
Trained batch 201 in epoch 18, gen_loss = 0.8517412909186712, disc_loss = 0.06199006465872252
Trained batch 202 in epoch 18, gen_loss = 0.8508676601748161, disc_loss = 0.06184254725018672
Trained batch 203 in epoch 18, gen_loss = 0.8528138375749775, disc_loss = 0.06167143030667349
Trained batch 204 in epoch 18, gen_loss = 0.8539496136874687, disc_loss = 0.061603467354959834
Trained batch 205 in epoch 18, gen_loss = 0.8533846189096136, disc_loss = 0.06182486087183278
Trained batch 206 in epoch 18, gen_loss = 0.8543369427395328, disc_loss = 0.06173686842222648
Trained batch 207 in epoch 18, gen_loss = 0.8549074258368748, disc_loss = 0.06149449200109722
Trained batch 208 in epoch 18, gen_loss = 0.8548178886682793, disc_loss = 0.06137685485531768
Trained batch 209 in epoch 18, gen_loss = 0.8553940511885143, disc_loss = 0.06113002760823639
Trained batch 210 in epoch 18, gen_loss = 0.8560810625835618, disc_loss = 0.06103190531848237
Trained batch 211 in epoch 18, gen_loss = 0.8563438136622591, disc_loss = 0.06084368220873107
Trained batch 212 in epoch 18, gen_loss = 0.8566924512666156, disc_loss = 0.060939311957152936
Trained batch 213 in epoch 18, gen_loss = 0.8569388005221001, disc_loss = 0.060718910318198746
Trained batch 214 in epoch 18, gen_loss = 0.8577506181805633, disc_loss = 0.060523526355364295
Trained batch 215 in epoch 18, gen_loss = 0.8562653255131509, disc_loss = 0.06110372141012232
Trained batch 216 in epoch 18, gen_loss = 0.8575535372654963, disc_loss = 0.06110157603226293
Trained batch 217 in epoch 18, gen_loss = 0.8576079686300471, disc_loss = 0.061427856276426974
Trained batch 218 in epoch 18, gen_loss = 0.8562691399495895, disc_loss = 0.061718541960823076
Trained batch 219 in epoch 18, gen_loss = 0.855865712870251, disc_loss = 0.06158054337455807
Trained batch 220 in epoch 18, gen_loss = 0.855987541006701, disc_loss = 0.06137572601648275
Trained batch 221 in epoch 18, gen_loss = 0.8559247848686872, disc_loss = 0.061187240657992324
Trained batch 222 in epoch 18, gen_loss = 0.8557805042095783, disc_loss = 0.06102563283978356
Trained batch 223 in epoch 18, gen_loss = 0.8566051349043846, disc_loss = 0.06079998682876716
Trained batch 224 in epoch 18, gen_loss = 0.8574158578448825, disc_loss = 0.06069365088103546
Trained batch 225 in epoch 18, gen_loss = 0.8578984824429571, disc_loss = 0.06049404466994503
Trained batch 226 in epoch 18, gen_loss = 0.8575970060499755, disc_loss = 0.06042901167875804
Trained batch 227 in epoch 18, gen_loss = 0.858230182476211, disc_loss = 0.06023389010959746
Trained batch 228 in epoch 18, gen_loss = 0.8582438639157725, disc_loss = 0.06023202937169562
Trained batch 229 in epoch 18, gen_loss = 0.8590893810210021, disc_loss = 0.060160269197481485
Trained batch 230 in epoch 18, gen_loss = 0.8591299209243808, disc_loss = 0.06041840566886646
Trained batch 231 in epoch 18, gen_loss = 0.8594835554731304, disc_loss = 0.06023587583331391
Trained batch 232 in epoch 18, gen_loss = 0.8583442359011573, disc_loss = 0.06045720414278525
Trained batch 233 in epoch 18, gen_loss = 0.8574121703958919, disc_loss = 0.060503607168077275
Trained batch 234 in epoch 18, gen_loss = 0.8589360249803422, disc_loss = 0.061335681519530554
Trained batch 235 in epoch 18, gen_loss = 0.8596740135196912, disc_loss = 0.061442883541191914
Trained batch 236 in epoch 18, gen_loss = 0.8587193773265629, disc_loss = 0.0617105029189354
Trained batch 237 in epoch 18, gen_loss = 0.858539652674138, disc_loss = 0.06157352898011626
Trained batch 238 in epoch 18, gen_loss = 0.8595850919081077, disc_loss = 0.06144027974433168
Trained batch 239 in epoch 18, gen_loss = 0.8591765803595384, disc_loss = 0.061533067637356
Trained batch 240 in epoch 18, gen_loss = 0.8591299717357049, disc_loss = 0.06135063978391255
Trained batch 241 in epoch 18, gen_loss = 0.8601122619199358, disc_loss = 0.06116331670979761
Trained batch 242 in epoch 18, gen_loss = 0.8605701822802854, disc_loss = 0.06094702904844664
Trained batch 243 in epoch 18, gen_loss = 0.8603717428250391, disc_loss = 0.06092965514131929
Trained batch 244 in epoch 18, gen_loss = 0.8589681014722708, disc_loss = 0.06136996359659397
Trained batch 245 in epoch 18, gen_loss = 0.8589745699390163, disc_loss = 0.06120860743018367
Trained batch 246 in epoch 18, gen_loss = 0.8598829901170152, disc_loss = 0.06104490074031206
Trained batch 247 in epoch 18, gen_loss = 0.860227883583115, disc_loss = 0.060975236222974113
Trained batch 248 in epoch 18, gen_loss = 0.8603148029511234, disc_loss = 0.06080602527405304
Trained batch 249 in epoch 18, gen_loss = 0.8596087634563446, disc_loss = 0.060757015278562906
Trained batch 250 in epoch 18, gen_loss = 0.8596081337130878, disc_loss = 0.06057449809991684
Trained batch 251 in epoch 18, gen_loss = 0.8593037984673939, disc_loss = 0.06070057015740386
Trained batch 252 in epoch 18, gen_loss = 0.8604730386507841, disc_loss = 0.0606328765199089
Trained batch 253 in epoch 18, gen_loss = 0.8596948976591816, disc_loss = 0.060672796204847494
Trained batch 254 in epoch 18, gen_loss = 0.8590370996325624, disc_loss = 0.060669877188389794
Trained batch 255 in epoch 18, gen_loss = 0.8584234481677413, disc_loss = 0.06061463223704777
Trained batch 256 in epoch 18, gen_loss = 0.8595960715401497, disc_loss = 0.06043492491512853
Trained batch 257 in epoch 18, gen_loss = 0.860609020373618, disc_loss = 0.06025206228869772
Trained batch 258 in epoch 18, gen_loss = 0.8619799305573393, disc_loss = 0.060149029190346426
Trained batch 259 in epoch 18, gen_loss = 0.8622890311938066, disc_loss = 0.060034217103384434
Trained batch 260 in epoch 18, gen_loss = 0.8620578457112513, disc_loss = 0.05989764993867598
Trained batch 261 in epoch 18, gen_loss = 0.8610662417557403, disc_loss = 0.06006293221135119
Trained batch 262 in epoch 18, gen_loss = 0.8618654982671992, disc_loss = 0.06019306225886306
Trained batch 263 in epoch 18, gen_loss = 0.8611747509602344, disc_loss = 0.0602485386876982
Trained batch 264 in epoch 18, gen_loss = 0.8598403348113006, disc_loss = 0.060418524303174806
Trained batch 265 in epoch 18, gen_loss = 0.8593962940954625, disc_loss = 0.06047260394859079
Trained batch 266 in epoch 18, gen_loss = 0.8586882879671532, disc_loss = 0.06042658554892359
Trained batch 267 in epoch 18, gen_loss = 0.8592976425121079, disc_loss = 0.06026534293256978
Trained batch 268 in epoch 18, gen_loss = 0.8592195891979458, disc_loss = 0.060151029646493576
Trained batch 269 in epoch 18, gen_loss = 0.8595721655421786, disc_loss = 0.059993088733473865
Trained batch 270 in epoch 18, gen_loss = 0.8590220481267274, disc_loss = 0.05997565294344432
Trained batch 271 in epoch 18, gen_loss = 0.8598224319079343, disc_loss = 0.05983417772051111
Trained batch 272 in epoch 18, gen_loss = 0.8596071159883296, disc_loss = 0.06008694728072255
Trained batch 273 in epoch 18, gen_loss = 0.8590889675338773, disc_loss = 0.0600848277252385
Trained batch 274 in epoch 18, gen_loss = 0.858554268100045, disc_loss = 0.05999382183463736
Trained batch 275 in epoch 18, gen_loss = 0.8601827636577081, disc_loss = 0.05993460695616955
Trained batch 276 in epoch 18, gen_loss = 0.860401910780139, disc_loss = 0.05976992354489567
Trained batch 277 in epoch 18, gen_loss = 0.8608006768518215, disc_loss = 0.0597414271688263
Trained batch 278 in epoch 18, gen_loss = 0.8606835197804222, disc_loss = 0.0597141700977039
Trained batch 279 in epoch 18, gen_loss = 0.860768244947706, disc_loss = 0.05955253900527688
Trained batch 280 in epoch 18, gen_loss = 0.8599274192416371, disc_loss = 0.0596195675442625
Trained batch 281 in epoch 18, gen_loss = 0.8598622565573835, disc_loss = 0.05958509265365911
Trained batch 282 in epoch 18, gen_loss = 0.8598062212812606, disc_loss = 0.05948307022761698
Trained batch 283 in epoch 18, gen_loss = 0.8601039213613725, disc_loss = 0.05948762167868218
Trained batch 284 in epoch 18, gen_loss = 0.8608443124252453, disc_loss = 0.05934667490390048
Trained batch 285 in epoch 18, gen_loss = 0.8602385208323285, disc_loss = 0.059374905704240595
Trained batch 286 in epoch 18, gen_loss = 0.859510760897128, disc_loss = 0.05971732081274278
Trained batch 287 in epoch 18, gen_loss = 0.861228198847837, disc_loss = 0.05969924101858245
Trained batch 288 in epoch 18, gen_loss = 0.8616236417351297, disc_loss = 0.059527637567500034
Trained batch 289 in epoch 18, gen_loss = 0.8622777887459459, disc_loss = 0.059463907966133336
Trained batch 290 in epoch 18, gen_loss = 0.8615606566475019, disc_loss = 0.05952843486833869
Trained batch 291 in epoch 18, gen_loss = 0.861555447113024, disc_loss = 0.05952251949570818
Trained batch 292 in epoch 18, gen_loss = 0.8624327949696433, disc_loss = 0.05938909437551891
Trained batch 293 in epoch 18, gen_loss = 0.8637800717434916, disc_loss = 0.0595885098667904
Trained batch 294 in epoch 18, gen_loss = 0.8633275531106076, disc_loss = 0.05961230771805523
Trained batch 295 in epoch 18, gen_loss = 0.8636568190680968, disc_loss = 0.05962188098409742
Trained batch 296 in epoch 18, gen_loss = 0.8639810115399987, disc_loss = 0.05957953169822743
Trained batch 297 in epoch 18, gen_loss = 0.862951284686991, disc_loss = 0.05972146762428718
Trained batch 298 in epoch 18, gen_loss = 0.8637810443157337, disc_loss = 0.060019335265654485
Trained batch 299 in epoch 18, gen_loss = 0.8643069883187612, disc_loss = 0.06006401270162314
Trained batch 300 in epoch 18, gen_loss = 0.8637136506083796, disc_loss = 0.06010100740066844
Trained batch 301 in epoch 18, gen_loss = 0.8623166318168703, disc_loss = 0.06098017145398486
Trained batch 302 in epoch 18, gen_loss = 0.861942834684951, disc_loss = 0.06097482449279809
Trained batch 303 in epoch 18, gen_loss = 0.8628005100120055, disc_loss = 0.061405849393371396
Trained batch 304 in epoch 18, gen_loss = 0.8625347734474745, disc_loss = 0.06144900348373368
Trained batch 305 in epoch 18, gen_loss = 0.8624473855970731, disc_loss = 0.06134181560528483
Trained batch 306 in epoch 18, gen_loss = 0.8617555585474456, disc_loss = 0.06137769444351136
Trained batch 307 in epoch 18, gen_loss = 0.8631769359692351, disc_loss = 0.06167228264256393
Trained batch 308 in epoch 18, gen_loss = 0.8632773864037783, disc_loss = 0.06153759336955002
Trained batch 309 in epoch 18, gen_loss = 0.8630658183367022, disc_loss = 0.061452918639406565
Trained batch 310 in epoch 18, gen_loss = 0.8625510012030219, disc_loss = 0.06161996343253941
Trained batch 311 in epoch 18, gen_loss = 0.8616261999003398, disc_loss = 0.06176420792680568
Trained batch 312 in epoch 18, gen_loss = 0.8621462413106864, disc_loss = 0.061807438583907706
Trained batch 313 in epoch 18, gen_loss = 0.8631990666791891, disc_loss = 0.06170346086198215
Trained batch 314 in epoch 18, gen_loss = 0.8628223645308661, disc_loss = 0.06164640541971912
Trained batch 315 in epoch 18, gen_loss = 0.8625553479488892, disc_loss = 0.06165560826665097
Trained batch 316 in epoch 18, gen_loss = 0.862254934262026, disc_loss = 0.0616181675089106
Trained batch 317 in epoch 18, gen_loss = 0.8624470176749259, disc_loss = 0.061490460388280405
Trained batch 318 in epoch 18, gen_loss = 0.8626626594500109, disc_loss = 0.06137246516063156
Trained batch 319 in epoch 18, gen_loss = 0.8624129555188119, disc_loss = 0.0613104845295311
Trained batch 320 in epoch 18, gen_loss = 0.8630981028451356, disc_loss = 0.0612925265660376
Trained batch 321 in epoch 18, gen_loss = 0.8625694808567533, disc_loss = 0.06137808732925596
Trained batch 322 in epoch 18, gen_loss = 0.8624311736309123, disc_loss = 0.06132655091520295
Trained batch 323 in epoch 18, gen_loss = 0.8626373306284716, disc_loss = 0.06118336178931511
Trained batch 324 in epoch 18, gen_loss = 0.8625414783221025, disc_loss = 0.06102192502898666
Trained batch 325 in epoch 18, gen_loss = 0.8626286710149671, disc_loss = 0.06086367033450561
Trained batch 326 in epoch 18, gen_loss = 0.8631435141468632, disc_loss = 0.06074780014568558
Trained batch 327 in epoch 18, gen_loss = 0.8625087313717459, disc_loss = 0.06073670587417238
Trained batch 328 in epoch 18, gen_loss = 0.8627333622029487, disc_loss = 0.06063794061728388
Trained batch 329 in epoch 18, gen_loss = 0.8631979742736527, disc_loss = 0.06050865720872852
Trained batch 330 in epoch 18, gen_loss = 0.8623664371016523, disc_loss = 0.06065445520079433
Trained batch 331 in epoch 18, gen_loss = 0.8629872209156852, disc_loss = 0.06097748927934746
Trained batch 332 in epoch 18, gen_loss = 0.8624879317777651, disc_loss = 0.06091758502121489
Trained batch 333 in epoch 18, gen_loss = 0.8618931200154527, disc_loss = 0.06088672866793851
Trained batch 334 in epoch 18, gen_loss = 0.8617985930905413, disc_loss = 0.0607378089758776
Trained batch 335 in epoch 18, gen_loss = 0.8621017900073812, disc_loss = 0.06059415007725225
Trained batch 336 in epoch 18, gen_loss = 0.8623273371765805, disc_loss = 0.060557732807654745
Trained batch 337 in epoch 18, gen_loss = 0.862522305027973, disc_loss = 0.06044152562131763
Trained batch 338 in epoch 18, gen_loss = 0.8615360466604036, disc_loss = 0.06042704295097771
Trained batch 339 in epoch 18, gen_loss = 0.8624970705193632, disc_loss = 0.060307787453262686
Trained batch 340 in epoch 18, gen_loss = 0.8627856516243775, disc_loss = 0.060154716471958455
Trained batch 341 in epoch 18, gen_loss = 0.8632884246041204, disc_loss = 0.060034956239784755
Trained batch 342 in epoch 18, gen_loss = 0.8626683572464712, disc_loss = 0.06004318603757041
Trained batch 343 in epoch 18, gen_loss = 0.862684729227493, disc_loss = 0.05994281630968502
Trained batch 344 in epoch 18, gen_loss = 0.8626924014609793, disc_loss = 0.059826149420299825
Trained batch 345 in epoch 18, gen_loss = 0.8638962621805985, disc_loss = 0.059820076715836376
Trained batch 346 in epoch 18, gen_loss = 0.8640882974914583, disc_loss = 0.05966958213967918
Trained batch 347 in epoch 18, gen_loss = 0.8644209708804371, disc_loss = 0.059548907649660504
Trained batch 348 in epoch 18, gen_loss = 0.863638252532243, disc_loss = 0.05964545814192355
Trained batch 349 in epoch 18, gen_loss = 0.863733407514436, disc_loss = 0.05973513331131211
Trained batch 350 in epoch 18, gen_loss = 0.86457816055018, disc_loss = 0.059635579000967436
Trained batch 351 in epoch 18, gen_loss = 0.8644726131619378, disc_loss = 0.05953189368566117
Trained batch 352 in epoch 18, gen_loss = 0.8636582391626774, disc_loss = 0.059742075123325536
Trained batch 353 in epoch 18, gen_loss = 0.8637787835241038, disc_loss = 0.05965300809755122
Trained batch 354 in epoch 18, gen_loss = 0.8643001473285783, disc_loss = 0.05956344010938011
Trained batch 355 in epoch 18, gen_loss = 0.8646954077850567, disc_loss = 0.05943114219332805
Trained batch 356 in epoch 18, gen_loss = 0.8647723898333328, disc_loss = 0.05981389870241034
Trained batch 357 in epoch 18, gen_loss = 0.8643377072817786, disc_loss = 0.05979892350186974
Trained batch 358 in epoch 18, gen_loss = 0.8638047166687532, disc_loss = 0.05999130634124025
Trained batch 359 in epoch 18, gen_loss = 0.8641721643507481, disc_loss = 0.060145085520990606
Trained batch 360 in epoch 18, gen_loss = 0.8634999071627112, disc_loss = 0.06033633699785103
Trained batch 361 in epoch 18, gen_loss = 0.8641005868905157, disc_loss = 0.06027319553843313
Trained batch 362 in epoch 18, gen_loss = 0.8635811520837884, disc_loss = 0.060305956123812385
Trained batch 363 in epoch 18, gen_loss = 0.8643662429281643, disc_loss = 0.0604587582305872
Trained batch 364 in epoch 18, gen_loss = 0.8640353910727043, disc_loss = 0.060365625127690704
Trained batch 365 in epoch 18, gen_loss = 0.8639588687426406, disc_loss = 0.060279500893383325
Trained batch 366 in epoch 18, gen_loss = 0.8643847095706483, disc_loss = 0.06021341329633337
Trained batch 367 in epoch 18, gen_loss = 0.8642703431617954, disc_loss = 0.06009724855539389
Trained batch 368 in epoch 18, gen_loss = 0.8636394512201067, disc_loss = 0.060191484707026545
Trained batch 369 in epoch 18, gen_loss = 0.8647422370878426, disc_loss = 0.060349825687857496
Trained batch 370 in epoch 18, gen_loss = 0.8654972638563326, disc_loss = 0.06022810264593467
Trained batch 371 in epoch 18, gen_loss = 0.8652965398405188, disc_loss = 0.06016554502565013
Trained batch 372 in epoch 18, gen_loss = 0.865032517798145, disc_loss = 0.060114674913090214
Trained batch 373 in epoch 18, gen_loss = 0.8648664654098093, disc_loss = 0.060107462629825276
Trained batch 374 in epoch 18, gen_loss = 0.8664733332792918, disc_loss = 0.060493221207211414
Trained batch 375 in epoch 18, gen_loss = 0.8662094815455853, disc_loss = 0.06042997910953226
Trained batch 376 in epoch 18, gen_loss = 0.8653442948977574, disc_loss = 0.06079248450968207
Trained batch 377 in epoch 18, gen_loss = 0.8653483151916473, disc_loss = 0.060716057475902654
Trained batch 378 in epoch 18, gen_loss = 0.8663424726054663, disc_loss = 0.06091195393456908
Trained batch 379 in epoch 18, gen_loss = 0.8661544941757855, disc_loss = 0.060881946219964636
Trained batch 380 in epoch 18, gen_loss = 0.8659910227213632, disc_loss = 0.06096847535641448
Trained batch 381 in epoch 18, gen_loss = 0.8663934922499182, disc_loss = 0.060921860267578856
Trained batch 382 in epoch 18, gen_loss = 0.8661939634822368, disc_loss = 0.06088382840599116
Trained batch 383 in epoch 18, gen_loss = 0.8666645016055554, disc_loss = 0.0607771082080338
Trained batch 384 in epoch 18, gen_loss = 0.8665222204350805, disc_loss = 0.06075847724984799
Trained batch 385 in epoch 18, gen_loss = 0.8667376086965126, disc_loss = 0.06065949620413618
Trained batch 386 in epoch 18, gen_loss = 0.8673683998658676, disc_loss = 0.06055848725809107
Trained batch 387 in epoch 18, gen_loss = 0.8668393137067864, disc_loss = 0.06050984991459925
Trained batch 388 in epoch 18, gen_loss = 0.866467924917878, disc_loss = 0.06050368643468749
Trained batch 389 in epoch 18, gen_loss = 0.8673877796301475, disc_loss = 0.06046177027388834
Trained batch 390 in epoch 18, gen_loss = 0.86779955166685, disc_loss = 0.06068667648312495
Trained batch 391 in epoch 18, gen_loss = 0.8668907391933762, disc_loss = 0.06103503986200014
Trained batch 392 in epoch 18, gen_loss = 0.8669122986059455, disc_loss = 0.06093761381638679
Trained batch 393 in epoch 18, gen_loss = 0.866483143062761, disc_loss = 0.06100957995625733
Trained batch 394 in epoch 18, gen_loss = 0.8661573795578148, disc_loss = 0.0609986881843379
Trained batch 395 in epoch 18, gen_loss = 0.8659430749037049, disc_loss = 0.06095834318995288
Trained batch 396 in epoch 18, gen_loss = 0.8661689502316098, disc_loss = 0.06083230487415825
Trained batch 397 in epoch 18, gen_loss = 0.8658442502495033, disc_loss = 0.060821087617923195
Trained batch 398 in epoch 18, gen_loss = 0.8654392265287557, disc_loss = 0.06081345323403191
Trained batch 399 in epoch 18, gen_loss = 0.8658833948522806, disc_loss = 0.060900596872670576
Trained batch 400 in epoch 18, gen_loss = 0.8666927116618787, disc_loss = 0.06083655320084712
Trained batch 401 in epoch 18, gen_loss = 0.8660461409619792, disc_loss = 0.060982438961544365
Trained batch 402 in epoch 18, gen_loss = 0.8652448063304939, disc_loss = 0.06103517956195154
Trained batch 403 in epoch 18, gen_loss = 0.8660123053901266, disc_loss = 0.06118038193308887
Trained batch 404 in epoch 18, gen_loss = 0.8660382977974268, disc_loss = 0.0610938173925711
Trained batch 405 in epoch 18, gen_loss = 0.8664378985542381, disc_loss = 0.061034953284760926
Trained batch 406 in epoch 18, gen_loss = 0.8659996869962397, disc_loss = 0.06098534434882773
Trained batch 407 in epoch 18, gen_loss = 0.8658875836899468, disc_loss = 0.06093654078408601
Trained batch 408 in epoch 18, gen_loss = 0.8661760120199479, disc_loss = 0.06082850825246469
Trained batch 409 in epoch 18, gen_loss = 0.8664222031831741, disc_loss = 0.06095904930858169
Trained batch 410 in epoch 18, gen_loss = 0.8658068414297128, disc_loss = 0.061214640313972446
Trained batch 411 in epoch 18, gen_loss = 0.8655747287337062, disc_loss = 0.061138637218108964
Trained batch 412 in epoch 18, gen_loss = 0.8659684842060034, disc_loss = 0.06119602913100083
Trained batch 413 in epoch 18, gen_loss = 0.8665901548476611, disc_loss = 0.061193604237098555
Trained batch 414 in epoch 18, gen_loss = 0.8660359015665858, disc_loss = 0.0613377966244806
Trained batch 415 in epoch 18, gen_loss = 0.8663731358515528, disc_loss = 0.06126226538841505
Trained batch 416 in epoch 18, gen_loss = 0.8660198184940741, disc_loss = 0.06125905885019427
Trained batch 417 in epoch 18, gen_loss = 0.8662619132316854, disc_loss = 0.06125902072927562
Trained batch 418 in epoch 18, gen_loss = 0.8665646568545293, disc_loss = 0.06116936654008054
Trained batch 419 in epoch 18, gen_loss = 0.8658173192824636, disc_loss = 0.06119240484577382
Trained batch 420 in epoch 18, gen_loss = 0.8661705547868498, disc_loss = 0.061119342885354
Trained batch 421 in epoch 18, gen_loss = 0.8660830293927713, disc_loss = 0.06106200170155915
Trained batch 422 in epoch 18, gen_loss = 0.8659130496195304, disc_loss = 0.06099852690931154
Trained batch 423 in epoch 18, gen_loss = 0.86614861697802, disc_loss = 0.06087601403727741
Trained batch 424 in epoch 18, gen_loss = 0.8658446452898138, disc_loss = 0.060855683518902345
Trained batch 425 in epoch 18, gen_loss = 0.8656567330231689, disc_loss = 0.06080938927378908
Trained batch 426 in epoch 18, gen_loss = 0.865393054080512, disc_loss = 0.060740317661856114
Trained batch 427 in epoch 18, gen_loss = 0.8653668948562345, disc_loss = 0.06063873094188867
Trained batch 428 in epoch 18, gen_loss = 0.865876348215939, disc_loss = 0.060623317389230144
Trained batch 429 in epoch 18, gen_loss = 0.8670355830774751, disc_loss = 0.060545328442483795
Trained batch 430 in epoch 18, gen_loss = 0.866364569025084, disc_loss = 0.06074134951128933
Trained batch 431 in epoch 18, gen_loss = 0.8662295307688139, disc_loss = 0.06067629810530451
Trained batch 432 in epoch 18, gen_loss = 0.865545217008018, disc_loss = 0.0607692556462184
Trained batch 433 in epoch 18, gen_loss = 0.8660621594311455, disc_loss = 0.060810165180425556
Trained batch 434 in epoch 18, gen_loss = 0.8653658742877258, disc_loss = 0.0610861982604296
Trained batch 435 in epoch 18, gen_loss = 0.8649856470730326, disc_loss = 0.06112126054331968
Trained batch 436 in epoch 18, gen_loss = 0.8646813286660192, disc_loss = 0.061164723740127665
Trained batch 437 in epoch 18, gen_loss = 0.8653037049318557, disc_loss = 0.061132897917376874
Trained batch 438 in epoch 18, gen_loss = 0.864752438521874, disc_loss = 0.06113675908887746
Trained batch 439 in epoch 18, gen_loss = 0.8650819028643044, disc_loss = 0.06102229825072837
Trained batch 440 in epoch 18, gen_loss = 0.8648360861537138, disc_loss = 0.06096266145140034
Trained batch 441 in epoch 18, gen_loss = 0.8649071710546632, disc_loss = 0.06103219908695853
Trained batch 442 in epoch 18, gen_loss = 0.8647886931088923, disc_loss = 0.06099162196202317
Trained batch 443 in epoch 18, gen_loss = 0.8647669711494231, disc_loss = 0.06089663511532283
Trained batch 444 in epoch 18, gen_loss = 0.8650809386473024, disc_loss = 0.06094236820203702
Trained batch 445 in epoch 18, gen_loss = 0.8651069602490541, disc_loss = 0.060849823781201455
Trained batch 446 in epoch 18, gen_loss = 0.8646930064797668, disc_loss = 0.06091053791081645
Trained batch 447 in epoch 18, gen_loss = 0.8644848876366658, disc_loss = 0.06097966127085134
Trained batch 448 in epoch 18, gen_loss = 0.8645755098365198, disc_loss = 0.06087929095952608
Trained batch 449 in epoch 18, gen_loss = 0.8650719640652339, disc_loss = 0.06091550268336303
Trained batch 450 in epoch 18, gen_loss = 0.8651067161903677, disc_loss = 0.06080097172248225
Trained batch 451 in epoch 18, gen_loss = 0.8646529510089781, disc_loss = 0.060850129000207955
Trained batch 452 in epoch 18, gen_loss = 0.864218666919283, disc_loss = 0.06083404872192288
Trained batch 453 in epoch 18, gen_loss = 0.865228918483604, disc_loss = 0.061301550929463315
Trained batch 454 in epoch 18, gen_loss = 0.8649475281710153, disc_loss = 0.06138671105113495
Trained batch 455 in epoch 18, gen_loss = 0.8645996957886637, disc_loss = 0.061391960656915774
Trained batch 456 in epoch 18, gen_loss = 0.8650956721874504, disc_loss = 0.06135575716940103
Trained batch 457 in epoch 18, gen_loss = 0.8646568816692027, disc_loss = 0.06139938644637805
Trained batch 458 in epoch 18, gen_loss = 0.8645793024880694, disc_loss = 0.06148346595380918
Trained batch 459 in epoch 18, gen_loss = 0.8643773124917694, disc_loss = 0.061527266004122796
Trained batch 460 in epoch 18, gen_loss = 0.863729135785858, disc_loss = 0.06170060849948554
Trained batch 461 in epoch 18, gen_loss = 0.8640706262418202, disc_loss = 0.06178740523977294
Trained batch 462 in epoch 18, gen_loss = 0.8637650038073439, disc_loss = 0.061756612969357236
Trained batch 463 in epoch 18, gen_loss = 0.8639622400675354, disc_loss = 0.0616495425337203
Trained batch 464 in epoch 18, gen_loss = 0.8643623278346113, disc_loss = 0.06155021018699132
Trained batch 465 in epoch 18, gen_loss = 0.864393771526128, disc_loss = 0.0614875024654243
Trained batch 466 in epoch 18, gen_loss = 0.8647905111440499, disc_loss = 0.06142765892533948
Trained batch 467 in epoch 18, gen_loss = 0.8650287213361162, disc_loss = 0.061650322538275175
Trained batch 468 in epoch 18, gen_loss = 0.8647158188479287, disc_loss = 0.06172607802073044
Trained batch 469 in epoch 18, gen_loss = 0.8641097442266789, disc_loss = 0.061885661943914726
Trained batch 470 in epoch 18, gen_loss = 0.8639640788490353, disc_loss = 0.061848495000352464
Trained batch 471 in epoch 18, gen_loss = 0.8644068979231988, disc_loss = 0.06250942873638281
Trained batch 472 in epoch 18, gen_loss = 0.8641181067104824, disc_loss = 0.06260526167173687
Trained batch 473 in epoch 18, gen_loss = 0.8640360277036071, disc_loss = 0.06254124625208729
Trained batch 474 in epoch 18, gen_loss = 0.8642551086450878, disc_loss = 0.06264695474485818
Trained batch 475 in epoch 18, gen_loss = 0.8650844781463888, disc_loss = 0.06257940577088754
Trained batch 476 in epoch 18, gen_loss = 0.8650265595323134, disc_loss = 0.06252127281630283
Trained batch 477 in epoch 18, gen_loss = 0.8645348220315439, disc_loss = 0.06257630175731639
Trained batch 478 in epoch 18, gen_loss = 0.8644067771375055, disc_loss = 0.06251395021182231
Trained batch 479 in epoch 18, gen_loss = 0.8650019867345691, disc_loss = 0.06260031617227166
Trained batch 480 in epoch 18, gen_loss = 0.8648294417996912, disc_loss = 0.06259513525834419
Trained batch 481 in epoch 18, gen_loss = 0.8642927936869538, disc_loss = 0.06266825757746844
Trained batch 482 in epoch 18, gen_loss = 0.8642944959503277, disc_loss = 0.06258714719199215
Trained batch 483 in epoch 18, gen_loss = 0.8643533405809363, disc_loss = 0.062493051816940245
Trained batch 484 in epoch 18, gen_loss = 0.864700293848195, disc_loss = 0.062483768870804424
Trained batch 485 in epoch 18, gen_loss = 0.8646084607996568, disc_loss = 0.06254619197371902
Trained batch 486 in epoch 18, gen_loss = 0.8641536907126527, disc_loss = 0.06258636956185377
Trained batch 487 in epoch 18, gen_loss = 0.8637439366124693, disc_loss = 0.06258116939513501
Trained batch 488 in epoch 18, gen_loss = 0.863336542206064, disc_loss = 0.06265008532497385
Trained batch 489 in epoch 18, gen_loss = 0.8630429339043948, disc_loss = 0.06268783054238528
Trained batch 490 in epoch 18, gen_loss = 0.8634040742323501, disc_loss = 0.0628005676872482
Trained batch 491 in epoch 18, gen_loss = 0.8629032679326166, disc_loss = 0.06291432228087016
Trained batch 492 in epoch 18, gen_loss = 0.8626225164526616, disc_loss = 0.06288175589289766
Trained batch 493 in epoch 18, gen_loss = 0.8620633857573575, disc_loss = 0.0629758225435293
Trained batch 494 in epoch 18, gen_loss = 0.862879201197865, disc_loss = 0.06294552350341522
Trained batch 495 in epoch 18, gen_loss = 0.8627157805547598, disc_loss = 0.06288227688186922
Trained batch 496 in epoch 18, gen_loss = 0.8628638422105394, disc_loss = 0.06304530787302305
Trained batch 497 in epoch 18, gen_loss = 0.8631937949652653, disc_loss = 0.06302409114065509
Trained batch 498 in epoch 18, gen_loss = 0.8625390849156466, disc_loss = 0.06332291140760443
Trained batch 499 in epoch 18, gen_loss = 0.8624916077256203, disc_loss = 0.06325119526591153
Trained batch 500 in epoch 18, gen_loss = 0.8624956394265035, disc_loss = 0.06317984736515228
Trained batch 501 in epoch 18, gen_loss = 0.8623246790997061, disc_loss = 0.06313918927124149
Trained batch 502 in epoch 18, gen_loss = 0.8623366377818181, disc_loss = 0.06303319258793122
Trained batch 503 in epoch 18, gen_loss = 0.862100558444148, disc_loss = 0.06302589447965609
Trained batch 504 in epoch 18, gen_loss = 0.8618042575840903, disc_loss = 0.06295127125161856
Trained batch 505 in epoch 18, gen_loss = 0.8625633679477593, disc_loss = 0.06304635072270548
Trained batch 506 in epoch 18, gen_loss = 0.8621063677399351, disc_loss = 0.0630817972941056
Trained batch 507 in epoch 18, gen_loss = 0.8621963690233043, disc_loss = 0.06307853917558275
Trained batch 508 in epoch 18, gen_loss = 0.8621425055450447, disc_loss = 0.06300538520407378
Trained batch 509 in epoch 18, gen_loss = 0.8619625978025736, disc_loss = 0.06293578584422814
Trained batch 510 in epoch 18, gen_loss = 0.8622999072891392, disc_loss = 0.06287031620102998
Trained batch 511 in epoch 18, gen_loss = 0.8621216470492072, disc_loss = 0.06280131174662529
Trained batch 512 in epoch 18, gen_loss = 0.8619788373306713, disc_loss = 0.06276392665206951
Trained batch 513 in epoch 18, gen_loss = 0.8623211128122612, disc_loss = 0.06288930856448811
Trained batch 514 in epoch 18, gen_loss = 0.8616660357100292, disc_loss = 0.06299224346966564
Trained batch 515 in epoch 18, gen_loss = 0.8613866143101869, disc_loss = 0.06301681296051617
Trained batch 516 in epoch 18, gen_loss = 0.8618567691434975, disc_loss = 0.0630037861397018
Trained batch 517 in epoch 18, gen_loss = 0.8617861309451946, disc_loss = 0.06292487371400085
Trained batch 518 in epoch 18, gen_loss = 0.8624477282539728, disc_loss = 0.06294317447054622
Trained batch 519 in epoch 18, gen_loss = 0.8619663032774741, disc_loss = 0.06289669976372701
Trained batch 520 in epoch 18, gen_loss = 0.8618095308370645, disc_loss = 0.06288697736895502
Trained batch 521 in epoch 18, gen_loss = 0.8613188639568643, disc_loss = 0.06288191445360952
Trained batch 522 in epoch 18, gen_loss = 0.8614534223398789, disc_loss = 0.06287522088063179
Trained batch 523 in epoch 18, gen_loss = 0.8614440626884234, disc_loss = 0.06280894844192045
Trained batch 524 in epoch 18, gen_loss = 0.8611710428623927, disc_loss = 0.06280647953440036
Trained batch 525 in epoch 18, gen_loss = 0.861695692396436, disc_loss = 0.06273860300664467
Trained batch 526 in epoch 18, gen_loss = 0.8622126057319894, disc_loss = 0.06266342237524589
Trained batch 527 in epoch 18, gen_loss = 0.8619651203467087, disc_loss = 0.06261590579401166
Trained batch 528 in epoch 18, gen_loss = 0.8619759531800824, disc_loss = 0.06253944248725116
Trained batch 529 in epoch 18, gen_loss = 0.861834339881843, disc_loss = 0.06245224021884771
Trained batch 530 in epoch 18, gen_loss = 0.8622018070207478, disc_loss = 0.06240915719738928
Trained batch 531 in epoch 18, gen_loss = 0.862069222431882, disc_loss = 0.06233738693041041
Trained batch 532 in epoch 18, gen_loss = 0.8615827179648415, disc_loss = 0.06237148603697012
Trained batch 533 in epoch 18, gen_loss = 0.8614562992634398, disc_loss = 0.06230698738766883
Trained batch 534 in epoch 18, gen_loss = 0.861713049066401, disc_loss = 0.0622213599498375
Trained batch 535 in epoch 18, gen_loss = 0.8619832082359649, disc_loss = 0.062129850774732376
Trained batch 536 in epoch 18, gen_loss = 0.861817957469205, disc_loss = 0.062127380922360406
Trained batch 537 in epoch 18, gen_loss = 0.8620459335998089, disc_loss = 0.06203643964572384
Trained batch 538 in epoch 18, gen_loss = 0.8621919746191028, disc_loss = 0.061977801717479124
Trained batch 539 in epoch 18, gen_loss = 0.8627745099089764, disc_loss = 0.061979340790357024
Trained batch 540 in epoch 18, gen_loss = 0.862531204816374, disc_loss = 0.06197963466406447
Trained batch 541 in epoch 18, gen_loss = 0.8619961508195778, disc_loss = 0.06208323125170743
Trained batch 542 in epoch 18, gen_loss = 0.8627218381805315, disc_loss = 0.06206124586106362
Trained batch 543 in epoch 18, gen_loss = 0.8629667206174311, disc_loss = 0.06204113505373243
Trained batch 544 in epoch 18, gen_loss = 0.8630807856354145, disc_loss = 0.06201232390888377
Trained batch 545 in epoch 18, gen_loss = 0.8628642889278713, disc_loss = 0.062015698391145894
Trained batch 546 in epoch 18, gen_loss = 0.8631431950184719, disc_loss = 0.061922080676076456
Trained batch 547 in epoch 18, gen_loss = 0.8628690922020996, disc_loss = 0.06186535666326238
Trained batch 548 in epoch 18, gen_loss = 0.8633083859102322, disc_loss = 0.061782956164913805
Trained batch 549 in epoch 18, gen_loss = 0.8631996666843241, disc_loss = 0.06173856528052552
Trained batch 550 in epoch 18, gen_loss = 0.8630571326954178, disc_loss = 0.06170312421457223
Trained batch 551 in epoch 18, gen_loss = 0.8632365704338619, disc_loss = 0.06178277444205773
Trained batch 552 in epoch 18, gen_loss = 0.8633023468646175, disc_loss = 0.06189436439313601
Trained batch 553 in epoch 18, gen_loss = 0.8631855047674386, disc_loss = 0.06191364186984026
Trained batch 554 in epoch 18, gen_loss = 0.8633744109321285, disc_loss = 0.06193203775145047
Trained batch 555 in epoch 18, gen_loss = 0.8629620873349176, disc_loss = 0.062008904541923045
Trained batch 556 in epoch 18, gen_loss = 0.862759500206908, disc_loss = 0.06198650540422842
Trained batch 557 in epoch 18, gen_loss = 0.862484181813869, disc_loss = 0.062033628591746895
Trained batch 558 in epoch 18, gen_loss = 0.8622836802747894, disc_loss = 0.06199235531829684
Trained batch 559 in epoch 18, gen_loss = 0.8632103745958635, disc_loss = 0.06205587790297743
Trained batch 560 in epoch 18, gen_loss = 0.8636392793234657, disc_loss = 0.061988908227254204
Trained batch 561 in epoch 18, gen_loss = 0.8629682998958431, disc_loss = 0.06214620543600746
Trained batch 562 in epoch 18, gen_loss = 0.8628605905371068, disc_loss = 0.062359520395453456
Trained batch 563 in epoch 18, gen_loss = 0.862599881458367, disc_loss = 0.062344722893148505
Trained batch 564 in epoch 18, gen_loss = 0.8626082690943659, disc_loss = 0.062286028200842905
Trained batch 565 in epoch 18, gen_loss = 0.8626359285714348, disc_loss = 0.06222633884597714
Trained batch 566 in epoch 18, gen_loss = 0.8627990026427745, disc_loss = 0.06217662231976945
Trained batch 567 in epoch 18, gen_loss = 0.8626638550678609, disc_loss = 0.06209931939817362
Trained batch 568 in epoch 18, gen_loss = 0.862327633978822, disc_loss = 0.06207929888203321
Trained batch 569 in epoch 18, gen_loss = 0.8618220058972376, disc_loss = 0.06210710578924862
Trained batch 570 in epoch 18, gen_loss = 0.8624228572574054, disc_loss = 0.06242579114810937
Trained batch 571 in epoch 18, gen_loss = 0.8622969759406743, disc_loss = 0.06237097268263073
Trained batch 572 in epoch 18, gen_loss = 0.8620688311404583, disc_loss = 0.062406949062602524
Trained batch 573 in epoch 18, gen_loss = 0.8622776089748855, disc_loss = 0.06243729918549415
Trained batch 574 in epoch 18, gen_loss = 0.86224408051242, disc_loss = 0.062411798446884624
Trained batch 575 in epoch 18, gen_loss = 0.8622286009809209, disc_loss = 0.062335649603078816
Trained batch 576 in epoch 18, gen_loss = 0.8618213800355095, disc_loss = 0.06243271347816446
Trained batch 577 in epoch 18, gen_loss = 0.8619752670138765, disc_loss = 0.062342040119112624
Trained batch 578 in epoch 18, gen_loss = 0.8625245701154897, disc_loss = 0.06236908782437598
Trained batch 579 in epoch 18, gen_loss = 0.862775995145584, disc_loss = 0.06238111116971563
Trained batch 580 in epoch 18, gen_loss = 0.8624190692749778, disc_loss = 0.06238192759162511
Trained batch 581 in epoch 18, gen_loss = 0.8626030494564587, disc_loss = 0.06229359613446666
Trained batch 582 in epoch 18, gen_loss = 0.8624178710462299, disc_loss = 0.06226639134336525
Trained batch 583 in epoch 18, gen_loss = 0.8625992973883675, disc_loss = 0.06219259801413226
Trained batch 584 in epoch 18, gen_loss = 0.8626008615025088, disc_loss = 0.06215161036811451
Trained batch 585 in epoch 18, gen_loss = 0.8623833394396427, disc_loss = 0.0620941056372477
Trained batch 586 in epoch 18, gen_loss = 0.8622205507714663, disc_loss = 0.062021019023698734
Trained batch 587 in epoch 18, gen_loss = 0.8622510194474337, disc_loss = 0.061941961869502404
Trained batch 588 in epoch 18, gen_loss = 0.8624101523531313, disc_loss = 0.06191582062340172
Trained batch 589 in epoch 18, gen_loss = 0.8624851916301048, disc_loss = 0.06196484058479763
Trained batch 590 in epoch 18, gen_loss = 0.8618109361875279, disc_loss = 0.0622539286069925
Trained batch 591 in epoch 18, gen_loss = 0.8613559054462491, disc_loss = 0.06227510492081401
Trained batch 592 in epoch 18, gen_loss = 0.8618429572043491, disc_loss = 0.062477210763540326
Trained batch 593 in epoch 18, gen_loss = 0.8621000513584927, disc_loss = 0.062464023000319245
Trained batch 594 in epoch 18, gen_loss = 0.8618265454007797, disc_loss = 0.06252556697175908
Trained batch 595 in epoch 18, gen_loss = 0.8623230114779217, disc_loss = 0.06258205027903911
Trained batch 596 in epoch 18, gen_loss = 0.8621310432452453, disc_loss = 0.06256542757069271
Trained batch 597 in epoch 18, gen_loss = 0.8619640345457804, disc_loss = 0.06255541374691977
Trained batch 598 in epoch 18, gen_loss = 0.8615247928140956, disc_loss = 0.06261353662784813
Trained batch 599 in epoch 18, gen_loss = 0.8616325987875462, disc_loss = 0.06262546617925788
Trained batch 600 in epoch 18, gen_loss = 0.8619052119639868, disc_loss = 0.06262143166153111
Trained batch 601 in epoch 18, gen_loss = 0.8613998915170911, disc_loss = 0.062685855033891
Trained batch 602 in epoch 18, gen_loss = 0.861455145512845, disc_loss = 0.06266421277715421
Trained batch 603 in epoch 18, gen_loss = 0.8615603644820239, disc_loss = 0.06258182881773135
Trained batch 604 in epoch 18, gen_loss = 0.8613152437466235, disc_loss = 0.06255438189014546
Trained batch 605 in epoch 18, gen_loss = 0.8614230972803859, disc_loss = 0.062470445991109555
Trained batch 606 in epoch 18, gen_loss = 0.8616081455099524, disc_loss = 0.062486007390006815
Trained batch 607 in epoch 18, gen_loss = 0.8614857828636703, disc_loss = 0.06243666600647358
Trained batch 608 in epoch 18, gen_loss = 0.8608681719585005, disc_loss = 0.0625687090684591
Trained batch 609 in epoch 18, gen_loss = 0.8615610910732238, disc_loss = 0.06253785512135288
Trained batch 610 in epoch 18, gen_loss = 0.861759163305139, disc_loss = 0.0626695326974527
Trained batch 611 in epoch 18, gen_loss = 0.8618170717865034, disc_loss = 0.06259468943261073
Trained batch 612 in epoch 18, gen_loss = 0.8614474384761363, disc_loss = 0.0626837094922111
Trained batch 613 in epoch 18, gen_loss = 0.8614634137103147, disc_loss = 0.06260961713193512
Trained batch 614 in epoch 18, gen_loss = 0.8616155945673222, disc_loss = 0.06258713298106218
Trained batch 615 in epoch 18, gen_loss = 0.8615744478226482, disc_loss = 0.06251516406705554
Trained batch 616 in epoch 18, gen_loss = 0.8617759156169149, disc_loss = 0.062450417135562895
Trained batch 617 in epoch 18, gen_loss = 0.8616493100776641, disc_loss = 0.06240480229285663
Trained batch 618 in epoch 18, gen_loss = 0.8615112235838839, disc_loss = 0.062395192821914865
Trained batch 619 in epoch 18, gen_loss = 0.861771393062607, disc_loss = 0.06230777943461773
Trained batch 620 in epoch 18, gen_loss = 0.8617194978799221, disc_loss = 0.0622603098468948
Trained batch 621 in epoch 18, gen_loss = 0.8617251217844402, disc_loss = 0.06218275805662755
Trained batch 622 in epoch 18, gen_loss = 0.8618363399853867, disc_loss = 0.06213875315757543
Trained batch 623 in epoch 18, gen_loss = 0.8621997557675991, disc_loss = 0.0620640382276645
Trained batch 624 in epoch 18, gen_loss = 0.8621395896434784, disc_loss = 0.06204656157717109
Trained batch 625 in epoch 18, gen_loss = 0.8624469723088292, disc_loss = 0.0619718662184922
Trained batch 626 in epoch 18, gen_loss = 0.8625218420983122, disc_loss = 0.06189302792267627
Trained batch 627 in epoch 18, gen_loss = 0.8628101855231698, disc_loss = 0.061898760627332336
Trained batch 628 in epoch 18, gen_loss = 0.8623872917198794, disc_loss = 0.06198251710476173
Trained batch 629 in epoch 18, gen_loss = 0.8623213398551184, disc_loss = 0.06194482133428138
Trained batch 630 in epoch 18, gen_loss = 0.8628822413469457, disc_loss = 0.06192431174345586
Trained batch 631 in epoch 18, gen_loss = 0.8629666122171697, disc_loss = 0.06184131394161053
Trained batch 632 in epoch 18, gen_loss = 0.8628582914387822, disc_loss = 0.06176904441735826
Trained batch 633 in epoch 18, gen_loss = 0.8626748928418295, disc_loss = 0.061697674179978505
Trained batch 634 in epoch 18, gen_loss = 0.8629040165679661, disc_loss = 0.06162664884349375
Trained batch 635 in epoch 18, gen_loss = 0.8628326954800378, disc_loss = 0.06155536323126827
Trained batch 636 in epoch 18, gen_loss = 0.8629593880528371, disc_loss = 0.06147988145919502
Trained batch 637 in epoch 18, gen_loss = 0.8629849025728561, disc_loss = 0.06139602976103772
Trained batch 638 in epoch 18, gen_loss = 0.8630839988752523, disc_loss = 0.061317876930871804
Trained batch 639 in epoch 18, gen_loss = 0.863039294956252, disc_loss = 0.061259794365469133
Trained batch 640 in epoch 18, gen_loss = 0.8632650891908803, disc_loss = 0.061178910578695504
Trained batch 641 in epoch 18, gen_loss = 0.8638191545770918, disc_loss = 0.06113070967560779
Trained batch 642 in epoch 18, gen_loss = 0.8636850435199857, disc_loss = 0.06105385386221354
Trained batch 643 in epoch 18, gen_loss = 0.8634638637767075, disc_loss = 0.061058454786033965
Trained batch 644 in epoch 18, gen_loss = 0.8635320607543916, disc_loss = 0.06098777943384624
Trained batch 645 in epoch 18, gen_loss = 0.8640299282114572, disc_loss = 0.06104628437763836
Trained batch 646 in epoch 18, gen_loss = 0.8638769710174484, disc_loss = 0.06098771942750633
Trained batch 647 in epoch 18, gen_loss = 0.863875920711844, disc_loss = 0.060907699437208335
Trained batch 648 in epoch 18, gen_loss = 0.8640401865282484, disc_loss = 0.06084234643087526
Trained batch 649 in epoch 18, gen_loss = 0.8637845763334862, disc_loss = 0.06081605218565808
Trained batch 650 in epoch 18, gen_loss = 0.8639658969210406, disc_loss = 0.060734598571935326
Trained batch 651 in epoch 18, gen_loss = 0.8641053365509203, disc_loss = 0.06065585830840253
Trained batch 652 in epoch 18, gen_loss = 0.8641972834355616, disc_loss = 0.060578422179477
Trained batch 653 in epoch 18, gen_loss = 0.8640168869258431, disc_loss = 0.060532679514310093
Trained batch 654 in epoch 18, gen_loss = 0.8642045760427722, disc_loss = 0.06045186202475474
Trained batch 655 in epoch 18, gen_loss = 0.8646417169763547, disc_loss = 0.06043036583819563
Trained batch 656 in epoch 18, gen_loss = 0.8646010924782745, disc_loss = 0.06036099197790934
Trained batch 657 in epoch 18, gen_loss = 0.8643146252831427, disc_loss = 0.060387806717085574
Trained batch 658 in epoch 18, gen_loss = 0.8644725543323887, disc_loss = 0.060314179872260155
Trained batch 659 in epoch 18, gen_loss = 0.8648928128860214, disc_loss = 0.06024179082773062
Trained batch 660 in epoch 18, gen_loss = 0.8652012701204072, disc_loss = 0.06019179577729277
Trained batch 661 in epoch 18, gen_loss = 0.8649636087911007, disc_loss = 0.060167798446772724
Trained batch 662 in epoch 18, gen_loss = 0.8652077442650342, disc_loss = 0.06010046724980166
Trained batch 663 in epoch 18, gen_loss = 0.8652215381433447, disc_loss = 0.06002784858202472
Trained batch 664 in epoch 18, gen_loss = 0.865258415883645, disc_loss = 0.05996398819694505
Trained batch 665 in epoch 18, gen_loss = 0.8655966757027594, disc_loss = 0.05990450172377443
Trained batch 666 in epoch 18, gen_loss = 0.8657531048851214, disc_loss = 0.05984276450815788
Trained batch 667 in epoch 18, gen_loss = 0.8657439365804552, disc_loss = 0.05977203957750434
Trained batch 668 in epoch 18, gen_loss = 0.8654059204196359, disc_loss = 0.05975597044202445
Trained batch 669 in epoch 18, gen_loss = 0.8657315605167133, disc_loss = 0.05971194431811237
Trained batch 670 in epoch 18, gen_loss = 0.865529497449693, disc_loss = 0.05966211597042383
Trained batch 671 in epoch 18, gen_loss = 0.8657515755455408, disc_loss = 0.059588657448849905
Trained batch 672 in epoch 18, gen_loss = 0.8660723300869362, disc_loss = 0.05951442249481847
Trained batch 673 in epoch 18, gen_loss = 0.8658578490025919, disc_loss = 0.05948837661289386
Trained batch 674 in epoch 18, gen_loss = 0.8660081187442497, disc_loss = 0.05963687561659349
Trained batch 675 in epoch 18, gen_loss = 0.8657706882914847, disc_loss = 0.05964375251405404
Trained batch 676 in epoch 18, gen_loss = 0.8655552720125528, disc_loss = 0.059623932952207116
Trained batch 677 in epoch 18, gen_loss = 0.8658900873235545, disc_loss = 0.059656949454896524
Trained batch 678 in epoch 18, gen_loss = 0.8660533764839875, disc_loss = 0.05958294030347502
Trained batch 679 in epoch 18, gen_loss = 0.8659276293042828, disc_loss = 0.05954459955682978
Trained batch 680 in epoch 18, gen_loss = 0.866197453765267, disc_loss = 0.059580404204063436
Trained batch 681 in epoch 18, gen_loss = 0.8662133993378832, disc_loss = 0.05951881722705521
Trained batch 682 in epoch 18, gen_loss = 0.8659682271683025, disc_loss = 0.05955810281400341
Trained batch 683 in epoch 18, gen_loss = 0.8660300429365788, disc_loss = 0.0594851749558383
Trained batch 684 in epoch 18, gen_loss = 0.8663426987011067, disc_loss = 0.059471692015029436
Trained batch 685 in epoch 18, gen_loss = 0.8664509170517629, disc_loss = 0.059401267844200696
Trained batch 686 in epoch 18, gen_loss = 0.8662796377528356, disc_loss = 0.0593823544020877
Trained batch 687 in epoch 18, gen_loss = 0.8667751092810271, disc_loss = 0.05957286294649875
Trained batch 688 in epoch 18, gen_loss = 0.866592221794696, disc_loss = 0.05953165367908008
Trained batch 689 in epoch 18, gen_loss = 0.8665889984887579, disc_loss = 0.059507926794416875
Trained batch 690 in epoch 18, gen_loss = 0.8666093040219954, disc_loss = 0.05945897408102015
Trained batch 691 in epoch 18, gen_loss = 0.8664131893674073, disc_loss = 0.059459219364357864
Trained batch 692 in epoch 18, gen_loss = 0.8663702828629536, disc_loss = 0.05941568580650944
Trained batch 693 in epoch 18, gen_loss = 0.8663941125790736, disc_loss = 0.05943020300131817
Trained batch 694 in epoch 18, gen_loss = 0.8663418234252244, disc_loss = 0.05937697528358951
Trained batch 695 in epoch 18, gen_loss = 0.8660335026510145, disc_loss = 0.059372723622424205
Trained batch 696 in epoch 18, gen_loss = 0.8666871686491425, disc_loss = 0.059363539006635865
Trained batch 697 in epoch 18, gen_loss = 0.8670019254216492, disc_loss = 0.05932073087570255
Trained batch 698 in epoch 18, gen_loss = 0.8669958448461197, disc_loss = 0.05925534393848886
Trained batch 699 in epoch 18, gen_loss = 0.86642682743924, disc_loss = 0.0594591505725735
Trained batch 700 in epoch 18, gen_loss = 0.8667146063140048, disc_loss = 0.05942728705292358
Trained batch 701 in epoch 18, gen_loss = 0.8668484190675269, disc_loss = 0.05949667128044422
Trained batch 702 in epoch 18, gen_loss = 0.8668507843319416, disc_loss = 0.059525216330150156
Trained batch 703 in epoch 18, gen_loss = 0.8667829118415036, disc_loss = 0.05949666462269802
Trained batch 704 in epoch 18, gen_loss = 0.8661943644073838, disc_loss = 0.05974279007022368
Trained batch 705 in epoch 18, gen_loss = 0.86607556357431, disc_loss = 0.05970465436263838
Trained batch 706 in epoch 18, gen_loss = 0.8665854713788633, disc_loss = 0.05973568341669744
Trained batch 707 in epoch 18, gen_loss = 0.8667509133617083, disc_loss = 0.05970964447192658
Trained batch 708 in epoch 18, gen_loss = 0.8666445409881716, disc_loss = 0.05968826666687141
Trained batch 709 in epoch 18, gen_loss = 0.8662983591707659, disc_loss = 0.05977355974306628
Trained batch 710 in epoch 18, gen_loss = 0.8662727473908839, disc_loss = 0.05997621067950264
Trained batch 711 in epoch 18, gen_loss = 0.8664864309634386, disc_loss = 0.05990276911251477
Trained batch 712 in epoch 18, gen_loss = 0.866453525770931, disc_loss = 0.05988238448522682
Trained batch 713 in epoch 18, gen_loss = 0.8661638331763885, disc_loss = 0.059880784258157724
Trained batch 714 in epoch 18, gen_loss = 0.8667858362614692, disc_loss = 0.06022573735734278
Trained batch 715 in epoch 18, gen_loss = 0.8669832800436952, disc_loss = 0.060158614188240186
Trained batch 716 in epoch 18, gen_loss = 0.8664885975908867, disc_loss = 0.06032988428485007
Trained batch 717 in epoch 18, gen_loss = 0.8662292997568098, disc_loss = 0.060318170477892986
Trained batch 718 in epoch 18, gen_loss = 0.8664278148858703, disc_loss = 0.06041381628769392
Trained batch 719 in epoch 18, gen_loss = 0.8663258307923873, disc_loss = 0.060400730934796025
Trained batch 720 in epoch 18, gen_loss = 0.8661320811749827, disc_loss = 0.06044801834508281
Trained batch 721 in epoch 18, gen_loss = 0.8661502350813134, disc_loss = 0.06039912518245424
Trained batch 722 in epoch 18, gen_loss = 0.8662150800228119, disc_loss = 0.06033217293992226
Trained batch 723 in epoch 18, gen_loss = 0.8660330607334553, disc_loss = 0.060317967011778516
Trained batch 724 in epoch 18, gen_loss = 0.8657322265772984, disc_loss = 0.06030258962499171
Trained batch 725 in epoch 18, gen_loss = 0.8657204028085572, disc_loss = 0.06025759719976689
Trained batch 726 in epoch 18, gen_loss = 0.865750642434439, disc_loss = 0.060188460190033606
Trained batch 727 in epoch 18, gen_loss = 0.865904347131868, disc_loss = 0.06011425886894218
Trained batch 728 in epoch 18, gen_loss = 0.8661295113821906, disc_loss = 0.06006157697103049
Trained batch 729 in epoch 18, gen_loss = 0.865960624569083, disc_loss = 0.060011643476860776
Trained batch 730 in epoch 18, gen_loss = 0.8662917403206127, disc_loss = 0.05994412324311041
Trained batch 731 in epoch 18, gen_loss = 0.8660882472421954, disc_loss = 0.059904595780379745
Trained batch 732 in epoch 18, gen_loss = 0.865924880945341, disc_loss = 0.059902036040995935
Trained batch 733 in epoch 18, gen_loss = 0.8655620835701191, disc_loss = 0.05990486927977598
Trained batch 734 in epoch 18, gen_loss = 0.8655177323591141, disc_loss = 0.059972064966830066
Trained batch 735 in epoch 18, gen_loss = 0.865336214678119, disc_loss = 0.05990576921170071
Trained batch 736 in epoch 18, gen_loss = 0.8653226618931769, disc_loss = 0.059847125363393386
Trained batch 737 in epoch 18, gen_loss = 0.8651590562529035, disc_loss = 0.0598235564845233
Trained batch 738 in epoch 18, gen_loss = 0.8652291698368703, disc_loss = 0.0597609422303212
Trained batch 739 in epoch 18, gen_loss = 0.8653194368288324, disc_loss = 0.05974179781860093
Trained batch 740 in epoch 18, gen_loss = 0.8650427465094568, disc_loss = 0.05978711588589748
Trained batch 741 in epoch 18, gen_loss = 0.8649095835470446, disc_loss = 0.05973604368861775
Trained batch 742 in epoch 18, gen_loss = 0.8647639073962959, disc_loss = 0.05971237734990498
Trained batch 743 in epoch 18, gen_loss = 0.8649588047416621, disc_loss = 0.05967698753648688
Trained batch 744 in epoch 18, gen_loss = 0.8649058613601147, disc_loss = 0.059677378140114895
Trained batch 745 in epoch 18, gen_loss = 0.8646967965140739, disc_loss = 0.059686257133769724
Trained batch 746 in epoch 18, gen_loss = 0.8643523704814144, disc_loss = 0.05969992975880164
Trained batch 747 in epoch 18, gen_loss = 0.864720135090504, disc_loss = 0.059854220974328805
Trained batch 748 in epoch 18, gen_loss = 0.8644876390576204, disc_loss = 0.05984548734655189
Trained batch 749 in epoch 18, gen_loss = 0.8644295836687088, disc_loss = 0.05980451484210789
Trained batch 750 in epoch 18, gen_loss = 0.8640602279042753, disc_loss = 0.05981314430985545
Trained batch 751 in epoch 18, gen_loss = 0.8640839793976951, disc_loss = 0.059768403847478925
Trained batch 752 in epoch 18, gen_loss = 0.8642604599990059, disc_loss = 0.05982887062861288
Trained batch 753 in epoch 18, gen_loss = 0.8642676820884649, disc_loss = 0.059797735679128876
Trained batch 754 in epoch 18, gen_loss = 0.8639657025700374, disc_loss = 0.05980804063910187
Trained batch 755 in epoch 18, gen_loss = 0.8639676425428617, disc_loss = 0.0597648181054475
Trained batch 756 in epoch 18, gen_loss = 0.8646964365062815, disc_loss = 0.05976435102096696
Trained batch 757 in epoch 18, gen_loss = 0.8647672859140939, disc_loss = 0.05970465201002332
Trained batch 758 in epoch 18, gen_loss = 0.8643229360715516, disc_loss = 0.05990197174606921
Trained batch 759 in epoch 18, gen_loss = 0.8643442926830367, disc_loss = 0.06000403591100813
Trained batch 760 in epoch 18, gen_loss = 0.8646703306463169, disc_loss = 0.06007698588330255
Trained batch 761 in epoch 18, gen_loss = 0.8648480883655273, disc_loss = 0.06002528217298485
Trained batch 762 in epoch 18, gen_loss = 0.8645467064874357, disc_loss = 0.06002107837577967
Trained batch 763 in epoch 18, gen_loss = 0.8646326821433936, disc_loss = 0.05998738077700782
Trained batch 764 in epoch 18, gen_loss = 0.8647283139961218, disc_loss = 0.05995444181417815
Trained batch 765 in epoch 18, gen_loss = 0.8645910689553766, disc_loss = 0.05995103563473854
Trained batch 766 in epoch 18, gen_loss = 0.8646066142573973, disc_loss = 0.059943582899649926
Trained batch 767 in epoch 18, gen_loss = 0.8645315976270164, disc_loss = 0.059896293523706845
Trained batch 768 in epoch 18, gen_loss = 0.8645729544646408, disc_loss = 0.059852955422651205
Trained batch 769 in epoch 18, gen_loss = 0.8644956904959369, disc_loss = 0.05988333755801734
Trained batch 770 in epoch 18, gen_loss = 0.8643554491214406, disc_loss = 0.05988042181038845
Trained batch 771 in epoch 18, gen_loss = 0.864804269774899, disc_loss = 0.05988756710858871
Trained batch 772 in epoch 18, gen_loss = 0.864870662792534, disc_loss = 0.05981890776135596
Trained batch 773 in epoch 18, gen_loss = 0.8645400540080181, disc_loss = 0.05980990729739923
Trained batch 774 in epoch 18, gen_loss = 0.8646970864649742, disc_loss = 0.05974904299743714
Trained batch 775 in epoch 18, gen_loss = 0.8650479317095476, disc_loss = 0.05970121433324728
Trained batch 776 in epoch 18, gen_loss = 0.8653127361985554, disc_loss = 0.05971250055954723
Trained batch 777 in epoch 18, gen_loss = 0.8651665833354916, disc_loss = 0.059657643592238886
Trained batch 778 in epoch 18, gen_loss = 0.8647274797703397, disc_loss = 0.05976487648588472
Trained batch 779 in epoch 18, gen_loss = 0.8649764331105428, disc_loss = 0.05975384501358255
Trained batch 780 in epoch 18, gen_loss = 0.864973713852532, disc_loss = 0.059724149719910954
Trained batch 781 in epoch 18, gen_loss = 0.8647391782773425, disc_loss = 0.059688058724660244
Trained batch 782 in epoch 18, gen_loss = 0.8646303032016998, disc_loss = 0.05964820674771626
Trained batch 783 in epoch 18, gen_loss = 0.8646502150032593, disc_loss = 0.05959777998956567
Trained batch 784 in epoch 18, gen_loss = 0.8649026735952705, disc_loss = 0.05954107707069748
Trained batch 785 in epoch 18, gen_loss = 0.8648969170473914, disc_loss = 0.0594902207811882
Trained batch 786 in epoch 18, gen_loss = 0.8649250990326554, disc_loss = 0.0594430556781164
Trained batch 787 in epoch 18, gen_loss = 0.8652519718720223, disc_loss = 0.05940685035344119
Trained batch 788 in epoch 18, gen_loss = 0.8652766222660684, disc_loss = 0.05937117912673187
Trained batch 789 in epoch 18, gen_loss = 0.8653857619324817, disc_loss = 0.05933012215279137
Testing Epoch 18
Training Epoch 19
Trained batch 0 in epoch 19, gen_loss = 1.0027832984924316, disc_loss = 0.009736647829413414
Trained batch 1 in epoch 19, gen_loss = 0.9633563160896301, disc_loss = 0.011026211082935333
Trained batch 2 in epoch 19, gen_loss = 0.9163364768028259, disc_loss = 0.02174985532959302
Trained batch 3 in epoch 19, gen_loss = 0.9237266331911087, disc_loss = 0.01975638372823596
Trained batch 4 in epoch 19, gen_loss = 0.9821422696113586, disc_loss = 0.040015498921275136
Trained batch 5 in epoch 19, gen_loss = 0.9095010856787363, disc_loss = 0.049305377838512264
Trained batch 6 in epoch 19, gen_loss = 0.9111623508589608, disc_loss = 0.05222581938973495
Trained batch 7 in epoch 19, gen_loss = 0.8868359997868538, disc_loss = 0.05512619181536138
Trained batch 8 in epoch 19, gen_loss = 0.8605860339270698, disc_loss = 0.055250185852249466
Trained batch 9 in epoch 19, gen_loss = 0.878786838054657, disc_loss = 0.05098217884078622
Trained batch 10 in epoch 19, gen_loss = 0.8607158064842224, disc_loss = 0.05011991792443124
Trained batch 11 in epoch 19, gen_loss = 0.8781367093324661, disc_loss = 0.06422231012644868
Trained batch 12 in epoch 19, gen_loss = 0.8536814038570111, disc_loss = 0.0663873442233755
Trained batch 13 in epoch 19, gen_loss = 0.8611754945346287, disc_loss = 0.06385600746476225
Trained batch 14 in epoch 19, gen_loss = 0.866652266184489, disc_loss = 0.060913114435970785
Trained batch 15 in epoch 19, gen_loss = 0.8558948747813702, disc_loss = 0.06204576668096706
Trained batch 16 in epoch 19, gen_loss = 0.8471081607482013, disc_loss = 0.06258861167246804
Trained batch 17 in epoch 19, gen_loss = 0.8583380977312723, disc_loss = 0.0709156871566342
Trained batch 18 in epoch 19, gen_loss = 0.8501534838425485, disc_loss = 0.0723911148839091
Trained batch 19 in epoch 19, gen_loss = 0.8464024156332016, disc_loss = 0.07347209281288088
Trained batch 20 in epoch 19, gen_loss = 0.8604148938542321, disc_loss = 0.07336963016894602
Trained batch 21 in epoch 19, gen_loss = 0.8586831553415819, disc_loss = 0.07251403628933159
Trained batch 22 in epoch 19, gen_loss = 0.8495713083640389, disc_loss = 0.07204440912312787
Trained batch 23 in epoch 19, gen_loss = 0.8550918797651926, disc_loss = 0.06972826648658763
Trained batch 24 in epoch 19, gen_loss = 0.8581853866577148, disc_loss = 0.06792429734021425
Trained batch 25 in epoch 19, gen_loss = 0.8596032766195444, disc_loss = 0.06566115980967879
Trained batch 26 in epoch 19, gen_loss = 0.8519901589111045, disc_loss = 0.06632316385016397
Trained batch 27 in epoch 19, gen_loss = 0.8675058377640588, disc_loss = 0.06555696054627853
Trained batch 28 in epoch 19, gen_loss = 0.8683215441374943, disc_loss = 0.06423373215285869
Trained batch 29 in epoch 19, gen_loss = 0.86449360648791, disc_loss = 0.0637047916961213
Trained batch 30 in epoch 19, gen_loss = 0.8687312756815264, disc_loss = 0.06190894988756026
Trained batch 31 in epoch 19, gen_loss = 0.8683007806539536, disc_loss = 0.06066625111270696
Trained batch 32 in epoch 19, gen_loss = 0.8770128958153002, disc_loss = 0.0613230142855283
Trained batch 33 in epoch 19, gen_loss = 0.8758832759716931, disc_loss = 0.06009878240087453
Trained batch 34 in epoch 19, gen_loss = 0.8748862487929208, disc_loss = 0.058955305442214015
Trained batch 35 in epoch 19, gen_loss = 0.8716313855515586, disc_loss = 0.057734482249038085
Trained batch 36 in epoch 19, gen_loss = 0.8744977954271678, disc_loss = 0.05695694111086227
Trained batch 37 in epoch 19, gen_loss = 0.882312619372418, disc_loss = 0.05595056124423679
Trained batch 38 in epoch 19, gen_loss = 0.8784604699183733, disc_loss = 0.05547170245494598
Trained batch 39 in epoch 19, gen_loss = 0.8826400622725487, disc_loss = 0.05477152364328504
Trained batch 40 in epoch 19, gen_loss = 0.8821014979990517, disc_loss = 0.053839752768597954
Trained batch 41 in epoch 19, gen_loss = 0.881811743690854, disc_loss = 0.0534660986491612
Trained batch 42 in epoch 19, gen_loss = 0.8820524271144423, disc_loss = 0.05248043352608071
Trained batch 43 in epoch 19, gen_loss = 0.8828200887550007, disc_loss = 0.051510245010087434
Trained batch 44 in epoch 19, gen_loss = 0.8812475628323025, disc_loss = 0.05123350452631712
Trained batch 45 in epoch 19, gen_loss = 0.8830437997113103, disc_loss = 0.05049001715024528
Trained batch 46 in epoch 19, gen_loss = 0.8822223252438485, disc_loss = 0.04980973283106342
Trained batch 47 in epoch 19, gen_loss = 0.8837021067738533, disc_loss = 0.04921297649464881
Trained batch 48 in epoch 19, gen_loss = 0.8824110870458641, disc_loss = 0.04889084685745896
Trained batch 49 in epoch 19, gen_loss = 0.8887708556652069, disc_loss = 0.04847958890721202
Trained batch 50 in epoch 19, gen_loss = 0.8947036488383424, disc_loss = 0.047889134517925626
Trained batch 51 in epoch 19, gen_loss = 0.8938151242641302, disc_loss = 0.047660511828815706
Trained batch 52 in epoch 19, gen_loss = 0.8949396059198199, disc_loss = 0.04702993464779179
Trained batch 53 in epoch 19, gen_loss = 0.8958084561206676, disc_loss = 0.04658372724359786
Trained batch 54 in epoch 19, gen_loss = 0.8943612868135625, disc_loss = 0.046440199796449054
Trained batch 55 in epoch 19, gen_loss = 0.895341365465096, disc_loss = 0.045899861392432025
Trained batch 56 in epoch 19, gen_loss = 0.8918672601381937, disc_loss = 0.04549271289847399
Trained batch 57 in epoch 19, gen_loss = 0.8951776839535812, disc_loss = 0.04571984210533315
Trained batch 58 in epoch 19, gen_loss = 0.9015906655182273, disc_loss = 0.04557435097709551
Trained batch 59 in epoch 19, gen_loss = 0.9017916907866795, disc_loss = 0.04502208000048995
Trained batch 60 in epoch 19, gen_loss = 0.8994013393511537, disc_loss = 0.04570389029066094
Trained batch 61 in epoch 19, gen_loss = 0.8985953446357481, disc_loss = 0.045178307370553096
Trained batch 62 in epoch 19, gen_loss = 0.9019325252563234, disc_loss = 0.04478089946011702
Trained batch 63 in epoch 19, gen_loss = 0.9004070153459907, disc_loss = 0.04450384114170447
Trained batch 64 in epoch 19, gen_loss = 0.8988835930824279, disc_loss = 0.04443376035644458
Trained batch 65 in epoch 19, gen_loss = 0.8987621692093936, disc_loss = 0.044003015609853195
Trained batch 66 in epoch 19, gen_loss = 0.8998031349324468, disc_loss = 0.0435718722474664
Trained batch 67 in epoch 19, gen_loss = 0.8993265549926197, disc_loss = 0.04339884174987674
Trained batch 68 in epoch 19, gen_loss = 0.898667163607003, disc_loss = 0.04312945130294648
Trained batch 69 in epoch 19, gen_loss = 0.89976738180433, disc_loss = 0.04260701152629086
Trained batch 70 in epoch 19, gen_loss = 0.8995381325063571, disc_loss = 0.04235036971545975
Trained batch 71 in epoch 19, gen_loss = 0.8984160282545619, disc_loss = 0.04211852817227029
Trained batch 72 in epoch 19, gen_loss = 0.9038957594192192, disc_loss = 0.04414707068864205
Trained batch 73 in epoch 19, gen_loss = 0.9004920777436849, disc_loss = 0.04481776324226647
Trained batch 74 in epoch 19, gen_loss = 0.9000256069501241, disc_loss = 0.044451345192889374
Trained batch 75 in epoch 19, gen_loss = 0.9006513945366207, disc_loss = 0.04413454194161061
Trained batch 76 in epoch 19, gen_loss = 0.9037003230738949, disc_loss = 0.04383197019191144
Trained batch 77 in epoch 19, gen_loss = 0.9030613662340702, disc_loss = 0.04341436268236393
Trained batch 78 in epoch 19, gen_loss = 0.9012507192696197, disc_loss = 0.04321272242106969
Trained batch 79 in epoch 19, gen_loss = 0.8997634932398796, disc_loss = 0.043050168664194643
Trained batch 80 in epoch 19, gen_loss = 0.9029186257609615, disc_loss = 0.042867874496696906
Trained batch 81 in epoch 19, gen_loss = 0.9041271849376399, disc_loss = 0.04249315424935847
Trained batch 82 in epoch 19, gen_loss = 0.9037600353539709, disc_loss = 0.04205147369977939
Trained batch 83 in epoch 19, gen_loss = 0.9028839270273844, disc_loss = 0.041772116596500077
Trained batch 84 in epoch 19, gen_loss = 0.902066481814665, disc_loss = 0.04152330081252491
Trained batch 85 in epoch 19, gen_loss = 0.9021829089453054, disc_loss = 0.04117521490945026
Trained batch 86 in epoch 19, gen_loss = 0.9026987463578411, disc_loss = 0.040807450414988504
Trained batch 87 in epoch 19, gen_loss = 0.9036504714326425, disc_loss = 0.040447849431075156
Trained batch 88 in epoch 19, gen_loss = 0.9029599274142405, disc_loss = 0.040126579133479785
Trained batch 89 in epoch 19, gen_loss = 0.9044256071249644, disc_loss = 0.039746843081795505
Trained batch 90 in epoch 19, gen_loss = 0.9070388137639224, disc_loss = 0.03946387099491044
Trained batch 91 in epoch 19, gen_loss = 0.90539799241916, disc_loss = 0.03950317830616689
Trained batch 92 in epoch 19, gen_loss = 0.9061018215712681, disc_loss = 0.03917673037898156
Trained batch 93 in epoch 19, gen_loss = 0.906625582816753, disc_loss = 0.040946215232636064
Trained batch 94 in epoch 19, gen_loss = 0.9032857919994154, disc_loss = 0.041358652083497295
Trained batch 95 in epoch 19, gen_loss = 0.901323019216458, disc_loss = 0.04173507005907595
Trained batch 96 in epoch 19, gen_loss = 0.9045332031151683, disc_loss = 0.04185664004732653
Trained batch 97 in epoch 19, gen_loss = 0.9023600804562472, disc_loss = 0.04315712147069221
Trained batch 98 in epoch 19, gen_loss = 0.900841003716594, disc_loss = 0.04353038104947167
Trained batch 99 in epoch 19, gen_loss = 0.8992017042636872, disc_loss = 0.04390449773520231
Trained batch 100 in epoch 19, gen_loss = 0.8991069787799721, disc_loss = 0.04515383529043434
Trained batch 101 in epoch 19, gen_loss = 0.8985060652097067, disc_loss = 0.04525360297046456
Trained batch 102 in epoch 19, gen_loss = 0.8971487978129711, disc_loss = 0.04533197738013221
Trained batch 103 in epoch 19, gen_loss = 0.8995170008677703, disc_loss = 0.04511203360743821
Trained batch 104 in epoch 19, gen_loss = 0.9005353587014334, disc_loss = 0.04485586739721752
Trained batch 105 in epoch 19, gen_loss = 0.8975579013239663, disc_loss = 0.045211345871102135
Trained batch 106 in epoch 19, gen_loss = 0.8981044626681605, disc_loss = 0.04621586530843628
Trained batch 107 in epoch 19, gen_loss = 0.8977019268053549, disc_loss = 0.04592154473411264
Trained batch 108 in epoch 19, gen_loss = 0.8959551552020082, disc_loss = 0.046058508114667114
Trained batch 109 in epoch 19, gen_loss = 0.8960534951903604, disc_loss = 0.045743510795926506
Trained batch 110 in epoch 19, gen_loss = 0.8939705152769346, disc_loss = 0.045660888381839335
Trained batch 111 in epoch 19, gen_loss = 0.8934321371572358, disc_loss = 0.04542464467730107
Trained batch 112 in epoch 19, gen_loss = 0.8959767533614572, disc_loss = 0.04521784769057964
Trained batch 113 in epoch 19, gen_loss = 0.8946194774226138, disc_loss = 0.04515003310843257
Trained batch 114 in epoch 19, gen_loss = 0.8962388038635254, disc_loss = 0.04486188319228265
Trained batch 115 in epoch 19, gen_loss = 0.8974211051546294, disc_loss = 0.04480022475412437
Trained batch 116 in epoch 19, gen_loss = 0.897520883470519, disc_loss = 0.044479128550419696
Trained batch 117 in epoch 19, gen_loss = 0.8946002519736855, disc_loss = 0.04532241761700203
Trained batch 118 in epoch 19, gen_loss = 0.8958691869463239, disc_loss = 0.0462831290430945
Trained batch 119 in epoch 19, gen_loss = 0.896149476369222, disc_loss = 0.04597901249071583
Trained batch 120 in epoch 19, gen_loss = 0.8957724807676205, disc_loss = 0.04575966165039288
Trained batch 121 in epoch 19, gen_loss = 0.8960984832927829, disc_loss = 0.045457218815648896
Trained batch 122 in epoch 19, gen_loss = 0.8956547272883779, disc_loss = 0.04526226441716639
Trained batch 123 in epoch 19, gen_loss = 0.8979622601501404, disc_loss = 0.045117260313652936
Trained batch 124 in epoch 19, gen_loss = 0.8975864043235778, disc_loss = 0.04492125403508544
Trained batch 125 in epoch 19, gen_loss = 0.8987337951622312, disc_loss = 0.04472138124725057
Trained batch 126 in epoch 19, gen_loss = 0.897936139989087, disc_loss = 0.044586595510843936
Trained batch 127 in epoch 19, gen_loss = 0.8968234262429178, disc_loss = 0.04447101156620192
Trained batch 128 in epoch 19, gen_loss = 0.8973733972209369, disc_loss = 0.044222133699804544
Trained batch 129 in epoch 19, gen_loss = 0.8984494631107037, disc_loss = 0.04405993388320964
Trained batch 130 in epoch 19, gen_loss = 0.8975842636050159, disc_loss = 0.043975865500374835
Trained batch 131 in epoch 19, gen_loss = 0.8967240416642391, disc_loss = 0.04377228352170663
Trained batch 132 in epoch 19, gen_loss = 0.8985060596824589, disc_loss = 0.043641376515668365
Trained batch 133 in epoch 19, gen_loss = 0.9006326865794053, disc_loss = 0.04397480154006895
Trained batch 134 in epoch 19, gen_loss = 0.9018235250755593, disc_loss = 0.04373978608529325
Trained batch 135 in epoch 19, gen_loss = 0.8992957288728041, disc_loss = 0.04478585665620973
Trained batch 136 in epoch 19, gen_loss = 0.8991993300236054, disc_loss = 0.044931889181943054
Trained batch 137 in epoch 19, gen_loss = 0.8983502085658087, disc_loss = 0.04510082337208956
Trained batch 138 in epoch 19, gen_loss = 0.8986641228627815, disc_loss = 0.04486358901083791
Trained batch 139 in epoch 19, gen_loss = 0.8988423036677496, disc_loss = 0.04461819623663489
Trained batch 140 in epoch 19, gen_loss = 0.8978831687717573, disc_loss = 0.04462350319397259
Trained batch 141 in epoch 19, gen_loss = 0.8966548186792455, disc_loss = 0.04469663656028119
Trained batch 142 in epoch 19, gen_loss = 0.8964733535593207, disc_loss = 0.04459042314088324
Trained batch 143 in epoch 19, gen_loss = 0.8975027493304677, disc_loss = 0.04443712501152833
Trained batch 144 in epoch 19, gen_loss = 0.8974726364530367, disc_loss = 0.04438992684450129
Trained batch 145 in epoch 19, gen_loss = 0.8958821182381617, disc_loss = 0.044409502830279814
Trained batch 146 in epoch 19, gen_loss = 0.8969487933074536, disc_loss = 0.04424604352525607
Trained batch 147 in epoch 19, gen_loss = 0.8968370999838855, disc_loss = 0.04444560101192847
Trained batch 148 in epoch 19, gen_loss = 0.8968380329592917, disc_loss = 0.04431676943067636
Trained batch 149 in epoch 19, gen_loss = 0.8950398902098338, disc_loss = 0.04483522994754215
Trained batch 150 in epoch 19, gen_loss = 0.8949200613609213, disc_loss = 0.044680101103118514
Trained batch 151 in epoch 19, gen_loss = 0.895021099009012, disc_loss = 0.04450216789815673
Trained batch 152 in epoch 19, gen_loss = 0.8951133361049727, disc_loss = 0.04494409164219024
Trained batch 153 in epoch 19, gen_loss = 0.8959900051742405, disc_loss = 0.04475848091004247
Trained batch 154 in epoch 19, gen_loss = 0.8950548914171035, disc_loss = 0.044938165907778084
Trained batch 155 in epoch 19, gen_loss = 0.8951849509508182, disc_loss = 0.044753012363798916
Trained batch 156 in epoch 19, gen_loss = 0.8976446337001339, disc_loss = 0.044827329644423194
Trained batch 157 in epoch 19, gen_loss = 0.8974102199832096, disc_loss = 0.04482575364210466
Trained batch 158 in epoch 19, gen_loss = 0.8947653076933615, disc_loss = 0.04570948824274746
Trained batch 159 in epoch 19, gen_loss = 0.8948141153901815, disc_loss = 0.045680242820526476
Trained batch 160 in epoch 19, gen_loss = 0.8933405835435998, disc_loss = 0.04566015358377965
Trained batch 161 in epoch 19, gen_loss = 0.8937725016364345, disc_loss = 0.04553204199678644
Trained batch 162 in epoch 19, gen_loss = 0.894671389296011, disc_loss = 0.04546982323910835
Trained batch 163 in epoch 19, gen_loss = 0.8948612434834968, disc_loss = 0.045356308913607965
Trained batch 164 in epoch 19, gen_loss = 0.8923620933836157, disc_loss = 0.046032517344098196
Trained batch 165 in epoch 19, gen_loss = 0.8927346315369549, disc_loss = 0.04588311384095395
Trained batch 166 in epoch 19, gen_loss = 0.8947989803231405, disc_loss = 0.045899019969772255
Trained batch 167 in epoch 19, gen_loss = 0.8949343397149018, disc_loss = 0.045695650310898644
Trained batch 168 in epoch 19, gen_loss = 0.8938278769247631, disc_loss = 0.045920490874142864
Trained batch 169 in epoch 19, gen_loss = 0.8926073402166367, disc_loss = 0.045954060672289306
Trained batch 170 in epoch 19, gen_loss = 0.893571677786565, disc_loss = 0.04602821342026194
Trained batch 171 in epoch 19, gen_loss = 0.894660975870698, disc_loss = 0.047053203817868476
Trained batch 172 in epoch 19, gen_loss = 0.8934581929204092, disc_loss = 0.0470920107435069
Trained batch 173 in epoch 19, gen_loss = 0.8918099226965301, disc_loss = 0.047462054803946066
Trained batch 174 in epoch 19, gen_loss = 0.8920247331687382, disc_loss = 0.04804511879969921
Trained batch 175 in epoch 19, gen_loss = 0.8922109483656558, disc_loss = 0.047865748646224594
Trained batch 176 in epoch 19, gen_loss = 0.8909392540400984, disc_loss = 0.0484308660067197
Trained batch 177 in epoch 19, gen_loss = 0.8919236936261145, disc_loss = 0.04838460075585276
Trained batch 178 in epoch 19, gen_loss = 0.8916886527112077, disc_loss = 0.04859653680049424
Trained batch 179 in epoch 19, gen_loss = 0.8914040255877707, disc_loss = 0.048490482141884665
Trained batch 180 in epoch 19, gen_loss = 0.89213691446004, disc_loss = 0.04832926378919851
Trained batch 181 in epoch 19, gen_loss = 0.8922441541166096, disc_loss = 0.04820987905355191
Trained batch 182 in epoch 19, gen_loss = 0.8907231634757558, disc_loss = 0.0485121540170509
Trained batch 183 in epoch 19, gen_loss = 0.8894671028398949, disc_loss = 0.048430201473504145
Trained batch 184 in epoch 19, gen_loss = 0.8888111957021662, disc_loss = 0.048687814133292116
Trained batch 185 in epoch 19, gen_loss = 0.890122456416007, disc_loss = 0.049201046344473635
Trained batch 186 in epoch 19, gen_loss = 0.8906534529306034, disc_loss = 0.04899993757742213
Trained batch 187 in epoch 19, gen_loss = 0.8897120754452462, disc_loss = 0.04925848143125706
Trained batch 188 in epoch 19, gen_loss = 0.889155310140085, disc_loss = 0.049374881360640444
Trained batch 189 in epoch 19, gen_loss = 0.8892263868921682, disc_loss = 0.05005797982755068
Trained batch 190 in epoch 19, gen_loss = 0.8902855136319605, disc_loss = 0.049906637068564824
Trained batch 191 in epoch 19, gen_loss = 0.8899117545224726, disc_loss = 0.04976845935016172
Trained batch 192 in epoch 19, gen_loss = 0.8896084571440603, disc_loss = 0.04977994304816263
Trained batch 193 in epoch 19, gen_loss = 0.8884027912137434, disc_loss = 0.04991486319820829
Trained batch 194 in epoch 19, gen_loss = 0.8897951259062841, disc_loss = 0.04983903327001593
Trained batch 195 in epoch 19, gen_loss = 0.8898314011036134, disc_loss = 0.04968875898190831
Trained batch 196 in epoch 19, gen_loss = 0.8895893640021988, disc_loss = 0.049900286587494125
Trained batch 197 in epoch 19, gen_loss = 0.8877329734539745, disc_loss = 0.050323382742006824
Trained batch 198 in epoch 19, gen_loss = 0.887603118042251, disc_loss = 0.05022205101400988
Trained batch 199 in epoch 19, gen_loss = 0.8894460932910442, disc_loss = 0.05036989856278524
Trained batch 200 in epoch 19, gen_loss = 0.8884548202379426, disc_loss = 0.050425408748604024
Trained batch 201 in epoch 19, gen_loss = 0.8865986526897638, disc_loss = 0.05122098330140925
Trained batch 202 in epoch 19, gen_loss = 0.8867748310706886, disc_loss = 0.05111769731546491
Trained batch 203 in epoch 19, gen_loss = 0.8880721656422988, disc_loss = 0.05109421999933308
Trained batch 204 in epoch 19, gen_loss = 0.8879519839112352, disc_loss = 0.051174169703863744
Trained batch 205 in epoch 19, gen_loss = 0.886968405067342, disc_loss = 0.05116823241250246
Trained batch 206 in epoch 19, gen_loss = 0.887178342267511, disc_loss = 0.051012889871256795
Trained batch 207 in epoch 19, gen_loss = 0.886082870599169, disc_loss = 0.05113239538667795
Trained batch 208 in epoch 19, gen_loss = 0.8862704368014085, disc_loss = 0.051290227204971194
Trained batch 209 in epoch 19, gen_loss = 0.8851900340545745, disc_loss = 0.05142545564144495
Trained batch 210 in epoch 19, gen_loss = 0.8847534324603058, disc_loss = 0.051356019909047826
Trained batch 211 in epoch 19, gen_loss = 0.8844507191822214, disc_loss = 0.05120783187405048
Trained batch 212 in epoch 19, gen_loss = 0.8855871640740426, disc_loss = 0.05115328059955872
Trained batch 213 in epoch 19, gen_loss = 0.8851497291683037, disc_loss = 0.05101800500850463
Trained batch 214 in epoch 19, gen_loss = 0.886442902614904, disc_loss = 0.05093274194270719
Trained batch 215 in epoch 19, gen_loss = 0.8866063628207754, disc_loss = 0.05079074326204136
Trained batch 216 in epoch 19, gen_loss = 0.886981253662417, disc_loss = 0.05116955556344533
Trained batch 217 in epoch 19, gen_loss = 0.8854641519281843, disc_loss = 0.051440125465854455
Trained batch 218 in epoch 19, gen_loss = 0.8857052011849129, disc_loss = 0.05126813634354026
Trained batch 219 in epoch 19, gen_loss = 0.8847815363244577, disc_loss = 0.05139860875100236
Trained batch 220 in epoch 19, gen_loss = 0.8857725077894478, disc_loss = 0.05202678694048416
Trained batch 221 in epoch 19, gen_loss = 0.886207898055111, disc_loss = 0.05191190864865643
Trained batch 222 in epoch 19, gen_loss = 0.8857493880351028, disc_loss = 0.05177820179268985
Trained batch 223 in epoch 19, gen_loss = 0.8851323046588472, disc_loss = 0.05192533663648646
Trained batch 224 in epoch 19, gen_loss = 0.8848874957031674, disc_loss = 0.05183326855508818
Trained batch 225 in epoch 19, gen_loss = 0.8855242988968317, disc_loss = 0.05172083431450996
Trained batch 226 in epoch 19, gen_loss = 0.8853526237515101, disc_loss = 0.051641109692843606
Trained batch 227 in epoch 19, gen_loss = 0.8847834547622162, disc_loss = 0.05150802057081213
Trained batch 228 in epoch 19, gen_loss = 0.8857286435808157, disc_loss = 0.05140644694397869
Trained batch 229 in epoch 19, gen_loss = 0.8859272144410921, disc_loss = 0.051211688825455695
Trained batch 230 in epoch 19, gen_loss = 0.8849883651062523, disc_loss = 0.05126755674534933
Trained batch 231 in epoch 19, gen_loss = 0.8855998540489838, disc_loss = 0.05114383622602527
Trained batch 232 in epoch 19, gen_loss = 0.8856422618479176, disc_loss = 0.05096940846929862
Trained batch 233 in epoch 19, gen_loss = 0.8852198912292464, disc_loss = 0.05087332067310683
Trained batch 234 in epoch 19, gen_loss = 0.8854355790513627, disc_loss = 0.05074768782533864
Trained batch 235 in epoch 19, gen_loss = 0.8860338712900372, disc_loss = 0.050582029462113216
Trained batch 236 in epoch 19, gen_loss = 0.8866927119498514, disc_loss = 0.050396016527768935
Trained batch 237 in epoch 19, gen_loss = 0.8868566614990475, disc_loss = 0.0502860407509348
Trained batch 238 in epoch 19, gen_loss = 0.8865033272170622, disc_loss = 0.05015606366129101
Trained batch 239 in epoch 19, gen_loss = 0.8867272162189086, disc_loss = 0.04998095597450932
Trained batch 240 in epoch 19, gen_loss = 0.887205791052941, disc_loss = 0.04980240139677441
Trained batch 241 in epoch 19, gen_loss = 0.8872938430752636, disc_loss = 0.049628579219387584
Trained batch 242 in epoch 19, gen_loss = 0.8869669185989678, disc_loss = 0.049527120749646256
Trained batch 243 in epoch 19, gen_loss = 0.8863992145071264, disc_loss = 0.0493842715657026
Trained batch 244 in epoch 19, gen_loss = 0.8867981921653358, disc_loss = 0.04920776297851485
Trained batch 245 in epoch 19, gen_loss = 0.8869987838878864, disc_loss = 0.049032902267451085
Trained batch 246 in epoch 19, gen_loss = 0.8874063104511756, disc_loss = 0.048864164704509716
Trained batch 247 in epoch 19, gen_loss = 0.8876528128260567, disc_loss = 0.04881155102761583
Trained batch 248 in epoch 19, gen_loss = 0.8864777529814157, disc_loss = 0.049104796200766264
Trained batch 249 in epoch 19, gen_loss = 0.8882563515901566, disc_loss = 0.049864204371348024
Trained batch 250 in epoch 19, gen_loss = 0.8878697514296527, disc_loss = 0.04989196699431752
Trained batch 251 in epoch 19, gen_loss = 0.8865931016348657, disc_loss = 0.049937268077868906
Trained batch 252 in epoch 19, gen_loss = 0.8866889704121903, disc_loss = 0.049916839331992174
Trained batch 253 in epoch 19, gen_loss = 0.8862174461911044, disc_loss = 0.04992408837250426
Trained batch 254 in epoch 19, gen_loss = 0.8856920208416733, disc_loss = 0.04991890663354128
Trained batch 255 in epoch 19, gen_loss = 0.8860513038234785, disc_loss = 0.04979339542660455
Trained batch 256 in epoch 19, gen_loss = 0.8860975252283223, disc_loss = 0.049681942629109674
Trained batch 257 in epoch 19, gen_loss = 0.8874622688506001, disc_loss = 0.05009161206792549
Trained batch 258 in epoch 19, gen_loss = 0.8860834840411845, disc_loss = 0.05066168434292251
Trained batch 259 in epoch 19, gen_loss = 0.8855735846436941, disc_loss = 0.05067271101109397
Trained batch 260 in epoch 19, gen_loss = 0.8851508581546988, disc_loss = 0.050807843129311143
Trained batch 261 in epoch 19, gen_loss = 0.8860773079040396, disc_loss = 0.05087967166670008
Trained batch 262 in epoch 19, gen_loss = 0.8857564328967845, disc_loss = 0.05074868836535757
Trained batch 263 in epoch 19, gen_loss = 0.8849165420414824, disc_loss = 0.050818847755153634
Trained batch 264 in epoch 19, gen_loss = 0.8852588814384532, disc_loss = 0.050716945158212255
Trained batch 265 in epoch 19, gen_loss = 0.8855182964326744, disc_loss = 0.050705685520096494
Trained batch 266 in epoch 19, gen_loss = 0.8851486092872833, disc_loss = 0.050757603735526964
Trained batch 267 in epoch 19, gen_loss = 0.8844403830259594, disc_loss = 0.050936267316800114
Trained batch 268 in epoch 19, gen_loss = 0.8836385730695547, disc_loss = 0.05094372308864968
Trained batch 269 in epoch 19, gen_loss = 0.8844656998360598, disc_loss = 0.050917794495062146
Trained batch 270 in epoch 19, gen_loss = 0.8846095339618486, disc_loss = 0.05092389639157706
Trained batch 271 in epoch 19, gen_loss = 0.8850544411689043, disc_loss = 0.050780428225955215
Trained batch 272 in epoch 19, gen_loss = 0.8845209115809136, disc_loss = 0.05088196611100119
Trained batch 273 in epoch 19, gen_loss = 0.8841279978952269, disc_loss = 0.050956040330190404
Trained batch 274 in epoch 19, gen_loss = 0.884064058932391, disc_loss = 0.05091277085413987
Trained batch 275 in epoch 19, gen_loss = 0.8835295379377793, disc_loss = 0.05090137268247866
Trained batch 276 in epoch 19, gen_loss = 0.882851304237593, disc_loss = 0.050843441430210315
Trained batch 277 in epoch 19, gen_loss = 0.8834084595064465, disc_loss = 0.05092335651333866
Trained batch 278 in epoch 19, gen_loss = 0.8835097988232917, disc_loss = 0.050776357440391426
Trained batch 279 in epoch 19, gen_loss = 0.8832275204360485, disc_loss = 0.050718462867994925
Trained batch 280 in epoch 19, gen_loss = 0.8836001171548171, disc_loss = 0.05057740207675354
Trained batch 281 in epoch 19, gen_loss = 0.8846889126596721, disc_loss = 0.05105211153950093
Trained batch 282 in epoch 19, gen_loss = 0.8835901983424548, disc_loss = 0.0510701237282594
Trained batch 283 in epoch 19, gen_loss = 0.882301673607927, disc_loss = 0.05143728089013832
Trained batch 284 in epoch 19, gen_loss = 0.8827175760478304, disc_loss = 0.05144691143282934
Trained batch 285 in epoch 19, gen_loss = 0.8833677052826314, disc_loss = 0.05134690981651363
Trained batch 286 in epoch 19, gen_loss = 0.8828939954370572, disc_loss = 0.05122529506482158
Trained batch 287 in epoch 19, gen_loss = 0.882137300964031, disc_loss = 0.05120939029438887
Trained batch 288 in epoch 19, gen_loss = 0.8834001596204962, disc_loss = 0.05113064466933736
Trained batch 289 in epoch 19, gen_loss = 0.8826203256845474, disc_loss = 0.051372026294020226
Trained batch 290 in epoch 19, gen_loss = 0.8813440870378435, disc_loss = 0.05185744015474346
Trained batch 291 in epoch 19, gen_loss = 0.8818639293313026, disc_loss = 0.05178201943795414
Trained batch 292 in epoch 19, gen_loss = 0.8823023514739482, disc_loss = 0.05164539634882641
Trained batch 293 in epoch 19, gen_loss = 0.8820859288074532, disc_loss = 0.05166866099556946
Trained batch 294 in epoch 19, gen_loss = 0.8815468639640485, disc_loss = 0.051694716173776634
Trained batch 295 in epoch 19, gen_loss = 0.881114902025139, disc_loss = 0.05165460820441965
Trained batch 296 in epoch 19, gen_loss = 0.8814065264732348, disc_loss = 0.05151012923838163
Trained batch 297 in epoch 19, gen_loss = 0.8816523952972168, disc_loss = 0.051463958540081275
Trained batch 298 in epoch 19, gen_loss = 0.8809817978570293, disc_loss = 0.05155688495745876
Trained batch 299 in epoch 19, gen_loss = 0.8799491017063459, disc_loss = 0.05175966192192088
Trained batch 300 in epoch 19, gen_loss = 0.8793396140847888, disc_loss = 0.05175014737640752
Trained batch 301 in epoch 19, gen_loss = 0.8806463396115018, disc_loss = 0.051717650923964305
Trained batch 302 in epoch 19, gen_loss = 0.881012619426935, disc_loss = 0.05158368452750269
Trained batch 303 in epoch 19, gen_loss = 0.8803603828541542, disc_loss = 0.051539965477882345
Trained batch 304 in epoch 19, gen_loss = 0.880833744514184, disc_loss = 0.051797437535018705
Trained batch 305 in epoch 19, gen_loss = 0.8798700634365767, disc_loss = 0.052135057761059964
Trained batch 306 in epoch 19, gen_loss = 0.8789189033671388, disc_loss = 0.05221051153808784
Trained batch 307 in epoch 19, gen_loss = 0.8794549131741771, disc_loss = 0.05274402786971542
Trained batch 308 in epoch 19, gen_loss = 0.8786595046134442, disc_loss = 0.052804153606982776
Trained batch 309 in epoch 19, gen_loss = 0.8783973802481928, disc_loss = 0.05290599034107741
Trained batch 310 in epoch 19, gen_loss = 0.8779181158619295, disc_loss = 0.052915613429015955
Trained batch 311 in epoch 19, gen_loss = 0.8771397130420575, disc_loss = 0.05297280467288473
Trained batch 312 in epoch 19, gen_loss = 0.8773197787828719, disc_loss = 0.052868836397192066
Trained batch 313 in epoch 19, gen_loss = 0.8771743955695706, disc_loss = 0.052794160405885734
Trained batch 314 in epoch 19, gen_loss = 0.8769631596784743, disc_loss = 0.05282357680566964
Trained batch 315 in epoch 19, gen_loss = 0.8767741917620732, disc_loss = 0.052758746781928725
Trained batch 316 in epoch 19, gen_loss = 0.8765822234401943, disc_loss = 0.052732199443686366
Trained batch 317 in epoch 19, gen_loss = 0.8763580130143735, disc_loss = 0.05261125469890734
Trained batch 318 in epoch 19, gen_loss = 0.8774232411272473, disc_loss = 0.052558082834668576
Trained batch 319 in epoch 19, gen_loss = 0.877369421441108, disc_loss = 0.05242136486194795
Trained batch 320 in epoch 19, gen_loss = 0.8760110107352058, disc_loss = 0.05281876280433803
Trained batch 321 in epoch 19, gen_loss = 0.8772483354214555, disc_loss = 0.05308342347737194
Trained batch 322 in epoch 19, gen_loss = 0.8776128287470377, disc_loss = 0.052970196727386475
Trained batch 323 in epoch 19, gen_loss = 0.8770194378348044, disc_loss = 0.05293048190292155
Trained batch 324 in epoch 19, gen_loss = 0.8767844157035534, disc_loss = 0.05301234830887272
Trained batch 325 in epoch 19, gen_loss = 0.8762842271408421, disc_loss = 0.052945579937802044
Trained batch 326 in epoch 19, gen_loss = 0.875799619550005, disc_loss = 0.05287771972055783
Trained batch 327 in epoch 19, gen_loss = 0.876132799630485, disc_loss = 0.05295334026507079
Trained batch 328 in epoch 19, gen_loss = 0.8759768318079163, disc_loss = 0.05287607036683833
Trained batch 329 in epoch 19, gen_loss = 0.8765354211583282, disc_loss = 0.05276442421176894
Trained batch 330 in epoch 19, gen_loss = 0.8758175258730113, disc_loss = 0.053247791294323624
Trained batch 331 in epoch 19, gen_loss = 0.8753178932042007, disc_loss = 0.05325943763867155
Trained batch 332 in epoch 19, gen_loss = 0.8759110096517626, disc_loss = 0.05352463546787967
Trained batch 333 in epoch 19, gen_loss = 0.8752999788451338, disc_loss = 0.05349313266279767
Trained batch 334 in epoch 19, gen_loss = 0.8753578571241294, disc_loss = 0.05354127531815598
Trained batch 335 in epoch 19, gen_loss = 0.8745056664837259, disc_loss = 0.053693823132475484
Trained batch 336 in epoch 19, gen_loss = 0.8745309598191202, disc_loss = 0.05377046148588422
Trained batch 337 in epoch 19, gen_loss = 0.8742856929111763, disc_loss = 0.05365356604689898
Trained batch 338 in epoch 19, gen_loss = 0.8738763380718794, disc_loss = 0.053682623932462266
Trained batch 339 in epoch 19, gen_loss = 0.8740294138298316, disc_loss = 0.054156852427267414
Trained batch 340 in epoch 19, gen_loss = 0.8735877080571967, disc_loss = 0.05418691452172014
Trained batch 341 in epoch 19, gen_loss = 0.8732643459449735, disc_loss = 0.054109644843265414
Trained batch 342 in epoch 19, gen_loss = 0.873935302648878, disc_loss = 0.05408665067692757
Trained batch 343 in epoch 19, gen_loss = 0.8738504326794037, disc_loss = 0.05396243635981972
Trained batch 344 in epoch 19, gen_loss = 0.8727484142434769, disc_loss = 0.05437671784716456
Trained batch 345 in epoch 19, gen_loss = 0.8733621256027607, disc_loss = 0.054484210764407855
Trained batch 346 in epoch 19, gen_loss = 0.8745506162773978, disc_loss = 0.054516218115524616
Trained batch 347 in epoch 19, gen_loss = 0.874339988776322, disc_loss = 0.054480251423939634
Trained batch 348 in epoch 19, gen_loss = 0.8739504739855627, disc_loss = 0.054708164352069696
Trained batch 349 in epoch 19, gen_loss = 0.8732641583681107, disc_loss = 0.054773350513673255
Trained batch 350 in epoch 19, gen_loss = 0.8749968885865986, disc_loss = 0.05524670847020301
Trained batch 351 in epoch 19, gen_loss = 0.8746133679524064, disc_loss = 0.055184340047575955
Trained batch 352 in epoch 19, gen_loss = 0.8745302487871802, disc_loss = 0.0551367347160349
Trained batch 353 in epoch 19, gen_loss = 0.874611561833802, disc_loss = 0.055207580281947714
Trained batch 354 in epoch 19, gen_loss = 0.8747458311033921, disc_loss = 0.055132179378046535
Trained batch 355 in epoch 19, gen_loss = 0.8754092757119222, disc_loss = 0.05503664288298342
Trained batch 356 in epoch 19, gen_loss = 0.8746679873526597, disc_loss = 0.05530622615205014
Trained batch 357 in epoch 19, gen_loss = 0.8759281750997352, disc_loss = 0.055955981795400296
Trained batch 358 in epoch 19, gen_loss = 0.8754425423224989, disc_loss = 0.0561734981391278
Trained batch 359 in epoch 19, gen_loss = 0.875026233577066, disc_loss = 0.056191259923960186
Trained batch 360 in epoch 19, gen_loss = 0.8747410535647268, disc_loss = 0.056162696807720076
Trained batch 361 in epoch 19, gen_loss = 0.8748301339248268, disc_loss = 0.056078218027836135
Trained batch 362 in epoch 19, gen_loss = 0.8744116856539546, disc_loss = 0.05620524028736903
Trained batch 363 in epoch 19, gen_loss = 0.8743136699546824, disc_loss = 0.05610257953758464
Trained batch 364 in epoch 19, gen_loss = 0.8741108722066226, disc_loss = 0.05602129601477964
Trained batch 365 in epoch 19, gen_loss = 0.8743938325695653, disc_loss = 0.05590096210597765
Trained batch 366 in epoch 19, gen_loss = 0.8754390764788645, disc_loss = 0.056237814139716874
Trained batch 367 in epoch 19, gen_loss = 0.8750137559583654, disc_loss = 0.05641866202906543
Trained batch 368 in epoch 19, gen_loss = 0.8753541235516711, disc_loss = 0.05631901931931292
Trained batch 369 in epoch 19, gen_loss = 0.8742641363594983, disc_loss = 0.057172107277438045
Trained batch 370 in epoch 19, gen_loss = 0.8743213395866744, disc_loss = 0.05748242089986761
Trained batch 371 in epoch 19, gen_loss = 0.8744509482896456, disc_loss = 0.05756866287374969
Trained batch 372 in epoch 19, gen_loss = 0.8742095650680582, disc_loss = 0.0574840770587425
Trained batch 373 in epoch 19, gen_loss = 0.8737070147685189, disc_loss = 0.057533933411297554
Trained batch 374 in epoch 19, gen_loss = 0.8733558122316997, disc_loss = 0.0575587949094673
Trained batch 375 in epoch 19, gen_loss = 0.8737066554579329, disc_loss = 0.05812486714282212
Trained batch 376 in epoch 19, gen_loss = 0.8729525565784869, disc_loss = 0.05824208610743008
Trained batch 377 in epoch 19, gen_loss = 0.872289646397192, disc_loss = 0.05836966298101716
Trained batch 378 in epoch 19, gen_loss = 0.8722446941448705, disc_loss = 0.05837681025910464
Trained batch 379 in epoch 19, gen_loss = 0.8715881258249283, disc_loss = 0.058422831851547875
Trained batch 380 in epoch 19, gen_loss = 0.8715740614362902, disc_loss = 0.05834156816844826
Trained batch 381 in epoch 19, gen_loss = 0.8717379969452064, disc_loss = 0.058407135896570005
Trained batch 382 in epoch 19, gen_loss = 0.8716134064813819, disc_loss = 0.058314675113852514
Trained batch 383 in epoch 19, gen_loss = 0.871017519539843, disc_loss = 0.05831759772627265
Trained batch 384 in epoch 19, gen_loss = 0.8709288700834498, disc_loss = 0.058209574995441486
Trained batch 385 in epoch 19, gen_loss = 0.8703536457657196, disc_loss = 0.05836538734865119
Trained batch 386 in epoch 19, gen_loss = 0.8696641763359385, disc_loss = 0.05839944370836982
Trained batch 387 in epoch 19, gen_loss = 0.8699967621527996, disc_loss = 0.0584936475311646
Trained batch 388 in epoch 19, gen_loss = 0.8698048940967471, disc_loss = 0.058519725760823274
Trained batch 389 in epoch 19, gen_loss = 0.869022902005758, disc_loss = 0.05865461919814921
Trained batch 390 in epoch 19, gen_loss = 0.8688322625806569, disc_loss = 0.05856164282216402
Trained batch 391 in epoch 19, gen_loss = 0.8689675907395324, disc_loss = 0.058605897719069024
Trained batch 392 in epoch 19, gen_loss = 0.8687269631536255, disc_loss = 0.058507717756018915
Trained batch 393 in epoch 19, gen_loss = 0.8676258463998736, disc_loss = 0.05876877723228621
Trained batch 394 in epoch 19, gen_loss = 0.8682363083845452, disc_loss = 0.05898008215347234
Trained batch 395 in epoch 19, gen_loss = 0.8692840812633736, disc_loss = 0.05890133420847394
Trained batch 396 in epoch 19, gen_loss = 0.8686893490009404, disc_loss = 0.05896440158558244
Trained batch 397 in epoch 19, gen_loss = 0.8680825186284942, disc_loss = 0.05903127022794256
Trained batch 398 in epoch 19, gen_loss = 0.8680862867294398, disc_loss = 0.05925656250913751
Trained batch 399 in epoch 19, gen_loss = 0.8671974933892489, disc_loss = 0.05938058446045034
Trained batch 400 in epoch 19, gen_loss = 0.8678963167263088, disc_loss = 0.059479131633903545
Trained batch 401 in epoch 19, gen_loss = 0.8681824053846189, disc_loss = 0.059359586578724324
Trained batch 402 in epoch 19, gen_loss = 0.867919007468756, disc_loss = 0.05927029867118072
Trained batch 403 in epoch 19, gen_loss = 0.8677927039489888, disc_loss = 0.059218784391944584
Trained batch 404 in epoch 19, gen_loss = 0.8680952589453003, disc_loss = 0.05910756287084502
Trained batch 405 in epoch 19, gen_loss = 0.8685049170196937, disc_loss = 0.058987629621661285
Trained batch 406 in epoch 19, gen_loss = 0.8681357178553316, disc_loss = 0.05892561213056161
Trained batch 407 in epoch 19, gen_loss = 0.8684906745512112, disc_loss = 0.05897519901718981
Trained batch 408 in epoch 19, gen_loss = 0.8680253262770496, disc_loss = 0.05890591773102037
Trained batch 409 in epoch 19, gen_loss = 0.8677137473007528, disc_loss = 0.058798701830617174
Trained batch 410 in epoch 19, gen_loss = 0.8674078981806762, disc_loss = 0.058746224968329326
Trained batch 411 in epoch 19, gen_loss = 0.8671185162316248, disc_loss = 0.0586308743183058
Trained batch 412 in epoch 19, gen_loss = 0.8672309273236023, disc_loss = 0.058522071834815975
Trained batch 413 in epoch 19, gen_loss = 0.8673025367484577, disc_loss = 0.05842742582688621
Trained batch 414 in epoch 19, gen_loss = 0.8672403120850942, disc_loss = 0.05837547677311014
Trained batch 415 in epoch 19, gen_loss = 0.8681716435373976, disc_loss = 0.05829051607221258
Trained batch 416 in epoch 19, gen_loss = 0.8686748457898339, disc_loss = 0.05839219016784565
Trained batch 417 in epoch 19, gen_loss = 0.8684296081083243, disc_loss = 0.05838538417659486
Trained batch 418 in epoch 19, gen_loss = 0.8683395696568318, disc_loss = 0.05831814417837806
Trained batch 419 in epoch 19, gen_loss = 0.869181230877127, disc_loss = 0.058266060277154405
Trained batch 420 in epoch 19, gen_loss = 0.8686615569149797, disc_loss = 0.05826426884203689
Trained batch 421 in epoch 19, gen_loss = 0.8680950194879731, disc_loss = 0.05828860290105768
Trained batch 422 in epoch 19, gen_loss = 0.868050840799972, disc_loss = 0.05819440680725531
Trained batch 423 in epoch 19, gen_loss = 0.8688040685681802, disc_loss = 0.058234044685652304
Trained batch 424 in epoch 19, gen_loss = 0.8682341469736661, disc_loss = 0.05826959187603172
Trained batch 425 in epoch 19, gen_loss = 0.8680106111115693, disc_loss = 0.05820062803869691
Trained batch 426 in epoch 19, gen_loss = 0.8686922431969252, disc_loss = 0.058434527830833645
Trained batch 427 in epoch 19, gen_loss = 0.8689358538695585, disc_loss = 0.058353120980079276
Trained batch 428 in epoch 19, gen_loss = 0.8682820804608173, disc_loss = 0.058446224940623785
Trained batch 429 in epoch 19, gen_loss = 0.868932275092879, disc_loss = 0.058522005982393786
Trained batch 430 in epoch 19, gen_loss = 0.8687870167109363, disc_loss = 0.05851116412256579
Trained batch 431 in epoch 19, gen_loss = 0.8679121633370718, disc_loss = 0.05895126099305883
Trained batch 432 in epoch 19, gen_loss = 0.8683962516366197, disc_loss = 0.059055800548610524
Trained batch 433 in epoch 19, gen_loss = 0.8684843339128978, disc_loss = 0.0589919612551975
Trained batch 434 in epoch 19, gen_loss = 0.8679294299805301, disc_loss = 0.05919096038794552
Trained batch 435 in epoch 19, gen_loss = 0.867628972874869, disc_loss = 0.05921917498098909
Trained batch 436 in epoch 19, gen_loss = 0.8679551910481137, disc_loss = 0.05919748371322075
Trained batch 437 in epoch 19, gen_loss = 0.8681473755128851, disc_loss = 0.059084053024794206
Trained batch 438 in epoch 19, gen_loss = 0.868405718059366, disc_loss = 0.05897773999470479
Trained batch 439 in epoch 19, gen_loss = 0.8679362406784837, disc_loss = 0.059004280922553415
Trained batch 440 in epoch 19, gen_loss = 0.8676433811923003, disc_loss = 0.059046644188438344
Trained batch 441 in epoch 19, gen_loss = 0.8674062775001267, disc_loss = 0.05900029631066073
Trained batch 442 in epoch 19, gen_loss = 0.8671961881506255, disc_loss = 0.05896259014627162
Trained batch 443 in epoch 19, gen_loss = 0.8666821563834542, disc_loss = 0.05900306970631989
Trained batch 444 in epoch 19, gen_loss = 0.8675184229786477, disc_loss = 0.05894216646785649
Trained batch 445 in epoch 19, gen_loss = 0.8679509960749758, disc_loss = 0.05890291556193923
Trained batch 446 in epoch 19, gen_loss = 0.8677197122733865, disc_loss = 0.058889364639309626
Trained batch 447 in epoch 19, gen_loss = 0.867870452547712, disc_loss = 0.05877554164804418
Trained batch 448 in epoch 19, gen_loss = 0.8676804929374321, disc_loss = 0.058836434419185984
Trained batch 449 in epoch 19, gen_loss = 0.8676003958119286, disc_loss = 0.05872700616199937
Trained batch 450 in epoch 19, gen_loss = 0.8676434857089345, disc_loss = 0.058627962775966214
Trained batch 451 in epoch 19, gen_loss = 0.8673971040850192, disc_loss = 0.0585786709304388
Trained batch 452 in epoch 19, gen_loss = 0.8675472454782617, disc_loss = 0.05848610052370176
Trained batch 453 in epoch 19, gen_loss = 0.8672683307252792, disc_loss = 0.058428032872459894
Trained batch 454 in epoch 19, gen_loss = 0.8674695528470553, disc_loss = 0.05847654634022287
Trained batch 455 in epoch 19, gen_loss = 0.8667495134368277, disc_loss = 0.058834898202851614
Trained batch 456 in epoch 19, gen_loss = 0.8671861896107964, disc_loss = 0.058768702673988676
Trained batch 457 in epoch 19, gen_loss = 0.8677042619890522, disc_loss = 0.05878637360071349
Trained batch 458 in epoch 19, gen_loss = 0.8675636566022902, disc_loss = 0.058730105931357295
Trained batch 459 in epoch 19, gen_loss = 0.8670035837785057, disc_loss = 0.05877539196314857
Trained batch 460 in epoch 19, gen_loss = 0.8670754863228043, disc_loss = 0.05868905635526375
Trained batch 461 in epoch 19, gen_loss = 0.8680009706453844, disc_loss = 0.059344554439920816
Trained batch 462 in epoch 19, gen_loss = 0.8675815645870844, disc_loss = 0.05936273966149526
Trained batch 463 in epoch 19, gen_loss = 0.86693651164914, disc_loss = 0.059512617210014565
Trained batch 464 in epoch 19, gen_loss = 0.8673798905905857, disc_loss = 0.05968445307044413
Trained batch 465 in epoch 19, gen_loss = 0.8674599180405743, disc_loss = 0.05958778301929424
Trained batch 466 in epoch 19, gen_loss = 0.8669845936640427, disc_loss = 0.0596012887066306
Trained batch 467 in epoch 19, gen_loss = 0.8665534681998767, disc_loss = 0.05963600205126195
Trained batch 468 in epoch 19, gen_loss = 0.8665241937139141, disc_loss = 0.05953857140528209
Trained batch 469 in epoch 19, gen_loss = 0.8662694871425629, disc_loss = 0.05946040545352437
Trained batch 470 in epoch 19, gen_loss = 0.8664153544766129, disc_loss = 0.05941056098191823
Trained batch 471 in epoch 19, gen_loss = 0.8659082955475581, disc_loss = 0.05956391958910498
Trained batch 472 in epoch 19, gen_loss = 0.8667068555793601, disc_loss = 0.05980430105819227
Trained batch 473 in epoch 19, gen_loss = 0.8660779086094869, disc_loss = 0.059802090013321124
Trained batch 474 in epoch 19, gen_loss = 0.8663013067998384, disc_loss = 0.05969731422337262
Trained batch 475 in epoch 19, gen_loss = 0.8662047148251734, disc_loss = 0.05974796890699845
Trained batch 476 in epoch 19, gen_loss = 0.8660408673296435, disc_loss = 0.05973620274332615
Trained batch 477 in epoch 19, gen_loss = 0.8656168816977465, disc_loss = 0.05972609971844782
Trained batch 478 in epoch 19, gen_loss = 0.8659846857345677, disc_loss = 0.05968495676612835
Trained batch 479 in epoch 19, gen_loss = 0.8659892064829667, disc_loss = 0.059621409234629635
Trained batch 480 in epoch 19, gen_loss = 0.8655924852821286, disc_loss = 0.05982071914169899
Trained batch 481 in epoch 19, gen_loss = 0.8652151410015787, disc_loss = 0.05988511908509579
Trained batch 482 in epoch 19, gen_loss = 0.8652322766203318, disc_loss = 0.05978239625480265
Trained batch 483 in epoch 19, gen_loss = 0.8655057069191263, disc_loss = 0.059699964013974344
Trained batch 484 in epoch 19, gen_loss = 0.8656424990634328, disc_loss = 0.059592694930309796
Trained batch 485 in epoch 19, gen_loss = 0.8655877332873796, disc_loss = 0.05951904228681491
Trained batch 486 in epoch 19, gen_loss = 0.8651481153294291, disc_loss = 0.05954402061638248
Trained batch 487 in epoch 19, gen_loss = 0.8652925681872446, disc_loss = 0.05951278361197958
Trained batch 488 in epoch 19, gen_loss = 0.8656615074914413, disc_loss = 0.05948514083651769
Trained batch 489 in epoch 19, gen_loss = 0.865615072299023, disc_loss = 0.05941349524073303
Trained batch 490 in epoch 19, gen_loss = 0.8656973267038582, disc_loss = 0.059348817155061025
Trained batch 491 in epoch 19, gen_loss = 0.865128205195675, disc_loss = 0.059399892075358306
Trained batch 492 in epoch 19, gen_loss = 0.8654178660249613, disc_loss = 0.059381361528437655
Trained batch 493 in epoch 19, gen_loss = 0.8654001257438891, disc_loss = 0.05928471664754817
Trained batch 494 in epoch 19, gen_loss = 0.8657179689166522, disc_loss = 0.05917799277983681
Trained batch 495 in epoch 19, gen_loss = 0.8656657964231507, disc_loss = 0.05909892608084896
Trained batch 496 in epoch 19, gen_loss = 0.8656756440158822, disc_loss = 0.05902006441982129
Trained batch 497 in epoch 19, gen_loss = 0.8661301838585651, disc_loss = 0.058944239596234085
Trained batch 498 in epoch 19, gen_loss = 0.8662924641119932, disc_loss = 0.05884751988731638
Trained batch 499 in epoch 19, gen_loss = 0.8664987834692002, disc_loss = 0.058799024528823796
Trained batch 500 in epoch 19, gen_loss = 0.8666609167576788, disc_loss = 0.05870219897348694
Trained batch 501 in epoch 19, gen_loss = 0.8664310384556592, disc_loss = 0.05868763769271809
Trained batch 502 in epoch 19, gen_loss = 0.865943760331535, disc_loss = 0.058696093147890885
Trained batch 503 in epoch 19, gen_loss = 0.8659869635862018, disc_loss = 0.058671062053661675
Trained batch 504 in epoch 19, gen_loss = 0.8663269725176368, disc_loss = 0.05859068776988009
Trained batch 505 in epoch 19, gen_loss = 0.8662845925851301, disc_loss = 0.0585549984140167
Trained batch 506 in epoch 19, gen_loss = 0.8658596385395269, disc_loss = 0.0586084914393723
Trained batch 507 in epoch 19, gen_loss = 0.8658197098594951, disc_loss = 0.05863298190020641
Trained batch 508 in epoch 19, gen_loss = 0.8654536158724712, disc_loss = 0.05860031621845362
Trained batch 509 in epoch 19, gen_loss = 0.8650975706530553, disc_loss = 0.05866487751094004
Trained batch 510 in epoch 19, gen_loss = 0.8655531893970915, disc_loss = 0.058664968812295076
Trained batch 511 in epoch 19, gen_loss = 0.865795427467674, disc_loss = 0.05886116403689812
Trained batch 512 in epoch 19, gen_loss = 0.8650630616072791, disc_loss = 0.05910548621055182
Trained batch 513 in epoch 19, gen_loss = 0.8659964884533492, disc_loss = 0.059228090963467726
Trained batch 514 in epoch 19, gen_loss = 0.8658346343966363, disc_loss = 0.059143720005720275
Trained batch 515 in epoch 19, gen_loss = 0.865425586122875, disc_loss = 0.059199483187096696
Trained batch 516 in epoch 19, gen_loss = 0.8647821923750282, disc_loss = 0.059353664231881126
Trained batch 517 in epoch 19, gen_loss = 0.8645190794495542, disc_loss = 0.05942651244243571
Trained batch 518 in epoch 19, gen_loss = 0.8653144014134343, disc_loss = 0.059598414197757923
Trained batch 519 in epoch 19, gen_loss = 0.8648227994258587, disc_loss = 0.05967535190552903
Trained batch 520 in epoch 19, gen_loss = 0.8648155379661443, disc_loss = 0.0596075531286536
Trained batch 521 in epoch 19, gen_loss = 0.8644421217085301, disc_loss = 0.0595534090835858
Trained batch 522 in epoch 19, gen_loss = 0.8646434862344716, disc_loss = 0.05947963128678401
Trained batch 523 in epoch 19, gen_loss = 0.8648601097005014, disc_loss = 0.05939984816314923
Trained batch 524 in epoch 19, gen_loss = 0.8646062125478472, disc_loss = 0.05941871445714718
Trained batch 525 in epoch 19, gen_loss = 0.8643634995806806, disc_loss = 0.05939774824210758
Trained batch 526 in epoch 19, gen_loss = 0.8646317047457541, disc_loss = 0.059397822199124255
Trained batch 527 in epoch 19, gen_loss = 0.8645522885701873, disc_loss = 0.05936493061281825
Trained batch 528 in epoch 19, gen_loss = 0.8642210428566022, disc_loss = 0.05935154687560433
Trained batch 529 in epoch 19, gen_loss = 0.8641240931906791, disc_loss = 0.05955770956088771
Trained batch 530 in epoch 19, gen_loss = 0.8641423741302922, disc_loss = 0.05951791904821094
Trained batch 531 in epoch 19, gen_loss = 0.8636302508805928, disc_loss = 0.059541482967674676
Trained batch 532 in epoch 19, gen_loss = 0.8638789904274145, disc_loss = 0.059489051162266986
Trained batch 533 in epoch 19, gen_loss = 0.8643695513407389, disc_loss = 0.059536257632293005
Trained batch 534 in epoch 19, gen_loss = 0.8637500465473282, disc_loss = 0.059690087956211
Trained batch 535 in epoch 19, gen_loss = 0.8634668238349815, disc_loss = 0.05966558795224236
Trained batch 536 in epoch 19, gen_loss = 0.8638874353421245, disc_loss = 0.060058655504317646
Trained batch 537 in epoch 19, gen_loss = 0.8636908468039063, disc_loss = 0.059979104861914836
Trained batch 538 in epoch 19, gen_loss = 0.8634570640181788, disc_loss = 0.0599485976830581
Trained batch 539 in epoch 19, gen_loss = 0.862885821307147, disc_loss = 0.06000348615753292
Trained batch 540 in epoch 19, gen_loss = 0.863282869130979, disc_loss = 0.0599809901818096
Trained batch 541 in epoch 19, gen_loss = 0.8636628228799883, disc_loss = 0.06007575539174417
Trained batch 542 in epoch 19, gen_loss = 0.8634628001497595, disc_loss = 0.060049199637258854
Trained batch 543 in epoch 19, gen_loss = 0.8633203945834848, disc_loss = 0.060050380648189114
Trained batch 544 in epoch 19, gen_loss = 0.863271675744188, disc_loss = 0.05999489362274698
Trained batch 545 in epoch 19, gen_loss = 0.8636344683257652, disc_loss = 0.06002486241902924
Trained batch 546 in epoch 19, gen_loss = 0.8635115825062042, disc_loss = 0.06000233553877778
Trained batch 547 in epoch 19, gen_loss = 0.8636449100109782, disc_loss = 0.05992469186027854
Trained batch 548 in epoch 19, gen_loss = 0.8632842320779199, disc_loss = 0.05990912117834164
Trained batch 549 in epoch 19, gen_loss = 0.8634152615070343, disc_loss = 0.05983982424082404
Trained batch 550 in epoch 19, gen_loss = 0.8630707485706101, disc_loss = 0.05981089326108514
Trained batch 551 in epoch 19, gen_loss = 0.8628816389735194, disc_loss = 0.059832927797063916
Trained batch 552 in epoch 19, gen_loss = 0.8632166973074349, disc_loss = 0.05975793244040977
Trained batch 553 in epoch 19, gen_loss = 0.8636986551947542, disc_loss = 0.059706631993256265
Trained batch 554 in epoch 19, gen_loss = 0.8636114112965696, disc_loss = 0.05963171395884306
Trained batch 555 in epoch 19, gen_loss = 0.8637007159723652, disc_loss = 0.059587279363977556
Trained batch 556 in epoch 19, gen_loss = 0.8638734646288668, disc_loss = 0.05959224301228162
Trained batch 557 in epoch 19, gen_loss = 0.8640576150254964, disc_loss = 0.05951204909909663
Trained batch 558 in epoch 19, gen_loss = 0.8638954896193284, disc_loss = 0.05947064373672195
Trained batch 559 in epoch 19, gen_loss = 0.8642711611730712, disc_loss = 0.059395929478341714
Trained batch 560 in epoch 19, gen_loss = 0.8646283568332964, disc_loss = 0.05942974325830579
Trained batch 561 in epoch 19, gen_loss = 0.8643040593408605, disc_loss = 0.05949451123344384
Trained batch 562 in epoch 19, gen_loss = 0.8639485541711268, disc_loss = 0.059492316427036826
Trained batch 563 in epoch 19, gen_loss = 0.8643163951998907, disc_loss = 0.05942088302393305
Trained batch 564 in epoch 19, gen_loss = 0.8645610072971446, disc_loss = 0.05937453583789478
Trained batch 565 in epoch 19, gen_loss = 0.8643936203141095, disc_loss = 0.059342571217468
Trained batch 566 in epoch 19, gen_loss = 0.8647997650519881, disc_loss = 0.059340530361756814
Trained batch 567 in epoch 19, gen_loss = 0.8648026163729143, disc_loss = 0.05928013422837953
Trained batch 568 in epoch 19, gen_loss = 0.865041646471342, disc_loss = 0.05919231684479096
Trained batch 569 in epoch 19, gen_loss = 0.8651713463298062, disc_loss = 0.05911716064519919
Trained batch 570 in epoch 19, gen_loss = 0.8657248654841542, disc_loss = 0.059053362008745273
Trained batch 571 in epoch 19, gen_loss = 0.8654963169898187, disc_loss = 0.05908558694108461
Trained batch 572 in epoch 19, gen_loss = 0.8657440777224396, disc_loss = 0.05899795487987927
Trained batch 573 in epoch 19, gen_loss = 0.8662876569850935, disc_loss = 0.05895774244194532
Trained batch 574 in epoch 19, gen_loss = 0.8662274951520174, disc_loss = 0.05892882374236765
Trained batch 575 in epoch 19, gen_loss = 0.8660349843816625, disc_loss = 0.05888804015881356
Trained batch 576 in epoch 19, gen_loss = 0.8659395818280595, disc_loss = 0.058847245163860466
Trained batch 577 in epoch 19, gen_loss = 0.8659652217861691, disc_loss = 0.058777025274797036
Trained batch 578 in epoch 19, gen_loss = 0.8657746736043888, disc_loss = 0.05869922657547091
Trained batch 579 in epoch 19, gen_loss = 0.8661843806505203, disc_loss = 0.05861435014963279
Trained batch 580 in epoch 19, gen_loss = 0.8662719674241728, disc_loss = 0.058537696533886116
Trained batch 581 in epoch 19, gen_loss = 0.8661465332475314, disc_loss = 0.058490381402498
Trained batch 582 in epoch 19, gen_loss = 0.8660720651186555, disc_loss = 0.058424660628485794
Trained batch 583 in epoch 19, gen_loss = 0.8667153410919725, disc_loss = 0.05839759346387949
Trained batch 584 in epoch 19, gen_loss = 0.8669730751942366, disc_loss = 0.0583161600976864
Trained batch 585 in epoch 19, gen_loss = 0.8669148006129997, disc_loss = 0.058239030960864635
Trained batch 586 in epoch 19, gen_loss = 0.8668369172582026, disc_loss = 0.05820459429590346
Trained batch 587 in epoch 19, gen_loss = 0.8666005872544789, disc_loss = 0.058158864305975534
Trained batch 588 in epoch 19, gen_loss = 0.8668572190257203, disc_loss = 0.05808716576707712
Trained batch 589 in epoch 19, gen_loss = 0.8672148354982926, disc_loss = 0.05845700668534106
Trained batch 590 in epoch 19, gen_loss = 0.8672234492656946, disc_loss = 0.058383309385580104
Trained batch 591 in epoch 19, gen_loss = 0.8669525566133293, disc_loss = 0.05838679814336796
Trained batch 592 in epoch 19, gen_loss = 0.8666945938115176, disc_loss = 0.05842987421670737
Trained batch 593 in epoch 19, gen_loss = 0.8669330856013379, disc_loss = 0.05846219466017678
Trained batch 594 in epoch 19, gen_loss = 0.8671646658112021, disc_loss = 0.05838687008622439
Trained batch 595 in epoch 19, gen_loss = 0.8671646737212303, disc_loss = 0.05832584921798775
Trained batch 596 in epoch 19, gen_loss = 0.8672514516903926, disc_loss = 0.05839358816247814
Trained batch 597 in epoch 19, gen_loss = 0.8668784923776734, disc_loss = 0.05847034486941993
Trained batch 598 in epoch 19, gen_loss = 0.8669969305172189, disc_loss = 0.05841662983902931
Trained batch 599 in epoch 19, gen_loss = 0.8671032704909643, disc_loss = 0.058354994841696074
Trained batch 600 in epoch 19, gen_loss = 0.8670776711525814, disc_loss = 0.05830144203545374
Trained batch 601 in epoch 19, gen_loss = 0.8672101677850236, disc_loss = 0.05822095285522507
Trained batch 602 in epoch 19, gen_loss = 0.8669713097029855, disc_loss = 0.058179042128317836
Trained batch 603 in epoch 19, gen_loss = 0.8670118011978288, disc_loss = 0.05825556650070091
Trained batch 604 in epoch 19, gen_loss = 0.8667322181473094, disc_loss = 0.05832795305639382
Trained batch 605 in epoch 19, gen_loss = 0.866476996602005, disc_loss = 0.05827506544397339
Trained batch 606 in epoch 19, gen_loss = 0.8667240461957514, disc_loss = 0.05824952058362141
Trained batch 607 in epoch 19, gen_loss = 0.8665895582617897, disc_loss = 0.05819099940019537
Trained batch 608 in epoch 19, gen_loss = 0.8670852660937066, disc_loss = 0.058174805260723696
Trained batch 609 in epoch 19, gen_loss = 0.8671374340526393, disc_loss = 0.05812769535638881
Trained batch 610 in epoch 19, gen_loss = 0.8675174802883167, disc_loss = 0.05809337267524116
Trained batch 611 in epoch 19, gen_loss = 0.8671789247226092, disc_loss = 0.05806207540368941
Trained batch 612 in epoch 19, gen_loss = 0.8672021759664837, disc_loss = 0.05800595463953949
Trained batch 613 in epoch 19, gen_loss = 0.8670772009253114, disc_loss = 0.05801250686162191
Trained batch 614 in epoch 19, gen_loss = 0.8674507152743456, disc_loss = 0.05797893584334875
Trained batch 615 in epoch 19, gen_loss = 0.8676362740142005, disc_loss = 0.05805384387132143
Trained batch 616 in epoch 19, gen_loss = 0.8675042874809216, disc_loss = 0.05799834620180378
Trained batch 617 in epoch 19, gen_loss = 0.8674183124284528, disc_loss = 0.057945442326445266
Trained batch 618 in epoch 19, gen_loss = 0.8671219265133576, disc_loss = 0.05799573271494714
Trained batch 619 in epoch 19, gen_loss = 0.8675374974166193, disc_loss = 0.057940758678371146
Trained batch 620 in epoch 19, gen_loss = 0.8675891030429834, disc_loss = 0.05788347305094106
Trained batch 621 in epoch 19, gen_loss = 0.867215371016904, disc_loss = 0.05786107925599339
Trained batch 622 in epoch 19, gen_loss = 0.8680883697675089, disc_loss = 0.05787741458103252
Trained batch 623 in epoch 19, gen_loss = 0.8684224717510052, disc_loss = 0.05799837030234556
Trained batch 624 in epoch 19, gen_loss = 0.8683067798614502, disc_loss = 0.057995268685370686
Trained batch 625 in epoch 19, gen_loss = 0.8680103546895158, disc_loss = 0.058032914598177845
Trained batch 626 in epoch 19, gen_loss = 0.8684180252479784, disc_loss = 0.05804471458357416
Trained batch 627 in epoch 19, gen_loss = 0.86839385482536, disc_loss = 0.05798335534825945
Trained batch 628 in epoch 19, gen_loss = 0.8680226713750624, disc_loss = 0.05808876129163396
Trained batch 629 in epoch 19, gen_loss = 0.8676620567601825, disc_loss = 0.05824449200789252
Trained batch 630 in epoch 19, gen_loss = 0.8682246209135525, disc_loss = 0.058559191598455095
Trained batch 631 in epoch 19, gen_loss = 0.8679525219375575, disc_loss = 0.058548448879206905
Trained batch 632 in epoch 19, gen_loss = 0.8677481654884315, disc_loss = 0.05849880122286849
Trained batch 633 in epoch 19, gen_loss = 0.867590818871459, disc_loss = 0.05843122987802308
Trained batch 634 in epoch 19, gen_loss = 0.866949905842308, disc_loss = 0.058567363942613984
Trained batch 635 in epoch 19, gen_loss = 0.8673196419042611, disc_loss = 0.05864929235994277
Trained batch 636 in epoch 19, gen_loss = 0.8675987738267967, disc_loss = 0.058595472666781445
Trained batch 637 in epoch 19, gen_loss = 0.8677198971887368, disc_loss = 0.058528588536607105
Trained batch 638 in epoch 19, gen_loss = 0.8678867094020515, disc_loss = 0.05845777279768775
Trained batch 639 in epoch 19, gen_loss = 0.8675644852221012, disc_loss = 0.05853046506890678
Trained batch 640 in epoch 19, gen_loss = 0.8674336938701814, disc_loss = 0.058526450425950165
Trained batch 641 in epoch 19, gen_loss = 0.867556408743992, disc_loss = 0.05846860198916235
Trained batch 642 in epoch 19, gen_loss = 0.8676089500750576, disc_loss = 0.058591980325611394
Trained batch 643 in epoch 19, gen_loss = 0.8674118402211562, disc_loss = 0.058607711295469996
Trained batch 644 in epoch 19, gen_loss = 0.8671338701432989, disc_loss = 0.05861748740611266
Trained batch 645 in epoch 19, gen_loss = 0.8671588525868053, disc_loss = 0.05863949660595287
Trained batch 646 in epoch 19, gen_loss = 0.8666768226041307, disc_loss = 0.058726882577155484
Trained batch 647 in epoch 19, gen_loss = 0.867028552165002, disc_loss = 0.05870269241895136
Trained batch 648 in epoch 19, gen_loss = 0.8671586778939046, disc_loss = 0.05863191284173282
Trained batch 649 in epoch 19, gen_loss = 0.8667770433425903, disc_loss = 0.05868935593403876
Trained batch 650 in epoch 19, gen_loss = 0.866470531933868, disc_loss = 0.05871587885635263
Trained batch 651 in epoch 19, gen_loss = 0.866175245562214, disc_loss = 0.05877665798622612
Trained batch 652 in epoch 19, gen_loss = 0.8665654012109018, disc_loss = 0.059070688640273775
Trained batch 653 in epoch 19, gen_loss = 0.866433450205975, disc_loss = 0.05903375793934803
Trained batch 654 in epoch 19, gen_loss = 0.8663552761987875, disc_loss = 0.0590039957663087
Trained batch 655 in epoch 19, gen_loss = 0.8660660663210764, disc_loss = 0.059002316055007324
Trained batch 656 in epoch 19, gen_loss = 0.8659372137380336, disc_loss = 0.05897040469316791
Trained batch 657 in epoch 19, gen_loss = 0.8661340084662916, disc_loss = 0.05899012716427604
Trained batch 658 in epoch 19, gen_loss = 0.8658077686979847, disc_loss = 0.05899196150126176
Trained batch 659 in epoch 19, gen_loss = 0.8659719343438294, disc_loss = 0.05893184072831928
Trained batch 660 in epoch 19, gen_loss = 0.8659547378905061, disc_loss = 0.05887492492572375
Trained batch 661 in epoch 19, gen_loss = 0.8659650506029677, disc_loss = 0.05879979415127045
Trained batch 662 in epoch 19, gen_loss = 0.8661641915459438, disc_loss = 0.058829195246094805
Trained batch 663 in epoch 19, gen_loss = 0.8664157779281398, disc_loss = 0.05879030445049214
Trained batch 664 in epoch 19, gen_loss = 0.8666258626414421, disc_loss = 0.05872326096015653
Trained batch 665 in epoch 19, gen_loss = 0.866138220012367, disc_loss = 0.05894652907820502
Trained batch 666 in epoch 19, gen_loss = 0.8661122641999504, disc_loss = 0.05889630990627891
Trained batch 667 in epoch 19, gen_loss = 0.8666423950009717, disc_loss = 0.059175800001611205
Trained batch 668 in epoch 19, gen_loss = 0.8664426935449666, disc_loss = 0.05921061292933843
Trained batch 669 in epoch 19, gen_loss = 0.866454555294407, disc_loss = 0.059222635676139106
Trained batch 670 in epoch 19, gen_loss = 0.8659709954048589, disc_loss = 0.05927785787378867
Trained batch 671 in epoch 19, gen_loss = 0.8661483812722421, disc_loss = 0.0592123930227466
Trained batch 672 in epoch 19, gen_loss = 0.8658037237922646, disc_loss = 0.059263434438906706
Trained batch 673 in epoch 19, gen_loss = 0.8659414742749947, disc_loss = 0.059393120311250366
Trained batch 674 in epoch 19, gen_loss = 0.8656033843534964, disc_loss = 0.05939865924211012
Trained batch 675 in epoch 19, gen_loss = 0.8654379614535168, disc_loss = 0.05935215373101958
Trained batch 676 in epoch 19, gen_loss = 0.8654414693573201, disc_loss = 0.05928310660089599
Trained batch 677 in epoch 19, gen_loss = 0.8651225226642811, disc_loss = 0.059273505199475315
Trained batch 678 in epoch 19, gen_loss = 0.8648267530552242, disc_loss = 0.05926258701883223
Trained batch 679 in epoch 19, gen_loss = 0.8647287437144447, disc_loss = 0.0592754744219265
Trained batch 680 in epoch 19, gen_loss = 0.8648144370833858, disc_loss = 0.05938370335538066
Trained batch 681 in epoch 19, gen_loss = 0.8645811068697059, disc_loss = 0.05942512491562259
Trained batch 682 in epoch 19, gen_loss = 0.8644693876080771, disc_loss = 0.05967109062467561
Trained batch 683 in epoch 19, gen_loss = 0.8642336584148351, disc_loss = 0.05966503387766384
Trained batch 684 in epoch 19, gen_loss = 0.8639196572512606, disc_loss = 0.059763917730047106
Trained batch 685 in epoch 19, gen_loss = 0.8640891149335977, disc_loss = 0.0599205973877167
Trained batch 686 in epoch 19, gen_loss = 0.864190452223782, disc_loss = 0.05987889559944926
Trained batch 687 in epoch 19, gen_loss = 0.8642033114162988, disc_loss = 0.05982017462198666
Trained batch 688 in epoch 19, gen_loss = 0.8639493081150968, disc_loss = 0.059819473797814986
Trained batch 689 in epoch 19, gen_loss = 0.8635939899562062, disc_loss = 0.06005320125529408
Trained batch 690 in epoch 19, gen_loss = 0.8639689688227111, disc_loss = 0.060012411286410175
Trained batch 691 in epoch 19, gen_loss = 0.8638034760090657, disc_loss = 0.05997576352243845
Trained batch 692 in epoch 19, gen_loss = 0.8637477062309287, disc_loss = 0.059971651229684876
Trained batch 693 in epoch 19, gen_loss = 0.8637269648591792, disc_loss = 0.05997632443166797
Trained batch 694 in epoch 19, gen_loss = 0.8638679218806808, disc_loss = 0.05991333904575637
Trained batch 695 in epoch 19, gen_loss = 0.8635415314942941, disc_loss = 0.05994228854167928
Trained batch 696 in epoch 19, gen_loss = 0.8633441615480946, disc_loss = 0.05993718699147254
Trained batch 697 in epoch 19, gen_loss = 0.8633239132627033, disc_loss = 0.059942230297369954
Trained batch 698 in epoch 19, gen_loss = 0.8639999032873282, disc_loss = 0.05992903543678838
Trained batch 699 in epoch 19, gen_loss = 0.864044531583786, disc_loss = 0.05987578803207725
Trained batch 700 in epoch 19, gen_loss = 0.8639620336758427, disc_loss = 0.059839155113778894
Trained batch 701 in epoch 19, gen_loss = 0.8640934726451537, disc_loss = 0.05978966477602996
Trained batch 702 in epoch 19, gen_loss = 0.8640213948734116, disc_loss = 0.05981114947410621
Trained batch 703 in epoch 19, gen_loss = 0.863719594580206, disc_loss = 0.05980244723204206
Trained batch 704 in epoch 19, gen_loss = 0.8637957145136299, disc_loss = 0.05974193880968588
Trained batch 705 in epoch 19, gen_loss = 0.8638242539704353, disc_loss = 0.05970391887372027
Trained batch 706 in epoch 19, gen_loss = 0.8637865617386522, disc_loss = 0.05965471501189483
Trained batch 707 in epoch 19, gen_loss = 0.8643914770103444, disc_loss = 0.05968904164343504
Trained batch 708 in epoch 19, gen_loss = 0.8641453430750138, disc_loss = 0.05965126249663353
Trained batch 709 in epoch 19, gen_loss = 0.8643470743172605, disc_loss = 0.05959250071007286
Trained batch 710 in epoch 19, gen_loss = 0.8643901271826775, disc_loss = 0.05953018264923606
Trained batch 711 in epoch 19, gen_loss = 0.8644706760899404, disc_loss = 0.05945794280746617
Trained batch 712 in epoch 19, gen_loss = 0.8644844964878088, disc_loss = 0.05938464085418642
Trained batch 713 in epoch 19, gen_loss = 0.8645511716186833, disc_loss = 0.059313143948510456
Trained batch 714 in epoch 19, gen_loss = 0.8645705063026268, disc_loss = 0.059267974017722
Trained batch 715 in epoch 19, gen_loss = 0.8645389061733331, disc_loss = 0.059210002469809404
Trained batch 716 in epoch 19, gen_loss = 0.8645033727463651, disc_loss = 0.059151398055021606
Trained batch 717 in epoch 19, gen_loss = 0.8649531663460319, disc_loss = 0.05913327584331103
Trained batch 718 in epoch 19, gen_loss = 0.8648966223374527, disc_loss = 0.05906988641179797
Trained batch 719 in epoch 19, gen_loss = 0.864724542780055, disc_loss = 0.05907215877733607
Trained batch 720 in epoch 19, gen_loss = 0.86487636974549, disc_loss = 0.05900932756160875
Trained batch 721 in epoch 19, gen_loss = 0.864963605215675, disc_loss = 0.05899115948205159
Trained batch 722 in epoch 19, gen_loss = 0.8648965235897449, disc_loss = 0.058949193163011046
Trained batch 723 in epoch 19, gen_loss = 0.8650101774799231, disc_loss = 0.0588801464532857
Trained batch 724 in epoch 19, gen_loss = 0.8647413244740716, disc_loss = 0.05896828440178571
Trained batch 725 in epoch 19, gen_loss = 0.8647567727513221, disc_loss = 0.058899864082971265
Trained batch 726 in epoch 19, gen_loss = 0.8648906433762678, disc_loss = 0.05884632376308311
Trained batch 727 in epoch 19, gen_loss = 0.8650282848176065, disc_loss = 0.058877836261072534
Trained batch 728 in epoch 19, gen_loss = 0.8650552775143596, disc_loss = 0.05882851948925845
Trained batch 729 in epoch 19, gen_loss = 0.8648468233134649, disc_loss = 0.05885979724882094
Trained batch 730 in epoch 19, gen_loss = 0.8643869181175076, disc_loss = 0.058989936303061964
Trained batch 731 in epoch 19, gen_loss = 0.8650762596742703, disc_loss = 0.059109005566223276
Trained batch 732 in epoch 19, gen_loss = 0.8656537812533516, disc_loss = 0.059146600175079715
Trained batch 733 in epoch 19, gen_loss = 0.8653046479829326, disc_loss = 0.059189433549792184
Trained batch 734 in epoch 19, gen_loss = 0.8653069569951012, disc_loss = 0.059126871138126876
Trained batch 735 in epoch 19, gen_loss = 0.8652322801720836, disc_loss = 0.059101864233051186
Trained batch 736 in epoch 19, gen_loss = 0.8653484831186292, disc_loss = 0.05904630022982749
Trained batch 737 in epoch 19, gen_loss = 0.8654236438959272, disc_loss = 0.05898256464432269
Trained batch 738 in epoch 19, gen_loss = 0.8650204898217373, disc_loss = 0.05903493245831705
Trained batch 739 in epoch 19, gen_loss = 0.8654473538334305, disc_loss = 0.05908585798712699
Trained batch 740 in epoch 19, gen_loss = 0.8656290956193458, disc_loss = 0.059052729844046546
Trained batch 741 in epoch 19, gen_loss = 0.8655625919929412, disc_loss = 0.05907466299543182
Trained batch 742 in epoch 19, gen_loss = 0.8653101339474982, disc_loss = 0.05906355741319734
Trained batch 743 in epoch 19, gen_loss = 0.8655915012763392, disc_loss = 0.05904861227972233
Trained batch 744 in epoch 19, gen_loss = 0.865389210665786, disc_loss = 0.058985055911185955
Trained batch 745 in epoch 19, gen_loss = 0.865808916715131, disc_loss = 0.05894962414891906
Trained batch 746 in epoch 19, gen_loss = 0.8656542457570353, disc_loss = 0.058950789395590106
Trained batch 747 in epoch 19, gen_loss = 0.8655703824790404, disc_loss = 0.05890599770015753
Trained batch 748 in epoch 19, gen_loss = 0.8656071776223279, disc_loss = 0.05884430455591017
Trained batch 749 in epoch 19, gen_loss = 0.8657586741447448, disc_loss = 0.058794751192753514
Trained batch 750 in epoch 19, gen_loss = 0.8660528642359808, disc_loss = 0.05874171247953839
Trained batch 751 in epoch 19, gen_loss = 0.8659738034326979, disc_loss = 0.058695593054351854
Trained batch 752 in epoch 19, gen_loss = 0.8657077576218056, disc_loss = 0.05875413808266658
Trained batch 753 in epoch 19, gen_loss = 0.8659712411364446, disc_loss = 0.05871751314629393
Trained batch 754 in epoch 19, gen_loss = 0.8663116290869303, disc_loss = 0.05870156634586635
Trained batch 755 in epoch 19, gen_loss = 0.8665214650845402, disc_loss = 0.05864168775314711
Trained batch 756 in epoch 19, gen_loss = 0.8662817495502285, disc_loss = 0.05864440136782264
Trained batch 757 in epoch 19, gen_loss = 0.8661189152414377, disc_loss = 0.05865384624364213
Trained batch 758 in epoch 19, gen_loss = 0.8664011045092808, disc_loss = 0.05868330842119608
Trained batch 759 in epoch 19, gen_loss = 0.8664280257726971, disc_loss = 0.05867250293407491
Trained batch 760 in epoch 19, gen_loss = 0.8660332052999038, disc_loss = 0.05879869460190662
Trained batch 761 in epoch 19, gen_loss = 0.8658364825830684, disc_loss = 0.05878993938065909
Trained batch 762 in epoch 19, gen_loss = 0.8658276547923157, disc_loss = 0.058787897945080214
Trained batch 763 in epoch 19, gen_loss = 0.8658437622779327, disc_loss = 0.05872547127981792
Trained batch 764 in epoch 19, gen_loss = 0.8664292326160505, disc_loss = 0.05869078764545859
Trained batch 765 in epoch 19, gen_loss = 0.866301417350769, disc_loss = 0.05868964705326869
Trained batch 766 in epoch 19, gen_loss = 0.8662547198703423, disc_loss = 0.0587015551784485
Trained batch 767 in epoch 19, gen_loss = 0.8660868290656557, disc_loss = 0.058650697720319535
Trained batch 768 in epoch 19, gen_loss = 0.8661507302204872, disc_loss = 0.05860376838650385
Trained batch 769 in epoch 19, gen_loss = 0.8662324739741041, disc_loss = 0.058544611309763864
Trained batch 770 in epoch 19, gen_loss = 0.8660708879991573, disc_loss = 0.058542414840755334
Trained batch 771 in epoch 19, gen_loss = 0.8660801500082016, disc_loss = 0.058544155010601284
Trained batch 772 in epoch 19, gen_loss = 0.8657926147536195, disc_loss = 0.05860123060761745
Trained batch 773 in epoch 19, gen_loss = 0.8660277438564202, disc_loss = 0.05855140366557822
Trained batch 774 in epoch 19, gen_loss = 0.8665932774543762, disc_loss = 0.058580415694103126
Trained batch 775 in epoch 19, gen_loss = 0.8667925916535338, disc_loss = 0.058523954135322576
Trained batch 776 in epoch 19, gen_loss = 0.8671239428078346, disc_loss = 0.0584686662111206
Trained batch 777 in epoch 19, gen_loss = 0.8671342696046461, disc_loss = 0.05841194927048388
Trained batch 778 in epoch 19, gen_loss = 0.86735117305381, disc_loss = 0.058359726504883004
Trained batch 779 in epoch 19, gen_loss = 0.867357136729436, disc_loss = 0.05831790807334563
Trained batch 780 in epoch 19, gen_loss = 0.8673670318612063, disc_loss = 0.05825799838168769
Trained batch 781 in epoch 19, gen_loss = 0.8674955121848894, disc_loss = 0.0582053081169391
Trained batch 782 in epoch 19, gen_loss = 0.8676229366701986, disc_loss = 0.05822517895609578
Trained batch 783 in epoch 19, gen_loss = 0.8675525793615653, disc_loss = 0.058174128141087876
Trained batch 784 in epoch 19, gen_loss = 0.8674591575458551, disc_loss = 0.05811911359559863
Trained batch 785 in epoch 19, gen_loss = 0.8674817466705507, disc_loss = 0.05809497500001986
Trained batch 786 in epoch 19, gen_loss = 0.8677402108415412, disc_loss = 0.058087990525163224
Trained batch 787 in epoch 19, gen_loss = 0.8679020690736432, disc_loss = 0.05802832226573872
Trained batch 788 in epoch 19, gen_loss = 0.8678295182486753, disc_loss = 0.057971322344184034
Trained batch 789 in epoch 19, gen_loss = 0.8679766283005099, disc_loss = 0.05791641777982535
Testing Epoch 19
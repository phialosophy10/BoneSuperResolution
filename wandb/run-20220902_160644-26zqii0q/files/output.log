wandb: WARNING Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 1.4109073877334595, disc_loss = 0.5821161270141602
Trained batch 1 in epoch 0, gen_loss = 1.3375452160835266, disc_loss = 0.6103419065475464
Trained batch 2 in epoch 0, gen_loss = 1.3882063627243042, disc_loss = 0.6524558067321777
Trained batch 3 in epoch 0, gen_loss = 1.348054677248001, disc_loss = 0.6214110851287842
Trained batch 4 in epoch 0, gen_loss = 1.278073799610138, disc_loss = 0.5541863679885864
Trained batch 5 in epoch 0, gen_loss = 1.216018795967102, disc_loss = 0.503375639518102
Trained batch 6 in epoch 0, gen_loss = 1.148575816835676, disc_loss = 0.4696431841169085
Trained batch 7 in epoch 0, gen_loss = 1.114770546555519, disc_loss = 0.44359439611434937
Trained batch 8 in epoch 0, gen_loss = 1.0886659953329298, disc_loss = 0.41808972424930996
Trained batch 9 in epoch 0, gen_loss = 1.0726941585540772, disc_loss = 0.39330851286649704
Trained batch 10 in epoch 0, gen_loss = 1.0643761591477827, disc_loss = 0.37170559574257245
Trained batch 11 in epoch 0, gen_loss = 1.0517501384019852, disc_loss = 0.35264529411991435
Trained batch 12 in epoch 0, gen_loss = 1.0365373308841999, disc_loss = 0.33729702348892504
Trained batch 13 in epoch 0, gen_loss = 1.0500921308994293, disc_loss = 0.3247951737471989
Trained batch 14 in epoch 0, gen_loss = 1.040873642762502, disc_loss = 0.3151083926359812
Trained batch 15 in epoch 0, gen_loss = 1.0316568575799465, disc_loss = 0.3087335415184498
Trained batch 16 in epoch 0, gen_loss = 1.03118155633702, disc_loss = 0.30487149690880494
Trained batch 17 in epoch 0, gen_loss = 1.0135099523597293, disc_loss = 0.30726304401954013
Trained batch 18 in epoch 0, gen_loss = 1.022914193178478, disc_loss = 0.30869665506638977
Trained batch 19 in epoch 0, gen_loss = 1.024831447005272, disc_loss = 0.30758270993828773
Trained batch 20 in epoch 0, gen_loss = 1.0070488481294542, disc_loss = 0.3078406885975883
Trained batch 21 in epoch 0, gen_loss = 1.0059086138551885, disc_loss = 0.3052729429169135
Trained batch 22 in epoch 0, gen_loss = 1.0121802402579265, disc_loss = 0.30586281872313953
Trained batch 23 in epoch 0, gen_loss = 1.004800205429395, disc_loss = 0.30978170968592167
Trained batch 24 in epoch 0, gen_loss = 0.9974128103256226, disc_loss = 0.3094349807500839
Trained batch 25 in epoch 0, gen_loss = 0.9971004930826334, disc_loss = 0.30772722970980865
Trained batch 26 in epoch 0, gen_loss = 0.9972213263864871, disc_loss = 0.30641079556058953
Trained batch 27 in epoch 0, gen_loss = 0.9901988314730781, disc_loss = 0.3043457344174385
Trained batch 28 in epoch 0, gen_loss = 0.9839725802684652, disc_loss = 0.30148226587936794
Trained batch 29 in epoch 0, gen_loss = 0.9805157323678334, disc_loss = 0.29831647078196205
Trained batch 30 in epoch 0, gen_loss = 0.9826639679170424, disc_loss = 0.29596210679700297
Trained batch 31 in epoch 0, gen_loss = 0.9775543641299009, disc_loss = 0.2928943228907883
Trained batch 32 in epoch 0, gen_loss = 0.973755166386113, disc_loss = 0.28971523994749243
Trained batch 33 in epoch 0, gen_loss = 0.9749295308309442, disc_loss = 0.2861645532881512
Trained batch 34 in epoch 0, gen_loss = 0.9783195989472525, disc_loss = 0.28262068799563816
Trained batch 35 in epoch 0, gen_loss = 0.9760603706041971, disc_loss = 0.28049904273615944
Trained batch 36 in epoch 0, gen_loss = 0.9772676455008017, disc_loss = 0.27711432004297104
Trained batch 37 in epoch 0, gen_loss = 0.9786828034802487, disc_loss = 0.27377240085288096
Trained batch 38 in epoch 0, gen_loss = 0.981574018796285, disc_loss = 0.2700174019122735
Trained batch 39 in epoch 0, gen_loss = 0.9875485688447952, disc_loss = 0.26610065028071406
Trained batch 40 in epoch 0, gen_loss = 0.987829913453358, disc_loss = 0.2626921349182362
Trained batch 41 in epoch 0, gen_loss = 0.9877562707378751, disc_loss = 0.2603511345528421
Trained batch 42 in epoch 0, gen_loss = 0.998882322810417, disc_loss = 0.2605707489473875
Trained batch 43 in epoch 0, gen_loss = 0.9918213879520242, disc_loss = 0.2633964273739945
Trained batch 44 in epoch 0, gen_loss = 0.9896804081069098, disc_loss = 0.26170511808660296
Trained batch 45 in epoch 0, gen_loss = 0.9884603399297466, disc_loss = 0.26194028005651804
Trained batch 46 in epoch 0, gen_loss = 0.989577517864552, disc_loss = 0.26432455442053204
Trained batch 47 in epoch 0, gen_loss = 0.9889598128696283, disc_loss = 0.26805455951641005
Trained batch 48 in epoch 0, gen_loss = 0.9904302735717929, disc_loss = 0.26749239314575585
Trained batch 49 in epoch 0, gen_loss = 0.9895291268825531, disc_loss = 0.2665326038002968
Trained batch 50 in epoch 0, gen_loss = 0.9858419112130707, disc_loss = 0.26556239613130983
Trained batch 51 in epoch 0, gen_loss = 0.9869997466985996, disc_loss = 0.26486479433683247
Trained batch 52 in epoch 0, gen_loss = 0.982003741669205, disc_loss = 0.26501719906645
Trained batch 53 in epoch 0, gen_loss = 0.9792918375244847, disc_loss = 0.2647239460989281
Trained batch 54 in epoch 0, gen_loss = 0.9781535907225175, disc_loss = 0.26470727757974105
Trained batch 55 in epoch 0, gen_loss = 0.9764824318034309, disc_loss = 0.26440958412630217
Trained batch 56 in epoch 0, gen_loss = 0.9721065801486635, disc_loss = 0.26438574780497637
Trained batch 57 in epoch 0, gen_loss = 0.9678225763912859, disc_loss = 0.26396688484940034
Trained batch 58 in epoch 0, gen_loss = 0.9655960606316388, disc_loss = 0.26359729317285246
Trained batch 59 in epoch 0, gen_loss = 0.9639332721630732, disc_loss = 0.26318048015236856
Trained batch 60 in epoch 0, gen_loss = 0.9627893400973961, disc_loss = 0.2626814602828417
Trained batch 61 in epoch 0, gen_loss = 0.95763732540992, disc_loss = 0.2625163697427319
Trained batch 62 in epoch 0, gen_loss = 0.9558879837157235, disc_loss = 0.26229508812465363
Trained batch 63 in epoch 0, gen_loss = 0.9528379458934069, disc_loss = 0.26201338740065694
Trained batch 64 in epoch 0, gen_loss = 0.950636913226201, disc_loss = 0.2617397654515046
Trained batch 65 in epoch 0, gen_loss = 0.9463456218892877, disc_loss = 0.2615658629572753
Trained batch 66 in epoch 0, gen_loss = 0.9435695979132581, disc_loss = 0.26162622290760723
Trained batch 67 in epoch 0, gen_loss = 0.9459661052507513, disc_loss = 0.2620871266459717
Trained batch 68 in epoch 0, gen_loss = 0.9417680631513181, disc_loss = 0.2630205316388089
Trained batch 69 in epoch 0, gen_loss = 0.9396805363042015, disc_loss = 0.26281668416091375
Trained batch 70 in epoch 0, gen_loss = 0.9407513250767345, disc_loss = 0.26301214686581786
Trained batch 71 in epoch 0, gen_loss = 0.9373035182555517, disc_loss = 0.2635262840323978
Trained batch 72 in epoch 0, gen_loss = 0.9351014184625182, disc_loss = 0.26323416135082506
Trained batch 73 in epoch 0, gen_loss = 0.9372190148443789, disc_loss = 0.26276863225408503
Trained batch 74 in epoch 0, gen_loss = 0.9333777356147767, disc_loss = 0.2624833309650421
Trained batch 75 in epoch 0, gen_loss = 0.9314507442085367, disc_loss = 0.26226531282851573
Trained batch 76 in epoch 0, gen_loss = 0.9294942555489478, disc_loss = 0.26213771956307547
Trained batch 77 in epoch 0, gen_loss = 0.9281797523681934, disc_loss = 0.2617731021764951
Trained batch 78 in epoch 0, gen_loss = 0.9260100141356263, disc_loss = 0.26157004093822045
Trained batch 79 in epoch 0, gen_loss = 0.9233155563473702, disc_loss = 0.2612215533852577
Trained batch 80 in epoch 0, gen_loss = 0.923266131936768, disc_loss = 0.26089282315454365
Trained batch 81 in epoch 0, gen_loss = 0.9205337566573445, disc_loss = 0.2606700037310763
Trained batch 82 in epoch 0, gen_loss = 0.9195285769830267, disc_loss = 0.26034876452871114
Trained batch 83 in epoch 0, gen_loss = 0.9183174194324584, disc_loss = 0.25994545292286647
Trained batch 84 in epoch 0, gen_loss = 0.916914859940024, disc_loss = 0.2595891819280737
Trained batch 85 in epoch 0, gen_loss = 0.9146859784458958, disc_loss = 0.2593277762102526
Trained batch 86 in epoch 0, gen_loss = 0.9157060069599371, disc_loss = 0.2594544544987295
Trained batch 87 in epoch 0, gen_loss = 0.9115200435573404, disc_loss = 0.2606785111129284
Trained batch 88 in epoch 0, gen_loss = 0.9097082293435429, disc_loss = 0.26051388630706274
Trained batch 89 in epoch 0, gen_loss = 0.9107925958103604, disc_loss = 0.2605857216649585
Trained batch 90 in epoch 0, gen_loss = 0.9083546439369956, disc_loss = 0.26039086527876804
Trained batch 91 in epoch 0, gen_loss = 0.9069723856189976, disc_loss = 0.2601250614161077
Trained batch 92 in epoch 0, gen_loss = 0.9070993194016077, disc_loss = 0.2597469240427017
Trained batch 93 in epoch 0, gen_loss = 0.9050746705937893, disc_loss = 0.25960958701498965
Trained batch 94 in epoch 0, gen_loss = 0.9026706350477118, disc_loss = 0.25986384498445614
Trained batch 95 in epoch 0, gen_loss = 0.9021176931758722, disc_loss = 0.2598031656816602
Trained batch 96 in epoch 0, gen_loss = 0.9003298761918372, disc_loss = 0.2596163251965316
Trained batch 97 in epoch 0, gen_loss = 0.8996109074475814, disc_loss = 0.2594588660463995
Trained batch 98 in epoch 0, gen_loss = 0.8979394718854115, disc_loss = 0.2592603157867085
Trained batch 99 in epoch 0, gen_loss = 0.8972635173797607, disc_loss = 0.25898295909166336
Trained batch 100 in epoch 0, gen_loss = 0.8947609733827043, disc_loss = 0.2586716270387763
Trained batch 101 in epoch 0, gen_loss = 0.8948215888995751, disc_loss = 0.25839319679082606
Trained batch 102 in epoch 0, gen_loss = 0.8928885101114662, disc_loss = 0.25838819406564956
Trained batch 103 in epoch 0, gen_loss = 0.892634256527974, disc_loss = 0.2581419520653211
Trained batch 104 in epoch 0, gen_loss = 0.8910952023097447, disc_loss = 0.25789944444383894
Trained batch 105 in epoch 0, gen_loss = 0.8886785068601932, disc_loss = 0.2576839195669822
Trained batch 106 in epoch 0, gen_loss = 0.8880071740284144, disc_loss = 0.25736203552963577
Trained batch 107 in epoch 0, gen_loss = 0.8863814384848984, disc_loss = 0.2571511957104559
Trained batch 108 in epoch 0, gen_loss = 0.8854763037567839, disc_loss = 0.2568090354357291
Trained batch 109 in epoch 0, gen_loss = 0.8849078752777794, disc_loss = 0.25644685585390437
Trained batch 110 in epoch 0, gen_loss = 0.8844194798856169, disc_loss = 0.25613654908296224
Trained batch 111 in epoch 0, gen_loss = 0.8829606579882758, disc_loss = 0.2558639415406755
Trained batch 112 in epoch 0, gen_loss = 0.8826979166638534, disc_loss = 0.25586556425664275
Trained batch 113 in epoch 0, gen_loss = 0.8804623427098257, disc_loss = 0.25608006917070925
Trained batch 114 in epoch 0, gen_loss = 0.8837903805401014, disc_loss = 0.25714182762996013
Trained batch 115 in epoch 0, gen_loss = 0.8842515894051256, disc_loss = 0.25609483312943887
Trained batch 116 in epoch 0, gen_loss = 0.8844204239356213, disc_loss = 0.2554583763464903
Trained batch 117 in epoch 0, gen_loss = 0.8842942982406939, disc_loss = 0.2548321385757398
Trained batch 118 in epoch 0, gen_loss = 0.885703381870975, disc_loss = 0.2547883934834424
Trained batch 119 in epoch 0, gen_loss = 0.8840172345439593, disc_loss = 0.25487062012155853
Trained batch 120 in epoch 0, gen_loss = 0.8845818042755127, disc_loss = 0.2548850259997628
Trained batch 121 in epoch 0, gen_loss = 0.8838294988772908, disc_loss = 0.2546704244173941
Trained batch 122 in epoch 0, gen_loss = 0.8826509781969272, disc_loss = 0.25434707395914125
Trained batch 123 in epoch 0, gen_loss = 0.8844950026081454, disc_loss = 0.2542468720386105
Trained batch 124 in epoch 0, gen_loss = 0.8816472406387329, disc_loss = 0.25469229340553284
Trained batch 125 in epoch 0, gen_loss = 0.8813058790706453, disc_loss = 0.25455779688698904
Trained batch 126 in epoch 0, gen_loss = 0.8816959097629457, disc_loss = 0.25440224782219084
Trained batch 127 in epoch 0, gen_loss = 0.8793217041529715, disc_loss = 0.2546653017634526
Trained batch 128 in epoch 0, gen_loss = 0.8789713636849278, disc_loss = 0.25437561948170034
Trained batch 129 in epoch 0, gen_loss = 0.8785141302989079, disc_loss = 0.2543671378722558
Trained batch 130 in epoch 0, gen_loss = 0.8780954057023725, disc_loss = 0.2542484247957477
Trained batch 131 in epoch 0, gen_loss = 0.8764004874410052, disc_loss = 0.2541150608749101
Trained batch 132 in epoch 0, gen_loss = 0.8759593421355226, disc_loss = 0.2540415496306312
Trained batch 133 in epoch 0, gen_loss = 0.8750120192321379, disc_loss = 0.25384125513816946
Trained batch 134 in epoch 0, gen_loss = 0.8729056548189233, disc_loss = 0.2538533038563199
Trained batch 135 in epoch 0, gen_loss = 0.8725059878300218, disc_loss = 0.25369530028718357
Trained batch 136 in epoch 0, gen_loss = 0.8713645182386802, disc_loss = 0.25339830465560415
Trained batch 137 in epoch 0, gen_loss = 0.8703114113945892, disc_loss = 0.25311080085626547
Trained batch 138 in epoch 0, gen_loss = 0.8700668554511859, disc_loss = 0.25267155779351436
Trained batch 139 in epoch 0, gen_loss = 0.8694829659802573, disc_loss = 0.25242321342229845
Trained batch 140 in epoch 0, gen_loss = 0.8690036023762209, disc_loss = 0.2522814267493309
Trained batch 141 in epoch 0, gen_loss = 0.8674008787517816, disc_loss = 0.2521081275083649
Trained batch 142 in epoch 0, gen_loss = 0.8668971616071421, disc_loss = 0.25198092691965035
Trained batch 143 in epoch 0, gen_loss = 0.8677769439915816, disc_loss = 0.2518968228250742
Trained batch 144 in epoch 0, gen_loss = 0.8652964119253488, disc_loss = 0.25214397783937126
Trained batch 145 in epoch 0, gen_loss = 0.8658024133884743, disc_loss = 0.2518283847260149
Trained batch 146 in epoch 0, gen_loss = 0.8644809783721457, disc_loss = 0.25171807246143313
Trained batch 147 in epoch 0, gen_loss = 0.8648792364307352, disc_loss = 0.2515163000773739
Trained batch 148 in epoch 0, gen_loss = 0.8641956784581178, disc_loss = 0.2512699646637744
Trained batch 149 in epoch 0, gen_loss = 0.8638187921047211, disc_loss = 0.2513978740572929
Trained batch 150 in epoch 0, gen_loss = 0.8626689796416175, disc_loss = 0.2514385118192395
Trained batch 151 in epoch 0, gen_loss = 0.8623298590904788, disc_loss = 0.2513078988382691
Trained batch 152 in epoch 0, gen_loss = 0.8615838678833706, disc_loss = 0.25103527190638525
Trained batch 153 in epoch 0, gen_loss = 0.8609832130469285, disc_loss = 0.25091317818536385
Trained batch 154 in epoch 0, gen_loss = 0.8591944725282731, disc_loss = 0.2509938668820166
Trained batch 155 in epoch 0, gen_loss = 0.8601535627475152, disc_loss = 0.25097778181617075
Trained batch 156 in epoch 0, gen_loss = 0.8580933691589696, disc_loss = 0.250946880620756
Trained batch 157 in epoch 0, gen_loss = 0.857352508397042, disc_loss = 0.2506085780413845
Trained batch 158 in epoch 0, gen_loss = 0.8580207611030003, disc_loss = 0.25048023921513707
Trained batch 159 in epoch 0, gen_loss = 0.8563471436500549, disc_loss = 0.25035825883969665
Trained batch 160 in epoch 0, gen_loss = 0.8560916163166117, disc_loss = 0.24994792951189954
Trained batch 161 in epoch 0, gen_loss = 0.8557998964815964, disc_loss = 0.24986482503605478
Trained batch 162 in epoch 0, gen_loss = 0.8545149367279802, disc_loss = 0.2498226184055118
Trained batch 163 in epoch 0, gen_loss = 0.8534910191849965, disc_loss = 0.2496355178697807
Trained batch 164 in epoch 0, gen_loss = 0.853263731436296, disc_loss = 0.24944272790894365
Trained batch 165 in epoch 0, gen_loss = 0.8519034069704722, disc_loss = 0.24932549274470434
Trained batch 166 in epoch 0, gen_loss = 0.851802954416789, disc_loss = 0.2490879968254866
Trained batch 167 in epoch 0, gen_loss = 0.851680614054203, disc_loss = 0.24911581405571528
Trained batch 168 in epoch 0, gen_loss = 0.8510828959871326, disc_loss = 0.24888024245493512
Trained batch 169 in epoch 0, gen_loss = 0.8505950233515571, disc_loss = 0.24845115051550024
Trained batch 170 in epoch 0, gen_loss = 0.851016436403955, disc_loss = 0.24843915225121013
Trained batch 171 in epoch 0, gen_loss = 0.848881816794706, disc_loss = 0.24886372087653294
Trained batch 172 in epoch 0, gen_loss = 0.8484672928132073, disc_loss = 0.24898268781989985
Trained batch 173 in epoch 0, gen_loss = 0.8498111072627977, disc_loss = 0.24929567289420929
Trained batch 174 in epoch 0, gen_loss = 0.8480120941570827, disc_loss = 0.2494795275585992
Trained batch 175 in epoch 0, gen_loss = 0.8463295721872286, disc_loss = 0.24952908004210753
Trained batch 176 in epoch 0, gen_loss = 0.8459018283644638, disc_loss = 0.24965641062475194
Trained batch 177 in epoch 0, gen_loss = 0.8455390722564097, disc_loss = 0.24979634239767376
Trained batch 178 in epoch 0, gen_loss = 0.8452272235348238, disc_loss = 0.24975443527352212
Trained batch 179 in epoch 0, gen_loss = 0.8440783354971144, disc_loss = 0.24956340922249687
Trained batch 180 in epoch 0, gen_loss = 0.8441314703851773, disc_loss = 0.24943507960817432
Trained batch 181 in epoch 0, gen_loss = 0.8437057163689162, disc_loss = 0.2493415110550084
Trained batch 182 in epoch 0, gen_loss = 0.8426202757111012, disc_loss = 0.24929703446359583
Trained batch 183 in epoch 0, gen_loss = 0.8418520889852358, disc_loss = 0.24912728037199247
Trained batch 184 in epoch 0, gen_loss = 0.8414822420558414, disc_loss = 0.24889941771288177
Trained batch 185 in epoch 0, gen_loss = 0.8414426253687951, disc_loss = 0.24848874161640802
Trained batch 186 in epoch 0, gen_loss = 0.8407924844619424, disc_loss = 0.24817807566035877
Trained batch 187 in epoch 0, gen_loss = 0.8408245111399508, disc_loss = 0.24790590953953723
Trained batch 188 in epoch 0, gen_loss = 0.8396472565080754, disc_loss = 0.2477725257003118
Trained batch 189 in epoch 0, gen_loss = 0.8405339040254292, disc_loss = 0.24782055302670128
Trained batch 190 in epoch 0, gen_loss = 0.8390350004765376, disc_loss = 0.24820099357535078
Trained batch 191 in epoch 0, gen_loss = 0.8391800308600068, disc_loss = 0.24814604261579612
Trained batch 192 in epoch 0, gen_loss = 0.8394725264045241, disc_loss = 0.24791739031749685
Trained batch 193 in epoch 0, gen_loss = 0.8382322152250821, disc_loss = 0.24770662426641307
Trained batch 194 in epoch 0, gen_loss = 0.8385234878613399, disc_loss = 0.24730447614804293
Trained batch 195 in epoch 0, gen_loss = 0.8388259039849651, disc_loss = 0.2470352287043114
Trained batch 196 in epoch 0, gen_loss = 0.8382798342535338, disc_loss = 0.24686055959481273
Trained batch 197 in epoch 0, gen_loss = 0.8386106677729674, disc_loss = 0.24646039871555386
Trained batch 198 in epoch 0, gen_loss = 0.8377160007630161, disc_loss = 0.24610701540307184
Trained batch 199 in epoch 0, gen_loss = 0.839091027379036, disc_loss = 0.24610195010900499
Trained batch 200 in epoch 0, gen_loss = 0.8371879330915005, disc_loss = 0.24628582878492364
Trained batch 201 in epoch 0, gen_loss = 0.8364506009781715, disc_loss = 0.24604083774703564
Trained batch 202 in epoch 0, gen_loss = 0.8370801935642224, disc_loss = 0.24612172557215387
Trained batch 203 in epoch 0, gen_loss = 0.836786685036678, disc_loss = 0.2457274286185994
Trained batch 204 in epoch 0, gen_loss = 0.8359454381756666, disc_loss = 0.24541769173087144
Trained batch 205 in epoch 0, gen_loss = 0.835692930858112, disc_loss = 0.24537236344756433
Trained batch 206 in epoch 0, gen_loss = 0.8355107638570998, disc_loss = 0.24530194951716253
Trained batch 207 in epoch 0, gen_loss = 0.8355654930839171, disc_loss = 0.2453866176880323
Trained batch 208 in epoch 0, gen_loss = 0.8344380484813708, disc_loss = 0.24552115441509412
Trained batch 209 in epoch 0, gen_loss = 0.8347008812995184, disc_loss = 0.24555904396942685
Trained batch 210 in epoch 0, gen_loss = 0.83386298773978, disc_loss = 0.24538296235116172
Trained batch 211 in epoch 0, gen_loss = 0.8329180771449827, disc_loss = 0.24527969886109513
Trained batch 212 in epoch 0, gen_loss = 0.834237342709107, disc_loss = 0.24511880277188172
Trained batch 213 in epoch 0, gen_loss = 0.8333700004025041, disc_loss = 0.24509797245264053
Trained batch 214 in epoch 0, gen_loss = 0.8329182940860127, disc_loss = 0.24482377261616464
Trained batch 215 in epoch 0, gen_loss = 0.8340134372313818, disc_loss = 0.24467861652374268
Trained batch 216 in epoch 0, gen_loss = 0.8326637646020283, disc_loss = 0.2446832470767509
Trained batch 217 in epoch 0, gen_loss = 0.8320588964387912, disc_loss = 0.2444568521112477
Trained batch 218 in epoch 0, gen_loss = 0.8330729086649472, disc_loss = 0.24436153947762704
Trained batch 219 in epoch 0, gen_loss = 0.8328523205085234, disc_loss = 0.24432607387954539
Trained batch 220 in epoch 0, gen_loss = 0.8325773728379297, disc_loss = 0.24416775313707498
Trained batch 221 in epoch 0, gen_loss = 0.8323076418391219, disc_loss = 0.24395314255007752
Trained batch 222 in epoch 0, gen_loss = 0.8328036949238969, disc_loss = 0.24372904176401985
Trained batch 223 in epoch 0, gen_loss = 0.8322181297200066, disc_loss = 0.2433127798140049
Trained batch 224 in epoch 0, gen_loss = 0.8317785220675998, disc_loss = 0.2432349556684494
Trained batch 225 in epoch 0, gen_loss = 0.8326267985116064, disc_loss = 0.24299556458682087
Trained batch 226 in epoch 0, gen_loss = 0.8317153432820862, disc_loss = 0.24298811438062642
Trained batch 227 in epoch 0, gen_loss = 0.8313323790044115, disc_loss = 0.2427277232994113
Trained batch 228 in epoch 0, gen_loss = 0.8317838441336519, disc_loss = 0.24256876618581047
Trained batch 229 in epoch 0, gen_loss = 0.8313536024611929, disc_loss = 0.2423873087634211
Trained batch 230 in epoch 0, gen_loss = 0.832581466668612, disc_loss = 0.24194950781343302
Trained batch 231 in epoch 0, gen_loss = 0.8324719623758875, disc_loss = 0.24142767138907623
Trained batch 232 in epoch 0, gen_loss = 0.8324234559812259, disc_loss = 0.2410523943571062
Trained batch 233 in epoch 0, gen_loss = 0.8338380219080509, disc_loss = 0.24097188450714463
Trained batch 234 in epoch 0, gen_loss = 0.8325986628836773, disc_loss = 0.24106436013541324
Trained batch 235 in epoch 0, gen_loss = 0.8326380338709233, disc_loss = 0.24081267122873815
Trained batch 236 in epoch 0, gen_loss = 0.8344081459166128, disc_loss = 0.2406491215659093
Trained batch 237 in epoch 0, gen_loss = 0.8328811801782176, disc_loss = 0.24094546827323296
Trained batch 238 in epoch 0, gen_loss = 0.8338750156897381, disc_loss = 0.24057199101443072
Trained batch 239 in epoch 0, gen_loss = 0.83403866092364, disc_loss = 0.2405536194331944
Trained batch 240 in epoch 0, gen_loss = 0.8340082269981194, disc_loss = 0.24030621458015006
Trained batch 241 in epoch 0, gen_loss = 0.8333794112540474, disc_loss = 0.24022042760548512
Trained batch 242 in epoch 0, gen_loss = 0.8329465548688002, disc_loss = 0.2399391919190501
Trained batch 243 in epoch 0, gen_loss = 0.8335125548917739, disc_loss = 0.23971444634018374
Trained batch 244 in epoch 0, gen_loss = 0.8322919050041511, disc_loss = 0.2396714676095515
Trained batch 245 in epoch 0, gen_loss = 0.8317693721472732, disc_loss = 0.2395097217484703
Trained batch 246 in epoch 0, gen_loss = 0.8330869208945919, disc_loss = 0.23963655830032912
Trained batch 247 in epoch 0, gen_loss = 0.8320912735596779, disc_loss = 0.23975747622429364
Trained batch 248 in epoch 0, gen_loss = 0.8320125075707953, disc_loss = 0.23954949192852382
Trained batch 249 in epoch 0, gen_loss = 0.8331309506893158, disc_loss = 0.2394427019059658
Trained batch 250 in epoch 0, gen_loss = 0.8329435292468128, disc_loss = 0.23899963210184735
Trained batch 251 in epoch 0, gen_loss = 0.8328884099684064, disc_loss = 0.2387274783695974
Trained batch 252 in epoch 0, gen_loss = 0.8334845363387006, disc_loss = 0.2385736247708675
Trained batch 253 in epoch 0, gen_loss = 0.8326749259562004, disc_loss = 0.23845021318145623
Trained batch 254 in epoch 0, gen_loss = 0.8333294057378582, disc_loss = 0.23813127200393117
Trained batch 255 in epoch 0, gen_loss = 0.8335312700364739, disc_loss = 0.23796395389945246
Trained batch 256 in epoch 0, gen_loss = 0.8328629829540327, disc_loss = 0.23778768043225842
Trained batch 257 in epoch 0, gen_loss = 0.833848584992017, disc_loss = 0.23761698150242022
Trained batch 258 in epoch 0, gen_loss = 0.8332955929303262, disc_loss = 0.23729404004499258
Trained batch 259 in epoch 0, gen_loss = 0.8333778952176755, disc_loss = 0.23720115173894626
Trained batch 260 in epoch 0, gen_loss = 0.8344020188083137, disc_loss = 0.23741559076240693
Trained batch 261 in epoch 0, gen_loss = 0.8344755891625207, disc_loss = 0.2371369431093904
Trained batch 262 in epoch 0, gen_loss = 0.8343546114040419, disc_loss = 0.23695338885707093
Trained batch 263 in epoch 0, gen_loss = 0.8340329726537069, disc_loss = 0.23685147491932818
Trained batch 264 in epoch 0, gen_loss = 0.8348942054892486, disc_loss = 0.2367787797777158
Trained batch 265 in epoch 0, gen_loss = 0.833995965638555, disc_loss = 0.23709648973623612
Trained batch 266 in epoch 0, gen_loss = 0.8356883561566528, disc_loss = 0.23711402616585686
Trained batch 267 in epoch 0, gen_loss = 0.8349934053509983, disc_loss = 0.23700039119306784
Trained batch 268 in epoch 0, gen_loss = 0.8357428926074372, disc_loss = 0.2365504094991542
Trained batch 269 in epoch 0, gen_loss = 0.8362937463654412, disc_loss = 0.2363931981501756
Trained batch 270 in epoch 0, gen_loss = 0.8358229202977846, disc_loss = 0.23609992410863898
Trained batch 271 in epoch 0, gen_loss = 0.8363329112968024, disc_loss = 0.2357442724682829
Trained batch 272 in epoch 0, gen_loss = 0.8362574199617128, disc_loss = 0.23556571221831954
Trained batch 273 in epoch 0, gen_loss = 0.8366786082730676, disc_loss = 0.2354508562788476
Trained batch 274 in epoch 0, gen_loss = 0.8359502725167708, disc_loss = 0.23520457116040316
Trained batch 275 in epoch 0, gen_loss = 0.8365045472763587, disc_loss = 0.23499420927702516
Trained batch 276 in epoch 0, gen_loss = 0.8362917562254069, disc_loss = 0.23480207378898718
Trained batch 277 in epoch 0, gen_loss = 0.8355085337333542, disc_loss = 0.2350927428911916
Trained batch 278 in epoch 0, gen_loss = 0.8352807886284312, disc_loss = 0.23493670397120991
Trained batch 279 in epoch 0, gen_loss = 0.8350191584655217, disc_loss = 0.235065448018057
Trained batch 280 in epoch 0, gen_loss = 0.8342783631379069, disc_loss = 0.2351971157823169
Trained batch 281 in epoch 0, gen_loss = 0.834284468111417, disc_loss = 0.23509836165194817
Trained batch 282 in epoch 0, gen_loss = 0.8345224210735765, disc_loss = 0.23512786637346653
Trained batch 283 in epoch 0, gen_loss = 0.833638769849925, disc_loss = 0.23518480496927047
Trained batch 284 in epoch 0, gen_loss = 0.8349920049048307, disc_loss = 0.23502519752895623
Trained batch 285 in epoch 0, gen_loss = 0.8338756457075372, disc_loss = 0.23505635809648287
Trained batch 286 in epoch 0, gen_loss = 0.8340549367230113, disc_loss = 0.23466207320681848
Trained batch 287 in epoch 0, gen_loss = 0.8344270597315497, disc_loss = 0.23444835981354117
Trained batch 288 in epoch 0, gen_loss = 0.834729771713072, disc_loss = 0.23414284903491658
Trained batch 289 in epoch 0, gen_loss = 0.8339334853764238, disc_loss = 0.23401906058706087
Trained batch 290 in epoch 0, gen_loss = 0.8343427431132785, disc_loss = 0.23383157912808186
Trained batch 291 in epoch 0, gen_loss = 0.8337607865464197, disc_loss = 0.23373351164468348
Trained batch 292 in epoch 0, gen_loss = 0.8341603665628531, disc_loss = 0.23355501478239132
Trained batch 293 in epoch 0, gen_loss = 0.8331963513173214, disc_loss = 0.23355888306689102
Trained batch 294 in epoch 0, gen_loss = 0.8329947542336027, disc_loss = 0.23343708414142414
Trained batch 295 in epoch 0, gen_loss = 0.8332957748222996, disc_loss = 0.2331681929125979
Trained batch 296 in epoch 0, gen_loss = 0.8325963467861266, disc_loss = 0.2331143319606781
Trained batch 297 in epoch 0, gen_loss = 0.8325589289201186, disc_loss = 0.23289128572948828
Trained batch 298 in epoch 0, gen_loss = 0.8333000676289051, disc_loss = 0.2326463223699742
Trained batch 299 in epoch 0, gen_loss = 0.8323215494553248, disc_loss = 0.2326810421049595
Trained batch 300 in epoch 0, gen_loss = 0.8327668713176766, disc_loss = 0.2324319834328965
Trained batch 301 in epoch 0, gen_loss = 0.8322971218469127, disc_loss = 0.2322791118594195
Trained batch 302 in epoch 0, gen_loss = 0.8337343254498523, disc_loss = 0.23210382402533353
Trained batch 303 in epoch 0, gen_loss = 0.83346525854186, disc_loss = 0.23169149664279662
Trained batch 304 in epoch 0, gen_loss = 0.8340014094212016, disc_loss = 0.23127776667719982
Trained batch 305 in epoch 0, gen_loss = 0.8334185340825249, disc_loss = 0.2310243881508416
Trained batch 306 in epoch 0, gen_loss = 0.8360613949524075, disc_loss = 0.2317495185408608
Trained batch 307 in epoch 0, gen_loss = 0.8353247762500465, disc_loss = 0.23175862378307752
Trained batch 308 in epoch 0, gen_loss = 0.8348840332339883, disc_loss = 0.23176156056737438
Trained batch 309 in epoch 0, gen_loss = 0.8346708582293603, disc_loss = 0.2319453098120228
Trained batch 310 in epoch 0, gen_loss = 0.8342830222519264, disc_loss = 0.2319142853907067
Trained batch 311 in epoch 0, gen_loss = 0.8340709702326701, disc_loss = 0.23183761513194975
Trained batch 312 in epoch 0, gen_loss = 0.8338605982427019, disc_loss = 0.2317616263041481
Trained batch 313 in epoch 0, gen_loss = 0.8333047224078208, disc_loss = 0.2315914260733659
Trained batch 314 in epoch 0, gen_loss = 0.8331571611147078, disc_loss = 0.23144110370249976
Trained batch 315 in epoch 0, gen_loss = 0.8331647334219534, disc_loss = 0.23153281499502026
Trained batch 316 in epoch 0, gen_loss = 0.8322444009103985, disc_loss = 0.2314740694847769
Trained batch 317 in epoch 0, gen_loss = 0.8318034978407733, disc_loss = 0.23133462344138128
Trained batch 318 in epoch 0, gen_loss = 0.8319337211058805, disc_loss = 0.23114343669534104
Trained batch 319 in epoch 0, gen_loss = 0.8317095326259732, disc_loss = 0.23100857785902917
Trained batch 320 in epoch 0, gen_loss = 0.8315969631307965, disc_loss = 0.23080690130823497
Trained batch 321 in epoch 0, gen_loss = 0.8310690607343402, disc_loss = 0.23063417986868331
Trained batch 322 in epoch 0, gen_loss = 0.8309408824879319, disc_loss = 0.23056777112255156
Trained batch 323 in epoch 0, gen_loss = 0.830824981501073, disc_loss = 0.23035604410149432
Trained batch 324 in epoch 0, gen_loss = 0.8311207740123455, disc_loss = 0.23021087696919074
Trained batch 325 in epoch 0, gen_loss = 0.8308135927454826, disc_loss = 0.23004761914168398
Trained batch 326 in epoch 0, gen_loss = 0.8309084178839984, disc_loss = 0.22993534657568743
Trained batch 327 in epoch 0, gen_loss = 0.8310408739418518, disc_loss = 0.2297924054650272
Trained batch 328 in epoch 0, gen_loss = 0.8301589635730152, disc_loss = 0.22971229984405192
Trained batch 329 in epoch 0, gen_loss = 0.8316844952828957, disc_loss = 0.22975249656222083
Trained batch 330 in epoch 0, gen_loss = 0.8310736968798219, disc_loss = 0.22961175833403885
Trained batch 331 in epoch 0, gen_loss = 0.8305128782269466, disc_loss = 0.22945485241621374
Trained batch 332 in epoch 0, gen_loss = 0.8309075789408641, disc_loss = 0.22937535702645243
Trained batch 333 in epoch 0, gen_loss = 0.8305209568160736, disc_loss = 0.229138035304889
Trained batch 334 in epoch 0, gen_loss = 0.8303436941175318, disc_loss = 0.22909617517421493
Trained batch 335 in epoch 0, gen_loss = 0.8304678222962788, disc_loss = 0.22913090015451112
Trained batch 336 in epoch 0, gen_loss = 0.8302194584017337, disc_loss = 0.2291267907760971
Trained batch 337 in epoch 0, gen_loss = 0.8310991818382896, disc_loss = 0.22920337178298003
Trained batch 338 in epoch 0, gen_loss = 0.8309820180093996, disc_loss = 0.22898549518402347
Trained batch 339 in epoch 0, gen_loss = 0.8312333415536319, disc_loss = 0.22870382622760885
Trained batch 340 in epoch 0, gen_loss = 0.831007401964182, disc_loss = 0.22853111635205334
Trained batch 341 in epoch 0, gen_loss = 0.8327182639412015, disc_loss = 0.22830993303081445
Trained batch 342 in epoch 0, gen_loss = 0.8335181314813153, disc_loss = 0.22803666935717748
Trained batch 343 in epoch 0, gen_loss = 0.8329905236876288, disc_loss = 0.2283057654493077
Trained batch 344 in epoch 0, gen_loss = 0.8352895391160163, disc_loss = 0.2286128704962523
Trained batch 345 in epoch 0, gen_loss = 0.8347756495710054, disc_loss = 0.2284100204706192
Trained batch 346 in epoch 0, gen_loss = 0.8339841029142441, disc_loss = 0.22845090539208063
Trained batch 347 in epoch 0, gen_loss = 0.8339354899422876, disc_loss = 0.22811872940296415
Trained batch 348 in epoch 0, gen_loss = 0.8339812273965524, disc_loss = 0.22792017391554606
Trained batch 349 in epoch 0, gen_loss = 0.8339083017621721, disc_loss = 0.22763829605919975
Trained batch 350 in epoch 0, gen_loss = 0.8333265557248368, disc_loss = 0.2275763137048466
Trained batch 351 in epoch 0, gen_loss = 0.8334083762019873, disc_loss = 0.2273655559190295
Trained batch 352 in epoch 0, gen_loss = 0.8332557379355174, disc_loss = 0.22721463078817633
Trained batch 353 in epoch 0, gen_loss = 0.8330612100113584, disc_loss = 0.22704710634583133
Trained batch 354 in epoch 0, gen_loss = 0.8334788844618999, disc_loss = 0.22715257653887844
Trained batch 355 in epoch 0, gen_loss = 0.8326693594120862, disc_loss = 0.22712907136491176
Trained batch 356 in epoch 0, gen_loss = 0.8336618829842041, disc_loss = 0.2267900397505413
Trained batch 357 in epoch 0, gen_loss = 0.8339081320016744, disc_loss = 0.22646064273804925
Trained batch 358 in epoch 0, gen_loss = 0.8338414487068367, disc_loss = 0.22611495705119083
Trained batch 359 in epoch 0, gen_loss = 0.8341078165504667, disc_loss = 0.22588692193643914
Trained batch 360 in epoch 0, gen_loss = 0.8342854791731055, disc_loss = 0.22570102921896035
Trained batch 361 in epoch 0, gen_loss = 0.83447909684471, disc_loss = 0.22556402120553987
Trained batch 362 in epoch 0, gen_loss = 0.8344902112135874, disc_loss = 0.2252032030219874
Trained batch 363 in epoch 0, gen_loss = 0.8355982821066301, disc_loss = 0.22486580560331818
Trained batch 364 in epoch 0, gen_loss = 0.8354109929032522, disc_loss = 0.22455176845805286
Trained batch 365 in epoch 0, gen_loss = 0.8369040178145216, disc_loss = 0.2245143134492994
Trained batch 366 in epoch 0, gen_loss = 0.8361443744043563, disc_loss = 0.22450000969363168
Trained batch 367 in epoch 0, gen_loss = 0.8369953021731066, disc_loss = 0.22442919764991687
Trained batch 368 in epoch 0, gen_loss = 0.8373548992604098, disc_loss = 0.22424395406633857
Trained batch 369 in epoch 0, gen_loss = 0.8370723071936015, disc_loss = 0.22418356332424524
Trained batch 370 in epoch 0, gen_loss = 0.8392815321603554, disc_loss = 0.22403614419811177
Trained batch 371 in epoch 0, gen_loss = 0.8391601241404011, disc_loss = 0.22376588167202088
Trained batch 372 in epoch 0, gen_loss = 0.838533962380151, disc_loss = 0.223706160050295
Trained batch 373 in epoch 0, gen_loss = 0.8408428956480587, disc_loss = 0.22419673439493792
Trained batch 374 in epoch 0, gen_loss = 0.8406208658218384, disc_loss = 0.22397911310195923
Trained batch 375 in epoch 0, gen_loss = 0.8404283216024967, disc_loss = 0.2237413039708391
Trained batch 376 in epoch 0, gen_loss = 0.8400635790445444, disc_loss = 0.2235183406334657
Trained batch 377 in epoch 0, gen_loss = 0.8404073975388966, disc_loss = 0.22328823296323655
Trained batch 378 in epoch 0, gen_loss = 0.8401591128283881, disc_loss = 0.223144758935025
Trained batch 379 in epoch 0, gen_loss = 0.8401953943465885, disc_loss = 0.22283080443739892
Trained batch 380 in epoch 0, gen_loss = 0.8399737830862911, disc_loss = 0.22257974736020947
Trained batch 381 in epoch 0, gen_loss = 0.8405148691219809, disc_loss = 0.22236165759295068
Trained batch 382 in epoch 0, gen_loss = 0.8411546013373931, disc_loss = 0.2222501164783697
Trained batch 383 in epoch 0, gen_loss = 0.8401293756905943, disc_loss = 0.22249737017167112
Trained batch 384 in epoch 0, gen_loss = 0.8401574796670443, disc_loss = 0.22238080408666042
Trained batch 385 in epoch 0, gen_loss = 0.8411284233467566, disc_loss = 0.22248160669223013
Trained batch 386 in epoch 0, gen_loss = 0.8412599779992757, disc_loss = 0.22230099064589162
Trained batch 387 in epoch 0, gen_loss = 0.8410772721945625, disc_loss = 0.22216127739892794
Trained batch 388 in epoch 0, gen_loss = 0.8407551610224657, disc_loss = 0.2220671960274787
Trained batch 389 in epoch 0, gen_loss = 0.8410645108192395, disc_loss = 0.22191980874691253
Trained batch 390 in epoch 0, gen_loss = 0.8417906885409294, disc_loss = 0.22167715540779825
Trained batch 391 in epoch 0, gen_loss = 0.8422646324093245, disc_loss = 0.22138273525907068
Trained batch 392 in epoch 0, gen_loss = 0.8413312732415041, disc_loss = 0.22170862358338353
Trained batch 393 in epoch 0, gen_loss = 0.8431721502149165, disc_loss = 0.2217614324716142
Trained batch 394 in epoch 0, gen_loss = 0.8437312403811684, disc_loss = 0.22163210975218423
Trained batch 395 in epoch 0, gen_loss = 0.8434631308220853, disc_loss = 0.22136821355106254
Trained batch 396 in epoch 0, gen_loss = 0.8436141042625274, disc_loss = 0.22123028745203835
Trained batch 397 in epoch 0, gen_loss = 0.8444935225661675, disc_loss = 0.22085493550303592
Trained batch 398 in epoch 0, gen_loss = 0.846286988646763, disc_loss = 0.2206634974905423
Trained batch 399 in epoch 0, gen_loss = 0.8451788370311261, disc_loss = 0.2211533528752625
Trained batch 400 in epoch 0, gen_loss = 0.8449687358744424, disc_loss = 0.2209096160947236
Trained batch 401 in epoch 0, gen_loss = 0.8466271916728708, disc_loss = 0.22093888129390293
Trained batch 402 in epoch 0, gen_loss = 0.8462847520044956, disc_loss = 0.22089538346079385
Trained batch 403 in epoch 0, gen_loss = 0.8457427619412394, disc_loss = 0.2207593607467295
Trained batch 404 in epoch 0, gen_loss = 0.8453188551796808, disc_loss = 0.2206199813956096
Trained batch 405 in epoch 0, gen_loss = 0.8453351285657272, disc_loss = 0.22059195424462186
Trained batch 406 in epoch 0, gen_loss = 0.8456179786665726, disc_loss = 0.2209046457960506
Trained batch 407 in epoch 0, gen_loss = 0.8449619316002902, disc_loss = 0.22098566421910243
Trained batch 408 in epoch 0, gen_loss = 0.8451400311768492, disc_loss = 0.22076649954747454
Trained batch 409 in epoch 0, gen_loss = 0.844702350075652, disc_loss = 0.22060070592092304
Trained batch 410 in epoch 0, gen_loss = 0.8449936259692022, disc_loss = 0.220404846480438
Trained batch 411 in epoch 0, gen_loss = 0.8449659039383953, disc_loss = 0.22022763750000487
Trained batch 412 in epoch 0, gen_loss = 0.8447355306177393, disc_loss = 0.22005571690151246
Trained batch 413 in epoch 0, gen_loss = 0.8448787651200226, disc_loss = 0.2199944248917886
Trained batch 414 in epoch 0, gen_loss = 0.8451601683375347, disc_loss = 0.2197222733174462
Trained batch 415 in epoch 0, gen_loss = 0.8449949064793495, disc_loss = 0.21949917126375323
Trained batch 416 in epoch 0, gen_loss = 0.8453996231515917, disc_loss = 0.21923417074503088
Trained batch 417 in epoch 0, gen_loss = 0.8453491622466219, disc_loss = 0.21903356692294754
Trained batch 418 in epoch 0, gen_loss = 0.8461288602084703, disc_loss = 0.21873525748816197
Trained batch 419 in epoch 0, gen_loss = 0.845977024095399, disc_loss = 0.2185553531561579
Trained batch 420 in epoch 0, gen_loss = 0.8465439677238464, disc_loss = 0.21830573545286605
Trained batch 421 in epoch 0, gen_loss = 0.846496305053268, disc_loss = 0.21803514428118959
Trained batch 422 in epoch 0, gen_loss = 0.847195183272621, disc_loss = 0.2177992924766056
Trained batch 423 in epoch 0, gen_loss = 0.8471297333544155, disc_loss = 0.21756662639244548
Trained batch 424 in epoch 0, gen_loss = 0.8478842801206252, disc_loss = 0.21730598670594833
Trained batch 425 in epoch 0, gen_loss = 0.8485047852209476, disc_loss = 0.21692621939653803
Trained batch 426 in epoch 0, gen_loss = 0.8483675775539121, disc_loss = 0.21671684875874944
Trained batch 427 in epoch 0, gen_loss = 0.84963027325189, disc_loss = 0.21639025880667928
Trained batch 428 in epoch 0, gen_loss = 0.8498865696655843, disc_loss = 0.21620462297316476
Trained batch 429 in epoch 0, gen_loss = 0.8502404942068943, disc_loss = 0.21582972124912017
Trained batch 430 in epoch 0, gen_loss = 0.8514030499690647, disc_loss = 0.21560462394820012
Trained batch 431 in epoch 0, gen_loss = 0.8507705714415621, disc_loss = 0.2158294315104959
Trained batch 432 in epoch 0, gen_loss = 0.8510894535870805, disc_loss = 0.2155525918714444
Trained batch 433 in epoch 0, gen_loss = 0.8534174377467775, disc_loss = 0.21574421148009015
Trained batch 434 in epoch 0, gen_loss = 0.8527230292901226, disc_loss = 0.21602989651005844
Trained batch 435 in epoch 0, gen_loss = 0.8529749246092018, disc_loss = 0.215717342024276
Trained batch 436 in epoch 0, gen_loss = 0.8537057852308592, disc_loss = 0.2156292707819142
Trained batch 437 in epoch 0, gen_loss = 0.8539352505446569, disc_loss = 0.215410175184681
Trained batch 438 in epoch 0, gen_loss = 0.8535076630957306, disc_loss = 0.21528281688961734
Trained batch 439 in epoch 0, gen_loss = 0.8541383844884959, disc_loss = 0.21500704911622134
Trained batch 440 in epoch 0, gen_loss = 0.8552714714657963, disc_loss = 0.21466974780605494
Trained batch 441 in epoch 0, gen_loss = 0.8552276095653552, disc_loss = 0.21443714793114102
Trained batch 442 in epoch 0, gen_loss = 0.8553964514495557, disc_loss = 0.21421961918574153
Trained batch 443 in epoch 0, gen_loss = 0.85589161689754, disc_loss = 0.21384926649599192
Trained batch 444 in epoch 0, gen_loss = 0.8555966262067302, disc_loss = 0.21376317427232025
Trained batch 445 in epoch 0, gen_loss = 0.8558234454805006, disc_loss = 0.21393264418325883
Trained batch 446 in epoch 0, gen_loss = 0.8552136237189274, disc_loss = 0.2140145458747743
Trained batch 447 in epoch 0, gen_loss = 0.8550986401470644, disc_loss = 0.21388372026350616
Trained batch 448 in epoch 0, gen_loss = 0.8550228226954794, disc_loss = 0.21423039689062698
Trained batch 449 in epoch 0, gen_loss = 0.8544728663232591, disc_loss = 0.21417662301825152
Trained batch 450 in epoch 0, gen_loss = 0.8542734638286007, disc_loss = 0.21412795867167925
Trained batch 451 in epoch 0, gen_loss = 0.8550406802544551, disc_loss = 0.2142495481890783
Trained batch 452 in epoch 0, gen_loss = 0.8553298231518558, disc_loss = 0.21396223864380362
Trained batch 453 in epoch 0, gen_loss = 0.85511195804054, disc_loss = 0.21382425655713427
Trained batch 454 in epoch 0, gen_loss = 0.8544147306746179, disc_loss = 0.21383845684128802
Trained batch 455 in epoch 0, gen_loss = 0.854980287191115, disc_loss = 0.21370155131444335
Trained batch 456 in epoch 0, gen_loss = 0.8557952215948043, disc_loss = 0.21365888050759385
Trained batch 457 in epoch 0, gen_loss = 0.8551425469234, disc_loss = 0.2136444601283193
Trained batch 458 in epoch 0, gen_loss = 0.8548293218893164, disc_loss = 0.2137111299681378
Trained batch 459 in epoch 0, gen_loss = 0.8552784467520921, disc_loss = 0.2139898299118099
Trained batch 460 in epoch 0, gen_loss = 0.8551652479326906, disc_loss = 0.213933914536186
Trained batch 461 in epoch 0, gen_loss = 0.8551336786189636, disc_loss = 0.213731665543212
Trained batch 462 in epoch 0, gen_loss = 0.8551652558936413, disc_loss = 0.2135999528510138
Trained batch 463 in epoch 0, gen_loss = 0.8555421766279072, disc_loss = 0.21348342663158887
Trained batch 464 in epoch 0, gen_loss = 0.8551982204119365, disc_loss = 0.21350276765804138
Trained batch 465 in epoch 0, gen_loss = 0.8550608558460366, disc_loss = 0.21361147104702538
Trained batch 466 in epoch 0, gen_loss = 0.8547581573369927, disc_loss = 0.2135360625829763
Trained batch 467 in epoch 0, gen_loss = 0.8547205317478913, disc_loss = 0.2133863452487649
Trained batch 468 in epoch 0, gen_loss = 0.8548658200418517, disc_loss = 0.21330261224908614
Trained batch 469 in epoch 0, gen_loss = 0.8546353362976237, disc_loss = 0.21331766419746775
Trained batch 470 in epoch 0, gen_loss = 0.8543864392424338, disc_loss = 0.21324056811678183
Trained batch 471 in epoch 0, gen_loss = 0.8544258268202766, disc_loss = 0.21309817491604363
Trained batch 472 in epoch 0, gen_loss = 0.8543143582394461, disc_loss = 0.21294590368488878
Trained batch 473 in epoch 0, gen_loss = 0.8545022010803223, disc_loss = 0.21267403433500212
Trained batch 474 in epoch 0, gen_loss = 0.8543360163036146, disc_loss = 0.21245561614632608
Trained batch 475 in epoch 0, gen_loss = 0.8547228960429921, disc_loss = 0.21220049496051394
Trained batch 476 in epoch 0, gen_loss = 0.8547062532706831, disc_loss = 0.21208162180126588
Trained batch 477 in epoch 0, gen_loss = 0.8543747609878684, disc_loss = 0.21195700729585343
Trained batch 478 in epoch 0, gen_loss = 0.8547292899239287, disc_loss = 0.2117199998170075
Trained batch 479 in epoch 0, gen_loss = 0.8548763040453196, disc_loss = 0.2116160073239977
Trained batch 480 in epoch 0, gen_loss = 0.854389827365439, disc_loss = 0.21150157372167105
Trained batch 481 in epoch 0, gen_loss = 0.8554203426194883, disc_loss = 0.21149389166771376
Trained batch 482 in epoch 0, gen_loss = 0.8551583705975155, disc_loss = 0.21136308002515117
Trained batch 483 in epoch 0, gen_loss = 0.8550639546607152, disc_loss = 0.21120289712374615
Trained batch 484 in epoch 0, gen_loss = 0.8562214396663548, disc_loss = 0.21138837336725796
Trained batch 485 in epoch 0, gen_loss = 0.8559797268836096, disc_loss = 0.21127187137955747
Trained batch 486 in epoch 0, gen_loss = 0.8556396344359161, disc_loss = 0.21116670653285188
Trained batch 487 in epoch 0, gen_loss = 0.8558880652560562, disc_loss = 0.21119478564007116
Trained batch 488 in epoch 0, gen_loss = 0.8558150290955308, disc_loss = 0.21097558713184789
Trained batch 489 in epoch 0, gen_loss = 0.8558413734241408, disc_loss = 0.21081943731678993
Trained batch 490 in epoch 0, gen_loss = 0.8559282907643289, disc_loss = 0.21054569063537476
Trained batch 491 in epoch 0, gen_loss = 0.8560968030516695, disc_loss = 0.21038716686965248
Trained batch 492 in epoch 0, gen_loss = 0.856184864020009, disc_loss = 0.21019537375888525
Trained batch 493 in epoch 0, gen_loss = 0.8561130694532202, disc_loss = 0.21010166078594775
Trained batch 494 in epoch 0, gen_loss = 0.8560866758076832, disc_loss = 0.20987686654082452
Trained batch 495 in epoch 0, gen_loss = 0.8565928169315861, disc_loss = 0.20958343592111864
Trained batch 496 in epoch 0, gen_loss = 0.8561164351776093, disc_loss = 0.20955425632041944
Trained batch 497 in epoch 0, gen_loss = 0.8581202717191244, disc_loss = 0.20975405725100674
Trained batch 498 in epoch 0, gen_loss = 0.8577461171006869, disc_loss = 0.2097383154283664
Trained batch 499 in epoch 0, gen_loss = 0.8579024357795715, disc_loss = 0.2097249661013484
Trained batch 500 in epoch 0, gen_loss = 0.8580448808308371, disc_loss = 0.20968374805506357
Trained batch 501 in epoch 0, gen_loss = 0.8583678833516946, disc_loss = 0.2094812324545179
Trained batch 502 in epoch 0, gen_loss = 0.8586069911896116, disc_loss = 0.20923710858104955
Trained batch 503 in epoch 0, gen_loss = 0.8585527340571085, disc_loss = 0.20907408468395708
Trained batch 504 in epoch 0, gen_loss = 0.8591673794359264, disc_loss = 0.20883123381155552
Trained batch 505 in epoch 0, gen_loss = 0.8589142871939618, disc_loss = 0.208792383543293
Trained batch 506 in epoch 0, gen_loss = 0.8598929493149827, disc_loss = 0.20871453227464265
Trained batch 507 in epoch 0, gen_loss = 0.8597592733741746, disc_loss = 0.20867514970353035
Trained batch 508 in epoch 0, gen_loss = 0.859200712037227, disc_loss = 0.20864650782029381
Trained batch 509 in epoch 0, gen_loss = 0.859757598474914, disc_loss = 0.208468559771484
Trained batch 510 in epoch 0, gen_loss = 0.8599100291379044, disc_loss = 0.20827244378903373
Trained batch 511 in epoch 0, gen_loss = 0.8597407672787085, disc_loss = 0.20809976648160955
Trained batch 512 in epoch 0, gen_loss = 0.8608852433182342, disc_loss = 0.20830972765011396
Trained batch 513 in epoch 0, gen_loss = 0.8606360863154964, disc_loss = 0.2082168837277226
Trained batch 514 in epoch 0, gen_loss = 0.8600088844021547, disc_loss = 0.20833855785646485
Trained batch 515 in epoch 0, gen_loss = 0.8605212474516196, disc_loss = 0.20826166307250427
Trained batch 516 in epoch 0, gen_loss = 0.8612248777651464, disc_loss = 0.2082135173162478
Trained batch 517 in epoch 0, gen_loss = 0.8610435519439373, disc_loss = 0.20813996459152478
Trained batch 518 in epoch 0, gen_loss = 0.8610547985415008, disc_loss = 0.20811668652072118
Trained batch 519 in epoch 0, gen_loss = 0.8621361542206544, disc_loss = 0.20793211737361092
Trained batch 520 in epoch 0, gen_loss = 0.8620739619242253, disc_loss = 0.2077115611200026
Trained batch 521 in epoch 0, gen_loss = 0.8622783514960058, disc_loss = 0.2075995463249898
Trained batch 522 in epoch 0, gen_loss = 0.8616715175015977, disc_loss = 0.20757525744019914
Trained batch 523 in epoch 0, gen_loss = 0.8617422799117692, disc_loss = 0.20742022969141488
Trained batch 524 in epoch 0, gen_loss = 0.862269815263294, disc_loss = 0.20733883211300486
Trained batch 525 in epoch 0, gen_loss = 0.8622426365718189, disc_loss = 0.20709523777459737
Trained batch 526 in epoch 0, gen_loss = 0.8618558495954046, disc_loss = 0.20699657393050375
Trained batch 527 in epoch 0, gen_loss = 0.8623527281663634, disc_loss = 0.2067175054936811
Trained batch 528 in epoch 0, gen_loss = 0.8633562885295241, disc_loss = 0.20645066702101092
Trained batch 529 in epoch 0, gen_loss = 0.8629401661315055, disc_loss = 0.20646654761765362
Trained batch 530 in epoch 0, gen_loss = 0.8626003016186299, disc_loss = 0.20633983009419424
Trained batch 531 in epoch 0, gen_loss = 0.8630408561767492, disc_loss = 0.2066033745072502
Trained batch 532 in epoch 0, gen_loss = 0.8637167604510825, disc_loss = 0.2063361967216625
Trained batch 533 in epoch 0, gen_loss = 0.8629303486941012, disc_loss = 0.2065320862771085
Trained batch 534 in epoch 0, gen_loss = 0.8633230351399038, disc_loss = 0.20650758632571897
Trained batch 535 in epoch 0, gen_loss = 0.8633787270023752, disc_loss = 0.20648934378691797
Trained batch 536 in epoch 0, gen_loss = 0.8632574383883946, disc_loss = 0.20636380374348362
Trained batch 537 in epoch 0, gen_loss = 0.8635199635556197, disc_loss = 0.20627919366396272
Trained batch 538 in epoch 0, gen_loss = 0.8636762549019037, disc_loss = 0.2061355907214263
Trained batch 539 in epoch 0, gen_loss = 0.8638457456672634, disc_loss = 0.20589710051124846
Trained batch 540 in epoch 0, gen_loss = 0.8640036059064918, disc_loss = 0.2057285348432011
Trained batch 541 in epoch 0, gen_loss = 0.8637987427495942, disc_loss = 0.20570187544883178
Trained batch 542 in epoch 0, gen_loss = 0.8634665868010091, disc_loss = 0.20562731678396956
Trained batch 543 in epoch 0, gen_loss = 0.8649991899180938, disc_loss = 0.20542085124864518
Trained batch 544 in epoch 0, gen_loss = 0.8660276106191338, disc_loss = 0.20514660158425296
Trained batch 545 in epoch 0, gen_loss = 0.8657924674260311, disc_loss = 0.20502251922238224
Trained batch 546 in epoch 0, gen_loss = 0.8654914228637214, disc_loss = 0.20501345739967208
Trained batch 547 in epoch 0, gen_loss = 0.8662943843833721, disc_loss = 0.20479500906229237
Trained batch 548 in epoch 0, gen_loss = 0.8671351707589648, disc_loss = 0.20459133255650003
Trained batch 549 in epoch 0, gen_loss = 0.8675303384932604, disc_loss = 0.20440531776032664
Trained batch 550 in epoch 0, gen_loss = 0.8673299068006975, disc_loss = 0.20424319056628404
Trained batch 551 in epoch 0, gen_loss = 0.8673712416295556, disc_loss = 0.20401375842672112
Trained batch 552 in epoch 0, gen_loss = 0.8688674968470286, disc_loss = 0.2038943235295914
Trained batch 553 in epoch 0, gen_loss = 0.8687782465658463, disc_loss = 0.20373437846153436
Trained batch 554 in epoch 0, gen_loss = 0.8690851698587606, disc_loss = 0.20353889284772916
Trained batch 555 in epoch 0, gen_loss = 0.869254650775906, disc_loss = 0.2032881906765292
Trained batch 556 in epoch 0, gen_loss = 0.8696971953557252, disc_loss = 0.20308168606307606
Trained batch 557 in epoch 0, gen_loss = 0.8696841432522702, disc_loss = 0.2028573563649556
Trained batch 558 in epoch 0, gen_loss = 0.8704256072560449, disc_loss = 0.2026492027175981
Trained batch 559 in epoch 0, gen_loss = 0.8703986067324877, disc_loss = 0.20250084918391492
Trained batch 560 in epoch 0, gen_loss = 0.87060832844486, disc_loss = 0.20231810170300504
Trained batch 561 in epoch 0, gen_loss = 0.8707186372360725, disc_loss = 0.20207111058206534
Trained batch 562 in epoch 0, gen_loss = 0.8706447303718614, disc_loss = 0.202000084218981
Trained batch 563 in epoch 0, gen_loss = 0.8709501859249799, disc_loss = 0.2018523787260584
Trained batch 564 in epoch 0, gen_loss = 0.871305151376049, disc_loss = 0.2015691537838594
Trained batch 565 in epoch 0, gen_loss = 0.8714528364448582, disc_loss = 0.20159982374536906
Trained batch 566 in epoch 0, gen_loss = 0.8708527437698694, disc_loss = 0.20169652420928869
Trained batch 567 in epoch 0, gen_loss = 0.871359004573503, disc_loss = 0.20147509645329606
Trained batch 568 in epoch 0, gen_loss = 0.8717361615810327, disc_loss = 0.2013248432696075
Trained batch 569 in epoch 0, gen_loss = 0.8721874952839132, disc_loss = 0.20109711589389725
Trained batch 570 in epoch 0, gen_loss = 0.8721921823383839, disc_loss = 0.20086080037487994
Trained batch 571 in epoch 0, gen_loss = 0.87342271099349, disc_loss = 0.20071249273507955
Trained batch 572 in epoch 0, gen_loss = 0.8732165707239514, disc_loss = 0.2005397456049607
Trained batch 573 in epoch 0, gen_loss = 0.8735543393403395, disc_loss = 0.20035774774122528
Trained batch 574 in epoch 0, gen_loss = 0.8731403673731762, disc_loss = 0.20033709232573924
Trained batch 575 in epoch 0, gen_loss = 0.8738025393233531, disc_loss = 0.20024969063362935
Trained batch 576 in epoch 0, gen_loss = 0.8735750759185084, disc_loss = 0.2004812320749206
Trained batch 577 in epoch 0, gen_loss = 0.874021144938304, disc_loss = 0.2003801741079785
Trained batch 578 in epoch 0, gen_loss = 0.8733852080009967, disc_loss = 0.2004663232064103
Trained batch 579 in epoch 0, gen_loss = 0.8749522116163682, disc_loss = 0.20029595480782206
Trained batch 580 in epoch 0, gen_loss = 0.87490755663271, disc_loss = 0.20010774203683546
Trained batch 581 in epoch 0, gen_loss = 0.8748700781069261, disc_loss = 0.19999760908436326
Trained batch 582 in epoch 0, gen_loss = 0.8750221759438719, disc_loss = 0.19976676797963946
Trained batch 583 in epoch 0, gen_loss = 0.8752544105359136, disc_loss = 0.19960975235532205
Trained batch 584 in epoch 0, gen_loss = 0.875205530009718, disc_loss = 0.19940288061132797
Trained batch 585 in epoch 0, gen_loss = 0.8761590973000477, disc_loss = 0.19919142408658824
Trained batch 586 in epoch 0, gen_loss = 0.8761486163842008, disc_loss = 0.1990278875312468
Trained batch 587 in epoch 0, gen_loss = 0.8763478091683518, disc_loss = 0.1988578034868958
Trained batch 588 in epoch 0, gen_loss = 0.8765142253886257, disc_loss = 0.19878075324340466
Trained batch 589 in epoch 0, gen_loss = 0.8766091506865065, disc_loss = 0.19859468043481898
Trained batch 590 in epoch 0, gen_loss = 0.8770654020474848, disc_loss = 0.19835209374374344
Trained batch 591 in epoch 0, gen_loss = 0.8776402143711174, disc_loss = 0.1983255810116896
Trained batch 592 in epoch 0, gen_loss = 0.8776285278957972, disc_loss = 0.19816968717547934
Trained batch 593 in epoch 0, gen_loss = 0.8785140083394066, disc_loss = 0.19795796149081052
Trained batch 594 in epoch 0, gen_loss = 0.8795203221445324, disc_loss = 0.19782451969109663
Trained batch 595 in epoch 0, gen_loss = 0.8795573473876754, disc_loss = 0.1978166725849045
Trained batch 596 in epoch 0, gen_loss = 0.8799524006232544, disc_loss = 0.1976402849645371
Trained batch 597 in epoch 0, gen_loss = 0.8799845310656921, disc_loss = 0.19743499380963103
Trained batch 598 in epoch 0, gen_loss = 0.8809994745234615, disc_loss = 0.19736798380646164
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.8343733549118042, disc_loss = 0.10930624604225159
Trained batch 1 in epoch 1, gen_loss = 0.9291293621063232, disc_loss = 0.10847404599189758
Trained batch 2 in epoch 1, gen_loss = 0.9969178040822347, disc_loss = 0.09723965326944987
Trained batch 3 in epoch 1, gen_loss = 1.023811399936676, disc_loss = 0.10863927751779556
Trained batch 4 in epoch 1, gen_loss = 1.0462742805480958, disc_loss = 0.10589410066604614
Trained batch 5 in epoch 1, gen_loss = 1.0319368441899617, disc_loss = 0.10575832674900691
Trained batch 6 in epoch 1, gen_loss = 1.1627793993268694, disc_loss = 0.10834158424820219
Trained batch 7 in epoch 1, gen_loss = 1.1564797013998032, disc_loss = 0.09877252764999866
Trained batch 8 in epoch 1, gen_loss = 1.1380197140905592, disc_loss = 0.09507631013790767
Trained batch 9 in epoch 1, gen_loss = 1.1770179927349091, disc_loss = 0.08862624876201153
Trained batch 10 in epoch 1, gen_loss = 1.1664555235342546, disc_loss = 0.08501224185932767
Trained batch 11 in epoch 1, gen_loss = 1.1411852190891902, disc_loss = 0.08469532461216052
Trained batch 12 in epoch 1, gen_loss = 1.1679901847472558, disc_loss = 0.08245567862804119
Trained batch 13 in epoch 1, gen_loss = 1.1833930654185159, disc_loss = 0.07856851230774607
Trained batch 14 in epoch 1, gen_loss = 1.1840261578559876, disc_loss = 0.07514507795373598
Trained batch 15 in epoch 1, gen_loss = 1.2059674821794033, disc_loss = 0.0719204565975815
Trained batch 16 in epoch 1, gen_loss = 1.1836181843982023, disc_loss = 0.07317518026513212
Trained batch 17 in epoch 1, gen_loss = 1.2307926846875086, disc_loss = 0.07736279463602437
Trained batch 18 in epoch 1, gen_loss = 1.2063888280015242, disc_loss = 0.07736719733006076
Trained batch 19 in epoch 1, gen_loss = 1.211058560013771, disc_loss = 0.07444093683734536
Trained batch 20 in epoch 1, gen_loss = 1.19339896099908, disc_loss = 0.07404742079476516
Trained batch 21 in epoch 1, gen_loss = 1.22594784877517, disc_loss = 0.08282987510954792
Trained batch 22 in epoch 1, gen_loss = 1.225511195866958, disc_loss = 0.08253356109818687
Trained batch 23 in epoch 1, gen_loss = 1.2228418961167336, disc_loss = 0.08105333778075874
Trained batch 24 in epoch 1, gen_loss = 1.210545687675476, disc_loss = 0.08147002436220646
Trained batch 25 in epoch 1, gen_loss = 1.213300613256601, disc_loss = 0.08366278709413913
Trained batch 26 in epoch 1, gen_loss = 1.1972835836587128, disc_loss = 0.08453416472507848
Trained batch 27 in epoch 1, gen_loss = 1.1952885197741645, disc_loss = 0.08314387945990477
Trained batch 28 in epoch 1, gen_loss = 1.1896009671277012, disc_loss = 0.08174937931371146
Trained batch 29 in epoch 1, gen_loss = 1.2034981946150463, disc_loss = 0.0818717789525787
Trained batch 30 in epoch 1, gen_loss = 1.1944344216777432, disc_loss = 0.0815468160735984
Trained batch 31 in epoch 1, gen_loss = 1.1908099260181189, disc_loss = 0.08019431616412476
Trained batch 32 in epoch 1, gen_loss = 1.1929450884009853, disc_loss = 0.08263752931220965
Trained batch 33 in epoch 1, gen_loss = 1.1763698861879461, disc_loss = 0.08445598519242861
Trained batch 34 in epoch 1, gen_loss = 1.183564269542694, disc_loss = 0.08355699963867665
Trained batch 35 in epoch 1, gen_loss = 1.1766059796015422, disc_loss = 0.0844453181554046
Trained batch 36 in epoch 1, gen_loss = 1.1756782531738281, disc_loss = 0.08334367938742444
Trained batch 37 in epoch 1, gen_loss = 1.1718681548771106, disc_loss = 0.08290550068609025
Trained batch 38 in epoch 1, gen_loss = 1.1748751952097967, disc_loss = 0.08161037773467027
Trained batch 39 in epoch 1, gen_loss = 1.166656568646431, disc_loss = 0.0821506108622998
Trained batch 40 in epoch 1, gen_loss = 1.172192064727225, disc_loss = 0.08071162074622584
Trained batch 41 in epoch 1, gen_loss = 1.1699597239494324, disc_loss = 0.08036665241455748
Trained batch 42 in epoch 1, gen_loss = 1.1743776437848112, disc_loss = 0.07915933027343694
Trained batch 43 in epoch 1, gen_loss = 1.1831197982484645, disc_loss = 0.07808826774866744
Trained batch 44 in epoch 1, gen_loss = 1.1727027376492818, disc_loss = 0.08013368095788691
Trained batch 45 in epoch 1, gen_loss = 1.1785920016143634, disc_loss = 0.08049650777779195
Trained batch 46 in epoch 1, gen_loss = 1.1697806081873305, disc_loss = 0.08055907563167683
Trained batch 47 in epoch 1, gen_loss = 1.1723505097130935, disc_loss = 0.08017556815563391
Trained batch 48 in epoch 1, gen_loss = 1.1755465719164635, disc_loss = 0.07995435105142545
Trained batch 49 in epoch 1, gen_loss = 1.1669743049144745, disc_loss = 0.08073530372232199
Trained batch 50 in epoch 1, gen_loss = 1.1744765756176967, disc_loss = 0.0804903568225164
Trained batch 51 in epoch 1, gen_loss = 1.1772174938366964, disc_loss = 0.07975510812292878
Trained batch 52 in epoch 1, gen_loss = 1.1708552455002408, disc_loss = 0.07979725642164923
Trained batch 53 in epoch 1, gen_loss = 1.177426031342259, disc_loss = 0.07876336467624814
Trained batch 54 in epoch 1, gen_loss = 1.1871565753763371, disc_loss = 0.07803011688996445
Trained batch 55 in epoch 1, gen_loss = 1.18281732073852, disc_loss = 0.07904759411966163
Trained batch 56 in epoch 1, gen_loss = 1.177026252997549, disc_loss = 0.07910003686291084
Trained batch 57 in epoch 1, gen_loss = 1.17044070568578, disc_loss = 0.08087679181761782
Trained batch 58 in epoch 1, gen_loss = 1.1775915935888128, disc_loss = 0.08181781867929434
Trained batch 59 in epoch 1, gen_loss = 1.1719305048386255, disc_loss = 0.08207583194598556
Trained batch 60 in epoch 1, gen_loss = 1.1675510064500276, disc_loss = 0.08326295619738884
Trained batch 61 in epoch 1, gen_loss = 1.1692565727618434, disc_loss = 0.08406442010234441
Trained batch 62 in epoch 1, gen_loss = 1.1702996218015278, disc_loss = 0.08377115892630721
Trained batch 63 in epoch 1, gen_loss = 1.1596294660121202, disc_loss = 0.08755156598635949
Trained batch 64 in epoch 1, gen_loss = 1.161469740134019, disc_loss = 0.0879458685620473
Trained batch 65 in epoch 1, gen_loss = 1.1645160425793042, disc_loss = 0.08746554468278632
Trained batch 66 in epoch 1, gen_loss = 1.1672030651747292, disc_loss = 0.0863532110659489
Trained batch 67 in epoch 1, gen_loss = 1.1598940404022442, disc_loss = 0.08760375751401572
Trained batch 68 in epoch 1, gen_loss = 1.166330916294153, disc_loss = 0.08893936378476412
Trained batch 69 in epoch 1, gen_loss = 1.1681103093283518, disc_loss = 0.0881575386705143
Trained batch 70 in epoch 1, gen_loss = 1.1657872821243715, disc_loss = 0.08790637429436328
Trained batch 71 in epoch 1, gen_loss = 1.164090136686961, disc_loss = 0.0880594802244256
Trained batch 72 in epoch 1, gen_loss = 1.1657856833444882, disc_loss = 0.08711694640247789
Trained batch 73 in epoch 1, gen_loss = 1.165642276003554, disc_loss = 0.0867491854807815
Trained batch 74 in epoch 1, gen_loss = 1.1689053773880005, disc_loss = 0.08585126685599485
Trained batch 75 in epoch 1, gen_loss = 1.1702948871411776, disc_loss = 0.08634506428222123
Trained batch 76 in epoch 1, gen_loss = 1.1731937891477113, disc_loss = 0.08563283983279359
Trained batch 77 in epoch 1, gen_loss = 1.1678427732907808, disc_loss = 0.08610494250957018
Trained batch 78 in epoch 1, gen_loss = 1.1720605651034584, disc_loss = 0.08536754489605185
Trained batch 79 in epoch 1, gen_loss = 1.1737183421850204, disc_loss = 0.08495969504583627
Trained batch 80 in epoch 1, gen_loss = 1.1695605273599978, disc_loss = 0.08483744148210978
Trained batch 81 in epoch 1, gen_loss = 1.1716057142106497, disc_loss = 0.08441378169397755
Trained batch 82 in epoch 1, gen_loss = 1.1712592014347214, disc_loss = 0.08379529445735087
Trained batch 83 in epoch 1, gen_loss = 1.1712011914877665, disc_loss = 0.08389367227486912
Trained batch 84 in epoch 1, gen_loss = 1.1682674478082096, disc_loss = 0.08430013343253556
Trained batch 85 in epoch 1, gen_loss = 1.1637853536494942, disc_loss = 0.08460259916217522
Trained batch 86 in epoch 1, gen_loss = 1.1714845649127303, disc_loss = 0.08521982524329903
Trained batch 87 in epoch 1, gen_loss = 1.1689147475090893, disc_loss = 0.0856906706678935
Trained batch 88 in epoch 1, gen_loss = 1.1645537976468547, disc_loss = 0.0866492713142312
Trained batch 89 in epoch 1, gen_loss = 1.1600378208690219, disc_loss = 0.08714964333921671
Trained batch 90 in epoch 1, gen_loss = 1.158799219917465, disc_loss = 0.08712528631664239
Trained batch 91 in epoch 1, gen_loss = 1.155377692502478, disc_loss = 0.08735220460221171
Trained batch 92 in epoch 1, gen_loss = 1.1598611954719789, disc_loss = 0.08790060895825585
Trained batch 93 in epoch 1, gen_loss = 1.153269055675953, disc_loss = 0.08981512631586891
Trained batch 94 in epoch 1, gen_loss = 1.149492723690836, disc_loss = 0.08995982379113374
Trained batch 95 in epoch 1, gen_loss = 1.1517748267700274, disc_loss = 0.09188052113555993
Trained batch 96 in epoch 1, gen_loss = 1.1494764120308394, disc_loss = 0.09173618788955752
Trained batch 97 in epoch 1, gen_loss = 1.1454500841851136, disc_loss = 0.09164031041900114
Trained batch 98 in epoch 1, gen_loss = 1.1486493234682564, disc_loss = 0.09160812946055273
Trained batch 99 in epoch 1, gen_loss = 1.145288603901863, disc_loss = 0.09180586123839021
Trained batch 100 in epoch 1, gen_loss = 1.1421746316522654, disc_loss = 0.09232793196962022
Trained batch 101 in epoch 1, gen_loss = 1.1427578090452681, disc_loss = 0.09190656166231516
Trained batch 102 in epoch 1, gen_loss = 1.142501468218646, disc_loss = 0.09122230544758653
Trained batch 103 in epoch 1, gen_loss = 1.146840373483988, disc_loss = 0.09074488380708946
Trained batch 104 in epoch 1, gen_loss = 1.1429425313359216, disc_loss = 0.09097240700253419
Trained batch 105 in epoch 1, gen_loss = 1.1426763090322603, disc_loss = 0.09056108133902527
Trained batch 106 in epoch 1, gen_loss = 1.145901963532528, disc_loss = 0.09029737896520958
Trained batch 107 in epoch 1, gen_loss = 1.1457286074205681, disc_loss = 0.09018472501042264
Trained batch 108 in epoch 1, gen_loss = 1.1490275012243778, disc_loss = 0.0895525247815552
Trained batch 109 in epoch 1, gen_loss = 1.151655238866806, disc_loss = 0.08889875439080325
Trained batch 110 in epoch 1, gen_loss = 1.153171964056857, disc_loss = 0.08832072339079401
Trained batch 111 in epoch 1, gen_loss = 1.1555556138711316, disc_loss = 0.0878173069629286
Trained batch 112 in epoch 1, gen_loss = 1.1569693072707252, disc_loss = 0.08722633677246296
Trained batch 113 in epoch 1, gen_loss = 1.1581847819319941, disc_loss = 0.08660758659243584
Trained batch 114 in epoch 1, gen_loss = 1.156807197695193, disc_loss = 0.08628491130859955
Trained batch 115 in epoch 1, gen_loss = 1.1595134580957478, disc_loss = 0.08586377579847286
Trained batch 116 in epoch 1, gen_loss = 1.1621126629348495, disc_loss = 0.08524278755116667
Trained batch 117 in epoch 1, gen_loss = 1.1607166356959586, disc_loss = 0.08482861089504372
Trained batch 118 in epoch 1, gen_loss = 1.1600034467312468, disc_loss = 0.08467706524524368
Trained batch 119 in epoch 1, gen_loss = 1.157771388689677, disc_loss = 0.08442345106353362
Trained batch 120 in epoch 1, gen_loss = 1.1642435828516307, disc_loss = 0.08567454715159313
Trained batch 121 in epoch 1, gen_loss = 1.1614726762302587, disc_loss = 0.0857169645853707
Trained batch 122 in epoch 1, gen_loss = 1.156995020261625, disc_loss = 0.08668306718269984
Trained batch 123 in epoch 1, gen_loss = 1.1592721746813865, disc_loss = 0.08684576212638809
Trained batch 124 in epoch 1, gen_loss = 1.1583593940734864, disc_loss = 0.08660557827353478
Trained batch 125 in epoch 1, gen_loss = 1.154934043449069, disc_loss = 0.08705311088216683
Trained batch 126 in epoch 1, gen_loss = 1.1555274035048297, disc_loss = 0.08673892290456088
Trained batch 127 in epoch 1, gen_loss = 1.1564915492199361, disc_loss = 0.08655649967840873
Trained batch 128 in epoch 1, gen_loss = 1.1555294135744258, disc_loss = 0.0863675668315832
Trained batch 129 in epoch 1, gen_loss = 1.1551586953493265, disc_loss = 0.08620965357583303
Trained batch 130 in epoch 1, gen_loss = 1.1553638095164116, disc_loss = 0.0857385313636019
Trained batch 131 in epoch 1, gen_loss = 1.1552732076608774, disc_loss = 0.08527694003317844
Trained batch 132 in epoch 1, gen_loss = 1.1544822127299201, disc_loss = 0.08521507684617563
Trained batch 133 in epoch 1, gen_loss = 1.1572750971388461, disc_loss = 0.08479633133636037
Trained batch 134 in epoch 1, gen_loss = 1.153328757374375, disc_loss = 0.08554205790989929
Trained batch 135 in epoch 1, gen_loss = 1.1560299006455086, disc_loss = 0.08687416295630529
Trained batch 136 in epoch 1, gen_loss = 1.1567332922977254, disc_loss = 0.08669994642319036
Trained batch 137 in epoch 1, gen_loss = 1.1552746749442557, disc_loss = 0.08687218895478957
Trained batch 138 in epoch 1, gen_loss = 1.1517884306770434, disc_loss = 0.08748472842434757
Trained batch 139 in epoch 1, gen_loss = 1.154087822352137, disc_loss = 0.08882945532511388
Trained batch 140 in epoch 1, gen_loss = 1.1536129091648346, disc_loss = 0.0891104529856156
Trained batch 141 in epoch 1, gen_loss = 1.151726630791812, disc_loss = 0.08898516735193175
Trained batch 142 in epoch 1, gen_loss = 1.1476837450807744, disc_loss = 0.09002645440087036
Trained batch 143 in epoch 1, gen_loss = 1.155827270199855, disc_loss = 0.09188258742344463
Trained batch 144 in epoch 1, gen_loss = 1.1560640873580144, disc_loss = 0.09246457518431647
Trained batch 145 in epoch 1, gen_loss = 1.1539528182108107, disc_loss = 0.09258496435997013
Trained batch 146 in epoch 1, gen_loss = 1.1531825787356111, disc_loss = 0.09235928102466119
Trained batch 147 in epoch 1, gen_loss = 1.1520784291866664, disc_loss = 0.09221272267451561
Trained batch 148 in epoch 1, gen_loss = 1.1505848173327093, disc_loss = 0.09191953187070837
Trained batch 149 in epoch 1, gen_loss = 1.1482285845279694, disc_loss = 0.09226326943685612
Trained batch 150 in epoch 1, gen_loss = 1.1456667457195306, disc_loss = 0.09267696206587435
Trained batch 151 in epoch 1, gen_loss = 1.1461559255656444, disc_loss = 0.09284495166502893
Trained batch 152 in epoch 1, gen_loss = 1.1434044074388892, disc_loss = 0.0932947311160806
Trained batch 153 in epoch 1, gen_loss = 1.1405674428134769, disc_loss = 0.09360735627592771
Trained batch 154 in epoch 1, gen_loss = 1.1392467906398158, disc_loss = 0.09356056015578008
Trained batch 155 in epoch 1, gen_loss = 1.1381675004959106, disc_loss = 0.09362206145977744
Trained batch 156 in epoch 1, gen_loss = 1.1412367623323088, disc_loss = 0.09363671431353518
Trained batch 157 in epoch 1, gen_loss = 1.1386961612520339, disc_loss = 0.09416658682395009
Trained batch 158 in epoch 1, gen_loss = 1.1381191615038697, disc_loss = 0.09383363095141432
Trained batch 159 in epoch 1, gen_loss = 1.1380243979394435, disc_loss = 0.09369156408356502
Trained batch 160 in epoch 1, gen_loss = 1.1373089722224645, disc_loss = 0.09348418946545686
Trained batch 161 in epoch 1, gen_loss = 1.1384426605554274, disc_loss = 0.09304912525148672
Trained batch 162 in epoch 1, gen_loss = 1.1370976080923725, disc_loss = 0.09280366344274553
Trained batch 163 in epoch 1, gen_loss = 1.1348598643047054, disc_loss = 0.09284176726303087
Trained batch 164 in epoch 1, gen_loss = 1.1391199075814449, disc_loss = 0.09329634691503914
Trained batch 165 in epoch 1, gen_loss = 1.137310596833746, disc_loss = 0.09362241871520338
Trained batch 166 in epoch 1, gen_loss = 1.134522732146486, disc_loss = 0.09396380501726788
Trained batch 167 in epoch 1, gen_loss = 1.1343340362821306, disc_loss = 0.09357888025364705
Trained batch 168 in epoch 1, gen_loss = 1.136515095389101, disc_loss = 0.09320737790735163
Trained batch 169 in epoch 1, gen_loss = 1.1360289244090809, disc_loss = 0.09286975504501778
Trained batch 170 in epoch 1, gen_loss = 1.1348531622635691, disc_loss = 0.0930942233695447
Trained batch 171 in epoch 1, gen_loss = 1.133859130185704, disc_loss = 0.0929016258545913
Trained batch 172 in epoch 1, gen_loss = 1.1338048150084612, disc_loss = 0.0926534444675108
Trained batch 173 in epoch 1, gen_loss = 1.1336808995953922, disc_loss = 0.09255530410071557
Trained batch 174 in epoch 1, gen_loss = 1.1337181646483285, disc_loss = 0.09240090292479311
Trained batch 175 in epoch 1, gen_loss = 1.1314151317558505, disc_loss = 0.0926386559784243
Trained batch 176 in epoch 1, gen_loss = 1.1341960770262163, disc_loss = 0.0926791436570344
Trained batch 177 in epoch 1, gen_loss = 1.132812341947234, disc_loss = 0.09255121622150869
Trained batch 178 in epoch 1, gen_loss = 1.1341213800387675, disc_loss = 0.09219963911025884
Trained batch 179 in epoch 1, gen_loss = 1.1351148823897044, disc_loss = 0.0918645717203617
Trained batch 180 in epoch 1, gen_loss = 1.1337137617458954, disc_loss = 0.09178055378284243
Trained batch 181 in epoch 1, gen_loss = 1.134755449635642, disc_loss = 0.09145526190871721
Trained batch 182 in epoch 1, gen_loss = 1.133131596234327, disc_loss = 0.09129649099430752
Trained batch 183 in epoch 1, gen_loss = 1.1355522116241248, disc_loss = 0.09109232694153553
Trained batch 184 in epoch 1, gen_loss = 1.1338046879381747, disc_loss = 0.0914316088565298
Trained batch 185 in epoch 1, gen_loss = 1.1356398995204637, disc_loss = 0.09127210170751618
Trained batch 186 in epoch 1, gen_loss = 1.136297330499333, disc_loss = 0.09098910135939159
Trained batch 187 in epoch 1, gen_loss = 1.1373504704617439, disc_loss = 0.09062409912176589
Trained batch 188 in epoch 1, gen_loss = 1.138494473916513, disc_loss = 0.09036123671780819
Trained batch 189 in epoch 1, gen_loss = 1.1410303235054016, disc_loss = 0.09003874936974363
Trained batch 190 in epoch 1, gen_loss = 1.1412994899050728, disc_loss = 0.08965246630978833
Trained batch 191 in epoch 1, gen_loss = 1.140258279318611, disc_loss = 0.08955470505558576
Trained batch 192 in epoch 1, gen_loss = 1.1388888105827293, disc_loss = 0.09080828380785458
Trained batch 193 in epoch 1, gen_loss = 1.1389526270099521, disc_loss = 0.09050106687336854
Trained batch 194 in epoch 1, gen_loss = 1.1384924766344902, disc_loss = 0.09034565179011761
Trained batch 195 in epoch 1, gen_loss = 1.1395799420317825, disc_loss = 0.09020342406037511
Trained batch 196 in epoch 1, gen_loss = 1.140632907751248, disc_loss = 0.08991467213343243
Trained batch 197 in epoch 1, gen_loss = 1.1408122597318706, disc_loss = 0.08972084021779021
Trained batch 198 in epoch 1, gen_loss = 1.138453619563999, disc_loss = 0.08996259735607022
Trained batch 199 in epoch 1, gen_loss = 1.140586693882942, disc_loss = 0.09034960743039847
Trained batch 200 in epoch 1, gen_loss = 1.1422941572037502, disc_loss = 0.09065076845943632
Trained batch 201 in epoch 1, gen_loss = 1.1396760793015508, disc_loss = 0.0912262082911364
Trained batch 202 in epoch 1, gen_loss = 1.1398241795929782, disc_loss = 0.09096339818438873
Trained batch 203 in epoch 1, gen_loss = 1.140593685355841, disc_loss = 0.0909808897139395
Trained batch 204 in epoch 1, gen_loss = 1.1395240219627938, disc_loss = 0.09102274997205269
Trained batch 205 in epoch 1, gen_loss = 1.1389860366154643, disc_loss = 0.09173616886283588
Trained batch 206 in epoch 1, gen_loss = 1.137496054460461, disc_loss = 0.09176707264161917
Trained batch 207 in epoch 1, gen_loss = 1.1357586332238638, disc_loss = 0.09196317779759948
Trained batch 208 in epoch 1, gen_loss = 1.1369330609244022, disc_loss = 0.09195316675604816
Trained batch 209 in epoch 1, gen_loss = 1.136437377475557, disc_loss = 0.09203196309861683
Trained batch 210 in epoch 1, gen_loss = 1.133889354800726, disc_loss = 0.09261799600169557
Trained batch 211 in epoch 1, gen_loss = 1.1330348450057912, disc_loss = 0.09250408966305121
Trained batch 212 in epoch 1, gen_loss = 1.1346513044106568, disc_loss = 0.092959946939643
Trained batch 213 in epoch 1, gen_loss = 1.1328451808924986, disc_loss = 0.0932167268523546
Trained batch 214 in epoch 1, gen_loss = 1.1329309710236484, disc_loss = 0.09325052350759507
Trained batch 215 in epoch 1, gen_loss = 1.1307142854288772, disc_loss = 0.0935200857412484
Trained batch 216 in epoch 1, gen_loss = 1.131235656375709, disc_loss = 0.09338443005277265
Trained batch 217 in epoch 1, gen_loss = 1.131221435212214, disc_loss = 0.09354701053795464
Trained batch 218 in epoch 1, gen_loss = 1.131232780680809, disc_loss = 0.09342429365061189
Trained batch 219 in epoch 1, gen_loss = 1.1300700515508653, disc_loss = 0.09323904150250283
Trained batch 220 in epoch 1, gen_loss = 1.1304670866258544, disc_loss = 0.09307576122596793
Trained batch 221 in epoch 1, gen_loss = 1.1321507850745778, disc_loss = 0.09279516874602786
Trained batch 222 in epoch 1, gen_loss = 1.1320145138176032, disc_loss = 0.0925021988961996
Trained batch 223 in epoch 1, gen_loss = 1.132417609382953, disc_loss = 0.09225026005879045
Trained batch 224 in epoch 1, gen_loss = 1.1321588471200732, disc_loss = 0.09199634699357881
Trained batch 225 in epoch 1, gen_loss = 1.1322182625268413, disc_loss = 0.09186688963884274
Trained batch 226 in epoch 1, gen_loss = 1.132372408448862, disc_loss = 0.09153602640698397
Trained batch 227 in epoch 1, gen_loss = 1.1307173504641181, disc_loss = 0.09158500569071948
Trained batch 228 in epoch 1, gen_loss = 1.131240557635195, disc_loss = 0.09133352655673392
Trained batch 229 in epoch 1, gen_loss = 1.133489604877389, disc_loss = 0.09109585363741803
Trained batch 230 in epoch 1, gen_loss = 1.1366636662772207, disc_loss = 0.09087685122279636
Trained batch 231 in epoch 1, gen_loss = 1.1375863770472592, disc_loss = 0.09057221779246526
Trained batch 232 in epoch 1, gen_loss = 1.1390950733499978, disc_loss = 0.09022985390775193
Trained batch 233 in epoch 1, gen_loss = 1.1400412934967594, disc_loss = 0.09070856262667057
Trained batch 234 in epoch 1, gen_loss = 1.1392708768235875, disc_loss = 0.09095905605465808
Trained batch 235 in epoch 1, gen_loss = 1.1397716216111586, disc_loss = 0.09087454229277575
Trained batch 236 in epoch 1, gen_loss = 1.1412785138761947, disc_loss = 0.090755151781226
Trained batch 237 in epoch 1, gen_loss = 1.1433930742640455, disc_loss = 0.09052797035948068
Trained batch 238 in epoch 1, gen_loss = 1.1442049741744995, disc_loss = 0.09035767847087593
Trained batch 239 in epoch 1, gen_loss = 1.1431900545954705, disc_loss = 0.09049053224734963
Trained batch 240 in epoch 1, gen_loss = 1.1424277076088047, disc_loss = 0.09037650628517772
Trained batch 241 in epoch 1, gen_loss = 1.1438645621961798, disc_loss = 0.09048205483242992
Trained batch 242 in epoch 1, gen_loss = 1.1443278244984003, disc_loss = 0.09037191931296278
Trained batch 243 in epoch 1, gen_loss = 1.1443139808099778, disc_loss = 0.09014593506018158
Trained batch 244 in epoch 1, gen_loss = 1.144124554128063, disc_loss = 0.08995537424878199
Trained batch 245 in epoch 1, gen_loss = 1.1479407117618778, disc_loss = 0.09002541612864025
Trained batch 246 in epoch 1, gen_loss = 1.1488394394577273, disc_loss = 0.08973787334344165
Trained batch 247 in epoch 1, gen_loss = 1.1480513145366023, disc_loss = 0.08964207502562672
Trained batch 248 in epoch 1, gen_loss = 1.1502586433207653, disc_loss = 0.08945314273477559
Trained batch 249 in epoch 1, gen_loss = 1.151134486913681, disc_loss = 0.08914840058982372
Trained batch 250 in epoch 1, gen_loss = 1.1520492638724733, disc_loss = 0.0888515621520193
Trained batch 251 in epoch 1, gen_loss = 1.1533260016687332, disc_loss = 0.08854797551600588
Trained batch 252 in epoch 1, gen_loss = 1.154264143097542, disc_loss = 0.08824949895248936
Trained batch 253 in epoch 1, gen_loss = 1.1544282617062096, disc_loss = 0.08796264907697171
Trained batch 254 in epoch 1, gen_loss = 1.1552959084510803, disc_loss = 0.0877308164924091
Trained batch 255 in epoch 1, gen_loss = 1.155871047405526, disc_loss = 0.08752608666327433
Trained batch 256 in epoch 1, gen_loss = 1.1557014037199058, disc_loss = 0.08736275167273293
Trained batch 257 in epoch 1, gen_loss = 1.1575710701850033, disc_loss = 0.08713530458495483
Trained batch 258 in epoch 1, gen_loss = 1.1594793904702176, disc_loss = 0.08694546505391713
Trained batch 259 in epoch 1, gen_loss = 1.1618371906188818, disc_loss = 0.08673119109052305
Trained batch 260 in epoch 1, gen_loss = 1.162710401061851, disc_loss = 0.08644600305349434
Trained batch 261 in epoch 1, gen_loss = 1.163222077011152, disc_loss = 0.08624437931953495
Trained batch 262 in epoch 1, gen_loss = 1.1642601632799938, disc_loss = 0.08600982296999417
Trained batch 263 in epoch 1, gen_loss = 1.1647389546939821, disc_loss = 0.08574908229550629
Trained batch 264 in epoch 1, gen_loss = 1.165653811085899, disc_loss = 0.08550761952855677
Trained batch 265 in epoch 1, gen_loss = 1.1658796567217748, disc_loss = 0.08523194272687337
Trained batch 266 in epoch 1, gen_loss = 1.1670840257562503, disc_loss = 0.08517824497757556
Trained batch 267 in epoch 1, gen_loss = 1.1669968248748068, disc_loss = 0.08501393711472403
Trained batch 268 in epoch 1, gen_loss = 1.1668090308465922, disc_loss = 0.0848328817746564
Trained batch 269 in epoch 1, gen_loss = 1.166810871715899, disc_loss = 0.08465579263176079
Trained batch 270 in epoch 1, gen_loss = 1.1673495037089414, disc_loss = 0.08446940418841434
Trained batch 271 in epoch 1, gen_loss = 1.1684929998043705, disc_loss = 0.08423291387118619
Trained batch 272 in epoch 1, gen_loss = 1.169791796923557, disc_loss = 0.08398105169990998
Trained batch 273 in epoch 1, gen_loss = 1.1687678314038437, disc_loss = 0.08391446866312602
Trained batch 274 in epoch 1, gen_loss = 1.1690297423709524, disc_loss = 0.08366318684748628
Trained batch 275 in epoch 1, gen_loss = 1.1692294782918433, disc_loss = 0.08378908484566795
Trained batch 276 in epoch 1, gen_loss = 1.1694773149404285, disc_loss = 0.0835480796885996
Trained batch 277 in epoch 1, gen_loss = 1.1706173859483047, disc_loss = 0.08330291832576124
Trained batch 278 in epoch 1, gen_loss = 1.1694935902045192, disc_loss = 0.083322067748368
Trained batch 279 in epoch 1, gen_loss = 1.1698464227574212, disc_loss = 0.083171397687069
Trained batch 280 in epoch 1, gen_loss = 1.1724156115827187, disc_loss = 0.08300297691410546
Trained batch 281 in epoch 1, gen_loss = 1.171159842758314, disc_loss = 0.08297119091482873
Trained batch 282 in epoch 1, gen_loss = 1.1712050265221208, disc_loss = 0.08276933623813487
Trained batch 283 in epoch 1, gen_loss = 1.1737168410294492, disc_loss = 0.08279301344194043
Trained batch 284 in epoch 1, gen_loss = 1.1717274201543708, disc_loss = 0.08314223077736403
Trained batch 285 in epoch 1, gen_loss = 1.1703638972102346, disc_loss = 0.08318139539731965
Trained batch 286 in epoch 1, gen_loss = 1.1737295401636316, disc_loss = 0.08503065105099296
Trained batch 287 in epoch 1, gen_loss = 1.1731596551835537, disc_loss = 0.08493916392843756
Trained batch 288 in epoch 1, gen_loss = 1.1715502363587746, disc_loss = 0.08507442229449955
Trained batch 289 in epoch 1, gen_loss = 1.1715447882126118, disc_loss = 0.0849199957503327
Trained batch 290 in epoch 1, gen_loss = 1.1704673279601683, disc_loss = 0.08500949130793617
Trained batch 291 in epoch 1, gen_loss = 1.1697003039186948, disc_loss = 0.08514066003518153
Trained batch 292 in epoch 1, gen_loss = 1.1696924371930926, disc_loss = 0.08500407495036874
Trained batch 293 in epoch 1, gen_loss = 1.1692853215194883, disc_loss = 0.08497177258285941
Trained batch 294 in epoch 1, gen_loss = 1.168323231349557, disc_loss = 0.08489847169336626
Trained batch 295 in epoch 1, gen_loss = 1.1695768585478938, disc_loss = 0.08467481290367809
Trained batch 296 in epoch 1, gen_loss = 1.168731734206781, disc_loss = 0.08472798528896036
Trained batch 297 in epoch 1, gen_loss = 1.1687596562324754, disc_loss = 0.08450222926701875
Trained batch 298 in epoch 1, gen_loss = 1.1691273648204612, disc_loss = 0.08434005763169913
Trained batch 299 in epoch 1, gen_loss = 1.1687074901660284, disc_loss = 0.08416308660060168
Trained batch 300 in epoch 1, gen_loss = 1.1674338244520548, disc_loss = 0.0841328601826267
Trained batch 301 in epoch 1, gen_loss = 1.167529543306654, disc_loss = 0.08422137415715006
Trained batch 302 in epoch 1, gen_loss = 1.1688618909801194, disc_loss = 0.08489861301217141
Trained batch 303 in epoch 1, gen_loss = 1.167103177426677, disc_loss = 0.08527574044848352
Trained batch 304 in epoch 1, gen_loss = 1.1658155937663843, disc_loss = 0.0854934755773818
Trained batch 305 in epoch 1, gen_loss = 1.1656703368511074, disc_loss = 0.08563802989041494
Trained batch 306 in epoch 1, gen_loss = 1.1651519855381223, disc_loss = 0.08553593356999589
Trained batch 307 in epoch 1, gen_loss = 1.1645385303667612, disc_loss = 0.08537760549890143
Trained batch 308 in epoch 1, gen_loss = 1.1642049969592911, disc_loss = 0.08528229054123838
Trained batch 309 in epoch 1, gen_loss = 1.1634776526881803, disc_loss = 0.0853832466948417
Trained batch 310 in epoch 1, gen_loss = 1.1626784897310558, disc_loss = 0.08528374811077424
Trained batch 311 in epoch 1, gen_loss = 1.1630228463655863, disc_loss = 0.08531966810234082
Trained batch 312 in epoch 1, gen_loss = 1.162080031423904, disc_loss = 0.08548035065586955
Trained batch 313 in epoch 1, gen_loss = 1.161008593193285, disc_loss = 0.08563156226638016
Trained batch 314 in epoch 1, gen_loss = 1.1597778284360492, disc_loss = 0.08584673868285285
Trained batch 315 in epoch 1, gen_loss = 1.158455507098874, disc_loss = 0.08602308566811719
Trained batch 316 in epoch 1, gen_loss = 1.1591331817750299, disc_loss = 0.0860012813180403
Trained batch 317 in epoch 1, gen_loss = 1.1590109848001469, disc_loss = 0.08580530766374285
Trained batch 318 in epoch 1, gen_loss = 1.158082560872583, disc_loss = 0.08573625471477972
Trained batch 319 in epoch 1, gen_loss = 1.15878775883466, disc_loss = 0.08568212961545214
Trained batch 320 in epoch 1, gen_loss = 1.1587845215173525, disc_loss = 0.08546066271413895
Trained batch 321 in epoch 1, gen_loss = 1.158233725321219, disc_loss = 0.08531555894368924
Trained batch 322 in epoch 1, gen_loss = 1.1581923797403695, disc_loss = 0.08529865822463582
Trained batch 323 in epoch 1, gen_loss = 1.1591447604659162, disc_loss = 0.08511899295550437
Trained batch 324 in epoch 1, gen_loss = 1.1594620468066288, disc_loss = 0.08496056009943669
Trained batch 325 in epoch 1, gen_loss = 1.159401197923473, disc_loss = 0.0848075125732122
Trained batch 326 in epoch 1, gen_loss = 1.1583992609190286, disc_loss = 0.08486055082638694
Trained batch 327 in epoch 1, gen_loss = 1.1604280887943943, disc_loss = 0.08521123456473394
Trained batch 328 in epoch 1, gen_loss = 1.158750004137903, disc_loss = 0.0854573622459155
Trained batch 329 in epoch 1, gen_loss = 1.159200837576028, disc_loss = 0.08571068629848234
Trained batch 330 in epoch 1, gen_loss = 1.1581888447355289, disc_loss = 0.08580048354145624
Trained batch 331 in epoch 1, gen_loss = 1.1589797354606262, disc_loss = 0.08606706679720118
Trained batch 332 in epoch 1, gen_loss = 1.1581747986532904, disc_loss = 0.08612080494518036
Trained batch 333 in epoch 1, gen_loss = 1.159293717609908, disc_loss = 0.08591516225593175
Trained batch 334 in epoch 1, gen_loss = 1.1590695174772347, disc_loss = 0.08579375783898938
Trained batch 335 in epoch 1, gen_loss = 1.1591258020628066, disc_loss = 0.08561568650683123
Trained batch 336 in epoch 1, gen_loss = 1.1592573539439577, disc_loss = 0.08562137996805527
Trained batch 337 in epoch 1, gen_loss = 1.1586566472194604, disc_loss = 0.08552912116800188
Trained batch 338 in epoch 1, gen_loss = 1.158704492898114, disc_loss = 0.08534955308610535
Trained batch 339 in epoch 1, gen_loss = 1.1602702796459199, disc_loss = 0.0861308200230055
Trained batch 340 in epoch 1, gen_loss = 1.158519934174602, disc_loss = 0.08659673714327498
Trained batch 341 in epoch 1, gen_loss = 1.1567775720392752, disc_loss = 0.0873053042348801
Trained batch 342 in epoch 1, gen_loss = 1.1575423633739483, disc_loss = 0.08785616750380909
Trained batch 343 in epoch 1, gen_loss = 1.1565218611165535, disc_loss = 0.0878924003444872
Trained batch 344 in epoch 1, gen_loss = 1.1550422614899234, disc_loss = 0.08821598570523918
Trained batch 345 in epoch 1, gen_loss = 1.1538083983983607, disc_loss = 0.08821937112902113
Trained batch 346 in epoch 1, gen_loss = 1.1531038818510533, disc_loss = 0.0882786828702482
Trained batch 347 in epoch 1, gen_loss = 1.1537346738850933, disc_loss = 0.08841350321904168
Trained batch 348 in epoch 1, gen_loss = 1.1532518709969726, disc_loss = 0.08834415215753381
Trained batch 349 in epoch 1, gen_loss = 1.1517919887815202, disc_loss = 0.08858824545251472
Trained batch 350 in epoch 1, gen_loss = 1.1524009446472863, disc_loss = 0.08909446360315183
Trained batch 351 in epoch 1, gen_loss = 1.1513021352954886, disc_loss = 0.08910086353584616
Trained batch 352 in epoch 1, gen_loss = 1.150229383460523, disc_loss = 0.08917389225964
Trained batch 353 in epoch 1, gen_loss = 1.1499824655258049, disc_loss = 0.08927239941191034
Trained batch 354 in epoch 1, gen_loss = 1.1493201568093099, disc_loss = 0.08918579141543785
Trained batch 355 in epoch 1, gen_loss = 1.1484037473630369, disc_loss = 0.08915624596450604
Trained batch 356 in epoch 1, gen_loss = 1.1476156756657512, disc_loss = 0.0892785441610409
Trained batch 357 in epoch 1, gen_loss = 1.1479614385346462, disc_loss = 0.08924569980912535
Trained batch 358 in epoch 1, gen_loss = 1.1473137563649658, disc_loss = 0.08915314691084175
Trained batch 359 in epoch 1, gen_loss = 1.1483594333132108, disc_loss = 0.08918103789393272
Trained batch 360 in epoch 1, gen_loss = 1.1476145056476224, disc_loss = 0.08940618890247351
Trained batch 361 in epoch 1, gen_loss = 1.1465944468316451, disc_loss = 0.08953707877711202
Trained batch 362 in epoch 1, gen_loss = 1.1451806580396395, disc_loss = 0.0898498849938149
Trained batch 363 in epoch 1, gen_loss = 1.1458113611071974, disc_loss = 0.0902479868433387
Trained batch 364 in epoch 1, gen_loss = 1.1446355274278823, disc_loss = 0.09028412251133625
Trained batch 365 in epoch 1, gen_loss = 1.1446066840750273, disc_loss = 0.09015295954288843
Trained batch 366 in epoch 1, gen_loss = 1.1461606704571592, disc_loss = 0.09003615503679017
Trained batch 367 in epoch 1, gen_loss = 1.14544406209303, disc_loss = 0.09002126375233512
Trained batch 368 in epoch 1, gen_loss = 1.144755262669509, disc_loss = 0.089940840842803
Trained batch 369 in epoch 1, gen_loss = 1.144960616730355, disc_loss = 0.08987002846457669
Trained batch 370 in epoch 1, gen_loss = 1.1457965476814949, disc_loss = 0.08970527019542504
Trained batch 371 in epoch 1, gen_loss = 1.1447845923323785, disc_loss = 0.08990689849741357
Trained batch 372 in epoch 1, gen_loss = 1.1439385279893235, disc_loss = 0.08985648827562383
Trained batch 373 in epoch 1, gen_loss = 1.1450209859858222, disc_loss = 0.09007568225105178
Trained batch 374 in epoch 1, gen_loss = 1.1438408889770508, disc_loss = 0.09018801579872768
Trained batch 375 in epoch 1, gen_loss = 1.143062634195419, disc_loss = 0.0906597241323362
Trained batch 376 in epoch 1, gen_loss = 1.1422029788993715, disc_loss = 0.09062670173237115
Trained batch 377 in epoch 1, gen_loss = 1.1409232219060261, disc_loss = 0.09078593585620481
Trained batch 378 in epoch 1, gen_loss = 1.1415375694435945, disc_loss = 0.09115160944672562
Trained batch 379 in epoch 1, gen_loss = 1.1410838133410404, disc_loss = 0.09109893911763241
Trained batch 380 in epoch 1, gen_loss = 1.1402907545172323, disc_loss = 0.09112317128757166
Trained batch 381 in epoch 1, gen_loss = 1.1403638609728888, disc_loss = 0.09110367822787524
Trained batch 382 in epoch 1, gen_loss = 1.1402413610067443, disc_loss = 0.09095661995771971
Trained batch 383 in epoch 1, gen_loss = 1.1390777567091088, disc_loss = 0.09106595717215289
Trained batch 384 in epoch 1, gen_loss = 1.1401865013234027, disc_loss = 0.09115396542595579
Trained batch 385 in epoch 1, gen_loss = 1.1399900022257177, disc_loss = 0.09103016182780266
Trained batch 386 in epoch 1, gen_loss = 1.13860504494773, disc_loss = 0.09159827877307739
Trained batch 387 in epoch 1, gen_loss = 1.1396830114199943, disc_loss = 0.09153122692993007
Trained batch 388 in epoch 1, gen_loss = 1.1392357992942046, disc_loss = 0.0913857395992947
Trained batch 389 in epoch 1, gen_loss = 1.1386062331688709, disc_loss = 0.09133464354926195
Trained batch 390 in epoch 1, gen_loss = 1.1392558959438979, disc_loss = 0.09114813196765797
Trained batch 391 in epoch 1, gen_loss = 1.1400762294628182, disc_loss = 0.09108966723920739
Trained batch 392 in epoch 1, gen_loss = 1.139531588129718, disc_loss = 0.09100287889175439
Trained batch 393 in epoch 1, gen_loss = 1.1396749769975691, disc_loss = 0.09084320215858178
Trained batch 394 in epoch 1, gen_loss = 1.1395517814008496, disc_loss = 0.0906776841541257
Trained batch 395 in epoch 1, gen_loss = 1.140441483921475, disc_loss = 0.09053658177097788
Trained batch 396 in epoch 1, gen_loss = 1.1408099221342456, disc_loss = 0.09111110909703547
Trained batch 397 in epoch 1, gen_loss = 1.139340124387837, disc_loss = 0.0917620430723881
Trained batch 398 in epoch 1, gen_loss = 1.1394238763285758, disc_loss = 0.0916402179766493
Trained batch 399 in epoch 1, gen_loss = 1.1402676771581173, disc_loss = 0.09186941586900503
Trained batch 400 in epoch 1, gen_loss = 1.1390759128882106, disc_loss = 0.09200103142928155
Trained batch 401 in epoch 1, gen_loss = 1.138678584377564, disc_loss = 0.09189213716438902
Trained batch 402 in epoch 1, gen_loss = 1.1390741221957998, disc_loss = 0.09202359713355159
Trained batch 403 in epoch 1, gen_loss = 1.1388130856327492, disc_loss = 0.09197022983951882
Trained batch 404 in epoch 1, gen_loss = 1.1383970156128025, disc_loss = 0.091980955818737
Trained batch 405 in epoch 1, gen_loss = 1.139278937002708, disc_loss = 0.09192723153718733
Trained batch 406 in epoch 1, gen_loss = 1.1403201942947632, disc_loss = 0.09179274602827481
Trained batch 407 in epoch 1, gen_loss = 1.1410825534486304, disc_loss = 0.09160803704906036
Trained batch 408 in epoch 1, gen_loss = 1.1416242607939797, disc_loss = 0.09148234347550968
Trained batch 409 in epoch 1, gen_loss = 1.1414155926646257, disc_loss = 0.09136488965553481
Trained batch 410 in epoch 1, gen_loss = 1.1417764296206825, disc_loss = 0.09122459198871669
Trained batch 411 in epoch 1, gen_loss = 1.1422773705234806, disc_loss = 0.0910529541168181
Trained batch 412 in epoch 1, gen_loss = 1.142167239298832, disc_loss = 0.09094043384073866
Trained batch 413 in epoch 1, gen_loss = 1.1427467469719872, disc_loss = 0.09075350097520052
Trained batch 414 in epoch 1, gen_loss = 1.144607652095427, disc_loss = 0.0906183223946985
Trained batch 415 in epoch 1, gen_loss = 1.145092024682806, disc_loss = 0.0904412865280532
Trained batch 416 in epoch 1, gen_loss = 1.1458548074431842, disc_loss = 0.09029363706815156
Trained batch 417 in epoch 1, gen_loss = 1.146264911696101, disc_loss = 0.09017324059060886
Trained batch 418 in epoch 1, gen_loss = 1.1471299716851593, disc_loss = 0.09000626654499755
Trained batch 419 in epoch 1, gen_loss = 1.1469388239440463, disc_loss = 0.08986402659543923
Trained batch 420 in epoch 1, gen_loss = 1.1469168845661462, disc_loss = 0.08970249085875136
Trained batch 421 in epoch 1, gen_loss = 1.1482606602223564, disc_loss = 0.08959092555558794
Trained batch 422 in epoch 1, gen_loss = 1.1492358816712742, disc_loss = 0.09032892507124454
Trained batch 423 in epoch 1, gen_loss = 1.1479766924145087, disc_loss = 0.09059036680374224
Trained batch 424 in epoch 1, gen_loss = 1.1476483001428492, disc_loss = 0.09047239509575507
Trained batch 425 in epoch 1, gen_loss = 1.1475281045190606, disc_loss = 0.09037082085272236
Trained batch 426 in epoch 1, gen_loss = 1.14717362901366, disc_loss = 0.09028142738642403
Trained batch 427 in epoch 1, gen_loss = 1.1479405764942971, disc_loss = 0.09022751108473429
Trained batch 428 in epoch 1, gen_loss = 1.148287689630246, disc_loss = 0.0900572949547173
Trained batch 429 in epoch 1, gen_loss = 1.148162071510803, disc_loss = 0.08991009132113567
Trained batch 430 in epoch 1, gen_loss = 1.1485481114232623, disc_loss = 0.09031124115681703
Trained batch 431 in epoch 1, gen_loss = 1.148008632991049, disc_loss = 0.09024167421308381
Trained batch 432 in epoch 1, gen_loss = 1.1475461410319832, disc_loss = 0.09017635875878378
Trained batch 433 in epoch 1, gen_loss = 1.147740669514177, disc_loss = 0.09010201799876404
Trained batch 434 in epoch 1, gen_loss = 1.14728135363809, disc_loss = 0.09001422266679249
Trained batch 435 in epoch 1, gen_loss = 1.1476043660979751, disc_loss = 0.08993283232861976
Trained batch 436 in epoch 1, gen_loss = 1.1481768655285955, disc_loss = 0.089750337075587
Trained batch 437 in epoch 1, gen_loss = 1.1483575798332963, disc_loss = 0.08958795036031911
Trained batch 438 in epoch 1, gen_loss = 1.1479692605742018, disc_loss = 0.08948763968647884
Trained batch 439 in epoch 1, gen_loss = 1.1492132674564015, disc_loss = 0.08932526793161577
Trained batch 440 in epoch 1, gen_loss = 1.1494136905453913, disc_loss = 0.08917766844942457
Trained batch 441 in epoch 1, gen_loss = 1.1495948973284587, disc_loss = 0.08910921060088263
Trained batch 442 in epoch 1, gen_loss = 1.1488484903060017, disc_loss = 0.0890897371244888
Trained batch 443 in epoch 1, gen_loss = 1.1493974658283028, disc_loss = 0.08893941843311663
Trained batch 444 in epoch 1, gen_loss = 1.150897368956148, disc_loss = 0.0888398335765252
Trained batch 445 in epoch 1, gen_loss = 1.1509792777989478, disc_loss = 0.0886894237467259
Trained batch 446 in epoch 1, gen_loss = 1.150488842653748, disc_loss = 0.0885954067211023
Trained batch 447 in epoch 1, gen_loss = 1.151621543802321, disc_loss = 0.0884468216681853
Trained batch 448 in epoch 1, gen_loss = 1.1521542899327182, disc_loss = 0.08827913796865197
Trained batch 449 in epoch 1, gen_loss = 1.1536899893813664, disc_loss = 0.08820716667920352
Trained batch 450 in epoch 1, gen_loss = 1.153049720232344, disc_loss = 0.0881859434690087
Trained batch 451 in epoch 1, gen_loss = 1.1525939825625546, disc_loss = 0.08809770912805621
Trained batch 452 in epoch 1, gen_loss = 1.1528796187826076, disc_loss = 0.08801231342090281
Trained batch 453 in epoch 1, gen_loss = 1.152367076684725, disc_loss = 0.08796963517016645
Trained batch 454 in epoch 1, gen_loss = 1.1538630275935917, disc_loss = 0.08784542653177466
Trained batch 455 in epoch 1, gen_loss = 1.1551652699708939, disc_loss = 0.08775974055670463
Trained batch 456 in epoch 1, gen_loss = 1.1545655269591502, disc_loss = 0.08768107367504217
Trained batch 457 in epoch 1, gen_loss = 1.154818638313285, disc_loss = 0.08751755797885781
Trained batch 458 in epoch 1, gen_loss = 1.1546048314223363, disc_loss = 0.08750595987930666
Trained batch 459 in epoch 1, gen_loss = 1.154052435056023, disc_loss = 0.08762414025790666
Trained batch 460 in epoch 1, gen_loss = 1.154099473725689, disc_loss = 0.08746776701943089
Trained batch 461 in epoch 1, gen_loss = 1.1544562020859161, disc_loss = 0.08736619193235905
Trained batch 462 in epoch 1, gen_loss = 1.1538109913243073, disc_loss = 0.0873299718957161
Trained batch 463 in epoch 1, gen_loss = 1.1540112264197449, disc_loss = 0.08721107371745566
Trained batch 464 in epoch 1, gen_loss = 1.1552490224120437, disc_loss = 0.08708713277773832
Trained batch 465 in epoch 1, gen_loss = 1.1557005602914376, disc_loss = 0.08697073966216759
Trained batch 466 in epoch 1, gen_loss = 1.1549897132644817, disc_loss = 0.08695878312231003
Trained batch 467 in epoch 1, gen_loss = 1.1559991006158357, disc_loss = 0.08682263299870567
Trained batch 468 in epoch 1, gen_loss = 1.155282669484234, disc_loss = 0.08685562686164623
Trained batch 469 in epoch 1, gen_loss = 1.1563661273489607, disc_loss = 0.08722706479515802
Trained batch 470 in epoch 1, gen_loss = 1.1558131187078553, disc_loss = 0.08720656743395734
Trained batch 471 in epoch 1, gen_loss = 1.1550114296250424, disc_loss = 0.08721326534257476
Trained batch 472 in epoch 1, gen_loss = 1.1547500053873525, disc_loss = 0.08710683245471744
Trained batch 473 in epoch 1, gen_loss = 1.1550966186865472, disc_loss = 0.08704283576112885
Trained batch 474 in epoch 1, gen_loss = 1.155562468578941, disc_loss = 0.08694428213724964
Trained batch 475 in epoch 1, gen_loss = 1.155773542257918, disc_loss = 0.08678779890369467
Trained batch 476 in epoch 1, gen_loss = 1.155112296280371, disc_loss = 0.08673785353544124
Trained batch 477 in epoch 1, gen_loss = 1.1557061961505204, disc_loss = 0.08658153749028197
Trained batch 478 in epoch 1, gen_loss = 1.1570590164566836, disc_loss = 0.086585387134524
Trained batch 479 in epoch 1, gen_loss = 1.1559992675979933, disc_loss = 0.08680330066126771
Trained batch 480 in epoch 1, gen_loss = 1.1553405394425262, disc_loss = 0.08679725890959808
Trained batch 481 in epoch 1, gen_loss = 1.1561922940475813, disc_loss = 0.08688042298755395
Trained batch 482 in epoch 1, gen_loss = 1.15664657820826, disc_loss = 0.0867881767941527
Trained batch 483 in epoch 1, gen_loss = 1.155771839963503, disc_loss = 0.0867887488277706
Trained batch 484 in epoch 1, gen_loss = 1.1558408872368409, disc_loss = 0.08683976108381121
Trained batch 485 in epoch 1, gen_loss = 1.154876537651682, disc_loss = 0.08706634643261509
Trained batch 486 in epoch 1, gen_loss = 1.1561495544239726, disc_loss = 0.08734926900939224
Trained batch 487 in epoch 1, gen_loss = 1.1568029397090926, disc_loss = 0.08724785414257194
Trained batch 488 in epoch 1, gen_loss = 1.1557421859788017, disc_loss = 0.0875343653089643
Trained batch 489 in epoch 1, gen_loss = 1.1558557104091256, disc_loss = 0.0874150029003468
Trained batch 490 in epoch 1, gen_loss = 1.1563716383912657, disc_loss = 0.08742760501748857
Trained batch 491 in epoch 1, gen_loss = 1.1569271962332532, disc_loss = 0.08730223336317615
Trained batch 492 in epoch 1, gen_loss = 1.1567693116940543, disc_loss = 0.08719790736534472
Trained batch 493 in epoch 1, gen_loss = 1.1563288369159468, disc_loss = 0.08713369317888188
Trained batch 494 in epoch 1, gen_loss = 1.156916092140506, disc_loss = 0.08699244120619212
Trained batch 495 in epoch 1, gen_loss = 1.1577591513914447, disc_loss = 0.08704855201217616
Trained batch 496 in epoch 1, gen_loss = 1.157177821491326, disc_loss = 0.08703645233109863
Trained batch 497 in epoch 1, gen_loss = 1.1563222542345284, disc_loss = 0.08715313113290801
Trained batch 498 in epoch 1, gen_loss = 1.1564070466525092, disc_loss = 0.08721466617610209
Trained batch 499 in epoch 1, gen_loss = 1.1562679286003112, disc_loss = 0.08714610263518989
Trained batch 500 in epoch 1, gen_loss = 1.15594846616962, disc_loss = 0.08705287010124522
Trained batch 501 in epoch 1, gen_loss = 1.1560633415244965, disc_loss = 0.08691129046659249
Trained batch 502 in epoch 1, gen_loss = 1.155666992749656, disc_loss = 0.08690730060004513
Trained batch 503 in epoch 1, gen_loss = 1.1570525674356356, disc_loss = 0.08685899504999971
Trained batch 504 in epoch 1, gen_loss = 1.156276028345127, disc_loss = 0.08689074542668491
Trained batch 505 in epoch 1, gen_loss = 1.1556305568444398, disc_loss = 0.08685645637592014
Trained batch 506 in epoch 1, gen_loss = 1.155496041802965, disc_loss = 0.08672128706487149
Trained batch 507 in epoch 1, gen_loss = 1.1558983960724252, disc_loss = 0.08659616951082694
Trained batch 508 in epoch 1, gen_loss = 1.1560079321880004, disc_loss = 0.08649753671037015
Trained batch 509 in epoch 1, gen_loss = 1.1569913697008993, disc_loss = 0.08646635552137798
Trained batch 510 in epoch 1, gen_loss = 1.1561811432213234, disc_loss = 0.08645578839956489
Trained batch 511 in epoch 1, gen_loss = 1.1560072926804423, disc_loss = 0.08635149626388738
Trained batch 512 in epoch 1, gen_loss = 1.1565361840915493, disc_loss = 0.08644635537657415
Trained batch 513 in epoch 1, gen_loss = 1.1563479812228725, disc_loss = 0.08637903484512222
Trained batch 514 in epoch 1, gen_loss = 1.1560935409323683, disc_loss = 0.08633458686865939
Trained batch 515 in epoch 1, gen_loss = 1.1552972024263337, disc_loss = 0.08643218150268518
Trained batch 516 in epoch 1, gen_loss = 1.1554592382054725, disc_loss = 0.08633611508513615
Trained batch 517 in epoch 1, gen_loss = 1.1570348778746764, disc_loss = 0.08651605357944563
Trained batch 518 in epoch 1, gen_loss = 1.1564463891505277, disc_loss = 0.0865748027404178
Trained batch 519 in epoch 1, gen_loss = 1.1559149326040195, disc_loss = 0.08662384420525855
Trained batch 520 in epoch 1, gen_loss = 1.1563433210817728, disc_loss = 0.08649017925833614
Trained batch 521 in epoch 1, gen_loss = 1.1569373907942424, disc_loss = 0.0863848149979851
Trained batch 522 in epoch 1, gen_loss = 1.157237708568573, disc_loss = 0.08635722152910144
Trained batch 523 in epoch 1, gen_loss = 1.156207198860081, disc_loss = 0.08649946588006241
Trained batch 524 in epoch 1, gen_loss = 1.156365079198565, disc_loss = 0.08638083728473811
Trained batch 525 in epoch 1, gen_loss = 1.1568622081451996, disc_loss = 0.08635447111455263
Trained batch 526 in epoch 1, gen_loss = 1.1567288702760294, disc_loss = 0.08624341939549462
Trained batch 527 in epoch 1, gen_loss = 1.1565775523583095, disc_loss = 0.08613526919031177
Trained batch 528 in epoch 1, gen_loss = 1.1566715560473206, disc_loss = 0.08603297588582695
Trained batch 529 in epoch 1, gen_loss = 1.1574274137335003, disc_loss = 0.08589486578690275
Trained batch 530 in epoch 1, gen_loss = 1.1578802094845673, disc_loss = 0.08578518572352868
Trained batch 531 in epoch 1, gen_loss = 1.1576389219976009, disc_loss = 0.08570039331653904
Trained batch 532 in epoch 1, gen_loss = 1.1575543220673896, disc_loss = 0.0856045383809739
Trained batch 533 in epoch 1, gen_loss = 1.158595676056008, disc_loss = 0.0854922286444082
Trained batch 534 in epoch 1, gen_loss = 1.1574775476321997, disc_loss = 0.08564309080383767
Trained batch 535 in epoch 1, gen_loss = 1.1586392329477553, disc_loss = 0.08568810158124221
Trained batch 536 in epoch 1, gen_loss = 1.1591591669638508, disc_loss = 0.08558086633814058
Trained batch 537 in epoch 1, gen_loss = 1.1588317702029274, disc_loss = 0.08551158811931661
Trained batch 538 in epoch 1, gen_loss = 1.1585742448610366, disc_loss = 0.08548378653250677
Trained batch 539 in epoch 1, gen_loss = 1.1581975322078775, disc_loss = 0.08541154765385997
Trained batch 540 in epoch 1, gen_loss = 1.1582508200638395, disc_loss = 0.08530429582147689
Trained batch 541 in epoch 1, gen_loss = 1.1581005560735935, disc_loss = 0.08527957603534704
Trained batch 542 in epoch 1, gen_loss = 1.1576298260117983, disc_loss = 0.08535037386791976
Trained batch 543 in epoch 1, gen_loss = 1.1570101584143497, disc_loss = 0.08534290851949823
Trained batch 544 in epoch 1, gen_loss = 1.1579858149957218, disc_loss = 0.08531543491664556
Trained batch 545 in epoch 1, gen_loss = 1.1578483026979607, disc_loss = 0.08523484000990733
Trained batch 546 in epoch 1, gen_loss = 1.157342305240073, disc_loss = 0.08518764863754376
Trained batch 547 in epoch 1, gen_loss = 1.1566073923867985, disc_loss = 0.08531614191265927
Trained batch 548 in epoch 1, gen_loss = 1.1562701532098114, disc_loss = 0.08539446935444418
Trained batch 549 in epoch 1, gen_loss = 1.156831423260949, disc_loss = 0.08528891808099368
Trained batch 550 in epoch 1, gen_loss = 1.156534959205482, disc_loss = 0.08523423171444997
Trained batch 551 in epoch 1, gen_loss = 1.156498763980209, disc_loss = 0.08513790076983202
Trained batch 552 in epoch 1, gen_loss = 1.1575690427050669, disc_loss = 0.08503891419026509
Trained batch 553 in epoch 1, gen_loss = 1.157211419907718, disc_loss = 0.08497014041781586
Trained batch 554 in epoch 1, gen_loss = 1.1576597157899324, disc_loss = 0.08485284499186385
Trained batch 555 in epoch 1, gen_loss = 1.1586387648428087, disc_loss = 0.08484402674638915
Trained batch 556 in epoch 1, gen_loss = 1.1583961413193433, disc_loss = 0.08479704993277039
Trained batch 557 in epoch 1, gen_loss = 1.1577791164639175, disc_loss = 0.08477672033752966
Trained batch 558 in epoch 1, gen_loss = 1.1583282076395476, disc_loss = 0.08469492398795533
Trained batch 559 in epoch 1, gen_loss = 1.1584826413009848, disc_loss = 0.0847235055557186
Trained batch 560 in epoch 1, gen_loss = 1.157660105117927, disc_loss = 0.08481560285417314
Trained batch 561 in epoch 1, gen_loss = 1.1574999778084059, disc_loss = 0.08474736545877896
Trained batch 562 in epoch 1, gen_loss = 1.1571595049454941, disc_loss = 0.08468333057245342
Trained batch 563 in epoch 1, gen_loss = 1.15724730269706, disc_loss = 0.08457058219483506
Trained batch 564 in epoch 1, gen_loss = 1.15741788169979, disc_loss = 0.08461330898798408
Trained batch 565 in epoch 1, gen_loss = 1.157275312464987, disc_loss = 0.08452282069816974
Trained batch 566 in epoch 1, gen_loss = 1.1570530220524553, disc_loss = 0.08441418686116235
Trained batch 567 in epoch 1, gen_loss = 1.1571089597025388, disc_loss = 0.08449924971521373
Trained batch 568 in epoch 1, gen_loss = 1.1565344088525888, disc_loss = 0.08447429848923257
Trained batch 569 in epoch 1, gen_loss = 1.1564798001657453, disc_loss = 0.08439507841443022
Trained batch 570 in epoch 1, gen_loss = 1.1573080308800612, disc_loss = 0.0843376361058728
Trained batch 571 in epoch 1, gen_loss = 1.1581723266965025, disc_loss = 0.08428791000090956
Trained batch 572 in epoch 1, gen_loss = 1.1577373381060456, disc_loss = 0.08427330699585131
Trained batch 573 in epoch 1, gen_loss = 1.15801852193859, disc_loss = 0.08419460519168279
Trained batch 574 in epoch 1, gen_loss = 1.158131128601406, disc_loss = 0.08406998537156893
Trained batch 575 in epoch 1, gen_loss = 1.158292805776, disc_loss = 0.08398445755139822
Trained batch 576 in epoch 1, gen_loss = 1.15887006523291, disc_loss = 0.08389515273492505
Trained batch 577 in epoch 1, gen_loss = 1.1581079345260936, disc_loss = 0.0839532086799714
Trained batch 578 in epoch 1, gen_loss = 1.1580890962702828, disc_loss = 0.08391728271474493
Trained batch 579 in epoch 1, gen_loss = 1.1583303659126676, disc_loss = 0.08378837969603724
Trained batch 580 in epoch 1, gen_loss = 1.1579097818179303, disc_loss = 0.08376955749104745
Trained batch 581 in epoch 1, gen_loss = 1.158034785404238, disc_loss = 0.08367666959621754
Trained batch 582 in epoch 1, gen_loss = 1.1582646487507566, disc_loss = 0.08355831612527728
Trained batch 583 in epoch 1, gen_loss = 1.1590832042163366, disc_loss = 0.08343945583169132
Trained batch 584 in epoch 1, gen_loss = 1.1590303269206967, disc_loss = 0.08352955744530145
Trained batch 585 in epoch 1, gen_loss = 1.1583838771024255, disc_loss = 0.08350887246677849
Trained batch 586 in epoch 1, gen_loss = 1.157441249190238, disc_loss = 0.08365398546874371
Trained batch 587 in epoch 1, gen_loss = 1.1586910481152892, disc_loss = 0.08369631438554094
Trained batch 588 in epoch 1, gen_loss = 1.1593167995354112, disc_loss = 0.08362826597299712
Trained batch 589 in epoch 1, gen_loss = 1.1588451144048724, disc_loss = 0.08364621937369644
Trained batch 590 in epoch 1, gen_loss = 1.1587872268181363, disc_loss = 0.08357182965659601
Trained batch 591 in epoch 1, gen_loss = 1.1582055419079356, disc_loss = 0.08360984917522434
Trained batch 592 in epoch 1, gen_loss = 1.1593194354645922, disc_loss = 0.08362981082610849
Trained batch 593 in epoch 1, gen_loss = 1.1593189559600972, disc_loss = 0.08354992633183747
Trained batch 594 in epoch 1, gen_loss = 1.159554192699304, disc_loss = 0.08345817471345683
Trained batch 595 in epoch 1, gen_loss = 1.1597125997279314, disc_loss = 0.08335219198156574
Trained batch 596 in epoch 1, gen_loss = 1.1596700423326924, disc_loss = 0.08327579576447232
Trained batch 597 in epoch 1, gen_loss = 1.1593156075198514, disc_loss = 0.08339215369807887
Trained batch 598 in epoch 1, gen_loss = 1.1591665807470855, disc_loss = 0.08363718596226434
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 1.262548804283142, disc_loss = 0.13213317096233368
Trained batch 1 in epoch 2, gen_loss = 0.9641703069210052, disc_loss = 0.1586252823472023
Trained batch 2 in epoch 2, gen_loss = 1.1812817056973774, disc_loss = 0.12407903124888738
Trained batch 3 in epoch 2, gen_loss = 1.1760146468877792, disc_loss = 0.1017740173265338
Trained batch 4 in epoch 2, gen_loss = 1.361273992061615, disc_loss = 0.1058275930583477
Trained batch 5 in epoch 2, gen_loss = 1.2629062632719676, disc_loss = 0.10501259751617908
Trained batch 6 in epoch 2, gen_loss = 1.2265951548303877, disc_loss = 0.1093223834676402
Trained batch 7 in epoch 2, gen_loss = 1.190585806965828, disc_loss = 0.10326343821361661
Trained batch 8 in epoch 2, gen_loss = 1.1495038006040785, disc_loss = 0.10246094109283553
Trained batch 9 in epoch 2, gen_loss = 1.2384613633155823, disc_loss = 0.12282839752733707
Trained batch 10 in epoch 2, gen_loss = 1.2531065832484851, disc_loss = 0.11540176143700426
Trained batch 11 in epoch 2, gen_loss = 1.2214392075936, disc_loss = 0.11478556723644336
Trained batch 12 in epoch 2, gen_loss = 1.2012160695516145, disc_loss = 0.11357152490661694
Trained batch 13 in epoch 2, gen_loss = 1.1918883451393671, disc_loss = 0.10973340645432472
Trained batch 14 in epoch 2, gen_loss = 1.1603941480318705, disc_loss = 0.11313120673100154
Trained batch 15 in epoch 2, gen_loss = 1.1585427410900593, disc_loss = 0.11009670700877905
Trained batch 16 in epoch 2, gen_loss = 1.194802750559414, disc_loss = 0.10993310765308492
Trained batch 17 in epoch 2, gen_loss = 1.192226207918591, disc_loss = 0.10553129472666317
Trained batch 18 in epoch 2, gen_loss = 1.1814401934021397, disc_loss = 0.102000379836873
Trained batch 19 in epoch 2, gen_loss = 1.1773989707231522, disc_loss = 0.10595254655927419
Trained batch 20 in epoch 2, gen_loss = 1.167083203792572, disc_loss = 0.10319660728176434
Trained batch 21 in epoch 2, gen_loss = 1.1592413891445508, disc_loss = 0.10025686838410118
Trained batch 22 in epoch 2, gen_loss = 1.1793978369754294, disc_loss = 0.09688527274714864
Trained batch 23 in epoch 2, gen_loss = 1.169852763414383, disc_loss = 0.09533750956567626
Trained batch 24 in epoch 2, gen_loss = 1.1660353660583496, disc_loss = 0.09529446132481098
Trained batch 25 in epoch 2, gen_loss = 1.1760192009118886, disc_loss = 0.09482662730778639
Trained batch 26 in epoch 2, gen_loss = 1.1602547610247578, disc_loss = 0.09510411246231308
Trained batch 27 in epoch 2, gen_loss = 1.1575357828821455, disc_loss = 0.09746699973142572
Trained batch 28 in epoch 2, gen_loss = 1.1507979466997345, disc_loss = 0.09537929238687301
Trained batch 29 in epoch 2, gen_loss = 1.150543717543284, disc_loss = 0.09398685488849878
Trained batch 30 in epoch 2, gen_loss = 1.141026485350824, disc_loss = 0.09386570937931538
Trained batch 31 in epoch 2, gen_loss = 1.1507251225411892, disc_loss = 0.09995648957556114
Trained batch 32 in epoch 2, gen_loss = 1.1372202707059456, disc_loss = 0.10226957087941242
Trained batch 33 in epoch 2, gen_loss = 1.1349889741224402, disc_loss = 0.100669978898676
Trained batch 34 in epoch 2, gen_loss = 1.1360128198351178, disc_loss = 0.10274325752896922
Trained batch 35 in epoch 2, gen_loss = 1.1379417247242398, disc_loss = 0.10135587589401338
Trained batch 36 in epoch 2, gen_loss = 1.1366236950900104, disc_loss = 0.09970833607823462
Trained batch 37 in epoch 2, gen_loss = 1.1414538433677273, disc_loss = 0.09766930204473044
Trained batch 38 in epoch 2, gen_loss = 1.1346473861963322, disc_loss = 0.09872274005260223
Trained batch 39 in epoch 2, gen_loss = 1.1274079456925392, disc_loss = 0.09795571435242892
Trained batch 40 in epoch 2, gen_loss = 1.1296738953125187, disc_loss = 0.09774855415268642
Trained batch 41 in epoch 2, gen_loss = 1.1388873642399198, disc_loss = 0.09704787426051639
Trained batch 42 in epoch 2, gen_loss = 1.1286295707835707, disc_loss = 0.09867715835571289
Trained batch 43 in epoch 2, gen_loss = 1.127041071653366, disc_loss = 0.09733553603291512
Trained batch 44 in epoch 2, gen_loss = 1.1320966243743897, disc_loss = 0.09740888443258074
Trained batch 45 in epoch 2, gen_loss = 1.1313992583233377, disc_loss = 0.09744914783083874
Trained batch 46 in epoch 2, gen_loss = 1.1269722339954782, disc_loss = 0.09666022460194344
Trained batch 47 in epoch 2, gen_loss = 1.1220812673370044, disc_loss = 0.09586890740320086
Trained batch 48 in epoch 2, gen_loss = 1.1234922044131221, disc_loss = 0.09448995380377283
Trained batch 49 in epoch 2, gen_loss = 1.1372072005271912, disc_loss = 0.09405301257967949
Trained batch 50 in epoch 2, gen_loss = 1.1439110204285265, disc_loss = 0.09254440402283388
Trained batch 51 in epoch 2, gen_loss = 1.134600281715393, disc_loss = 0.09386027718965824
Trained batch 52 in epoch 2, gen_loss = 1.1325937801936887, disc_loss = 0.092934158331943
Trained batch 53 in epoch 2, gen_loss = 1.1377320973961442, disc_loss = 0.09323747276707932
Trained batch 54 in epoch 2, gen_loss = 1.1458597204901955, disc_loss = 0.0924173122102564
Trained batch 55 in epoch 2, gen_loss = 1.1355615077274186, disc_loss = 0.09331928539488997
Trained batch 56 in epoch 2, gen_loss = 1.1293369176094992, disc_loss = 0.09439593788824584
Trained batch 57 in epoch 2, gen_loss = 1.1320761976570919, disc_loss = 0.09528715523152516
Trained batch 58 in epoch 2, gen_loss = 1.1283622586120994, disc_loss = 0.09453749423057346
Trained batch 59 in epoch 2, gen_loss = 1.1276233742634456, disc_loss = 0.0944266385709246
Trained batch 60 in epoch 2, gen_loss = 1.1241250262885798, disc_loss = 0.09384440270359398
Trained batch 61 in epoch 2, gen_loss = 1.118209392793717, disc_loss = 0.09390665801061739
Trained batch 62 in epoch 2, gen_loss = 1.1286039957924494, disc_loss = 0.0964360007099689
Trained batch 63 in epoch 2, gen_loss = 1.1323559619486332, disc_loss = 0.09517282561864704
Trained batch 64 in epoch 2, gen_loss = 1.1264681302584134, disc_loss = 0.0952135858627466
Trained batch 65 in epoch 2, gen_loss = 1.120490292708079, disc_loss = 0.09573784854375955
Trained batch 66 in epoch 2, gen_loss = 1.1194802344734989, disc_loss = 0.09828293746087088
Trained batch 67 in epoch 2, gen_loss = 1.1183883144575006, disc_loss = 0.09885137046084684
Trained batch 68 in epoch 2, gen_loss = 1.111723762491475, disc_loss = 0.09983885957710985
Trained batch 69 in epoch 2, gen_loss = 1.1133582668645041, disc_loss = 0.09893189344022955
Trained batch 70 in epoch 2, gen_loss = 1.1151090751231556, disc_loss = 0.09888671669112124
Trained batch 71 in epoch 2, gen_loss = 1.1151858841379483, disc_loss = 0.0979397718846384
Trained batch 72 in epoch 2, gen_loss = 1.1130052184405392, disc_loss = 0.09726455856165657
Trained batch 73 in epoch 2, gen_loss = 1.1082570391732294, disc_loss = 0.09743396653416189
Trained batch 74 in epoch 2, gen_loss = 1.1136323070526124, disc_loss = 0.09925858515004317
Trained batch 75 in epoch 2, gen_loss = 1.1113179929946597, disc_loss = 0.09861919536304317
Trained batch 76 in epoch 2, gen_loss = 1.1109167670274709, disc_loss = 0.09765426190449046
Trained batch 77 in epoch 2, gen_loss = 1.1082436335392487, disc_loss = 0.09686501906850399
Trained batch 78 in epoch 2, gen_loss = 1.1100721902485136, disc_loss = 0.0958527087976661
Trained batch 79 in epoch 2, gen_loss = 1.116226953268051, disc_loss = 0.09514931561425329
Trained batch 80 in epoch 2, gen_loss = 1.1164691595383633, disc_loss = 0.09433338161052009
Trained batch 81 in epoch 2, gen_loss = 1.1185299158096313, disc_loss = 0.09332075712793483
Trained batch 82 in epoch 2, gen_loss = 1.1180808055831726, disc_loss = 0.09262645368026681
Trained batch 83 in epoch 2, gen_loss = 1.1153425389812106, disc_loss = 0.09247953282846581
Trained batch 84 in epoch 2, gen_loss = 1.117685451227076, disc_loss = 0.09195899759583613
Trained batch 85 in epoch 2, gen_loss = 1.1244952179664789, disc_loss = 0.09709029148744289
Trained batch 86 in epoch 2, gen_loss = 1.1177762500171005, disc_loss = 0.09814330359556894
Trained batch 87 in epoch 2, gen_loss = 1.115559770302339, disc_loss = 0.09788764164444398
Trained batch 88 in epoch 2, gen_loss = 1.1123648172014216, disc_loss = 0.09778614340119818
Trained batch 89 in epoch 2, gen_loss = 1.1147994518280029, disc_loss = 0.09828452416178253
Trained batch 90 in epoch 2, gen_loss = 1.113267081124442, disc_loss = 0.0991797314363194
Trained batch 91 in epoch 2, gen_loss = 1.1079748674579288, disc_loss = 0.09955892175355036
Trained batch 92 in epoch 2, gen_loss = 1.1073443453799012, disc_loss = 0.09952162444511409
Trained batch 93 in epoch 2, gen_loss = 1.1058508176752861, disc_loss = 0.09903792448421107
Trained batch 94 in epoch 2, gen_loss = 1.1066509152713575, disc_loss = 0.09832489304244518
Trained batch 95 in epoch 2, gen_loss = 1.1077230752756198, disc_loss = 0.09803301385060574
Trained batch 96 in epoch 2, gen_loss = 1.1026074560647159, disc_loss = 0.09910365487880927
Trained batch 97 in epoch 2, gen_loss = 1.1022921307962767, disc_loss = 0.09875758974907958
Trained batch 98 in epoch 2, gen_loss = 1.1013410025172763, disc_loss = 0.09880319698666683
Trained batch 99 in epoch 2, gen_loss = 1.1020100551843643, disc_loss = 0.09802747195586563
Trained batch 100 in epoch 2, gen_loss = 1.1016770312101534, disc_loss = 0.09736843309411318
Trained batch 101 in epoch 2, gen_loss = 1.101184949571011, disc_loss = 0.09727243434491695
Trained batch 102 in epoch 2, gen_loss = 1.0998712928549756, disc_loss = 0.09678781168191757
Trained batch 103 in epoch 2, gen_loss = 1.100002916959616, disc_loss = 0.0963982728202469
Trained batch 104 in epoch 2, gen_loss = 1.1029599439530147, disc_loss = 0.09562908691309747
Trained batch 105 in epoch 2, gen_loss = 1.1052255945385627, disc_loss = 0.09480599939541996
Trained batch 106 in epoch 2, gen_loss = 1.1074709134681202, disc_loss = 0.09405026124424745
Trained batch 107 in epoch 2, gen_loss = 1.1054542130894132, disc_loss = 0.09358436903157444
Trained batch 108 in epoch 2, gen_loss = 1.1087632397992895, disc_loss = 0.09283189568668604
Trained batch 109 in epoch 2, gen_loss = 1.10852557962591, disc_loss = 0.09276895805008033
Trained batch 110 in epoch 2, gen_loss = 1.1049174456983, disc_loss = 0.09360880771366593
Trained batch 111 in epoch 2, gen_loss = 1.109747123505388, disc_loss = 0.09438232077185862
Trained batch 112 in epoch 2, gen_loss = 1.1094898892714915, disc_loss = 0.09391058952572336
Trained batch 113 in epoch 2, gen_loss = 1.1103892430924533, disc_loss = 0.09335729949535769
Trained batch 114 in epoch 2, gen_loss = 1.1096839645634526, disc_loss = 0.09284365529437429
Trained batch 115 in epoch 2, gen_loss = 1.109613956048571, disc_loss = 0.09236708786820286
Trained batch 116 in epoch 2, gen_loss = 1.1109986580335176, disc_loss = 0.0928975597390125
Trained batch 117 in epoch 2, gen_loss = 1.1065588654097864, disc_loss = 0.0945949343790821
Trained batch 118 in epoch 2, gen_loss = 1.1096995007090207, disc_loss = 0.0942431145089389
Trained batch 119 in epoch 2, gen_loss = 1.111704550186793, disc_loss = 0.09375468836321185
Trained batch 120 in epoch 2, gen_loss = 1.1125338057841152, disc_loss = 0.09333288881250403
Trained batch 121 in epoch 2, gen_loss = 1.111754970472367, disc_loss = 0.0928936207010487
Trained batch 122 in epoch 2, gen_loss = 1.110521577722658, disc_loss = 0.0928010817814043
Trained batch 123 in epoch 2, gen_loss = 1.1140713821495734, disc_loss = 0.09263052931806494
Trained batch 124 in epoch 2, gen_loss = 1.1158992457389831, disc_loss = 0.09376071425527334
Trained batch 125 in epoch 2, gen_loss = 1.110838619962571, disc_loss = 0.09535794855198926
Trained batch 126 in epoch 2, gen_loss = 1.109595345699881, disc_loss = 0.09614815964092185
Trained batch 127 in epoch 2, gen_loss = 1.1076883752830327, disc_loss = 0.09592972028622171
Trained batch 128 in epoch 2, gen_loss = 1.1092202039652093, disc_loss = 0.0957788150078913
Trained batch 129 in epoch 2, gen_loss = 1.1086110394734603, disc_loss = 0.09560797818434927
Trained batch 130 in epoch 2, gen_loss = 1.113363769673209, disc_loss = 0.09529740194868268
Trained batch 131 in epoch 2, gen_loss = 1.1118461259386756, disc_loss = 0.09505145677196031
Trained batch 132 in epoch 2, gen_loss = 1.1113729400742323, disc_loss = 0.09465951844349615
Trained batch 133 in epoch 2, gen_loss = 1.1148755883992607, disc_loss = 0.09431488819614943
Trained batch 134 in epoch 2, gen_loss = 1.1170782385049043, disc_loss = 0.09380933089802662
Trained batch 135 in epoch 2, gen_loss = 1.1180546007612173, disc_loss = 0.09353089668815408
Trained batch 136 in epoch 2, gen_loss = 1.1181810306806634, disc_loss = 0.09314385874292058
Trained batch 137 in epoch 2, gen_loss = 1.1207657573015795, disc_loss = 0.09257670982565352
Trained batch 138 in epoch 2, gen_loss = 1.1238035353825246, disc_loss = 0.09202225510325791
Trained batch 139 in epoch 2, gen_loss = 1.1256735175848007, disc_loss = 0.0914816612776901
Trained batch 140 in epoch 2, gen_loss = 1.127943386000099, disc_loss = 0.09096611614821228
Trained batch 141 in epoch 2, gen_loss = 1.1297915674431223, disc_loss = 0.09078319860018895
Trained batch 142 in epoch 2, gen_loss = 1.13040658769074, disc_loss = 0.09027733785341253
Trained batch 143 in epoch 2, gen_loss = 1.1325610540807247, disc_loss = 0.08977525643745644
Trained batch 144 in epoch 2, gen_loss = 1.1315022595997515, disc_loss = 0.08960148706261455
Trained batch 145 in epoch 2, gen_loss = 1.1358894252613798, disc_loss = 0.09000747532213796
Trained batch 146 in epoch 2, gen_loss = 1.1361899420517643, disc_loss = 0.09016297310337323
Trained batch 147 in epoch 2, gen_loss = 1.1313035629085593, disc_loss = 0.09174603172200355
Trained batch 148 in epoch 2, gen_loss = 1.1297615314490044, disc_loss = 0.09172817063361606
Trained batch 149 in epoch 2, gen_loss = 1.1364854721228281, disc_loss = 0.0924236079926292
Trained batch 150 in epoch 2, gen_loss = 1.1369634183826824, disc_loss = 0.0921807550757334
Trained batch 151 in epoch 2, gen_loss = 1.1360106307424997, disc_loss = 0.09195742647065536
Trained batch 152 in epoch 2, gen_loss = 1.1362066615640727, disc_loss = 0.09164927492003425
Trained batch 153 in epoch 2, gen_loss = 1.1380135103479607, disc_loss = 0.09121699985600525
Trained batch 154 in epoch 2, gen_loss = 1.14054784505598, disc_loss = 0.09075854325727109
Trained batch 155 in epoch 2, gen_loss = 1.1437309968930025, disc_loss = 0.09026406759109634
Trained batch 156 in epoch 2, gen_loss = 1.1425624056986183, disc_loss = 0.09027530050059412
Trained batch 157 in epoch 2, gen_loss = 1.1421806559532504, disc_loss = 0.090008837713188
Trained batch 158 in epoch 2, gen_loss = 1.1440179681628004, disc_loss = 0.08967524280759899
Trained batch 159 in epoch 2, gen_loss = 1.145840823277831, disc_loss = 0.08920573045616038
Trained batch 160 in epoch 2, gen_loss = 1.1466048159954711, disc_loss = 0.0887289651906731
Trained batch 161 in epoch 2, gen_loss = 1.1471521033916945, disc_loss = 0.08825829975812892
Trained batch 162 in epoch 2, gen_loss = 1.1476050553146315, disc_loss = 0.08793842012028387
Trained batch 163 in epoch 2, gen_loss = 1.1473330117580367, disc_loss = 0.0875775785094536
Trained batch 164 in epoch 2, gen_loss = 1.1508565241640265, disc_loss = 0.08736822741727034
Trained batch 165 in epoch 2, gen_loss = 1.152083184704723, disc_loss = 0.08690921937575541
Trained batch 166 in epoch 2, gen_loss = 1.149999895138655, disc_loss = 0.08676705257353669
Trained batch 167 in epoch 2, gen_loss = 1.1521745150287945, disc_loss = 0.08643127274921253
Trained batch 168 in epoch 2, gen_loss = 1.1512229643629852, disc_loss = 0.08637453736902694
Trained batch 169 in epoch 2, gen_loss = 1.15116226848434, disc_loss = 0.08605551016243065
Trained batch 170 in epoch 2, gen_loss = 1.150797897263577, disc_loss = 0.0857020642455907
Trained batch 171 in epoch 2, gen_loss = 1.153738415865011, disc_loss = 0.08530572016701796
Trained batch 172 in epoch 2, gen_loss = 1.1528023822459181, disc_loss = 0.08505115956283374
Trained batch 173 in epoch 2, gen_loss = 1.1530333034608555, disc_loss = 0.08474525628375938
Trained batch 174 in epoch 2, gen_loss = 1.1583403645242965, disc_loss = 0.08489189495997769
Trained batch 175 in epoch 2, gen_loss = 1.1561933992938562, disc_loss = 0.08494197411081669
Trained batch 176 in epoch 2, gen_loss = 1.1566236672428367, disc_loss = 0.08602235583051787
Trained batch 177 in epoch 2, gen_loss = 1.155722567204679, disc_loss = 0.08580936649500319
Trained batch 178 in epoch 2, gen_loss = 1.155431028184944, disc_loss = 0.08573174975063215
Trained batch 179 in epoch 2, gen_loss = 1.1540423654847676, disc_loss = 0.08557265329485138
Trained batch 180 in epoch 2, gen_loss = 1.1523308806656474, disc_loss = 0.08549234401743386
Trained batch 181 in epoch 2, gen_loss = 1.154156120268853, disc_loss = 0.08603254221584443
Trained batch 182 in epoch 2, gen_loss = 1.1509214411667787, disc_loss = 0.08654824818377613
Trained batch 183 in epoch 2, gen_loss = 1.148984452628571, disc_loss = 0.08653592981357613
Trained batch 184 in epoch 2, gen_loss = 1.1534927706460696, disc_loss = 0.08771622067166342
Trained batch 185 in epoch 2, gen_loss = 1.1508185844267569, disc_loss = 0.08797558764576592
Trained batch 186 in epoch 2, gen_loss = 1.1483122690476197, disc_loss = 0.08818724734539335
Trained batch 187 in epoch 2, gen_loss = 1.147493783780869, disc_loss = 0.08824213854770394
Trained batch 188 in epoch 2, gen_loss = 1.146642736656956, disc_loss = 0.08846020547761804
Trained batch 189 in epoch 2, gen_loss = 1.145759159640262, disc_loss = 0.08884891137284667
Trained batch 190 in epoch 2, gen_loss = 1.14400723841802, disc_loss = 0.08901181823881196
Trained batch 191 in epoch 2, gen_loss = 1.143392426893115, disc_loss = 0.08883216661827949
Trained batch 192 in epoch 2, gen_loss = 1.1444265718904802, disc_loss = 0.08847774481256082
Trained batch 193 in epoch 2, gen_loss = 1.1443690921842438, disc_loss = 0.08844541275355312
Trained batch 194 in epoch 2, gen_loss = 1.1410630791615217, disc_loss = 0.08961435557366945
Trained batch 195 in epoch 2, gen_loss = 1.1444437519019963, disc_loss = 0.08967976082990668
Trained batch 196 in epoch 2, gen_loss = 1.1437096287151278, disc_loss = 0.08973666969781297
Trained batch 197 in epoch 2, gen_loss = 1.142310535365885, disc_loss = 0.08965006046411064
Trained batch 198 in epoch 2, gen_loss = 1.1416849847414985, disc_loss = 0.08942358589838798
Trained batch 199 in epoch 2, gen_loss = 1.1415130051970481, disc_loss = 0.08907635123468935
Trained batch 200 in epoch 2, gen_loss = 1.1434948761664814, disc_loss = 0.0888004939891954
Trained batch 201 in epoch 2, gen_loss = 1.1421195472231005, disc_loss = 0.0886538047620123
Trained batch 202 in epoch 2, gen_loss = 1.1418595481388674, disc_loss = 0.08848611312216433
Trained batch 203 in epoch 2, gen_loss = 1.144259268454477, disc_loss = 0.08819834623193624
Trained batch 204 in epoch 2, gen_loss = 1.1434263115975916, disc_loss = 0.08796525501259943
Trained batch 205 in epoch 2, gen_loss = 1.143362698335092, disc_loss = 0.08780205182875823
Trained batch 206 in epoch 2, gen_loss = 1.141353918446435, disc_loss = 0.08791440557958423
Trained batch 207 in epoch 2, gen_loss = 1.1436972867410917, disc_loss = 0.08862959978600535
Trained batch 208 in epoch 2, gen_loss = 1.1430582917478096, disc_loss = 0.08837425715900495
Trained batch 209 in epoch 2, gen_loss = 1.1409533412683577, disc_loss = 0.08846156841942242
Trained batch 210 in epoch 2, gen_loss = 1.1413963408831735, disc_loss = 0.08826349137165534
Trained batch 211 in epoch 2, gen_loss = 1.139876421611264, disc_loss = 0.0884850590823675
Trained batch 212 in epoch 2, gen_loss = 1.1387746960904117, disc_loss = 0.08842216458329012
Trained batch 213 in epoch 2, gen_loss = 1.1375360241003125, disc_loss = 0.08863599965714405
Trained batch 214 in epoch 2, gen_loss = 1.1374900061030722, disc_loss = 0.08840068358668061
Trained batch 215 in epoch 2, gen_loss = 1.1399867002058912, disc_loss = 0.08817013003001059
Trained batch 216 in epoch 2, gen_loss = 1.138501526298611, disc_loss = 0.088311113228309
Trained batch 217 in epoch 2, gen_loss = 1.1360858561248954, disc_loss = 0.08875627096298092
Trained batch 218 in epoch 2, gen_loss = 1.1388214954502507, disc_loss = 0.08993400822151197
Trained batch 219 in epoch 2, gen_loss = 1.1372103693810376, disc_loss = 0.09008147968825969
Trained batch 220 in epoch 2, gen_loss = 1.1380851649051338, disc_loss = 0.0899631901732667
Trained batch 221 in epoch 2, gen_loss = 1.1375898920200966, disc_loss = 0.09000550574614657
Trained batch 222 in epoch 2, gen_loss = 1.1374182682400862, disc_loss = 0.09023460814303347
Trained batch 223 in epoch 2, gen_loss = 1.1364077593066864, disc_loss = 0.09022434696089476
Trained batch 224 in epoch 2, gen_loss = 1.133632809056176, disc_loss = 0.09087697342038155
Trained batch 225 in epoch 2, gen_loss = 1.1329549271448525, disc_loss = 0.09090821021360106
Trained batch 226 in epoch 2, gen_loss = 1.1374044444592513, disc_loss = 0.09152577986473029
Trained batch 227 in epoch 2, gen_loss = 1.136200489443645, disc_loss = 0.09153697693622426
Trained batch 228 in epoch 2, gen_loss = 1.1360207861167375, disc_loss = 0.09131059637821919
Trained batch 229 in epoch 2, gen_loss = 1.1351723372936249, disc_loss = 0.09142071891414083
Trained batch 230 in epoch 2, gen_loss = 1.1349731763719997, disc_loss = 0.09117370039160118
Trained batch 231 in epoch 2, gen_loss = 1.133605206064109, disc_loss = 0.09118547465587998
Trained batch 232 in epoch 2, gen_loss = 1.1345004065865611, disc_loss = 0.09106195230404707
Trained batch 233 in epoch 2, gen_loss = 1.1349252230591245, disc_loss = 0.09086588233645655
Trained batch 234 in epoch 2, gen_loss = 1.134389575745197, disc_loss = 0.09100391593702296
Trained batch 235 in epoch 2, gen_loss = 1.1326051457958706, disc_loss = 0.0913381444732264
Trained batch 236 in epoch 2, gen_loss = 1.134585447200743, disc_loss = 0.09133623909786784
Trained batch 237 in epoch 2, gen_loss = 1.13420769572258, disc_loss = 0.0911520355294983
Trained batch 238 in epoch 2, gen_loss = 1.1332498990840991, disc_loss = 0.09094808637222984
Trained batch 239 in epoch 2, gen_loss = 1.1326919632653396, disc_loss = 0.09094393206760287
Trained batch 240 in epoch 2, gen_loss = 1.133010690884966, disc_loss = 0.09070772900249949
Trained batch 241 in epoch 2, gen_loss = 1.1335817371025558, disc_loss = 0.09038906007204667
Trained batch 242 in epoch 2, gen_loss = 1.1350051368214957, disc_loss = 0.09025454030605991
Trained batch 243 in epoch 2, gen_loss = 1.1337611435866746, disc_loss = 0.09013582191994933
Trained batch 244 in epoch 2, gen_loss = 1.1332105191386477, disc_loss = 0.09018776815156547
Trained batch 245 in epoch 2, gen_loss = 1.1314308018219181, disc_loss = 0.09042081027859594
Trained batch 246 in epoch 2, gen_loss = 1.132266747806719, disc_loss = 0.09013898749100535
Trained batch 247 in epoch 2, gen_loss = 1.134014836242122, disc_loss = 0.09027559826931646
Trained batch 248 in epoch 2, gen_loss = 1.1339219889966359, disc_loss = 0.09021387835702743
Trained batch 249 in epoch 2, gen_loss = 1.1342466716766357, disc_loss = 0.09042120090126991
Trained batch 250 in epoch 2, gen_loss = 1.1331109606412302, disc_loss = 0.09051277203507632
Trained batch 251 in epoch 2, gen_loss = 1.1316812265486944, disc_loss = 0.09058904754264015
Trained batch 252 in epoch 2, gen_loss = 1.1329239682246575, disc_loss = 0.09095380717351031
Trained batch 253 in epoch 2, gen_loss = 1.1335829867152718, disc_loss = 0.09086433982872587
Trained batch 254 in epoch 2, gen_loss = 1.1340260042863735, disc_loss = 0.0907014955200401
Trained batch 255 in epoch 2, gen_loss = 1.133184200618416, disc_loss = 0.09063314824015833
Trained batch 256 in epoch 2, gen_loss = 1.1318503905826969, disc_loss = 0.09060391430029145
Trained batch 257 in epoch 2, gen_loss = 1.1303434441255968, disc_loss = 0.09080954456283141
Trained batch 258 in epoch 2, gen_loss = 1.1327390546504135, disc_loss = 0.09140907331553205
Trained batch 259 in epoch 2, gen_loss = 1.130947311107929, disc_loss = 0.09154726112118135
Trained batch 260 in epoch 2, gen_loss = 1.131167466613068, disc_loss = 0.09132403006841397
Trained batch 261 in epoch 2, gen_loss = 1.1322087413482083, disc_loss = 0.09120353514627191
Trained batch 262 in epoch 2, gen_loss = 1.1322812979665546, disc_loss = 0.09102327402100363
Trained batch 263 in epoch 2, gen_loss = 1.1302185460473553, disc_loss = 0.09122671903760145
Trained batch 264 in epoch 2, gen_loss = 1.130681361342376, disc_loss = 0.09094869922495114
Trained batch 265 in epoch 2, gen_loss = 1.13286391640068, disc_loss = 0.09089222080529408
Trained batch 266 in epoch 2, gen_loss = 1.131791068373548, disc_loss = 0.09083926078448358
Trained batch 267 in epoch 2, gen_loss = 1.1313518058897845, disc_loss = 0.09061189398947936
Trained batch 268 in epoch 2, gen_loss = 1.1317168549534113, disc_loss = 0.09056608165617769
Trained batch 269 in epoch 2, gen_loss = 1.131191990993641, disc_loss = 0.09040342968095232
Trained batch 270 in epoch 2, gen_loss = 1.1308286629919637, disc_loss = 0.09027448521988858
Trained batch 271 in epoch 2, gen_loss = 1.1296998082714922, disc_loss = 0.09027515006635119
Trained batch 272 in epoch 2, gen_loss = 1.1298414765696823, disc_loss = 0.0906586725087393
Trained batch 273 in epoch 2, gen_loss = 1.1304934059616423, disc_loss = 0.09054357542173706
Trained batch 274 in epoch 2, gen_loss = 1.129975664398887, disc_loss = 0.09043305831876668
Trained batch 275 in epoch 2, gen_loss = 1.1290989833465521, disc_loss = 0.09040024581000856
Trained batch 276 in epoch 2, gen_loss = 1.1286083842873142, disc_loss = 0.09023781272747457
Trained batch 277 in epoch 2, gen_loss = 1.1268610323933388, disc_loss = 0.0903397380046064
Trained batch 278 in epoch 2, gen_loss = 1.128527066613611, disc_loss = 0.09031447598637218
Trained batch 279 in epoch 2, gen_loss = 1.1306156520332609, disc_loss = 0.09015068689893399
Trained batch 280 in epoch 2, gen_loss = 1.1294630220776352, disc_loss = 0.0902730649290772
Trained batch 281 in epoch 2, gen_loss = 1.1293970534564755, disc_loss = 0.09004532525329091
Trained batch 282 in epoch 2, gen_loss = 1.1284339404780115, disc_loss = 0.08999853792465407
Trained batch 283 in epoch 2, gen_loss = 1.129531411008096, disc_loss = 0.08976001569240445
Trained batch 284 in epoch 2, gen_loss = 1.1315877226361057, disc_loss = 0.08973202677933793
Trained batch 285 in epoch 2, gen_loss = 1.1319336005440959, disc_loss = 0.0894717270495383
Trained batch 286 in epoch 2, gen_loss = 1.1306711113411374, disc_loss = 0.08953678009557807
Trained batch 287 in epoch 2, gen_loss = 1.1309127755877044, disc_loss = 0.08930645550652924
Trained batch 288 in epoch 2, gen_loss = 1.134016719862664, disc_loss = 0.08937901649044047
Trained batch 289 in epoch 2, gen_loss = 1.1348577361682366, disc_loss = 0.08912873553304837
Trained batch 290 in epoch 2, gen_loss = 1.1346694196212743, disc_loss = 0.08891078141034674
Trained batch 291 in epoch 2, gen_loss = 1.134514539413256, disc_loss = 0.08866483431743229
Trained batch 292 in epoch 2, gen_loss = 1.1339361142786697, disc_loss = 0.08860179654135028
Trained batch 293 in epoch 2, gen_loss = 1.1334490159741875, disc_loss = 0.08844604945684574
Trained batch 294 in epoch 2, gen_loss = 1.132972281262026, disc_loss = 0.08826552925599834
Trained batch 295 in epoch 2, gen_loss = 1.135552475984032, disc_loss = 0.08883833827929118
Trained batch 296 in epoch 2, gen_loss = 1.1351801546334417, disc_loss = 0.08878973586114769
Trained batch 297 in epoch 2, gen_loss = 1.134611392981254, disc_loss = 0.08870524951200558
Trained batch 298 in epoch 2, gen_loss = 1.1346327114264703, disc_loss = 0.08857351611913447
Trained batch 299 in epoch 2, gen_loss = 1.1332377982139588, disc_loss = 0.08857381053889792
Trained batch 300 in epoch 2, gen_loss = 1.1341573558376477, disc_loss = 0.08869147274110999
Trained batch 301 in epoch 2, gen_loss = 1.1337400489295555, disc_loss = 0.08863205549658726
Trained batch 302 in epoch 2, gen_loss = 1.1333107169311825, disc_loss = 0.08849965399223389
Trained batch 303 in epoch 2, gen_loss = 1.133224286923283, disc_loss = 0.08827557093708922
Trained batch 304 in epoch 2, gen_loss = 1.1334374056487786, disc_loss = 0.08816716336324566
Trained batch 305 in epoch 2, gen_loss = 1.134910290147744, disc_loss = 0.08793842707291927
Trained batch 306 in epoch 2, gen_loss = 1.1355283706894914, disc_loss = 0.08770747920225226
Trained batch 307 in epoch 2, gen_loss = 1.1351862437539286, disc_loss = 0.08771286286147577
Trained batch 308 in epoch 2, gen_loss = 1.1340450441953047, disc_loss = 0.08766706049755746
Trained batch 309 in epoch 2, gen_loss = 1.1356086857857244, disc_loss = 0.08745599456972653
Trained batch 310 in epoch 2, gen_loss = 1.136583545200311, disc_loss = 0.08729121175825212
Trained batch 311 in epoch 2, gen_loss = 1.137070248142267, disc_loss = 0.08734769341297066
Trained batch 312 in epoch 2, gen_loss = 1.135906893414811, disc_loss = 0.08741797293170382
Trained batch 313 in epoch 2, gen_loss = 1.135944471807237, disc_loss = 0.08726640625198366
Trained batch 314 in epoch 2, gen_loss = 1.1351125836372375, disc_loss = 0.08754797152701825
Trained batch 315 in epoch 2, gen_loss = 1.1366670039258426, disc_loss = 0.08735684575395117
Trained batch 316 in epoch 2, gen_loss = 1.1378397134952365, disc_loss = 0.0871380234154805
Trained batch 317 in epoch 2, gen_loss = 1.1381246963012144, disc_loss = 0.08708098864639705
Trained batch 318 in epoch 2, gen_loss = 1.136930678892285, disc_loss = 0.08715283558893727
Trained batch 319 in epoch 2, gen_loss = 1.1368550496175884, disc_loss = 0.08693938025971874
Trained batch 320 in epoch 2, gen_loss = 1.1370798897149035, disc_loss = 0.08676892176641854
Trained batch 321 in epoch 2, gen_loss = 1.1376744917831065, disc_loss = 0.08657797193443924
Trained batch 322 in epoch 2, gen_loss = 1.1380078849777717, disc_loss = 0.08650722321203619
Trained batch 323 in epoch 2, gen_loss = 1.1371160493588741, disc_loss = 0.08643023996257487
Trained batch 324 in epoch 2, gen_loss = 1.1372867472355181, disc_loss = 0.08620470688033563
Trained batch 325 in epoch 2, gen_loss = 1.1381856735132954, disc_loss = 0.08639429417364528
Trained batch 326 in epoch 2, gen_loss = 1.1376429085337787, disc_loss = 0.08626490160651984
Trained batch 327 in epoch 2, gen_loss = 1.1372859656083874, disc_loss = 0.08611930350534527
Trained batch 328 in epoch 2, gen_loss = 1.1383136452874876, disc_loss = 0.08595354617559167
Trained batch 329 in epoch 2, gen_loss = 1.1384445237390923, disc_loss = 0.08601714436134154
Trained batch 330 in epoch 2, gen_loss = 1.1376198699467133, disc_loss = 0.085983810088178
Trained batch 331 in epoch 2, gen_loss = 1.137229125183749, disc_loss = 0.08594099717517664
Trained batch 332 in epoch 2, gen_loss = 1.1369667894489415, disc_loss = 0.08608112148884628
Trained batch 333 in epoch 2, gen_loss = 1.1373190233807364, disc_loss = 0.08587361362757172
Trained batch 334 in epoch 2, gen_loss = 1.1375859449158854, disc_loss = 0.08572878431973617
Trained batch 335 in epoch 2, gen_loss = 1.1381118936198098, disc_loss = 0.08551468642794394
Trained batch 336 in epoch 2, gen_loss = 1.136868411249506, disc_loss = 0.085655020635564
Trained batch 337 in epoch 2, gen_loss = 1.1387599426261066, disc_loss = 0.08580179019010015
Trained batch 338 in epoch 2, gen_loss = 1.137893137326986, disc_loss = 0.08587365377980084
Trained batch 339 in epoch 2, gen_loss = 1.138622922406477, disc_loss = 0.0858163446872769
Trained batch 340 in epoch 2, gen_loss = 1.137686454131107, disc_loss = 0.08580647476967916
Trained batch 341 in epoch 2, gen_loss = 1.1383216605897535, disc_loss = 0.08559395004967936
Trained batch 342 in epoch 2, gen_loss = 1.1373711965174438, disc_loss = 0.0857423164042761
Trained batch 343 in epoch 2, gen_loss = 1.1382447347738023, disc_loss = 0.08587831261210403
Trained batch 344 in epoch 2, gen_loss = 1.1379523455232814, disc_loss = 0.08574233711899623
Trained batch 345 in epoch 2, gen_loss = 1.1381861865520477, disc_loss = 0.08554206930929957
Trained batch 346 in epoch 2, gen_loss = 1.1374447471126699, disc_loss = 0.08556456825500006
Trained batch 347 in epoch 2, gen_loss = 1.1372931183412158, disc_loss = 0.08537570304965236
Trained batch 348 in epoch 2, gen_loss = 1.1392775444383265, disc_loss = 0.085531894739365
Trained batch 349 in epoch 2, gen_loss = 1.1392531151430947, disc_loss = 0.08536587828238096
Trained batch 350 in epoch 2, gen_loss = 1.1386327938816148, disc_loss = 0.0852483286843383
Trained batch 351 in epoch 2, gen_loss = 1.1402190810238773, disc_loss = 0.08515307422864928
Trained batch 352 in epoch 2, gen_loss = 1.1422798696050562, disc_loss = 0.08502911353383541
Trained batch 353 in epoch 2, gen_loss = 1.1418987601827093, disc_loss = 0.08495062210013048
Trained batch 354 in epoch 2, gen_loss = 1.1428740335182406, disc_loss = 0.0848083609347822
Trained batch 355 in epoch 2, gen_loss = 1.142830700854237, disc_loss = 0.08466652304907277
Trained batch 356 in epoch 2, gen_loss = 1.143150106698525, disc_loss = 0.0844671830576675
Trained batch 357 in epoch 2, gen_loss = 1.1436957708617161, disc_loss = 0.08426361021913546
Trained batch 358 in epoch 2, gen_loss = 1.1458439516489884, disc_loss = 0.0841083170607437
Trained batch 359 in epoch 2, gen_loss = 1.145092554224862, disc_loss = 0.0840224104338429
Trained batch 360 in epoch 2, gen_loss = 1.146201220906012, disc_loss = 0.08382257392985999
Trained batch 361 in epoch 2, gen_loss = 1.1456145038262258, disc_loss = 0.083743196073405
Trained batch 362 in epoch 2, gen_loss = 1.1465795227318756, disc_loss = 0.08357968565189478
Trained batch 363 in epoch 2, gen_loss = 1.1474443952460864, disc_loss = 0.08340666492745935
Trained batch 364 in epoch 2, gen_loss = 1.147687778734181, disc_loss = 0.08327431085277094
Trained batch 365 in epoch 2, gen_loss = 1.147039035304648, disc_loss = 0.08321132613193305
Trained batch 366 in epoch 2, gen_loss = 1.1472538612194216, disc_loss = 0.08303272274985138
Trained batch 367 in epoch 2, gen_loss = 1.1487920967781025, disc_loss = 0.0830168727653749
Trained batch 368 in epoch 2, gen_loss = 1.148564567410849, disc_loss = 0.08285853926970707
Trained batch 369 in epoch 2, gen_loss = 1.1477782030363342, disc_loss = 0.0828023675627805
Trained batch 370 in epoch 2, gen_loss = 1.1491926359037825, disc_loss = 0.08276632065681434
Trained batch 371 in epoch 2, gen_loss = 1.1512324630573232, disc_loss = 0.08274326496507212
Trained batch 372 in epoch 2, gen_loss = 1.1500180096792472, disc_loss = 0.08277572129151457
Trained batch 373 in epoch 2, gen_loss = 1.1487203504949968, disc_loss = 0.08292472578664833
Trained batch 374 in epoch 2, gen_loss = 1.1505605058670043, disc_loss = 0.0828183761537075
Trained batch 375 in epoch 2, gen_loss = 1.1506750783387651, disc_loss = 0.08269488022841037
Trained batch 376 in epoch 2, gen_loss = 1.1508454191906066, disc_loss = 0.08255559435751615
Trained batch 377 in epoch 2, gen_loss = 1.150555136973265, disc_loss = 0.0824166442558327
Trained batch 378 in epoch 2, gen_loss = 1.1492502428296374, disc_loss = 0.08251570366165727
Trained batch 379 in epoch 2, gen_loss = 1.1507947604907187, disc_loss = 0.08247613813237924
Trained batch 380 in epoch 2, gen_loss = 1.151343741441962, disc_loss = 0.0823141975655878
Trained batch 381 in epoch 2, gen_loss = 1.1515502826705653, disc_loss = 0.08215335956945313
Trained batch 382 in epoch 2, gen_loss = 1.1517176705925645, disc_loss = 0.08198915162262344
Trained batch 383 in epoch 2, gen_loss = 1.1520498460158706, disc_loss = 0.08201796572150973
Trained batch 384 in epoch 2, gen_loss = 1.151062256639654, disc_loss = 0.08202115518899707
Trained batch 385 in epoch 2, gen_loss = 1.1513877643822388, disc_loss = 0.0818322594567091
Trained batch 386 in epoch 2, gen_loss = 1.1509501373429014, disc_loss = 0.0817209700295745
Trained batch 387 in epoch 2, gen_loss = 1.1526609696063799, disc_loss = 0.08177834149862918
Trained batch 388 in epoch 2, gen_loss = 1.1531611745339125, disc_loss = 0.08159785633451834
Trained batch 389 in epoch 2, gen_loss = 1.1530776653534327, disc_loss = 0.08148825745552014
Trained batch 390 in epoch 2, gen_loss = 1.1532677988262128, disc_loss = 0.08132202221590387
Trained batch 391 in epoch 2, gen_loss = 1.1539299561052907, disc_loss = 0.08134793354749527
Trained batch 392 in epoch 2, gen_loss = 1.1540305065441374, disc_loss = 0.08116660928282574
Trained batch 393 in epoch 2, gen_loss = 1.154779829047053, disc_loss = 0.08118427306092178
Trained batch 394 in epoch 2, gen_loss = 1.1533222126055367, disc_loss = 0.081531933662069
Trained batch 395 in epoch 2, gen_loss = 1.152730774397802, disc_loss = 0.08146449050047633
Trained batch 396 in epoch 2, gen_loss = 1.1539100018196202, disc_loss = 0.08135762411434795
Trained batch 397 in epoch 2, gen_loss = 1.1547230056781865, disc_loss = 0.08135457638763453
Trained batch 398 in epoch 2, gen_loss = 1.1547301562507648, disc_loss = 0.08119517024653149
Trained batch 399 in epoch 2, gen_loss = 1.1547227531671524, disc_loss = 0.08106962805148214
Trained batch 400 in epoch 2, gen_loss = 1.155483791655733, disc_loss = 0.08094976488918884
Trained batch 401 in epoch 2, gen_loss = 1.1555314016579397, disc_loss = 0.08079060384846148
Trained batch 402 in epoch 2, gen_loss = 1.1554805883402859, disc_loss = 0.0806741108355244
Trained batch 403 in epoch 2, gen_loss = 1.1559535961339968, disc_loss = 0.0805118653812621
Trained batch 404 in epoch 2, gen_loss = 1.1570529010560777, disc_loss = 0.08036339686792573
Trained batch 405 in epoch 2, gen_loss = 1.1578011592033461, disc_loss = 0.0801920080098686
Trained batch 406 in epoch 2, gen_loss = 1.1582338470205922, disc_loss = 0.08002117417606294
Trained batch 407 in epoch 2, gen_loss = 1.158634186959734, disc_loss = 0.07986046455563138
Trained batch 408 in epoch 2, gen_loss = 1.1589052735447591, disc_loss = 0.07975450155842129
Trained batch 409 in epoch 2, gen_loss = 1.1590649430344744, disc_loss = 0.07959536388062122
Trained batch 410 in epoch 2, gen_loss = 1.1595968121159685, disc_loss = 0.07942641197891856
Trained batch 411 in epoch 2, gen_loss = 1.1607016929723684, disc_loss = 0.07927540376402654
Trained batch 412 in epoch 2, gen_loss = 1.1616504530063843, disc_loss = 0.07911404206013853
Trained batch 413 in epoch 2, gen_loss = 1.1620415958805361, disc_loss = 0.07894317150691857
Trained batch 414 in epoch 2, gen_loss = 1.162380095562303, disc_loss = 0.07881694329700556
Trained batch 415 in epoch 2, gen_loss = 1.162251784824408, disc_loss = 0.0787034701117171
Trained batch 416 in epoch 2, gen_loss = 1.1626810375735057, disc_loss = 0.07858095080893246
Trained batch 417 in epoch 2, gen_loss = 1.1636466957165295, disc_loss = 0.07843181955668202
Trained batch 418 in epoch 2, gen_loss = 1.1650616018755056, disc_loss = 0.07829537903689968
Trained batch 419 in epoch 2, gen_loss = 1.165257504724321, disc_loss = 0.07816557418111535
Trained batch 420 in epoch 2, gen_loss = 1.1652416811986095, disc_loss = 0.07802889399637519
Trained batch 421 in epoch 2, gen_loss = 1.1665042404314918, disc_loss = 0.07800928327603646
Trained batch 422 in epoch 2, gen_loss = 1.1669229846755946, disc_loss = 0.07786514705606246
Trained batch 423 in epoch 2, gen_loss = 1.1668497700736207, disc_loss = 0.07775948086384472
Trained batch 424 in epoch 2, gen_loss = 1.1678855910020716, disc_loss = 0.07769971093272461
Trained batch 425 in epoch 2, gen_loss = 1.166922132174174, disc_loss = 0.07784375149162023
Trained batch 426 in epoch 2, gen_loss = 1.1677015603844958, disc_loss = 0.07792051078476867
Trained batch 427 in epoch 2, gen_loss = 1.1687319922112973, disc_loss = 0.07782873474322607
Trained batch 428 in epoch 2, gen_loss = 1.168150780362127, disc_loss = 0.07773820006468773
Trained batch 429 in epoch 2, gen_loss = 1.1690876217775568, disc_loss = 0.07760118812235982
Trained batch 430 in epoch 2, gen_loss = 1.1699203294280511, disc_loss = 0.07746597245473873
Trained batch 431 in epoch 2, gen_loss = 1.170628997462767, disc_loss = 0.07730936620134378
Trained batch 432 in epoch 2, gen_loss = 1.1703700738470768, disc_loss = 0.07718757689902538
Trained batch 433 in epoch 2, gen_loss = 1.1706836781194132, disc_loss = 0.07705088287446013
Trained batch 434 in epoch 2, gen_loss = 1.1711543113335796, disc_loss = 0.07690796150943671
Trained batch 435 in epoch 2, gen_loss = 1.1714684101966544, disc_loss = 0.07676964814757603
Trained batch 436 in epoch 2, gen_loss = 1.1722682381658314, disc_loss = 0.07662725456067504
Trained batch 437 in epoch 2, gen_loss = 1.172191682199365, disc_loss = 0.07649119636979482
Trained batch 438 in epoch 2, gen_loss = 1.1723613567938838, disc_loss = 0.07634627026906725
Trained batch 439 in epoch 2, gen_loss = 1.172501542893323, disc_loss = 0.07636513661339202
Trained batch 440 in epoch 2, gen_loss = 1.1723594303304106, disc_loss = 0.07624692670460326
Trained batch 441 in epoch 2, gen_loss = 1.1729112653171314, disc_loss = 0.07610448923096802
Trained batch 442 in epoch 2, gen_loss = 1.1735947121346777, disc_loss = 0.07598181628111254
Trained batch 443 in epoch 2, gen_loss = 1.173770876618119, disc_loss = 0.07585651083505368
Trained batch 444 in epoch 2, gen_loss = 1.1737406711899832, disc_loss = 0.07571179947993728
Trained batch 445 in epoch 2, gen_loss = 1.1749062730592463, disc_loss = 0.07561366145620164
Trained batch 446 in epoch 2, gen_loss = 1.1756325800146832, disc_loss = 0.07546728625851923
Trained batch 447 in epoch 2, gen_loss = 1.1758808006665535, disc_loss = 0.07531959964918704
Trained batch 448 in epoch 2, gen_loss = 1.1761777100955988, disc_loss = 0.07517442931493698
Trained batch 449 in epoch 2, gen_loss = 1.1760398777325949, disc_loss = 0.07507222237272396
Trained batch 450 in epoch 2, gen_loss = 1.1771850382409446, disc_loss = 0.07494190607029953
Trained batch 451 in epoch 2, gen_loss = 1.1777882673571596, disc_loss = 0.07512219191685451
Trained batch 452 in epoch 2, gen_loss = 1.1769736613132569, disc_loss = 0.07514364945868783
Trained batch 453 in epoch 2, gen_loss = 1.1762589443360132, disc_loss = 0.07513466914746467
Trained batch 454 in epoch 2, gen_loss = 1.1766245911409567, disc_loss = 0.07554593954931249
Trained batch 455 in epoch 2, gen_loss = 1.176031321548579, disc_loss = 0.07551627550600913
Trained batch 456 in epoch 2, gen_loss = 1.1755778481715096, disc_loss = 0.07543920171273877
Trained batch 457 in epoch 2, gen_loss = 1.1762556204629258, disc_loss = 0.07538706604309998
Trained batch 458 in epoch 2, gen_loss = 1.175498782679406, disc_loss = 0.0754321009927066
Trained batch 459 in epoch 2, gen_loss = 1.175977593401204, disc_loss = 0.07529742008925457
Trained batch 460 in epoch 2, gen_loss = 1.1761614257498056, disc_loss = 0.07517741911250637
Trained batch 461 in epoch 2, gen_loss = 1.1757675551232838, disc_loss = 0.07515028255963416
Trained batch 462 in epoch 2, gen_loss = 1.1766754563889803, disc_loss = 0.07505215783895157
Trained batch 463 in epoch 2, gen_loss = 1.1762020925766434, disc_loss = 0.07499959977977941
Trained batch 464 in epoch 2, gen_loss = 1.1768296858315828, disc_loss = 0.07487855127622042
Trained batch 465 in epoch 2, gen_loss = 1.1777445401500735, disc_loss = 0.07475713916850384
Trained batch 466 in epoch 2, gen_loss = 1.1786568745555919, disc_loss = 0.07462848247501529
Trained batch 467 in epoch 2, gen_loss = 1.179115900499189, disc_loss = 0.07466643957946545
Trained batch 468 in epoch 2, gen_loss = 1.1780324766376633, disc_loss = 0.0749409403215085
Trained batch 469 in epoch 2, gen_loss = 1.1786009044089216, disc_loss = 0.07482362304754714
Trained batch 470 in epoch 2, gen_loss = 1.1791891959315906, disc_loss = 0.07476830306105046
Trained batch 471 in epoch 2, gen_loss = 1.1784444789765245, disc_loss = 0.0747949405636449
Trained batch 472 in epoch 2, gen_loss = 1.1795194970628928, disc_loss = 0.07469162060219565
Trained batch 473 in epoch 2, gen_loss = 1.1798040590205776, disc_loss = 0.07456413298090801
Trained batch 474 in epoch 2, gen_loss = 1.1799331552103947, disc_loss = 0.07446776291649593
Trained batch 475 in epoch 2, gen_loss = 1.1809168305216717, disc_loss = 0.07434229202130262
Trained batch 476 in epoch 2, gen_loss = 1.1818475805738438, disc_loss = 0.07421917846305315
Trained batch 477 in epoch 2, gen_loss = 1.1813148453395237, disc_loss = 0.07417306121610198
Trained batch 478 in epoch 2, gen_loss = 1.1805936109297956, disc_loss = 0.07416382253107795
Trained batch 479 in epoch 2, gen_loss = 1.1815724013994138, disc_loss = 0.07406956698590268
Trained batch 480 in epoch 2, gen_loss = 1.1822429026734556, disc_loss = 0.07415108450082385
Trained batch 481 in epoch 2, gen_loss = 1.1812976645730837, disc_loss = 0.07424906591007571
Trained batch 482 in epoch 2, gen_loss = 1.181602876625693, disc_loss = 0.07413828215613869
Trained batch 483 in epoch 2, gen_loss = 1.1826760372347083, disc_loss = 0.07403813034665487
Trained batch 484 in epoch 2, gen_loss = 1.183106815200491, disc_loss = 0.07394413416917177
Trained batch 485 in epoch 2, gen_loss = 1.1833343807561898, disc_loss = 0.07384853293437035
Trained batch 486 in epoch 2, gen_loss = 1.1834076824129485, disc_loss = 0.07372325793811306
Trained batch 487 in epoch 2, gen_loss = 1.1831184752651902, disc_loss = 0.07363324226109219
Trained batch 488 in epoch 2, gen_loss = 1.1830725772249187, disc_loss = 0.07351879439943285
Trained batch 489 in epoch 2, gen_loss = 1.1847402421795592, disc_loss = 0.07345268300221283
Trained batch 490 in epoch 2, gen_loss = 1.1846638619292778, disc_loss = 0.0733444777425462
Trained batch 491 in epoch 2, gen_loss = 1.1850322375937206, disc_loss = 0.07321338845999927
Trained batch 492 in epoch 2, gen_loss = 1.1864047096418802, disc_loss = 0.07391216087345842
Trained batch 493 in epoch 2, gen_loss = 1.1858384201401158, disc_loss = 0.07392059954124605
Trained batch 494 in epoch 2, gen_loss = 1.1852216019774928, disc_loss = 0.07387542034301794
Trained batch 495 in epoch 2, gen_loss = 1.1840953077039411, disc_loss = 0.073962485303186
Trained batch 496 in epoch 2, gen_loss = 1.1838668340168728, disc_loss = 0.07417751846261607
Trained batch 497 in epoch 2, gen_loss = 1.1832811681621045, disc_loss = 0.07417947223529699
Trained batch 498 in epoch 2, gen_loss = 1.1835693983372324, disc_loss = 0.07416445410106787
Trained batch 499 in epoch 2, gen_loss = 1.1834410438537597, disc_loss = 0.0742397610154003
Trained batch 500 in epoch 2, gen_loss = 1.1833191750768177, disc_loss = 0.0741470423015857
Trained batch 501 in epoch 2, gen_loss = 1.1825589722846135, disc_loss = 0.07424239719850549
Trained batch 502 in epoch 2, gen_loss = 1.181566421364695, disc_loss = 0.07430931673038965
Trained batch 503 in epoch 2, gen_loss = 1.1821185232154907, disc_loss = 0.07437576497498427
Trained batch 504 in epoch 2, gen_loss = 1.184051521225731, disc_loss = 0.07441247595972059
Trained batch 505 in epoch 2, gen_loss = 1.18452152032626, disc_loss = 0.07428795609461225
Trained batch 506 in epoch 2, gen_loss = 1.1844051006512764, disc_loss = 0.07420762254318307
Trained batch 507 in epoch 2, gen_loss = 1.1843776360271483, disc_loss = 0.07411533505765824
Trained batch 508 in epoch 2, gen_loss = 1.184535882796192, disc_loss = 0.07399431785499067
Trained batch 509 in epoch 2, gen_loss = 1.1853400466488857, disc_loss = 0.0739191440427128
Trained batch 510 in epoch 2, gen_loss = 1.1857089499438112, disc_loss = 0.0737938937146049
Trained batch 511 in epoch 2, gen_loss = 1.185814181342721, disc_loss = 0.07386722288538294
Trained batch 512 in epoch 2, gen_loss = 1.185492068238658, disc_loss = 0.07379743659625566
Trained batch 513 in epoch 2, gen_loss = 1.1851634638318755, disc_loss = 0.07373250557964936
Trained batch 514 in epoch 2, gen_loss = 1.185858996169081, disc_loss = 0.07362234845070295
Trained batch 515 in epoch 2, gen_loss = 1.1868136231751405, disc_loss = 0.07351475603726887
Trained batch 516 in epoch 2, gen_loss = 1.186614220792597, disc_loss = 0.0734299842170953
Trained batch 517 in epoch 2, gen_loss = 1.1867562369029954, disc_loss = 0.0733083580821954
Trained batch 518 in epoch 2, gen_loss = 1.1863713068080086, disc_loss = 0.073256378607584
Trained batch 519 in epoch 2, gen_loss = 1.1867512823297428, disc_loss = 0.07313804673210073
Trained batch 520 in epoch 2, gen_loss = 1.1867367764809769, disc_loss = 0.07304304688203643
Trained batch 521 in epoch 2, gen_loss = 1.186970972580928, disc_loss = 0.07294514680538199
Trained batch 522 in epoch 2, gen_loss = 1.1869844440976247, disc_loss = 0.07288281265717449
Trained batch 523 in epoch 2, gen_loss = 1.1872964272744784, disc_loss = 0.0727582038317999
Trained batch 524 in epoch 2, gen_loss = 1.1877275842712038, disc_loss = 0.07263123456300015
Trained batch 525 in epoch 2, gen_loss = 1.1880935048649066, disc_loss = 0.07251898945882888
Trained batch 526 in epoch 2, gen_loss = 1.1883851774955836, disc_loss = 0.0723971877877991
Trained batch 527 in epoch 2, gen_loss = 1.1897008327597922, disc_loss = 0.0724160039037198
Trained batch 528 in epoch 2, gen_loss = 1.1894841033028745, disc_loss = 0.07234210723532199
Trained batch 529 in epoch 2, gen_loss = 1.1891288511033329, disc_loss = 0.07230800086333646
Trained batch 530 in epoch 2, gen_loss = 1.1904945576707298, disc_loss = 0.07224474235292236
Trained batch 531 in epoch 2, gen_loss = 1.1900627236617238, disc_loss = 0.07224948709582056
Trained batch 532 in epoch 2, gen_loss = 1.1907075958896085, disc_loss = 0.0721734507475922
Trained batch 533 in epoch 2, gen_loss = 1.1913217663318476, disc_loss = 0.07206085432156893
Trained batch 534 in epoch 2, gen_loss = 1.1920434635376262, disc_loss = 0.0721655206885363
Trained batch 535 in epoch 2, gen_loss = 1.1915200758558602, disc_loss = 0.07221441167326811
Trained batch 536 in epoch 2, gen_loss = 1.1904204405663843, disc_loss = 0.0725795792760865
Trained batch 537 in epoch 2, gen_loss = 1.1909455988265325, disc_loss = 0.07274274989619824
Trained batch 538 in epoch 2, gen_loss = 1.1907374393298586, disc_loss = 0.07276620273953494
Trained batch 539 in epoch 2, gen_loss = 1.1910636534293493, disc_loss = 0.07265303762439915
Trained batch 540 in epoch 2, gen_loss = 1.1908128985415545, disc_loss = 0.07257100381043201
Trained batch 541 in epoch 2, gen_loss = 1.190415479490238, disc_loss = 0.07250495032043063
Trained batch 542 in epoch 2, gen_loss = 1.1903568685164547, disc_loss = 0.07258916378422584
Trained batch 543 in epoch 2, gen_loss = 1.1904230445404262, disc_loss = 0.0724892335034811
Trained batch 544 in epoch 2, gen_loss = 1.1899671371923675, disc_loss = 0.07245460016687119
Trained batch 545 in epoch 2, gen_loss = 1.190460320466604, disc_loss = 0.07239628571679223
Trained batch 546 in epoch 2, gen_loss = 1.1912107067744517, disc_loss = 0.07228931629097249
Trained batch 547 in epoch 2, gen_loss = 1.1917739916239343, disc_loss = 0.07217668544545253
Trained batch 548 in epoch 2, gen_loss = 1.1914786867973801, disc_loss = 0.07208760143876863
Trained batch 549 in epoch 2, gen_loss = 1.1915975476395, disc_loss = 0.07199760854328897
Trained batch 550 in epoch 2, gen_loss = 1.1925754933305315, disc_loss = 0.07192208119727225
Trained batch 551 in epoch 2, gen_loss = 1.1928351870265559, disc_loss = 0.07180671480845363
Trained batch 552 in epoch 2, gen_loss = 1.1926139038035926, disc_loss = 0.07173070982418564
Trained batch 553 in epoch 2, gen_loss = 1.192675672175652, disc_loss = 0.0716208453224602
Trained batch 554 in epoch 2, gen_loss = 1.1925074612772142, disc_loss = 0.0715585805769372
Trained batch 555 in epoch 2, gen_loss = 1.1925275305406653, disc_loss = 0.07147483374477907
Trained batch 556 in epoch 2, gen_loss = 1.1938473973924852, disc_loss = 0.07142233845478516
Trained batch 557 in epoch 2, gen_loss = 1.1928018167027437, disc_loss = 0.0717590453068135
Trained batch 558 in epoch 2, gen_loss = 1.1938929101435571, disc_loss = 0.07196299600696494
Trained batch 559 in epoch 2, gen_loss = 1.1938486993312836, disc_loss = 0.07204230274323241
Trained batch 560 in epoch 2, gen_loss = 1.1931800715851062, disc_loss = 0.07203530216981356
Trained batch 561 in epoch 2, gen_loss = 1.1932595676586721, disc_loss = 0.07195936352117285
Trained batch 562 in epoch 2, gen_loss = 1.1925714193821801, disc_loss = 0.07199108904247464
Trained batch 563 in epoch 2, gen_loss = 1.1925204753453005, disc_loss = 0.07194977443159974
Trained batch 564 in epoch 2, gen_loss = 1.1929114132855845, disc_loss = 0.0719536240179652
Trained batch 565 in epoch 2, gen_loss = 1.1927187348001838, disc_loss = 0.07186440895344444
Trained batch 566 in epoch 2, gen_loss = 1.1924880276281367, disc_loss = 0.07182572424868401
Trained batch 567 in epoch 2, gen_loss = 1.1915858190664104, disc_loss = 0.07191859894271442
Trained batch 568 in epoch 2, gen_loss = 1.191807984048746, disc_loss = 0.07189569825483307
Trained batch 569 in epoch 2, gen_loss = 1.1934838859658492, disc_loss = 0.0722915441345162
Trained batch 570 in epoch 2, gen_loss = 1.1927252519360356, disc_loss = 0.07237545599436776
Trained batch 571 in epoch 2, gen_loss = 1.19211984368471, disc_loss = 0.07238717882819083
Trained batch 572 in epoch 2, gen_loss = 1.1917355003365255, disc_loss = 0.07235170306839427
Trained batch 573 in epoch 2, gen_loss = 1.192494854382937, disc_loss = 0.0723322529681611
Trained batch 574 in epoch 2, gen_loss = 1.1922498339155445, disc_loss = 0.07225547618435128
Trained batch 575 in epoch 2, gen_loss = 1.1921742669203215, disc_loss = 0.0722231047976594
Trained batch 576 in epoch 2, gen_loss = 1.1921886805851702, disc_loss = 0.07213749305185324
Trained batch 577 in epoch 2, gen_loss = 1.1914177741146417, disc_loss = 0.0721846884011797
Trained batch 578 in epoch 2, gen_loss = 1.19173366603456, disc_loss = 0.07240747511049087
Trained batch 579 in epoch 2, gen_loss = 1.1920211333653024, disc_loss = 0.07232250670083509
Trained batch 580 in epoch 2, gen_loss = 1.1913694779351738, disc_loss = 0.07233664870387177
Trained batch 581 in epoch 2, gen_loss = 1.1917442396744011, disc_loss = 0.07232644553520297
Trained batch 582 in epoch 2, gen_loss = 1.1918030026437487, disc_loss = 0.07226047062875757
Trained batch 583 in epoch 2, gen_loss = 1.1925675493397125, disc_loss = 0.07218136078572819
Trained batch 584 in epoch 2, gen_loss = 1.1921982037715422, disc_loss = 0.07215952157703602
Trained batch 585 in epoch 2, gen_loss = 1.1926398415614314, disc_loss = 0.07213673055562932
Trained batch 586 in epoch 2, gen_loss = 1.1921604694052896, disc_loss = 0.0720769505102181
Trained batch 587 in epoch 2, gen_loss = 1.1920825233873056, disc_loss = 0.07203475108645781
Trained batch 588 in epoch 2, gen_loss = 1.1926699978993582, disc_loss = 0.07192916676468503
Trained batch 589 in epoch 2, gen_loss = 1.192843450429076, disc_loss = 0.07182829344755638
Trained batch 590 in epoch 2, gen_loss = 1.1931144847280886, disc_loss = 0.07173108541234924
Trained batch 591 in epoch 2, gen_loss = 1.1932348505266615, disc_loss = 0.07164660954259562
Trained batch 592 in epoch 2, gen_loss = 1.193210578185913, disc_loss = 0.07159197732922425
Trained batch 593 in epoch 2, gen_loss = 1.1929337048169337, disc_loss = 0.07151335765143561
Trained batch 594 in epoch 2, gen_loss = 1.1921577783191906, disc_loss = 0.07160874283442102
Trained batch 595 in epoch 2, gen_loss = 1.1937318017218737, disc_loss = 0.07162079755169959
Trained batch 596 in epoch 2, gen_loss = 1.1946186808685162, disc_loss = 0.0715296120956927
Trained batch 597 in epoch 2, gen_loss = 1.1952195868244937, disc_loss = 0.07178109141773728
Trained batch 598 in epoch 2, gen_loss = 1.1944575043074874, disc_loss = 0.07183860883020325
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 1.286210298538208, disc_loss = 0.02753434143960476
Trained batch 1 in epoch 3, gen_loss = 1.3455954194068909, disc_loss = 0.026612491346895695
Trained batch 2 in epoch 3, gen_loss = 1.240459640820821, disc_loss = 0.036649554346998535
Trained batch 3 in epoch 3, gen_loss = 1.1983782947063446, disc_loss = 0.03367987088859081
Trained batch 4 in epoch 3, gen_loss = 1.155425477027893, disc_loss = 0.0337409533560276
Trained batch 5 in epoch 3, gen_loss = 1.2414351105690002, disc_loss = 0.0354731734842062
Trained batch 6 in epoch 3, gen_loss = 1.2045431392533439, disc_loss = 0.036369042204959054
Trained batch 7 in epoch 3, gen_loss = 1.1915588900446892, disc_loss = 0.041101792361587286
Trained batch 8 in epoch 3, gen_loss = 1.1465166608492534, disc_loss = 0.04703657370474604
Trained batch 9 in epoch 3, gen_loss = 1.1338443219661714, disc_loss = 0.04670243076980114
Trained batch 10 in epoch 3, gen_loss = 1.1549022143537349, disc_loss = 0.043533029881390656
Trained batch 11 in epoch 3, gen_loss = 1.1663758506377537, disc_loss = 0.04064280710493525
Trained batch 12 in epoch 3, gen_loss = 1.1322576311918406, disc_loss = 0.0459632992457885
Trained batch 13 in epoch 3, gen_loss = 1.1727205046585627, disc_loss = 0.05017899548900979
Trained batch 14 in epoch 3, gen_loss = 1.2087080677350361, disc_loss = 0.048110513885815935
Trained batch 15 in epoch 3, gen_loss = 1.2030633874237537, disc_loss = 0.04669341736007482
Trained batch 16 in epoch 3, gen_loss = 1.2099558079943937, disc_loss = 0.04432780194260618
Trained batch 17 in epoch 3, gen_loss = 1.2145481937461429, disc_loss = 0.042422986666982375
Trained batch 18 in epoch 3, gen_loss = 1.2175131942096509, disc_loss = 0.04309088106904375
Trained batch 19 in epoch 3, gen_loss = 1.2032229274511337, disc_loss = 0.04333186594303697
Trained batch 20 in epoch 3, gen_loss = 1.2028966602824984, disc_loss = 0.043106503052903075
Trained batch 21 in epoch 3, gen_loss = 1.1929762959480286, disc_loss = 0.04333418080667881
Trained batch 22 in epoch 3, gen_loss = 1.196157921915469, disc_loss = 0.04441533025111193
Trained batch 23 in epoch 3, gen_loss = 1.176745389898618, disc_loss = 0.0472789675113745
Trained batch 24 in epoch 3, gen_loss = 1.1628997945785522, disc_loss = 0.05069444609805942
Trained batch 25 in epoch 3, gen_loss = 1.1704341585819538, disc_loss = 0.04945513940989398
Trained batch 26 in epoch 3, gen_loss = 1.172318524784512, disc_loss = 0.0540610142569575
Trained batch 27 in epoch 3, gen_loss = 1.1663507265704018, disc_loss = 0.05451466454126473
Trained batch 28 in epoch 3, gen_loss = 1.1649661393001163, disc_loss = 0.055660871002052366
Trained batch 29 in epoch 3, gen_loss = 1.1510013043880463, disc_loss = 0.05718275052495301
Trained batch 30 in epoch 3, gen_loss = 1.1560211739232462, disc_loss = 0.05780569841003706
Trained batch 31 in epoch 3, gen_loss = 1.1610422264784575, disc_loss = 0.05789170500065666
Trained batch 32 in epoch 3, gen_loss = 1.148839336453062, disc_loss = 0.05831821820218906
Trained batch 33 in epoch 3, gen_loss = 1.1469386184916777, disc_loss = 0.05852345216964536
Trained batch 34 in epoch 3, gen_loss = 1.1302804044314794, disc_loss = 0.06187232747407896
Trained batch 35 in epoch 3, gen_loss = 1.142921903067165, disc_loss = 0.06593728907561551
Trained batch 36 in epoch 3, gen_loss = 1.1425397122228467, disc_loss = 0.06492425258447593
Trained batch 37 in epoch 3, gen_loss = 1.152605199500134, disc_loss = 0.06359720106334671
Trained batch 38 in epoch 3, gen_loss = 1.1407815768168523, disc_loss = 0.06494917752794348
Trained batch 39 in epoch 3, gen_loss = 1.1410809189081192, disc_loss = 0.06577519526472315
Trained batch 40 in epoch 3, gen_loss = 1.1425360528434194, disc_loss = 0.06504252438274462
Trained batch 41 in epoch 3, gen_loss = 1.1411005570774986, disc_loss = 0.06515057858390112
Trained batch 42 in epoch 3, gen_loss = 1.141412344089774, disc_loss = 0.06422507077412204
Trained batch 43 in epoch 3, gen_loss = 1.1419390412894161, disc_loss = 0.06315358553547412
Trained batch 44 in epoch 3, gen_loss = 1.139503100183275, disc_loss = 0.06262059661870202
Trained batch 45 in epoch 3, gen_loss = 1.1515849336333897, disc_loss = 0.06227121197456575
Trained batch 46 in epoch 3, gen_loss = 1.1540230360436947, disc_loss = 0.061492068247195886
Trained batch 47 in epoch 3, gen_loss = 1.1593720788757007, disc_loss = 0.060524797096149996
Trained batch 48 in epoch 3, gen_loss = 1.1529439334966698, disc_loss = 0.060254050485257594
Trained batch 49 in epoch 3, gen_loss = 1.151341539621353, disc_loss = 0.059510488053783776
Trained batch 50 in epoch 3, gen_loss = 1.1446470174134946, disc_loss = 0.059413040668575785
Trained batch 51 in epoch 3, gen_loss = 1.1553431967130074, disc_loss = 0.06463975773658603
Trained batch 52 in epoch 3, gen_loss = 1.156732641301065, disc_loss = 0.0639926316655891
Trained batch 53 in epoch 3, gen_loss = 1.1471207528202623, disc_loss = 0.06542336063769956
Trained batch 54 in epoch 3, gen_loss = 1.1481134642254223, disc_loss = 0.06595282005146146
Trained batch 55 in epoch 3, gen_loss = 1.1390130892395973, disc_loss = 0.0678882403881289
Trained batch 56 in epoch 3, gen_loss = 1.1390363155749805, disc_loss = 0.06746443765433996
Trained batch 57 in epoch 3, gen_loss = 1.1423775194020107, disc_loss = 0.06748748377190325
Trained batch 58 in epoch 3, gen_loss = 1.139233905380055, disc_loss = 0.06739477389413169
Trained batch 59 in epoch 3, gen_loss = 1.1378210435311, disc_loss = 0.06737966965107868
Trained batch 60 in epoch 3, gen_loss = 1.1451445769091122, disc_loss = 0.06647933580622566
Trained batch 61 in epoch 3, gen_loss = 1.149025047017682, disc_loss = 0.06788349296567181
Trained batch 62 in epoch 3, gen_loss = 1.1513087096668424, disc_loss = 0.06703244539214269
Trained batch 63 in epoch 3, gen_loss = 1.1421975744888186, disc_loss = 0.06956870189605979
Trained batch 64 in epoch 3, gen_loss = 1.147822369978978, disc_loss = 0.06889060130342842
Trained batch 65 in epoch 3, gen_loss = 1.1426120174653602, disc_loss = 0.0692616343484119
Trained batch 66 in epoch 3, gen_loss = 1.1510235667228699, disc_loss = 0.07094502973773364
Trained batch 67 in epoch 3, gen_loss = 1.153512543615173, disc_loss = 0.07014140264158521
Trained batch 68 in epoch 3, gen_loss = 1.14488665090091, disc_loss = 0.07279832981715816
Trained batch 69 in epoch 3, gen_loss = 1.1397342451981136, disc_loss = 0.0730985603893974
Trained batch 70 in epoch 3, gen_loss = 1.1509026767502368, disc_loss = 0.07346858668573936
Trained batch 71 in epoch 3, gen_loss = 1.1521748395429716, disc_loss = 0.07358232975497635
Trained batch 72 in epoch 3, gen_loss = 1.1545373258525378, disc_loss = 0.0727261606514556
Trained batch 73 in epoch 3, gen_loss = 1.1510950375247646, disc_loss = 0.0723642898232651
Trained batch 74 in epoch 3, gen_loss = 1.1461319820086162, disc_loss = 0.07246085157617926
Trained batch 75 in epoch 3, gen_loss = 1.154533070168997, disc_loss = 0.07561183045005523
Trained batch 76 in epoch 3, gen_loss = 1.1499572148570767, disc_loss = 0.07594594243889699
Trained batch 77 in epoch 3, gen_loss = 1.1491539944440892, disc_loss = 0.07579780351489973
Trained batch 78 in epoch 3, gen_loss = 1.1479044752784922, disc_loss = 0.07531931789450441
Trained batch 79 in epoch 3, gen_loss = 1.1478551857173442, disc_loss = 0.07557735201553442
Trained batch 80 in epoch 3, gen_loss = 1.1461736721757017, disc_loss = 0.07542776574530168
Trained batch 81 in epoch 3, gen_loss = 1.1447786565234022, disc_loss = 0.07494531463400074
Trained batch 82 in epoch 3, gen_loss = 1.1478432754436172, disc_loss = 0.07448937353981008
Trained batch 83 in epoch 3, gen_loss = 1.144183724409058, disc_loss = 0.0743843838184451
Trained batch 84 in epoch 3, gen_loss = 1.1433260167346282, disc_loss = 0.07445971891831826
Trained batch 85 in epoch 3, gen_loss = 1.1403818872085838, disc_loss = 0.07430837485874288
Trained batch 86 in epoch 3, gen_loss = 1.1377803717536488, disc_loss = 0.07485884608401136
Trained batch 87 in epoch 3, gen_loss = 1.1393462419509888, disc_loss = 0.07517009474527599
Trained batch 88 in epoch 3, gen_loss = 1.1382826821187908, disc_loss = 0.07480509655047836
Trained batch 89 in epoch 3, gen_loss = 1.138349625799391, disc_loss = 0.074323601115288
Trained batch 90 in epoch 3, gen_loss = 1.1377438673606286, disc_loss = 0.07390236261474727
Trained batch 91 in epoch 3, gen_loss = 1.137120219676391, disc_loss = 0.07376631702114221
Trained batch 92 in epoch 3, gen_loss = 1.1392493004439979, disc_loss = 0.07361193554556017
Trained batch 93 in epoch 3, gen_loss = 1.1367838471493823, disc_loss = 0.07356032016290788
Trained batch 94 in epoch 3, gen_loss = 1.1387648996553923, disc_loss = 0.073025370374518
Trained batch 95 in epoch 3, gen_loss = 1.1378564536571503, disc_loss = 0.07252236807350225
Trained batch 96 in epoch 3, gen_loss = 1.1375313382787802, disc_loss = 0.07201573811951525
Trained batch 97 in epoch 3, gen_loss = 1.1431481436807283, disc_loss = 0.07156343473482649
Trained batch 98 in epoch 3, gen_loss = 1.1448022705135923, disc_loss = 0.07096648818785042
Trained batch 99 in epoch 3, gen_loss = 1.1458304631710052, disc_loss = 0.07047965953592211
Trained batch 100 in epoch 3, gen_loss = 1.1459142170330086, disc_loss = 0.07098027092340116
Trained batch 101 in epoch 3, gen_loss = 1.142079016157225, disc_loss = 0.07181083398651988
Trained batch 102 in epoch 3, gen_loss = 1.1496627579614953, disc_loss = 0.07218764225491187
Trained batch 103 in epoch 3, gen_loss = 1.1527098778348703, disc_loss = 0.07169213905805148
Trained batch 104 in epoch 3, gen_loss = 1.1503034392992655, disc_loss = 0.07169653802134451
Trained batch 105 in epoch 3, gen_loss = 1.150704340552384, disc_loss = 0.07117267774048981
Trained batch 106 in epoch 3, gen_loss = 1.152067753199105, disc_loss = 0.07096606982593363
Trained batch 107 in epoch 3, gen_loss = 1.1464810691497944, disc_loss = 0.07219626397946505
Trained batch 108 in epoch 3, gen_loss = 1.1485518851411451, disc_loss = 0.07207492700085864
Trained batch 109 in epoch 3, gen_loss = 1.1473148736086758, disc_loss = 0.07173989911733025
Trained batch 110 in epoch 3, gen_loss = 1.1473672443682008, disc_loss = 0.07226007836577189
Trained batch 111 in epoch 3, gen_loss = 1.147337682545185, disc_loss = 0.07195872758997471
Trained batch 112 in epoch 3, gen_loss = 1.1475111446549406, disc_loss = 0.07189211327236443
Trained batch 113 in epoch 3, gen_loss = 1.1450025188295465, disc_loss = 0.0718362798563025
Trained batch 114 in epoch 3, gen_loss = 1.1504036416178165, disc_loss = 0.07146874726547495
Trained batch 115 in epoch 3, gen_loss = 1.1487989692852414, disc_loss = 0.07116202896476947
Trained batch 116 in epoch 3, gen_loss = 1.1478430695003934, disc_loss = 0.07101217512853253
Trained batch 117 in epoch 3, gen_loss = 1.1505197923062211, disc_loss = 0.07071170945241416
Trained batch 118 in epoch 3, gen_loss = 1.1473123576460766, disc_loss = 0.07099789746121324
Trained batch 119 in epoch 3, gen_loss = 1.1476371814807256, disc_loss = 0.07055033608727777
Trained batch 120 in epoch 3, gen_loss = 1.1497798803424046, disc_loss = 0.07003344066271727
Trained batch 121 in epoch 3, gen_loss = 1.1540817422944991, disc_loss = 0.06994953504610868
Trained batch 122 in epoch 3, gen_loss = 1.1578142294069615, disc_loss = 0.06950249182575238
Trained batch 123 in epoch 3, gen_loss = 1.1582926031081908, disc_loss = 0.06909825180041333
Trained batch 124 in epoch 3, gen_loss = 1.1554045505523682, disc_loss = 0.06934011014178396
Trained batch 125 in epoch 3, gen_loss = 1.154615344509246, disc_loss = 0.06926188862232106
Trained batch 126 in epoch 3, gen_loss = 1.1577609007752787, disc_loss = 0.0689538991716727
Trained batch 127 in epoch 3, gen_loss = 1.159173403866589, disc_loss = 0.0685789686285716
Trained batch 128 in epoch 3, gen_loss = 1.1564893597780272, disc_loss = 0.0685582566869178
Trained batch 129 in epoch 3, gen_loss = 1.1594856606079982, disc_loss = 0.06842175259684714
Trained batch 130 in epoch 3, gen_loss = 1.1601137118485139, disc_loss = 0.06804907645049099
Trained batch 131 in epoch 3, gen_loss = 1.163751344337608, disc_loss = 0.06781757740430873
Trained batch 132 in epoch 3, gen_loss = 1.164440858184843, disc_loss = 0.06779509636090326
Trained batch 133 in epoch 3, gen_loss = 1.1632805542269748, disc_loss = 0.06761600760006305
Trained batch 134 in epoch 3, gen_loss = 1.165090752089465, disc_loss = 0.06725394040415132
Trained batch 135 in epoch 3, gen_loss = 1.166736228062826, disc_loss = 0.0670121449545738
Trained batch 136 in epoch 3, gen_loss = 1.1666920172036999, disc_loss = 0.06663718911050989
Trained batch 137 in epoch 3, gen_loss = 1.1701037680757218, disc_loss = 0.0663920592793358
Trained batch 138 in epoch 3, gen_loss = 1.1682724931257233, disc_loss = 0.06639446150980514
Trained batch 139 in epoch 3, gen_loss = 1.1705424244914735, disc_loss = 0.06597678701592875
Trained batch 140 in epoch 3, gen_loss = 1.168650651654453, disc_loss = 0.06605199479055426
Trained batch 141 in epoch 3, gen_loss = 1.1726054826252896, disc_loss = 0.06614995782237343
Trained batch 142 in epoch 3, gen_loss = 1.1773087886663585, disc_loss = 0.06598837786008949
Trained batch 143 in epoch 3, gen_loss = 1.1775165953569942, disc_loss = 0.0656670496003547
Trained batch 144 in epoch 3, gen_loss = 1.1766031446128056, disc_loss = 0.06556389231941309
Trained batch 145 in epoch 3, gen_loss = 1.1735314841139806, disc_loss = 0.06592096911730526
Trained batch 146 in epoch 3, gen_loss = 1.1763158874446844, disc_loss = 0.06608107972725415
Trained batch 147 in epoch 3, gen_loss = 1.177927716358288, disc_loss = 0.06572742528923964
Trained batch 148 in epoch 3, gen_loss = 1.1769289506361789, disc_loss = 0.065510627810512
Trained batch 149 in epoch 3, gen_loss = 1.1776090463002522, disc_loss = 0.06532167420101663
Trained batch 150 in epoch 3, gen_loss = 1.1794720224986803, disc_loss = 0.06498938688194218
Trained batch 151 in epoch 3, gen_loss = 1.1770350842883712, disc_loss = 0.06548024515780669
Trained batch 152 in epoch 3, gen_loss = 1.180540629072127, disc_loss = 0.0654743397334481
Trained batch 153 in epoch 3, gen_loss = 1.1793855974426517, disc_loss = 0.06666717018218493
Trained batch 154 in epoch 3, gen_loss = 1.1753340401957113, disc_loss = 0.0681076756197839
Trained batch 155 in epoch 3, gen_loss = 1.1748800014074032, disc_loss = 0.06841821651249073
Trained batch 156 in epoch 3, gen_loss = 1.1739044443816895, disc_loss = 0.06825739031681305
Trained batch 157 in epoch 3, gen_loss = 1.1756066276302821, disc_loss = 0.06809971165914042
Trained batch 158 in epoch 3, gen_loss = 1.1746351032886866, disc_loss = 0.06785276838220984
Trained batch 159 in epoch 3, gen_loss = 1.1739107187837363, disc_loss = 0.06761157320870552
Trained batch 160 in epoch 3, gen_loss = 1.1739690759167167, disc_loss = 0.06737434278930658
Trained batch 161 in epoch 3, gen_loss = 1.1734060332363034, disc_loss = 0.0670858836175161
Trained batch 162 in epoch 3, gen_loss = 1.174896636989219, disc_loss = 0.06701957535261482
Trained batch 163 in epoch 3, gen_loss = 1.1762533285995809, disc_loss = 0.06666073719005487
Trained batch 164 in epoch 3, gen_loss = 1.1747270544370016, disc_loss = 0.06650503013903895
Trained batch 165 in epoch 3, gen_loss = 1.1761050644409226, disc_loss = 0.06622917757436902
Trained batch 166 in epoch 3, gen_loss = 1.1777149520948262, disc_loss = 0.06588266000519702
Trained batch 167 in epoch 3, gen_loss = 1.1797040789609863, disc_loss = 0.06557044274051718
Trained batch 168 in epoch 3, gen_loss = 1.1793138257850557, disc_loss = 0.06527790166272303
Trained batch 169 in epoch 3, gen_loss = 1.1803648356129142, disc_loss = 0.06498227639069014
Trained batch 170 in epoch 3, gen_loss = 1.1825046842558342, disc_loss = 0.06471155766038257
Trained batch 171 in epoch 3, gen_loss = 1.1837314814329147, disc_loss = 0.06444861329712927
Trained batch 172 in epoch 3, gen_loss = 1.1842845957403239, disc_loss = 0.06417951849423822
Trained batch 173 in epoch 3, gen_loss = 1.1871010246633114, disc_loss = 0.06392898581033551
Trained batch 174 in epoch 3, gen_loss = 1.1886961804117475, disc_loss = 0.0636328925910805
Trained batch 175 in epoch 3, gen_loss = 1.1906031251631, disc_loss = 0.06333968666413883
Trained batch 176 in epoch 3, gen_loss = 1.1909627789831432, disc_loss = 0.06303522867113773
Trained batch 177 in epoch 3, gen_loss = 1.1936128919713953, disc_loss = 0.06295668259210717
Trained batch 178 in epoch 3, gen_loss = 1.193503739780554, disc_loss = 0.06276231968525652
Trained batch 179 in epoch 3, gen_loss = 1.1953785647948583, disc_loss = 0.06259718770937374
Trained batch 180 in epoch 3, gen_loss = 1.1961382492471135, disc_loss = 0.06248162155559297
Trained batch 181 in epoch 3, gen_loss = 1.1955907872089973, disc_loss = 0.062299948275232546
Trained batch 182 in epoch 3, gen_loss = 1.1974707636676851, disc_loss = 0.06215747990111103
Trained batch 183 in epoch 3, gen_loss = 1.199712412836759, disc_loss = 0.06195369226928881
Trained batch 184 in epoch 3, gen_loss = 1.2004791714049674, disc_loss = 0.06180404094173699
Trained batch 185 in epoch 3, gen_loss = 1.2000065596513851, disc_loss = 0.06168047266371388
Trained batch 186 in epoch 3, gen_loss = 1.2009796767948784, disc_loss = 0.061393183304923264
Trained batch 187 in epoch 3, gen_loss = 1.2038788513300267, disc_loss = 0.06121378953994668
Trained batch 188 in epoch 3, gen_loss = 1.2054725711938565, disc_loss = 0.06093843871845849
Trained batch 189 in epoch 3, gen_loss = 1.2054462900287226, disc_loss = 0.06075921303984758
Trained batch 190 in epoch 3, gen_loss = 1.2073466131824473, disc_loss = 0.06053193341891881
Trained batch 191 in epoch 3, gen_loss = 1.207872505299747, disc_loss = 0.06027447862288682
Trained batch 192 in epoch 3, gen_loss = 1.209835643286532, disc_loss = 0.060070012674372585
Trained batch 193 in epoch 3, gen_loss = 1.211616441453855, disc_loss = 0.05981356315746827
Trained batch 194 in epoch 3, gen_loss = 1.211754371264042, disc_loss = 0.05958256759943489
Trained batch 195 in epoch 3, gen_loss = 1.2115928022837152, disc_loss = 0.05934677118368979
Trained batch 196 in epoch 3, gen_loss = 1.2124626905784994, disc_loss = 0.05907188143420416
Trained batch 197 in epoch 3, gen_loss = 1.2145613206155372, disc_loss = 0.058827563605243056
Trained batch 198 in epoch 3, gen_loss = 1.2151429039150028, disc_loss = 0.05857994264908996
Trained batch 199 in epoch 3, gen_loss = 1.2152255561947822, disc_loss = 0.058378724434878675
Trained batch 200 in epoch 3, gen_loss = 1.2167776938694626, disc_loss = 0.05849651893860294
Trained batch 201 in epoch 3, gen_loss = 1.2158024750723697, disc_loss = 0.05846382308483935
Trained batch 202 in epoch 3, gen_loss = 1.215778039300383, disc_loss = 0.058279675920149814
Trained batch 203 in epoch 3, gen_loss = 1.2172069564169528, disc_loss = 0.058047989874110355
Trained batch 204 in epoch 3, gen_loss = 1.2179199372849814, disc_loss = 0.05789100695628582
Trained batch 205 in epoch 3, gen_loss = 1.2194863630151285, disc_loss = 0.057675056066816145
Trained batch 206 in epoch 3, gen_loss = 1.2237399779080194, disc_loss = 0.057625911029838564
Trained batch 207 in epoch 3, gen_loss = 1.2226391815795348, disc_loss = 0.057567698699690834
Trained batch 208 in epoch 3, gen_loss = 1.2236222562037016, disc_loss = 0.057332245087135206
Trained batch 209 in epoch 3, gen_loss = 1.2222174539452508, disc_loss = 0.057367449091924795
Trained batch 210 in epoch 3, gen_loss = 1.2239583016006867, disc_loss = 0.057184280922539285
Trained batch 211 in epoch 3, gen_loss = 1.2244957401505057, disc_loss = 0.05699918823940504
Trained batch 212 in epoch 3, gen_loss = 1.2248132388356705, disc_loss = 0.05678909318084378
Trained batch 213 in epoch 3, gen_loss = 1.2258909586991105, disc_loss = 0.0565661004261401
Trained batch 214 in epoch 3, gen_loss = 1.2253990026407464, disc_loss = 0.05648354922399618
Trained batch 215 in epoch 3, gen_loss = 1.2257946693786868, disc_loss = 0.05627600052954491
Trained batch 216 in epoch 3, gen_loss = 1.224430413290103, disc_loss = 0.05622284511996922
Trained batch 217 in epoch 3, gen_loss = 1.2276074995688342, disc_loss = 0.0564908603945354
Trained batch 218 in epoch 3, gen_loss = 1.2294914793206133, disc_loss = 0.05631901297641739
Trained batch 219 in epoch 3, gen_loss = 1.2292715684934097, disc_loss = 0.056129148210906844
Trained batch 220 in epoch 3, gen_loss = 1.2291356195691485, disc_loss = 0.055963486211787386
Trained batch 221 in epoch 3, gen_loss = 1.2294852755091212, disc_loss = 0.055751021911583105
Trained batch 222 in epoch 3, gen_loss = 1.2299305959667326, disc_loss = 0.055600610509464694
Trained batch 223 in epoch 3, gen_loss = 1.2303787815783704, disc_loss = 0.05538808609500328
Trained batch 224 in epoch 3, gen_loss = 1.2301559707853529, disc_loss = 0.05523714884494742
Trained batch 225 in epoch 3, gen_loss = 1.2311411120195304, disc_loss = 0.055036389810832594
Trained batch 226 in epoch 3, gen_loss = 1.2321292230211165, disc_loss = 0.05485033609243807
Trained batch 227 in epoch 3, gen_loss = 1.2335251737059207, disc_loss = 0.05464337287233783
Trained batch 228 in epoch 3, gen_loss = 1.2334980850136437, disc_loss = 0.05444481736862438
Trained batch 229 in epoch 3, gen_loss = 1.2339184444883595, disc_loss = 0.054226704782036984
Trained batch 230 in epoch 3, gen_loss = 1.235110660136004, disc_loss = 0.05402768243837989
Trained batch 231 in epoch 3, gen_loss = 1.2358467044501469, disc_loss = 0.053815109974399596
Trained batch 232 in epoch 3, gen_loss = 1.2356240140521986, disc_loss = 0.05361390548314531
Trained batch 233 in epoch 3, gen_loss = 1.2365688141594586, disc_loss = 0.053650428338024095
Trained batch 234 in epoch 3, gen_loss = 1.2353293299674988, disc_loss = 0.05361669377047331
Trained batch 235 in epoch 3, gen_loss = 1.2363281747547246, disc_loss = 0.0535501804384324
Trained batch 236 in epoch 3, gen_loss = 1.2357246435644254, disc_loss = 0.05348246787843699
Trained batch 237 in epoch 3, gen_loss = 1.2356937705468731, disc_loss = 0.05330035674675297
Trained batch 238 in epoch 3, gen_loss = 1.236824656380769, disc_loss = 0.05310413264572059
Trained batch 239 in epoch 3, gen_loss = 1.2383725675443809, disc_loss = 0.052995567534041284
Trained batch 240 in epoch 3, gen_loss = 1.2385099673666895, disc_loss = 0.05282755868308463
Trained batch 241 in epoch 3, gen_loss = 1.2376714843856402, disc_loss = 0.052783900823767396
Trained batch 242 in epoch 3, gen_loss = 1.2392226680806635, disc_loss = 0.0526513950458494
Trained batch 243 in epoch 3, gen_loss = 1.2408406927448805, disc_loss = 0.05252248873040996
Trained batch 244 in epoch 3, gen_loss = 1.2410053893011443, disc_loss = 0.05237447802471567
Trained batch 245 in epoch 3, gen_loss = 1.241398803344587, disc_loss = 0.05221660622032132
Trained batch 246 in epoch 3, gen_loss = 1.2418321856120338, disc_loss = 0.052041164427799616
Trained batch 247 in epoch 3, gen_loss = 1.2426092679942808, disc_loss = 0.05187647978797735
Trained batch 248 in epoch 3, gen_loss = 1.2432064701275654, disc_loss = 0.05168689544271513
Trained batch 249 in epoch 3, gen_loss = 1.243120088815689, disc_loss = 0.051516903754323724
Trained batch 250 in epoch 3, gen_loss = 1.2438463601933059, disc_loss = 0.05133613179144691
Trained batch 251 in epoch 3, gen_loss = 1.2443980794577372, disc_loss = 0.051222313707324836
Trained batch 252 in epoch 3, gen_loss = 1.244315020416094, disc_loss = 0.05106489964219716
Trained batch 253 in epoch 3, gen_loss = 1.244236718247256, disc_loss = 0.050923335664780946
Trained batch 254 in epoch 3, gen_loss = 1.2447239765933915, disc_loss = 0.05078653983735278
Trained batch 255 in epoch 3, gen_loss = 1.2450461343396455, disc_loss = 0.050637007092518616
Trained batch 256 in epoch 3, gen_loss = 1.246692343212751, disc_loss = 0.05049225792890335
Trained batch 257 in epoch 3, gen_loss = 1.2485499315021573, disc_loss = 0.050704455802708055
Trained batch 258 in epoch 3, gen_loss = 1.249168541670766, disc_loss = 0.05056514430424364
Trained batch 259 in epoch 3, gen_loss = 1.2480433519069964, disc_loss = 0.05069942867490821
Trained batch 260 in epoch 3, gen_loss = 1.2459456623742406, disc_loss = 0.05092057883132863
Trained batch 261 in epoch 3, gen_loss = 1.2467954390831577, disc_loss = 0.050859556304120264
Trained batch 262 in epoch 3, gen_loss = 1.2468091326521378, disc_loss = 0.050820464408202204
Trained batch 263 in epoch 3, gen_loss = 1.2464089325883172, disc_loss = 0.05072487996376091
Trained batch 264 in epoch 3, gen_loss = 1.247536352895341, disc_loss = 0.050629257746392264
Trained batch 265 in epoch 3, gen_loss = 1.2470456939890868, disc_loss = 0.05053471805898935
Trained batch 266 in epoch 3, gen_loss = 1.2460015476419684, disc_loss = 0.050536370803061385
Trained batch 267 in epoch 3, gen_loss = 1.2457113750834963, disc_loss = 0.05041914921663979
Trained batch 268 in epoch 3, gen_loss = 1.2478118487893428, disc_loss = 0.05035928652542176
Trained batch 269 in epoch 3, gen_loss = 1.2481988549232483, disc_loss = 0.050203000166005006
Trained batch 270 in epoch 3, gen_loss = 1.2467760837386015, disc_loss = 0.05094531122629438
Trained batch 271 in epoch 3, gen_loss = 1.2448897633482428, disc_loss = 0.051158367866746095
Trained batch 272 in epoch 3, gen_loss = 1.242567778288663, disc_loss = 0.051610957072099374
Trained batch 273 in epoch 3, gen_loss = 1.245337015303382, disc_loss = 0.052793470875829134
Trained batch 274 in epoch 3, gen_loss = 1.2455233068899674, disc_loss = 0.05285621398382566
Trained batch 275 in epoch 3, gen_loss = 1.2447763255972792, disc_loss = 0.05293981951452198
Trained batch 276 in epoch 3, gen_loss = 1.2440155871508354, disc_loss = 0.052868592467105235
Trained batch 277 in epoch 3, gen_loss = 1.2450661121083677, disc_loss = 0.05271870665513515
Trained batch 278 in epoch 3, gen_loss = 1.2458206489949244, disc_loss = 0.05257602789903253
Trained batch 279 in epoch 3, gen_loss = 1.2458370713250977, disc_loss = 0.05241799323786316
Trained batch 280 in epoch 3, gen_loss = 1.246709003355155, disc_loss = 0.052303403879439596
Trained batch 281 in epoch 3, gen_loss = 1.2471443577438381, disc_loss = 0.05215206641063147
Trained batch 282 in epoch 3, gen_loss = 1.247365969440541, disc_loss = 0.052008405010225814
Trained batch 283 in epoch 3, gen_loss = 1.2482233637235534, disc_loss = 0.05185830339782832
Trained batch 284 in epoch 3, gen_loss = 1.248424754435556, disc_loss = 0.051712574442162325
Trained batch 285 in epoch 3, gen_loss = 1.2489512143851993, disc_loss = 0.05155145019533803
Trained batch 286 in epoch 3, gen_loss = 1.2498680591998614, disc_loss = 0.05139195838722462
Trained batch 287 in epoch 3, gen_loss = 1.249935414435135, disc_loss = 0.05123283080239263
Trained batch 288 in epoch 3, gen_loss = 1.2505804892229786, disc_loss = 0.05107403798576664
Trained batch 289 in epoch 3, gen_loss = 1.2509116725674991, disc_loss = 0.050929989151913546
Trained batch 290 in epoch 3, gen_loss = 1.2503575387689256, disc_loss = 0.05085218649139929
Trained batch 291 in epoch 3, gen_loss = 1.2518518761004487, disc_loss = 0.050729221243360274
Trained batch 292 in epoch 3, gen_loss = 1.2514235503437576, disc_loss = 0.05066379960689935
Trained batch 293 in epoch 3, gen_loss = 1.253478532137514, disc_loss = 0.05058792215727624
Trained batch 294 in epoch 3, gen_loss = 1.2530897376901013, disc_loss = 0.05062439459360252
Trained batch 295 in epoch 3, gen_loss = 1.2535485369530883, disc_loss = 0.050526389071868884
Trained batch 296 in epoch 3, gen_loss = 1.2532164944141402, disc_loss = 0.0504475995170749
Trained batch 297 in epoch 3, gen_loss = 1.2540826671475531, disc_loss = 0.05032401693822353
Trained batch 298 in epoch 3, gen_loss = 1.2541714541888158, disc_loss = 0.05027992599160974
Trained batch 299 in epoch 3, gen_loss = 1.2541276516517004, disc_loss = 0.050229862462729216
Trained batch 300 in epoch 3, gen_loss = 1.253999946323344, disc_loss = 0.050120000532546706
Trained batch 301 in epoch 3, gen_loss = 1.255430888458593, disc_loss = 0.050011687424798675
Trained batch 302 in epoch 3, gen_loss = 1.256264849267777, disc_loss = 0.04990664142316127
Trained batch 303 in epoch 3, gen_loss = 1.256895063543006, disc_loss = 0.049802603849552964
Trained batch 304 in epoch 3, gen_loss = 1.2550985127198893, disc_loss = 0.050043136846335205
Trained batch 305 in epoch 3, gen_loss = 1.2549050347088209, disc_loss = 0.05005528391917157
Trained batch 306 in epoch 3, gen_loss = 1.2559155837332387, disc_loss = 0.04999369405307094
Trained batch 307 in epoch 3, gen_loss = 1.2563226085591626, disc_loss = 0.0499048147761783
Trained batch 308 in epoch 3, gen_loss = 1.2558882766942763, disc_loss = 0.05013566790902113
Trained batch 309 in epoch 3, gen_loss = 1.254776660280843, disc_loss = 0.05021556398320583
Trained batch 310 in epoch 3, gen_loss = 1.2549453235899137, disc_loss = 0.05008507709219525
Trained batch 311 in epoch 3, gen_loss = 1.2554211465594096, disc_loss = 0.049950984915575154
Trained batch 312 in epoch 3, gen_loss = 1.2567241669843754, disc_loss = 0.04994134717998794
Trained batch 313 in epoch 3, gen_loss = 1.2564218854828246, disc_loss = 0.049927152111936525
Trained batch 314 in epoch 3, gen_loss = 1.2558261816463774, disc_loss = 0.04986711320659471
Trained batch 315 in epoch 3, gen_loss = 1.2546474735570858, disc_loss = 0.050041554955459096
Trained batch 316 in epoch 3, gen_loss = 1.256434941705469, disc_loss = 0.050216545759221354
Trained batch 317 in epoch 3, gen_loss = 1.256222907664641, disc_loss = 0.050141321957907964
Trained batch 318 in epoch 3, gen_loss = 1.2570876034449634, disc_loss = 0.05006939918970613
Trained batch 319 in epoch 3, gen_loss = 1.2566436706110835, disc_loss = 0.04999948617769405
Trained batch 320 in epoch 3, gen_loss = 1.2571249425968276, disc_loss = 0.04996533553780425
Trained batch 321 in epoch 3, gen_loss = 1.2579372312341417, disc_loss = 0.04985563932218074
Trained batch 322 in epoch 3, gen_loss = 1.256410264193827, disc_loss = 0.05002247113965152
Trained batch 323 in epoch 3, gen_loss = 1.2571640586779442, disc_loss = 0.049995327928896854
Trained batch 324 in epoch 3, gen_loss = 1.2571694507965674, disc_loss = 0.049916228156250256
Trained batch 325 in epoch 3, gen_loss = 1.2559747778199202, disc_loss = 0.05001500398320563
Trained batch 326 in epoch 3, gen_loss = 1.2556643469618, disc_loss = 0.05008146842081521
Trained batch 327 in epoch 3, gen_loss = 1.2572961251546697, disc_loss = 0.05004440297702009
Trained batch 328 in epoch 3, gen_loss = 1.2579246315550296, disc_loss = 0.04991332528897558
Trained batch 329 in epoch 3, gen_loss = 1.2568943697394748, disc_loss = 0.0499489724875964
Trained batch 330 in epoch 3, gen_loss = 1.2570184355776115, disc_loss = 0.04983355244903001
Trained batch 331 in epoch 3, gen_loss = 1.2586388051150792, disc_loss = 0.049771315298963295
Trained batch 332 in epoch 3, gen_loss = 1.2585936070562482, disc_loss = 0.04974116020704488
Trained batch 333 in epoch 3, gen_loss = 1.2576314380425893, disc_loss = 0.04973079716301562
Trained batch 334 in epoch 3, gen_loss = 1.2583346667574413, disc_loss = 0.04963013572451561
Trained batch 335 in epoch 3, gen_loss = 1.2592368383137953, disc_loss = 0.04954482353198165
Trained batch 336 in epoch 3, gen_loss = 1.259020778651761, disc_loss = 0.04943740935940903
Trained batch 337 in epoch 3, gen_loss = 1.258434660865005, disc_loss = 0.049365391865229376
Trained batch 338 in epoch 3, gen_loss = 1.2588723491778415, disc_loss = 0.04928538732225169
Trained batch 339 in epoch 3, gen_loss = 1.2594610114307965, disc_loss = 0.04917533760753406
Trained batch 340 in epoch 3, gen_loss = 1.2606105949522113, disc_loss = 0.04914168984413453
Trained batch 341 in epoch 3, gen_loss = 1.2595894451726948, disc_loss = 0.04916892250133842
Trained batch 342 in epoch 3, gen_loss = 1.259839544490892, disc_loss = 0.04909314051047836
Trained batch 343 in epoch 3, gen_loss = 1.2598984037027803, disc_loss = 0.04899251726753793
Trained batch 344 in epoch 3, gen_loss = 1.2599920500879702, disc_loss = 0.04888799235197729
Trained batch 345 in epoch 3, gen_loss = 1.2604801386077968, disc_loss = 0.048816696017969806
Trained batch 346 in epoch 3, gen_loss = 1.2601170797512924, disc_loss = 0.0487442649726458
Trained batch 347 in epoch 3, gen_loss = 1.2605242139991673, disc_loss = 0.04862926498285613
Trained batch 348 in epoch 3, gen_loss = 1.2612504986432358, disc_loss = 0.04857257989376655
Trained batch 349 in epoch 3, gen_loss = 1.2615831899642944, disc_loss = 0.04860712180047163
Trained batch 350 in epoch 3, gen_loss = 1.2609603282732842, disc_loss = 0.048724779003482856
Trained batch 351 in epoch 3, gen_loss = 1.2609446048736572, disc_loss = 0.04863964671411933
Trained batch 352 in epoch 3, gen_loss = 1.2616937775112076, disc_loss = 0.04863903318365598
Trained batch 353 in epoch 3, gen_loss = 1.2616828909028048, disc_loss = 0.04883271945498378
Trained batch 354 in epoch 3, gen_loss = 1.2603163371623403, disc_loss = 0.049070631212909034
Trained batch 355 in epoch 3, gen_loss = 1.2591695227984632, disc_loss = 0.04910483702446931
Trained batch 356 in epoch 3, gen_loss = 1.260329040659576, disc_loss = 0.04914470903278023
Trained batch 357 in epoch 3, gen_loss = 1.2615480128280276, disc_loss = 0.04917604170672013
Trained batch 358 in epoch 3, gen_loss = 1.2610262766854012, disc_loss = 0.04917993133337675
Trained batch 359 in epoch 3, gen_loss = 1.2619873565104274, disc_loss = 0.0491177333971589
Trained batch 360 in epoch 3, gen_loss = 1.260990954006808, disc_loss = 0.04910135750434364
Trained batch 361 in epoch 3, gen_loss = 1.26025707402282, disc_loss = 0.04948913296092899
Trained batch 362 in epoch 3, gen_loss = 1.2602112104413266, disc_loss = 0.04941752034088099
Trained batch 363 in epoch 3, gen_loss = 1.2590856013389735, disc_loss = 0.04948065933837954
Trained batch 364 in epoch 3, gen_loss = 1.2596941397614676, disc_loss = 0.049388219164811994
Trained batch 365 in epoch 3, gen_loss = 1.2614356626252659, disc_loss = 0.04942489571518219
Trained batch 366 in epoch 3, gen_loss = 1.2616062562212307, disc_loss = 0.049353529847600074
Trained batch 367 in epoch 3, gen_loss = 1.2616334698446419, disc_loss = 0.04925151744670154
Trained batch 368 in epoch 3, gen_loss = 1.2621164329975925, disc_loss = 0.04917721383571423
Trained batch 369 in epoch 3, gen_loss = 1.2617750923375826, disc_loss = 0.0491089872197827
Trained batch 370 in epoch 3, gen_loss = 1.2619328680385475, disc_loss = 0.04905587624422101
Trained batch 371 in epoch 3, gen_loss = 1.2608495346641029, disc_loss = 0.04903425213064678
Trained batch 372 in epoch 3, gen_loss = 1.2612388327358235, disc_loss = 0.048994643527555004
Trained batch 373 in epoch 3, gen_loss = 1.2613044239301732, disc_loss = 0.04889642031748784
Trained batch 374 in epoch 3, gen_loss = 1.2611477710405985, disc_loss = 0.04879438845192393
Trained batch 375 in epoch 3, gen_loss = 1.2618402691280588, disc_loss = 0.04900230625718634
Trained batch 376 in epoch 3, gen_loss = 1.2602026258602699, disc_loss = 0.04929567434619964
Trained batch 377 in epoch 3, gen_loss = 1.2593592288632873, disc_loss = 0.04925407574600762
Trained batch 378 in epoch 3, gen_loss = 1.260998560130439, disc_loss = 0.049257583364519957
Trained batch 379 in epoch 3, gen_loss = 1.2610591000632236, disc_loss = 0.049156119325198235
Trained batch 380 in epoch 3, gen_loss = 1.260716586601077, disc_loss = 0.04915611332849529
Trained batch 381 in epoch 3, gen_loss = 1.2611899644292461, disc_loss = 0.04921627536547707
Trained batch 382 in epoch 3, gen_loss = 1.2596413871326895, disc_loss = 0.04997476282123447
Trained batch 383 in epoch 3, gen_loss = 1.2578530008904636, disc_loss = 0.050423537384631345
Trained batch 384 in epoch 3, gen_loss = 1.2579660181875352, disc_loss = 0.05040483068698993
Trained batch 385 in epoch 3, gen_loss = 1.2579180593626487, disc_loss = 0.05050388949807405
Trained batch 386 in epoch 3, gen_loss = 1.2578844566677891, disc_loss = 0.050398218605513335
Trained batch 387 in epoch 3, gen_loss = 1.2575981713754614, disc_loss = 0.05030339942481753
Trained batch 388 in epoch 3, gen_loss = 1.2572123016060777, disc_loss = 0.050230661681242725
Trained batch 389 in epoch 3, gen_loss = 1.257625274016307, disc_loss = 0.05016613103186664
Trained batch 390 in epoch 3, gen_loss = 1.2568515921797594, disc_loss = 0.05015042806377687
Trained batch 391 in epoch 3, gen_loss = 1.2559519884537678, disc_loss = 0.0501523731972509
Trained batch 392 in epoch 3, gen_loss = 1.2557950150268982, disc_loss = 0.05021237984001068
Trained batch 393 in epoch 3, gen_loss = 1.2555728699955238, disc_loss = 0.050313713814978143
Trained batch 394 in epoch 3, gen_loss = 1.2557542776759667, disc_loss = 0.05025931851042411
Trained batch 395 in epoch 3, gen_loss = 1.256356071041088, disc_loss = 0.05041285688551425
Trained batch 396 in epoch 3, gen_loss = 1.2545395025077934, disc_loss = 0.05093823446157935
Trained batch 397 in epoch 3, gen_loss = 1.2550369340870249, disc_loss = 0.05084285829520443
Trained batch 398 in epoch 3, gen_loss = 1.2570191303590186, disc_loss = 0.05125334545769227
Trained batch 399 in epoch 3, gen_loss = 1.2557686287164689, disc_loss = 0.05136585398227908
Trained batch 400 in epoch 3, gen_loss = 1.2563631992387652, disc_loss = 0.05127608363500371
Trained batch 401 in epoch 3, gen_loss = 1.2560675956716585, disc_loss = 0.05123576286378599
Trained batch 402 in epoch 3, gen_loss = 1.2558558815466263, disc_loss = 0.05118884382741734
Trained batch 403 in epoch 3, gen_loss = 1.255632646898232, disc_loss = 0.05159405331095072
Trained batch 404 in epoch 3, gen_loss = 1.254694962207182, disc_loss = 0.05172669609640668
Trained batch 405 in epoch 3, gen_loss = 1.2537068724632263, disc_loss = 0.05180602449019958
Trained batch 406 in epoch 3, gen_loss = 1.2529607201384092, disc_loss = 0.05179786852261175
Trained batch 407 in epoch 3, gen_loss = 1.252887170542689, disc_loss = 0.05175858176217469
Trained batch 408 in epoch 3, gen_loss = 1.2529199209364819, disc_loss = 0.05167556370888589
Trained batch 409 in epoch 3, gen_loss = 1.2525038845655394, disc_loss = 0.051650099255280885
Trained batch 410 in epoch 3, gen_loss = 1.2527768993319677, disc_loss = 0.05206312715821421
Trained batch 411 in epoch 3, gen_loss = 1.2520745418314796, disc_loss = 0.052021712298703934
Trained batch 412 in epoch 3, gen_loss = 1.250076106977232, disc_loss = 0.05266012833961094
Trained batch 413 in epoch 3, gen_loss = 1.2511709791018768, disc_loss = 0.05323454580980618
Trained batch 414 in epoch 3, gen_loss = 1.2510452411979078, disc_loss = 0.05328177832942232
Trained batch 415 in epoch 3, gen_loss = 1.2498452134000568, disc_loss = 0.05342982249007596
Trained batch 416 in epoch 3, gen_loss = 1.249218220976617, disc_loss = 0.05341139191770546
Trained batch 417 in epoch 3, gen_loss = 1.2484570189098423, disc_loss = 0.05336715833453292
Trained batch 418 in epoch 3, gen_loss = 1.2489090785917634, disc_loss = 0.05354948946317049
Trained batch 419 in epoch 3, gen_loss = 1.2486340114758128, disc_loss = 0.053486344806983
Trained batch 420 in epoch 3, gen_loss = 1.247414929779012, disc_loss = 0.0535890516148097
Trained batch 421 in epoch 3, gen_loss = 1.2469810882309602, disc_loss = 0.05358365065444667
Trained batch 422 in epoch 3, gen_loss = 1.2464638293916734, disc_loss = 0.0536609989740659
Trained batch 423 in epoch 3, gen_loss = 1.2471220495425306, disc_loss = 0.053582131145478065
Trained batch 424 in epoch 3, gen_loss = 1.2459977143652299, disc_loss = 0.053710212675744995
Trained batch 425 in epoch 3, gen_loss = 1.2464321213009213, disc_loss = 0.05360847556889232
Trained batch 426 in epoch 3, gen_loss = 1.2466437187769932, disc_loss = 0.053602204486876026
Trained batch 427 in epoch 3, gen_loss = 1.24629752094222, disc_loss = 0.053539689674877745
Trained batch 428 in epoch 3, gen_loss = 1.2455587283575729, disc_loss = 0.053511240970048106
Trained batch 429 in epoch 3, gen_loss = 1.2455527457386948, disc_loss = 0.05342366833261453
Trained batch 430 in epoch 3, gen_loss = 1.246781820971562, disc_loss = 0.05343419817447005
Trained batch 431 in epoch 3, gen_loss = 1.2451850555975128, disc_loss = 0.05412545426925472
Trained batch 432 in epoch 3, gen_loss = 1.2471025297740865, disc_loss = 0.05412130988811683
Trained batch 433 in epoch 3, gen_loss = 1.2480711801672861, disc_loss = 0.05408482021901087
Trained batch 434 in epoch 3, gen_loss = 1.2472002478166557, disc_loss = 0.054126072736007384
Trained batch 435 in epoch 3, gen_loss = 1.2469152323559884, disc_loss = 0.05404984315434351
Trained batch 436 in epoch 3, gen_loss = 1.247209989710858, disc_loss = 0.05394846913287548
Trained batch 437 in epoch 3, gen_loss = 1.247750319778647, disc_loss = 0.05397663464170102
Trained batch 438 in epoch 3, gen_loss = 1.2477068699438099, disc_loss = 0.05389983206669161
Trained batch 439 in epoch 3, gen_loss = 1.2483873615888033, disc_loss = 0.05380678457652473
Trained batch 440 in epoch 3, gen_loss = 1.2484547355953528, disc_loss = 0.053706655102463065
Trained batch 441 in epoch 3, gen_loss = 1.248025072308687, disc_loss = 0.05364759252996635
Trained batch 442 in epoch 3, gen_loss = 1.247877862262403, disc_loss = 0.053692295257018935
Trained batch 443 in epoch 3, gen_loss = 1.247130316052888, disc_loss = 0.05372533714084106
Trained batch 444 in epoch 3, gen_loss = 1.2466152667329553, disc_loss = 0.05367448553547598
Trained batch 445 in epoch 3, gen_loss = 1.2467707908073349, disc_loss = 0.0536991947261625
Trained batch 446 in epoch 3, gen_loss = 1.2476201008763623, disc_loss = 0.053670263748149274
Trained batch 447 in epoch 3, gen_loss = 1.2468263020605914, disc_loss = 0.053667730420004646
Trained batch 448 in epoch 3, gen_loss = 1.2456336184041803, disc_loss = 0.053816294153418
Trained batch 449 in epoch 3, gen_loss = 1.2471142639716466, disc_loss = 0.05379536868900889
Trained batch 450 in epoch 3, gen_loss = 1.2472249574116752, disc_loss = 0.05374285865042301
Trained batch 451 in epoch 3, gen_loss = 1.2468799126491081, disc_loss = 0.053668719597894335
Trained batch 452 in epoch 3, gen_loss = 1.2481737932227306, disc_loss = 0.053670391708686455
Trained batch 453 in epoch 3, gen_loss = 1.248146266729821, disc_loss = 0.05357706157125467
Trained batch 454 in epoch 3, gen_loss = 1.2471216536485232, disc_loss = 0.0537090629431327
Trained batch 455 in epoch 3, gen_loss = 1.246412605112582, disc_loss = 0.05371488456046535
Trained batch 456 in epoch 3, gen_loss = 1.247596296035487, disc_loss = 0.053692346639499164
Trained batch 457 in epoch 3, gen_loss = 1.248413728118984, disc_loss = 0.053648510558416816
Trained batch 458 in epoch 3, gen_loss = 1.2481781244927241, disc_loss = 0.05365891876470192
Trained batch 459 in epoch 3, gen_loss = 1.248689709862937, disc_loss = 0.05356993873340442
Trained batch 460 in epoch 3, gen_loss = 1.248303378804904, disc_loss = 0.053512669042148776
Trained batch 461 in epoch 3, gen_loss = 1.2480158360102476, disc_loss = 0.05345784966406529
Trained batch 462 in epoch 3, gen_loss = 1.2483339990060736, disc_loss = 0.053359504138395096
Trained batch 463 in epoch 3, gen_loss = 1.248765521586455, disc_loss = 0.05325611608990083
Trained batch 464 in epoch 3, gen_loss = 1.2490427497253622, disc_loss = 0.053155145670978295
Trained batch 465 in epoch 3, gen_loss = 1.2498884836107875, disc_loss = 0.053074975395095515
Trained batch 466 in epoch 3, gen_loss = 1.2507087378353838, disc_loss = 0.052994321099416666
Trained batch 467 in epoch 3, gen_loss = 1.2511250914798842, disc_loss = 0.052903255134319455
Trained batch 468 in epoch 3, gen_loss = 1.251043216315414, disc_loss = 0.05283412995881268
Trained batch 469 in epoch 3, gen_loss = 1.250967710893205, disc_loss = 0.0527554188171362
Trained batch 470 in epoch 3, gen_loss = 1.2508891943027514, disc_loss = 0.05267422511529043
Trained batch 471 in epoch 3, gen_loss = 1.2518210836007433, disc_loss = 0.05260369717242133
Trained batch 472 in epoch 3, gen_loss = 1.2512748431075702, disc_loss = 0.05256310396435932
Trained batch 473 in epoch 3, gen_loss = 1.2513832088386962, disc_loss = 0.05250183979878477
Trained batch 474 in epoch 3, gen_loss = 1.2533507515882192, disc_loss = 0.05263065469598299
Trained batch 475 in epoch 3, gen_loss = 1.2537249640381636, disc_loss = 0.05254883859443533
Trained batch 476 in epoch 3, gen_loss = 1.253374306473342, disc_loss = 0.05250098095792863
Trained batch 477 in epoch 3, gen_loss = 1.2530894055650823, disc_loss = 0.052436415307714784
Trained batch 478 in epoch 3, gen_loss = 1.2534710935983877, disc_loss = 0.05234274848817317
Trained batch 479 in epoch 3, gen_loss = 1.2524451679860553, disc_loss = 0.052405615854271066
Trained batch 480 in epoch 3, gen_loss = 1.2527561162340914, disc_loss = 0.05241328206498044
Trained batch 481 in epoch 3, gen_loss = 1.252192340636649, disc_loss = 0.052371643364808186
Trained batch 482 in epoch 3, gen_loss = 1.2522725221656619, disc_loss = 0.05229733300956417
Trained batch 483 in epoch 3, gen_loss = 1.2520113776414847, disc_loss = 0.0522356015670475
Trained batch 484 in epoch 3, gen_loss = 1.2532705333429512, disc_loss = 0.05228394560765513
Trained batch 485 in epoch 3, gen_loss = 1.2528556842249607, disc_loss = 0.05224401789426098
Trained batch 486 in epoch 3, gen_loss = 1.252768401186569, disc_loss = 0.05216933163533129
Trained batch 487 in epoch 3, gen_loss = 1.2526645364209277, disc_loss = 0.05208637078433893
Trained batch 488 in epoch 3, gen_loss = 1.252929935365123, disc_loss = 0.05200413968471205
Trained batch 489 in epoch 3, gen_loss = 1.2535637806264721, disc_loss = 0.05192412644035506
Trained batch 490 in epoch 3, gen_loss = 1.2527300457483397, disc_loss = 0.05192773127283468
Trained batch 491 in epoch 3, gen_loss = 1.2528925919072416, disc_loss = 0.0518379665511789
Trained batch 492 in epoch 3, gen_loss = 1.2536219605688632, disc_loss = 0.05179187528596356
Trained batch 493 in epoch 3, gen_loss = 1.2542908358791096, disc_loss = 0.051717661401287085
Trained batch 494 in epoch 3, gen_loss = 1.253073005062161, disc_loss = 0.051872366806962576
Trained batch 495 in epoch 3, gen_loss = 1.2549832694592975, disc_loss = 0.05200916616294923
Trained batch 496 in epoch 3, gen_loss = 1.2558275289098981, disc_loss = 0.05196257581057353
Trained batch 497 in epoch 3, gen_loss = 1.2556300910720863, disc_loss = 0.05193470737964184
Trained batch 498 in epoch 3, gen_loss = 1.2560851928107963, disc_loss = 0.05184591226820985
Trained batch 499 in epoch 3, gen_loss = 1.2559709203839302, disc_loss = 0.05176573300268501
Trained batch 500 in epoch 3, gen_loss = 1.255973014586462, disc_loss = 0.051687824994347945
Trained batch 501 in epoch 3, gen_loss = 1.2557912381640468, disc_loss = 0.051620743626105296
Trained batch 502 in epoch 3, gen_loss = 1.2564571259865467, disc_loss = 0.051542040361480315
Trained batch 503 in epoch 3, gen_loss = 1.2561630418021528, disc_loss = 0.051480646386543025
Trained batch 504 in epoch 3, gen_loss = 1.2563539675556787, disc_loss = 0.05142275528834746
Trained batch 505 in epoch 3, gen_loss = 1.2552806050056526, disc_loss = 0.051559370173980656
Trained batch 506 in epoch 3, gen_loss = 1.2557246610375317, disc_loss = 0.05161010121368239
Trained batch 507 in epoch 3, gen_loss = 1.2559795039962596, disc_loss = 0.051521996963827865
Trained batch 508 in epoch 3, gen_loss = 1.2560793742800977, disc_loss = 0.05143724875030618
Trained batch 509 in epoch 3, gen_loss = 1.2552783045698614, disc_loss = 0.05147119548500461
Trained batch 510 in epoch 3, gen_loss = 1.2551107108592987, disc_loss = 0.05139221683501789
Trained batch 511 in epoch 3, gen_loss = 1.255428533826489, disc_loss = 0.05134930826352502
Trained batch 512 in epoch 3, gen_loss = 1.255674788419731, disc_loss = 0.05126623941865
Trained batch 513 in epoch 3, gen_loss = 1.2558871510543712, disc_loss = 0.05118202339089566
Trained batch 514 in epoch 3, gen_loss = 1.2555331885814667, disc_loss = 0.051129539951103406
Trained batch 515 in epoch 3, gen_loss = 1.2556392698902492, disc_loss = 0.05106734068948747
Trained batch 516 in epoch 3, gen_loss = 1.2549273733128892, disc_loss = 0.051062623269466874
Trained batch 517 in epoch 3, gen_loss = 1.2559546881776058, disc_loss = 0.051164042222597655
Trained batch 518 in epoch 3, gen_loss = 1.2555275671399397, disc_loss = 0.05111722789905779
Trained batch 519 in epoch 3, gen_loss = 1.2550849674412838, disc_loss = 0.05106289721667193
Trained batch 520 in epoch 3, gen_loss = 1.255605548277011, disc_loss = 0.050985542994757646
Trained batch 521 in epoch 3, gen_loss = 1.2565409943632695, disc_loss = 0.05096727839967243
Trained batch 522 in epoch 3, gen_loss = 1.2554334652241512, disc_loss = 0.05108751875684948
Trained batch 523 in epoch 3, gen_loss = 1.255297206910967, disc_loss = 0.051033560881561794
Trained batch 524 in epoch 3, gen_loss = 1.2558374717689695, disc_loss = 0.05104241456836462
Trained batch 525 in epoch 3, gen_loss = 1.2563530362490918, disc_loss = 0.050963534433536316
Trained batch 526 in epoch 3, gen_loss = 1.2567599708147248, disc_loss = 0.05090399090893411
Trained batch 527 in epoch 3, gen_loss = 1.2563526566620127, disc_loss = 0.050853285471076204
Trained batch 528 in epoch 3, gen_loss = 1.2555887769548564, disc_loss = 0.05096707608381776
Trained batch 529 in epoch 3, gen_loss = 1.2553639576682505, disc_loss = 0.05089578796529545
Trained batch 530 in epoch 3, gen_loss = 1.2551130310627028, disc_loss = 0.0509518444075086
Trained batch 531 in epoch 3, gen_loss = 1.2549696917036421, disc_loss = 0.05087200588987846
Trained batch 532 in epoch 3, gen_loss = 1.255024518181638, disc_loss = 0.050794965087822296
Trained batch 533 in epoch 3, gen_loss = 1.255382453067026, disc_loss = 0.050725923601733273
Trained batch 534 in epoch 3, gen_loss = 1.2557641981361067, disc_loss = 0.050653779198563544
Trained batch 535 in epoch 3, gen_loss = 1.2555490648234957, disc_loss = 0.050590296840614904
Trained batch 536 in epoch 3, gen_loss = 1.2559217696860294, disc_loss = 0.05050804649498765
Trained batch 537 in epoch 3, gen_loss = 1.2558053107620615, disc_loss = 0.05045665012928744
Trained batch 538 in epoch 3, gen_loss = 1.2559637088390803, disc_loss = 0.05037692123384721
Trained batch 539 in epoch 3, gen_loss = 1.255565715112068, disc_loss = 0.05041936742728231
Trained batch 540 in epoch 3, gen_loss = 1.2554193651940597, disc_loss = 0.05034967960338771
Trained batch 541 in epoch 3, gen_loss = 1.2555975751793254, disc_loss = 0.050284472529559886
Trained batch 542 in epoch 3, gen_loss = 1.256173776713085, disc_loss = 0.05021480239866023
Trained batch 543 in epoch 3, gen_loss = 1.2568729551070754, disc_loss = 0.05014580970130149
Trained batch 544 in epoch 3, gen_loss = 1.257514256785769, disc_loss = 0.050078888227223256
Trained batch 545 in epoch 3, gen_loss = 1.256364345277622, disc_loss = 0.05028471176345379
Trained batch 546 in epoch 3, gen_loss = 1.2575771455028157, disc_loss = 0.05026318834689352
Trained batch 547 in epoch 3, gen_loss = 1.2565799196162364, disc_loss = 0.050349457043284265
Trained batch 548 in epoch 3, gen_loss = 1.256619258602243, disc_loss = 0.050289058867835176
Trained batch 549 in epoch 3, gen_loss = 1.2565698763999071, disc_loss = 0.05025552535937591
Trained batch 550 in epoch 3, gen_loss = 1.2564381308542623, disc_loss = 0.05021922440418531
Trained batch 551 in epoch 3, gen_loss = 1.2566711610534054, disc_loss = 0.05013679689559006
Trained batch 552 in epoch 3, gen_loss = 1.2564164727225657, disc_loss = 0.050101102498203355
Trained batch 553 in epoch 3, gen_loss = 1.2567546754429917, disc_loss = 0.05002038635898529
Trained batch 554 in epoch 3, gen_loss = 1.256758358403369, disc_loss = 0.04994739208974548
Trained batch 555 in epoch 3, gen_loss = 1.2565756926326443, disc_loss = 0.04988155011992178
Trained batch 556 in epoch 3, gen_loss = 1.2563237972169632, disc_loss = 0.04983361141130836
Trained batch 557 in epoch 3, gen_loss = 1.2569653372076677, disc_loss = 0.0497887846312776
Trained batch 558 in epoch 3, gen_loss = 1.2567823836863148, disc_loss = 0.04976045554387175
Trained batch 559 in epoch 3, gen_loss = 1.2561557215771504, disc_loss = 0.04974250031269289
Trained batch 560 in epoch 3, gen_loss = 1.2566126068114385, disc_loss = 0.04967465048652547
Trained batch 561 in epoch 3, gen_loss = 1.2563843088111843, disc_loss = 0.04967303201721922
Trained batch 562 in epoch 3, gen_loss = 1.2554741339298168, disc_loss = 0.049790904271626454
Trained batch 563 in epoch 3, gen_loss = 1.2559000354603673, disc_loss = 0.049812620725310966
Trained batch 564 in epoch 3, gen_loss = 1.256913390993017, disc_loss = 0.049766400626209455
Trained batch 565 in epoch 3, gen_loss = 1.2560041037654708, disc_loss = 0.049960626504801924
Trained batch 566 in epoch 3, gen_loss = 1.2553633868273815, disc_loss = 0.049973055331046304
Trained batch 567 in epoch 3, gen_loss = 1.2566286344868196, disc_loss = 0.05001298982722186
Trained batch 568 in epoch 3, gen_loss = 1.2565744765927795, disc_loss = 0.05001463463958778
Trained batch 569 in epoch 3, gen_loss = 1.2560902724663416, disc_loss = 0.05000164234814675
Trained batch 570 in epoch 3, gen_loss = 1.2553606439910294, disc_loss = 0.05004829251013318
Trained batch 571 in epoch 3, gen_loss = 1.2556622286255543, disc_loss = 0.04998101455556763
Trained batch 572 in epoch 3, gen_loss = 1.2562305537713967, disc_loss = 0.050094678945982435
Trained batch 573 in epoch 3, gen_loss = 1.2551571593363526, disc_loss = 0.050284798370628825
Trained batch 574 in epoch 3, gen_loss = 1.2555584681034089, disc_loss = 0.05032729838205421
Trained batch 575 in epoch 3, gen_loss = 1.2569856736291614, disc_loss = 0.050363654658819236
Trained batch 576 in epoch 3, gen_loss = 1.257228233320461, disc_loss = 0.05032821410889229
Trained batch 577 in epoch 3, gen_loss = 1.256709672742649, disc_loss = 0.05035419624853093
Trained batch 578 in epoch 3, gen_loss = 1.2571329643792233, disc_loss = 0.05028474745734728
Trained batch 579 in epoch 3, gen_loss = 1.2571273182486666, disc_loss = 0.05026653110178123
Trained batch 580 in epoch 3, gen_loss = 1.2563809588833643, disc_loss = 0.05033093142497919
Trained batch 581 in epoch 3, gen_loss = 1.2559971384883337, disc_loss = 0.050359992616045006
Trained batch 582 in epoch 3, gen_loss = 1.2553238608518145, disc_loss = 0.05041258489971862
Trained batch 583 in epoch 3, gen_loss = 1.2558343532456928, disc_loss = 0.050373262497724024
Trained batch 584 in epoch 3, gen_loss = 1.255792177385754, disc_loss = 0.050310340878736766
Trained batch 585 in epoch 3, gen_loss = 1.2565499244594738, disc_loss = 0.05025170995049662
Trained batch 586 in epoch 3, gen_loss = 1.2563141429546136, disc_loss = 0.05021278366440149
Trained batch 587 in epoch 3, gen_loss = 1.2563854380428385, disc_loss = 0.05023742486646741
Trained batch 588 in epoch 3, gen_loss = 1.255597450889027, disc_loss = 0.05026769703048549
Trained batch 589 in epoch 3, gen_loss = 1.2549426671306965, disc_loss = 0.050302005917528425
Trained batch 590 in epoch 3, gen_loss = 1.2555702477441424, disc_loss = 0.05056583812513882
Trained batch 591 in epoch 3, gen_loss = 1.2555775536173903, disc_loss = 0.050520203571854716
Trained batch 592 in epoch 3, gen_loss = 1.2555960670591004, disc_loss = 0.05047985376604844
Trained batch 593 in epoch 3, gen_loss = 1.255000108470419, disc_loss = 0.05048272039220741
Trained batch 594 in epoch 3, gen_loss = 1.2553685188794337, disc_loss = 0.05042136044343229
Trained batch 595 in epoch 3, gen_loss = 1.2552919504326463, disc_loss = 0.05036763436373498
Trained batch 596 in epoch 3, gen_loss = 1.2548313291128756, disc_loss = 0.05035048714640802
Trained batch 597 in epoch 3, gen_loss = 1.2552707682186146, disc_loss = 0.05031370126290315
Trained batch 598 in epoch 3, gen_loss = 1.2558003984926538, disc_loss = 0.05055229946852775
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.6025981307029724, disc_loss = 0.17043240368366241
Trained batch 1 in epoch 4, gen_loss = 1.009977251291275, disc_loss = 0.18642564862966537
Trained batch 2 in epoch 4, gen_loss = 0.9193421006202698, disc_loss = 0.18844348192214966
Trained batch 3 in epoch 4, gen_loss = 0.9528960734605789, disc_loss = 0.2046261951327324
Trained batch 4 in epoch 4, gen_loss = 1.0420033097267152, disc_loss = 0.26297077536582947
Trained batch 5 in epoch 4, gen_loss = 1.1746988395849864, disc_loss = 0.36632563173770905
Trained batch 6 in epoch 4, gen_loss = 1.3779751999037606, disc_loss = 0.6584508887359074
Trained batch 7 in epoch 4, gen_loss = 1.489536114037037, disc_loss = 0.764031108468771
Trained batch 8 in epoch 4, gen_loss = 1.461781018310123, disc_loss = 0.7645201517475976
Trained batch 9 in epoch 4, gen_loss = 1.3743314802646638, disc_loss = 0.7160874038934708
Trained batch 10 in epoch 4, gen_loss = 1.3132736953822048, disc_loss = 0.6763864945281636
Trained batch 11 in epoch 4, gen_loss = 1.2641653269529343, disc_loss = 0.6393332084019979
Trained batch 12 in epoch 4, gen_loss = 1.2329488671742952, disc_loss = 0.6067643956496165
Trained batch 13 in epoch 4, gen_loss = 1.2019759033407484, disc_loss = 0.576722515480859
Trained batch 14 in epoch 4, gen_loss = 1.17246009906133, disc_loss = 0.5493730922540029
Trained batch 15 in epoch 4, gen_loss = 1.145946215838194, disc_loss = 0.5242856508120894
Trained batch 16 in epoch 4, gen_loss = 1.118010419256547, disc_loss = 0.5038285421974519
Trained batch 17 in epoch 4, gen_loss = 1.1101687848567963, disc_loss = 0.4864537641406059
Trained batch 18 in epoch 4, gen_loss = 1.0877124227975543, disc_loss = 0.472609785042311
Trained batch 19 in epoch 4, gen_loss = 1.0765364676713944, disc_loss = 0.4552712619304657
Trained batch 20 in epoch 4, gen_loss = 1.0594892785662697, disc_loss = 0.4399668418225788
Trained batch 21 in epoch 4, gen_loss = 1.0553640533577313, disc_loss = 0.42356151748787274
Trained batch 22 in epoch 4, gen_loss = 1.0494776212650796, disc_loss = 0.4087277475906455
Trained batch 23 in epoch 4, gen_loss = 1.0364429131150246, disc_loss = 0.3966828187306722
Trained batch 24 in epoch 4, gen_loss = 1.0424729132652282, disc_loss = 0.394677129983902
Trained batch 25 in epoch 4, gen_loss = 1.030397424331078, disc_loss = 0.3846381295185823
Trained batch 26 in epoch 4, gen_loss = 1.01883805681158, disc_loss = 0.3748246812158161
Trained batch 27 in epoch 4, gen_loss = 1.0129355128322328, disc_loss = 0.3664827522422586
Trained batch 28 in epoch 4, gen_loss = 1.0176220330698738, disc_loss = 0.35599785041192483
Trained batch 29 in epoch 4, gen_loss = 1.008157612880071, disc_loss = 0.3473491159578164
Trained batch 30 in epoch 4, gen_loss = 1.0115970161653334, disc_loss = 0.34013984400418495
Trained batch 31 in epoch 4, gen_loss = 1.0009929239749908, disc_loss = 0.33317848667502403
Trained batch 32 in epoch 4, gen_loss = 1.0051564592303652, disc_loss = 0.3243892908547864
Trained batch 33 in epoch 4, gen_loss = 1.0019417633028591, disc_loss = 0.31690197854357605
Trained batch 34 in epoch 4, gen_loss = 0.9991834759712219, disc_loss = 0.3096350718821798
Trained batch 35 in epoch 4, gen_loss = 0.997474279668596, disc_loss = 0.3030625209212303
Trained batch 36 in epoch 4, gen_loss = 1.0004517516574345, disc_loss = 0.297165432693185
Trained batch 37 in epoch 4, gen_loss = 0.9963283695672688, disc_loss = 0.2910464353075153
Trained batch 38 in epoch 4, gen_loss = 0.9982429192616389, disc_loss = 0.28499975953346646
Trained batch 39 in epoch 4, gen_loss = 1.0018516063690186, disc_loss = 0.27864612988196313
Trained batch 40 in epoch 4, gen_loss = 1.0044393568504146, disc_loss = 0.2731828032197749
Trained batch 41 in epoch 4, gen_loss = 1.0026053899810428, disc_loss = 0.26794548940268303
Trained batch 42 in epoch 4, gen_loss = 1.004213535508444, disc_loss = 0.2628517861716276
Trained batch 43 in epoch 4, gen_loss = 1.0075339376926422, disc_loss = 0.25874819085848605
Trained batch 44 in epoch 4, gen_loss = 1.003620179494222, disc_loss = 0.25568138133320545
Trained batch 45 in epoch 4, gen_loss = 1.001349979120752, disc_loss = 0.25304015729900287
Trained batch 46 in epoch 4, gen_loss = 0.9996079117693799, disc_loss = 0.24927620815628387
Trained batch 47 in epoch 4, gen_loss = 0.9928534080584844, disc_loss = 0.24679655523505062
Trained batch 48 in epoch 4, gen_loss = 0.9981045893260411, disc_loss = 0.24658260665529844
Trained batch 49 in epoch 4, gen_loss = 0.9910834729671478, disc_loss = 0.24459136757999658
Trained batch 50 in epoch 4, gen_loss = 0.9971796729985405, disc_loss = 0.2437981335336671
Trained batch 51 in epoch 4, gen_loss = 0.9915727090377074, disc_loss = 0.24139857109492788
Trained batch 52 in epoch 4, gen_loss = 0.9851520635047049, disc_loss = 0.23942919346099756
Trained batch 53 in epoch 4, gen_loss = 0.9835199018319448, disc_loss = 0.2407707761352261
Trained batch 54 in epoch 4, gen_loss = 0.9808321811936118, disc_loss = 0.238611288131638
Trained batch 55 in epoch 4, gen_loss = 0.9790644528610366, disc_loss = 0.2369647985656879
Trained batch 56 in epoch 4, gen_loss = 0.9706445555937918, disc_loss = 0.2369130650175768
Trained batch 57 in epoch 4, gen_loss = 0.9701644757698322, disc_loss = 0.23526801005134296
Trained batch 58 in epoch 4, gen_loss = 0.9702749171499478, disc_loss = 0.23391322125443967
Trained batch 59 in epoch 4, gen_loss = 0.9655629495779673, disc_loss = 0.23152523329481484
Trained batch 60 in epoch 4, gen_loss = 0.9642095233573288, disc_loss = 0.22832802765559954
Trained batch 61 in epoch 4, gen_loss = 0.9590677388252751, disc_loss = 0.22727337236245793
Trained batch 62 in epoch 4, gen_loss = 0.9612144610238453, disc_loss = 0.22566998025609386
Trained batch 63 in epoch 4, gen_loss = 0.9606781387701631, disc_loss = 0.22333145068841986
Trained batch 64 in epoch 4, gen_loss = 0.9562761444311876, disc_loss = 0.2244283586453933
Trained batch 65 in epoch 4, gen_loss = 0.9525767935044838, disc_loss = 0.22351395381106573
Trained batch 66 in epoch 4, gen_loss = 0.9575592768726064, disc_loss = 0.2224715442966614
Trained batch 67 in epoch 4, gen_loss = 0.9515463087488624, disc_loss = 0.2220303407212829
Trained batch 68 in epoch 4, gen_loss = 0.9546006200970083, disc_loss = 0.22340983538415984
Trained batch 69 in epoch 4, gen_loss = 0.9533385115010398, disc_loss = 0.22188342402556113
Trained batch 70 in epoch 4, gen_loss = 0.9498654805438619, disc_loss = 0.22059318063859368
Trained batch 71 in epoch 4, gen_loss = 0.9491315715842776, disc_loss = 0.21823033356728652
Trained batch 72 in epoch 4, gen_loss = 0.9519800943871067, disc_loss = 0.21685091434174206
Trained batch 73 in epoch 4, gen_loss = 0.95348977398228, disc_loss = 0.21451125069949273
Trained batch 74 in epoch 4, gen_loss = 0.9518798160552978, disc_loss = 0.21255937116841475
Trained batch 75 in epoch 4, gen_loss = 0.953608828155618, disc_loss = 0.21052352444415814
Trained batch 76 in epoch 4, gen_loss = 0.9557915771162355, disc_loss = 0.20828971390116524
Trained batch 77 in epoch 4, gen_loss = 0.9570472622529055, disc_loss = 0.20604473020499334
Trained batch 78 in epoch 4, gen_loss = 0.9601622925528998, disc_loss = 0.20391601595225967
Trained batch 79 in epoch 4, gen_loss = 0.9604901865124702, disc_loss = 0.20393715172540397
Trained batch 80 in epoch 4, gen_loss = 0.956057338067043, disc_loss = 0.2030583083583617
Trained batch 81 in epoch 4, gen_loss = 0.9582689956920903, disc_loss = 0.20093086398229365
Trained batch 82 in epoch 4, gen_loss = 0.9578402387090477, disc_loss = 0.20029432658689567
Trained batch 83 in epoch 4, gen_loss = 0.9559388167801357, disc_loss = 0.19886535051323118
Trained batch 84 in epoch 4, gen_loss = 0.9563104699639713, disc_loss = 0.19683666858164703
Trained batch 85 in epoch 4, gen_loss = 0.9530089345089224, disc_loss = 0.19628070864479902
Trained batch 86 in epoch 4, gen_loss = 0.9586247630502985, disc_loss = 0.19520637202451283
Trained batch 87 in epoch 4, gen_loss = 0.9572553743015636, disc_loss = 0.19516598668203436
Trained batch 88 in epoch 4, gen_loss = 0.9573543453484439, disc_loss = 0.19352389727666808
Trained batch 89 in epoch 4, gen_loss = 0.9639080213175879, disc_loss = 0.19168026016818152
Trained batch 90 in epoch 4, gen_loss = 0.9633633048979791, disc_loss = 0.19034430679384168
Trained batch 91 in epoch 4, gen_loss = 0.9599938405596692, disc_loss = 0.18958403907068397
Trained batch 92 in epoch 4, gen_loss = 0.9635626282743228, disc_loss = 0.18838727978929395
Trained batch 93 in epoch 4, gen_loss = 0.959343155013754, disc_loss = 0.18884774860232434
Trained batch 94 in epoch 4, gen_loss = 0.96018448942586, disc_loss = 0.18708730124329265
Trained batch 95 in epoch 4, gen_loss = 0.9614546876400709, disc_loss = 0.18643350119236857
Trained batch 96 in epoch 4, gen_loss = 0.9644088419442324, disc_loss = 0.1850000136368668
Trained batch 97 in epoch 4, gen_loss = 0.962036387652767, disc_loss = 0.18419751429892317
Trained batch 99 in epoch 4, gen_loss = 0.9688253229856492, disc_loss = 0.1826129746809602
Trained batch 100 in epoch 4, gen_loss = 0.9691080746084156, disc_loss = 0.18158756996883024
Trained batch 101 in epoch 4, gen_loss = 0.9707728466566872, disc_loss = 0.18044413892807915
Trained batch 102 in epoch 4, gen_loss = 0.9715684959032003, disc_loss = 0.18084663561391598
Trained batch 103 in epoch 4, gen_loss = 0.9682736706275207, disc_loss = 0.18045829612618455
Trained batch 104 in epoch 4, gen_loss = 0.9689490568070185, disc_loss = 0.18139024210118113
Trained batch 105 in epoch 4, gen_loss = 0.9683656506943252, disc_loss = 0.18042695982698
Trained batch 106 in epoch 4, gen_loss = 0.9670108640305349, disc_loss = 0.17981285758525412
Trained batch 107 in epoch 4, gen_loss = 0.9665271319724895, disc_loss = 0.1794665502384305
Trained batch 108 in epoch 4, gen_loss = 0.9625446107409416, disc_loss = 0.1797893513164936
Trained batch 109 in epoch 4, gen_loss = 0.962453156709671, disc_loss = 0.17854913012547927
Trained batch 110 in epoch 4, gen_loss = 0.9646860387948182, disc_loss = 0.1784404422248806
Trained batch 111 in epoch 4, gen_loss = 0.9638654648193291, disc_loss = 0.1774123768721308
Trained batch 112 in epoch 4, gen_loss = 0.9689410898537762, disc_loss = 0.17728413760134604
Trained batch 113 in epoch 4, gen_loss = 0.9655835393228029, disc_loss = 0.17692159168552934
Trained batch 114 in epoch 4, gen_loss = 0.9660272406495136, disc_loss = 0.17570871205433555
Trained batch 115 in epoch 4, gen_loss = 0.970592655498406, disc_loss = 0.17454413125484153
Trained batch 116 in epoch 4, gen_loss = 0.9714364867943984, disc_loss = 0.1734037896634167
Trained batch 117 in epoch 4, gen_loss = 0.9736907022484278, disc_loss = 0.1720621141810286
Trained batch 118 in epoch 4, gen_loss = 0.9745529824946108, disc_loss = 0.17084203535268286
Trained batch 119 in epoch 4, gen_loss = 0.9757196769118309, disc_loss = 0.17057809097071489
Trained batch 120 in epoch 4, gen_loss = 0.9737535394912908, disc_loss = 0.16996414614610436
Trained batch 121 in epoch 4, gen_loss = 0.9756157676704594, disc_loss = 0.16883565204553916
Trained batch 122 in epoch 4, gen_loss = 0.971529824946954, disc_loss = 0.16973117999429624
Trained batch 123 in epoch 4, gen_loss = 0.9822451991419638, disc_loss = 0.17021528859772989
Trained batch 124 in epoch 4, gen_loss = 0.9851739253997803, disc_loss = 0.1690004133284092
Trained batch 125 in epoch 4, gen_loss = 0.9831894508429936, disc_loss = 0.16848670765166246
Trained batch 126 in epoch 4, gen_loss = 0.9862713668290086, disc_loss = 0.16752923365066372
Trained batch 127 in epoch 4, gen_loss = 0.9838774078525603, disc_loss = 0.16979028316563927
Trained batch 128 in epoch 4, gen_loss = 0.9811814529027125, disc_loss = 0.17010554737707442
Trained batch 129 in epoch 4, gen_loss = 0.9802272980029766, disc_loss = 0.17087604102606957
Trained batch 130 in epoch 4, gen_loss = 0.9779246772518595, disc_loss = 0.17231070241741553
Trained batch 131 in epoch 4, gen_loss = 0.9739983641740048, disc_loss = 0.1734119260570768
Trained batch 132 in epoch 4, gen_loss = 0.9744325284671066, disc_loss = 0.1743253489354051
Trained batch 133 in epoch 4, gen_loss = 0.9709827650838824, disc_loss = 0.17525678870282066
Trained batch 134 in epoch 4, gen_loss = 0.9679431226518419, disc_loss = 0.17597651258111
Trained batch 135 in epoch 4, gen_loss = 0.9658923166639665, disc_loss = 0.1763812341617749
Trained batch 136 in epoch 4, gen_loss = 0.963473633258012, disc_loss = 0.17696134873876607
Trained batch 137 in epoch 4, gen_loss = 0.9614554647950159, disc_loss = 0.17705322723781716
Trained batch 138 in epoch 4, gen_loss = 0.9594333480587967, disc_loss = 0.1773388652439169
Trained batch 139 in epoch 4, gen_loss = 0.9585065352065223, disc_loss = 0.17762072222041234
Trained batch 140 in epoch 4, gen_loss = 0.9560001818000847, disc_loss = 0.17839090565734722
Trained batch 141 in epoch 4, gen_loss = 0.9542639776014946, disc_loss = 0.17866661627842506
Trained batch 142 in epoch 4, gen_loss = 0.953030759638006, disc_loss = 0.17864945246935723
Trained batch 143 in epoch 4, gen_loss = 0.9528078035347991, disc_loss = 0.1786813569099953
Trained batch 144 in epoch 4, gen_loss = 0.9509094538359807, disc_loss = 0.17874520140989072
Trained batch 145 in epoch 4, gen_loss = 0.9509064632735841, disc_loss = 0.17854155403600164
Trained batch 146 in epoch 4, gen_loss = 0.9503785619119398, disc_loss = 0.1783678528352254
Trained batch 147 in epoch 4, gen_loss = 0.94805381910221, disc_loss = 0.17808739818330552
Trained batch 148 in epoch 4, gen_loss = 0.9476142905702527, disc_loss = 0.17787002554575868
Trained batch 149 in epoch 4, gen_loss = 0.9485162711143493, disc_loss = 0.1775003634641568
Trained batch 150 in epoch 4, gen_loss = 0.9470719351673758, disc_loss = 0.17692512187440665
Trained batch 151 in epoch 4, gen_loss = 0.94635109603405, disc_loss = 0.17815968994737455
Trained batch 152 in epoch 4, gen_loss = 0.9457508878770218, disc_loss = 0.17748699792557293
Trained batch 153 in epoch 4, gen_loss = 0.9434306199674483, disc_loss = 0.177412908790367
Trained batch 154 in epoch 4, gen_loss = 0.9462022423744202, disc_loss = 0.17684552215280072
Trained batch 155 in epoch 4, gen_loss = 0.9489219047320194, disc_loss = 0.17631425691816288
Trained batch 156 in epoch 4, gen_loss = 0.9493229415765994, disc_loss = 0.17542919113188032
Trained batch 157 in epoch 4, gen_loss = 0.948778120777275, disc_loss = 0.17467338822876352
Trained batch 158 in epoch 4, gen_loss = 0.949306568259713, disc_loss = 0.17379552882703594
Trained batch 159 in epoch 4, gen_loss = 0.9494305361062289, disc_loss = 0.17314066260587424
Trained batch 160 in epoch 4, gen_loss = 0.9468102851269408, disc_loss = 0.17371879552739747
Trained batch 161 in epoch 4, gen_loss = 0.9510408570001154, disc_loss = 0.17317911184588333
Trained batch 162 in epoch 4, gen_loss = 0.9497425468421421, disc_loss = 0.17321215005465812
Trained batch 163 in epoch 4, gen_loss = 0.9504915766599702, disc_loss = 0.17233897834198503
Trained batch 164 in epoch 4, gen_loss = 0.9538588892329823, disc_loss = 0.1716342070563273
Trained batch 165 in epoch 4, gen_loss = 0.95298635241497, disc_loss = 0.1710190047925136
Trained batch 166 in epoch 4, gen_loss = 0.9511289403824035, disc_loss = 0.17086377581525705
Trained batch 167 in epoch 4, gen_loss = 0.9519996678545362, disc_loss = 0.17047798711185655
Trained batch 168 in epoch 4, gen_loss = 0.9500161663315, disc_loss = 0.17049908944400105
Trained batch 169 in epoch 4, gen_loss = 0.9539831799619338, disc_loss = 0.16995562071747639
Trained batch 170 in epoch 4, gen_loss = 0.9562470271573429, disc_loss = 0.16912273948260567
Trained batch 171 in epoch 4, gen_loss = 0.9583824588808902, disc_loss = 0.16820328169350707
Trained batch 172 in epoch 4, gen_loss = 0.9583484265156564, disc_loss = 0.16743632072227538
Trained batch 173 in epoch 4, gen_loss = 0.9579782917581755, disc_loss = 0.16675635324469928
Trained batch 174 in epoch 4, gen_loss = 0.9625712156295776, disc_loss = 0.16636792642729623
Trained batch 175 in epoch 4, gen_loss = 0.9611189243468371, disc_loss = 0.1659968596121127
Trained batch 176 in epoch 4, gen_loss = 0.9637857156958284, disc_loss = 0.16523548903859267
Trained batch 177 in epoch 4, gen_loss = 0.9642386208759265, disc_loss = 0.16445974336958
Trained batch 178 in epoch 4, gen_loss = 0.9641325936637111, disc_loss = 0.16381845008269702
Trained batch 179 in epoch 4, gen_loss = 0.9656287507878409, disc_loss = 0.16318298703473474
Trained batch 180 in epoch 4, gen_loss = 0.9707503763351651, disc_loss = 0.16251537676139102
Trained batch 181 in epoch 4, gen_loss = 0.9733588214103992, disc_loss = 0.16178164731424588
Trained batch 182 in epoch 4, gen_loss = 0.9742690301983734, disc_loss = 0.16117066519507944
Trained batch 183 in epoch 4, gen_loss = 0.9727303618970125, disc_loss = 0.1611733532956113
Trained batch 184 in epoch 4, gen_loss = 0.9731870264620395, disc_loss = 0.1615499753404308
Trained batch 185 in epoch 4, gen_loss = 0.9723682115154881, disc_loss = 0.16119790229425635
Trained batch 186 in epoch 4, gen_loss = 0.9758887565072207, disc_loss = 0.16060441401712397
Trained batch 187 in epoch 4, gen_loss = 0.9758845789635435, disc_loss = 0.16009375100281645
Trained batch 188 in epoch 4, gen_loss = 0.9768351745353174, disc_loss = 0.15938272867253217
Trained batch 189 in epoch 4, gen_loss = 0.9761855125427246, disc_loss = 0.1589583366717163
Trained batch 190 in epoch 4, gen_loss = 0.9767780216576541, disc_loss = 0.1584151322265882
Trained batch 191 in epoch 4, gen_loss = 0.9803925591210524, disc_loss = 0.15809853698980683
Trained batch 192 in epoch 4, gen_loss = 0.9815058868783744, disc_loss = 0.15745688586886683
Trained batch 193 in epoch 4, gen_loss = 0.9824830656199112, disc_loss = 0.15675997958739393
Trained batch 194 in epoch 4, gen_loss = 0.9854099292021531, disc_loss = 0.15628261243303618
Trained batch 195 in epoch 4, gen_loss = 0.9877467496054513, disc_loss = 0.1556130328918902
Trained batch 196 in epoch 4, gen_loss = 0.9897628344860173, disc_loss = 0.15491646588756347
Trained batch 197 in epoch 4, gen_loss = 0.9939859256599889, disc_loss = 0.15423733550076835
Trained batch 198 in epoch 4, gen_loss = 0.9963812774150216, disc_loss = 0.15352069912244326
Trained batch 199 in epoch 4, gen_loss = 0.9963741570711135, disc_loss = 0.15293156053870915
Trained batch 200 in epoch 4, gen_loss = 0.9984080073845327, disc_loss = 0.1522580249911517
Trained batch 201 in epoch 4, gen_loss = 0.9996434951772785, disc_loss = 0.15169775598488822
Trained batch 202 in epoch 4, gen_loss = 1.0017477966881738, disc_loss = 0.1510250703271093
Trained batch 203 in epoch 4, gen_loss = 1.0025249713776159, disc_loss = 0.1503434631946113
Trained batch 204 in epoch 4, gen_loss = 1.0042015098943944, disc_loss = 0.1496657367205111
Trained batch 205 in epoch 4, gen_loss = 1.005093443162233, disc_loss = 0.14902335054069324
Trained batch 206 in epoch 4, gen_loss = 1.0076360529747561, disc_loss = 0.14835679728609785
Trained batch 207 in epoch 4, gen_loss = 1.0131276972018755, disc_loss = 0.14811999468544784
Trained batch 208 in epoch 4, gen_loss = 1.0130044989038312, disc_loss = 0.1477245225317099
Trained batch 209 in epoch 4, gen_loss = 1.0148453652858733, disc_loss = 0.14706352036002845
Trained batch 210 in epoch 4, gen_loss = 1.0180240985341547, disc_loss = 0.14663648854729264
Trained batch 211 in epoch 4, gen_loss = 1.0195651119047742, disc_loss = 0.14599279083206124
Trained batch 212 in epoch 4, gen_loss = 1.019817029646305, disc_loss = 0.14550733819009273
Trained batch 213 in epoch 4, gen_loss = 1.0212166874765236, disc_loss = 0.14491670647479385
Trained batch 214 in epoch 4, gen_loss = 1.0231645298558611, disc_loss = 0.14431242870470118
Trained batch 215 in epoch 4, gen_loss = 1.027399223987703, disc_loss = 0.14378633197069307
Trained batch 216 in epoch 4, gen_loss = 1.0299355574467215, disc_loss = 0.143160841414868
Trained batch 217 in epoch 4, gen_loss = 1.0307148736004437, disc_loss = 0.14257102329796606
Trained batch 218 in epoch 4, gen_loss = 1.0308147530033165, disc_loss = 0.1420292433895613
Trained batch 219 in epoch 4, gen_loss = 1.0314941024238413, disc_loss = 0.1414445970715447
Trained batch 220 in epoch 4, gen_loss = 1.0330328830766462, disc_loss = 0.14089444057164688
Trained batch 221 in epoch 4, gen_loss = 1.036181738516232, disc_loss = 0.14037400781101472
Trained batch 222 in epoch 4, gen_loss = 1.0355594486933652, disc_loss = 0.13999131729517283
Trained batch 223 in epoch 4, gen_loss = 1.0376637846763646, disc_loss = 0.13952532761530684
Trained batch 224 in epoch 4, gen_loss = 1.0378913860850865, disc_loss = 0.1390385398765405
Trained batch 225 in epoch 4, gen_loss = 1.0392890406393371, disc_loss = 0.1384477892404307
Trained batch 226 in epoch 4, gen_loss = 1.0409525372908504, disc_loss = 0.13789472061451444
Trained batch 227 in epoch 4, gen_loss = 1.0432434121244831, disc_loss = 0.13733670115879362
Trained batch 228 in epoch 4, gen_loss = 1.0427869206953257, disc_loss = 0.13693603902941318
Trained batch 229 in epoch 4, gen_loss = 1.0443164838396986, disc_loss = 0.13646277607540075
Trained batch 230 in epoch 4, gen_loss = 1.0456734516403892, disc_loss = 0.13591651653959638
Trained batch 231 in epoch 4, gen_loss = 1.0488736698853558, disc_loss = 0.13540458616575804
Trained batch 232 in epoch 4, gen_loss = 1.048628970021342, disc_loss = 0.13504293046156224
Trained batch 233 in epoch 4, gen_loss = 1.048958138268218, disc_loss = 0.134512024334608
Trained batch 234 in epoch 4, gen_loss = 1.0512490280131077, disc_loss = 0.13411842388041476
Trained batch 235 in epoch 4, gen_loss = 1.052625208840532, disc_loss = 0.13358641295867452
Trained batch 236 in epoch 4, gen_loss = 1.0516745566315793, disc_loss = 0.13338818064721827
Trained batch 237 in epoch 4, gen_loss = 1.0513542504871594, disc_loss = 0.13521704515990088
Trained batch 238 in epoch 4, gen_loss = 1.0514405965805054, disc_loss = 0.13479104977896025
Trained batch 239 in epoch 4, gen_loss = 1.0504278679688772, disc_loss = 0.1345565492287278
Trained batch 240 in epoch 4, gen_loss = 1.0499742894251811, disc_loss = 0.13416206544551118
Trained batch 241 in epoch 4, gen_loss = 1.051427606462447, disc_loss = 0.13375164008091303
Trained batch 242 in epoch 4, gen_loss = 1.0542789601985318, disc_loss = 0.13334476326902708
Trained batch 243 in epoch 4, gen_loss = 1.0545444779220174, disc_loss = 0.13288412788180543
Trained batch 244 in epoch 4, gen_loss = 1.0538081993862074, disc_loss = 0.1326776442022956
Trained batch 245 in epoch 4, gen_loss = 1.0542519739488276, disc_loss = 0.13243788445928717
Trained batch 246 in epoch 4, gen_loss = 1.0553105212898872, disc_loss = 0.1319550969958426
Trained batch 247 in epoch 4, gen_loss = 1.0554547706438648, disc_loss = 0.13148648339894511
Trained batch 248 in epoch 4, gen_loss = 1.0543791735507397, disc_loss = 0.131253122655024
Trained batch 249 in epoch 4, gen_loss = 1.0547458453178407, disc_loss = 0.1311210286319256
Trained batch 250 in epoch 4, gen_loss = 1.0558839784675385, disc_loss = 0.13069237204661882
Trained batch 251 in epoch 4, gen_loss = 1.0577010398819333, disc_loss = 0.13028050938414204
Trained batch 252 in epoch 4, gen_loss = 1.0585650544863916, disc_loss = 0.12982627060706084
Trained batch 253 in epoch 4, gen_loss = 1.057109667090919, disc_loss = 0.12972730404411362
Trained batch 254 in epoch 4, gen_loss = 1.0572475395950616, disc_loss = 0.12930021490901708
Trained batch 255 in epoch 4, gen_loss = 1.0586614161729813, disc_loss = 0.12886551311748917
Trained batch 256 in epoch 4, gen_loss = 1.058481889476108, disc_loss = 0.12927173708243012
Trained batch 257 in epoch 4, gen_loss = 1.0583901442298593, disc_loss = 0.12897139107230907
Trained batch 258 in epoch 4, gen_loss = 1.0593538937881646, disc_loss = 0.12851093006482112
Trained batch 259 in epoch 4, gen_loss = 1.060704589348573, disc_loss = 0.12804564428515733
Trained batch 260 in epoch 4, gen_loss = 1.0615250502509632, disc_loss = 0.1275904415018314
Trained batch 261 in epoch 4, gen_loss = 1.0615267976549745, disc_loss = 0.1278917433459397
Trained batch 262 in epoch 4, gen_loss = 1.0619101157206545, disc_loss = 0.1274755998079031
Trained batch 263 in epoch 4, gen_loss = 1.06218496010159, disc_loss = 0.1270731708465257
Trained batch 264 in epoch 4, gen_loss = 1.062912812772787, disc_loss = 0.1267447336278153
Trained batch 265 in epoch 4, gen_loss = 1.0632984768179126, disc_loss = 0.12632740348143348
Trained batch 266 in epoch 4, gen_loss = 1.0646170248253068, disc_loss = 0.12703253465882514
Trained batch 267 in epoch 4, gen_loss = 1.0627491093838393, disc_loss = 0.12722122522223908
Trained batch 268 in epoch 4, gen_loss = 1.0619039360475362, disc_loss = 0.12704041439929084
Trained batch 269 in epoch 4, gen_loss = 1.062394733119894, disc_loss = 0.12673886606331777
Trained batch 270 in epoch 4, gen_loss = 1.0621873894740734, disc_loss = 0.1265386443935692
Trained batch 271 in epoch 4, gen_loss = 1.0610683632685858, disc_loss = 0.12652829333605684
Trained batch 272 in epoch 4, gen_loss = 1.0628056253269043, disc_loss = 0.12649936575933798
Trained batch 273 in epoch 4, gen_loss = 1.0620044132653814, disc_loss = 0.12640880257992523
Trained batch 274 in epoch 4, gen_loss = 1.0634972860596397, disc_loss = 0.12598644053055483
Trained batch 275 in epoch 4, gen_loss = 1.062685736063598, disc_loss = 0.12572476966644003
Trained batch 276 in epoch 4, gen_loss = 1.06275105583969, disc_loss = 0.12539405847432272
Trained batch 277 in epoch 4, gen_loss = 1.0628852280352612, disc_loss = 0.12518781478175048
Trained batch 278 in epoch 4, gen_loss = 1.0618387625208892, disc_loss = 0.12512146722605472
Trained batch 279 in epoch 4, gen_loss = 1.0608741042869432, disc_loss = 0.12493327002905841
Trained batch 280 in epoch 4, gen_loss = 1.062006919621573, disc_loss = 0.12513490952882797
Trained batch 281 in epoch 4, gen_loss = 1.0617688575112227, disc_loss = 0.12498202241943977
Trained batch 282 in epoch 4, gen_loss = 1.0629441668625013, disc_loss = 0.12466953208755584
Trained batch 283 in epoch 4, gen_loss = 1.0621625002421125, disc_loss = 0.12444482290868084
Trained batch 284 in epoch 4, gen_loss = 1.0616840308172661, disc_loss = 0.12419156392611433
Trained batch 285 in epoch 4, gen_loss = 1.062360401753779, disc_loss = 0.12406233898396571
Trained batch 286 in epoch 4, gen_loss = 1.0625043559157474, disc_loss = 0.12370575662338879
Trained batch 287 in epoch 4, gen_loss = 1.0623568213648267, disc_loss = 0.12340925674329305
Trained batch 288 in epoch 4, gen_loss = 1.0620440145677348, disc_loss = 0.12310123027569798
Trained batch 289 in epoch 4, gen_loss = 1.0628897666931152, disc_loss = 0.12301894944353864
Trained batch 290 in epoch 4, gen_loss = 1.064001232078395, disc_loss = 0.12280948566676107
Trained batch 291 in epoch 4, gen_loss = 1.0631748094950637, disc_loss = 0.1226833478439191
Trained batch 292 in epoch 4, gen_loss = 1.0634214300344422, disc_loss = 0.12235666231376217
Trained batch 293 in epoch 4, gen_loss = 1.067704641900095, disc_loss = 0.12325298811188665
Trained batch 294 in epoch 4, gen_loss = 1.0679405943822053, disc_loss = 0.12292968249106306
Trained batch 295 in epoch 4, gen_loss = 1.0662983184730686, disc_loss = 0.12307126077231825
Trained batch 296 in epoch 4, gen_loss = 1.0668919989556978, disc_loss = 0.12269708054823807
Trained batch 297 in epoch 4, gen_loss = 1.0666765678648982, disc_loss = 0.12251538132948664
Trained batch 298 in epoch 4, gen_loss = 1.0673499418341594, disc_loss = 0.12220492074110337
Trained batch 299 in epoch 4, gen_loss = 1.0699220494429271, disc_loss = 0.12203674273875853
Trained batch 300 in epoch 4, gen_loss = 1.0715985508060137, disc_loss = 0.12168491645050901
Trained batch 301 in epoch 4, gen_loss = 1.0709874878655996, disc_loss = 0.12144589856797397
Trained batch 302 in epoch 4, gen_loss = 1.0708752681713294, disc_loss = 0.12112984983035342
Trained batch 303 in epoch 4, gen_loss = 1.0706597241131883, disc_loss = 0.12103159892017414
Trained batch 304 in epoch 4, gen_loss = 1.0714980813323474, disc_loss = 0.12065714158911685
Trained batch 305 in epoch 4, gen_loss = 1.0711107016388888, disc_loss = 0.12038430106199158
Trained batch 306 in epoch 4, gen_loss = 1.0712222194826952, disc_loss = 0.12014569140400386
Trained batch 307 in epoch 4, gen_loss = 1.0747024134382026, disc_loss = 0.11997701295095121
Trained batch 308 in epoch 4, gen_loss = 1.0735805190882637, disc_loss = 0.11985257991007905
Trained batch 309 in epoch 4, gen_loss = 1.0728258996240554, disc_loss = 0.11965441376631779
Trained batch 310 in epoch 4, gen_loss = 1.0722430852448441, disc_loss = 0.11974051728593095
Trained batch 311 in epoch 4, gen_loss = 1.0728006343810985, disc_loss = 0.1195324869820466
Trained batch 312 in epoch 4, gen_loss = 1.0722969473360446, disc_loss = 0.11926432959318828
Trained batch 313 in epoch 4, gen_loss = 1.0735290654145988, disc_loss = 0.11892840578843644
Trained batch 314 in epoch 4, gen_loss = 1.072828385375795, disc_loss = 0.11883713893355831
Trained batch 315 in epoch 4, gen_loss = 1.0744685838116874, disc_loss = 0.11850721795772072
Trained batch 316 in epoch 4, gen_loss = 1.0758453233384935, disc_loss = 0.11820689417210287
Trained batch 317 in epoch 4, gen_loss = 1.0753838253096215, disc_loss = 0.11796012122488622
Trained batch 318 in epoch 4, gen_loss = 1.0747772572929957, disc_loss = 0.11782941757044449
Trained batch 319 in epoch 4, gen_loss = 1.077397412993014, disc_loss = 0.11763208967167885
Trained batch 320 in epoch 4, gen_loss = 1.0799794377196243, disc_loss = 0.1175470954718248
Trained batch 321 in epoch 4, gen_loss = 1.0788557733067814, disc_loss = 0.11745852090834831
Trained batch 322 in epoch 4, gen_loss = 1.0782733613123465, disc_loss = 0.11725916104512318
Trained batch 323 in epoch 4, gen_loss = 1.0779000629245499, disc_loss = 0.11698536926673518
Trained batch 324 in epoch 4, gen_loss = 1.078990405706259, disc_loss = 0.11675131075657331
Trained batch 325 in epoch 4, gen_loss = 1.0814065258561467, disc_loss = 0.11648676002775234
Trained batch 326 in epoch 4, gen_loss = 1.082814251428715, disc_loss = 0.11616765912223483
Trained batch 327 in epoch 4, gen_loss = 1.0825488431061185, disc_loss = 0.11590769851194103
Trained batch 328 in epoch 4, gen_loss = 1.0822523719996304, disc_loss = 0.11574004169859241
Trained batch 329 in epoch 4, gen_loss = 1.0819995312979727, disc_loss = 0.11547116598848141
Trained batch 330 in epoch 4, gen_loss = 1.0845068729175902, disc_loss = 0.11547451621636164
Trained batch 331 in epoch 4, gen_loss = 1.0834628702646278, disc_loss = 0.11535422551075378
Trained batch 332 in epoch 4, gen_loss = 1.0834667378359728, disc_loss = 0.11508033468245386
Trained batch 333 in epoch 4, gen_loss = 1.083802633656713, disc_loss = 0.1147886043425627
Trained batch 334 in epoch 4, gen_loss = 1.0833134014215042, disc_loss = 0.11475780943214003
Trained batch 335 in epoch 4, gen_loss = 1.0850570159299033, disc_loss = 0.11449533852837271
Trained batch 336 in epoch 4, gen_loss = 1.0850189888866435, disc_loss = 0.11422731354279936
Trained batch 337 in epoch 4, gen_loss = 1.0851928090908118, disc_loss = 0.11430559673803974
Trained batch 338 in epoch 4, gen_loss = 1.0836288099092017, disc_loss = 0.11458907995625758
Trained batch 339 in epoch 4, gen_loss = 1.0838688001913184, disc_loss = 0.11435830644057954
Trained batch 340 in epoch 4, gen_loss = 1.085423327610989, disc_loss = 0.11426444905004368
Trained batch 341 in epoch 4, gen_loss = 1.0853047754332337, disc_loss = 0.11399812201767812
Trained batch 342 in epoch 4, gen_loss = 1.0845584224681466, disc_loss = 0.11386678007814176
Trained batch 343 in epoch 4, gen_loss = 1.0838809358172639, disc_loss = 0.11378065962885875
Trained batch 344 in epoch 4, gen_loss = 1.0864757114562436, disc_loss = 0.11364325080336868
Trained batch 345 in epoch 4, gen_loss = 1.0863543078734006, disc_loss = 0.11342610809090682
Trained batch 346 in epoch 4, gen_loss = 1.0878362743243017, disc_loss = 0.11320841504040816
Trained batch 347 in epoch 4, gen_loss = 1.086453605828614, disc_loss = 0.11333808832234521
Trained batch 348 in epoch 4, gen_loss = 1.0880684031114878, disc_loss = 0.11307646490014385
Trained batch 349 in epoch 4, gen_loss = 1.0893061213833946, disc_loss = 0.11277976009994745
Trained batch 350 in epoch 4, gen_loss = 1.090399547350033, disc_loss = 0.11251734130806224
Trained batch 351 in epoch 4, gen_loss = 1.091513336890123, disc_loss = 0.11223984921922568
Trained batch 352 in epoch 4, gen_loss = 1.0909130642501896, disc_loss = 0.11208943789956759
Trained batch 353 in epoch 4, gen_loss = 1.0926072683374761, disc_loss = 0.11215410086373656
Trained batch 354 in epoch 4, gen_loss = 1.092044648486124, disc_loss = 0.11200075581354994
Trained batch 355 in epoch 4, gen_loss = 1.0928551978274677, disc_loss = 0.1117285855501639
Trained batch 356 in epoch 4, gen_loss = 1.0923281849599351, disc_loss = 0.11151784316686188
Trained batch 357 in epoch 4, gen_loss = 1.0910998965774834, disc_loss = 0.11166867110670112
Trained batch 358 in epoch 4, gen_loss = 1.0920901374896588, disc_loss = 0.11159488459670278
Trained batch 359 in epoch 4, gen_loss = 1.092335052953826, disc_loss = 0.11138588961524268
Trained batch 360 in epoch 4, gen_loss = 1.0938630417773598, disc_loss = 0.11181550715995793
Trained batch 361 in epoch 4, gen_loss = 1.093188171228651, disc_loss = 0.11177277360728927
Trained batch 362 in epoch 4, gen_loss = 1.0927819734434123, disc_loss = 0.11157627869140839
Trained batch 363 in epoch 4, gen_loss = 1.092951612321885, disc_loss = 0.11133941714293681
Trained batch 364 in epoch 4, gen_loss = 1.0925431086592479, disc_loss = 0.1111789721434247
Trained batch 365 in epoch 4, gen_loss = 1.0925795222566428, disc_loss = 0.11107343643944446
Trained batch 366 in epoch 4, gen_loss = 1.0928544993296632, disc_loss = 0.11085868371036461
Trained batch 367 in epoch 4, gen_loss = 1.092963424227808, disc_loss = 0.11062277983064236
Trained batch 368 in epoch 4, gen_loss = 1.0923436607125652, disc_loss = 0.1104659204217315
Trained batch 369 in epoch 4, gen_loss = 1.0919514496584197, disc_loss = 0.11044351469624687
Trained batch 370 in epoch 4, gen_loss = 1.0926888768242375, disc_loss = 0.11034104767232893
Trained batch 371 in epoch 4, gen_loss = 1.0919322494858055, disc_loss = 0.11062545138060727
Trained batch 372 in epoch 4, gen_loss = 1.0902160558719738, disc_loss = 0.1109068975871274
Trained batch 373 in epoch 4, gen_loss = 1.0905003725366795, disc_loss = 0.11069053296936068
Trained batch 374 in epoch 4, gen_loss = 1.0907569283644358, disc_loss = 0.1107014787097772
Trained batch 375 in epoch 4, gen_loss = 1.089978380009849, disc_loss = 0.11063584468347278
Trained batch 376 in epoch 4, gen_loss = 1.0896004567253812, disc_loss = 0.11045962146209153
Trained batch 377 in epoch 4, gen_loss = 1.0919885145766395, disc_loss = 0.11048703007005825
Trained batch 378 in epoch 4, gen_loss = 1.0918264410269292, disc_loss = 0.11026731676527723
Trained batch 379 in epoch 4, gen_loss = 1.0908731974269215, disc_loss = 0.11029088958411624
Trained batch 380 in epoch 4, gen_loss = 1.0915479246243405, disc_loss = 0.11017252280428184
Trained batch 381 in epoch 4, gen_loss = 1.091171622822422, disc_loss = 0.11002579269472373
Trained batch 382 in epoch 4, gen_loss = 1.09216564061125, disc_loss = 0.10981396291473049
Trained batch 383 in epoch 4, gen_loss = 1.0927829707507044, disc_loss = 0.10956880552597188
Trained batch 384 in epoch 4, gen_loss = 1.0940695696836942, disc_loss = 0.11016287379353852
Trained batch 385 in epoch 4, gen_loss = 1.0928076915635965, disc_loss = 0.11043129164069274
Trained batch 386 in epoch 4, gen_loss = 1.093689879628731, disc_loss = 0.1102351546335667
Trained batch 387 in epoch 4, gen_loss = 1.0940515711596333, disc_loss = 0.11002254173082789
Trained batch 388 in epoch 4, gen_loss = 1.09318504411641, disc_loss = 0.10993620502381828
Trained batch 389 in epoch 4, gen_loss = 1.0940416995531475, disc_loss = 0.10970132903028758
Trained batch 390 in epoch 4, gen_loss = 1.093921735692207, disc_loss = 0.10958889349723411
Trained batch 391 in epoch 4, gen_loss = 1.0941583528658565, disc_loss = 0.10948954380060337
Trained batch 392 in epoch 4, gen_loss = 1.0943608862601466, disc_loss = 0.10924485600233533
Trained batch 393 in epoch 4, gen_loss = 1.0942738330757558, disc_loss = 0.1090593480547597
Trained batch 394 in epoch 4, gen_loss = 1.0950913965702056, disc_loss = 0.10888056147230576
Trained batch 395 in epoch 4, gen_loss = 1.094876636083078, disc_loss = 0.10872921518360575
Trained batch 396 in epoch 4, gen_loss = 1.0957148380633865, disc_loss = 0.10848343213527493
Trained batch 397 in epoch 4, gen_loss = 1.0974472427937254, disc_loss = 0.10829026324805527
Trained batch 398 in epoch 4, gen_loss = 1.09783561688318, disc_loss = 0.10805363119124695
Trained batch 399 in epoch 4, gen_loss = 1.0979210378974675, disc_loss = 0.10783082782989367
Trained batch 400 in epoch 4, gen_loss = 1.0988227140130544, disc_loss = 0.1075740766785853
Trained batch 401 in epoch 4, gen_loss = 1.0998578660968523, disc_loss = 0.1073377170792285
Trained batch 402 in epoch 4, gen_loss = 1.1011322502314898, disc_loss = 0.10717357616645119
Trained batch 403 in epoch 4, gen_loss = 1.1004848110646304, disc_loss = 0.10707729805081087
Trained batch 404 in epoch 4, gen_loss = 1.101776671041677, disc_loss = 0.10684140603414473
Trained batch 405 in epoch 4, gen_loss = 1.1025664297671154, disc_loss = 0.10659767943663807
Trained batch 406 in epoch 4, gen_loss = 1.1029592007764728, disc_loss = 0.10637711336222964
Trained batch 407 in epoch 4, gen_loss = 1.1041583324618198, disc_loss = 0.10614929712199442
Trained batch 408 in epoch 4, gen_loss = 1.104422392574091, disc_loss = 0.10594974430551192
Trained batch 409 in epoch 4, gen_loss = 1.1050924573729677, disc_loss = 0.10571489218145427
Trained batch 410 in epoch 4, gen_loss = 1.105656820129594, disc_loss = 0.1054839165076849
Trained batch 411 in epoch 4, gen_loss = 1.1059856688947354, disc_loss = 0.10525499577340172
Trained batch 412 in epoch 4, gen_loss = 1.1069043126435314, disc_loss = 0.10516890172776709
Trained batch 413 in epoch 4, gen_loss = 1.1064020623475457, disc_loss = 0.10511605963583334
Trained batch 414 in epoch 4, gen_loss = 1.1061595989279, disc_loss = 0.10495986403583224
Trained batch 415 in epoch 4, gen_loss = 1.1085601870973523, disc_loss = 0.10487969470537231
Trained batch 416 in epoch 4, gen_loss = 1.1098707188948167, disc_loss = 0.10470734411689768
Trained batch 417 in epoch 4, gen_loss = 1.1105192027736508, disc_loss = 0.10447884751728882
Trained batch 418 in epoch 4, gen_loss = 1.1112732398623784, disc_loss = 0.10425593036833733
Trained batch 419 in epoch 4, gen_loss = 1.111483759610426, disc_loss = 0.10421827951379653
Trained batch 420 in epoch 4, gen_loss = 1.1121032221725038, disc_loss = 0.1041187707416607
Trained batch 421 in epoch 4, gen_loss = 1.1108809323248705, disc_loss = 0.10425805223342119
Trained batch 422 in epoch 4, gen_loss = 1.1108375320620572, disc_loss = 0.10408488842141297
Trained batch 423 in epoch 4, gen_loss = 1.1105186781090386, disc_loss = 0.1039505100793662
Trained batch 424 in epoch 4, gen_loss = 1.1119099666791803, disc_loss = 0.10392303273629616
Trained batch 425 in epoch 4, gen_loss = 1.1122002547755487, disc_loss = 0.10370733371297414
Trained batch 426 in epoch 4, gen_loss = 1.111511776751601, disc_loss = 0.10368120969672288
Trained batch 427 in epoch 4, gen_loss = 1.1121479598021953, disc_loss = 0.10345492128796319
Trained batch 428 in epoch 4, gen_loss = 1.111736426750819, disc_loss = 0.1033191686791383
Trained batch 429 in epoch 4, gen_loss = 1.1135500993146452, disc_loss = 0.10323465980892611
Trained batch 430 in epoch 4, gen_loss = 1.1134774443583255, disc_loss = 0.10303664761282107
Trained batch 431 in epoch 4, gen_loss = 1.114125088064207, disc_loss = 0.10284175994780122
Trained batch 432 in epoch 4, gen_loss = 1.113906964625277, disc_loss = 0.1031673351887777
Trained batch 433 in epoch 4, gen_loss = 1.1132079958229022, disc_loss = 0.1031545920464884
Trained batch 434 in epoch 4, gen_loss = 1.1120842895973688, disc_loss = 0.10325253962314335
Trained batch 435 in epoch 4, gen_loss = 1.113411274046526, disc_loss = 0.1032906516109072
Trained batch 436 in epoch 4, gen_loss = 1.1133063811322916, disc_loss = 0.10312270221579607
Trained batch 437 in epoch 4, gen_loss = 1.114382503851908, disc_loss = 0.10297610228200822
Trained batch 438 in epoch 4, gen_loss = 1.1144653456221951, disc_loss = 0.10302987492989095
Trained batch 439 in epoch 4, gen_loss = 1.113721659576351, disc_loss = 0.10301605905194512
Trained batch 440 in epoch 4, gen_loss = 1.1129246419654681, disc_loss = 0.10318200085987918
Trained batch 441 in epoch 4, gen_loss = 1.1140834998625975, disc_loss = 0.10341357431538842
Trained batch 442 in epoch 4, gen_loss = 1.1130972793220666, disc_loss = 0.10351251084441593
Trained batch 443 in epoch 4, gen_loss = 1.1122705334344425, disc_loss = 0.10351620613060354
Trained batch 444 in epoch 4, gen_loss = 1.1114254342706016, disc_loss = 0.10350787735261609
Trained batch 445 in epoch 4, gen_loss = 1.11358164959157, disc_loss = 0.10410322331000671
Trained batch 446 in epoch 4, gen_loss = 1.113216005115701, disc_loss = 0.10398148397979654
Trained batch 447 in epoch 4, gen_loss = 1.1124833928022002, disc_loss = 0.10393103903334122
Trained batch 448 in epoch 4, gen_loss = 1.111351670626808, disc_loss = 0.10410836484399365
Trained batch 449 in epoch 4, gen_loss = 1.1123359617259767, disc_loss = 0.10419901102160414
Trained batch 450 in epoch 4, gen_loss = 1.1124285721858167, disc_loss = 0.10402053056652358
Trained batch 451 in epoch 4, gen_loss = 1.1125537732665518, disc_loss = 0.10386393556115836
Trained batch 452 in epoch 4, gen_loss = 1.1118553077543019, disc_loss = 0.10374967535756216
Trained batch 453 in epoch 4, gen_loss = 1.1119652133812463, disc_loss = 0.1035636514117572
Trained batch 454 in epoch 4, gen_loss = 1.1117239371105865, disc_loss = 0.10348186445637392
Trained batch 455 in epoch 4, gen_loss = 1.111808979785756, disc_loss = 0.10329541636083536
Trained batch 456 in epoch 4, gen_loss = 1.1118954866798492, disc_loss = 0.10312801376351968
Trained batch 457 in epoch 4, gen_loss = 1.1114199907889013, disc_loss = 0.10299423239580213
Trained batch 458 in epoch 4, gen_loss = 1.1117464524078993, disc_loss = 0.10294052075659592
Trained batch 459 in epoch 4, gen_loss = 1.112122197708358, disc_loss = 0.10275369208184597
Trained batch 460 in epoch 4, gen_loss = 1.1122968640994613, disc_loss = 0.10255411924054915
Trained batch 461 in epoch 4, gen_loss = 1.11175069683816, disc_loss = 0.10256664486182653
Trained batch 462 in epoch 4, gen_loss = 1.110905063010704, disc_loss = 0.10258448988673947
Trained batch 463 in epoch 4, gen_loss = 1.1130033563822508, disc_loss = 0.10251215497505498
Trained batch 464 in epoch 4, gen_loss = 1.113569764873033, disc_loss = 0.10236769045192388
Trained batch 465 in epoch 4, gen_loss = 1.1130953133745767, disc_loss = 0.10225598120566282
Trained batch 466 in epoch 4, gen_loss = 1.1124170827789022, disc_loss = 0.10242337546644362
Trained batch 467 in epoch 4, gen_loss = 1.1124906341871645, disc_loss = 0.10224007826465635
Trained batch 468 in epoch 4, gen_loss = 1.1132879247670489, disc_loss = 0.10209835448792812
Trained batch 469 in epoch 4, gen_loss = 1.1129584674505477, disc_loss = 0.10197475666893606
Trained batch 470 in epoch 4, gen_loss = 1.1134533570197485, disc_loss = 0.10177033698095321
Trained batch 471 in epoch 4, gen_loss = 1.1131977925740055, disc_loss = 0.10170453002131781
Trained batch 472 in epoch 4, gen_loss = 1.1123927110219354, disc_loss = 0.10168165656645442
Trained batch 473 in epoch 4, gen_loss = 1.1132650724317454, disc_loss = 0.10150488742080985
Trained batch 474 in epoch 4, gen_loss = 1.113544656540218, disc_loss = 0.10140969029578724
Trained batch 475 in epoch 4, gen_loss = 1.112868822610178, disc_loss = 0.10140449302701451
Trained batch 476 in epoch 4, gen_loss = 1.112427056148117, disc_loss = 0.10132414882951875
Trained batch 477 in epoch 4, gen_loss = 1.112743016005061, disc_loss = 0.10116856407459872
Trained batch 478 in epoch 4, gen_loss = 1.1140022386713166, disc_loss = 0.10180593628265228
Trained batch 479 in epoch 4, gen_loss = 1.113128837880989, disc_loss = 0.10191151129741532
Trained batch 480 in epoch 4, gen_loss = 1.1122851616503544, disc_loss = 0.10193944381058154
Trained batch 481 in epoch 4, gen_loss = 1.113036055226049, disc_loss = 0.10189347851179015
Trained batch 482 in epoch 4, gen_loss = 1.1131182745500134, disc_loss = 0.10182733418261844
Trained batch 483 in epoch 4, gen_loss = 1.1132561265806522, disc_loss = 0.10164886100163822
Trained batch 484 in epoch 4, gen_loss = 1.1127685563465983, disc_loss = 0.10184797149766045
Trained batch 485 in epoch 4, gen_loss = 1.11216812510304, disc_loss = 0.10180246353019105
Trained batch 486 in epoch 4, gen_loss = 1.111602643860439, disc_loss = 0.10177107494768114
Trained batch 487 in epoch 4, gen_loss = 1.1125865472999752, disc_loss = 0.10173989511591183
Trained batch 488 in epoch 4, gen_loss = 1.112315937602447, disc_loss = 0.10159657598265537
Trained batch 489 in epoch 4, gen_loss = 1.1142481731516973, disc_loss = 0.10149663965578894
Trained batch 490 in epoch 4, gen_loss = 1.1141607786268906, disc_loss = 0.10134222973593322
Trained batch 491 in epoch 4, gen_loss = 1.1139185298385659, disc_loss = 0.10120694479920213
Trained batch 492 in epoch 4, gen_loss = 1.1136683122260576, disc_loss = 0.1011316691474275
Trained batch 493 in epoch 4, gen_loss = 1.1153355861603007, disc_loss = 0.10126222348640021
Trained batch 494 in epoch 4, gen_loss = 1.1151984870433806, disc_loss = 0.10110812229151377
Trained batch 495 in epoch 4, gen_loss = 1.1141165966588644, disc_loss = 0.10124584133999663
Trained batch 496 in epoch 4, gen_loss = 1.115048061014421, disc_loss = 0.10127192218291388
Trained batch 497 in epoch 4, gen_loss = 1.115169796898183, disc_loss = 0.10110980640146806
Trained batch 498 in epoch 4, gen_loss = 1.1149780222910917, disc_loss = 0.10096045306329438
Trained batch 499 in epoch 4, gen_loss = 1.1150642052292823, disc_loss = 0.10081532005034387
Trained batch 500 in epoch 4, gen_loss = 1.1150909553387922, disc_loss = 0.10065159239358233
Trained batch 501 in epoch 4, gen_loss = 1.1144979494620129, disc_loss = 0.10062558087242018
Trained batch 502 in epoch 4, gen_loss = 1.115737798969978, disc_loss = 0.1004752807974608
Trained batch 503 in epoch 4, gen_loss = 1.1168124049547172, disc_loss = 0.10033868702815935
Trained batch 504 in epoch 4, gen_loss = 1.1172930413543587, disc_loss = 0.10015956682180709
Trained batch 505 in epoch 4, gen_loss = 1.1173404557078253, disc_loss = 0.10003077233828633
Trained batch 506 in epoch 4, gen_loss = 1.1175991109254562, disc_loss = 0.0999110393626597
Trained batch 507 in epoch 4, gen_loss = 1.1174836072513437, disc_loss = 0.09991857775589671
Trained batch 508 in epoch 4, gen_loss = 1.1171760017487764, disc_loss = 0.09980083607715391
Trained batch 509 in epoch 4, gen_loss = 1.1177793644806917, disc_loss = 0.09965501504530218
Trained batch 510 in epoch 4, gen_loss = 1.116637405059109, disc_loss = 0.09988289868273205
Trained batch 511 in epoch 4, gen_loss = 1.1177312442450784, disc_loss = 0.09979125969584857
Trained batch 512 in epoch 4, gen_loss = 1.1180381142256552, disc_loss = 0.09962313041112751
Trained batch 513 in epoch 4, gen_loss = 1.1171820483203063, disc_loss = 0.099700553855471
Trained batch 514 in epoch 4, gen_loss = 1.1176508227019635, disc_loss = 0.09975443755647222
Trained batch 515 in epoch 4, gen_loss = 1.1181526550835417, disc_loss = 0.09957911455895492
Trained batch 516 in epoch 4, gen_loss = 1.117384887006804, disc_loss = 0.09960759051208973
Trained batch 517 in epoch 4, gen_loss = 1.1183477200021155, disc_loss = 0.09956686847940317
Trained batch 518 in epoch 4, gen_loss = 1.1182923378397733, disc_loss = 0.099436566576376
Trained batch 519 in epoch 4, gen_loss = 1.1195542525213498, disc_loss = 0.0992825090365771
Trained batch 520 in epoch 4, gen_loss = 1.1207434036795787, disc_loss = 0.09937891178726864
Trained batch 521 in epoch 4, gen_loss = 1.12000800064012, disc_loss = 0.09939825321258657
Trained batch 522 in epoch 4, gen_loss = 1.1195767216996984, disc_loss = 0.09931969046272181
Trained batch 523 in epoch 4, gen_loss = 1.1190350874120953, disc_loss = 0.0992553957741537
Trained batch 524 in epoch 4, gen_loss = 1.1198585230395908, disc_loss = 0.09914627894581783
Trained batch 525 in epoch 4, gen_loss = 1.1199941913324618, disc_loss = 0.0990707859478381
Trained batch 526 in epoch 4, gen_loss = 1.120104484528699, disc_loss = 0.09892996666207203
Trained batch 527 in epoch 4, gen_loss = 1.119507100489555, disc_loss = 0.0988886764989178
Trained batch 528 in epoch 4, gen_loss = 1.1198989920782907, disc_loss = 0.098730205949079
Trained batch 529 in epoch 4, gen_loss = 1.1205981726354024, disc_loss = 0.09858209883161592
Trained batch 530 in epoch 4, gen_loss = 1.1211521490257788, disc_loss = 0.0984384123106152
Trained batch 531 in epoch 4, gen_loss = 1.1218257653421926, disc_loss = 0.09826816740459797
Trained batch 532 in epoch 4, gen_loss = 1.1221537410541949, disc_loss = 0.09813371969746884
Trained batch 533 in epoch 4, gen_loss = 1.1222135562463647, disc_loss = 0.09798814760423387
Trained batch 534 in epoch 4, gen_loss = 1.1222979266509832, disc_loss = 0.09789584548708713
Trained batch 535 in epoch 4, gen_loss = 1.12287739781079, disc_loss = 0.09773025455286921
Trained batch 536 in epoch 4, gen_loss = 1.123129441251968, disc_loss = 0.09758976661015711
Trained batch 537 in epoch 4, gen_loss = 1.1238447159085576, disc_loss = 0.0974364318922993
Trained batch 538 in epoch 4, gen_loss = 1.1245612478322575, disc_loss = 0.0972790782044405
Trained batch 539 in epoch 4, gen_loss = 1.12390569884468, disc_loss = 0.09724201087805408
Trained batch 540 in epoch 4, gen_loss = 1.1248964081740422, disc_loss = 0.097089219714434
Trained batch 541 in epoch 4, gen_loss = 1.1260361512538692, disc_loss = 0.09693606547337727
Trained batch 542 in epoch 4, gen_loss = 1.1270417578202805, disc_loss = 0.09681557432763814
Trained batch 543 in epoch 4, gen_loss = 1.1271008728072047, disc_loss = 0.09669257897322121
Trained batch 544 in epoch 4, gen_loss = 1.1272879849333282, disc_loss = 0.09653825210834588
Trained batch 545 in epoch 4, gen_loss = 1.1280469588198505, disc_loss = 0.09638852777894273
Trained batch 546 in epoch 4, gen_loss = 1.1287879132592482, disc_loss = 0.09625586352806531
Trained batch 547 in epoch 4, gen_loss = 1.1290135618000134, disc_loss = 0.09610695950686932
Trained batch 548 in epoch 4, gen_loss = 1.1297572529272522, disc_loss = 0.09622122576707916
Trained batch 549 in epoch 4, gen_loss = 1.1292547594959086, disc_loss = 0.09618178295818242
Trained batch 550 in epoch 4, gen_loss = 1.1291197060781468, disc_loss = 0.0960941019513646
Trained batch 551 in epoch 4, gen_loss = 1.1301473632346892, disc_loss = 0.09595353230226623
Trained batch 552 in epoch 4, gen_loss = 1.1302015883258627, disc_loss = 0.09583677010944157
Trained batch 553 in epoch 4, gen_loss = 1.1310888477718788, disc_loss = 0.09569253470910047
Trained batch 554 in epoch 4, gen_loss = 1.1314345334564244, disc_loss = 0.09554152298752253
Trained batch 555 in epoch 4, gen_loss = 1.1311540490538954, disc_loss = 0.09544281733872222
Trained batch 556 in epoch 4, gen_loss = 1.1315469810842826, disc_loss = 0.09528418061285007
Trained batch 557 in epoch 4, gen_loss = 1.1324522961531915, disc_loss = 0.09516352624799322
Trained batch 558 in epoch 4, gen_loss = 1.1333492651501793, disc_loss = 0.09502940081902955
Trained batch 559 in epoch 4, gen_loss = 1.1331452476658992, disc_loss = 0.0949129439832177
Trained batch 560 in epoch 4, gen_loss = 1.1338892293805107, disc_loss = 0.09475852801662052
Trained batch 561 in epoch 4, gen_loss = 1.1340304384558226, disc_loss = 0.09461248542672666
Trained batch 562 in epoch 4, gen_loss = 1.1347567493602184, disc_loss = 0.09446808545507795
Trained batch 563 in epoch 4, gen_loss = 1.1354603901082743, disc_loss = 0.09432178464179845
Trained batch 564 in epoch 4, gen_loss = 1.1357176928921084, disc_loss = 0.09418140711691396
Trained batch 565 in epoch 4, gen_loss = 1.1357490543025963, disc_loss = 0.09405896202134555
Trained batch 566 in epoch 4, gen_loss = 1.1356747153049214, disc_loss = 0.09393556869623286
Trained batch 567 in epoch 4, gen_loss = 1.1367917691003269, disc_loss = 0.0938275565129285
Trained batch 568 in epoch 4, gen_loss = 1.1372879733624484, disc_loss = 0.09367672294158953
Trained batch 569 in epoch 4, gen_loss = 1.136232177782477, disc_loss = 0.09395627467402894
Trained batch 570 in epoch 4, gen_loss = 1.1361610185348423, disc_loss = 0.09393144388896807
Trained batch 571 in epoch 4, gen_loss = 1.1367970431497048, disc_loss = 0.09378610021952488
Trained batch 572 in epoch 4, gen_loss = 1.1362624058652715, disc_loss = 0.09377344061310093
Trained batch 573 in epoch 4, gen_loss = 1.1362944846057725, disc_loss = 0.09363234081493775
Trained batch 574 in epoch 4, gen_loss = 1.1366787670487943, disc_loss = 0.09349215485236567
Trained batch 575 in epoch 4, gen_loss = 1.1372224467599557, disc_loss = 0.09351031903659329
Trained batch 576 in epoch 4, gen_loss = 1.1370345131466666, disc_loss = 0.09341689576015548
Trained batch 577 in epoch 4, gen_loss = 1.1365213231747537, disc_loss = 0.09335230226841172
Trained batch 578 in epoch 4, gen_loss = 1.1369305771352507, disc_loss = 0.09321068869324622
Trained batch 579 in epoch 4, gen_loss = 1.1381833677147997, disc_loss = 0.09329507665564145
Trained batch 580 in epoch 4, gen_loss = 1.1378618355154375, disc_loss = 0.09319418354485691
Trained batch 581 in epoch 4, gen_loss = 1.1371154162994366, disc_loss = 0.09321259718653954
Trained batch 582 in epoch 4, gen_loss = 1.1369750616787637, disc_loss = 0.09309690243342499
Trained batch 583 in epoch 4, gen_loss = 1.13867912660927, disc_loss = 0.09310113657377533
Trained batch 584 in epoch 4, gen_loss = 1.1386545603601341, disc_loss = 0.09296573471102831
Trained batch 585 in epoch 4, gen_loss = 1.1385555874060445, disc_loss = 0.09284172079894602
Trained batch 586 in epoch 4, gen_loss = 1.138595138792285, disc_loss = 0.09269617054471825
Trained batch 587 in epoch 4, gen_loss = 1.13891623868626, disc_loss = 0.09337385815606282
Trained batch 588 in epoch 4, gen_loss = 1.1390466087439266, disc_loss = 0.09325612109496001
Trained batch 589 in epoch 4, gen_loss = 1.1387889979754464, disc_loss = 0.09317315619407317
Trained batch 590 in epoch 4, gen_loss = 1.138776246918438, disc_loss = 0.09304864804990047
Trained batch 591 in epoch 4, gen_loss = 1.1390958591993596, disc_loss = 0.09291510565860851
Trained batch 592 in epoch 4, gen_loss = 1.1394731820031725, disc_loss = 0.09276950636542516
Trained batch 593 in epoch 4, gen_loss = 1.1403473200721772, disc_loss = 0.09264480631629174
Trained batch 594 in epoch 4, gen_loss = 1.1402755040581487, disc_loss = 0.09254045322881777
Trained batch 595 in epoch 4, gen_loss = 1.1395133670244442, disc_loss = 0.09256145162289124
Trained batch 596 in epoch 4, gen_loss = 1.1401870091456665, disc_loss = 0.09249382732370541
Trained batch 597 in epoch 4, gen_loss = 1.1402775324806322, disc_loss = 0.09269088654183973
Trained batch 598 in epoch 4, gen_loss = 1.140351322586827, disc_loss = 0.09255822840611605
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.8272924423217773, disc_loss = 0.12227524816989899
Trained batch 1 in epoch 5, gen_loss = 1.0172017812728882, disc_loss = 0.07250924222171307
Trained batch 2 in epoch 5, gen_loss = 1.0283032258351643, disc_loss = 0.06018293276429176
Trained batch 3 in epoch 5, gen_loss = 1.047117829322815, disc_loss = 0.056151784025132656
Trained batch 4 in epoch 5, gen_loss = 1.198838233947754, disc_loss = 0.06940752789378166
Trained batch 5 in epoch 5, gen_loss = 1.236336588859558, disc_loss = 0.07350299693644047
Trained batch 6 in epoch 5, gen_loss = 1.232659203665597, disc_loss = 0.06569641775318555
Trained batch 7 in epoch 5, gen_loss = 1.148956261575222, disc_loss = 0.0839243340305984
Trained batch 8 in epoch 5, gen_loss = 1.1342515879207187, disc_loss = 0.07772322206033601
Trained batch 9 in epoch 5, gen_loss = 1.1681772649288178, disc_loss = 0.07288305684924126
Trained batch 10 in epoch 5, gen_loss = 1.130693869157271, disc_loss = 0.07545724240216342
Trained batch 11 in epoch 5, gen_loss = 1.170535941918691, disc_loss = 0.07221527087191741
Trained batch 12 in epoch 5, gen_loss = 1.1602284541496863, disc_loss = 0.06907958508684085
Trained batch 13 in epoch 5, gen_loss = 1.1580840604645866, disc_loss = 0.06596290333462614
Trained batch 14 in epoch 5, gen_loss = 1.1606959104537964, disc_loss = 0.0668243603159984
Trained batch 15 in epoch 5, gen_loss = 1.1586699932813644, disc_loss = 0.06342038133880123
Trained batch 16 in epoch 5, gen_loss = 1.165366579504574, disc_loss = 0.05997309417409055
Trained batch 17 in epoch 5, gen_loss = 1.1464535858896043, disc_loss = 0.06117745923499266
Trained batch 18 in epoch 5, gen_loss = 1.1569056573667025, disc_loss = 0.05881968219029276
Trained batch 19 in epoch 5, gen_loss = 1.1599518418312074, disc_loss = 0.057415444124490025
Trained batch 20 in epoch 5, gen_loss = 1.1782597303390503, disc_loss = 0.0552018028462217
Trained batch 21 in epoch 5, gen_loss = 1.1722184148701755, disc_loss = 0.05525920074433088
Trained batch 22 in epoch 5, gen_loss = 1.1710198184718257, disc_loss = 0.05402786981152451
Trained batch 23 in epoch 5, gen_loss = 1.1625341673692067, disc_loss = 0.05343263767038783
Trained batch 24 in epoch 5, gen_loss = 1.1925697612762451, disc_loss = 0.05273894712328911
Trained batch 25 in epoch 5, gen_loss = 1.1958883909078746, disc_loss = 0.05144434257482107
Trained batch 26 in epoch 5, gen_loss = 1.201605408279984, disc_loss = 0.050169568922784596
Trained batch 27 in epoch 5, gen_loss = 1.197621728692736, disc_loss = 0.04930374950968793
Trained batch 28 in epoch 5, gen_loss = 1.1991200940362339, disc_loss = 0.04800673831125785
Trained batch 29 in epoch 5, gen_loss = 1.2320190747578939, disc_loss = 0.04876477097471555
Trained batch 30 in epoch 5, gen_loss = 1.2329234692358202, disc_loss = 0.04748121378642897
Trained batch 31 in epoch 5, gen_loss = 1.239548247307539, disc_loss = 0.04662725538946688
Trained batch 32 in epoch 5, gen_loss = 1.2401896498420022, disc_loss = 0.045569373153601635
Trained batch 33 in epoch 5, gen_loss = 1.2316060031161589, disc_loss = 0.045213067602804476
Trained batch 34 in epoch 5, gen_loss = 1.2285770688738142, disc_loss = 0.04444444714380162
Trained batch 35 in epoch 5, gen_loss = 1.255688402387831, disc_loss = 0.05520835459335811
Trained batch 36 in epoch 5, gen_loss = 1.2489981039150342, disc_loss = 0.054682711214833965
Trained batch 37 in epoch 5, gen_loss = 1.2337425758964138, disc_loss = 0.05603145192818422
Trained batch 38 in epoch 5, gen_loss = 1.2173189154038062, disc_loss = 0.05880152923651995
Trained batch 39 in epoch 5, gen_loss = 1.2286648467183112, disc_loss = 0.05949108370114118
Trained batch 40 in epoch 5, gen_loss = 1.2347938912670786, disc_loss = 0.05963292256815404
Trained batch 41 in epoch 5, gen_loss = 1.2271237245627813, disc_loss = 0.05921782573152866
Trained batch 42 in epoch 5, gen_loss = 1.2199577259462933, disc_loss = 0.05904886951713368
Trained batch 43 in epoch 5, gen_loss = 1.2142792967232792, disc_loss = 0.06105685600248927
Trained batch 44 in epoch 5, gen_loss = 1.2058324270778231, disc_loss = 0.0622922726182474
Trained batch 45 in epoch 5, gen_loss = 1.20468208193779, disc_loss = 0.06295173722521766
Trained batch 46 in epoch 5, gen_loss = 1.2162955885237836, disc_loss = 0.06197562498694405
Trained batch 47 in epoch 5, gen_loss = 1.2078013283511002, disc_loss = 0.062090571057827525
Trained batch 48 in epoch 5, gen_loss = 1.2021858607019698, disc_loss = 0.062360714759905726
Trained batch 49 in epoch 5, gen_loss = 1.2116209089756012, disc_loss = 0.061449903342872855
Trained batch 50 in epoch 5, gen_loss = 1.224419555243324, disc_loss = 0.06082136057974661
Trained batch 51 in epoch 5, gen_loss = 1.2231365453738432, disc_loss = 0.06007993907237855
Trained batch 52 in epoch 5, gen_loss = 1.2234490626263168, disc_loss = 0.05941034823585794
Trained batch 53 in epoch 5, gen_loss = 1.2199985528433765, disc_loss = 0.058854994726263814
Trained batch 54 in epoch 5, gen_loss = 1.216802593794736, disc_loss = 0.06247342206876386
Trained batch 55 in epoch 5, gen_loss = 1.2110079590763365, disc_loss = 0.06223923185773726
Trained batch 56 in epoch 5, gen_loss = 1.2072724877742298, disc_loss = 0.06181187873804256
Trained batch 57 in epoch 5, gen_loss = 1.2040817614259391, disc_loss = 0.0620340925705587
Trained batch 58 in epoch 5, gen_loss = 1.1951022653256433, disc_loss = 0.063256851429025
Trained batch 59 in epoch 5, gen_loss = 1.1983516991138459, disc_loss = 0.06377113422689339
Trained batch 60 in epoch 5, gen_loss = 1.1963153921189855, disc_loss = 0.06315665537888399
Trained batch 61 in epoch 5, gen_loss = 1.1990838377706465, disc_loss = 0.062320842272451805
Trained batch 62 in epoch 5, gen_loss = 1.1992044997593714, disc_loss = 0.06173288279641715
Trained batch 63 in epoch 5, gen_loss = 1.2023597285151482, disc_loss = 0.06163770852435846
Trained batch 64 in epoch 5, gen_loss = 1.2002656129690317, disc_loss = 0.06213461500234329
Trained batch 65 in epoch 5, gen_loss = 1.195466051499049, disc_loss = 0.06232541625980626
Trained batch 66 in epoch 5, gen_loss = 1.1918387528675705, disc_loss = 0.062341680013532956
Trained batch 67 in epoch 5, gen_loss = 1.18920615578399, disc_loss = 0.06180291495505063
Trained batch 68 in epoch 5, gen_loss = 1.1902811103972837, disc_loss = 0.061157871348162494
Trained batch 69 in epoch 5, gen_loss = 1.1892596593924931, disc_loss = 0.06077311117468136
Trained batch 70 in epoch 5, gen_loss = 1.198840491368737, disc_loss = 0.060368952498784365
Trained batch 71 in epoch 5, gen_loss = 1.1953252719508276, disc_loss = 0.06016977932045443
Trained batch 72 in epoch 5, gen_loss = 1.192904338444749, disc_loss = 0.05975400729181424
Trained batch 73 in epoch 5, gen_loss = 1.1969581471907127, disc_loss = 0.05910145477517634
Trained batch 74 in epoch 5, gen_loss = 1.2061080678304037, disc_loss = 0.05919571167478959
Trained batch 75 in epoch 5, gen_loss = 1.2029257542208622, disc_loss = 0.05902634871094242
Trained batch 76 in epoch 5, gen_loss = 1.2022660862315784, disc_loss = 0.05866399021553142
Trained batch 77 in epoch 5, gen_loss = 1.20742400487264, disc_loss = 0.05810499450382896
Trained batch 78 in epoch 5, gen_loss = 1.205014624173128, disc_loss = 0.0579448030742852
Trained batch 79 in epoch 5, gen_loss = 1.2041358947753906, disc_loss = 0.05743748379172757
Trained batch 80 in epoch 5, gen_loss = 1.2082147598266602, disc_loss = 0.05843567279063993
Trained batch 81 in epoch 5, gen_loss = 1.214005057404681, disc_loss = 0.05801233691276937
Trained batch 82 in epoch 5, gen_loss = 1.2097246043653374, disc_loss = 0.058402426686721395
Trained batch 83 in epoch 5, gen_loss = 1.2044998549279713, disc_loss = 0.05879636637733451
Trained batch 84 in epoch 5, gen_loss = 1.201824543055366, disc_loss = 0.0591086785254233
Trained batch 85 in epoch 5, gen_loss = 1.202342361904854, disc_loss = 0.05857039818020408
Trained batch 86 in epoch 5, gen_loss = 1.2059688485901932, disc_loss = 0.05835781031256092
Trained batch 87 in epoch 5, gen_loss = 1.2068372910672969, disc_loss = 0.05779671749438752
Trained batch 88 in epoch 5, gen_loss = 1.2103512809517678, disc_loss = 0.05723733988621931
Trained batch 89 in epoch 5, gen_loss = 1.2091732674174838, disc_loss = 0.056844499500261415
Trained batch 90 in epoch 5, gen_loss = 1.2097195635785114, disc_loss = 0.056308227724262645
Trained batch 91 in epoch 5, gen_loss = 1.211045451786207, disc_loss = 0.05588444316273798
Trained batch 92 in epoch 5, gen_loss = 1.214112518936075, disc_loss = 0.055415899663041994
Trained batch 93 in epoch 5, gen_loss = 1.2157970831749287, disc_loss = 0.05489668414551527
Trained batch 94 in epoch 5, gen_loss = 1.2163058255848131, disc_loss = 0.054538353218844066
Trained batch 95 in epoch 5, gen_loss = 1.2157645573218663, disc_loss = 0.054119037095612534
Trained batch 96 in epoch 5, gen_loss = 1.2182123648751642, disc_loss = 0.05363009311258793
Trained batch 97 in epoch 5, gen_loss = 1.2224620933435402, disc_loss = 0.0532186761099313
Trained batch 98 in epoch 5, gen_loss = 1.2251622676849365, disc_loss = 0.05323496866369187
Trained batch 99 in epoch 5, gen_loss = 1.2279372596740723, disc_loss = 0.05276315988972783
Trained batch 100 in epoch 5, gen_loss = 1.2292253144896856, disc_loss = 0.052280121353814504
Trained batch 101 in epoch 5, gen_loss = 1.2251094153114395, disc_loss = 0.05278381412191426
Trained batch 102 in epoch 5, gen_loss = 1.2266600126201668, disc_loss = 0.05243985138797355
Trained batch 103 in epoch 5, gen_loss = 1.2299537503948579, disc_loss = 0.05206826412512992
Trained batch 104 in epoch 5, gen_loss = 1.2317584156990051, disc_loss = 0.05176256550032468
Trained batch 105 in epoch 5, gen_loss = 1.2327010502230447, disc_loss = 0.051338464601562835
Trained batch 106 in epoch 5, gen_loss = 1.233233501420957, disc_loss = 0.05140124266601612
Trained batch 107 in epoch 5, gen_loss = 1.2321980358273894, disc_loss = 0.05110284332530918
Trained batch 108 in epoch 5, gen_loss = 1.2312812231002597, disc_loss = 0.050954624890871006
Trained batch 109 in epoch 5, gen_loss = 1.2349564243446698, disc_loss = 0.05063014602796598
Trained batch 110 in epoch 5, gen_loss = 1.2368363007768854, disc_loss = 0.050759751081198186
Trained batch 111 in epoch 5, gen_loss = 1.2344303147069045, disc_loss = 0.05066268325650266
Trained batch 112 in epoch 5, gen_loss = 1.2371053943591834, disc_loss = 0.05029561520611818
Trained batch 113 in epoch 5, gen_loss = 1.238084160967877, disc_loss = 0.04990969253540562
Trained batch 114 in epoch 5, gen_loss = 1.240374939856322, disc_loss = 0.049548978358507155
Trained batch 115 in epoch 5, gen_loss = 1.2437262201103672, disc_loss = 0.04923683943644423
Trained batch 116 in epoch 5, gen_loss = 1.2452320802924979, disc_loss = 0.04895776079601457
Trained batch 117 in epoch 5, gen_loss = 1.245551945294364, disc_loss = 0.04859670280021126
Trained batch 118 in epoch 5, gen_loss = 1.2474823173354654, disc_loss = 0.048234573913691174
Trained batch 119 in epoch 5, gen_loss = 1.2488793089985848, disc_loss = 0.0478680416670007
Trained batch 120 in epoch 5, gen_loss = 1.2489032632063244, disc_loss = 0.04754607429851062
Trained batch 121 in epoch 5, gen_loss = 1.2483458748606384, disc_loss = 0.04724643711901468
Trained batch 122 in epoch 5, gen_loss = 1.25237595501954, disc_loss = 0.04699197648910851
Trained batch 123 in epoch 5, gen_loss = 1.2556381307301983, disc_loss = 0.04669283160323938
Trained batch 124 in epoch 5, gen_loss = 1.2552530045509338, disc_loss = 0.04643386321887374
Trained batch 125 in epoch 5, gen_loss = 1.2565528329402682, disc_loss = 0.046106580249403444
Trained batch 126 in epoch 5, gen_loss = 1.2539329308224476, disc_loss = 0.04608599415166289
Trained batch 127 in epoch 5, gen_loss = 1.2572694481350482, disc_loss = 0.0465599950584874
Trained batch 128 in epoch 5, gen_loss = 1.254327278728633, disc_loss = 0.0466577385754375
Trained batch 129 in epoch 5, gen_loss = 1.2500625972564403, disc_loss = 0.04705057922535791
Trained batch 130 in epoch 5, gen_loss = 1.2464345079341919, disc_loss = 0.04754744867175704
Trained batch 131 in epoch 5, gen_loss = 1.2499465829495229, disc_loss = 0.04774432267048255
Trained batch 132 in epoch 5, gen_loss = 1.2529546950096475, disc_loss = 0.047766333757514566
Trained batch 133 in epoch 5, gen_loss = 1.2529632391324683, disc_loss = 0.04746583318546303
Trained batch 134 in epoch 5, gen_loss = 1.251195032066769, disc_loss = 0.04730785034114012
Trained batch 135 in epoch 5, gen_loss = 1.2516241998356932, disc_loss = 0.04728115440743482
Trained batch 136 in epoch 5, gen_loss = 1.2498266692579227, disc_loss = 0.0472891355225694
Trained batch 137 in epoch 5, gen_loss = 1.2523307174012281, disc_loss = 0.047052462230962905
Trained batch 138 in epoch 5, gen_loss = 1.2542599118013176, disc_loss = 0.046774536743090095
Trained batch 139 in epoch 5, gen_loss = 1.2570292145013808, disc_loss = 0.04655805237790836
Trained batch 140 in epoch 5, gen_loss = 1.254693217734073, disc_loss = 0.04653943932106626
Trained batch 141 in epoch 5, gen_loss = 1.2549856049074253, disc_loss = 0.04633477879491386
Trained batch 142 in epoch 5, gen_loss = 1.2500635181273614, disc_loss = 0.047267083974125296
Trained batch 143 in epoch 5, gen_loss = 1.2531719278130267, disc_loss = 0.048807975975149825
Trained batch 144 in epoch 5, gen_loss = 1.256291087331443, disc_loss = 0.04875520707654028
Trained batch 145 in epoch 5, gen_loss = 1.253865321613338, disc_loss = 0.04881390598475015
Trained batch 146 in epoch 5, gen_loss = 1.251270965248549, disc_loss = 0.04900651421005122
Trained batch 147 in epoch 5, gen_loss = 1.2517344544868212, disc_loss = 0.04877346627905059
Trained batch 148 in epoch 5, gen_loss = 1.2519595386997966, disc_loss = 0.04851660251479921
Trained batch 149 in epoch 5, gen_loss = 1.251186587413152, disc_loss = 0.04851504717332621
Trained batch 150 in epoch 5, gen_loss = 1.2489565401677265, disc_loss = 0.048920567403393275
Trained batch 151 in epoch 5, gen_loss = 1.2470689808067523, disc_loss = 0.04937863834263561
Trained batch 152 in epoch 5, gen_loss = 1.2442427199650434, disc_loss = 0.04964871606272128
Trained batch 153 in epoch 5, gen_loss = 1.2492894867023865, disc_loss = 0.050125674565334795
Trained batch 154 in epoch 5, gen_loss = 1.2503815670167246, disc_loss = 0.05009144981121344
Trained batch 155 in epoch 5, gen_loss = 1.2490844913782218, disc_loss = 0.049956732110168114
Trained batch 156 in epoch 5, gen_loss = 1.2482706669029917, disc_loss = 0.04988067159666472
Trained batch 157 in epoch 5, gen_loss = 1.2484438822993749, disc_loss = 0.04963840259227289
Trained batch 158 in epoch 5, gen_loss = 1.2498190534189813, disc_loss = 0.049448439491174695
Trained batch 159 in epoch 5, gen_loss = 1.250755700096488, disc_loss = 0.04917020519205835
Trained batch 160 in epoch 5, gen_loss = 1.2506884458642569, disc_loss = 0.049677867890676915
Trained batch 161 in epoch 5, gen_loss = 1.2515783865510681, disc_loss = 0.049452120182391854
Trained batch 162 in epoch 5, gen_loss = 1.2517726315311128, disc_loss = 0.049212858403684355
Trained batch 163 in epoch 5, gen_loss = 1.250635993553371, disc_loss = 0.049031243594249756
Trained batch 164 in epoch 5, gen_loss = 1.249824330662236, disc_loss = 0.048906868145885796
Trained batch 165 in epoch 5, gen_loss = 1.2531386021390019, disc_loss = 0.04878433901782944
Trained batch 166 in epoch 5, gen_loss = 1.2552658408701778, disc_loss = 0.048557790417313396
Trained batch 167 in epoch 5, gen_loss = 1.2547667186175073, disc_loss = 0.048362624030449386
Trained batch 168 in epoch 5, gen_loss = 1.254657931934447, disc_loss = 0.04810822075343079
Trained batch 169 in epoch 5, gen_loss = 1.254372827095144, disc_loss = 0.04787084040889407
Trained batch 170 in epoch 5, gen_loss = 1.2538209613303692, disc_loss = 0.047766450087251194
Trained batch 171 in epoch 5, gen_loss = 1.25432005351366, disc_loss = 0.04773902331294795
Trained batch 172 in epoch 5, gen_loss = 1.2537207407069344, disc_loss = 0.04758539866128495
Trained batch 173 in epoch 5, gen_loss = 1.2521977452026016, disc_loss = 0.04752674361894271
Trained batch 174 in epoch 5, gen_loss = 1.2534982790265765, disc_loss = 0.047314452084579635
Trained batch 175 in epoch 5, gen_loss = 1.2531818314032122, disc_loss = 0.04711898506502621
Trained batch 176 in epoch 5, gen_loss = 1.2528115706255207, disc_loss = 0.047062937141327706
Trained batch 177 in epoch 5, gen_loss = 1.2541346483016282, disc_loss = 0.04873855746079111
Trained batch 178 in epoch 5, gen_loss = 1.2508265998776398, disc_loss = 0.049173538736978224
Trained batch 179 in epoch 5, gen_loss = 1.249995297855801, disc_loss = 0.04906882040668279
Trained batch 180 in epoch 5, gen_loss = 1.249507985062362, disc_loss = 0.0490128906850204
Trained batch 181 in epoch 5, gen_loss = 1.2493505785753438, disc_loss = 0.048939557369941704
Trained batch 182 in epoch 5, gen_loss = 1.2498997019939735, disc_loss = 0.048757750553694745
Trained batch 183 in epoch 5, gen_loss = 1.2501807180435762, disc_loss = 0.04857563874532428
Trained batch 184 in epoch 5, gen_loss = 1.2503256121197261, disc_loss = 0.04836088354271409
Trained batch 185 in epoch 5, gen_loss = 1.2508406036643571, disc_loss = 0.048210881758100725
Trained batch 186 in epoch 5, gen_loss = 1.2516110045387145, disc_loss = 0.048011837878269466
Trained batch 187 in epoch 5, gen_loss = 1.2529542636364064, disc_loss = 0.047804664654478905
Trained batch 188 in epoch 5, gen_loss = 1.2525753413558638, disc_loss = 0.047644113868021615
Trained batch 189 in epoch 5, gen_loss = 1.2527379431222614, disc_loss = 0.04750662428621007
Trained batch 190 in epoch 5, gen_loss = 1.2533929273096054, disc_loss = 0.047286123390850754
Trained batch 191 in epoch 5, gen_loss = 1.2548884910841782, disc_loss = 0.04710744035401149
Trained batch 192 in epoch 5, gen_loss = 1.2552946132699443, disc_loss = 0.04698502431850436
Trained batch 193 in epoch 5, gen_loss = 1.253692275470065, disc_loss = 0.046883990308845935
Trained batch 194 in epoch 5, gen_loss = 1.2518891016642253, disc_loss = 0.04695519401142612
Trained batch 195 in epoch 5, gen_loss = 1.2511622005579424, disc_loss = 0.0468442326302317
Trained batch 196 in epoch 5, gen_loss = 1.2509267923190508, disc_loss = 0.0470869453732624
Trained batch 197 in epoch 5, gen_loss = 1.2488238877720303, disc_loss = 0.047155298962906905
Trained batch 198 in epoch 5, gen_loss = 1.2490486703326356, disc_loss = 0.04711051715126065
Trained batch 199 in epoch 5, gen_loss = 1.248248752951622, disc_loss = 0.047046886563766745
Trained batch 200 in epoch 5, gen_loss = 1.2489997842418614, disc_loss = 0.046863635763322094
Trained batch 201 in epoch 5, gen_loss = 1.248488237362097, disc_loss = 0.04678375157988676
Trained batch 202 in epoch 5, gen_loss = 1.2480694818966493, disc_loss = 0.046630348315178025
Trained batch 203 in epoch 5, gen_loss = 1.248818836960138, disc_loss = 0.0464615368343634
Trained batch 204 in epoch 5, gen_loss = 1.2509340891023961, disc_loss = 0.0463040833997472
Trained batch 205 in epoch 5, gen_loss = 1.249785371775766, disc_loss = 0.0462239967066867
Trained batch 206 in epoch 5, gen_loss = 1.2464994307301471, disc_loss = 0.046895768990569214
Trained batch 207 in epoch 5, gen_loss = 1.2500562203618197, disc_loss = 0.04739544119085902
Trained batch 208 in epoch 5, gen_loss = 1.2481880461770383, disc_loss = 0.04747765316320449
Trained batch 209 in epoch 5, gen_loss = 1.247976204894838, disc_loss = 0.047352430581425624
Trained batch 210 in epoch 5, gen_loss = 1.2497797300465299, disc_loss = 0.04739451249708285
Trained batch 211 in epoch 5, gen_loss = 1.2510655409884903, disc_loss = 0.04724130683077745
Trained batch 212 in epoch 5, gen_loss = 1.2511898262400023, disc_loss = 0.047082351479119676
Trained batch 213 in epoch 5, gen_loss = 1.2495025535610234, disc_loss = 0.047165498313729036
Trained batch 214 in epoch 5, gen_loss = 1.252538240233133, disc_loss = 0.04716330153521064
Trained batch 215 in epoch 5, gen_loss = 1.2530903247771439, disc_loss = 0.04698780672064189
Trained batch 216 in epoch 5, gen_loss = 1.254776883784527, disc_loss = 0.04707348246925643
Trained batch 217 in epoch 5, gen_loss = 1.251972594665825, disc_loss = 0.0476502266545874
Trained batch 218 in epoch 5, gen_loss = 1.252045846148713, disc_loss = 0.04784815384024014
Trained batch 219 in epoch 5, gen_loss = 1.2531168322671544, disc_loss = 0.047677571392110124
Trained batch 220 in epoch 5, gen_loss = 1.2524286117488983, disc_loss = 0.047640315832241494
Trained batch 221 in epoch 5, gen_loss = 1.2514159112900227, disc_loss = 0.047658804550280306
Trained batch 222 in epoch 5, gen_loss = 1.2510296392333882, disc_loss = 0.04750336406151075
Trained batch 223 in epoch 5, gen_loss = 1.2512121107429266, disc_loss = 0.04737505062491566
Trained batch 224 in epoch 5, gen_loss = 1.2517437238163418, disc_loss = 0.04753460382628772
Trained batch 225 in epoch 5, gen_loss = 1.2500867155273403, disc_loss = 0.04757435293662139
Trained batch 226 in epoch 5, gen_loss = 1.2480579795816396, disc_loss = 0.04774164937083745
Trained batch 227 in epoch 5, gen_loss = 1.2520112099877574, disc_loss = 0.048349744005112404
Trained batch 228 in epoch 5, gen_loss = 1.251822155375668, disc_loss = 0.0482555674694023
Trained batch 229 in epoch 5, gen_loss = 1.2508645070635753, disc_loss = 0.048253049752067616
Trained batch 230 in epoch 5, gen_loss = 1.250688796177571, disc_loss = 0.04813204976846968
Trained batch 231 in epoch 5, gen_loss = 1.248278368392895, disc_loss = 0.048408937642495306
Trained batch 232 in epoch 5, gen_loss = 1.249745859352816, disc_loss = 0.04961357815910626
Trained batch 233 in epoch 5, gen_loss = 1.249865832237097, disc_loss = 0.04946973635098682
Trained batch 234 in epoch 5, gen_loss = 1.2508303482481773, disc_loss = 0.04938481630202621
Trained batch 235 in epoch 5, gen_loss = 1.2489261766106396, disc_loss = 0.049470410849977976
Trained batch 236 in epoch 5, gen_loss = 1.2461123667688812, disc_loss = 0.05026751646048975
Trained batch 237 in epoch 5, gen_loss = 1.2473832348815532, disc_loss = 0.05063416761299204
Trained batch 238 in epoch 5, gen_loss = 1.247407362550871, disc_loss = 0.050485659587473676
Trained batch 239 in epoch 5, gen_loss = 1.2467426359653473, disc_loss = 0.050385469611501324
Trained batch 240 in epoch 5, gen_loss = 1.2464725951436149, disc_loss = 0.05024161897174612
Trained batch 241 in epoch 5, gen_loss = 1.246975479539761, disc_loss = 0.05010440048361428
Trained batch 242 in epoch 5, gen_loss = 1.2470262575541995, disc_loss = 0.04993225391302641
Trained batch 243 in epoch 5, gen_loss = 1.2466695997558657, disc_loss = 0.04987949779692304
Trained batch 244 in epoch 5, gen_loss = 1.2462292997204527, disc_loss = 0.04973529235326818
Trained batch 245 in epoch 5, gen_loss = 1.2460657343631838, disc_loss = 0.0495874947940219
Trained batch 246 in epoch 5, gen_loss = 1.2475546130284607, disc_loss = 0.04944523146587164
Trained batch 247 in epoch 5, gen_loss = 1.2481723168203909, disc_loss = 0.04938374583106188
Trained batch 248 in epoch 5, gen_loss = 1.2472552649946098, disc_loss = 0.04931653189439192
Trained batch 249 in epoch 5, gen_loss = 1.2470984325408936, disc_loss = 0.04917430684901774
Trained batch 250 in epoch 5, gen_loss = 1.2464720661421695, disc_loss = 0.049053085242505685
Trained batch 251 in epoch 5, gen_loss = 1.2485094789474729, disc_loss = 0.04894631991850301
Trained batch 252 in epoch 5, gen_loss = 1.2494390109782163, disc_loss = 0.048877368509960856
Trained batch 253 in epoch 5, gen_loss = 1.2501089042565954, disc_loss = 0.048711132531340316
Trained batch 254 in epoch 5, gen_loss = 1.2482908543418436, disc_loss = 0.048810374219993166
Trained batch 255 in epoch 5, gen_loss = 1.2502917530946434, disc_loss = 0.048711580247982056
Trained batch 256 in epoch 5, gen_loss = 1.25043413332928, disc_loss = 0.04855699825792751
Trained batch 257 in epoch 5, gen_loss = 1.2502915184627208, disc_loss = 0.048963271256521806
Trained batch 258 in epoch 5, gen_loss = 1.2503368136505362, disc_loss = 0.04881799733625818
Trained batch 259 in epoch 5, gen_loss = 1.2484706688385743, disc_loss = 0.04892637830478354
Trained batch 260 in epoch 5, gen_loss = 1.248084836764354, disc_loss = 0.048946326297004905
Trained batch 261 in epoch 5, gen_loss = 1.2460757503072724, disc_loss = 0.04909667990326824
Trained batch 262 in epoch 5, gen_loss = 1.2493526038108216, disc_loss = 0.049903503422600574
Trained batch 263 in epoch 5, gen_loss = 1.2474133561957965, disc_loss = 0.05008277006863588
Trained batch 264 in epoch 5, gen_loss = 1.2466796236218147, disc_loss = 0.04999109924647887
Trained batch 265 in epoch 5, gen_loss = 1.2466499070475872, disc_loss = 0.04983331295801677
Trained batch 266 in epoch 5, gen_loss = 1.2470106560639227, disc_loss = 0.050079565193532
Trained batch 267 in epoch 5, gen_loss = 1.2459042901868251, disc_loss = 0.05004926448958968
Trained batch 268 in epoch 5, gen_loss = 1.244725818306097, disc_loss = 0.05009455612400152
Trained batch 269 in epoch 5, gen_loss = 1.2426640199290382, disc_loss = 0.05029542503223099
Trained batch 270 in epoch 5, gen_loss = 1.2433117841442574, disc_loss = 0.05032485861475562
Trained batch 271 in epoch 5, gen_loss = 1.244028555777143, disc_loss = 0.05022540198029567
Trained batch 272 in epoch 5, gen_loss = 1.2451066160813355, disc_loss = 0.050089457827951114
Trained batch 273 in epoch 5, gen_loss = 1.2456189665916193, disc_loss = 0.05002436907384137
Trained batch 274 in epoch 5, gen_loss = 1.2444771060076627, disc_loss = 0.04999393319033764
Trained batch 275 in epoch 5, gen_loss = 1.2435702869425649, disc_loss = 0.049954162001191384
Trained batch 276 in epoch 5, gen_loss = 1.243728209703838, disc_loss = 0.04985391348096061
Trained batch 277 in epoch 5, gen_loss = 1.2439607641250967, disc_loss = 0.04976097751817525
Trained batch 278 in epoch 5, gen_loss = 1.245024517659218, disc_loss = 0.049624946013453505
Trained batch 279 in epoch 5, gen_loss = 1.2465551059160913, disc_loss = 0.04966707486892119
Trained batch 280 in epoch 5, gen_loss = 1.244695096889849, disc_loss = 0.049887591719402005
Trained batch 281 in epoch 5, gen_loss = 1.2443844606267644, disc_loss = 0.04976080797764585
Trained batch 282 in epoch 5, gen_loss = 1.2467141039801148, disc_loss = 0.05029589033688916
Trained batch 283 in epoch 5, gen_loss = 1.2451037409859644, disc_loss = 0.05049117309415162
Trained batch 284 in epoch 5, gen_loss = 1.2437096062459443, disc_loss = 0.050532820178686
Trained batch 285 in epoch 5, gen_loss = 1.243734166547135, disc_loss = 0.05044791483242143
Trained batch 286 in epoch 5, gen_loss = 1.2433607227295533, disc_loss = 0.05035439522236015
Trained batch 287 in epoch 5, gen_loss = 1.243196452450421, disc_loss = 0.050397659695590846
Trained batch 288 in epoch 5, gen_loss = 1.2414882123264062, disc_loss = 0.05049573108521661
Trained batch 289 in epoch 5, gen_loss = 1.2411367282785217, disc_loss = 0.050486142334431924
Trained batch 290 in epoch 5, gen_loss = 1.2409075783290404, disc_loss = 0.05035989289732067
Trained batch 291 in epoch 5, gen_loss = 1.2415209361543393, disc_loss = 0.050262235894429255
Trained batch 292 in epoch 5, gen_loss = 1.2413841154388194, disc_loss = 0.05045035646579931
Trained batch 293 in epoch 5, gen_loss = 1.2400284314236674, disc_loss = 0.0505670375193843
Trained batch 294 in epoch 5, gen_loss = 1.242303884837587, disc_loss = 0.050790508519226715
Trained batch 295 in epoch 5, gen_loss = 1.2443687704366606, disc_loss = 0.05073605845147442
Trained batch 296 in epoch 5, gen_loss = 1.2428219773954012, disc_loss = 0.05090861398607543
Trained batch 297 in epoch 5, gen_loss = 1.2424267568444245, disc_loss = 0.050878880331417756
Trained batch 298 in epoch 5, gen_loss = 1.2447879045304646, disc_loss = 0.0516602479927491
Trained batch 299 in epoch 5, gen_loss = 1.2432244298855464, disc_loss = 0.05183828482870013
Trained batch 300 in epoch 5, gen_loss = 1.2418812556916297, disc_loss = 0.05199511561920229
Trained batch 301 in epoch 5, gen_loss = 1.2427091637984018, disc_loss = 0.05267851952531233
Trained batch 302 in epoch 5, gen_loss = 1.241412658305845, disc_loss = 0.052735388129888094
Trained batch 303 in epoch 5, gen_loss = 1.2393591727473234, disc_loss = 0.0530629045755823
Trained batch 304 in epoch 5, gen_loss = 1.2389289619492703, disc_loss = 0.05320289481706062
Trained batch 305 in epoch 5, gen_loss = 1.2374718524272146, disc_loss = 0.053454280238951636
Trained batch 306 in epoch 5, gen_loss = 1.2368774355816918, disc_loss = 0.053532139266194954
Trained batch 307 in epoch 5, gen_loss = 1.236809737883605, disc_loss = 0.053687119274400175
Trained batch 308 in epoch 5, gen_loss = 1.2349303733183727, disc_loss = 0.054179296739893724
Trained batch 309 in epoch 5, gen_loss = 1.2346619167635517, disc_loss = 0.05407062957453872
Trained batch 310 in epoch 5, gen_loss = 1.234915761319004, disc_loss = 0.053928262908969946
Trained batch 311 in epoch 5, gen_loss = 1.234057251459513, disc_loss = 0.05425942610226906
Trained batch 312 in epoch 5, gen_loss = 1.2357649746032568, disc_loss = 0.054190453902160686
Trained batch 313 in epoch 5, gen_loss = 1.2339724304190107, disc_loss = 0.05451660734826735
Trained batch 314 in epoch 5, gen_loss = 1.2343338434658353, disc_loss = 0.05456651816854165
Trained batch 315 in epoch 5, gen_loss = 1.2340279830784737, disc_loss = 0.054492817093806836
Trained batch 316 in epoch 5, gen_loss = 1.2341813843709062, disc_loss = 0.05434601972091132
Trained batch 317 in epoch 5, gen_loss = 1.2348365556893859, disc_loss = 0.05420564102893402
Trained batch 318 in epoch 5, gen_loss = 1.2335425258430195, disc_loss = 0.05423804612678467
Trained batch 319 in epoch 5, gen_loss = 1.233678604848683, disc_loss = 0.054107732056581884
Trained batch 320 in epoch 5, gen_loss = 1.234155719339662, disc_loss = 0.0540122333725456
Trained batch 321 in epoch 5, gen_loss = 1.2343691356063629, disc_loss = 0.053899757759298506
Trained batch 322 in epoch 5, gen_loss = 1.2345364110388624, disc_loss = 0.053759312492163834
Trained batch 323 in epoch 5, gen_loss = 1.2356680813762877, disc_loss = 0.05363904525106198
Trained batch 324 in epoch 5, gen_loss = 1.2353556836568391, disc_loss = 0.05382052700250194
Trained batch 325 in epoch 5, gen_loss = 1.2340080279148429, disc_loss = 0.053908407906687425
Trained batch 326 in epoch 5, gen_loss = 1.233523655922041, disc_loss = 0.05389579045030912
Trained batch 327 in epoch 5, gen_loss = 1.2340988994735043, disc_loss = 0.053963105661351596
Trained batch 328 in epoch 5, gen_loss = 1.2338533979418793, disc_loss = 0.053844811486810626
Trained batch 329 in epoch 5, gen_loss = 1.2338617518092647, disc_loss = 0.0537118911757275
Trained batch 330 in epoch 5, gen_loss = 1.2340511769686582, disc_loss = 0.053603706775891546
Trained batch 331 in epoch 5, gen_loss = 1.2346742646880897, disc_loss = 0.05346500143795891
Trained batch 332 in epoch 5, gen_loss = 1.2351637020841375, disc_loss = 0.053328687332111886
Trained batch 333 in epoch 5, gen_loss = 1.2344130802297306, disc_loss = 0.053265897480458645
Trained batch 334 in epoch 5, gen_loss = 1.2357074093462816, disc_loss = 0.05319018729948508
Trained batch 335 in epoch 5, gen_loss = 1.2363352789765312, disc_loss = 0.05305160300867144
Trained batch 336 in epoch 5, gen_loss = 1.2367587705040544, disc_loss = 0.05292255504786393
Trained batch 337 in epoch 5, gen_loss = 1.2368728451474884, disc_loss = 0.052786287070477944
Trained batch 338 in epoch 5, gen_loss = 1.237073605742778, disc_loss = 0.05266012096019313
Trained batch 339 in epoch 5, gen_loss = 1.2377587718122145, disc_loss = 0.052521217799307233
Trained batch 340 in epoch 5, gen_loss = 1.238717813995227, disc_loss = 0.0523909599591276
Trained batch 341 in epoch 5, gen_loss = 1.2388336139115674, disc_loss = 0.05230854920993902
Trained batch 342 in epoch 5, gen_loss = 1.239044612767745, disc_loss = 0.05218583602137842
Trained batch 343 in epoch 5, gen_loss = 1.2388164522342904, disc_loss = 0.05224982315950572
Trained batch 344 in epoch 5, gen_loss = 1.2386342964310577, disc_loss = 0.05213046045164051
Trained batch 345 in epoch 5, gen_loss = 1.2388609024141566, disc_loss = 0.05200125379999292
Trained batch 346 in epoch 5, gen_loss = 1.2387484167769593, disc_loss = 0.051885212896397116
Trained batch 347 in epoch 5, gen_loss = 1.2388121533667904, disc_loss = 0.051773675619731604
Trained batch 348 in epoch 5, gen_loss = 1.2395943973672423, disc_loss = 0.0516435826947128
Trained batch 349 in epoch 5, gen_loss = 1.2403376647404263, disc_loss = 0.05156190861947835
Trained batch 350 in epoch 5, gen_loss = 1.2403645712425906, disc_loss = 0.05143811537663948
Trained batch 351 in epoch 5, gen_loss = 1.2402058833024718, disc_loss = 0.05134986513373654
Trained batch 352 in epoch 5, gen_loss = 1.2423987976214703, disc_loss = 0.05133043509108613
Trained batch 353 in epoch 5, gen_loss = 1.2423019139780163, disc_loss = 0.051213969585701485
Trained batch 354 in epoch 5, gen_loss = 1.2419599533081054, disc_loss = 0.051118211630521944
Trained batch 355 in epoch 5, gen_loss = 1.2437913679005055, disc_loss = 0.05106301309954207
Trained batch 356 in epoch 5, gen_loss = 1.244915663695135, disc_loss = 0.05103841077938091
Trained batch 357 in epoch 5, gen_loss = 1.243345906115111, disc_loss = 0.05137678473412616
Trained batch 358 in epoch 5, gen_loss = 1.2425173471232975, disc_loss = 0.05136181000480039
Trained batch 359 in epoch 5, gen_loss = 1.242726488908132, disc_loss = 0.05131952643989482
Trained batch 360 in epoch 5, gen_loss = 1.2449149464636298, disc_loss = 0.051496141477954935
Trained batch 361 in epoch 5, gen_loss = 1.2449055165875682, disc_loss = 0.05142557668726047
Trained batch 362 in epoch 5, gen_loss = 1.245468549163545, disc_loss = 0.05135684248352469
Trained batch 363 in epoch 5, gen_loss = 1.2458993252162094, disc_loss = 0.05128309612065185
Trained batch 364 in epoch 5, gen_loss = 1.246255884105212, disc_loss = 0.051216432353966446
Trained batch 365 in epoch 5, gen_loss = 1.2452019184339242, disc_loss = 0.051249451511615855
Trained batch 366 in epoch 5, gen_loss = 1.2436853567650923, disc_loss = 0.05138426018645353
Trained batch 367 in epoch 5, gen_loss = 1.2444207637530307, disc_loss = 0.051554015861652064
Trained batch 368 in epoch 5, gen_loss = 1.245544221504594, disc_loss = 0.051468773251576075
Trained batch 369 in epoch 5, gen_loss = 1.244706559825588, disc_loss = 0.05150816610611572
Trained batch 370 in epoch 5, gen_loss = 1.2446687096212752, disc_loss = 0.051450170233916
Trained batch 371 in epoch 5, gen_loss = 1.2430693910967918, disc_loss = 0.05171491345766211
Trained batch 372 in epoch 5, gen_loss = 1.242907353444649, disc_loss = 0.051786701555735865
Trained batch 373 in epoch 5, gen_loss = 1.241638139448064, disc_loss = 0.051849760492406985
Trained batch 374 in epoch 5, gen_loss = 1.2418657021522521, disc_loss = 0.05221406803404292
Trained batch 375 in epoch 5, gen_loss = 1.2398581617373101, disc_loss = 0.05270990556814371
Trained batch 376 in epoch 5, gen_loss = 1.2390469200415068, disc_loss = 0.052965934952814875
Trained batch 377 in epoch 5, gen_loss = 1.2407634524756639, disc_loss = 0.053812907820212696
Trained batch 378 in epoch 5, gen_loss = 1.2388737497354876, disc_loss = 0.054290020075383395
Trained batch 379 in epoch 5, gen_loss = 1.2371630519628525, disc_loss = 0.05481058776648225
Trained batch 380 in epoch 5, gen_loss = 1.2364865629066006, disc_loss = 0.05516702599525256
Trained batch 381 in epoch 5, gen_loss = 1.2364834802937132, disc_loss = 0.055489796870851316
Trained batch 382 in epoch 5, gen_loss = 1.2353408025387995, disc_loss = 0.05558927090566206
Trained batch 383 in epoch 5, gen_loss = 1.2353584617376328, disc_loss = 0.05555442517773675
Trained batch 384 in epoch 5, gen_loss = 1.2361266616102937, disc_loss = 0.055452550220750754
Trained batch 385 in epoch 5, gen_loss = 1.235934633356302, disc_loss = 0.05533938067772189
Trained batch 386 in epoch 5, gen_loss = 1.2359081143248605, disc_loss = 0.05546505992163637
Trained batch 387 in epoch 5, gen_loss = 1.235349624120083, disc_loss = 0.055392372017467065
Trained batch 388 in epoch 5, gen_loss = 1.2345109232593625, disc_loss = 0.0553582038402385
Trained batch 389 in epoch 5, gen_loss = 1.2333934093132997, disc_loss = 0.05544819194608583
Trained batch 390 in epoch 5, gen_loss = 1.2337873756428204, disc_loss = 0.05570776052558628
Trained batch 391 in epoch 5, gen_loss = 1.233374970299857, disc_loss = 0.055636184284111906
Trained batch 392 in epoch 5, gen_loss = 1.2326686914640528, disc_loss = 0.055590869478511676
Trained batch 393 in epoch 5, gen_loss = 1.2317249452704706, disc_loss = 0.055639692202806096
Trained batch 394 in epoch 5, gen_loss = 1.2333683809147606, disc_loss = 0.055696542187346314
Trained batch 395 in epoch 5, gen_loss = 1.2328126988928727, disc_loss = 0.05580384231929789
Trained batch 396 in epoch 5, gen_loss = 1.2328022969159431, disc_loss = 0.055693817818748485
Trained batch 397 in epoch 5, gen_loss = 1.2320394065212366, disc_loss = 0.0556757557264356
Trained batch 398 in epoch 5, gen_loss = 1.231857603205774, disc_loss = 0.05558434662696226
Trained batch 399 in epoch 5, gen_loss = 1.2313185016810895, disc_loss = 0.05551123682758771
Trained batch 400 in epoch 5, gen_loss = 1.2305155280522277, disc_loss = 0.05547030373567023
Trained batch 401 in epoch 5, gen_loss = 1.2322427756454222, disc_loss = 0.05573064755458403
Trained batch 402 in epoch 5, gen_loss = 1.2323443364564597, disc_loss = 0.05577991684094515
Trained batch 403 in epoch 5, gen_loss = 1.2314575886962438, disc_loss = 0.05579131950813318
Trained batch 404 in epoch 5, gen_loss = 1.2306046765527607, disc_loss = 0.05580834704393774
Trained batch 405 in epoch 5, gen_loss = 1.230998368392437, disc_loss = 0.05576543342390928
Trained batch 406 in epoch 5, gen_loss = 1.2311008761497328, disc_loss = 0.0556496715651372
Trained batch 407 in epoch 5, gen_loss = 1.2302035867583518, disc_loss = 0.05570222378831685
Trained batch 408 in epoch 5, gen_loss = 1.23086640216902, disc_loss = 0.055583714428961206
Trained batch 409 in epoch 5, gen_loss = 1.231618162190042, disc_loss = 0.05555521011829558
Trained batch 410 in epoch 5, gen_loss = 1.2314795658826247, disc_loss = 0.055450847178670395
Trained batch 411 in epoch 5, gen_loss = 1.2314378705996911, disc_loss = 0.05534628241942309
Trained batch 412 in epoch 5, gen_loss = 1.2302118288691337, disc_loss = 0.05541695102702005
Trained batch 413 in epoch 5, gen_loss = 1.2304313505329372, disc_loss = 0.05531476156286679
Trained batch 414 in epoch 5, gen_loss = 1.2325276949319495, disc_loss = 0.05534342865695257
Trained batch 415 in epoch 5, gen_loss = 1.2333392068170583, disc_loss = 0.05544059880216642
Trained batch 416 in epoch 5, gen_loss = 1.233547602340186, disc_loss = 0.05534857130392814
Trained batch 417 in epoch 5, gen_loss = 1.233440162462481, disc_loss = 0.05527220046900783
Trained batch 418 in epoch 5, gen_loss = 1.2334444204207538, disc_loss = 0.055157410662158936
Trained batch 419 in epoch 5, gen_loss = 1.2338077349322183, disc_loss = 0.055124375952540765
Trained batch 420 in epoch 5, gen_loss = 1.2340824000909039, disc_loss = 0.055013141259683776
Trained batch 421 in epoch 5, gen_loss = 1.2342422084785751, disc_loss = 0.054896348551074614
Trained batch 422 in epoch 5, gen_loss = 1.234448287503939, disc_loss = 0.05480170354520105
Trained batch 423 in epoch 5, gen_loss = 1.2347455111876973, disc_loss = 0.05469410683089902
Trained batch 424 in epoch 5, gen_loss = 1.2350361728668213, disc_loss = 0.05457458978135358
Trained batch 425 in epoch 5, gen_loss = 1.2352503129574055, disc_loss = 0.05447373722358541
Trained batch 426 in epoch 5, gen_loss = 1.2352445457802443, disc_loss = 0.05437376637794775
Trained batch 427 in epoch 5, gen_loss = 1.2354443020352692, disc_loss = 0.05426117377497134
Trained batch 428 in epoch 5, gen_loss = 1.2362029419078693, disc_loss = 0.054172430075118905
Trained batch 429 in epoch 5, gen_loss = 1.2360081395437552, disc_loss = 0.05408727894916177
Trained batch 430 in epoch 5, gen_loss = 1.2356830708112074, disc_loss = 0.054007130746865806
Trained batch 431 in epoch 5, gen_loss = 1.2364397151050743, disc_loss = 0.05390700732230606
Trained batch 432 in epoch 5, gen_loss = 1.235345385091134, disc_loss = 0.05405307731345967
Trained batch 433 in epoch 5, gen_loss = 1.236597932703484, disc_loss = 0.05404869143256686
Trained batch 434 in epoch 5, gen_loss = 1.2369453860425401, disc_loss = 0.0539481472571905
Trained batch 435 in epoch 5, gen_loss = 1.237568949614096, disc_loss = 0.05384332661510556
Trained batch 436 in epoch 5, gen_loss = 1.2378488217120311, disc_loss = 0.053734425247009644
Trained batch 437 in epoch 5, gen_loss = 1.2381175111417901, disc_loss = 0.053904199645829015
Trained batch 438 in epoch 5, gen_loss = 1.2375990467353943, disc_loss = 0.053909748508902545
Trained batch 439 in epoch 5, gen_loss = 1.2362944518977945, disc_loss = 0.05417960312016393
Trained batch 440 in epoch 5, gen_loss = 1.2375596599513983, disc_loss = 0.05444459376018283
Trained batch 441 in epoch 5, gen_loss = 1.2378663328977733, disc_loss = 0.054352522672288864
Trained batch 442 in epoch 5, gen_loss = 1.2376226894473383, disc_loss = 0.054261141669522325
Trained batch 443 in epoch 5, gen_loss = 1.237027275669682, disc_loss = 0.054226074368286005
Trained batch 444 in epoch 5, gen_loss = 1.2367101562157106, disc_loss = 0.054203838947637195
Trained batch 445 in epoch 5, gen_loss = 1.2369850331357777, disc_loss = 0.054278894190283936
Trained batch 446 in epoch 5, gen_loss = 1.2358219604897553, disc_loss = 0.05437739515183306
Trained batch 447 in epoch 5, gen_loss = 1.2350613187466348, disc_loss = 0.05440592940483059
Trained batch 448 in epoch 5, gen_loss = 1.2350582590612909, disc_loss = 0.05459741131352771
Trained batch 449 in epoch 5, gen_loss = 1.235338208940294, disc_loss = 0.05450558198667649
Trained batch 450 in epoch 5, gen_loss = 1.234784978192027, disc_loss = 0.054474120607037935
Trained batch 451 in epoch 5, gen_loss = 1.2343959172742556, disc_loss = 0.054412455877507586
Trained batch 452 in epoch 5, gen_loss = 1.2350171278117772, disc_loss = 0.054390557433599836
Trained batch 453 in epoch 5, gen_loss = 1.2356863428842655, disc_loss = 0.054319048573730704
Trained batch 454 in epoch 5, gen_loss = 1.234854251080817, disc_loss = 0.054346000544911066
Trained batch 455 in epoch 5, gen_loss = 1.2348206624911542, disc_loss = 0.05434344352167835
Trained batch 456 in epoch 5, gen_loss = 1.234557011847423, disc_loss = 0.05429746565425308
Trained batch 457 in epoch 5, gen_loss = 1.2335911935854167, disc_loss = 0.054391723771286746
Trained batch 458 in epoch 5, gen_loss = 1.2335597228640305, disc_loss = 0.0543397912103277
Trained batch 459 in epoch 5, gen_loss = 1.2338206844485324, disc_loss = 0.05423703036807558
Trained batch 460 in epoch 5, gen_loss = 1.234215873570349, disc_loss = 0.05417140455534702
Trained batch 461 in epoch 5, gen_loss = 1.2341232435269789, disc_loss = 0.05408044116726766
Trained batch 462 in epoch 5, gen_loss = 1.2339424717503542, disc_loss = 0.054004073159600215
Trained batch 463 in epoch 5, gen_loss = 1.2339815403623828, disc_loss = 0.05391147625803193
Trained batch 464 in epoch 5, gen_loss = 1.2331189764443264, disc_loss = 0.05390479296135406
Trained batch 465 in epoch 5, gen_loss = 1.2330342967366967, disc_loss = 0.053860241609681475
Trained batch 466 in epoch 5, gen_loss = 1.2338602855578225, disc_loss = 0.05379595413526851
Trained batch 467 in epoch 5, gen_loss = 1.234820227465059, disc_loss = 0.053711792611831434
Trained batch 468 in epoch 5, gen_loss = 1.2341957301981668, disc_loss = 0.05370128283283111
Trained batch 469 in epoch 5, gen_loss = 1.2332050045754046, disc_loss = 0.05380764525789926
Trained batch 470 in epoch 5, gen_loss = 1.2326007029812807, disc_loss = 0.05382558409838429
Trained batch 471 in epoch 5, gen_loss = 1.2330344878768518, disc_loss = 0.053744822967959315
Trained batch 472 in epoch 5, gen_loss = 1.2325340116250842, disc_loss = 0.053714149431217204
Trained batch 473 in epoch 5, gen_loss = 1.2323717837092243, disc_loss = 0.053623939668347095
Trained batch 474 in epoch 5, gen_loss = 1.23354297838713, disc_loss = 0.053642480487592126
Trained batch 475 in epoch 5, gen_loss = 1.233699591219926, disc_loss = 0.0535631939624984
Trained batch 476 in epoch 5, gen_loss = 1.2326870388204947, disc_loss = 0.053706986556782445
Trained batch 477 in epoch 5, gen_loss = 1.232949086687056, disc_loss = 0.053605760738475706
Trained batch 478 in epoch 5, gen_loss = 1.2329764631197697, disc_loss = 0.053515191307089184
Trained batch 479 in epoch 5, gen_loss = 1.2336866419762373, disc_loss = 0.05342104768545444
Trained batch 480 in epoch 5, gen_loss = 1.233913137734308, disc_loss = 0.053326447446406536
Trained batch 481 in epoch 5, gen_loss = 1.2342281397200223, disc_loss = 0.053227460269306116
Trained batch 482 in epoch 5, gen_loss = 1.234387535362757, disc_loss = 0.05312968522944636
Trained batch 483 in epoch 5, gen_loss = 1.2351457204454201, disc_loss = 0.05304606280276121
Trained batch 484 in epoch 5, gen_loss = 1.2357063879671786, disc_loss = 0.052950245738701565
Trained batch 485 in epoch 5, gen_loss = 1.236554209464862, disc_loss = 0.052931428313496766
Trained batch 486 in epoch 5, gen_loss = 1.2363742865331364, disc_loss = 0.052864120674111115
Trained batch 487 in epoch 5, gen_loss = 1.2349682913207618, disc_loss = 0.05312641762859249
Trained batch 488 in epoch 5, gen_loss = 1.2350358142687012, disc_loss = 0.0531129871103684
Trained batch 489 in epoch 5, gen_loss = 1.2371306101886594, disc_loss = 0.05350972200525278
Trained batch 490 in epoch 5, gen_loss = 1.23625134814781, disc_loss = 0.05354185294039365
Trained batch 491 in epoch 5, gen_loss = 1.2352087279645407, disc_loss = 0.05364243123761749
Trained batch 492 in epoch 5, gen_loss = 1.2354234899517005, disc_loss = 0.054466287162944556
Trained batch 493 in epoch 5, gen_loss = 1.2347669987543393, disc_loss = 0.054598117354212834
Trained batch 494 in epoch 5, gen_loss = 1.2338711200338421, disc_loss = 0.05471518079731425
Trained batch 495 in epoch 5, gen_loss = 1.2335178783584027, disc_loss = 0.05467435044016794
Trained batch 496 in epoch 5, gen_loss = 1.233734043431234, disc_loss = 0.05470156701988123
Trained batch 497 in epoch 5, gen_loss = 1.2335639104067562, disc_loss = 0.05463192763927217
Trained batch 498 in epoch 5, gen_loss = 1.2328150495737493, disc_loss = 0.05482917079815869
Trained batch 499 in epoch 5, gen_loss = 1.2320723484754563, disc_loss = 0.05481362015148625
Trained batch 500 in epoch 5, gen_loss = 1.2328500970157084, disc_loss = 0.05473646865237482
Trained batch 501 in epoch 5, gen_loss = 1.233818142656311, disc_loss = 0.05469966574573882
Trained batch 502 in epoch 5, gen_loss = 1.2329424829416673, disc_loss = 0.054790709265387406
Trained batch 503 in epoch 5, gen_loss = 1.232651991858369, disc_loss = 0.0547506550547763
Trained batch 504 in epoch 5, gen_loss = 1.2331765202012392, disc_loss = 0.054797646286666835
Trained batch 505 in epoch 5, gen_loss = 1.2323462701597703, disc_loss = 0.0549714199535129
Trained batch 506 in epoch 5, gen_loss = 1.2315775307677908, disc_loss = 0.05508881669328043
Trained batch 507 in epoch 5, gen_loss = 1.232099446138059, disc_loss = 0.055055036364896885
Trained batch 508 in epoch 5, gen_loss = 1.2335599203006693, disc_loss = 0.055176163543736625
Trained batch 509 in epoch 5, gen_loss = 1.233072041647107, disc_loss = 0.05518196377236688
Trained batch 510 in epoch 5, gen_loss = 1.2328187027789375, disc_loss = 0.05512868028467634
Trained batch 511 in epoch 5, gen_loss = 1.2328740962548181, disc_loss = 0.0551483861795532
Trained batch 512 in epoch 5, gen_loss = 1.2322046798572206, disc_loss = 0.05515820238345301
Trained batch 513 in epoch 5, gen_loss = 1.231463031778076, disc_loss = 0.055164014211681885
Trained batch 514 in epoch 5, gen_loss = 1.2312166757953977, disc_loss = 0.05526207912017058
Trained batch 515 in epoch 5, gen_loss = 1.2324890713821086, disc_loss = 0.05552777160787522
Trained batch 516 in epoch 5, gen_loss = 1.2314041714603712, disc_loss = 0.05573112733177552
Trained batch 517 in epoch 5, gen_loss = 1.2308454777052964, disc_loss = 0.0556799303717789
Trained batch 518 in epoch 5, gen_loss = 1.230976484988696, disc_loss = 0.05560220064826826
Trained batch 519 in epoch 5, gen_loss = 1.23131911192949, disc_loss = 0.05564176364613769
Trained batch 520 in epoch 5, gen_loss = 1.2311679174026007, disc_loss = 0.05561568272289339
Trained batch 521 in epoch 5, gen_loss = 1.2312039181418803, disc_loss = 0.05552952440403816
Trained batch 522 in epoch 5, gen_loss = 1.2313829132749292, disc_loss = 0.055452369042649066
Trained batch 523 in epoch 5, gen_loss = 1.2312772329754502, disc_loss = 0.05537018813290598
Trained batch 524 in epoch 5, gen_loss = 1.2301183441707066, disc_loss = 0.05555538077395232
Trained batch 525 in epoch 5, gen_loss = 1.230836567769939, disc_loss = 0.05559604815357921
Trained batch 526 in epoch 5, gen_loss = 1.2309615150574715, disc_loss = 0.05551003916692731
Trained batch 527 in epoch 5, gen_loss = 1.230448112004634, disc_loss = 0.05547944685244919
Trained batch 528 in epoch 5, gen_loss = 1.2303755992076348, disc_loss = 0.05542392564263188
Trained batch 529 in epoch 5, gen_loss = 1.2313520985954212, disc_loss = 0.05538283505274932
Trained batch 530 in epoch 5, gen_loss = 1.23153921316348, disc_loss = 0.0553016814130504
Trained batch 531 in epoch 5, gen_loss = 1.231142203946759, disc_loss = 0.05524824124444066
Trained batch 532 in epoch 5, gen_loss = 1.231115543484464, disc_loss = 0.05520675980964742
Trained batch 533 in epoch 5, gen_loss = 1.2307519324486622, disc_loss = 0.055162830944068396
Trained batch 534 in epoch 5, gen_loss = 1.2300894746156497, disc_loss = 0.05519841231501479
Trained batch 535 in epoch 5, gen_loss = 1.2316494828729487, disc_loss = 0.055235331269491934
Trained batch 536 in epoch 5, gen_loss = 1.231461849070572, disc_loss = 0.05519505426091675
Trained batch 537 in epoch 5, gen_loss = 1.2315993173858046, disc_loss = 0.055378418328797925
Trained batch 538 in epoch 5, gen_loss = 1.2314573544075846, disc_loss = 0.05540722197635317
Trained batch 539 in epoch 5, gen_loss = 1.2311735248124158, disc_loss = 0.055362350482890316
Trained batch 540 in epoch 5, gen_loss = 1.2313910383393716, disc_loss = 0.055510518362731874
Trained batch 541 in epoch 5, gen_loss = 1.2307275546872747, disc_loss = 0.05569879200981373
Trained batch 542 in epoch 5, gen_loss = 1.2303601040146408, disc_loss = 0.0556971689726485
Trained batch 543 in epoch 5, gen_loss = 1.2296262100777204, disc_loss = 0.05589149200985797
Trained batch 544 in epoch 5, gen_loss = 1.2290468926823468, disc_loss = 0.055952878422402874
Trained batch 545 in epoch 5, gen_loss = 1.2289197894679758, disc_loss = 0.05599548012971701
Trained batch 546 in epoch 5, gen_loss = 1.2287931128437384, disc_loss = 0.05610996307983954
Trained batch 547 in epoch 5, gen_loss = 1.2283342380593294, disc_loss = 0.05608618348780815
Trained batch 548 in epoch 5, gen_loss = 1.2276433405546108, disc_loss = 0.05610191064398186
Trained batch 549 in epoch 5, gen_loss = 1.2278110648285259, disc_loss = 0.05604130086192692
Trained batch 550 in epoch 5, gen_loss = 1.2282859990254937, disc_loss = 0.05605007792880485
Trained batch 551 in epoch 5, gen_loss = 1.2281049076413764, disc_loss = 0.055996405915272815
Trained batch 552 in epoch 5, gen_loss = 1.2274421859822264, disc_loss = 0.05626216752725783
Trained batch 553 in epoch 5, gen_loss = 1.2263302098327595, disc_loss = 0.05634945627959237
Trained batch 554 in epoch 5, gen_loss = 1.2259072377875044, disc_loss = 0.056320844130456314
Trained batch 555 in epoch 5, gen_loss = 1.225750963572118, disc_loss = 0.056285933004742446
Trained batch 556 in epoch 5, gen_loss = 1.2258210940891794, disc_loss = 0.05624338786813298
Trained batch 557 in epoch 5, gen_loss = 1.2261375800896717, disc_loss = 0.0561587503259187
Trained batch 558 in epoch 5, gen_loss = 1.2259701491468495, disc_loss = 0.056135397182430984
Trained batch 559 in epoch 5, gen_loss = 1.2261317762945378, disc_loss = 0.05604581427885153
Trained batch 560 in epoch 5, gen_loss = 1.2264934479659042, disc_loss = 0.055964816077371624
Trained batch 561 in epoch 5, gen_loss = 1.2268668524523223, disc_loss = 0.05588417929254167
Trained batch 562 in epoch 5, gen_loss = 1.2264832909323182, disc_loss = 0.055838242551596376
Trained batch 563 in epoch 5, gen_loss = 1.2269413091823564, disc_loss = 0.05577511847116621
Trained batch 564 in epoch 5, gen_loss = 1.2267308204574923, disc_loss = 0.05571909402579531
Trained batch 565 in epoch 5, gen_loss = 1.2284051835958192, disc_loss = 0.055763859691364895
Trained batch 566 in epoch 5, gen_loss = 1.2280037517690574, disc_loss = 0.056008432101133085
Trained batch 567 in epoch 5, gen_loss = 1.2271282489241009, disc_loss = 0.05609050960547265
Trained batch 568 in epoch 5, gen_loss = 1.2272805179778636, disc_loss = 0.05600522487974269
Trained batch 569 in epoch 5, gen_loss = 1.2271902668894383, disc_loss = 0.05594108880440329
Trained batch 570 in epoch 5, gen_loss = 1.2271873294367681, disc_loss = 0.055903673706569706
Trained batch 571 in epoch 5, gen_loss = 1.2271011218532815, disc_loss = 0.055838172948818286
Trained batch 572 in epoch 5, gen_loss = 1.2278395927597299, disc_loss = 0.0557889337948057
Trained batch 573 in epoch 5, gen_loss = 1.2287960828181343, disc_loss = 0.05582766931216826
Trained batch 574 in epoch 5, gen_loss = 1.2283908070688663, disc_loss = 0.05589611976650422
Trained batch 575 in epoch 5, gen_loss = 1.228169085457921, disc_loss = 0.05584107354217041
Trained batch 576 in epoch 5, gen_loss = 1.2289240955273448, disc_loss = 0.05577537689827693
Trained batch 577 in epoch 5, gen_loss = 1.2293814666130964, disc_loss = 0.05571753376326282
Trained batch 578 in epoch 5, gen_loss = 1.2286057519583298, disc_loss = 0.05575835005386647
Trained batch 579 in epoch 5, gen_loss = 1.2286392978553113, disc_loss = 0.055764405396847246
Trained batch 580 in epoch 5, gen_loss = 1.2285812448921793, disc_loss = 0.05574025711879814
Trained batch 581 in epoch 5, gen_loss = 1.2287088560894184, disc_loss = 0.05566205425608801
Trained batch 582 in epoch 5, gen_loss = 1.2279064698243836, disc_loss = 0.055712331764920776
Trained batch 583 in epoch 5, gen_loss = 1.2277671121162912, disc_loss = 0.055674376751994714
Trained batch 584 in epoch 5, gen_loss = 1.2284971675302228, disc_loss = 0.05588096473963024
Trained batch 585 in epoch 5, gen_loss = 1.2286257404109318, disc_loss = 0.05580588146756521
Trained batch 586 in epoch 5, gen_loss = 1.2280258939457103, disc_loss = 0.05584780571171522
Trained batch 587 in epoch 5, gen_loss = 1.2269593742834468, disc_loss = 0.056102429992965976
Trained batch 588 in epoch 5, gen_loss = 1.226678519783279, disc_loss = 0.05622024989864
Trained batch 589 in epoch 5, gen_loss = 1.2289892004708112, disc_loss = 0.0564135628117059
Trained batch 590 in epoch 5, gen_loss = 1.2297952286079652, disc_loss = 0.05637592870337091
Trained batch 591 in epoch 5, gen_loss = 1.2287141495459788, disc_loss = 0.05655855923455297
Trained batch 592 in epoch 5, gen_loss = 1.228624223054561, disc_loss = 0.056480607342581195
Trained batch 593 in epoch 5, gen_loss = 1.2286954285319807, disc_loss = 0.056484371644400864
Trained batch 594 in epoch 5, gen_loss = 1.228342620464934, disc_loss = 0.056439447692133674
Trained batch 595 in epoch 5, gen_loss = 1.2289237708053333, disc_loss = 0.05651646466330381
Trained batch 596 in epoch 5, gen_loss = 1.228280907100569, disc_loss = 0.056559345606555365
Trained batch 597 in epoch 5, gen_loss = 1.228024262847709, disc_loss = 0.05650055744369081
Trained batch 598 in epoch 5, gen_loss = 1.228486069056745, disc_loss = 0.056573984352716294
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.9295945167541504, disc_loss = 0.05236829072237015
Trained batch 1 in epoch 6, gen_loss = 0.9711402654647827, disc_loss = 0.15618427470326424
Trained batch 2 in epoch 6, gen_loss = 0.9361661672592163, disc_loss = 0.1564781591296196
Trained batch 3 in epoch 6, gen_loss = 0.839907705783844, disc_loss = 0.17470856942236423
Trained batch 4 in epoch 6, gen_loss = 0.8832527160644531, disc_loss = 0.15676329284906387
Trained batch 5 in epoch 6, gen_loss = 0.9018825689951578, disc_loss = 0.14281776174902916
Trained batch 6 in epoch 6, gen_loss = 0.9341057198388236, disc_loss = 0.14236664239849364
Trained batch 7 in epoch 6, gen_loss = 0.9618483930826187, disc_loss = 0.12680857023224235
Trained batch 8 in epoch 6, gen_loss = 0.986193060874939, disc_loss = 0.11441921049522029
Trained batch 9 in epoch 6, gen_loss = 1.030056929588318, disc_loss = 0.10493097137659788
Trained batch 10 in epoch 6, gen_loss = 1.0304769277572632, disc_loss = 0.09852069667117162
Trained batch 11 in epoch 6, gen_loss = 1.05649330218633, disc_loss = 0.1164858693567415
Trained batch 12 in epoch 6, gen_loss = 1.029588832305028, disc_loss = 0.11995898115520294
Trained batch 13 in epoch 6, gen_loss = 1.0282945420060838, disc_loss = 0.11509237185652767
Trained batch 14 in epoch 6, gen_loss = 1.0489289005597433, disc_loss = 0.11409185789525508
Trained batch 15 in epoch 6, gen_loss = 1.0697929300367832, disc_loss = 0.10870472865644842
Trained batch 16 in epoch 6, gen_loss = 1.082961429567898, disc_loss = 0.10363285868045162
Trained batch 17 in epoch 6, gen_loss = 1.0938190718491871, disc_loss = 0.09861913820107777
Trained batch 18 in epoch 6, gen_loss = 1.089941065562399, disc_loss = 0.09469696575481641
Trained batch 19 in epoch 6, gen_loss = 1.11181900203228, disc_loss = 0.09072436569258571
Trained batch 20 in epoch 6, gen_loss = 1.1212502462523324, disc_loss = 0.08682754813205629
Trained batch 21 in epoch 6, gen_loss = 1.136692244898189, disc_loss = 0.08371751179749315
Trained batch 22 in epoch 6, gen_loss = 1.1437066093735073, disc_loss = 0.08061926164056944
Trained batch 23 in epoch 6, gen_loss = 1.1412304565310478, disc_loss = 0.07797390276876588
Trained batch 24 in epoch 6, gen_loss = 1.1310241150856017, disc_loss = 0.07634575672447681
Trained batch 25 in epoch 6, gen_loss = 1.126906883258086, disc_loss = 0.07420464461812606
Trained batch 26 in epoch 6, gen_loss = 1.112667977809906, disc_loss = 0.07678245532291907
Trained batch 27 in epoch 6, gen_loss = 1.1475056260824203, disc_loss = 0.077662821326937
Trained batch 28 in epoch 6, gen_loss = 1.1645350970070938, disc_loss = 0.07598317729244972
Trained batch 29 in epoch 6, gen_loss = 1.1600039899349213, disc_loss = 0.07456658004472654
Trained batch 30 in epoch 6, gen_loss = 1.1514174842065381, disc_loss = 0.07457097926207128
Trained batch 31 in epoch 6, gen_loss = 1.158798260614276, disc_loss = 0.07297366805141792
Trained batch 32 in epoch 6, gen_loss = 1.1646043911124722, disc_loss = 0.07234458518073414
Trained batch 33 in epoch 6, gen_loss = 1.1537763318594765, disc_loss = 0.07239915961947511
Trained batch 34 in epoch 6, gen_loss = 1.1414342369352068, disc_loss = 0.07526902902339186
Trained batch 35 in epoch 6, gen_loss = 1.1470529205269284, disc_loss = 0.07342404008118643
Trained batch 36 in epoch 6, gen_loss = 1.157525304201487, disc_loss = 0.07209300677719954
Trained batch 37 in epoch 6, gen_loss = 1.1522092536876076, disc_loss = 0.07101734585471843
Trained batch 38 in epoch 6, gen_loss = 1.156665624716343, disc_loss = 0.06939809836256199
Trained batch 39 in epoch 6, gen_loss = 1.1702824592590333, disc_loss = 0.06892883479595184
Trained batch 40 in epoch 6, gen_loss = 1.1631353541118343, disc_loss = 0.06852349339098465
Trained batch 41 in epoch 6, gen_loss = 1.1628779513495309, disc_loss = 0.06740996773753848
Trained batch 42 in epoch 6, gen_loss = 1.1565716363662897, disc_loss = 0.06689469083104023
Trained batch 43 in epoch 6, gen_loss = 1.1502928611907093, disc_loss = 0.06675179573622617
Trained batch 44 in epoch 6, gen_loss = 1.1643448525004916, disc_loss = 0.06837013198269738
Trained batch 45 in epoch 6, gen_loss = 1.1728218677251234, disc_loss = 0.06708242402047566
Trained batch 46 in epoch 6, gen_loss = 1.1616312937533602, disc_loss = 0.06903055926507458
Trained batch 47 in epoch 6, gen_loss = 1.1647029854357243, disc_loss = 0.06792101688915864
Trained batch 48 in epoch 6, gen_loss = 1.1608024847750762, disc_loss = 0.06749226736398983
Trained batch 49 in epoch 6, gen_loss = 1.1670995795726775, disc_loss = 0.06668181722983718
Trained batch 50 in epoch 6, gen_loss = 1.167164062752443, disc_loss = 0.06592973177412562
Trained batch 51 in epoch 6, gen_loss = 1.170429141475604, disc_loss = 0.0648026681290223
Trained batch 52 in epoch 6, gen_loss = 1.1639074705681711, disc_loss = 0.06491803026424264
Trained batch 53 in epoch 6, gen_loss = 1.174875291409316, disc_loss = 0.0643885933138706
Trained batch 54 in epoch 6, gen_loss = 1.1763104102828286, disc_loss = 0.06376597840677609
Trained batch 55 in epoch 6, gen_loss = 1.1714224783437592, disc_loss = 0.06378668413630553
Trained batch 56 in epoch 6, gen_loss = 1.1835052559250279, disc_loss = 0.06468012458399723
Trained batch 57 in epoch 6, gen_loss = 1.188889705929263, disc_loss = 0.06368589790634296
Trained batch 58 in epoch 6, gen_loss = 1.179444507016974, disc_loss = 0.06558214182476119
Trained batch 59 in epoch 6, gen_loss = 1.1811269025007884, disc_loss = 0.06533089842802535
Trained batch 60 in epoch 6, gen_loss = 1.1846777142071334, disc_loss = 0.06464263168545287
Trained batch 61 in epoch 6, gen_loss = 1.180694745432946, disc_loss = 0.06456107136252667
Trained batch 62 in epoch 6, gen_loss = 1.1770689591528878, disc_loss = 0.0643185407943314
Trained batch 63 in epoch 6, gen_loss = 1.1786770662292838, disc_loss = 0.06630123919603648
Trained batch 64 in epoch 6, gen_loss = 1.1740688479863681, disc_loss = 0.06598481817457538
Trained batch 65 in epoch 6, gen_loss = 1.1701479897354587, disc_loss = 0.06596313965168189
Trained batch 66 in epoch 6, gen_loss = 1.166599919546896, disc_loss = 0.06563862502825127
Trained batch 67 in epoch 6, gen_loss = 1.176536153344547, disc_loss = 0.06541162182111293
Trained batch 68 in epoch 6, gen_loss = 1.1750192624935205, disc_loss = 0.06473861157597191
Trained batch 69 in epoch 6, gen_loss = 1.1727000594139099, disc_loss = 0.06458846126416964
Trained batch 70 in epoch 6, gen_loss = 1.1793666910117782, disc_loss = 0.06714391129248788
Trained batch 71 in epoch 6, gen_loss = 1.1760198457373514, disc_loss = 0.0669924112670641
Trained batch 72 in epoch 6, gen_loss = 1.1713963942985013, disc_loss = 0.06713621438901922
Trained batch 73 in epoch 6, gen_loss = 1.177432973642607, disc_loss = 0.06740177108755184
Trained batch 74 in epoch 6, gen_loss = 1.1765420039494832, disc_loss = 0.06754647382224599
Trained batch 75 in epoch 6, gen_loss = 1.1693902250967527, disc_loss = 0.06893843106655895
Trained batch 76 in epoch 6, gen_loss = 1.1738875283823385, disc_loss = 0.0683708504483394
Trained batch 77 in epoch 6, gen_loss = 1.1730201167938037, disc_loss = 0.06773177895527811
Trained batch 78 in epoch 6, gen_loss = 1.1818628069720691, disc_loss = 0.06738284954659735
Trained batch 79 in epoch 6, gen_loss = 1.181577132642269, disc_loss = 0.06749584198114462
Trained batch 80 in epoch 6, gen_loss = 1.1843518489672813, disc_loss = 0.06679444880236263
Trained batch 81 in epoch 6, gen_loss = 1.181605477885502, disc_loss = 0.0665262320203843
Trained batch 82 in epoch 6, gen_loss = 1.1815934949610607, disc_loss = 0.06585881887677025
Trained batch 83 in epoch 6, gen_loss = 1.186594532359214, disc_loss = 0.06585968500335834
Trained batch 84 in epoch 6, gen_loss = 1.1911418388871586, disc_loss = 0.06538909072713817
Trained batch 85 in epoch 6, gen_loss = 1.1876837930013968, disc_loss = 0.06547004750626552
Trained batch 86 in epoch 6, gen_loss = 1.1924095236021897, disc_loss = 0.06493216491272223
Trained batch 87 in epoch 6, gen_loss = 1.1959886794740504, disc_loss = 0.06445159995399247
Trained batch 88 in epoch 6, gen_loss = 1.1969413502832478, disc_loss = 0.06396528743102811
Trained batch 89 in epoch 6, gen_loss = 1.1967948052618238, disc_loss = 0.0634158076149308
Trained batch 90 in epoch 6, gen_loss = 1.1951004345338423, disc_loss = 0.06294822095698871
Trained batch 91 in epoch 6, gen_loss = 1.1985163286976193, disc_loss = 0.06264473081303193
Trained batch 92 in epoch 6, gen_loss = 1.2027611181300173, disc_loss = 0.062066297953127215
Trained batch 93 in epoch 6, gen_loss = 1.2040834236652294, disc_loss = 0.061606866342233536
Trained batch 94 in epoch 6, gen_loss = 1.2060102098866512, disc_loss = 0.061020984162429445
Trained batch 95 in epoch 6, gen_loss = 1.2030032736559708, disc_loss = 0.060918587235695064
Trained batch 96 in epoch 6, gen_loss = 1.2106377205897851, disc_loss = 0.06168385262399451
Trained batch 97 in epoch 6, gen_loss = 1.2085717125814788, disc_loss = 0.06131968181105141
Trained batch 98 in epoch 6, gen_loss = 1.2105820889424797, disc_loss = 0.06078624747448949
Trained batch 99 in epoch 6, gen_loss = 1.2072334420681, disc_loss = 0.060679094302468005
Trained batch 100 in epoch 6, gen_loss = 1.207436480144463, disc_loss = 0.06114670991584068
Trained batch 101 in epoch 6, gen_loss = 1.2031016595223372, disc_loss = 0.061538781272247434
Trained batch 102 in epoch 6, gen_loss = 1.2051674220168476, disc_loss = 0.06125398681417686
Trained batch 103 in epoch 6, gen_loss = 1.2007530194062452, disc_loss = 0.06175434818186869
Trained batch 104 in epoch 6, gen_loss = 1.205758736247108, disc_loss = 0.06238791090658023
Trained batch 105 in epoch 6, gen_loss = 1.2023416408952676, disc_loss = 0.06257697074884935
Trained batch 106 in epoch 6, gen_loss = 1.2069637051252562, disc_loss = 0.06240534869013963
Trained batch 107 in epoch 6, gen_loss = 1.2098025491944067, disc_loss = 0.06194414805914103
Trained batch 108 in epoch 6, gen_loss = 1.2075501718652357, disc_loss = 0.0618525375782965
Trained batch 109 in epoch 6, gen_loss = 1.204862688888203, disc_loss = 0.061951213401996275
Trained batch 110 in epoch 6, gen_loss = 1.2042792928111445, disc_loss = 0.061689805243634155
Trained batch 111 in epoch 6, gen_loss = 1.2107000148722105, disc_loss = 0.06154099765782511
Trained batch 112 in epoch 6, gen_loss = 1.2147052193109968, disc_loss = 0.06118978382360223
Trained batch 113 in epoch 6, gen_loss = 1.214228187736712, disc_loss = 0.060829384321869726
Trained batch 114 in epoch 6, gen_loss = 1.2130841296652088, disc_loss = 0.060532507919908864
Trained batch 115 in epoch 6, gen_loss = 1.2149667986508073, disc_loss = 0.06016402040078337
Trained batch 116 in epoch 6, gen_loss = 1.2146332019414656, disc_loss = 0.059819630645693116
Trained batch 117 in epoch 6, gen_loss = 1.2169734421422926, disc_loss = 0.05945356692566331
Trained batch 118 in epoch 6, gen_loss = 1.2217074712785352, disc_loss = 0.05919272875601128
Trained batch 119 in epoch 6, gen_loss = 1.2174555346369744, disc_loss = 0.05940284540023034
Trained batch 120 in epoch 6, gen_loss = 1.2184800692826263, disc_loss = 0.05954354056657469
Trained batch 121 in epoch 6, gen_loss = 1.221078955247754, disc_loss = 0.05917565696720095
Trained batch 122 in epoch 6, gen_loss = 1.222747522156413, disc_loss = 0.0589605587519463
Trained batch 123 in epoch 6, gen_loss = 1.2221242473010094, disc_loss = 0.05873539531227922
Trained batch 124 in epoch 6, gen_loss = 1.2227147192955017, disc_loss = 0.05848770780488849
Trained batch 125 in epoch 6, gen_loss = 1.22572698999965, disc_loss = 0.05811537529844495
Trained batch 126 in epoch 6, gen_loss = 1.2258855841291232, disc_loss = 0.05771739265008822
Trained batch 127 in epoch 6, gen_loss = 1.232168538030237, disc_loss = 0.05787255673567415
Trained batch 128 in epoch 6, gen_loss = 1.2309646971466006, disc_loss = 0.057680200009296335
Trained batch 129 in epoch 6, gen_loss = 1.2312928983798395, disc_loss = 0.05734792266112681
Trained batch 130 in epoch 6, gen_loss = 1.2311651010549705, disc_loss = 0.05698054998700742
Trained batch 131 in epoch 6, gen_loss = 1.2326575440890861, disc_loss = 0.05661743251028273
Trained batch 132 in epoch 6, gen_loss = 1.2316623410784213, disc_loss = 0.056367735676047276
Trained batch 133 in epoch 6, gen_loss = 1.231945190411895, disc_loss = 0.05661899508533082
Trained batch 134 in epoch 6, gen_loss = 1.2338940598346568, disc_loss = 0.056315101493425945
Trained batch 135 in epoch 6, gen_loss = 1.2317830372382612, disc_loss = 0.05619699346682276
Trained batch 136 in epoch 6, gen_loss = 1.232377965519898, disc_loss = 0.05607930862134064
Trained batch 137 in epoch 6, gen_loss = 1.2321777823178663, disc_loss = 0.05579903700550937
Trained batch 138 in epoch 6, gen_loss = 1.2308503144936596, disc_loss = 0.055563871986601204
Trained batch 139 in epoch 6, gen_loss = 1.2315034845045634, disc_loss = 0.05521319816221616
Trained batch 140 in epoch 6, gen_loss = 1.2293514575518616, disc_loss = 0.05524296407647272
Trained batch 141 in epoch 6, gen_loss = 1.2350937761891057, disc_loss = 0.05534862788905665
Trained batch 142 in epoch 6, gen_loss = 1.234536021322637, disc_loss = 0.05536511719187761
Trained batch 143 in epoch 6, gen_loss = 1.232350634617938, disc_loss = 0.05536174191123185
Trained batch 144 in epoch 6, gen_loss = 1.2327383686756266, disc_loss = 0.055185864470770646
Trained batch 145 in epoch 6, gen_loss = 1.2303220846065104, disc_loss = 0.05560092007014135
Trained batch 146 in epoch 6, gen_loss = 1.2325840040940006, disc_loss = 0.05530550658107311
Trained batch 147 in epoch 6, gen_loss = 1.2344649760304272, disc_loss = 0.05498230751490573
Trained batch 148 in epoch 6, gen_loss = 1.2329285836859838, disc_loss = 0.05483238356212942
Trained batch 149 in epoch 6, gen_loss = 1.2353879662354788, disc_loss = 0.05455407678770522
Trained batch 150 in epoch 6, gen_loss = 1.2339903680694024, disc_loss = 0.05470085301627683
Trained batch 151 in epoch 6, gen_loss = 1.2354822343117313, disc_loss = 0.054382674864762906
Trained batch 152 in epoch 6, gen_loss = 1.2354446302831563, disc_loss = 0.05411850369164075
Trained batch 153 in epoch 6, gen_loss = 1.236210477429551, disc_loss = 0.05387985692117605
Trained batch 154 in epoch 6, gen_loss = 1.2347997353922937, disc_loss = 0.053722709852961764
Trained batch 155 in epoch 6, gen_loss = 1.2339495653525376, disc_loss = 0.05357265735391337
Trained batch 156 in epoch 6, gen_loss = 1.2345184903995248, disc_loss = 0.05330572274044915
Trained batch 157 in epoch 6, gen_loss = 1.2380301035657715, disc_loss = 0.05340434673619516
Trained batch 158 in epoch 6, gen_loss = 1.2417381893163957, disc_loss = 0.05325478308617412
Trained batch 159 in epoch 6, gen_loss = 1.2412082690745592, disc_loss = 0.053208279868704265
Trained batch 160 in epoch 6, gen_loss = 1.2414299001604874, disc_loss = 0.05295936189742285
Trained batch 161 in epoch 6, gen_loss = 1.241947333385915, disc_loss = 0.05268762020658656
Trained batch 162 in epoch 6, gen_loss = 1.2389552553007208, disc_loss = 0.05328444824868276
Trained batch 163 in epoch 6, gen_loss = 1.2397127060628519, disc_loss = 0.05319971290541949
Trained batch 164 in epoch 6, gen_loss = 1.239045967838981, disc_loss = 0.053545090637988214
Trained batch 165 in epoch 6, gen_loss = 1.2393802163830723, disc_loss = 0.05329254467365702
Trained batch 166 in epoch 6, gen_loss = 1.2397867266289488, disc_loss = 0.0530111094027713
Trained batch 167 in epoch 6, gen_loss = 1.239224860001178, disc_loss = 0.0527870317095048
Trained batch 168 in epoch 6, gen_loss = 1.2380780725789493, disc_loss = 0.05261683677593191
Trained batch 169 in epoch 6, gen_loss = 1.2389880471369799, disc_loss = 0.05235864655662547
Trained batch 170 in epoch 6, gen_loss = 1.2400285022997717, disc_loss = 0.052109053382944116
Trained batch 171 in epoch 6, gen_loss = 1.243394064002259, disc_loss = 0.051960963791041356
Trained batch 172 in epoch 6, gen_loss = 1.2410450722440818, disc_loss = 0.05202124262702344
Trained batch 173 in epoch 6, gen_loss = 1.2417194346586864, disc_loss = 0.05183844528717642
Trained batch 174 in epoch 6, gen_loss = 1.2426112369128637, disc_loss = 0.052172953648758784
Trained batch 175 in epoch 6, gen_loss = 1.2411996353078971, disc_loss = 0.052023989182833415
Trained batch 176 in epoch 6, gen_loss = 1.2410762468300296, disc_loss = 0.05184433421141094
Trained batch 177 in epoch 6, gen_loss = 1.238577288523149, disc_loss = 0.05210060326204625
Trained batch 178 in epoch 6, gen_loss = 1.239011975973012, disc_loss = 0.05205831844515724
Trained batch 179 in epoch 6, gen_loss = 1.2394042674038146, disc_loss = 0.05197513162727571
Trained batch 180 in epoch 6, gen_loss = 1.2363218862707444, disc_loss = 0.05241936611176278
Trained batch 181 in epoch 6, gen_loss = 1.2372486673213623, disc_loss = 0.05263229943863065
Trained batch 182 in epoch 6, gen_loss = 1.2373303757990644, disc_loss = 0.05243635685768365
Trained batch 183 in epoch 6, gen_loss = 1.2375147274654845, disc_loss = 0.052383887614427214
Trained batch 184 in epoch 6, gen_loss = 1.236656366490029, disc_loss = 0.05252866623419765
Trained batch 185 in epoch 6, gen_loss = 1.2347541749477386, disc_loss = 0.05255645949403525
Trained batch 186 in epoch 6, gen_loss = 1.2349687263289875, disc_loss = 0.05237527623184942
Trained batch 187 in epoch 6, gen_loss = 1.237469362768721, disc_loss = 0.05236972883551758
Trained batch 188 in epoch 6, gen_loss = 1.2388034052949735, disc_loss = 0.05215916735558677
Trained batch 189 in epoch 6, gen_loss = 1.2387560446011392, disc_loss = 0.05193201757134183
Trained batch 190 in epoch 6, gen_loss = 1.2386625665020567, disc_loss = 0.05173092189912943
Trained batch 191 in epoch 6, gen_loss = 1.2373777811105053, disc_loss = 0.05169260795567728
Trained batch 192 in epoch 6, gen_loss = 1.240625751142057, disc_loss = 0.05200790543196038
Trained batch 193 in epoch 6, gen_loss = 1.238072749572931, disc_loss = 0.05212237592546519
Trained batch 194 in epoch 6, gen_loss = 1.2375510995204633, disc_loss = 0.051941687066872154
Trained batch 195 in epoch 6, gen_loss = 1.2383548772456694, disc_loss = 0.051712071430413245
Trained batch 196 in epoch 6, gen_loss = 1.2392493108202358, disc_loss = 0.05153202721470882
Trained batch 197 in epoch 6, gen_loss = 1.242347966841977, disc_loss = 0.051417219755945334
Trained batch 198 in epoch 6, gen_loss = 1.2420747115384394, disc_loss = 0.05142988630771712
Trained batch 199 in epoch 6, gen_loss = 1.2399446365237237, disc_loss = 0.051621908389497546
Trained batch 200 in epoch 6, gen_loss = 1.2411583089709874, disc_loss = 0.051396585514407546
Trained batch 201 in epoch 6, gen_loss = 1.2400132438333908, disc_loss = 0.05133466792781607
Trained batch 202 in epoch 6, gen_loss = 1.2398158455717152, disc_loss = 0.05133067276512314
Trained batch 203 in epoch 6, gen_loss = 1.2401705194337695, disc_loss = 0.05183931578443769
Trained batch 204 in epoch 6, gen_loss = 1.2391131526086387, disc_loss = 0.05217505998273448
Trained batch 205 in epoch 6, gen_loss = 1.23674729437504, disc_loss = 0.05249165305506113
Trained batch 206 in epoch 6, gen_loss = 1.2338379437220846, disc_loss = 0.052794825731088284
Trained batch 207 in epoch 6, gen_loss = 1.2347937375307083, disc_loss = 0.0535233043304358
Trained batch 208 in epoch 6, gen_loss = 1.232933025040695, disc_loss = 0.053556776249059364
Trained batch 209 in epoch 6, gen_loss = 1.2331981375103904, disc_loss = 0.05337200726692875
Trained batch 210 in epoch 6, gen_loss = 1.2320418764629635, disc_loss = 0.05360095786875317
Trained batch 211 in epoch 6, gen_loss = 1.230835330936144, disc_loss = 0.05356224407969078
Trained batch 212 in epoch 6, gen_loss = 1.2290795134826444, disc_loss = 0.05387987636746795
Trained batch 213 in epoch 6, gen_loss = 1.2318037419675667, disc_loss = 0.055035550177758824
Trained batch 214 in epoch 6, gen_loss = 1.2307692843814229, disc_loss = 0.055096347521730635
Trained batch 215 in epoch 6, gen_loss = 1.229150799965417, disc_loss = 0.055280403195259474
Trained batch 216 in epoch 6, gen_loss = 1.2297611393137462, disc_loss = 0.05516187281429356
Trained batch 217 in epoch 6, gen_loss = 1.230299897423578, disc_loss = 0.05522788389064713
Trained batch 218 in epoch 6, gen_loss = 1.2299612485654823, disc_loss = 0.05510869623506314
Trained batch 219 in epoch 6, gen_loss = 1.229634504155679, disc_loss = 0.054946199190718206
Trained batch 220 in epoch 6, gen_loss = 1.227448368773741, disc_loss = 0.05509497558622204
Trained batch 221 in epoch 6, gen_loss = 1.2281271705219337, disc_loss = 0.05493363840841092
Trained batch 222 in epoch 6, gen_loss = 1.2288012913524302, disc_loss = 0.05659010106355219
Trained batch 223 in epoch 6, gen_loss = 1.226638263091445, disc_loss = 0.05687624490903025
Trained batch 224 in epoch 6, gen_loss = 1.2272559189796448, disc_loss = 0.056699310743974315
Trained batch 225 in epoch 6, gen_loss = 1.2265961811078334, disc_loss = 0.056877472763468995
Trained batch 226 in epoch 6, gen_loss = 1.2252984732258163, disc_loss = 0.05702448170632124
Trained batch 227 in epoch 6, gen_loss = 1.223082125448344, disc_loss = 0.05724477787959602
Trained batch 228 in epoch 6, gen_loss = 1.2230531047525364, disc_loss = 0.05723366912812255
Trained batch 229 in epoch 6, gen_loss = 1.2242839893569117, disc_loss = 0.05709891028135367
Trained batch 230 in epoch 6, gen_loss = 1.2252882850634588, disc_loss = 0.05691126615083192
Trained batch 231 in epoch 6, gen_loss = 1.2237005411037083, disc_loss = 0.057050636267000486
Trained batch 232 in epoch 6, gen_loss = 1.22423360608678, disc_loss = 0.0568808568321776
Trained batch 233 in epoch 6, gen_loss = 1.2256897680270367, disc_loss = 0.05667917926708221
Trained batch 234 in epoch 6, gen_loss = 1.2260260351160739, disc_loss = 0.05660047343674492
Trained batch 235 in epoch 6, gen_loss = 1.2257053213099303, disc_loss = 0.05642093014035184
Trained batch 236 in epoch 6, gen_loss = 1.2257820641944177, disc_loss = 0.056225538532787986
Trained batch 237 in epoch 6, gen_loss = 1.2246232811643296, disc_loss = 0.05620276725639691
Trained batch 238 in epoch 6, gen_loss = 1.2247881777116942, disc_loss = 0.05618957612102376
Trained batch 239 in epoch 6, gen_loss = 1.223786947876215, disc_loss = 0.056112385739106686
Trained batch 240 in epoch 6, gen_loss = 1.2231987727133564, disc_loss = 0.056032062778674466
Trained batch 241 in epoch 6, gen_loss = 1.2252255946644082, disc_loss = 0.055886359742942676
Trained batch 242 in epoch 6, gen_loss = 1.2261665070989005, disc_loss = 0.056485828667603155
Trained batch 243 in epoch 6, gen_loss = 1.2259634935953578, disc_loss = 0.05634658062662624
Trained batch 244 in epoch 6, gen_loss = 1.2239711856355473, disc_loss = 0.05652757256234787
Trained batch 245 in epoch 6, gen_loss = 1.2234666868438566, disc_loss = 0.056533300079314446
Trained batch 246 in epoch 6, gen_loss = 1.2247956805383629, disc_loss = 0.05643508401944449
Trained batch 247 in epoch 6, gen_loss = 1.2241831356959958, disc_loss = 0.05633333958910718
Trained batch 248 in epoch 6, gen_loss = 1.2250312210086838, disc_loss = 0.05615466557084078
Trained batch 249 in epoch 6, gen_loss = 1.2249729301929473, disc_loss = 0.05596152233332396
Trained batch 250 in epoch 6, gen_loss = 1.2244100454319047, disc_loss = 0.05589215625893785
Trained batch 251 in epoch 6, gen_loss = 1.2249048728318441, disc_loss = 0.056567706130740664
Trained batch 252 in epoch 6, gen_loss = 1.22343274373782, disc_loss = 0.0565723587534291
Trained batch 253 in epoch 6, gen_loss = 1.2230127137007676, disc_loss = 0.056423321212311896
Trained batch 254 in epoch 6, gen_loss = 1.2214158640188328, disc_loss = 0.05648621775794263
Trained batch 255 in epoch 6, gen_loss = 1.2212222947273403, disc_loss = 0.05659176699555246
Trained batch 256 in epoch 6, gen_loss = 1.2219257477656413, disc_loss = 0.05642238733311571
Trained batch 257 in epoch 6, gen_loss = 1.2224685233230739, disc_loss = 0.05624416183550344
Trained batch 258 in epoch 6, gen_loss = 1.2228823732225131, disc_loss = 0.05609539921780236
Trained batch 259 in epoch 6, gen_loss = 1.2226595266507223, disc_loss = 0.05597102832980454
Trained batch 260 in epoch 6, gen_loss = 1.2238344655183084, disc_loss = 0.05587632811746036
Trained batch 261 in epoch 6, gen_loss = 1.2229766584079684, disc_loss = 0.05581401766611988
Trained batch 262 in epoch 6, gen_loss = 1.2240690285262046, disc_loss = 0.05562658574318818
Trained batch 263 in epoch 6, gen_loss = 1.2249794419516216, disc_loss = 0.05545202152323768
Trained batch 264 in epoch 6, gen_loss = 1.2251675306626086, disc_loss = 0.05528363087829554
Trained batch 265 in epoch 6, gen_loss = 1.2265423605764718, disc_loss = 0.05512179192715794
Trained batch 266 in epoch 6, gen_loss = 1.2286869700481828, disc_loss = 0.055066758599341584
Trained batch 267 in epoch 6, gen_loss = 1.2286596803078011, disc_loss = 0.054957316444714126
Trained batch 268 in epoch 6, gen_loss = 1.2285011787396825, disc_loss = 0.05483799148697171
Trained batch 269 in epoch 6, gen_loss = 1.2281878641358128, disc_loss = 0.054724391680900694
Trained batch 270 in epoch 6, gen_loss = 1.2283986202025325, disc_loss = 0.0546642677081797
Trained batch 271 in epoch 6, gen_loss = 1.228901056024958, disc_loss = 0.05451386895797709
Trained batch 272 in epoch 6, gen_loss = 1.2308772573104272, disc_loss = 0.05440442844024508
Trained batch 273 in epoch 6, gen_loss = 1.2309552698674864, disc_loss = 0.05427515860239085
Trained batch 274 in epoch 6, gen_loss = 1.2305328262935986, disc_loss = 0.05416438738053495
Trained batch 275 in epoch 6, gen_loss = 1.23155108547729, disc_loss = 0.05401632524486901
Trained batch 276 in epoch 6, gen_loss = 1.2322300252931644, disc_loss = 0.05384035616279294
Trained batch 277 in epoch 6, gen_loss = 1.2327214610233581, disc_loss = 0.05366346839540671
Trained batch 278 in epoch 6, gen_loss = 1.2328745325406392, disc_loss = 0.05352041055031094
Trained batch 279 in epoch 6, gen_loss = 1.2336752003857068, disc_loss = 0.0533511795170073
Trained batch 280 in epoch 6, gen_loss = 1.2342648440408537, disc_loss = 0.053178750691120096
Trained batch 281 in epoch 6, gen_loss = 1.2349934842146881, disc_loss = 0.05320900416741452
Trained batch 282 in epoch 6, gen_loss = 1.2351306885375573, disc_loss = 0.05305707029498087
Trained batch 283 in epoch 6, gen_loss = 1.2356525665857423, disc_loss = 0.0529038257647673
Trained batch 284 in epoch 6, gen_loss = 1.2360234003317982, disc_loss = 0.05273969293359602
Trained batch 285 in epoch 6, gen_loss = 1.2365218102931976, disc_loss = 0.052571346901904244
Trained batch 286 in epoch 6, gen_loss = 1.236124253231474, disc_loss = 0.052473858151364204
Trained batch 287 in epoch 6, gen_loss = 1.2352468129247427, disc_loss = 0.052617213400986254
Trained batch 288 in epoch 6, gen_loss = 1.2352214187486774, disc_loss = 0.05248685118623052
Trained batch 289 in epoch 6, gen_loss = 1.2344016393710826, disc_loss = 0.05335366298797829
Trained batch 290 in epoch 6, gen_loss = 1.2335358839674093, disc_loss = 0.053290764433155766
Trained batch 291 in epoch 6, gen_loss = 1.2347395160835084, disc_loss = 0.05314540750130194
Trained batch 292 in epoch 6, gen_loss = 1.2351449514411823, disc_loss = 0.05298264967055146
Trained batch 293 in epoch 6, gen_loss = 1.2338031090441204, disc_loss = 0.053052259029402415
Trained batch 294 in epoch 6, gen_loss = 1.234781123621989, disc_loss = 0.0531524041099316
Trained batch 295 in epoch 6, gen_loss = 1.2345654503316492, disc_loss = 0.05313747100897033
Trained batch 296 in epoch 6, gen_loss = 1.2328614484180103, disc_loss = 0.0532417269423604
Trained batch 297 in epoch 6, gen_loss = 1.2333607027594675, disc_loss = 0.05311861103275578
Trained batch 298 in epoch 6, gen_loss = 1.2345124110330308, disc_loss = 0.05297414217779668
Trained batch 299 in epoch 6, gen_loss = 1.2357566807667415, disc_loss = 0.05290431061759591
Trained batch 300 in epoch 6, gen_loss = 1.235295070168188, disc_loss = 0.05282499022361052
Trained batch 301 in epoch 6, gen_loss = 1.2351184039321166, disc_loss = 0.05272863120679429
Trained batch 302 in epoch 6, gen_loss = 1.2347205729767827, disc_loss = 0.05260384648042445
Trained batch 303 in epoch 6, gen_loss = 1.2355701105767174, disc_loss = 0.05245308673291124
Trained batch 304 in epoch 6, gen_loss = 1.2362515392850657, disc_loss = 0.05237325580454752
Trained batch 305 in epoch 6, gen_loss = 1.2356480685324451, disc_loss = 0.05230262777250674
Trained batch 306 in epoch 6, gen_loss = 1.2363505676048974, disc_loss = 0.05215326563154836
Trained batch 307 in epoch 6, gen_loss = 1.2364989722316915, disc_loss = 0.052002346814404445
Trained batch 308 in epoch 6, gen_loss = 1.2360110770923034, disc_loss = 0.05188381931108564
Trained batch 309 in epoch 6, gen_loss = 1.237416427173922, disc_loss = 0.05212467282770142
Trained batch 310 in epoch 6, gen_loss = 1.237267829022607, disc_loss = 0.05231939312489853
Trained batch 311 in epoch 6, gen_loss = 1.2350967096594663, disc_loss = 0.05271213615122132
Trained batch 312 in epoch 6, gen_loss = 1.2340927739112904, disc_loss = 0.0528531921581148
Trained batch 313 in epoch 6, gen_loss = 1.2329836358689958, disc_loss = 0.052911103115814505
Trained batch 314 in epoch 6, gen_loss = 1.2330676332352652, disc_loss = 0.05300190731409996
Trained batch 315 in epoch 6, gen_loss = 1.234102883293659, disc_loss = 0.05315231528321776
Trained batch 316 in epoch 6, gen_loss = 1.2328902887245081, disc_loss = 0.053186574792166236
Trained batch 317 in epoch 6, gen_loss = 1.2322618550849411, disc_loss = 0.05313089984299252
Trained batch 318 in epoch 6, gen_loss = 1.2333984466555723, disc_loss = 0.05301478991524366
Trained batch 319 in epoch 6, gen_loss = 1.2344181211665273, disc_loss = 0.05289206291199662
Trained batch 320 in epoch 6, gen_loss = 1.2351194878233556, disc_loss = 0.052757161257446186
Trained batch 321 in epoch 6, gen_loss = 1.233354504619326, disc_loss = 0.05305814892574219
Trained batch 322 in epoch 6, gen_loss = 1.2328259005635147, disc_loss = 0.052987109820701574
Trained batch 323 in epoch 6, gen_loss = 1.2349915031665637, disc_loss = 0.05316073137887374
Trained batch 324 in epoch 6, gen_loss = 1.2339168332173274, disc_loss = 0.05314905369224457
Trained batch 325 in epoch 6, gen_loss = 1.2336803685668056, disc_loss = 0.05304626535132893
Trained batch 326 in epoch 6, gen_loss = 1.2333616470342748, disc_loss = 0.053013225473372394
Trained batch 327 in epoch 6, gen_loss = 1.2335843552903432, disc_loss = 0.05287421974864584
Trained batch 328 in epoch 6, gen_loss = 1.233094927025421, disc_loss = 0.05283047992305825
Trained batch 329 in epoch 6, gen_loss = 1.2326006820707611, disc_loss = 0.05276469223370606
Trained batch 330 in epoch 6, gen_loss = 1.2322952113482888, disc_loss = 0.052752910544842574
Trained batch 331 in epoch 6, gen_loss = 1.2339938232697636, disc_loss = 0.05276431824103087
Trained batch 332 in epoch 6, gen_loss = 1.2337835200198062, disc_loss = 0.052654636959480985
Trained batch 333 in epoch 6, gen_loss = 1.2325766247189687, disc_loss = 0.05269384279032935
Trained batch 334 in epoch 6, gen_loss = 1.2343758917566556, disc_loss = 0.05260600816569666
Trained batch 335 in epoch 6, gen_loss = 1.235854243238767, disc_loss = 0.05254275297158442
Trained batch 336 in epoch 6, gen_loss = 1.2337459925374221, disc_loss = 0.05307185776719619
Trained batch 337 in epoch 6, gen_loss = 1.2351423450828305, disc_loss = 0.05311519719561088
Trained batch 338 in epoch 6, gen_loss = 1.2351208937554936, disc_loss = 0.05297763201965783
Trained batch 339 in epoch 6, gen_loss = 1.234805496475276, disc_loss = 0.05303905198953169
Trained batch 340 in epoch 6, gen_loss = 1.2359697376528094, disc_loss = 0.05296417545592767
Trained batch 341 in epoch 6, gen_loss = 1.2352204111933012, disc_loss = 0.05292101540161591
Trained batch 342 in epoch 6, gen_loss = 1.2347981813350155, disc_loss = 0.052818236000966225
Trained batch 343 in epoch 6, gen_loss = 1.233497670396816, disc_loss = 0.05301315861829925
Trained batch 344 in epoch 6, gen_loss = 1.2322577450586403, disc_loss = 0.05307742070298696
Trained batch 345 in epoch 6, gen_loss = 1.2328056298583918, disc_loss = 0.05301239024147908
Trained batch 346 in epoch 6, gen_loss = 1.2330875003372215, disc_loss = 0.05305416471128934
Trained batch 347 in epoch 6, gen_loss = 1.232939178744952, disc_loss = 0.052945819498714186
Trained batch 348 in epoch 6, gen_loss = 1.2332415575625904, disc_loss = 0.05282711578442323
Trained batch 349 in epoch 6, gen_loss = 1.233065848520824, disc_loss = 0.05276336444541812
Trained batch 350 in epoch 6, gen_loss = 1.2330419067983274, disc_loss = 0.05266264254264427
Trained batch 351 in epoch 6, gen_loss = 1.2322525641118938, disc_loss = 0.05262447394356555
Trained batch 352 in epoch 6, gen_loss = 1.2329950695672725, disc_loss = 0.05255135815991643
Trained batch 353 in epoch 6, gen_loss = 1.233995291641203, disc_loss = 0.052982268973364166
Trained batch 354 in epoch 6, gen_loss = 1.2329116362920949, disc_loss = 0.05307135800503089
Trained batch 355 in epoch 6, gen_loss = 1.233149740635679, disc_loss = 0.05294638907986829
Trained batch 356 in epoch 6, gen_loss = 1.2312640267259933, disc_loss = 0.05338704024887636
Trained batch 357 in epoch 6, gen_loss = 1.232007729108107, disc_loss = 0.053500068589899294
Trained batch 358 in epoch 6, gen_loss = 1.2330497418605517, disc_loss = 0.053910981689924815
Trained batch 359 in epoch 6, gen_loss = 1.232663092845016, disc_loss = 0.05384864173053453
Trained batch 360 in epoch 6, gen_loss = 1.2313783165490528, disc_loss = 0.05393534415037761
Trained batch 361 in epoch 6, gen_loss = 1.2303012645705629, disc_loss = 0.053964966848924836
Trained batch 362 in epoch 6, gen_loss = 1.2301519899000477, disc_loss = 0.053866669907652806
Trained batch 363 in epoch 6, gen_loss = 1.2291623940179637, disc_loss = 0.05388177337974392
Trained batch 364 in epoch 6, gen_loss = 1.2308371204219453, disc_loss = 0.05398828742693956
Trained batch 365 in epoch 6, gen_loss = 1.231486890485378, disc_loss = 0.05393790766403405
Trained batch 366 in epoch 6, gen_loss = 1.2310225531580663, disc_loss = 0.05387237320123722
Trained batch 367 in epoch 6, gen_loss = 1.2292733030474705, disc_loss = 0.05431758941647232
Trained batch 368 in epoch 6, gen_loss = 1.2330315733343604, disc_loss = 0.054638871022053365
Trained batch 369 in epoch 6, gen_loss = 1.2314955614708565, disc_loss = 0.05480642976440691
Trained batch 370 in epoch 6, gen_loss = 1.2326917230600938, disc_loss = 0.05477936294010145
Trained batch 371 in epoch 6, gen_loss = 1.231728740917739, disc_loss = 0.05478546927903368
Trained batch 372 in epoch 6, gen_loss = 1.232236720921207, disc_loss = 0.05473214985388294
Trained batch 373 in epoch 6, gen_loss = 1.2322704310723167, disc_loss = 0.054607254507787084
Trained batch 374 in epoch 6, gen_loss = 1.232515217781067, disc_loss = 0.05449952851732572
Trained batch 375 in epoch 6, gen_loss = 1.231260323302543, disc_loss = 0.0546854594821467
Trained batch 376 in epoch 6, gen_loss = 1.2319224859422335, disc_loss = 0.05457364717888737
Trained batch 377 in epoch 6, gen_loss = 1.230476067652778, disc_loss = 0.05484003730847564
Trained batch 378 in epoch 6, gen_loss = 1.230932263239707, disc_loss = 0.05476739058040063
Trained batch 379 in epoch 6, gen_loss = 1.2307090152251092, disc_loss = 0.055469738250892416
Trained batch 380 in epoch 6, gen_loss = 1.2304002874166633, disc_loss = 0.05540160428527303
Trained batch 381 in epoch 6, gen_loss = 1.230739116512668, disc_loss = 0.05528562654697224
Trained batch 382 in epoch 6, gen_loss = 1.2301488509377363, disc_loss = 0.05539264839492719
Trained batch 383 in epoch 6, gen_loss = 1.2291228361427784, disc_loss = 0.05548094770104702
Trained batch 384 in epoch 6, gen_loss = 1.2292592426399132, disc_loss = 0.0555277162001698
Trained batch 385 in epoch 6, gen_loss = 1.2287916945669934, disc_loss = 0.05548672570359599
Trained batch 386 in epoch 6, gen_loss = 1.2277155001034108, disc_loss = 0.05557256401095356
Trained batch 387 in epoch 6, gen_loss = 1.2294037887423308, disc_loss = 0.05560729757537009
Trained batch 388 in epoch 6, gen_loss = 1.2284737952570681, disc_loss = 0.05570476501461856
Trained batch 389 in epoch 6, gen_loss = 1.2288087045535063, disc_loss = 0.055599994988491136
Trained batch 390 in epoch 6, gen_loss = 1.228786534817932, disc_loss = 0.055625410195525804
Trained batch 391 in epoch 6, gen_loss = 1.2288187841067508, disc_loss = 0.05551254795151478
Trained batch 392 in epoch 6, gen_loss = 1.2280408914459267, disc_loss = 0.05547242497186397
Trained batch 393 in epoch 6, gen_loss = 1.2283438014500032, disc_loss = 0.05540507309242781
Trained batch 394 in epoch 6, gen_loss = 1.2283296120317677, disc_loss = 0.055469981720081614
Trained batch 395 in epoch 6, gen_loss = 1.2271278639032384, disc_loss = 0.05559691880603857
Trained batch 396 in epoch 6, gen_loss = 1.226523873037295, disc_loss = 0.05553229140723007
Trained batch 397 in epoch 6, gen_loss = 1.2280570404912958, disc_loss = 0.05572274131419596
Trained batch 398 in epoch 6, gen_loss = 1.2272930919078358, disc_loss = 0.05567025178273145
Trained batch 399 in epoch 6, gen_loss = 1.2269957268238068, disc_loss = 0.055583560082595795
Trained batch 400 in epoch 6, gen_loss = 1.2269105789370074, disc_loss = 0.055688479750363756
Trained batch 401 in epoch 6, gen_loss = 1.226386455457602, disc_loss = 0.055637717087155404
Trained batch 402 in epoch 6, gen_loss = 1.2261222450076499, disc_loss = 0.055604067741992606
Trained batch 403 in epoch 6, gen_loss = 1.2273053332130508, disc_loss = 0.05551517372351546
Trained batch 404 in epoch 6, gen_loss = 1.2270102362573883, disc_loss = 0.055437336956369286
Trained batch 405 in epoch 6, gen_loss = 1.2268087799325953, disc_loss = 0.055380256949772534
Trained batch 406 in epoch 6, gen_loss = 1.2263516934556515, disc_loss = 0.05527931539895567
Trained batch 407 in epoch 6, gen_loss = 1.2281117448035408, disc_loss = 0.05525498233927304
Trained batch 408 in epoch 6, gen_loss = 1.227600370176264, disc_loss = 0.05518530194208135
Trained batch 409 in epoch 6, gen_loss = 1.2280401895685893, disc_loss = 0.05509140224127871
Trained batch 410 in epoch 6, gen_loss = 1.2286949444861308, disc_loss = 0.05498572576501001
Trained batch 411 in epoch 6, gen_loss = 1.2288846500868935, disc_loss = 0.05486891477468234
Trained batch 412 in epoch 6, gen_loss = 1.227953933486061, disc_loss = 0.054869022247433376
Trained batch 413 in epoch 6, gen_loss = 1.229626946259236, disc_loss = 0.05548898909906834
Trained batch 414 in epoch 6, gen_loss = 1.2296112162521087, disc_loss = 0.05539303907159581
Trained batch 415 in epoch 6, gen_loss = 1.2289222051890998, disc_loss = 0.055369110531710945
Trained batch 416 in epoch 6, gen_loss = 1.2283675298988104, disc_loss = 0.055364127232909774
Trained batch 417 in epoch 6, gen_loss = 1.228014242135737, disc_loss = 0.055363592014394024
Trained batch 418 in epoch 6, gen_loss = 1.2275453131637026, disc_loss = 0.055328288291156436
Trained batch 419 in epoch 6, gen_loss = 1.2265729242847079, disc_loss = 0.055439028467628215
Trained batch 420 in epoch 6, gen_loss = 1.2268685496051634, disc_loss = 0.0554307615627798
Trained batch 421 in epoch 6, gen_loss = 1.2262129890975229, disc_loss = 0.05540151137999873
Trained batch 422 in epoch 6, gen_loss = 1.225822996585927, disc_loss = 0.05537348617106042
Trained batch 423 in epoch 6, gen_loss = 1.2254049373122882, disc_loss = 0.05533019980890149
Trained batch 424 in epoch 6, gen_loss = 1.2250019749473122, disc_loss = 0.05525272012633436
Trained batch 425 in epoch 6, gen_loss = 1.2260630788377753, disc_loss = 0.055175190323640204
Trained batch 426 in epoch 6, gen_loss = 1.226863401835082, disc_loss = 0.05512880379076724
Trained batch 427 in epoch 6, gen_loss = 1.226924197139027, disc_loss = 0.05502877971940787
Trained batch 428 in epoch 6, gen_loss = 1.2267266678643394, disc_loss = 0.05498953137572829
Trained batch 429 in epoch 6, gen_loss = 1.2262634313383767, disc_loss = 0.05495803517311118
Trained batch 430 in epoch 6, gen_loss = 1.2259095038725993, disc_loss = 0.05488766515044076
Trained batch 431 in epoch 6, gen_loss = 1.227178299040706, disc_loss = 0.0552998153725639
Trained batch 432 in epoch 6, gen_loss = 1.2271614680389333, disc_loss = 0.0552654112829003
Trained batch 433 in epoch 6, gen_loss = 1.226347854472525, disc_loss = 0.05531648223284066
Trained batch 434 in epoch 6, gen_loss = 1.2259613359111479, disc_loss = 0.05526971177722531
Trained batch 435 in epoch 6, gen_loss = 1.2265682123396375, disc_loss = 0.055158108694974436
Trained batch 436 in epoch 6, gen_loss = 1.2268588350621186, disc_loss = 0.05515655373101649
Trained batch 437 in epoch 6, gen_loss = 1.2261218240816298, disc_loss = 0.05514499583370881
Trained batch 438 in epoch 6, gen_loss = 1.2260104053927445, disc_loss = 0.05508592484650417
Trained batch 439 in epoch 6, gen_loss = 1.2247656946832484, disc_loss = 0.055210026395930485
Trained batch 440 in epoch 6, gen_loss = 1.2271560206164578, disc_loss = 0.055793591882704066
Trained batch 441 in epoch 6, gen_loss = 1.2267240431513722, disc_loss = 0.05574614139130482
Trained batch 442 in epoch 6, gen_loss = 1.2264893431695805, disc_loss = 0.055682497128474256
Trained batch 443 in epoch 6, gen_loss = 1.2265467831680366, disc_loss = 0.05559294579366037
Trained batch 444 in epoch 6, gen_loss = 1.2271872707967009, disc_loss = 0.055500655836854755
Trained batch 445 in epoch 6, gen_loss = 1.227054607440538, disc_loss = 0.05541126719245796
Trained batch 446 in epoch 6, gen_loss = 1.2260329245987622, disc_loss = 0.05550734075598869
Trained batch 447 in epoch 6, gen_loss = 1.2266755838479315, disc_loss = 0.05544174876454885
Trained batch 448 in epoch 6, gen_loss = 1.2259844715451875, disc_loss = 0.05548904042790555
Trained batch 449 in epoch 6, gen_loss = 1.2259493601322173, disc_loss = 0.05561104784202245
Trained batch 450 in epoch 6, gen_loss = 1.227070583340334, disc_loss = 0.055546007874915315
Trained batch 451 in epoch 6, gen_loss = 1.2267210099813157, disc_loss = 0.05549451242926308
Trained batch 452 in epoch 6, gen_loss = 1.2267624367414984, disc_loss = 0.056478194799890975
Trained batch 453 in epoch 6, gen_loss = 1.2265452977581697, disc_loss = 0.056444010124972605
Trained batch 454 in epoch 6, gen_loss = 1.226565725855775, disc_loss = 0.056382231960830455
Trained batch 455 in epoch 6, gen_loss = 1.2256181089763056, disc_loss = 0.05651056623339588
Trained batch 456 in epoch 6, gen_loss = 1.2246492664193167, disc_loss = 0.056879780752506895
Trained batch 457 in epoch 6, gen_loss = 1.2245225402725837, disc_loss = 0.05680691595412953
Trained batch 458 in epoch 6, gen_loss = 1.2238934565992916, disc_loss = 0.05693795210387647
Trained batch 459 in epoch 6, gen_loss = 1.2234159652305685, disc_loss = 0.0568904849315953
Trained batch 460 in epoch 6, gen_loss = 1.2233713083049997, disc_loss = 0.05679714143550965
Trained batch 461 in epoch 6, gen_loss = 1.2246453394363452, disc_loss = 0.05728935034647262
Trained batch 462 in epoch 6, gen_loss = 1.2237879537351704, disc_loss = 0.057328265703426064
Trained batch 463 in epoch 6, gen_loss = 1.2238461331560695, disc_loss = 0.05730988430903004
Trained batch 464 in epoch 6, gen_loss = 1.2229722348592615, disc_loss = 0.05740541886658438
Trained batch 465 in epoch 6, gen_loss = 1.2230452050978533, disc_loss = 0.05762211844532914
Trained batch 466 in epoch 6, gen_loss = 1.2222913919730667, disc_loss = 0.057615626934413224
Trained batch 467 in epoch 6, gen_loss = 1.2221396825252435, disc_loss = 0.0575735398217972
Trained batch 468 in epoch 6, gen_loss = 1.221953213341963, disc_loss = 0.057515419860765624
Trained batch 469 in epoch 6, gen_loss = 1.2210258046363263, disc_loss = 0.057546476671036254
Trained batch 470 in epoch 6, gen_loss = 1.2217703390779515, disc_loss = 0.057545454591322855
Trained batch 471 in epoch 6, gen_loss = 1.2222664857567367, disc_loss = 0.05744960447931188
Trained batch 472 in epoch 6, gen_loss = 1.222410083699176, disc_loss = 0.05737337409410366
Trained batch 473 in epoch 6, gen_loss = 1.2216204739321133, disc_loss = 0.05740560958248402
Trained batch 474 in epoch 6, gen_loss = 1.221877159068459, disc_loss = 0.057352714860125595
Trained batch 475 in epoch 6, gen_loss = 1.221246827550295, disc_loss = 0.05731705845404072
Trained batch 476 in epoch 6, gen_loss = 1.2209122553311553, disc_loss = 0.05733588893958358
Trained batch 477 in epoch 6, gen_loss = 1.2219170977879767, disc_loss = 0.05734693650234195
Trained batch 478 in epoch 6, gen_loss = 1.2223327381376932, disc_loss = 0.057249806469426893
Trained batch 479 in epoch 6, gen_loss = 1.2218067272255817, disc_loss = 0.05719828277166623
Trained batch 480 in epoch 6, gen_loss = 1.2214463147452863, disc_loss = 0.057301363001602726
Trained batch 481 in epoch 6, gen_loss = 1.2210746354334583, disc_loss = 0.05725143230578155
Trained batch 482 in epoch 6, gen_loss = 1.21967878956232, disc_loss = 0.05755703896862564
Trained batch 483 in epoch 6, gen_loss = 1.2214375932600872, disc_loss = 0.05794403168434385
Trained batch 484 in epoch 6, gen_loss = 1.2219484851532376, disc_loss = 0.05785632262716896
Trained batch 485 in epoch 6, gen_loss = 1.2208039523888026, disc_loss = 0.058001815262844654
Trained batch 486 in epoch 6, gen_loss = 1.2197295345320105, disc_loss = 0.05811356338701026
Trained batch 487 in epoch 6, gen_loss = 1.2204098876138203, disc_loss = 0.058273693212674414
Trained batch 488 in epoch 6, gen_loss = 1.2214095254861017, disc_loss = 0.05820555685008048
Trained batch 489 in epoch 6, gen_loss = 1.2219691647558797, disc_loss = 0.058177080782776586
Trained batch 490 in epoch 6, gen_loss = 1.2210448309020452, disc_loss = 0.05823515061395292
Trained batch 491 in epoch 6, gen_loss = 1.2201485515125399, disc_loss = 0.05831383280948228
Trained batch 492 in epoch 6, gen_loss = 1.2200681367703916, disc_loss = 0.0582471455165901
Trained batch 493 in epoch 6, gen_loss = 1.2200941542382182, disc_loss = 0.058190941541014535
Trained batch 494 in epoch 6, gen_loss = 1.2213049931959672, disc_loss = 0.05817510573889571
Trained batch 495 in epoch 6, gen_loss = 1.2206619813317252, disc_loss = 0.05816855585961152
Trained batch 496 in epoch 6, gen_loss = 1.2217794629169902, disc_loss = 0.05816340107110964
Trained batch 497 in epoch 6, gen_loss = 1.2210017743120232, disc_loss = 0.05816387803477037
Trained batch 498 in epoch 6, gen_loss = 1.2213124138319897, disc_loss = 0.058075179116341295
Trained batch 499 in epoch 6, gen_loss = 1.2209558149576187, disc_loss = 0.05800789275020361
Trained batch 500 in epoch 6, gen_loss = 1.221141342274443, disc_loss = 0.05795405464927236
Trained batch 501 in epoch 6, gen_loss = 1.2212437976641484, disc_loss = 0.057884480934070635
Trained batch 502 in epoch 6, gen_loss = 1.2220520012184355, disc_loss = 0.05780434775468014
Trained batch 503 in epoch 6, gen_loss = 1.2215830532331315, disc_loss = 0.057788884773525215
Trained batch 504 in epoch 6, gen_loss = 1.2209181494051866, disc_loss = 0.05776011028723552
Trained batch 505 in epoch 6, gen_loss = 1.2199493812713698, disc_loss = 0.05783723002822385
Trained batch 506 in epoch 6, gen_loss = 1.2226062884932674, disc_loss = 0.05886032697937545
Trained batch 507 in epoch 6, gen_loss = 1.2225572754313627, disc_loss = 0.05880618789489931
Trained batch 508 in epoch 6, gen_loss = 1.2221996740882664, disc_loss = 0.058848262319893874
Trained batch 509 in epoch 6, gen_loss = 1.220852149701586, disc_loss = 0.059316688911149315
Trained batch 510 in epoch 6, gen_loss = 1.2214365364754036, disc_loss = 0.05994117535913177
Trained batch 511 in epoch 6, gen_loss = 1.2208988689817488, disc_loss = 0.060115747637610184
Trained batch 512 in epoch 6, gen_loss = 1.220414389411376, disc_loss = 0.06011629565373847
Trained batch 513 in epoch 6, gen_loss = 1.2197326904141021, disc_loss = 0.06012917023355047
Trained batch 514 in epoch 6, gen_loss = 1.219144101397505, disc_loss = 0.06038694376288687
Trained batch 515 in epoch 6, gen_loss = 1.2188401459030402, disc_loss = 0.06041618318535214
Trained batch 516 in epoch 6, gen_loss = 1.218225060048832, disc_loss = 0.060500342207933766
Trained batch 517 in epoch 6, gen_loss = 1.217339119510761, disc_loss = 0.06065380529043873
Trained batch 518 in epoch 6, gen_loss = 1.2176694255573441, disc_loss = 0.06056543252285505
Trained batch 519 in epoch 6, gen_loss = 1.2175916416140704, disc_loss = 0.06053464512269084
Trained batch 520 in epoch 6, gen_loss = 1.2174971672257626, disc_loss = 0.060711703715477704
Trained batch 521 in epoch 6, gen_loss = 1.2171285217520835, disc_loss = 0.06065492172122458
Trained batch 522 in epoch 6, gen_loss = 1.215947677824739, disc_loss = 0.06083664295208386
Trained batch 523 in epoch 6, gen_loss = 1.2155139984292838, disc_loss = 0.06079185515187169
Trained batch 524 in epoch 6, gen_loss = 1.2157349576268877, disc_loss = 0.06124725165821257
Trained batch 525 in epoch 6, gen_loss = 1.2148853883770483, disc_loss = 0.06132557067467686
Trained batch 526 in epoch 6, gen_loss = 1.2153976731553702, disc_loss = 0.06123210717013823
Trained batch 527 in epoch 6, gen_loss = 1.21544925270207, disc_loss = 0.061158481861859786
Trained batch 528 in epoch 6, gen_loss = 1.2152125119937616, disc_loss = 0.0611402055808468
Trained batch 529 in epoch 6, gen_loss = 1.2146444009160096, disc_loss = 0.06115872437169529
Trained batch 530 in epoch 6, gen_loss = 1.2141226332515422, disc_loss = 0.061159931680997884
Trained batch 531 in epoch 6, gen_loss = 1.2145697790429109, disc_loss = 0.06109081161789652
Trained batch 532 in epoch 6, gen_loss = 1.2143927168443547, disc_loss = 0.06106411597881935
Trained batch 533 in epoch 6, gen_loss = 1.2144641474391638, disc_loss = 0.06102882058460837
Trained batch 534 in epoch 6, gen_loss = 1.2142400643535864, disc_loss = 0.06094873296532118
Trained batch 535 in epoch 6, gen_loss = 1.2151527431473803, disc_loss = 0.06086643459970382
Trained batch 536 in epoch 6, gen_loss = 1.2146109395852969, disc_loss = 0.06083951425674464
Trained batch 537 in epoch 6, gen_loss = 1.2155568730432305, disc_loss = 0.060828995658950294
Trained batch 538 in epoch 6, gen_loss = 1.2148817702436712, disc_loss = 0.06101390326150273
Trained batch 539 in epoch 6, gen_loss = 1.2144900650889785, disc_loss = 0.06096280745610043
Trained batch 540 in epoch 6, gen_loss = 1.2148334649486154, disc_loss = 0.06087517512827947
Trained batch 541 in epoch 6, gen_loss = 1.214392266260302, disc_loss = 0.06091854802755522
Trained batch 542 in epoch 6, gen_loss = 1.213857407947491, disc_loss = 0.06089069848300453
Trained batch 543 in epoch 6, gen_loss = 1.2140999795759426, disc_loss = 0.06083974365131272
Trained batch 544 in epoch 6, gen_loss = 1.214211948639756, disc_loss = 0.06077605950381231
Trained batch 545 in epoch 6, gen_loss = 1.2148388449525658, disc_loss = 0.06070193773538093
Trained batch 546 in epoch 6, gen_loss = 1.2142631280792697, disc_loss = 0.06068354941414196
Trained batch 547 in epoch 6, gen_loss = 1.2144414252825897, disc_loss = 0.060598599938607785
Trained batch 548 in epoch 6, gen_loss = 1.2148964419173847, disc_loss = 0.060506805977724724
Trained batch 549 in epoch 6, gen_loss = 1.2151130612330003, disc_loss = 0.06043212799524719
Trained batch 550 in epoch 6, gen_loss = 1.2154389960579777, disc_loss = 0.06033745438313473
Trained batch 551 in epoch 6, gen_loss = 1.2151300288412883, disc_loss = 0.060284675306478595
Trained batch 552 in epoch 6, gen_loss = 1.2148005577582348, disc_loss = 0.06023763780184023
Trained batch 553 in epoch 6, gen_loss = 1.2152941574473675, disc_loss = 0.0601952925899372
Trained batch 554 in epoch 6, gen_loss = 1.2152557887472548, disc_loss = 0.060102916002139316
Trained batch 555 in epoch 6, gen_loss = 1.2160284764689506, disc_loss = 0.06002021650281206
Trained batch 556 in epoch 6, gen_loss = 1.2156891250310724, disc_loss = 0.05997485982143793
Trained batch 557 in epoch 6, gen_loss = 1.216478452139858, disc_loss = 0.05990627873688936
Trained batch 558 in epoch 6, gen_loss = 1.2165445629940477, disc_loss = 0.05984421961062816
Trained batch 559 in epoch 6, gen_loss = 1.2167957647570542, disc_loss = 0.059758044072493376
Trained batch 560 in epoch 6, gen_loss = 1.2161951892728686, disc_loss = 0.05977052241504033
Trained batch 561 in epoch 6, gen_loss = 1.2162847759672755, disc_loss = 0.05968402525794517
Trained batch 562 in epoch 6, gen_loss = 1.218144719490573, disc_loss = 0.059703449817907005
Trained batch 563 in epoch 6, gen_loss = 1.2185421635707219, disc_loss = 0.0596190379017713
Trained batch 564 in epoch 6, gen_loss = 1.2180472571237952, disc_loss = 0.05958289906085856
Trained batch 565 in epoch 6, gen_loss = 1.2173944131435017, disc_loss = 0.0595719937692551
Trained batch 566 in epoch 6, gen_loss = 1.218022542340415, disc_loss = 0.05963523639119649
Trained batch 567 in epoch 6, gen_loss = 1.2183435593902225, disc_loss = 0.05954379324381515
Trained batch 568 in epoch 6, gen_loss = 1.2177856461863525, disc_loss = 0.0597204714849827
Trained batch 569 in epoch 6, gen_loss = 1.2171704070609912, disc_loss = 0.05974547024816275
Trained batch 570 in epoch 6, gen_loss = 1.21666935634279, disc_loss = 0.05974625515867344
Trained batch 571 in epoch 6, gen_loss = 1.2172117289546487, disc_loss = 0.05969689037794104
Trained batch 572 in epoch 6, gen_loss = 1.217106099528168, disc_loss = 0.059632459135293754
Trained batch 573 in epoch 6, gen_loss = 1.2164884517001773, disc_loss = 0.05968780047503602
Trained batch 574 in epoch 6, gen_loss = 1.216883053364961, disc_loss = 0.05963736572019432
Trained batch 575 in epoch 6, gen_loss = 1.2163560236286786, disc_loss = 0.05960667058631467
Trained batch 576 in epoch 6, gen_loss = 1.2164612625252642, disc_loss = 0.05960311662192671
Trained batch 577 in epoch 6, gen_loss = 1.216436187804364, disc_loss = 0.05956049704002571
Trained batch 578 in epoch 6, gen_loss = 1.21710514126664, disc_loss = 0.059477739724522014
Trained batch 579 in epoch 6, gen_loss = 1.2168258816003799, disc_loss = 0.0594279189818892
Trained batch 580 in epoch 6, gen_loss = 1.2170987392867083, disc_loss = 0.059508546571313
Trained batch 581 in epoch 6, gen_loss = 1.2164928541355526, disc_loss = 0.0595582595600705
Trained batch 582 in epoch 6, gen_loss = 1.216375540603291, disc_loss = 0.05951784273823579
Trained batch 583 in epoch 6, gen_loss = 1.216839522021274, disc_loss = 0.05943312956505034
Trained batch 584 in epoch 6, gen_loss = 1.2178182825064048, disc_loss = 0.05938099650745718
Trained batch 585 in epoch 6, gen_loss = 1.2179947280843104, disc_loss = 0.05929978040552383
Trained batch 586 in epoch 6, gen_loss = 1.2179897904802222, disc_loss = 0.05922494746516165
Trained batch 587 in epoch 6, gen_loss = 1.2178079322690056, disc_loss = 0.05916669859303808
Trained batch 588 in epoch 6, gen_loss = 1.2181213740986758, disc_loss = 0.05909969641531364
Trained batch 589 in epoch 6, gen_loss = 1.2181697294873706, disc_loss = 0.05901209651334685
Trained batch 590 in epoch 6, gen_loss = 1.2187620729157567, disc_loss = 0.0589323034344553
Trained batch 591 in epoch 6, gen_loss = 1.2191272783722427, disc_loss = 0.05884439439742473
Trained batch 592 in epoch 6, gen_loss = 1.219148118319037, disc_loss = 0.05876723576798834
Trained batch 593 in epoch 6, gen_loss = 1.2195949099882684, disc_loss = 0.05871081561781466
Trained batch 594 in epoch 6, gen_loss = 1.2202673862962161, disc_loss = 0.058635456798238166
Trained batch 595 in epoch 6, gen_loss = 1.2203446145625723, disc_loss = 0.058562834813547064
Trained batch 596 in epoch 6, gen_loss = 1.2202885637131569, disc_loss = 0.058489002188327574
Trained batch 597 in epoch 6, gen_loss = 1.2205803315575705, disc_loss = 0.05839867477872125
Trained batch 598 in epoch 6, gen_loss = 1.2210290325503914, disc_loss = 0.058318342606945954
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 1.5844483375549316, disc_loss = 0.008062145672738552
Trained batch 1 in epoch 7, gen_loss = 1.4375155568122864, disc_loss = 0.009337943512946367
Trained batch 2 in epoch 7, gen_loss = 1.360237956047058, disc_loss = 0.011633575273056826
Trained batch 3 in epoch 7, gen_loss = 1.3862673044204712, disc_loss = 0.010786135913804173
Trained batch 4 in epoch 7, gen_loss = 1.4558627128601074, disc_loss = 0.01596286091953516
Trained batch 5 in epoch 7, gen_loss = 1.4141147136688232, disc_loss = 0.01572675056134661
Trained batch 6 in epoch 7, gen_loss = 1.390209436416626, disc_loss = 0.015556376959596361
Trained batch 7 in epoch 7, gen_loss = 1.360773652791977, disc_loss = 0.02563310321420431
Trained batch 8 in epoch 7, gen_loss = 1.3076859447691176, disc_loss = 0.030294306576251984
Trained batch 9 in epoch 7, gen_loss = 1.2952046990394592, disc_loss = 0.03060573451220989
Trained batch 10 in epoch 7, gen_loss = 1.3405703197826038, disc_loss = 0.03009005889973857
Trained batch 11 in epoch 7, gen_loss = 1.359895368417104, disc_loss = 0.028394440189003944
Trained batch 12 in epoch 7, gen_loss = 1.36609070117657, disc_loss = 0.027363670130188648
Trained batch 13 in epoch 7, gen_loss = 1.3413822054862976, disc_loss = 0.027663140557706356
Trained batch 14 in epoch 7, gen_loss = 1.3472926378250123, disc_loss = 0.02784606603284677
Trained batch 15 in epoch 7, gen_loss = 1.3645372241735458, disc_loss = 0.02696348971221596
Trained batch 16 in epoch 7, gen_loss = 1.3786348314846264, disc_loss = 0.026112247806261566
Trained batch 17 in epoch 7, gen_loss = 1.3630436857541401, disc_loss = 0.028004814663694963
Trained batch 18 in epoch 7, gen_loss = 1.3617175252814042, disc_loss = 0.027538563369920378
Trained batch 19 in epoch 7, gen_loss = 1.3704288065433503, disc_loss = 0.027186443097889423
Trained batch 20 in epoch 7, gen_loss = 1.370426473163423, disc_loss = 0.02606819543455328
Trained batch 21 in epoch 7, gen_loss = 1.3898799907077442, disc_loss = 0.025670964948155663
Trained batch 22 in epoch 7, gen_loss = 1.3587643633718076, disc_loss = 0.03114031741152639
Trained batch 23 in epoch 7, gen_loss = 1.3559670845667522, disc_loss = 0.03125612096240123
Trained batch 24 in epoch 7, gen_loss = 1.3569681596755983, disc_loss = 0.03180696815252304
Trained batch 25 in epoch 7, gen_loss = 1.3666317417071416, disc_loss = 0.03192258353989858
Trained batch 26 in epoch 7, gen_loss = 1.3733389819109882, disc_loss = 0.031062859489961906
Trained batch 27 in epoch 7, gen_loss = 1.3639270918709892, disc_loss = 0.031048701676939214
Trained batch 28 in epoch 7, gen_loss = 1.3640298185677364, disc_loss = 0.030169111355368435
Trained batch 29 in epoch 7, gen_loss = 1.3573516607284546, disc_loss = 0.02963333229223887
Trained batch 30 in epoch 7, gen_loss = 1.3593472203900736, disc_loss = 0.02889685340285782
Trained batch 31 in epoch 7, gen_loss = 1.3679104521870613, disc_loss = 0.028780099135474302
Trained batch 32 in epoch 7, gen_loss = 1.3662878347165657, disc_loss = 0.02817881859443856
Trained batch 33 in epoch 7, gen_loss = 1.3732498498523937, disc_loss = 0.030115813304505804
Trained batch 34 in epoch 7, gen_loss = 1.3486784049442837, disc_loss = 0.03432980335450598
Trained batch 35 in epoch 7, gen_loss = 1.3455732299221888, disc_loss = 0.03368057115262167
Trained batch 36 in epoch 7, gen_loss = 1.3471616152170542, disc_loss = 0.032938561880507984
Trained batch 37 in epoch 7, gen_loss = 1.346847073027962, disc_loss = 0.0328204892085571
Trained batch 38 in epoch 7, gen_loss = 1.3394700991801727, disc_loss = 0.03273776207023706
Trained batch 39 in epoch 7, gen_loss = 1.3324630916118623, disc_loss = 0.0325353947468102
Trained batch 40 in epoch 7, gen_loss = 1.3539404578325225, disc_loss = 0.03538203866380017
Trained batch 41 in epoch 7, gen_loss = 1.3486347766149611, disc_loss = 0.03544682911818936
Trained batch 42 in epoch 7, gen_loss = 1.3298115397608556, disc_loss = 0.038393035964217295
Trained batch 43 in epoch 7, gen_loss = 1.3218706724318592, disc_loss = 0.03834431135857647
Trained batch 44 in epoch 7, gen_loss = 1.3295236786206563, disc_loss = 0.03797398072977861
Trained batch 45 in epoch 7, gen_loss = 1.3305084303669308, disc_loss = 0.03913735416110443
Trained batch 46 in epoch 7, gen_loss = 1.3307747397016971, disc_loss = 0.03919752223536055
Trained batch 47 in epoch 7, gen_loss = 1.324211474508047, disc_loss = 0.03902377343426148
Trained batch 48 in epoch 7, gen_loss = 1.3187122454448623, disc_loss = 0.03901254872278291
Trained batch 49 in epoch 7, gen_loss = 1.3222445261478424, disc_loss = 0.038449654653668404
Trained batch 50 in epoch 7, gen_loss = 1.32217840236776, disc_loss = 0.03802201619335249
Trained batch 51 in epoch 7, gen_loss = 1.3183863105682225, disc_loss = 0.03754480168796503
Trained batch 52 in epoch 7, gen_loss = 1.313594731519807, disc_loss = 0.03724897315479674
Trained batch 53 in epoch 7, gen_loss = 1.307280018373772, disc_loss = 0.03740604056252374
Trained batch 54 in epoch 7, gen_loss = 1.3055557456883518, disc_loss = 0.03720294609665871
Trained batch 55 in epoch 7, gen_loss = 1.3074809515050478, disc_loss = 0.03743832837790251
Trained batch 56 in epoch 7, gen_loss = 1.3150590668644822, disc_loss = 0.03725775475041908
Trained batch 57 in epoch 7, gen_loss = 1.313175689557503, disc_loss = 0.03715890710209978
Trained batch 58 in epoch 7, gen_loss = 1.3077413722620173, disc_loss = 0.03729192470594988
Trained batch 59 in epoch 7, gen_loss = 1.3035135994354883, disc_loss = 0.03704870169361432
Trained batch 60 in epoch 7, gen_loss = 1.3093944602325314, disc_loss = 0.03683437944435682
Trained batch 61 in epoch 7, gen_loss = 1.3063147731365696, disc_loss = 0.03730231247121288
Trained batch 62 in epoch 7, gen_loss = 1.3019221557511225, disc_loss = 0.04005141591741925
Trained batch 63 in epoch 7, gen_loss = 1.2953913798555732, disc_loss = 0.04059978807345033
Trained batch 64 in epoch 7, gen_loss = 1.288758972974924, disc_loss = 0.040977755991312176
Trained batch 65 in epoch 7, gen_loss = 1.2915736942580252, disc_loss = 0.04149398805968689
Trained batch 66 in epoch 7, gen_loss = 1.2854957607255053, disc_loss = 0.04186710637451997
Trained batch 67 in epoch 7, gen_loss = 1.2821695655584335, disc_loss = 0.041612466523314226
Trained batch 68 in epoch 7, gen_loss = 1.2759986433429995, disc_loss = 0.041981887720201325
Trained batch 69 in epoch 7, gen_loss = 1.2762602508068084, disc_loss = 0.04153684031750474
Trained batch 70 in epoch 7, gen_loss = 1.2877993054792916, disc_loss = 0.0443528537494196
Trained batch 71 in epoch 7, gen_loss = 1.278415073123243, disc_loss = 0.04673848378782471
Trained batch 72 in epoch 7, gen_loss = 1.2788357873485512, disc_loss = 0.04636646284122173
Trained batch 73 in epoch 7, gen_loss = 1.2727317270394918, disc_loss = 0.04717814114347503
Trained batch 74 in epoch 7, gen_loss = 1.2701265947024027, disc_loss = 0.04723072903851668
Trained batch 75 in epoch 7, gen_loss = 1.2712115355228122, disc_loss = 0.04686910955627498
Trained batch 76 in epoch 7, gen_loss = 1.2681020815651138, disc_loss = 0.047419122698438634
Trained batch 77 in epoch 7, gen_loss = 1.2642266696844346, disc_loss = 0.04731889391461244
Trained batch 78 in epoch 7, gen_loss = 1.2576869386660903, disc_loss = 0.04781774976113929
Trained batch 79 in epoch 7, gen_loss = 1.2662187390029431, disc_loss = 0.04824750430416316
Trained batch 80 in epoch 7, gen_loss = 1.2679505075937436, disc_loss = 0.04776103565768327
Trained batch 81 in epoch 7, gen_loss = 1.2677130124917844, disc_loss = 0.04749046262671671
Trained batch 82 in epoch 7, gen_loss = 1.2682881750256183, disc_loss = 0.0470352858551834
Trained batch 83 in epoch 7, gen_loss = 1.268845063589868, disc_loss = 0.04656632995188591
Trained batch 84 in epoch 7, gen_loss = 1.2692146686946644, disc_loss = 0.04609596206642249
Trained batch 85 in epoch 7, gen_loss = 1.270286575999371, disc_loss = 0.04578170902637202
Trained batch 86 in epoch 7, gen_loss = 1.2699372651933254, disc_loss = 0.045384141156214405
Trained batch 87 in epoch 7, gen_loss = 1.273197554051876, disc_loss = 0.04495300756852058
Trained batch 88 in epoch 7, gen_loss = 1.2734461292791903, disc_loss = 0.04454276543319895
Trained batch 89 in epoch 7, gen_loss = 1.273679229285982, disc_loss = 0.044135413825925854
Trained batch 90 in epoch 7, gen_loss = 1.2741772689662136, disc_loss = 0.0437741959262844
Trained batch 91 in epoch 7, gen_loss = 1.2776413359071896, disc_loss = 0.04338686600448969
Trained batch 92 in epoch 7, gen_loss = 1.281081166959578, disc_loss = 0.04308906521007259
Trained batch 93 in epoch 7, gen_loss = 1.2836359479325883, disc_loss = 0.04270363035809962
Trained batch 94 in epoch 7, gen_loss = 1.286796890434466, disc_loss = 0.04240909665332813
Trained batch 95 in epoch 7, gen_loss = 1.2830706741660833, disc_loss = 0.04244726631926218
Trained batch 96 in epoch 7, gen_loss = 1.2827148222431695, disc_loss = 0.04226878711224063
Trained batch 97 in epoch 7, gen_loss = 1.2849716830010316, disc_loss = 0.04190410960617722
Trained batch 98 in epoch 7, gen_loss = 1.2884723303293941, disc_loss = 0.041666038165038284
Trained batch 99 in epoch 7, gen_loss = 1.2918054181337357, disc_loss = 0.04144813215360046
Trained batch 100 in epoch 7, gen_loss = 1.2853845800503645, disc_loss = 0.04262611968903848
Trained batch 101 in epoch 7, gen_loss = 1.2891220397808973, disc_loss = 0.043584235943853855
Trained batch 102 in epoch 7, gen_loss = 1.285258403680857, disc_loss = 0.04383113312996128
Trained batch 103 in epoch 7, gen_loss = 1.285547832456919, disc_loss = 0.04352372490729277
Trained batch 104 in epoch 7, gen_loss = 1.2818853196643647, disc_loss = 0.043515119666144964
Trained batch 105 in epoch 7, gen_loss = 1.2858343551743705, disc_loss = 0.043836686268167675
Trained batch 106 in epoch 7, gen_loss = 1.2905095893645955, disc_loss = 0.04365441394604255
Trained batch 107 in epoch 7, gen_loss = 1.2864307181702719, disc_loss = 0.043902053497731686
Trained batch 108 in epoch 7, gen_loss = 1.2855430945343929, disc_loss = 0.04376690513497099
Trained batch 109 in epoch 7, gen_loss = 1.2876611151478508, disc_loss = 0.04366595663807609
Trained batch 110 in epoch 7, gen_loss = 1.2836971014469594, disc_loss = 0.04390227787934982
Trained batch 111 in epoch 7, gen_loss = 1.2841475595320975, disc_loss = 0.04358545578517286
Trained batch 112 in epoch 7, gen_loss = 1.293309320390752, disc_loss = 0.04455461129711001
Trained batch 113 in epoch 7, gen_loss = 1.2918016649129098, disc_loss = 0.04435545643137997
Trained batch 114 in epoch 7, gen_loss = 1.289713624249334, disc_loss = 0.04421677857475436
Trained batch 115 in epoch 7, gen_loss = 1.2881445329764794, disc_loss = 0.0439911979202438
Trained batch 116 in epoch 7, gen_loss = 1.285440523400266, disc_loss = 0.04420314002463706
Trained batch 117 in epoch 7, gen_loss = 1.2886873109865997, disc_loss = 0.04426335946704119
Trained batch 118 in epoch 7, gen_loss = 1.2872890434345277, disc_loss = 0.04424722319734948
Trained batch 119 in epoch 7, gen_loss = 1.2849256505568822, disc_loss = 0.04415068886398028
Trained batch 120 in epoch 7, gen_loss = 1.2816344218805802, disc_loss = 0.044148517964977374
Trained batch 121 in epoch 7, gen_loss = 1.2840196612428447, disc_loss = 0.044362234096729854
Trained batch 122 in epoch 7, gen_loss = 1.2811228182257675, disc_loss = 0.044516863672411054
Trained batch 123 in epoch 7, gen_loss = 1.279262363910675, disc_loss = 0.04436005930596542
Trained batch 124 in epoch 7, gen_loss = 1.2822474155426025, disc_loss = 0.044143607668578624
Trained batch 125 in epoch 7, gen_loss = 1.2816518507306538, disc_loss = 0.04445575608591002
Trained batch 126 in epoch 7, gen_loss = 1.2793982329331046, disc_loss = 0.044396042024467404
Trained batch 127 in epoch 7, gen_loss = 1.278547229245305, disc_loss = 0.04437309942295542
Trained batch 128 in epoch 7, gen_loss = 1.2795867938403935, disc_loss = 0.0443246022603193
Trained batch 129 in epoch 7, gen_loss = 1.281459901883052, disc_loss = 0.04424178972123907
Trained batch 130 in epoch 7, gen_loss = 1.2815200199607675, disc_loss = 0.04417897202785461
Trained batch 131 in epoch 7, gen_loss = 1.2789514258955463, disc_loss = 0.04429207306891454
Trained batch 132 in epoch 7, gen_loss = 1.2734501518701251, disc_loss = 0.04569064556179862
Trained batch 133 in epoch 7, gen_loss = 1.2774548704054818, disc_loss = 0.04590269994796879
Trained batch 134 in epoch 7, gen_loss = 1.2847153659220094, disc_loss = 0.04717494033415009
Trained batch 135 in epoch 7, gen_loss = 1.2804887500755928, disc_loss = 0.0480049991473446
Trained batch 136 in epoch 7, gen_loss = 1.277165441182408, disc_loss = 0.048168318652051643
Trained batch 137 in epoch 7, gen_loss = 1.27743669912435, disc_loss = 0.048177152271449995
Trained batch 138 in epoch 7, gen_loss = 1.2772080302238464, disc_loss = 0.048466806192781854
Trained batch 139 in epoch 7, gen_loss = 1.273854614155633, disc_loss = 0.0487165842138763
Trained batch 140 in epoch 7, gen_loss = 1.2739155013510521, disc_loss = 0.04922474867248155
Trained batch 141 in epoch 7, gen_loss = 1.271898754045997, disc_loss = 0.04925604825052367
Trained batch 142 in epoch 7, gen_loss = 1.2695747872332592, disc_loss = 0.049290216045936086
Trained batch 143 in epoch 7, gen_loss = 1.270787798696094, disc_loss = 0.049284741146645196
Trained batch 144 in epoch 7, gen_loss = 1.2709207617003342, disc_loss = 0.04901444849654518
Trained batch 145 in epoch 7, gen_loss = 1.2732729062642136, disc_loss = 0.04877532014546737
Trained batch 146 in epoch 7, gen_loss = 1.2708749937362411, disc_loss = 0.04887758323377898
Trained batch 147 in epoch 7, gen_loss = 1.2694484514964592, disc_loss = 0.04882245285537194
Trained batch 148 in epoch 7, gen_loss = 1.2677442023418093, disc_loss = 0.04871172389178068
Trained batch 149 in epoch 7, gen_loss = 1.2709502923488616, disc_loss = 0.04928397790839275
Trained batch 150 in epoch 7, gen_loss = 1.2705555992410673, disc_loss = 0.049013692731444805
Trained batch 151 in epoch 7, gen_loss = 1.2677803941463168, disc_loss = 0.04909143285017068
Trained batch 152 in epoch 7, gen_loss = 1.2685301186991673, disc_loss = 0.04898670395483184
Trained batch 153 in epoch 7, gen_loss = 1.2668119034209808, disc_loss = 0.04893054319061823
Trained batch 154 in epoch 7, gen_loss = 1.2688663590338922, disc_loss = 0.0486773559042523
Trained batch 155 in epoch 7, gen_loss = 1.2698122973625476, disc_loss = 0.048494462855160236
Trained batch 156 in epoch 7, gen_loss = 1.268527621676208, disc_loss = 0.048292740372715484
Trained batch 157 in epoch 7, gen_loss = 1.266803680341455, disc_loss = 0.048570875832928885
Trained batch 158 in epoch 7, gen_loss = 1.264995832488222, disc_loss = 0.04860096495106535
Trained batch 159 in epoch 7, gen_loss = 1.2672385331243277, disc_loss = 0.048689363477751615
Trained batch 160 in epoch 7, gen_loss = 1.2646975787530035, disc_loss = 0.048867139710772854
Trained batch 161 in epoch 7, gen_loss = 1.2628627783722348, disc_loss = 0.04881497730075577
Trained batch 162 in epoch 7, gen_loss = 1.262599449581895, disc_loss = 0.04862091020663823
Trained batch 163 in epoch 7, gen_loss = 1.2652664013752124, disc_loss = 0.04866876487234017
Trained batch 164 in epoch 7, gen_loss = 1.264617018627398, disc_loss = 0.04844119151433309
Trained batch 165 in epoch 7, gen_loss = 1.2633548346628625, disc_loss = 0.04824333906128823
Trained batch 166 in epoch 7, gen_loss = 1.2654326964995104, disc_loss = 0.04812487601832358
Trained batch 167 in epoch 7, gen_loss = 1.2631242317812783, disc_loss = 0.04819194547876361
Trained batch 168 in epoch 7, gen_loss = 1.2645269829845993, disc_loss = 0.04796024042694173
Trained batch 169 in epoch 7, gen_loss = 1.268738061540267, disc_loss = 0.04835208690560916
Trained batch 170 in epoch 7, gen_loss = 1.268550311612804, disc_loss = 0.04820655225313198
Trained batch 171 in epoch 7, gen_loss = 1.2697308860545935, disc_loss = 0.04796979063038909
Trained batch 172 in epoch 7, gen_loss = 1.26869690142615, disc_loss = 0.04788274612988351
Trained batch 173 in epoch 7, gen_loss = 1.2673039772044654, disc_loss = 0.04789599033350917
Trained batch 174 in epoch 7, gen_loss = 1.2704428931644984, disc_loss = 0.04790152196373258
Trained batch 175 in epoch 7, gen_loss = 1.2705921036275951, disc_loss = 0.04785202140919864
Trained batch 176 in epoch 7, gen_loss = 1.269395405963316, disc_loss = 0.04772227203820722
Trained batch 177 in epoch 7, gen_loss = 1.2689408887638134, disc_loss = 0.04757418542095784
Trained batch 178 in epoch 7, gen_loss = 1.270919283675082, disc_loss = 0.0473612976213657
Trained batch 179 in epoch 7, gen_loss = 1.2709857212172615, disc_loss = 0.04716189799623357
Trained batch 180 in epoch 7, gen_loss = 1.2740010866144085, disc_loss = 0.04706232857926445
Trained batch 181 in epoch 7, gen_loss = 1.2726378270557948, disc_loss = 0.046966989954503685
Trained batch 182 in epoch 7, gen_loss = 1.2734679309396797, disc_loss = 0.04673686389724821
Trained batch 183 in epoch 7, gen_loss = 1.2722474265357722, disc_loss = 0.046942553019819214
Trained batch 184 in epoch 7, gen_loss = 1.2719382466496647, disc_loss = 0.04681088426276236
Trained batch 185 in epoch 7, gen_loss = 1.2729461962176907, disc_loss = 0.046597144914470534
Trained batch 186 in epoch 7, gen_loss = 1.2716280368560138, disc_loss = 0.04650733096744208
Trained batch 187 in epoch 7, gen_loss = 1.2716789321696504, disc_loss = 0.04630462054232572
Trained batch 188 in epoch 7, gen_loss = 1.2713898464485451, disc_loss = 0.04619356376616649
Trained batch 189 in epoch 7, gen_loss = 1.2733005335456447, disc_loss = 0.04611422018344073
Trained batch 190 in epoch 7, gen_loss = 1.2726358849340709, disc_loss = 0.04594957831691151
Trained batch 191 in epoch 7, gen_loss = 1.2738668775806825, disc_loss = 0.04576028019315951
Trained batch 192 in epoch 7, gen_loss = 1.273911101830438, disc_loss = 0.04560711600822565
Trained batch 193 in epoch 7, gen_loss = 1.2712894106648631, disc_loss = 0.04601123763161913
Trained batch 194 in epoch 7, gen_loss = 1.2755267393894685, disc_loss = 0.046968519947945306
Trained batch 195 in epoch 7, gen_loss = 1.2782869807311468, disc_loss = 0.04687197806019032
Trained batch 196 in epoch 7, gen_loss = 1.2788537311069856, disc_loss = 0.04677433670181687
Trained batch 197 in epoch 7, gen_loss = 1.2794930477334996, disc_loss = 0.04660773495767228
Trained batch 198 in epoch 7, gen_loss = 1.2777172572648705, disc_loss = 0.04671018503503359
Trained batch 199 in epoch 7, gen_loss = 1.2775817000865937, disc_loss = 0.04653086150297895
Trained batch 200 in epoch 7, gen_loss = 1.2789564025935842, disc_loss = 0.04644950588850017
Trained batch 201 in epoch 7, gen_loss = 1.2808381832472169, disc_loss = 0.04628125298998807
Trained batch 202 in epoch 7, gen_loss = 1.2814611537115914, disc_loss = 0.04609423907235118
Trained batch 203 in epoch 7, gen_loss = 1.2808735247920542, disc_loss = 0.04598150970459934
Trained batch 204 in epoch 7, gen_loss = 1.2807995220509971, disc_loss = 0.04581405418447968
Trained batch 205 in epoch 7, gen_loss = 1.2801185996787061, disc_loss = 0.04566756482869025
Trained batch 206 in epoch 7, gen_loss = 1.2804391597204163, disc_loss = 0.045563024353991816
Trained batch 207 in epoch 7, gen_loss = 1.2803825604227872, disc_loss = 0.045415601117733434
Trained batch 208 in epoch 7, gen_loss = 1.2830178486673456, disc_loss = 0.04534810289303866
Trained batch 209 in epoch 7, gen_loss = 1.2844084915660676, disc_loss = 0.04518417452816807
Trained batch 210 in epoch 7, gen_loss = 1.2856449973526725, disc_loss = 0.045125624502598535
Trained batch 211 in epoch 7, gen_loss = 1.2854938074102942, disc_loss = 0.04494291958003744
Trained batch 212 in epoch 7, gen_loss = 1.2858408185797678, disc_loss = 0.04476634689121389
Trained batch 213 in epoch 7, gen_loss = 1.2850132473161286, disc_loss = 0.044782686958994684
Trained batch 214 in epoch 7, gen_loss = 1.283755093397096, disc_loss = 0.0447129714346036
Trained batch 215 in epoch 7, gen_loss = 1.2835817182505573, disc_loss = 0.044571895805549704
Trained batch 216 in epoch 7, gen_loss = 1.2855688344498384, disc_loss = 0.044459894966883455
Trained batch 217 in epoch 7, gen_loss = 1.2867579246879717, disc_loss = 0.044290948802297676
Trained batch 218 in epoch 7, gen_loss = 1.2884892758713464, disc_loss = 0.04493873635068808
Trained batch 219 in epoch 7, gen_loss = 1.2876143655993721, disc_loss = 0.044851846711456096
Trained batch 220 in epoch 7, gen_loss = 1.285986484715302, disc_loss = 0.044938833151450926
Trained batch 221 in epoch 7, gen_loss = 1.2848541121762078, disc_loss = 0.044897627628718816
Trained batch 222 in epoch 7, gen_loss = 1.285363681915095, disc_loss = 0.04493704173221115
Trained batch 223 in epoch 7, gen_loss = 1.2847003726554769, disc_loss = 0.044878999193315394
Trained batch 224 in epoch 7, gen_loss = 1.2850912276903788, disc_loss = 0.04471837983156244
Trained batch 225 in epoch 7, gen_loss = 1.284960540258779, disc_loss = 0.044557773992336826
Trained batch 226 in epoch 7, gen_loss = 1.2852097032878893, disc_loss = 0.04439511306436183
Trained batch 227 in epoch 7, gen_loss = 1.2831365975894427, disc_loss = 0.044588300109465136
Trained batch 228 in epoch 7, gen_loss = 1.285054461664508, disc_loss = 0.04472200392326543
Trained batch 229 in epoch 7, gen_loss = 1.2854341328144074, disc_loss = 0.04457796683696949
Trained batch 230 in epoch 7, gen_loss = 1.2847965973796267, disc_loss = 0.044503238789930746
Trained batch 231 in epoch 7, gen_loss = 1.2845908534424058, disc_loss = 0.04437887919504709
Trained batch 232 in epoch 7, gen_loss = 1.2849523824171958, disc_loss = 0.04425657959854782
Trained batch 233 in epoch 7, gen_loss = 1.2854126714743102, disc_loss = 0.044117113197238274
Trained batch 234 in epoch 7, gen_loss = 1.2853984830227303, disc_loss = 0.043993750460287355
Trained batch 235 in epoch 7, gen_loss = 1.2852159756219994, disc_loss = 0.04387732846978105
Trained batch 236 in epoch 7, gen_loss = 1.2865610819325668, disc_loss = 0.043829111618143096
Trained batch 237 in epoch 7, gen_loss = 1.2872629924481656, disc_loss = 0.04372289589754924
Trained batch 238 in epoch 7, gen_loss = 1.2872722091535145, disc_loss = 0.04357135081741663
Trained batch 239 in epoch 7, gen_loss = 1.2873660994072755, disc_loss = 0.04341816283413209
Trained batch 240 in epoch 7, gen_loss = 1.2880263380489902, disc_loss = 0.04327443046340742
Trained batch 241 in epoch 7, gen_loss = 1.2883445145177448, disc_loss = 0.04313282751139592
Trained batch 242 in epoch 7, gen_loss = 1.2890224886038666, disc_loss = 0.04298539843923822
Trained batch 243 in epoch 7, gen_loss = 1.288990010247856, disc_loss = 0.042882783706757986
Trained batch 244 in epoch 7, gen_loss = 1.2893105231985753, disc_loss = 0.04301349450929128
Trained batch 245 in epoch 7, gen_loss = 1.2894522244852733, disc_loss = 0.04287153382679614
Trained batch 246 in epoch 7, gen_loss = 1.2896151858785374, disc_loss = 0.042752805352588054
Trained batch 247 in epoch 7, gen_loss = 1.2897895740405205, disc_loss = 0.04263479672109468
Trained batch 248 in epoch 7, gen_loss = 1.2901650731822094, disc_loss = 0.04250292484293202
Trained batch 249 in epoch 7, gen_loss = 1.2908367774486542, disc_loss = 0.042717511100694536
Trained batch 250 in epoch 7, gen_loss = 1.2901935280556698, disc_loss = 0.04264944021319191
Trained batch 251 in epoch 7, gen_loss = 1.290245474567489, disc_loss = 0.042532645736909694
Trained batch 252 in epoch 7, gen_loss = 1.2907650991390816, disc_loss = 0.042391709344675066
Trained batch 253 in epoch 7, gen_loss = 1.2915847205270932, disc_loss = 0.042251650022166805
Trained batch 254 in epoch 7, gen_loss = 1.2922856796021556, disc_loss = 0.04213789821072828
Trained batch 255 in epoch 7, gen_loss = 1.292477764422074, disc_loss = 0.042001454190540244
Trained batch 256 in epoch 7, gen_loss = 1.2925809716900034, disc_loss = 0.041987418767847555
Trained batch 257 in epoch 7, gen_loss = 1.292220891677132, disc_loss = 0.04188502022036344
Trained batch 258 in epoch 7, gen_loss = 1.2918998456369495, disc_loss = 0.041778300584987896
Trained batch 259 in epoch 7, gen_loss = 1.2926849500491069, disc_loss = 0.041646476480393456
Trained batch 260 in epoch 7, gen_loss = 1.2932515772366433, disc_loss = 0.04152416471049361
Trained batch 261 in epoch 7, gen_loss = 1.2934602314734276, disc_loss = 0.04141570150297676
Trained batch 262 in epoch 7, gen_loss = 1.2935789086972806, disc_loss = 0.041344283045952994
Trained batch 263 in epoch 7, gen_loss = 1.2934833631822558, disc_loss = 0.04122170223148935
Trained batch 264 in epoch 7, gen_loss = 1.2931455380511734, disc_loss = 0.04111167245878364
Trained batch 265 in epoch 7, gen_loss = 1.294142409598917, disc_loss = 0.04100570119777344
Trained batch 266 in epoch 7, gen_loss = 1.2954569740241832, disc_loss = 0.040894285374589626
Trained batch 267 in epoch 7, gen_loss = 1.296627799299226, disc_loss = 0.040789100543053736
Trained batch 268 in epoch 7, gen_loss = 1.2968431895107142, disc_loss = 0.0406742662357575
Trained batch 269 in epoch 7, gen_loss = 1.2966137336360084, disc_loss = 0.040569657690961054
Trained batch 270 in epoch 7, gen_loss = 1.2968076421325938, disc_loss = 0.0404397730571235
Trained batch 271 in epoch 7, gen_loss = 1.297054436057806, disc_loss = 0.04031724821235163
Trained batch 272 in epoch 7, gen_loss = 1.2971030825223677, disc_loss = 0.0401993875848914
Trained batch 273 in epoch 7, gen_loss = 1.2986523485096702, disc_loss = 0.04172430100279731
Trained batch 274 in epoch 7, gen_loss = 1.295878271406347, disc_loss = 0.042891373470086945
Trained batch 275 in epoch 7, gen_loss = 1.2940351993277452, disc_loss = 0.04303022668244776
Trained batch 276 in epoch 7, gen_loss = 1.2925745713581678, disc_loss = 0.043238048786331064
Trained batch 277 in epoch 7, gen_loss = 1.2918205814395878, disc_loss = 0.043454832630231977
Trained batch 278 in epoch 7, gen_loss = 1.2905165371501746, disc_loss = 0.04352307358195865
Trained batch 279 in epoch 7, gen_loss = 1.2895280220678875, disc_loss = 0.04347126882889175
Trained batch 280 in epoch 7, gen_loss = 1.2885325688908533, disc_loss = 0.04347349998783121
Trained batch 281 in epoch 7, gen_loss = 1.2876133052169854, disc_loss = 0.04344858273910028
Trained batch 282 in epoch 7, gen_loss = 1.2888700338639978, disc_loss = 0.043484370245568636
Trained batch 283 in epoch 7, gen_loss = 1.2899358071072, disc_loss = 0.04340114737500135
Trained batch 284 in epoch 7, gen_loss = 1.2908385966953477, disc_loss = 0.043589651916306794
Trained batch 285 in epoch 7, gen_loss = 1.28802452450032, disc_loss = 0.04448421978574064
Trained batch 286 in epoch 7, gen_loss = 1.2871796895818013, disc_loss = 0.04441954691826207
Trained batch 287 in epoch 7, gen_loss = 1.2867064436690674, disc_loss = 0.04454884117229893
Trained batch 288 in epoch 7, gen_loss = 1.2854718949555526, disc_loss = 0.04468656589589678
Trained batch 289 in epoch 7, gen_loss = 1.2854767571235526, disc_loss = 0.04464716246383714
Trained batch 290 in epoch 7, gen_loss = 1.2846278036173266, disc_loss = 0.044706668607135305
Trained batch 291 in epoch 7, gen_loss = 1.2847249481367737, disc_loss = 0.044627363154065014
Trained batch 292 in epoch 7, gen_loss = 1.2840563431127894, disc_loss = 0.04456342326845885
Trained batch 293 in epoch 7, gen_loss = 1.2848499804532447, disc_loss = 0.04452934287025967
Trained batch 294 in epoch 7, gen_loss = 1.2833343035083706, disc_loss = 0.04457446662393414
Trained batch 295 in epoch 7, gen_loss = 1.2829724443522659, disc_loss = 0.044467148495322045
Trained batch 296 in epoch 7, gen_loss = 1.2842896159249122, disc_loss = 0.044412036703880685
Trained batch 297 in epoch 7, gen_loss = 1.2856102303770565, disc_loss = 0.0443241110855976
Trained batch 298 in epoch 7, gen_loss = 1.2853108797982384, disc_loss = 0.04425146084833255
Trained batch 299 in epoch 7, gen_loss = 1.284437881509463, disc_loss = 0.044241646321800845
Trained batch 300 in epoch 7, gen_loss = 1.2848138573557832, disc_loss = 0.0443400592029565
Trained batch 301 in epoch 7, gen_loss = 1.2830490479800876, disc_loss = 0.04450835785150084
Trained batch 302 in epoch 7, gen_loss = 1.282791528568016, disc_loss = 0.04442704526596878
Trained batch 303 in epoch 7, gen_loss = 1.2840359107052024, disc_loss = 0.04452084197117457
Trained batch 304 in epoch 7, gen_loss = 1.2833548285922065, disc_loss = 0.044619711389246045
Trained batch 305 in epoch 7, gen_loss = 1.2822067916782853, disc_loss = 0.04462939875620399
Trained batch 306 in epoch 7, gen_loss = 1.2805483826596884, disc_loss = 0.044683270203404686
Trained batch 307 in epoch 7, gen_loss = 1.2796377837657928, disc_loss = 0.04463771370681027
Trained batch 308 in epoch 7, gen_loss = 1.2804525897726657, disc_loss = 0.04496685522050871
Trained batch 309 in epoch 7, gen_loss = 1.281311023235321, disc_loss = 0.044903870460186755
Trained batch 310 in epoch 7, gen_loss = 1.2805273210887358, disc_loss = 0.044864078479073345
Trained batch 311 in epoch 7, gen_loss = 1.2789984039771252, disc_loss = 0.04493341600158228
Trained batch 312 in epoch 7, gen_loss = 1.2777158726518527, disc_loss = 0.04494028427034093
Trained batch 313 in epoch 7, gen_loss = 1.2798620416859912, disc_loss = 0.04502566370395291
Trained batch 314 in epoch 7, gen_loss = 1.2810134789300343, disc_loss = 0.04496063589310599
Trained batch 315 in epoch 7, gen_loss = 1.281192901768262, disc_loss = 0.044841734664455714
Trained batch 316 in epoch 7, gen_loss = 1.279444022509578, disc_loss = 0.044969029908218314
Trained batch 317 in epoch 7, gen_loss = 1.279985101342951, disc_loss = 0.0450627968936526
Trained batch 318 in epoch 7, gen_loss = 1.2802542122927578, disc_loss = 0.04499420236510029
Trained batch 319 in epoch 7, gen_loss = 1.281014644727111, disc_loss = 0.04537422687426442
Trained batch 320 in epoch 7, gen_loss = 1.2798795083601526, disc_loss = 0.045443708397668564
Trained batch 321 in epoch 7, gen_loss = 1.2790677240176231, disc_loss = 0.04553191403291472
Trained batch 322 in epoch 7, gen_loss = 1.2775553992658208, disc_loss = 0.045726834506592234
Trained batch 323 in epoch 7, gen_loss = 1.2760615249474843, disc_loss = 0.045900131013807785
Trained batch 324 in epoch 7, gen_loss = 1.2768203001755936, disc_loss = 0.04631810401637967
Trained batch 325 in epoch 7, gen_loss = 1.2765532816114602, disc_loss = 0.04621705021623499
Trained batch 326 in epoch 7, gen_loss = 1.2757489458865712, disc_loss = 0.04616528389041258
Trained batch 327 in epoch 7, gen_loss = 1.2751193995155938, disc_loss = 0.04611260636579018
Trained batch 328 in epoch 7, gen_loss = 1.2747759065367168, disc_loss = 0.04655260705505144
Trained batch 329 in epoch 7, gen_loss = 1.2736252045992649, disc_loss = 0.04659032313237813
Trained batch 330 in epoch 7, gen_loss = 1.2725011243560884, disc_loss = 0.04669357516192282
Trained batch 331 in epoch 7, gen_loss = 1.2712527938995017, disc_loss = 0.04681635517430638
Trained batch 332 in epoch 7, gen_loss = 1.2731460270222958, disc_loss = 0.04734029278142361
Trained batch 333 in epoch 7, gen_loss = 1.2732138096572396, disc_loss = 0.04721856059807682
Trained batch 334 in epoch 7, gen_loss = 1.272281690142048, disc_loss = 0.047277592016912215
Trained batch 335 in epoch 7, gen_loss = 1.2712215493832315, disc_loss = 0.047353745909363386
Trained batch 336 in epoch 7, gen_loss = 1.2710585604789348, disc_loss = 0.047247725248734745
Trained batch 337 in epoch 7, gen_loss = 1.272495275771124, disc_loss = 0.04748013578685959
Trained batch 338 in epoch 7, gen_loss = 1.2716764781327374, disc_loss = 0.047443598558285595
Trained batch 339 in epoch 7, gen_loss = 1.2709705016192268, disc_loss = 0.047373029847136316
Trained batch 340 in epoch 7, gen_loss = 1.271165475118195, disc_loss = 0.04725811052575839
Trained batch 341 in epoch 7, gen_loss = 1.2700895813473485, disc_loss = 0.04729536566774399
Trained batch 342 in epoch 7, gen_loss = 1.2700351935433924, disc_loss = 0.04718903374502506
Trained batch 343 in epoch 7, gen_loss = 1.2703312212644622, disc_loss = 0.04708567263590995
Trained batch 344 in epoch 7, gen_loss = 1.2709227050560108, disc_loss = 0.04701900070506162
Trained batch 345 in epoch 7, gen_loss = 1.269896120177528, disc_loss = 0.047053067463132515
Trained batch 346 in epoch 7, gen_loss = 1.269321708411236, disc_loss = 0.047009630281725084
Trained batch 347 in epoch 7, gen_loss = 1.268697474365947, disc_loss = 0.04696096443228595
Trained batch 348 in epoch 7, gen_loss = 1.2708955188535347, disc_loss = 0.04699235547995755
Trained batch 349 in epoch 7, gen_loss = 1.2709362924098968, disc_loss = 0.046888409813067744
Trained batch 350 in epoch 7, gen_loss = 1.2709956361018016, disc_loss = 0.04681386702303958
Trained batch 351 in epoch 7, gen_loss = 1.271242093802853, disc_loss = 0.04671212953293103
Trained batch 352 in epoch 7, gen_loss = 1.269830069021868, disc_loss = 0.04691706064603062
Trained batch 353 in epoch 7, gen_loss = 1.27277222814533, disc_loss = 0.047892008068850314
Trained batch 354 in epoch 7, gen_loss = 1.2730783363463174, disc_loss = 0.04778457394683025
Trained batch 355 in epoch 7, gen_loss = 1.2726271124033446, disc_loss = 0.04776125614206945
Trained batch 356 in epoch 7, gen_loss = 1.2721461596943082, disc_loss = 0.047681435264375696
Trained batch 357 in epoch 7, gen_loss = 1.2736663873302203, disc_loss = 0.04774196775807016
Trained batch 358 in epoch 7, gen_loss = 1.273494670152, disc_loss = 0.04765614402846208
Trained batch 359 in epoch 7, gen_loss = 1.273642354706923, disc_loss = 0.04758085023301343
Trained batch 360 in epoch 7, gen_loss = 1.272801893734866, disc_loss = 0.04765222965123085
Trained batch 361 in epoch 7, gen_loss = 1.2713908571235382, disc_loss = 0.047843531540785376
Trained batch 362 in epoch 7, gen_loss = 1.2735269498233952, disc_loss = 0.04813004026995053
Trained batch 363 in epoch 7, gen_loss = 1.2730093868551673, disc_loss = 0.04808642466010137
Trained batch 364 in epoch 7, gen_loss = 1.2728603658610826, disc_loss = 0.047986028195448116
Trained batch 365 in epoch 7, gen_loss = 1.2731890878716454, disc_loss = 0.047872836509454855
Trained batch 366 in epoch 7, gen_loss = 1.2723236348713451, disc_loss = 0.04790711459356083
Trained batch 367 in epoch 7, gen_loss = 1.2736615640637667, disc_loss = 0.04782785037557757
Trained batch 368 in epoch 7, gen_loss = 1.2743348408197646, disc_loss = 0.047938142624257135
Trained batch 369 in epoch 7, gen_loss = 1.2741387339862618, disc_loss = 0.04784495979421646
Trained batch 370 in epoch 7, gen_loss = 1.2730264189751, disc_loss = 0.04794886921007799
Trained batch 371 in epoch 7, gen_loss = 1.2734482309190176, disc_loss = 0.047851000202729574
Trained batch 372 in epoch 7, gen_loss = 1.2739583415256428, disc_loss = 0.04784385159976241
Trained batch 373 in epoch 7, gen_loss = 1.2744584725821082, disc_loss = 0.047730890755108335
Trained batch 374 in epoch 7, gen_loss = 1.2744142622947694, disc_loss = 0.04762978906929493
Trained batch 375 in epoch 7, gen_loss = 1.2744012238814475, disc_loss = 0.04752935016616941
Trained batch 376 in epoch 7, gen_loss = 1.2743461908332865, disc_loss = 0.047421517292783655
Trained batch 377 in epoch 7, gen_loss = 1.2740414459553977, disc_loss = 0.047341391574788505
Trained batch 378 in epoch 7, gen_loss = 1.274453912844444, disc_loss = 0.04722801713508831
Trained batch 379 in epoch 7, gen_loss = 1.2746289603020016, disc_loss = 0.04711888370373728
Trained batch 380 in epoch 7, gen_loss = 1.2738397970912962, disc_loss = 0.04715720140387419
Trained batch 381 in epoch 7, gen_loss = 1.2734198693517615, disc_loss = 0.047094654395483944
Trained batch 382 in epoch 7, gen_loss = 1.2734650312764837, disc_loss = 0.04703415848202906
Trained batch 383 in epoch 7, gen_loss = 1.2733034306826692, disc_loss = 0.04693555021488768
Trained batch 384 in epoch 7, gen_loss = 1.2725869688120754, disc_loss = 0.046884455165354076
Trained batch 385 in epoch 7, gen_loss = 1.2728675679530503, disc_loss = 0.04679360411158845
Trained batch 386 in epoch 7, gen_loss = 1.272883407059258, disc_loss = 0.04668883222590853
Trained batch 387 in epoch 7, gen_loss = 1.2740205008651793, disc_loss = 0.046646913406727164
Trained batch 388 in epoch 7, gen_loss = 1.2750633597986865, disc_loss = 0.046578778072492555
Trained batch 389 in epoch 7, gen_loss = 1.275338423404938, disc_loss = 0.046629845082330014
Trained batch 390 in epoch 7, gen_loss = 1.2744727200254455, disc_loss = 0.046647342268491876
Trained batch 391 in epoch 7, gen_loss = 1.2736662348010102, disc_loss = 0.04663497405197965
Trained batch 392 in epoch 7, gen_loss = 1.2728081530590396, disc_loss = 0.04660410527732346
Trained batch 393 in epoch 7, gen_loss = 1.2720406662086545, disc_loss = 0.047856928930773875
Trained batch 394 in epoch 7, gen_loss = 1.271299885043615, disc_loss = 0.04780365802889949
Trained batch 395 in epoch 7, gen_loss = 1.2711626355997239, disc_loss = 0.04778835404960608
Trained batch 396 in epoch 7, gen_loss = 1.271202305852616, disc_loss = 0.04777871134106811
Trained batch 397 in epoch 7, gen_loss = 1.2709079586980332, disc_loss = 0.047861907330467995
Trained batch 398 in epoch 7, gen_loss = 1.269036698909033, disc_loss = 0.04842199655809909
Trained batch 399 in epoch 7, gen_loss = 1.2682731406390666, disc_loss = 0.048491915034828706
Trained batch 400 in epoch 7, gen_loss = 1.268083795199073, disc_loss = 0.0485791596305322
Trained batch 401 in epoch 7, gen_loss = 1.266527180203158, disc_loss = 0.048843215278752926
Trained batch 402 in epoch 7, gen_loss = 1.266942714787003, disc_loss = 0.04916970856908348
Trained batch 403 in epoch 7, gen_loss = 1.2664451606497906, disc_loss = 0.04929363253494116
Trained batch 404 in epoch 7, gen_loss = 1.2657569346604525, disc_loss = 0.049256019799015775
Trained batch 405 in epoch 7, gen_loss = 1.2646307676590134, disc_loss = 0.049294569303644044
Trained batch 406 in epoch 7, gen_loss = 1.2648617332338994, disc_loss = 0.04922980799497602
Trained batch 407 in epoch 7, gen_loss = 1.2648352637302642, disc_loss = 0.04928810205013838
Trained batch 408 in epoch 7, gen_loss = 1.2652591672386693, disc_loss = 0.04923068106625329
Trained batch 409 in epoch 7, gen_loss = 1.2643794318524804, disc_loss = 0.04925143807195127
Trained batch 410 in epoch 7, gen_loss = 1.265129383753106, disc_loss = 0.04915554990194321
Trained batch 411 in epoch 7, gen_loss = 1.2652047779953595, disc_loss = 0.049071548403765174
Trained batch 412 in epoch 7, gen_loss = 1.2654730009397641, disc_loss = 0.048976885706195315
Trained batch 413 in epoch 7, gen_loss = 1.265690113035377, disc_loss = 0.0488694755670925
Trained batch 414 in epoch 7, gen_loss = 1.2657690932951777, disc_loss = 0.04877946386450385
Trained batch 415 in epoch 7, gen_loss = 1.2659714915431464, disc_loss = 0.048711104575956524
Trained batch 416 in epoch 7, gen_loss = 1.266064398580318, disc_loss = 0.04863837690760406
Trained batch 417 in epoch 7, gen_loss = 1.2665358354030043, disc_loss = 0.048547715766346485
Trained batch 418 in epoch 7, gen_loss = 1.2670553069126065, disc_loss = 0.04852834886922401
Trained batch 419 in epoch 7, gen_loss = 1.2672357879933858, disc_loss = 0.04843486114183352
Trained batch 420 in epoch 7, gen_loss = 1.2671250685376962, disc_loss = 0.048346777835909516
Trained batch 421 in epoch 7, gen_loss = 1.2675405379155236, disc_loss = 0.0482465749875735
Trained batch 422 in epoch 7, gen_loss = 1.2678223434069478, disc_loss = 0.04827409041010671
Trained batch 423 in epoch 7, gen_loss = 1.267989601729051, disc_loss = 0.04817535612899107
Trained batch 424 in epoch 7, gen_loss = 1.2680570725833669, disc_loss = 0.04808308235205272
Trained batch 425 in epoch 7, gen_loss = 1.2679913564467094, disc_loss = 0.04798576956453073
Trained batch 426 in epoch 7, gen_loss = 1.268636230562554, disc_loss = 0.0479143362860926
Trained batch 427 in epoch 7, gen_loss = 1.2691804337724346, disc_loss = 0.047813674284876366
Trained batch 428 in epoch 7, gen_loss = 1.2690437862645219, disc_loss = 0.04775135051285401
Trained batch 429 in epoch 7, gen_loss = 1.2688205669092578, disc_loss = 0.04767903026063428
Trained batch 430 in epoch 7, gen_loss = 1.2677761534803704, disc_loss = 0.04774535311442171
Trained batch 431 in epoch 7, gen_loss = 1.2682981259293027, disc_loss = 0.04779160859847993
Trained batch 432 in epoch 7, gen_loss = 1.2684281557867214, disc_loss = 0.0477110163048426
Trained batch 433 in epoch 7, gen_loss = 1.2682551008215697, disc_loss = 0.0477200097614719
Trained batch 434 in epoch 7, gen_loss = 1.2670856415540321, disc_loss = 0.04787978463131806
Trained batch 435 in epoch 7, gen_loss = 1.2679014430133575, disc_loss = 0.048095027702527306
Trained batch 436 in epoch 7, gen_loss = 1.2664140356487212, disc_loss = 0.048359988432045115
Trained batch 437 in epoch 7, gen_loss = 1.2674871857307817, disc_loss = 0.048317954781971297
Trained batch 438 in epoch 7, gen_loss = 1.2674230019432537, disc_loss = 0.048247258601061035
Trained batch 439 in epoch 7, gen_loss = 1.2671992421150207, disc_loss = 0.04816746872595765
Trained batch 440 in epoch 7, gen_loss = 1.2670385956493906, disc_loss = 0.04815186940285624
Trained batch 441 in epoch 7, gen_loss = 1.266439469421611, disc_loss = 0.048137611570468856
Trained batch 442 in epoch 7, gen_loss = 1.266204817569552, disc_loss = 0.04820337001040881
Trained batch 443 in epoch 7, gen_loss = 1.2667984248281599, disc_loss = 0.04812038251458927
Trained batch 444 in epoch 7, gen_loss = 1.2666789585284972, disc_loss = 0.048060294797413805
Trained batch 445 in epoch 7, gen_loss = 1.2662959130890166, disc_loss = 0.047993286504439445
Trained batch 446 in epoch 7, gen_loss = 1.2665006362351796, disc_loss = 0.04791544223000072
Trained batch 447 in epoch 7, gen_loss = 1.2666242883673735, disc_loss = 0.047824642076323344
Trained batch 448 in epoch 7, gen_loss = 1.2653024110337407, disc_loss = 0.04794157675170819
Trained batch 449 in epoch 7, gen_loss = 1.2663774038685693, disc_loss = 0.04821143821295765
Trained batch 450 in epoch 7, gen_loss = 1.2662728465845738, disc_loss = 0.04824206216917466
Trained batch 451 in epoch 7, gen_loss = 1.2670757938011559, disc_loss = 0.04822473376742111
Trained batch 452 in epoch 7, gen_loss = 1.2668712300970064, disc_loss = 0.04816053644497005
Trained batch 453 in epoch 7, gen_loss = 1.267108059008216, disc_loss = 0.04810665890016482
Trained batch 454 in epoch 7, gen_loss = 1.2675057585422809, disc_loss = 0.04802219521172427
Trained batch 455 in epoch 7, gen_loss = 1.2673427139719327, disc_loss = 0.047969578804137804
Trained batch 456 in epoch 7, gen_loss = 1.2666486912535369, disc_loss = 0.047962491429070546
Trained batch 457 in epoch 7, gen_loss = 1.2668960155618243, disc_loss = 0.04788843739379246
Trained batch 458 in epoch 7, gen_loss = 1.266865401875739, disc_loss = 0.04787355840960943
Trained batch 459 in epoch 7, gen_loss = 1.2678227957176125, disc_loss = 0.04780643512899785
Trained batch 460 in epoch 7, gen_loss = 1.2669387488199677, disc_loss = 0.04787169854457686
Trained batch 461 in epoch 7, gen_loss = 1.2673564554550947, disc_loss = 0.047786008866979576
Trained batch 462 in epoch 7, gen_loss = 1.2665696167276437, disc_loss = 0.047780538136722846
Trained batch 463 in epoch 7, gen_loss = 1.2666405971194137, disc_loss = 0.04771608680462593
Trained batch 464 in epoch 7, gen_loss = 1.2672007655584685, disc_loss = 0.04763233748575051
Trained batch 465 in epoch 7, gen_loss = 1.2667115573719336, disc_loss = 0.04758716812717045
Trained batch 466 in epoch 7, gen_loss = 1.2677616131127007, disc_loss = 0.047549448181462235
Trained batch 467 in epoch 7, gen_loss = 1.2673420108791091, disc_loss = 0.04748725058494979
Trained batch 468 in epoch 7, gen_loss = 1.2685677044427217, disc_loss = 0.04746733227772499
Trained batch 469 in epoch 7, gen_loss = 1.2693525928132077, disc_loss = 0.04742781060173156
Trained batch 470 in epoch 7, gen_loss = 1.26960057665588, disc_loss = 0.04733813401200906
Trained batch 471 in epoch 7, gen_loss = 1.2695912875361361, disc_loss = 0.047429741760794765
Trained batch 472 in epoch 7, gen_loss = 1.2690513494402864, disc_loss = 0.047418744496245085
Trained batch 473 in epoch 7, gen_loss = 1.2686903049171223, disc_loss = 0.04735278479464132
Trained batch 474 in epoch 7, gen_loss = 1.269159708775972, disc_loss = 0.04726798357932191
Trained batch 475 in epoch 7, gen_loss = 1.269603928848475, disc_loss = 0.04719755850427103
Trained batch 476 in epoch 7, gen_loss = 1.2695716094670806, disc_loss = 0.047122509562385034
Trained batch 477 in epoch 7, gen_loss = 1.269631361861608, disc_loss = 0.04703706919379283
Trained batch 478 in epoch 7, gen_loss = 1.2697007036408203, disc_loss = 0.04695564746129519
Trained batch 479 in epoch 7, gen_loss = 1.2703475795686245, disc_loss = 0.04687745489936788
Trained batch 480 in epoch 7, gen_loss = 1.2705560947406316, disc_loss = 0.04678701882864389
Trained batch 481 in epoch 7, gen_loss = 1.2700408570993986, disc_loss = 0.04673963410420444
Trained batch 482 in epoch 7, gen_loss = 1.2691558925261408, disc_loss = 0.04676918725639304
Trained batch 483 in epoch 7, gen_loss = 1.269560686566613, disc_loss = 0.046733417468384095
Trained batch 484 in epoch 7, gen_loss = 1.2695480880049086, disc_loss = 0.046671729558867586
Trained batch 485 in epoch 7, gen_loss = 1.2694279448485668, disc_loss = 0.04662454309643327
Trained batch 486 in epoch 7, gen_loss = 1.2708378775653408, disc_loss = 0.046609671290168346
Trained batch 487 in epoch 7, gen_loss = 1.2707448071632228, disc_loss = 0.04655931663382646
Trained batch 488 in epoch 7, gen_loss = 1.2711766987490507, disc_loss = 0.04655624540705531
Trained batch 489 in epoch 7, gen_loss = 1.271522988348591, disc_loss = 0.046477958158000696
Trained batch 490 in epoch 7, gen_loss = 1.2706861126932738, disc_loss = 0.04647345609617725
Trained batch 491 in epoch 7, gen_loss = 1.2712440044899298, disc_loss = 0.04640386656316648
Trained batch 492 in epoch 7, gen_loss = 1.2715073320976862, disc_loss = 0.046339171569280586
Trained batch 493 in epoch 7, gen_loss = 1.2716395340950384, disc_loss = 0.046501003423524714
Trained batch 494 in epoch 7, gen_loss = 1.2716225860094783, disc_loss = 0.04643276827786155
Trained batch 495 in epoch 7, gen_loss = 1.271270473157206, disc_loss = 0.04637536478150005
Trained batch 496 in epoch 7, gen_loss = 1.271227525273559, disc_loss = 0.046327808668548374
Trained batch 497 in epoch 7, gen_loss = 1.2714004535751648, disc_loss = 0.046247473993641604
Trained batch 498 in epoch 7, gen_loss = 1.2716271406662967, disc_loss = 0.04620013113239993
Trained batch 499 in epoch 7, gen_loss = 1.2707570977210998, disc_loss = 0.04631324767041951
Trained batch 500 in epoch 7, gen_loss = 1.2703823043914613, disc_loss = 0.04626166065151017
Trained batch 501 in epoch 7, gen_loss = 1.2709460229987641, disc_loss = 0.0462722144659193
Trained batch 502 in epoch 7, gen_loss = 1.2720951351446375, disc_loss = 0.04623351307311808
Trained batch 503 in epoch 7, gen_loss = 1.272266375640082, disc_loss = 0.04617558824478663
Trained batch 504 in epoch 7, gen_loss = 1.2716652014467975, disc_loss = 0.04624361112289647
Trained batch 505 in epoch 7, gen_loss = 1.2704972686032532, disc_loss = 0.046380717819924706
Trained batch 506 in epoch 7, gen_loss = 1.2707169284011721, disc_loss = 0.046508548275202045
Trained batch 507 in epoch 7, gen_loss = 1.2717563608499962, disc_loss = 0.046466008522621116
Trained batch 508 in epoch 7, gen_loss = 1.2717413604844998, disc_loss = 0.04640212216394384
Trained batch 509 in epoch 7, gen_loss = 1.2720511579046063, disc_loss = 0.04632918297897513
Trained batch 510 in epoch 7, gen_loss = 1.2722186298053093, disc_loss = 0.046267664870119664
Trained batch 511 in epoch 7, gen_loss = 1.2718195843044668, disc_loss = 0.04623157647893095
Trained batch 512 in epoch 7, gen_loss = 1.2721102711750052, disc_loss = 0.046151515617458325
Trained batch 513 in epoch 7, gen_loss = 1.2726991816717363, disc_loss = 0.04607972079264688
Trained batch 514 in epoch 7, gen_loss = 1.272850800949393, disc_loss = 0.046003092347996904
Trained batch 515 in epoch 7, gen_loss = 1.2728871883347976, disc_loss = 0.04604004814412243
Trained batch 516 in epoch 7, gen_loss = 1.2731076428230772, disc_loss = 0.045977815468678504
Trained batch 517 in epoch 7, gen_loss = 1.2727627547091038, disc_loss = 0.04593693056686792
Trained batch 518 in epoch 7, gen_loss = 1.2726515336303124, disc_loss = 0.045870258587705035
Trained batch 519 in epoch 7, gen_loss = 1.2728234433210812, disc_loss = 0.04580581052264628
Trained batch 520 in epoch 7, gen_loss = 1.2727207965905745, disc_loss = 0.045739522480875996
Trained batch 521 in epoch 7, gen_loss = 1.2731968719383766, disc_loss = 0.04567893658375717
Trained batch 522 in epoch 7, gen_loss = 1.2737976989600217, disc_loss = 0.04560778366248649
Trained batch 523 in epoch 7, gen_loss = 1.27317240356489, disc_loss = 0.04563203002575017
Trained batch 524 in epoch 7, gen_loss = 1.274095319112142, disc_loss = 0.04558486062855947
Trained batch 525 in epoch 7, gen_loss = 1.27436578636387, disc_loss = 0.04551219077738349
Trained batch 526 in epoch 7, gen_loss = 1.2739357482323836, disc_loss = 0.045486391659833106
Trained batch 527 in epoch 7, gen_loss = 1.2747082940556786, disc_loss = 0.04542391759054171
Trained batch 528 in epoch 7, gen_loss = 1.2738868847686537, disc_loss = 0.04545622185710642
Trained batch 529 in epoch 7, gen_loss = 1.274379294098548, disc_loss = 0.0455683418936184
Trained batch 530 in epoch 7, gen_loss = 1.2745529732012704, disc_loss = 0.045508955771948884
Trained batch 531 in epoch 7, gen_loss = 1.2746304213104391, disc_loss = 0.04544401586342855
Trained batch 532 in epoch 7, gen_loss = 1.2732822419778491, disc_loss = 0.04571497753632952
Trained batch 533 in epoch 7, gen_loss = 1.2735237082961792, disc_loss = 0.04565774735886506
Trained batch 534 in epoch 7, gen_loss = 1.2748756703929367, disc_loss = 0.045703883510883725
Trained batch 535 in epoch 7, gen_loss = 1.2748201904234602, disc_loss = 0.04563811923717774
Trained batch 536 in epoch 7, gen_loss = 1.2754758506513841, disc_loss = 0.04557582726129773
Trained batch 537 in epoch 7, gen_loss = 1.2754760396746454, disc_loss = 0.045648337918295624
Trained batch 538 in epoch 7, gen_loss = 1.2747792517541734, disc_loss = 0.04565408010837486
Trained batch 539 in epoch 7, gen_loss = 1.2742739656457194, disc_loss = 0.04562653751043534
Trained batch 540 in epoch 7, gen_loss = 1.274012881264008, disc_loss = 0.04556177318089275
Trained batch 541 in epoch 7, gen_loss = 1.274564595789927, disc_loss = 0.045513085833651004
Trained batch 542 in epoch 7, gen_loss = 1.2736992299227425, disc_loss = 0.04627957369816622
Trained batch 543 in epoch 7, gen_loss = 1.2729045504375416, disc_loss = 0.04635354153887259
Trained batch 544 in epoch 7, gen_loss = 1.272616009865332, disc_loss = 0.04630583860150991
Trained batch 545 in epoch 7, gen_loss = 1.2726968012668274, disc_loss = 0.04625659080686204
Trained batch 546 in epoch 7, gen_loss = 1.2733692038647653, disc_loss = 0.046315993461587636
Trained batch 547 in epoch 7, gen_loss = 1.2727453525919115, disc_loss = 0.04630312526999653
Trained batch 548 in epoch 7, gen_loss = 1.272260241386886, disc_loss = 0.046290213505114905
Trained batch 549 in epoch 7, gen_loss = 1.2713287156278437, disc_loss = 0.04640096980909055
Trained batch 550 in epoch 7, gen_loss = 1.272226953030498, disc_loss = 0.04670323712240817
Trained batch 551 in epoch 7, gen_loss = 1.2718044709468233, disc_loss = 0.04666049141551543
Trained batch 552 in epoch 7, gen_loss = 1.2709314829617684, disc_loss = 0.046712030191816536
Trained batch 553 in epoch 7, gen_loss = 1.269949961332638, disc_loss = 0.046844008168548563
Trained batch 554 in epoch 7, gen_loss = 1.2701831116332665, disc_loss = 0.046813817045374496
Trained batch 555 in epoch 7, gen_loss = 1.2710017046268038, disc_loss = 0.04696153672981552
Trained batch 556 in epoch 7, gen_loss = 1.2703425779376896, disc_loss = 0.04701415760211874
Trained batch 557 in epoch 7, gen_loss = 1.2694857280741456, disc_loss = 0.047076140405229665
Trained batch 558 in epoch 7, gen_loss = 1.2696364648866738, disc_loss = 0.04700769499204187
Trained batch 559 in epoch 7, gen_loss = 1.2688569466982569, disc_loss = 0.04702112119744665
Trained batch 560 in epoch 7, gen_loss = 1.2696083354864953, disc_loss = 0.047174352865314205
Trained batch 561 in epoch 7, gen_loss = 1.2690414140445057, disc_loss = 0.04720972854730232
Trained batch 562 in epoch 7, gen_loss = 1.268965706414482, disc_loss = 0.047163241744689895
Trained batch 563 in epoch 7, gen_loss = 1.2691636473363173, disc_loss = 0.04709981134035856
Trained batch 564 in epoch 7, gen_loss = 1.268900942907924, disc_loss = 0.04708707754426034
Trained batch 565 in epoch 7, gen_loss = 1.268499700740875, disc_loss = 0.04705284482078765
Trained batch 566 in epoch 7, gen_loss = 1.2682546464433957, disc_loss = 0.04700025053599577
Trained batch 567 in epoch 7, gen_loss = 1.2682757907560174, disc_loss = 0.047664014591415685
Trained batch 568 in epoch 7, gen_loss = 1.2688882626422888, disc_loss = 0.04761681290791879
Trained batch 569 in epoch 7, gen_loss = 1.2679849441637072, disc_loss = 0.04767786136485244
Trained batch 570 in epoch 7, gen_loss = 1.2679164978543431, disc_loss = 0.047736776025473236
Trained batch 571 in epoch 7, gen_loss = 1.2673218482649409, disc_loss = 0.047735101681762745
Trained batch 572 in epoch 7, gen_loss = 1.266750086144419, disc_loss = 0.0477370256753102
Trained batch 573 in epoch 7, gen_loss = 1.2665888389851574, disc_loss = 0.04774457498742365
Trained batch 574 in epoch 7, gen_loss = 1.2667179448708243, disc_loss = 0.04772380320436281
Trained batch 575 in epoch 7, gen_loss = 1.2667478274347053, disc_loss = 0.04765246936262378
Trained batch 576 in epoch 7, gen_loss = 1.2659437917753977, disc_loss = 0.04768662850341826
Trained batch 577 in epoch 7, gen_loss = 1.266899692661622, disc_loss = 0.04767043083893283
Trained batch 578 in epoch 7, gen_loss = 1.268042742176583, disc_loss = 0.04770643108030572
Trained batch 579 in epoch 7, gen_loss = 1.2681902539113472, disc_loss = 0.047755111493812556
Trained batch 580 in epoch 7, gen_loss = 1.2674376725534975, disc_loss = 0.047845500070928706
Trained batch 581 in epoch 7, gen_loss = 1.2669744763997002, disc_loss = 0.047861882498251
Trained batch 582 in epoch 7, gen_loss = 1.2672645894372851, disc_loss = 0.04779234640444046
Trained batch 583 in epoch 7, gen_loss = 1.2678606716329104, disc_loss = 0.04778904792587974
Trained batch 584 in epoch 7, gen_loss = 1.267108951572679, disc_loss = 0.04781708682401695
Trained batch 585 in epoch 7, gen_loss = 1.2674734668723553, disc_loss = 0.047744439791652785
Trained batch 586 in epoch 7, gen_loss = 1.267917457085858, disc_loss = 0.04767587028040822
Trained batch 587 in epoch 7, gen_loss = 1.2682604107524262, disc_loss = 0.04761435552484349
Trained batch 588 in epoch 7, gen_loss = 1.267503955874257, disc_loss = 0.047637819729157184
Trained batch 589 in epoch 7, gen_loss = 1.267765122045905, disc_loss = 0.04757755108067166
Trained batch 590 in epoch 7, gen_loss = 1.2678287812901028, disc_loss = 0.047699097119265454
Trained batch 591 in epoch 7, gen_loss = 1.267396556062473, disc_loss = 0.047689169454168075
Trained batch 592 in epoch 7, gen_loss = 1.2673747834025506, disc_loss = 0.04763764767196111
Trained batch 593 in epoch 7, gen_loss = 1.266894240170617, disc_loss = 0.047661391470223816
Trained batch 594 in epoch 7, gen_loss = 1.2672830307183145, disc_loss = 0.047601784976246224
Trained batch 595 in epoch 7, gen_loss = 1.2676110085624976, disc_loss = 0.047539521775195916
Trained batch 596 in epoch 7, gen_loss = 1.2678414022103826, disc_loss = 0.047532763142588
Trained batch 597 in epoch 7, gen_loss = 1.2681712264998701, disc_loss = 0.0474658747659965
Trained batch 598 in epoch 7, gen_loss = 1.2682642974519172, disc_loss = 0.04751845004459927
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.8172131180763245, disc_loss = 0.08816272020339966
Trained batch 1 in epoch 8, gen_loss = 0.8599874079227448, disc_loss = 0.07443345710635185
Trained batch 2 in epoch 8, gen_loss = 1.019971231619517, disc_loss = 0.10265935709079106
Trained batch 3 in epoch 8, gen_loss = 1.0534829050302505, disc_loss = 0.0812555612064898
Trained batch 4 in epoch 8, gen_loss = 0.9716117024421692, disc_loss = 0.09955724366009236
Trained batch 5 in epoch 8, gen_loss = 0.9852074086666107, disc_loss = 0.08606695818404357
Trained batch 6 in epoch 8, gen_loss = 1.099172634737832, disc_loss = 0.08733771475298065
Trained batch 7 in epoch 8, gen_loss = 1.0775943472981453, disc_loss = 0.08385859290137887
Trained batch 8 in epoch 8, gen_loss = 1.1589034464624193, disc_loss = 0.07835281433330642
Trained batch 9 in epoch 8, gen_loss = 1.118940669298172, disc_loss = 0.07939887531101704
Trained batch 10 in epoch 8, gen_loss = 1.153803754936565, disc_loss = 0.07296540740538728
Trained batch 11 in epoch 8, gen_loss = 1.1310112724701564, disc_loss = 0.07142703343803684
Trained batch 12 in epoch 8, gen_loss = 1.1797344638751104, disc_loss = 0.08231611535526238
Trained batch 13 in epoch 8, gen_loss = 1.1547387199742454, disc_loss = 0.08139989458556686
Trained batch 14 in epoch 8, gen_loss = 1.1339990337689718, disc_loss = 0.08034114477535088
Trained batch 15 in epoch 8, gen_loss = 1.1331504918634892, disc_loss = 0.07781671674456447
Trained batch 16 in epoch 8, gen_loss = 1.151683460263645, disc_loss = 0.07658626522649736
Trained batch 17 in epoch 8, gen_loss = 1.1557483573754628, disc_loss = 0.0729903766574959
Trained batch 18 in epoch 8, gen_loss = 1.1576103819044012, disc_loss = 0.06956882701304398
Trained batch 19 in epoch 8, gen_loss = 1.1672250837087632, disc_loss = 0.06659296145662666
Trained batch 20 in epoch 8, gen_loss = 1.1797880643890017, disc_loss = 0.06374921263860804
Trained batch 21 in epoch 8, gen_loss = 1.1917714828794652, disc_loss = 0.061794981487434016
Trained batch 22 in epoch 8, gen_loss = 1.1954115240470222, disc_loss = 0.05943949289781892
Trained batch 23 in epoch 8, gen_loss = 1.2003047938148181, disc_loss = 0.0575815176901718
Trained batch 24 in epoch 8, gen_loss = 1.1955951142311096, disc_loss = 0.055932535752654076
Trained batch 25 in epoch 8, gen_loss = 1.1964989694265218, disc_loss = 0.05422207412238304
Trained batch 26 in epoch 8, gen_loss = 1.1929303827109161, disc_loss = 0.052991915218256136
Trained batch 27 in epoch 8, gen_loss = 1.1986763030290604, disc_loss = 0.05136387509160808
Trained batch 28 in epoch 8, gen_loss = 1.206994408163531, disc_loss = 0.05011053980681403
Trained batch 29 in epoch 8, gen_loss = 1.2220140119393668, disc_loss = 0.04877299852669239
Trained batch 30 in epoch 8, gen_loss = 1.221102539570101, disc_loss = 0.04778827552593524
Trained batch 31 in epoch 8, gen_loss = 1.236260810866952, disc_loss = 0.05137002019910142
Trained batch 32 in epoch 8, gen_loss = 1.2157486315929529, disc_loss = 0.05830011511165084
Trained batch 33 in epoch 8, gen_loss = 1.211137624347911, disc_loss = 0.05784193837248227
Trained batch 34 in epoch 8, gen_loss = 1.2340723310198103, disc_loss = 0.0615264962294272
Trained batch 35 in epoch 8, gen_loss = 1.2224562962849934, disc_loss = 0.06205494489727749
Trained batch 36 in epoch 8, gen_loss = 1.2305223394084621, disc_loss = 0.06088758526823005
Trained batch 37 in epoch 8, gen_loss = 1.2234869222891958, disc_loss = 0.06015425494038745
Trained batch 38 in epoch 8, gen_loss = 1.2250287379973974, disc_loss = 0.0588241163880015
Trained batch 39 in epoch 8, gen_loss = 1.2383285015821457, disc_loss = 0.059700310020707546
Trained batch 40 in epoch 8, gen_loss = 1.2352174433266245, disc_loss = 0.05868970100745195
Trained batch 41 in epoch 8, gen_loss = 1.237548399539221, disc_loss = 0.05757901713340765
Trained batch 42 in epoch 8, gen_loss = 1.2278511732123618, disc_loss = 0.058077954297322175
Trained batch 43 in epoch 8, gen_loss = 1.232366674325683, disc_loss = 0.057455623712898654
Trained batch 44 in epoch 8, gen_loss = 1.2386100782288445, disc_loss = 0.05785432807687256
Trained batch 45 in epoch 8, gen_loss = 1.2417583426703578, disc_loss = 0.05671021220800669
Trained batch 46 in epoch 8, gen_loss = 1.2399765443294606, disc_loss = 0.05608763529899272
Trained batch 47 in epoch 8, gen_loss = 1.2402853406965733, disc_loss = 0.0553532459307462
Trained batch 48 in epoch 8, gen_loss = 1.2420394943684947, disc_loss = 0.054339478609665315
Trained batch 49 in epoch 8, gen_loss = 1.238453415632248, disc_loss = 0.05386881588026881
Trained batch 50 in epoch 8, gen_loss = 1.2348111201735104, disc_loss = 0.05384839631105755
Trained batch 51 in epoch 8, gen_loss = 1.2291598125145986, disc_loss = 0.05329603571086549
Trained batch 52 in epoch 8, gen_loss = 1.2270154694341264, disc_loss = 0.05261301971479969
Trained batch 53 in epoch 8, gen_loss = 1.2360393747135445, disc_loss = 0.053256272769498604
Trained batch 54 in epoch 8, gen_loss = 1.2376145872202786, disc_loss = 0.0524778073314916
Trained batch 55 in epoch 8, gen_loss = 1.2299701922706194, disc_loss = 0.05323449813295156
Trained batch 56 in epoch 8, gen_loss = 1.2373811288883811, disc_loss = 0.052579307814308425
Trained batch 57 in epoch 8, gen_loss = 1.2419025497189884, disc_loss = 0.05240651738733567
Trained batch 58 in epoch 8, gen_loss = 1.243036929833687, disc_loss = 0.0518372698323959
Trained batch 59 in epoch 8, gen_loss = 1.2348619669675827, disc_loss = 0.05249085381316642
Trained batch 60 in epoch 8, gen_loss = 1.2407755216614145, disc_loss = 0.05182283128932363
Trained batch 61 in epoch 8, gen_loss = 1.247930625754018, disc_loss = 0.05136758631335631
Trained batch 62 in epoch 8, gen_loss = 1.2507287140876528, disc_loss = 0.0506711130784381
Trained batch 63 in epoch 8, gen_loss = 1.2488140827044845, disc_loss = 0.050568500635563396
Trained batch 64 in epoch 8, gen_loss = 1.2549721488585839, disc_loss = 0.05020462018079483
Trained batch 65 in epoch 8, gen_loss = 1.254225849202185, disc_loss = 0.049705082000317896
Trained batch 66 in epoch 8, gen_loss = 1.2484267905576905, disc_loss = 0.049743901173681465
Trained batch 67 in epoch 8, gen_loss = 1.2428840214715284, disc_loss = 0.04962347525938907
Trained batch 68 in epoch 8, gen_loss = 1.2497151822283648, disc_loss = 0.049142132540219936
Trained batch 69 in epoch 8, gen_loss = 1.2491020500659942, disc_loss = 0.04859375388228467
Trained batch 70 in epoch 8, gen_loss = 1.2478948353042065, disc_loss = 0.04929318823392542
Trained batch 71 in epoch 8, gen_loss = 1.2538112757934465, disc_loss = 0.048804076039232314
Trained batch 72 in epoch 8, gen_loss = 1.251035170195854, disc_loss = 0.048607888708069716
Trained batch 73 in epoch 8, gen_loss = 1.2480379206103247, disc_loss = 0.05189382709009019
Trained batch 74 in epoch 8, gen_loss = 1.2485727429389955, disc_loss = 0.05127067320048809
Trained batch 75 in epoch 8, gen_loss = 1.2465120734352815, disc_loss = 0.05092624690089571
Trained batch 76 in epoch 8, gen_loss = 1.2412810364326874, disc_loss = 0.051247764112693925
Trained batch 77 in epoch 8, gen_loss = 1.2416712725773835, disc_loss = 0.051138752999787145
Trained batch 78 in epoch 8, gen_loss = 1.2444791982445536, disc_loss = 0.05078202818485
Trained batch 79 in epoch 8, gen_loss = 1.247189600020647, disc_loss = 0.05033560661831871
Trained batch 80 in epoch 8, gen_loss = 1.2460322357990123, disc_loss = 0.04999272981773556
Trained batch 81 in epoch 8, gen_loss = 1.245668013648289, disc_loss = 0.04947631233144642
Trained batch 82 in epoch 8, gen_loss = 1.2400371561567467, disc_loss = 0.04957613680534154
Trained batch 83 in epoch 8, gen_loss = 1.241255400436265, disc_loss = 0.049486864130899665
Trained batch 84 in epoch 8, gen_loss = 1.2386828177115496, disc_loss = 0.049233091222670146
Trained batch 85 in epoch 8, gen_loss = 1.2418399099693742, disc_loss = 0.04897232634708459
Trained batch 86 in epoch 8, gen_loss = 1.2442670752262246, disc_loss = 0.04853040877536967
Trained batch 87 in epoch 8, gen_loss = 1.2410914254459469, disc_loss = 0.04837830087953163
Trained batch 88 in epoch 8, gen_loss = 1.2467518127366397, disc_loss = 0.04838536816303817
Trained batch 89 in epoch 8, gen_loss = 1.2485362324449751, disc_loss = 0.04811575485703846
Trained batch 90 in epoch 8, gen_loss = 1.24789874959778, disc_loss = 0.04808179541378395
Trained batch 91 in epoch 8, gen_loss = 1.2416498732307684, disc_loss = 0.04912222547800806
Trained batch 92 in epoch 8, gen_loss = 1.2421195974913977, disc_loss = 0.04896100588964038
Trained batch 93 in epoch 8, gen_loss = 1.244705411347937, disc_loss = 0.04903477844980327
Trained batch 94 in epoch 8, gen_loss = 1.2428211331367494, disc_loss = 0.048672601791392815
Trained batch 95 in epoch 8, gen_loss = 1.2423047677924235, disc_loss = 0.0483290064294124
Trained batch 96 in epoch 8, gen_loss = 1.2426185663213436, disc_loss = 0.04794807105622802
Trained batch 97 in epoch 8, gen_loss = 1.2480448587816588, disc_loss = 0.04775256455913946
Trained batch 98 in epoch 8, gen_loss = 1.2492104208830632, disc_loss = 0.04885443342811983
Trained batch 99 in epoch 8, gen_loss = 1.2423562639951706, disc_loss = 0.050486509702168406
Trained batch 100 in epoch 8, gen_loss = 1.2398823293128816, disc_loss = 0.050756917561007905
Trained batch 101 in epoch 8, gen_loss = 1.2412351749691308, disc_loss = 0.05109385895433233
Trained batch 102 in epoch 8, gen_loss = 1.2401003033212088, disc_loss = 0.05113188052115944
Trained batch 103 in epoch 8, gen_loss = 1.2385366839858203, disc_loss = 0.05096080452830602
Trained batch 104 in epoch 8, gen_loss = 1.238145156701406, disc_loss = 0.050966167214903095
Trained batch 105 in epoch 8, gen_loss = 1.2401825285182808, disc_loss = 0.050851537947068516
Trained batch 106 in epoch 8, gen_loss = 1.2342926921131454, disc_loss = 0.052579235960076624
Trained batch 107 in epoch 8, gen_loss = 1.2353458625298959, disc_loss = 0.052246357568677654
Trained batch 108 in epoch 8, gen_loss = 1.240017300352044, disc_loss = 0.05201884268125126
Trained batch 109 in epoch 8, gen_loss = 1.2417826576666398, disc_loss = 0.051734128674830904
Trained batch 110 in epoch 8, gen_loss = 1.2390298075504131, disc_loss = 0.05195093847525952
Trained batch 111 in epoch 8, gen_loss = 1.246470181537526, disc_loss = 0.05238689955772965
Trained batch 112 in epoch 8, gen_loss = 1.250280972603148, disc_loss = 0.052678276821806105
Trained batch 113 in epoch 8, gen_loss = 1.2471568924293184, disc_loss = 0.053081852510538804
Trained batch 114 in epoch 8, gen_loss = 1.250948795546656, disc_loss = 0.052865738401432404
Trained batch 115 in epoch 8, gen_loss = 1.2512388224231785, disc_loss = 0.05300817723337818
Trained batch 116 in epoch 8, gen_loss = 1.25101504723231, disc_loss = 0.052794383484551795
Trained batch 117 in epoch 8, gen_loss = 1.2512497391741155, disc_loss = 0.05248543839128214
Trained batch 118 in epoch 8, gen_loss = 1.252885100721311, disc_loss = 0.05236017745880395
Trained batch 119 in epoch 8, gen_loss = 1.2548546915253003, disc_loss = 0.051992713454334684
Trained batch 120 in epoch 8, gen_loss = 1.252885552969846, disc_loss = 0.05187478930543154
Trained batch 121 in epoch 8, gen_loss = 1.255651844818084, disc_loss = 0.05156599377190358
Trained batch 122 in epoch 8, gen_loss = 1.2546484581823272, disc_loss = 0.05134964452268995
Trained batch 123 in epoch 8, gen_loss = 1.2562294943678765, disc_loss = 0.051060846800194876
Trained batch 124 in epoch 8, gen_loss = 1.2578607506752013, disc_loss = 0.050724634397774936
Trained batch 125 in epoch 8, gen_loss = 1.2586430864674705, disc_loss = 0.05041867491996123
Trained batch 126 in epoch 8, gen_loss = 1.2582193627132205, disc_loss = 0.05011410218861511
Trained batch 127 in epoch 8, gen_loss = 1.257764904294163, disc_loss = 0.05034154431996285
Trained batch 128 in epoch 8, gen_loss = 1.2537846006164255, disc_loss = 0.050803961849576515
Trained batch 129 in epoch 8, gen_loss = 1.2564419430035811, disc_loss = 0.051110757081411204
Trained batch 130 in epoch 8, gen_loss = 1.256858179132447, disc_loss = 0.05079984597733799
Trained batch 131 in epoch 8, gen_loss = 1.253571785309098, disc_loss = 0.05099635380390806
Trained batch 132 in epoch 8, gen_loss = 1.2533406642146576, disc_loss = 0.050694781772204135
Trained batch 133 in epoch 8, gen_loss = 1.2567902932416146, disc_loss = 0.050466445611734224
Trained batch 134 in epoch 8, gen_loss = 1.2581722643640307, disc_loss = 0.05022430527886307
Trained batch 135 in epoch 8, gen_loss = 1.2622322698726374, disc_loss = 0.04997370795086574
Trained batch 136 in epoch 8, gen_loss = 1.2650325450583966, disc_loss = 0.049715416441352044
Trained batch 137 in epoch 8, gen_loss = 1.2649748519710873, disc_loss = 0.049455528704287564
Trained batch 138 in epoch 8, gen_loss = 1.2655358190159145, disc_loss = 0.04918582741800937
Trained batch 139 in epoch 8, gen_loss = 1.2652073626007352, disc_loss = 0.04896427269559354
Trained batch 140 in epoch 8, gen_loss = 1.2662490517535108, disc_loss = 0.048934207571974246
Trained batch 141 in epoch 8, gen_loss = 1.268367672890005, disc_loss = 0.048680347092056146
Trained batch 142 in epoch 8, gen_loss = 1.2653765499175011, disc_loss = 0.048909033671464326
Trained batch 143 in epoch 8, gen_loss = 1.2645984329283237, disc_loss = 0.048734691100738324
Trained batch 144 in epoch 8, gen_loss = 1.2666080684497438, disc_loss = 0.0484463255691888
Trained batch 145 in epoch 8, gen_loss = 1.2717541337829747, disc_loss = 0.048460389573560796
Trained batch 146 in epoch 8, gen_loss = 1.2715106671359264, disc_loss = 0.0482224240791382
Trained batch 147 in epoch 8, gen_loss = 1.2726198551622596, disc_loss = 0.04792827152886201
Trained batch 148 in epoch 8, gen_loss = 1.2719308781943865, disc_loss = 0.047833714224773165
Trained batch 149 in epoch 8, gen_loss = 1.2732627244790395, disc_loss = 0.047575554540380836
Trained batch 150 in epoch 8, gen_loss = 1.274700934918511, disc_loss = 0.04730882019186947
Trained batch 151 in epoch 8, gen_loss = 1.27622334149323, disc_loss = 0.04718883889175853
Trained batch 152 in epoch 8, gen_loss = 1.2728012192483042, disc_loss = 0.04757373229436138
Trained batch 153 in epoch 8, gen_loss = 1.2747514642678297, disc_loss = 0.047360407064559976
Trained batch 154 in epoch 8, gen_loss = 1.2751406969562653, disc_loss = 0.047267764923913824
Trained batch 155 in epoch 8, gen_loss = 1.2777996712770217, disc_loss = 0.04709299266612969
Trained batch 156 in epoch 8, gen_loss = 1.27790931987155, disc_loss = 0.0468498704166027
Trained batch 157 in epoch 8, gen_loss = 1.2758010561707653, disc_loss = 0.04680503720028585
Trained batch 158 in epoch 8, gen_loss = 1.2769900121778812, disc_loss = 0.04664048054929143
Trained batch 159 in epoch 8, gen_loss = 1.2757631745189428, disc_loss = 0.046484814785071646
Trained batch 160 in epoch 8, gen_loss = 1.2771634600177315, disc_loss = 0.04629016932828919
Trained batch 161 in epoch 8, gen_loss = 1.2754159120865811, disc_loss = 0.04631006594942768
Trained batch 162 in epoch 8, gen_loss = 1.2766039656715158, disc_loss = 0.04624943848002268
Trained batch 163 in epoch 8, gen_loss = 1.276177507348177, disc_loss = 0.04744845793707433
Trained batch 164 in epoch 8, gen_loss = 1.272411794012243, disc_loss = 0.04802988985779159
Trained batch 165 in epoch 8, gen_loss = 1.270202427384365, disc_loss = 0.048287087908373716
Trained batch 166 in epoch 8, gen_loss = 1.2714939306596083, disc_loss = 0.048317854869887676
Trained batch 167 in epoch 8, gen_loss = 1.2724649185935657, disc_loss = 0.04828239941049278
Trained batch 168 in epoch 8, gen_loss = 1.2726786549274738, disc_loss = 0.04817973631957667
Trained batch 169 in epoch 8, gen_loss = 1.2715665932963875, disc_loss = 0.048184913542012084
Trained batch 170 in epoch 8, gen_loss = 1.2724379158159445, disc_loss = 0.04796521138258235
Trained batch 171 in epoch 8, gen_loss = 1.2740271843450015, disc_loss = 0.047772716495295076
Trained batch 172 in epoch 8, gen_loss = 1.2739477112803157, disc_loss = 0.04754590290743922
Trained batch 173 in epoch 8, gen_loss = 1.27482843912881, disc_loss = 0.04739584184208906
Trained batch 174 in epoch 8, gen_loss = 1.2733971517426628, disc_loss = 0.04728437962542687
Trained batch 175 in epoch 8, gen_loss = 1.273674894801595, disc_loss = 0.04706253872559914
Trained batch 176 in epoch 8, gen_loss = 1.2740463466294067, disc_loss = 0.046824397632357594
Trained batch 177 in epoch 8, gen_loss = 1.2744542584660348, disc_loss = 0.04659702740557324
Trained batch 178 in epoch 8, gen_loss = 1.275843001277753, disc_loss = 0.04653277681807483
Trained batch 179 in epoch 8, gen_loss = 1.2762185172902214, disc_loss = 0.04656447402667254
Trained batch 180 in epoch 8, gen_loss = 1.2730628508889215, disc_loss = 0.04695675121517389
Trained batch 181 in epoch 8, gen_loss = 1.27265375656086, disc_loss = 0.04677462909667456
Trained batch 182 in epoch 8, gen_loss = 1.274142088134432, disc_loss = 0.04664928735045543
Trained batch 183 in epoch 8, gen_loss = 1.2762902249460635, disc_loss = 0.0464753771539899
Trained batch 184 in epoch 8, gen_loss = 1.2767603352263166, disc_loss = 0.04625244878635213
Trained batch 185 in epoch 8, gen_loss = 1.2760248530295588, disc_loss = 0.04614596320216053
Trained batch 186 in epoch 8, gen_loss = 1.2756969055389975, disc_loss = 0.045986892197301045
Trained batch 187 in epoch 8, gen_loss = 1.2776981427314433, disc_loss = 0.045793248479195095
Trained batch 188 in epoch 8, gen_loss = 1.2774186247871036, disc_loss = 0.04565057778366344
Trained batch 189 in epoch 8, gen_loss = 1.2781565189361572, disc_loss = 0.04546465722745971
Trained batch 190 in epoch 8, gen_loss = 1.2795123017895285, disc_loss = 0.04548693541924991
Trained batch 191 in epoch 8, gen_loss = 1.2786631491035223, disc_loss = 0.04536359367193654
Trained batch 192 in epoch 8, gen_loss = 1.2778344308774088, disc_loss = 0.045247335720401974
Trained batch 193 in epoch 8, gen_loss = 1.276722047132315, disc_loss = 0.04513223369404213
Trained batch 194 in epoch 8, gen_loss = 1.2789254017365284, disc_loss = 0.04501707229094628
Trained batch 195 in epoch 8, gen_loss = 1.2801207699337784, disc_loss = 0.04484899729794385
Trained batch 196 in epoch 8, gen_loss = 1.2817441866482575, disc_loss = 0.04466659181897864
Trained batch 197 in epoch 8, gen_loss = 1.2820435509537205, disc_loss = 0.04447706507500073
Trained batch 198 in epoch 8, gen_loss = 1.2814228307062656, disc_loss = 0.0443209688548916
Trained batch 199 in epoch 8, gen_loss = 1.2811117577552795, disc_loss = 0.044127475444693115
Trained batch 200 in epoch 8, gen_loss = 1.2823115118700474, disc_loss = 0.0439456936124879
Trained batch 201 in epoch 8, gen_loss = 1.2840981571981223, disc_loss = 0.043801443266341146
Trained batch 202 in epoch 8, gen_loss = 1.2845395227958416, disc_loss = 0.043607253500999046
Trained batch 203 in epoch 8, gen_loss = 1.2854575152490653, disc_loss = 0.04346210941644933
Trained batch 204 in epoch 8, gen_loss = 1.2850394888622005, disc_loss = 0.04331011476176905
Trained batch 205 in epoch 8, gen_loss = 1.2856026135602043, disc_loss = 0.04315610798482684
Trained batch 206 in epoch 8, gen_loss = 1.2859124382912825, disc_loss = 0.042966844439776476
Trained batch 207 in epoch 8, gen_loss = 1.2864609859310663, disc_loss = 0.042783070306401126
Trained batch 208 in epoch 8, gen_loss = 1.287131835399062, disc_loss = 0.0425972669657195
Trained batch 209 in epoch 8, gen_loss = 1.2878926016035535, disc_loss = 0.04241052616188037
Trained batch 210 in epoch 8, gen_loss = 1.288125779956438, disc_loss = 0.04222759739407537
Trained batch 211 in epoch 8, gen_loss = 1.2884351178160254, disc_loss = 0.042047168983735214
Trained batch 212 in epoch 8, gen_loss = 1.2888991681622788, disc_loss = 0.0420692033416421
Trained batch 213 in epoch 8, gen_loss = 1.2887028672984828, disc_loss = 0.0419116919657877
Trained batch 214 in epoch 8, gen_loss = 1.289344673378523, disc_loss = 0.0417607725955286
Trained batch 215 in epoch 8, gen_loss = 1.289525004448714, disc_loss = 0.04158774902073977
Trained batch 216 in epoch 8, gen_loss = 1.2902517933999338, disc_loss = 0.04143422753507194
Trained batch 217 in epoch 8, gen_loss = 1.2904015112360683, disc_loss = 0.04126889206396433
Trained batch 218 in epoch 8, gen_loss = 1.2913482537552647, disc_loss = 0.04110363404241021
Trained batch 219 in epoch 8, gen_loss = 1.2908441982486032, disc_loss = 0.04099152107109231
Trained batch 220 in epoch 8, gen_loss = 1.2918871473942408, disc_loss = 0.04087177161190541
Trained batch 221 in epoch 8, gen_loss = 1.2943034274084073, disc_loss = 0.04079278172014768
Trained batch 222 in epoch 8, gen_loss = 1.2956007692311378, disc_loss = 0.04066259504062011
Trained batch 223 in epoch 8, gen_loss = 1.2953464990215642, disc_loss = 0.04054077542449314
Trained batch 224 in epoch 8, gen_loss = 1.294845117463006, disc_loss = 0.040411251674716674
Trained batch 225 in epoch 8, gen_loss = 1.2961048420551604, disc_loss = 0.04028166984146115
Trained batch 226 in epoch 8, gen_loss = 1.29570077116794, disc_loss = 0.04012952452332667
Trained batch 227 in epoch 8, gen_loss = 1.2955691113806607, disc_loss = 0.039971342004974486
Trained batch 228 in epoch 8, gen_loss = 1.2951954868683129, disc_loss = 0.03983522453508035
Trained batch 229 in epoch 8, gen_loss = 1.2955916694972827, disc_loss = 0.039681282116140686
Trained batch 230 in epoch 8, gen_loss = 1.2963621028057941, disc_loss = 0.03952783433563233
Trained batch 231 in epoch 8, gen_loss = 1.297135630558277, disc_loss = 0.03937961805334861
Trained batch 232 in epoch 8, gen_loss = 1.297635841778931, disc_loss = 0.039227086961741035
Trained batch 233 in epoch 8, gen_loss = 1.2975392682939513, disc_loss = 0.03908881163284278
Trained batch 234 in epoch 8, gen_loss = 1.2974305426820796, disc_loss = 0.038941517970623805
Trained batch 235 in epoch 8, gen_loss = 1.297672967789537, disc_loss = 0.03878980664678423
Trained batch 236 in epoch 8, gen_loss = 1.2981318406414886, disc_loss = 0.03863993415192461
Trained batch 237 in epoch 8, gen_loss = 1.2984508666671624, disc_loss = 0.03849593666969102
Trained batch 238 in epoch 8, gen_loss = 1.2985882858850966, disc_loss = 0.03835887541004679
Trained batch 239 in epoch 8, gen_loss = 1.299537075559298, disc_loss = 0.038236033780655515
Trained batch 240 in epoch 8, gen_loss = 1.2994264725332934, disc_loss = 0.03813678175365529
Trained batch 241 in epoch 8, gen_loss = 1.2991781889899703, disc_loss = 0.038015494323220135
Trained batch 242 in epoch 8, gen_loss = 1.2991465168234744, disc_loss = 0.0378800366043186
Trained batch 243 in epoch 8, gen_loss = 1.2999214999011306, disc_loss = 0.03774664317234801
Trained batch 244 in epoch 8, gen_loss = 1.3005067854511494, disc_loss = 0.03760412883260572
Trained batch 245 in epoch 8, gen_loss = 1.3009607985736877, disc_loss = 0.037464117729748656
Trained batch 246 in epoch 8, gen_loss = 1.3008333574905087, disc_loss = 0.03734830953557844
Trained batch 247 in epoch 8, gen_loss = 1.3005616660079649, disc_loss = 0.037217253841640006
Trained batch 248 in epoch 8, gen_loss = 1.2999203870574154, disc_loss = 0.03717747269325467
Trained batch 249 in epoch 8, gen_loss = 1.3013077182769774, disc_loss = 0.03706192070618272
Trained batch 250 in epoch 8, gen_loss = 1.3009743462520766, disc_loss = 0.03696497566107497
Trained batch 251 in epoch 8, gen_loss = 1.3014497908334883, disc_loss = 0.036835315191955674
Trained batch 252 in epoch 8, gen_loss = 1.3014983466491397, disc_loss = 0.036710167761980425
Trained batch 253 in epoch 8, gen_loss = 1.3020105404177988, disc_loss = 0.03657754463524976
Trained batch 254 in epoch 8, gen_loss = 1.3027644063912185, disc_loss = 0.036456410612399674
Trained batch 255 in epoch 8, gen_loss = 1.3034301036968827, disc_loss = 0.03633208348765038
Trained batch 256 in epoch 8, gen_loss = 1.3034569474973567, disc_loss = 0.03624043053429182
Trained batch 257 in epoch 8, gen_loss = 1.3043725000795467, disc_loss = 0.03613097479841275
Trained batch 258 in epoch 8, gen_loss = 1.3043797108197304, disc_loss = 0.03600944164047255
Trained batch 259 in epoch 8, gen_loss = 1.3048122470195478, disc_loss = 0.03588195918486095
Trained batch 260 in epoch 8, gen_loss = 1.3049709047850977, disc_loss = 0.03575783655211558
Trained batch 261 in epoch 8, gen_loss = 1.3053125261350442, disc_loss = 0.03563524972921138
Trained batch 262 in epoch 8, gen_loss = 1.30615500442882, disc_loss = 0.03553962814904919
Trained batch 263 in epoch 8, gen_loss = 1.3056521487958503, disc_loss = 0.0354620898398218
Trained batch 264 in epoch 8, gen_loss = 1.3052887853586448, disc_loss = 0.03536675392896078
Trained batch 265 in epoch 8, gen_loss = 1.3067991437768578, disc_loss = 0.03528551244845656
Trained batch 266 in epoch 8, gen_loss = 1.307508112785968, disc_loss = 0.03516968843624805
Trained batch 267 in epoch 8, gen_loss = 1.3089058590469076, disc_loss = 0.03508673164447936
Trained batch 268 in epoch 8, gen_loss = 1.3090207337446815, disc_loss = 0.034968624825392015
Trained batch 269 in epoch 8, gen_loss = 1.3087079993000736, disc_loss = 0.03487658679950982
Trained batch 270 in epoch 8, gen_loss = 1.3092534850004414, disc_loss = 0.03476089422034299
Trained batch 271 in epoch 8, gen_loss = 1.3100527463590397, disc_loss = 0.034658611386582966
Trained batch 272 in epoch 8, gen_loss = 1.3098521852667953, disc_loss = 0.03454901039985865
Trained batch 273 in epoch 8, gen_loss = 1.3105594354824428, disc_loss = 0.034437873314923345
Trained batch 274 in epoch 8, gen_loss = 1.3098553770238703, disc_loss = 0.034369347098029475
Trained batch 275 in epoch 8, gen_loss = 1.310780580492987, disc_loss = 0.03429853837461332
Trained batch 276 in epoch 8, gen_loss = 1.311336630948614, disc_loss = 0.03419269306252337
Trained batch 277 in epoch 8, gen_loss = 1.3115850009506556, disc_loss = 0.03408117224747087
Trained batch 278 in epoch 8, gen_loss = 1.3111360496090305, disc_loss = 0.0340287752381082
Trained batch 279 in epoch 8, gen_loss = 1.3114306999104364, disc_loss = 0.033918842250880384
Trained batch 280 in epoch 8, gen_loss = 1.3128767492932356, disc_loss = 0.03390849751894266
Trained batch 281 in epoch 8, gen_loss = 1.3134826400601272, disc_loss = 0.03379871931376187
Trained batch 282 in epoch 8, gen_loss = 1.3135140889946226, disc_loss = 0.033696402887757805
Trained batch 283 in epoch 8, gen_loss = 1.3130688667297363, disc_loss = 0.033621586836271096
Trained batch 284 in epoch 8, gen_loss = 1.3128684980827465, disc_loss = 0.033523171231673476
Trained batch 285 in epoch 8, gen_loss = 1.3135391332052804, disc_loss = 0.03342221047520846
Trained batch 286 in epoch 8, gen_loss = 1.31374099528748, disc_loss = 0.03333925606377864
Trained batch 287 in epoch 8, gen_loss = 1.3138835959964328, disc_loss = 0.03323952577516644
Trained batch 288 in epoch 8, gen_loss = 1.3142276849713705, disc_loss = 0.033141767140477896
Trained batch 289 in epoch 8, gen_loss = 1.3139462343577681, disc_loss = 0.033069607051860156
Trained batch 290 in epoch 8, gen_loss = 1.3142739112434518, disc_loss = 0.032966160745907226
Trained batch 291 in epoch 8, gen_loss = 1.314202421332059, disc_loss = 0.03286976304642014
Trained batch 292 in epoch 8, gen_loss = 1.3144290675075387, disc_loss = 0.03298072932596372
Trained batch 293 in epoch 8, gen_loss = 1.3125321818452302, disc_loss = 0.03311316857706806
Trained batch 294 in epoch 8, gen_loss = 1.3132543258747813, disc_loss = 0.03303684326346522
Trained batch 295 in epoch 8, gen_loss = 1.3144628737826605, disc_loss = 0.032971548312186336
Trained batch 296 in epoch 8, gen_loss = 1.3152763825474363, disc_loss = 0.03293463818474927
Trained batch 297 in epoch 8, gen_loss = 1.3155948573710934, disc_loss = 0.03284361998272447
Trained batch 298 in epoch 8, gen_loss = 1.3146966518367014, disc_loss = 0.03283392698784362
Trained batch 299 in epoch 8, gen_loss = 1.3152381104230881, disc_loss = 0.03275506085793798
Trained batch 300 in epoch 8, gen_loss = 1.3144102411412717, disc_loss = 0.03270869480950318
Trained batch 301 in epoch 8, gen_loss = 1.314755977976401, disc_loss = 0.032617949818211624
Trained batch 302 in epoch 8, gen_loss = 1.3148191555498456, disc_loss = 0.03253389172879948
Trained batch 303 in epoch 8, gen_loss = 1.3152927981787605, disc_loss = 0.03243876636368345
Trained batch 304 in epoch 8, gen_loss = 1.3154094916875245, disc_loss = 0.03234726268050001
Trained batch 305 in epoch 8, gen_loss = 1.3157053813825246, disc_loss = 0.03225900439980738
Trained batch 306 in epoch 8, gen_loss = 1.3163980620303448, disc_loss = 0.032165875895773986
Trained batch 307 in epoch 8, gen_loss = 1.3160008166904573, disc_loss = 0.032092505035613506
Trained batch 308 in epoch 8, gen_loss = 1.316287025857512, disc_loss = 0.03200143789887597
Trained batch 309 in epoch 8, gen_loss = 1.316597020049249, disc_loss = 0.031920268136497225
Trained batch 310 in epoch 8, gen_loss = 1.3172859308037344, disc_loss = 0.03183307186131429
Trained batch 311 in epoch 8, gen_loss = 1.317482933593102, disc_loss = 0.03174082212559043
Trained batch 312 in epoch 8, gen_loss = 1.318163729513796, disc_loss = 0.031685600965506974
Trained batch 313 in epoch 8, gen_loss = 1.3188545694396754, disc_loss = 0.03160767935907504
Trained batch 314 in epoch 8, gen_loss = 1.3187437002621, disc_loss = 0.03152850295919629
Trained batch 315 in epoch 8, gen_loss = 1.318388690488248, disc_loss = 0.03144140142425777
Trained batch 316 in epoch 8, gen_loss = 1.3181544453939804, disc_loss = 0.03135700943462598
Trained batch 317 in epoch 8, gen_loss = 1.3190413096790794, disc_loss = 0.03127931577882747
Trained batch 318 in epoch 8, gen_loss = 1.319684525455427, disc_loss = 0.03119603874596846
Trained batch 319 in epoch 8, gen_loss = 1.3199699958786368, disc_loss = 0.031107960741064745
Trained batch 320 in epoch 8, gen_loss = 1.3202474954715027, disc_loss = 0.031027117213872597
Trained batch 321 in epoch 8, gen_loss = 1.3201154505614168, disc_loss = 0.03094476831698015
Trained batch 322 in epoch 8, gen_loss = 1.3202284126089823, disc_loss = 0.030860197394451953
Trained batch 323 in epoch 8, gen_loss = 1.320311630765597, disc_loss = 0.0312101295588676
Trained batch 324 in epoch 8, gen_loss = 1.3182558463169978, disc_loss = 0.031622703541070225
Trained batch 325 in epoch 8, gen_loss = 1.3172180707469308, disc_loss = 0.031603736638668584
Trained batch 326 in epoch 8, gen_loss = 1.3178833365804923, disc_loss = 0.03153506998080954
Trained batch 327 in epoch 8, gen_loss = 1.3193272152325002, disc_loss = 0.03151526728150912
Trained batch 328 in epoch 8, gen_loss = 1.3196245243484126, disc_loss = 0.03143387382544328
Trained batch 329 in epoch 8, gen_loss = 1.3205423860838919, disc_loss = 0.03136492103592239
Trained batch 330 in epoch 8, gen_loss = 1.319401937489063, disc_loss = 0.031366698968637835
Trained batch 331 in epoch 8, gen_loss = 1.319763048406107, disc_loss = 0.03130266184957855
Trained batch 332 in epoch 8, gen_loss = 1.3189922440517414, disc_loss = 0.03127951764112881
Trained batch 333 in epoch 8, gen_loss = 1.3186291993378165, disc_loss = 0.03123363565436068
Trained batch 334 in epoch 8, gen_loss = 1.3181450276232478, disc_loss = 0.03117585096702869
Trained batch 335 in epoch 8, gen_loss = 1.3182772751010599, disc_loss = 0.0322054025309626
Trained batch 336 in epoch 8, gen_loss = 1.317974738091319, disc_loss = 0.032170515547531385
Trained batch 337 in epoch 8, gen_loss = 1.3164720097942466, disc_loss = 0.032304056172022186
Trained batch 338 in epoch 8, gen_loss = 1.316104422628352, disc_loss = 0.032284849618663215
Trained batch 339 in epoch 8, gen_loss = 1.31706542022088, disc_loss = 0.03229756004259209
Trained batch 340 in epoch 8, gen_loss = 1.3178647011955462, disc_loss = 0.03223212981389022
Trained batch 341 in epoch 8, gen_loss = 1.3178732621739482, disc_loss = 0.032165348032837986
Trained batch 342 in epoch 8, gen_loss = 1.3178905210411584, disc_loss = 0.03208959693328067
Trained batch 343 in epoch 8, gen_loss = 1.3170954931614012, disc_loss = 0.03215423843493079
Trained batch 344 in epoch 8, gen_loss = 1.3175858908805294, disc_loss = 0.0320811085038535
Trained batch 345 in epoch 8, gen_loss = 1.317543090767943, disc_loss = 0.03199917464813142
Trained batch 346 in epoch 8, gen_loss = 1.317907265696127, disc_loss = 0.03192075471036802
Trained batch 347 in epoch 8, gen_loss = 1.3180276388409493, disc_loss = 0.032299174255445255
Trained batch 348 in epoch 8, gen_loss = 1.3162975731415187, disc_loss = 0.03246679590657396
Trained batch 349 in epoch 8, gen_loss = 1.3144613564014436, disc_loss = 0.03273004489551697
Trained batch 350 in epoch 8, gen_loss = 1.315248608079731, disc_loss = 0.032820377321091304
Trained batch 351 in epoch 8, gen_loss = 1.3154436256736517, disc_loss = 0.03289680571602234
Trained batch 352 in epoch 8, gen_loss = 1.3149955520886538, disc_loss = 0.03284605723613129
Trained batch 353 in epoch 8, gen_loss = 1.314321921201749, disc_loss = 0.032805987010252176
Trained batch 354 in epoch 8, gen_loss = 1.3137932718639642, disc_loss = 0.032772107036705585
Trained batch 355 in epoch 8, gen_loss = 1.3139834948135225, disc_loss = 0.03270113994262778
Trained batch 356 in epoch 8, gen_loss = 1.3142846737589156, disc_loss = 0.03262273590302184
Trained batch 357 in epoch 8, gen_loss = 1.3152136481341037, disc_loss = 0.03256404507572258
Trained batch 358 in epoch 8, gen_loss = 1.3157829071153837, disc_loss = 0.03249442430529588
Trained batch 359 in epoch 8, gen_loss = 1.315938345094522, disc_loss = 0.03242012992397779
Trained batch 360 in epoch 8, gen_loss = 1.315971971053496, disc_loss = 0.03237276427819293
Trained batch 361 in epoch 8, gen_loss = 1.3154924856035748, disc_loss = 0.03231396386142594
Trained batch 362 in epoch 8, gen_loss = 1.3148496917785035, disc_loss = 0.03229655217656419
Trained batch 363 in epoch 8, gen_loss = 1.3158114577060218, disc_loss = 0.032862575980578804
Trained batch 364 in epoch 8, gen_loss = 1.313787286412226, disc_loss = 0.0330933214356638
Trained batch 365 in epoch 8, gen_loss = 1.3133792487975677, disc_loss = 0.033041105554769926
Trained batch 366 in epoch 8, gen_loss = 1.3147125606315988, disc_loss = 0.0330137036618972
Trained batch 367 in epoch 8, gen_loss = 1.315045097761828, disc_loss = 0.032950465860979064
Trained batch 368 in epoch 8, gen_loss = 1.3148467658658014, disc_loss = 0.03288902178770158
Trained batch 369 in epoch 8, gen_loss = 1.3137096732049376, disc_loss = 0.03292078039533383
Trained batch 370 in epoch 8, gen_loss = 1.313162759147243, disc_loss = 0.03289688597972984
Trained batch 371 in epoch 8, gen_loss = 1.313293148593236, disc_loss = 0.032827325252896195
Trained batch 372 in epoch 8, gen_loss = 1.31257346632014, disc_loss = 0.03281584467698917
Trained batch 373 in epoch 8, gen_loss = 1.312647433682559, disc_loss = 0.03362722246394677
Trained batch 374 in epoch 8, gen_loss = 1.3104003303050995, disc_loss = 0.03443043269465367
Trained batch 375 in epoch 8, gen_loss = 1.3107405010848603, disc_loss = 0.03447923097670316
Trained batch 376 in epoch 8, gen_loss = 1.3100763585428343, disc_loss = 0.03446964582364107
Trained batch 377 in epoch 8, gen_loss = 1.3100737945901022, disc_loss = 0.0344418669833984
Trained batch 378 in epoch 8, gen_loss = 1.3086932958116002, disc_loss = 0.03456938364801039
Trained batch 379 in epoch 8, gen_loss = 1.3077474452163045, disc_loss = 0.034605941713150394
Trained batch 380 in epoch 8, gen_loss = 1.308592677351058, disc_loss = 0.03478638097164747
Trained batch 381 in epoch 8, gen_loss = 1.3078952942687179, disc_loss = 0.034839567467472785
Trained batch 382 in epoch 8, gen_loss = 1.3076974009564901, disc_loss = 0.034790704087609564
Trained batch 383 in epoch 8, gen_loss = 1.3080655316977452, disc_loss = 0.034721997367644995
Trained batch 384 in epoch 8, gen_loss = 1.3099036550367034, disc_loss = 0.034939318929206244
Trained batch 385 in epoch 8, gen_loss = 1.3087027993998996, disc_loss = 0.03519979910201205
Trained batch 386 in epoch 8, gen_loss = 1.3090891031793845, disc_loss = 0.0351279906565155
Trained batch 387 in epoch 8, gen_loss = 1.310339464431571, disc_loss = 0.03512473801539769
Trained batch 388 in epoch 8, gen_loss = 1.3096595166734681, disc_loss = 0.03510573784674693
Trained batch 389 in epoch 8, gen_loss = 1.3090519792758502, disc_loss = 0.035066711985004634
Trained batch 390 in epoch 8, gen_loss = 1.3101357210170277, disc_loss = 0.035056493491591775
Trained batch 391 in epoch 8, gen_loss = 1.3094892566453438, disc_loss = 0.03509557031555938
Trained batch 392 in epoch 8, gen_loss = 1.3093921990339992, disc_loss = 0.035028147192449136
Trained batch 393 in epoch 8, gen_loss = 1.3092854057017922, disc_loss = 0.03498097902121315
Trained batch 394 in epoch 8, gen_loss = 1.309104016234603, disc_loss = 0.03491569933705503
Trained batch 395 in epoch 8, gen_loss = 1.3092113523320719, disc_loss = 0.03486816838002679
Trained batch 396 in epoch 8, gen_loss = 1.308823945915669, disc_loss = 0.03488185195608876
Trained batch 397 in epoch 8, gen_loss = 1.309490132646345, disc_loss = 0.034812503434652135
Trained batch 398 in epoch 8, gen_loss = 1.3100442776554508, disc_loss = 0.034752044015631714
Trained batch 399 in epoch 8, gen_loss = 1.3086209044605495, disc_loss = 0.034901722018839794
Trained batch 400 in epoch 8, gen_loss = 1.308634702478561, disc_loss = 0.034891012601991025
Trained batch 401 in epoch 8, gen_loss = 1.3100669559702944, disc_loss = 0.0348914187987664
Trained batch 402 in epoch 8, gen_loss = 1.3109074902741549, disc_loss = 0.03486580710520704
Trained batch 403 in epoch 8, gen_loss = 1.3103506164533076, disc_loss = 0.03485994541782443
Trained batch 404 in epoch 8, gen_loss = 1.3097910293090491, disc_loss = 0.03481564104763998
Trained batch 405 in epoch 8, gen_loss = 1.310687301854782, disc_loss = 0.03534414720712367
Trained batch 406 in epoch 8, gen_loss = 1.3089811662051836, disc_loss = 0.03565935877149499
Trained batch 407 in epoch 8, gen_loss = 1.309342869137432, disc_loss = 0.03560975505673673
Trained batch 408 in epoch 8, gen_loss = 1.3093757289108845, disc_loss = 0.035562819041867345
Trained batch 409 in epoch 8, gen_loss = 1.3087800221472252, disc_loss = 0.035583342651541276
Trained batch 410 in epoch 8, gen_loss = 1.3088173556646872, disc_loss = 0.03551345740143581
Trained batch 411 in epoch 8, gen_loss = 1.309558754768765, disc_loss = 0.035515373872222325
Trained batch 412 in epoch 8, gen_loss = 1.3083225232492637, disc_loss = 0.03559382455694077
Trained batch 413 in epoch 8, gen_loss = 1.3082795817638941, disc_loss = 0.03552918095290121
Trained batch 414 in epoch 8, gen_loss = 1.308904682081866, disc_loss = 0.035470150993486126
Trained batch 415 in epoch 8, gen_loss = 1.3093181267523994, disc_loss = 0.035546788881989554
Trained batch 416 in epoch 8, gen_loss = 1.3086742346378253, disc_loss = 0.0355346449137145
Trained batch 417 in epoch 8, gen_loss = 1.3076385856387718, disc_loss = 0.03564318175801927
Trained batch 418 in epoch 8, gen_loss = 1.3087431764972524, disc_loss = 0.03561005206014028
Trained batch 419 in epoch 8, gen_loss = 1.3086535826325416, disc_loss = 0.03553651704319886
Trained batch 420 in epoch 8, gen_loss = 1.30894559388206, disc_loss = 0.03546612209700172
Trained batch 421 in epoch 8, gen_loss = 1.3088127609819034, disc_loss = 0.035402637878785975
Trained batch 422 in epoch 8, gen_loss = 1.3083782577204648, disc_loss = 0.03537668567260917
Trained batch 423 in epoch 8, gen_loss = 1.308986996493812, disc_loss = 0.03536450814451354
Trained batch 424 in epoch 8, gen_loss = 1.3089868425621707, disc_loss = 0.035369693276417605
Trained batch 425 in epoch 8, gen_loss = 1.3081659818059401, disc_loss = 0.035377385198606504
Trained batch 426 in epoch 8, gen_loss = 1.30707214357423, disc_loss = 0.03541808446162583
Trained batch 427 in epoch 8, gen_loss = 1.307509573193911, disc_loss = 0.035360993315883535
Trained batch 428 in epoch 8, gen_loss = 1.308262964437058, disc_loss = 0.03531404001429885
Trained batch 429 in epoch 8, gen_loss = 1.308697778333065, disc_loss = 0.035275465530494966
Trained batch 430 in epoch 8, gen_loss = 1.3088029553193228, disc_loss = 0.03521084929697579
Trained batch 431 in epoch 8, gen_loss = 1.3085156507376168, disc_loss = 0.03516843882109107
Trained batch 432 in epoch 8, gen_loss = 1.3083850857704946, disc_loss = 0.03511182851895828
Trained batch 433 in epoch 8, gen_loss = 1.308172857637779, disc_loss = 0.035094165246427264
Trained batch 434 in epoch 8, gen_loss = 1.3086133424578041, disc_loss = 0.03513284060012164
Trained batch 435 in epoch 8, gen_loss = 1.3085855679637795, disc_loss = 0.03524289090387147
Trained batch 436 in epoch 8, gen_loss = 1.3082594338898255, disc_loss = 0.03520444994451354
Trained batch 437 in epoch 8, gen_loss = 1.3082723695801817, disc_loss = 0.035150318473500954
Trained batch 438 in epoch 8, gen_loss = 1.308067745051786, disc_loss = 0.03510465690280589
Trained batch 439 in epoch 8, gen_loss = 1.3089111725715075, disc_loss = 0.035060408255297014
Trained batch 440 in epoch 8, gen_loss = 1.3093004185461403, disc_loss = 0.035010749994737016
Trained batch 441 in epoch 8, gen_loss = 1.309511340783732, disc_loss = 0.03495201830566772
Trained batch 442 in epoch 8, gen_loss = 1.3093187560749915, disc_loss = 0.03490184980043069
Trained batch 443 in epoch 8, gen_loss = 1.3094302442025494, disc_loss = 0.03483897874127603
Trained batch 444 in epoch 8, gen_loss = 1.3098967013064395, disc_loss = 0.03478328604774361
Trained batch 445 in epoch 8, gen_loss = 1.3101196074565964, disc_loss = 0.03471562312915921
Trained batch 446 in epoch 8, gen_loss = 1.3103567225154347, disc_loss = 0.03464633395001542
Trained batch 447 in epoch 8, gen_loss = 1.310539677140436, disc_loss = 0.034576349033159204
Trained batch 448 in epoch 8, gen_loss = 1.3104932973937096, disc_loss = 0.03451695026444035
Trained batch 449 in epoch 8, gen_loss = 1.3106279057264327, disc_loss = 0.034465114292171264
Trained batch 450 in epoch 8, gen_loss = 1.3114388231559762, disc_loss = 0.03440545664526142
Trained batch 451 in epoch 8, gen_loss = 1.3119377872980802, disc_loss = 0.034343523615188234
Trained batch 452 in epoch 8, gen_loss = 1.3122735428099601, disc_loss = 0.03431807846862979
Trained batch 453 in epoch 8, gen_loss = 1.3118220666825509, disc_loss = 0.03428082827310435
Trained batch 454 in epoch 8, gen_loss = 1.3120904675551823, disc_loss = 0.034229352719222124
Trained batch 455 in epoch 8, gen_loss = 1.3124486928838386, disc_loss = 0.03416783851265025
Trained batch 456 in epoch 8, gen_loss = 1.3128041117013936, disc_loss = 0.034104757918823406
Trained batch 457 in epoch 8, gen_loss = 1.313219172400158, disc_loss = 0.03458257206089339
Trained batch 458 in epoch 8, gen_loss = 1.312337874651994, disc_loss = 0.03461959434080715
Trained batch 459 in epoch 8, gen_loss = 1.3116495135685673, disc_loss = 0.03464442300711475
Trained batch 460 in epoch 8, gen_loss = 1.3118124590649263, disc_loss = 0.034714898505650155
Trained batch 461 in epoch 8, gen_loss = 1.3120912889510523, disc_loss = 0.03468999738635665
Trained batch 462 in epoch 8, gen_loss = 1.3125681988492641, disc_loss = 0.034658355858643616
Trained batch 463 in epoch 8, gen_loss = 1.3127784359686334, disc_loss = 0.03461062311544083
Trained batch 464 in epoch 8, gen_loss = 1.3125646607209278, disc_loss = 0.0345942781567173
Trained batch 465 in epoch 8, gen_loss = 1.312853131747041, disc_loss = 0.034543888752304755
Trained batch 466 in epoch 8, gen_loss = 1.3129803721475908, disc_loss = 0.034485998865599866
Trained batch 467 in epoch 8, gen_loss = 1.3121467192585652, disc_loss = 0.03452917352481944
Trained batch 468 in epoch 8, gen_loss = 1.312915672434927, disc_loss = 0.03449117722831714
Trained batch 469 in epoch 8, gen_loss = 1.313139790486782, disc_loss = 0.03457248290267555
Trained batch 470 in epoch 8, gen_loss = 1.311410753463737, disc_loss = 0.03499588816507765
Trained batch 471 in epoch 8, gen_loss = 1.3107487291602764, disc_loss = 0.0350212543202422
Trained batch 472 in epoch 8, gen_loss = 1.3123311724269617, disc_loss = 0.035169840773595126
Trained batch 473 in epoch 8, gen_loss = 1.311347981293996, disc_loss = 0.03521647856900869
Trained batch 474 in epoch 8, gen_loss = 1.309930521061546, disc_loss = 0.03535963239736463
Trained batch 475 in epoch 8, gen_loss = 1.3099264099317438, disc_loss = 0.03532714572120771
Trained batch 476 in epoch 8, gen_loss = 1.3095347363993806, disc_loss = 0.03531863833377352
Trained batch 477 in epoch 8, gen_loss = 1.3095490306491133, disc_loss = 0.035394182803779525
Trained batch 478 in epoch 8, gen_loss = 1.3097740929410453, disc_loss = 0.035347430079218804
Trained batch 479 in epoch 8, gen_loss = 1.3090266659855843, disc_loss = 0.0353962870479639
Trained batch 480 in epoch 8, gen_loss = 1.3094060941446348, disc_loss = 0.03542081004186783
Trained batch 481 in epoch 8, gen_loss = 1.3087833793331478, disc_loss = 0.03542005734545221
Trained batch 482 in epoch 8, gen_loss = 1.3096831713650785, disc_loss = 0.03538909493646667
Trained batch 483 in epoch 8, gen_loss = 1.309963622369057, disc_loss = 0.03532863798943802
Trained batch 484 in epoch 8, gen_loss = 1.3090817402318582, disc_loss = 0.03533837126625567
Trained batch 485 in epoch 8, gen_loss = 1.3101730434982866, disc_loss = 0.035374492625303476
Trained batch 486 in epoch 8, gen_loss = 1.3097159304413217, disc_loss = 0.03538746872125098
Trained batch 487 in epoch 8, gen_loss = 1.3087617784249979, disc_loss = 0.03540783794978481
Trained batch 488 in epoch 8, gen_loss = 1.30837008558168, disc_loss = 0.03536704429453867
Trained batch 489 in epoch 8, gen_loss = 1.3086574413338485, disc_loss = 0.0353179774836314
Trained batch 490 in epoch 8, gen_loss = 1.3091131460885166, disc_loss = 0.03542128670770986
Trained batch 491 in epoch 8, gen_loss = 1.3083401855414476, disc_loss = 0.035424636105242054
Trained batch 492 in epoch 8, gen_loss = 1.3075331697357595, disc_loss = 0.03544864226623795
Trained batch 493 in epoch 8, gen_loss = 1.3060060752789502, disc_loss = 0.035862406425419366
Trained batch 494 in epoch 8, gen_loss = 1.3062658241300873, disc_loss = 0.035817634713168095
Trained batch 495 in epoch 8, gen_loss = 1.3076841772323655, disc_loss = 0.03641369844216012
Trained batch 496 in epoch 8, gen_loss = 1.306684351423137, disc_loss = 0.03646654281877656
Trained batch 497 in epoch 8, gen_loss = 1.3054796325633804, disc_loss = 0.03659077576664557
Trained batch 498 in epoch 8, gen_loss = 1.3049919571809634, disc_loss = 0.03672077972628549
Trained batch 499 in epoch 8, gen_loss = 1.3042367391586305, disc_loss = 0.03685610568523407
Trained batch 500 in epoch 8, gen_loss = 1.3040967544395767, disc_loss = 0.03700119597528747
Trained batch 501 in epoch 8, gen_loss = 1.303461862987731, disc_loss = 0.03701416072825274
Trained batch 502 in epoch 8, gen_loss = 1.3024605567128236, disc_loss = 0.03716011224666362
Trained batch 503 in epoch 8, gen_loss = 1.301993128326204, disc_loss = 0.03713806063335921
Trained batch 504 in epoch 8, gen_loss = 1.3030731755908174, disc_loss = 0.03753246214646514
Trained batch 505 in epoch 8, gen_loss = 1.3022982819749434, disc_loss = 0.03754917542880821
Trained batch 506 in epoch 8, gen_loss = 1.3009290556465616, disc_loss = 0.03774606892416581
Trained batch 507 in epoch 8, gen_loss = 1.3011970719483894, disc_loss = 0.037817730022022336
Trained batch 508 in epoch 8, gen_loss = 1.3011431331016226, disc_loss = 0.037773276889634506
Trained batch 509 in epoch 8, gen_loss = 1.300558583876666, disc_loss = 0.037743685858360694
Trained batch 510 in epoch 8, gen_loss = 1.3006636387214736, disc_loss = 0.037687693481969625
Trained batch 511 in epoch 8, gen_loss = 1.3001300930045545, disc_loss = 0.037669911040211446
Trained batch 512 in epoch 8, gen_loss = 1.2996767659401103, disc_loss = 0.03766339949602679
Trained batch 513 in epoch 8, gen_loss = 1.299618671840267, disc_loss = 0.037918707325054396
Trained batch 514 in epoch 8, gen_loss = 1.2986034470854453, disc_loss = 0.03800378300575087
Trained batch 515 in epoch 8, gen_loss = 1.2985531411660733, disc_loss = 0.03796252412107853
Trained batch 516 in epoch 8, gen_loss = 1.298956015700298, disc_loss = 0.03790907432979092
Trained batch 517 in epoch 8, gen_loss = 1.2992193304203652, disc_loss = 0.03784789027408859
Trained batch 518 in epoch 8, gen_loss = 1.2999282853681458, disc_loss = 0.0378087245624132
Trained batch 519 in epoch 8, gen_loss = 1.2991703549256692, disc_loss = 0.037835407583042976
Trained batch 520 in epoch 8, gen_loss = 1.2991720680540675, disc_loss = 0.037825757787775624
Trained batch 521 in epoch 8, gen_loss = 1.2989524945445445, disc_loss = 0.03777586747945725
Trained batch 522 in epoch 8, gen_loss = 1.2981730954824853, disc_loss = 0.037837178163216176
Trained batch 523 in epoch 8, gen_loss = 1.297879959335764, disc_loss = 0.03781872874353337
Trained batch 524 in epoch 8, gen_loss = 1.2986436239878336, disc_loss = 0.03788357837214357
Trained batch 525 in epoch 8, gen_loss = 1.2979971959110448, disc_loss = 0.037880025573868034
Trained batch 526 in epoch 8, gen_loss = 1.298269514567033, disc_loss = 0.03792448840554683
Trained batch 527 in epoch 8, gen_loss = 1.297678564759818, disc_loss = 0.03790134633185737
Trained batch 528 in epoch 8, gen_loss = 1.297332795671344, disc_loss = 0.03788996615318585
Trained batch 529 in epoch 8, gen_loss = 1.298275347925582, disc_loss = 0.03786707414349295
Trained batch 530 in epoch 8, gen_loss = 1.2989660153505718, disc_loss = 0.037844081698669554
Trained batch 531 in epoch 8, gen_loss = 1.298820193548848, disc_loss = 0.03779908484793303
Trained batch 532 in epoch 8, gen_loss = 1.298449716469584, disc_loss = 0.03775173794708825
Trained batch 533 in epoch 8, gen_loss = 1.2980605450908789, disc_loss = 0.03772442856601227
Trained batch 534 in epoch 8, gen_loss = 1.2990887265339075, disc_loss = 0.03772406687733726
Trained batch 535 in epoch 8, gen_loss = 1.299126812103969, disc_loss = 0.0378281243194117
Trained batch 536 in epoch 8, gen_loss = 1.298344815465547, disc_loss = 0.03786813090702786
Trained batch 537 in epoch 8, gen_loss = 1.2974478383046544, disc_loss = 0.037935999969927574
Trained batch 538 in epoch 8, gen_loss = 1.2972385991703381, disc_loss = 0.03801591292452171
Trained batch 539 in epoch 8, gen_loss = 1.2980264827057166, disc_loss = 0.03807772312796226
Trained batch 540 in epoch 8, gen_loss = 1.2985373338798059, disc_loss = 0.03802365995082804
Trained batch 541 in epoch 8, gen_loss = 1.2984237519137534, disc_loss = 0.03796774139748096
Trained batch 542 in epoch 8, gen_loss = 1.2983033560477129, disc_loss = 0.037916889072020246
Trained batch 543 in epoch 8, gen_loss = 1.2983568426879013, disc_loss = 0.03785796311464818
Trained batch 544 in epoch 8, gen_loss = 1.29807909059962, disc_loss = 0.03782227221158666
Trained batch 545 in epoch 8, gen_loss = 1.2984343823932467, disc_loss = 0.03778633528863227
Trained batch 546 in epoch 8, gen_loss = 1.2987764934299197, disc_loss = 0.037739989693383845
Trained batch 547 in epoch 8, gen_loss = 1.2988633287214015, disc_loss = 0.037695524335437776
Trained batch 548 in epoch 8, gen_loss = 1.2990175194644755, disc_loss = 0.037634598448336505
Trained batch 549 in epoch 8, gen_loss = 1.2986233553019437, disc_loss = 0.03761017939668487
Trained batch 550 in epoch 8, gen_loss = 1.2977864537827548, disc_loss = 0.03767246053302272
Trained batch 551 in epoch 8, gen_loss = 1.2983599364541578, disc_loss = 0.03774169062524089
Trained batch 552 in epoch 8, gen_loss = 1.2988224541515812, disc_loss = 0.03770151321993464
Trained batch 553 in epoch 8, gen_loss = 1.2980979215151998, disc_loss = 0.03770171859577325
Trained batch 554 in epoch 8, gen_loss = 1.2974981750453916, disc_loss = 0.03774641003744962
Trained batch 555 in epoch 8, gen_loss = 1.2976695116904142, disc_loss = 0.03770063824117478
Trained batch 556 in epoch 8, gen_loss = 1.2972457877609418, disc_loss = 0.037689933549157964
Trained batch 557 in epoch 8, gen_loss = 1.2978432657043566, disc_loss = 0.03765980165541893
Trained batch 558 in epoch 8, gen_loss = 1.2971892331282013, disc_loss = 0.03767071772210153
Trained batch 559 in epoch 8, gen_loss = 1.2975490318877356, disc_loss = 0.03762000492591012
Trained batch 560 in epoch 8, gen_loss = 1.297782317202359, disc_loss = 0.037563762868258195
Trained batch 561 in epoch 8, gen_loss = 1.297847517656686, disc_loss = 0.03750954762853523
Trained batch 562 in epoch 8, gen_loss = 1.2979458000901325, disc_loss = 0.03746101895982456
Trained batch 563 in epoch 8, gen_loss = 1.2981330663599866, disc_loss = 0.03741012121045447
Trained batch 564 in epoch 8, gen_loss = 1.298460604659224, disc_loss = 0.0373690218813058
Trained batch 565 in epoch 8, gen_loss = 1.2989049151592458, disc_loss = 0.037317330268616444
Trained batch 566 in epoch 8, gen_loss = 1.2991510757903784, disc_loss = 0.03731920384938255
Trained batch 567 in epoch 8, gen_loss = 1.2990279965837237, disc_loss = 0.037316360931456564
Trained batch 568 in epoch 8, gen_loss = 1.298675774270914, disc_loss = 0.03729188399756023
Trained batch 569 in epoch 8, gen_loss = 1.2979573160932776, disc_loss = 0.03732783266408533
Trained batch 570 in epoch 8, gen_loss = 1.298201402411152, disc_loss = 0.037283863868212065
Trained batch 571 in epoch 8, gen_loss = 1.29915814393467, disc_loss = 0.03726938431935997
Trained batch 572 in epoch 8, gen_loss = 1.2994546254683956, disc_loss = 0.037223525185229006
Trained batch 573 in epoch 8, gen_loss = 1.2995756932044278, disc_loss = 0.037168370263702934
Trained batch 574 in epoch 8, gen_loss = 1.2995910836302715, disc_loss = 0.03711614640915523
Trained batch 575 in epoch 8, gen_loss = 1.2996254684403539, disc_loss = 0.03706510679492365
Trained batch 576 in epoch 8, gen_loss = 1.2997680095700705, disc_loss = 0.037008486612275425
Trained batch 577 in epoch 8, gen_loss = 1.2997972442410808, disc_loss = 0.03695344527583943
Trained batch 578 in epoch 8, gen_loss = 1.3000347547374653, disc_loss = 0.03698031359476026
Trained batch 579 in epoch 8, gen_loss = 1.2997580839642162, disc_loss = 0.036963271924519335
Trained batch 580 in epoch 8, gen_loss = 1.298906922032624, disc_loss = 0.03704600635973701
Trained batch 581 in epoch 8, gen_loss = 1.29964880097363, disc_loss = 0.03734786472766567
Trained batch 582 in epoch 8, gen_loss = 1.2993312165217783, disc_loss = 0.037326526769003984
Trained batch 583 in epoch 8, gen_loss = 1.2988758512759861, disc_loss = 0.037515217932706624
Trained batch 584 in epoch 8, gen_loss = 1.297896035002847, disc_loss = 0.037609179391183405
Trained batch 585 in epoch 8, gen_loss = 1.2978802977365032, disc_loss = 0.03756048230123754
Trained batch 586 in epoch 8, gen_loss = 1.2977586059594683, disc_loss = 0.03751042969620055
Trained batch 587 in epoch 8, gen_loss = 1.2980609535157275, disc_loss = 0.03747381040110525
Trained batch 588 in epoch 8, gen_loss = 1.2990230278369728, disc_loss = 0.03747787964901869
Trained batch 589 in epoch 8, gen_loss = 1.2991973316265364, disc_loss = 0.03743784075160905
Trained batch 590 in epoch 8, gen_loss = 1.2989958166672695, disc_loss = 0.037394715561302985
Trained batch 591 in epoch 8, gen_loss = 1.299029461334686, disc_loss = 0.037344569884668534
Trained batch 592 in epoch 8, gen_loss = 1.298943482904772, disc_loss = 0.03729931793126951
Trained batch 593 in epoch 8, gen_loss = 1.2996981472077995, disc_loss = 0.0372686743428962
Trained batch 594 in epoch 8, gen_loss = 1.2998213434419712, disc_loss = 0.03721358652985772
Trained batch 595 in epoch 8, gen_loss = 1.3001014303241, disc_loss = 0.037157443723166296
Trained batch 596 in epoch 8, gen_loss = 1.2999361756458954, disc_loss = 0.037114424321338706
Trained batch 597 in epoch 8, gen_loss = 1.2999688989940694, disc_loss = 0.03705891039157068
Trained batch 598 in epoch 8, gen_loss = 1.3000791953481696, disc_loss = 0.037735446708398145
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.9029757976531982, disc_loss = 0.06806039065122604
Trained batch 1 in epoch 9, gen_loss = 0.9401025176048279, disc_loss = 0.057310041040182114
Trained batch 2 in epoch 9, gen_loss = 1.0962715943654378, disc_loss = 0.04809292467931906
Trained batch 3 in epoch 9, gen_loss = 1.2320870459079742, disc_loss = 0.04537819558754563
Trained batch 4 in epoch 9, gen_loss = 1.2402479887008666, disc_loss = 0.038943085446953775
Trained batch 5 in epoch 9, gen_loss = 1.2169658144315083, disc_loss = 0.03923507872968912
Trained batch 6 in epoch 9, gen_loss = 1.187531590461731, disc_loss = 0.03726091954324927
Trained batch 7 in epoch 9, gen_loss = 1.1883538961410522, disc_loss = 0.03386516042519361
Trained batch 8 in epoch 9, gen_loss = 1.2292396889792547, disc_loss = 0.033064447860750884
Trained batch 9 in epoch 9, gen_loss = 1.230881917476654, disc_loss = 0.03097388008609414
Trained batch 10 in epoch 9, gen_loss = 1.2662705833261663, disc_loss = 0.029514745047146625
Trained batch 11 in epoch 9, gen_loss = 1.2599639197190602, disc_loss = 0.028109008679166436
Trained batch 12 in epoch 9, gen_loss = 1.2849814066520104, disc_loss = 0.027273345953569963
Trained batch 13 in epoch 9, gen_loss = 1.2854648232460022, disc_loss = 0.027238207403570414
Trained batch 14 in epoch 9, gen_loss = 1.2664448658625285, disc_loss = 0.02690297259638707
Trained batch 15 in epoch 9, gen_loss = 1.243079200387001, disc_loss = 0.029101508611347526
Trained batch 16 in epoch 9, gen_loss = 1.2655321009018843, disc_loss = 0.02789964203667991
Trained batch 17 in epoch 9, gen_loss = 1.2831627660327487, disc_loss = 0.02687690407037735
Trained batch 18 in epoch 9, gen_loss = 1.2837744888506437, disc_loss = 0.027235434243553562
Trained batch 19 in epoch 9, gen_loss = 1.2926644921302795, disc_loss = 0.02619798658415675
Trained batch 20 in epoch 9, gen_loss = 1.291702429453532, disc_loss = 0.025318401333476816
Trained batch 21 in epoch 9, gen_loss = 1.286192774772644, disc_loss = 0.024774432393976233
Trained batch 22 in epoch 9, gen_loss = 1.28342996991199, disc_loss = 0.024157627161754215
Trained batch 23 in epoch 9, gen_loss = 1.2709032048781712, disc_loss = 0.024558663562250633
Trained batch 24 in epoch 9, gen_loss = 1.3047679471969604, disc_loss = 0.02780614722520113
Trained batch 25 in epoch 9, gen_loss = 1.2976043407733624, disc_loss = 0.02810955223125907
Trained batch 26 in epoch 9, gen_loss = 1.3023039014251143, disc_loss = 0.027423204095275315
Trained batch 27 in epoch 9, gen_loss = 1.2841616081339973, disc_loss = 0.029751770198345184
Trained batch 28 in epoch 9, gen_loss = 1.2901787038507133, disc_loss = 0.03444164631695583
Trained batch 29 in epoch 9, gen_loss = 1.2912456929683684, disc_loss = 0.033776331382493176
Trained batch 30 in epoch 9, gen_loss = 1.2758437318186606, disc_loss = 0.0343596207638902
Trained batch 31 in epoch 9, gen_loss = 1.263826945796609, disc_loss = 0.03477666823891923
Trained batch 32 in epoch 9, gen_loss = 1.2666399388602285, disc_loss = 0.03488498006128904
Trained batch 33 in epoch 9, gen_loss = 1.2690015733242035, disc_loss = 0.0341807440854609
Trained batch 34 in epoch 9, gen_loss = 1.2593560576438905, disc_loss = 0.03559242372534105
Trained batch 35 in epoch 9, gen_loss = 1.2635266664955351, disc_loss = 0.03495658305473626
Trained batch 36 in epoch 9, gen_loss = 1.279110368844625, disc_loss = 0.03559282454787879
Trained batch 37 in epoch 9, gen_loss = 1.2664317520041215, disc_loss = 0.03692494599932903
Trained batch 38 in epoch 9, gen_loss = 1.2758307029039433, disc_loss = 0.036366891784545705
Trained batch 39 in epoch 9, gen_loss = 1.2701419174671174, disc_loss = 0.036098718037828804
Trained batch 40 in epoch 9, gen_loss = 1.276113254267995, disc_loss = 0.035542425608671296
Trained batch 41 in epoch 9, gen_loss = 1.2766105362347193, disc_loss = 0.03645875271675842
Trained batch 42 in epoch 9, gen_loss = 1.2687502406364264, disc_loss = 0.036919562644216905
Trained batch 43 in epoch 9, gen_loss = 1.263592611659657, disc_loss = 0.03670557416890832
Trained batch 44 in epoch 9, gen_loss = 1.268182216750251, disc_loss = 0.036239307353066075
Trained batch 45 in epoch 9, gen_loss = 1.2685082865797954, disc_loss = 0.03776848225084984
Trained batch 46 in epoch 9, gen_loss = 1.2598120468728087, disc_loss = 0.03800065131818361
Trained batch 47 in epoch 9, gen_loss = 1.2577540439864, disc_loss = 0.03755580018817758
Trained batch 48 in epoch 9, gen_loss = 1.2639189800437616, disc_loss = 0.03694525292637397
Trained batch 49 in epoch 9, gen_loss = 1.2736239898204804, disc_loss = 0.03656129248440266
Trained batch 50 in epoch 9, gen_loss = 1.2675573790774626, disc_loss = 0.03670826992567848
Trained batch 51 in epoch 9, gen_loss = 1.2654126527217717, disc_loss = 0.03732059093622061
Trained batch 52 in epoch 9, gen_loss = 1.264996147380685, disc_loss = 0.03681640773308727
Trained batch 53 in epoch 9, gen_loss = 1.2628102092831224, disc_loss = 0.03659902889005564
Trained batch 54 in epoch 9, gen_loss = 1.2643608342517505, disc_loss = 0.03602809674021873
Trained batch 55 in epoch 9, gen_loss = 1.263866368149008, disc_loss = 0.035628748907973726
Trained batch 56 in epoch 9, gen_loss = 1.27036515348836, disc_loss = 0.035407674008686295
Trained batch 57 in epoch 9, gen_loss = 1.2669544476887276, disc_loss = 0.03540687473362376
Trained batch 58 in epoch 9, gen_loss = 1.2753528225219857, disc_loss = 0.035351930833342725
Trained batch 59 in epoch 9, gen_loss = 1.2706684470176697, disc_loss = 0.035298599287246664
Trained batch 60 in epoch 9, gen_loss = 1.2738155888729408, disc_loss = 0.034987881886543795
Trained batch 61 in epoch 9, gen_loss = 1.2732647715076324, disc_loss = 0.034584390224828836
Trained batch 62 in epoch 9, gen_loss = 1.2738385408643693, disc_loss = 0.034344406872396434
Trained batch 63 in epoch 9, gen_loss = 1.2754412479698658, disc_loss = 0.03388496864499757
Trained batch 64 in epoch 9, gen_loss = 1.2758089835827167, disc_loss = 0.033466979023069145
Trained batch 65 in epoch 9, gen_loss = 1.2763461922154282, disc_loss = 0.03348741812321047
Trained batch 66 in epoch 9, gen_loss = 1.2804692538816538, disc_loss = 0.03321575957920347
Trained batch 67 in epoch 9, gen_loss = 1.2755548235248118, disc_loss = 0.03340755551642574
Trained batch 68 in epoch 9, gen_loss = 1.2792990414992622, disc_loss = 0.03300605308048535
Trained batch 69 in epoch 9, gen_loss = 1.2761822496141706, disc_loss = 0.03832324789837003
Trained batch 70 in epoch 9, gen_loss = 1.2703808227055509, disc_loss = 0.038572903499531914
Trained batch 71 in epoch 9, gen_loss = 1.2628960286577542, disc_loss = 0.03968022477864805
Trained batch 72 in epoch 9, gen_loss = 1.2644874502534735, disc_loss = 0.039242370168946376
Trained batch 73 in epoch 9, gen_loss = 1.2650609072801229, disc_loss = 0.03948469176838124
Trained batch 74 in epoch 9, gen_loss = 1.2578335769971212, disc_loss = 0.04009611625224352
Trained batch 75 in epoch 9, gen_loss = 1.2558418708412271, disc_loss = 0.04012081447351528
Trained batch 76 in epoch 9, gen_loss = 1.2559301055871046, disc_loss = 0.03990983966641225
Trained batch 77 in epoch 9, gen_loss = 1.2512951844777815, disc_loss = 0.039919294930325866
Trained batch 78 in epoch 9, gen_loss = 1.2556854893889609, disc_loss = 0.0396208546089032
Trained batch 79 in epoch 9, gen_loss = 1.2535612836480141, disc_loss = 0.03929488258436322
Trained batch 80 in epoch 9, gen_loss = 1.2557339432798786, disc_loss = 0.03897058089942108
Trained batch 81 in epoch 9, gen_loss = 1.2569868157549602, disc_loss = 0.03864949892797485
Trained batch 82 in epoch 9, gen_loss = 1.2577250018177262, disc_loss = 0.03825191923989409
Trained batch 83 in epoch 9, gen_loss = 1.2591673249290103, disc_loss = 0.03792792374068605
Trained batch 84 in epoch 9, gen_loss = 1.2611256571377025, disc_loss = 0.03752756031668362
Trained batch 85 in epoch 9, gen_loss = 1.2628185665884684, disc_loss = 0.0371278146725841
Trained batch 86 in epoch 9, gen_loss = 1.2658412620939057, disc_loss = 0.03677753859531434
Trained batch 87 in epoch 9, gen_loss = 1.2680125412615864, disc_loss = 0.036412828654812816
Trained batch 88 in epoch 9, gen_loss = 1.2692441565267156, disc_loss = 0.03618245857527082
Trained batch 89 in epoch 9, gen_loss = 1.2690568129221598, disc_loss = 0.035973659126708905
Trained batch 90 in epoch 9, gen_loss = 1.270421883562109, disc_loss = 0.03959381773781318
Trained batch 91 in epoch 9, gen_loss = 1.2627433305201323, disc_loss = 0.041653186700347324
Trained batch 92 in epoch 9, gen_loss = 1.2646445612753592, disc_loss = 0.041815782396463295
Trained batch 93 in epoch 9, gen_loss = 1.2644580729464268, disc_loss = 0.041594182170848266
Trained batch 94 in epoch 9, gen_loss = 1.265798440732454, disc_loss = 0.041260606001474354
Trained batch 95 in epoch 9, gen_loss = 1.264052181194226, disc_loss = 0.04108959119184874
Trained batch 96 in epoch 9, gen_loss = 1.2652069649745508, disc_loss = 0.04084831553981783
Trained batch 97 in epoch 9, gen_loss = 1.2651673579702571, disc_loss = 0.04051508717428969
Trained batch 98 in epoch 9, gen_loss = 1.2678766407147803, disc_loss = 0.040195026021036834
Trained batch 99 in epoch 9, gen_loss = 1.2674920415878297, disc_loss = 0.03996701913885772
Trained batch 100 in epoch 9, gen_loss = 1.267385201879067, disc_loss = 0.039659206451165795
Trained batch 101 in epoch 9, gen_loss = 1.2681032875004936, disc_loss = 0.039300192581197504
Trained batch 102 in epoch 9, gen_loss = 1.2704042381453282, disc_loss = 0.038962225013783255
Trained batch 103 in epoch 9, gen_loss = 1.2717094169213221, disc_loss = 0.03862534593253468
Trained batch 104 in epoch 9, gen_loss = 1.271589107740493, disc_loss = 0.038485576221275894
Trained batch 105 in epoch 9, gen_loss = 1.2699916149085422, disc_loss = 0.038320436098454695
Trained batch 106 in epoch 9, gen_loss = 1.271969537868678, disc_loss = 0.038160882655217825
Trained batch 107 in epoch 9, gen_loss = 1.2710892293188307, disc_loss = 0.037928969875254015
Trained batch 108 in epoch 9, gen_loss = 1.273086560975521, disc_loss = 0.03763465490192175
Trained batch 109 in epoch 9, gen_loss = 1.2746017748659306, disc_loss = 0.03739462636241859
Trained batch 110 in epoch 9, gen_loss = 1.2765696961600501, disc_loss = 0.03714351049783799
Trained batch 111 in epoch 9, gen_loss = 1.2774516652737344, disc_loss = 0.036867622776688744
Trained batch 112 in epoch 9, gen_loss = 1.277029139805684, disc_loss = 0.03661444541726228
Trained batch 113 in epoch 9, gen_loss = 1.277032483042332, disc_loss = 0.03635302853460113
Trained batch 114 in epoch 9, gen_loss = 1.277041568963424, disc_loss = 0.036109165903990686
Trained batch 115 in epoch 9, gen_loss = 1.2794633086385399, disc_loss = 0.03595612754499347
Trained batch 116 in epoch 9, gen_loss = 1.2800961366066566, disc_loss = 0.03570592902505245
Trained batch 117 in epoch 9, gen_loss = 1.2830633379645267, disc_loss = 0.03549312830949992
Trained batch 118 in epoch 9, gen_loss = 1.283185907772609, disc_loss = 0.035247397299918555
Trained batch 119 in epoch 9, gen_loss = 1.2807096814115841, disc_loss = 0.035191255602209516
Trained batch 120 in epoch 9, gen_loss = 1.284419376495456, disc_loss = 0.035029136525728734
Trained batch 121 in epoch 9, gen_loss = 1.2871166853631129, disc_loss = 0.03502488541264148
Trained batch 122 in epoch 9, gen_loss = 1.2887965145149851, disc_loss = 0.03479143297602612
Trained batch 123 in epoch 9, gen_loss = 1.2861333523065812, disc_loss = 0.03484764667002544
Trained batch 124 in epoch 9, gen_loss = 1.2877561221122742, disc_loss = 0.03460334708914161
Trained batch 125 in epoch 9, gen_loss = 1.283947118217983, disc_loss = 0.03485426604969516
Trained batch 126 in epoch 9, gen_loss = 1.288677623422127, disc_loss = 0.03604437178734133
Trained batch 127 in epoch 9, gen_loss = 1.2852782914415002, disc_loss = 0.03635391234638519
Trained batch 128 in epoch 9, gen_loss = 1.2829710480778715, disc_loss = 0.03635413459206159
Trained batch 129 in epoch 9, gen_loss = 1.2836972745565267, disc_loss = 0.03611088760841925
Trained batch 130 in epoch 9, gen_loss = 1.2882445600196606, disc_loss = 0.03685969761608325
Trained batch 131 in epoch 9, gen_loss = 1.2878226235960468, disc_loss = 0.03677569255303366
Trained batch 132 in epoch 9, gen_loss = 1.2865669758696305, disc_loss = 0.0366676470537887
Trained batch 133 in epoch 9, gen_loss = 1.2863010910909567, disc_loss = 0.03649851110930652
Trained batch 134 in epoch 9, gen_loss = 1.288074047035641, disc_loss = 0.036431226075661405
Trained batch 135 in epoch 9, gen_loss = 1.285381946931867, disc_loss = 0.03647609419011347
Trained batch 136 in epoch 9, gen_loss = 1.282790722638151, disc_loss = 0.03664319518695239
Trained batch 137 in epoch 9, gen_loss = 1.284568845361903, disc_loss = 0.03665462586745296
Trained batch 138 in epoch 9, gen_loss = 1.2905870924750678, disc_loss = 0.0369312184554585
Trained batch 139 in epoch 9, gen_loss = 1.2901762672833035, disc_loss = 0.03675390310652022
Trained batch 140 in epoch 9, gen_loss = 1.2890172435882243, disc_loss = 0.03664111915698394
Trained batch 141 in epoch 9, gen_loss = 1.2874458532937816, disc_loss = 0.03664592203920261
Trained batch 142 in epoch 9, gen_loss = 1.2879715966177987, disc_loss = 0.036605571263137605
Trained batch 143 in epoch 9, gen_loss = 1.2903087321254942, disc_loss = 0.0365343734576729
Trained batch 144 in epoch 9, gen_loss = 1.2909677595927798, disc_loss = 0.036323793698102236
Trained batch 145 in epoch 9, gen_loss = 1.2912206641615254, disc_loss = 0.03614567610919986
Trained batch 146 in epoch 9, gen_loss = 1.2906036052574106, disc_loss = 0.03597843426210033
Trained batch 147 in epoch 9, gen_loss = 1.2905159495972298, disc_loss = 0.03579502387563824
Trained batch 148 in epoch 9, gen_loss = 1.292011464202164, disc_loss = 0.03559327766536766
Trained batch 149 in epoch 9, gen_loss = 1.2950529964764912, disc_loss = 0.03615166302459935
Trained batch 150 in epoch 9, gen_loss = 1.2970966953315481, disc_loss = 0.03600716839748009
Trained batch 151 in epoch 9, gen_loss = 1.2954702471431934, disc_loss = 0.03593854542123154
Trained batch 152 in epoch 9, gen_loss = 1.292756920546488, disc_loss = 0.03604865083592682
Trained batch 153 in epoch 9, gen_loss = 1.2896441794061042, disc_loss = 0.036353663381116536
Trained batch 154 in epoch 9, gen_loss = 1.2904687758414977, disc_loss = 0.03668618913319322
Trained batch 155 in epoch 9, gen_loss = 1.2916772090471709, disc_loss = 0.03649527407908
Trained batch 156 in epoch 9, gen_loss = 1.29263532845078, disc_loss = 0.03633577790953646
Trained batch 157 in epoch 9, gen_loss = 1.2885328516175476, disc_loss = 0.03716261167656866
Trained batch 158 in epoch 9, gen_loss = 1.2920647709624573, disc_loss = 0.03776942869742055
Trained batch 159 in epoch 9, gen_loss = 1.2939414344727993, disc_loss = 0.037612346254172736
Trained batch 160 in epoch 9, gen_loss = 1.2928900222600617, disc_loss = 0.0375716814406864
Trained batch 161 in epoch 9, gen_loss = 1.290908262685493, disc_loss = 0.03756168233748111
Trained batch 162 in epoch 9, gen_loss = 1.2891787484379633, disc_loss = 0.03760123846801055
Trained batch 163 in epoch 9, gen_loss = 1.2862518004527905, disc_loss = 0.03814610411560663
Trained batch 164 in epoch 9, gen_loss = 1.2866172815814163, disc_loss = 0.038081196918519154
Trained batch 165 in epoch 9, gen_loss = 1.2902089310697762, disc_loss = 0.03827859826823584
Trained batch 166 in epoch 9, gen_loss = 1.2905294277710828, disc_loss = 0.03816553567463677
Trained batch 167 in epoch 9, gen_loss = 1.2895859710517383, disc_loss = 0.03810217664743375
Trained batch 168 in epoch 9, gen_loss = 1.2900214882997365, disc_loss = 0.037942294474999756
Trained batch 169 in epoch 9, gen_loss = 1.2868550149833455, disc_loss = 0.038288248223526514
Trained batch 170 in epoch 9, gen_loss = 1.2865326226803295, disc_loss = 0.03827715501984396
Trained batch 171 in epoch 9, gen_loss = 1.2887347052956737, disc_loss = 0.03835478102582572
Trained batch 172 in epoch 9, gen_loss = 1.2868780252561405, disc_loss = 0.03836584982941347
Trained batch 173 in epoch 9, gen_loss = 1.2888264974643444, disc_loss = 0.03825241732196989
Trained batch 174 in epoch 9, gen_loss = 1.288945701122284, disc_loss = 0.03811621498050434
Trained batch 175 in epoch 9, gen_loss = 1.2852230546149341, disc_loss = 0.038580248240825975
Trained batch 176 in epoch 9, gen_loss = 1.2858308951059978, disc_loss = 0.03844205944372688
Trained batch 177 in epoch 9, gen_loss = 1.289307390705923, disc_loss = 0.03900010785182122
Trained batch 178 in epoch 9, gen_loss = 1.2872271444544445, disc_loss = 0.0390064323180506
Trained batch 179 in epoch 9, gen_loss = 1.2851267827881707, disc_loss = 0.03985175512886296
Trained batch 180 in epoch 9, gen_loss = 1.2836364962119424, disc_loss = 0.03989669997296528
Trained batch 181 in epoch 9, gen_loss = 1.2806193317685808, disc_loss = 0.040224863561689035
Trained batch 182 in epoch 9, gen_loss = 1.2835960153673516, disc_loss = 0.040408838761695584
Trained batch 183 in epoch 9, gen_loss = 1.2834021254726078, disc_loss = 0.0403282235897875
Trained batch 184 in epoch 9, gen_loss = 1.282988579853161, disc_loss = 0.04020546544594942
Trained batch 185 in epoch 9, gen_loss = 1.2819373421771552, disc_loss = 0.04016575079801823
Trained batch 186 in epoch 9, gen_loss = 1.2805990618180463, disc_loss = 0.04019959126275411
Trained batch 187 in epoch 9, gen_loss = 1.2808335531265178, disc_loss = 0.04003811523348014
Trained batch 188 in epoch 9, gen_loss = 1.2829712667162456, disc_loss = 0.04007986109831898
Trained batch 189 in epoch 9, gen_loss = 1.2835344094979135, disc_loss = 0.04010636668015075
Trained batch 190 in epoch 9, gen_loss = 1.2825071749262784, disc_loss = 0.040034115126756316
Trained batch 191 in epoch 9, gen_loss = 1.2802930269390345, disc_loss = 0.04021889511447322
Trained batch 192 in epoch 9, gen_loss = 1.2792332487402802, disc_loss = 0.040089733625998616
Trained batch 193 in epoch 9, gen_loss = 1.281392787535166, disc_loss = 0.03998515960165136
Trained batch 194 in epoch 9, gen_loss = 1.284787920805124, disc_loss = 0.03998551351280931
Trained batch 195 in epoch 9, gen_loss = 1.284034406652256, disc_loss = 0.03992455509462755
Trained batch 196 in epoch 9, gen_loss = 1.285050349792248, disc_loss = 0.0397550646348048
Trained batch 197 in epoch 9, gen_loss = 1.2858615914980571, disc_loss = 0.039576078595762905
Trained batch 198 in epoch 9, gen_loss = 1.2858997565418033, disc_loss = 0.039512362546432554
Trained batch 199 in epoch 9, gen_loss = 1.2872596526145934, disc_loss = 0.03944752580486238
Trained batch 200 in epoch 9, gen_loss = 1.2862879998648344, disc_loss = 0.039347317227306056
Trained batch 201 in epoch 9, gen_loss = 1.2851331204471022, disc_loss = 0.03926612668218884
Trained batch 202 in epoch 9, gen_loss = 1.2855797213286602, disc_loss = 0.03910376199433956
Trained batch 203 in epoch 9, gen_loss = 1.2835566541727852, disc_loss = 0.039178941161463074
Trained batch 204 in epoch 9, gen_loss = 1.284916368344935, disc_loss = 0.03904054473812987
Trained batch 205 in epoch 9, gen_loss = 1.2855446662717653, disc_loss = 0.038890249339990246
Trained batch 206 in epoch 9, gen_loss = 1.285526167943282, disc_loss = 0.03873458309863932
Trained batch 207 in epoch 9, gen_loss = 1.2854601196371591, disc_loss = 0.03914735612656491
Trained batch 208 in epoch 9, gen_loss = 1.2841595069073033, disc_loss = 0.03911567714207908
Trained batch 209 in epoch 9, gen_loss = 1.2833831883612132, disc_loss = 0.039018151434581906
Trained batch 210 in epoch 9, gen_loss = 1.2848321583598712, disc_loss = 0.038987125676142945
Trained batch 211 in epoch 9, gen_loss = 1.285355346382789, disc_loss = 0.03884561618192578
Trained batch 212 in epoch 9, gen_loss = 1.2851453560618726, disc_loss = 0.03869960789389454
Trained batch 213 in epoch 9, gen_loss = 1.2853043608576338, disc_loss = 0.03853706377297292
Trained batch 214 in epoch 9, gen_loss = 1.285834559174471, disc_loss = 0.038377617401352454
Trained batch 215 in epoch 9, gen_loss = 1.286626974189723, disc_loss = 0.03842679667933327
Trained batch 216 in epoch 9, gen_loss = 1.2844901727641234, disc_loss = 0.038638306873923486
Trained batch 217 in epoch 9, gen_loss = 1.2839296044559654, disc_loss = 0.03851039958220625
Trained batch 218 in epoch 9, gen_loss = 1.286431663656888, disc_loss = 0.03843193271805503
Trained batch 219 in epoch 9, gen_loss = 1.2864252724430778, disc_loss = 0.03828870999330485
Trained batch 220 in epoch 9, gen_loss = 1.2875443427271434, disc_loss = 0.03815077121550748
Trained batch 221 in epoch 9, gen_loss = 1.2875760315774798, disc_loss = 0.038022823575128976
Trained batch 222 in epoch 9, gen_loss = 1.2877066215592115, disc_loss = 0.037911646625636806
Trained batch 223 in epoch 9, gen_loss = 1.2889112026563712, disc_loss = 0.037778785100921856
Trained batch 224 in epoch 9, gen_loss = 1.2905585781733195, disc_loss = 0.03766033880619539
Trained batch 225 in epoch 9, gen_loss = 1.290164847817041, disc_loss = 0.03754893557860854
Trained batch 226 in epoch 9, gen_loss = 1.2907213975679508, disc_loss = 0.03741142433752113
Trained batch 227 in epoch 9, gen_loss = 1.2911170511914973, disc_loss = 0.037272640749027856
Trained batch 228 in epoch 9, gen_loss = 1.2929013051320373, disc_loss = 0.03717800769060199
Trained batch 229 in epoch 9, gen_loss = 1.2930966569029767, disc_loss = 0.037035497636331814
Trained batch 230 in epoch 9, gen_loss = 1.2929137511686846, disc_loss = 0.03691454625837666
Trained batch 231 in epoch 9, gen_loss = 1.2930299788713455, disc_loss = 0.036794839344581526
Trained batch 232 in epoch 9, gen_loss = 1.2948039452917075, disc_loss = 0.0367038905192886
Trained batch 233 in epoch 9, gen_loss = 1.2948272452395186, disc_loss = 0.03663230248185623
Trained batch 234 in epoch 9, gen_loss = 1.293864827460431, disc_loss = 0.03663620325994301
Trained batch 235 in epoch 9, gen_loss = 1.2930124260611453, disc_loss = 0.03655460520481722
Trained batch 236 in epoch 9, gen_loss = 1.2944113373253416, disc_loss = 0.03645564850128967
Trained batch 237 in epoch 9, gen_loss = 1.293906840456634, disc_loss = 0.03635608013758451
Trained batch 238 in epoch 9, gen_loss = 1.2935232632329774, disc_loss = 0.03643952611109016
Trained batch 239 in epoch 9, gen_loss = 1.2917573029796283, disc_loss = 0.03653682565200143
Trained batch 240 in epoch 9, gen_loss = 1.2935131174894785, disc_loss = 0.036480904276641204
Trained batch 241 in epoch 9, gen_loss = 1.2928902994502673, disc_loss = 0.03637938743480289
Trained batch 242 in epoch 9, gen_loss = 1.2942821395740587, disc_loss = 0.03641667442564918
Trained batch 243 in epoch 9, gen_loss = 1.2944605941655205, disc_loss = 0.036453910799864986
Trained batch 244 in epoch 9, gen_loss = 1.2918807506561278, disc_loss = 0.03679929039802174
Trained batch 245 in epoch 9, gen_loss = 1.29160543476663, disc_loss = 0.036709388818334396
Trained batch 246 in epoch 9, gen_loss = 1.291516552569895, disc_loss = 0.0366104307531677
Trained batch 247 in epoch 9, gen_loss = 1.2908336765343142, disc_loss = 0.036520849930257684
Trained batch 248 in epoch 9, gen_loss = 1.291727806190889, disc_loss = 0.03648750357756234
Trained batch 249 in epoch 9, gen_loss = 1.2932553386688233, disc_loss = 0.03642071157135069
Trained batch 250 in epoch 9, gen_loss = 1.2938195671218324, disc_loss = 0.03633461394106071
Trained batch 251 in epoch 9, gen_loss = 1.2925152177848513, disc_loss = 0.036327132809212404
Trained batch 252 in epoch 9, gen_loss = 1.2898340451387549, disc_loss = 0.03675703728100351
Trained batch 253 in epoch 9, gen_loss = 1.2917894275169672, disc_loss = 0.03714653433256555
Trained batch 254 in epoch 9, gen_loss = 1.2931893199097877, disc_loss = 0.0373728807376442
Trained batch 255 in epoch 9, gen_loss = 1.290307420073077, disc_loss = 0.03812336558075913
Trained batch 256 in epoch 9, gen_loss = 1.2882064406973843, disc_loss = 0.038292781592995394
Trained batch 257 in epoch 9, gen_loss = 1.2881027587162432, disc_loss = 0.03879453932195036
Trained batch 258 in epoch 9, gen_loss = 1.2869702506249476, disc_loss = 0.03879611481980755
Trained batch 259 in epoch 9, gen_loss = 1.2860223098443104, disc_loss = 0.03884606944719473
Trained batch 260 in epoch 9, gen_loss = 1.2839300004458518, disc_loss = 0.03911314406735516
Trained batch 261 in epoch 9, gen_loss = 1.284528925901151, disc_loss = 0.03901917874308317
Trained batch 262 in epoch 9, gen_loss = 1.2836447720745217, disc_loss = 0.039142019000301
Trained batch 263 in epoch 9, gen_loss = 1.2855309507612027, disc_loss = 0.03921624357903828
Trained batch 264 in epoch 9, gen_loss = 1.285497946334335, disc_loss = 0.03917308333241996
Trained batch 265 in epoch 9, gen_loss = 1.2855728723500903, disc_loss = 0.03912071154901016
Trained batch 266 in epoch 9, gen_loss = 1.2847716140836365, disc_loss = 0.039081980821359136
Trained batch 267 in epoch 9, gen_loss = 1.2842605623291499, disc_loss = 0.03900051867040291
Trained batch 268 in epoch 9, gen_loss = 1.2845120569587196, disc_loss = 0.03898560734410324
Trained batch 269 in epoch 9, gen_loss = 1.2836014418690294, disc_loss = 0.03898803628463712
Trained batch 270 in epoch 9, gen_loss = 1.2835750533645884, disc_loss = 0.0388974481214154
Trained batch 271 in epoch 9, gen_loss = 1.2819976394667345, disc_loss = 0.03898403150721125
Trained batch 272 in epoch 9, gen_loss = 1.2844029774159302, disc_loss = 0.0392175929317244
Trained batch 273 in epoch 9, gen_loss = 1.2866406814895408, disc_loss = 0.039287460228618586
Trained batch 274 in epoch 9, gen_loss = 1.286576359055259, disc_loss = 0.039278572711416264
Trained batch 275 in epoch 9, gen_loss = 1.2847177481305772, disc_loss = 0.03943180529893362
Trained batch 276 in epoch 9, gen_loss = 1.2839172643874956, disc_loss = 0.039436659464673125
Trained batch 277 in epoch 9, gen_loss = 1.2855369054156243, disc_loss = 0.039653225039741655
Trained batch 278 in epoch 9, gen_loss = 1.2856919154471393, disc_loss = 0.0395716542334673
Trained batch 279 in epoch 9, gen_loss = 1.2844955840281078, disc_loss = 0.03959216590737924
Trained batch 280 in epoch 9, gen_loss = 1.2822835152683734, disc_loss = 0.040009582788083586
Trained batch 281 in epoch 9, gen_loss = 1.281966025524951, disc_loss = 0.04059083314103913
Trained batch 282 in epoch 9, gen_loss = 1.2814233618995747, disc_loss = 0.04054112250788315
Trained batch 283 in epoch 9, gen_loss = 1.2808392371090365, disc_loss = 0.040534858160625985
Trained batch 284 in epoch 9, gen_loss = 1.278921505861115, disc_loss = 0.04061257081237017
Trained batch 285 in epoch 9, gen_loss = 1.2797680042840385, disc_loss = 0.04063029238348501
Trained batch 286 in epoch 9, gen_loss = 1.2821620146156603, disc_loss = 0.04062803875077321
Trained batch 287 in epoch 9, gen_loss = 1.2819454251892037, disc_loss = 0.040602492002007134
Trained batch 288 in epoch 9, gen_loss = 1.2821113444529604, disc_loss = 0.04048873668949033
Trained batch 289 in epoch 9, gen_loss = 1.281631507544682, disc_loss = 0.04043020702866388
Trained batch 290 in epoch 9, gen_loss = 1.2823057879287352, disc_loss = 0.04031503007705627
Trained batch 291 in epoch 9, gen_loss = 1.2818246414400127, disc_loss = 0.04026087729917354
Trained batch 292 in epoch 9, gen_loss = 1.2819416649105606, disc_loss = 0.04014379407816373
Trained batch 293 in epoch 9, gen_loss = 1.2826071933013241, disc_loss = 0.04004815721022738
Trained batch 294 in epoch 9, gen_loss = 1.2847775030944306, disc_loss = 0.04000091736157567
Trained batch 295 in epoch 9, gen_loss = 1.2851813032820418, disc_loss = 0.03987945617189178
Trained batch 296 in epoch 9, gen_loss = 1.2850132417999935, disc_loss = 0.039783776348914564
Trained batch 297 in epoch 9, gen_loss = 1.285158629385417, disc_loss = 0.03967624938040472
Trained batch 298 in epoch 9, gen_loss = 1.2857682063029363, disc_loss = 0.03959077478925321
Trained batch 299 in epoch 9, gen_loss = 1.2870966605345409, disc_loss = 0.03956226458773017
Trained batch 300 in epoch 9, gen_loss = 1.2879048423513622, disc_loss = 0.039450988940820345
Trained batch 301 in epoch 9, gen_loss = 1.2880706913423854, disc_loss = 0.039339199703840526
Trained batch 302 in epoch 9, gen_loss = 1.2881535814933651, disc_loss = 0.039234483394796404
Trained batch 303 in epoch 9, gen_loss = 1.2882288247346878, disc_loss = 0.03915179337184925
Trained batch 304 in epoch 9, gen_loss = 1.288445101800512, disc_loss = 0.0390396763998099
Trained batch 305 in epoch 9, gen_loss = 1.2885217218617209, disc_loss = 0.0389291435537945
Trained batch 306 in epoch 9, gen_loss = 1.288940218838496, disc_loss = 0.0388300848642443
Trained batch 307 in epoch 9, gen_loss = 1.28964042392644, disc_loss = 0.038733925611421756
Trained batch 308 in epoch 9, gen_loss = 1.2904812163133836, disc_loss = 0.0386493610576832
Trained batch 309 in epoch 9, gen_loss = 1.2905786671946127, disc_loss = 0.038543727163285496
Trained batch 310 in epoch 9, gen_loss = 1.2907463787452969, disc_loss = 0.03844030987070065
Trained batch 311 in epoch 9, gen_loss = 1.2907176170593653, disc_loss = 0.038385890780960046
Trained batch 312 in epoch 9, gen_loss = 1.290603083162643, disc_loss = 0.038325162960020025
Trained batch 313 in epoch 9, gen_loss = 1.2899405660143324, disc_loss = 0.03828402404424254
Trained batch 314 in epoch 9, gen_loss = 1.2902814221760583, disc_loss = 0.03817546074796054
Trained batch 315 in epoch 9, gen_loss = 1.2883734350340277, disc_loss = 0.03835203364650613
Trained batch 316 in epoch 9, gen_loss = 1.2895257023606768, disc_loss = 0.03836653806263293
Trained batch 317 in epoch 9, gen_loss = 1.289165498138224, disc_loss = 0.038367319680785515
Trained batch 318 in epoch 9, gen_loss = 1.288385817436589, disc_loss = 0.038409530571997634
Trained batch 319 in epoch 9, gen_loss = 1.2864510253071786, disc_loss = 0.03877129509783117
Trained batch 320 in epoch 9, gen_loss = 1.2881735566991883, disc_loss = 0.03889739965277251
Trained batch 321 in epoch 9, gen_loss = 1.2900830684981732, disc_loss = 0.038872265515802716
Trained batch 322 in epoch 9, gen_loss = 1.2903568763112874, disc_loss = 0.03880280145406492
Trained batch 323 in epoch 9, gen_loss = 1.2909155528486511, disc_loss = 0.03872756070578126
Trained batch 324 in epoch 9, gen_loss = 1.2901968706571139, disc_loss = 0.03874915156656733
Trained batch 325 in epoch 9, gen_loss = 1.2894678766742074, disc_loss = 0.03873981676418677
Trained batch 326 in epoch 9, gen_loss = 1.2907467420677161, disc_loss = 0.038920612001808685
Trained batch 327 in epoch 9, gen_loss = 1.289506304918266, disc_loss = 0.039573953048292004
Trained batch 328 in epoch 9, gen_loss = 1.2879914547172362, disc_loss = 0.03967258931310298
Trained batch 329 in epoch 9, gen_loss = 1.288157202800115, disc_loss = 0.03959600847694233
Trained batch 330 in epoch 9, gen_loss = 1.287257022187789, disc_loss = 0.03960207189233506
Trained batch 331 in epoch 9, gen_loss = 1.287455809942211, disc_loss = 0.03969997566064304
Trained batch 332 in epoch 9, gen_loss = 1.2871894698601227, disc_loss = 0.039651735997604985
Trained batch 333 in epoch 9, gen_loss = 1.2876970716222318, disc_loss = 0.03955599220335751
Trained batch 334 in epoch 9, gen_loss = 1.2881983684070075, disc_loss = 0.03958752229531754
Trained batch 335 in epoch 9, gen_loss = 1.2884468342221918, disc_loss = 0.03952066173743723
Trained batch 336 in epoch 9, gen_loss = 1.2875095936594094, disc_loss = 0.039557790657289836
Trained batch 337 in epoch 9, gen_loss = 1.2866042346291289, disc_loss = 0.039649901109797187
Trained batch 338 in epoch 9, gen_loss = 1.2870492789245989, disc_loss = 0.03962437736260592
Trained batch 339 in epoch 9, gen_loss = 1.2880296316216975, disc_loss = 0.03960827164187589
Trained batch 340 in epoch 9, gen_loss = 1.2870886622985438, disc_loss = 0.0396313584406923
Trained batch 341 in epoch 9, gen_loss = 1.2871624262709367, disc_loss = 0.03959487879932014
Trained batch 342 in epoch 9, gen_loss = 1.2867735846744681, disc_loss = 0.03952018011622022
Trained batch 343 in epoch 9, gen_loss = 1.2879206981769828, disc_loss = 0.039475990851886224
Trained batch 344 in epoch 9, gen_loss = 1.2876594612563865, disc_loss = 0.03942617830968853
Trained batch 345 in epoch 9, gen_loss = 1.2888879176509174, disc_loss = 0.03936828580022806
Trained batch 346 in epoch 9, gen_loss = 1.2900992800248117, disc_loss = 0.03930001621878027
Trained batch 347 in epoch 9, gen_loss = 1.2908837082742275, disc_loss = 0.03921502414052428
Trained batch 348 in epoch 9, gen_loss = 1.2902239561080933, disc_loss = 0.03918055108985877
Trained batch 349 in epoch 9, gen_loss = 1.2892797604628972, disc_loss = 0.03916918764423047
Trained batch 350 in epoch 9, gen_loss = 1.2901779734171355, disc_loss = 0.03953586435184265
Trained batch 351 in epoch 9, gen_loss = 1.289427010003816, disc_loss = 0.039544943278253246
Trained batch 352 in epoch 9, gen_loss = 1.2879442962641081, disc_loss = 0.039666119807270535
Trained batch 353 in epoch 9, gen_loss = 1.2877794042818964, disc_loss = 0.04010223456537404
Trained batch 354 in epoch 9, gen_loss = 1.2863489533813905, disc_loss = 0.040236178085103
Trained batch 355 in epoch 9, gen_loss = 1.2850380235173728, disc_loss = 0.04034879816476297
Trained batch 356 in epoch 9, gen_loss = 1.2850092322218651, disc_loss = 0.04048724815051178
Trained batch 357 in epoch 9, gen_loss = 1.2851593880680021, disc_loss = 0.040593331880014204
Trained batch 358 in epoch 9, gen_loss = 1.2845042525559747, disc_loss = 0.04080012505277369
Trained batch 359 in epoch 9, gen_loss = 1.2848991331126955, disc_loss = 0.04079345742292288
Trained batch 360 in epoch 9, gen_loss = 1.2848491196487088, disc_loss = 0.04072277992705807
Trained batch 361 in epoch 9, gen_loss = 1.2837135264886677, disc_loss = 0.0407844007359972
Trained batch 362 in epoch 9, gen_loss = 1.2838081656737104, disc_loss = 0.040730478773124454
Trained batch 363 in epoch 9, gen_loss = 1.2842038463760208, disc_loss = 0.0406415781267192
Trained batch 364 in epoch 9, gen_loss = 1.284388120207068, disc_loss = 0.040551189210725154
Trained batch 365 in epoch 9, gen_loss = 1.2846772364579915, disc_loss = 0.040643906994351275
Trained batch 366 in epoch 9, gen_loss = 1.2840328681046695, disc_loss = 0.04063635320486425
Trained batch 367 in epoch 9, gen_loss = 1.2836646065115929, disc_loss = 0.04059283884302915
Trained batch 368 in epoch 9, gen_loss = 1.2835955697346508, disc_loss = 0.040521610177407255
Trained batch 369 in epoch 9, gen_loss = 1.2836305618286132, disc_loss = 0.04045977475927085
Trained batch 370 in epoch 9, gen_loss = 1.283421484286573, disc_loss = 0.040454713233578396
Trained batch 371 in epoch 9, gen_loss = 1.283483818013181, disc_loss = 0.04040943752343376
Trained batch 372 in epoch 9, gen_loss = 1.282213207544015, disc_loss = 0.040449941098869804
Trained batch 373 in epoch 9, gen_loss = 1.2827280033080972, disc_loss = 0.040449927767668974
Trained batch 374 in epoch 9, gen_loss = 1.2821321716308594, disc_loss = 0.040424762360751626
Trained batch 375 in epoch 9, gen_loss = 1.2822508428325043, disc_loss = 0.040337705983473186
Trained batch 376 in epoch 9, gen_loss = 1.2827204952821807, disc_loss = 0.040279004716657754
Trained batch 377 in epoch 9, gen_loss = 1.2839949809054219, disc_loss = 0.04023180281984861
Trained batch 378 in epoch 9, gen_loss = 1.2841345562469362, disc_loss = 0.04014506635052154
Trained batch 379 in epoch 9, gen_loss = 1.2846505187059705, disc_loss = 0.04005205556260128
Trained batch 380 in epoch 9, gen_loss = 1.2849662247605211, disc_loss = 0.03996288523889511
Trained batch 381 in epoch 9, gen_loss = 1.2849355586536269, disc_loss = 0.03987510048989109
Trained batch 382 in epoch 9, gen_loss = 1.2850534041307613, disc_loss = 0.03977975739511435
Trained batch 383 in epoch 9, gen_loss = 1.2851083232089877, disc_loss = 0.03969209075876279
Trained batch 384 in epoch 9, gen_loss = 1.2856756430167657, disc_loss = 0.039600769167935305
Trained batch 385 in epoch 9, gen_loss = 1.28606309699271, disc_loss = 0.03952061316756039
Trained batch 386 in epoch 9, gen_loss = 1.2866123326373038, disc_loss = 0.03954451073331696
Trained batch 387 in epoch 9, gen_loss = 1.2863667257053335, disc_loss = 0.039470964640657386
Trained batch 388 in epoch 9, gen_loss = 1.2862130614969602, disc_loss = 0.03938199790041405
Trained batch 389 in epoch 9, gen_loss = 1.2861367983695788, disc_loss = 0.039310498770851736
Trained batch 390 in epoch 9, gen_loss = 1.2865432820966483, disc_loss = 0.0392484314885
Trained batch 391 in epoch 9, gen_loss = 1.2866966636205206, disc_loss = 0.03917032075280856
Trained batch 392 in epoch 9, gen_loss = 1.286185308267142, disc_loss = 0.039128232044677316
Trained batch 393 in epoch 9, gen_loss = 1.2867289600033445, disc_loss = 0.039048209551220694
Trained batch 394 in epoch 9, gen_loss = 1.2867805203305016, disc_loss = 0.03898284125577989
Trained batch 395 in epoch 9, gen_loss = 1.2871039193688016, disc_loss = 0.03889924866462484
Trained batch 396 in epoch 9, gen_loss = 1.2878873417299401, disc_loss = 0.03882891128440235
Trained batch 397 in epoch 9, gen_loss = 1.2862321147367584, disc_loss = 0.03915426634069551
Trained batch 398 in epoch 9, gen_loss = 1.2880537010972064, disc_loss = 0.03980169220381699
Trained batch 399 in epoch 9, gen_loss = 1.2871311491727828, disc_loss = 0.03981603639316745
Trained batch 400 in epoch 9, gen_loss = 1.2877036151743293, disc_loss = 0.03974737238459419
Trained batch 401 in epoch 9, gen_loss = 1.2878717934314292, disc_loss = 0.03972324219170902
Trained batch 402 in epoch 9, gen_loss = 1.2874794802062268, disc_loss = 0.039677112655617096
Trained batch 403 in epoch 9, gen_loss = 1.2868944096683275, disc_loss = 0.03964187492418223
Trained batch 404 in epoch 9, gen_loss = 1.2863337610974723, disc_loss = 0.03963277639683198
Trained batch 405 in epoch 9, gen_loss = 1.2867876338254054, disc_loss = 0.04000183857238755
Trained batch 406 in epoch 9, gen_loss = 1.2855183817537763, disc_loss = 0.04011110545774459
Trained batch 407 in epoch 9, gen_loss = 1.2857457574676066, disc_loss = 0.04002578112447415
Trained batch 408 in epoch 9, gen_loss = 1.2863434859184881, disc_loss = 0.03998895945974733
Trained batch 409 in epoch 9, gen_loss = 1.286605435173686, disc_loss = 0.039909683858476035
Trained batch 410 in epoch 9, gen_loss = 1.2869492200749344, disc_loss = 0.039825269810791944
Trained batch 411 in epoch 9, gen_loss = 1.2871244211220048, disc_loss = 0.03973849182745026
Trained batch 412 in epoch 9, gen_loss = 1.2871494348054937, disc_loss = 0.03965325388475603
Trained batch 413 in epoch 9, gen_loss = 1.2873884425071127, disc_loss = 0.03964508106315662
Trained batch 414 in epoch 9, gen_loss = 1.2877261618533766, disc_loss = 0.03960376255416188
Trained batch 415 in epoch 9, gen_loss = 1.2877593146493802, disc_loss = 0.039542292348834544
Trained batch 416 in epoch 9, gen_loss = 1.2878450158116914, disc_loss = 0.03946519775173182
Trained batch 417 in epoch 9, gen_loss = 1.2885010946880688, disc_loss = 0.039480100193118865
Trained batch 418 in epoch 9, gen_loss = 1.288221791137659, disc_loss = 0.039413299070346686
Trained batch 419 in epoch 9, gen_loss = 1.2880881485484896, disc_loss = 0.039346227241635674
Trained batch 420 in epoch 9, gen_loss = 1.2877902704293258, disc_loss = 0.0392849934375856
Trained batch 421 in epoch 9, gen_loss = 1.2877523557269743, disc_loss = 0.03921027762607905
Trained batch 422 in epoch 9, gen_loss = 1.289052080319001, disc_loss = 0.039232782705799274
Trained batch 423 in epoch 9, gen_loss = 1.28883758609025, disc_loss = 0.039176343697483455
Trained batch 424 in epoch 9, gen_loss = 1.2892148475085987, disc_loss = 0.03909750481410062
Trained batch 425 in epoch 9, gen_loss = 1.2891358979431116, disc_loss = 0.03902596068795893
Trained batch 426 in epoch 9, gen_loss = 1.288910658353944, disc_loss = 0.03897489819444489
Trained batch 427 in epoch 9, gen_loss = 1.288460446295337, disc_loss = 0.03892886134791493
Trained batch 428 in epoch 9, gen_loss = 1.2891983024446003, disc_loss = 0.0388565757225044
Trained batch 429 in epoch 9, gen_loss = 1.2896643056425938, disc_loss = 0.03878823319601631
Trained batch 430 in epoch 9, gen_loss = 1.290228779797211, disc_loss = 0.038709060065318636
Trained batch 431 in epoch 9, gen_loss = 1.2905182107179254, disc_loss = 0.03863252115789456
Trained batch 432 in epoch 9, gen_loss = 1.2906766521462667, disc_loss = 0.03856568649523046
Trained batch 433 in epoch 9, gen_loss = 1.29106696684789, disc_loss = 0.038513431808383375
Trained batch 434 in epoch 9, gen_loss = 1.2912116694724423, disc_loss = 0.03843670083295511
Trained batch 435 in epoch 9, gen_loss = 1.2908389628480335, disc_loss = 0.038396113138825315
Trained batch 436 in epoch 9, gen_loss = 1.291120753681087, disc_loss = 0.03832127128405927
Trained batch 437 in epoch 9, gen_loss = 1.2916721252545917, disc_loss = 0.03825056445827393
Trained batch 438 in epoch 9, gen_loss = 1.2916221884768753, disc_loss = 0.038182607598407595
Trained batch 439 in epoch 9, gen_loss = 1.2917321346022865, disc_loss = 0.03812421684005213
Trained batch 440 in epoch 9, gen_loss = 1.2914262272062755, disc_loss = 0.038082958003738364
Trained batch 441 in epoch 9, gen_loss = 1.2925921821486357, disc_loss = 0.03806234741208409
Trained batch 442 in epoch 9, gen_loss = 1.293090187399974, disc_loss = 0.03798834754902508
Trained batch 443 in epoch 9, gen_loss = 1.2937450124336793, disc_loss = 0.03791466755855426
Trained batch 444 in epoch 9, gen_loss = 1.293651386861051, disc_loss = 0.037872426248459
Trained batch 445 in epoch 9, gen_loss = 1.2934726000901295, disc_loss = 0.03782818464232367
Trained batch 446 in epoch 9, gen_loss = 1.2933482985101823, disc_loss = 0.03775967132420981
Trained batch 447 in epoch 9, gen_loss = 1.293274734701429, disc_loss = 0.03769458470196696
Trained batch 448 in epoch 9, gen_loss = 1.2935870338919964, disc_loss = 0.03763032582939036
Trained batch 449 in epoch 9, gen_loss = 1.293973966439565, disc_loss = 0.03758928732222153
Trained batch 450 in epoch 9, gen_loss = 1.2940225545688637, disc_loss = 0.03752264323357303
Trained batch 451 in epoch 9, gen_loss = 1.2942879972732173, disc_loss = 0.03745121602690161
Trained batch 452 in epoch 9, gen_loss = 1.2943703762479701, disc_loss = 0.03740130267342425
Trained batch 453 in epoch 9, gen_loss = 1.2949340718958346, disc_loss = 0.03733957219676069
Trained batch 454 in epoch 9, gen_loss = 1.29576130096729, disc_loss = 0.037278503720945384
Trained batch 455 in epoch 9, gen_loss = 1.2963167896919083, disc_loss = 0.03720607716291979
Trained batch 456 in epoch 9, gen_loss = 1.2962576907364494, disc_loss = 0.03713769246712001
Trained batch 457 in epoch 9, gen_loss = 1.2961573525287178, disc_loss = 0.037080448766454534
Trained batch 458 in epoch 9, gen_loss = 1.296550461149943, disc_loss = 0.03701482456652265
Trained batch 459 in epoch 9, gen_loss = 1.2963629958422287, disc_loss = 0.0369626676329695
Trained batch 460 in epoch 9, gen_loss = 1.296386303974077, disc_loss = 0.0368949309942957
Trained batch 461 in epoch 9, gen_loss = 1.2963055201939173, disc_loss = 0.036825852108780636
Trained batch 462 in epoch 9, gen_loss = 1.2972085501668777, disc_loss = 0.03677023745787614
Trained batch 463 in epoch 9, gen_loss = 1.2978842638689896, disc_loss = 0.03670482888139367
Trained batch 464 in epoch 9, gen_loss = 1.2979171176110544, disc_loss = 0.036641211552365174
Trained batch 465 in epoch 9, gen_loss = 1.2977668438346601, disc_loss = 0.03657672533969287
Trained batch 466 in epoch 9, gen_loss = 1.297877251718999, disc_loss = 0.037041686799345296
Trained batch 467 in epoch 9, gen_loss = 1.2969629783660939, disc_loss = 0.037070629016782805
Trained batch 468 in epoch 9, gen_loss = 1.2955173772535344, disc_loss = 0.03734794605090452
Trained batch 469 in epoch 9, gen_loss = 1.2953226845315162, disc_loss = 0.03735729083121615
Trained batch 470 in epoch 9, gen_loss = 1.29621506572529, disc_loss = 0.03733763973191064
Trained batch 471 in epoch 9, gen_loss = 1.2962157448469582, disc_loss = 0.037276667677915765
Trained batch 472 in epoch 9, gen_loss = 1.297316556249058, disc_loss = 0.03726259736052811
Trained batch 473 in epoch 9, gen_loss = 1.2972806204220413, disc_loss = 0.03720294308597183
Trained batch 474 in epoch 9, gen_loss = 1.2960758845429672, disc_loss = 0.03737853986750308
Trained batch 475 in epoch 9, gen_loss = 1.297206819433124, disc_loss = 0.03746655165558258
Trained batch 476 in epoch 9, gen_loss = 1.2977152934114389, disc_loss = 0.03741721303126066
Trained batch 477 in epoch 9, gen_loss = 1.2980578148963562, disc_loss = 0.03736131600977144
Trained batch 478 in epoch 9, gen_loss = 1.2978478270682015, disc_loss = 0.037302278729820615
Trained batch 479 in epoch 9, gen_loss = 1.2977003337194521, disc_loss = 0.03724831202901745
Trained batch 480 in epoch 9, gen_loss = 1.297322726918853, disc_loss = 0.03719806448186665
Trained batch 481 in epoch 9, gen_loss = 1.2975607577448565, disc_loss = 0.037129477042264276
Trained batch 482 in epoch 9, gen_loss = 1.2972082826414957, disc_loss = 0.03707763974074714
Trained batch 483 in epoch 9, gen_loss = 1.2972295610618985, disc_loss = 0.0370137352517552
Trained batch 484 in epoch 9, gen_loss = 1.2976192259296928, disc_loss = 0.03710367101887913
Trained batch 485 in epoch 9, gen_loss = 1.297399047593521, disc_loss = 0.037053464644554036
Trained batch 486 in epoch 9, gen_loss = 1.297587975217087, disc_loss = 0.03698932703056619
Trained batch 487 in epoch 9, gen_loss = 1.2974274196341389, disc_loss = 0.03693591848160827
Trained batch 488 in epoch 9, gen_loss = 1.2965875662908963, disc_loss = 0.03693155512206089
Trained batch 489 in epoch 9, gen_loss = 1.2971962526136516, disc_loss = 0.03689536500760183
Trained batch 490 in epoch 9, gen_loss = 1.297457287243573, disc_loss = 0.036837999348560926
Trained batch 491 in epoch 9, gen_loss = 1.2978394473713588, disc_loss = 0.03677996191408152
Trained batch 492 in epoch 9, gen_loss = 1.2971674880923412, disc_loss = 0.036784812061845286
Trained batch 493 in epoch 9, gen_loss = 1.2968913007844314, disc_loss = 0.036731732909299944
Trained batch 494 in epoch 9, gen_loss = 1.2975455344325364, disc_loss = 0.036701986850286375
Trained batch 495 in epoch 9, gen_loss = 1.2988202336334413, disc_loss = 0.03680292212952589
Trained batch 496 in epoch 9, gen_loss = 1.2990387510245955, disc_loss = 0.03674190742913746
Trained batch 497 in epoch 9, gen_loss = 1.2973661311419613, disc_loss = 0.03718929595302745
Trained batch 498 in epoch 9, gen_loss = 1.2979377141457522, disc_loss = 0.03713851935138743
Trained batch 499 in epoch 9, gen_loss = 1.2980420140028, disc_loss = 0.037106404991820455
Trained batch 500 in epoch 9, gen_loss = 1.2985882584206359, disc_loss = 0.03709113039262221
Trained batch 501 in epoch 9, gen_loss = 1.2989951824524488, disc_loss = 0.037027003905880616
Trained batch 502 in epoch 9, gen_loss = 1.2984870064329674, disc_loss = 0.037015877421537995
Trained batch 503 in epoch 9, gen_loss = 1.297698687348101, disc_loss = 0.037057287505059135
Trained batch 504 in epoch 9, gen_loss = 1.2987325487750592, disc_loss = 0.03702794887900057
Trained batch 505 in epoch 9, gen_loss = 1.298438199777377, disc_loss = 0.036974371348327324
Trained batch 506 in epoch 9, gen_loss = 1.2986886255604746, disc_loss = 0.03691392564958722
Trained batch 507 in epoch 9, gen_loss = 1.298203175110141, disc_loss = 0.03686745288070497
Trained batch 508 in epoch 9, gen_loss = 1.2986134172422712, disc_loss = 0.03680791229847636
Trained batch 509 in epoch 9, gen_loss = 1.2993189644579795, disc_loss = 0.0369469035170315
Trained batch 510 in epoch 9, gen_loss = 1.2989416499193867, disc_loss = 0.036922607950888094
Trained batch 511 in epoch 9, gen_loss = 1.2975104729412124, disc_loss = 0.03711859261329664
Trained batch 512 in epoch 9, gen_loss = 1.298027572459877, disc_loss = 0.03706811269069886
Trained batch 513 in epoch 9, gen_loss = 1.298260787465693, disc_loss = 0.03700465642473867
Trained batch 514 in epoch 9, gen_loss = 1.2988252971936198, disc_loss = 0.03706343000555791
Trained batch 515 in epoch 9, gen_loss = 1.2985366937495018, disc_loss = 0.03703452404696754
Trained batch 516 in epoch 9, gen_loss = 1.2984389206196398, disc_loss = 0.03698151016056653
Trained batch 517 in epoch 9, gen_loss = 1.2978725689948756, disc_loss = 0.036962488421659674
Trained batch 518 in epoch 9, gen_loss = 1.2975668033193761, disc_loss = 0.03692322314460268
Trained batch 519 in epoch 9, gen_loss = 1.2984040277508588, disc_loss = 0.03688067293081146
Trained batch 520 in epoch 9, gen_loss = 1.2988909722060937, disc_loss = 0.03682078785779609
Trained batch 521 in epoch 9, gen_loss = 1.2986128772127217, disc_loss = 0.036776499185796785
Trained batch 522 in epoch 9, gen_loss = 1.2991864917155205, disc_loss = 0.036721287841906855
Trained batch 523 in epoch 9, gen_loss = 1.2990608869390634, disc_loss = 0.03665993366930776
Trained batch 524 in epoch 9, gen_loss = 1.299300578094664, disc_loss = 0.036598097444290205
Trained batch 525 in epoch 9, gen_loss = 1.2992334715993685, disc_loss = 0.036546629467561216
Trained batch 526 in epoch 9, gen_loss = 1.2996111564210968, disc_loss = 0.036483505453589235
Trained batch 527 in epoch 9, gen_loss = 1.2995881653870598, disc_loss = 0.036425524143410395
Trained batch 528 in epoch 9, gen_loss = 1.2999274562797836, disc_loss = 0.036366832752435664
Trained batch 529 in epoch 9, gen_loss = 1.300087744222497, disc_loss = 0.03630337410624016
Trained batch 530 in epoch 9, gen_loss = 1.3005394269966586, disc_loss = 0.03625056012875616
Trained batch 531 in epoch 9, gen_loss = 1.3004942277544422, disc_loss = 0.03619983444109391
Trained batch 532 in epoch 9, gen_loss = 1.3008272447684468, disc_loss = 0.0361411048144829
Trained batch 533 in epoch 9, gen_loss = 1.3012404235338004, disc_loss = 0.03612134627621161
Trained batch 534 in epoch 9, gen_loss = 1.3013297271505695, disc_loss = 0.036059604344941744
Trained batch 535 in epoch 9, gen_loss = 1.3011510044113914, disc_loss = 0.03600811127072839
Trained batch 536 in epoch 9, gen_loss = 1.3007539212148727, disc_loss = 0.03597273753550133
Trained batch 537 in epoch 9, gen_loss = 1.3010214634765922, disc_loss = 0.03592032565195183
Trained batch 538 in epoch 9, gen_loss = 1.3010420079355116, disc_loss = 0.03586551782991288
Trained batch 539 in epoch 9, gen_loss = 1.3009916145492484, disc_loss = 0.03580928966144307
Trained batch 540 in epoch 9, gen_loss = 1.300605541566824, disc_loss = 0.03576873203347026
Trained batch 541 in epoch 9, gen_loss = 1.3012408822005086, disc_loss = 0.03573136345991982
Trained batch 542 in epoch 9, gen_loss = 1.3018371904093917, disc_loss = 0.03572521511290366
Trained batch 543 in epoch 9, gen_loss = 1.3016567509621382, disc_loss = 0.035689128305153535
Trained batch 544 in epoch 9, gen_loss = 1.3014932351374844, disc_loss = 0.03563774628393831
Trained batch 545 in epoch 9, gen_loss = 1.3015873671232998, disc_loss = 0.03558016734218204
Trained batch 546 in epoch 9, gen_loss = 1.301087934203732, disc_loss = 0.035609487015106994
Trained batch 547 in epoch 9, gen_loss = 1.3017244794725502, disc_loss = 0.035563772749903536
Trained batch 548 in epoch 9, gen_loss = 1.3020192976423517, disc_loss = 0.03550767493629336
Trained batch 549 in epoch 9, gen_loss = 1.302242992032658, disc_loss = 0.035449522023766555
Trained batch 550 in epoch 9, gen_loss = 1.3018390793765737, disc_loss = 0.03550474850854713
Trained batch 551 in epoch 9, gen_loss = 1.3009915040886921, disc_loss = 0.03555488217397647
Trained batch 552 in epoch 9, gen_loss = 1.3012738831435577, disc_loss = 0.03550280819252928
Trained batch 553 in epoch 9, gen_loss = 1.3017900319305997, disc_loss = 0.03545253522675619
Trained batch 554 in epoch 9, gen_loss = 1.3017503699740849, disc_loss = 0.03541285413787239
Trained batch 555 in epoch 9, gen_loss = 1.3014849081313868, disc_loss = 0.03538072369565597
Trained batch 556 in epoch 9, gen_loss = 1.3016495169600208, disc_loss = 0.0353314690011816
Trained batch 557 in epoch 9, gen_loss = 1.3023914573013142, disc_loss = 0.03529122131367591
Trained batch 558 in epoch 9, gen_loss = 1.302625278454134, disc_loss = 0.03523745109770307
Trained batch 559 in epoch 9, gen_loss = 1.302595475954669, disc_loss = 0.035196495324323354
Trained batch 560 in epoch 9, gen_loss = 1.3025669720083635, disc_loss = 0.03516144888540282
Trained batch 561 in epoch 9, gen_loss = 1.3024327010446597, disc_loss = 0.03510973991841091
Trained batch 562 in epoch 9, gen_loss = 1.3021591677335398, disc_loss = 0.0350800858563239
Trained batch 563 in epoch 9, gen_loss = 1.3013020033109273, disc_loss = 0.035134563280735165
Trained batch 564 in epoch 9, gen_loss = 1.3034056598106316, disc_loss = 0.03557874994739824
Trained batch 565 in epoch 9, gen_loss = 1.3037092262359053, disc_loss = 0.03552920392150053
Trained batch 566 in epoch 9, gen_loss = 1.3030526631723636, disc_loss = 0.03555288281894537
Trained batch 567 in epoch 9, gen_loss = 1.3025527571288633, disc_loss = 0.03554647134962938
Trained batch 568 in epoch 9, gen_loss = 1.3026174535231767, disc_loss = 0.03550267289228973
Trained batch 569 in epoch 9, gen_loss = 1.3031494491978695, disc_loss = 0.035461433404615446
Trained batch 570 in epoch 9, gen_loss = 1.3034044744254412, disc_loss = 0.03541214341638633
Trained batch 571 in epoch 9, gen_loss = 1.3038679886531164, disc_loss = 0.035365651217956824
Trained batch 572 in epoch 9, gen_loss = 1.3044089130914232, disc_loss = 0.035319021803426054
Trained batch 573 in epoch 9, gen_loss = 1.304603330972718, disc_loss = 0.03527950459096633
Trained batch 574 in epoch 9, gen_loss = 1.3044017762723177, disc_loss = 0.03525719389926804
Trained batch 575 in epoch 9, gen_loss = 1.3044794785479705, disc_loss = 0.03520718875006423
Trained batch 576 in epoch 9, gen_loss = 1.3047718968713717, disc_loss = 0.03515325687652974
Trained batch 577 in epoch 9, gen_loss = 1.3047886418636283, disc_loss = 0.03510387070762206
Trained batch 578 in epoch 9, gen_loss = 1.3047701474504356, disc_loss = 0.035050208793328964
Trained batch 579 in epoch 9, gen_loss = 1.3040981886715723, disc_loss = 0.03508012357593418
Trained batch 580 in epoch 9, gen_loss = 1.3040300792342825, disc_loss = 0.03504748262742313
Trained batch 581 in epoch 9, gen_loss = 1.3044731541187902, disc_loss = 0.03500871587411862
Trained batch 582 in epoch 9, gen_loss = 1.3047815908903118, disc_loss = 0.03496051989903108
Trained batch 583 in epoch 9, gen_loss = 1.3048165558952174, disc_loss = 0.03490702426762716
Trained batch 584 in epoch 9, gen_loss = 1.304985748600756, disc_loss = 0.03485399240062723
Trained batch 585 in epoch 9, gen_loss = 1.3049195640729963, disc_loss = 0.03480085851378269
Trained batch 586 in epoch 9, gen_loss = 1.3049477501256705, disc_loss = 0.03475562852150499
Trained batch 587 in epoch 9, gen_loss = 1.305054398215547, disc_loss = 0.03471254943561151
Trained batch 588 in epoch 9, gen_loss = 1.3050791674842253, disc_loss = 0.034664226490735424
Trained batch 589 in epoch 9, gen_loss = 1.3051435888823817, disc_loss = 0.034612061460976
Trained batch 590 in epoch 9, gen_loss = 1.3053111937243724, disc_loss = 0.034570217648262624
Trained batch 591 in epoch 9, gen_loss = 1.3053939221678554, disc_loss = 0.03451634394445431
Trained batch 592 in epoch 9, gen_loss = 1.305251779684932, disc_loss = 0.03447052198155935
Trained batch 593 in epoch 9, gen_loss = 1.3055042116730302, disc_loss = 0.03441926931432426
Trained batch 594 in epoch 9, gen_loss = 1.3059404655664908, disc_loss = 0.034380782872219295
Trained batch 595 in epoch 9, gen_loss = 1.3060419179449145, disc_loss = 0.03432862290131216
Trained batch 596 in epoch 9, gen_loss = 1.30587289800596, disc_loss = 0.0342785320775131
Trained batch 597 in epoch 9, gen_loss = 1.3059303294057432, disc_loss = 0.03422800064893645
Trained batch 598 in epoch 9, gen_loss = 1.306042295863513, disc_loss = 0.03418538399360987
Testing Epoch 9
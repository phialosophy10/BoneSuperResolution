/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 1.6435670852661133, disc_loss = 0.5995702743530273
Trained batch 1 in epoch 0, gen_loss = 1.5508812069892883, disc_loss = 0.6195516586303711
Trained batch 2 in epoch 0, gen_loss = 1.5964001417160034, disc_loss = 0.6661538879076639
Trained batch 3 in epoch 0, gen_loss = 1.6000782251358032, disc_loss = 0.6410173326730728
Trained batch 4 in epoch 0, gen_loss = 1.5904603242874145, disc_loss = 0.5852635443210602
Trained batch 5 in epoch 0, gen_loss = 1.541129231452942, disc_loss = 0.5423093388477961
Trained batch 6 in epoch 0, gen_loss = 1.5477099759238107, disc_loss = 0.5062531190259116
Trained batch 7 in epoch 0, gen_loss = 1.5359514653682709, disc_loss = 0.4727928526699543
Trained batch 8 in epoch 0, gen_loss = 1.513004673851861, disc_loss = 0.44724275999599034
Trained batch 9 in epoch 0, gen_loss = 1.5192665338516236, disc_loss = 0.42897306084632875
Trained batch 10 in epoch 0, gen_loss = 1.5197156234221025, disc_loss = 0.4119252860546112
Trained batch 11 in epoch 0, gen_loss = 1.5235589842001598, disc_loss = 0.3947846218943596
Trained batch 12 in epoch 0, gen_loss = 1.530684782908513, disc_loss = 0.38042195255939776
Trained batch 13 in epoch 0, gen_loss = 1.523389390536717, disc_loss = 0.36569284754140036
Trained batch 14 in epoch 0, gen_loss = 1.529240655899048, disc_loss = 0.35325906972090404
Trained batch 15 in epoch 0, gen_loss = 1.5199477672576904, disc_loss = 0.34035277273505926
Trained batch 16 in epoch 0, gen_loss = 1.5146153674406164, disc_loss = 0.3292499964728075
Trained batch 17 in epoch 0, gen_loss = 1.5164107481638591, disc_loss = 0.3193410130010711
Trained batch 18 in epoch 0, gen_loss = 1.5150234197315418, disc_loss = 0.3091829097584674
Trained batch 19 in epoch 0, gen_loss = 1.5206545114517211, disc_loss = 0.30057195797562597
Trained batch 20 in epoch 0, gen_loss = 1.5225086439223516, disc_loss = 0.291069915606862
Trained batch 21 in epoch 0, gen_loss = 1.5247083577242764, disc_loss = 0.28394029289484024
Trained batch 22 in epoch 0, gen_loss = 1.529248444930367, disc_loss = 0.2801567290140235
Trained batch 23 in epoch 0, gen_loss = 1.5327038715283077, disc_loss = 0.2814798280596733
Trained batch 24 in epoch 0, gen_loss = 1.52978759765625, disc_loss = 0.27747138023376466
Trained batch 25 in epoch 0, gen_loss = 1.5404669504899244, disc_loss = 0.27055990581329054
Trained batch 26 in epoch 0, gen_loss = 1.5459220585999665, disc_loss = 0.2642174492831583
Trained batch 27 in epoch 0, gen_loss = 1.550644155059542, disc_loss = 0.2572674945529018
Trained batch 28 in epoch 0, gen_loss = 1.5568002955666904, disc_loss = 0.25069448351860046
Trained batch 29 in epoch 0, gen_loss = 1.5581148147583008, disc_loss = 0.24506855209668477
Trained batch 30 in epoch 0, gen_loss = 1.5642758069499847, disc_loss = 0.23931192486516892
Trained batch 31 in epoch 0, gen_loss = 1.5720852389931679, disc_loss = 0.2337221564957872
Trained batch 32 in epoch 0, gen_loss = 1.5790187842918164, disc_loss = 0.22903896744052568
Trained batch 33 in epoch 0, gen_loss = 1.5775852834477144, disc_loss = 0.22394085368689368
Trained batch 34 in epoch 0, gen_loss = 1.577040846007211, disc_loss = 0.22004288860729762
Trained batch 35 in epoch 0, gen_loss = 1.5747444762123957, disc_loss = 0.21532566886809137
Trained batch 36 in epoch 0, gen_loss = 1.57577184728674, disc_loss = 0.21148897385275042
Trained batch 37 in epoch 0, gen_loss = 1.5818642001403005, disc_loss = 0.20750267627207855
Trained batch 38 in epoch 0, gen_loss = 1.5956718554863563, disc_loss = 0.20459078825437105
Trained batch 39 in epoch 0, gen_loss = 1.6031595885753631, disc_loss = 0.20311746299266814
Trained batch 40 in epoch 0, gen_loss = 1.609575553638179, disc_loss = 0.20140853233453704
Trained batch 41 in epoch 0, gen_loss = 1.6137997621581668, disc_loss = 0.19876590016342344
Trained batch 42 in epoch 0, gen_loss = 1.6158946253532587, disc_loss = 0.1954846113573673
Trained batch 43 in epoch 0, gen_loss = 1.6148894781416112, disc_loss = 0.19238672286949374
Trained batch 44 in epoch 0, gen_loss = 1.6224768453174168, disc_loss = 0.1894783962931898
Trained batch 45 in epoch 0, gen_loss = 1.6216598723245703, disc_loss = 0.18661693839923196
Trained batch 46 in epoch 0, gen_loss = 1.6222013970638842, disc_loss = 0.18352355562309
Trained batch 47 in epoch 0, gen_loss = 1.624155821899573, disc_loss = 0.18049750795277456
Trained batch 48 in epoch 0, gen_loss = 1.624111109850358, disc_loss = 0.17765681453201235
Trained batch 49 in epoch 0, gen_loss = 1.6239519691467286, disc_loss = 0.17481648929417135
Trained batch 50 in epoch 0, gen_loss = 1.6218708706837075, disc_loss = 0.17227379795090825
Trained batch 51 in epoch 0, gen_loss = 1.6240907953335688, disc_loss = 0.1695916228569471
Trained batch 52 in epoch 0, gen_loss = 1.62829219845106, disc_loss = 0.16706185253723613
Trained batch 53 in epoch 0, gen_loss = 1.6294264484334875, disc_loss = 0.16461443356065839
Trained batch 54 in epoch 0, gen_loss = 1.6295483329079368, disc_loss = 0.16233203343369745
Trained batch 55 in epoch 0, gen_loss = 1.6313216175351823, disc_loss = 0.16027947328984737
Trained batch 56 in epoch 0, gen_loss = 1.63074637295907, disc_loss = 0.15812442726210543
Trained batch 57 in epoch 0, gen_loss = 1.6320082545280457, disc_loss = 0.15595908039088907
Trained batch 58 in epoch 0, gen_loss = 1.634229437779572, disc_loss = 0.15385003602605754
Trained batch 59 in epoch 0, gen_loss = 1.6370943148930868, disc_loss = 0.15180240689466398
Trained batch 60 in epoch 0, gen_loss = 1.6363313159004587, disc_loss = 0.14993384449941213
Trained batch 61 in epoch 0, gen_loss = 1.635527330060159, disc_loss = 0.1481864731758833
Trained batch 62 in epoch 0, gen_loss = 1.6386307345496283, disc_loss = 0.14649096060366856
Trained batch 63 in epoch 0, gen_loss = 1.639060428366065, disc_loss = 0.14474795653950423
Trained batch 64 in epoch 0, gen_loss = 1.6398766297560472, disc_loss = 0.1430211519392637
Trained batch 65 in epoch 0, gen_loss = 1.6434620076959783, disc_loss = 0.1412643650828889
Trained batch 66 in epoch 0, gen_loss = 1.6448946621880602, disc_loss = 0.13953862909172007
Trained batch 67 in epoch 0, gen_loss = 1.6438851374037124, disc_loss = 0.13813590502147288
Trained batch 68 in epoch 0, gen_loss = 1.644386068634365, disc_loss = 0.13650904274613096
Trained batch 69 in epoch 0, gen_loss = 1.6444882784570967, disc_loss = 0.1349718879642231
Trained batch 70 in epoch 0, gen_loss = 1.6439327370952552, disc_loss = 0.1336083420303086
Trained batch 71 in epoch 0, gen_loss = 1.6442723158333037, disc_loss = 0.1321563501583619
Trained batch 72 in epoch 0, gen_loss = 1.647380774968291, disc_loss = 0.13072231146570754
Trained batch 73 in epoch 0, gen_loss = 1.648528563009726, disc_loss = 0.12935184606829206
Trained batch 74 in epoch 0, gen_loss = 1.6481517012914022, disc_loss = 0.1281242448091507
Trained batch 75 in epoch 0, gen_loss = 1.6507385796622227, disc_loss = 0.12685636053548047
Trained batch 76 in epoch 0, gen_loss = 1.649409244586895, disc_loss = 0.12636201620682494
Trained batch 77 in epoch 0, gen_loss = 1.6454749076794355, disc_loss = 0.12651423570246267
Trained batch 78 in epoch 0, gen_loss = 1.646049816397172, disc_loss = 0.1254331993434248
Trained batch 79 in epoch 0, gen_loss = 1.6457072168588638, disc_loss = 0.12456549615599215
Trained batch 80 in epoch 0, gen_loss = 1.647114759610023, disc_loss = 0.12348438196896035
Trained batch 81 in epoch 0, gen_loss = 1.6466837757971229, disc_loss = 0.12231323100263025
Trained batch 82 in epoch 0, gen_loss = 1.6472820316452579, disc_loss = 0.12115532341581511
Trained batch 83 in epoch 0, gen_loss = 1.6471012092771984, disc_loss = 0.11994893290102482
Trained batch 84 in epoch 0, gen_loss = 1.6465984288383932, disc_loss = 0.11872453406891402
Trained batch 85 in epoch 0, gen_loss = 1.6448044222454692, disc_loss = 0.11760719876389863
Trained batch 86 in epoch 0, gen_loss = 1.644983538265886, disc_loss = 0.1166679944157943
Trained batch 87 in epoch 0, gen_loss = 1.6448813026601619, disc_loss = 0.11567310190928931
Trained batch 88 in epoch 0, gen_loss = 1.644731806905082, disc_loss = 0.11460372845359733
Trained batch 89 in epoch 0, gen_loss = 1.6426491353246901, disc_loss = 0.11351383491936658
Trained batch 90 in epoch 0, gen_loss = 1.6413445957414396, disc_loss = 0.1125368056921186
Trained batch 91 in epoch 0, gen_loss = 1.6399998898091523, disc_loss = 0.11151434446725508
Trained batch 92 in epoch 0, gen_loss = 1.6375414286890337, disc_loss = 0.11054854587681832
Trained batch 93 in epoch 0, gen_loss = 1.6374312677281968, disc_loss = 0.10971211776771445
Trained batch 94 in epoch 0, gen_loss = 1.638845746140731, disc_loss = 0.10897707829349919
Trained batch 95 in epoch 0, gen_loss = 1.6381830424070358, disc_loss = 0.10832263591388862
Trained batch 96 in epoch 0, gen_loss = 1.6346453121027995, disc_loss = 0.10784049604817764
Trained batch 97 in epoch 0, gen_loss = 1.6292358782826637, disc_loss = 0.10826315134003454
Trained batch 98 in epoch 0, gen_loss = 1.6329948275980324, disc_loss = 0.10811059203262281
Trained batch 99 in epoch 0, gen_loss = 1.6346826457977295, disc_loss = 0.10779914032667876
Trained batch 100 in epoch 0, gen_loss = 1.634161329505467, disc_loss = 0.10757160389629922
Trained batch 101 in epoch 0, gen_loss = 1.631772151180342, disc_loss = 0.10701283954960458
Trained batch 102 in epoch 0, gen_loss = 1.6311580579257705, disc_loss = 0.10618367923188557
Trained batch 103 in epoch 0, gen_loss = 1.6287364386595213, disc_loss = 0.1054015971111277
Trained batch 104 in epoch 0, gen_loss = 1.6290067400251116, disc_loss = 0.10454168707309734
Trained batch 105 in epoch 0, gen_loss = 1.6278719542161473, disc_loss = 0.10372266993102319
Trained batch 106 in epoch 0, gen_loss = 1.625902253890706, disc_loss = 0.10292002430760136
Trained batch 107 in epoch 0, gen_loss = 1.6233719200999648, disc_loss = 0.1021153102370186
Trained batch 108 in epoch 0, gen_loss = 1.620094328845313, disc_loss = 0.10132075896606259
Trained batch 109 in epoch 0, gen_loss = 1.6203692447055469, disc_loss = 0.10051705139604482
Trained batch 110 in epoch 0, gen_loss = 1.620405380790298, disc_loss = 0.09976421826863074
Trained batch 111 in epoch 0, gen_loss = 1.6196020894816943, disc_loss = 0.0989886523873013
Trained batch 112 in epoch 0, gen_loss = 1.617530393389474, disc_loss = 0.09823520348069414
Trained batch 113 in epoch 0, gen_loss = 1.6159526036496747, disc_loss = 0.09748091793766148
Trained batch 114 in epoch 0, gen_loss = 1.6132206927175108, disc_loss = 0.09675730596417965
Trained batch 115 in epoch 0, gen_loss = 1.6127959027372558, disc_loss = 0.09602152691062155
Trained batch 116 in epoch 0, gen_loss = 1.6123537354999118, disc_loss = 0.09529703877802588
Trained batch 117 in epoch 0, gen_loss = 1.6111364556571184, disc_loss = 0.09458125273744433
Trained batch 118 in epoch 0, gen_loss = 1.6118059228448307, disc_loss = 0.0938730713668741
Trained batch 119 in epoch 0, gen_loss = 1.6114502042531966, disc_loss = 0.0932065021712333
Trained batch 120 in epoch 0, gen_loss = 1.6099272217632326, disc_loss = 0.09251918000253764
Trained batch 121 in epoch 0, gen_loss = 1.6069334344785722, disc_loss = 0.09188731703296547
Trained batch 122 in epoch 0, gen_loss = 1.6045119684886158, disc_loss = 0.09124242590089154
Trained batch 123 in epoch 0, gen_loss = 1.6026649484711308, disc_loss = 0.09062755406053076
Trained batch 124 in epoch 0, gen_loss = 1.6013246631622315, disc_loss = 0.08998715672641992
Trained batch 125 in epoch 0, gen_loss = 1.6006898482640584, disc_loss = 0.08935993999272349
Trained batch 126 in epoch 0, gen_loss = 1.5997155313416729, disc_loss = 0.08872826526484151
Trained batch 127 in epoch 0, gen_loss = 1.6012084316462278, disc_loss = 0.08810357954644132
Trained batch 128 in epoch 0, gen_loss = 1.6012417863505755, disc_loss = 0.0875105765150037
Trained batch 129 in epoch 0, gen_loss = 1.6013851770987877, disc_loss = 0.08692756691374458
Trained batch 130 in epoch 0, gen_loss = 1.6004511745831438, disc_loss = 0.08633375871670611
Trained batch 131 in epoch 0, gen_loss = 1.6000457803408306, disc_loss = 0.08574307753676266
Trained batch 132 in epoch 0, gen_loss = 1.5994012642623787, disc_loss = 0.0851697419819079
Trained batch 133 in epoch 0, gen_loss = 1.5984874625704182, disc_loss = 0.08458669271681514
Trained batch 134 in epoch 0, gen_loss = 1.5982805331548056, disc_loss = 0.08401603501428057
Trained batch 135 in epoch 0, gen_loss = 1.59555482776726, disc_loss = 0.0834818416795529
Trained batch 136 in epoch 0, gen_loss = 1.596283805631373, disc_loss = 0.082951839904498
Trained batch 137 in epoch 0, gen_loss = 1.5939154961834783, disc_loss = 0.0824101341591365
Trained batch 138 in epoch 0, gen_loss = 1.5942214101338559, disc_loss = 0.08187970243019166
Trained batch 139 in epoch 0, gen_loss = 1.5947117779936109, disc_loss = 0.08136229061388543
Trained batch 140 in epoch 0, gen_loss = 1.5933290060530318, disc_loss = 0.08084005179504554
Trained batch 141 in epoch 0, gen_loss = 1.5918195222465086, disc_loss = 0.08035239368729608
Trained batch 142 in epoch 0, gen_loss = 1.5910772418642378, disc_loss = 0.07986159897507071
Trained batch 143 in epoch 0, gen_loss = 1.5904530626204278, disc_loss = 0.07936455055217569
Trained batch 144 in epoch 0, gen_loss = 1.590528654230052, disc_loss = 0.07888653661156522
Trained batch 145 in epoch 0, gen_loss = 1.5904009219718307, disc_loss = 0.07840928886953281
Trained batch 146 in epoch 0, gen_loss = 1.5901436035324927, disc_loss = 0.07793908433190413
Trained batch 147 in epoch 0, gen_loss = 1.5883340964446198, disc_loss = 0.0774659509707645
Trained batch 148 in epoch 0, gen_loss = 1.586321262705246, disc_loss = 0.07699680453066358
Trained batch 149 in epoch 0, gen_loss = 1.5848478555679322, disc_loss = 0.07656403246956567
Trained batch 150 in epoch 0, gen_loss = 1.5837005866284402, disc_loss = 0.0761165380607427
Trained batch 151 in epoch 0, gen_loss = 1.581321396325764, disc_loss = 0.07567901394366727
Trained batch 152 in epoch 0, gen_loss = 1.5801238896800023, disc_loss = 0.07525386811946244
Trained batch 153 in epoch 0, gen_loss = 1.5783279460745971, disc_loss = 0.07481869505778826
Trained batch 154 in epoch 0, gen_loss = 1.5764431115119688, disc_loss = 0.07438345342994698
Trained batch 155 in epoch 0, gen_loss = 1.5747274733506715, disc_loss = 0.07397123347991744
Trained batch 156 in epoch 0, gen_loss = 1.573850201952989, disc_loss = 0.07354668799230153
Trained batch 157 in epoch 0, gen_loss = 1.5742817438101466, disc_loss = 0.07312912160023764
Trained batch 158 in epoch 0, gen_loss = 1.5741685291506209, disc_loss = 0.07272907541244754
Trained batch 159 in epoch 0, gen_loss = 1.5730589747428894, disc_loss = 0.07232261136814486
Trained batch 160 in epoch 0, gen_loss = 1.5729998535251024, disc_loss = 0.07192317285627034
Trained batch 161 in epoch 0, gen_loss = 1.5720842944251165, disc_loss = 0.07156179620263477
Trained batch 162 in epoch 0, gen_loss = 1.5711038449059236, disc_loss = 0.07117182843992773
Trained batch 163 in epoch 0, gen_loss = 1.5722444493596146, disc_loss = 0.0707923446401454
Trained batch 164 in epoch 0, gen_loss = 1.5714546954993045, disc_loss = 0.07041476362977515
Trained batch 165 in epoch 0, gen_loss = 1.570920407053936, disc_loss = 0.07004197187867599
Trained batch 166 in epoch 0, gen_loss = 1.5694431808894267, disc_loss = 0.06967651648000775
Trained batch 167 in epoch 0, gen_loss = 1.568330237553233, disc_loss = 0.06931723815311368
Trained batch 168 in epoch 0, gen_loss = 1.5673705868467072, disc_loss = 0.0689440231643529
Trained batch 169 in epoch 0, gen_loss = 1.5664354352390064, disc_loss = 0.06857674368383253
Trained batch 170 in epoch 0, gen_loss = 1.5651901695463393, disc_loss = 0.06821344032535079
Trained batch 171 in epoch 0, gen_loss = 1.5648995991363082, disc_loss = 0.06787417426727019
Trained batch 172 in epoch 0, gen_loss = 1.5641424600788623, disc_loss = 0.06752364905389575
Trained batch 173 in epoch 0, gen_loss = 1.5630843940822559, disc_loss = 0.06717222140320502
Trained batch 174 in epoch 0, gen_loss = 1.5620059170041765, disc_loss = 0.06682286989209907
Trained batch 175 in epoch 0, gen_loss = 1.5607372190464626, disc_loss = 0.06647833674585192
Trained batch 176 in epoch 0, gen_loss = 1.5599278440583224, disc_loss = 0.06613896444892395
Trained batch 177 in epoch 0, gen_loss = 1.5587070256136777, disc_loss = 0.06582810737851881
Trained batch 178 in epoch 0, gen_loss = 1.5576395082740144, disc_loss = 0.06552253598243248
Trained batch 179 in epoch 0, gen_loss = 1.5558366643057928, disc_loss = 0.06519998095463961
Trained batch 180 in epoch 0, gen_loss = 1.5542471975252774, disc_loss = 0.0648856488190262
Trained batch 181 in epoch 0, gen_loss = 1.5524666702354348, disc_loss = 0.06458326883788047
Trained batch 182 in epoch 0, gen_loss = 1.550976949962762, disc_loss = 0.06426173678848668
Trained batch 183 in epoch 0, gen_loss = 1.550725695879563, disc_loss = 0.06397729146081711
Trained batch 184 in epoch 0, gen_loss = 1.5490487098693848, disc_loss = 0.0637250453409915
Trained batch 185 in epoch 0, gen_loss = 1.5487746064380934, disc_loss = 0.06344064750948981
Trained batch 186 in epoch 0, gen_loss = 1.547109512721791, disc_loss = 0.06322506740739081
Trained batch 187 in epoch 0, gen_loss = 1.5459763084320313, disc_loss = 0.06305786611839256
Trained batch 188 in epoch 0, gen_loss = 1.5441523178544625, disc_loss = 0.06279187069752465
Trained batch 189 in epoch 0, gen_loss = 1.5433537784375642, disc_loss = 0.06251397091454189
Trained batch 190 in epoch 0, gen_loss = 1.5425690137903103, disc_loss = 0.0622745073566223
Trained batch 191 in epoch 0, gen_loss = 1.541484085842967, disc_loss = 0.062011745916000414
Trained batch 192 in epoch 0, gen_loss = 1.5413625777694229, disc_loss = 0.06175064350782358
Trained batch 193 in epoch 0, gen_loss = 1.5397591203758396, disc_loss = 0.061465927706935354
Trained batch 194 in epoch 0, gen_loss = 1.539226405437176, disc_loss = 0.06119756327512173
Trained batch 195 in epoch 0, gen_loss = 1.537332249539239, disc_loss = 0.060930158068635026
Trained batch 196 in epoch 0, gen_loss = 1.536014384424626, disc_loss = 0.06064707258725681
Trained batch 197 in epoch 0, gen_loss = 1.535659038057231, disc_loss = 0.06037078476087614
Trained batch 198 in epoch 0, gen_loss = 1.5351854496864816, disc_loss = 0.06009314777376364
Trained batch 199 in epoch 0, gen_loss = 1.5345674765110016, disc_loss = 0.05981868813047186
Trained batch 200 in epoch 0, gen_loss = 1.5338200953469348, disc_loss = 0.05957089242900708
Trained batch 201 in epoch 0, gen_loss = 1.532580560976916, disc_loss = 0.05931376814980539
Trained batch 202 in epoch 0, gen_loss = 1.531300333333133, disc_loss = 0.059045356156974295
Trained batch 203 in epoch 0, gen_loss = 1.5298271798620038, disc_loss = 0.05880036711802378
Trained batch 204 in epoch 0, gen_loss = 1.5304760932922363, disc_loss = 0.05854333207102084
Trained batch 205 in epoch 0, gen_loss = 1.5305197580346783, disc_loss = 0.05829915533619888
Trained batch 206 in epoch 0, gen_loss = 1.5293803693015795, disc_loss = 0.05805792311287444
Trained batch 207 in epoch 0, gen_loss = 1.5284060560739958, disc_loss = 0.057807113480521366
Trained batch 208 in epoch 0, gen_loss = 1.5276291849510522, disc_loss = 0.057569535549409225
Trained batch 209 in epoch 0, gen_loss = 1.5277618902070182, disc_loss = 0.05733180024350683
Trained batch 210 in epoch 0, gen_loss = 1.5276577851218636, disc_loss = 0.05709098609411533
Trained batch 211 in epoch 0, gen_loss = 1.5261602092464015, disc_loss = 0.05685280405977776
Trained batch 212 in epoch 0, gen_loss = 1.5250598046701278, disc_loss = 0.05663619324468741
Trained batch 213 in epoch 0, gen_loss = 1.5245126112599239, disc_loss = 0.05641252087716396
Trained batch 214 in epoch 0, gen_loss = 1.5235480286354242, disc_loss = 0.05617565090313207
Trained batch 215 in epoch 0, gen_loss = 1.5222234196133084, disc_loss = 0.05594480440615573
Trained batch 216 in epoch 0, gen_loss = 1.5208535908554006, disc_loss = 0.05571143667123491
Trained batch 217 in epoch 0, gen_loss = 1.5209156477123225, disc_loss = 0.05548140944682335
Trained batch 218 in epoch 0, gen_loss = 1.520611706389684, disc_loss = 0.055256321643517445
Trained batch 219 in epoch 0, gen_loss = 1.5207913420417092, disc_loss = 0.055028730664740906
Trained batch 220 in epoch 0, gen_loss = 1.5196509997769179, disc_loss = 0.054842374911236814
Trained batch 221 in epoch 0, gen_loss = 1.5190751992904388, disc_loss = 0.05463651600839184
Trained batch 222 in epoch 0, gen_loss = 1.519252366549231, disc_loss = 0.054426284573738354
Trained batch 223 in epoch 0, gen_loss = 1.518849675144468, disc_loss = 0.05422763380504746
Trained batch 224 in epoch 0, gen_loss = 1.5187323305341933, disc_loss = 0.05401915987746583
Trained batch 225 in epoch 0, gen_loss = 1.5182748748137889, disc_loss = 0.053804900361208524
Trained batch 226 in epoch 0, gen_loss = 1.518331947305654, disc_loss = 0.05358685251522301
Trained batch 227 in epoch 0, gen_loss = 1.5180914804600834, disc_loss = 0.05337096743179452
Trained batch 228 in epoch 0, gen_loss = 1.5176716215225285, disc_loss = 0.05315921216487364
Trained batch 229 in epoch 0, gen_loss = 1.5171866028205208, disc_loss = 0.05296163735303866
Trained batch 230 in epoch 0, gen_loss = 1.5162463322346345, disc_loss = 0.05276175554503094
Trained batch 231 in epoch 0, gen_loss = 1.515461909359899, disc_loss = 0.05255715184090338
Trained batch 232 in epoch 0, gen_loss = 1.5143620410190632, disc_loss = 0.052354838737074784
Trained batch 233 in epoch 0, gen_loss = 1.5141604237067394, disc_loss = 0.052152109360242754
Trained batch 234 in epoch 0, gen_loss = 1.5133972619442229, disc_loss = 0.05194817879930773
Trained batch 235 in epoch 0, gen_loss = 1.5119644241817927, disc_loss = 0.051758083554332035
Trained batch 236 in epoch 0, gen_loss = 1.5115369110670773, disc_loss = 0.05158082194594894
Trained batch 237 in epoch 0, gen_loss = 1.5107725643310226, disc_loss = 0.05142649998810111
Trained batch 238 in epoch 0, gen_loss = 1.50970770873784, disc_loss = 0.05123956584484632
Trained batch 239 in epoch 0, gen_loss = 1.5095959439873696, disc_loss = 0.05104692301829346
Trained batch 240 in epoch 0, gen_loss = 1.507938893009518, disc_loss = 0.0508600319349265
Trained batch 241 in epoch 0, gen_loss = 1.5064569233862821, disc_loss = 0.05066744407661998
Trained batch 242 in epoch 0, gen_loss = 1.5057277385099435, disc_loss = 0.05048408134123732
Trained batch 243 in epoch 0, gen_loss = 1.5048216249121995, disc_loss = 0.050296698668284616
Trained batch 244 in epoch 0, gen_loss = 1.5045006114609387, disc_loss = 0.05011419589840332
Trained batch 245 in epoch 0, gen_loss = 1.5059071919782374, disc_loss = 0.04993484830635229
Trained batch 246 in epoch 0, gen_loss = 1.5062232051301099, disc_loss = 0.04975180269826038
Trained batch 247 in epoch 0, gen_loss = 1.5060035528675202, disc_loss = 0.04957332125594539
Trained batch 248 in epoch 0, gen_loss = 1.5051897625367805, disc_loss = 0.049401492405922176
Trained batch 249 in epoch 0, gen_loss = 1.5052005743980408, disc_loss = 0.04922479326464236
Trained batch 250 in epoch 0, gen_loss = 1.5046174663946448, disc_loss = 0.04905109304148125
Trained batch 251 in epoch 0, gen_loss = 1.5041579135826655, disc_loss = 0.04887512030213007
Trained batch 252 in epoch 0, gen_loss = 1.5034657528277913, disc_loss = 0.048704122458198086
Trained batch 253 in epoch 0, gen_loss = 1.5026716331797323, disc_loss = 0.04854193073147395
Trained batch 254 in epoch 0, gen_loss = 1.501679695821276, disc_loss = 0.04837935758279819
Trained batch 255 in epoch 0, gen_loss = 1.5009235688485205, disc_loss = 0.048213349815341644
Trained batch 256 in epoch 0, gen_loss = 1.4999187563179996, disc_loss = 0.04804275320763138
Trained batch 257 in epoch 0, gen_loss = 1.4992788526438927, disc_loss = 0.047878557397413625
Trained batch 258 in epoch 0, gen_loss = 1.4984698470494922, disc_loss = 0.04770954356719398
Trained batch 259 in epoch 0, gen_loss = 1.4985938163904042, disc_loss = 0.047541901433410555
Trained batch 260 in epoch 0, gen_loss = 1.498645327100352, disc_loss = 0.047376300204702265
Trained batch 261 in epoch 0, gen_loss = 1.4976324621047683, disc_loss = 0.04721014880049149
Trained batch 262 in epoch 0, gen_loss = 1.49712312402834, disc_loss = 0.047045180145580276
Trained batch 263 in epoch 0, gen_loss = 1.4964596227262958, disc_loss = 0.04688856141839289
Trained batch 264 in epoch 0, gen_loss = 1.4957683981589551, disc_loss = 0.04672807265635369
Trained batch 265 in epoch 0, gen_loss = 1.4953701473716507, disc_loss = 0.046572734615800526
Trained batch 266 in epoch 0, gen_loss = 1.495091544554921, disc_loss = 0.046427636400339534
Trained batch 267 in epoch 0, gen_loss = 1.4955760631988297, disc_loss = 0.04630827889499713
Trained batch 268 in epoch 0, gen_loss = 1.49489320343755, disc_loss = 0.0461692540494372
Trained batch 269 in epoch 0, gen_loss = 1.4945750876709267, disc_loss = 0.04601920792074115
Trained batch 270 in epoch 0, gen_loss = 1.4936685870054462, disc_loss = 0.045878740707996586
Trained batch 271 in epoch 0, gen_loss = 1.4926745536572792, disc_loss = 0.0457388858879259
Trained batch 272 in epoch 0, gen_loss = 1.4924973651166364, disc_loss = 0.04559578382215657
Trained batch 273 in epoch 0, gen_loss = 1.491558064074412, disc_loss = 0.04546398591984362
Trained batch 274 in epoch 0, gen_loss = 1.4911571537364612, disc_loss = 0.04532601967115294
Trained batch 275 in epoch 0, gen_loss = 1.4907086223795794, disc_loss = 0.045177639740438244
Trained batch 276 in epoch 0, gen_loss = 1.490043553634671, disc_loss = 0.045033794676461375
Trained batch 277 in epoch 0, gen_loss = 1.4902614303630033, disc_loss = 0.04489914690338665
Trained batch 278 in epoch 0, gen_loss = 1.4894972095352774, disc_loss = 0.044761736142886366
Trained batch 279 in epoch 0, gen_loss = 1.4882103208984647, disc_loss = 0.044620306591968986
Trained batch 280 in epoch 0, gen_loss = 1.4873218294564514, disc_loss = 0.04449598383973767
Trained batch 281 in epoch 0, gen_loss = 1.4862418069061658, disc_loss = 0.04435490603981447
Trained batch 282 in epoch 0, gen_loss = 1.4857519485925197, disc_loss = 0.04421509109773137
Trained batch 283 in epoch 0, gen_loss = 1.4852535178963566, disc_loss = 0.04407842815558518
Trained batch 284 in epoch 0, gen_loss = 1.4853453836942974, disc_loss = 0.0439456805309052
Trained batch 285 in epoch 0, gen_loss = 1.4848440664631504, disc_loss = 0.04381698162386103
Trained batch 286 in epoch 0, gen_loss = 1.4840959800660403, disc_loss = 0.04367648371664048
Trained batch 287 in epoch 0, gen_loss = 1.4850517238179843, disc_loss = 0.043541152509634334
Trained batch 288 in epoch 0, gen_loss = 1.4842846001720758, disc_loss = 0.04341280987489466
Trained batch 289 in epoch 0, gen_loss = 1.4832885220133025, disc_loss = 0.043281999862239025
Trained batch 290 in epoch 0, gen_loss = 1.4824600387684668, disc_loss = 0.043145486898560244
Trained batch 291 in epoch 0, gen_loss = 1.4825474758670754, disc_loss = 0.043011812639122904
Trained batch 292 in epoch 0, gen_loss = 1.4822095636621677, disc_loss = 0.042882067665502226
Trained batch 293 in epoch 0, gen_loss = 1.4813060209053714, disc_loss = 0.04275780340393714
Trained batch 294 in epoch 0, gen_loss = 1.4806225889820164, disc_loss = 0.042630751239199
Trained batch 295 in epoch 0, gen_loss = 1.480706745708311, disc_loss = 0.04249946363002842
Trained batch 296 in epoch 0, gen_loss = 1.480100306597623, disc_loss = 0.04237750195741327
Trained batch 297 in epoch 0, gen_loss = 1.4797420301693398, disc_loss = 0.04225442535634584
Trained batch 298 in epoch 0, gen_loss = 1.4790474786407573, disc_loss = 0.04212627846071727
Trained batch 299 in epoch 0, gen_loss = 1.4784928373495738, disc_loss = 0.042002172577970974
Trained batch 300 in epoch 0, gen_loss = 1.4777623264496509, disc_loss = 0.04187376104121984
Trained batch 301 in epoch 0, gen_loss = 1.4772708546246913, disc_loss = 0.04175851655667586
Trained batch 302 in epoch 0, gen_loss = 1.4769987249531762, disc_loss = 0.04164207522010449
Trained batch 303 in epoch 0, gen_loss = 1.4764940542610068, disc_loss = 0.04151740862748978
Trained batch 304 in epoch 0, gen_loss = 1.4758010301433626, disc_loss = 0.041391083094306655
Trained batch 305 in epoch 0, gen_loss = 1.4751247720780716, disc_loss = 0.04126867320802477
Trained batch 306 in epoch 0, gen_loss = 1.4760036010307287, disc_loss = 0.04114840448764229
Trained batch 307 in epoch 0, gen_loss = 1.475001955574209, disc_loss = 0.04102577365233333
Trained batch 308 in epoch 0, gen_loss = 1.4757627152316393, disc_loss = 0.0409103932030933
Trained batch 309 in epoch 0, gen_loss = 1.4752801718250397, disc_loss = 0.04079261308445806
Trained batch 310 in epoch 0, gen_loss = 1.4748092517975442, disc_loss = 0.04067634563395975
Trained batch 311 in epoch 0, gen_loss = 1.4738068068638825, disc_loss = 0.040563619670231275
Trained batch 312 in epoch 0, gen_loss = 1.4738452305047276, disc_loss = 0.040451800345053406
Trained batch 313 in epoch 0, gen_loss = 1.4732285532981726, disc_loss = 0.04033627498236479
Trained batch 314 in epoch 0, gen_loss = 1.4722324371337892, disc_loss = 0.04022082222684745
Trained batch 315 in epoch 0, gen_loss = 1.4714424685586858, disc_loss = 0.04011975676911777
Trained batch 316 in epoch 0, gen_loss = 1.4717464650090937, disc_loss = 0.04001511902216387
Trained batch 317 in epoch 0, gen_loss = 1.471254033112676, disc_loss = 0.03990348668493705
Trained batch 318 in epoch 0, gen_loss = 1.4707212515385546, disc_loss = 0.039800306408429596
Trained batch 319 in epoch 0, gen_loss = 1.4700705714523792, disc_loss = 0.03970544689509552
Trained batch 320 in epoch 0, gen_loss = 1.4693401290620227, disc_loss = 0.039736848205583306
Trained batch 321 in epoch 0, gen_loss = 1.4682464155351154, disc_loss = 0.039959464994438504
Trained batch 322 in epoch 0, gen_loss = 1.4676871617143, disc_loss = 0.039879997826005466
Trained batch 323 in epoch 0, gen_loss = 1.4675021009680667, disc_loss = 0.03981118552950153
Trained batch 324 in epoch 0, gen_loss = 1.46733522268442, disc_loss = 0.039725047911588963
Trained batch 325 in epoch 0, gen_loss = 1.4670064317668143, disc_loss = 0.03963040884161379
Trained batch 326 in epoch 0, gen_loss = 1.4671666819021243, disc_loss = 0.039532919649308156
Trained batch 327 in epoch 0, gen_loss = 1.4665102736978997, disc_loss = 0.03943047826547494
Trained batch 328 in epoch 0, gen_loss = 1.4662159347968986, disc_loss = 0.03932232065565069
Trained batch 329 in epoch 0, gen_loss = 1.4656385819117228, disc_loss = 0.039214281435830126
Trained batch 330 in epoch 0, gen_loss = 1.4647533043633776, disc_loss = 0.0391116309573373
Trained batch 331 in epoch 0, gen_loss = 1.4639560971633498, disc_loss = 0.03900786315887628
Trained batch 332 in epoch 0, gen_loss = 1.4641594922578371, disc_loss = 0.03890260077968195
Trained batch 333 in epoch 0, gen_loss = 1.4633097113249545, disc_loss = 0.038819808872628536
Trained batch 334 in epoch 0, gen_loss = 1.4621934356974131, disc_loss = 0.03874227935309286
Trained batch 335 in epoch 0, gen_loss = 1.4615824666051638, disc_loss = 0.038648220750647375
Trained batch 336 in epoch 0, gen_loss = 1.4611209666339864, disc_loss = 0.03855977824665274
Trained batch 337 in epoch 0, gen_loss = 1.4606703202399982, disc_loss = 0.038471130465471445
Trained batch 338 in epoch 0, gen_loss = 1.4603358384078935, disc_loss = 0.0383704120422381
Trained batch 339 in epoch 0, gen_loss = 1.4603664966190562, disc_loss = 0.038270002383026566
Trained batch 340 in epoch 0, gen_loss = 1.4600736825696883, disc_loss = 0.03817755507600229
Trained batch 341 in epoch 0, gen_loss = 1.4603461431480989, disc_loss = 0.03807475754844123
Trained batch 342 in epoch 0, gen_loss = 1.4600865760975608, disc_loss = 0.03798150057896277
Trained batch 343 in epoch 0, gen_loss = 1.4593299745127213, disc_loss = 0.037891712512138714
Trained batch 344 in epoch 0, gen_loss = 1.4584359638932822, disc_loss = 0.03781669205594538
Trained batch 345 in epoch 0, gen_loss = 1.4580331861628273, disc_loss = 0.03774444359849945
Trained batch 346 in epoch 0, gen_loss = 1.4571384868292026, disc_loss = 0.037653699093189635
Trained batch 347 in epoch 0, gen_loss = 1.4569703566616978, disc_loss = 0.037584271961716056
Trained batch 348 in epoch 0, gen_loss = 1.4563492580949406, disc_loss = 0.03751813292898302
Trained batch 349 in epoch 0, gen_loss = 1.4560860797337123, disc_loss = 0.0374229759656425
Trained batch 350 in epoch 0, gen_loss = 1.4558031494461234, disc_loss = 0.03733124454211221
Trained batch 351 in epoch 0, gen_loss = 1.4551894607191735, disc_loss = 0.037240689305525106
Trained batch 352 in epoch 0, gen_loss = 1.4545694231649295, disc_loss = 0.03714625815473096
Trained batch 353 in epoch 0, gen_loss = 1.4538546160789534, disc_loss = 0.03705136091671989
Trained batch 354 in epoch 0, gen_loss = 1.4540183198284096, disc_loss = 0.036960797604094715
Trained batch 355 in epoch 0, gen_loss = 1.4531485331192444, disc_loss = 0.03687419832273376
Trained batch 356 in epoch 0, gen_loss = 1.452737145063256, disc_loss = 0.03678604152186641
Trained batch 357 in epoch 0, gen_loss = 1.4517903684237816, disc_loss = 0.03669855917879385
Trained batch 358 in epoch 0, gen_loss = 1.452011080505456, disc_loss = 0.03660558981491476
Trained batch 359 in epoch 0, gen_loss = 1.4515342795186572, disc_loss = 0.03651792610051214
Trained batch 360 in epoch 0, gen_loss = 1.450984845531284, disc_loss = 0.0364302825576102
Trained batch 361 in epoch 0, gen_loss = 1.4504606545959389, disc_loss = 0.03633927611327982
Trained batch 362 in epoch 0, gen_loss = 1.449630615468196, disc_loss = 0.03624828260702392
Trained batch 363 in epoch 0, gen_loss = 1.4492325321003632, disc_loss = 0.036156882997602224
Trained batch 364 in epoch 0, gen_loss = 1.4488889984888573, disc_loss = 0.036066971754986944
Trained batch 365 in epoch 0, gen_loss = 1.4482680386532851, disc_loss = 0.03597818049754886
Trained batch 366 in epoch 0, gen_loss = 1.4479391061642515, disc_loss = 0.03588854334423729
Trained batch 367 in epoch 0, gen_loss = 1.4472539609541064, disc_loss = 0.035800932754089285
Trained batch 368 in epoch 0, gen_loss = 1.4466645623933332, disc_loss = 0.03571015181585258
Trained batch 369 in epoch 0, gen_loss = 1.446516621757198, disc_loss = 0.03562055977715834
Trained batch 370 in epoch 0, gen_loss = 1.4460101047294802, disc_loss = 0.035535907627628094
Trained batch 371 in epoch 0, gen_loss = 1.445432831523239, disc_loss = 0.03544804734185398
Trained batch 372 in epoch 0, gen_loss = 1.4450953908004964, disc_loss = 0.03536182114899398
Trained batch 373 in epoch 0, gen_loss = 1.444580025213925, disc_loss = 0.03527630744738514
Trained batch 374 in epoch 0, gen_loss = 1.4441379092534383, disc_loss = 0.035190365705639125
Trained batch 375 in epoch 0, gen_loss = 1.4435682544048796, disc_loss = 0.03510519889978434
Trained batch 376 in epoch 0, gen_loss = 1.4437602609791238, disc_loss = 0.035018641765375155
Trained batch 377 in epoch 0, gen_loss = 1.4439424780941514, disc_loss = 0.034933832049660545
Trained batch 378 in epoch 0, gen_loss = 1.4437031311850435, disc_loss = 0.03485170436597928
Trained batch 379 in epoch 0, gen_loss = 1.4436644127494411, disc_loss = 0.034769312976124254
Trained batch 380 in epoch 0, gen_loss = 1.4431895446276728, disc_loss = 0.03468510514098339
Trained batch 381 in epoch 0, gen_loss = 1.442695620484377, disc_loss = 0.03460634760595176
Trained batch 382 in epoch 0, gen_loss = 1.4428133771562701, disc_loss = 0.034527350711337154
Trained batch 383 in epoch 0, gen_loss = 1.442483302205801, disc_loss = 0.03444504722877658
Trained batch 384 in epoch 0, gen_loss = 1.441935811414347, disc_loss = 0.034361883015190435
Trained batch 385 in epoch 0, gen_loss = 1.4422347020608774, disc_loss = 0.03428028185714345
Trained batch 386 in epoch 0, gen_loss = 1.4417585815262117, disc_loss = 0.03420172080587721
Trained batch 387 in epoch 0, gen_loss = 1.4413496360336382, disc_loss = 0.03412236742250448
Trained batch 388 in epoch 0, gen_loss = 1.4412345423490038, disc_loss = 0.03404398709188448
Trained batch 389 in epoch 0, gen_loss = 1.4407790556932107, disc_loss = 0.033972275516806316
Trained batch 390 in epoch 0, gen_loss = 1.4403582930259997, disc_loss = 0.03389742317885789
Trained batch 391 in epoch 0, gen_loss = 1.4396205696524407, disc_loss = 0.033820182671865484
Trained batch 392 in epoch 0, gen_loss = 1.439402097964105, disc_loss = 0.033741974402171665
Trained batch 393 in epoch 0, gen_loss = 1.4399553207576576, disc_loss = 0.0336646818252148
Trained batch 394 in epoch 0, gen_loss = 1.4396900186055823, disc_loss = 0.03359196187185619
Trained batch 395 in epoch 0, gen_loss = 1.439785804712411, disc_loss = 0.03351527566591165
Trained batch 396 in epoch 0, gen_loss = 1.4404089120533363, disc_loss = 0.03344297533097116
Trained batch 397 in epoch 0, gen_loss = 1.4405914263509625, disc_loss = 0.03336796176212667
Trained batch 398 in epoch 0, gen_loss = 1.4403736734748782, disc_loss = 0.0332906046639521
Trained batch 399 in epoch 0, gen_loss = 1.4403601455688477, disc_loss = 0.03321473851217888
Trained batch 400 in epoch 0, gen_loss = 1.4404100622619476, disc_loss = 0.03313917549735776
Trained batch 401 in epoch 0, gen_loss = 1.439828730934295, disc_loss = 0.03306253973061024
Trained batch 402 in epoch 0, gen_loss = 1.439167349865064, disc_loss = 0.03298829686215549
Trained batch 403 in epoch 0, gen_loss = 1.4385199906802413, disc_loss = 0.03291633397474479
Trained batch 404 in epoch 0, gen_loss = 1.4383405332212096, disc_loss = 0.03284686244334336
Trained batch 405 in epoch 0, gen_loss = 1.4377031564125287, disc_loss = 0.03277771088771816
Trained batch 406 in epoch 0, gen_loss = 1.4373372681896575, disc_loss = 0.03270336045913343
Trained batch 407 in epoch 0, gen_loss = 1.4370656270606845, disc_loss = 0.03262959941125968
Trained batch 408 in epoch 0, gen_loss = 1.4372329056117237, disc_loss = 0.032556508705338744
Trained batch 409 in epoch 0, gen_loss = 1.4368205163537002, disc_loss = 0.03248206634960342
Trained batch 410 in epoch 0, gen_loss = 1.4366162037907435, disc_loss = 0.032407854274685725
Trained batch 411 in epoch 0, gen_loss = 1.4367968657063048, disc_loss = 0.032334680157573445
Trained batch 412 in epoch 0, gen_loss = 1.4363051439312988, disc_loss = 0.032262347024678284
Trained batch 413 in epoch 0, gen_loss = 1.4364340840906338, disc_loss = 0.03219032694151454
Trained batch 414 in epoch 0, gen_loss = 1.436391734789653, disc_loss = 0.032122266109112695
Trained batch 415 in epoch 0, gen_loss = 1.4359013131604745, disc_loss = 0.03205556598941957
Trained batch 416 in epoch 0, gen_loss = 1.4355677337669355, disc_loss = 0.031984519857770316
Trained batch 417 in epoch 0, gen_loss = 1.4349127688476344, disc_loss = 0.031913326544081126
Trained batch 418 in epoch 0, gen_loss = 1.4343902569682045, disc_loss = 0.03184248156832233
Trained batch 419 in epoch 0, gen_loss = 1.433734613373166, disc_loss = 0.03177133188028598
Trained batch 420 in epoch 0, gen_loss = 1.4342390732074293, disc_loss = 0.03170542565070429
Trained batch 421 in epoch 0, gen_loss = 1.4340091517186278, disc_loss = 0.03164945648855119
Trained batch 422 in epoch 0, gen_loss = 1.4340732537262828, disc_loss = 0.03159448771625229
Trained batch 423 in epoch 0, gen_loss = 1.4336880254295636, disc_loss = 0.03153520352470706
Trained batch 424 in epoch 0, gen_loss = 1.4335176150939044, disc_loss = 0.03146642901551198
Trained batch 425 in epoch 0, gen_loss = 1.4336118807255382, disc_loss = 0.031404321816500644
Trained batch 426 in epoch 0, gen_loss = 1.433035501830751, disc_loss = 0.0313415843644452
Trained batch 427 in epoch 0, gen_loss = 1.4334726517445573, disc_loss = 0.0312734265010978
Trained batch 428 in epoch 0, gen_loss = 1.433338582376778, disc_loss = 0.03121039494524747
Trained batch 429 in epoch 0, gen_loss = 1.4329270884048106, disc_loss = 0.031143811989987138
Trained batch 430 in epoch 0, gen_loss = 1.4325228893563255, disc_loss = 0.03107611939263489
Trained batch 431 in epoch 0, gen_loss = 1.432096141907904, disc_loss = 0.031009728605298464
Trained batch 432 in epoch 0, gen_loss = 1.4317524378073958, disc_loss = 0.03094251297159426
Trained batch 433 in epoch 0, gen_loss = 1.4315069944078471, disc_loss = 0.030877901866982697
Trained batch 434 in epoch 0, gen_loss = 1.4312310243475026, disc_loss = 0.030811581317731446
Trained batch 435 in epoch 0, gen_loss = 1.4307649996849374, disc_loss = 0.0307478226308493
Trained batch 436 in epoch 0, gen_loss = 1.430915879985015, disc_loss = 0.030686027112254953
Trained batch 437 in epoch 0, gen_loss = 1.4306896837878988, disc_loss = 0.030620798576234086
Trained batch 438 in epoch 0, gen_loss = 1.4300265350211454, disc_loss = 0.030560500339863732
Trained batch 439 in epoch 0, gen_loss = 1.4296141296625138, disc_loss = 0.0304997886745365
Trained batch 440 in epoch 0, gen_loss = 1.4298427637472175, disc_loss = 0.030436978465560698
Trained batch 441 in epoch 0, gen_loss = 1.429054999513324, disc_loss = 0.03037440284957047
Trained batch 442 in epoch 0, gen_loss = 1.4293702671274913, disc_loss = 0.030311644093331126
Trained batch 443 in epoch 0, gen_loss = 1.4290794485861116, disc_loss = 0.030251654388062103
Trained batch 444 in epoch 0, gen_loss = 1.4288059264086606, disc_loss = 0.0301902593184116
Trained batch 445 in epoch 0, gen_loss = 1.4291200394587666, disc_loss = 0.030129020700320985
Trained batch 446 in epoch 0, gen_loss = 1.4288081394746, disc_loss = 0.03006947264299255
Trained batch 447 in epoch 0, gen_loss = 1.4281621567372764, disc_loss = 0.030010539288144043
Trained batch 448 in epoch 0, gen_loss = 1.4276072365669472, disc_loss = 0.029949736356463506
Trained batch 449 in epoch 0, gen_loss = 1.4271922749943204, disc_loss = 0.02989065874600783
Trained batch 450 in epoch 0, gen_loss = 1.4265854332240882, disc_loss = 0.029831138548148
Trained batch 451 in epoch 0, gen_loss = 1.426070158460499, disc_loss = 0.02976968636930986
Trained batch 452 in epoch 0, gen_loss = 1.4256925490781434, disc_loss = 0.029707900279563406
Trained batch 453 in epoch 0, gen_loss = 1.425728133333937, disc_loss = 0.029648262398401563
Trained batch 454 in epoch 0, gen_loss = 1.4251454403112223, disc_loss = 0.02958980279508978
Trained batch 455 in epoch 0, gen_loss = 1.4245441558591105, disc_loss = 0.029530184458085466
Trained batch 456 in epoch 0, gen_loss = 1.4239627568935669, disc_loss = 0.029470943235201226
Trained batch 457 in epoch 0, gen_loss = 1.423855610289428, disc_loss = 0.029411630472930873
Trained batch 458 in epoch 0, gen_loss = 1.42343701204703, disc_loss = 0.029354339708728323
Trained batch 459 in epoch 0, gen_loss = 1.4235916391662928, disc_loss = 0.02929675861327585
Trained batch 460 in epoch 0, gen_loss = 1.423358512545356, disc_loss = 0.02923960744786135
Trained batch 461 in epoch 0, gen_loss = 1.4228177248657523, disc_loss = 0.029181589997621472
Trained batch 462 in epoch 0, gen_loss = 1.4224394325561194, disc_loss = 0.029127254439708948
Trained batch 463 in epoch 0, gen_loss = 1.4217777185398957, disc_loss = 0.029084471326596344
Trained batch 464 in epoch 0, gen_loss = 1.4213257661429786, disc_loss = 0.0290376446462707
Trained batch 465 in epoch 0, gen_loss = 1.4215016436679169, disc_loss = 0.028984279786746215
Trained batch 466 in epoch 0, gen_loss = 1.4212400928554494, disc_loss = 0.02893227645633762
Trained batch 467 in epoch 0, gen_loss = 1.4208175809974344, disc_loss = 0.028877535307805777
Trained batch 468 in epoch 0, gen_loss = 1.4201174420334384, disc_loss = 0.028823173447285712
Trained batch 469 in epoch 0, gen_loss = 1.4203396231570142, disc_loss = 0.02876906020125929
Trained batch 470 in epoch 0, gen_loss = 1.419855995289586, disc_loss = 0.02871838778098195
Trained batch 471 in epoch 0, gen_loss = 1.4191713403847257, disc_loss = 0.0286674019522961
Trained batch 472 in epoch 0, gen_loss = 1.419786468368756, disc_loss = 0.02861502414237487
Trained batch 473 in epoch 0, gen_loss = 1.419649522515792, disc_loss = 0.02856391746200079
Trained batch 474 in epoch 0, gen_loss = 1.4192936199589778, disc_loss = 0.028510291425168123
Trained batch 475 in epoch 0, gen_loss = 1.419087537947823, disc_loss = 0.028461354208215994
Trained batch 476 in epoch 0, gen_loss = 1.418369280717158, disc_loss = 0.02842424146755866
Trained batch 477 in epoch 0, gen_loss = 1.4182295502479105, disc_loss = 0.028382888610063658
Trained batch 478 in epoch 0, gen_loss = 1.418020189430619, disc_loss = 0.02832877311815696
Trained batch 479 in epoch 0, gen_loss = 1.418327330549558, disc_loss = 0.028276794057213315
Trained batch 480 in epoch 0, gen_loss = 1.4180229619734004, disc_loss = 0.028223886264230582
Trained batch 481 in epoch 0, gen_loss = 1.4176467461704714, disc_loss = 0.028176686240802617
Trained batch 482 in epoch 0, gen_loss = 1.417164507119552, disc_loss = 0.02812497737777938
Trained batch 483 in epoch 0, gen_loss = 1.4169028869345168, disc_loss = 0.028080125100966465
Trained batch 484 in epoch 0, gen_loss = 1.4165122425433287, disc_loss = 0.028043026271871455
Trained batch 485 in epoch 0, gen_loss = 1.4161446786221163, disc_loss = 0.027990871862893535
Trained batch 486 in epoch 0, gen_loss = 1.4157781219090768, disc_loss = 0.027943770340701193
Trained batch 487 in epoch 0, gen_loss = 1.4163021704212564, disc_loss = 0.027891228730040296
Trained batch 488 in epoch 0, gen_loss = 1.4162860867435947, disc_loss = 0.02784034976490977
Trained batch 489 in epoch 0, gen_loss = 1.416752061551931, disc_loss = 0.02778758134203488
Trained batch 490 in epoch 0, gen_loss = 1.4162784540483278, disc_loss = 0.027734615357048326
Trained batch 491 in epoch 0, gen_loss = 1.4160058663143376, disc_loss = 0.02768108683114879
Trained batch 492 in epoch 0, gen_loss = 1.4155096693406481, disc_loss = 0.027630462210850214
Trained batch 493 in epoch 0, gen_loss = 1.4150923027200737, disc_loss = 0.02785334470262374
Trained batch 494 in epoch 0, gen_loss = 1.4137187607360608, disc_loss = 0.028913813614700405
Trained batch 495 in epoch 0, gen_loss = 1.4127697063790214, disc_loss = 0.029087776930077046
Trained batch 496 in epoch 0, gen_loss = 1.4134190575457675, disc_loss = 0.029387433415183226
Trained batch 497 in epoch 0, gen_loss = 1.4129382030791546, disc_loss = 0.02966404698361796
Trained batch 498 in epoch 0, gen_loss = 1.412127272041145, disc_loss = 0.029864664168754045
Trained batch 499 in epoch 0, gen_loss = 1.4115830065011978, disc_loss = 0.029920616160845383
Trained batch 500 in epoch 0, gen_loss = 1.4113537607316724, disc_loss = 0.029908656761442456
Trained batch 501 in epoch 0, gen_loss = 1.4115726329178448, disc_loss = 0.029918956944850677
Trained batch 502 in epoch 0, gen_loss = 1.4116319452317998, disc_loss = 0.029912930644565367
Trained batch 503 in epoch 0, gen_loss = 1.4111738270000806, disc_loss = 0.02991216379519929
Trained batch 504 in epoch 0, gen_loss = 1.4107247450564167, disc_loss = 0.029892466869896814
Trained batch 505 in epoch 0, gen_loss = 1.4111188102381031, disc_loss = 0.029859249807458018
Trained batch 506 in epoch 0, gen_loss = 1.4107382451523927, disc_loss = 0.029818074187838804
Trained batch 507 in epoch 0, gen_loss = 1.410449526558711, disc_loss = 0.02976969434805471
Trained batch 508 in epoch 0, gen_loss = 1.4100094770167337, disc_loss = 0.029720675331734354
Trained batch 509 in epoch 0, gen_loss = 1.4097617961612403, disc_loss = 0.029672892948420827
Trained batch 510 in epoch 0, gen_loss = 1.4102410200524003, disc_loss = 0.02962449334134437
Trained batch 511 in epoch 0, gen_loss = 1.4099003066075966, disc_loss = 0.029573214698530137
Trained batch 512 in epoch 0, gen_loss = 1.4096599985749168, disc_loss = 0.02952202499846857
Trained batch 513 in epoch 0, gen_loss = 1.40957412958609, disc_loss = 0.02947069804753985
Trained batch 514 in epoch 0, gen_loss = 1.4092860748466935, disc_loss = 0.029422775156190167
Trained batch 515 in epoch 0, gen_loss = 1.4089623910281086, disc_loss = 0.029374583910603814
Trained batch 516 in epoch 0, gen_loss = 1.4089672603505723, disc_loss = 0.029326974235275107
Trained batch 517 in epoch 0, gen_loss = 1.4089251753216085, disc_loss = 0.029283462053849848
Trained batch 518 in epoch 0, gen_loss = 1.4086578357426418, disc_loss = 0.029236620231280337
Trained batch 519 in epoch 0, gen_loss = 1.4082726997824815, disc_loss = 0.029188513387075194
Trained batch 520 in epoch 0, gen_loss = 1.4081943333720979, disc_loss = 0.02914113454514446
Trained batch 521 in epoch 0, gen_loss = 1.4079940201450583, disc_loss = 0.029090538733126774
Trained batch 522 in epoch 0, gen_loss = 1.4079465336143173, disc_loss = 0.02904070749853063
Trained batch 523 in epoch 0, gen_loss = 1.4077076605940593, disc_loss = 0.02899273904418139
Trained batch 524 in epoch 0, gen_loss = 1.4074463868141174, disc_loss = 0.028944271712209143
Trained batch 525 in epoch 0, gen_loss = 1.4070249110346964, disc_loss = 0.028897556364527434
Trained batch 526 in epoch 0, gen_loss = 1.406671090076273, disc_loss = 0.028849488530931836
Trained batch 527 in epoch 0, gen_loss = 1.4061439277773553, disc_loss = 0.028799773327288374
Trained batch 528 in epoch 0, gen_loss = 1.4060299490034467, disc_loss = 0.028753473916591017
Trained batch 529 in epoch 0, gen_loss = 1.405696221455088, disc_loss = 0.0287079198173915
Trained batch 530 in epoch 0, gen_loss = 1.405495806490185, disc_loss = 0.028658675135327275
Trained batch 531 in epoch 0, gen_loss = 1.4057844985920684, disc_loss = 0.0286103667990266
Trained batch 532 in epoch 0, gen_loss = 1.4058793603143818, disc_loss = 0.02856574426636652
Trained batch 533 in epoch 0, gen_loss = 1.406111096286595, disc_loss = 0.028524488863606732
Trained batch 534 in epoch 0, gen_loss = 1.4057888141302304, disc_loss = 0.028477688945577454
Trained batch 535 in epoch 0, gen_loss = 1.4056903761047035, disc_loss = 0.02843501147837552
Trained batch 536 in epoch 0, gen_loss = 1.4059800001718035, disc_loss = 0.028388695030219964
Trained batch 537 in epoch 0, gen_loss = 1.4058262093138074, disc_loss = 0.02834196178286707
Trained batch 538 in epoch 0, gen_loss = 1.4055138896038006, disc_loss = 0.028297372647657894
Trained batch 539 in epoch 0, gen_loss = 1.4051802075571485, disc_loss = 0.02825492898204916
Trained batch 540 in epoch 0, gen_loss = 1.4046300423784308, disc_loss = 0.028209191139971633
Trained batch 541 in epoch 0, gen_loss = 1.404595080446933, disc_loss = 0.028167032724120945
Trained batch 542 in epoch 0, gen_loss = 1.4048555115748944, disc_loss = 0.028127078609035093
Trained batch 543 in epoch 0, gen_loss = 1.4044739513055366, disc_loss = 0.028083278053493227
Trained batch 544 in epoch 0, gen_loss = 1.4042812556301782, disc_loss = 0.028039927528359408
Trained batch 545 in epoch 0, gen_loss = 1.4039845910919455, disc_loss = 0.02799496127632805
Trained batch 546 in epoch 0, gen_loss = 1.4042438773176134, disc_loss = 0.027949447895764583
Trained batch 547 in epoch 0, gen_loss = 1.4042679311802788, disc_loss = 0.027903020231309857
Trained batch 548 in epoch 0, gen_loss = 1.4037742485548412, disc_loss = 0.027856739445925368
Trained batch 549 in epoch 0, gen_loss = 1.4036942548101599, disc_loss = 0.02781297719042579
Trained batch 550 in epoch 0, gen_loss = 1.4037649450847327, disc_loss = 0.02776798154307722
Trained batch 551 in epoch 0, gen_loss = 1.4037493351792945, disc_loss = 0.02772179717198858
Trained batch 552 in epoch 0, gen_loss = 1.403610103276927, disc_loss = 0.02767552413441288
Trained batch 553 in epoch 0, gen_loss = 1.4037970232404096, disc_loss = 0.027629828727123284
Trained batch 554 in epoch 0, gen_loss = 1.403488837383889, disc_loss = 0.027587666559905688
Trained batch 555 in epoch 0, gen_loss = 1.403275061747153, disc_loss = 0.02754260280162009
Trained batch 556 in epoch 0, gen_loss = 1.4029287203638088, disc_loss = 0.02749759105265749
Trained batch 557 in epoch 0, gen_loss = 1.4032605438890422, disc_loss = 0.02745299073128951
Trained batch 558 in epoch 0, gen_loss = 1.402747515595663, disc_loss = 0.027407253500114134
Trained batch 559 in epoch 0, gen_loss = 1.4027048397277082, disc_loss = 0.027361989578847508
Trained batch 560 in epoch 0, gen_loss = 1.4022805166966987, disc_loss = 0.027322084076433658
Trained batch 561 in epoch 0, gen_loss = 1.4017912950167877, disc_loss = 0.02728371397514241
Trained batch 562 in epoch 0, gen_loss = 1.4013404197210104, disc_loss = 0.027240257426107146
Trained batch 563 in epoch 0, gen_loss = 1.4012214443150988, disc_loss = 0.027199375984367936
Trained batch 564 in epoch 0, gen_loss = 1.4008055179519991, disc_loss = 0.02715576441991514
Trained batch 565 in epoch 0, gen_loss = 1.400396126213849, disc_loss = 0.027119668778986424
Trained batch 566 in epoch 0, gen_loss = 1.3998765044531916, disc_loss = 0.027081282101440157
Trained batch 567 in epoch 0, gen_loss = 1.3997908808605772, disc_loss = 0.02703926366717804
Trained batch 568 in epoch 0, gen_loss = 1.3993859897598442, disc_loss = 0.02699811418945058
Trained batch 569 in epoch 0, gen_loss = 1.3996459650365929, disc_loss = 0.02695664709777032
Trained batch 570 in epoch 0, gen_loss = 1.3996667023715539, disc_loss = 0.026912976862885542
Trained batch 571 in epoch 0, gen_loss = 1.3995473577634439, disc_loss = 0.026869875923942098
Trained batch 572 in epoch 0, gen_loss = 1.3999521084272841, disc_loss = 0.02682674258181835
Trained batch 573 in epoch 0, gen_loss = 1.3996185146350064, disc_loss = 0.02678273783413408
Trained batch 574 in epoch 0, gen_loss = 1.399318914309792, disc_loss = 0.02674277072387707
Trained batch 575 in epoch 0, gen_loss = 1.3989104370897014, disc_loss = 0.02670643107093282
Trained batch 576 in epoch 0, gen_loss = 1.3984835035259637, disc_loss = 0.026673529144784876
Trained batch 577 in epoch 0, gen_loss = 1.3982671578656432, disc_loss = 0.026634696698836197
Trained batch 578 in epoch 0, gen_loss = 1.3978588557408058, disc_loss = 0.026597235954385925
Trained batch 579 in epoch 0, gen_loss = 1.397943003321516, disc_loss = 0.02656139839251911
Trained batch 580 in epoch 0, gen_loss = 1.3975223078169634, disc_loss = 0.02652506647161056
Trained batch 581 in epoch 0, gen_loss = 1.397485475462327, disc_loss = 0.026485357195726207
Trained batch 582 in epoch 0, gen_loss = 1.3969856552766895, disc_loss = 0.02644366179620863
Trained batch 583 in epoch 0, gen_loss = 1.396480274220852, disc_loss = 0.026404704443499613
Trained batch 584 in epoch 0, gen_loss = 1.3963793103511517, disc_loss = 0.026363054999054815
Trained batch 585 in epoch 0, gen_loss = 1.3959047644821858, disc_loss = 0.026324932827612658
Trained batch 586 in epoch 0, gen_loss = 1.3956644826487747, disc_loss = 0.026282875113438315
Trained batch 587 in epoch 0, gen_loss = 1.3958338504137635, disc_loss = 0.026246173774742768
Trained batch 588 in epoch 0, gen_loss = 1.395581470989007, disc_loss = 0.0262090789554609
Trained batch 589 in epoch 0, gen_loss = 1.3956001569659022, disc_loss = 0.026169840978276994
Trained batch 590 in epoch 0, gen_loss = 1.3954631613595836, disc_loss = 0.02613876110778778
Trained batch 591 in epoch 0, gen_loss = 1.3951066127298652, disc_loss = 0.026104575061008044
Trained batch 592 in epoch 0, gen_loss = 1.3948949680963616, disc_loss = 0.026063560071388735
Trained batch 593 in epoch 0, gen_loss = 1.394887238540232, disc_loss = 0.02602404784328878
Trained batch 594 in epoch 0, gen_loss = 1.3948233038437468, disc_loss = 0.025983261633781764
Trained batch 595 in epoch 0, gen_loss = 1.3945059483283317, disc_loss = 0.02594366163189598
Trained batch 596 in epoch 0, gen_loss = 1.394256852280155, disc_loss = 0.025904323113809215
Trained batch 597 in epoch 0, gen_loss = 1.3942101130318083, disc_loss = 0.025863785617891388
Trained batch 598 in epoch 0, gen_loss = 1.3940464042263954, disc_loss = 0.025824517550767836
Trained batch 599 in epoch 0, gen_loss = 1.3937750984231632, disc_loss = 0.025784063308965415
Trained batch 600 in epoch 0, gen_loss = 1.3940221790267704, disc_loss = 0.025744653325496913
Trained batch 601 in epoch 0, gen_loss = 1.3938769564478104, disc_loss = 0.025706427436371478
Trained batch 602 in epoch 0, gen_loss = 1.3937836574084723, disc_loss = 0.02566949761423219
Trained batch 603 in epoch 0, gen_loss = 1.3936581462621689, disc_loss = 0.025631319377602182
Trained batch 604 in epoch 0, gen_loss = 1.393394923111624, disc_loss = 0.025592142679874808
Trained batch 605 in epoch 0, gen_loss = 1.3930846955319836, disc_loss = 0.025552946513613974
Trained batch 606 in epoch 0, gen_loss = 1.393150661785088, disc_loss = 0.02551441662868138
Trained batch 607 in epoch 0, gen_loss = 1.3927979062458402, disc_loss = 0.02547970740699001
Trained batch 608 in epoch 0, gen_loss = 1.3928735997093526, disc_loss = 0.02544391469545173
Trained batch 609 in epoch 0, gen_loss = 1.393195464669681, disc_loss = 0.025405119165022416
Trained batch 610 in epoch 0, gen_loss = 1.393351625791353, disc_loss = 0.025369770019909643
Trained batch 611 in epoch 0, gen_loss = 1.3931240267028995, disc_loss = 0.02533428273083843
Trained batch 612 in epoch 0, gen_loss = 1.3927899913142205, disc_loss = 0.025300381785497178
Trained batch 613 in epoch 0, gen_loss = 1.392409399297416, disc_loss = 0.025264291275339655
Trained batch 614 in epoch 0, gen_loss = 1.3927316767413442, disc_loss = 0.025227312587496893
Trained batch 615 in epoch 0, gen_loss = 1.392835412029322, disc_loss = 0.02518978077852524
Trained batch 616 in epoch 0, gen_loss = 1.392643071360874, disc_loss = 0.025151515600491902
Trained batch 617 in epoch 0, gen_loss = 1.392276663514017, disc_loss = 0.025113177721797032
Trained batch 618 in epoch 0, gen_loss = 1.3921642025183398, disc_loss = 0.025075046594784278
Trained batch 619 in epoch 0, gen_loss = 1.3920510093050618, disc_loss = 0.02503977326109194
Trained batch 620 in epoch 0, gen_loss = 1.3918959603985344, disc_loss = 0.02500835713542752
Trained batch 621 in epoch 0, gen_loss = 1.391936858463134, disc_loss = 0.024978764094090406
Trained batch 622 in epoch 0, gen_loss = 1.3916323017538264, disc_loss = 0.02494494123163859
Trained batch 623 in epoch 0, gen_loss = 1.3916378066134758, disc_loss = 0.024907232850427345
Trained batch 624 in epoch 0, gen_loss = 1.391461911869049, disc_loss = 0.02487293948736042
Trained batch 625 in epoch 0, gen_loss = 1.3911797984149128, disc_loss = 0.024837347433921665
Trained batch 626 in epoch 0, gen_loss = 1.3910084442848984, disc_loss = 0.024800267425719263
Trained batch 627 in epoch 0, gen_loss = 1.3906871466689807, disc_loss = 0.024765246240221923
Trained batch 628 in epoch 0, gen_loss = 1.3910524518197973, disc_loss = 0.024728981488005262
Trained batch 629 in epoch 0, gen_loss = 1.3909309806331756, disc_loss = 0.024692241136272927
Trained batch 630 in epoch 0, gen_loss = 1.3908817309962966, disc_loss = 0.02465629783180792
Trained batch 631 in epoch 0, gen_loss = 1.3907281574380548, disc_loss = 0.024620259458072412
Trained batch 632 in epoch 0, gen_loss = 1.390402036914705, disc_loss = 0.02458467582199505
Trained batch 633 in epoch 0, gen_loss = 1.3899708144860312, disc_loss = 0.02454820005476551
Trained batch 634 in epoch 0, gen_loss = 1.3896779936129653, disc_loss = 0.024513057848313955
Trained batch 635 in epoch 0, gen_loss = 1.3897275203991237, disc_loss = 0.024477327820360252
Trained batch 636 in epoch 0, gen_loss = 1.3894967816688202, disc_loss = 0.02444271144535381
Trained batch 637 in epoch 0, gen_loss = 1.3894291821878906, disc_loss = 0.02440688160808646
Trained batch 638 in epoch 0, gen_loss = 1.38918189011829, disc_loss = 0.024379207425443267
Trained batch 639 in epoch 0, gen_loss = 1.3888143352232873, disc_loss = 0.024351827583450357
Trained batch 640 in epoch 0, gen_loss = 1.3886027257081686, disc_loss = 0.024319089593165286
Trained batch 641 in epoch 0, gen_loss = 1.3887418165942218, disc_loss = 0.024287848644150057
Trained batch 642 in epoch 0, gen_loss = 1.3885078612790323, disc_loss = 0.024260285627647284
Trained batch 643 in epoch 0, gen_loss = 1.3881712351341424, disc_loss = 0.0242266652155494
Trained batch 644 in epoch 0, gen_loss = 1.3879487999649935, disc_loss = 0.024191977550788214
Trained batch 645 in epoch 0, gen_loss = 1.3877543390904419, disc_loss = 0.024157497213162977
Trained batch 646 in epoch 0, gen_loss = 1.3881680411754473, disc_loss = 0.024123130702137244
Trained batch 647 in epoch 0, gen_loss = 1.3884131775042157, disc_loss = 0.02408829366376503
Trained batch 648 in epoch 0, gen_loss = 1.388712208792682, disc_loss = 0.024054011883026128
Trained batch 649 in epoch 0, gen_loss = 1.3890786932981931, disc_loss = 0.024020386141402502
Trained batch 650 in epoch 0, gen_loss = 1.3888298618262447, disc_loss = 0.023987647127567544
Trained batch 651 in epoch 0, gen_loss = 1.388624994209939, disc_loss = 0.02395423841816259
Trained batch 652 in epoch 0, gen_loss = 1.388381025783866, disc_loss = 0.02392249911325409
Trained batch 653 in epoch 0, gen_loss = 1.3880319156960246, disc_loss = 0.02388983930298056
Trained batch 654 in epoch 0, gen_loss = 1.3879316922362523, disc_loss = 0.023856255854302236
Trained batch 655 in epoch 0, gen_loss = 1.3878310937888738, disc_loss = 0.023822520502840124
Trained batch 656 in epoch 0, gen_loss = 1.38751679296, disc_loss = 0.023789665761688665
Trained batch 657 in epoch 0, gen_loss = 1.3873608147663186, disc_loss = 0.023756598301110137
Trained batch 658 in epoch 0, gen_loss = 1.3872006083294546, disc_loss = 0.023723079477421295
Trained batch 659 in epoch 0, gen_loss = 1.3870959176258608, disc_loss = 0.02368867492345585
Trained batch 660 in epoch 0, gen_loss = 1.3868120343349706, disc_loss = 0.023669714155309635
Trained batch 661 in epoch 0, gen_loss = 1.386631758821695, disc_loss = 0.023643519355862026
Trained batch 662 in epoch 0, gen_loss = 1.3863355896771403, disc_loss = 0.023613690743840905
Trained batch 663 in epoch 0, gen_loss = 1.3861572095249073, disc_loss = 0.023582203881057674
Trained batch 664 in epoch 0, gen_loss = 1.3858025675429437, disc_loss = 0.023549024156413804
Trained batch 665 in epoch 0, gen_loss = 1.3855832889452353, disc_loss = 0.023518317788783404
Trained batch 666 in epoch 0, gen_loss = 1.3852088332533659, disc_loss = 0.023488942375253032
Trained batch 667 in epoch 0, gen_loss = 1.3848955669624363, disc_loss = 0.02345717053206548
Trained batch 668 in epoch 0, gen_loss = 1.3845365930387614, disc_loss = 0.023424752320925828
Trained batch 669 in epoch 0, gen_loss = 1.3843303743583053, disc_loss = 0.023393126967217105
Trained batch 670 in epoch 0, gen_loss = 1.383967422604028, disc_loss = 0.023360325007743845
Trained batch 671 in epoch 0, gen_loss = 1.3836712681998808, disc_loss = 0.02332807016881859
Trained batch 672 in epoch 0, gen_loss = 1.3844645488315317, disc_loss = 0.02329800762706623
Trained batch 673 in epoch 0, gen_loss = 1.3842922432309441, disc_loss = 0.02326811803401191
Trained batch 674 in epoch 0, gen_loss = 1.3840077125584638, disc_loss = 0.023238438804875368
Trained batch 675 in epoch 0, gen_loss = 1.3836477872358977, disc_loss = 0.023208957253652213
Trained batch 676 in epoch 0, gen_loss = 1.383247982011764, disc_loss = 0.023178670621040984
Trained batch 677 in epoch 0, gen_loss = 1.3827794659278385, disc_loss = 0.023146920660950223
Trained batch 678 in epoch 0, gen_loss = 1.3827439624711937, disc_loss = 0.023114867462462503
Trained batch 679 in epoch 0, gen_loss = 1.3824727983159177, disc_loss = 0.023083230915397185
Trained batch 680 in epoch 0, gen_loss = 1.3826667788970488, disc_loss = 0.02305130055858022
Trained batch 681 in epoch 0, gen_loss = 1.3822839136871774, disc_loss = 0.023020338352265714
Trained batch 682 in epoch 0, gen_loss = 1.3827165655824485, disc_loss = 0.022991162879388415
Trained batch 683 in epoch 0, gen_loss = 1.3825980068473092, disc_loss = 0.022959721333902786
Trained batch 684 in epoch 0, gen_loss = 1.3825126260736562, disc_loss = 0.022931815297036928
Trained batch 685 in epoch 0, gen_loss = 1.3823869029391265, disc_loss = 0.022903106222200716
Trained batch 686 in epoch 0, gen_loss = 1.382196234042988, disc_loss = 0.022873568543798278
Trained batch 687 in epoch 0, gen_loss = 1.3820561563033005, disc_loss = 0.02284226406414365
Trained batch 688 in epoch 0, gen_loss = 1.3816542626292336, disc_loss = 0.022813594603373066
Trained batch 689 in epoch 0, gen_loss = 1.3814576820186946, disc_loss = 0.022783580703822814
Trained batch 690 in epoch 0, gen_loss = 1.3813760464339802, disc_loss = 0.02275269161492004
Trained batch 691 in epoch 0, gen_loss = 1.3813110694203075, disc_loss = 0.02272244539876291
Trained batch 692 in epoch 0, gen_loss = 1.3812443061824484, disc_loss = 0.022693063352864456
Trained batch 693 in epoch 0, gen_loss = 1.381236774863015, disc_loss = 0.02266484815681015
Trained batch 694 in epoch 0, gen_loss = 1.3808724433398076, disc_loss = 0.02263498384984572
Trained batch 695 in epoch 0, gen_loss = 1.380874222636908, disc_loss = 0.022605606154558762
Trained batch 696 in epoch 0, gen_loss = 1.3810211266985584, disc_loss = 0.022576697117453935
Trained batch 697 in epoch 0, gen_loss = 1.3811247862000178, disc_loss = 0.022548451952477462
Trained batch 698 in epoch 0, gen_loss = 1.3808330242043743, disc_loss = 0.022523668018577404
Trained batch 699 in epoch 0, gen_loss = 1.3806760858637945, disc_loss = 0.02249454469702739
Trained batch 700 in epoch 0, gen_loss = 1.3804363553942356, disc_loss = 0.02246517280432875
Trained batch 701 in epoch 0, gen_loss = 1.3801694394346655, disc_loss = 0.022438294449263912
Trained batch 702 in epoch 0, gen_loss = 1.3799927121884115, disc_loss = 0.022411550507134895
Trained batch 703 in epoch 0, gen_loss = 1.3804341230372137, disc_loss = 0.022383234472892418
Trained batch 704 in epoch 0, gen_loss = 1.3803606997990439, disc_loss = 0.02235457350083805
Trained batch 705 in epoch 0, gen_loss = 1.3802728111784452, disc_loss = 0.02232451157142453
Trained batch 706 in epoch 0, gen_loss = 1.3803645154037099, disc_loss = 0.022295615386021556
Trained batch 707 in epoch 0, gen_loss = 1.3801891861830728, disc_loss = 0.022266218658585343
Trained batch 708 in epoch 0, gen_loss = 1.380112892902116, disc_loss = 0.022237195179841057
Trained batch 709 in epoch 0, gen_loss = 1.3799235566401147, disc_loss = 0.02220916897615969
Trained batch 710 in epoch 0, gen_loss = 1.3796235479718355, disc_loss = 0.022183807211457823
Trained batch 711 in epoch 0, gen_loss = 1.3795550769467033, disc_loss = 0.022158844867038403
Trained batch 712 in epoch 0, gen_loss = 1.3792666209362667, disc_loss = 0.02212984622736967
Trained batch 713 in epoch 0, gen_loss = 1.3791574921761574, disc_loss = 0.022101474453366417
Trained batch 714 in epoch 0, gen_loss = 1.3790132986915695, disc_loss = 0.022072937487057978
Trained batch 715 in epoch 0, gen_loss = 1.3789511125680454, disc_loss = 0.022043779569121295
Trained batch 716 in epoch 0, gen_loss = 1.378587509714576, disc_loss = 0.022014778706529587
Trained batch 717 in epoch 0, gen_loss = 1.3786064872004526, disc_loss = 0.021986572965129972
Trained batch 718 in epoch 0, gen_loss = 1.378400391182747, disc_loss = 0.02195770427586591
Trained batch 719 in epoch 0, gen_loss = 1.3781182872752349, disc_loss = 0.02193064777028566
Trained batch 720 in epoch 0, gen_loss = 1.377658029121764, disc_loss = 0.021902039989082456
Trained batch 721 in epoch 0, gen_loss = 1.3772336775411198, disc_loss = 0.021873610884104687
Trained batch 722 in epoch 0, gen_loss = 1.3771730226929586, disc_loss = 0.021846934017676338
Trained batch 723 in epoch 0, gen_loss = 1.3768103971501082, disc_loss = 0.021822825727826088
Trained batch 724 in epoch 0, gen_loss = 1.3765079356062002, disc_loss = 0.0217950933714044
Trained batch 725 in epoch 0, gen_loss = 1.3762499713864864, disc_loss = 0.021768229488076864
Trained batch 726 in epoch 0, gen_loss = 1.3762372562449112, disc_loss = 0.021743574464261953
Trained batch 727 in epoch 0, gen_loss = 1.3760947456562913, disc_loss = 0.021715893606197315
Trained batch 728 in epoch 0, gen_loss = 1.3757016245883842, disc_loss = 0.021688829990236705
Trained batch 729 in epoch 0, gen_loss = 1.376265093969972, disc_loss = 0.0216628517473933
Trained batch 730 in epoch 0, gen_loss = 1.375998033136741, disc_loss = 0.021636137583709632
Trained batch 731 in epoch 0, gen_loss = 1.3760610912504092, disc_loss = 0.021609744108587382
Trained batch 732 in epoch 0, gen_loss = 1.3758062834141198, disc_loss = 0.021582123705301572
Trained batch 733 in epoch 0, gen_loss = 1.3756119021765219, disc_loss = 0.02155477101806734
Trained batch 734 in epoch 0, gen_loss = 1.3754343229897168, disc_loss = 0.021527421989376804
Trained batch 735 in epoch 0, gen_loss = 1.3756402726892545, disc_loss = 0.021500581035386702
Trained batch 736 in epoch 0, gen_loss = 1.3753839693205328, disc_loss = 0.021473358511157697
Trained batch 737 in epoch 0, gen_loss = 1.3750916679861747, disc_loss = 0.02144570701404129
Trained batch 738 in epoch 0, gen_loss = 1.3748224042103965, disc_loss = 0.02141877218336749
Trained batch 739 in epoch 0, gen_loss = 1.3746859196875547, disc_loss = 0.021392000578910213
Trained batch 740 in epoch 0, gen_loss = 1.3749727167581256, disc_loss = 0.021365728189536547
Trained batch 741 in epoch 0, gen_loss = 1.3748739810806079, disc_loss = 0.02133990786677839
Trained batch 742 in epoch 0, gen_loss = 1.3747884804435566, disc_loss = 0.021313646922018353
Trained batch 743 in epoch 0, gen_loss = 1.374768789176659, disc_loss = 0.021287069335186815
Trained batch 744 in epoch 0, gen_loss = 1.3748513246542655, disc_loss = 0.021259935817762508
Trained batch 745 in epoch 0, gen_loss = 1.3746460234351836, disc_loss = 0.02123329578087373
Trained batch 746 in epoch 0, gen_loss = 1.3744202299290393, disc_loss = 0.021206301242397373
Trained batch 747 in epoch 0, gen_loss = 1.3741717049304176, disc_loss = 0.021179645927373897
Trained batch 748 in epoch 0, gen_loss = 1.3740673629400408, disc_loss = 0.021154288654507837
Trained batch 749 in epoch 0, gen_loss = 1.3743845326900481, disc_loss = 0.02112849062308669
Trained batch 750 in epoch 0, gen_loss = 1.3741679547947352, disc_loss = 0.02110191209107816
Trained batch 751 in epoch 0, gen_loss = 1.37406202080719, disc_loss = 0.021077131895544107
Trained batch 752 in epoch 0, gen_loss = 1.3744020193696498, disc_loss = 0.02105234537161095
Trained batch 753 in epoch 0, gen_loss = 1.3742026413941573, disc_loss = 0.021026434474414712
Trained batch 754 in epoch 0, gen_loss = 1.3739398778669092, disc_loss = 0.021001182576111017
Trained batch 755 in epoch 0, gen_loss = 1.3737216591046602, disc_loss = 0.020974971334913144
Trained batch 756 in epoch 0, gen_loss = 1.373580984190559, disc_loss = 0.02094962602112777
Trained batch 757 in epoch 0, gen_loss = 1.3737182058099078, disc_loss = 0.020923552253697617
Trained batch 758 in epoch 0, gen_loss = 1.3734465788004426, disc_loss = 0.02089787991159155
Trained batch 759 in epoch 0, gen_loss = 1.3732618597777266, disc_loss = 0.02087325587482682
Trained batch 760 in epoch 0, gen_loss = 1.3729525889892928, disc_loss = 0.020848805938128986
Trained batch 761 in epoch 0, gen_loss = 1.3726267172439204, disc_loss = 0.02082350383466232
Trained batch 762 in epoch 0, gen_loss = 1.3728579430405152, disc_loss = 0.02079787833047335
Trained batch 763 in epoch 0, gen_loss = 1.3727145988435645, disc_loss = 0.02077246682245421
Trained batch 764 in epoch 0, gen_loss = 1.3728948651575574, disc_loss = 0.02074975219549112
Trained batch 765 in epoch 0, gen_loss = 1.3730503705867587, disc_loss = 0.020726295507527578
Trained batch 766 in epoch 0, gen_loss = 1.3728962876339779, disc_loss = 0.020701868061614958
Trained batch 767 in epoch 0, gen_loss = 1.3727221919689327, disc_loss = 0.0206774793726557
Trained batch 768 in epoch 0, gen_loss = 1.3726150315976733, disc_loss = 0.020651912588870783
Trained batch 769 in epoch 0, gen_loss = 1.3723497600524457, disc_loss = 0.020627470115235972
Trained batch 770 in epoch 0, gen_loss = 1.3722892153123938, disc_loss = 0.020602081708752596
Trained batch 771 in epoch 0, gen_loss = 1.3722055777521331, disc_loss = 0.020579249095630112
Trained batch 772 in epoch 0, gen_loss = 1.372024908488349, disc_loss = 0.020555135399105574
Trained batch 773 in epoch 0, gen_loss = 1.372033321503213, disc_loss = 0.02053301661902225
Trained batch 774 in epoch 0, gen_loss = 1.372188997037949, disc_loss = 0.020511663121381595
Trained batch 775 in epoch 0, gen_loss = 1.3719555104977077, disc_loss = 0.020487609883763146
Trained batch 776 in epoch 0, gen_loss = 1.3718138231273784, disc_loss = 0.020463639818745615
Trained batch 777 in epoch 0, gen_loss = 1.3716341188910075, disc_loss = 0.020440648762379943
Trained batch 778 in epoch 0, gen_loss = 1.37125539404743, disc_loss = 0.020424783416331502
Trained batch 779 in epoch 0, gen_loss = 1.3715997823537924, disc_loss = 0.020407208006303662
Trained batch 780 in epoch 0, gen_loss = 1.3714886641990818, disc_loss = 0.020388044970212613
Trained batch 781 in epoch 0, gen_loss = 1.3711903582296103, disc_loss = 0.020365012350225406
Trained batch 782 in epoch 0, gen_loss = 1.3710482460785642, disc_loss = 0.020342037838492377
Trained batch 783 in epoch 0, gen_loss = 1.3707714107419764, disc_loss = 0.020320173252281276
Trained batch 784 in epoch 0, gen_loss = 1.370727194722291, disc_loss = 0.020296188084717105
Trained batch 785 in epoch 0, gen_loss = 1.3705712301282178, disc_loss = 0.02027262239459234
Trained batch 786 in epoch 0, gen_loss = 1.370463420884279, disc_loss = 0.020250625319493724
Trained batch 787 in epoch 0, gen_loss = 1.370180710545046, disc_loss = 0.020229291197575563
Trained batch 788 in epoch 0, gen_loss = 1.3701532626635524, disc_loss = 0.02020631184938974
Trained batch 789 in epoch 0, gen_loss = 1.3699092610727384, disc_loss = 0.020182312608555054
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 1.1110918521881104, disc_loss = 0.0013542169472202659
Trained batch 1 in epoch 1, gen_loss = 1.2281975746154785, disc_loss = 0.0015461730072274804
Trained batch 2 in epoch 1, gen_loss = 1.2512660026550293, disc_loss = 0.0015229436103254557
Trained batch 3 in epoch 1, gen_loss = 1.3072124123573303, disc_loss = 0.0016778151039034128
Trained batch 4 in epoch 1, gen_loss = 1.2734898328781128, disc_loss = 0.0018985685892403126
Trained batch 5 in epoch 1, gen_loss = 1.2868898510932922, disc_loss = 0.0018801303619208436
Trained batch 6 in epoch 1, gen_loss = 1.2780887569699968, disc_loss = 0.001813008782586881
Trained batch 7 in epoch 1, gen_loss = 1.2687039822340012, disc_loss = 0.0017157406255137175
Trained batch 8 in epoch 1, gen_loss = 1.2573706706364949, disc_loss = 0.001722428637246291
Trained batch 9 in epoch 1, gen_loss = 1.24904922246933, disc_loss = 0.0016467754961922766
Trained batch 10 in epoch 1, gen_loss = 1.2472946535457263, disc_loss = 0.0016130323056131601
Trained batch 11 in epoch 1, gen_loss = 1.2564693788687389, disc_loss = 0.001581057518099745
Trained batch 12 in epoch 1, gen_loss = 1.2614681262236376, disc_loss = 0.0015242969473967184
Trained batch 13 in epoch 1, gen_loss = 1.2716536947659083, disc_loss = 0.001556696037628821
Trained batch 14 in epoch 1, gen_loss = 1.28431077003479, disc_loss = 0.0016394361077497403
Trained batch 15 in epoch 1, gen_loss = 1.293315276503563, disc_loss = 0.0016178873338503763
Trained batch 16 in epoch 1, gen_loss = 1.2860860684338737, disc_loss = 0.0015916043125531252
Trained batch 17 in epoch 1, gen_loss = 1.2814351121584575, disc_loss = 0.0015686039631772372
Trained batch 18 in epoch 1, gen_loss = 1.2740753575375205, disc_loss = 0.0015335624339058995
Trained batch 19 in epoch 1, gen_loss = 1.2765175521373748, disc_loss = 0.0015325731656048447
Trained batch 20 in epoch 1, gen_loss = 1.2746408155986242, disc_loss = 0.001513404666357452
Trained batch 21 in epoch 1, gen_loss = 1.276534844528545, disc_loss = 0.001483723658814349
Trained batch 22 in epoch 1, gen_loss = 1.2733567538468733, disc_loss = 0.0014738005170922565
Trained batch 23 in epoch 1, gen_loss = 1.2689986775318782, disc_loss = 0.001466781264753081
Trained batch 24 in epoch 1, gen_loss = 1.2659005260467528, disc_loss = 0.0014515945687890053
Trained batch 25 in epoch 1, gen_loss = 1.2598491448622484, disc_loss = 0.001459100292637371
Trained batch 26 in epoch 1, gen_loss = 1.2648576895395915, disc_loss = 0.001464478386979964
Trained batch 27 in epoch 1, gen_loss = 1.2639137761933463, disc_loss = 0.0014507326413877308
Trained batch 28 in epoch 1, gen_loss = 1.262667442190236, disc_loss = 0.0014401912801609985
Trained batch 29 in epoch 1, gen_loss = 1.2628282944361369, disc_loss = 0.0014579126068080465
Trained batch 30 in epoch 1, gen_loss = 1.263123216167573, disc_loss = 0.00149891214565404
Trained batch 31 in epoch 1, gen_loss = 1.2605021446943283, disc_loss = 0.0015298405778594315
Trained batch 32 in epoch 1, gen_loss = 1.2597307219649807, disc_loss = 0.0015780132715449188
Trained batch 33 in epoch 1, gen_loss = 1.2608458960757536, disc_loss = 0.001617759356603903
Trained batch 34 in epoch 1, gen_loss = 1.2567201716559273, disc_loss = 0.0016236781641574842
Trained batch 35 in epoch 1, gen_loss = 1.2547215289539762, disc_loss = 0.00163697656050014
Trained batch 36 in epoch 1, gen_loss = 1.2514858632474333, disc_loss = 0.0016887950289340035
Trained batch 37 in epoch 1, gen_loss = 1.2558962859605487, disc_loss = 0.0016953134694822917
Trained batch 38 in epoch 1, gen_loss = 1.255044148518489, disc_loss = 0.0016991171227672543
Trained batch 39 in epoch 1, gen_loss = 1.2535935521125794, disc_loss = 0.0017020315601257608
Trained batch 40 in epoch 1, gen_loss = 1.2507213673940518, disc_loss = 0.0016911733162975528
Trained batch 41 in epoch 1, gen_loss = 1.2461813631511869, disc_loss = 0.0017408407709029103
Trained batch 42 in epoch 1, gen_loss = 1.245245661846427, disc_loss = 0.0017824442705226152
Trained batch 43 in epoch 1, gen_loss = 1.2444368492473254, disc_loss = 0.0017985078659628264
Trained batch 44 in epoch 1, gen_loss = 1.249899615181817, disc_loss = 0.0017928787507116794
Trained batch 45 in epoch 1, gen_loss = 1.252252169277357, disc_loss = 0.0017851720837390294
Trained batch 46 in epoch 1, gen_loss = 1.252178395048101, disc_loss = 0.001801178389367588
Trained batch 47 in epoch 1, gen_loss = 1.2556776305039723, disc_loss = 0.001835257833590731
Trained batch 48 in epoch 1, gen_loss = 1.2579812079059833, disc_loss = 0.0018457481780146457
Trained batch 49 in epoch 1, gen_loss = 1.2548452019691467, disc_loss = 0.0018426667526364327
Trained batch 50 in epoch 1, gen_loss = 1.259386796577304, disc_loss = 0.0018385860694608853
Trained batch 51 in epoch 1, gen_loss = 1.2614402037400465, disc_loss = 0.001839900474386433
Trained batch 52 in epoch 1, gen_loss = 1.2619214035430044, disc_loss = 0.0018391374428317231
Trained batch 53 in epoch 1, gen_loss = 1.259287542766995, disc_loss = 0.0018404856371624326
Trained batch 54 in epoch 1, gen_loss = 1.2589014291763305, disc_loss = 0.0018666245699436826
Trained batch 55 in epoch 1, gen_loss = 1.2559215447732381, disc_loss = 0.0018762250027586041
Trained batch 56 in epoch 1, gen_loss = 1.2546666337732684, disc_loss = 0.001877104532659838
Trained batch 57 in epoch 1, gen_loss = 1.255401664766772, disc_loss = 0.0018662529202691954
Trained batch 58 in epoch 1, gen_loss = 1.254275237099599, disc_loss = 0.0018501088350727144
Trained batch 59 in epoch 1, gen_loss = 1.2541308224201202, disc_loss = 0.001842095572889472
Trained batch 60 in epoch 1, gen_loss = 1.2577718515865137, disc_loss = 0.001841037200198921
Trained batch 61 in epoch 1, gen_loss = 1.2577981025941911, disc_loss = 0.001836098862000771
Trained batch 62 in epoch 1, gen_loss = 1.2573264931875563, disc_loss = 0.001822387782065937
Trained batch 63 in epoch 1, gen_loss = 1.2596685886383057, disc_loss = 0.0018063188190353685
Trained batch 64 in epoch 1, gen_loss = 1.2585912447709304, disc_loss = 0.0017948036861176102
Trained batch 65 in epoch 1, gen_loss = 1.2578461874615063, disc_loss = 0.0017811375851813477
Trained batch 66 in epoch 1, gen_loss = 1.2569985460879198, disc_loss = 0.001768013906366289
Trained batch 67 in epoch 1, gen_loss = 1.259557364618077, disc_loss = 0.0017592553588602802
Trained batch 68 in epoch 1, gen_loss = 1.2582277508749478, disc_loss = 0.0017508467856754103
Trained batch 69 in epoch 1, gen_loss = 1.2561196310179574, disc_loss = 0.0017465204624126532
Trained batch 70 in epoch 1, gen_loss = 1.258404211259224, disc_loss = 0.0017362096155075434
Trained batch 71 in epoch 1, gen_loss = 1.2559418148464627, disc_loss = 0.0017295663443898472
Trained batch 72 in epoch 1, gen_loss = 1.2564771485655275, disc_loss = 0.0017369125598135774
Trained batch 73 in epoch 1, gen_loss = 1.2582911430178463, disc_loss = 0.0017348965716460166
Trained batch 74 in epoch 1, gen_loss = 1.2584830649693808, disc_loss = 0.0017246303559901813
Trained batch 75 in epoch 1, gen_loss = 1.2570112347602844, disc_loss = 0.0017224754854779395
Trained batch 76 in epoch 1, gen_loss = 1.259631924814992, disc_loss = 0.0017157536046881858
Trained batch 77 in epoch 1, gen_loss = 1.2596651835319324, disc_loss = 0.0017039289001005297
Trained batch 78 in epoch 1, gen_loss = 1.2577324969859063, disc_loss = 0.0016971115513610407
Trained batch 79 in epoch 1, gen_loss = 1.2557367756962776, disc_loss = 0.0016927961194596719
Trained batch 80 in epoch 1, gen_loss = 1.2570504273897336, disc_loss = 0.0016881317916372215
Trained batch 81 in epoch 1, gen_loss = 1.258217248974777, disc_loss = 0.0016785058350495359
Trained batch 82 in epoch 1, gen_loss = 1.2567848196948868, disc_loss = 0.0016682421590807478
Trained batch 83 in epoch 1, gen_loss = 1.2589695382685888, disc_loss = 0.001661363050169755
Trained batch 84 in epoch 1, gen_loss = 1.2592104813631844, disc_loss = 0.0016644173062077777
Trained batch 85 in epoch 1, gen_loss = 1.2627813829932102, disc_loss = 0.0016574172748436847
Trained batch 86 in epoch 1, gen_loss = 1.2612247192996673, disc_loss = 0.0016500679193995893
Trained batch 87 in epoch 1, gen_loss = 1.2602770789103075, disc_loss = 0.0016665035727783106
Trained batch 88 in epoch 1, gen_loss = 1.2606672329849071, disc_loss = 0.0016698734213472502
Trained batch 89 in epoch 1, gen_loss = 1.2605098207791647, disc_loss = 0.001665837571878607
Trained batch 90 in epoch 1, gen_loss = 1.258594193301358, disc_loss = 0.0016730281704739965
Trained batch 91 in epoch 1, gen_loss = 1.2570791840553284, disc_loss = 0.0016755865913380505
Trained batch 92 in epoch 1, gen_loss = 1.255859878755385, disc_loss = 0.0016766700208918142
Trained batch 93 in epoch 1, gen_loss = 1.2578911388174017, disc_loss = 0.0016804992950749287
Trained batch 94 in epoch 1, gen_loss = 1.257742913145768, disc_loss = 0.0016848616651259363
Trained batch 95 in epoch 1, gen_loss = 1.2577648498117924, disc_loss = 0.001676492820479325
Trained batch 96 in epoch 1, gen_loss = 1.2579643247053796, disc_loss = 0.0016776588175340182
Trained batch 97 in epoch 1, gen_loss = 1.2567072826988843, disc_loss = 0.0016844971372736428
Trained batch 98 in epoch 1, gen_loss = 1.255357700164872, disc_loss = 0.0016785632622559942
Trained batch 99 in epoch 1, gen_loss = 1.2548072469234466, disc_loss = 0.0016704299859702587
Trained batch 100 in epoch 1, gen_loss = 1.2567271702360399, disc_loss = 0.001664669877655878
Trained batch 101 in epoch 1, gen_loss = 1.2586225914020164, disc_loss = 0.0016643815450187698
Trained batch 102 in epoch 1, gen_loss = 1.2573673620964716, disc_loss = 0.0016650620529211116
Trained batch 103 in epoch 1, gen_loss = 1.2592648485532174, disc_loss = 0.001664280796271319
Trained batch 104 in epoch 1, gen_loss = 1.261398296129136, disc_loss = 0.0016574870273914366
Trained batch 105 in epoch 1, gen_loss = 1.259951576871692, disc_loss = 0.0016521504357509878
Trained batch 106 in epoch 1, gen_loss = 1.2580049271895506, disc_loss = 0.0016476473636124456
Trained batch 107 in epoch 1, gen_loss = 1.2569750823356487, disc_loss = 0.0016539403090805368
Trained batch 108 in epoch 1, gen_loss = 1.2558588052014692, disc_loss = 0.0016575080957776363
Trained batch 109 in epoch 1, gen_loss = 1.2568568045442754, disc_loss = 0.0016517934093082493
Trained batch 110 in epoch 1, gen_loss = 1.257924189438691, disc_loss = 0.0016467289491514632
Trained batch 111 in epoch 1, gen_loss = 1.2564776071480341, disc_loss = 0.0019488510754724433
Trained batch 112 in epoch 1, gen_loss = 1.2545880564546164, disc_loss = 0.0024780234614535505
Trained batch 113 in epoch 1, gen_loss = 1.2542577009452016, disc_loss = 0.0025329606979268425
Trained batch 114 in epoch 1, gen_loss = 1.2550126293431159, disc_loss = 0.0026649026260913713
Trained batch 115 in epoch 1, gen_loss = 1.2546185347540626, disc_loss = 0.0030219011663073867
Trained batch 116 in epoch 1, gen_loss = 1.2575371978629348, disc_loss = 0.00392798635049954
Trained batch 117 in epoch 1, gen_loss = 1.2575952835002189, disc_loss = 0.004685402814283083
Trained batch 118 in epoch 1, gen_loss = 1.2568314786718673, disc_loss = 0.004832892199320828
Trained batch 119 in epoch 1, gen_loss = 1.2579890837272008, disc_loss = 0.005085495360738908
Trained batch 120 in epoch 1, gen_loss = 1.257885297467886, disc_loss = 0.00526062802273072
Trained batch 121 in epoch 1, gen_loss = 1.2561501020290813, disc_loss = 0.005323422322675708
Trained batch 122 in epoch 1, gen_loss = 1.2550912901638, disc_loss = 0.005447776683386627
Trained batch 123 in epoch 1, gen_loss = 1.2548651166500584, disc_loss = 0.0054783479051454175
Trained batch 124 in epoch 1, gen_loss = 1.253770562171936, disc_loss = 0.005494019826874137
Trained batch 125 in epoch 1, gen_loss = 1.2553581425121851, disc_loss = 0.005479104852022987
Trained batch 126 in epoch 1, gen_loss = 1.2548799336425902, disc_loss = 0.005462145724326489
Trained batch 127 in epoch 1, gen_loss = 1.2548531852662563, disc_loss = 0.00543969788668619
Trained batch 128 in epoch 1, gen_loss = 1.254044489343037, disc_loss = 0.005419013613849416
Trained batch 129 in epoch 1, gen_loss = 1.253565985422868, disc_loss = 0.005392136317319595
Trained batch 130 in epoch 1, gen_loss = 1.2531057541606991, disc_loss = 0.005371833971936171
Trained batch 131 in epoch 1, gen_loss = 1.2530399786703514, disc_loss = 0.005346659876081641
Trained batch 132 in epoch 1, gen_loss = 1.2538295177588785, disc_loss = 0.005333323322264548
Trained batch 133 in epoch 1, gen_loss = 1.255565361300511, disc_loss = 0.00531174741171078
Trained batch 134 in epoch 1, gen_loss = 1.2556031165299593, disc_loss = 0.0052929316250676355
Trained batch 135 in epoch 1, gen_loss = 1.2551662843017017, disc_loss = 0.005276995421702261
Trained batch 136 in epoch 1, gen_loss = 1.2566137339946997, disc_loss = 0.005253977631728579
Trained batch 137 in epoch 1, gen_loss = 1.2561761158100073, disc_loss = 0.005234740728485412
Trained batch 138 in epoch 1, gen_loss = 1.2575384884429492, disc_loss = 0.0052125557432982994
Trained batch 139 in epoch 1, gen_loss = 1.2575819049562726, disc_loss = 0.0051883189015955265
Trained batch 140 in epoch 1, gen_loss = 1.2570999260489821, disc_loss = 0.005179034436207449
Trained batch 141 in epoch 1, gen_loss = 1.2568461928569095, disc_loss = 0.005165276838250091
Trained batch 142 in epoch 1, gen_loss = 1.2568174767327476, disc_loss = 0.00514065672096412
Trained batch 143 in epoch 1, gen_loss = 1.2570847703350916, disc_loss = 0.005123673761974917
Trained batch 144 in epoch 1, gen_loss = 1.2586389015460837, disc_loss = 0.00509689413171647
Trained batch 145 in epoch 1, gen_loss = 1.2595139603092247, disc_loss = 0.005078039851282047
Trained batch 146 in epoch 1, gen_loss = 1.259854321577111, disc_loss = 0.005053893187824561
Trained batch 147 in epoch 1, gen_loss = 1.2603452366751593, disc_loss = 0.005037248103149436
Trained batch 148 in epoch 1, gen_loss = 1.2604027018451052, disc_loss = 0.005011645652003736
Trained batch 149 in epoch 1, gen_loss = 1.262933582464854, disc_loss = 0.004992775636104246
Trained batch 150 in epoch 1, gen_loss = 1.2627087136767559, disc_loss = 0.004971136373702116
Trained batch 151 in epoch 1, gen_loss = 1.2634035795927048, disc_loss = 0.00496317409852054
Trained batch 152 in epoch 1, gen_loss = 1.263303594651565, disc_loss = 0.004938742254702435
Trained batch 153 in epoch 1, gen_loss = 1.2626933664470523, disc_loss = 0.0049250108369795435
Trained batch 154 in epoch 1, gen_loss = 1.2638178802305653, disc_loss = 0.004919485065094646
Trained batch 155 in epoch 1, gen_loss = 1.2631073662867913, disc_loss = 0.004903241788269952
Trained batch 156 in epoch 1, gen_loss = 1.2630199482486506, disc_loss = 0.004893924755483249
Trained batch 157 in epoch 1, gen_loss = 1.2625308874287182, disc_loss = 0.004878559972813848
Trained batch 158 in epoch 1, gen_loss = 1.2614459811516527, disc_loss = 0.004860588726470446
Trained batch 159 in epoch 1, gen_loss = 1.2605139397084713, disc_loss = 0.0048842348238395065
Trained batch 160 in epoch 1, gen_loss = 1.259422371106118, disc_loss = 0.00487689552785285
Trained batch 161 in epoch 1, gen_loss = 1.2612704708252425, disc_loss = 0.004856052176802661
Trained batch 162 in epoch 1, gen_loss = 1.2610655788995007, disc_loss = 0.004853279102005156
Trained batch 163 in epoch 1, gen_loss = 1.2614097522526253, disc_loss = 0.004833133125297226
Trained batch 164 in epoch 1, gen_loss = 1.2617594003677368, disc_loss = 0.004822662813504311
Trained batch 165 in epoch 1, gen_loss = 1.2618277690496789, disc_loss = 0.004811430642386921
Trained batch 166 in epoch 1, gen_loss = 1.2613855479006282, disc_loss = 0.004812676708414749
Trained batch 167 in epoch 1, gen_loss = 1.261143717027846, disc_loss = 0.004813523121161519
Trained batch 168 in epoch 1, gen_loss = 1.2606421617361216, disc_loss = 0.004798896605914911
Trained batch 169 in epoch 1, gen_loss = 1.261252638872932, disc_loss = 0.004778736034709522
Trained batch 170 in epoch 1, gen_loss = 1.2612476195508278, disc_loss = 0.004757471926570243
Trained batch 171 in epoch 1, gen_loss = 1.2615304845710134, disc_loss = 0.0047454453028770984
Trained batch 172 in epoch 1, gen_loss = 1.262115150517811, disc_loss = 0.0047280355168215805
Trained batch 173 in epoch 1, gen_loss = 1.2621202921045238, disc_loss = 0.0047108210187041385
Trained batch 174 in epoch 1, gen_loss = 1.2613311113630021, disc_loss = 0.004689316359415118
Trained batch 175 in epoch 1, gen_loss = 1.2607042660767382, disc_loss = 0.004669963197309037
Trained batch 176 in epoch 1, gen_loss = 1.2598669885915552, disc_loss = 0.004649276987552159
Trained batch 177 in epoch 1, gen_loss = 1.2614695510167755, disc_loss = 0.00463028360332174
Trained batch 178 in epoch 1, gen_loss = 1.2612393075527426, disc_loss = 0.004618285822502582
Trained batch 179 in epoch 1, gen_loss = 1.2618375129169888, disc_loss = 0.004600836897669877
Trained batch 180 in epoch 1, gen_loss = 1.2611555947783244, disc_loss = 0.004582766340260821
Trained batch 181 in epoch 1, gen_loss = 1.260890549355811, disc_loss = 0.004565980460348918
Trained batch 182 in epoch 1, gen_loss = 1.26017120040831, disc_loss = 0.004560159207283534
Trained batch 183 in epoch 1, gen_loss = 1.2594108620415563, disc_loss = 0.004547046074509601
Trained batch 184 in epoch 1, gen_loss = 1.25953489123164, disc_loss = 0.00453091878790056
Trained batch 185 in epoch 1, gen_loss = 1.2601543934114519, disc_loss = 0.00451872102829868
Trained batch 186 in epoch 1, gen_loss = 1.260100222526387, disc_loss = 0.004498386079816516
Trained batch 187 in epoch 1, gen_loss = 1.2593226451823052, disc_loss = 0.00448026038994864
Trained batch 188 in epoch 1, gen_loss = 1.2586633824797535, disc_loss = 0.004461800532043473
Trained batch 189 in epoch 1, gen_loss = 1.2584028614194769, disc_loss = 0.004442696034675464
Trained batch 190 in epoch 1, gen_loss = 1.2579565216733524, disc_loss = 0.004423962530243596
Trained batch 191 in epoch 1, gen_loss = 1.2568305600434542, disc_loss = 0.004405685641359014
Trained batch 192 in epoch 1, gen_loss = 1.2571549335291967, disc_loss = 0.0043880315796095744
Trained batch 193 in epoch 1, gen_loss = 1.2575521782501458, disc_loss = 0.004373495821953876
Trained batch 194 in epoch 1, gen_loss = 1.2570664448615831, disc_loss = 0.004356705463933162
Trained batch 195 in epoch 1, gen_loss = 1.256694278546742, disc_loss = 0.0043406249276405125
Trained batch 196 in epoch 1, gen_loss = 1.2558487871576687, disc_loss = 0.004322782645786777
Trained batch 197 in epoch 1, gen_loss = 1.2554861957376653, disc_loss = 0.00430523828753844
Trained batch 198 in epoch 1, gen_loss = 1.2551919371638465, disc_loss = 0.004287656628580568
Trained batch 199 in epoch 1, gen_loss = 1.2560965704917908, disc_loss = 0.004270680058689322
Trained batch 200 in epoch 1, gen_loss = 1.257196056309031, disc_loss = 0.00425487590127796
Trained batch 201 in epoch 1, gen_loss = 1.25761348422211, disc_loss = 0.004246699397560522
Trained batch 202 in epoch 1, gen_loss = 1.2571609877600458, disc_loss = 0.004235370426147424
Trained batch 203 in epoch 1, gen_loss = 1.2573870432143117, disc_loss = 0.0042256921967468684
Trained batch 204 in epoch 1, gen_loss = 1.2585366033926242, disc_loss = 0.004215991693242203
Trained batch 205 in epoch 1, gen_loss = 1.2585191900290331, disc_loss = 0.004199472649047803
Trained batch 206 in epoch 1, gen_loss = 1.261101400218724, disc_loss = 0.004183013003110292
Trained batch 207 in epoch 1, gen_loss = 1.2606638498031175, disc_loss = 0.004171149263129337
Trained batch 208 in epoch 1, gen_loss = 1.2607013460551724, disc_loss = 0.004156529418533695
Trained batch 209 in epoch 1, gen_loss = 1.2602810030891782, disc_loss = 0.004144660185834038
Trained batch 210 in epoch 1, gen_loss = 1.2601746518465016, disc_loss = 0.004129970765405586
Trained batch 211 in epoch 1, gen_loss = 1.2602471900436114, disc_loss = 0.004117325056763805
Trained batch 212 in epoch 1, gen_loss = 1.2596693083713872, disc_loss = 0.004102038084026514
Trained batch 213 in epoch 1, gen_loss = 1.2591835527776558, disc_loss = 0.0040925614118019
Trained batch 214 in epoch 1, gen_loss = 1.259829174086105, disc_loss = 0.004082914524126884
Trained batch 215 in epoch 1, gen_loss = 1.2600591006102386, disc_loss = 0.004073472427316355
Trained batch 216 in epoch 1, gen_loss = 1.26034332969771, disc_loss = 0.00406911637857213
Trained batch 217 in epoch 1, gen_loss = 1.2596643233517988, disc_loss = 0.004060884075743411
Trained batch 218 in epoch 1, gen_loss = 1.2599438826243083, disc_loss = 0.00404945674796746
Trained batch 219 in epoch 1, gen_loss = 1.259445616873828, disc_loss = 0.004043241958028044
Trained batch 220 in epoch 1, gen_loss = 1.2599505110563736, disc_loss = 0.004032330703921616
Trained batch 221 in epoch 1, gen_loss = 1.2590910824569497, disc_loss = 0.004019085229227638
Trained batch 222 in epoch 1, gen_loss = 1.2586911371470566, disc_loss = 0.004006988465506166
Trained batch 223 in epoch 1, gen_loss = 1.2581057649637972, disc_loss = 0.003995491355973562
Trained batch 224 in epoch 1, gen_loss = 1.258942239019606, disc_loss = 0.003981037250616484
Trained batch 225 in epoch 1, gen_loss = 1.2598029158811654, disc_loss = 0.003967467964363112
Trained batch 226 in epoch 1, gen_loss = 1.258907162145371, disc_loss = 0.003954506251501485
Trained batch 227 in epoch 1, gen_loss = 1.259715808588162, disc_loss = 0.003939980970595539
Trained batch 228 in epoch 1, gen_loss = 1.2603541393987998, disc_loss = 0.003926758209597238
Trained batch 229 in epoch 1, gen_loss = 1.2609991410504218, disc_loss = 0.003913913587988962
Trained batch 230 in epoch 1, gen_loss = 1.2605908262781251, disc_loss = 0.003900234964202477
Trained batch 231 in epoch 1, gen_loss = 1.2610630506071552, disc_loss = 0.00389911467686159
Trained batch 232 in epoch 1, gen_loss = 1.2612864541393494, disc_loss = 0.0038917567848243905
Trained batch 233 in epoch 1, gen_loss = 1.260837831048884, disc_loss = 0.003884176653760095
Trained batch 234 in epoch 1, gen_loss = 1.2607630902148308, disc_loss = 0.0038735620466932813
Trained batch 235 in epoch 1, gen_loss = 1.259946552373595, disc_loss = 0.003865789270602656
Trained batch 236 in epoch 1, gen_loss = 1.260767510168663, disc_loss = 0.0038569833813647775
Trained batch 237 in epoch 1, gen_loss = 1.2608931620581811, disc_loss = 0.0038452748375056513
Trained batch 238 in epoch 1, gen_loss = 1.260998211645182, disc_loss = 0.0038345052320490664
Trained batch 239 in epoch 1, gen_loss = 1.2609273274739583, disc_loss = 0.0038225147839208756
Trained batch 240 in epoch 1, gen_loss = 1.2612364321823437, disc_loss = 0.003809780628745023
Trained batch 241 in epoch 1, gen_loss = 1.2610345881832532, disc_loss = 0.0037980772995520845
Trained batch 242 in epoch 1, gen_loss = 1.2603923303109628, disc_loss = 0.0037864703386102194
Trained batch 243 in epoch 1, gen_loss = 1.2607340231293538, disc_loss = 0.003775798572517443
Trained batch 244 in epoch 1, gen_loss = 1.260113185765792, disc_loss = 0.0037640074676624975
Trained batch 245 in epoch 1, gen_loss = 1.2594589750941207, disc_loss = 0.004133302808315228
Trained batch 246 in epoch 1, gen_loss = 1.2580863905821735, disc_loss = 0.006077279143510499
Trained batch 247 in epoch 1, gen_loss = 1.2585120318878082, disc_loss = 0.006314085555195268
Trained batch 248 in epoch 1, gen_loss = 1.2611955468913159, disc_loss = 0.006620695402127612
Trained batch 249 in epoch 1, gen_loss = 1.2610154535770417, disc_loss = 0.006706074400804937
Trained batch 250 in epoch 1, gen_loss = 1.2614004091912532, disc_loss = 0.006749331304595705
Trained batch 251 in epoch 1, gen_loss = 1.2611462807371503, disc_loss = 0.006760289910108974
Trained batch 252 in epoch 1, gen_loss = 1.261205469902325, disc_loss = 0.0067490342435732546
Trained batch 253 in epoch 1, gen_loss = 1.2609141231991174, disc_loss = 0.006742056733268629
Trained batch 254 in epoch 1, gen_loss = 1.2613246934086668, disc_loss = 0.006723334111601991
Trained batch 255 in epoch 1, gen_loss = 1.2610393993090838, disc_loss = 0.006709843254611769
Trained batch 256 in epoch 1, gen_loss = 1.2617143014525625, disc_loss = 0.006692793718557298
Trained batch 257 in epoch 1, gen_loss = 1.2618293528871019, disc_loss = 0.006673425197323365
Trained batch 258 in epoch 1, gen_loss = 1.2614785665250654, disc_loss = 0.006657107904441942
Trained batch 259 in epoch 1, gen_loss = 1.2614599739129726, disc_loss = 0.006639849583063131
Trained batch 260 in epoch 1, gen_loss = 1.260782712035709, disc_loss = 0.006621114854786502
Trained batch 261 in epoch 1, gen_loss = 1.260798110989214, disc_loss = 0.006604071148895154
Trained batch 262 in epoch 1, gen_loss = 1.2605898468666656, disc_loss = 0.006592578629559409
Trained batch 263 in epoch 1, gen_loss = 1.2610636631196195, disc_loss = 0.006579919486698186
Trained batch 264 in epoch 1, gen_loss = 1.2630486513083836, disc_loss = 0.006564241756228203
Trained batch 265 in epoch 1, gen_loss = 1.2628482179086011, disc_loss = 0.006547926097523589
Trained batch 266 in epoch 1, gen_loss = 1.2629646801769956, disc_loss = 0.006528796022496281
Trained batch 267 in epoch 1, gen_loss = 1.2628973244286295, disc_loss = 0.0065158242876676205
Trained batch 268 in epoch 1, gen_loss = 1.262323033632399, disc_loss = 0.006500872868618696
Trained batch 269 in epoch 1, gen_loss = 1.2617531244401579, disc_loss = 0.0064820133964531125
Trained batch 270 in epoch 1, gen_loss = 1.2609021094012525, disc_loss = 0.006463397171853516
Trained batch 271 in epoch 1, gen_loss = 1.2602731434299665, disc_loss = 0.006452761624292608
Trained batch 272 in epoch 1, gen_loss = 1.2594802298825303, disc_loss = 0.006436369596339162
Trained batch 273 in epoch 1, gen_loss = 1.2587665552205414, disc_loss = 0.0064250428011185445
Trained batch 274 in epoch 1, gen_loss = 1.259634729081934, disc_loss = 0.006412274975922298
Trained batch 275 in epoch 1, gen_loss = 1.2603916001060735, disc_loss = 0.006393877957674229
Trained batch 276 in epoch 1, gen_loss = 1.2601499292824674, disc_loss = 0.006375809746881819
Trained batch 277 in epoch 1, gen_loss = 1.2608148564966462, disc_loss = 0.0063557560683777485
Trained batch 278 in epoch 1, gen_loss = 1.2605615023216465, disc_loss = 0.006336049860849055
Trained batch 279 in epoch 1, gen_loss = 1.2612881637045315, disc_loss = 0.006316208222623183
Trained batch 280 in epoch 1, gen_loss = 1.2618567512977166, disc_loss = 0.006297880306622855
Trained batch 281 in epoch 1, gen_loss = 1.2626235664736294, disc_loss = 0.006286582141885111
Trained batch 282 in epoch 1, gen_loss = 1.262608051510666, disc_loss = 0.006268111200939021
Trained batch 283 in epoch 1, gen_loss = 1.262949385903251, disc_loss = 0.006254958157947379
Trained batch 284 in epoch 1, gen_loss = 1.2630217867985107, disc_loss = 0.00623835920940333
Trained batch 285 in epoch 1, gen_loss = 1.2628137167100306, disc_loss = 0.006219685353441294
Trained batch 286 in epoch 1, gen_loss = 1.262358049274737, disc_loss = 0.006204781509272248
Trained batch 287 in epoch 1, gen_loss = 1.2624519957850378, disc_loss = 0.006186184684338514
Trained batch 288 in epoch 1, gen_loss = 1.2625216631328358, disc_loss = 0.0061738931100209695
Trained batch 289 in epoch 1, gen_loss = 1.2622763031515583, disc_loss = 0.006159831373149465
Trained batch 290 in epoch 1, gen_loss = 1.2625498904805004, disc_loss = 0.00614668986571255
Trained batch 291 in epoch 1, gen_loss = 1.2625020924088073, disc_loss = 0.006136835937082053
Trained batch 292 in epoch 1, gen_loss = 1.262319202919462, disc_loss = 0.0061224402451360085
Trained batch 293 in epoch 1, gen_loss = 1.2625178469687093, disc_loss = 0.006114206800306989
Trained batch 294 in epoch 1, gen_loss = 1.2633065213591366, disc_loss = 0.006099090079571736
Trained batch 295 in epoch 1, gen_loss = 1.262964343501104, disc_loss = 0.00608187127304641
Trained batch 296 in epoch 1, gen_loss = 1.262803519012952, disc_loss = 0.0060642072086235016
Trained batch 297 in epoch 1, gen_loss = 1.262341199105218, disc_loss = 0.0060501614487464325
Trained batch 298 in epoch 1, gen_loss = 1.2617610407912212, disc_loss = 0.006035992028666691
Trained batch 299 in epoch 1, gen_loss = 1.2636768784125645, disc_loss = 0.006022089543015075
Trained batch 300 in epoch 1, gen_loss = 1.2633682950786578, disc_loss = 0.006007324935337745
Trained batch 301 in epoch 1, gen_loss = 1.2628873576786344, disc_loss = 0.0059928435996862515
Trained batch 302 in epoch 1, gen_loss = 1.262395937253933, disc_loss = 0.006023790428942076
Trained batch 303 in epoch 1, gen_loss = 1.2621295128605867, disc_loss = 0.006022513013656288
Trained batch 304 in epoch 1, gen_loss = 1.2620007309757295, disc_loss = 0.006016965799575641
Trained batch 305 in epoch 1, gen_loss = 1.2617866235231263, disc_loss = 0.0060101721853891305
Trained batch 306 in epoch 1, gen_loss = 1.262596415191986, disc_loss = 0.006007010892074531
Trained batch 307 in epoch 1, gen_loss = 1.2633365019188298, disc_loss = 0.005997500537143258
Trained batch 308 in epoch 1, gen_loss = 1.2635185755186482, disc_loss = 0.005988521560006338
Trained batch 309 in epoch 1, gen_loss = 1.2642498998872695, disc_loss = 0.005973201440159052
Trained batch 310 in epoch 1, gen_loss = 1.264316062643597, disc_loss = 0.005957895911402006
Trained batch 311 in epoch 1, gen_loss = 1.265174690538492, disc_loss = 0.0059453436770127155
Trained batch 312 in epoch 1, gen_loss = 1.2653173107308702, disc_loss = 0.005930116475811199
Trained batch 313 in epoch 1, gen_loss = 1.2657549694465224, disc_loss = 0.005916493381469979
Trained batch 314 in epoch 1, gen_loss = 1.265830387577178, disc_loss = 0.005904685596691533
Trained batch 315 in epoch 1, gen_loss = 1.2655664578646044, disc_loss = 0.005890037689639456
Trained batch 316 in epoch 1, gen_loss = 1.2664570261251287, disc_loss = 0.005874189873753345
Trained batch 317 in epoch 1, gen_loss = 1.2659758811101973, disc_loss = 0.005861589678675932
Trained batch 318 in epoch 1, gen_loss = 1.2673491357262232, disc_loss = 0.00584564666441849
Trained batch 319 in epoch 1, gen_loss = 1.2676339430734516, disc_loss = 0.0058294156877309435
Trained batch 320 in epoch 1, gen_loss = 1.2673650372808225, disc_loss = 0.005816994237639532
Trained batch 321 in epoch 1, gen_loss = 1.2673261089724783, disc_loss = 0.005803112359102873
Trained batch 322 in epoch 1, gen_loss = 1.2679704673150007, disc_loss = 0.005790282305922567
Trained batch 323 in epoch 1, gen_loss = 1.2677877723802755, disc_loss = 0.005778450337576358
Trained batch 324 in epoch 1, gen_loss = 1.2676847551419186, disc_loss = 0.005763778755835329
Trained batch 325 in epoch 1, gen_loss = 1.268412000745352, disc_loss = 0.0057488409164890165
Trained batch 326 in epoch 1, gen_loss = 1.267923464651137, disc_loss = 0.005768885499041596
Trained batch 327 in epoch 1, gen_loss = 1.2678353257659005, disc_loss = 0.005775243202018518
Trained batch 328 in epoch 1, gen_loss = 1.2672101279160173, disc_loss = 0.005766140862324171
Trained batch 329 in epoch 1, gen_loss = 1.267367843245015, disc_loss = 0.0057570878068817725
Trained batch 330 in epoch 1, gen_loss = 1.2669081995854565, disc_loss = 0.005743283969582286
Trained batch 331 in epoch 1, gen_loss = 1.2662323514022022, disc_loss = 0.005733596032495184
Trained batch 332 in epoch 1, gen_loss = 1.266658456296892, disc_loss = 0.005728394336202783
Trained batch 333 in epoch 1, gen_loss = 1.2664306729496597, disc_loss = 0.005717196326645671
Trained batch 334 in epoch 1, gen_loss = 1.266429037656357, disc_loss = 0.005702997241064962
Trained batch 335 in epoch 1, gen_loss = 1.266200743793022, disc_loss = 0.005689452334904456
Trained batch 336 in epoch 1, gen_loss = 1.2662569979531828, disc_loss = 0.0056777676204371455
Trained batch 337 in epoch 1, gen_loss = 1.2668385507439721, disc_loss = 0.005663867695250179
Trained batch 338 in epoch 1, gen_loss = 1.2664151256766643, disc_loss = 0.005651120444832529
Trained batch 339 in epoch 1, gen_loss = 1.266466359005255, disc_loss = 0.005638643641278203
Trained batch 340 in epoch 1, gen_loss = 1.2666706026823988, disc_loss = 0.005626462076830233
Trained batch 341 in epoch 1, gen_loss = 1.266933811512607, disc_loss = 0.005615631179517811
Trained batch 342 in epoch 1, gen_loss = 1.2666800795421655, disc_loss = 0.0056025613818532155
Trained batch 343 in epoch 1, gen_loss = 1.266173388202523, disc_loss = 0.0055898707398947135
Trained batch 344 in epoch 1, gen_loss = 1.265583244095678, disc_loss = 0.0055779623328303185
Trained batch 345 in epoch 1, gen_loss = 1.2653788181743182, disc_loss = 0.005563721013816633
Trained batch 346 in epoch 1, gen_loss = 1.2650801391697755, disc_loss = 0.005549828109421341
Trained batch 347 in epoch 1, gen_loss = 1.2646013352720218, disc_loss = 0.005535770821332899
Trained batch 348 in epoch 1, gen_loss = 1.2649744549248485, disc_loss = 0.005522471554724121
Trained batch 349 in epoch 1, gen_loss = 1.2653556481429509, disc_loss = 0.005509244668230946
Trained batch 350 in epoch 1, gen_loss = 1.2652490347878547, disc_loss = 0.005496854752241143
Trained batch 351 in epoch 1, gen_loss = 1.2652190325951034, disc_loss = 0.005484245203247569
Trained batch 352 in epoch 1, gen_loss = 1.265314944911611, disc_loss = 0.005472948810312549
Trained batch 353 in epoch 1, gen_loss = 1.265484483733689, disc_loss = 0.005459959976379049
Trained batch 354 in epoch 1, gen_loss = 1.2655409965716617, disc_loss = 0.005449858420482561
Trained batch 355 in epoch 1, gen_loss = 1.2653475991460714, disc_loss = 0.005437632850495565
Trained batch 356 in epoch 1, gen_loss = 1.2647295397202842, disc_loss = 0.005424974991676479
Trained batch 357 in epoch 1, gen_loss = 1.2654471512280363, disc_loss = 0.0054145673837502325
Trained batch 358 in epoch 1, gen_loss = 1.265433786141175, disc_loss = 0.005404013161051987
Trained batch 359 in epoch 1, gen_loss = 1.2649591497249073, disc_loss = 0.005391696842464929
Trained batch 360 in epoch 1, gen_loss = 1.2653977453213319, disc_loss = 0.005382386502523461
Trained batch 361 in epoch 1, gen_loss = 1.2651039231877301, disc_loss = 0.0053711948284071494
Trained batch 362 in epoch 1, gen_loss = 1.264954075176197, disc_loss = 0.005360798676467447
Trained batch 363 in epoch 1, gen_loss = 1.2648782509041356, disc_loss = 0.005352274361539857
Trained batch 364 in epoch 1, gen_loss = 1.2646289487407631, disc_loss = 0.005339370245011906
Trained batch 365 in epoch 1, gen_loss = 1.2644979870710216, disc_loss = 0.0053312598970652525
Trained batch 366 in epoch 1, gen_loss = 1.2639341869211327, disc_loss = 0.005321072896673504
Trained batch 367 in epoch 1, gen_loss = 1.263732459720062, disc_loss = 0.005309775816504439
Trained batch 368 in epoch 1, gen_loss = 1.263465104871972, disc_loss = 0.005297488094746642
Trained batch 369 in epoch 1, gen_loss = 1.2636484850097347, disc_loss = 0.0052891782764974676
Trained batch 370 in epoch 1, gen_loss = 1.2640759792289322, disc_loss = 0.005277663483435032
Trained batch 371 in epoch 1, gen_loss = 1.263629475428212, disc_loss = 0.005267644132379823
Trained batch 372 in epoch 1, gen_loss = 1.263466657806018, disc_loss = 0.0052551629281435515
Trained batch 373 in epoch 1, gen_loss = 1.2641580093671931, disc_loss = 0.0052436302876085
Trained batch 374 in epoch 1, gen_loss = 1.2647842682202657, disc_loss = 0.005231339122168719
Trained batch 375 in epoch 1, gen_loss = 1.2647593374899093, disc_loss = 0.00521924410682875
Trained batch 376 in epoch 1, gen_loss = 1.264697565166008, disc_loss = 0.005207989436193846
Trained batch 377 in epoch 1, gen_loss = 1.2646369153545016, disc_loss = 0.005195813734582059
Trained batch 378 in epoch 1, gen_loss = 1.264467711341727, disc_loss = 0.005186833699889933
Trained batch 379 in epoch 1, gen_loss = 1.2642659066539061, disc_loss = 0.005177855840577793
Trained batch 380 in epoch 1, gen_loss = 1.2637501640582647, disc_loss = 0.0051672043562365644
Trained batch 381 in epoch 1, gen_loss = 1.2639378120449825, disc_loss = 0.005156704952394229
Trained batch 382 in epoch 1, gen_loss = 1.26388808750297, disc_loss = 0.0051447207137927725
Trained batch 383 in epoch 1, gen_loss = 1.2636186295809846, disc_loss = 0.00513315324587893
Trained batch 384 in epoch 1, gen_loss = 1.2636658044604512, disc_loss = 0.0051216608484868295
Trained batch 385 in epoch 1, gen_loss = 1.263079920735384, disc_loss = 0.0051130058815089955
Trained batch 386 in epoch 1, gen_loss = 1.2631101723789244, disc_loss = 0.005102637132150855
Trained batch 387 in epoch 1, gen_loss = 1.2627498702597373, disc_loss = 0.005097223386065266
Trained batch 388 in epoch 1, gen_loss = 1.2632437296269179, disc_loss = 0.005091756104927386
Trained batch 389 in epoch 1, gen_loss = 1.2630687794624231, disc_loss = 0.00508079509003064
Trained batch 390 in epoch 1, gen_loss = 1.2627358852749895, disc_loss = 0.005070688132860024
Trained batch 391 in epoch 1, gen_loss = 1.262562605343303, disc_loss = 0.005059611441612681
Trained batch 392 in epoch 1, gen_loss = 1.2623100870741537, disc_loss = 0.005048313481157347
Trained batch 393 in epoch 1, gen_loss = 1.2625804899005115, disc_loss = 0.005036962933768636
Trained batch 394 in epoch 1, gen_loss = 1.2621099437339396, disc_loss = 0.005026357906393094
Trained batch 395 in epoch 1, gen_loss = 1.2626466114412656, disc_loss = 0.005015349865484174
Trained batch 396 in epoch 1, gen_loss = 1.262969820415343, disc_loss = 0.005004261819157815
Trained batch 397 in epoch 1, gen_loss = 1.2625823660412026, disc_loss = 0.004993551381777073
Trained batch 398 in epoch 1, gen_loss = 1.2629637776460862, disc_loss = 0.004983027245502751
Trained batch 399 in epoch 1, gen_loss = 1.2625251461565494, disc_loss = 0.00497302239513374
Trained batch 400 in epoch 1, gen_loss = 1.2628371491099237, disc_loss = 0.00496364228745012
Trained batch 401 in epoch 1, gen_loss = 1.2626004158264368, disc_loss = 0.00495394844077041
Trained batch 402 in epoch 1, gen_loss = 1.2631518182624362, disc_loss = 0.00494445096594501
Trained batch 403 in epoch 1, gen_loss = 1.2628111229969723, disc_loss = 0.0049353944842811985
Trained batch 404 in epoch 1, gen_loss = 1.2624150536678456, disc_loss = 0.00492618682457962
Trained batch 405 in epoch 1, gen_loss = 1.263147997885502, disc_loss = 0.004916204997651471
Trained batch 406 in epoch 1, gen_loss = 1.262731674408737, disc_loss = 0.004906332806920912
Trained batch 407 in epoch 1, gen_loss = 1.2623791628900696, disc_loss = 0.004899519892990379
Trained batch 408 in epoch 1, gen_loss = 1.2630827335098844, disc_loss = 0.004890195718678375
Trained batch 409 in epoch 1, gen_loss = 1.2634277368464122, disc_loss = 0.0048806511826824574
Trained batch 410 in epoch 1, gen_loss = 1.263874286717742, disc_loss = 0.0048739088127341965
Trained batch 411 in epoch 1, gen_loss = 1.264256313443184, disc_loss = 0.0048650852801533665
Trained batch 412 in epoch 1, gen_loss = 1.2644949916199968, disc_loss = 0.004854571170790333
Trained batch 413 in epoch 1, gen_loss = 1.2644560332747474, disc_loss = 0.00484507038313693
Trained batch 414 in epoch 1, gen_loss = 1.2649348404034075, disc_loss = 0.004835990851279348
Trained batch 415 in epoch 1, gen_loss = 1.2652671779864109, disc_loss = 0.004825715908737038
Trained batch 416 in epoch 1, gen_loss = 1.264931256107861, disc_loss = 0.004817251098309856
Trained batch 417 in epoch 1, gen_loss = 1.2648529135154194, disc_loss = 0.004808216333878338
Trained batch 418 in epoch 1, gen_loss = 1.2646251090386602, disc_loss = 0.004801680437685935
Trained batch 419 in epoch 1, gen_loss = 1.2649008933986936, disc_loss = 0.004792071155887762
Trained batch 420 in epoch 1, gen_loss = 1.2646859138142186, disc_loss = 0.004784120855528879
Trained batch 421 in epoch 1, gen_loss = 1.2645717456724972, disc_loss = 0.0047787149684775125
Trained batch 422 in epoch 1, gen_loss = 1.2645096859187945, disc_loss = 0.004770115420665927
Trained batch 423 in epoch 1, gen_loss = 1.2641427284985218, disc_loss = 0.004761676315162199
Trained batch 424 in epoch 1, gen_loss = 1.2640394669420578, disc_loss = 0.00475312059320619
Trained batch 425 in epoch 1, gen_loss = 1.264419439113196, disc_loss = 0.004743932561206679
Trained batch 426 in epoch 1, gen_loss = 1.2642827071685703, disc_loss = 0.004735198379979541
Trained batch 427 in epoch 1, gen_loss = 1.2639880009065165, disc_loss = 0.004726616173267808
Trained batch 428 in epoch 1, gen_loss = 1.2636327728247032, disc_loss = 0.004718035155183273
Trained batch 429 in epoch 1, gen_loss = 1.2635897560175076, disc_loss = 0.004709438138051219
Trained batch 430 in epoch 1, gen_loss = 1.2633623475265061, disc_loss = 0.004704049087087397
Trained batch 431 in epoch 1, gen_loss = 1.2632548611749101, disc_loss = 0.004696375527230514
Trained batch 432 in epoch 1, gen_loss = 1.2632307649759993, disc_loss = 0.004687375693789557
Trained batch 433 in epoch 1, gen_loss = 1.2630760412886395, disc_loss = 0.004678080200559936
Trained batch 434 in epoch 1, gen_loss = 1.262983194849957, disc_loss = 0.004669075553846043
Trained batch 435 in epoch 1, gen_loss = 1.2626101646674883, disc_loss = 0.004661030714787808
Trained batch 436 in epoch 1, gen_loss = 1.2627708640469566, disc_loss = 0.004652482735843439
Trained batch 437 in epoch 1, gen_loss = 1.2625806343882051, disc_loss = 0.00464385443076823
Trained batch 438 in epoch 1, gen_loss = 1.2633154779197415, disc_loss = 0.004634919919626223
Trained batch 439 in epoch 1, gen_loss = 1.2630316643552346, disc_loss = 0.004625983179456936
Trained batch 440 in epoch 1, gen_loss = 1.262719095564213, disc_loss = 0.004617904613450245
Trained batch 441 in epoch 1, gen_loss = 1.262371014281096, disc_loss = 0.004609981056211129
Trained batch 442 in epoch 1, gen_loss = 1.262212276593288, disc_loss = 0.004601862504536971
Trained batch 443 in epoch 1, gen_loss = 1.2621757711644646, disc_loss = 0.00459361917901415
Trained batch 444 in epoch 1, gen_loss = 1.2620719535966938, disc_loss = 0.004587828390969989
Trained batch 445 in epoch 1, gen_loss = 1.2621155473416161, disc_loss = 0.004580244080021543
Trained batch 446 in epoch 1, gen_loss = 1.26186344914255, disc_loss = 0.004571514072102939
Trained batch 447 in epoch 1, gen_loss = 1.2620525805811798, disc_loss = 0.004565009322634849
Trained batch 448 in epoch 1, gen_loss = 1.2616618007487868, disc_loss = 0.00455752843373843
Trained batch 449 in epoch 1, gen_loss = 1.2617631653944652, disc_loss = 0.0045492817879292284
Trained batch 450 in epoch 1, gen_loss = 1.2624628574250807, disc_loss = 0.004541301209285459
Trained batch 451 in epoch 1, gen_loss = 1.2621793012439677, disc_loss = 0.004533443274903647
Trained batch 452 in epoch 1, gen_loss = 1.2621644920860695, disc_loss = 0.00452531462537318
Trained batch 453 in epoch 1, gen_loss = 1.2621413281573073, disc_loss = 0.004517423708529297
Trained batch 454 in epoch 1, gen_loss = 1.261664004771264, disc_loss = 0.004509761501205983
Trained batch 455 in epoch 1, gen_loss = 1.2617263303775537, disc_loss = 0.004504386074187463
Trained batch 456 in epoch 1, gen_loss = 1.2613094089067738, disc_loss = 0.004500170671880343
Trained batch 457 in epoch 1, gen_loss = 1.2610356957371058, disc_loss = 0.004494116479921354
Trained batch 458 in epoch 1, gen_loss = 1.2615377153706187, disc_loss = 0.004485795956890227
Trained batch 459 in epoch 1, gen_loss = 1.2619798767825832, disc_loss = 0.00447822455949474
Trained batch 460 in epoch 1, gen_loss = 1.2622437907661637, disc_loss = 0.004470408749802002
Trained batch 461 in epoch 1, gen_loss = 1.2623058223363124, disc_loss = 0.004462370943420192
Trained batch 462 in epoch 1, gen_loss = 1.262403459966054, disc_loss = 0.0044555157360411605
Trained batch 463 in epoch 1, gen_loss = 1.262409190807877, disc_loss = 0.004447272441933004
Trained batch 464 in epoch 1, gen_loss = 1.2621316654707795, disc_loss = 0.004440408484804975
Trained batch 465 in epoch 1, gen_loss = 1.261915385595207, disc_loss = 0.004432143840854868
Trained batch 466 in epoch 1, gen_loss = 1.262042930473352, disc_loss = 0.004423891284280682
Trained batch 467 in epoch 1, gen_loss = 1.2623092940984628, disc_loss = 0.004417052202331674
Trained batch 468 in epoch 1, gen_loss = 1.2626360699312011, disc_loss = 0.004409359744203879
Trained batch 469 in epoch 1, gen_loss = 1.262666442926894, disc_loss = 0.004400875632022012
Trained batch 470 in epoch 1, gen_loss = 1.2624416142512278, disc_loss = 0.004392875777779942
Trained batch 471 in epoch 1, gen_loss = 1.2625703012286607, disc_loss = 0.004384844518395859
Trained batch 472 in epoch 1, gen_loss = 1.2627098130625347, disc_loss = 0.004376683785480666
Trained batch 473 in epoch 1, gen_loss = 1.2629019367795453, disc_loss = 0.0043701842997787045
Trained batch 474 in epoch 1, gen_loss = 1.2625913081671063, disc_loss = 0.004363265128585657
Trained batch 475 in epoch 1, gen_loss = 1.262372040823728, disc_loss = 0.004355442686375238
Trained batch 476 in epoch 1, gen_loss = 1.2628702271409504, disc_loss = 0.0043486664170522315
Trained batch 477 in epoch 1, gen_loss = 1.263046880521535, disc_loss = 0.004341493067224452
Trained batch 478 in epoch 1, gen_loss = 1.263273334577835, disc_loss = 0.004334056758689296
Trained batch 479 in epoch 1, gen_loss = 1.2631846111267806, disc_loss = 0.004326594908828459
Trained batch 480 in epoch 1, gen_loss = 1.2629950521145938, disc_loss = 0.004321244974880094
Trained batch 481 in epoch 1, gen_loss = 1.2627346390757819, disc_loss = 0.004316144742417493
Trained batch 482 in epoch 1, gen_loss = 1.263187735347274, disc_loss = 0.00430959733236797
Trained batch 483 in epoch 1, gen_loss = 1.2633502420561373, disc_loss = 0.004302548397571033
Trained batch 484 in epoch 1, gen_loss = 1.2632759926245385, disc_loss = 0.004294851918455175
Trained batch 485 in epoch 1, gen_loss = 1.2633762655189498, disc_loss = 0.00428866872797747
Trained batch 486 in epoch 1, gen_loss = 1.263441567670638, disc_loss = 0.004283205106676589
Trained batch 487 in epoch 1, gen_loss = 1.2633766902030492, disc_loss = 0.004277732842563667
Trained batch 488 in epoch 1, gen_loss = 1.2635197184812315, disc_loss = 0.0042723345956888915
Trained batch 489 in epoch 1, gen_loss = 1.263350774682298, disc_loss = 0.004264856930774617
Trained batch 490 in epoch 1, gen_loss = 1.2631311192046357, disc_loss = 0.004258555788575253
Trained batch 491 in epoch 1, gen_loss = 1.2634742312072738, disc_loss = 0.004251456200840838
Trained batch 492 in epoch 1, gen_loss = 1.2634550459970084, disc_loss = 0.004245431293354655
Trained batch 493 in epoch 1, gen_loss = 1.2635039094729945, disc_loss = 0.004240049867111217
Trained batch 494 in epoch 1, gen_loss = 1.2631202975908915, disc_loss = 0.004234708056460614
Trained batch 495 in epoch 1, gen_loss = 1.2632322353461096, disc_loss = 0.0042272688318212934
Trained batch 496 in epoch 1, gen_loss = 1.2630879187008264, disc_loss = 0.004220022494113916
Trained batch 497 in epoch 1, gen_loss = 1.2628146447091697, disc_loss = 0.004213162171645053
Trained batch 498 in epoch 1, gen_loss = 1.262447118639707, disc_loss = 0.004206004743380304
Trained batch 499 in epoch 1, gen_loss = 1.2623700927495956, disc_loss = 0.004199398720636964
Trained batch 500 in epoch 1, gen_loss = 1.2622903351060406, disc_loss = 0.004193078146544759
Trained batch 501 in epoch 1, gen_loss = 1.2621470971173974, disc_loss = 0.004186121683240315
Trained batch 502 in epoch 1, gen_loss = 1.2618914009562543, disc_loss = 0.0041788524581687836
Trained batch 503 in epoch 1, gen_loss = 1.2615310553283918, disc_loss = 0.004171744035071849
Trained batch 504 in epoch 1, gen_loss = 1.2618760527950703, disc_loss = 0.004166201766612617
Trained batch 505 in epoch 1, gen_loss = 1.261636214411777, disc_loss = 0.004160581131878938
Trained batch 506 in epoch 1, gen_loss = 1.2618560872134372, disc_loss = 0.004153841269511134
Trained batch 507 in epoch 1, gen_loss = 1.2617895367342655, disc_loss = 0.004147022028153901
Trained batch 508 in epoch 1, gen_loss = 1.2615274346647656, disc_loss = 0.004140628096835106
Trained batch 509 in epoch 1, gen_loss = 1.2611517051855723, disc_loss = 0.004135138119968093
Trained batch 510 in epoch 1, gen_loss = 1.2609574177727074, disc_loss = 0.0041295424482599265
Trained batch 511 in epoch 1, gen_loss = 1.2609498939709738, disc_loss = 0.004122981288332994
Trained batch 512 in epoch 1, gen_loss = 1.2612603615831446, disc_loss = 0.004117378742968732
Trained batch 513 in epoch 1, gen_loss = 1.2613092128636771, disc_loss = 0.004110981028183664
Trained batch 514 in epoch 1, gen_loss = 1.261047000676683, disc_loss = 0.004103789309229593
Trained batch 515 in epoch 1, gen_loss = 1.2613459089698718, disc_loss = 0.0040982243288651314
Trained batch 516 in epoch 1, gen_loss = 1.2616303770638988, disc_loss = 0.004092309471063056
Trained batch 517 in epoch 1, gen_loss = 1.2615634484871014, disc_loss = 0.004085344124767879
Trained batch 518 in epoch 1, gen_loss = 1.261233966359743, disc_loss = 0.0040786659600965045
Trained batch 519 in epoch 1, gen_loss = 1.2610266643074843, disc_loss = 0.004072093614489019
Trained batch 520 in epoch 1, gen_loss = 1.2609153913902458, disc_loss = 0.00406653798065075
Trained batch 521 in epoch 1, gen_loss = 1.2609129962564884, disc_loss = 0.004060985763013984
Trained batch 522 in epoch 1, gen_loss = 1.2614126220260022, disc_loss = 0.004054482698834094
Trained batch 523 in epoch 1, gen_loss = 1.2611716745691446, disc_loss = 0.0040474878625747866
Trained batch 524 in epoch 1, gen_loss = 1.2615065276055109, disc_loss = 0.004041338858715746
Trained batch 525 in epoch 1, gen_loss = 1.2613645561974312, disc_loss = 0.00403509375911707
Trained batch 526 in epoch 1, gen_loss = 1.2610702271479584, disc_loss = 0.004029423841114016
Trained batch 527 in epoch 1, gen_loss = 1.261063102632761, disc_loss = 0.004023432553643061
Trained batch 528 in epoch 1, gen_loss = 1.260786337415302, disc_loss = 0.004016776887239142
Trained batch 529 in epoch 1, gen_loss = 1.2605749428272248, disc_loss = 0.004011291001960723
Trained batch 530 in epoch 1, gen_loss = 1.260189645146695, disc_loss = 0.004006870970379459
Trained batch 531 in epoch 1, gen_loss = 1.259722745844296, disc_loss = 0.004002681618288975
Trained batch 532 in epoch 1, gen_loss = 1.2593954270373588, disc_loss = 0.0039968797570644
Trained batch 533 in epoch 1, gen_loss = 1.2591547121046187, disc_loss = 0.003990729932670223
Trained batch 534 in epoch 1, gen_loss = 1.2593297297709456, disc_loss = 0.003984640767116744
Trained batch 535 in epoch 1, gen_loss = 1.2589823913885587, disc_loss = 0.003978865844105916
Trained batch 536 in epoch 1, gen_loss = 1.2588373432612285, disc_loss = 0.003973245824345958
Trained batch 537 in epoch 1, gen_loss = 1.2592142890155538, disc_loss = 0.0039670108000122075
Trained batch 538 in epoch 1, gen_loss = 1.2588493809629238, disc_loss = 0.003960894047360822
Trained batch 539 in epoch 1, gen_loss = 1.258540724714597, disc_loss = 0.003954832049472585
Trained batch 540 in epoch 1, gen_loss = 1.2588667703203706, disc_loss = 0.003948519133169517
Trained batch 541 in epoch 1, gen_loss = 1.258573608974689, disc_loss = 0.003943119102771518
Trained batch 542 in epoch 1, gen_loss = 1.2587204031083685, disc_loss = 0.003937168640539506
Trained batch 543 in epoch 1, gen_loss = 1.2588831130415201, disc_loss = 0.00393101648943925
Trained batch 544 in epoch 1, gen_loss = 1.2586296275121356, disc_loss = 0.003925789497769224
Trained batch 545 in epoch 1, gen_loss = 1.258636196781864, disc_loss = 0.003919654085154598
Trained batch 546 in epoch 1, gen_loss = 1.25881714238981, disc_loss = 0.0039140839294945036
Trained batch 547 in epoch 1, gen_loss = 1.2590073100189223, disc_loss = 0.003908540658029493
Trained batch 548 in epoch 1, gen_loss = 1.2590002823614248, disc_loss = 0.003902934641924641
Trained batch 549 in epoch 1, gen_loss = 1.2587023603916168, disc_loss = 0.003896909803522497
Trained batch 550 in epoch 1, gen_loss = 1.2584963319738633, disc_loss = 0.0038908521122169833
Trained batch 551 in epoch 1, gen_loss = 1.2582830062163048, disc_loss = 0.0038847227702005866
Trained batch 552 in epoch 1, gen_loss = 1.2587207791818202, disc_loss = 0.0038789173737728286
Trained batch 553 in epoch 1, gen_loss = 1.2588142011354977, disc_loss = 0.0038764103545764436
Trained batch 554 in epoch 1, gen_loss = 1.2585188946208439, disc_loss = 0.003871556877227802
Trained batch 555 in epoch 1, gen_loss = 1.2584493437902533, disc_loss = 0.0038664077801513486
Trained batch 556 in epoch 1, gen_loss = 1.2589817741614913, disc_loss = 0.0038605602226647277
Trained batch 557 in epoch 1, gen_loss = 1.2590769628683727, disc_loss = 0.0038544219165083226
Trained batch 558 in epoch 1, gen_loss = 1.2598068049853943, disc_loss = 0.0038495269608296526
Trained batch 559 in epoch 1, gen_loss = 1.259838490081685, disc_loss = 0.003844676818750616
Trained batch 560 in epoch 1, gen_loss = 1.2596761917897936, disc_loss = 0.0038393737071043513
Trained batch 561 in epoch 1, gen_loss = 1.2597284224746066, disc_loss = 0.0038338427326134058
Trained batch 562 in epoch 1, gen_loss = 1.2597316155213445, disc_loss = 0.0038323767898752327
Trained batch 563 in epoch 1, gen_loss = 1.2595599569538807, disc_loss = 0.0038302930856618125
Trained batch 564 in epoch 1, gen_loss = 1.259345028991193, disc_loss = 0.003826733176808689
Trained batch 565 in epoch 1, gen_loss = 1.2590584284214585, disc_loss = 0.003821462793113226
Trained batch 566 in epoch 1, gen_loss = 1.2589408204458798, disc_loss = 0.003816404198146486
Trained batch 567 in epoch 1, gen_loss = 1.2585248121283423, disc_loss = 0.003811884445536301
Trained batch 568 in epoch 1, gen_loss = 1.258025063781202, disc_loss = 0.003949919866464676
Trained batch 569 in epoch 1, gen_loss = 1.257128091862327, disc_loss = 0.004231476244923103
Trained batch 570 in epoch 1, gen_loss = 1.2568275354372014, disc_loss = 0.004319380874565726
Trained batch 571 in epoch 1, gen_loss = 1.256894992573278, disc_loss = 0.004378304820395013
Trained batch 572 in epoch 1, gen_loss = 1.257577450279582, disc_loss = 0.004396602732808383
Trained batch 573 in epoch 1, gen_loss = 1.2572868007400726, disc_loss = 0.004413694575238723
Trained batch 574 in epoch 1, gen_loss = 1.2575330790229466, disc_loss = 0.004460407414868393
Trained batch 575 in epoch 1, gen_loss = 1.2576095699850056, disc_loss = 0.004519823554144548
Trained batch 576 in epoch 1, gen_loss = 1.2576938229169135, disc_loss = 0.004557021969775596
Trained batch 577 in epoch 1, gen_loss = 1.2577787361343014, disc_loss = 0.004561166347849995
Trained batch 578 in epoch 1, gen_loss = 1.257708467555993, disc_loss = 0.004556852241200741
Trained batch 579 in epoch 1, gen_loss = 1.2574945283347163, disc_loss = 0.0045537680908856945
Trained batch 580 in epoch 1, gen_loss = 1.2574210599859899, disc_loss = 0.004550809894995796
Trained batch 581 in epoch 1, gen_loss = 1.2571460723467298, disc_loss = 0.004545509655945103
Trained batch 582 in epoch 1, gen_loss = 1.2572583565376636, disc_loss = 0.0045412412562945105
Trained batch 583 in epoch 1, gen_loss = 1.2574138465809495, disc_loss = 0.004534724090686499
Trained batch 584 in epoch 1, gen_loss = 1.257430857878465, disc_loss = 0.004528831566721758
Trained batch 585 in epoch 1, gen_loss = 1.2578394929703591, disc_loss = 0.004522682158997578
Trained batch 586 in epoch 1, gen_loss = 1.2576084998031694, disc_loss = 0.004517048552068699
Trained batch 587 in epoch 1, gen_loss = 1.2575901937322551, disc_loss = 0.004512101023322918
Trained batch 588 in epoch 1, gen_loss = 1.2573062009438998, disc_loss = 0.0045071518473490816
Trained batch 589 in epoch 1, gen_loss = 1.2573223845433381, disc_loss = 0.004504863246910322
Trained batch 590 in epoch 1, gen_loss = 1.2572106917699177, disc_loss = 0.004499425708508125
Trained batch 591 in epoch 1, gen_loss = 1.2570416907200943, disc_loss = 0.004494965228602539
Trained batch 592 in epoch 1, gen_loss = 1.256775613980993, disc_loss = 0.004492022019320577
Trained batch 593 in epoch 1, gen_loss = 1.2569002007394527, disc_loss = 0.0044877544626642975
Trained batch 594 in epoch 1, gen_loss = 1.2567788162151305, disc_loss = 0.004481947366803681
Trained batch 595 in epoch 1, gen_loss = 1.2565174182789438, disc_loss = 0.004476975303035051
Trained batch 596 in epoch 1, gen_loss = 1.2564580630217765, disc_loss = 0.004471571522776952
Trained batch 597 in epoch 1, gen_loss = 1.2561926652356534, disc_loss = 0.004465856429695208
Trained batch 598 in epoch 1, gen_loss = 1.2563052193350306, disc_loss = 0.004459477620903257
Trained batch 599 in epoch 1, gen_loss = 1.256412630478541, disc_loss = 0.004453640613889244
Trained batch 600 in epoch 1, gen_loss = 1.256522157029582, disc_loss = 0.004447553519551997
Trained batch 601 in epoch 1, gen_loss = 1.2565711504993249, disc_loss = 0.004442763438673019
Trained batch 602 in epoch 1, gen_loss = 1.2570557880955153, disc_loss = 0.004441365318584826
Trained batch 603 in epoch 1, gen_loss = 1.2569404702312899, disc_loss = 0.0044368368601723305
Trained batch 604 in epoch 1, gen_loss = 1.2570823220182057, disc_loss = 0.0044308338968048625
Trained batch 605 in epoch 1, gen_loss = 1.2569376859727865, disc_loss = 0.004424823172151867
Trained batch 606 in epoch 1, gen_loss = 1.2568941029921001, disc_loss = 0.0044197972561942364
Trained batch 607 in epoch 1, gen_loss = 1.2569639855309536, disc_loss = 0.0044170631425387045
Trained batch 608 in epoch 1, gen_loss = 1.2570390221716343, disc_loss = 0.004411895238641077
Trained batch 609 in epoch 1, gen_loss = 1.2566710178969336, disc_loss = 0.00440663596434847
Trained batch 610 in epoch 1, gen_loss = 1.256618237144233, disc_loss = 0.004401104773900436
Trained batch 611 in epoch 1, gen_loss = 1.2565752297055488, disc_loss = 0.004394756314058231
Trained batch 612 in epoch 1, gen_loss = 1.2568451345064122, disc_loss = 0.004389344734095301
Trained batch 613 in epoch 1, gen_loss = 1.2570602977314678, disc_loss = 0.004383635685537602
Trained batch 614 in epoch 1, gen_loss = 1.2568049494813127, disc_loss = 0.004377884242534108
Trained batch 615 in epoch 1, gen_loss = 1.2566098913356856, disc_loss = 0.00437184197166912
Trained batch 616 in epoch 1, gen_loss = 1.256325384786102, disc_loss = 0.004366312735943075
Trained batch 617 in epoch 1, gen_loss = 1.255972928985423, disc_loss = 0.004360851016779834
Trained batch 618 in epoch 1, gen_loss = 1.2556516715898653, disc_loss = 0.004354833345361857
Trained batch 619 in epoch 1, gen_loss = 1.2555677412017698, disc_loss = 0.004348722454151063
Trained batch 620 in epoch 1, gen_loss = 1.256460866106497, disc_loss = 0.004343318399527424
Trained batch 621 in epoch 1, gen_loss = 1.2560898353049226, disc_loss = 0.004337965223443743
Trained batch 622 in epoch 1, gen_loss = 1.2559845166259938, disc_loss = 0.004332524263174804
Trained batch 623 in epoch 1, gen_loss = 1.2558334273023484, disc_loss = 0.0043285195262843705
Trained batch 624 in epoch 1, gen_loss = 1.2557861070632934, disc_loss = 0.004323053429694846
Trained batch 625 in epoch 1, gen_loss = 1.2556111745940992, disc_loss = 0.00431837814960654
Trained batch 626 in epoch 1, gen_loss = 1.2555337923755676, disc_loss = 0.004313212882943134
Trained batch 627 in epoch 1, gen_loss = 1.2557297504631577, disc_loss = 0.004311216298157459
Trained batch 628 in epoch 1, gen_loss = 1.2557213006982364, disc_loss = 0.004306057380930268
Trained batch 629 in epoch 1, gen_loss = 1.2558386831056505, disc_loss = 0.0043010328407122175
Trained batch 630 in epoch 1, gen_loss = 1.255629265742899, disc_loss = 0.004295512225555268
Trained batch 631 in epoch 1, gen_loss = 1.2555676962755904, disc_loss = 0.004290728148025434
Trained batch 632 in epoch 1, gen_loss = 1.2554185959211834, disc_loss = 0.00428518212786037
Trained batch 633 in epoch 1, gen_loss = 1.2555797064341958, disc_loss = 0.004279193069935667
Trained batch 634 in epoch 1, gen_loss = 1.2554632605530145, disc_loss = 0.0042742990582492054
Trained batch 635 in epoch 1, gen_loss = 1.2558515424248557, disc_loss = 0.004268794996684429
Trained batch 636 in epoch 1, gen_loss = 1.2556860911041452, disc_loss = 0.004263492722175372
Trained batch 637 in epoch 1, gen_loss = 1.2554826241301893, disc_loss = 0.004258573605959248
Trained batch 638 in epoch 1, gen_loss = 1.2556609252995354, disc_loss = 0.004253040874742718
Trained batch 639 in epoch 1, gen_loss = 1.2555635279044508, disc_loss = 0.004247467077038891
Trained batch 640 in epoch 1, gen_loss = 1.255537660185149, disc_loss = 0.00424277083857447
Trained batch 641 in epoch 1, gen_loss = 1.2551865278746108, disc_loss = 0.0042393386744418275
Trained batch 642 in epoch 1, gen_loss = 1.2549105773261324, disc_loss = 0.00423485115945374
Trained batch 643 in epoch 1, gen_loss = 1.254785598435017, disc_loss = 0.004230977207428041
Trained batch 644 in epoch 1, gen_loss = 1.2546199447424837, disc_loss = 0.004226164706412327
Trained batch 645 in epoch 1, gen_loss = 1.2547061406421958, disc_loss = 0.004221356649026736
Trained batch 646 in epoch 1, gen_loss = 1.2549386284266595, disc_loss = 0.004215787998307064
Trained batch 647 in epoch 1, gen_loss = 1.2546784612867568, disc_loss = 0.004210648000424291
Trained batch 648 in epoch 1, gen_loss = 1.254429233276238, disc_loss = 0.0042064557381502376
Trained batch 649 in epoch 1, gen_loss = 1.2548213665301984, disc_loss = 0.004202271924139215
Trained batch 650 in epoch 1, gen_loss = 1.2547778442341795, disc_loss = 0.0041971710851571925
Trained batch 651 in epoch 1, gen_loss = 1.2548701739384354, disc_loss = 0.004191798658468732
Trained batch 652 in epoch 1, gen_loss = 1.254617808788878, disc_loss = 0.004186678816140793
Trained batch 653 in epoch 1, gen_loss = 1.254487638262069, disc_loss = 0.0041808608021524475
Trained batch 654 in epoch 1, gen_loss = 1.2543314466039643, disc_loss = 0.004177049897568485
Trained batch 655 in epoch 1, gen_loss = 1.2540857317607577, disc_loss = 0.004172227117545312
Trained batch 656 in epoch 1, gen_loss = 1.2539694693897776, disc_loss = 0.004166802923961243
Trained batch 657 in epoch 1, gen_loss = 1.2539381393908005, disc_loss = 0.004161487733587866
Trained batch 658 in epoch 1, gen_loss = 1.254171645514701, disc_loss = 0.004155838439106441
Trained batch 659 in epoch 1, gen_loss = 1.2540295140309767, disc_loss = 0.004150594854736207
Trained batch 660 in epoch 1, gen_loss = 1.2540907771432273, disc_loss = 0.004145104419529852
Trained batch 661 in epoch 1, gen_loss = 1.2541029649558744, disc_loss = 0.004139673462609923
Trained batch 662 in epoch 1, gen_loss = 1.2539566316575845, disc_loss = 0.004134389314037392
Trained batch 663 in epoch 1, gen_loss = 1.2541722901255252, disc_loss = 0.004129217281481405
Trained batch 664 in epoch 1, gen_loss = 1.2541659572070702, disc_loss = 0.004124051329891611
Trained batch 665 in epoch 1, gen_loss = 1.2541233829191856, disc_loss = 0.0041200134562074655
Trained batch 666 in epoch 1, gen_loss = 1.254101239222994, disc_loss = 0.0041150654506163795
Trained batch 667 in epoch 1, gen_loss = 1.2540078016812215, disc_loss = 0.004110057212223793
Trained batch 668 in epoch 1, gen_loss = 1.2540123031456551, disc_loss = 0.004105667501118282
Trained batch 669 in epoch 1, gen_loss = 1.2537036125339678, disc_loss = 0.0041026887080350665
Trained batch 670 in epoch 1, gen_loss = 1.254148437795625, disc_loss = 0.004099035581763648
Trained batch 671 in epoch 1, gen_loss = 1.2542912456251325, disc_loss = 0.00409436084767852
Trained batch 672 in epoch 1, gen_loss = 1.2541464675234473, disc_loss = 0.0040898341856350955
Trained batch 673 in epoch 1, gen_loss = 1.2539674844869166, disc_loss = 0.004085587028568425
Trained batch 674 in epoch 1, gen_loss = 1.2540396278875845, disc_loss = 0.00408061613100236
Trained batch 675 in epoch 1, gen_loss = 1.2537689743310036, disc_loss = 0.004076202911283124
Trained batch 676 in epoch 1, gen_loss = 1.2536264436107618, disc_loss = 0.004071076039767905
Trained batch 677 in epoch 1, gen_loss = 1.2536007983494648, disc_loss = 0.004065829718917825
Trained batch 678 in epoch 1, gen_loss = 1.2539505726810056, disc_loss = 0.004060740989112722
Trained batch 679 in epoch 1, gen_loss = 1.2538701870862174, disc_loss = 0.004055781509711831
Trained batch 680 in epoch 1, gen_loss = 1.2537012481829493, disc_loss = 0.004050924662675329
Trained batch 681 in epoch 1, gen_loss = 1.2534702264668305, disc_loss = 0.004045837426814524
Trained batch 682 in epoch 1, gen_loss = 1.253168870554487, disc_loss = 0.004041658800446782
Trained batch 683 in epoch 1, gen_loss = 1.2528893640863965, disc_loss = 0.004036977354902434
Trained batch 684 in epoch 1, gen_loss = 1.252809146024885, disc_loss = 0.004032353639397022
Trained batch 685 in epoch 1, gen_loss = 1.2530094227012323, disc_loss = 0.004027883533030984
Trained batch 686 in epoch 1, gen_loss = 1.2533405528144892, disc_loss = 0.0040227991585661095
Trained batch 687 in epoch 1, gen_loss = 1.2536006535208502, disc_loss = 0.004017809822556067
Trained batch 688 in epoch 1, gen_loss = 1.2534057005742465, disc_loss = 0.004012959754861234
Trained batch 689 in epoch 1, gen_loss = 1.2537430519643038, disc_loss = 0.004010171500630205
Trained batch 690 in epoch 1, gen_loss = 1.2541571460480974, disc_loss = 0.004006982972421218
Trained batch 691 in epoch 1, gen_loss = 1.2538772327017922, disc_loss = 0.004002967438765874
Trained batch 692 in epoch 1, gen_loss = 1.253872368758891, disc_loss = 0.003998616447446809
Trained batch 693 in epoch 1, gen_loss = 1.2537355651429476, disc_loss = 0.003994956490007009
Trained batch 694 in epoch 1, gen_loss = 1.2535819832369577, disc_loss = 0.003990788569065856
Trained batch 695 in epoch 1, gen_loss = 1.2532973652598502, disc_loss = 0.0039861660187508
Trained batch 696 in epoch 1, gen_loss = 1.2535307879427413, disc_loss = 0.003982221311563893
Trained batch 697 in epoch 1, gen_loss = 1.2532878475407816, disc_loss = 0.003978536706486181
Trained batch 698 in epoch 1, gen_loss = 1.2529857927808092, disc_loss = 0.003973893961345894
Trained batch 699 in epoch 1, gen_loss = 1.252854779788426, disc_loss = 0.0039691325159427445
Trained batch 700 in epoch 1, gen_loss = 1.2526231805200074, disc_loss = 0.003965857622458449
Trained batch 701 in epoch 1, gen_loss = 1.2524899183175502, disc_loss = 0.003962273619138036
Trained batch 702 in epoch 1, gen_loss = 1.2526383854417, disc_loss = 0.003958260064759487
Trained batch 703 in epoch 1, gen_loss = 1.2523267341947013, disc_loss = 0.003954864337133172
Trained batch 704 in epoch 1, gen_loss = 1.2524223466291495, disc_loss = 0.003951004504577871
Trained batch 705 in epoch 1, gen_loss = 1.2522482880451862, disc_loss = 0.0039463791132277335
Trained batch 706 in epoch 1, gen_loss = 1.2521881495709128, disc_loss = 0.003942261115936668
Trained batch 707 in epoch 1, gen_loss = 1.251977633116609, disc_loss = 0.003937423688671644
Trained batch 708 in epoch 1, gen_loss = 1.2520770523881037, disc_loss = 0.003932497240279503
Trained batch 709 in epoch 1, gen_loss = 1.251874122653209, disc_loss = 0.003927653312107588
Trained batch 710 in epoch 1, gen_loss = 1.251800368774457, disc_loss = 0.003924496598325934
Trained batch 711 in epoch 1, gen_loss = 1.2521160596542145, disc_loss = 0.003920275805898343
Trained batch 712 in epoch 1, gen_loss = 1.2520783414011416, disc_loss = 0.003916353436908914
Trained batch 713 in epoch 1, gen_loss = 1.2519832206707375, disc_loss = 0.003913327025962767
Trained batch 714 in epoch 1, gen_loss = 1.2516534483516133, disc_loss = 0.003911407392144763
Trained batch 715 in epoch 1, gen_loss = 1.2521108217412533, disc_loss = 0.003910997556286731
Trained batch 716 in epoch 1, gen_loss = 1.25185260297198, disc_loss = 0.003910966956885038
Trained batch 717 in epoch 1, gen_loss = 1.2518164264790528, disc_loss = 0.0039071255104670116
Trained batch 718 in epoch 1, gen_loss = 1.2516046495530468, disc_loss = 0.0039027663943456857
Trained batch 719 in epoch 1, gen_loss = 1.251479898724291, disc_loss = 0.003898764152796098
Trained batch 720 in epoch 1, gen_loss = 1.2514898679458153, disc_loss = 0.003894219712049722
Trained batch 721 in epoch 1, gen_loss = 1.251188826693062, disc_loss = 0.003890200462967862
Trained batch 722 in epoch 1, gen_loss = 1.251184991121622, disc_loss = 0.003885681693962895
Trained batch 723 in epoch 1, gen_loss = 1.2511862649772707, disc_loss = 0.003881385582021646
Trained batch 724 in epoch 1, gen_loss = 1.251272821755245, disc_loss = 0.003877310965105827
Trained batch 725 in epoch 1, gen_loss = 1.2511916820667992, disc_loss = 0.0038730381753795317
Trained batch 726 in epoch 1, gen_loss = 1.2512316756268151, disc_loss = 0.0038692131196164706
Trained batch 727 in epoch 1, gen_loss = 1.2513796561039412, disc_loss = 0.0038658164528817076
Trained batch 728 in epoch 1, gen_loss = 1.251336959817936, disc_loss = 0.00386142168849271
Trained batch 729 in epoch 1, gen_loss = 1.2512999919995869, disc_loss = 0.003857030578664096
Trained batch 730 in epoch 1, gen_loss = 1.2512777804023754, disc_loss = 0.0038526766348955708
Trained batch 731 in epoch 1, gen_loss = 1.2515182195465422, disc_loss = 0.0038486881334034986
Trained batch 732 in epoch 1, gen_loss = 1.2512585180030187, disc_loss = 0.003844932767876715
Trained batch 733 in epoch 1, gen_loss = 1.2518721188771302, disc_loss = 0.003840701049677482
Trained batch 734 in epoch 1, gen_loss = 1.251877806462398, disc_loss = 0.0038364340828772837
Trained batch 735 in epoch 1, gen_loss = 1.2517523775282113, disc_loss = 0.003832123213412516
Trained batch 736 in epoch 1, gen_loss = 1.2518552954193696, disc_loss = 0.003829532943792664
Trained batch 737 in epoch 1, gen_loss = 1.2516538820615628, disc_loss = 0.0038255720440254783
Trained batch 738 in epoch 1, gen_loss = 1.2514488648658515, disc_loss = 0.003821424350162328
Trained batch 739 in epoch 1, gen_loss = 1.2512489160975895, disc_loss = 0.0038170709612549633
Trained batch 740 in epoch 1, gen_loss = 1.2516161748754833, disc_loss = 0.003812584460091773
Trained batch 741 in epoch 1, gen_loss = 1.2513079188583354, disc_loss = 0.0038084461668056293
Trained batch 742 in epoch 1, gen_loss = 1.2510944803823212, disc_loss = 0.003804837168602669
Trained batch 743 in epoch 1, gen_loss = 1.2512634997406313, disc_loss = 0.0038002680926330222
Trained batch 744 in epoch 1, gen_loss = 1.2512278027182457, disc_loss = 0.0037962405266155855
Trained batch 745 in epoch 1, gen_loss = 1.2515969770203965, disc_loss = 0.003792141760075552
Trained batch 746 in epoch 1, gen_loss = 1.251417714429189, disc_loss = 0.0037888580114799494
Trained batch 747 in epoch 1, gen_loss = 1.2513576677457534, disc_loss = 0.0037847100467969575
Trained batch 748 in epoch 1, gen_loss = 1.2513325180962822, disc_loss = 0.0037819227634339116
Trained batch 749 in epoch 1, gen_loss = 1.251186140537262, disc_loss = 0.003779424782881203
Trained batch 750 in epoch 1, gen_loss = 1.2510462075511561, disc_loss = 0.003775082650625726
Trained batch 751 in epoch 1, gen_loss = 1.2513625531437549, disc_loss = 0.0037711932456775377
Trained batch 752 in epoch 1, gen_loss = 1.2511494883186471, disc_loss = 0.00376711654416372
Trained batch 753 in epoch 1, gen_loss = 1.2511599198260421, disc_loss = 0.003762962103184295
Trained batch 754 in epoch 1, gen_loss = 1.2512944264127719, disc_loss = 0.003759068522304728
Trained batch 755 in epoch 1, gen_loss = 1.2512650494537656, disc_loss = 0.0037551020661590094
Trained batch 756 in epoch 1, gen_loss = 1.2510584784939864, disc_loss = 0.0037522407234698665
Trained batch 757 in epoch 1, gen_loss = 1.251009097199956, disc_loss = 0.0037489709794741874
Trained batch 758 in epoch 1, gen_loss = 1.2508889369185576, disc_loss = 0.0037454907467256867
Trained batch 759 in epoch 1, gen_loss = 1.250818394673498, disc_loss = 0.0037420503702857164
Trained batch 760 in epoch 1, gen_loss = 1.2508851194193735, disc_loss = 0.003737810186657176
Trained batch 761 in epoch 1, gen_loss = 1.2509510335646903, disc_loss = 0.003733537986569334
Trained batch 762 in epoch 1, gen_loss = 1.2512781298176177, disc_loss = 0.0037304044216044303
Trained batch 763 in epoch 1, gen_loss = 1.2514685280035929, disc_loss = 0.003726865994051911
Trained batch 764 in epoch 1, gen_loss = 1.2513457969902388, disc_loss = 0.003724229348757992
Trained batch 765 in epoch 1, gen_loss = 1.251382373487358, disc_loss = 0.0037211265861237294
Trained batch 766 in epoch 1, gen_loss = 1.2515101067556706, disc_loss = 0.0037171370495153854
Trained batch 767 in epoch 1, gen_loss = 1.2512893190917869, disc_loss = 0.003713310391920762
Trained batch 768 in epoch 1, gen_loss = 1.251064220547521, disc_loss = 0.0037095316929693645
Trained batch 769 in epoch 1, gen_loss = 1.2513655674922002, disc_loss = 0.0037055241568059384
Trained batch 770 in epoch 1, gen_loss = 1.2514341373851792, disc_loss = 0.0037014314108096357
Trained batch 771 in epoch 1, gen_loss = 1.2516999480946693, disc_loss = 0.0036972969977551264
Trained batch 772 in epoch 1, gen_loss = 1.2518848820769, disc_loss = 0.003693629198948302
Trained batch 773 in epoch 1, gen_loss = 1.2521075104250157, disc_loss = 0.0036899639378606824
Trained batch 774 in epoch 1, gen_loss = 1.252031256614193, disc_loss = 0.0036861224649398917
Trained batch 775 in epoch 1, gen_loss = 1.2521017763725262, disc_loss = 0.0036820337611305188
Trained batch 776 in epoch 1, gen_loss = 1.2520107659900817, disc_loss = 0.0036786994772098425
Trained batch 777 in epoch 1, gen_loss = 1.252136764458948, disc_loss = 0.0036750267678228323
Trained batch 778 in epoch 1, gen_loss = 1.2519027977148895, disc_loss = 0.0036712855021651613
Trained batch 779 in epoch 1, gen_loss = 1.2517059673101474, disc_loss = 0.003667360540436139
Trained batch 780 in epoch 1, gen_loss = 1.2516969063828451, disc_loss = 0.003663296863341599
Trained batch 781 in epoch 1, gen_loss = 1.2516338941081406, disc_loss = 0.0036594270653126505
Trained batch 782 in epoch 1, gen_loss = 1.251415208533958, disc_loss = 0.0036555159319829112
Trained batch 783 in epoch 1, gen_loss = 1.2513542906666288, disc_loss = 0.003652393638341372
Trained batch 784 in epoch 1, gen_loss = 1.2510600357298638, disc_loss = 0.0036487303396529713
Trained batch 785 in epoch 1, gen_loss = 1.250774564330511, disc_loss = 0.003645111768959391
Trained batch 786 in epoch 1, gen_loss = 1.2507291865621468, disc_loss = 0.00364126694384102
Trained batch 787 in epoch 1, gen_loss = 1.250511347491124, disc_loss = 0.003637206854839717
Trained batch 788 in epoch 1, gen_loss = 1.2505174446166392, disc_loss = 0.0036332746129232154
Trained batch 789 in epoch 1, gen_loss = 1.2503746289241162, disc_loss = 0.0036295546043761473
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 1.1089857816696167, disc_loss = 0.0008346950053237379
Trained batch 1 in epoch 2, gen_loss = 1.208281695842743, disc_loss = 0.0008563384471926838
Trained batch 2 in epoch 2, gen_loss = 1.1533802350362141, disc_loss = 0.0016300396722120543
Trained batch 3 in epoch 2, gen_loss = 1.1552671790122986, disc_loss = 0.0016134272591443732
Trained batch 4 in epoch 2, gen_loss = 1.1840691328048707, disc_loss = 0.001455062406603247
Trained batch 5 in epoch 2, gen_loss = 1.1974538564682007, disc_loss = 0.001324335316894576
Trained batch 6 in epoch 2, gen_loss = 1.1922132628304618, disc_loss = 0.0012153041731965328
Trained batch 7 in epoch 2, gen_loss = 1.2331558614969254, disc_loss = 0.0011487936935736798
Trained batch 8 in epoch 2, gen_loss = 1.2336724996566772, disc_loss = 0.001158410094730142
Trained batch 9 in epoch 2, gen_loss = 1.2171530961990356, disc_loss = 0.0011284452630206943
Trained batch 10 in epoch 2, gen_loss = 1.2453761100769043, disc_loss = 0.0010682140180671756
Trained batch 11 in epoch 2, gen_loss = 1.235603352387746, disc_loss = 0.001026849776584034
Trained batch 12 in epoch 2, gen_loss = 1.2278674657528217, disc_loss = 0.0009933877557229537
Trained batch 13 in epoch 2, gen_loss = 1.2391882368496485, disc_loss = 0.0009740971436258405
Trained batch 14 in epoch 2, gen_loss = 1.2279417912165325, disc_loss = 0.0009638159962681432
Trained batch 15 in epoch 2, gen_loss = 1.216422937810421, disc_loss = 0.0009678717578935903
Trained batch 16 in epoch 2, gen_loss = 1.221994869849261, disc_loss = 0.0009478884577915511
Trained batch 17 in epoch 2, gen_loss = 1.2303558786710103, disc_loss = 0.0009381305976098196
Trained batch 18 in epoch 2, gen_loss = 1.224847348112809, disc_loss = 0.0009145622025243938
Trained batch 19 in epoch 2, gen_loss = 1.221921330690384, disc_loss = 0.0009055224945768714
Trained batch 20 in epoch 2, gen_loss = 1.2231259516307287, disc_loss = 0.000913729780309257
Trained batch 21 in epoch 2, gen_loss = 1.2194922783158042, disc_loss = 0.0009457120428454469
Trained batch 22 in epoch 2, gen_loss = 1.2218695723492166, disc_loss = 0.0009397697513518126
Trained batch 23 in epoch 2, gen_loss = 1.2183491935332615, disc_loss = 0.0009239093099798387
Trained batch 24 in epoch 2, gen_loss = 1.2108604335784912, disc_loss = 0.0009123629750683904
Trained batch 25 in epoch 2, gen_loss = 1.2191296540773833, disc_loss = 0.0008977120249675444
Trained batch 26 in epoch 2, gen_loss = 1.2128177837089256, disc_loss = 0.0008915191542150246
Trained batch 27 in epoch 2, gen_loss = 1.2145885867731911, disc_loss = 0.0008745412155154295
Trained batch 28 in epoch 2, gen_loss = 1.2196681869441066, disc_loss = 0.0008814320036467036
Trained batch 29 in epoch 2, gen_loss = 1.2226150711377461, disc_loss = 0.0008802748653882494
Trained batch 30 in epoch 2, gen_loss = 1.224483613044985, disc_loss = 0.0008694640672465246
Trained batch 31 in epoch 2, gen_loss = 1.2283803634345531, disc_loss = 0.0009016424901346909
Trained batch 32 in epoch 2, gen_loss = 1.2310012940204504, disc_loss = 0.000901298574524734
Trained batch 33 in epoch 2, gen_loss = 1.2299414732876945, disc_loss = 0.0008923700301880565
Trained batch 34 in epoch 2, gen_loss = 1.2266924789973668, disc_loss = 0.0008880164357833564
Trained batch 35 in epoch 2, gen_loss = 1.2267400092548795, disc_loss = 0.0008824111104735897
Trained batch 36 in epoch 2, gen_loss = 1.2240431566496153, disc_loss = 0.0008687503632736971
Trained batch 37 in epoch 2, gen_loss = 1.2234614616946171, disc_loss = 0.0008625463922630603
Trained batch 38 in epoch 2, gen_loss = 1.222475794645456, disc_loss = 0.0008693220293841874
Trained batch 39 in epoch 2, gen_loss = 1.2302355855703353, disc_loss = 0.0008668895068694837
Trained batch 40 in epoch 2, gen_loss = 1.234218411329316, disc_loss = 0.0008644733092429616
Trained batch 41 in epoch 2, gen_loss = 1.2326535100028628, disc_loss = 0.0008547518671201985
Trained batch 42 in epoch 2, gen_loss = 1.234677652980006, disc_loss = 0.0008690043820912928
Trained batch 43 in epoch 2, gen_loss = 1.233820909803564, disc_loss = 0.0008605427323015068
Trained batch 44 in epoch 2, gen_loss = 1.2332913213306003, disc_loss = 0.0008609943880906536
Trained batch 45 in epoch 2, gen_loss = 1.2300121291824009, disc_loss = 0.0008559594672355477
Trained batch 46 in epoch 2, gen_loss = 1.2313352823257446, disc_loss = 0.0008572729495155843
Trained batch 47 in epoch 2, gen_loss = 1.229672374824683, disc_loss = 0.0008535773170782098
Trained batch 48 in epoch 2, gen_loss = 1.2265329190662928, disc_loss = 0.0008468832369247565
Trained batch 49 in epoch 2, gen_loss = 1.22545574426651, disc_loss = 0.0008405272965319455
Trained batch 50 in epoch 2, gen_loss = 1.2232351303100586, disc_loss = 0.0008357301806373632
Trained batch 51 in epoch 2, gen_loss = 1.225152781376472, disc_loss = 0.000829497993646118
Trained batch 52 in epoch 2, gen_loss = 1.2224760550373006, disc_loss = 0.0008324848230980899
Trained batch 53 in epoch 2, gen_loss = 1.2277093331019084, disc_loss = 0.0008319368708827016
Trained batch 54 in epoch 2, gen_loss = 1.2257454503666272, disc_loss = 0.0008343712183308194
Trained batch 55 in epoch 2, gen_loss = 1.2229365089109965, disc_loss = 0.0008412456882069819
Trained batch 56 in epoch 2, gen_loss = 1.2226828796821727, disc_loss = 0.0008398093663057999
Trained batch 57 in epoch 2, gen_loss = 1.220139887826196, disc_loss = 0.0008439409389995552
Trained batch 58 in epoch 2, gen_loss = 1.2261211225541973, disc_loss = 0.0008493629382860105
Trained batch 59 in epoch 2, gen_loss = 1.2272371212641398, disc_loss = 0.0008433322524069809
Trained batch 60 in epoch 2, gen_loss = 1.2261111267277451, disc_loss = 0.0008450659821153481
Trained batch 61 in epoch 2, gen_loss = 1.23279623446926, disc_loss = 0.0008467885486278383
Trained batch 62 in epoch 2, gen_loss = 1.2307664080271645, disc_loss = 0.0008589890032511441
Trained batch 63 in epoch 2, gen_loss = 1.232967171818018, disc_loss = 0.0008679818406562845
Trained batch 64 in epoch 2, gen_loss = 1.2320368124888494, disc_loss = 0.0008716000642520018
Trained batch 65 in epoch 2, gen_loss = 1.2291623444268198, disc_loss = 0.0008819302050996515
Trained batch 66 in epoch 2, gen_loss = 1.2302276091789133, disc_loss = 0.0008802648686713525
Trained batch 67 in epoch 2, gen_loss = 1.2308201404178845, disc_loss = 0.0008882095627247027
Trained batch 68 in epoch 2, gen_loss = 1.231928472933562, disc_loss = 0.0008885704366443003
Trained batch 69 in epoch 2, gen_loss = 1.2363551139831543, disc_loss = 0.0008835595096960397
Trained batch 70 in epoch 2, gen_loss = 1.2354587669103918, disc_loss = 0.0008815938748688187
Trained batch 71 in epoch 2, gen_loss = 1.2367180585861206, disc_loss = 0.0008815123878270646
Trained batch 72 in epoch 2, gen_loss = 1.238620202835292, disc_loss = 0.0008805965122045975
Trained batch 73 in epoch 2, gen_loss = 1.2371840348114838, disc_loss = 0.000881081070621951
Trained batch 74 in epoch 2, gen_loss = 1.2365842803319296, disc_loss = 0.0008853342799314608
Trained batch 75 in epoch 2, gen_loss = 1.2341099052052749, disc_loss = 0.0008885675308288467
Trained batch 76 in epoch 2, gen_loss = 1.2363421808589588, disc_loss = 0.0008840908613146658
Trained batch 77 in epoch 2, gen_loss = 1.2369540761678646, disc_loss = 0.0008813026775337326
Trained batch 78 in epoch 2, gen_loss = 1.237332236917713, disc_loss = 0.0008946060305431815
Trained batch 79 in epoch 2, gen_loss = 1.234733435511589, disc_loss = 0.0009029819306306308
Trained batch 80 in epoch 2, gen_loss = 1.2359839957437397, disc_loss = 0.0009011528551733742
Trained batch 81 in epoch 2, gen_loss = 1.2373454803373756, disc_loss = 0.0008968939162114998
Trained batch 82 in epoch 2, gen_loss = 1.2394969348447868, disc_loss = 0.0008913210950124201
Trained batch 83 in epoch 2, gen_loss = 1.2396235820792971, disc_loss = 0.0008890349989607264
Trained batch 84 in epoch 2, gen_loss = 1.2408166983548332, disc_loss = 0.0008880422344458673
Trained batch 85 in epoch 2, gen_loss = 1.243572980858559, disc_loss = 0.0008849972973409823
Trained batch 86 in epoch 2, gen_loss = 1.244784209920072, disc_loss = 0.0008806835330792585
Trained batch 87 in epoch 2, gen_loss = 1.2433193082159215, disc_loss = 0.0008797905019574417
Trained batch 88 in epoch 2, gen_loss = 1.2424069308163075, disc_loss = 0.000875130205825913
Trained batch 89 in epoch 2, gen_loss = 1.2420791943868001, disc_loss = 0.0008720839412287913
Trained batch 90 in epoch 2, gen_loss = 1.2422610390317308, disc_loss = 0.0008676813737550689
Trained batch 91 in epoch 2, gen_loss = 1.2422769782335863, disc_loss = 0.0008635201685019242
Trained batch 92 in epoch 2, gen_loss = 1.2393289766004008, disc_loss = 0.0008592506957000062
Trained batch 93 in epoch 2, gen_loss = 1.2428390979766846, disc_loss = 0.0008596147242140897
Trained batch 94 in epoch 2, gen_loss = 1.2428732746525815, disc_loss = 0.0008597714452710199
Trained batch 95 in epoch 2, gen_loss = 1.2447361747423809, disc_loss = 0.0008573208961024648
Trained batch 96 in epoch 2, gen_loss = 1.2439237279990285, disc_loss = 0.0008585011789373593
Trained batch 97 in epoch 2, gen_loss = 1.2435418416042716, disc_loss = 0.0008612436733009028
Trained batch 98 in epoch 2, gen_loss = 1.241434835424327, disc_loss = 0.0008612088335800276
Trained batch 99 in epoch 2, gen_loss = 1.241487432718277, disc_loss = 0.0008593236765591427
Trained batch 100 in epoch 2, gen_loss = 1.2430370031016889, disc_loss = 0.0008555266736444123
Trained batch 101 in epoch 2, gen_loss = 1.2424511477059008, disc_loss = 0.000854014508613367
Trained batch 102 in epoch 2, gen_loss = 1.2428551021131498, disc_loss = 0.0008527875953643284
Trained batch 103 in epoch 2, gen_loss = 1.2417258482712965, disc_loss = 0.0008532342802097376
Trained batch 104 in epoch 2, gen_loss = 1.2416645140874953, disc_loss = 0.000854187062387133
Trained batch 105 in epoch 2, gen_loss = 1.243246703777673, disc_loss = 0.000852177408853335
Trained batch 106 in epoch 2, gen_loss = 1.2437708589518182, disc_loss = 0.0008490954185226741
Trained batch 107 in epoch 2, gen_loss = 1.243310006680312, disc_loss = 0.000849858671750149
Trained batch 108 in epoch 2, gen_loss = 1.242041287072208, disc_loss = 0.0008518548533875803
Trained batch 109 in epoch 2, gen_loss = 1.243049470944838, disc_loss = 0.0008497055080211298
Trained batch 110 in epoch 2, gen_loss = 1.2412517811800983, disc_loss = 0.0008467320643306651
Trained batch 111 in epoch 2, gen_loss = 1.2411893552967481, disc_loss = 0.0008431701618454619
Trained batch 112 in epoch 2, gen_loss = 1.2418971726324706, disc_loss = 0.0008395712238538648
Trained batch 113 in epoch 2, gen_loss = 1.241003733977937, disc_loss = 0.0008369927889904367
Trained batch 114 in epoch 2, gen_loss = 1.2408941300018974, disc_loss = 0.0008324815400714135
Trained batch 115 in epoch 2, gen_loss = 1.2396000356509769, disc_loss = 0.0008279146046522234
Trained batch 116 in epoch 2, gen_loss = 1.238503859593318, disc_loss = 0.0008255557592910451
Trained batch 117 in epoch 2, gen_loss = 1.2392932843353788, disc_loss = 0.0008231763026511328
Trained batch 118 in epoch 2, gen_loss = 1.2380150436353283, disc_loss = 0.0008199232025854603
Trained batch 119 in epoch 2, gen_loss = 1.238032936056455, disc_loss = 0.0008190109559412425
Trained batch 120 in epoch 2, gen_loss = 1.2369216286446438, disc_loss = 0.000818908118358082
Trained batch 121 in epoch 2, gen_loss = 1.2388723238569792, disc_loss = 0.0008160660113017152
Trained batch 122 in epoch 2, gen_loss = 1.2387858105868828, disc_loss = 0.0008142222532040886
Trained batch 123 in epoch 2, gen_loss = 1.238798524102857, disc_loss = 0.0008113241947871904
Trained batch 124 in epoch 2, gen_loss = 1.2371282205581664, disc_loss = 0.0008135782955214381
Trained batch 125 in epoch 2, gen_loss = 1.2358948191006978, disc_loss = 0.000813454775775354
Trained batch 126 in epoch 2, gen_loss = 1.2352006763923826, disc_loss = 0.0008186013841136234
Trained batch 127 in epoch 2, gen_loss = 1.2375959577038884, disc_loss = 0.0008262258006652701
Trained batch 128 in epoch 2, gen_loss = 1.236441082732622, disc_loss = 0.0008361188599175607
Trained batch 129 in epoch 2, gen_loss = 1.235510949905102, disc_loss = 0.0008435956793479048
Trained batch 130 in epoch 2, gen_loss = 1.2370486432359418, disc_loss = 0.0008473200776848857
Trained batch 131 in epoch 2, gen_loss = 1.2369205382737247, disc_loss = 0.0008477469157448716
Trained batch 132 in epoch 2, gen_loss = 1.237466796000201, disc_loss = 0.0008446733837971758
Trained batch 133 in epoch 2, gen_loss = 1.2373524495025179, disc_loss = 0.0008449099352843921
Trained batch 134 in epoch 2, gen_loss = 1.2385811973501135, disc_loss = 0.0008448754154852833
Trained batch 135 in epoch 2, gen_loss = 1.2397244739181854, disc_loss = 0.0008428949515612604
Trained batch 136 in epoch 2, gen_loss = 1.2394528197546075, disc_loss = 0.0008412469388750538
Trained batch 137 in epoch 2, gen_loss = 1.2420951110729272, disc_loss = 0.0008404354901859483
Trained batch 138 in epoch 2, gen_loss = 1.242024953416783, disc_loss = 0.0008380484870691925
Trained batch 139 in epoch 2, gen_loss = 1.24257418853896, disc_loss = 0.0008356563844634885
Trained batch 140 in epoch 2, gen_loss = 1.241497740677908, disc_loss = 0.0008332557769422915
Trained batch 141 in epoch 2, gen_loss = 1.2411570188025354, disc_loss = 0.0008314410058542116
Trained batch 142 in epoch 2, gen_loss = 1.23951134398267, disc_loss = 0.0008300075775999055
Trained batch 143 in epoch 2, gen_loss = 1.2415240613950624, disc_loss = 0.0008323910593996212
Trained batch 144 in epoch 2, gen_loss = 1.2409280349468363, disc_loss = 0.0008303476684196885
Trained batch 145 in epoch 2, gen_loss = 1.2421884577568263, disc_loss = 0.0008287948457769769
Trained batch 146 in epoch 2, gen_loss = 1.241393273379527, disc_loss = 0.0008272173314364817
Trained batch 147 in epoch 2, gen_loss = 1.240813681402722, disc_loss = 0.0008267403402872308
Trained batch 148 in epoch 2, gen_loss = 1.241198205307826, disc_loss = 0.0008261834871689571
Trained batch 149 in epoch 2, gen_loss = 1.240199654897054, disc_loss = 0.0008239019763035079
Trained batch 150 in epoch 2, gen_loss = 1.2395445637355578, disc_loss = 0.0008216974994673437
Trained batch 151 in epoch 2, gen_loss = 1.238170953957658, disc_loss = 0.0008192270123752104
Trained batch 152 in epoch 2, gen_loss = 1.2378802946190428, disc_loss = 0.000817035089568022
Trained batch 153 in epoch 2, gen_loss = 1.2379286730444277, disc_loss = 0.0008161831059411483
Trained batch 154 in epoch 2, gen_loss = 1.237358295532965, disc_loss = 0.000814531545432645
Trained batch 155 in epoch 2, gen_loss = 1.2366183423078978, disc_loss = 0.0008153494588138225
Trained batch 156 in epoch 2, gen_loss = 1.2363738960521236, disc_loss = 0.000820392938694104
Trained batch 157 in epoch 2, gen_loss = 1.2357176489467863, disc_loss = 0.0008223122761281254
Trained batch 158 in epoch 2, gen_loss = 1.235543926556905, disc_loss = 0.0008202096604399454
Trained batch 159 in epoch 2, gen_loss = 1.2344841994345188, disc_loss = 0.0008179684688002453
Trained batch 160 in epoch 2, gen_loss = 1.2337253041889356, disc_loss = 0.000818762830812889
Trained batch 161 in epoch 2, gen_loss = 1.2329200910933225, disc_loss = 0.000816700523747936
Trained batch 162 in epoch 2, gen_loss = 1.2337176382907329, disc_loss = 0.0008163527550570027
Trained batch 163 in epoch 2, gen_loss = 1.2343852505451296, disc_loss = 0.0008142724245993943
Trained batch 164 in epoch 2, gen_loss = 1.2348841501004768, disc_loss = 0.000811654183075227
Trained batch 165 in epoch 2, gen_loss = 1.2349207896784127, disc_loss = 0.0008101647894013202
Trained batch 166 in epoch 2, gen_loss = 1.2348043247611222, disc_loss = 0.0008073862484157152
Trained batch 167 in epoch 2, gen_loss = 1.2338508324963706, disc_loss = 0.0008065286090727785
Trained batch 168 in epoch 2, gen_loss = 1.2336511343893921, disc_loss = 0.0008110489030492619
Trained batch 169 in epoch 2, gen_loss = 1.2329503641409032, disc_loss = 0.000816759531324565
Trained batch 170 in epoch 2, gen_loss = 1.2325844966877273, disc_loss = 0.000818496491529908
Trained batch 171 in epoch 2, gen_loss = 1.2323680478473042, disc_loss = 0.0008163582181644648
Trained batch 172 in epoch 2, gen_loss = 1.2321277684559022, disc_loss = 0.0008131372680109684
Trained batch 173 in epoch 2, gen_loss = 1.2319993657627324, disc_loss = 0.000810101733344939
Trained batch 174 in epoch 2, gen_loss = 1.231672386441912, disc_loss = 0.0008082511871387916
Trained batch 175 in epoch 2, gen_loss = 1.2322548668492923, disc_loss = 0.0008070914260646201
Trained batch 176 in epoch 2, gen_loss = 1.2311682357626446, disc_loss = 0.0008062848937697709
Trained batch 177 in epoch 2, gen_loss = 1.2301963514156555, disc_loss = 0.000805802982407779
Trained batch 178 in epoch 2, gen_loss = 1.2300296648920581, disc_loss = 0.0008045520751175143
Trained batch 179 in epoch 2, gen_loss = 1.2300336678822836, disc_loss = 0.0008025613196271782
Trained batch 180 in epoch 2, gen_loss = 1.2297005271384729, disc_loss = 0.0008014168320815414
Trained batch 181 in epoch 2, gen_loss = 1.2287019176797553, disc_loss = 0.0008005432443626757
Trained batch 182 in epoch 2, gen_loss = 1.2276667336948583, disc_loss = 0.0007981748156035777
Trained batch 183 in epoch 2, gen_loss = 1.227080858272055, disc_loss = 0.0007971288802724777
Trained batch 184 in epoch 2, gen_loss = 1.2276096459981558, disc_loss = 0.0007969635888002812
Trained batch 185 in epoch 2, gen_loss = 1.2274686386508327, disc_loss = 0.0007990829083913317
Trained batch 186 in epoch 2, gen_loss = 1.228135926838227, disc_loss = 0.0008029317409223454
Trained batch 187 in epoch 2, gen_loss = 1.2277552219147378, disc_loss = 0.0008069826373607514
Trained batch 188 in epoch 2, gen_loss = 1.2269822983514695, disc_loss = 0.000812373859820168
Trained batch 189 in epoch 2, gen_loss = 1.22635810751664, disc_loss = 0.0008235182089265436
Trained batch 190 in epoch 2, gen_loss = 1.2278594789704727, disc_loss = 0.0008373223613893994
Trained batch 191 in epoch 2, gen_loss = 1.2292697199930747, disc_loss = 0.0008414464067148705
Trained batch 192 in epoch 2, gen_loss = 1.2291424157088284, disc_loss = 0.0008412890930640767
Trained batch 193 in epoch 2, gen_loss = 1.228246417856708, disc_loss = 0.0008443545411489712
Trained batch 194 in epoch 2, gen_loss = 1.227979065821721, disc_loss = 0.0008456178812477261
Trained batch 195 in epoch 2, gen_loss = 1.2271916805481424, disc_loss = 0.000847952485818663
Trained batch 196 in epoch 2, gen_loss = 1.2270612395959457, disc_loss = 0.000849814171049517
Trained batch 197 in epoch 2, gen_loss = 1.2275709341270755, disc_loss = 0.0008504758439040884
Trained batch 198 in epoch 2, gen_loss = 1.2275871853133542, disc_loss = 0.0008488080859764586
Trained batch 199 in epoch 2, gen_loss = 1.2267998462915422, disc_loss = 0.000848488166811876
Trained batch 200 in epoch 2, gen_loss = 1.2268625201277472, disc_loss = 0.0008470623192738797
Trained batch 201 in epoch 2, gen_loss = 1.2266902681624536, disc_loss = 0.000846389991733808
Trained batch 202 in epoch 2, gen_loss = 1.2274622030446094, disc_loss = 0.0008480873657390475
Trained batch 203 in epoch 2, gen_loss = 1.2267335460466497, disc_loss = 0.0008489867671182854
Trained batch 204 in epoch 2, gen_loss = 1.2270636389895184, disc_loss = 0.0008469402753157405
Trained batch 205 in epoch 2, gen_loss = 1.226483918509437, disc_loss = 0.0008445822802492083
Trained batch 206 in epoch 2, gen_loss = 1.226415567352, disc_loss = 0.0008430837324296308
Trained batch 207 in epoch 2, gen_loss = 1.2253656106499524, disc_loss = 0.000841444335702153
Trained batch 208 in epoch 2, gen_loss = 1.2275588632200323, disc_loss = 0.0008400407775458947
Trained batch 209 in epoch 2, gen_loss = 1.2276239940098355, disc_loss = 0.0008401673590664618
Trained batch 210 in epoch 2, gen_loss = 1.2269963099493235, disc_loss = 0.0008438925695510678
Trained batch 211 in epoch 2, gen_loss = 1.2282052748608139, disc_loss = 0.0008503178024460245
Trained batch 212 in epoch 2, gen_loss = 1.2281970373341735, disc_loss = 0.0008544780519198486
Trained batch 213 in epoch 2, gen_loss = 1.2279315072799397, disc_loss = 0.0008572852145173265
Trained batch 214 in epoch 2, gen_loss = 1.2287048539450003, disc_loss = 0.0008572690880608334
Trained batch 215 in epoch 2, gen_loss = 1.2291828300114032, disc_loss = 0.00085593071748412
Trained batch 216 in epoch 2, gen_loss = 1.2289390036587342, disc_loss = 0.000853830398181625
Trained batch 217 in epoch 2, gen_loss = 1.2286644463145404, disc_loss = 0.0008529923927549426
Trained batch 218 in epoch 2, gen_loss = 1.2281047035025678, disc_loss = 0.0008525372291202806
Trained batch 219 in epoch 2, gen_loss = 1.2282235486940905, disc_loss = 0.0008527018938118338
Trained batch 220 in epoch 2, gen_loss = 1.227663973877333, disc_loss = 0.0008581524731420671
Trained batch 221 in epoch 2, gen_loss = 1.2282285072782018, disc_loss = 0.0008668505280175841
Trained batch 222 in epoch 2, gen_loss = 1.2283886959734518, disc_loss = 0.0008732099883465072
Trained batch 223 in epoch 2, gen_loss = 1.228109730673688, disc_loss = 0.0008746235724694478
Trained batch 224 in epoch 2, gen_loss = 1.2282554562886556, disc_loss = 0.0008733756228401843
Trained batch 225 in epoch 2, gen_loss = 1.2275878560226576, disc_loss = 0.0008714671523065051
Trained batch 226 in epoch 2, gen_loss = 1.228257845676943, disc_loss = 0.0008699064555071245
Trained batch 227 in epoch 2, gen_loss = 1.2273543769853157, disc_loss = 0.0008699628885727163
Trained batch 228 in epoch 2, gen_loss = 1.226641798123522, disc_loss = 0.0008701751216804795
Trained batch 229 in epoch 2, gen_loss = 1.226946103054544, disc_loss = 0.0008700625919078922
Trained batch 230 in epoch 2, gen_loss = 1.2271075764775792, disc_loss = 0.0008694848968713943
Trained batch 231 in epoch 2, gen_loss = 1.2268241047859192, disc_loss = 0.0008688835197094234
Trained batch 232 in epoch 2, gen_loss = 1.2267519056541214, disc_loss = 0.0008673459897767113
Trained batch 233 in epoch 2, gen_loss = 1.2264171716494439, disc_loss = 0.0008652037863806686
Trained batch 234 in epoch 2, gen_loss = 1.2266744486829069, disc_loss = 0.0008631359317657003
Trained batch 235 in epoch 2, gen_loss = 1.2272894953267048, disc_loss = 0.0008629062775348834
Trained batch 236 in epoch 2, gen_loss = 1.227210165076115, disc_loss = 0.0008646458876613952
Trained batch 237 in epoch 2, gen_loss = 1.2277309644122083, disc_loss = 0.0008681831757162361
Trained batch 238 in epoch 2, gen_loss = 1.22713445320289, disc_loss = 0.0008711216042878177
Trained batch 239 in epoch 2, gen_loss = 1.2265839904546738, disc_loss = 0.0008707308964706802
Trained batch 240 in epoch 2, gen_loss = 1.2266508236960256, disc_loss = 0.0008687585172256942
Trained batch 241 in epoch 2, gen_loss = 1.226201641658121, disc_loss = 0.0008692031006823286
Trained batch 242 in epoch 2, gen_loss = 1.225827752807994, disc_loss = 0.0008686856734863417
Trained batch 243 in epoch 2, gen_loss = 1.2249451929428539, disc_loss = 0.0008680270511235232
Trained batch 244 in epoch 2, gen_loss = 1.2248871092893638, disc_loss = 0.0008666038913509751
Trained batch 245 in epoch 2, gen_loss = 1.2246087963988141, disc_loss = 0.0008656462900315948
Trained batch 246 in epoch 2, gen_loss = 1.2238022856384154, disc_loss = 0.0008665728424006493
Trained batch 247 in epoch 2, gen_loss = 1.2233891328496318, disc_loss = 0.000867645548081078
Trained batch 248 in epoch 2, gen_loss = 1.2240471040388667, disc_loss = 0.0008681758734010475
Trained batch 249 in epoch 2, gen_loss = 1.224149661064148, disc_loss = 0.0008680532266153023
Trained batch 250 in epoch 2, gen_loss = 1.2244557166004562, disc_loss = 0.0008673844971476991
Trained batch 251 in epoch 2, gen_loss = 1.224166901811721, disc_loss = 0.0008679990568207503
Trained batch 252 in epoch 2, gen_loss = 1.2243899248334258, disc_loss = 0.0008701056766778363
Trained batch 253 in epoch 2, gen_loss = 1.2249233520875766, disc_loss = 0.0008720657353951251
Trained batch 254 in epoch 2, gen_loss = 1.2245718619402717, disc_loss = 0.0008753410651229834
Trained batch 255 in epoch 2, gen_loss = 1.2247742731124163, disc_loss = 0.000876243122206688
Trained batch 256 in epoch 2, gen_loss = 1.2246311304634183, disc_loss = 0.0008766184462884855
Trained batch 257 in epoch 2, gen_loss = 1.2244905094767726, disc_loss = 0.00087704198818939
Trained batch 258 in epoch 2, gen_loss = 1.2236788885013477, disc_loss = 0.0008769138424223987
Trained batch 259 in epoch 2, gen_loss = 1.2233851496989911, disc_loss = 0.0008766115706888601
Trained batch 260 in epoch 2, gen_loss = 1.223111096926576, disc_loss = 0.0008760568048221584
Trained batch 261 in epoch 2, gen_loss = 1.2223012738555443, disc_loss = 0.0008747684410533278
Trained batch 262 in epoch 2, gen_loss = 1.2233584888081133, disc_loss = 0.0008756487291463838
Trained batch 263 in epoch 2, gen_loss = 1.2231601616649916, disc_loss = 0.0008751489452455038
Trained batch 264 in epoch 2, gen_loss = 1.2231093033304754, disc_loss = 0.0008754021418939854
Trained batch 265 in epoch 2, gen_loss = 1.223842329996869, disc_loss = 0.0008751779635606642
Trained batch 266 in epoch 2, gen_loss = 1.2236788589856151, disc_loss = 0.0008745296106783653
Trained batch 267 in epoch 2, gen_loss = 1.2240393344146103, disc_loss = 0.000874200431954067
Trained batch 268 in epoch 2, gen_loss = 1.2237438597200527, disc_loss = 0.0008743357539331007
Trained batch 269 in epoch 2, gen_loss = 1.2242612295680575, disc_loss = 0.0008762253173497608
Trained batch 270 in epoch 2, gen_loss = 1.2246754877681663, disc_loss = 0.0008800555729587318
Trained batch 271 in epoch 2, gen_loss = 1.2245061068850405, disc_loss = 0.0008827004118810531
Trained batch 272 in epoch 2, gen_loss = 1.2247162459097503, disc_loss = 0.0008821862236120748
Trained batch 273 in epoch 2, gen_loss = 1.2247054385442804, disc_loss = 0.0008810566126217685
Trained batch 274 in epoch 2, gen_loss = 1.2246711739626799, disc_loss = 0.0008804425655398518
Trained batch 275 in epoch 2, gen_loss = 1.224330541016399, disc_loss = 0.0008796039806127184
Trained batch 276 in epoch 2, gen_loss = 1.2238739608427247, disc_loss = 0.0008779036080580715
Trained batch 277 in epoch 2, gen_loss = 1.2237712908134186, disc_loss = 0.0008761535698913118
Trained batch 278 in epoch 2, gen_loss = 1.2243543470204945, disc_loss = 0.0008750385573504352
Trained batch 279 in epoch 2, gen_loss = 1.2243494519165583, disc_loss = 0.0008743686638938795
Trained batch 280 in epoch 2, gen_loss = 1.2242396938419002, disc_loss = 0.0008726234181562035
Trained batch 281 in epoch 2, gen_loss = 1.2241938849712939, disc_loss = 0.000873723625063447
Trained batch 282 in epoch 2, gen_loss = 1.223291035886367, disc_loss = 0.0008771531139878892
Trained batch 283 in epoch 2, gen_loss = 1.2231562580441084, disc_loss = 0.0008781929041298342
Trained batch 284 in epoch 2, gen_loss = 1.222444634897667, disc_loss = 0.0008811234222855746
Trained batch 285 in epoch 2, gen_loss = 1.2227968321396754, disc_loss = 0.000882596679119771
Trained batch 286 in epoch 2, gen_loss = 1.22285987878095, disc_loss = 0.0008817632467232852
Trained batch 287 in epoch 2, gen_loss = 1.2224983972393804, disc_loss = 0.0008816294593998464
Trained batch 288 in epoch 2, gen_loss = 1.2230301903605874, disc_loss = 0.0008809650081184057
Trained batch 289 in epoch 2, gen_loss = 1.2224244802162565, disc_loss = 0.0008802654882009816
Trained batch 290 in epoch 2, gen_loss = 1.2224662412482847, disc_loss = 0.0008804512678651952
Trained batch 291 in epoch 2, gen_loss = 1.222376120621211, disc_loss = 0.0008806826346250864
Trained batch 292 in epoch 2, gen_loss = 1.2230991289884157, disc_loss = 0.0008810782861107572
Trained batch 293 in epoch 2, gen_loss = 1.2228782422283069, disc_loss = 0.0008822565224753427
Trained batch 294 in epoch 2, gen_loss = 1.222618702104536, disc_loss = 0.0008848218624164366
Trained batch 295 in epoch 2, gen_loss = 1.2221267547559094, disc_loss = 0.0008879763404980327
Trained batch 296 in epoch 2, gen_loss = 1.2212944779331836, disc_loss = 0.000894143261205129
Trained batch 297 in epoch 2, gen_loss = 1.2212166312156907, disc_loss = 0.0009027158229333667
Trained batch 298 in epoch 2, gen_loss = 1.220976211354884, disc_loss = 0.0009114771271918754
Trained batch 299 in epoch 2, gen_loss = 1.2211427932977676, disc_loss = 0.000914967738596412
Trained batch 300 in epoch 2, gen_loss = 1.2209042708739093, disc_loss = 0.000915308736080607
Trained batch 301 in epoch 2, gen_loss = 1.220720901986621, disc_loss = 0.000913967372655301
Trained batch 302 in epoch 2, gen_loss = 1.2204652137488816, disc_loss = 0.0009122115295540185
Trained batch 303 in epoch 2, gen_loss = 1.2207171185628365, disc_loss = 0.0009106284910797656
Trained batch 304 in epoch 2, gen_loss = 1.2208755682726375, disc_loss = 0.0009088172592589112
Trained batch 305 in epoch 2, gen_loss = 1.2211944871868183, disc_loss = 0.0009075866961163877
Trained batch 306 in epoch 2, gen_loss = 1.220770361563282, disc_loss = 0.0009058531015771608
Trained batch 307 in epoch 2, gen_loss = 1.2213964371325134, disc_loss = 0.0009043330859427655
Trained batch 308 in epoch 2, gen_loss = 1.2215797887650894, disc_loss = 0.0009045763901761857
Trained batch 309 in epoch 2, gen_loss = 1.221088820311331, disc_loss = 0.0009042368607497924
Trained batch 310 in epoch 2, gen_loss = 1.2205913735739289, disc_loss = 0.00090296740632076
Trained batch 311 in epoch 2, gen_loss = 1.2210420994804456, disc_loss = 0.000902235396680249
Trained batch 312 in epoch 2, gen_loss = 1.2217126629603938, disc_loss = 0.0009016005563908242
Trained batch 313 in epoch 2, gen_loss = 1.2217641972052824, disc_loss = 0.0009002986386867691
Trained batch 314 in epoch 2, gen_loss = 1.2214114062369816, disc_loss = 0.0009006803107839669
Trained batch 315 in epoch 2, gen_loss = 1.2208761770891239, disc_loss = 0.000901320383237834
Trained batch 316 in epoch 2, gen_loss = 1.22119897303145, disc_loss = 0.0009011858994360097
Trained batch 317 in epoch 2, gen_loss = 1.2210762723811768, disc_loss = 0.0009010434411532017
Trained batch 318 in epoch 2, gen_loss = 1.2208256420670631, disc_loss = 0.0009002937928176424
Trained batch 319 in epoch 2, gen_loss = 1.2209858441725374, disc_loss = 0.000900317668219941
Trained batch 320 in epoch 2, gen_loss = 1.220703789935305, disc_loss = 0.0008995502733304876
Trained batch 321 in epoch 2, gen_loss = 1.2210569731567218, disc_loss = 0.0008988278902241359
Trained batch 322 in epoch 2, gen_loss = 1.2213403922116424, disc_loss = 0.0008983536070715866
Trained batch 323 in epoch 2, gen_loss = 1.2216190219293406, disc_loss = 0.0008986748171643998
Trained batch 324 in epoch 2, gen_loss = 1.2218991901324345, disc_loss = 0.000899791648844257
Trained batch 325 in epoch 2, gen_loss = 1.2215606882893966, disc_loss = 0.0009027579450227057
Trained batch 326 in epoch 2, gen_loss = 1.2222080152333694, disc_loss = 0.0009050715020651266
Trained batch 327 in epoch 2, gen_loss = 1.2216589568955143, disc_loss = 0.0009080805769083715
Trained batch 328 in epoch 2, gen_loss = 1.221252852841351, disc_loss = 0.0009105860671958402
Trained batch 329 in epoch 2, gen_loss = 1.2221643272674445, disc_loss = 0.0009113779535806371
Trained batch 330 in epoch 2, gen_loss = 1.222054482046571, disc_loss = 0.0009115488590071895
Trained batch 331 in epoch 2, gen_loss = 1.222011209072837, disc_loss = 0.0009114050485385885
Trained batch 332 in epoch 2, gen_loss = 1.2219974140863161, disc_loss = 0.0009108889623728299
Trained batch 333 in epoch 2, gen_loss = 1.2226159124674199, disc_loss = 0.0009106556428519697
Trained batch 334 in epoch 2, gen_loss = 1.222928805671521, disc_loss = 0.0009116396319239275
Trained batch 335 in epoch 2, gen_loss = 1.2230046169743651, disc_loss = 0.000910400293703008
Trained batch 336 in epoch 2, gen_loss = 1.2226671778129894, disc_loss = 0.0009090101272275379
Trained batch 337 in epoch 2, gen_loss = 1.2229631164017514, disc_loss = 0.000907280696239102
Trained batch 338 in epoch 2, gen_loss = 1.2231560799576189, disc_loss = 0.0009063129817413106
Trained batch 339 in epoch 2, gen_loss = 1.2228215121171053, disc_loss = 0.0009047530346673311
Trained batch 340 in epoch 2, gen_loss = 1.222365403979405, disc_loss = 0.0009035874585569167
Trained batch 341 in epoch 2, gen_loss = 1.222686267909948, disc_loss = 0.0009031586152602162
Trained batch 342 in epoch 2, gen_loss = 1.2228589733905069, disc_loss = 0.000902681050614424
Trained batch 343 in epoch 2, gen_loss = 1.222059388146844, disc_loss = 0.0009092260685107714
Trained batch 344 in epoch 2, gen_loss = 1.2219067981277687, disc_loss = 0.0009135230813863809
Trained batch 345 in epoch 2, gen_loss = 1.2217270339155473, disc_loss = 0.0009168221147911289
Trained batch 346 in epoch 2, gen_loss = 1.221416201302916, disc_loss = 0.0009193117067725089
Trained batch 347 in epoch 2, gen_loss = 1.2213530835063977, disc_loss = 0.0009196488658065276
Trained batch 348 in epoch 2, gen_loss = 1.2216238620288051, disc_loss = 0.0009196367030389564
Trained batch 349 in epoch 2, gen_loss = 1.2215449959891183, disc_loss = 0.0009196490087612932
Trained batch 350 in epoch 2, gen_loss = 1.2214265457245699, disc_loss = 0.0009205467039467156
Trained batch 351 in epoch 2, gen_loss = 1.2208717285909436, disc_loss = 0.00092199788543274
Trained batch 352 in epoch 2, gen_loss = 1.2215581639292559, disc_loss = 0.0009222705332396114
Trained batch 353 in epoch 2, gen_loss = 1.2214265933818063, disc_loss = 0.0009213328480886264
Trained batch 354 in epoch 2, gen_loss = 1.2213249142740814, disc_loss = 0.0009195497047982481
Trained batch 355 in epoch 2, gen_loss = 1.2218995861123116, disc_loss = 0.0009178185110828012
Trained batch 356 in epoch 2, gen_loss = 1.222257543678711, disc_loss = 0.0009162237097969649
Trained batch 357 in epoch 2, gen_loss = 1.222660013084305, disc_loss = 0.0009148551560723738
Trained batch 358 in epoch 2, gen_loss = 1.2230517435870796, disc_loss = 0.0009134344247975296
Trained batch 359 in epoch 2, gen_loss = 1.2227651652362612, disc_loss = 0.0009121178558012212
Trained batch 360 in epoch 2, gen_loss = 1.2235037405405018, disc_loss = 0.0009111141844186932
Trained batch 361 in epoch 2, gen_loss = 1.2240275658296618, disc_loss = 0.0009111407656223868
Trained batch 362 in epoch 2, gen_loss = 1.2248068965827794, disc_loss = 0.0009123459638746778
Trained batch 363 in epoch 2, gen_loss = 1.2242327892518305, disc_loss = 0.0009139409554376431
Trained batch 364 in epoch 2, gen_loss = 1.224025194285667, disc_loss = 0.0009140276476862037
Trained batch 365 in epoch 2, gen_loss = 1.2239673942164646, disc_loss = 0.0009141422629571403
Trained batch 366 in epoch 2, gen_loss = 1.2234267230254752, disc_loss = 0.0009135325311280899
Trained batch 367 in epoch 2, gen_loss = 1.2232009033146112, disc_loss = 0.0009129075565199499
Trained batch 368 in epoch 2, gen_loss = 1.223378427306488, disc_loss = 0.0009117973054258208
Trained batch 369 in epoch 2, gen_loss = 1.223611320353843, disc_loss = 0.0009117249705407114
Trained batch 370 in epoch 2, gen_loss = 1.2234482787690073, disc_loss = 0.0009110678661824267
Trained batch 371 in epoch 2, gen_loss = 1.223328681081854, disc_loss = 0.0009101802446117114
Trained batch 372 in epoch 2, gen_loss = 1.2235901432446437, disc_loss = 0.0009093679530307621
Trained batch 373 in epoch 2, gen_loss = 1.2237663823653033, disc_loss = 0.0009083545031082034
Trained batch 374 in epoch 2, gen_loss = 1.2244326858520507, disc_loss = 0.000908220941433683
Trained batch 375 in epoch 2, gen_loss = 1.2241063308208546, disc_loss = 0.0009081286932880485
Trained batch 376 in epoch 2, gen_loss = 1.223833701338629, disc_loss = 0.0009077159716131348
Trained batch 377 in epoch 2, gen_loss = 1.2239459557508034, disc_loss = 0.0009066005622063857
Trained batch 378 in epoch 2, gen_loss = 1.2239103496546482, disc_loss = 0.000905226884590398
Trained batch 379 in epoch 2, gen_loss = 1.2241187732470662, disc_loss = 0.0009036592794520977
Trained batch 380 in epoch 2, gen_loss = 1.2238630935588846, disc_loss = 0.0009020747714052637
Trained batch 381 in epoch 2, gen_loss = 1.2238581414622163, disc_loss = 0.0009023211814136444
Trained batch 382 in epoch 2, gen_loss = 1.2233668338536594, disc_loss = 0.0009029492673247703
Trained batch 383 in epoch 2, gen_loss = 1.223716509838899, disc_loss = 0.0009029015715592928
Trained batch 384 in epoch 2, gen_loss = 1.223131200555083, disc_loss = 0.0009033746515436993
Trained batch 385 in epoch 2, gen_loss = 1.2229033958726596, disc_loss = 0.0009023480744938333
Trained batch 386 in epoch 2, gen_loss = 1.222390964357736, disc_loss = 0.0009027826243311225
Trained batch 387 in epoch 2, gen_loss = 1.2223693780677836, disc_loss = 0.0009028267611319814
Trained batch 388 in epoch 2, gen_loss = 1.2221733990549122, disc_loss = 0.0009016801190447627
Trained batch 389 in epoch 2, gen_loss = 1.2228655772331434, disc_loss = 0.0009005257058351372
Trained batch 390 in epoch 2, gen_loss = 1.2225775761372597, disc_loss = 0.0008992976497869482
Trained batch 391 in epoch 2, gen_loss = 1.2233391948500458, disc_loss = 0.0008987690119710703
Trained batch 392 in epoch 2, gen_loss = 1.2230748732884724, disc_loss = 0.0008981066022652412
Trained batch 393 in epoch 2, gen_loss = 1.2228375319296938, disc_loss = 0.0008974967969535391
Trained batch 394 in epoch 2, gen_loss = 1.222937112216708, disc_loss = 0.0008979017735028616
Trained batch 395 in epoch 2, gen_loss = 1.223428961303499, disc_loss = 0.0008973757154455248
Trained batch 396 in epoch 2, gen_loss = 1.2227688898667881, disc_loss = 0.0009029489800114635
Trained batch 397 in epoch 2, gen_loss = 1.2223650252998775, disc_loss = 0.0009079441009469601
Trained batch 398 in epoch 2, gen_loss = 1.222832875741753, disc_loss = 0.0009106375761522694
Trained batch 399 in epoch 2, gen_loss = 1.2223374608159066, disc_loss = 0.0009117861765116686
Trained batch 400 in epoch 2, gen_loss = 1.2222643436636413, disc_loss = 0.0009119157558754133
Trained batch 401 in epoch 2, gen_loss = 1.2219860524087403, disc_loss = 0.0009111312029921492
Trained batch 402 in epoch 2, gen_loss = 1.2221597004173412, disc_loss = 0.0009102525420471906
Trained batch 403 in epoch 2, gen_loss = 1.2222842786571768, disc_loss = 0.0009087719112412202
Trained batch 404 in epoch 2, gen_loss = 1.222693743823487, disc_loss = 0.0009073015823414159
Trained batch 405 in epoch 2, gen_loss = 1.2227213003952515, disc_loss = 0.0009058134090826328
Trained batch 406 in epoch 2, gen_loss = 1.2228528091304132, disc_loss = 0.000904400457390092
Trained batch 407 in epoch 2, gen_loss = 1.2230003777087903, disc_loss = 0.0009029561790835121
Trained batch 408 in epoch 2, gen_loss = 1.222619117034968, disc_loss = 0.0009014998989015781
Trained batch 409 in epoch 2, gen_loss = 1.2219722013647962, disc_loss = 0.000900793792367572
Trained batch 410 in epoch 2, gen_loss = 1.221662361691468, disc_loss = 0.0009010113967489677
Trained batch 411 in epoch 2, gen_loss = 1.2214524692412718, disc_loss = 0.0009008734568939951
Trained batch 412 in epoch 2, gen_loss = 1.2212902199269495, disc_loss = 0.000901357829176142
Trained batch 413 in epoch 2, gen_loss = 1.222269373671444, disc_loss = 0.0009029691036147232
Trained batch 414 in epoch 2, gen_loss = 1.2221591824508575, disc_loss = 0.0009027440570777349
Trained batch 415 in epoch 2, gen_loss = 1.2220654706828868, disc_loss = 0.0009020109046105063
Trained batch 416 in epoch 2, gen_loss = 1.2218023468550447, disc_loss = 0.0009015358335950481
Trained batch 417 in epoch 2, gen_loss = 1.2215645676879792, disc_loss = 0.000901042401448614
Trained batch 418 in epoch 2, gen_loss = 1.2211293040425795, disc_loss = 0.0008999439370223856
Trained batch 419 in epoch 2, gen_loss = 1.220958635210991, disc_loss = 0.0008989359372034891
Trained batch 420 in epoch 2, gen_loss = 1.2210909438246502, disc_loss = 0.0008986145015302692
Trained batch 421 in epoch 2, gen_loss = 1.221109228535286, disc_loss = 0.0008980171260191128
Trained batch 422 in epoch 2, gen_loss = 1.2213358973498605, disc_loss = 0.0008982696167130604
Trained batch 423 in epoch 2, gen_loss = 1.2209334152768243, disc_loss = 0.000898367136577913
Trained batch 424 in epoch 2, gen_loss = 1.2211087584495544, disc_loss = 0.0008984647841220174
Trained batch 425 in epoch 2, gen_loss = 1.2209405670983131, disc_loss = 0.0008976355357234423
Trained batch 426 in epoch 2, gen_loss = 1.221165334173332, disc_loss = 0.0008964231766000241
Trained batch 427 in epoch 2, gen_loss = 1.2210215103124904, disc_loss = 0.0008953387857736829
Trained batch 428 in epoch 2, gen_loss = 1.220979026008597, disc_loss = 0.0008944122694402343
Trained batch 429 in epoch 2, gen_loss = 1.2210015578325404, disc_loss = 0.0008934832099543581
Trained batch 430 in epoch 2, gen_loss = 1.2212856777029635, disc_loss = 0.0008924999318880801
Trained batch 431 in epoch 2, gen_loss = 1.2216151818909027, disc_loss = 0.0008914924009904671
Trained batch 432 in epoch 2, gen_loss = 1.2218119584660607, disc_loss = 0.000891075632548364
Trained batch 433 in epoch 2, gen_loss = 1.2220444922348321, disc_loss = 0.0008904229559745717
Trained batch 434 in epoch 2, gen_loss = 1.2219948046508877, disc_loss = 0.0008900944699517226
Trained batch 435 in epoch 2, gen_loss = 1.2222094922710995, disc_loss = 0.0008890651586442041
Trained batch 436 in epoch 2, gen_loss = 1.2224309503077369, disc_loss = 0.0008881947448428132
Trained batch 437 in epoch 2, gen_loss = 1.2224290271600087, disc_loss = 0.0008869321140265049
Trained batch 438 in epoch 2, gen_loss = 1.222481887405717, disc_loss = 0.0008857087595473152
Trained batch 439 in epoch 2, gen_loss = 1.2224068615924228, disc_loss = 0.0008852590106967413
Trained batch 440 in epoch 2, gen_loss = 1.2223975646252534, disc_loss = 0.0008846181076571193
Trained batch 441 in epoch 2, gen_loss = 1.2227714837136852, disc_loss = 0.0008853640196880755
Trained batch 442 in epoch 2, gen_loss = 1.2227699615347196, disc_loss = 0.0008901336434524313
Trained batch 443 in epoch 2, gen_loss = 1.222493717128092, disc_loss = 0.0008992123212256292
Trained batch 444 in epoch 2, gen_loss = 1.222629903541522, disc_loss = 0.0009084881708454969
Trained batch 445 in epoch 2, gen_loss = 1.2225178251619295, disc_loss = 0.0009152525040110148
Trained batch 446 in epoch 2, gen_loss = 1.2225378905100044, disc_loss = 0.000917726817881476
Trained batch 447 in epoch 2, gen_loss = 1.2227046038689358, disc_loss = 0.0009199339291236745
Trained batch 448 in epoch 2, gen_loss = 1.22250295123438, disc_loss = 0.0009204400110863282
Trained batch 449 in epoch 2, gen_loss = 1.2224745349089305, disc_loss = 0.0009214646432600501
Trained batch 450 in epoch 2, gen_loss = 1.2220760883883204, disc_loss = 0.0009233691883707077
Trained batch 451 in epoch 2, gen_loss = 1.2218314191672655, disc_loss = 0.000923872033295848
Trained batch 452 in epoch 2, gen_loss = 1.2217736816564142, disc_loss = 0.0009232861324980295
Trained batch 453 in epoch 2, gen_loss = 1.2220707988686499, disc_loss = 0.0009222845502027478
Trained batch 454 in epoch 2, gen_loss = 1.2223623007208437, disc_loss = 0.000920986958170453
Trained batch 455 in epoch 2, gen_loss = 1.2224973117311795, disc_loss = 0.0009204121752031425
Trained batch 456 in epoch 2, gen_loss = 1.2222582450059103, disc_loss = 0.0009197513966442084
Trained batch 457 in epoch 2, gen_loss = 1.222142472928268, disc_loss = 0.0009196129892891737
Trained batch 458 in epoch 2, gen_loss = 1.2218565409739293, disc_loss = 0.0009189774594239257
Trained batch 459 in epoch 2, gen_loss = 1.221431347986926, disc_loss = 0.0009181492470974183
Trained batch 460 in epoch 2, gen_loss = 1.221875110960317, disc_loss = 0.0009174057494125727
Trained batch 461 in epoch 2, gen_loss = 1.221714314573255, disc_loss = 0.0009167707107912797
Trained batch 462 in epoch 2, gen_loss = 1.2212505511794698, disc_loss = 0.0009166959040299396
Trained batch 463 in epoch 2, gen_loss = 1.2213956540257767, disc_loss = 0.000917598701625107
Trained batch 464 in epoch 2, gen_loss = 1.2211404068495637, disc_loss = 0.0009165955778782166
Trained batch 465 in epoch 2, gen_loss = 1.2212144644219476, disc_loss = 0.0009159177125535521
Trained batch 466 in epoch 2, gen_loss = 1.2209910112223739, disc_loss = 0.0009164175485326595
Trained batch 467 in epoch 2, gen_loss = 1.2206163733688176, disc_loss = 0.0009174067611630975
Trained batch 468 in epoch 2, gen_loss = 1.220205152848128, disc_loss = 0.0009179179241924462
Trained batch 469 in epoch 2, gen_loss = 1.2201627415545444, disc_loss = 0.0009177945653333309
Trained batch 470 in epoch 2, gen_loss = 1.220281767364267, disc_loss = 0.0009175136387783188
Trained batch 471 in epoch 2, gen_loss = 1.220906270131216, disc_loss = 0.0009182184819680623
Trained batch 472 in epoch 2, gen_loss = 1.2210270548219662, disc_loss = 0.0009174543985679557
Trained batch 473 in epoch 2, gen_loss = 1.2209848222098774, disc_loss = 0.0009166066983531971
Trained batch 474 in epoch 2, gen_loss = 1.2211321365205865, disc_loss = 0.0009157354776796542
Trained batch 475 in epoch 2, gen_loss = 1.2209875296895243, disc_loss = 0.0009143492418484168
Trained batch 476 in epoch 2, gen_loss = 1.2208721371566724, disc_loss = 0.000913510976073213
Trained batch 477 in epoch 2, gen_loss = 1.2208926721347426, disc_loss = 0.0009124814448064723
Trained batch 478 in epoch 2, gen_loss = 1.221753083962737, disc_loss = 0.0009112680360158645
Trained batch 479 in epoch 2, gen_loss = 1.221605159714818, disc_loss = 0.0009099725296133935
Trained batch 480 in epoch 2, gen_loss = 1.2215729526819161, disc_loss = 0.0009085863772448125
Trained batch 481 in epoch 2, gen_loss = 1.221726452537592, disc_loss = 0.000907341519394103
Trained batch 482 in epoch 2, gen_loss = 1.2215338295044118, disc_loss = 0.00090619109178229
Trained batch 483 in epoch 2, gen_loss = 1.2214356388681191, disc_loss = 0.0009050872236115508
Trained batch 484 in epoch 2, gen_loss = 1.2213174491813503, disc_loss = 0.0009045229980196401
Trained batch 485 in epoch 2, gen_loss = 1.2216978201895585, disc_loss = 0.000904097090794565
Trained batch 486 in epoch 2, gen_loss = 1.2216902020285996, disc_loss = 0.0009042497356940975
Trained batch 487 in epoch 2, gen_loss = 1.22157863820674, disc_loss = 0.0009047332483443497
Trained batch 488 in epoch 2, gen_loss = 1.2216170279038707, disc_loss = 0.0009043810565411713
Trained batch 489 in epoch 2, gen_loss = 1.221467072988043, disc_loss = 0.0009038430551002848
Trained batch 490 in epoch 2, gen_loss = 1.2211633975297032, disc_loss = 0.0009049237800902894
Trained batch 491 in epoch 2, gen_loss = 1.2209763903685702, disc_loss = 0.0009076974683403837
Trained batch 492 in epoch 2, gen_loss = 1.221527994646262, disc_loss = 0.0009127010664353374
Trained batch 493 in epoch 2, gen_loss = 1.2217048832520783, disc_loss = 0.0009186123229427968
Trained batch 494 in epoch 2, gen_loss = 1.221342312085508, disc_loss = 0.0009276590653697518
Trained batch 495 in epoch 2, gen_loss = 1.2209196315417368, disc_loss = 0.0009320079036643297
Trained batch 496 in epoch 2, gen_loss = 1.220832647572101, disc_loss = 0.0009321853054054475
Trained batch 497 in epoch 2, gen_loss = 1.2205779469874969, disc_loss = 0.0009320922419216098
Trained batch 498 in epoch 2, gen_loss = 1.220589336627471, disc_loss = 0.0009317625967987752
Trained batch 499 in epoch 2, gen_loss = 1.2201145676374436, disc_loss = 0.0009326159896154422
Trained batch 500 in epoch 2, gen_loss = 1.2202326969472235, disc_loss = 0.0009330479184943094
Trained batch 501 in epoch 2, gen_loss = 1.2202803916427718, disc_loss = 0.0009335837776198022
Trained batch 502 in epoch 2, gen_loss = 1.2198052548508995, disc_loss = 0.0009339374937517495
Trained batch 503 in epoch 2, gen_loss = 1.2196206157169645, disc_loss = 0.0009335907268125863
Trained batch 504 in epoch 2, gen_loss = 1.2191451939025728, disc_loss = 0.0009337035424161315
Trained batch 505 in epoch 2, gen_loss = 1.2194606873828904, disc_loss = 0.0009353916137352708
Trained batch 506 in epoch 2, gen_loss = 1.2189460101682523, disc_loss = 0.000938515216200539
Trained batch 507 in epoch 2, gen_loss = 1.218962242753487, disc_loss = 0.0009428707996026272
Trained batch 508 in epoch 2, gen_loss = 1.2190320519895124, disc_loss = 0.00094826666063383
Trained batch 509 in epoch 2, gen_loss = 1.219477380958258, disc_loss = 0.0009520630536238006
Trained batch 510 in epoch 2, gen_loss = 1.219049675124032, disc_loss = 0.0009539502320244796
Trained batch 511 in epoch 2, gen_loss = 1.2185627797152847, disc_loss = 0.0009544801690992699
Trained batch 512 in epoch 2, gen_loss = 1.2180812433216772, disc_loss = 0.000956702989588045
Trained batch 513 in epoch 2, gen_loss = 1.2181783181684027, disc_loss = 0.0009596511713514043
Trained batch 514 in epoch 2, gen_loss = 1.2180122009758811, disc_loss = 0.0009598096669029933
Trained batch 515 in epoch 2, gen_loss = 1.2177188142325528, disc_loss = 0.0009601392408766577
Trained batch 516 in epoch 2, gen_loss = 1.217515395273323, disc_loss = 0.00095990437571688
Trained batch 517 in epoch 2, gen_loss = 1.2178121386347591, disc_loss = 0.0009590718100122967
Trained batch 518 in epoch 2, gen_loss = 1.2181541791081658, disc_loss = 0.0009583761384910303
Trained batch 519 in epoch 2, gen_loss = 1.2182961789461282, disc_loss = 0.0009572548889431906
Trained batch 520 in epoch 2, gen_loss = 1.2181082931910274, disc_loss = 0.0009562201629986722
Trained batch 521 in epoch 2, gen_loss = 1.218132919963749, disc_loss = 0.0009554709992569986
Trained batch 522 in epoch 2, gen_loss = 1.2183197189699395, disc_loss = 0.0009552568677658336
Trained batch 523 in epoch 2, gen_loss = 1.218104231448574, disc_loss = 0.0009545371824671525
Trained batch 524 in epoch 2, gen_loss = 1.2181037071772984, disc_loss = 0.0009536210782659639
Trained batch 525 in epoch 2, gen_loss = 1.2179950133475967, disc_loss = 0.0009524098978085291
Trained batch 526 in epoch 2, gen_loss = 1.2184507754088805, disc_loss = 0.000951314141082072
Trained batch 527 in epoch 2, gen_loss = 1.2184512161395766, disc_loss = 0.0009500753574849858
Trained batch 528 in epoch 2, gen_loss = 1.2182529060511598, disc_loss = 0.0009488311102660021
Trained batch 529 in epoch 2, gen_loss = 1.218434997999443, disc_loss = 0.0009477214602465776
Trained batch 530 in epoch 2, gen_loss = 1.2182016231245913, disc_loss = 0.0009475254840728355
Trained batch 531 in epoch 2, gen_loss = 1.217847451455611, disc_loss = 0.0009467117449269136
Trained batch 532 in epoch 2, gen_loss = 1.217684468677299, disc_loss = 0.0009456650170990777
Trained batch 533 in epoch 2, gen_loss = 1.2176978574709947, disc_loss = 0.0009449049716255949
Trained batch 534 in epoch 2, gen_loss = 1.2178118872865338, disc_loss = 0.0009443355281674086
Trained batch 535 in epoch 2, gen_loss = 1.2178907031888393, disc_loss = 0.0009437861899098594
Trained batch 536 in epoch 2, gen_loss = 1.2178567430382556, disc_loss = 0.0009444647922418626
Trained batch 537 in epoch 2, gen_loss = 1.2174184625919866, disc_loss = 0.0009477761614174915
Trained batch 538 in epoch 2, gen_loss = 1.2173036334687128, disc_loss = 0.0009530409509914363
Trained batch 539 in epoch 2, gen_loss = 1.217527413809741, disc_loss = 0.0009576587877678254
Trained batch 540 in epoch 2, gen_loss = 1.2173465448474707, disc_loss = 0.0009597121930111788
Trained batch 541 in epoch 2, gen_loss = 1.217771560503548, disc_loss = 0.0009599779876702073
Trained batch 542 in epoch 2, gen_loss = 1.2180662581055643, disc_loss = 0.0009590843240320974
Trained batch 543 in epoch 2, gen_loss = 1.2179065039929222, disc_loss = 0.0009578745134069108
Trained batch 544 in epoch 2, gen_loss = 1.218178462763445, disc_loss = 0.0009568415187275755
Trained batch 545 in epoch 2, gen_loss = 1.2178812295525938, disc_loss = 0.0009557856484830137
Trained batch 546 in epoch 2, gen_loss = 1.2179375437975366, disc_loss = 0.0009547823677880185
Trained batch 547 in epoch 2, gen_loss = 1.2181282128295758, disc_loss = 0.0009539238240492927
Trained batch 548 in epoch 2, gen_loss = 1.2179128969519082, disc_loss = 0.0009528883401368522
Trained batch 549 in epoch 2, gen_loss = 1.2180277952280911, disc_loss = 0.0009528597729778002
Trained batch 550 in epoch 2, gen_loss = 1.2178958492140588, disc_loss = 0.0009538611671969738
Trained batch 551 in epoch 2, gen_loss = 1.2174893219185912, disc_loss = 0.0009539653371799774
Trained batch 552 in epoch 2, gen_loss = 1.2173183092588111, disc_loss = 0.0009539004742994375
Trained batch 553 in epoch 2, gen_loss = 1.2175472950031612, disc_loss = 0.0009536783152673013
Trained batch 554 in epoch 2, gen_loss = 1.2173325150936574, disc_loss = 0.0009544080561435958
Trained batch 555 in epoch 2, gen_loss = 1.216873864368569, disc_loss = 0.0009546581950286159
Trained batch 556 in epoch 2, gen_loss = 1.2167361066200146, disc_loss = 0.0009545206416620249
Trained batch 557 in epoch 2, gen_loss = 1.216345126804058, disc_loss = 0.000954207173404893
Trained batch 558 in epoch 2, gen_loss = 1.216299635459784, disc_loss = 0.000953505009662465
Trained batch 559 in epoch 2, gen_loss = 1.216546270357711, disc_loss = 0.000952977703205501
Trained batch 560 in epoch 2, gen_loss = 1.2162357002443596, disc_loss = 0.000952450500724633
Trained batch 561 in epoch 2, gen_loss = 1.2164608338761584, disc_loss = 0.0009533664255079422
Trained batch 562 in epoch 2, gen_loss = 1.2161128522024274, disc_loss = 0.000953691458278071
Trained batch 563 in epoch 2, gen_loss = 1.215959296475911, disc_loss = 0.0009536307059417905
Trained batch 564 in epoch 2, gen_loss = 1.2161482506093726, disc_loss = 0.0009528983411929298
Trained batch 565 in epoch 2, gen_loss = 1.2158145583349909, disc_loss = 0.0009530617966505455
Trained batch 566 in epoch 2, gen_loss = 1.2154767836002236, disc_loss = 0.0009543181954613251
Trained batch 567 in epoch 2, gen_loss = 1.2155522770235236, disc_loss = 0.0009558357284385891
Trained batch 568 in epoch 2, gen_loss = 1.2151067729365008, disc_loss = 0.0009559695016351726
Trained batch 569 in epoch 2, gen_loss = 1.214753865672831, disc_loss = 0.0009555156644701288
Trained batch 570 in epoch 2, gen_loss = 1.214897247934926, disc_loss = 0.0009546274675418021
Trained batch 571 in epoch 2, gen_loss = 1.2149884893552407, disc_loss = 0.0009536710816325206
Trained batch 572 in epoch 2, gen_loss = 1.2148989450453047, disc_loss = 0.0009532311771409976
Trained batch 573 in epoch 2, gen_loss = 1.214733960840345, disc_loss = 0.0009534113494306559
Trained batch 574 in epoch 2, gen_loss = 1.2144882719413095, disc_loss = 0.0009537348578653662
Trained batch 575 in epoch 2, gen_loss = 1.2142714412055082, disc_loss = 0.0009534565984570994
Trained batch 576 in epoch 2, gen_loss = 1.2140906643206366, disc_loss = 0.0009529700564945672
Trained batch 577 in epoch 2, gen_loss = 1.2143669925552751, disc_loss = 0.0009526754972401275
Trained batch 578 in epoch 2, gen_loss = 1.2143363706600274, disc_loss = 0.0009519227368273372
Trained batch 579 in epoch 2, gen_loss = 1.2141091064132492, disc_loss = 0.0009515836884333865
Trained batch 580 in epoch 2, gen_loss = 1.2136823206678315, disc_loss = 0.0009508580909394731
Trained batch 581 in epoch 2, gen_loss = 1.2134833314369635, disc_loss = 0.000951071269235124
Trained batch 582 in epoch 2, gen_loss = 1.2134804395418837, disc_loss = 0.0009514918787922873
Trained batch 583 in epoch 2, gen_loss = 1.2136185317210955, disc_loss = 0.0009511307306551415
Trained batch 584 in epoch 2, gen_loss = 1.2134563222909585, disc_loss = 0.0009519560574245456
Trained batch 585 in epoch 2, gen_loss = 1.2131927805752478, disc_loss = 0.000952349883650625
Trained batch 586 in epoch 2, gen_loss = 1.2131099346549181, disc_loss = 0.0009527003421185195
Trained batch 587 in epoch 2, gen_loss = 1.2127370366028376, disc_loss = 0.0009530624179979295
Trained batch 588 in epoch 2, gen_loss = 1.21269785103045, disc_loss = 0.0009525268505288269
Trained batch 589 in epoch 2, gen_loss = 1.2123001709832983, disc_loss = 0.0009515718663736815
Trained batch 590 in epoch 2, gen_loss = 1.2122501228666547, disc_loss = 0.0009507139619605697
Trained batch 591 in epoch 2, gen_loss = 1.2123116269909047, disc_loss = 0.0009499569471921171
Trained batch 592 in epoch 2, gen_loss = 1.2125172127559656, disc_loss = 0.0009495879409445645
Trained batch 593 in epoch 2, gen_loss = 1.2123006388595208, disc_loss = 0.0009490165383265329
Trained batch 594 in epoch 2, gen_loss = 1.2121285401472524, disc_loss = 0.0009486565079995893
Trained batch 595 in epoch 2, gen_loss = 1.2123117633913987, disc_loss = 0.0009481998499814536
Trained batch 596 in epoch 2, gen_loss = 1.2125527400467264, disc_loss = 0.0009472925048307836
Trained batch 597 in epoch 2, gen_loss = 1.2125677686670553, disc_loss = 0.000946406849493922
Trained batch 598 in epoch 2, gen_loss = 1.212927734214993, disc_loss = 0.0009466976847160275
Trained batch 599 in epoch 2, gen_loss = 1.2129368310173352, disc_loss = 0.0009468267483316594
Trained batch 600 in epoch 2, gen_loss = 1.212757553018865, disc_loss = 0.0009461026493227109
Trained batch 601 in epoch 2, gen_loss = 1.2131146708398166, disc_loss = 0.0009452310103164642
Trained batch 602 in epoch 2, gen_loss = 1.2131624736793796, disc_loss = 0.0009448580886884076
Trained batch 603 in epoch 2, gen_loss = 1.21318021505479, disc_loss = 0.0009443219222769446
Trained batch 604 in epoch 2, gen_loss = 1.2130157166276097, disc_loss = 0.0009434771703600437
Trained batch 605 in epoch 2, gen_loss = 1.2126251669606753, disc_loss = 0.0009428611680626694
Trained batch 606 in epoch 2, gen_loss = 1.2127808210680866, disc_loss = 0.0009425220957294005
Trained batch 607 in epoch 2, gen_loss = 1.2125528131268526, disc_loss = 0.0009425628887392553
Trained batch 608 in epoch 2, gen_loss = 1.2125561448740843, disc_loss = 0.0009428657051464482
Trained batch 609 in epoch 2, gen_loss = 1.2126752685328, disc_loss = 0.000942424102185378
Trained batch 610 in epoch 2, gen_loss = 1.2127837416778415, disc_loss = 0.0009417933208359948
Trained batch 611 in epoch 2, gen_loss = 1.212788908310186, disc_loss = 0.0009409300866679462
Trained batch 612 in epoch 2, gen_loss = 1.2125668197043762, disc_loss = 0.0009402360599387367
Trained batch 613 in epoch 2, gen_loss = 1.2122171786204223, disc_loss = 0.0009399693791217213
Trained batch 614 in epoch 2, gen_loss = 1.2125300150576646, disc_loss = 0.0009399788974494696
Trained batch 615 in epoch 2, gen_loss = 1.2123553972546157, disc_loss = 0.0009399454446285343
Trained batch 616 in epoch 2, gen_loss = 1.2121220990363357, disc_loss = 0.0009394832952557482
Trained batch 617 in epoch 2, gen_loss = 1.2121743830855225, disc_loss = 0.0009389063919595635
Trained batch 618 in epoch 2, gen_loss = 1.2118916629974599, disc_loss = 0.0009388392900937855
Trained batch 619 in epoch 2, gen_loss = 1.2121036563188798, disc_loss = 0.0009386614958085345
Trained batch 620 in epoch 2, gen_loss = 1.2122900700031656, disc_loss = 0.000938395672321624
Trained batch 621 in epoch 2, gen_loss = 1.2121519236510974, disc_loss = 0.0009378220224511582
Trained batch 622 in epoch 2, gen_loss = 1.2124431744624486, disc_loss = 0.0009370434928689538
Trained batch 623 in epoch 2, gen_loss = 1.2125443284137127, disc_loss = 0.0009360627003470421
Trained batch 624 in epoch 2, gen_loss = 1.2123840350151063, disc_loss = 0.0009353961636079475
Trained batch 625 in epoch 2, gen_loss = 1.2124109691895617, disc_loss = 0.0009349173026896951
Trained batch 626 in epoch 2, gen_loss = 1.212730074137972, disc_loss = 0.0009340984006035416
Trained batch 627 in epoch 2, gen_loss = 1.2125899728126586, disc_loss = 0.0009334882730619973
Trained batch 628 in epoch 2, gen_loss = 1.2124506734512948, disc_loss = 0.0009328908887249454
Trained batch 629 in epoch 2, gen_loss = 1.2123625260496897, disc_loss = 0.0009321118294056283
Trained batch 630 in epoch 2, gen_loss = 1.2121971740775555, disc_loss = 0.0009313769481580619
Trained batch 631 in epoch 2, gen_loss = 1.2117812055387074, disc_loss = 0.0009305125292450634
Trained batch 632 in epoch 2, gen_loss = 1.2119594340640787, disc_loss = 0.0009303161499741903
Trained batch 633 in epoch 2, gen_loss = 1.2120257517328774, disc_loss = 0.0009300698291307259
Trained batch 634 in epoch 2, gen_loss = 1.2121552742372348, disc_loss = 0.000930112464913519
Trained batch 635 in epoch 2, gen_loss = 1.2127215986919102, disc_loss = 0.0009315919926865597
Trained batch 636 in epoch 2, gen_loss = 1.2128086659934494, disc_loss = 0.000933950556089606
Trained batch 637 in epoch 2, gen_loss = 1.212522128626097, disc_loss = 0.000935707231876798
Trained batch 638 in epoch 2, gen_loss = 1.212311481739247, disc_loss = 0.0009359264570637789
Trained batch 639 in epoch 2, gen_loss = 1.2124564317055047, disc_loss = 0.0009356014196555407
Trained batch 640 in epoch 2, gen_loss = 1.212387279396682, disc_loss = 0.0009349609761091687
Trained batch 641 in epoch 2, gen_loss = 1.2123388819791074, disc_loss = 0.0009340608136946367
Trained batch 642 in epoch 2, gen_loss = 1.2121492495432982, disc_loss = 0.0009332616841951009
Trained batch 643 in epoch 2, gen_loss = 1.212313424633897, disc_loss = 0.0009324268788568927
Trained batch 644 in epoch 2, gen_loss = 1.2121497471203175, disc_loss = 0.0009315871573802329
Trained batch 645 in epoch 2, gen_loss = 1.2120552004859912, disc_loss = 0.0009305328962163519
Trained batch 646 in epoch 2, gen_loss = 1.2119700677428031, disc_loss = 0.0009296527537011644
Trained batch 647 in epoch 2, gen_loss = 1.2116628643355252, disc_loss = 0.0009290452859137009
Trained batch 648 in epoch 2, gen_loss = 1.2116640030143808, disc_loss = 0.0009285409558621466
Trained batch 649 in epoch 2, gen_loss = 1.2114910544798925, disc_loss = 0.000928562032573749
Trained batch 650 in epoch 2, gen_loss = 1.2116368821322827, disc_loss = 0.0009290813648786765
Trained batch 651 in epoch 2, gen_loss = 1.2116360533639696, disc_loss = 0.0009290322834728329
Trained batch 652 in epoch 2, gen_loss = 1.2119402021032746, disc_loss = 0.0009283940462674732
Trained batch 653 in epoch 2, gen_loss = 1.2117120855991994, disc_loss = 0.0009277638889497092
Trained batch 654 in epoch 2, gen_loss = 1.2118044255344012, disc_loss = 0.0009281686474062602
Trained batch 655 in epoch 2, gen_loss = 1.212004644750822, disc_loss = 0.0009279877333871654
Trained batch 656 in epoch 2, gen_loss = 1.2117209687624892, disc_loss = 0.0009282527130996933
Trained batch 657 in epoch 2, gen_loss = 1.211605219221405, disc_loss = 0.0009281946846457711
Trained batch 658 in epoch 2, gen_loss = 1.2118246453123136, disc_loss = 0.0009281845244270579
Trained batch 659 in epoch 2, gen_loss = 1.2115966772491282, disc_loss = 0.0009277269156662055
Trained batch 660 in epoch 2, gen_loss = 1.211674772574934, disc_loss = 0.0009271420778432979
Trained batch 661 in epoch 2, gen_loss = 1.2116070666161909, disc_loss = 0.0009264636095576311
Trained batch 662 in epoch 2, gen_loss = 1.2118269308480023, disc_loss = 0.0009256371611553324
Trained batch 663 in epoch 2, gen_loss = 1.2115947978503734, disc_loss = 0.0009246965555247292
Trained batch 664 in epoch 2, gen_loss = 1.2118599046441845, disc_loss = 0.0009241105926694012
Trained batch 665 in epoch 2, gen_loss = 1.2116433586981203, disc_loss = 0.0009241488315984845
Trained batch 666 in epoch 2, gen_loss = 1.2117272303558362, disc_loss = 0.000924686555537909
Trained batch 667 in epoch 2, gen_loss = 1.2116724844285829, disc_loss = 0.0009245707712585489
Trained batch 668 in epoch 2, gen_loss = 1.2114810579204416, disc_loss = 0.0009237302732641735
Trained batch 669 in epoch 2, gen_loss = 1.2114064753055573, disc_loss = 0.000923107311224266
Trained batch 670 in epoch 2, gen_loss = 1.2111104146734257, disc_loss = 0.0009226854045879881
Trained batch 671 in epoch 2, gen_loss = 1.2110739528600658, disc_loss = 0.0009219114261083762
Trained batch 672 in epoch 2, gen_loss = 1.210984004464936, disc_loss = 0.0009216341805372063
Trained batch 673 in epoch 2, gen_loss = 1.2106321017183252, disc_loss = 0.0009247715842852422
Trained batch 674 in epoch 2, gen_loss = 1.2108225709420664, disc_loss = 0.0009335531146239697
Trained batch 675 in epoch 2, gen_loss = 1.2107832706891573, disc_loss = 0.0009454341468440173
Trained batch 676 in epoch 2, gen_loss = 1.210816281760989, disc_loss = 0.0009519843844997117
Trained batch 677 in epoch 2, gen_loss = 1.210729424229062, disc_loss = 0.0009534133225481938
Trained batch 678 in epoch 2, gen_loss = 1.210704870532995, disc_loss = 0.0009552758847013876
Trained batch 679 in epoch 2, gen_loss = 1.210979480603162, disc_loss = 0.0009570443818066612
Trained batch 680 in epoch 2, gen_loss = 1.2108715963433667, disc_loss = 0.0009587680902026071
Trained batch 681 in epoch 2, gen_loss = 1.210646506103952, disc_loss = 0.0009594247743217316
Trained batch 682 in epoch 2, gen_loss = 1.2103803175260173, disc_loss = 0.0009592421521648483
Trained batch 683 in epoch 2, gen_loss = 1.2101099275008977, disc_loss = 0.0009586403609707214
Trained batch 684 in epoch 2, gen_loss = 1.2103321792435473, disc_loss = 0.000958996365483286
Trained batch 685 in epoch 2, gen_loss = 1.2104954333764124, disc_loss = 0.0009594864252747347
Trained batch 686 in epoch 2, gen_loss = 1.2104679519606123, disc_loss = 0.0009610385147373774
Trained batch 687 in epoch 2, gen_loss = 1.21041129061649, disc_loss = 0.0009619628699933961
Trained batch 688 in epoch 2, gen_loss = 1.2100929076335947, disc_loss = 0.0009615836399636084
Trained batch 689 in epoch 2, gen_loss = 1.2100003046402033, disc_loss = 0.0009607256825657332
Trained batch 690 in epoch 2, gen_loss = 1.2100551070594237, disc_loss = 0.000959928093856981
Trained batch 691 in epoch 2, gen_loss = 1.2097229896425512, disc_loss = 0.0009590062687556715
Trained batch 692 in epoch 2, gen_loss = 1.209660991703793, disc_loss = 0.0009580894741375863
Trained batch 693 in epoch 2, gen_loss = 1.2096795011150734, disc_loss = 0.0009574911022491374
Trained batch 694 in epoch 2, gen_loss = 1.2095417814289064, disc_loss = 0.0009570392642443222
Trained batch 695 in epoch 2, gen_loss = 1.2095222064647182, disc_loss = 0.0009564474783829432
Trained batch 696 in epoch 2, gen_loss = 1.209493766983749, disc_loss = 0.0009565743409727541
Trained batch 697 in epoch 2, gen_loss = 1.2094393967728219, disc_loss = 0.0009572289168044463
Trained batch 698 in epoch 2, gen_loss = 1.2091456069284583, disc_loss = 0.000959644127730913
Trained batch 699 in epoch 2, gen_loss = 1.2090582785436086, disc_loss = 0.0009615595884679351
Trained batch 700 in epoch 2, gen_loss = 1.2090588917745844, disc_loss = 0.000961442634750778
Trained batch 701 in epoch 2, gen_loss = 1.2091774409822589, disc_loss = 0.0009603860976973461
Trained batch 702 in epoch 2, gen_loss = 1.2091257266096167, disc_loss = 0.0009596665127735763
Trained batch 703 in epoch 2, gen_loss = 1.2092694703658873, disc_loss = 0.0009591809971218688
Trained batch 704 in epoch 2, gen_loss = 1.2094116292946728, disc_loss = 0.0009585047770887679
Trained batch 705 in epoch 2, gen_loss = 1.2091255523158875, disc_loss = 0.0009582775056326864
Trained batch 706 in epoch 2, gen_loss = 1.2093490717097422, disc_loss = 0.000957828028447158
Trained batch 707 in epoch 2, gen_loss = 1.2094116375102835, disc_loss = 0.000957547086522037
Trained batch 708 in epoch 2, gen_loss = 1.2092349133303202, disc_loss = 0.0009572664830133868
Trained batch 709 in epoch 2, gen_loss = 1.209284189133577, disc_loss = 0.0009564281620198376
Trained batch 710 in epoch 2, gen_loss = 1.2091795641158702, disc_loss = 0.0009559837532658379
Trained batch 711 in epoch 2, gen_loss = 1.2088771595546368, disc_loss = 0.0009557394799261336
Trained batch 712 in epoch 2, gen_loss = 1.2091885262585622, disc_loss = 0.0009549977826250085
Trained batch 713 in epoch 2, gen_loss = 1.2092021993395328, disc_loss = 0.0009541060070219287
Trained batch 714 in epoch 2, gen_loss = 1.2091156031701948, disc_loss = 0.0009534278441866912
Trained batch 715 in epoch 2, gen_loss = 1.2091959764005085, disc_loss = 0.0009529011078901113
Trained batch 716 in epoch 2, gen_loss = 1.2092349343885105, disc_loss = 0.0009525757975010279
Trained batch 717 in epoch 2, gen_loss = 1.2093671813482694, disc_loss = 0.0009517287945935521
Trained batch 718 in epoch 2, gen_loss = 1.209587708716598, disc_loss = 0.0009508679911109874
Trained batch 719 in epoch 2, gen_loss = 1.209602910031875, disc_loss = 0.0009499098463493283
Trained batch 720 in epoch 2, gen_loss = 1.209520276227705, disc_loss = 0.0009492499562780903
Trained batch 721 in epoch 2, gen_loss = 1.2092544673387364, disc_loss = 0.0009490079422011504
Trained batch 722 in epoch 2, gen_loss = 1.2090445459301211, disc_loss = 0.0009486869848125587
Trained batch 723 in epoch 2, gen_loss = 1.2089209534351337, disc_loss = 0.0009480176409872092
Trained batch 724 in epoch 2, gen_loss = 1.2090982566208675, disc_loss = 0.0009477045846870169
Trained batch 725 in epoch 2, gen_loss = 1.2088410485710324, disc_loss = 0.0009476466557341653
Trained batch 726 in epoch 2, gen_loss = 1.2086230782891894, disc_loss = 0.0009470763446324719
Trained batch 727 in epoch 2, gen_loss = 1.2085570996770492, disc_loss = 0.0009466842524948783
Trained batch 728 in epoch 2, gen_loss = 1.2085004535558619, disc_loss = 0.0009461812879524509
Trained batch 729 in epoch 2, gen_loss = 1.2089804753048778, disc_loss = 0.0009458652497962921
Trained batch 730 in epoch 2, gen_loss = 1.2088397696471573, disc_loss = 0.0009454829640749895
Trained batch 731 in epoch 2, gen_loss = 1.2089336533201196, disc_loss = 0.0009454103084584848
Trained batch 732 in epoch 2, gen_loss = 1.2088071967374743, disc_loss = 0.0009455437870087269
Trained batch 733 in epoch 2, gen_loss = 1.208821852379339, disc_loss = 0.000945974729998178
Trained batch 734 in epoch 2, gen_loss = 1.2088244421141487, disc_loss = 0.0009456967131739964
Trained batch 735 in epoch 2, gen_loss = 1.2090157125469134, disc_loss = 0.0009451160606896219
Trained batch 736 in epoch 2, gen_loss = 1.208903389433184, disc_loss = 0.000944615956872109
Trained batch 737 in epoch 2, gen_loss = 1.208669480673343, disc_loss = 0.0009441807376734122
Trained batch 738 in epoch 2, gen_loss = 1.2086314505750013, disc_loss = 0.0009437888781425099
Trained batch 739 in epoch 2, gen_loss = 1.2088920283156472, disc_loss = 0.0009433742542397168
Trained batch 740 in epoch 2, gen_loss = 1.2089037583907123, disc_loss = 0.000942754793051076
Trained batch 741 in epoch 2, gen_loss = 1.208792325701675, disc_loss = 0.0009423060435197703
Trained batch 742 in epoch 2, gen_loss = 1.2089579821756038, disc_loss = 0.0009415832490240027
Trained batch 743 in epoch 2, gen_loss = 1.208732562119602, disc_loss = 0.0009409385840372515
Trained batch 744 in epoch 2, gen_loss = 1.208679226180851, disc_loss = 0.0009402264289490741
Trained batch 745 in epoch 2, gen_loss = 1.2083327014388732, disc_loss = 0.0009396865420443275
Trained batch 746 in epoch 2, gen_loss = 1.2085347084635232, disc_loss = 0.0009391065248435642
Trained batch 747 in epoch 2, gen_loss = 1.2086208383029795, disc_loss = 0.0009390813057327377
Trained batch 748 in epoch 2, gen_loss = 1.2087906129528907, disc_loss = 0.0009386225047128682
Trained batch 749 in epoch 2, gen_loss = 1.2089675030708313, disc_loss = 0.000937796444806736
Trained batch 750 in epoch 2, gen_loss = 1.208865676040497, disc_loss = 0.0009370241095409598
Trained batch 751 in epoch 2, gen_loss = 1.2089455427324518, disc_loss = 0.0009363170962155601
Trained batch 752 in epoch 2, gen_loss = 1.2088384355998452, disc_loss = 0.0009356423806664095
Trained batch 753 in epoch 2, gen_loss = 1.2089790365107813, disc_loss = 0.0009361782269831808
Trained batch 754 in epoch 2, gen_loss = 1.2090183842261106, disc_loss = 0.0009382935020562249
Trained batch 755 in epoch 2, gen_loss = 1.2089856591804948, disc_loss = 0.0009417208954305376
Trained batch 756 in epoch 2, gen_loss = 1.2087959378682165, disc_loss = 0.0009446389337608227
Trained batch 757 in epoch 2, gen_loss = 1.2089776962916896, disc_loss = 0.0009453961068998081
Trained batch 758 in epoch 2, gen_loss = 1.2087190176344358, disc_loss = 0.0009458902226498703
Trained batch 759 in epoch 2, gen_loss = 1.208514818862865, disc_loss = 0.0009460384060060421
Trained batch 760 in epoch 2, gen_loss = 1.2083800204010111, disc_loss = 0.0009463025081565276
Trained batch 761 in epoch 2, gen_loss = 1.2084841013267598, disc_loss = 0.0009463532819430065
Trained batch 762 in epoch 2, gen_loss = 1.2085232951850442, disc_loss = 0.0009459979512869425
Trained batch 763 in epoch 2, gen_loss = 1.2085260833121094, disc_loss = 0.0009454888843753587
Trained batch 764 in epoch 2, gen_loss = 1.208476936271767, disc_loss = 0.0009448736367916104
Trained batch 765 in epoch 2, gen_loss = 1.2083158893000052, disc_loss = 0.0009442332106137553
Trained batch 766 in epoch 2, gen_loss = 1.208012336080668, disc_loss = 0.0009441071457186753
Trained batch 767 in epoch 2, gen_loss = 1.207783983554691, disc_loss = 0.0009440297838523293
Trained batch 768 in epoch 2, gen_loss = 1.2074675087190883, disc_loss = 0.000949687177601624
Trained batch 769 in epoch 2, gen_loss = 1.2074516342831896, disc_loss = 0.0009543080399736653
Trained batch 770 in epoch 2, gen_loss = 1.2072249505615729, disc_loss = 0.0009564368344591834
Trained batch 771 in epoch 2, gen_loss = 1.2073024217946542, disc_loss = 0.0009582181571953547
Trained batch 772 in epoch 2, gen_loss = 1.2074133803896885, disc_loss = 0.0009592380327795166
Trained batch 773 in epoch 2, gen_loss = 1.2074826253476993, disc_loss = 0.0009605089074188124
Trained batch 774 in epoch 2, gen_loss = 1.2072909612040366, disc_loss = 0.0009621161970332445
Trained batch 775 in epoch 2, gen_loss = 1.2072808601192593, disc_loss = 0.000963145097370047
Trained batch 776 in epoch 2, gen_loss = 1.207062070741003, disc_loss = 0.0009630089144585318
Trained batch 777 in epoch 2, gen_loss = 1.206882249573509, disc_loss = 0.0009624900083363733
Trained batch 778 in epoch 2, gen_loss = 1.2066361755706532, disc_loss = 0.0009618691858288261
Trained batch 779 in epoch 2, gen_loss = 1.2065901345167405, disc_loss = 0.0009610141103061883
Trained batch 780 in epoch 2, gen_loss = 1.2067930263380082, disc_loss = 0.0009602959203587788
Trained batch 781 in epoch 2, gen_loss = 1.2068151081614482, disc_loss = 0.0009599449850841845
Trained batch 782 in epoch 2, gen_loss = 1.2066459389329718, disc_loss = 0.000960583904390711
Trained batch 783 in epoch 2, gen_loss = 1.206471738614598, disc_loss = 0.000961546212906518
Trained batch 784 in epoch 2, gen_loss = 1.206264053180719, disc_loss = 0.0009614964864983455
Trained batch 785 in epoch 2, gen_loss = 1.2062333286870224, disc_loss = 0.0009610248498274096
Trained batch 786 in epoch 2, gen_loss = 1.2060588955727738, disc_loss = 0.0009610007820170778
Trained batch 787 in epoch 2, gen_loss = 1.2059773984294253, disc_loss = 0.0009603736413972805
Trained batch 788 in epoch 2, gen_loss = 1.2058852072451052, disc_loss = 0.0009598805915591742
Trained batch 789 in epoch 2, gen_loss = 1.205747317513333, disc_loss = 0.0009599420645228539
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 1.4697039127349854, disc_loss = 0.0011813156306743622
Trained batch 1 in epoch 3, gen_loss = 1.2313342690467834, disc_loss = 0.0011114634107798338
Trained batch 2 in epoch 3, gen_loss = 1.1350990335146587, disc_loss = 0.0009402943154176077
Trained batch 3 in epoch 3, gen_loss = 1.2236288636922836, disc_loss = 0.0008431075257249177
Trained batch 4 in epoch 3, gen_loss = 1.2360167384147644, disc_loss = 0.0007774563739076257
Trained batch 5 in epoch 3, gen_loss = 1.2350909610589345, disc_loss = 0.0007189901176995287
Trained batch 6 in epoch 3, gen_loss = 1.25192563022886, disc_loss = 0.0006686429343452412
Trained batch 7 in epoch 3, gen_loss = 1.2409428283572197, disc_loss = 0.0006452490160882007
Trained batch 8 in epoch 3, gen_loss = 1.2409947911898296, disc_loss = 0.0006651547187680586
Trained batch 9 in epoch 3, gen_loss = 1.2400268971920014, disc_loss = 0.0007376373949227854
Trained batch 10 in epoch 3, gen_loss = 1.249909980730577, disc_loss = 0.0008616786085026847
Trained batch 11 in epoch 3, gen_loss = 1.229334607720375, disc_loss = 0.0011550749162173208
Trained batch 12 in epoch 3, gen_loss = 1.2278834718924303, disc_loss = 0.0015981506820445736
Trained batch 13 in epoch 3, gen_loss = 1.2294292492525918, disc_loss = 0.0019710682245204225
Trained batch 14 in epoch 3, gen_loss = 1.2162376523017884, disc_loss = 0.002225587049421544
Trained batch 15 in epoch 3, gen_loss = 1.1988920345902443, disc_loss = 0.0023990744066395564
Trained batch 16 in epoch 3, gen_loss = 1.2043954133987427, disc_loss = 0.002445506313747233
Trained batch 17 in epoch 3, gen_loss = 1.206514424747891, disc_loss = 0.0023720132222580207
Trained batch 18 in epoch 3, gen_loss = 1.1998283423875507, disc_loss = 0.0023326556133964147
Trained batch 19 in epoch 3, gen_loss = 1.192897242307663, disc_loss = 0.0024066644240519964
Trained batch 20 in epoch 3, gen_loss = 1.1939363479614258, disc_loss = 0.002491833552041845
Trained batch 21 in epoch 3, gen_loss = 1.19442909414118, disc_loss = 0.002463069690169174
Trained batch 22 in epoch 3, gen_loss = 1.204160389692887, disc_loss = 0.002383211595967979
Trained batch 23 in epoch 3, gen_loss = 1.1963066309690475, disc_loss = 0.0023447333842341322
Trained batch 24 in epoch 3, gen_loss = 1.196246829032898, disc_loss = 0.0023736678704153746
Trained batch 25 in epoch 3, gen_loss = 1.2020355783976042, disc_loss = 0.002432612566805731
Trained batch 26 in epoch 3, gen_loss = 1.2104156767880474, disc_loss = 0.002467792031691513
Trained batch 27 in epoch 3, gen_loss = 1.2145948622907912, disc_loss = 0.0024339432992357096
Trained batch 28 in epoch 3, gen_loss = 1.208070002753159, disc_loss = 0.0023942613072998435
Trained batch 29 in epoch 3, gen_loss = 1.207168964544932, disc_loss = 0.002334506944559204
Trained batch 30 in epoch 3, gen_loss = 1.202474178806428, disc_loss = 0.0022743018297103025
Trained batch 31 in epoch 3, gen_loss = 1.195512842386961, disc_loss = 0.0022262558986767544
Trained batch 32 in epoch 3, gen_loss = 1.1913181868466465, disc_loss = 0.0021827104898296634
Trained batch 33 in epoch 3, gen_loss = 1.190556946922751, disc_loss = 0.002131803355843979
Trained batch 34 in epoch 3, gen_loss = 1.1964366776602608, disc_loss = 0.0020806266768236777
Trained batch 35 in epoch 3, gen_loss = 1.1971732709142897, disc_loss = 0.00203395603441297
Trained batch 36 in epoch 3, gen_loss = 1.1973565172504734, disc_loss = 0.002001648100967695
Trained batch 37 in epoch 3, gen_loss = 1.1973171767435575, disc_loss = 0.0019894442390834322
Trained batch 38 in epoch 3, gen_loss = 1.1956140719927275, disc_loss = 0.0020032775019689533
Trained batch 39 in epoch 3, gen_loss = 1.1990638822317123, disc_loss = 0.002029857009620173
Trained batch 40 in epoch 3, gen_loss = 1.1943601660612153, disc_loss = 0.0020339861448297686
Trained batch 41 in epoch 3, gen_loss = 1.1926650972593398, disc_loss = 0.002006745766266249
Trained batch 42 in epoch 3, gen_loss = 1.1957080946412197, disc_loss = 0.0019791885488937328
Trained batch 43 in epoch 3, gen_loss = 1.1947788569060238, disc_loss = 0.0019842993821260857
Trained batch 44 in epoch 3, gen_loss = 1.1892023894521926, disc_loss = 0.0019936486140876594
Trained batch 45 in epoch 3, gen_loss = 1.191712429989939, disc_loss = 0.001984001496052572
Trained batch 46 in epoch 3, gen_loss = 1.188120039219552, disc_loss = 0.001961395076966468
Trained batch 47 in epoch 3, gen_loss = 1.1973476472000282, disc_loss = 0.001947033451263754
Trained batch 48 in epoch 3, gen_loss = 1.192929174218859, disc_loss = 0.0019363670993586813
Trained batch 49 in epoch 3, gen_loss = 1.193487275838852, disc_loss = 0.001926662558107637
Trained batch 50 in epoch 3, gen_loss = 1.1917206995627458, disc_loss = 0.0019051789508119006
Trained batch 51 in epoch 3, gen_loss = 1.1921499726864009, disc_loss = 0.0018774949634322324
Trained batch 52 in epoch 3, gen_loss = 1.1906663685474757, disc_loss = 0.001850715630801992
Trained batch 53 in epoch 3, gen_loss = 1.1886762877305348, disc_loss = 0.0018240522978077126
Trained batch 54 in epoch 3, gen_loss = 1.1903284560550342, disc_loss = 0.0017969077034980397
Trained batch 55 in epoch 3, gen_loss = 1.1919565530759948, disc_loss = 0.0017723255852095982
Trained batch 56 in epoch 3, gen_loss = 1.1953725950759755, disc_loss = 0.001747167712637109
Trained batch 57 in epoch 3, gen_loss = 1.1910854567741525, disc_loss = 0.0017288023287807752
Trained batch 58 in epoch 3, gen_loss = 1.1912999345084367, disc_loss = 0.0017093479612613318
Trained batch 59 in epoch 3, gen_loss = 1.1903316626946132, disc_loss = 0.001692126676304421
Trained batch 60 in epoch 3, gen_loss = 1.1901807169445227, disc_loss = 0.0016795802717364287
Trained batch 61 in epoch 3, gen_loss = 1.1924460982122729, disc_loss = 0.0016626194462127564
Trained batch 62 in epoch 3, gen_loss = 1.1946546851642548, disc_loss = 0.0016434556515406936
Trained batch 63 in epoch 3, gen_loss = 1.1964671397581697, disc_loss = 0.001623954068236344
Trained batch 64 in epoch 3, gen_loss = 1.1950604576330919, disc_loss = 0.0016047931468794838
Trained batch 65 in epoch 3, gen_loss = 1.193959043784575, disc_loss = 0.0015913863824221842
Trained batch 66 in epoch 3, gen_loss = 1.190773961259358, disc_loss = 0.0015765337500227754
Trained batch 67 in epoch 3, gen_loss = 1.186983766801217, disc_loss = 0.0015650293948163059
Trained batch 68 in epoch 3, gen_loss = 1.1854657582614734, disc_loss = 0.0015486670051451665
Trained batch 69 in epoch 3, gen_loss = 1.18487794143813, disc_loss = 0.0015356068570067042
Trained batch 70 in epoch 3, gen_loss = 1.1862756979297584, disc_loss = 0.0015192098426140687
Trained batch 71 in epoch 3, gen_loss = 1.186547301709652, disc_loss = 0.001503938795293733
Trained batch 72 in epoch 3, gen_loss = 1.186372501392887, disc_loss = 0.001488513518555396
Trained batch 73 in epoch 3, gen_loss = 1.1852341543983769, disc_loss = 0.001483933486884485
Trained batch 74 in epoch 3, gen_loss = 1.1851427785555522, disc_loss = 0.0014827241465294114
Trained batch 75 in epoch 3, gen_loss = 1.182455752240984, disc_loss = 0.0014869496881146915
Trained batch 76 in epoch 3, gen_loss = 1.185427471414789, disc_loss = 0.0014809168820033552
Trained batch 77 in epoch 3, gen_loss = 1.187244992225598, disc_loss = 0.001470549418277537
Trained batch 78 in epoch 3, gen_loss = 1.187601197369491, disc_loss = 0.0014599504563043814
Trained batch 79 in epoch 3, gen_loss = 1.189274188131094, disc_loss = 0.0014506371760944603
Trained batch 80 in epoch 3, gen_loss = 1.1888481901015764, disc_loss = 0.0014457961721891929
Trained batch 81 in epoch 3, gen_loss = 1.1883140475284764, disc_loss = 0.001437505509451645
Trained batch 82 in epoch 3, gen_loss = 1.1879520136189747, disc_loss = 0.0014255518579002783
Trained batch 83 in epoch 3, gen_loss = 1.187138204773267, disc_loss = 0.0014171088190605154
Trained batch 84 in epoch 3, gen_loss = 1.1866912371972027, disc_loss = 0.0014121695414788145
Trained batch 85 in epoch 3, gen_loss = 1.1887629288573598, disc_loss = 0.0014040982574062032
Trained batch 86 in epoch 3, gen_loss = 1.1886791395044876, disc_loss = 0.001399084312129423
Trained batch 87 in epoch 3, gen_loss = 1.1898392147638581, disc_loss = 0.0014002461969291537
Trained batch 88 in epoch 3, gen_loss = 1.189620297276572, disc_loss = 0.0014113245572465775
Trained batch 89 in epoch 3, gen_loss = 1.190200032790502, disc_loss = 0.0014138240308966487
Trained batch 90 in epoch 3, gen_loss = 1.1910605764651037, disc_loss = 0.0014185413154057013
Trained batch 91 in epoch 3, gen_loss = 1.1920934986809026, disc_loss = 0.0014183313817383073
Trained batch 92 in epoch 3, gen_loss = 1.1924080444920448, disc_loss = 0.0014148879156608174
Trained batch 93 in epoch 3, gen_loss = 1.1956689059734344, disc_loss = 0.001408049940785512
Trained batch 94 in epoch 3, gen_loss = 1.1953483813687376, disc_loss = 0.0013977752226453863
Trained batch 95 in epoch 3, gen_loss = 1.1947912331670523, disc_loss = 0.0013902758025020983
Trained batch 96 in epoch 3, gen_loss = 1.1967046684825544, disc_loss = 0.0013847197730036587
Trained batch 97 in epoch 3, gen_loss = 1.1982961558565801, disc_loss = 0.0013772999958078169
Trained batch 98 in epoch 3, gen_loss = 1.1980481226034838, disc_loss = 0.0013675789302920527
Trained batch 99 in epoch 3, gen_loss = 1.1966037279367447, disc_loss = 0.0013577631313819438
Trained batch 100 in epoch 3, gen_loss = 1.1948805734662726, disc_loss = 0.0013485338814362958
Trained batch 101 in epoch 3, gen_loss = 1.1922105498173658, disc_loss = 0.0013439615214855282
Trained batch 102 in epoch 3, gen_loss = 1.1922199674023009, disc_loss = 0.0013406846103782865
Trained batch 103 in epoch 3, gen_loss = 1.190924077652968, disc_loss = 0.0013412002282655942
Trained batch 104 in epoch 3, gen_loss = 1.1932904374031794, disc_loss = 0.0013357268319287826
Trained batch 105 in epoch 3, gen_loss = 1.1925981995069757, disc_loss = 0.0013279417619759322
Trained batch 106 in epoch 3, gen_loss = 1.1941150332165655, disc_loss = 0.0013210287123970757
Trained batch 107 in epoch 3, gen_loss = 1.1943692945771747, disc_loss = 0.001314465211988944
Trained batch 108 in epoch 3, gen_loss = 1.1930895852386405, disc_loss = 0.00130639207088004
Trained batch 109 in epoch 3, gen_loss = 1.192365869066932, disc_loss = 0.001301967442586002
Trained batch 110 in epoch 3, gen_loss = 1.192241801334931, disc_loss = 0.0012996360514866741
Trained batch 111 in epoch 3, gen_loss = 1.192949086959873, disc_loss = 0.0012987566452855909
Trained batch 112 in epoch 3, gen_loss = 1.1929982452265984, disc_loss = 0.001299262617558109
Trained batch 113 in epoch 3, gen_loss = 1.1938175093709378, disc_loss = 0.0013058646725033199
Trained batch 114 in epoch 3, gen_loss = 1.19253561237584, disc_loss = 0.0013245326527596816
Trained batch 115 in epoch 3, gen_loss = 1.1932482827326347, disc_loss = 0.0013547157487382405
Trained batch 116 in epoch 3, gen_loss = 1.1921185637131715, disc_loss = 0.001381474895339109
Trained batch 117 in epoch 3, gen_loss = 1.19376739859581, disc_loss = 0.001403306391863626
Trained batch 118 in epoch 3, gen_loss = 1.1934233979016793, disc_loss = 0.001432847382281633
Trained batch 119 in epoch 3, gen_loss = 1.1932532077034315, disc_loss = 0.0014697387833924344
Trained batch 120 in epoch 3, gen_loss = 1.1924445909902084, disc_loss = 0.0014974197646033418
Trained batch 121 in epoch 3, gen_loss = 1.1920434593177232, disc_loss = 0.0015107790355524812
Trained batch 122 in epoch 3, gen_loss = 1.1913965799944188, disc_loss = 0.0015143248833700772
Trained batch 123 in epoch 3, gen_loss = 1.1912432760000229, disc_loss = 0.0015145105398034738
Trained batch 124 in epoch 3, gen_loss = 1.1917004532814026, disc_loss = 0.0015092374780215324
Trained batch 125 in epoch 3, gen_loss = 1.1899007889959548, disc_loss = 0.0015031126492272412
Trained batch 126 in epoch 3, gen_loss = 1.1914897913069238, disc_loss = 0.0014967295684023049
Trained batch 127 in epoch 3, gen_loss = 1.191477314569056, disc_loss = 0.0014924511960998643
Trained batch 128 in epoch 3, gen_loss = 1.1898722029471582, disc_loss = 0.0014878685185469168
Trained batch 129 in epoch 3, gen_loss = 1.188096046447754, disc_loss = 0.0014829786100353185
Trained batch 130 in epoch 3, gen_loss = 1.1883663730766938, disc_loss = 0.0014826534751390342
Trained batch 131 in epoch 3, gen_loss = 1.1887707800576182, disc_loss = 0.0014879519664894112
Trained batch 132 in epoch 3, gen_loss = 1.1896316548039143, disc_loss = 0.0014879857041151788
Trained batch 133 in epoch 3, gen_loss = 1.1899192973748962, disc_loss = 0.0014836383855783505
Trained batch 134 in epoch 3, gen_loss = 1.1909439378314548, disc_loss = 0.0014768662181234471
Trained batch 135 in epoch 3, gen_loss = 1.1900962740182877, disc_loss = 0.0014703062676263096
Trained batch 136 in epoch 3, gen_loss = 1.1893429695254696, disc_loss = 0.001465125245647165
Trained batch 137 in epoch 3, gen_loss = 1.1908741636552673, disc_loss = 0.0014601770456900576
Trained batch 138 in epoch 3, gen_loss = 1.1925080311384133, disc_loss = 0.0014539092880499502
Trained batch 139 in epoch 3, gen_loss = 1.1938759131090981, disc_loss = 0.0014473942312179134
Trained batch 140 in epoch 3, gen_loss = 1.1942178721123553, disc_loss = 0.0014406932478255414
Trained batch 141 in epoch 3, gen_loss = 1.194910142623203, disc_loss = 0.0014366985312630226
Trained batch 142 in epoch 3, gen_loss = 1.1938182157236379, disc_loss = 0.0014350458729680028
Trained batch 143 in epoch 3, gen_loss = 1.1939732738667064, disc_loss = 0.001433945856357847
Trained batch 144 in epoch 3, gen_loss = 1.1923473169063699, disc_loss = 0.0014324539023901112
Trained batch 145 in epoch 3, gen_loss = 1.192087124471795, disc_loss = 0.0014286007355796557
Trained batch 146 in epoch 3, gen_loss = 1.192838665579452, disc_loss = 0.0014241389272145319
Trained batch 147 in epoch 3, gen_loss = 1.1932071157403894, disc_loss = 0.0014189897652564418
Trained batch 148 in epoch 3, gen_loss = 1.1920999168549609, disc_loss = 0.0014173000286827051
Trained batch 149 in epoch 3, gen_loss = 1.1923021626472474, disc_loss = 0.0014169169131976864
Trained batch 150 in epoch 3, gen_loss = 1.1915197538224278, disc_loss = 0.001410897825042785
Trained batch 151 in epoch 3, gen_loss = 1.1906554589146061, disc_loss = 0.0014033129401995164
Trained batch 152 in epoch 3, gen_loss = 1.1931452953737545, disc_loss = 0.0014002611902481541
Trained batch 153 in epoch 3, gen_loss = 1.194370367310264, disc_loss = 0.0013995485152752901
Trained batch 154 in epoch 3, gen_loss = 1.1959439846777147, disc_loss = 0.0014022246329864908
Trained batch 155 in epoch 3, gen_loss = 1.195452107832982, disc_loss = 0.0014087607250519048
Trained batch 156 in epoch 3, gen_loss = 1.1962016008462115, disc_loss = 0.0014146397992891443
Trained batch 157 in epoch 3, gen_loss = 1.1962284566480903, disc_loss = 0.0014179391124067664
Trained batch 158 in epoch 3, gen_loss = 1.1959504353925117, disc_loss = 0.0014196600147768996
Trained batch 159 in epoch 3, gen_loss = 1.195932586491108, disc_loss = 0.00142029434464348
Trained batch 160 in epoch 3, gen_loss = 1.1971593465864288, disc_loss = 0.0014173013815419134
Trained batch 161 in epoch 3, gen_loss = 1.1960365448468997, disc_loss = 0.0014135447807931973
Trained batch 162 in epoch 3, gen_loss = 1.1954218332021513, disc_loss = 0.0014115528944891197
Trained batch 163 in epoch 3, gen_loss = 1.1953623760037306, disc_loss = 0.0014086616716756507
Trained batch 164 in epoch 3, gen_loss = 1.1944347815080123, disc_loss = 0.0014046277660368519
Trained batch 165 in epoch 3, gen_loss = 1.1948479787412896, disc_loss = 0.0014007806978525077
Trained batch 166 in epoch 3, gen_loss = 1.1947737610982563, disc_loss = 0.0013952958768771817
Trained batch 167 in epoch 3, gen_loss = 1.1942810955501737, disc_loss = 0.0013898573292646602
Trained batch 168 in epoch 3, gen_loss = 1.1953841250323685, disc_loss = 0.0013857030336601804
Trained batch 169 in epoch 3, gen_loss = 1.1956537141519434, disc_loss = 0.0013840428741840535
Trained batch 170 in epoch 3, gen_loss = 1.1957901067901076, disc_loss = 0.0013854968935463642
Trained batch 171 in epoch 3, gen_loss = 1.1950380233831184, disc_loss = 0.0013813916177537596
Trained batch 172 in epoch 3, gen_loss = 1.1939775723253372, disc_loss = 0.001376736866420598
Trained batch 173 in epoch 3, gen_loss = 1.1938427488009136, disc_loss = 0.0013743426711646434
Trained batch 174 in epoch 3, gen_loss = 1.1941441202163696, disc_loss = 0.001373150008397975
Trained batch 175 in epoch 3, gen_loss = 1.1932740346951918, disc_loss = 0.0013709213536375582
Trained batch 176 in epoch 3, gen_loss = 1.192908710005593, disc_loss = 0.0013661969556357438
Trained batch 177 in epoch 3, gen_loss = 1.1916005989808716, disc_loss = 0.0013621496438870227
Trained batch 178 in epoch 3, gen_loss = 1.1920794498321063, disc_loss = 0.0013646724989622124
Trained batch 179 in epoch 3, gen_loss = 1.1916105717420578, disc_loss = 0.0013685012633989876
Trained batch 180 in epoch 3, gen_loss = 1.1919635906403894, disc_loss = 0.0013648644035028613
Trained batch 181 in epoch 3, gen_loss = 1.1914211914434538, disc_loss = 0.0013605101289263426
Trained batch 182 in epoch 3, gen_loss = 1.191421597707467, disc_loss = 0.0013564610328968064
Trained batch 183 in epoch 3, gen_loss = 1.1908059965657152, disc_loss = 0.0013512699847722063
Trained batch 184 in epoch 3, gen_loss = 1.1918236471511223, disc_loss = 0.001346371936095828
Trained batch 185 in epoch 3, gen_loss = 1.1908473625618925, disc_loss = 0.0013415517200345314
Trained batch 186 in epoch 3, gen_loss = 1.1908132969376874, disc_loss = 0.0013367446123268754
Trained batch 187 in epoch 3, gen_loss = 1.1912385127011766, disc_loss = 0.0013319198888951933
Trained batch 188 in epoch 3, gen_loss = 1.1914926246991233, disc_loss = 0.001326755914811252
Trained batch 189 in epoch 3, gen_loss = 1.192055007344798, disc_loss = 0.0013217890518717468
Trained batch 190 in epoch 3, gen_loss = 1.1922096285520423, disc_loss = 0.0013174563801740125
Trained batch 191 in epoch 3, gen_loss = 1.1916467749203246, disc_loss = 0.0013147004195464735
Trained batch 193 in epoch 3, gen_loss = 1.1931425465136458, disc_loss = 0.0013103622006439633
Trained batch 194 in epoch 3, gen_loss = 1.192437276779077, disc_loss = 0.0013077516789333178
Trained batch 195 in epoch 3, gen_loss = 1.1943418611677326, disc_loss = 0.001305003008123354
Trained batch 196 in epoch 3, gen_loss = 1.1945957674592884, disc_loss = 0.0013024275753112879
Trained batch 197 in epoch 3, gen_loss = 1.194669962832422, disc_loss = 0.0012985583764590285
Trained batch 198 in epoch 3, gen_loss = 1.1955430241086376, disc_loss = 0.0012940820272901942
Trained batch 199 in epoch 3, gen_loss = 1.194753545820713, disc_loss = 0.0012886476896528621
Trained batch 200 in epoch 3, gen_loss = 1.1953079412825665, disc_loss = 0.0012831773810333049
Trained batch 201 in epoch 3, gen_loss = 1.1948832848874649, disc_loss = 0.0012788283086115596
Trained batch 202 in epoch 3, gen_loss = 1.194654463253585, disc_loss = 0.001274520335240138
Trained batch 203 in epoch 3, gen_loss = 1.1943205819994795, disc_loss = 0.0012691835158786453
Trained batch 204 in epoch 3, gen_loss = 1.1943264911814433, disc_loss = 0.0012639384172294607
Trained batch 205 in epoch 3, gen_loss = 1.1942494445055434, disc_loss = 0.0012587895958081964
Trained batch 206 in epoch 3, gen_loss = 1.1942838295070446, disc_loss = 0.0012558512279290284
Trained batch 207 in epoch 3, gen_loss = 1.1931037487318883, disc_loss = 0.001255616966213543
Trained batch 208 in epoch 3, gen_loss = 1.1938639277476444, disc_loss = 0.0012575705586815628
Trained batch 209 in epoch 3, gen_loss = 1.193676568496795, disc_loss = 0.0012562568783843224
Trained batch 210 in epoch 3, gen_loss = 1.193206126373526, disc_loss = 0.001252762905928368
Trained batch 211 in epoch 3, gen_loss = 1.1927329776984341, disc_loss = 0.0012488727934053387
Trained batch 212 in epoch 3, gen_loss = 1.192136889052503, disc_loss = 0.0012445963460469985
Trained batch 213 in epoch 3, gen_loss = 1.191598352706321, disc_loss = 0.0012401062484518363
Trained batch 214 in epoch 3, gen_loss = 1.191179880707763, disc_loss = 0.0012374848750728552
Trained batch 215 in epoch 3, gen_loss = 1.190576671174279, disc_loss = 0.0012379290474200388
Trained batch 216 in epoch 3, gen_loss = 1.1901492998347305, disc_loss = 0.0012395565231327474
Trained batch 217 in epoch 3, gen_loss = 1.1910503547672833, disc_loss = 0.0012390912733272513
Trained batch 218 in epoch 3, gen_loss = 1.190696493947887, disc_loss = 0.0012369787780441488
Trained batch 219 in epoch 3, gen_loss = 1.19179511801763, disc_loss = 0.001234536392902638
Trained batch 220 in epoch 3, gen_loss = 1.1922676598324495, disc_loss = 0.0012326278472640573
Trained batch 221 in epoch 3, gen_loss = 1.1928047019619126, disc_loss = 0.0012307806603997517
Trained batch 222 in epoch 3, gen_loss = 1.1926316335596845, disc_loss = 0.0012273935583757337
Trained batch 223 in epoch 3, gen_loss = 1.1924667760197605, disc_loss = 0.0012235758520416442
Trained batch 224 in epoch 3, gen_loss = 1.1925582967864143, disc_loss = 0.0012197788115978863
Trained batch 225 in epoch 3, gen_loss = 1.1919515710488884, disc_loss = 0.00121639473347016
Trained batch 226 in epoch 3, gen_loss = 1.1913679604488323, disc_loss = 0.0012130835158304242
Trained batch 227 in epoch 3, gen_loss = 1.1920880040055828, disc_loss = 0.0012097056252905372
Trained batch 228 in epoch 3, gen_loss = 1.1911899645255644, disc_loss = 0.0012077360289292328
Trained batch 229 in epoch 3, gen_loss = 1.1912142636983292, disc_loss = 0.0012084356953931527
Trained batch 230 in epoch 3, gen_loss = 1.1913693134402816, disc_loss = 0.0012115086881757324
Trained batch 231 in epoch 3, gen_loss = 1.190922166509875, disc_loss = 0.0012155259238201765
Trained batch 232 in epoch 3, gen_loss = 1.1917142353856, disc_loss = 0.0012165988023395853
Trained batch 233 in epoch 3, gen_loss = 1.1910975323273585, disc_loss = 0.0012160892708154402
Trained batch 234 in epoch 3, gen_loss = 1.190971322008904, disc_loss = 0.0012161574707282312
Trained batch 235 in epoch 3, gen_loss = 1.1910080200029631, disc_loss = 0.0012140766592569042
Trained batch 236 in epoch 3, gen_loss = 1.1918035511729084, disc_loss = 0.00121125486429598
Trained batch 237 in epoch 3, gen_loss = 1.1918871034594143, disc_loss = 0.0012092824162354794
Trained batch 238 in epoch 3, gen_loss = 1.1931959378170667, disc_loss = 0.0012069024431405231
Trained batch 239 in epoch 3, gen_loss = 1.1931552442411582, disc_loss = 0.0012046891739373677
Trained batch 240 in epoch 3, gen_loss = 1.193076838348911, disc_loss = 0.0012022475187287037
Trained batch 241 in epoch 3, gen_loss = 1.1925387419452351, disc_loss = 0.00120250006851669
Trained batch 242 in epoch 3, gen_loss = 1.192709456500693, disc_loss = 0.0012029199110638205
Trained batch 243 in epoch 3, gen_loss = 1.1937405249623, disc_loss = 0.0012019532562694399
Trained batch 244 in epoch 3, gen_loss = 1.1939029876066714, disc_loss = 0.0011983810419725178
Trained batch 245 in epoch 3, gen_loss = 1.1939140420134475, disc_loss = 0.001196974886728477
Trained batch 246 in epoch 3, gen_loss = 1.1938587139975205, disc_loss = 0.001194747550088275
Trained batch 247 in epoch 3, gen_loss = 1.1948923644038938, disc_loss = 0.0011936371996149142
Trained batch 248 in epoch 3, gen_loss = 1.1948071701459617, disc_loss = 0.001190870093688066
Trained batch 249 in epoch 3, gen_loss = 1.1956077992916108, disc_loss = 0.001187871314876247
Trained batch 250 in epoch 3, gen_loss = 1.195295691727642, disc_loss = 0.0011848927925056055
Trained batch 251 in epoch 3, gen_loss = 1.1946093693139062, disc_loss = 0.0011819321290882756
Trained batch 252 in epoch 3, gen_loss = 1.1956133331234746, disc_loss = 0.001184156088431351
Trained batch 253 in epoch 3, gen_loss = 1.1950441192923569, disc_loss = 0.0011961342280251194
Trained batch 254 in epoch 3, gen_loss = 1.1947130060663411, disc_loss = 0.0012108549816355876
Trained batch 255 in epoch 3, gen_loss = 1.1939635372254997, disc_loss = 0.0012207546599825037
Trained batch 256 in epoch 3, gen_loss = 1.1933997036881947, disc_loss = 0.0012217471093516471
Trained batch 257 in epoch 3, gen_loss = 1.1933563196843908, disc_loss = 0.001220325003127665
Trained batch 258 in epoch 3, gen_loss = 1.1932973601643182, disc_loss = 0.0012243382680939122
Trained batch 259 in epoch 3, gen_loss = 1.1930895839746183, disc_loss = 0.001230994798746766
Trained batch 260 in epoch 3, gen_loss = 1.1924400003020335, disc_loss = 0.0012360139820975398
Trained batch 261 in epoch 3, gen_loss = 1.1931316158698715, disc_loss = 0.001238705650407853
Trained batch 262 in epoch 3, gen_loss = 1.1928905967070575, disc_loss = 0.0012379415385171014
Trained batch 263 in epoch 3, gen_loss = 1.1930350424213843, disc_loss = 0.0012354492000943565
Trained batch 264 in epoch 3, gen_loss = 1.1930585103214912, disc_loss = 0.001232951529870987
Trained batch 265 in epoch 3, gen_loss = 1.1927759600313086, disc_loss = 0.0012306095879630857
Trained batch 266 in epoch 3, gen_loss = 1.1929530836223217, disc_loss = 0.0012273462506142804
Trained batch 267 in epoch 3, gen_loss = 1.1926291440405064, disc_loss = 0.0012240272078644866
Trained batch 268 in epoch 3, gen_loss = 1.1936272810382913, disc_loss = 0.0012218244732457098
Trained batch 269 in epoch 3, gen_loss = 1.1936547886442255, disc_loss = 0.0012193540410306823
Trained batch 270 in epoch 3, gen_loss = 1.1933554487914617, disc_loss = 0.0012199934487676976
Trained batch 271 in epoch 3, gen_loss = 1.1936914353247952, disc_loss = 0.0012192733716694742
Trained batch 272 in epoch 3, gen_loss = 1.1932969785435297, disc_loss = 0.0012162228155093977
Trained batch 273 in epoch 3, gen_loss = 1.193882295902628, disc_loss = 0.0012158913269446122
Trained batch 274 in epoch 3, gen_loss = 1.193815350749276, disc_loss = 0.001217930179607885
Trained batch 275 in epoch 3, gen_loss = 1.1945142203914947, disc_loss = 0.0012169224739963006
Trained batch 276 in epoch 3, gen_loss = 1.1948326350549499, disc_loss = 0.0012146846556952827
Trained batch 277 in epoch 3, gen_loss = 1.194007534774945, disc_loss = 0.0012132424119254406
Trained batch 278 in epoch 3, gen_loss = 1.193374615843578, disc_loss = 0.001211959582273214
Trained batch 279 in epoch 3, gen_loss = 1.1935658889157432, disc_loss = 0.0012101033100147367
Trained batch 280 in epoch 3, gen_loss = 1.1932119321992813, disc_loss = 0.0012072655735342695
Trained batch 281 in epoch 3, gen_loss = 1.1930589261629903, disc_loss = 0.001207429622822187
Trained batch 282 in epoch 3, gen_loss = 1.1926014187479188, disc_loss = 0.0012124445310044316
Trained batch 283 in epoch 3, gen_loss = 1.1927244176327343, disc_loss = 0.001216887129385854
Trained batch 284 in epoch 3, gen_loss = 1.1919474501358835, disc_loss = 0.0012188541746326609
Trained batch 285 in epoch 3, gen_loss = 1.1919244702879366, disc_loss = 0.0012179584056892028
Trained batch 286 in epoch 3, gen_loss = 1.1926505931163083, disc_loss = 0.0012161648795856422
Trained batch 287 in epoch 3, gen_loss = 1.1925788149237633, disc_loss = 0.0012146786473042287
Trained batch 288 in epoch 3, gen_loss = 1.193035845525537, disc_loss = 0.0012130018843399927
Trained batch 289 in epoch 3, gen_loss = 1.1925862431526184, disc_loss = 0.0012162908930271254
Trained batch 290 in epoch 3, gen_loss = 1.1918037668945862, disc_loss = 0.0012181202409076073
Trained batch 291 in epoch 3, gen_loss = 1.1922843519547215, disc_loss = 0.0012183438048938016
Trained batch 292 in epoch 3, gen_loss = 1.1920015842434488, disc_loss = 0.0012178352353844073
Trained batch 293 in epoch 3, gen_loss = 1.1932504183175612, disc_loss = 0.0012163491678589696
Trained batch 294 in epoch 3, gen_loss = 1.1932938379756475, disc_loss = 0.001214743252908732
Trained batch 295 in epoch 3, gen_loss = 1.1940241075448088, disc_loss = 0.0012128823909242292
Trained batch 296 in epoch 3, gen_loss = 1.1941574613253276, disc_loss = 0.00121004121702028
Trained batch 297 in epoch 3, gen_loss = 1.1940215167983266, disc_loss = 0.001207206154137853
Trained batch 298 in epoch 3, gen_loss = 1.1938489557907335, disc_loss = 0.0012045811202683109
Trained batch 299 in epoch 3, gen_loss = 1.1937728744745255, disc_loss = 0.0012024378513160628
Trained batch 300 in epoch 3, gen_loss = 1.194580570209858, disc_loss = 0.0012005707860612573
Trained batch 301 in epoch 3, gen_loss = 1.1952088591673515, disc_loss = 0.001198328516705483
Trained batch 302 in epoch 3, gen_loss = 1.19504311474243, disc_loss = 0.0011961305706178547
Trained batch 303 in epoch 3, gen_loss = 1.194680291767183, disc_loss = 0.0011935446882489487
Trained batch 304 in epoch 3, gen_loss = 1.1954664376915478, disc_loss = 0.0011907605826950128
Trained batch 305 in epoch 3, gen_loss = 1.1957113787629245, disc_loss = 0.0011884732009919841
Trained batch 306 in epoch 3, gen_loss = 1.1954064662371087, disc_loss = 0.0011857322797635024
Trained batch 307 in epoch 3, gen_loss = 1.195640016492311, disc_loss = 0.001183241035446431
Trained batch 308 in epoch 3, gen_loss = 1.1955796605560771, disc_loss = 0.0011800768222222043
Trained batch 309 in epoch 3, gen_loss = 1.1947632208947212, disc_loss = 0.0011768877100210727
Trained batch 310 in epoch 3, gen_loss = 1.1943096811748395, disc_loss = 0.0011738119980524717
Trained batch 311 in epoch 3, gen_loss = 1.1944228907426198, disc_loss = 0.0011709337110145357
Trained batch 312 in epoch 3, gen_loss = 1.194019505771966, disc_loss = 0.0011687043715530958
Trained batch 313 in epoch 3, gen_loss = 1.1936241297205543, disc_loss = 0.0011682426813225393
Trained batch 314 in epoch 3, gen_loss = 1.192932318884229, disc_loss = 0.0011680614299765448
Trained batch 315 in epoch 3, gen_loss = 1.192666182412377, disc_loss = 0.0011684635306043179
Trained batch 316 in epoch 3, gen_loss = 1.1924195060218545, disc_loss = 0.0011713162901585816
Trained batch 317 in epoch 3, gen_loss = 1.1930782495054808, disc_loss = 0.0011754823389991023
Trained batch 318 in epoch 3, gen_loss = 1.1930612508779783, disc_loss = 0.0011770854008235883
Trained batch 319 in epoch 3, gen_loss = 1.1928782768547534, disc_loss = 0.001175723160895359
Trained batch 320 in epoch 3, gen_loss = 1.1925869708492005, disc_loss = 0.0011733758994149671
Trained batch 321 in epoch 3, gen_loss = 1.1925454409966558, disc_loss = 0.0011720604958574531
Trained batch 322 in epoch 3, gen_loss = 1.1924685904116084, disc_loss = 0.0011707633523715245
Trained batch 323 in epoch 3, gen_loss = 1.1928368545608756, disc_loss = 0.0011684690147331473
Trained batch 324 in epoch 3, gen_loss = 1.1924860514127291, disc_loss = 0.001165870046466947
Trained batch 325 in epoch 3, gen_loss = 1.1922801166224333, disc_loss = 0.0011635148219540687
Trained batch 326 in epoch 3, gen_loss = 1.1921961245551387, disc_loss = 0.0011609693882265626
Trained batch 327 in epoch 3, gen_loss = 1.1928056046003248, disc_loss = 0.0011583578345779665
Trained batch 328 in epoch 3, gen_loss = 1.1925643791181337, disc_loss = 0.0011557332662625612
Trained batch 329 in epoch 3, gen_loss = 1.1923870213104018, disc_loss = 0.0011545025394739104
Trained batch 330 in epoch 3, gen_loss = 1.191965747095667, disc_loss = 0.0011548993158455956
Trained batch 331 in epoch 3, gen_loss = 1.1922266253505844, disc_loss = 0.0011558815590488158
Trained batch 332 in epoch 3, gen_loss = 1.1921046897097751, disc_loss = 0.0011541905282670072
Trained batch 333 in epoch 3, gen_loss = 1.191946892324322, disc_loss = 0.0011517373921400532
Trained batch 334 in epoch 3, gen_loss = 1.1916578524148287, disc_loss = 0.0011491160793316816
Trained batch 335 in epoch 3, gen_loss = 1.1914605537340754, disc_loss = 0.0011466345153426768
Trained batch 336 in epoch 3, gen_loss = 1.1910802097631845, disc_loss = 0.0011444830062169752
Trained batch 337 in epoch 3, gen_loss = 1.1905356123602602, disc_loss = 0.0011436554953988404
Trained batch 338 in epoch 3, gen_loss = 1.1902725176121984, disc_loss = 0.0011437395637786938
Trained batch 339 in epoch 3, gen_loss = 1.1904192742179422, disc_loss = 0.0011423941532591605
Trained batch 340 in epoch 3, gen_loss = 1.1899594872578148, disc_loss = 0.0011412154216489338
Trained batch 341 in epoch 3, gen_loss = 1.1898691560092725, disc_loss = 0.0011386134020003153
Trained batch 342 in epoch 3, gen_loss = 1.1896156468822379, disc_loss = 0.0011360213319949518
Trained batch 343 in epoch 3, gen_loss = 1.1889906601850377, disc_loss = 0.001133347339841854
Trained batch 344 in epoch 3, gen_loss = 1.1894540966420935, disc_loss = 0.0011312741203743128
Trained batch 345 in epoch 3, gen_loss = 1.1888739142803788, disc_loss = 0.0011301803329170175
Trained batch 346 in epoch 3, gen_loss = 1.1884339731777092, disc_loss = 0.00112943146346769
Trained batch 347 in epoch 3, gen_loss = 1.1881699764180458, disc_loss = 0.001128167298984722
Trained batch 348 in epoch 3, gen_loss = 1.1879517113240197, disc_loss = 0.0011265489517862542
Trained batch 349 in epoch 3, gen_loss = 1.1876597223963057, disc_loss = 0.0011246623541644241
Trained batch 350 in epoch 3, gen_loss = 1.187868654558122, disc_loss = 0.0011227887756561999
Trained batch 351 in epoch 3, gen_loss = 1.1881883208724586, disc_loss = 0.0011212945346828333
Trained batch 352 in epoch 3, gen_loss = 1.1884622827130067, disc_loss = 0.0011199378937719621
Trained batch 353 in epoch 3, gen_loss = 1.1879318248754167, disc_loss = 0.0011194813797183961
Trained batch 354 in epoch 3, gen_loss = 1.1880769430751532, disc_loss = 0.0011191977320393076
Trained batch 355 in epoch 3, gen_loss = 1.1879615505759635, disc_loss = 0.001118042379684074
Trained batch 356 in epoch 3, gen_loss = 1.1875757720290112, disc_loss = 0.0011173662476757467
Trained batch 357 in epoch 3, gen_loss = 1.1869835394054817, disc_loss = 0.0011160906014281752
Trained batch 358 in epoch 3, gen_loss = 1.186646939652212, disc_loss = 0.0011147986106431204
Trained batch 359 in epoch 3, gen_loss = 1.187126761674881, disc_loss = 0.001113242518355643
Trained batch 360 in epoch 3, gen_loss = 1.1872599950457543, disc_loss = 0.00111139718654541
Trained batch 361 in epoch 3, gen_loss = 1.1872946326903875, disc_loss = 0.0011093012736682543
Trained batch 362 in epoch 3, gen_loss = 1.187113311336717, disc_loss = 0.0011069060731971041
Trained batch 363 in epoch 3, gen_loss = 1.186698350605074, disc_loss = 0.0011047304656780657
Trained batch 364 in epoch 3, gen_loss = 1.1869235319634006, disc_loss = 0.0011029849266266604
Trained batch 365 in epoch 3, gen_loss = 1.1873151158374515, disc_loss = 0.0011019306442248025
Trained batch 366 in epoch 3, gen_loss = 1.1867047100041153, disc_loss = 0.0011007259657358425
Trained batch 367 in epoch 3, gen_loss = 1.1866576299071312, disc_loss = 0.0010990349243476649
Trained batch 368 in epoch 3, gen_loss = 1.1861322066648219, disc_loss = 0.0010974406368281506
Trained batch 369 in epoch 3, gen_loss = 1.1864292433132997, disc_loss = 0.0010969830430317292
Trained batch 370 in epoch 3, gen_loss = 1.1858790577903913, disc_loss = 0.0010965533452651356
Trained batch 371 in epoch 3, gen_loss = 1.1861415789011986, disc_loss = 0.001094508329877362
Trained batch 372 in epoch 3, gen_loss = 1.1859196461237786, disc_loss = 0.001093193656496826
Trained batch 373 in epoch 3, gen_loss = 1.1857044182040475, disc_loss = 0.0010923037130306575
Trained batch 374 in epoch 3, gen_loss = 1.184907886981964, disc_loss = 0.001093597834968629
Trained batch 375 in epoch 3, gen_loss = 1.1849085820165086, disc_loss = 0.0010972291372726953
Trained batch 376 in epoch 3, gen_loss = 1.1850307479461244, disc_loss = 0.0011002525788888122
Trained batch 377 in epoch 3, gen_loss = 1.1847563933127772, disc_loss = 0.0011013204628917655
Trained batch 378 in epoch 3, gen_loss = 1.1846498155027707, disc_loss = 0.0011007219404710143
Trained batch 379 in epoch 3, gen_loss = 1.1855482146928185, disc_loss = 0.0010990944548163832
Trained batch 380 in epoch 3, gen_loss = 1.1851203674719402, disc_loss = 0.0011001255207318016
Trained batch 381 in epoch 3, gen_loss = 1.1850052767711161, disc_loss = 0.0011061089475933555
Trained batch 382 in epoch 3, gen_loss = 1.1846410806434273, disc_loss = 0.0011108478744542858
Trained batch 383 in epoch 3, gen_loss = 1.1850506025366485, disc_loss = 0.0011111168188335796
Trained batch 384 in epoch 3, gen_loss = 1.1846884893132494, disc_loss = 0.0011101918206958392
Trained batch 385 in epoch 3, gen_loss = 1.1844408584691082, disc_loss = 0.001112223223086695
Trained batch 386 in epoch 3, gen_loss = 1.1839558824088223, disc_loss = 0.0011168490659950292
Trained batch 387 in epoch 3, gen_loss = 1.184104461798963, disc_loss = 0.0011186037520075711
Trained batch 388 in epoch 3, gen_loss = 1.1840731296257372, disc_loss = 0.001119525901095494
Trained batch 389 in epoch 3, gen_loss = 1.1839167883762947, disc_loss = 0.0011186102661528052
Trained batch 390 in epoch 3, gen_loss = 1.183777212334411, disc_loss = 0.0011164658127011389
Trained batch 391 in epoch 3, gen_loss = 1.1840730189364783, disc_loss = 0.0011158615220572719
Trained batch 392 in epoch 3, gen_loss = 1.1843656506247193, disc_loss = 0.0011187287415339287
Trained batch 393 in epoch 3, gen_loss = 1.1840813621349142, disc_loss = 0.0011223784331654831
Trained batch 394 in epoch 3, gen_loss = 1.1838258971141864, disc_loss = 0.0011222126538190354
Trained batch 395 in epoch 3, gen_loss = 1.1835388166434837, disc_loss = 0.001120331867195541
Trained batch 396 in epoch 3, gen_loss = 1.1835187939312355, disc_loss = 0.001118828561554325
Trained batch 397 in epoch 3, gen_loss = 1.1833324484789192, disc_loss = 0.001118442304243729
Trained batch 398 in epoch 3, gen_loss = 1.1836334106916173, disc_loss = 0.0011180884774554321
Trained batch 399 in epoch 3, gen_loss = 1.1829800589382649, disc_loss = 0.0011176479865025613
Trained batch 400 in epoch 3, gen_loss = 1.182591051680786, disc_loss = 0.0011179936015000102
Trained batch 401 in epoch 3, gen_loss = 1.1823667642192461, disc_loss = 0.0011168272978095083
Trained batch 402 in epoch 3, gen_loss = 1.1822810875570804, disc_loss = 0.0011162934684360436
Trained batch 403 in epoch 3, gen_loss = 1.1820137481583226, disc_loss = 0.001118218483993182
Trained batch 404 in epoch 3, gen_loss = 1.1819754622600698, disc_loss = 0.0011169901613166187
Trained batch 405 in epoch 3, gen_loss = 1.1821177503451925, disc_loss = 0.0011154622860809701
Trained batch 406 in epoch 3, gen_loss = 1.1821777526225152, disc_loss = 0.0011133781330146843
Trained batch 407 in epoch 3, gen_loss = 1.1821585144190228, disc_loss = 0.0011112461889555847
Trained batch 408 in epoch 3, gen_loss = 1.1817351228450506, disc_loss = 0.0011100774626421211
Trained batch 409 in epoch 3, gen_loss = 1.1821559075902148, disc_loss = 0.001111382182876341
Trained batch 410 in epoch 3, gen_loss = 1.181953733129803, disc_loss = 0.0011142515083460518
Trained batch 411 in epoch 3, gen_loss = 1.181947731421989, disc_loss = 0.0011177187506406165
Trained batch 412 in epoch 3, gen_loss = 1.1820849377941565, disc_loss = 0.0011191409831084694
Trained batch 413 in epoch 3, gen_loss = 1.1815814689737587, disc_loss = 0.0011187375843784196
Trained batch 414 in epoch 3, gen_loss = 1.1816418593188367, disc_loss = 0.0011213784295776635
Trained batch 415 in epoch 3, gen_loss = 1.1813475142877836, disc_loss = 0.0011261451950304036
Trained batch 416 in epoch 3, gen_loss = 1.181339359111923, disc_loss = 0.0011307623312259718
Trained batch 417 in epoch 3, gen_loss = 1.1811156774822034, disc_loss = 0.0011337131704162009
Trained batch 418 in epoch 3, gen_loss = 1.1809758878266328, disc_loss = 0.001133469458140693
Trained batch 419 in epoch 3, gen_loss = 1.180659064224788, disc_loss = 0.0011321231361459164
Trained batch 420 in epoch 3, gen_loss = 1.180744514046259, disc_loss = 0.001131811635376556
Trained batch 421 in epoch 3, gen_loss = 1.180421388827229, disc_loss = 0.001131342280546029
Trained batch 422 in epoch 3, gen_loss = 1.1801646671678439, disc_loss = 0.0011298799570872784
Trained batch 423 in epoch 3, gen_loss = 1.180448037835787, disc_loss = 0.0011288874586926057
Trained batch 424 in epoch 3, gen_loss = 1.1800589438045725, disc_loss = 0.001128029369728585
Trained batch 425 in epoch 3, gen_loss = 1.180039022170322, disc_loss = 0.0011267965358417993
Trained batch 426 in epoch 3, gen_loss = 1.1795819514808388, disc_loss = 0.00112515477716745
Trained batch 427 in epoch 3, gen_loss = 1.179547166434404, disc_loss = 0.0011231636606544697
Trained batch 428 in epoch 3, gen_loss = 1.1798203641718084, disc_loss = 0.0011213836189245996
Trained batch 429 in epoch 3, gen_loss = 1.179846901671831, disc_loss = 0.0011195885532245928
Trained batch 430 in epoch 3, gen_loss = 1.1797706375542483, disc_loss = 0.0011189144424861297
Trained batch 431 in epoch 3, gen_loss = 1.179899954409511, disc_loss = 0.0011200944373841695
Trained batch 432 in epoch 3, gen_loss = 1.180464784487841, disc_loss = 0.0011230666114366344
Trained batch 433 in epoch 3, gen_loss = 1.1806222906310437, disc_loss = 0.0011292505115906338
Trained batch 434 in epoch 3, gen_loss = 1.180645316770707, disc_loss = 0.0011396333174151102
Trained batch 435 in epoch 3, gen_loss = 1.1805261061825882, disc_loss = 0.0011470599464525858
Trained batch 436 in epoch 3, gen_loss = 1.1801824787934256, disc_loss = 0.001150290589936523
Trained batch 437 in epoch 3, gen_loss = 1.1796699505146235, disc_loss = 0.0011523403371187229
Trained batch 438 in epoch 3, gen_loss = 1.1796820895546933, disc_loss = 0.0011527430959131276
Trained batch 439 in epoch 3, gen_loss = 1.1797359118407422, disc_loss = 0.0011525485776060537
Trained batch 440 in epoch 3, gen_loss = 1.179732139824199, disc_loss = 0.0011519155001582983
Trained batch 441 in epoch 3, gen_loss = 1.180180182688916, disc_loss = 0.0011508728216396437
Trained batch 442 in epoch 3, gen_loss = 1.1799170288759753, disc_loss = 0.0011501022910241471
Trained batch 443 in epoch 3, gen_loss = 1.1804186746075347, disc_loss = 0.0011498665711163387
Trained batch 444 in epoch 3, gen_loss = 1.1801304339023118, disc_loss = 0.0011514788255778277
Trained batch 445 in epoch 3, gen_loss = 1.1798312887215294, disc_loss = 0.0011519970304258022
Trained batch 446 in epoch 3, gen_loss = 1.1804158094211978, disc_loss = 0.001150493465565297
Trained batch 447 in epoch 3, gen_loss = 1.1802104361621397, disc_loss = 0.0011522686649771327
Trained batch 448 in epoch 3, gen_loss = 1.1796491878866353, disc_loss = 0.0011582590312189328
Trained batch 449 in epoch 3, gen_loss = 1.1800111304389105, disc_loss = 0.001162970809091348
Trained batch 450 in epoch 3, gen_loss = 1.1799689026470987, disc_loss = 0.0011639317519616381
Trained batch 451 in epoch 3, gen_loss = 1.179880724016544, disc_loss = 0.0011634871681270795
Trained batch 452 in epoch 3, gen_loss = 1.1801733462752622, disc_loss = 0.001163810778649012
Trained batch 453 in epoch 3, gen_loss = 1.1798830925105426, disc_loss = 0.0011631071315024413
Trained batch 454 in epoch 3, gen_loss = 1.1797622641364296, disc_loss = 0.0011622456237891238
Trained batch 455 in epoch 3, gen_loss = 1.1795719085555327, disc_loss = 0.0011609941014109624
Trained batch 456 in epoch 3, gen_loss = 1.1794089978842037, disc_loss = 0.0011597001341824202
Trained batch 457 in epoch 3, gen_loss = 1.1792027997137677, disc_loss = 0.0011581898656179092
Trained batch 458 in epoch 3, gen_loss = 1.1791666600698998, disc_loss = 0.0011567135366764882
Trained batch 459 in epoch 3, gen_loss = 1.1791419272837431, disc_loss = 0.0011573021511139814
Trained batch 460 in epoch 3, gen_loss = 1.179185804731158, disc_loss = 0.0011578884018105789
Trained batch 461 in epoch 3, gen_loss = 1.1792203479515009, disc_loss = 0.0011584065347500206
Trained batch 462 in epoch 3, gen_loss = 1.180278102213569, disc_loss = 0.0011585289658613998
Trained batch 463 in epoch 3, gen_loss = 1.1800650638239136, disc_loss = 0.0011584654944115378
Trained batch 464 in epoch 3, gen_loss = 1.1802579620833038, disc_loss = 0.0011579082773995877
Trained batch 465 in epoch 3, gen_loss = 1.1803171596301982, disc_loss = 0.0011574633122167486
Trained batch 466 in epoch 3, gen_loss = 1.1802256114988308, disc_loss = 0.0011564127526460894
Trained batch 467 in epoch 3, gen_loss = 1.1806001339712713, disc_loss = 0.0011565558838150087
Trained batch 468 in epoch 3, gen_loss = 1.1804257435585135, disc_loss = 0.00115834333325626
Trained batch 469 in epoch 3, gen_loss = 1.1809906183405126, disc_loss = 0.001158356039253549
Trained batch 470 in epoch 3, gen_loss = 1.1810477306382166, disc_loss = 0.0011571422232561617
Trained batch 471 in epoch 3, gen_loss = 1.1808656171216803, disc_loss = 0.0011558563898796496
Trained batch 472 in epoch 3, gen_loss = 1.1813063669406334, disc_loss = 0.0011542869637827104
Trained batch 473 in epoch 3, gen_loss = 1.1816018291666537, disc_loss = 0.001152865672937176
Trained batch 474 in epoch 3, gen_loss = 1.1816812972018593, disc_loss = 0.0011510932690304654
Trained batch 475 in epoch 3, gen_loss = 1.1812420705286395, disc_loss = 0.00114932920225038
Trained batch 476 in epoch 3, gen_loss = 1.1810919056398563, disc_loss = 0.001147367798793325
Trained batch 477 in epoch 3, gen_loss = 1.1805510683039742, disc_loss = 0.001147043507999914
Trained batch 478 in epoch 3, gen_loss = 1.180252373342972, disc_loss = 0.0011504076564106565
Trained batch 479 in epoch 3, gen_loss = 1.180097521096468, disc_loss = 0.0011546702610151745
Trained batch 480 in epoch 3, gen_loss = 1.1800874620366246, disc_loss = 0.0011570416091689103
Trained batch 481 in epoch 3, gen_loss = 1.1800954908256214, disc_loss = 0.0011568892375154022
Trained batch 482 in epoch 3, gen_loss = 1.1801970313548054, disc_loss = 0.0011555860488804241
Trained batch 483 in epoch 3, gen_loss = 1.1803207358052907, disc_loss = 0.0011545563448778033
Trained batch 484 in epoch 3, gen_loss = 1.1804222067606818, disc_loss = 0.0011535018917410778
Trained batch 485 in epoch 3, gen_loss = 1.1803813844060702, disc_loss = 0.001152069019250727
Trained batch 486 in epoch 3, gen_loss = 1.1804297714507554, disc_loss = 0.0011509288919267762
Trained batch 487 in epoch 3, gen_loss = 1.1804867682398343, disc_loss = 0.0011498355255693629
Trained batch 488 in epoch 3, gen_loss = 1.1802926173239399, disc_loss = 0.0011485105898273644
Trained batch 489 in epoch 3, gen_loss = 1.1802130662665076, disc_loss = 0.0011471246409275075
Trained batch 490 in epoch 3, gen_loss = 1.1807251309183124, disc_loss = 0.0011455957427070344
Trained batch 491 in epoch 3, gen_loss = 1.1805632526312417, disc_loss = 0.0011448712625937835
Trained batch 492 in epoch 3, gen_loss = 1.1806741723182477, disc_loss = 0.0011441422728564246
Trained batch 493 in epoch 3, gen_loss = 1.1806256807284798, disc_loss = 0.0011425341636134285
Trained batch 494 in epoch 3, gen_loss = 1.1800635219824434, disc_loss = 0.0011418423509269933
Trained batch 495 in epoch 3, gen_loss = 1.1800843486862798, disc_loss = 0.001141996885904049
Trained batch 496 in epoch 3, gen_loss = 1.1799187636231512, disc_loss = 0.001141252246528622
Trained batch 497 in epoch 3, gen_loss = 1.1800310750562981, disc_loss = 0.0011395888921608831
Trained batch 498 in epoch 3, gen_loss = 1.1798899818756776, disc_loss = 0.0011385170436841725
Trained batch 499 in epoch 3, gen_loss = 1.1796605803966522, disc_loss = 0.0011368632129451725
Trained batch 500 in epoch 3, gen_loss = 1.1792391186464808, disc_loss = 0.0011355756891962465
Trained batch 501 in epoch 3, gen_loss = 1.1790501446837922, disc_loss = 0.0011340074752333603
Trained batch 502 in epoch 3, gen_loss = 1.1789518120748623, disc_loss = 0.0011326541207236872
Trained batch 503 in epoch 3, gen_loss = 1.178707172709798, disc_loss = 0.0011312889013107264
Trained batch 504 in epoch 3, gen_loss = 1.1783978745488837, disc_loss = 0.0011303319410469364
Trained batch 505 in epoch 3, gen_loss = 1.1786143984719228, disc_loss = 0.0011315232437813063
Trained batch 506 in epoch 3, gen_loss = 1.1784847426931768, disc_loss = 0.0011342442403026237
Trained batch 507 in epoch 3, gen_loss = 1.1790618643047304, disc_loss = 0.0011365128339666554
Trained batch 508 in epoch 3, gen_loss = 1.1789872412128861, disc_loss = 0.0011370989188063828
Trained batch 509 in epoch 3, gen_loss = 1.1790822618147907, disc_loss = 0.001136582727143404
Trained batch 510 in epoch 3, gen_loss = 1.1788041066750155, disc_loss = 0.0011361005735447368
Trained batch 511 in epoch 3, gen_loss = 1.1788021286483854, disc_loss = 0.0011356186779778454
Trained batch 512 in epoch 3, gen_loss = 1.1787940654141165, disc_loss = 0.0011350877896928434
Trained batch 513 in epoch 3, gen_loss = 1.1787727238603138, disc_loss = 0.0011343762103537486
Trained batch 514 in epoch 3, gen_loss = 1.1787136723694291, disc_loss = 0.001133076255113673
Trained batch 515 in epoch 3, gen_loss = 1.179075710764227, disc_loss = 0.0011320015862654052
Trained batch 516 in epoch 3, gen_loss = 1.1792963814689297, disc_loss = 0.0011308984476043906
Trained batch 517 in epoch 3, gen_loss = 1.1793093326929454, disc_loss = 0.0011291809566139196
Trained batch 518 in epoch 3, gen_loss = 1.1793219122124086, disc_loss = 0.0011275511565066421
Trained batch 519 in epoch 3, gen_loss = 1.179072365623254, disc_loss = 0.001126145449681924
Trained batch 520 in epoch 3, gen_loss = 1.1790400638232532, disc_loss = 0.0011250075561060587
Trained batch 521 in epoch 3, gen_loss = 1.1787663969957052, disc_loss = 0.0011246697165400246
Trained batch 522 in epoch 3, gen_loss = 1.1787169791088505, disc_loss = 0.001125049358634474
Trained batch 523 in epoch 3, gen_loss = 1.178642211524585, disc_loss = 0.0011269739979632796
Trained batch 524 in epoch 3, gen_loss = 1.1785632778349378, disc_loss = 0.001130778516554052
Trained batch 525 in epoch 3, gen_loss = 1.1784147590738738, disc_loss = 0.0011330968104993407
Trained batch 526 in epoch 3, gen_loss = 1.1786256361279135, disc_loss = 0.0011341860893392755
Trained batch 527 in epoch 3, gen_loss = 1.1783768880096348, disc_loss = 0.0011334664031341108
Trained batch 528 in epoch 3, gen_loss = 1.1779369702861981, disc_loss = 0.0011322309184046584
Trained batch 529 in epoch 3, gen_loss = 1.1782619331242903, disc_loss = 0.0011310202692292701
Trained batch 530 in epoch 3, gen_loss = 1.178329522439091, disc_loss = 0.0011295397212249165
Trained batch 531 in epoch 3, gen_loss = 1.1786061008845954, disc_loss = 0.0011280413261983242
Trained batch 532 in epoch 3, gen_loss = 1.1785703283537172, disc_loss = 0.0011264397057234598
Trained batch 533 in epoch 3, gen_loss = 1.1781934798880016, disc_loss = 0.0011251095989989362
Trained batch 534 in epoch 3, gen_loss = 1.1780611864874295, disc_loss = 0.0011238278115546835
Trained batch 535 in epoch 3, gen_loss = 1.177734687924385, disc_loss = 0.0011232965526456855
Trained batch 536 in epoch 3, gen_loss = 1.1775028436987538, disc_loss = 0.0011226968313294188
Trained batch 537 in epoch 3, gen_loss = 1.1771333944398674, disc_loss = 0.0011220483159015413
Trained batch 538 in epoch 3, gen_loss = 1.1771424320942838, disc_loss = 0.0011207417337978102
Trained batch 539 in epoch 3, gen_loss = 1.177169845280824, disc_loss = 0.0011191606038159483
Trained batch 540 in epoch 3, gen_loss = 1.1771336760847053, disc_loss = 0.0011178305078975257
Trained batch 541 in epoch 3, gen_loss = 1.1769166063118686, disc_loss = 0.0011173250376288967
Trained batch 542 in epoch 3, gen_loss = 1.1770739682691094, disc_loss = 0.0011165503138169462
Trained batch 543 in epoch 3, gen_loss = 1.1776396772440743, disc_loss = 0.0011151148040452802
Trained batch 544 in epoch 3, gen_loss = 1.1778525024379065, disc_loss = 0.0011136871862434568
Trained batch 545 in epoch 3, gen_loss = 1.1776636157717024, disc_loss = 0.0011123456720253384
Trained batch 546 in epoch 3, gen_loss = 1.1772470513471083, disc_loss = 0.0011110279303775347
Trained batch 547 in epoch 3, gen_loss = 1.1773110297474547, disc_loss = 0.0011099078377558387
Trained batch 548 in epoch 3, gen_loss = 1.1770248269774224, disc_loss = 0.0011098028316170161
Trained batch 549 in epoch 3, gen_loss = 1.1769308510693637, disc_loss = 0.001109940651962957
Trained batch 550 in epoch 3, gen_loss = 1.176807144808899, disc_loss = 0.0011097880258557037
Trained batch 551 in epoch 3, gen_loss = 1.1763829904190009, disc_loss = 0.001109228443543754
Trained batch 552 in epoch 3, gen_loss = 1.1768186368304179, disc_loss = 0.0011087865122929924
Trained batch 553 in epoch 3, gen_loss = 1.1770324954487357, disc_loss = 0.001107779670717272
Trained batch 554 in epoch 3, gen_loss = 1.1773820260623553, disc_loss = 0.0011061552623580504
Trained batch 555 in epoch 3, gen_loss = 1.1778687978391167, disc_loss = 0.0011048750501090874
Trained batch 556 in epoch 3, gen_loss = 1.177718812088136, disc_loss = 0.0011036009954633877
Trained batch 557 in epoch 3, gen_loss = 1.1776332889406484, disc_loss = 0.001102108911107925
Trained batch 558 in epoch 3, gen_loss = 1.1774383851581909, disc_loss = 0.0011005336322169
Trained batch 559 in epoch 3, gen_loss = 1.1771496304443905, disc_loss = 0.0010989761042115528
Trained batch 560 in epoch 3, gen_loss = 1.177576226984116, disc_loss = 0.0010985652207213896
Trained batch 561 in epoch 3, gen_loss = 1.1776152940407343, disc_loss = 0.0011009070364328755
Trained batch 562 in epoch 3, gen_loss = 1.177832739391293, disc_loss = 0.0011031309327101963
Trained batch 563 in epoch 3, gen_loss = 1.1776791882853137, disc_loss = 0.0011064152379389373
Trained batch 564 in epoch 3, gen_loss = 1.1776580506721428, disc_loss = 0.0011109196458092222
Trained batch 565 in epoch 3, gen_loss = 1.177434468859076, disc_loss = 0.0011189310522632782
Trained batch 566 in epoch 3, gen_loss = 1.1774682689596105, disc_loss = 0.0011322047920251672
Trained batch 567 in epoch 3, gen_loss = 1.17752766651167, disc_loss = 0.0011461712601117079
Trained batch 568 in epoch 3, gen_loss = 1.1777663408976657, disc_loss = 0.001153392429247307
Trained batch 569 in epoch 3, gen_loss = 1.1777453729980871, disc_loss = 0.0011561593164132271
Trained batch 570 in epoch 3, gen_loss = 1.177760897292356, disc_loss = 0.0011576871925036483
Trained batch 571 in epoch 3, gen_loss = 1.1777001179598428, disc_loss = 0.0011588967103994259
Trained batch 572 in epoch 3, gen_loss = 1.1778670079212954, disc_loss = 0.0011603515104292755
Trained batch 573 in epoch 3, gen_loss = 1.178354093629724, disc_loss = 0.0011614820661495005
Trained batch 574 in epoch 3, gen_loss = 1.1781330790727036, disc_loss = 0.0011622975368568997
Trained batch 575 in epoch 3, gen_loss = 1.1779348521182935, disc_loss = 0.0011628937704952274
Trained batch 576 in epoch 3, gen_loss = 1.1779992439924534, disc_loss = 0.0011627075545184325
Trained batch 577 in epoch 3, gen_loss = 1.1781146724331337, disc_loss = 0.001161877982189297
Trained batch 578 in epoch 3, gen_loss = 1.1780119129619038, disc_loss = 0.0011613357420646809
Trained batch 579 in epoch 3, gen_loss = 1.178141147103803, disc_loss = 0.001160783637771664
Trained batch 580 in epoch 3, gen_loss = 1.1778098685400826, disc_loss = 0.0011595051545838517
Trained batch 581 in epoch 3, gen_loss = 1.177744355193528, disc_loss = 0.0011584132359852403
Trained batch 582 in epoch 3, gen_loss = 1.1778927493463454, disc_loss = 0.001157924573301213
Trained batch 583 in epoch 3, gen_loss = 1.1778046976621837, disc_loss = 0.0011569382228889767
Trained batch 584 in epoch 3, gen_loss = 1.1778548401645106, disc_loss = 0.0011555616104822113
Trained batch 585 in epoch 3, gen_loss = 1.1778738990985493, disc_loss = 0.0011544627786457854
Trained batch 586 in epoch 3, gen_loss = 1.1779945644040732, disc_loss = 0.0011533399009543632
Trained batch 587 in epoch 3, gen_loss = 1.1777592942017276, disc_loss = 0.0011520357541417224
Trained batch 588 in epoch 3, gen_loss = 1.1774478537522268, disc_loss = 0.001150913660598133
Trained batch 589 in epoch 3, gen_loss = 1.1774695202455683, disc_loss = 0.001151164906948876
Trained batch 590 in epoch 3, gen_loss = 1.177597081600712, disc_loss = 0.0011515103221893415
Trained batch 591 in epoch 3, gen_loss = 1.177669248065433, disc_loss = 0.0011506863405687713
Trained batch 592 in epoch 3, gen_loss = 1.1779494965056343, disc_loss = 0.0011495948415243696
Trained batch 593 in epoch 3, gen_loss = 1.1776174487489643, disc_loss = 0.0011494448214703905
Trained batch 594 in epoch 3, gen_loss = 1.177694245346454, disc_loss = 0.0011488181544015842
Trained batch 595 in epoch 3, gen_loss = 1.1776004813661511, disc_loss = 0.0011483153369367175
Trained batch 596 in epoch 3, gen_loss = 1.1775134029100889, disc_loss = 0.0011489778813694243
Trained batch 597 in epoch 3, gen_loss = 1.1770781715179366, disc_loss = 0.0011492485600653303
Trained batch 598 in epoch 3, gen_loss = 1.1770323057206524, disc_loss = 0.0011489714931617748
Trained batch 599 in epoch 3, gen_loss = 1.177438275416692, disc_loss = 0.0011488188602622055
Trained batch 600 in epoch 3, gen_loss = 1.1772535511737259, disc_loss = 0.0011478607800098433
Trained batch 601 in epoch 3, gen_loss = 1.17716022266502, disc_loss = 0.001147320717918351
Trained batch 602 in epoch 3, gen_loss = 1.177594729521579, disc_loss = 0.0011467593606450605
Trained batch 603 in epoch 3, gen_loss = 1.1775664770050553, disc_loss = 0.0011452416093736294
Trained batch 604 in epoch 3, gen_loss = 1.1773917611965463, disc_loss = 0.0011438121403421252
Trained batch 605 in epoch 3, gen_loss = 1.177275579557954, disc_loss = 0.0011423149790362034
Trained batch 606 in epoch 3, gen_loss = 1.177045268517546, disc_loss = 0.0011413926634108234
Trained batch 607 in epoch 3, gen_loss = 1.1770174499405057, disc_loss = 0.0011411999102117413
Trained batch 608 in epoch 3, gen_loss = 1.1769197546985546, disc_loss = 0.0011402163980968375
Trained batch 609 in epoch 3, gen_loss = 1.1770294545126743, disc_loss = 0.0011387950178239586
Trained batch 610 in epoch 3, gen_loss = 1.1770016434930155, disc_loss = 0.0011375045920466874
Trained batch 611 in epoch 3, gen_loss = 1.176877194565106, disc_loss = 0.001136290647207038
Trained batch 612 in epoch 3, gen_loss = 1.1766739636416537, disc_loss = 0.0011362512150135948
Trained batch 613 in epoch 3, gen_loss = 1.1766595850161699, disc_loss = 0.0011376027821836969
Trained batch 614 in epoch 3, gen_loss = 1.1764588257161583, disc_loss = 0.0011389447245992931
Trained batch 615 in epoch 3, gen_loss = 1.17633119960884, disc_loss = 0.0011389722538580544
Trained batch 616 in epoch 3, gen_loss = 1.1760863496573277, disc_loss = 0.0011384046884729848
Trained batch 617 in epoch 3, gen_loss = 1.176499281886326, disc_loss = 0.0011379213066614146
Trained batch 618 in epoch 3, gen_loss = 1.1764415620024253, disc_loss = 0.001137803008835176
Trained batch 619 in epoch 3, gen_loss = 1.1768398765594728, disc_loss = 0.0011397427912602472
Trained batch 620 in epoch 3, gen_loss = 1.1772090789776493, disc_loss = 0.0011420076691501305
Trained batch 621 in epoch 3, gen_loss = 1.177239235957719, disc_loss = 0.0011426909768956165
Trained batch 622 in epoch 3, gen_loss = 1.1775102839232638, disc_loss = 0.0011418252958849604
Trained batch 623 in epoch 3, gen_loss = 1.1776618382487543, disc_loss = 0.001141026866603986
Trained batch 624 in epoch 3, gen_loss = 1.177415930747986, disc_loss = 0.0011419134532567113
Trained batch 625 in epoch 3, gen_loss = 1.177587453168802, disc_loss = 0.001143415132081865
Trained batch 626 in epoch 3, gen_loss = 1.177594687189592, disc_loss = 0.0011433111267454739
Trained batch 627 in epoch 3, gen_loss = 1.1771533083004557, disc_loss = 0.0011429042120410017
Trained batch 628 in epoch 3, gen_loss = 1.1773814427265112, disc_loss = 0.0011429873795121973
Trained batch 629 in epoch 3, gen_loss = 1.1772416023981003, disc_loss = 0.0011438758507470734
Trained batch 630 in epoch 3, gen_loss = 1.17757261422848, disc_loss = 0.0011465718372220914
Trained batch 631 in epoch 3, gen_loss = 1.177879278984251, disc_loss = 0.0011513105639579994
Trained batch 632 in epoch 3, gen_loss = 1.1781133029133222, disc_loss = 0.0011552302791655363
Trained batch 633 in epoch 3, gen_loss = 1.1779814905924753, disc_loss = 0.0011568533671907463
Trained batch 634 in epoch 3, gen_loss = 1.1780010013129767, disc_loss = 0.0011578682732610692
Trained batch 635 in epoch 3, gen_loss = 1.1778233377438672, disc_loss = 0.0011613044423126593
Trained batch 636 in epoch 3, gen_loss = 1.1780648712460624, disc_loss = 0.001164619859081022
Trained batch 637 in epoch 3, gen_loss = 1.1781395537352488, disc_loss = 0.0011652703082672873
Trained batch 638 in epoch 3, gen_loss = 1.1779738216892655, disc_loss = 0.0011645162071182258
Trained batch 639 in epoch 3, gen_loss = 1.1778831278905273, disc_loss = 0.0011639935176845028
Trained batch 640 in epoch 3, gen_loss = 1.1779450120494444, disc_loss = 0.0011636858389479675
Trained batch 641 in epoch 3, gen_loss = 1.1778877600331172, disc_loss = 0.001165799007468532
Trained batch 642 in epoch 3, gen_loss = 1.1777450708356652, disc_loss = 0.0011684169684023297
Trained batch 643 in epoch 3, gen_loss = 1.1776804348326617, disc_loss = 0.0011681579176776881
Trained batch 644 in epoch 3, gen_loss = 1.1773964360702869, disc_loss = 0.00116923121169621
Trained batch 645 in epoch 3, gen_loss = 1.1776517253173024, disc_loss = 0.0011700578670514078
Trained batch 646 in epoch 3, gen_loss = 1.1777676839548432, disc_loss = 0.0011691246563629888
Trained batch 647 in epoch 3, gen_loss = 1.1780112014140611, disc_loss = 0.001167856199628412
Trained batch 648 in epoch 3, gen_loss = 1.1781896663189668, disc_loss = 0.00116693023559049
Trained batch 649 in epoch 3, gen_loss = 1.1779534033628611, disc_loss = 0.0011665223932448919
Trained batch 650 in epoch 3, gen_loss = 1.1776687540400046, disc_loss = 0.0011652828320362298
Trained batch 651 in epoch 3, gen_loss = 1.1779744970652224, disc_loss = 0.0011645787024775526
Trained batch 652 in epoch 3, gen_loss = 1.1778216725286628, disc_loss = 0.0011654525374759069
Trained batch 653 in epoch 3, gen_loss = 1.1777169095631403, disc_loss = 0.001166742742309042
Trained batch 654 in epoch 3, gen_loss = 1.1776141352325906, disc_loss = 0.0011662441733709132
Trained batch 655 in epoch 3, gen_loss = 1.1773162898493976, disc_loss = 0.0011652598690178398
Trained batch 656 in epoch 3, gen_loss = 1.1769491713522413, disc_loss = 0.0011649420827324537
Trained batch 657 in epoch 3, gen_loss = 1.1768089112539784, disc_loss = 0.0011635844379530422
Trained batch 658 in epoch 3, gen_loss = 1.176901411756941, disc_loss = 0.0011632485867778973
Trained batch 659 in epoch 3, gen_loss = 1.1767978637507468, disc_loss = 0.0011630214750766755
Trained batch 660 in epoch 3, gen_loss = 1.1768330701721237, disc_loss = 0.0011618365767889526
Trained batch 661 in epoch 3, gen_loss = 1.1770775613467859, disc_loss = 0.0011614403230900626
Trained batch 662 in epoch 3, gen_loss = 1.1770770734971105, disc_loss = 0.0011619347755882894
Trained batch 663 in epoch 3, gen_loss = 1.1767925173044205, disc_loss = 0.0011613249828890302
Trained batch 664 in epoch 3, gen_loss = 1.1769571881545218, disc_loss = 0.0011599893360468734
Trained batch 665 in epoch 3, gen_loss = 1.1768350636994875, disc_loss = 0.0011592138604597992
Trained batch 666 in epoch 3, gen_loss = 1.1765555599103983, disc_loss = 0.0011588168900175163
Trained batch 667 in epoch 3, gen_loss = 1.1762976280586448, disc_loss = 0.0011580777012089177
Trained batch 668 in epoch 3, gen_loss = 1.1764359857291207, disc_loss = 0.0011585475012948195
Trained batch 669 in epoch 3, gen_loss = 1.1766707557350842, disc_loss = 0.0011587360035454327
Trained batch 670 in epoch 3, gen_loss = 1.1767798953546675, disc_loss = 0.0011576951538915601
Trained batch 671 in epoch 3, gen_loss = 1.1767601972179753, disc_loss = 0.0011566206055379422
Trained batch 672 in epoch 3, gen_loss = 1.176728304746778, disc_loss = 0.0011560491680698316
Trained batch 673 in epoch 3, gen_loss = 1.176468075382957, disc_loss = 0.0011595258331123202
Trained batch 674 in epoch 3, gen_loss = 1.1765683107022886, disc_loss = 0.0011680548695450718
Trained batch 675 in epoch 3, gen_loss = 1.176859625345151, disc_loss = 0.0011750405605489074
Trained batch 676 in epoch 3, gen_loss = 1.176579679308825, disc_loss = 0.001177046699953256
Trained batch 677 in epoch 3, gen_loss = 1.1768419099065055, disc_loss = 0.0011772444613973657
Trained batch 678 in epoch 3, gen_loss = 1.1765339727429824, disc_loss = 0.001177132209779733
Trained batch 679 in epoch 3, gen_loss = 1.1766314553863861, disc_loss = 0.0011772147185076713
Trained batch 680 in epoch 3, gen_loss = 1.176422764551272, disc_loss = 0.001177195005268255
Trained batch 681 in epoch 3, gen_loss = 1.1764643559357988, disc_loss = 0.0011775844500081264
Trained batch 682 in epoch 3, gen_loss = 1.1763800492572924, disc_loss = 0.0011775629468535594
Trained batch 683 in epoch 3, gen_loss = 1.1766637661303694, disc_loss = 0.0011776858212358906
Trained batch 684 in epoch 3, gen_loss = 1.1764240111747797, disc_loss = 0.0011771643507535684
Trained batch 685 in epoch 3, gen_loss = 1.176439749429942, disc_loss = 0.0011761358854854372
Trained batch 686 in epoch 3, gen_loss = 1.176832997816272, disc_loss = 0.001175691476462848
Trained batch 687 in epoch 3, gen_loss = 1.1769614552342615, disc_loss = 0.0011746217517421152
Trained batch 688 in epoch 3, gen_loss = 1.176758401798752, disc_loss = 0.0011739621395687877
Trained batch 689 in epoch 3, gen_loss = 1.1765809592993364, disc_loss = 0.001175095265236872
Trained batch 690 in epoch 3, gen_loss = 1.1771019686838307, disc_loss = 0.0011759389460328752
Trained batch 691 in epoch 3, gen_loss = 1.1771053490955705, disc_loss = 0.001175449727023373
Trained batch 692 in epoch 3, gen_loss = 1.1770729543842795, disc_loss = 0.0011751657424674035
Trained batch 693 in epoch 3, gen_loss = 1.1769887521562383, disc_loss = 0.0011745967567339405
Trained batch 694 in epoch 3, gen_loss = 1.1769487878401503, disc_loss = 0.0011736197150463118
Trained batch 695 in epoch 3, gen_loss = 1.1771363538914714, disc_loss = 0.0011725343410317096
Trained batch 696 in epoch 3, gen_loss = 1.1772452656131565, disc_loss = 0.001171339359458461
Trained batch 697 in epoch 3, gen_loss = 1.1772795162433198, disc_loss = 0.001170542423531979
Trained batch 698 in epoch 3, gen_loss = 1.1776548068069763, disc_loss = 0.0011695623080557923
Trained batch 699 in epoch 3, gen_loss = 1.1776969277858733, disc_loss = 0.0011685063664585219
Trained batch 700 in epoch 3, gen_loss = 1.1776254178794066, disc_loss = 0.0011684368267776935
Trained batch 701 in epoch 3, gen_loss = 1.1774533139674412, disc_loss = 0.001168331258492133
Trained batch 702 in epoch 3, gen_loss = 1.1771058268940466, disc_loss = 0.0011673599693465151
Trained batch 703 in epoch 3, gen_loss = 1.1772354818372563, disc_loss = 0.001167820206774195
Trained batch 704 in epoch 3, gen_loss = 1.1770288471634507, disc_loss = 0.001169157584143327
Trained batch 705 in epoch 3, gen_loss = 1.1767132674837248, disc_loss = 0.0011686327015613693
Trained batch 706 in epoch 3, gen_loss = 1.1766992344546015, disc_loss = 0.001167321512030202
Trained batch 707 in epoch 3, gen_loss = 1.1768785574510272, disc_loss = 0.0011660489048780861
Trained batch 708 in epoch 3, gen_loss = 1.1766507621376403, disc_loss = 0.0011646652082777655
Trained batch 709 in epoch 3, gen_loss = 1.1767234143236993, disc_loss = 0.0011635628527048385
Trained batch 710 in epoch 3, gen_loss = 1.176422112685551, disc_loss = 0.0011628776099675293
Trained batch 711 in epoch 3, gen_loss = 1.176382498543584, disc_loss = 0.0011619090758389309
Trained batch 712 in epoch 3, gen_loss = 1.1763638755382362, disc_loss = 0.001160641395036088
Trained batch 713 in epoch 3, gen_loss = 1.1763333156496203, disc_loss = 0.0011593401250647934
Trained batch 714 in epoch 3, gen_loss = 1.176252011735956, disc_loss = 0.0011580336226355546
Trained batch 715 in epoch 3, gen_loss = 1.176096929601451, disc_loss = 0.0011568299299818151
Trained batch 716 in epoch 3, gen_loss = 1.1762715214798474, disc_loss = 0.0011557978260489325
Trained batch 717 in epoch 3, gen_loss = 1.1763820214025822, disc_loss = 0.0011547529544781187
Trained batch 718 in epoch 3, gen_loss = 1.1763222753918718, disc_loss = 0.0011537110015490224
Trained batch 719 in epoch 3, gen_loss = 1.1762439149121444, disc_loss = 0.0011536451531557962
Trained batch 720 in epoch 3, gen_loss = 1.1762582481155448, disc_loss = 0.0011555828371982318
Trained batch 721 in epoch 3, gen_loss = 1.1762278909663415, disc_loss = 0.0011564155095601918
Trained batch 722 in epoch 3, gen_loss = 1.176456104587882, disc_loss = 0.0011555629594069243
Trained batch 723 in epoch 3, gen_loss = 1.1763551733276463, disc_loss = 0.0011546910324057393
Trained batch 724 in epoch 3, gen_loss = 1.1765188392277421, disc_loss = 0.0011535332461112531
Trained batch 725 in epoch 3, gen_loss = 1.1762552166116467, disc_loss = 0.0011531074532017769
Trained batch 726 in epoch 3, gen_loss = 1.1759949483110619, disc_loss = 0.00115379193900832
Trained batch 727 in epoch 3, gen_loss = 1.17582374893047, disc_loss = 0.0011545819371739136
Trained batch 728 in epoch 3, gen_loss = 1.1756508100179979, disc_loss = 0.0011543242996354141
Trained batch 729 in epoch 3, gen_loss = 1.1754580750857313, disc_loss = 0.001153844506447905
Trained batch 730 in epoch 3, gen_loss = 1.175201502609514, disc_loss = 0.0011531903237109512
Trained batch 731 in epoch 3, gen_loss = 1.174987862344648, disc_loss = 0.0011527570176206763
Trained batch 732 in epoch 3, gen_loss = 1.1748356041771653, disc_loss = 0.0011529821319166333
Trained batch 733 in epoch 3, gen_loss = 1.174969884777589, disc_loss = 0.0011550723190440946
Trained batch 734 in epoch 3, gen_loss = 1.1748621692462844, disc_loss = 0.001156983429132042
Trained batch 735 in epoch 3, gen_loss = 1.174815859645605, disc_loss = 0.0011573303578663163
Trained batch 736 in epoch 3, gen_loss = 1.1750995936516668, disc_loss = 0.0011569400273896552
Trained batch 737 in epoch 3, gen_loss = 1.175108949020303, disc_loss = 0.0011561457284626508
Trained batch 738 in epoch 3, gen_loss = 1.1753990243671713, disc_loss = 0.0011554481807424459
Trained batch 739 in epoch 3, gen_loss = 1.1756063433917794, disc_loss = 0.0011546917293516516
Trained batch 740 in epoch 3, gen_loss = 1.1756566063112575, disc_loss = 0.001154314898700402
Trained batch 741 in epoch 3, gen_loss = 1.1753906763467505, disc_loss = 0.0011546982607127713
Trained batch 742 in epoch 3, gen_loss = 1.1756039185607416, disc_loss = 0.001157860553896739
Trained batch 743 in epoch 3, gen_loss = 1.1754810882191504, disc_loss = 0.0011640606608125381
Trained batch 744 in epoch 3, gen_loss = 1.1755374929248887, disc_loss = 0.001167836962439645
Trained batch 745 in epoch 3, gen_loss = 1.1759987992831273, disc_loss = 0.0011688109003375696
Trained batch 746 in epoch 3, gen_loss = 1.1758654822945755, disc_loss = 0.0011693791239622137
Trained batch 747 in epoch 3, gen_loss = 1.175947206702462, disc_loss = 0.00116950679232085
Trained batch 748 in epoch 3, gen_loss = 1.1761820179438878, disc_loss = 0.0011703100849536107
Trained batch 749 in epoch 3, gen_loss = 1.1760146684646606, disc_loss = 0.0011704272768304994
Trained batch 750 in epoch 3, gen_loss = 1.1762015048101961, disc_loss = 0.0011704394910217928
Trained batch 751 in epoch 3, gen_loss = 1.176325555811537, disc_loss = 0.001169962498487563
Trained batch 752 in epoch 3, gen_loss = 1.1763141452870363, disc_loss = 0.0011694244960023666
Trained batch 753 in epoch 3, gen_loss = 1.1762879856069144, disc_loss = 0.0011686080092019513
Trained batch 754 in epoch 3, gen_loss = 1.1762209352278552, disc_loss = 0.0011674458694887896
Trained batch 755 in epoch 3, gen_loss = 1.1762839719731972, disc_loss = 0.001166926930381648
Trained batch 756 in epoch 3, gen_loss = 1.1762526161289593, disc_loss = 0.0011675470964838547
Trained batch 757 in epoch 3, gen_loss = 1.176278259634657, disc_loss = 0.0011687129751688833
Trained batch 758 in epoch 3, gen_loss = 1.1763209834871555, disc_loss = 0.0011715102169373747
Trained batch 759 in epoch 3, gen_loss = 1.1768218211437527, disc_loss = 0.0011727355457735126
Trained batch 760 in epoch 3, gen_loss = 1.1770258935146356, disc_loss = 0.0011724544911716945
Trained batch 761 in epoch 3, gen_loss = 1.176814525928397, disc_loss = 0.0011717028408436583
Trained batch 762 in epoch 3, gen_loss = 1.176908475543381, disc_loss = 0.0011705521604081013
Trained batch 763 in epoch 3, gen_loss = 1.1767282440712314, disc_loss = 0.001169601511938561
Trained batch 764 in epoch 3, gen_loss = 1.1765165057836795, disc_loss = 0.0011686403039550665
Trained batch 765 in epoch 3, gen_loss = 1.1764405511377998, disc_loss = 0.0011675106611512553
Trained batch 766 in epoch 3, gen_loss = 1.176348205029265, disc_loss = 0.001167054675052591
Trained batch 767 in epoch 3, gen_loss = 1.1761811426840723, disc_loss = 0.0011673384052149534
Trained batch 768 in epoch 3, gen_loss = 1.1758722759037241, disc_loss = 0.0011674782318930215
Trained batch 769 in epoch 3, gen_loss = 1.1754882991313935, disc_loss = 0.0011669705935614789
Trained batch 770 in epoch 3, gen_loss = 1.1753885239633295, disc_loss = 0.0011666309039848922
Trained batch 771 in epoch 3, gen_loss = 1.1753946679398186, disc_loss = 0.0011660651342431808
Trained batch 772 in epoch 3, gen_loss = 1.1753631881877953, disc_loss = 0.0011652037549527774
Trained batch 773 in epoch 3, gen_loss = 1.1757223160229913, disc_loss = 0.0011651855532455351
Trained batch 774 in epoch 3, gen_loss = 1.175797065073444, disc_loss = 0.0011665355324024154
Trained batch 775 in epoch 3, gen_loss = 1.175846713335858, disc_loss = 0.0011689146052321093
Trained batch 776 in epoch 3, gen_loss = 1.1759664957894629, disc_loss = 0.0011703390517227707
Trained batch 777 in epoch 3, gen_loss = 1.175798635173273, disc_loss = 0.0011698600669555453
Trained batch 778 in epoch 3, gen_loss = 1.1756721215468469, disc_loss = 0.001168879977911914
Trained batch 779 in epoch 3, gen_loss = 1.175641854527669, disc_loss = 0.0011680520948944971
Trained batch 780 in epoch 3, gen_loss = 1.1754121475885222, disc_loss = 0.0011672787067570417
Trained batch 781 in epoch 3, gen_loss = 1.175595125045313, disc_loss = 0.0011664742143968206
Trained batch 782 in epoch 3, gen_loss = 1.1757537517054328, disc_loss = 0.0011661201821402843
Trained batch 783 in epoch 3, gen_loss = 1.175765508367699, disc_loss = 0.0011650547336585634
Trained batch 784 in epoch 3, gen_loss = 1.175657613034461, disc_loss = 0.0011643846161518197
Trained batch 785 in epoch 3, gen_loss = 1.175705160424303, disc_loss = 0.0011641602917220656
Trained batch 786 in epoch 3, gen_loss = 1.1758320588320303, disc_loss = 0.0011641893367146366
Trained batch 787 in epoch 3, gen_loss = 1.1756571905715816, disc_loss = 0.0011633398267425724
Trained batch 788 in epoch 3, gen_loss = 1.1755291615602181, disc_loss = 0.0011625932613302126
Trained batch 789 in epoch 3, gen_loss = 1.1756482070759882, disc_loss = 0.001161995454347999
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 1.152787685394287, disc_loss = 0.0004570020828396082
Trained batch 1 in epoch 4, gen_loss = 1.1195443272590637, disc_loss = 0.00040337642712984234
Trained batch 2 in epoch 4, gen_loss = 1.0534761746724446, disc_loss = 0.0005056682760672023
Trained batch 3 in epoch 4, gen_loss = 1.018993616104126, disc_loss = 0.0005199402003199793
Trained batch 4 in epoch 4, gen_loss = 1.0806663751602172, disc_loss = 0.0005165997717995197
Trained batch 5 in epoch 4, gen_loss = 1.1318191687266033, disc_loss = 0.0004973400985666861
Trained batch 6 in epoch 4, gen_loss = 1.1671716145106725, disc_loss = 0.0004820542734315885
Trained batch 7 in epoch 4, gen_loss = 1.1413698941469193, disc_loss = 0.0004723755409941077
Trained batch 8 in epoch 4, gen_loss = 1.1375567250781589, disc_loss = 0.0005377839552238584
Trained batch 9 in epoch 4, gen_loss = 1.1270290851593017, disc_loss = 0.0006193335051648319
Trained batch 10 in epoch 4, gen_loss = 1.1667875159870496, disc_loss = 0.0007257118122652173
Trained batch 11 in epoch 4, gen_loss = 1.1566848854223888, disc_loss = 0.0007989584507110218
Trained batch 12 in epoch 4, gen_loss = 1.158808735700754, disc_loss = 0.0008470695286702651
Trained batch 13 in epoch 4, gen_loss = 1.1645017947469438, disc_loss = 0.0008584719117996949
Trained batch 14 in epoch 4, gen_loss = 1.162747319539388, disc_loss = 0.0008654268924146891
Trained batch 15 in epoch 4, gen_loss = 1.162483960390091, disc_loss = 0.0008725840743863955
Trained batch 16 in epoch 4, gen_loss = 1.1826707685694975, disc_loss = 0.0008886615088319077
Trained batch 17 in epoch 4, gen_loss = 1.1865018606185913, disc_loss = 0.000881807881847231
Trained batch 18 in epoch 4, gen_loss = 1.1867767760628147, disc_loss = 0.0008916964932148786
Trained batch 19 in epoch 4, gen_loss = 1.1940003275871276, disc_loss = 0.0008889984077541157
Trained batch 20 in epoch 4, gen_loss = 1.1939524128323509, disc_loss = 0.0008741478807115484
Trained batch 21 in epoch 4, gen_loss = 1.181010964241895, disc_loss = 0.000860178890765052
Trained batch 22 in epoch 4, gen_loss = 1.1781729382017385, disc_loss = 0.0008524936249317682
Trained batch 23 in epoch 4, gen_loss = 1.1844214474161465, disc_loss = 0.000852844687566782
Trained batch 24 in epoch 4, gen_loss = 1.1839017748832703, disc_loss = 0.0008508412400260567
Trained batch 25 in epoch 4, gen_loss = 1.1805467628515685, disc_loss = 0.0008384351743958318
Trained batch 26 in epoch 4, gen_loss = 1.1704794389230233, disc_loss = 0.0008437848494698604
Trained batch 27 in epoch 4, gen_loss = 1.1740126524652754, disc_loss = 0.0008833267992096287
Trained batch 28 in epoch 4, gen_loss = 1.1734880661142284, disc_loss = 0.0009465022654882793
Trained batch 29 in epoch 4, gen_loss = 1.1735490163167317, disc_loss = 0.0009580318350344896
Trained batch 30 in epoch 4, gen_loss = 1.1695924035964473, disc_loss = 0.0009445817596579511
Trained batch 31 in epoch 4, gen_loss = 1.1674591079354286, disc_loss = 0.000954336073846207
Trained batch 32 in epoch 4, gen_loss = 1.1611979639891423, disc_loss = 0.0009967659716494381
Trained batch 33 in epoch 4, gen_loss = 1.165935507592033, disc_loss = 0.001075890608583851
Trained batch 34 in epoch 4, gen_loss = 1.1637359261512756, disc_loss = 0.0011750121551033642
Trained batch 35 in epoch 4, gen_loss = 1.1624774254030652, disc_loss = 0.00122561822030952
Trained batch 36 in epoch 4, gen_loss = 1.1724828304471195, disc_loss = 0.0012144178507623037
Trained batch 37 in epoch 4, gen_loss = 1.1752742764196897, disc_loss = 0.0012049978525426827
Trained batch 38 in epoch 4, gen_loss = 1.178417785045428, disc_loss = 0.0012135283711055915
Trained batch 39 in epoch 4, gen_loss = 1.179319892823696, disc_loss = 0.0012119093182263896
Trained batch 40 in epoch 4, gen_loss = 1.1749332925168479, disc_loss = 0.00118996992582319
Trained batch 41 in epoch 4, gen_loss = 1.1801984182425909, disc_loss = 0.0011811219848736766
Trained batch 42 in epoch 4, gen_loss = 1.178250480529874, disc_loss = 0.0011805644675786065
Trained batch 43 in epoch 4, gen_loss = 1.1829813298853962, disc_loss = 0.0011722123348259959
Trained batch 44 in epoch 4, gen_loss = 1.1777023063765633, disc_loss = 0.0011554525570116108
Trained batch 45 in epoch 4, gen_loss = 1.1757961317248966, disc_loss = 0.001158316111009892
Trained batch 46 in epoch 4, gen_loss = 1.1751344698540709, disc_loss = 0.0012083993506360245
Trained batch 47 in epoch 4, gen_loss = 1.170733659217755, disc_loss = 0.0012691967688927737
Trained batch 48 in epoch 4, gen_loss = 1.1678857523567823, disc_loss = 0.0012987338990087108
Trained batch 49 in epoch 4, gen_loss = 1.1697959864139558, disc_loss = 0.0013463414250873028
Trained batch 50 in epoch 4, gen_loss = 1.169137782910291, disc_loss = 0.0014780846529402862
Trained batch 51 in epoch 4, gen_loss = 1.172617535178478, disc_loss = 0.0016600420103014375
Trained batch 52 in epoch 4, gen_loss = 1.1708171671291567, disc_loss = 0.0017718496482011
Trained batch 53 in epoch 4, gen_loss = 1.1711680127514734, disc_loss = 0.0018215340506112963
Trained batch 54 in epoch 4, gen_loss = 1.1699181957678362, disc_loss = 0.0018251668640666388
Trained batch 55 in epoch 4, gen_loss = 1.1669784794960703, disc_loss = 0.0018204099552739145
Trained batch 56 in epoch 4, gen_loss = 1.1679387646808959, disc_loss = 0.0018267913643891613
Trained batch 57 in epoch 4, gen_loss = 1.1705194598641888, disc_loss = 0.0018227119058980767
Trained batch 58 in epoch 4, gen_loss = 1.1676075488834057, disc_loss = 0.0018104832635213763
Trained batch 59 in epoch 4, gen_loss = 1.1679286152124404, disc_loss = 0.001797883848970135
Trained batch 60 in epoch 4, gen_loss = 1.1667413877659156, disc_loss = 0.0017782829846942523
Trained batch 61 in epoch 4, gen_loss = 1.1653093916754569, disc_loss = 0.0017609066919483725
Trained batch 62 in epoch 4, gen_loss = 1.1682415983033558, disc_loss = 0.0017455866623167244
Trained batch 63 in epoch 4, gen_loss = 1.1710951989516616, disc_loss = 0.0017261178745684447
Trained batch 64 in epoch 4, gen_loss = 1.1718875454022335, disc_loss = 0.0017063687130128248
Trained batch 65 in epoch 4, gen_loss = 1.1704482680017299, disc_loss = 0.0016848543605054588
Trained batch 66 in epoch 4, gen_loss = 1.1761013064811479, disc_loss = 0.0016640434080713998
Trained batch 67 in epoch 4, gen_loss = 1.1753412791911293, disc_loss = 0.001644485850513721
Trained batch 68 in epoch 4, gen_loss = 1.1765073546464893, disc_loss = 0.0016253812198925332
Trained batch 69 in epoch 4, gen_loss = 1.175314781495503, disc_loss = 0.0016083971958973313
Trained batch 70 in epoch 4, gen_loss = 1.1761678364914907, disc_loss = 0.0015931340212389355
Trained batch 71 in epoch 4, gen_loss = 1.1806733517183199, disc_loss = 0.001576166918514193
Trained batch 72 in epoch 4, gen_loss = 1.1798173180998188, disc_loss = 0.0015654903812627372
Trained batch 73 in epoch 4, gen_loss = 1.1802143639809377, disc_loss = 0.0015570552904800687
Trained batch 74 in epoch 4, gen_loss = 1.1783603342374165, disc_loss = 0.0015643013260948162
Trained batch 75 in epoch 4, gen_loss = 1.1790179225959276, disc_loss = 0.001557883689345449
Trained batch 76 in epoch 4, gen_loss = 1.178126340562647, disc_loss = 0.0015441229976653182
Trained batch 77 in epoch 4, gen_loss = 1.1802462820823376, disc_loss = 0.0015363559113421405
Trained batch 78 in epoch 4, gen_loss = 1.1830728499195244, disc_loss = 0.00152464698826234
Trained batch 79 in epoch 4, gen_loss = 1.1846989534795285, disc_loss = 0.001513448407058604
Trained batch 80 in epoch 4, gen_loss = 1.18327123073884, disc_loss = 0.0015101600179655685
Trained batch 81 in epoch 4, gen_loss = 1.188249029037429, disc_loss = 0.0015200537930401723
Trained batch 82 in epoch 4, gen_loss = 1.187465652643916, disc_loss = 0.001535506069054266
Trained batch 83 in epoch 4, gen_loss = 1.1847784029585975, disc_loss = 0.001541483404469632
Trained batch 84 in epoch 4, gen_loss = 1.1818365160156699, disc_loss = 0.0015588929767117782
Trained batch 85 in epoch 4, gen_loss = 1.1796998194483823, disc_loss = 0.0016132318468894376
Trained batch 86 in epoch 4, gen_loss = 1.1781475482315853, disc_loss = 0.0016659998078027676
Trained batch 87 in epoch 4, gen_loss = 1.1777746562253346, disc_loss = 0.0017176642326045442
Trained batch 88 in epoch 4, gen_loss = 1.1796153201146071, disc_loss = 0.0017552306415157372
Trained batch 89 in epoch 4, gen_loss = 1.1790601154168447, disc_loss = 0.0017627898293236892
Trained batch 90 in epoch 4, gen_loss = 1.1782184885098383, disc_loss = 0.0017578890137783774
Trained batch 91 in epoch 4, gen_loss = 1.181271154595458, disc_loss = 0.0017506556949861672
Trained batch 92 in epoch 4, gen_loss = 1.1823941988329734, disc_loss = 0.0017472209161027304
Trained batch 93 in epoch 4, gen_loss = 1.1824211383119543, disc_loss = 0.0017425650631652234
Trained batch 94 in epoch 4, gen_loss = 1.1824861683343586, disc_loss = 0.0017344351514781775
Trained batch 95 in epoch 4, gen_loss = 1.1830728470037382, disc_loss = 0.0017220396687965451
Trained batch 96 in epoch 4, gen_loss = 1.1819314348328973, disc_loss = 0.0017126056314061982
Trained batch 97 in epoch 4, gen_loss = 1.1806479783690706, disc_loss = 0.001701634468710316
Trained batch 98 in epoch 4, gen_loss = 1.179305906849678, disc_loss = 0.0016939141258428042
Trained batch 99 in epoch 4, gen_loss = 1.1804548567533493, disc_loss = 0.0016941094165667892
Trained batch 100 in epoch 4, gen_loss = 1.180855646581933, disc_loss = 0.0016937526888075737
Trained batch 101 in epoch 4, gen_loss = 1.1806648496319265, disc_loss = 0.0016873030621996697
Trained batch 102 in epoch 4, gen_loss = 1.1792905104970468, disc_loss = 0.0016743578536671053
Trained batch 103 in epoch 4, gen_loss = 1.1802058695600584, disc_loss = 0.0016665152518096594
Trained batch 104 in epoch 4, gen_loss = 1.1783770328476315, disc_loss = 0.0016658201625215866
Trained batch 105 in epoch 4, gen_loss = 1.1787374261415229, disc_loss = 0.0016573387712134787
Trained batch 106 in epoch 4, gen_loss = 1.1795399094296393, disc_loss = 0.0016459353925294686
Trained batch 107 in epoch 4, gen_loss = 1.1782877969521064, disc_loss = 0.0016373566753894989
Trained batch 108 in epoch 4, gen_loss = 1.1780919388893547, disc_loss = 0.001627997392703087
Trained batch 109 in epoch 4, gen_loss = 1.1784035579724745, disc_loss = 0.0016185380634851753
Trained batch 110 in epoch 4, gen_loss = 1.1787744347039644, disc_loss = 0.0016124802589131235
Trained batch 111 in epoch 4, gen_loss = 1.1786656438239984, disc_loss = 0.0016038818082181802
Trained batch 112 in epoch 4, gen_loss = 1.1782390137689303, disc_loss = 0.0015927630577615536
Trained batch 113 in epoch 4, gen_loss = 1.1786752275207586, disc_loss = 0.001582168014577116
Trained batch 114 in epoch 4, gen_loss = 1.1791589638461237, disc_loss = 0.0015714933989448069
Trained batch 115 in epoch 4, gen_loss = 1.1773397084967843, disc_loss = 0.0015628844753493845
Trained batch 116 in epoch 4, gen_loss = 1.1805005037886465, disc_loss = 0.0015595708540879572
Trained batch 117 in epoch 4, gen_loss = 1.1815666106797882, disc_loss = 0.0015656007774434667
Trained batch 118 in epoch 4, gen_loss = 1.182256676068827, disc_loss = 0.0015753840469019565
Trained batch 119 in epoch 4, gen_loss = 1.181630177795887, disc_loss = 0.0015823843408725225
Trained batch 120 in epoch 4, gen_loss = 1.1811339436483776, disc_loss = 0.0015866383510903448
Trained batch 121 in epoch 4, gen_loss = 1.1812672160687994, disc_loss = 0.0015843804418987242
Trained batch 122 in epoch 4, gen_loss = 1.1793560172484172, disc_loss = 0.0015754692528086405
Trained batch 123 in epoch 4, gen_loss = 1.1795568547902568, disc_loss = 0.0015661088043763753
Trained batch 124 in epoch 4, gen_loss = 1.1807444939613343, disc_loss = 0.0015596681497991086
Trained batch 125 in epoch 4, gen_loss = 1.1806255224205198, disc_loss = 0.001552187398793028
Trained batch 126 in epoch 4, gen_loss = 1.1789014334753742, disc_loss = 0.0015478916484569236
Trained batch 127 in epoch 4, gen_loss = 1.1801624945364892, disc_loss = 0.001544374510558555
Trained batch 128 in epoch 4, gen_loss = 1.1786435177159864, disc_loss = 0.0015360760198393475
Trained batch 129 in epoch 4, gen_loss = 1.1786196992947504, disc_loss = 0.0015295361907472118
Trained batch 130 in epoch 4, gen_loss = 1.1794842072115599, disc_loss = 0.001524406969138485
Trained batch 131 in epoch 4, gen_loss = 1.1782685446016716, disc_loss = 0.0015155815761483443
Trained batch 132 in epoch 4, gen_loss = 1.1795698269865567, disc_loss = 0.0015060620026179777
Trained batch 133 in epoch 4, gen_loss = 1.1792880492423898, disc_loss = 0.001499278610745973
Trained batch 134 in epoch 4, gen_loss = 1.1785799812387536, disc_loss = 0.001492366187395183
Trained batch 135 in epoch 4, gen_loss = 1.1789365025127636, disc_loss = 0.0014837143346941209
Trained batch 136 in epoch 4, gen_loss = 1.1772290059249766, disc_loss = 0.0014745871540469994
Trained batch 137 in epoch 4, gen_loss = 1.1777875181557476, disc_loss = 0.0014746576762527052
Trained batch 138 in epoch 4, gen_loss = 1.17704418494547, disc_loss = 0.0014797693800822692
Trained batch 139 in epoch 4, gen_loss = 1.175200737799917, disc_loss = 0.0014808370597685489
Trained batch 140 in epoch 4, gen_loss = 1.177532396840711, disc_loss = 0.0014743366713614156
Trained batch 141 in epoch 4, gen_loss = 1.1790448036831869, disc_loss = 0.0014680586577988308
Trained batch 142 in epoch 4, gen_loss = 1.179308087258906, disc_loss = 0.0014598581526172837
Trained batch 143 in epoch 4, gen_loss = 1.1782563109364774, disc_loss = 0.001453581064702626
Trained batch 144 in epoch 4, gen_loss = 1.1778977521534624, disc_loss = 0.0014504522670277169
Trained batch 145 in epoch 4, gen_loss = 1.1777151794466254, disc_loss = 0.0014502597670349904
Trained batch 146 in epoch 4, gen_loss = 1.1771027883704828, disc_loss = 0.0014513862630325452
Trained batch 147 in epoch 4, gen_loss = 1.1779335845966596, disc_loss = 0.0014496150250960381
Trained batch 148 in epoch 4, gen_loss = 1.176737916149549, disc_loss = 0.0014462343888043195
Trained batch 149 in epoch 4, gen_loss = 1.1764275387922922, disc_loss = 0.0014414389546921788
Trained batch 150 in epoch 4, gen_loss = 1.175993281089707, disc_loss = 0.0014367142089122956
Trained batch 151 in epoch 4, gen_loss = 1.1753814538058482, disc_loss = 0.0014307917819295606
Trained batch 152 in epoch 4, gen_loss = 1.1779243521441043, disc_loss = 0.0014233054482686986
Trained batch 153 in epoch 4, gen_loss = 1.1786079031306427, disc_loss = 0.0014152605236430846
Trained batch 154 in epoch 4, gen_loss = 1.179255635123099, disc_loss = 0.0014078682047247346
Trained batch 155 in epoch 4, gen_loss = 1.1779207430588894, disc_loss = 0.0014010274825499763
Trained batch 156 in epoch 4, gen_loss = 1.177067242989874, disc_loss = 0.0013949413212708784
Trained batch 157 in epoch 4, gen_loss = 1.1767135990571371, disc_loss = 0.0013889552611095796
Trained batch 158 in epoch 4, gen_loss = 1.1760225359748744, disc_loss = 0.0013822539442814828
Trained batch 159 in epoch 4, gen_loss = 1.1767331723123788, disc_loss = 0.0013764857961177767
Trained batch 160 in epoch 4, gen_loss = 1.1773452866151466, disc_loss = 0.0013714855530853123
Trained batch 161 in epoch 4, gen_loss = 1.1763955814602933, disc_loss = 0.0013654441523321121
Trained batch 162 in epoch 4, gen_loss = 1.1751415411387485, disc_loss = 0.0013593849676919736
Trained batch 163 in epoch 4, gen_loss = 1.174808474939044, disc_loss = 0.001353155520851809
Trained batch 164 in epoch 4, gen_loss = 1.1745456113959805, disc_loss = 0.0013473038874728832
Trained batch 165 in epoch 4, gen_loss = 1.1755098862102233, disc_loss = 0.0013428212767459889
Trained batch 166 in epoch 4, gen_loss = 1.1765254925111097, disc_loss = 0.0013367082026311682
Trained batch 167 in epoch 4, gen_loss = 1.1776922682211513, disc_loss = 0.0013306364443927859
Trained batch 168 in epoch 4, gen_loss = 1.1775217532406193, disc_loss = 0.0013273957022018014
Trained batch 169 in epoch 4, gen_loss = 1.177456799324821, disc_loss = 0.0013236483975881984
Trained batch 170 in epoch 4, gen_loss = 1.176407369605282, disc_loss = 0.0013188906047154184
Trained batch 171 in epoch 4, gen_loss = 1.175794237228327, disc_loss = 0.0013150908492016876
Trained batch 172 in epoch 4, gen_loss = 1.1761519333530712, disc_loss = 0.0013108014497021751
Trained batch 173 in epoch 4, gen_loss = 1.1769471528201267, disc_loss = 0.0013056123172081526
Trained batch 174 in epoch 4, gen_loss = 1.1768309596606663, disc_loss = 0.001301768907994431
Trained batch 175 in epoch 4, gen_loss = 1.1771639148620041, disc_loss = 0.0012974760170850045
Trained batch 176 in epoch 4, gen_loss = 1.1763627647006578, disc_loss = 0.0012918883949580029
Trained batch 177 in epoch 4, gen_loss = 1.1754613629217898, disc_loss = 0.0012873519916549126
Trained batch 178 in epoch 4, gen_loss = 1.176366431420076, disc_loss = 0.001286725908489872
Trained batch 179 in epoch 4, gen_loss = 1.1752820289797252, disc_loss = 0.001295946888421895
Trained batch 180 in epoch 4, gen_loss = 1.1747305547993485, disc_loss = 0.0013105562555723314
Trained batch 181 in epoch 4, gen_loss = 1.1745493369443076, disc_loss = 0.001316299216241632
Trained batch 182 in epoch 4, gen_loss = 1.174821024058295, disc_loss = 0.001312644706350049
Trained batch 183 in epoch 4, gen_loss = 1.1745133273627446, disc_loss = 0.0013099494150557566
Trained batch 184 in epoch 4, gen_loss = 1.1742242139738959, disc_loss = 0.0013075536334843099
Trained batch 185 in epoch 4, gen_loss = 1.17331904845853, disc_loss = 0.0013035257517952242
Trained batch 186 in epoch 4, gen_loss = 1.1723199617416464, disc_loss = 0.0012984471148929564
Trained batch 187 in epoch 4, gen_loss = 1.1724188061470682, disc_loss = 0.0012926582382939895
Trained batch 188 in epoch 4, gen_loss = 1.1715672180135415, disc_loss = 0.001287027681538978
Trained batch 189 in epoch 4, gen_loss = 1.1711047442335831, disc_loss = 0.0012824930507217927
Trained batch 190 in epoch 4, gen_loss = 1.1705537678683615, disc_loss = 0.0012804521643160476
Trained batch 191 in epoch 4, gen_loss = 1.1705178891619046, disc_loss = 0.0012786602840151318
Trained batch 192 in epoch 4, gen_loss = 1.1709024016721261, disc_loss = 0.0012741077746659122
Trained batch 193 in epoch 4, gen_loss = 1.1702401048129367, disc_loss = 0.0012693748326783702
Trained batch 194 in epoch 4, gen_loss = 1.1698545633218227, disc_loss = 0.0012652395889371968
Trained batch 195 in epoch 4, gen_loss = 1.1714921028030163, disc_loss = 0.001260461206639979
Trained batch 196 in epoch 4, gen_loss = 1.171874509245006, disc_loss = 0.0012559660707882885
Trained batch 197 in epoch 4, gen_loss = 1.1731315736818795, disc_loss = 0.0012547713318560977
Trained batch 198 in epoch 4, gen_loss = 1.1728216625338224, disc_loss = 0.001254787771180436
Trained batch 199 in epoch 4, gen_loss = 1.174125828742981, disc_loss = 0.0012556570112792543
Trained batch 200 in epoch 4, gen_loss = 1.1747277138838128, disc_loss = 0.0012558454595389197
Trained batch 201 in epoch 4, gen_loss = 1.1736348976593207, disc_loss = 0.0012590593319371259
Trained batch 202 in epoch 4, gen_loss = 1.1741115838436071, disc_loss = 0.0012596511689050287
Trained batch 203 in epoch 4, gen_loss = 1.174456413177883, disc_loss = 0.0012578863262366641
Trained batch 204 in epoch 4, gen_loss = 1.1742260081012075, disc_loss = 0.0012553318638621443
Trained batch 205 in epoch 4, gen_loss = 1.1757886522603267, disc_loss = 0.0012510567727624167
Trained batch 206 in epoch 4, gen_loss = 1.175755206225575, disc_loss = 0.0012472282384678604
Trained batch 207 in epoch 4, gen_loss = 1.1752485853548233, disc_loss = 0.001247374177392675
Trained batch 208 in epoch 4, gen_loss = 1.1754278061492591, disc_loss = 0.001257279790805889
Trained batch 209 in epoch 4, gen_loss = 1.174776646920613, disc_loss = 0.0012643080525560348
Trained batch 210 in epoch 4, gen_loss = 1.1746096608198084, disc_loss = 0.0012647284980906368
Trained batch 211 in epoch 4, gen_loss = 1.1743677705526352, disc_loss = 0.0012623342837921984
Trained batch 212 in epoch 4, gen_loss = 1.1740305219457743, disc_loss = 0.0012591248590629242
Trained batch 213 in epoch 4, gen_loss = 1.1740329335226076, disc_loss = 0.0012579719099040996
Trained batch 214 in epoch 4, gen_loss = 1.174187142072722, disc_loss = 0.0012575148479596083
Trained batch 215 in epoch 4, gen_loss = 1.1745930725225695, disc_loss = 0.001257478907266179
Trained batch 216 in epoch 4, gen_loss = 1.1743684504438656, disc_loss = 0.0012552031596306033
Trained batch 217 in epoch 4, gen_loss = 1.1737387833792134, disc_loss = 0.0012521009139664291
Trained batch 218 in epoch 4, gen_loss = 1.1733642351137448, disc_loss = 0.0012539153924338376
Trained batch 219 in epoch 4, gen_loss = 1.1741032337600534, disc_loss = 0.0012543183375038841
Trained batch 220 in epoch 4, gen_loss = 1.1740853880865003, disc_loss = 0.001251169645195359
Trained batch 221 in epoch 4, gen_loss = 1.17460394630561, disc_loss = 0.0012468273612080134
Trained batch 222 in epoch 4, gen_loss = 1.1740129012698015, disc_loss = 0.001242743031580665
Trained batch 223 in epoch 4, gen_loss = 1.1731665208935738, disc_loss = 0.0012391766975140075
Trained batch 224 in epoch 4, gen_loss = 1.1725524044036866, disc_loss = 0.0012347300527229285
Trained batch 225 in epoch 4, gen_loss = 1.1715766170383555, disc_loss = 0.001230107915131334
Trained batch 226 in epoch 4, gen_loss = 1.171336207620898, disc_loss = 0.0012257039007327688
Trained batch 227 in epoch 4, gen_loss = 1.170691148230904, disc_loss = 0.001221863199533433
Trained batch 228 in epoch 4, gen_loss = 1.1697710411517381, disc_loss = 0.0012190103836283372
Trained batch 229 in epoch 4, gen_loss = 1.1698980567247972, disc_loss = 0.0012151377682407063
Trained batch 230 in epoch 4, gen_loss = 1.1700272242744247, disc_loss = 0.0012109869009703277
Trained batch 231 in epoch 4, gen_loss = 1.1692112273183362, disc_loss = 0.0012093099070123823
Trained batch 232 in epoch 4, gen_loss = 1.168506356779598, disc_loss = 0.0012157296988830298
Trained batch 233 in epoch 4, gen_loss = 1.1681748969942076, disc_loss = 0.0012287773915420238
Trained batch 234 in epoch 4, gen_loss = 1.1678111152446016, disc_loss = 0.001231295984310217
Trained batch 235 in epoch 4, gen_loss = 1.167835799819332, disc_loss = 0.0012300688023230068
Trained batch 236 in epoch 4, gen_loss = 1.1687030294273473, disc_loss = 0.0012322246910093494
Trained batch 237 in epoch 4, gen_loss = 1.1678019827153503, disc_loss = 0.0012294927425707002
Trained batch 238 in epoch 4, gen_loss = 1.1673105795513137, disc_loss = 0.0012259294976559214
Trained batch 239 in epoch 4, gen_loss = 1.1672993118564288, disc_loss = 0.0012239613570879252
Trained batch 240 in epoch 4, gen_loss = 1.1668172975793418, disc_loss = 0.0012212162427396487
Trained batch 241 in epoch 4, gen_loss = 1.1668987022943733, disc_loss = 0.0012171738097335458
Trained batch 242 in epoch 4, gen_loss = 1.1664535366458657, disc_loss = 0.001214561942682617
Trained batch 243 in epoch 4, gen_loss = 1.1671707512902432, disc_loss = 0.001213623627724
Trained batch 244 in epoch 4, gen_loss = 1.167526355081675, disc_loss = 0.0012115563521974207
Trained batch 245 in epoch 4, gen_loss = 1.1670697098825036, disc_loss = 0.0012081249954100373
Trained batch 246 in epoch 4, gen_loss = 1.1671274031704737, disc_loss = 0.0012041039383467777
Trained batch 247 in epoch 4, gen_loss = 1.1683470544315153, disc_loss = 0.0012005065161628731
Trained batch 248 in epoch 4, gen_loss = 1.1691109554834633, disc_loss = 0.001196927319285011
Trained batch 249 in epoch 4, gen_loss = 1.1691740527153016, disc_loss = 0.0011933636504109018
Trained batch 250 in epoch 4, gen_loss = 1.1692909372755256, disc_loss = 0.0011904768973790235
Trained batch 251 in epoch 4, gen_loss = 1.1686747457299913, disc_loss = 0.001187881183247396
Trained batch 252 in epoch 4, gen_loss = 1.1692724986509844, disc_loss = 0.0011848563535103074
Trained batch 253 in epoch 4, gen_loss = 1.1694149759810741, disc_loss = 0.0011813945566532275
Trained batch 254 in epoch 4, gen_loss = 1.170195959596073, disc_loss = 0.0011775116025305847
Trained batch 255 in epoch 4, gen_loss = 1.169787046033889, disc_loss = 0.0011735389905993543
Trained batch 256 in epoch 4, gen_loss = 1.1693266305478167, disc_loss = 0.0011708144933018827
Trained batch 257 in epoch 4, gen_loss = 1.169462072294812, disc_loss = 0.0011698279161274237
Trained batch 258 in epoch 4, gen_loss = 1.1699494615945116, disc_loss = 0.0011698698983316465
Trained batch 259 in epoch 4, gen_loss = 1.169785649042863, disc_loss = 0.001169011353060621
Trained batch 260 in epoch 4, gen_loss = 1.1710674182665302, disc_loss = 0.0011671008638635286
Trained batch 261 in epoch 4, gen_loss = 1.170140066902146, disc_loss = 0.0011645912058684327
Trained batch 262 in epoch 4, gen_loss = 1.1698623739267937, disc_loss = 0.0011617387965310033
Trained batch 263 in epoch 4, gen_loss = 1.1695478506612056, disc_loss = 0.0011585064057175205
Trained batch 264 in epoch 4, gen_loss = 1.1688227880675837, disc_loss = 0.0011554235200955585
Trained batch 265 in epoch 4, gen_loss = 1.1683341007035477, disc_loss = 0.0011522427919129071
Trained batch 266 in epoch 4, gen_loss = 1.1679842322506708, disc_loss = 0.0011496353952352774
Trained batch 267 in epoch 4, gen_loss = 1.1678430248997105, disc_loss = 0.0011473214144643862
Trained batch 268 in epoch 4, gen_loss = 1.1690707248826009, disc_loss = 0.001146307563420894
Trained batch 269 in epoch 4, gen_loss = 1.1689079688655006, disc_loss = 0.0011450663251539313
Trained batch 270 in epoch 4, gen_loss = 1.1687975433479816, disc_loss = 0.0011422742137017856
Trained batch 271 in epoch 4, gen_loss = 1.1683865524828434, disc_loss = 0.0011417830738162807
Trained batch 272 in epoch 4, gen_loss = 1.1676774219278887, disc_loss = 0.0011457979483269804
Trained batch 273 in epoch 4, gen_loss = 1.167276303045941, disc_loss = 0.0011494786144097431
Trained batch 274 in epoch 4, gen_loss = 1.1674115209145979, disc_loss = 0.0011500290175370702
Trained batch 275 in epoch 4, gen_loss = 1.167324899547342, disc_loss = 0.001148000340501734
Trained batch 276 in epoch 4, gen_loss = 1.167406397390882, disc_loss = 0.001145017433195839
Trained batch 277 in epoch 4, gen_loss = 1.1670134485625534, disc_loss = 0.0011421108887746105
Trained batch 278 in epoch 4, gen_loss = 1.1666163156964018, disc_loss = 0.0011389900709182779
Trained batch 279 in epoch 4, gen_loss = 1.1667557135224342, disc_loss = 0.0011373126582579322
Trained batch 280 in epoch 4, gen_loss = 1.1658704783568603, disc_loss = 0.0011374588939879137
Trained batch 281 in epoch 4, gen_loss = 1.1653500835523538, disc_loss = 0.0011417237761143944
Trained batch 282 in epoch 4, gen_loss = 1.1659504286813231, disc_loss = 0.0011529618808477228
Trained batch 283 in epoch 4, gen_loss = 1.1663109666444886, disc_loss = 0.0011608474279698935
Trained batch 284 in epoch 4, gen_loss = 1.1666853337957148, disc_loss = 0.001163752982239729
Trained batch 285 in epoch 4, gen_loss = 1.1665107976723383, disc_loss = 0.0011652681101508393
Trained batch 286 in epoch 4, gen_loss = 1.1668753115142263, disc_loss = 0.0011669934035351058
Trained batch 287 in epoch 4, gen_loss = 1.16723890002403, disc_loss = 0.0011679089166641966
Trained batch 288 in epoch 4, gen_loss = 1.1674145569438341, disc_loss = 0.0011677913560397492
Trained batch 289 in epoch 4, gen_loss = 1.1673936315651599, disc_loss = 0.0011665373661752052
Trained batch 290 in epoch 4, gen_loss = 1.16674148933994, disc_loss = 0.0011659772429856092
Trained batch 291 in epoch 4, gen_loss = 1.1678761188706306, disc_loss = 0.0011678179309879628
Trained batch 292 in epoch 4, gen_loss = 1.168140079584545, disc_loss = 0.0011709961854338602
Trained batch 293 in epoch 4, gen_loss = 1.168193859916155, disc_loss = 0.001170247211170519
Trained batch 294 in epoch 4, gen_loss = 1.1677178978919982, disc_loss = 0.0011673423710725096
Trained batch 295 in epoch 4, gen_loss = 1.1685544355092823, disc_loss = 0.0011647120340844471
Trained batch 296 in epoch 4, gen_loss = 1.1683638366785916, disc_loss = 0.0011619572888417733
Trained batch 297 in epoch 4, gen_loss = 1.1679690990271985, disc_loss = 0.00115952529693874
Trained batch 298 in epoch 4, gen_loss = 1.1671629284935252, disc_loss = 0.0011571051010626048
Trained batch 299 in epoch 4, gen_loss = 1.1674493032693862, disc_loss = 0.001154877782537369
Trained batch 300 in epoch 4, gen_loss = 1.1673925027894816, disc_loss = 0.0011529102573883674
Trained batch 301 in epoch 4, gen_loss = 1.168673847092698, disc_loss = 0.001150955316012753
Trained batch 302 in epoch 4, gen_loss = 1.1685445389338451, disc_loss = 0.0011488217559336492
Trained batch 303 in epoch 4, gen_loss = 1.168349191742508, disc_loss = 0.0011481925511313755
Trained batch 304 in epoch 4, gen_loss = 1.1678300836047188, disc_loss = 0.0011498139765147943
Trained batch 305 in epoch 4, gen_loss = 1.167991798882391, disc_loss = 0.0011523574390665482
Trained batch 306 in epoch 4, gen_loss = 1.1678324730077863, disc_loss = 0.0011542389131509866
Trained batch 307 in epoch 4, gen_loss = 1.1679616135049176, disc_loss = 0.0011522089928791513
Trained batch 308 in epoch 4, gen_loss = 1.1682074037184607, disc_loss = 0.001150601647327455
Trained batch 309 in epoch 4, gen_loss = 1.167611195387379, disc_loss = 0.0011513702352174498
Trained batch 310 in epoch 4, gen_loss = 1.1679175442438035, disc_loss = 0.0011509341430431831
Trained batch 311 in epoch 4, gen_loss = 1.1674769190259469, disc_loss = 0.001149688552080382
Trained batch 312 in epoch 4, gen_loss = 1.1675512476470142, disc_loss = 0.0011472261467366108
Trained batch 313 in epoch 4, gen_loss = 1.1678317168336005, disc_loss = 0.0011447680431249802
Trained batch 314 in epoch 4, gen_loss = 1.1674975506843082, disc_loss = 0.0011428504907396726
Trained batch 315 in epoch 4, gen_loss = 1.1674056138041653, disc_loss = 0.00114084969893064
Trained batch 316 in epoch 4, gen_loss = 1.1673945352106063, disc_loss = 0.0011380918040575624
Trained batch 317 in epoch 4, gen_loss = 1.1672339583717801, disc_loss = 0.0011356415648695005
Trained batch 318 in epoch 4, gen_loss = 1.1678581082708783, disc_loss = 0.0011327383151317314
Trained batch 319 in epoch 4, gen_loss = 1.1673285400494933, disc_loss = 0.0011300165148895758
Trained batch 320 in epoch 4, gen_loss = 1.1679046616376003, disc_loss = 0.0011278051465736685
Trained batch 321 in epoch 4, gen_loss = 1.1681549217760192, disc_loss = 0.0011254063024155228
Trained batch 322 in epoch 4, gen_loss = 1.1684185367988729, disc_loss = 0.0011227449757946603
Trained batch 323 in epoch 4, gen_loss = 1.1681863855064651, disc_loss = 0.0011202808334614311
Trained batch 324 in epoch 4, gen_loss = 1.1678325592554533, disc_loss = 0.001118082113367004
Trained batch 325 in epoch 4, gen_loss = 1.1685931073741678, disc_loss = 0.0011154125223009122
Trained batch 326 in epoch 4, gen_loss = 1.1691563812964554, disc_loss = 0.001112605002210319
Trained batch 327 in epoch 4, gen_loss = 1.1689593557540963, disc_loss = 0.001109957009825072
Trained batch 328 in epoch 4, gen_loss = 1.1683476123403995, disc_loss = 0.0011081332997220786
Trained batch 329 in epoch 4, gen_loss = 1.1686754819118614, disc_loss = 0.0011080061217812313
Trained batch 330 in epoch 4, gen_loss = 1.1681621296168094, disc_loss = 0.0011075061831758372
Trained batch 331 in epoch 4, gen_loss = 1.167713228298957, disc_loss = 0.0011067051361230798
Trained batch 332 in epoch 4, gen_loss = 1.1674985368330557, disc_loss = 0.0011053456155395878
Trained batch 333 in epoch 4, gen_loss = 1.1675832169855427, disc_loss = 0.0011039103186496917
Trained batch 334 in epoch 4, gen_loss = 1.1674796337512001, disc_loss = 0.0011032609015341793
Trained batch 335 in epoch 4, gen_loss = 1.1668728212160724, disc_loss = 0.0011036448042778787
Trained batch 336 in epoch 4, gen_loss = 1.1672812592381894, disc_loss = 0.0011044043179833571
Trained batch 337 in epoch 4, gen_loss = 1.1671080248948384, disc_loss = 0.00110320702605721
Trained batch 338 in epoch 4, gen_loss = 1.1666721058102836, disc_loss = 0.0011018470503529945
Trained batch 339 in epoch 4, gen_loss = 1.1668940766769298, disc_loss = 0.0011025140190373778
Trained batch 340 in epoch 4, gen_loss = 1.1666739125056, disc_loss = 0.001102735563775366
Trained batch 341 in epoch 4, gen_loss = 1.1663842258746164, disc_loss = 0.0011018589913384847
Trained batch 342 in epoch 4, gen_loss = 1.1666917079739252, disc_loss = 0.001099689282224386
Trained batch 343 in epoch 4, gen_loss = 1.1676488063016603, disc_loss = 0.0010970829695251332
Trained batch 344 in epoch 4, gen_loss = 1.167466900486877, disc_loss = 0.0010950831154384988
Trained batch 345 in epoch 4, gen_loss = 1.1673655484108567, disc_loss = 0.0010944465531498554
Trained batch 346 in epoch 4, gen_loss = 1.1667681989133873, disc_loss = 0.0010935082460565074
Trained batch 347 in epoch 4, gen_loss = 1.1671900010999592, disc_loss = 0.0010926309009480703
Trained batch 348 in epoch 4, gen_loss = 1.1669320959416365, disc_loss = 0.0010935041726480791
Trained batch 349 in epoch 4, gen_loss = 1.1662884066786086, disc_loss = 0.001096017320898162
Trained batch 350 in epoch 4, gen_loss = 1.1672434234551214, disc_loss = 0.0010947284221624626
Trained batch 351 in epoch 4, gen_loss = 1.167408508841287, disc_loss = 0.0010931185854381263
Trained batch 352 in epoch 4, gen_loss = 1.1674086296186907, disc_loss = 0.0010914178127762611
Trained batch 353 in epoch 4, gen_loss = 1.167072739136421, disc_loss = 0.0010895889732473014
Trained batch 354 in epoch 4, gen_loss = 1.166823754344188, disc_loss = 0.0010893185906240086
Trained batch 355 in epoch 4, gen_loss = 1.1664307959628908, disc_loss = 0.0010879637962164688
Trained batch 356 in epoch 4, gen_loss = 1.1665584772240882, disc_loss = 0.0010865546525465795
Trained batch 357 in epoch 4, gen_loss = 1.1669242483610547, disc_loss = 0.0010872964059733057
Trained batch 358 in epoch 4, gen_loss = 1.1664412229174026, disc_loss = 0.001087697302398251
Trained batch 359 in epoch 4, gen_loss = 1.1666786102785005, disc_loss = 0.0010860950793964246
Trained batch 360 in epoch 4, gen_loss = 1.1664086505977072, disc_loss = 0.0010843610471560183
Trained batch 361 in epoch 4, gen_loss = 1.1660939581815708, disc_loss = 0.0010830693601586248
Trained batch 362 in epoch 4, gen_loss = 1.1663107453298962, disc_loss = 0.0010810607029481075
Trained batch 363 in epoch 4, gen_loss = 1.1661856294005781, disc_loss = 0.0010792156427559458
Trained batch 364 in epoch 4, gen_loss = 1.165755215899585, disc_loss = 0.0010774111855625214
Trained batch 365 in epoch 4, gen_loss = 1.165549408705508, disc_loss = 0.0010757006813668331
Trained batch 366 in epoch 4, gen_loss = 1.1655274611727744, disc_loss = 0.001074377008231943
Trained batch 367 in epoch 4, gen_loss = 1.165525735558375, disc_loss = 0.0010730257203170406
Trained batch 368 in epoch 4, gen_loss = 1.165678116525738, disc_loss = 0.001070920715897551
Trained batch 369 in epoch 4, gen_loss = 1.1654840232552708, disc_loss = 0.001068822958788243
Trained batch 370 in epoch 4, gen_loss = 1.165100822712212, disc_loss = 0.001066664418114934
Trained batch 371 in epoch 4, gen_loss = 1.1647233890910302, disc_loss = 0.001065057129948087
Trained batch 372 in epoch 4, gen_loss = 1.1641607423570137, disc_loss = 0.0010646810241642186
Trained batch 373 in epoch 4, gen_loss = 1.1655805326081852, disc_loss = 0.0010635285757100434
Trained batch 374 in epoch 4, gen_loss = 1.166042904694875, disc_loss = 0.0010629535138529415
Trained batch 375 in epoch 4, gen_loss = 1.166130283570036, disc_loss = 0.0010624151585788956
Trained batch 376 in epoch 4, gen_loss = 1.1663780596591433, disc_loss = 0.0010603957301773383
Trained batch 377 in epoch 4, gen_loss = 1.1661792235084312, disc_loss = 0.001059844233697741
Trained batch 378 in epoch 4, gen_loss = 1.165743952848037, disc_loss = 0.0010593201452359375
Trained batch 379 in epoch 4, gen_loss = 1.1663085882600985, disc_loss = 0.0010575302381384015
Trained batch 380 in epoch 4, gen_loss = 1.1660678613530056, disc_loss = 0.001056010142148086
Trained batch 381 in epoch 4, gen_loss = 1.1669563078443417, disc_loss = 0.0010570933470848084
Trained batch 382 in epoch 4, gen_loss = 1.1673916168997245, disc_loss = 0.0010603160846856235
Trained batch 383 in epoch 4, gen_loss = 1.1671194724428158, disc_loss = 0.0010628740016045413
Trained batch 384 in epoch 4, gen_loss = 1.1672142720841743, disc_loss = 0.0010629568327227366
Trained batch 385 in epoch 4, gen_loss = 1.1670632509061092, disc_loss = 0.0010612543685216374
Trained batch 386 in epoch 4, gen_loss = 1.1673116990454129, disc_loss = 0.0010601604343148294
Trained batch 387 in epoch 4, gen_loss = 1.1673023929608237, disc_loss = 0.0010591567521803825
Trained batch 388 in epoch 4, gen_loss = 1.1672950356355976, disc_loss = 0.0010587932009792798
Trained batch 389 in epoch 4, gen_loss = 1.1671442996232937, disc_loss = 0.0010591107776958663
Trained batch 390 in epoch 4, gen_loss = 1.1676391553695855, disc_loss = 0.0010588738439908927
Trained batch 391 in epoch 4, gen_loss = 1.1675285166319536, disc_loss = 0.0010578925422513358
Trained batch 392 in epoch 4, gen_loss = 1.1675436261652687, disc_loss = 0.001056100623411098
Trained batch 393 in epoch 4, gen_loss = 1.167337596870316, disc_loss = 0.0010544948394278532
Trained batch 394 in epoch 4, gen_loss = 1.1668297885339471, disc_loss = 0.0010538257431913804
Trained batch 395 in epoch 4, gen_loss = 1.166346955781031, disc_loss = 0.0010538889866365199
Trained batch 396 in epoch 4, gen_loss = 1.1656737833539546, disc_loss = 0.0010528543884341045
Trained batch 397 in epoch 4, gen_loss = 1.1660209404463744, disc_loss = 0.0010512256867971257
Trained batch 398 in epoch 4, gen_loss = 1.1656443969647687, disc_loss = 0.0010495693486678136
Trained batch 399 in epoch 4, gen_loss = 1.1658022026717663, disc_loss = 0.0010479587147347047
Trained batch 400 in epoch 4, gen_loss = 1.165662508504349, disc_loss = 0.0010468141187636758
Trained batch 401 in epoch 4, gen_loss = 1.165765592559653, disc_loss = 0.0010458389644274159
Trained batch 402 in epoch 4, gen_loss = 1.1657954426320551, disc_loss = 0.0010444015972174718
Trained batch 403 in epoch 4, gen_loss = 1.1654787481126219, disc_loss = 0.0010426306664049832
Trained batch 404 in epoch 4, gen_loss = 1.165384696295232, disc_loss = 0.0010406074936596538
Trained batch 405 in epoch 4, gen_loss = 1.1651499660437918, disc_loss = 0.0010389453494417244
Trained batch 406 in epoch 4, gen_loss = 1.1646947890007524, disc_loss = 0.0010371235179893914
Trained batch 407 in epoch 4, gen_loss = 1.1640288606286049, disc_loss = 0.0010358246201184217
Trained batch 408 in epoch 4, gen_loss = 1.1644535077813203, disc_loss = 0.0010351619012110176
Trained batch 409 in epoch 4, gen_loss = 1.1644816871096448, disc_loss = 0.001034772127941989
Trained batch 410 in epoch 4, gen_loss = 1.165111304924726, disc_loss = 0.0010343993553473135
Trained batch 411 in epoch 4, gen_loss = 1.1651212669981337, disc_loss = 0.0010344443372091916
Trained batch 412 in epoch 4, gen_loss = 1.1654169670606063, disc_loss = 0.0010345257413429806
Trained batch 413 in epoch 4, gen_loss = 1.1654811079663354, disc_loss = 0.001034862123007137
Trained batch 414 in epoch 4, gen_loss = 1.1651860387928514, disc_loss = 0.001036373873876621
Trained batch 415 in epoch 4, gen_loss = 1.1647067057112088, disc_loss = 0.0010387769022180203
Trained batch 416 in epoch 4, gen_loss = 1.1649585294780684, disc_loss = 0.001041796769366412
Trained batch 417 in epoch 4, gen_loss = 1.1651796711403788, disc_loss = 0.0010435929739222255
Trained batch 418 in epoch 4, gen_loss = 1.1653073265046094, disc_loss = 0.0010437950296930387
Trained batch 419 in epoch 4, gen_loss = 1.1653491149346034, disc_loss = 0.0010435039886076646
Trained batch 420 in epoch 4, gen_loss = 1.1656878587752226, disc_loss = 0.001042406753319727
Trained batch 421 in epoch 4, gen_loss = 1.165397868760954, disc_loss = 0.001041066888668762
Trained batch 422 in epoch 4, gen_loss = 1.1652189821498051, disc_loss = 0.0010399832583930296
Trained batch 423 in epoch 4, gen_loss = 1.1653248379534145, disc_loss = 0.0010393540155489045
Trained batch 424 in epoch 4, gen_loss = 1.165206508776721, disc_loss = 0.0010397720032522236
Trained batch 425 in epoch 4, gen_loss = 1.164727700428224, disc_loss = 0.0010411460739284417
Trained batch 426 in epoch 4, gen_loss = 1.1648953014011965, disc_loss = 0.0010409489782421853
Trained batch 427 in epoch 4, gen_loss = 1.1647708053900816, disc_loss = 0.0010393893108667836
Trained batch 428 in epoch 4, gen_loss = 1.1646422295025733, disc_loss = 0.0010403115451235502
Trained batch 429 in epoch 4, gen_loss = 1.1647122538366983, disc_loss = 0.0010416090577437412
Trained batch 430 in epoch 4, gen_loss = 1.1650554967866973, disc_loss = 0.00104457421712183
Trained batch 431 in epoch 4, gen_loss = 1.1658548409188236, disc_loss = 0.001049715677119686
Trained batch 432 in epoch 4, gen_loss = 1.165538277416802, disc_loss = 0.0010533185304918457
Trained batch 433 in epoch 4, gen_loss = 1.165430669136311, disc_loss = 0.001053508604984797
Trained batch 434 in epoch 4, gen_loss = 1.1652028875789424, disc_loss = 0.0010525952712512286
Trained batch 435 in epoch 4, gen_loss = 1.1651470543594535, disc_loss = 0.0010526701881069104
Trained batch 436 in epoch 4, gen_loss = 1.1651425173408108, disc_loss = 0.0010527767208966935
Trained batch 437 in epoch 4, gen_loss = 1.1655762742643487, disc_loss = 0.0010521000142665856
Trained batch 438 in epoch 4, gen_loss = 1.1658584294938281, disc_loss = 0.0010514726647446865
Trained batch 439 in epoch 4, gen_loss = 1.165615342421965, disc_loss = 0.001050074580912637
Trained batch 440 in epoch 4, gen_loss = 1.1655575753339564, disc_loss = 0.00104811431037166
Trained batch 441 in epoch 4, gen_loss = 1.165406035352077, disc_loss = 0.0010464346186509167
Trained batch 442 in epoch 4, gen_loss = 1.165069549132147, disc_loss = 0.0010447917228791144
Trained batch 443 in epoch 4, gen_loss = 1.1647772053340535, disc_loss = 0.0010431218114726115
Trained batch 444 in epoch 4, gen_loss = 1.164491953474752, disc_loss = 0.0010419244614097531
Trained batch 445 in epoch 4, gen_loss = 1.164619621674576, disc_loss = 0.0010421809841444896
Trained batch 446 in epoch 4, gen_loss = 1.1650706825640378, disc_loss = 0.0010431758703997825
Trained batch 447 in epoch 4, gen_loss = 1.1653138835515295, disc_loss = 0.0010438698843699967
Trained batch 448 in epoch 4, gen_loss = 1.1656525262480057, disc_loss = 0.0010434098120476482
Trained batch 449 in epoch 4, gen_loss = 1.1654666296641032, disc_loss = 0.0010425376543167254
Trained batch 450 in epoch 4, gen_loss = 1.1655592188866863, disc_loss = 0.0010418573571815612
Trained batch 451 in epoch 4, gen_loss = 1.165551712555168, disc_loss = 0.0010411956456535705
Trained batch 452 in epoch 4, gen_loss = 1.1655666970259306, disc_loss = 0.0010397170755971597
Trained batch 453 in epoch 4, gen_loss = 1.1651900137573612, disc_loss = 0.001038181317383208
Trained batch 454 in epoch 4, gen_loss = 1.1656208795505565, disc_loss = 0.0010368762807447239
Trained batch 455 in epoch 4, gen_loss = 1.1653287797643428, disc_loss = 0.0010354773746433224
Trained batch 456 in epoch 4, gen_loss = 1.1652187372453886, disc_loss = 0.0010342214819050498
Trained batch 457 in epoch 4, gen_loss = 1.1650886603317927, disc_loss = 0.001032842562019705
Trained batch 458 in epoch 4, gen_loss = 1.164990369011374, disc_loss = 0.0010310182222538
Trained batch 459 in epoch 4, gen_loss = 1.164742292010266, disc_loss = 0.0010290853113869873
Trained batch 460 in epoch 4, gen_loss = 1.1649959826934881, disc_loss = 0.0010272596890211344
Trained batch 461 in epoch 4, gen_loss = 1.1651132996980247, disc_loss = 0.0010259935164103967
Trained batch 462 in epoch 4, gen_loss = 1.1649195841527655, disc_loss = 0.001025296330519099
Trained batch 463 in epoch 4, gen_loss = 1.1645444140865886, disc_loss = 0.0010255625067719816
Trained batch 464 in epoch 4, gen_loss = 1.164265888737094, disc_loss = 0.00102802867927934
Trained batch 465 in epoch 4, gen_loss = 1.163872563531982, disc_loss = 0.0010309951367591659
Trained batch 466 in epoch 4, gen_loss = 1.1650041923788426, disc_loss = 0.0010339741802181575
Trained batch 467 in epoch 4, gen_loss = 1.165004469645329, disc_loss = 0.0010369877861979373
Trained batch 468 in epoch 4, gen_loss = 1.1653382846795675, disc_loss = 0.001038546875477391
Trained batch 469 in epoch 4, gen_loss = 1.1654903566583674, disc_loss = 0.0010390553221866945
Trained batch 470 in epoch 4, gen_loss = 1.165954305361284, disc_loss = 0.0010393698713799045
Trained batch 471 in epoch 4, gen_loss = 1.1659414677296656, disc_loss = 0.0010393702768080897
Trained batch 472 in epoch 4, gen_loss = 1.165541496639776, disc_loss = 0.0010383204420342802
Trained batch 473 in epoch 4, gen_loss = 1.1650614991218229, disc_loss = 0.001037505125686603
Trained batch 474 in epoch 4, gen_loss = 1.1648248957332812, disc_loss = 0.001036600428847841
Trained batch 475 in epoch 4, gen_loss = 1.1646181904718655, disc_loss = 0.0010355035146782
Trained batch 476 in epoch 4, gen_loss = 1.1644691420051287, disc_loss = 0.0010340730532448822
Trained batch 477 in epoch 4, gen_loss = 1.1642901033287767, disc_loss = 0.0010323795003725886
Trained batch 478 in epoch 4, gen_loss = 1.1644660106282643, disc_loss = 0.0010309620683945692
Trained batch 479 in epoch 4, gen_loss = 1.16472326554358, disc_loss = 0.0010312448429734408
Trained batch 480 in epoch 4, gen_loss = 1.1648288661625679, disc_loss = 0.0010328550833077006
Trained batch 481 in epoch 4, gen_loss = 1.16453552159531, disc_loss = 0.0010344446389776503
Trained batch 482 in epoch 4, gen_loss = 1.1645258039421176, disc_loss = 0.0010359303588428443
Trained batch 483 in epoch 4, gen_loss = 1.164382544061369, disc_loss = 0.0010372325479152057
Trained batch 484 in epoch 4, gen_loss = 1.164642659536342, disc_loss = 0.0010394274851801737
Trained batch 485 in epoch 4, gen_loss = 1.1646762749049888, disc_loss = 0.0010416510096562398
Trained batch 486 in epoch 4, gen_loss = 1.1649750523743443, disc_loss = 0.0010427892782646031
Trained batch 487 in epoch 4, gen_loss = 1.1648325320394313, disc_loss = 0.00104241080401555
Trained batch 488 in epoch 4, gen_loss = 1.1649037583717783, disc_loss = 0.001041221984408335
Trained batch 489 in epoch 4, gen_loss = 1.1652674087456294, disc_loss = 0.0010397115721704666
Trained batch 490 in epoch 4, gen_loss = 1.165355519340383, disc_loss = 0.001038353204373422
Trained batch 491 in epoch 4, gen_loss = 1.1651532554287252, disc_loss = 0.0010372959689011918
Trained batch 492 in epoch 4, gen_loss = 1.1652497056773419, disc_loss = 0.0010357779479877453
Trained batch 493 in epoch 4, gen_loss = 1.1656876205191438, disc_loss = 0.0010340599527760212
Trained batch 494 in epoch 4, gen_loss = 1.1654738374430724, disc_loss = 0.0010327966385485718
Trained batch 495 in epoch 4, gen_loss = 1.1650502560359817, disc_loss = 0.0010322594814551262
Trained batch 496 in epoch 4, gen_loss = 1.1647940505918122, disc_loss = 0.0010336112930269357
Trained batch 497 in epoch 4, gen_loss = 1.1646823573064613, disc_loss = 0.0010357046725490715
Trained batch 498 in epoch 4, gen_loss = 1.1645732811075413, disc_loss = 0.0010355097115544215
Trained batch 499 in epoch 4, gen_loss = 1.164553237080574, disc_loss = 0.0010343474845576565
Trained batch 500 in epoch 4, gen_loss = 1.164328185027231, disc_loss = 0.0010349298741084295
Trained batch 501 in epoch 4, gen_loss = 1.164466622459936, disc_loss = 0.0010367132845022567
Trained batch 502 in epoch 4, gen_loss = 1.1646715958360174, disc_loss = 0.0010366028678549313
Trained batch 503 in epoch 4, gen_loss = 1.1642931883060743, disc_loss = 0.0010357507285262395
Trained batch 504 in epoch 4, gen_loss = 1.1640957847680196, disc_loss = 0.0010354261203048898
Trained batch 505 in epoch 4, gen_loss = 1.1640117975327338, disc_loss = 0.0010348550462899748
Trained batch 506 in epoch 4, gen_loss = 1.164019606404991, disc_loss = 0.001033773482759957
Trained batch 507 in epoch 4, gen_loss = 1.1638285718330248, disc_loss = 0.0010326614333960634
Trained batch 508 in epoch 4, gen_loss = 1.1637819374239984, disc_loss = 0.0010310492286134294
Trained batch 509 in epoch 4, gen_loss = 1.1635730854436463, disc_loss = 0.001029275247585211
Trained batch 510 in epoch 4, gen_loss = 1.1632540448771065, disc_loss = 0.0010278126842947404
Trained batch 511 in epoch 4, gen_loss = 1.163019674248062, disc_loss = 0.0010274952122699688
Trained batch 512 in epoch 4, gen_loss = 1.1636994034923307, disc_loss = 0.0010278239957652404
Trained batch 513 in epoch 4, gen_loss = 1.1636818363276902, disc_loss = 0.001027676502558863
Trained batch 514 in epoch 4, gen_loss = 1.1635960318509815, disc_loss = 0.0010276889429626606
Trained batch 515 in epoch 4, gen_loss = 1.1638408546992975, disc_loss = 0.001026926955091767
Trained batch 516 in epoch 4, gen_loss = 1.163546253334392, disc_loss = 0.001026224225063266
Trained batch 517 in epoch 4, gen_loss = 1.1633674317115061, disc_loss = 0.0010255013468259996
Trained batch 518 in epoch 4, gen_loss = 1.163353872781544, disc_loss = 0.0010243844885113496
Trained batch 519 in epoch 4, gen_loss = 1.1629405802259078, disc_loss = 0.001023774638843651
Trained batch 520 in epoch 4, gen_loss = 1.1624805713340554, disc_loss = 0.0010233709284536998
Trained batch 521 in epoch 4, gen_loss = 1.1625447623802785, disc_loss = 0.0010228473737735973
Trained batch 522 in epoch 4, gen_loss = 1.162057058305175, disc_loss = 0.00102235551903035
Trained batch 523 in epoch 4, gen_loss = 1.161809511767089, disc_loss = 0.0010237916621987403
Trained batch 524 in epoch 4, gen_loss = 1.161865624019078, disc_loss = 0.0010243688756600023
Trained batch 525 in epoch 4, gen_loss = 1.161830190016743, disc_loss = 0.0010234405197638722
Trained batch 526 in epoch 4, gen_loss = 1.1618947557525345, disc_loss = 0.001022197017989579
Trained batch 527 in epoch 4, gen_loss = 1.1616767125599312, disc_loss = 0.0010208785561465475
Trained batch 528 in epoch 4, gen_loss = 1.1615664668254455, disc_loss = 0.0010200366922495764
Trained batch 529 in epoch 4, gen_loss = 1.1614792826040736, disc_loss = 0.001019580776579151
Trained batch 530 in epoch 4, gen_loss = 1.1610530769757632, disc_loss = 0.0010185387617384
Trained batch 531 in epoch 4, gen_loss = 1.1606426000371015, disc_loss = 0.0010174111785022262
Trained batch 532 in epoch 4, gen_loss = 1.1606278302074597, disc_loss = 0.0010162754100965822
Trained batch 533 in epoch 4, gen_loss = 1.1603777601701044, disc_loss = 0.0010149699530833704
Trained batch 534 in epoch 4, gen_loss = 1.16021485874586, disc_loss = 0.0010138211193577186
Trained batch 535 in epoch 4, gen_loss = 1.1603223549118682, disc_loss = 0.0010125077419819608
Trained batch 536 in epoch 4, gen_loss = 1.1605911719954436, disc_loss = 0.0010110212131069533
Trained batch 537 in epoch 4, gen_loss = 1.1611072792218078, disc_loss = 0.001009596707279877
Trained batch 538 in epoch 4, gen_loss = 1.1611391968320164, disc_loss = 0.0010080346713719046
Trained batch 539 in epoch 4, gen_loss = 1.1610985823251583, disc_loss = 0.0010065751275019634
Trained batch 540 in epoch 4, gen_loss = 1.1609001887924348, disc_loss = 0.0010051577606820716
Trained batch 541 in epoch 4, gen_loss = 1.1609177715883923, disc_loss = 0.0010036681049790774
Trained batch 542 in epoch 4, gen_loss = 1.1608408629125873, disc_loss = 0.001002303400561668
Trained batch 543 in epoch 4, gen_loss = 1.1613794616697466, disc_loss = 0.0010013182315346699
Trained batch 544 in epoch 4, gen_loss = 1.16158079630738, disc_loss = 0.001000288635499801
Trained batch 545 in epoch 4, gen_loss = 1.1615908234329013, disc_loss = 0.0009991246517442743
Trained batch 546 in epoch 4, gen_loss = 1.1613890441505739, disc_loss = 0.000997890866274513
Trained batch 547 in epoch 4, gen_loss = 1.1616177475147873, disc_loss = 0.000996553675218674
Trained batch 548 in epoch 4, gen_loss = 1.1615678051347507, disc_loss = 0.0009952188441213917
Trained batch 549 in epoch 4, gen_loss = 1.1618649464303796, disc_loss = 0.0009938491258600897
Trained batch 550 in epoch 4, gen_loss = 1.1619976868214061, disc_loss = 0.0009923867029099879
Trained batch 551 in epoch 4, gen_loss = 1.1620164683115655, disc_loss = 0.0009909075072399623
Trained batch 552 in epoch 4, gen_loss = 1.1617392697127344, disc_loss = 0.0009895590376900424
Trained batch 553 in epoch 4, gen_loss = 1.1618749188387008, disc_loss = 0.0009886661182167782
Trained batch 554 in epoch 4, gen_loss = 1.1619162773226832, disc_loss = 0.0009880329196987388
Trained batch 555 in epoch 4, gen_loss = 1.1617915144712805, disc_loss = 0.0009870861844149612
Trained batch 556 in epoch 4, gen_loss = 1.1616101507866619, disc_loss = 0.0009858778172508686
Trained batch 557 in epoch 4, gen_loss = 1.161764642777836, disc_loss = 0.0009846048772595422
Trained batch 558 in epoch 4, gen_loss = 1.1617448015375087, disc_loss = 0.000983519688825921
Trained batch 559 in epoch 4, gen_loss = 1.1615774971033845, disc_loss = 0.0009826124662400356
Trained batch 560 in epoch 4, gen_loss = 1.1616518568652623, disc_loss = 0.000981557971105617
Trained batch 561 in epoch 4, gen_loss = 1.1619714181406218, disc_loss = 0.0009807150256223446
Trained batch 562 in epoch 4, gen_loss = 1.1616750063100039, disc_loss = 0.0009795949551596125
Trained batch 563 in epoch 4, gen_loss = 1.1614282337274957, disc_loss = 0.0009788996402747229
Trained batch 564 in epoch 4, gen_loss = 1.161520676380765, disc_loss = 0.0009785561825445465
Trained batch 565 in epoch 4, gen_loss = 1.1613874792420822, disc_loss = 0.0009778561024283232
Trained batch 566 in epoch 4, gen_loss = 1.161222816039225, disc_loss = 0.0009768669309942102
Trained batch 567 in epoch 4, gen_loss = 1.1613552632256292, disc_loss = 0.0009757715518607653
Trained batch 568 in epoch 4, gen_loss = 1.161092416997115, disc_loss = 0.0009751231238771368
Trained batch 569 in epoch 4, gen_loss = 1.1611069870622535, disc_loss = 0.0009743695542534911
Trained batch 570 in epoch 4, gen_loss = 1.160988132820029, disc_loss = 0.0009736456830199684
Trained batch 571 in epoch 4, gen_loss = 1.161202903289895, disc_loss = 0.0009734820949208395
Trained batch 572 in epoch 4, gen_loss = 1.161222926505157, disc_loss = 0.0009738935490242851
Trained batch 573 in epoch 4, gen_loss = 1.160930115067585, disc_loss = 0.0009737128830143292
Trained batch 574 in epoch 4, gen_loss = 1.160948331148728, disc_loss = 0.0009734668561419391
Trained batch 575 in epoch 4, gen_loss = 1.1607699701562524, disc_loss = 0.0009726130144574401
Trained batch 576 in epoch 4, gen_loss = 1.1611786383483398, disc_loss = 0.0009715286028237313
Trained batch 577 in epoch 4, gen_loss = 1.1614381513174843, disc_loss = 0.000970335422733486
Trained batch 578 in epoch 4, gen_loss = 1.1614475263626876, disc_loss = 0.0009690946204180062
Trained batch 579 in epoch 4, gen_loss = 1.1612623482942581, disc_loss = 0.0009679882907597669
Trained batch 580 in epoch 4, gen_loss = 1.1609270734754158, disc_loss = 0.0009674000101550298
Trained batch 581 in epoch 4, gen_loss = 1.1611989185572489, disc_loss = 0.0009676053502182461
Trained batch 582 in epoch 4, gen_loss = 1.161383217849208, disc_loss = 0.0009676229781199623
Trained batch 583 in epoch 4, gen_loss = 1.1614110290187678, disc_loss = 0.0009666486429560879
Trained batch 584 in epoch 4, gen_loss = 1.1613093602351654, disc_loss = 0.0009661544944183566
Trained batch 585 in epoch 4, gen_loss = 1.161235516998955, disc_loss = 0.0009669860755013931
Trained batch 586 in epoch 4, gen_loss = 1.1615688605852794, disc_loss = 0.0009693946559267718
Trained batch 587 in epoch 4, gen_loss = 1.1615806899103178, disc_loss = 0.0009721997071241289
Trained batch 588 in epoch 4, gen_loss = 1.1613532132730013, disc_loss = 0.0009737496753658069
Trained batch 589 in epoch 4, gen_loss = 1.1618321297532421, disc_loss = 0.0009747123416765767
Trained batch 590 in epoch 4, gen_loss = 1.1620647447363375, disc_loss = 0.0009750511470469828
Trained batch 591 in epoch 4, gen_loss = 1.1617445530923638, disc_loss = 0.0009760043919684265
Trained batch 592 in epoch 4, gen_loss = 1.1614351432399845, disc_loss = 0.0009767697795418297
Trained batch 593 in epoch 4, gen_loss = 1.1615576658786748, disc_loss = 0.0009765960836645078
Trained batch 594 in epoch 4, gen_loss = 1.1614925668019207, disc_loss = 0.000977058003132208
Trained batch 595 in epoch 4, gen_loss = 1.1616816453685697, disc_loss = 0.0009774450931913726
Trained batch 596 in epoch 4, gen_loss = 1.161860895017084, disc_loss = 0.00097798121920701
Trained batch 597 in epoch 4, gen_loss = 1.1618159914694501, disc_loss = 0.0009788468822347855
Trained batch 598 in epoch 4, gen_loss = 1.1617668786510602, disc_loss = 0.000979684949199512
Trained batch 599 in epoch 4, gen_loss = 1.1618378286560376, disc_loss = 0.0009798750752815976
Trained batch 600 in epoch 4, gen_loss = 1.1624319121960593, disc_loss = 0.0009794214733809654
Trained batch 601 in epoch 4, gen_loss = 1.1627580671017352, disc_loss = 0.0009784853948644546
Trained batch 602 in epoch 4, gen_loss = 1.1628261382504679, disc_loss = 0.0009776186809031784
Trained batch 603 in epoch 4, gen_loss = 1.1626468019572316, disc_loss = 0.000977910847795529
Trained batch 604 in epoch 4, gen_loss = 1.162325531096498, disc_loss = 0.0009783447041822797
Trained batch 605 in epoch 4, gen_loss = 1.1621637990569125, disc_loss = 0.0009776524922398622
Trained batch 606 in epoch 4, gen_loss = 1.1622530933856179, disc_loss = 0.0009767274920601564
Trained batch 607 in epoch 4, gen_loss = 1.1621200719750242, disc_loss = 0.0009756667462313903
Trained batch 608 in epoch 4, gen_loss = 1.162155797426728, disc_loss = 0.0009743250360328563
Trained batch 609 in epoch 4, gen_loss = 1.1622107926939353, disc_loss = 0.0009731460224787445
Trained batch 610 in epoch 4, gen_loss = 1.1619267705614555, disc_loss = 0.0009718567958002934
Trained batch 611 in epoch 4, gen_loss = 1.1623506814825768, disc_loss = 0.0009705946421270864
Trained batch 612 in epoch 4, gen_loss = 1.1621650655740237, disc_loss = 0.0009694701497874877
Trained batch 613 in epoch 4, gen_loss = 1.162269261450255, disc_loss = 0.0009686652691028056
Trained batch 614 in epoch 4, gen_loss = 1.1620871875344254, disc_loss = 0.0009682714796437678
Trained batch 615 in epoch 4, gen_loss = 1.1622272218976701, disc_loss = 0.0009676321426320703
Trained batch 616 in epoch 4, gen_loss = 1.1621427787181045, disc_loss = 0.0009668570904921954
Trained batch 617 in epoch 4, gen_loss = 1.1621681756572044, disc_loss = 0.0009659776568134363
Trained batch 618 in epoch 4, gen_loss = 1.1620553217719944, disc_loss = 0.0009650465477660813
Trained batch 619 in epoch 4, gen_loss = 1.1619429376817518, disc_loss = 0.000964123397317317
Trained batch 620 in epoch 4, gen_loss = 1.1619693108034979, disc_loss = 0.0009631050697701418
Trained batch 621 in epoch 4, gen_loss = 1.162006172336566, disc_loss = 0.0009625032222917725
Trained batch 622 in epoch 4, gen_loss = 1.1617465308160306, disc_loss = 0.0009632837214874534
Trained batch 623 in epoch 4, gen_loss = 1.1616852251000893, disc_loss = 0.0009677295834197325
Trained batch 624 in epoch 4, gen_loss = 1.161804450416565, disc_loss = 0.0009722326983464881
Trained batch 625 in epoch 4, gen_loss = 1.161717617283233, disc_loss = 0.0009746947173970549
Trained batch 626 in epoch 4, gen_loss = 1.1615833279808934, disc_loss = 0.0009751551977625752
Trained batch 627 in epoch 4, gen_loss = 1.1616274716368147, disc_loss = 0.0009751964943618054
Trained batch 628 in epoch 4, gen_loss = 1.1620530947592755, disc_loss = 0.0009758302889679542
Trained batch 629 in epoch 4, gen_loss = 1.1621630702699934, disc_loss = 0.0009760593853859482
Trained batch 630 in epoch 4, gen_loss = 1.1625601644561332, disc_loss = 0.0009757566874174891
Trained batch 631 in epoch 4, gen_loss = 1.162726259684261, disc_loss = 0.000974687171912615
Trained batch 632 in epoch 4, gen_loss = 1.1623052164653278, disc_loss = 0.0009747245040710054
Trained batch 633 in epoch 4, gen_loss = 1.1619074544884054, disc_loss = 0.0009752908086561016
Trained batch 634 in epoch 4, gen_loss = 1.1616007928773173, disc_loss = 0.0009747275652494062
Trained batch 635 in epoch 4, gen_loss = 1.161469265537442, disc_loss = 0.0009744494548973513
Trained batch 636 in epoch 4, gen_loss = 1.1612760451749504, disc_loss = 0.0009754924891979669
Trained batch 637 in epoch 4, gen_loss = 1.161357976613, disc_loss = 0.0009770686766247668
Trained batch 638 in epoch 4, gen_loss = 1.161708180706639, disc_loss = 0.0009779550770910876
Trained batch 639 in epoch 4, gen_loss = 1.1615608045831323, disc_loss = 0.0009778347176279567
Trained batch 640 in epoch 4, gen_loss = 1.1614953275775761, disc_loss = 0.0009777961417917502
Trained batch 641 in epoch 4, gen_loss = 1.161706957861642, disc_loss = 0.0009790800700739905
Trained batch 642 in epoch 4, gen_loss = 1.161922803006684, disc_loss = 0.0009804522692836736
Trained batch 643 in epoch 4, gen_loss = 1.1621321250933299, disc_loss = 0.000980974134430687
Trained batch 644 in epoch 4, gen_loss = 1.1619903117187262, disc_loss = 0.0009825647771385564
Trained batch 645 in epoch 4, gen_loss = 1.161867456354962, disc_loss = 0.0009840135994875852
Trained batch 646 in epoch 4, gen_loss = 1.1621089060855612, disc_loss = 0.0009843859630786214
Trained batch 647 in epoch 4, gen_loss = 1.1622970981730356, disc_loss = 0.000987932026054082
Trained batch 648 in epoch 4, gen_loss = 1.1619189832537493, disc_loss = 0.0009932419079926671
Trained batch 649 in epoch 4, gen_loss = 1.1626321059006912, disc_loss = 0.0009939944053453823
Trained batch 650 in epoch 4, gen_loss = 1.1626412806239912, disc_loss = 0.000995230894157922
Trained batch 651 in epoch 4, gen_loss = 1.1631325128619656, disc_loss = 0.0009998395060147288
Trained batch 652 in epoch 4, gen_loss = 1.1629528020826634, disc_loss = 0.0010085744096868662
Trained batch 653 in epoch 4, gen_loss = 1.1630897656857786, disc_loss = 0.0010141845231059446
Trained batch 654 in epoch 4, gen_loss = 1.1632791533724953, disc_loss = 0.0010148211466530623
Trained batch 655 in epoch 4, gen_loss = 1.1632914455925547, disc_loss = 0.0010146961302136953
Trained batch 656 in epoch 4, gen_loss = 1.1630871578982975, disc_loss = 0.0010144280309743168
Trained batch 657 in epoch 4, gen_loss = 1.1629828196528473, disc_loss = 0.0010147851329510196
Trained batch 658 in epoch 4, gen_loss = 1.163175301233445, disc_loss = 0.0010144865466555587
Trained batch 659 in epoch 4, gen_loss = 1.1631979525089264, disc_loss = 0.0010138488235084382
Trained batch 660 in epoch 4, gen_loss = 1.1631437442667005, disc_loss = 0.0010135504111333056
Trained batch 661 in epoch 4, gen_loss = 1.1634800317064153, disc_loss = 0.0010141939819842123
Trained batch 662 in epoch 4, gen_loss = 1.163492696677218, disc_loss = 0.0010156010478047715
Trained batch 663 in epoch 4, gen_loss = 1.1636455005191895, disc_loss = 0.0010160790251717688
Trained batch 664 in epoch 4, gen_loss = 1.1637072620535256, disc_loss = 0.0010156692948176602
Trained batch 665 in epoch 4, gen_loss = 1.163419247837038, disc_loss = 0.0010155571512372775
Trained batch 666 in epoch 4, gen_loss = 1.1634172396860023, disc_loss = 0.00101716231684863
Trained batch 667 in epoch 4, gen_loss = 1.1633078401495596, disc_loss = 0.0010210020514649497
Trained batch 668 in epoch 4, gen_loss = 1.163696017589626, disc_loss = 0.0010274944450698936
Trained batch 669 in epoch 4, gen_loss = 1.1636055178606688, disc_loss = 0.0010320601445134492
Trained batch 670 in epoch 4, gen_loss = 1.1633600517108083, disc_loss = 0.001034595276191435
Trained batch 671 in epoch 4, gen_loss = 1.16318754922776, disc_loss = 0.0010363931646679703
Trained batch 672 in epoch 4, gen_loss = 1.163404758936583, disc_loss = 0.0010375865833668792
Trained batch 673 in epoch 4, gen_loss = 1.1634212971087379, disc_loss = 0.0010375330418385274
Trained batch 674 in epoch 4, gen_loss = 1.163519829114278, disc_loss = 0.001037171190772723
Trained batch 675 in epoch 4, gen_loss = 1.1634780671116869, disc_loss = 0.0010364272984696385
Trained batch 676 in epoch 4, gen_loss = 1.163432947465905, disc_loss = 0.0010352989187678377
Trained batch 677 in epoch 4, gen_loss = 1.163611318685312, disc_loss = 0.001035143759809565
Trained batch 678 in epoch 4, gen_loss = 1.1636926799529783, disc_loss = 0.00103630327575635
Trained batch 679 in epoch 4, gen_loss = 1.1636884489480186, disc_loss = 0.0010366542081422213
Trained batch 680 in epoch 4, gen_loss = 1.1634852501089177, disc_loss = 0.0010367107395178102
Trained batch 681 in epoch 4, gen_loss = 1.163298178278456, disc_loss = 0.0010363282432465247
Trained batch 682 in epoch 4, gen_loss = 1.1636548564165263, disc_loss = 0.0010357756522989669
Trained batch 683 in epoch 4, gen_loss = 1.1633815898707038, disc_loss = 0.0010353301311848203
Trained batch 684 in epoch 4, gen_loss = 1.1631229131761258, disc_loss = 0.0010347526685129103
Trained batch 685 in epoch 4, gen_loss = 1.1632548774817941, disc_loss = 0.0010346034893644878
Trained batch 686 in epoch 4, gen_loss = 1.163000815386682, disc_loss = 0.0010356309990731734
Trained batch 687 in epoch 4, gen_loss = 1.1628087484386078, disc_loss = 0.0010360652376072911
Trained batch 688 in epoch 4, gen_loss = 1.162781874829003, disc_loss = 0.0010353140242988141
Trained batch 689 in epoch 4, gen_loss = 1.162727422213209, disc_loss = 0.0010344074722472242
Trained batch 690 in epoch 4, gen_loss = 1.1624317080343167, disc_loss = 0.0010336952964570064
Trained batch 691 in epoch 4, gen_loss = 1.1626052905541624, disc_loss = 0.0010334229123645066
Trained batch 692 in epoch 4, gen_loss = 1.162555186177401, disc_loss = 0.0010329088231057807
Trained batch 693 in epoch 4, gen_loss = 1.1625423911497297, disc_loss = 0.001032174500043441
Trained batch 694 in epoch 4, gen_loss = 1.1624196024249784, disc_loss = 0.0010319096629847872
Trained batch 695 in epoch 4, gen_loss = 1.1622946936337428, disc_loss = 0.001031135330317059
Trained batch 696 in epoch 4, gen_loss = 1.162772338992383, disc_loss = 0.0010302084302230721
Trained batch 697 in epoch 4, gen_loss = 1.1627888526650076, disc_loss = 0.0010292587425423997
Trained batch 698 in epoch 4, gen_loss = 1.162818723567395, disc_loss = 0.001028519624116223
Trained batch 699 in epoch 4, gen_loss = 1.162448033435004, disc_loss = 0.001028149375945629
Trained batch 700 in epoch 4, gen_loss = 1.1624086229675337, disc_loss = 0.001027488277431414
Trained batch 701 in epoch 4, gen_loss = 1.1625343404943786, disc_loss = 0.0010267831231117516
Trained batch 702 in epoch 4, gen_loss = 1.162284966552919, disc_loss = 0.001026341133651782
Trained batch 703 in epoch 4, gen_loss = 1.1620584396137432, disc_loss = 0.001025488255333006
Trained batch 704 in epoch 4, gen_loss = 1.1618630240149532, disc_loss = 0.001025715978392598
Trained batch 705 in epoch 4, gen_loss = 1.1617972523227291, disc_loss = 0.00102668372788793
Trained batch 706 in epoch 4, gen_loss = 1.161938855469311, disc_loss = 0.0010278056636628863
Trained batch 707 in epoch 4, gen_loss = 1.1621639341284327, disc_loss = 0.0010295485563457504
Trained batch 708 in epoch 4, gen_loss = 1.1618692425982067, disc_loss = 0.0010311149544243823
Trained batch 709 in epoch 4, gen_loss = 1.1619117023239673, disc_loss = 0.00103191635143061
Trained batch 710 in epoch 4, gen_loss = 1.1619949342496956, disc_loss = 0.0010312285654581808
Trained batch 711 in epoch 4, gen_loss = 1.1619585059332045, disc_loss = 0.0010308861884991887
Trained batch 712 in epoch 4, gen_loss = 1.162025522550393, disc_loss = 0.001030414579592111
Trained batch 713 in epoch 4, gen_loss = 1.1620906933682973, disc_loss = 0.00103014462145423
Trained batch 714 in epoch 4, gen_loss = 1.1618372808803212, disc_loss = 0.001030840051594073
Trained batch 715 in epoch 4, gen_loss = 1.161582417494758, disc_loss = 0.001031332257750552
Trained batch 716 in epoch 4, gen_loss = 1.1612872944383608, disc_loss = 0.0010305746606668988
Trained batch 717 in epoch 4, gen_loss = 1.161052777574587, disc_loss = 0.0010298927209635453
Trained batch 718 in epoch 4, gen_loss = 1.1608234539482956, disc_loss = 0.0010289059363469749
Trained batch 719 in epoch 4, gen_loss = 1.1606809405816927, disc_loss = 0.0010280868210126451
Trained batch 720 in epoch 4, gen_loss = 1.1605511556551293, disc_loss = 0.0010275205191563564
Trained batch 721 in epoch 4, gen_loss = 1.1604004913419899, disc_loss = 0.0010271135705255212
Trained batch 722 in epoch 4, gen_loss = 1.1603093678196106, disc_loss = 0.0010265100412310667
Trained batch 723 in epoch 4, gen_loss = 1.1603661449574634, disc_loss = 0.0010262578888418402
Trained batch 724 in epoch 4, gen_loss = 1.1601904227815825, disc_loss = 0.0010260845695277035
Trained batch 725 in epoch 4, gen_loss = 1.160148048696439, disc_loss = 0.0010258748616226922
Trained batch 726 in epoch 4, gen_loss = 1.1599683304108483, disc_loss = 0.0010265063383673194
Trained batch 727 in epoch 4, gen_loss = 1.160125923025739, disc_loss = 0.0010268571723617453
Trained batch 728 in epoch 4, gen_loss = 1.1602856143184814, disc_loss = 0.00102644371545017
Trained batch 729 in epoch 4, gen_loss = 1.1600810908291437, disc_loss = 0.001025922947394987
Trained batch 730 in epoch 4, gen_loss = 1.1603809763077346, disc_loss = 0.001025538688762688
Trained batch 731 in epoch 4, gen_loss = 1.1601127974811147, disc_loss = 0.0010263193824337706
Trained batch 732 in epoch 4, gen_loss = 1.1599846106596892, disc_loss = 0.0010281696458898884
Trained batch 733 in epoch 4, gen_loss = 1.1598331363876768, disc_loss = 0.0010295668895439149
Trained batch 734 in epoch 4, gen_loss = 1.1596579675771752, disc_loss = 0.0010291723518032062
Trained batch 735 in epoch 4, gen_loss = 1.1593259724423937, disc_loss = 0.001028203196434017
Trained batch 736 in epoch 4, gen_loss = 1.1590675349313175, disc_loss = 0.0010276398191418376
Trained batch 737 in epoch 4, gen_loss = 1.1591649317967536, disc_loss = 0.0010278451298926653
Trained batch 738 in epoch 4, gen_loss = 1.1591068779664047, disc_loss = 0.0010285945464480423
Trained batch 739 in epoch 4, gen_loss = 1.158908432963732, disc_loss = 0.001029336480349082
Trained batch 740 in epoch 4, gen_loss = 1.1588057320610232, disc_loss = 0.0010290454864992438
Trained batch 741 in epoch 4, gen_loss = 1.1589555297739744, disc_loss = 0.0010282901866492348
Trained batch 742 in epoch 4, gen_loss = 1.1590218316979235, disc_loss = 0.0010280763111078816
Trained batch 743 in epoch 4, gen_loss = 1.1592684813564824, disc_loss = 0.001027852769238375
Trained batch 744 in epoch 4, gen_loss = 1.159239801864496, disc_loss = 0.0010271438115609234
Trained batch 745 in epoch 4, gen_loss = 1.1593051678213933, disc_loss = 0.0010265486166681707
Trained batch 746 in epoch 4, gen_loss = 1.1594618377755763, disc_loss = 0.0010260747657152805
Trained batch 747 in epoch 4, gen_loss = 1.1593689659540667, disc_loss = 0.0010253792674130358
Trained batch 748 in epoch 4, gen_loss = 1.1592249958632943, disc_loss = 0.001024489413275575
Trained batch 749 in epoch 4, gen_loss = 1.1592046096324922, disc_loss = 0.0010236695942973408
Trained batch 750 in epoch 4, gen_loss = 1.159147137728893, disc_loss = 0.0010231587701651035
Trained batch 751 in epoch 4, gen_loss = 1.1588455685117143, disc_loss = 0.0010225859670096357
Trained batch 752 in epoch 4, gen_loss = 1.158814283085376, disc_loss = 0.001022617565409978
Trained batch 753 in epoch 4, gen_loss = 1.1588689067477573, disc_loss = 0.001022892955272052
Trained batch 754 in epoch 4, gen_loss = 1.159060857548619, disc_loss = 0.0010230452376795587
Trained batch 755 in epoch 4, gen_loss = 1.1593688547453553, disc_loss = 0.0010226562385493212
Trained batch 756 in epoch 4, gen_loss = 1.159112799435342, disc_loss = 0.001022249796029329
Trained batch 757 in epoch 4, gen_loss = 1.1590630575660665, disc_loss = 0.0010219344195682805
Trained batch 758 in epoch 4, gen_loss = 1.1587649978039607, disc_loss = 0.0010216886002844328
Trained batch 759 in epoch 4, gen_loss = 1.1590642194998892, disc_loss = 0.0010220562160898944
Trained batch 760 in epoch 4, gen_loss = 1.159107133530756, disc_loss = 0.0010227324814070934
Trained batch 761 in epoch 4, gen_loss = 1.1593349500903933, disc_loss = 0.001023257390588792
Trained batch 762 in epoch 4, gen_loss = 1.159027589882967, disc_loss = 0.0010233158696734872
Trained batch 763 in epoch 4, gen_loss = 1.1587796286138565, disc_loss = 0.0010231703890133126
Trained batch 764 in epoch 4, gen_loss = 1.1589046032600154, disc_loss = 0.0010232344596362156
Trained batch 765 in epoch 4, gen_loss = 1.1588693836961652, disc_loss = 0.001022758930542369
Trained batch 766 in epoch 4, gen_loss = 1.158783124198814, disc_loss = 0.001022147360131675
Trained batch 767 in epoch 4, gen_loss = 1.1585898254998028, disc_loss = 0.0010213118325926491
Trained batch 768 in epoch 4, gen_loss = 1.1587901113867294, disc_loss = 0.0010204373209085375
Trained batch 769 in epoch 4, gen_loss = 1.1586082989519293, disc_loss = 0.0010200065219519332
Trained batch 770 in epoch 4, gen_loss = 1.1589346901452031, disc_loss = 0.0010203538383361758
Trained batch 771 in epoch 4, gen_loss = 1.1589642900568216, disc_loss = 0.001021076848701341
Trained batch 772 in epoch 4, gen_loss = 1.159257869362677, disc_loss = 0.001021712137602919
Trained batch 773 in epoch 4, gen_loss = 1.1593420399251835, disc_loss = 0.0010221780388751692
Trained batch 774 in epoch 4, gen_loss = 1.1590921734225366, disc_loss = 0.001022980585750643
Trained batch 775 in epoch 4, gen_loss = 1.1592949128028043, disc_loss = 0.0010239683133008418
Trained batch 776 in epoch 4, gen_loss = 1.1592328235449478, disc_loss = 0.001025037050927855
Trained batch 777 in epoch 4, gen_loss = 1.1590597945191254, disc_loss = 0.0010254524538320714
Trained batch 778 in epoch 4, gen_loss = 1.1589787398131424, disc_loss = 0.0010252211182801153
Trained batch 779 in epoch 4, gen_loss = 1.1588418933061453, disc_loss = 0.001026693049080234
Trained batch 780 in epoch 4, gen_loss = 1.1588467281698112, disc_loss = 0.0010316193564346289
Trained batch 781 in epoch 4, gen_loss = 1.1588489021486639, disc_loss = 0.0010402264623970326
Trained batch 782 in epoch 4, gen_loss = 1.158896677643251, disc_loss = 0.001049907656119914
Trained batch 783 in epoch 4, gen_loss = 1.1586891853687715, disc_loss = 0.0010586382994897206
Trained batch 784 in epoch 4, gen_loss = 1.158687139013011, disc_loss = 0.0010628078559044285
Trained batch 785 in epoch 4, gen_loss = 1.158578393113522, disc_loss = 0.0010637562031140515
Trained batch 786 in epoch 4, gen_loss = 1.1585271676583393, disc_loss = 0.001064077743829531
Trained batch 787 in epoch 4, gen_loss = 1.158277278926772, disc_loss = 0.0010641319965871304
Trained batch 788 in epoch 4, gen_loss = 1.15832478495454, disc_loss = 0.0010633989125960867
Trained batch 789 in epoch 4, gen_loss = 1.1581443617615519, disc_loss = 0.0010628370290196242
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.9946789145469666, disc_loss = 0.0005891970358788967
Trained batch 1 in epoch 5, gen_loss = 1.1486973464488983, disc_loss = 0.0006191306747496128
Trained batch 2 in epoch 5, gen_loss = 1.1516958673795064, disc_loss = 0.0005638091436897715
Trained batch 3 in epoch 5, gen_loss = 1.202032670378685, disc_loss = 0.0005965905293123797
Trained batch 4 in epoch 5, gen_loss = 1.1571577310562133, disc_loss = 0.0008457526215352118
Trained batch 5 in epoch 5, gen_loss = 1.1564438939094543, disc_loss = 0.001153935183538124
Trained batch 6 in epoch 5, gen_loss = 1.1397034440721785, disc_loss = 0.0013783490035815962
Trained batch 7 in epoch 5, gen_loss = 1.1456768214702606, disc_loss = 0.0014090160329942591
Trained batch 8 in epoch 5, gen_loss = 1.1460704406102498, disc_loss = 0.0013485750015307632
Trained batch 9 in epoch 5, gen_loss = 1.1487653374671936, disc_loss = 0.001404421211918816
Trained batch 10 in epoch 5, gen_loss = 1.1612144058400935, disc_loss = 0.001532659479628571
Trained batch 11 in epoch 5, gen_loss = 1.1486740509668987, disc_loss = 0.0016226450631317373
Trained batch 12 in epoch 5, gen_loss = 1.1361708503503065, disc_loss = 0.0016121832304634154
Trained batch 13 in epoch 5, gen_loss = 1.1233769953250885, disc_loss = 0.0016179131052922457
Trained batch 14 in epoch 5, gen_loss = 1.1418030222256979, disc_loss = 0.0015958138625137507
Trained batch 15 in epoch 5, gen_loss = 1.1409812532365322, disc_loss = 0.0015505540250160266
Trained batch 16 in epoch 5, gen_loss = 1.1343971666167765, disc_loss = 0.0014915431418237003
Trained batch 17 in epoch 5, gen_loss = 1.142647819386588, disc_loss = 0.0014290416147559881
Trained batch 18 in epoch 5, gen_loss = 1.1355305627772683, disc_loss = 0.0013798646763653348
Trained batch 19 in epoch 5, gen_loss = 1.1357310444116593, disc_loss = 0.0013334896982996724
Trained batch 20 in epoch 5, gen_loss = 1.135070644673847, disc_loss = 0.001328347149648748
Trained batch 21 in epoch 5, gen_loss = 1.125538097186522, disc_loss = 0.0013212782148250633
Trained batch 22 in epoch 5, gen_loss = 1.12676050092863, disc_loss = 0.001293287191124957
Trained batch 23 in epoch 5, gen_loss = 1.118394486606121, disc_loss = 0.0012616166216806353
Trained batch 24 in epoch 5, gen_loss = 1.1221244263648986, disc_loss = 0.0012410644034389407
Trained batch 25 in epoch 5, gen_loss = 1.119096244756992, disc_loss = 0.0012127779135390972
Trained batch 26 in epoch 5, gen_loss = 1.1177051354337622, disc_loss = 0.0011911863252020408
Trained batch 27 in epoch 5, gen_loss = 1.1173214593103953, disc_loss = 0.0011890698712834688
Trained batch 28 in epoch 5, gen_loss = 1.1279873950728054, disc_loss = 0.0011769915350857351
Trained batch 29 in epoch 5, gen_loss = 1.1256623129049936, disc_loss = 0.0011533265322213992
Trained batch 30 in epoch 5, gen_loss = 1.1224633589867623, disc_loss = 0.0011237450474460098
Trained batch 31 in epoch 5, gen_loss = 1.1243854518979788, disc_loss = 0.0010969528789246397
Trained batch 32 in epoch 5, gen_loss = 1.1210042039553325, disc_loss = 0.0010785329571014947
Trained batch 33 in epoch 5, gen_loss = 1.1263168121085447, disc_loss = 0.0010810590033275623
Trained batch 34 in epoch 5, gen_loss = 1.1266291601317269, disc_loss = 0.0010886207634549854
Trained batch 35 in epoch 5, gen_loss = 1.1245474765698116, disc_loss = 0.0010974470945560217
Trained batch 36 in epoch 5, gen_loss = 1.1240934471826296, disc_loss = 0.0010927139141917782
Trained batch 37 in epoch 5, gen_loss = 1.1276706127743972, disc_loss = 0.0010858177338377573
Trained batch 38 in epoch 5, gen_loss = 1.1324629340416346, disc_loss = 0.001076691879111772
Trained batch 39 in epoch 5, gen_loss = 1.1285533845424651, disc_loss = 0.0010625237813655986
Trained batch 40 in epoch 5, gen_loss = 1.1243412974404126, disc_loss = 0.0010450398844025076
Trained batch 41 in epoch 5, gen_loss = 1.1228863071827662, disc_loss = 0.001026498516564191
Trained batch 42 in epoch 5, gen_loss = 1.1216457236644835, disc_loss = 0.0010111576279890615
Trained batch 43 in epoch 5, gen_loss = 1.1247974051670595, disc_loss = 0.0009929357481517152
Trained batch 44 in epoch 5, gen_loss = 1.122668272919125, disc_loss = 0.000979496293520141
Trained batch 45 in epoch 5, gen_loss = 1.1190101828264154, disc_loss = 0.0009849815858457157
Trained batch 46 in epoch 5, gen_loss = 1.1255906325705507, disc_loss = 0.0009883003900114922
Trained batch 47 in epoch 5, gen_loss = 1.122651492555936, disc_loss = 0.000984519752212994
Trained batch 48 in epoch 5, gen_loss = 1.122804838783887, disc_loss = 0.0009751219833412265
Trained batch 49 in epoch 5, gen_loss = 1.123529579639435, disc_loss = 0.0009637985262088477
Trained batch 50 in epoch 5, gen_loss = 1.1225616370930391, disc_loss = 0.0009563118230788878
Trained batch 51 in epoch 5, gen_loss = 1.1219273713918834, disc_loss = 0.0009476958288220116
Trained batch 52 in epoch 5, gen_loss = 1.1260592127746005, disc_loss = 0.0009516839998914807
Trained batch 53 in epoch 5, gen_loss = 1.1222480690037762, disc_loss = 0.000976178531008945
Trained batch 54 in epoch 5, gen_loss = 1.1192198276519776, disc_loss = 0.0010278797570870003
Trained batch 55 in epoch 5, gen_loss = 1.122151451451438, disc_loss = 0.0010574595102558046
Trained batch 56 in epoch 5, gen_loss = 1.123339096705119, disc_loss = 0.0010572510532495614
Trained batch 57 in epoch 5, gen_loss = 1.1225765326927448, disc_loss = 0.0010467312807530358
Trained batch 58 in epoch 5, gen_loss = 1.1213628073870126, disc_loss = 0.0010383405404015428
Trained batch 59 in epoch 5, gen_loss = 1.1222596049308777, disc_loss = 0.001029112730854346
Trained batch 60 in epoch 5, gen_loss = 1.1218677681000506, disc_loss = 0.0010225319873243875
Trained batch 61 in epoch 5, gen_loss = 1.1209086852688943, disc_loss = 0.001013858443325115
Trained batch 62 in epoch 5, gen_loss = 1.119432426634289, disc_loss = 0.0010072292167774683
Trained batch 63 in epoch 5, gen_loss = 1.1215959452092648, disc_loss = 0.0010045891335721535
Trained batch 64 in epoch 5, gen_loss = 1.125638114489042, disc_loss = 0.0010033766009235898
Trained batch 65 in epoch 5, gen_loss = 1.133989888610262, disc_loss = 0.0009990392828705917
Trained batch 66 in epoch 5, gen_loss = 1.133314429824032, disc_loss = 0.0009916201333772501
Trained batch 67 in epoch 5, gen_loss = 1.1328578608877518, disc_loss = 0.000981684383826659
Trained batch 68 in epoch 5, gen_loss = 1.1323013011960015, disc_loss = 0.0009747259158546618
Trained batch 69 in epoch 5, gen_loss = 1.1316821319716317, disc_loss = 0.0009718131298931049
Trained batch 70 in epoch 5, gen_loss = 1.1319360917722676, disc_loss = 0.0009691227861994904
Trained batch 71 in epoch 5, gen_loss = 1.1357543981737561, disc_loss = 0.0009617233566435365
Trained batch 72 in epoch 5, gen_loss = 1.1363303057134968, disc_loss = 0.000953011630559085
Trained batch 73 in epoch 5, gen_loss = 1.1391017098684568, disc_loss = 0.0009446343622560537
Trained batch 74 in epoch 5, gen_loss = 1.1382049163182577, disc_loss = 0.0009355700939583281
Trained batch 75 in epoch 5, gen_loss = 1.1364530889611495, disc_loss = 0.0009312360282484932
Trained batch 76 in epoch 5, gen_loss = 1.13600484117285, disc_loss = 0.0009349780905592654
Trained batch 77 in epoch 5, gen_loss = 1.1379033357669146, disc_loss = 0.000938113025861243
Trained batch 78 in epoch 5, gen_loss = 1.1367901850350295, disc_loss = 0.0009350706565288143
Trained batch 79 in epoch 5, gen_loss = 1.138227291405201, disc_loss = 0.0009295788353483658
Trained batch 80 in epoch 5, gen_loss = 1.1386272921974276, disc_loss = 0.0009227606412569452
Trained batch 81 in epoch 5, gen_loss = 1.1402461136259683, disc_loss = 0.0009179724889336062
Trained batch 82 in epoch 5, gen_loss = 1.1412178435957576, disc_loss = 0.000917149820934465
Trained batch 83 in epoch 5, gen_loss = 1.1414307795819782, disc_loss = 0.0009179119186315109
Trained batch 84 in epoch 5, gen_loss = 1.1391261886147892, disc_loss = 0.0009123284647049492
Trained batch 85 in epoch 5, gen_loss = 1.137906041256217, disc_loss = 0.000904117179235855
Trained batch 86 in epoch 5, gen_loss = 1.1375723118069527, disc_loss = 0.0008965901152000645
Trained batch 87 in epoch 5, gen_loss = 1.1353652782060883, disc_loss = 0.0008889775668979961
Trained batch 88 in epoch 5, gen_loss = 1.1351304730672516, disc_loss = 0.0008820463988924755
Trained batch 89 in epoch 5, gen_loss = 1.133809784385893, disc_loss = 0.0008791919186478481
Trained batch 90 in epoch 5, gen_loss = 1.1342465988882295, disc_loss = 0.0008783978080648192
Trained batch 91 in epoch 5, gen_loss = 1.1337936799163404, disc_loss = 0.0008748476118299826
Trained batch 92 in epoch 5, gen_loss = 1.1351646178512163, disc_loss = 0.0008686023475777518
Trained batch 93 in epoch 5, gen_loss = 1.1364831791279164, disc_loss = 0.0008653806026485015
Trained batch 94 in epoch 5, gen_loss = 1.1363972030187908, disc_loss = 0.0008696115633938462
Trained batch 95 in epoch 5, gen_loss = 1.1354344294716914, disc_loss = 0.0008709430218611184
Trained batch 96 in epoch 5, gen_loss = 1.136319510101043, disc_loss = 0.0008679264841346819
Trained batch 97 in epoch 5, gen_loss = 1.1344595423766546, disc_loss = 0.0008757889519649919
Trained batch 98 in epoch 5, gen_loss = 1.1348624283617192, disc_loss = 0.0009048814115683652
Trained batch 99 in epoch 5, gen_loss = 1.1363225477933883, disc_loss = 0.000923328816134017
Trained batch 100 in epoch 5, gen_loss = 1.1357571813139584, disc_loss = 0.000923968804020453
Trained batch 101 in epoch 5, gen_loss = 1.1358863448395449, disc_loss = 0.0009301891912792937
Trained batch 102 in epoch 5, gen_loss = 1.1363584827450872, disc_loss = 0.0009395489726301499
Trained batch 103 in epoch 5, gen_loss = 1.1363714904739306, disc_loss = 0.0009430700075217129
Trained batch 104 in epoch 5, gen_loss = 1.1351573245865958, disc_loss = 0.0009404712919301043
Trained batch 105 in epoch 5, gen_loss = 1.1333826600380663, disc_loss = 0.0009402292887658268
Trained batch 106 in epoch 5, gen_loss = 1.1330866100632142, disc_loss = 0.0009439723350207765
Trained batch 107 in epoch 5, gen_loss = 1.1350976173524503, disc_loss = 0.00094313663295772
Trained batch 108 in epoch 5, gen_loss = 1.1341294793907655, disc_loss = 0.0009421051520995215
Trained batch 109 in epoch 5, gen_loss = 1.1351905140009793, disc_loss = 0.0009406003738563
Trained batch 110 in epoch 5, gen_loss = 1.1359544090322546, disc_loss = 0.000936956467109036
Trained batch 111 in epoch 5, gen_loss = 1.1356670196567262, disc_loss = 0.0009361841509546918
Trained batch 112 in epoch 5, gen_loss = 1.1335160436883438, disc_loss = 0.0009390991776089588
Trained batch 113 in epoch 5, gen_loss = 1.1348185560159516, disc_loss = 0.0009385751600667279
Trained batch 114 in epoch 5, gen_loss = 1.1346187311670055, disc_loss = 0.000937385958082893
Trained batch 115 in epoch 5, gen_loss = 1.132890003508535, disc_loss = 0.0009386421706635859
Trained batch 116 in epoch 5, gen_loss = 1.1320830746593638, disc_loss = 0.0009365594847840217
Trained batch 117 in epoch 5, gen_loss = 1.130691712690612, disc_loss = 0.0009336369395773006
Trained batch 118 in epoch 5, gen_loss = 1.1304554713874304, disc_loss = 0.0009355464812755553
Trained batch 119 in epoch 5, gen_loss = 1.1308216308554013, disc_loss = 0.0009452394081260233
Trained batch 120 in epoch 5, gen_loss = 1.1311647473287976, disc_loss = 0.0009516467528383071
Trained batch 121 in epoch 5, gen_loss = 1.1330474268217556, disc_loss = 0.000956067943050465
Trained batch 122 in epoch 5, gen_loss = 1.133274804770462, disc_loss = 0.0009590567321974663
Trained batch 123 in epoch 5, gen_loss = 1.1327607761467657, disc_loss = 0.0009608187150837282
Trained batch 124 in epoch 5, gen_loss = 1.1340976414680481, disc_loss = 0.0009592325536068529
Trained batch 125 in epoch 5, gen_loss = 1.1333449288966164, disc_loss = 0.0009555348335111159
Trained batch 126 in epoch 5, gen_loss = 1.133302230065263, disc_loss = 0.0009525655720687259
Trained batch 127 in epoch 5, gen_loss = 1.133451386820525, disc_loss = 0.0009553995839723939
Trained batch 128 in epoch 5, gen_loss = 1.1323430233223493, disc_loss = 0.0009554127213642607
Trained batch 129 in epoch 5, gen_loss = 1.133551210623521, disc_loss = 0.0009569303448258255
Trained batch 130 in epoch 5, gen_loss = 1.132334203665493, disc_loss = 0.0009646314537980885
Trained batch 131 in epoch 5, gen_loss = 1.1323533622604427, disc_loss = 0.0009757365096998965
Trained batch 132 in epoch 5, gen_loss = 1.1317398498829145, disc_loss = 0.0009796074462469836
Trained batch 133 in epoch 5, gen_loss = 1.1312278282286516, disc_loss = 0.000977951600850532
Trained batch 134 in epoch 5, gen_loss = 1.131819146209293, disc_loss = 0.0009724928357172757
Trained batch 135 in epoch 5, gen_loss = 1.13354260036174, disc_loss = 0.00096736642808537
Trained batch 136 in epoch 5, gen_loss = 1.1339193708705206, disc_loss = 0.000964252233384585
Trained batch 137 in epoch 5, gen_loss = 1.1342477612737296, disc_loss = 0.000962779200273107
Trained batch 138 in epoch 5, gen_loss = 1.1345760552145594, disc_loss = 0.0009588374102592012
Trained batch 139 in epoch 5, gen_loss = 1.1328636837857111, disc_loss = 0.0009543063844570757
Trained batch 140 in epoch 5, gen_loss = 1.1320479791215126, disc_loss = 0.0009501318095156144
Trained batch 141 in epoch 5, gen_loss = 1.133043065457277, disc_loss = 0.00094581236566817
Trained batch 142 in epoch 5, gen_loss = 1.1322174468240538, disc_loss = 0.0009407543652964483
Trained batch 143 in epoch 5, gen_loss = 1.131580579198069, disc_loss = 0.0009358884797418594
Trained batch 144 in epoch 5, gen_loss = 1.1333227613876606, disc_loss = 0.0009306215582784779
Trained batch 145 in epoch 5, gen_loss = 1.1332535788620988, disc_loss = 0.0009254357673479755
Trained batch 146 in epoch 5, gen_loss = 1.1334268621035986, disc_loss = 0.0009216720099342341
Trained batch 147 in epoch 5, gen_loss = 1.133557047795605, disc_loss = 0.0009200653288201933
Trained batch 148 in epoch 5, gen_loss = 1.1330892011623255, disc_loss = 0.0009200849858247019
Trained batch 149 in epoch 5, gen_loss = 1.1317166697978973, disc_loss = 0.00091817484179046
Trained batch 150 in epoch 5, gen_loss = 1.130730850412356, disc_loss = 0.0009176756522467125
Trained batch 151 in epoch 5, gen_loss = 1.1312246059900837, disc_loss = 0.0009195406411507927
Trained batch 152 in epoch 5, gen_loss = 1.1309347437098136, disc_loss = 0.0009219505129080704
Trained batch 153 in epoch 5, gen_loss = 1.1316430680937581, disc_loss = 0.000922433719191664
Trained batch 154 in epoch 5, gen_loss = 1.131321979722669, disc_loss = 0.0009192969077341859
Trained batch 155 in epoch 5, gen_loss = 1.1324326613774667, disc_loss = 0.0009152867970465778
Trained batch 156 in epoch 5, gen_loss = 1.1319506566995268, disc_loss = 0.0009128628786175755
Trained batch 157 in epoch 5, gen_loss = 1.131829830287378, disc_loss = 0.0009121093108787354
Trained batch 158 in epoch 5, gen_loss = 1.130728525560607, disc_loss = 0.0009099225659705347
Trained batch 159 in epoch 5, gen_loss = 1.1303586039692164, disc_loss = 0.0009063703726496896
Trained batch 160 in epoch 5, gen_loss = 1.13015937249853, disc_loss = 0.0009053853267777757
Trained batch 161 in epoch 5, gen_loss = 1.1305578494513477, disc_loss = 0.0009050317103960148
Trained batch 162 in epoch 5, gen_loss = 1.1302312682011375, disc_loss = 0.0009025703296793819
Trained batch 163 in epoch 5, gen_loss = 1.130690170860872, disc_loss = 0.0009022915071066719
Trained batch 164 in epoch 5, gen_loss = 1.1308225505279772, disc_loss = 0.0009021049462414036
Trained batch 165 in epoch 5, gen_loss = 1.1323583646711097, disc_loss = 0.0008999527393803786
Trained batch 166 in epoch 5, gen_loss = 1.1332864565049816, disc_loss = 0.0008962067620672598
Trained batch 167 in epoch 5, gen_loss = 1.133882995517481, disc_loss = 0.0008926584156316018
Trained batch 168 in epoch 5, gen_loss = 1.133405629347062, disc_loss = 0.0008929983749586163
Trained batch 169 in epoch 5, gen_loss = 1.1329769937431111, disc_loss = 0.0008953875771326506
Trained batch 170 in epoch 5, gen_loss = 1.1327688376805936, disc_loss = 0.0008956803924918763
Trained batch 171 in epoch 5, gen_loss = 1.1321148293655972, disc_loss = 0.000892245335413717
Trained batch 172 in epoch 5, gen_loss = 1.13452021958511, disc_loss = 0.0008894606559696161
Trained batch 173 in epoch 5, gen_loss = 1.134047720966668, disc_loss = 0.0008909261871420982
Trained batch 174 in epoch 5, gen_loss = 1.133246534551893, disc_loss = 0.0008959083387162537
Trained batch 175 in epoch 5, gen_loss = 1.1341463832015342, disc_loss = 0.0008965405380546475
Trained batch 176 in epoch 5, gen_loss = 1.1358552696341175, disc_loss = 0.0008974714064247127
Trained batch 177 in epoch 5, gen_loss = 1.1360483259967205, disc_loss = 0.0009034572987035021
Trained batch 178 in epoch 5, gen_loss = 1.1363884893209575, disc_loss = 0.00091288922183533
Trained batch 179 in epoch 5, gen_loss = 1.1367843770318562, disc_loss = 0.0009191047466528188
Trained batch 180 in epoch 5, gen_loss = 1.1365816333017296, disc_loss = 0.0009212471811340103
Trained batch 181 in epoch 5, gen_loss = 1.1371947111009242, disc_loss = 0.0009215223568729585
Trained batch 182 in epoch 5, gen_loss = 1.1370504075060777, disc_loss = 0.0009222883946463323
Trained batch 183 in epoch 5, gen_loss = 1.1372607379503872, disc_loss = 0.0009206937144841978
Trained batch 184 in epoch 5, gen_loss = 1.1366551705308863, disc_loss = 0.0009179492603760917
Trained batch 185 in epoch 5, gen_loss = 1.1383774552934913, disc_loss = 0.0009152619052372913
Trained batch 186 in epoch 5, gen_loss = 1.138807471741967, disc_loss = 0.0009131670844203289
Trained batch 187 in epoch 5, gen_loss = 1.1384947708946593, disc_loss = 0.0009108622790007119
Trained batch 188 in epoch 5, gen_loss = 1.137874115396429, disc_loss = 0.0009076297501836307
Trained batch 189 in epoch 5, gen_loss = 1.1383730176248048, disc_loss = 0.0009051643541744469
Trained batch 190 in epoch 5, gen_loss = 1.138050436037373, disc_loss = 0.0009029144128657761
Trained batch 191 in epoch 5, gen_loss = 1.1376039624835055, disc_loss = 0.0009012916101103959
Trained batch 192 in epoch 5, gen_loss = 1.1373568411935797, disc_loss = 0.0008998326354037604
Trained batch 193 in epoch 5, gen_loss = 1.1385811644116628, disc_loss = 0.0008966499872352044
Trained batch 194 in epoch 5, gen_loss = 1.138316297225463, disc_loss = 0.0008956582685454915
Trained batch 195 in epoch 5, gen_loss = 1.1378913853241472, disc_loss = 0.0008955928942483223
Trained batch 196 in epoch 5, gen_loss = 1.1384088427282226, disc_loss = 0.0008943888455095138
Trained batch 197 in epoch 5, gen_loss = 1.1381607239294533, disc_loss = 0.000891555490935306
Trained batch 198 in epoch 5, gen_loss = 1.1384862886002316, disc_loss = 0.0008887707478958814
Trained batch 199 in epoch 5, gen_loss = 1.1377885535359382, disc_loss = 0.0008879526318924035
Trained batch 200 in epoch 5, gen_loss = 1.137408086019962, disc_loss = 0.0008877122993940089
Trained batch 201 in epoch 5, gen_loss = 1.1374761860559481, disc_loss = 0.0008861623979046811
Trained batch 202 in epoch 5, gen_loss = 1.137493429806432, disc_loss = 0.0008843907315956126
Trained batch 203 in epoch 5, gen_loss = 1.1372724879606098, disc_loss = 0.0008839475718274366
Trained batch 204 in epoch 5, gen_loss = 1.1367628833142722, disc_loss = 0.0008855815001524894
Trained batch 205 in epoch 5, gen_loss = 1.1354816194298198, disc_loss = 0.0008867388090753964
Trained batch 206 in epoch 5, gen_loss = 1.135698123542583, disc_loss = 0.0008843275563732905
Trained batch 207 in epoch 5, gen_loss = 1.136163188574406, disc_loss = 0.0008819355191987527
Trained batch 208 in epoch 5, gen_loss = 1.1365908900516455, disc_loss = 0.0008802797365989358
Trained batch 209 in epoch 5, gen_loss = 1.1371207677182698, disc_loss = 0.0008826366089384204
Trained batch 210 in epoch 5, gen_loss = 1.1373887895407835, disc_loss = 0.0008942554513118296
Trained batch 211 in epoch 5, gen_loss = 1.1376484787126757, disc_loss = 0.0009088854263986918
Trained batch 212 in epoch 5, gen_loss = 1.139013280051415, disc_loss = 0.0009118788860609291
Trained batch 213 in epoch 5, gen_loss = 1.1394336443638133, disc_loss = 0.0009110434693186413
Trained batch 214 in epoch 5, gen_loss = 1.1391233785207882, disc_loss = 0.0009095795272557109
Trained batch 215 in epoch 5, gen_loss = 1.1391064593637432, disc_loss = 0.0009078037111504711
Trained batch 216 in epoch 5, gen_loss = 1.1380453332228595, disc_loss = 0.0009069301340619557
Trained batch 217 in epoch 5, gen_loss = 1.1380047642309732, disc_loss = 0.000905000528458446
Trained batch 218 in epoch 5, gen_loss = 1.1385119492060518, disc_loss = 0.0009022084711710646
Trained batch 219 in epoch 5, gen_loss = 1.1376449416984211, disc_loss = 0.0009022124495293776
Trained batch 220 in epoch 5, gen_loss = 1.1378862728360553, disc_loss = 0.0009053407188997988
Trained batch 221 in epoch 5, gen_loss = 1.1394320468644838, disc_loss = 0.0009070834061571372
Trained batch 222 in epoch 5, gen_loss = 1.1392230415558067, disc_loss = 0.0009050365784591807
Trained batch 223 in epoch 5, gen_loss = 1.138696274054902, disc_loss = 0.0009020342521840316
Trained batch 224 in epoch 5, gen_loss = 1.1384603632820978, disc_loss = 0.000898977783573274
Trained batch 225 in epoch 5, gen_loss = 1.138683780632188, disc_loss = 0.0008966405125848941
Trained batch 226 in epoch 5, gen_loss = 1.1382921440485816, disc_loss = 0.0008954447949903151
Trained batch 227 in epoch 5, gen_loss = 1.1374583082240926, disc_loss = 0.0008975187430271609
Trained batch 228 in epoch 5, gen_loss = 1.1376684966566262, disc_loss = 0.0009063664339172682
Trained batch 229 in epoch 5, gen_loss = 1.1380201293074566, disc_loss = 0.0009180022838257213
Trained batch 230 in epoch 5, gen_loss = 1.1390521805007736, disc_loss = 0.0009207020243967468
Trained batch 231 in epoch 5, gen_loss = 1.138382503184779, disc_loss = 0.0009243930282913236
Trained batch 232 in epoch 5, gen_loss = 1.1383358572685667, disc_loss = 0.0009315423491933531
Trained batch 233 in epoch 5, gen_loss = 1.1382657493281567, disc_loss = 0.0009415979216917036
Trained batch 234 in epoch 5, gen_loss = 1.138081535887211, disc_loss = 0.0009502178210978138
Trained batch 235 in epoch 5, gen_loss = 1.1370919139708502, disc_loss = 0.0009528373059657821
Trained batch 236 in epoch 5, gen_loss = 1.1371501055447863, disc_loss = 0.0009516777584544395
Trained batch 237 in epoch 5, gen_loss = 1.1381265941788168, disc_loss = 0.0009501609704119717
Trained batch 238 in epoch 5, gen_loss = 1.1378892031673606, disc_loss = 0.0009482885071219658
Trained batch 239 in epoch 5, gen_loss = 1.1379836176832516, disc_loss = 0.0009482718950190853
Trained batch 240 in epoch 5, gen_loss = 1.1372842516641894, disc_loss = 0.0009472258359409242
Trained batch 241 in epoch 5, gen_loss = 1.1369915274549123, disc_loss = 0.0009451955422775413
Trained batch 242 in epoch 5, gen_loss = 1.1374848384425473, disc_loss = 0.0009426500370037079
Trained batch 243 in epoch 5, gen_loss = 1.137306693636003, disc_loss = 0.0009399430186857019
Trained batch 244 in epoch 5, gen_loss = 1.1367163439186252, disc_loss = 0.0009374285783804002
Trained batch 245 in epoch 5, gen_loss = 1.137521368216693, disc_loss = 0.000935341575742809
Trained batch 246 in epoch 5, gen_loss = 1.1370696418198496, disc_loss = 0.0009334158502412613
Trained batch 247 in epoch 5, gen_loss = 1.1369395265656133, disc_loss = 0.00093145413302409
Trained batch 248 in epoch 5, gen_loss = 1.1369528478407955, disc_loss = 0.0009295072534049573
Trained batch 249 in epoch 5, gen_loss = 1.1378662877082826, disc_loss = 0.0009277666375855915
Trained batch 250 in epoch 5, gen_loss = 1.137766687518572, disc_loss = 0.0009254841260919051
Trained batch 251 in epoch 5, gen_loss = 1.1375457119374048, disc_loss = 0.0009238658682974462
Trained batch 252 in epoch 5, gen_loss = 1.1378809731939565, disc_loss = 0.0009221775645805199
Trained batch 253 in epoch 5, gen_loss = 1.1381562859054626, disc_loss = 0.0009200251327234496
Trained batch 254 in epoch 5, gen_loss = 1.1376245886671776, disc_loss = 0.0009176621811039855
Trained batch 255 in epoch 5, gen_loss = 1.1369660329073668, disc_loss = 0.0009149927261091761
Trained batch 256 in epoch 5, gen_loss = 1.1368620163735712, disc_loss = 0.0009132140602690896
Trained batch 257 in epoch 5, gen_loss = 1.1365868301354638, disc_loss = 0.0009118511012458431
Trained batch 258 in epoch 5, gen_loss = 1.1362098938709981, disc_loss = 0.0009100609557306696
Trained batch 259 in epoch 5, gen_loss = 1.1358428514920749, disc_loss = 0.0009097013017498495
Trained batch 260 in epoch 5, gen_loss = 1.1363573859934606, disc_loss = 0.0009084222788661112
Trained batch 261 in epoch 5, gen_loss = 1.135945645907453, disc_loss = 0.0009056518844862909
Trained batch 262 in epoch 5, gen_loss = 1.1358623314266423, disc_loss = 0.0009033306998784119
Trained batch 263 in epoch 5, gen_loss = 1.1358203720865827, disc_loss = 0.0009007830213897361
Trained batch 264 in epoch 5, gen_loss = 1.135763108505393, disc_loss = 0.0008999349446725627
Trained batch 265 in epoch 5, gen_loss = 1.1352585809571403, disc_loss = 0.0009001304977682867
Trained batch 266 in epoch 5, gen_loss = 1.135734981811895, disc_loss = 0.0008977545859237212
Trained batch 267 in epoch 5, gen_loss = 1.1359005490345742, disc_loss = 0.000895518958388303
Trained batch 268 in epoch 5, gen_loss = 1.1361312671221766, disc_loss = 0.0008933673567657072
Trained batch 269 in epoch 5, gen_loss = 1.1358808124506916, disc_loss = 0.0008907408565627756
Trained batch 270 in epoch 5, gen_loss = 1.1354885580794838, disc_loss = 0.0008884530005000559
Trained batch 271 in epoch 5, gen_loss = 1.1350545791142128, disc_loss = 0.0008862032518663909
Trained batch 272 in epoch 5, gen_loss = 1.1356895699169174, disc_loss = 0.0008841007485245474
Trained batch 273 in epoch 5, gen_loss = 1.1359152954860325, disc_loss = 0.0008819965642696777
Trained batch 274 in epoch 5, gen_loss = 1.1368352235447277, disc_loss = 0.0008799750530372628
Trained batch 275 in epoch 5, gen_loss = 1.1371463869792828, disc_loss = 0.0008788235409419808
Trained batch 276 in epoch 5, gen_loss = 1.1369844528742215, disc_loss = 0.0008775302168403817
Trained batch 277 in epoch 5, gen_loss = 1.1364745827887555, disc_loss = 0.0008757319996508656
Trained batch 278 in epoch 5, gen_loss = 1.1365097684244956, disc_loss = 0.0008748196783946246
Trained batch 279 in epoch 5, gen_loss = 1.1365361669233867, disc_loss = 0.0008736165448291494
Trained batch 280 in epoch 5, gen_loss = 1.1359523628105896, disc_loss = 0.0008716625656544817
Trained batch 281 in epoch 5, gen_loss = 1.1352759806822377, disc_loss = 0.0008692925249751499
Trained batch 282 in epoch 5, gen_loss = 1.1347669421994644, disc_loss = 0.0008673871840208821
Trained batch 283 in epoch 5, gen_loss = 1.1349136082219407, disc_loss = 0.0008653584166969382
Trained batch 284 in epoch 5, gen_loss = 1.135600881827505, disc_loss = 0.0008634170747092483
Trained batch 285 in epoch 5, gen_loss = 1.1358561645020973, disc_loss = 0.0008614403768597248
Trained batch 286 in epoch 5, gen_loss = 1.1360314345110585, disc_loss = 0.000859457190036579
Trained batch 287 in epoch 5, gen_loss = 1.1352003800372283, disc_loss = 0.0008572870287935075
Trained batch 288 in epoch 5, gen_loss = 1.1350742508383358, disc_loss = 0.0008558852422944589
Trained batch 289 in epoch 5, gen_loss = 1.1348611054749325, disc_loss = 0.0008541474259831814
Trained batch 290 in epoch 5, gen_loss = 1.1348168362456907, disc_loss = 0.000852240372580777
Trained batch 291 in epoch 5, gen_loss = 1.1349172735050932, disc_loss = 0.0008500048845160389
Trained batch 292 in epoch 5, gen_loss = 1.1346821357772618, disc_loss = 0.00084955124982113
Trained batch 293 in epoch 5, gen_loss = 1.1350992897740837, disc_loss = 0.0008512531397971135
Trained batch 294 in epoch 5, gen_loss = 1.1347826246487893, disc_loss = 0.0008529018886462328
Trained batch 295 in epoch 5, gen_loss = 1.1344117719579387, disc_loss = 0.0008527271362942662
Trained batch 296 in epoch 5, gen_loss = 1.1355645716792406, disc_loss = 0.0008507852627474795
Trained batch 297 in epoch 5, gen_loss = 1.1354198059779685, disc_loss = 0.0008498205239911901
Trained batch 298 in epoch 5, gen_loss = 1.134916380496328, disc_loss = 0.0008513424363992579
Trained batch 299 in epoch 5, gen_loss = 1.1344671734174092, disc_loss = 0.0008526741446985397
Trained batch 300 in epoch 5, gen_loss = 1.1345178486896907, disc_loss = 0.0008527805685569251
Trained batch 301 in epoch 5, gen_loss = 1.1345958693927487, disc_loss = 0.0008511013572165181
Trained batch 302 in epoch 5, gen_loss = 1.1345475498992619, disc_loss = 0.0008502422052296493
Trained batch 303 in epoch 5, gen_loss = 1.134713090956211, disc_loss = 0.0008501472651148919
Trained batch 304 in epoch 5, gen_loss = 1.1348510155912306, disc_loss = 0.0008500520292131353
Trained batch 305 in epoch 5, gen_loss = 1.1348189672613456, disc_loss = 0.0008487267901621046
Trained batch 306 in epoch 5, gen_loss = 1.1341803535964667, disc_loss = 0.0008468437142702766
Trained batch 307 in epoch 5, gen_loss = 1.1346089983141268, disc_loss = 0.0008458601948771136
Trained batch 308 in epoch 5, gen_loss = 1.1343978828596837, disc_loss = 0.0008459034822576055
Trained batch 309 in epoch 5, gen_loss = 1.1339439670885763, disc_loss = 0.0008456317690527818
Trained batch 310 in epoch 5, gen_loss = 1.1348633714427518, disc_loss = 0.0008443827757973469
Trained batch 311 in epoch 5, gen_loss = 1.1347420297754116, disc_loss = 0.0008443183754328251
Trained batch 312 in epoch 5, gen_loss = 1.135417559466804, disc_loss = 0.0008455037900239985
Trained batch 313 in epoch 5, gen_loss = 1.135560202560607, disc_loss = 0.0008467819508232598
Trained batch 314 in epoch 5, gen_loss = 1.135052722408658, disc_loss = 0.0008456576299125566
Trained batch 315 in epoch 5, gen_loss = 1.1349786378537552, disc_loss = 0.0008462618314274262
Trained batch 316 in epoch 5, gen_loss = 1.1349343247594141, disc_loss = 0.0008483287264216156
Trained batch 317 in epoch 5, gen_loss = 1.1347831759437825, disc_loss = 0.0008469837888033399
Trained batch 318 in epoch 5, gen_loss = 1.1342757404037405, disc_loss = 0.0008469040359703964
Trained batch 319 in epoch 5, gen_loss = 1.135223406739533, disc_loss = 0.0008507673008807615
Trained batch 320 in epoch 5, gen_loss = 1.1345172619151178, disc_loss = 0.000851324533710381
Trained batch 321 in epoch 5, gen_loss = 1.1345107866370159, disc_loss = 0.0008502448763013586
Trained batch 322 in epoch 5, gen_loss = 1.1351858251973201, disc_loss = 0.0008502933281872439
Trained batch 323 in epoch 5, gen_loss = 1.134988569918974, disc_loss = 0.0008490905342181644
Trained batch 324 in epoch 5, gen_loss = 1.135956234565148, disc_loss = 0.0008484246406722097
Trained batch 325 in epoch 5, gen_loss = 1.135378149755162, disc_loss = 0.0008605168700704574
Trained batch 326 in epoch 5, gen_loss = 1.1351329769927792, disc_loss = 0.0008796517084732179
Trained batch 327 in epoch 5, gen_loss = 1.1349065609094573, disc_loss = 0.0008878574253463828
Trained batch 328 in epoch 5, gen_loss = 1.1356972079146597, disc_loss = 0.0008881701525646803
Trained batch 329 in epoch 5, gen_loss = 1.1351006963036276, disc_loss = 0.0008889095911096471
Trained batch 330 in epoch 5, gen_loss = 1.1346102012968495, disc_loss = 0.0008904110398751984
Trained batch 331 in epoch 5, gen_loss = 1.1342892427760434, disc_loss = 0.000891420866844191
Trained batch 332 in epoch 5, gen_loss = 1.1352233603909925, disc_loss = 0.0008915370867630276
Trained batch 333 in epoch 5, gen_loss = 1.135195386980822, disc_loss = 0.0008919527953296125
Trained batch 334 in epoch 5, gen_loss = 1.1346344414042002, disc_loss = 0.0008939247109680506
Trained batch 335 in epoch 5, gen_loss = 1.134809048402877, disc_loss = 0.0008948514171909968
Trained batch 336 in epoch 5, gen_loss = 1.1348724846316374, disc_loss = 0.0008958483665220534
Trained batch 337 in epoch 5, gen_loss = 1.1342484418457077, disc_loss = 0.0008963558612513279
Trained batch 338 in epoch 5, gen_loss = 1.1340284301819703, disc_loss = 0.0008992163243701484
Trained batch 339 in epoch 5, gen_loss = 1.1333878057844498, disc_loss = 0.0009033724789333064
Trained batch 340 in epoch 5, gen_loss = 1.133267483753193, disc_loss = 0.0009059596638542756
Trained batch 341 in epoch 5, gen_loss = 1.134071343823483, disc_loss = 0.0009068847448467712
Trained batch 342 in epoch 5, gen_loss = 1.134400042083451, disc_loss = 0.0009062060315936462
Trained batch 343 in epoch 5, gen_loss = 1.1344224082869152, disc_loss = 0.0009054937797986366
Trained batch 344 in epoch 5, gen_loss = 1.134926646343176, disc_loss = 0.000905140774009034
Trained batch 345 in epoch 5, gen_loss = 1.1348045030770275, disc_loss = 0.0009042028209609734
Trained batch 346 in epoch 5, gen_loss = 1.1349881822162815, disc_loss = 0.0009027373106322877
Trained batch 347 in epoch 5, gen_loss = 1.1347519710831258, disc_loss = 0.0009014692644494312
Trained batch 348 in epoch 5, gen_loss = 1.13445139682737, disc_loss = 0.0008996055977413015
Trained batch 349 in epoch 5, gen_loss = 1.1344422878537859, disc_loss = 0.0008985688458778895
Trained batch 350 in epoch 5, gen_loss = 1.1344210575109195, disc_loss = 0.0008983662979398056
Trained batch 351 in epoch 5, gen_loss = 1.1345406144180081, disc_loss = 0.0009011871259396933
Trained batch 352 in epoch 5, gen_loss = 1.1346114269397076, disc_loss = 0.0009048128186539739
Trained batch 353 in epoch 5, gen_loss = 1.1344368282684498, disc_loss = 0.0009062971406676122
Trained batch 354 in epoch 5, gen_loss = 1.1345403943263308, disc_loss = 0.000905896900147921
Trained batch 355 in epoch 5, gen_loss = 1.134770600313551, disc_loss = 0.0009050125099134532
Trained batch 356 in epoch 5, gen_loss = 1.1352420330715447, disc_loss = 0.0009054750689883855
Trained batch 357 in epoch 5, gen_loss = 1.135584102662582, disc_loss = 0.0009058311565921579
Trained batch 358 in epoch 5, gen_loss = 1.1362975121872672, disc_loss = 0.0009058721427670174
Trained batch 359 in epoch 5, gen_loss = 1.1360496504439248, disc_loss = 0.000906208842894153
Trained batch 360 in epoch 5, gen_loss = 1.1364296730865733, disc_loss = 0.0009049837103992613
Trained batch 361 in epoch 5, gen_loss = 1.1370091994823013, disc_loss = 0.000904681017416213
Trained batch 362 in epoch 5, gen_loss = 1.1375838222582477, disc_loss = 0.0009102187413749857
Trained batch 363 in epoch 5, gen_loss = 1.1372613451638065, disc_loss = 0.0009155019451809694
Trained batch 364 in epoch 5, gen_loss = 1.1381029703845718, disc_loss = 0.0009147995753988802
Trained batch 365 in epoch 5, gen_loss = 1.1380521632283112, disc_loss = 0.0009158313286072788
Trained batch 366 in epoch 5, gen_loss = 1.1382867669539491, disc_loss = 0.0009183405396291905
Trained batch 367 in epoch 5, gen_loss = 1.1376933873347614, disc_loss = 0.0009200562844062401
Trained batch 368 in epoch 5, gen_loss = 1.1382586080530472, disc_loss = 0.0009194536340535873
Trained batch 369 in epoch 5, gen_loss = 1.1382438070065266, disc_loss = 0.0009179150714378528
Trained batch 370 in epoch 5, gen_loss = 1.1380519516705825, disc_loss = 0.0009160189565150018
Trained batch 371 in epoch 5, gen_loss = 1.1379079283565603, disc_loss = 0.0009141799145186024
Trained batch 372 in epoch 5, gen_loss = 1.1381985601087679, disc_loss = 0.0009122977420112153
Trained batch 373 in epoch 5, gen_loss = 1.1385999755425886, disc_loss = 0.000910692109385839
Trained batch 374 in epoch 5, gen_loss = 1.1385537042617797, disc_loss = 0.0009088980940092976
Trained batch 375 in epoch 5, gen_loss = 1.1394655409645527, disc_loss = 0.0009068631783559388
Trained batch 376 in epoch 5, gen_loss = 1.1395648572425943, disc_loss = 0.000904834094534218
Trained batch 377 in epoch 5, gen_loss = 1.1394873778656047, disc_loss = 0.0009027955117056432
Trained batch 378 in epoch 5, gen_loss = 1.1392052201922775, disc_loss = 0.0009009193792668267
Trained batch 379 in epoch 5, gen_loss = 1.1390216843078012, disc_loss = 0.0008991490880266371
Trained batch 380 in epoch 5, gen_loss = 1.1392384535997246, disc_loss = 0.000898079750243589
Trained batch 381 in epoch 5, gen_loss = 1.1399366802570083, disc_loss = 0.0008974827144749667
Trained batch 382 in epoch 5, gen_loss = 1.1399204429073682, disc_loss = 0.0008967742865677806
Trained batch 383 in epoch 5, gen_loss = 1.1399744550387065, disc_loss = 0.0008962816019296346
Trained batch 384 in epoch 5, gen_loss = 1.1400572132754636, disc_loss = 0.0008955140812050358
Trained batch 385 in epoch 5, gen_loss = 1.139955901420178, disc_loss = 0.0008944176782707929
Trained batch 386 in epoch 5, gen_loss = 1.13998478420021, disc_loss = 0.0008934611677660219
Trained batch 387 in epoch 5, gen_loss = 1.140454695704057, disc_loss = 0.0008920529360262456
Trained batch 388 in epoch 5, gen_loss = 1.1404383056880882, disc_loss = 0.0008902565982691934
Trained batch 389 in epoch 5, gen_loss = 1.1406099041303, disc_loss = 0.0008887138934089588
Trained batch 390 in epoch 5, gen_loss = 1.1407874773835283, disc_loss = 0.0008881050836392547
Trained batch 391 in epoch 5, gen_loss = 1.1406221599603186, disc_loss = 0.0008876229099138184
Trained batch 392 in epoch 5, gen_loss = 1.1405924922637356, disc_loss = 0.0008865832702171427
Trained batch 393 in epoch 5, gen_loss = 1.1405113115528513, disc_loss = 0.0008852585634130389
Trained batch 394 in epoch 5, gen_loss = 1.1405077861834176, disc_loss = 0.0008837345641996429
Trained batch 395 in epoch 5, gen_loss = 1.140266387149541, disc_loss = 0.0008819635755810511
Trained batch 396 in epoch 5, gen_loss = 1.1401506908594512, disc_loss = 0.0008803402827375261
Trained batch 397 in epoch 5, gen_loss = 1.1406186696273, disc_loss = 0.000878873177672135
Trained batch 398 in epoch 5, gen_loss = 1.1403000710303324, disc_loss = 0.000877854260267342
Trained batch 399 in epoch 5, gen_loss = 1.1397378128767013, disc_loss = 0.000876821311430831
Trained batch 400 in epoch 5, gen_loss = 1.1395826788614516, disc_loss = 0.0008764442077392545
Trained batch 401 in epoch 5, gen_loss = 1.1394248794560409, disc_loss = 0.0008763690903422015
Trained batch 402 in epoch 5, gen_loss = 1.139917276337484, disc_loss = 0.0008755345088525076
Trained batch 403 in epoch 5, gen_loss = 1.1401568783981966, disc_loss = 0.0008747484402786964
Trained batch 404 in epoch 5, gen_loss = 1.140507627122196, disc_loss = 0.0008734290719817013
Trained batch 405 in epoch 5, gen_loss = 1.1404151323393648, disc_loss = 0.0008722410345260224
Trained batch 406 in epoch 5, gen_loss = 1.1402806743649945, disc_loss = 0.0008710090804851387
Trained batch 407 in epoch 5, gen_loss = 1.1404913126253615, disc_loss = 0.0008695878973501784
Trained batch 408 in epoch 5, gen_loss = 1.1404578531283913, disc_loss = 0.0008685914023587489
Trained batch 409 in epoch 5, gen_loss = 1.140648933445535, disc_loss = 0.0008683091702107226
Trained batch 410 in epoch 5, gen_loss = 1.1406447704691087, disc_loss = 0.0008690574241747146
Trained batch 411 in epoch 5, gen_loss = 1.1402960988213715, disc_loss = 0.0008682512119228757
Trained batch 412 in epoch 5, gen_loss = 1.1400242724949743, disc_loss = 0.0008669811825295595
Trained batch 413 in epoch 5, gen_loss = 1.1402826782873863, disc_loss = 0.0008660186939984717
Trained batch 414 in epoch 5, gen_loss = 1.1401349775762444, disc_loss = 0.0008658749251612406
Trained batch 415 in epoch 5, gen_loss = 1.1406105551868677, disc_loss = 0.0008645749246450298
Trained batch 416 in epoch 5, gen_loss = 1.140934808219937, disc_loss = 0.0008658545967445506
Trained batch 417 in epoch 5, gen_loss = 1.1410808812773399, disc_loss = 0.0008737540964477775
Trained batch 418 in epoch 5, gen_loss = 1.141141713803594, disc_loss = 0.0008787336119332269
Trained batch 419 in epoch 5, gen_loss = 1.1416110221828732, disc_loss = 0.0008803589366185147
Trained batch 420 in epoch 5, gen_loss = 1.1420891886652225, disc_loss = 0.0008812890671989428
Trained batch 421 in epoch 5, gen_loss = 1.1417367915971584, disc_loss = 0.0008814752968323364
Trained batch 422 in epoch 5, gen_loss = 1.1415837137975309, disc_loss = 0.0008826995349032849
Trained batch 423 in epoch 5, gen_loss = 1.1413977837787483, disc_loss = 0.0008846098300877339
Trained batch 424 in epoch 5, gen_loss = 1.1410663930107565, disc_loss = 0.0008872267619966913
Trained batch 425 in epoch 5, gen_loss = 1.1410417416845688, disc_loss = 0.0008891953544200949
Trained batch 426 in epoch 5, gen_loss = 1.1412550370084598, disc_loss = 0.0008897767557293085
Trained batch 427 in epoch 5, gen_loss = 1.140926180041839, disc_loss = 0.0008891770950663796
Trained batch 428 in epoch 5, gen_loss = 1.1407521260090363, disc_loss = 0.0008878850846945922
Trained batch 429 in epoch 5, gen_loss = 1.1405891673509465, disc_loss = 0.0008866043601978332
Trained batch 430 in epoch 5, gen_loss = 1.1408491925684316, disc_loss = 0.0008852886647623996
Trained batch 431 in epoch 5, gen_loss = 1.1408666499235012, disc_loss = 0.000884569688659448
Trained batch 432 in epoch 5, gen_loss = 1.1411288742655694, disc_loss = 0.0008847031674918334
Trained batch 433 in epoch 5, gen_loss = 1.140978403904471, disc_loss = 0.0008841568219793578
Trained batch 434 in epoch 5, gen_loss = 1.1411807756314332, disc_loss = 0.0008838633081043439
Trained batch 435 in epoch 5, gen_loss = 1.1412313148516033, disc_loss = 0.0008837058072508668
Trained batch 436 in epoch 5, gen_loss = 1.1411461101789497, disc_loss = 0.000882816784840676
Trained batch 437 in epoch 5, gen_loss = 1.141410001608879, disc_loss = 0.0008822475092819909
Trained batch 438 in epoch 5, gen_loss = 1.1413941190563193, disc_loss = 0.0008818617385002235
Trained batch 439 in epoch 5, gen_loss = 1.1415451765060425, disc_loss = 0.0008812043292312988
Trained batch 440 in epoch 5, gen_loss = 1.1416659438961487, disc_loss = 0.0008798688140319229
Trained batch 441 in epoch 5, gen_loss = 1.1419119033878204, disc_loss = 0.0008791613961636864
Trained batch 442 in epoch 5, gen_loss = 1.1417927421780796, disc_loss = 0.0008783061904493723
Trained batch 443 in epoch 5, gen_loss = 1.1417447513825185, disc_loss = 0.0008770362539245718
Trained batch 444 in epoch 5, gen_loss = 1.1415875903676065, disc_loss = 0.0008754550617677421
Trained batch 445 in epoch 5, gen_loss = 1.1417425240101835, disc_loss = 0.0008742848064109888
Trained batch 446 in epoch 5, gen_loss = 1.1417705986057085, disc_loss = 0.0008735531274402739
Trained batch 447 in epoch 5, gen_loss = 1.1417247208633594, disc_loss = 0.0008729208206789606
Trained batch 448 in epoch 5, gen_loss = 1.1425107085625155, disc_loss = 0.000872070724171802
Trained batch 449 in epoch 5, gen_loss = 1.1422076243824428, disc_loss = 0.0008707607548826167
Trained batch 450 in epoch 5, gen_loss = 1.1424903422924473, disc_loss = 0.0008711860252339331
Trained batch 451 in epoch 5, gen_loss = 1.1423979522907628, disc_loss = 0.0008720951807410642
Trained batch 452 in epoch 5, gen_loss = 1.1428480379891974, disc_loss = 0.000871625840662625
Trained batch 453 in epoch 5, gen_loss = 1.1426380688923572, disc_loss = 0.0008716366981965949
Trained batch 454 in epoch 5, gen_loss = 1.1424827748602564, disc_loss = 0.0008711766424412317
Trained batch 455 in epoch 5, gen_loss = 1.1425981966027043, disc_loss = 0.0008702374723310513
Trained batch 456 in epoch 5, gen_loss = 1.1433003702622795, disc_loss = 0.0008692795700707964
Trained batch 457 in epoch 5, gen_loss = 1.1430796054252892, disc_loss = 0.0008686325025369056
Trained batch 458 in epoch 5, gen_loss = 1.1434164265402003, disc_loss = 0.0008679696049377391
Trained batch 459 in epoch 5, gen_loss = 1.1431657938853554, disc_loss = 0.0008681090173131847
Trained batch 460 in epoch 5, gen_loss = 1.1431861836584427, disc_loss = 0.000869166555137923
Trained batch 461 in epoch 5, gen_loss = 1.1434810380915026, disc_loss = 0.000870875228712692
Trained batch 462 in epoch 5, gen_loss = 1.1434198762119203, disc_loss = 0.0008729031646976722
Trained batch 463 in epoch 5, gen_loss = 1.143431765509063, disc_loss = 0.0008760086836352049
Trained batch 464 in epoch 5, gen_loss = 1.1437039080486502, disc_loss = 0.000877784172189422
Trained batch 465 in epoch 5, gen_loss = 1.143691298020244, disc_loss = 0.0008774642247565255
Trained batch 466 in epoch 5, gen_loss = 1.1433282822561979, disc_loss = 0.0008763327581194235
Trained batch 467 in epoch 5, gen_loss = 1.1435353200659792, disc_loss = 0.0008758299419187253
Trained batch 468 in epoch 5, gen_loss = 1.1435542541272097, disc_loss = 0.0008754186840891254
Trained batch 469 in epoch 5, gen_loss = 1.1433219359276143, disc_loss = 0.000874768896059361
Trained batch 470 in epoch 5, gen_loss = 1.1431462914067976, disc_loss = 0.000874170969392869
Trained batch 471 in epoch 5, gen_loss = 1.143377461423308, disc_loss = 0.0008736927035697282
Trained batch 472 in epoch 5, gen_loss = 1.1433465183411289, disc_loss = 0.000872278686847398
Trained batch 473 in epoch 5, gen_loss = 1.1430971969532062, disc_loss = 0.000871022500596078
Trained batch 474 in epoch 5, gen_loss = 1.1432100868225097, disc_loss = 0.0008701239143020326
Trained batch 475 in epoch 5, gen_loss = 1.1428378435994397, disc_loss = 0.0008699318215589943
Trained batch 476 in epoch 5, gen_loss = 1.1427268583319723, disc_loss = 0.000870556629315825
Trained batch 477 in epoch 5, gen_loss = 1.1425369847020346, disc_loss = 0.0008710728965616379
Trained batch 478 in epoch 5, gen_loss = 1.1423720493446063, disc_loss = 0.0008713412328561504
Trained batch 479 in epoch 5, gen_loss = 1.1426123078912496, disc_loss = 0.000871772794835124
Trained batch 480 in epoch 5, gen_loss = 1.1423871364762035, disc_loss = 0.0008712992438595846
Trained batch 481 in epoch 5, gen_loss = 1.1420452667717123, disc_loss = 0.0008702918042583851
Trained batch 482 in epoch 5, gen_loss = 1.1420107350586364, disc_loss = 0.0008689883204770427
Trained batch 483 in epoch 5, gen_loss = 1.1417634291343453, disc_loss = 0.0008679923301931637
Trained batch 484 in epoch 5, gen_loss = 1.1416724609345505, disc_loss = 0.0008670922975144685
Trained batch 485 in epoch 5, gen_loss = 1.1418168989964474, disc_loss = 0.0008658570901995214
Trained batch 486 in epoch 5, gen_loss = 1.1420684730982145, disc_loss = 0.0008651876652212163
Trained batch 487 in epoch 5, gen_loss = 1.1417927230235005, disc_loss = 0.0008649901647302493
Trained batch 488 in epoch 5, gen_loss = 1.1416235649025026, disc_loss = 0.000863861684133451
Trained batch 489 in epoch 5, gen_loss = 1.141704330274037, disc_loss = 0.0008626404216890794
Trained batch 490 in epoch 5, gen_loss = 1.1415930281103022, disc_loss = 0.0008616044172481776
Trained batch 491 in epoch 5, gen_loss = 1.1414891327542018, disc_loss = 0.0008604138683727886
Trained batch 492 in epoch 5, gen_loss = 1.1412900805956936, disc_loss = 0.0008594355901972906
Trained batch 493 in epoch 5, gen_loss = 1.1412235147315963, disc_loss = 0.0008585041064308553
Trained batch 494 in epoch 5, gen_loss = 1.1411962953480808, disc_loss = 0.0008572385973894424
Trained batch 495 in epoch 5, gen_loss = 1.1412611453523558, disc_loss = 0.0008562127862997811
Trained batch 496 in epoch 5, gen_loss = 1.1412093575811482, disc_loss = 0.0008558405346449809
Trained batch 497 in epoch 5, gen_loss = 1.1412015647055156, disc_loss = 0.0008553652517449852
Trained batch 498 in epoch 5, gen_loss = 1.1407666329391495, disc_loss = 0.0008542543809178783
Trained batch 499 in epoch 5, gen_loss = 1.1405847519636154, disc_loss = 0.0008530281669227406
Trained batch 500 in epoch 5, gen_loss = 1.1408311553344042, disc_loss = 0.0008518536365544517
Trained batch 501 in epoch 5, gen_loss = 1.1411784356571288, disc_loss = 0.0008507578417939872
Trained batch 502 in epoch 5, gen_loss = 1.1410972144210314, disc_loss = 0.0008499419588478056
Trained batch 503 in epoch 5, gen_loss = 1.1411814052197669, disc_loss = 0.0008491683762431854
Trained batch 504 in epoch 5, gen_loss = 1.1412687085642672, disc_loss = 0.0008487036520854966
Trained batch 505 in epoch 5, gen_loss = 1.1409873951800726, disc_loss = 0.0008477875297951692
Trained batch 506 in epoch 5, gen_loss = 1.140947623483293, disc_loss = 0.0008469871482977192
Trained batch 507 in epoch 5, gen_loss = 1.1410930369078645, disc_loss = 0.0008477980442167311
Trained batch 508 in epoch 5, gen_loss = 1.1411322700719702, disc_loss = 0.0008499535263336698
Trained batch 509 in epoch 5, gen_loss = 1.141297462056665, disc_loss = 0.000851580174982219
Trained batch 510 in epoch 5, gen_loss = 1.1413811509389933, disc_loss = 0.0008517076074985929
Trained batch 511 in epoch 5, gen_loss = 1.1414174489909783, disc_loss = 0.0008507157504595853
Trained batch 512 in epoch 5, gen_loss = 1.141228025071105, disc_loss = 0.0008495950554093603
Trained batch 513 in epoch 5, gen_loss = 1.1411562502848036, disc_loss = 0.0008488987820609817
Trained batch 514 in epoch 5, gen_loss = 1.1409525226620794, disc_loss = 0.0008484712790006102
Trained batch 515 in epoch 5, gen_loss = 1.1410447378722273, disc_loss = 0.0008476914816748987
Trained batch 516 in epoch 5, gen_loss = 1.1409104424934091, disc_loss = 0.0008470449991599879
Trained batch 517 in epoch 5, gen_loss = 1.1409314469250933, disc_loss = 0.0008471639589568363
Trained batch 518 in epoch 5, gen_loss = 1.1408503072799285, disc_loss = 0.000847149240158082
Trained batch 519 in epoch 5, gen_loss = 1.140884503378318, disc_loss = 0.0008475972254438183
Trained batch 520 in epoch 5, gen_loss = 1.140479226602016, disc_loss = 0.0008511479198575134
Trained batch 521 in epoch 5, gen_loss = 1.1402004849865062, disc_loss = 0.0008549807268512431
Trained batch 522 in epoch 5, gen_loss = 1.1400096455222106, disc_loss = 0.0008561048290761719
Trained batch 523 in epoch 5, gen_loss = 1.140324492945926, disc_loss = 0.0008557230873541721
Trained batch 524 in epoch 5, gen_loss = 1.1404010096050443, disc_loss = 0.0008556901636932577
Trained batch 525 in epoch 5, gen_loss = 1.1401195770887367, disc_loss = 0.0008574021765926831
Trained batch 526 in epoch 5, gen_loss = 1.1404917222046536, disc_loss = 0.0008618836940586058
Trained batch 527 in epoch 5, gen_loss = 1.1406366364522413, disc_loss = 0.0008690173276453138
Trained batch 528 in epoch 5, gen_loss = 1.140763815048737, disc_loss = 0.0008742685772175769
Trained batch 529 in epoch 5, gen_loss = 1.1407112218299003, disc_loss = 0.0008758844774796294
Trained batch 530 in epoch 5, gen_loss = 1.1407599523242584, disc_loss = 0.0008762915359578479
Trained batch 531 in epoch 5, gen_loss = 1.1408979348222117, disc_loss = 0.0008758357752296597
Trained batch 532 in epoch 5, gen_loss = 1.1411022348207112, disc_loss = 0.0008752680196659203
Trained batch 533 in epoch 5, gen_loss = 1.1411790591054194, disc_loss = 0.000874856471111091
Trained batch 534 in epoch 5, gen_loss = 1.1411820864008966, disc_loss = 0.0008746187129736852
Trained batch 535 in epoch 5, gen_loss = 1.141129112065728, disc_loss = 0.0008740810822493939
Trained batch 536 in epoch 5, gen_loss = 1.1409163517214955, disc_loss = 0.000873390582149061
Trained batch 537 in epoch 5, gen_loss = 1.1408665446100625, disc_loss = 0.0008725458915673411
Trained batch 538 in epoch 5, gen_loss = 1.1406202358306008, disc_loss = 0.0008715928011337996
Trained batch 539 in epoch 5, gen_loss = 1.1403499484062194, disc_loss = 0.0008705597900660467
Trained batch 540 in epoch 5, gen_loss = 1.1405288181551723, disc_loss = 0.0008695844837697653
Trained batch 541 in epoch 5, gen_loss = 1.14057416141693, disc_loss = 0.0008686713427472757
Trained batch 542 in epoch 5, gen_loss = 1.1406119581085543, disc_loss = 0.0008676368037292744
Trained batch 543 in epoch 5, gen_loss = 1.1402416027644102, disc_loss = 0.0008666151140513487
Trained batch 544 in epoch 5, gen_loss = 1.1403010980798565, disc_loss = 0.0008657820377533042
Trained batch 545 in epoch 5, gen_loss = 1.1401837151565832, disc_loss = 0.0008650388035176137
Trained batch 546 in epoch 5, gen_loss = 1.1401373049894679, disc_loss = 0.0008644508843827768
Trained batch 547 in epoch 5, gen_loss = 1.140260169975949, disc_loss = 0.000863524886629082
Trained batch 548 in epoch 5, gen_loss = 1.1406342631480733, disc_loss = 0.0008624708046712564
Trained batch 549 in epoch 5, gen_loss = 1.1409774550524625, disc_loss = 0.0008617686336881228
Trained batch 550 in epoch 5, gen_loss = 1.1410819856744063, disc_loss = 0.0008613900213351071
Trained batch 551 in epoch 5, gen_loss = 1.1411094384780829, disc_loss = 0.0008609113456918419
Trained batch 552 in epoch 5, gen_loss = 1.1407388041291056, disc_loss = 0.0008600477799609014
Trained batch 553 in epoch 5, gen_loss = 1.141009432529284, disc_loss = 0.0008598714427571132
Trained batch 554 in epoch 5, gen_loss = 1.1407347348359254, disc_loss = 0.0008619016094598919
Trained batch 555 in epoch 5, gen_loss = 1.1409021131426311, disc_loss = 0.0008636269813781208
Trained batch 556 in epoch 5, gen_loss = 1.1407854308773842, disc_loss = 0.0008651262169174643
Trained batch 557 in epoch 5, gen_loss = 1.1405249679174048, disc_loss = 0.0008647323992978748
Trained batch 558 in epoch 5, gen_loss = 1.1405768312367215, disc_loss = 0.000863980831403855
Trained batch 559 in epoch 5, gen_loss = 1.1408248576734747, disc_loss = 0.0008633066650093367
Trained batch 560 in epoch 5, gen_loss = 1.1408605487376398, disc_loss = 0.0008623815146702343
Trained batch 561 in epoch 5, gen_loss = 1.1409484471502678, disc_loss = 0.000861993398870759
Trained batch 562 in epoch 5, gen_loss = 1.1409184205383855, disc_loss = 0.0008613405837392068
Trained batch 563 in epoch 5, gen_loss = 1.1409747793953469, disc_loss = 0.0008604101552764211
Trained batch 564 in epoch 5, gen_loss = 1.1409087855204016, disc_loss = 0.0008597956814255104
Trained batch 565 in epoch 5, gen_loss = 1.1408498677895684, disc_loss = 0.0008591296758141547
Trained batch 566 in epoch 5, gen_loss = 1.1407823744484566, disc_loss = 0.0008585590247998615
Trained batch 567 in epoch 5, gen_loss = 1.140588782517843, disc_loss = 0.0008590825150157555
Trained batch 568 in epoch 5, gen_loss = 1.1409881092961518, disc_loss = 0.0008595311525339172
Trained batch 569 in epoch 5, gen_loss = 1.1409884412037699, disc_loss = 0.0008589549301081876
Trained batch 570 in epoch 5, gen_loss = 1.14060231046376, disc_loss = 0.0008605335082800899
Trained batch 571 in epoch 5, gen_loss = 1.1407300808004566, disc_loss = 0.0008619290580049034
Trained batch 572 in epoch 5, gen_loss = 1.140870542322362, disc_loss = 0.0008634194276311043
Trained batch 573 in epoch 5, gen_loss = 1.140776327366613, disc_loss = 0.0008657966381549764
Trained batch 574 in epoch 5, gen_loss = 1.1407369090163189, disc_loss = 0.0008676236896755417
Trained batch 575 in epoch 5, gen_loss = 1.1410824657521315, disc_loss = 0.0008692740996391674
Trained batch 576 in epoch 5, gen_loss = 1.1412003258278713, disc_loss = 0.000870937840503429
Trained batch 577 in epoch 5, gen_loss = 1.1411250552297876, disc_loss = 0.0008731345619597862
Trained batch 578 in epoch 5, gen_loss = 1.1413322276402014, disc_loss = 0.0008739155356990196
Trained batch 579 in epoch 5, gen_loss = 1.140935561471972, disc_loss = 0.0008734826590155316
Trained batch 580 in epoch 5, gen_loss = 1.1407427195837905, disc_loss = 0.000872729550534138
Trained batch 581 in epoch 5, gen_loss = 1.1405587904027237, disc_loss = 0.0008720527137021607
Trained batch 582 in epoch 5, gen_loss = 1.140633629791528, disc_loss = 0.0008712939585169289
Trained batch 583 in epoch 5, gen_loss = 1.140827510148695, disc_loss = 0.0008704038947854153
Trained batch 584 in epoch 5, gen_loss = 1.1409654952522017, disc_loss = 0.0008692085882748326
Trained batch 585 in epoch 5, gen_loss = 1.1406940179066447, disc_loss = 0.0008682726602087516
Trained batch 586 in epoch 5, gen_loss = 1.1409885190820774, disc_loss = 0.00086779453943593
Trained batch 587 in epoch 5, gen_loss = 1.1411457968001464, disc_loss = 0.0008680647943718486
Trained batch 588 in epoch 5, gen_loss = 1.1410140337482575, disc_loss = 0.0008688734369771476
Trained batch 589 in epoch 5, gen_loss = 1.1411534622564155, disc_loss = 0.0008687066411504806
Trained batch 590 in epoch 5, gen_loss = 1.1412831050692072, disc_loss = 0.0008678232352056284
Trained batch 591 in epoch 5, gen_loss = 1.1413519599953212, disc_loss = 0.0008669292293799683
Trained batch 592 in epoch 5, gen_loss = 1.1414775536796093, disc_loss = 0.0008660245162704221
Trained batch 593 in epoch 5, gen_loss = 1.1414212476123462, disc_loss = 0.0008648714307979414
Trained batch 594 in epoch 5, gen_loss = 1.1410045754007931, disc_loss = 0.0008637577883249634
Trained batch 595 in epoch 5, gen_loss = 1.1410082934686803, disc_loss = 0.0008629649496561498
Trained batch 596 in epoch 5, gen_loss = 1.1413342880843274, disc_loss = 0.0008620830837085724
Trained batch 597 in epoch 5, gen_loss = 1.1414051986857003, disc_loss = 0.000861022923211606
Trained batch 598 in epoch 5, gen_loss = 1.1417693807207085, disc_loss = 0.0008605351039309145
Trained batch 599 in epoch 5, gen_loss = 1.1413854412237803, disc_loss = 0.0008614440832510203
Trained batch 600 in epoch 5, gen_loss = 1.141466332156329, disc_loss = 0.0008635256197464307
Trained batch 601 in epoch 5, gen_loss = 1.1411380183657143, disc_loss = 0.0008675892793786545
Trained batch 602 in epoch 5, gen_loss = 1.14109892651414, disc_loss = 0.0008719447114963199
Trained batch 603 in epoch 5, gen_loss = 1.1411487312111634, disc_loss = 0.000874282092923593
Trained batch 604 in epoch 5, gen_loss = 1.1410199504253293, disc_loss = 0.0008747803645491339
Trained batch 605 in epoch 5, gen_loss = 1.1410550270536945, disc_loss = 0.0008744998484580599
Trained batch 606 in epoch 5, gen_loss = 1.1412904437330644, disc_loss = 0.0008737544526119334
Trained batch 607 in epoch 5, gen_loss = 1.1414148744783903, disc_loss = 0.0008729686259549022
Trained batch 608 in epoch 5, gen_loss = 1.1414252022412805, disc_loss = 0.0008723675657347783
Trained batch 609 in epoch 5, gen_loss = 1.1412181402816146, disc_loss = 0.0008718099176729114
Trained batch 610 in epoch 5, gen_loss = 1.1410236645447251, disc_loss = 0.0008710086688011771
Trained batch 611 in epoch 5, gen_loss = 1.1411532356458551, disc_loss = 0.0008700303973265226
Trained batch 612 in epoch 5, gen_loss = 1.1410014248205438, disc_loss = 0.0008691645999692402
Trained batch 613 in epoch 5, gen_loss = 1.1406648603635037, disc_loss = 0.0008685321056544523
Trained batch 614 in epoch 5, gen_loss = 1.1404948926553493, disc_loss = 0.0008684952172395826
Trained batch 615 in epoch 5, gen_loss = 1.1407256569568214, disc_loss = 0.0008685740920956557
Trained batch 616 in epoch 5, gen_loss = 1.1405890507674874, disc_loss = 0.0008680059152987003
Trained batch 617 in epoch 5, gen_loss = 1.1404330030228327, disc_loss = 0.0008679911789578886
Trained batch 618 in epoch 5, gen_loss = 1.1405927470504564, disc_loss = 0.0008684155845633589
Trained batch 619 in epoch 5, gen_loss = 1.1405371888991325, disc_loss = 0.0008684166952838085
Trained batch 620 in epoch 5, gen_loss = 1.14069615105308, disc_loss = 0.0008680849718655446
Trained batch 621 in epoch 5, gen_loss = 1.1414345134876165, disc_loss = 0.000868379408837082
Trained batch 622 in epoch 5, gen_loss = 1.1415105795975098, disc_loss = 0.0008688743790694966
Trained batch 623 in epoch 5, gen_loss = 1.1412739900824351, disc_loss = 0.0008690719414516934
Trained batch 624 in epoch 5, gen_loss = 1.1413128356933593, disc_loss = 0.0008690215056529269
Trained batch 625 in epoch 5, gen_loss = 1.1410468517781827, disc_loss = 0.0008690424634992835
Trained batch 626 in epoch 5, gen_loss = 1.1408694940700865, disc_loss = 0.0008688050967578418
Trained batch 627 in epoch 5, gen_loss = 1.140853143231884, disc_loss = 0.0008680222802867766
Trained batch 628 in epoch 5, gen_loss = 1.1410247102640392, disc_loss = 0.0008676385807326147
Trained batch 629 in epoch 5, gen_loss = 1.1411626533856467, disc_loss = 0.0008672085042538432
Trained batch 630 in epoch 5, gen_loss = 1.1411432923303353, disc_loss = 0.0008664374499094323
Trained batch 631 in epoch 5, gen_loss = 1.1410029287202448, disc_loss = 0.0008656292822614646
Trained batch 632 in epoch 5, gen_loss = 1.1409599133200743, disc_loss = 0.0008649764856587328
Trained batch 633 in epoch 5, gen_loss = 1.1411093729151536, disc_loss = 0.0008646862051673366
Trained batch 634 in epoch 5, gen_loss = 1.141547812063863, disc_loss = 0.0008649321232865543
Trained batch 635 in epoch 5, gen_loss = 1.1413829926424806, disc_loss = 0.0008652024842594068
Trained batch 636 in epoch 5, gen_loss = 1.1410067607319712, disc_loss = 0.0008649472302797044
Trained batch 637 in epoch 5, gen_loss = 1.1407774231837462, disc_loss = 0.0008642991309225352
Trained batch 638 in epoch 5, gen_loss = 1.140691937881643, disc_loss = 0.0008650725106980159
Trained batch 639 in epoch 5, gen_loss = 1.1405851998366416, disc_loss = 0.0008661336206614578
Trained batch 640 in epoch 5, gen_loss = 1.1408787598476022, disc_loss = 0.0008667630265191177
Trained batch 641 in epoch 5, gen_loss = 1.1407793261737467, disc_loss = 0.0008668810846742803
Trained batch 642 in epoch 5, gen_loss = 1.1408869212559927, disc_loss = 0.0008667179953510052
Trained batch 643 in epoch 5, gen_loss = 1.140715976401886, disc_loss = 0.0008672748872244179
Trained batch 644 in epoch 5, gen_loss = 1.1405272584552912, disc_loss = 0.0008679387464897361
Trained batch 645 in epoch 5, gen_loss = 1.1403717519513594, disc_loss = 0.0008674333098961902
Trained batch 646 in epoch 5, gen_loss = 1.1404486989495928, disc_loss = 0.0008668710912948105
Trained batch 647 in epoch 5, gen_loss = 1.1400894678117317, disc_loss = 0.0008663462323719064
Trained batch 648 in epoch 5, gen_loss = 1.140228852560781, disc_loss = 0.000865503838641866
Trained batch 649 in epoch 5, gen_loss = 1.1400950931585752, disc_loss = 0.0008645797796466817
Trained batch 650 in epoch 5, gen_loss = 1.1400742524413652, disc_loss = 0.0008635330448700001
Trained batch 651 in epoch 5, gen_loss = 1.1399828222083168, disc_loss = 0.0008624481961305719
Trained batch 652 in epoch 5, gen_loss = 1.1402625918023255, disc_loss = 0.0008614298066448429
Trained batch 653 in epoch 5, gen_loss = 1.1403561142424194, disc_loss = 0.0008604890009929819
Trained batch 654 in epoch 5, gen_loss = 1.140188723029071, disc_loss = 0.0008595752010152157
Trained batch 655 in epoch 5, gen_loss = 1.1399982974114942, disc_loss = 0.000858989599691995
Trained batch 656 in epoch 5, gen_loss = 1.139891449084202, disc_loss = 0.0008586245407380484
Trained batch 657 in epoch 5, gen_loss = 1.1400988680794608, disc_loss = 0.0008579418460577004
Trained batch 658 in epoch 5, gen_loss = 1.1401881492373072, disc_loss = 0.0008570337280967062
Trained batch 659 in epoch 5, gen_loss = 1.1403073822910135, disc_loss = 0.0008560442378714497
Trained batch 660 in epoch 5, gen_loss = 1.14015225915072, disc_loss = 0.0008552368518654412
Trained batch 661 in epoch 5, gen_loss = 1.1403405609627866, disc_loss = 0.0008548804967190432
Trained batch 662 in epoch 5, gen_loss = 1.1400912105587633, disc_loss = 0.0008546159242788684
Trained batch 663 in epoch 5, gen_loss = 1.140091890581401, disc_loss = 0.0008541146165164292
Trained batch 664 in epoch 5, gen_loss = 1.1398635436717728, disc_loss = 0.000853349745235952
Trained batch 665 in epoch 5, gen_loss = 1.1401988947176718, disc_loss = 0.0008527134734497115
Trained batch 666 in epoch 5, gen_loss = 1.1404281126326885, disc_loss = 0.0008523987007379389
Trained batch 667 in epoch 5, gen_loss = 1.140252161793366, disc_loss = 0.0008524699280783325
Trained batch 668 in epoch 5, gen_loss = 1.1400526513433242, disc_loss = 0.0008520711409681517
Trained batch 669 in epoch 5, gen_loss = 1.140212067472401, disc_loss = 0.0008512896573589767
Trained batch 670 in epoch 5, gen_loss = 1.1403614910633126, disc_loss = 0.0008511375741043854
Trained batch 671 in epoch 5, gen_loss = 1.1406132810349976, disc_loss = 0.0008509822544813991
Trained batch 672 in epoch 5, gen_loss = 1.1404719399661933, disc_loss = 0.0008510609970950102
Trained batch 673 in epoch 5, gen_loss = 1.140196373183225, disc_loss = 0.0008510076729534125
Trained batch 674 in epoch 5, gen_loss = 1.1399817756370263, disc_loss = 0.0008505256805370596
Trained batch 675 in epoch 5, gen_loss = 1.1397293947152132, disc_loss = 0.0008497800997338883
Trained batch 676 in epoch 5, gen_loss = 1.1397631404318873, disc_loss = 0.0008489691597202165
Trained batch 677 in epoch 5, gen_loss = 1.1396152748119164, disc_loss = 0.0008485034198692868
Trained batch 678 in epoch 5, gen_loss = 1.1395520647776496, disc_loss = 0.0008485899392773627
Trained batch 679 in epoch 5, gen_loss = 1.1395586425767226, disc_loss = 0.0008487790823196787
Trained batch 680 in epoch 5, gen_loss = 1.1396454122798207, disc_loss = 0.000849323161583149
Trained batch 681 in epoch 5, gen_loss = 1.139370173827644, disc_loss = 0.0008503368020112643
Trained batch 682 in epoch 5, gen_loss = 1.1391266599232073, disc_loss = 0.0008507173237267072
Trained batch 683 in epoch 5, gen_loss = 1.139180299569989, disc_loss = 0.000850270536925803
Trained batch 684 in epoch 5, gen_loss = 1.1390445520407961, disc_loss = 0.0008498540579173102
Trained batch 685 in epoch 5, gen_loss = 1.138634736527507, disc_loss = 0.0008718668609498131
Trained batch 686 in epoch 5, gen_loss = 1.1377732036242145, disc_loss = 0.0017864884658226217
Trained batch 687 in epoch 5, gen_loss = 1.137727423722661, disc_loss = 0.0024194622172767277
Trained batch 688 in epoch 5, gen_loss = 1.1379960402521927, disc_loss = 0.0033492074886052052
Trained batch 689 in epoch 5, gen_loss = 1.1382544138293336, disc_loss = 0.004555247665616596
Trained batch 690 in epoch 5, gen_loss = 1.1379830531894557, disc_loss = 0.005142899875313633
Trained batch 691 in epoch 5, gen_loss = 1.1378187914459692, disc_loss = 0.0055888346486600085
Trained batch 692 in epoch 5, gen_loss = 1.1375344341451472, disc_loss = 0.005774892088094515
Trained batch 693 in epoch 5, gen_loss = 1.1377405137768397, disc_loss = 0.005873921073263448
Trained batch 694 in epoch 5, gen_loss = 1.138027943638589, disc_loss = 0.005943864504509378
Trained batch 695 in epoch 5, gen_loss = 1.1378446889334712, disc_loss = 0.006024263687730377
Trained batch 696 in epoch 5, gen_loss = 1.1381084677820739, disc_loss = 0.006163418416868009
Trained batch 697 in epoch 5, gen_loss = 1.1381033793903013, disc_loss = 0.0062082143867414055
Trained batch 698 in epoch 5, gen_loss = 1.138035113207772, disc_loss = 0.006251072701209462
Trained batch 699 in epoch 5, gen_loss = 1.1382710313796998, disc_loss = 0.00627498425104672
Trained batch 700 in epoch 5, gen_loss = 1.1381978429163064, disc_loss = 0.006340623535246578
Trained batch 701 in epoch 5, gen_loss = 1.1379892333620294, disc_loss = 0.006377368847952467
Trained batch 702 in epoch 5, gen_loss = 1.1382455242477134, disc_loss = 0.006408749769179642
Trained batch 703 in epoch 5, gen_loss = 1.1387399824505502, disc_loss = 0.006440868276699389
Trained batch 704 in epoch 5, gen_loss = 1.1390343618731127, disc_loss = 0.006445495460239398
Trained batch 705 in epoch 5, gen_loss = 1.1390160862514722, disc_loss = 0.006460871593239314
Trained batch 706 in epoch 5, gen_loss = 1.1388652887843453, disc_loss = 0.006463886488528225
Trained batch 707 in epoch 5, gen_loss = 1.138970486188339, disc_loss = 0.006472578600689796
Trained batch 708 in epoch 5, gen_loss = 1.1391879501732851, disc_loss = 0.006473529720958881
Trained batch 709 in epoch 5, gen_loss = 1.1391278433128142, disc_loss = 0.006488391877300414
Trained batch 710 in epoch 5, gen_loss = 1.1396281269867545, disc_loss = 0.006496880803020303
Trained batch 711 in epoch 5, gen_loss = 1.1395788132474665, disc_loss = 0.006497894032088042
Trained batch 712 in epoch 5, gen_loss = 1.1397896679052966, disc_loss = 0.006497904454815256
Trained batch 713 in epoch 5, gen_loss = 1.139949813109486, disc_loss = 0.006495485678632288
Trained batch 714 in epoch 5, gen_loss = 1.139858921757945, disc_loss = 0.006494260978192202
Trained batch 715 in epoch 5, gen_loss = 1.1395811717436966, disc_loss = 0.006489870939980158
Trained batch 716 in epoch 5, gen_loss = 1.1396065741735855, disc_loss = 0.006486643009889394
Trained batch 717 in epoch 5, gen_loss = 1.1393826461103966, disc_loss = 0.006490801854327763
Trained batch 718 in epoch 5, gen_loss = 1.1394629476796603, disc_loss = 0.006502678846071412
Trained batch 719 in epoch 5, gen_loss = 1.1394127789470885, disc_loss = 0.0065008768879124545
Trained batch 720 in epoch 5, gen_loss = 1.1393628950423242, disc_loss = 0.00649643353446585
Trained batch 721 in epoch 5, gen_loss = 1.139557805087758, disc_loss = 0.006495705662799742
Trained batch 722 in epoch 5, gen_loss = 1.1396352395642018, disc_loss = 0.006493975781552387
Trained batch 723 in epoch 5, gen_loss = 1.1394845530473066, disc_loss = 0.006489138409900717
Trained batch 724 in epoch 5, gen_loss = 1.1401166488384378, disc_loss = 0.006486349456787013
Trained batch 725 in epoch 5, gen_loss = 1.140343570183788, disc_loss = 0.0064809053963136515
Trained batch 726 in epoch 5, gen_loss = 1.1404070444251353, disc_loss = 0.006475632323245672
Trained batch 727 in epoch 5, gen_loss = 1.1404370216877906, disc_loss = 0.006469317798501624
Trained batch 728 in epoch 5, gen_loss = 1.140395752523498, disc_loss = 0.0064641002980860935
Trained batch 729 in epoch 5, gen_loss = 1.1402743973144114, disc_loss = 0.006458891799600878
Trained batch 730 in epoch 5, gen_loss = 1.1399795106432506, disc_loss = 0.0064580283657765195
Trained batch 731 in epoch 5, gen_loss = 1.140200661912642, disc_loss = 0.006459398288919897
Trained batch 732 in epoch 5, gen_loss = 1.1401529203983478, disc_loss = 0.006454167277956386
Trained batch 733 in epoch 5, gen_loss = 1.1402583751594013, disc_loss = 0.006449983323222738
Trained batch 734 in epoch 5, gen_loss = 1.1402350583854988, disc_loss = 0.006445865804700935
Trained batch 735 in epoch 5, gen_loss = 1.1399385277181864, disc_loss = 0.006444849220928439
Trained batch 736 in epoch 5, gen_loss = 1.1396880003458123, disc_loss = 0.0064460868599738996
Trained batch 737 in epoch 5, gen_loss = 1.1395421342313452, disc_loss = 0.00645346462570505
Trained batch 738 in epoch 5, gen_loss = 1.139699506904824, disc_loss = 0.00644969577007944
Trained batch 739 in epoch 5, gen_loss = 1.140015914391827, disc_loss = 0.00644819836057109
Trained batch 740 in epoch 5, gen_loss = 1.1404598921577618, disc_loss = 0.006445439802876274
Trained batch 741 in epoch 5, gen_loss = 1.1406386898694976, disc_loss = 0.006440704144262728
Trained batch 742 in epoch 5, gen_loss = 1.1406730279466826, disc_loss = 0.0064344443969372445
Trained batch 743 in epoch 5, gen_loss = 1.140683605706179, disc_loss = 0.0064279158515844715
Trained batch 744 in epoch 5, gen_loss = 1.1407484549804021, disc_loss = 0.006420722544672211
Trained batch 745 in epoch 5, gen_loss = 1.1408852131852516, disc_loss = 0.006414847210897464
Trained batch 746 in epoch 5, gen_loss = 1.140792695952547, disc_loss = 0.006410409351926916
Trained batch 747 in epoch 5, gen_loss = 1.1407718356439773, disc_loss = 0.006404815377038934
Trained batch 748 in epoch 5, gen_loss = 1.1407741425193358, disc_loss = 0.006399845410930583
Trained batch 749 in epoch 5, gen_loss = 1.1408379288514454, disc_loss = 0.006394343185490773
Trained batch 750 in epoch 5, gen_loss = 1.14082228780269, disc_loss = 0.006389087283015456
Trained batch 751 in epoch 5, gen_loss = 1.140884027598386, disc_loss = 0.006385157122206286
Trained batch 752 in epoch 5, gen_loss = 1.140851511977425, disc_loss = 0.00638202652991066
Trained batch 753 in epoch 5, gen_loss = 1.1408486025561073, disc_loss = 0.006375872328033979
Trained batch 754 in epoch 5, gen_loss = 1.1407728800710464, disc_loss = 0.006368734951178075
Trained batch 755 in epoch 5, gen_loss = 1.140682330128377, disc_loss = 0.0063642468284385925
Trained batch 756 in epoch 5, gen_loss = 1.140802205553773, disc_loss = 0.0063583650924008564
Trained batch 757 in epoch 5, gen_loss = 1.1410325689334668, disc_loss = 0.006356031643378021
Trained batch 758 in epoch 5, gen_loss = 1.1410204006435058, disc_loss = 0.006353307091690047
Trained batch 759 in epoch 5, gen_loss = 1.141410450323632, disc_loss = 0.0063470232567947515
Trained batch 760 in epoch 5, gen_loss = 1.141327679157257, disc_loss = 0.006347622183698741
Trained batch 761 in epoch 5, gen_loss = 1.1413892575605649, disc_loss = 0.006346232110908374
Trained batch 762 in epoch 5, gen_loss = 1.1412708594477192, disc_loss = 0.006339750169453072
Trained batch 763 in epoch 5, gen_loss = 1.141128226646578, disc_loss = 0.006333523502404081
Trained batch 764 in epoch 5, gen_loss = 1.1414005317719154, disc_loss = 0.006330688048121398
Trained batch 765 in epoch 5, gen_loss = 1.141481788989458, disc_loss = 0.00632778043711972
Trained batch 766 in epoch 5, gen_loss = 1.1416664460025523, disc_loss = 0.006322846654988491
Trained batch 767 in epoch 5, gen_loss = 1.1419063492212445, disc_loss = 0.006318095687618097
Trained batch 768 in epoch 5, gen_loss = 1.1421403857759445, disc_loss = 0.00631483160534959
Trained batch 769 in epoch 5, gen_loss = 1.142293778565023, disc_loss = 0.006308331034337503
Trained batch 770 in epoch 5, gen_loss = 1.1422038205866685, disc_loss = 0.0063038520484502295
Trained batch 771 in epoch 5, gen_loss = 1.1421681797720609, disc_loss = 0.006299519314346359
Trained batch 772 in epoch 5, gen_loss = 1.1424081967842379, disc_loss = 0.00629274706627085
Trained batch 773 in epoch 5, gen_loss = 1.142374534708585, disc_loss = 0.006295311819490205
Trained batch 774 in epoch 5, gen_loss = 1.1421666701378361, disc_loss = 0.006299046000499548
Trained batch 775 in epoch 5, gen_loss = 1.1418693802252258, disc_loss = 0.006294060167326194
Trained batch 776 in epoch 5, gen_loss = 1.141715942585944, disc_loss = 0.006290171035398979
Trained batch 777 in epoch 5, gen_loss = 1.1419442656873737, disc_loss = 0.006287550292811135
Trained batch 778 in epoch 5, gen_loss = 1.1419292803906353, disc_loss = 0.006282071168215399
Trained batch 779 in epoch 5, gen_loss = 1.141777604436263, disc_loss = 0.006277458489822516
Trained batch 780 in epoch 5, gen_loss = 1.141665425785983, disc_loss = 0.006273299669188796
Trained batch 781 in epoch 5, gen_loss = 1.141609282825914, disc_loss = 0.006266947829226643
Trained batch 782 in epoch 5, gen_loss = 1.1417833020860664, disc_loss = 0.006260851942812923
Trained batch 783 in epoch 5, gen_loss = 1.1417175523024432, disc_loss = 0.006262662554370169
Trained batch 784 in epoch 5, gen_loss = 1.1416254196197364, disc_loss = 0.006261180708971569
Trained batch 785 in epoch 5, gen_loss = 1.1413595421623637, disc_loss = 0.006257847265424663
Trained batch 786 in epoch 5, gen_loss = 1.1414843671961086, disc_loss = 0.006253618487187844
Trained batch 787 in epoch 5, gen_loss = 1.1414587325251042, disc_loss = 0.006248820720475816
Trained batch 788 in epoch 5, gen_loss = 1.141247914015718, disc_loss = 0.006245896713847279
Trained batch 789 in epoch 5, gen_loss = 1.1413557890095287, disc_loss = 0.006240106108867345
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 1.0613157749176025, disc_loss = 0.0014288837555795908
Trained batch 1 in epoch 6, gen_loss = 1.1822128295898438, disc_loss = 0.0013545399997383356
Trained batch 2 in epoch 6, gen_loss = 1.227943738301595, disc_loss = 0.002212299189219872
Trained batch 3 in epoch 6, gen_loss = 1.1999733448028564, disc_loss = 0.0026728020748123527
Trained batch 4 in epoch 6, gen_loss = 1.1979477882385254, disc_loss = 0.002426426764577627
Trained batch 5 in epoch 6, gen_loss = 1.168631414572398, disc_loss = 0.003568195349847277
Trained batch 6 in epoch 6, gen_loss = 1.1497053418840681, disc_loss = 0.003928462109927621
Trained batch 7 in epoch 6, gen_loss = 1.144820898771286, disc_loss = 0.0038845957606099546
Trained batch 8 in epoch 6, gen_loss = 1.1449372238583035, disc_loss = 0.0037341586883283323
Trained batch 9 in epoch 6, gen_loss = 1.1774927616119384, disc_loss = 0.003505169157870114
Trained batch 10 in epoch 6, gen_loss = 1.1950421333312988, disc_loss = 0.0032785059355030007
Trained batch 11 in epoch 6, gen_loss = 1.203329583009084, disc_loss = 0.0030922565783839673
Trained batch 12 in epoch 6, gen_loss = 1.1930639560406024, disc_loss = 0.003066784030614564
Trained batch 13 in epoch 6, gen_loss = 1.1988985879080636, disc_loss = 0.0030472276017202865
Trained batch 14 in epoch 6, gen_loss = 1.190045181910197, disc_loss = 0.0029182960822557408
Trained batch 15 in epoch 6, gen_loss = 1.1885408088564873, disc_loss = 0.002775796539935982
Trained batch 16 in epoch 6, gen_loss = 1.1817171082777136, disc_loss = 0.00274333157508141
Trained batch 17 in epoch 6, gen_loss = 1.1793805890613132, disc_loss = 0.002775367773008636
Trained batch 18 in epoch 6, gen_loss = 1.193028588044016, disc_loss = 0.002729960708070154
Trained batch 19 in epoch 6, gen_loss = 1.1991361677646637, disc_loss = 0.002632702307892032
Trained batch 20 in epoch 6, gen_loss = 1.1944243226732527, disc_loss = 0.0026178647170863336
Trained batch 21 in epoch 6, gen_loss = 1.197560039433566, disc_loss = 0.0025934425463095645
Trained batch 22 in epoch 6, gen_loss = 1.1889390789944192, disc_loss = 0.0026636517874937017
Trained batch 23 in epoch 6, gen_loss = 1.1904189984003704, disc_loss = 0.0026736380944688185
Trained batch 24 in epoch 6, gen_loss = 1.1927727413177491, disc_loss = 0.0026437741634435952
Trained batch 25 in epoch 6, gen_loss = 1.188455526645367, disc_loss = 0.002667772863507987
Trained batch 26 in epoch 6, gen_loss = 1.1837668816248577, disc_loss = 0.002635265435350852
Trained batch 27 in epoch 6, gen_loss = 1.1847679487296514, disc_loss = 0.0025786059039611636
Trained batch 28 in epoch 6, gen_loss = 1.1828460076759602, disc_loss = 0.0025589324851070755
Trained batch 29 in epoch 6, gen_loss = 1.1812918583552043, disc_loss = 0.0025610261499726525
Trained batch 30 in epoch 6, gen_loss = 1.1787409167135916, disc_loss = 0.0025066768134673757
Trained batch 31 in epoch 6, gen_loss = 1.1806225515902042, disc_loss = 0.002469035371177597
Trained batch 32 in epoch 6, gen_loss = 1.1790337959925334, disc_loss = 0.0024309470000761476
Trained batch 33 in epoch 6, gen_loss = 1.1753461536239176, disc_loss = 0.0024056584156556603
Trained batch 34 in epoch 6, gen_loss = 1.1732850176947458, disc_loss = 0.002390408273121076
Trained batch 35 in epoch 6, gen_loss = 1.1745497186978657, disc_loss = 0.002348794993142494
Trained batch 36 in epoch 6, gen_loss = 1.177631275073902, disc_loss = 0.0023242843972921773
Trained batch 37 in epoch 6, gen_loss = 1.174641656248193, disc_loss = 0.0022972403002265644
Trained batch 38 in epoch 6, gen_loss = 1.1758565566478631, disc_loss = 0.0022533638910271036
Trained batch 39 in epoch 6, gen_loss = 1.1746277064085007, disc_loss = 0.0022366678400430827
Trained batch 40 in epoch 6, gen_loss = 1.1733465834361752, disc_loss = 0.00220425674839445
Trained batch 41 in epoch 6, gen_loss = 1.1701227653594244, disc_loss = 0.0021700675660256473
Trained batch 42 in epoch 6, gen_loss = 1.1696293686711512, disc_loss = 0.002159856284188843
Trained batch 43 in epoch 6, gen_loss = 1.1644902500239285, disc_loss = 0.002157542994775047
Trained batch 44 in epoch 6, gen_loss = 1.1603475266032748, disc_loss = 0.0021347367747997243
Trained batch 45 in epoch 6, gen_loss = 1.1612306172433107, disc_loss = 0.0021116308786946793
Trained batch 46 in epoch 6, gen_loss = 1.1631916063897154, disc_loss = 0.002104242726110239
Trained batch 47 in epoch 6, gen_loss = 1.1666395800809066, disc_loss = 0.0020773234233881035
Trained batch 48 in epoch 6, gen_loss = 1.1692643104767313, disc_loss = 0.002114893564460229
Trained batch 49 in epoch 6, gen_loss = 1.1698486697673798, disc_loss = 0.0022205824125558138
Trained batch 50 in epoch 6, gen_loss = 1.172221893189, disc_loss = 0.0023148437030613422
Trained batch 51 in epoch 6, gen_loss = 1.1761880688942397, disc_loss = 0.002297213395090344
Trained batch 52 in epoch 6, gen_loss = 1.175490657113633, disc_loss = 0.002299500352544886
Trained batch 53 in epoch 6, gen_loss = 1.1720441921993539, disc_loss = 0.002312808401054806
Trained batch 54 in epoch 6, gen_loss = 1.1707135384733027, disc_loss = 0.002309084848754785
Trained batch 55 in epoch 6, gen_loss = 1.1678385127867972, disc_loss = 0.002293078016789098
Trained batch 56 in epoch 6, gen_loss = 1.170693994614116, disc_loss = 0.0022790074111534316
Trained batch 57 in epoch 6, gen_loss = 1.1703703927582707, disc_loss = 0.002251979077018091
Trained batch 58 in epoch 6, gen_loss = 1.1697896890721078, disc_loss = 0.0022284690639935434
Trained batch 59 in epoch 6, gen_loss = 1.1702501326799393, disc_loss = 0.002210915629014683
Trained batch 60 in epoch 6, gen_loss = 1.166584499546739, disc_loss = 0.002337332995280196
Trained batch 61 in epoch 6, gen_loss = 1.1648428632367043, disc_loss = 0.0025591338626033957
Trained batch 62 in epoch 6, gen_loss = 1.1685888615865556, disc_loss = 0.0025879563292532807
Trained batch 63 in epoch 6, gen_loss = 1.1695125792175531, disc_loss = 0.002596602917947166
Trained batch 64 in epoch 6, gen_loss = 1.1722366681465737, disc_loss = 0.0026163370250007856
Trained batch 65 in epoch 6, gen_loss = 1.1714293252338062, disc_loss = 0.0026521817613463622
Trained batch 66 in epoch 6, gen_loss = 1.1692922346627534, disc_loss = 0.0026441039769465463
Trained batch 67 in epoch 6, gen_loss = 1.1682698463692385, disc_loss = 0.002627661661416128
Trained batch 68 in epoch 6, gen_loss = 1.1671760324118794, disc_loss = 0.002615486630204849
Trained batch 69 in epoch 6, gen_loss = 1.1646507339818137, disc_loss = 0.002600901637924835
Trained batch 70 in epoch 6, gen_loss = 1.1635244203285433, disc_loss = 0.0025786593774477884
Trained batch 71 in epoch 6, gen_loss = 1.1637713950541284, disc_loss = 0.0025567503608827894
Trained batch 72 in epoch 6, gen_loss = 1.1622312240404626, disc_loss = 0.0025616715580850124
Trained batch 73 in epoch 6, gen_loss = 1.163248584882633, disc_loss = 0.0026078437953696563
Trained batch 74 in epoch 6, gen_loss = 1.162255577246348, disc_loss = 0.002619143737635265
Trained batch 75 in epoch 6, gen_loss = 1.1622001960089332, disc_loss = 0.002593354252320224
Trained batch 76 in epoch 6, gen_loss = 1.1616517560822623, disc_loss = 0.0025794276137618565
Trained batch 77 in epoch 6, gen_loss = 1.1615865161785712, disc_loss = 0.0025617240604240065
Trained batch 78 in epoch 6, gen_loss = 1.1622540762152853, disc_loss = 0.0025369186305051927
Trained batch 79 in epoch 6, gen_loss = 1.1607580848038197, disc_loss = 0.0025130532958428375
Trained batch 80 in epoch 6, gen_loss = 1.1621946854355893, disc_loss = 0.002509273889037654
Trained batch 81 in epoch 6, gen_loss = 1.1616639749306004, disc_loss = 0.002507564868698487
Trained batch 82 in epoch 6, gen_loss = 1.1624838465667633, disc_loss = 0.002493888143932514
Trained batch 83 in epoch 6, gen_loss = 1.1617177291995002, disc_loss = 0.002480570089703958
Trained batch 84 in epoch 6, gen_loss = 1.1609922570340774, disc_loss = 0.0024631005561198383
Trained batch 85 in epoch 6, gen_loss = 1.1605752865935481, disc_loss = 0.002448356780765015
Trained batch 86 in epoch 6, gen_loss = 1.1595347167431622, disc_loss = 0.002427314697154637
Trained batch 87 in epoch 6, gen_loss = 1.156075161289085, disc_loss = 0.0024220250541640616
Trained batch 88 in epoch 6, gen_loss = 1.1570133044478599, disc_loss = 0.002423141489140271
Trained batch 89 in epoch 6, gen_loss = 1.1562506271733177, disc_loss = 0.0024133667272205153
Trained batch 90 in epoch 6, gen_loss = 1.157303424326928, disc_loss = 0.0023959545325231996
Trained batch 91 in epoch 6, gen_loss = 1.1586727312077647, disc_loss = 0.0023788914157826776
Trained batch 92 in epoch 6, gen_loss = 1.1574589635736199, disc_loss = 0.00236656378594137
Trained batch 93 in epoch 6, gen_loss = 1.1564974372691297, disc_loss = 0.0023721078648529154
Trained batch 94 in epoch 6, gen_loss = 1.1562151852406954, disc_loss = 0.002367630152423915
Trained batch 95 in epoch 6, gen_loss = 1.1572105828672647, disc_loss = 0.002355921175573409
Trained batch 96 in epoch 6, gen_loss = 1.1545820826107693, disc_loss = 0.0023611936797435906
Trained batch 97 in epoch 6, gen_loss = 1.156532566158139, disc_loss = 0.0023742952462456816
Trained batch 98 in epoch 6, gen_loss = 1.1574560668733385, disc_loss = 0.0023604231237462072
Trained batch 99 in epoch 6, gen_loss = 1.156333352327347, disc_loss = 0.002352498342515901
Trained batch 100 in epoch 6, gen_loss = 1.1559759425644827, disc_loss = 0.002336446638449584
Trained batch 101 in epoch 6, gen_loss = 1.1535205992997861, disc_loss = 0.0023412540413475795
Trained batch 102 in epoch 6, gen_loss = 1.1554493059232398, disc_loss = 0.002349263314808746
Trained batch 103 in epoch 6, gen_loss = 1.157064554783014, disc_loss = 0.0023395828913915185
Trained batch 104 in epoch 6, gen_loss = 1.1561178593408494, disc_loss = 0.002331076481468266
Trained batch 105 in epoch 6, gen_loss = 1.1546177374866773, disc_loss = 0.0023260100839114835
Trained batch 106 in epoch 6, gen_loss = 1.1536943015651169, disc_loss = 0.00232187115095521
Trained batch 107 in epoch 6, gen_loss = 1.1526226462037474, disc_loss = 0.0023165739742883793
Trained batch 108 in epoch 6, gen_loss = 1.1514233739004223, disc_loss = 0.0023023873180954145
Trained batch 109 in epoch 6, gen_loss = 1.150287882306359, disc_loss = 0.0022878875659609384
Trained batch 110 in epoch 6, gen_loss = 1.1510424136041522, disc_loss = 0.002274924773840351
Trained batch 111 in epoch 6, gen_loss = 1.1518884466162749, disc_loss = 0.002260376184234961
Trained batch 112 in epoch 6, gen_loss = 1.151523072635178, disc_loss = 0.002263679355073852
Trained batch 113 in epoch 6, gen_loss = 1.1499060815886448, disc_loss = 0.0022751748517948088
Trained batch 114 in epoch 6, gen_loss = 1.151092395056849, disc_loss = 0.0022677116121327424
Trained batch 115 in epoch 6, gen_loss = 1.1510934053823865, disc_loss = 0.002260596678564164
Trained batch 116 in epoch 6, gen_loss = 1.1509833473425646, disc_loss = 0.002256666128543548
Trained batch 117 in epoch 6, gen_loss = 1.150555744514627, disc_loss = 0.002244531065995126
Trained batch 118 in epoch 6, gen_loss = 1.151576475435946, disc_loss = 0.0022293279615637823
Trained batch 119 in epoch 6, gen_loss = 1.151429677506288, disc_loss = 0.0022186216025147586
Trained batch 120 in epoch 6, gen_loss = 1.150093962338345, disc_loss = 0.0022137511544668476
Trained batch 121 in epoch 6, gen_loss = 1.1495018904326393, disc_loss = 0.002203666063056129
Trained batch 122 in epoch 6, gen_loss = 1.1479318500534306, disc_loss = 0.002206457604661705
Trained batch 123 in epoch 6, gen_loss = 1.147780712573759, disc_loss = 0.0022122532790226322
Trained batch 124 in epoch 6, gen_loss = 1.1470373477935791, disc_loss = 0.0022193558923900127
Trained batch 125 in epoch 6, gen_loss = 1.1467023009345645, disc_loss = 0.0022325196602780905
Trained batch 126 in epoch 6, gen_loss = 1.1449399520093062, disc_loss = 0.0022275497739049277
Trained batch 127 in epoch 6, gen_loss = 1.1455745389685035, disc_loss = 0.002217443293375254
Trained batch 128 in epoch 6, gen_loss = 1.1464901035146196, disc_loss = 0.0022062526247825097
Trained batch 129 in epoch 6, gen_loss = 1.1467305165070754, disc_loss = 0.00220904088122412
Trained batch 130 in epoch 6, gen_loss = 1.1457987869058857, disc_loss = 0.0022021243157654374
Trained batch 131 in epoch 6, gen_loss = 1.1463033547907164, disc_loss = 0.002191789667862891
Trained batch 132 in epoch 6, gen_loss = 1.1473068016812318, disc_loss = 0.002189662963102915
Trained batch 133 in epoch 6, gen_loss = 1.1456400285016244, disc_loss = 0.0021823044534452925
Trained batch 134 in epoch 6, gen_loss = 1.1441383534007603, disc_loss = 0.0021720221498981117
Trained batch 135 in epoch 6, gen_loss = 1.1428313890800756, disc_loss = 0.0021621329484760817
Trained batch 136 in epoch 6, gen_loss = 1.143255593567869, disc_loss = 0.0021532941707341938
Trained batch 137 in epoch 6, gen_loss = 1.1420488284117933, disc_loss = 0.002155523259189331
Trained batch 138 in epoch 6, gen_loss = 1.1427740737688628, disc_loss = 0.0021483056417250968
Trained batch 139 in epoch 6, gen_loss = 1.1439753528152192, disc_loss = 0.002142514506704174
Trained batch 140 in epoch 6, gen_loss = 1.1429596145947774, disc_loss = 0.002138001791033101
Trained batch 141 in epoch 6, gen_loss = 1.1417195058204759, disc_loss = 0.002129944308224777
Trained batch 142 in epoch 6, gen_loss = 1.1418585602220122, disc_loss = 0.002117297963818887
Trained batch 143 in epoch 6, gen_loss = 1.1425873082545068, disc_loss = 0.0021060962167717256
Trained batch 144 in epoch 6, gen_loss = 1.1415426796880261, disc_loss = 0.0020961567462454067
Trained batch 145 in epoch 6, gen_loss = 1.1411906799224958, disc_loss = 0.0020895335179026402
Trained batch 146 in epoch 6, gen_loss = 1.1404785161115685, disc_loss = 0.0020782082004244533
Trained batch 147 in epoch 6, gen_loss = 1.140465083154472, disc_loss = 0.002073198022805406
Trained batch 148 in epoch 6, gen_loss = 1.1401940440171516, disc_loss = 0.0020679150725208574
Trained batch 149 in epoch 6, gen_loss = 1.1405101521809895, disc_loss = 0.002056714786449447
Trained batch 150 in epoch 6, gen_loss = 1.1403968855245223, disc_loss = 0.0020499972712143713
Trained batch 151 in epoch 6, gen_loss = 1.1394481466788995, disc_loss = 0.0020415984346120815
Trained batch 152 in epoch 6, gen_loss = 1.140464880497627, disc_loss = 0.002040965697542442
Trained batch 153 in epoch 6, gen_loss = 1.140581379076103, disc_loss = 0.002035583555773989
Trained batch 154 in epoch 6, gen_loss = 1.1401917584480779, disc_loss = 0.002027637037944289
Trained batch 155 in epoch 6, gen_loss = 1.1398605310764067, disc_loss = 0.0020301664551833454
Trained batch 156 in epoch 6, gen_loss = 1.1379525794345102, disc_loss = 0.0021413051842854233
Trained batch 157 in epoch 6, gen_loss = 1.1354904212529147, disc_loss = 0.003700413344401418
Trained batch 158 in epoch 6, gen_loss = 1.1370075461249682, disc_loss = 0.0043480523884642
Trained batch 159 in epoch 6, gen_loss = 1.1401878997683526, disc_loss = 0.004508930891097407
Trained batch 160 in epoch 6, gen_loss = 1.139926694935153, disc_loss = 0.004775554709272424
Trained batch 161 in epoch 6, gen_loss = 1.139277709119114, disc_loss = 0.004860341230933382
Trained batch 162 in epoch 6, gen_loss = 1.1379279073762016, disc_loss = 0.004893833969539728
Trained batch 163 in epoch 6, gen_loss = 1.1372238768310081, disc_loss = 0.004899937322678431
Trained batch 164 in epoch 6, gen_loss = 1.1371294303373858, disc_loss = 0.004917237008427919
Trained batch 165 in epoch 6, gen_loss = 1.1364368027951344, disc_loss = 0.004911008032518495
Trained batch 166 in epoch 6, gen_loss = 1.1356033215265788, disc_loss = 0.004894903029697183
Trained batch 167 in epoch 6, gen_loss = 1.134289073092597, disc_loss = 0.004886933000567036
Trained batch 168 in epoch 6, gen_loss = 1.134835113435102, disc_loss = 0.004879704499878981
Trained batch 169 in epoch 6, gen_loss = 1.1346486680647907, disc_loss = 0.004867380772210548
Trained batch 170 in epoch 6, gen_loss = 1.1335559832422357, disc_loss = 0.004868701492144851
Trained batch 171 in epoch 6, gen_loss = 1.1337131012317747, disc_loss = 0.004861655796344695
Trained batch 172 in epoch 6, gen_loss = 1.1336878910230075, disc_loss = 0.004841640459392435
Trained batch 173 in epoch 6, gen_loss = 1.1329723411592945, disc_loss = 0.004847271000931639
Trained batch 174 in epoch 6, gen_loss = 1.1336787332807268, disc_loss = 0.004847356290889106
Trained batch 175 in epoch 6, gen_loss = 1.134487468410622, disc_loss = 0.004829549423448043
Trained batch 176 in epoch 6, gen_loss = 1.1345445348718073, disc_loss = 0.004815158123442493
Trained batch 177 in epoch 6, gen_loss = 1.1348764789238404, disc_loss = 0.004810042026272211
Trained batch 178 in epoch 6, gen_loss = 1.1343588462755, disc_loss = 0.004800259833830258
Trained batch 179 in epoch 6, gen_loss = 1.1345557192961375, disc_loss = 0.00478111029337419
Trained batch 180 in epoch 6, gen_loss = 1.1353780294650166, disc_loss = 0.004768850035818798
Trained batch 181 in epoch 6, gen_loss = 1.1366109736673125, disc_loss = 0.00475332197563078
Trained batch 182 in epoch 6, gen_loss = 1.1376975286202353, disc_loss = 0.004735166431834687
Trained batch 183 in epoch 6, gen_loss = 1.1375832726126132, disc_loss = 0.004716163888034593
Trained batch 184 in epoch 6, gen_loss = 1.1372656326036195, disc_loss = 0.004698403139686766
Trained batch 185 in epoch 6, gen_loss = 1.1377852969272162, disc_loss = 0.004678209264066711
Trained batch 186 in epoch 6, gen_loss = 1.1386415148801345, disc_loss = 0.004658443013450161
Trained batch 187 in epoch 6, gen_loss = 1.1381640668879165, disc_loss = 0.004643526024239613
Trained batch 188 in epoch 6, gen_loss = 1.1377420198349726, disc_loss = 0.004628829613066815
Trained batch 189 in epoch 6, gen_loss = 1.139051013871243, disc_loss = 0.004610956383035763
Trained batch 190 in epoch 6, gen_loss = 1.1399969168358448, disc_loss = 0.004594103925671253
Trained batch 191 in epoch 6, gen_loss = 1.1397019755095243, disc_loss = 0.004579219827670992
Trained batch 192 in epoch 6, gen_loss = 1.1405236109550754, disc_loss = 0.004560606942000591
Trained batch 193 in epoch 6, gen_loss = 1.1414145839583014, disc_loss = 0.004542105222725761
Trained batch 194 in epoch 6, gen_loss = 1.1411288377566216, disc_loss = 0.0045344241572400695
Trained batch 195 in epoch 6, gen_loss = 1.1402939308662803, disc_loss = 0.004523495801401382
Trained batch 196 in epoch 6, gen_loss = 1.1405750077388008, disc_loss = 0.004511616268398496
Trained batch 197 in epoch 6, gen_loss = 1.139975575485615, disc_loss = 0.004533913348697954
Trained batch 198 in epoch 6, gen_loss = 1.1401821764270266, disc_loss = 0.004578626761446946
Trained batch 199 in epoch 6, gen_loss = 1.140233439207077, disc_loss = 0.00457125790650025
Trained batch 200 in epoch 6, gen_loss = 1.1408398536900384, disc_loss = 0.004564331470298308
Trained batch 201 in epoch 6, gen_loss = 1.1415033464384552, disc_loss = 0.004546802712254005
Trained batch 202 in epoch 6, gen_loss = 1.1408761686879425, disc_loss = 0.004539854265978844
Trained batch 203 in epoch 6, gen_loss = 1.1411162229145275, disc_loss = 0.004528722885594356
Trained batch 204 in epoch 6, gen_loss = 1.1413467767761976, disc_loss = 0.004510757486086066
Trained batch 205 in epoch 6, gen_loss = 1.1406260940056403, disc_loss = 0.004499428946235516
Trained batch 206 in epoch 6, gen_loss = 1.140553267393711, disc_loss = 0.004487365915030601
Trained batch 207 in epoch 6, gen_loss = 1.1406205849578748, disc_loss = 0.004472799787785893
Trained batch 208 in epoch 6, gen_loss = 1.14154973868548, disc_loss = 0.004461343064302641
Trained batch 209 in epoch 6, gen_loss = 1.142376743895667, disc_loss = 0.004456029850656965
Trained batch 210 in epoch 6, gen_loss = 1.14346519550441, disc_loss = 0.004443592947501671
Trained batch 211 in epoch 6, gen_loss = 1.1427003679410466, disc_loss = 0.004437311341050344
Trained batch 212 in epoch 6, gen_loss = 1.142411729539504, disc_loss = 0.004419639362557901
Trained batch 213 in epoch 6, gen_loss = 1.1436850974492938, disc_loss = 0.004415426472099672
Trained batch 214 in epoch 6, gen_loss = 1.1443128480467686, disc_loss = 0.004403161540421722
Trained batch 215 in epoch 6, gen_loss = 1.1446094110056206, disc_loss = 0.004388500212236842
Trained batch 216 in epoch 6, gen_loss = 1.1456977365203718, disc_loss = 0.00437506738420327
Trained batch 217 in epoch 6, gen_loss = 1.145848517024189, disc_loss = 0.0043667643889037195
Trained batch 218 in epoch 6, gen_loss = 1.1449302840450584, disc_loss = 0.004358370276221146
Trained batch 219 in epoch 6, gen_loss = 1.1454628665338864, disc_loss = 0.004342942613452165
Trained batch 220 in epoch 6, gen_loss = 1.1458189975622013, disc_loss = 0.004328072780102694
Trained batch 221 in epoch 6, gen_loss = 1.1460650351133432, disc_loss = 0.0043117001968402385
Trained batch 222 in epoch 6, gen_loss = 1.1457299274714003, disc_loss = 0.004302775893974297
Trained batch 223 in epoch 6, gen_loss = 1.1460474354348011, disc_loss = 0.004292462349050246
Trained batch 224 in epoch 6, gen_loss = 1.1465912233458624, disc_loss = 0.00428197948106875
Trained batch 225 in epoch 6, gen_loss = 1.1475456570629525, disc_loss = 0.0042670362781469535
Trained batch 226 in epoch 6, gen_loss = 1.148493934045279, disc_loss = 0.004251715559194414
Trained batch 227 in epoch 6, gen_loss = 1.1481803951033376, disc_loss = 0.004237828136211375
Trained batch 228 in epoch 6, gen_loss = 1.1475725962605539, disc_loss = 0.004223793242523227
Trained batch 229 in epoch 6, gen_loss = 1.1477435933507008, disc_loss = 0.0042099362170910865
Trained batch 230 in epoch 6, gen_loss = 1.1487713956729675, disc_loss = 0.004195254036271743
Trained batch 231 in epoch 6, gen_loss = 1.149559734453415, disc_loss = 0.0041791151989259406
Trained batch 232 in epoch 6, gen_loss = 1.1499162050275844, disc_loss = 0.004164432830481027
Trained batch 233 in epoch 6, gen_loss = 1.1508966024614806, disc_loss = 0.004148655338585974
Trained batch 234 in epoch 6, gen_loss = 1.150023178597714, disc_loss = 0.004138071591683485
Trained batch 235 in epoch 6, gen_loss = 1.150015572622671, disc_loss = 0.004126301179694257
Trained batch 236 in epoch 6, gen_loss = 1.1498632222288268, disc_loss = 0.004111112939672278
Trained batch 237 in epoch 6, gen_loss = 1.1495772262080377, disc_loss = 0.004099791812169475
Trained batch 238 in epoch 6, gen_loss = 1.1493576478259833, disc_loss = 0.004094927484402433
Trained batch 239 in epoch 6, gen_loss = 1.1496315417190393, disc_loss = 0.004090160049357413
Trained batch 240 in epoch 6, gen_loss = 1.1498069790389034, disc_loss = 0.004079282184153664
Trained batch 241 in epoch 6, gen_loss = 1.149393118856367, disc_loss = 0.004075575715064625
Trained batch 242 in epoch 6, gen_loss = 1.149973154803853, disc_loss = 0.00407029738840877
Trained batch 243 in epoch 6, gen_loss = 1.1499220394208782, disc_loss = 0.004061485769405587
Trained batch 244 in epoch 6, gen_loss = 1.1500131687339472, disc_loss = 0.004051997490602603
Trained batch 245 in epoch 6, gen_loss = 1.1510525561445129, disc_loss = 0.0040532508967926996
Trained batch 246 in epoch 6, gen_loss = 1.1513935735351162, disc_loss = 0.004045966507274062
Trained batch 247 in epoch 6, gen_loss = 1.151855429093684, disc_loss = 0.004043206551760968
Trained batch 248 in epoch 6, gen_loss = 1.1519222314577984, disc_loss = 0.004036513441331108
Trained batch 249 in epoch 6, gen_loss = 1.1527590429782868, disc_loss = 0.004032267312402837
Trained batch 250 in epoch 6, gen_loss = 1.1530255433097778, disc_loss = 0.004019687669857245
Trained batch 251 in epoch 6, gen_loss = 1.1540007513193857, disc_loss = 0.0040067331060454885
Trained batch 252 in epoch 6, gen_loss = 1.1535105448466516, disc_loss = 0.004250612618698897
Trained batch 253 in epoch 6, gen_loss = 1.1523450591902094, disc_loss = 0.004723375172635694
Trained batch 254 in epoch 6, gen_loss = 1.1518424863908805, disc_loss = 0.004768103544540959
Trained batch 255 in epoch 6, gen_loss = 1.152861766749993, disc_loss = 0.004808741968076902
Trained batch 256 in epoch 6, gen_loss = 1.1535540529262232, disc_loss = 0.004830584420024413
Trained batch 257 in epoch 6, gen_loss = 1.1546020325302153, disc_loss = 0.004838132464517334
Trained batch 258 in epoch 6, gen_loss = 1.1545763321824976, disc_loss = 0.004830231476448382
Trained batch 259 in epoch 6, gen_loss = 1.154909781080026, disc_loss = 0.004819419089807735
Trained batch 260 in epoch 6, gen_loss = 1.1549117864320104, disc_loss = 0.004808086549869464
Trained batch 261 in epoch 6, gen_loss = 1.1546175250115285, disc_loss = 0.004797339619235989
Trained batch 262 in epoch 6, gen_loss = 1.15526780588092, disc_loss = 0.004786754357553275
Trained batch 263 in epoch 6, gen_loss = 1.1546550517280896, disc_loss = 0.004775530579618961
Trained batch 264 in epoch 6, gen_loss = 1.1547009182426164, disc_loss = 0.004766273230889742
Trained batch 265 in epoch 6, gen_loss = 1.1556651693089564, disc_loss = 0.004753660289741373
Trained batch 266 in epoch 6, gen_loss = 1.1560069695394137, disc_loss = 0.00474196887121201
Trained batch 267 in epoch 6, gen_loss = 1.1560040714580622, disc_loss = 0.0047275521174558
Trained batch 268 in epoch 6, gen_loss = 1.1562704687668046, disc_loss = 0.004712188366361717
Trained batch 269 in epoch 6, gen_loss = 1.1558323871206355, disc_loss = 0.004700497294349285
Trained batch 270 in epoch 6, gen_loss = 1.155146461791218, disc_loss = 0.00468629742450617
Trained batch 271 in epoch 6, gen_loss = 1.1550770412911386, disc_loss = 0.004672738988494316
Trained batch 272 in epoch 6, gen_loss = 1.1551709103060293, disc_loss = 0.004658920344476155
Trained batch 273 in epoch 6, gen_loss = 1.1552187002053227, disc_loss = 0.004644376922668176
Trained batch 274 in epoch 6, gen_loss = 1.154463872909546, disc_loss = 0.004631675892954015
Trained batch 275 in epoch 6, gen_loss = 1.154335567916649, disc_loss = 0.004623797917557185
Trained batch 276 in epoch 6, gen_loss = 1.1539318002087975, disc_loss = 0.004610993463267818
Trained batch 277 in epoch 6, gen_loss = 1.1536388611621995, disc_loss = 0.004597349381413505
Trained batch 278 in epoch 6, gen_loss = 1.1532393347832464, disc_loss = 0.004583357919385577
Trained batch 279 in epoch 6, gen_loss = 1.1527755060366223, disc_loss = 0.004568949908155316
Trained batch 280 in epoch 6, gen_loss = 1.1528041477305184, disc_loss = 0.004555743506772351
Trained batch 281 in epoch 6, gen_loss = 1.1524543859434466, disc_loss = 0.00454148691358517
Trained batch 282 in epoch 6, gen_loss = 1.1525575436467417, disc_loss = 0.004529024311732139
Trained batch 283 in epoch 6, gen_loss = 1.1531399509436648, disc_loss = 0.004516548732386633
Trained batch 284 in epoch 6, gen_loss = 1.153138998516819, disc_loss = 0.004503029575591842
Trained batch 285 in epoch 6, gen_loss = 1.1521741406067267, disc_loss = 0.0049560380993953134
Trained batch 286 in epoch 6, gen_loss = 1.1514526132091827, disc_loss = 0.005222402607639992
Trained batch 287 in epoch 6, gen_loss = 1.1515462626185682, disc_loss = 0.005352713481847281
Trained batch 288 in epoch 6, gen_loss = 1.1525180838924791, disc_loss = 0.005392961117546122
Trained batch 289 in epoch 6, gen_loss = 1.1526334709134596, disc_loss = 0.0054316171963803535
Trained batch 290 in epoch 6, gen_loss = 1.1527765759897395, disc_loss = 0.005434114003215542
Trained batch 291 in epoch 6, gen_loss = 1.1529641139180693, disc_loss = 0.005437128027850819
Trained batch 292 in epoch 6, gen_loss = 1.1534682642477772, disc_loss = 0.00542418718619714
Trained batch 293 in epoch 6, gen_loss = 1.1538737627113758, disc_loss = 0.005411058501281053
Trained batch 294 in epoch 6, gen_loss = 1.1539165969622338, disc_loss = 0.005396228187453097
Trained batch 295 in epoch 6, gen_loss = 1.1538046159454294, disc_loss = 0.00538264597245772
Trained batch 296 in epoch 6, gen_loss = 1.153924974528226, disc_loss = 0.005368793233997825
Trained batch 297 in epoch 6, gen_loss = 1.1542340833068694, disc_loss = 0.0053559287507657346
Trained batch 298 in epoch 6, gen_loss = 1.1534380085492213, disc_loss = 0.005346280622025827
Trained batch 299 in epoch 6, gen_loss = 1.1533959573507309, disc_loss = 0.005330929707949205
Trained batch 300 in epoch 6, gen_loss = 1.1533131070707328, disc_loss = 0.005315346746497395
Trained batch 301 in epoch 6, gen_loss = 1.152908690125737, disc_loss = 0.005301069637004206
Trained batch 302 in epoch 6, gen_loss = 1.1528154326350775, disc_loss = 0.005285650108562069
Trained batch 303 in epoch 6, gen_loss = 1.1523891622690778, disc_loss = 0.005270464911135557
Trained batch 304 in epoch 6, gen_loss = 1.1519007547956999, disc_loss = 0.005255142471955357
Trained batch 305 in epoch 6, gen_loss = 1.1525941298288458, disc_loss = 0.005240299721918787
Trained batch 306 in epoch 6, gen_loss = 1.152162253856659, disc_loss = 0.005225112199565662
Trained batch 307 in epoch 6, gen_loss = 1.1525785309540761, disc_loss = 0.0052103095094699035
Trained batch 308 in epoch 6, gen_loss = 1.1519977228541205, disc_loss = 0.005195539182938883
Trained batch 309 in epoch 6, gen_loss = 1.1518012662087718, disc_loss = 0.005183549957714164
Trained batch 310 in epoch 6, gen_loss = 1.1516719213252666, disc_loss = 0.005168660544701238
Trained batch 311 in epoch 6, gen_loss = 1.1519202547959793, disc_loss = 0.005153450551286089
Trained batch 312 in epoch 6, gen_loss = 1.151588906495335, disc_loss = 0.005138612244264803
Trained batch 313 in epoch 6, gen_loss = 1.152246545454499, disc_loss = 0.005124422570299002
Trained batch 314 in epoch 6, gen_loss = 1.1525653759638468, disc_loss = 0.005109989785567103
Trained batch 315 in epoch 6, gen_loss = 1.1531548654731316, disc_loss = 0.0050955206563599005
Trained batch 316 in epoch 6, gen_loss = 1.153043311853138, disc_loss = 0.005081608973932673
Trained batch 317 in epoch 6, gen_loss = 1.1525844215596996, disc_loss = 0.005073759142703336
Trained batch 318 in epoch 6, gen_loss = 1.1521551978999172, disc_loss = 0.005062934166867122
Trained batch 319 in epoch 6, gen_loss = 1.1523349300026893, disc_loss = 0.005048805955630087
Trained batch 320 in epoch 6, gen_loss = 1.1521379869674968, disc_loss = 0.0050372477953403464
Trained batch 321 in epoch 6, gen_loss = 1.1521376315851388, disc_loss = 0.005025655286992547
Trained batch 322 in epoch 6, gen_loss = 1.1528203055585502, disc_loss = 0.005012327392301566
Trained batch 323 in epoch 6, gen_loss = 1.152738861095758, disc_loss = 0.005000515460262339
Trained batch 324 in epoch 6, gen_loss = 1.1522385674256546, disc_loss = 0.004987945692577901
Trained batch 325 in epoch 6, gen_loss = 1.151917242565038, disc_loss = 0.0049750220655117965
Trained batch 326 in epoch 6, gen_loss = 1.1517425684389353, disc_loss = 0.004961488128174096
Trained batch 327 in epoch 6, gen_loss = 1.1516616082772977, disc_loss = 0.004947945929349616
Trained batch 328 in epoch 6, gen_loss = 1.1522820079217928, disc_loss = 0.004935675041819427
Trained batch 329 in epoch 6, gen_loss = 1.1525504784150558, disc_loss = 0.0049232595402634504
Trained batch 330 in epoch 6, gen_loss = 1.1521189151573756, disc_loss = 0.004910152768111279
Trained batch 331 in epoch 6, gen_loss = 1.152484325400318, disc_loss = 0.004899441553854821
Trained batch 332 in epoch 6, gen_loss = 1.1525327912322036, disc_loss = 0.004891373876093498
Trained batch 333 in epoch 6, gen_loss = 1.152637093010063, disc_loss = 0.004883109102887241
Trained batch 334 in epoch 6, gen_loss = 1.1533553888548667, disc_loss = 0.004873979836702347
Trained batch 335 in epoch 6, gen_loss = 1.1529254295996256, disc_loss = 0.004861758930062587
Trained batch 336 in epoch 6, gen_loss = 1.1530052480075055, disc_loss = 0.004850374559943705
Trained batch 337 in epoch 6, gen_loss = 1.1529055428222792, disc_loss = 0.004839127378045036
Trained batch 338 in epoch 6, gen_loss = 1.1523867495643705, disc_loss = 0.004826393438939961
Trained batch 339 in epoch 6, gen_loss = 1.1522154736168244, disc_loss = 0.004813725358861334
Trained batch 340 in epoch 6, gen_loss = 1.151940911221714, disc_loss = 0.004801236500156514
Trained batch 341 in epoch 6, gen_loss = 1.1513555076038628, disc_loss = 0.0047899906091903996
Trained batch 342 in epoch 6, gen_loss = 1.1511576820392997, disc_loss = 0.004783773907452126
Trained batch 343 in epoch 6, gen_loss = 1.1510607120256091, disc_loss = 0.004771644807438268
Trained batch 344 in epoch 6, gen_loss = 1.1510681485784227, disc_loss = 0.004759558969332526
Trained batch 345 in epoch 6, gen_loss = 1.151383571714335, disc_loss = 0.0047504951024355336
Trained batch 346 in epoch 6, gen_loss = 1.1513845867313637, disc_loss = 0.004739389659384647
Trained batch 347 in epoch 6, gen_loss = 1.1517885993609482, disc_loss = 0.004727276582364528
Trained batch 348 in epoch 6, gen_loss = 1.151589085003708, disc_loss = 0.0047145088239610305
Trained batch 349 in epoch 6, gen_loss = 1.1521709610734667, disc_loss = 0.004702458450171565
Trained batch 350 in epoch 6, gen_loss = 1.152104775620322, disc_loss = 0.004690527165059181
Trained batch 351 in epoch 6, gen_loss = 1.1520340498536825, disc_loss = 0.004679437314156199
Trained batch 352 in epoch 6, gen_loss = 1.15182137506204, disc_loss = 0.004668040497712632
Trained batch 353 in epoch 6, gen_loss = 1.152104250960431, disc_loss = 0.004656172739960106
Trained batch 354 in epoch 6, gen_loss = 1.1523805039029726, disc_loss = 0.0046439420776999175
Trained batch 355 in epoch 6, gen_loss = 1.1521859970990191, disc_loss = 0.0046320779528174535
Trained batch 356 in epoch 6, gen_loss = 1.1521928749498533, disc_loss = 0.004621244364770923
Trained batch 357 in epoch 6, gen_loss = 1.152049829007527, disc_loss = 0.004610579217378929
Trained batch 358 in epoch 6, gen_loss = 1.151639245844817, disc_loss = 0.004600413042865823
Trained batch 359 in epoch 6, gen_loss = 1.1511233884427283, disc_loss = 0.004588380596639278
Trained batch 360 in epoch 6, gen_loss = 1.1515419712687462, disc_loss = 0.004577090647045801
Trained batch 361 in epoch 6, gen_loss = 1.1509004892235961, disc_loss = 0.004568985768192505
Trained batch 362 in epoch 6, gen_loss = 1.1508957579444592, disc_loss = 0.004561254873964166
Trained batch 363 in epoch 6, gen_loss = 1.1519730394030665, disc_loss = 0.004551702627405565
Trained batch 364 in epoch 6, gen_loss = 1.1519118147353604, disc_loss = 0.0045403344032022945
Trained batch 365 in epoch 6, gen_loss = 1.15185663169199, disc_loss = 0.004530915902524199
Trained batch 366 in epoch 6, gen_loss = 1.1518309420071116, disc_loss = 0.00452121105714389
Trained batch 367 in epoch 6, gen_loss = 1.151889911002439, disc_loss = 0.004510389184123715
Trained batch 368 in epoch 6, gen_loss = 1.151891603540922, disc_loss = 0.004499606844788635
Trained batch 369 in epoch 6, gen_loss = 1.1516268561015257, disc_loss = 0.004490985121810809
Trained batch 370 in epoch 6, gen_loss = 1.1516283938505578, disc_loss = 0.004483867231900791
Trained batch 371 in epoch 6, gen_loss = 1.1517507608539315, disc_loss = 0.004473379276435001
Trained batch 372 in epoch 6, gen_loss = 1.1515088581527526, disc_loss = 0.004466297136477367
Trained batch 373 in epoch 6, gen_loss = 1.1511652952528255, disc_loss = 0.004455537453697207
Trained batch 374 in epoch 6, gen_loss = 1.1511896138191222, disc_loss = 0.004445389351341873
Trained batch 375 in epoch 6, gen_loss = 1.1514166449295713, disc_loss = 0.004435625781201103
Trained batch 376 in epoch 6, gen_loss = 1.1511665378704627, disc_loss = 0.004427625059980197
Trained batch 377 in epoch 6, gen_loss = 1.1511810436135246, disc_loss = 0.0044215187912673825
Trained batch 378 in epoch 6, gen_loss = 1.1511584062689526, disc_loss = 0.004412747082536386
Trained batch 379 in epoch 6, gen_loss = 1.1512218680820967, disc_loss = 0.004402847615787514
Trained batch 380 in epoch 6, gen_loss = 1.1510799311277435, disc_loss = 0.004393448661603376
Trained batch 381 in epoch 6, gen_loss = 1.150877238412178, disc_loss = 0.004385013129478028
Trained batch 382 in epoch 6, gen_loss = 1.1508706762958756, disc_loss = 0.004376315835932654
Trained batch 383 in epoch 6, gen_loss = 1.151718538099279, disc_loss = 0.004367845528122416
Trained batch 384 in epoch 6, gen_loss = 1.151625415721497, disc_loss = 0.004364085228744798
Trained batch 385 in epoch 6, gen_loss = 1.1514323321339999, disc_loss = 0.004356266672987191
Trained batch 386 in epoch 6, gen_loss = 1.1516937989289138, disc_loss = 0.004347877446243188
Trained batch 387 in epoch 6, gen_loss = 1.1515840754373787, disc_loss = 0.004340284066688817
Trained batch 388 in epoch 6, gen_loss = 1.1520564839588645, disc_loss = 0.004331529538349457
Trained batch 389 in epoch 6, gen_loss = 1.151939582060545, disc_loss = 0.004322092226730325
Trained batch 390 in epoch 6, gen_loss = 1.1520041125204863, disc_loss = 0.004312752226493834
Trained batch 391 in epoch 6, gen_loss = 1.1524562016129494, disc_loss = 0.004302707817408432
Trained batch 392 in epoch 6, gen_loss = 1.152825860121778, disc_loss = 0.004293203406090997
Trained batch 393 in epoch 6, gen_loss = 1.1526098576596546, disc_loss = 0.004284326901064292
Trained batch 394 in epoch 6, gen_loss = 1.1520849178108987, disc_loss = 0.004275016154713716
Trained batch 395 in epoch 6, gen_loss = 1.1522441396508554, disc_loss = 0.004265865554807901
Trained batch 396 in epoch 6, gen_loss = 1.1517128732702895, disc_loss = 0.004257762883581638
Trained batch 397 in epoch 6, gen_loss = 1.152193210981599, disc_loss = 0.00424966671576913
Trained batch 398 in epoch 6, gen_loss = 1.1527118015110045, disc_loss = 0.004240738106077481
Trained batch 399 in epoch 6, gen_loss = 1.152471013814211, disc_loss = 0.004231033872711123
Trained batch 400 in epoch 6, gen_loss = 1.1526363159058397, disc_loss = 0.004221281090224663
Trained batch 401 in epoch 6, gen_loss = 1.1521885930305689, disc_loss = 0.004211862508841183
Trained batch 402 in epoch 6, gen_loss = 1.1525994440166294, disc_loss = 0.004203003171280202
Trained batch 403 in epoch 6, gen_loss = 1.1525430919805375, disc_loss = 0.004193717658192399
Trained batch 404 in epoch 6, gen_loss = 1.1523459639078306, disc_loss = 0.004186807941346441
Trained batch 405 in epoch 6, gen_loss = 1.1521764173002667, disc_loss = 0.004179544132111108
Trained batch 406 in epoch 6, gen_loss = 1.1519965435714627, disc_loss = 0.004170758273716815
Trained batch 407 in epoch 6, gen_loss = 1.151775354409919, disc_loss = 0.00416183915170704
Trained batch 408 in epoch 6, gen_loss = 1.1519305660847055, disc_loss = 0.0041538379870954
Trained batch 409 in epoch 6, gen_loss = 1.1517241764359358, disc_loss = 0.004145962890044491
Trained batch 410 in epoch 6, gen_loss = 1.1515956680560053, disc_loss = 0.004136881021821844
Trained batch 411 in epoch 6, gen_loss = 1.1510664007617433, disc_loss = 0.004127636335273635
Trained batch 412 in epoch 6, gen_loss = 1.1504230152896762, disc_loss = 0.004118579475899152
Trained batch 413 in epoch 6, gen_loss = 1.1496854328015, disc_loss = 0.004110995159317978
Trained batch 414 in epoch 6, gen_loss = 1.1505856885967485, disc_loss = 0.0041034557360101
Trained batch 415 in epoch 6, gen_loss = 1.1505879477526133, disc_loss = 0.004096211063789759
Trained batch 416 in epoch 6, gen_loss = 1.1500885725307235, disc_loss = 0.004088718503014558
Trained batch 417 in epoch 6, gen_loss = 1.1502826434858677, disc_loss = 0.0040813555540494696
Trained batch 418 in epoch 6, gen_loss = 1.1502545396297246, disc_loss = 0.004073015036453718
Trained batch 419 in epoch 6, gen_loss = 1.150222712897119, disc_loss = 0.004064126037355025
Trained batch 420 in epoch 6, gen_loss = 1.149992024672003, disc_loss = 0.004056545222762113
Trained batch 421 in epoch 6, gen_loss = 1.1506124575273686, disc_loss = 0.004048790381305467
Trained batch 422 in epoch 6, gen_loss = 1.1513548749840288, disc_loss = 0.004041981503552367
Trained batch 423 in epoch 6, gen_loss = 1.1507672888209235, disc_loss = 0.004036219209050408
Trained batch 424 in epoch 6, gen_loss = 1.1506738375214969, disc_loss = 0.00402860914795276
Trained batch 425 in epoch 6, gen_loss = 1.150526050530689, disc_loss = 0.004020037928988562
Trained batch 426 in epoch 6, gen_loss = 1.1509922936872798, disc_loss = 0.004011693322241516
Trained batch 427 in epoch 6, gen_loss = 1.1511011242030937, disc_loss = 0.004004021293797017
Trained batch 428 in epoch 6, gen_loss = 1.1505655108631907, disc_loss = 0.0039964237571683105
Trained batch 429 in epoch 6, gen_loss = 1.150274062433908, disc_loss = 0.003987740769814483
Trained batch 430 in epoch 6, gen_loss = 1.1503487609655287, disc_loss = 0.003979664266605379
Trained batch 431 in epoch 6, gen_loss = 1.1506673983401723, disc_loss = 0.00397125427338728
Trained batch 432 in epoch 6, gen_loss = 1.1509357085128855, disc_loss = 0.003962824221468674
Trained batch 433 in epoch 6, gen_loss = 1.1510904236323274, disc_loss = 0.003954452721142931
Trained batch 434 in epoch 6, gen_loss = 1.1519990893616074, disc_loss = 0.0039460787969111495
Trained batch 435 in epoch 6, gen_loss = 1.153017836699792, disc_loss = 0.003937817082410345
Trained batch 436 in epoch 6, gen_loss = 1.1532829487078249, disc_loss = 0.003929386775926271
Trained batch 437 in epoch 6, gen_loss = 1.1528936346916303, disc_loss = 0.003921234141530248
Trained batch 438 in epoch 6, gen_loss = 1.1530091811421248, disc_loss = 0.003913642474633678
Trained batch 439 in epoch 6, gen_loss = 1.1528337234800512, disc_loss = 0.003905851486276581
Trained batch 440 in epoch 6, gen_loss = 1.1529983328042928, disc_loss = 0.0038979396547661788
Trained batch 441 in epoch 6, gen_loss = 1.1523847078306104, disc_loss = 0.0038900836068653287
Trained batch 442 in epoch 6, gen_loss = 1.1522859805862737, disc_loss = 0.003882232357253285
Trained batch 443 in epoch 6, gen_loss = 1.1515349674600739, disc_loss = 0.003874813888664043
Trained batch 444 in epoch 6, gen_loss = 1.1512990773393867, disc_loss = 0.003868209494976327
Trained batch 445 in epoch 6, gen_loss = 1.151130456694573, disc_loss = 0.003860587956704358
Trained batch 446 in epoch 6, gen_loss = 1.1510526127196532, disc_loss = 0.0038526065663098082
Trained batch 447 in epoch 6, gen_loss = 1.1508478167067682, disc_loss = 0.00384484444716041
Trained batch 448 in epoch 6, gen_loss = 1.1505941955708714, disc_loss = 0.00383755307428628
Trained batch 449 in epoch 6, gen_loss = 1.1503419307867686, disc_loss = 0.0038301520142057497
Trained batch 450 in epoch 6, gen_loss = 1.1503116287571893, disc_loss = 0.003823644310525596
Trained batch 451 in epoch 6, gen_loss = 1.15024505028155, disc_loss = 0.0038162399250401013
Trained batch 452 in epoch 6, gen_loss = 1.1500665603357698, disc_loss = 0.003808743186836248
Trained batch 453 in epoch 6, gen_loss = 1.1503757988041192, disc_loss = 0.003801042093453818
Trained batch 454 in epoch 6, gen_loss = 1.1500075318001128, disc_loss = 0.0037938225791139713
Trained batch 455 in epoch 6, gen_loss = 1.149838687950059, disc_loss = 0.00378597483154807
Trained batch 456 in epoch 6, gen_loss = 1.1500362738216994, disc_loss = 0.0037810797175174453
Trained batch 457 in epoch 6, gen_loss = 1.1497928730525304, disc_loss = 0.0037754810463248726
Trained batch 458 in epoch 6, gen_loss = 1.1498593371158592, disc_loss = 0.0037683537782804964
Trained batch 459 in epoch 6, gen_loss = 1.1494900225297264, disc_loss = 0.0037612626559364246
Trained batch 460 in epoch 6, gen_loss = 1.1492641793155878, disc_loss = 0.0037536547499569437
Trained batch 461 in epoch 6, gen_loss = 1.1492189967529083, disc_loss = 0.003746586531129549
Trained batch 462 in epoch 6, gen_loss = 1.1494495517234309, disc_loss = 0.003739593258518806
Trained batch 463 in epoch 6, gen_loss = 1.1492213189344982, disc_loss = 0.003732473553978268
Trained batch 464 in epoch 6, gen_loss = 1.1491942778710396, disc_loss = 0.0037249707141503072
Trained batch 465 in epoch 6, gen_loss = 1.1494434717642903, disc_loss = 0.00371760041414847
Trained batch 466 in epoch 6, gen_loss = 1.149457079823063, disc_loss = 0.003711082186439968
Trained batch 467 in epoch 6, gen_loss = 1.1493575125932693, disc_loss = 0.0037040399282941353
Trained batch 468 in epoch 6, gen_loss = 1.149274885908627, disc_loss = 0.0036969574247196473
Trained batch 469 in epoch 6, gen_loss = 1.148932660260099, disc_loss = 0.003690083726882647
Trained batch 470 in epoch 6, gen_loss = 1.148866642685706, disc_loss = 0.0036850475210035536
Trained batch 471 in epoch 6, gen_loss = 1.1484287109667972, disc_loss = 0.003680809636981872
Trained batch 472 in epoch 6, gen_loss = 1.1481317598018284, disc_loss = 0.003674567063223624
Trained batch 473 in epoch 6, gen_loss = 1.1478203868312675, disc_loss = 0.0036679855896293123
Trained batch 474 in epoch 6, gen_loss = 1.1482062617101167, disc_loss = 0.003661654927296025
Trained batch 475 in epoch 6, gen_loss = 1.148038296013319, disc_loss = 0.003655756288813378
Trained batch 476 in epoch 6, gen_loss = 1.1480245808885283, disc_loss = 0.0036487914345130048
Trained batch 477 in epoch 6, gen_loss = 1.1476293317194264, disc_loss = 0.0036420516166400076
Trained batch 478 in epoch 6, gen_loss = 1.1477426192207973, disc_loss = 0.0036350399726213854
Trained batch 479 in epoch 6, gen_loss = 1.1477678526192903, disc_loss = 0.0036279005240430705
Trained batch 480 in epoch 6, gen_loss = 1.147741577853284, disc_loss = 0.003620990900104486
Trained batch 481 in epoch 6, gen_loss = 1.1479277085219182, disc_loss = 0.003614232698549648
Trained batch 482 in epoch 6, gen_loss = 1.1481143454587237, disc_loss = 0.003607477048977411
Trained batch 483 in epoch 6, gen_loss = 1.1478028471065946, disc_loss = 0.0036007777810234324
Trained batch 484 in epoch 6, gen_loss = 1.1478325567294643, disc_loss = 0.003594199333702377
Trained batch 485 in epoch 6, gen_loss = 1.1482181807849632, disc_loss = 0.00358723657023772
Trained batch 486 in epoch 6, gen_loss = 1.1482293205584344, disc_loss = 0.003580386588237348
Trained batch 487 in epoch 6, gen_loss = 1.1482861280197003, disc_loss = 0.0035738397145309376
Trained batch 488 in epoch 6, gen_loss = 1.1483385434911295, disc_loss = 0.0035672087701985513
Trained batch 489 in epoch 6, gen_loss = 1.1489816250849743, disc_loss = 0.003561197543529822
Trained batch 490 in epoch 6, gen_loss = 1.1487613257225564, disc_loss = 0.00355506528845477
Trained batch 491 in epoch 6, gen_loss = 1.1483916421004428, disc_loss = 0.0035489268290204074
Trained batch 492 in epoch 6, gen_loss = 1.1484136512506806, disc_loss = 0.0035425768660711557
Trained batch 493 in epoch 6, gen_loss = 1.1483773300763567, disc_loss = 0.003536114695962464
Trained batch 494 in epoch 6, gen_loss = 1.148564464275283, disc_loss = 0.0035309536533954674
Trained batch 495 in epoch 6, gen_loss = 1.1481329087288148, disc_loss = 0.0035256827490405657
Trained batch 496 in epoch 6, gen_loss = 1.147857360197025, disc_loss = 0.0035194861559444193
Trained batch 497 in epoch 6, gen_loss = 1.1475842346149276, disc_loss = 0.003513103955836516
Trained batch 498 in epoch 6, gen_loss = 1.148336374688005, disc_loss = 0.0035069928943883637
Trained batch 499 in epoch 6, gen_loss = 1.1483853654861451, disc_loss = 0.003500396985997213
Trained batch 500 in epoch 6, gen_loss = 1.1488606351578308, disc_loss = 0.003493994564075207
Trained batch 501 in epoch 6, gen_loss = 1.14908247901149, disc_loss = 0.0034878392288087037
Trained batch 502 in epoch 6, gen_loss = 1.1490513024699853, disc_loss = 0.00348214556780254
Trained batch 503 in epoch 6, gen_loss = 1.1492988599671259, disc_loss = 0.0034760594071918775
Trained batch 504 in epoch 6, gen_loss = 1.1489755097002086, disc_loss = 0.003469662203731264
Trained batch 505 in epoch 6, gen_loss = 1.149100468328348, disc_loss = 0.0034634447848392565
Trained batch 506 in epoch 6, gen_loss = 1.1490490723408655, disc_loss = 0.003457438008954126
Trained batch 507 in epoch 6, gen_loss = 1.1487339810123594, disc_loss = 0.003451490977990549
Trained batch 508 in epoch 6, gen_loss = 1.148494553238095, disc_loss = 0.003445223135838682
Trained batch 509 in epoch 6, gen_loss = 1.1479322177522322, disc_loss = 0.003439938831319987
Trained batch 510 in epoch 6, gen_loss = 1.1479073120189973, disc_loss = 0.003436453638268214
Trained batch 511 in epoch 6, gen_loss = 1.1474059756146744, disc_loss = 0.0034322379611637643
Trained batch 512 in epoch 6, gen_loss = 1.147085696865476, disc_loss = 0.0034268267579968077
Trained batch 513 in epoch 6, gen_loss = 1.1467550836416533, disc_loss = 0.003420696023720043
Trained batch 514 in epoch 6, gen_loss = 1.146886984005715, disc_loss = 0.0034149952211080443
Trained batch 515 in epoch 6, gen_loss = 1.1469335679629051, disc_loss = 0.003409242117907193
Trained batch 516 in epoch 6, gen_loss = 1.1471499540127914, disc_loss = 0.003403516835167174
Trained batch 517 in epoch 6, gen_loss = 1.1470395484256009, disc_loss = 0.0033977053270162387
Trained batch 518 in epoch 6, gen_loss = 1.1470485178032361, disc_loss = 0.003391736669048464
Trained batch 519 in epoch 6, gen_loss = 1.147073804988311, disc_loss = 0.0033857301367019176
Trained batch 520 in epoch 6, gen_loss = 1.147046430898033, disc_loss = 0.0033796334402283095
Trained batch 521 in epoch 6, gen_loss = 1.1472356405066348, disc_loss = 0.003373589062004152
Trained batch 522 in epoch 6, gen_loss = 1.1468990807551498, disc_loss = 0.003369153716954684
Trained batch 523 in epoch 6, gen_loss = 1.1466966049589273, disc_loss = 0.003364028255800665
Trained batch 524 in epoch 6, gen_loss = 1.1464165495690846, disc_loss = 0.0033584132737624235
Trained batch 525 in epoch 6, gen_loss = 1.1460615231057083, disc_loss = 0.0033533591039254357
Trained batch 526 in epoch 6, gen_loss = 1.1460075285674498, disc_loss = 0.003348983795452992
Trained batch 527 in epoch 6, gen_loss = 1.1459947350350292, disc_loss = 0.003343344965011938
Trained batch 528 in epoch 6, gen_loss = 1.145444727349597, disc_loss = 0.003338247016137193
Trained batch 529 in epoch 6, gen_loss = 1.1454762717462936, disc_loss = 0.003332751437847037
Trained batch 530 in epoch 6, gen_loss = 1.1454944496100905, disc_loss = 0.0033276916742502414
Trained batch 531 in epoch 6, gen_loss = 1.14584279508519, disc_loss = 0.0033227420514906824
Trained batch 532 in epoch 6, gen_loss = 1.1459656414797785, disc_loss = 0.0033174413683621988
Trained batch 533 in epoch 6, gen_loss = 1.1459136027075378, disc_loss = 0.0033117604946570683
Trained batch 534 in epoch 6, gen_loss = 1.1456750780622535, disc_loss = 0.0033065660896647946
Trained batch 535 in epoch 6, gen_loss = 1.145776365452738, disc_loss = 0.0033009919934285327
Trained batch 536 in epoch 6, gen_loss = 1.1457770103848846, disc_loss = 0.0032952184107029304
Trained batch 537 in epoch 6, gen_loss = 1.1455756919977833, disc_loss = 0.0032910268033366067
Trained batch 538 in epoch 6, gen_loss = 1.1451945656526952, disc_loss = 0.003287633958916052
Trained batch 539 in epoch 6, gen_loss = 1.1450116261287973, disc_loss = 0.00328291186734633
Trained batch 540 in epoch 6, gen_loss = 1.1450070043588523, disc_loss = 0.0032774785996142297
Trained batch 541 in epoch 6, gen_loss = 1.1447939498838025, disc_loss = 0.0032725105927670734
Trained batch 542 in epoch 6, gen_loss = 1.1448776994181822, disc_loss = 0.003267061843372355
Trained batch 543 in epoch 6, gen_loss = 1.1446982172920424, disc_loss = 0.003261581080417219
Trained batch 544 in epoch 6, gen_loss = 1.1444152547678816, disc_loss = 0.00325604343729162
Trained batch 545 in epoch 6, gen_loss = 1.144297209414807, disc_loss = 0.003250877171645671
Trained batch 546 in epoch 6, gen_loss = 1.1440286204845422, disc_loss = 0.0032460677797797135
Trained batch 547 in epoch 6, gen_loss = 1.14385902533566, disc_loss = 0.0032408014599473495
Trained batch 548 in epoch 6, gen_loss = 1.1436244507739235, disc_loss = 0.0032361336965292
Trained batch 549 in epoch 6, gen_loss = 1.1437589406967164, disc_loss = 0.0032313761718317188
Trained batch 550 in epoch 6, gen_loss = 1.143581574711739, disc_loss = 0.0032262028503010284
Trained batch 551 in epoch 6, gen_loss = 1.1432112969350123, disc_loss = 0.003221557058366117
Trained batch 552 in epoch 6, gen_loss = 1.1431768600160348, disc_loss = 0.003216603200564373
Trained batch 553 in epoch 6, gen_loss = 1.1431705863467192, disc_loss = 0.003212043799507005
Trained batch 554 in epoch 6, gen_loss = 1.1431059442124925, disc_loss = 0.0032072258185016343
Trained batch 555 in epoch 6, gen_loss = 1.1430428825694023, disc_loss = 0.003202198939787378
Trained batch 556 in epoch 6, gen_loss = 1.143335801266682, disc_loss = 0.00319695318628962
Trained batch 557 in epoch 6, gen_loss = 1.1436777881823987, disc_loss = 0.0031916183183461223
Trained batch 558 in epoch 6, gen_loss = 1.1436768638000079, disc_loss = 0.0031863560896760023
Trained batch 559 in epoch 6, gen_loss = 1.143982321023941, disc_loss = 0.0031812139363215203
Trained batch 560 in epoch 6, gen_loss = 1.1437633029067367, disc_loss = 0.0031759939677851465
Trained batch 561 in epoch 6, gen_loss = 1.1437767903151461, disc_loss = 0.0031707073297530574
Trained batch 562 in epoch 6, gen_loss = 1.1434421926789766, disc_loss = 0.0031655201305148106
Trained batch 563 in epoch 6, gen_loss = 1.143572933496313, disc_loss = 0.0031603366128397704
Trained batch 564 in epoch 6, gen_loss = 1.1432517152971926, disc_loss = 0.003155176278380924
Trained batch 565 in epoch 6, gen_loss = 1.1432464756729745, disc_loss = 0.0031501701793365195
Trained batch 566 in epoch 6, gen_loss = 1.1432211085812334, disc_loss = 0.003145175203268303
Trained batch 567 in epoch 6, gen_loss = 1.1434752536071857, disc_loss = 0.0031400968326918918
Trained batch 568 in epoch 6, gen_loss = 1.143474105581877, disc_loss = 0.003135173202628149
Trained batch 569 in epoch 6, gen_loss = 1.143397351315147, disc_loss = 0.003130648991199243
Trained batch 570 in epoch 6, gen_loss = 1.1432631990746733, disc_loss = 0.003125985953094431
Trained batch 571 in epoch 6, gen_loss = 1.1429307385758087, disc_loss = 0.003122715645852756
Trained batch 572 in epoch 6, gen_loss = 1.1427153970974695, disc_loss = 0.0031180344144614612
Trained batch 573 in epoch 6, gen_loss = 1.1425490134269103, disc_loss = 0.003113717464448232
Trained batch 574 in epoch 6, gen_loss = 1.1424456523812336, disc_loss = 0.003109060366101482
Trained batch 575 in epoch 6, gen_loss = 1.1429404624634318, disc_loss = 0.003104639743216669
Trained batch 576 in epoch 6, gen_loss = 1.1433120844062528, disc_loss = 0.003100170300996247
Trained batch 577 in epoch 6, gen_loss = 1.1432985288049111, disc_loss = 0.003095936912881729
Trained batch 578 in epoch 6, gen_loss = 1.1437445751331836, disc_loss = 0.003091307913344466
Trained batch 579 in epoch 6, gen_loss = 1.143712695097101, disc_loss = 0.0030864652234695628
Trained batch 580 in epoch 6, gen_loss = 1.1435692140034266, disc_loss = 0.0030823926628818143
Trained batch 581 in epoch 6, gen_loss = 1.1433473665689684, disc_loss = 0.00307786489239393
Trained batch 582 in epoch 6, gen_loss = 1.1437878379690913, disc_loss = 0.00307303581978466
Trained batch 583 in epoch 6, gen_loss = 1.1435934770597171, disc_loss = 0.0030685042957348703
Trained batch 584 in epoch 6, gen_loss = 1.1434183257257837, disc_loss = 0.0030639054954676834
Trained batch 585 in epoch 6, gen_loss = 1.1431026741506296, disc_loss = 0.003059730026463711
Trained batch 586 in epoch 6, gen_loss = 1.142849457934118, disc_loss = 0.0030557223108499524
Trained batch 587 in epoch 6, gen_loss = 1.1429600030386529, disc_loss = 0.003051060101026859
Trained batch 588 in epoch 6, gen_loss = 1.1426803729732493, disc_loss = 0.0030465240501134586
Trained batch 589 in epoch 6, gen_loss = 1.142646900678085, disc_loss = 0.003041827710004034
Trained batch 590 in epoch 6, gen_loss = 1.1428829413380115, disc_loss = 0.0030375804860746035
Trained batch 591 in epoch 6, gen_loss = 1.1428332926856506, disc_loss = 0.0030330622575510877
Trained batch 592 in epoch 6, gen_loss = 1.1425514797135108, disc_loss = 0.003028447442999405
Trained batch 593 in epoch 6, gen_loss = 1.1423248936632266, disc_loss = 0.0030252518762324022
Trained batch 594 in epoch 6, gen_loss = 1.1422203802261033, disc_loss = 0.0030213672615403793
Trained batch 595 in epoch 6, gen_loss = 1.142190316479478, disc_loss = 0.0030172570224639636
Trained batch 596 in epoch 6, gen_loss = 1.1422951837480568, disc_loss = 0.0030127666156736658
Trained batch 597 in epoch 6, gen_loss = 1.1428902738269755, disc_loss = 0.003008105976899921
Trained batch 598 in epoch 6, gen_loss = 1.1427730553735278, disc_loss = 0.0030035957485030815
Trained batch 599 in epoch 6, gen_loss = 1.142572914659977, disc_loss = 0.0029991751822914616
Trained batch 600 in epoch 6, gen_loss = 1.1424470585515218, disc_loss = 0.0029947715905861475
Trained batch 601 in epoch 6, gen_loss = 1.142800512404933, disc_loss = 0.0029910964468487095
Trained batch 602 in epoch 6, gen_loss = 1.1425512498290977, disc_loss = 0.002986815436845522
Trained batch 603 in epoch 6, gen_loss = 1.1424868362431495, disc_loss = 0.002982895150740202
Trained batch 604 in epoch 6, gen_loss = 1.1424043014029825, disc_loss = 0.002978761218948105
Trained batch 605 in epoch 6, gen_loss = 1.142390400367995, disc_loss = 0.002975614208882911
Trained batch 606 in epoch 6, gen_loss = 1.1427569637777777, disc_loss = 0.002971297445527893
Trained batch 607 in epoch 6, gen_loss = 1.1427271757274866, disc_loss = 0.0029673609568290934
Trained batch 608 in epoch 6, gen_loss = 1.1424986992172028, disc_loss = 0.0029633771914400753
Trained batch 609 in epoch 6, gen_loss = 1.142414513474605, disc_loss = 0.0029590226142556545
Trained batch 610 in epoch 6, gen_loss = 1.1425545957982053, disc_loss = 0.0029553792618215845
Trained batch 611 in epoch 6, gen_loss = 1.142272520591231, disc_loss = 0.0029512860125453467
Trained batch 612 in epoch 6, gen_loss = 1.1421512346866665, disc_loss = 0.002946803515676719
Trained batch 613 in epoch 6, gen_loss = 1.1420411858768338, disc_loss = 0.002942746781580247
Trained batch 614 in epoch 6, gen_loss = 1.141781182890016, disc_loss = 0.0029389166247622087
Trained batch 615 in epoch 6, gen_loss = 1.1415760264574708, disc_loss = 0.0029345170220606977
Trained batch 616 in epoch 6, gen_loss = 1.141939342794774, disc_loss = 0.0029307082843767914
Trained batch 617 in epoch 6, gen_loss = 1.141868189411256, disc_loss = 0.002926694484515919
Trained batch 618 in epoch 6, gen_loss = 1.1415342621156201, disc_loss = 0.002923044811762901
Trained batch 619 in epoch 6, gen_loss = 1.1414343519556907, disc_loss = 0.0029192002750454363
Trained batch 620 in epoch 6, gen_loss = 1.1412162939131547, disc_loss = 0.0029148982393552717
Trained batch 621 in epoch 6, gen_loss = 1.1411979396818535, disc_loss = 0.0029106595692847304
Trained batch 622 in epoch 6, gen_loss = 1.141350252383402, disc_loss = 0.002906695323024374
Trained batch 623 in epoch 6, gen_loss = 1.1412511440232778, disc_loss = 0.002902346708418545
Trained batch 624 in epoch 6, gen_loss = 1.1411572365760803, disc_loss = 0.0028981397557538003
Trained batch 625 in epoch 6, gen_loss = 1.1411300961392374, disc_loss = 0.0028941011835598557
Trained batch 626 in epoch 6, gen_loss = 1.1411621035381176, disc_loss = 0.002889802139397247
Trained batch 627 in epoch 6, gen_loss = 1.1413604511766677, disc_loss = 0.002885833746404387
Trained batch 628 in epoch 6, gen_loss = 1.1411445507563545, disc_loss = 0.0028819791332352906
Trained batch 629 in epoch 6, gen_loss = 1.1410969786227696, disc_loss = 0.0028783459275949835
Trained batch 630 in epoch 6, gen_loss = 1.1408732901851273, disc_loss = 0.0028745319424735797
Trained batch 631 in epoch 6, gen_loss = 1.1406723722061025, disc_loss = 0.0028711770215591923
Trained batch 632 in epoch 6, gen_loss = 1.1404800242722317, disc_loss = 0.002867324071916815
Trained batch 633 in epoch 6, gen_loss = 1.1402761899522427, disc_loss = 0.002863172858699896
Trained batch 634 in epoch 6, gen_loss = 1.140227028234737, disc_loss = 0.002859293978764881
Trained batch 635 in epoch 6, gen_loss = 1.1406126403771106, disc_loss = 0.002855128023570071
Trained batch 636 in epoch 6, gen_loss = 1.1407012242350136, disc_loss = 0.0028513501560415272
Trained batch 637 in epoch 6, gen_loss = 1.1404009488495914, disc_loss = 0.0028473401462834774
Trained batch 638 in epoch 6, gen_loss = 1.1403034765955429, disc_loss = 0.002843650448627381
Trained batch 639 in epoch 6, gen_loss = 1.1402850869111716, disc_loss = 0.002840262921586145
Trained batch 640 in epoch 6, gen_loss = 1.1398988306615356, disc_loss = 0.0028376799998174724
Trained batch 641 in epoch 6, gen_loss = 1.140082921658721, disc_loss = 0.0028354184462181494
Trained batch 642 in epoch 6, gen_loss = 1.1401014536572838, disc_loss = 0.002831562726312494
Trained batch 643 in epoch 6, gen_loss = 1.1401315473066354, disc_loss = 0.002828038025377875
Trained batch 644 in epoch 6, gen_loss = 1.14033788535022, disc_loss = 0.0028246591024889516
Trained batch 645 in epoch 6, gen_loss = 1.1399717524693846, disc_loss = 0.0028212129130706135
Trained batch 646 in epoch 6, gen_loss = 1.1397743798112943, disc_loss = 0.002818852830218501
Trained batch 647 in epoch 6, gen_loss = 1.1399895502829258, disc_loss = 0.0028158612319573338
Trained batch 648 in epoch 6, gen_loss = 1.1397272037982207, disc_loss = 0.0028120258413655225
Trained batch 649 in epoch 6, gen_loss = 1.139486443721331, disc_loss = 0.0028089939193719497
Trained batch 650 in epoch 6, gen_loss = 1.1394180298400913, disc_loss = 0.002805385176361876
Trained batch 651 in epoch 6, gen_loss = 1.1394746655518293, disc_loss = 0.0028016536405384668
Trained batch 652 in epoch 6, gen_loss = 1.1393393244349026, disc_loss = 0.0027976964097997745
Trained batch 653 in epoch 6, gen_loss = 1.1395674044385962, disc_loss = 0.002793795601034036
Trained batch 654 in epoch 6, gen_loss = 1.1397310183248448, disc_loss = 0.0027899260559823107
Trained batch 655 in epoch 6, gen_loss = 1.1402613794113077, disc_loss = 0.002786364223871582
Trained batch 656 in epoch 6, gen_loss = 1.140083490894991, disc_loss = 0.002782504947257513
Trained batch 657 in epoch 6, gen_loss = 1.1400356971203012, disc_loss = 0.00277882299057242
Trained batch 658 in epoch 6, gen_loss = 1.1401079638955807, disc_loss = 0.0027750356320086133
Trained batch 659 in epoch 6, gen_loss = 1.1401916288065188, disc_loss = 0.0027710952637734765
Trained batch 660 in epoch 6, gen_loss = 1.140685433789569, disc_loss = 0.002767600103571332
Trained batch 661 in epoch 6, gen_loss = 1.1406106333898274, disc_loss = 0.0027645857124276364
Trained batch 662 in epoch 6, gen_loss = 1.1406926217841526, disc_loss = 0.002760816847208078
Trained batch 663 in epoch 6, gen_loss = 1.1405794405973102, disc_loss = 0.0027570315136669584
Trained batch 664 in epoch 6, gen_loss = 1.1406845391244818, disc_loss = 0.0027534846795015597
Trained batch 665 in epoch 6, gen_loss = 1.1405838184707515, disc_loss = 0.002749830711015581
Trained batch 666 in epoch 6, gen_loss = 1.1406219074393678, disc_loss = 0.0027460638971090307
Trained batch 667 in epoch 6, gen_loss = 1.1410742627824852, disc_loss = 0.0027422771631763735
Trained batch 668 in epoch 6, gen_loss = 1.1407067980645127, disc_loss = 0.0027394064765434672
Trained batch 669 in epoch 6, gen_loss = 1.1408394060917755, disc_loss = 0.0027368639051955916
Trained batch 670 in epoch 6, gen_loss = 1.140876569442351, disc_loss = 0.0027334223004840813
Trained batch 671 in epoch 6, gen_loss = 1.1413553041361628, disc_loss = 0.0027302960435398355
Trained batch 672 in epoch 6, gen_loss = 1.1414697407613361, disc_loss = 0.002726730392650074
Trained batch 673 in epoch 6, gen_loss = 1.1419597227424825, disc_loss = 0.002723041944351194
Trained batch 674 in epoch 6, gen_loss = 1.1421458639921966, disc_loss = 0.002719623536449271
Trained batch 675 in epoch 6, gen_loss = 1.1421817019140932, disc_loss = 0.002716593616602449
Trained batch 676 in epoch 6, gen_loss = 1.1424665169314407, disc_loss = 0.0027136514497700078
Trained batch 677 in epoch 6, gen_loss = 1.1421338150986529, disc_loss = 0.002710559785667914
Trained batch 678 in epoch 6, gen_loss = 1.1422322958663917, disc_loss = 0.0027078470806793523
Trained batch 679 in epoch 6, gen_loss = 1.1419868693632238, disc_loss = 0.0027051715515399874
Trained batch 680 in epoch 6, gen_loss = 1.1418224511867754, disc_loss = 0.002701611874825779
Trained batch 681 in epoch 6, gen_loss = 1.1419060908454604, disc_loss = 0.0026982363870847407
Trained batch 682 in epoch 6, gen_loss = 1.1420025778375293, disc_loss = 0.0026945064526452175
Trained batch 683 in epoch 6, gen_loss = 1.142183675229201, disc_loss = 0.0026908821815617005
Trained batch 684 in epoch 6, gen_loss = 1.142112049743207, disc_loss = 0.002687265714702713
Trained batch 685 in epoch 6, gen_loss = 1.1419487027315636, disc_loss = 0.0026835781315186487
Trained batch 686 in epoch 6, gen_loss = 1.141751014509576, disc_loss = 0.0026801069711870143
Trained batch 687 in epoch 6, gen_loss = 1.1414592039966307, disc_loss = 0.0026766121669255837
Trained batch 688 in epoch 6, gen_loss = 1.1416776912997872, disc_loss = 0.0026731255330310604
Trained batch 689 in epoch 6, gen_loss = 1.141663303668948, disc_loss = 0.002669930475847492
Trained batch 690 in epoch 6, gen_loss = 1.1418563676984541, disc_loss = 0.002666685501326316
Trained batch 691 in epoch 6, gen_loss = 1.141799839848728, disc_loss = 0.0026632192839841115
Trained batch 692 in epoch 6, gen_loss = 1.1417658986983361, disc_loss = 0.002659604832334988
Trained batch 693 in epoch 6, gen_loss = 1.1416784986123572, disc_loss = 0.0026561359079413436
Trained batch 694 in epoch 6, gen_loss = 1.1415869892072334, disc_loss = 0.002652585240044939
Trained batch 695 in epoch 6, gen_loss = 1.141641139898492, disc_loss = 0.0026490727660770396
Trained batch 696 in epoch 6, gen_loss = 1.1419041870827313, disc_loss = 0.002645534544149641
Trained batch 697 in epoch 6, gen_loss = 1.1421442767098162, disc_loss = 0.0026419276748655463
Trained batch 698 in epoch 6, gen_loss = 1.14197234099515, disc_loss = 0.002638539039037385
Trained batch 699 in epoch 6, gen_loss = 1.1422767551456179, disc_loss = 0.002635073005907803
Trained batch 700 in epoch 6, gen_loss = 1.1423692676888384, disc_loss = 0.0026317359578817982
Trained batch 701 in epoch 6, gen_loss = 1.1424537714560148, disc_loss = 0.002628331290575559
Trained batch 702 in epoch 6, gen_loss = 1.1425219491908425, disc_loss = 0.0026249898384225184
Trained batch 703 in epoch 6, gen_loss = 1.142341366969049, disc_loss = 0.002622121999303834
Trained batch 704 in epoch 6, gen_loss = 1.1420740033717867, disc_loss = 0.0026197387898383756
Trained batch 705 in epoch 6, gen_loss = 1.142056767815571, disc_loss = 0.0026167978385609122
Trained batch 706 in epoch 6, gen_loss = 1.1418765094526417, disc_loss = 0.0026141506257250278
Trained batch 707 in epoch 6, gen_loss = 1.1417504524612156, disc_loss = 0.0026116914061666994
Trained batch 708 in epoch 6, gen_loss = 1.141792310562053, disc_loss = 0.0026085133495926463
Trained batch 709 in epoch 6, gen_loss = 1.1417006886341203, disc_loss = 0.0026051706505134295
Trained batch 710 in epoch 6, gen_loss = 1.1415610394732694, disc_loss = 0.0026020081465123693
Trained batch 711 in epoch 6, gen_loss = 1.1414101991928025, disc_loss = 0.0025986335069646477
Trained batch 712 in epoch 6, gen_loss = 1.1415943464925211, disc_loss = 0.0025954196220147915
Trained batch 713 in epoch 6, gen_loss = 1.1425139403977649, disc_loss = 0.0025927680115946255
Trained batch 714 in epoch 6, gen_loss = 1.1426746412590667, disc_loss = 0.002589958346423602
Trained batch 715 in epoch 6, gen_loss = 1.1424676207357278, disc_loss = 0.0025870422123973297
Trained batch 716 in epoch 6, gen_loss = 1.1421294244762246, disc_loss = 0.002584365756866117
Trained batch 717 in epoch 6, gen_loss = 1.1422075752926404, disc_loss = 0.0025814990527821837
Trained batch 718 in epoch 6, gen_loss = 1.142042709408284, disc_loss = 0.0025789310104417343
Trained batch 719 in epoch 6, gen_loss = 1.1417239276899231, disc_loss = 0.00257630660790811
Trained batch 720 in epoch 6, gen_loss = 1.1415655515395653, disc_loss = 0.0025737367474692636
Trained batch 721 in epoch 6, gen_loss = 1.1414246151321812, disc_loss = 0.002571354110337764
Trained batch 722 in epoch 6, gen_loss = 1.1413400669480425, disc_loss = 0.0025681331984186415
Trained batch 723 in epoch 6, gen_loss = 1.141209568931253, disc_loss = 0.002565086175470056
Trained batch 724 in epoch 6, gen_loss = 1.1409397385038178, disc_loss = 0.0025620472275226474
Trained batch 725 in epoch 6, gen_loss = 1.141072433513715, disc_loss = 0.0025590125550687525
Trained batch 726 in epoch 6, gen_loss = 1.1411987218437036, disc_loss = 0.0025558959480502835
Trained batch 727 in epoch 6, gen_loss = 1.1412137142577015, disc_loss = 0.002552623119129918
Trained batch 728 in epoch 6, gen_loss = 1.1410723983505626, disc_loss = 0.0025494686484252853
Trained batch 729 in epoch 6, gen_loss = 1.1410858939771782, disc_loss = 0.0025468767915847582
Trained batch 730 in epoch 6, gen_loss = 1.1408295743931824, disc_loss = 0.0025444132387238364
Trained batch 731 in epoch 6, gen_loss = 1.1412123563836833, disc_loss = 0.0025415362991130837
Trained batch 732 in epoch 6, gen_loss = 1.1411204723511679, disc_loss = 0.0025388059755388614
Trained batch 733 in epoch 6, gen_loss = 1.1409823758075932, disc_loss = 0.0025357304170306794
Trained batch 734 in epoch 6, gen_loss = 1.1405880899656387, disc_loss = 0.0025326579792756066
Trained batch 735 in epoch 6, gen_loss = 1.140500366282852, disc_loss = 0.0025304213867773638
Trained batch 736 in epoch 6, gen_loss = 1.140694632378168, disc_loss = 0.0025276828268702423
Trained batch 737 in epoch 6, gen_loss = 1.1408511050509889, disc_loss = 0.0025246256136350893
Trained batch 738 in epoch 6, gen_loss = 1.1412429845865428, disc_loss = 0.0025222374951816323
Trained batch 739 in epoch 6, gen_loss = 1.1412419113758447, disc_loss = 0.002519645570085944
Trained batch 740 in epoch 6, gen_loss = 1.1410281297005462, disc_loss = 0.002516546177945047
Trained batch 741 in epoch 6, gen_loss = 1.140908805266866, disc_loss = 0.0025136919283724486
Trained batch 742 in epoch 6, gen_loss = 1.140864435387813, disc_loss = 0.002510797299665128
Trained batch 743 in epoch 6, gen_loss = 1.1407358823444254, disc_loss = 0.002507762473478872
Trained batch 744 in epoch 6, gen_loss = 1.1406598943191886, disc_loss = 0.0025048542324173882
Trained batch 745 in epoch 6, gen_loss = 1.1403578899341358, disc_loss = 0.0025021558705395543
Trained batch 746 in epoch 6, gen_loss = 1.1403502430941366, disc_loss = 0.0025001554047245312
Trained batch 747 in epoch 6, gen_loss = 1.140292148937516, disc_loss = 0.002497295863324257
Trained batch 748 in epoch 6, gen_loss = 1.1401896611234057, disc_loss = 0.002495051737502808
Trained batch 749 in epoch 6, gen_loss = 1.1400622657934825, disc_loss = 0.0024921443213825113
Trained batch 750 in epoch 6, gen_loss = 1.1397976836415327, disc_loss = 0.0024891932087911036
Trained batch 751 in epoch 6, gen_loss = 1.13944042608776, disc_loss = 0.0024866208062295746
Trained batch 752 in epoch 6, gen_loss = 1.139486332101176, disc_loss = 0.0024845335291240026
Trained batch 753 in epoch 6, gen_loss = 1.1394851039353986, disc_loss = 0.00248218211887694
Trained batch 754 in epoch 6, gen_loss = 1.139397626444204, disc_loss = 0.0024793635996171143
Trained batch 755 in epoch 6, gen_loss = 1.1391608927142682, disc_loss = 0.0024765183217015066
Trained batch 756 in epoch 6, gen_loss = 1.139139750910876, disc_loss = 0.0024738081967077665
Trained batch 757 in epoch 6, gen_loss = 1.1391511061732562, disc_loss = 0.0024710347832220185
Trained batch 758 in epoch 6, gen_loss = 1.139271977155105, disc_loss = 0.0024680558299930763
Trained batch 759 in epoch 6, gen_loss = 1.1392023881015025, disc_loss = 0.002465361111554605
Trained batch 760 in epoch 6, gen_loss = 1.1392808930945928, disc_loss = 0.0024628949724833826
Trained batch 761 in epoch 6, gen_loss = 1.1390951337620343, disc_loss = 0.0024608606689362393
Trained batch 762 in epoch 6, gen_loss = 1.1389697679998365, disc_loss = 0.002458541230175755
Trained batch 763 in epoch 6, gen_loss = 1.1387913614823557, disc_loss = 0.0024557885866746594
Trained batch 764 in epoch 6, gen_loss = 1.1385350069189384, disc_loss = 0.0024528028303452956
Trained batch 765 in epoch 6, gen_loss = 1.1386045467293293, disc_loss = 0.00245000161084665
Trained batch 766 in epoch 6, gen_loss = 1.1385521398373968, disc_loss = 0.0024471955845995186
Trained batch 767 in epoch 6, gen_loss = 1.1386305957566947, disc_loss = 0.002444438642972576
Trained batch 768 in epoch 6, gen_loss = 1.1385701506438584, disc_loss = 0.0024417212235369515
Trained batch 769 in epoch 6, gen_loss = 1.1386478643138687, disc_loss = 0.0024389293097721583
Trained batch 770 in epoch 6, gen_loss = 1.1384164654636506, disc_loss = 0.0024363272263965632
Trained batch 771 in epoch 6, gen_loss = 1.1382452759100365, disc_loss = 0.002433534965013791
Trained batch 772 in epoch 6, gen_loss = 1.138198370458546, disc_loss = 0.0024306015361317
Trained batch 773 in epoch 6, gen_loss = 1.1379072013905498, disc_loss = 0.0024278093448748934
Trained batch 774 in epoch 6, gen_loss = 1.1376618734482795, disc_loss = 0.002425125670720703
Trained batch 775 in epoch 6, gen_loss = 1.1376970829730182, disc_loss = 0.0024223976566439156
Trained batch 776 in epoch 6, gen_loss = 1.1380935230770626, disc_loss = 0.002419889937801451
Trained batch 777 in epoch 6, gen_loss = 1.1380597472497307, disc_loss = 0.002417063345725781
Trained batch 778 in epoch 6, gen_loss = 1.1378858888256382, disc_loss = 0.0024144992685916538
Trained batch 779 in epoch 6, gen_loss = 1.1382079475965254, disc_loss = 0.0024117340818263938
Trained batch 780 in epoch 6, gen_loss = 1.1384533935258696, disc_loss = 0.0024091581283228127
Trained batch 781 in epoch 6, gen_loss = 1.1382915830368276, disc_loss = 0.0024064099289040092
Trained batch 782 in epoch 6, gen_loss = 1.138344982574726, disc_loss = 0.002403505534554521
Trained batch 783 in epoch 6, gen_loss = 1.138159521760381, disc_loss = 0.002400813320083235
Trained batch 784 in epoch 6, gen_loss = 1.138234925194151, disc_loss = 0.0023985697190087455
Trained batch 785 in epoch 6, gen_loss = 1.138439504472354, disc_loss = 0.00239590825843293
Trained batch 786 in epoch 6, gen_loss = 1.1383604561812997, disc_loss = 0.002393151910704433
Trained batch 787 in epoch 6, gen_loss = 1.1382728476966093, disc_loss = 0.002390303833104775
Trained batch 788 in epoch 6, gen_loss = 1.138279576340858, disc_loss = 0.0023875828879123735
Trained batch 789 in epoch 6, gen_loss = 1.1381336025799378, disc_loss = 0.002384825071535085
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 1.1430952548980713, disc_loss = 0.0002887313603423536
Trained batch 1 in epoch 7, gen_loss = 1.1423761248588562, disc_loss = 0.00034478209272492677
Trained batch 2 in epoch 7, gen_loss = 1.1757829984029133, disc_loss = 0.0004007690295111388
Trained batch 3 in epoch 7, gen_loss = 1.1601037979125977, disc_loss = 0.0005028961822972633
Trained batch 4 in epoch 7, gen_loss = 1.1233102798461914, disc_loss = 0.0005246919638011605
Trained batch 5 in epoch 7, gen_loss = 1.1394307216008503, disc_loss = 0.0004780223195363457
Trained batch 6 in epoch 7, gen_loss = 1.1224804776055473, disc_loss = 0.0004435533150431833
Trained batch 7 in epoch 7, gen_loss = 1.1447046399116516, disc_loss = 0.0004313705394451972
Trained batch 8 in epoch 7, gen_loss = 1.1335508823394775, disc_loss = 0.00044835352067214745
Trained batch 9 in epoch 7, gen_loss = 1.1703416585922242, disc_loss = 0.0004379445657832548
Trained batch 10 in epoch 7, gen_loss = 1.1588424227454446, disc_loss = 0.0004205778664485975
Trained batch 11 in epoch 7, gen_loss = 1.159139444430669, disc_loss = 0.0004400029089689876
Trained batch 12 in epoch 7, gen_loss = 1.171422655765827, disc_loss = 0.00048585163089088525
Trained batch 13 in epoch 7, gen_loss = 1.1751422882080078, disc_loss = 0.0004972992340169315
Trained batch 14 in epoch 7, gen_loss = 1.177415625254313, disc_loss = 0.000488562286288167
Trained batch 15 in epoch 7, gen_loss = 1.175022378563881, disc_loss = 0.0004703178237832617
Trained batch 16 in epoch 7, gen_loss = 1.1778439353494083, disc_loss = 0.0004655959372244337
Trained batch 17 in epoch 7, gen_loss = 1.1697153117921617, disc_loss = 0.0004556847286746941
Trained batch 18 in epoch 7, gen_loss = 1.1572822175527875, disc_loss = 0.0004471133625453436
Trained batch 19 in epoch 7, gen_loss = 1.1541759759187697, disc_loss = 0.00044464114180300387
Trained batch 20 in epoch 7, gen_loss = 1.157167551063356, disc_loss = 0.00043457768610789485
Trained batch 21 in epoch 7, gen_loss = 1.1634799377484755, disc_loss = 0.0004332416488482109
Trained batch 22 in epoch 7, gen_loss = 1.1645071947056314, disc_loss = 0.0004404983072005131
Trained batch 23 in epoch 7, gen_loss = 1.1629418755571048, disc_loss = 0.0004324171853416677
Trained batch 24 in epoch 7, gen_loss = 1.1686373162269592, disc_loss = 0.00042474470159504563
Trained batch 25 in epoch 7, gen_loss = 1.1706956923007965, disc_loss = 0.0004293899541013301
Trained batch 26 in epoch 7, gen_loss = 1.1801662467144154, disc_loss = 0.00043791047722118457
Trained batch 27 in epoch 7, gen_loss = 1.1727395462138313, disc_loss = 0.00048724204628212774
Trained batch 28 in epoch 7, gen_loss = 1.1669942120025898, disc_loss = 0.0005236269553906509
Trained batch 29 in epoch 7, gen_loss = 1.17121435602506, disc_loss = 0.000528774954242787
Trained batch 30 in epoch 7, gen_loss = 1.1695359195432355, disc_loss = 0.0005490225857131243
Trained batch 31 in epoch 7, gen_loss = 1.1714720632880926, disc_loss = 0.0005723242616113566
Trained batch 32 in epoch 7, gen_loss = 1.1683399659214597, disc_loss = 0.0005725569759361503
Trained batch 33 in epoch 7, gen_loss = 1.1615724931744968, disc_loss = 0.0005848852558890084
Trained batch 34 in epoch 7, gen_loss = 1.1584597264017378, disc_loss = 0.0005918305504435141
Trained batch 35 in epoch 7, gen_loss = 1.1622515271107356, disc_loss = 0.0005927502113788958
Trained batch 36 in epoch 7, gen_loss = 1.1573541067742013, disc_loss = 0.0005883013910607662
Trained batch 37 in epoch 7, gen_loss = 1.1572216937416477, disc_loss = 0.0005857190251270751
Trained batch 38 in epoch 7, gen_loss = 1.1542538435031207, disc_loss = 0.000576534659604733
Trained batch 39 in epoch 7, gen_loss = 1.1518148839473725, disc_loss = 0.0005728495150833623
Trained batch 40 in epoch 7, gen_loss = 1.1504385122438756, disc_loss = 0.0005689201554959277
Trained batch 41 in epoch 7, gen_loss = 1.1469427318800063, disc_loss = 0.0005645483806368983
Trained batch 42 in epoch 7, gen_loss = 1.1406840349352636, disc_loss = 0.0005569762352659086
Trained batch 43 in epoch 7, gen_loss = 1.1424701931801708, disc_loss = 0.0005515645012068985
Trained batch 44 in epoch 7, gen_loss = 1.1381131264898512, disc_loss = 0.0005444559592029287
Trained batch 45 in epoch 7, gen_loss = 1.1377114407394244, disc_loss = 0.0005362937789987368
Trained batch 46 in epoch 7, gen_loss = 1.1431210814638342, disc_loss = 0.000532183802359678
Trained batch 47 in epoch 7, gen_loss = 1.1456429945925872, disc_loss = 0.0005282623836440811
Trained batch 48 in epoch 7, gen_loss = 1.1451065065909405, disc_loss = 0.0005215346377832359
Trained batch 49 in epoch 7, gen_loss = 1.1470249283313751, disc_loss = 0.0005175719954422676
Trained batch 50 in epoch 7, gen_loss = 1.1412665890712363, disc_loss = 0.0005190947624357125
Trained batch 51 in epoch 7, gen_loss = 1.1446353013698871, disc_loss = 0.000519036512112227
Trained batch 52 in epoch 7, gen_loss = 1.1451168645103023, disc_loss = 0.0005162595054639925
Trained batch 53 in epoch 7, gen_loss = 1.1467641062206693, disc_loss = 0.0005205787620744323
Trained batch 54 in epoch 7, gen_loss = 1.1465809865431351, disc_loss = 0.000526679808601991
Trained batch 55 in epoch 7, gen_loss = 1.1453742725508553, disc_loss = 0.0005269511776922238
Trained batch 56 in epoch 7, gen_loss = 1.1449098712519596, disc_loss = 0.0005231484474120008
Trained batch 57 in epoch 7, gen_loss = 1.147540452151463, disc_loss = 0.0005173704683266837
Trained batch 58 in epoch 7, gen_loss = 1.1473829968500946, disc_loss = 0.0005209703043781978
Trained batch 59 in epoch 7, gen_loss = 1.1489665706952412, disc_loss = 0.0005336209753295407
Trained batch 60 in epoch 7, gen_loss = 1.1466557061085936, disc_loss = 0.0005417487299695733
Trained batch 61 in epoch 7, gen_loss = 1.1464948423447148, disc_loss = 0.000540608043534561
Trained batch 62 in epoch 7, gen_loss = 1.143235785620553, disc_loss = 0.0005366105885644044
Trained batch 63 in epoch 7, gen_loss = 1.1455338597297668, disc_loss = 0.0005358771650207927
Trained batch 64 in epoch 7, gen_loss = 1.1435788246301504, disc_loss = 0.0005400338004199931
Trained batch 65 in epoch 7, gen_loss = 1.145111858844757, disc_loss = 0.0005414866159712387
Trained batch 66 in epoch 7, gen_loss = 1.1422732232221917, disc_loss = 0.0005430618488688522
Trained batch 67 in epoch 7, gen_loss = 1.1422417339156656, disc_loss = 0.0005389497005928527
Trained batch 68 in epoch 7, gen_loss = 1.1427319326262544, disc_loss = 0.0005338949065291039
Trained batch 69 in epoch 7, gen_loss = 1.143746280670166, disc_loss = 0.0005300565764108407
Trained batch 70 in epoch 7, gen_loss = 1.146147501300758, disc_loss = 0.0005282132089479078
Trained batch 71 in epoch 7, gen_loss = 1.1499745200077693, disc_loss = 0.0005259710928334647
Trained batch 72 in epoch 7, gen_loss = 1.148338603646788, disc_loss = 0.0005264582793381422
Trained batch 73 in epoch 7, gen_loss = 1.1467971495679907, disc_loss = 0.0005215551929133064
Trained batch 74 in epoch 7, gen_loss = 1.1452225335439046, disc_loss = 0.0005198508586424092
Trained batch 75 in epoch 7, gen_loss = 1.148587355488225, disc_loss = 0.0005185074535946018
Trained batch 76 in epoch 7, gen_loss = 1.1483196809694365, disc_loss = 0.0005149044869044287
Trained batch 77 in epoch 7, gen_loss = 1.1471052353198712, disc_loss = 0.0005141780331121901
Trained batch 78 in epoch 7, gen_loss = 1.1471473355836506, disc_loss = 0.0005137398301128628
Trained batch 79 in epoch 7, gen_loss = 1.1480750992894173, disc_loss = 0.0005129090597620234
Trained batch 80 in epoch 7, gen_loss = 1.1485462056265936, disc_loss = 0.0005094109898588309
Trained batch 81 in epoch 7, gen_loss = 1.1491244507998954, disc_loss = 0.0005063804738910687
Trained batch 82 in epoch 7, gen_loss = 1.148333954523845, disc_loss = 0.0005056840281355677
Trained batch 83 in epoch 7, gen_loss = 1.1476676237015497, disc_loss = 0.0005034518728193472
Trained batch 84 in epoch 7, gen_loss = 1.1481250145856072, disc_loss = 0.000499768610632814
Trained batch 85 in epoch 7, gen_loss = 1.1467715002769647, disc_loss = 0.0004971678288204076
Trained batch 86 in epoch 7, gen_loss = 1.1463701478366195, disc_loss = 0.0004949975058291878
Trained batch 87 in epoch 7, gen_loss = 1.148710073395209, disc_loss = 0.0004920430141778938
Trained batch 88 in epoch 7, gen_loss = 1.1485396971863306, disc_loss = 0.00049037370013905
Trained batch 89 in epoch 7, gen_loss = 1.1467105673419105, disc_loss = 0.0004924792329095201
Trained batch 90 in epoch 7, gen_loss = 1.1482585334515834, disc_loss = 0.0004905785638954143
Trained batch 91 in epoch 7, gen_loss = 1.1474577363418497, disc_loss = 0.00048746040445858733
Trained batch 92 in epoch 7, gen_loss = 1.1482256144605658, disc_loss = 0.0004839492989616388
Trained batch 93 in epoch 7, gen_loss = 1.148338996983589, disc_loss = 0.0004811096762150942
Trained batch 94 in epoch 7, gen_loss = 1.1489458429185968, disc_loss = 0.0004777944559464231
Trained batch 95 in epoch 7, gen_loss = 1.1511618575702112, disc_loss = 0.0004744007137560402
Trained batch 96 in epoch 7, gen_loss = 1.1497020211416422, disc_loss = 0.0004724067006951448
Trained batch 97 in epoch 7, gen_loss = 1.1503484316018162, disc_loss = 0.0004694153250632237
Trained batch 98 in epoch 7, gen_loss = 1.1504553538380247, disc_loss = 0.0004661346777198799
Trained batch 99 in epoch 7, gen_loss = 1.1514435356855393, disc_loss = 0.0004633034353901166
Trained batch 100 in epoch 7, gen_loss = 1.1549706016436663, disc_loss = 0.00046044529319422706
Trained batch 101 in epoch 7, gen_loss = 1.1529787971692926, disc_loss = 0.00045813062909063793
Trained batch 102 in epoch 7, gen_loss = 1.1524496477784463, disc_loss = 0.00045587793340142455
Trained batch 103 in epoch 7, gen_loss = 1.1510775278394039, disc_loss = 0.0004537064718393734
Trained batch 104 in epoch 7, gen_loss = 1.1493301136153085, disc_loss = 0.00045190076773343166
Trained batch 105 in epoch 7, gen_loss = 1.1507984000556875, disc_loss = 0.00045052184413059805
Trained batch 106 in epoch 7, gen_loss = 1.148932192927209, disc_loss = 0.0004492583718623043
Trained batch 107 in epoch 7, gen_loss = 1.1475670172108545, disc_loss = 0.0004481875074378439
Trained batch 108 in epoch 7, gen_loss = 1.1466678741875045, disc_loss = 0.0004472924670612508
Trained batch 109 in epoch 7, gen_loss = 1.1464248234575445, disc_loss = 0.0004450949031954885
Trained batch 110 in epoch 7, gen_loss = 1.1473302873405251, disc_loss = 0.0004425498775965828
Trained batch 111 in epoch 7, gen_loss = 1.1473344734736852, disc_loss = 0.00043988444472883463
Trained batch 112 in epoch 7, gen_loss = 1.1463944437229527, disc_loss = 0.0004388020481796836
Trained batch 113 in epoch 7, gen_loss = 1.1454941944072121, disc_loss = 0.0004405956714068899
Trained batch 114 in epoch 7, gen_loss = 1.1459910029950349, disc_loss = 0.0004401936434948331
Trained batch 115 in epoch 7, gen_loss = 1.1446434937674423, disc_loss = 0.00044112889598432834
Trained batch 116 in epoch 7, gen_loss = 1.1439197634020422, disc_loss = 0.0004383266598616058
Trained batch 117 in epoch 7, gen_loss = 1.1435971967244551, disc_loss = 0.0004366534396190141
Trained batch 118 in epoch 7, gen_loss = 1.1428829762114197, disc_loss = 0.00043415224653846747
Trained batch 119 in epoch 7, gen_loss = 1.1415124545494715, disc_loss = 0.000432044160879741
Trained batch 120 in epoch 7, gen_loss = 1.143226533881889, disc_loss = 0.00043006295746929313
Trained batch 121 in epoch 7, gen_loss = 1.1430580410800997, disc_loss = 0.00042787993050773904
Trained batch 122 in epoch 7, gen_loss = 1.1411398469917173, disc_loss = 0.00042614095771687134
Trained batch 123 in epoch 7, gen_loss = 1.1427620173461976, disc_loss = 0.00042417051155362354
Trained batch 124 in epoch 7, gen_loss = 1.1414191136360168, disc_loss = 0.00042296080017695204
Trained batch 125 in epoch 7, gen_loss = 1.1431574447760506, disc_loss = 0.00042129751223939587
Trained batch 126 in epoch 7, gen_loss = 1.142220543594811, disc_loss = 0.00041938622982386046
Trained batch 127 in epoch 7, gen_loss = 1.1426011151634157, disc_loss = 0.00041720430630221017
Trained batch 128 in epoch 7, gen_loss = 1.1423893857371898, disc_loss = 0.0004153450434443599
Trained batch 129 in epoch 7, gen_loss = 1.1420091083416573, disc_loss = 0.0004137340324702494
Trained batch 130 in epoch 7, gen_loss = 1.1415287633888593, disc_loss = 0.0004114886973642403
Trained batch 131 in epoch 7, gen_loss = 1.1401428377086467, disc_loss = 0.00040949160806617743
Trained batch 132 in epoch 7, gen_loss = 1.138634737272908, disc_loss = 0.00040800792224840015
Trained batch 133 in epoch 7, gen_loss = 1.1392314229438554, disc_loss = 0.0004073674539160574
Trained batch 134 in epoch 7, gen_loss = 1.1372761125917787, disc_loss = 0.00040688522023157457
Trained batch 135 in epoch 7, gen_loss = 1.1375665585784351, disc_loss = 0.00040779127261082656
Trained batch 136 in epoch 7, gen_loss = 1.1377098690854373, disc_loss = 0.00040807891353483847
Trained batch 137 in epoch 7, gen_loss = 1.1378684734952622, disc_loss = 0.0004067137238777924
Trained batch 138 in epoch 7, gen_loss = 1.136898467866637, disc_loss = 0.00040524240587159604
Trained batch 139 in epoch 7, gen_loss = 1.1354220743690218, disc_loss = 0.00040388470468834774
Trained batch 140 in epoch 7, gen_loss = 1.1361563083127881, disc_loss = 0.00040242586862617867
Trained batch 141 in epoch 7, gen_loss = 1.1360741580875826, disc_loss = 0.0004009540994880347
Trained batch 142 in epoch 7, gen_loss = 1.1368271566771126, disc_loss = 0.0003992547956274959
Trained batch 143 in epoch 7, gen_loss = 1.136830796384149, disc_loss = 0.0003974424889242477
Trained batch 144 in epoch 7, gen_loss = 1.1354549247643044, disc_loss = 0.00039690810547748196
Trained batch 145 in epoch 7, gen_loss = 1.1350659454522067, disc_loss = 0.00039916434591398444
Trained batch 146 in epoch 7, gen_loss = 1.1343415963406465, disc_loss = 0.00040124666311447095
Trained batch 147 in epoch 7, gen_loss = 1.1339933159383568, disc_loss = 0.000401123455909279
Trained batch 148 in epoch 7, gen_loss = 1.1328414162533396, disc_loss = 0.0004007801365778444
Trained batch 149 in epoch 7, gen_loss = 1.1340957454840341, disc_loss = 0.0003994068315660115
Trained batch 150 in epoch 7, gen_loss = 1.1338719086141775, disc_loss = 0.0003983756284547865
Trained batch 151 in epoch 7, gen_loss = 1.1343776564064778, disc_loss = 0.0003980041771539714
Trained batch 152 in epoch 7, gen_loss = 1.1325997531024459, disc_loss = 0.00039768748688610465
Trained batch 153 in epoch 7, gen_loss = 1.1333812541001802, disc_loss = 0.00039745972030864147
Trained batch 154 in epoch 7, gen_loss = 1.1340577237067684, disc_loss = 0.00039626122532119494
Trained batch 155 in epoch 7, gen_loss = 1.1325781177251766, disc_loss = 0.0003962025999405738
Trained batch 156 in epoch 7, gen_loss = 1.1322368808612702, disc_loss = 0.0003984930458761141
Trained batch 157 in epoch 7, gen_loss = 1.1320328229590306, disc_loss = 0.0003997992521650718
Trained batch 158 in epoch 7, gen_loss = 1.1335497232353162, disc_loss = 0.00039881804421486967
Trained batch 159 in epoch 7, gen_loss = 1.1326174482703208, disc_loss = 0.0003986031881595409
Trained batch 160 in epoch 7, gen_loss = 1.1310553010206046, disc_loss = 0.0003980389465480285
Trained batch 161 in epoch 7, gen_loss = 1.130922599339191, disc_loss = 0.0003974134215016499
Trained batch 162 in epoch 7, gen_loss = 1.1309686928438993, disc_loss = 0.00039621807144350584
Trained batch 163 in epoch 7, gen_loss = 1.1310281121149295, disc_loss = 0.00039542838119193286
Trained batch 164 in epoch 7, gen_loss = 1.1302806608604663, disc_loss = 0.0003941817811926629
Trained batch 165 in epoch 7, gen_loss = 1.1307049005864613, disc_loss = 0.0003959381372470785
Trained batch 166 in epoch 7, gen_loss = 1.1316584398646554, disc_loss = 0.0003983682316632434
Trained batch 167 in epoch 7, gen_loss = 1.131001462539037, disc_loss = 0.0003976012715481504
Trained batch 168 in epoch 7, gen_loss = 1.1306571346768262, disc_loss = 0.0003979015756056082
Trained batch 169 in epoch 7, gen_loss = 1.1302862959749558, disc_loss = 0.0003994124119344633
Trained batch 170 in epoch 7, gen_loss = 1.1310625640969527, disc_loss = 0.00039841871219653123
Trained batch 171 in epoch 7, gen_loss = 1.1318836690381515, disc_loss = 0.0003973383816120859
Trained batch 172 in epoch 7, gen_loss = 1.1315949169886594, disc_loss = 0.00039585405718259287
Trained batch 173 in epoch 7, gen_loss = 1.1309717194787388, disc_loss = 0.0003951510535161701
Trained batch 174 in epoch 7, gen_loss = 1.1304063252040317, disc_loss = 0.00039494163718440436
Trained batch 175 in epoch 7, gen_loss = 1.1304455135356297, disc_loss = 0.00039378503586042575
Trained batch 176 in epoch 7, gen_loss = 1.1301512940455292, disc_loss = 0.0003923457459955066
Trained batch 177 in epoch 7, gen_loss = 1.1308098261275987, disc_loss = 0.00039142332360406115
Trained batch 178 in epoch 7, gen_loss = 1.1307054478362952, disc_loss = 0.00038996436362455253
Trained batch 179 in epoch 7, gen_loss = 1.1311941338909997, disc_loss = 0.00038896692862585447
Trained batch 180 in epoch 7, gen_loss = 1.1319070316809976, disc_loss = 0.000388797788917105
Trained batch 181 in epoch 7, gen_loss = 1.131975566947853, disc_loss = 0.000389066177836407
Trained batch 182 in epoch 7, gen_loss = 1.1317034920708078, disc_loss = 0.00038827241044854136
Trained batch 183 in epoch 7, gen_loss = 1.1316702650940937, disc_loss = 0.00038745964716129134
Trained batch 184 in epoch 7, gen_loss = 1.1312450286504385, disc_loss = 0.00038600197393050717
Trained batch 185 in epoch 7, gen_loss = 1.13174250882159, disc_loss = 0.0003847376012286517
Trained batch 186 in epoch 7, gen_loss = 1.132567668981093, disc_loss = 0.0003833703162975953
Trained batch 187 in epoch 7, gen_loss = 1.132100779325404, disc_loss = 0.0003823529143041827
Trained batch 188 in epoch 7, gen_loss = 1.1327652483390123, disc_loss = 0.00038126230206144676
Trained batch 189 in epoch 7, gen_loss = 1.1316253279384814, disc_loss = 0.00038030676296330057
Trained batch 190 in epoch 7, gen_loss = 1.1319129460769175, disc_loss = 0.00037892856651914665
Trained batch 191 in epoch 7, gen_loss = 1.1323218426356714, disc_loss = 0.0003783886670589709
Trained batch 192 in epoch 7, gen_loss = 1.1310231735051606, disc_loss = 0.0003802463658234838
Trained batch 193 in epoch 7, gen_loss = 1.1306013790602536, disc_loss = 0.0003796394859031371
Trained batch 194 in epoch 7, gen_loss = 1.1308328659106524, disc_loss = 0.0003792512365646708
Trained batch 195 in epoch 7, gen_loss = 1.1302775412189716, disc_loss = 0.0003786744014270917
Trained batch 196 in epoch 7, gen_loss = 1.1313054948893901, disc_loss = 0.0003778287372817782
Trained batch 197 in epoch 7, gen_loss = 1.1334534739003037, disc_loss = 0.0003774577722798873
Trained batch 198 in epoch 7, gen_loss = 1.1330691647889026, disc_loss = 0.0003769263653956288
Trained batch 199 in epoch 7, gen_loss = 1.132696459889412, disc_loss = 0.00037607651007419917
Trained batch 200 in epoch 7, gen_loss = 1.1315303275834268, disc_loss = 0.00037617997542331783
Trained batch 201 in epoch 7, gen_loss = 1.1324087782661514, disc_loss = 0.0003758450682041014
Trained batch 202 in epoch 7, gen_loss = 1.1325259361361049, disc_loss = 0.0003745244672792055
Trained batch 203 in epoch 7, gen_loss = 1.132761782875248, disc_loss = 0.00037341529380629417
Trained batch 204 in epoch 7, gen_loss = 1.1317999752556405, disc_loss = 0.0003726755930096615
Trained batch 205 in epoch 7, gen_loss = 1.1321201984164784, disc_loss = 0.00037218626863091454
Trained batch 206 in epoch 7, gen_loss = 1.1316570625213034, disc_loss = 0.0003711255149511454
Trained batch 207 in epoch 7, gen_loss = 1.1320834561036184, disc_loss = 0.0003708416493981741
Trained batch 208 in epoch 7, gen_loss = 1.1321793537961238, disc_loss = 0.0003700772229413297
Trained batch 209 in epoch 7, gen_loss = 1.1322332251639593, disc_loss = 0.00036940689477930953
Trained batch 210 in epoch 7, gen_loss = 1.1309387418331127, disc_loss = 0.0003701512294838545
Trained batch 211 in epoch 7, gen_loss = 1.130802166911791, disc_loss = 0.0003728540473876253
Trained batch 212 in epoch 7, gen_loss = 1.130994908686535, disc_loss = 0.0003720363744487002
Trained batch 213 in epoch 7, gen_loss = 1.131463412926576, disc_loss = 0.00037213123450953315
Trained batch 214 in epoch 7, gen_loss = 1.1316153337789137, disc_loss = 0.0003712588553330428
Trained batch 215 in epoch 7, gen_loss = 1.132386051946216, disc_loss = 0.0003705623075465728
Trained batch 216 in epoch 7, gen_loss = 1.1327325253992038, disc_loss = 0.00036950984082269496
Trained batch 217 in epoch 7, gen_loss = 1.1320352606270292, disc_loss = 0.00036943673714648275
Trained batch 218 in epoch 7, gen_loss = 1.1320528578540505, disc_loss = 0.0003691602211706574
Trained batch 219 in epoch 7, gen_loss = 1.131458602981134, disc_loss = 0.0003687749182559359
Trained batch 220 in epoch 7, gen_loss = 1.132406335880314, disc_loss = 0.00036797829489755693
Trained batch 221 in epoch 7, gen_loss = 1.131858338912328, disc_loss = 0.00036738833850003184
Trained batch 222 in epoch 7, gen_loss = 1.1314509361314131, disc_loss = 0.00036718738448702744
Trained batch 223 in epoch 7, gen_loss = 1.131690965433206, disc_loss = 0.0003665837184923605
Trained batch 224 in epoch 7, gen_loss = 1.1304245890511406, disc_loss = 0.00036719158489076007
Trained batch 225 in epoch 7, gen_loss = 1.129465159325473, disc_loss = 0.0003682903916664129
Trained batch 226 in epoch 7, gen_loss = 1.1295518993281057, disc_loss = 0.000367754064932402
Trained batch 227 in epoch 7, gen_loss = 1.129156284426388, disc_loss = 0.0003678727412319093
Trained batch 228 in epoch 7, gen_loss = 1.1295363562075853, disc_loss = 0.00036744062927186565
Trained batch 229 in epoch 7, gen_loss = 1.1295862309310747, disc_loss = 0.0003671204585533933
Trained batch 230 in epoch 7, gen_loss = 1.1295603340838378, disc_loss = 0.0003661963291724769
Trained batch 231 in epoch 7, gen_loss = 1.129307706551305, disc_loss = 0.0003662534785501615
Trained batch 232 in epoch 7, gen_loss = 1.1294902151234671, disc_loss = 0.0003658170103159925
Trained batch 233 in epoch 7, gen_loss = 1.1295315478092585, disc_loss = 0.00036515392875870986
Trained batch 234 in epoch 7, gen_loss = 1.1296885518317528, disc_loss = 0.00036421087332084734
Trained batch 235 in epoch 7, gen_loss = 1.1306527481745865, disc_loss = 0.0003634061016844313
Trained batch 236 in epoch 7, gen_loss = 1.1306558211141498, disc_loss = 0.0003625054345213227
Trained batch 237 in epoch 7, gen_loss = 1.1304481562947024, disc_loss = 0.00036145160381903307
Trained batch 238 in epoch 7, gen_loss = 1.1303809788935355, disc_loss = 0.00036083542853623053
Trained batch 239 in epoch 7, gen_loss = 1.1296951693793138, disc_loss = 0.0003603788551724089
Trained batch 240 in epoch 7, gen_loss = 1.1295527603121713, disc_loss = 0.00035975012280717414
Trained batch 241 in epoch 7, gen_loss = 1.1284540327619914, disc_loss = 0.0003590289424442925
Trained batch 242 in epoch 7, gen_loss = 1.1277419546994654, disc_loss = 0.0003589137156451803
Trained batch 243 in epoch 7, gen_loss = 1.1268289042789428, disc_loss = 0.0003596783036434809
Trained batch 244 in epoch 7, gen_loss = 1.1263142062693225, disc_loss = 0.00036183672372669894
Trained batch 245 in epoch 7, gen_loss = 1.1259587317462858, disc_loss = 0.0003633903350389555
Trained batch 246 in epoch 7, gen_loss = 1.1253110525096477, disc_loss = 0.000365577240593294
Trained batch 247 in epoch 7, gen_loss = 1.124599166214466, disc_loss = 0.000366567314138651
Trained batch 248 in epoch 7, gen_loss = 1.1241721673662883, disc_loss = 0.0003668111150553188
Trained batch 249 in epoch 7, gen_loss = 1.1244228026866914, disc_loss = 0.0003658572682179511
Trained batch 250 in epoch 7, gen_loss = 1.1248127276678959, disc_loss = 0.00036571970009115115
Trained batch 251 in epoch 7, gen_loss = 1.1249892382867752, disc_loss = 0.00036558328983595683
Trained batch 252 in epoch 7, gen_loss = 1.124945468346592, disc_loss = 0.00036529450366280884
Trained batch 253 in epoch 7, gen_loss = 1.1247271113977657, disc_loss = 0.00036497636699103054
Trained batch 254 in epoch 7, gen_loss = 1.1247229503650291, disc_loss = 0.0003658078702203199
Trained batch 255 in epoch 7, gen_loss = 1.1251006668899208, disc_loss = 0.0003660232853235357
Trained batch 256 in epoch 7, gen_loss = 1.1243328772166359, disc_loss = 0.0003659842150369188
Trained batch 257 in epoch 7, gen_loss = 1.1241512393304545, disc_loss = 0.0003654685944441504
Trained batch 258 in epoch 7, gen_loss = 1.1239013536096079, disc_loss = 0.00036492878999282396
Trained batch 259 in epoch 7, gen_loss = 1.123840005810444, disc_loss = 0.0003641965579635535
Trained batch 260 in epoch 7, gen_loss = 1.1236443700004812, disc_loss = 0.00036381125475558313
Trained batch 261 in epoch 7, gen_loss = 1.1232430714232322, disc_loss = 0.0003638951973643026
Trained batch 262 in epoch 7, gen_loss = 1.12298614013331, disc_loss = 0.00036399401252922877
Trained batch 263 in epoch 7, gen_loss = 1.1230458041483706, disc_loss = 0.00036394913706427553
Trained batch 264 in epoch 7, gen_loss = 1.1233854453518706, disc_loss = 0.0003637119859703026
Trained batch 265 in epoch 7, gen_loss = 1.1238811063139063, disc_loss = 0.0003669444704428315
Trained batch 266 in epoch 7, gen_loss = 1.1239055986708024, disc_loss = 0.00037042203983675675
Trained batch 267 in epoch 7, gen_loss = 1.123576600827388, disc_loss = 0.0003715027653639997
Trained batch 268 in epoch 7, gen_loss = 1.1232430914963931, disc_loss = 0.00037081226521278954
Trained batch 269 in epoch 7, gen_loss = 1.1228603484453978, disc_loss = 0.0003706260249061786
Trained batch 270 in epoch 7, gen_loss = 1.1231957289125647, disc_loss = 0.0003701948915819579
Trained batch 271 in epoch 7, gen_loss = 1.1227431430974428, disc_loss = 0.00036958945501657366
Trained batch 272 in epoch 7, gen_loss = 1.1223658963000818, disc_loss = 0.0003687733641037574
Trained batch 273 in epoch 7, gen_loss = 1.1224892454860855, disc_loss = 0.00036839779124792364
Trained batch 274 in epoch 7, gen_loss = 1.1232849253307688, disc_loss = 0.00036812142289074305
Trained batch 275 in epoch 7, gen_loss = 1.1230309590481329, disc_loss = 0.0003676625630654651
Trained batch 276 in epoch 7, gen_loss = 1.1230672526875989, disc_loss = 0.00036704251315740577
Trained batch 277 in epoch 7, gen_loss = 1.1223980713662485, disc_loss = 0.0003666843418718698
Trained batch 278 in epoch 7, gen_loss = 1.121593186504952, disc_loss = 0.0003665896217292008
Trained batch 279 in epoch 7, gen_loss = 1.122074836066791, disc_loss = 0.00036616291108657604
Trained batch 280 in epoch 7, gen_loss = 1.1214259481090667, disc_loss = 0.00036566189498130194
Trained batch 281 in epoch 7, gen_loss = 1.1213728853151308, disc_loss = 0.0003650697847190049
Trained batch 282 in epoch 7, gen_loss = 1.1215450363529866, disc_loss = 0.0003646316037940309
Trained batch 283 in epoch 7, gen_loss = 1.1213721536414725, disc_loss = 0.0003640132440331156
Trained batch 284 in epoch 7, gen_loss = 1.12103298337836, disc_loss = 0.0003639154163752928
Trained batch 285 in epoch 7, gen_loss = 1.12100239441945, disc_loss = 0.000363955656949828
Trained batch 286 in epoch 7, gen_loss = 1.120864564533433, disc_loss = 0.0003639914540376008
Trained batch 287 in epoch 7, gen_loss = 1.1200222288154893, disc_loss = 0.0003652361063157312
Trained batch 288 in epoch 7, gen_loss = 1.1203517449768357, disc_loss = 0.00036721081077362893
Trained batch 289 in epoch 7, gen_loss = 1.1204120995669529, disc_loss = 0.0003677761087852434
Trained batch 290 in epoch 7, gen_loss = 1.1199361714710485, disc_loss = 0.0003675913629826171
Trained batch 291 in epoch 7, gen_loss = 1.12008708980802, disc_loss = 0.0003673593582041651
Trained batch 292 in epoch 7, gen_loss = 1.119905396329665, disc_loss = 0.00036666503945109675
Trained batch 293 in epoch 7, gen_loss = 1.1195766372340066, disc_loss = 0.00036664126154002067
Trained batch 294 in epoch 7, gen_loss = 1.1190429358159082, disc_loss = 0.0003664058535971474
Trained batch 295 in epoch 7, gen_loss = 1.1191597292954858, disc_loss = 0.00036561923460229427
Trained batch 296 in epoch 7, gen_loss = 1.118379775321845, disc_loss = 0.000365884491984861
Trained batch 297 in epoch 7, gen_loss = 1.1183894514637505, disc_loss = 0.00036730987342908954
Trained batch 298 in epoch 7, gen_loss = 1.118301704775131, disc_loss = 0.0003683079487876188
Trained batch 299 in epoch 7, gen_loss = 1.1181305950880052, disc_loss = 0.00036835861615448567
Trained batch 300 in epoch 7, gen_loss = 1.1178266247641604, disc_loss = 0.00036787442035123746
Trained batch 301 in epoch 7, gen_loss = 1.1176784849719497, disc_loss = 0.0003672728463116916
Trained batch 302 in epoch 7, gen_loss = 1.1173396446917316, disc_loss = 0.0003667086685670343
Trained batch 303 in epoch 7, gen_loss = 1.1180364252313186, disc_loss = 0.00036621684744444024
Trained batch 304 in epoch 7, gen_loss = 1.1175395617719557, disc_loss = 0.00036658309719746657
Trained batch 305 in epoch 7, gen_loss = 1.117327654673383, disc_loss = 0.0003665288548564289
Trained batch 306 in epoch 7, gen_loss = 1.117713892110396, disc_loss = 0.000365921546026673
Trained batch 307 in epoch 7, gen_loss = 1.1174526249433492, disc_loss = 0.00036597455226757274
Trained batch 308 in epoch 7, gen_loss = 1.1179130432289395, disc_loss = 0.00036692224213330553
Trained batch 309 in epoch 7, gen_loss = 1.1178190604332954, disc_loss = 0.0003678529745347107
Trained batch 310 in epoch 7, gen_loss = 1.1181495868124762, disc_loss = 0.00036833910583151605
Trained batch 311 in epoch 7, gen_loss = 1.1179730941851933, disc_loss = 0.00036900863429204596
Trained batch 312 in epoch 7, gen_loss = 1.11761902277462, disc_loss = 0.0003687439747389031
Trained batch 313 in epoch 7, gen_loss = 1.1177851519766886, disc_loss = 0.0003682634800915001
Trained batch 314 in epoch 7, gen_loss = 1.1177851294714307, disc_loss = 0.0003677586280641013
Trained batch 315 in epoch 7, gen_loss = 1.1187593770932547, disc_loss = 0.0003671019176987171
Trained batch 316 in epoch 7, gen_loss = 1.1193808640591354, disc_loss = 0.0003664089662514257
Trained batch 317 in epoch 7, gen_loss = 1.118691975403132, disc_loss = 0.0003657923292814543
Trained batch 318 in epoch 7, gen_loss = 1.1182964836542135, disc_loss = 0.00036557248334997397
Trained batch 319 in epoch 7, gen_loss = 1.1181444535031915, disc_loss = 0.0003651762524896185
Trained batch 320 in epoch 7, gen_loss = 1.118189068041115, disc_loss = 0.0003644861844861503
Trained batch 321 in epoch 7, gen_loss = 1.1184550210926103, disc_loss = 0.000364124234613922
Trained batch 322 in epoch 7, gen_loss = 1.1191383749707933, disc_loss = 0.0003640280247899493
Trained batch 323 in epoch 7, gen_loss = 1.1185977768014979, disc_loss = 0.0003641946985024131
Trained batch 324 in epoch 7, gen_loss = 1.1181517457962036, disc_loss = 0.000364262462199594
Trained batch 325 in epoch 7, gen_loss = 1.1180060732584058, disc_loss = 0.0003637234731955865
Trained batch 326 in epoch 7, gen_loss = 1.1175970715849406, disc_loss = 0.0003629916945482328
Trained batch 327 in epoch 7, gen_loss = 1.1171947038028298, disc_loss = 0.00036235603382498615
Trained batch 328 in epoch 7, gen_loss = 1.1164453645607622, disc_loss = 0.0003623190756298398
Trained batch 329 in epoch 7, gen_loss = 1.1158903893196221, disc_loss = 0.0003628036229532551
Trained batch 330 in epoch 7, gen_loss = 1.116023267684026, disc_loss = 0.0003627654115087001
Trained batch 331 in epoch 7, gen_loss = 1.116592893937984, disc_loss = 0.00036260453380675177
Trained batch 332 in epoch 7, gen_loss = 1.1169067093201943, disc_loss = 0.00036194735769862056
Trained batch 333 in epoch 7, gen_loss = 1.1168557503623162, disc_loss = 0.0003614171802325587
Trained batch 334 in epoch 7, gen_loss = 1.1162460200822175, disc_loss = 0.0003611610224122988
Trained batch 335 in epoch 7, gen_loss = 1.116357254662684, disc_loss = 0.00036075455916164046
Trained batch 336 in epoch 7, gen_loss = 1.1159095684569384, disc_loss = 0.0003603055716256641
Trained batch 337 in epoch 7, gen_loss = 1.1167422644132694, disc_loss = 0.0003597582210376776
Trained batch 338 in epoch 7, gen_loss = 1.116950048282083, disc_loss = 0.0003594830869590578
Trained batch 339 in epoch 7, gen_loss = 1.116630187280038, disc_loss = 0.0003591353824851788
Trained batch 340 in epoch 7, gen_loss = 1.1163955732874158, disc_loss = 0.00035859064935246356
Trained batch 341 in epoch 7, gen_loss = 1.115945876864662, disc_loss = 0.0003583881853312412
Trained batch 342 in epoch 7, gen_loss = 1.1158928845088614, disc_loss = 0.00035860775410755656
Trained batch 343 in epoch 7, gen_loss = 1.1157095732037412, disc_loss = 0.0003584623364288344
Trained batch 344 in epoch 7, gen_loss = 1.115581422785054, disc_loss = 0.0003578357557948355
Trained batch 345 in epoch 7, gen_loss = 1.1154501398519285, disc_loss = 0.0003578746867987914
Trained batch 346 in epoch 7, gen_loss = 1.1155983242246534, disc_loss = 0.00035972059727847706
Trained batch 347 in epoch 7, gen_loss = 1.1159570311335312, disc_loss = 0.00036115975429614383
Trained batch 348 in epoch 7, gen_loss = 1.1163159788167238, disc_loss = 0.00036114103839276384
Trained batch 349 in epoch 7, gen_loss = 1.1157945701054164, disc_loss = 0.00036114766620033023
Trained batch 350 in epoch 7, gen_loss = 1.1152947726752345, disc_loss = 0.00036113355554205146
Trained batch 351 in epoch 7, gen_loss = 1.1162078593942253, disc_loss = 0.0003614132922600468
Trained batch 352 in epoch 7, gen_loss = 1.1158193853016278, disc_loss = 0.0003608594063660209
Trained batch 353 in epoch 7, gen_loss = 1.1159798991208696, disc_loss = 0.00036042855894995467
Trained batch 354 in epoch 7, gen_loss = 1.115491995677142, disc_loss = 0.00035995207062896185
Trained batch 355 in epoch 7, gen_loss = 1.1155894355157787, disc_loss = 0.00035933958056017895
Trained batch 356 in epoch 7, gen_loss = 1.1151763614820165, disc_loss = 0.00035926471409715286
Trained batch 357 in epoch 7, gen_loss = 1.1149002323603496, disc_loss = 0.00035926427245211613
Trained batch 358 in epoch 7, gen_loss = 1.1154521637308232, disc_loss = 0.0003588367905743384
Trained batch 359 in epoch 7, gen_loss = 1.1155201332436668, disc_loss = 0.0003582027931972536
Trained batch 360 in epoch 7, gen_loss = 1.115142075639022, disc_loss = 0.00035810509000529494
Trained batch 361 in epoch 7, gen_loss = 1.1151108435504344, disc_loss = 0.0003587942046176987
Trained batch 362 in epoch 7, gen_loss = 1.1151873536674772, disc_loss = 0.0003591285272133883
Trained batch 363 in epoch 7, gen_loss = 1.1154940210200928, disc_loss = 0.00035874190783303405
Trained batch 364 in epoch 7, gen_loss = 1.115592395116205, disc_loss = 0.00035805724370245476
Trained batch 365 in epoch 7, gen_loss = 1.1150916264356812, disc_loss = 0.0003577847256749179
Trained batch 366 in epoch 7, gen_loss = 1.1149027483989498, disc_loss = 0.0003574557996893299
Trained batch 367 in epoch 7, gen_loss = 1.1143648475408554, disc_loss = 0.0003571995290139571
Trained batch 368 in epoch 7, gen_loss = 1.1147094887446583, disc_loss = 0.00035653171462128645
Trained batch 369 in epoch 7, gen_loss = 1.114705221717422, disc_loss = 0.0003561343914141715
Trained batch 370 in epoch 7, gen_loss = 1.115505115041193, disc_loss = 0.0003556852754965773
Trained batch 371 in epoch 7, gen_loss = 1.1150239957596666, disc_loss = 0.00035515388461585304
Trained batch 372 in epoch 7, gen_loss = 1.115779628223133, disc_loss = 0.00035466841769940906
Trained batch 373 in epoch 7, gen_loss = 1.1164728149692005, disc_loss = 0.00035410093498509004
Trained batch 374 in epoch 7, gen_loss = 1.1164195914268493, disc_loss = 0.0003539558927101704
Trained batch 375 in epoch 7, gen_loss = 1.1161384000740153, disc_loss = 0.00035354157956889854
Trained batch 376 in epoch 7, gen_loss = 1.1161499739641851, disc_loss = 0.0003528622065442898
Trained batch 377 in epoch 7, gen_loss = 1.116029132453222, disc_loss = 0.0003525700788404768
Trained batch 378 in epoch 7, gen_loss = 1.115830599318079, disc_loss = 0.00035242817565365043
Trained batch 379 in epoch 7, gen_loss = 1.1153985857963562, disc_loss = 0.00035235294233548065
Trained batch 380 in epoch 7, gen_loss = 1.1149972046767007, disc_loss = 0.00035176693732707256
Trained batch 381 in epoch 7, gen_loss = 1.1152349721386794, disc_loss = 0.00035188430195695023
Trained batch 382 in epoch 7, gen_loss = 1.1151469686012667, disc_loss = 0.0003524850254927643
Trained batch 383 in epoch 7, gen_loss = 1.1152110955057044, disc_loss = 0.0003528682503883829
Trained batch 384 in epoch 7, gen_loss = 1.1153603734908166, disc_loss = 0.00035235766686541453
Trained batch 385 in epoch 7, gen_loss = 1.115388184785843, disc_loss = 0.00035216833383823297
Trained batch 386 in epoch 7, gen_loss = 1.115098762727831, disc_loss = 0.0003529049928624361
Trained batch 387 in epoch 7, gen_loss = 1.1154619094330012, disc_loss = 0.000353754771813047
Trained batch 388 in epoch 7, gen_loss = 1.1155474414249311, disc_loss = 0.00035355771655500517
Trained batch 389 in epoch 7, gen_loss = 1.1154940398839803, disc_loss = 0.0003531549820670476
Trained batch 390 in epoch 7, gen_loss = 1.1163627709574102, disc_loss = 0.0003532507608536288
Trained batch 391 in epoch 7, gen_loss = 1.1164625252083855, disc_loss = 0.0003540727840136613
Trained batch 392 in epoch 7, gen_loss = 1.1167806033566405, disc_loss = 0.00035427781981629326
Trained batch 393 in epoch 7, gen_loss = 1.1168591741680494, disc_loss = 0.00035378936947640127
Trained batch 394 in epoch 7, gen_loss = 1.1174568585202664, disc_loss = 0.0003534094031894273
Trained batch 395 in epoch 7, gen_loss = 1.1176865195686168, disc_loss = 0.0003533741469392694
Trained batch 396 in epoch 7, gen_loss = 1.1172749376116833, disc_loss = 0.0003543874247835935
Trained batch 397 in epoch 7, gen_loss = 1.1171997682233552, disc_loss = 0.00035504958159161555
Trained batch 398 in epoch 7, gen_loss = 1.1166254809326994, disc_loss = 0.00035550559027398235
Trained batch 399 in epoch 7, gen_loss = 1.1171267153322697, disc_loss = 0.0003551161581708584
Trained batch 400 in epoch 7, gen_loss = 1.1170743443722142, disc_loss = 0.0003547308840376657
Trained batch 401 in epoch 7, gen_loss = 1.1169003371279038, disc_loss = 0.00035444009565923187
Trained batch 402 in epoch 7, gen_loss = 1.1168045472566306, disc_loss = 0.00035396679422255404
Trained batch 403 in epoch 7, gen_loss = 1.1164750809421633, disc_loss = 0.0003535678828988653
Trained batch 404 in epoch 7, gen_loss = 1.1160077296657327, disc_loss = 0.0003538380667673608
Trained batch 405 in epoch 7, gen_loss = 1.1161461127509038, disc_loss = 0.00035380445002249024
Trained batch 406 in epoch 7, gen_loss = 1.1164461024270305, disc_loss = 0.00035396183300185583
Trained batch 407 in epoch 7, gen_loss = 1.1162012586114454, disc_loss = 0.0003541422560659817
Trained batch 408 in epoch 7, gen_loss = 1.1160678069282568, disc_loss = 0.00035460775459502893
Trained batch 409 in epoch 7, gen_loss = 1.116324963366113, disc_loss = 0.0003560329551408181
Trained batch 410 in epoch 7, gen_loss = 1.1167693824083555, disc_loss = 0.0003564393938019976
Trained batch 411 in epoch 7, gen_loss = 1.1165587052847574, disc_loss = 0.00035700227867318
Trained batch 412 in epoch 7, gen_loss = 1.116239431262305, disc_loss = 0.0003577495537758591
Trained batch 413 in epoch 7, gen_loss = 1.1159652919297056, disc_loss = 0.00035889441993707286
Trained batch 414 in epoch 7, gen_loss = 1.1157173258712494, disc_loss = 0.0003590521698253768
Trained batch 415 in epoch 7, gen_loss = 1.1154779182890286, disc_loss = 0.00035889538576856675
Trained batch 416 in epoch 7, gen_loss = 1.1150916540365425, disc_loss = 0.00035884716975579723
Trained batch 417 in epoch 7, gen_loss = 1.1153973366655232, disc_loss = 0.00035931401630238583
Trained batch 418 in epoch 7, gen_loss = 1.115289652546721, disc_loss = 0.00036031202779752747
Trained batch 419 in epoch 7, gen_loss = 1.115131208726338, disc_loss = 0.00036111572224486045
Trained batch 420 in epoch 7, gen_loss = 1.1152101641879228, disc_loss = 0.0003609535179746331
Trained batch 421 in epoch 7, gen_loss = 1.1152619086735622, disc_loss = 0.0003604884464233028
Trained batch 422 in epoch 7, gen_loss = 1.11487034576159, disc_loss = 0.0003604363137085528
Trained batch 423 in epoch 7, gen_loss = 1.114877662990453, disc_loss = 0.0003602384481296813
Trained batch 424 in epoch 7, gen_loss = 1.114900856438805, disc_loss = 0.00035990694462431264
Trained batch 425 in epoch 7, gen_loss = 1.1146387627147174, disc_loss = 0.00035939986513929765
Trained batch 426 in epoch 7, gen_loss = 1.1151869725566836, disc_loss = 0.0003593123162959198
Trained batch 427 in epoch 7, gen_loss = 1.1146522477686962, disc_loss = 0.00035982944477114514
Trained batch 428 in epoch 7, gen_loss = 1.1147641864689914, disc_loss = 0.0003603972584966544
Trained batch 429 in epoch 7, gen_loss = 1.1145203009594318, disc_loss = 0.0003603297193686283
Trained batch 430 in epoch 7, gen_loss = 1.1148334839781033, disc_loss = 0.00036040939762864237
Trained batch 431 in epoch 7, gen_loss = 1.1147106859695028, disc_loss = 0.00036122135551758456
Trained batch 432 in epoch 7, gen_loss = 1.1148718049014137, disc_loss = 0.0003617026921905853
Trained batch 433 in epoch 7, gen_loss = 1.1143681600621218, disc_loss = 0.00036216890122870213
Trained batch 434 in epoch 7, gen_loss = 1.114351378775191, disc_loss = 0.00036230014915438906
Trained batch 435 in epoch 7, gen_loss = 1.1142124893195038, disc_loss = 0.0003624074895323656
Trained batch 436 in epoch 7, gen_loss = 1.1146582513706635, disc_loss = 0.00036267311409759405
Trained batch 437 in epoch 7, gen_loss = 1.1142033289556634, disc_loss = 0.00036263379486826285
Trained batch 438 in epoch 7, gen_loss = 1.1143376914135144, disc_loss = 0.00036302711766909016
Trained batch 439 in epoch 7, gen_loss = 1.1143392102284866, disc_loss = 0.0003628608099957505
Trained batch 440 in epoch 7, gen_loss = 1.114713895077608, disc_loss = 0.000363165656022322
Trained batch 441 in epoch 7, gen_loss = 1.1147018503819117, disc_loss = 0.0003646199322280335
Trained batch 442 in epoch 7, gen_loss = 1.1149127305764914, disc_loss = 0.0003663087925930459
Trained batch 443 in epoch 7, gen_loss = 1.1156458752649325, disc_loss = 0.00036724376243639837
Trained batch 444 in epoch 7, gen_loss = 1.1154434364833188, disc_loss = 0.0003669927040575428
Trained batch 445 in epoch 7, gen_loss = 1.1153117049435328, disc_loss = 0.000366752320232868
Trained batch 446 in epoch 7, gen_loss = 1.115492574587231, disc_loss = 0.00036649130739509157
Trained batch 447 in epoch 7, gen_loss = 1.1154588413025652, disc_loss = 0.00036623236941782773
Trained batch 448 in epoch 7, gen_loss = 1.1151583535899563, disc_loss = 0.0003657791055588545
Trained batch 449 in epoch 7, gen_loss = 1.11475270708402, disc_loss = 0.0003654239215474162
Trained batch 450 in epoch 7, gen_loss = 1.1145426282068578, disc_loss = 0.0003655492774021921
Trained batch 451 in epoch 7, gen_loss = 1.1143812285324113, disc_loss = 0.0003655580004684388
Trained batch 452 in epoch 7, gen_loss = 1.1148492591270547, disc_loss = 0.00036532040725248323
Trained batch 453 in epoch 7, gen_loss = 1.1153998197700483, disc_loss = 0.0003651947812982404
Trained batch 454 in epoch 7, gen_loss = 1.115430894133809, disc_loss = 0.0003654302646672087
Trained batch 455 in epoch 7, gen_loss = 1.1152495222917773, disc_loss = 0.00036522548524724126
Trained batch 456 in epoch 7, gen_loss = 1.1152844863334421, disc_loss = 0.00036482858484054566
Trained batch 457 in epoch 7, gen_loss = 1.115716639174124, disc_loss = 0.00036458395680516356
Trained batch 458 in epoch 7, gen_loss = 1.1153504462803112, disc_loss = 0.00036461516471137344
Trained batch 459 in epoch 7, gen_loss = 1.1154228965873303, disc_loss = 0.00036461003069037
Trained batch 460 in epoch 7, gen_loss = 1.1154585079877857, disc_loss = 0.0003643989325107081
Trained batch 461 in epoch 7, gen_loss = 1.1151572392358409, disc_loss = 0.0003641731606809487
Trained batch 462 in epoch 7, gen_loss = 1.1152443735182413, disc_loss = 0.00036374499838920935
Trained batch 463 in epoch 7, gen_loss = 1.1152999602772038, disc_loss = 0.0003639550715324104
Trained batch 464 in epoch 7, gen_loss = 1.1152420947628636, disc_loss = 0.0003643597676781737
Trained batch 465 in epoch 7, gen_loss = 1.1157176232389114, disc_loss = 0.00036533102281356645
Trained batch 466 in epoch 7, gen_loss = 1.115528484355714, disc_loss = 0.0003659837519088401
Trained batch 467 in epoch 7, gen_loss = 1.1155258553405094, disc_loss = 0.0003661446051752199
Trained batch 468 in epoch 7, gen_loss = 1.115623727917417, disc_loss = 0.000366176633112905
Trained batch 469 in epoch 7, gen_loss = 1.1158900023774898, disc_loss = 0.00036598250119416836
Trained batch 470 in epoch 7, gen_loss = 1.1163543145114956, disc_loss = 0.0003657414041365143
Trained batch 471 in epoch 7, gen_loss = 1.1161771670488987, disc_loss = 0.00036550538588618126
Trained batch 472 in epoch 7, gen_loss = 1.1160027326791533, disc_loss = 0.00036516249954260404
Trained batch 473 in epoch 7, gen_loss = 1.1158586643667663, disc_loss = 0.00036500988427804045
Trained batch 474 in epoch 7, gen_loss = 1.1154458983320938, disc_loss = 0.00036479668455860134
Trained batch 475 in epoch 7, gen_loss = 1.1149156498057502, disc_loss = 0.0003643795255299642
Trained batch 476 in epoch 7, gen_loss = 1.1148723575054225, disc_loss = 0.00036463141032549274
Trained batch 477 in epoch 7, gen_loss = 1.1151707525283223, disc_loss = 0.0003659738516693187
Trained batch 478 in epoch 7, gen_loss = 1.1149654996917742, disc_loss = 0.00036689792442551593
Trained batch 479 in epoch 7, gen_loss = 1.1148924476156632, disc_loss = 0.00036656354338144106
Trained batch 480 in epoch 7, gen_loss = 1.114971488652259, disc_loss = 0.0003661775546198761
Trained batch 481 in epoch 7, gen_loss = 1.1147116139469304, disc_loss = 0.00036595901196602253
Trained batch 482 in epoch 7, gen_loss = 1.1149338860195863, disc_loss = 0.00036606005119163673
Trained batch 483 in epoch 7, gen_loss = 1.1146513187934544, disc_loss = 0.0003657655464593525
Trained batch 484 in epoch 7, gen_loss = 1.1147223938371718, disc_loss = 0.00036542572800583715
Trained batch 485 in epoch 7, gen_loss = 1.1148601707852916, disc_loss = 0.0003655783821234131
Trained batch 486 in epoch 7, gen_loss = 1.114850430640352, disc_loss = 0.000365658563381736
Trained batch 487 in epoch 7, gen_loss = 1.1143782755634823, disc_loss = 0.00036532105380009865
Trained batch 488 in epoch 7, gen_loss = 1.114739200454548, disc_loss = 0.00036501625135797124
Trained batch 489 in epoch 7, gen_loss = 1.1152503343261018, disc_loss = 0.00036504712494503594
Trained batch 490 in epoch 7, gen_loss = 1.1156747922635126, disc_loss = 0.0003649385728910774
Trained batch 491 in epoch 7, gen_loss = 1.11586293469115, disc_loss = 0.0003645729785063399
Trained batch 492 in epoch 7, gen_loss = 1.1159290901062213, disc_loss = 0.0003644188757219331
Trained batch 493 in epoch 7, gen_loss = 1.1157124724224028, disc_loss = 0.00036437556632207176
Trained batch 494 in epoch 7, gen_loss = 1.1157839470439488, disc_loss = 0.0003641463242614679
Trained batch 495 in epoch 7, gen_loss = 1.115699922726039, disc_loss = 0.0003639971744984993
Trained batch 496 in epoch 7, gen_loss = 1.1154414598850657, disc_loss = 0.0003638569311807082
Trained batch 497 in epoch 7, gen_loss = 1.1155199103326683, disc_loss = 0.00036368359373643974
Trained batch 498 in epoch 7, gen_loss = 1.1156232933959884, disc_loss = 0.0003634778090590753
Trained batch 499 in epoch 7, gen_loss = 1.115692442059517, disc_loss = 0.00036320024184533395
Trained batch 500 in epoch 7, gen_loss = 1.1155825892608322, disc_loss = 0.0003629274874393031
Trained batch 501 in epoch 7, gen_loss = 1.1153460188928352, disc_loss = 0.00036265706751644947
Trained batch 502 in epoch 7, gen_loss = 1.115578077540957, disc_loss = 0.0003626407181673311
Trained batch 503 in epoch 7, gen_loss = 1.1153866850904055, disc_loss = 0.0003633359262046667
Trained batch 504 in epoch 7, gen_loss = 1.1151574723791369, disc_loss = 0.00036357708213652606
Trained batch 505 in epoch 7, gen_loss = 1.1149218886972887, disc_loss = 0.0003636246405897585
Trained batch 506 in epoch 7, gen_loss = 1.1150708608843636, disc_loss = 0.0003633409108187272
Trained batch 507 in epoch 7, gen_loss = 1.1151669226058825, disc_loss = 0.0003631302256902082
Trained batch 508 in epoch 7, gen_loss = 1.115162044587913, disc_loss = 0.0003631466657780056
Trained batch 509 in epoch 7, gen_loss = 1.1151889748433057, disc_loss = 0.00036284873546238113
Trained batch 510 in epoch 7, gen_loss = 1.1155353069538707, disc_loss = 0.0003627270537928848
Trained batch 511 in epoch 7, gen_loss = 1.1159885461675003, disc_loss = 0.00036254218753128953
Trained batch 512 in epoch 7, gen_loss = 1.1159316007389195, disc_loss = 0.00036213852882250913
Trained batch 513 in epoch 7, gen_loss = 1.1166757629307327, disc_loss = 0.0003622724260846769
Trained batch 514 in epoch 7, gen_loss = 1.1167964994328694, disc_loss = 0.00036294207618870204
Trained batch 515 in epoch 7, gen_loss = 1.1169329224399818, disc_loss = 0.0003634448898252273
Trained batch 516 in epoch 7, gen_loss = 1.1167379602703411, disc_loss = 0.0003636627501044314
Trained batch 517 in epoch 7, gen_loss = 1.116333775883936, disc_loss = 0.0003639413410182826
Trained batch 518 in epoch 7, gen_loss = 1.116363775638257, disc_loss = 0.0003636808087286649
Trained batch 519 in epoch 7, gen_loss = 1.1163587413155116, disc_loss = 0.00036365090423854643
Trained batch 520 in epoch 7, gen_loss = 1.116588655566071, disc_loss = 0.00036352036624517643
Trained batch 521 in epoch 7, gen_loss = 1.116686670602053, disc_loss = 0.00036383564376550587
Trained batch 522 in epoch 7, gen_loss = 1.116717345741921, disc_loss = 0.00036495929727701197
Trained batch 523 in epoch 7, gen_loss = 1.116236280280215, disc_loss = 0.00036756787349146483
Trained batch 524 in epoch 7, gen_loss = 1.116422952583858, disc_loss = 0.00037053512021278343
Trained batch 525 in epoch 7, gen_loss = 1.1170991193432318, disc_loss = 0.0003716132144121446
Trained batch 526 in epoch 7, gen_loss = 1.1174470049380352, disc_loss = 0.00037148658873644114
Trained batch 527 in epoch 7, gen_loss = 1.1174512793394653, disc_loss = 0.0003714067606779281
Trained batch 528 in epoch 7, gen_loss = 1.1171969227168872, disc_loss = 0.0003711807602397668
Trained batch 529 in epoch 7, gen_loss = 1.1169250495028946, disc_loss = 0.0003708647239243805
Trained batch 530 in epoch 7, gen_loss = 1.117318403473906, disc_loss = 0.00037070994214185476
Trained batch 531 in epoch 7, gen_loss = 1.1175099763655125, disc_loss = 0.00037153162617657395
Trained batch 532 in epoch 7, gen_loss = 1.1175290603351413, disc_loss = 0.00037320364017312996
Trained batch 533 in epoch 7, gen_loss = 1.1174402223544175, disc_loss = 0.0003743498281836039
Trained batch 534 in epoch 7, gen_loss = 1.1176941033835723, disc_loss = 0.0003750479723833867
Trained batch 535 in epoch 7, gen_loss = 1.1176664731395778, disc_loss = 0.0003752859135615768
Trained batch 536 in epoch 7, gen_loss = 1.1178076193985327, disc_loss = 0.0003751921718144526
Trained batch 537 in epoch 7, gen_loss = 1.1176188452979445, disc_loss = 0.00037505707497856506
Trained batch 538 in epoch 7, gen_loss = 1.1175926019176703, disc_loss = 0.00037502780349226236
Trained batch 539 in epoch 7, gen_loss = 1.1176103373368582, disc_loss = 0.000374979814552245
Trained batch 540 in epoch 7, gen_loss = 1.117991473890717, disc_loss = 0.00037493607836371794
Trained batch 541 in epoch 7, gen_loss = 1.1180326401967404, disc_loss = 0.00037504486941858763
Trained batch 542 in epoch 7, gen_loss = 1.1181524746106255, disc_loss = 0.0003751622979294656
Trained batch 543 in epoch 7, gen_loss = 1.1177192213123335, disc_loss = 0.00037541758986074403
Trained batch 544 in epoch 7, gen_loss = 1.1175625957480264, disc_loss = 0.0003756923295841595
Trained batch 545 in epoch 7, gen_loss = 1.1174848685552785, disc_loss = 0.0003756974580334824
Trained batch 546 in epoch 7, gen_loss = 1.1171917851054036, disc_loss = 0.00037563454548226435
Trained batch 547 in epoch 7, gen_loss = 1.1172811827302849, disc_loss = 0.0003754176334811487
Trained batch 548 in epoch 7, gen_loss = 1.117457224697363, disc_loss = 0.0003751631879068755
Trained batch 549 in epoch 7, gen_loss = 1.1170508952574296, disc_loss = 0.0003750494462755424
Trained batch 550 in epoch 7, gen_loss = 1.116988455102578, disc_loss = 0.00037492094589980444
Trained batch 551 in epoch 7, gen_loss = 1.1171928518924161, disc_loss = 0.0003752009335216101
Trained batch 552 in epoch 7, gen_loss = 1.1171036508156638, disc_loss = 0.0003760973338200248
Trained batch 553 in epoch 7, gen_loss = 1.1168304598933954, disc_loss = 0.0003772534362048025
Trained batch 554 in epoch 7, gen_loss = 1.1167059991810773, disc_loss = 0.0003776363703854348
Trained batch 555 in epoch 7, gen_loss = 1.1169190199898302, disc_loss = 0.00037766625740809915
Trained batch 556 in epoch 7, gen_loss = 1.1170082442208296, disc_loss = 0.0003774586684175866
Trained batch 557 in epoch 7, gen_loss = 1.116733674293778, disc_loss = 0.00037721280133940855
Trained batch 558 in epoch 7, gen_loss = 1.1164105207207804, disc_loss = 0.00037684437484782
Trained batch 559 in epoch 7, gen_loss = 1.1161592400499754, disc_loss = 0.0003765728025038178
Trained batch 560 in epoch 7, gen_loss = 1.115867416488933, disc_loss = 0.0003765494240364458
Trained batch 561 in epoch 7, gen_loss = 1.1156022795790879, disc_loss = 0.000376367711697604
Trained batch 562 in epoch 7, gen_loss = 1.1157124471283297, disc_loss = 0.00037611743642970897
Trained batch 563 in epoch 7, gen_loss = 1.1156941666036633, disc_loss = 0.0003759579728421481
Trained batch 564 in epoch 7, gen_loss = 1.1158108220691174, disc_loss = 0.00037631546896655705
Trained batch 565 in epoch 7, gen_loss = 1.1159645697042715, disc_loss = 0.0003773476563132032
Trained batch 566 in epoch 7, gen_loss = 1.1162723930424483, disc_loss = 0.00037829128817866214
Trained batch 567 in epoch 7, gen_loss = 1.1163699290072415, disc_loss = 0.0003781957388845269
Trained batch 568 in epoch 7, gen_loss = 1.1161163296347554, disc_loss = 0.0003780848657381303
Trained batch 569 in epoch 7, gen_loss = 1.1163228586054685, disc_loss = 0.00037790603193826156
Trained batch 570 in epoch 7, gen_loss = 1.1165032989089418, disc_loss = 0.00037771022430357676
Trained batch 571 in epoch 7, gen_loss = 1.117221000415462, disc_loss = 0.0003773447292174255
Trained batch 572 in epoch 7, gen_loss = 1.1173724026580132, disc_loss = 0.0003769592859763587
Trained batch 573 in epoch 7, gen_loss = 1.1173214477321411, disc_loss = 0.00037662208250959856
Trained batch 574 in epoch 7, gen_loss = 1.117009168189505, disc_loss = 0.0003763759568961256
Trained batch 575 in epoch 7, gen_loss = 1.1166415472204487, disc_loss = 0.0003760761949504538
Trained batch 576 in epoch 7, gen_loss = 1.1170429626618557, disc_loss = 0.0003757252656706194
Trained batch 577 in epoch 7, gen_loss = 1.1168051369256213, disc_loss = 0.00037541359776907334
Trained batch 578 in epoch 7, gen_loss = 1.1167345780988638, disc_loss = 0.00037515434280776985
Trained batch 579 in epoch 7, gen_loss = 1.1167752322451823, disc_loss = 0.00037471225795311983
Trained batch 580 in epoch 7, gen_loss = 1.117245906293905, disc_loss = 0.00037427455019885063
Trained batch 581 in epoch 7, gen_loss = 1.1174205462752338, disc_loss = 0.00037389307241009537
Trained batch 582 in epoch 7, gen_loss = 1.1177021456214618, disc_loss = 0.00037365233295548814
Trained batch 583 in epoch 7, gen_loss = 1.1172672830624124, disc_loss = 0.0003736410384067001
Trained batch 584 in epoch 7, gen_loss = 1.117258938153585, disc_loss = 0.0003732482486670144
Trained batch 585 in epoch 7, gen_loss = 1.1175051831954983, disc_loss = 0.0003728599763437017
Trained batch 586 in epoch 7, gen_loss = 1.117106330049505, disc_loss = 0.00037241333822804636
Trained batch 587 in epoch 7, gen_loss = 1.1177099075447134, disc_loss = 0.0003721465707428319
Trained batch 588 in epoch 7, gen_loss = 1.1176278627586689, disc_loss = 0.0003719425188558941
Trained batch 589 in epoch 7, gen_loss = 1.1173545570696815, disc_loss = 0.00037161645608247746
Trained batch 590 in epoch 7, gen_loss = 1.1176295431737366, disc_loss = 0.0003713667971360168
Trained batch 591 in epoch 7, gen_loss = 1.1177611419477977, disc_loss = 0.000371078217859896
Trained batch 592 in epoch 7, gen_loss = 1.117431717618521, disc_loss = 0.00037085214283958886
Trained batch 593 in epoch 7, gen_loss = 1.1176385130946485, disc_loss = 0.0003709254582008419
Trained batch 594 in epoch 7, gen_loss = 1.117350841069422, disc_loss = 0.00037141084485636447
Trained batch 595 in epoch 7, gen_loss = 1.1173368975420126, disc_loss = 0.00037224571072225356
Trained batch 596 in epoch 7, gen_loss = 1.1171961017389793, disc_loss = 0.0003725220739088369
Trained batch 597 in epoch 7, gen_loss = 1.1169343867828216, disc_loss = 0.00037236435334085264
Trained batch 598 in epoch 7, gen_loss = 1.1166106237592999, disc_loss = 0.00037204282433987875
Trained batch 599 in epoch 7, gen_loss = 1.1165307488044103, disc_loss = 0.0003716790824061415
Trained batch 600 in epoch 7, gen_loss = 1.1161845816352007, disc_loss = 0.00037129767123453267
Trained batch 601 in epoch 7, gen_loss = 1.1159601648186528, disc_loss = 0.00037083273028683743
Trained batch 602 in epoch 7, gen_loss = 1.1158735840079401, disc_loss = 0.0003705194793118567
Trained batch 603 in epoch 7, gen_loss = 1.1160859900791913, disc_loss = 0.0003701451461640185
Trained batch 604 in epoch 7, gen_loss = 1.1159543651194612, disc_loss = 0.0003697823051075559
Trained batch 605 in epoch 7, gen_loss = 1.115959769920154, disc_loss = 0.0003694298953608811
Trained batch 606 in epoch 7, gen_loss = 1.1159948370798416, disc_loss = 0.0003690333693094369
Trained batch 607 in epoch 7, gen_loss = 1.1158912412234043, disc_loss = 0.00036866448921931517
Trained batch 608 in epoch 7, gen_loss = 1.1157088550832275, disc_loss = 0.0003683155802706882
Trained batch 609 in epoch 7, gen_loss = 1.115738056624522, disc_loss = 0.00036791386148371334
Trained batch 610 in epoch 7, gen_loss = 1.1156411776761181, disc_loss = 0.00036762566630316613
Trained batch 611 in epoch 7, gen_loss = 1.1155023848504022, disc_loss = 0.00036750361526655443
Trained batch 612 in epoch 7, gen_loss = 1.11572626179622, disc_loss = 0.00036704461692521335
Trained batch 613 in epoch 7, gen_loss = 1.1154589356933433, disc_loss = 0.0003667747260133716
Trained batch 614 in epoch 7, gen_loss = 1.1152678263865836, disc_loss = 0.00036681945346025144
Trained batch 615 in epoch 7, gen_loss = 1.1153096325405232, disc_loss = 0.00036704040962536353
Trained batch 616 in epoch 7, gen_loss = 1.1151681318275353, disc_loss = 0.000366911522937411
Trained batch 617 in epoch 7, gen_loss = 1.1151744892103386, disc_loss = 0.0003667424532324324
Trained batch 618 in epoch 7, gen_loss = 1.1151774225211875, disc_loss = 0.0003663908711442557
Trained batch 619 in epoch 7, gen_loss = 1.1152898606754118, disc_loss = 0.00036612871071772514
Trained batch 620 in epoch 7, gen_loss = 1.1153073252303205, disc_loss = 0.0003657764642593682
Trained batch 621 in epoch 7, gen_loss = 1.1151000267056408, disc_loss = 0.00036556174033394436
Trained batch 622 in epoch 7, gen_loss = 1.1151763250510154, disc_loss = 0.0003653381379984766
Trained batch 623 in epoch 7, gen_loss = 1.115178569769248, disc_loss = 0.0003650574548117173
Trained batch 624 in epoch 7, gen_loss = 1.1153602210998534, disc_loss = 0.00036483314390061425
Trained batch 625 in epoch 7, gen_loss = 1.1151981528955526, disc_loss = 0.000364605827044012
Trained batch 626 in epoch 7, gen_loss = 1.1155956129898486, disc_loss = 0.0003643929759328078
Trained batch 627 in epoch 7, gen_loss = 1.1157991495102075, disc_loss = 0.0003644697397271991
Trained batch 628 in epoch 7, gen_loss = 1.1157221680415264, disc_loss = 0.00036448574480269365
Trained batch 629 in epoch 7, gen_loss = 1.1158707157013907, disc_loss = 0.00036465866683607195
Trained batch 630 in epoch 7, gen_loss = 1.1154752300960704, disc_loss = 0.0003647992999401577
Trained batch 631 in epoch 7, gen_loss = 1.1158873125722137, disc_loss = 0.00036454331851168317
Trained batch 632 in epoch 7, gen_loss = 1.1161940809674737, disc_loss = 0.00036429967604569084
Trained batch 633 in epoch 7, gen_loss = 1.1161178760348058, disc_loss = 0.0003640225271514231
Trained batch 634 in epoch 7, gen_loss = 1.1158856243599118, disc_loss = 0.00036397174542254627
Trained batch 635 in epoch 7, gen_loss = 1.1159111536898703, disc_loss = 0.0003643612941552602
Trained batch 636 in epoch 7, gen_loss = 1.116064259732724, disc_loss = 0.0003649203855579235
Trained batch 637 in epoch 7, gen_loss = 1.115831827482086, disc_loss = 0.00036504386750086016
Trained batch 638 in epoch 7, gen_loss = 1.115738439821115, disc_loss = 0.00036484771495816517
Trained batch 639 in epoch 7, gen_loss = 1.1157150136306881, disc_loss = 0.0003650547739766807
Trained batch 640 in epoch 7, gen_loss = 1.1156115909448465, disc_loss = 0.00036571834809787925
Trained batch 641 in epoch 7, gen_loss = 1.115725416817769, disc_loss = 0.00036656831564010715
Trained batch 642 in epoch 7, gen_loss = 1.1152544668636648, disc_loss = 0.0004885408555905763
Trained batch 643 in epoch 7, gen_loss = 1.1150897521039713, disc_loss = 0.0012579869927994087
Trained batch 644 in epoch 7, gen_loss = 1.1152629854143128, disc_loss = 0.0015386925704886437
Trained batch 645 in epoch 7, gen_loss = 1.1157711270054798, disc_loss = 0.0017924584250129656
Trained batch 646 in epoch 7, gen_loss = 1.115893959630586, disc_loss = 0.0019246574195478452
Trained batch 647 in epoch 7, gen_loss = 1.115828635332025, disc_loss = 0.0020659787428765996
Trained batch 648 in epoch 7, gen_loss = 1.1157399919257143, disc_loss = 0.0022708440745538724
Trained batch 649 in epoch 7, gen_loss = 1.1155528992872972, disc_loss = 0.002333154958961621
Trained batch 650 in epoch 7, gen_loss = 1.115488830616214, disc_loss = 0.0023955371566339446
Trained batch 651 in epoch 7, gen_loss = 1.1154881993685763, disc_loss = 0.0024194204606326685
Trained batch 652 in epoch 7, gen_loss = 1.1155749893480567, disc_loss = 0.0024919034953851853
Trained batch 653 in epoch 7, gen_loss = 1.116450534683484, disc_loss = 0.002595318014029394
Trained batch 654 in epoch 7, gen_loss = 1.1173692313769392, disc_loss = 0.0026525154138958783
Trained batch 655 in epoch 7, gen_loss = 1.1176462642303326, disc_loss = 0.002688095052856558
Trained batch 656 in epoch 7, gen_loss = 1.1182020189555268, disc_loss = 0.0026953201001756145
Trained batch 657 in epoch 7, gen_loss = 1.1185615548246899, disc_loss = 0.0027065261245209273
Trained batch 658 in epoch 7, gen_loss = 1.1187691804309896, disc_loss = 0.0027099868452992774
Trained batch 659 in epoch 7, gen_loss = 1.1191595832506815, disc_loss = 0.0027125199690172766
Trained batch 660 in epoch 7, gen_loss = 1.1194770536336163, disc_loss = 0.002711877572167832
Trained batch 661 in epoch 7, gen_loss = 1.1197887469994698, disc_loss = 0.002711772792229202
Trained batch 662 in epoch 7, gen_loss = 1.1198203277803653, disc_loss = 0.002712375558648054
Trained batch 663 in epoch 7, gen_loss = 1.119783703282655, disc_loss = 0.002712762399287056
Trained batch 664 in epoch 7, gen_loss = 1.1197884030808183, disc_loss = 0.00271619468857578
Trained batch 665 in epoch 7, gen_loss = 1.119601299275865, disc_loss = 0.002719131183837888
Trained batch 666 in epoch 7, gen_loss = 1.1196352679511419, disc_loss = 0.0027177639583125185
Trained batch 667 in epoch 7, gen_loss = 1.119704728890322, disc_loss = 0.0027172954576348777
Trained batch 668 in epoch 7, gen_loss = 1.1197332749630482, disc_loss = 0.0027150425256386723
Trained batch 669 in epoch 7, gen_loss = 1.1197155698021846, disc_loss = 0.0027124553397250076
Trained batch 670 in epoch 7, gen_loss = 1.1196044891317627, disc_loss = 0.0027103230805156564
Trained batch 671 in epoch 7, gen_loss = 1.1197121952261244, disc_loss = 0.002708725945456622
Trained batch 672 in epoch 7, gen_loss = 1.1195648722627365, disc_loss = 0.002708713819806372
Trained batch 673 in epoch 7, gen_loss = 1.1193461149311914, disc_loss = 0.0027078211148987485
Trained batch 674 in epoch 7, gen_loss = 1.119305943383111, disc_loss = 0.0027065574529222904
Trained batch 675 in epoch 7, gen_loss = 1.1192763858645625, disc_loss = 0.0027042999434493758
Trained batch 676 in epoch 7, gen_loss = 1.1194968910301806, disc_loss = 0.0027015078819393485
Trained batch 677 in epoch 7, gen_loss = 1.119560148512016, disc_loss = 0.0026991186222937377
Trained batch 678 in epoch 7, gen_loss = 1.1196702753847934, disc_loss = 0.002698362034072826
Trained batch 679 in epoch 7, gen_loss = 1.1195927399046282, disc_loss = 0.0026970399170108176
Trained batch 680 in epoch 7, gen_loss = 1.1194035117671703, disc_loss = 0.0026940936306116266
Trained batch 681 in epoch 7, gen_loss = 1.1193545107617755, disc_loss = 0.0026921475665321022
Trained batch 682 in epoch 7, gen_loss = 1.1195859750228256, disc_loss = 0.002689460709680906
Trained batch 683 in epoch 7, gen_loss = 1.1195652267040566, disc_loss = 0.0026865988604068973
Trained batch 684 in epoch 7, gen_loss = 1.1197574965275117, disc_loss = 0.0026836981542810398
Trained batch 685 in epoch 7, gen_loss = 1.119567478884761, disc_loss = 0.0026827358999161445
Trained batch 686 in epoch 7, gen_loss = 1.1196098318960643, disc_loss = 0.0026807790247980524
Trained batch 687 in epoch 7, gen_loss = 1.1197097684408344, disc_loss = 0.002678036545307276
Trained batch 688 in epoch 7, gen_loss = 1.1197196771167706, disc_loss = 0.002675230400818005
Trained batch 689 in epoch 7, gen_loss = 1.1199566994888195, disc_loss = 0.0026723373777159673
Trained batch 690 in epoch 7, gen_loss = 1.1200923184755052, disc_loss = 0.0026693164989610497
Trained batch 691 in epoch 7, gen_loss = 1.1203365105425003, disc_loss = 0.0026667062620144653
Trained batch 692 in epoch 7, gen_loss = 1.1203759064061989, disc_loss = 0.0026641622049154274
Trained batch 693 in epoch 7, gen_loss = 1.1204010026599214, disc_loss = 0.0026613707988180245
Trained batch 694 in epoch 7, gen_loss = 1.120935621021463, disc_loss = 0.002659818985411083
Trained batch 695 in epoch 7, gen_loss = 1.1209197282448582, disc_loss = 0.002657581811579531
Trained batch 696 in epoch 7, gen_loss = 1.1206794944692033, disc_loss = 0.002654911118840222
Trained batch 697 in epoch 7, gen_loss = 1.1211651768588746, disc_loss = 0.0026522854946168938
Trained batch 698 in epoch 7, gen_loss = 1.1211867398970117, disc_loss = 0.002649323101665839
Trained batch 699 in epoch 7, gen_loss = 1.1214654685769763, disc_loss = 0.0026489528653265942
Trained batch 700 in epoch 7, gen_loss = 1.1212787184327544, disc_loss = 0.00264770313375206
Trained batch 701 in epoch 7, gen_loss = 1.1213441379049904, disc_loss = 0.002647091356188439
Trained batch 702 in epoch 7, gen_loss = 1.121140658770652, disc_loss = 0.0026465366834465443
Trained batch 703 in epoch 7, gen_loss = 1.1211651858281007, disc_loss = 0.002644730771252894
Trained batch 704 in epoch 7, gen_loss = 1.121126016657403, disc_loss = 0.002642345265867205
Trained batch 705 in epoch 7, gen_loss = 1.1211342359061958, disc_loss = 0.0026403576630503554
Trained batch 706 in epoch 7, gen_loss = 1.121209617045509, disc_loss = 0.002638235427437978
Trained batch 707 in epoch 7, gen_loss = 1.1210423278606545, disc_loss = 0.002635821079759083
Trained batch 708 in epoch 7, gen_loss = 1.1210524338088688, disc_loss = 0.0026333368777440125
Trained batch 709 in epoch 7, gen_loss = 1.1209239974827834, disc_loss = 0.0026301642479461085
Trained batch 710 in epoch 7, gen_loss = 1.1208473967097479, disc_loss = 0.0026275018984917714
Trained batch 711 in epoch 7, gen_loss = 1.120702469951651, disc_loss = 0.0026248618059163276
Trained batch 712 in epoch 7, gen_loss = 1.1209677653426375, disc_loss = 0.002621928350884434
Trained batch 713 in epoch 7, gen_loss = 1.1208563260003632, disc_loss = 0.0026194045434958474
Trained batch 714 in epoch 7, gen_loss = 1.121011112786673, disc_loss = 0.002616882447279107
Trained batch 715 in epoch 7, gen_loss = 1.1210796501716422, disc_loss = 0.0026148998785677645
Trained batch 716 in epoch 7, gen_loss = 1.1210474023592853, disc_loss = 0.0026120760809323126
Trained batch 717 in epoch 7, gen_loss = 1.1211938602346563, disc_loss = 0.0026092333691266805
Trained batch 718 in epoch 7, gen_loss = 1.121207543142316, disc_loss = 0.0026068300964079715
Trained batch 719 in epoch 7, gen_loss = 1.1213123396039009, disc_loss = 0.0026038957073069467
Trained batch 720 in epoch 7, gen_loss = 1.1213844812858782, disc_loss = 0.0026010291602310918
Trained batch 721 in epoch 7, gen_loss = 1.1213135271851706, disc_loss = 0.0025981532950767727
Trained batch 722 in epoch 7, gen_loss = 1.121394443973631, disc_loss = 0.0025951662249490393
Trained batch 723 in epoch 7, gen_loss = 1.1214988272822364, disc_loss = 0.00259349689948077
Trained batch 724 in epoch 7, gen_loss = 1.1218902132428925, disc_loss = 0.002591280142891076
Trained batch 725 in epoch 7, gen_loss = 1.1219182454521663, disc_loss = 0.002588807619608552
Trained batch 726 in epoch 7, gen_loss = 1.121836169713793, disc_loss = 0.0025909741224992176
Trained batch 727 in epoch 7, gen_loss = 1.1217615751774757, disc_loss = 0.002592577506530378
Trained batch 728 in epoch 7, gen_loss = 1.1216303157544758, disc_loss = 0.0025902601370329406
Trained batch 729 in epoch 7, gen_loss = 1.1217468888792272, disc_loss = 0.0025895519598011624
Trained batch 730 in epoch 7, gen_loss = 1.121856869816291, disc_loss = 0.0025890338539755675
Trained batch 731 in epoch 7, gen_loss = 1.1220783360017454, disc_loss = 0.0025861977414461646
Trained batch 732 in epoch 7, gen_loss = 1.1220383367629525, disc_loss = 0.0025833730877328335
Trained batch 733 in epoch 7, gen_loss = 1.1219881621953252, disc_loss = 0.0025805557967622465
Trained batch 734 in epoch 7, gen_loss = 1.122087442631624, disc_loss = 0.002579628644627123
Trained batch 735 in epoch 7, gen_loss = 1.1220533549785614, disc_loss = 0.002577532868569862
Trained batch 736 in epoch 7, gen_loss = 1.121988656401149, disc_loss = 0.002574962962312094
Trained batch 737 in epoch 7, gen_loss = 1.1218877063211063, disc_loss = 0.0025728221013556016
Trained batch 738 in epoch 7, gen_loss = 1.1221679176464778, disc_loss = 0.0025720857806568833
Trained batch 739 in epoch 7, gen_loss = 1.1225237744885521, disc_loss = 0.0025695085677816185
Trained batch 740 in epoch 7, gen_loss = 1.1227061959252504, disc_loss = 0.0025674506043469347
Trained batch 741 in epoch 7, gen_loss = 1.1225543150683297, disc_loss = 0.002565274274306867
Trained batch 742 in epoch 7, gen_loss = 1.1227444350960116, disc_loss = 0.002562953109906947
Trained batch 743 in epoch 7, gen_loss = 1.122752258373845, disc_loss = 0.0025602135869101854
Trained batch 744 in epoch 7, gen_loss = 1.1228448203746104, disc_loss = 0.002557718272419762
Trained batch 745 in epoch 7, gen_loss = 1.1229841592484442, disc_loss = 0.002555367862885701
Trained batch 746 in epoch 7, gen_loss = 1.122696176350835, disc_loss = 0.0025537542733096536
Trained batch 747 in epoch 7, gen_loss = 1.1228803040031443, disc_loss = 0.002552437990451967
Trained batch 748 in epoch 7, gen_loss = 1.1229657551475138, disc_loss = 0.0025502789563404426
Trained batch 749 in epoch 7, gen_loss = 1.1228968985080718, disc_loss = 0.0025479374767455737
Trained batch 750 in epoch 7, gen_loss = 1.1227291712906962, disc_loss = 0.0025471907506961797
Trained batch 751 in epoch 7, gen_loss = 1.1227968290765236, disc_loss = 0.0025483352575994354
Trained batch 752 in epoch 7, gen_loss = 1.1227929294505126, disc_loss = 0.0025459118175542492
Trained batch 753 in epoch 7, gen_loss = 1.1228352320289106, disc_loss = 0.002543371591153224
Trained batch 754 in epoch 7, gen_loss = 1.1227789400429125, disc_loss = 0.0025417440152740176
Trained batch 755 in epoch 7, gen_loss = 1.1225852742396965, disc_loss = 0.00253954650609572
Trained batch 756 in epoch 7, gen_loss = 1.122619884332231, disc_loss = 0.00253746992466632
Trained batch 757 in epoch 7, gen_loss = 1.1225333018793595, disc_loss = 0.0025356643402748244
Trained batch 758 in epoch 7, gen_loss = 1.1224155749571025, disc_loss = 0.0025329593694064065
Trained batch 759 in epoch 7, gen_loss = 1.1223388969898225, disc_loss = 0.002530574190285207
Trained batch 760 in epoch 7, gen_loss = 1.1222396216473973, disc_loss = 0.002528496424647421
Trained batch 761 in epoch 7, gen_loss = 1.122374793519498, disc_loss = 0.0025264895343597707
Trained batch 762 in epoch 7, gen_loss = 1.1221833086107535, disc_loss = 0.0025243758421860723
Trained batch 763 in epoch 7, gen_loss = 1.1221300055375274, disc_loss = 0.0025221067300653455
Trained batch 764 in epoch 7, gen_loss = 1.1222924114831911, disc_loss = 0.002519246182806586
Trained batch 765 in epoch 7, gen_loss = 1.1224645148213788, disc_loss = 0.002516873061420854
Trained batch 766 in epoch 7, gen_loss = 1.1223441490604793, disc_loss = 0.002514152432318107
Trained batch 767 in epoch 7, gen_loss = 1.1222738272044808, disc_loss = 0.0025114994372662145
Trained batch 768 in epoch 7, gen_loss = 1.1221646125511944, disc_loss = 0.0025085729570555686
Trained batch 769 in epoch 7, gen_loss = 1.1225804565014776, disc_loss = 0.0025057676571512795
Trained batch 770 in epoch 7, gen_loss = 1.122497923411284, disc_loss = 0.0025030544390766784
Trained batch 771 in epoch 7, gen_loss = 1.1225105226811967, disc_loss = 0.002501412699402957
Trained batch 772 in epoch 7, gen_loss = 1.1225163181725635, disc_loss = 0.0024988305573427736
Trained batch 773 in epoch 7, gen_loss = 1.1226685312829277, disc_loss = 0.0024962599333848722
Trained batch 774 in epoch 7, gen_loss = 1.1226364142664018, disc_loss = 0.002493633333858358
Trained batch 775 in epoch 7, gen_loss = 1.122779952880648, disc_loss = 0.002491179595203106
Trained batch 776 in epoch 7, gen_loss = 1.1226144291872837, disc_loss = 0.0024888084405447187
Trained batch 777 in epoch 7, gen_loss = 1.122388912273863, disc_loss = 0.0024864561163828857
Trained batch 778 in epoch 7, gen_loss = 1.1226303986774635, disc_loss = 0.00248422679160215
Trained batch 779 in epoch 7, gen_loss = 1.122609025010696, disc_loss = 0.002483709123165075
Trained batch 780 in epoch 7, gen_loss = 1.1223701477508692, disc_loss = 0.002482501528412238
Trained batch 781 in epoch 7, gen_loss = 1.1222423739597926, disc_loss = 0.002480494661910279
Trained batch 782 in epoch 7, gen_loss = 1.1223077200838432, disc_loss = 0.002479528601345351
Trained batch 783 in epoch 7, gen_loss = 1.1222536176899258, disc_loss = 0.00247744548629011
Trained batch 784 in epoch 7, gen_loss = 1.1222399407131656, disc_loss = 0.0024751854798060273
Trained batch 785 in epoch 7, gen_loss = 1.1223137787431858, disc_loss = 0.0024725686379388576
Trained batch 786 in epoch 7, gen_loss = 1.1227174466416676, disc_loss = 0.002470658183017739
Trained batch 787 in epoch 7, gen_loss = 1.1228393500075122, disc_loss = 0.00246790481008612
Trained batch 788 in epoch 7, gen_loss = 1.1230094323291222, disc_loss = 0.0024654156610689716
Trained batch 789 in epoch 7, gen_loss = 1.1229711747622189, disc_loss = 0.0024634315847523094
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 1.1840789318084717, disc_loss = 0.00040616735350340605
Trained batch 1 in epoch 8, gen_loss = 1.2664833664894104, disc_loss = 0.0004762508615385741
Trained batch 2 in epoch 8, gen_loss = 1.2314213514328003, disc_loss = 0.0004310920388282587
Trained batch 3 in epoch 8, gen_loss = 1.2726786136627197, disc_loss = 0.0004109269139007665
Trained batch 4 in epoch 8, gen_loss = 1.2341528415679932, disc_loss = 0.0004861427762079984
Trained batch 5 in epoch 8, gen_loss = 1.1936551729838054, disc_loss = 0.0005456201082173114
Trained batch 6 in epoch 8, gen_loss = 1.178276743207659, disc_loss = 0.0005198071220157934
Trained batch 7 in epoch 8, gen_loss = 1.1543534994125366, disc_loss = 0.0006078283076931257
Trained batch 8 in epoch 8, gen_loss = 1.169986857308282, disc_loss = 0.000639922848980253
Trained batch 9 in epoch 8, gen_loss = 1.1672407269477845, disc_loss = 0.0006473481626017019
Trained batch 10 in epoch 8, gen_loss = 1.1965695186094805, disc_loss = 0.0006191630831877278
Trained batch 11 in epoch 8, gen_loss = 1.1963716546694438, disc_loss = 0.0006699304431094788
Trained batch 12 in epoch 8, gen_loss = 1.1866548611567571, disc_loss = 0.0006588211421890614
Trained batch 13 in epoch 8, gen_loss = 1.1900223919323512, disc_loss = 0.0006648583616229839
Trained batch 14 in epoch 8, gen_loss = 1.1715757171312968, disc_loss = 0.0006789472206340482
Trained batch 15 in epoch 8, gen_loss = 1.171003807336092, disc_loss = 0.0006811451730754925
Trained batch 16 in epoch 8, gen_loss = 1.1728498900637907, disc_loss = 0.0006714042615118053
Trained batch 17 in epoch 8, gen_loss = 1.1625874373647902, disc_loss = 0.0007148800440417188
Trained batch 18 in epoch 8, gen_loss = 1.157566001540736, disc_loss = 0.0007239103357087037
Trained batch 19 in epoch 8, gen_loss = 1.1562182903289795, disc_loss = 0.0007205730493296869
Trained batch 20 in epoch 8, gen_loss = 1.1584261712573825, disc_loss = 0.0007147851242085121
Trained batch 21 in epoch 8, gen_loss = 1.1498592360453173, disc_loss = 0.0007011705932778899
Trained batch 22 in epoch 8, gen_loss = 1.1545480152835017, disc_loss = 0.0007080285286065191
Trained batch 23 in epoch 8, gen_loss = 1.1532746975620587, disc_loss = 0.0006929930289819216
Trained batch 24 in epoch 8, gen_loss = 1.1497202229499817, disc_loss = 0.0007108943490311503
Trained batch 25 in epoch 8, gen_loss = 1.145968645811081, disc_loss = 0.0007511038745108705
Trained batch 26 in epoch 8, gen_loss = 1.1412259803877935, disc_loss = 0.0007427778306279193
Trained batch 27 in epoch 8, gen_loss = 1.1343811941998345, disc_loss = 0.0007307274572667666
Trained batch 28 in epoch 8, gen_loss = 1.1410569507500221, disc_loss = 0.0007204602418290772
Trained batch 29 in epoch 8, gen_loss = 1.1382386227448782, disc_loss = 0.0007381470262771472
Trained batch 30 in epoch 8, gen_loss = 1.131034501137272, disc_loss = 0.0007988838713631154
Trained batch 31 in epoch 8, gen_loss = 1.1271252073347569, disc_loss = 0.0008039412286962033
Trained batch 32 in epoch 8, gen_loss = 1.1303328853664976, disc_loss = 0.0008302166763424987
Trained batch 33 in epoch 8, gen_loss = 1.1338687398854423, disc_loss = 0.0008405239727033083
Trained batch 34 in epoch 8, gen_loss = 1.1311981167112077, disc_loss = 0.0008436621141819549
Trained batch 35 in epoch 8, gen_loss = 1.1349527438481648, disc_loss = 0.0008459403575721404
Trained batch 36 in epoch 8, gen_loss = 1.136993646621704, disc_loss = 0.0008478875317598215
Trained batch 37 in epoch 8, gen_loss = 1.138142871229272, disc_loss = 0.000835572682645809
Trained batch 38 in epoch 8, gen_loss = 1.1372535014763856, disc_loss = 0.0008291489159604773
Trained batch 39 in epoch 8, gen_loss = 1.1342910557985306, disc_loss = 0.0008202445271308534
Trained batch 40 in epoch 8, gen_loss = 1.1385264774648154, disc_loss = 0.000814343517271393
Trained batch 41 in epoch 8, gen_loss = 1.133359737339474, disc_loss = 0.0008178505882997776
Trained batch 42 in epoch 8, gen_loss = 1.1340953929479731, disc_loss = 0.0008078330794760827
Trained batch 43 in epoch 8, gen_loss = 1.1373118175701662, disc_loss = 0.000797761739125814
Trained batch 44 in epoch 8, gen_loss = 1.1352139751116435, disc_loss = 0.0008215866905326645
Trained batch 45 in epoch 8, gen_loss = 1.13161828595659, disc_loss = 0.0008269906798175172
Trained batch 46 in epoch 8, gen_loss = 1.129324216791924, disc_loss = 0.0008198129288119046
Trained batch 47 in epoch 8, gen_loss = 1.1290253264208634, disc_loss = 0.0008353631261949582
Trained batch 48 in epoch 8, gen_loss = 1.1283681307520186, disc_loss = 0.0008365210829948893
Trained batch 49 in epoch 8, gen_loss = 1.1288717877864838, disc_loss = 0.0008287810604088008
Trained batch 50 in epoch 8, gen_loss = 1.1305870460528953, disc_loss = 0.0008212138451270613
Trained batch 51 in epoch 8, gen_loss = 1.1305166425613256, disc_loss = 0.000818588075792202
Trained batch 52 in epoch 8, gen_loss = 1.126516599700136, disc_loss = 0.0008183533077585107
Trained batch 53 in epoch 8, gen_loss = 1.1287728735694178, disc_loss = 0.0008253307476277567
Trained batch 54 in epoch 8, gen_loss = 1.1258463046767495, disc_loss = 0.0008210987275974317
Trained batch 55 in epoch 8, gen_loss = 1.1284953792180334, disc_loss = 0.0008317158021132595
Trained batch 56 in epoch 8, gen_loss = 1.1288952607857554, disc_loss = 0.0008408159524071635
Trained batch 57 in epoch 8, gen_loss = 1.1286787113239025, disc_loss = 0.0008346673336024556
Trained batch 58 in epoch 8, gen_loss = 1.1326851794275188, disc_loss = 0.0008304708852369528
Trained batch 59 in epoch 8, gen_loss = 1.1359327167272568, disc_loss = 0.000824080371724752
Trained batch 60 in epoch 8, gen_loss = 1.1373324071774717, disc_loss = 0.0008151909597905077
Trained batch 61 in epoch 8, gen_loss = 1.1348256324568102, disc_loss = 0.0008082819497963835
Trained batch 62 in epoch 8, gen_loss = 1.1332616872257657, disc_loss = 0.000802135245139075
Trained batch 63 in epoch 8, gen_loss = 1.1314690494909883, disc_loss = 0.0007984338558344461
Trained batch 64 in epoch 8, gen_loss = 1.1307517097546504, disc_loss = 0.0007939563773106783
Trained batch 65 in epoch 8, gen_loss = 1.1275345692128846, disc_loss = 0.0007870948770273985
Trained batch 66 in epoch 8, gen_loss = 1.1286088646347843, disc_loss = 0.0007818911138595318
Trained batch 67 in epoch 8, gen_loss = 1.1275517300647848, disc_loss = 0.0007847012024927501
Trained batch 68 in epoch 8, gen_loss = 1.1259133651636648, disc_loss = 0.0007875770928533883
Trained batch 69 in epoch 8, gen_loss = 1.1241370107446398, disc_loss = 0.000785647501054752
Trained batch 70 in epoch 8, gen_loss = 1.1232677085298888, disc_loss = 0.0007831404361919775
Trained batch 71 in epoch 8, gen_loss = 1.12085869246059, disc_loss = 0.0007766490719707994
Trained batch 72 in epoch 8, gen_loss = 1.1181095250665325, disc_loss = 0.000771861059721942
Trained batch 73 in epoch 8, gen_loss = 1.1179101805429201, disc_loss = 0.0007697717704325663
Trained batch 74 in epoch 8, gen_loss = 1.1170849847793578, disc_loss = 0.0007629018307973942
Trained batch 75 in epoch 8, gen_loss = 1.1155112479862415, disc_loss = 0.0007638089001901742
Trained batch 76 in epoch 8, gen_loss = 1.1161465613872974, disc_loss = 0.0007657922181458055
Trained batch 77 in epoch 8, gen_loss = 1.1156454178003163, disc_loss = 0.0007600259264925113
Trained batch 78 in epoch 8, gen_loss = 1.1161365780649306, disc_loss = 0.0007565112248847049
Trained batch 79 in epoch 8, gen_loss = 1.1158094823360443, disc_loss = 0.0007504390719986987
Trained batch 80 in epoch 8, gen_loss = 1.1158893387994648, disc_loss = 0.0007454883623408315
Trained batch 81 in epoch 8, gen_loss = 1.1135849661943389, disc_loss = 0.0007437783841429869
Trained batch 82 in epoch 8, gen_loss = 1.114290734371507, disc_loss = 0.0007428034364402922
Trained batch 83 in epoch 8, gen_loss = 1.1175226129236675, disc_loss = 0.0007430674955858627
Trained batch 84 in epoch 8, gen_loss = 1.1193832832224229, disc_loss = 0.0007390670416712323
Trained batch 85 in epoch 8, gen_loss = 1.1177333939907164, disc_loss = 0.0007380678333331246
Trained batch 86 in epoch 8, gen_loss = 1.1170926642143864, disc_loss = 0.0007327386009474767
Trained batch 87 in epoch 8, gen_loss = 1.11668191308325, disc_loss = 0.000728023872811305
Trained batch 88 in epoch 8, gen_loss = 1.1159940636559817, disc_loss = 0.0007248148547741847
Trained batch 89 in epoch 8, gen_loss = 1.1139799270364974, disc_loss = 0.0007226431422168389
Trained batch 90 in epoch 8, gen_loss = 1.114213615328401, disc_loss = 0.000720862103152795
Trained batch 91 in epoch 8, gen_loss = 1.1124620988317158, disc_loss = 0.0007181278453335044
Trained batch 92 in epoch 8, gen_loss = 1.1145102855979756, disc_loss = 0.0007137780444526304
Trained batch 93 in epoch 8, gen_loss = 1.1151793821060911, disc_loss = 0.0007090142115633539
Trained batch 94 in epoch 8, gen_loss = 1.114798235265832, disc_loss = 0.0007054861163181302
Trained batch 95 in epoch 8, gen_loss = 1.114765369022886, disc_loss = 0.00070313348229926
Trained batch 96 in epoch 8, gen_loss = 1.1140411496162415, disc_loss = 0.0007168707463616678
Trained batch 97 in epoch 8, gen_loss = 1.114205117736544, disc_loss = 0.0007272597508652288
Trained batch 98 in epoch 8, gen_loss = 1.112571738585077, disc_loss = 0.0007268139569799068
Trained batch 99 in epoch 8, gen_loss = 1.1135767501592637, disc_loss = 0.0007464932263246737
Trained batch 100 in epoch 8, gen_loss = 1.114140498166037, disc_loss = 0.0007573040925533428
Trained batch 101 in epoch 8, gen_loss = 1.1136850101106308, disc_loss = 0.0007588513707399697
Trained batch 102 in epoch 8, gen_loss = 1.112923900479252, disc_loss = 0.0007574734251462466
Trained batch 103 in epoch 8, gen_loss = 1.1118525066054785, disc_loss = 0.0007688400826457207
Trained batch 104 in epoch 8, gen_loss = 1.1116733318283445, disc_loss = 0.0007687444391194731
Trained batch 105 in epoch 8, gen_loss = 1.111747049498108, disc_loss = 0.0007656026817748394
Trained batch 106 in epoch 8, gen_loss = 1.1159688262181862, disc_loss = 0.0007628821607387547
Trained batch 107 in epoch 8, gen_loss = 1.1181991966786209, disc_loss = 0.0007636323563120742
Trained batch 108 in epoch 8, gen_loss = 1.120172934247813, disc_loss = 0.0007614515245990366
Trained batch 109 in epoch 8, gen_loss = 1.1203853558410297, disc_loss = 0.0007567300268089061
Trained batch 110 in epoch 8, gen_loss = 1.1194332220532872, disc_loss = 0.000756542560977962
Trained batch 111 in epoch 8, gen_loss = 1.118893044867686, disc_loss = 0.0007579131776895208
Trained batch 112 in epoch 8, gen_loss = 1.1190714756999396, disc_loss = 0.0007592309140126361
Trained batch 113 in epoch 8, gen_loss = 1.1181480994350033, disc_loss = 0.0007571295154456605
Trained batch 114 in epoch 8, gen_loss = 1.118583795817002, disc_loss = 0.0007530567580429108
Trained batch 115 in epoch 8, gen_loss = 1.118387645174717, disc_loss = 0.0007564186786927668
Trained batch 116 in epoch 8, gen_loss = 1.1211004863437424, disc_loss = 0.000758822794414611
Trained batch 117 in epoch 8, gen_loss = 1.1220914181006156, disc_loss = 0.000755419739831823
Trained batch 118 in epoch 8, gen_loss = 1.1215566922636593, disc_loss = 0.000755352303904223
Trained batch 119 in epoch 8, gen_loss = 1.1220511381824811, disc_loss = 0.0007549173894706958
Trained batch 120 in epoch 8, gen_loss = 1.122435326911201, disc_loss = 0.0007512870074869403
Trained batch 121 in epoch 8, gen_loss = 1.1221286845011789, disc_loss = 0.0007505419558643165
Trained batch 122 in epoch 8, gen_loss = 1.1207580837776991, disc_loss = 0.0007542665066799467
Trained batch 123 in epoch 8, gen_loss = 1.1206160802995004, disc_loss = 0.0007563035720640103
Trained batch 124 in epoch 8, gen_loss = 1.1210764770507813, disc_loss = 0.0007529463504906743
Trained batch 125 in epoch 8, gen_loss = 1.1230182534172422, disc_loss = 0.000752307269269497
Trained batch 126 in epoch 8, gen_loss = 1.1220660463092833, disc_loss = 0.000749872881216987
Trained batch 127 in epoch 8, gen_loss = 1.1211377242580056, disc_loss = 0.0007467299467407429
Trained batch 128 in epoch 8, gen_loss = 1.119885646557623, disc_loss = 0.0007432083061863777
Trained batch 129 in epoch 8, gen_loss = 1.119102440889065, disc_loss = 0.000743048769968132
Trained batch 130 in epoch 8, gen_loss = 1.11928584420954, disc_loss = 0.0007412806577635716
Trained batch 131 in epoch 8, gen_loss = 1.1179282574942617, disc_loss = 0.0007406588280873345
Trained batch 132 in epoch 8, gen_loss = 1.1184426626764743, disc_loss = 0.0007414207756571836
Trained batch 133 in epoch 8, gen_loss = 1.1177584164178194, disc_loss = 0.0007422060465506181
Trained batch 134 in epoch 8, gen_loss = 1.116178192032708, disc_loss = 0.0007416473751180564
Trained batch 135 in epoch 8, gen_loss = 1.1170104216126835, disc_loss = 0.0007387942046882338
Trained batch 136 in epoch 8, gen_loss = 1.1170399780691105, disc_loss = 0.0007349808886689712
Trained batch 137 in epoch 8, gen_loss = 1.11701793687931, disc_loss = 0.0007312387004250027
Trained batch 138 in epoch 8, gen_loss = 1.1158260107040405, disc_loss = 0.0007284702129097549
Trained batch 139 in epoch 8, gen_loss = 1.1145734199455806, disc_loss = 0.0007255280534861543
Trained batch 140 in epoch 8, gen_loss = 1.113928940279264, disc_loss = 0.000724555838152152
Trained batch 141 in epoch 8, gen_loss = 1.1138242130548182, disc_loss = 0.0007213191562750324
Trained batch 142 in epoch 8, gen_loss = 1.1142793135209517, disc_loss = 0.0007176139106822584
Trained batch 143 in epoch 8, gen_loss = 1.1123123963673909, disc_loss = 0.0007222951667750345
Trained batch 144 in epoch 8, gen_loss = 1.1121246354333285, disc_loss = 0.0007216307907646265
Trained batch 145 in epoch 8, gen_loss = 1.113998963408274, disc_loss = 0.0007196065641051375
Trained batch 146 in epoch 8, gen_loss = 1.115085091720633, disc_loss = 0.0007174094784711836
Trained batch 147 in epoch 8, gen_loss = 1.114511485035355, disc_loss = 0.0007141697580565862
Trained batch 148 in epoch 8, gen_loss = 1.1155447487863117, disc_loss = 0.00071213901503521
Trained batch 149 in epoch 8, gen_loss = 1.1155665691693624, disc_loss = 0.0007083287325804122
Trained batch 150 in epoch 8, gen_loss = 1.1148676327522227, disc_loss = 0.0007047942647400516
Trained batch 151 in epoch 8, gen_loss = 1.11473417046823, disc_loss = 0.0007021523399185083
Trained batch 152 in epoch 8, gen_loss = 1.1153987614937078, disc_loss = 0.0006995481714565197
Trained batch 153 in epoch 8, gen_loss = 1.1152858594795325, disc_loss = 0.0006969361230557144
Trained batch 154 in epoch 8, gen_loss = 1.116965926078058, disc_loss = 0.0006989039267571042
Trained batch 155 in epoch 8, gen_loss = 1.1163370502300751, disc_loss = 0.0006985505540050769
Trained batch 156 in epoch 8, gen_loss = 1.1165124246269276, disc_loss = 0.0006955468491057919
Trained batch 157 in epoch 8, gen_loss = 1.1179018080989016, disc_loss = 0.0006932227959255158
Trained batch 158 in epoch 8, gen_loss = 1.1166874312754698, disc_loss = 0.0006924209323325107
Trained batch 159 in epoch 8, gen_loss = 1.116633166372776, disc_loss = 0.0006909515403094701
Trained batch 160 in epoch 8, gen_loss = 1.114949573641238, disc_loss = 0.000691829973785496
Trained batch 161 in epoch 8, gen_loss = 1.1149210289672569, disc_loss = 0.0006931159145164269
Trained batch 162 in epoch 8, gen_loss = 1.1142695513239667, disc_loss = 0.0006914815427649743
Trained batch 163 in epoch 8, gen_loss = 1.1162701052863424, disc_loss = 0.0006900922920222667
Trained batch 164 in epoch 8, gen_loss = 1.1163948319175028, disc_loss = 0.0006888321743727746
Trained batch 165 in epoch 8, gen_loss = 1.1160071025411766, disc_loss = 0.0006880934109296987
Trained batch 166 in epoch 8, gen_loss = 1.116474255830228, disc_loss = 0.0006871612501695953
Trained batch 167 in epoch 8, gen_loss = 1.1167842256171363, disc_loss = 0.0006853656150702765
Trained batch 168 in epoch 8, gen_loss = 1.1170814326528966, disc_loss = 0.0006833013211523
Trained batch 169 in epoch 8, gen_loss = 1.1158305154127233, disc_loss = 0.0006827424850438119
Trained batch 170 in epoch 8, gen_loss = 1.115785775128861, disc_loss = 0.0006811774449153362
Trained batch 171 in epoch 8, gen_loss = 1.1162851480550544, disc_loss = 0.0006786180952182148
Trained batch 172 in epoch 8, gen_loss = 1.116878629419845, disc_loss = 0.0006759523018229634
Trained batch 173 in epoch 8, gen_loss = 1.11719504855145, disc_loss = 0.000674073171488079
Trained batch 174 in epoch 8, gen_loss = 1.115895711013249, disc_loss = 0.0006726477764979271
Trained batch 175 in epoch 8, gen_loss = 1.1171827468682418, disc_loss = 0.0006708589516248056
Trained batch 176 in epoch 8, gen_loss = 1.1159209757201416, disc_loss = 0.0006757527159817654
Trained batch 177 in epoch 8, gen_loss = 1.1163324295135026, disc_loss = 0.0006766963013208451
Trained batch 178 in epoch 8, gen_loss = 1.116086622523196, disc_loss = 0.0006744292506645044
Trained batch 179 in epoch 8, gen_loss = 1.116312829322285, disc_loss = 0.0006719978341910367
Trained batch 180 in epoch 8, gen_loss = 1.1164629719533974, disc_loss = 0.0006704865232848393
Trained batch 181 in epoch 8, gen_loss = 1.1158181330659886, disc_loss = 0.0006690899965258643
Trained batch 182 in epoch 8, gen_loss = 1.1171201754137468, disc_loss = 0.0006683377466034755
Trained batch 183 in epoch 8, gen_loss = 1.1171298227880313, disc_loss = 0.0006659705811572443
Trained batch 184 in epoch 8, gen_loss = 1.1185752353152714, disc_loss = 0.000664002336152653
Trained batch 185 in epoch 8, gen_loss = 1.1186475138510428, disc_loss = 0.0006650007310791582
Trained batch 186 in epoch 8, gen_loss = 1.119348273557775, disc_loss = 0.0006629969271953232
Trained batch 187 in epoch 8, gen_loss = 1.1205460517964465, disc_loss = 0.0006608407182168176
Trained batch 188 in epoch 8, gen_loss = 1.120400556180843, disc_loss = 0.0006584157667858231
Trained batch 189 in epoch 8, gen_loss = 1.1207841672395404, disc_loss = 0.0006562710688357535
Trained batch 190 in epoch 8, gen_loss = 1.1216641633298385, disc_loss = 0.0006539785804187986
Trained batch 191 in epoch 8, gen_loss = 1.122178219879667, disc_loss = 0.0006519041665645394
Trained batch 192 in epoch 8, gen_loss = 1.1223473023874155, disc_loss = 0.0006500140803328044
Trained batch 193 in epoch 8, gen_loss = 1.1235408039437127, disc_loss = 0.0006480757820662399
Trained batch 194 in epoch 8, gen_loss = 1.1234896152447431, disc_loss = 0.0006456481167473472
Trained batch 195 in epoch 8, gen_loss = 1.1226936046566283, disc_loss = 0.0006442898112273185
Trained batch 196 in epoch 8, gen_loss = 1.1237015703002813, disc_loss = 0.0006428588530980051
Trained batch 197 in epoch 8, gen_loss = 1.1236068374580808, disc_loss = 0.0006490342846408373
Trained batch 198 in epoch 8, gen_loss = 1.1245388208921232, disc_loss = 0.0006536937745208455
Trained batch 199 in epoch 8, gen_loss = 1.124999735057354, disc_loss = 0.0006542942454689182
Trained batch 200 in epoch 8, gen_loss = 1.1255476412488454, disc_loss = 0.0006558639631578838
Trained batch 201 in epoch 8, gen_loss = 1.1259636073419363, disc_loss = 0.0006583001177024908
Trained batch 202 in epoch 8, gen_loss = 1.1250594308223631, disc_loss = 0.0006599530553000203
Trained batch 203 in epoch 8, gen_loss = 1.1264619307190764, disc_loss = 0.0006619273583911469
Trained batch 204 in epoch 8, gen_loss = 1.127485018823205, disc_loss = 0.0006612876421635653
Trained batch 205 in epoch 8, gen_loss = 1.1276997136838227, disc_loss = 0.0006607832874225688
Trained batch 206 in epoch 8, gen_loss = 1.1276881896355302, disc_loss = 0.0006590157872119892
Trained batch 207 in epoch 8, gen_loss = 1.127295161669071, disc_loss = 0.0006573907938638093
Trained batch 208 in epoch 8, gen_loss = 1.126436195875469, disc_loss = 0.0006562541837750546
Trained batch 209 in epoch 8, gen_loss = 1.1253006393001193, disc_loss = 0.0006559663432805489
Trained batch 210 in epoch 8, gen_loss = 1.126080200287968, disc_loss = 0.0006543211841688743
Trained batch 211 in epoch 8, gen_loss = 1.1260169471772212, disc_loss = 0.0006522123796869737
Trained batch 212 in epoch 8, gen_loss = 1.1250919688475525, disc_loss = 0.000651162643638164
Trained batch 213 in epoch 8, gen_loss = 1.1261601679235975, disc_loss = 0.0006497109244375219
Trained batch 214 in epoch 8, gen_loss = 1.1257725036421486, disc_loss = 0.0006507605870611706
Trained batch 215 in epoch 8, gen_loss = 1.125579428065706, disc_loss = 0.0006508474415804139
Trained batch 216 in epoch 8, gen_loss = 1.125631915534147, disc_loss = 0.000649375724740335
Trained batch 217 in epoch 8, gen_loss = 1.1256069724166065, disc_loss = 0.0006474433084303693
Trained batch 218 in epoch 8, gen_loss = 1.1258119135142461, disc_loss = 0.0006468943045788219
Trained batch 219 in epoch 8, gen_loss = 1.126804438775236, disc_loss = 0.0006449521737522445
Trained batch 220 in epoch 8, gen_loss = 1.1271245520039381, disc_loss = 0.0006441581508089952
Trained batch 221 in epoch 8, gen_loss = 1.1291286760085337, disc_loss = 0.000644262191820638
Trained batch 222 in epoch 8, gen_loss = 1.1294176853825693, disc_loss = 0.0006422913471323484
Trained batch 223 in epoch 8, gen_loss = 1.1284267324954271, disc_loss = 0.0006407481589251672
Trained batch 224 in epoch 8, gen_loss = 1.1287188495530023, disc_loss = 0.0006394009356154129
Trained batch 225 in epoch 8, gen_loss = 1.129122985939009, disc_loss = 0.0006378296727548452
Trained batch 226 in epoch 8, gen_loss = 1.1287179400217167, disc_loss = 0.0006361686482144487
Trained batch 227 in epoch 8, gen_loss = 1.128476762196474, disc_loss = 0.0006351153269382561
Trained batch 228 in epoch 8, gen_loss = 1.1285502444708713, disc_loss = 0.0006329626508751543
Trained batch 229 in epoch 8, gen_loss = 1.1289711498695871, disc_loss = 0.0006308163171406309
Trained batch 230 in epoch 8, gen_loss = 1.1282234055139286, disc_loss = 0.0006293175558461828
Trained batch 231 in epoch 8, gen_loss = 1.127288329960971, disc_loss = 0.0006280539617928926
Trained batch 232 in epoch 8, gen_loss = 1.1273484498646127, disc_loss = 0.0006267166562960982
Trained batch 233 in epoch 8, gen_loss = 1.1263748165379224, disc_loss = 0.0006250221893921669
Trained batch 234 in epoch 8, gen_loss = 1.1254613287905428, disc_loss = 0.0006242865871172399
Trained batch 235 in epoch 8, gen_loss = 1.1252136260776195, disc_loss = 0.0006258547819324107
Trained batch 236 in epoch 8, gen_loss = 1.1246767406222187, disc_loss = 0.0006244723117254077
Trained batch 237 in epoch 8, gen_loss = 1.1249920600602608, disc_loss = 0.0006251412075983376
Trained batch 238 in epoch 8, gen_loss = 1.1244130144558193, disc_loss = 0.000625610408065334
Trained batch 239 in epoch 8, gen_loss = 1.1241486663619678, disc_loss = 0.0006241845473899351
Trained batch 240 in epoch 8, gen_loss = 1.1246175419740163, disc_loss = 0.0006233736122977685
Trained batch 241 in epoch 8, gen_loss = 1.1245357763668722, disc_loss = 0.0006222012155729708
Trained batch 242 in epoch 8, gen_loss = 1.1260991081779386, disc_loss = 0.0006207801769784586
Trained batch 243 in epoch 8, gen_loss = 1.1266015631253603, disc_loss = 0.0006192573422535521
Trained batch 244 in epoch 8, gen_loss = 1.1264427666761436, disc_loss = 0.0006183123947786434
Trained batch 245 in epoch 8, gen_loss = 1.125857754936063, disc_loss = 0.0006167922999257434
Trained batch 246 in epoch 8, gen_loss = 1.1268287940546569, disc_loss = 0.0006158431412921729
Trained batch 247 in epoch 8, gen_loss = 1.1280692181279581, disc_loss = 0.0006143702143632372
Trained batch 248 in epoch 8, gen_loss = 1.1272053170395664, disc_loss = 0.0006138399699431691
Trained batch 249 in epoch 8, gen_loss = 1.127565153837204, disc_loss = 0.0006126218523131683
Trained batch 250 in epoch 8, gen_loss = 1.128550145968023, disc_loss = 0.0006111307645706364
Trained batch 251 in epoch 8, gen_loss = 1.1298440905317428, disc_loss = 0.0006093459209267398
Trained batch 252 in epoch 8, gen_loss = 1.129377656538967, disc_loss = 0.0006091548918480451
Trained batch 253 in epoch 8, gen_loss = 1.1285217702388763, disc_loss = 0.0006079441481283646
Trained batch 254 in epoch 8, gen_loss = 1.1283133116422914, disc_loss = 0.0006069249138532791
Trained batch 255 in epoch 8, gen_loss = 1.127455192618072, disc_loss = 0.0006082586779143639
Trained batch 256 in epoch 8, gen_loss = 1.126984464983068, disc_loss = 0.0006099349895790255
Trained batch 257 in epoch 8, gen_loss = 1.127146912637607, disc_loss = 0.00060989665434481
Trained batch 258 in epoch 8, gen_loss = 1.1262855828959049, disc_loss = 0.000608527084439903
Trained batch 259 in epoch 8, gen_loss = 1.12630886894006, disc_loss = 0.0006111451692749352
Trained batch 260 in epoch 8, gen_loss = 1.1264426356531194, disc_loss = 0.0006136354419712327
Trained batch 261 in epoch 8, gen_loss = 1.125878373857673, disc_loss = 0.0006139671161947666
Trained batch 262 in epoch 8, gen_loss = 1.1254201010152867, disc_loss = 0.0006139808494979233
Trained batch 263 in epoch 8, gen_loss = 1.1262438308560487, disc_loss = 0.0006132068082837522
Trained batch 264 in epoch 8, gen_loss = 1.1264226420870367, disc_loss = 0.0006122856737523041
Trained batch 265 in epoch 8, gen_loss = 1.1259253695046991, disc_loss = 0.0006107105294183856
Trained batch 266 in epoch 8, gen_loss = 1.1262507606088445, disc_loss = 0.0006090456463221272
Trained batch 267 in epoch 8, gen_loss = 1.1268889741666281, disc_loss = 0.0006075878791035841
Trained batch 268 in epoch 8, gen_loss = 1.1269325418986353, disc_loss = 0.0006059397604999385
Trained batch 269 in epoch 8, gen_loss = 1.1271317965454526, disc_loss = 0.0006047746394566881
Trained batch 270 in epoch 8, gen_loss = 1.1273370684292923, disc_loss = 0.0006033072434000609
Trained batch 271 in epoch 8, gen_loss = 1.126983019139837, disc_loss = 0.0006037109838229406
Trained batch 272 in epoch 8, gen_loss = 1.1269674587162424, disc_loss = 0.000605620962306226
Trained batch 273 in epoch 8, gen_loss = 1.1261597264857188, disc_loss = 0.0006056986383249963
Trained batch 274 in epoch 8, gen_loss = 1.1260894729874351, disc_loss = 0.0006053430614040487
Trained batch 275 in epoch 8, gen_loss = 1.1268649224353873, disc_loss = 0.0006046184646855683
Trained batch 276 in epoch 8, gen_loss = 1.1265377845574802, disc_loss = 0.0006037658249723156
Trained batch 277 in epoch 8, gen_loss = 1.1260897137707087, disc_loss = 0.000602536964120943
Trained batch 278 in epoch 8, gen_loss = 1.1261705311823063, disc_loss = 0.0006016562505575952
Trained batch 279 in epoch 8, gen_loss = 1.1264659351536206, disc_loss = 0.0006020250441776755
Trained batch 280 in epoch 8, gen_loss = 1.1265719117218913, disc_loss = 0.0006011756486777262
Trained batch 281 in epoch 8, gen_loss = 1.1257447991388063, disc_loss = 0.0006033704252950748
Trained batch 282 in epoch 8, gen_loss = 1.1254833702906282, disc_loss = 0.0006059924025494151
Trained batch 283 in epoch 8, gen_loss = 1.1248451229971899, disc_loss = 0.0006061602504468936
Trained batch 284 in epoch 8, gen_loss = 1.124534066727287, disc_loss = 0.0006063873534960868
Trained batch 285 in epoch 8, gen_loss = 1.1242791266291292, disc_loss = 0.0006053588962954977
Trained batch 286 in epoch 8, gen_loss = 1.1236320918860752, disc_loss = 0.0006040255545710704
Trained batch 287 in epoch 8, gen_loss = 1.1238970961421728, disc_loss = 0.0006028461351787781
Trained batch 288 in epoch 8, gen_loss = 1.1234777186156144, disc_loss = 0.0006015059222172378
Trained batch 289 in epoch 8, gen_loss = 1.1235424105463356, disc_loss = 0.0006002283803636915
Trained batch 290 in epoch 8, gen_loss = 1.1232179266070992, disc_loss = 0.0006032582781280798
Trained batch 291 in epoch 8, gen_loss = 1.1229240704480916, disc_loss = 0.0006045773621387014
Trained batch 292 in epoch 8, gen_loss = 1.1222816721978042, disc_loss = 0.0006055443858769134
Trained batch 293 in epoch 8, gen_loss = 1.1219870030474501, disc_loss = 0.0006064884762555285
Trained batch 294 in epoch 8, gen_loss = 1.121787114466651, disc_loss = 0.000606797738355916
Trained batch 295 in epoch 8, gen_loss = 1.1218043674488325, disc_loss = 0.0006072769530284269
Trained batch 296 in epoch 8, gen_loss = 1.121916732001385, disc_loss = 0.0006065139980510078
Trained batch 297 in epoch 8, gen_loss = 1.1212424891907096, disc_loss = 0.0006068453343894533
Trained batch 298 in epoch 8, gen_loss = 1.1216532215226853, disc_loss = 0.0006077499080209504
Trained batch 299 in epoch 8, gen_loss = 1.1219375503063203, disc_loss = 0.0006078364787390455
Trained batch 300 in epoch 8, gen_loss = 1.1225479706577288, disc_loss = 0.0006076318190194839
Trained batch 301 in epoch 8, gen_loss = 1.1227577202367467, disc_loss = 0.0006071395731827133
Trained batch 302 in epoch 8, gen_loss = 1.1228814062112236, disc_loss = 0.0006067435996354905
Trained batch 303 in epoch 8, gen_loss = 1.1229009071463032, disc_loss = 0.0006058493218963696
Trained batch 304 in epoch 8, gen_loss = 1.1226453914016974, disc_loss = 0.0006048887093994217
Trained batch 305 in epoch 8, gen_loss = 1.122454066681706, disc_loss = 0.0006035227089621175
Trained batch 306 in epoch 8, gen_loss = 1.1220628858000914, disc_loss = 0.0006024005068412979
Trained batch 307 in epoch 8, gen_loss = 1.1220501537446852, disc_loss = 0.0006012645843567314
Trained batch 308 in epoch 8, gen_loss = 1.1217463545043105, disc_loss = 0.00060016047622041
Trained batch 309 in epoch 8, gen_loss = 1.1214788233080217, disc_loss = 0.0005986398135240551
Trained batch 310 in epoch 8, gen_loss = 1.1213034230413161, disc_loss = 0.0005974803618967706
Trained batch 311 in epoch 8, gen_loss = 1.121037067893224, disc_loss = 0.0005969210540057154
Trained batch 312 in epoch 8, gen_loss = 1.1210448212516955, disc_loss = 0.0005959719737947802
Trained batch 313 in epoch 8, gen_loss = 1.120737729938167, disc_loss = 0.0005947126127623028
Trained batch 314 in epoch 8, gen_loss = 1.12049247461652, disc_loss = 0.000593309793602823
Trained batch 315 in epoch 8, gen_loss = 1.1210008621970309, disc_loss = 0.0005923483437487171
Trained batch 316 in epoch 8, gen_loss = 1.1206517949089267, disc_loss = 0.0005913394029003976
Trained batch 317 in epoch 8, gen_loss = 1.1208874931875266, disc_loss = 0.0005899239406989062
Trained batch 318 in epoch 8, gen_loss = 1.1208532745935327, disc_loss = 0.0005886056560342022
Trained batch 319 in epoch 8, gen_loss = 1.1210387587547301, disc_loss = 0.0005874044092252006
Trained batch 320 in epoch 8, gen_loss = 1.12091675577134, disc_loss = 0.0005863445340507052
Trained batch 321 in epoch 8, gen_loss = 1.12109881454373, disc_loss = 0.0005854946278344395
Trained batch 322 in epoch 8, gen_loss = 1.1211157059152799, disc_loss = 0.0005863008415813042
Trained batch 323 in epoch 8, gen_loss = 1.1208366733274342, disc_loss = 0.0005875075414089089
Trained batch 324 in epoch 8, gen_loss = 1.1206110781889695, disc_loss = 0.0005865138723031403
Trained batch 325 in epoch 8, gen_loss = 1.1205462842631193, disc_loss = 0.0005855607696893865
Trained batch 326 in epoch 8, gen_loss = 1.1200242425323625, disc_loss = 0.0005852488649311968
Trained batch 327 in epoch 8, gen_loss = 1.1196806332687053, disc_loss = 0.0005856094647730593
Trained batch 328 in epoch 8, gen_loss = 1.119414176259722, disc_loss = 0.0005855222624435732
Trained batch 329 in epoch 8, gen_loss = 1.1194633747592118, disc_loss = 0.0005847040667449068
Trained batch 330 in epoch 8, gen_loss = 1.1193870435668622, disc_loss = 0.0005838642727490093
Trained batch 331 in epoch 8, gen_loss = 1.1200199410857925, disc_loss = 0.0005842550891835147
Trained batch 332 in epoch 8, gen_loss = 1.1199315252962772, disc_loss = 0.0005835492368672161
Trained batch 333 in epoch 8, gen_loss = 1.1197907817577888, disc_loss = 0.0005826423084345914
Trained batch 334 in epoch 8, gen_loss = 1.120055178386062, disc_loss = 0.0005822304551534827
Trained batch 335 in epoch 8, gen_loss = 1.11982073563905, disc_loss = 0.0005814331099740922
Trained batch 336 in epoch 8, gen_loss = 1.1198378065573356, disc_loss = 0.0005808849465354132
Trained batch 337 in epoch 8, gen_loss = 1.1198649180711373, disc_loss = 0.0005804024691939404
Trained batch 338 in epoch 8, gen_loss = 1.1198941785677345, disc_loss = 0.0005793670908967582
Trained batch 339 in epoch 8, gen_loss = 1.120137696757036, disc_loss = 0.0005789918542123975
Trained batch 340 in epoch 8, gen_loss = 1.1207702505973078, disc_loss = 0.0005779478188072907
Trained batch 341 in epoch 8, gen_loss = 1.1205440777087072, disc_loss = 0.0005770092227561563
Trained batch 342 in epoch 8, gen_loss = 1.1200746016321654, disc_loss = 0.0005770642357897394
Trained batch 343 in epoch 8, gen_loss = 1.1206264741892038, disc_loss = 0.0005771093245468449
Trained batch 344 in epoch 8, gen_loss = 1.1207195382187332, disc_loss = 0.0005772099953374245
Trained batch 345 in epoch 8, gen_loss = 1.120672891594771, disc_loss = 0.0005765531198296567
Trained batch 346 in epoch 8, gen_loss = 1.1203177672641764, disc_loss = 0.0005757905308342397
Trained batch 347 in epoch 8, gen_loss = 1.1200265062266384, disc_loss = 0.0005749966241700318
Trained batch 348 in epoch 8, gen_loss = 1.1197450383003256, disc_loss = 0.0005738178374316479
Trained batch 349 in epoch 8, gen_loss = 1.1194008374214173, disc_loss = 0.0005726797363604419
Trained batch 350 in epoch 8, gen_loss = 1.119767734807441, disc_loss = 0.0005714687803760834
Trained batch 351 in epoch 8, gen_loss = 1.1196515489030967, disc_loss = 0.0005705216045829399
Trained batch 352 in epoch 8, gen_loss = 1.1194156678472633, disc_loss = 0.0005701879003872072
Trained batch 353 in epoch 8, gen_loss = 1.119294394544289, disc_loss = 0.0005704812879564298
Trained batch 354 in epoch 8, gen_loss = 1.1189333440552296, disc_loss = 0.0005717767806294125
Trained batch 355 in epoch 8, gen_loss = 1.118825784392571, disc_loss = 0.0005718146106558512
Trained batch 356 in epoch 8, gen_loss = 1.118035254024324, disc_loss = 0.0005728114298587216
Trained batch 357 in epoch 8, gen_loss = 1.1179781829178665, disc_loss = 0.0005726217136242916
Trained batch 358 in epoch 8, gen_loss = 1.118207672512299, disc_loss = 0.000571586579651232
Trained batch 359 in epoch 8, gen_loss = 1.1187394281228384, disc_loss = 0.000570458176743058
Trained batch 360 in epoch 8, gen_loss = 1.1184386005031766, disc_loss = 0.0005694065113852466
Trained batch 361 in epoch 8, gen_loss = 1.1192525997346277, disc_loss = 0.0005682826486611688
Trained batch 362 in epoch 8, gen_loss = 1.1194661727621535, disc_loss = 0.0005679114914297821
Trained batch 363 in epoch 8, gen_loss = 1.1206739597268156, disc_loss = 0.0005676568145025777
Trained batch 364 in epoch 8, gen_loss = 1.1209214497918951, disc_loss = 0.000566577957664004
Trained batch 365 in epoch 8, gen_loss = 1.1205567727323438, disc_loss = 0.0005655929151126642
Trained batch 366 in epoch 8, gen_loss = 1.120295927375149, disc_loss = 0.000565153917249188
Trained batch 367 in epoch 8, gen_loss = 1.1207448639299558, disc_loss = 0.0005654844133301674
Trained batch 368 in epoch 8, gen_loss = 1.1208371909330208, disc_loss = 0.0005655942154971903
Trained batch 369 in epoch 8, gen_loss = 1.1207322671606734, disc_loss = 0.0005651146009473155
Trained batch 370 in epoch 8, gen_loss = 1.1202341038583103, disc_loss = 0.000564434261111771
Trained batch 371 in epoch 8, gen_loss = 1.1199171905235579, disc_loss = 0.0005637851260275134
Trained batch 372 in epoch 8, gen_loss = 1.120433599316083, disc_loss = 0.0005628414719784382
Trained batch 373 in epoch 8, gen_loss = 1.1203218386134999, disc_loss = 0.000561842617839027
Trained batch 374 in epoch 8, gen_loss = 1.120379072189331, disc_loss = 0.0005607751624193043
Trained batch 375 in epoch 8, gen_loss = 1.119839777337744, disc_loss = 0.0005595930574890326
Trained batch 376 in epoch 8, gen_loss = 1.1195240090317056, disc_loss = 0.0005593145518923124
Trained batch 377 in epoch 8, gen_loss = 1.1199871749474257, disc_loss = 0.000559340954635652
Trained batch 378 in epoch 8, gen_loss = 1.1202775526172568, disc_loss = 0.0005593043073949142
Trained batch 379 in epoch 8, gen_loss = 1.1201008834336934, disc_loss = 0.0005589175004340512
Trained batch 380 in epoch 8, gen_loss = 1.1201208867425994, disc_loss = 0.0005578534430356726
Trained batch 381 in epoch 8, gen_loss = 1.119824959657579, disc_loss = 0.000557337722295215
Trained batch 382 in epoch 8, gen_loss = 1.1197316596775702, disc_loss = 0.0005565362925992005
Trained batch 383 in epoch 8, gen_loss = 1.1200106733789046, disc_loss = 0.0005563106506466889
Trained batch 384 in epoch 8, gen_loss = 1.120978799423614, disc_loss = 0.0005558500176389375
Trained batch 385 in epoch 8, gen_loss = 1.1212909162971023, disc_loss = 0.0005558879332061389
Trained batch 386 in epoch 8, gen_loss = 1.1211590030704666, disc_loss = 0.0005556737957236499
Trained batch 387 in epoch 8, gen_loss = 1.120748553693909, disc_loss = 0.0005548248201315819
Trained batch 388 in epoch 8, gen_loss = 1.1209425638144916, disc_loss = 0.0005540540236123816
Trained batch 389 in epoch 8, gen_loss = 1.1208557397891314, disc_loss = 0.0005530180465519571
Trained batch 390 in epoch 8, gen_loss = 1.1205008130549166, disc_loss = 0.0005521982036399371
Trained batch 391 in epoch 8, gen_loss = 1.1203374105448625, disc_loss = 0.0005511384252360808
Trained batch 392 in epoch 8, gen_loss = 1.1204693690511107, disc_loss = 0.0005501195170463989
Trained batch 393 in epoch 8, gen_loss = 1.1200078952736057, disc_loss = 0.0005491331152749121
Trained batch 394 in epoch 8, gen_loss = 1.1204189303555065, disc_loss = 0.0005482394502813562
Trained batch 395 in epoch 8, gen_loss = 1.1203615957438344, disc_loss = 0.0005472962043910743
Trained batch 396 in epoch 8, gen_loss = 1.1212781379445074, disc_loss = 0.000546836766602896
Trained batch 397 in epoch 8, gen_loss = 1.1210302770437308, disc_loss = 0.0005466888394208518
Trained batch 398 in epoch 8, gen_loss = 1.120447592030193, disc_loss = 0.0005466868523738807
Trained batch 399 in epoch 8, gen_loss = 1.1202400919795037, disc_loss = 0.0005459869450351106
Trained batch 400 in epoch 8, gen_loss = 1.1206070309565253, disc_loss = 0.000545076065863125
Trained batch 401 in epoch 8, gen_loss = 1.120603698403088, disc_loss = 0.0005445532968504683
Trained batch 402 in epoch 8, gen_loss = 1.1206903150004726, disc_loss = 0.0005441756976295203
Trained batch 403 in epoch 8, gen_loss = 1.121155052491934, disc_loss = 0.0005455646034065602
Trained batch 404 in epoch 8, gen_loss = 1.1209374516098587, disc_loss = 0.0005477719025091372
Trained batch 405 in epoch 8, gen_loss = 1.1210857386072282, disc_loss = 0.0005475140426246555
Trained batch 406 in epoch 8, gen_loss = 1.1208769715681708, disc_loss = 0.0005466807301482872
Trained batch 407 in epoch 8, gen_loss = 1.1204912853883762, disc_loss = 0.0005461035503400376
Trained batch 408 in epoch 8, gen_loss = 1.120111171657124, disc_loss = 0.0005454329343203541
Trained batch 409 in epoch 8, gen_loss = 1.119619009989064, disc_loss = 0.0005451337404892689
Trained batch 410 in epoch 8, gen_loss = 1.1199194997766593, disc_loss = 0.0005452548969243007
Trained batch 411 in epoch 8, gen_loss = 1.1193886823156505, disc_loss = 0.0006361579592353822
Trained batch 412 in epoch 8, gen_loss = 1.1190780763476005, disc_loss = 0.0006926952437094591
Trained batch 413 in epoch 8, gen_loss = 1.1191759539975061, disc_loss = 0.0007038485854743206
Trained batch 414 in epoch 8, gen_loss = 1.1191322330968925, disc_loss = 0.0007129322981857414
Trained batch 415 in epoch 8, gen_loss = 1.1188616435974836, disc_loss = 0.0007425267179734454
Trained batch 416 in epoch 8, gen_loss = 1.1199559529336522, disc_loss = 0.0007816385855014398
Trained batch 417 in epoch 8, gen_loss = 1.1203770493491414, disc_loss = 0.0007956485176900664
Trained batch 418 in epoch 8, gen_loss = 1.1204630257406212, disc_loss = 0.000802065927941221
Trained batch 419 in epoch 8, gen_loss = 1.1202731253135771, disc_loss = 0.0008045241777532889
Trained batch 420 in epoch 8, gen_loss = 1.1200183322763784, disc_loss = 0.0008049087427546007
Trained batch 421 in epoch 8, gen_loss = 1.1201348659269053, disc_loss = 0.0008049774284971661
Trained batch 422 in epoch 8, gen_loss = 1.1204694448915216, disc_loss = 0.000804792649596192
Trained batch 423 in epoch 8, gen_loss = 1.1205689160610146, disc_loss = 0.0008073603646307503
Trained batch 424 in epoch 8, gen_loss = 1.1205595699478599, disc_loss = 0.00081061328518177
Trained batch 425 in epoch 8, gen_loss = 1.1201941682978975, disc_loss = 0.0008103480879088947
Trained batch 426 in epoch 8, gen_loss = 1.1202280332947223, disc_loss = 0.0008111482133952011
Trained batch 427 in epoch 8, gen_loss = 1.1199766852866824, disc_loss = 0.0008113312691183016
Trained batch 428 in epoch 8, gen_loss = 1.1201095501859706, disc_loss = 0.0008109895346454499
Trained batch 429 in epoch 8, gen_loss = 1.1201783073502918, disc_loss = 0.0008109073330943343
Trained batch 430 in epoch 8, gen_loss = 1.1201906556872923, disc_loss = 0.0008099466413240599
Trained batch 431 in epoch 8, gen_loss = 1.1202704206936889, disc_loss = 0.0008109332981836849
Trained batch 432 in epoch 8, gen_loss = 1.1198271646510647, disc_loss = 0.0008117725994229837
Trained batch 433 in epoch 8, gen_loss = 1.1210499440195374, disc_loss = 0.0008110362872567719
Trained batch 434 in epoch 8, gen_loss = 1.121164784897333, disc_loss = 0.0008120420322306561
Trained batch 435 in epoch 8, gen_loss = 1.121140946078738, disc_loss = 0.0008150044075491595
Trained batch 436 in epoch 8, gen_loss = 1.1212010240391135, disc_loss = 0.0008162199653105947
Trained batch 437 in epoch 8, gen_loss = 1.1213937299708798, disc_loss = 0.0008153849450877196
Trained batch 438 in epoch 8, gen_loss = 1.1216996580973302, disc_loss = 0.0008152317115387313
Trained batch 439 in epoch 8, gen_loss = 1.1214846940203147, disc_loss = 0.0008158787589887983
Trained batch 440 in epoch 8, gen_loss = 1.1211823279084532, disc_loss = 0.000817491525863065
Trained batch 441 in epoch 8, gen_loss = 1.1215220077544856, disc_loss = 0.0008173605102328774
Trained batch 442 in epoch 8, gen_loss = 1.1212328372367617, disc_loss = 0.0008170997490252328
Trained batch 443 in epoch 8, gen_loss = 1.1219642622782304, disc_loss = 0.0008167012802496665
Trained batch 444 in epoch 8, gen_loss = 1.1219927025644967, disc_loss = 0.0008158241965993716
Trained batch 445 in epoch 8, gen_loss = 1.121730570167704, disc_loss = 0.0008149177015530918
Trained batch 446 in epoch 8, gen_loss = 1.1221169416003045, disc_loss = 0.0008145557249720694
Trained batch 447 in epoch 8, gen_loss = 1.1219266268557735, disc_loss = 0.0008142042414159992
Trained batch 448 in epoch 8, gen_loss = 1.1218162643617404, disc_loss = 0.0008132799414392531
Trained batch 449 in epoch 8, gen_loss = 1.1227373905976614, disc_loss = 0.0008128150766909432
Trained batch 450 in epoch 8, gen_loss = 1.1227490435418428, disc_loss = 0.0008132611912148106
Trained batch 451 in epoch 8, gen_loss = 1.1227186291882423, disc_loss = 0.000814014908710064
Trained batch 452 in epoch 8, gen_loss = 1.1226426195887804, disc_loss = 0.0008146206631618665
Trained batch 453 in epoch 8, gen_loss = 1.1228664613242716, disc_loss = 0.0008150859330952607
Trained batch 454 in epoch 8, gen_loss = 1.122819933131501, disc_loss = 0.0008153752372331487
Trained batch 455 in epoch 8, gen_loss = 1.1226749264618807, disc_loss = 0.0008150500466160194
Trained batch 456 in epoch 8, gen_loss = 1.1230783695986808, disc_loss = 0.0008147067437954634
Trained batch 457 in epoch 8, gen_loss = 1.1233221145436232, disc_loss = 0.0008137243196882173
Trained batch 458 in epoch 8, gen_loss = 1.1237156353485092, disc_loss = 0.0008164106388279584
Trained batch 459 in epoch 8, gen_loss = 1.1241113464469494, disc_loss = 0.0008188613081469868
Trained batch 460 in epoch 8, gen_loss = 1.1247707575624264, disc_loss = 0.0008217010124262782
Trained batch 461 in epoch 8, gen_loss = 1.125035639320101, disc_loss = 0.0008225184934275745
Trained batch 462 in epoch 8, gen_loss = 1.1249650445149217, disc_loss = 0.0008218321574539586
Trained batch 463 in epoch 8, gen_loss = 1.1247306531616326, disc_loss = 0.0008221610348833753
Trained batch 464 in epoch 8, gen_loss = 1.1246263400200875, disc_loss = 0.0008217695873588704
Trained batch 465 in epoch 8, gen_loss = 1.124558061617127, disc_loss = 0.0008209778144023813
Trained batch 466 in epoch 8, gen_loss = 1.1246346915559544, disc_loss = 0.0008230351015506113
Trained batch 467 in epoch 8, gen_loss = 1.1244857302333555, disc_loss = 0.0008251412567853207
Trained batch 468 in epoch 8, gen_loss = 1.1242078866785779, disc_loss = 0.0008278625005712685
Trained batch 469 in epoch 8, gen_loss = 1.124160504467944, disc_loss = 0.0008297061894096414
Trained batch 470 in epoch 8, gen_loss = 1.1239025938283107, disc_loss = 0.0008307052417517385
Trained batch 471 in epoch 8, gen_loss = 1.1238620673953477, disc_loss = 0.0008332647446538539
Trained batch 472 in epoch 8, gen_loss = 1.1238186317820882, disc_loss = 0.0008373104547971001
Trained batch 473 in epoch 8, gen_loss = 1.1235171364078038, disc_loss = 0.0008391185370084774
Trained batch 474 in epoch 8, gen_loss = 1.123650589616675, disc_loss = 0.0008387767118830724
Trained batch 475 in epoch 8, gen_loss = 1.1235285768238437, disc_loss = 0.0008386956512115547
Trained batch 476 in epoch 8, gen_loss = 1.123898723965171, disc_loss = 0.0008394219957434121
Trained batch 477 in epoch 8, gen_loss = 1.1241299703280796, disc_loss = 0.000839508937765059
Trained batch 478 in epoch 8, gen_loss = 1.123945667873096, disc_loss = 0.0008388533558497703
Trained batch 479 in epoch 8, gen_loss = 1.1241199685881536, disc_loss = 0.000838722732290383
Trained batch 480 in epoch 8, gen_loss = 1.1243030471018596, disc_loss = 0.0008400784573494021
Trained batch 481 in epoch 8, gen_loss = 1.1248322523728447, disc_loss = 0.0008400167998579075
Trained batch 482 in epoch 8, gen_loss = 1.1253095321033313, disc_loss = 0.0008391122733265467
Trained batch 483 in epoch 8, gen_loss = 1.1255906865862775, disc_loss = 0.0008394094735751032
Trained batch 484 in epoch 8, gen_loss = 1.1253678881015974, disc_loss = 0.0008391575804688325
Trained batch 485 in epoch 8, gen_loss = 1.1251882458174671, disc_loss = 0.0008384348387643599
Trained batch 486 in epoch 8, gen_loss = 1.1249561257186123, disc_loss = 0.0008377771697844258
Trained batch 487 in epoch 8, gen_loss = 1.1248889564246427, disc_loss = 0.0008390916454580472
Trained batch 488 in epoch 8, gen_loss = 1.1248742801523892, disc_loss = 0.0008385843988200878
Trained batch 489 in epoch 8, gen_loss = 1.1253864114381829, disc_loss = 0.0008375758727197536
Trained batch 490 in epoch 8, gen_loss = 1.124953186560551, disc_loss = 0.0008366037312908811
Trained batch 491 in epoch 8, gen_loss = 1.1253646150594805, disc_loss = 0.000836129410470868
Trained batch 492 in epoch 8, gen_loss = 1.1253958890936195, disc_loss = 0.0008357969638629406
Trained batch 493 in epoch 8, gen_loss = 1.1253867237432766, disc_loss = 0.0008354423421132001
Trained batch 494 in epoch 8, gen_loss = 1.1250006687761558, disc_loss = 0.0008349267061802117
Trained batch 495 in epoch 8, gen_loss = 1.1257299045401234, disc_loss = 0.000834389334393622
Trained batch 496 in epoch 8, gen_loss = 1.1260446940869153, disc_loss = 0.0008333930536372385
Trained batch 497 in epoch 8, gen_loss = 1.1262970162203991, disc_loss = 0.0008330641219536886
Trained batch 498 in epoch 8, gen_loss = 1.126752409046303, disc_loss = 0.0008326673873278867
Trained batch 499 in epoch 8, gen_loss = 1.1272505931854249, disc_loss = 0.0008314553951204288
Trained batch 500 in epoch 8, gen_loss = 1.1270818765053967, disc_loss = 0.0008305721341907892
Trained batch 501 in epoch 8, gen_loss = 1.1271910311216378, disc_loss = 0.0008292027357031139
Trained batch 502 in epoch 8, gen_loss = 1.1275579474318336, disc_loss = 0.0008280596661529084
Trained batch 503 in epoch 8, gen_loss = 1.1276507335049766, disc_loss = 0.0008269064001069637
Trained batch 504 in epoch 8, gen_loss = 1.127542234411334, disc_loss = 0.0008256792894790484
Trained batch 505 in epoch 8, gen_loss = 1.127393156879033, disc_loss = 0.0008243423810501569
Trained batch 506 in epoch 8, gen_loss = 1.1272191888481908, disc_loss = 0.0008232680057128157
Trained batch 507 in epoch 8, gen_loss = 1.1273405047382896, disc_loss = 0.0008229566224968504
Trained batch 508 in epoch 8, gen_loss = 1.1273775716661705, disc_loss = 0.0008226530845123774
Trained batch 509 in epoch 8, gen_loss = 1.1278601403329886, disc_loss = 0.0008225358270768387
Trained batch 510 in epoch 8, gen_loss = 1.1278934040181559, disc_loss = 0.000822580043494623
Trained batch 511 in epoch 8, gen_loss = 1.1281598745845258, disc_loss = 0.0008221372654872994
Trained batch 512 in epoch 8, gen_loss = 1.1282307332486903, disc_loss = 0.0008210667770559724
Trained batch 513 in epoch 8, gen_loss = 1.1279665690915595, disc_loss = 0.0008198933823442753
Trained batch 514 in epoch 8, gen_loss = 1.1274438929789274, disc_loss = 0.0008194193245675776
Trained batch 515 in epoch 8, gen_loss = 1.127274285915286, disc_loss = 0.0008194733643114689
Trained batch 516 in epoch 8, gen_loss = 1.1269368680348941, disc_loss = 0.0008187772781246772
Trained batch 517 in epoch 8, gen_loss = 1.126647601716767, disc_loss = 0.0008178631827108468
Trained batch 518 in epoch 8, gen_loss = 1.126510551439774, disc_loss = 0.0008176107926680913
Trained batch 519 in epoch 8, gen_loss = 1.1259331331803248, disc_loss = 0.0008195157925701307
Trained batch 520 in epoch 8, gen_loss = 1.1263011270658525, disc_loss = 0.0008197655131429927
Trained batch 521 in epoch 8, gen_loss = 1.1259106076768532, disc_loss = 0.0008188383754675538
Trained batch 522 in epoch 8, gen_loss = 1.1260591641666784, disc_loss = 0.000817965691137692
Trained batch 523 in epoch 8, gen_loss = 1.1261541530603671, disc_loss = 0.0008172278580405103
Trained batch 524 in epoch 8, gen_loss = 1.1263593295642307, disc_loss = 0.0008167593469399782
Trained batch 525 in epoch 8, gen_loss = 1.126275374748861, disc_loss = 0.000816097896800203
Trained batch 526 in epoch 8, gen_loss = 1.1259648773882829, disc_loss = 0.0008148972510666794
Trained batch 527 in epoch 8, gen_loss = 1.1259746814541745, disc_loss = 0.0008137591342650315
Trained batch 528 in epoch 8, gen_loss = 1.125656943465451, disc_loss = 0.000812761552559453
Trained batch 529 in epoch 8, gen_loss = 1.1261641473140356, disc_loss = 0.0008118539851736541
Trained batch 530 in epoch 8, gen_loss = 1.1258997793700511, disc_loss = 0.0008111321702483329
Trained batch 531 in epoch 8, gen_loss = 1.1258047565929872, disc_loss = 0.0008115114254824016
Trained batch 532 in epoch 8, gen_loss = 1.1260364612539981, disc_loss = 0.0008116989178042666
Trained batch 533 in epoch 8, gen_loss = 1.1259613997034366, disc_loss = 0.0008110607743308153
Trained batch 534 in epoch 8, gen_loss = 1.1259693809758837, disc_loss = 0.0008099296387278466
Trained batch 535 in epoch 8, gen_loss = 1.1258184453889506, disc_loss = 0.0008091786694693389
Trained batch 536 in epoch 8, gen_loss = 1.12531677315799, disc_loss = 0.0008083947970142963
Trained batch 537 in epoch 8, gen_loss = 1.1251886583393835, disc_loss = 0.0008078336884857495
Trained batch 538 in epoch 8, gen_loss = 1.1254635063969358, disc_loss = 0.0008072459530886625
Trained batch 539 in epoch 8, gen_loss = 1.125455774532424, disc_loss = 0.0008068318889181008
Trained batch 540 in epoch 8, gen_loss = 1.1256279278815122, disc_loss = 0.0008059053602656384
Trained batch 541 in epoch 8, gen_loss = 1.125321326990409, disc_loss = 0.0008051790355507549
Trained batch 542 in epoch 8, gen_loss = 1.1250738830856197, disc_loss = 0.000804535739757781
Trained batch 543 in epoch 8, gen_loss = 1.1255735087701504, disc_loss = 0.0008041797955496911
Trained batch 544 in epoch 8, gen_loss = 1.1257059509601068, disc_loss = 0.0008034315418693399
Trained batch 545 in epoch 8, gen_loss = 1.1258306801319122, disc_loss = 0.0008023070647371011
Trained batch 546 in epoch 8, gen_loss = 1.1256021083599907, disc_loss = 0.0008015516033171382
Trained batch 547 in epoch 8, gen_loss = 1.125535911778464, disc_loss = 0.0008005501826597126
Trained batch 548 in epoch 8, gen_loss = 1.125315693666809, disc_loss = 0.0007997381696303651
Trained batch 549 in epoch 8, gen_loss = 1.1254054924574766, disc_loss = 0.0007988205760590393
Trained batch 550 in epoch 8, gen_loss = 1.1255299784310717, disc_loss = 0.0007977191563323816
Trained batch 551 in epoch 8, gen_loss = 1.1256549612119577, disc_loss = 0.000797293290868739
Trained batch 552 in epoch 8, gen_loss = 1.125730640310491, disc_loss = 0.0007962408317111947
Trained batch 553 in epoch 8, gen_loss = 1.1256418532628014, disc_loss = 0.0007952328592527066
Trained batch 554 in epoch 8, gen_loss = 1.1255403564856934, disc_loss = 0.0007940445018739246
Trained batch 555 in epoch 8, gen_loss = 1.126060127675962, disc_loss = 0.0007929059654527023
Trained batch 556 in epoch 8, gen_loss = 1.1258279169697307, disc_loss = 0.0007919083750746973
Trained batch 557 in epoch 8, gen_loss = 1.1258209199247395, disc_loss = 0.0007916503488288535
Trained batch 558 in epoch 8, gen_loss = 1.1257636394611625, disc_loss = 0.000791088803651516
Trained batch 559 in epoch 8, gen_loss = 1.1254565657249518, disc_loss = 0.0007903394673121511
Trained batch 560 in epoch 8, gen_loss = 1.1251717420185314, disc_loss = 0.0007894814950374574
Trained batch 561 in epoch 8, gen_loss = 1.1253257307929925, disc_loss = 0.00078864401524652
Trained batch 562 in epoch 8, gen_loss = 1.125876346765149, disc_loss = 0.0007878228494796991
Trained batch 563 in epoch 8, gen_loss = 1.125426415433275, disc_loss = 0.0007869757151535418
Trained batch 564 in epoch 8, gen_loss = 1.12557219235243, disc_loss = 0.0007860860750501546
Trained batch 565 in epoch 8, gen_loss = 1.1253195028001766, disc_loss = 0.0007853989268321126
Trained batch 566 in epoch 8, gen_loss = 1.1253941683542161, disc_loss = 0.0007845853479027607
Trained batch 567 in epoch 8, gen_loss = 1.1252533405179708, disc_loss = 0.0007836839352383092
Trained batch 568 in epoch 8, gen_loss = 1.1253840812270797, disc_loss = 0.0007832108362099509
Trained batch 569 in epoch 8, gen_loss = 1.1256878905129015, disc_loss = 0.0007822239114096176
Trained batch 570 in epoch 8, gen_loss = 1.1253710630269893, disc_loss = 0.0007816011719611569
Trained batch 571 in epoch 8, gen_loss = 1.1255761320357556, disc_loss = 0.0007807214077494117
Trained batch 572 in epoch 8, gen_loss = 1.12558661435079, disc_loss = 0.0007798423807806763
Trained batch 573 in epoch 8, gen_loss = 1.1256363690937854, disc_loss = 0.0007789725458700914
Trained batch 574 in epoch 8, gen_loss = 1.1257681091972018, disc_loss = 0.0007781656448091583
Trained batch 575 in epoch 8, gen_loss = 1.1263098836772971, disc_loss = 0.0007773571410578168
Trained batch 576 in epoch 8, gen_loss = 1.1265574047015898, disc_loss = 0.0007764815646770492
Trained batch 577 in epoch 8, gen_loss = 1.1264323060075305, disc_loss = 0.0007755055854765289
Trained batch 578 in epoch 8, gen_loss = 1.1263810239719398, disc_loss = 0.0007744909167184779
Trained batch 579 in epoch 8, gen_loss = 1.1260945864792529, disc_loss = 0.0007734491669468518
Trained batch 580 in epoch 8, gen_loss = 1.1262453492865505, disc_loss = 0.0007724602170588718
Trained batch 581 in epoch 8, gen_loss = 1.1258940188745452, disc_loss = 0.0007716536710586454
Trained batch 582 in epoch 8, gen_loss = 1.1258688032320392, disc_loss = 0.0007706704340772511
Trained batch 583 in epoch 8, gen_loss = 1.1258265535308891, disc_loss = 0.0007696721589638076
Trained batch 584 in epoch 8, gen_loss = 1.1259228671717847, disc_loss = 0.0007688108190613537
Trained batch 585 in epoch 8, gen_loss = 1.1261581595440366, disc_loss = 0.0007681009532641795
Trained batch 586 in epoch 8, gen_loss = 1.126168232150947, disc_loss = 0.0007670755675411585
Trained batch 587 in epoch 8, gen_loss = 1.1261363323448466, disc_loss = 0.0007660591458459464
Trained batch 588 in epoch 8, gen_loss = 1.1261290491942841, disc_loss = 0.0007654741581706077
Trained batch 589 in epoch 8, gen_loss = 1.1259967127088772, disc_loss = 0.0007648767665930298
Trained batch 590 in epoch 8, gen_loss = 1.126210734928925, disc_loss = 0.0007641333569337215
Trained batch 591 in epoch 8, gen_loss = 1.1261231895234134, disc_loss = 0.0007632597078161387
Trained batch 592 in epoch 8, gen_loss = 1.1260686270503129, disc_loss = 0.000762229658699395
Trained batch 593 in epoch 8, gen_loss = 1.1260540716174476, disc_loss = 0.0007613413595407888
Trained batch 594 in epoch 8, gen_loss = 1.1256966989581325, disc_loss = 0.000760665349955788
Trained batch 595 in epoch 8, gen_loss = 1.1256018234979386, disc_loss = 0.000760035889116569
Trained batch 596 in epoch 8, gen_loss = 1.1256770965841347, disc_loss = 0.000759599061179329
Trained batch 597 in epoch 8, gen_loss = 1.1261210447569754, disc_loss = 0.0007596023645610969
Trained batch 598 in epoch 8, gen_loss = 1.1258906852422852, disc_loss = 0.0007594431638628251
Trained batch 599 in epoch 8, gen_loss = 1.125869593222936, disc_loss = 0.000758914557954995
Trained batch 600 in epoch 8, gen_loss = 1.1257346299246027, disc_loss = 0.0007583534881296706
Trained batch 601 in epoch 8, gen_loss = 1.1256420291539442, disc_loss = 0.0007576137043684999
Trained batch 602 in epoch 8, gen_loss = 1.125688761225585, disc_loss = 0.000756808027679527
Trained batch 603 in epoch 8, gen_loss = 1.1254999258660323, disc_loss = 0.0007561074456297144
Trained batch 604 in epoch 8, gen_loss = 1.1252890973051717, disc_loss = 0.0007558915030003395
Trained batch 605 in epoch 8, gen_loss = 1.1249218764084794, disc_loss = 0.0007555167246056665
Trained batch 606 in epoch 8, gen_loss = 1.1247991865510014, disc_loss = 0.000754694012492355
Trained batch 607 in epoch 8, gen_loss = 1.124388078423707, disc_loss = 0.0007537997201468802
Trained batch 608 in epoch 8, gen_loss = 1.1244059651356024, disc_loss = 0.0007533989876813801
Trained batch 609 in epoch 8, gen_loss = 1.1241670021268189, disc_loss = 0.0007525873971629705
Trained batch 610 in epoch 8, gen_loss = 1.1243628362001648, disc_loss = 0.0007516319843539937
Trained batch 611 in epoch 8, gen_loss = 1.12427231640208, disc_loss = 0.0007510245251467412
Trained batch 612 in epoch 8, gen_loss = 1.124257758916105, disc_loss = 0.0007504377492806429
Trained batch 613 in epoch 8, gen_loss = 1.1240786769296913, disc_loss = 0.0007500813881999735
Trained batch 614 in epoch 8, gen_loss = 1.1237756240658643, disc_loss = 0.0007498782358796722
Trained batch 615 in epoch 8, gen_loss = 1.1235900993471022, disc_loss = 0.0007491087878182267
Trained batch 616 in epoch 8, gen_loss = 1.1232193473672172, disc_loss = 0.0007485440088391856
Trained batch 617 in epoch 8, gen_loss = 1.1230704571244015, disc_loss = 0.0007480210952641982
Trained batch 618 in epoch 8, gen_loss = 1.1228267556245954, disc_loss = 0.0007472005606693274
Trained batch 619 in epoch 8, gen_loss = 1.1228972203308536, disc_loss = 0.0007462870513864477
Trained batch 620 in epoch 8, gen_loss = 1.1228115025925751, disc_loss = 0.0007452549153185096
Trained batch 621 in epoch 8, gen_loss = 1.123130149300842, disc_loss = 0.0007445197062426692
Trained batch 622 in epoch 8, gen_loss = 1.123108085143241, disc_loss = 0.000743979677225984
Trained batch 623 in epoch 8, gen_loss = 1.123010134181151, disc_loss = 0.0007430498006285164
Trained batch 624 in epoch 8, gen_loss = 1.1230112858772279, disc_loss = 0.0007424192609381862
Trained batch 625 in epoch 8, gen_loss = 1.1230210154391707, disc_loss = 0.0007415878433722462
Trained batch 626 in epoch 8, gen_loss = 1.1231001873145643, disc_loss = 0.0007410093342208235
Trained batch 627 in epoch 8, gen_loss = 1.123474879724205, disc_loss = 0.0007410714570489441
Trained batch 628 in epoch 8, gen_loss = 1.1237601160245025, disc_loss = 0.0007414266343021414
Trained batch 629 in epoch 8, gen_loss = 1.1236531767580245, disc_loss = 0.00074195816129167
Trained batch 630 in epoch 8, gen_loss = 1.1236250664088314, disc_loss = 0.0007415975304103675
Trained batch 631 in epoch 8, gen_loss = 1.1235659974096697, disc_loss = 0.0007406142665993546
Trained batch 632 in epoch 8, gen_loss = 1.1236256925039005, disc_loss = 0.0007397595722295232
Trained batch 633 in epoch 8, gen_loss = 1.1234642245604036, disc_loss = 0.0007391186762576899
Trained batch 634 in epoch 8, gen_loss = 1.1231089178032763, disc_loss = 0.000738552680530578
Trained batch 635 in epoch 8, gen_loss = 1.1228669340130668, disc_loss = 0.000737844086601765
Trained batch 636 in epoch 8, gen_loss = 1.1229246875367696, disc_loss = 0.0007373351244448891
Trained batch 637 in epoch 8, gen_loss = 1.1232150408167825, disc_loss = 0.0007368826623392937
Trained batch 638 in epoch 8, gen_loss = 1.1235286969347553, disc_loss = 0.0007359655839952178
Trained batch 639 in epoch 8, gen_loss = 1.1231605777516962, disc_loss = 0.0007357455432611459
Trained batch 640 in epoch 8, gen_loss = 1.1230711957407815, disc_loss = 0.0007352751113351597
Trained batch 641 in epoch 8, gen_loss = 1.123080030594288, disc_loss = 0.0007345572052247143
Trained batch 642 in epoch 8, gen_loss = 1.1232726611023187, disc_loss = 0.000733736420542177
Trained batch 643 in epoch 8, gen_loss = 1.1236681338422787, disc_loss = 0.0007328624831541855
Trained batch 644 in epoch 8, gen_loss = 1.123331402253735, disc_loss = 0.0007320014427798663
Trained batch 645 in epoch 8, gen_loss = 1.1236270913398672, disc_loss = 0.0007312453275145646
Trained batch 646 in epoch 8, gen_loss = 1.1234603379572377, disc_loss = 0.0007303926139975318
Trained batch 647 in epoch 8, gen_loss = 1.1237176551863, disc_loss = 0.0007296468589674426
Trained batch 648 in epoch 8, gen_loss = 1.12360471698279, disc_loss = 0.0007298032634377476
Trained batch 649 in epoch 8, gen_loss = 1.1234509521264295, disc_loss = 0.0007291756477430821
Trained batch 650 in epoch 8, gen_loss = 1.123442827281864, disc_loss = 0.000728436083848139
Trained batch 651 in epoch 8, gen_loss = 1.1231384238948119, disc_loss = 0.0007278271677374962
Trained batch 652 in epoch 8, gen_loss = 1.1232434589683917, disc_loss = 0.0007272072655502151
Trained batch 653 in epoch 8, gen_loss = 1.1229475119609715, disc_loss = 0.0007264659715243558
Trained batch 654 in epoch 8, gen_loss = 1.1230847408753315, disc_loss = 0.00072571100911058
Trained batch 655 in epoch 8, gen_loss = 1.1230202145511057, disc_loss = 0.0007251653621385297
Trained batch 656 in epoch 8, gen_loss = 1.1231596868150673, disc_loss = 0.0007244200946767056
Trained batch 657 in epoch 8, gen_loss = 1.123024670820468, disc_loss = 0.0007237176834628634
Trained batch 658 in epoch 8, gen_loss = 1.1228437238289481, disc_loss = 0.0007228498625643594
Trained batch 659 in epoch 8, gen_loss = 1.1225554324460751, disc_loss = 0.0007220008311516281
Trained batch 660 in epoch 8, gen_loss = 1.122404073532699, disc_loss = 0.0007212586299274624
Trained batch 661 in epoch 8, gen_loss = 1.1226190941751544, disc_loss = 0.0007206138417816206
Trained batch 662 in epoch 8, gen_loss = 1.1227419384464419, disc_loss = 0.0007199223706309809
Trained batch 663 in epoch 8, gen_loss = 1.1230101988437664, disc_loss = 0.0007190552887440861
Trained batch 664 in epoch 8, gen_loss = 1.1228970148509607, disc_loss = 0.000718465826826002
Trained batch 665 in epoch 8, gen_loss = 1.1226775097596395, disc_loss = 0.0007176818693627942
Trained batch 666 in epoch 8, gen_loss = 1.1228054444650482, disc_loss = 0.0007169798308546408
Trained batch 667 in epoch 8, gen_loss = 1.122552117544734, disc_loss = 0.0007165056096688247
Trained batch 668 in epoch 8, gen_loss = 1.1225951908237017, disc_loss = 0.0007158384002972762
Trained batch 669 in epoch 8, gen_loss = 1.122340500977502, disc_loss = 0.0007155392073536181
Trained batch 670 in epoch 8, gen_loss = 1.1222630329707697, disc_loss = 0.0007160348191301459
Trained batch 671 in epoch 8, gen_loss = 1.1219733931301605, disc_loss = 0.000715710238702221
Trained batch 672 in epoch 8, gen_loss = 1.121988806558045, disc_loss = 0.0007153266577176711
Trained batch 673 in epoch 8, gen_loss = 1.1216820428031842, disc_loss = 0.0007159465069185462
Trained batch 674 in epoch 8, gen_loss = 1.1221017667099282, disc_loss = 0.0007174410620549073
Trained batch 675 in epoch 8, gen_loss = 1.1219257635654076, disc_loss = 0.0007175232263363914
Trained batch 676 in epoch 8, gen_loss = 1.1220147920500052, disc_loss = 0.0007173992459819772
Trained batch 677 in epoch 8, gen_loss = 1.1221556117576836, disc_loss = 0.0007175293885934467
Trained batch 678 in epoch 8, gen_loss = 1.1225251091948665, disc_loss = 0.0007171335415204847
Trained batch 679 in epoch 8, gen_loss = 1.122554151889156, disc_loss = 0.0007163532950097065
Trained batch 680 in epoch 8, gen_loss = 1.1222093965688642, disc_loss = 0.0007159506683542137
Trained batch 681 in epoch 8, gen_loss = 1.1219412409140568, disc_loss = 0.0007153721671784297
Trained batch 682 in epoch 8, gen_loss = 1.1220240213336916, disc_loss = 0.0007150157740919838
Trained batch 683 in epoch 8, gen_loss = 1.1222057005292492, disc_loss = 0.000714721688270577
Trained batch 684 in epoch 8, gen_loss = 1.1222413345845077, disc_loss = 0.0007142481189747987
Trained batch 685 in epoch 8, gen_loss = 1.1225805658814512, disc_loss = 0.0007135619146090256
Trained batch 686 in epoch 8, gen_loss = 1.1226157212882062, disc_loss = 0.0007133825710995646
Trained batch 687 in epoch 8, gen_loss = 1.1225275171184264, disc_loss = 0.0007131070570446968
Trained batch 688 in epoch 8, gen_loss = 1.1229392740826822, disc_loss = 0.0007123856017307253
Trained batch 689 in epoch 8, gen_loss = 1.123143471064775, disc_loss = 0.0007116216878310535
Trained batch 690 in epoch 8, gen_loss = 1.123296325958931, disc_loss = 0.0007108861092801844
Trained batch 691 in epoch 8, gen_loss = 1.123381816324471, disc_loss = 0.0007102578004068127
Trained batch 692 in epoch 8, gen_loss = 1.1231794045945094, disc_loss = 0.0007096814433010941
Trained batch 693 in epoch 8, gen_loss = 1.1234829977197676, disc_loss = 0.0007095372414235523
Trained batch 694 in epoch 8, gen_loss = 1.123603933835201, disc_loss = 0.0007095394869839183
Trained batch 695 in epoch 8, gen_loss = 1.1238664094058948, disc_loss = 0.0007089257441471457
Trained batch 696 in epoch 8, gen_loss = 1.1241617012913292, disc_loss = 0.0007083151599355884
Trained batch 697 in epoch 8, gen_loss = 1.1241137258986005, disc_loss = 0.0007075804984238717
Trained batch 698 in epoch 8, gen_loss = 1.1238654370983272, disc_loss = 0.0007072119696176702
Trained batch 699 in epoch 8, gen_loss = 1.1239218607970647, disc_loss = 0.0007070261437287887
Trained batch 700 in epoch 8, gen_loss = 1.1237261893915893, disc_loss = 0.0007063341992746138
Trained batch 701 in epoch 8, gen_loss = 1.123800422391321, disc_loss = 0.0007057163341873342
Trained batch 702 in epoch 8, gen_loss = 1.1237802864986328, disc_loss = 0.0007051114372521239
Trained batch 703 in epoch 8, gen_loss = 1.1242397295480424, disc_loss = 0.0007044865521534534
Trained batch 704 in epoch 8, gen_loss = 1.124011697921347, disc_loss = 0.0007038400085116175
Trained batch 705 in epoch 8, gen_loss = 1.1239271461963654, disc_loss = 0.0007035463655978592
Trained batch 706 in epoch 8, gen_loss = 1.1237900193880774, disc_loss = 0.0007028334295613259
Trained batch 707 in epoch 8, gen_loss = 1.1235160621377709, disc_loss = 0.000702860220017255
Trained batch 708 in epoch 8, gen_loss = 1.1237721921526662, disc_loss = 0.0007023658203488158
Trained batch 709 in epoch 8, gen_loss = 1.1239929352847624, disc_loss = 0.0007022070246920789
Trained batch 710 in epoch 8, gen_loss = 1.124047659536622, disc_loss = 0.00070175928122717
Trained batch 711 in epoch 8, gen_loss = 1.123892443149947, disc_loss = 0.0007009713929445742
Trained batch 712 in epoch 8, gen_loss = 1.1241192933887787, disc_loss = 0.0007001611178678488
Trained batch 713 in epoch 8, gen_loss = 1.1240139320617963, disc_loss = 0.000699360159142445
Trained batch 714 in epoch 8, gen_loss = 1.1242055045141206, disc_loss = 0.000698554212955263
Trained batch 715 in epoch 8, gen_loss = 1.1242333361722903, disc_loss = 0.000697876221787148
Trained batch 716 in epoch 8, gen_loss = 1.1243807891256474, disc_loss = 0.000697107510029915
Trained batch 717 in epoch 8, gen_loss = 1.1244548317615701, disc_loss = 0.0006963314801578742
Trained batch 718 in epoch 8, gen_loss = 1.1244352010592964, disc_loss = 0.0006957557471930497
Trained batch 719 in epoch 8, gen_loss = 1.1243846962021458, disc_loss = 0.0006953533785134722
Trained batch 720 in epoch 8, gen_loss = 1.1243852579477922, disc_loss = 0.0006946828831692812
Trained batch 721 in epoch 8, gen_loss = 1.1244188211135917, disc_loss = 0.0006939205121149959
Trained batch 722 in epoch 8, gen_loss = 1.1243270001635677, disc_loss = 0.0006931644412647047
Trained batch 723 in epoch 8, gen_loss = 1.124061876321366, disc_loss = 0.000692480990593386
Trained batch 724 in epoch 8, gen_loss = 1.1238305834244038, disc_loss = 0.0006917356263950531
Trained batch 725 in epoch 8, gen_loss = 1.1234317844728465, disc_loss = 0.0006911880416276393
Trained batch 726 in epoch 8, gen_loss = 1.1235529478675235, disc_loss = 0.0006907099517927975
Trained batch 727 in epoch 8, gen_loss = 1.1237062673483575, disc_loss = 0.0006900455051776249
Trained batch 728 in epoch 8, gen_loss = 1.1237489214813432, disc_loss = 0.0006894694085065876
Trained batch 729 in epoch 8, gen_loss = 1.1234857880089382, disc_loss = 0.0006907352983308892
Trained batch 730 in epoch 8, gen_loss = 1.123947701359578, disc_loss = 0.0006925279702222046
Trained batch 731 in epoch 8, gen_loss = 1.1240816319086513, disc_loss = 0.0006925961363284856
Trained batch 732 in epoch 8, gen_loss = 1.1241142456235533, disc_loss = 0.0006924356173066103
Trained batch 733 in epoch 8, gen_loss = 1.124377731974833, disc_loss = 0.0006918882795827456
Trained batch 734 in epoch 8, gen_loss = 1.1244681036391226, disc_loss = 0.0006916379354708847
Trained batch 735 in epoch 8, gen_loss = 1.1245425274676604, disc_loss = 0.0006912259489818889
Trained batch 736 in epoch 8, gen_loss = 1.1248051119788853, disc_loss = 0.0006908595734274298
Trained batch 737 in epoch 8, gen_loss = 1.1246861486738613, disc_loss = 0.000690135347669052
Trained batch 738 in epoch 8, gen_loss = 1.1248174835606422, disc_loss = 0.0006894280001204789
Trained batch 739 in epoch 8, gen_loss = 1.1248941623681301, disc_loss = 0.0006887540417271855
Trained batch 740 in epoch 8, gen_loss = 1.1249696346912308, disc_loss = 0.0006880151617440349
Trained batch 741 in epoch 8, gen_loss = 1.1248607761615692, disc_loss = 0.0006873783437146698
Trained batch 742 in epoch 8, gen_loss = 1.1249266846022727, disc_loss = 0.0006866948693778559
Trained batch 743 in epoch 8, gen_loss = 1.1250022471111307, disc_loss = 0.0006860479748592229
Trained batch 744 in epoch 8, gen_loss = 1.1250849055763859, disc_loss = 0.0006854438477456757
Trained batch 745 in epoch 8, gen_loss = 1.1248660956886434, disc_loss = 0.0006847390978562461
Trained batch 746 in epoch 8, gen_loss = 1.1248092212511034, disc_loss = 0.0006843413443279975
Trained batch 747 in epoch 8, gen_loss = 1.1245725578802792, disc_loss = 0.0006840312861042772
Trained batch 748 in epoch 8, gen_loss = 1.1245058814737603, disc_loss = 0.0006844332102350132
Trained batch 749 in epoch 8, gen_loss = 1.124582913716634, disc_loss = 0.0006844258894949841
Trained batch 750 in epoch 8, gen_loss = 1.1248111528023264, disc_loss = 0.0006837593887775414
Trained batch 751 in epoch 8, gen_loss = 1.1250727133865053, disc_loss = 0.0006835011822368734
Trained batch 752 in epoch 8, gen_loss = 1.1251144792295864, disc_loss = 0.0006839756135636159
Trained batch 753 in epoch 8, gen_loss = 1.1251272143356363, disc_loss = 0.0006840175502868406
Trained batch 754 in epoch 8, gen_loss = 1.1248497910846937, disc_loss = 0.0006834370171418414
Trained batch 755 in epoch 8, gen_loss = 1.1246266626807118, disc_loss = 0.000682776242308411
Trained batch 756 in epoch 8, gen_loss = 1.1246083215804208, disc_loss = 0.0006821315557649175
Trained batch 757 in epoch 8, gen_loss = 1.1245141820416915, disc_loss = 0.0006815231195597241
Trained batch 758 in epoch 8, gen_loss = 1.124208976000508, disc_loss = 0.0006809240123369008
Trained batch 759 in epoch 8, gen_loss = 1.1242201130641134, disc_loss = 0.0006804986053267432
Trained batch 760 in epoch 8, gen_loss = 1.1243519953766572, disc_loss = 0.0006798543495679232
Trained batch 761 in epoch 8, gen_loss = 1.1241882930746854, disc_loss = 0.0006792458973038487
Trained batch 762 in epoch 8, gen_loss = 1.1243864315834144, disc_loss = 0.0006789366740517948
Trained batch 763 in epoch 8, gen_loss = 1.1245440474823507, disc_loss = 0.000678431720974799
Trained batch 764 in epoch 8, gen_loss = 1.1243860028927621, disc_loss = 0.0006778976986537767
Trained batch 765 in epoch 8, gen_loss = 1.1244465981855716, disc_loss = 0.0006772960504760428
Trained batch 766 in epoch 8, gen_loss = 1.124284662898858, disc_loss = 0.0006766315434297129
Trained batch 767 in epoch 8, gen_loss = 1.1242668365594, disc_loss = 0.0006763118833722123
Trained batch 768 in epoch 8, gen_loss = 1.1240449726039008, disc_loss = 0.0006757208753172223
Trained batch 769 in epoch 8, gen_loss = 1.1243411088144624, disc_loss = 0.0006752083040418575
Trained batch 770 in epoch 8, gen_loss = 1.124601480020778, disc_loss = 0.0006746809774502114
Trained batch 771 in epoch 8, gen_loss = 1.1246222049924377, disc_loss = 0.0006742923436775367
Trained batch 772 in epoch 8, gen_loss = 1.124878604769861, disc_loss = 0.0006739917612551165
Trained batch 773 in epoch 8, gen_loss = 1.124789549013749, disc_loss = 0.0006737320120658458
Trained batch 774 in epoch 8, gen_loss = 1.1247792190890158, disc_loss = 0.0006733602746727786
Trained batch 775 in epoch 8, gen_loss = 1.1246970301282775, disc_loss = 0.0006726858314370062
Trained batch 776 in epoch 8, gen_loss = 1.124475219765225, disc_loss = 0.0006720732182359917
Trained batch 777 in epoch 8, gen_loss = 1.1242223930542756, disc_loss = 0.0006715069727847654
Trained batch 778 in epoch 8, gen_loss = 1.1245269048504714, disc_loss = 0.0006712114287702311
Trained batch 779 in epoch 8, gen_loss = 1.1244615531884707, disc_loss = 0.000671370690561628
Trained batch 780 in epoch 8, gen_loss = 1.1241139846635688, disc_loss = 0.0006714658522140711
Trained batch 781 in epoch 8, gen_loss = 1.1239470442390198, disc_loss = 0.000671217990148922
Trained batch 782 in epoch 8, gen_loss = 1.1239538386863768, disc_loss = 0.0006707631088933036
Trained batch 783 in epoch 8, gen_loss = 1.1237931385332225, disc_loss = 0.0006703426369108921
Trained batch 784 in epoch 8, gen_loss = 1.123812901594077, disc_loss = 0.000669817015444148
Trained batch 785 in epoch 8, gen_loss = 1.123516345600439, disc_loss = 0.0006691679179934434
Trained batch 786 in epoch 8, gen_loss = 1.123226167286215, disc_loss = 0.0006685893274615891
Trained batch 787 in epoch 8, gen_loss = 1.1232141032436778, disc_loss = 0.0006681216746904925
Trained batch 788 in epoch 8, gen_loss = 1.1231798491097222, disc_loss = 0.000667601741843884
Trained batch 789 in epoch 8, gen_loss = 1.1233510322208646, disc_loss = 0.0006669989094076254
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 1.4187092781066895, disc_loss = 0.00014866760466247797
Trained batch 1 in epoch 9, gen_loss = 1.2412899136543274, disc_loss = 0.00018911657389253378
Trained batch 2 in epoch 9, gen_loss = 1.144670307636261, disc_loss = 0.000201944310295706
Trained batch 3 in epoch 9, gen_loss = 1.127836748957634, disc_loss = 0.00019383877952350304
Trained batch 4 in epoch 9, gen_loss = 1.1329003930091859, disc_loss = 0.00017629758222028613
Trained batch 5 in epoch 9, gen_loss = 1.1129401624202728, disc_loss = 0.00019039636633048454
Trained batch 6 in epoch 9, gen_loss = 1.108343848160335, disc_loss = 0.00021519669930317571
Trained batch 7 in epoch 9, gen_loss = 1.1133537665009499, disc_loss = 0.00023110438633011654
Trained batch 8 in epoch 9, gen_loss = 1.1197577913602192, disc_loss = 0.00024180334164864488
Trained batch 9 in epoch 9, gen_loss = 1.1181081593036652, disc_loss = 0.00025421965110581366
Trained batch 10 in epoch 9, gen_loss = 1.122263567014174, disc_loss = 0.00023991292718247595
Trained batch 11 in epoch 9, gen_loss = 1.113399272163709, disc_loss = 0.0002398852629994508
Trained batch 12 in epoch 9, gen_loss = 1.1072929868331323, disc_loss = 0.0002353091616756641
Trained batch 13 in epoch 9, gen_loss = 1.1115070368562425, disc_loss = 0.00022637791386971782
Trained batch 14 in epoch 9, gen_loss = 1.1148775378863016, disc_loss = 0.0002273741129708166
Trained batch 15 in epoch 9, gen_loss = 1.1026471368968487, disc_loss = 0.00023362654155789642
Trained batch 16 in epoch 9, gen_loss = 1.0967897632542778, disc_loss = 0.0002319547561723191
Trained batch 17 in epoch 9, gen_loss = 1.098939256535636, disc_loss = 0.00023497965351756042
Trained batch 18 in epoch 9, gen_loss = 1.101839890605525, disc_loss = 0.00023646244555589204
Trained batch 19 in epoch 9, gen_loss = 1.102985754609108, disc_loss = 0.00023658272402826697
Trained batch 20 in epoch 9, gen_loss = 1.0990409822691054, disc_loss = 0.00023321715915309533
Trained batch 21 in epoch 9, gen_loss = 1.096413105726242, disc_loss = 0.00023296370372091505
Trained batch 22 in epoch 9, gen_loss = 1.1153830678566643, disc_loss = 0.00023624057243780598
Trained batch 23 in epoch 9, gen_loss = 1.1267123743891716, disc_loss = 0.00023626542982431906
Trained batch 24 in epoch 9, gen_loss = 1.1352883982658386, disc_loss = 0.0002326905948575586
Trained batch 25 in epoch 9, gen_loss = 1.1273471483817468, disc_loss = 0.00023252641851566016
Trained batch 26 in epoch 9, gen_loss = 1.1328505233482078, disc_loss = 0.0002348837200164174
Trained batch 27 in epoch 9, gen_loss = 1.1339734920433588, disc_loss = 0.00024341035116646838
Trained batch 28 in epoch 9, gen_loss = 1.1358112343426408, disc_loss = 0.0002615881320048959
Trained batch 29 in epoch 9, gen_loss = 1.13171439965566, disc_loss = 0.0002739649804425426
Trained batch 30 in epoch 9, gen_loss = 1.135779861480959, disc_loss = 0.0002755624502183749
Trained batch 31 in epoch 9, gen_loss = 1.1317041851580143, disc_loss = 0.00027423939673099085
Trained batch 32 in epoch 9, gen_loss = 1.1255354592294404, disc_loss = 0.0002822869251813796
Trained batch 33 in epoch 9, gen_loss = 1.1221623876515556, disc_loss = 0.00028543885384672596
Trained batch 34 in epoch 9, gen_loss = 1.1190508535930088, disc_loss = 0.00029177123173472605
Trained batch 35 in epoch 9, gen_loss = 1.1213396423392825, disc_loss = 0.00029491275806018774
Trained batch 36 in epoch 9, gen_loss = 1.1238845457901825, disc_loss = 0.0002912324054852581
Trained batch 37 in epoch 9, gen_loss = 1.1213253140449524, disc_loss = 0.0002910471816185715
Trained batch 38 in epoch 9, gen_loss = 1.1157223735100184, disc_loss = 0.0002908922828142889
Trained batch 39 in epoch 9, gen_loss = 1.1145969852805138, disc_loss = 0.00030755222724110354
Trained batch 40 in epoch 9, gen_loss = 1.1136065096389958, disc_loss = 0.0003170734487911232
Trained batch 41 in epoch 9, gen_loss = 1.111477180605843, disc_loss = 0.00031969679271458604
Trained batch 42 in epoch 9, gen_loss = 1.1088443550952645, disc_loss = 0.0003221951574655683
Trained batch 43 in epoch 9, gen_loss = 1.102312522855672, disc_loss = 0.0003293446316092741
Trained batch 44 in epoch 9, gen_loss = 1.1086724559466044, disc_loss = 0.0003291508102039289
Trained batch 45 in epoch 9, gen_loss = 1.1079673365406368, disc_loss = 0.0003346978448225064
Trained batch 46 in epoch 9, gen_loss = 1.108517125565955, disc_loss = 0.000338012230907012
Trained batch 47 in epoch 9, gen_loss = 1.1090580237408478, disc_loss = 0.0003361627553507181
Trained batch 48 in epoch 9, gen_loss = 1.1067428503717696, disc_loss = 0.000337949097192162
Trained batch 49 in epoch 9, gen_loss = 1.1112265837192536, disc_loss = 0.00033695559221087024
Trained batch 50 in epoch 9, gen_loss = 1.1105409825549406, disc_loss = 0.0003345353927180244
Trained batch 51 in epoch 9, gen_loss = 1.1165923785704832, disc_loss = 0.0003472407613746607
Trained batch 52 in epoch 9, gen_loss = 1.1128475924707808, disc_loss = 0.00036316714743767287
Trained batch 53 in epoch 9, gen_loss = 1.1134744452105627, disc_loss = 0.0003645992325834447
Trained batch 54 in epoch 9, gen_loss = 1.1109867334365844, disc_loss = 0.0003688688077752224
Trained batch 55 in epoch 9, gen_loss = 1.1106184529406684, disc_loss = 0.0003816262849016182
Trained batch 56 in epoch 9, gen_loss = 1.1099285263764231, disc_loss = 0.0003982476584752205
Trained batch 57 in epoch 9, gen_loss = 1.1053369333004128, disc_loss = 0.00039654920441660517
Trained batch 58 in epoch 9, gen_loss = 1.1067107309729367, disc_loss = 0.0003983689066598792
Trained batch 59 in epoch 9, gen_loss = 1.1066716730594635, disc_loss = 0.0003986255270622981
Trained batch 60 in epoch 9, gen_loss = 1.1053452022740098, disc_loss = 0.00039605693758053127
Trained batch 61 in epoch 9, gen_loss = 1.1058973285459703, disc_loss = 0.00039181259372496915
Trained batch 62 in epoch 9, gen_loss = 1.1039118965466816, disc_loss = 0.0003884012971649922
Trained batch 63 in epoch 9, gen_loss = 1.1018577544018626, disc_loss = 0.00038738835382901016
Trained batch 64 in epoch 9, gen_loss = 1.1039855195925785, disc_loss = 0.0003909239030550592
Trained batch 65 in epoch 9, gen_loss = 1.1039503821820924, disc_loss = 0.0003907696858126049
Trained batch 66 in epoch 9, gen_loss = 1.1044541979903606, disc_loss = 0.0003914946169807895
Trained batch 67 in epoch 9, gen_loss = 1.1080652045852997, disc_loss = 0.00038975870676735854
Trained batch 68 in epoch 9, gen_loss = 1.1089302240938381, disc_loss = 0.00038829269149151725
Trained batch 69 in epoch 9, gen_loss = 1.1123264627797262, disc_loss = 0.0003888886251453576
Trained batch 70 in epoch 9, gen_loss = 1.1133208854097716, disc_loss = 0.00040383053194193667
Trained batch 71 in epoch 9, gen_loss = 1.1144973047905498, disc_loss = 0.0004257577428587764
Trained batch 72 in epoch 9, gen_loss = 1.1153879075834197, disc_loss = 0.00045189854636316326
Trained batch 73 in epoch 9, gen_loss = 1.1148818674925212, disc_loss = 0.0004664982737488793
Trained batch 74 in epoch 9, gen_loss = 1.1141496284802754, disc_loss = 0.00046998516151991986
Trained batch 75 in epoch 9, gen_loss = 1.1122335062215203, disc_loss = 0.00046849144679359406
Trained batch 76 in epoch 9, gen_loss = 1.1130505281609375, disc_loss = 0.00046927675373501497
Trained batch 77 in epoch 9, gen_loss = 1.115477585639709, disc_loss = 0.000466377123815712
Trained batch 78 in epoch 9, gen_loss = 1.116706993760942, disc_loss = 0.00046320191434955907
Trained batch 79 in epoch 9, gen_loss = 1.1176034785807132, disc_loss = 0.00046279391262942226
Trained batch 80 in epoch 9, gen_loss = 1.11733106404175, disc_loss = 0.0004651037306757644
Trained batch 81 in epoch 9, gen_loss = 1.1183702880289497, disc_loss = 0.0004650897741468237
Trained batch 82 in epoch 9, gen_loss = 1.1182900932898003, disc_loss = 0.0004642089253434552
Trained batch 83 in epoch 9, gen_loss = 1.1197338409367061, disc_loss = 0.0004622919346036811
Trained batch 84 in epoch 9, gen_loss = 1.1193327924784493, disc_loss = 0.00046065472946365307
Trained batch 85 in epoch 9, gen_loss = 1.1185141878072606, disc_loss = 0.0004593228826875972
Trained batch 86 in epoch 9, gen_loss = 1.115550853055099, disc_loss = 0.0004579838742997133
Trained batch 87 in epoch 9, gen_loss = 1.1159612895412878, disc_loss = 0.0004561993603353833
Trained batch 88 in epoch 9, gen_loss = 1.1138856779323536, disc_loss = 0.000455678202077129
Trained batch 89 in epoch 9, gen_loss = 1.112356048822403, disc_loss = 0.00045427379001113067
Trained batch 90 in epoch 9, gen_loss = 1.1097245072270487, disc_loss = 0.00045409266581723036
Trained batch 91 in epoch 9, gen_loss = 1.1091920629791592, disc_loss = 0.00045117912494511666
Trained batch 92 in epoch 9, gen_loss = 1.1095821959998018, disc_loss = 0.0004499248222395357
Trained batch 93 in epoch 9, gen_loss = 1.1086919003344597, disc_loss = 0.0004540505926459136
Trained batch 94 in epoch 9, gen_loss = 1.1072682368127924, disc_loss = 0.00046323974184863466
Trained batch 95 in epoch 9, gen_loss = 1.110252883285284, disc_loss = 0.00046395946856137016
Trained batch 96 in epoch 9, gen_loss = 1.1109393613854635, disc_loss = 0.00046523418814572743
Trained batch 97 in epoch 9, gen_loss = 1.1091810647322207, disc_loss = 0.00046503820651975857
Trained batch 98 in epoch 9, gen_loss = 1.1099867254796654, disc_loss = 0.0004626533233812267
Trained batch 99 in epoch 9, gen_loss = 1.1124037420749664, disc_loss = 0.0004608110677509103
Trained batch 100 in epoch 9, gen_loss = 1.1119937318386417, disc_loss = 0.00045948218462624505
Trained batch 101 in epoch 9, gen_loss = 1.1149407426516216, disc_loss = 0.00045904841838409103
Trained batch 102 in epoch 9, gen_loss = 1.1147023728750285, disc_loss = 0.0004573136959982204
Trained batch 103 in epoch 9, gen_loss = 1.1137589812278748, disc_loss = 0.00045763106013160164
Trained batch 104 in epoch 9, gen_loss = 1.1120611968494596, disc_loss = 0.0004573871491066668
Trained batch 105 in epoch 9, gen_loss = 1.1117382246368337, disc_loss = 0.0004550803256142041
Trained batch 106 in epoch 9, gen_loss = 1.1129127401057806, disc_loss = 0.0004530828641988685
Trained batch 107 in epoch 9, gen_loss = 1.112800845945323, disc_loss = 0.0004526002524437866
Trained batch 108 in epoch 9, gen_loss = 1.1116905863131952, disc_loss = 0.00045436566830142785
Trained batch 109 in epoch 9, gen_loss = 1.1103598675944588, disc_loss = 0.00046088240289298647
Trained batch 110 in epoch 9, gen_loss = 1.1094411079948012, disc_loss = 0.00046402938991180946
Trained batch 111 in epoch 9, gen_loss = 1.1105156833572047, disc_loss = 0.00046835575994919054
Trained batch 112 in epoch 9, gen_loss = 1.1122647275966882, disc_loss = 0.0004697351467144568
Trained batch 113 in epoch 9, gen_loss = 1.1111620915563483, disc_loss = 0.00047442297708537236
Trained batch 114 in epoch 9, gen_loss = 1.1095788437387217, disc_loss = 0.0004760216010491485
Trained batch 115 in epoch 9, gen_loss = 1.1085909466291297, disc_loss = 0.0004751548614625915
Trained batch 116 in epoch 9, gen_loss = 1.1086814164096475, disc_loss = 0.0004735803104734096
Trained batch 117 in epoch 9, gen_loss = 1.106288768477359, disc_loss = 0.0004715351479116164
Trained batch 118 in epoch 9, gen_loss = 1.1070301112006693, disc_loss = 0.0004690765161575953
Trained batch 119 in epoch 9, gen_loss = 1.1052582398056985, disc_loss = 0.00046707696164958177
Trained batch 120 in epoch 9, gen_loss = 1.1046369809749699, disc_loss = 0.0004649562931962096
Trained batch 121 in epoch 9, gen_loss = 1.1044267147290903, disc_loss = 0.0004627406112868797
Trained batch 122 in epoch 9, gen_loss = 1.1053705927802295, disc_loss = 0.0004622819608671788
Trained batch 123 in epoch 9, gen_loss = 1.1052426296857096, disc_loss = 0.00045985172231843125
Trained batch 124 in epoch 9, gen_loss = 1.1054572443962096, disc_loss = 0.0004580587527016178
Trained batch 125 in epoch 9, gen_loss = 1.105094896895545, disc_loss = 0.0004569618249661289
Trained batch 126 in epoch 9, gen_loss = 1.1047059743423162, disc_loss = 0.0004558822402032092
Trained batch 127 in epoch 9, gen_loss = 1.1038068630732596, disc_loss = 0.0004544739596212821
Trained batch 128 in epoch 9, gen_loss = 1.1038015244543091, disc_loss = 0.0004529217942825396
Trained batch 129 in epoch 9, gen_loss = 1.104095296217845, disc_loss = 0.00045162767939753114
Trained batch 130 in epoch 9, gen_loss = 1.1038003882379022, disc_loss = 0.0004498083827588778
Trained batch 131 in epoch 9, gen_loss = 1.1025228279106545, disc_loss = 0.0004480679465015066
Trained batch 132 in epoch 9, gen_loss = 1.1035578945525606, disc_loss = 0.00044569743504394125
Trained batch 133 in epoch 9, gen_loss = 1.1033218614201048, disc_loss = 0.00044429371119980744
Trained batch 134 in epoch 9, gen_loss = 1.1027927509060613, disc_loss = 0.0004432729250294398
Trained batch 135 in epoch 9, gen_loss = 1.1024746303172672, disc_loss = 0.0004420410429755815
Trained batch 136 in epoch 9, gen_loss = 1.103257351113062, disc_loss = 0.000440254769339838
Trained batch 137 in epoch 9, gen_loss = 1.1019556328006412, disc_loss = 0.00043928628714427867
Trained batch 138 in epoch 9, gen_loss = 1.101652083208235, disc_loss = 0.000440329020460163
Trained batch 139 in epoch 9, gen_loss = 1.1005462846585683, disc_loss = 0.00043967136495796564
Trained batch 140 in epoch 9, gen_loss = 1.1016792147717578, disc_loss = 0.0004398149331075516
Trained batch 141 in epoch 9, gen_loss = 1.1012136033723052, disc_loss = 0.0004407567814243367
Trained batch 142 in epoch 9, gen_loss = 1.1008246265924895, disc_loss = 0.0004402281156980426
Trained batch 143 in epoch 9, gen_loss = 1.100569119469987, disc_loss = 0.00044067020917282207
Trained batch 144 in epoch 9, gen_loss = 1.099401513461409, disc_loss = 0.0004402809584681908
Trained batch 145 in epoch 9, gen_loss = 1.0978300636761809, disc_loss = 0.0004397188266460171
Trained batch 146 in epoch 9, gen_loss = 1.0968854029973347, disc_loss = 0.0004398600519262571
Trained batch 147 in epoch 9, gen_loss = 1.0964956750740875, disc_loss = 0.00043987446534211395
Trained batch 148 in epoch 9, gen_loss = 1.0961709830584943, disc_loss = 0.00043913029826124316
Trained batch 149 in epoch 9, gen_loss = 1.0957421692212423, disc_loss = 0.0004399929291685112
Trained batch 150 in epoch 9, gen_loss = 1.0963359660660195, disc_loss = 0.000439873279672924
Trained batch 151 in epoch 9, gen_loss = 1.0961236373374337, disc_loss = 0.0004382132815647454
Trained batch 152 in epoch 9, gen_loss = 1.0962840778375762, disc_loss = 0.0004370404333956661
Trained batch 153 in epoch 9, gen_loss = 1.096093326419979, disc_loss = 0.000436405525028754
Trained batch 154 in epoch 9, gen_loss = 1.0957653860892018, disc_loss = 0.0004344544262670341
Trained batch 155 in epoch 9, gen_loss = 1.0954127242931953, disc_loss = 0.000433243140063356
Trained batch 156 in epoch 9, gen_loss = 1.094732770874242, disc_loss = 0.00043158759722622576
Trained batch 157 in epoch 9, gen_loss = 1.0958865794199932, disc_loss = 0.0004310249503852234
Trained batch 158 in epoch 9, gen_loss = 1.096632569465997, disc_loss = 0.000430610667329879
Trained batch 159 in epoch 9, gen_loss = 1.0964056018739938, disc_loss = 0.0004293948226404609
Trained batch 160 in epoch 9, gen_loss = 1.0957514391922802, disc_loss = 0.00042836954969021935
Trained batch 161 in epoch 9, gen_loss = 1.0950277775158117, disc_loss = 0.00042744920237627984
Trained batch 162 in epoch 9, gen_loss = 1.0940582258569682, disc_loss = 0.0004264055995879112
Trained batch 163 in epoch 9, gen_loss = 1.0934550747638796, disc_loss = 0.0004258789973924073
Trained batch 164 in epoch 9, gen_loss = 1.0930411772294477, disc_loss = 0.0004264348514632068
Trained batch 165 in epoch 9, gen_loss = 1.0925367955701897, disc_loss = 0.0004274432900844209
Trained batch 166 in epoch 9, gen_loss = 1.0928078946953048, disc_loss = 0.00042690745447511355
Trained batch 167 in epoch 9, gen_loss = 1.092704380551974, disc_loss = 0.0004260734647340585
Trained batch 168 in epoch 9, gen_loss = 1.093321833384813, disc_loss = 0.00042505423795327147
Trained batch 169 in epoch 9, gen_loss = 1.0930590194814345, disc_loss = 0.00042363689495045144
Trained batch 170 in epoch 9, gen_loss = 1.0938550331439192, disc_loss = 0.000421970930445411
Trained batch 171 in epoch 9, gen_loss = 1.0925055880879246, disc_loss = 0.000420483354351153
Trained batch 172 in epoch 9, gen_loss = 1.094625656315357, disc_loss = 0.0004190107250843208
Trained batch 173 in epoch 9, gen_loss = 1.0939029331864982, disc_loss = 0.0004194080310267525
Trained batch 174 in epoch 9, gen_loss = 1.0934940671920776, disc_loss = 0.0004198590502242691
Trained batch 175 in epoch 9, gen_loss = 1.0925764949484305, disc_loss = 0.0004234084404246956
Trained batch 176 in epoch 9, gen_loss = 1.0925757730074521, disc_loss = 0.0004357382747059225
Trained batch 177 in epoch 9, gen_loss = 1.0917023644688424, disc_loss = 0.00044807704357532365
Trained batch 178 in epoch 9, gen_loss = 1.0913487962504338, disc_loss = 0.0004514624294272088
Trained batch 179 in epoch 9, gen_loss = 1.0923266294929717, disc_loss = 0.00045155960469855927
Trained batch 180 in epoch 9, gen_loss = 1.0924460627756065, disc_loss = 0.0004525169699153096
Trained batch 181 in epoch 9, gen_loss = 1.0924433512347085, disc_loss = 0.00045839594739455994
Trained batch 182 in epoch 9, gen_loss = 1.092707637554961, disc_loss = 0.0004681225434611068
Trained batch 183 in epoch 9, gen_loss = 1.0944973648242329, disc_loss = 0.0004765699922364033
Trained batch 184 in epoch 9, gen_loss = 1.094937679252109, disc_loss = 0.0004774237236454831
Trained batch 185 in epoch 9, gen_loss = 1.0943633833880066, disc_loss = 0.00047640450715315176
Trained batch 186 in epoch 9, gen_loss = 1.094011484301664, disc_loss = 0.0004769329010119243
Trained batch 187 in epoch 9, gen_loss = 1.0931998592741945, disc_loss = 0.0004801807804819583
Trained batch 188 in epoch 9, gen_loss = 1.093281175724413, disc_loss = 0.0004828451942774423
Trained batch 189 in epoch 9, gen_loss = 1.0927453492817125, disc_loss = 0.0004825131416988657
Trained batch 190 in epoch 9, gen_loss = 1.0929385479832194, disc_loss = 0.00048122442381076164
Trained batch 191 in epoch 9, gen_loss = 1.092873460923632, disc_loss = 0.00048086876783296856
Trained batch 192 in epoch 9, gen_loss = 1.0939294729825746, disc_loss = 0.00048024191248467084
Trained batch 193 in epoch 9, gen_loss = 1.0932595416442634, disc_loss = 0.00047917760093696415
Trained batch 194 in epoch 9, gen_loss = 1.0948239509875959, disc_loss = 0.00047846278847338486
Trained batch 195 in epoch 9, gen_loss = 1.094201379588672, disc_loss = 0.00047724695750916074
Trained batch 196 in epoch 9, gen_loss = 1.0949441046279094, disc_loss = 0.0004765223652634978
Trained batch 197 in epoch 9, gen_loss = 1.0945047287627905, disc_loss = 0.000479434374037829
Trained batch 198 in epoch 9, gen_loss = 1.0946945314431311, disc_loss = 0.0004828568394693672
Trained batch 199 in epoch 9, gen_loss = 1.093534410595894, disc_loss = 0.00048357572930399326
Trained batch 200 in epoch 9, gen_loss = 1.0930213676163214, disc_loss = 0.00048356062187627884
Trained batch 201 in epoch 9, gen_loss = 1.0924197591767453, disc_loss = 0.0004828063335147511
Trained batch 202 in epoch 9, gen_loss = 1.091973851173382, disc_loss = 0.000481306908570753
Trained batch 203 in epoch 9, gen_loss = 1.0918368927988351, disc_loss = 0.0004797764491990629
Trained batch 204 in epoch 9, gen_loss = 1.0930606548379107, disc_loss = 0.000478222030754451
Trained batch 205 in epoch 9, gen_loss = 1.0935105956295161, disc_loss = 0.00047663076775367777
Trained batch 206 in epoch 9, gen_loss = 1.0930938216799124, disc_loss = 0.0004749313595953312
Trained batch 207 in epoch 9, gen_loss = 1.0929048671745336, disc_loss = 0.00047337207168031734
Trained batch 208 in epoch 9, gen_loss = 1.0925457902502216, disc_loss = 0.0004724593398341704
Trained batch 209 in epoch 9, gen_loss = 1.0927746588275546, disc_loss = 0.00047214918304234744
Trained batch 210 in epoch 9, gen_loss = 1.0925646836723761, disc_loss = 0.0004706767447551015
Trained batch 211 in epoch 9, gen_loss = 1.0919827113174043, disc_loss = 0.0004694843571413449
Trained batch 212 in epoch 9, gen_loss = 1.091420292014807, disc_loss = 0.0004685170633692137
Trained batch 213 in epoch 9, gen_loss = 1.0914280500924476, disc_loss = 0.00046796086635962826
Trained batch 214 in epoch 9, gen_loss = 1.0909996002219444, disc_loss = 0.00046649618320665216
Trained batch 215 in epoch 9, gen_loss = 1.0910315626749285, disc_loss = 0.0004672198926898461
Trained batch 216 in epoch 9, gen_loss = 1.090677271515543, disc_loss = 0.0004704667217460834
Trained batch 217 in epoch 9, gen_loss = 1.0912723636955297, disc_loss = 0.0004740531064747243
Trained batch 218 in epoch 9, gen_loss = 1.090543530030882, disc_loss = 0.00047405477872088585
Trained batch 219 in epoch 9, gen_loss = 1.08996211967685, disc_loss = 0.00047498209976104343
Trained batch 220 in epoch 9, gen_loss = 1.090244530822357, disc_loss = 0.0004766524709577828
Trained batch 221 in epoch 9, gen_loss = 1.0905326768621668, disc_loss = 0.0004767594033871098
Trained batch 222 in epoch 9, gen_loss = 1.09064610041845, disc_loss = 0.0004765565266713684
Trained batch 223 in epoch 9, gen_loss = 1.0904636385717563, disc_loss = 0.00047658880677252976
Trained batch 224 in epoch 9, gen_loss = 1.0909634153048198, disc_loss = 0.00047634957785097263
Trained batch 225 in epoch 9, gen_loss = 1.0915473997592926, disc_loss = 0.0004770663589809865
Trained batch 226 in epoch 9, gen_loss = 1.090965857852398, disc_loss = 0.00047675206514161556
Trained batch 227 in epoch 9, gen_loss = 1.0909382855160195, disc_loss = 0.0004767977405112776
Trained batch 228 in epoch 9, gen_loss = 1.0908126068427573, disc_loss = 0.00047740411924861176
Trained batch 229 in epoch 9, gen_loss = 1.0912681266017583, disc_loss = 0.0004786640404389523
Trained batch 230 in epoch 9, gen_loss = 1.0926762775425272, disc_loss = 0.00047807591411414116
Trained batch 231 in epoch 9, gen_loss = 1.0934716034038314, disc_loss = 0.00047746622620816826
Trained batch 232 in epoch 9, gen_loss = 1.0948849366458189, disc_loss = 0.0004778754494708559
Trained batch 233 in epoch 9, gen_loss = 1.094898879273325, disc_loss = 0.0004778019904803771
Trained batch 234 in epoch 9, gen_loss = 1.0947500479982255, disc_loss = 0.0004767963245382255
Trained batch 235 in epoch 9, gen_loss = 1.0946729685795509, disc_loss = 0.00047616254029227264
Trained batch 236 in epoch 9, gen_loss = 1.0943492059969198, disc_loss = 0.00047650594654284763
Trained batch 237 in epoch 9, gen_loss = 1.0938218493922418, disc_loss = 0.00047746571142836907
Trained batch 238 in epoch 9, gen_loss = 1.09343067896416, disc_loss = 0.00047657544121621604
Trained batch 239 in epoch 9, gen_loss = 1.092732048034668, disc_loss = 0.00047538548557592245
Trained batch 240 in epoch 9, gen_loss = 1.0922799862272017, disc_loss = 0.00047496039878298755
Trained batch 241 in epoch 9, gen_loss = 1.0927194888926735, disc_loss = 0.00047613451813447697
Trained batch 242 in epoch 9, gen_loss = 1.0931361447636483, disc_loss = 0.00047694165676395283
Trained batch 243 in epoch 9, gen_loss = 1.0934477018528297, disc_loss = 0.0004763914382879118
Trained batch 244 in epoch 9, gen_loss = 1.0930410570027878, disc_loss = 0.00047544777721204623
Trained batch 245 in epoch 9, gen_loss = 1.0928997344117823, disc_loss = 0.00047517622886339157
Trained batch 246 in epoch 9, gen_loss = 1.0925179572723172, disc_loss = 0.0004759826640851102
Trained batch 247 in epoch 9, gen_loss = 1.091680907674374, disc_loss = 0.0004787123170606191
Trained batch 248 in epoch 9, gen_loss = 1.0919407196791775, disc_loss = 0.00048312965694470816
Trained batch 249 in epoch 9, gen_loss = 1.0918634040355681, disc_loss = 0.0004837778736837208
Trained batch 250 in epoch 9, gen_loss = 1.0917665072646274, disc_loss = 0.00048351559713315885
Trained batch 251 in epoch 9, gen_loss = 1.0919142320515618, disc_loss = 0.0004853380829907052
Trained batch 252 in epoch 9, gen_loss = 1.091968405623681, disc_loss = 0.0004881359258318769
Trained batch 253 in epoch 9, gen_loss = 1.092142927599704, disc_loss = 0.0004894912249076833
Trained batch 254 in epoch 9, gen_loss = 1.0927512643383999, disc_loss = 0.000488565005498993
Trained batch 255 in epoch 9, gen_loss = 1.0921334729064256, disc_loss = 0.0004877520414083847
Trained batch 256 in epoch 9, gen_loss = 1.0920053977910646, disc_loss = 0.0004870972862459922
Trained batch 257 in epoch 9, gen_loss = 1.09168060828549, disc_loss = 0.0004861008298272888
Trained batch 258 in epoch 9, gen_loss = 1.0910860751126263, disc_loss = 0.00048510463938429864
Trained batch 259 in epoch 9, gen_loss = 1.0911261333869053, disc_loss = 0.00048380483405288454
Trained batch 260 in epoch 9, gen_loss = 1.090665772500166, disc_loss = 0.00048361876707388467
Trained batch 261 in epoch 9, gen_loss = 1.09041693010403, disc_loss = 0.0004838815619653617
Trained batch 262 in epoch 9, gen_loss = 1.0904356776081563, disc_loss = 0.00048356124942683165
Trained batch 263 in epoch 9, gen_loss = 1.0902502712878315, disc_loss = 0.0004824643081409511
Trained batch 264 in epoch 9, gen_loss = 1.0906024271587156, disc_loss = 0.0004820158051102826
Trained batch 265 in epoch 9, gen_loss = 1.090475436888243, disc_loss = 0.00048307797840237967
Trained batch 266 in epoch 9, gen_loss = 1.0902393172296245, disc_loss = 0.0004833172784951665
Trained batch 267 in epoch 9, gen_loss = 1.090494396526422, disc_loss = 0.0004832220860299091
Trained batch 268 in epoch 9, gen_loss = 1.0906205811021938, disc_loss = 0.00048301805882519075
Trained batch 269 in epoch 9, gen_loss = 1.089955857064989, disc_loss = 0.00048217335893746674
Trained batch 270 in epoch 9, gen_loss = 1.0902068482993714, disc_loss = 0.0004811307864918329
Trained batch 271 in epoch 9, gen_loss = 1.0902319397119915, disc_loss = 0.00048007200910112313
Trained batch 272 in epoch 9, gen_loss = 1.0898811900135361, disc_loss = 0.00047875658950969686
Trained batch 273 in epoch 9, gen_loss = 1.0905416903704623, disc_loss = 0.0004782091044858234
Trained batch 274 in epoch 9, gen_loss = 1.0902583612095227, disc_loss = 0.00047920345117084004
Trained batch 275 in epoch 9, gen_loss = 1.0902755990408468, disc_loss = 0.00048021469147120047
Trained batch 276 in epoch 9, gen_loss = 1.0902679853060615, disc_loss = 0.00048002449540078426
Trained batch 277 in epoch 9, gen_loss = 1.0921781003046378, disc_loss = 0.0004797072975608192
Trained batch 278 in epoch 9, gen_loss = 1.0928407399030569, disc_loss = 0.0004787910628461322
Trained batch 279 in epoch 9, gen_loss = 1.0930711550371988, disc_loss = 0.0004778694580766439
Trained batch 280 in epoch 9, gen_loss = 1.0932802131591743, disc_loss = 0.00047681645937247395
Trained batch 281 in epoch 9, gen_loss = 1.0937098294285172, disc_loss = 0.00047561229506535587
Trained batch 282 in epoch 9, gen_loss = 1.0935966985385746, disc_loss = 0.0004742237130295594
Trained batch 283 in epoch 9, gen_loss = 1.0937780578371505, disc_loss = 0.00047288081917889633
Trained batch 284 in epoch 9, gen_loss = 1.0938433488210042, disc_loss = 0.00047153992189825596
Trained batch 285 in epoch 9, gen_loss = 1.0938662953310079, disc_loss = 0.00047035871634412056
Trained batch 286 in epoch 9, gen_loss = 1.094124402318682, disc_loss = 0.0004692097053891908
Trained batch 287 in epoch 9, gen_loss = 1.093774328629176, disc_loss = 0.0004680733188706654
Trained batch 288 in epoch 9, gen_loss = 1.0934786957440492, disc_loss = 0.0004672417840886149
Trained batch 289 in epoch 9, gen_loss = 1.0940973832689482, disc_loss = 0.000468302937701208
Trained batch 290 in epoch 9, gen_loss = 1.0938725266669624, disc_loss = 0.00046894472052684837
Trained batch 291 in epoch 9, gen_loss = 1.0932066252786818, disc_loss = 0.0004689958936418008
Trained batch 292 in epoch 9, gen_loss = 1.0925985578790867, disc_loss = 0.0004686823073977608
Trained batch 293 in epoch 9, gen_loss = 1.0919053627520192, disc_loss = 0.000469502445474088
Trained batch 294 in epoch 9, gen_loss = 1.092482648461552, disc_loss = 0.00047086260113292925
Trained batch 295 in epoch 9, gen_loss = 1.0931198588899664, disc_loss = 0.00047242978343018803
Trained batch 296 in epoch 9, gen_loss = 1.0928043183252867, disc_loss = 0.00047299105033450146
Trained batch 297 in epoch 9, gen_loss = 1.092952687868336, disc_loss = 0.0004724814454138501
Trained batch 298 in epoch 9, gen_loss = 1.0923110609469207, disc_loss = 0.0004716302387883192
Trained batch 299 in epoch 9, gen_loss = 1.092461442152659, disc_loss = 0.00047045301034813746
Trained batch 300 in epoch 9, gen_loss = 1.0930935417694903, disc_loss = 0.00046957220536605627
Trained batch 301 in epoch 9, gen_loss = 1.0933747406037437, disc_loss = 0.00046906385973399654
Trained batch 302 in epoch 9, gen_loss = 1.093387739493115, disc_loss = 0.00046886941142381777
Trained batch 303 in epoch 9, gen_loss = 1.093032343411132, disc_loss = 0.0004691047110770198
Trained batch 304 in epoch 9, gen_loss = 1.0936088825835557, disc_loss = 0.00046967280838737784
Trained batch 305 in epoch 9, gen_loss = 1.0942178962667004, disc_loss = 0.0004707147697617568
Trained batch 306 in epoch 9, gen_loss = 1.0943318448159904, disc_loss = 0.00047139910639207565
Trained batch 307 in epoch 9, gen_loss = 1.094479102399442, disc_loss = 0.00047185640562327226
Trained batch 308 in epoch 9, gen_loss = 1.093900475301403, disc_loss = 0.0004725448418846414
Trained batch 309 in epoch 9, gen_loss = 1.0939819397464876, disc_loss = 0.0004733975201698711
Trained batch 310 in epoch 9, gen_loss = 1.093469566662595, disc_loss = 0.00047439582020956185
Trained batch 311 in epoch 9, gen_loss = 1.0933296113060071, disc_loss = 0.00047492162957496475
Trained batch 312 in epoch 9, gen_loss = 1.093388775095772, disc_loss = 0.00047488388600394713
Trained batch 313 in epoch 9, gen_loss = 1.0927575350187386, disc_loss = 0.00047469146574356525
Trained batch 314 in epoch 9, gen_loss = 1.0941385884133596, disc_loss = 0.0004743638301050172
Trained batch 315 in epoch 9, gen_loss = 1.0936428763066666, disc_loss = 0.0004738268543854857
Trained batch 316 in epoch 9, gen_loss = 1.093456066181231, disc_loss = 0.0004734227699407579
Trained batch 317 in epoch 9, gen_loss = 1.093499890850775, disc_loss = 0.00047336095390708107
Trained batch 318 in epoch 9, gen_loss = 1.0936824193568813, disc_loss = 0.0004732726666135538
Trained batch 319 in epoch 9, gen_loss = 1.0941521609202027, disc_loss = 0.0004728230011551204
Trained batch 320 in epoch 9, gen_loss = 1.0944363627106972, disc_loss = 0.0004718872154841629
Trained batch 321 in epoch 9, gen_loss = 1.0939912198122985, disc_loss = 0.000470911020473418
Trained batch 322 in epoch 9, gen_loss = 1.0937492033645464, disc_loss = 0.00047000008964105205
Trained batch 323 in epoch 9, gen_loss = 1.0939083413945303, disc_loss = 0.0004692165025011895
Trained batch 324 in epoch 9, gen_loss = 1.0936001447530894, disc_loss = 0.00047068373241927476
Trained batch 325 in epoch 9, gen_loss = 1.093480106877403, disc_loss = 0.00047266169677401374
Trained batch 326 in epoch 9, gen_loss = 1.09319121757414, disc_loss = 0.0004727202322991246
Trained batch 327 in epoch 9, gen_loss = 1.0931811936017943, disc_loss = 0.00047223080316432126
Trained batch 328 in epoch 9, gen_loss = 1.0930076696227748, disc_loss = 0.0004716750548315294
Trained batch 329 in epoch 9, gen_loss = 1.0930739482243856, disc_loss = 0.00047083213871563644
Trained batch 330 in epoch 9, gen_loss = 1.0935846502327127, disc_loss = 0.00046994199752462945
Trained batch 331 in epoch 9, gen_loss = 1.0938940360603562, disc_loss = 0.0004693802042618108
Trained batch 332 in epoch 9, gen_loss = 1.0941000550358861, disc_loss = 0.0004696588923154097
Trained batch 333 in epoch 9, gen_loss = 1.094346090705095, disc_loss = 0.00047061754315485063
Trained batch 334 in epoch 9, gen_loss = 1.0938515431845366, disc_loss = 0.00047023838760379926
Trained batch 335 in epoch 9, gen_loss = 1.094961980978648, disc_loss = 0.00046962481692822795
Trained batch 336 in epoch 9, gen_loss = 1.0951510635964594, disc_loss = 0.0004699443583463067
Trained batch 337 in epoch 9, gen_loss = 1.0953280453145857, disc_loss = 0.0004701257500189257
Trained batch 338 in epoch 9, gen_loss = 1.0955618750029257, disc_loss = 0.0004695740320728707
Trained batch 339 in epoch 9, gen_loss = 1.0950048383544473, disc_loss = 0.00046893989017596195
Trained batch 340 in epoch 9, gen_loss = 1.0955573963629535, disc_loss = 0.00046833268689541995
Trained batch 341 in epoch 9, gen_loss = 1.0958355592008222, disc_loss = 0.0004671985441224843
Trained batch 342 in epoch 9, gen_loss = 1.0957323149411393, disc_loss = 0.00046634967136383466
Trained batch 343 in epoch 9, gen_loss = 1.095709963593372, disc_loss = 0.00046609575789727047
Trained batch 344 in epoch 9, gen_loss = 1.0960933353589928, disc_loss = 0.0004660238329434187
Trained batch 345 in epoch 9, gen_loss = 1.0963866817468852, disc_loss = 0.0004652780564587679
Trained batch 346 in epoch 9, gen_loss = 1.0958686898695975, disc_loss = 0.00046429749898547416
Trained batch 347 in epoch 9, gen_loss = 1.0966354351619194, disc_loss = 0.0004634081121795375
Trained batch 348 in epoch 9, gen_loss = 1.0965164455779985, disc_loss = 0.0004626094625439204
Trained batch 349 in epoch 9, gen_loss = 1.0968188881874084, disc_loss = 0.00046367966293473726
Trained batch 350 in epoch 9, gen_loss = 1.0964380672514609, disc_loss = 0.00046696199360485996
Trained batch 351 in epoch 9, gen_loss = 1.096581773663109, disc_loss = 0.0004694624369676603
Trained batch 352 in epoch 9, gen_loss = 1.0960079320091702, disc_loss = 0.00047061494415973526
Trained batch 353 in epoch 9, gen_loss = 1.0965918470910714, disc_loss = 0.00047510250830890656
Trained batch 354 in epoch 9, gen_loss = 1.0965732762511347, disc_loss = 0.00048075012399890446
Trained batch 355 in epoch 9, gen_loss = 1.0962529333119981, disc_loss = 0.00048554053989463363
Trained batch 356 in epoch 9, gen_loss = 1.09677969875122, disc_loss = 0.0004870952536436437
Trained batch 357 in epoch 9, gen_loss = 1.096802294254303, disc_loss = 0.0004869838624335136
Trained batch 358 in epoch 9, gen_loss = 1.0969301096908228, disc_loss = 0.0004867730255218931
Trained batch 359 in epoch 9, gen_loss = 1.0969292292992274, disc_loss = 0.0004866590761189905
Trained batch 360 in epoch 9, gen_loss = 1.0973461087060437, disc_loss = 0.00048601157316945136
Trained batch 361 in epoch 9, gen_loss = 1.0973321505673024, disc_loss = 0.0004851665967959301
Trained batch 362 in epoch 9, gen_loss = 1.0972974329940544, disc_loss = 0.000484564272633442
Trained batch 363 in epoch 9, gen_loss = 1.0975046868507679, disc_loss = 0.00048406268525558427
Trained batch 364 in epoch 9, gen_loss = 1.0973738516846747, disc_loss = 0.0004832536422875582
Trained batch 365 in epoch 9, gen_loss = 1.0971949533686611, disc_loss = 0.0004822120177688375
Trained batch 366 in epoch 9, gen_loss = 1.097370080467141, disc_loss = 0.000481589231659926
Trained batch 367 in epoch 9, gen_loss = 1.0980942887456522, disc_loss = 0.00048156672625301997
Trained batch 368 in epoch 9, gen_loss = 1.097592109264074, disc_loss = 0.00048188627694766885
Trained batch 369 in epoch 9, gen_loss = 1.0970062948562003, disc_loss = 0.0004822976537390197
Trained batch 370 in epoch 9, gen_loss = 1.0965242718429258, disc_loss = 0.0004828559550134443
Trained batch 371 in epoch 9, gen_loss = 1.0967445272591807, disc_loss = 0.0004827981393714498
Trained batch 372 in epoch 9, gen_loss = 1.0967932186880955, disc_loss = 0.00048206594307833895
Trained batch 373 in epoch 9, gen_loss = 1.0965138469787843, disc_loss = 0.00048122088295917456
Trained batch 374 in epoch 9, gen_loss = 1.0970981973012288, disc_loss = 0.00048162960647217307
Trained batch 375 in epoch 9, gen_loss = 1.0972140967211825, disc_loss = 0.0004841178069329273
Trained batch 376 in epoch 9, gen_loss = 1.0974742050828605, disc_loss = 0.00048529622433333476
Trained batch 377 in epoch 9, gen_loss = 1.097593657554142, disc_loss = 0.0004853931419905854
Trained batch 378 in epoch 9, gen_loss = 1.097952545160983, disc_loss = 0.00048513169196359984
Trained batch 379 in epoch 9, gen_loss = 1.0976710034044166, disc_loss = 0.000484642205207676
Trained batch 380 in epoch 9, gen_loss = 1.0975626062533361, disc_loss = 0.0004838981481843134
Trained batch 381 in epoch 9, gen_loss = 1.097761918737002, disc_loss = 0.000483130830054687
Trained batch 382 in epoch 9, gen_loss = 1.0975964642069047, disc_loss = 0.0004822681141433953
Trained batch 383 in epoch 9, gen_loss = 1.0977961582442124, disc_loss = 0.00048150783590017454
Trained batch 384 in epoch 9, gen_loss = 1.097288025818862, disc_loss = 0.0004810130952550522
Trained batch 385 in epoch 9, gen_loss = 1.0975913074967776, disc_loss = 0.00048099187184429793
Trained batch 386 in epoch 9, gen_loss = 1.0979085067137884, disc_loss = 0.00048055359531565175
Trained batch 387 in epoch 9, gen_loss = 1.097836510729544, disc_loss = 0.00047966139647973456
Trained batch 388 in epoch 9, gen_loss = 1.0983217786087782, disc_loss = 0.00047880909106006445
Trained batch 389 in epoch 9, gen_loss = 1.098412062571599, disc_loss = 0.00047802221698265595
Trained batch 390 in epoch 9, gen_loss = 1.0978984869349644, disc_loss = 0.0004777208185846122
Trained batch 391 in epoch 9, gen_loss = 1.0977712778412565, disc_loss = 0.00047701349539776706
Trained batch 392 in epoch 9, gen_loss = 1.0974075313439502, disc_loss = 0.0004762318524235502
Trained batch 393 in epoch 9, gen_loss = 1.0969078263958094, disc_loss = 0.0004754147794578392
Trained batch 394 in epoch 9, gen_loss = 1.096895210501514, disc_loss = 0.00047452455204896794
Trained batch 395 in epoch 9, gen_loss = 1.0966622547970877, disc_loss = 0.0004746240995360734
Trained batch 396 in epoch 9, gen_loss = 1.0964180588421955, disc_loss = 0.00047531360872861075
Trained batch 397 in epoch 9, gen_loss = 1.0962882479231562, disc_loss = 0.0004754831340629315
Trained batch 398 in epoch 9, gen_loss = 1.0962718716241364, disc_loss = 0.00047504204887541403
Trained batch 399 in epoch 9, gen_loss = 1.0962114468216897, disc_loss = 0.0004743057180348842
Trained batch 400 in epoch 9, gen_loss = 1.096520708683423, disc_loss = 0.0004734985566556632
Trained batch 401 in epoch 9, gen_loss = 1.0965950678830123, disc_loss = 0.0004728139195941905
Trained batch 402 in epoch 9, gen_loss = 1.0971966487893987, disc_loss = 0.0004722071052654577
Trained batch 403 in epoch 9, gen_loss = 1.0976148401156511, disc_loss = 0.0004717382392003189
Trained batch 404 in epoch 9, gen_loss = 1.0970782243175272, disc_loss = 0.0004712336945863452
Trained batch 405 in epoch 9, gen_loss = 1.0966904106104902, disc_loss = 0.00047085183738771564
Trained batch 406 in epoch 9, gen_loss = 1.0964835634688488, disc_loss = 0.0004704926568659821
Trained batch 407 in epoch 9, gen_loss = 1.0967579570178891, disc_loss = 0.00046975808028019305
Trained batch 408 in epoch 9, gen_loss = 1.0970903860910597, disc_loss = 0.00046908180697233026
Trained batch 409 in epoch 9, gen_loss = 1.097294515662077, disc_loss = 0.0004683922287523917
Trained batch 410 in epoch 9, gen_loss = 1.0970172774762712, disc_loss = 0.00046766929729168084
Trained batch 411 in epoch 9, gen_loss = 1.0969724666725085, disc_loss = 0.0004670607337457731
Trained batch 412 in epoch 9, gen_loss = 1.096521178688899, disc_loss = 0.0004665867218709118
Trained batch 413 in epoch 9, gen_loss = 1.0967008313119124, disc_loss = 0.0004660718697189311
Trained batch 414 in epoch 9, gen_loss = 1.097958947951535, disc_loss = 0.00046568931007115395
Trained batch 415 in epoch 9, gen_loss = 1.0977628615040045, disc_loss = 0.0004651232464556625
Trained batch 416 in epoch 9, gen_loss = 1.0978454008376857, disc_loss = 0.0004645125905091749
Trained batch 417 in epoch 9, gen_loss = 1.097921194071975, disc_loss = 0.000463963583400434
Trained batch 418 in epoch 9, gen_loss = 1.0981170442622146, disc_loss = 0.00046325626124659564
Trained batch 419 in epoch 9, gen_loss = 1.0978791341895149, disc_loss = 0.00046246593460853635
Trained batch 420 in epoch 9, gen_loss = 1.0976987802500964, disc_loss = 0.000461839514406649
Trained batch 421 in epoch 9, gen_loss = 1.0973661563125268, disc_loss = 0.0004612447755358577
Trained batch 422 in epoch 9, gen_loss = 1.0975285451462928, disc_loss = 0.00046055610251409854
Trained batch 423 in epoch 9, gen_loss = 1.0977139547467232, disc_loss = 0.00045989152006785725
Trained batch 424 in epoch 9, gen_loss = 1.0977976317966684, disc_loss = 0.00045983277509495726
Trained batch 425 in epoch 9, gen_loss = 1.0978862529909108, disc_loss = 0.0004597770858140927
Trained batch 426 in epoch 9, gen_loss = 1.0980025204618307, disc_loss = 0.0004595511503670576
Trained batch 427 in epoch 9, gen_loss = 1.0976461711052423, disc_loss = 0.000459139071387662
Trained batch 428 in epoch 9, gen_loss = 1.0974357524118223, disc_loss = 0.0004596117419921489
Trained batch 429 in epoch 9, gen_loss = 1.0974867184494816, disc_loss = 0.0004600384523909333
Trained batch 430 in epoch 9, gen_loss = 1.098097583395699, disc_loss = 0.0004598110946946834
Trained batch 431 in epoch 9, gen_loss = 1.0985870884248503, disc_loss = 0.00045977975769009963
Trained batch 432 in epoch 9, gen_loss = 1.0986935925814076, disc_loss = 0.00046029707564293205
Trained batch 433 in epoch 9, gen_loss = 1.0989305482756706, disc_loss = 0.0004615909268566963
Trained batch 434 in epoch 9, gen_loss = 1.0985946041414107, disc_loss = 0.0004627077278430873
Trained batch 435 in epoch 9, gen_loss = 1.0981911103659814, disc_loss = 0.00046299009824798064
Trained batch 436 in epoch 9, gen_loss = 1.0986825405051015, disc_loss = 0.00046259205170933186
Trained batch 437 in epoch 9, gen_loss = 1.098189117973798, disc_loss = 0.00046203191002810133
Trained batch 438 in epoch 9, gen_loss = 1.0983148693766844, disc_loss = 0.0004618177107719074
Trained batch 439 in epoch 9, gen_loss = 1.0980980520898647, disc_loss = 0.0004618294767417617
Trained batch 440 in epoch 9, gen_loss = 1.0979671902667367, disc_loss = 0.0004619072386135702
Trained batch 441 in epoch 9, gen_loss = 1.0976395004205575, disc_loss = 0.00046203120961446604
Trained batch 442 in epoch 9, gen_loss = 1.097962886027773, disc_loss = 0.00046219237812105714
Trained batch 443 in epoch 9, gen_loss = 1.0979951014658351, disc_loss = 0.00046213317016752643
Trained batch 444 in epoch 9, gen_loss = 1.0986348054382238, disc_loss = 0.00046179869594484084
Trained batch 445 in epoch 9, gen_loss = 1.0982550326484202, disc_loss = 0.00046123641063399183
Trained batch 446 in epoch 9, gen_loss = 1.0981295079459548, disc_loss = 0.00046067873147325134
Trained batch 447 in epoch 9, gen_loss = 1.0987805178655046, disc_loss = 0.00046017821840190924
Trained batch 448 in epoch 9, gen_loss = 1.098652376098463, disc_loss = 0.0004597640703638387
Trained batch 449 in epoch 9, gen_loss = 1.0989348893695408, disc_loss = 0.00045910623123442444
Trained batch 450 in epoch 9, gen_loss = 1.0991440984996619, disc_loss = 0.0004584824720361712
Trained batch 451 in epoch 9, gen_loss = 1.0991926907965568, disc_loss = 0.00045831976451025556
Trained batch 452 in epoch 9, gen_loss = 1.0990910580089814, disc_loss = 0.00045885054274653875
Trained batch 453 in epoch 9, gen_loss = 1.0995211238903095, disc_loss = 0.00045951155313644004
Trained batch 454 in epoch 9, gen_loss = 1.0999485340747204, disc_loss = 0.00046090479963523036
Trained batch 455 in epoch 9, gen_loss = 1.0997758272447085, disc_loss = 0.00046323771160435473
Trained batch 456 in epoch 9, gen_loss = 1.0998291238914173, disc_loss = 0.0004664137055956009
Trained batch 457 in epoch 9, gen_loss = 1.1002665195923185, disc_loss = 0.0004719050221154558
Trained batch 458 in epoch 9, gen_loss = 1.10028133750741, disc_loss = 0.00047758612348375973
Trained batch 459 in epoch 9, gen_loss = 1.0998147031535273, disc_loss = 0.00048112136739845204
Trained batch 460 in epoch 9, gen_loss = 1.0994535891456356, disc_loss = 0.00048320927920636627
Trained batch 461 in epoch 9, gen_loss = 1.099978138100017, disc_loss = 0.00048473327921401584
Trained batch 462 in epoch 9, gen_loss = 1.1002413634347608, disc_loss = 0.00048592466025044497
Trained batch 463 in epoch 9, gen_loss = 1.0999968059617897, disc_loss = 0.0004864826275855915
Trained batch 464 in epoch 9, gen_loss = 1.0995885482398413, disc_loss = 0.0004865640373330974
Trained batch 465 in epoch 9, gen_loss = 1.0997445867296964, disc_loss = 0.000486516026816108
Trained batch 466 in epoch 9, gen_loss = 1.0997943796488663, disc_loss = 0.0004862994927349819
Trained batch 467 in epoch 9, gen_loss = 1.0998130980719867, disc_loss = 0.00048589347350835486
Trained batch 468 in epoch 9, gen_loss = 1.0996030228478568, disc_loss = 0.00048520042178300975
Trained batch 469 in epoch 9, gen_loss = 1.0995745651265407, disc_loss = 0.0004846876439609951
Trained batch 470 in epoch 9, gen_loss = 1.100245995886007, disc_loss = 0.0004843475523157858
Trained batch 471 in epoch 9, gen_loss = 1.10048279090453, disc_loss = 0.00048388494994114963
Trained batch 472 in epoch 9, gen_loss = 1.100886561905859, disc_loss = 0.00048331900089784735
Trained batch 473 in epoch 9, gen_loss = 1.1008248698862293, disc_loss = 0.0004826079121095036
Trained batch 474 in epoch 9, gen_loss = 1.1009634482233148, disc_loss = 0.000481819310332771
Trained batch 475 in epoch 9, gen_loss = 1.1012905447923838, disc_loss = 0.0004810800684263544
Trained batch 476 in epoch 9, gen_loss = 1.100942567709357, disc_loss = 0.0004804434197381543
Trained batch 477 in epoch 9, gen_loss = 1.101093012418707, disc_loss = 0.0004801122047401386
Trained batch 478 in epoch 9, gen_loss = 1.1009520195222349, disc_loss = 0.00047974032281530003
Trained batch 479 in epoch 9, gen_loss = 1.1009111801783245, disc_loss = 0.0004792647157197886
Trained batch 480 in epoch 9, gen_loss = 1.100731900972537, disc_loss = 0.0004787825316711321
Trained batch 481 in epoch 9, gen_loss = 1.1007191479453406, disc_loss = 0.00047805035767047396
Trained batch 482 in epoch 9, gen_loss = 1.1003730155172802, disc_loss = 0.0004773727653196947
Trained batch 483 in epoch 9, gen_loss = 1.1001439199221035, disc_loss = 0.00047665950221340036
Trained batch 484 in epoch 9, gen_loss = 1.1000854576985861, disc_loss = 0.00047597239121312235
Trained batch 485 in epoch 9, gen_loss = 1.1002287387602614, disc_loss = 0.00047534677947556637
Trained batch 486 in epoch 9, gen_loss = 1.1000401306690866, disc_loss = 0.0004745656336386147
Trained batch 487 in epoch 9, gen_loss = 1.0998426589076635, disc_loss = 0.0004737803160051193
Trained batch 488 in epoch 9, gen_loss = 1.0999235713164988, disc_loss = 0.0004730480734391256
Trained batch 489 in epoch 9, gen_loss = 1.1001741259681934, disc_loss = 0.0004723192713958715
Trained batch 490 in epoch 9, gen_loss = 1.099911964109619, disc_loss = 0.0004718538164380462
Trained batch 491 in epoch 9, gen_loss = 1.0996733837253678, disc_loss = 0.0004717220028426273
Trained batch 492 in epoch 9, gen_loss = 1.0997388990365466, disc_loss = 0.000471998534770895
Trained batch 493 in epoch 9, gen_loss = 1.099957716006499, disc_loss = 0.0004716561333214353
Trained batch 494 in epoch 9, gen_loss = 1.0999979836772187, disc_loss = 0.00047103334390240806
Trained batch 495 in epoch 9, gen_loss = 1.0999048194817957, disc_loss = 0.0004704049037495532
Trained batch 496 in epoch 9, gen_loss = 1.099568357050299, disc_loss = 0.0004697760051427647
Trained batch 497 in epoch 9, gen_loss = 1.0997335603198852, disc_loss = 0.0004690719565350224
Trained batch 498 in epoch 9, gen_loss = 1.0998454224131629, disc_loss = 0.00046847331263150604
Trained batch 499 in epoch 9, gen_loss = 1.099639824271202, disc_loss = 0.00046791299393225927
Trained batch 500 in epoch 9, gen_loss = 1.0999747475464188, disc_loss = 0.0004672893109837567
Trained batch 501 in epoch 9, gen_loss = 1.099532816158348, disc_loss = 0.00046755381943845833
Trained batch 502 in epoch 9, gen_loss = 1.0998094244221333, disc_loss = 0.00046873165302454894
Trained batch 503 in epoch 9, gen_loss = 1.0996967124797048, disc_loss = 0.00047036948673473763
Trained batch 504 in epoch 9, gen_loss = 1.0996975878677746, disc_loss = 0.000470816111206515
Trained batch 505 in epoch 9, gen_loss = 1.09977156736634, disc_loss = 0.000470721679261684
Trained batch 506 in epoch 9, gen_loss = 1.0994841168382934, disc_loss = 0.00047060544776220034
Trained batch 507 in epoch 9, gen_loss = 1.0994735360145569, disc_loss = 0.00047070586697373074
Trained batch 508 in epoch 9, gen_loss = 1.0992734820997316, disc_loss = 0.00047080485828182876
Trained batch 509 in epoch 9, gen_loss = 1.0993885771901, disc_loss = 0.0004705907686358984
Trained batch 510 in epoch 9, gen_loss = 1.099106049700959, disc_loss = 0.00047026894772309106
Trained batch 511 in epoch 9, gen_loss = 1.0994411351857707, disc_loss = 0.0004700623722584396
Trained batch 512 in epoch 9, gen_loss = 1.09935203246903, disc_loss = 0.00046964147753414897
Trained batch 513 in epoch 9, gen_loss = 1.0988585194029232, disc_loss = 0.0004692650416664143
Trained batch 514 in epoch 9, gen_loss = 1.099119350169469, disc_loss = 0.00046873194295788653
Trained batch 515 in epoch 9, gen_loss = 1.0988333807435147, disc_loss = 0.0004680601906266231
Trained batch 516 in epoch 9, gen_loss = 1.0992182320275667, disc_loss = 0.0004674702533548905
Trained batch 517 in epoch 9, gen_loss = 1.0991280065079914, disc_loss = 0.0004671577326253346
Trained batch 518 in epoch 9, gen_loss = 1.0989755291010832, disc_loss = 0.00046692346285785025
Trained batch 519 in epoch 9, gen_loss = 1.098622448857014, disc_loss = 0.0004666977782667695
Trained batch 520 in epoch 9, gen_loss = 1.0986406070943529, disc_loss = 0.00046677220555618065
Trained batch 521 in epoch 9, gen_loss = 1.0985912943251745, disc_loss = 0.0004670841993512702
Trained batch 522 in epoch 9, gen_loss = 1.0983380888433802, disc_loss = 0.00046736130238090863
Trained batch 523 in epoch 9, gen_loss = 1.0981450986316186, disc_loss = 0.00046718951246315943
Trained batch 524 in epoch 9, gen_loss = 1.0981353264763243, disc_loss = 0.00046672568718869503
Trained batch 525 in epoch 9, gen_loss = 1.0983138907091698, disc_loss = 0.00046627849374799066
Trained batch 526 in epoch 9, gen_loss = 1.0984016941892127, disc_loss = 0.00046585257056284523
Trained batch 527 in epoch 9, gen_loss = 1.0985869465000702, disc_loss = 0.0004654194222535862
Trained batch 528 in epoch 9, gen_loss = 1.098458943835729, disc_loss = 0.000464816491480143
Trained batch 529 in epoch 9, gen_loss = 1.0986620972741326, disc_loss = 0.000464297612546394
Trained batch 530 in epoch 9, gen_loss = 1.0984237185081296, disc_loss = 0.0004644140648924598
Trained batch 531 in epoch 9, gen_loss = 1.0985361203215176, disc_loss = 0.0004648728919349203
Trained batch 532 in epoch 9, gen_loss = 1.09842740482953, disc_loss = 0.0004655597262287829
Trained batch 533 in epoch 9, gen_loss = 1.0981814686055487, disc_loss = 0.00046586092218505094
Trained batch 534 in epoch 9, gen_loss = 1.097949648014853, disc_loss = 0.00046537757801407703
Trained batch 535 in epoch 9, gen_loss = 1.098141000008405, disc_loss = 0.00046492854474295266
Trained batch 536 in epoch 9, gen_loss = 1.0982987899576042, disc_loss = 0.0004643437123665147
Trained batch 537 in epoch 9, gen_loss = 1.0982061758582033, disc_loss = 0.00046369022692789125
Trained batch 538 in epoch 9, gen_loss = 1.0985627244045209, disc_loss = 0.0004630913846019797
Trained batch 539 in epoch 9, gen_loss = 1.0987148886477505, disc_loss = 0.000462471608948868
Trained batch 540 in epoch 9, gen_loss = 1.0989307406429, disc_loss = 0.000461777548439966
Trained batch 541 in epoch 9, gen_loss = 1.0990462161298167, disc_loss = 0.0004612197129187308
Trained batch 542 in epoch 9, gen_loss = 1.0990646911809019, disc_loss = 0.0004607901732011957
Trained batch 543 in epoch 9, gen_loss = 1.0988881705219256, disc_loss = 0.0004601602313548082
Trained batch 544 in epoch 9, gen_loss = 1.0989366066565207, disc_loss = 0.00045947715407237413
Trained batch 545 in epoch 9, gen_loss = 1.098909827706578, disc_loss = 0.00045909339582527077
Trained batch 546 in epoch 9, gen_loss = 1.0985938808599818, disc_loss = 0.00045889307277862805
Trained batch 547 in epoch 9, gen_loss = 1.0985410999860206, disc_loss = 0.0004585768434666879
Trained batch 548 in epoch 9, gen_loss = 1.0981528436551329, disc_loss = 0.0004580339004636788
Trained batch 549 in epoch 9, gen_loss = 1.0987602070244875, disc_loss = 0.00045767219075721434
Trained batch 550 in epoch 9, gen_loss = 1.0984693390271625, disc_loss = 0.00045752412543003323
Trained batch 551 in epoch 9, gen_loss = 1.0986452686829844, disc_loss = 0.0004571547178257142
Trained batch 552 in epoch 9, gen_loss = 1.0987784216891145, disc_loss = 0.0004567158356149787
Trained batch 553 in epoch 9, gen_loss = 1.0988298319952583, disc_loss = 0.00045637967283938363
Trained batch 554 in epoch 9, gen_loss = 1.0987390858633024, disc_loss = 0.0004561201121284719
Trained batch 555 in epoch 9, gen_loss = 1.0991317916045087, disc_loss = 0.00045575758467617666
Trained batch 556 in epoch 9, gen_loss = 1.0991417658607237, disc_loss = 0.00045547092028707937
Trained batch 557 in epoch 9, gen_loss = 1.099365874751067, disc_loss = 0.0004549879842774949
Trained batch 558 in epoch 9, gen_loss = 1.099525774420907, disc_loss = 0.0004546791840405478
Trained batch 559 in epoch 9, gen_loss = 1.0992654425757271, disc_loss = 0.000454476668528514
Trained batch 560 in epoch 9, gen_loss = 1.0988092403360867, disc_loss = 0.0004541536622121266
Trained batch 561 in epoch 9, gen_loss = 1.0993381938051923, disc_loss = 0.0004536608503128856
Trained batch 562 in epoch 9, gen_loss = 1.0994034512216626, disc_loss = 0.00045322583349161906
Trained batch 563 in epoch 9, gen_loss = 1.0994988462180957, disc_loss = 0.0004529851279365962
Trained batch 564 in epoch 9, gen_loss = 1.0994577342430047, disc_loss = 0.0004526920550692398
Trained batch 565 in epoch 9, gen_loss = 1.0994998338786957, disc_loss = 0.00045242470108275385
Trained batch 566 in epoch 9, gen_loss = 1.099452113558586, disc_loss = 0.00045191932606040226
Trained batch 567 in epoch 9, gen_loss = 1.0990801244764261, disc_loss = 0.00045172217026665234
Trained batch 568 in epoch 9, gen_loss = 1.0992455630185105, disc_loss = 0.0004515363766514305
Trained batch 569 in epoch 9, gen_loss = 1.0989046028831548, disc_loss = 0.0004511455518679628
Trained batch 570 in epoch 9, gen_loss = 1.0989526573914363, disc_loss = 0.00045072051253856443
Trained batch 571 in epoch 9, gen_loss = 1.0989392048620676, disc_loss = 0.0004503994224486397
Trained batch 572 in epoch 9, gen_loss = 1.098647872086803, disc_loss = 0.0004506174653844118
Trained batch 573 in epoch 9, gen_loss = 1.098741830952907, disc_loss = 0.0004508756708052782
Trained batch 574 in epoch 9, gen_loss = 1.099024439169013, disc_loss = 0.0004507182479289401
Trained batch 575 in epoch 9, gen_loss = 1.0992931677028537, disc_loss = 0.0004503604916660859
Trained batch 576 in epoch 9, gen_loss = 1.0994947315088797, disc_loss = 0.00045010122714485117
Trained batch 577 in epoch 9, gen_loss = 1.099618695083374, disc_loss = 0.0004500625589596604
Trained batch 578 in epoch 9, gen_loss = 1.0997549234688384, disc_loss = 0.0004502409179003295
Trained batch 579 in epoch 9, gen_loss = 1.0998822221468234, disc_loss = 0.00045054196641009685
Trained batch 580 in epoch 9, gen_loss = 1.100132435303752, disc_loss = 0.0004507309844133904
Trained batch 581 in epoch 9, gen_loss = 1.1000158107772315, disc_loss = 0.0004510803041536412
Trained batch 582 in epoch 9, gen_loss = 1.0999195615586859, disc_loss = 0.0004513334305389859
Trained batch 583 in epoch 9, gen_loss = 1.0999619725019965, disc_loss = 0.0004514104492120343
Trained batch 584 in epoch 9, gen_loss = 1.1001048494607975, disc_loss = 0.0004514658083824807
Trained batch 585 in epoch 9, gen_loss = 1.100133870750564, disc_loss = 0.0004513798553815251
Trained batch 586 in epoch 9, gen_loss = 1.1002687685940498, disc_loss = 0.00045098036379784224
Trained batch 587 in epoch 9, gen_loss = 1.1005657784590104, disc_loss = 0.000450487432948537
Trained batch 588 in epoch 9, gen_loss = 1.1005782901937164, disc_loss = 0.00045005597425379644
Trained batch 589 in epoch 9, gen_loss = 1.1004875761977697, disc_loss = 0.0004495416870251914
Trained batch 590 in epoch 9, gen_loss = 1.1009339466312815, disc_loss = 0.0004489300270001885
Trained batch 591 in epoch 9, gen_loss = 1.1008539369984254, disc_loss = 0.0004483957573029329
Trained batch 592 in epoch 9, gen_loss = 1.1006401789329103, disc_loss = 0.0004478829673483173
Trained batch 593 in epoch 9, gen_loss = 1.100316127944073, disc_loss = 0.0004475107290344987
Trained batch 594 in epoch 9, gen_loss = 1.1003216032220535, disc_loss = 0.0004474051250976377
Trained batch 595 in epoch 9, gen_loss = 1.1000802440931332, disc_loss = 0.0004476037780270246
Trained batch 596 in epoch 9, gen_loss = 1.1002899046918655, disc_loss = 0.0004489200402114001
Trained batch 597 in epoch 9, gen_loss = 1.1001115098446108, disc_loss = 0.00045044816247157184
Trained batch 598 in epoch 9, gen_loss = 1.0996796455924618, disc_loss = 0.0004514070818418768
Trained batch 599 in epoch 9, gen_loss = 1.0998362108071644, disc_loss = 0.0004518320430118668
Trained batch 600 in epoch 9, gen_loss = 1.099531855440378, disc_loss = 0.0004523591247719237
Trained batch 601 in epoch 9, gen_loss = 1.0997084949499745, disc_loss = 0.0004525646054933538
Trained batch 602 in epoch 9, gen_loss = 1.0993073688415351, disc_loss = 0.0004526473966994358
Trained batch 603 in epoch 9, gen_loss = 1.099355573488387, disc_loss = 0.0004534402559636645
Trained batch 604 in epoch 9, gen_loss = 1.099607275734263, disc_loss = 0.00045467725705282283
Trained batch 605 in epoch 9, gen_loss = 1.0999547262789786, disc_loss = 0.0004560104001933177
Trained batch 606 in epoch 9, gen_loss = 1.0999478681083565, disc_loss = 0.00045653964006675703
Trained batch 607 in epoch 9, gen_loss = 1.0999921401472468, disc_loss = 0.00045649690307407963
Trained batch 608 in epoch 9, gen_loss = 1.0997989881410584, disc_loss = 0.00045622323047769624
Trained batch 609 in epoch 9, gen_loss = 1.0997716392649979, disc_loss = 0.00045584488813250066
Trained batch 610 in epoch 9, gen_loss = 1.0994141664715718, disc_loss = 0.0004555942259819221
Trained batch 611 in epoch 9, gen_loss = 1.0990898269259073, disc_loss = 0.0004555274381405397
Trained batch 612 in epoch 9, gen_loss = 1.0991970857827154, disc_loss = 0.00045515715014865564
Trained batch 613 in epoch 9, gen_loss = 1.0989918657351005, disc_loss = 0.0004547896404111309
Trained batch 614 in epoch 9, gen_loss = 1.0991163840138816, disc_loss = 0.00045463001252364036
Trained batch 615 in epoch 9, gen_loss = 1.099118901247328, disc_loss = 0.00045422058242188717
Trained batch 616 in epoch 9, gen_loss = 1.0992549042454416, disc_loss = 0.0004536740033645062
Trained batch 617 in epoch 9, gen_loss = 1.0991894077135906, disc_loss = 0.00045325176960458633
Trained batch 618 in epoch 9, gen_loss = 1.0995394102205944, disc_loss = 0.0004530783374707315
Trained batch 619 in epoch 9, gen_loss = 1.099590244120167, disc_loss = 0.00045292971100875987
Trained batch 620 in epoch 9, gen_loss = 1.0995283329352472, disc_loss = 0.0004527900768117754
Trained batch 621 in epoch 9, gen_loss = 1.0996308885394952, disc_loss = 0.0004527637331860314
Trained batch 622 in epoch 9, gen_loss = 1.0994404997335774, disc_loss = 0.00045278797049096294
Trained batch 623 in epoch 9, gen_loss = 1.1005228346165938, disc_loss = 0.00045330326004962745
Trained batch 624 in epoch 9, gen_loss = 1.100427322101593, disc_loss = 0.0004543876988813281
Trained batch 625 in epoch 9, gen_loss = 1.1004226212493908, disc_loss = 0.00045538153711367194
Trained batch 626 in epoch 9, gen_loss = 1.1004904205338997, disc_loss = 0.0004557167757131706
Trained batch 627 in epoch 9, gen_loss = 1.100987701564078, disc_loss = 0.00045571875782382445
Trained batch 628 in epoch 9, gen_loss = 1.101051009042464, disc_loss = 0.0004565064712121804
Trained batch 629 in epoch 9, gen_loss = 1.1012327321938107, disc_loss = 0.0004577791608873725
Trained batch 630 in epoch 9, gen_loss = 1.1011360195094924, disc_loss = 0.0004588626329281564
Trained batch 631 in epoch 9, gen_loss = 1.1010376623348346, disc_loss = 0.0004601264179516967
Trained batch 632 in epoch 9, gen_loss = 1.100667684940742, disc_loss = 0.0004627126441274639
Trained batch 633 in epoch 9, gen_loss = 1.1008071895653517, disc_loss = 0.0004661415962223992
Trained batch 634 in epoch 9, gen_loss = 1.100605626744548, disc_loss = 0.0004666269335650113
Trained batch 635 in epoch 9, gen_loss = 1.1002694558609956, disc_loss = 0.0004673180551178103
Trained batch 636 in epoch 9, gen_loss = 1.1000981681762347, disc_loss = 0.0004683859362409507
Trained batch 637 in epoch 9, gen_loss = 1.100735257318401, disc_loss = 0.00046963675582064696
Trained batch 638 in epoch 9, gen_loss = 1.1007535331685778, disc_loss = 0.00047058012054654503
Trained batch 639 in epoch 9, gen_loss = 1.1007798512466251, disc_loss = 0.0004707911230525497
Trained batch 640 in epoch 9, gen_loss = 1.1008194029424194, disc_loss = 0.0004712764658022951
Trained batch 641 in epoch 9, gen_loss = 1.1010028002232406, disc_loss = 0.0004714353471458382
Trained batch 642 in epoch 9, gen_loss = 1.100999628310997, disc_loss = 0.00047138786819853285
Trained batch 643 in epoch 9, gen_loss = 1.1007259547340205, disc_loss = 0.0004718141140497972
Trained batch 644 in epoch 9, gen_loss = 1.1004997519559638, disc_loss = 0.00047187203646984036
Trained batch 645 in epoch 9, gen_loss = 1.1004966873871653, disc_loss = 0.0004719860135702324
Trained batch 646 in epoch 9, gen_loss = 1.1010998745421539, disc_loss = 0.00047178260019945824
Trained batch 647 in epoch 9, gen_loss = 1.1011288909264554, disc_loss = 0.0004712825504813938
Trained batch 648 in epoch 9, gen_loss = 1.1014637912183036, disc_loss = 0.0004709435661887687
Trained batch 649 in epoch 9, gen_loss = 1.1012126332062941, disc_loss = 0.0004718529931135261
Trained batch 650 in epoch 9, gen_loss = 1.101051756954779, disc_loss = 0.0004740938349219594
Trained batch 651 in epoch 9, gen_loss = 1.1011560115894656, disc_loss = 0.0004752451722716207
Trained batch 652 in epoch 9, gen_loss = 1.1009433583497636, disc_loss = 0.0004754825689728981
Trained batch 653 in epoch 9, gen_loss = 1.1011378254730038, disc_loss = 0.00047572204914454524
Trained batch 654 in epoch 9, gen_loss = 1.10133540393742, disc_loss = 0.0004759188089386439
Trained batch 655 in epoch 9, gen_loss = 1.1015014117810784, disc_loss = 0.00047606706980664836
Trained batch 656 in epoch 9, gen_loss = 1.1012635719104809, disc_loss = 0.0004759802579990683
Trained batch 657 in epoch 9, gen_loss = 1.101410029325804, disc_loss = 0.0004755908664118493
Trained batch 658 in epoch 9, gen_loss = 1.1014459840444586, disc_loss = 0.0004751974894673661
Trained batch 659 in epoch 9, gen_loss = 1.1013086212403846, disc_loss = 0.0004747806028524682
Trained batch 660 in epoch 9, gen_loss = 1.101503527471049, disc_loss = 0.0004743504773291059
Trained batch 661 in epoch 9, gen_loss = 1.1014400747607482, disc_loss = 0.00047402309496578227
Trained batch 662 in epoch 9, gen_loss = 1.1014256092577859, disc_loss = 0.00047349388926075055
Trained batch 663 in epoch 9, gen_loss = 1.101560196065041, disc_loss = 0.0004730202022567181
Trained batch 664 in epoch 9, gen_loss = 1.1015619873104239, disc_loss = 0.0004724909910097144
Trained batch 665 in epoch 9, gen_loss = 1.1015016893008809, disc_loss = 0.0004722165403663539
Trained batch 666 in epoch 9, gen_loss = 1.1012973852422105, disc_loss = 0.00047235310632603544
Trained batch 667 in epoch 9, gen_loss = 1.1016126083221265, disc_loss = 0.00047230407616808805
Trained batch 668 in epoch 9, gen_loss = 1.101649283739127, disc_loss = 0.0004723308091245032
Trained batch 669 in epoch 9, gen_loss = 1.1018564766022696, disc_loss = 0.0004731211831937405
Trained batch 670 in epoch 9, gen_loss = 1.1016476793012036, disc_loss = 0.0004755411027601383
Trained batch 671 in epoch 9, gen_loss = 1.1014316455416737, disc_loss = 0.00047809930053214583
Trained batch 672 in epoch 9, gen_loss = 1.1014614494027568, disc_loss = 0.0004805998944282673
Trained batch 673 in epoch 9, gen_loss = 1.101423814936986, disc_loss = 0.0004818789891818143
Trained batch 674 in epoch 9, gen_loss = 1.1011681613215694, disc_loss = 0.0004819873526166366
Trained batch 675 in epoch 9, gen_loss = 1.1008444518379912, disc_loss = 0.0004822149852415776
Trained batch 676 in epoch 9, gen_loss = 1.1008298434041979, disc_loss = 0.00048216050309751545
Trained batch 677 in epoch 9, gen_loss = 1.101061927006308, disc_loss = 0.00048204553134551897
Trained batch 678 in epoch 9, gen_loss = 1.1009044603325306, disc_loss = 0.00048183924676689275
Trained batch 679 in epoch 9, gen_loss = 1.100610734259381, disc_loss = 0.0004816953423441566
Trained batch 680 in epoch 9, gen_loss = 1.1005512426953308, disc_loss = 0.00048151667829088063
Trained batch 681 in epoch 9, gen_loss = 1.1007944986967049, disc_loss = 0.00048115666386179073
Trained batch 682 in epoch 9, gen_loss = 1.1006059684132063, disc_loss = 0.0004809736690712727
Trained batch 683 in epoch 9, gen_loss = 1.100517351986372, disc_loss = 0.000480927784183595
Trained batch 684 in epoch 9, gen_loss = 1.1005739893356379, disc_loss = 0.0004806779597139829
Trained batch 685 in epoch 9, gen_loss = 1.100525174040141, disc_loss = 0.0004802605669837548
Trained batch 686 in epoch 9, gen_loss = 1.100538460188037, disc_loss = 0.000479848009387263
Trained batch 687 in epoch 9, gen_loss = 1.1005686175857865, disc_loss = 0.00047941778141881344
Trained batch 688 in epoch 9, gen_loss = 1.1006353660141954, disc_loss = 0.00047907857925118133
Trained batch 689 in epoch 9, gen_loss = 1.1007213938927305, disc_loss = 0.0004785943812010742
Trained batch 690 in epoch 9, gen_loss = 1.1010636138674492, disc_loss = 0.0004782380546138564
Trained batch 691 in epoch 9, gen_loss = 1.1008006543610138, disc_loss = 0.0004778981288584458
Trained batch 692 in epoch 9, gen_loss = 1.1007524911975448, disc_loss = 0.0004773522822062376
Trained batch 693 in epoch 9, gen_loss = 1.1005227430924902, disc_loss = 0.00047682954270781154
Trained batch 694 in epoch 9, gen_loss = 1.1002839986368906, disc_loss = 0.0004764021910926354
Trained batch 695 in epoch 9, gen_loss = 1.1003656347078838, disc_loss = 0.0004761775033476551
Trained batch 696 in epoch 9, gen_loss = 1.1003549512010735, disc_loss = 0.00047572790370309403
Trained batch 697 in epoch 9, gen_loss = 1.1005898848133306, disc_loss = 0.0004752623896525818
Trained batch 698 in epoch 9, gen_loss = 1.1006791732341947, disc_loss = 0.00047477991853554855
Trained batch 699 in epoch 9, gen_loss = 1.1003564312628338, disc_loss = 0.0004743358108472811
Trained batch 700 in epoch 9, gen_loss = 1.1004134920796382, disc_loss = 0.0004740242184976451
Trained batch 701 in epoch 9, gen_loss = 1.1003308027048735, disc_loss = 0.0004741899630655481
Trained batch 702 in epoch 9, gen_loss = 1.1006200102450667, disc_loss = 0.00047512326887918035
Trained batch 703 in epoch 9, gen_loss = 1.1006529472598976, disc_loss = 0.0004763187686090863
Trained batch 704 in epoch 9, gen_loss = 1.1003104817782734, disc_loss = 0.00047693064678642
Trained batch 705 in epoch 9, gen_loss = 1.100129291119724, disc_loss = 0.0004770526078207453
Trained batch 706 in epoch 9, gen_loss = 1.099956593385343, disc_loss = 0.0004769801875782862
Trained batch 707 in epoch 9, gen_loss = 1.099795710400673, disc_loss = 0.00047668440948259535
Trained batch 708 in epoch 9, gen_loss = 1.0998761094003202, disc_loss = 0.00047639660422387435
Trained batch 709 in epoch 9, gen_loss = 1.0997974721478745, disc_loss = 0.000476167144923648
Trained batch 710 in epoch 9, gen_loss = 1.100299258272356, disc_loss = 0.0004769628810404529
Trained batch 711 in epoch 9, gen_loss = 1.100104519992732, disc_loss = 0.00047823110940095083
Trained batch 712 in epoch 9, gen_loss = 1.100189036941796, disc_loss = 0.00047883484873814224
Trained batch 713 in epoch 9, gen_loss = 1.1001572695766844, disc_loss = 0.00047973814912884513
Trained batch 714 in epoch 9, gen_loss = 1.1001825716112044, disc_loss = 0.00048028143626308863
Trained batch 715 in epoch 9, gen_loss = 1.100327788285037, disc_loss = 0.00048046291797430326
Trained batch 716 in epoch 9, gen_loss = 1.1001245132550037, disc_loss = 0.0004808136774137723
Trained batch 717 in epoch 9, gen_loss = 1.1000778600366004, disc_loss = 0.0004811708809599387
Trained batch 718 in epoch 9, gen_loss = 1.1000636557378756, disc_loss = 0.0004822246527977052
Trained batch 719 in epoch 9, gen_loss = 1.1002808479799164, disc_loss = 0.0004855709840234744
Trained batch 720 in epoch 9, gen_loss = 1.100141383655855, disc_loss = 0.0004920453914699834
Trained batch 721 in epoch 9, gen_loss = 1.10021516185388, disc_loss = 0.0004964253915852088
Trained batch 722 in epoch 9, gen_loss = 1.1000168296311406, disc_loss = 0.0004982716840620051
Trained batch 723 in epoch 9, gen_loss = 1.0998975240229243, disc_loss = 0.0004987287290597872
Trained batch 724 in epoch 9, gen_loss = 1.099925571556749, disc_loss = 0.0004991207694321679
Trained batch 725 in epoch 9, gen_loss = 1.100120757811654, disc_loss = 0.0004990067134828424
Trained batch 726 in epoch 9, gen_loss = 1.0999011694155172, disc_loss = 0.0004989236231630365
Trained batch 727 in epoch 9, gen_loss = 1.1000749502371956, disc_loss = 0.000498757878001645
Trained batch 728 in epoch 9, gen_loss = 1.1001394188289617, disc_loss = 0.0004984795430121657
Trained batch 729 in epoch 9, gen_loss = 1.1001398167381549, disc_loss = 0.0004980819183202422
Trained batch 730 in epoch 9, gen_loss = 1.1000945322653826, disc_loss = 0.000498017184696703
Trained batch 731 in epoch 9, gen_loss = 1.1004282613106764, disc_loss = 0.0004990751859011533
Trained batch 732 in epoch 9, gen_loss = 1.1003868627840956, disc_loss = 0.0004997922070532476
Trained batch 733 in epoch 9, gen_loss = 1.1001895511020432, disc_loss = 0.0004997576793047665
Trained batch 734 in epoch 9, gen_loss = 1.100482630486391, disc_loss = 0.0004993108178601366
Trained batch 735 in epoch 9, gen_loss = 1.1004874490039505, disc_loss = 0.0004991454423401118
Trained batch 736 in epoch 9, gen_loss = 1.1004990983850436, disc_loss = 0.0004991046013413224
Trained batch 737 in epoch 9, gen_loss = 1.1005833711889055, disc_loss = 0.0004987300143188792
Trained batch 738 in epoch 9, gen_loss = 1.1005642050335307, disc_loss = 0.000498501046615683
Trained batch 739 in epoch 9, gen_loss = 1.1002375609971382, disc_loss = 0.0004983292259960247
Trained batch 740 in epoch 9, gen_loss = 1.1001369915349604, disc_loss = 0.0004981431746803533
Trained batch 741 in epoch 9, gen_loss = 1.1003242619436064, disc_loss = 0.0004979864856524134
Trained batch 742 in epoch 9, gen_loss = 1.1002072460879226, disc_loss = 0.0004980120306148621
Trained batch 743 in epoch 9, gen_loss = 1.1000551872195736, disc_loss = 0.00049813447281282
Trained batch 744 in epoch 9, gen_loss = 1.0997666836584974, disc_loss = 0.0004991292499354259
Trained batch 745 in epoch 9, gen_loss = 1.0996290359835843, disc_loss = 0.000500640274994119
Trained batch 746 in epoch 9, gen_loss = 1.099495272160853, disc_loss = 0.0005022106236780381
Trained batch 747 in epoch 9, gen_loss = 1.0995064550701947, disc_loss = 0.0005027033221267629
Trained batch 748 in epoch 9, gen_loss = 1.0994551206462693, disc_loss = 0.0005027764002276206
Trained batch 749 in epoch 9, gen_loss = 1.0995164778232573, disc_loss = 0.0005030918315169402
Trained batch 750 in epoch 9, gen_loss = 1.0998102225730326, disc_loss = 0.0005033715632854194
Trained batch 751 in epoch 9, gen_loss = 1.0997361996547972, disc_loss = 0.0005033534116591909
Trained batch 752 in epoch 9, gen_loss = 1.099544289656686, disc_loss = 0.0005045453286357162
Trained batch 753 in epoch 9, gen_loss = 1.0997491870223686, disc_loss = 0.0005052551727015365
Trained batch 754 in epoch 9, gen_loss = 1.0998653340023874, disc_loss = 0.0005054987818796792
Trained batch 755 in epoch 9, gen_loss = 1.0999225445052303, disc_loss = 0.0005066050410388646
Trained batch 756 in epoch 9, gen_loss = 1.0997854191686864, disc_loss = 0.0005073534312885306
Trained batch 757 in epoch 9, gen_loss = 1.0999261426265132, disc_loss = 0.0005077709948039235
Trained batch 758 in epoch 9, gen_loss = 1.099911755645385, disc_loss = 0.0005082083446774644
Trained batch 759 in epoch 9, gen_loss = 1.1000495887900654, disc_loss = 0.0005088570146127543
Trained batch 760 in epoch 9, gen_loss = 1.1000562557722986, disc_loss = 0.0005090381561693736
Trained batch 761 in epoch 9, gen_loss = 1.0998738624761737, disc_loss = 0.0005092129781480153
Trained batch 762 in epoch 9, gen_loss = 1.1000322301140932, disc_loss = 0.0005090918920732495
Trained batch 763 in epoch 9, gen_loss = 1.0998279350122233, disc_loss = 0.0005088080871289203
Trained batch 764 in epoch 9, gen_loss = 1.0997840509695165, disc_loss = 0.000508801791618359
Trained batch 765 in epoch 9, gen_loss = 1.0995123136603802, disc_loss = 0.0005087702733690379
Trained batch 766 in epoch 9, gen_loss = 1.0994780034875933, disc_loss = 0.0005085657246104554
Trained batch 767 in epoch 9, gen_loss = 1.0991929237886022, disc_loss = 0.0005084280410490768
Trained batch 768 in epoch 9, gen_loss = 1.0992212894679045, disc_loss = 0.000508594467028066
Trained batch 769 in epoch 9, gen_loss = 1.099036827102884, disc_loss = 0.0005090376384315903
Trained batch 770 in epoch 9, gen_loss = 1.0993833423588526, disc_loss = 0.0005090126633408858
Trained batch 771 in epoch 9, gen_loss = 1.0991173066160222, disc_loss = 0.000509396385510212
Trained batch 772 in epoch 9, gen_loss = 1.0990186324403326, disc_loss = 0.0005104391945607027
Trained batch 773 in epoch 9, gen_loss = 1.0990367230672862, disc_loss = 0.0005109094624813389
Trained batch 774 in epoch 9, gen_loss = 1.0992800321117524, disc_loss = 0.0005111554456732026
Trained batch 775 in epoch 9, gen_loss = 1.0992889366659921, disc_loss = 0.0005115229812441406
Trained batch 776 in epoch 9, gen_loss = 1.0994619334373081, disc_loss = 0.0005116749646753718
Trained batch 777 in epoch 9, gen_loss = 1.0993572944693824, disc_loss = 0.0005117872178533287
Trained batch 778 in epoch 9, gen_loss = 1.100012003457286, disc_loss = 0.0005119814207684428
Trained batch 779 in epoch 9, gen_loss = 1.1002668438049463, disc_loss = 0.0005121596583101051
Trained batch 780 in epoch 9, gen_loss = 1.1005683747357504, disc_loss = 0.000511902335773475
Trained batch 781 in epoch 9, gen_loss = 1.1002501051901552, disc_loss = 0.0005118431749685472
Trained batch 782 in epoch 9, gen_loss = 1.1003293443761415, disc_loss = 0.0005124701053166696
Trained batch 783 in epoch 9, gen_loss = 1.1004006852756958, disc_loss = 0.0005133706509343251
Trained batch 784 in epoch 9, gen_loss = 1.1004298500953966, disc_loss = 0.0005141818960261038
Trained batch 785 in epoch 9, gen_loss = 1.1003151573145966, disc_loss = 0.000514346434293835
Trained batch 786 in epoch 9, gen_loss = 1.1003474773415465, disc_loss = 0.0005140573841872007
Trained batch 787 in epoch 9, gen_loss = 1.10036895685087, disc_loss = 0.0005136814211739871
Trained batch 788 in epoch 9, gen_loss = 1.100433616659336, disc_loss = 0.0005131895970652017
Trained batch 789 in epoch 9, gen_loss = 1.1004479440707196, disc_loss = 0.0005126675418644401
Testing Epoch 9
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 1
Epoch 1, batch no. 10, gen. loss: nan, disc. loss: 0.33425143361091614
Epoch 1, batch no. 20, gen. loss: nan, disc. loss: 0.49981629848480225
Epoch 1, batch no. 30, gen. loss: nan, disc. loss: 0.3292669653892517
Epoch 1, batch no. 40, gen. loss: nan, disc. loss: 0.359843909740448
Epoch 1, batch no. 50, gen. loss: nan, disc. loss: 0.41761258244514465
Epoch 1, batch no. 60, gen. loss: nan, disc. loss: 0.4004706144332886
Epoch 1, batch no. 70, gen. loss: nan, disc. loss: 0.3284730911254883
Epoch 1, batch no. 80, gen. loss: nan, disc. loss: 1.5625184774398804
Epoch 1, batch no. 90, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 100, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 110, gen. loss: nan, disc. loss: 0.4554162323474884
Epoch 1, batch no. 120, gen. loss: nan, disc. loss: 2.4945216178894043
Epoch 1, batch no. 130, gen. loss: nan, disc. loss: 1.1348552703857422
Epoch 1, batch no. 140, gen. loss: nan, disc. loss: 1.3025754690170288
Epoch 1, batch no. 150, gen. loss: nan, disc. loss: 1.2330135107040405
Epoch 1, batch no. 160, gen. loss: nan, disc. loss: 1.4227430820465088
Epoch 1, batch no. 170, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 180, gen. loss: nan, disc. loss: 1.6242411136627197
Epoch 1, batch no. 190, gen. loss: nan, disc. loss: 1.4250972270965576
Epoch 1, batch no. 200, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 210, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 220, gen. loss: nan, disc. loss: 1.5658509731292725
Epoch 1, batch no. 230, gen. loss: nan, disc. loss: 1.4290181398391724
Epoch 1, batch no. 240, gen. loss: nan, disc. loss: 1.4936472177505493
Epoch 1, batch no. 250, gen. loss: nan, disc. loss: 1.5934823751449585
Epoch 1, batch no. 260, gen. loss: nan, disc. loss: 1.5116313695907593
Epoch 1, batch no. 270, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 280, gen. loss: nan, disc. loss: 1.3150986433029175
Epoch 1, batch no. 290, gen. loss: nan, disc. loss: 1.4454212188720703
Epoch 1, batch no. 300, gen. loss: nan, disc. loss: 1.6344070434570312
Epoch 1, batch no. 310, gen. loss: nan, disc. loss: 1.7459743022918701
Epoch 1, batch no. 320, gen. loss: nan, disc. loss: 1.4563713073730469
Epoch 1, batch no. 330, gen. loss: nan, disc. loss: 1.598517656326294
Epoch 1, batch no. 340, gen. loss: nan, disc. loss: 1.6740292310714722
Epoch 1, batch no. 350, gen. loss: nan, disc. loss: 1.4889531135559082
Epoch 1, batch no. 360, gen. loss: nan, disc. loss: 1.5100677013397217
Epoch 1, batch no. 370, gen. loss: nan, disc. loss: 1.603387475013733
Epoch 1, batch no. 380, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 390, gen. loss: nan, disc. loss: 1.3785663843154907
Epoch 1, batch no. 400, gen. loss: nan, disc. loss: 1.4808733463287354
Epoch 1, batch no. 410, gen. loss: nan, disc. loss: 1.476181983947754
Epoch 1, batch no. 420, gen. loss: nan, disc. loss: 1.0105807781219482
Epoch 1, batch no. 430, gen. loss: nan, disc. loss: 1.5549027919769287
Epoch 1, batch no. 440, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 450, gen. loss: nan, disc. loss: 1.5805760622024536
Epoch 1, batch no. 460, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 470, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 480, gen. loss: nan, disc. loss: 1.0080491304397583
Epoch 1, batch no. 490, gen. loss: nan, disc. loss: 1.6148643493652344
Epoch 1, batch no. 500, gen. loss: nan, disc. loss: 1.5337899923324585
Epoch 1, batch no. 510, gen. loss: nan, disc. loss: 1.3734769821166992
Epoch 1, batch no. 520, gen. loss: nan, disc. loss: 1.5093536376953125
Epoch 1, batch no. 530, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 540, gen. loss: nan, disc. loss: 1.6495261192321777
Epoch 1, batch no. 550, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 560, gen. loss: nan, disc. loss: 1.463698148727417
Epoch 1, batch no. 570, gen. loss: nan, disc. loss: 1.572628378868103
Epoch 1, batch no. 580, gen. loss: nan, disc. loss: 1.5124133825302124
Epoch 1, batch no. 590, gen. loss: nan, disc. loss: 1.4196147918701172
Epoch 1, batch no. 600, gen. loss: nan, disc. loss: 1.4232728481292725
Epoch 1, batch no. 610, gen. loss: nan, disc. loss: 1.6331037282943726
Epoch 1, batch no. 620, gen. loss: nan, disc. loss: 1.315101146697998
Epoch 1, batch no. 630, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 640, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 650, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 660, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 670, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 680, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 690, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 700, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 710, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 720, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 730, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 740, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 750, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 760, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 770, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 780, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 790, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 800, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 810, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 820, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 830, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 840, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 850, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 860, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 870, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 880, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 890, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 900, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 910, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 920, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 930, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 940, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 950, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 960, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 970, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 980, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 990, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 1000, gen. loss: nan, disc. loss: nan
Epoch 1, batch no. 1010, gen. loss: nan, disc. loss: nan
Testing Epoch 1
Discriminator training/validation loss in epoch 1/1 was nan/nan
Generator GAN training/validation loss in epoch 1/1 was nan/nan
Average PSNR of validation set in epoch 1/1 was 7.9244
Average SSIM of validation set in epoch 1/1 was -0.0257
Average discriminator guess on reals in epoch 1/1 was nan
Average discriminator guess on fakes in epoch 1/1 was nan